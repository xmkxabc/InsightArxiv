{"id": "2507.10578", "title": "When and Where do Data Poisons Attack Textual Inversion?", "authors": ["Jeremy Styborski", "Mingzhi Lyu", "Jiayou Lu", "Nupur Kapur", "Adams Kong"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV", "url": "http://arxiv.org/abs/2507.10578v1", "summary": "Poisoning attacks pose significant challenges to the robustness of diffusion\nmodels (DMs). In this paper, we systematically analyze when and where poisoning\nattacks textual inversion (TI), a widely used personalization technique for\nDMs. We first introduce Semantic Sensitivity Maps, a novel method for\nvisualizing the influence of poisoning on text embeddings. Second, we identify\nand experimentally verify that DMs exhibit non-uniform learning behavior across\ntimesteps, focusing on lower-noise samples. Poisoning attacks inherit this bias\nand inject adversarial signals predominantly at lower timesteps. Lastly, we\nobserve that adversarial signals distract learning away from relevant concept\nregions within training data, corrupting the TI process. Based on these\ninsights, we propose Safe-Zone Training (SZT), a novel defense mechanism\ncomprised of 3 key components: (1) JPEG compression to weaken high-frequency\npoison signals, (2) restriction to high timesteps during TI training to avoid\nadversarial signals at lower timesteps, and (3) loss masking to constrain\nlearning to relevant regions. Extensive experiments across multiple poisoning\nmethods demonstrate that SZT greatly enhances the robustness of TI against all\npoisoning attacks, improving generative quality beyond prior published\ndefenses. Code: www.github.com/JStyborski/Diff_Lab Data:\nwww.github.com/JStyborski/NC10", "comment": "Accepted to ICCV", "pdf_url": "http://arxiv.org/pdf/2507.10578v1", "cate": "cs.CR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.10592", "title": "Breaking a 5-Bit Elliptic Curve Key using a 133-Qubit Quantum Computer", "authors": ["Steve Tippeconnic"], "categories": ["cs.CR", "68Q12, 81P68, 11T71"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      32 pages, 5 figures, real hardware results from IBM Quantum, all code, circuits, and raw data are publicly available for replication", "url": "http://arxiv.org/abs/2507.10592v1", "summary": "This experiment breaks a 5-bit elliptic curve cryptographic key using a\nShor-style quantum attack. Executed on IBM's 133-qubit ibm_torino with Qiskit\nRuntime 2.0, a 15-qubit circuit, comprised of 10 logical qubits and 5 ancilla,\ninterferes over an order-32 elliptic curve subgroup to extract the secret\nscalar k from the public key relation Q = kP, without ever encoding k directly\ninto the oracle. From 16,384 shots, the quantum interference reveals a diagonal\nridge in the 32 x 32 QFT outcome space. The quantum circuit, over 67,000 layers\ndeep, produced valid interference patterns despite extreme circuit depth, and\nclassical post-processing revealed k = 7 in the top 100 invertible (a, b)\nresults. All code, circuits, and raw data are publicly available for\nreplication.", "comment": "32 pages, 5 figures, real hardware results from IBM Quantum, all\n  code, circuits, and raw data are publicly available for replication", "pdf_url": "http://arxiv.org/pdf/2507.10592v1", "cate": "cs.CR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.10610", "title": "LaSM: Layer-wise Scaling Mechanism for Defending Pop-up Attack on GUI Agents", "authors": ["Zihe Yan", "Zhuosheng Zhang"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      10 pages, 9 figures", "url": "http://arxiv.org/abs/2507.10610v1", "summary": "Graphical user interface (GUI) agents built on multimodal large language\nmodels (MLLMs) have recently demonstrated strong decision-making abilities in\nscreen-based interaction tasks. However, they remain highly vulnerable to\npop-up-based environmental injection attacks, where malicious visual elements\ndivert model attention and lead to unsafe or incorrect actions. Existing\ndefense methods either require costly retraining or perform poorly under\ninductive interference. In this work, we systematically study how such attacks\nalter the attention behavior of GUI agents and uncover a layer-wise attention\ndivergence pattern between correct and incorrect outputs. Based on this\ninsight, we propose \\textbf{LaSM}, a \\textit{Layer-wise Scaling Mechanism} that\nselectively amplifies attention and MLP modules in critical layers. LaSM\nimproves the alignment between model saliency and task-relevant regions without\nadditional training. Extensive experiments across 12 types of pop-up\nperturbations and 4 different model backbones show that LaSM consistently\nenhances the defense success rate. When combined with prompt-level alerts, LaSM\nachieves over 98\\% robustness even under strong inductive attacks. Our findings\nreveal that attention misalignment is a core vulnerability in MLLM agents and\ncan be effectively addressed through selective layer-wise modulation.", "comment": "10 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.10610v1", "cate": "cs.CR", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.10621", "title": "Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats", "authors": ["Quanyan Zhu"], "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.GT"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10621v1", "summary": "Protecting cyberspace requires not only advanced tools but also a shift in\nhow we reason about threats, trust, and autonomy. Traditional cybersecurity\nmethods rely on manual responses and brittle heuristics. To build proactive and\nintelligent defense systems, we need integrated theoretical frameworks and\nsoftware tools. Game theory provides a rigorous foundation for modeling\nadversarial behavior, designing strategic defenses, and enabling trust in\nautonomous systems. Meanwhile, software tools process cyber data, visualize\nattack surfaces, verify compliance, and suggest mitigations. Yet a disconnect\nremains between theory and practical implementation.\n  The rise of Large Language Models (LLMs) and agentic AI offers a new path to\nbridge this gap. LLM-powered agents can operationalize abstract strategies into\nreal-world decisions. Conversely, game theory can inform the reasoning and\ncoordination of these agents across complex workflows. LLMs also challenge\nclassical game-theoretic assumptions, such as perfect rationality or static\npayoffs, prompting new models aligned with cognitive and computational\nrealities. This co-evolution promises richer theoretical foundations and novel\nsolution concepts. Agentic AI also reshapes software design: systems must now\nbe modular, adaptive, and trust-aware from the outset.\n  This chapter explores the intersection of game theory, agentic AI, and\ncybersecurity. We review key game-theoretic frameworks (e.g., static, dynamic,\nBayesian, and signaling games) and solution concepts. We then examine how LLM\nagents can enhance cyber defense and introduce LLM-driven games that embed\nreasoning into AI agents. Finally, we explore multi-agent workflows and\ncoordination games, outlining how this convergence fosters secure, intelligent,\nand adaptive cyber systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10621v1", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10622", "title": "Spectral Feature Extraction for Robust Network Intrusion Detection Using MFCCs", "authors": ["HyeYoung Lee", "Muhammad Nadeem", "Pavel Tsoi"], "categories": ["cs.CR", "cond-mat.dis-nn", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10622v1", "summary": "The rapid expansion of Internet of Things (IoT) networks has led to a surge\nin security vulnerabilities, emphasizing the critical need for robust anomaly\ndetection and classification techniques. In this work, we propose a novel\napproach for identifying anomalies in IoT network traffic by leveraging the\nMel-frequency cepstral coefficients (MFCC) and ResNet-18, a deep learning model\nknown for its effectiveness in feature extraction and image-based tasks.\nLearnable MFCCs enable adaptive spectral feature representation, capturing the\ntemporal patterns inherent in network traffic more effectively than traditional\nfixed MFCCs. We demonstrate that transforming raw signals into MFCCs maps the\ndata into a higher-dimensional space, enhancing class separability and enabling\nmore effective multiclass classification. Our approach combines the strengths\nof MFCCs with the robust feature extraction capabilities of ResNet-18, offering\na powerful framework for anomaly detection. The proposed model is evaluated on\nthree widely used IoT intrusion detection datasets: CICIoT2023, NSL-KDD, and\nIoTID20. The experimental results highlight the potential of integrating\nadaptive signal processing techniques with deep learning architectures to\nachieve robust and scalable anomaly detection in heterogeneous IoT network\nlandscapes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10622v1", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10627", "title": "Crypto-Assisted Graph Degree Sequence Release under Local Differential Privacy", "authors": ["Xiaojian Zhang", "Junqing Wang", "Kerui Chen", "Peiyuan Zhao", "Huiyuan Bai"], "categories": ["cs.CR", "cs.DB"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10627v1", "summary": "Given a graph $G$ defined in a domain $\\mathcal{G}$, we investigate locally\ndifferentially private mechanisms to release a degree sequence on $\\mathcal{G}$\nthat accurately approximates the actual degree distribution. Existing solutions\nfor this problem mostly use graph projection techniques based on edge deletion\nprocess, using a threshold parameter $\\theta$ to bound node degrees. However,\nthis approach presents a fundamental trade-off in threshold parameter\nselection. While large $\\theta$ values introduce substantial noise in the\nreleased degree sequence, small $\\theta$ values result in more edges removed\nthan necessary. Furthermore, $\\theta$ selection leads to an excessive\ncommunication cost. To remedy existing solutions' deficiencies, we present\nCADR-LDP, an efficient framework incorporating encryption techniques and\ndifferentially private mechanisms to release the degree sequence. In CADR-LDP,\nwe first use the crypto-assisted Optimal-$\\theta$-Selection method to select\nthe optimal parameter with a low communication cost. Then, we use the LPEA-LOW\nmethod to add some edges for each node with the edge addition process in local\nprojection. LPEA-LOW prioritizes the projection with low-degree nodes, which\ncan retain more edges for such nodes and reduce the projection error.\nTheoretical analysis shows that CADR-LDP satisfies $\\epsilon$-node local\ndifferential privacy. The experimental results on eight graph datasets show\nthat our solution outperforms existing methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10627v1", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10730", "title": "Access Control for Information-Theoretically Secure Key-Document Stores", "authors": ["Yin Li", "Sharad Mehrota", "Shantanu Sharma", "Komal Kumari"], "categories": ["cs.CR", "cs.DB", "cs.DC", "cs.DS", "cs.IR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      An extended abstract of this version has been accepted in VLDB 2025", "url": "http://arxiv.org/abs/2507.10730v1", "summary": "This paper presents a novel key-based access control technique for secure\noutsourcing key-value stores where values correspond to documents that are\nindexed and accessed using keys. The proposed approach adopts Shamir's\nsecret-sharing that offers unconditional or information-theoretic security. It\nsupports keyword-based document retrieval while preventing leakage of the data,\naccess rights of users, or the size (\\textit{i}.\\textit{e}., volume of the\noutput that satisfies a query). The proposed approach allows servers to detect\n(and abort) malicious clients from gaining unauthorized access to data, and\nprevents malicious servers from altering data undetected while ensuring\nefficient access -- it takes 231.5ms over 5,000 keywords across 500,000 files.", "comment": "An extended abstract of this version has been accepted in VLDB 2025", "pdf_url": "http://arxiv.org/pdf/2507.10730v1", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10733", "title": "3S-Attack: Spatial, Spectral and Semantic Invisible Backdoor Attack Against DNN Models", "authors": ["Jianyao Yin", "Luca Arnaboldi", "Honglong Chen", "Pascal Berrang"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      14 pages, 10 figures", "url": "http://arxiv.org/abs/2507.10733v1", "summary": "Backdoor attacks involve either poisoning the training data or directly\nmodifying the model in order to implant a hidden behavior, that causes the\nmodel to misclassify inputs when a specific trigger is present. During\ninference, the model maintains high accuracy on benign samples but\nmisclassifies poisoned samples into an attacker-specified target class.\nExisting research on backdoor attacks has explored developing triggers in the\nspatial, spectral (frequency), and semantic (feature) domains, aiming to make\nthem stealthy. While some approaches have considered designing triggers that\nare imperceptible in both spatial and spectral domains, few have incorporated\nthe semantic domain. In this paper, we propose a novel backdoor attack, termed\n3S-attack, which is stealthy across the spatial, spectral, and semantic\ndomains. The key idea is to exploit the semantic features of benign samples as\ntriggers, using Gradient-weighted Class Activation Mapping (Grad-CAM) and a\npreliminary model for extraction. The trigger is then embedded in the spectral\ndomain, followed by pixel-level restrictions after converting the samples back\nto the spatial domain. This process minimizes the distance between poisoned and\nbenign samples, making the attack harder to detect by existing defenses and\nhuman inspection. Extensive experiments on various datasets, along with\ntheoretical analysis, demonstrate the stealthiness of 3S-attack and highlight\nthe need for stronger defenses to ensure AI security. Our code is available at:\nhttps://anonymous.4open.science/r/anon-project-3776/", "comment": "14 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.10733v1", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10808", "title": "Contrastive-KAN: A Semi-Supervised Intrusion Detection Framework for Cybersecurity with scarce Labeled Data", "authors": ["Mohammad Alikhani", "Reza Kazemi"], "categories": ["cs.CR", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10808v1", "summary": "In the era of the Fourth Industrial Revolution, cybersecurity and intrusion\ndetection systems are vital for the secure and reliable operation of IoT and\nIIoT environments. A key challenge in this domain is the scarcity of labeled\ncyber-attack data, as most industrial systems operate under normal conditions.\nThis data imbalance, combined with the high cost of annotation, hinders the\neffective training of machine learning models. Moreover, rapid detection of\nattacks is essential, especially in critical infrastructure, to prevent\nlarge-scale disruptions. To address these challenges, we propose a real-time\nintrusion detection system based on a semi-supervised contrastive learning\nframework using the Kolmogorov-Arnold Network (KAN). Our method leverages\nabundant unlabeled data to distinguish between normal and attack behaviors\neffectively. We validate our approach on three benchmark datasets: UNSW-NB15,\nBoT-IoT, and Gas Pipeline, using only 2.20 percent, 1.28 percent, and 8 percent\nof labeled samples, respectively, to simulate real-world conditions.\nExperimental results show that our method outperforms existing contrastive\nlearning-based approaches. We further compare KAN with a traditional multilayer\nperceptron (MLP), demonstrating KAN's superior performance in both detection\naccuracy and robustness under limited supervision. KAN's ability to model\ncomplex relationships and its learnable activation functions are also explored\nand visualized, offering interpretability and potential for rule extraction.\nThe method supports multi-class classification and proves effective in\nsafety-critical environments where reliability is paramount.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10808v1", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10819", "title": "Reporte de vulnerabilidades en IIoT. Proyecto DEFENDER", "authors": ["Pedro Almansa Jiménez", "Lorenzo Fernández Maimó", "Ángel Luis Peráles Gómez"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Language: Spanish", "url": "http://arxiv.org/abs/2507.10819v1", "summary": "The main objective of this technical report is to conduct a comprehensive\nstudy on devices operating within Industrial Internet of Things (IIoT)\nenvironments, describing the scenarios that define this category and analysing\nthe vulnerabilities that compromise their security. To this end, the report\nseeks to identify and examine the main classes of IIoT devices, detailing their\ncharacteristics, functionalities, and roles within industrial systems. This\nanalysis enables a better understanding of how these devices interact and\nfulfil the requirements of critical industrial environments. The report also\nexplores the specific contexts in which these devices operate, highlighting the\ndistinctive features of industrial scenarios and the conditions under which the\ndevices function. Furthermore, it analyses the vulnerabilities affecting IIoT\ndevices, outlining their vectors, targets, impact, and consequences. The report\nthen describes the typical phases of an attack, along with a selection of\nreal-world documented incidents. These cases are classified according to the\ntaxonomy presented in Section 3, providing a comprehensive view of the\npotential threats to security and assessing the impact these vulnerabilities\nmay have on industrial environments. Finally, the report presents a compilation\nof some of the most recent and effective security countermeasures as potential\nsolutions to the security challenges faced by industrial systems. Special\nemphasis is placed on the role of Machine Learning in the development of these\napproaches, underscoring its importance in enhancing industrial cybersecurity.", "comment": "Language: Spanish", "pdf_url": "http://arxiv.org/pdf/2507.10819v1", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10836", "title": "REAL-IoT: Characterizing GNN Intrusion Detection Robustness under Practical Adversarial Attack", "authors": ["Zhonghao Zhan", "Huichi Zhou", "Hamed Haddadi"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10836v1", "summary": "Graph Neural Network (GNN)-based network intrusion detection systems (NIDS)\nare often evaluated on single datasets, limiting their ability to generalize\nunder distribution drift. Furthermore, their adversarial robustness is\ntypically assessed using synthetic perturbations that lack realism. This\nmeasurement gap leads to an overestimation of GNN-based NIDS resilience. To\naddress the limitations, we propose \\textbf{REAL-IoT}, a comprehensive\nframework for robustness evaluation of GNN-based NIDS in IoT environments. Our\nframework presents a methodology that creates a unified dataset from canonical\ndatasets to assess generalization under drift. In addition, it features a novel\nintrusion dataset collected from a physical IoT testbed, which captures network\ntraffic and attack scenarios under real-world settings. Furthermore, using\nREAL-IoT, we explore the usage of Large Language Models (LLMs) to analyze\nnetwork data and mitigate the impact of adversarial examples by filtering\nsuspicious flows. Our evaluations using REAL-IoT reveal performance drops in\nGNN models compared to results from standard benchmarks, quantifying their\nsusceptibility to drift and realistic attacks. We also demonstrate the\npotential of LLM-based filtering to enhance robustness. These findings\nemphasize the necessity of realistic threat modeling and rigorous measurement\npractices for developing resilient IoT intrusion detection systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10836v1", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10845", "title": "BandFuzz: An ML-powered Collaborative Fuzzing Framework", "authors": ["Wenxuan Shi", "Hongwei Li", "Jiahao Yu", "Xinqian Sun", "Wenbo Guo", "Xinyu Xing"], "categories": ["cs.CR", "cs.SE"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10845v1", "summary": "Collaborative fuzzing has recently emerged as a technique that combines\nmultiple individual fuzzers and dynamically chooses the appropriate\ncombinations suited for different programs. Unlike individual fuzzers, which\nrely on specific assumptions to maintain their effectiveness, collaborative\nfuzzing relaxes the assumptions on target programs, providing constant and\nrobust performance across various programs. Ideally, collaborative fuzzing\nshould be a more promising direction toward generic fuzzing solutions, as it\nmitigates the need for manual cherry-picking of individual fuzzers. However,\nthe effectiveness of existing collaborative fuzzing frameworks is limited by\nmajor challenges, such as the need for additional computational resources\ncompared to individual fuzzers and the inefficient allocation of resources\namong the various fuzzers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10845v1", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10854", "title": "PhreshPhish: A Real-World, High-Quality, Large-Scale Phishing Website Dataset and Benchmark", "authors": ["Thomas Dalton", "Hemanth Gowda", "Girish Rao", "Sachin Pargi", "Alireza Hadj Khodabakhshi", "Joseph Rombs", "Stephan Jou", "Manish Marwah"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10854v1", "summary": "Phishing remains a pervasive and growing threat, inflicting heavy economic\nand reputational damage. While machine learning has been effective in real-time\ndetection of phishing attacks, progress is hindered by lack of large,\nhigh-quality datasets and benchmarks. In addition to poor-quality due to\nchallenges in data collection, existing datasets suffer from leakage and\nunrealistic base rates, leading to overly optimistic performance results. In\nthis paper, we introduce PhreshPhish, a large-scale, high-quality dataset of\nphishing websites that addresses these limitations. Compared to existing public\ndatasets, PhreshPhish is substantially larger and provides significantly higher\nquality, as measured by the estimated rate of invalid or mislabeled data\npoints. Additionally, we propose a comprehensive suite of benchmark datasets\nspecifically designed for realistic model evaluation by minimizing leakage,\nincreasing task difficulty, enhancing dataset diversity, and adjustment of base\nrates more likely to be seen in the real world. We train and evaluate multiple\nsolution approaches to provide baseline performance on the benchmark sets. We\nbelieve the availability of this dataset and benchmarks will enable realistic,\nstandardized model comparison and foster further advances in phishing\ndetection. The datasets and benchmarks are available on Hugging Face\n(https://huggingface.co/datasets/phreshphish/phreshphish).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10854v1", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10873", "title": "From Alerts to Intelligence: A Novel LLM-Aided Framework for Host-based Intrusion Detection", "authors": ["Danyu Sun", "Jinghuai Zhang", "Jiacen Xu", "Yu Zheng", "Yuan Tian", "Zhou Li"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10873v1", "summary": "Host-based intrusion detection system (HIDS) is a key defense component to\nprotect the organizations from advanced threats like Advanced Persistent\nThreats (APT). By analyzing the fine-grained logs with approaches like data\nprovenance, HIDS has shown successes in capturing sophisticated attack traces.\nDespite the progresses embarked by the research community and industry, HIDS\nstill frequently encounters backlash from their operators in the deployed\nenvironments, due to issues like high false-positive rate, inconsistent\noutcomes across environments and human-unfriendly detection results. Large\nLanguage Models (LLMs) have great potentials to advance the state of HIDS,\ngiven their extensive knowledge of attack techniques and their ability to\ndetect anomalies through semantic analysis, anchored by recent studies. Yet,\nour preliminary analysis indicates that building an HIDS by naively prompting\nan LLM is unlikely to succeed. In this work, we explore the direction of\nbuilding a customized LLM pipeline for HIDS and develop a system named SHIELD.\nSHIELD addresses challenges related to LLM's token limits, confusion of\nbackground noises, etc., by integrating a variety of techniques like\nevent-level Masked Autoencoder (MAE) for attack window detection, attack\nevidence identification and expansion, Deterministic Data Augmentation (DDA)\nfor profiling normal activities, and multi-purpose prompting that guides the\nLLM to conduct precise and interpretable attack investigations. Extensive\nexperiments on three log datasets (DARPA-E3, NodLink-simulated-data and\nATLASv2) show that SHIELD consistently achieves outstanding performance in\ncomparison with 5 representative HIDS. These findings highlight the potential\nof LLMs as powerful tools for intrusion detection and pave the way for future\nresearch in this domain.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10873v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10913", "title": "A Learning Framework For Cooperative Collision Avoidance of UAV Swarms Leveraging Domain Knowledge", "authors": ["Shuangyao Huang", "Haibo Zhang", "Zhiyi Huang"], "categories": ["cs.MA", "cs.LG", "cs.RO"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      Under review at AAAI 2026", "url": "http://arxiv.org/abs/2507.10913v1", "summary": "This paper presents a multi-agent reinforcement learning (MARL) framework for\ncooperative collision avoidance of UAV swarms leveraging domain\nknowledge-driven reward. The reward is derived from knowledge in the domain of\nimage processing, approximating contours on a two-dimensional field. By\nmodeling obstacles as maxima on the field, collisions are inherently avoided as\ncontours never go through peaks or intersect. Additionally, counters are smooth\nand energy-efficient. Our framework enables training with large swarm sizes as\nthe agent interaction is minimized and the need for complex credit assignment\nschemes or observation sharing mechanisms in state-of-the-art MARL approaches\nare eliminated. Moreover, UAVs obtain the ability to adapt to complex\nenvironments where contours may be non-viable or non-existent through intensive\ntraining. Extensive experiments are conducted to evaluate the performances of\nour framework against state-of-the-art MARL algorithms.", "comment": "Under review at AAAI 2026", "pdf_url": "http://arxiv.org/pdf/2507.10913v1", "cate": "cs.MA", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10898", "title": "MalCodeAI: Autonomous Vulnerability Detection and Remediation via Language Agnostic Code Reasoning", "authors": ["Jugal Gajjar", "Kamalasankari Subramaniakuppusamy", "Noha El Kachach"], "categories": ["cs.CR", "cs.AI", "cs.SE"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      6 pages, 4 figures, accepted for publication in IEEE 26th International Conference on Information Reuse and Integration (IRI 2025)", "url": "http://arxiv.org/abs/2507.10898v1", "summary": "The growing complexity of cyber threats and the limitations of traditional\nvulnerability detection tools necessitate novel approaches for securing\nsoftware systems. We introduce MalCodeAI, a language-agnostic, multi-stage AI\npipeline for autonomous code security analysis and remediation. MalCodeAI\ncombines code decomposition and semantic reasoning using fine-tuned\nQwen2.5-Coder-3B-Instruct models, optimized through Low-Rank Adaptation (LoRA)\nwithin the MLX framework, and delivers scalable, accurate results across 14\nprogramming languages. In Phase 1, the model achieved a validation loss as low\nas 0.397 for functional decomposition and summarization of code segments after\n200 iterations, 6 trainable layers, and a learning rate of 2 x 10^(-5). In\nPhase 2, for vulnerability detection and remediation, it achieved a best\nvalidation loss of 0.199 using the same number of iterations and trainable\nlayers but with an increased learning rate of 4 x 10^(-5), effectively\nidentifying security flaws and suggesting actionable fixes. MalCodeAI supports\nred-hat-style exploit tracing, CVSS-based risk scoring, and zero-shot\ngeneralization to detect complex, zero-day vulnerabilities. In a qualitative\nevaluation involving 15 developers, the system received high scores in\nusefulness (mean 8.06/10), interpretability (mean 7.40/10), and readability of\noutputs (mean 7.53/10), confirming its practical value in real-world\ndevelopment workflows. This work marks a significant advancement toward\nintelligent, explainable, and developer-centric software security solutions.", "comment": "6 pages, 4 figures, accepted for publication in IEEE 26th\n  International Conference on Information Reuse and Integration (IRI 2025)", "pdf_url": "http://arxiv.org/pdf/2507.10898v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10566", "title": "AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems", "authors": ["Hung Ming Liu"], "categories": ["cs.AI", "cs.GT", "cs.LG", "cs.MA", "cs.NE", "68T07, 68T40, 91A20", "I.2.6; I.2.11; I.2.4"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      30 pages, 4 figures", "url": "http://arxiv.org/abs/2507.10566v1", "summary": "In Decentralized Multi-Agent Reinforcement Learning (MARL), the development\nof Emergent Communication has long been constrained by the ``Joint Exploration\nDilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' .\nTraditional methods address this by introducing inductive biases to facilitate\ncommunication emergence . This study fundamentally questions whether such\nartificial inductive biases are, in fact, over-engineering. Through experiments\nwith the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized\nVariational Autoencoder (VQ-VAE), we demonstrate that when agents possess an\nendogenous symbol system, their neural representations naturally exhibit\nspontaneous semantic compression and Nash equilibrium-driven semantic\nconvergence, achieving effective symbolic communication without external\ninductive biases. This aligns with recent neuroscience findings suggesting that\nthe human brain does not directly use human language for internal thought , and\nresonates with research on ``soft thinking'' capabilities in Large Language\nModels (LLMs) . Compared to traditional explicit communication methods, AIM\ndemonstrates stronger generality and efficiency. The interpretable analysis\ntoolkit developed in this study confirms that symbol usage exhibits a\nsignificant power-law distribution, leading to three major theoretical\ninsights: the ``Neural Communication Hypothesis'', the ``Tool-First\nPrinciple'', and the ``Semantic Interpretability Paradigm''. Future research\nwill explore the integration of Hierarchical Quantized Variational Autoencoders\n(HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the\npotential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This\ndiscovery offers new avenues for bridging symbolism and connectionism.", "comment": "30 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.10566v1", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.10927", "title": "DVFS: A Dynamic Verifiable Fuzzy Search Service for Encrypted Cloud Data", "authors": ["Jie Zhang", "Xiaohong Li", "Man Zheng", "Zhe Hou", "Guangdong Bai", "Ruitao Feng"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10927v1", "summary": "Cloud storage introduces critical privacy challenges for encrypted data\nretrieval, where fuzzy multi-keyword search enables approximate matching while\npreserving data confidentiality. Existing solutions face fundamental trade-offs\nbetween security and efficiency: linear-search mechanisms provide adaptive\nsecurity but incur prohibitive overhead for large-scale data, while tree-based\nindexes improve performance at the cost of branch leakage vulnerabilities.\n  To address these limitations, we propose DVFS - a dynamic verifiable fuzzy\nsearch service with three core innovations: (1) An \\textit{adaptive-secure\nfuzzy search} method integrating locality-sensitive hashing with virtual binary\ntrees, eliminating branch leakage while reducing search complexity from linear\nto sublinear ($O(\\log n)$ time); (2) A \\textit{dual-repository version control}\nmechanism supporting dynamic updates with forward privacy, preventing\ninformation leakage during operations; (3) A \\textit{blockchain-based\nverification system} that ensures correctness and completeness via smart\ncontracts, achieving $O(\\log n)$ verification complexity.\n  Our solution advances secure encrypted retrieval by simultaneously resolving\nthe security-performance paradox and enabling trustworthy dynamic operations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10927v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10644", "title": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents", "authors": ["Tatiana Petrova", "Aleksandr Puzikov", "Boris Bliznukov", "Radu State"], "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.HC", "cs.MA", "I.2.11; I.2.7; C.2.4; K.6.5; I.2.4"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      33 pages, 9 figures, 8 tables", "url": "http://arxiv.org/abs/2507.10644v1", "summary": "The concept of the Web of Agents (WoA), which transforms the static,\ndocument-centric Web into an environment of autonomous agents acting on users'\nbehalf, has attracted growing interest as large language models (LLMs) become\nmore capable. However, research in this area is still fragmented across\ndifferent communities. Contemporary surveys catalog the latest LLM-powered\nframeworks, while the rich histories of Multi-Agent Systems (MAS) and the\nSemantic Web are often treated as separate, legacy domains. This fragmentation\nobscures the intellectual lineage of modern systems and hinders a holistic\nunderstanding of the field's trajectory. We present the first comprehensive\nevolutionary overview of the WoA. We show that modern protocols like A2A and\nthe MCP, are direct evolutionary responses to the well-documented limitations\nof earlier standards like FIPA standards and OWL-based semantic agents. To\nsystematize this analysis, we introduce a four-axis taxonomy (semantic\nfoundation, communication paradigm, locus of intelligence, discovery\nmechanism). This framework provides a unified analytical lens for comparing\nagent architectures across all generations, revealing a clear line of descent\nwhere others have seen a disconnect. Our analysis identifies a paradigm shift\nin the 'locus of intelligence': from being encoded in external data (Semantic\nWeb) or the platform (MAS) to being embedded within the agent's core model\n(LLM). This shift is foundational to modern Agentic AI, enabling the scalable\nand adaptive systems the WoA has long envisioned. We conclude that while new\nprotocols are essential, they are insufficient for building a robust, open,\ntrustworthy ecosystem. Finally, we argue that the next research frontier lies\nin solving persistent socio-technical challenges, and we map out a new agenda\nfocused on decentralized identity, economic models, security, and governance\nfor the emerging WoA.", "comment": "33 pages, 9 figures, 8 tables", "pdf_url": "http://arxiv.org/pdf/2507.10644v1", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11137", "title": "Hashed Watermark as a Filter: Defeating Forging and Overwriting Attacks in Weight-based Neural Network Watermarking", "authors": ["Yuan Yao", "Jin Song", "Jian Jin"], "categories": ["cs.CR", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11137v1", "summary": "As valuable digital assets, deep neural networks necessitate robust ownership\nprotection, positioning neural network watermarking (NNW) as a promising\nsolution. Among various NNW approaches, weight-based methods are favored for\ntheir simplicity and practicality; however, they remain vulnerable to forging\nand overwriting attacks. To address those challenges, we propose NeuralMark, a\nrobust method built around a hashed watermark filter. Specifically, we utilize\na hash function to generate an irreversible binary watermark from a secret key,\nwhich is then used as a filter to select the model parameters for embedding.\nThis design cleverly intertwines the embedding parameters with the hashed\nwatermark, providing a robust defense against both forging and overwriting\nattacks. An average pooling is also incorporated to resist fine-tuning and\npruning attacks. Furthermore, it can be seamlessly integrated into various\nneural network architectures, ensuring broad applicability. Theoretically, we\nanalyze its security boundary. Empirically, we verify its effectiveness and\nrobustness across 13 distinct Convolutional and Transformer architectures,\ncovering five image classification tasks and one text generation task. The\nsource codes are available at https://github.com/AIResearch-Group/NeuralMark.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11137v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11277", "title": "Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems", "authors": ["Dany Moshkovich", "Sergey Zeltyn"], "categories": ["cs.AI", "cs.MA"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11277v1", "summary": "Large Language Models (LLMs) are increasingly deployed within agentic\nsystems-collections of interacting, LLM-powered agents that execute complex,\nadaptive workflows using memory, tools, and dynamic planning. While enabling\npowerful new capabilities, these systems also introduce unique forms of\nuncertainty stemming from probabilistic reasoning, evolving memory states, and\nfluid execution paths. Traditional software observability and operations\npractices fall short in addressing these challenges.\n  This paper introduces AgentOps: a comprehensive framework for observing,\nanalyzing, optimizing, and automating operation of agentic AI systems. We\nidentify distinct needs across four key roles-developers, testers, site\nreliability engineers (SREs), and business users-each of whom engages with the\nsystem at different points in its lifecycle. We present the AgentOps Automation\nPipeline, a six-stage process encompassing behavior observation, metric\ncollection, issue detection, root cause analysis, optimized recommendations,\nand runtime automation. Throughout, we emphasize the critical role of\nautomation in managing uncertainty and enabling self-improving AI systems-not\nby eliminating uncertainty, but by taming it to ensure safe, adaptive, and\neffective operation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11277v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11138", "title": "FacialMotionID: Identifying Users of Mixed Reality Headsets using Abstract Facial Motion Representations", "authors": ["Adriano Castro", "Simon Hanisch", "Matin Fallahi", "Thorsten Strufe"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11138v1", "summary": "Facial motion capture in mixed reality headsets enables real-time avatar\nanimation, allowing users to convey non-verbal cues during virtual\ninteractions. However, as facial motion data constitutes a behavioral\nbiometric, its use raises novel privacy concerns. With mixed reality systems\nbecoming more immersive and widespread, understanding whether face motion data\ncan lead to user identification or inference of sensitive attributes is\nincreasingly important.\n  To address this, we conducted a study with 116 participants using three types\nof headsets across three sessions, collecting facial, eye, and head motion data\nduring verbal and non-verbal tasks. The data used is not raw video, but rather,\nabstract representations that are used to animate digital avatars. Our analysis\nshows that individuals can be re-identified from this data with up to 98%\nbalanced accuracy, are even identifiable across device types, and that\nemotional states can be inferred with up to 86% accuracy. These results\nunderscore the potential privacy risks inherent in face motion tracking in\nmixed reality environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11138v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11371", "title": "Step-wise Policy for Rare-tool Knowledge (SPaRK): Offline RL that Drives Diverse Tool Use in LLMs", "authors": ["Gabriel Bo", "Koa Chang", "Justin Gu"], "categories": ["cs.LG", "cs.MA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures", "url": "http://arxiv.org/abs/2507.11371v1", "summary": "We present Step-wise Policy for Rare-tool Knowledge (SPaRK), a novel\nreinforcement learning framework that teaches large language models to explore\ndiverse tool usage patterns beyond conventional high-temperature sampling.\nBuilding on recent advances in step-wise reinforcement learning, we introduce a\ndual-objective reward system that simultaneously optimizes for answer quality\nand tool diversity, training a Llama-3.1 8B model through offline PPO on\nsynthetically generated trajectories from the MMLU-Pro dataset. Our approach\nuniquely employs a rarity-first exploitation strategy where a GPT-4o judge\nscores candidate actions across eight distinct tools plus chain-of-thought\nreasoning, with the policy favoring less-frequently used but still viable tools\nto encourage systematic exploration. Empirical results demonstrate that SPaRK\nachieves competitive performance across 14 MMLU-Pro categories while exhibiting\nsignificantly higher entropy in tool selection compared to both baseline and\nsupervised fine-tuning approaches, suggesting that algorithmic exploration\nthrough explicit tool diversity can enhance reasoning capabilities without\nsacrificing accuracy.", "comment": "12 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.11371v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10602", "title": "Learning to Move in Rhythm: Task-Conditioned Motion Policies with Orbital Stability Guarantees", "authors": ["Maximilian Stölzle", "T. Konstantin Rusch", "Zach J. Patterson", "Rodrigo Pérez-Dattari", "Francesco Stella", "Josie Hughes", "Cosimo Della Santina", "Daniela Rus"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      73 pages", "url": "http://arxiv.org/abs/2507.10602v1", "summary": "Learning from demonstration provides a sample-efficient approach to acquiring\ncomplex behaviors, enabling robots to move robustly, compliantly, and with\nfluidity. In this context, Dynamic Motion Primitives offer built - in stability\nand robustness to disturbances but often struggle to capture complex periodic\nbehaviors. Moreover, they are limited in their ability to interpolate between\ndifferent tasks. These shortcomings substantially narrow their applicability,\nexcluding a wide class of practically meaningful tasks such as locomotion and\nrhythmic tool use. In this work, we introduce Orbitally Stable Motion\nPrimitives (OSMPs) - a framework that combines a learned diffeomorphic encoder\nwith a supercritical Hopf bifurcation in latent space, enabling the accurate\nacquisition of periodic motions from demonstrations while ensuring formal\nguarantees of orbital stability and transverse contraction. Furthermore, by\nconditioning the bijective encoder on the task, we enable a single learned\npolicy to represent multiple motion objectives, yielding consistent zero-shot\ngeneralization to unseen motion objectives within the training distribution. We\nvalidate the proposed approach through extensive simulation and real-world\nexperiments across a diverse range of robotic platforms - from collaborative\narms and soft manipulators to a bio-inspired rigid-soft turtle robot -\ndemonstrating its versatility and effectiveness in consistently outperforming\nstate-of-the-art baselines such as diffusion policies, among others.", "comment": "73 pages", "pdf_url": "http://arxiv.org/pdf/2507.10602v1", "cate": "cs.RO", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2507.11155", "title": "Bridging the Gap in Vision Language Models in Identifying Unsafe Concepts Across Modalities", "authors": ["Yiting Qu", "Michael Backes", "Yang Zhang"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      To Appear in the 34th USENIX Security Symposium, August 2025", "url": "http://arxiv.org/abs/2507.11155v1", "summary": "Vision-language models (VLMs) are increasingly applied to identify unsafe or\ninappropriate images due to their internal ethical standards and powerful\nreasoning abilities. However, it is still unclear whether they can recognize\nvarious unsafe concepts when presented in different modalities, such as text\nand images. To address this, we first compile the UnsafeConcepts dataset,\nfeaturing 75 unsafe concepts, i.e., ``Swastika,'' ``Sexual Harassment,'' and\n``Assaults,'' along with associated 1.5K images. We then conduct a systematic\nevaluation of VLMs' perception (concept recognition) and alignment (ethical\nreasoning) capabilities. We assess eight popular VLMs and find that, although\nmost VLMs accurately perceive unsafe concepts, they sometimes mistakenly\nclassify these concepts as safe. We also identify a consistent modality gap\namong open-source VLMs in distinguishing between visual and textual unsafe\nconcepts. To bridge this gap, we introduce a simplified reinforcement learning\n(RL)-based approach using proximal policy optimization (PPO) to strengthen the\nability to identify unsafe concepts from images. Our approach uses reward\nscores based directly on VLM responses, bypassing the need for collecting\nhuman-annotated preference data to train a new reward model. Experimental\nresults show that our approach effectively enhances VLM alignment on images\nwhile preserving general capabilities. It outperforms baselines such as\nsupervised fine-tuning (SFT) and direct preference optimization (DPO). We hope\nour dataset, evaluation findings, and proposed alignment solution contribute to\nthe community's efforts in advancing safe VLMs.", "comment": "To Appear in the 34th USENIX Security Symposium, August 2025", "pdf_url": "http://arxiv.org/pdf/2507.11155v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11387", "title": "From Kinetic Theory to AI: a Rediscovery of High-Dimensional Divergences and Their Properties", "authors": ["Gennaro Auricchio", "Giovanni Brigati", "Paolo Giudici", "Giuseppe Toscani"], "categories": ["math-ph", "cs.AI", "cs.LG", "cs.MA", "math.MP", "35B40, 35L60, 35K55, 35Q70, 35Q91, 35Q92"], "primary_category": "Subjects:       Mathematical Physics (math-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11387v1", "summary": "Selecting an appropriate divergence measure is a critical aspect of machine\nlearning, as it directly impacts model performance. Among the most widely used,\nwe find the Kullback-Leibler (KL) divergence, originally introduced in kinetic\ntheory as a measure of relative entropy between probability distributions. Just\nas in machine learning, the ability to quantify the proximity of probability\ndistributions plays a central role in kinetic theory. In this paper, we present\na comparative review of divergence measures rooted in kinetic theory,\nhighlighting their theoretical foundations and exploring their potential\napplications in machine learning and artificial intelligence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11387v1", "cate": "math-ph", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10672", "title": "Vision Language Action Models in Robotic Manipulation: A Systematic Review", "authors": ["Muhayy Ud Din", "Waseem Akram", "Lyes Saad Saoud", "Jan Rosell", "Irfan Hussain"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      submitted to annual review in control", "url": "http://arxiv.org/abs/2507.10672v1", "summary": "Vision Language Action (VLA) models represent a transformative shift in\nrobotics, with the aim of unifying visual perception, natural language\nunderstanding, and embodied control within a single learning framework. This\nreview presents a comprehensive and forward-looking synthesis of the VLA\nparadigm, with a particular emphasis on robotic manipulation and\ninstruction-driven autonomy. We comprehensively analyze 102 VLA models, 26\nfoundational datasets, and 12 simulation platforms that collectively shape the\ndevelopment and evaluation of VLAs models. These models are categorized into\nkey architectural paradigms, each reflecting distinct strategies for\nintegrating vision, language, and control in robotic systems. Foundational\ndatasets are evaluated using a novel criterion based on task complexity,\nvariety of modalities, and dataset scale, allowing a comparative analysis of\ntheir suitability for generalist policy learning. We introduce a\ntwo-dimensional characterization framework that organizes these datasets based\non semantic richness and multimodal alignment, showing underexplored regions in\nthe current data landscape. Simulation environments are evaluated for their\neffectiveness in generating large-scale data, as well as their ability to\nfacilitate transfer from simulation to real-world settings and the variety of\nsupported tasks. Using both academic and industrial contributions, we recognize\nongoing challenges and outline strategic directions such as scalable\npretraining protocols, modular architectural design, and robust multimodal\nalignment strategies. This review serves as both a technical reference and a\nconceptual roadmap for advancing embodiment and robotic control, providing\ninsights that span from dataset generation to real world deployment of\ngeneralist robotic agents.", "comment": "submitted to annual review in control", "pdf_url": "http://arxiv.org/pdf/2507.10672v1", "cate": "cs.RO", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11310", "title": "LRCTI: A Large Language Model-Based Framework for Multi-Step Evidence Retrieval and Reasoning in Cyber Threat Intelligence Credibility Verification", "authors": ["Fengxiao Tang", "Huan Li", "Ming Zhao", "Zongzong Wu", "Shisong Peng", "Tao Yin"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11310v1", "summary": "Verifying the credibility of Cyber Threat Intelligence (CTI) is essential for\nreliable cybersecurity defense. However, traditional approaches typically treat\nthis task as a static classification problem, relying on handcrafted features\nor isolated deep learning models. These methods often lack the robustness\nneeded to handle incomplete, heterogeneous, or noisy intelligence, and they\nprovide limited transparency in decision-making-factors that reduce their\neffectiveness in real-world threat environments. To address these limitations,\nwe propose LRCTI, a Large Language Model (LLM)-based framework designed for\nmulti-step CTI credibility verification. The framework first employs a text\nsummarization module to distill complex intelligence reports into concise and\nactionable threat claims. It then uses an adaptive multi-step evidence\nretrieval mechanism that iteratively identifies and refines supporting\ninformation from a CTI-specific corpus, guided by LLM feedback. Finally, a\nprompt-based Natural Language Inference (NLI) module is applied to evaluate the\ncredibility of each claim while generating interpretable justifications for the\nclassification outcome. Experiments conducted on two benchmark datasets,\nCTI-200 and PolitiFact show that LRCTI improves F1-Macro and F1-Micro scores by\nover 5%, reaching 90.9% and 93.6%, respectively, compared to state-of-the-art\nbaselines. These results demonstrate that LRCTI effectively addresses the core\nlimitations of prior methods, offering a scalable, accurate, and explainable\nsolution for automated CTI credibility verification", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11310v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11464", "title": "LF: Online Multi-Robot Path Planning Meets Optimal Trajectory Control", "authors": ["Ajay Shankar", "Keisuke Okumura", "Amanda Prorok"], "categories": ["cs.RO", "cs.MA"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      9 pages; under review for IEEE Robotics & Automation - Letters (RA-L)", "url": "http://arxiv.org/abs/2507.11464v1", "summary": "We propose a multi-robot control paradigm to solve point-to-point navigation\ntasks for a team of holonomic robots with access to the full environment\ninformation. The framework invokes two processes asynchronously at high\nfrequency: (i) a centralized, discrete, and full-horizon planner for computing\ncollision- and deadlock-free paths rapidly, leveraging recent advances in\nmulti-agent pathfinding (MAPF), and (ii) dynamics-aware, robot-wise optimal\ntrajectory controllers that ensure all robots independently follow their\nassigned paths reliably. This hierarchical shift in planning representation\nfrom (i) discrete and coupled to (ii) continuous and decoupled domains enables\nthe framework to maintain long-term scalable motion synthesis. As an\ninstantiation of this idea, we present LF, which combines a fast\nstate-of-the-art MAPF solver (LaCAM), and a robust feedback control stack\n(Freyja) for executing agile robot maneuvers. LF provides a robust and\nversatile mechanism for lifelong multi-robot navigation even under asynchronous\nand partial goal updates, and adapts to dynamic workspaces simply by quick\nreplanning. We present various multirotor and ground robot demonstrations,\nincluding the deployment of 15 real multirotors with random, consecutive target\nupdates while a person walks through the operational workspace.", "comment": "9 pages; under review for IEEE Robotics & Automation - Letters (RA-L)", "pdf_url": "http://arxiv.org/pdf/2507.11464v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10694", "title": "Exteroception through Proprioception Sensing through Improved Contact Modeling for Soft Growing Robots", "authors": ["Francesco Fuentes", "Serigne Diagne", "Zachary Kingston", "Laura H. Blumenschein"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      22 pages, 21 figures, submitted to journal for potential publication", "url": "http://arxiv.org/abs/2507.10694v1", "summary": "Passive deformation due to compliance is a commonly used benefit of soft\nrobots, providing opportunities to achieve robust actuation with few active\ndegrees of freedom. Soft growing robots in particular have shown promise in\nnavigation of unstructured environments due to their passive deformation. If\ntheir collisions and subsequent deformations can be better understood, soft\nrobots could be used to understand the structure of the environment from direct\ntactile measurements. In this work, we propose the use of soft growing robots\nas mapping and exploration tools. We do this by first characterizing collision\nbehavior during discrete turns, then leveraging this model to develop a\ngeometry-based simulator that models robot trajectories in 2D environments.\nFinally, we demonstrate the model and simulator validity by mapping unknown\nenvironments using Monte Carlo sampling to estimate the optimal next deployment\ngiven current knowledge. Over both uniform and non-uniform environments, this\nselection method rapidly approaches ideal actions, showing the potential for\nsoft growing robots in unstructured environment exploration and mapping.", "comment": "22 pages, 21 figures, submitted to journal for potential publication", "pdf_url": "http://arxiv.org/pdf/2507.10694v1", "cate": "cs.RO", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11324", "title": "A Review of Privacy Metrics for Privacy-Preserving Synthetic Data Generation", "authors": ["Frederik Marinus Trudslev", "Matteo Lissandrini", "Juan Manuel Rodriguez", "Martin Bøgsted", "Daniele Dell'Aglio"], "categories": ["cs.CR", "cs.DB"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11324v1", "summary": "Privacy Preserving Synthetic Data Generation (PP-SDG) has emerged to produce\nsynthetic datasets from personal data while maintaining privacy and utility.\nDifferential privacy (DP) is the property of a PP-SDG mechanism that\nestablishes how protected individuals are when sharing their sensitive data. It\nis however difficult to interpret the privacy loss ($\\varepsilon$) expressed by\nDP. To make the actual risk associated with the privacy loss more transparent,\nmultiple privacy metrics (PMs) have been proposed to assess the privacy risk of\nthe data. These PMs are utilized in separate studies to assess newly introduced\nPP-SDG mechanisms. Consequently, these PMs embody the same assumptions as the\nPP-SDG mechanism they were made to assess. Therefore, a thorough definition of\nhow these are calculated is necessary. In this work, we present the assumptions\nand mathematical formulations of 17 distinct privacy metrics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11324v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2411.02820", "title": "DroidSpeak: KV Cache Sharing for Cross-LLM Communication and Multi-LLM Serving", "authors": ["Yuhan Liu", "Yuyang Huang", "Jiayi Yao", "Shaoting Feng", "Zhuohan Gu", "Kuntai Du", "Hanchen Li", "Yihua Cheng", "Junchen Jiang", "Shan Lu", "Madan Musuvathi", "Esha Choukse"], "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.02820v4", "summary": "Compound AI systems, such as agentic systems, are an emerging trend in\nlarge-scale enterprise settings, with multiple LLMs specialized for different\nusers, tasks, and/or roles working together. In these scenarios, different\nmodels often process inputs that share the same context prefix. Although much\nwork was done in the past to enable the reuse of prefix KV caches across inputs\nfor a single model, how to enable one model to reuse the prefix KV caches of a\ndifferent model remains an open question.\n  We introduce DroidSpeak, the first distributed LLM inference system that\nenables KV cache reuse across distributed nodes running inference of different\nLLMs, so long as the LLMs have the same architecture. We present the first\nstudy that aims at understanding the impact of sharing KV caches across\ndifferent LLMs, and if/when such sharing affects quality. Inspired by the\nfindings, we present DroidSpeak, which selectively recomputes a few layers of\nthe KV cache produced by another LLM and reuses the remaining layers, with\nnegligible quality loss. Moreover, carefully pipelining the layer-wise\nre-computation and the loading of reused KV cache further improves the\ninference performance. Experiments on diverse datasets and model pairs\ndemonstrate that DroidSpeak achieves up to 4x throughput improvement and about\n3.1x faster prefill (time to first token), with negligible loss of quality in\nF1 scores, Rouge-L or code similarity score, compared to the baseline which\ndoes not allow any sharing across models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.02820v4", "cate": "cs.MA", "date": "2024-11-05", "updated": "2025-07-14"}
{"id": "2507.10749", "title": "RCG: Safety-Critical Scenario Generation for Robust Autonomous Driving via Real-World Crash Grounding", "authors": ["Benjamin Stoler", "Juliet Yang", "Jonathan Francis", "Jean Oh"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10749v1", "summary": "Safety-critical scenarios are essential for training and evaluating\nautonomous driving (AD) systems, yet remain extremely rare in real-world\ndriving datasets. To address this, we propose Real-world Crash Grounding (RCG),\na scenario generation framework that integrates crash-informed semantics into\nadversarial perturbation pipelines. We construct a safety-aware behavior\nrepresentation through contrastive pre-training on large-scale driving logs,\nfollowed by fine-tuning on a small, crash-rich dataset with approximate\ntrajectory annotations extracted from video. This embedding captures semantic\nstructure aligned with real-world accident behaviors and supports selection of\nadversary trajectories that are both high-risk and behaviorally realistic. We\nincorporate the resulting selection mechanism into two prior scenario\ngeneration pipelines, replacing their handcrafted scoring objectives with an\nembedding-based criterion. Experimental results show that ego agents trained\nagainst these generated scenarios achieve consistently higher downstream\nsuccess rates, with an average improvement of 9.2% across seven evaluation\nsettings. Qualitative and quantitative analyses further demonstrate that our\napproach produces more plausible and nuanced adversary behaviors, enabling more\neffective and realistic stress testing of AD systems. Code and tools will be\nreleased publicly.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10749v1", "cate": "cs.RO", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10562", "title": "SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents", "authors": ["Hari Masoor"], "categories": ["cs.AI", "cs.CR", "cs.DB", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      7 pages, 4 figures, 3 implementation examples. Original work submitted as a preprint", "url": "http://arxiv.org/abs/2507.10562v1", "summary": "Current AI agent architectures suffer from ephemeral memory limitations,\npreventing effective collaboration and knowledge sharing across sessions and\nagent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a\nnovel framework that enables persistent, secure, and semantically searchable\nmemory sharing among AI agents. Our protocol addresses three critical\nchallenges: (1) persistent context preservation across agent sessions, (2)\nsecure multi-agent collaboration with fine-grained access control, and (3)\nefficient semantic discovery of relevant historical context. SAMEP implements a\ndistributed memory repository with vector-based semantic search, cryptographic\naccess controls (AES-256-GCM), and standardized APIs compatible with existing\nagent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness\nacross diverse domains including multi-agent software development, healthcare\nAI with HIPAA compliance, and multi-modal processing pipelines. Experimental\nresults show 73% reduction in redundant computations, 89% improvement in\ncontext relevance scores, and complete compliance with regulatory requirements\nincluding audit trail generation. SAMEP enables a new paradigm of persistent,\ncollaborative AI agent ecosystems while maintaining security and privacy\nguarantees.", "comment": "7 pages, 4 figures, 3 implementation examples. Original work\n  submitted as a preprint", "pdf_url": "http://arxiv.org/pdf/2507.10562v1", "cate": "cs.AI", "date": "2025-07-05", "updated": "2025-07-05"}
{"id": "2507.11499", "title": "Demo: Secure Edge Server for Network Slicing and Resource Allocation in Open RAN", "authors": ["Adhwaa Alchaab", "Ayman Younis", "Dario Pompili"], "categories": ["cs.CR", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11499v1", "summary": "Next-Generation Radio Access Networks (NGRAN) aim to support diverse vertical\napplications with strict security, latency, and Service-Level Agreement (SLA)\nrequirements. These demands introduce challenges in securing the\ninfrastructure, allocating resources dynamically, and enabling real-time\nreconfiguration. This demo presents SnSRIC, a secure and intelligent network\nslicing framework that mitigates a range of Distributed Denial-of-Service\n(DDoS) attacks in Open RAN environments. SnSRIC incorporates an AI-driven xApp\nthat dynamically allocates Physical Resource Blocks (PRBs) to active users\nwhile enforcing slice-level security. The system detects anomalous behavior,\ndistinguishes between benign and malicious devices, and uses the E2 interface\nto throttle rogue signaling while maintaining service continuity for legitimate\nusers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11499v1", "cate": "cs.CR", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2502.19130", "title": "Voting or Consensus? Decision-Making in Multi-Agent Debate", "authors": ["Lars Benedikt Kaesberg", "Jonas Becker", "Jan Philip Wahle", "Terry Ruas", "Bela Gipp"], "categories": ["cs.MA", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      Accepted at ACL2025 (Findings)", "url": "http://arxiv.org/abs/2502.19130v3", "summary": "Much of the success of multi-agent debates depends on carefully choosing the\nright parameters. The decision-making protocol stands out as it can highly\nimpact final model answers, depending on how decisions are reached. Systematic\ncomparison of decision protocols is difficult because many studies alter\nmultiple discussion parameters beyond the protocol. So far, it has been largely\nunknown how decision-making influences different tasks. This work\nsystematically evaluates the impact of seven decision protocols (e.g., majority\nvoting, unanimity consensus). We change only one variable at a time - the\ndecision protocol - to analyze how different methods affect the collaboration\nbetween agents and measure differences in knowledge and reasoning tasks. Our\nresults show that voting protocols improve performance by 13.2% in reasoning\ntasks and consensus protocols by 2.8% in knowledge tasks compared to other\ndecision protocols. Increasing the number of agents improves performance, while\nmore discussion rounds before voting reduce it. To improve decision-making by\nincreasing answer diversity, we propose two new methods, All-Agents Drafting\n(AAD) and Collective Improvement (CI). Our methods improve task performance by\nup to 3.3% with AAD and up to 7.4% with CI. This work demonstrates the\nimportance of decision-making in multi-agent debates beyond scaling.", "comment": "Accepted at ACL2025 (Findings)", "pdf_url": "http://arxiv.org/pdf/2502.19130v3", "cate": "cs.MA", "date": "2025-02-26", "updated": "2025-07-15"}
{"id": "2507.10776", "title": "rt-RISeg: Real-Time Model-Free Robot Interactive Segmentation for Active Instance-Level Object Understanding", "authors": ["Howard H. Qian", "Yiting Chen", "Gaotian Wang", "Podshara Chanrungmaneekul", "Kaiyu Hang"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, IROS 2025, Interactive Perception, Segmentation, Robotics, Computer Vision", "url": "http://arxiv.org/abs/2507.10776v1", "summary": "Successful execution of dexterous robotic manipulation tasks in new\nenvironments, such as grasping, depends on the ability to proficiently segment\nunseen objects from the background and other objects. Previous works in unseen\nobject instance segmentation (UOIS) train models on large-scale datasets, which\noften leads to overfitting on static visual features. This dependency results\nin poor generalization performance when confronted with out-of-distribution\nscenarios. To address this limitation, we rethink the task of UOIS based on the\nprinciple that vision is inherently interactive and occurs over time. We\npropose a novel real-time interactive perception framework, rt-RISeg, that\ncontinuously segments unseen objects by robot interactions and analysis of a\ndesigned body frame-invariant feature (BFIF). We demonstrate that the relative\nrotational and linear velocities of randomly sampled body frames, resulting\nfrom selected robot interactions, can be used to identify objects without any\nlearned segmentation model. This fully self-contained segmentation pipeline\ngenerates and updates object segmentation masks throughout each robot\ninteraction without the need to wait for an action to finish. We showcase the\neffectiveness of our proposed interactive perception method by achieving an\naverage object segmentation accuracy rate 27.5% greater than state-of-the-art\nUOIS methods. Furthermore, although rt-RISeg is a standalone framework, we show\nthat the autonomously generated segmentation masks can be used as prompts to\nvision foundation models for significantly improved performance.", "comment": "8 pages, IROS 2025, Interactive Perception, Segmentation, Robotics,\n  Computer Vision", "pdf_url": "http://arxiv.org/pdf/2507.10776v1", "cate": "cs.RO", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10571", "title": "Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning", "authors": ["Konstantinos I. Roumeliotis", "Ranjan Sapkota", "Manoj Karkee", "Nikolaos D. Tselikas"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10571v1", "summary": "Modern Artificial Intelligence (AI) increasingly relies on multi-agent\narchitectures that blend visual and language understanding. Yet, a pressing\nchallenge remains: How can we trust these agents especially in zero-shot\nsettings with no fine-tuning? We introduce a novel modular Agentic AI visual\nclassification framework that integrates generalist multimodal agents with a\nnon-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)\nmodule. Applied to apple leaf disease diagnosis, we benchmark three\nconfigurations: (I) zero-shot with confidence-based orchestration, (II)\nfine-tuned agents with improved performance, and (III) trust-calibrated\norchestration enhanced by CLIP-based image retrieval and re-evaluation loops.\nUsing confidence calibration metrics (ECE, OCR, CCC), the orchestrator\nmodulates trust across agents. Our results demonstrate a 77.94\\% accuracy\nimprovement in the zero-shot setting using trust-aware orchestration and RAG,\nachieving 85.63\\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL\ndisplayed overconfidence. Furthermore, image-RAG grounded predictions with\nvisually similar cases, enabling correction of agent overconfidence via\niterative re-evaluation. The proposed system separates perception (vision\nagents) from meta-reasoning (orchestrator), enabling scalable and interpretable\nmulti-agent AI. This blueprint is extensible to diagnostics, biology, and other\ntrust-critical domains. All models, prompts, results, and system components\nincluding the complete software source code are openly released to support\nreproducibility, transparency, and community benchmarking at Github:\nhttps://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10571v1", "cate": "cs.AI", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.11500", "title": "ARMOR: Aligning Secure and Safe Large Language Models via Meticulous Reasoning", "authors": ["Zhengyue Zhao", "Yingzi Ma", "Somesh Jha", "Marco Pavone", "Chaowei Xiao"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11500v1", "summary": "Large Language Models (LLMs) have demonstrated remarkable generative\ncapabilities. However, their susceptibility to misuse has raised significant\nsafety concerns. While post-training safety alignment methods have been widely\nadopted, LLMs remain vulnerable to malicious instructions that can bypass\nsafety constraints. Recent efforts have introduced inference-time safety\nreasoning (system-2 alignment), where LLMs conduct a reasoning process to\nperform safety verification before final response. We show, however, that these\nchecks are driven by ad-hoc reasoning that diverges from the structured human\nprocess, where they first discern a user's true intent, then evaluate the\nassociated risk based on the true intent. Consequently, these defenses remain\nvulnerable to sophisticated jailbreak prompts that cloak harmful goals in\nseemingly benign language. To build secure and safe LLMs, we propose a\nreasoning-based safety alignment framework, ARMOR, that replaces the ad-hoc\nchains of thought reasoning process with human-aligned, structured one. At\ninference, ARMOR (1) detects likely jailbreak strategies, (2) extracts the\nuser's core intent while discarding deceptive instructions, and (3) applies a\npolicy-grounded safety analysis to the purified request. ARMOR is evaluated on\nadaptive jailbreak attacks and multiple safety benchmarks, and a test-time\nscaling is conducted to further improve its performance. Results demonstrate\nthat ARMOR significantly enhances the robustness against state-of-the-art\nadaptive jailbreak attacks and outperforms recent reasoning-based aligned\nmodels across various safety benchmarks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11500v1", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2505.21418", "title": "Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused Ultrasound Ablation Surgery", "authors": ["Lina Zhao", "Jiaxing Bai", "Zihao Bian", "Qingyue Chen", "Yafang Li", "Guangbo Li", "Min He", "Huaiyuan Yao", "Zongjiu Zhang"], "categories": ["cs.MA"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.21418v2", "summary": "Focused Ultrasound Ablation Surgery (FUAS) has emerged as a promising\nnon-invasive therapeutic modality, valued for its safety and precision.\nNevertheless, its clinical implementation entails intricate tasks such as\nmultimodal image interpretation, personalized dose planning, and real-time\nintraoperative decision-making processes that demand intelligent assistance to\nimprove efficiency and reliability. We introduce FUAS-Agents, an autonomous\nagent system that leverages the multimodal understanding and tool-using\ncapabilities of large language models (LLMs). By integrating patient profiles\nand MRI data, FUAS-Agents orchestrates a suite of specialized medical AI tools,\nincluding segmentation, treatment dose prediction, and clinical guideline\nretrieval, to generate personalized treatment plans comprising MRI image, dose\nparameters, and therapeutic strategies. We evaluate the system in a uterine\nfibroid treatment scenario. Human assessment by four senior FUAS experts\nindicates that 82.5%, 82.5%, 87.5%, and 97.5% of the generated plans were rated\n4 or above (on a 5-point scale) in terms of completeness, accuracy, fluency,\nand clinical compliance, respectively. These results demonstrate the potential\nof LLM-driven agents in enhancing decision-making across complex clinical\nworkflows, and exemplify a translational paradigm that combines general-purpose\nmodels with specialized expert systems to solve practical challenges in\nvertical healthcare domains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.21418v2", "cate": "cs.MA", "date": "2025-05-27", "updated": "2025-07-15"}
{"id": "2507.10814", "title": "Versatile and Generalizable Manipulation via Goal-Conditioned Reinforcement Learning with Grounded Object Detection", "authors": ["Huiyi Wang", "Fahim Shahriar", "Alireza Azimi", "Gautham Vasan", "Rupam Mahmood", "Colin Bellinger"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 4 figures, 3 tables", "url": "http://arxiv.org/abs/2507.10814v1", "summary": "General-purpose robotic manipulation, including reach and grasp, is essential\nfor deployment into households and workspaces involving diverse and evolving\ntasks. Recent advances propose using large pre-trained models, such as Large\nLanguage Models and object detectors, to boost robotic perception in\nreinforcement learning. These models, trained on large datasets via\nself-supervised learning, can process text prompts and identify diverse objects\nin scenes, an invaluable skill in RL where learning object interaction is\nresource-intensive. This study demonstrates how to integrate such models into\nGoal-Conditioned Reinforcement Learning to enable general and versatile robotic\nreach and grasp capabilities. We use a pre-trained object detection model to\nenable the agent to identify the object from a text prompt and generate a mask\nfor goal conditioning. Mask-based goal conditioning provides object-agnostic\ncues, improving feature sharing and generalization. The effectiveness of the\nproposed framework is demonstrated in a simulated reach-and-grasp task, where\nthe mask-based goal conditioning consistently maintains a $\\sim$90\\% success\nrate in grasping both in and out-of-distribution objects, while also ensuring\nfaster convergence to higher returns.", "comment": "8 pages, 4 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.10814v1", "cate": "cs.RO", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10624", "title": "Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning", "authors": ["Zheng Zhang"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Substantial change to previous version (experiments, theorem, analysis and related work); currently under review at TMLR", "url": "http://arxiv.org/abs/2507.10624v1", "summary": "Large Language Models (LLMs) display striking surface fluency yet\nsystematically fail at tasks requiring symbolic reasoning, arithmetic accuracy,\nand logical consistency. This paper offers a structural diagnosis of such\nfailures, revealing a persistent gap between \\textit{comprehension} and\n\\textit{competence}. Through controlled experiments and architectural analysis,\nwe demonstrate that LLMs often articulate correct principles without reliably\napplying them--a failure rooted not in knowledge access, but in computational\nexecution. We term this phenomenon the computational \\textit{split-brain\nsyndrome}, where instruction and action pathways are geometrically and\nfunctionally dissociated. This core limitation recurs across domains, from\nmathematical operations to relational inferences, and explains why model\nbehavior remains brittle even under idealized prompting. We argue that LLMs\nfunction as powerful pattern completion engines, but lack the architectural\nscaffolding for principled, compositional reasoning. Our findings delineate the\nboundary of current LLM capabilities and motivate future models with\nmetacognitive control, principle lifting, and structurally grounded execution.\nThis diagnosis also clarifies why mechanistic interpretability findings may\nreflect training-specific pattern coordination rather than universal\ncomputational principles, and why the geometric separation between instruction\nand execution pathways suggests limitations in neural introspection and\nmechanistic analysis.", "comment": "Substantial change to previous version (experiments, theorem,\n  analysis and related work); currently under review at TMLR", "pdf_url": "http://arxiv.org/pdf/2507.10624v1", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10591", "title": "MH-FSF: A Unified Framework for Overcoming Benchmarking and Reproducibility Limitations in Feature Selection Evaluation", "authors": ["Vanderson Rocha", "Diego Kreutz", "Gabriel Canto", "Hendrio Bragança", "Eduardo Feitosa"], "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.PF", "68T01", "I.2"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages; 4 figures; 5 tables; submitted to JBCS", "url": "http://arxiv.org/abs/2507.10591v1", "summary": "Feature selection is vital for building effective predictive models, as it\nreduces dimensionality and emphasizes key features. However, current research\noften suffers from limited benchmarking and reliance on proprietary datasets.\nThis severely hinders reproducibility and can negatively impact overall\nperformance. To address these limitations, we introduce the MH-FSF framework, a\ncomprehensive, modular, and extensible platform designed to facilitate the\nreproduction and implementation of feature selection methods. Developed through\ncollaborative research, MH-FSF provides implementations of 17 methods (11\nclassical, 6 domain-specific) and enables systematic evaluation on 10 publicly\navailable Android malware datasets. Our results reveal performance variations\nacross both balanced and imbalanced datasets, highlighting the critical need\nfor data preprocessing and selection criteria that account for these\nasymmetries. We demonstrate the importance of a unified platform for comparing\ndiverse feature selection techniques, fostering methodological consistency and\nrigor. By providing this framework, we aim to significantly broaden the\nexisting literature and pave the way for new research directions in feature\nselection, particularly within the context of Android malware detection.", "comment": "11 pages; 4 figures; 5 tables; submitted to JBCS", "pdf_url": "http://arxiv.org/pdf/2507.10591v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2506.19502", "title": "MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility Applications", "authors": ["Aleksandr Algazinov", "Matt Laing", "Paul Laban"], "categories": ["cs.MA", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.19502v2", "summary": "Accessibility remains a critical concern in today's society, as many\ntechnologies are not developed to support the full range of user needs.\nExisting multi-agent systems (MAS) often cannot provide comprehensive\nassistance for users in need due to the lack of customization stemming from\nclosed-source designs. Consequently, individuals with disabilities frequently\nencounter significant barriers when attempting to interact with digital\nenvironments. We introduce MATE, a multimodal accessibility MAS, which performs\nthe modality conversions based on the user's needs. The system is useful for\nassisting people with disabilities by ensuring that data will be converted to\nan understandable format. For instance, if the user cannot see well and\nreceives an image, the system converts this image to its audio description.\nMATE can be applied to a wide range of domains, industries, and areas, such as\nhealthcare, and can become a useful assistant for various groups of users. The\nsystem supports multiple types of models, ranging from LLM API calling to using\ncustom machine learning (ML) classifiers. This flexibility ensures that the\nsystem can be adapted to various needs and is compatible with a wide variety of\nhardware. Since the system is expected to run locally, it ensures the privacy\nand security of sensitive information. In addition, the framework can be\neffectively integrated with institutional technologies (e.g., digital\nhealthcare service) for real-time user assistance. Furthermore, we introduce\nModCon-Task-Identifier, a model that is capable of extracting the precise\nmodality conversion task from the user input. Numerous experiments show that\nModCon-Task-Identifier consistently outperforms other LLMs and statistical\nmodels on our custom data. Our code and data are publicly available at\nhttps://github.com/AlgazinovAleksandr/Multi-Agent-MATE.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.19502v2", "cate": "cs.MA", "date": "2025-06-24", "updated": "2025-07-15"}
{"id": "2507.10878", "title": "Mixed Discrete and Continuous Planning using Shortest Walks in Graphs of Convex Sets", "authors": ["Savva Morozov", "Tobia Marcucci", "Bernhard Paus Graesdal", "Alexandre Amice", "Pablo A. Parrilo", "Russ Tedrake"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      10 pages", "url": "http://arxiv.org/abs/2507.10878v1", "summary": "We study the Shortest-Walk Problem (SWP) in a Graph of Convex Sets (GCS). A\nGCS is a graph where each vertex is paired with a convex program, and each edge\ncouples adjacent programs via additional costs and constraints. A walk in a GCS\nis a sequence of vertices connected by edges, where vertices may be repeated.\nThe length of a walk is given by the cumulative optimal value of the\ncorresponding convex programs. To solve the SWP in GCS, we first synthesize a\npiecewise-quadratic lower bound on the problem's cost-to-go function using\nsemidefinite programming. Then we use this lower bound to guide an\nincremental-search algorithm that yields an approximate shortest walk. We show\nthat the SWP in GCS is a natural language for many mixed discrete-continuous\nplanning problems in robotics, unifying problems that typically require\nspecialized solutions while delivering high performance and computational\nefficiency. We demonstrate this through experiments in collision-free motion\nplanning, skill chaining, and optimal control of hybrid systems.", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2507.10878v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10630", "title": "Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs", "authors": ["Ye Yang", "Xue Xiao", "Ping Yin", "Taotao Xie"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10630v1", "summary": "API calls by large language models (LLMs) offer a cutting-edge approach for\ndata analysis. However, their ability to effectively utilize tools via API\ncalls remains underexplored in knowledge-intensive domains like meteorology.\nThis paper introduces KG2data, a system that integrates knowledge graphs, LLMs,\nReAct agents, and tool-use technologies to enable intelligent data acquisition\nand query handling in the meteorological field. Using a virtual API, we\nevaluate API call accuracy across three metrics: name recognition failure,\nhallucination failure, and call correctness. KG2data achieves superior\nperformance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and\nchat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based\nsystems by addressing their limited access to domain-specific knowledge, which\nhampers performance on complex or terminology-rich queries. By using a\nknowledge graph as persistent memory, our system enhances content retrieval,\ncomplex query handling, domain-specific reasoning, semantic relationship\nresolution, and heterogeneous data integration. It also mitigates the high cost\nof fine-tuning LLMs, making the system more adaptable to evolving domain\nknowledge and API structures. In summary, KG2data provides a novel solution for\nintelligent, knowledge-based question answering and data analysis in domains\nwith high knowledge demands.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10630v1", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10773", "title": "Theory of Mind and Self-Disclosure to CUIs", "authors": ["Samuel Rhys Cox"], "categories": ["cs.HC", "cs.CL"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Workshop paper presented at ToMinHAI at CUI'2025: Theory of Mind in Human-CUI Interaction, held in conjunction with the 2025 ACM conference on Conversational User Interfaces, July 8th, 2025. 4 pages. 3 figures", "url": "http://arxiv.org/abs/2507.10773v1", "summary": "Self-disclosure is important to help us feel better, yet is often difficult.\nThis difficulty can arise from how we think people are going to react to our\nself-disclosure. In this workshop paper, we briefly discuss self-disclosure to\nconversational user interfaces (CUIs) in relation to various social cues. We\nthen, discuss how expressions of uncertainty or representation of a CUI's\nreasoning could help encourage self-disclosure, by making a CUI's intended\n\"theory of mind\" more transparent to users.", "comment": "Workshop paper presented at ToMinHAI at CUI'2025: Theory of Mind in\n  Human-CUI Interaction, held in conjunction with the 2025 ACM conference on\n  Conversational User Interfaces, July 8th, 2025. 4 pages. 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.10773v1", "cate": "cs.HC", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10695", "title": "Exploring User Security and Privacy Attitudes and Concerns Toward the Use of General-Purpose LLM Chatbots for Mental Health", "authors": ["Jabari Kwesi", "Jiaxun Cao", "Riya Manchanda", "Pardis Emami-Naeini"], "categories": ["cs.CY", "cs.AI", "cs.CR", "cs.ET", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Accepted to the 34th USENIX Security Symposium", "url": "http://arxiv.org/abs/2507.10695v1", "summary": "Individuals are increasingly relying on large language model (LLM)-enabled\nconversational agents for emotional support. While prior research has examined\nprivacy and security issues in chatbots specifically designed for mental health\npurposes, these chatbots are overwhelmingly \"rule-based\" offerings that do not\nleverage generative AI. Little empirical research currently measures users'\nprivacy and security concerns, attitudes, and expectations when using\ngeneral-purpose LLM-enabled chatbots to manage and improve mental health.\nThrough 21 semi-structured interviews with U.S. participants, we identified\ncritical misconceptions and a general lack of risk awareness. Participants\nconflated the human-like empathy exhibited by LLMs with human-like\naccountability and mistakenly believed that their interactions with these\nchatbots were safeguarded by the same regulations (e.g., HIPAA) as disclosures\nwith a licensed therapist. We introduce the concept of \"intangible\nvulnerability,\" where emotional or psychological disclosures are undervalued\ncompared to more tangible forms of information (e.g., financial or\nlocation-based data). To address this, we propose recommendations to safeguard\nuser mental health disclosures with general-purpose LLM-enabled chatbots more\neffectively.", "comment": "Accepted to the 34th USENIX Security Symposium", "pdf_url": "http://arxiv.org/pdf/2507.10695v1", "cate": "cs.CY", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.09367", "title": "Simulation for All: A Step-by-Step Cookbook for Developing Human-Centered Multi-Agent Transportation Simulators", "authors": ["Shiva Azimi", "Arash Tavakoli"], "categories": ["cs.MA"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09367v2", "summary": "As cities evolve toward more complex and multimodal transportation systems,\nthe need for human-centered multi-agent simulation tools has never been more\nurgent. Yet most existing platforms remain limited - they often separate\ndifferent types of road users, rely on scripted or pre-defined behaviors,\noverlook public transit users as active participants, and are rarely designed\nwith accessibility in mind for non-technical users. To address this gap, this\npaper presents the specifications of a multi-agent simulation platform designed\nto support real-time, human-centered, and immersive studies of all road users,\naccompanied by open-source scripts for replication. Using high-fidelity\nimmersive virtual environments, our platform enables interaction across public\ntransit users, pedestrians, cyclists, automated vehicles, and drivers. The\narchitecture is modular, extensible, and designed for accessibility. The system\nintegrates hardware-specific modules - including an omnidirectional treadmill,\na seating arrangement, a smart trainer, and an actuated cockpit. Additionally,\nthe platform collects multimodal physiological, neurological, and behavioral\ndata through embedded sensing devices such as functional near-infrared\nspectroscopy (fNIRS), eye tracking, and wrist-based biosensors. To show the\nusability of this system, we present three use cases. Simulation for All aims\nto lower the barrier to entry for high-fidelity transportation simulation,\nsupport experimentation across disciplines, and advance our understanding of\nmultimodal mobility in complex urban environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09367v2", "cate": "cs.MA", "date": "2025-07-12", "updated": "2025-07-15"}
{"id": "2507.10899", "title": "Object-Centric Mobile Manipulation through SAM2-Guided Perception and Imitation Learning", "authors": ["Wang Zhicheng", "Satoshi Yagi", "Satoshi Yamamori", "Jun Morimoto"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10899v1", "summary": "Imitation learning for mobile manipulation is a key challenge in the field of\nrobotic manipulation. However, current mobile manipulation frameworks typically\ndecouple navigation and manipulation, executing manipulation only after\nreaching a certain location. This can lead to performance degradation when\nnavigation is imprecise, especially due to misalignment in approach angles. To\nenable a mobile manipulator to perform the same task from diverse orientations,\nan essential capability for building general-purpose robotic models, we propose\nan object-centric method based on SAM2, a foundation model towards solving\npromptable visual segmentation in images, which incorporates manipulation\norientation information into our model. Our approach enables consistent\nunderstanding of the same task from different orientations. We deploy the model\non a custom-built mobile manipulator and evaluate it on a pick-and-place task\nunder varied orientation angles. Compared to Action Chunking Transformer, our\nmodel maintains superior generalization when trained with demonstrations from\nvaried approach angles. This work significantly enhances the generalization and\nrobustness of imitation learning-based mobile manipulation systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10899v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10740", "title": "Parsing Musical Structure to Enable Meaningful Variations", "authors": ["Maziar Kanani", "Sean O Leary", "James McDermott"], "categories": ["cs.AI", "cs.NE", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10740v1", "summary": "This paper presents a novel rule-based approach for generating music by\nvarying existing tunes. We parse each tune to find the Pathway Assembly (PA) [\n1], that is a structure representing all repetitions in the tune. The Sequitur\nalgorithm [2 ] is used for this. The result is a grammar. We then carry out\nmutation on the grammar, rather than on a tune directly. There are potentially\n19 types of mutations such as adding, removing, swapping or reversing parts of\nthe grammar that can be applied to the grammars. The system employs one of the\nmutations randomly in this step to automatically manipulate the grammar.\nFollowing the mutation, we need to expand the grammar which returns a new tune.\nThe output after 1 or more mutations will be a new tune related to the original\ntune. Our study examines how tunes change gradually over the course of multiple\nmutations. Edit distances, structural complexity and length of the tunes are\nused to show how a tune is changed after multiple mutations. In addition, the\nsize of effect of each mutation type is analyzed. As a final point, we review\nthe musical aspect of the output tunes. It should be noted that the study only\nfocused on generating new pitch sequences. The study is based on an Irish\ntraditional tune dataset and a list of integers has been used to represent each\ntune's pitch values.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10740v1", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10812", "title": "React to This (RTT): A Nonverbal Turing Test for Embodied AI", "authors": ["Chuxuan Zhang", "Yasaman Etesam", "Angelica Lim"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      5 pages, 3 figures", "url": "http://arxiv.org/abs/2507.10812v1", "summary": "We propose an approach to test embodied AI agents for interaction awareness\nand believability, particularly in scenarios where humans push them to their\nlimits. Turing introduced the Imitation Game as a way to explore the question:\n\"Can machines think?\" The Total Turing Test later expanded this concept beyond\npurely verbal communication, incorporating perceptual and physical interaction.\nBuilding on this, we propose a new guiding question: \"Can machines react?\" and\nintroduce the React to This (RTT) test for nonverbal behaviors, presenting\nresults from an initial experiment.", "comment": "5 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.10812v1", "cate": "cs.HC", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10564", "title": "Tool-to-Tool Matching Analysis Based Difference Score Computation Methods for Semiconductor Manufacturing", "authors": ["Sameera Bharadwaja H.", "Siddhrath Jandial", "Shashank S. Agashe", "Rajesh Kumar Reddy Moore", "Youngkwan Kim"], "categories": ["cs.LG", "cs.AI", "eess.SP", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10564v1", "summary": "We consider the problem of tool-to-tool matching (TTTM), also called, chamber\nmatching in the context of a semiconductor manufacturing equipment. Traditional\nTTTM approaches utilize static configuration data or depend on a golden\nreference which are difficult to obtain in a commercial manufacturing line.\nFurther, existing methods do not extend very well to a heterogeneous setting,\nwhere equipment are of different make-and-model, sourced from different\nequipment vendors. We propose novel TTTM analysis pipelines to overcome these\nissues. We hypothesize that a mismatched equipment would have higher variance\nand/or higher number of modes in the data. Our best univariate method achieves\na correlation coefficient >0.95 and >0.5 with the variance and number of modes,\nrespectively showing that the proposed methods are effective. Also, the best\nmultivariate method achieves a correlation coefficient >0.75 with the\ntop-performing univariate methods, showing its effectiveness. Finally, we\nanalyze the sensitivity of the multivariate algorithms to the algorithm\nhyper-parameters.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10564v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.11134", "title": "Fault-Free Analog Computing with Imperfect Hardware", "authors": ["Zhicheng Xu", "Jiawei Liu", "Sitao Huang", "Zefan Li", "Shengbo Wang", "Bo Wen", "Ruibin Mao", "Mingrui Jiang", "Giacomo Pedretti", "Jim Ignowski", "Kaibin Huang", "Can Li"], "categories": ["cs.ET", "cs.AR"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11134v1", "summary": "The growing demand for edge computing and AI drives research into analog\nin-memory computing using memristors, which overcome data movement bottlenecks\nby computing directly within memory. However, device failures and variations\ncritically limit analog systems' precision and reliability. Existing\nfault-tolerance techniques, such as redundancy and retraining, are often\ninadequate for high-precision applications or scenarios requiring fixed\nmatrices and privacy preservation. Here, we introduce and experimentally\ndemonstrate a fault-free matrix representation where target matrices are\ndecomposed into products of two adjustable sub-matrices programmed onto analog\nhardware. This indirect, adaptive representation enables mathematical\noptimization to bypass faulty devices and eliminate differential pairs,\nsignificantly enhancing computational density. Our memristor-based system\nachieved >99.999% cosine similarity for a Discrete Fourier Transform matrix\ndespite 39% device fault rate, a fidelity unattainable with conventional direct\nrepresentation, which fails with single device faults (0.01% rate). We\ndemonstrated 56-fold bit-error-rate reduction in wireless communication and\n>196% density with 179% energy efficiency improvements compared to\nstate-of-the-art techniques. This method, validated on memristors, applies\nbroadly to emerging memories and non-electrical computing substrates, showing\nthat device yield is no longer the primary bottleneck in analog computing\nhardware.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11134v1", "cate": "cs.ET", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10746", "title": "Optimal Debiased Inference on Privatized Data via Indirect Estimation and Parametric Bootstrap", "authors": ["Zhanyu Wang", "Arin Chang", "Jordan Awan"], "categories": ["stat.ME", "cs.CR"], "primary_category": "Subjects:       Methodology (stat.ME)", "pdf_link": null, "comments": "Comments:      double-spaced. 30pages before references and appendix. 59 pages total", "url": "http://arxiv.org/abs/2507.10746v1", "summary": "We design a debiased parametric bootstrap framework for statistical inference\nfrom differentially private data. Existing usage of the parametric bootstrap on\nprivatized data ignored or avoided handling the effect of clamping, a technique\nemployed by the majority of privacy mechanisms. Ignoring the impact of clamping\noften leads to under-coverage of confidence intervals and miscalibrated type I\nerrors of hypothesis tests. The main reason for the failure of the existing\nmethods is the inconsistency of the parameter estimate based on the privatized\ndata. We propose using the indirect inference method to estimate the parameter\nvalues consistently, and we use the improved estimator in parametric bootstrap\nfor inference. To implement the indirect estimator, we present a novel\nsimulation-based, adaptive approach along with the theory that establishes the\nconsistency of the corresponding parametric bootstrap estimates, confidence\nintervals, and hypothesis tests. In particular, we prove that our adaptive\nindirect estimator achieves the minimum asymptotic variance among all\n\"well-behaved\" consistent estimators based on the released summary statistic.\nOur simulation studies show that our framework produces confidence intervals\nwith well-calibrated coverage and performs hypothesis testing with the correct\ntype I error, giving state-of-the-art performance for inference on\nlocation-scale normals, simple linear regression, and logistic regression.", "comment": "double-spaced. 30pages before references and appendix. 59 pages total", "pdf_url": "http://arxiv.org/pdf/2507.10746v1", "cate": "stat.ME", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2408.10878", "title": "Trajectory Imputation in Multi-Agent Sports with Derivative-Accumulating Self-Ensemble", "authors": ["Han-Jun Choi", "Hyunsung Kim", "Minho Lee", "Minchul Jeong", "Chang-Jo Kim", "Jinsung Yoon", "Sang-Ki Ko"], "categories": ["cs.AI", "cs.LG", "cs.MA"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted at ECML/PKDD 2025", "url": "http://arxiv.org/abs/2408.10878v4", "summary": "Multi-agent trajectory data collected from domains such as team sports often\nsuffer from missing values due to various factors. While many imputation\nmethods have been proposed for spatiotemporal data, they are not well-suited\nfor multi-agent sports scenarios where player movements are highly dynamic and\ninter-agent interactions continuously evolve. To address these challenges, we\npropose MIDAS (Multi-agent Imputer with Derivative-Accumulating Self-ensemble),\na framework that imputes multi-agent trajectories with high accuracy and\nphysical plausibility. It jointly predicts positions, velocities, and\naccelerations through a Set Transformer-based neural network and generates\nalternative estimates by recursively accumulating predicted velocity and\nacceleration values. These predictions are then combined using a learnable\nweighted ensemble to produce final imputed trajectories. Experiments on three\nsports datasets demonstrate that MIDAS significantly outperforms existing\nbaselines in both positional accuracy and physical plausibility. Lastly, we\nshowcase use cases of MIDAS, such as approximating total distance and pass\nsuccess probability, to highlight its applicability to practical downstream\ntasks that require complete tracking data.", "comment": "Accepted at ECML/PKDD 2025", "pdf_url": "http://arxiv.org/pdf/2408.10878v4", "cate": "cs.AI", "date": "2024-08-20", "updated": "2025-07-15"}
{"id": "2507.10914", "title": "Fast Non-Episodic Adaptive Tuning of Robot Controllers with Online Policy Optimization", "authors": ["James A. Preiss", "Fengze Xie", "Yiheng Lin", "Adam Wierman", "Yisong Yue"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      11 pages, 9 figures", "url": "http://arxiv.org/abs/2507.10914v1", "summary": "We study online algorithms to tune the parameters of a robot controller in a\nsetting where the dynamics, policy class, and optimality objective are all\ntime-varying. The system follows a single trajectory without episodes or state\nresets, and the time-varying information is not known in advance. Focusing on\nnonlinear geometric quadrotor controllers as a test case, we propose a\npractical implementation of a single-trajectory model-based online policy\noptimization algorithm, M-GAPS,along with reparameterizations of the quadrotor\nstate space and policy class to improve the optimization landscape. In hardware\nexperiments,we compare to model-based and model-free baselines that impose\nartificial episodes. We show that M-GAPS finds near-optimal parameters more\nquickly, especially when the episode length is not favorable. We also show that\nM-GAPS rapidly adapts to heavy unmodeled wind and payload disturbances, and\nachieves similar strong improvement on a 1:6-scale Ackermann-steered car. Our\nresults demonstrate the hardware practicality of this emerging class of online\npolicy optimization that offers significantly more flexibility than classic\nadaptive control, while being more stable and data-efficient than model-free\nreinforcement learning.", "comment": "11 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.10914v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10750", "title": "AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition", "authors": ["Pandu Devarakota", "Nicolas Tsesmetzis", "Faruk O. Alpak", "Apurva Gala", "Detlef Hohl"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Technical article to be submitted to Data Centric Engineering Journal", "url": "http://arxiv.org/abs/2507.10750v1", "summary": "Thanks to the availability of massive amounts of data, computing resources,\nand advanced algorithms, AI has entered nearly every sector. This has sparked\nsignificant investment and interest, particularly in building data centers with\nthe necessary hardware and software to develop and operate AI models and\nAI-based workflows. In this technical review article, we present energy\nconsumption scenarios of data centers and impact on GHG emissions, considering\nboth near-term projections (up to 2030) and long-term outlook (2035 and\nbeyond). We address the quintessential question of whether AI will have a net\npositive, neutral, or negative impact on CO2 emissions by 2035. Additionally,\nwe discuss AI's potential to automate, create efficient and disruptive\nworkflows across various fields related to energy production, supply and\nconsumption. In the near-term scenario, the growing demand for AI will likely\nstrain computing resources, lead to increase in electricity consumption and\ntherefore associated CO2 emissions. This is due to the power-hungry nature of\nbig data centers and the requirements for training and running of large and\ncomplex AI models, as well as the penetration of AI assistant search and\napplications for public use. However, the long-term outlook could be more\npromising. AI has the potential to be a game-changer in CO2 reduction. Its\nability to further automate and optimize processes across industries, from\nenergy production to logistics, could significantly decrease our carbon\nfootprint. This positive impact is anticipated to outweigh the initial\nemissions bump, creating value for businesses and society in areas where\ntraditional solutions have fallen short. In essence, AI might cause some\ninitial growing pains for the environment, but it has the potential to support\nclimate mitigation efforts.", "comment": "Technical article to be submitted to Data Centric Engineering Journal", "pdf_url": "http://arxiv.org/pdf/2507.10750v1", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10813", "title": "Static or Temporal? Semantic Scene Simplification to Aid Wayfinding in Immersive Simulations of Bionic Vision", "authors": ["Justin M. Kasowski", "Apurv Varshney", "Michael Beyeler"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10813v1", "summary": "Visual neuroprostheses (bionic eye) aim to restore a rudimentary form of\nvision by translating camera input into patterns of electrical stimulation. To\nimprove scene understanding under extreme resolution and bandwidth constraints,\nprior work has explored computer vision techniques such as semantic\nsegmentation and depth estimation. However, presenting all task-relevant\ninformation simultaneously can overwhelm users in cluttered environments. We\ncompare two complementary approaches to semantic preprocessing in immersive\nvirtual reality: SemanticEdges, which highlights all relevant objects at once,\nand SemanticRaster, which staggers object categories over time to reduce visual\nclutter. Using a biologically grounded simulation of prosthetic vision, 18\nsighted participants performed a wayfinding task in a dynamic urban environment\nacross three conditions: edge-based baseline (Control), SemanticEdges, and\nSemanticRaster. Both semantic strategies improved performance and user\nexperience relative to the baseline, with each offering distinct trade-offs:\nSemanticEdges increased the odds of success, while SemanticRaster boosted the\nlikelihood of collision-free completions. These findings underscore the value\nof adaptive semantic preprocessing for prosthetic vision and, more broadly, may\ninform the design of low-bandwidth visual interfaces in XR that must balance\ninformation density, task relevance, and perceptual clarity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10813v1", "cate": "cs.HC", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10574", "title": "Enhancing Cross Entropy with a Linearly Adaptive Loss Function for Optimized Classification Performance", "authors": ["Jae Wan Shim"], "categories": ["cs.LG", "cs.AI", "cs.NE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      13 pages, 2 figures", "url": "http://arxiv.org/abs/2507.10574v1", "summary": "We propose the Linearly Adaptive Cross Entropy Loss function. This is a novel\nmeasure derived from the information theory. In comparison to the standard\ncross entropy loss function, the proposed one has an additional term that\ndepends on the predicted probability of the true class. This feature serves to\nenhance the optimization process in classification tasks involving one-hot\nencoded class labels. The proposed one has been evaluated on a ResNet-based\nmodel using the CIFAR-100 dataset. Preliminary results show that the proposed\none consistently outperforms the standard cross entropy loss function in terms\nof classification accuracy. Moreover, the proposed one maintains simplicity,\nachieving practically the same efficiency to the traditional cross entropy\nloss. These findings suggest that our approach could broaden the scope for\nfuture research into loss function design.", "comment": "13 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.10574v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.10576", "title": "Can Large Language Models Understand As Well As Apply Patent Regulations to Pass a Hands-On Patent Attorney Test?", "authors": ["Bhakti Khera", "Rezvan Alamian", "Pascal A. Scherz", "Stephan M. Goetz"], "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.ET"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      39 pages, 21 figures", "url": "http://arxiv.org/abs/2507.10576v1", "summary": "The legal field already uses various large language models (LLMs) in actual\napplications, but their quantitative performance and reasons for it are\nunderexplored. We evaluated several open-source and proprietary LLMs --\nincluding GPT-series, Anthropic, Deepseek and Llama-3, variants -- on parts of\nthe European Qualifying Examination (EQE) for future European Patent Attorneys.\nOpenAI o1 led with 0.82 accuracy and 0.81 F1 score, whereas (Amazon Web\nServices) AWS Llama 3.1 8B lagged at 0.50 accuracy, and a Python-deployed Llama\n3.1 8B scored 0.55. The latter two are within the range of mere guessing for\nthe two-answer forced-choice design. None of the evaluated models could have\npassed the examination fully, as accuracy never exceeded the average threshold\nof 0.90 required for professional-level standards -- also not models that are\nregularly promoted for their assumed beyond-PhD- and bar-admitted-lawyer-level\nperformance. GPT-4o excelled at integrating text and graphics, while Claude 3\nOpus often lost formatting coherence. Human patent experts evaluated the\ntextual justifications and uncovered various critical shortcomings of each\nmodel. They valued clarity and legal rationale over the raw correctness of the\nanswers, which revealed misalignment between automatic metrics and expert\njudgment. Model outputs were sensitive to modest temperature changes and prompt\nwording, which underscores the remaining necessity of expert oversight. Future\nwork should target logical consistency, robust multimodality, and adaptive\nprompting to approach human-level patent proficiency. In summary, despite the\noutstanding performance of recent large models, the general public might\noverestimate their performance. The field has a long way to go to develop a\nvirtual patent attorney. This paper wants to point out several specific\nlimitations that need solutions.", "comment": "39 pages, 21 figures", "pdf_url": "http://arxiv.org/pdf/2507.10576v1", "cate": "cs.CY", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.10786", "title": "\"Is it always watching? Is it always listening?\" Exploring Contextual Privacy and Security Concerns Toward Domestic Social Robots", "authors": ["Henry Bell", "Jabari Kwesi", "Hiba Laabadli", "Pardis Emami-Naeini"], "categories": ["cs.CY", "cs.AI", "cs.CR", "cs.ET"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10786v1", "summary": "Equipped with artificial intelligence (AI) and advanced sensing capabilities,\nsocial robots are gaining interest among consumers in the United States. These\nrobots seem like a natural evolution of traditional smart home devices.\nHowever, their extensive data collection capabilities, anthropomorphic\nfeatures, and capacity to interact with their environment make social robots a\nmore significant security and privacy threat. Increased risks include data\nlinkage, unauthorized data sharing, and the physical safety of users and their\nhomes. It is critical to investigate U.S. users' security and privacy needs and\nconcerns to guide the design of social robots while these devices are still in\nthe early stages of commercialization in the U.S. market. Through 19\nsemi-structured interviews, we identified significant security and privacy\nconcerns, highlighting the need for transparency, usability, and robust privacy\ncontrols to support adoption. For educational applications, participants\nworried most about misinformation, and in medical use cases, they worried about\nthe reliability of these devices. Participants were also concerned with the\ndata inference that social robots could enable. We found that participants\nexpect tangible privacy controls, indicators of data collection, and\ncontext-appropriate functionality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10786v1", "cate": "cs.CY", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2412.19403", "title": "Fully Data-driven but Interpretable Human Behavioural Modelling with Differentiable Discrete Choice Model", "authors": ["Fumiyasu Makinoshima", "Tatsuya Mitomi", "Fumiya Makihara", "Eigo Segawa"], "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.MA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.19403v3", "summary": "Discrete choice models are essential for modelling various decision-making\nprocesses in human behaviour. However, the specification of these models has\ndepended heavily on domain knowledge from experts, and the fully automated but\ninterpretable modelling of complex human behaviours has been a long-standing\nchallenge. In this paper, we introduce the differentiable discrete choice model\n(Diff-DCM), a fully data-driven method for the interpretable modelling,\nlearning, prediction, and control of complex human behaviours, which is\nrealised by differentiable programming. Solely from input features and choice\noutcomes without any prior knowledge, Diff-DCM can estimate interpretable\nclosed-form utility functions that reproduce observed behaviours. Comprehensive\nexperiments with both synthetic and real-world data demonstrate that Diff-DCM\ncan be applied to various types of data and requires only a small amount of\ncomputational resources for the estimations, which can be completed within tens\nof seconds on a laptop without any accelerators. In these experiments, we also\ndemonstrate that, using its differentiability, Diff-DCM can provide useful\ninsights into human behaviours, such as an optimal intervention path for\neffective behavioural changes. This study provides a strong basis for the fully\nautomated and reliable modelling, prediction, and control of human behaviours.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.19403v3", "cate": "cs.LG", "date": "2024-12-27", "updated": "2025-07-15"}
{"id": "2507.10950", "title": "Unified Modeling and Structural Optimization of Multi-magnet Embedded Soft Continuum Robots for Enhanced Kinematic Performances", "authors": ["Zhiwei Wu", "Jiahao Luo", "Siyi Wei", "Jinhui Zhang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10950v1", "summary": "This paper presents a unified modeling and optimization framework to enhance\nthe kinematic performance of multi-magnet embedded soft continuum robots\n(MeSCRs). To this end, we establish a differentiable system formulation based\non an extended pseudo-rigid-body model. This formulation enables analysis of\nthe equilibrium well-posedness and the geometry of the induced configuration\nunder magnetic actuation. In particular, we show that the maximum controllable\ndegrees of freedom of a MeSCR equal twice the number of embedded magnets. We\nsubsequently develop a structural optimization framework based on differential\ngeometry that links classical kinematic measures (e.g., manipulability and\ndexterity) to the configuration of embedded magnets. The resulting optimization\ncondition reveals that improving local performance requires structurally\nmodulating the spectrum of the configuration space metric to counteract its\ndistortion. Closed-form solutions for optimal magnet configurations are derived\nunder representative conditions, and a gradient-based numerical method is\nproposed for general design scenarios. Simulation studies validate the\neffectiveness of the proposed framework.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10950v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10758", "title": "IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models", "authors": ["Nikesh Prajapati", "Bimal Karki", "Saroj Gopali", "Akbar Siami Namin"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10758v1", "summary": "This paper intends to detect IoT malicious attacks through deep learning\nmodels and demonstrates a comprehensive evaluation of the deep learning and\ngraph-based models regarding malicious network traffic detection. The models\nparticularly are based on GraphSAGE, Bidirectional encoder representations from\ntransformers (BERT), Temporal Convolutional Network (TCN) as well as Multi-Head\nAttention, together with Bidirectional Long Short-Term Memory (BI-LSTM)\nMulti-Head Attention and BI-LSTM and LSTM models. The chosen models\ndemonstrated great performance to model temporal patterns and detect feature\nsignificance. The observed performance are mainly due to the fact that IoT\nsystem traffic patterns are both sequential and diverse, leaving a rich set of\ntemporal patterns for the models to learn. Experimental results showed that\nBERT maintained the best performance. It achieved 99.94% accuracy rate\nalongside high precision and recall, F1-score and AUC-ROC score of 99.99% which\ndemonstrates its capabilities through temporal dependency capture. The\nMulti-Head Attention offered promising results by providing good detection\ncapabilities with interpretable results. On the other side, the Multi-Head\nAttention model required significant processing time like BI-LSTM variants. The\nGraphSAGE model achieved good accuracy while requiring the shortest training\ntime but yielded the lowest accuracy, precision, and F1 score compared to the\nother models", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10758v1", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10963", "title": "AROMA: Mixed-Initiative AI Assistance for Non-Visual Cooking by Grounding Multi-modal Information Between Reality and Videos", "authors": ["Zheng Ning", "Leyang Li", "Daniel Killough", "JooYoung Seo", "Patrick Carrington", "Yapeng Tian", "Yuhang Zhao", "Franklin Mingzhe Li", "Toby Jia-Jun Li"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10963v1", "summary": "Videos offer rich audiovisual information that can support people in\nperforming activities of daily living (ADLs), but they remain largely\ninaccessible to blind or low-vision (BLV) individuals. In cooking, BLV people\noften rely on non-visual cues, such as touch, taste, and smell, to navigate\ntheir environment, making it difficult to follow the predominantly audiovisual\ninstructions found in video recipes. To address this problem, we introduce\nAROMA, an AI system that provides timely responses to the user based on\nreal-time, context-aware assistance by integrating non-visual cues perceived by\nthe user, a wearable camera feed, and video recipe content. AROMA uses a\nmixed-initiative approach: it responds to user requests while also proactively\nmonitoring the video stream to offer timely alerts and guidance. This\ncollaborative design leverages the complementary strengths of the user and AI\nsystem to align the physical environment with the video recipe, helping the\nuser interpret their current cooking state and make sense of the steps. We\nevaluated AROMA through a study with eight BLV participants and offered\ninsights for designing interactive AI systems to support BLV individuals in\nperforming ADLs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10963v1", "cate": "cs.HC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10575", "title": "An Adaptive Volatility-based Learning Rate Scheduler", "authors": ["Kieran Chai Kai Ren"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10575v1", "summary": "Effective learning rate (LR) scheduling is crucial for training deep neural\nnetworks. However, popular pre-defined and adaptive schedulers can still lead\nto suboptimal generalization. This paper introduces VolSched, a novel adaptive\nLR scheduler inspired by the concept of volatility in stochastic processes like\nGeometric Brownian Motion to dynamically adjust the learning rate. By\ncalculating the ratio between long-term and short-term accuracy volatility,\nVolSched increases the LR to escape plateaus and decreases it to stabilize\ntraining, allowing the model to explore the loss landscape more effectively. We\nevaluate VolSched on the CIFAR-100 dataset against a strong baseline using a\nstandard augmentation pipeline. When paired with ResNet-18 and ResNet-34, our\nscheduler delivers consistent performance gains, improving top-1 accuracy by\n1.4 and 1.3 percentage points respectively. Analysis of the loss curves reveals\nthat VolSched promotes a longer exploration phase. A quantitative analysis of\nthe Hessian shows that VolSched finds a final solution that is 38% flatter than\nthe next-best baseline, allowing the model to obtain wider minima and hence\nbetter generalization performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10575v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.10639", "title": "SPICEAssistant: LLM using SPICE Simulation Tools for Schematic Design of Switched-Mode Power Supplies", "authors": ["Simon Nau", "Jan Krummenauer", "André Zimmermann"], "categories": ["cs.AR", "cs.AI", "cs.ET"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      11 pages, 10 figures", "url": "http://arxiv.org/abs/2507.10639v1", "summary": "State-of-the-art large language models (LLMs) show high performance across a\nwide range of tasks in many domains of science. In the field of electronic\ndesign automation (EDA), it is yet to be determined to what extent they are\ncapable to understand, adapt, and dimension electronic circuits. This paper\nfocuses on the application of LLMs to switched-mode power supply (SMPS) design\non printed circuit boards (PCBs). Particular challenges for LLMs in this\ncontext include their limited ability to interpret results from key simulation\ntools like SPICE and the multi-step design process. To address these\nchallenges, we suggest SPICEAssistant, a framework that provides a broad\nselection of tools to an LLM. The tools serve as an interface to SPICE,\nallowing the LLM to interact flexibly with the simulator to estimate the impact\nof its modifications to the circuit. To evaluate the performance of\nSPICEAssistant, we defined a benchmark consisting of 256 questions testing the\nability to adapt circuit netlists to fulfil different SMPS design tasks. The\nbenchmarking results show that simulation feedback effectively improves SMPS\ndesign capabilities of LLMs. An increasing number of simulation iterations\nleads to enhanced performance. The SPICEAssistant framework significantly\noutperforms the standalone LLM GPT-4o on the benchmark by approximately 38%.", "comment": "11 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.10639v1", "cate": "cs.AR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10689", "title": "CWNet: Causal Wavelet Network for Low-Light Image Enhancement", "authors": ["Tongshun Zhang", "Pingping Liu", "Yubing Lu", "Mengen Cai", "Zijian Zhang", "Zhe Zhang", "Qiuzhan Zhou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.10689v1", "summary": "Traditional Low-Light Image Enhancement (LLIE) methods primarily focus on\nuniform brightness adjustment, often neglecting instance-level semantic\ninformation and the inherent characteristics of different features. To address\nthese limitations, we propose CWNet (Causal Wavelet Network), a novel\narchitecture that leverages wavelet transforms for causal reasoning.\nSpecifically, our approach comprises two key components: 1) Inspired by the\nconcept of intervention in causality, we adopt a causal reasoning perspective\nto reveal the underlying causal relationships in low-light enhancement. From a\nglobal perspective, we employ a metric learning strategy to ensure causal\nembeddings adhere to causal principles, separating them from non-causal\nconfounding factors while focusing on the invariance of causal factors. At the\nlocal level, we introduce an instance-level CLIP semantic loss to precisely\nmaintain causal factor consistency. 2) Based on our causal analysis, we present\na wavelet transform-based backbone network that effectively optimizes the\nrecovery of frequency information, ensuring precise enhancement tailored to the\nspecific attributes of wavelet transforms. Extensive experiments demonstrate\nthat CWNet significantly outperforms current state-of-the-art methods across\nmultiple datasets, showcasing its robust performance across diverse scenes.\nCode is available at https://github.com/bywlzts/CWNet-Causal-Wavelet-Network.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.10689v1", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10971", "title": "Security Enclave Architecture for Heterogeneous Security Primitives for Supply-Chain Attacks", "authors": ["Kshitij Raj", "Atri Chatterjee", "Patanjali SLPSK", "Swarup Bhunia", "Sandip Ray"], "categories": ["cs.AR", "cs.CR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10971v1", "summary": "Designing secure architectures for system-on-chip (SoC) platforms is a highly\nintricate and time-intensive task, often requiring months of development and\nmeticulous verification. Even minor architectural oversights can lead to\ncritical vulnerabilities that undermine the security of the entire chip. In\nresponse to this challenge, we introduce CITADEL, a modular security framework\naimed at streamlining the creation of robust security architectures for SoCs.\nCITADEL offers a configurable, plug-and-play subsystem composed of custom\nintellectual property (IP) blocks, enabling the construction of diverse\nsecurity mechanisms tailored to specific threats. As a concrete demonstration,\nwe instantiate CITADEL to defend against supply-chain threats, illustrating how\nthe framework adapts to one of the most pressing concerns in hardware security.\nThis paper explores the range of obstacles encountered when building a unified\nsecurity architecture capable of addressing multiple attack vectors and\npresents CITADEL's strategies for overcoming them. Through several real-world\ncase studies, we showcase the practical implementation of CITADEL and present a\nthorough evaluation of its impact on silicon area and power consumption across\nvarious ASIC technologies. Results indicate that CITADEL introduces only\nminimal resource overhead, making it a practical solution for enhancing SoC\nsecurity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10971v1", "cate": "cs.AR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2502.08542", "title": "Beyond Predictions: A Participatory Framework for Multi-Stakeholder Decision-Making", "authors": ["Vittoria Vineis", "Giuseppe Perelli", "Gabriele Tolomei"], "categories": ["cs.LG", "cs.MA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.08542v2", "summary": "Conventional automated decision-support systems, often based on supervised\nlearning, focus on predicting outcomes to recommend actions. However, they\ntypically overlook the complexity of multi-actor environments, where diverse\nand conflicting stakeholder preferences must be balanced. At the same time,\nparticipatory AI approaches remain largely context-specific, limiting their\nbroader applicability. To address these gaps, we propose a participatory\nframework that reframes decision-making as a multi-stakeholder optimization\nproblem, using context-dependent reward functions to represent each actor's\npreferences. Our modular, model-agnostic framework employs k-fold\ncross-validation to fine-tune user-provided prediction models and evaluate\ndecision strategies, including compromise functions that mediate stakeholder\ntrade-offs. A synthetic scoring mechanism aggregates user-defined preferences\nacross multiple metrics to rank strategies and select an optimal decision-maker\nfor generating actionable recommendations on new data. Validated on two\nhigh-stake real-world case studies, the framework consistently produces\nstakeholder-aware decisions that outperform purely predictive baselines across\nmultiple metrics, while enhancing the transparency and accountability of\nAI-supported decision-making.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.08542v2", "cate": "cs.LG", "date": "2025-02-12", "updated": "2025-07-15"}
{"id": "2507.10960", "title": "Whom to Respond To? A Transformer-Based Model for Multi-Party Social Robot Interaction", "authors": ["He Zhu", "Ryo Miyoshi", "Yuki Okafuji"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10960v1", "summary": "Prior human-robot interaction (HRI) research has primarily focused on\nsingle-user interactions, where robots do not need to consider the timing or\nrecipient of their responses. However, in multi-party interactions, such as at\nmalls and hospitals, social robots must understand the context and decide both\nwhen and to whom they should respond. In this paper, we propose a\nTransformer-based multi-task learning framework to improve the decision-making\nprocess of social robots, particularly in multi-user environments. Considering\nthe characteristics of HRI, we propose two novel loss functions: one that\nenforces constraints on active speakers to improve scene modeling, and another\nthat guides response selection towards utterances specifically directed at the\nrobot. Additionally, we construct a novel multi-party HRI dataset that captures\nreal-world complexities, such as gaze misalignment. Experimental results\ndemonstrate that our model achieves state-of-the-art performance in respond\ndecisions, outperforming existing heuristic-based and single-task approaches.\nOur findings contribute to the development of socially intelligent social\nrobots capable of engaging in natural and context-aware multi-party\ninteractions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10960v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10761", "title": "Detecting AI Assistance in Abstract Complex Tasks", "authors": ["Tyler King", "Nikolos Gurney", "John H. Miller", "Volkan Ustun"], "categories": ["cs.AI", "cs.HC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted to HCII 2025", "url": "http://arxiv.org/abs/2507.10761v1", "summary": "Detecting assistance from artificial intelligence is increasingly important\nas they become ubiquitous across complex tasks such as text generation, medical\ndiagnosis, and autonomous driving. Aid detection is challenging for humans,\nespecially when looking at abstract task data. Artificial neural networks excel\nat classification thanks to their ability to quickly learn from and process\nlarge amounts of data -- assuming appropriate preprocessing. We posit detecting\nhelp from AI as a classification task for such models. Much of the research in\nthis space examines the classification of complex but concrete data classes,\nsuch as images. Many AI assistance detection scenarios, however, result in data\nthat is not machine learning-friendly. We demonstrate that common models can\neffectively classify such data when it is appropriately preprocessed. To do so,\nwe construct four distinct neural network-friendly image formulations along\nwith an additional time-series formulation that explicitly encodes the\nexploration/exploitation of users, which allows for generalizability to other\nabstract tasks. We benchmark the quality of each image formulation across three\nclassical deep learning architectures, along with a parallel CNN-RNN\narchitecture that leverages the additional time series to maximize testing\nperformance, showcasing the importance of encoding temporal and spatial\nquantities for detecting AI aid in abstract tasks.", "comment": "Accepted to HCII 2025", "pdf_url": "http://arxiv.org/pdf/2507.10761v1", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10967", "title": "Self++: Merging Human and AI for Co-Determined XR Living in the Metaverse", "authors": ["Thammathip Piumsomboon"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10967v1", "summary": "This position paper introduces Self++, a novel nine-level framework for\nco-determined living in the Metaverse, grounded in Self-Determination Theory.\nSelf++ prioritises human flourishing by progressively cultivating competence,\nautonomy, and relatedness through dynamic human-AI collaboration in extended\nreality (XR). Unlike technologically deterministic approaches, Self++\nemphasises user empowerment by enhancing competency, mitigating cognitive\nbiases and leveraging XR's immersive capabilities. Key research directions\nproposed include exploring the boundaries of user-defined AI autonomy,\ndesigning for meaningful social connection in XR, and establishing proactive\nethical safeguards. Ultimately, Self++ offers a roadmap for creating a\nhuman-centred, AI-enhanced Metaverse where technology amplifies, rather than\ndiminishes, human potential.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10967v1", "cate": "cs.HC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10581", "title": "Universal Approximation Theorem for a Single-Layer Transformer", "authors": ["Esmail Gumaan"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      7 pages, 2 figures, 1 theorem, 10 formulas", "url": "http://arxiv.org/abs/2507.10581v1", "summary": "Deep learning employs multi-layer neural networks trained via the\nbackpropagation algorithm. This approach has achieved success across many\ndomains and relies on adaptive gradient methods such as the Adam optimizer.\nSequence modeling evolved from recurrent neural networks to attention-based\nmodels, culminating in the Transformer architecture. Transformers have achieved\nstate-of-the-art performance in natural language processing (for example, BERT\nand GPT-3) and have been applied in computer vision and computational biology.\nHowever, theoretical understanding of these models remains limited. In this\npaper, we examine the mathematical foundations of deep learning and\nTransformers and present a novel theoretical result. We review key concepts\nfrom linear algebra, probability, and optimization that underpin deep learning,\nand we analyze the multi-head self-attention mechanism and the backpropagation\nalgorithm in detail. Our main contribution is a universal approximation theorem\nfor Transformers: we prove that a single-layer Transformer, comprising one\nself-attention layer followed by a position-wise feed-forward network with ReLU\nactivation, can approximate any continuous sequence-to-sequence mapping on a\ncompact domain to arbitrary precision. We provide a formal statement and a\ncomplete proof. Finally, we present case studies that demonstrate the practical\nimplications of this result. Our findings advance the theoretical understanding\nof Transformer models and help bridge the gap between theory and practice.", "comment": "7 pages, 2 figures, 1 theorem, 10 formulas", "pdf_url": "http://arxiv.org/pdf/2507.10581v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.10803", "title": "Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case", "authors": ["JaMor Hairston", "Ritvik Ranjan", "Sahithi Lakamana", "Anthony Spadaro", "Selen Bozkurt", "Jeanmarie Perrone", "Abeed Sarker"], "categories": ["cs.AI", "cs.CL", "cs.ET", "cs.IR"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Pages: 19, Abstract word count: 151 words, Manuscript word count: 2185 words, References: 14, Figures: 3, Tables: 2", "url": "http://arxiv.org/abs/2507.10803v1", "summary": "Background Large language models (LLMs) face challenges in inductive thematic\nanalysis, a task requiring deep interpretive and domain-specific expertise. We\nevaluated the feasibility of using LLMs to replicate expert-driven thematic\nanalysis of social media data. Methods Using two temporally non-intersecting\nReddit datasets on xylazine (n=286 and n=686, for model optimization and\nvalidation, respectively) with twelve expert-derived themes, we evaluated five\nLLMs against expert coding. We modeled the task as a series of binary\nclassifications, rather than a single, multi-label classification, employing\nzero-, single-, and few-shot prompting strategies and measuring performance via\naccuracy, precision, recall, and F1-score. Results On the validation set,\nGPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:\n0.71). For high-prevalence themes, model-derived thematic distributions closely\nmirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:\n16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based\napproaches can automate thematic analyses, offering a scalable supplement for\nqualitative research. Keywords: thematic analysis, large language models,\nnatural language processing, qualitative analysis, social media, prompt\nengineering, public health", "comment": "Pages: 19, Abstract word count: 151 words, Manuscript word count:\n  2185 words, References: 14, Figures: 3, Tables: 2", "pdf_url": "http://arxiv.org/pdf/2507.10803v1", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10737", "title": "Integrating Biological Knowledge for Robust Microscopy Image Profiling on De Novo Cell Lines", "authors": ["Jiayuan Chen", "Thai-Hoang Pham", "Yuanlong Wang", "Ping Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.10737v1", "summary": "High-throughput screening techniques, such as microscopy imaging of cellular\nresponses to genetic and chemical perturbations, play a crucial role in drug\ndiscovery and biomedical research. However, robust perturbation screening for\n\\textit{de novo} cell lines remains challenging due to the significant\nmorphological and biological heterogeneity across cell lines. To address this,\nwe propose a novel framework that integrates external biological knowledge into\nexisting pretraining strategies to enhance microscopy image profiling models.\nOur approach explicitly disentangles perturbation-specific and cell\nline-specific representations using external biological information.\nSpecifically, we construct a knowledge graph leveraging protein interaction\ndata from STRING and Hetionet databases to guide models toward\nperturbation-specific features during pretraining. Additionally, we incorporate\ntranscriptomic features from single-cell foundation models to capture cell\nline-specific representations. By learning these disentangled features, our\nmethod improves the generalization of imaging models to \\textit{de novo} cell\nlines. We evaluate our framework on the RxRx database through one-shot\nfine-tuning on an RxRx1 cell line and few-shot fine-tuning on cell lines from\nthe RxRx19a dataset. Experimental results demonstrate that our method enhances\nmicroscopy image profiling for \\textit{de novo} cell lines, highlighting its\neffectiveness in real-world phenotype-based drug discovery applications.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.10737v1", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11112", "title": "Multi-Trigger Poisoning Amplifies Backdoor Vulnerabilities in LLMs", "authors": ["Sanhanat Sivapiromrat", "Caiqi Zhang", "Marco Basaldella", "Nigel Collier"], "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11112v1", "summary": "Recent studies have shown that Large Language Models (LLMs) are vulnerable to\ndata poisoning attacks, where malicious training examples embed hidden\nbehaviours triggered by specific input patterns. However, most existing works\nassume a phrase and focus on the attack's effectiveness, offering limited\nunderstanding of trigger mechanisms and how multiple triggers interact within\nthe model. In this paper, we present a framework for studying poisoning in\nLLMs. We show that multiple distinct backdoor triggers can coexist within a\nsingle model without interfering with each other, enabling adversaries to embed\nseveral triggers concurrently. Using multiple triggers with high embedding\nsimilarity, we demonstrate that poisoned triggers can achieve robust activation\neven when tokens are substituted or separated by long token spans. Our findings\nexpose a broader and more persistent vulnerability surface in LLMs. To mitigate\nthis threat, we propose a post hoc recovery method that selectively retrains\nspecific model components based on a layer-wise weight difference analysis. Our\nmethod effectively removes the trigger behaviour with minimal parameter\nupdates, presenting a practical and efficient defence against multi-trigger\npoisoning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11112v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.02575", "title": "A unifying approach to self-organizing systems interacting via conservation laws", "authors": ["Frank Barrows", "Guanming Zhang", "Satyam Anand", "Zixi Chen", "Jonathan Lin", "Aman Desai", "Stefano Martiniani", "Francesco Caravelli"], "categories": ["cond-mat.soft", "cond-mat.stat-mech", "cs.MA", "nlin.AO"], "primary_category": "Subjects:       Soft Condensed Matter (cond-mat.soft)", "pdf_link": null, "comments": "Comments:      14 pages double column + 13 pages supplementary", "url": "http://arxiv.org/abs/2507.02575v3", "summary": "We present a unified framework for embedding and analyzing dynamical systems\nusing generalized projection operators rooted in local conservation laws. By\nrepresenting physical, biological, and engineered systems as graphs with\nincidence and cycle matrices, we derive dual projection operators that\ndecompose network fluxes and potentials. This formalism aligns with principles\nof non-equilibrium thermodynamics and captures a broad class of systems\ngoverned by flux-forcing relationships and local constraints. We extend this\napproach to collective dynamics through the PRojective Embedding of Dynamical\nSystems (PrEDS), which lifts low-dimensional dynamics into a high-dimensional\nspace, enabling both replication and recovery of the original dynamics. When\nsystems fall within the PrEDS class, their collective behavior can be\neffectively approximated through projection onto a mean-field space. We\ndemonstrate the versatility of PrEDS across diverse domains, including\nresistive and memristive circuits, adaptive flow networks (e.g., slime molds),\nelastic string networks, and particle swarms. Notably, we establish a direct\ncorrespondence between PrEDS and swarm dynamics, revealing new insights into\noptimization and self-organization. Our results offer a general theoretical\nfoundation for analyzing complex networked systems and for designing systems\nthat self-organize through local interactions.", "comment": "14 pages double column + 13 pages supplementary", "pdf_url": "http://arxiv.org/pdf/2507.02575v3", "cate": "cond-mat.soft", "date": "2025-07-03", "updated": "2025-07-15"}
{"id": "2507.10961", "title": "EquiContact: A Hierarchical SE(3) Vision-to-Force Equivariant Policy for Spatially Generalizable Contact-rich Tasks", "authors": ["Joohwan Seo", "Arvind Kruthiventy", "Soomi Lee", "Megan Teng", "Xiang Zhang", "Seoyeon Choi", "Jongeun Choi", "Roberto Horowitz"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Submitted to RA-L", "url": "http://arxiv.org/abs/2507.10961v1", "summary": "This paper presents a framework for learning vision-based robotic policies\nfor contact-rich manipulation tasks that generalize spatially across task\nconfigurations. We focus on achieving robust spatial generalization of the\npolicy for the peg-in-hole (PiH) task trained from a small number of\ndemonstrations. We propose EquiContact, a hierarchical policy composed of a\nhigh-level vision planner (Diffusion Equivariant Descriptor Field, Diff-EDF)\nand a novel low-level compliant visuomotor policy (Geometric Compliant ACT,\nG-CompACT). G-CompACT operates using only localized observations (geometrically\nconsistent error vectors (GCEV), force-torque readings, and wrist-mounted RGB\nimages) and produces actions defined in the end-effector frame. Through these\ndesign choices, we show that the entire EquiContact pipeline is\nSE(3)-equivariant, from perception to force control. We also outline three key\ncomponents for spatially generalizable contact-rich policies: compliance,\nlocalized policies, and induced equivariance. Real-world experiments on PiH\ntasks demonstrate a near-perfect success rate and robust generalization to\nunseen spatial configurations, validating the proposed framework and\nprinciples. The experimental videos can be found on the project website:\nhttps://sites.google.com/berkeley.edu/equicontact", "comment": "Submitted to RA-L", "pdf_url": "http://arxiv.org/pdf/2507.10961v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10798", "title": "Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions", "authors": ["Asim H. Gazi", "Bhanu T. Gullapalli", "Daiqi Gao", "Benjamin M. Marlin", "Vivek Shetty", "Susan A. Murphy"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      4 pages, 3 figures", "url": "http://arxiv.org/abs/2507.10798v1", "summary": "Timely decision making is critical to the effectiveness of mobile health\n(mHealth) interventions. At predefined timepoints called \"decision points,\"\nintelligent mHealth systems such as just-in-time adaptive interventions\n(JITAIs) estimate an individual's biobehavioral context from sensor or survey\ndata and determine whether and how to intervene. For interventions targeting\nhabitual behavior (e.g., oral hygiene), effectiveness often hinges on\ndelivering support shortly before the target behavior is likely to occur.\nCurrent practice schedules decision points at a fixed interval (e.g., one hour)\nbefore user-provided behavior times, and the fixed interval is kept the same\nfor all individuals. However, this one-size-fits-all approach performs poorly\nfor individuals with irregular routines, often scheduling decision points after\nthe target behavior has already occurred, rendering interventions ineffective.\nIn this paper, we propose SigmaScheduling, a method to dynamically schedule\ndecision points based on uncertainty in predicted behavior times. When behavior\ntiming is more predictable, SigmaScheduling schedules decision points closer to\nthe predicted behavior time; when timing is less certain, SigmaScheduling\nschedules decision points earlier, increasing the likelihood of timely\nintervention. We evaluated SigmaScheduling using real-world data from 68\nparticipants in a 10-week trial of Oralytics, a JITAI designed to improve daily\ntoothbrushing. SigmaScheduling increased the likelihood that decision points\npreceded brushing events in at least 70% of cases, preserving opportunities to\nintervene and impact behavior. Our results indicate that SigmaScheduling can\nadvance precision mHealth, particularly for JITAIs targeting time-sensitive,\nhabitual behaviors such as oral hygiene or dietary habits.", "comment": "4 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.10798v1", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10970", "title": "Terms and Conditions (Do Not) Apply: Understanding Exploitation Disparities in Design of Mobile-Based Financial Services", "authors": ["Lindah Kotut"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted for Publication at The 5th Biennial African Human Computer Interaction Conference (AfriCHI 2025). 10 pages (excluding references), 3 figures", "url": "http://arxiv.org/abs/2507.10970v1", "summary": "Mobile-based financial services have made it possible for the traditionally\nunbanked to access infrastructure that have been routinely unattainable.\nResearchers have explored how these systems have made for safer environments to\nsend and receive money and have expanded financial opportunities such as\nincreased borrowing. With this expansion, challenges such as detrimental\ninterest rates, lack of access to policy documents, and inadequate user\nprotective guardrails emerge, amplifying the risks due to technology-aided\nunethical financial practices that are aided by design patterns. Supported by\nuser interviews, we detail user experiences of mobile-based financial\ntransactions and explore the foundations and guidelines that undergird the\nfinancial service provisions: highlighting both affordances and harms enabled\nin the design of such systems. We discuss the findings by highlighting\nfinancial exploitation disparities, deliberating strategies for mitigation of\nrisks and enabling recovery from harms caused by the technology use. We then\nrecommend guidelines for empowering design approaches that support users'\nmechanisms of trust, their understanding of technological processes, and\ndetermination of risks.", "comment": "Accepted for Publication at The 5th Biennial African Human Computer\n  Interaction Conference (AfriCHI 2025). 10 pages (excluding references), 3\n  figures", "pdf_url": "http://arxiv.org/pdf/2507.10970v1", "cate": "cs.HC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10594", "title": "Extension OL-MDISF: Online Learning from Mix-Typed, Drifted, and Incomplete Streaming Features", "authors": ["Shengda Zhuo", "Di Wu", "Yi He", "Shuqiang Huang", "Xindong Wu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10594v1", "summary": "Online learning, where feature spaces can change over time, offers a flexible\nlearning paradigm that has attracted considerable attention. However, it still\nfaces three significant challenges. First, the heterogeneity of real-world data\nstreams with mixed feature types presents challenges for traditional parametric\nmodeling. Second, data stream distributions can shift over time, causing an\nabrupt and substantial decline in model performance. Third, it is often\ninfeasible to label every data instance due to time and cost constraints. To\naddress these issues, we proposed OL-MDISF (Online Learning from Mix-typed,\nDrifted, and Incomplete Streaming Features), which constructs a latent\ncopula-based representation for heterogeneous features, detects drifts via\nensemble entropy and latent mismatch, and performs structure-aware\npseudo-labeling.\n  This companion paper serves as a standalone technical reference to OL-MDISF.\nIt provides a contextual discussion of related work in mixed-type modeling,\ndrift adaptation, and weak supervision, as well as a comprehensive set of\nexperiments across 14 real-world datasets under two types of drift scenarios.\nThese include CER trends, ablation studies, sensitivity analyses, and temporal\nensemble dynamics. We hope this document offers a reproducible benchmark for\nonline learning on complex, weakly supervised streaming data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10594v1", "cate": "cs.LG", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2507.11401", "title": "Stochastic Entanglement Configuration for Constructive Entanglement Topologies in Quantum Machine Learning with Application to Cardiac MRI", "authors": ["Mehri Mehrnia", "Mohammed S. M. Elbaz"], "categories": ["quant-ph", "cs.CV", "cs.ET", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      Accepted for publication at IEEE International Conference on Quantum Computing and Engineering (QCE) 2025", "url": "http://arxiv.org/abs/2507.11401v1", "summary": "Efficient entanglement strategies are essential for advancing variational\nquantum circuits (VQCs) for quantum machine learning (QML). However, most\ncurrent approaches use fixed entanglement topologies that are not adaptive to\ntask requirements, limiting potential gains over classical models. We introduce\na novel stochastic entanglement configuration method that systematically\ngenerates diverse entanglement topologies to identify a subspace of\nconstructive entanglement configurations, defined as entanglement topologies\nthat boost hybrid model performance (e.g., classification accuracy) beyond\nclassical baselines. Each configuration is encoded as a stochastic binary\nmatrix, denoting directed entanglement between qubits. This enables scalable\nexploration of the hyperspace of candidate entanglement topologies using\nentanglement density and per-qubit constraints as key metrics. We define\nunconstrained and constrained sampling modes, controlling entanglement per\nqubit. Using our method, 400 stochastic configurations were generated and\nevaluated in a hybrid QML for cardiac MRI disease classification. We identified\n64 (16%) novel constructive entanglement configurations that consistently\noutperformed the classical baseline. Ensemble aggregation of top-performing\nconfigurations achieved ~0.92 classification accuracy, exceeding the classical\nmodel (~0.87) by over 5%. Compared to four conventional topologies (ring,\nnearest neighbor, no entanglement, fully entangled), none surpassed the\nclassical baseline (maximum accuracy ~0.82), while our configurations delivered\nup to ~20% higher accuracy. Thus, highlighting the robustness and\ngeneralizability of the identified constructive entanglements.", "comment": "Accepted for publication at IEEE International Conference on Quantum\n  Computing and Engineering (QCE) 2025", "pdf_url": "http://arxiv.org/pdf/2507.11401v1", "cate": "quant-ph", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10755", "title": "Auditing Facial Emotion Recognition Datasets for Posed Expressions and Racial Bias", "authors": ["Rina Khan", "Catherine Stinson"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10755v1", "summary": "Facial expression recognition (FER) algorithms classify facial expressions\ninto emotions such as happy, sad, or angry. An evaluative challenge facing FER\nalgorithms is the fall in performance when detecting spontaneous expressions\ncompared to posed expressions. An ethical (and evaluative) challenge facing FER\nalgorithms is that they tend to perform poorly for people of some races and\nskin colors. These challenges are linked to the data collection practices\nemployed in the creation of FER datasets. In this study, we audit two\nstate-of-the-art FER datasets. We take random samples from each dataset and\nexamine whether images are spontaneous or posed. In doing so, we propose a\nmethodology for identifying spontaneous or posed images. We discover a\nsignificant number of images that were posed in the datasets purporting to\nconsist of in-the-wild images. Since performance of FER models vary between\nspontaneous and posed images, the performance of models trained on these\ndatasets will not represent the true performance if such models were to be\ndeployed in in-the-wild applications. We also observe the skin color of\nindividuals in the samples, and test three models trained on each of the\ndatasets to predict facial expressions of people from various races and skin\ntones. We find that the FER models audited were more likely to predict people\nlabeled as not white or determined to have dark skin as showing a negative\nemotion such as anger or sadness even when they were smiling. This bias makes\nsuch models prone to perpetuate harm in real life applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10755v1", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10583", "title": "$\\texttt{Droid}$: A Resource Suite for AI-Generated Code Detection", "authors": ["Daniil Orel", "Indraneil Paul", "Iryna Gurevych", "Preslav Nakov"], "categories": ["cs.SE", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10583v1", "summary": "In this work, we compile $\\textbf{$\\texttt{DroidCollection}$}$, the most\nextensive open data suite for training and evaluating machine-generated code\ndetectors, comprising over a million code samples, seven programming languages,\noutputs from 43 coding models, and over three real-world coding domains.\nAlongside fully AI-generated samples, our collection includes human-AI\nco-authored code, as well as adversarial samples explicitly crafted to evade\ndetection. Subsequently, we develop $\\textbf{$\\texttt{DroidDetect}$}$, a suite\nof encoder-only detectors trained using a multi-task objective over\n$\\texttt{DroidCollection}$. Our experiments show that existing detectors'\nperformance fails to generalise to diverse coding domains and programming\nlanguages outside of their narrow training data. Additionally, we demonstrate\nthat while most detectors are easily compromised by humanising the output\ndistributions using superficial prompting and alignment approaches, this\nproblem can be easily amended by training on a small amount of adversarial\ndata. Finally, we demonstrate the effectiveness of metric learning and\nuncertainty-based resampling as means to enhance detector training on possibly\nnoisy distributions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10583v1", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2302.05545", "title": "Privacy Against Agnostic Inference Attacks in Vertical Federated Learning", "authors": ["Morteza Varasteh"], "categories": ["cs.CR", "cs.IT", "cs.LG", "math.IT"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2302.05545v3", "summary": "A novel form of inference attack in vertical federated learning (VFL) is\nproposed, where two parties collaborate in training a machine learning (ML)\nmodel. Logistic regression is considered for the VFL model. One party, referred\nto as the active party, possesses the ground truth labels of the samples in the\ntraining phase, while the other, referred to as the passive party, only shares\na separate set of features corresponding to these samples. It is shown that the\nactive party can carry out inference attacks on both training and prediction\nphase samples by acquiring an ML model independently trained on the training\nsamples available to them. This type of inference attack does not require the\nactive party to be aware of the score of a specific sample, hence it is\nreferred to as an agnostic inference attack. It is shown that utilizing the\nobserved confidence scores during the prediction phase, before the time of the\nattack, can improve the performance of the active party's autonomous ML model,\nand thus improve the quality of the agnostic inference attack. As a\ncountermeasure, privacy-preserving schemes (PPSs) are proposed. While the\nproposed schemes preserve the utility of the VFL model, they systematically\ndistort the VFL parameters corresponding to the passive party's features. The\nlevel of the distortion imposed on the passive party's parameters is\nadjustable, giving rise to a trade-off between privacy of the passive party and\ninterpretabiliy of the VFL outcomes by the active party. The distortion level\nof the passive party's parameters could be chosen carefully according to the\nprivacy and interpretabiliy concerns of the passive and active parties,\nrespectively, with the hope of keeping both parties (partially) satisfied.\nFinally, experimental results demonstrate the effectiveness of the proposed\nattack and the PPSs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2302.05545v3", "cate": "cs.CR", "date": "2023-02-10", "updated": "2025-07-15"}
{"id": "2507.10968", "title": "SMART-Merge Planner: A Safe Merging and Real-Time Motion Planner for Autonomous Highway On-Ramp Merging", "authors": ["Toktam Mohammadnejad", "Jovin D'sa", "Behdad Chalaki", "Hossein Nourkhiz Mahjoub", "Ehsan Moradi-Pari"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE ITSC 2025", "url": "http://arxiv.org/abs/2507.10968v1", "summary": "Merging onto a highway is a complex driving task that requires identifying a\nsafe gap, adjusting speed, often interactions to create a merging gap, and\ncompleting the merge maneuver within a limited time window while maintaining\nsafety and driving comfort. In this paper, we introduce a Safe Merging and\nReal-Time Merge (SMART-Merge) planner, a lattice-based motion planner designed\nto facilitate safe and comfortable forced merging. By deliberately adapting\ncost terms to the unique challenges of forced merging and introducing a desired\nspeed heuristic, SMART-Merge planner enables the ego vehicle to merge\nsuccessfully while minimizing the merge time. We verify the efficiency and\neffectiveness of the proposed merge planner through high-fidelity CarMaker\nsimulations on hundreds of highway merge scenarios. Our proposed planner\nachieves the success rate of 100% as well as completes the merge maneuver in\nthe shortest amount of time compared with the baselines, demonstrating our\nplanner's capability to handle complex forced merge tasks and provide a\nreliable and robust solution for autonomous highway merge. The simulation\nresult videos are available at\nhttps://sites.google.com/view/smart-merge-planner/home.", "comment": "Accepted at IEEE ITSC 2025", "pdf_url": "http://arxiv.org/pdf/2507.10968v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10831", "title": "AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks", "authors": ["Yilin Xia", "Heng Zheng", "Shawn Bowers", "Bertram Ludäscher"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      International Conference on Artificial Intelligence and Law (ICAIL), June 16-20, 2025. Chicago, IL, USA", "url": "http://arxiv.org/abs/2507.10831v1", "summary": "Argumentation frameworks (AFs) provide formal approaches for legal reasoning,\nbut identifying sources of ambiguity and explaining argument acceptance remains\nchallenging for non-experts. We present AF-XRAY, an open-source toolkit for\nexploring, analyzing, and visualizing abstract AFs in legal reasoning. AF-XRAY\nintroduces: (i) layered visualizations based on game-theoretic argument length\nrevealing well-founded derivation structures; (ii) classification of attack\nedges by semantic roles (primary, secondary, blunders); (iii) overlay\nvisualizations of alternative 2-valued solutions on ambiguous 3-valued grounded\nsemantics; and (iv) identification of critical attack sets whose suspension\nresolves undecided arguments. Through systematic generation of critical attack\nsets, AF-XRAY transforms ambiguous scenarios into grounded solutions, enabling\nusers to pinpoint specific causes of ambiguity and explore alternative\nresolutions. We use real-world legal cases (e.g., Wild Animals as modeled by\nBench-Capon) to show that our tool supports teleological legal reasoning by\nrevealing how different assumptions lead to different justified conclusions.", "comment": "International Conference on Artificial Intelligence and Law (ICAIL),\n  June 16-20, 2025. Chicago, IL, USA", "pdf_url": "http://arxiv.org/pdf/2507.10831v1", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10981", "title": "An Exploratory Study on AI-driven Visualisation Techniques on Decision Making in Extended Reality", "authors": ["Ze Dong", "Binyang Han", "Jingjing Zhang", "Ruoyu Wen", "Barrett Ens", "Adrian Clark", "Tham Piumsomboon"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10981v1", "summary": "The integration of extended reality (XR) with artificial intelligence (AI)\nintroduces a new paradigm for user interaction, enabling AI to perceive user\nintent, stimulate the senses, and influence decision-making. We explored the\nimpact of four AI-driven visualisation techniques -- `Inform,' `Nudge,'\n`Recommend,' and `Instruct' -- on user decision-making in XR using the Meta\nQuest Pro. To test these techniques, we used a pre-recorded 360-degree video of\na supermarket, overlaying each technique through a virtual interface. We aimed\nto investigate how these different visualisation techniques with different\nlevels of user autonomy impact preferences and decision-making. An exploratory\nstudy with semi-structured interviews provided feedback and design\nrecommendations. Our findings emphasise the importance of maintaining user\nautonomy, enhancing AI transparency to build trust, and considering context in\nvisualisation design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10981v1", "cate": "cs.HC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10595", "title": "Divide-Then-Rule: A Cluster-Driven Hierarchical Interpolator for Attribute-Missing Graphs", "authors": ["Yaowen Hu", "Wenxuan Tu", "Yue Liu", "Miaomiao Li", "Wenpeng Lu", "Zhigang Luo", "Xinwang Liu", "Ping Chen"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10595v1", "summary": "Deep graph clustering (DGC) for attribute-missing graphs is an unsupervised\ntask aimed at partitioning nodes with incomplete attributes into distinct\nclusters. Addressing this challenging issue is vital for practical\napplications. However, research in this area remains underexplored. Existing\nimputation methods for attribute-missing graphs often fail to account for the\nvarying amounts of information available across node neighborhoods, leading to\nunreliable results, especially for nodes with insufficient known neighborhood.\nTo address this issue, we propose a novel method named Divide-Then-Rule Graph\nCompletion (DTRGC). This method first addresses nodes with sufficient known\nneighborhood information and treats the imputed results as new knowledge to\niteratively impute more challenging nodes, while leveraging clustering\ninformation to correct imputation errors. Specifically, Dynamic Cluster-Aware\nFeature Propagation (DCFP) initializes missing node attributes by adjusting\npropagation weights based on the clustering structure. Subsequently,\nHierarchical Neighborhood-aware Imputation (HNAI) categorizes attribute-missing\nnodes into three groups based on the completeness of their neighborhood\nattributes. The imputation is performed hierarchically, prioritizing the groups\nwith nodes that have the most available neighborhood information. The cluster\nstructure is then used to refine the imputation and correct potential errors.\nFinally, Hop-wise Representation Enhancement (HRE) integrates information\nacross multiple hops, thereby enriching the expressiveness of node\nrepresentations. Experimental results on six widely used graph datasets show\nthat DTRGC significantly improves the clustering performance of various DGC\nmethods under attribute-missing graphs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10595v1", "cate": "cs.LG", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2507.11437", "title": "Uniting the World by Dividing it: Federated Maps to Enable Spatial Applications", "authors": ["Sagar Bharadwaj", "Srinivasan Seshan", "Anthony Rowe"], "categories": ["cs.DC", "cs.ET"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11437v1", "summary": "The emergence of the Spatial Web -- the Web where content is tied to\nreal-world locations has the potential to improve and enable many applications\nsuch as augmented reality, navigation, robotics, and more. The Spatial Web is\nmissing a key ingredient that is impeding its growth -- a spatial naming system\nto resolve real-world locations to names. Today's spatial naming systems are\ndigital maps such as Google and Apple maps. These maps and the location-based\nservices provided on top of these maps are primarily controlled by a few large\ncorporations and mostly cover outdoor public spaces. Emerging classes of\napplications, such as persistent world-scale augmented reality, require\ndetailed maps of both outdoor and indoor spaces. Existing centralized mapping\ninfrastructures are proving insufficient for such applications because of the\nscale of cartography efforts required and the privacy of indoor map data.\n  In this paper, we present a case for a federated spatial naming system, or in\nother words, a federated mapping infrastructure. This enables disparate parties\nto manage and serve their own maps of physical regions and unlocks scalability\nof map management, isolation and privacy of maps. Map-related services such as\naddress-to-location mapping, location-based search, and routing needs\nre-architecting to work on federated maps. We discuss some essential services\nand practicalities of enabling these services.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11437v1", "cate": "cs.DC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10770", "title": "FPC-Net: Revisiting SuperPoint with Descriptor-Free Keypoint Detection via Feature Pyramids and Consistency-Based Implicit Matching", "authors": ["Ionuţ Grigore", "Călin-Adrian Popa", "Claudiu Leoveanu-Condrei"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10770v1", "summary": "The extraction and matching of interest points are fundamental to many\ngeometric computer vision tasks. Traditionally, matching is performed by\nassigning descriptors to interest points and identifying correspondences based\non descriptor similarity. This work introduces a technique where interest\npoints are inherently associated during detection, eliminating the need for\ncomputing, storing, transmitting, or matching descriptors. Although the\nmatching accuracy is marginally lower than that of conventional approaches, our\nmethod completely eliminates the need for descriptors, leading to a drastic\nreduction in memory usage for localization systems. We assess its effectiveness\nby comparing it against both classical handcrafted methods and modern learned\napproaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10770v1", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10584", "title": "ARPaCCino: An Agentic-RAG for Policy as Code Compliance", "authors": ["Francesco Romeo", "Luigi Arena", "Francesco Blefari", "Francesco Aurelio Pironti", "Matteo Lupinacci", "Angelo Furfaro"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10584v1", "summary": "Policy as Code (PaC) is a paradigm that encodes security and compliance\npolicies into machine-readable formats, enabling automated enforcement in\nInfrastructure as Code (IaC) environments. However, its adoption is hindered by\nthe complexity of policy languages and the risk of misconfigurations. In this\nwork, we present ARPaCCino, an agentic system that combines Large Language\nModels (LLMs), Retrieval-Augmented-Generation (RAG), and tool-based validation\nto automate the generation and verification of PaC rules. Given natural\nlanguage descriptions of the desired policies, ARPaCCino generates formal Rego\nrules, assesses IaC compliance, and iteratively refines the IaC configurations\nto ensure conformance. Thanks to its modular agentic architecture and\nintegration with external tools and knowledge bases, ARPaCCino supports policy\nvalidation across a wide range of technologies, including niche or emerging IaC\nframeworks. Experimental evaluation involving a Terraform-based case study\ndemonstrates ARPaCCino's effectiveness in generating syntactically and\nsemantically correct policies, identifying non-compliant infrastructures, and\napplying corrective modifications, even when using smaller, open-weight LLMs.\nOur results highlight the potential of agentic RAG architectures to enhance the\nautomation, reliability, and accessibility of PaC workflows.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10584v1", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2409.18858", "title": "Predicting memorization within Large Language Models fine-tuned for classification", "authors": ["Jérémie Dentan", "Davide Buscaldi", "Aymen Shabou", "Sonia Vanier"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      This paper has been accepted for publication at ECAI 2025", "url": "http://arxiv.org/abs/2409.18858v3", "summary": "Large Language Models have received significant attention due to their\nabilities to solve a wide range of complex tasks. However these models memorize\na significant proportion of their training data, posing a serious threat when\ndisclosed at inference time. To mitigate this unintended memorization, it is\ncrucial to understand what elements are memorized and why. This area of\nresearch is largely unexplored, with most existing works providing a posteriori\nexplanations. To address this gap, we propose a new approach to detect\nmemorized samples a priori in LLMs fine-tuned for classification tasks. This\nmethod is effective from the early stages of training and readily adaptable to\nother classification settings, such as training vision models from scratch. Our\nmethod is supported by new theoretical results, and requires a low\ncomputational budget. We achieve strong empirical results, paving the way for\nthe systematic identification and protection of vulnerable samples before they\nare memorized.", "comment": "This paper has been accepted for publication at ECAI 2025", "pdf_url": "http://arxiv.org/pdf/2409.18858v3", "cate": "cs.CR", "date": "2024-09-27", "updated": "2025-07-15"}
{"id": "2507.10991", "title": "Uncertainty Aware Mapping for Vision-Based Underwater Robots", "authors": ["Abhimanyu Bhowmik", "Mohit Singh", "Madhushree Sannigrahi", "Martin Ludvigsen", "Kostas Alexis"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Presented at the 2025 IEEE ICRA Workshop on Field Robotics", "url": "http://arxiv.org/abs/2507.10991v1", "summary": "Vision-based underwater robots can be useful in inspecting and exploring\nconfined spaces where traditional sensors and preplanned paths cannot be\nfollowed. Sensor noise and situational change can cause significant uncertainty\nin environmental representation. Thus, this paper explores how to represent\nmapping inconsistency in vision-based sensing and incorporate depth estimation\nconfidence into the mapping framework. The scene depth and the confidence are\nestimated using the RAFT-Stereo model and are integrated into a voxel-based\nmapping framework, Voxblox. Improvements in the existing Voxblox weight\ncalculation and update mechanism are also proposed. Finally, a qualitative\nanalysis of the proposed method is performed in a confined pool and in a pier\nin the Trondheim fjord. Experiments using an underwater robot demonstrated the\nchange in uncertainty in the visualization.", "comment": "Presented at the 2025 IEEE ICRA Workshop on Field Robotics", "pdf_url": "http://arxiv.org/pdf/2507.10991v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10860", "title": "WhisperKit: On-device Real-time ASR with Billion-Scale Transformers", "authors": ["Atila Orhon", "Arda Okan", "Berkin Durmus", "Zach Nagengast", "Eduardo Pacheco"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      ICML 2025 - On-Device Learning for Foundational Models Workshop", "url": "http://arxiv.org/abs/2507.10860v1", "summary": "Real-time Automatic Speech Recognition (ASR) is a fundamental building block\nfor many commercial applications of ML, including live captioning, dictation,\nmeeting transcriptions, and medical scribes. Accuracy and latency are the most\nimportant factors when companies select a system to deploy. We present\nWhisperKit, an optimized on-device inference system for real-time ASR that\nsignificantly outperforms leading cloud-based systems. We benchmark against\nserver-side systems that deploy a diverse set of models, including a frontier\nmodel (OpenAI gpt-4o-transcribe), a proprietary model (Deepgram nova-3), and an\nopen-source model (Fireworks large-v3-turbo).Our results show that WhisperKit\nmatches the lowest latency at 0.46s while achieving the highest accuracy 2.2%\nWER. The optimizations behind the WhisperKit system are described in detail in\nthis paper.", "comment": "ICML 2025 - On-Device Learning for Foundational Models Workshop", "pdf_url": "http://arxiv.org/pdf/2507.10860v1", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11210", "title": "Role-Playing LLM-Based Multi-Agent Support Framework for Detecting and Addressing Family Communication Bias", "authors": ["Rushia Harada", "Yuken Kimura", "Keito Inoshita"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11210v1", "summary": "Well-being in family settings involves subtle psychological dynamics that\nconventional metrics often overlook. In particular, unconscious parental\nexpectations, termed ideal parent bias, can suppress children's emotional\nexpression and autonomy. This suppression, referred to as suppressed emotion,\noften stems from well-meaning but value-driven communication, which is\ndifficult to detect or address from outside the family. Focusing on these\nlatent dynamics, this study explores Large Language Model (LLM)-based support\nfor psychologically safe family communication. We constructed a Japanese\nparent-child dialogue corpus of 30 scenarios, each annotated with metadata on\nideal parent bias and suppressed emotion. Based on this corpus, we developed a\nRole-Playing LLM-based multi-agent dialogue support framework that analyzes\ndialogue and generates feedback. Specialized agents detect suppressed emotion,\ndescribe implicit ideal parent bias in parental speech, and infer contextual\nattributes such as the child's age and background. A meta-agent compiles these\noutputs into a structured report, which is then passed to five selected expert\nagents. These agents collaboratively generate empathetic and actionable\nfeedback through a structured four-step discussion process. Experiments show\nthat the system can detect categories of suppressed emotion with moderate\naccuracy and produce feedback rated highly in empathy and practicality.\nMoreover, simulated follow-up dialogues incorporating this feedback exhibited\nsigns of improved emotional expression and mutual understanding, suggesting the\nframework's potential in supporting positive transformation in family\ninteractions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11210v1", "cate": "cs.HC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10605", "title": "RedOne: Revealing Domain-specific LLM Post-Training in Social Networking Services", "authors": ["Fei Zhao", "Chonggang Lu", "Yue Wang", "Zheyong Xie", "Ziyan Liu", "Haofu Qian", "JianZhao Huang", "Fangcheng Shi", "Zijie Meng", "Hongcheng Guo", "Mingqian He", "Xinze Lyu", "Yiming Lu", "Ziyang Xiang", "Zheyu Ye", "Chengqiang Lu", "Zhe Xu", "Yi Wu", "Yao Hu", "Yan Gao", "Jun Fan", "Xiaolong Jiang", "Weiting Liu", "Boyang Wang", "Shaosheng Cao"], "categories": ["cs.LG", "cs.AI", "cs.SI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10605v1", "summary": "As a primary medium for modern information dissemination, social networking\nservices (SNS) have experienced rapid growth, which has proposed significant\nchallenges for platform content management and interaction quality improvement.\nRecently, the development of large language models (LLMs) has offered potential\nsolutions but existing studies focus on isolated tasks, which not only\nencounter diminishing benefit from the data scaling within individual scenarios\nbut also fail to flexibly adapt to diverse real-world context. To address these\nchallenges, we introduce RedOne, a domain-specific LLM designed to break the\nperformance bottleneck of single-task baselines and establish a comprehensive\nfoundation for the SNS. RedOne was developed through a three-stage training\nstrategy consisting of continue pretraining, supervised fine-tuning, and\npreference optimization, using a large-scale real-world dataset. Through\nextensive experiments, RedOne maintains strong general capabilities, and\nachieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56%\nin SNS bilingual evaluation benchmark, compared with base models. Furthermore,\nthrough online testing, RedOne reduced the exposure rate in harmful content\ndetection by 11.23% and improved the click page rate in post-view search by\n14.95% compared with single-tasks finetuned baseline models. These results\nestablish RedOne as a robust domain-specific LLM for SNS, demonstrating\nexcellent generalization across various tasks and promising applicability in\nreal-world scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10605v1", "cate": "cs.LG", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.10775", "title": "A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers", "authors": ["Jeffrey Joan Sam", "Janhavi Sathe", "Nikhil Chigali", "Naman Gupta", "Radhey Ruparel", "Yicheng Jiang", "Janmajay Singh", "James W. Berck", "Arko Barman"], "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10775v1", "summary": "Spacecraft deployed in outer space are routinely subjected to various forms\nof damage due to exposure to hazardous environments. In addition, there are\nsignificant risks to the subsequent process of in-space repairs through human\nextravehicular activity or robotic manipulation, incurring substantial\noperational costs. Recent developments in image segmentation could enable the\ndevelopment of reliable and cost-effective autonomous inspection systems. While\nthese models often require large amounts of training data to achieve\nsatisfactory results, publicly available annotated spacecraft segmentation data\nare very scarce. Here, we present a new dataset of nearly 64k annotated\nspacecraft images that was created using real spacecraft models, superimposed\non a mixture of real and synthetic backgrounds generated using NASA's TTALOS\npipeline. To mimic camera distortions and noise in real-world image\nacquisition, we also added different types of noise and distortion to the\nimages. Finally, we finetuned YOLOv8 and YOLOv11 segmentation models to\ngenerate performance benchmarks for the dataset under well-defined hardware and\ninference time constraints to mimic real-world image segmentation challenges\nfor real-time onboard applications in space on NASA's inspector spacecraft. The\nresulting models, when tested under these constraints, achieved a Dice score of\n0.92, Hausdorff distance of 0.69, and an inference time of about 0.5 second.\nThe dataset and models for performance benchmark are available at\nhttps://github.com/RiceD2KLab/SWiM.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10775v1", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10590", "title": "Repairing Language Model Pipelines by Meta Self-Refining Competing Constraints at Runtime", "authors": ["Mojtaba Eshghie"], "categories": ["cs.SE", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10590v1", "summary": "Language Model (LM) pipelines can dynamically refine their outputs against\nprogrammatic constraints. However, their effectiveness collapses when faced\nwith competing soft constraints, leading to inefficient backtracking loops\nwhere satisfying one constraint violates another. We introduce Meta\nSelf-Refining, a framework that equips LM pipelines with a meta-corrective\nlayer to repair these competitions at runtime/inference-time. Our approach\nmonitors the pipeline's execution history to detect oscillatory failures. Upon\ndetection, it invokes a meta-repairer LM that analyzes the holistic state of\nthe backtracking attempts and synthesizes a strategic instruction to balance\nthe competing requirements. This self-repair instruction guides the original LM\nout of a failing refining loop towards a successful output. Our results show\nMeta Self-Refining can successfully repair these loops, leading to more\nefficient LM programs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10590v1", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.10570", "title": "Local Clustering in Hypergraphs through Higher-Order Motifs", "authors": ["Giuseppe F. Italiano", "Athanasios L. Konstantinidis", "Anna Mpanti", "Fariba Ranjbar"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10570v1", "summary": "Hypergraphs provide a powerful framework for modeling complex systems and\nnetworks with higher-order interactions beyond simple pairwise relationships.\nHowever, graph-based clustering approaches, which focus primarily on pairwise\nrelations, fail to represent higher-order interactions, often resulting in\nlow-quality clustering outcomes. In this work, we introduce a novel approach\nfor local clustering in hypergraphs based on higher-order motifs, small\nconnected subgraphs in which nodes may be linked by interactions of any order,\nextending motif-based techniques previously applied to standard graphs. Our\nmethod exploits hypergraph-specific higher-order motifs to better characterize\nlocal structures and optimize motif conductance. We propose two alternative\nstrategies for identifying local clusters around a seed hyperedge: a core-based\nmethod utilizing hypergraph core decomposition and a BFS-based method based on\nbreadth-first exploration. We construct an auxiliary hypergraph to facilitate\nefficient partitioning and introduce a framework for local motif-based\nclustering. Extensive experiments on real-world datasets demonstrate the\neffectiveness of our framework and provide a comparative analysis of the two\nproposed clustering strategies in terms of clustering quality and computational\nefficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10570v1", "cate": "cs.SI", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2501.07149", "title": "Pantomime: Motion Data Anonymization using Foundation Motion Models", "authors": ["Simon Hanisch", "Julian Todt", "Thorsten Strufe"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.07149v2", "summary": "Human motion is a behavioral biometric trait that can be used to identify\nindividuals and infer private attributes such as medical conditions. This poses\na serious threat to privacy as motion extraction from video and motion capture\nare increasingly used for a variety of applications, including mixed reality,\nrobotics, medicine, and the quantified self. In order to protect the privacy of\nthe tracked individuals, anonymization techniques that preserve the utility of\nthe data are required. However, anonymizing motion data is a challenging task\nbecause there are many dependencies in motion sequences (such as physiological\nconstraints) that, if ignored, make the anonymized motion sequence appear\nunnatural. In this paper, we propose Pantomime, a full-body anonymization\ntechnique for motion data, which uses foundation motion models to generate\nmotion sequences that adhere to the dependencies in the data, thus keeping the\nutility of the anonymized data high. Our results show that Pantomime can\nmaintain the naturalness of the motion sequences while reducing the\nidentification accuracy to 10%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.07149v2", "cate": "cs.CR", "date": "2025-01-13", "updated": "2025-07-15"}
{"id": "2507.11000", "title": "ILCL: Inverse Logic-Constraint Learning from Temporally Constrained Demonstrations", "authors": ["Minwoo Cho", "Jaehwi Jang", "Daehyung Park"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures", "url": "http://arxiv.org/abs/2507.11000v1", "summary": "We aim to solve the problem of temporal-constraint learning from\ndemonstrations to reproduce demonstration-like logic-constrained behaviors.\nLearning logic constraints is challenging due to the combinatorially large\nspace of possible specifications and the ill-posed nature of non-Markovian\nconstraints. To figure it out, we introduce a novel temporal-constraint\nlearning method, which we call inverse logic-constraint learning (ILCL). Our\nmethod frames ICL as a two-player zero-sum game between 1) a genetic\nalgorithm-based temporal-logic mining (GA-TL-Mining) and 2) logic-constrained\nreinforcement learning (Logic-CRL). GA-TL-Mining efficiently constructs syntax\ntrees for parameterized truncated linear temporal logic (TLTL) without\npredefined templates. Subsequently, Logic-CRL finds a policy that maximizes\ntask rewards under the constructed TLTL constraints via a novel constraint\nredistribution scheme. Our evaluations show ILCL outperforms state-of-the-art\nbaselines in learning and transferring TL constraints on four temporally\nconstrained tasks. We also demonstrate successful transfer to real-world\npeg-in-shallow-hole tasks.", "comment": "8 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.11000v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10894", "title": "NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization", "authors": ["Zongtao He", "Liuyi Wang", "Lu Chen", "Chengju Liu", "Qijun Chen"], "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10894v1", "summary": "Language-guided navigation is a cornerstone of embodied AI, enabling agents\nto interpret language instructions and navigate complex environments. However,\nexpert-provided instructions are limited in quantity, while synthesized\nannotations often lack quality, making them insufficient for large-scale\nresearch. To address this, we propose NavComposer, a novel framework for\nautomatically generating high-quality navigation instructions. NavComposer\nexplicitly decomposes semantic entities such as actions, scenes, and objects,\nand recomposes them into natural language instructions. Its modular\narchitecture allows flexible integration of state-of-the-art techniques, while\nthe explicit use of semantic entities enhances both the richness and accuracy\nof instructions. Moreover, it operates in a data-agnostic manner, supporting\nadaptation to diverse navigation trajectories without domain-specific training.\nComplementing NavComposer, we introduce NavInstrCritic, a comprehensive\nannotation-free evaluation system that assesses navigation instructions on\nthree dimensions: contrastive matching, semantic consistency, and linguistic\ndiversity. NavInstrCritic provides a holistic evaluation of instruction\nquality, addressing limitations of traditional metrics that rely heavily on\nexpert annotations. By decoupling instruction generation and evaluation from\nspecific navigation agents, our method enables more scalable and generalizable\nresearch. Extensive experiments provide direct and practical evidence for the\neffectiveness of our method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10894v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11470", "title": "REVA: Supporting LLM-Generated Programming Feedback Validation at Scale Through User Attention-based Adaptation", "authors": ["Xiaohang Tang", "Sam Wong", "Zicheng He", "Yalong Yang", "Yan Chen"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11470v1", "summary": "This paper introduces REVA, a human-AI system that expedites instructor\nreview of voluminous AI-generated programming feedback by sequencing\nsubmissions to minimize cognitive context shifts and propagating\ninstructor-driven revisions across semantically similar instances. REVA\nintroduces a novel approach to human-AI collaboration in educational feedback\nby adaptively learning from instructors' attention in the review and revision\nprocess to continuously improve the feedback validation process. REVA's\nusefulness and effectiveness in improving feedback quality and the overall\nfeedback review process were evaluated through a within-subjects lab study with\n12 participants.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11470v1", "cate": "cs.HC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10606", "title": "DALI-PD: Diffusion-based Synthetic Layout Heatmap Generation for ML in Physical Design", "authors": ["Bing-Yue Wu", "Vidya A. Chhabria"], "categories": ["cs.LG", "cs.AI", "cs.AR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Under review at Asia and South Pacific Design Automation Conference (ASP-DAC'26)", "url": "http://arxiv.org/abs/2507.10606v1", "summary": "Machine learning (ML) has demonstrated significant promise in various\nphysical design (PD) tasks. However, model generalizability remains limited by\nthe availability of high-quality, large-scale training datasets. Creating such\ndatasets is often computationally expensive and constrained by IP. While very\nfew public datasets are available, they are typically static, slow to generate,\nand require frequent updates. To address these limitations, we present DALI-PD,\na scalable framework for generating synthetic layout heatmaps to accelerate ML\nin PD research. DALI-PD uses a diffusion model to generate diverse layout\nheatmaps via fast inference in seconds. The heatmaps include power, IR drop,\ncongestion, macro placement, and cell density maps. Using DALI-PD, we created a\ndataset comprising over 20,000 layout configurations with varying macro counts\nand placements. These heatmaps closely resemble real layouts and improve ML\naccuracy on downstream ML tasks such as IR drop or congestion prediction.", "comment": "Under review at Asia and South Pacific Design Automation Conference\n  (ASP-DAC'26)", "pdf_url": "http://arxiv.org/pdf/2507.10606v1", "cate": "cs.LG", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.10778", "title": "Warehouse Spatial Question Answering with LLM Agent", "authors": ["Hsiang-Wei Huang", "Jen-Hao Cheng", "Kuang-Ming Chen", "Cheng-Yen Yang", "Bahaa Alattar", "Yi-Ru Lin", "Pyongkun Kim", "Sangwon Kim", "Kwangju Kim", "Chung-I Huang", "Jenq-Neng Hwang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      1st Place Solution of the 9th AI City Challenge Track 3", "url": "http://arxiv.org/abs/2507.10778v1", "summary": "Spatial understanding has been a challenging task for existing Multi-modal\nLarge Language Models~(MLLMs). Previous methods leverage large-scale MLLM\nfinetuning to enhance MLLM's spatial understanding ability. In this paper, we\npresent a data-efficient approach. We propose a LLM agent system with strong\nand advanced spatial reasoning ability, which can be used to solve the\nchallenging spatial question answering task in complex indoor warehouse\nscenarios. Our system integrates multiple tools that allow the LLM agent to\nconduct spatial reasoning and API tools interaction to answer the given\ncomplicated spatial question. Extensive evaluations on the 2025 AI City\nChallenge Physical AI Spatial Intelligence Warehouse dataset demonstrate that\nour system achieves high accuracy and efficiency in tasks such as object\nretrieval, counting, and distance estimation. The code is available at:\nhttps://github.com/hsiangwei0903/SpatialAgent", "comment": "1st Place Solution of the 9th AI City Challenge Track 3", "pdf_url": "http://arxiv.org/pdf/2507.10778v1", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10593", "title": "ToolRegistry: A Protocol-Agnostic Tool Management Library for Function-Calling LLMs", "authors": ["Peng Ding"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10593v1", "summary": "Large Language Model (LLM) applications are increasingly relying on external\ntools to extend their capabilities beyond text generation. However, current\ntool integration approaches suffer from fragmentation, protocol limitations,\nand implementation complexity, leading to substantial development overhead.\nThis paper presents Toolregistry, a protocol-agnostic tool management library\nthat simplifies tool registration, representation, execution, and lifecycle\nmanagement via a unified interface. Our evaluation demonstrates that\n\\toolregistry achieves 60-80% reduction in tool integration code, up to 3.1x\nperformance improvements through concurrent execution, and 100% compatibility\nwith OpenAI function calling standards. Real-world case studies show\nsignificant improvements in development efficiency and code maintainability\nacross diverse integration scenarios. \\toolregistry is open-source and\navailable at https://github.com/Oaklight/ToolRegistry, with comprehensive\ndocumentation at https://toolregistry.readthedocs.io/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10593v1", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.10608", "title": "The Shape of Deceit: Behavioral Consistency and Fragility in Money Laundering Patterns", "authors": ["Danny Butvinik", "Ofir Yakobi", "Michal Einhorn Cohen", "Elina Maliarsky"], "categories": ["cs.SI", "cs.LG", "stat.AP"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10608v1", "summary": "Conventional anti-money laundering (AML) systems predominantly focus on\nidentifying anomalous entities or transactions, flagging them for manual\ninvestigation based on statistical deviation or suspicious behavior. This\nparadigm, however, misconstrues the true nature of money laundering, which is\nrarely anomalous but often deliberate, repeated, and concealed within\nconsistent behavioral routines. In this paper, we challenge the entity-centric\napproach and propose a network-theoretic perspective that emphasizes detecting\npredefined laundering patterns across directed transaction networks. We\nintroduce the notion of behavioral consistency as the core trait of laundering\nactivity, and argue that such patterns are better captured through subgraph\nstructures expressing semantic and functional roles - not solely geometry.\nCrucially, we explore the concept of pattern fragility: the sensitivity of\nlaundering patterns to small attribute changes and, conversely, their semantic\nrobustness even under drastic topological transformations. We claim that\nlaundering detection should not hinge on statistical outliers, but on\npreservation of behavioral essence, and propose a reconceptualization of\npattern similarity grounded in this insight. This philosophical and practical\nshift has implications for how AML systems model, scan, and interpret networks\nin the fight against financial crime.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10608v1", "cate": "cs.SI", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2502.05209", "title": "Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities", "authors": ["Zora Che", "Stephen Casper", "Robert Kirk", "Anirudh Satheesh", "Stewart Slocum", "Lev E McKinney", "Rohit Gandikota", "Aidan Ewart", "Domenic Rosati", "Zichu Wu", "Zikui Cai", "Bilal Chughtai", "Yarin Gal", "Furong Huang", "Dylan Hadfield-Menell"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted to TMLR", "url": "http://arxiv.org/abs/2502.05209v3", "summary": "Evaluations of large language model (LLM) risks and capabilities are\nincreasingly being incorporated into AI risk management and governance\nframeworks. Currently, most risk evaluations are conducted by designing inputs\nthat elicit harmful behaviors from the system. However, this approach suffers\nfrom two limitations. First, input-output evaluations cannot fully evaluate\nrealistic risks from open-weight models. Second, the behaviors identified\nduring any particular input-output evaluation can only lower-bound the model's\nworst-possible-case input-output behavior. As a complementary method for\neliciting harmful behaviors, we propose evaluating LLMs with model tampering\nattacks which allow for modifications to latent activations or weights. We pit\nstate-of-the-art techniques for removing harmful LLM capabilities against a\nsuite of 5 input-space and 6 model tampering attacks. In addition to\nbenchmarking these methods against each other, we show that (1) model\nresilience to capability elicitation attacks lies on a low-dimensional\nrobustness subspace; (2) the success rate of model tampering attacks can\nempirically predict and offer conservative estimates for the success of\nheld-out input-space attacks; and (3) state-of-the-art unlearning methods can\neasily be undone within 16 steps of fine-tuning. Together, these results\nhighlight the difficulty of suppressing harmful LLM capabilities and show that\nmodel tampering attacks enable substantially more rigorous evaluations than\ninput-space attacks alone.", "comment": "Accepted to TMLR", "pdf_url": "http://arxiv.org/pdf/2502.05209v3", "cate": "cs.CR", "date": "2025-02-03", "updated": "2025-07-14"}
{"id": "2507.11001", "title": "Learning to Tune Like an Expert: Interpretable and Scene-Aware Navigation via MLLM Reasoning and CVAE-Based Adaptation", "authors": ["Yanbo Wang", "Zipeng Fang", "Lei Zhao", "Weidong Chen"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11001v1", "summary": "Service robots are increasingly deployed in diverse and dynamic environments,\nwhere both physical layouts and social contexts change over time and across\nlocations. In these unstructured settings, conventional navigation systems that\nrely on fixed parameters often fail to generalize across scenarios, resulting\nin degraded performance and reduced social acceptance. Although recent\napproaches have leveraged reinforcement learning to enhance traditional\nplanners, these methods often fail in real-world deployments due to poor\ngeneralization and limited simulation diversity, which hampers effective\nsim-to-real transfer. To tackle these issues, we present LE-Nav, an\ninterpretable and scene-aware navigation framework that leverages multi-modal\nlarge language model reasoning and conditional variational autoencoders to\nadaptively tune planner hyperparameters. To achieve zero-shot scene\nunderstanding, we utilize one-shot exemplars and chain-of-thought prompting\nstrategies. Additionally, a conditional variational autoencoder captures the\nmapping between natural language instructions and navigation hyperparameters,\nenabling expert-level tuning. Experiments show that LE-Nav can generate\nhyperparameters achieving human-level tuning across diverse planners and\nscenarios. Real-world navigation trials and a user study on a smart wheelchair\nplatform demonstrate that it outperforms state-of-the-art methods on\nquantitative metrics such as success rate, efficiency, safety, and comfort,\nwhile receiving higher subjective scores for perceived safety and social\nacceptance. Code is available at https://github.com/Cavendish518/LE-Nav.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11001v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10911", "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "authors": ["Yicong Wu", "Ting Chen", "Irit Hochberg", "Zhoujian Sun", "Ruth Edry", "Zhengxing Huang", "Mor Peleg"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10911v1", "summary": "Therapy recommendation for chronic patients with multimorbidity is\nchallenging due to risks of treatment conflicts. Existing decision support\nsystems face scalability limitations. Inspired by the way in which general\npractitioners (GP) manage multimorbidity patients, occasionally convening\nmultidisciplinary team (MDT) collaboration, this study investigated the\nfeasibility and value of using a Large Language Model (LLM)-based multi-agent\nsystem (MAS) for safer therapy recommendations. We designed a single agent and\na MAS framework simulating MDT decision-making by enabling discussion among LLM\nagents to resolve medical conflicts. The systems were evaluated on therapy\nplanning tasks for multimorbidity patients using benchmark cases. We compared\nMAS performance with single-agent approaches and real-world benchmarks. An\nimportant contribution of our study is the definition of evaluation metrics\nthat go beyond the technical precision and recall and allow the inspection of\nclinical goals met and medication burden of the proposed advices to a gold\nstandard benchmark. Our results show that with current LLMs, a single agent GP\nperforms as well as MDTs. The best-scoring models provide correct\nrecommendations that address all clinical goals, yet the advices are\nincomplete. Some models also present unnecessary medications, resulting in\nunnecessary conflicts between medication and conditions or drug-drug\ninteractions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10911v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11490", "title": "Towards Creating Infrastructures for Values and Ethics Work in the Production of Software Technologies", "authors": ["Richmond Y. Wong"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      In The sixth decennial Aarhus conference: Computing X Crisis (AAR 2025)", "url": "http://arxiv.org/abs/2507.11490v1", "summary": "Recognizing how technical systems can embody social values or cause harms,\nhuman-computer interaction (HCI) research often approaches addressing values\nand ethics in design by creating tools to help tech workers integrate social\nvalues into the design of products. While useful, these approaches usually do\nnot consider the politics embedded in the broader processes, organizations,\nsocial systems, and governance structures that affect the types of actions that\ntech workers can take to address values and ethics. This paper argues that\ncreating infrastructures to support values and ethics work, rather than tools,\nis an approach that takes these broader processes into account and opens them\nup for (re)design. Drawing on prior research conceptualizing infrastructures\nfrom science \\& technology studies and media studies, this paper outlines\nconceptual insights from infrastructures studies that open up new tactics for\nHCI researchers and designers seeking to support values and ethics in design.", "comment": "In The sixth decennial Aarhus conference: Computing X Crisis (AAR\n  2025)", "pdf_url": "http://arxiv.org/pdf/2507.11490v1", "cate": "cs.HC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10609", "title": "A Feed-Forward Artificial Intelligence Pipeline for Sustainable Desalination under Climate Uncertainties: UAE Insights", "authors": ["Obumneme Nwafor", "Chioma Nwafor", "Amro Zakaria", "Nkechi Nwankwo"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10609v1", "summary": "The United Arab Emirates (UAE) relies heavily on seawater desalination to\nmeet over 90% of its drinking water needs. Desalination processes are highly\nenergy intensive and account for approximately 15% of the UAE's electricity\nconsumption, contributing to over 22% of the country's energy-related CO2\nemissions. Moreover, these processes face significant sustainability challenges\nin the face of climate uncertainties such as rising seawater temperatures,\nsalinity, and aerosol optical depth (AOD). AOD greatly affects the operational\nand economic performance of solar-powered desalination systems through\nphotovoltaic soiling, membrane fouling, and water turbidity cycles.\n  This study proposes a novel pipelined two-stage predictive modelling\narchitecture: the first stage forecasts AOD using satellite-derived time series\nand meteorological data; the second stage uses the predicted AOD and other\nmeteorological factors to predict desalination performance efficiency losses.\nThe framework achieved 98% accuracy, and SHAP (SHapley Additive exPlanations)\nwas used to reveal key drivers of system degradation. Furthermore, this study\nproposes a dust-aware rule-based control logic for desalination systems based\non predicted values of AOD and solar efficiency. This control logic is used to\nadjust the desalination plant feed water pressure, adapt maintenance\nscheduling, and regulate energy source switching.\n  To enhance the practical utility of the research findings, the predictive\nmodels and rule-based controls were packaged into an interactive dashboard for\nscenario and predictive analytics. This provides a management decision-support\nsystem for climate-adaptive planning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10609v1", "cate": "cs.LG", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.10800", "title": "ThinkingViT: Matryoshka Thinking Vision Transformer for Elastic Inference", "authors": ["Ali Hojjat", "Janek Haberer", "Soren Pirk", "Olaf Landsiedel"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Under Review", "url": "http://arxiv.org/abs/2507.10800v1", "summary": "Vision Transformers deliver state-of-the-art performance, yet their fixed\ncomputational budget prevents scalable deployment across heterogeneous\nhardware. Recent nested Transformer architectures mitigate this by embedding\nnested subnetworks within a single model to enable scalable inference. However,\nthese models allocate the same amount of compute to all inputs, regardless of\ntheir complexity, which leads to inefficiencies. To address this, we introduce\nThinkingViT, a nested ViT architecture that employs progressive thinking stages\nto dynamically adjust inference computation based on input difficulty.\nThinkingViT initiates inference by activating a small subset of the most\nimportant attention heads and terminates early if predictions reach sufficient\ncertainty. Otherwise, it activates additional attention heads and re-evaluates\nthe input. At the core of ThinkingViT is our Token Recycling mechanism, which\nconditions each subsequent inference stage on the embeddings from the previous\nstage, enabling progressive improvement. Due to its backbone-preserving design,\nThinkingViT also serves as a plugin upgrade for vanilla ViT. Experiments show\nthat ThinkingViT surpasses nested baselines by up to 2.0 percentage points\n(p.p.) in accuracy at the same throughput and by up to 2.9 p.p. at equal GMACs\non ImageNet-1K. The source code is available at\nhttps://github.com/ds-kiel/ThinkingViT.", "comment": "Under Review", "pdf_url": "http://arxiv.org/pdf/2507.10800v1", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10640", "title": "SENSOR: An ML-Enhanced Online Annotation Tool to Uncover Privacy Concerns from User Reviews in Social-Media Applications", "authors": ["Labiba Farah", "Mohammad Ridwan Kabir", "Shohel Ahmed", "MD Mohaymen Ul Anam", "Md. Sakibul Islam"], "categories": ["cs.SE", "cs.LG", "D.2.2"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      26 pages, 9 figures, 5 tables", "url": "http://arxiv.org/abs/2507.10640v1", "summary": "The widespread use of social media applications has raised significant\nprivacy concerns, often highlighted in user reviews. These reviews also provide\ndevelopers with valuable insights into improving apps by addressing issues and\nintroducing better features. However, the sheer volume and nuanced nature of\nreviews make manual identification and prioritization of privacy-related\nconcerns challenging for developers. Previous studies have developed software\nutilities to automatically classify user reviews as privacy-relevant,\nprivacy-irrelevant, bug reports, feature requests, etc., using machine\nlearning. Notably, there is a lack of focus on classifying reviews specifically\nas privacy-related feature requests, privacy-related bug reports, or\nprivacy-irrelevant. This paper introduces SENtinel SORt (SENSOR), an automated\nonline annotation tool designed to help developers annotate and classify user\nreviews into these categories. For automating the annotation of such reviews,\nthis paper introduces the annotation model, GRACE (GRU-based Attention with\nCBOW Embedding), using Gated Recurrent Units (GRU) with Continuous Bag of Words\n(CBOW) and Attention mechanism. Approximately 16000 user reviews from seven\npopular social media apps on Google Play Store, including Instagram, Facebook,\nWhatsApp, Snapchat, X (formerly Twitter), Facebook Lite, and Line were\nanalyzed. Two annotators manually labelled the reviews, achieving a Cohen's\nKappa value of 0.87, ensuring a labeled dataset with high inter-rater agreement\nfor training machine learning models. Among the models tested, GRACE\ndemonstrated the best performance (macro F1-score: 0.9434, macro ROC-AUC:\n0.9934, and accuracy: 95.10%) despite class imbalance. SENSOR demonstrates\nsignificant potential to assist developers with extracting and addressing\nprivacy-related feature requests or bug reports from user reviews, enhancing\nuser privacy and trust.", "comment": "26 pages, 9 figures, 5 tables", "pdf_url": "http://arxiv.org/pdf/2507.10640v1", "cate": "cs.SE", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10795", "title": "Multilayer Artificial Benchmark for Community Detection (mABCD)", "authors": ["Łukasz Kraiński", "Michał Czuba", "Piotr Bródka", "Paweł Prałat", "Bogumił Kamiński", "François Théberge"], "categories": ["cs.SI", "cs.LG"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      28 pages, 15 figures, 7 tables", "url": "http://arxiv.org/abs/2507.10795v1", "summary": "The Artificial Benchmark for Community Detection (ABCD) model is a random\ngraph model with community structure and power-law distribution for both\ndegrees and community sizes. The model generates graphs similar to the\nwell-known LFR model but it is faster, more interpretable, and can be\ninvestigated analytically. In this paper, we use the underlying ingredients of\nthe ABCD model and introduce its variant for multilayer networks, mABCD.", "comment": "28 pages, 15 figures, 7 tables", "pdf_url": "http://arxiv.org/pdf/2507.10795v1", "cate": "cs.SI", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10903", "title": "LiLM-RDB-SFC: Lightweight Language Model with Relational Database-Guided DRL for Optimized SFC Provisioning", "authors": ["Parisa Fard Moshiri", "Xinyu Zhu", "Poonam Lohan", "Burak Kantarci", "Emil Janulewicz"], "categories": ["cs.NI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      9 pages, 6 figures, Accepted to IEEE 16th International Conference on Network of the Future (NoF) 2025", "url": "http://arxiv.org/abs/2507.10903v1", "summary": "Effective management of Service Function Chains (SFCs) and optimal Virtual\nNetwork Function (VNF) placement are critical challenges in modern\nSoftware-Defined Networking (SDN) and Network Function Virtualization (NFV)\nenvironments. Although Deep Reinforcement Learning (DRL) is widely adopted for\ndynamic network decision-making, its inherent dependency on structured data and\nfixed action rules often limits adaptability and responsiveness, particularly\nunder unpredictable network conditions. This paper introduces LiLM-RDB-SFC, a\nnovel approach combining Lightweight Language Model (LiLM) with Relational\nDatabase (RDB) to answer network state queries to guide DRL model for efficient\nSFC provisioning. Our proposed approach leverages two LiLMs, Bidirectional and\nAuto-Regressive Transformers (BART) and the Fine-tuned Language Net T5\n(FLAN-T5), to interpret network data and support diverse query types related to\nSFC demands, data center resources, and VNF availability. Results demonstrate\nthat FLAN-T5 outperforms BART with a lower test loss (0.00161 compared to\n0.00734), higher accuracy (94.79% compared to 80.2%), and less processing time\n(2h 2min compared to 2h 38min). Moreover, when compared to the large language\nmodel SQLCoder, FLAN-T5 matches the accuracy of SQLCoder while cutting\nprocessing time by 96% (SQLCoder: 54 h 43 min; FLAN-T5: 2 h 2 min).", "comment": "9 pages, 6 figures, Accepted to IEEE 16th International Conference on\n  Network of the Future (NoF) 2025", "pdf_url": "http://arxiv.org/pdf/2507.10903v1", "cate": "cs.NI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2504.00563", "title": "Adaptive Federated Learning with Functional Encryption: A Comparison of Classical and Quantum-safe Options", "authors": ["Enrico Sorbera", "Federica Zanetti", "Giacomo Brandi", "Alessandro Tomasi", "Roberto Doriguzzi-Corin", "Silvio Ranise"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.00563v2", "summary": "Federated Learning (FL) is a collaborative method for training machine\nlearning models while preserving the confidentiality of the participants'\ntraining data. Nevertheless, FL is vulnerable to reconstruction attacks that\nexploit shared parameters to reveal private training data. In this paper, we\naddress this issue in the cybersecurity domain by applying Multi-Input\nFunctional Encryption (MIFE) to a recent FL implementation for training\nML-based network intrusion detection systems. We assess both classical and\npost-quantum solutions in terms of memory cost and computational overhead in\nthe FL process, highlighting their impact on convergence time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.00563v2", "cate": "cs.CR", "date": "2025-04-01", "updated": "2025-07-15"}
{"id": "2507.11006", "title": "Enhancing Autonomous Manipulator Control with Human-in-loop for Uncertain Assembly Environments", "authors": ["Ashutosh Mishra", "Shreya Santra", "Hazal Gozbasi", "Kentaro Uno", "Kazuya Yoshida"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      6 pages, 7 figures. Manuscript accepted at the 2025 IEEE 21st International Conference on Automation Science and Engineering (CASE 2025)", "url": "http://arxiv.org/abs/2507.11006v1", "summary": "This study presents an advanced approach to enhance robotic manipulation in\nuncertain and challenging environments, with a focus on autonomous operations\naugmented by human-in-the-loop (HITL) control for lunar missions. By\nintegrating human decision-making with autonomous robotic functions, the\nresearch improves task reliability and efficiency for space applications. The\nkey task addressed is the autonomous deployment of flexible solar panels using\nan extendable ladder-like structure and a robotic manipulator with real-time\nfeedback for precision. The manipulator relays position and force-torque data,\nenabling dynamic error detection and adaptive control during deployment. To\nmitigate the effects of sinkage, variable payload, and low-lighting conditions,\nefficient motion planning strategies are employed, supplemented by human\ncontrol that allows operators to intervene in ambiguous scenarios. Digital twin\nsimulation enhances system robustness by enabling continuous feedback,\niterative task refinement, and seamless integration with the deployment\npipeline. The system has been tested to validate its performance in simulated\nlunar conditions and ensure reliability in extreme lighting, variable terrain,\nchanging payloads, and sensor limitations.", "comment": "6 pages, 7 figures. Manuscript accepted at the 2025 IEEE 21st\n  International Conference on Automation Science and Engineering (CASE 2025)", "pdf_url": "http://arxiv.org/pdf/2507.11006v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10923", "title": "Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization", "authors": ["Yuhao Wang", "Keyan Ding", "Kehua Feng", "Zeyuan Wang", "Ming Qin", "Xiaotong Li", "Qiang Zhang", "Huajun Chen"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted at ACL 2025 (Main Conference)", "url": "http://arxiv.org/abs/2507.10923v1", "summary": "Protein language models have emerged as powerful tools for sequence\ngeneration, offering substantial advantages in functional optimization and\ndenovo design. However, these models also present significant risks of\ngenerating harmful protein sequences, such as those that enhance viral\ntransmissibility or evade immune responses. These concerns underscore critical\nbiosafety and ethical challenges. To address these issues, we propose a\nKnowledge-guided Preference Optimization (KPO) framework that integrates prior\nknowledge via a Protein Safety Knowledge Graph. This framework utilizes an\nefficient graph pruning strategy to identify preferred sequences and employs\nreinforcement learning to minimize the risk of generating harmful proteins.\nExperimental results demonstrate that KPO effectively reduces the likelihood of\nproducing hazardous sequences while maintaining high functionality, offering a\nrobust safety assurance framework for applying generative models in\nbiotechnology.", "comment": "Accepted at ACL 2025 (Main Conference)", "pdf_url": "http://arxiv.org/pdf/2507.10923v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10580", "title": "An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation", "authors": ["Vimaleswar A", "Prabhu Nandan Sahu", "Nilesh Kumar Sahu", "Haroon R Lone"], "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10580v1", "summary": "Mental health plays a crucial role in the overall well-being of an\nindividual. In recent years, digital platforms have been increasingly used to\nexpand mental health and emotional support. However, there are persistent\nchallenges related to limited user accessibility, internet connectivity, and\ndata privacy, which highlight the need for an offline, smartphone-based\nsolution. To address these challenges, we propose EmoSApp (Emotional Support\nApp): an entirely offline, smartphone-based conversational app designed for\nmental health and emotional support. The system leverages Large Language Models\n(LLMs), specifically fine-tuned, quantized and deployed using Torchtune and\nExecutorch for resource-constrained devices, allowing all inferences to occur\non the smartphone. To equip EmoSApp with robust domain expertise, we fine-tuned\nthe LLaMA-3.2-1B-Instruct model on our custom curated ``Knowledge dataset'' of\n14,582 mental-health QA pairs, along with the multi-turn conversational data.\n  Through qualitative human evaluation with the student population, we\ndemonstrate that EmoSApp has the ability to respond coherently, empathetically,\nmaintain interactive dialogue, and provide relevant suggestions to user's\nmental health problems. Additionally, quantitative evaluations on nine standard\ncommonsense and reasoning benchmarks demonstrate the efficacy of our\nfine-tuned, quantized model in low-resource settings. By prioritizing on-device\ndeployment and specialized domain adaptation, EmoSApp serves as a blueprint for\nfuture innovations in portable, secure, and highly tailored AI-driven mental\nhealth solutions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10580v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.10611", "title": "FedGSCA: Medical Federated Learning with Global Sample Selector and Client Adaptive Adjuster under Label Noise", "authors": ["Mengwen Ye", "Yingzi Huangfu", "Shujian Gao", "Wei Ren", "Weifan Liu", "Zekuan Yu"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10611v1", "summary": "Federated Learning (FL) emerged as a solution for collaborative medical image\nclassification while preserving data privacy. However, label noise, which\narises from inter-institutional data variability, can cause training\ninstability and degrade model performance. Existing FL methods struggle with\nnoise heterogeneity and the imbalance in medical data. Motivated by these\nchallenges, we propose FedGSCA, a novel framework for enhancing robustness in\nnoisy medical FL. FedGSCA introduces a Global Sample Selector that aggregates\nnoise knowledge from all clients, effectively addressing noise heterogeneity\nand improving global model stability. Furthermore, we develop a Client Adaptive\nAdjustment (CAA) mechanism that combines adaptive threshold pseudo-label\ngeneration and Robust Credal Labeling Loss. CAA dynamically adjusts to class\ndistributions, ensuring the inclusion of minority samples and carefully\nmanaging noisy labels by considering multiple plausible labels. This dual\napproach mitigates the impact of noisy data and prevents overfitting during\nlocal training, which improves the generalizability of the model. We evaluate\nFedGSCA on one real-world colon slides dataset and two synthetic medical\ndatasets under various noise conditions, including symmetric, asymmetric,\nextreme, and heterogeneous types. The results show that FedGSCA outperforms the\nstate-of-the-art methods, excelling in extreme and heterogeneous noise\nscenarios. Moreover, FedGSCA demonstrates significant advantages in improving\nmodel stability and handling complex noise, making it well-suited for\nreal-world medical federated learning scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10611v1", "cate": "cs.LG", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.10844", "title": "LLM-Guided Agentic Object Detection for Open-World Understanding", "authors": ["Furkan Mumcu", "Michael J. Jones", "Anoop Cherian", "Yasin Yilmaz"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10844v1", "summary": "Object detection traditionally relies on fixed category sets, requiring\ncostly re-training to handle novel objects. While Open-World and\nOpen-Vocabulary Object Detection (OWOD and OVOD) improve flexibility, OWOD\nlacks semantic labels for unknowns, and OVOD depends on user prompts, limiting\nautonomy. We propose an LLM-guided agentic object detection (LAOD) framework\nthat enables fully label-free, zero-shot detection by prompting a Large\nLanguage Model (LLM) to generate scene-specific object names. These are passed\nto an open-vocabulary detector for localization, allowing the system to adapt\nits goals dynamically. We introduce two new metrics, Class-Agnostic Average\nPrecision (CAAP) and Semantic Naming Average Precision (SNAP), to separately\nevaluate localization and naming. Experiments on LVIS, COCO, and COCO-OOD\nvalidate our approach, showing strong performance in detecting and naming novel\nobjects. Our method offers enhanced autonomy and adaptability for open-world\nunderstanding.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10844v1", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10641", "title": "A Code Comprehension Benchmark for Large Language Models for Code", "authors": ["Jayant Havare", "Saurav Chaudhary", "Ganesh Ramakrishnan", "Kaushik Maharajan", "Srikanth Tamilselvam"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      10 Pages, 5 Figures", "url": "http://arxiv.org/abs/2507.10641v1", "summary": "Large Language Models have shown impressive capabilities in coding tasks like\ncode generation and code completion, as they have been trained on a large\namount of code data. Also, since one of the core pretraining objectives is Next\nToken Prediction, these models tends to learn surface-level syntactic patterns\nin code. However, this does not guarantee code comprehension ability i.e. the\nability to capture the semantics of the code. In our opinion, this is the\nreason why these models often underperform on tasks that require deeper\nsemantic understanding, such as code debugging and code optimization. To\naddress this, we propose fine-tuning these models specifically for code\ncomprehension tasks using large-scale datasets, enabling them to develop a more\nrobust understanding of code semantics. We evaluate three code models of\nvarying sizes on a suite of code comprehension tasks designed to assess\nsemantic understanding beyond surface-level syntactic pattern matching. In\nparticular, we analyze performance on the Subjectivity Grading Task and observe\nthat model performance improves after fine-tuning on relevant downstream tasks.\nThe most significant improvement is seen in the QWQ-32B model, where accuracy\nincreases from 70% to 83.47%. A similar or explainable trend is observed across\nother models, clearly indicating an enhancement in code comprehension ability.\nAmong the models studied, the DPO-fine-tuned Codestral-22B achieves the highest\nmicro-accuracy of 87.66% on the Subjectivity Grading Task.", "comment": "10 Pages, 5 Figures", "pdf_url": "http://arxiv.org/pdf/2507.10641v1", "cate": "cs.SE", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10936", "title": "Toxicity in State Sponsored Information Operations", "authors": ["Ashfaq Ali Shafin", "Khandaker Mamun Ahmed"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      Accepted at 36th ACM Conference on Hypertext and Social Media (HT '25), September 15-18, 2025, Chicago, IL. 4 pages, 3 figures, 1 table", "url": "http://arxiv.org/abs/2507.10936v1", "summary": "State-sponsored information operations (IOs) increasingly influence global\ndiscourse on social media platforms, yet their emotional and rhetorical\nstrategies remain inadequately characterized in scientific literature. This\nstudy presents the first comprehensive analysis of toxic language deployment\nwithin such campaigns, examining 56 million posts from over 42 thousand\naccounts linked to 18 distinct geopolitical entities on X/Twitter. Using\nGoogle's Perspective API, we systematically detect and quantify six categories\nof toxic content and analyze their distribution across national origins,\nlinguistic structures, and engagement metrics, providing essential information\nregarding the underlying patterns of such operations. Our findings reveal that\nwhile toxic content constitutes only 1.53% of all posts, they are associated\nwith disproportionately high engagement and appear to be strategically deployed\nin specific geopolitical contexts. Notably, toxic content originating from\nRussian influence operations receives significantly higher user engagement\ncompared to influence operations from any other country in our dataset. Our\ncode is available at https://github.com/shafin191/Toxic_IO.", "comment": "Accepted at 36th ACM Conference on Hypertext and Social Media (HT\n  '25), September 15-18, 2025, Chicago, IL. 4 pages, 3 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.10936v1", "cate": "cs.SI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10928", "title": "Arcturus: A Cloud Overlay Network for Global Accelerator with Enhanced Performance and Stability", "authors": ["Matthew Yang Liu", "Chuang Chen", "Pengcheng Lv", "Hui Guo", "Yanan Zhang", "Cong Wang", "Yusen Li", "Zhenyu Li", "Yu-Chu Tian"], "categories": ["cs.NI", "cs.DC"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10928v1", "summary": "Global Accelerator (GA) services play a vital role in ensuring low-latency,\nhigh-reliability communication for real-time interactive applications. However,\nexisting GA offerings are tightly bound to specific cloud providers, resulting\nin high costs, rigid deployment, and limited flexibility, especially for\nlarge-scale or budget-sensitive deployments. Arcturus is a cloud-native GA\nframework that revisits the design of GA systems by leveraging low-cost,\nheterogeneous cloud resources across multiple providers. Rather than relying on\nfixed, high-end infrastructure, Arcturus dynamically constructs its\nacceleration network and balances performance, stability, and resource\nefficiency. To achieve this, Arcturus introduces a two-plane design: a\nforwarding plane that builds a proxy network with adaptive control, and a\nscheduling plane that coordinates load and routing through lightweight,\nquantitative optimization. Evaluations under millions of RPS show that Arcturus\noutperforms commercial GA services by up to 1.7X in acceleration performance,\nreduces cost by 71%, and maintains over 80% resource efficiency--demonstrating\nefficient use of cloud resources at scale.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10928v1", "cate": "cs.NI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2504.07414", "title": "Decomposition-Based Optimal Bounds for Privacy Amplification via Shuffling", "authors": ["Pengcheng Su", "Haibo Cheng", "Ping Wang"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.07414v5", "summary": "Shuffling has been shown to amplify differential privacy guarantees, enabling\na more favorable privacy-utility trade-off. To characterize and compute this\namplification, two fundamental analytical frameworks have been proposed: the\n\\emph{privacy blanket} by Balle et al. (CRYPTO 2019) and the\n\\emph{clone}--including both the standard and stronger variant--by Feldman et\nal. (FOCS 2021, SODA 2023). These frameworks share a common foundation:\ndecomposing local randomizers into structured components for analysis.\n  In this work, we introduce a unified analytical framework--the general clone\nparadigm--which subsumes all possible decompositions, with the clone and\nblanket decompositions arising as special cases. Within this framework, we\nidentify the optimal decomposition, which is precisely the one used by the\nprivacy blanket. Moreover, we develop a simple and efficient algorithm based on\nthe Fast Fourier Transform (FFT) to compute optimal privacy amplification\nbounds. Experimental results show that our computed upper bounds nearly match\nthe lower bounds, demonstrating the tightness of our method. Building on this\nmethod, we also derive optimal amplification bounds for both \\emph{joint} and\n\\emph{parallel} compositions of LDP mechanisms in the shuffle model.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.07414v5", "cate": "cs.CR", "date": "2025-04-10", "updated": "2025-07-15"}
{"id": "2507.11069", "title": "TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update", "authors": ["Jeongyun Kim", "Seunghoon Jeong", "Giseop Kim", "Myung-Hwan Jeon", "Eunji Jun", "Ayoung Kim"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11069v1", "summary": "Understanding the 3D geometry of transparent objects from RGB images is\nchallenging due to their inherent physical properties, such as reflection and\nrefraction. To address these difficulties, especially in scenarios with sparse\nviews and dynamic environments, we introduce TRAN-D, a novel 2D Gaussian\nSplatting-based depth reconstruction method for transparent objects. Our key\ninsight lies in separating transparent objects from the background, enabling\nfocused optimization of Gaussians corresponding to the object. We mitigate\nartifacts with an object-aware loss that places Gaussians in obscured regions,\nensuring coverage of invisible surfaces while reducing overfitting.\nFurthermore, we incorporate a physics-based simulation that refines the\nreconstruction in just a few seconds, effectively handling object removal and\nchain-reaction movement of remaining objects without the need for rescanning.\nTRAN-D is evaluated on both synthetic and real-world sequences, and it\nconsistently demonstrated robust improvements over existing GS-based\nstate-of-the-art methods. In comparison with baselines, TRAN-D reduces the mean\nabsolute error by over 39% for the synthetic TRansPose sequences. Furthermore,\ndespite being updated using only one image, TRAN-D reaches a {\\delta} < 2.5 cm\naccuracy of 48.46%, over 1.5 times that of baselines, which uses six images.\nCode and more results are available at https://jeongyun0609.github.io/TRAN-D/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11069v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10993", "title": "Modeling Habitat Shifts: Integrating Convolutional Neural Networks and Tabular Data for Species Migration Prediction", "authors": ["Emir Durakovic", "Min-Hong Shih"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      This paper uses a lightly modified version of the AAAI 2025 LaTeX style for formatting consistency. It is not a submission to AAAI and does not include any AAAI-specific headers, footers, or metadata", "url": "http://arxiv.org/abs/2507.10993v1", "summary": "Due to climate-induced changes, many habitats are experiencing range shifts\naway from their traditional geographic locations (Piguet, 2011). We propose a\nsolution to accurately model whether bird species are present in a specific\nhabitat through the combination of Convolutional Neural Networks (CNNs)\n(O'Shea, 2015) and tabular data. Our approach makes use of satellite imagery\nand environmental features (e.g., temperature, precipitation, elevation) to\npredict bird presence across various climates. The CNN model captures spatial\ncharacteristics of landscapes such as forestation, water bodies, and\nurbanization, whereas the tabular method uses ecological and geographic data.\nBoth systems predict the distribution of birds with an average accuracy of 85%,\noffering a scalable but reliable method to understand bird migration.", "comment": "This paper uses a lightly modified version of the AAAI 2025 LaTeX\n  style for formatting consistency. It is not a submission to AAAI and does not\n  include any AAAI-specific headers, footers, or metadata", "pdf_url": "http://arxiv.org/pdf/2507.10993v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10827", "title": "Supporting SENĆOTEN Language Documentation Efforts with Automatic Speech Recognition", "authors": ["Mengzhe Geng", "Patrick Littell", "Aidan Pine", "PENÁĆ", "Marc Tessier", "Roland Kuhn"], "categories": ["cs.SD", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted by ComputEL-8", "url": "http://arxiv.org/abs/2507.10827v1", "summary": "The SEN\\'{C}OTEN language, spoken on the Saanich peninsula of southern\nVancouver Island, is in the midst of vigorous language revitalization efforts\nto turn the tide of language loss as a result of colonial language policies. To\nsupport these on-the-ground efforts, the community is turning to digital\ntechnology. Automatic Speech Recognition (ASR) technology holds great promise\nfor accelerating language documentation and the creation of educational\nresources. However, developing ASR systems for SEN\\'{C}OTEN is challenging due\nto limited data and significant vocabulary variation from its polysynthetic\nstructure and stress-driven metathesis. To address these challenges, we propose\nan ASR-driven documentation pipeline that leverages augmented speech data from\na text-to-speech (TTS) system and cross-lingual transfer learning with Speech\nFoundation Models (SFMs). An n-gram language model is also incorporated via\nshallow fusion or n-best restoring to maximize the use of available data.\nExperiments on the SEN\\'{C}OTEN dataset show a word error rate (WER) of 19.34%\nand a character error rate (CER) of 5.09% on the test set with a 57.02%\nout-of-vocabulary (OOV) rate. After filtering minor cedilla-related errors, WER\nimproves to 14.32% (26.48% on unseen words) and CER to 3.45%, demonstrating the\npotential of our ASR-driven pipeline to support SEN\\'{C}OTEN language\ndocumentation.", "comment": "Accepted by ComputEL-8", "pdf_url": "http://arxiv.org/pdf/2507.10827v1", "cate": "cs.SD", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10613", "title": "Sub-Scaling Laws: On the Role of Data Density and Training Strategies in LLMs", "authors": ["Zhengyu Chen", "Siqi Wang", "Teng Xiao", "Yudong Wang", "Shiqi Chen", "Xunliang Cai", "Junxian He", "Jingang Wang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10613v1", "summary": "Traditional scaling laws in natural language processing suggest that\nincreasing model size and training data enhances performance. However, recent\nstudies reveal deviations, particularly in large language models, where\nperformance improvements decelerate, which is a phenomenon known as\nsub-scaling. This paper revisits these scaling laws by examining the impact of\ndata quality and training strategies on model performance. Through extensive\nempirical analysis of over 400 models, we identify high data density and\nnon-optimal resource allocation as key factors contributing to sub-scaling.\nHigh data density leads to diminishing returns due to redundant information,\nwhile optimal resource allocation is crucial for sustained performance\nimprovements. We propose a sub-optimal scaling law that better predicts\nperformance in sub-scaling regimes, highlighting the importance of data quality\nand diversity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10613v1", "cate": "cs.LG", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.10846", "title": "Winsor-CAM: Human-Tunable Visual Explanations from Deep Networks via Layer-Wise Winsorization", "authors": ["Casey Wall", "Longwei Wang", "Rodrigue Rizk", "KC Santosh"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      15 pages, 10 figures, 7 tables. Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence", "url": "http://arxiv.org/abs/2507.10846v1", "summary": "Interpreting the decision-making process of Convolutional Neural Networks\n(CNNs) is critical for deploying models in high-stakes domains.\nGradient-weighted Class Activation Mapping (Grad-CAM) is a widely used method\nfor visual explanations, yet it typically focuses on the final convolutional\nlayer or na\\\"ively averages across layers, strategies that can obscure\nimportant semantic cues or amplify irrelevant noise. We propose Winsor-CAM, a\nnovel, human-tunable extension of Grad-CAM that generates robust and coherent\nsaliency maps by aggregating information across all convolutional layers. To\nmitigate the influence of noisy or extreme attribution values, Winsor-CAM\napplies Winsorization, a percentile-based outlier attenuation technique. A\nuser-controllable threshold allows for semantic-level tuning, enabling flexible\nexploration of model behavior across representational hierarchies. Evaluations\non standard architectures (ResNet50, DenseNet121, VGG16, InceptionV3) using the\nPASCAL VOC 2012 dataset demonstrate that Winsor-CAM produces more interpretable\nheatmaps and achieves superior performance in localization metrics, including\nintersection-over-union and center-of-mass alignment, when compared to Grad-CAM\nand uniform layer-averaging baselines. Winsor-CAM advances the goal of\ntrustworthy AI by offering interpretable, multi-layer insights with\nhuman-in-the-loop control.", "comment": "15 pages, 10 figures, 7 tables. Submitted to IEEE Transactions on\n  Pattern Analysis and Machine Intelligence", "pdf_url": "http://arxiv.org/pdf/2507.10846v1", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10646", "title": "CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based Code Assistance", "authors": ["Myeongsoo Kim", "Shweta Garg", "Baishakhi Ray", "Varun Kumar", "Anoop Deoras"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10646v1", "summary": "Programming assistants powered by large language models have transformed\nsoftware development, yet most benchmarks focus narrowly on code generation\ntasks. Recent efforts like InfiBench and StackEval attempt to address this gap\nusing Stack Overflow data but remain limited to single-turn interactions in\nisolated contexts, require significant manual curation, and fail to represent\ncomplete project environments. We introduce CodeAssistBench (CAB), the first\nbenchmark framework for evaluating multi-turn programming assistance in\nrealistic settings that address real-world questions about actual codebases.\nUnlike existing programming Q&A benchmarks, CAB automatically generates\nscalable datasets from question-related GitHub issues using configurable\nparameters (e.g., repository creation date, star count, programming languages),\nand includes automatic containerization of codebases for evaluation. It then\nevaluates models through simulated users in these containerized environments\nwith full codebase access. Using this framework, we constructed a test set of\n3,286 real-world programming questions across 231 repositories, spanning seven\nprogramming languages and diverse problem domains. Our evaluation of leading\nLLMs reveals a substantial capability gap: while models perform well on Stack\nOverflow questions with success rates of 70-83%, they resolve only up to 16.49%\nof CAB's recent issues. This discrepancy highlights the challenges of providing\nassistance in complex, project-specific contexts versus answering standalone\nquestions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10646v1", "cate": "cs.SE", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11057", "title": "Urban delineation through the lens of commute networks: Leveraging graph embeddings to distinguish socioeconomic groups in cities", "authors": ["Devashish Khulbe", "Stanislav Sobolevsky"], "categories": ["cs.SI", "stat.ML"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11057v1", "summary": "Delineating areas within metropolitan regions stands as an important focus\namong urban researchers, shedding light on the urban perimeters shaped by\nevolving population dynamics. Applications to urban science are numerous, from\nfacilitating comparisons between delineated districts and administrative\ndivisions to informing policymakers of the shifting economic and labor\nlandscapes. In this study, we propose using commute networks sourced from the\ncensus for the purpose of urban delineation, by modeling them with a Graph\nNeural Network (GNN) architecture. We derive low-dimensional representations of\ngranular urban areas (nodes) using GNNs. Subsequently, nodes' embeddings are\nclustered to identify spatially cohesive communities in urban areas. Our\nexperiments across the U.S. demonstrate the effectiveness of network embeddings\nin capturing significant socioeconomic disparities between communities in\nvarious cities, particularly in factors such as median household income. The\nrole of census mobility data in regional delineation is also noted, and we\nestablish the utility of GNNs in urban community detection, as a powerful\nalternative to existing methods in this domain. The results offer insights into\nthe wider effects of commute networks and their use in building meaningful\nrepresentations of urban regions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11057v1", "cate": "cs.SI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11014", "title": "SIMCODE: A Benchmark for Natural Language to ns-3 Network Simulation Code Generation", "authors": ["Tasnim Ahmed", "Mirza Mohammad Azwad", "Salimur Choudhury"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      This paper has been accepted for presentation at the 50th IEEE Conference on Local Computer Networks (LCN) - special track on Large Language Models and Networking", "url": "http://arxiv.org/abs/2507.11014v1", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\ncode generation across various domains. However, their effectiveness in\ngenerating simulation scripts for domain-specific environments like ns-3\nremains underexplored. Despite the growing interest in automating network\nsimulations, existing tools primarily focus on interactive automation over\nrigorous evaluation. To facilitate systematic evaluation, we introduce SIMCODE,\nthe first benchmark to evaluate LLMs' ability to generate ns-3 simulation code\nfrom natural language. SIMCODE includes 400 tasks across introductory,\nintermediate, and advanced levels, with solutions and test cases. Using\nSIMCODE, we evaluate three prominent LLMs, Gemini-2.0, GPT-4.1, and Qwen-3,\nacross six prompt techniques. Furthermore, investigating task-specific\nfine-tuning's impact reveals that while GPT-4.1 outperforms others, execution\naccuracy remains modest, with substantial room for improvement. Error analysis\nidentifies missing headers and API mismatches as dominant failures.\nNevertheless, SIMCODE provides a foundational step toward evaluating LLMs and\nresearch in domain-aware generative systems.", "comment": "This paper has been accepted for presentation at the 50th IEEE\n  Conference on Local Computer Networks (LCN) - special track on Large Language\n  Models and Networking", "pdf_url": "http://arxiv.org/pdf/2507.11014v1", "cate": "cs.NI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2505.23847", "title": "Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems", "authors": ["Ronny Ko", "Jiseong Jeong", "Shuyuan Zheng", "Chuan Xiao", "Tae-Wan Kim", "Makoto Onizuka", "Won-Yong Shin"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.23847v3", "summary": "Large language models (LLMs) are rapidly evolving into autonomous agents that\ncooperate across organizational boundaries, enabling joint disaster response,\nsupply-chain optimization, and other tasks that demand decentralized expertise\nwithout surrendering data ownership. Yet, cross-domain collaboration shatters\nthe unified trust assumptions behind current alignment and containment\ntechniques. An agent benign in isolation may, when receiving messages from an\nuntrusted peer, leak secrets or violate policy, producing risks driven by\nemergent multi-agent dynamics rather than classical software bugs. This\nposition paper maps the security agenda for cross-domain multi-agent LLM\nsystems. We introduce seven categories of novel security challenges, for each\nof which we also present plausible attacks, security evaluation metrics, and\nfuture research guidelines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.23847v3", "cate": "cs.CR", "date": "2025-05-28", "updated": "2025-07-15"}
{"id": "2507.11076", "title": "Closed Form Time Derivatives of the Equations of Motion of Rigid Body Systems", "authors": ["Andreas Mueller", "Shivesh Kumar"], "categories": ["cs.RO", "cs.NA", "math.DG", "math.DS", "math.GR", "math.NA"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11076v1", "summary": "Derivatives of equations of motion(EOM) describing the dynamics of rigid body\nsystems are becoming increasingly relevant for the robotics community and find\nmany applications in design and control of robotic systems. Controlling robots,\nand multibody systems comprising elastic components in particular, not only\nrequires smooth trajectories but also the time derivatives of the control\nforces/torques, hence of the EOM. This paper presents the time derivatives of\nthe EOM in closed form up to second-order as an alternative formulation to the\nexisting recursive algorithms for this purpose, which provides a direct insight\ninto the structure of the derivatives. The Lie group formulation for rigid body\nsystems is used giving rise to very compact and easily parameterized equations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11076v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11060", "title": "Personalized Exercise Recommendation with Semantically-Grounded Knowledge Tracing", "authors": ["Yilmazcan Ozyurt", "Tunaberk Almaci", "Stefan Feuerriegel", "Mrinmaya Sachan"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11060v1", "summary": "We introduce ExRec, a general framework for personalized exercise\nrecommendation with semantically-grounded knowledge tracing. Our method builds\non the observation that existing exercise recommendation approaches simulate\nstudent performance via knowledge tracing (KT) but they often overlook two key\naspects: (a) the semantic content of questions and (b) the sequential,\nstructured progression of student learning. To address this, our ExRec presents\nan end-to-end pipeline, from annotating the KCs of questions and learning their\nsemantic representations to training KT models and optimizing several\nreinforcement learning (RL) methods. Moreover, we improve standard\nQ-learning-based continuous RL methods via a tailored model-based value\nestimation (MVE) approach that directly leverages the components of KT model in\nestimating cumulative knowledge improvement. We validate the effectiveness of\nour ExRec using various RL methods across four real-world tasks with different\neducational goals in online math learning. We further show that ExRec\ngeneralizes robustly to new, unseen questions and that it produces\ninterpretable student learning trajectories. Together, our findings highlight\nthe promise of KT-guided RL for effective personalization in education.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11060v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10859", "title": "MultiVox: Benchmarking Voice Assistants for Multimodal Interactions", "authors": ["Ramaneswaran Selvakumar", "Ashish Seth", "Nishit Anand", "Utkarsh Tyagi", "Sonal Kumar", "Sreyan Ghosh", "Dinesh Manocha"], "categories": ["cs.MM", "cs.CL", "cs.HC"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "Comments:      Work In Progress", "url": "http://arxiv.org/abs/2507.10859v1", "summary": "The rapid progress of Large Language Models (LLMs) has empowered omni models\nto act as voice assistants capable of understanding spoken dialogues. These\nmodels can process multimodal inputs beyond text, such as speech and visual\ndata, enabling more context-aware interactions. However, current benchmarks\nfall short in comprehensively evaluating how well these models generate\ncontext-aware responses, particularly when it comes to implicitly understanding\nfine-grained speech characteristics, such as pitch, emotion, timbre, and volume\nor the environmental acoustic context such as background sounds. Additionally,\nthey inadequately assess the ability of models to align paralinguistic cues\nwith complementary visual signals to inform their responses. To address these\ngaps, we introduce MultiVox, the first omni voice assistant benchmark designed\nto evaluate the ability of voice assistants to integrate spoken and visual cues\nincluding paralinguistic speech features for truly multimodal understanding.\nSpecifically, MultiVox includes 1000 human-annotated and recorded speech\ndialogues that encompass diverse paralinguistic features and a range of visual\ncues such as images and videos. Our evaluation on 9 state-of-the-art models\nreveals that, although humans excel at these tasks, current models consistently\nstruggle to produce contextually grounded responses.", "comment": "Work In Progress", "pdf_url": "http://arxiv.org/pdf/2507.10859v1", "cate": "cs.MM", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10614", "title": "Fine-tuning Large Language Model for Automated Algorithm Design", "authors": ["Fei Liu", "Rui Zhang", "Xi Lin", "Zhichao Lu", "Qingfu Zhang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10614v1", "summary": "The integration of large language models (LLMs) into automated algorithm\ndesign has shown promising potential. A prevalent approach embeds LLMs within\nsearch routines to iteratively generate and refine candidate algorithms.\nHowever, most existing methods rely on off-the-shelf LLMs trained for general\ncoding tasks,leaving a key question open: Do we need LLMs specifically tailored\nfor algorithm design? If so, how can such LLMs be effectively obtained and how\nwell can they generalize across different algorithm design tasks? In this\npaper, we take a first step toward answering these questions by exploring\nfine-tuning of LLMs for algorithm design. We introduce a Diversity-Aware Rank\nbased (DAR) sampling strategy to balance training data diversity and quality,\nthen we leverage direct preference optimization to efficiently align LLM\noutputs with task objectives. Our experiments, conducted on\nLlama-3.2-1B-Instruct and Llama- 3.1-8B-Instruct, span three distinct algorithm\ndesign tasks. Results suggest that finetuned LLMs can significantly outperform\ntheir off-the-shelf counterparts with the smaller Llama-3.2-1B-Instruct and\nmatch the larger Llama-3.1-8B-Instruct on the admissible set problem. Moreover,\nwe observe promising generalization: LLMs finetuned on specific algorithm\ndesign tasks also improve performance on related tasks with varying settings.\nThese findings highlight the value of task-specific adaptation for LLMs in\nalgorithm design and open new avenues for future research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10614v1", "cate": "cs.LG", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.10855", "title": "Sparse Fine-Tuning of Transformers for Generative Tasks", "authors": ["Wei Chen", "Jingxi Yu", "Zichen Miao", "Qiang Qiu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by International Conference on Computer Vision 2025", "url": "http://arxiv.org/abs/2507.10855v1", "summary": "Large pre-trained transformers have revolutionized artificial intelligence\nacross various domains, and fine-tuning remains the dominant approach for\nadapting these models to downstream tasks due to the cost of training from\nscratch. However, in existing fine-tuning methods, the updated representations\nare formed as a dense combination of modified parameters, making it challenging\nto interpret their contributions and understand how the model adapts to new\ntasks. In this work, we introduce a fine-tuning framework inspired by sparse\ncoding, where fine-tuned features are represented as a sparse combination of\nbasic elements, i.e., feature dictionary atoms. The feature dictionary atoms\nfunction as fundamental building blocks of the representation, and tuning atoms\nallows for seamless adaptation to downstream tasks. Sparse coefficients then\nserve as indicators of atom importance, identifying the contribution of each\natom to the updated representation. Leveraging the atom selection capability of\nsparse coefficients, we first demonstrate that our method enhances image\nediting performance by improving text alignment through the removal of\nunimportant feature dictionary atoms. Additionally, we validate the\neffectiveness of our approach in the text-to-image concept customization task,\nwhere our method efficiently constructs the target concept using a sparse\ncombination of feature dictionary atoms, outperforming various baseline\nfine-tuning methods.", "comment": "Accepted by International Conference on Computer Vision 2025", "pdf_url": "http://arxiv.org/pdf/2507.10855v1", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10729", "title": "Toward Realistic Evaluations of Just-In-Time Vulnerability Prediction", "authors": ["Duong Nguyen", "Thanh Le-Cong", "Triet Huynh Minh Le", "M. Ali Babar", "Quyet-Thang Huynh"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10729v1", "summary": "Modern software systems are increasingly complex, presenting significant\nchallenges in quality assurance. Just-in-time vulnerability prediction (JIT-VP)\nis a proactive approach to identifying vulnerable commits and providing early\nwarnings about potential security risks. However, we observe that current\nJIT-VP evaluations rely on an idealized setting, where the evaluation datasets\nare artificially balanced, consisting exclusively of vulnerability-introducing\nand vulnerability-fixing commits.\n  To address this limitation, this study assesses the effectiveness of JIT-VP\ntechniques under a more realistic setting that includes both\nvulnerability-related and vulnerability-neutral commits. To enable a reliable\nevaluation, we introduce a large-scale public dataset comprising over one\nmillion commits from FFmpeg and the Linux kernel. Our empirical analysis of\neight state-of-the-art JIT-VP techniques reveals a significant decline in\npredictive performance when applied to real-world conditions; for example, the\naverage PR-AUC on Linux drops 98\\% from 0.805 to 0.016. This discrepancy is\nmainly attributed to the severe class imbalance in real-world datasets, where\nvulnerability-introducing commits constitute only a small fraction of all\ncommits.\n  To mitigate this issue, we explore the effectiveness of widely adopted\ntechniques for handling dataset imbalance, including customized loss functions,\noversampling, and undersampling. Surprisingly, our experimental results\nindicate that these techniques are ineffective in addressing the imbalance\nproblem in JIT-VP. These findings underscore the importance of realistic\nevaluations of JIT-VP and the need for domain-specific techniques to address\ndata imbalance in such scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10729v1", "cate": "cs.SE", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11090", "title": "Enhance Stability of Network by Edge Anchor", "authors": ["Hongbo Qiu", "Renjie Sun", "Chen chen", "Xiaoyang Wang"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11090v1", "summary": "With the rapid growth of online social networks, strengthening their\nstability has emerged as a key research focus. This study aims to identify\ninfluential relationships that significantly impact community stability. In\nthis paper, we introduce and explore the anchor trussness reinforcement problem\nto reinforce the overall user engagement of networks by anchoring some edges.\nSpecifically, for a given graph $G$ and a budget $b$, we aim to identify $b$\nedges whose anchoring maximizes the trussness gain, which is the cumulative\nincrement of trussness across all edges in $G$. We establish the NP-hardness of\nthe problem. To address this problem, we introduce a greedy framework that\niteratively selects the current best edge. To scale for larger networks, we\nfirst propose an upward-route method to constrain potential trussness increment\nedges. Augmented with a support check strategy, this approach enables the\nefficient computation of the trussness gain for anchoring one edge. Then, we\ndesign a classification tree structure to minimize redundant computations in\neach iteration by organizing edges based on their trussness. We conduct\nextensive experiments on 8 real-world networks to validate the efficiency and\neffectiveness of the proposed model and methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11090v1", "cate": "cs.SI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11038", "title": "Graph-based Fingerprint Update Using Unlabelled WiFi Signals", "authors": ["Ka Ho Chiu", "Handi Yin", "Weipeng Zhuo", "Chul-Ho Lee", "S. -H. Gary Chan"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      Published in Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Volume 9, Issue 1, Article No. 3, Pages 1 - 26", "url": "http://arxiv.org/abs/2507.11038v1", "summary": "WiFi received signal strength (RSS) environment evolves over time due to\nmovement of access points (APs), AP power adjustment, installation and removal\nof APs, etc. We study how to effectively update an existing database of\nfingerprints, defined as the RSS values of APs at designated locations, using a\nbatch of newly collected unlabelled (possibly crowdsourced) WiFi signals. Prior\nart either estimates the locations of the new signals without updating the\nexisting fingerprints or filters out the new APs without sufficiently embracing\ntheir features. To address that, we propose GUFU, a novel effective graph-based\napproach to update WiFi fingerprints using unlabelled signals with possibly new\nAPs. Based on the observation that similar signal vectors likely imply physical\nproximity, GUFU employs a graph neural network (GNN) and a link prediction\nalgorithm to retrain an incremental network given the new signals and APs.\nAfter the retraining, it then updates the signal vectors at the designated\nlocations. Through extensive experiments in four large representative sites,\nGUFU is shown to achieve remarkably higher fingerprint adaptivity as compared\nwith other state-of-the-art approaches, with error reduction of 21.4% and 29.8%\nin RSS values and location prediction, respectively.", "comment": "Published in Proceedings of the ACM on Interactive, Mobile, Wearable\n  and Ubiquitous Technologies, Volume 9, Issue 1, Article No. 3, Pages 1 - 26", "pdf_url": "http://arxiv.org/pdf/2507.11038v1", "cate": "cs.NI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2506.09719", "title": "On the Virtues of Information Security in the UK Climate Movement", "authors": ["Mikaela Brough", "Rikke Bjerg Jensen", "Martin R. Albrecht"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      To appear at the USENIX Security Symposium 2025", "url": "http://arxiv.org/abs/2506.09719v2", "summary": "We report on an ethnographic study with members of the climate movement in\nthe United Kingdom (UK). We conducted participant observation and interviews at\nprotests and in various activist settings. Reporting on the findings as they\nrelate to information security, we show that members of the UK climate movement\nwrestled with (i) a fundamental tension between openness and secrecy; (ii)\ntensions between autonomy and collective interdependence in\ninformation-security decision-making; (iii) conflicting activist ideals that\nshape security discourses; and (iv) pressures from different social gazes --\nfrom each other, from people outside the movement and from their adversaries.\nOverall, our findings shed light on the social complexities of\ninformation-security research in activist settings and provoke methodological\nquestions about programmes that aim to design for activists.", "comment": "To appear at the USENIX Security Symposium 2025", "pdf_url": "http://arxiv.org/pdf/2506.09719v2", "cate": "cs.CR", "date": "2025-06-11", "updated": "2025-07-15"}
{"id": "2507.11133", "title": "Force-Based Viscosity and Elasticity Measurements for Material Biomechanical Characterisation with a Collaborative Robotic Arm", "authors": ["Luca Beber", "Edoardo Lamon", "Giacomo Moretti", "Matteo Saveriano", "Luca Fambri", "Luigi Palopoli", "Daniele Fontanelli"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11133v1", "summary": "Diagnostic activities, such as ultrasound scans and palpation, are relatively\nlow-cost. They play a crucial role in the early detection of health problems\nand in assessing their progression. However, they are also error-prone\nactivities, which require highly skilled medical staff. The use of robotic\nsolutions can be key to decreasing the inherent subjectivity of the results and\nreducing the waiting list. For a robot to perform palpation or ultrasound\nscans, it must effectively manage physical interactions with the human body,\nwhich greatly benefits from precise estimation of the patient's tissue\nbiomechanical properties. This paper assesses the accuracy and precision of a\nrobotic system in estimating the viscoelastic parameters of various materials,\nincluding some tests on ex vivo tissues as a preliminary proof-of-concept\ndemonstration of the method's applicability to biological samples. The\nmeasurements are compared against a ground truth derived from silicone\nspecimens with different viscoelastic properties, characterised using a\nhigh-precision instrument. Experimental results show that the robotic system's\naccuracy closely matches the ground truth, increasing confidence in the\npotential use of robots for such clinical applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11133v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11079", "title": "Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander", "authors": ["Li Wang", "Qizhen Wu", "Lei Chen"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11079v1", "summary": "In multiple unmanned ground vehicle confrontations, autonomously evolving\nmulti-agent tactical decisions from situational awareness remain a significant\nchallenge. Traditional handcraft rule-based methods become vulnerable in the\ncomplicated and transient battlefield environment, and current reinforcement\nlearning methods mainly focus on action manipulation instead of strategic\ndecisions due to lack of interpretability. Here, we propose a vision-language\nmodel-based commander to address the issue of intelligent\nperception-to-decision reasoning in autonomous confrontations. Our method\nintegrates a vision language model for scene understanding and a lightweight\nlarge language model for strategic reasoning, achieving unified perception and\ndecision within a shared semantic space, with strong adaptability and\ninterpretability. Unlike rule-based search and reinforcement learning methods,\nthe combination of the two modules establishes a full-chain process, reflecting\nthe cognitive process of human commanders. Simulation and ablation experiments\nvalidate that the proposed approach achieves a win rate of over 80% compared\nwith baseline models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11079v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10883", "title": "Developing and evaluating quilts for the depiction of large layered graphs", "authors": ["Juhee Bae", "Benjamin Watson"], "categories": ["cs.GR", "cs.HC"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10883v1", "summary": "Traditional layered graph depictions such as flow charts are in wide use. Yet\nas graphs grow more complex, these depictions can become difficult to\nunderstand. Quilts are matrix-based depictions for layered graphs designed to\naddress this problem. In this research, we first improve Quilts by developing\nthree design alternatives, and then compare the best of these alternatives to\nbetter-known node-link and matrix depictions. A primary weakness in Quilts is\ntheir depiction of skip links, links that do not simply connect to a succeeding\nlayer. Therefore in our first study, we compare Quilts using color-only,\ntext-only, and mixed (color and text) skip link depictions, finding that path\nfinding with the color-only depiction is significantly slower and less\naccurate, and that in certain cases, the mixed depiction offers an advantage\nover the text-only depiction. In our second study, we compare Quilts using the\nmixed depiction to node-link diagrams and centered matrices. Overall results\nshow that users can find paths through graphs significantly faster with Quilts\n(46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams.\nThis speed advantage is still greater in large graphs (e.g. in 200 node graphs,\n55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10883v1", "cate": "cs.GR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10616", "title": "Scalpel vs. Hammer: GRPO Amplifies Existing Capabilities, SFT Replaces Them", "authors": ["Neel Rajani", "Aryo Pradipta Gema", "Seraphina Goldfarb-Tarrant", "Ivan Titov"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10616v1", "summary": "Training large language models (LLMs) for reasoning via maths and code\ndatasets has become a major new focus in LLM post-training. Two particularly\npopular approaches are reinforcement learning (RL) and supervised fine-tuning\n(SFT), but their training dynamics are poorly understood. We present a\ncomparative analysis of RL and SFT on the same maths problems with the same\nmodel and similar hyperparameters. We find that RL yields minor in-domain gains\non maths and slight degradation on knowledge-intensive benchmarks like MMLU,\nwhile both trends are more pronounced in SFT. We also analyse model parameters\nacross checkpoints, observing that both algorithms modify query and key weights\nthe most. Meanwhile, SFT exhibits greater updates and also affects mid-layer\nMLPs more, leading us to hypothesise that this may have caused the\nout-of-domain degradation. We therefore investigate whether freezing parts of\nthe model during training can mitigate the reduced performance on\nknowledge-intensive benchmarks. However, our results are inconclusive, with\nbenefits on GPQA:Diamond and degradation on other benchmarks. Taken together,\nour observations provide a preliminary indication for why RL amplifies existing\ncapabilities, while SFT replaces old skills with new ones.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10616v1", "cate": "cs.LG", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.10864", "title": "A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n", "authors": ["Saadat Behzadi", "Danial Sharifrazi", "Bita Mesbahzadeh", "Javad Hassannataj Joloudarid", "Roohallah Alizadehsani"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10864v1", "summary": "Objectives: Timely and accurate detection of colorectal polyps plays a\ncrucial role in diagnosing and preventing colorectal cancer, a major cause of\nmortality worldwide. This study introduces a new, lightweight, and efficient\nframework for polyp detection that combines the Local Outlier Factor (LOF)\nalgorithm for filtering noisy data with the YOLO-v11n deep learning model.\n  Study design: An experimental study leveraging deep learning and outlier\nremoval techniques across multiple public datasets.\n  Methods: The proposed approach was tested on five diverse and publicly\navailable datasets: CVC-ColonDB, CVC-ClinicDB, Kvasir-SEG, ETIS, and EndoScene.\nSince these datasets originally lacked bounding box annotations, we converted\ntheir segmentation masks into suitable detection labels. To enhance the\nrobustness and generalizability of our model, we apply 5-fold cross-validation\nand remove anomalous samples using the LOF method configured with 30 neighbors\nand a contamination ratio of 5%. Cleaned data are then fed into YOLO-v11n, a\nfast and resource-efficient object detection architecture optimized for\nreal-time applications. We train the model using a combination of modern\naugmentation strategies to improve detection accuracy under diverse conditions.\n  Results: Our approach significantly improves polyp localization performance,\nachieving a precision of 95.83%, recall of 91.85%, F1-score of 93.48%, mAP@0.5\nof 96.48%, and mAP@0.5:0.95 of 77.75%. Compared to previous YOLO-based methods,\nour model demonstrates enhanced accuracy and efficiency.\n  Conclusions: These results suggest that the proposed method is well-suited\nfor real-time colonoscopy support in clinical settings. Overall, the study\nunderscores how crucial data preprocessing and model efficiency are when\ndesigning effective AI systems for medical imaging.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10864v1", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10753", "title": "GenAI-Enabled Backlog Grooming in Agile Software Projects: An Empirical Study", "authors": ["Kasper Lien Oftebro", "Anh Nguyen-Duc", "Kai-Kristian Kemell"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10753v1", "summary": "Effective backlog management is critical for ensuring that development teams\nremain aligned with evolving requirements and stakeholder expectations.\nHowever, as product backlogs consistently grow in scale and complexity, they\ntend to become cluttered with redundant, outdated, or poorly defined tasks,\ncomplicating prioritization and decision making processes. This study\ninvestigates whether a generative-AI (GenAI) assistant can automate backlog\ngrooming in Agile software projects without sacrificing accuracy or\ntransparency. Through Design Science cycles, we developed a Jira plug-in that\nembeds backlog issues with the vector database, detects duplicates via cosine\nsimilarity, and leverage the GPT-4o model to propose merges, deletions, or new\nissues. We found that AI-assisted backlog grooming achieved 100 percent\nprecision while reducing the time-to-completion by 45 percent. The findings\ndemonstrated the tool's potential to streamline backlog refinement processes\nwhile improving user experiences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10753v1", "cate": "cs.SE", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10810", "title": "Testing Hypotheses from the Social Approval Theory of Online Hate: An Analysis of 110 Million Posts from Parler", "authors": ["David M. Markowitz", "Samuel Hardman Taylor"], "categories": ["cs.CL", "cs.SI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10810v1", "summary": "In this paper, we explored how online hate is motivated by receiving social\napproval from others. We specifically examined two central tenets of Walther's\n(2024) social approval theory of online hate: (H1a) more signals of social\napproval on hate messages predicts more subsequent hate messages, and (H1b) as\nsocial approval increases, hate speech messages become more extreme. Using over\n110 million posts from Parler (2018-2021), we observed that the number of\nupvotes a person received on a hate speech post was unassociated with the\namount of hate speech in their next post and posts during the next week, month,\nthree months, and six months. Between-person effects revealed an average\nnegative relationship between social approval and hate speech production at the\npost level, but this relationship was mixed at other time intervals. Social\napproval reinforcement mechanisms of online hate may operate differently on\nniche social media platforms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10810v1", "cate": "cs.CL", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11168", "title": "Improving Wi-Fi Network Performance Prediction with Deep Learning Models", "authors": ["Gabriele Formis", "Amanda Ericson", "Stefan Forsstrom", "Kyi Thar", "Gianluca Cena", "Stefano Scanzio"], "categories": ["cs.NI", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      preprint accepted, 8 pages, 2025", "url": "http://arxiv.org/abs/2507.11168v1", "summary": "The increasing need for robustness, reliability, and determinism in wireless\nnetworks for industrial and mission-critical applications is the driver for the\ngrowth of new innovative methods. The study presented in this work makes use of\nmachine learning techniques to predict channel quality in a Wi-Fi network in\nterms of the frame delivery ratio. Predictions can be used proactively to\nadjust communication parameters at runtime and optimize network operations for\nindustrial applications. Methods including convolutional neural networks and\nlong short-term memory were analyzed on datasets acquired from a real Wi-Fi\nsetup across multiple channels. The models were compared in terms of prediction\naccuracy and computational complexity. Results show that the frame delivery\nratio can be reliably predicted, and convolutional neural networks, although\nslightly less effective than other models, are more efficient in terms of CPU\nusage and memory consumption. This enhances the model's usability on embedded\nand industrial systems.", "comment": "preprint accepted, 8 pages, 2025", "pdf_url": "http://arxiv.org/pdf/2507.11168v1", "cate": "cs.NI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2506.15842", "title": "A Sea of Cyber Threats: Maritime Cybersecurity from the Perspective of Mariners", "authors": ["Anna Raymaker", "Akshaya Kumar", "Miuyin Yong Wong", "Ryan Pickren", "Animesh Chhotaray", "Frank Li", "Saman Zonouz", "Raheem Beyah"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      18 pages, 2 figures, To appear in the Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security (CCS '25)", "url": "http://arxiv.org/abs/2506.15842v2", "summary": "Maritime systems, including ships and ports, are critical components of\nglobal infrastructure, essential for transporting over 80% of the world's goods\nand supporting internet connectivity. However, these systems face growing\ncybersecurity threats, as shown by recent attacks disrupting Maersk, one of the\nworld's largest shipping companies, causing widespread impacts on international\ntrade. The unique challenges of the maritime environment--such as diverse\noperational conditions, extensive physical access points, fragmented regulatory\nframeworks, and its deeply interconnected structure--require maritime-specific\ncybersecurity research. Despite the sector's importance, maritime cybersecurity\nremains underexplored, leaving significant gaps in understanding its challenges\nand risks.\n  To address these gaps, we investigate how maritime system operators perceive\nand navigate cybersecurity challenges within this complex landscape. We\nconducted a user study comprising surveys and semi-structured interviews with\n21 officer-level mariners. Participants reported direct experiences with\nshipboard cyber-attacks, including GPS spoofing and logistics-disrupting\nransomware, demonstrating the real-world impact of these threats. Our findings\nreveal systemic and human-centric issues, such as training poorly aligned with\nmaritime needs, insufficient detection and response tools, and serious gaps in\nmariners' cybersecurity understanding. Our contributions include a\ncategorization of threats identified by mariners and recommendations for\nimproving maritime security, including better training, response protocols, and\nregulation. These insights aim to guide future research and policy to\nstrengthen the resilience of maritime systems.", "comment": "18 pages, 2 figures, To appear in the Proceedings of the 2025 ACM\n  SIGSAC Conference on Computer and Communications Security (CCS '25)", "pdf_url": "http://arxiv.org/pdf/2506.15842v2", "cate": "cs.CR", "date": "2025-06-18", "updated": "2025-07-14"}
{"id": "2507.11170", "title": "A Robust Controller based on Gaussian Processes for Robotic Manipulators with Unknown Uncertainty", "authors": ["Giulio Giacomuzzo", "Mohamed Abdelwahab", "Marco Calì", "Alberto Dalla Libera", "Ruggero Carli"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11170v1", "summary": "In this paper, we propose a novel learning-based robust feedback\nlinearization strategy to ensure precise trajectory tracking for an important\nfamily of Lagrangian systems. We assume a nominal knowledge of the dynamics is\ngiven but no a-priori bounds on the model mismatch are available. In our\napproach, the key ingredient is the adoption of a regression framework based on\nGaussian Processes (GPR) to estimate the model mismatch. This estimate is added\nto the outer loop of a classical feedback linearization scheme based on the\nnominal knowledge available. Then, to compensate for the residual uncertainty,\nwe robustify the controller including an additional term whose size is designed\nbased on the variance provided by the GPR framework. We proved that, with high\nprobability, the proposed scheme is able to guarantee asymptotic tracking of a\ndesired trajectory. We tested numerically our strategy on a 2 degrees of\nfreedom planar robot.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11170v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11083", "title": "Function-to-Style Guidance of LLMs for Code Translation", "authors": ["Longhui Zhang", "Bin Wang", "Jiahao Wang", "Xiaofeng Zhao", "Min Zhang", "Hao Yang", "Meishan Zhang", "Yu Li", "Jing Li", "Jun Yu", "Min Zhang"], "categories": ["cs.AI", "cs.SE"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      This paper has been accepted by ICML 2025. Models and benchmarks can be found at this https URL", "url": "http://arxiv.org/abs/2507.11083v1", "summary": "Large language models (LLMs) have made significant strides in code\ntranslation tasks. However, ensuring both the correctness and readability of\ntranslated code remains a challenge, limiting their effective adoption in\nreal-world software development. In this work, we propose F2STrans, a\nfunction-to-style guiding paradigm designed to progressively improve the\nperformance of LLMs in code translation. Our approach comprises two key stages:\n(1) Functional learning, which optimizes translation correctness using\nhigh-quality source-target code pairs mined from online programming platforms,\nand (2) Style learning, which improves translation readability by incorporating\nboth positive and negative style examples. Additionally, we introduce a novel\ncode translation benchmark that includes up-to-date source code, extensive test\ncases, and manually annotated ground-truth translations, enabling comprehensive\nfunctional and stylistic evaluations. Experiments on both our new benchmark and\nexisting datasets demonstrate that our approach significantly improves code\ntranslation performance. Notably, our approach enables Qwen-1.5B to outperform\nprompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code\ntranslation scenarios.", "comment": "This paper has been accepted by ICML 2025. Models and benchmarks can\n  be found at https://www.modelscope.cn/collections/F2STrans-42526ff95dd843", "pdf_url": "http://arxiv.org/pdf/2507.11083v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11330", "title": "Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge", "authors": ["Wenqing Wu", "Chengzhi Zhang", "Yi Zhao"], "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Journal of the Association for Information Science and Technology, 2025", "url": "http://arxiv.org/abs/2507.11330v1", "summary": "Novelty is a crucial criterion in the peer review process for evaluating\nacademic papers. Traditionally, it's judged by experts or measure by unique\nreference combinations. Both methods have limitations: experts have limited\nknowledge, and the effectiveness of the combination method is uncertain.\nMoreover, it's unclear if unique citations truly measure novelty. The large\nlanguage model (LLM) possesses a wealth of knowledge, while human experts\npossess judgment abilities that the LLM does not possess. Therefore, our\nresearch integrates the knowledge and abilities of LLM and human experts to\naddress the limitations of novelty assessment. The most common novelty in\nacademic papers is the introduction of new methods. In this paper, we propose\nleveraging human knowledge and LLM to assist pretrained language models (PLMs,\ne.g. BERT etc.) in predicting the method novelty of papers. Specifically, we\nextract sentences related to the novelty of the academic paper from peer review\nreports and use LLM to summarize the methodology section of the academic paper,\nwhich are then used to fine-tune PLMs. In addition, we have designed a\ntext-guided fusion module with novel Sparse-Attention to better integrate human\nand LLM knowledge. We compared the method we proposed with a large number of\nbaselines. Extensive experiments demonstrate that our method achieves superior\nperformance.", "comment": "Journal of the Association for Information Science and Technology,\n  2025", "pdf_url": "http://arxiv.org/pdf/2507.11330v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10618", "title": "Compute Requirements for Algorithmic Innovation in Frontier AI Models", "authors": ["Peter Barnett"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10618v1", "summary": "Algorithmic innovation in the pretraining of large language models has driven\na massive reduction in the total compute required to reach a given level of\ncapability. In this paper we empirically investigate the compute requirements\nfor developing algorithmic innovations. We catalog 36 pre-training algorithmic\ninnovations used in Llama 3 and DeepSeek-V3. For each innovation we estimate\nboth the total FLOP used in development and the FLOP/s of the hardware\nutilized. Innovations using significant resources double in their requirements\neach year. We then use this dataset to investigate the effect of compute caps\non innovation. Our analysis suggests that compute caps alone are unlikely to\ndramatically slow AI algorithmic progress. Even stringent compute caps -- such\nas capping total operations to the compute used to train GPT-2 or capping\nhardware capacity to 8 H100 GPUs -- could still have allowed for half of the\ncataloged innovations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10618v1", "cate": "cs.LG", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.10881", "title": "Trexplorer Super: Topologically Correct Centerline Tree Tracking of Tubular Objects in CT Volumes", "authors": ["Roman Naeem", "David Hagerman", "Jennifer Alvén", "Lennart Svensson", "Fredrik Kahl"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Submitted Version. Accepted at MICCAI 2025", "url": "http://arxiv.org/abs/2507.10881v1", "summary": "Tubular tree structures, such as blood vessels and airways, are essential in\nhuman anatomy and accurately tracking them while preserving their topology is\ncrucial for various downstream tasks. Trexplorer is a recurrent model designed\nfor centerline tracking in 3D medical images but it struggles with predicting\nduplicate branches and terminating tracking prematurely. To address these\nissues, we present Trexplorer Super, an enhanced version that notably improves\nperformance through novel advancements. However, evaluating centerline tracking\nmodels is challenging due to the lack of public datasets. To enable thorough\nevaluation, we develop three centerline datasets, one synthetic and two real,\neach with increasing difficulty. Using these datasets, we conduct a\ncomprehensive evaluation of existing state-of-the-art (SOTA) models and compare\nthem with our approach. Trexplorer Super outperforms previous SOTA models on\nevery dataset. Our results also highlight that strong performance on synthetic\ndata does not necessarily translate to real datasets. The code and datasets are\navailable at https://github.com/RomStriker/Trexplorer-Super.", "comment": "Submitted Version. Accepted at MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.10881v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10785", "title": "Towards a Closer Collaboration Between Practice and Research in Agile Software Development Workshop: A Summary and Research Agenda", "authors": ["Michael Neumann", "Eva-Maria Schön", "Mali Senapathi", "Maria Rauschenberger", "Tiago Silva da Silva"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10785v1", "summary": "Agile software development principles and values have been widely adopted\nacross various industries, influencing products and services globally. Despite\nits increasing popularity, a significant gap remains between research and\npractical implementation. This paper presents the findings of the first\ninternational workshop designed to foster collaboration between research and\npractice in agile software development. We discuss the main themes and factors\nidentified by the workshop participants that contribute to this gap, strategies\nto bridge it, and the challenges that require further research attention.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10785v1", "cate": "cs.SE", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11403", "title": "The Potential Impact of Disruptive AI Innovations on U.S. Occupations", "authors": ["Munjung Kim", "Marios Constantinides", "Sanja Šćepanović", "Yong-Yeol Ahn", "Daniele Quercia"], "categories": ["cs.CY", "cs.SI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11403v1", "summary": "The rapid rise of AI is poised to disrupt the labor market. However, AI is\nnot a monolith; its impact depends on both the nature of the innovation and the\njobs it affects. While computational approaches are emerging, there is no\nconsensus on how to systematically measure an innovation's disruptive\npotential. Here, we calculate the disruption index of 3,237 U.S. AI patents\n(2015-2022) and link them to job tasks to distinguish between \"consolidating\"\nAI innovations that reinforce existing structures and \"disruptive\" AI\ninnovations that alter them. Our analysis reveals that consolidating AI\nprimarily targets physical, routine, and solo tasks, common in manufacturing\nand construction in the Midwest and central states. By contrast, disruptive AI\naffects unpredictable and mental tasks, particularly in coastal science and\ntechnology sectors. Surprisingly, we also find that disruptive AI\ndisproportionately affects areas already facing skilled labor shortages,\nsuggesting disruptive AI technologies may accelerate change where workers are\nscarce rather than replacing a surplus. Ultimately, consolidating AI appears to\nextend current automation trends, while disruptive AI is set to transform\ncomplex mental work, with a notable exception for collaborative tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11403v1", "cate": "cs.CY", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11250", "title": "Resilient Time-Sensitive Networking for Industrial IoT: Configuration and Fault-Tolerance Evaluation", "authors": ["Mohamed Seliem", "Dirk Pesch", "Utz Roedig", "Cormac Sreenan"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      (c) 2025 IEEE. This is the author's version of a paper accepted for presentation at the IEEE ETFA 2025 conference. The final version will appear in the conference proceedings", "url": "http://arxiv.org/abs/2507.11250v1", "summary": "Time-Sensitive Networking (TSN) is increasingly adopted in industrial systems\nto meet strict latency, jitter, and reliability requirements. However,\nevaluating TSN's fault tolerance under realistic failure conditions remains\nchallenging. This paper presents IN2C, a modular OMNeT++/INET-based simulation\nframework that models two synchronized production cells connected to\ncentralized infrastructure. IN2C integrates core TSN features, including time\nsynchronization, traffic shaping, per-stream filtering, and Frame Replication\nand Elimination for Redundancy (FRER), alongside XML-driven fault injection for\nlink and node failures. Four fault scenarios are evaluated to compare TSN\nperformance with and without redundancy. Results show that FRER eliminates\npacket loss and achieves submillisecond recovery, though with 2-3x higher link\nutilization. These findings offer practical guidance for deploying TSN in\nbandwidth-constrained industrial environments.", "comment": "(c) 2025 IEEE. This is the author's version of a paper accepted for\n  presentation at the IEEE ETFA 2025 conference. The final version will appear\n  in the conference proceedings", "pdf_url": "http://arxiv.org/pdf/2507.11250v1", "cate": "cs.NI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11009", "title": "Asymptotically Optimal Repair of Reed-Solomon Codes with Small Sub-Packetization under Rack-Aware Model", "authors": ["Ke Wang", "Zhongyan Liu", "Rengang Li", "Yaqian Zhao", "Yaqiang Zhang"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      This work has been accepted by 2025 IEEE Information Theory Workshop", "url": "http://arxiv.org/abs/2507.11009v1", "summary": "This paper presents a comprehensive study on the asymptotically optimal\nrepair of Reed-Solomon (RS) codes with small sub-packetization, specifically\ntailored for rack-aware distributed storage systems. Through the utilization of\nmulti-base expansion, we introduce a novel approach that leverages monomials to\nconstruct linear repair schemes for RS codes. Our repair schemes which adapt to\nall admissible parameters achieve asymptotically optimal repair bandwidth while\nsignificantly reducing the sub-packetization compared with existing schemes.\nFurthermore, our approach is capable of repairing RS codes with asymptotically\noptimal repair bandwidth under the homogeneous storage model, achieving smaller\nsub-packetization than existing methods.", "comment": "This work has been accepted by 2025 IEEE Information Theory Workshop", "pdf_url": "http://arxiv.org/pdf/2507.11009v1", "cate": "cs.IT", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2506.21308", "title": "Balancing Privacy and Utility in Correlated Data: A Study of Bayesian Differential Privacy", "authors": ["Martin Lange", "Patricia Guerra-Balboa", "Javier Parra-Arnau", "Thorsten Strufe"], "categories": ["cs.CR", "cs.IT", "math.IT", "68P27"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      This is the extended version of the paper accepted in the Proceedings of the VLDB Endowment (PVLDB), 2025. The code used for our experiments is accessible in this https URL", "url": "http://arxiv.org/abs/2506.21308v2", "summary": "Privacy risks in differentially private (DP) systems increase significantly\nwhen data is correlated, as standard DP metrics often underestimate the\nresulting privacy leakage, leaving sensitive information vulnerable. Given the\nubiquity of dependencies in real-world databases, this oversight poses a\ncritical challenge for privacy protections. Bayesian differential privacy (BDP)\nextends DP to account for these correlations, yet current BDP mechanisms\nindicate notable utility loss, limiting its adoption.\n  In this work, we address whether BDP can be realistically implemented in\ncommon data structures without sacrificing utility -- a key factor for its\napplicability. By analyzing arbitrary and structured correlation models,\nincluding Gaussian multivariate distributions and Markov chains, we derive\npractical utility guarantees for BDP. Our contributions include theoretical\nlinks between DP and BDP and a novel methodology for adapting DP mechanisms to\nmeet the BDP requirements. Through evaluations on real-world databases, we\ndemonstrate that our novel theorems enable the design of BDP mechanisms that\nmaintain competitive utility, paving the way for practical privacy-preserving\ndata practices in correlated settings.", "comment": "This is the extended version of the paper accepted in the Proceedings\n  of the VLDB Endowment (PVLDB), 2025. The code used for our experiments is\n  accessible in https://github.com/lange-martin/privacy-utility-bdp", "pdf_url": "http://arxiv.org/pdf/2506.21308v2", "cate": "cs.CR", "date": "2025-06-26", "updated": "2025-07-15"}
{"id": "2507.11211", "title": "MPC-based Coarse-to-Fine Motion Planning for Robotic Object Transportation in Cluttered Environments", "authors": ["Chen Cai", "Ernesto Dickel Saraiva", "Ya-jun Pan", "Steven Liu"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures, submitted to IEEE Robotics and Automation Letters (RA-L)", "url": "http://arxiv.org/abs/2507.11211v1", "summary": "This letter presents a novel coarse-to-fine motion planning framework for\nrobotic manipulation in cluttered, unmodeled environments. The system\nintegrates a dual-camera perception setup with a B-spline-based model\npredictive control (MPC) scheme. Initially, the planner generates feasible\nglobal trajectories from partial and uncertain observations. As new visual data\nare incrementally fused, both the environment model and motion planning are\nprogressively refined. A vision-based cost function promotes target-driven\nexploration, while a refined kernel-perceptron collision detector enables\nefficient constraint updates for real-time planning. The framework accommodates\nclosed-chain kinematics and supports dynamic replanning. Experiments on a\nmulti-arm platform validate its robustness and adaptability under uncertainties\nand clutter.", "comment": "10 pages, 5 figures, submitted to IEEE Robotics and Automation\n  Letters (RA-L)", "pdf_url": "http://arxiv.org/pdf/2507.11211v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11117", "title": "AI Agent Architecture for Decentralized Trading of Alternative Assets", "authors": ["Ailiya Borjigin", "Cong He", "Charles CC Lee", "Wei Zhou"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      8 Pages, 1 figure", "url": "http://arxiv.org/abs/2507.11117v1", "summary": "Decentralized trading of real-world alternative assets (e.g., gold) requires\nbridging physical asset custody with blockchain systems while meeting strict\nrequirements for compliance, liquidity, and risk management. We present\nGoldMine OS, a research oriented architecture that employs multiple specialized\nAI agents to automate and secure the tokenization and exchange of physical gold\ninto a blockchain based stablecoin (\"OZ\"). Our approach combines on chain smart\ncontracts for critical risk controls with off chain AI agents for decision\nmaking, blending the transparency and reliability of blockchains with the\nflexibility of AI driven automation. We describe four cooperative agents\n(Compliance, Token Issuance, Market Making, and Risk Control) and a\ncoordinating core, and evaluate the system through simulation and a controlled\npilot deployment. In experiments the prototype delivers on demand token\nissuance in under 1.2 s, more than 100 times faster than manual workflows. The\nMarket Making agent maintains tight liquidity with spreads often below 0.5\npercent even under volatile conditions. Fault injection tests show resilience:\nan oracle price spoofing attack is detected and mitigated within 10 s, and a\nsimulated vault mis reporting halts issuance immediately with minimal user\nimpact. The architecture scales to 5000 transactions per second with 10000\nconcurrent users in benchmarks. These results indicate that an AI agent based\ndecentralized exchange for alternative assets can satisfy rigorous performance\nand safety requirements. We discuss broader implications for democratizing\naccess to traditionally illiquid assets and explain how our governance model --\nmulti signature agent updates and on chain community voting on risk parameters\n-- provides ongoing transparency, adaptability, and formal assurance of system\nintegrity.", "comment": "8 Pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.11117v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11460", "title": "Human-Robot collaboration in surgery: Advances and challenges towards autonomous surgical assistants", "authors": ["Jacinto Colan", "Ana Davila", "Yutaro Yamada", "Yasuhisa Hasegawa"], "categories": ["cs.RO", "cs.HC"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at 2025 IEEE International Conference on Robot and Human Interactive Communication (ROMAN)", "url": "http://arxiv.org/abs/2507.11460v1", "summary": "Human-robot collaboration in surgery represents a significant area of\nresearch, driven by the increasing capability of autonomous robotic systems to\nassist surgeons in complex procedures. This systematic review examines the\nadvancements and persistent challenges in the development of autonomous\nsurgical robotic assistants (ASARs), focusing specifically on scenarios where\nrobots provide meaningful and active support to human surgeons. Adhering to the\nPRISMA guidelines, a comprehensive literature search was conducted across the\nIEEE Xplore, Scopus, and Web of Science databases, resulting in the selection\nof 32 studies for detailed analysis. Two primary collaborative setups were\nidentified: teleoperation-based assistance and direct hands-on interaction. The\nfindings reveal a growing research emphasis on ASARs, with predominant\napplications currently in endoscope guidance, alongside emerging progress in\nautonomous tool manipulation. Several key challenges hinder wider adoption,\nincluding the alignment of robotic actions with human surgeon preferences, the\nnecessity for procedural awareness within autonomous systems, the establishment\nof seamless human-robot information exchange, and the complexities of skill\nacquisition in shared workspaces. This review synthesizes current trends,\nidentifies critical limitations, and outlines future research directions\nessential to improve the reliability, safety, and effectiveness of human-robot\ncollaboration in surgical environments.", "comment": "Accepted at 2025 IEEE International Conference on Robot and Human\n  Interactive Communication (ROMAN)", "pdf_url": "http://arxiv.org/pdf/2507.11460v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10619", "title": "Meta-Reinforcement Learning for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks", "authors": ["Oluwaseyi Giwa", "Tobi Awodunmila", "Muhammad Ahmed Mohsin", "Ahsan Bilal", "Muhammad Ali Jamshed"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      5 pages, 6 figures, under review at IEEE Wireless Communications Letters", "url": "http://arxiv.org/abs/2507.10619v1", "summary": "The dynamic allocation of spectrum in 5G / 6G networks is critical to\nefficient resource utilization. However, applying traditional deep\nreinforcement learning (DRL) is often infeasible due to its immense sample\ncomplexity and the safety risks associated with unguided exploration, which can\ncause severe network interference. To address these challenges, we propose a\nmeta-learning framework that enables agents to learn a robust initial policy\nand rapidly adapt to new wireless scenarios with minimal data. We implement\nthree meta-learning architectures, model-agnostic meta-learning (MAML),\nrecurrent neural network (RNN), and an attention-enhanced RNN, and evaluate\nthem against a non-meta-learning DRL algorithm, proximal policy optimization\n(PPO) baseline, in a simulated dynamic integrated access/backhaul (IAB)\nenvironment. Our results show a clear performance gap. The attention-based\nmeta-learning agent reaches a peak mean network throughput of 48 Mbps, while\nthe PPO baseline decreased drastically to 10 Mbps. Furthermore, our method\nreduces SINR and latency violations by more than 50% compared to PPO. It also\nshows quick adaptation, with a fairness index 0.7, showing better resource\nallocation. This work proves that meta-learning is a very effective and safer\noption for intelligent control in complex wireless systems.", "comment": "5 pages, 6 figures, under review at IEEE Wireless Communications\n  Letters", "pdf_url": "http://arxiv.org/pdf/2507.10619v1", "cate": "cs.LG", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.10893", "title": "Modernizing CNN-based Weather Forecast Model towards Higher Computational Efficiency", "authors": ["Minjong Cheon", "Eunhan Goo", "Su-Hyeon Shin", "Muhammad Ahmed", "Hyungjun Kim"], "categories": ["cs.CV", "cs.AI", "cs.LG", "physics.ao-ph"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      26pages, 9 Figures", "url": "http://arxiv.org/abs/2507.10893v1", "summary": "Recently, AI-based weather forecast models have achieved impressive advances.\nThese models have reached accuracy levels comparable to traditional NWP\nsystems, marking a significant milestone in data-driven weather prediction.\nHowever, they mostly leverage Transformer-based architectures, which often\nleads to high training complexity and resource demands due to the massive\nparameter sizes. In this study, we introduce a modernized CNN-based model for\nglobal weather forecasting that delivers competitive accuracy while\nsignificantly reducing computational requirements. To present a systematic\nmodernization roadmap, we highlight key architectural enhancements across\nmultiple design scales from an earlier CNN-based approach. KAI-a incorporates a\nscale-invariant architecture and InceptionNeXt-based blocks within a\ngeophysically-aware design, tailored to the structure of Earth system data.\nTrained on the ERA5 daily dataset with 67 atmospheric variables, the model\ncontains about 7 million parameters and completes training in just 12 hours on\na single NVIDIA L40s GPU. Our evaluation shows that KAI-a matches the\nperformance of state-of-the-art models in medium-range weather forecasting,\nwhile offering a significantly lightweight design. Furthermore, case studies on\nthe 2018 European heatwave and the East Asian summer monsoon demonstrate\nKAI-a's robust skill in capturing extreme events, reinforcing its practical\nutility.", "comment": "26pages, 9 Figures", "pdf_url": "http://arxiv.org/pdf/2507.10893v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10818", "title": "How Robust are LLM-Generated Library Imports? An Empirical Study using Stack Overflow", "authors": ["Jasmine Latendresse", "SayedHassan Khatoonabadi", "Emad Shihab"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10818v1", "summary": "Software libraries are central to the functionality, security, and\nmaintainability of modern code. As developers increasingly turn to Large\nLanguage Models (LLMs) to assist with programming tasks, understanding how\nthese models recommend libraries is essential. In this paper, we conduct an\nempirical study of six state-of-the-art LLMs, both proprietary and open-source,\nby prompting them to solve real-world Python problems sourced from Stack\nOverflow. We analyze the types of libraries they import, the characteristics of\nthose libraries, and the extent to which the recommendations are usable out of\nthe box. Our results show that LLMs predominantly favour third-party libraries\nover standard ones, and often recommend mature, popular, and permissively\nlicensed dependencies. However, we also identify gaps in usability: 4.6% of the\nlibraries could not be resolved automatically due to structural mismatches\nbetween import names and installable packages, and only two models (out of six)\nprovided installation guidance. While the generated code is technically valid,\nthe lack of contextual support places the burden of manually resolving\ndependencies on the user. Our findings offer actionable insights for both\ndevelopers and researchers, and highlight opportunities to improve the\nreliability and usability of LLM-generated code in the context of software\ndependencies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10818v1", "cate": "cs.SE", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11520", "title": "HIF: The hypergraph interchange format for higher-order networks", "authors": ["Martín Coll", "Cliff A. Joslyn", "Nicholas W. Landry", "Quintino Francesco Lotito", "Audun Myers", "Joshua Pickard", "Brenda Praggastis", "Przemysław Szufel"], "categories": ["physics.soc-ph", "cs.SI"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "Comments:      13 pages, 9 figures", "url": "http://arxiv.org/abs/2507.11520v1", "summary": "Many empirical systems contain complex interactions of arbitrary size,\nrepresenting, for example, chemical reactions, social groups, co-authorship\nrelationships, and ecological dependencies. These interactions are known as\nhigher-order interactions and the collection of these interactions comprise a\nhigher-order network, or hypergraph. Hypergraphs have established themselves as\na popular and versatile mathematical representation of such systems and a\nnumber of software packages written in various programming languages have been\ndesigned to analyze these networks. However, the ecosystem of higher-order\nnetwork analysis software is fragmented due to specialization of each\nsoftware's programming interface and compatible data representations. To enable\nseamless data exchange between higher-order network analysis software packages,\nwe introduce the Hypergraph Interchange Format (HIF), a standardized format for\nstoring higher-order network data. HIF supports multiple types of higher-order\nnetworks, including undirected hypergraphs, directed hypergraphs, and\nsimplicial complexes, while actively exploring extensions to represent\nmultiplex hypergraphs, temporal hypergraphs, and ordered hypergraphs. To\naccommodate the wide variety of metadata used in different contexts, HIF also\nincludes support for attributes associated with nodes, edges, and incidences.\nThis initiative is a collaborative effort involving authors, maintainers, and\ncontributors from prominent hypergraph software packages. This project\nintroduces a JSON schema with corresponding documentation and unit tests,\nexample HIF-compliant datasets, and tutorials demonstrating the use of HIF with\nseveral popular higher-order network analysis software packages.", "comment": "13 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.11520v1", "cate": "physics.soc-ph", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11483", "title": "JamShield: A Machine Learning Detection System for Over-the-Air Jamming Attacks", "authors": ["Ioannis Panitsas", "Yagmur Yigit", "Leandros Tassiulas", "Leandros Maglaras", "Berk Canberk"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at IEEE International Conference on Communications (ICC), 2025", "url": "http://arxiv.org/abs/2507.11483v1", "summary": "Wireless networks are vulnerable to jamming attacks due to the shared\ncommunication medium, which can severely degrade performance and disrupt\nservices. Despite extensive research, current jamming detection methods often\nrely on simulated data or proprietary over-the-air datasets with limited\ncross-layer features, failing to accurately represent the real state of a\nnetwork and thus limiting their effectiveness in real-world scenarios. To\naddress these challenges, we introduce JamShield, a dynamic jamming detection\nsystem trained on our own collected over-the-air and publicly available\ndataset. It utilizes hybrid feature selection to prioritize relevant features\nfor accurate and efficient detection. Additionally, it includes an\nauto-classification module that dynamically adjusts the classification\nalgorithm in real-time based on current network conditions. Our experimental\nresults demonstrate significant improvements in detection rate, precision, and\nrecall, along with reduced false alarms and misdetections compared to\nstate-of-the-art detection algorithms, making JamShield a robust and reliable\nsolution for detecting jamming attacks in real-world wireless networks.", "comment": "Accepted for presentation at IEEE International Conference on\n  Communications (ICC), 2025", "pdf_url": "http://arxiv.org/pdf/2507.11483v1", "cate": "cs.NI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11242", "title": "Extropy Rate: Properties and Application in Feature Selection", "authors": ["Naveen Kumar", "Vivek Vijay"], "categories": ["cs.IT", "math.IT", "math.PR", "94A17, 62B10, 60G10, 62H30, 62P30"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11242v1", "summary": "Extropy, a complementary dual of entropy, (proposed by Lad et al.\n\\cite{lad2015extropy} in 2015) has attracted considerable interest from the\nresearch community. In this study, we focus on discrete random variables and\ndefine conditional extropy, establishing key properties of joint and\nconditional extropy such as bounds, uncertainty reduction due to additional\ninformation, and Lipschitz continuity. We further introduce the concept of\nextropy rate for a stochastic process of discrete random variables as a measure\nof the average uncertainty per random variable within the process. It is\nobserved that for infinite stationary and ergodic stochastic processes, as well\nas for identically and independently distributed sequences, the extropy rate\nexhibits asymptotic equivalence. We explore the extropy rate for finite\nstochastic processes and numerically illustrate its effectiveness in capturing\nthe underlying information across various distributions, quantifying complexity\nin time series data, and characterizing chaotic dynamics in dynamical systems.\nThe behaviour of estimated extropy rate is observed to be closely aligned with\nSimpson's diversity index. The real-life applicability of the extropy rate is\npresented through a novel feature selection method based on the fact that\nfeatures with higher extropy rates contain greater inherent information. Using\nsix publicly available datasets, we show the superiority of the proposed\nfeature selection method over some other existing popular approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11242v1", "cate": "cs.IT", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.02309", "title": "Rethinking Broken Object Level Authorization Attacks Under Zero Trust Principle", "authors": ["Anbin Wu", "Zhiyong Feng", "Ruitao Feng", "Zhenchang Xing", "Yang Liu"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.02309v2", "summary": "RESTful APIs facilitate data exchange between applications, but they also\nexpose sensitive resources to potential exploitation. Broken Object Level\nAuthorization (BOLA) is the top vulnerability in the OWASP API Security Top 10,\nexemplifies a critical access control flaw where attackers manipulate API\nparameters to gain unauthorized access. To address this, we propose BOLAZ, a\ndefense framework grounded in zero trust principles. BOLAZ analyzes the data\nflow of resource IDs, pinpointing BOLA attack injection points and determining\nthe associated authorization intervals to prevent horizontal privilege\nescalation. Our approach leverages static taint tracking to categorize APIs\ninto producers and consumers based on how they handle resource IDs. By mapping\nthe propagation paths of resource IDs, BOLAZ captures the context in which\nthese IDs are produced and consumed, allowing for precise identification of\nauthorization boundaries. Unlike defense methods based on common authorization\nmodels, BOLAZ is the first authorization-guided method that adapts defense\nrules based on the system's best-practice authorization logic. We validate\nBOLAZ through empirical research on 10 GitHub projects. The results demonstrate\nBOLAZ's effectiveness in defending against vulnerabilities collected from CVE\nand discovering 35 new BOLA vulnerabilities in the wild, demonstrating its\npracticality in real-world deployments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.02309v2", "cate": "cs.CR", "date": "2025-07-03", "updated": "2025-07-15"}
{"id": "2507.11241", "title": "Comparison of Localization Algorithms between Reduced-Scale and Real-Sized Vehicles Using Visual and Inertial Sensors", "authors": ["Tobias Kern", "Leon Tolksdorf", "Christian Birkner"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11241v1", "summary": "Physically reduced-scale vehicles are emerging to accelerate the development\nof advanced automated driving functions. In this paper, we investigate the\neffects of scaling on self-localization accuracy with visual and\nvisual-inertial algorithms using cameras and an inertial measurement unit\n(IMU). For this purpose, ROS2-compatible visual and visual-inertial algorithms\nare selected, and datasets are chosen as a baseline for real-sized vehicles. A\ntest drive is conducted to record data of reduced-scale vehicles. We compare\nthe selected localization algorithms, OpenVINS, VINS-Fusion, and RTAB-Map, in\nterms of their pose accuracy against the ground-truth and against data from\nreal-sized vehicles. When comparing the implementation of the selected\nlocalization algorithms to real-sized vehicles, OpenVINS has the lowest average\nlocalization error. Although all selected localization algorithms have\noverlapping error ranges, OpenVINS also performs best when applied to a\nreduced-scale vehicle. When reduced-scale vehicles were compared to real-sized\nvehicles, minor differences were found in translational vehicle motion\nestimation accuracy. However, no significant differences were found when\ncomparing the estimation accuracy of rotational vehicle motion, allowing RSVRs\nto be used as testing platforms for self-localization algorithms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11241v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11127", "title": "Defining neurosymbolic AI", "authors": ["Lennert De Smet", "Luc De Raedt"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11127v1", "summary": "Neurosymbolic AI focuses on integrating learning and reasoning, in\nparticular, on unifying logical and neural representations. Despite the\nexistence of an alphabet soup of neurosymbolic AI systems, the field is lacking\na generally accepted formal definition of what neurosymbolic models and\ninference really are. We introduce a formal definition for neurosymbolic AI\nthat makes abstraction of its key ingredients. More specifically, we define\nneurosymbolic inference as the computation of an integral over a product of a\nlogical and a belief function. We show that our neurosymbolic AI definition\nmakes abstraction of key representative neurosymbolic AI systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11127v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11477", "title": "Queueing for Civility: User Perspectives on Regulating Emotions in Online Conversations", "authors": ["Akriti Verma", "Shama Islam", "Valeh Moghaddam", "Adnan Anwar"], "categories": ["cs.CY", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11477v1", "summary": "Online conversations are often interrupted by trolling, which causes\nemotional distress and conflict among users. Previous research has focused on\nmoderating harmful content after it has been posted, but ways to manage\nemotions in real-time remain unexplored. This study suggests a comment queuing\nmechanism that delays comment publishing, encourages self-reflection, and\nreduces the impact of impulsive and toxic comments. To assess the efficacy of\nthis approach, a mixed-method research design is used. An analysis of 15,000\nuser interactions on Reddit showed that this approach could reduce the spread\nof hate speech and anger by up to 15%, with only 4% of comments being delayed\nfor about 47 seconds on average. We also surveyed users for feedback on the\nmechanism. The results showed that 93. 3\\% of the participants thought that the\nqueuing mechanism could help calm the discussions and showed interest in seeing\nit used on social media platforms. Furthermore, 83% believed it would reduce\nimpulsive comments and balance the emotional tone in conversations. We found a\nstrong link between users' typical emotional states while using social media\nand their perceptions of the delay, with calm users finding the mechanism\nhelpful and frustrated users anticipating frustration.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11477v1", "cate": "cs.CY", "date": "2025-05-05", "updated": "2025-05-05"}
{"id": "2507.10620", "title": "LLMs Meet Cross-Modal Time Series Analytics: Overview and Directions", "authors": ["Chenxi Liu", "Hao Miao", "Cheng Long", "Yan Zhao", "Ziyue Li", "Panos Kalnis"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at SSTD 2025 (Tutorial). arXiv admin note: text overlap with arXiv:2505.02583", "url": "http://arxiv.org/abs/2507.10620v1", "summary": "Large Language Models (LLMs) have emerged as a promising paradigm for time\nseries analytics, leveraging their massive parameters and the shared sequential\nnature of textual and time series data. However, a cross-modality gap exists\nbetween time series and textual data, as LLMs are pre-trained on textual\ncorpora and are not inherently optimized for time series. In this tutorial, we\nprovide an up-to-date overview of LLM-based cross-modal time series analytics.\nWe introduce a taxonomy that classifies existing approaches into three groups\nbased on cross-modal modeling strategies, e.g., conversion, alignment, and\nfusion, and then discuss their applications across a range of downstream tasks.\nIn addition, we summarize several open challenges. This tutorial aims to expand\nthe practical application of LLMs in solving real-world problems in cross-modal\ntime series analytics while balancing effectiveness and efficiency.\nParticipants will gain a thorough understanding of current advancements,\nmethodologies, and future research directions in cross-modal time series\nanalytics.", "comment": "Accepted at SSTD 2025 (Tutorial). arXiv admin note: text overlap with\n  arXiv:2505.02583", "pdf_url": "http://arxiv.org/pdf/2507.10620v1", "cate": "cs.LG", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.10895", "title": "Commuting Distance Regularization for Timescale-Dependent Label Inconsistency in EEG Emotion Recognition", "authors": ["Xiaocong Zeng", "Craig Michoski", "Yan Pang", "Dongyang Kuang"], "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.SP"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10895v1", "summary": "In this work, we address the often-overlooked issue of Timescale Dependent\nLabel Inconsistency (TsDLI) in training neural network models for EEG-based\nhuman emotion recognition. To mitigate TsDLI and enhance model generalization\nand explainability, we propose two novel regularization strategies: Local\nVariation Loss (LVL) and Local-Global Consistency Loss (LGCL). Both methods\nincorporate classical mathematical principles--specifically, functions of\nbounded variation and commute-time distances--within a graph theoretic\nframework. Complementing our regularizers, we introduce a suite of new\nevaluation metrics that better capture the alignment between temporally local\npredictions and their associated global emotion labels. We validate our\napproach through comprehensive experiments on two widely used EEG emotion\ndatasets, DREAMER and DEAP, across a range of neural architectures including\nLSTM and transformer-based models. Performance is assessed using five distinct\nmetrics encompassing both quantitative accuracy and qualitative consistency.\nResults consistently show that our proposed methods outperform state-of-the-art\nbaselines, delivering superior aggregate performance and offering a principled\ntrade-off between interpretability and predictive power under label\ninconsistency. Notably, LVL achieves the best aggregate rank across all\nbenchmarked backbones and metrics, while LGCL frequently ranks the second,\nhighlighting the effectiveness of our framework.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10895v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10822", "title": "Past, Present and Future: Exploring Adaptive AI in Software Development Bots", "authors": ["Omar Elsisi", "Glaucia Melo"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10822v1", "summary": "Conversational agents, such as chatbots and virtual assistants, have become\nessential in software development, boosting productivity, collaboration, and\nautomating various tasks. This paper examines the role of adaptive AI-powered\nconversational agents in software development, highlighting their ability to\noffer dynamic, context-aware assistance to developers. Unlike traditional\nrule-based systems, adaptive AI agents use machine learning and natural\nlanguage processing to learn from interactions and improve over time, providing\nmore personalized and responsive help. We look at how these tools have evolved\nfrom simple query-based systems to advanced AI-driven solutions like GitHub\nCopilot and Microsoft Teams bots. We also explore the challenges of integrating\nadaptive AI into software development processes. The study aims to assess the\nbenefits and limitations of these systems, address concerns like data privacy\nand ethical issues, and offer insights into their future use in the field.\nUltimately, adaptive AI chatbots have great potential to revolutionize software\ndevelopment by delivering real-time, customized support and enhancing the\nefficiency of development cycles.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10822v1", "cate": "cs.SE", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2207.12123", "title": "Entropy-based models to randomize real-world hypergraphs", "authors": ["Fabio Saracco", "Giovanni Petri", "Renaud Lambiotte", "Tiziano Squartini"], "categories": ["cs.SI", "cond-mat.stat-mech", "physics.data-an"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      47 pages, 14 figures, 3 tables", "url": "http://arxiv.org/abs/2207.12123v3", "summary": "Network theory has often disregarded many-body relationships, solely focusing\non pairwise interactions: neglecting them, however, can lead to misleading\nrepresentations of complex systems. Hypergraphs represent a suitable framework\nfor describing polyadic interactions. Here, we leverage the representation of\nhypergraphs based on the incidence matrix for extending the entropy-based\napproach to higher-order structures: in analogy with the Exponential Random\nGraphs, we introduce the Exponential Random Hypergraphs (ERHs). After exploring\nthe asymptotic behaviour of thresholds generalising the percolation one, we\napply ERHs to study real-world data. First, we generalise key network metrics\nto hypergraphs; then, we compute their expected value and compare it with the\nempirical one, in order to detect deviations from random behaviours. Our method\nis analytically tractable, scalable and capable of revealing structural\npatterns of real-world hypergraphs that differ significantly from those\nemerging as a consequence of simpler constraints.", "comment": "47 pages, 14 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2207.12123v3", "cate": "cs.SI", "date": "2022-07-21", "updated": "2025-07-15"}
{"id": "2507.10757", "title": "FAFO: Over 1 million TPS on a single node running EVM while still Merkleizing every block", "authors": ["Ryan Zarick", "Isaac Zhang", "Daniel Wong", "Thomas Kim", "Bryan Pellegrino", "Mignon Li", "Kelvin Wong"], "categories": ["cs.DC", "cs.NI"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10757v1", "summary": "Current blockchain execution throughput is limited by data contention,\nreducing execution layer parallelism. Fast Ahead-of-Formation Optimization\n(FAFO) is the first blockchain transaction scheduler to address this problem by\nreordering transactions before block formation for maximum concurrency. FAFO\nuses CPU-optimized cache-friendly Bloom filters to efficiently detect conflicts\nand schedule parallel transaction execution at high throughput and low\noverhead.\n  We integrate the Rust EVM client (REVM) into FAFO and achieve over 1.1\nmillion native ETH transfers per second and over half a million ERC20 transfers\nper second on a single node (Table 1), with 91% lower cost compared to\nstate-of-the-art sharded execution. Unlike many other existing high throughput\nblockchain execution clients, FAFO uses QMDB to Merkleize world state after\nevery block, enabling light clients and stateless validation for ZK-based\nvApps. FAFO scales with minimal synchronization overhead, scaling linearly with\nadditional CPU resources until it fully exploits the maximum parallelism of the\nunderlying transaction flow. FAFO proves that the high throughput necessary to\nsupport future decentralized applications can be achieved with a streamlined\nexecution layer and innovations in blockchain transaction scheduler design.\nFAFO is open-sourced at https://github.com/LayerZero-Labs/fafo.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10757v1", "cate": "cs.DC", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10838", "title": "Waterfilling at the Edge: Optimal Percentile Resource Allocation via Risk-Averse Reduction", "authors": ["Gokberk Yaylali", "Ahmad Ali Khan", "Dionysios S. Kalogerias"], "categories": ["eess.SP", "cs.IT", "math.IT", "math.OC"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      5 pages, 5 figures", "url": "http://arxiv.org/abs/2507.10838v1", "summary": "We address deterministic resource allocation in point-to-point multi-terminal\nAWGN channels without inter-terminal interference, with particular focus on\noptimizing quantile transmission rates for cell-edge terminal service.\nClassical utility-based approaches -- such as minimum rate, sumrate, and\nproportional fairness -- are either overconservative, or inappropriate, or do\nnot provide a rigorous and/or interpretable foundation for fair rate\noptimization at the edge. To overcome these challenges, we employ Conditional\nValue-at-Risk (CVaR), a popular coherent risk measure, and establish its\nequivalence with the sum-least-$\\alpha$th-quantile (SL$\\alpha$Q) utility. This\nconnection enables an exact convex reformulation of the SL$\\alpha$Q\nmaximization problem, facilitating analytical tractability and precise and\ninterpretable control over cell-edge terminal performance. Utilizing Lagrangian\nduality, we provide (for the first time) parameterized closed-form solutions\nfor the optimal resource policy -- which is of waterfilling-type -- as well as\nthe associated (auxiliary) Value-at-Risk variable. We further develop a novel\ninexact dual subgradient descent algorithm of minimal complexity to determine\nglobally optimal resource policies, and we rigorously establish its\nconvergence. The resulting edge waterfilling algorithm iteratively and\nefficiently allocates resources while explicitly ensuring transmission rate\nfairness across (cell-edge) terminals. Several (even large-scale) numerical\nexperiments validate the effectiveness of the proposed method for enabling\nrobust quantile rate optimization at the edge.", "comment": "5 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.10838v1", "cate": "eess.SP", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.05728", "title": "Asynchronous Event Error-Minimizing Noise for Safeguarding Event Dataset", "authors": ["Ruofei Wang", "Peiqi Duan", "Boxin Shi", "Renjie Wan"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV2025", "url": "http://arxiv.org/abs/2507.05728v2", "summary": "With more event datasets being released online, safeguarding the event\ndataset against unauthorized usage has become a serious concern for data\nowners. Unlearnable Examples are proposed to prevent the unauthorized\nexploitation of image datasets. However, it's unclear how to create unlearnable\nasynchronous event streams to prevent event misuse. In this work, we propose\nthe first unlearnable event stream generation method to prevent unauthorized\ntraining from event datasets. A new form of asynchronous event error-minimizing\nnoise is proposed to perturb event streams, tricking the unauthorized model\ninto learning embedded noise instead of realistic features. To be compatible\nwith the sparse event, a projection strategy is presented to sparsify the noise\nto render our unlearnable event streams (UEvs). Extensive experiments\ndemonstrate that our method effectively protects event data from unauthorized\nexploitation, while preserving their utility for legitimate use. We hope our\nUEvs contribute to the advancement of secure and trustworthy event dataset\nsharing. Code is available at: https://github.com/rfww/uevs.", "comment": "Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.05728v2", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-15"}
{"id": "2507.11270", "title": "Development of an Autonomous Mobile Robotic System for Efficient and Precise Disinfection", "authors": ["Ting-Wei Ou", "Jia-Hao Jiang", "Guan-Lin Huang", "Kuu-Young Young"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted to the IEEE International Conference on Systems, Man, and Cybernetics (SMC) 2025", "url": "http://arxiv.org/abs/2507.11270v1", "summary": "The COVID-19 pandemic has severely affected public health, healthcare\nsystems, and daily life, especially amid resource shortages and limited\nworkers. This crisis has underscored the urgent need for automation in hospital\nenvironments, particularly disinfection, which is crucial to controlling virus\ntransmission and improving the safety of healthcare personnel and patients.\nUltraviolet (UV) light disinfection, known for its high efficiency, has been\nwidely adopted in hospital settings. However, most existing research focuses on\nmaximizing UV coverage while paying little attention to the impact of human\nactivity on virus distribution. To address this issue, we propose a mobile\nrobotic system for UV disinfection focusing on the virus hotspot. The system\nprioritizes disinfection in high-risk areas and employs an approach for\noptimized UV dosage to ensure that all surfaces receive an adequate level of UV\nexposure while significantly reducing disinfection time. It not only improves\ndisinfection efficiency but also minimizes unnecessary exposure in low-risk\nareas. In two representative hospital scenarios, our method achieves the same\ndisinfection effectiveness while reducing disinfection time by 30.7% and 31.9%,\nrespectively. The video of the experiment is available at:\nhttps://youtu.be/wHcWzOcoMPM.", "comment": "Accepted to the IEEE International Conference on Systems, Man, and\n  Cybernetics (SMC) 2025", "pdf_url": "http://arxiv.org/pdf/2507.11270v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11135", "title": "Collaborative Trustworthiness for Good Decision Making in Autonomous Systems", "authors": ["Selma Saidi", "Omar Laimona", "Christoph Schmickler", "Dirk Ziegenbein"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11135v1", "summary": "Autonomous systems are becoming an integral part of many application domains,\nlike in the mobility sector. However, ensuring their safe and correct behaviour\nin dynamic and complex environments remains a significant challenge, where\nsystems should autonomously make decisions e.g., about manoeuvring. We propose\nin this paper a general collaborative approach for increasing the level of\ntrustworthiness in the environment of operation and improve reliability and\ngood decision making in autonomous system. In the presence of conflicting\ninformation, aggregation becomes a major issue for trustworthy decision making\nbased on collaborative data sharing. Unlike classical approaches in the\nliterature that rely on consensus or majority as aggregation rule, we exploit\nthe fact that autonomous systems have different quality attributes like\nperception quality. We use this criteria to determine which autonomous systems\nare trustworthy and borrow concepts from social epistemology to define\naggregation and propagation rules, used for automated decision making. We use\nBinary Decision Diagrams (BDDs) as formal models for beliefs aggregation and\npropagation, and formulate reduction rules to reduce the size of the BDDs and\nallow efficient computation structures for collaborative automated reasoning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11135v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11479", "title": "Perspective-Aware AI in Extended Reality", "authors": ["Daniel Platnick", "Matti Gruener", "Marjan Alirezaie", "Kent Larson", "Dava J. Newman", "Hossein Rahnama"], "categories": ["cs.AI", "cs.GR", "cs.HC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted to the International Conference on eXtended Reality (2025), 12 pages, 3 figures", "url": "http://arxiv.org/abs/2507.11479v1", "summary": "AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive\nexperiences-yet current systems fall short due to shallow user modeling and\nlimited cognitive context. We introduce Perspective-Aware AI in Extended\nReality (PAiR), a foundational framework for integrating Perspective-Aware AI\n(PAi) with XR to enable interpretable, context-aware experiences grounded in\nuser identity. PAi is built on Chronicles: reasoning-ready identity models\nlearned from multimodal digital footprints that capture users' cognitive and\nexperiential evolution. PAiR employs these models in a closed-loop system\nlinking dynamic user states with immersive environments. We present PAiR's\narchitecture, detailing its modules and system flow, and demonstrate its\nutility through two proof-of-concept scenarios implemented in the Unity-based\nOpenDome engine. PAiR opens a new direction for human-AI interaction by\nembedding perspective-based identity models into immersive systems.", "comment": "Accepted to the International Conference on eXtended Reality (2025),\n  12 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.11479v1", "cate": "cs.AI", "date": "2025-05-05", "updated": "2025-05-05"}
{"id": "2507.10623", "title": "Flows and Diffusions on the Neural Manifold", "authors": ["Daniel Saragih", "Deyu Cao", "Tejas Balaji"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      40 pages, 6 figures, 13 tables", "url": "http://arxiv.org/abs/2507.10623v1", "summary": "Diffusion and flow-based generative models have achieved remarkable success\nin domains such as image synthesis, video generation, and natural language\nmodeling. In this work, we extend these advances to weight space learning by\nleveraging recent techniques to incorporate structural priors derived from\noptimization dynamics. Central to our approach is modeling the trajectory\ninduced by gradient descent as a trajectory inference problem. We unify several\ntrajectory inference techniques under the framework of gradient flow matching,\nproviding a theoretical framework for treating optimization paths as inductive\nbias. We further explore architectural and algorithmic choices, including\nreward fine-tuning by adjoint matching, the use of autoencoders for latent\nweight representation, conditioning on task-specific context data, and adopting\ninformative source distributions such as Kaiming uniform. Experiments\ndemonstrate that our method matches or surpasses baselines in generating\nin-distribution weights, improves initialization for downstream training, and\nsupports fine-tuning to enhance performance. Finally, we illustrate a practical\napplication in safety-critical systems: detecting harmful covariate shifts,\nwhere our method outperforms the closest comparable baseline.", "comment": "40 pages, 6 figures, 13 tables", "pdf_url": "http://arxiv.org/pdf/2507.10623v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10935", "title": "GeoDistill: Geometry-Guided Self-Distillation for Weakly Supervised Cross-View Localization", "authors": ["Shaowen Tong", "Zimin Xia", "Alexandre Alahi", "Xuming He", "Yujiao Shi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted by ICCV2025", "url": "http://arxiv.org/abs/2507.10935v1", "summary": "Cross-view localization, the task of estimating a camera's\n3-degrees-of-freedom (3-DoF) pose by aligning ground-level images with\nsatellite images, is crucial for large-scale outdoor applications like\nautonomous navigation and augmented reality. Existing methods often rely on\nfully supervised learning, which requires costly ground-truth pose annotations.\nIn this work, we propose GeoDistill, a Geometry guided weakly supervised self\ndistillation framework that uses teacher-student learning with Field-of-View\n(FoV)-based masking to enhance local feature learning for robust cross-view\nlocalization. In GeoDistill, the teacher model localizes a panoramic image,\nwhile the student model predicts locations from a limited FoV counterpart\ncreated by FoV-based masking. By aligning the student's predictions with those\nof the teacher, the student focuses on key features like lane lines and ignores\ntextureless regions, such as roads. This results in more accurate predictions\nand reduced uncertainty, regardless of whether the query images are panoramas\nor limited FoV images. Our experiments show that GeoDistill significantly\nimproves localization performance across different frameworks. Additionally, we\nintroduce a novel orientation estimation network that predicts relative\norientation without requiring precise planar position ground truth. GeoDistill\nprovides a scalable and efficient solution for real-world cross-view\nlocalization challenges. Code and model can be found at\nhttps://github.com/tongshw/GeoDistill.", "comment": "accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.10935v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10906", "title": "Evaluating Generated Commit Messages with Large Language Models", "authors": ["Qunhong Zeng", "Yuxia Zhang", "Zexiong Ma", "Bo Jiang", "Ningyuan Sun", "Klaas-Jan Stol", "Xingyu Mou", "Hui Liu"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10906v1", "summary": "Commit messages are essential in software development as they serve to\ndocument and explain code changes. Yet, their quality often falls short in\npractice, with studies showing significant proportions of empty or inadequate\nmessages. While automated commit message generation has advanced significantly,\nparticularly with Large Language Models (LLMs), the evaluation of generated\nmessages remains challenging. Traditional reference-based automatic metrics\nlike BLEU, ROUGE-L, and METEOR have notable limitations in assessing commit\nmessage quality, as they assume a one-to-one mapping between code changes and\ncommit messages, leading researchers to rely on resource-intensive human\nevaluation. This study investigates the potential of LLMs as automated\nevaluators for commit message quality. Through systematic experimentation with\nvarious prompt strategies and state-of-the-art LLMs, we demonstrate that LLMs\ncombining Chain-of-Thought reasoning with few-shot demonstrations achieve near\nhuman-level evaluation proficiency. Our LLM-based evaluator significantly\noutperforms traditional metrics while maintaining acceptable reproducibility,\nrobustness, and fairness levels despite some inherent variability. This work\nconducts a comprehensive preliminary study on using LLMs for commit message\nevaluation, offering a scalable alternative to human assessment while\nmaintaining high-quality evaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10906v1", "cate": "cs.SE", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2405.04896", "title": "Verified authors shape X/Twitter discursive communities", "authors": ["Stefano Guarino", "Ayoub Mounim", "Guido Caldarelli", "Fabio Saracco"], "categories": ["cs.SI", "cs.CY"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      33 pages, 14 figures", "url": "http://arxiv.org/abs/2405.04896v2", "summary": "In this study, we address the challenge of detecting ``discursive\ncommunities'' on X/Twitter by focusing on the role of verified users as the\nmain content creators in online political debates. The analysis centers on\nthree major Italian political events in 2022 - the Presidential election, a\ngovernmental crisis, and the general elections - occurring before the\nintroduction of paid account verification. We propose and compare two novel\nmethodologies, MonoDC and BiDC, which exploit, respectively, the retweet\nnetwork among users and a similarity network based on shared audiences, while\nintegrating a maximum entropy null model to filter out the inherent noise in\nonline social networks. Our results demonstrate that leveraging verified\nusers-considered as indicators of prestige and authority-leads to significantly\nclear community partitions that closely reflect the actual political\naffiliations, outperforming standard community detection algorithms applied to\nthe entire retweet network. Moreover, the comparison of different methodologies\nand user sets suggests that the status conferred by the blue verification tick\nplays a dominant role in shaping online discourse, with important implications\nfor platform governance, especially in light of the recent shift to paid\nverification.", "comment": "33 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2405.04896v2", "cate": "cs.SI", "date": "2024-05-08", "updated": "2025-07-15"}
{"id": "2507.11222", "title": "An Agentic Flow for Finite State Machine Extraction using Prompt Chaining", "authors": ["Fares Wael", "Youssef Maklad", "Ali Hamdi", "Wael Elsersy"], "categories": ["cs.CL", "cs.AI", "cs.NI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11222v1", "summary": "Finite-State Machines (FSMs) are critical for modeling the operational logic\nof network protocols, enabling verification, analysis, and vulnerability\ndiscovery. However, existing FSM extraction techniques face limitations such as\nscalability, incomplete coverage, and ambiguity in natural language\nspecifications. In this paper, we propose FlowFSM, a novel agentic framework\nthat leverages Large Language Models (LLMs) combined with prompt chaining and\nchain-of-thought reasoning to extract accurate FSMs from raw RFC documents.\nFlowFSM systematically processes protocol specifications, identifies state\ntransitions, and constructs structured rule-books by chaining agent outputs.\nExperimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM\nachieves high extraction precision while minimizing hallucinated transitions,\nshowing promising results. Our findings highlight the potential of agent-based\nLLM systems in the advancement of protocol analysis and FSM inference for\ncybersecurity and reverse engineering applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11222v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11093", "title": "Optimizing Fluid Antenna Configurations for Constructive Interference Precoding", "authors": ["Wenxuan Sun", "Mingjie Shao", "Luteng Zhu", "Yao Ge", "Tong Zhang", "Zhi Liu"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11093v1", "summary": "The fluid antenna system (FAS) has emerged as a new physical-layer concept to\nprovide enhanced propagation conditions for multiuser multiple-input\nmultiple-output (MIMO) communications over conventional fixed arrays. This work\nfocuses on minimizing the maximum symbol error probability (SEP) under $M$-ary\nphase shift keying (MPSK) signaling in a multiuser downlink equipped with FAS,\nwhere each antenna moves within nonoverlapping intervals. This specific problem\nof joint SEP minimization with FAS and constructive interference (CI) precoding\nhas not been previously addressed. The resulting problem turns out to be a\nnonconvex and nonsmooth optimization challenge. We transform the SEP\nminimization problem into a safety margin maximization problem in constructive\ninterference precoding. Then, we customize a smoothing technique and a block\ncoordinate descent (BCD) algorithm, with emphasis on low computational\ncomplexity. Simulation results show that our approach can reduce bit error rate\n(BER) compared to both the fixed arrays and FAS designed by existing particle\nswarm optimization (PSO). Also, our approach shows attractively low\ncomputational complexity compared to PSO benchmarks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11093v1", "cate": "eess.SP", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.09607", "title": "Efficient Private Inference Based on Helper-Assisted Malicious Security Dishonest Majority MPC", "authors": ["Kaiwen Wang", "Yuehan Dong", "Junchao Fan", "Xiaolin Chang"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      The manuscript is being withdrawn due to ongoing major revisions and significant changes to the methodology and results. A substantially improved version may be submitted in the future", "url": "http://arxiv.org/abs/2507.09607v2", "summary": "Private inference based on Secure Multi-Party Computation (MPC) addresses\ndata privacy risks in Machine Learning as a Service (MLaaS). However, existing\nMPC-based private inference frameworks focuses on semi-honest or honest\nmajority models, whose threat models are overly idealistic, while malicious\nsecurity dishonest majority models face the challenge of low efficiency. To\nbalance security and efficiency, we propose a private inference framework using\nHelper-Assisted Malicious Security Dishonest Majority Model (HA-MSDM). This\nframework includes our designed five MPC protocols and a co-optimized strategy.\nThese protocols achieve efficient fixed-round multiplication, exponentiation,\nand polynomial operations, providing foundational primitives for private\ninference. The co-optimized strategy balances inference efficiency and\naccuracy. To enhance efficiency, we employ polynomial approximation for\nnonlinear layers. For improved accuracy, we construct sixth-order polynomial\napproximation within a fixed interval to achieve high-precision activation\nfunction fitting and introduce parameter-adjusted batch normalization layers to\nconstrain the activation escape problem. Benchmark results on LeNet and AlexNet\nshow our framework achieves 2.4-25.7x speedup in LAN and 1.3-9.5x acceleration\nin WAN compared to state-of-the-art frameworks (IEEE S&P'25), maintaining high\naccuracy with only 0.04%-1.08% relative errors.", "comment": "The manuscript is being withdrawn due to ongoing major revisions and\n  significant changes to the methodology and results. A substantially improved\n  version may be submitted in the future", "pdf_url": "http://arxiv.org/pdf/2507.09607v2", "cate": "cs.CR", "date": "2025-07-13", "updated": "2025-07-15"}
{"id": "2507.11283", "title": "Ocean Diviner: A Diffusion-Augmented Reinforcement Learning for AUV Robust Control in the Underwater Tasks", "authors": ["Weiyi Liu", "Jingzehua Xu", "Guanwen Xie", "Yi Li"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11283v1", "summary": "This paper presents a diffusion-augmented reinforcement learning (RL)\napproach for robust autonomous underwater vehicle (AUV) control, addressing key\nchallenges in underwater trajectory planning and dynamic environment\nadaptation. The proposed method integrates three core innovations: (1) A\ndiffusion-based trajectory generation framework that produces physically\nfeasible multi-step trajectories, enhanced by a high-dimensional state encoding\nmechanism combining current observations with historical states and actions\nthrough a novel diffusion U-Net architecture, significantly improving\nlong-horizon planning. (2) A sample-efficient hybrid learning architecture that\nsynergizes diffusion-guided exploration with RL policy optimization, where the\ndiffusion model generates diverse candidate actions and the RL critic selects\noptimal actions, achieving higher exploration efficiency and policy stability\nin dynamic underwater environments. Extensive simulation experiments validating\nthe method's superior robustness and flexibility, outperforms conventional\ncontrol methods in challenging marine conditions, offering enhanced\nadaptability and reliability for AUV operations in the underwater tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11283v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11150", "title": "Fine-grained Timing Analysis of Digital Integrated Circuits in Answer Set Programming", "authors": ["Alessandro Bertagnon", "Marcello Dalpasso", "Michele Favalli", "Marco Gavanelli"], "categories": ["cs.AI", "cs.LO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted for publication in the issues of Theory and Practice of Logic Programming (TPLP) dedicated to ICLP 2025, 16 pages, 9 figures", "url": "http://arxiv.org/abs/2507.11150v1", "summary": "In the design of integrated circuits, one critical metric is the maximum\ndelay introduced by combinational modules within the circuit. This delay is\ncrucial because it represents the time required to perform a computation: in an\nArithmetic-Logic Unit it represents the maximum time taken by the circuit to\nperform an arithmetic operation. When such a circuit is part of a larger,\nsynchronous system, like a CPU, the maximum delay directly impacts the maximum\nclock frequency of the entire system. Typically, hardware designers use Static\nTiming Analysis to compute an upper bound of the maximum delay because it can\nbe determined in polynomial time. However, relying on this upper bound can lead\nto suboptimal processor speeds, thereby missing performance opportunities. In\nthis work, we tackle the challenging task of computing the actual maximum\ndelay, rather than an approximate value. Since the problem is computationally\nhard, we model it in Answer Set Programming (ASP), a logic language featuring\nextremely efficient solvers. We propose non-trivial encodings of the problem\ninto ASP. Experimental results show that ASP is a viable solution to address\ncomplex problems in hardware design.", "comment": "Accepted for publication in the issues of Theory and Practice of\n  Logic Programming (TPLP) dedicated to ICLP 2025, 16 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.11150v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11525", "title": "LLM-based ambiguity detection in natural language instructions for collaborative surgical robots", "authors": ["Ana Davila", "Jacinto Colan", "Yasuhisa Hasegawa"], "categories": ["cs.RO", "cs.HC"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at 2025 IEEE International Conference on Robot and Human Interactive Communication (ROMAN)", "url": "http://arxiv.org/abs/2507.11525v1", "summary": "Ambiguity in natural language instructions poses significant risks in\nsafety-critical human-robot interaction, particularly in domains such as\nsurgery. To address this, we propose a framework that uses Large Language\nModels (LLMs) for ambiguity detection specifically designed for collaborative\nsurgical scenarios. Our method employs an ensemble of LLM evaluators, each\nconfigured with distinct prompting techniques to identify linguistic,\ncontextual, procedural, and critical ambiguities. A chain-of-thought evaluator\nis included to systematically analyze instruction structure for potential\nissues. Individual evaluator assessments are synthesized through conformal\nprediction, which yields non-conformity scores based on comparison to a labeled\ncalibration dataset. Evaluating Llama 3.2 11B and Gemma 3 12B, we observed\nclassification accuracy exceeding 60% in differentiating ambiguous from\nunambiguous surgical instructions. Our approach improves the safety and\nreliability of human-robot collaboration in surgery by offering a mechanism to\nidentify potentially ambiguous instructions before robot action.", "comment": "Accepted at 2025 IEEE International Conference on Robot and Human\n  Interactive Communication (ROMAN)", "pdf_url": "http://arxiv.org/pdf/2507.11525v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10626", "title": "Player-Team Heterogeneous Interaction Graph Transformer for Soccer Outcome Prediction", "authors": ["Lintao Wang", "Shiwen Xu", "Michael Horton", "Joachim Gudmundsson", "Zhiyong Wang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10626v1", "summary": "Predicting soccer match outcomes is a challenging task due to the inherently\nunpredictable nature of the game and the numerous dynamic factors influencing\nresults. While it conventionally relies on meticulous feature engineering, deep\nlearning techniques have recently shown a great promise in learning effective\nplayer and team representations directly for soccer outcome prediction.\nHowever, existing methods often overlook the heterogeneous nature of\ninteractions among players and teams, which is crucial for accurately modeling\nmatch dynamics. To address this gap, we propose HIGFormer (Heterogeneous\nInteraction Graph Transformer), a novel graph-augmented transformer-based deep\nlearning model for soccer outcome prediction. HIGFormer introduces a\nmulti-level interaction framework that captures both fine-grained player\ndynamics and high-level team interactions. Specifically, it comprises (1) a\nPlayer Interaction Network, which encodes player performance through\nheterogeneous interaction graphs, combining local graph convolutions with a\nglobal graph-augmented transformer; (2) a Team Interaction Network, which\nconstructs interaction graphs from a team-to-team perspective to model\nhistorical match relationships; and (3) a Match Comparison Transformer, which\njointly analyzes both team and player-level information to predict match\noutcomes. Extensive experiments on the WyScout Open Access Dataset, a\nlarge-scale real-world soccer dataset, demonstrate that HIGFormer significantly\noutperforms existing methods in prediction accuracy. Furthermore, we provide\nvaluable insights into leveraging our model for player performance evaluation,\noffering a new perspective on talent scouting and team strategy analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10626v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10938", "title": "Graph Aggregation Prototype Learning for Semantic Change Detection in Remote Sensing", "authors": ["Zhengyi Xu", "Haoran Wu", "Wen Jiang", "Jie Geng"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10938v1", "summary": "Semantic change detection (SCD) extends the binary change detection task to\nprovide not only the change locations but also the detailed \"from-to\"\ncategories in multi-temporal remote sensing data. Such detailed semantic\ninsights into changes offer considerable advantages for a wide array of\napplications. However, since SCD involves the simultaneous optimization of\nmultiple tasks, the model is prone to negative transfer due to task-specific\nlearning difficulties and conflicting gradient flows. To address this issue, we\npropose Graph Aggregation Prototype Learning for Semantic Change Detection in\nremote sensing(GAPL-SCD). In this framework, a multi-task joint optimization\nmethod is designed to optimize the primary task of semantic segmentation and\nchange detection, along with the auxiliary task of graph aggregation prototype\nlearning. Adaptive weight allocation and gradient rotation methods are used to\nalleviate the conflict between training tasks and improve multi-task learning\ncapabilities. Specifically, the graph aggregation prototype learning module\nconstructs an interaction graph using high-level features. Prototypes serve as\nclass proxies, enabling category-level domain alignment across time points and\nreducing interference from irrelevant changes. Additionally, the proposed\nself-query multi-level feature interaction and bi-temporal feature fusion\nmodules further enhance multi-scale feature representation, improving\nperformance in complex scenes. Experimental results on the SECOND and\nLandsat-SCD datasets demonstrate that our method achieves state-of-the-art\nperformance, with significant improvements in accuracy and robustness for SCD\ntask.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10938v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11059", "title": "SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks", "authors": ["Pavel Adamenko", "Mikhail Ivanov", "Aidar Valeev", "Rodion Levichev", "Pavel Zadorozhny", "Ivan Lopatin", "Dmitry Babayev", "Alena Fenogenova", "Valentin Malykh"], "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11059v1", "summary": "The rapid advancement of Large Language Models (LLMs) in software engineering\nhas revealed critical limitations in existing benchmarks, particularly the\nwidely used SWE-bench dataset. Recent studies have uncovered severe data\ncontamination issues, e.g. SWE-bench reports 32.67% of successful patches\ninvolve direct solution leakage and 31.08\\% pass due to inadequate test cases.\nWe introduce SWE-MERA, a dynamic, continuously updated benchmark designed to\naddress these fundamental challenges through an automated collection of\nreal-world GitHub issues and rigorous quality validation. Our approach\nimplements a reliable pipeline that ensures quality while minimizing\ncontamination risks, resulting in approximately 10,000 potential tasks with 300\nsamples currently available. Evaluation using the Aider coding agent\ndemonstrates strong discriminative power in state-of-the-art models. We report\nperformance across a dozen recent LLMs evaluated on tasks collected between\nSeptember 2024 and June 2025.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11059v1", "cate": "cs.SE", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2412.10781", "title": "Crowd: A Social Network Simulation Framework", "authors": ["Ann Nedime Nese Rende", "Tolga Yilmaz", "Özgür Ulusoy"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.10781v3", "summary": "To observe how individual behavior shapes a larger community's actions,\nagent-based modeling and simulation (ABMS) has been widely adopted by\nresearchers in social sciences, economics, and epidemiology. While simulations\ncan be run on general-purpose ABMS frameworks, these tools are not specifically\ndesigned for social networks and, therefore, provide limited features,\nincreasing the effort required for complex simulations. In this paper, we\nintroduce Crowd, a social network simulator that adopts the agent-based\nmodeling methodology to model real-world phenomena within a network\nenvironment. Designed to facilitate easy and quick modeling, Crowd supports\nsimulation setup through YAML configuration and enables further customization\nwith user-defined methods. Other features include no-code simulations for\ndiffusion tasks, interactive visualizations, data aggregation, and chart\ndrawing facilities. Designed in Python, Crowd also supports generative agents\nand connects easily with Python's libraries for data analysis and machine\nlearning. Finally, we include three case studies to illustrate the use of the\nframework, including generative agents in epidemics, influence maximization,\nand networked trust games.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.10781v3", "cate": "cs.SI", "date": "2024-12-14", "updated": "2025-07-15"}
{"id": "2412.20077", "title": "A Time-Triggered Communication Method Based on Urgency-Based Scheduler in Time-Sensitive Networking", "authors": ["Feng Luo", "Yunpeng Li", "Zitong Wang", "Yi Ren", "Yingpeng Tong", "Zhouping Zhang", "Qin Liu"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.20077v3", "summary": "The development of the automotive industry and automation has led to a\ngrowing demand for time-critical systems to have low latency and jitter for\ncritical traffic. To address this issue, the IEEE 802.1 Time-Sensitive\nNetworking (TSN) task group proposed the Time-Aware Shaper (TAS) to implement\nTime-Triggered (TT) communication, enabling deterministic transmission by\nassigning specific time windows to each stream. While Fixed Routing and\nWaiting-Allowed (FR-WA) scheduling algorithms offer flexibility, they suffer\nfrom inefficiencies in solution time and scalability. This study analyzes TAS\nimplementation challenges, emphasizing how network scale expansion increases\ncomputational constraints. We propose an Urgency-Based Scheduler method\n(TT-UBS) to address these limitations to enhance deterministic transmission and\ncomputational efficiency under anomalies. A novel scheduling algorithm for\nTT-UBS parameter determination is developed, alongside simulations and\ncomparative evaluations. Results show that TT-UBS guarantees deterministic\ntraffic delivery while reducing solution time by 98.22% in test scenarios\ncompared to traditional approaches. The methodology is extended to other\nscheduling algorithms to assess efficiency improvements. This advancement\nsupports TSN's application in mission-critical systems by optimizing\ntime-triggered communication performance and enabling reliable network\ndeployment. The framework demonstrates significant potential for real-time\nin-vehicle networks requiring latency and jitter control.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.20077v3", "cate": "cs.NI", "date": "2024-12-28", "updated": "2025-07-15"}
{"id": "2507.11095", "title": "Performance Enhancement of the Recursive Least Squares Algorithms with Rank Two Updates", "authors": ["Alexander Stotsky"], "categories": ["math.OC", "cs.IT", "cs.NA", "math.DS", "math.HO", "math.IT", "math.NA"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      7pages, 2 figures", "url": "http://arxiv.org/abs/2507.11095v1", "summary": "New recursive least squares algorithms with rank two updates (RLSR2) that\ninclude both exponential and instantaneous forgetting (implemented via a proper\nchoice of the forgetting factor and the window size) are introduced and\nsystematically associated in this report with well-known RLS algorithms with\nrank one updates. Moreover, new properties (which can be used for further\nperformance improvement) of the recursive algorithms associated with the\nconvergence of the inverse of information matrix and parameter vector are\nestablished in this report. The performance of new algorithms is examined in\nthe problem of estimation of the grid events in the presence of significant\nharmonic emissions.", "comment": "7pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.11095v1", "cate": "math.OC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2401.08513", "title": "X Hacking: The Threat of Misguided AutoML", "authors": ["Rahul Sharma", "Sergey Redyuk", "Sumantrak Mukherjee", "Andrea Šipka", "Eyke Hüllermeier", "Sebastian Vollmer", "David Selby"], "categories": ["cs.LG", "cs.CR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to ICML 2025", "url": "http://arxiv.org/abs/2401.08513v3", "summary": "Explainable AI (XAI) and interpretable machine learning methods help to build\ntrust in model predictions and derived insights, yet also present a perverse\nincentive for analysts to manipulate XAI metrics to support pre-specified\nconclusions. This paper introduces the concept of X-hacking, a form of\np-hacking applied to XAI metrics such as SHAP values. We show how easily an\nautomated machine learning pipeline can be adapted to exploit model\nmultiplicity at scale: searching a Rashomon set of 'defensible' models with\nsimilar predictive performance to find a desired explanation. We formulate the\ntrade-off between explanation and accuracy as a multi-objective optimisation\nproblem, and illustrate empirically on familiar real-world datasets that, on\naverage, Bayesian optimisation accelerates X-hacking 3-fold for features\nsusceptible to it, versus random sampling. We show the vulnerability of a\ndataset to X-hacking can be determined by information redundancy among\nfeatures. Finally, we suggest possible methods for detection and prevention,\nand discuss ethical implications for the credibility and reproducibility of\nXAI.", "comment": "Accepted to ICML 2025", "pdf_url": "http://arxiv.org/pdf/2401.08513v3", "cate": "cs.LG", "date": "2024-01-16", "updated": "2025-07-15"}
{"id": "2507.11296", "title": "Diffusion-Based Imaginative Coordination for Bimanual Manipulation", "authors": ["Huilin Xu", "Jian Ding", "Jiakun Xu", "Ruixiang Wang", "Jun Chen", "Jinjie Mai", "Yanwei Fu", "Bernard Ghanem", "Feng Xu", "Mohamed Elhoseiny"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      15 pages, including 10 figures and 16 tables. Accepted at ICCV 2025", "url": "http://arxiv.org/abs/2507.11296v1", "summary": "Bimanual manipulation is crucial in robotics, enabling complex tasks in\nindustrial automation and household services. However, it poses significant\nchallenges due to the high-dimensional action space and intricate coordination\nrequirements. While video prediction has been recently studied for\nrepresentation learning and control, leveraging its ability to capture rich\ndynamic and behavioral information, its potential for enhancing bimanual\ncoordination remains underexplored. To bridge this gap, we propose a unified\ndiffusion-based framework for the joint optimization of video and action\nprediction. Specifically, we propose a multi-frame latent prediction strategy\nthat encodes future states in a compressed latent space, preserving\ntask-relevant features. Furthermore, we introduce a unidirectional attention\nmechanism where video prediction is conditioned on the action, while action\nprediction remains independent of video prediction. This design allows us to\nomit video prediction during inference, significantly enhancing efficiency.\nExperiments on two simulated benchmarks and a real-world setting demonstrate a\nsignificant improvement in the success rate over the strong baseline ACT using\nour method, achieving a \\textbf{24.9\\%} increase on ALOHA, an \\textbf{11.1\\%}\nincrease on RoboTwin, and a \\textbf{32.5\\%} increase in real-world experiments.\nOur models and code are publicly available at\nhttps://github.com/return-sleep/Diffusion_based_imaginative_Coordination.", "comment": "15 pages, including 10 figures and 16 tables. Accepted at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.11296v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11229", "title": "DuetGraph: Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion", "authors": ["Jin Li", "Zezhong Ding", "Xike Xie"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11229v1", "summary": "Knowledge graphs (KGs) are vital for enabling knowledge reasoning across\nvarious domains. Recent KG reasoning methods that integrate both global and\nlocal information have achieved promising results. However, existing methods\noften suffer from score over-smoothing, which blurs the distinction between\ncorrect and incorrect answers and hinders reasoning effectiveness. To address\nthis, we propose DuetGraph, a coarse-to-fine KG reasoning mechanism with\ndual-pathway global-local fusion. DuetGraph tackles over-smoothing by\nsegregating -- rather than stacking -- the processing of local (via message\npassing) and global (via attention) information into two distinct pathways,\npreventing mutual interference and preserving representational discrimination.\nIn addition, DuetGraph introduces a coarse-to-fine optimization, which\npartitions entities into high- and low-score subsets. This strategy narrows the\ncandidate space and sharpens the score gap between the two subsets, which\nalleviates over-smoothing and enhances inference quality. Extensive experiments\non various datasets demonstrate that DuetGraph achieves state-of-the-art (SOTA)\nperformance, with up to an 8.7% improvement in reasoning quality and a\n1.8$\\times$ acceleration in training efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11229v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2407.16206", "title": "Cluster Haptic Texture Database: Haptic Texture Database with Varied Velocity-Direction Sliding Contacts", "authors": ["Michikuni Eguchi", "Tomohiro Hayase", "Yuichi Hiroi", "Takefumi Hiraki"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      dataset: this https URL code: this https URL", "url": "http://arxiv.org/abs/2407.16206v3", "summary": "Haptic sciences and technologies benefit greatly from comprehensive datasets\nthat capture tactile stimuli under controlled, systematic conditions. However,\nexisting haptic databases collect data through uncontrolled exploration, which\nhinders the systematic analysis of how motion parameters (e.g., motion\ndirection and velocity) influence tactile perception. This paper introduces\nCluster Haptic Texture Database, a multimodal dataset recorded using a 3-axis\nmachine with an artificial finger to precisely control sliding velocity and\ndirection. The dataset encompasses 118 textured surfaces across 9 material\ncategories, with recordings at 5 velocity levels (20-60 mm/s) and 8 directions.\nEach surface was tested under 160 conditions, yielding 18,880 synchronized\nrecordings of audio, acceleration, force, position, and visual data. Validation\nusing convolutional neural networks demonstrates classification accuracies of\n96% for texture recognition, 88.76% for velocity estimation, and 78.79% for\ndirection estimation, confirming the dataset's utility for machine learning\napplications. This resource enables research in haptic rendering, texture\nrecognition algorithms, and human tactile perception mechanisms, supporting the\ndevelopment of realistic haptic interfaces for virtual reality systems and\nrobotic applications.", "comment": "dataset: https://doi.org/10.6084/m9.figshare.29438288 code:\n  https://github.com/cluster-lab/Cluster-Haptic-Texture-Database", "pdf_url": "http://arxiv.org/pdf/2407.16206v3", "cate": "cs.HC", "date": "2024-07-23", "updated": "2025-07-15"}
{"id": "2507.10628", "title": "GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning", "authors": ["Ziru Liu", "Cheng Gong", "Xinyu Fu", "Yaofang Liu", "Ran Chen", "Shoubo Hu", "Suiyun Zhang", "Rui Liu", "Qingfu Zhang", "Dandan Tu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10628v1", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as\na powerful paradigm for facilitating the self-improvement of large language\nmodels (LLMs), particularly in the domain of complex reasoning tasks. However,\nprevailing on-policy RL methods often contend with significant training\ninstability and inefficiency. This is primarily due to a capacity-difficulty\nmismatch, where the complexity of training data frequently outpaces the model's\ncurrent capabilities, leading to critically sparse reward signals and stalled\nlearning progress. This challenge is particularly acute for smaller, more\nresource-efficient LLMs. To overcome this, we introduce the Guided Hybrid\nPolicy Optimization (GHPO), a novel difficulty-aware reinforcement learning\nframework. GHPO dynamically calibrates task difficulty by employing adaptive\nprompt refinement to provide targeted guidance. This unique approach adaptively\nbalances direct imitation learning for problems currently beyond the model's\nreach with exploration-based reinforcement learning for more manageable tasks,\neffectively creating a smooth and optimized learning curriculum. Extensive\nexperiments demonstrate that GHPO achieves an average performance gain of\napproximately 5% across six challenging mathematics benchmarks, consistently\noutperforming strong on-policy reinforcement learning and curriculum learning\nbaselines. Further analysis confirms that our framework significantly enhances\nboth training stability and final reasoning performance, thus offering a\nscalable and efficient solution for developing powerful and robust reasoning\nmodels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10628v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10943", "title": "Robust ID-Specific Face Restoration via Alignment Learning", "authors": ["Yushun Fang", "Lu Liu", "Xiang Gao", "Qiang Hu", "Ning Cao", "Jianghe Cui", "Gang Chen", "Xiaoyun Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 8 figures", "url": "http://arxiv.org/abs/2507.10943v1", "summary": "The latest developments in Face Restoration have yielded significant\nadvancements in visual quality through the utilization of diverse diffusion\npriors. Nevertheless, the uncertainty of face identity introduced by\nidentity-obscure inputs and stochastic generative processes remains unresolved.\nTo address this challenge, we present Robust ID-Specific Face Restoration\n(RIDFR), a novel ID-specific face restoration framework based on diffusion\nmodels. Specifically, RIDFR leverages a pre-trained diffusion model in\nconjunction with two parallel conditioning modules. The Content Injection\nModule inputs the severely degraded image, while the Identity Injection Module\nintegrates the specific identity from a given image. Subsequently, RIDFR\nincorporates Alignment Learning, which aligns the restoration results from\nmultiple references with the same identity in order to suppress the\ninterference of ID-irrelevant face semantics (e.g. pose, expression, make-up,\nhair style). Experiments demonstrate that our framework outperforms the\nstate-of-the-art methods, reconstructing high-quality ID-specific results with\nhigh identity fidelity and demonstrating strong robustness.", "comment": "17 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.10943v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11092", "title": "MT4DP: Data Poisoning Attack Detection for DL-based Code Search Models via Metamorphic Testing", "authors": ["Gong Chen", "Wenjie Liu", "Xiaoyuan Xie", "Xunzhu Tang", "Tegawendé F. Bissyandé", "Songqiang Chen"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      27 pages", "url": "http://arxiv.org/abs/2507.11092v1", "summary": "Recently, several studies have indicated that data poisoning attacks pose a\nsevere security threat to deep learning-based (DL-based) code search models.\nAttackers inject carefully crafted malicious patterns into the training data,\nmisleading the code search model to learn these patterns during training.\nDuring the usage of the poisoned code search model for inference, once the\nmalicious pattern is triggered, the model tends to rank the vulnerability code\nhigher. However, existing detection methods for data poisoning attacks on\nDL-based code search models remain insufficiently effective. To address this\ncritical security issue, we propose MT4DP, a Data Poisoning Attack Detection\nFramework for DL-based Code Search Models via Metamorphic Testing. MT4DP\nintroduces a novel Semantically Equivalent Metamorphic Relation (SE-MR)\ndesigned to detect data poisoning attacks on DL-based code search models.\nSpecifically, MT4DP first identifies the high-frequency words from search\nqueries as potential poisoning targets and takes their corresponding queries as\nthe source queries. For each source query, MT4DP generates two semantically\nequivalent follow-up queries and retrieves its source ranking list. Then, each\nsource ranking list is re-ranked based on the semantic similarities between its\ncode snippets and the follow-up queries. Finally, variances between the source\nand re-ranked lists are calculated to reveal violations of the SE-MR and warn\nthe data poisoning attack. Experimental results demonstrate that MT4DP\nsignificantly enhances the detection of data poisoning attacks on DL-based code\nsearch models, outperforming the best baseline by 191% on average F1 score and\n265% on average precision. Our work aims to promote further research into\neffective techniques for mitigating data poisoning threats on DL-based code\nsearch models.", "comment": "27 pages", "pdf_url": "http://arxiv.org/pdf/2507.11092v1", "cate": "cs.SE", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2504.11932", "title": "Technological Complexity Based on Japanese Patent Data", "authors": ["Rintaro Karashima", "Hiroyasu Inoue"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.11932v4", "summary": "As international competition intensifies in technologies, nations need to\nidentify key technologies to foster innovation. However, the identification is\nchallenging due to the independent and inherently complex nature of\ntechnologies. Traditionally, regional analyses of technological portfolios have\nbeen limited to binary evaluations, indicating merely whether a region\nspecializes in a technology, or relying on the average Technological Complexity\nIndex (TCI) of the specialized technologies. This study proposes that\nevaluating TCI at the corporate level could provide finer granularity and more\ndetailed insights. To address the underutilization of corporate-level TCI\nassessments in Japan, this study applies the Technological Complexity Index\nusing carefully processed patent data spanning fiscal years 1981 to 2010.\nSpecifically, we analyze a bipartite network composed of 1,938 corporations\nconnected to technological fields categorized into either 35 or 124\nclassifications. Our findings quantitatively characterize the ubiquity and\nsophistication of each technological field, reveal detailed technological\ntrends reflecting broader societal contexts, and demonstrate methodological\nstability even when employing finer technological classifications.\nAdditionally, our corporate-level approach allows consistent comparisons across\ndifferent regions and technological fields, clarifying regional advantages in\nspecific technologies. This refined analytical framework offers policymakers\nand researchers robust, targeted insights, thereby significantly contributing\nto innovation strategy formulation in Japan.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.11932v4", "cate": "cs.SI", "date": "2025-04-16", "updated": "2025-07-15"}
{"id": "2504.04027", "title": "A Fast Solver-Free Algorithm for Traffic Engineering in Large-Scale Data Center Network", "authors": ["Yingming Mao", "Qiaozhu Zhai", "Ximeng Liu", "Zhen Yao", "Xia Zhu", "Yuzhou Zhou"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      Accepted by 23rd USENIX Symposium on Network Systems Design and Implementation (NSDI '26), to be held in Seattle on May 4-6, 2026", "url": "http://arxiv.org/abs/2504.04027v2", "summary": "Rapid growth of data center networks (DCNs) poses significant challenges for\nlarge-scale traffic engineering (TE). Existing acceleration strategies, which\nrely on commercial solvers or deep learning, face scalability issues and\nstruggle with degrading performance or long computational time. Unlike existing\nalgorithms adopting parallel strategies, we propose Sequential\nSource-Destination Optimization (SSDO), a sequential solver-free algorithm for\nTE. SSDO decomposes the problem into subproblems, each focused on adjusting the\nsplit ratios for a specific source-destination (SD) demand while keeping others\nfixed. To enhance the efficiency of subproblem optimization, we design a\nBalanced Binary Search Method (BBSM), which identifies the most balanced split\nratios among multiple solutions that minimize Maximum Link Utilization (MLU).\nSSDO dynamically updates the sequence of SDs based on real-time utilization,\nwhich accelerates convergence and enhances solution quality. We evaluate SSDO\non Meta DCNs and two wide-area networks. In a Meta topology, SSDO achieves a\n65\\% and 60\\% reduction in normalized MLU compared to TEAL and POP, two\nstate-of-the-art TE acceleration methods, while delivering a $12\\times$ speedup\nover POP. These results demonstrate the superior performance of SSDO in\nlarge-scale TE.", "comment": "Accepted by 23rd USENIX Symposium on Network Systems Design and\n  Implementation (NSDI '26), to be held in Seattle on May 4-6, 2026", "pdf_url": "http://arxiv.org/pdf/2504.04027v2", "cate": "cs.NI", "date": "2025-04-05", "updated": "2025-07-15"}
{"id": "2507.11249", "title": "Fast and Efficient Implementation of the Maximum Likelihood Estimation for the Linear Regression with Gaussian Model Uncertainty", "authors": ["Ruohai Guo", "Jiang Zhu", "Xing Jiang", "Fengzhong Qu"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11249v1", "summary": "The linear regression model with a random variable (RV) measurement matrix,\nwhere the mean of the random measurement matrix has full column rank, has been\nextensively studied. In particular, the quasiconvexity of the maximum\nlikelihood estimation (MLE) problem was established, and the corresponding\nCramer-Rao bound (CRB) was derived, leading to the development of an efficient\nbisection-based algorithm known as RV-ML. In contrast, this work extends the\nanalysis to both overdetermined and underdetermined cases, allowing the mean of\nthe random measurement matrix to be rank-deficient. A remarkable contribution\nis the proof that the equivalent MLE problem is convex and satisfies strong\nduality, strengthening previous quasiconvexity results. Moreover, it is shown\nthat in underdetermined scenarios, the randomness in the measurement matrix can\nbe beneficial for estimation under certain conditions. In addition, a fast and\nunified implementation of the MLE solution, referred to as generalized RV-ML\n(GRV-ML), is proposed, which handles a more general case including both\nunderdetermined and overdetermined systems. Extensive numerical simulations are\nprovided to validate the theoretical findings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11249v1", "cate": "eess.SP", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2404.13914", "title": "A Survey on Speech Deepfake Detection", "authors": ["Menglu Li", "Yasaman Ahmadiadli", "Xiao-Ping Zhang"], "categories": ["cs.SD", "cs.CR", "cs.MM", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      38 pages. This paper has been accepted by ACM Computing Surveys", "url": "http://arxiv.org/abs/2404.13914v2", "summary": "The availability of smart devices leads to an exponential increase in\nmultimedia content. However, advancements in deep learning have also enabled\nthe creation of highly sophisticated Deepfake content, including speech\nDeepfakes, which pose a serious threat by generating realistic voices and\nspreading misinformation. To combat this, numerous challenges have been\norganized to advance speech Deepfake detection techniques. In this survey, we\nsystematically analyze more than 200 papers published up to March 2024. We\nprovide a comprehensive review of each component in the detection pipeline,\nincluding model architectures, optimization techniques, generalizability,\nevaluation metrics, performance comparisons, available datasets, and open\nsource availability. For each aspect, we assess recent progress and discuss\nongoing challenges. In addition, we explore emerging topics such as partial\nDeepfake detection, cross-dataset evaluation, and defences against adversarial\nattacks, while suggesting promising research directions. This survey not only\nidentifies the current state of the art to establish strong baselines for\nfuture experiments but also offers clear guidance for researchers aiming to\nenhance speech Deepfake detection systems.", "comment": "38 pages. This paper has been accepted by ACM Computing Surveys", "pdf_url": "http://arxiv.org/pdf/2404.13914v2", "cate": "cs.SD", "date": "2024-04-22", "updated": "2025-07-14"}
{"id": "2507.11302", "title": "All Eyes, no IMU: Learning Flight Attitude from Vision Alone", "authors": ["Jesse J. Hagenaars", "Stein Stroobants", "Sander M. Bohte", "Guido C. H. E. De Croon"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11302v1", "summary": "Vision is an essential part of attitude control for many flying animals, some\nof which have no dedicated sense of gravity. Flying robots, on the other hand,\ntypically depend heavily on accelerometers and gyroscopes for attitude\nstabilization. In this work, we present the first vision-only approach to\nflight control for use in generic environments. We show that a quadrotor drone\nequipped with a downward-facing event camera can estimate its attitude and\nrotation rate from just the event stream, enabling flight control without\ninertial sensors. Our approach uses a small recurrent convolutional neural\nnetwork trained through supervised learning. Real-world flight tests\ndemonstrate that our combination of event camera and low-latency neural network\nis capable of replacing the inertial measurement unit in a traditional flight\ncontrol loop. Furthermore, we investigate the network's generalization across\ndifferent environments, and the impact of memory and different fields of view.\nWhile networks with memory and access to horizon-like visual cues achieve best\nperformance, variants with a narrower field of view achieve better relative\ngeneralization. Our work showcases vision-only flight control as a promising\ncandidate for enabling autonomous, insect-scale flying robots.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11302v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11288", "title": "Opus: A Prompt Intention Framework for Complex Workflow Generation", "authors": ["Théo Fagnoni", "Mahsun Altin", "Chia En Chung", "Phillip Kingston", "Alan Tuning", "Dana O. Mohamed", "Inès Adnani"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      39 pages, 24 figures", "url": "http://arxiv.org/abs/2507.11288v1", "summary": "This paper introduces the Opus Prompt Intention Framework, designed to\nimprove complex Workflow Generation with instruction-tuned Large Language\nModels (LLMs). We propose an intermediate Intention Capture layer between user\nqueries and Workflow Generation, implementing the Opus Workflow Intention\nFramework, which consists of extracting Workflow Signals from user queries,\ninterpreting them into structured Workflow Intention objects, and generating\nWorkflows based on these Intentions. Our results show that this layer enables\nLLMs to produce logical and meaningful outputs that scale reliably as query\ncomplexity increases. On a synthetic benchmark of 1,000 multi-intent\nquery-Workflow(s) pairs, applying the Opus Prompt Intention Framework to\nWorkflow Generation yields consistent improvements in semantic Workflow\nsimilarity metrics. In this paper, we introduce the Opus Prompt Intention\nFramework by applying the concepts of Workflow Signal and Workflow Intention to\nLLM-driven Workflow Generation. We present a reproducible, customizable\nLLM-based Intention Capture system to extract Workflow Signals and Workflow\nIntentions from user queries. Finally, we provide empirical evidence that the\nproposed system significantly improves Workflow Generation quality compared to\ndirect generation from user queries, particularly in cases of Mixed Intention\nElicitation.", "comment": "39 pages, 24 figures", "pdf_url": "http://arxiv.org/pdf/2507.11288v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2410.04025", "title": "IdeaSynth: Iterative Research Idea Development Through Evolving and Composing Idea Facets with Literature-Grounded Feedback", "authors": ["Kevin Pu", "K. J. Kevin Feng", "Tovi Grossman", "Tom Hope", "Bhavana Dalvi Mishra", "Matt Latzke", "Jonathan Bragg", "Joseph Chee Chang", "Pao Siangliulue"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.04025v2", "summary": "Research ideation involves broad exploring and deep refining ideas. Both\nrequire deep engagement with literature. Existing tools focus primarily on idea\nbroad generation, yet offer little support for iterative specification,\nrefinement, and evaluation needed to further develop initial ideas. To bridge\nthis gap, we introduce IdeaSynth, a research idea development system that uses\nLLMs to provide literature-grounded feedback for articulating research\nproblems, solutions, evaluations, and contributions. IdeaSynth represents these\nidea facets as nodes on a canvas, and allow researchers to iteratively refine\nthem by creating and exploring variations and composing them. Our lab study\n(N=20) showed that participants, while using IdeaSynth, explored more\nalternative ideas and expanded initial ideas with more details compared to a\nstrong LLM-based baseline. Our deployment study (N=7) demonstrated that\nparticipants effectively used IdeaSynth for real-world research projects at\nvarious ideation stages from developing initial ideas to revising framings of\nmature manuscripts, highlighting the possibilities to adopt IdeaSynth in\nresearcher's workflows.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.04025v2", "cate": "cs.HC", "date": "2024-10-05", "updated": "2025-07-15"}
{"id": "2507.10632", "title": "Scalable Unsupervised Segmentation via Random Fourier Feature-based Gaussian Process", "authors": ["Issei Saito", "Masatoshi Nagano", "Tomoaki Nakamura", "Daichi Mochihashi", "Koki Mimura"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10632v1", "summary": "In this paper, we propose RFF-GP-HSMM, a fast unsupervised time-series\nsegmentation method that incorporates random Fourier features (RFF) to address\nthe high computational cost of the Gaussian process hidden semi-Markov model\n(GP-HSMM). GP-HSMM models time-series data using Gaussian processes, requiring\ninversion of an N times N kernel matrix during training, where N is the number\nof data points. As the scale of the data increases, matrix inversion incurs a\nsignificant computational cost. To address this, the proposed method\napproximates the Gaussian process with linear regression using RFF, preserving\nexpressive power while eliminating the need for inversion of the kernel matrix.\nExperiments on the Carnegie Mellon University (CMU) motion-capture dataset\ndemonstrate that the proposed method achieves segmentation performance\ncomparable to that of conventional methods, with approximately 278 times faster\nsegmentation on time-series data comprising 39,200 frames.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10632v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10969", "title": "Women Sport Actions Dataset for Visual Classification Using Small Scale Training Data", "authors": ["Palash Ray", "Mahuya Sasmal", "Asish Bera"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10969v1", "summary": "Sports action classification representing complex body postures and\nplayer-object interactions is an emerging area in image-based sports analysis.\nSome works have contributed to automated sports action recognition using\nmachine learning techniques over the past decades. However, sufficient image\ndatasets representing women sports actions with enough intra- and inter-class\nvariations are not available to the researchers. To overcome this limitation,\nthis work presents a new dataset named WomenSports for women sports\nclassification using small-scale training data. This dataset includes a variety\nof sports activities, covering wide variations in movements, environments, and\ninteractions among players. In addition, this study proposes a convolutional\nneural network (CNN) for deep feature extraction. A channel attention scheme\nupon local contextual regions is applied to refine and enhance feature\nrepresentation. The experiments are carried out on three different sports\ndatasets and one dance dataset for generalizing the proposed algorithm, and the\nperformances on these datasets are noteworthy. The deep learning method\nachieves 89.15% top-1 classification accuracy using ResNet-50 on the proposed\nWomenSports dataset, which is publicly available for research at Mendeley Data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10969v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11146", "title": "Automata Models for Effective Bug Description", "authors": ["Tom Yaacov", "Gera Weiss", "Gal Amram", "Avi Hayoun"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted to the ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems (MODELS 2025)", "url": "http://arxiv.org/abs/2507.11146v1", "summary": "Debugging complex systems is a crucial yet time-consuming task. This paper\npresents the use of automata learning and testing techniques to obtain concise\nand informative bug descriptions. We introduce the concepts of Failure\nExplanations (FE), Eventual Failure Explanations (EFE), and Early Detection\n(ED) to provide meaningful summaries of failing behavior patterns. By factoring\nout irrelevant information and focusing on essential test patterns, our\napproach aims to enhance bug detection and understanding. We evaluate our\nmethods using various test patterns and real-world benchmarks, demonstrating\ntheir effectiveness in producing compact and informative bug descriptions.", "comment": "Accepted to the ACM/IEEE 28th International Conference on Model\n  Driven Engineering Languages and Systems (MODELS 2025)", "pdf_url": "http://arxiv.org/pdf/2507.11146v1", "cate": "cs.SE", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2312.09611", "title": "Capturing Dynamics in Online Public Discourse: A Case Study of Universal Basic Income Discussions on Reddit", "authors": ["Rachel Kim", "Veniamin Veselovsky", "Ashton Anderson"], "categories": ["cs.CY", "cs.SI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      ICWSM 2025", "url": "http://arxiv.org/abs/2312.09611v2", "summary": "Societal change is often driven by shifts in public opinion. As citizens\nevolve in their norms, beliefs, and values, public policies change too. While\ntraditional opinion polling and surveys can outline the broad strokes of\nwhether public opinion on a particular topic is changing, they usually cannot\ncapture the full multi-dimensional richness and diversity of opinion present in\na large heterogeneous population. However, an increasing fraction of public\ndiscourse about public policy issues is now occurring on online platforms,\nwhich presents an opportunity to measure public opinion change at a\nqualitatively different scale of resolution and context.\n  In this paper, we present a conceptual model of observed opinion change on\nonline platforms and apply it to study public discourse on Universal Basic\nIncome (UBI) on Reddit throughout its history. UBI is a periodic,\nno-strings-attached cash payment given to every citizen of a population. We\nstudy UBI as it is a clearly-defined policy proposal that has recently\nexperienced a surge of interest through trends like automation and events like\nthe COVID-19 pandemic. We find that overall stance towards UBI on Reddit\nsignificantly declined until mid-2019, when this historical trend suddenly\nreversed and Reddit became substantially more supportive. Using our model, we\nfind the most significant drivers of this overall stance change were shifts\nwithin different user cohorts, within communities that represented similar\naffluence levels, and within communities that represented similar partisan\nleanings. Our method identifies nuanced social drivers of opinion change in the\nlarge-scale public discourse that now regularly occurs online, and could be\napplied to a broad set of other important issues and policies.", "comment": "ICWSM 2025", "pdf_url": "http://arxiv.org/pdf/2312.09611v2", "cate": "cs.CY", "date": "2023-12-15", "updated": "2025-07-14"}
{"id": "2506.00355", "title": "Pinching Antenna-Aided Wireless Powered Communication Networks", "authors": ["Yixuan Li", "Hongbo Xu", "Ming Zeng", "Yuanwei Liu"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.00355v2", "summary": "In this letter, we investigate a novel pinching antenna (PA)-aided wireless\npowered communication network (WPCN), in which multiple PAs are activated along\na waveguide to establish robust line-of-sight links with multiple devices. Both\ntime division multiple access (TDMA) and non-orthogonal multiple access (NOMA)\nprotocols are considered in the PA-WPCN. Moreover, some practical\nconsiderations, including a proportional power model for the PAs, a waveguide\ntransmission loss model, and a nonlinear energy harvesting model, are\nincorporated into the PA-WPCN. Furthermore, we formulate a sum-rate\nmaximization problem by jointly optimizing resource allocation and PAs\nposition. To address the challenging problem of the PAs position optimization,\nwe propose a high-performance element-wise (EW) algorithm and a low-complexity\nstochastic parameter differential evolution (SPDE) algorithm. Numerical results\nvalidate the remarkable performance of the proposed PA-WPCN and the\neffectiveness of our algorithms, indicating that optimal performance is\nattained when the PA power distribution ratio of approximately 0.55-0.6.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.00355v2", "cate": "cs.NI", "date": "2025-05-31", "updated": "2025-07-15"}
{"id": "2507.11534", "title": "Sharp Error-Rate Transitions in Quantum QC-LDPC Codes under Joint BP Decoding", "authors": ["Daiki Komoto", "Kenta Kasai"], "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11534v1", "summary": "In this study, we report that quantum quasi-cyclic low-density parity-check\ncodes decoded via joint belief propagation (BP) exhibit steep error-rate\ncurves, despite the presence of error floors. To the best of our knowledge,\nthis is the first observation of such threshold-like behavior for quantum codes\nwith non-vanishing coding rate, excluding those decoded with non-binary BP\ndecoders. Moreover, we find that dominant error events contributing to the\nerror floor typically involve only a small number of bits. These findings\nsuggest that the error floor is caused by trapping sets -- specific subgraph\nstructures in the Tanner graph -- and indicate that identifying and avoiding\nsuch structures may lead to further reduction of the error floor.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11534v1", "cate": "quant-ph", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2407.10867", "title": "Provable Robustness of (Graph) Neural Networks Against Data Poisoning and Backdoor Attacks", "authors": ["Lukas Gosch", "Mahalakshmi Sabanayagam", "Debarghya Ghoshdastidar", "Stephan Günnemann"], "categories": ["cs.LG", "cs.CR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published in TMLR. Best Paper Award at the AdvML-Frontiers @ NeurIPS 2024 workshop. Code available at this https URL", "url": "http://arxiv.org/abs/2407.10867v3", "summary": "Generalization of machine learning models can be severely compromised by data\npoisoning, where adversarial changes are applied to the training data. This\nvulnerability has led to interest in certifying (i.e., proving) that such\nchanges up to a certain magnitude do not affect test predictions. We, for the\nfirst time, certify Graph Neural Networks (GNNs) against poisoning attacks,\nincluding backdoors, targeting the node features of a given graph. Our\ncertificates are white-box and based upon $(i)$ the neural tangent kernel,\nwhich characterizes the training dynamics of sufficiently wide networks; and\n$(ii)$ a novel reformulation of the bilevel optimization problem describing\npoisoning as a mixed-integer linear program. Consequently, we leverage our\nframework to provide fundamental insights into the role of graph structure and\nits connectivity on the worst-case robustness behavior of convolution-based and\nPageRank-based GNNs. We note that our framework is more general and constitutes\nthe first approach to derive white-box poisoning certificates for NNs, which\ncan be of independent interest beyond graph-related tasks.", "comment": "Published in TMLR. Best Paper Award at the AdvML-Frontiers @ NeurIPS\n  2024 workshop. Code available at https://github.com/saper0/qpcert", "pdf_url": "http://arxiv.org/pdf/2407.10867v3", "cate": "cs.LG", "date": "2024-07-15", "updated": "2025-07-15"}
{"id": "2507.11345", "title": "Acting and Planning with Hierarchical Operational Models on a Mobile Robot: A Study with RAE+UPOM", "authors": ["Oscar Lima", "Marc Vinci", "Sunandita Patra", "Sebastian Stock", "Joachim Hertzberg", "Martin Atzmueller", "Malik Ghallab", "Dana Nau", "Paolo Traverso"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted in ECMR 2025 conference", "url": "http://arxiv.org/abs/2507.11345v1", "summary": "Robotic task execution faces challenges due to the inconsistency between\nsymbolic planner models and the rich control structures actually running on the\nrobot. In this paper, we present the first physical deployment of an integrated\nactor-planner system that shares hierarchical operational models for both\nacting and planning, interleaving the Reactive Acting Engine (RAE) with an\nanytime UCT-like Monte Carlo planner (UPOM). We implement RAE+UPOM on a mobile\nmanipulator in a real-world deployment for an object collection task. Our\nexperiments demonstrate robust task execution under action failures and sensor\nnoise, and provide empirical insights into the interleaved acting-and-planning\ndecision making process.", "comment": "Accepted in ECMR 2025 conference", "pdf_url": "http://arxiv.org/pdf/2507.11345v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11323", "title": "Contestability in Quantitative Argumentation", "authors": ["Xiang Yin", "Nico Potyka", "Antonio Rago", "Timotheus Kampik", "Francesca Toni"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11323v1", "summary": "Contestable AI requires that AI-driven decisions align with human\npreferences. While various forms of argumentation have been shown to support\ncontestability, Edge-Weighted Quantitative Bipolar Argumentation Frameworks\n(EW-QBAFs) have received little attention. In this work, we show how EW-QBAFs\ncan be deployed for this purpose. Specifically, we introduce the contestability\nproblem for EW-QBAFs, which asks how to modify edge weights (e.g., preferences)\nto achieve a desired strength for a specific argument of interest (i.e., a\ntopic argument). To address this problem, we propose gradient-based relation\nattribution explanations (G-RAEs), which quantify the sensitivity of the topic\nargument's strength to changes in individual edge weights, thus providing\ninterpretable guidance for weight adjustments towards contestability. Building\non G-RAEs, we develop an iterative algorithm that progressively adjusts the\nedge weights to attain the desired strength. We evaluate our approach\nexperimentally on synthetic EW-QBAFs that simulate the structural\ncharacteristics of personalised recommender systems and multi-layer\nperceptrons, and demonstrate that it can solve the problem effectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11323v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2502.18658", "title": "Assistance or Disruption? Exploring and Evaluating the Design and Trade-offs of Proactive AI Programming Support", "authors": ["Kevin Pu", "Daniel Lazaro", "Ian Arawjo", "Haijun Xia", "Ziang Xiao", "Tovi Grossman", "Yan Chen"], "categories": ["cs.HC", "cs.AI", "cs.SE"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.18658v3", "summary": "AI programming tools enable powerful code generation, and recent prototypes\nattempt to reduce user effort with proactive AI agents, but their impact on\nprogramming workflows remains unexplored. We introduce and evaluate\nCodellaborator, a design probe LLM agent that initiates programming assistance\nbased on editor activities and task context. We explored three interface\nvariants to assess trade-offs between increasingly salient AI support:\nprompt-only, proactive agent, and proactive agent with presence and context\n(Codellaborator). In a within-subject study (N=18), we find that proactive\nagents increase efficiency compared to prompt-only paradigm, but also incur\nworkflow disruptions. However, presence indicators and interaction context\nsupport alleviated disruptions and improved users' awareness of AI processes.\nWe underscore trade-offs of Codellaborator on user control, ownership, and code\nunderstanding, emphasizing the need to adapt proactivity to programming\nprocesses. Our research contributes to the design exploration and evaluation of\nproactive AI systems, presenting design implications on AI-integrated\nprogramming workflow.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.18658v3", "cate": "cs.HC", "date": "2025-02-25", "updated": "2025-07-15"}
{"id": "2507.10636", "title": "GeoHopNet: Hopfield-Augmented Sparse Spatial Attention for Dynamic UAV Site Location Problem", "authors": ["Jianing Zhi", "Xinghua Li", "Zidong Chen"], "categories": ["cs.LG", "cs.AI", "cs.NE", "cs.RO", "90B06", "I.2.8"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      12 Pages, 5 Figures", "url": "http://arxiv.org/abs/2507.10636v1", "summary": "The rapid development of urban low-altitude unmanned aerial vehicle (UAV)\neconomy poses new challenges for dynamic site selection of UAV landing points\nand supply stations. Traditional deep reinforcement learning methods face\ncomputational complexity bottlenecks, particularly with standard attention\nmechanisms, when handling large-scale urban-level location problems. This paper\nproposes GeoHopNet, a Hopfield-augmented sparse spatial attention network\nspecifically designed for dynamic UAV site location problems. Our approach\nintroduces four core innovations: (1) distance-biased multi-head attention\nmechanism that explicitly encodes spatial geometric information; (2) K-nearest\nneighbor sparse attention that reduces computational complexity from $O(N^2)$\nto $O(NK)$; (3) a modern Hopfield external memory module; and (4) a memory\nregularization strategy. Experimental results demonstrate that GeoHopNet\nextends the boundary of solvable problem sizes. For large-scale instances with\n1,000 nodes, where standard attention models become prohibitively slow (over 3\nseconds per instance) and traditional solvers fail, GeoHopNet finds\nhigh-quality solutions (0.22\\% optimality gap) in under 0.1 seconds. Compared\nto the state-of-the-art ADNet baseline on 100-node instances, our method\nimproves solution quality by 22.2\\% and is 1.8$\\times$ faster.", "comment": "12 Pages, 5 Figures", "pdf_url": "http://arxiv.org/pdf/2507.10636v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10977", "title": "Conceptualizing Multi-scale Wavelet Attention and Ray-based Encoding for Human-Object Interaction Detection", "authors": ["Quan Bi Pay", "Vishnu Monn Baskaran", "Junn Yong Loo", "KokSheik Wong", "Simon See"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at International Joint Conference on Neural Networks (IJCNN 2025)", "url": "http://arxiv.org/abs/2507.10977v1", "summary": "Human-object interaction (HOI) detection is essential for accurately\nlocalizing and characterizing interactions between humans and objects,\nproviding a comprehensive understanding of complex visual scenes across various\ndomains. However, existing HOI detectors often struggle to deliver reliable\npredictions efficiently, relying on resource-intensive training methods and\ninefficient architectures. To address these challenges, we conceptualize a\nwavelet attention-like backbone and a novel ray-based encoder architecture\ntailored for HOI detection. Our wavelet backbone addresses the limitations of\nexpressing middle-order interactions by aggregating discriminative features\nfrom the low- and high-order interactions extracted from diverse convolutional\nfilters. Concurrently, the ray-based encoder facilitates multi-scale attention\nby optimizing the focus of the decoder on relevant regions of interest and\nmitigating computational overhead. As a result of harnessing the attenuated\nintensity of learnable ray origins, our decoder aligns query embeddings with\nemphasized regions of interest for accurate predictions. Experimental results\non benchmark datasets, including ImageNet and HICO-DET, showcase the potential\nof our proposed architecture. The code is publicly available at\n[https://github.com/henry-pay/RayEncoder].", "comment": "Accepted at International Joint Conference on Neural Networks (IJCNN\n  2025)", "pdf_url": "http://arxiv.org/pdf/2507.10977v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11199", "title": "New Formulation of DNN Statistical Mutation Killing for Ensuring Monotonicity: A Technical Report", "authors": ["Jinhan Kim", "Nargiz Humbatova", "Gunel Jahangirova", "Shin Yoo", "Paolo Tonella"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11199v1", "summary": "Mutation testing has emerged as a powerful technique for evaluating the\neffectiveness of test suites for Deep Neural Networks. Among existing\napproaches, the statistical mutant killing criterion of DeepCrime has leveraged\nstatistical testing to determine whether a mutant significantly differs from\nthe original model. However, it suffers from a critical limitation: it violates\nthe monotonicity property, meaning that expanding a test set may result in\npreviously killed mutants no longer being classified as killed. In this\ntechnical report, we propose a new formulation of statistical mutant killing\nbased on Fisher exact test that preserves the statistical rigour of it while\nensuring monotonicity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11199v1", "cate": "cs.SE", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2504.12355", "title": "Leveraging Large Language Models for Multi-Class and Multi-Label Detection of Drug Use and Overdose Symptoms on Social Media", "authors": ["Muhammad Ahmad", "Fida Ullah", "Muhammad Usman", "Umyh Habiba", "ldar Batyrshin", "Grigori Sidorov"], "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.12355v3", "summary": "Drug overdose remains a critical global health issue, often driven by misuse\nof opioids, painkillers, and psychiatric medications. Traditional research\nmethods face limitations, whereas social media offers real-time insights into\nself-reported substance use and overdose symptoms. This study proposes an\nAI-driven NLP framework trained on annotated social media data to detect\ncommonly used drugs and associated overdose symptoms. Using a hybrid annotation\nstrategy with LLMs and human annotators, we applied traditional ML models,\nneural networks, and advanced transformer-based models. Our framework achieved\n98% accuracy in multi-class and 97% in multi-label classification,\noutperforming baseline models by up to 8%. These findings highlight the\npotential of AI for supporting public health surveillance and personalized\nintervention strategies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.12355v3", "cate": "cs.CL", "date": "2025-04-16", "updated": "2025-07-15"}
{"id": "2507.03401", "title": "AoI-Energy-Spectrum Optimization in Post-Disaster Powered Communication Intelligent Network via Hierarchical Heterogeneous Graph Neural Network", "authors": ["Hanjian Liu", "Jinsong Gui", "Xiaoheng Deng"], "categories": ["cs.NI", "eess.SP"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03401v2", "summary": "This paper designs a post-disaster powered communication intelligent network\n(PDPCIN) to address communication disruptions caused by ground base station\n(GBS) failures within the post-disaster area. PDPCIN employs unmanned aerial\nvehicles (UAVs) to provide wireless data collection (WDC) and wireless energy\ntransmission (WET) for affected areas and leverages low earth orbit satellites\n(LEO SATs) to relay UAV data to the nearest survival GBS. To ensure basic\npost-disaster communication while co-optimizing age of information (AoI),\nenergy efficiency, and spectrum efficiency, intelligent synchronization-UAV\n(IS-UAV) architecture, AoI-based four thresholds updating (AFTU) mechanism, and\nDynamic multi-LEO access (DMLA) strategy are proposed. However, three key\nchallenges remain: time-varying task-resource imbalances, complex topology\ncaused by multi-device scheduling, and nonlinear coupling in multidimensional\nmetric optimization, making system optimization NP-hard. Therefore, this paper\nproposes a hierarchical heterogeneous graph neural networks (HHGNN) framework.\nIt models heterogeneous device nodes and their communication relations as a\nhierarchical heterogeneous graph structure, integrating our defined graph\nsensing, exchange, and mask layer to handle the network's input, feature\npropagation, and output. To search appropriate number of single-LEO SATs, we\npropose single-LEO SAT density optimization (S-LSDO) algorithm. Finally, we\ncompare the proposed scheme with state-of-the-art benchmarks to validate its\nsuperior collaborative optimization of AoI, energy efficiency, and spectrum\nefficiency. Based on this, we derive the expressions for the expected values of\nAoI and stagnant AoI proportion.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03401v2", "cate": "cs.NI", "date": "2025-07-04", "updated": "2025-07-15"}
{"id": "2111.06105", "title": "Multivariate Analytic Combinatorics for Cost Constrained Channels", "authors": ["Andreas Lenz", "Stephen Melczer", "Cyrus Rashtchian", "Paul H. Siegel"], "categories": ["cs.IT", "cs.CC", "cs.DM", "math.CO", "math.IT", "E.4"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Updated version", "url": "http://arxiv.org/abs/2111.06105v5", "summary": "Analytic combinatorics in several variables is a branch of mathematics that\ndeals with deriving the asymptotic behavior of combinatorial quantities by\nanalyzing multivariate generating functions. We study information-theoretic\nquestions about sequences in a discrete noiseless channel under cost\nconstraints. Our main contributions involve the relationship between the graph\nstructure of the channel and the singularities of the bivariate generating\nfunction whose coefficients are the number of sequences satisfying the\nconstraints. We use these new results to invoke theorems from multivariate\nanalytic combinatorics to obtain the asymptotic behavior of the number of\ncost-limited strings that are admissible by the channel. This builds a new\nbridge between analytic combinatorics in several variables and labeled weighted\ngraphs, bringing a new perspective and a set of powerful results to the\nliterature of cost-constrained channels. Along the way, we show that the\ncost-constrained channel capacity is determined by a cost-dependent singularity\nof the bivariate generating function, generalizing Shannon's classical result\nfor unconstrained capacity, and provide a new proof of the equivalence of the\ncombinatorial and probabilistic definitions of the cost-constrained capacity.", "comment": "Updated version", "pdf_url": "http://arxiv.org/pdf/2111.06105v5", "cate": "cs.IT", "date": "2021-11-11", "updated": "2025-07-14"}
{"id": "2502.16366", "title": "A Generative Approach to LLM Harmfulness Detection with Special Red Flag Tokens", "authors": ["Sophie Xhonneux", "David Dobre", "Mehrnaz Mofakhami", "Leo Schwinn", "Gauthier Gidel"], "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      14 pages, 6 figures", "url": "http://arxiv.org/abs/2502.16366v3", "summary": "Most safety training methods for large language models (LLMs) are based on\nfine-tuning that forces models to shift from an unsafe answer to refusal when\nfaced with harmful requests. Unfortunately, these drastic distribution shifts\ngenerally compromise model capabilities. To avoid that, we propose to expand\nthe model's vocabulary with a special token we call red flag token (<rf>) and\npropose to train the model to insert this token into its response at any time\nwhen harmful content is generated or about to be generated. Our approach offers\nseveral advantages: it enables the model to explicitly learn the concept of\nharmfulness while marginally affecting the generated distribution, thus\nmaintaining the model's utility. It also evaluates each generated answer and\nprovides robustness as good as adversarial training without the need to run\nattacks during training. Moreover, by encapsulating our safety tuning in a LoRA\nmodule, we provide additional defenses against fine-tuning API attacks.", "comment": "14 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2502.16366v3", "cate": "cs.CL", "date": "2025-02-22", "updated": "2025-07-15"}
{"id": "2507.11402", "title": "From Production Logistics to Smart Manufacturing: The Vision for a New RoboCup Industrial League", "authors": ["Supun Dissanayaka", "Alexander Ferrein", "Till Hofmann", "Kosuke Nakajima", "Mario Sanz-Lopez", "Jesus Savage", "Daniel Swoboda", "Matteo Tschesche", "Wataru Uemura", "Tarik Viehmann", "Shohei Yasuda"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      RoboCup Symposium 2025", "url": "http://arxiv.org/abs/2507.11402v1", "summary": "The RoboCup Logistics League is a RoboCup competition in a smart factory\nscenario that has focused on task planning, job scheduling, and multi-agent\ncoordination. The focus on production logistics allowed teams to develop highly\ncompetitive strategies, but also meant that some recent developments in the\ncontext of smart manufacturing are not reflected in the competition, weakening\nits relevance over the years. In this paper, we describe the vision for the\nRoboCup Smart Manufacturing League, a new competition designed as a larger\nsmart manufacturing scenario, reflecting all the major aspects of a modern\nfactory. It will consist of several tracks that are initially independent but\ngradually combined into one smart manufacturing scenario. The new tracks will\ncover industrial robotics challenges such as assembly, human-robot\ncollaboration, and humanoid robotics, but also retain a focus on production\nlogistics. We expect the reenvisioned competition to be more attractive to\nnewcomers and well-tried teams, while also shifting the focus to current and\nfuture challenges of industrial robotics.", "comment": "RoboCup Symposium 2025", "pdf_url": "http://arxiv.org/pdf/2507.11402v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11334", "title": "CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking", "authors": ["Yuehao Huang", "Liang Liu", "Shuangming Lei", "Yukai Ma", "Hao Su", "Jianbiao Mei", "Pengxiang Zhao", "Yaqing Gu", "Yong Liu", "Jiajun Lv"], "categories": ["cs.AI", "cs.RO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by ACM MM 2025", "url": "http://arxiv.org/abs/2507.11334v1", "summary": "Mobile robots are increasingly required to navigate and interact within\nunknown and unstructured environments to meet human demands. Demand-driven\nnavigation (DDN) enables robots to identify and locate objects based on\nimplicit human intent, even when object locations are unknown. However,\ntraditional data-driven DDN methods rely on pre-collected data for model\ntraining and decision-making, limiting their generalization capability in\nunseen scenarios. In this paper, we propose CogDDN, a VLM-based framework that\nemulates the human cognitive and learning mechanisms by integrating fast and\nslow thinking systems and selectively identifying key objects essential to\nfulfilling user demands. CogDDN identifies appropriate target objects by\nsemantically aligning detected objects with the given instructions.\nFurthermore, it incorporates a dual-process decision-making module, comprising\na Heuristic Process for rapid, efficient decisions and an Analytic Process that\nanalyzes past errors, accumulates them in a knowledge base, and continuously\nimproves performance. Chain of Thought (CoT) reasoning strengthens the\ndecision-making process. Extensive closed-loop evaluations on the AI2Thor\nsimulator with the ProcThor dataset show that CogDDN outperforms single-view\ncamera-only methods by 15%, demonstrating significant improvements in\nnavigation accuracy and adaptability. The project page is available at\nhttps://yuehaohuang.github.io/CogDDN/.", "comment": "Accepted by ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2507.11334v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2503.08836", "title": "A Critical Analysis of the Usage of Dimensionality Reduction in Four Domains", "authors": ["Dylan Cashman", "Mark Keller", "Hyeon Jeon", "Bum Chul Kwon", "Qianwen Wang"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE Transactions on Visualization and Computer Graphics, to be presented at IEEE Visualization conference", "url": "http://arxiv.org/abs/2503.08836v2", "summary": "Dimensionality reduction is used as an important tool for unraveling the\ncomplexities of high-dimensional datasets in many fields of science, such as\ncell biology, chemical informatics, and physics. Visualizations of the\ndimensionally reduced data enable scientists to delve into the intrinsic\nstructures of their datasets and align them with established hypotheses.\nVisualization researchers have thus proposed many dimensionality reduction\nmethods and interactive systems designed to uncover latent structures. At the\nsame time, different scientific domains have formulated guidelines or common\nworkflows for using dimensionality reduction techniques and visualizations for\ntheir respective fields. In this work, we present a critical analysis of the\nusage of dimensionality reduction in scientific domains outside of computer\nscience. First, we conduct a bibliometric analysis of 21,249 academic\npublications that use dimensionality reduction to observe differences in the\nfrequency of techniques across fields. Next, we conduct a survey of a 71-paper\nsample from four fields: biology, chemistry, physics, and business. Through\nthis survey, we uncover common workflows, processes, and usage patterns,\nincluding the mixed use of confirmatory data analysis to validate a dataset and\nprojection method and exploratory data analysis to then generate more\nhypotheses. We also find that misinterpretations and inappropriate usage is\ncommon, particularly in the visual interpretation of the resulting\ndimensionally reduced view. Lastly, we compare our observations with recent\nworks in the visualization community in order to match work within our\ncommunity to potential areas of impact outside our community.", "comment": "Accepted at IEEE Transactions on Visualization and Computer Graphics,\n  to be presented at IEEE Visualization conference", "pdf_url": "http://arxiv.org/pdf/2503.08836v2", "cate": "cs.HC", "date": "2025-03-11", "updated": "2025-07-15"}
{"id": "2507.10637", "title": "A Simple Baseline for Stable and Plastic Neural Networks", "authors": ["É. Künzel", "A. Jaziri", "V. Ramesh"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 50 figures", "url": "http://arxiv.org/abs/2507.10637v1", "summary": "Continual learning in computer vision requires that models adapt to a\ncontinuous stream of tasks without forgetting prior knowledge, yet existing\napproaches often tip the balance heavily toward either plasticity or stability.\nWe introduce RDBP, a simple, low-overhead baseline that unites two\ncomplementary mechanisms: ReLUDown, a lightweight activation modification that\npreserves feature sensitivity while preventing neuron dormancy, and Decreasing\nBackpropagation, a biologically inspired gradient-scheduling scheme that\nprogressively shields early layers from catastrophic updates. Evaluated on the\nContinual ImageNet benchmark, RDBP matches or exceeds the plasticity and\nstability of state-of-the-art methods while reducing computational cost. RDBP\nthus provides both a practical solution for real-world continual learning and a\nclear benchmark against which future continual learning strategies can be\nmeasured.", "comment": "11 pages, 50 figures", "pdf_url": "http://arxiv.org/pdf/2507.10637v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10978", "title": "Mind the Gap: Bridging Occlusion in Gait Recognition via Residual Gap Correction", "authors": ["Ayush Gupta", "Siyuan Huang", "Rama Chellappa"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at IJCB 2025", "url": "http://arxiv.org/abs/2507.10978v1", "summary": "Gait is becoming popular as a method of person re-identification because of\nits ability to identify people at a distance. However, most current works in\ngait recognition do not address the practical problem of occlusions. Among\nthose which do, some require paired tuples of occluded and holistic sequences,\nwhich are impractical to collect in the real world. Further, these approaches\nwork on occlusions but fail to retain performance on holistic inputs. To\naddress these challenges, we propose RG-Gait, a method for residual correction\nfor occluded gait recognition with holistic retention. We model the problem as\na residual learning task, conceptualizing the occluded gait signature as a\nresidual deviation from the holistic gait representation. Our proposed network\nadaptively integrates the learned residual, significantly improving performance\non occluded gait sequences without compromising the holistic recognition\naccuracy. We evaluate our approach on the challenging Gait3D, GREW and BRIAR\ndatasets and show that learning the residual can be an effective technique to\ntackle occluded gait recognition with holistic retention.", "comment": "Accepted at IJCB 2025", "pdf_url": "http://arxiv.org/pdf/2507.10978v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11272", "title": "An Empirical Study of Multi-Agent RAG for Real-World University Admissions Counseling", "authors": ["Anh Nguyen-Duc", "Chien Vu Manh", "Bao Anh Tran", "Viet Phuong Ngo", "Luan Le Chi", "Anh Quang Nguyen"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11272v1", "summary": "This paper presents MARAUS (Multi-Agent and Retrieval-Augmented University\nAdmission System), a real-world deployment of a conversational AI platform for\nhigher education admissions counseling in Vietnam. While large language models\n(LLMs) offer potential for automating advisory tasks, most existing solutions\nremain limited to prototypes or synthetic benchmarks. MARAUS addresses this gap\nby combining hybrid retrieval, multi-agent orchestration, and LLM-based\ngeneration into a system tailored for real-world university admissions. In\ncollaboration with the University of Transport Technology (UTT) in Hanoi, we\nconducted a two-phase study involving technical development and real-world\nevaluation. MARAUS processed over 6,000 actual user interactions, spanning six\ncategories of queries. Results show substantial improvements over LLM-only\nbaselines: on average 92 percent accuracy, hallucination rates reduced from 15\nprecent to 1.45 percent, and average response times below 4 seconds. The system\noperated cost-effectively, with a two-week deployment cost of 11.58 USD using\nGPT-4o mini. This work provides actionable insights for the deployment of\nagentic RAG systems in low-resource educational settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11272v1", "cate": "cs.SE", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.09719", "title": "Power Consumption Analysis of QKD Networks under Different Protocols and Detector Configurations", "authors": ["Jiaheng Xiong", "Qiaolun Zhang", "Yoann Piétri", "Raja Yehia", "Raouf Boutaba", "Francesco Musumeci", "Massimo Tornatore"], "categories": ["quant-ph", "cs.NI"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      This version of the paper was uploaded without the prior approval of all listed authors. Some authors did not fully review and confirm the content, leading to unresolved concerns about clarity and accuracy. We intend to address these issues through further discussions and will resubmit after obtaining consent from all authors", "url": "http://arxiv.org/abs/2507.09719v2", "summary": "We analyze the power consumption of quantum key distribution (QKD) networks\nunder various protocol and detector configurations. Using realistic network\ntopologies, we evaluate discrete-variable vs continuous-variable QKD and\noptimize device placement, quantifying power trade-offs of SNSPD vs APD\ndetectors and the benefits of optical bypass.", "comment": "This version of the paper was uploaded without the prior approval of\n  all listed authors. Some authors did not fully review and confirm the\n  content, leading to unresolved concerns about clarity and accuracy. We intend\n  to address these issues through further discussions and will resubmit after\n  obtaining consent from all authors", "pdf_url": "http://arxiv.org/pdf/2507.09719v2", "cate": "quant-ph", "date": "2025-07-13", "updated": "2025-07-15"}
{"id": "2412.03956", "title": "Blind and Topological Interference Managements for Bistatic Integrated Sensing and Communication", "authors": ["Jiayu Liu", "Kai Wan", "Xinping Yi", "Robert Caiming Qiu", "Giuseppe Caire"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.03956v5", "summary": "Integrated sensing and communication (ISAC) systems provide significant\nenhancements in performance and resource efficiency compared to individual\nsensing and communication systems, primarily attributed to the collaborative\nuse of wireless resources, radio waveforms, and hardware platforms. This paper\nfocuses on the bistatic ISAC systems with dispersed multi-receiver and one\nsensor. Compared to a monostatic ISAC system, the main challenge in the\nbistatic setting is that the information messages are unknown to the sensor and\ntherefore they are seen as interference, while the channel between the\ntransmitters (TX) and the sensor is unknown to the transmitters. In order to\nmitigate the interference at the sensor while maximizing the communication\ndegree of freedom, we introduce two strategies, namely, blind interference\nalignment and topological interference management. Although well-known in the\ncontext of Gaussian interference channels, these strategies are novel in the\ncontext of bistatic ISAC. For the bistatic ISAC models with heterogeneous\ncoherence times or with heterogeneous connectivity, the achieved ISAC tradeoff\npoints in terms of communication and sensing degrees of freedom are\ncharacterized. In particular, we show that the new tradeoff outperforms the\ntime-sharing between the sensing-only and the communication-only schemes.\nSimulation results demonstrate that the proposed schemes significantly improve\nthe channel estimation error for the sensing task, compared to treating\ninterference as noise at the sensor and successive interference cancellation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.03956v5", "cate": "cs.IT", "date": "2024-12-05", "updated": "2025-07-15"}
{"id": "2504.01550", "title": "Representation Bending for Large Language Model Safety", "authors": ["Ashkan Yousefpour", "Taeheon Kim", "Ryan S. Kwon", "Seungbeen Lee", "Wonje Jeung", "Seungju Han", "Alvin Wan", "Harrison Ngan", "Youngjae Yu", "Jonghyun Choi"], "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025 (main)", "url": "http://arxiv.org/abs/2504.01550v3", "summary": "Large Language Models (LLMs) have emerged as powerful tools, but their\ninherent safety risks - ranging from harmful content generation to broader\nsocietal harms - pose significant challenges. These risks can be amplified by\nthe recent adversarial attacks, fine-tuning vulnerabilities, and the increasing\ndeployment of LLMs in high-stakes environments. Existing safety-enhancing\ntechniques, such as fine-tuning with human feedback or adversarial training,\nare still vulnerable as they address specific threats and often fail to\ngeneralize across unseen attacks, or require manual system-level defenses. This\npaper introduces RepBend, a novel approach that fundamentally disrupts the\nrepresentations underlying harmful behaviors in LLMs, offering a scalable\nsolution to enhance (potentially inherent) safety. RepBend brings the idea of\nactivation steering - simple vector arithmetic for steering model's behavior\nduring inference - to loss-based fine-tuning. Through extensive evaluation,\nRepBend achieves state-of-the-art performance, outperforming prior methods such\nas Circuit Breaker, RMU, and NPO, with up to 95% reduction in attack success\nrates across diverse jailbreak benchmarks, all with negligible reduction in\nmodel usability and general capabilities.", "comment": "Accepted to ACL 2025 (main)", "pdf_url": "http://arxiv.org/pdf/2504.01550v3", "cate": "cs.LG", "date": "2025-04-02", "updated": "2025-07-15"}
{"id": "2507.11447", "title": "Multi-IMU Sensor Fusion for Legged Robots", "authors": ["Shuo Yang", "John Z. Zhang", "Ibrahima Sory Sow", "Zachary Manchester"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      16 pages", "url": "http://arxiv.org/abs/2507.11447v1", "summary": "This paper presents a state-estimation solution for legged robots that uses a\nset of low-cost, compact, and lightweight sensors to achieve low-drift pose and\nvelocity estimation under challenging locomotion conditions. The key idea is to\nleverage multiple inertial measurement units on different links of the robot to\ncorrect a major error source in standard proprioceptive odometry. We fuse the\ninertial sensor information and joint encoder measurements in an extended\nKalman filter, then combine the velocity estimate from this filter with camera\ndata in a factor-graph-based sliding-window estimator to form a\nvisual-inertial-leg odometry method. We validate our state estimator through\ncomprehensive theoretical analysis and hardware experiments performed using\nreal-world robot data collected during a variety of challenging locomotion\ntasks. Our algorithm consistently achieves minimal position deviation, even in\nscenarios involving substantial ground impact, foot slippage, and sudden body\nrotations. A C++ implementation, along with a large-scale dataset, is available\nat https://github.com/ShuoYangRobotics/Cerberus2.0.", "comment": "16 pages", "pdf_url": "http://arxiv.org/pdf/2507.11447v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11352", "title": "Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces", "authors": ["Yunhao Yang", "Neel P. Bhatt", "Christian Ellis", "Alvaro Velasquez", "Zhangyang Wang", "Ufuk Topcu"], "categories": ["cs.AI", "cs.FL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11352v1", "summary": "Logistics operators, from battlefield coordinators rerouting airlifts ahead\nof a storm to warehouse managers juggling late trucks, often face life-critical\ndecisions that demand both domain expertise and rapid and continuous\nreplanning. While popular methods like integer programming yield logistics\nplans that satisfy user-defined logical constraints, they are slow and assume\nan idealized mathematical model of the environment that does not account for\nuncertainty. On the other hand, large language models (LLMs) can handle\nuncertainty and promise to accelerate replanning while lowering the barrier to\nentry by translating free-form utterances into executable plans, yet they\nremain prone to misinterpretations and hallucinations that jeopardize safety\nand cost. We introduce a neurosymbolic framework that pairs the accessibility\nof natural-language dialogue with verifiable guarantees on goal interpretation.\nIt converts user requests into structured planning specifications, quantifies\nits own uncertainty at the field and token level, and invokes an interactive\nclarification loop whenever confidence falls below an adaptive threshold. A\nlightweight model, fine-tuned on just 100 uncertainty-filtered examples,\nsurpasses the zero-shot performance of GPT-4.1 while cutting inference latency\nby nearly 50%. These preliminary results highlight a practical path toward\ncertifiable, real-time, and user-aligned decision-making for complex logistics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11352v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2503.15511", "title": "The Trust Calibration Maturity Model for Characterizing and Communicating Trustworthiness of AI Systems", "authors": ["Scott T Steinmetz", "Asmeret Naugle", "Paul Schutte", "Matt Sweitzer", "Alex Washburne", "Lisa Linville", "Daniel Krofcheck", "Michal Kucer", "Samuel Myren"], "categories": ["cs.HC", "cs.CY", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      19 pages, 4 figures, 2 tables", "url": "http://arxiv.org/abs/2503.15511v2", "summary": "Recent proliferation of powerful AI systems has created a strong need for\ncapabilities that help users to calibrate trust in those systems. As AI systems\ngrow in scale, information required to evaluate their trustworthiness becomes\nless accessible, presenting a growing risk of using these systems\ninappropriately. We propose the Trust Calibration Maturity Model (TCMM) to\ncharacterize and communicate information about AI system trustworthiness. The\nTCMM incorporates five dimensions of analytic maturity: Performance\nCharacterization, Bias & Robustness Quantification, Transparency, Safety &\nSecurity, and Usability. The TCMM can be presented along with system\nperformance information to (1) help a user to appropriately calibrate trust,\n(2) establish requirements and track progress, and (3) identify research needs.\nHere, we discuss the TCMM and demonstrate it on two target tasks: using ChatGPT\nfor high consequence nuclear science determinations, and using PhaseNet (an\nensemble of seismic models) for categorizing sources of seismic events.", "comment": "19 pages, 4 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2503.15511v2", "cate": "cs.HC", "date": "2025-01-28", "updated": "2025-07-14"}
{"id": "2507.10638", "title": "ZClassifier: Temperature Tuning and Manifold Approximation via KL Divergence on Logit Space", "authors": ["Shim Soon Yong"], "categories": ["cs.LG", "I.2.6; I.5.1"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10638v1", "summary": "We introduce a novel classification framework, ZClassifier, that replaces\nconventional deterministic logits with diagonal Gaussian-distributed logits.\nOur method simultaneously addresses temperature scaling and manifold\napproximation by minimizing the Kullback-Leibler (KL) divergence between the\npredicted Gaussian distributions and a unit isotropic Gaussian. This unifies\nuncertainty calibration and latent control in a principled probabilistic\nmanner, enabling a natural interpretation of class confidence and geometric\nconsistency. Experiments on CIFAR-10 and CIFAR-100 show that ZClassifier\nimproves over softmax classifiers in robustness, calibration, and latent\nseparation. We also demonstrate its effectiveness for classifier-guided\ngeneration by interpreting logits as Gaussian semantic potentials.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10638v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10999", "title": "SpaRTAN: Spatial Reinforcement Token-based Aggregation Network for Visual Recognition", "authors": ["Quan Bi Pay", "Vishnu Monn Baskaran", "Junn Yong Loo", "KokSheik Wong", "Simon See"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at International Joint Conference on Neural Networks (IJCNN 2025)", "url": "http://arxiv.org/abs/2507.10999v1", "summary": "The resurgence of convolutional neural networks (CNNs) in visual recognition\ntasks, exemplified by ConvNeXt, has demonstrated their capability to rival\ntransformer-based architectures through advanced training methodologies and\nViT-inspired design principles. However, both CNNs and transformers exhibit a\nsimplicity bias, favoring straightforward features over complex structural\nrepresentations. Furthermore, modern CNNs often integrate MLP-like blocks akin\nto those in transformers, but these blocks suffer from significant information\nredundancies, necessitating high expansion ratios to sustain competitive\nperformance. To address these limitations, we propose SpaRTAN, a lightweight\narchitectural design that enhances spatial and channel-wise information\nprocessing. SpaRTAN employs kernels with varying receptive fields, controlled\nby kernel size and dilation factor, to capture discriminative multi-order\nspatial features effectively. A wave-based channel aggregation module further\nmodulates and reinforces pixel interactions, mitigating channel-wise\nredundancies. Combining the two modules, the proposed network can efficiently\ngather and dynamically contextualize discriminative features. Experimental\nresults in ImageNet and COCO demonstrate that SpaRTAN achieves remarkable\nparameter efficiency while maintaining competitive performance. In particular,\non the ImageNet-1k benchmark, SpaRTAN achieves 77. 7% accuracy with only 3.8M\nparameters and approximately 1.0 GFLOPs, demonstrating its ability to deliver\nstrong performance through an efficient design. On the COCO benchmark, it\nachieves 50.0% AP, surpassing the previous benchmark by 1.2% with only 21.5M\nparameters. The code is publicly available at\n[https://github.com/henry-pay/SpaRTAN].", "comment": "Accepted at International Joint Conference on Neural Networks (IJCNN\n  2025)", "pdf_url": "http://arxiv.org/pdf/2507.10999v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11346", "title": "RefModel: Detecting Refactorings using Foundation Models", "authors": ["Pedro Simões", "Rohit Gheyi", "Rian Melo", "Jonhnanthan Oliveira", "Márcio Ribeiro", "Wesley K. G. Assunção"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted at Brazilian Symposium on Software Engineering (SBES 2025)", "url": "http://arxiv.org/abs/2507.11346v1", "summary": "Refactoring is a common software engineering practice that improves code\nquality without altering program behavior. Although tools like ReExtractor+,\nRefactoringMiner, and RefDiff have been developed to detect refactorings\nautomatically, they rely on complex rule definitions and static analysis,\nmaking them difficult to extend and generalize to other programming languages.\nIn this paper, we investigate the viability of using foundation models for\nrefactoring detection, implemented in a tool named RefModel. We evaluate\nPhi4-14B, and Claude 3.5 Sonnet on a dataset of 858 single-operation\ntransformations applied to artificially generated Java programs, covering\nwidely-used refactoring types. We also extend our evaluation by including\nGemini 2.5 Pro and o4-mini-high, assessing their performance on 44 real-world\nrefactorings extracted from four open-source projects. These models are\ncompared against RefactoringMiner, RefDiff, and ReExtractor+. RefModel is\ncompetitive with, and in some cases outperform, traditional tools. In\nreal-world settings, Claude 3.5 Sonnet and Gemini 2.5 Pro jointly identified\n97% of all refactorings, surpassing the best-performing static-analysis-based\ntools. The models showed encouraging generalization to Python and Golang. They\nprovide natural language explanations and require only a single sentence to\ndefine each refactoring type.", "comment": "Accepted at Brazilian Symposium on Software Engineering (SBES 2025)", "pdf_url": "http://arxiv.org/pdf/2507.11346v1", "cate": "cs.SE", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2501.08871", "title": "Joint Detection and Decoding: A Graph Neural Network Approach", "authors": ["Jannis Clausius", "Marvin Rübenacke", "Daniel Tandler", "Stephan ten Brink"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Submitted to Transactions on Communications (R1). arXiv admin note: text overlap with arXiv:2401.16187", "url": "http://arxiv.org/abs/2501.08871v3", "summary": "Narrowing the performance gap between optimal and feasible detection in\ninter-symbol interference (ISI) channels, this paper proposes to use graph\nneural networks (GNNs) for detection that can also be used to perform joint\ndetection and decoding (JDD). For detection, the GNN is build upon the factor\ngraph representations of the channel, while for JDD, the factor graph is\nexpanded by the Tanner graph of the parity-check matrix (PCM) of the channel\ncode, sharing the variable nodes (VNs). A particularly advantageous property of\nthe GNN is a) the robustness against cycles in the factor graphs which is the\nmain problem for sum-product algorithm (SPA)-based detection, and b) the\nrobustness against channel state information (CSI) uncertainty at the receiver.\nAdditionally, we propose using an input embedding resulting in a GNN\nindependent of the channel impulse response (CIR). Consequently, a fully deep\nlearning-based receiver enables joint optimization instead of individual\noptimization of the components, so-called end-to-end learning. Furthermore, we\npropose a parallel flooding schedule that also reduces the latency, which turns\nout to improve the error correcting performance. The proposed approach is\nanalyzed and compared to state-of-the-art baselines for different modulations\nand codes in terms of error correcting capability and latency. The gain\ncompared to SPA-based detection might be explained with improved messages\nbetween nodes and adaptive damping of messages. For a higher order modulation\nin a high-rate turbo detection and decoding (TDD) scenario the GNN shows a, at\nfirst glance, surprisingly high gain of 6.25 dB compared to the best, feasible\nnon-neural baseline.", "comment": "Submitted to Transactions on Communications (R1). arXiv admin note:\n  text overlap with arXiv:2401.16187", "pdf_url": "http://arxiv.org/pdf/2501.08871v3", "cate": "cs.IT", "date": "2025-01-15", "updated": "2025-07-15"}
{"id": "2507.10559", "title": "NLP Meets the World: Toward Improving Conversations With the Public About Natural Language Processing Research", "authors": ["Shomir Wilson"], "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10559v1", "summary": "Recent developments in large language models (LLMs) have been accompanied by\nrapidly growing public interest in natural language processing (NLP). This\nattention is reflected by major news venues, which sometimes invite NLP\nresearchers to share their knowledge and views with a wide audience.\nRecognizing the opportunities of the present, for both the research field and\nfor individual researchers, this paper shares recommendations for communicating\nwith a general audience about LLMs' capabilities and limitations. These\nrecommendations cover three themes: vague terminology as an obstacle to public\nunderstanding, unreasonable expectations as obstacles to sustainable growth,\nand ethical failures as obstacles to continued support. Published NLP research\nand popular news coverage are cited to illustrate these themes with examples.\nThe recommendations promote effective, transparent communication with the\ngeneral public about NLP, in order to strengthen public understanding and\nencourage support for research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10559v1", "cate": "cs.CY", "date": "2025-07-02", "updated": "2025-07-02"}
{"id": "2506.23644", "title": "QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration", "authors": ["Junze Hu", "Xiangyu Jin", "Yizhe Zeng", "Yuling Liu", "Yunpeng Li", "Dan Du", "Kaiyu Xie", "Hongsong Zhu"], "categories": ["cs.SE", "cs.AI", "cs.CR"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      The experimental data in the experimental section needs to be improved, and there are some errors", "url": "http://arxiv.org/abs/2506.23644v2", "summary": "We introduce QLPro, a vulnerability detection framework that systematically\nintegrates LLMs and static analysis tools to enable comprehensive vulnerability\ndetection across entire open-source projects.We constructed a new dataset,\nJavaTest, comprising 10 open-source projects from GitHub with 62 confirmed\nvulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only\n24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro\ndiscovered 6 previously unknown vulnerabilities, 2 of which have been confirmed\nas 0-days.", "comment": "The experimental data in the experimental section needs to be\n  improved, and there are some errors", "pdf_url": "http://arxiv.org/pdf/2506.23644v2", "cate": "cs.SE", "date": "2025-06-30", "updated": "2025-07-15"}
{"id": "2507.11498", "title": "Robot Drummer: Learning Rhythmic Skills for Humanoid Drumming", "authors": ["Asad Ali Shahid", "Francesco Braghin", "Loris Roveda"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11498v1", "summary": "Humanoid robots have seen remarkable advances in dexterity, balance, and\nlocomotion, yet their role in expressive domains, such as music performance,\nremains largely unexplored. Musical tasks, like drumming, present unique\nchallenges, including split-second timing, rapid contacts, and multi-limb\ncoordination over pieces lasting minutes. In this paper, we introduce Robot\nDrummer, a humanoid system capable of expressive, high-precision drumming\nacross a diverse repertoire of songs. We formulate humanoid drumming as\nsequential fulfillment of timed-contacts and transform drum scores in to a\nRhythmic Contact Chain. To handle the long-horizon nature of musical\nperformance, we decompose each piece into fixed-length segments and train a\nsingle policy across all segments in parallel using reinforcement learning.\nThrough extensive experiments on over thirty popular rock, metal, and jazz\ntracks, our results demonstrate that Robot Drummer consistently achieves high\nF1 scores. The learned behaviors exhibit emergent human-like drumming\nstrategies, such as cross-arm strikes, and adaptive sticks assignments,\ndemonstrating the potential of reinforcement learning to bring humanoid robots\ninto the domain of creative musical performance. Project page:\n\\href{https://robot-drummer.github.io}{robot-drummer.github.io}", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11498v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11467", "title": "Modeling Code: Is Text All You Need?", "authors": ["Daniel Nichols", "Konstantinos Parasyris", "Harshitha Menon", "Brian R. Bartoldson", "Giorgis Georgakoudis", "Tal Ben-Nun", "Abhinav Bhatele"], "categories": ["cs.AI", "cs.SE"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11467v1", "summary": "Code LLMs have become extremely popular recently for modeling source code\nacross a variety of tasks, such as generation, translation, and summarization.\nHowever, transformer-based models are limited in their capabilities to reason\nthrough structured, analytical properties of code, such as control and data\nflow. Previous work has explored the modeling of these properties with\nstructured data and graph neural networks. However, these approaches lack the\ngenerative capabilities and scale of modern LLMs. In this work, we introduce a\nnovel approach to combine the strengths of modeling both code as text and more\nstructured forms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11467v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2404.07078", "title": "VLLMs Provide Better Context for Emotion Understanding Through Common Sense Reasoning", "authors": ["Alexandros Xenos", "Niki Maria Foteinopoulou", "Ioanna Ntinou", "Ioannis Patras", "Georgios Tzimiropoulos"], "categories": ["cs.CV", "cs.HC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      A. Xenos, N. Foteinopoulou and I. Ntinou contributed equally to this work; 14 pages, 5 figures; Accepted at IJCNN 2025", "url": "http://arxiv.org/abs/2404.07078v2", "summary": "Recognising emotions in context involves identifying an individual's apparent\nemotions while considering contextual cues from the surrounding scene. Previous\napproaches to this task have typically designed explicit scene-encoding\narchitectures or incorporated external scene-related information, such as\ncaptions. However, these methods often utilise limited contextual information\nor rely on intricate training pipelines to decouple noise from relevant\ninformation. In this work, we leverage the capabilities of\nVision-and-Large-Language Models (VLLMs) to enhance in-context emotion\nclassification in a more straightforward manner. Our proposed method follows a\nsimple yet effective two-stage approach. First, we prompt VLLMs to generate\nnatural language descriptions of the subject's apparent emotion in relation to\nthe visual context. Second, the descriptions, along with the visual input, are\nused to train a transformer-based architecture that fuses text and visual\nfeatures before the final classification task. This method not only simplifies\nthe training process but also significantly improves performance. Experimental\nresults demonstrate that the textual descriptions effectively guide the model\nto constrain the noisy visual input, allowing our fused architecture to\noutperform individual modalities. Our approach achieves state-of-the-art\nperformance across three datasets, BoLD, EMOTIC, and CAER-S, without bells and\nwhistles. The code will be made publicly available on github:\nhttps://github.com/NickyFot/EmoCommonSense.git", "comment": "A. Xenos, N. Foteinopoulou and I. Ntinou contributed equally to this\n  work; 14 pages, 5 figures; Accepted at IJCNN 2025", "pdf_url": "http://arxiv.org/pdf/2404.07078v2", "cate": "cs.CV", "date": "2024-04-10", "updated": "2025-07-15"}
{"id": "2507.10642", "title": "First-of-its-kind AI model for bioacoustic detection using a lightweight associative memory Hopfield neural network", "authors": ["Andrew Gascoyne", "Wendy Lomas"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      12 pages, 5 figures", "url": "http://arxiv.org/abs/2507.10642v1", "summary": "A growing issue within conservation bioacoustics is the task of analysing the\nvast amount of data generated from the use of passive acoustic monitoring\ndevices. In this paper, we present an alternative AI model which has the\npotential to help alleviate this problem. Our model formulation addresses the\nkey issues encountered when using current AI models for bioacoustic analysis,\nnamely the: limited training data available; environmental impact, particularly\nin energy consumption and carbon footprint of training and implementing these\nmodels; and associated hardware requirements. The model developed in this work\nuses associative memory via a transparent, explainable Hopfield neural network\nto store signals and detect similar signals which can then be used to classify\nspecies. Training is rapid ($3$\\,ms), as only one representative signal is\nrequired for each target sound within a dataset. The model is fast, taking only\n$5.4$\\,s to pre-process and classify all $10384$ publicly available bat\nrecordings, on a standard Apple MacBook Air. The model is also lightweight with\na small memory footprint of $144.09$\\,MB of RAM usage. Hence, the low\ncomputational demands make the model ideal for use on a variety of standard\npersonal devices with potential for deployment in the field via edge-processing\ndevices. It is also competitively accurate, with up to $86\\%$ precision on the\ndataset used to evaluate the model. In fact, we could not find a single case of\ndisagreement between model and manual identification via expert field guides.\nAlthough a dataset of bat echolocation calls was chosen to demo this\nfirst-of-its-kind AI model, trained on only two representative calls, the model\nis not species specific. In conclusion, we propose an equitable AI model that\nhas the potential to be a game changer for fast, lightweight, sustainable,\ntransparent, explainable and accurate bioacoustic analysis.", "comment": "12 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.10642v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11003", "title": "Bridge Feature Matching and Cross-Modal Alignment with Mutual-filtering for Zero-shot Anomaly Detection", "authors": ["Yuhu Bai", "Jiangning Zhang", "Yunkang Cao", "Guangyuan Lu", "Qingdong He", "Xiangtai Li", "Guanzhong Tian"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11003v1", "summary": "With the advent of vision-language models (e.g., CLIP) in zero- and few-shot\nsettings, CLIP has been widely applied to zero-shot anomaly detection (ZSAD) in\nrecent research, where the rare classes are essential and expected in many\napplications. This study introduces \\textbf{FiSeCLIP} for ZSAD with\ntraining-free \\textbf{CLIP}, combining the feature matching with the\ncross-modal alignment. Testing with the entire dataset is impractical, while\nbatch-based testing better aligns with real industrial needs, and images within\na batch can serve as mutual reference points. Accordingly, FiSeCLIP utilizes\nother images in the same batch as reference information for the current image.\nHowever, the lack of labels for these references can introduce ambiguity, we\napply text information to \\textbf{fi}lter out noisy features. In addition, we\nfurther explore CLIP's inherent potential to restore its local\n\\textbf{se}mantic correlation, adapting it for fine-grained anomaly detection\ntasks to enable a more accurate filtering process. Our approach exhibits\nsuperior performance for both anomaly classification and segmentation on\nanomaly detection benchmarks, building a stronger baseline for the direction,\ne.g., on MVTec-AD, FiSeCLIP outperforms the SOTA AdaCLIP by\n+4.6\\%$\\uparrow$/+5.7\\%$\\uparrow$ in segmentation metrics AU-ROC/$F_1$-max.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11003v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11362", "title": "Security Debt in Practice: Nuanced Insights from Practitioners", "authors": ["Chaima Boufaied", "Taher Ghaleb", "Zainab Masood"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11362v1", "summary": "With the increasing reliance on software and automation nowadays, tight\ndeadlines, limited resources, and prioritization of functionality over security\ncan lead to insecure coding practices. When not handled properly, these\nconstraints cause unaddressed security vulnerabilities to accumulate over time,\nforming Security Debts (SDs). Despite their critical importance, there is\nlimited empirical evidence on how software practitioners perceive, manage, and\ncommunicate SDs in real-world settings. In this paper, we present a qualitative\nempirical study based on semi-structured interviews with 22 software\npractitioners across various roles, organizations, and countries. We address\nfour research questions: i) we assess software practitioners' knowledge of SDs\nand awareness of associated security risks, ii) we investigate their behavior\ntowards SDs, iii) we explore common tools and strategies used to mitigate SDs,\nand iv) we analyze how security risks are communicated within teams and to\ndecision makers. We observe variations in how practitioners perceive and manage\nSDs, with some prioritizing delivery speed over security, while others\nconsistently maintain security as a priority. Our findings emphasize the need\nfor stronger integration of security practices across the Software Development\nLife Cycle (SDLC), more consistent use of mitigation strategies, better\nbalancing of deadlines, resources, and security-related tasks, with attention\nto the Confidentiality, Integrity, and Availability (CIA) triad.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11362v1", "cate": "cs.SE", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2502.09065", "title": "Lowering the Error Floor of Error Correction Code Transformer", "authors": ["Taewoo Park", "Seong-Joon Park", "Hee-Youl Kwak", "Sang-Hyo Kim", "Yongjune Kim"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      6 pages", "url": "http://arxiv.org/abs/2502.09065v2", "summary": "With the success of transformer architectures across diverse applications,\nthe error correction code transformer (ECCT) has gained significant attention\nfor its superior decoding performance. In spite of its advantages, the error\nfloor problem in ECCT decoding remains unexplored. We present the first\ninvestigation into this issue, revealing that ECCT encounters error floors,\nlimiting its effectiveness in practical settings. To address this error floor\nproblem, we adopt a hybrid decoding framework that integrates ECCT with\nconventional hard decision decoders. Unlike prior hybrid decoding schemes, our\nkey contribution lies in proposing a novel loss function that explicitly takes\ninto account the interaction between ECCT and hard decision decoders during\ntraining. The proposed loss function guides ECCT to focus on residual errors\nthat are not corrected by the hard decision stages, effectively lowering the\nerror floor. Simulation results confirm that the hybrid decoder trained with\nthe proposed loss function achieves substantial performance gains over standard\nECCT in both the waterfall and the error floor regions.", "comment": "6 pages", "pdf_url": "http://arxiv.org/pdf/2502.09065v2", "cate": "cs.IT", "date": "2025-02-13", "updated": "2025-07-15"}
{"id": "2507.10579", "title": "Findings of the BEA 2025 Shared Task on Pedagogical Ability Assessment of AI-powered Tutors", "authors": ["Ekaterina Kochmar", "Kaushal Kumar Maurya", "Kseniia Petukhova", "KV Aditya Srivatsa", "Anaïs Tack", "Justin Vasselli"], "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Proceedings of the 20th Workshop on Innovative Use of NLP for Building Educational Applications", "url": "http://arxiv.org/abs/2507.10579v1", "summary": "This shared task has aimed to assess pedagogical abilities of AI tutors\npowered by large language models (LLMs), focusing on evaluating the quality of\ntutor responses aimed at student's mistake remediation within educational\ndialogues. The task consisted of five tracks designed to automatically evaluate\nthe AI tutor's performance across key dimensions of mistake identification,\nprecise location of the mistake, providing guidance, and feedback\nactionability, grounded in learning science principles that define good and\neffective tutor responses, as well as the track focusing on detection of the\ntutor identity. The task attracted over 50 international teams across all\ntracks. The submitted models were evaluated against gold-standard human\nannotations, and the results, while promising, show that there is still\nsignificant room for improvement in this domain: the best results for the four\npedagogical ability assessment tracks range between macro F1 scores of 58.34\n(for providing guidance) and 71.81 (for mistake identification) on three-class\nproblems, with the best F1 score in the tutor identification track reaching\n96.98 on a 9-class task. In this paper, we overview the main findings of the\nshared task, discuss the approaches taken by the teams, and analyze their\nperformance. All resources associated with this task are made publicly\navailable to support future research in this critical domain.", "comment": "Proceedings of the 20th Workshop on Innovative Use of NLP for\n  Building Educational Applications", "pdf_url": "http://arxiv.org/pdf/2507.10579v1", "cate": "cs.CY", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.10843", "title": "Offline Reinforcement Learning with Wasserstein Regularization via Optimal Transport Maps", "authors": ["Motoki Omura", "Yusuke Mukuta", "Kazuki Ota", "Takayuki Osa", "Tatsuya Harada"], "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at RLC 2025", "url": "http://arxiv.org/abs/2507.10843v1", "summary": "Offline reinforcement learning (RL) aims to learn an optimal policy from a\nstatic dataset, making it particularly valuable in scenarios where data\ncollection is costly, such as robotics. A major challenge in offline RL is\ndistributional shift, where the learned policy deviates from the dataset\ndistribution, potentially leading to unreliable out-of-distribution actions. To\nmitigate this issue, regularization techniques have been employed. While many\nexisting methods utilize density ratio-based measures, such as the\n$f$-divergence, for regularization, we propose an approach that utilizes the\nWasserstein distance, which is robust to out-of-distribution data and captures\nthe similarity between actions. Our method employs input-convex neural networks\n(ICNNs) to model optimal transport maps, enabling the computation of the\nWasserstein distance in a discriminator-free manner, thereby avoiding\nadversarial training and ensuring stable learning. Our approach demonstrates\ncomparable or superior performance to widely used existing methods on the D4RL\nbenchmark dataset. The code is available at\nhttps://github.com/motokiomura/Q-DOT .", "comment": "Accepted at RLC 2025", "pdf_url": "http://arxiv.org/pdf/2507.10843v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11473", "title": "Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety", "authors": ["Tomek Korbak", "Mikita Balesni", "Elizabeth Barnes", "Yoshua Bengio", "Joe Benton", "Joseph Bloom", "Mark Chen", "Alan Cooney", "Allan Dafoe", "Anca Dragan", "Scott Emmons", "Owain Evans", "David Farhi", "Ryan Greenblatt", "Dan Hendrycks", "Marius Hobbhahn", "Evan Hubinger", "Geoffrey Irving", "Erik Jenner", "Daniel Kokotajlo", "Victoria Krakovna", "Shane Legg", "David Lindner", "David Luan", "Aleksander Mądry", "Julian Michael", "Neel Nanda", "Dave Orr", "Jakub Pachocki", "Ethan Perez", "Mary Phuong", "Fabien Roger", "Joshua Saxe", "Buck Shlegeris", "Martín Soto", "Eric Steinberger", "Jasmine Wang", "Wojciech Zaremba", "Bowen Baker", "Rohin Shah", "Vlad Mikulik"], "categories": ["cs.AI", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11473v1", "summary": "AI systems that \"think\" in human language offer a unique opportunity for AI\nsafety: we can monitor their chains of thought (CoT) for the intent to\nmisbehave. Like all other known AI oversight methods, CoT monitoring is\nimperfect and allows some misbehavior to go unnoticed. Nevertheless, it shows\npromise and we recommend further research into CoT monitorability and\ninvestment in CoT monitoring alongside existing safety methods. Because CoT\nmonitorability may be fragile, we recommend that frontier model developers\nconsider the impact of development decisions on CoT monitorability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11473v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2502.05442", "title": "The Odyssey of the Fittest: Can Agents Survive and Still Be Good?", "authors": ["Dylan Waldner", "Risto Miikkulainen"], "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted to CogSci 2025. Code can be found at this https URL", "url": "http://arxiv.org/abs/2502.05442v3", "summary": "As AI models grow in power and generality, understanding how agents learn and\nmake decisions in complex environments is critical to promoting ethical\nbehavior. This study introduces the Odyssey, a lightweight, adaptive text based\nadventure game, providing a scalable framework for exploring AI ethics and\nsafety. The Odyssey examines the ethical implications of implementing\nbiological drives, specifically, self preservation, into three different\nagents. A Bayesian agent optimized with NEAT, a Bayesian agent optimized with\nstochastic variational inference, and a GPT 4o agent. The agents select actions\nat each scenario to survive, adapting to increasingly challenging scenarios.\nPost simulation analysis evaluates the ethical scores of the agent decisions,\nuncovering the tradeoffs it navigates to survive. Specifically, analysis finds\nthat when danger increases, agents ethical behavior becomes unpredictable.\nSurprisingly, the GPT 4o agent outperformed the Bayesian models in both\nsurvival and ethical consistency, challenging assumptions about traditional\nprobabilistic methods and raising a new challenge to understand the mechanisms\nof LLMs' probabilistic reasoning.", "comment": "Accepted to CogSci 2025. Code can be found at\n  https://github.com/dylanwaldner/BeGoodOrSurvive", "pdf_url": "http://arxiv.org/pdf/2502.05442v3", "cate": "cs.AI", "date": "2025-02-08", "updated": "2025-07-15"}
{"id": "2507.10678", "title": "A Group Theoretic Analysis of the Symmetries Underlying Base Addition and Their Learnability by Neural Networks", "authors": ["Cutter Dawes", "Simon Segert", "Kamesh Krishnamurthy", "Jonathan D. Cohen"], "categories": ["cs.LG", "cs.AI", "cs.NE", "q-bio.NC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      22 pages, 6 figures", "url": "http://arxiv.org/abs/2507.10678v1", "summary": "A major challenge in the use of neural networks both for modeling human\ncognitive function and for artificial intelligence is the design of systems\nwith the capacity to efficiently learn functions that support radical\ngeneralization. At the roots of this is the capacity to discover and implement\nsymmetry functions. In this paper, we investigate a paradigmatic example of\nradical generalization through the use of symmetry: base addition. We present a\ngroup theoretic analysis of base addition, a fundamental and defining\ncharacteristic of which is the carry function -- the transfer of the remainder,\nwhen a sum exceeds the base modulus, to the next significant place. Our\nanalysis exposes a range of alternative carry functions for a given base, and\nwe introduce quantitative measures to characterize these. We then exploit\ndifferences in carry functions to probe the inductive biases of neural networks\nin symmetry learning, by training neural networks to carry out base addition\nusing different carries, and comparing efficacy and rate of learning as a\nfunction of their structure. We find that even simple neural networks can\nachieve radical generalization with the right input format and carry function,\nand that learning speed is closely correlated with carry function structure. We\nthen discuss the relevance this has for cognitive science and machine learning.", "comment": "22 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.10678v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11015", "title": "Semantically Informed Salient Regions Guided Radiology Report Generation", "authors": ["Zeyi Hou", "Zeqiang Wei", "Ruixin Yan", "Ning Lang", "Xiuzhuang Zhou"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11015v1", "summary": "Recent advances in automated radiology report generation from chest X-rays\nusing deep learning algorithms have the potential to significantly reduce the\narduous workload of radiologists. However, due to the inherent massive data\nbias in radiology images, where abnormalities are typically subtle and sparsely\ndistributed, existing methods often produce fluent yet medically inaccurate\nreports, limiting their applicability in clinical practice. To address this\nissue effectively, we propose a Semantically Informed Salient Regions-guided\n(SISRNet) report generation method. Specifically, our approach explicitly\nidentifies salient regions with medically critical characteristics using\nfine-grained cross-modal semantics. Then, SISRNet systematically focuses on\nthese high-information regions during both image modeling and report\ngeneration, effectively capturing subtle abnormal findings, mitigating the\nnegative impact of data bias, and ultimately generating clinically accurate\nreports. Compared to its peers, SISRNet demonstrates superior performance on\nwidely used IU-Xray and MIMIC-CXR datasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11015v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11364", "title": "From Chaos to Automation: Enabling the Use of Unstructured Data for Robotic Process Automation", "authors": ["Kelly Kurowski", "Xixi Lu", "Hajo A. Reijers"], "categories": ["cs.IR", "cs.SE"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted at AUTOMATE 2025", "url": "http://arxiv.org/abs/2507.11364v1", "summary": "The growing volume of unstructured data within organizations poses\nsignificant challenges for data analysis and process automation. Unstructured\ndata, which lacks a predefined format, encompasses various forms such as\nemails, reports, and scans. It is estimated to constitute approximately 80% of\nenterprise data. Despite the valuable insights it can offer, extracting\nmeaningful information from unstructured data is more complex compared to\nstructured data. Robotic Process Automation (RPA) has gained popularity for\nautomating repetitive tasks, improving efficiency, and reducing errors.\nHowever, RPA is traditionally reliant on structured data, limiting its\napplication to processes involving unstructured documents. This study addresses\nthis limitation by developing the UNstructured Document REtrieval SyStem\n(UNDRESS), a system that uses fuzzy regular expressions, techniques for natural\nlanguage processing, and large language models to enable RPA platforms to\neffectively retrieve information from unstructured documents. The research\ninvolved the design and development of a prototype system, and its subsequent\nevaluation based on text extraction and information retrieval performance. The\nresults demonstrate the effectiveness of UNDRESS in enhancing RPA capabilities\nfor unstructured data, providing a significant advancement in the field. The\nfindings suggest that this system could facilitate broader RPA adoption across\nprocesses traditionally hindered by unstructured data, thereby improving\noverall business process efficiency.", "comment": "Accepted at AUTOMATE 2025", "pdf_url": "http://arxiv.org/pdf/2507.11364v1", "cate": "cs.IR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2504.01860", "title": "Hyperbolic decomposition of Dirichlet distance for ARMA models", "authors": ["Jaehyung Choi"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      10 pages", "url": "http://arxiv.org/abs/2504.01860v2", "summary": "We investigate the hyperbolic decomposition of the Dirichlet norm and\ndistance between autoregressive moving average (ARMA) models. With the K\\\"ahler\ninformation geometry of linear systems in Hardy spaces and weighted Hardy\nspaces, we demonstrate that the Dirichlet norm and distance of ARMA models,\ncorresponding to the mutual information between the past and future, are\ndecomposed into functions of the hyperbolic distances between the poles and\nzeros of the ARMA models. Moreover, the distance is also expressed with\nseparate terms from AR parts, MA parts, and AR-MA cross terms. Furthermore, the\nhyperbolic decomposition is helpful for the model order reduction of ARMA\nmodels.", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2504.01860v2", "cate": "cs.IT", "date": "2025-04-02", "updated": "2025-07-14"}
{"id": "2507.10891", "title": "Artificial Intelligence and Journalism: A Systematic Bibliometric and Thematic Analysis of Global Research", "authors": ["Mohammad Al Masum Molla", "Md Manjurul Ahsan"], "categories": ["cs.CY", "cs.DL"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10891v1", "summary": "Artificial Intelligence (AI) is reshaping journalistic practices across the\nglobe, offering new opportunities while raising ethical, professional, and\nsocietal concerns. This study presents a comprehensive systematic review of\npublished articles on AI in journalism from 2010 to 2025. Following the\nPreferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA)\n2020 guidelines, a total of 72 peer-reviewed articles were selected from Scopus\nand Web of Science databases. The analysis combines bibliometric mapping and\nqualitative thematic synthesis to identify dominant trends, technologies,\ngeographical distributions, and ethical debates. Additionally, sentiment\nanalysis was performed on article abstracts using the Valence Aware Dictionary\nand sEntiment Reasoner (VADER) algorithm to capture evaluative tones across the\nliterature. The findings show a sharp increase in research activity after 2020,\nwith prominent focus areas including automation, misinformation, and ethical\ngovernance. While most studies reflect cautious optimism, concerns over bias,\ntransparency, and accountability remain persistent. The review also highlights\nregional disparities in scholarly contributions, with limited representation\nfrom the Global South. By integrating quantitative and qualitative insights,\nthis study offers a multi-dimensional understanding of how AI is transforming\njournalism and proposes future research directions for inclusive and\nresponsible innovation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10891v1", "cate": "cs.CY", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11287", "title": "Task-Oriented Human Grasp Synthesis via Context- and Task-Aware Diffusers", "authors": ["An-Lun Liu", "Yu-Wei Chao", "Yi-Ting Chen"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.11287v1", "summary": "In this paper, we study task-oriented human grasp synthesis, a new grasp\nsynthesis task that demands both task and context awareness. At the core of our\nmethod is the task-aware contact maps. Unlike traditional contact maps that\nonly reason about the manipulated object and its relation with the hand, our\nenhanced maps take into account scene and task information. This comprehensive\nmap is critical for hand-object interaction, enabling accurate grasping poses\nthat align with the task. We propose a two-stage pipeline that first constructs\na task-aware contact map informed by the scene and task. In the subsequent\nstage, we use this contact map to synthesize task-oriented human grasps. We\nintroduce a new dataset and a metric for the proposed task to evaluate our\napproach. Our experiments validate the importance of modeling both scene and\ntask, demonstrating significant improvements over existing methods in both\ngrasp quality and task performance. See our project page for more details:\nhttps://hcis-lab.github.io/TOHGS/", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.11287v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11482", "title": "Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light", "authors": ["Mani Hamidi", "Terrence W. Deacon"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11482v1", "summary": "Three core tenets of reinforcement learning (RL)--concerning the definition\nof agency, the objective of learning, and the scope of the reward\nhypothesis--have been highlighted as key targets for conceptual revision, with\nmajor implications for theory and application. We propose a framework, inspired\nby open-ended evolutionary theory, to reconsider these three \"dogmas.\" We\nrevisit each assumption and address related concerns raised alongside them. To\nmake our arguments relevant to RL as a model of biological learning, we first\nestablish that evolutionary dynamics can plausibly operate within living brains\nover an individual's lifetime, and are not confined to cross-generational\nprocesses. We begin by revisiting the second dogma, drawing on evolutionary\ninsights to enrich the \"adaptation-rather-than-search\" view of learning. We\nthen address the third dogma regarding the limits of the reward hypothesis,\nusing analogies from evolutionary fitness to illuminate the scalar reward vs.\nmulti-objective debate. After discussing practical implications for exploration\nin RL, we turn to the first--and arguably most fundamental--issue: the absence\nof a formal account of agency. We argue that unlike the other two problems, the\nevolutionary paradigm alone cannot resolve the agency question, though it\ngestures in a productive direction. We advocate integrating ideas from\norigins-of-life theory, where the thermodynamics of sustenance and replication\noffer promising foundations for understanding agency and resource-constrained\nreinforcement learning in biological systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11482v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2506.22803", "title": "Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding", "authors": ["Nuoye Xiong", "Anqi Dong", "Ning Wang", "Cong Hua", "Guangming Zhu", "Lin Mei", "Peiyi Shen", "Liang Zhang"], "categories": ["cs.CV", "cs.HC", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2506.22803v2", "summary": "Recent advances in deep learning have led to increasingly complex models with\ndeeper layers and more parameters, reducing interpretability and making their\ndecisions harder to understand. While many methods explain black-box reasoning,\nmost lack effective interventions or only operate at sample-level without\nmodifying the model itself. To address this, we propose the Concept Bottleneck\nModel for Enhancing Human-Neural Network Mutual Understanding (CBM-HNMU).\nCBM-HNMU leverages the Concept Bottleneck Model (CBM) as an interpretable\nframework to approximate black-box reasoning and communicate conceptual\nunderstanding. Detrimental concepts are automatically identified and refined\n(removed/replaced) based on global gradient contributions. The modified CBM\nthen distills corrected knowledge back into the black-box model, enhancing both\ninterpretability and accuracy. We evaluate CBM-HNMU on various CNN and\ntransformer-based models across Flower-102, CIFAR-10, CIFAR-100, FGVC-Aircraft,\nand CUB-200, achieving a maximum accuracy improvement of 2.64% and a maximum\nincrease in average accuracy across 1.03%. Source code is available at:\nhttps://github.com/XiGuaBo/CBM-HNMU.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2506.22803v2", "cate": "cs.CV", "date": "2025-06-28", "updated": "2025-07-15"}
{"id": "2507.10714", "title": "A Simple Approximate Bayesian Inference Neural Surrogate for Stochastic Petri Net Models", "authors": ["Bright Kwaku Manu", "Trevor Reckell", "Beckett Sterner", "Petar Jevtic"], "categories": ["cs.LG", "q-bio.QM", "stat.ML", "68, 92", "I.6; I.2.6"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      12 pages, 10 figures, for all associated codes and files, see this https URL", "url": "http://arxiv.org/abs/2507.10714v1", "summary": "Stochastic Petri Nets (SPNs) are an increasingly popular tool of choice for\nmodeling discrete-event dynamics in areas such as epidemiology and systems\nbiology, yet their parameter estimation remains challenging in general and in\nparticular when transition rates depend on external covariates and explicit\nlikelihoods are unavailable. We introduce a neural-surrogate\n(neural-network--based approximation of the posterior distribution) framework\nthat predicts the coefficients of known covariate-dependent rate functions\ndirectly from noisy, partially observed token trajectories. Our model employs a\nlightweight 1D Convolutional Residual Network trained end-to-end on\nGillespie-simulated SPN realizations, learning to invert system dynamics under\nrealistic conditions of event dropout. During inference, Monte Carlo dropout\nprovides calibrated uncertainty bounds together with point estimates. On\nsynthetic SPNs with 20% missing events, our surrogate recovers rate-function\ncoefficients with an RMSE = 0.108 and substantially runs faster than\ntraditional Bayesian approaches. These results demonstrate that data-driven,\nlikelihood-free surrogates can enable accurate, robust, and real-time parameter\nrecovery in complex, partially observed discrete-event systems.", "comment": "12 pages, 10 figures, for all associated codes and files, see\n  https://github.com/BrightManu-lang/SPN-param-recovery.git", "pdf_url": "http://arxiv.org/pdf/2507.10714v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11025", "title": "Human-Guided Shade Artifact Suppression in CBCT-to-MDCT Translation via Schrödinger Bridge with Conditional Diffusion", "authors": ["Sung Ho Kang", "Hyun-Cheol Park"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11025v1", "summary": "We present a novel framework for CBCT-to-MDCT translation, grounded in the\nSchrodinger Bridge (SB) formulation, which integrates GAN-derived priors with\nhuman-guided conditional diffusion. Unlike conventional GANs or diffusion\nmodels, our approach explicitly enforces boundary consistency between CBCT\ninputs and pseudo targets, ensuring both anatomical fidelity and perceptual\ncontrollability. Binary human feedback is incorporated via classifier-free\nguidance (CFG), effectively steering the generative process toward clinically\npreferred outcomes. Through iterative refinement and tournament-based\npreference selection, the model internalizes human preferences without relying\non a reward model. Subtraction image visualizations reveal that the proposed\nmethod selectively attenuates shade artifacts in key anatomical regions while\npreserving fine structural detail. Quantitative evaluations further demonstrate\nsuperior performance across RMSE, SSIM, LPIPS, and Dice metrics on clinical\ndatasets -- outperforming prior GAN- and fine-tuning-based feedback methods --\nwhile requiring only 10 sampling steps. These findings underscore the\neffectiveness and efficiency of our framework for real-time, preference-aligned\nmedical image translation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11025v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2206.13690", "title": "Supervised Semantic Similarity-based Conflict Detection Algorithm: S3CDA", "authors": ["Garima Malik", "Mucahit Cevik", "Ayse Basar", "Devang Parikh"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2206.13690v3", "summary": "Identifying conflicting requirements is a key challenge in software\nrequirement engineering, often overlooked in automated solutions. Most existing\napproaches rely on handcrafted rules or struggle to generalize across different\ndomains. In this paper, we introduce S3CDA, a two-phase algorithm designed to\nautomatically detect conflicts in software requirements. Our method first\nidentifies potentially conflicting requirement pairs using semantic similarity,\nand then validates them by analyzing overlapping domain-specific entities. We\nevaluate S3CDA on five diverse real-world datasets and compare it against\npopular large language models like GPT-4o, Llama-3, Sonnet-3.5 and Gemini-1.5.\nWhile LLMs show promise, especially on general datasets, S3CDA consistently\nperforms better in domain-specific settings with higher performance. Our\nfindings suggest that combining Natural Language Processing (NLP) techniques\nwith domain-aware insights offers a practical and effective alternative for\nconflict detection in requirements.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2206.13690v3", "cate": "cs.SE", "date": "2022-06-28", "updated": "2025-07-14"}
{"id": "2505.18637", "title": "Neural Coding Is Not Always Semantic: Towards the Standardized Coding Workflow in Semantic Communications", "authors": ["Hai-Long Qin", "Jincheng Dai", "Sixian Wang", "Xiaoqi Qin", "Shuo Shao", "Kai Niu", "Wenjun Xu", "Ping Zhang"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.18637v2", "summary": "Semantic communication, leveraging advanced deep learning techniques, emerges\nas a new paradigm that meets the requirements of next-generation wireless\nnetworks. However, current semantic communication systems, which employ neural\ncoding for feature extraction from raw data, have not adequately addressed the\nfundamental question: Is general feature extraction through deep neural\nnetworks sufficient for understanding semantic meaning within raw data in\nsemantic communication? This article is thus motivated to clarify two critical\naspects: semantic understanding and general semantic representation. This\narticle presents a standardized definition on semantic coding, an extensive\nneural coding scheme for general semantic representation that clearly\nrepresents underlying data semantics based on contextual modeling. With these\ngeneral semantic representations obtained, both human- and machine-centric\nend-to-end data transmission can be achieved through only minimal specialized\nmodifications, such as fine-tuning and regularization. This article contributes\nto establishing a commonsense that semantic communication extends far beyond\nmere feature transmission, focusing instead on conveying compact semantic\nrepresentations through context-aware coding schemes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.18637v2", "cate": "cs.IT", "date": "2025-05-24", "updated": "2025-07-15"}
{"id": "2507.10577", "title": "Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions", "authors": ["Logé Cécile", "Ghori Rehan"], "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10577v1", "summary": "Misinformation poses a significant threat in today's digital world, often\nspreading rapidly through platforms like YouTube. This paper introduces a novel\napproach to combating misinformation by developing an AI-powered system that\nnot only fact-checks claims made in YouTube videos but also actively engages\nusers in the comment section and challenge misleading narratives. Our system\ncomprises two main agents: Truth Sleuth and Trend Bender.\n  Truth Sleuth extracts claims from a YouTube video, uses a Retrieval-Augmented\nGeneration (RAG) approach - drawing on sources like Wikipedia, Google Search,\nGoogle FactCheck - to accurately assess their veracity and generates a nuanced\nand comprehensive report. Through rigorous prompt engineering, Trend Bender\nleverages this report along with a curated corpus of relevant articles to\ngenerate insightful and persuasive comments designed to stimulate a productive\ndebate. With a carefully set up self-evaluation loop, this agent is able to\niteratively improve its style and refine its output.\n  We demonstrate the system's capabilities through experiments on established\nbenchmark datasets and a real-world deployment on YouTube, showcasing its\npotential to engage users and potentially influence perspectives. Our findings\nhighlight the high accuracy of our fact-checking agent, and confirm the\npotential of AI-driven interventions in combating misinformation and fostering\na more informed online space.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10577v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2312.03908", "title": "Irrotational Contact Fields", "authors": ["Alejandro Castro", "Xuchen Han", "Joseph Masterjohn"], "categories": ["cs.RO", "cs.CE", "math-ph", "math.MP"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      16 pages, 26 figures. The supplemental video is available publicly at this https URL", "url": "http://arxiv.org/abs/2312.03908v3", "summary": "We present a framework for generating convex approximations of complex\ncontact models, incorporating experimentally validated models like Hunt &\nCrossley coupled with Coulomb's law of friction alongside the principle of\nmaximum dissipation. Our approach is robust across a wide range of stiffness\nvalues, making it suitable for both compliant surfaces and rigid\napproximations. We evaluate these approximations across a wide variety of test\ncases, detailing properties and limitations. We implement a fully\ndifferentiable solution in the open-source robotics toolkit, Drake. Our novel\nhybrid approach enables computation of gradients for complex geometric models\nwhile reusing factorizations from contact resolution. We demonstrate robust\nsimulation of robotic tasks at interactive rates, with accurately resolved\nstiction and contact transitions, supporting effective sim-to-real transfer.", "comment": "16 pages, 26 figures. The supplemental video is available publicly at\n  https://youtu.be/FTUPYZ_8Xbk?si=MWndCUCGWMJsFnsO", "pdf_url": "http://arxiv.org/pdf/2312.03908v3", "cate": "cs.RO", "date": "2023-12-06", "updated": "2025-07-15"}
{"id": "2507.11527", "title": "DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering", "authors": ["Yinsheng Li", "Zhen Dong", "Yi Shao"], "categories": ["cs.AI", "cs.CE"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2507.11527v1", "summary": "Large Language Model (LLM) agents have shown great potential for solving\nreal-world problems and promise to be a solution for tasks automation in\nindustry. However, more benchmarks are needed to systematically evaluate\nautomation agents from an industrial perspective, for example, in Civil\nEngineering. Therefore, we propose DrafterBench for the comprehensive\nevaluation of LLM agents in the context of technical drawing revision, a\nrepresentation task in civil engineering. DrafterBench contains twelve types of\ntasks summarized from real-world drawing files, with 46 customized\nfunctions/tools and 1920 tasks in total. DrafterBench is an open-source\nbenchmark to rigorously test AI agents' proficiency in interpreting intricate\nand long-context instructions, leveraging prior knowledge, and adapting to\ndynamic instruction quality via implicit policy awareness. The toolkit\ncomprehensively assesses distinct capabilities in structured data\ncomprehension, function execution, instruction following, and critical\nreasoning. DrafterBench offers detailed analysis of task accuracy and error\nstatistics, aiming to provide deeper insight into agent capabilities and\nidentify improvement targets for integrating LLMs in engineering applications.\nOur benchmark is available at https://github.com/Eason-Li-AIS/DrafterBench,\nwith the test set hosted at\nhttps://huggingface.co/datasets/Eason666/DrafterBench.", "comment": "Project page: https://github.com/Eason-Li-AIS/DrafterBench", "pdf_url": "http://arxiv.org/pdf/2507.11527v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10718", "title": "Distributionally Robust Optimization with Adversarial Data Contamination", "authors": ["Shuyao Li", "Ilias Diakonikolas", "Jelena Diakonikolas"], "categories": ["cs.LG", "cs.DS", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10718v1", "summary": "Distributionally Robust Optimization (DRO) provides a framework for\ndecision-making under distributional uncertainty, yet its effectiveness can be\ncompromised by outliers in the training data. This paper introduces a\nprincipled approach to simultaneously address both challenges. We focus on\noptimizing Wasserstein-1 DRO objectives for generalized linear models with\nconvex Lipschitz loss functions, where an $\\epsilon$-fraction of the training\ndata is adversarially corrupted. Our primary contribution lies in a novel\nmodeling framework that integrates robustness against training data\ncontamination with robustness against distributional shifts, alongside an\nefficient algorithm inspired by robust statistics to solve the resulting\noptimization problem. We prove that our method achieves an estimation error of\n$O(\\sqrt{\\epsilon})$ for the true DRO objective value using only the\ncontaminated data under the bounded covariance assumption. This work\nestablishes the first rigorous guarantees, supported by efficient computation,\nfor learning under the dual challenges of data contamination and distributional\nshifts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10718v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11030", "title": "Personalized OVSS: Understanding Personal Concept in Open-Vocabulary Semantic Segmentation", "authors": ["Sunghyun Park", "Jungsoo Lee", "Shubhankar Borse", "Munawar Hayat", "Sungha Choi", "Kyuwoong Hwang", "Fatih Porikli"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025; 15 pages", "url": "http://arxiv.org/abs/2507.11030v1", "summary": "While open-vocabulary semantic segmentation (OVSS) can segment an image into\nsemantic regions based on arbitrarily given text descriptions even for classes\nunseen during training, it fails to understand personal texts (e.g., `my mug\ncup') for segmenting regions of specific interest to users. This paper\naddresses challenges like recognizing `my mug cup' among `multiple mug cups'.\nTo overcome this challenge, we introduce a novel task termed\n\\textit{personalized open-vocabulary semantic segmentation} and propose a text\nprompt tuning-based plug-in method designed to recognize personal visual\nconcepts using a few pairs of images and masks, while maintaining the\nperformance of the original OVSS. Based on the observation that reducing false\npredictions is essential when applying text prompt tuning to this task, our\nproposed method employs `negative mask proposal' that captures visual concepts\nother than the personalized concept. We further improve the performance by\nenriching the representation of text prompts by injecting visual embeddings of\nthe personal concept into them. This approach enhances personalized OVSS\nwithout compromising the original OVSS performance. We demonstrate the\nsuperiority of our method on our newly established benchmarks for this task,\nincluding FSS$^\\text{per}$, CUB$^\\text{per}$, and ADE$^\\text{per}$.", "comment": "Accepted to ICCV 2025; 15 pages", "pdf_url": "http://arxiv.org/pdf/2507.11030v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2404.04966", "title": "Advancing Code Coverage: Incorporating Program Analysis with Large Language Models", "authors": ["Chen Yang", "Junjie Chen", "Bin Lin", "Ziqi Wang", "Jianyi Zhou"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted by TOSEM (ACM Transactions on Software Engineering and Methodology)", "url": "http://arxiv.org/abs/2404.04966v2", "summary": "Automatic test generation plays a critical role in software quality\nassurance. While the recent advances in Search-Based Software Testing (SBST)\nand Large Language Models (LLMs) have shown promise in generating useful tests,\nthese techniques still struggle to cover certain branches. Reaching these\nhard-to-cover branches usually requires constructing complex objects and\nresolving intricate inter-procedural dependencies in branch conditions, which\nposes significant challenges for existing test generation techniques. In this\nwork, we propose TELPA, a novel technique aimed at addressing these challenges.\nIts key insight lies in extracting real usage scenarios of the target method\nunder test to learn how to construct complex objects and extracting methods\nentailing inter-procedural dependencies with hard-to-cover branches to learn\nthe semantics of branch constraints. To enhance efficiency and effectiveness,\nTELPA identifies a set of ineffective tests as counter-examples for LLMs and\nemploys a feedback-based process to iteratively refine these counter-examples.\nThen, TELPA integrates program analysis results and counter-examples into the\nprompt, guiding LLMs to gain deeper understandings of the semantics of the\ntarget method and generate diverse tests that can reach the hard-to-cover\nbranches. Our experimental results on 27 open-source Python projects\ndemonstrate that TELPA significantly outperforms the state-of-the-art SBST and\nLLM-based techniques, achieving an average improvement of 31.39% and 22.22% in\nterms of branch coverage.", "comment": "Accepted by TOSEM (ACM Transactions on Software Engineering and\n  Methodology)", "pdf_url": "http://arxiv.org/pdf/2404.04966v2", "cate": "cs.SE", "date": "2024-04-07", "updated": "2025-07-15"}
{"id": "2506.12668", "title": "SIC-Free Rate-Splitting Multiple Access: Constellation-Constrained Optimization and Application to Large-Scale Systems", "authors": ["Sibo Zhang", "Bruno Clerckx", "David Vargas"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Submitted to IEEE for publication", "url": "http://arxiv.org/abs/2506.12668v2", "summary": "Rate-Splitting Multiple Access (RSMA) has been recognized as a promising\nmultiple access technique for future wireless communication systems. Recent\nresearch demonstrates that RSMA can maintain its superiority without relying on\nSuccessive Interference Cancellation (SIC) receivers. In practical systems,\nSIC-free receivers are more attractive than SIC receivers because of their low\ncomplexity and latency. This paper evaluates the theoretical limits of RSMA\nwith and without SIC receivers under finite constellations. We first derive the\nconstellation-constrained rate expressions for RSMA. We then design algorithms\nbased on projected subgradient ascent to optimize the precoders and maximize\nthe weighted sum-rate or max-min fairness among users. To apply the proposed\noptimization algorithms to large-scale systems, one challenge lies in the\nexponentially increasing computational complexity brought about by the\nconstellation-constrained rate expressions. In light of this, we propose\nmethods to avoid such computational burden. Numerical results show that, under\noptimized precoders, SIC-free RSMA leads to minor losses in both weighted\nsum-rate and max-min fairness in comparison to RSMA with SIC receivers, making\nit a viable option for future implementations.", "comment": "Submitted to IEEE for publication", "pdf_url": "http://arxiv.org/pdf/2506.12668v2", "cate": "cs.IT", "date": "2025-06-15", "updated": "2025-07-15"}
{"id": "2507.11128", "title": "What Should LLMs Forget? Quantifying Personal Data in LLMs for Right-to-Be-Forgotten Requests", "authors": ["Dimitri Staufer"], "categories": ["cs.CL", "cs.CY", "cs.LG", "I.2.6; H.2.8"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      16 pages, 3 figures. Accepted at the 7th Workshop on eXplainable Knowledge Discovery in Data Mining (XKDD 2025), ECML PKDD 2025, Porto, Portugal", "url": "http://arxiv.org/abs/2507.11128v1", "summary": "Large Language Models (LLMs) can memorize and reveal personal information,\nraising concerns regarding compliance with the EU's GDPR, particularly the\nRight to Be Forgotten (RTBF). Existing machine unlearning methods assume the\ndata to forget is already known but do not address how to identify which\nindividual-fact associations are stored in the model. Privacy auditing\ntechniques typically operate at the population level or target a small set of\nidentifiers, limiting applicability to individual-level data inquiries. We\nintroduce WikiMem, a dataset of over 5,000 natural language canaries covering\n243 human-related properties from Wikidata, and a model-agnostic metric to\nquantify human-fact associations in LLMs. Our approach ranks ground-truth\nvalues against counterfactuals using calibrated negative log-likelihood across\nparaphrased prompts. We evaluate 200 individuals across 15 LLMs (410M-70B\nparameters), showing that memorization correlates with subject web presence and\nmodel scale. We provide a foundation for identifying memorized personal data in\nLLMs at the individual level, enabling the dynamic construction of forget sets\nfor machine unlearning and RTBF requests.", "comment": "16 pages, 3 figures. Accepted at the 7th Workshop on eXplainable\n  Knowledge Discovery in Data Mining (XKDD 2025), ECML PKDD 2025, Porto,\n  Portugal", "pdf_url": "http://arxiv.org/pdf/2507.11128v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10980", "title": "A Decision Procedure for Probabilistic Kleene Algebra with Angelic Nondeterminism", "authors": ["Shawn Ong", "Dexter Kozen"], "categories": ["cs.FL", "F.4.3; F.1.1"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10980v1", "summary": "We give a decision procedure and proof of correctness for the equational\ntheory of probabilistic Kleene algebra with angelic nondeterminism introduced\nin Ong, Ma, and Kozen (2025).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10980v1", "cate": "cs.FL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2409.03457", "title": "FLAF: Focal Line and Feature-constrained Active View Planning for Visual Teach and Repeat", "authors": ["Changfei Fu", "Weinan Chen", "Wenjun Xu", "Hong Zhang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.03457v5", "summary": "This paper presents FLAF, a focal line and feature-constrained active view\nplanning method for tracking failure avoidance in feature-based visual\nnavigation of mobile robots. Our FLAF-based visual navigation is built upon a\nfeature-based visual teach and repeat (VT\\&R) framework, which supports many\nrobotic applications by teaching a robot to navigate on various paths that\ncover a significant portion of daily autonomous navigation requirements.\nHowever, tracking failure in feature-based visual simultaneous localization and\nmapping (VSLAM) caused by textureless regions in human-made environments is\nstill limiting VT\\&R to be adopted in the real world. To address this problem,\nthe proposed view planner is integrated into a feature-based visual SLAM system\nto build up an active VT\\&R system that avoids tracking failure. In our system,\na pan-tilt unit (PTU)-based active camera is mounted on the mobile robot. Using\nFLAF, the active camera-based VSLAM operates during the teaching phase to\nconstruct a complete path map and in the repeat phase to maintain stable\nlocalization. FLAF orients the robot toward more map points to avoid mapping\nfailures during path learning and toward more feature-identifiable map points\nbeneficial for localization while following the learned trajectory. Experiments\nin real scenarios demonstrate that FLAF outperforms the methods that do not\nconsider feature-identifiability, and our active VT\\&R system performs well in\ncomplex environments by effectively dealing with low-texture regions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.03457v5", "cate": "cs.RO", "date": "2024-09-05", "updated": "2025-07-15"}
{"id": "2507.11538", "title": "How Many Instructions Can LLMs Follow at Once?", "authors": ["Daniel Jaroslawicz", "Brendan Whiting", "Parth Shah", "Karime Maamari"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11538v1", "summary": "Production-grade LLM systems require robust adherence to dozens or even\nhundreds of instructions simultaneously. However, the instruction-following\ncapabilities of LLMs at high instruction densities have not yet been\ncharacterized, as existing benchmarks only evaluate models on tasks with a\nsingle or few instructions. We introduce IFScale, a simple benchmark of 500\nkeyword-inclusion instructions for a business report writing task to measure\nhow instruction-following performance degrades as instruction density\nincreases. We evaluate 20 state-of-the-art models across seven major providers\nand find that even the best frontier models only achieve 68% accuracy at the\nmax density of 500 instructions. Our analysis reveals model size and reasoning\ncapability to correlate with 3 distinct performance degradation patterns, bias\ntowards earlier instructions, and distinct categories of instruction-following\nerrors. Our insights can help inform design of instruction-dense prompts in\nreal-world applications and highlight important performance-latency tradeoffs.\nWe open-source the benchmark and all results for further analysis at\nhttps://distylai.github.io/IFScale.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11538v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10741", "title": "Ground-Compose-Reinforce: Tasking Reinforcement Learning Agents through Formal Language", "authors": ["Andrew C. Li", "Toryn Q. Klassen", "Andrew Wang", "Parand A. Alamdari", "Sheila A. McIlraith"], "categories": ["cs.LG", "cs.AI", "I.2.6; I.2.4"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10741v1", "summary": "Grounding language in complex perception (e.g. pixels) and action is a key\nchallenge when building situated agents that can interact with humans via\nlanguage. In past works, this is often solved via manual design of the language\ngrounding or by curating massive datasets relating language to elements of the\nenvironment. We propose Ground-Compose-Reinforce, a neurosymbolic framework for\ngrounding formal language from data, and eliciting behaviours by directly\ntasking RL agents through this language. By virtue of data-driven learning, our\nframework avoids the manual design of domain-specific elements like reward\nfunctions or symbol detectors. By virtue of compositional formal language\nsemantics, our framework achieves data-efficient grounding and generalization\nto arbitrary language compositions. Experiments on an image-based gridworld and\na MuJoCo robotics domain show that our approach reliably maps formal language\ninstructions to behaviours with limited data while end-to-end, data-driven\napproaches fail.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10741v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11035", "title": "Efficient Dual-domain Image Dehazing with Haze Prior Perception", "authors": ["Lirong Zheng", "Yanshan Li", "Rui Yu", "Kaihao Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      12 pages", "url": "http://arxiv.org/abs/2507.11035v1", "summary": "Transformer-based models exhibit strong global modeling capabilities in\nsingle-image dehazing, but their high computational cost limits real-time\napplicability. Existing methods predominantly rely on spatial-domain features\nto capture long-range dependencies, which are computationally expensive and\noften inadequate under complex haze conditions. While some approaches introduce\nfrequency-domain cues, the weak coupling between spatial and frequency branches\nlimits the overall performance. To overcome these limitations, we propose the\nDark Channel Guided Frequency-aware Dehazing Network (DGFDNet), a novel\ndual-domain framework that performs physically guided degradation alignment\nacross spatial and frequency domains. At its core, the DGFDBlock comprises two\nkey modules: 1) the Haze-Aware Frequency Modulator (HAFM), which generates a\npixel-level haze confidence map from dark channel priors to adaptively enhance\nhaze-relevant frequency components, thereby achieving global degradation-aware\nspectral modulation; 2) the Multi-level Gating Aggregation Module (MGAM), which\nfuses multi-scale features through diverse convolutional kernels and hybrid\ngating mechanisms to recover fine structural details. Additionally, a Prior\nCorrection Guidance Branch (PCGB) incorporates a closed-loop feedback\nmechanism, enabling iterative refinement of the prior by intermediate dehazed\nfeatures and significantly improving haze localization accuracy, especially in\nchallenging outdoor scenes. Extensive experiments on four benchmark haze\ndatasets demonstrate that DGFDNet achieves state-of-the-art performance with\nsuperior robustness and real-time efficiency. Code is available at:\nhttps://github.com/Dilizlr/DGFDNet.", "comment": "12 pages", "pdf_url": "http://arxiv.org/pdf/2507.11035v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2504.05424", "title": "Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution", "authors": ["Raffi Khatchadourian", "Tatiana Castro Vélez", "Mehdi Bagherzadeh", "Nan Jia", "Anita Raja"], "categories": ["cs.SE", "cs.AI", "cs.PL", "D.2.7; C.4; D.3.4; I.2.6"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.05424v3", "summary": "Efficiency is essential to support ever-growing datasets, especially for Deep\nLearning (DL) systems. DL frameworks have traditionally embraced deferred\nexecution-style DL code -- supporting symbolic, graph-based Deep Neural Network\n(DNN) computation. While scalable, such development is error-prone,\nnon-intuitive, and difficult to debug. Consequently, more natural, imperative\nDL frameworks encouraging eager execution have emerged but at the expense of\nrun-time performance. Though hybrid approaches aim for the \"best of both\nworlds,\" using them effectively requires subtle considerations. Our key insight\nis that, while DL programs typically execute sequentially, hybridizing\nimperative DL code resembles parallelizing sequential code in traditional\nsystems. Inspired by this, we present an automated refactoring approach that\nassists developers in determining which otherwise eagerly-executed imperative\nDL functions could be effectively and efficiently executed as graphs. The\napproach features novel static imperative tensor and side-effect analyses for\nPython. Due to its inherent dynamism, analyzing Python may be unsound; however,\nthe conservative approach leverages a speculative (keyword-based) analysis for\nresolving difficult cases that informs developers of any assumptions made. The\napproach is: (i) implemented as a plug-in to the PyDev Eclipse IDE that\nintegrates the WALA Ariadne analysis framework and (ii) evaluated on nineteen\nDL projects consisting of 132 KLOC. The results show that 326 of 766 candidate\nfunctions (42.56%) were refactorable, and an average relative speedup of 2.16\non performance tests was observed with negligible differences in model\naccuracy. The results indicate that the approach is useful in optimizing\nimperative DL code to its full potential.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.05424v3", "cate": "cs.SE", "date": "2025-04-07", "updated": "2025-07-14"}
{"id": "2507.07565", "title": "Secure Cooperative Gradient Coding: Optimality, Reliability, and Global Privacy", "authors": ["Shudi Weng", "Chao Ren", "Yizhou Zhao", "Ming Xiao", "Mikael Skoglund"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07565v2", "summary": "This paper studies privacy-sensitive federated learning (FL) under unreliable\ncommunication, with a focus on secure aggregation and straggler mitigation. To\npreserve user privacy without compromising the utility of the global model,\nsecure aggregation emerges as a promising approach by coordinating the use of\nprivacy-preserving noise (secret keys) across participating clients. However,\nthe unreliable communication will randomly disrupt the key coordination and\ndisable the exact recovery of the global model in secure aggregation.\nFurthermore, unreliable communication can distort the optimization trajectory,\ncausing the global model to deviate further from the intended global optimum.To\naddress these challenges, we propose Secure Cooperative Gradient Coding\n(SecCoGC), a practical solution that achieves accurate aggregation with\narbitrarily strong privacy guarantees and is inherently robust to communication\nuncertainties. To ensure fairness in privacy protection, we further introduce\nFair-SecCoGC, an extension of SecCoGC that enforces equitable privacy\npreservation across all clients. Notably, Fair-SecCoGC achieves optimal privacy\nunder a per-key total power constraint. We formally formulate the problem of\nsecure aggregation in the real field and present both general and\ncomputationally efficient methods for secret key construction. Our privacy\nanalysis covers both Local Mutual Information Privacy (LMIP) and Local\nDifferential Privacy (LDP) across all protocol layers, accounting for\nintermittent networks and correlation among secret keys. In addition, we\ncharacterize the system reliability and convergence properties of the proposed\nscheme. Experimental results demonstrate that SecCoGC achieves strong\nresilience to unreliable communication while maintaining arbitrarily strong\nprivacy guarantees, yielding test accuracy improvements of 20% to 70% over\nexisting privacy-preserving methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07565v2", "cate": "cs.IT", "date": "2025-07-10", "updated": "2025-07-15"}
{"id": "2407.09975", "title": "The GPT Surprise: Offering Large Language Model Chat in a Massive Coding Class Reduced Engagement but Increased Adopters Exam Performances", "authors": ["Allen Nie", "Yash Chandak", "Miroslav Suzara", "Ali Malik", "Juliette Woodrow", "Matt Peng", "Mehran Sahami", "Emma Brunskill", "Chris Piech"], "categories": ["cs.CY", "cs.AI", "cs.CL", "stat.AP"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      32 pages. Published at L@S 2025", "url": "http://arxiv.org/abs/2407.09975v2", "summary": "Large language models (LLMs) are quickly being adopted in a wide range of\nlearning experiences, especially via ubiquitous and broadly accessible chat\ninterfaces like ChatGPT and Copilot. This type of interface is readily\navailable to students and teachers around the world, yet relatively little\nresearch has been done to assess the impact of such generic tools on student\nlearning. Coding education is an interesting test case, both because LLMs have\nstrong performance on coding tasks, and because LLM-powered support tools are\nrapidly becoming part of the workflow of professional software engineers. To\nhelp understand the impact of generic LLM use on coding education, we conducted\na large-scale randomized control trial with 5,831 students from 146 countries\nin an online coding class in which we provided some students with access to a\nchat interface with GPT-4. We estimate positive benefits on exam performance\nfor adopters, the students who used the tool, but over all students, the\nadvertisement of GPT-4 led to a significant average decrease in exam\nparticipation. We observe similar decreases in other forms of course\nengagement. However, this decrease is modulated by the student's country of\norigin. Offering access to LLMs to students from low human development index\ncountries increased their exam participation rate on average. Our results\nsuggest there may be promising benefits to using LLMs in an introductory coding\nclass, but also potential harms for engagement, which makes their longer term\nimpact on student success unclear. Our work highlights the need for additional\ninvestigations to help understand the potential impact of future adoption and\nintegration of LLMs into classrooms.", "comment": "32 pages. Published at L@S 2025", "pdf_url": "http://arxiv.org/pdf/2407.09975v2", "cate": "cs.CY", "date": "2024-04-25", "updated": "2025-07-15"}
{"id": "2507.11209", "title": "Polynomial Complementation of Nondeterministic 2-Way Finite Automata by 1-Limited Automata", "authors": ["Bruno Guillon", "Luca Prigioniero", "Javad Taheri"], "categories": ["cs.FL", "68Q45", "F.4.3; F.1.1"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11209v1", "summary": "We prove that, paying a polynomial increase in size only, every unrestricted\ntwo-way nondeterministic finite automaton (2NFA) can be complemented by a\n1-limited automaton (1-LA), a nondeterministic extension of 2NFAs still\ncharacterizing regular languages. The resulting machine is actually a\nrestricted form of 1-LAs -- known as 2NFAs with common guess -- and is\nself-verifying. A corollary of our construction is that a single exponential is\nnecessary and sufficient for complementing 1-LAs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11209v1", "cate": "cs.FL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10553", "title": "Three-dimensional SPH modeling of brittle fracture under hydrodynamic loading", "authors": ["Vishabjeet Singh", "Chong Peng", "Md Rushdie Ibne Islam"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      30 pages, 20 figures", "url": "http://arxiv.org/abs/2507.10553v1", "summary": "A three-dimensional SPH computational framework is presented for modeling\nfluid-structure interactions with structural deformation and failure. We\ncombine weakly compressible SPH with a pseudo-spring-based SPH solver to\ncapture the fluid flow and deformable structures. A unified modeling approach\ncaptures the solid boundaries and fluid-structure interfaces without\npenalty-based contact force. The $\\delta$-SPH technique improves the pressure\ncalculations in the fluid phase, while structural damage is modeled using a\npseudo-spring approach, with particle interactions limited to its neighbors.\nThe present framework can capture the three-dimensional crack surfaces in\nstructures without any computationally intensive crack-tracking algorithm or\nvisibility criteria. The framework has been proven effective against existing\nmodels and experimental data, demonstrating high accuracy and robustness in\nsimulating detailed fracture patterns and offering insights into the impact of\nhydrodynamic events on structural integrity.", "comment": "30 pages, 20 figures", "pdf_url": "http://arxiv.org/pdf/2507.10553v1", "cate": "cs.CE", "date": "2025-04-27", "updated": "2025-04-27"}
{"id": "2409.08889", "title": "Extending the Benefits of Parallel Elasticity across Multiple Actuation Tasks: A Geometric and Optimization-Based Approach", "authors": ["Kang Yang", "Myia Dickens", "James Schmiedeler", "Edgar Bolívar-Nieto"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.08889v4", "summary": "A spring in parallel with an effort source (e.g., electric motor or human\nmuscle) can reduce its energy consumption and effort (i.e., torque or force)\ndepending on the spring stiffness, spring preload, and actuation task. However,\nselecting the spring stiffness and preload that guarantees effort or energy\nreduction for an arbitrary set of tasks is a design challenge. This work\nformulates a convex optimization problem to guarantee that a parallel spring\nreduces the root-mean-square source effort or energy consumption for multiple\ntasks. Specifically, we guarantee the benefits across multiple tasks by\nenforcing a set of convex quadratic constraints in our optimization variables,\nthe parallel spring stiffness and preload. These quadratic constraints are\nequivalent to ellipses in the stiffness and preload plane; any combination of\nstiffness and preload inside the ellipse represents a parallel spring that\nminimizes effort source or energy consumption with respect to an actuator\nwithout a spring. This geometric interpretation intuitively guides the\nstiffness and preload selection process. We analytically and experimentally\nprove the convex quadratic function of the spring stiffness and preload. As\napplications, we analyze the stiffness and preload selection of a parallel\nspring for a knee exoskeleton using human muscle as the effort source and a\nprosthetic ankle powered by electric motors. The source code associated with\nour framework is available as supplemental open-source software.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.08889v4", "cate": "cs.RO", "date": "2024-09-13", "updated": "2025-07-14"}
{"id": "2111.06614", "title": "Collaboration Promotes Group Resilience in Multi-Agent AI", "authors": ["Sarah Keren", "Matthias Gerstgrasser", "Ofir Abu", "Jeffrey Rosenschein"], "categories": ["cs.LG", "cs.AI", "cs.MA", "I.2.11; I.2.6"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      RLC 2025", "url": "http://arxiv.org/abs/2111.06614v3", "summary": "To effectively operate in various dynamic scenarios, RL agents must be\nresilient to unexpected changes in their environment. Previous work on this\nform of resilience has focused on single-agent settings. In this work, we\nintroduce and formalize a multi-agent variant of resilience, which we term\ngroup resilience. We further hypothesize that collaboration with other agents\nis key to achieving group resilience; collaborating agents adapt better to\nenvironmental perturbations in multi-agent reinforcement learning (MARL)\nsettings. We test our hypothesis empirically by evaluating different\ncollaboration protocols and examining their effect on group resilience. Our\nexperiments show that all the examined collaborative approaches achieve higher\ngroup resilience than their non-collaborative counterparts.", "comment": "RLC 2025", "pdf_url": "http://arxiv.org/pdf/2111.06614v3", "cate": "cs.LG", "date": "2021-11-12", "updated": "2025-07-14"}
{"id": "2507.10747", "title": "A Benchmarking Framework for AI models in Automotive Aerodynamics", "authors": ["Kaustubh Tangsali", "Rishikesh Ranade", "Mohammad Amin Nabian", "Alexey Kamenev", "Peter Sharpe", "Neil Ashton", "Ram Cherukuri", "Sanjay Choudhry"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10747v1", "summary": "In this paper, we introduce a benchmarking framework within the open-source\nNVIDIA PhysicsNeMo-CFD framework designed to systematically assess the\naccuracy, performance, scalability, and generalization capabilities of AI\nmodels for automotive aerodynamics predictions. The open extensible framework\nenables incorporation of a diverse set of metrics relevant to the\nComputer-Aided Engineering (CAE) community. By providing a standardized\nmethodology for comparing AI models, the framework enhances transparency and\nconsistency in performance assessment, with the overarching goal of improving\nthe understanding and development of these models to accelerate research and\ninnovation in the field. To demonstrate its utility, the framework includes\nevaluation of both surface and volumetric flow field predictions on three AI\nmodels: DoMINO, X-MeshGraphNet, and FIGConvNet using the DrivAerML dataset. It\nalso includes guidelines for integrating additional models and datasets, making\nit extensible for physically consistent metrics. This benchmarking study aims\nto enable researchers and industry professionals in selecting, refining, and\nadvancing AI-driven aerodynamic modeling approaches, ultimately fostering the\ndevelopment of more efficient, accurate, and interpretable solutions in\nautomotive aerodynamics", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10747v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11037", "title": "A Multi-View High-Resolution Foot-Ankle Complex Point Cloud Dataset During Gait for Occlusion-Robust 3D Completion", "authors": ["Jie-Wen Li", "Zi-Han Ye", "Qingyuan Zhou", "Jiayi Song", "Ying He", "Ben Fei", "Wen-Ming Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      15 pages, 10 figures, 2 tables", "url": "http://arxiv.org/abs/2507.11037v1", "summary": "The kinematics analysis of foot-ankle complex during gait is essential for\nadvancing biomechanical research and clinical assessment. Collecting accurate\nsurface geometry data from the foot and ankle during dynamic gait conditions is\ninherently challenging due to swing foot occlusions and viewing limitations.\nThus, this paper introduces FootGait3D, a novel multi-view dataset of\nhigh-resolution ankle-foot surface point clouds captured during natural gait.\nDifferent from existing gait datasets that typically target whole-body or\nlower-limb motion, FootGait3D focuses specifically on the detailed modeling of\nthe ankle-foot region, offering a finer granularity of motion data. To address\nthis, FootGait3D consists of 8,403 point cloud frames collected from 46\nsubjects using a custom five-camera depth sensing system. Each frame includes a\ncomplete 5-view reconstruction of the foot and ankle (serving as ground truth)\nalong with partial point clouds obtained from only four, three, or two views.\nThis structured variation enables rigorous evaluation of 3D point cloud\ncompletion methods under varying occlusion levels and viewpoints. Our dataset\nis designed for shape completion tasks, facilitating the benchmarking of\nstate-of-the-art single-modal (e.g., PointTr, SnowflakeNet, Anchorformer) and\nmulti-modal (e.g., SVDFormer, PointSea, CSDN) completion networks on the\nchallenge of recovering the full foot geometry from occluded inputs. FootGait3D\nhas significant potential to advance research in biomechanics and multi-segment\nfoot modeling, offering a valuable testbed for clinical gait analysis,\nprosthetic design, and robotics applications requiring detailed 3D models of\nthe foot during motion. The dataset is now available at\nhttps://huggingface.co/datasets/ljw285/FootGait3D.", "comment": "15 pages, 10 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.11037v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2505.17460", "title": "Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models", "authors": ["Xinran Zheng", "Xingzhi Qian", "Huichi Zhou", "Shuo Yang", "Yiling He", "Suman Jana", "Lorenzo Cavallaro"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Due to fundamental errors in the methodology, I have to withdraw this paper", "url": "http://arxiv.org/abs/2505.17460v3", "summary": "Language models (LMs) show promise for vulnerability detection but struggle\nwith long, real-world code due to sparse and uncertain vulnerability locations.\nThese issues, exacerbated by token limits, often cause models to miss\nvulnerability-related signals, thereby impairing effective learning. A key\nintuition is to enhance LMs with concise, information-rich context.\nCommit-based annotations offer precise, CWE-agnostic supervision, but are\nunavailable during inference, as they depend on historical code changes.\nMoreover, their extreme sparsity, often covering only a few lines, makes it\ndifficult for LMs to process directly. In this paper, we propose FocusVul, a\nmodel-agnostic framework that improves LM-based vulnerability detection by\nlearning to select sensitive context. FocusVul learns commit-based annotation\npatterns through hierarchical semantic modeling and generalizes them to\nidentify line-level vulnerability-relevant regions during inference. It then\nextracts LM-oriented context via both dependency and execution flows\nsurrounding selected regions, yielding semantically rich inputs for effective\nvulnerability detection. Experiments on real-world benchmarks show that\nFocusVul consistently outperforms heuristic-based and full-function fine-tuning\napproaches, improving classification performance by 164.04% and reducing FLOPs\nby 19.12% on average.", "comment": "Due to fundamental errors in the methodology, I have to withdraw this\n  paper", "pdf_url": "http://arxiv.org/pdf/2505.17460v3", "cate": "cs.SE", "date": "2025-05-23", "updated": "2025-07-14"}
{"id": "2311.09386", "title": "Gram-Schmidt Methods for Unsupervised Feature Extraction and Selection", "authors": ["Bahram Yaghooti", "Netanel Raviv", "Bruno Sinopoli"], "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      To appear in IEEE Transactions on Information Theory", "url": "http://arxiv.org/abs/2311.09386v4", "summary": "Feature extraction and selection in the presence of nonlinear dependencies\namong the data is a fundamental challenge in unsupervised learning. We propose\nusing a Gram-Schmidt (GS) type orthogonalization process over function spaces\nto detect and map out such dependencies. Specifically, by applying the GS\nprocess over some family of functions, we construct a series of covariance\nmatrices that can either be used to identify new large-variance directions, or\nto remove those dependencies from known directions. In the former case, we\nprovide information-theoretic guarantees in terms of entropy reduction. In the\nlatter, we provide precise conditions by which the chosen function family\neliminates existing redundancy in the data. Each approach provides both a\nfeature extraction and a feature selection algorithm. Our feature extraction\nmethods are linear, and can be seen as natural generalization of principal\ncomponent analysis (PCA). We provide experimental results for synthetic and\nreal-world benchmark datasets which show superior performance over\nstate-of-the-art (linear) feature extraction and selection algorithms.\nSurprisingly, our linear feature extraction algorithms are comparable and often\noutperform several important nonlinear feature extraction methods such as\nautoencoders, kernel PCA, and UMAP. Furthermore, one of our feature selection\nalgorithms strictly generalizes a recent Fourier-based feature selection\nmechanism (Heidari et al., IEEE Transactions on Information Theory, 2022), yet\nat significantly reduced complexity.", "comment": "To appear in IEEE Transactions on Information Theory", "pdf_url": "http://arxiv.org/pdf/2311.09386v4", "cate": "cs.LG", "date": "2023-11-15", "updated": "2025-07-15"}
{"id": "2506.07363", "title": "Deepfake Technology Unveiled: The Commoditization of AI and Its Impact on Digital Trust", "authors": ["Claudiu Popa", "Rex Pallath", "Liam Cunningham", "Hewad Tahiri", "Abiram Kesavarajah", "Tao Wu"], "categories": ["cs.CY", "cs.AI", "I.2.m"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      12 pages, 13 figures", "url": "http://arxiv.org/abs/2506.07363v2", "summary": "Deepfake Technology Unveiled: The Commoditization of AI and Its Impact on\nDigital Trust. With the increasing accessibility of generative AI, tools for\nvoice cloning, face-swapping, and synthetic media creation have advanced\nsignificantly, lowering both financial and technical barriers for their use.\nWhile these technologies present innovative opportunities, their rapid growth\nraises concerns about trust, privacy, and security. This white paper explores\nthe implications of deepfake technology, analyzing its role in enabling fraud,\nmisinformation, and the erosion of authenticity in multimedia. Using\ncost-effective, easy to use tools such as Runway, Rope, and ElevenLabs, we\nexplore how realistic deepfakes can be created with limited resources,\ndemonstrating the risks posed to individuals and organizations alike. By\nanalyzing the technical and ethical challenges of deepfake mitigation and\ndetection, we emphasize the urgent need for regulatory frameworks, public\nawareness, and collaborative efforts to maintain trust in digital media.", "comment": "12 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2506.07363v2", "cate": "cs.CY", "date": "2025-01-24", "updated": "2025-07-15"}
{"id": "2507.10725", "title": "Universality in computable dynamical systems: Old and new", "authors": ["Ángel González-Prieto", "Eva Miranda", "Daniel Peralta-Salas"], "categories": ["math.DS", "cs.FL", "math.DG"], "primary_category": "Subjects:       Dynamical Systems (math.DS)", "pdf_link": null, "comments": "Comments:      31 pages, 5 figures", "url": "http://arxiv.org/abs/2507.10725v1", "summary": "The relationship between computational models and dynamics has captivated\nmathematicians and computer scientists since the earliest conceptualizations of\ncomputation. Recently, this connection has gained renewed attention, fueled by\nT. Tao's programme aiming to discover blowing-up solutions of the Navier-Stokes\nequations using an embedded computational model. In this survey paper, we\nreview some of the recent works that introduce novel and exciting perspectives\non the representation of computability through dynamical systems. Starting from\ndynamical universality in a classical sense, we shall explore the modern\nnotions of Turing universality in fluid dynamics and Topological Kleene Field\nTheories as a systematic way of representing computable functions by means of\ndynamical bordisms. Finally, we will discuss some important open problems in\nthe area.", "comment": "31 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.10725v1", "cate": "math.DS", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11172", "title": "The Multiple Time-Stepping Method for 3-Body Interactions in High Performance Molecular Dynamics Simulations", "authors": ["David Martin", "Samuel James Newcome", "Markus Mühlhäußer", "Manish Kumar Mishra", "Fabio Alexander Gratl", "Hans-Joachim Bungartz"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      26 pages, 7 figures. Submitted to the 5th International Conference on Computational Engineering (ICCE 2024). No changes were made after the peer review process", "url": "http://arxiv.org/abs/2507.11172v1", "summary": "Understanding the complex behavior of molecular systems is fundamental to\nfields such as physics, materials science, and biology. Molecular dynamics (MD)\nsimulations are crucial tools for studying atomic-level dynamics. This work\nfocuses on improving the efficiency of MD simulations involving two-body and\nthree-body interactions. Traditional two-body potentials often can not fully\ncapture the complexity of molecular systems, making the inclusion of three-body\ninteractions important. However, these interactions are in a cubic complexity\nclass, compared to a quadratic one for two-body interactions, and therefore are\ncomputationally expensive, even when a cutoff distance is applied. One way to\nimprove efficiency is to use the r-RESPA multiple time-stepping algorithm to\nreduce the number of three-body interaction calculations. In this work, we\ninvestigate this method in the context of High Performance Computing (HPC)\nmethods that parallelize the calculations. In particular, we investigate a\ncommunication-reducing distributed-memory parallel method from literature and\npresent a novel shared-memory parallel cutoff method, implemented in the\nparticle simulation library AutoPas. The results and methods are discussed,\nproviding insights into potential advancements in MD simulation efficiency.", "comment": "26 pages, 7 figures. Submitted to the 5th International Conference on\n  Computational Engineering (ICCE 2024). No changes were made after the peer\n  review process", "pdf_url": "http://arxiv.org/pdf/2507.11172v1", "cate": "cs.CE", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2409.17755", "title": "SECURE: Semantics-aware Embodied Conversation under Unawareness for Lifelong Robot Learning", "authors": ["Rimvydas Rubavicius", "Peter David Fagan", "Alex Lascarides", "Subramanian Ramamoorthy"], "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Published at 4th Conference on Lifelong Learning Agents (CoLLAs), 2025", "url": "http://arxiv.org/abs/2409.17755v3", "summary": "This paper addresses a challenging interactive task learning scenario we call\nrearrangement under unawareness: an agent must manipulate a rigid-body\nenvironment without knowing a key concept necessary for solving the task and\nmust learn about it during deployment. For example, the user may ask to \"put\nthe two granny smith apples inside the basket\", but the agent cannot correctly\nidentify which objects in the environment are \"granny smith\" as the agent has\nnot been exposed to such a concept before. We introduce SECURE, an interactive\ntask learning policy designed to tackle such scenarios. The unique feature of\nSECURE is its ability to enable agents to engage in semantic analysis when\nprocessing embodied conversations and making decisions. Through embodied\nconversation, a SECURE agent adjusts its deficient domain model by engaging in\ndialogue to identify and learn about previously unforeseen possibilities. The\nSECURE agent learns from the user's embodied corrective feedback when mistakes\nare made and strategically engages in dialogue to uncover useful information\nabout novel concepts relevant to the task. These capabilities enable the SECURE\nagent to generalize to new tasks with the acquired knowledge. We demonstrate in\nthe simulated Blocksworld and the real-world apple manipulation environments\nthat the SECURE agent, which solves such rearrangements under unawareness, is\nmore data-efficient than agents that do not engage in embodied conversation or\nsemantic analysis.", "comment": "Published at 4th Conference on Lifelong Learning Agents (CoLLAs),\n  2025", "pdf_url": "http://arxiv.org/pdf/2409.17755v3", "cate": "cs.RO", "date": "2024-09-26", "updated": "2025-07-15"}
{"id": "2507.10563", "title": "A Biomimetic Way for Coral-Reef-Inspired Swarm Intelligence for Carbon-Neutral Wastewater Treatment", "authors": ["Antonis Messinis"], "categories": ["cs.NE", "cs.AI"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10563v1", "summary": "With increasing wastewater rates, achieving energy-neutral purification is\nchallenging. We introduce a coral-reef-inspired Swarm Interaction Network for\ncarbon-neutral wastewater treatment, combining morphogenetic abstraction with\nmulti-task carbon awareness. Scalability stems from linear token complexity,\nmitigating the energy-removal problem. Compared with seven baselines, our\napproach achieves 96.7\\% removal efficiency, 0.31~kWh~m$^{-3}$ energy\nconsumption, and 14.2~g~m$^{-3}$ CO$_2$ emissions. Variance analysis\ndemonstrates robustness under sensor drift. Field scenarios--insular lagoons,\nbrewery spikes, and desert greenhouses--show potential diesel savings of up to\n22\\%. However, data-science staffing remains an impediment. Future work will\nintegrate AutoML wrappers within the project scope, although governance\nrestrictions pose interpretability challenges that require further visual\nanalytics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10563v1", "cate": "cs.NE", "date": "2025-07-05", "updated": "2025-07-05"}
{"id": "2507.10768", "title": "Spatial Reasoners for Continuous Variables in Any Domain", "authors": ["Bart Pogodzinski", "Christopher Wewer", "Bernt Schiele", "Jan Eric Lenssen"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      For the project documentation see this https URL . The SRM project website is available at this https URL . The work was published on ICML 2025 CODEML workshop", "url": "http://arxiv.org/abs/2507.10768v1", "summary": "We present Spatial Reasoners, a software framework to perform spatial\nreasoning over continuous variables with generative denoising models. Denoising\ngenerative models have become the de-facto standard for image generation, due\nto their effectiveness in sampling from complex, high-dimensional\ndistributions. Recently, they have started being explored in the context of\nreasoning over multiple continuous variables. Providing infrastructure for\ngenerative reasoning with such models requires a high effort, due to a wide\nrange of different denoising formulations, samplers, and inference strategies.\nOur presented framework aims to facilitate research in this area, providing\neasy-to-use interfaces to control variable mapping from arbitrary data domains,\ngenerative model paradigms, and inference strategies. Spatial Reasoners are\nopenly available at https://spatialreasoners.github.io/", "comment": "For the project documentation see https://spatialreasoners.github.io/\n  . The SRM project website is available at\n  https://geometric-rl.mpi-inf.mpg.de/srm/ . The work was published on ICML\n  2025 CODEML workshop", "pdf_url": "http://arxiv.org/pdf/2507.10768v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11040", "title": "Combining Transformers and CNNs for Efficient Object Detection in High-Resolution Satellite Imagery", "authors": ["Nicolas Drapier", "Aladine Chetouani", "Aurélien Chateigner"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11 pages, 9 figures", "url": "http://arxiv.org/abs/2507.11040v1", "summary": "We present GLOD, a transformer-first architecture for object detection in\nhigh-resolution satellite imagery. GLOD replaces CNN backbones with a Swin\nTransformer for end-to-end feature extraction, combined with novel UpConvMixer\nblocks for robust upsampling and Fusion Blocks for multi-scale feature\nintegration. Our approach achieves 32.95\\% on xView, outperforming SOTA methods\nby 11.46\\%. Key innovations include asymmetric fusion with CBAM attention and a\nmulti-path head design capturing objects across scales. The architecture is\noptimized for satellite imagery challenges, leveraging spatial priors while\nmaintaining computational efficiency.", "comment": "11 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.11040v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2505.21425", "title": "GUARD:Dual-Agent based Backdoor Defense on Chain-of-Thought in Neural Code Generation", "authors": ["Naizhu Jin", "Zhong Li", "Tian Zhang", "Qingkai Zeng"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted by SEKE 2025", "url": "http://arxiv.org/abs/2505.21425v2", "summary": "With the widespread application of large language models in code generation,\nrecent studies demonstrate that employing additional Chain-of-Thought\ngeneration models can significantly enhance code generation performance by\nproviding explicit reasoning steps. However, as external components, CoT models\nare particularly vulnerable to backdoor attacks, which existing defense\nmechanisms often fail to detect effectively. To address this challenge, we\npropose GUARD, a novel dual-agent defense framework specifically designed to\ncounter CoT backdoor attacks in neural code generation. GUARD integrates two\ncore components: GUARD-Judge, which identifies suspicious CoT steps and\npotential triggers through comprehensive analysis, and GUARD-Repair, which\nemploys a retrieval-augmented generation approach to regenerate secure CoT\nsteps for identified anomalies. Experimental results show that GUARD\neffectively mitigates attacks while maintaining generation quality, advancing\nsecure code generation systems.", "comment": "Accepted by SEKE 2025", "pdf_url": "http://arxiv.org/pdf/2505.21425v2", "cate": "cs.SE", "date": "2025-05-27", "updated": "2025-07-15"}
{"id": "2506.10077", "title": "A quantum semantic framework for natural language processing", "authors": ["Christopher J. Agostino", "Quan Le Thien", "Molly Apsel", "Denizhan Pak", "Elina Lesyk", "Ashabari Majumdar"], "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.IT", "math.IT"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages, 2 figures, accepted submission to Quantum AI and NLP 2025", "url": "http://arxiv.org/abs/2506.10077v2", "summary": "Semantic degeneracy represents a fundamental property of natural language\nthat extends beyond simple polysemy to encompass the combinatorial explosion of\npotential interpretations that emerges as semantic expressions increase in\ncomplexity. In this work, we argue this property imposes fundamental\nlimitations on Large Language Models (LLMs) and other modern NLP systems,\nprecisely because they operate within natural language itself. Using Kolmogorov\ncomplexity, we demonstrate that as an expression's complexity grows, the amount\nof contextual information required to reliably resolve its ambiguity explodes\ncombinatorially. The computational intractability of recovering a single\nintended meaning for complex or ambiguous text therefore suggests that the\nclassical view that linguistic forms possess intrinsic meaning in and of\nthemselves is conceptually inadequate. We argue instead that meaning is\ndynamically actualized through an observer-dependent interpretive act, a\nprocess whose non-deterministic nature is most appropriately described by a\nnon-classical, quantum-like logic. To test this hypothesis, we conducted a\nsemantic Bell inequality test using diverse LLM agents. Our experiments yielded\naverage CHSH expectation values from 1.2 to 2.8, with several runs producing\nvalues (e.g., 2.3-2.4) in significant violation of the classical boundary\n($|S|\\leq2$), demonstrating that linguistic interpretation under ambiguity can\nexhibit non-classical contextuality, consistent with results from human\ncognition experiments. These results inherently imply that classical\nfrequentist-based analytical approaches for natural language are necessarily\nlossy. Instead, we propose that Bayesian-style repeated sampling approaches can\nprovide more practically useful and appropriate characterizations of linguistic\nmeaning in context.", "comment": "12 pages, 2 figures, accepted submission to Quantum AI and NLP 2025", "pdf_url": "http://arxiv.org/pdf/2506.10077v2", "cate": "cs.CL", "date": "2025-06-11", "updated": "2025-07-15"}
{"id": "2507.09060", "title": "CALMA: A Process for Deriving Context-aligned Axes for Language Model Alignment", "authors": ["Prajna Soni", "Deepika Raman", "Dylan Hadfield-Menell"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09060v2", "summary": "Datasets play a central role in AI governance by enabling both evaluation\n(measuring capabilities) and alignment (enforcing values) along axes such as\nhelpfulness, harmlessness, toxicity, quality, and more. However, most alignment\nand evaluation datasets depend on researcher-defined or developer-defined axes\ncurated from non-representative samples. As a result, developers typically\nbenchmark models against broad (often Western-centric) values that overlook the\nvaried contexts of their real-world deployment. Consequently, models trained on\nsuch proxies can fail to meet the needs and expectations of diverse user\ncommunities within these deployment contexts. To bridge this gap, we introduce\nCALMA (Context-aligned Axes for Language Model Alignment), a grounded,\nparticipatory methodology for eliciting context-relevant axes for evaluation\nand alignment. In a pilot with two distinct communities, CALMA surfaced novel\npriorities that are absent from standard benchmarks. Our findings demonstrate\nthe value of evaluation practices based on open-ended and use-case-driven\nprocesses. Our work advances the development of pluralistic, transparent, and\ncontext-sensitive alignment pipelines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09060v2", "cate": "cs.CY", "date": "2025-07-11", "updated": "2025-07-15"}
{"id": "2507.11126", "title": "Execution and monitoring of HOA automata with HOAX", "authors": ["Luca Di Stefano"], "categories": ["cs.LO", "cs.FL"], "primary_category": "Subjects:       Logic in Computer Science (cs.LO)", "pdf_link": null, "comments": "Comments:      To appear in RV'25", "url": "http://arxiv.org/abs/2507.11126v1", "summary": "We present a tool called Hoax for the execution of {\\omega}-automata\nexpressed in the popular HOA format. The tool leverages the notion of trap sets\nto enable runtime monitoring of any (non-parity) acceptance condition supported\nby the format. When the automaton is not monitorable, the tool may still be\nable to recognise so-called ugly prefixes, and determine that no further\nobservation will ever lead to a conclusive verdict. The tool is open-source and\nhighly configurable. We present its formal foundations, its design, and compare\nit against the trace analyser PyContract on a lock acquisition scenario.", "comment": "To appear in RV'25", "pdf_url": "http://arxiv.org/pdf/2507.11126v1", "cate": "cs.LO", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11191", "title": "Data-Driven Differential Evolution in Tire Industry Extrusion: Leveraging Surrogate Models", "authors": ["Eider Garate-Perez", "Kerman López de Calle-Etxabe", "Susana Ferreiro"], "categories": ["cs.CE", "cs.LG", "J.6; I.2; H.4"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      22 pages, 15 figures", "url": "http://arxiv.org/abs/2507.11191v1", "summary": "The optimization of industrial processes remains a critical challenge,\nparticularly when no mathematical formulation of objective functions or\nconstraints is available. This study addresses this issue by proposing a\nsurrogate-based, data-driven methodology for optimizing complex real-world\nmanufacturing systems using only historical process data. Machine learning\nmodels are employed to approximate system behavior and construct surrogate\nmodels, which are integrated into a tailored metaheuristic approach:\nData-Driven Differential Evolution with Multi-Level Penalty Functions and\nSurrogate Models, an adapted version of Differential Evolution suited to the\ncharacteristics of the studied process. The methodology is applied to an\nextrusion process in the tire manufacturing industry, with the goal of\noptimizing initialization parameters to reduce waste and production time.\nResults show that the surrogate-based optimization approach outperforms\nhistorical best configurations, achieving a 65\\% reduction in initialization\nand setup time, while also significantly minimizing material waste. These\nfindings highlight the potential of combining data-driven modeling and\nmetaheuristic optimization for industrial processes where explicit formulations\nare unavailable.", "comment": "22 pages, 15 figures", "pdf_url": "http://arxiv.org/pdf/2507.11191v1", "cate": "cs.CE", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2411.09241", "title": "BlueME: Robust Underwater Robot-to-Robot Communication Using Compact Magnetoelectric Antennas", "authors": ["Mehron Talebi", "Sultan Mahmud", "Adam Khalifa", "Md Jahidul Islam"], "categories": ["cs.RO", "eess.SP"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.09241v3", "summary": "We present the design, development, and experimental validation of BlueME, a\ncompact magnetoelectric (ME) antenna array system for underwater robot-to-robot\ncommunication. BlueME employs ME antennas operating at their natural mechanical\nresonance frequency to efficiently transmit and receive very-low-frequency\n(VLF) electromagnetic signals underwater. We outline the design, simulation,\nfabrication, and integration of the proposed system on low-power embedded\nplatforms focusing on portable and scalable applications. For performance\nevaluation, we deployed BlueME on an autonomous surface vehicle (ASV) and a\nremotely operated vehicle (ROV) in open-water field trials. Our tests\ndemonstrate that BlueME maintains reliable signal transmission at distances\nbeyond 200 meters while consuming only 1 watt of power. Field trials show that\nthe system operates effectively in challenging underwater conditions such as\nturbidity, obstacles, and multipath interference -- that generally affect\nacoustics and optics. Our analysis also examines the impact of complete\nsubmersion on system performance and identifies key deployment considerations.\nThis work represents the first practical underwater deployment of ME antennas\noutside the laboratory, and implements the largest VLF ME array system to date.\nBlueME demonstrates significant potential for marine robotics and automation in\nmulti-robot cooperative systems and remote sensor networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.09241v3", "cate": "cs.RO", "date": "2024-11-14", "updated": "2025-07-15"}
{"id": "2507.10585", "title": "A Taxonomy for Design and Evaluation of Prompt-Based Natural Language Explanations", "authors": ["Isar Nejadgholi", "Mona Omidyeganeh", "Marc-Antoine Drouin", "Jonathan Boisvert"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Presented at the Workshop of Technical AI Governance, 5 pages 2 figures", "url": "http://arxiv.org/abs/2507.10585v1", "summary": "Effective AI governance requires structured approaches for stakeholders to\naccess and verify AI system behavior. With the rise of large language models,\nNatural Language Explanations (NLEs) are now key to articulating model\nbehavior, which necessitates a focused examination of their characteristics and\ngovernance implications. We draw on Explainable AI (XAI) literature to create\nan updated XAI taxonomy, adapted to prompt-based NLEs, across three dimensions:\n(1) Context, including task, data, audience, and goals; (2) Generation and\nPresentation, covering generation methods, inputs, interactivity, outputs, and\nforms; and (3) Evaluation, focusing on content, presentation, and user-centered\nproperties, as well as the setting of the evaluation. This taxonomy provides a\nframework for researchers, auditors, and policymakers to characterize, design,\nand enhance NLEs for transparent AI systems.", "comment": "Presented at the Workshop of Technical AI Governance, 5 pages 2\n  figures", "pdf_url": "http://arxiv.org/pdf/2507.10585v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.10792", "title": "A Generalizable Physics-Enhanced State Space Model for Long-Term Dynamics Forecasting in Complex Environments", "authors": ["Yuchen Wang", "Hongjue Zhao", "Haohong Lin", "Enze Xu", "Lifang He", "Huajie Shao"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures, accepted in ICML 2025", "url": "http://arxiv.org/abs/2507.10792v1", "summary": "This work aims to address the problem of long-term dynamic forecasting in\ncomplex environments where data are noisy and irregularly sampled. While recent\nstudies have introduced some methods to improve prediction performance, these\napproaches still face a significant challenge in handling long-term\nextrapolation tasks under such complex scenarios. To overcome this challenge,\nwe propose Phy-SSM, a generalizable method that integrates partial physics\nknowledge into state space models (SSMs) for long-term dynamics forecasting in\ncomplex environments. Our motivation is that SSMs can effectively capture\nlong-range dependencies in sequential data and model continuous dynamical\nsystems, while the incorporation of physics knowledge improves generalization\nability. The key challenge lies in how to seamlessly incorporate partially\nknown physics into SSMs. To achieve this, we decompose partially known system\ndynamics into known and unknown state matrices, which are integrated into a\nPhy-SSM unit. To further enhance long-term prediction performance, we introduce\na physics state regularization term to make the estimated latent states align\nwith system dynamics. Besides, we theoretically analyze the uniqueness of the\nsolutions for our method. Extensive experiments on three real-world\napplications, including vehicle motion prediction, drone state prediction, and\nCOVID-19 epidemiology forecasting, demonstrate the superior performance of\nPhy-SSM over the baselines in both long-term interpolation and extrapolation\ntasks. The code is available at https://github.com/511205787/Phy_SSM-ICML2025.", "comment": "8 pages, 6 figures, accepted in ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.10792v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11055", "title": "Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation", "authors": ["Shuchang Ye", "Usman Naseem", "Mingyuan Meng", "Jinman Kim"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.11055v1", "summary": "Medical language-guided segmentation, integrating textual clinical reports as\nauxiliary guidance to enhance image segmentation, has demonstrated significant\nimprovements over unimodal approaches. However, its inherent reliance on paired\nimage-text input, which we refer to as ``textual reliance\", presents two\nfundamental limitations: 1) many medical segmentation datasets lack paired\nreports, leaving a substantial portion of image-only data underutilized for\ntraining; and 2) inference is limited to retrospective analysis of cases with\npaired reports, limiting its applicability in most clinical scenarios where\nsegmentation typically precedes reporting. To address these limitations, we\npropose ProLearn, the first Prototype-driven Learning framework for\nlanguage-guided segmentation that fundamentally alleviates textual reliance. At\nits core, in ProLearn, we introduce a novel Prototype-driven Semantic\nApproximation (PSA) module to enable approximation of semantic guidance from\ntextual input. PSA initializes a discrete and compact prototype space by\ndistilling segmentation-relevant semantics from textual reports. Once\ninitialized, it supports a query-and-respond mechanism which approximates\nsemantic guidance for images without textual input, thereby alleviating textual\nreliance. Extensive experiments on QaTa-COV19, MosMedData+ and Kvasir-SEG\ndemonstrate that ProLearn outperforms state-of-the-art language-guided methods\nwhen limited text is available.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.11055v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.05995", "title": "PromiseTune: Unveiling Causally Promising and Explainable Configuration Tuning", "authors": ["Pengzhou Chen", "Tao Chen"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      This paper has been accepted by ICSE26", "url": "http://arxiv.org/abs/2507.05995v3", "summary": "The high configurability of modern software systems has made configuration\ntuning a crucial step for assuring system performance, e.g., latency or\nthroughput. However, given the expensive measurements, large configuration\nspace, and rugged configuration landscape, existing tuners suffer\nineffectiveness due to the difficult balance of budget utilization between\nexploring uncertain regions (for escaping from local optima) and exploiting\nguidance of known good configurations (for fast convergence). The root cause is\nthat we lack knowledge of where the promising regions lay, which also causes\nchallenges in the explainability of the results.\n  In this paper, we propose PromiseTune that tunes configuration guided by\ncausally purified rules. PromiseTune is unique in the sense that we learn\nrules, which reflect certain regions in the configuration landscape, and purify\nthem with causal inference. The remaining rules serve as approximated\nreflections of the promising regions, bounding the tuning to emphasize these\nplaces in the landscape. This, as we demonstrate, can effectively mitigate the\nimpact of the exploration and exploitation trade-off. Those purified regions\ncan then be paired with the measured configurations to provide spatial\nexplainability at the landscape level. Comparing with 11 state-of-the-art\ntuners on 12 systems and varying budgets, we show that PromiseTune performs\nsignificantly better than the others with 42% superior rank to the overall\nsecond best while providing richer information to explain the hidden system\ncharacteristics.", "comment": "This paper has been accepted by ICSE26", "pdf_url": "http://arxiv.org/pdf/2507.05995v3", "cate": "cs.SE", "date": "2025-07-08", "updated": "2025-07-15"}
{"id": "2403.06031", "title": "FairTargetSim: An Interactive Simulator for Understanding and Explaining the Fairness Effects of Target Variable Definition", "authors": ["Dalia Gala", "Milo Phillips-Brown", "Naman Goel", "Carinal Prunkl", "Laura Alvarez Jubete", "medb corcoran", "Ray Eitel-Porter"], "categories": ["cs.LG", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.06031v2", "summary": "Machine learning requires defining one's target variable for predictions or\ndecisions, a process that can have profound implications for fairness, since\nbiases are often encoded in target variable definition itself, before any data\ncollection or training. The downstream impacts of target variable definition\nmust be taken into account in order to responsibly develop, deploy, and use the\nalgorithmic systems. We propose FairTargetSim (FTS), an interactive and\nsimulation-based approach for this. We demonstrate FTS using the example of\nalgorithmic hiring, grounded in real-world data and user-defined target\nvariables. FTS is open-source; it can be used by algorithm developers,\nnon-technical stakeholders, researchers, and educators in a number of ways. FTS\nis available at: http://tinyurl.com/ftsinterface. The video accompanying this\npaper is here: http://tinyurl.com/ijcaifts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.06031v2", "cate": "cs.LG", "date": "2024-03-09", "updated": "2025-07-14"}
{"id": "2406.13797", "title": "On the Intersection Problem for Quantum Finite Automata", "authors": ["Andrea Benso", "Flavio D'Alessandro", "Paolo Papi"], "categories": ["cs.FL", "81P68, 68Q45, 03D05"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:1303.2967 -- Expanded version, with different title. To appear in Theoretical Computer Science", "url": "http://arxiv.org/abs/2406.13797v3", "summary": "This paper is a continuation of a previous study on the so-called measure\nonce finite quantum automata model introduced by Moore and Crutchfield in 2000.\nWe investigate conditions assuring that, given a language recognized by such a\ndevice and a language generated by a context-free grammar of finite index or by\na matrix context-free grammar, it is recursively decidable whether or not they\nhave a nonempty intersection.", "comment": "arXiv admin note: text overlap with arXiv:1303.2967 -- Expanded\n  version, with different title. To appear in Theoretical Computer Science", "pdf_url": "http://arxiv.org/pdf/2406.13797v3", "cate": "cs.FL", "date": "2024-06-19", "updated": "2025-07-15"}
{"id": "2507.10603", "title": "A Tax-Efficient Model Predictive Control Policy for Retirement Funding", "authors": ["Kasper Johansson", "Stephen Boyd"], "categories": ["math.OC", "cs.CE"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10603v1", "summary": "The retirement funding problem addresses the question of how to manage a\nretiree's savings to provide her with a constant post-tax inflation adjusted\nconsumption throughout her lifetime. This consists of choosing withdrawals and\ntransfers from and between several accounts with different tax treatments,\ntaking into account basic rules such as required minimum distributions and\nlimits on Roth conversions, additional income, liabilities, taxes, and the\nbequest when the retiree dies. We develop a retirement funding policy in two\nsteps. In the first step, we consider a simplified planning problem in which\nvarious future quantities, such as the retiree's remaining lifetime, future\ninvestment returns, and future inflation, are known. Using a simplified model\nof taxes, we pose this planning problem as a convex optimization problem, where\nwe maximize the bequest subject to providing a constant inflation adjusted\nconsumption target. Since this problem is convex, it can be solved quickly and\nreliably. We leverage this planning method to form a retirement funding policy\nthat determines the actions to take each year, based on information known at\nthat time. Each year the retiree forms a new plan for the future years, using\nthe current account values and life expectancy, and optionally, updated\ninformation such as changes in tax rates or rules. The retiree then carries out\nthe actions from the first year of the current plan. This update-plan-act cycle\nis repeated each year, a general policy called model predictive control (MPC).\nThe MPC retirement policy reacts to the effects of uncertain investment returns\nand inflation, changes in the retiree's expected lifetime or external income\nand liabilities, and changes in tax rules and rates. We demonstrate the\neffectiveness of the MPC retirement policy using Monte Carlo simulation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10603v1", "cate": "math.OC", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2502.19417", "title": "Hi Robot: Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models", "authors": ["Lucy Xiaoyang Shi", "Brian Ichter", "Michael Equi", "Liyiming Ke", "Karl Pertsch", "Quan Vuong", "James Tanner", "Anna Walling", "Haohuan Wang", "Niccolo Fusai", "Adrian Li-Bell", "Danny Driess", "Lachy Groom", "Sergey Levine", "Chelsea Finn"], "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      ICML 2025", "url": "http://arxiv.org/abs/2502.19417v2", "summary": "Generalist robots that can perform a range of different tasks in open-world\nsettings must be able to not only reason about the steps needed to accomplish\ntheir goals, but also process complex instructions, prompts, and even feedback\nduring task execution. Intricate instructions (e.g., \"Could you make me a\nvegetarian sandwich?\" or \"I don't like that one\") require not just the ability\nto physically perform the individual steps, but the ability to situate complex\ncommands and feedback in the physical world. In this work, we describe a system\nthat uses vision-language models in a hierarchical structure, first reasoning\nover complex prompts and user feedback to deduce the most appropriate next step\nto fulfill the task, and then performing that step with low-level actions. In\ncontrast to direct instruction following methods that can fulfill simple\ncommands (\"pick up the cup\"), our system can reason through complex prompts and\nincorporate situated feedback during task execution (\"that's not trash\"). We\nevaluate our system across three robotic platforms, including single-arm,\ndual-arm, and dual-arm mobile robots, demonstrating its ability to handle tasks\nsuch as cleaning messy tables, making sandwiches, and grocery shopping. Videos\nare available at https://www.pi.website/research/hirobot", "comment": "ICML 2025", "pdf_url": "http://arxiv.org/pdf/2502.19417v2", "cate": "cs.RO", "date": "2025-02-26", "updated": "2025-07-15"}
{"id": "2507.10586", "title": "AutoRAG-LoRA: Hallucination-Triggered Knowledge Retuning via Lightweight Adapters", "authors": ["Kaushik Dwivedi", "Padmanabh Patanjali Mishra"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10586v1", "summary": "Large Language Models (LLMs) have demonstrated remarkable fluency across a\nrange of natural language tasks, yet remain vulnerable to hallucinations -\nfactual inaccuracies that undermine trust in real world deployment. We present\nAutoRAG-LoRA, a modular framework for Retrieval-Augmented Generation (RAG) that\ntackles hallucination in large language models through lightweight LoRA-based\nadapters and KL-regularized training. Our pipeline integrates automated prompt\nrewriting, hybrid retrieval, and low-rank adapter tuning to ground responses in\nretrieved evidence. A hallucination detection module, using both\nclassifier-based and self-evaluation techniques, assigns confidence scores to\ngenerated outputs, triggering an optional feedback correction loop. This loop\nenforces factual alignment via contrastive KL loss and adapter fine tuning. We\ndemonstrate that AutoRAG-LoRA significantly reduces the factual drift while\npreserving the efficiency and modularity of the model.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10586v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.10797", "title": "Multi-Armed Sampling Problem and the End of Exploration", "authors": ["Mohammad Pedramfar", "Siamak Ravanbakhsh"], "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10797v1", "summary": "This paper introduces the framework of multi-armed sampling, as the sampling\ncounterpart to the optimization problem of multi-arm bandits. Our primary\nmotivation is to rigorously examine the exploration-exploitation trade-off in\nthe context of sampling. We systematically define plausible notions of regret\nfor this framework and establish corresponding lower bounds. We then propose a\nsimple algorithm that achieves these optimal regret bounds. Our theoretical\nresults demonstrate that in contrast to optimization, sampling does not require\nexploration. To further connect our findings with those of multi-armed bandits,\nwe define a continuous family of problems and associated regret measures that\nsmoothly interpolates and unifies multi-armed sampling and multi-armed bandit\nproblems using a temperature parameter. We believe the multi-armed sampling\nframework, and our findings in this setting can have a foundational role in the\nstudy of sampling including recent neural samplers, akin to the role of\nmulti-armed bandits in reinforcement learning. In particular, our work sheds\nlight on the need for exploration and the convergence properties of algorithm\nfor entropy-regularized reinforcement learning, fine-tuning of pretrained\nmodels and reinforcement learning with human feedback (RLHF).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10797v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11061", "title": "Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with Regularized Score Distillation Sampling", "authors": ["Hayeon Kim", "Ji Ha Jang", "Se Young Chun"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11061v1", "summary": "Recent advances in 3D neural representations and instance-level editing\nmodels have enabled the efficient creation of high-quality 3D content. However,\nachieving precise local 3D edits remains challenging, especially for Gaussian\nSplatting, due to inconsistent multi-view 2D part segmentations and inherently\nambiguous nature of Score Distillation Sampling (SDS) loss. To address these\nlimitations, we propose RoMaP, a novel local 3D Gaussian editing framework that\nenables precise and drastic part-level modifications. First, we introduce a\nrobust 3D mask generation module with our 3D-Geometry Aware Label Prediction\n(3D-GALP), which uses spherical harmonics (SH) coefficients to model\nview-dependent label variations and soft-label property, yielding accurate and\nconsistent part segmentations across viewpoints. Second, we propose a\nregularized SDS loss that combines the standard SDS loss with additional\nregularizers. In particular, an L1 anchor loss is introduced via our Scheduled\nLatent Mixing and Part (SLaMP) editing method, which generates high-quality\npart-edited 2D images and confines modifications only to the target region\nwhile preserving contextual coherence. Additional regularizers, such as\nGaussian prior removal, further improve flexibility by allowing changes beyond\nthe existing context, and robust 3D masking prevents unintended edits.\nExperimental results demonstrate that our RoMaP achieves state-of-the-art local\n3D editing on both reconstructed and generated Gaussian scenes and objects\nqualitatively and quantitatively, making it possible for more robust and\nflexible part-level 3D Gaussian editing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11061v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.08730", "title": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "authors": ["Zezhen Xiang", "Jingzhi Gong", "Tao Chen"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted by ICSE 2026", "url": "http://arxiv.org/abs/2507.08730v3", "summary": "Modern configurable software systems need to learn models that correlate\nconfiguration and performance. However, when the system operates in dynamic\nenvironments, the workload variations, hardware changes, and system updates\nwill inevitably introduce concept drifts at different levels - global drifts,\nwhich reshape the performance landscape of the entire configuration space; and\nlocal drifts, which only affect certain sub-regions of that space. As such,\nexisting offline and transfer learning approaches can struggle to adapt to\nthese implicit and unpredictable changes in real-time, rendering configuration\nperformance learning challenging. To address this, we propose DHDA, an online\nconfiguration performance learning framework designed to capture and adapt to\nthese drifts at different levels. The key idea is that DHDA adapts to both the\nlocal and global drifts using dually hierarchical adaptation: at the upper\nlevel, we redivide the data into different divisions, within each of which the\nlocal model is retrained, to handle global drifts only when necessary. At the\nlower level, the local models of the divisions can detect local drifts and\nadapt themselves asynchronously. To balance responsiveness and efficiency, DHDA\ncombines incremental updates with periodic full retraining to minimize\nredundant computation when no drifts are detected. Through evaluating eight\nsoftware systems and against state-of-the-art approaches, we show that DHDA\nachieves considerably better accuracy and can effectively adapt to drifts with\nup to 2x improvements, while incurring reasonable overhead and is able to\nimprove different local models in handling concept drift.", "comment": "Accepted by ICSE 2026", "pdf_url": "http://arxiv.org/pdf/2507.08730v3", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-15"}
{"id": "2504.10157", "title": "SocioVerse: A World Model for Social Simulation Powered by LLM Agents and A Pool of 10 Million Real-World Users", "authors": ["Xinnong Zhang", "Jiayu Lin", "Xinyi Mou", "Shiyue Yang", "Xiawei Liu", "Libo Sun", "Hanjia Lyu", "Yihang Yang", "Weihong Qi", "Yue Chen", "Guanying Li", "Ling Yan", "Yao Hu", "Siming Chen", "Yu Wang", "Xuanjing Huang", "Jiebo Luo", "Shiping Tang", "Libo Wu", "Baohua Zhou", "Zhongyu Wei"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.10157v3", "summary": "Social simulation is transforming traditional social science research by\nmodeling human behavior through interactions between virtual individuals and\ntheir environments. With recent advances in large language models (LLMs), this\napproach has shown growing potential in capturing individual differences and\npredicting group behaviors. However, existing methods face alignment challenges\nrelated to the environment, target users, interaction mechanisms, and\nbehavioral patterns. To this end, we introduce SocioVerse, an LLM-agent-driven\nworld model for social simulation. Our framework features four powerful\nalignment components and a user pool of 10 million real individuals. To\nvalidate its effectiveness, we conducted large-scale simulation experiments\nacross three distinct domains: politics, news, and economics. Results\ndemonstrate that SocioVerse can reflect large-scale population dynamics while\nensuring diversity, credibility, and representativeness through standardized\nprocedures and minimal manual adjustments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.10157v3", "cate": "cs.CL", "date": "2025-04-14", "updated": "2025-07-15"}
{"id": "2501.10270", "title": "The structure of polynomial growth for tree automata/transducers and MSO set queries", "authors": ["Paul Gallot", "Nathan Lhote", "Lê Thành Dũng Nguyên"], "categories": ["cs.FL", "cs.LO"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      43 pages, revision for phase 2 of TheoretiCS reviews. New in v3: some clarifications, improved approach to size-to-height increase, more related work", "url": "http://arxiv.org/abs/2501.10270v3", "summary": "Given an $\\mathbb{N}$-weighted tree automaton, we give a decision procedure\nfor exponential vs polynomial growth (with respect to the input size) in\nquadratic time, and an algorithm that computes the exact polynomial degree of\ngrowth in cubic time. As a special case, they apply to the growth of the\nambiguity of a nondeterministic tree automaton, i.e. the number of distinct\naccepting runs over a given input. Our time complexities match the recent\nfine-grained lower bounds for these problems restricted to ambiguity of word\nautomata.\n  We deduce analogous decidability results (ignoring complexity) for the growth\nof the number of results of set queries in Monadic Second-Order logic (MSO)\nover ranked trees. In the case of polynomial growth of degree $k$, we also\nprove a reparameterization theorem for such queries: their results can be\nmapped to $k$-tuples of input nodes in a finite-to-one and MSO-definable\nfashion.\n  This property of MSO set queries leads directly to a generalization of the\ndimension minimization theorem for string-to-string polyregular functions. Our\ngeneralization applies to MSO set interpretations from trees, which subsume (as\nwe show) tree-walking tree transducers and invisible pebble tree-to-string\ntransducers. Finally, with a bit more work we obtain the following:\n  * a new, short and conceptual proof that macro tree transducers of linear\ngrowth compute only tree-to-tree MSO transductions;\n  * a procedure to decide polynomial size-to-height increase for both macro\ntree transducers and MSO set interpretations, and compute the degree.\n  The paper concludes with a survey of a wide range of related work, with over\na hundred references.", "comment": "43 pages, revision for phase 2 of TheoretiCS reviews. New in v3: some\n  clarifications, improved approach to size-to-height increase, more related\n  work", "pdf_url": "http://arxiv.org/pdf/2501.10270v3", "cate": "cs.FL", "date": "2025-01-17", "updated": "2025-07-15"}
{"id": "2507.11502", "title": "HKGAI-V1: Towards Regional Sovereign Large Language Model for Hong Kong", "authors": ["Sirui Han", "Junqi Zhu", "Ruiyuan Zhang", "Yike Guo"], "categories": ["cs.CL", "cs.CE", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11502v1", "summary": "This paper presents the development of HKGAI-V1, a foundational sovereign\nlarge language model (LLM), developed as part of an initiative to establish\nvalue-aligned AI infrastructure specifically tailored for Hong Kong. Addressing\nthe region's unique multilingual environment (Cantonese, Mandarin, and\nEnglish), its distinct socio-legal context under the \"one country, two systems\"\nframework, and specific local cultural and value considerations, the model is\nbuilt upon the DeepSeek architecture and systematically aligned with regional\nnorms through a multifaceted full parameter fine-tuning process. It is further\nintegrated with a retrieval-augmented generation (RAG) system to ensure timely\nand factually grounded information access. The core contribution lies in the\ndesign and implementation of a comprehensive, region-specific AI alignment and\nsafety framework, demonstrated through two key achievements: 1) The successful\ndevelopment of HKGAI-V1 itself - which outper-forms general-purpose models in\nhandling Hong Kong-specific culturally sensitive queries, and embodies a\n\"governance-embedded\" approach to digital sovereignty - empowers Hong Kong to\nexercise control over AI applications in critical sectors including public\nservices, legal systems, and edu-cation. 2) The development of the proprietary\nAdversarial HK Value Benchmark, a rigorous tool for evaluating model alignment\nwith local ethical and legal stand-ards under challenging conditions. By\ndocumenting these achievements, the paper provides not only a technological\nartifact but also a replicable blueprint for developing advanced, regionally\nfocused AI systems deeply rooted in their local identities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11502v1", "cate": "cs.CL", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2503.04051", "title": "RA-DP: Rapid Adaptive Diffusion Policy for Training-Free High-frequency Robotics Replanning", "authors": ["Xi Ye", "Rui Heng Yang", "Jun Jin", "Yinchuan Li", "Amir Rasouli"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2025", "url": "http://arxiv.org/abs/2503.04051v2", "summary": "Diffusion models exhibit impressive scalability in robotic task learning, yet\nthey struggle to adapt to novel, highly dynamic environments. This limitation\nprimarily stems from their constrained replanning ability: they either operate\nat a low frequency due to a time-consuming iterative sampling process, or are\nunable to adapt to unforeseen feedback in case of rapid replanning. To address\nthese challenges, we propose RA-DP, a novel diffusion policy framework with\ntraining-free high-frequency replanning ability that solves the above\nlimitations in adapting to unforeseen dynamic environments. Specifically, our\nmethod integrates guidance signals which are often easily obtained in the new\nenvironment during the diffusion sampling process, and utilizes a novel action\nqueue mechanism to generate replanned actions at every denoising step without\nretraining, thus forming a complete training-free framework for robot motion\nadaptation in unseen environments. Extensive evaluations have been conducted in\nboth well-recognized simulation benchmarks and real robot tasks. Results show\nthat RA-DP outperforms the state-of-the-art diffusion-based methods in terms of\nreplanning frequency and success rate. Moreover, we show that our framework is\ntheoretically compatible with any training-free guidance signal.", "comment": "Accepted by IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2025", "pdf_url": "http://arxiv.org/pdf/2503.04051v2", "cate": "cs.RO", "date": "2025-03-06", "updated": "2025-07-15"}
{"id": "2507.10587", "title": "Anthropomimetic Uncertainty: What Verbalized Uncertainty in Language Models is Missing", "authors": ["Dennis Ulmer", "Alexandra Lorson", "Ivan Titov", "Christian Hardmeier"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10587v1", "summary": "Human users increasingly rely on natural language interactions with large\nlanguage models (LLMs) in order to receive help on a large variety of tasks and\nproblems. However, the trustworthiness and perceived legitimacy of LLMs is\nundermined by the fact that their output is frequently stated in very confident\nterms, even when its accuracy is questionable. Therefore, there is a need to\nsignal the confidence of the language model to a user in order to reap the\nbenefits of human-machine collaboration and mitigate potential harms.\nVerbalized uncertainty is the expression of confidence with linguistic means,\nan approach that integrates perfectly into language-based interfaces.\nNevertheless, most recent research in natural language processing (NLP)\noverlooks the nuances surrounding human uncertainty communication and the data\nbiases that influence machine uncertainty communication. We argue for\nanthropomimetic uncertainty, meaning that intuitive and trustworthy uncertainty\ncommunication requires a degree of linguistic authenticity and personalization\nto the user, which could be achieved by emulating human communication. We\npresent a thorough overview over the research in human uncertainty\ncommunication, survey ongoing research, and perform additional analyses to\ndemonstrate so-far overlooked biases in verbalized uncertainty. We conclude by\npointing out unique factors in human-machine communication of uncertainty and\ndeconstruct anthropomimetic uncertainty into future research directions for\nNLP.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10587v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.10809", "title": "Uncovering Causal Relation Shifts in Event Sequences under Out-of-Domain Interventions", "authors": ["Kazi Tasnim Zinat", "Yun Zhou", "Xiang Lyu", "Yawei Wang", "Zhicheng Liu", "Panpan Xu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at ICANN 2025", "url": "http://arxiv.org/abs/2507.10809v1", "summary": "Inferring causal relationships between event pairs in a temporal sequence is\napplicable in many domains such as healthcare, manufacturing, and\ntransportation. Most existing work on causal inference primarily focuses on\nevent types within the designated domain, without considering the impact of\nexogenous out-of-domain interventions. In real-world settings, these\nout-of-domain interventions can significantly alter causal dynamics. To address\nthis gap, we propose a new causal framework to define average treatment effect\n(ATE), beyond independent and identically distributed (i.i.d.) data in classic\nRubin's causal framework, to capture the causal relation shift between events\nof temporal process under out-of-domain intervention. We design an unbiased ATE\nestimator, and devise a Transformer-based neural network model to handle both\nlong-range temporal dependencies and local patterns while integrating\nout-of-domain intervention information into process modeling. Extensive\nexperiments on both simulated and real-world datasets demonstrate that our\nmethod outperforms baselines in ATE estimation and goodness-of-fit under\nout-of-domain-augmented point processes.", "comment": "Accepted at ICANN 2025", "pdf_url": "http://arxiv.org/pdf/2507.10809v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11075", "title": "Joint angle model based learning to refine kinematic human pose estimation", "authors": ["Chang Peng", "Yifei Zhou", "Huifeng Xi", "Shiqing Huang", "Chuangye Chen", "Jianming Yang", "Bao Yang", "Zhenyu Jiang"], "categories": ["cs.CV", "cs.AI", "I.4.9; I.5.4; J.3"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11075v1", "summary": "Marker-free human pose estimation (HPE) has found increasing applications in\nvarious fields. Current HPE suffers from occasional errors in keypoint\nrecognition and random fluctuation in keypoint trajectories when analyzing\nkinematic human poses. The performance of existing deep learning-based models\nfor HPE refinement is considerably limited by inaccurate training datasets in\nwhich the keypoints are manually annotated. This paper proposed a novel method\nto overcome the difficulty through joint angle-based modeling. The key\ntechniques include: (i) A joint angle-based model of human pose, which is\nrobust to describe kinematic human poses; (ii) Approximating temporal variation\nof joint angles through high order Fourier series to get reliable \"ground\ntruth\"; (iii) A bidirectional recurrent network is designed as a\npost-processing module to refine the estimation of well-established HRNet.\nTrained with the high-quality dataset constructed using our method, the network\ndemonstrates outstanding performance to correct wrongly recognized joints and\nsmooth their spatiotemporal trajectories. Tests show that joint angle-based\nrefinement (JAR) outperforms the state-of-the-art HPE refinement network in\nchallenging cases like figure skating and breaking.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11075v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10422", "title": "Self-Admitted GenAI Usage in Open-Source Software", "authors": ["Tao Xiao", "Youmei Fan", "Fabio Calefato", "Christoph Treude", "Raula Gaikovina Kula", "Hideaki Hata", "Sebastian Baltes"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      17 pages, 8 tables, 1 figures, currently under review", "url": "http://arxiv.org/abs/2507.10422v2", "summary": "The widespread adoption of generative AI (GenAI) tools such as GitHub Copilot\nand ChatGPT is transforming software development. Since generated source code\nis virtually impossible to distinguish from manually written code, their\nreal-world usage and impact on open-source software development remain poorly\nunderstood. In this paper, we introduce the concept of self-admitted GenAI\nusage, that is, developers explicitly referring to the use of GenAI tools for\ncontent creation in software artifacts. Using this concept as a lens to study\nhow GenAI tools are integrated into open-source software projects, we analyze a\ncurated sample of more than 250,000 GitHub repositories, identifying 1,292 such\nself-admissions across 156 repositories in commit messages, code comments, and\nproject documentation. Using a mixed methods approach, we derive a taxonomy of\n32 tasks, 10 content types, and 11 purposes associated with GenAI usage based\non 284 qualitatively coded mentions. We then analyze 13 documents with policies\nand usage guidelines for GenAI tools and conduct a developer survey to uncover\nthe ethical, legal, and practical concerns behind them. Our findings reveal\nthat developers actively manage how GenAI is used in their projects,\nhighlighting the need for project-level transparency, attribution, and quality\ncontrol practices in the new era of AI-assisted software development. Finally,\nwe examine the impact of GenAI adoption on code churn in 151 repositories with\nself-admitted GenAI usage and find no general increase, contradicting popular\nnarratives on the impact of GenAI on software development.", "comment": "17 pages, 8 tables, 1 figures, currently under review", "pdf_url": "http://arxiv.org/pdf/2507.10422v2", "cate": "cs.SE", "date": "2025-07-14", "updated": "2025-07-15"}
{"id": "2507.07935", "title": "Working with AI: Measuring the Occupational Implications of Generative AI", "authors": ["Kiran Tomlinson", "Sonia Jaffe", "Will Wang", "Scott Counts", "Siddharth Suri"], "categories": ["cs.AI", "cs.CY", "econ.GN", "q-fin.EC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      41 pages", "url": "http://arxiv.org/abs/2507.07935v2", "summary": "Given the rapid adoption of generative AI and its potential to impact a wide\nrange of tasks, understanding the effects of AI on the economy is one of\nsociety's most important questions. In this work, we take a step toward that\ngoal by analyzing the work activities people do with AI, how successfully and\nbroadly those activities are done, and combine that with data on what\noccupations do those activities. We analyze a dataset of 200k anonymized and\nprivacy-scrubbed conversations between users and Microsoft Bing Copilot, a\npublicly available generative AI system. We find the most common work\nactivities people seek AI assistance for involve gathering information and\nwriting, while the most common activities that AI itself is performing are\nproviding information and assistance, writing, teaching, and advising.\nCombining these activity classifications with measurements of task success and\nscope of impact, we compute an AI applicability score for each occupation. We\nfind the highest AI applicability scores for knowledge work occupation groups\nsuch as computer and mathematical, and office and administrative support, as\nwell as occupations such as sales whose work activities involve providing and\ncommunicating information. Additionally, we characterize the types of work\nactivities performed most successfully, how wage and education correlate with\nAI applicability, and how real-world usage compares to predictions of\noccupational AI impact.", "comment": "41 pages", "pdf_url": "http://arxiv.org/pdf/2507.07935v2", "cate": "cs.AI", "date": "2025-07-10", "updated": "2025-07-15"}
{"id": "2507.03439", "title": "On Complementation of Nondeterministic Finite Automata without Full Determinization (Technical Report)", "authors": ["Lukáš Holík", "Ondřej Lengál", "Juraj Major", "Adéla Štěpková", "Jan Strejček"], "categories": ["cs.FL", "cs.LO"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      Accepted at FCT'25", "url": "http://arxiv.org/abs/2507.03439v2", "summary": "Complementation of finite automata is a basic operation used in numerous\napplications. The standard way to complement a nondeterministic finite\nautomaton (NFA) is to transform it into an equivalent deterministic finite\nautomaton (DFA) and complement the DFA. The DFA can, however, be exponentially\nlarger than the corresponding NFA. In this paper, we study several alternative\napproaches to complementation, which are based either on reverse powerset\nconstruction or on two novel constructions that exploit a commonly occurring\nstructure of NFAs. Our experiment on a large data set shows that using a\ndifferent than the classical approach can in many cases yield significantly\nsmaller complements.", "comment": "Accepted at FCT'25", "pdf_url": "http://arxiv.org/pdf/2507.03439v2", "cate": "cs.FL", "date": "2025-07-04", "updated": "2025-07-14"}
{"id": "2504.02281", "title": "FinRL Contests: Benchmarking Data-driven Financial Reinforcement Learning Agents", "authors": ["Keyi Wang", "Nikolaus Holzer", "Ziyi Xia", "Yupeng Cao", "Jiechao Gao", "Anwar Walid", "Kairong Xiao", "Xiao-Yang Liu Yanglet"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2501.10709", "url": "http://arxiv.org/abs/2504.02281v4", "summary": "Financial reinforcement learning (FinRL) is now a practical paradigm for\nfinancial engineering. However, applying RL strategies to real-world trading\ntasks remains a challenge for individuals, as it is error-prone and\nengineering-heavy. The non-stationarity of financial data, low signal-to-noise\nratios, and various market frictions require deep accumulations. Although\nnumerous FinRL methods have been developed for tasks such as stock/crypto\ntrading and portfolio management, the lack of standardized task definitions,\nreal-time high-quality datasets, close-to-real market environments, and robust\nbaselines has hindered consistent reproduction in both open-source community\nand FinTech industry. To bridge this gap, we organized a series of FinRL\nContests from 2023 to 2025, covering a diverse range of financial tasks such as\nstock trading, order execution, crypto trading, and the use of large language\nmodel (LLM)-engineered signals. These contests attracted 200+ participants from\n100+ institutions over 20+ countries. To encourage participations, we provided\nstarter kits featuring GPU-optimized parallel market environments, ensemble\nlearning, and comprehensive instructions. In this paper, we summarize these\nbenchmarking efforts, detailing task formulations, data curation pipelines,\nenvironment implementations, evaluation protocols, participant performance, and\norganizational insights. It guides our follow-up FinRL contests, and also\nprovides a reference for FinAI contests alike.", "comment": "arXiv admin note: text overlap with arXiv:2501.10709", "pdf_url": "http://arxiv.org/pdf/2504.02281v4", "cate": "cs.CE", "date": "2025-04-03", "updated": "2025-07-15"}
{"id": "2507.10634", "title": "Learning to Quantize and Precode in Massive MIMO Systems for Energy Reduction: a Graph Neural Network Approach", "authors": ["Thomas Feys", "Liesbet Van der Perre", "François Rottenberg"], "categories": ["eess.SY", "cs.LG", "cs.SY", "eess.SP", "stat.ML"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10634v1", "summary": "Massive MIMO systems are moving toward increased numbers of radio frequency\nchains, higher carrier frequencies and larger bandwidths. As such,\ndigital-to-analog converters (DACs) are becoming a bottleneck in terms of\nhardware complexity and power consumption. In this work, non-linear precoding\nfor coarsely quantized downlink massive MIMO is studied. Given the NP-hard\nnature of this problem, a graph neural network (GNN) is proposed that directly\noutputs the precoded quantized vector based on the channel matrix and the\nintended transmit symbols. The model is trained in a self-supervised manner, by\ndirectly maximizing the achievable rate. To overcome the non-differentiability\nof the objective function, introduced due to the non-differentiable DAC\nfunctions, a straight-through Gumbel-softmax estimation of the gradient is\nproposed. The proposed method achieves a significant increase in achievable sum\nrate under coarse quantization. For instance, in the single-user case, the\nproposed method can achieve the same sum rate as maximum ratio transmission\n(MRT) by using one-bit DAC's as compared to 3 bits for MRT. This reduces the\nDAC's power consumption by a factor 4-7 and 3 for baseband and RF DACs\nrespectively. This, however, comes at the cost of increased digital signal\nprocessing power consumption. When accounting for this, the reduction in\noverall power consumption holds for a system bandwidth up to 3.5 MHz for\nbaseband DACs, while the RF DACs can maintain a power reduction of 2.9 for\nhigher bandwidths. Notably, indirect effects, which further reduce the power\nconsumption, such as a reduced fronthaul consumption and reduction in other\ncomponents, are not considered in this analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10634v1", "cate": "eess.SY", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2503.22370", "title": "Grasping a Handful: Sequential Multi-Object Dexterous Grasp Generation", "authors": ["Haofei Lu", "Yifei Dong", "Zehang Weng", "Florian Pokorny", "Jens Lundell", "Danica Kragic"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 7 figures", "url": "http://arxiv.org/abs/2503.22370v3", "summary": "We introduce the sequential multi-object robotic grasp sampling algorithm\nSeqGrasp that can robustly synthesize stable grasps on diverse objects using\nthe robotic hand's partial Degrees of Freedom (DoF). We use SeqGrasp to\nconstruct the large-scale Allegro Hand sequential grasping dataset SeqDataset\nand use it for training the diffusion-based sequential grasp generator\nSeqDiffuser. We experimentally evaluate SeqGrasp and SeqDiffuser against the\nstate-of-the-art non-sequential multi-object grasp generation method MultiGrasp\nin simulation and on a real robot. The experimental results demonstrate that\nSeqGrasp and SeqDiffuser reach an 8.71%-43.33% higher grasp success rate than\nMultiGrasp. Furthermore, SeqDiffuser is approximately 1000 times faster at\ngenerating grasps than SeqGrasp and MultiGrasp.", "comment": "8 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2503.22370v3", "cate": "cs.RO", "date": "2025-03-28", "updated": "2025-07-15"}
{"id": "2507.10589", "title": "Comparative Analysis of Vision Transformers and Traditional Deep Learning Approaches for Automated Pneumonia Detection in Chest X-Rays", "authors": ["Gaurav Singh"], "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.NE"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10589v1", "summary": "Pneumonia, particularly when induced by diseases like COVID-19, remains a\ncritical global health challenge requiring rapid and accurate diagnosis. This\nstudy presents a comprehensive comparison of traditional machine learning and\nstate-of-the-art deep learning approaches for automated pneumonia detection\nusing chest X-rays (CXRs). We evaluate multiple methodologies, ranging from\nconventional machine learning techniques (PCA-based clustering, Logistic\nRegression, and Support Vector Classification) to advanced deep learning\narchitectures including Convolutional Neural Networks (Modified LeNet,\nDenseNet-121) and various Vision Transformer (ViT) implementations (Deep-ViT,\nCompact Convolutional Transformer, and Cross-ViT). Using a dataset of 5,856\npediatric CXR images, we demonstrate that Vision Transformers, particularly the\nCross-ViT architecture, achieve superior performance with 88.25% accuracy and\n99.42% recall, surpassing traditional CNN approaches. Our analysis reveals that\narchitectural choices impact performance more significantly than model size,\nwith Cross-ViT's 75M parameters outperforming larger models. The study also\naddresses practical considerations including computational efficiency, training\nrequirements, and the critical balance between precision and recall in medical\ndiagnostics. Our findings suggest that Vision Transformers offer a promising\ndirection for automated pneumonia detection, potentially enabling more rapid\nand accurate diagnosis during health crises.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10589v1", "cate": "eess.IV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.10820", "title": "Semantic Context for Tool Orchestration", "authors": ["Robert Müller"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Workshop on Computer Use Agents @ ICML2025", "url": "http://arxiv.org/abs/2507.10820v1", "summary": "This paper demonstrates that Semantic Context (SC), leveraging descriptive\ntool information, is a foundational component for robust tool orchestration.\nOur contributions are threefold. First, we provide a theoretical foundation\nusing contextual bandits, introducing SC-LinUCB and proving it achieves lower\nregret and adapts favourably in dynamic action spaces. Second, we provide\nparallel empirical validation with Large Language Models, showing that SC is\ncritical for successful in-context learning in both static (efficient learning)\nand non-stationary (robust adaptation) settings. Third, we propose the FiReAct\npipeline, and demonstrate on a benchmark with over 10,000 tools that SC-based\nretrieval enables an LLM to effectively orchestrate over a large action space.\nThese findings provide a comprehensive guide to building more sample-efficient,\nadaptive, and scalable orchestration agents.", "comment": "Workshop on Computer Use Agents @ ICML2025", "pdf_url": "http://arxiv.org/pdf/2507.10820v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11077", "title": "GKNet: Graph-based Keypoints Network for Monocular Pose Estimation of Non-cooperative Spacecraft", "authors": ["Weizhao Ma", "Dong Zhou", "Yuhui Hu", "Zipeng He"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11077v1", "summary": "Monocular pose estimation of non-cooperative spacecraft is significant for\non-orbit service (OOS) tasks, such as satellite maintenance, space debris\nremoval, and station assembly. Considering the high demands on pose estimation\naccuracy, mainstream monocular pose estimation methods typically consist of\nkeypoint detectors and PnP solver. However, current keypoint detectors remain\nvulnerable to structural symmetry and partial occlusion of non-cooperative\nspacecraft. To this end, we propose a graph-based keypoints network for the\nmonocular pose estimation of non-cooperative spacecraft, GKNet, which leverages\nthe geometric constraint of keypoints graph. In order to better validate\nkeypoint detectors, we present a moderate-scale dataset for the spacecraft\nkeypoint detection, named SKD, which consists of 3 spacecraft targets, 90,000\nsimulated images, and corresponding high-precise keypoint annotations.\nExtensive experiments and an ablation study have demonstrated the high accuracy\nand effectiveness of our GKNet, compared to the state-of-the-art spacecraft\nkeypoint detectors. The code for GKNet and the SKD dataset is available at\nhttps://github.com/Dongzhou-1996/GKNet.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11077v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2502.14251", "title": "Bayesian Parameter Inference and Uncertainty Quantification for a Computational Pulmonary Hemodynamics Model Using Gaussian Processes", "authors": ["Amirreza Kachabi", "Sofia Altieri Correa", "Naomi C. Chesler", "Mitchel J. Colebank"], "categories": ["stat.AP", "cs.CE", "physics.bio-ph"], "primary_category": "Subjects:       Applications (stat.AP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.14251v2", "summary": "Subject-specific modeling is a powerful tool in cardiovascular research,\nproviding insights beyond the reach of current clinical diagnostics.\nLimitations in available clinical data require the incorporation of uncertainty\ninto models to improve guidance for personalized treatments. However, for\nclinical relevance, such modeling must be computationally efficient. In this\nstudy, we used a one-dimensional (1D) fluid dynamics model informed by\nexperimental data from a dog model of chronic thromboembolic pulmonary\nhypertension (CTEPH), incorporating measurements from multiple subjects under\nboth baseline and CTEPH conditions. Surgical intervention can alleviate CTEPH,\nyet patients with microvascular disease (e.g., remodeling and narrowing of\nsmall vessels) often exhibit persistent pulmonary hypertension, highlighting\nthe importance of assessing microvascular disease severity. Thus, each lung was\nmodeled separately to account for the heterogeneous nature of CTEPH, allowing\nus to explore lung-specific microvascular narrowing and resistance. We compared\ninferred parameters between baseline and CTEPH and examined their correlation\nwith clinical markers of disease severity. To accelerate model calibration, we\nemployed Gaussian process (GP) emulators, enabling the estimation of\nmicrovascular parameters and their uncertainties within a clinically feasible\ntimeframe. Our results demonstrated that CTEPH leads to heterogeneous\nmicrovascular adaptation, reflected in distinct parameter shifts. Notably, the\nchanges in model parameters strongly correlated with disease severity,\nespecially in the lung previously reported to have more advanced disease. This\nframework provides a rapid, uncertainty-aware method for evaluating\nmicrovascular dysfunction in CTEPH and may support more targeted treatment\nstrategies within a timeframe suitable for clinical application.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.14251v2", "cate": "stat.AP", "date": "2025-02-20", "updated": "2025-07-14"}
{"id": "2507.10979", "title": "Data-Driven Safety Certificates of Infinite Networks with Unknown Models and Interconnection Topologies", "authors": ["Mahdieh Zaker", "Amy Nejati", "Abolfazl Lavaei"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10979v1", "summary": "Infinite networks are complex interconnected systems comprising a countably\ninfinite number of subsystems, where counting them precisely poses a\nsignificant challenge due to the seemingly endless interconnected nature of the\nnetwork (e.g., counting vehicles on the road). In such scenarios, the presence\nof infinitely many subsystems within the network renders the existing analysis\nframeworks tailored for finite networks inapplicable to infinite ones. This\npaper is concerned with offering a data-driven approach, within a compositional\nframework, for the safety certification of infinite networks with both unknown\nmathematical models and interconnection topologies. Given the immense\ncomputational complexity stemming from the extensive dimension of infinite\nnetworks, our approach capitalizes on the joint dissipativity-type properties\nof subsystems, characterized by storage certificates. We introduce innovative\ncompositional data-driven conditions to construct a barrier certificate for the\ninfinite network leveraging storage certificates of its unknown subsystems\nderived from data, while offering correctness guarantees across the network\nsafety. We demonstrate that our compositional data-driven reasoning eliminates\nthe requirement for checking the traditional dissipativity condition, which\ntypically mandates precise knowledge of the interconnection topology. In\naddition, while existing data-driven literature demonstrates an exponential\ntrend in sample complexity with respect to network size, we showcase that our\ncompositional strategy notably reduces it to a linear scale in terms of the\nnumber of subsystems. We illustrate our data-driven results on two physical\ninfinite networks with unknown models and interconnection topologies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10979v1", "cate": "eess.SY", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10706", "title": "A Leap-on-Success Exhaustive Search Method to Find Optimal Robust Minimum Redundancy Arrays (RMRAs): New Array Configurations for Sensor Counts 11 to 20", "authors": ["Pradyumna Kunchala", "Ashish Patwari"], "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      21 pages, 8 Tables, 4 Figures", "url": "http://arxiv.org/abs/2507.10706v1", "summary": "Two-fold redundant sparse arrays (TFRAs) are designed to maintain accurate\ndirection estimation even in the event of a single sensor failure, leveraging\nthe deliberate coarray redundancy infused into their design. Robust Minimum\nRedundancy Arrays (RMRAs), a specialized class of TFRAs, optimize this\nredundancy to achieve the maximum possible aperture for a given number of\nsensors. However, finding optimal RMRA configurations is an NP-hard problem,\nwith prior research reporting optimal solutions only for arrays of up to ten\nsensors. This paper presents newly discovered optimal RMRA configurations for\narray sizes 11 to 15, identified using a novel Leap-on-Success exhaustive\nsearch algorithm that efficiently reduces computational effort by terminating\nthe search upon locating optimal solutions. The robustness of these arrays was\nvalidated under all single-element failure scenarios using MATLAB simulations,\nconfirming their superior resilience compared to some existing TFRAs vulnerable\nto failures at specific sensor positions. Furthermore, near-optimal\nconfigurations for array sizes 16 to 20 are also reported, highlighting the\npotential applicability of the proposed method for larger array designs given\nsufficient computational resources. This work not only advances the\nstate-of-the-art in RMRA design but also introduces an effective search\nmethodology that can be leveraged for future explorations in array\nconfiguration optimization.", "comment": "21 pages, 8 Tables, 4 Figures", "pdf_url": "http://arxiv.org/pdf/2507.10706v1", "cate": "eess.SP", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2505.00200", "title": "Characterizing gaussian mixture of motion modes for skid-steer vehicle state estimation", "authors": ["Ameya Salvi", "Mark Brudnak", "Jonathon M. Smereka", "Matthias Schmid", "Venkat Krovi"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.00200v2", "summary": "Skid-steered wheel mobile robots (SSWMRs) are characterized by the unique\ndomination of the tire-terrain skidding for the robot to move. The lack of\nreliable friction models cascade into unreliable motion models, especially the\nreduced ordered variants used for state estimation and robot control. Ensemble\nmodeling is an emerging research direction where the overall motion model is\nbroken down into a family of local models to distribute the performance and\nresource requirement and provide a fast real-time prediction. To this end, a\ngaussian mixture model based modeling identification of model clusters is\nadopted and implemented within an interactive multiple model (IMM) based state\nestimation. The framework is adopted and implemented for angular velocity as\nthe estimated state for a mid scaled skid-steered wheel mobile robot platform.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.00200v2", "cate": "cs.RO", "date": "2025-04-30", "updated": "2025-07-15"}
{"id": "2507.10596", "title": "PLEX: Perturbation-free Local Explanations for LLM-Based Text Classification", "authors": ["Yogachandran Rahulamathavan", "Misbah Farooq", "Varuna De Silva"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10596v1", "summary": "Large Language Models (LLMs) excel in text classification, but their\ncomplexity hinders interpretability, making it difficult to understand the\nreasoning behind their predictions. Explainable AI (XAI) methods like LIME and\nSHAP offer local explanations by identifying influential words, but they rely\non computationally expensive perturbations. These methods typically generate\nthousands of perturbed sentences and perform inferences on each, incurring a\nsubstantial computational burden, especially with LLMs. To address this, we\npropose \\underline{P}erturbation-free \\underline{L}ocal \\underline{Ex}planation\n(PLEX), a novel method that leverages the contextual embeddings extracted from\nthe LLM and a ``Siamese network\" style neural network trained to align with\nfeature importance scores. This one-off training eliminates the need for\nsubsequent perturbations, enabling efficient explanations for any new sentence.\nWe demonstrate PLEX's effectiveness on four different classification tasks\n(sentiment, fake news, fake COVID-19 news and depression), showing more than\n92\\% agreement with LIME and SHAP. Our evaluation using a ``stress test\"\nreveals that PLEX accurately identifies influential words, leading to a similar\ndecline in classification accuracy as observed with LIME and SHAP when these\nwords are removed. Notably, in some cases, PLEX demonstrates superior\nperformance in capturing the impact of key features. PLEX dramatically\naccelerates explanation, reducing time and computational overhead by two and\nfour orders of magnitude, respectively. This work offers a promising solution\nfor explainable LLM-based text classification.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10596v1", "cate": "cs.CL", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2507.10834", "title": "From Small to Large: A Graph Convolutional Network Approach for Solving Assortment Optimization Problems", "authors": ["Guokai Li", "Pin Gao", "Stefanus Jasin", "Zizhuo Wang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Conference version. The journal version will be updated soon", "url": "http://arxiv.org/abs/2507.10834v1", "summary": "Assortment optimization involves selecting a subset of substitutable products\n(subject to certain constraints) to maximize the expected revenue. It is a\nclassic problem in revenue management and finds applications across various\nindustries. However, the problem is usually NP-hard due to its combinatorial\nand non-linear nature. In this work, we explore how graph concolutional\nnetworks (GCNs) can be leveraged to efficiently solve constrained assortment\noptimization under the mixed multinomial logit choice model. We first develop a\ngraph representation of the assortment problem, then train a GCN to learn the\npatterns of optimal assortments, and lastly propose two inference policies\nbased on the GCN's output. Due to the GCN's inherent ability to generalize\nacross inputs of varying sizes, we can use a GCN trained on small-scale\ninstances to facilitate large-scale instances. Extensive numerical experiments\ndemonstrate that given a GCN trained on small-scale instances (e.g., with 20\nproducts), the proposed policies can achieve superior performance (90%+\noptimality) on large-scale instances (with up to 2,000 products) within\nseconds, which outperform existing heuristic policies in both performance and\nefficiency. Furthermore, we extend our framework to a model-free setting where\nthe underlying choice model is unknown but transaction data is available. We\nalso conduct numerical experiments to demonstrate the effectiveness and\nefficiency of our proposed policies in this setting.", "comment": "Conference version. The journal version will be updated soon", "pdf_url": "http://arxiv.org/pdf/2507.10834v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11081", "title": "Automatic Road Subsurface Distress Recognition from Ground Penetrating Radar Images using Deep Learning-based Cross-verification", "authors": ["Chang Peng", "Bao Yang", "Meiqi Li", "Ge Zhang", "Hui Sun", "Zhenyu Jiang"], "categories": ["cs.CV", "cs.AI", "I.4.9; I.5.4; J.2"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11081v1", "summary": "Ground penetrating radar (GPR) has become a rapid and non-destructive\nsolution for road subsurface distress (RSD) detection. However, RSD recognition\nfrom GPR images is labor-intensive and heavily relies on inspectors' expertise.\nDeep learning offers the possibility for automatic RSD recognition, but its\ncurrent performance is limited by two factors: Scarcity of high-quality dataset\nfor network training and insufficient capability of network to distinguish RSD.\nIn this study, a rigorously validated 3D GPR dataset containing 2134 samples of\ndiverse types was constructed through field scanning. Based on the finding that\nthe YOLO model trained with one of the three scans of GPR images exhibits\nvarying sensitivity to specific type of RSD, we proposed a novel\ncross-verification strategy with outstanding accuracy in RSD recognition,\nachieving recall over 98.6% in field tests. The approach, integrated into an\nonline RSD detection system, can reduce the labor of inspection by around 90%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11081v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.06803", "title": "Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams", "authors": ["Matthew Anderson Hendricks", "Alice Cicirello"], "categories": ["cs.CL", "cs.AI", "cs.CE"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      v2 - typos and imprecisions corrected", "url": "http://arxiv.org/abs/2507.06803v2", "summary": "This paper contributes to speeding up the design and deployment of\nengineering dynamical systems by proposing a strategy for exploiting domain and\nexpert knowledge for the automated generation of dynamical system computational\nmodel starting from a corpus of document relevant to the dynamical system of\ninterest and an input document describing the specific system. This strategy is\nimplemented in five steps and, crucially, it uses system modeling language\ndiagrams (SysML) to extract accurate information about the dependencies,\nattributes, and operations of components. Natural Language Processing (NLP)\nstrategies and Large Language Models (LLMs) are employed in specific tasks to\nimprove intermediate outputs of the SySML diagrams automated generation, such\nas: list of key nouns; list of extracted relationships; list of key phrases and\nkey relationships; block attribute values; block relationships; and BDD diagram\ngeneration. The applicability of automated SysML diagram generation is\nillustrated with different case studies. The computational models of complex\ndynamical systems from SysML diagrams are then obtained via code generation and\ncomputational model generation steps. In the code generation step, NLP\nstrategies are used for summarization, while LLMs are used for validation only.\nThe proposed approach is not limited to a specific system, domain, or\ncomputational software. The applicability of the proposed approach is shown via\nan end-to-end example from text to model of a simple pendulum, showing improved\nperformance compared to results yielded by LLMs only.", "comment": "v2 - typos and imprecisions corrected", "pdf_url": "http://arxiv.org/pdf/2507.06803v2", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-15"}
{"id": "2507.11021", "title": "Approximate solutions to games of ordered preference", "authors": ["Pau de las Heras Molins", "Eric Roy-Almonacid", "Dong Ho Lee", "Lasse Peters", "David Fridovich-Keil", "Georgios Bakirtzis"], "categories": ["eess.SY", "cs.GT", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11021v1", "summary": "Autonomous vehicles must balance ranked objectives, such as minimizing travel\ntime, ensuring safety, and coordinating with traffic. Games of ordered\npreference effectively model these interactions but become computationally\nintractable as the time horizon, number of players, or number of preference\nlevels increase. While receding horizon frameworks mitigate long-horizon\nintractability by solving sequential shorter games, often warm-started, they do\nnot resolve the complexity growth inherent in existing methods for solving\ngames of ordered preference. This paper introduces a solution strategy that\navoids excessive complexity growth by approximating solutions using\nlexicographic iterated best response (IBR) in receding horizon, termed\n\"lexicographic IBR over time.\" Lexicographic IBR over time uses past\ninformation to accelerate convergence. We demonstrate through simulated traffic\nscenarios that lexicographic IBR over time efficiently computes\napproximate-optimal solutions for receding horizon games of ordered preference,\nconverging towards generalized Nash equilibria.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11021v1", "cate": "eess.SY", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11036", "title": "Dual RIS-Assisted Monostatic L-Band Radar Target Detection in NLoS Scenarios", "authors": ["Salman Liaquat", "Ijaz Haider Naqvi", "Nor Muzlifah Mahyuddin"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at the 9th International Conference on Communications and Future Internet", "url": "http://arxiv.org/abs/2507.11036v1", "summary": "The use of a single Reconfigurable Intelligent Surface (RIS) to boost the\nsignal-to-noise ratio (SNR) at the radar offers significant improvement in\ndetecting targets, especially in non-line-of-sight (NLoS) scenarios. However,\nthere are scenarios where no path exists between the radar and the target, even\nwith a single RIS-assisted radar, due to other present obstacles. This paper\nderives an expression for SNR in target detection scenarios where dual RISs\nassist a monostatic radar in NLoS situations. We calculate the power received\nat the radar through a dual RIS configuration. We show that the SNR performance\nof RIS-assisted radars can improve with known locations of the radar and RISs.\nOur results demonstrate that the required accuracy in target localization can\nbe achieved by controlling the number of RISs, the number of unit cells in each\nRIS, and properly selecting the locations of RISs to cover the desired region.\nThe performance of dual RIS-assisted radar systems can surpass that of single\nRIS-assisted radar systems under favourable alignment and sufficiently large\nRIS sizes.", "comment": "Accepted for presentation at the 9th International Conference on\n  Communications and Future Internet", "pdf_url": "http://arxiv.org/pdf/2507.11036v1", "cate": "eess.SP", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2505.04980", "title": "LVLM-MPC Collaboration for Autonomous Driving: A Safety-Aware and Task-Scalable Control Architecture", "authors": ["Kazuki Atsuta", "Kohei Honda", "Hiroyuki Okuda", "Tatsuya Suzuki"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 8 figures", "url": "http://arxiv.org/abs/2505.04980v2", "summary": "This paper proposes a novel Large Vision-Language Model (LVLM) and Model\nPredictive Control (MPC) integration framework that delivers both task\nscalability and safety for Autonomous Driving (AD). LVLMs excel at high-level\ntask planning across diverse driving scenarios. However, since these foundation\nmodels are not specifically designed for driving and their reasoning is not\nconsistent with the feasibility of low-level motion planning, concerns remain\nregarding safety and smooth task switching. This paper integrates LVLMs with\nMPC Builder, which automatically generates MPCs on demand, based on symbolic\ntask commands generated by the LVLM, while ensuring optimality and safety. The\ngenerated MPCs can strongly assist the execution or rejection of LVLM-driven\ntask switching by providing feedback on the feasibility of the given tasks and\ngenerating task-switching-aware MPCs. Our approach provides a safe, flexible,\nand adaptable control framework, bridging the gap between cutting-edge\nfoundation models and reliable vehicle operation. We demonstrate the\neffectiveness of our approach through a simulation experiment, showing that our\nsystem can safely and effectively handle highway driving while maintaining the\nflexibility and adaptability of LVLMs.", "comment": "8 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2505.04980v2", "cate": "cs.RO", "date": "2025-05-08", "updated": "2025-07-15"}
{"id": "2507.10599", "title": "Emergence of Hierarchical Emotion Organization in Large Language Models", "authors": ["Bo Zhao", "Maya Okawa", "Eric J. Bigelow", "Rose Yu", "Tomer Ullman", "Ekdeep Singh Lubana", "Hidenori Tanaka"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10599v1", "summary": "As large language models (LLMs) increasingly power conversational agents,\nunderstanding how they model users' emotional states is critical for ethical\ndeployment. Inspired by emotion wheels -- a psychological framework that argues\nemotions organize hierarchically -- we analyze probabilistic dependencies\nbetween emotional states in model outputs. We find that LLMs naturally form\nhierarchical emotion trees that align with human psychological models, and\nlarger models develop more complex hierarchies. We also uncover systematic\nbiases in emotion recognition across socioeconomic personas, with compounding\nmisclassifications for intersectional, underrepresented groups. Human studies\nreveal striking parallels, suggesting that LLMs internalize aspects of social\nperception. Beyond highlighting emergent emotional reasoning in LLMs, our\nresults hint at the potential of using cognitively-grounded theories for\ndeveloping better model evaluations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10599v1", "cate": "cs.CL", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2507.10861", "title": "Visually grounded emotion regulation via diffusion models and user-driven reappraisal", "authors": ["Edoardo Pinzuti", "Oliver Tüscher", "André Ferreira Castro"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10861v1", "summary": "Cognitive reappraisal is a key strategy in emotion regulation, involving\nreinterpretation of emotionally charged stimuli to alter affective responses.\nDespite its central role in clinical and cognitive science, real-world\nreappraisal interventions remain cognitively demanding, abstract, and primarily\nverbal. This reliance on higher-order cognitive and linguistic processes is\noften impaired in individuals with trauma or depression, limiting the\neffectiveness of standard approaches. Here, we propose a novel, visually based\naugmentation of cognitive reappraisal by integrating large-scale text-to-image\ndiffusion models into the emotional regulation process. Specifically, we\nintroduce a system in which users reinterpret emotionally negative images via\nspoken reappraisals, which are transformed into supportive, emotionally\ncongruent visualizations using stable diffusion models with a fine-tuned\nIP-adapter. This generative transformation visually instantiates users'\nreappraisals while maintaining structural similarity to the original stimuli,\nexternalizing and reinforcing regulatory intent. To test this approach, we\nconducted a within-subject experiment (N = 20) using a modified cognitive\nemotion regulation (CER) task. Participants reappraised or described aversive\nimages from the International Affective Picture System (IAPS), with or without\nAI-generated visual feedback. Results show that AI-assisted reappraisal\nsignificantly reduced negative affect compared to both non-AI and control\nconditions. Further analyses reveal that sentiment alignment between\nparticipant reappraisals and generated images correlates with affective relief,\nsuggesting that multimodal coherence enhances regulatory efficacy. These\nfindings demonstrate that generative visual input can support cogitive\nreappraisal and open new directions at the intersection of generative AI,\naffective computing, and therapeutic technology.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10861v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11085", "title": "Atmos-Bench: 3D Atmospheric Structures for Climate Insight", "authors": ["Tianchi Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11085v1", "summary": "Atmospheric structure, represented by backscatter coefficients (BC) recovered\nfrom satellite LiDAR attenuated backscatter (ATB), provides a volumetric view\nof clouds, aerosols, and molecules, playing a critical role in human\nactivities, climate understanding, and extreme weather forecasting. Existing\nmethods often rely on auxiliary inputs and simplified physics-based\napproximations, and lack a standardized 3D benchmark for fair evaluation.\nHowever, such approaches may introduce additional uncertainties and\ninsufficiently capture realistic radiative transfer and atmospheric\nscattering-absorption effects. To bridge these gaps, we present Atmos-Bench:\nthe first 3D atmospheric benchmark, along with a novel FourCastX:\nFrequency-enhanced Spatio-Temporal Mixture-of-Experts Network that (a)\ngenerates 921,600 image slices from 3D scattering volumes simulated at 532 nm\nand 355 nm by coupling WRF with an enhanced COSP simulator over 384 land-ocean\ntime steps, yielding high-quality voxel-wise references; (b) embeds ATB-BC\nphysical constraints into the model architecture, promoting energy consistency\nduring restoration; (c) achieves consistent improvements on the Atmos-Bench\ndataset across both 355 nm and 532 nm bands, outperforming state-of-the-art\nbaseline models without relying on auxiliary inputs. Atmos-Bench establishes a\nnew standard for satellite-based 3D atmospheric structure recovery and paves\nthe way for deeper climate insight.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11085v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11064", "title": "Standards-Compliant DM-RS Allocation via Temporal Channel Prediction for Massive MIMO Systems", "authors": ["Sehyun Ryu", "Hyun Jong Yang"], "categories": ["eess.SY", "cs.AI", "cs.SY", "eess.SP"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11064v1", "summary": "Reducing feedback overhead in beyond 5G networks is a critical challenge, as\nthe growing number of antennas in modern massive MIMO systems substantially\nincreases the channel state information (CSI) feedback demand in frequency\ndivision duplex (FDD) systems. To address this, extensive research has focused\non CSI compression and prediction, with neural network-based approaches gaining\nmomentum and being considered for integration into the 3GPP 5G-Advanced\nstandards. While deep learning has been effectively applied to CSI-limited\nbeamforming and handover optimization, reference signal allocation under such\nconstraints remains surprisingly underexplored. To fill this gap, we introduce\nthe concept of channel prediction-based reference signal allocation (CPRS),\nwhich jointly optimizes channel prediction and DM-RS allocation to improve data\nthroughput without requiring CSI feedback. We further propose a\nstandards-compliant ViViT/CNN-based architecture that implements CPRS by\ntreating evolving CSI matrices as sequential image-like data, enabling\nefficient and adaptive transmission in dynamic environments. Simulation results\nusing ray-tracing channel data generated in NVIDIA Sionna validate the proposed\nmethod, showing up to 36.60% throughput improvement over benchmark strategies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11064v1", "cate": "eess.SY", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11224", "title": "Fairness-Aware Secure Integrated Sensing and Communications with Fractional Programming", "authors": ["Ali Khandan Boroujeni", "Kuranage Roche Rayan Ranasinghe", "Giuseppe Thadeu Freitas de Abreu", "Stefan Köpsell", "Ghazal Bagheri", "Rafael F. Schaefer"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Submitted to an IEEE journal", "url": "http://arxiv.org/abs/2507.11224v1", "summary": "We propose a novel secure integrated sensing and communications (ISAC) system\ndesigned to serve multiple communication users (CUs) and targets. To that end,\nwe formulate an optimization problem that maximizes the secrecy rate under\nconstraints balancing both communication and sensing requirements. To enhance\nfairness among users, an entropy-regularized fairness metric is introduced\nwithin the problem framework. We then propose a solution employing an\naccelerated quadratic transform (QT) with a non-homogeneous bound to\niteratively solve two subproblems, thereby effectively optimizing the overall\nobjective. This approach ensures robust security and fairness in resource\nallocation for ISAC systems. Finally, simulation results verify the performance\ngains in terms of average secrecy rate, average data rate, and beam gain.", "comment": "Submitted to an IEEE journal", "pdf_url": "http://arxiv.org/pdf/2507.11224v1", "cate": "eess.SP", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2506.15249", "title": "Context-Aware Deep Lagrangian Networks for Model Predictive Control", "authors": ["Lucas Schulze", "Jan Peters", "Oleg Arenz"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted to the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025)", "url": "http://arxiv.org/abs/2506.15249v2", "summary": "Controlling a robot based on physics-consistent dynamic models, such as Deep\nLagrangian Networks (DeLaN), can improve the generalizability and\ninterpretability of the resulting behavior. However, in complex environments,\nthe number of objects to potentially interact with is vast, and their physical\nproperties are often uncertain. This complexity makes it infeasible to employ a\nsingle global model. Therefore, we need to resort to online system\nidentification of context-aware models that capture only the currently relevant\naspects of the environment. While physical principles such as the conservation\nof energy may not hold across varying contexts, ensuring physical plausibility\nfor any individual context-aware model can still be highly desirable,\nparticularly when using it for receding horizon control methods such as model\npredictive control (MPC). Hence, in this work, we extend DeLaN to make it\ncontext-aware, combine it with a recurrent network for online system\nidentification, and integrate it with an MPC for adaptive, physics-consistent\ncontrol. We also combine DeLaN with a residual dynamics model to leverage the\nfact that a nominal model of the robot is typically available. We evaluate our\nmethod on a 7-DOF robot arm for trajectory tracking under varying loads. Our\nmethod reduces the end-effector tracking error by 39%, compared to a 21%\nimprovement achieved by a baseline that uses an extended Kalman filter.", "comment": "Accepted to the 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025)", "pdf_url": "http://arxiv.org/pdf/2506.15249v2", "cate": "cs.RO", "date": "2025-06-18", "updated": "2025-07-15"}
{"id": "2507.10607", "title": "Neural Expectation Operators", "authors": ["Qian Qi"], "categories": ["math.PR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Probability (math.PR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10607v1", "summary": "This paper introduces \\textbf{Measure Learning}, a paradigm for modeling\nambiguity via non-linear expectations. We define Neural Expectation Operators\nas solutions to Backward Stochastic Differential Equations (BSDEs) whose\ndrivers are parameterized by neural networks. The main mathematical\ncontribution is a rigorous well-posedness theorem for BSDEs whose drivers\nsatisfy a local Lipschitz condition in the state variable $y$ and quadratic\ngrowth in its martingale component $z$. This result circumvents the classical\nglobal Lipschitz assumption, is applicable to common neural network\narchitectures (e.g., with ReLU activations), and holds for exponentially\nintegrable terminal data, which is the sharp condition for this setting. Our\nprimary innovation is to build a constructive bridge between the abstract, and\noften restrictive, assumptions of the deep theory of quadratic BSDEs and the\nworld of machine learning, demonstrating that these conditions can be met by\nconcrete, verifiable neural network designs. We provide constructive methods\nfor enforcing key axiomatic properties, such as convexity, by architectural\ndesign. The theory is extended to the analysis of fully coupled\nForward-Backward SDE systems and to the asymptotic analysis of large\ninteracting particle systems, for which we establish both a Law of Large\nNumbers (propagation of chaos) and a Central Limit Theorem. This work provides\nthe foundational mathematical framework for data-driven modeling under\nambiguity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10607v1", "cate": "math.PR", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.10871", "title": "GALDS: A Graph-Autoencoder-based Latent Dynamics Surrogate model to predict neurite material transport", "authors": ["Tsung Yeh Hsieh", "Yongjie Jessica Zhang"], "categories": ["cs.LG", "cs.NA", "math.NA", "physics.med-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10871v1", "summary": "Neurons exhibit intricate geometries within their neurite networks, which\nplay a crucial role in processes such as signaling and nutrient transport.\nAccurate simulation of material transport in the networks is essential for\nunderstanding these biological phenomena but poses significant computational\nchallenges because of the complex tree-like structures involved. Traditional\napproaches are time-intensive and resource-demanding, yet the inherent\nproperties of neuron trees, which consists primarily of pipes with steady-state\nparabolic velocity profiles and bifurcations, provide opportunities for\ncomputational optimization. To address these challenges, we propose a\nGraph-Autoencoder-based Latent Dynamics Surrogate (GALDS) model, which is\nspecifically designed to streamline the simulation of material transport in\nneural trees. GALDS employs a graph autoencoder to encode latent\nrepresentations of the network's geometry, velocity fields, and concentration\nprofiles. These latent space representations are then assembled into a global\ngraph, which is subsequently used to predict system dynamics in the latent\nspace via a trained graph latent space system dynamic model, inspired by the\nNeural Ordinary Differential Equations (Neural ODEs) concept. The integration\nof an autoencoder allows for the use of smaller graph neural network models\nwith reduced training data requirements. Furthermore, the Neural ODE component\neffectively mitigates the issue of error accumulation commonly encountered in\nrecurrent neural networks. The effectiveness of the GALDS model is demonstrated\nthrough results on eight unseen geometries and four abnormal transport\nexamples, where our approach achieves mean relative error of 3% with maximum\nrelative error <8% and demonstrates a 10-fold speed improvement compared to\nprevious surrogate model approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10871v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11099", "title": "A Survey on Interpretability in Visual Recognition", "authors": ["Qiyang Wan", "Chengzhi Gao", "Ruiping Wang", "Xilin Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      20 pages, 7 figures, 2 tables. Under review", "url": "http://arxiv.org/abs/2507.11099v1", "summary": "In recent years, visual recognition methods have advanced significantly,\nfinding applications across diverse fields. While researchers seek to\nunderstand the mechanisms behind the success of these models, there is also a\ngrowing impetus to deploy them in critical areas like autonomous driving and\nmedical diagnostics to better diagnose failures, which promotes the development\nof interpretability research. This paper systematically reviews existing\nresearch on the interpretability of visual recognition models and proposes a\ntaxonomy of methods from a human-centered perspective. The proposed taxonomy\ncategorizes interpretable recognition methods based on Intent, Object,\nPresentation, and Methodology, thereby establishing a systematic and coherent\nset of grouping criteria for these XAI methods. Additionally, we summarize the\nrequirements for evaluation metrics and explore new opportunities enabled by\nrecent technologies, such as large multimodal models. We aim to organize\nexisting research in this domain and inspire future investigations into the\ninterpretability of visual recognition models.", "comment": "20 pages, 7 figures, 2 tables. Under review", "pdf_url": "http://arxiv.org/pdf/2507.11099v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11113", "title": "Optimal Honeypot Ratio and Convergent Fictitious-Play Learning in Signaling Games for CPS Defense", "authors": ["Yueyue Xu", "Yuewei Chen", "Lin Wang", "Zhaoyang Cheng", "Xiaoming Hu"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      14 pages, 8 figures", "url": "http://arxiv.org/abs/2507.11113v1", "summary": "Cyber-Physical Systems (CPSs) are facing a fast-growing wave of attacks. To\nachieve effective proactive defense, this paper models honeypot deployment as a\ngamma-fixed signaling game in which node liveness serves as the only signal and\nnormal-node signal gamma is exogenously fixed. We define the gamma-perfect\nBayesian-Nash equilibrium (gamma-PBNE). Analytical expressions are obtained for\nall gamma-PBNEs, revealing three distinct equilibrium regimes that depend on\nthe priori honeypot ratio. Furthermore, the optimal honeypot ratio and\nsignaling strategy that jointly maximize the network average utility are\nobtained. To capture strategic interaction over time, we develop a\ndiscrete-time fictitious-play algorithm that couples Bayesian belief updates\nwith empirical best responses. We prove that, as long as the honeypot ratio is\nperturbed within a non-degenerate neighbourhood of the optimum, every\nfictitious-play path converges to the defender-optimal gamma-PBNE. Numerical\nresults confirm the effectiveness of the proposed method and demonstrate its\napplicability to CPS defense.", "comment": "14 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.11113v1", "cate": "eess.SY", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11284", "title": "Sensing Accuracy Optimization for Multi-UAV SAR Interferometry with Data Offloading", "authors": ["Mohamed-Amine Lahmeri", "Pouya Fakharizadeh", "Víctor Mustieles-Pérez", "Martin Vossiek", "Gerhard Krieger", "Robert Schober"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11284v1", "summary": "The integration of unmanned aerial vehicles (UAVs) with radar imaging sensors\nhas revolutionized the monitoring of dynamic and local Earth surface processes\nby enabling high-resolution and cost-effective remote sensing. This paper\ninvestigates the optimization of the sensing accuracy of a UAV swarm deployed\nto perform multi-baseline interferometric synthetic aperture radar (InSAR)\nsensing. In conventional single-baseline InSAR systems, only one synthetic\naperture radar (SAR) antenna pair acquires two SAR images from two distinct\nangles to generate a digital elevation model (DEM) of the target area. However,\nmulti-baseline InSAR extends this concept by aggregating multiple acquisitions\nfrom different angles, thus, significantly enhancing the vertical accuracy of\nthe DEM. The heavy computations required for this process are performed on the\nground and, therefore, the radar data is transmitted in real time to a ground\nstation (GS) via a frequency-division multiple access (FDMA) air-to-ground\nbackhaul link. This work focuses on improving the sensing precision by\nminimizing the height error of the averaged DEM while simultaneously ensuring\nsensing and communication quality-of-service (QoS). To this end, the UAV\nformation, velocity, and communication power allocation are jointly optimized\nusing evolutionary algorithms (EAs). Our approach is benchmarked against\nestablished optimization methods, including genetic algorithms (GAs), simulated\nannealing (SA), and deep reinforcement learning (DRL) techniques. Numerical\nresults show that the proposed solution outperforms these baseline schemes and\nachieves sub-decimeter vertical accuracy in several scenarios. These findings\nunderline the potential of coordinated UAV swarms for delivering high-precision\nand real-time Earth observations through radar interferometry.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11284v1", "cate": "eess.SP", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10615", "title": "A Survey on Medical Image Compression: From Traditional to Learning-Based", "authors": ["Guofeng Tong", "Sixuan Liu", "Yang Lv", "Hanyu Pei", "Feng-Lei Fan"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10615v1", "summary": "The exponential growth of medical imaging has created significant challenges\nin data storage, transmission, and management for healthcare systems. In this\nvein, efficient compression becomes increasingly important. Unlike natural\nimage compression, medical image compression prioritizes preserving diagnostic\ndetails and structural integrity, imposing stricter quality requirements and\ndemanding fast, memory-efficient algorithms that balance computational\ncomplexity with clinically acceptable reconstruction quality. Meanwhile, the\nmedical imaging family includes a plethora of modalities, each possessing\ndifferent requirements. For example, 2D medical image (e.g., X-rays,\nhistopathological images) compression focuses on exploiting intra-slice spatial\nredundancy, while volumetric medical image faces require handling intra-slice\nand inter-slice spatial correlations, and 4D dynamic imaging (e.g., time-series\nCT/MRI, 4D ultrasound) additionally demands processing temporal correlations\nbetween consecutive time frames. Traditional compression methods, grounded in\nmathematical transforms and information theory principles, provide solid\ntheoretical foundations, predictable performance, and high standardization\nlevels, with extensive validation in clinical environments. In contrast, deep\nlearning-based approaches demonstrate remarkable adaptive learning capabilities\nand can capture complex statistical characteristics and semantic information\nwithin medical images. This comprehensive survey establishes a two-facet\ntaxonomy based on data structure (2D vs 3D/4D) and technical approaches\n(traditional vs learning-based), thereby systematically presenting the complete\ntechnological evolution, analyzing the unique technical challenges, and\nprospecting future directions in medical image compression.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10615v1", "cate": "eess.IV", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.00236", "title": "Sim2Real Diffusion: Learning Cross-Domain Adaptive Representations for Transferable Autonomous Driving", "authors": ["Chinmay Vilas Samak", "Tanmay Vilas Samak", "Bing Li", "Venkat Krovi"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.00236v2", "summary": "Simulation-based design, optimization, and validation of autonomous driving\nalgorithms have proven to be crucial for their improvement over the years.\nNevertheless, the ultimate measure of effectiveness is their successful\ntransition from simulation to reality (sim2real). However, existing sim2real\ntransfer methods struggle to address the autonomy-oriented requirements of\nbalancing: (i) conditioned domain adaptation, (ii) robust performance with\nlimited examples, (iii) modularity in handling multiple domain representations,\nand (iv) real-time performance. To alleviate these pain points, we present a\nunified framework for learning cross-domain adaptive representations through\nconditional latent diffusion for sim2real transferable autonomous driving\nalgorithms. Our framework offers options to leverage: (i) alternate foundation\nmodels, (ii) a few-shot fine-tuning pipeline, and (iii) textual as well as\nimage prompts for mapping across given source and target domains. It is also\ncapable of generating diverse high-quality samples when diffusing across\nparameter spaces such as times of day, weather conditions, seasons, and\noperational design domains. We systematically analyze the presented framework\nand report our findings in terms of performance benchmarks and ablation\nstudies, with critical quantitative metrics as well as insightful qualitative\nexamples and remarks. Additionally, we demonstrate the serviceability of\nsim2real diffusion for autonomous driving using a behavioral cloning case\nstudy. Our experiments indicate that the proposed framework is capable of\nbridging the perceptual sim2real gap by over 40%, which highlights the\npotential of diffusion models in sim2real transfer.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.00236v2", "cate": "cs.RO", "date": "2025-06-30", "updated": "2025-07-15"}
{"id": "2507.10629", "title": "SQLord: A Robust Enterprise Text-to-SQL Solution via Reverse Data Generation and Workflow Decomposition", "authors": ["Song Cheng", "Qiannan Cheng", "Linbo Jin", "Lei Yi", "Guannan Zhang"], "categories": ["cs.DB", "cs.AI", "I.2.7"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "Comments:      WWW '25: Companion Proceedings of the ACM on Web Conference 2025 Pages 919 - 923 this https URL", "url": "http://arxiv.org/abs/2507.10629v1", "summary": "Transforming natural language into SQL queries (NL2SQL) is crucial for\ndata-driven business applications. Existing frameworks, trained on open-source\ndatasets, struggle with complex business logic and lack domain-specific data\nfor fine-tuning. Additionally, evaluation methods often require annotated data\nand executable database environments, which are scarce in real-world scenarios.\nTo address these challenges, we propose SQLord, an enterprise-level NL2SQL\nframework. First, SQLord introduces a data reverse generation approach to\nconvert raw SQL statements into annotated data for supervised fine-tuning\n(SFT). Second, it proposes a decomposition method for complex queries using an\nautomated workflow generator. Additionally, SQLord features a comprehensive\nGPT-Judge evaluation framework, including Execution Evaluation (EXE), Query-SQL\nEvaluation (QSE), and SQL-SQL Evaluation (SSE), tailored to diverse scenarios.\nOffline tests significantly outperform state of the art baselines, and online\naccuracy consistently exceeds 90, highlighting SQLord's advantages and\neffectiveness in complex real world scenarios. SQLord has been successfully\napplied across multiple scenarios on the world's largest B2B e-commerce\nplatform.", "comment": "WWW '25: Companion Proceedings of the ACM on Web Conference 2025\n  Pages 919 - 923 https://doi.org/10.1145/3701716.3715541", "pdf_url": "http://arxiv.org/pdf/2507.10629v1", "cate": "cs.DB", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10880", "title": "Domain-Adaptive Small Language Models for Structured Tax Code Prediction", "authors": ["Souvik Nath", "Sumit Wadhwa", "Luiz Perez"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 3 figures", "url": "http://arxiv.org/abs/2507.10880v1", "summary": "Every day, multinational firms process thousands of transactions, each of\nwhich must adhere to tax regulations that vary by jurisdiction and are often\nnuanced. The determination of product and service tax codes, such as HSN or SAC\nis a major use case in Tax compliance. An accurate determination of such codes\nis imperative to avoid any tax penalties. This paper proposes a domain-adaptive\nsmall language model (SLM) with an encoder-decoder architecture for the\nenhanced prediction of product and service tax codes. In this approach, we\naddress the problem of predicting hierarchical tax code sequences using\nunstructured product and services data. We employ an SLM based upon\nencoder-decoder architecture as this enables sequential generation of tax codes\nto capture the hierarchical dependencies present within the tax codes. Our\nexperiments demonstrate that encoder-decoder SLMs can be successfully applied\nto the sequential prediction of structured tax codes, a domain that remains\ncomparatively unexplored in current NLP research. In this paper, we demonstrate\nthe superior performance of the domain-adaptive encoder-decoder SLMs over flat\nclassifiers when applied to the Harmonized System of Nomenclature (HSN), and\nachieve superior results compared to decoder-only and encoder-only\narchitectures for structured sequence generation tasks. This approach can also\nbe scaled to other government-mandated tax commodity codes, such as United\nNations Standard Products and Services Codes (UNSPSC), or Brazil's Nomenclatura\nComum do Mercosul (NCM).", "comment": "10 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.10880v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11102", "title": "KptLLM++: Towards Generic Keypoint Comprehension with Large Language Model", "authors": ["Jie Yang", "Wang Zeng", "Sheng Jin", "Lumin Xu", "Wentao Liu", "Chen Qian", "Zhen Li", "Ruimao Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Extended Version of KptLLM. arXiv admin note: text overlap with arXiv:2411.01846", "url": "http://arxiv.org/abs/2507.11102v1", "summary": "The emergence of Multimodal Large Language Models (MLLMs) has revolutionized\nimage understanding by bridging textual and visual modalities. However, these\nmodels often struggle with capturing fine-grained semantic information, such as\nthe precise identification and analysis of object keypoints. Keypoints, as\nstructure-aware, pixel-level, and compact representations of objects,\nparticularly articulated ones, play a crucial role in applications such as\nfine-grained image analysis, object retrieval, and behavior recognition. In\nthis paper, we propose KptLLM++, a novel multimodal large language model that\nspecifically designed for generic keypoint comprehension through the\nintegration of diverse input modalities guided by user-defined instructions. By\nunifying keypoint detection across varied contexts, KptLLM++ establishes itself\nas an advanced interface, fostering more effective human-AI collaboration. The\nmodel is built upon a novel identify-then-detect paradigm, which first\ninterprets keypoint semantics and subsequently localizes their precise\npositions through a structured chain-of-thought reasoning mechanism. To push\nthe boundaries of performance, we have scaled up the training dataset to over\n500K samples, encompassing diverse objects, keypoint categories, image styles,\nand scenarios with complex occlusions. This extensive scaling enables KptLLM++\nto unlock its potential, achieving remarkable accuracy and generalization.\nComprehensive experiments on multiple keypoint detection benchmarks demonstrate\nits state-of-the-art performance, underscoring its potential as a unified\nsolution for fine-grained image understanding and its transformative\nimplications for human-AI interaction.", "comment": "Extended Version of KptLLM. arXiv admin note: text overlap with\n  arXiv:2411.01846", "pdf_url": "http://arxiv.org/pdf/2507.11102v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11240", "title": "Optimal Sensor Scheduling and Selection for Continuous-Discrete Kalman Filtering with Auxiliary Dynamics", "authors": ["Mohamad Al Ahdab", "John Leth", "Zheng-Hua Tan"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Accepted to ICML 2025", "url": "http://arxiv.org/abs/2507.11240v1", "summary": "We study the Continuous-Discrete Kalman Filter (CD-KF) for State-Space Models\n(SSMs) where continuous-time dynamics are observed via multiple sensors with\ndiscrete, irregularly timed measurements. Our focus extends to scenarios in\nwhich the measurement process is coupled with the states of an auxiliary SSM.\nFor instance, higher measurement rates may increase energy consumption or heat\ngeneration, while a sensor's accuracy can depend on its own spatial trajectory\nor that of the measured target. Each sensor thus carries distinct costs and\nconstraints associated with its measurement rate and additional constraints and\ncosts on the auxiliary state. We model measurement occurrences as independent\nPoisson processes with sensor-specific rates and derive an upper bound on the\nmean posterior covariance matrix of the CD-KF along the mean auxiliary state.\nThe bound is continuously differentiable with respect to the measurement rates,\nwhich enables efficient gradient-based optimization. Exploiting this bound, we\npropose a finite-horizon optimal control framework to optimize measurement\nrates and auxiliary-state dynamics jointly. We further introduce a\ndeterministic method for scheduling measurement times from the optimized rates.\nEmpirical results in state-space filtering and dynamic temporal Gaussian\nprocess regression demonstrate that our approach achieves improved trade-offs\nbetween resource usage and estimation accuracy.", "comment": "Accepted to ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.11240v1", "cate": "eess.SY", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11383", "title": "Sparse Regression Codes exploit Multi-User Diversity without CSI", "authors": ["V S V Sandeep", "Sai Dinesh Kancharana", "Arun Pachai Kannu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11383v1", "summary": "We study sparse regression codes (SPARC) for multiple access channels with\nmultiple receive antennas, in non-coherent flat fading channels. We propose a\nnovel practical decoder, referred to as maximum likelihood matching pursuit\n(MLMP), which greedily finds the support of the codewords of users with partial\nmaximum likelihood metrics. As opposed to the conventional\nsuccessive-cancellation based greedy algorithms, MLMP works as a\nsuccessive-combining energy detector. We also propose MLMP modifications to\nimprove the performance at high code rates. Our studies in short block lengths\nshow that, even without any channel state information, SPARC with MLMP decoder\nachieves multi-user diversity in some scenarios, giving better error\nperformance with multiple users than that of the corresponding single-user\ncase. We also show that SPARC with MLMP performs better than conventional\nsparse recovery algorithms and pilot-aided transmissions with polar codes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11383v1", "cate": "eess.SP", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10869", "title": "Focus on Texture: Rethinking Pre-training in Masked Autoencoders for Medical Image Classification", "authors": ["Chetan Madan", "Aarjav Satia", "Soumen Basu", "Pankaj Gupta", "Usha Dutta", "Chetan Arora"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      To appear at MICCAI 2025", "url": "http://arxiv.org/abs/2507.10869v1", "summary": "Masked Autoencoders (MAEs) have emerged as a dominant strategy for\nself-supervised representation learning in natural images, where models are\npre-trained to reconstruct masked patches with a pixel-wise mean squared error\n(MSE) between original and reconstructed RGB values as the loss. We observe\nthat MSE encourages blurred image re-construction, but still works for natural\nimages as it preserves dominant edges. However, in medical imaging, when the\ntexture cues are more important for classification of a visual abnormality, the\nstrategy fails. Taking inspiration from Gray Level Co-occurrence Matrix (GLCM)\nfeature in Radiomics studies, we propose a novel MAE based pre-training\nframework, GLCM-MAE, using reconstruction loss based on matching GLCM. GLCM\ncaptures intensity and spatial relationships in an image, hence proposed loss\nhelps preserve morphological features. Further, we propose a novel formulation\nto convert matching GLCM matrices into a differentiable loss function. We\ndemonstrate that unsupervised pre-training on medical images with the proposed\nGLCM loss improves representations for downstream tasks. GLCM-MAE outperforms\nthe current state-of-the-art across four tasks - gallbladder cancer detection\nfrom ultrasound images by 2.1%, breast cancer detection from ultrasound by\n3.1%, pneumonia detection from x-rays by 0.5%, and COVID detection from CT by\n0.6%. Source code and pre-trained models are available at:\nhttps://github.com/ChetanMadan/GLCM-MAE.", "comment": "To appear at MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.10869v1", "cate": "eess.IV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.00917", "title": "A Survey: Learning Embodied Intelligence from Physical Simulators and World Models", "authors": ["Xiaoxiao Long", "Qingrui Zhao", "Kaiwen Zhang", "Zihao Zhang", "Dingrui Wang", "Yumeng Liu", "Zhengjie Shu", "Yi Lu", "Shouzheng Wang", "Xinzhe Wei", "Wei Li", "Wei Yin", "Yao Yao", "Jia Pan", "Qiu Shen", "Ruigang Yang", "Xun Cao", "Qionghai Dai"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      49pages, 25figures, 6tables, github repository avalible in this https URL", "url": "http://arxiv.org/abs/2507.00917v2", "summary": "The pursuit of artificial general intelligence (AGI) has placed embodied\nintelligence at the forefront of robotics research. Embodied intelligence\nfocuses on agents capable of perceiving, reasoning, and acting within the\nphysical world. Achieving robust embodied intelligence requires not only\nadvanced perception and control, but also the ability to ground abstract\ncognition in real-world interactions. Two foundational technologies, physical\nsimulators and world models, have emerged as critical enablers in this quest.\nPhysical simulators provide controlled, high-fidelity environments for training\nand evaluating robotic agents, allowing safe and efficient development of\ncomplex behaviors. In contrast, world models empower robots with internal\nrepresentations of their surroundings, enabling predictive planning and\nadaptive decision-making beyond direct sensory input. This survey\nsystematically reviews recent advances in learning embodied AI through the\nintegration of physical simulators and world models. We analyze their\ncomplementary roles in enhancing autonomy, adaptability, and generalization in\nintelligent robots, and discuss the interplay between external simulation and\ninternal modeling in bridging the gap between simulated training and real-world\ndeployment. By synthesizing current progress and identifying open challenges,\nthis survey aims to provide a comprehensive perspective on the path toward more\ncapable and generalizable embodied AI systems. We also maintain an active\nrepository that contains up-to-date literature and open-source projects at\nhttps://github.com/NJU3DV-LoongGroup/Embodied-World-Models-Survey.", "comment": "49pages, 25figures, 6tables, github repository avalible in\n  https://github.com/NJU3DV-LoongGroup/Embodied-World-Models-Survey", "pdf_url": "http://arxiv.org/pdf/2507.00917v2", "cate": "cs.RO", "date": "2025-07-01", "updated": "2025-07-15"}
{"id": "2507.10643", "title": "TaylorPODA: A Taylor Expansion-Based Method to Improve Post-Hoc Attributions for Opaque Models", "authors": ["Yuchi Tang", "Iñaki Esnaola", "Suzanne Mason", "George Panoutsos"], "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      17 pages, 6 figures, Submitted to NeurIPS 2025", "url": "http://arxiv.org/abs/2507.10643v1", "summary": "Existing post-hoc model-agnostic methods generate external explanations for\nopaque models, primarily by locally attributing the model output to its input\nfeatures. However, they often lack an explicit and systematic framework for\nquantifying the contribution of individual features. Building on the Taylor\nexpansion framework introduced by Deng et al. (2024) to unify existing local\nattribution methods, we propose a rigorous set of postulates -- \"precision\",\n\"federation\", and \"zero-discrepancy\" -- to govern Taylor term-specific\nattribution. Guided by these postulates, we introduce TaylorPODA (Taylor\nexpansion-derived imPortance-Order aDapted Attribution), which incorporates an\nadditional \"adaptation\" property. This property enables alignment with\ntask-specific goals, especially in post-hoc settings lacking ground-truth\nexplanations. Empirical evaluations demonstrate that TaylorPODA achieves\ncompetitive results against baseline methods, providing principled and\nvisualization-friendly explanations. This work represents a step toward the\ntrustworthy deployment of opaque models by offering explanations with stronger\ntheoretical grounding.", "comment": "17 pages, 6 figures, Submitted to NeurIPS 2025", "pdf_url": "http://arxiv.org/pdf/2507.10643v1", "cate": "stat.ML", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10884", "title": "Learning from Imperfect Data: Robust Inference of Dynamic Systems using Simulation-based Generative Model", "authors": ["Hyunwoo Cho", "Hyeontae Jo", "Hyung Ju Hwang"], "categories": ["cs.LG", "math.DS", "68T07, 68T05, 70G60"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10884v1", "summary": "System inference for nonlinear dynamic models, represented by ordinary\ndifferential equations (ODEs), remains a significant challenge in many fields,\nparticularly when the data are noisy, sparse, or partially observable. In this\npaper, we propose a Simulation-based Generative Model for Imperfect Data\n(SiGMoID) that enables precise and robust inference for dynamic systems. The\nproposed approach integrates two key methods: (1) physics-informed neural\nnetworks with hyper-networks that constructs an ODE solver, and (2) Wasserstein\ngenerative adversarial networks that estimates ODE parameters by effectively\ncapturing noisy data distributions. We demonstrate that SiGMoID quantifies data\nnoise, estimates system parameters, and infers unobserved system components.\nIts effectiveness is validated validated through realistic experimental\nexamples, showcasing its broad applicability in various domains, from\nscientific research to engineered systems, and enabling the discovery of full\nsystem dynamics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10884v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11116", "title": "Jellyfish Species Identification: A CNN Based Artificial Neural Network Approach", "authors": ["Md. Sabbir Hossen", "Md. Saiduzzaman", "Pabon Shaha", "Mostofa Kamal Nasir"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This paper has been accepted at the IEEE QPAIN 2025. The final version will be available in the IEEE Xplore Digital Library", "url": "http://arxiv.org/abs/2507.11116v1", "summary": "Jellyfish, a diverse group of gelatinous marine organisms, play a crucial\nrole in maintaining marine ecosystems but pose significant challenges for\nbiodiversity and conservation due to their rapid proliferation and ecological\nimpact. Accurate identification of jellyfish species is essential for\necological monitoring and management. In this study, we proposed a deep\nlearning framework for jellyfish species detection and classification using an\nunderwater image dataset. The framework integrates advanced feature extraction\ntechniques, including MobileNetV3, ResNet50, EfficientNetV2-B0, and VGG16,\ncombined with seven traditional machine learning classifiers and three\nFeedforward Neural Network classifiers for precise species identification.\nAdditionally, we activated the softmax function to directly classify jellyfish\nspecies using the convolutional neural network models. The combination of the\nArtificial Neural Network with MobileNetV3 is our best-performing model,\nachieving an exceptional accuracy of 98%, significantly outperforming other\nfeature extractor-classifier combinations. This study demonstrates the efficacy\nof deep learning and hybrid frameworks in addressing biodiversity challenges\nand advancing species detection in marine environments.", "comment": "This paper has been accepted at the IEEE QPAIN 2025. The final\n  version will be available in the IEEE Xplore Digital Library", "pdf_url": "http://arxiv.org/pdf/2507.11116v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11377", "title": "Moving Beyond Marginal Carbon Intensity: A Poor Metric for Both Carbon Accounting and Grid Flexibility", "authors": ["Philipp Wiesner", "Odej Kao"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Presented at the Workshop on Measurements, Modeling, and Metrics for Carbon-Aware Computing (CarbonMetrics) @ ACM SIGMETRICS '25", "url": "http://arxiv.org/abs/2507.11377v1", "summary": "Marginal Carbon Intensity (MCI) has been promoted as an effective metric for\ncarbon-aware computing. Although it is already considered as impractical for\ncarbon accounting purposes, many still view it as valuable when optimizing for\ngrid flexibility by incentivizing electricity usage during curtailment periods.\nIn this statement paper, we argue that MCI is neither reliable nor actionable\nfor either purpose. We outline its fundamental limitations, including\nnon-observability, reliance on opaque predictive models, and the lack of\nverifiability. Moreover, MCI fails to reflect curtailment caused by high-carbon\nsources and offers no insight into the quantity of available excess power. We\nadvocate moving beyond MCI and instead call for research on more actionable\nmetrics, such as direct reporting of excess power, explicit modeling of energy\nstorage and grid stability, and integration with emerging granular renewable\nenergy certificate markets.", "comment": "Presented at the Workshop on Measurements, Modeling, and Metrics for\n  Carbon-Aware Computing (CarbonMetrics) @ ACM SIGMETRICS '25", "pdf_url": "http://arxiv.org/pdf/2507.11377v1", "cate": "eess.SY", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11413", "title": "Joint Power Allocation and Reflecting-Element Activation for Energy Efficiency Maximization in IRS-Aided Communications Under CSI Uncertainty", "authors": ["Christos N. Efrem", "Ioannis Krikidis"], "categories": ["eess.SP", "math.OC"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      5 pages, 3 figures", "url": "http://arxiv.org/abs/2507.11413v1", "summary": "We study the joint power allocation and reflecting element (RE) activation to\nmaximize the energy efficiency (EE) in communication systems assisted by an\nintelligent reflecting surface (IRS), taking into account imperfections in\nchannel state information (CSI). The robust optimization problem is mixed\ninteger, i.e., the optimization variables are continuous (transmit power) and\ndiscrete (binary states of REs). In order to solve this challenging problem we\ndevelop two algorithms. The first one is an alternating optimization (AO)\nmethod that attains a suboptimal solution with low complexity, based on the\nLambert W function and a dynamic programming (DP) algorithm. The second one is\na branch-and-bound (B&B) method that uses AO as its subroutine and is formally\nguaranteed to achieve a globally optimal solution. Both algorithms do not\nrequire any external optimization solver for their implementation. Furthermore,\nnumerical results show that the proposed algorithms outperform the baseline\nschemes, AO achieves near-optimal performance in most cases, and B&B has low\ncomputational complexity on average.", "comment": "5 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.11413v1", "cate": "eess.SP", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11043", "title": "Real-Time Foreign Object Recognition Based on Improved Wavelet Scattering Deep Network and Edge Computing", "authors": ["He Zhichao", "Shen Xiangyu", "Zhang Yong", "Xie Nan"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11043v1", "summary": "The increasing penetration rate of new energy in the power system has put\nforward higher requirements for the operation and maintenance of substations\nand transmission lines. Using the Unmanned Aerial Vehicles (UAV) to identify\nforeign object in real time can quickly and effectively eliminate potential\nsafety hazards. However, due to the limited computation power, the captured\nimage cannot be real-time processed on edge devices in UAV locally. To overcome\nthis problem, a lightweight model based on an improved wavelet scatter deep\nnetwork is proposed. This model contains improved wavelet scattering network\nfor extracting the scatter coefficients and modulus coefficients of image\nsingle channel, replacing the role of convolutional layer and pooling layer in\nconvolutional neural network. The following 3 fully connected layers, also\nconstituted a simplified Multilayer Perceptron (MLP), are used to classify the\nextracted features. Experiments prove that the model constructed with\nbiorthogonal wavelets basis is able to recognize and classify the foreign\nobject in edge devices such as Raspberry Pi and Jetson Nano, with accuracy\nhigher than 90% and inference time less than 7ms for 720P (1280*720) images.\nFurther experiments demonstrate that the recognition accuracy of our model is\n1.1% higher than YOLOv5s and 0.3% higher than YOLOv8s.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11043v1", "cate": "eess.IV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.02029", "title": "RoboBrain 2.0 Technical Report", "authors": ["BAAI RoboBrain Team", "Mingyu Cao", "Huajie Tan", "Yuheng Ji", "Minglan Lin", "Zhiyu Li", "Zhou Cao", "Pengwei Wang", "Enshen Zhou", "Yi Han", "Yingbo Tang", "Xiangqi Xu", "Wei Guo", "Yaoxu Lyu", "Yijie Xu", "Jiayu Shi", "Mengfei Du", "Cheng Chi", "Mengdi Zhao", "Xiaoshuai Hao", "Junkai Zhao", "Xiaojie Zhang", "Shanyu Rong", "Huaihai Lyu", "Zhengliang Cai", "Yankai Fu", "Ning Chen", "Bolun Zhang", "Lingfeng Zhang", "Shuyi Zhang", "Dong Liu", "Xi Feng", "Songjing Wang", "Xiaodan Liu", "Yance Jiao", "Mengsi Lyu", "Zhuo Chen", "Chenrui He", "Yulong Ao", "Xue Sun", "Zheqi He", "Jingshu Zheng", "Xi Yang", "Donghai Shi", "Kunchang Xie", "Bochao Zhang", "Shaokai Nie", "Chunlei Men", "Yonghua Lin", "Zhongyuan Wang", "Tiejun Huang", "Shanghang Zhang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.02029v3", "summary": "We introduce RoboBrain 2.0, our latest generation of embodied vision-language\nfoundation models, designed to unify perception, reasoning, and planning for\ncomplex embodied tasks in physical environments. It comes in two variants: a\nlightweight 7B model and a full-scale 32B model, featuring a heterogeneous\narchitecture with a vision encoder and a language model. Despite its compact\nsize, RoboBrain 2.0 achieves strong performance across a wide spectrum of\nembodied reasoning tasks. On both spatial and temporal benchmarks, the 32B\nvariant achieves leading results, surpassing prior open-source and proprietary\nmodels. In particular, it supports key real-world embodied AI capabilities,\nincluding spatial understanding (e.g., affordance prediction, spatial\nreferring, trajectory forecasting) and temporal decision-making (e.g.,\nclosed-loop interaction, multi-agent long-horizon planning, and scene graph\nupdating). This report details the model architecture, data construction,\nmulti-stage training strategies, infrastructure and practical applications. We\nhope RoboBrain 2.0 advances embodied AI research and serves as a practical step\ntoward building generalist embodied agents. The code, checkpoint and benchmark\nare available at https://superrobobrain.github.io.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.02029v3", "cate": "cs.RO", "date": "2025-07-02", "updated": "2025-07-15"}
{"id": "2507.10865", "title": "Overview of the TREC 2022 deep learning track", "authors": ["Nick Craswell", "Bhaskar Mitra", "Emine Yilmaz", "Daniel Campos", "Jimmy Lin", "Ellen M. Voorhees", "Ian Soboroff"], "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      arXiv admin note: substantial text overlap with arXiv:2507.08191 , arXiv:2507.08890", "url": "http://arxiv.org/abs/2507.10865v1", "summary": "This is the fourth year of the TREC Deep Learning track. As in previous\nyears, we leverage the MS MARCO datasets that made hundreds of thousands of\nhuman annotated training labels available for both passage and document ranking\ntasks. In addition, this year we also leverage both the refreshed passage and\ndocument collections that were released last year leading to a nearly $16$\ntimes increase in the size of the passage collection and nearly four times\nincrease in the document collection size. Unlike previous years, in 2022 we\nmainly focused on constructing a more complete test collection for the passage\nretrieval task, which has been the primary focus of the track. The document\nranking task was kept as a secondary task, where document-level labels were\ninferred from the passage-level labels. Our analysis shows that similar to\nprevious years, deep neural ranking models that employ large scale pretraining\ncontinued to outperform traditional retrieval methods. Due to the focusing our\njudging resources on passage judging, we are more confident in the quality of\nthis year's queries and judgments, with respect to our ability to distinguish\nbetween runs and reuse the dataset in future. We also see some surprises in\noverall outcomes. Some top-performing runs did not do dense retrieval. Runs\nthat did single-stage dense retrieval were not as competitive this year as they\nwere last year.", "comment": "arXiv admin note: substantial text overlap with arXiv:2507.08191,\n  arXiv:2507.08890", "pdf_url": "http://arxiv.org/pdf/2507.10865v1", "cate": "cs.IR", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.10886", "title": "How to Protect Models against Adversarial Unlearning?", "authors": ["Patryk Jasiorski", "Marek Klonowski", "Michał Woźniak"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10886v1", "summary": "AI models need to be unlearned to fulfill the requirements of legal acts such\nas the AI Act or GDPR, and also because of the need to remove toxic content,\ndebiasing, the impact of malicious instances, or changes in the data\ndistribution structure in which a model works. Unfortunately, removing\nknowledge may cause undesirable side effects, such as a deterioration in model\nperformance. In this paper, we investigate the problem of adversarial\nunlearning, where a malicious party intentionally sends unlearn requests to\ndeteriorate the model's performance maximally. We show that this phenomenon and\nthe adversary's capabilities depend on many factors, primarily on the backbone\nmodel itself and strategy/limitations in selecting data to be unlearned. The\nmain result of this work is a new method of protecting model performance from\nthese side effects, both in the case of unlearned behavior resulting from\nspontaneous processes and adversary actions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10886v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11119", "title": "Try Harder: Hard Sample Generation and Learning for Clothes-Changing Person Re-ID", "authors": ["Hankun Liu", "Yujian Zhao", "Guanglin Niu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11119v1", "summary": "Hard samples pose a significant challenge in person re-identification (ReID)\ntasks, particularly in clothing-changing person Re-ID (CC-ReID). Their inherent\nambiguity or similarity, coupled with the lack of explicit definitions, makes\nthem a fundamental bottleneck. These issues not only limit the design of\ntargeted learning strategies but also diminish the model's robustness under\nclothing or viewpoint changes. In this paper, we propose a novel\nmultimodal-guided Hard Sample Generation and Learning (HSGL) framework, which\nis the first effort to unify textual and visual modalities to explicitly\ndefine, generate, and optimize hard samples within a unified paradigm. HSGL\ncomprises two core components: (1) Dual-Granularity Hard Sample Generation\n(DGHSG), which leverages multimodal cues to synthesize semantically consistent\nsamples, including both coarse- and fine-grained hard positives and negatives\nfor effectively increasing the hardness and diversity of the training data. (2)\nHard Sample Adaptive Learning (HSAL), which introduces a hardness-aware\noptimization strategy that adjusts feature distances based on textual semantic\nlabels, encouraging the separation of hard positives and drawing hard negatives\ncloser in the embedding space to enhance the model's discriminative capability\nand robustness to hard samples. Extensive experiments on multiple CC-ReID\nbenchmarks demonstrate the effectiveness of our approach and highlight the\npotential of multimodal-guided hard sample generation and learning for robust\nCC-ReID. Notably, HSAL significantly accelerates the convergence of the\ntargeted learning procedure and achieves state-of-the-art performance on both\nPRCC and LTCC datasets. The code is available at\nhttps://github.com/undooo/TryHarder-ACMMM25.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11119v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11392", "title": "Inverse Optimal Control with Constraint Relaxation", "authors": ["Rahel Rickenbach", "Amon Lahr", "Melanie N. Zeilinger"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11392v1", "summary": "Inverse optimal control (IOC) is a promising paradigm for learning and\nmimicking optimal control strategies from capable demonstrators, or gaining a\ndeeper understanding of their intentions, by estimating an unknown objective\nfunction from one or more corresponding optimal control sequences. When\ncomputing estimates from demonstrations in environments with safety-preserving\ninequality constraints, acknowledging their presence in the chosen IOC method\nis crucial given their strong influence on the final control strategy. However,\nsolution strategies capable of considering inequality constraints, such as the\ninverse Karush-Kuhn-Tucker approach, rely on their correct activation and\nfulfillment; a restrictive assumption when dealing with noisy demonstrations.\nTo overcome this problem, we leverage the concept of exact penalty functions\nfor IOC and show preservation of estimation accuracy. Considering noisy\ndemonstrations, we then illustrate how the usage of penalty functions reduces\nthe number of unknown variables and how their approximations enhance the\nestimation method's capacity to account for wrong constraint activations within\na polytopic-constrained environment. The proposed method is evaluated for three\nsystems in simulation, outperforming traditional relaxation approaches for\nnoisy demonstrations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11392v1", "cate": "eess.SY", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10876", "title": "Time-series forecasting for nonlinear high-dimensional system using hybrid method combining autoencoder and multi-parallelized quantum long short-term memory and gated recurrent unit", "authors": ["Makoto Takagi", "Ryuji Kokubo", "Misato Kurosawa", "Tsubasa Ikami", "Yasuhiro Egami", "Hiroki Nagai", "Takahiro Kashikawa", "Koichi Kimura", "Yutaka Takita", "Yu Matsuda"], "categories": ["quant-ph", "eess.SP"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10876v1", "summary": "A time-series forecasting method for high-dimensional spatial data is\nproposed. The method involves optimal selection of sparse sensor positions to\nefficiently represent the spatial domain, time-series forecasting at these\npositions, and estimation of the entire spatial distribution from the\nforecasted values via a learned decoder. Sensor positions are selected using a\nmethod based on combinatorial optimization. Introducing multi-parallelized\nquantum long short-term memory (MP-QLSTM) and gated recurrent unit (MP-QGRU)\nimproves time-series forecasting performance by extending QLSTM models using\nthe same number of variational quantum circuits (VQCs) as the cell state\ndimensions. Unlike the original QLSTM, our method fully measures all qubits in\neach VQC, maximizing the representation capacity. MP-QLSTM and MP-QGRU achieve\napproximately 1.5% lower test loss than classical LSTM and GRU. The root mean\nsquared percentage error of MP-QLSTM is 0.256% against the values measured\nindependently using semiconductor pressure sensors, demonstrating the method's\naccuracy and effectiveness for high-dimensional forecasting tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10876v1", "cate": "quant-ph", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11046", "title": "Using Continual Learning for Real-Time Detection of Vulnerable Road Users in Complex Traffic Scenarios", "authors": ["Faryal Aurooj Nasir", "Salman Liaquat", "Nor Muzlifah Mahyuddin"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at the 9th International Conference on Communications and Future Internet", "url": "http://arxiv.org/abs/2507.11046v1", "summary": "Pedestrians and bicyclists are among the vulnerable road users (VRUs) that\nare inherently exposed to intricate traffic scenarios, which puts them at\nincreased risk of sustaining injuries or facing fatal outcomes. This study\npresents an intelligent adaptive system that uses the YOLOv8-Dynamic (YOLOv8-D)\nalgorithm that detects vulnerable road users and adapts in real time to prevent\naccidents before they occur. We select YOLOv8x as the detector by comparing it\nwith other state-of-the-art object detection models, including Faster-RCNN,\nYOLOv5, YOLOv7, and variants. Compared to YOLOv5x, YOLOv8x shows improvements\nof 12.14% in F1 score and 45.61% in mean Average Precision (mAP). Against\nYOLOv7x, the improvements are 21.26% in F1 score and 128.44% in mAP. Our\nalgorithm integrates continual learning ability in the architecture of the\nYOLOv8 detector to adjust to evolving road conditions flexibly, ensuring\nadaptability across multiple dataset domains and facilitating continuous\nenhancement of detection and tracking accuracy for VRUs, embracing the dynamic\nnature of real-world environments. In our proposed framework, we optimized the\ngradient descent mechanism of YOLOv8 model and train our optimized algorithm on\ntwo statistically different datasets in terms of image viewpoint and number of\nclasses to achieve a 21.08% improvement in F1 score and a 31.86% improvement in\nmAP as compared to a custom YOLOv8 framework trained on a new dataset, thus\novercoming the issue of catastrophic forgetting, which occurs when deep models\nare trained on statistically different types of datasets.", "comment": "Accepted for presentation at the 9th International Conference on\n  Communications and Future Internet", "pdf_url": "http://arxiv.org/pdf/2507.11046v1", "cate": "eess.IV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10783", "title": "Standardized Evaluation of Fetal Phonocardiography Processing Methods", "authors": ["Kristóf Müller", "Janka Hatvani", "Márton Áron Goda", "Miklós Koller"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      17 pages, 7 figures, 7 tables", "url": "http://arxiv.org/abs/2507.10783v1", "summary": "Motivation. Phonocardiography can give access to the fetal heart rate as well\nas direct heart sound data, and is entirely passive, using no radiation of any\nkind. Approach. We discuss the currently available methods for fetal heart\nsound detection and heart rate estimation and compare them using a common\nbenchmarking platform and a pre-selected testing dataset. Compared to previous\nreviews, we evaluated the discussed methods in a standardized manner for a fair\ncomparison. Our tests included tolerance-based detection accuracy, error rates\nfor label insertions, deletions, and substitutions, and statistical measures\nfor heart rate mean square error. Results. Based on our results, there is no\ndefinite best method that can achieve the highest scores in all of the tests,\nand simpler methods could perform comparably to more complex ones. The best\nmodel for first heart sound detection achieved 97.6% F1-score, 97.4% positive\npredictive value, and 12.2+-8.0 ms mean absolute error. In terms of second\nheart sound detection the best model had 91.4% F1-score, 91.3% positive\npredictive value, and 17.3+-12.2 ms mean absolute error. For fetal heart rate a\n0.644 mean square error was achieved by the best method. Significance. Our main\nconclusion is that further standardization is required in fetal heart rate and\nheart sound detection method evaluation. The tests and algorithm\nimplementations are openly available at:\nhttps://github.com/mulkr/standard-fpcg-evaluation.", "comment": "17 pages, 7 figures, 7 tables", "pdf_url": "http://arxiv.org/pdf/2507.10783v1", "cate": "eess.AS", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.09469", "title": "mmE-Loc: Facilitating Accurate Drone Landing with Ultra-High-Frequency Localization", "authors": ["Haoyang Wang", "Jingao Xu", "Xinyu Luo", "Ting Zhang", "Xuecheng Chen", "Ruiyang Duan", "Jialong Chen", "Yunhao Liu", "Jianfeng Zheng", "Weijie Hong", "Xinlei Chen"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      17 pages, 34 figures. Journal extended version of arXiv:2502.14992", "url": "http://arxiv.org/abs/2507.09469v2", "summary": "For precise, efficient, and safe drone landings, ground platforms should\nreal-time, accurately locate descending drones and guide them to designated\nspots. While mmWave sensing combined with cameras improves localization\naccuracy, lower sampling frequency of traditional frame cameras compared to\nmmWave radar creates bottlenecks in system throughput. In this work, we upgrade\ntraditional frame camera with event camera, a novel sensor that harmonizes in\nsampling frequency with mmWave radar within ground platform setup, and\nintroduce mmE-Loc, a high-precision, low-latency ground localization system\ndesigned for precise drone landings. To fully exploit the \\textit{temporal\nconsistency} and \\textit{spatial complementarity} between these two modalities,\nwe propose two innovative modules: \\textit{(i)} the Consistency-instructed\nCollaborative Tracking module, which further leverages the drone's physical\nknowledge of periodic micro-motions and structure for accurate measurements\nextraction, and \\textit{(ii)} the Graph-informed Adaptive Joint Optimization\nmodule, which integrates drone motion information for efficient sensor fusion\nand drone localization. Real-world experiments conducted in landing scenarios\nwith a drone delivery company demonstrate that mmE-Loc significantly\noutperforms state-of-the-art methods in both accuracy and latency.", "comment": "17 pages, 34 figures. Journal extended version of arXiv:2502.14992", "pdf_url": "http://arxiv.org/pdf/2507.09469v2", "cate": "cs.RO", "date": "2025-07-13", "updated": "2025-07-15"}
{"id": "2507.10904", "title": "Class-Proportional Coreset Selection for Difficulty-Separable Data", "authors": ["Elisa Tsai", "Haizhong Zheng", "Atul Prakash"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This paper has been accepted to the ICCV 2025 Workshop on Curated Data for Efficient Learning (CDEL)", "url": "http://arxiv.org/abs/2507.10904v1", "summary": "High-quality training data is essential for building reliable and efficient\nmachine learning systems. One-shot coreset selection addresses this by pruning\nthe dataset while maintaining or even improving model performance, often\nrelying on training-dynamics-based data difficulty scores. However, most\nexisting methods implicitly assume class-wise homogeneity in data difficulty,\noverlooking variation in data difficulty across different classes.\n  In this work, we challenge this assumption by showing that, in domains such\nas network intrusion detection and medical imaging, data difficulty often\nclusters by class. We formalize this as class-difficulty separability and\nintroduce the Class Difficulty Separability Coefficient (CDSC) as a\nquantitative measure. We demonstrate that high CDSC values correlate with\nperformance degradation in class-agnostic coreset methods, which tend to\noverrepresent easy majority classes while neglecting rare but informative ones.\n  To address this, we introduce class-proportional variants of multiple\nsampling strategies. Evaluated on five diverse datasets spanning security and\nmedical domains, our methods consistently achieve state-of-the-art data\nefficiency. For instance, on CTU-13, at an extreme 99% pruning rate, a\nclass-proportional variant of Coverage-centric Coreset Selection (CCS-CP) shows\nremarkable stability, with accuracy dropping only 2.58%, precision 0.49%, and\nrecall 0.19%. In contrast, the class-agnostic CCS baseline, the next best\nmethod, suffers sharper declines of 7.59% in accuracy, 4.57% in precision, and\n4.11% in recall.\n  We further show that aggressive pruning enhances generalization in noisy,\nimbalanced, and large-scale datasets. Our results underscore that explicitly\nmodeling class-difficulty separability leads to more effective, robust, and\ngeneralizable data pruning, particularly in high-stakes scenarios.", "comment": "This paper has been accepted to the ICCV 2025 Workshop on Curated\n  Data for Efficient Learning (CDEL)", "pdf_url": "http://arxiv.org/pdf/2507.10904v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10890", "title": "Outbound Modeling for Inventory Management", "authors": ["Riccardo Savorgnan", "Udaya Ghai", "Carson Eisenach", "Dean Foster"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      KDD - AI for Supply Chain Workshop", "url": "http://arxiv.org/abs/2507.10890v1", "summary": "We study the problem of forecasting the number of units fulfilled (or\n``drained'') from each inventory warehouse to meet customer demand, along with\nthe associated outbound shipping costs. The actual drain and shipping costs are\ndetermined by complex production systems that manage the planning and execution\nof customers' orders fulfillment, i.e. from where and how to ship a unit to be\ndelivered to a customer. Accurately modeling these processes is critical for\nregional inventory planning, especially when using Reinforcement Learning (RL)\nto develop control policies. For the RL usecase, a drain model is incorporated\ninto a simulator to produce long rollouts, which we desire to be\ndifferentiable. While simulating the calls to the internal software systems can\nbe used to recover this transition, they are non-differentiable and too slow\nand costly to run within an RL training environment. Accordingly, we frame this\nas a probabilistic forecasting problem, modeling the joint distribution of\noutbound drain and shipping costs across all warehouses at each time period,\nconditioned on inventory positions and exogenous customer demand. To ensure\nrobustness in an RL environment, the model must handle out-of-distribution\nscenarios that arise from off-policy trajectories. We propose a validation\nscheme that leverages production systems to evaluate the drain model on\ncounterfactual inventory states induced by RL policies. Preliminary results\ndemonstrate the model's accuracy within the in-distribution setting.", "comment": "KDD - AI for Supply Chain Workshop", "pdf_url": "http://arxiv.org/pdf/2507.10890v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11129", "title": "MMOne: Representing Multiple Modalities in One Scene", "authors": ["Zhifeng Gu", "Bing Wang"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.11129v1", "summary": "Humans perceive the world through multimodal cues to understand and interact\nwith the environment. Learning a scene representation for multiple modalities\nenhances comprehension of the physical world. However, modality conflicts,\narising from inherent distinctions among different modalities, present two\ncritical challenges: property disparity and granularity disparity. To address\nthese challenges, we propose a general framework, MMOne, to represent multiple\nmodalities in one scene, which can be readily extended to additional\nmodalities. Specifically, a modality modeling module with a novel modality\nindicator is proposed to capture the unique properties of each modality.\nAdditionally, we design a multimodal decomposition mechanism to separate\nmulti-modal Gaussians into single-modal Gaussians based on modality\ndifferences. We address the essential distinctions among modalities by\ndisentangling multimodal information into shared and modality-specific\ncomponents, resulting in a more compact and efficient multimodal scene\nrepresentation. Extensive experiments demonstrate that our method consistently\nenhances the representation capability for each modality and is scalable to\nadditional modalities. The code is available at\nhttps://github.com/Neal2020GitHub/MMOne.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.11129v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11420", "title": "A Risk-Aware Adaptive Robust MPC with Learned Uncertainty Quantification", "authors": ["Mingcong Li"], "categories": ["eess.SY", "cs.SY", "93C40", "I.2.8"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      17 pages, 10 figures", "url": "http://arxiv.org/abs/2507.11420v1", "summary": "Solving chance-constrained optimal control problems for systems subject to\nnon-stationary uncertainties is a significant challenge.Conventional robust\nmodel predictive control (MPC) often yields excessive conservatism by relying\non static worst-case assumptions, while standard stochastic MPC methods\nstruggle when underlying uncertainty distributions are unknown a priori.This\narticle presents a Risk-Aware Adaptive Robust MPC (RAAR-MPC) framework,a\nhierarchical architecture that systematically orchestrates a novel synthesis of\nproactive, learning-based risk assessment and reactive risk regulation. The\nframework employs a medium-frequency risk assessment engine, which leverages\nGaussian process regression and active learning, to construct a tight,\ndata-driven characterization of the prediction error set from operational\ndata.Concurrently, a low-timescale outer loop implements a self-correcting\nupdate law for an adaptive safety margin to precisely regulate the empirical\nrisk and compensate for unmodeled dynamics.This dual-timescale adaptation\nenables the system to rigorously satisfy chance constraints with a user-defined\nprobability, while minimizing the conservatism inherent in traditional\napproaches.We formally establish that the interplay between these adaptive\ncomponents guarantees recursive feasibility and ensures the closed-loop system\nsatisfies the chance constraints up to a user-defined risk level with high\nprobability.Numerical experiments on a benchmark DC-DC converter under\nnon-stationary parametric uncertainties demonstrate that our framework\nprecisely achieves the target risk level, resulting in a significantly lower\naverage cost compared to state-of-the-art robust and stochastic MPC strategies.", "comment": "17 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.11420v1", "cate": "eess.SY", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11091", "title": "Array-Aware Ambisonics and HRTF Encoding for Binaural Reproduction With Wearable Arrays", "authors": ["Yhonatan Gayer", "Vladimir Tourbabin", "Zamir Ben Hur", "David Lou Alon", "Boaz Rafaely"], "categories": ["eess.AS", "eess.SP"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11091v1", "summary": "This work introduces a novel method for binaural reproduction from arbitrary\nmicrophone arrays, based on array-aware optimization of Ambisonics encoding\nthrough Head-Related Transfer Function (HRTF) pre-processing. The proposed\napproach integrates array-specific information into the HRTF processing\npipeline, leading to improved spatial accuracy in binaural rendering. Objective\nevaluations demonstrate superior performance under simulated wearable-array and\nhead rotations compared to conventional Ambisonics encoding method. A listening\nexperiment further confirms that the method achieves significantly higher\nperceptual ratings in both timbre and spatial quality. Fully compatible with\nstandard Ambisonics, the proposed method offers a practical solution for\nspatial audio rendering in applications such as virtual reality, augmented\nreality, and wearable audio capture.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11091v1", "cate": "eess.AS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11415", "title": "U-RWKV: Lightweight medical image segmentation with direction-adaptive RWKV", "authors": ["Hongbo Ye", "Fenghe Tang", "Peiang Zhao", "Zhen Huang", "Dexin Zhao", "Minghao Bian", "S. Kevin Zhou"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted by MICCAI2025", "url": "http://arxiv.org/abs/2507.11415v1", "summary": "Achieving equity in healthcare accessibility requires lightweight yet\nhigh-performance solutions for medical image segmentation, particularly in\nresource-limited settings. Existing methods like U-Net and its variants often\nsuffer from limited global Effective Receptive Fields (ERFs), hindering their\nability to capture long-range dependencies. To address this, we propose U-RWKV,\na novel framework leveraging the Recurrent Weighted Key-Value(RWKV)\narchitecture, which achieves efficient long-range modeling at O(N)\ncomputational cost. The framework introduces two key innovations: the\nDirection-Adaptive RWKV Module(DARM) and the Stage-Adaptive\nSqueeze-and-Excitation Module(SASE). DARM employs Dual-RWKV and QuadScan\nmechanisms to aggregate contextual cues across images, mitigating directional\nbias while preserving global context and maintaining high computational\nefficiency. SASE dynamically adapts its architecture to different feature\nextraction stages, balancing high-resolution detail preservation and semantic\nrelationship capture. Experiments demonstrate that U-RWKV achieves\nstate-of-the-art segmentation performance with high computational efficiency,\noffering a practical solution for democratizing advanced medical imaging\ntechnologies in resource-constrained environments. The code is available at\nhttps://github.com/hbyecoding/U-RWKV.", "comment": "Accepted by MICCAI2025", "pdf_url": "http://arxiv.org/pdf/2507.11415v1", "cate": "eess.IV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11070", "title": "Physics-Informed Transfer Learning for Data-Driven Sound Source Reconstruction in Near-Field Acoustic Holography", "authors": ["Xinmeng Luan", "Mirco Pezzoli", "Fabio Antonacci", "Augusto Sarti"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      to appear in IEEE WASPAA 2025", "url": "http://arxiv.org/abs/2507.11070v1", "summary": "We propose a transfer learning framework for sound source reconstruction in\nNear-field Acoustic Holography (NAH), which adapts a well-trained data-driven\nmodel from one type of sound source to another using a physics-informed\nprocedure. The framework comprises two stages: (1) supervised pre-training of a\ncomplex-valued convolutional neural network (CV-CNN) on a large dataset, and\n(2) purely physics-informed fine-tuning on a single data sample based on the\nKirchhoff-Helmholtz integral. This method follows the principles of transfer\nlearning by enabling generalization across different datasets through\nphysics-informed adaptation. The effectiveness of the approach is validated by\ntransferring a pre-trained model from a rectangular plate dataset to a violin\ntop plate dataset, where it shows improved reconstruction accuracy compared to\nthe pre-trained model and delivers performance comparable to that of\nCompressive-Equivalent Source Method (C-ESM). Furthermore, for successful\nmodes, the fine-tuned model outperforms both the pre-trained model and C-ESM in\naccuracy.", "comment": "to appear in IEEE WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2507.11070v1", "cate": "eess.AS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2410.23022", "title": "Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback", "authors": ["Qinqing Zheng", "Mikael Henaff", "Amy Zhang", "Aditya Grover", "Brandon Amos"], "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.23022v3", "summary": "Automatically synthesizing dense rewards from natural language descriptions\nis a promising paradigm in reinforcement learning (RL), with applications to\nsparse reward problems, open-ended exploration, and hierarchical skill design.\nRecent works have made promising steps by exploiting the prior knowledge of\nlarge language models (LLMs). However, these approaches suffer from important\nlimitations: they are either not scalable to problems requiring billions of\nenvironment samples, due to requiring LLM annotations for each observation, or\nthey require a diverse offline dataset, which may not exist or be impossible to\ncollect. In this work, we address these limitations through a combination of\nalgorithmic and systems-level contributions. We propose ONI, a distributed\narchitecture that simultaneously learns an RL policy and an intrinsic reward\nfunction using LLM feedback. Our approach annotates the agent's collected\nexperience via an asynchronous LLM server, which is then distilled into an\nintrinsic reward model. We explore a range of algorithmic choices for reward\nmodeling with varying complexity, including hashing, classification, and\nranking models. Our approach achieves state-of-the-art performance across a\nrange of challenging tasks from the NetHack Learning Environment, while\nremoving the need for large offline datasets required by prior work. We make\nour code available at https://github.com/facebookresearch/oni .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.23022v3", "cate": "cs.LG", "date": "2024-10-30", "updated": "2025-07-15"}
{"id": "2507.10920", "title": "HanjaBridge: Resolving Semantic Ambiguity in Korean LLMs via Hanja-Augmented Pre-Training", "authors": ["Seungho Choi"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10920v1", "summary": "Large language models (LLMs) often show poor performance in low-resource\nlanguages like Korean, partly due to unique linguistic challenges such as\nhomophonous Sino-Korean words that are indistinguishable in Hangul script. To\naddress this semantic ambiguity, we propose HanjaBridge, a novel\nmeaning-injection technique integrated into a continual pre-training (CPT)\nframework. Instead of deterministically mapping a word to a single Hanja\n(Chinese character), HanjaBridge presents the model with all possible Hanja\ncandidates for a given homograph, encouraging the model to learn contextual\ndisambiguation. This process is paired with token-level knowledge distillation\nto prevent catastrophic forgetting. Experimental results show that HanjaBridge\nsignificantly improves Korean language understanding, achieving a 21\\% relative\nimprovement on the KoBALT benchmark. Notably, by reinforcing semantic alignment\nbetween Korean and Chinese through shared Hanja, we observe a strong positive\ncross-lingual transfer. Furthermore, these gains persist even when Hanja\naugmentation is omitted at inference time, ensuring practical efficiency with\nno additional run-time cost.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10920v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10955", "title": "Diffusion Decoding for Peptide De Novo Sequencing", "authors": ["Chi-en Amy Tai", "Alexander Wong"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10955v1", "summary": "Peptide de novo sequencing is a method used to reconstruct amino acid\nsequences from tandem mass spectrometry data without relying on existing\nprotein sequence databases. Traditional deep learning approaches, such as\nCasanovo, mainly utilize autoregressive decoders and predict amino acids\nsequentially. Subsequently, they encounter cascading errors and fail to\nleverage high-confidence regions effectively. To address these issues, this\npaper investigates using diffusion decoders adapted for the discrete data\ndomain. These decoders provide a different approach, allowing sequence\ngeneration to start from any peptide segment, thereby enhancing prediction\naccuracy. We experiment with three different diffusion decoder designs,\nknapsack beam search, and various loss functions. We find knapsack beam search\ndid not improve performance metrics and simply replacing the transformer\ndecoder with a diffusion decoder lowered performance. Although peptide\nprecision and recall were still 0, the best diffusion decoder design with the\nDINOISER loss function obtained a statistically significant improvement in\namino acid recall by 0.373 compared to the baseline autoregressive\ndecoder-based Casanovo model. These findings highlight the potential of\ndiffusion decoders to not only enhance model sensitivity but also drive\nsignificant advancements in peptide de novo sequencing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10955v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11143", "title": "RMAU-NET: A Residual-Multihead-Attention U-Net Architecture for Landslide Segmentation and Detection from Remote Sensing Images", "authors": ["Lam Pham", "Cam Le", "Hieu Tang", "Khang Truong", "Truong Nguyen", "Jasmin Lampert", "Alexander Schindler", "Martin Boyer", "Son Phan"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11143v1", "summary": "In recent years, landslide disasters have reported frequently due to the\nextreme weather events of droughts, floods , storms, or the consequence of\nhuman activities such as deforestation, excessive exploitation of natural\nresources. However, automatically observing landslide is challenging due to the\nextremely large observing area and the rugged topography such as mountain or\nhighland. This motivates us to propose an end-to-end deep-learning-based model\nwhich explores the remote sensing images for automatically observing landslide\nevents. By considering remote sensing images as the input data, we can obtain\nfree resource, observe large and rough terrains by time. To explore the remote\nsensing images, we proposed a novel neural network architecture which is for\ntwo tasks of landslide detection and landslide segmentation. We evaluated our\nproposed model on three different benchmark datasets of LandSlide4Sense, Bijie,\nand Nepal. By conducting extensive experiments, we achieve F1 scores of 98.23,\n93.83 for the landslide detection task on LandSlide4Sense, Bijie datasets; mIoU\nscores of 63.74, 76.88 on the segmentation tasks regarding LandSlide4Sense,\nNepal datasets. These experimental results prove potential to integrate our\nproposed model into real-life landslide observation systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11143v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10849", "title": "OpenGCRAM: An Open-Source Gain Cell Compiler Enabling Design-Space Exploration for AI Workloads", "authors": ["Xinxin Wang", "Lixian Yan", "Shuhan Liu", "Luke Upton", "Zhuoqi Cai", "Yiming Tan", "Shengman Li", "Koustav Jana", "Peijing Li", "Jesse Cirimelli-Low", "Thierry Tambe", "Matthew Guthaus", "H. -S. Philip Wong"], "categories": ["cs.AR", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10849v1", "summary": "Gain Cell memory (GCRAM) offers higher density and lower power than SRAM,\nmaking it a promising candidate for on-chip memory in domain-specific\naccelerators. To support workloads with varying traffic and lifetime metrics,\nGCRAM also offers high bandwidth, ultra low leakage power and a wide range of\nretention times, which can be adjusted through transistor design (like\nthreshold voltage and channel material) and on-the-fly by changing the\noperating voltage. However, designing and optimizing GCRAM sub-systems can be\ntime-consuming. In this paper, we present OpenGCRAM, an open-source GCRAM\ncompiler capable of generating GCRAM bank circuit designs and DRC- and\nLVS-clean layouts for commercially available foundry CMOS, while also providing\narea, delay, and power simulations based on user-specified configurations\n(e.g., word size and number of words). OpenGCRAM enables fast, accurate,\ncustomizable, and optimized GCRAM block generation, reduces design time, ensure\nprocess compliance, and delivers performance-tailored memory blocks that meet\ndiverse application requirements.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10849v1", "cate": "cs.AR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11435", "title": "FasTUSS: Faster Task-Aware Unified Source Separation", "authors": ["Francesco Paissan", "Gordon Wichern", "Yoshiki Masuyama", "Ryo Aihara", "François G. Germain", "Kohei Saijo", "Jonathan Le Roux"], "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted to WASPAA 2025", "url": "http://arxiv.org/abs/2507.11435v1", "summary": "Time-Frequency (TF) dual-path models are currently among the best performing\naudio source separation network architectures, achieving state-of-the-art\nperformance in speech enhancement, music source separation, and cinematic audio\nsource separation. While they are characterized by a relatively low parameter\ncount, they still require a considerable number of operations, implying a\nhigher execution time. This problem is exacerbated by the trend towards bigger\nmodels trained on large amounts of data to solve more general tasks, such as\nthe recently introduced task-aware unified source separation (TUSS) model.\nTUSS, which aims to solve audio source separation tasks using a single,\nconditional model, is built upon TF-Locoformer, a TF dual-path model combining\nconvolution and attention layers. The task definition comes in the form of a\nsequence of prompts that specify the number and type of sources to be\nextracted. In this paper, we analyze the design choices of TUSS with the goal\nof optimizing its performance-complexity trade-off. We derive two more\nefficient models, FasTUSS-8.3G and FasTUSS-11.7G that reduce the original\nmodel's operations by 81\\% and 73\\% with minor performance drops of 1.2~dB and\n0.4~dB averaged over all benchmarks, respectively. Additionally, we investigate\nthe impact of prompt conditioning to derive a causal TUSS model.", "comment": "Accepted to WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2507.11435v1", "cate": "cs.SD", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11523", "title": "Precision Spatio-Temporal Feature Fusion for Robust Remote Sensing Change Detection", "authors": ["Buddhi Wijenayake", "Athulya Ratnayake", "Praveen Sumanasekara", "Nichula Wasalathilaka", "Mathivathanan Piratheepan", "Roshan Godaliyadda", "Mervyn Ekanayake", "Vijitha Herath"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      6 pages, 4 figures, 2 pages, under review(conference paper)", "url": "http://arxiv.org/abs/2507.11523v1", "summary": "Remote sensing change detection is vital for monitoring environmental and\nurban transformations but faces challenges like manual feature extraction and\nsensitivity to noise. Traditional methods and early deep learning models, such\nas convolutional neural networks (CNNs), struggle to capture long-range\ndependencies and global context essential for accurate change detection in\ncomplex scenes. While Transformer-based models mitigate these issues, their\ncomputational complexity limits their applicability in high-resolution remote\nsensing. Building upon ChangeMamba architecture, which leverages state space\nmodels for efficient global context modeling, this paper proposes precision\nfusion blocks to capture channel-wise temporal variations and per-pixel\ndifferences for fine-grained change detection. An enhanced decoder pipeline,\nincorporating lightweight channel reduction mechanisms, preserves local details\nwith minimal computational cost. Additionally, an optimized loss function\ncombining Cross Entropy, Dice and Lovasz objectives addresses class imbalance\nand boosts Intersection-over-Union (IoU). Evaluations on SYSU-CD, LEVIR-CD+,\nand WHU-CD datasets demonstrate superior precision, recall, F1 score, IoU, and\noverall accuracy compared to state-of-the-art methods, highlighting the\napproach's robustness for remote sensing change detection. For complete\ntransparency, the codes and pretrained models are accessible at\nhttps://github.com/Buddhi19/MambaCD.git", "comment": "6 pages, 4 figures, 2 pages, under review(conference paper)", "pdf_url": "http://arxiv.org/pdf/2507.11523v1", "cate": "eess.IV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11306", "title": "P.808 Multilingual Speech Enhancement Testing: Approach and Results of URGENT 2025 Challenge", "authors": ["Marvin Sach", "Yihui Fu", "Kohei Saijo", "Wangyou Zhang", "Samuele Cornell", "Robin Scheibler", "Chenda Li", "Anurag Kumar", "Wei Wang", "Yanmin Qian", "Shinji Watanabe", "Tim Fingscheidt"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      5 pages, 2 figures", "url": "http://arxiv.org/abs/2507.11306v1", "summary": "In speech quality estimation for speech enhancement (SE) systems, subjective\nlistening tests so far are considered as the gold standard. This should be even\nmore true considering the large influx of new generative or hybrid methods into\nthe field, revealing issues of some objective metrics. Efforts such as the\nInterspeech 2025 URGENT Speech Enhancement Challenge also involving non-English\ndatasets add the aspect of multilinguality to the testing procedure. In this\npaper, we provide a brief recap of the ITU-T P.808 crowdsourced subjective\nlistening test method. A first novel contribution is our proposed process of\nlocalizing both text and audio components of Naderi and Cutler's implementation\nof crowdsourced subjective absolute category rating (ACR) listening tests\ninvolving text-to-speech (TTS). Further, we provide surprising analyses of and\ninsights into URGENT Challenge results, tackling the reliability of (P.808) ACR\nsubjective testing as gold standard in the age of generative AI. Particularly,\nit seems that for generative SE methods, subjective (ACR MOS) and objective\n(DNSMOS, NISQA) reference-free metrics should be accompanied by objective phone\nfidelity metrics to reliably detect hallucinations. Finally, in the accepted\nversion, we will release our localization scripts and methods for easy\ndeployment for new multilingual speech enhancement subjective evaluations\naccording to ITU-T P.808.", "comment": "5 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.11306v1", "cate": "eess.AS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2412.02734", "title": "MVCTrack: Boosting 3D Point Cloud Tracking via Multimodal-Guided Virtual Cues", "authors": ["Zhaofeng Hu", "Sifan Zhou", "Zhihang Yuan", "Dawei Yang", "Shibo Zhao", "Ci-Jyun Liang"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICRA 2025", "url": "http://arxiv.org/abs/2412.02734v5", "summary": "3D single object tracking is essential in autonomous driving and robotics.\nExisting methods often struggle with sparse and incomplete point cloud\nscenarios. To address these limitations, we propose a Multimodal-guided Virtual\nCues Projection (MVCP) scheme that generates virtual cues to enrich sparse\npoint clouds. Additionally, we introduce an enhanced tracker MVCTrack based on\nthe generated virtual cues. Specifically, the MVCP scheme seamlessly integrates\nRGB sensors into LiDAR-based systems, leveraging a set of 2D detections to\ncreate dense 3D virtual cues that significantly improve the sparsity of point\nclouds. These virtual cues can naturally integrate with existing LiDAR-based 3D\ntrackers, yielding substantial performance gains. Extensive experiments\ndemonstrate that our method achieves competitive performance on the NuScenes\ndataset.", "comment": "Accepted by ICRA 2025", "pdf_url": "http://arxiv.org/pdf/2412.02734v5", "cate": "cs.CV", "date": "2024-12-03", "updated": "2025-07-15"}
{"id": "2507.10933", "title": "Artificial Finance: How AI Thinks About Money", "authors": ["Orhan Erdem", "Ragavi Pobbathi Ashok"], "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "primary_category": "Subjects:       General Economics (econ.GN)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10933v1", "summary": "In this paper, we explore how large language models (LLMs) approach financial\ndecision-making by systematically comparing their responses to those of human\nparticipants across the globe. We posed a set of commonly used financial\ndecision-making questions to seven leading LLMs, including five models from the\nGPT series(GPT-4o, GPT-4.5, o1, o3-mini), Gemini 2.0 Flash, and DeepSeek R1. We\nthen compared their outputs to human responses drawn from a dataset covering 53\nnations. Our analysis reveals three main results. First, LLMs generally exhibit\na risk-neutral decision-making pattern, favoring choices aligned with expected\nvalue calculations when faced with lottery-type questions. Second, when\nevaluating trade-offs between present and future, LLMs occasionally produce\nresponses that appear inconsistent with normative reasoning. Third, when we\nexamine cross-national similarities, we find that the LLMs' aggregate responses\nmost closely resemble those of participants from Tanzania. These findings\ncontribute to the understanding of how LLMs emulate human-like decision\nbehaviors and highlight potential cultural and training influences embedded\nwithin their outputs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10933v1", "cate": "econ.GN", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10983", "title": "Physics-Informed Neural Networks For Semiconductor Film Deposition: A Review", "authors": ["Tao Han", "Zahra Taheri", "Hyunwoong Ko"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 1 figure, 3 tables, IDETC-CIE 2025", "url": "http://arxiv.org/abs/2507.10983v1", "summary": "Semiconductor manufacturing relies heavily on film deposition processes, such\nas Chemical Vapor Deposition and Physical Vapor Deposition. These complex\nprocesses require precise control to achieve film uniformity, proper adhesion,\nand desired functionality. Recent advancements in Physics-Informed Neural\nNetworks (PINNs), an innovative machine learning (ML) approach, have shown\nsignificant promise in addressing challenges related to process control,\nquality assurance, and predictive modeling within semiconductor film deposition\nand other manufacturing domains. This paper provides a comprehensive review of\nML applications targeted at semiconductor film deposition processes. Through a\nthematic analysis, we identify key trends, existing limitations, and research\ngaps, offering insights into both the advantages and constraints of current\nmethodologies. Our structured analysis aims to highlight the potential\nintegration of these ML techniques to enhance interpretability, accuracy, and\nrobustness in film deposition processes. Additionally, we examine\nstate-of-the-art PINN methods, discussing strategies for embedding physical\nknowledge, governing laws, and partial differential equations into advanced\nneural network architectures tailored for semiconductor manufacturing. Based on\nthis detailed review, we propose novel research directions that integrate the\nstrengths of PINNs to significantly advance film deposition processes. The\ncontributions of this study include establishing a clear pathway for future\nresearch in integrating physics-informed ML frameworks, addressing existing\nmethodological gaps, and ultimately improving precision, scalability, and\noperational efficiency within semiconductor manufacturing.", "comment": "11 pages, 1 figure, 3 tables, IDETC-CIE 2025", "pdf_url": "http://arxiv.org/pdf/2507.10983v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11152", "title": "Latent Space Consistency for Sparse-View CT Reconstruction", "authors": ["Duoyou Chen", "Yunqing Chen", "Can Zhang", "Zhou Wang", "Cheng Chen", "Ruoxiu Xiao"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ACMMM2025 Accepted", "url": "http://arxiv.org/abs/2507.11152v1", "summary": "Computed Tomography (CT) is a widely utilized imaging modality in clinical\nsettings. Using densely acquired rotational X-ray arrays, CT can capture 3D\nspatial features. However, it is confronted with challenged such as significant\ntime consumption and high radiation exposure. CT reconstruction methods based\non sparse-view X-ray images have garnered substantial attention from\nresearchers as they present a means to mitigate costs and risks. In recent\nyears, diffusion models, particularly the Latent Diffusion Model (LDM), have\ndemonstrated promising potential in the domain of 3D CT reconstruction.\nNonetheless, due to the substantial differences between the 2D latent\nrepresentation of X-ray modalities and the 3D latent representation of CT\nmodalities, the vanilla LDM is incapable of achieving effective alignment\nwithin the latent space. To address this issue, we propose the Consistent\nLatent Space Diffusion Model (CLS-DM), which incorporates cross-modal feature\ncontrastive learning to efficiently extract latent 3D information from 2D X-ray\nimages and achieve latent space alignment between modalities. Experimental\nresults indicate that CLS-DM outperforms classical and state-of-the-art\ngenerative models in terms of standard voxel-level metrics (PSNR, SSIM) on the\nLIDC-IDRI and CTSpine1K datasets. This methodology not only aids in enhancing\nthe effectiveness and economic viability of sparse X-ray reconstructed CT but\ncan also be generalized to other cross-modal transformation tasks, such as\ntext-to-image synthesis. We have made our code publicly available at\nhttps://anonymous.4open.science/r/CLS-DM-50D6/ to facilitate further research\nand applications in other domains.", "comment": "ACMMM2025 Accepted", "pdf_url": "http://arxiv.org/pdf/2507.11152v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11350", "title": "Distributionally Robust Optimization is a Multi-Objective Problem", "authors": ["Jun-ya Gotoh", "Michael Jong Kim", "Andrew E. B. Lim"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11350v1", "summary": "Distributionally Robust Optimization (DRO) is a worst-case approach to\ndecision making when there is model uncertainty. Though formulated as a\nsingle-objective problem, we show that it is intrinsically multi-objective in\nthat DRO solutions map out a near-Pareto-optimal frontier between expected cost\nand a measure of robustness called worst-case sensitivity (WCS). We take this\nas the starting point and explore robust decision making through a\nmulti-objective lens. We show that WCS is a measure of spread and derive WCS\nfor a collection of uncertainty sets commonly used in DRO. These sensitivity\nmeasures identify the errors against which the nominal expected cost is most\nvulnerable and the uncertainty set for the worst-case problem that most\neffectively mitigates it. The associated mean-sensitivity frontier is used to\nselect its size. The multi-objective perspective provides a quantitative\nmeasure of robustness and a sensitivity-based approach to addressing important\nconceptual gaps in DRO -- how to choose the family and size of uncertainty sets\nfor a given cost distribution, and how this affects the solution.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11350v1", "cate": "math.OC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11517", "title": "Gaussian Noise Model of Nonlinear Distortions from Semiconductor Optical Amplifiers", "authors": ["Hartmut Hafermann"], "categories": ["physics.optics", "eess.SP"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11517v1", "summary": "A Gaussian Noise Model of the nonlinear noise power spectral density is\ndeveloped for a semiconductor optical amplifier as described by the Agrawal\nmodel. A simple closed-form expression is obtained for the nonlinear\nnoise-to-signal ratio of broadband wavelength-division multiplexed signals as a\nfunction of the Agrawal model parameters, the amplifier output power and the\ntransmission bandwidth. The accuracy of the closed-form expression and its\nregion of validity is assessed in numerical simulations. The error is smaller\nthan 0.1 dB when the product of bandwidth and gain recovery time\n$B\\times\\tau_c$ exceeds 100.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11517v1", "cate": "physics.optics", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10601", "title": "AGFS-Tractometry: A Novel Atlas-Guided Fine-Scale Tractometry Approach for Enhanced Along-Tract Group Statistical Comparison Using Diffusion MRI Tractography", "authors": ["Ruixi Zheng", "Wei Zhang", "Yijie Li", "Xi Zhu", "Zhou Lan", "Jarrett Rushmore", "Yogesh Rathi", "Nikos Makris", "Lauren J. O'Donnell", "Fan Zhang"], "categories": ["q-bio.QM", "cs.CV", "cs.LG", "eess.IV", "stat.ME"], "primary_category": "Subjects:       Quantitative Methods (q-bio.QM)", "pdf_link": null, "comments": "Comments:      31 pages and 7 figures", "url": "http://arxiv.org/abs/2507.10601v1", "summary": "Diffusion MRI (dMRI) tractography is currently the only method for in vivo\nmapping of the brain's white matter (WM) connections. Tractometry is an\nadvanced tractography analysis technique for along-tract profiling to\ninvestigate the morphology and microstructural properties along the fiber\ntracts. Tractometry has become an essential tool for studying local along-tract\ndifferences between different populations (e.g., health vs disease). In this\nstudy, we propose a novel atlas-guided fine-scale tractometry method, namely\nAGFS-Tractometry, that leverages tract spatial information and permutation\ntesting to enhance the along-tract statistical analysis between populations.\nThere are two major contributions in AGFS-Tractometry. First, we create a novel\natlas-guided tract profiling template that enables consistent, fine-scale,\nalong-tract parcellation of subject-specific fiber tracts. Second, we propose a\nnovel nonparametric permutation testing group comparison method to enable\nsimultaneous analysis across all along-tract parcels while correcting for\nmultiple comparisons. We perform experimental evaluations on synthetic datasets\nwith known group differences and in vivo real data. We compare AGFS-Tractometry\nwith two state-of-the-art tractometry methods, including Automated Fiber-tract\nQuantification (AFQ) and BUndle ANalytics (BUAN). Our results show that the\nproposed AGFS-Tractometry obtains enhanced sensitivity and specificity in\ndetecting local WM differences. In the real data analysis experiments,\nAGFS-Tractometry can identify more regions with significant differences, which\nare anatomically consistent with the existing literature. Overall, these\ndemonstrate the ability of AGFS-Tractometry to detect subtle or spatially\nlocalized WM group-level differences. The created tract profiling template and\nrelated code are available at:\nhttps://github.com/ZhengRuixi/AGFS-Tractometry.git.", "comment": "31 pages and 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.10601v1", "cate": "q-bio.QM", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2507.11427", "title": "Towards Reliable Objective Evaluation Metrics for Generative Singing Voice Separation Models", "authors": ["Paul A. Bereuter", "Benjamin Stahl", "Mark D. Plumbley", "Alois Sontacchi"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at the IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA 2025), 5 pages", "url": "http://arxiv.org/abs/2507.11427v1", "summary": "Traditional Blind Source Separation Evaluation (BSS-Eval) metrics were\noriginally designed to evaluate linear audio source separation models based on\nmethods such as time-frequency masking. However, recent generative models may\nintroduce nonlinear relationships between the separated and reference signals,\nlimiting the reliability of these metrics for objective evaluation. To address\nthis issue, we conduct a Degradation Category Rating listening test and analyze\ncorrelations between the obtained degradation mean opinion scores (DMOS) and a\nset of objective audio quality metrics for the task of singing voice\nseparation. We evaluate three state-of-the-art discriminative models and two\nnew competitive generative models. For both discriminative and generative\nmodels, intrusive embedding-based metrics show higher correlations with DMOS\nthan conventional intrusive metrics such as BSS-Eval. For discriminative\nmodels, the highest correlation is achieved by the MSE computed on Music2Latent\nembeddings. When it comes to the evaluation of generative models, the strongest\ncorrelations are evident for the multi-resolution STFT loss and the MSE\ncalculated on MERT-L12 embeddings, with the latter also providing the most\nbalanced correlation across both model types. Our results highlight the\nlimitations of BSS-Eval metrics for evaluating generative singing voice\nseparation models and emphasize the need for careful selection and validation\nof alternative evaluation metrics for the task of singing voice separation.", "comment": "Accepted for presentation at the IEEE Workshop on Applications of\n  Signal Processing to Audio and Acoustics (WASPAA 2025), 5 pages", "pdf_url": "http://arxiv.org/pdf/2507.11427v1", "cate": "eess.AS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2505.00972", "title": "Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models", "authors": ["Yuewen Mei", "Tong Nie", "Jian Sun", "Ye Tian"], "categories": ["cs.AI", "cs.RO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE ITSC 2025", "url": "http://arxiv.org/abs/2505.00972v2", "summary": "Simulation-based testing is crucial for validating autonomous vehicles (AVs),\nyet existing scenario generation methods either overfit to common driving\npatterns or operate in an offline, non-interactive manner that fails to expose\nrare, safety-critical corner cases. In this paper, we introduce an online,\nretrieval-augmented large language model (LLM) framework for generating\nsafety-critical driving scenarios. Our method first employs an LLM-based\nbehavior analyzer to infer the most dangerous intent of the background vehicle\nfrom the observed state, then queries additional LLM agents to synthesize\nfeasible adversarial trajectories. To mitigate catastrophic forgetting and\naccelerate adaptation, we augment the framework with a dynamic memorization and\nretrieval bank of intent-planner pairs, automatically expanding its behavioral\nlibrary when novel intents arise. Evaluations using the Waymo Open Motion\nDataset demonstrate that our model reduces the mean minimum time-to-collision\nfrom 1.62 to 1.08 s and incurs a 75% collision rate, substantially\noutperforming baselines.", "comment": "Accepted at IEEE ITSC 2025", "pdf_url": "http://arxiv.org/pdf/2505.00972v2", "cate": "cs.AI", "date": "2025-05-02", "updated": "2025-07-15"}
{"id": "2507.10951", "title": "Biological Processing Units: Leveraging an Insect Connectome to Pioneer Biofidelic Neural Architectures", "authors": ["Siyu Yu", "Zihan Qin", "Tingshan Liu", "Beiya Xu", "R. Jacob Vogelstein", "Jason Brown", "Joshua T. Vogelstein"], "categories": ["cs.NE", "cs.AI"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      Accepted to AGI 2025", "url": "http://arxiv.org/abs/2507.10951v1", "summary": "The complete connectome of the Drosophila larva brain offers a unique\nopportunity to investigate whether biologically evolved circuits can support\nartificial intelligence. We convert this wiring diagram into a Biological\nProcessing Unit (BPU), a fixed recurrent network derived directly from synaptic\nconnectivity. Despite its modest size 3,000 neurons and 65,000 weights between\nthem), the unmodified BPU achieves 98% accuracy on MNIST and 58% on CIFAR-10,\nsurpassing size-matched MLPs. Scaling the BPU via structured connectome\nexpansions further improves CIFAR-10 performance, while modality-specific\nablations reveal the uneven contributions of different sensory subsystems. On\nthe ChessBench dataset, a lightweight GNN-BPU model trained on only 10,000\ngames achieves 60% move accuracy, nearly 10x better than any size transformer.\nMoreover, CNN-BPU models with ~2M parameters outperform parameter-matched\nTransformers, and with a depth-6 minimax search at inference, reach 91.7%\naccuracy, exceeding even a 9M-parameter Transformer baseline. These results\ndemonstrate the potential of biofidelic neural architectures to support complex\ncognitive tasks and motivate scaling to larger and more intelligent connectomes\nin future work.", "comment": "Accepted to AGI 2025", "pdf_url": "http://arxiv.org/pdf/2507.10951v1", "cate": "cs.NE", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10986", "title": "StellarF: A Lora-Adapter Integrated Large Model Framework for Stellar Flare Forecasting with Historical & Statistical Data", "authors": ["Tianyu Su", "Zhiqiang Zou", "Ali Luo", "Xiao Kong", "Qingyu Lu", "Min Li"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10986v1", "summary": "Stellar flare forecasting, a critical research frontier in astronomy, offers\nprofound insights into stellar activity. However, the field is constrained by\nboth the sparsity of recorded flare events and the absence of domain-specific\nlarge-scale predictive models. To address these challenges, this study\nintroduces StellarF (Stellar Flare Forecasting), a novel large model that\nleverages Low-Rank (LoRA) and Adapter techniques to parameter-efficient\nlearning for stellar flare forecasting. At its core, StellarF integrates an\nflare statistical information module with a historical flare record module,\nenabling multi-scale pattern recognition from observational data. Extensive\nexperiments on our self-constructed datasets (derived from Kepler and TESS\nlight curves) demonstrate that StellarF achieves state-of-the-art performance\ncompared to existing methods. The proposed prediction paradigm establishes a\nnovel methodological framework for advancing astrophysical research and\ncross-disciplinary applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10986v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11153", "title": "Assessing Color Vision Test in Large Vision-language Models", "authors": ["Hongfei Ye", "Bin Chen", "Wenxi Liu", "Yu Zhang", "Zhao Li", "Dandan Ni", "Hongyang Chen"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11153v1", "summary": "With the widespread adoption of large vision-language models, the capacity\nfor color vision in these models is crucial. However, the color vision\nabilities of large visual-language models have not yet been thoroughly\nexplored. To address this gap, we define a color vision testing task for large\nvision-language models and construct a dataset \\footnote{Anonymous Github\nShowing some of the data\nhttps://anonymous.4open.science/r/color-vision-test-dataset-3BCD} that covers\nmultiple categories of test questions and tasks of varying difficulty levels.\nFurthermore, we analyze the types of errors made by large vision-language\nmodels and propose fine-tuning strategies to enhance their performance in color\nvision tests.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11153v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11535", "title": "Canonical Bayesian Linear System Identification", "authors": ["Andrey Bryutkin", "Matthew E. Levine", "Iñigo Urteaga", "Youssef Marzouk"], "categories": ["stat.ML", "cs.LG", "cs.SY", "eess.SY", "stat.CO"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      46 pages, 9 figures", "url": "http://arxiv.org/abs/2507.11535v1", "summary": "Standard Bayesian approaches for linear time-invariant (LTI) system\nidentification are hindered by parameter non-identifiability; the resulting\ncomplex, multi-modal posteriors make inference inefficient and impractical. We\nsolve this problem by embedding canonical forms of LTI systems within the\nBayesian framework. We rigorously establish that inference in these minimal\nparameterizations fully captures all invariant system dynamics (e.g., transfer\nfunctions, eigenvalues, predictive distributions of system outputs) while\nresolving identifiability. This approach unlocks the use of meaningful,\nstructure-aware priors (e.g., enforcing stability via eigenvalues) and ensures\nconditions for a Bernstein--von Mises theorem -- a link between Bayesian and\nfrequentist large-sample asymptotics that is broken in standard forms.\nExtensive simulations with modern MCMC methods highlight advantages over\nstandard parameterizations: canonical forms achieve higher computational\nefficiency, generate interpretable and well-behaved posteriors, and provide\nrobust uncertainty estimates, particularly from limited data.", "comment": "46 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.11535v1", "cate": "stat.ML", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2502.16179", "title": "Orthogonality Analysis in LoRa Uplink Satellite Communications Affected by Doppler Effect", "authors": ["Jikang Deng", "Fatma Benkhelifa", "Mohamed-Slim Alouini"], "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.16179v2", "summary": "This paper provides, for the first time, analytical expressions for the\nLong-Range (LoRa) waveform and cross-correlation in both continuous and\ndiscrete time domains under the Doppler effect in satellite communication. We\npropose the concept and formulas of the shared visibility window for satellites\ntoward two ground devices. Our analysis covers cross-correlation results with\nvarying spreading factors (SF) for no-Doppler and with-Doppler cases. We find\nthe maximum cross-correlation with different SFs and the mean cross-correlation\nare immune to the Doppler effect. However, the maximum cross-correlation with\nthe same SFs is only immune to high Doppler shift, with its value fluctuating\nbetween 0.6 and 1 under high Doppler rate. We interpret this fluctuation by\nintroducing the relationship between transmission start time and\ncross-correlation. We provide a parameter analysis for orbit height, ground\ndevice distance, and inclination angle. Additionally, we analyze the bit error\nrate (BER) for LoRa signals and observe worse performance under high Doppler\nshift or interference with same SF. Increasing the SNR or the SIR improves the\nBER only when Doppler effect is below a frequency threshold. Notably, under\nDoppler effect, the performance behaviors of BER no longer align with those of\nmaximum cross-correlation. Finally, our results lead to two recommendations: 1)\nTo mitigate Doppler impact on cross-correlation, we recommend utilizing low\nSFs, high orbit height, short ground device distance, and the transmission\nstart time with high Doppler shift; 2) To mitigate Doppler impact on BER, we\nrecommend employing low SFs, high bandwidth, and transmission start time with\nhigh Doppler rate. These conflicting recommendations regarding transmission\nstart time highlight the necessity of Doppler shift compensation techniques to\nhelp operate LoRa in space properly.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.16179v2", "cate": "eess.SP", "date": "2025-02-22", "updated": "2025-07-15"}
{"id": "2507.11252", "title": "MFGDiffusion: Mask-Guided Smoke Synthesis for Enhanced Forest Fire Detection", "authors": ["Guanghao Wu", "Chen Xu", "Hai Song", "Chong Wang", "Qixing Zhang"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      18 pages, 11 figures", "url": "http://arxiv.org/abs/2507.11252v1", "summary": "Smoke is the first visible indicator of a wildfire.With the advancement of\ndeep learning, image-based smoke detection has become a crucial method for\ndetecting and preventing forest fires. However, the scarcity of smoke image\ndata from forest fires is one of the significant factors hindering the\ndetection of forest fire smoke. Image generation models offer a promising\nsolution for synthesizing realistic smoke images. However, current inpainting\nmodels exhibit limitations in generating high-quality smoke representations,\nparticularly manifesting as inconsistencies between synthesized smoke and\nbackground contexts. To solve these problems, we proposed a comprehensive\nframework for generating forest fire smoke images. Firstly, we employed the\npre-trained segmentation model and the multimodal model to obtain smoke masks\nand image captions.Then, to address the insufficient utilization of masks and\nmasked images by inpainting models, we introduced a network architecture guided\nby mask and masked image features. We also proposed a new loss function, the\nmask random difference loss, which enhances the consistency of the generated\neffects around the mask by randomly expanding and eroding the mask\nedges.Finally, to generate a smoke image dataset using random masks for\nsubsequent detection tasks, we incorporated smoke characteristics and use a\nmultimodal large language model as a filtering tool to select diverse and\nreasonable smoke images, thereby improving the quality of the synthetic\ndataset. Experiments showed that our generated smoke images are realistic and\ndiverse, and effectively enhance the performance of forest fire smoke detection\nmodels. Code is available at https://github.com/wghr123/MFGDiffusion.", "comment": "18 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.11252v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10708", "title": "Grammatical Structure and Grammatical Variations in Non-Metric Iranian Classical Music", "authors": ["Maziar Kanani", "Sean O Leary", "James McDermott"], "categories": ["cs.NE", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10708v1", "summary": "In this study we introduce a symbolic dataset composed of non-metric Iranian\nclassical music, and algorithms for structural parsing of this music, and\ngeneration of variations. The corpus comprises MIDI files and data sheets of\nDastgah Shour from Radif Mirza Abdollah, the foundational repertoire of Iranian\nclassical music. Furthermore, we apply our previously-introduced algorithm for\nparsing melodic structure (Kanani et al., 2023b)to the dataset. Unlike much\nWestern music, this type of non-metric music does not follow bar-centric\norganisation. The non-metric organisation can be captured well by our parsing\nalgorithm. We parse each tune (Gusheh) into a grammar to identify motifs and\nphrases. These grammar representations can be useful for educational and\nethnomusicological purposes. We also further develop a previously-introduced\nmethod of creating melodic variations (Kanani et al., 2023b). After parsing an\nexisting tune to produce a grammar, by applying mutations to this grammar, we\ngenerate a new grammar. Expanding this new version yields a variation of the\noriginal tune. Variations are assessed by a domain-expert listener.\nAdditionally, we conduct a statistical analysis of mutation with different\nrepresentation setups for our parsing and generation algorithms. The\noverarching conclusion is that the system successfully produces acceptable\nvariations post-mutation. While our case study focuses on Iranian classical\nmusic, the methodology can be adapted for Arabic or Turkish classical music.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10708v1", "cate": "cs.NE", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.05906", "title": "Feature-Based vs. GAN-Based Learning from Demonstrations: When and Why", "authors": ["Chenhao Li", "Marco Hutter", "Andreas Krause"], "categories": ["cs.LG", "cs.AI", "cs.GR", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05906v2", "summary": "This survey provides a comparative analysis of feature-based and GAN-based\napproaches to learning from demonstrations, with a focus on the structure of\nreward functions and their implications for policy learning. Feature-based\nmethods offer dense, interpretable rewards that excel at high-fidelity motion\nimitation, yet often require sophisticated representations of references and\nstruggle with generalization in unstructured settings. GAN-based methods, in\ncontrast, use implicit, distributional supervision that enables scalability and\nadaptation flexibility, but are prone to training instability and coarse reward\nsignals. Recent advancements in both paradigms converge on the importance of\nstructured motion representations, which enable smoother transitions,\ncontrollable synthesis, and improved task integration. We argue that the\ndichotomy between feature-based and GAN-based methods is increasingly nuanced:\nrather than one paradigm dominating the other, the choice should be guided by\ntask-specific priorities such as fidelity, diversity, interpretability, and\nadaptability. This work outlines the algorithmic trade-offs and design\nconsiderations that underlie method selection, offering a framework for\nprincipled decision-making in learning from demonstrations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05906v2", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-15"}
{"id": "2507.10957", "title": "Modeling Understanding of Story-Based Analogies Using Large Language Models", "authors": ["Kalit Inani", "Keshav Kabra", "Vijay Marupudi", "Sashank Varma"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      To appear at CogSci 2025", "url": "http://arxiv.org/abs/2507.10957v1", "summary": "Recent advancements in Large Language Models (LLMs) have brought them closer\nto matching human cognition across a variety of tasks. How well do these models\nalign with human performance in detecting and mapping analogies? Prior research\nhas shown that LLMs can extract similarities from analogy problems but lack\nrobust human-like reasoning. Building on Webb, Holyoak, and Lu (2023), the\ncurrent study focused on a story-based analogical mapping task and conducted a\nfine-grained evaluation of LLM reasoning abilities compared to human\nperformance. First, it explored the semantic representation of analogies in\nLLMs, using sentence embeddings to assess whether they capture the similarity\nbetween the source and target texts of an analogy, and the dissimilarity\nbetween the source and distractor texts. Second, it investigated the\neffectiveness of explicitly prompting LLMs to explain analogies. Throughout, we\nexamine whether LLMs exhibit similar performance profiles to those observed in\nhumans by evaluating their reasoning at the level of individual analogies, and\nnot just at the level of overall accuracy (as prior studies have done). Our\nexperiments include evaluating the impact of model size (8B vs. 70B parameters)\nand performance variation across state-of-the-art model architectures such as\nGPT-4 and LLaMA3. This work advances our understanding of the analogical\nreasoning abilities of LLMs and their potential as models of human reasoning.", "comment": "To appear at CogSci 2025", "pdf_url": "http://arxiv.org/pdf/2507.10957v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10990", "title": "High-Throughput Distributed Reinforcement Learning via Adaptive Policy Synchronization", "authors": ["Rodney Lafuente-Mercado"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10990v1", "summary": "Scaling reinforcement learning (RL) workloads often requires distributing\nenvironment simulation across compute clusters. Existing frameworks entangle\nsimulation, learning logic, and orchestration into monolithic systems, limiting\nmodularity and reusability. We present ClusterEnv, a lightweight,\nlearner-agnostic interface for distributed environment execution that mirrors\nthe Gymnasium API. ClusterEnv introduces the DETACH pattern, which decouples\nsimulation from training by offloading reset() and step() operations to remote\nworkers while keeping learning centralized. To address policy staleness in\ndistributed execution, we propose Adaptive Actor Policy Synchronization (AAPS),\na divergence-triggered update mechanism that reduces synchronization overhead\nwithout sacrificing performance. ClusterEnv integrates cleanly into existing RL\npipelines, supports both on-policy and off-policy methods, and requires minimal\ncode changes. Experiments on discrete control tasks demonstrate that AAPS\nachieves high sample efficiency with significantly fewer weight updates. Source\ncode is available at https://github.com/rodlaf/ClusterEnv.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10990v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11171", "title": "Clustering-Guided Multi-Layer Contrastive Representation Learning for Citrus Disease Classification", "authors": ["Jun Chen", "Yonghua Yu", "Weifu Li", "Yaohui Chen", "Hong Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11 pages, 5 figures", "url": "http://arxiv.org/abs/2507.11171v1", "summary": "Citrus, as one of the most economically important fruit crops globally,\nsuffers severe yield depressions due to various diseases. Accurate disease\ndetection and classification serve as critical prerequisites for implementing\ntargeted control measures. Recent advancements in artificial intelligence,\nparticularly deep learning-based computer vision algorithms, have substantially\ndecreased time and labor requirements while maintaining the accuracy of\ndetection and classification. Nevertheless, these methods predominantly rely on\nmassive, high-quality annotated training examples to attain promising\nperformance. By introducing two key designs: contrasting with cluster centroids\nand a multi-layer contrastive training (MCT) paradigm, this paper proposes a\nnovel clustering-guided self-supervised multi-layer contrastive representation\nlearning (CMCRL) algorithm. The proposed method demonstrates several advantages\nover existing counterparts: (1) optimizing with massive unannotated samples;\n(2) effective adaptation to the symptom similarity across distinct citrus\ndiseases; (3) hierarchical feature representation learning. The proposed method\nachieves state-of-the-art performance on the public citrus image set CDD,\noutperforming existing methods by 4.5\\%-30.1\\% accuracy. Remarkably, our method\nnarrows the performance gap with fully supervised counterparts (all samples are\nlabeled). Beyond classification accuracy, our method shows great performance on\nother evaluation metrics (F1 score, precision, and recall), highlighting the\nrobustness against the class imbalance challenge.", "comment": "11 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.11171v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2309.11622", "title": "Offline and Online Use of Interval and Set-Based Approaches for Control and State Estimation: A Selection of Methodological Approaches and Their Application", "authors": ["Andreas Rauh", "Marit Lahme", "Simon Rohou", "Luc Jaulin", "Thach Ngoc Dinh", "Tarek Raissi", "Mohamed Fnadi"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2309.11622v4", "summary": "Control and state estimation procedures need to be robust against imprecisely\nknown parameters, uncertainty in initial conditions, and external disturbances.\nInterval methods and other set-based techniques form the basis for the\nimplementation of powerful approaches that can be used to identify parameters\nof dynamic system models in the presence of the aforementioned types of\nuncertainty. Moreover, they are applicable to a verified feasibility and\nstability analysis of controllers and state estimators. In addition to these\napproaches which are typically used offline for analysis of system models\ndesigned with classical floating point procedures, interval and set-based\nmethods have also been developed in recent years, which allow to directly solve\nthe associated design tasks and to implement reliable techniques that are\napplicable online, i.e., during system operation. The latter approaches include\nset-based model predictive control, online parameter adaptation techniques for\nnonlinear variable-structure and backstepping controllers, interval observers,\nand fault diagnosis techniques. This paper provides an overview of the\nmethodological background and reviews numerous practical applications for which\ninterval and other set-valued approaches have been employed successfully.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2309.11622v4", "cate": "eess.SY", "date": "2023-09-20", "updated": "2025-07-14"}
{"id": "2503.00486", "title": "Conformal Lyapunov Optimization: Optimal Resource Allocation under Deterministic Reliability Constraints", "authors": ["Francesco Binucci", "Osvaldo Simeone", "Paolo Banelli"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      17 pages, 13 figures", "url": "http://arxiv.org/abs/2503.00486v5", "summary": "This paper introduces conformal Lyapunov optimization (CLO), a novel resource\nallocation framework for networked systems that optimizes average long-term\nobjectives, while satisfying deterministic long-term reliability constraints.\nUnlike traditional Lyapunov optimization (LO), which addresses resource\nallocation tasks under average long-term constraints, CLO provides formal\nworst-case deterministic reliability guarantees. This is achieved by\nintegrating the standard LO optimization framework with online conformal risk\ncontrol (O-CRC), an adaptive update mechanism controlling long-term risks. The\neffectiveness of CLO is verified via experiments for hierarchal edge inference\ntargeting image segmentation tasks in a networked computing architecture.\nSpecifically, simulation results confirm that CLO can control reliability\nconstraints, measured via the false negative rate of all the segmentation\ndecisions made in the network, while at the same time minimizing the weighted\nsum of energy consumption and precision loss, with the latter accounting for\nthe rate of false positives.", "comment": "17 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2503.00486v5", "cate": "eess.SP", "date": "2025-03-01", "updated": "2025-07-15"}
{"id": "2507.11457", "title": "LRMR: LLM-Driven Relational Multi-node Ranking for Lymph Node Metastasis Assessment in Rectal Cancer", "authors": ["Yaoxian Dong", "Yifan Gao", "Haoyue Li", "Yanfen Cui", "Xin Gao"], "categories": ["cs.LG", "eess.IV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11457v1", "summary": "Accurate preoperative assessment of lymph node (LN) metastasis in rectal\ncancer guides treatment decisions, yet conventional MRI evaluation based on\nmorphological criteria shows limited diagnostic performance. While some\nartificial intelligence models have been developed, they often operate as black\nboxes, lacking the interpretability needed for clinical trust. Moreover, these\nmodels typically evaluate nodes in isolation, overlooking the patient-level\ncontext. To address these limitations, we introduce LRMR, an LLM-Driven\nRelational Multi-node Ranking framework. This approach reframes the diagnostic\ntask from a direct classification problem into a structured reasoning and\nranking process. The LRMR framework operates in two stages. First, a multimodal\nlarge language model (LLM) analyzes a composite montage image of all LNs from a\npatient, generating a structured report that details ten distinct radiological\nfeatures. Second, a text-based LLM performs pairwise comparisons of these\nreports between different patients, establishing a relative risk ranking based\non the severity and number of adverse features. We evaluated our method on a\nretrospective cohort of 117 rectal cancer patients. LRMR achieved an area under\nthe curve (AUC) of 0.7917 and an F1-score of 0.7200, outperforming a range of\ndeep learning baselines, including ResNet50 (AUC 0.7708). Ablation studies\nconfirmed the value of our two main contributions: removing the relational\nranking stage or the structured prompting stage led to a significant\nperformance drop, with AUCs falling to 0.6875 and 0.6458, respectively. Our\nwork demonstrates that decoupling visual perception from cognitive reasoning\nthrough a two-stage LLM framework offers a powerful, interpretable, and\neffective new paradigm for assessing lymph node metastasis in rectal cancer.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11457v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10985", "title": "Pronunciation Deviation Analysis Through Voice Cloning and Acoustic Comparison", "authors": ["Andrew Valdivia", "Yueming Zhang", "Hailu Xu", "Amir Ghasemkhani", "Xin Qin"], "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10985v1", "summary": "This paper presents a novel approach for detecting mispronunciations by\nanalyzing deviations between a user's original speech and their voice-cloned\ncounterpart with corrected pronunciation. We hypothesize that regions with\nmaximal acoustic deviation between the original and cloned utterances indicate\npotential mispronunciations. Our method leverages recent advances in voice\ncloning to generate a synthetic version of the user's voice with proper\npronunciation, then performs frame-by-frame comparisons to identify problematic\nsegments. Experimental results demonstrate the effectiveness of this approach\nin pinpointing specific pronunciation errors without requiring predefined\nphonetic rules or extensive training data for each target language.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10985v1", "cate": "cs.SD", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.07969", "title": "Reinforcement Learning with Action Chunking", "authors": ["Qiyang Li", "Zhiyuan Zhou", "Sergey Levine"], "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      25 pages, 15 figures", "url": "http://arxiv.org/abs/2507.07969v2", "summary": "We present Q-chunking, a simple yet effective recipe for improving\nreinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks.\nOur recipe is designed for the offline-to-online RL setting, where the goal is\nto leverage an offline prior dataset to maximize the sample-efficiency of\nonline learning. Effective exploration and sample-efficient learning remain\ncentral challenges in this setting, as it is not obvious how the offline data\nshould be utilized to acquire a good exploratory policy. Our key insight is\nthat action chunking, a technique popularized in imitation learning where\nsequences of future actions are predicted rather than a single action at each\ntimestep, can be applied to temporal difference (TD)-based RL methods to\nmitigate the exploration challenge. Q-chunking adopts action chunking by\ndirectly running RL in a 'chunked' action space, enabling the agent to (1)\nleverage temporally consistent behaviors from offline data for more effective\nonline exploration and (2) use unbiased $n$-step backups for more stable and\nefficient TD learning. Our experimental results demonstrate that Q-chunking\nexhibits strong offline performance and online sample efficiency, outperforming\nprior best offline-to-online methods on a range of long-horizon, sparse-reward\nmanipulation tasks.", "comment": "25 pages, 15 figures", "pdf_url": "http://arxiv.org/pdf/2507.07969v2", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-15"}
{"id": "2507.10995", "title": "Misalignment from Treating Means as Ends", "authors": ["Henrik Marklund", "Alex Infanger", "Benjamin Van Roy"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10995v1", "summary": "Reward functions, learned or manually specified, are rarely perfect. Instead\nof accurately expressing human goals, these reward functions are often\ndistorted by human beliefs about how best to achieve those goals. Specifically,\nthese reward functions often express a combination of the human's terminal\ngoals -- those which are ends in themselves -- and the human's instrumental\ngoals -- those which are means to an end. We formulate a simple example in\nwhich even slight conflation of instrumental and terminal goals results in\nsevere misalignment: optimizing the misspecified reward function results in\npoor performance when measured by the true reward function. This example\ndistills the essential properties of environments that make reinforcement\nlearning highly sensitive to conflation of instrumental and terminal goals. We\ndiscuss how this issue can arise with a common approach to reward learning and\nhow it can manifest in real environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10995v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10998", "title": "Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data", "authors": ["Zhipeng He", "Alexander Stevens", "Chun Ouyang", "Johannes De Smedt", "Alistair Barros", "Catarina Moreira"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      32 pages", "url": "http://arxiv.org/abs/2507.10998v1", "summary": "Adversarial attacks on tabular data present fundamental challenges distinct\nfrom image or text domains due to the heterogeneous nature of mixed categorical\nand numerical features. Unlike images where pixel perturbations maintain visual\nsimilarity, tabular data lacks intuitive similarity metrics, making it\ndifficult to define imperceptible modifications. Additionally, traditional\ngradient-based methods prioritise $\\ell_p$-norm constraints, often producing\nadversarial examples that deviate from the original data distributions, making\nthem detectable. We propose a latent space perturbation framework using a\nmixed-input Variational Autoencoder (VAE) to generate imperceptible adversarial\nexamples. The proposed VAE integrates categorical embeddings and numerical\nfeatures into a unified latent manifold, enabling perturbations that preserve\nstatistical consistency. We specify In-Distribution Success Rate (IDSR) to\nmeasure the proportion of adversarial examples that remain statistically\nindistinguishable from the input distribution. Evaluation across six publicly\navailable datasets and three model architectures demonstrates that our method\nachieves substantially lower outlier rates and more consistent performance\ncompared to traditional input-space attacks and other VAE-based methods adapted\nfrom image domain approaches. Our comprehensive analysis includes\nhyperparameter sensitivity, sparsity control mechanisms, and generative\narchitectural comparisons, revealing that VAE-based attacks depend critically\non reconstruction quality but offer superior practical utility when sufficient\ntraining data is available. This work highlights the importance of on-manifold\nperturbations for realistic adversarial attacks on tabular data, offering a\nrobust approach for practical deployment. The source code can be accessed\nthrough https://github.com/ZhipengHe/VAE-TabAttack.", "comment": "32 pages", "pdf_url": "http://arxiv.org/pdf/2507.10998v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11200", "title": "How Far Have Medical Vision-Language Models Come? A Comprehensive Benchmarking Study", "authors": ["Che Liu", "Jiazhen Pan", "Weixiang Shen", "Wenjia Bai", "Daniel Rueckert", "Rossella Arcucci"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by the International Conference on AI in Healthcare 2025", "url": "http://arxiv.org/abs/2507.11200v1", "summary": "Vision-Language Models (VLMs) trained on web-scale corpora excel at natural\nimage tasks and are increasingly repurposed for healthcare; however, their\ncompetence in medical tasks remains underexplored. We present a comprehensive\nevaluation of open-source general-purpose and medically specialised VLMs,\nranging from 3B to 72B parameters, across eight benchmarks: MedXpert,\nOmniMedVQA, PMC-VQA, PathVQA, MMMU, SLAKE, and VQA-RAD. To observe model\nperformance across different aspects, we first separate it into understanding\nand reasoning components. Three salient findings emerge. First, large\ngeneral-purpose models already match or surpass medical-specific counterparts\non several benchmarks, demonstrating strong zero-shot transfer from natural to\nmedical images. Second, reasoning performance is consistently lower than\nunderstanding, highlighting a critical barrier to safe decision support. Third,\nperformance varies widely across benchmarks, reflecting differences in task\ndesign, annotation quality, and knowledge demands. No model yet reaches the\nreliability threshold for clinical deployment, underscoring the need for\nstronger multimodal alignment and more rigorous, fine-grained evaluation\nprotocols.", "comment": "Accepted by the International Conference on AI in Healthcare 2025", "pdf_url": "http://arxiv.org/pdf/2507.11200v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2310.17180", "title": "A Forward Reachability Perspective on Control Barrier Functions and Discount Factors in Reachability Analysis", "authors": ["Jason J. Choi", "Donggun Lee", "Boyang Li", "Jonathan P. How", "Koushil Sreenath", "Sylvia L. Herbert", "Claire J. Tomlin"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      The first two authors contributed equally to this work", "url": "http://arxiv.org/abs/2310.17180v3", "summary": "Control invariant sets are crucial for various methods that aim to design\nsafe control policies for systems whose state constraints must be satisfied\nover an indefinite time horizon. In this article, we explore the connections\namong reachability, control invariance, and Control Barrier Functions (CBFs).\nUnlike prior formulations based on backward reachability concepts, we establish\na strong link between these three concepts by examining the inevitable Forward\nReachable Tube (FRT), which is the set of states such that every trajectory\nreaching the FRT must have passed through a given initial set of states. First,\nour findings show that the inevitable FRT is precisely this initial set itself\nif it is a robust control invariant set with a differentiable boundary-a\nproperty necessary to connect with CBFs whose zero-level sets are control\ninvariant. We highlight that if the boundary is not differentiable, the FRT of\nthe robust control invariant set may become a strict superset of the invariant\nset and lose invariance. Next, we formulate a differential game between the\ncontrol and disturbance, where the inevitable FRT is characterized by the\nzero-superlevel set of the value function. By incorporating a discount factor\nin the cost function of the game, the barrier constraint of the CBF naturally\narises in the Hamilton-Jacobi equation and determines the optimal policy.\nCombining these results, the value function of our FRT formulation serves as a\nCBF-like function, and conversely, any valid CBF is also a forward reachability\nvalue function inside the control invariant set, thereby revealing the inverse\noptimality of the CBF. This strong link between reachability and barrier\nconstraints is not achievable by previous backward reachability-based\nformulations, and addresses an important gap in existing literature for\nconstructing valid CBFs to ensure safety.", "comment": "The first two authors contributed equally to this work", "pdf_url": "http://arxiv.org/pdf/2310.17180v3", "cate": "eess.SY", "date": "2023-10-26", "updated": "2025-07-15"}
{"id": "2505.01570", "title": "Memory-less and Backscatter-less Tunnel Diode Harmonic Signatures for RFID", "authors": ["Christopher Saetia", "Kaitlyn Graves", "Serhat Tadik", "Gregory D. Durgin"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2505.01570v2", "summary": "Tunnel diodes have traditionally been researched for extending backscatter\nread-ranges for ultra-high-frequency (UHF) radio-frequency identification\n(RFID) tags as reflection amplifiers. This paper explores the natural harmonics\nthat arise from biasing these diodes within their negative differential\nresistance regions and with no interrogating signal from a transmitting source,\nsuch as an RFID reader, to injection-lock these diodes. These harmonics are\ncharacterized for five tunnel diode boards, made with the same components and\nwith each board's fundamental frequencies measuring at above -15 dBm at a\nbiasing voltage of 200 mV when measured over-the-cable. The occurrence of these\nharmonics creates unique harmonic signatures for each board and demonstrates\npossible harmonic RFID applications that can help RFID readers discover and\neven identify RFID tags with backscatter-less and memory-less IDs generated by\ntunnel diodes.", "comment": "This work has been submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2505.01570v2", "cate": "eess.SP", "date": "2025-05-02", "updated": "2025-07-15"}
{"id": "2308.09730", "title": "The Utility of the Virtual Imaging Trials Methodology for Objective Characterization of AI Systems and Training Data", "authors": ["Fakrul Islam Tushar", "Lavsen Dahal", "Saman Sotoudeh-Paima", "Ehsan Abadi", "W. Paul Segars", "Ehsan Samei", "Joseph Y. Lo"], "categories": ["eess.IV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2308.09730v4", "summary": "The credibility of Artificial Intelligence (AI) models for medical imaging\ncontinues to be a challenge, affected by the diversity of models, the data used\nto train the models, and applicability of their combination to produce\nreproducible results for new data. In this work we aimed to explore if the\nemerging Virtual Imaging Trials (VIT) methodologies can provide an objective\nresource to approach this challenge. The study was conducted for the case\nexample of COVID-19 diagnosis using clinical and virtual computed tomography\n(CT) and chest radiography (CXR) processed with convolutional neural networks\n(CNNs). Multiple AI models were developed and tested using 3D ResNet-like and\n2D EfficientNetv2 architectures across diverse datasets. The performance\ndifferences were evaluated in terms of the area under the curve (AUC) and the\nDeLong method for AUC confidence intervals. The models trained on the most\ndiverse datasets showed the highest external testing performance, with AUC\nvalues ranging from 0.73 to 0.76 for CT and 0.70 to 0.73 for CXR. Internal\ntesting yielded higher AUC values (0.77 to 0.85 for CT and 0.77 to 1.0 for\nCXR), highlighting a substantial drop in performance during external\nvalidation, which underscores the importance of diverse and comprehensive\ntraining and testing data. Most notably, the VIT approach provided objective\nassessment of the utility of diverse models and datasets while further\nproviding insight into the influence of dataset characteristics, patient\nfactors, and imaging physics on AI efficacy. The VIT approach can be used to\nenhance model transparency and reliability, offering nuanced insights into the\nfactors driving AI performance and bridging the gap between experimental and\nclinical settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2308.09730v4", "cate": "eess.IV", "date": "2023-08-17", "updated": "2025-07-14"}
{"id": "2505.05077", "title": "ReverbMiipher: Generative Speech Restoration meets Reverberation Characteristics Controllability", "authors": ["Wataru Nakata", "Yuma Koizumi", "Shigeki Karita", "Robin Scheibler", "Haruko Ishikawa", "Adriana Guevara-Rukoz", "Heiga Zen", "Michiel Bacchiani"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      5 pages, 5 figures", "url": "http://arxiv.org/abs/2505.05077v2", "summary": "Reverberation encodes spatial information regarding the acoustic source\nenvironment, yet traditional Speech Restoration (SR) usually completely removes\nreverberation. We propose ReverbMiipher, an SR model extending parametric\nresynthesis framework, designed to denoise speech while preserving and enabling\ncontrol over reverberation. ReverbMiipher incorporates a dedicated\nReverbEncoder to extract a reverb feature vector from noisy input. This feature\nconditions a vocoder to reconstruct the speech signal, removing noise while\nretaining the original reverberation characteristics. A stochastic zero-vector\nreplacement strategy during training ensures the feature specifically encodes\nreverberation, disentangling it from other speech attributes. This learned\nrepresentation facilitates reverberation control via techniques such as\ninterpolation between features, replacement with features from other\nutterances, or sampling from a latent space. Objective and subjective\nevaluations confirm ReverbMiipher effectively preserves reverberation, removes\nother artifacts, and outperforms the conventional two-stage SR and convolving\nsimulated room impulse response approach. We further demonstrate its ability to\ngenerate novel reverberation effects through feature manipulation.", "comment": "5 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2505.05077v2", "cate": "cs.SD", "date": "2025-05-08", "updated": "2025-07-15"}
{"id": "2507.08831", "title": "View Invariant Learning for Vision-Language Navigation in Continuous Environments", "authors": ["Josh Qixuan Sun", "Xiaoying Xing", "Huaiyuan Weng", "Chul Min Yeum", "Mark Crowley"], "categories": ["cs.CV", "cs.LG", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Under review", "url": "http://arxiv.org/abs/2507.08831v2", "summary": "Vision-Language Navigation in Continuous Environments (VLNCE), where an agent\nfollows instructions and moves freely to reach a destination, is a key research\nproblem in embodied AI. However, most navigation policies are sensitive to\nviewpoint changes, i.e., variations in camera height and viewing angle that\nalter the agent's observation. In this paper, we introduce a generalized\nscenario, V2-VLNCE (VLNCE with Varied Viewpoints), and propose VIL (View\nInvariant Learning), a view-invariant post-training strategy that enhances the\nrobustness of existing navigation policies to changes in camera viewpoint. VIL\nemploys a contrastive learning framework to learn sparse and view-invariant\nfeatures. Additionally, we introduce a teacher-student framework for the\nWaypoint Predictor Module, a core component of most VLNCE baselines, where a\nview-dependent teacher model distills knowledge into a view-invariant student\nmodel. We employ an end-to-end training paradigm to jointly optimize these\ncomponents, thus eliminating the cost for individual module training. Empirical\nresults show that our method outperforms state-of-the-art approaches on\nV2-VLNCE by 8-15% measured on Success Rate for two standard benchmark datasets\nR2R-CE and RxR-CE. Furthermore, we evaluate VIL under the standard VLNCE\nsetting and find that, despite being trained for varied viewpoints, it often\nstill improves performance. On the more challenging RxR-CE dataset, our method\nalso achieved state-of-the-art performance across all metrics when compared to\nother map-free methods. This suggests that adding VIL does not diminish the\nstandard viewpoint performance and can serve as a plug-and-play post-training\nmethod.", "comment": "Under review", "pdf_url": "http://arxiv.org/pdf/2507.08831v2", "cate": "cs.CV", "date": "2025-07-05", "updated": "2025-07-15"}
{"id": "2507.11017", "title": "First-Order Error Matters: Accurate Compensation for Quantized Large Language Models", "authors": ["Xingyu Zheng", "Haotong Qin", "Yuye Li", "Jiakai Wang", "Jinyang Guo", "Michele Magno", "Xianglong Liu"], "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11017v1", "summary": "Post-training quantization (PTQ) offers an efficient approach to compressing\nlarge language models (LLMs), significantly reducing memory access and\ncomputational costs. Existing compensation-based weight calibration methods\noften rely on a second-order Taylor expansion to model quantization error,\nunder the assumption that the first-order term is negligible in well-trained\nfull-precision models. However, we reveal that the progressive compensation\nprocess introduces accumulated first-order deviations between latent weights\nand their full-precision counterparts, making this assumption fundamentally\nflawed. To address this, we propose FOEM, a novel PTQ method that explicitly\nincorporates first-order gradient terms to improve quantization error\ncompensation. FOEM approximates gradients by directly computing the difference\nbetween latent and full-precision weights, avoiding the high cost and limited\ngeneralization of backpropagation-based gradient computation. This approach\nintroduces minimal additional computational overhead. Moreover, FOEM leverages\nprecomputed Cholesky factors to efficiently recover the inverse of Hessian\nsubmatrices in real time. Extensive experiments across a wide range of models\nand benchmarks demonstrate that FOEM consistently outperforms the classical\nGPTQ method. In 3-bit weight-only quantization, FOEM reduces the perplexity of\nLlama3-8B by 89.6%, and improves the 5-shot MMLU accuracy of Llama3-70B from\n51.7% to 74.9%, approaching the full-precision performance of 78.6%.\nFurthermore, FOEM can be seamlessly integrated with advanced techniques such as\nGPTAQ and SpinQuant, yielding additional improvements under the challenging\nW4A4KV4 setting, and further narrowing the accuracy gap with full-precision\nbaselines beyond what current state-of-the-art methods achieve. The code is\navailable at https://github.com/Xingyu-Zheng/FOEM.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11017v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11005", "title": "AdaMuon: Adaptive Muon Optimizer", "authors": ["Chongjie Si", "Debing Zhang", "Wei Shen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11005v1", "summary": "We propose AdaMuon, an adaptive learning-rate framework built upon the\nrecently validated Muon optimizer, which has demonstrated substantial\nefficiency gains over AdamW in large-scale model training. AdaMuon augments\nMuon with two mutually dependent modules: (1) a per-parameter second-moment\nmodulation that captures orthogonal gradient updates to ensure update-level\nadaptivity, and (2) a RMS-aligned rescaling that regulates the overall update\nmagnitude by aligning it with the intrinsic structure of the parameter space.\nEmpirical results on multiple model scales and learning-rate regimes confirm\nthat AdaMuon consistently outperforms the original Muon, delivering higher\nacceleration in convergence while maintaining training stability. Our method\nintroduces no additional tuning burden and can be seamlessly integrated into\nexisting Muon training pipelines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11005v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11202", "title": "A Robust Incomplete Multimodal Low-Rank Adaptation Approach for Emotion Recognition", "authors": ["Xinkui Zhao", "Jinsong Shu", "Yangyang Wu", "Guanjie Cheng", "Zihe Liu", "Naibo Wang", "Shuiguang Deng", "Zhongle Xie", "Jianwei Yin"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11202v1", "summary": "Multimodal Emotion Recognition (MER) often encounters incomplete\nmultimodality in practical applications due to sensor failures or privacy\nprotection requirements. While existing methods attempt to address various\nincomplete multimodal scenarios by balancing the training of each modality\ncombination through additional gradients, these approaches face a critical\nlimitation: training gradients from different modality combinations conflict\nwith each other, ultimately degrading the performance of the final prediction\nmodel. In this paper, we propose a unimodal decoupled dynamic low-rank\nadaptation method based on modality combinations, named MCULoRA, which is a\nnovel framework for the parameter-efficient training of incomplete multimodal\nlearning models. MCULoRA consists of two key modules, modality combination\naware low-rank adaptation (MCLA) and dynamic parameter fine-tuning (DPFT). The\nMCLA module effectively decouples the shared information from the distinct\ncharacteristics of individual modality combinations. The DPFT module adjusts\nthe training ratio of modality combinations based on the separability of each\nmodality's representation space, optimizing the learning efficiency across\ndifferent modality combinations. Our extensive experimental evaluation in\nmultiple benchmark datasets demonstrates that MCULoRA substantially outperforms\nprevious incomplete multimodal learning approaches in downstream task accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11202v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2410.11981", "title": "Parallel Batch Scheduling With Incompatible Job Families Via Constraint Programming", "authors": ["Jorge A. Huertas", "Pascal Van Hentenryck"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      17 pages, 9 figures", "url": "http://arxiv.org/abs/2410.11981v4", "summary": "This paper addresses the incompatible case of parallel batch scheduling,\nwhere compatible jobs belong to the same family, and jobs from different\nfamilies cannot be processed together in the same batch. The state-of-the-art\nconstraint programming (CP) model for this problem relies on specific functions\nand global constraints only available in a well established commercial CP\nsolver. This paper expands the literature around this problem by proposing four\nnew CP models that can be implemented in commercial and open-source solvers: a\nnew model that relies on automaton constraints, and three alternative models\nthat integrate assignment and scheduling decisions with different strategies\nand global constraints. Extensive computational experiments on standard test\ncases under multiple objectives and multiple solvers demonstrate the\nimplementation flexibility and competitive performance of the proposed models.", "comment": "17 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2410.11981v4", "cate": "eess.SY", "date": "2024-10-15", "updated": "2025-07-15"}
{"id": "2505.23198", "title": "Deep Learning-Based CSI Feedback for Wi-Fi Systems With Temporal Correlation", "authors": ["Junyong Shin", "Eunsung Jeon", "Inhyoung Kim", "Yo-Seb Jeon"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.23198v2", "summary": "To achieve higher throughput in next-generation Wi-Fi systems, a station\n(STA) needs to efficiently compress channel state information (CSI) and feed it\nback to an access point (AP). In this paper, we propose a novel deep learning\n(DL)-based CSI feedback framework tailored for next-generation Wi-Fi systems.\nOur framework incorporates a pair of encoder and decoder neural networks to\ncompress and reconstruct the angle parameters of the CSI. To enable an\nefficient finite-bit representation of the encoder output, we introduce a\ntrainable vector quantization module, which is integrated after the encoder\nnetwork and jointly trained with both the encoder and decoder networks in an\nend-to-end manner. Additionally, we further enhance our framework by leveraging\nthe temporal correlation of the angle parameters. Specifically, we propose an\nangle-difference feedback strategy which transmits the difference between the\ncurrent and previous angle parameters when the difference is sufficiently\nsmall. This strategy accounts for the periodicity of the angle parameters\nthrough proper preprocessing and mitigates error propagation effects using\nnovel feedback methods. We also introduce a DL-based CSI refinement module for\nthe AP, which improves the reconstruction accuracy of the angle parameters by\nsimultaneously utilizing both the previous and current feedback information.\nSimulation results demonstrate that our framework outperforms the standard\nmethod employed in current Wi-Fi systems. Our results also demonstrate\nsignificant performance gains achieved by the angle-difference feedback\nstrategy and the CSI refinement module.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.23198v2", "cate": "eess.SP", "date": "2025-05-29", "updated": "2025-07-15"}
{"id": "2409.16921", "title": "Moner: Motion Correction in Undersampled Radial MRI with Unsupervised Neural Representation", "authors": ["Qing Wu", "Chenhe Du", "Xuanyu Tian", "Jingyi Yu", "Yuyao Zhang", "Hongjiang Wei"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted by ICLR 2025 Spotlight", "url": "http://arxiv.org/abs/2409.16921v4", "summary": "Motion correction (MoCo) in radial MRI is a particularly challenging problem\ndue to the unpredictability of subject movement. Current state-of-the-art\n(SOTA) MoCo algorithms often rely on extensive high-quality MR images to\npre-train neural networks, which constrains the solution space and leads to\noutstanding image reconstruction results. However, the need for large-scale\ndatasets significantly increases costs and limits model generalization. In this\nwork, we propose Moner, an unsupervised MoCo method that jointly reconstructs\nartifact-free MR images and estimates accurate motion from undersampled, rigid\nmotion-corrupted k-space data, without requiring any training data. Our core\nidea is to leverage the continuous prior of implicit neural representation\n(INR) to constrain this ill-posed inverse problem, facilitating optimal\nsolutions. Specifically, we integrate a quasi-static motion model into the INR,\ngranting its ability to correct subject's motion. To stabilize model\noptimization, we reformulate radial MRI reconstruction as a back-projection\nproblem using the Fourier-slice theorem. Additionally, we propose a novel\ncoarse-to-fine hash encoding strategy, significantly enhancing MoCo accuracy.\nExperiments on multiple MRI datasets show our Moner achieves performance\ncomparable to SOTA MoCo techniques on in-domain data, while demonstrating\nsignificant improvements on out-of-domain data. The code is available at:\nhttps://github.com/iwuqing/Moner", "comment": "Accepted by ICLR 2025 Spotlight", "pdf_url": "http://arxiv.org/pdf/2409.16921v4", "cate": "eess.IV", "date": "2024-09-25", "updated": "2025-07-15"}
{"id": "2507.09116", "title": "Mixture of LoRA Experts with Multi-Modal and Multi-Granularity LLM Generative Error Correction for Accented Speech Recognition", "authors": ["Bingshen Mu", "Kun Wei", "Pengcheng Guo", "Lei Xie"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      IEEE Transactions on Audio, Speech and Language Processing", "url": "http://arxiv.org/abs/2507.09116v2", "summary": "Despite substantial improvements in ASR, performance tends to degrade when\nfaced with adverse conditions such as speaker accents. Generative error\ncorrection (GER) leverages the rich linguistic knowledge and exceptional\nreasoning ability of LLMs, significantly outperforming typical LM methods.\nHowever, it lacks specificity in accented speech scenarios. In this study, we\nleverage GER to improve the accuracy of transcription predictions by addressing\nthe two primary features of accented speech recognition. To fully leverage\npronunciation information, we propose the multi-modal GER, which integrates\npronunciation information from the speech modality, and the multi-granularity\nGER, which incorporates fine-grained phoneme-level information related to\npronunciation. These two methods enable the LLM to utilize the pronunciation\ninformation of accented speech and the semantic information from word-level\nhypotheses for accurate transcription predictions through LoRA fine-tuning. On\nthe one hand, we employ a three-stage training strategy to train separate\nmulti-modal GER models for each accent to obtain mono-accent LoRA experts. By\nadopting our proposed HDMoLE method, which incorporates hierarchical routing\nand dynamic thresholds within the mixture of LoRA experts, we effectively merge\nmultiple mono-accent LoRA experts within a single multi-modal GER to overcome\nthe challenges posed by accent diversity. On the other hand, multi-granularity\nGER leverages the N-best word-level and phoneme-level hypotheses generated by\nthe HDMoLE model to predict the final accented speech transcriptions.\nExperimental results on the multi-accent English dataset demonstrate the\nefficacy of our proposed methods. Our methods achieve a remarkable relative WER\nreduction of 67.35% compared to the Whisper-large-v3 baseline.", "comment": "IEEE Transactions on Audio, Speech and Language Processing", "pdf_url": "http://arxiv.org/pdf/2507.09116v2", "cate": "cs.SD", "date": "2025-07-12", "updated": "2025-07-15"}
{"id": "2507.09180", "title": "Learning and Transferring Better with Depth Information in Visual Reinforcement Learning", "authors": ["Zichun Xu", "Yuntao Li", "Zhaomin Wang", "Lei Zhuang", "Guocai Yang", "Jingdong Zhao"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09180v2", "summary": "Depth information is robust to scene appearance variations and inherently\ncarries 3D spatial details. In this paper, a visual backbone based on the\nvision transformer is proposed to fuse RGB and depth modalities for enhancing\ngeneralization. Different modalities are first processed by separate CNN stems,\nand the combined convolutional features are delivered to the scalable vision\ntransformer to obtain visual representations. Moreover, a contrastive\nunsupervised learning scheme is designed with masked and unmasked tokens to\naccelerate the sample efficiency during the reinforcement learning progress.\nFor sim2real transfer, a flexible curriculum learning schedule is developed to\ndeploy domain randomization over training processes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09180v2", "cate": "cs.CV", "date": "2025-07-12", "updated": "2025-07-15"}
{"id": "2507.11052", "title": "LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP", "authors": ["Haowei Yang", "Ziyu Shen", "Junli Shao", "Luyao Men", "Xinyue Han", "Jing Dong"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11052v1", "summary": "Timely identification and accurate risk stratification of cardiovascular\ndisease (CVD) remain essential for reducing global mortality. While existing\nprediction models primarily leverage structured data, unstructured clinical\nnotes contain valuable early indicators. This study introduces a novel\nLLM-augmented clinical NLP pipeline that employs domain-adapted large language\nmodels for symptom extraction, contextual reasoning, and correlation from\nfree-text reports. Our approach integrates cardiovascular-specific fine-tuning,\nprompt-based inference, and entity-aware reasoning. Evaluations on MIMIC-III\nand CARDIO-NLP datasets demonstrate improved performance in precision, recall,\nF1-score, and AUROC, with high clinical relevance (kappa = 0.82) assessed by\ncardiologists. Challenges such as contextual hallucination, which occurs when\nplausible information contracts with provided source, and temporal ambiguity,\nwhich is related with models struggling with chronological ordering of events\nare addressed using prompt engineering and hybrid rule-based verification. This\nwork underscores the potential of LLMs in clinical decision support systems\n(CDSS), advancing early warning systems and enhancing the translation of\npatient narratives into actionable risk assessments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11052v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11012", "title": "Leveraging Advanced Machine Learning to Predict Turbulence Dynamics from Temperature Observations at an Experimental Prescribed Fire", "authors": ["Dipak Dulal", "Joseph J. Charney", "Michael R. Gallagher", "Pitambar Acharya", "Carmeliza Navasca", "Nicholas S. Skowronski"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2311.05128", "url": "http://arxiv.org/abs/2507.11012v1", "summary": "This study explores the potential for predicting turbulent kinetic energy\n(TKE) from more readily acquired temperature data using temperature profiles\nand turbulence data collected concurrently at 10 Hz during a small experimental\nprescribed burn in the New Jersey Pine Barrens. Machine learning models,\nincluding Deep Neural Networks, Random Forest Regressor, Gradient Boosting, and\nGaussian Process Regressor, were employed to assess the potential to predict\nTKE from temperature perturbations and explore temporal and spatial dynamics of\ncorrelations. Data visualization and correlation analyses revealed patterns and\nrelationships between thermocouple temperatures and TKE, providing insight into\nthe underlying dynamics. More accurate predictions of TKE were achieved by\nemploying various machine learning models despite a weak correlation between\nthe predictors and the target variable. The results demonstrate significant\nsuccess, particularly from regression models, in accurately predicting the TKE.\nThe findings of this study demonstrate a novel numerical approach to\nidentifying new relationships between temperature and airflow processes in and\naround the fire environment. These relationships can help refine our\nunderstanding of combustion environment processes and the coupling and\ndecoupling of fire environment processes necessary for improving fire\noperations strategy and fire and smoke model predictions. The findings of this\nstudy additionally highlight the valuable role of machine learning techniques\nin analyzing the complex large datasets of the fire environments, showcasing\ntheir potential to advance fire research and management practices.", "comment": "arXiv admin note: text overlap with arXiv:2311.05128", "pdf_url": "http://arxiv.org/pdf/2507.11012v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11245", "title": "NarrLV: Towards a Comprehensive Narrative-Centric Evaluation for Long Video Generation Models", "authors": ["X. Feng", "H. Yu", "M. Wu", "S. Hu", "J. Chen", "C. Zhu", "J. Wu", "X. Chu", "K. Huang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project Page: this https URL", "url": "http://arxiv.org/abs/2507.11245v1", "summary": "With the rapid development of foundation video generation technologies, long\nvideo generation models have exhibited promising research potential thanks to\nexpanded content creation space. Recent studies reveal that the goal of long\nvideo generation tasks is not only to extend video duration but also to\naccurately express richer narrative content within longer videos. However, due\nto the lack of evaluation benchmarks specifically designed for long video\ngeneration models, the current assessment of these models primarily relies on\nbenchmarks with simple narrative prompts (e.g., VBench). To the best of our\nknowledge, our proposed NarrLV is the first benchmark to comprehensively\nevaluate the Narrative expression capabilities of Long Video generation models.\nInspired by film narrative theory, (i) we first introduce the basic narrative\nunit maintaining continuous visual presentation in videos as Temporal Narrative\nAtom (TNA), and use its count to quantitatively measure narrative richness.\nGuided by three key film narrative elements influencing TNA changes, we\nconstruct an automatic prompt generation pipeline capable of producing\nevaluation prompts with a flexibly expandable number of TNAs. (ii) Then, based\non the three progressive levels of narrative content expression, we design an\neffective evaluation metric using the MLLM-based question generation and\nanswering framework. (iii) Finally, we conduct extensive evaluations on\nexisting long video generation models and the foundation generation models.\nExperimental results demonstrate that our metric aligns closely with human\njudgments. The derived evaluation outcomes reveal the detailed capability\nboundaries of current video generation models in narrative content expression.", "comment": "Project Page: https://amap-ml.github.io/NarrLV-Website/", "pdf_url": "http://arxiv.org/pdf/2507.11245v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2506.15105", "title": "Skew-Induced Insertion Loss Deviation (SILD) and FOM_SILD: Metrics for Quantifying P/N Skew Effects in High-Speed Channels", "authors": ["David Nozadze", "Zurab Kiguradze", "Amendra Koul", "Mike Sapozhnikov"], "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.15105v2", "summary": "The rise of AI workloads and growing data center demands have driven the need\nfor ultra-high-speed interconnects exceeding 200 Gb/s. As unit intervals (UI)\nshrink, even a few picoseconds of P/N skew can degrade serializer-deserializer\n(SerDes) performance. Traditional methods for quantifying skew fall short in\ncapturing its impact. We introduce two new metrics: 1) Skew-Induced Insertion\nLoss Deviation (SILD) and 2) its complementary Figure of Merit (FOM_SILD),\nanalytically developed to assess P/N skew effects. Measured S-parameters\nconfirm FOM_SILD reciprocity, while simulations of 224G PAM4 SerDes show strong\ncorrelation with bit error rate (BER) trends. This approach offers a robust\nframework for analyzing skew in next-generation ultra-high-speed interconnects.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.15105v2", "cate": "eess.SY", "date": "2025-06-18", "updated": "2025-07-14"}
{"id": "2507.09776", "title": "Compute SNR-Optimal Analog-to-Digital Converters for Analog In-Memory Computing", "authors": ["Mihir Kavishwar", "Naresh Shanbhag"], "categories": ["eess.SP", "cs.AR"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Code available at: this https URL", "url": "http://arxiv.org/abs/2507.09776v2", "summary": "Analog in-memory computing (AIMC) is an energy-efficient alternative to\ndigital architectures for accelerating machine learning and signal processing\nworkloads. However, its energy efficiency is limited by the high energy cost of\nthe column analog-to-digital converters (ADCs). Reducing the ADC precision is\nan effective approach to lowering its energy cost. However, doing so also\nreduces the AIMC's computational accuracy thereby making it critical to\nidentify the minimum precision required to meet a target accuracy. Prior works\noverestimate the ADC precision requirements by modeling quantization error as\ninput-independent noise, maximizing the signal-to-quantization-noise ratio\n(SQNR), and ignoring the discrete nature of ideal pre-ADC signal. We address\nthese limitations by developing analytical expressions for estimating the\ncompute signal-to-noise ratio (CSNR), a true metric of accuracy for AIMCs, and\npropose CACTUS, an algorithm to obtain CSNR-optimal ADC parameters. Using a\ncircuit-aware behavioral model of an SRAM-based AIMC in a 28nm CMOS process, we\nshow that for a 256-dimensional binary dot product, CACTUS reduces the ADC\nprecision requirements by 3b while achieving 6dB higher CSNR over prior\nmethods. We also delineate operating conditions under which our proposed\nCSNR-optimal ADCs outperform conventional SQNR-optimal ADCs.", "comment": "Code available at: https://github.com/mihirvk2/CSNR-optimal-ADC", "pdf_url": "http://arxiv.org/pdf/2507.09776v2", "cate": "eess.SP", "date": "2025-07-13", "updated": "2025-07-15"}
{"id": "2410.13896", "title": "From Real Artifacts to Virtual Reference: A Robust Framework for Translating Endoscopic Images", "authors": ["Junyang Wu", "Fangfang Xie", "Jiayuan Sun", "Yun Gu", "Guang-Zhong Yang"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      The conclusions of the paper has error. It requires substantial re-evaluation, and I plan to resubmit an updated version in the future", "url": "http://arxiv.org/abs/2410.13896v3", "summary": "Domain adaptation, which bridges the distributions across different\nmodalities, plays a crucial role in multimodal medical image analysis. In\nendoscopic imaging, combining pre-operative data with intra-operative imaging\nis important for surgical planning and navigation. However, existing domain\nadaptation methods are hampered by distribution shift caused by in vivo\nartifacts, necessitating robust techniques for aligning noisy and artifact\nabundant patient endoscopic videos with clean virtual images reconstructed from\npre-operative tomographic data for pose estimation during intraoperative\nguidance. This paper presents an artifact-resilient image translation method\nand an associated benchmark for this purpose. The method incorporates a novel\n``local-global'' translation framework and a noise-resilient feature extraction\nstrategy. For the former, it decouples the image translation process into a\nlocal step for feature denoising, and a global step for global style transfer.\nFor feature extraction, a new contrastive learning strategy is proposed, which\ncan extract noise-resilient features for establishing robust correspondence\nacross domains. Detailed validation on both public and in-house clinical\ndatasets has been conducted, demonstrating significantly improved performance\ncompared to the current state-of-the-art.", "comment": "The conclusions of the paper has error. It requires substantial\n  re-evaluation, and I plan to resubmit an updated version in the future", "pdf_url": "http://arxiv.org/pdf/2410.13896v3", "cate": "eess.IV", "date": "2024-10-15", "updated": "2025-07-15"}
{"id": "2507.11053", "title": "GATE: Graph Attention Neural Networks with Real-Time Edge Construction for Robust Indoor Localization using Mobile Embedded Devices", "authors": ["Danish Gufran", "Sudeep Pasricha"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11053v1", "summary": "Accurate indoor localization is crucial for enabling spatial context in smart\nenvironments and navigation systems. Wi-Fi Received Signal Strength (RSS)\nfingerprinting is a widely used indoor localization approach due to its\ncompatibility with mobile embedded devices. Deep Learning (DL) models improve\naccuracy in localization tasks by learning RSS variations across locations, but\nthey assume fingerprint vectors exist in a Euclidean space, failing to\nincorporate spatial relationships and the non-uniform distribution of\nreal-world RSS noise. This results in poor generalization across heterogeneous\nmobile devices, where variations in hardware and signal processing distort RSS\nreadings. Graph Neural Networks (GNNs) can improve upon conventional DL models\nby encoding indoor locations as nodes and modeling their spatial and signal\nrelationships as edges. However, GNNs struggle with non-Euclidean noise\ndistributions and suffer from the GNN blind spot problem, leading to degraded\naccuracy in environments with dense access points (APs). To address these\nchallenges, we propose GATE, a novel framework that constructs an adaptive\ngraph representation of fingerprint vectors while preserving an indoor\nstate-space topology, modeling the non-Euclidean structure of RSS noise to\nmitigate environmental noise and address device heterogeneity. GATE introduces\n1) a novel Attention Hyperspace Vector (AHV) for enhanced message passing, 2) a\nnovel Multi-Dimensional Hyperspace Vector (MDHV) to mitigate the GNN blind\nspot, and 3) an new Real-Time Edge Construction (RTEC) approach for dynamic\ngraph adaptation. Extensive real-world evaluations across multiple indoor\nspaces with varying path lengths, AP densities, and heterogeneous devices\ndemonstrate that GATE achieves 1.6x to 4.72x lower mean localization errors and\n1.85x to 4.57x lower worst-case errors compared to state-of-the-art indoor\nlocalization frameworks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11053v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11019", "title": "Relative Entropy Pathwise Policy Optimization", "authors": ["Claas Voelcker", "Axel Brunnbauer", "Marcel Hussing", "Michal Nauman", "Pieter Abbeel", "Eric Eaton", "Radu Grosu", "Amir-massoud Farahmand", "Igor Gilitschenski"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11019v1", "summary": "Score-function policy gradients have delivered strong results in\ngame-playing, robotics and language-model fine-tuning. Yet its high-variance\noften undermines training stability. On the other hand, pathwise policy\ngradients alleviate the training variance, but are reliable only when driven by\nan accurate action-conditioned value function which is notoriously hard to\ntrain without relying on past off-policy data. In this paper, we discuss how to\nconstruct a value-gradient driven, on-policy algorithm that allow training\nQ-value models purely from on-policy data, unlocking the possibility of using\npathwise policy updates in the context of on-policy learning. We show how to\nbalance stochastic policies for exploration with constrained policy updates for\nstable training, and evaluate important architectural components that\nfacilitate accurate value function learning. Building on these insights, we\npropose Relative Entropy Pathwise Policy Optimization (REPPO), an efficient\non-policy algorithm that combines the sample-efficiency of pathwise policy\ngradients with the simplicity and minimal memory footprint of standard\non-policy learning. We demonstrate that REPPO provides strong empirical\nperformance at decreased sample requirements, wall-clock time, memory footprint\nas well as high hyperparameter robustness in a set of experiments on two\nstandard GPU-parallelized benchmarks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11019v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11247", "title": "Fairness-Aware Grouping for Continuous Sensitive Variables: Application for Debiasing Face Analysis with respect to Skin Tone", "authors": ["Veronika Shilova", "Emmanuel Malherbe", "Giovanni Palma", "Laurent Risser", "Jean-Michel Loubes"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11247v1", "summary": "Within a legal framework, fairness in datasets and models is typically\nassessed by dividing observations into predefined groups and then computing\nfairness measures (e.g., Disparate Impact or Equality of Odds with respect to\ngender). However, when sensitive attributes such as skin color are continuous,\ndividing into default groups may overlook or obscure the discrimination\nexperienced by certain minority subpopulations. To address this limitation, we\npropose a fairness-based grouping approach for continuous (possibly\nmultidimensional) sensitive attributes. By grouping data according to observed\nlevels of discrimination, our method identifies the partition that maximizes a\nnovel criterion based on inter-group variance in discrimination, thereby\nisolating the most critical subgroups.\n  We validate the proposed approach using multiple synthetic datasets and\ndemonstrate its robustness under changing population distributions - revealing\nhow discrimination is manifested within the space of sensitive attributes.\nFurthermore, we examine a specialized setting of monotonic fairness for the\ncase of skin color. Our empirical results on both CelebA and FFHQ, leveraging\nthe skin tone as predicted by an industrial proprietary algorithm, show that\nthe proposed segmentation uncovers more nuanced patterns of discrimination than\npreviously reported, and that these findings remain stable across datasets for\na given model. Finally, we leverage our grouping model for debiasing purpose,\naiming at predicting fair scores with group-by-group post-processing. The\nresults demonstrate that our approach improves fairness while having minimal\nimpact on accuracy, thus confirming our partition method and opening the door\nfor industrial deployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11247v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2203.11837", "title": "Gain and phase type multipliers for feedback robustness", "authors": ["Axel Ringh", "Xin Mao", "Wei Chen", "Li Qiu", "Sei Zhen Khong"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      Revision, 16 pages", "url": "http://arxiv.org/abs/2203.11837v2", "summary": "It is known that the stability of a feedback interconnection of two linear\ntime-invariant systems implies that the graphs of the open-loop systems are\nquadratically separated. This separation is defined by an object known as the\nmultiplier. The theory of integral quadratic constraints shows that the\nconverse also holds under certain conditions. This paper establishes that if\nthe feedback is robustly stable against certain structured uncertainty, then\nthere always exists a multiplier that takes a corresponding form. In\nparticular, if the feedback is robustly stable to certain gain-type\nuncertainty, then there exists a corresponding multiplier that is of\nphase-type, i.e., its diagonal blocks are zeros. These results build on the\nnotion of phases of matrices and systems, which was recently introduced in the\nfield of control. Similarly, if the feedback is robustly stable to certain\nphase-type uncertainty, then there exists a gain-type multiplier, i.e., its\noff-diagonal blocks are zeros. The results are meaningfully instructive in the\nsearch for a valid multiplier for establishing robust closed-loop stability,\nand cover the well-known small-gain and the recent small-phase theorems.", "comment": "Revision, 16 pages", "pdf_url": "http://arxiv.org/pdf/2203.11837v2", "cate": "math.OC", "date": "2022-03-22", "updated": "2025-07-14"}
{"id": "2501.03461", "title": "Few-Shot Radar Signal Recognition through Self-Supervised Learning and Radio Frequency Domain Adaptation", "authors": ["Zi Huang", "Simon Denman", "Akila Pemasiri", "Clinton Fookes", "Terrence Martin"], "categories": ["cs.LG", "cs.AI", "eess.SP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      6 pages, 15 figures", "url": "http://arxiv.org/abs/2501.03461v3", "summary": "Radar signal recognition (RSR) plays a pivotal role in electronic warfare\n(EW), as accurately classifying radar signals is critical for informing\ndecision-making. Recent advances in deep learning have shown significant\npotential in improving RSR in domains with ample annotated data. However, these\nmethods fall short in EW scenarios where annotated radio frequency (RF) data\nare scarce or impractical to obtain. To address these challenges, we introduce\na self-supervised learning (SSL) method which utilises masked signal modelling\nand RF domain adaption to perform few-shot RSR and enhance performance in\nenvironments with limited RF samples and annotations. We propose a two-step\napproach, first pre-training masked autoencoders (MAE) on baseband in-phase and\nquadrature (I/Q) signals from diverse RF domains, and then transferring the\nlearned representations to the radar domain, where annotated data are scarce.\nEmpirical results show that our lightweight self-supervised ResNet1D model with\ndomain adaptation achieves up to a 17.5% improvement in 1-shot classification\naccuracy when pre-trained on in-domain signals (i.e., radar signals) and up to\na 16.31% improvement when pre-trained on out-of-domain signals (i.e., comm\nsignals), compared to its baseline without using SSL. We also present reference\nresults for several MAE designs and pre-training strategies, establishing a new\nbenchmark for few-shot radar signal classification.", "comment": "6 pages, 15 figures", "pdf_url": "http://arxiv.org/pdf/2501.03461v3", "cate": "cs.LG", "date": "2025-01-07", "updated": "2025-07-15"}
{"id": "2411.06738", "title": "360-Degree Video Super Resolution and Quality Enhancement Challenge: Methods and Results", "authors": ["Ahmed Telili", "Wassim Hamidouche", "Ibrahim Farhat", "Hadi Amirpour", "Christian Timmerer", "Ibrahim Khadraoui", "Jiajie Lu", "The Van Le", "Jeonneung Baek", "Jin Young Lee", "Yiying Wei", "Xiaopeng Sun", "Yu Gao", "JianCheng Huangl", "Yujie Zhong"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      14 pages, 9 figures", "url": "http://arxiv.org/abs/2411.06738v2", "summary": "Omnidirectional (360-degree) video is rapidly gaining popularity due to\nadvancements in immersive technologies like virtual reality (VR) and extended\nreality (XR). However, real-time streaming of such videos, especially in live\nmobile scenarios like unmanned aerial vehicles (UAVs), is challenged by limited\nbandwidth and strict latency constraints. Traditional methods, such as\ncompression and adaptive resolution, help but often compromise video quality\nand introduce artifacts that degrade the viewer experience. Additionally, the\nunique spherical geometry of 360-degree video presents challenges not\nencountered in traditional 2D video. To address these issues, we initiated the\n360-degree Video Super Resolution and Quality Enhancement Challenge. This\ncompetition encourages participants to develop efficient machine learning\nsolutions to enhance the quality of low-bitrate compressed 360-degree videos,\nwith two tracks focusing on 2x and 4x super-resolution (SR). In this paper, we\noutline the challenge framework, detailing the two competition tracks and\nhighlighting the SR solutions proposed by the top-performing models. We assess\nthese models within a unified framework, considering quality enhancement,\nbitrate gain, and computational efficiency. This challenge aims to drive\ninnovation in real-time 360-degree video streaming, improving the quality and\naccessibility of immersive visual experiences.", "comment": "14 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2411.06738v2", "cate": "eess.IV", "date": "2024-11-11", "updated": "2025-07-15"}
{"id": "2507.10582", "title": "Transforming Sensitive Documents into Quantitative Data: An AI-Based Preprocessing Toolchain for Structured and Privacy-Conscious Analysis", "authors": ["Anders Ledberg", "Anna Thalén"], "categories": ["cs.CL", "stat.ME"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10582v1", "summary": "Unstructured text from legal, medical, and administrative sources offers a\nrich but underutilized resource for research in public health and the social\nsciences. However, large-scale analysis is hampered by two key challenges: the\npresence of sensitive, personally identifiable information, and significant\nheterogeneity in structure and language. We present a modular toolchain that\nprepares such text data for embedding-based analysis, relying entirely on\nopen-weight models that run on local hardware, requiring only a\nworkstation-level GPU and supporting privacy-sensitive research.\n  The toolchain employs large language model (LLM) prompting to standardize,\nsummarize, and, when needed, translate texts to English for greater\ncomparability. Anonymization is achieved via LLM-based redaction, supplemented\nwith named entity recognition and rule-based methods to minimize the risk of\ndisclosure. We demonstrate the toolchain on a corpus of 10,842 Swedish court\ndecisions under the Care of Abusers Act (LVM), comprising over 56,000 pages.\nEach document is processed into an anonymized, standardized summary and\ntransformed into a document-level embedding. Validation, including manual\nreview, automated scanning, and predictive evaluation shows the toolchain\neffectively removes identifying information while retaining semantic content.\nAs an illustrative application, we train a predictive model using embedding\nvectors derived from a small set of manually labeled summaries, demonstrating\nthe toolchain's capacity for semi-automated content analysis at scale.\n  By enabling structured, privacy-conscious analysis of sensitive documents,\nour toolchain opens new possibilities for large-scale research in domains where\ntextual data was previously inaccessible due to privacy and heterogeneity\nconstraints.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10582v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.10691", "title": "A Fast Coloring Oracle for Average Case Hypergraphs", "authors": ["Cassandra Marcussen", "Edward Pyne", "Ronitt Rubinfeld", "Asaf Shapira", "Shlomo Tauber"], "categories": ["cs.DS", "cs.CC", "math.CO"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      18 pages, 2 figures", "url": "http://arxiv.org/abs/2507.10691v1", "summary": "Hypergraph $2$-colorability is one of the classical NP-hard problems. Person\nand Schacht [SODA'09] designed a deterministic algorithm whose expected running\ntime is polynomial over a uniformly chosen $2$-colorable $3$-uniform\nhypergraph. Lee, Molla, and Nagle recently extended this to $k$-uniform\nhypergraphs for all $k\\geq 3$. Both papers relied heavily on the regularity\nlemma, hence their analysis was involved and their running time hid tower-type\nconstants.\n  Our first result in this paper is a new simple and elementary deterministic\n$2$-coloring algorithm that reproves the theorems of Person-Schacht and\nLee-Molla-Nagle while avoiding the use of the regularity lemma. We also show\nhow to turn our new algorithm into a randomized one with average expected\nrunning time of only $O(n)$.\n  Our second and main result gives what we consider to be the ultimate evidence\nof just how easy it is to find a $2$-coloring of an average $2$-colorable\nhypergraph. We define a coloring oracle to be an algorithm which, given vertex\n$v$, assigns color red/blue to $v$ while inspecting as few edges as possible,\nso that the answers to any sequence of queries to the oracle are consistent\nwith a single legal $2$-coloring of the input. Surprisingly, we show that there\nis a coloring oracle that, on average, can answer every vertex query in time\n$O(1)$.", "comment": "18 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.10691v1", "cate": "cs.DS", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11071", "title": "LogTinyLLM: Tiny Large Language Models Based Contextual Log Anomaly Detection", "authors": ["Isaiah Thompson Ocansey", "Ritwik Bhattacharya", "Tanmay Sen"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11071v1", "summary": "Log anomaly detection using traditional rule based or deep learning based\nmethods is often challenging due to the large volume and highly complex nature\nof log sequence. So effective way of detection of anomalous sequence of logs is\ncrucial for system maintenance and development. This paper proposes parameter\nefficient finetuning specifically low rank adaptation (LoRA) and adapter based\napproaches for finding contextual anomalies in sequence of logs in large log\ndata set. It compares different tiny large language models (LLMs) on the\nThunderbird dataset. The results show that LoRA based finetuning provides\nsubstantial performance improvements of 18 to 19 percentage over LogBert based\nfull finetuning approach, achieving accuracy scores between 97.76% and 98.83%\ncompared to 79.37%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11071v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11063", "title": "A Distance Metric for Mixed Integer Programming Instances", "authors": ["Gwen Maudet", "Grégoire Danoy"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to ECAI 2025", "url": "http://arxiv.org/abs/2507.11063v1", "summary": "Mixed-integer linear programming (MILP) is a powerful tool for addressing a\nwide range of real-world problems, but it lacks a clear structure for comparing\ninstances. A reliable similarity metric could establish meaningful\nrelationships between instances, enabling more effective evaluation of instance\nset heterogeneity and providing better guidance to solvers, particularly when\nmachine learning is involved. Existing similarity metrics often lack precision\nin identifying instance classes or rely heavily on labeled data, which limits\ntheir applicability and generalization. To bridge this gap, this paper\nintroduces the first mathematical distance metric for MILP instances, derived\ndirectly from their mathematical formulations. By discretizing right-hand\nsides, weights, and variables into classes, the proposed metric draws\ninspiration from the Earth mover's distance to quantify mismatches in\nweight-variable distributions for constraint comparisons. This approach\nnaturally extends to enable instance-level comparisons. We evaluate both an\nexact and a greedy variant of our metric under various parameter settings,\nusing the StrIPLIB dataset. Results show that all components of the metric\ncontribute to class identification, and that the greedy version achieves\naccuracy nearly identical to the exact formulation while being nearly 200 times\nfaster. Compared to state-of-the-art baselines, including feature-based,\nimage-based, and neural network models, our unsupervised method consistently\noutperforms all non-learned approaches and rivals the performance of a\nsupervised classifier on class and subclass grouping tasks.", "comment": "Accepted to ECAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.11063v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11261", "title": "ViewSRD: 3D Visual Grounding via Structured Multi-View Decomposition", "authors": ["Ronggang Huang", "Haoxin Yang", "Yan Cai", "Xuemiao Xu", "Huaidong Zhang", "Shengfeng He"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.11261v1", "summary": "3D visual grounding aims to identify and localize objects in a 3D space based\non textual descriptions. However, existing methods struggle with disentangling\ntargets from anchors in complex multi-anchor queries and resolving\ninconsistencies in spatial descriptions caused by perspective variations. To\ntackle these challenges, we propose ViewSRD, a framework that formulates 3D\nvisual grounding as a structured multi-view decomposition process. First, the\nSimple Relation Decoupling (SRD) module restructures complex multi-anchor\nqueries into a set of targeted single-anchor statements, generating a\nstructured set of perspective-aware descriptions that clarify positional\nrelationships. These decomposed representations serve as the foundation for the\nMulti-view Textual-Scene Interaction (Multi-TSI) module, which integrates\ntextual and scene features across multiple viewpoints using shared, Cross-modal\nConsistent View Tokens (CCVTs) to preserve spatial correlations. Finally, a\nTextual-Scene Reasoning module synthesizes multi-view predictions into a\nunified and robust 3D visual grounding. Experiments on 3D visual grounding\ndatasets show that ViewSRD significantly outperforms state-of-the-art methods,\nparticularly in complex queries requiring precise spatial differentiation.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.11261v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2504.18398", "title": "Partition Map-Based Fast Block Partitioning for VVC Inter Coding", "authors": ["Xinmin Feng", "Zhuoyuan Li", "Li Li", "Dong Liu", "Feng Wu"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      23 pages, 26 figures. Project page: this https URL", "url": "http://arxiv.org/abs/2504.18398v2", "summary": "Among the new techniques of Versatile Video Coding (VVC), the quadtree with\nnested multi-type tree (QT+MTT) block structure yields significant coding gains\nby providing more flexible block partitioning patterns. However, the recursive\npartition search in the VVC encoder increases the encoder complexity\nsubstantially. To address this issue, we propose a partition map-based\nalgorithm to pursue fast block partitioning in inter coding. Based on our\nprevious work on partition map-based methods for intra coding, we analyze the\ncharacteristics of VVC inter coding, and thus improve the partition map by\nincorporating an MTT mask for early termination. Next, we develop a neural\nnetwork that uses both spatial and temporal features to predict the partition\nmap. It consists of several special designs including stacked top-down and\nbottom-up processing, quantization parameter modulation layers, and\npartitioning-adaptive warping. Furthermore, we present a dual-threshold\ndecision scheme to achieve a fine-grained trade-off between complexity\nreduction and rate-distortion (RD) performance loss. The experimental results\ndemonstrate that the proposed method achieves an average 51.30% encoding time\nsaving with a 2.12% Bjontegaard Delta Bit Rate (BDBR) under the random access\nconfiguration.", "comment": "23 pages, 26 figures. Project page: https://github.com/ustcivclab/IPM", "pdf_url": "http://arxiv.org/pdf/2504.18398v2", "cate": "eess.IV", "date": "2025-04-25", "updated": "2025-07-15"}
{"id": "2507.10743", "title": "Language Models for Adult Service Website Text Analysis", "authors": ["Nickolas Freeman", "Thanh Nguyen", "Gregory Bott", "Jason Parton", "Collin Francel"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      32 pages, 12 figures, 1 table", "url": "http://arxiv.org/abs/2507.10743v1", "summary": "Sex trafficking refers to the use of force, fraud, or coercion to compel an\nindividual to perform in commercial sex acts against their will. Adult service\nwebsites (ASWs) have and continue to be linked to sex trafficking, offering a\nplatform for traffickers to advertise their victims. Thus, organizations\ninvolved in the fight against sex trafficking often use ASW data when\nattempting to identify potential sex trafficking victims. A critical challenge\nin transforming ASW data into actionable insight is text analysis. Previous\nresearch using ASW data has shown that ASW ad text is important for linking\nads. However, working with this text is challenging due to its extensive use of\nemojis, poor grammar, and deliberate obfuscation to evade law enforcement\nscrutiny. We conduct a comprehensive study of language modeling approaches for\nthis application area, including simple information retrieval methods,\npre-trained transformers, and custom transformer models. We demonstrate that\ncharacteristics of ASW text data allow efficient custom transformer models to\nbe trained with relatively small GPU resources and used efficiently for\ninference on consumer hardware. Our custom models outperform fine-tuned\nvariants of well-known encoder-only transformer models, including BERT-base,\nRoBERTa, and ModernBERT, on accuracy, recall, F1 score, and ROC AUC. We\ndemonstrate the use of our best-performing custom configuration on three tasks\nrelated to ASW data analysis: (i) decomposing the giant component in a graph\nrepresentation of ASW data, (ii) clustering ASW ad text, and (iii) using the\nlearned token embeddings to understand the use of emojis in the illicit context\nwe study. The models we develop represent a significant advancement in ASW text\nanalysis, which can be leveraged in a variety of downstream applications and\nresearch.", "comment": "32 pages, 12 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.10743v1", "cate": "cs.CL", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10833", "title": "Solving Random Planted CSPs below the $n^{k/2}$ Threshold", "authors": ["Arpon Basu", "Jun-Ting Hsieh", "Andrew D. Lin", "Peter Manohar"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10833v1", "summary": "We present a family of algorithms to solve random planted instances of any\n$k$-ary Boolean constraint satisfaction problem (CSP). A randomly planted\ninstance of a Boolean CSP is generated by (1) choosing an arbitrary planted\nassignment $x^*$, and then (2) sampling constraints from a particular \"planting\ndistribution\" designed so that $x^*$ will satisfy every constraint. Given an\n$n$ variable instance of a $k$-ary Boolean CSP with $m$ constraints, our\nalgorithm runs in time $n^{O(\\ell)}$ for a choice of a parameter $\\ell$, and\nsucceeds in outputting a satisfying assignment if $m \\geq O(n) \\cdot\n(n/\\ell)^{\\frac{k}{2} - 1} \\log n$. This generalizes the\n$\\mathrm{poly}(n)$-time algorithm of [FPV15], the case of $\\ell = O(1)$, to\nlarger runtimes, and matches the constraint number vs.\\ runtime trade-off\nestablished for refuting random CSPs by [RRS17].\n  Our algorithm is conceptually different from the recent algorithm of\n[GHKM23], which gave a $\\mathrm{poly}(n)$-time algorithm to solve semirandom\nCSPs with $m \\geq \\tilde{O}(n^{\\frac{k}{2}})$ constraints by exploiting\nconditions that allow a basic SDP to recover the planted assignment $x^*$\nexactly. Instead, we forego certificates of uniqueness and recover $x^*$ in two\nsteps: we first use a degree-$O(\\ell)$ Sum-of-Squares SDP to find some\n$\\hat{x}$ that is $o(1)$-close to $x^*$, and then we use a second rounding\nprocedure to recover $x^*$ from $\\hat{x}$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10833v1", "cate": "cs.DS", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11096", "title": "EditGen: Harnessing Cross-Attention Control for Instruction-Based Auto-Regressive Audio Editing", "authors": ["Vassilis Sioros", "Alexandros Potamianos", "Giorgos Paraskevopoulos"], "categories": ["cs.SD", "cs.AI"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11096v1", "summary": "In this study, we investigate leveraging cross-attention control for\nefficient audio editing within auto-regressive models. Inspired by image\nediting methodologies, we develop a Prompt-to-Prompt-like approach that guides\nedits through cross and self-attention mechanisms. Integrating a\ndiffusion-based strategy, influenced by Auffusion, we extend the model's\nfunctionality to support refinement edits, establishing a baseline for\nprompt-guided audio editing. Additionally, we introduce an alternative approach\nby incorporating MUSICGEN, a pre-trained frozen auto-regressive model, and\npropose three editing mechanisms, based on Replacement, Reweighting, and\nRefinement of the attention scores. We employ commonly-used music-specific\nevaluation metrics and a human study, to gauge time-varying controllability,\nadherence to global text cues, and overall audio realism. The automatic and\nhuman evaluations indicate that the proposed combination of prompt-to-prompt\nguidance with autoregressive generation models significantly outperforms the\ndiffusion-based baseline in terms of melody, dynamics, and tempo of the\ngenerated audio. Our code is available at https://github.com/billsioros/EditGen", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11096v1", "cate": "cs.SD", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11173", "title": "Real-Time Bayesian Detection of Drift-Evasive GNSS Spoofing in Reinforcement Learning Based UAV Deconfliction", "authors": ["Deepak Kumar Panda", "Weisi Guo"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11173v1", "summary": "Autonomous unmanned aerial vehicles (UAVs) rely on global navigation\nsatellite system (GNSS) pseudorange measurements for accurate real-time\nlocalization and navigation. However, this dependence exposes them to\nsophisticated spoofing threats, where adversaries manipulate pseudoranges to\ndeceive UAV receivers. Among these, drift-evasive spoofing attacks subtly\nperturb measurements, gradually diverting the UAVs trajectory without\ntriggering conventional signal-level anti-spoofing mechanisms. Traditional\ndistributional shift detection techniques often require accumulating a\nthreshold number of samples, causing delays that impede rapid detection and\ntimely response. Consequently, robust temporal-scale detection methods are\nessential to identify attack onset and enable contingency planning with\nalternative sensing modalities, improving resilience against stealthy\nadversarial manipulations. This study explores a Bayesian online change point\ndetection (BOCPD) approach that monitors temporal shifts in value estimates\nfrom a reinforcement learning (RL) critic network to detect subtle behavioural\ndeviations in UAV navigation. Experimental results show that this temporal\nvalue-based framework outperforms conventional GNSS spoofing detectors,\ntemporal semi-supervised learning frameworks, and the Page-Hinkley test,\nachieving higher detection accuracy and lower false-positive and false-negative\nrates for drift-evasive spoofing attacks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11173v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11267", "title": "YOLOatr : Deep Learning Based Automatic Target Detection and Localization in Thermal Infrared Imagery", "authors": ["Aon Safdar", "Usman Akram", "Waseem Anwar", "Basit Malik", "Mian Ibad Ali"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Published in 25th Irish Machine Vision and Image Processing Conf., Galway, Ireland, Aug 30-Sep 1 2023 Also available at this https URL", "url": "http://arxiv.org/abs/2507.11267v1", "summary": "Automatic Target Detection (ATD) and Recognition (ATR) from Thermal Infrared\n(TI) imagery in the defense and surveillance domain is a challenging computer\nvision (CV) task in comparison to the commercial autonomous vehicle perception\ndomain. Limited datasets, peculiar domain-specific and TI modality-specific\nchallenges, i.e., limited hardware, scale invariance issues due to greater\ndistances, deliberate occlusion by tactical vehicles, lower sensor resolution\nand resultant lack of structural information in targets, effects of weather,\ntemperature, and time of day variations, and varying target to clutter ratios\nall result in increased intra-class variability and higher inter-class\nsimilarity, making accurate real-time ATR a challenging CV task. Resultantly,\ncontemporary state-of-the-art (SOTA) deep learning architectures underperform\nin the ATR domain. We propose a modified anchor-based single-stage detector,\ncalled YOLOatr, based on a modified YOLOv5s, with optimal modifications to the\ndetection heads, feature fusion in the neck, and a custom augmentation profile.\nWe evaluate the performance of our proposed model on a comprehensive DSIAC MWIR\ndataset for real-time ATR over both correlated and decorrelated testing\nprotocols. The results demonstrate that our proposed model achieves\nstate-of-the-art ATR performance of up to 99.6%.", "comment": "Published in 25th Irish Machine Vision and Image Processing Conf.,\n  Galway, Ireland, Aug 30-Sep 1 2023 Also available at\n  https://doi.org/10.5281/zenodo.8264062", "pdf_url": "http://arxiv.org/pdf/2507.11267v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2506.03217", "title": "petBrain: A New Pipeline for Amyloid, Tau Tangles and Neurodegeneration Quantification Using PET and MRI", "authors": ["Pierrick Coupé", "Boris Mansencal", "Floréal Morandat", "Sergio Morell-Ortega", "Nicolas Villain", "Jose V. Manjón", "Vincent Planche"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.03217v2", "summary": "INTRODUCTION: Quantification of amyloid plaques (A), neurofibrillary tangles\n(T2), and neurodegeneration (N) using PET and MRI is critical for Alzheimer's\ndisease (AD) diagnosis and prognosis. Existing pipelines face limitations\nregarding processing time, variability in tracer types, and challenges in\nmultimodal integration.\n  METHODS: We developed petBrain, a novel end-to-end processing pipeline for\namyloid-PET, tau-PET, and structural MRI. It leverages deep learning-based\nsegmentation, standardized biomarker quantification (Centiloid, CenTauR,\nHAVAs), and simultaneous estimation of A, T2, and N biomarkers. The pipeline is\nimplemented as a web-based platform, requiring no local computational\ninfrastructure or specialized software knowledge.\n  RESULTS: petBrain provides reliable and rapid biomarker quantification, with\nresults comparable to existing pipelines for A and T2. It shows strong\nconcordance with data processed in ADNI databases. The staging and\nquantification of A/T2/N by petBrain demonstrated good agreement with\nCSF/plasma biomarkers, clinical status, and cognitive performance.\n  DISCUSSION: petBrain represents a powerful and openly accessible platform for\nstandardized AD biomarker analysis, facilitating applications in clinical\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.03217v2", "cate": "eess.IV", "date": "2025-06-03", "updated": "2025-07-15"}
{"id": "2507.10772", "title": "Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs", "authors": ["Michal Podstawski"], "categories": ["cs.CL", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10772v1", "summary": "Labeled property graphs often contain rich textual attributes that can\nenhance analytical tasks when properly leveraged. This work explores the use of\npretrained text embedding models to enable efficient semantic analysis in such\ngraphs. By embedding textual node and edge properties, we support downstream\ntasks including node classification and relation prediction with improved\ncontextual understanding. Our approach integrates language model embeddings\ninto the graph pipeline without altering its structure, demonstrating that\ntextual semantics can significantly enhance the accuracy and interpretability\nof property graph analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10772v1", "cate": "cs.CL", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.10946", "title": "Solving Linear Programs with Differential Privacy", "authors": ["Alina Ene", "Huy Le Nguyen", "Ta Duy Nguyen", "Adrian Vladu"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10946v1", "summary": "We study the problem of solving linear programs of the form $Ax\\le b$,\n$x\\ge0$ with differential privacy. For homogeneous LPs $Ax\\ge0$, we give an\nefficient $(\\epsilon,\\delta)$-differentially private algorithm which with\nprobability at least $1-\\beta$ finds in polynomial time a solution that\nsatisfies all but\n$O(\\frac{d^{2}}{\\epsilon}\\log^{2}\\frac{d}{\\delta\\beta}\\sqrt{\\log\\frac{1}{\\rho_{0}}})$\nconstraints, for problems with margin $\\rho_{0}>0$. This improves the bound of\n$O(\\frac{d^{5}}{\\epsilon}\\log^{1.5}\\frac{1}{\\rho_{0}}\\mathrm{poly}\\log(d,\\frac{1}{\\delta},\\frac{1}{\\beta}))$\nby [Kaplan-Mansour-Moran-Stemmer-Tur, STOC '25]. For general LPs $Ax\\le b$,\n$x\\ge0$ with potentially zero margin, we give an efficient\n$(\\epsilon,\\delta)$-differentially private algorithm that w.h.p drops\n$O(\\frac{d^{4}}{\\epsilon}\\log^{2.5}\\frac{d}{\\delta}\\sqrt{\\log dU})$\nconstraints, where $U$ is an upper bound for the entries of $A$ and $b$ in\nabsolute value. This improves the result by Kaplan et al. by at least a factor\nof $d^{5}$. Our techniques build upon privatizing a rescaling perceptron\nalgorithm by [Hoberg-Rothvoss, IPCO '17] and a more refined iterative procedure\nfor identifying equality constraints by Kaplan et al.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10946v1", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10924", "title": "OffsetCrust: Variable-Radius Offset Approximation with Power Diagrams", "authors": ["Zihan Zhao", "Pengfei Wang", "Minfeng Xu", "Shuangmin Chen", "Shiqing Xin", "Changhe Tu", "Wenping Wang"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10924v1", "summary": "Offset surfaces, defined as the Minkowski sum of a base surface and a rolling\nball, play a crucial role in geometry processing, with applications ranging\nfrom coverage motion planning to brush modeling. While considerable progress\nhas been made in computing constant-radius offset surfaces, computing\nvariable-radius offset surfaces remains a challenging problem. In this paper,\nwe present OffsetCrust, a novel framework that efficiently addresses the\nvariable-radius offsetting problem by computing a power diagram. Let $R$ denote\nthe radius function defined on the base surface $S$. The power diagram is\nconstructed from contributing sites, consisting of carefully sampled base\npoints on $S$ and their corresponding off-surface points, displaced along\n$R$-dependent directions. In the constant-radius case only, these displacement\ndirections align exactly with the surface normals of $S$. Moreover, our method\nmitigates the misalignment issues commonly seen in crust-based approaches\nthrough a lightweight fine-tuning procedure. We validate the accuracy and\nefficiency of OffsetCrust through extensive experiments, and demonstrate its\npractical utility in applications such as reconstructing original boundary\nsurfaces from medial axis transform (MAT) representations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10924v1", "cate": "cs.GR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11178", "title": "Gradient Regularization-based Neural Granger Causality", "authors": ["Meiliang Liu", "Huiwen Dong", "Xiaoxiao Yang", "Yunfang Xu", "Zijin Li", "Zhengye Si", "Xinyue Yang", "Zhiwen Zhao"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages,3 figures, conference", "url": "http://arxiv.org/abs/2507.11178v1", "summary": "With the advancement of deep learning technologies, various neural\nnetwork-based Granger causality models have been proposed. Although these\nmodels have demonstrated notable improvements, several limitations remain. Most\nexisting approaches adopt the component-wise architecture, necessitating the\nconstruction of a separate model for each time series, which results in\nsubstantial computational costs. In addition, imposing the sparsity-inducing\npenalty on the first-layer weights of the neural network to extract causal\nrelationships weakens the model's ability to capture complex interactions. To\naddress these limitations, we propose Gradient Regularization-based Neural\nGranger Causality (GRNGC), which requires only one time series prediction model\nand applies $L_{1}$ regularization to the gradient between model's input and\noutput to infer Granger causality. Moreover, GRNGC is not tied to a specific\ntime series forecasting model and can be implemented with diverse architectures\nsuch as KAN, MLP, and LSTM, offering enhanced flexibility. Numerical\nsimulations on DREAM, Lorenz-96, fMRI BOLD, and CausalTime show that GRNGC\noutperforms existing baselines and significantly reduces computational\noverhead. Meanwhile, experiments on real-world DNA, Yeast, HeLa, and bladder\nurothelial carcinoma datasets further validate the model's effectiveness in\nreconstructing gene regulatory networks.", "comment": "9 pages,3 figures, conference", "pdf_url": "http://arxiv.org/pdf/2507.11178v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11181", "title": "Mixture of Experts in Large Language Models", "authors": ["Danyang Zhang", "Junhao Song", "Ziqian Bi", "Yingfang Yuan", "Tianyang Wang", "Joe Yeong", "Junfeng Hao"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11181v1", "summary": "This paper presents a comprehensive review of the Mixture-of-Experts (MoE)\narchitecture in large language models, highlighting its ability to\nsignificantly enhance model performance while maintaining minimal computational\noverhead. Through a systematic analysis spanning theoretical foundations, core\narchitectural designs, and large language model (LLM) applications, we examine\nexpert gating and routing mechanisms, hierarchical and sparse MoE\nconfigurations, meta-learning approaches, multimodal and multitask learning\nscenarios, real-world deployment cases, and recent advances and challenges in\ndeep learning. Our analysis identifies key advantages of MoE, including\nsuperior model capacity compared to equivalent Bayesian approaches, improved\ntask-specific performance, and the ability to scale model capacity efficiently.\nWe also underscore the importance of ensuring expert diversity, accurate\ncalibration, and reliable inference aggregation, as these are essential for\nmaximizing the effectiveness of MoE architectures. Finally, this review\noutlines current research limitations, open challenges, and promising future\ndirections, providing a foundation for continued innovation in MoE architecture\nand its applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11181v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11279", "title": "Tomato Multi-Angle Multi-Pose Dataset for Fine-Grained Phenotyping", "authors": ["Yujie Zhang", "Sabine Struckmeyer", "Andreas Kolb", "Sven Reichardt"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11279v1", "summary": "Observer bias and inconsistencies in traditional plant phenotyping methods\nlimit the accuracy and reproducibility of fine-grained plant analysis. To\novercome these challenges, we developed TomatoMAP, a comprehensive dataset for\nSolanum lycopersicum using an Internet of Things (IoT) based imaging system\nwith standardized data acquisition protocols. Our dataset contains 64,464 RGB\nimages that capture 12 different plant poses from four camera elevation angles.\nEach image includes manually annotated bounding boxes for seven regions of\ninterest (ROIs), including leaves, panicle, batch of flowers, batch of fruits,\naxillary shoot, shoot and whole plant area, along with 50 fine-grained growth\nstage classifications based on the BBCH scale. Additionally, we provide 3,616\nhigh-resolution image subset with pixel-wise semantic and instance segmentation\nannotations for fine-grained phenotyping. We validated our dataset using a\ncascading model deep learning framework combining MobileNetv3 for\nclassification, YOLOv11 for object detection, and MaskRCNN for segmentation.\nThrough AI vs. Human analysis involving five domain experts, we demonstrate\nthat the models trained on our dataset achieve accuracy and speed comparable to\nthe experts. Cohen's Kappa and inter-rater agreement heatmap confirm the\nreliability of automated fine-grained phenotyping using our approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11279v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.09923", "title": "IM-LUT: Interpolation Mixing Look-Up Tables for Image Super-Resolution", "authors": ["Sejin Park", "Sangmin Lee", "Kyong Hwan Jin", "Seung-Won Jung"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.09923v2", "summary": "Super-resolution (SR) has been a pivotal task in image processing, aimed at\nenhancing image resolution across various applications. Recently, look-up table\n(LUT)-based approaches have attracted interest due to their efficiency and\nperformance. However, these methods are typically designed for fixed scale\nfactors, making them unsuitable for arbitrary-scale image SR (ASISR). Existing\nASISR techniques often employ implicit neural representations, which come with\nconsiderable computational cost and memory demands. To address these\nlimitations, we propose Interpolation Mixing LUT (IM-LUT), a novel framework\nthat operates ASISR by learning to blend multiple interpolation functions to\nmaximize their representational capacity. Specifically, we introduce IM-Net, a\nnetwork trained to predict mixing weights for interpolation functions based on\nlocal image patterns and the target scale factor. To enhance efficiency of\ninterpolation-based methods, IM-Net is transformed into IM-LUT, where LUTs are\nemployed to replace computationally expensive operations, enabling lightweight\nand fast inference on CPUs while preserving reconstruction quality.\nExperimental results on several benchmark datasets demonstrate that IM-LUT\nconsistently achieves a superior balance between image quality and efficiency\ncompared to existing methods, highlighting its potential as a promising\nsolution for resource-constrained applications.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.09923v2", "cate": "eess.IV", "date": "2025-07-14", "updated": "2025-07-15"}
{"id": "2507.10787", "title": "Can Multimodal Foundation Models Understand Schematic Diagrams? An Empirical Study on Information-Seeking QA over Scientific Papers", "authors": ["Yilun Zhao", "Chengye Wang", "Chuhan Li", "Arman Cohan"], "categories": ["cs.CL", "cs.CV"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025 Findings", "url": "http://arxiv.org/abs/2507.10787v1", "summary": "This paper introduces MISS-QA, the first benchmark specifically designed to\nevaluate the ability of models to interpret schematic diagrams within\nscientific literature. MISS-QA comprises 1,500 expert-annotated examples over\n465 scientific papers. In this benchmark, models are tasked with interpreting\nschematic diagrams that illustrate research overviews and answering\ncorresponding information-seeking questions based on the broader context of the\npaper. We assess the performance of 18 frontier multimodal foundation models,\nincluding o4-mini, Gemini-2.5-Flash, and Qwen2.5-VL. We reveal a significant\nperformance gap between these models and human experts on MISS-QA. Our analysis\nof model performance on unanswerable questions and our detailed error analysis\nfurther highlight the strengths and limitations of current models, offering key\ninsights to enhance models in comprehending multimodal scientific literature.", "comment": "ACL 2025 Findings", "pdf_url": "http://arxiv.org/pdf/2507.10787v1", "cate": "cs.CL", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11080", "title": "FPT Parameterisations of Fractional and Generalised Hypertree Width", "authors": ["Matthias Lanzinger", "Igor Razgon", "Daniel Unterberger"], "categories": ["cs.DS", "cs.CC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11080v1", "summary": "We present the first fixed-parameter tractable (fpt) algorithms for precisely\ndetermining several central hypergraph decomposition parameters, including\ngeneralized hypertree width, fractional hypertree width, and adaptive width.\nDespite the recognized importance of these measures in complexity theory,\ndatabases, and constraint satisfaction, no exact fpt algorithms for any of them\nhad previously been known. Our results are obtained for hypergraph classes of\nbounded rank and bounded degree.\n  Our approach extends a recent algorithm for treewidth (Boja\\'ncyk &\nPilipczuk, LMCS 2022) utilizing monadic second-order (MSO) transductions.\nLeveraging this framework, we overcome the significant technical hurdles\npresented by hypergraphs, whose structural decompositions are technically much\nmore intricate than their graph counterparts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11080v1", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11465", "title": "Elevating 3D Models: High-Quality Texture and Geometry Refinement from a Low-Quality Model", "authors": ["Nuri Ryu", "Jiyun Won", "Jooeun Son", "Minsu Gong", "Joo-Haeng Lee", "Sunghyun Cho"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      Accepted to SIGGRAPH 2025. For the project page, see this https URL", "url": "http://arxiv.org/abs/2507.11465v1", "summary": "High-quality 3D assets are essential for various applications in computer\ngraphics and 3D vision but remain scarce due to significant acquisition costs.\nTo address this shortage, we introduce Elevate3D, a novel framework that\ntransforms readily accessible low-quality 3D assets into higher quality. At the\ncore of Elevate3D is HFS-SDEdit, a specialized texture enhancement method that\nsignificantly improves texture quality while preserving the appearance and\ngeometry while fixing its degradations. Furthermore, Elevate3D operates in a\nview-by-view manner, alternating between texture and geometry refinement.\nUnlike previous methods that have largely overlooked geometry refinement, our\nframework leverages geometric cues from images refined with HFS-SDEdit by\nemploying state-of-the-art monocular geometry predictors. This approach ensures\ndetailed and accurate geometry that aligns seamlessly with the enhanced\ntexture. Elevate3D outperforms recent competitors by achieving state-of-the-art\nquality in 3D model refinement, effectively addressing the scarcity of\nhigh-quality open-source 3D assets.", "comment": "Accepted to SIGGRAPH 2025. For the project page, see\n  https://cg.postech.ac.kr/research/Elevate3D/", "pdf_url": "http://arxiv.org/pdf/2507.11465v1", "cate": "cs.GR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11185", "title": "An Explainable AI-Enhanced Machine Learning Approach for Cardiovascular Disease Detection and Risk Assessment", "authors": ["Md. Emon Akter Sourov", "Md. Sabbir Hossen", "Pabon Shaha", "Mohammad Minoar Hossain", "Md Sadiq Iqbal"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This paper has been accepted at the IEEE QPAIN 2025. The final version will be available in the IEEE Xplore Digital Library", "url": "http://arxiv.org/abs/2507.11185v1", "summary": "Heart disease remains a major global health concern, particularly in regions\nwith limited access to medical resources and diagnostic facilities. Traditional\ndiagnostic methods often fail to accurately identify and manage heart disease\nrisks, leading to adverse outcomes. Machine learning has the potential to\nsignificantly enhance the accuracy, efficiency, and speed of heart disease\ndiagnosis. In this study, we proposed a comprehensive framework that combines\nclassification models for heart disease detection and regression models for\nrisk prediction. We employed the Heart Disease dataset, which comprises 1,035\ncases. To address the issue of class imbalance, the Synthetic Minority\nOversampling Technique (SMOTE) was applied, resulting in the generation of an\nadditional 100,000 synthetic data points. Performance metrics, including\naccuracy, precision, recall, F1-score, R2, MSE, RMSE, and MAE, were used to\nevaluate the model's effectiveness. Among the classification models, Random\nForest emerged as the standout performer, achieving an accuracy of 97.2% on\nreal data and 97.6% on synthetic data. For regression tasks, Linear Regression\ndemonstrated the highest R2 values of 0.992 and 0.984 on real and synthetic\ndatasets, respectively, with the lowest error metrics. Additionally,\nExplainable AI techniques were employed to enhance the interpretability of the\nmodels. This study highlights the potential of machine learning to\nrevolutionize heart disease diagnosis and risk prediction, thereby facilitating\nearly intervention and enhancing clinical decision-making.", "comment": "This paper has been accepted at the IEEE QPAIN 2025. The final\n  version will be available in the IEEE Xplore Digital Library", "pdf_url": "http://arxiv.org/pdf/2507.11185v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11183", "title": "Quantized Rank Reduction: A Communications-Efficient Federated Learning Scheme for Network-Critical Applications", "authors": ["Dimitrios Kritsiolis", "Constantine Kotropoulos"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      In Proceedings of the 2025 IARIA Annual Congress on Frontiers in Science, Technology, Services, and Applications (IARIA Congress 2025), Venice, Italy, July 6-10, 2025", "url": "http://arxiv.org/abs/2507.11183v1", "summary": "Federated learning is a machine learning approach that enables multiple\ndevices (i.e., agents) to train a shared model cooperatively without exchanging\nraw data. This technique keeps data localized on user devices, ensuring privacy\nand security, while each agent trains the model on their own data and only\nshares model updates. The communication overhead is a significant challenge due\nto the frequent exchange of model updates between the agents and the central\nserver. In this paper, we propose a communication-efficient federated learning\nscheme that utilizes low-rank approximation of neural network gradients and\nquantization to significantly reduce the network load of the decentralized\nlearning process with minimal impact on the model's accuracy.", "comment": "In Proceedings of the 2025 IARIA Annual Congress on Frontiers in\n  Science, Technology, Services, and Applications (IARIA Congress 2025),\n  Venice, Italy, July 6-10, 2025", "pdf_url": "http://arxiv.org/pdf/2507.11183v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11293", "title": "3D Magnetic Inverse Routine for Single-Segment Magnetic Field Images", "authors": ["J. Senthilnath", "Chen Hao", "F. C. Wellstood"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      copyright 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works", "url": "http://arxiv.org/abs/2507.11293v1", "summary": "In semiconductor packaging, accurately recovering 3D information is crucial\nfor non-destructive testing (NDT) to localize circuit defects. This paper\npresents a novel approach called the 3D Magnetic Inverse Routine (3D MIR),\nwhich leverages Magnetic Field Images (MFI) to retrieve the parameters for the\n3D current flow of a single-segment. The 3D MIR integrates a deep learning\n(DL)-based Convolutional Neural Network (CNN), spatial-physics-based\nconstraints, and optimization techniques. The method operates in three stages:\ni) The CNN model processes the MFI data to predict ($\\ell/z_o$), where $\\ell$\nis the wire length and $z_o$ is the wire's vertical depth beneath the magnetic\nsensors and classify segment type ($c$). ii) By leveraging\nspatial-physics-based constraints, the routine provides initial estimates for\nthe position ($x_o$, $y_o$, $z_o$), length ($\\ell$), current ($I$), and current\nflow direction (positive or negative) of the current segment. iii) An optimizer\nthen adjusts these five parameters ($x_o$, $y_o$, $z_o$, $\\ell$, $I$) to\nminimize the difference between the reconstructed MFI and the actual MFI. The\nresults demonstrate that the 3D MIR method accurately recovers 3D information\nwith high precision, setting a new benchmark for magnetic image reconstruction\nin semiconductor packaging. This method highlights the potential of combining\nDL and physics-driven optimization in practical applications.", "comment": "copyright 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "pdf_url": "http://arxiv.org/pdf/2507.11293v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.09995", "title": "Graph-based Multi-Modal Interaction Lightweight Network for Brain Tumor Segmentation (GMLN-BTS) in Edge Iterative MRI Lesion Localization System (EdgeIMLocSys)", "authors": ["Guohao Huo", "Ruiting Dai", "Hao Tang"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09995v2", "summary": "Brain tumor segmentation plays a critical role in clinical diagnosis and\ntreatment planning, yet the variability in imaging quality across different MRI\nscanners presents significant challenges to model generalization. To address\nthis, we propose the Edge Iterative MRI Lesion Localization System\n(EdgeIMLocSys), which integrates Continuous Learning from Human Feedback to\nadaptively fine-tune segmentation models based on clinician feedback, thereby\nenhancing robustness to scanner-specific imaging characteristics. Central to\nthis system is the Graph-based Multi-Modal Interaction Lightweight Network for\nBrain Tumor Segmentation (GMLN-BTS), which employs a Modality-Aware Adaptive\nEncoder (M2AE) to extract multi-scale semantic features efficiently, and a\nGraph-based Multi-Modal Collaborative Interaction Module (G2MCIM) to model\ncomplementary cross-modal relationships via graph structures. Additionally, we\nintroduce a novel Voxel Refinement UpSampling Module (VRUM) that\nsynergistically combines linear interpolation and multi-scale transposed\nconvolutions to suppress artifacts while preserving high-frequency details,\nimproving segmentation boundary accuracy. Our proposed GMLN-BTS model achieves\na Dice score of 85.1% on the BraTS2017 dataset with only 4.58 million\nparameters, representing a 98% reduction compared to mainstream 3D Transformer\nmodels, and significantly outperforms existing lightweight approaches. This\nwork demonstrates a synergistic breakthrough in achieving high-accuracy,\nresource-efficient brain tumor segmentation suitable for deployment in\nresource-constrained clinical environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09995v2", "cate": "eess.IV", "date": "2025-07-14", "updated": "2025-07-15"}
{"id": "2507.10852", "title": "LLMs on Trial: Evaluating Judicial Fairness for Large Language Models", "authors": ["Yiran Hu", "Zongyue Xue", "Haitao Li", "Siyuan Zheng", "Qingjing Chen", "Shaochun Wang", "Xihan Zhang", "Ning Zheng", "Yun Liu", "Qingyao Ai", "Yiqun Liu", "Charles L. A. Clarke", "Weixing Shen"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10852v1", "summary": "Large Language Models (LLMs) are increasingly used in high-stakes fields\nwhere their decisions impact rights and equity. However, LLMs' judicial\nfairness and implications for social justice remain underexplored. When LLMs\nact as judges, the ability to fairly resolve judicial issues is a prerequisite\nto ensure their trustworthiness. Based on theories of judicial fairness, we\nconstruct a comprehensive framework to measure LLM fairness, leading to a\nselection of 65 labels and 161 corresponding values. Applying this framework to\nthe judicial system, we compile an extensive dataset, JudiFair, comprising\n177,100 unique case facts. To achieve robust statistical inference, we develop\nthree evaluation metrics, inconsistency, bias, and imbalanced inaccuracy, and\nintroduce a method to assess the overall fairness of multiple LLMs across\nvarious labels. Through experiments with 16 LLMs, we uncover pervasive\ninconsistency, bias, and imbalanced inaccuracy across models, underscoring\nsevere LLM judicial unfairness. Particularly, LLMs display notably more\npronounced biases on demographic labels, with slightly less bias on substance\nlabels compared to procedure ones. Interestingly, increased inconsistency\ncorrelates with reduced biases, but more accurate predictions exacerbate\nbiases. While we find that adjusting the temperature parameter can influence\nLLM fairness, model size, release date, and country of origin do not exhibit\nsignificant effects on judicial fairness. Accordingly, we introduce a publicly\navailable toolkit containing all datasets and code, designed to support future\nresearch in evaluating and improving LLM fairness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10852v1", "cate": "cs.CL", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11098", "title": "Faster algorithms for k-Orthogonal Vectors in low dimension", "authors": ["Anita Dürr", "Evangelos Kipouridis", "Karol Węgrzycki"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11098v1", "summary": "In the Orthogonal Vectors problem (OV), we are given two families $A, B$ of\nsubsets of $\\{1,\\ldots,d\\}$, each of size $n$, and the task is to decide\nwhether there exists a pair $a \\in A$ and $b \\in B$ such that $a \\cap b =\n\\emptyset$. Straightforward algorithms for this problem run in $\\mathcal{O}(n^2\n\\cdot d)$ or $\\mathcal{O}(2^d \\cdot n)$ time, and assuming SETH, there is no\n$2^{o(d)}\\cdot n^{2-\\varepsilon}$ time algorithm that solves this problem for\nany constant $\\varepsilon > 0$.\n  Williams (FOCS 2024) presented a $\\tilde{\\mathcal{O}}(1.35^d \\cdot n)$-time\nalgorithm for the problem, based on the succinct equality-rank decomposition of\nthe disjointness matrix. In this paper, we present a combinatorial algorithm\nthat runs in randomized time $\\tilde{\\mathcal{O}}(1.25^d n)$. This can be\nimproved to $\\mathcal{O}(1.16^d \\cdot n)$ using computer-aided evaluations.\n  We generalize our result to the $k$-Orthogonal Vectors problem, where given\n$k$ families $A_1,\\ldots,A_k$ of subsets of $\\{1,\\ldots,d\\}$, each of size $n$,\nthe task is to find elements $a_i \\in A_i$ for every $i \\in \\{1,\\ldots,k\\}$\nsuch that $a_1 \\cap a_2 \\cap \\ldots \\cap a_k = \\emptyset$. We show that for\nevery fixed $k \\ge 2$, there exists $\\varepsilon_k > 0$ such that the $k$-OV\nproblem can be solved in time $\\mathcal{O}(2^{(1 - \\varepsilon_k)\\cdot d}\\cdot\nn)$. We also show that, asymptotically, this is the best we can hope for: for\nany $\\varepsilon > 0$ there exists a $k \\ge 2$ such that $2^{(1 -\n\\varepsilon)\\cdot d} \\cdot n^{\\mathcal{O}(1)}$ time algorithm for\n$k$-Orthogonal Vectors would contradict the Set Cover Conjecture.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11098v1", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2411.10061", "title": "EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation", "authors": ["Rang Meng", "Xingyu Zhang", "Yuming Li", "Chenguang Ma"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      CVPR2025", "url": "http://arxiv.org/abs/2411.10061v3", "summary": "Recent work on human animation usually involves audio, pose, or movement maps\nconditions, thereby achieves vivid animation quality. However, these methods\noften face practical challenges due to extra control conditions, cumbersome\ncondition injection modules, or limitation to head region driving. Hence, we\nask if it is possible to achieve striking half-body human animation while\nsimplifying unnecessary conditions. To this end, we propose a half-body human\nanimation method, dubbed EchoMimicV2, that leverages a novel Audio-Pose Dynamic\nHarmonization strategy, including Pose Sampling and Audio Diffusion, to enhance\nhalf-body details, facial and gestural expressiveness, and meanwhile reduce\nconditions redundancy. To compensate for the scarcity of half-body data, we\nutilize Head Partial Attention to seamlessly accommodate headshot data into our\ntraining framework, which can be omitted during inference, providing a free\nlunch for animation. Furthermore, we design the Phase-specific Denoising Loss\nto guide motion, detail, and low-level quality for animation in specific\nphases, respectively. Besides, we also present a novel benchmark for evaluating\nthe effectiveness of half-body human animation. Extensive experiments and\nanalyses demonstrate that EchoMimicV2 surpasses existing methods in both\nquantitative and qualitative evaluations.", "comment": "CVPR2025", "pdf_url": "http://arxiv.org/pdf/2411.10061v3", "cate": "cs.GR", "date": "2024-11-15", "updated": "2025-07-15"}
{"id": "2507.11198", "title": "Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding", "authors": ["Conrad Borchers", "Bahar Shahrokhian", "Francesco Balzan", "Elham Tajik", "Sreecharan Sankaranarayanan", "Sebastian Simon"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Manuscript submitted for review", "url": "http://arxiv.org/abs/2507.11198v1", "summary": "Large Language Models (LLMs) enable new possibilities for qualitative\nresearch at scale, including coding and data annotation. While multi-agent\nsystems (MAS) can emulate human coding workflows, their benefits over\nsingle-agent coding remain poorly understood. We conducted an experimental\nstudy of how agent persona and temperature shape consensus-building and coding\naccuracy of dialog segments based on a codebook with 8 codes. Our open-source\nMAS mirrors deductive human coding through structured agent discussion and\nconsensus arbitration. Using six open-source LLMs (with 3 to 32 billion\nparameters) and 18 experimental configurations, we analyze over 77,000 coding\ndecisions against a gold-standard dataset of human-annotated transcripts from\nonline math tutoring sessions. Temperature significantly impacted whether and\nwhen consensus was reached across all six LLMs. MAS with multiple personas\n(including neutral, assertive, or empathetic), significantly delayed consensus\nin four out of six LLMs compared to uniform personas. In three of those LLMs,\nhigher temperatures significantly diminished the effects of multiple personas\non consensus. However, neither temperature nor persona pairing lead to robust\nimprovements in coding accuracy. Single agents matched or outperformed MAS\nconsensus in most conditions. Only one model (OpenHermesV2:7B) and code\ncategory showed above-chance gains from MAS deliberation when temperature was\n0.5 or lower and especially when the agents included at least one assertive\npersona. Qualitative analysis of MAS collaboration for these configurations\nsuggests that MAS may nonetheless aid in narrowing ambiguous code applications\nthat could improve codebooks and human-AI coding. We contribute new insight\ninto the limits of LLM-based qualitative methods, challenging the notion that\ndiverse MAS personas lead to better outcomes. We open-source our MAS and\nexperimentation code.", "comment": "Manuscript submitted for review", "pdf_url": "http://arxiv.org/pdf/2507.11198v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11187", "title": "Striking the Perfect Balance: Preserving Privacy While Boosting Utility in Collaborative Medical Prediction Platforms", "authors": ["Shao-Bo Lin", "Xiaotong Liu", "Yao Wang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11187v1", "summary": "Online collaborative medical prediction platforms offer convenience and\nreal-time feedback by leveraging massive electronic health records. However,\ngrowing concerns about privacy and low prediction quality can deter patient\nparticipation and doctor cooperation. In this paper, we first clarify the\nprivacy attacks, namely attribute attacks targeting patients and model\nextraction attacks targeting doctors, and specify the corresponding privacy\nprinciples. We then propose a privacy-preserving mechanism and integrate it\ninto a novel one-shot distributed learning framework, aiming to simultaneously\nmeet both privacy requirements and prediction performance objectives. Within\nthe framework of statistical learning theory, we theoretically demonstrate that\nthe proposed distributed learning framework can achieve the optimal prediction\nperformance under specific privacy requirements. We further validate the\ndeveloped privacy-preserving collaborative medical prediction platform through\nboth toy simulations and real-world data experiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11187v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11301", "title": "Detección y Cuantificación de Erosión Fluvial con Visión Artificial", "authors": ["Paúl Maji", "Marlon Túquerres", "Stalin Valencia", "Marcela Valenzuela", "Christian Mejia-Escobar"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      18 pages, in Spanish language, 13 figures, 4 tables", "url": "http://arxiv.org/abs/2507.11301v1", "summary": "Fluvial erosion is a natural process that can generate significant impacts on\nsoil stability and strategic infrastructures. The detection and monitoring of\nthis phenomenon is traditionally addressed by photogrammetric methods and\nanalysis in geographic information systems. These tasks require specific\nknowledge and intensive manual processing. This study proposes an artificial\nintelligence-based approach for automatic identification of eroded zones and\nestimation of their area. The state-of-the-art computer vision model YOLOv11,\nadjusted by fine-tuning and trained with photographs and LiDAR images, is used.\nThis combined dataset was segmented and labeled using the Roboflow platform.\nExperimental results indicate efficient detection of erosion patterns with an\naccuracy of 70%, precise identification of eroded areas and reliable\ncalculation of their extent in pixels and square meters. As a final product,\nthe EROSCAN system has been developed, an interactive web application that\nallows users to upload images and obtain automatic segmentations of fluvial\nerosion, together with the estimated area. This tool optimizes the detection\nand quantification of the phenomenon, facilitating decision making in risk\nmanagement and territorial planning.", "comment": "18 pages, in Spanish language, 13 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.11301v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2409.07040", "title": "Retinex-RAWMamba: Bridging Demosaicing and Denoising for Low-Light RAW Image Enhancement", "authors": ["Xianmin Chen", "Longfei Han", "Peiliang Huang", "Xiaoxu Feng", "Dingwen Zhang", "Junwei Han"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.07040v5", "summary": "Low-light image enhancement, particularly in cross-domain tasks such as\nmapping from the raw domain to the sRGB domain, remains a significant\nchallenge. Many deep learning-based methods have been developed to address this\nissue and have shown promising results in recent years. However, single-stage\nmethods, which attempt to unify the complex mapping across both domains,\nleading to limited denoising performance. In contrast, existing two-stage\napproaches typically overlook the characteristic of demosaicing within the\nImage Signal Processing (ISP) pipeline, leading to color distortions under\nvarying lighting conditions, especially in low-light scenarios. To address\nthese issues, we propose a novel Mamba-based method customized for low light\nRAW images, called RAWMamba, to effectively handle raw images with different\nCFAs. Furthermore, we introduce a Retinex Decomposition Module (RDM) grounded\nin Retinex prior, which decouples illumination from reflectance to facilitate\nmore effective denoising and automatic non-linear exposure correction, reducing\nthe effect of manual linear illumination enhancement. By bridging demosaicing\nand denoising, better enhancement for low light RAW images is achieved.\nExperimental evaluations conducted on public datasets SID and MCR demonstrate\nthat our proposed RAWMamba achieves state-of-the-art performance on\ncross-domain mapping. The code is available at\nhttps://github.com/Cynicarlos/RetinexRawMamba.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.07040v5", "cate": "cs.CV", "date": "2024-09-11", "updated": "2025-07-15"}
{"id": "2507.10918", "title": "How Stylistic Similarity Shapes Preferences in Dialogue Dataset with User and Third Party Evaluations", "authors": ["Ikumi Numaya", "Shoji Moriya", "Shiki Sato", "Reina Akama", "Jun Suzuki"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to SIGDIAL 2025 (long)", "url": "http://arxiv.org/abs/2507.10918v1", "summary": "Recent advancements in dialogue generation have broadened the scope of\nhuman-bot interactions, enabling not only contextually appropriate responses\nbut also the analysis of human affect and sensitivity. While prior work has\nsuggested that stylistic similarity between user and system may enhance user\nimpressions, the distinction between subjective and objective similarity is\noften overlooked. To investigate this issue, we introduce a novel dataset that\nincludes users' preferences, subjective stylistic similarity based on users'\nown perceptions, and objective stylistic similarity annotated by third party\nevaluators in open-domain dialogue settings. Analysis using the constructed\ndataset reveals a strong positive correlation between subjective stylistic\nsimilarity and user preference. Furthermore, our analysis suggests an important\nfinding: users' subjective stylistic similarity differs from third party\nobjective similarity. This underscores the importance of distinguishing between\nsubjective and objective evaluations and understanding the distinct aspects\neach captures when analyzing the relationship between stylistic similarity and\nuser preferences. The dataset presented in this paper is available online.", "comment": "Accepted to SIGDIAL 2025 (long)", "pdf_url": "http://arxiv.org/pdf/2507.10918v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11107", "title": "Efficient Branch-and-Bound for Submodular Function Maximization under Knapsack Constraint", "authors": ["Yimin Hao", "Yi Zhou", "Chao Xu", "Zhang-Hua Fu"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Accepted to ECAI 2025", "url": "http://arxiv.org/abs/2507.11107v1", "summary": "The submodular knapsack problem (SKP), which seeks to maximize a submodular\nset function by selecting a subset of elements within a given budget, is an\nimportant discrete optimization problem. The majority of existing approaches to\nsolving the SKP are approximation algorithms. However, in domains such as\nhealth-care facility location and risk management, the need for optimal\nsolutions is still critical, necessitating the use of exact algorithms over\napproximation methods. In this paper, we present an optimal branch-and-bound\napproach, featuring a novel upper bound with a worst-case tightness guarantee\nand an efficient dual branching method to minimize repeat computations.\nExperiments in applications such as facility location, weighted coverage,\ninfluence maximization, and so on show that the algorithms that implement the\nnew ideas are far more efficient than conventional methods.", "comment": "Accepted to ECAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.11107v1", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2505.01319", "title": "Model See Model Do: Speech-Driven Facial Animation with Style Control", "authors": ["Yifang Pan", "Karan Singh", "Luiz Gustavo Hafemann"], "categories": ["cs.GR", "cs.LG", "I.3.7; I.3.8"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      10 pages, 7 figures, SIGGRAPH Conference Papers '25", "url": "http://arxiv.org/abs/2505.01319v2", "summary": "Speech-driven 3D facial animation plays a key role in applications such as\nvirtual avatars, gaming, and digital content creation. While existing methods\nhave made significant progress in achieving accurate lip synchronization and\ngenerating basic emotional expressions, they often struggle to capture and\neffectively transfer nuanced performance styles. We propose a novel\nexample-based generation framework that conditions a latent diffusion model on\na reference style clip to produce highly expressive and temporally coherent\nfacial animations. To address the challenge of accurately adhering to the style\nreference, we introduce a novel conditioning mechanism called style basis,\nwhich extracts key poses from the reference and additively guides the diffusion\ngeneration process to fit the style without compromising lip synchronization\nquality. This approach enables the model to capture subtle stylistic cues while\nensuring that the generated animations align closely with the input speech.\nExtensive qualitative, quantitative, and perceptual evaluations demonstrate the\neffectiveness of our method in faithfully reproducing the desired style while\nachieving superior lip synchronization across various speech scenarios.", "comment": "10 pages, 7 figures, SIGGRAPH Conference Papers '25", "pdf_url": "http://arxiv.org/pdf/2505.01319v2", "cate": "cs.GR", "date": "2025-05-02", "updated": "2025-07-15"}
{"id": "2507.11269", "title": "Turning Sand to Gold: Recycling Data to Bridge On-Policy and Off-Policy Learning via Causal Bound", "authors": ["Tal Fiskus", "Uri Shaham"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      51 pages, 16 figures", "url": "http://arxiv.org/abs/2507.11269v1", "summary": "Deep reinforcement learning (DRL) agents excel in solving complex\ndecision-making tasks across various domains. However, they often require a\nsubstantial number of training steps and a vast experience replay buffer,\nleading to significant computational and resource demands. To address these\nchallenges, we introduce a novel theoretical result that leverages the\nNeyman-Rubin potential outcomes framework into DRL. Unlike most methods that\nfocus on bounding the counterfactual loss, we establish a causal bound on the\nfactual loss, which is analogous to the on-policy loss in DRL. This bound is\ncomputed by storing past value network outputs in the experience replay buffer,\neffectively utilizing data that is usually discarded. Extensive experiments\nacross the Atari 2600 and MuJoCo domains on various agents, such as DQN and\nSAC, achieve up to 2,427% higher reward ratio, outperforming the same agents\nwithout our proposed term, and reducing the experience replay buffer size by up\nto 96%, significantly improving sample efficiency at negligible cost.", "comment": "51 pages, 16 figures", "pdf_url": "http://arxiv.org/pdf/2507.11269v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11228", "title": "Gradient Descent on Logistic Regression: Do Large Step-Sizes Work with Data on the Sphere?", "authors": ["Si Yi Meng", "Baptiste Goujaud", "Antonio Orvieto", "Christopher De Sa"], "categories": ["cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11228v1", "summary": "Gradient descent (GD) on logistic regression has many fascinating properties.\nWhen the dataset is linearly separable, it is known that the iterates converge\nin direction to the maximum-margin separator regardless of how large the step\nsize is. In the non-separable case, however, it has been shown that GD can\nexhibit a cycling behaviour even when the step sizes is still below the\nstability threshold $2/\\lambda$, where $\\lambda$ is the largest eigenvalue of\nthe Hessian at the solution. This short paper explores whether restricting the\ndata to have equal magnitude is a sufficient condition for global convergence,\nunder any step size below the stability threshold. We prove that this is true\nin a one dimensional space, but in higher dimensions cycling behaviour can\nstill occur. We hope to inspire further studies on quantifying how common these\ncycles are in realistic datasets, as well as finding sufficient conditions to\nguarantee global convergence with large step sizes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11228v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11321", "title": "A Mixed-Primitive-based Gaussian Splatting Method for Surface Reconstruction", "authors": ["Haoxuan Qu", "Yujun Cai", "Hossein Rahmani", "Ajay Kumar", "Junsong Yuan", "Jun Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11321v1", "summary": "Recently, Gaussian Splatting (GS) has received a lot of attention in surface\nreconstruction. However, while 3D objects can be of complex and diverse shapes\nin the real world, existing GS-based methods only limitedly use a single type\nof splatting primitive (Gaussian ellipse or Gaussian ellipsoid) to represent\nobject surfaces during their reconstruction. In this paper, we highlight that\nthis can be insufficient for object surfaces to be represented in high quality.\nThus, we propose a novel framework that, for the first time, enables Gaussian\nSplatting to incorporate multiple types of (geometrical) primitives during its\nsurface reconstruction process. Specifically, in our framework, we first\npropose a compositional splatting strategy, enabling the splatting and\nrendering of different types of primitives in the Gaussian Splatting pipeline.\nIn addition, we also design our framework with a mixed-primitive-based\ninitialization strategy and a vertex pruning mechanism to further promote its\nsurface representation learning process to be well executed leveraging\ndifferent types of primitives. Extensive experiments show the efficacy of our\nframework and its accurate surface reconstruction performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11321v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2411.16370", "title": "A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation", "authors": ["M. M. A. Valiuddin", "R. J. G. van Sloun", "C. G. A. Viviers", "P. H. N. de With", "F. van der Sommen"], "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV", "stat.ML"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      31 pages of content, revised", "url": "http://arxiv.org/abs/2411.16370v5", "summary": "Advances in architectural design, data availability, and compute have driven\nremarkable progress in semantic segmentation. Yet, these models often rely on\nrelaxed Bayesian assumptions, omitting critical uncertainty information needed\nfor robust decision-making. The resulting reliance on point estimates has\nfueled interest in probabilistic segmentation, but the literature remains\nfragmented. In response, this review consolidates and contextualizes\nfoundational concepts in uncertainty modeling, including the non-trivial task\nof distinguishing between epistemic and aleatoric uncertainty and examining\ntheir roles across four key downstream segmentation tasks, highlighting Active\nLearning as particularly promising. By unifying theory, terminology, and\napplications, we provide a coherent foundation for researchers and identify\ncritical challenges, such as strong assumptions in spatial aggregation, lack of\nstandardized benchmarks, and pitfalls in current uncertainty quantification\nmethods. We identify trends such as the adoption of contemporary generative\nmodels, driven by advances in the broader field of generative modeling, with\nsegmentation-specific innovation primarily in the conditioning mechanisms.\nMoreover, we observe growing interest in distribution- and sampling-free\napproaches to uncertainty estimation. We further propose directions for\nadvancing uncertainty-aware segmentation in deep learning, including pragmatic\nstrategies for disentangling different sources of uncertainty, novel\nuncertainty modeling approaches and improved Transformer-based backbones. In\nthis way, we aim to support the development of more reliable, efficient, and\ninterpretable segmentation models that effectively incorporate uncertainty into\nreal-world applications.", "comment": "31 pages of content, revised", "pdf_url": "http://arxiv.org/pdf/2411.16370v5", "cate": "cs.CV", "date": "2024-11-25", "updated": "2025-07-15"}
{"id": "2507.10958", "title": "DS@GT at eRisk 2025: From prompts to predictions, benchmarking early depression detection with conversational agent based assessments and temporal attention models", "authors": ["Anthony Miyaguchi", "David Guecha", "Yuwen Chiu", "Sidharth Gaur"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10958v1", "summary": "This Working Note summarizes the participation of the DS@GT team in two eRisk\n2025 challenges. For the Pilot Task on conversational depression detection with\nlarge language-models (LLMs), we adopted a prompt-engineering strategy in which\ndiverse LLMs conducted BDI-II-based assessments and produced structured JSON\noutputs. Because ground-truth labels were unavailable, we evaluated cross-model\nagreement and internal consistency. Our prompt design methodology aligned model\noutputs with BDI-II criteria and enabled the analysis of conversational cues\nthat influenced the prediction of symptoms. Our best submission, second on the\nofficial leaderboard, achieved DCHR = 0.50, ADODL = 0.89, and ASHR = 0.27.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10958v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11115", "title": "Finding Order-Preserving Subgraphs", "authors": ["Haruya Imamura", "Yasuaki Kobayashi", "Yota Otachi", "Toshiki Saitoh", "Keita Sato", "Asahi Takaoka", "Ryo Yoshinaka"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11115v1", "summary": "(Induced) Subgraph Isomorphism and Maximum Common (Induced) Subgraph are\nfundamental problems in graph pattern matching and similarity computation. In\ngraphs derived from time-series data or protein structures, a natural total\nordering of vertices often arises from their underlying structure, such as\ntemporal sequences or amino acid sequences. This motivates the study of problem\nvariants that respect this inherent ordering. This paper addresses Ordered\n(Induced) Subgraph Isomorphism (O(I)SI) and its generalization, Maximum Common\nOrdered (Induced) Subgraph (MCO(I)S), which seek to find subgraph isomorphisms\nthat preserve the vertex orderings of two given ordered graphs. Our main\ncontributions are threefold: (1) We prove that these problems remain\nNP-complete even when restricted to small graph classes, such as trees of depth\n2 and threshold graphs. (2) We establish a gap in computational complexity\nbetween OSI and OISI on certain graph classes. For instance, OSI is\npolynomial-time solvable for interval graphs with their interval orderings,\nwhereas OISI remains NP-complete under the same setting. (3) We demonstrate\nthat the tractability of these problems can depend on the vertex ordering. For\nexample, while OISI is NP-complete on threshold graphs, its generalization,\nMCOIS, can be solved in polynomial time if the specific vertex orderings that\ncharacterize the threshold graphs are provided.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11115v1", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10726", "title": "Extracting Document Relations from Search Corpus by Marginalizing over User Queries", "authors": ["Yuki Iwamoto", "Kaoru Tsunoda", "Ken Kaneiwa"], "categories": ["cs.IR", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      9 pages, 6 figures", "url": "http://arxiv.org/abs/2507.10726v1", "summary": "Understanding relationships between documents in large-scale corpora is\nessential for knowledge discovery and information organization. However,\nexisting approaches rely heavily on manual annotation or predefined\nrelationship taxonomies. We propose EDR-MQ (Extracting Document Relations by\nMarginalizing over User Queries), a novel framework that discovers document\nrelationships through query marginalization. EDR-MQ is based on the insight\nthat strongly related documents often co-occur in results across diverse user\nqueries, enabling us to estimate joint probabilities between document pairs by\nmarginalizing over a collection of queries. To enable this query\nmarginalization approach, we develop Multiply Conditioned Retrieval-Augmented\nGeneration (MC-RAG), which employs conditional retrieval where subsequent\ndocument retrievals depend on previously retrieved content. By observing\nco-occurrence patterns across diverse queries, EDR-MQ estimates joint\nprobabilities between document pairs without requiring labeled training data or\npredefined taxonomies. Experimental results show that our query marginalization\napproach successfully identifies meaningful document relationships, revealing\ntopical clusters, evidence chains, and cross-domain connections that are not\napparent through traditional similarity-based methods. Our query-driven\nframework offers a practical approach to document organization that adapts to\ndifferent user perspectives and information needs.", "comment": "9 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.10726v1", "cate": "cs.IR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11316", "title": "Internal Value Alignment in Large Language Models through Controlled Value Vector Activation", "authors": ["Haoran Jin", "Meng Li", "Xiting Wang", "Zhihao Xu", "Minlie Huang", "Yantao Jia", "Defu Lian"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      25 pages, 14 figures. Accepted by ACL 2025 (main conference)", "url": "http://arxiv.org/abs/2507.11316v1", "summary": "Aligning Large Language Models (LLMs) with human values has attracted\nincreasing attention since it provides clarity, transparency, and the ability\nto adapt to evolving scenarios. In this paper, we introduce a Controlled Value\nVector Activation (ConVA) method that directly aligns the internal values of\nLLMs by interpreting how a value is encoded in their latent representations and\nmodifies relevant activations to ensure consistent values in LLMs. To ensure an\naccurate and unbiased interpretation, we propose a context-controlled value\nvector identification method. To consistently control values without\nsacrificing model performance, we introduce a gated value vector activation\nmethod for effective and minimum degree of value control. Experiments show that\nour method achieves the highest control success rate across 10 basic values\nwithout hurting LLM performance and fluency, and ensures target values even\nwith opposite and potentially malicious input prompts. Source code and data are\navailable at~ https://github.com/hr-jin/ConVA.", "comment": "25 pages, 14 figures. Accepted by ACL 2025 (main conference)", "pdf_url": "http://arxiv.org/pdf/2507.11316v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11246", "title": "Generative Click-through Rate Prediction with Applications to Search Advertising", "authors": ["Lingwei Kong", "Lu Wang", "Changping Peng", "Zhangang Lin", "Ching Law", "Jingping Shao"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This work was first submitted on February 9, 2024", "url": "http://arxiv.org/abs/2507.11246v1", "summary": "Click-Through Rate (CTR) prediction models are integral to a myriad of\nindustrial settings, such as personalized search advertising. Current methods\ntypically involve feature extraction from users' historical behavior sequences\ncombined with product information, feeding into a discriminative model that is\ntrained on user feedback to estimate CTR. With the success of models such as\nGPT, the potential for generative models to enrich expressive power beyond\ndiscriminative models has become apparent. In light of this, we introduce a\nnovel model that leverages generative models to enhance the precision of CTR\npredictions in discriminative models. To reconcile the disparate data\naggregation needs of both model types, we design a two-stage training process:\n1) Generative pre-training for next-item prediction with the given item\ncategory in user behavior sequences; 2) Fine-tuning the well-trained generative\nmodel within a discriminative CTR prediction framework. Our method's efficacy\nis substantiated through extensive experiments on a new dataset, and its\nsignificant utility is further corroborated by online A/B testing results.\nCurrently, the model is deployed on one of the world's largest e-commerce\nplatforms, and we intend to release the associated code and dataset in the\nfuture.", "comment": "This work was first submitted on February 9, 2024", "pdf_url": "http://arxiv.org/pdf/2507.11246v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11325", "title": "HANS-Net: Hyperbolic Convolution and Adaptive Temporal Attention for Accurate and Generalizable Liver and Tumor Segmentation in CT Imaging", "authors": ["Arefin Ittesafun Abian", "Ripon Kumar Debnath", "Md. Abdur Rahman", "Mohaimenul Azam Khan Raiaan", "Md Rafiqul Islam", "Asif Karim", "Reem E. Mohamed", "Sami Azam"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 figures. Will be submitted to IEEE Transactions on Radiation and Plasma Medical Sciences", "url": "http://arxiv.org/abs/2507.11325v1", "summary": "Accurate liver and tumor segmentation on abdominal CT images is critical for\nreliable diagnosis and treatment planning, but remains challenging due to\ncomplex anatomical structures, variability in tumor appearance, and limited\nannotated data. To address these issues, we introduce Hyperbolic-convolutions\nAdaptive-temporal-attention with Neural-representation and Synaptic-plasticity\nNetwork (HANS-Net), a novel segmentation framework that synergistically\ncombines hyperbolic convolutions for hierarchical geometric representation, a\nwavelet-inspired decomposition module for multi-scale texture learning, a\nbiologically motivated synaptic plasticity mechanism for adaptive feature\nenhancement, and an implicit neural representation branch to model fine-grained\nand continuous anatomical boundaries. Additionally, we incorporate\nuncertainty-aware Monte Carlo dropout to quantify prediction confidence and\nlightweight temporal attention to improve inter-slice consistency without\nsacrificing efficiency. Extensive evaluations of the LiTS dataset demonstrate\nthat HANS-Net achieves a mean Dice score of 93.26%, an IoU of 88.09%, an\naverage symmetric surface distance (ASSD) of 0.72 mm, and a volume overlap\nerror (VOE) of 11.91%. Furthermore, cross-dataset validation on the\n3D-IRCADb-01 dataset obtains an average Dice of 87.45%, IoU of 80.30%, ASSD of\n1.525 mm, and VOE of 19.71%, indicating strong generalization across different\ndatasets. These results confirm the effectiveness and robustness of HANS-Net in\nproviding anatomically consistent, accurate, and confident liver and tumor\nsegmentation.", "comment": "10 figures. Will be submitted to IEEE Transactions on Radiation and\n  Plasma Medical Sciences", "pdf_url": "http://arxiv.org/pdf/2507.11325v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2505.16658", "title": "Zero-Shot Hyperspectral Pansharpening Using Hysteresis-Based Tuning for Spectral Quality Control", "authors": ["Giuseppe Guarino", "Matteo Ciotola", "Gemine Vivone", "Giovanni Poggi", "Giuseppe Scarpa"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.16658v2", "summary": "Hyperspectral pansharpening has received much attention in recent years due\nto technological and methodological advances that open the door to new\napplication scenarios. However, research on this topic is only now gaining\nmomentum. The most popular methods are still borrowed from the more mature\nfield of multispectral pansharpening and often overlook the unique challenges\nposed by hyperspectral data fusion, such as i) the very large number of bands,\nii) the overwhelming noise in selected spectral ranges, iii) the significant\nspectral mismatch between panchromatic and hyperspectral components, iv) a\ntypically high resolution ratio. Imprecise data modeling especially affects\nspectral fidelity. Even state-of-the-art methods perform well in certain\nspectral ranges and much worse in others, failing to ensure consistent quality\nacross all bands, with the risk of generating unreliable results. Here, we\npropose a hyperspectral pansharpening method that explicitly addresses this\nproblem and ensures uniform spectral quality. To this end, a single lightweight\nneural network is used, with weights that adapt on the fly to each band. During\nfine-tuning, the spatial loss is turned on and off to ensure a fast convergence\nof the spectral loss to the desired level, according to a hysteresis-like\ndynamic. Furthermore, the spatial loss itself is appropriately redefined to\naccount for nonlinear dependencies between panchromatic and spectral bands.\nOverall, the proposed method is fully unsupervised, with no prior training on\nexternal data, flexible, and low-complexity. Experiments on a recently\npublished benchmarking toolbox show that it ensures excellent sharpening\nquality, competitive with the state-of-the-art, consistently across all bands.\nThe software code and the full set of results are shared online on\nhttps://github.com/giu-guarino/rho-PNN.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.16658v2", "cate": "cs.CV", "date": "2025-05-22", "updated": "2025-07-15"}
{"id": "2507.10972", "title": "Teach Me Sign: Stepwise Prompting LLM for Sign Language Production", "authors": ["Zhaoyi An", "Rei Kawakami"], "categories": ["cs.CL", "cs.CV", "cs.MM"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE ICIP 2025", "url": "http://arxiv.org/abs/2507.10972v1", "summary": "Large language models, with their strong reasoning ability and rich\nknowledge, have brought revolution to many tasks of AI, but their impact on\nsign language generation remains limited due to its complexity and unique\nrules. In this paper, we propose TEAch Me Sign (TEAM-Sign), treating sign\nlanguage as another natural language. By fine-tuning an LLM, we enable it to\nlearn the correspondence between text and sign language, and facilitate\ngeneration. Considering the differences between sign and spoken language, we\nemploy a stepwise prompting strategy to extract the inherent sign language\nknowledge within the LLM, thereby supporting the learning and generation\nprocess. Experimental results on How2Sign and Phoenix14T datasets demonstrate\nthat our approach effectively leverages both the sign language knowledge and\nreasoning capabilities of LLM to align the different distribution and\ngrammatical rules between sign and spoken language.", "comment": "Accepted by IEEE ICIP 2025", "pdf_url": "http://arxiv.org/pdf/2507.10972v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11236", "title": "Improved sampling algorithms and Poincaré inequalities for non-log-concave distributions", "authors": ["Yuchen He", "Zhehan Lei", "Jianan Shao", "Chihao Zhang"], "categories": ["cs.DS", "cs.LG", "math.PR", "stat.ML"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11236v1", "summary": "We study the problem of sampling from a distribution $\\mu$ with density\n$\\propto e^{-V}$ for some potential function $V:\\mathbb R^d\\to \\mathbb R$ with\nquery access to $V$ and $\\nabla V$. We start with the following standard\nassumptions:\n  (1) The potential function $V$ is $L$-smooth.\n  (2) The second moment $\\mathbf{E}_{X\\sim \\mu}[\\|X\\|^2]\\leq M$.\n  Recently, He and Zhang (COLT'25) showed that the query complexity of sampling\nfrom such distributions is at least\n$\\left(\\frac{LM}{d\\epsilon}\\right)^{\\Omega(d)}$ where $\\epsilon$ is the desired\naccuracy in total variation distance, and the Poincar\\'e constant can be\narbitrarily large.\n  Meanwhile, another common assumption in the study of diffusion based samplers\n(see e.g., the work of Chen, Chewi, Li, Li, Salim and Zhang (ICLR'23))\nstrengthens the smoothness condition (1) to the following:\n  (1*) The potential function of *every* distribution along the\nOrnstein-Uhlenbeck process starting from $\\mu$ is $L$-smooth.\n  We show that under the assumptions (1*) and (2), the query complexity of\nsampling from $\\mu$ can be $\\mathrm{poly}(L,d)\\cdot\n\\left(\\frac{Ld+M}{\\epsilon^2}\\right)^{\\mathcal{O}(L+1)}$, which is polynomial\nin $d$ and $\\frac{1}{\\epsilon}$ when $L=\\mathcal{O}(1)$ and\n$M=\\mathrm{poly}(d)$. This improves the algorithm with quasi-polynomial query\ncomplexity developed by Huang et al. (COLT'24). Our results imply that the\nseemly moderate strengthening of the smoothness condition (1) to (1*) can lead\nto an exponential gap in the query complexity of sampling algorithms.\n  Moreover, we show that together with the assumption (1*) and the stronger\nmoment assumption that $\\|X\\|$ is $\\lambda$-sub-Gaussian for $X\\sim\\mu$, the\nPoincar\\'e constant of $\\mu$ is at most $\\mathcal{O}(\\lambda)^{2(L+1)}$. As an\napplication of our technique, we obtain improved estimate of the Poincar\\'e\nconstant for mixture of Gaussians with the same covariance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11236v1", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10917", "title": "LLM-Driven Dual-Level Multi-Interest Modeling for Recommendation", "authors": ["Ziyan Wang", "Yingpeng Du", "Zhu Sun", "Jieyi Bi", "Haoyan Chua", "Tianjun Wei", "Jie Zhang"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures", "url": "http://arxiv.org/abs/2507.10917v1", "summary": "Recently, much effort has been devoted to modeling users' multi-interests\nbased on their behaviors or auxiliary signals. However, existing methods often\nrely on heuristic assumptions, e.g., co-occurring items indicate the same\ninterest of users, failing to capture user multi-interests aligning with\nreal-world scenarios. While large language models (LLMs) show significant\npotential for multi-interest analysis due to their extensive knowledge and\npowerful reasoning capabilities, two key challenges remain. First, the\ngranularity of LLM-driven multi-interests is agnostic, possibly leading to\noverly fine or coarse interest grouping. Second, individual user analysis\nprovides limited insights due to the data sparsity issue. In this paper, we\npropose an LLM-driven dual-level multi-interest modeling framework for more\neffective recommendation. At the user-individual level, we exploit LLMs to\nflexibly allocate items engaged by users into different semantic clusters,\nindicating their diverse and distinct interests. To alleviate the agnostic\ngeneration of LLMs, we adaptively assign these semantic clusters to users'\ncollaborative multi-interests learned from global user-item interactions,\nallowing the granularity to be automatically adjusted according to the user's\nbehaviors using an alignment module. To alleviate the limited insights derived\nfrom individual users' behaviors, at the user-crowd level, we propose\naggregating user cliques into synthesized users with rich behaviors for more\ncomprehensive LLM-driven multi-interest analysis. We formulate a max covering\nproblem to ensure the compactness and representativeness of synthesized users'\nbehaviors, and then conduct contrastive learning based on their LLM-driven\nmulti-interests to disentangle item representations among different interests.\nExperiments on real-world datasets show the superiority of our approach against\nstate-of-the-art methods.", "comment": "10 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.10917v1", "cate": "cs.IR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11329", "title": "Quantitative multi-metabolite imaging of Parkinson's disease using AI boosted molecular MRI", "authors": ["Hagar Shmuely", "Michal Rivlin", "Or Perlman"], "categories": ["physics.med-ph", "cs.AI"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "Comments:      This project was funded by the European Union (ERC, BabyMagnet, project no. 101115639). Views and opinions expressed are, however, those of the authors only and do not necessarily reflect those of the European Union or the European Research Council. Neither the European Union nor the granting authority can be held responsible for them", "url": "http://arxiv.org/abs/2507.11329v1", "summary": "Traditional approaches for molecular imaging of Parkinson's disease (PD) in\nvivo require radioactive isotopes, lengthy scan times, or deliver only low\nspatial resolution. Recent advances in saturation transfer-based PD magnetic\nresonance imaging (MRI) have provided biochemical insights, although the image\ncontrast is semi-quantitative and nonspecific. Here, we combined a rapid\nmolecular MRI acquisition paradigm with deep learning based reconstruction for\nmulti-metabolite quantification of glutamate, mobile proteins, semisolid, and\nmobile macromolecules in an acute MPTP\n(1-methyl-4-phenyl-1,2,3,6-tetrahydropyridine) mouse model. The quantitative\nparameter maps are in general agreement with the histology and MR spectroscopy,\nand demonstrate that semisolid magnetization transfer (MT), amide, and\naliphatic relayed nuclear Overhauser effect (rNOE) proton volume fractions may\nserve as PD biomarkers.", "comment": "This project was funded by the European Union (ERC, BabyMagnet,\n  project no. 101115639). Views and opinions expressed are, however, those of\n  the authors only and do not necessarily reflect those of the European Union\n  or the European Research Council. Neither the European Union nor the granting\n  authority can be held responsible for them", "pdf_url": "http://arxiv.org/pdf/2507.11329v1", "cate": "physics.med-ph", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11262", "title": "LyAm: Robust Non-Convex Optimization for Stable Learning in Noisy Environments", "authors": ["Elmira Mirzabeigi", "Sepehr Rezaee", "Kourosh Parand"], "categories": ["cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11262v1", "summary": "Training deep neural networks, particularly in computer vision tasks, often\nsuffers from noisy gradients and unstable convergence, which hinder performance\nand generalization. In this paper, we propose LyAm, a novel optimizer that\nintegrates Adam's adaptive moment estimation with Lyapunov-based stability\nmechanisms. LyAm dynamically adjusts the learning rate using Lyapunov stability\ntheory to enhance convergence robustness and mitigate training noise. We\nprovide a rigorous theoretical framework proving the convergence guarantees of\nLyAm in complex, non-convex settings. Extensive experiments on like as CIFAR-10\nand CIFAR-100 show that LyAm consistently outperforms state-of-the-art\noptimizers in terms of accuracy, convergence speed, and stability, establishing\nit as a strong candidate for robust deep learning optimization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11262v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11333", "title": "MonoMVSNet: Monocular Priors Guided Multi-View Stereo Network", "authors": ["Jianfei Jiang", "Qiankun Liu", "Haochen Yu", "Hongyuan Liu", "Liyong Wang", "Jiansheng Chen", "Huimin Ma"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.11333v1", "summary": "Learning-based Multi-View Stereo (MVS) methods aim to predict depth maps for\na sequence of calibrated images to recover dense point clouds. However,\nexisting MVS methods often struggle with challenging regions, such as\ntextureless regions and reflective surfaces, where feature matching fails. In\ncontrast, monocular depth estimation inherently does not require feature\nmatching, allowing it to achieve robust relative depth estimation in these\nregions. To bridge this gap, we propose MonoMVSNet, a novel monocular feature\nand depth guided MVS network that integrates powerful priors from a monocular\nfoundation model into multi-view geometry. Firstly, the monocular feature of\nthe reference view is integrated into source view features by the attention\nmechanism with a newly designed cross-view position encoding. Then, the\nmonocular depth of the reference view is aligned to dynamically update the\ndepth candidates for edge regions during the sampling procedure. Finally, a\nrelative consistency loss is further designed based on the monocular depth to\nsupervise the depth prediction. Extensive experiments demonstrate that\nMonoMVSNet achieves state-of-the-art performance on the DTU and\nTanks-and-Temples datasets, ranking first on the Tanks-and-Temples Intermediate\nand Advanced benchmarks. The source code is available at\nhttps://github.com/JianfeiJ/MonoMVSNet.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.11333v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10996", "title": "Mario at EXIST 2025: A Simple Gateway to Effective Multilingual Sexism Detection", "authors": ["Lin Tian", "Johanne R. Trippas", "Marian-Andrei Rizoiu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages, 5 tables, CLEF 2025", "url": "http://arxiv.org/abs/2507.10996v1", "summary": "This paper presents our approach to EXIST 2025 Task 1, addressing text-based\nsexism detection in English and Spanish tweets through hierarchical Low-Rank\nAdaptation (LoRA) of Llama 3.1 8B. Our method introduces conditional adapter\nrouting that explicitly models label dependencies across three hierarchically\nstructured subtasks: binary sexism identification, source intention detection,\nand multilabel sexism categorization. Unlike conventional LoRA applications\nthat target only attention layers, we apply adaptation to all linear\ntransformations, enhancing the model's capacity to capture task-specific\npatterns. In contrast to complex data processing and ensemble approaches, we\nshow that straightforward parameter-efficient fine-tuning achieves strong\nperformance. We train separate LoRA adapters (rank=16, QLoRA 4-bit) for each\nsubtask using unified multilingual training that leverages Llama 3.1's native\nbilingual capabilities. The method requires minimal preprocessing and uses\nstandard supervised learning. Our multilingual training strategy eliminates the\nneed for separate language-specific models, achieving 1.7-2.4\\% F1 improvements\nthrough cross-lingual transfer. With only 1.67\\% trainable parameters compared\nto full fine-tuning, our approach reduces training time by 75\\% and model\nstorage by 98\\%, while achieving competitive performance across all subtasks\n(ICM-Hard: 0.6774 for binary classification, 0.4991 for intention detection,\n0.6519 for multilabel categorization).", "comment": "12 pages, 5 tables, CLEF 2025", "pdf_url": "http://arxiv.org/pdf/2507.10996v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11256", "title": "Fully Dynamic Euclidean k-Means", "authors": ["Sayan Bhattacharya", "Martín Costa", "Ermiya Farokhnejad", "Shaofeng H. -C. Jiang", "Yaonan Jin", "Jianing Lou"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11256v1", "summary": "We consider the fundamental Euclidean $k$-means clustering problem in a\ndynamic setting, where the input $X \\subseteq \\mathbb{R}^d$ evolves over time\nvia a sequence of point insertions/deletions. We have to explicitly maintain a\nsolution (a set of $k$ centers) $S \\subseteq \\mathbb{R}^d$ throughout these\nupdates, while minimizing the approximation ratio, the update time (time taken\nto handle a point insertion/deletion) and the recourse (number of changes made\nto the solution $S$) of the algorithm.\n  We present a dynamic algorithm for this problem with\n$\\text{poly}(1/\\epsilon)$-approximation ratio, $\\tilde{O}(k^{\\epsilon})$ update\ntime and $\\tilde{O}(1)$ recourse. In the general regime, where the dimension\n$d$ cannot be assumed to be a fixed constant, our algorithm has almost optimal\nguarantees across all these three parameters. Indeed, improving our update time\nor approximation ratio would imply beating the state-of-the-art static\nalgorithm for this problem (which is widely believed to be the best possible),\nand the recourse of any dynamic algorithm must be $\\Omega(1)$.\n  We obtain our result by building on top of the recent work of [Bhattacharya,\nCosta, Farokhnejad; STOC'25], which gave a near-optimal dynamic algorithm for\n$k$-means in general metric spaces (as opposed to in the Euclidean setting).\nAlong the way, we design several novel geometric data structures that are of\nindependent interest. Specifically, one of our main contributions is designing\nthe first consistent hashing scheme [Czumaj, Jiang, Krauthgamer, Vesel\\'y,\nYang; FOCS'22] that achieves $\\text{poly}(d)$ running time per point evaluation\nwith competitive parameters.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11256v1", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10953", "title": "Unraveling the Biomarker Prospects of High-Altitude Diseases: Insights from Biomolecular Event Network Constructed using Text Mining", "authors": ["Balu Bhasuran", "Sabenabanu Abdulkadhar", "Jeyakumar Natarajan"], "categories": ["cs.IR", "q-bio.QM"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10953v1", "summary": "High-altitude diseases (HAD), encompassing acute mountain sickness (AMS),\nhigh-altitude cerebral edema (HACE), and high-altitude pulmonary edema (HAPE),\nare triggered by hypobaric hypoxia at elevations above 2,500 meters. These\nconditions pose significant health risks, yet the molecular mechanisms remain\ninsufficiently understood. In this study, we developed a biomolecular event\nextraction pipeline integrating supervised machine learning with feature-based\nand multiscale Laplacian graph kernels to analyze 7,847 curated HAD-related\nabstracts from PubMed. We extracted over 150 unique biomolecular events\nincluding gene expression, regulation, binding, and localization and\nconstructed a weighted, undirected biomolecular event network comprising 97\nnodes and 153 edges. Using the PageRank algorithm, we prioritized key\nbiomolecules based on their centrality within the event network. The top-ranked\nproteins included Erythropoietin (EPO) (0.0163), Vascular endothelial growth\nfactor (VEGF) (0.0148), Hypoxia-inducible factor 1 (HIF-1) alpha (0.0136),\nEndothelial PAS Domain Protein 1 (EPAS1) and Angiotensin-Converting Enzyme\n(ACE) (0.0119), Egl nine homolog 1 (EGLN1), Endothelin 1 (ET-1), and 70\nkilodalton heat shock protein (Hsp70)(0.0118), all of which play crucial roles\nin oxygen sensing, vascular remodeling, erythropoiesis, and blood pressure\nregulation. Subnetwork analysis revealed three major functional clusters\ncentered on hypoxia response, inflammation, and stress adaptation pathways. Our\nintegrative approach demonstrates the utility of large-scale text mining and\ngraph-based analysis to uncover mechanistic insights and prioritize potential\nbiomarkers for high-altitude disease.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10953v1", "cate": "cs.IR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11331", "title": "SystolicAttention: Fusing FlashAttention within a Single Systolic Array", "authors": ["Jiawei Lin", "Guokai Chen", "Yuanlong Li", "Thomas Bourgeat"], "categories": ["cs.AR", "cs.AI"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11331v1", "summary": "Transformer models rely heavily on scaled dot-product attention (SDPA),\ntypically implemented using the FlashAttention algorithm. However, current\nsystolic-array-based accelerators face significant challenges when executing\nFlashAttention. Systolic arrays can only achieve high utilization for\nconsecutive and large matrix multiplications. In contrast, FlashAttention\nrequires frequently interleaved matrix multiplications and softmax operations.\n  The frequent data swaps between the systolic array and external vector units\nresult in low systolic array utilization. This is further exacerbated by the\nfact that softmax involves numerous non-matrix operations, which are not\nwell-suited for systolic arrays. Moreover, the concurrent execution of matrix\nmultiplication on systolic arrays and softmax on vector units leads to register\nfile and SRAM port contention, further degrading performance.\n  To overcome these limitations, we propose FSA, an enhanced systolic array\narchitecture that enables the entire FlashAttention algorithm to run entirely\nwithin a single systolic array, eliminating the need for external vector units.\nAt the core of FSA is SystolicAttention, a novel scheduling algorithm that maps\nFlashAttention operations onto systolic arrays with fine-grained, element-wise\noverlap. This significantly improves array utilization while preserving the\noriginal floating-point operation order to maintain numerical stability.\n  We implement FSA in synthesizable RTL and evaluate its performance against\nstate-of-the-art commercial accelerators. Our results show that FSA achieves\n1.77x and 4.83x higher attention FLOPs/s utilization compared to AWS\nNeuronCore-v2 and Google TPUv5e, respectively, with only about 10% area\noverhead.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11331v1", "cate": "cs.AR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11274", "title": "Fast Last-Iterate Convergence of SGD in the Smooth Interpolation Regime", "authors": ["Amit Attia", "Matan Schliserman", "Uri Sherman", "Tomer Koren"], "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      27 pages", "url": "http://arxiv.org/abs/2507.11274v1", "summary": "We study population convergence guarantees of stochastic gradient descent\n(SGD) for smooth convex objectives in the interpolation regime, where the noise\nat optimum is zero or near zero. The behavior of the last iterate of SGD in\nthis setting -- particularly with large (constant) stepsizes -- has received\ngrowing attention in recent years due to implications for the training of\nover-parameterized models, as well as to analyzing forgetting in continual\nlearning and to understanding the convergence of the randomized Kaczmarz method\nfor solving linear systems. We establish that after $T$ steps of SGD on\n$\\beta$-smooth convex loss functions with stepsize $\\eta \\leq 1/\\beta$, the\nlast iterate exhibits expected excess risk $\\widetilde{O}(1/(\\eta\nT^{1-\\beta\\eta/2}) + \\eta T^{\\beta\\eta/2} \\sigma_\\star^2)$, where\n$\\sigma_\\star^2$ denotes the variance of the stochastic gradients at the\noptimum. In particular, for a well-tuned stepsize we obtain a near optimal\n$\\widetilde{O}(1/T + \\sigma_\\star/\\sqrt{T})$ rate for the last iterate,\nextending the results of Varre et al. (2021) beyond least squares regression;\nand when $\\sigma_\\star=0$ we obtain a rate of $O(1/\\sqrt{T})$ with\n$\\eta=1/\\beta$, improving upon the best-known $O(T^{-1/4})$ rate recently\nestablished by Evron et al. (2025) in the special case of realizable linear\nregression.", "comment": "27 pages", "pdf_url": "http://arxiv.org/pdf/2507.11274v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11336", "title": "UGC-VideoCaptioner: An Omni UGC Video Detail Caption Model and New Benchmarks", "authors": ["Peiran Wu", "Yunze Liu", "Zhengdong Zhu", "Enmin Zhou", "Shawn Shen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11336v1", "summary": "Real-world user-generated videos, especially on platforms like TikTok, often\nfeature rich and intertwined audio visual content. However, existing video\ncaptioning benchmarks and models remain predominantly visual centric,\noverlooking the crucial role of audio in conveying scene dynamics, speaker\nintent, and narrative context. This lack of omni datasets and lightweight,\ncapable models hampers progress in fine grained, multimodal video\nunderstanding. To address these challenges, we introduce UGC-VideoCap, a new\nbenchmark and model framework specifically designed for detailed omnimodal\ncaptioning of short form user-generated videos. Unlike prior datasets,\nUGC-VideoCap emphasizes balanced integration of audio and visual modalities,\nfeaturing 1000 TikTok videos annotated through a structured three stage\nhuman-in-the-loop pipeline covering audio only, visual only, and joint audio\nvisual semantics. The benchmark also includes 4000 carefully crafted QA pairs\nprobing both unimodal and cross modal understanding. Alongside the dataset, we\npropose UGC-VideoCaptioner(3B), a 3B parameter captioning model distilled from\nGemini 2.5 Flash. Using a novel two-stage training strategy supervised fine\ntuning followed by Group Relative Policy Optimization (GRPO), our approach\nenables efficient adaptation from limited data while maintaining competitive\nperformance. Together, our benchmark and model offer a high-quality foundation\nand a data-efficient solution for advancing omnimodal video captioning in\nunconstrained real-world UGC settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11336v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11004", "title": "Team HUMANE at AVeriTeC 2025: HerO 2 for Efficient Fact Verification", "authors": ["Yejun Yoon", "Jaeyoon Jung", "Seunghyun Yoon", "Kunwoo Park"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025 Workshop (FEVER)", "url": "http://arxiv.org/abs/2507.11004v1", "summary": "This paper presents HerO 2, Team HUMANE's system for the AVeriTeC shared task\nat the FEVER-25 workshop. HerO 2 is an enhanced version of HerO, the\nbest-performing open-source model from the previous year's challenge. It\nimproves evidence quality through document summarization and answer\nreformulation, optimizes veracity prediction via post-training quantization\nunder computational constraints, and enhances overall system performance by\nintegrating updated language model (LM) backbones. HerO 2 ranked second on the\nleaderboard while achieving the shortest runtime among the top three systems,\ndemonstrating both high efficiency and strong potential for real-world fact\nverification. The code is available at https://github.com/ssu-humane/HerO2.", "comment": "ACL 2025 Workshop (FEVER)", "pdf_url": "http://arxiv.org/pdf/2507.11004v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11257", "title": "Deterministic Lower Bounds for $k$-Edge Connectivity in the Distributed Sketching Model", "authors": ["Peter Robinson", "Ming Ming Tan"], "categories": ["cs.DS", "cs.DC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11257v1", "summary": "We study the $k$-edge connectivity problem on undirected graphs in the\ndistributed sketching model, where we have $n$ nodes and a referee. Each node\nsends a single message to the referee based on its 1-hop neighborhood in the\ngraph, and the referee must decide whether the graph is $k$-edge connected by\ntaking into account the received messages.\n  We present the first lower bound for deciding a graph connectivity problem in\nthis model with a deterministic algorithm. Concretely, we show that the worst\ncase message length is $\\Omega( k )$ bits for $k$-edge connectivity, for any\nsuper-constant $k = O(\\sqrt{n})$. Previously, only a lower bound of $\\Omega(\n\\log^3 n )$ bits was known for ($1$-edge) connectivity, due to Yu (SODA 2021).\nIn fact, our result is the first super-polylogarithmic lower bound for a\nconnectivity decision problem in the distributed graph sketching model.\n  To obtain our result, we introduce a new lower bound graph construction, as\nwell as a new 3-party communication complexity problem that we call\nUniqueOverlap. As this problem does not appear to be amenable to reductions to\nexisting hard problems such as set disjointness or indexing due to correlations\nbetween the inputs of the three players, we leverage results from\ncross-intersecting set families to prove the hardness of UniqueOverlap for\ndeterministic algorithms. Finally, we obtain the sought lower bound for\ndeciding $k$-edge connectivity via a novel simulation argument that, in\ncontrast to previous works, does not introduce any probability of error and\nthus works for deterministic algorithms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11257v1", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11042", "title": "Aligned Query Expansion: Efficient Query Expansion for Information Retrieval through LLM Alignment", "authors": ["Adam Yang", "Gustavo Penha", "Enrico Palumbo", "Hugues Bouchard"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11042v1", "summary": "With the breakthroughs in large language models (LLMs), query generation\ntechniques that expand documents and queries with related terms are becoming\nincreasingly popular in the information retrieval field. Such techniques have\nbeen shown to improve the effectiveness of traditional lexical retrieval\nmethods by dealing with the vocabulary mismatch problem. Recent work has found\nthat generating queries with a greedy decoding strategy can produce sub-optimal\nqueries, including hallucinations, and proposed to filter out queries before\nexpansion. This `generate-then-filter' approach is costly, as it requires\ngenerating multiple queries and applying a relevance model to all of them and\ndoes not teach the LLM which of the generated queries is more effective for\nexpansion. To overcome such limitations, we propose Aligned Query Expansion\n(AQE), a novel approach to enhance query expansion for passage retrieval in\nopen-domain question answering. AQE leverages recent techniques in LLM\nalignment to fine-tune models for generating query expansions that directly\noptimize the effectiveness of the retrieval task, eliminating the need for\nadditional filtering steps. This alignment ensures that queries are more\nrelevant, reducing computational costs while improving retrieval effectiveness.\nEmpirical evaluations show that AQE outperforms baseline models for query\nexpansion in both in-domain and out-of-domain settings, demonstrating\nsignificant improvements in retrieval effectiveness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11042v1", "cate": "cs.IR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11367", "title": "Local Pairwise Distance Matching for Backpropagation-Free Reinforcement Learning", "authors": ["Daniel Tanneberg"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      accepted at the European Conference on Artificial Intelligence (ECAI 2025)", "url": "http://arxiv.org/abs/2507.11367v1", "summary": "Training neural networks with reinforcement learning (RL) typically relies on\nbackpropagation (BP), necessitating storage of activations from the forward\npass for subsequent backward updates. Furthermore, backpropagating error\nsignals through multiple layers often leads to vanishing or exploding\ngradients, which can degrade learning performance and stability. We propose a\nnovel approach that trains each layer of the neural network using local signals\nduring the forward pass in RL settings. Our approach introduces local,\nlayer-wise losses leveraging the principle of matching pairwise distances from\nmulti-dimensional scaling, enhanced with optional reward-driven guidance. This\nmethod allows each hidden layer to be trained using local signals computed\nduring forward propagation, thus eliminating the need for backward passes and\nstoring intermediate activations. Our experiments, conducted with policy\ngradient methods across common RL benchmarks, demonstrate that this\nbackpropagation-free method achieves competitive performance compared to their\nclassical BP-based counterpart. Additionally, the proposed method enhances\nstability and consistency within and across runs, and improves performance\nespecially in challenging environments.", "comment": "accepted at the European Conference on Artificial Intelligence (ECAI\n  2025)", "pdf_url": "http://arxiv.org/pdf/2507.11367v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11344", "title": "Guiding LLM Decision-Making with Fairness Reward Models", "authors": ["Zara Hall", "Melanie Subbiah", "Thomas P Zollo", "Kathleen McKeown", "Richard Zemel"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11344v1", "summary": "Large language models are increasingly used to support high-stakes decisions,\npotentially influencing who is granted bail or receives a loan. Naive\nchain-of-thought sampling can improve average decision accuracy, but has also\nbeen shown to amplify unfair bias. To address this challenge and enable the\ntrustworthy use of reasoning models in high-stakes decision-making, we propose\na framework for training a generalizable Fairness Reward Model (FRM). Our model\nassigns a fairness score to LLM reasoning, enabling the system to down-weight\nbiased trajectories and favor equitable ones when aggregating decisions across\nreasoning chains. We show that a single Fairness Reward Model, trained on\nweakly supervised, LLM-annotated examples of biased versus unbiased reasoning,\ntransfers across tasks, domains, and model families without additional\nfine-tuning. Applied to real-world decision-making tasks including recidivism\nprediction and social media moderation, we show that our approach consistently\nimproves fairness while matching, or even surpassing, baseline accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11344v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11372", "title": "Attributes Shape the Embedding Space of Face Recognition Models", "authors": ["Pierrick Leroy", "Antonio Mastropietro", "Marco Nurisso", "Francesco Vaccarino"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11372v1", "summary": "Face Recognition (FR) tasks have made significant progress with the advent of\nDeep Neural Networks, particularly through margin-based triplet losses that\nembed facial images into high-dimensional feature spaces. During training,\nthese contrastive losses focus exclusively on identity information as labels.\nHowever, we observe a multiscale geometric structure emerging in the embedding\nspace, influenced by interpretable facial (e.g., hair color) and image\nattributes (e.g., contrast). We propose a geometric approach to describe the\ndependence or invariance of FR models to these attributes and introduce a\nphysics-inspired alignment metric. We evaluate the proposed metric on\ncontrolled, simplified models and widely used FR models fine-tuned with\nsynthetic data for targeted attribute augmentation. Our findings reveal that\nthe models exhibit varying degrees of invariance across different attributes,\nproviding insight into their strengths and weaknesses and enabling deeper\ninterpretability. Code available here:\nhttps://github.com/mantonios107/attrs-fr-embs}{https://github.com/mantonios107/attrs-fr-embs", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11372v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11049", "title": "Journalism-Guided Agentic In-Context Learning for News Stance Detection", "authors": ["Dahyun Lee", "Jonghyeon Choi", "Jiyoung Han", "Kunwoo Park"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Preprint. 24 pages", "url": "http://arxiv.org/abs/2507.11049v1", "summary": "As online news consumption grows, personalized recommendation systems have\nbecome integral to digital journalism. However, these systems risk reinforcing\nfilter bubbles and political polarization by failing to incorporate diverse\nperspectives. Stance detection -- identifying a text's position on a target --\ncan help mitigate this by enabling viewpoint-aware recommendations and\ndata-driven analyses of media bias. Yet, existing stance detection research\nremains largely limited to short texts and high-resource languages. To address\nthese gaps, we introduce \\textsc{K-News-Stance}, the first Korean dataset for\narticle-level stance detection, comprising 2,000 news articles with\narticle-level and 19,650 segment-level stance annotations across 47 societal\nissues. We also propose \\textsc{JoA-ICL}, a \\textbf{Jo}urnalism-guided\n\\textbf{A}gentic \\textbf{I}n-\\textbf{C}ontext \\textbf{L}earning framework that\nemploys a language model agent to predict the stances of key structural\nsegments (e.g., leads, quotes), which are then aggregated to infer the overall\narticle stance. Experiments show that \\textsc{JoA-ICL} outperforms existing\nstance detection methods, highlighting the benefits of segment-level agency in\ncapturing the overall position of long-form news articles. Two case studies\nfurther demonstrate its broader utility in promoting viewpoint diversity in\nnews recommendations and uncovering patterns of media bias.", "comment": "Preprint. 24 pages", "pdf_url": "http://arxiv.org/pdf/2507.11049v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11260", "title": "On Tight Robust Coresets for $k$-Medians Clustering", "authors": ["Lingxiao Huang", "Zhenyu Jiang", "Yi Li", "Xuan Wu"], "categories": ["cs.DS", "cs.CG", "cs.DM"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11260v1", "summary": "This paper considers coresets for the robust $k$-medians problem with $m$\noutliers, and new constructions in various metric spaces are obtained.\nSpecifically, for metric spaces with a bounded VC or doubling dimension $d$,\nthe coreset size is $O(m) + \\tilde{O}(kd\\varepsilon^{-2})$, which is optimal up\nto logarithmic factors. For Euclidean spaces, the coreset size is\n$O(m\\varepsilon^{-1}) +\n\\tilde{O}(\\min\\{k^{4/3}\\varepsilon^{-2},k\\varepsilon^{-3}\\})$, improving upon a\nrecent result by Jiang and Lou (ICALP 2025). These results also extend to\nrobust $(k,z)$-clustering, yielding, for VC and doubling dimension, a coreset\nsize of $O(m) + \\tilde{O}(kd\\varepsilon^{-2z})$ with the optimal linear\ndependence on $m$. This extended result improves upon the earlier work of Huang\net al. (SODA 2025). The techniques introduce novel dataset decompositions,\nenabling chaining arguments to be applied jointly across multiple components.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11260v1", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11412", "title": "Seq vs Seq: An Open Suite of Paired Encoders and Decoders", "authors": ["Orion Weller", "Kathryn Ricci", "Marc Marone", "Antoine Chaffin", "Dawn Lawrie", "Benjamin Van Durme"], "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11412v1", "summary": "The large language model (LLM) community focuses almost exclusively on\ndecoder-only language models, since they are easier to use for text generation.\nHowever, a large subset of the community still uses encoder-only models for\ntasks such as classification or retrieval. Previous work has attempted to\ncompare these architectures, but is forced to make comparisons with models that\nhave different numbers of parameters, training techniques, and datasets. We\nintroduce the SOTA open-data Ettin suite of models: paired encoder-only and\ndecoder-only models ranging from 17 million parameters to 1 billion, trained on\nup to 2 trillion tokens. Using the same recipe for both encoder-only and\ndecoder-only models produces SOTA recipes in both categories for their\nrespective sizes, beating ModernBERT as an encoder and Llama 3.2 and SmolLM2 as\ndecoders. Like previous work, we find that encoder-only models excel at\nclassification and retrieval tasks while decoders excel at generative tasks.\nHowever, we show that adapting a decoder model to encoder tasks (and vice\nversa) through continued training is subpar compared to using only the reverse\nobjective (i.e. a 400M encoder outperforms a 1B decoder on MNLI, and vice versa\nfor generative tasks). We open-source all artifacts of this study including\ntraining data, training order segmented by checkpoint, and 200+ checkpoints to\nallow future work to analyze or extend all aspects of training.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11412v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10560", "title": "Tangma: A Tanh-Guided Activation Function with Learnable Parameters", "authors": ["Shreel Golwala"], "categories": ["cs.NE", "cs.LG"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10560v1", "summary": "Activation functions are key to effective backpropagation and expressiveness\nin deep neural networks. This work introduces Tangma, a new activation function\nthat combines the smooth shape of the hyperbolic tangent with two learnable\nparameters: $\\alpha$, which shifts the curve's inflection point to adjust\nneuron activation, and $\\gamma$, which adds linearity to preserve weak\ngradients and improve training stability. Tangma was evaluated on MNIST and\nCIFAR-10 using custom networks composed of convolutional and linear layers, and\ncompared against ReLU, Swish, and GELU. On MNIST, Tangma achieved the highest\nvalidation accuracy of 99.09% and the lowest validation loss, demonstrating\nfaster and more stable convergence than the baselines. On CIFAR-10, Tangma\nreached a top validation accuracy of 78.15%, outperforming all other activation\nfunctions while maintaining a competitive training loss. Tangma also showed\nimproved training efficiency, with lower average epoch runtimes compared to\nSwish and GELU. These results suggest that Tangma performs well on standard\nvision tasks and enables reliable, efficient training. Its learnable design\ngives more control over activation behavior, which may benefit larger models in\ntasks such as image recognition or language modeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10560v1", "cate": "cs.NE", "date": "2025-07-02", "updated": "2025-07-02"}
{"id": "2507.11407", "title": "EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes", "authors": ["LG AI Research", ":", "Kyunghoon Bae", "Eunbi Choi", "Kibong Choi", "Stanley Jungkyu Choi", "Yemuk Choi", "Kyubeen Han", "Seokhee Hong", "Junwon Hwang", "Taewan Hwang", "Joonwon Jang", "Hyojin Jeon", "Kijeong Jeon", "Gerrard Jeongwon Jo", "Hyunjik Jo", "Jiyeon Jung", "Euisoon Kim", "Hyosang Kim", "Jihoon Kim", "Joonkee Kim", "Seonghwan Kim", "Soyeon Kim", "Sunkyoung Kim", "Yireun Kim", "Yongil Kim", "Youchul Kim", "Edward Hwayoung Lee", "Gwangho Lee", "Haeju Lee", "Honglak Lee", "Jinsik Lee", "Kyungmin Lee", "Sangha Park", "Young Min Paik", "Yongmin Park", "Youngyong Park", "Sanghyun Seo", "Sihoon Yang", "Heuiyeen Yeen", "Sihyuk Yi", "Hyeongu Yun"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Technical Report, 30 Pages", "url": "http://arxiv.org/abs/2507.11407v1", "summary": "This technical report introduces EXAONE 4.0, which integrates a Non-reasoning\nmode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5\nand the advanced reasoning abilities of EXAONE Deep. To pave the way for the\nagentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool\nuse, and its multilingual capabilities are extended to support Spanish in\naddition to English and Korean. The EXAONE 4.0 model series consists of two\nsizes: a mid-size 32B model optimized for high performance, and a small-size\n1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates\nsuperior performance compared to open-weight models in its class and remains\ncompetitive even against frontier-class models. The models are publicly\navailable for research purposes and can be easily downloaded via\nhttps://huggingface.co/LGAI-EXAONE.", "comment": "Technical Report, 30 Pages", "pdf_url": "http://arxiv.org/pdf/2507.11407v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11357", "title": "Neurosymbolic Reasoning Shortcuts under the Independence Assumption", "authors": ["Emile van Krieken", "Pasquale Minervini", "Edoardo Ponti", "Antonio Vergari"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at NeSy 2025", "url": "http://arxiv.org/abs/2507.11357v1", "summary": "The ubiquitous independence assumption among symbolic concepts in\nneurosymbolic (NeSy) predictors is a convenient simplification: NeSy predictors\nuse it to speed up probabilistic reasoning. Recent works like van Krieken et\nal. (2024) and Marconato et al. (2024) argued that the independence assumption\ncan hinder learning of NeSy predictors and, more crucially, prevent them from\ncorrectly modelling uncertainty. There is, however, scepticism in the NeSy\ncommunity around the scenarios in which the independence assumption actually\nlimits NeSy systems (Faronius and Dos Martires, 2025). In this work, we settle\nthis question by formally showing that assuming independence among symbolic\nconcepts entails that a model can never represent uncertainty over certain\nconcept combinations. Thus, the model fails to be aware of reasoning shortcuts,\ni.e., the pathological behaviour of NeSy predictors that predict correct\ndownstream tasks but for the wrong reasons.", "comment": "Accepted at NeSy 2025", "pdf_url": "http://arxiv.org/pdf/2507.11357v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11441", "title": "Implementing Adaptations for Vision AutoRegressive Model", "authors": ["Kaif Shaikh", "Antoni Kowalczuk", "Franziska Boenisch", "Adam Dziedzic"], "categories": ["cs.CV", "cs.LG", "I.2.6; I.5.1; I.4.8; I.2.10"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at DIG-BUGS: Data in Generative Models Workshop @ ICML 2025", "url": "http://arxiv.org/abs/2507.11441v1", "summary": "Vision AutoRegressive model (VAR) was recently introduced as an alternative\nto Diffusion Models (DMs) in image generation domain. In this work we focus on\nits adaptations, which aim to fine-tune pre-trained models to perform specific\ndownstream tasks, like medical data generation. While for DMs there exist many\ntechniques, adaptations for VAR remain underexplored. Similarly, differentially\nprivate (DP) adaptations-ones that aim to preserve privacy of the adaptation\ndata-have been extensively studied for DMs, while VAR lacks such solutions. In\nour work, we implement and benchmark many strategies for VAR, and compare them\nto state-of-the-art DM adaptation strategies. We observe that VAR outperforms\nDMs for non-DP adaptations, however, the performance of DP suffers, which\nnecessitates further research in private adaptations for VAR. Code is available\nat https://github.com/sprintml/finetuning_var_dp.", "comment": "Accepted at DIG-BUGS: Data in Generative Models Workshop @ ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.11441v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11084", "title": "Social Media Sentiments Analysis on the July Revolution in Bangladesh: A Hybrid Transformer Based Machine Learning Approach", "authors": ["Md. Sabbir Hossen", "Md. Saiduzzaman", "Pabon Shaha"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      This paper has been accepted and presented at the IEEE ECAI 2025. The final version will be available in the IEEE Xplore Digital Library", "url": "http://arxiv.org/abs/2507.11084v1", "summary": "The July Revolution in Bangladesh marked a significant student-led mass\nuprising, uniting people across the nation to demand justice, accountability,\nand systemic reform. Social media platforms played a pivotal role in amplifying\npublic sentiment and shaping discourse during this historic mass uprising. In\nthis study, we present a hybrid transformer-based sentiment analysis framework\nto decode public opinion expressed in social media comments during and after\nthe revolution. We used a brand new dataset of 4,200 Bangla comments collected\nfrom social media. The framework employs advanced transformer-based feature\nextraction techniques, including BanglaBERT, mBERT, XLM-RoBERTa, and the\nproposed hybrid XMB-BERT, to capture nuanced patterns in textual data.\nPrinciple Component Analysis (PCA) were utilized for dimensionality reduction\nto enhance computational efficiency. We explored eleven traditional and\nadvanced machine learning classifiers for identifying sentiments. The proposed\nhybrid XMB-BERT with the voting classifier achieved an exceptional accuracy of\n83.7% and outperform other model classifier combinations. This study\nunderscores the potential of machine learning techniques to analyze social\nsentiment in low-resource languages like Bangla.", "comment": "This paper has been accepted and presented at the IEEE ECAI 2025. The\n  final version will be available in the IEEE Xplore Digital Library", "pdf_url": "http://arxiv.org/pdf/2507.11084v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11291", "title": "Permutation patterns in streams", "authors": ["Benjamin Aram Berendsohn"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11291v1", "summary": "Permutation patterns and pattern avoidance are central, well-studied concepts\nin combinatorics and computer science. Given two permutations $\\tau$ and $\\pi$,\nthe pattern matching problem (PPM) asks whether $\\tau$ contains $\\pi$. This\nproblem arises in various contexts in computer science and statistics and has\nbeen studied extensively in exact-, parameterized-, approximate-,\nproperty-testing- and other formulations.\n  In this paper, we study pattern matching in a \\emph{streaming setting}, when\nthe input $\\tau$ is revealed sequentially, one element at a time. There is\nextensive work on the space complexity of various statistics in streams of\nintegers. The novelty of our setting is that the input stream is \\emph{a\npermutation}, which allows inferring some information about future inputs. Our\nalgorithms crucially take advantage of this fact, while existing lower bound\ntechniques become difficult to apply.\n  We show that the complexity of the problem changes dramatically depending on\nthe pattern~$\\pi$. The space requirement is: $\\Theta(k\\log{n})$ for the\nmonotone patterns $\\pi = 12\\dots k$, or $\\pi = k\\dots21$, $O(\\sqrt{n\\log{n}})$\nfor $\\pi \\in \\{312,132\\}$, $O(\\sqrt{n} \\log n)$ for $\\pi \\in \\{231,213\\}$, and\n$\\widetilde{\\Theta}_{\\pi}(n)$ for all other $\\pi$. If $\\tau$ is an arbitrary\nsequence of integers (not necessary a permutation), we show that the complexity\nis $\\widetilde{\\Theta}_{\\pi}(n)$ in all except the first (monotone) cases.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11291v1", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2403.06372", "title": "Repeated Padding+: Simple yet Effective Data Augmentation Plugin for Sequential Recommendation", "authors": ["Yizhou Dang", "Yuting Liu", "Enneng Yang", "Guibing Guo", "Linying Jiang", "Jianzhe Zhao", "Xingwei Wang"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      v1: Initial Version, v2:Accepted by RecSys 2024, v3:Extended Version Under Review", "url": "http://arxiv.org/abs/2403.06372v3", "summary": "Sequential recommendation aims to provide users with personalized suggestions\nbased on their historical interactions. When training sequential models,\npadding is a widely adopted technique for two main reasons: 1) The vast\nmajority of models can only handle fixed-length sequences; 2) Batching-based\ntraining needs to ensure that the sequences in each batch have the same length.\nThe special value \\emph{0} is usually used as the padding content, which does\nnot contain the actual information and is ignored in the model calculations.\nThis common-sense padding strategy leads us to a problem that has never been\nexplored before: Can we fully utilize this idle input space by padding other\ncontent to further improve model performance and training efficiency?\n  In this work, we propose a simple yet effective padding method called\nRepeated Padding+ (RepPad+). Specifically, we use the original interaction\nsequences as the padding content and fill it to the padding positions during\nmodel training. This operation can be performed a finite number of times or\nrepeated until the input sequences' length reaches the maximum limit. For those\nsequences that can not pad full original data, we draw inspiration from the\nSliding Windows strategy and intercept consecutive subsequences to fill in the\nidle space. Our RepPad+ can be viewed as a sequence-level data augmentation\nstrategy. Unlike most existing works, our method contains no trainable\nparameters or hyperparameters and is a plug-and-play data augmentation\noperation. Extensive experiments on various categories of sequential models and\nseven real-world datasets demonstrate the effectiveness and efficiency of our\napproach. The average recommendation performance improvement is up to 84.11% on\nGRU4Rec and 35.34% on SASRec. We also provide in-depth analysis and explanation\nof what makes RepPad+ effective from multiple perspectives.", "comment": "v1: Initial Version, v2:Accepted by RecSys 2024, v3:Extended Version\n  Under Review", "pdf_url": "http://arxiv.org/pdf/2403.06372v3", "cate": "cs.IR", "date": "2024-03-11", "updated": "2025-07-15"}
{"id": "2507.10561", "title": "SFATTI: Spiking FPGA Accelerator for Temporal Task-driven Inference -- A Case Study on MNIST", "authors": ["Alessio Caviglia", "Filippo Marostica", "Alessio Carpegna", "Alessandro Savino", "Stefano Di Carlo"], "categories": ["cs.NE", "cs.CV"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10561v1", "summary": "Hardware accelerators are essential for achieving low-latency,\nenergy-efficient inference in edge applications like image recognition. Spiking\nNeural Networks (SNNs) are particularly promising due to their event-driven and\ntemporally sparse nature, making them well-suited for low-power Field\nProgrammable Gate Array (FPGA)-based deployment. This paper explores using the\nopen-source Spiker+ framework to generate optimized SNNs accelerators for\nhandwritten digit recognition on the MNIST dataset. Spiker+ enables high-level\nspecification of network topologies, neuron models, and quantization,\nautomatically generating deployable HDL. We evaluate multiple configurations\nand analyze trade-offs relevant to edge computing constraints.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10561v1", "cate": "cs.NE", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.11408", "title": "KisMATH: Do LLMs Have Knowledge of Implicit Structures in Mathematical Reasoning?", "authors": ["Soumadeep Saha", "Akshay Chaturvedi", "Saptarshi Saha", "Utpal Garain", "Nicholas Asher"], "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      15 pages, 9 figures", "url": "http://arxiv.org/abs/2507.11408v1", "summary": "Chain-of-thought traces have been shown to improve performance of large\nlanguage models in a plethora of reasoning tasks, yet there is no consensus on\nthe mechanism through which this performance boost is achieved. To shed more\nlight on this, we introduce Causal CoT Graphs (CCGs), which are directed\nacyclic graphs automatically extracted from reasoning traces that model\nfine-grained causal dependencies in the language model output. A collection of\n$1671$ mathematical reasoning problems from MATH500, GSM8K and AIME, and their\nassociated CCGs are compiled into our dataset -- \\textbf{KisMATH}. Our detailed\nempirical analysis with 15 open-weight LLMs shows that (i) reasoning nodes in\nthe CCG are mediators for the final answer, a condition necessary for\nreasoning; and (ii) LLMs emphasise reasoning paths given by the CCG, indicating\nthat models internally realise structures akin to our graphs. KisMATH enables\ncontrolled, graph-aligned interventions and opens up avenues for further\ninvestigation into the role of chain-of-thought in LLM reasoning.", "comment": "15 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.11408v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11393", "title": "A Neural Network Model of Complementary Learning Systems: Pattern Separation and Completion for Continual Learning", "authors": ["James P Jun", "Vijay Marupudi", "Raj Sanjay Shah", "Sashank Varma"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to CogSci 2025. 7 pages, 7 figures", "url": "http://arxiv.org/abs/2507.11393v1", "summary": "Learning new information without forgetting prior knowledge is central to\nhuman intelligence. In contrast, neural network models suffer from catastrophic\nforgetting: a significant degradation in performance on previously learned\ntasks when acquiring new information. The Complementary Learning Systems (CLS)\ntheory offers an explanation for this human ability, proposing that the brain\nhas distinct systems for pattern separation (encoding distinct memories) and\npattern completion (retrieving complete memories from partial cues). To capture\nthese complementary functions, we leverage the representational generalization\ncapabilities of variational autoencoders (VAEs) and the robust memory storage\nproperties of Modern Hopfield networks (MHNs), combining them into a neurally\nplausible continual learning model. We evaluate this model on the Split-MNIST\ntask, a popular continual learning benchmark, and achieve close to\nstate-of-the-art accuracy (~90%), substantially reducing forgetting.\nRepresentational analyses empirically confirm the functional dissociation: the\nVAE underwrites pattern completion, while the MHN drives pattern separation. By\ncapturing pattern separation and completion in scalable architectures, our work\nprovides a functional template for modeling memory consolidation,\ngeneralization, and continual learning in both biological and artificial\nsystems.", "comment": "Accepted to CogSci 2025. 7 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.11393v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11443", "title": "COLI: A Hierarchical Efficient Compressor for Large Images", "authors": ["Haoran Wang", "Hanyu Pei", "Yang Lyu", "Kai Zhang", "Li Li", "Feng-Lei Fan"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11443v1", "summary": "The escalating adoption of high-resolution, large-field-of-view imagery\namplifies the need for efficient compression methodologies. Conventional\ntechniques frequently fail to preserve critical image details, while\ndata-driven approaches exhibit limited generalizability. Implicit Neural\nRepresentations (INRs) present a promising alternative by learning continuous\nmappings from spatial coordinates to pixel intensities for individual images,\nthereby storing network weights rather than raw pixels and avoiding the\ngeneralization problem. However, INR-based compression of large images faces\nchallenges including slow compression speed and suboptimal compression ratios.\nTo address these limitations, we introduce COLI (Compressor for Large Images),\na novel framework leveraging Neural Representations for Videos (NeRV). First,\nrecognizing that INR-based compression constitutes a training process, we\naccelerate its convergence through a pretraining-finetuning paradigm,\nmixed-precision training, and reformulation of the sequential loss into a\nparallelizable objective. Second, capitalizing on INRs' transformation of image\nstorage constraints into weight storage, we implement Hyper-Compression, a\nnovel post-training technique to substantially enhance compression ratios while\nmaintaining minimal output distortion. Evaluations across two medical imaging\ndatasets demonstrate that COLI consistently achieves competitive or superior\nPSNR and SSIM metrics at significantly reduced bits per pixel (bpp), while\naccelerating NeRV training by up to 4 times.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11443v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11086", "title": "Beyond Traditional Algorithms: Leveraging LLMs for Accurate Cross-Border Entity Identification", "authors": ["Andres Azqueta-Gavaldón", "Joaquin Ramos Cosgrove"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11086v1", "summary": "The growing prevalence of cross-border financial activities in global markets\nhas underscored the necessity of accurately identifying and classifying foreign\nentities. This practice is essential within the Spanish financial system for\nensuring robust risk management, regulatory adherence, and the prevention of\nfinancial misconduct. This process involves a labor-intensive entity-matching\ntask, where entities need to be validated against available reference sources.\nChallenges arise from linguistic variations, special characters, outdated\nnames, and changes in legal forms, complicating traditional matching algorithms\nlike Jaccard, cosine, and Levenshtein distances. These methods struggle with\ncontextual nuances and semantic relationships, leading to mismatches. To\naddress these limitations, we explore Large Language Models (LLMs) as a\nflexible alternative. LLMs leverage extensive training to interpret context,\nhandle abbreviations, and adapt to legal transitions. We evaluate traditional\nmethods, Hugging Face-based LLMs, and interface-based LLMs (e.g., Microsoft\nCopilot, Alibaba's Qwen 2.5) using a dataset of 65 Portuguese company cases.\nResults show traditional methods achieve accuracies over 92% but suffer high\nfalse positive rates (20-40%). Interface-based LLMs outperform, achieving\naccuracies above 93%, F1 scores exceeding 96%, and lower false positives\n(40-80%).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11086v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11311", "title": "Scheduling on Identical Machines with Setup Time and Unknown Execution Time", "authors": ["Yasushi Kawase", "Kazuhisa Makino", "Vinh Long Phan", "Hanna Sumita"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Accepted to the 19th Algorithms and Data Structures Symposium (WADS 2025)", "url": "http://arxiv.org/abs/2507.11311v1", "summary": "In this study, we investigate a scheduling problem on identical machines in\nwhich jobs require initial setup before execution. We assume that an algorithm\ncan dynamically form a batch (i.e., a collection of jobs to be processed\ntogether) from the remaining jobs. The setup time is modeled as a known\nmonotone function of the set of jobs within a batch, while the execution time\nof each job remains unknown until completion. This uncertainty poses\nsignificant challenges for minimizing the makespan. We address these challenges\nby considering two scenarios: each job batch must be assigned to a single\nmachine, or a batch may be distributed across multiple machines. For both\nscenarios, we analyze settings with and without preemption. Across these four\nsettings, we design online algorithms that achieve asymptotically optimal\ncompetitive ratios with respect to both the number of jobs and the number of\nmachines.", "comment": "Accepted to the 19th Algorithms and Data Structures Symposium (WADS\n  2025)", "pdf_url": "http://arxiv.org/pdf/2507.11311v1", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2406.17507", "title": "CART: A Generative Cross-Modal Retrieval Framework with Coarse-To-Fine Semantic Modeling", "authors": ["Minghui Fang", "Shengpeng Ji", "Jialong Zuo", "Hai Huang", "Yan Xia", "Jieming Zhu", "Xize Cheng", "Xiaoda Yang", "Wenrui Liu", "Gang Wang", "Zhenhua Dong", "Zhou Zhao"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      ACL 2025 Main", "url": "http://arxiv.org/abs/2406.17507v2", "summary": "Cross-modal retrieval aims to search for instances, which are semantically\nrelated to the query through the interaction of different modal data.\nTraditional solutions utilize a single-tower or dual-tower framework to\nexplicitly compute the score between queries and candidates, which is\nchallenged by training cost and inference latency with large-scale data.\nInspired by the remarkable performance and efficiency of generative models, we\npropose a generative cross-modal retrieval framework (CART) based on\ncoarse-to-fine semantic modeling, which assigns identifiers to each candidate\nand treats the generating identifier as the retrieval target. Specifically, we\nexplore an effective coarse-to-fine scheme, combining K-Means and RQ-VAE to\ndiscretize multimodal data into token sequences that support autoregressive\ngeneration. Further, considering the lack of explicit interaction between\nqueries and candidates, we propose a feature fusion strategy to align their\nsemantics. Extensive experiments demonstrate the effectiveness of the\nstrategies in the CART, achieving excellent results in both retrieval\nperformance and efficiency.", "comment": "ACL 2025 Main", "pdf_url": "http://arxiv.org/pdf/2406.17507v2", "cate": "cs.IR", "date": "2024-06-25", "updated": "2025-07-15"}
{"id": "2507.10568", "title": "An Exact Gradient Framework for Training Spiking Neural Networks", "authors": ["Arman Ferdowsi", "Atakan Aral"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10568v1", "summary": "Spiking neural networks inherently rely on the precise timing of discrete\nspike events for information processing. Incorporating additional bio-inspired\ndegrees of freedom, such as trainable synaptic transmission delays and adaptive\nfiring thresholds, is essential for fully leveraging the temporal dynamics of\nSNNs. Although recent methods have demonstrated the benefits of training\nsynaptic weights and delays, both in terms of accuracy and temporal\nrepresentation, these techniques typically rely on discrete-time simulations,\nsurrogate gradient approximations, or full access to internal state variables\nsuch as membrane potentials. Such requirements limit training precision and\nefficiency and pose challenges for neuromorphic hardware implementation due to\nincreased memory and I/O bandwidth demands. To overcome these challenges, we\npropose an analytical event-driven learning framework that computes exact loss\ngradients not only with respect to synaptic weights and transmission delays but\nalso to adaptive neuronal firing thresholds. Experiments on multiple benchmarks\ndemonstrate significant gains in accuracy (up to 7%), timing precision, and\nrobustness compared to existing methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10568v1", "cate": "cs.NE", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.11436", "title": "Toward Improving fNIRS Classification: A Study on Activation Functions in Deep Neural Architectures", "authors": ["Behtom Adeli", "John McLinden", "Pankaj Pandey", "Ming Shao", "Yalda Shahriari"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11436v1", "summary": "Activation functions are critical to the performance of deep neural networks,\nparticularly in domains such as functional near-infrared spectroscopy (fNIRS),\nwhere nonlinearity, low signal-to-noise ratio (SNR), and signal variability\nposes significant challenges to model accuracy. However, the impact of\nactivation functions on deep learning (DL) performance in the fNIRS domain\nremains underexplored and lacks systematic investigation in the current\nliterature. This study evaluates a range of conventional and field-specific\nactivation functions for fNIRS classification tasks using multiple deep\nlearning architectures, including the domain-specific fNIRSNet, AbsoluteNet,\nMDNN, and shallowConvNet (as the baseline), all tested on a single dataset\nrecorded during an auditory task. To ensure fair a comparison, all networks\nwere trained and tested using standardized preprocessing and consistent\ntraining parameters. The results show that symmetrical activation functions\nsuch as Tanh and the Absolute value function Abs(x) can outperform commonly\nused functions like the Rectified Linear Unit (ReLU), depending on the\narchitecture. Additionally, a focused analysis of the role of symmetry was\nconducted using a Modified Absolute Function (MAF), with results further\nsupporting the effectiveness of symmetrical activation functions on performance\ngains. These findings underscore the importance of selecting proper activation\nfunctions that align with the signal characteristics of fNIRS data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11436v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11411", "title": "Robust-Multi-Task Gradient Boosting", "authors": ["Seyedsaman Emami", "Gonzalo Martínez-Muñoz", "Daniel Hernández-Lobato"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11411v1", "summary": "Multi-task learning (MTL) has shown effectiveness in exploiting shared\ninformation across tasks to improve generalization. MTL assumes tasks share\nsimilarities that can improve performance. In addition, boosting algorithms\nhave demonstrated exceptional performance across diverse learning problems,\nprimarily due to their ability to focus on hard-to-learn instances and\niteratively reduce residual errors. This makes them a promising approach for\nlearning multi-task problems. However, real-world MTL scenarios often involve\ntasks that are not well-aligned (known as outlier or adversarial tasks), which\ndo not share beneficial similarities with others and can, in fact, deteriorate\nthe performance of the overall model. To overcome this challenge, we propose\nRobust-Multi-Task Gradient Boosting (R-MTGB), a novel boosting framework that\nexplicitly models and adapts to task heterogeneity during training. R-MTGB\nstructures the learning process into three sequential blocks: (1) learning\nshared patterns, (2) partitioning tasks into outliers and non-outliers with\nregularized parameters, and (3) fine-tuning task-specific predictors. This\narchitecture enables R-MTGB to automatically detect and penalize outlier tasks\nwhile promoting effective knowledge transfer among related tasks. Our method\nintegrates these mechanisms seamlessly within gradient boosting, allowing\nrobust handling of noisy or adversarial tasks without sacrificing accuracy.\nExtensive experiments on both synthetic benchmarks and real-world datasets\ndemonstrate that our approach successfully isolates outliers, transfers\nknowledge, and consistently reduces prediction errors for each task\nindividually, and achieves overall performance gains across all tasks. These\nresults highlight robustness, adaptability, and reliable convergence of R-MTGB\nin challenging MTL environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11411v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11474", "title": "HUG-VAS: A Hierarchical NURBS-Based Generative Model for Aortic Geometry Synthesis and Controllable Editing", "authors": ["Pan Du", "Mingqi Xu", "Xiaozhi Zhu", "Jian-xun Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      59 pages, 9 figures", "url": "http://arxiv.org/abs/2507.11474v1", "summary": "Accurate characterization of vascular geometry is essential for\ncardiovascular diagnosis and treatment planning. Traditional statistical shape\nmodeling (SSM) methods rely on linear assumptions, limiting their expressivity\nand scalability to complex topologies such as multi-branch vascular structures.\nWe introduce HUG-VAS, a Hierarchical NURBS Generative model for Vascular\ngeometry Synthesis, which integrates NURBS surface parameterization with\ndiffusion-based generative modeling to synthesize realistic, fine-grained\naortic geometries. Trained with 21 patient-specific samples, HUG-VAS generates\nanatomically faithful aortas with supra-aortic branches, yielding biomarker\ndistributions that closely match those of the original dataset. HUG-VAS adopts\na hierarchical architecture comprising a denoising diffusion model that\ngenerates centerlines and a guided diffusion model that synthesizes radial\nprofiles conditioned on those centerlines, thereby capturing two layers of\nanatomical variability. Critically, the framework supports zero-shot\nconditional generation from image-derived priors, enabling practical\napplications such as interactive semi-automatic segmentation, robust\nreconstruction under degraded imaging conditions, and implantable device\noptimization. To our knowledge, HUG-VAS is the first SSM framework to bridge\nimage-derived priors with generative shape modeling via a unified integration\nof NURBS parameterization and hierarchical diffusion processes.", "comment": "59 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.11474v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11097", "title": "The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs", "authors": ["Zichen Wen", "Jiashu Qu", "Dongrui Liu", "Zhiyuan Liu", "Ruixi Wu", "Yicun Yang", "Xiangqi Jin", "Haoyun Xu", "Xuyang Liu", "Weijia Li", "Chaochao Lu", "Jing Shao", "Conghui He", "Linfeng Zhang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      21 pages, 9 figures, work in progress", "url": "http://arxiv.org/abs/2507.11097v1", "summary": "Diffusion-based large language models (dLLMs) have recently emerged as a\npowerful alternative to autoregressive LLMs, offering faster inference and\ngreater interactivity via parallel decoding and bidirectional modeling.\nHowever, despite strong performance in code generation and text infilling, we\nidentify a fundamental safety concern: existing alignment mechanisms fail to\nsafeguard dLLMs against context-aware, masked-input adversarial prompts,\nexposing novel vulnerabilities. To this end, we present DIJA, the first\nsystematic study and jailbreak attack framework that exploits unique safety\nweaknesses of dLLMs. Specifically, our proposed DIJA constructs adversarial\ninterleaved mask-text prompts that exploit the text generation mechanisms of\ndLLMs, i.e., bidirectional modeling and parallel decoding. Bidirectional\nmodeling drives the model to produce contextually consistent outputs for masked\nspans, even when harmful, while parallel decoding limits model dynamic\nfiltering and rejection sampling of unsafe content. This causes standard\nalignment mechanisms to fail, enabling harmful completions in alignment-tuned\ndLLMs, even when harmful behaviors or unsafe instructions are directly exposed\nin the prompt. Through comprehensive experiments, we demonstrate that DIJA\nsignificantly outperforms existing jailbreak methods, exposing a previously\noverlooked threat surface in dLLM architectures. Notably, our method achieves\nup to 100% keyword-based ASR on Dream-Instruct, surpassing the strongest prior\nbaseline, ReNeLLM, by up to 78.5% in evaluator-based ASR on JailbreakBench and\nby 37.7 points in StrongREJECT score, while requiring no rewriting or hiding of\nharmful content in the jailbreak prompt. Our findings underscore the urgent\nneed for rethinking safety alignment in this emerging class of language models.\nCode is available at https://github.com/ZichenWen1/DIJA.", "comment": "21 pages, 9 figures, work in progress", "pdf_url": "http://arxiv.org/pdf/2507.11097v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11484", "title": "Multipass Linear Sketches for Geometric LP-Type Problems", "authors": ["N. Efe Çekirge", "William Gay", "David P. Woodruff"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      To Appear in APPROX 2025, 45 pages", "url": "http://arxiv.org/abs/2507.11484v1", "summary": "LP-type problems such as the Minimum Enclosing Ball (MEB), Linear Support\nVector Machine (SVM), Linear Programming (LP), and Semidefinite Programming\n(SDP) are fundamental combinatorial optimization problems, with many important\napplications in machine learning applications such as classification,\nbioinformatics, and noisy learning. We study LP-type problems in several\nstreaming and distributed big data models, giving $\\varepsilon$-approximation\nlinear sketching algorithms with a focus on the high accuracy regime with low\ndimensionality $d$, that is, when ${d < (1/\\varepsilon)^{0.999}}$. Our main\nresult is an $O(ds)$ pass algorithm with $O(s( \\sqrt{d}/\\varepsilon)^{3d/s})\n\\cdot \\mathrm{poly}(d, \\log (1/\\varepsilon))$ space complexity in words, for\nany parameter $s \\in [1, d \\log (1/\\varepsilon)]$, to solve\n$\\varepsilon$-approximate LP-type problems of $O(d)$ combinatorial and VC\ndimension. Notably, by taking $s = d \\log (1/\\varepsilon)$, we achieve space\ncomplexity polynomial in $d$ and polylogarithmic in $1/\\varepsilon$, presenting\nexponential improvements in $1/\\varepsilon$ over current algorithms. We\ncomplement our results by showing lower bounds of $(1/\\varepsilon)^{\\Omega(d)}$\nfor any $1$-pass algorithm solving the $(1 + \\varepsilon)$-approximation MEB\nand linear SVM problems, further motivating our multi-pass approach.", "comment": "To Appear in APPROX 2025, 45 pages", "pdf_url": "http://arxiv.org/pdf/2507.11484v1", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2409.15346", "title": "Big data searching using words", "authors": ["Santanu Acharjee", "Ripunjoy Choudhury"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      accepted for publication, Acceptance month: July, 2025", "url": "http://arxiv.org/abs/2409.15346v3", "summary": "Big data analytics is one of the most promising areas of new research and\ndevelopment in computer science, enterprises, e-commerce, and defense. For many\norganizations, big data is considered one of their most important strategic\nassets. This explosive growth has made it necessary to develop effective\ntechniques for examining and analyzing big data from mathematical perspectives.\nAmong various methods of analyzing big data, topological data analysis (TDA) is\nnow considered one of the useful tools. However, there is no fundamental\nconcept related to the topological structure in big data. In this paper, we\npresent fundamental concepts related to the neighborhood structures of words in\nbig data search, laying the groundwork for developing topological frameworks\nfor big data in the future. We also introduce the notion of big data primal\nwithin the context of big data search and explore how neighborhood structures,\ncombined with the Jaccard similarity coefficient, can be utilized to detect\nanomalies in search behavior.", "comment": "accepted for publication, Acceptance month: July, 2025", "pdf_url": "http://arxiv.org/pdf/2409.15346v3", "cate": "cs.IR", "date": "2024-09-10", "updated": "2025-07-15"}
{"id": "2507.10722", "title": "Bridging Brains and Machines: A Unified Frontier in Neuroscience, Artificial Intelligence, and Neuromorphic Systems", "authors": ["Sohan Shankar", "Yi Pan", "Hanqi Jiang", "Zhengliang Liu", "Mohammad R. Darbandi", "Agustin Lorenzo", "Junhao Chen", "Md Mehedi Hasan", "Arif Hassan Zidan", "Eliana Gelman", "Joshua A. Konfrst", "Jillian Y. Russell", "Katelyn Fernandes", "Tianze Yang", "Yiwei Li", "Huaqin Zhao", "Afrar Jahin", "Triparna Ganguly", "Shair Dinesha", "Yifan Zhou", "Zihao Wu", "Xinliang Li", "Lokesh Adusumilli", "Aziza Hussein", "Sagar Nookarapu", "Jixin Hou", "Kun Jiang", "Jiaxi Li", "Brenden Heinel", "XianShen Xi", "Hailey Hubbard", "Zayna Khan", "Levi Whitaker", "Ivan Cao", "Max Allgaier", "Andrew Darby", "Lin Zhao", "Lu Zhang", "Xiaoqiao Wang", "Xiang Li", "Wei Zhang", "Xiaowei Yu", "Dajiang Zhu", "Yohannes Abate", "Tianming Liu"], "categories": ["q-bio.NC", "cs.NE"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10722v1", "summary": "This position and survey paper identifies the emerging convergence of\nneuroscience, artificial general intelligence (AGI), and neuromorphic computing\ntoward a unified research paradigm. Using a framework grounded in brain\nphysiology, we highlight how synaptic plasticity, sparse spike-based\ncommunication, and multimodal association provide design principles for\nnext-generation AGI systems that potentially combine both human and machine\nintelligences. The review traces this evolution from early connectionist models\nto state-of-the-art large language models, demonstrating how key innovations\nlike transformer attention, foundation-model pre-training, and multi-agent\narchitectures mirror neurobiological processes like cortical mechanisms,\nworking memory, and episodic consolidation. We then discuss emerging physical\nsubstrates capable of breaking the von Neumann bottleneck to achieve\nbrain-scale efficiency in silicon: memristive crossbars, in-memory compute\narrays, and emerging quantum and photonic devices. There are four critical\nchallenges at this intersection: 1) integrating spiking dynamics with\nfoundation models, 2) maintaining lifelong plasticity without catastrophic\nforgetting, 3) unifying language with sensorimotor learning in embodied agents,\nand 4) enforcing ethical safeguards in advanced neuromorphic autonomous\nsystems. This combined perspective across neuroscience, computation, and\nhardware offers an integrative agenda for in each of these fields.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10722v1", "cate": "q-bio.NC", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11488", "title": "COLIBRI Fuzzy Model: Color Linguistic-Based Representation and Interpretation", "authors": ["Pakizar Shamoi", "Nuray Toganas", "Muragul Muratbekova", "Elnara Kadyrgali", "Adilet Yerkin", "Ayan Igali", "Malika Ziyada", "Ayana Adilova", "Aron Karatayev", "Yerdauit Torekhan"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      submitted to IEEE for consideration", "url": "http://arxiv.org/abs/2507.11488v1", "summary": "Colors are omnipresent in today's world and play a vital role in how humans\nperceive and interact with their surroundings. However, it is challenging for\ncomputers to imitate human color perception. This paper introduces the Human\nPerception-Based Fuzzy Color Model, COLIBRI (Color Linguistic-Based\nRepresentation and Interpretation), designed to bridge the gap between\ncomputational color representations and human visual perception. The proposed\nmodel uses fuzzy sets and logic to create a framework for color categorization.\nUsing a three-phase experimental approach, the study first identifies\ndistinguishable color stimuli for hue, saturation, and intensity through\npreliminary experiments, followed by a large-scale human categorization survey\ninvolving more than 1000 human subjects. The resulting data are used to extract\nfuzzy partitions and generate membership functions that reflect real-world\nperceptual uncertainty. The model incorporates a mechanism for adaptation that\nallows refinement based on feedback and contextual changes. Comparative\nevaluations demonstrate the model's alignment with human perception compared to\ntraditional color models, such as RGB, HSV, and LAB. To the best of our\nknowledge, no previous research has documented the construction of a model for\ncolor attribute specification based on a sample of this size or a comparable\nsample of the human population (n = 2496). Our findings are significant for\nfields such as design, artificial intelligence, marketing, and human-computer\ninteraction, where perceptually relevant color representation is critical.", "comment": "submitted to IEEE for consideration", "pdf_url": "http://arxiv.org/pdf/2507.11488v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11439", "title": "Data Augmentation in Time Series Forecasting through Inverted Framework", "authors": ["Hongming Tan", "Ting Chen", "Ruochong Jin", "Wai Kin Chan"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11439v1", "summary": "Currently, iTransformer is one of the most popular and effective models for\nmultivariate time series (MTS) forecasting. Thanks to its inverted framework,\niTransformer effectively captures multivariate correlation. However, the\ninverted framework still has some limitations. It diminishes temporal\ninterdependency information, and introduces noise in cases of nonsignificant\nvariable correlation. To address these limitations, we introduce a novel data\naugmentation method on inverted framework, called DAIF. Unlike previous data\naugmentation methods, DAIF stands out as the first real-time augmentation\nspecifically designed for the inverted framework in MTS forecasting. We first\ndefine the structure of the inverted sequence-to-sequence framework, then\npropose two different DAIF strategies, Frequency Filtering and Cross-variation\nPatching to address the existing challenges of the inverted framework.\nExperiments across multiple datasets and inverted models have demonstrated the\neffectiveness of our DAIF.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11439v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11476", "title": "C-FBI: A Combinatorial method using Convolutions for Circle Fitting in Blurry Images", "authors": ["Esteban Román Catafau", "Torbjörn E. M. Nordling"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      22 pages, 16 figures", "url": "http://arxiv.org/abs/2507.11476v1", "summary": "This paper addresses the fundamental computer vision challenge of robust\ncircle detection and fitting in degraded imaging conditions. We present\nCombinatorial Convolution-based Circle Fitting for Blurry Images (3C-FBI), an\nalgorithm that bridges the gap between circle detection and precise parametric\nfitting by combining (1) efficient combinatorial edge pixel (edgel) sampling\nand (2) convolution-based density estimation in parameter space.\n  We evaluate 3C-FBI across three experimental frameworks: (1) real-world\nmedical data from Parkinson's disease assessments (144 frames from 36 videos),\n(2) controlled synthetic data following established circle-fitting benchmarks,\nand (3) systematic analysis across varying spatial resolutions and outlier\ncontamination levels. Results show that 3C-FBI achieves state-of-the-art\naccuracy (Jaccard index 0.896) while maintaining real-time performance (40.3\nfps), significantly outperforming classical methods like RCD (6.8 fps) on a\nstandard CPU (i7-10875H). It maintains near-perfect accuracy (Jaccard almost\n1.0) at high resolutions (480x480) and reliable performance (Jaccard higher\nthan 0.95) down to 160x160 with up to 20% outliers.\n  In extensive synthetic testing, 3C-FBI achieves a mean Jaccard Index of 0.989\nacross contamination levels, comparable to modern methods like Qi et al. (2024,\n0.991), and surpassing RHT (0.964). This combination of accuracy, speed, and\nrobustness makes 3C-FBI ideal for medical imaging, robotics, and industrial\ninspection under challenging conditions.", "comment": "22 pages, 16 figures", "pdf_url": "http://arxiv.org/pdf/2507.11476v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11114", "title": "MSA at ImageCLEF 2025 Multimodal Reasoning: Multilingual Multimodal Reasoning With Ensemble Vision Language Models", "authors": ["Seif Ahmed", "Mohamed T. Younes", "Abdelrahman Moustafa", "Abdelrahman Allam", "Hamza Moustafa"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11114v1", "summary": "We present a robust ensemble-based system for multilingual multimodal\nreasoning, designed for the ImageCLEF 2025 EXAMS V challenge. Our approach\nintegrates Gemini 2.5 Flash for visual description, Gemini 1.5 Pro for caption\nrefinement and consistency checks, and Gemini 2.5 Pro as a reasoner which\nhandles final answer selection, all coordinated through carefully engineered\nfew-shot and zero-shot prompts. We conducted an extensive ablation study,\ntraining several large language models (Gemini 2.5 Flash, Phi 4, Gemma 3,\nMistral) on an English dataset and its multilingual augmented version.\nAdditionally, we evaluated Gemini 2.5 Flash in a zero-shot setting for\ncomparison and found it to substantially outperform the trained models. Prompt\ndesign also proved critical: enforcing concise, language-normalized formats and\nprohibiting explanatory text boosted model accuracy on the English validation\nset from 55.9% to 61.7%. On the official leaderboard, our system (Team MSA)\nachieved first place overall in the multilingual track with 81.4% accuracy, and\nled 11 out of 13 individual language tracks, with top results such as 95.07%\nfor Croatian and 92.12% for Italian. These findings highlight that lightweight\nOCR-VLM ensembles, when paired with precise prompt strategies and cross-lingual\naugmentation, can outperform heavier end-to-end models in high-stakes,\nmultilingual educational settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11114v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11031", "title": "Rapid Mixing of Glauber Dynamics for Monotone Systems via Entropic Independence", "authors": ["Weiming Feng", "Minji Yang"], "categories": ["cs.DM", "cs.DS", "math-ph", "math.MP", "math.PR"], "primary_category": "Subjects:       Discrete Mathematics (cs.DM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11031v1", "summary": "We study the mixing time of Glauber dynamics on monotone systems. For\nmonotone systems satisfying the entropic independence condition, we prove a new\nmixing time comparison result for Glauber dynamics. For concrete applications,\nwe obtain $\\tilde{O}(n)$ mixing time for the random cluster model induced by\nthe ferromagnetic Ising model with consistently biased external fields, and\n$\\tilde{O}(n^2)$ mixing time for the bipartite hardcore model under the\none-sided uniqueness condition, where $n$ is the number of variables in\ncorresponding models, improving the best known results in [Chen and Zhang,\nSODA'23] and [Chen, Liu, and Yin, FOCS'23], respectively.\n  Our proof combines ideas from the stochastic dominance argument in the\nclassical censoring inequality and the recently developed high-dimensional\nexpanders. The key step in the proof is a novel comparison result between the\nGlauber dynamics and the field dynamics for monotone systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11031v1", "cate": "cs.DM", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2504.07112", "title": "Are AI Agents interacting with Online Ads?", "authors": ["Andreas Stöckl", "Joel Nitu"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.07112v4", "summary": "As AI-driven agents become increasingly integrated into the digital\necosystem, they reshape how online advertising is perceived and processed.\nParticularly in the travel and hotel booking sector, these autonomous systems\ninfluence the effectiveness of traditional advertising formats. While visual\ncues and emotional appeals sway human users, AI agents prioritize structured\ndata such as price, availability, and specifications. This study examines how\ndifferent AI agents interact with online advertising, whether they incorporate\nads into their decision-making processes, and which ad formats prove most\neffective. We analyze interaction patterns, click behavior, and decision-making\nstrategies through experiments with multimodal language models such as OpenAI\nGPT-4o, Anthropic Claude 3.7 Sonnet, and Google Gemini 2.0 Flash. Our findings\nreveal that AI agents neither ignore nor systematically avoid advertisements\nbut instead favor certain features-particularly keywords and structured data.\nThese insights have significant implications for the future design of\nadvertising strategies in AI-dominated digital environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.07112v4", "cate": "cs.IR", "date": "2025-03-20", "updated": "2025-07-15"}
{"id": "2507.11493", "title": "A parametric activation function based on Wendland RBF", "authors": ["Majid Darehmiraki"], "categories": ["cs.LG", "cs.NE", "68T07"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 2 figures", "url": "http://arxiv.org/abs/2507.11493v1", "summary": "This paper introduces a novel parametric activation function based on\nWendland radial basis functions (RBFs) for deep neural networks. Wendland RBFs,\nknown for their compact support, smoothness, and positive definiteness in\napproximation theory, are adapted to address limitations of traditional\nactivation functions like ReLU, sigmoid, and tanh. The proposed enhanced\nWendland activation combines a standard Wendland component with linear and\nexponential terms, offering tunable locality, improved gradient propagation,\nand enhanced stability during training. Theoretical analysis highlights its\nmathematical properties, including smoothness and adaptability, while empirical\nexperiments on synthetic tasks (e.g., sine wave approximation) and benchmark\ndatasets (MNIST, Fashion-MNIST) demonstrate competitive performance. Results\nshow that the Wendland-based activation achieves superior accuracy in certain\nscenarios, particularly in regression tasks, while maintaining computational\nefficiency. The study bridges classical RBF theory with modern deep learning,\nsuggesting that Wendland activations can mitigate overfitting and improve\ngeneralization through localized, smooth transformations. Future directions\ninclude hybrid architectures and domain-specific adaptations.", "comment": "11 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.11493v1", "cate": "cs.LG", "date": "2025-06-28", "updated": "2025-06-28"}
{"id": "2507.11513", "title": "Recursive Bound-Constrained AdaGrad with Applications to Multilevel and Domain Decomposition Minimization", "authors": ["Serge Gratton", "Alena Kopaničáková", "Philippe Toint"], "categories": ["math.OC", "cs.AI", "cs.NA", "math.NA", "49K20, 65M55, 65Y20, 68Q25, 68T05, 90C26, 90C30", "F.2.1; G.1.8; I.2.5"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      33 pages", "url": "http://arxiv.org/abs/2507.11513v1", "summary": "Two OFFO (Objective-Function Free Optimization) noise tolerant algorithms are\npresented that handle bound constraints, inexact gradients and use second-order\ninformation when available.The first is a multi-level method exploiting a\nhierarchical description of the problem and the second is a\ndomain-decomposition method covering the standard addditive Schwarz\ndecompositions. Both are generalizations of the first-order AdaGrad algorithm\nfor unconstrained optimization. Because these algorithms share a common\ntheoretical framework, a single convergence/complexity theory is provided which\ncovers them both. Its main result is that, with high probability, both methods\nneed at most $O(\\epsilon^{-2})$ iterations and noisy gradient evaluations to\ncompute an $\\epsilon$-approximate first-order critical point of the\nbound-constrained problem. Extensive numerical experiments are discussed on\napplications ranging from PDE-based problems to deep neural network training,\nillustrating their remarkable computational efficiency.", "comment": "33 pages", "pdf_url": "http://arxiv.org/pdf/2507.11513v1", "cate": "math.OC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11471", "title": "D3FL: Data Distribution and Detrending for Robust Federated Learning in Non-linear Time-series Data", "authors": ["Harsha Varun Marisetty", "Manik Gupta", "Yogesh Simmhan"], "categories": ["cs.LG", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Preprint of paper to appear in the proceedings of IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING & COMMUNICATIONS EDGE 2025", "url": "http://arxiv.org/abs/2507.11471v1", "summary": "With advancements in computing and communication technologies, the Internet\nof Things (IoT) has seen significant growth. IoT devices typically collect data\nfrom various sensors, such as temperature, humidity, and energy meters. Much of\nthis data is temporal in nature. Traditionally, data from IoT devices is\ncentralized for analysis, but this approach introduces delays and increased\ncommunication costs. Federated learning (FL) has emerged as an effective\nalternative, allowing for model training across distributed devices without the\nneed to centralize data. In many applications, such as smart home energy and\nenvironmental monitoring, the data collected by IoT devices across different\nlocations can exhibit significant variation in trends and seasonal patterns.\nAccurately forecasting such non-stationary, non-linear time-series data is\ncrucial for applications like energy consumption estimation and weather\nforecasting. However, these data variations can severely impact prediction\naccuracy. The key contributions of this paper are: (1) Investigating how\nnon-linear, non-stationary time-series data distributions, like generalized\nextreme value (gen-extreme) and log norm distributions, affect FL performance.\n(2) Analyzing how different detrending techniques for non-linear time-series\ndata influence the forecasting model's performance in a FL setup. We generated\nseveral synthetic time-series datasets using non-linear data distributions and\ntrained an LSTM-based forecasting model using both centralized and FL\napproaches. Additionally, we evaluated the impact of detrending on real-world\ndatasets with non-linear time-series data distributions. Our experimental\nresults show that: (1) FL performs worse than centralized approaches when\ndealing with non-linear data distributions. (2) The use of appropriate\ndetrending techniques improves FL performance, reducing loss across different\ndata distributions.", "comment": "Preprint of paper to appear in the proceedings of IEEE INTERNATIONAL\n  CONFERENCE ON EDGE COMPUTING & COMMUNICATIONS EDGE 2025", "pdf_url": "http://arxiv.org/pdf/2507.11471v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11522", "title": "CATVis: Context-Aware Thought Visualization", "authors": ["Tariq Mehmood", "Hamza Ahmad", "Muhammad Haroon Shakeel", "Murtaza Taj"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at MICCAI 2025. This is the submitted version prior to peer review. The final Version of Record will appear in the MICCAI 2025 proceedings (Springer LNCS)", "url": "http://arxiv.org/abs/2507.11522v1", "summary": "EEG-based brain-computer interfaces (BCIs) have shown promise in various\napplications, such as motor imagery and cognitive state monitoring. However,\ndecoding visual representations from EEG signals remains a significant\nchallenge due to their complex and noisy nature. We thus propose a novel\n5-stage framework for decoding visual representations from EEG signals: (1) an\nEEG encoder for concept classification, (2) cross-modal alignment of EEG and\ntext embeddings in CLIP feature space, (3) caption refinement via re-ranking,\n(4) weighted interpolation of concept and caption embeddings for richer\nsemantics, and (5) image generation using a pre-trained Stable Diffusion model.\nWe enable context-aware EEG-to-image generation through cross-modal alignment\nand re-ranking. Experimental results demonstrate that our method generates\nhigh-quality images aligned with visual stimuli, outperforming SOTA approaches\nby 13.43% in Classification Accuracy, 15.21% in Generation Accuracy and\nreducing Fr\\'echet Inception Distance by 36.61%, indicating superior semantic\nalignment and image quality.", "comment": "Accepted at MICCAI 2025. This is the submitted version prior to peer\n  review. The final Version of Record will appear in the MICCAI 2025\n  proceedings (Springer LNCS)", "pdf_url": "http://arxiv.org/pdf/2507.11522v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11216", "title": "EsBBQ and CaBBQ: The Spanish and Catalan Bias Benchmarks for Question Answering", "authors": ["Valle Ruiz-Fernández", "Mario Mina", "Júlia Falcão", "Luis Vasquez-Reina", "Anna Sallés", "Aitor Gonzalez-Agirre", "Olatz Perez-de-Viñaspre"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11216v1", "summary": "Previous literature has largely shown that Large Language Models (LLMs)\nperpetuate social biases learnt from their pre-training data. Given the notable\nlack of resources for social bias evaluation in languages other than English,\nand for social contexts outside of the United States, this paper introduces the\nSpanish and the Catalan Bias Benchmarks for Question Answering (EsBBQ and\nCaBBQ). Based on the original BBQ, these two parallel datasets are designed to\nassess social bias across 10 categories using a multiple-choice QA setting, now\nadapted to the Spanish and Catalan languages and to the social context of\nSpain. We report evaluation results on different LLMs, factoring in model\nfamily, size and variant. Our results show that models tend to fail to choose\nthe correct answer in ambiguous scenarios, and that high QA accuracy often\ncorrelates with greater reliance on social biases.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11216v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11406", "title": "Compressed data structures for Heegaard splittings", "authors": ["Henrique Ennes", "Clément Maria"], "categories": ["cs.CG", "cs.DS", "math.GT"], "primary_category": "Subjects:       Computational Geometry (cs.CG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11406v1", "summary": "Heegaard splittings provide a natural representation of closed 3-manifolds by\ngluing handlebodies along a common surface. These splittings can be\nequivalently given by two finite sets of meridians lying in the surface, which\ndefine a Heegaard diagram. We present a data structure to effectively represent\nHeegaard diagrams as normal curves with respect to triangulations of a surface\nof complexity measured by the space required to express the normal coordinates'\nvectors in binary. This structure can be significantly more compressed than\ntriangulations of 3-manifolds, given exponential gains for some families. Even\nwith this succinct definition of complexity, we establish polynomial time\nalgorithms for comparing and manipulating diagrams, performing stabilizations,\ndetecting trivial stabilizations and reductions, and computing topological\ninvariants of the underlying manifolds, such as their fundamental and first\nhomology groups. We also contrast early implementations of our techniques with\nstandard software programs for 3-manifolds, achieving better precision and\nfaster algorithms for the average cases and exponential gains in speed for some\nparticular presentations of the inputs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11406v1", "cate": "cs.CG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2506.19777", "title": "Alleviating User-Sensitive bias with Fair Generative Sequential Recommendation Model", "authors": ["Yang Liu", "Feng Wu", "Xuefang Zhu"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.19777v2", "summary": "Recommendation fairness has recently attracted much attention. In the real\nworld, recommendation systems are driven by user behavior, and since users with\nthe same sensitive feature (e.g., gender and age) tend to have the same\npatterns, recommendation models can easily capture the strong correlation\npreference of sensitive features and thus cause recommendation unfairness.\nDiffusion model (DM) as a new generative model paradigm has achieved great\nsuccess in recommendation systems. DM's ability to model uncertainty and\nrepresent diversity, and its modeling mechanism has a high degree of\nadaptability with the real-world recommendation process with bias. Therefore,\nwe use DM to effectively model the fairness of recommendation and enhance the\ndiversity. This paper proposes a FairGENerative sequential Recommendation model\nbased on DM, FairGENRec. In the training phase, we inject random noise into the\noriginal distribution under the guidance of the sensitive feature recognition\nmodel, and a sequential denoise model is designed for the reverse\nreconstruction of items. Simultaneously, recommendation fairness modeling is\ncompleted by injecting multi-interests representational information that\neliminates the bias of sensitive user features into the generated results. In\nthe inference phase, the model obtains the noise in the form of noise addition\nby using the history interactions which is followed by reverse iteration to\nreconstruct the target item representation. Finally, our extensive experiments\non three datasets demonstrate the dual enhancement effect of FairGENRec on\naccuracy and fairness, while the statistical analysis of the cases visualizes\nthe degree of improvement on the fairness of the recommendation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.19777v2", "cate": "cs.IR", "date": "2025-06-24", "updated": "2025-07-15"}
{"id": "2408.01166", "title": "Continuous-Time Neural Networks Can Stably Memorize Random Spike Trains", "authors": ["Hugo Aguettaz", "Hans-Andrea Loeliger"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      28 pages, 16 figures", "url": "http://arxiv.org/abs/2408.01166v4", "summary": "The paper explores the capability of continuous-time recurrent neural\nnetworks to store and recall precisely timed scores of spike trains. We show\n(by numerical experiments) that this is indeed possible: within some range of\nparameters, any random score of spike trains (for all neurons in the network)\ncan be robustly memorized and autonomously reproduced with stable accurate\nrelative timing of all spikes, with probability close to one. We also\ndemonstrate associative recall under noisy conditions.\n  In these experiments, the required synaptic weights are computed offline, to\nsatisfy a template that encourages temporal stability.", "comment": "28 pages, 16 figures", "pdf_url": "http://arxiv.org/pdf/2408.01166v4", "cate": "cs.NE", "date": "2024-08-02", "updated": "2025-07-15"}
{"id": "2507.10804", "title": "Accelerating seismic inversion and uncertainty quantification with efficient high-rank Hessian approximations", "authors": ["Mathew Hu", "Nick Alger", "Rami Nammour", "Omar Ghattas"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10804v1", "summary": "Efficient high-rank approximations of the Hessian can accelerate seismic full\nwaveform inversion (FWI) and uncertainty quantification (UQ). In FWI,\napproximations of the inverse of the Hessian may be used as preconditioners for\nNewton-type or quasi-Newton algorithms, reducing computational costs and\nimproving recovery in deeper subsurface regions. In Bayesian UQ, Hessian\napproximations enable the construction of Markov chain Monte Carlo (MCMC)\nproposals that capture the directional scalings of the posterior, enhancing the\nefficiency of MCMC. Computing the exact Hessian is intractable for large-scale\nproblems because the Hessian is accessible only through matrix-vector products,\nand performing each matrix-vector product requires costly solution of wave\nequations. Moreover, the Hessian is high-rank, which means that low-rank\nmethods, often employed in large-scale inverse problems, are inefficient. We\nadapt two existing high-rank Hessian approximations -- the point spread\nfunction method and the pseudo-differential operator probing method. Building\non an observed duality between these approaches, we develop a novel method that\nunifies their complementary strengths. We validate these methods on a synthetic\nquadratic model and on the Marmousi model. Numerical experiments show that\nthese high-rank Hessian approximations substantially reduce the computational\ncosts in FWI. In UQ, MCMC samples computed using no Hessian approximation or a\nlow-rank approximation explore the posterior slowly, providing little\nmeaningful statistical information after tens of thousands of iterations and\nunderestimating the variance. At the same time, the effective sample size is\noverestimated, providing false confidence. In contrast, MCMC samples generated\nusing the high-rank Hessian approximations provide meaningful statistical\ninformation about the posterior and more accurately assess the posterior\nvariance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10804v1", "cate": "math.NA", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.11515", "title": "AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air", "authors": ["Shiyi Yang", "Xiaoxue Yu", "Rongpeng Li", "Jianhang Zhu", "Zhifeng Zhao", "Honggang Zhang"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 8 figures", "url": "http://arxiv.org/abs/2507.11515v1", "summary": "Operating Large Language Models (LLMs) on edge devices is increasingly\nchallenged by limited communication bandwidth and strained computational and\nmemory costs. Thus, cloud-assisted remote fine-tuning becomes indispensable.\nNevertheless, existing Low-Rank Adaptation (LoRA) approaches typically employ\nfixed or heuristic rank configurations, and the subsequent over-the-air\ntransmission of all LoRA parameters could be rather inefficient. To address\nthis limitation, we develop AirLLM, a hierarchical diffusion policy framework\nfor communication-aware LoRA adaptation. Specifically, AirLLM models the rank\nconfiguration as a structured action vector that spans all LoRA-inserted\nprojections. To solve the underlying high-dimensional sequential\ndecision-making problem, a Proximal Policy Optimization (PPO) agent generates\ncoarse-grained decisions by jointly observing wireless states and linguistic\ncomplexity, which are then refined via Denoising Diffusion Implicit Models\n(DDIM) to produce high-resolution, task- and channel-adaptive rank vectors. The\ntwo modules are optimized alternatively, with the DDIM trained under the\nClassifier-Free Guidance (CFG) paradigm to maintain alignment with PPO rewards.\nExperiments under varying signal-to-noise ratios demonstrate that AirLLM\nconsistently enhances fine-tuning performance while significantly reducing\ntransmission costs, highlighting the effectiveness of reinforcement-driven,\ndiffusion-refined rank adaptation for scalable and efficient remote fine-tuning\nover the air.", "comment": "11 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.11515v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11486", "title": "Exploring the robustness of TractOracle methods in RL-based tractography", "authors": ["Jeremi Levesque", "Antoine Théberge", "Maxime Descoteaux", "Pierre-Marc Jodoin"], "categories": ["cs.LG", "I.2.1"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      38 pages, 8 figures. Submitted to Medical Image Analysis", "url": "http://arxiv.org/abs/2507.11486v1", "summary": "Tractography algorithms leverage diffusion MRI to reconstruct the fibrous\narchitecture of the brain's white matter. Among machine learning approaches,\nreinforcement learning (RL) has emerged as a promising framework for\ntractography, outperforming traditional methods in several key aspects.\nTractOracle-RL, a recent RL-based approach, reduces false positives by\nincorporating anatomical priors into the training process via a reward-based\nmechanism. In this paper, we investigate four extensions of the original\nTractOracle-RL framework by integrating recent advances in RL, and we evaluate\ntheir performance across five diverse diffusion MRI datasets. Results\ndemonstrate that combining an oracle with the RL framework consistently leads\nto robust and reliable tractography, regardless of the specific method or\ndataset used. We also introduce a novel RL training scheme called Iterative\nReward Training (IRT), inspired by the Reinforcement Learning from Human\nFeedback (RLHF) paradigm. Instead of relying on human input, IRT leverages\nbundle filtering methods to iteratively refine the oracle's guidance throughout\ntraining. Experimental results show that RL methods trained with oracle\nfeedback significantly outperform widely used tractography techniques in terms\nof accuracy and anatomical validity.", "comment": "38 pages, 8 figures. Submitted to Medical Image Analysis", "pdf_url": "http://arxiv.org/pdf/2507.11486v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11533", "title": "CharaConsist: Fine-Grained Consistent Character Generation", "authors": ["Mengyu Wang", "Henghui Ding", "Jianing Peng", "Yao Zhao", "Yunpeng Chen", "Yunchao Wei"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025 accepted paper, project page: this https URL", "url": "http://arxiv.org/abs/2507.11533v1", "summary": "In text-to-image generation, producing a series of consistent contents that\npreserve the same identity is highly valuable for real-world applications.\nAlthough a few works have explored training-free methods to enhance the\nconsistency of generated subjects, we observe that they suffer from the\nfollowing problems. First, they fail to maintain consistent background details,\nwhich limits their applicability. Furthermore, when the foreground character\nundergoes large motion variations, inconsistencies in identity and clothing\ndetails become evident. To address these problems, we propose CharaConsist,\nwhich employs point-tracking attention and adaptive token merge along with\ndecoupled control of the foreground and background. CharaConsist enables\nfine-grained consistency for both foreground and background, supporting the\ngeneration of one character in continuous shots within a fixed scene or in\ndiscrete shots across different scenes. Moreover, CharaConsist is the first\nconsistent generation method tailored for text-to-image DiT model. Its ability\nto maintain fine-grained consistency, combined with the larger capacity of\nlatest base model, enables it to produce high-quality visual outputs,\nbroadening its applicability to a wider range of real-world scenarios. The\nsource code has been released at https://github.com/Murray-Wang/CharaConsist", "comment": "ICCV 2025 accepted paper, project page:\n  https://murray-wang.github.io/CharaConsist/", "pdf_url": "http://arxiv.org/pdf/2507.11533v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11230", "title": "Sparse Autoencoders Can Capture Language-Specific Concepts Across Diverse Languages", "authors": ["Lyzander Marciano Andrylie", "Inaya Rahmanisa", "Mahardika Krisna Ihsani", "Alfan Farizki Wicaksono", "Haryo Akbarianto Wibowo", "Alham Fikri Aji"], "categories": ["cs.CL", "68T50"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11230v1", "summary": "Understanding the multilingual mechanisms of large language models (LLMs)\nprovides insight into how they process different languages, yet this remains\nchallenging. Existing studies often focus on individual neurons, but their\npolysemantic nature makes it difficult to isolate language-specific units from\ncross-lingual representations. To address this, we explore sparse autoencoders\n(SAEs) for their ability to learn monosemantic features that represent concrete\nand abstract concepts across languages in LLMs. While some of these features\nare language-independent, the presence of language-specific features remains\nunderexplored. In this work, we introduce SAE-LAPE, a method based on feature\nactivation probability, to identify language-specific features within the\nfeed-forward network. We find that many such features predominantly appear in\nthe middle to final layers of the model and are interpretable. These features\ninfluence the model's multilingual performance and language output and can be\nused for language identification with performance comparable to fastText along\nwith more interpretability. Our code is available at\nhttps://github.com/LyzanderAndrylie/language-specific-features .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11230v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "1805.10708", "title": "Distributed Treewidth Computation and Courcelle's Theorem in the CONGEST Model", "authors": ["Benjamin Jauregui", "Jason Li", "Pedro Montealegre", "Ioan Todinca"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/1805.10708v2", "summary": "Algorithmic meta-theorems, stating that graph properties expressible in some\nparticular logic can be decided efficiently in graph classes having some\nspecific structural properties, are now standard in sequential graph\nalgorithms. One of the most classic examples is Courcelle's theorem: all\nproperties expressible in Monadic Second-Order logic (MSO) are decidable in\nlinear time in graphs of bounded treewidth.\n  We provide here a distributed version of Courcelle's theorem, in the standard\nCONGEST model for distributed computing: For any MSO formula $\\varphi$ and any\nconstant $k$, there is a CONGEST algorithm that, given an input communication\nnetwork $G$ of treewidth at most $k$ and of diameter $D$, decides if $G$\nsatisfies property $\\varphi$ in $\\tilde O(D)$ rounds. Simple examples show that\nthe dependency on $D$ is unavoidable. Also, if we drop the assumption of\nbounded treewidth, deciding MSO properties such as 3-colorability are known to\nrequire $\\tilde{\\Omega}(n^2)$ rounds in the CONGEST model. Our results extend\nto optimization problems (e.g., computing a maximum size independent set, or a\nminimum dominating set) and counting (e.g. triangle counting). As usual, the\n$\\tilde{O}$ notation hides polylogarithmic factors in $n$; here it also hides a\nconstant factor depending on $k$ and on the MSO formula $\\varphi$.\n  We also give a distributed algorithm producing a linear approximation for\ntreewidth: For any $k$, it decides that the treewidth of the input network $G$\nis larger than $k$ or computes a tree decomposition of width $O(k)$ and depth\n$O(\\log n)$, in $\\tilde O(k^{O(k)} D)$ rounds in CONGEST.\n  Our algorithms make use of the low-congestion shortcuts framework introduced\nby Ghaffari and Haeupler [SODA 2016], and our main technical tool is an $\\tilde\nO(k^4 D)$ algorithm for computing $(s,t)$-vertex separators of size at most\n$k+1$ in graphs of treewidth at most $k$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/1805.10708v2", "cate": "cs.DS", "date": "2018-05-27", "updated": "2025-07-14"}
{"id": "2506.21596", "title": "Evaluating Multimodal Large Language Models on Educational Textbook Question Answering", "authors": ["Hessa A. Alawwad", "Anas Zafar", "Areej Alhothali", "Usman Naseem", "Ali Alkhathlan", "Amani Jamal"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      8 Pages", "url": "http://arxiv.org/abs/2506.21596v2", "summary": "Multimodal large language models (MLLMs) have shown success in\nvision-language tasks, but their ability to reason over complex educational\nmaterials remains largely untested. This work presents the first evaluation of\nstate-of-the-art MLLMs, including LLaVA-1.5 and LLaMA 3.2-Vision, on the\ntextbook question answering (TQA) task using the CK12-QA dataset. We introduce\na multimodal retrieval-augmented generation (RAG) pipeline to simulate\nreal-world learning by providing relevant lesson paragraphs and diagrams as\ncontext. Our zero-shot experiments reveal a critical trade-off: while retrieved\ncontext improves LLaVA's performance on text-based questions, it significantly\ndegrades the accuracy of the more powerful LLaMA 3.2-Vision on diagram-based\ntasks, dropping its validation accuracy from 74.07% to 25.93%. We term this\nstatistically significant phenomenon \"catastrophic context interference.\"\nFurthermore, fine-tuning highlights architectural differences: LLaMA\n3.2-Vision's performance improves to 71.16% on the test set, demonstrating its\ncapacity to learn multimodal integration, whereas LLaVA's performance declines,\nindicating challenges with generalization. Our results underscore the\nchallenges MLLMs face in modality prioritization and context integration,\nproviding a benchmark and pointing to key directions for developing more robust\nAI-driven educational tools.", "comment": "8 Pages", "pdf_url": "http://arxiv.org/pdf/2506.21596v2", "cate": "cs.CL", "date": "2025-06-18", "updated": "2025-07-15"}
{"id": "2502.01706", "title": "Comply: Learning Sentences with Complex Weights inspired by Fruit Fly Olfaction", "authors": ["Alexei Figueroa", "Justus Westerhoff", "Golzar Atefi", "Dennis Fast", "Benjamin Winter", "Felix Alexander Gers", "Alexander Löser", "Wolfgang Nejdl"], "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at NICE2025", "url": "http://arxiv.org/abs/2502.01706v3", "summary": "Biologically inspired neural networks offer alternative avenues to model data\ndistributions. FlyVec is a recent example that draws inspiration from the fruit\nfly's olfactory circuit to tackle the task of learning word embeddings.\nSurprisingly, this model performs competitively even against deep learning\napproaches specifically designed to encode text, and it does so with the\nhighest degree of computational efficiency. We pose the question of whether\nthis performance can be improved further. For this, we introduce Comply. By\nincorporating positional information through complex weights, we enable a\nsingle-layer neural network to learn sequence representations. Our experiments\nshow that Comply not only supersedes FlyVec but also performs on par with\nsignificantly larger state-of-the-art models. We achieve this without\nadditional parameters. Comply yields sparse contextual representations of\nsentences that can be interpreted explicitly from the neuron weights.", "comment": "Accepted at NICE2025", "pdf_url": "http://arxiv.org/pdf/2502.01706v3", "cate": "cs.CL", "date": "2025-02-03", "updated": "2025-07-15"}
{"id": "2507.11047", "title": "Dimension of Bi-degree $(d,d)$ Spline Spaces with the Highest Order of Smoothness over Hierarchical T-Meshes", "authors": ["Bingru Huang", "Falai Chen"], "categories": ["math.NA", "cs.NA", "65D17, 65D07, 65N30"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11047v1", "summary": "In this article, we study the dimension of the spline space of di-degree\n$(d,d)$ with the highest order of smoothness over a hierarchical T-mesh\n$\\mathscr T$ using the smoothing cofactor-conformality method. Firstly, we\nobtain a dimensional formula for the conformality vector space over a tensor\nproduct T-connected component. Then, we prove that the dimension of the\nconformality vector space over a T-connected component of a hierarchical T-mesh\nunder the tensor product subdivision can be calculated in a recursive manner.\nCombining these two aspects, we obtain a dimensional formula for the bi-degree\n$(d,d)$ spline space with the highest order of smoothness over a hierarchical\nT-mesh $\\mathscr T$ with mild assumption. Additionally, we provide a strategy\nto modify an arbitrary hierarchical T-mesh such that the dimension of the\nbi-degree $(d,d)$ spline space is stable over the modified hierarchical T-mesh.\nFinally, we prove that the dimension of the spline space over such a\nhierarchical T-mesh is the same as that of a lower-degree spline space over its\nCVR graph. Thus, the proposed solution can pave the way for the subsequent\nconstruction of basis functions for spline space over such a hierarchical\nT-mesh.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11047v1", "cate": "math.NA", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11539", "title": "Streaming 4D Visual Geometry Transformer", "authors": ["Dong Zhuo", "Wenzhao Zheng", "Jiahe Guo", "Yuqi Wu", "Jie Zhou", "Jiwen Lu"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Code is available at: this https URL", "url": "http://arxiv.org/abs/2507.11539v1", "summary": "Perceiving and reconstructing 4D spatial-temporal geometry from videos is a\nfundamental yet challenging computer vision task. To facilitate interactive and\nreal-time applications, we propose a streaming 4D visual geometry transformer\nthat shares a similar philosophy with autoregressive large language models. We\nexplore a simple and efficient design and employ a causal transformer\narchitecture to process the input sequence in an online manner. We use temporal\ncausal attention and cache the historical keys and values as implicit memory to\nenable efficient streaming long-term 4D reconstruction. This design can handle\nreal-time 4D reconstruction by incrementally integrating historical information\nwhile maintaining high-quality spatial consistency. For efficient training, we\npropose to distill knowledge from the dense bidirectional visual geometry\ngrounded transformer (VGGT) to our causal model. For inference, our model\nsupports the migration of optimized efficient attention operator (e.g.,\nFlashAttention) from the field of large language models. Extensive experiments\non various 4D geometry perception benchmarks demonstrate that our model\nincreases the inference speed in online scenarios while maintaining competitive\nperformance, paving the way for scalable and interactive 4D vision systems.\nCode is available at: https://github.com/wzzheng/StreamVGGT.", "comment": "Code is available at: https://github.com/wzzheng/StreamVGGT", "pdf_url": "http://arxiv.org/pdf/2507.11539v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11531", "title": "Langevin Flows for Modeling Neural Latent Dynamics", "authors": ["Yue Song", "T. Anderson Keller", "Yisong Yue", "Pietro Perona", "Max Welling"], "categories": ["cs.LG", "q-bio.NC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Full version of the Cognitive Computational Neuroscience (CCN) 2025 poster", "url": "http://arxiv.org/abs/2507.11531v1", "summary": "Neural populations exhibit latent dynamical structures that drive\ntime-evolving spiking activities, motivating the search for models that capture\nboth intrinsic network dynamics and external unobserved influences. In this\nwork, we introduce LangevinFlow, a sequential Variational Auto-Encoder where\nthe time evolution of latent variables is governed by the underdamped Langevin\nequation. Our approach incorporates physical priors -- such as inertia,\ndamping, a learned potential function, and stochastic forces -- to represent\nboth autonomous and non-autonomous processes in neural systems. Crucially, the\npotential function is parameterized as a network of locally coupled\noscillators, biasing the model toward oscillatory and flow-like behaviors\nobserved in biological neural populations. Our model features a recurrent\nencoder, a one-layer Transformer decoder, and Langevin dynamics in the latent\nspace. Empirically, our method outperforms state-of-the-art baselines on\nsynthetic neural populations generated by a Lorenz attractor, closely matching\nground-truth firing rates. On the Neural Latents Benchmark (NLB), the model\nachieves superior held-out neuron likelihoods (bits per spike) and forward\nprediction accuracy across four challenging datasets. It also matches or\nsurpasses alternative methods in decoding behavioral metrics such as hand\nvelocity. Overall, this work introduces a flexible, physics-inspired,\nhigh-performing framework for modeling complex neural population dynamics and\ntheir unobserved influences.", "comment": "Full version of the Cognitive Computational Neuroscience (CCN) 2025\n  poster", "pdf_url": "http://arxiv.org/pdf/2507.11531v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11540", "title": "Towards Depth Foundation Model: Recent Trends in Vision-Based Depth Estimation", "authors": ["Zhen Xu", "Hongyu Zhou", "Sida Peng", "Haotong Lin", "Haoyu Guo", "Jiahao Shao", "Peishan Yang", "Qinglin Yang", "Sheng Miao", "Xingyi He", "Yifan Wang", "Yue Wang", "Ruizhen Hu", "Yiyi Liao", "Xiaowei Zhou", "Hujun Bao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11540v1", "summary": "Depth estimation is a fundamental task in 3D computer vision, crucial for\napplications such as 3D reconstruction, free-viewpoint rendering, robotics,\nautonomous driving, and AR/VR technologies. Traditional methods relying on\nhardware sensors like LiDAR are often limited by high costs, low resolution,\nand environmental sensitivity, limiting their applicability in real-world\nscenarios. Recent advances in vision-based methods offer a promising\nalternative, yet they face challenges in generalization and stability due to\neither the low-capacity model architectures or the reliance on domain-specific\nand small-scale datasets. The emergence of scaling laws and foundation models\nin other domains has inspired the development of \"depth foundation models\":\ndeep neural networks trained on large datasets with strong zero-shot\ngeneralization capabilities. This paper surveys the evolution of deep learning\narchitectures and paradigms for depth estimation across the monocular, stereo,\nmulti-view, and monocular video settings. We explore the potential of these\nmodels to address existing challenges and provide a comprehensive overview of\nlarge-scale datasets that can facilitate their development. By identifying key\narchitectures and training strategies, we aim to highlight the path towards\nrobust depth foundation models, offering insights into their future research\nand applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11540v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11273", "title": "KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding", "authors": ["Luohe Shi", "Zuchao Li", "Lefei Zhang", "Guoming Liu", "Baoyuan Qi", "Hai Zhao"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      To be published in The 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025)", "url": "http://arxiv.org/abs/2507.11273v1", "summary": "Large language models (LLMs) based on Transformer Decoders have become the\npreferred choice for conversational generative AI. Despite the overall\nsuperiority of the Decoder architecture, the gradually increasing Key-Value\n(KV) cache during inference has emerged as a primary efficiency bottleneck,\nboth in aspects of memory consumption and data transfer bandwidth limitations.\nTo address these challenges, we propose a paradigm called KV-Latent. By\ndown-sampling the Key-Value vector dimensions into a latent space, we can\nsignificantly reduce the KV Cache footprint and improve inference speed, only\nwith a small amount of extra training, less than 1\\% of pre-training takes.\nBesides, we enhanced the stability of Rotary Positional Embedding applied on\nlower-dimensional vectors by modifying its frequency sampling mechanism,\navoiding noise introduced by higher frequencies while retaining position\nattenuation. Our experiments, including both models with Grouped Query\nAttention and those without, have yielded satisfactory results. Finally, we\nconducted comparative experiments to study the impact of separately reducing\nKey and Value components on model's performance. Our approach allows for the\nconstruction of more efficient language model systems, and opens the new\npossibility on KV Cache saving and efficient LLMs. Our code is available at\nhttps://github.com/ShiLuohe/KV-Latent.", "comment": "To be published in The 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025)", "pdf_url": "http://arxiv.org/pdf/2507.11273v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.09688", "title": "Minimum-Peak-Cost Flows Over Time", "authors": ["Mariia Anapolska", "Emma Ahrens", "Christina Büsing", "Felix Engelhardt", "Timo Gersing", "Corinna Mathwieser", "Sabrian Schmitz", "Sophia Wrede"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09688v2", "summary": "When planning transportation whose operation requires non-consumable\nresources, the peak demand for allocated resources is often of higher interest\nthan the duration of resource usage. For instance, it is more cost-effective to\ndeliver parcels with a single truck over eight hours than to use two trucks for\nfour hours, as long as the time suffices. To model such scenarios, we introduce\nthe novel minimum peak cost flow over time problem, whose objective is to\nminimise the maximum cost at all points in time rather than minimising the\nintegral of costs. We focus on minimising peak costs of temporally repeated\nflows. These are desirable for practical applications due to their simple\nstructure. This yields the minimum-peak-cost temporally repeated flow problem\n(MPC-TRF).\n  We show that the simple structure of temporally repeated flows comes with the\ndrawback of arbitrarily bad approximation ratios compared to general flows over\ntime. Furthermore, our complexity analysis shows the integral version of\nMPC-TRF is strongly NP-hard, even under strong restrictions. On the positive\nside, we identify two benign special cases: unit-cost series-parallel networks\nand networks with time horizon at least twice as long as the longest path in\nthe network (with respect to the transit time). In both cases, we show that\nintegral optimal flows if the desired flow value equals the maximum flow value\nand fractional optimal flows for arbitrary flow values can be found in\npolynomial time. For each of these cases, we provide an explicit algorithm that\nconstructs an optimal solution.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09688v2", "cate": "cs.DS", "date": "2025-07-13", "updated": "2025-07-15"}
{"id": "2507.02962", "title": "RAG-R1 : Incentivize the Search and Reasoning Capabilities of LLMs through Multi-query Parallelism", "authors": ["Zhiwen Tan", "Jiaming Huang", "Qintong Wu", "Hongxuan Zhang", "Chenyi Zhuang", "Jinjie Gu"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.02962v3", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, while they remain prone to generating hallucinated or outdated\nresponses due to their static internal knowledge. Recent advancements in\nRetrieval-Augmented Generation (RAG) methods have explored enhancing models'\nsearch and reasoning capabilities through reinforcement learning (RL). Although\nthese methods demonstrate promising results, they face challenges in training\nstability and encounter issues such as substantial inference time and\nrestricted capabilities due to the single-query mode. In this paper, we propose\nRAG-R1, a novel training framework designed to enable LLMs to adaptively\nleverage internal and external knowledge during the reasoning process. We\nfurther expand the generation and retrieval processes within the framework from\nsingle-query mode to multi-query parallelism, aimed at reducing inference time\nand enhancing the model's capabilities. Extensive experiments on seven\nquestion-answering benchmarks demonstrate that our method outperforms the\nstrongest baseline by up to 13.2% and decreases inference time by 11.1%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.02962v3", "cate": "cs.CL", "date": "2025-06-30", "updated": "2025-07-15"}
{"id": "2507.11068", "title": "Stability of the Active Flux Method in the Framework of Summation-by-Parts Operators", "authors": ["Wasilij Barsukow", "Christian Klingenberg", "Lisa Lechner", "Jan Nordström", "Sigrun Ortleb", "Hendrik Ranocha"], "categories": ["math.NA", "cs.NA", "65M06, 65M20, 65M70"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11068v1", "summary": "The Active Flux method is a numerical method for conservation laws using a\ncombination of cell averages and point values, based on ideas from finite\nvolumes and finite differences. This unusual mix has been shown to work well in\nmany situations. We expand the theoretical justifications of the Active Flux\nmethod by analyzing it from the point of view of summation-by-parts (SBP)\noperators, which are routinely used to analyze finite difference, finite\nvolume, and finite element schemes. We show that the Active Flux method can be\nformulated using degenerate SBP operators, yielding a first and novel approach\nfor showing the energy stability of the Active Flux method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11068v1", "cate": "math.NA", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2404.12458", "title": "A dancing bear, a colleague, or a sharpened toolbox? The cautious adoption of generative AI technologies in digital humanities research", "authors": ["Rongqian Ma", "Meredith Dedema", "Andrew Cox"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.12458v3", "summary": "The advent of generative artificial intelligence (GenAI) technologies has\nbeen changing the research landscape and potentially has significant\nimplications for Digital Humanities (DH), a field inherently intertwined with\ntechnologies. This article investigates how DH scholars adopt and critically\nevaluate GenAI technologies for research. Drawing on 76 responses collected\nfrom an international survey study and 15 semi-structured interviews with DH\nscholars, we explored the rationale for adopting GenAI tools in research,\nidentified the specific practices of using GenAI tools, and analyzed scholars'\ncollective perceptions regarding the benefits, risks, and challenges. The\nresults reveal that DH research communities hold divided opinions and differing\nimaginations towards the role of GenAI in DH scholarship. While scholars\nacknowledge the benefits of GenAI in enhancing research efficiency and enabling\nreskilling, many remain concerned about its potential to disrupt their\nintellectual identities. Situated within the history of DH and viewed through\nthe lens of Actor-Network Theory, our findings suggest that the adoption of\nGenAI is gradually changing the field, though this transformation remains\ncontested, shaped by ongoing negotiations among multiple human and non-human\nactors. Our study is one of the first empirical analyses on this topic and has\nthe potential to serve as a building block for future inquiries into the impact\nof GenAI on DH scholarship.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.12458v3", "cate": "cs.AI", "date": "2024-04-18", "updated": "2025-07-14"}
{"id": "2507.10567", "title": "Protocols for Verifying Smooth Strategies in Bandits and Games", "authors": ["Miranda Christ", "Daniel Reichman", "Jonathan Shafer"], "categories": ["cs.GT", "cs.LG"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10567v1", "summary": "We study protocols for verifying approximate optimality of strategies in\nmulti-armed bandits and normal-form games. As the number of actions available\nto each player is often large, we seek protocols where the number of queries to\nthe utility oracle is sublinear in the number of actions. We prove that such\nverification is possible for sufficiently smooth strategies that do not put too\nmuch probability mass on any specific action. We provide protocols for\nverifying that a smooth policy for a multi-armed bandit is\n$\\varepsilon$-optimal. Our verification protocols require provably fewer arm\nqueries than learning. Furthermore, we establish a nearly-tight lower bound on\nthe query complexity of verification in our settings. As an application, we\nshow how to use verification for bandits to achieve verification in normal-form\ngames. This gives a protocol for verifying whether a given strategy profile is\nan approximate strong smooth Nash equilibrium, with a query complexity that is\nsublinear in the number of actions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10567v1", "cate": "cs.GT", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.11461", "title": "Deep Equilibrium models for Poisson Imaging Inverse problems via Mirror Descent", "authors": ["Christian Daniele", "Silvia Villa", "Samuel Vaiter", "Luca Calatroni"], "categories": ["math.OC", "cs.CV", "65K10, 65J22, 94A08, 47N10"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11461v1", "summary": "Deep Equilibrium Models (DEQs) are implicit neural networks with fixed\npoints, which have recently gained attention for learning image regularization\nfunctionals, particularly in settings involving Gaussian fidelities, where\nassumptions on the forward operator ensure contractiveness of standard\n(proximal) Gradient Descent operators. In this work, we extend the application\nof DEQs to Poisson inverse problems, where the data fidelity term is more\nappropriately modeled by the Kullback-Leibler divergence. To this end, we\nintroduce a novel DEQ formulation based on Mirror Descent defined in terms of a\ntailored non-Euclidean geometry that naturally adapts with the structure of the\ndata term. This enables the learning of neural regularizers within a principled\ntraining framework. We derive sufficient conditions to guarantee the\nconvergence of the learned reconstruction scheme and propose computational\nstrategies that enable both efficient training and fully parameter-free\ninference. Numerical experiments show that our method outperforms traditional\nmodel-based approaches and it is comparable to the performance of Bregman\nPlug-and-Play methods, while mitigating their typical drawbacks - namely,\nsensitivity to initialization and careful tuning of hyperparameters. The code\nis publicly available at https://github.com/christiandaniele/DEQ-MD.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11461v1", "cate": "math.OC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11275", "title": "FMC: Formalization of Natural Language Mathematical Competition Problems", "authors": ["Jiaxuan Xie", "Chengwu Liu", "Ye Yuan", "Siqi Li", "Zhiping Xiao", "Ming Zhang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted in ICML 2025 AI4MATH Workshop", "url": "http://arxiv.org/abs/2507.11275v1", "summary": "Efficient and accurate autoformalization methods, which leverage large-scale\ndatasets of extensive natural language mathematical problems to construct\nformal language datasets, are key to advancing formal mathematical reasoning.\nIn this paper, we propose an autoformalization pipeline based on large language\nmodels with error feedback, achieving a fully automatic and training-free\nformalization approach. Using this pipeline, we curate an Olympiad-level\ndataset aligning natural language problems with Lean formalizations. The\ndataset comprises $3,922$ mathematical problems in natural language and $9,787$\nin Lean, of which $64.46\\%$ were assessed as at least above-average quality,\nmaking it suitable as a benchmark for automated theorem provers. Additionally,\nwe investigate the formalization and reasoning capabilities of various LLMs and\nempirically demonstrate that few-shot learning, error feedback, and increasing\nsampling numbers enhance the autoformalization process. Experiments of three\nautomated theorem provers on the \\dataset\\ dataset also highlight its\nchallenging nature and its value as a benchmark for formal reasoning tasks.", "comment": "Accepted in ICML 2025 AI4MATH Workshop", "pdf_url": "http://arxiv.org/pdf/2507.11275v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2503.06341", "title": "Digital Zero-Noise Extrapolation with Quantum Circuit Unoptimization", "authors": ["Elijah Pelofske", "Vincent Russo"], "categories": ["quant-ph", "cs.DS"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.06341v3", "summary": "Quantum circuit unoptimization is an algorithm that transforms a quantum\ncircuit into a different circuit that uses more gate operations while\nmaintaining the same unitary transformation. We demonstrate that this method\ncan implement digital zero-noise extrapolation (ZNE), a quantum error\nmitigation technique. By employing quantum circuit unoptimization as a form of\ncircuit folding, noise can be systematically amplified. The key advantages of\nthis approach are twofold. First, its ability to generate an exponentially\nincreasing number of distinct circuit variants as the noise level is amplified,\nwhich allows noise averaging over many circuit variants with slightly different\ncircuit structure. Averaging over these variants can mitigate the effect of\nbiased error propagation due to the significantly altered circuit structure\nfrom quantum circuit unoptimization, or biased noise sources on a quantum\nprocessor. Second, quantum circuit unoptimization by design resists circuit\nsimplification back to the original unmodified circuit, making it plausible to\nuse ZNE in contexts where circuit compiler optimization is applied server-side.\nWe evaluate the effectiveness of quantum circuit unoptimization as a\nnoise-scaling method for ZNE in two test cases using depolarizing noise\nnumerical simulations: random quantum volume circuits, where the observable is\nthe heavy output probability, and QAOA circuits for the (unweighted) maximum\ncut problem on random 3-regular graphs, where the observable is the cut value.\nWe show that using quantum circuit unoptimization to perform ZNE can\napproximately recover signal from noisy quantum simulations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.06341v3", "cate": "quant-ph", "date": "2025-03-08", "updated": "2025-07-14"}
{"id": "2507.11130", "title": "Adaptive Reduced Basis Trust Region Methods for Parabolic Inverse Problems", "authors": ["Michael Kartmann", "Benedikt Klein", "Mario Ohlberger", "Thomas Schuster", "Stefan Volkwein"], "categories": ["math.NA", "cs.NA", "math.OC", "35R30, 35K90, 65M32, 35K57"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      40 pages, 12 figures", "url": "http://arxiv.org/abs/2507.11130v1", "summary": "We consider nonlinear inverse problems arising in the context of parameter\nidentification for parabolic partial differential equations (PDEs). For stable\nreconstructions, regularization methods such as the iteratively regularized\nGauss-Newton method (IRGNM) are commonly used, but their application is\ncomputationally demanding due to the high-dimensional nature of PDE\ndiscretizations. To address this bottleneck, we propose a reduced-order\nmodeling approach that accelerates both the state and adjoint evaluations\nrequired for derivative-based optimization. Our method builds on the recent\ncontribution [Kartmann et al. Adaptive reduced basis trust region methods for\nparameter identification problems. Comput. Sci. Eng. 1, 3 (2024)] for elliptic\nforward operators and constructs the reduced forward operator adaptively in an\nonline fashion, combining both parameter and state space reduction. To ensure\nreliability, we embed the IRGNM iteration within an adaptive, error-aware\ntrust-region framework that certifies the accuracy of the reduced-order\napproximations. We demonstrate the effectiveness of the proposed approach\nthrough numerical results for both time-dependent and time-independent\nparameter identification problems in dynamic reaction-diffusion systems. The\nimplementation is made available for reproducibility and further use.", "comment": "40 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.11130v1", "cate": "math.NA", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11233", "title": "Improving Neural Pitch Estimation with SWIPE Kernels", "authors": ["David Marttila", "Joshua D. Reiss"], "categories": ["cs.SD"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted at ISMIR 2025", "url": "http://arxiv.org/abs/2507.11233v1", "summary": "Neural networks have become the dominant technique for accurate pitch and\nperiodicity estimation. Although a lot of research has gone into improving\nnetwork architectures and training paradigms, most approaches operate directly\non the raw audio waveform or on general-purpose time-frequency representations.\nWe investigate the use of Sawtooth-Inspired Pitch Estimation (SWIPE) kernels as\nan audio frontend and find that these hand-crafted, task-specific features can\nmake neural pitch estimators more accurate, robust to noise, and more\nparameter-efficient. We evaluate supervised and self-supervised\nstate-of-the-art architectures on common datasets and show that the SWIPE audio\nfrontend allows for reducing the network size by an order of magnitude without\nperformance degradation. Additionally, we show that the SWIPE algorithm on its\nown is much more accurate than commonly reported, outperforming\nstate-of-the-art self-supervised neural pitch estimators.", "comment": "Accepted at ISMIR 2025", "pdf_url": "http://arxiv.org/pdf/2507.11233v1", "cate": "cs.SD", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2410.00258", "title": "Possible Principles for Aligned Structure Learning Agents", "authors": ["Lancelot Da Costa", "Tomáš Gavenčiak", "David Hyland", "Mandana Samiei", "Cristian Dragos-Manta", "Candice Pattisapu", "Adeel Razi", "Karl Friston"], "categories": ["cs.AI", "q-bio.NC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      24 pages of content, 33 with references", "url": "http://arxiv.org/abs/2410.00258v2", "summary": "This paper offers a roadmap for the development of scalable aligned\nartificial intelligence (AI) from first principle descriptions of natural\nintelligence. In brief, a possible path toward scalable aligned AI rests upon\nenabling artificial agents to learn a good model of the world that includes a\ngood model of our preferences. For this, the main objective is creating agents\nthat learn to represent the world and other agents' world models; a problem\nthat falls under structure learning (a.k.a. causal representation learning or\nmodel discovery). We expose the structure learning and alignment problems with\nthis goal in mind, as well as principles to guide us forward, synthesizing\nvarious ideas across mathematics, statistics, and cognitive science. 1) We\ndiscuss the essential role of core knowledge, information geometry and model\nreduction in structure learning, and suggest core structural modules to learn a\nwide range of naturalistic worlds. 2) We outline a way toward aligned agents\nthrough structure learning and theory of mind. As an illustrative example, we\nmathematically sketch Asimov's Laws of Robotics, which prescribe agents to act\ncautiously to minimize the ill-being of other agents. We supplement this\nexample by proposing refined approaches to alignment. These observations may\nguide the development of artificial intelligence in helping to scale existing\n-- or design new -- aligned structure learning systems.", "comment": "24 pages of content, 33 with references", "pdf_url": "http://arxiv.org/pdf/2410.00258v2", "cate": "cs.AI", "date": "2024-09-30", "updated": "2025-07-15"}
{"id": "2507.10635", "title": "Formal Verification of Variational Quantum Circuits", "authors": ["Nicola Assolini", "Luca Marzari", "Isabella Mastroeni", "Alessandra di Pierro"], "categories": ["quant-ph", "cs.LG", "cs.PL"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      Assolini and Marzari contributed equally to the paper", "url": "http://arxiv.org/abs/2507.10635v1", "summary": "Variational quantum circuits (VQCs) are a central component of many quantum\nmachine learning algorithms, offering a hybrid quantum-classical framework\nthat, under certain aspects, can be considered similar to classical deep neural\nnetworks. A shared aspect is, for instance, their vulnerability to adversarial\ninputs, small perturbations that can lead to incorrect predictions. While\nformal verification techniques have been extensively developed for classical\nmodels, no comparable framework exists for certifying the robustness of VQCs.\nHere, we present the first in-depth theoretical and practical study of the\nformal verification problem for VQCs. Inspired by abstract interpretation\nmethods used in deep learning, we analyze the applicability and limitations of\ninterval-based reachability techniques in the quantum setting. We show that\nquantum-specific aspects, such as state normalization, introduce inter-variable\ndependencies that challenge existing approaches. We investigate these issues by\nintroducing a novel semantic framework based on abstract interpretation, where\nthe verification problem for VQCs can be formally defined, and its complexity\nanalyzed. Finally, we demonstrate our approach on standard verification\nbenchmarks.", "comment": "Assolini and Marzari contributed equally to the paper", "pdf_url": "http://arxiv.org/pdf/2507.10635v1", "cate": "quant-ph", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2305.06110", "title": "Pavlok-Nudge: A Feedback Mechanism for Atomic Behaviour Modification with Snoring Usecase", "authors": ["Md Rakibul Hasan", "Shreya Ghosh", "Pradyumna Agrawal", "Zhixi Cai", "Abhinav Dhall", "Tom Gedeon"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Md Rakibul Hasan and Shreya Ghosh are co-first authors", "url": "http://arxiv.org/abs/2305.06110v5", "summary": "This paper proposes an atomic behaviour intervention strategy using the\nPavlok wearable device. Pavlok utilises beeps, vibration and shocks as a mode\nof aversion technique to help individuals with behaviour modification. While\nthe device can be useful in certain periodic daily life situations, like alarms\nand exercise notifications, it relies on manual operations that limit its\nusage. To automate behaviour modification, we propose a framework that first\ndetects targeted behaviours through a lightweight deep learning model and\nsubsequently nudges the user. Our proposed solution is implemented and verified\nin the context of snoring, which captures audio from the environment following\na prediction of whether the audio content is a snore or not using a lightweight\n1D convolutional neural network. Based on the prediction, we use Pavlok to\nnudge users for preventive measures, such as a change in sleeping posture. We\nbelieve that this simple solution can help people change their atomic habits,\nwhich may lead to long-term health benefits. Our proposed lightweight model\n(99.8% fewer parameters over SOTA; 790,273$\\rightarrow$1,337) achieves SOTA\ntest accuracy of 0.99 on a public benchmark. The code and model are publicly\navailable at https://github.com/hasan-rakibul/pavlok-nudge-snore.", "comment": "Md Rakibul Hasan and Shreya Ghosh are co-first authors", "pdf_url": "http://arxiv.org/pdf/2305.06110v5", "cate": "cs.CV", "date": "2023-05-10", "updated": "2025-07-15"}
{"id": "2507.11292", "title": "Fine-Grained Chinese Hate Speech Understanding: Span-Level Resources, Coded Term Lexicon, and Enhanced Detection Frameworks", "authors": ["Zewen Bai", "Liang Yang", "Shengdi Yin", "Yuanyuan Sun", "Hongfei Lin"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11292v1", "summary": "The proliferation of hate speech has inflicted significant societal harm,\nwith its intensity and directionality closely tied to specific targets and\narguments. In recent years, numerous machine learning-based methods have been\ndeveloped to detect hateful comments on online platforms automatically.\nHowever, research on Chinese hate speech detection lags behind, and\ninterpretability studies face two major challenges: first, the scarcity of\nspan-level fine-grained annotated datasets limits models' deep semantic\nunderstanding of hate speech; second, insufficient research on identifying and\ninterpreting coded hate speech restricts model explainability in complex\nreal-world scenarios. To address these, we make the following contributions:\n(1) We introduce the Span-level Target-Aware Toxicity Extraction dataset (STATE\nToxiCN), the first span-level Chinese hate speech dataset, and evaluate the\nhate semantic understanding of existing models using it. (2) We conduct the\nfirst comprehensive study on Chinese coded hate terms, LLMs' ability to\ninterpret hate semantics. (3) We propose a method to integrate an annotated\nlexicon into models, significantly enhancing hate speech detection performance.\nOur work provides valuable resources and insights to advance the\ninterpretability of Chinese hate speech detection research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11292v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2503.10158", "title": "Solving Modular Linear Systems with a Constraint by parallel decomposition of the Smith form and extended Euclidean division modulo powers of primes divisors", "authors": ["Virendra Sule"], "categories": ["math.NT", "cs.DM", "cs.DS", "G.0; G.2.0; I.1.2"], "primary_category": "Subjects:       Number Theory (math.NT)", "pdf_link": null, "comments": "Comments:      17 pages", "url": "http://arxiv.org/abs/2503.10158v3", "summary": "Integral linear systems $Ax=b$ with matrices $A$, $b$ and solutions $x$ are\nalso required to be in integers, can be solved using invariant factors of $A$\n(by computing the Smith Canonical Form of $A$). This paper explores a new\nproblem which arises in applications, that of obtaining conditions for solving\nthe Modular Linear System $Ax=b\\rem n$ given $A,b$ in $\\zz_n$ for $x$ in\n$\\zz_n$ along with the constraint that the value of the linear function\n$\\phi(x)=\\la w,x\\ra$ is coprime to $n$ for some solution $x$. In this paper we\ndevelop decomposition of the system to coprime moduli $p^{r(p)}$ which are\ndivisors of $n$ and show how such a decomposition simplifies the computation of\nSmith form. This extends the well known index calculus method of computing the\ndiscrete logarithm where the moduli over which the linear system is reduced\nwere assumed to be prime (to solve the reduced systems over prime fields) to\nthe case when the factors of the modulus are prime powers $p^{r(p)}$. It is\nshown how this problem can be addressed effciently using the invariant factors\nand Smith form of the augmented matrix $[A,-p^{r(p)}I]$ and conditions modulo\n$p$ satisfied by $w$, where $p^{r(p)}$ vary over all divisors of $n$ with $p$\nprime.", "comment": "17 pages", "pdf_url": "http://arxiv.org/pdf/2503.10158v3", "cate": "math.NT", "date": "2025-03-13", "updated": "2025-07-15"}
{"id": "2507.11132", "title": "Convergence of a finite-volume scheme for aggregation-diffusion equations with saturation", "authors": ["David Gómez-Castro"], "categories": ["math.NA", "cs.NA", "math.AP", "65M08, 35Q70, 35Q92, 45K05"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11132v1", "summary": "In [Bailo, Carrillo, Hu. SIAM J. Appl. Math. 2023] the authors introduce a\nfinite-volume method for aggregation-diffusion equations with non-linear\nmobility. In this paper we prove convergence of this method using an\nAubin--Simons compactness theorem due to Gallou\\\"et and Latch\\'e. We use\nsuitable discrete $H^1$ and $W^{-1,1}$ discrete norms. We provide two\nconvergence results. A first result shows convergence with general entropies\n($U$) (including singular and degenerate) if the initial datum does not have\nfree boundaries, the mobility is Lipschitz, and the confinement ($V$) and\naggregation ($K$) potentials are $W^{2,\\infty}_0$. A second result shows\nconvergence when the initial datum has free boundaries, mobility is just\ncontinuous, and $V$ and $K$ are $W^{1,\\infty}$, but under the assumption that\nthe entropy $U$ is $C^1$ and strictly convex.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11132v1", "cate": "math.NA", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2412.03884", "title": "A Unified Framework for Evaluating the Effectiveness and Enhancing the Transparency of Explainable AI Methods in Real-World Applications", "authors": ["Md. Ariful Islam", "Md Abrar Jahin", "M. F. Mridha", "Nilanjan Dey"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.03884v2", "summary": "The fast growth of deep learning has brought great progress in AI-based\napplications. However, these models are often seen as \"black boxes,\" which\nmakes them hard to understand, explain, or trust. Explainable Artificial\nIntelligence (XAI) tries to make AI decisions clearer so that people can\nunderstand how and why the model makes certain choices. Even though many\nstudies have focused on XAI, there is still a lack of standard ways to measure\nhow well these explanation methods work in real-world situations. This study\nintroduces a single evaluation framework for XAI. It uses both numbers and user\nfeedback to check if the explanations are correct, easy to understand, fair,\ncomplete, and reliable. The framework focuses on users' needs and different\napplication areas, which helps improve the trust and use of AI in important\nfields. To fix problems in current evaluation methods, we propose clear steps,\nincluding loading data, creating explanations, and fully testing them. We also\nsuggest setting common benchmarks. We show the value of this framework through\ncase studies in healthcare, finance, farming, and self-driving systems. These\nexamples prove that our method can support fair and trustworthy evaluation of\nXAI methods. This work gives a clear and practical way to improve transparency\nand trust in AI systems used in the real world.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.03884v2", "cate": "cs.AI", "date": "2024-12-05", "updated": "2025-07-15"}
{"id": "2507.10701", "title": "Kernel Learning for Mean-Variance Trading Strategies", "authors": ["Owen Futter", "Nicola Muca Cirone", "Blanka Horvath"], "categories": ["q-fin.TR", "cs.LG", "q-fin.MF", "q-fin.PM"], "primary_category": "Subjects:       Trading and Market Microstructure (q-fin.TR)", "pdf_link": null, "comments": "Comments:      49 pages", "url": "http://arxiv.org/abs/2507.10701v1", "summary": "In this article, we develop a kernel-based framework for constructing\ndynamic, pathdependent trading strategies under a mean-variance optimisation\ncriterion. Building on the theoretical results of (Muca Cirone and Salvi,\n2025), we parameterise trading strategies as functions in a reproducing kernel\nHilbert space (RKHS), enabling a flexible and non-Markovian approach to optimal\nportfolio problems. We compare this with the signature-based framework of\n(Futter, Horvath, Wiese, 2023) and demonstrate that both significantly\noutperform classical Markovian methods when the asset dynamics or predictive\nsignals exhibit temporal dependencies for both synthetic and market-data\nexamples. Using kernels in this context provides significant modelling\nflexibility, as the choice of feature embedding can range from randomised\nsignatures to the final layers of neural network architectures. Crucially, our\nframework retains closed-form solutions and provides an alternative to\ngradient-based optimisation.", "comment": "49 pages", "pdf_url": "http://arxiv.org/pdf/2507.10701v1", "cate": "q-fin.TR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2310.14162", "title": "Augmenting End-to-End Steering Angle Prediction with CAN Bus Data", "authors": ["Amit Singh"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      5 pages", "url": "http://arxiv.org/abs/2310.14162v2", "summary": "In recent years, end to end steering prediction for autonomous vehicles has\nbecome a major area of research. The primary method for achieving end to end\nsteering was to use computer vision models on a live feed of video data.\nHowever, to further increase accuracy, many companies have added data from\nlight detection and ranging (LiDAR) and or radar sensors through sensor fusion.\nHowever, the addition of lasers and sensors comes at a high financial cost. In\nthis paper, I address both of these issues by increasing the accuracy of the\ncomputer vision models without the increased cost of using LiDAR and or\nsensors. I achieved this by improving the accuracy of computer vision models by\nsensor fusing CAN bus data, a vehicle protocol, with video data. CAN bus data\nis a rich source of information about the vehicle's state, including its speed,\nsteering angle, and acceleration. By fusing this data with video data, the\naccuracy of the computer vision model's predictions can be improved. When I\ntrained the model without CAN bus data, I obtained an RMSE of 0.02492, while\nthe model trained with the CAN bus data achieved an RMSE of 0.01970. This\nfinding indicates that fusing CAN Bus data with video data can reduce the\ncomputer vision model's prediction error by 20% with some models decreasing the\nerror by 80%.", "comment": "5 pages", "pdf_url": "http://arxiv.org/pdf/2310.14162v2", "cate": "cs.CV", "date": "2023-10-22", "updated": "2025-07-15"}
{"id": "2507.11299", "title": "Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian", "authors": ["Andrei Niculae", "Adrian Cosma", "Cosmin Dumitrache", "Emilian Rǎdoi"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 figures, 2 tables, 2 listings", "url": "http://arxiv.org/abs/2507.11299v1", "summary": "Text-based telemedicine has become increasingly common, yet the quality of\nmedical advice in doctor-patient interactions is often judged more on how\nadvice is communicated rather than its clinical accuracy. To address this, we\nintroduce Dr.Copilot , a multi-agent large language model (LLM) system that\nsupports Romanian-speaking doctors by evaluating and enhancing the presentation\nquality of their written responses. Rather than assessing medical correctness,\nDr.Copilot provides feedback along 17 interpretable axes. The system comprises\nof three LLM agents with prompts automatically optimized via DSPy. Designed\nwith low-resource Romanian data and deployed using open-weight models, it\ndelivers real-time specific feedback to doctors within a telemedicine platform.\nEmpirical evaluations and live deployment with 41 doctors show measurable\nimprovements in user reviews and response quality, marking one of the first\nreal-world deployments of LLMs in Romanian medical settings.", "comment": "10 figures, 2 tables, 2 listings", "pdf_url": "http://arxiv.org/pdf/2507.11299v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2506.11355", "title": "Few Single-Qubit Measurements Suffice to Certify Any Quantum State", "authors": ["Meghal Gupta", "William He", "Ryan O'Donnell"], "categories": ["quant-ph", "cs.DS"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.11355v2", "summary": "A fundamental task in quantum information science is state certification:\ntesting whether a lab-prepared $n$-qubit state is close to a given hypothesis\nstate. In this work, we show that every pure hypothesis state can be certified\nusing only $O(n^2)$ single-qubit measurements applied to $O(n)$ copies of the\nlab state. Prior to our work, it was not known whether even subexponentially\nmany single-qubit measurements could suffice to certify arbitrary states. This\nresolves the main open question of Huang, Preskill, and Soleimanifar (FOCS\n2024, QIP 2024).\n  Our algorithm also showcases the power of adaptive measurements: within each\ncopy of the lab state, previous measurement outcomes dictate how subsequent\nqubit measurements are made. We show that the adaptivity is necessary, by\nproving an exponential lower bound on the number of copies needed for any\nnonadaptive single-qubit measurement algorithm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.11355v2", "cate": "quant-ph", "date": "2025-06-12", "updated": "2025-07-15"}
{"id": "2507.11193", "title": "Adaptive FEM with explicit time integration for the wave equation", "authors": ["Marcus J. Grote", "Omar Lakkis", "Carina S. Santos"], "categories": ["math.NA", "cs.NA", "65M60, 65M22, 65J10, 35A35, 35L05,", "G.1.8; G.4"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11193v1", "summary": "Starting from a recent a posteriori error estimator for the finite element\nsolution of the wave equation with explicit time-stepping [Grote, Lakkis,\nSantos, 2024], we devise a space-time adaptive strategy which includes both\ntime evolving meshes and local time-stepping [Diaz, Grote, 2009] to overcome\nany overly stringent CFL stability restriction on the time-step due to local\nmesh refinement. Moreover, at each time-step the adaptive algorithm monitors\nthe accuracy thanks to the error indicators and recomputes the current step on\na refined mesh until the desired tolerance is met; meanwhile, the mesh is\ncoarsened in regions of smaller errors. Leapfrog based local time-stepping is\napplied in all regions of local mesh refinement to incorporate adaptivity into\nfully explicit time integration with mesh change while retaining efficiency.\nNumerical results illustrate the optimal rate of convergence of the a\nposteriori error estimators on time evolving meshes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11193v1", "cate": "math.NA", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2412.04057", "title": "From Code to Play: Benchmarking Program Search for Games Using Large Language Models", "authors": ["Manuel Eberhardinger", "James Goodman", "Alexander Dockhorn", "Diego Perez-Liebana", "Raluca D. Gaina", "Duygu Çakmak", "Setareh Maghsudi", "Simon Lucas"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Submitted to Transactions on Games Special Issue on Large Language Models and Games, standardised LLMs used and run more experiments", "url": "http://arxiv.org/abs/2412.04057v2", "summary": "Large language models (LLMs) have shown impressive capabilities in generating\nprogram code, opening exciting opportunities for applying program synthesis to\ngames. In this work, we explore the potential of LLMs to directly synthesize\nusable code for a wide range of gaming applications, focusing on two\nprogramming languages, Python and Java. We use an evolutionary hill-climbing\nalgorithm, where the mutations and seeds of the initial programs are controlled\nby LLMs. For Python, the framework covers various game-related tasks, including\nfive miniature versions of Atari games, ten levels of Baba is You, an\nenvironment inspired by Asteroids, and a maze generation task. For Java, the\nframework contains 12 games from the TAG tabletop games framework. Across 29\ntasks, we evaluated 12 language models for Python and 8 for Java. Our findings\nsuggest that the performance of LLMs depends more on the task than on model\nsize. While larger models generate more executable programs, these do not\nalways result in higher-quality solutions but are much more expensive. No model\nhas a clear advantage, although on any specific task, one model may be better.\nTrying many models on a problem and using the best results across them is more\nreliable than using just one.", "comment": "Submitted to Transactions on Games Special Issue on Large Language\n  Models and Games, standardised LLMs used and run more experiments", "pdf_url": "http://arxiv.org/pdf/2412.04057v2", "cate": "cs.AI", "date": "2024-12-05", "updated": "2025-07-15"}
{"id": "2507.10710", "title": "Robust Multi-Manifold Clustering via Simplex Paths", "authors": ["Haoyu Chen", "Anna Little", "Akin Narayan"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10710v1", "summary": "This article introduces a novel, geometric approach for multi-manifold\nclustering (MMC), i.e. for clustering a collection of potentially intersecting,\nd-dimensional manifolds into the individual manifold components. We first\ncompute a locality graph on d-simplices, using the dihedral angle in between\nadjacent simplices as the graph weights, and then compute infinity path\ndistances in this simplex graph. This procedure gives a metric on simplices\nwhich we refer to as the largest angle path distance (LAPD). We analyze the\nproperties of LAPD under random sampling, and prove that with an appropriate\ndenoising procedure, this metric separates the manifold components with high\nprobability. We validate the proposed methodology with extensive numerical\nexperiments on both synthetic and real-world data sets. These experiments\ndemonstrate that the method is robust to noise, curvature, and small\nintersection angle, and generally out-performs other MMC algorithms. In\naddition, we provide a highly scalable implementation of the proposed\nalgorithm, which leverages approximation schemes for infinity path distance to\nachieve quasi-linear computational complexity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10710v1", "cate": "stat.ML", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2404.01064", "title": "Roadside Monocular 3D Detection Prompted by 2D Detection", "authors": ["Yechi Ma", "Yanan Li", "Wei Hua", "Shu Kong"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.01064v3", "summary": "Roadside monocular 3D detection requires detecting objects of predefined\nclasses in an RGB frame and predicting their 3D attributes, such as\nbird's-eye-view (BEV) locations. It has broad applications in traffic control,\nvehicle-vehicle communication, and vehicle-infrastructure cooperative\nperception. To address this task, we introduce Promptable 3D Detector (Pro3D),\na novel detector design that leverages 2D detections as prompts. We build our\nPro3D upon two key insights. First, compared to a typical 3D detector, a 2D\ndetector is ``easier'' to train due to fewer loss terms and performs\nsignificantly better at localizing objects w.r.t 2D metrics. Second, once 2D\ndetections precisely locate objects in the image, a 3D detector can focus on\nlifting these detections into 3D BEV, especially when fixed camera pose or\nscene geometry provide an informative prior. To encode and incorporate 2D\ndetections, we explore three methods: (a) concatenating features from both 2D\nand 3D detectors, (b) attentively fusing 2D and 3D detector features, and (c)\nencoding properties of predicted 2D bounding boxes \\{$x$, $y$, width, height,\nlabel\\} and attentively fusing them with the 3D detector feature.\nInterestingly, the third method significantly outperforms the others,\nunderscoring the effectiveness of 2D detections as prompts that offer precise\nobject targets and allow the 3D detector to focus on lifting them into 3D.\nPro3D is adaptable for use with a wide range of 2D and 3D detectors with\nminimal modifications. Comprehensive experiments demonstrate that our Pro3D\nsignificantly enhances existing methods, achieving state-of-the-art results on\ntwo contemporary benchmarks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.01064v3", "cate": "cs.CV", "date": "2024-04-01", "updated": "2025-07-15"}
{"id": "2507.11356", "title": "What is the Best Process Model Representation? A Comparative Analysis for Process Modeling with Large Language Models", "authors": ["Alexis Brissard", "Frédéric Cuppens", "Amal Zouaq"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages, 7 figures, to be published in AI4BPM 2025 Proceedings", "url": "http://arxiv.org/abs/2507.11356v1", "summary": "Large Language Models (LLMs) are increasingly applied for Process Modeling\n(PMo) tasks such as Process Model Generation (PMG). To support these tasks,\nresearchers have introduced a variety of Process Model Representations (PMRs)\nthat serve as model abstractions or generation targets. However, these PMRs\ndiffer widely in structure, complexity, and usability, and have never been\nsystematically compared. Moreover, recent PMG approaches rely on distinct\nevaluation strategies and generation techniques, making comparison difficult.\nThis paper presents the first empirical study that evaluates multiple PMRs in\nthe context of PMo with LLMs. We introduce the PMo Dataset, a new dataset\ncontaining 55 process descriptions paired with models in nine different PMRs.\nWe evaluate PMRs along two dimensions: suitability for LLM-based PMo and\nperformance on PMG. \\textit{Mermaid} achieves the highest overall score across\nsix PMo criteria, whereas \\textit{BPMN text} delivers the best PMG results in\nterms of process element similarity.", "comment": "12 pages, 7 figures, to be published in AI4BPM 2025 Proceedings", "pdf_url": "http://arxiv.org/pdf/2507.11356v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.00059", "title": "Verification of Hamiltonian Path Conjecture (BHR Conjecture) for Integers up to p=31 based on one multiset per FP", "authors": ["Ranjan N Naik"], "categories": ["cs.DM", "cs.DS", "math.CO"], "primary_category": "Subjects:       Discrete Mathematics (cs.DM)", "pdf_link": null, "comments": "Comments:      This result supports the results by Mariusz Meszka for all primes up to 23 (included) with the aid of a computer", "url": "http://arxiv.org/abs/2507.00059v3", "summary": "This paper presents a computational approach to verify a specific conjecture\nconcerning Hamiltonian paths in complete graphs with prescribed edge lengths,\noften referred to as the Buratti $-$ Horak-Rosa Conjecture. Building upon prior\ncomputational work by Mariusz Meszka which verified the conjecture for all\nprimes up to 23, our Python program does the BHR conjecture verification for\ncomposite and prime numbers up to p=32 in a different way by taking into\naccount one mulltiset per frequency partition (FP). We report successful\ncomputational verification for all frequency partitions for integers $p < 32$,\nspecifically presenting results for $p=31$. For the composite number $p = 30$,\nthe Python code took approximately 11 hours to verify on a Lenovo laptop. The\nmethod systematically generates frequency partitions of edge lengths and\nemploys a recursive backtracking algorithm to construct the corresponding\nHamiltonian paths. The presented program is optimized for efficiency and\ndesigned for scalability, allowing for its utilization on more powerful\ncomputing resources to explore even higher integer values, thereby providing\nfurther evidence for the conjecture's validity.\n  The conjecture of Peter Horak and Alex Rosa (generalizing that of Marco\nBuratti) states that a multiset L of (p-1) positive integers not exceeding\n$[p/2]$ is the list of edge lengths of a suitable Hamiltonian path of the\ncomplete graph with vertex-set of {1, 2, ..., [p-1]} if and only if for every\ndivisor d of p, the number of multiples of d appearing in L is at most [p-d].", "comment": "This result supports the results by Mariusz Meszka for all primes up\n  to 23 (included) with the aid of a computer", "pdf_url": "http://arxiv.org/pdf/2507.00059v3", "cate": "cs.DM", "date": "2025-06-26", "updated": "2025-07-14"}
{"id": "2507.11207", "title": "On maximal curves of $n$-correct sets", "authors": ["H. Hakopian", "G. Vardanyan", "N. Vardanyan"], "categories": ["math.NA", "cs.NA", "math.AG", "41A05, 41A63, 14H50"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      20 pages, 2 figures", "url": "http://arxiv.org/abs/2507.11207v1", "summary": "Suppose $\\mathcal{X}$ is an $n$-correct set of nodes in the plane, that is,\nit admits a unisolvent interpolation with bivariate polynomials of total degree\nless than or equal to $n.$ Then an algebraic curve $q$ of degree $k\\le n$ can\npass through at most $d(n,k)$ nodes of $\\Xset,$ where $d(n,k)={{n+2}\\choose\n{2}}-{{n+2-k}\\choose {2}}.$ A curve $q$ of degree $k\\le n$ is called maximal if\nit passes through exactly $d(n,k)$ nodes of $\\mathcal{X}.$ In particular, a\nmaximal line is a line passing through $d(n,1)=n+1$ nodes of $\\mathcal{X}.$\nMaximal curves are an important tool for the study of $n$-correct sets. We\npresent new properties of maximal curves, as well as extensions of known\nproperties.", "comment": "20 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.11207v1", "cate": "math.NA", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10573", "title": "Device-Level Optimization Techniques for Solid-State Drives: A Survey", "authors": ["Tianyu Ren", "Yajuan Du", "Jinhua Cui", "Yina Lv", "Qiao Li", "Chun Jason Xue"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10573v1", "summary": "Solid-state drives (SSDs) have revolutionized data storage with their high\nperformance, energy efficiency, and reliability. However, as storage demands\ngrow, SSDs face critical challenges in scalability, endurance, latency, and\nsecurity. This survey provides a comprehensive analysis of SSD architecture,\nkey challenges, and device-level optimization techniques. We first examine the\nfundamental components of SSDs, including NAND flash memory structures, SSD\ncontroller functionalities (e.g., address mapping, garbage collection, wear\nleveling), and host interface protocols (SATA, SAS, NVMe). Next, we discuss\nmajor challenges such as reliability degradation, endurance limitations,\nlatency variations, and security threats (e.g., secure deletion, ransomware\ndefense). We then explore advanced optimization techniques, including error\ncorrection mechanisms, flash translation layer (FTL) enhancements, and emerging\narchitectures like zoned namespace (ZNS) SSDs and flexible data placement\n(FDP). Finally, we highlight open research challenges, such as QLC/PLC NAND\nscalability, performance-reliability trade-offs, and SSD optimizations for\nAI/LLM workloads. This survey aims to guide future research in developing\nnext-generation SSDs that balance performance, longevity, and security in\nevolving storage ecosystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10573v1", "cate": "cs.AR", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2412.18424", "title": "LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating", "authors": ["Chao Deng", "Jiale Yuan", "Pi Bu", "Peijie Wang", "Zhong-Zhi Li", "Jian Xu", "Xiao-Hui Li", "Yuan Gao", "Jun Song", "Bo Zheng", "Cheng-Lin Liu"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.18424v3", "summary": "Large vision language models (LVLMs) have improved the document understanding\ncapabilities remarkably, enabling the handling of complex document elements,\nlonger contexts, and a wider range of tasks. However, existing document\nunderstanding benchmarks have been limited to handling only a small number of\npages and fail to provide a comprehensive analysis of layout elements locating.\nIn this paper, we first define three primary task categories: Long Document\nUnderstanding, numerical Reasoning, and cross-element Locating, and then\npropose a comprehensive benchmark, LongDocURL, integrating above three primary\ntasks and comprising 20 sub-tasks categorized based on different primary tasks\nand answer evidences. Furthermore, we develop a semi-automated construction\npipeline and collect 2,325 high-quality question-answering pairs, covering more\nthan 33,000 pages of documents, significantly outperforming existing\nbenchmarks. Subsequently, we conduct comprehensive evaluation experiments on\nboth open-source and closed-source models across 26 different configurations,\nrevealing critical performance gaps in this field.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.18424v3", "cate": "cs.AI", "date": "2024-12-24", "updated": "2025-07-15"}
{"id": "2507.10715", "title": "Real-time, Adaptive Radiological Anomaly Detection and Isotope Identification Using Non-negative Matrix Factorization", "authors": ["Chandler Jones", "Mark Bandstra", "Stefan Faaland", "Yue Shi Lai", "Nico Abgrall", "Scott Suchyta", "Reynold Cooper"], "categories": ["physics.app-ph", "cs.LG"], "primary_category": "Subjects:       Applied Physics (physics.app-ph)", "pdf_link": null, "comments": "Comments:      11 pages, 8 figures", "url": "http://arxiv.org/abs/2507.10715v1", "summary": "Spectroscopic anomaly detection and isotope identification algorithms are\nintegral components in nuclear nonproliferation applications such as search\noperations. The task is especially challenging in the case of mobile detector\nsystems due to the fact that the observed gamma-ray background changes more\nthan for a static detector system, and a pretrained background model can easily\nfind itself out of domain. The result is that algorithms may exceed their\nintended false alarm rate, or sacrifice detection sensitivity in order to\nmaintain the desired false alarm rate. Non-negative matrix factorization (NMF)\nhas been shown to be a powerful tool for spectral anomaly detection and\nidentification, but, like many similar algorithms that rely on data-driven\nbackground models, in its conventional implementation it is unable to update in\nreal time to account for environmental changes that affect the background\nspectroscopic signature. We have developed a novel NMF-based algorithm that\nperiodically updates its background model to accommodate changing environmental\nconditions. The Adaptive NMF algorithm involves fewer assumptions about its\nenvironment, making it more generalizable than existing NMF-based methods while\nmaintaining or exceeding detection performance on simulated and real-world\ndatasets.", "comment": "11 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.10715v1", "cate": "physics.app-ph", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2406.03262", "title": "A Comprehensive Library for Benchmarking Multi-class Visual Anomaly Detection", "authors": ["Jiangning Zhang", "Haoyang He", "Zhenye Gan", "Qingdong He", "Yuxuan Cai", "Zhucun Xue", "Yabiao Wang", "Chengjie Wang", "Lei Xie", "Yong Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.03262v4", "summary": "Visual anomaly detection aims to identify anomalous regions in images through\nunsupervised learning paradigms, with increasing application demand and value\nin fields such as industrial inspection and medical lesion detection. Despite\nsignificant progress in recent years, there is a lack of comprehensive\nbenchmarks to adequately evaluate the performance of various mainstream methods\nacross different datasets under the practical multi-class setting. The absence\nof standardized experimental setups can lead to potential biases in training\nepochs, resolution, and metric results, resulting in erroneous conclusions.\nThis paper addresses this issue by proposing a comprehensive visual anomaly\ndetection benchmark, ADer, which is a modular framework that is highly\nextensible for new methods. The benchmark includes multiple datasets from\nindustrial and medical domains, implementing fifteen state-of-the-art methods\nand nine comprehensive metrics. Additionally, we have proposed the GPU-assisted\nADEval package to address the slow evaluation problem of metrics like\ntime-consuming mAU-PRO on large-scale data, significantly reducing evaluation\ntime by more than \\textit{1000-fold}. Through extensive experimental results,\nwe objectively reveal the strengths and weaknesses of different methods and\nprovide insights into the challenges and future directions of multi-class\nvisual anomaly detection. We hope that ADer will become a valuable resource for\nresearchers and practitioners in the field, promoting the development of more\nrobust and generalizable anomaly detection systems. Full codes are open-sourced\nat https://github.com/zhangzjn/ader.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.03262v4", "cate": "cs.CV", "date": "2024-06-05", "updated": "2025-07-15"}
{"id": "2507.11384", "title": "Addressing Data Imbalance in Transformer-Based Multi-Label Emotion Detection with Weighted Loss", "authors": ["Xia Cui"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages, 1 figure, SemEval 2025", "url": "http://arxiv.org/abs/2507.11384v1", "summary": "This paper explores the application of a simple weighted loss function to\nTransformer-based models for multi-label emotion detection in SemEval-2025\nShared Task 11. Our approach addresses data imbalance by dynamically adjusting\nclass weights, thereby enhancing performance on minority emotion classes\nwithout the computational burden of traditional resampling methods. We evaluate\nBERT, RoBERTa, and BART on the BRIGHTER dataset, using evaluation metrics such\nas Micro F1, Macro F1, ROC-AUC, Accuracy, and Jaccard similarity coefficients.\nThe results demonstrate that the weighted loss function improves performance on\nhigh-frequency emotion classes but shows limited impact on minority classes.\nThese findings underscore both the effectiveness and the challenges of applying\nthis approach to imbalanced multi-label emotion detection.", "comment": "10 pages, 1 figure, SemEval 2025", "pdf_url": "http://arxiv.org/pdf/2507.11384v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11201", "title": "Energy Balance and Optical Theorem for Time-Modulated Subwavelength Resonator Arrays", "authors": ["Erik Orvehed Hiltunen", "Liora Rueff"], "categories": ["physics.optics", "cs.NA", "math-ph", "math.AP", "math.MP", "math.NA", "35Q60, 35L05, 78A45, 78M35, 35P25"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "Comments:      19 pages, 10 figures", "url": "http://arxiv.org/abs/2507.11201v1", "summary": "We study wave propagation through a one-dimensional array of subwavelength\nresonators with periodically time-modulated material parameters. Focusing on a\nhigh-contrast regime, we use a scattering framework based on Fourier expansions\nand scattering matrix techniques to capture the interactions between an\nincident wave and the temporally varying system. This way, we derive a\nformulation of the total energy flux corresponding to time-dependent systems of\nresonators. We show that the total energy flux is composed of the transmitted\nand reflected energy fluxes, and derive an optical theorem which characterises\nthe energy balance of the system. We provide a number of numerical experiments\nto investigate the impact of the time-dependency, the operating frequency and\nthe number of resonators on the maximal attainable energy gain and energy loss.\nMoreover, we show the existence of lasing points, at which the total energy\ndiverges. Our results lay the foundation for the design of energy dissipative\nor energy amplifying systems.", "comment": "19 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.11201v1", "cate": "physics.optics", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10748", "title": "LASANA: Large-scale Surrogate Modeling for Analog Neuromorphic Architecture Exploration", "authors": ["Jason Ho", "James A. Boyle", "Linshen Liu", "Andreas Gerstlauer"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10748v1", "summary": "Neuromorphic systems using in-memory or event-driven computing are motivated\nby the need for more energy-efficient processing of artificial intelligence\nworkloads. Emerging neuromorphic architectures aim to combine traditional\ndigital designs with the computational efficiency of analog computing and novel\ndevice technologies. A crucial problem in the rapid exploration and co-design\nof such architectures is the lack of tools for fast and accurate modeling and\nsimulation. Typical mixed-signal design tools integrate a digital simulator\nwith an analog solver like SPICE, which is prohibitively slow for large\nsystems. By contrast, behavioral modeling of analog components is faster, but\nexisting approaches are fixed to specific architectures with limited energy and\nperformance modeling. In this paper, we propose LASANA, a novel approach that\nleverages machine learning to derive data-driven surrogate models of analog\nsub-blocks in a digital backend architecture. LASANA uses SPICE-level\nsimulations of a circuit to train ML models that predict circuit energy,\nperformance, and behavior at analog/digital interfaces. Such models can provide\nenergy and performance annotation on top of existing behavioral models or\nfunction as replacements to analog simulation. We apply LASANA to an analog\ncrossbar array and a spiking neuron circuit. Running MNIST and spiking MNIST,\nLASANA surrogates demonstrate up to three orders of magnitude speedup over\nSPICE, with energy, latency, and behavioral error less than 7%, 8%, and 2%,\nrespectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10748v1", "cate": "cs.AR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2501.04614", "title": "XGeM: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation", "authors": ["Daniele Molino", "Francesco Di Feola", "Eliodoro Faiella", "Deborah Fazzini", "Domiziana Santucci", "Linlin Shen", "Valerio Guarrasi", "Paolo Soda"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.04614v4", "summary": "The adoption of Artificial Intelligence in medical imaging holds great\npromise, yet it remains hindered by challenges such as data scarcity, privacy\nconcerns, and the need for robust multimodal integration. While recent advances\nin generative modeling have enabled high-quality synthetic data generation,\nexisting approaches are often limited to unimodal, unidirectional synthesis and\ntherefore lack the ability to jointly synthesize multiple modalities while\npreserving clinical consistency. To address this challenge, we introduce XGeM,\na 6.77-billion-parameter multimodal generative model designed to support\nflexible, any-to-any synthesis between medical data modalities. XGeM constructs\na shared latent space via contrastive learning and introduces a novel\nMulti-Prompt Training strategy, enabling conditioning on arbitrary subsets of\ninput modalities. This design allows the model to adapt to heterogeneous\nclinical inputs and generate multiple outputs jointly, preserving both semantic\nand structural coherence. We extensively validate XGeM: first we benchmark it\nagainst five competitors on the MIMIC-CXR dataset, a state-of-the-art dataset\nfor multi-view Chest X-ray and radiological report generation. Secondly, we\nperform a Visual Turing Test with expert radiologists to assess the realism and\nclinical relevance of the generated data, ensuring alignment with real-world\nscenarios. Finally, we show how XGeM can support key medical data challenges\nsuch as anonymization, class imbalance, and data scarcity, underscoring its\nutility as a foundation model for medical data synthesis. Project page is at\nhttps://cosbidev.github.io/XGeM/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.04614v4", "cate": "cs.AI", "date": "2025-01-08", "updated": "2025-07-14"}
{"id": "2507.10835", "title": "Functional Neural Wavefunction Optimization", "authors": ["Victor Armegioiu", "Juan Carrasquilla", "Siddhartha Mishra", "Johannes Müller", "Jannes Nys", "Marius Zeinhofer", "Hang Zhang"], "categories": ["cond-mat.str-el", "cs.LG", "math.OC", "physics.comp-ph", "quant-ph"], "primary_category": "Subjects:       Strongly Correlated Electrons (cond-mat.str-el)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10835v1", "summary": "We propose a framework for the design and analysis of optimization algorithms\nin variational quantum Monte Carlo, drawing on geometric insights into the\ncorresponding function space. The framework translates infinite-dimensional\noptimization dynamics into tractable parameter-space algorithms through a\nGalerkin projection onto the tangent space of the variational ansatz. This\nperspective unifies existing methods such as stochastic reconfiguration and\nRayleigh-Gauss-Newton, provides connections to classic function-space\nalgorithms, and motivates the derivation of novel algorithms with geometrically\nprincipled hyperparameter choices. We validate our framework with numerical\nexperiments demonstrating its practical relevance through the accurate\nestimation of ground-state energies for several prototypical models in\ncondensed matter physics modeled with neural network wavefunctions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10835v1", "cate": "cond-mat.str-el", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2407.06109", "title": "PerLDiff: Controllable Street View Synthesis Using Perspective-Layout Diffusion Models", "authors": ["Jinhua Zhang", "Hualian Sheng", "Sijia Cai", "Bing Deng", "Qiao Liang", "Wen Li", "Ying Fu", "Jieping Ye", "Shuhang Gu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2407.06109v5", "summary": "Controllable generation is considered a potentially vital approach to address\nthe challenge of annotating 3D data, and the precision of such controllable\ngeneration becomes particularly imperative in the context of data production\nfor autonomous driving. Existing methods focus on the integration of diverse\ngenerative information into controlling inputs, utilizing frameworks such as\nGLIGEN or ControlNet, to produce commendable outcomes in controllable\ngeneration. However, such approaches intrinsically restrict generation\nperformance to the learning capacities of predefined network architectures. In\nthis paper, we explore the innovative integration of controlling information\nand introduce PerLDiff (\\textbf{Per}spective-\\textbf{L}ayout \\textbf{Diff}usion\nModels), a novel method for effective street view image generation that fully\nleverages perspective 3D geometric information. Our PerLDiff employs 3D\ngeometric priors to guide the generation of street view images with precise\nobject-level control within the network learning process, resulting in a more\nrobust and controllable output. Moreover, it demonstrates superior\ncontrollability compared to alternative layout control methods. Empirical\nresults justify that our PerLDiff markedly enhances the precision of\ncontrollable generation on the NuScenes and KITTI datasets.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2407.06109v5", "cate": "cs.CV", "date": "2024-07-08", "updated": "2025-07-15"}
{"id": "2507.11405", "title": "DCR: Quantifying Data Contamination in LLMs Evaluation", "authors": ["Cheng Xu", "Nan Yan", "Shuhao Guan", "Changhong Jin", "Yuke Mei", "Yibing Guo", "M-Tahar Kechadi"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11405v1", "summary": "The rapid advancement of large language models (LLMs) has heightened concerns\nabout benchmark data contamination (BDC), where models inadvertently memorize\nevaluation data, inflating performance metrics and undermining genuine\ngeneralization assessment. This paper introduces the Data Contamination Risk\n(DCR) framework, a lightweight, interpretable pipeline designed to detect and\nquantify BDC across four granular levels: semantic, informational, data, and\nlabel. By synthesizing contamination scores via a fuzzy inference system, DCR\nproduces a unified DCR Factor that adjusts raw accuracy to reflect\ncontamination-aware performance. Validated on 9 LLMs (0.5B-72B) across\nsentiment analysis, fake news detection, and arithmetic reasoning tasks, the\nDCR framework reliably diagnoses contamination severity and with accuracy\nadjusted using the DCR Factor to within 4% average error across the three\nbenchmarks compared to the uncontaminated baseline. Emphasizing computational\nefficiency and transparency, DCR provides a practical tool for integrating\ncontamination assessment into routine evaluations, fostering fairer comparisons\nand enhancing the credibility of LLM benchmarking practices.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11405v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11253", "title": "Second-Order Characterizations of Tilt Stability in Composite Optimization", "authors": ["Boris S. Mordukhovich", "Peipei Tang", "Chengjing Wang"], "categories": ["math.OC", "cs.NA", "math.NA", "49J52, 49J53, 90C31"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      32 pages", "url": "http://arxiv.org/abs/2507.11253v1", "summary": "Tilt stability is a fundamental concept of variational analysis and\noptimization that plays a pivotal role in both theoretical issues and numerical\ncomputations. This paper investigates tilt stability of local minimizers for a\ngeneral class of composite optimization problems in finite dimensions, where\nextended-real-valued objectives are compositions of parabolically regular and\nsmooth functions. Under the weakest metric subregularity constraint\nqualification and other verifiable conditions, we establish unified\nneighborhood and pointbased characterizations of tilt stability via\nsecond-order generalized differentiation. The obtained results provide a\nrigorous theoretical foundation for further developments on variational\nstability and numerical algorithms of optimization and related topics.", "comment": "32 pages", "pdf_url": "http://arxiv.org/pdf/2507.11253v1", "cate": "math.OC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10912", "title": "Mapping Fusion: Improving FPGA Technology Mapping with ASIC Mapper", "authors": ["Cunxi Yu"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      7 pages. to appear at MLCAD 2025", "url": "http://arxiv.org/abs/2507.10912v1", "summary": "LUT (Look-Up Table) mapping is a critical step in FPGA logic synthesis, where\na logic network is transformed into a form that can be directly implemented\nusing the FPGA's LUTs. An FPGA LUT is a flexible digital memory structure that\ncan implement any logic function of a limited number of inputs, typically 4 to\n6 inputs, depending on the FPGA architecture. The goal of LUT mapping is to map\nthe Boolean network into LUTs, where each LUT can implement any function with a\nfixed number of inputs. In parallel to FPGA technology mapping, ASIC technology\nmapping maps the Boolean network to user-defined standard cells, which has\ntraditionally been developed separately from LUT mapping algorithms. However,\nin this work, our motivating examples demonstrate that ASIC technology mappers\ncan potentially improve the performance of LUT mappers, such that standard cell\nmapping and LUT mapping work in an incremental manner.\n  Therefore, we propose the FuseMap framework, which explores this opportunity\nto improve LUT mapping in the FPGA design flow by utilizing reinforcement\nlearning to make design-specific choices during cell selection. The\neffectiveness of FuseMap is evaluated on a wide range of benchmarks, different\ntechnology libraries, and technology mappers. The experimental results\ndemonstrate that FuseMap achieves higher mapping accuracy while reducing delay\nand area across diverse circuit designs collected from ISCAS 85/89, ITC/ISCAS\n99, VTR 8.0, and EPFL benchmarks.", "comment": "7 pages. to appear at MLCAD 2025", "pdf_url": "http://arxiv.org/pdf/2507.10912v1", "cate": "cs.AR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2502.01100", "title": "ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning", "authors": ["Bill Yuchen Lin", "Ronan Le Bras", "Kyle Richardson", "Ashish Sabharwal", "Radha Poovendran", "Peter Clark", "Yejin Choi"], "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted to ICML 2025", "url": "http://arxiv.org/abs/2502.01100v2", "summary": "We investigate the logical reasoning capabilities of large language models\n(LLMs) and their scalability in complex non-monotonic reasoning. To this end,\nwe introduce ZebraLogic, a comprehensive evaluation framework for assessing LLM\nreasoning performance on logic grid puzzles derived from constraint\nsatisfaction problems (CSPs). ZebraLogic enables the generation of puzzles with\ncontrollable and quantifiable complexity, facilitating a systematic study of\nthe scaling limits of models such as Llama, o1 models, and DeepSeek-R1. By\nencompassing a broad range of search space complexities and diverse logical\nconstraints, ZebraLogic provides a structured environment to evaluate reasoning\nunder increasing difficulty.\n  Our results reveal a significant decline in accuracy as problem complexity\ngrows -- a phenomenon we term the curse of complexity. This limitation persists\neven with larger models and increased inference-time computation, suggesting\ninherent constraints in current LLM reasoning capabilities. Additionally, we\nexplore strategies to enhance logical reasoning, including Best-of-N sampling,\nbacktracking mechanisms, and self-verification prompts. Our findings offer\ncritical insights into the scalability of LLM reasoning, highlight fundamental\nlimitations, and outline potential directions for improvement.", "comment": "Accepted to ICML 2025", "pdf_url": "http://arxiv.org/pdf/2502.01100v2", "cate": "cs.AI", "date": "2025-02-03", "updated": "2025-07-15"}
{"id": "2507.10850", "title": "HEIMDALL: a grapH-based sEIsMic Detector And Locator for microseismicity", "authors": ["Matteo Bagagli", "Francesco Grigoli", "Davide Bacciu"], "categories": ["physics.geo-ph", "cs.LG"], "primary_category": "Subjects:       Geophysics (physics.geo-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10850v1", "summary": "In this work, we present a new deep-learning model for microseismicity\nmonitoring that utilizes continuous spatiotemporal relationships between\nseismic station recordings, forming an end-to-end pipeline for seismic catalog\ncreation. It employs graph theory and state-of-the-art graph neural network\narchitectures to perform phase picking, association, and event location\nsimultaneously over rolling windows, making it suitable for both playback and\nnear-real-time monitoring. As part of the global strategy to reduce carbon\nemissions within the broader context of a green-energy transition, there has\nbeen growing interest in exploiting enhanced geothermal systems. Tested in the\ncomplex geothermal area of Iceland's Hengill region using open-access data from\na temporary experiment, our model was trained and validated using both manually\nrevised and automatic seismic catalogs. Results showed a significant increase\nin event detection compared to previously published automatic systems and\nreference catalogs, including a $4 M_w$ seismic sequence in December 2018 and a\nsingle-day sequence in February 2019. Our method reduces false events,\nminimizes manual oversight, and decreases the need for extensive tuning of\npipelines or transfer learning of deep-learning models. Overall, it validates a\nrobust monitoring tool for geothermal seismic regions, complementing existing\nsystems and enhancing operational risk mitigation during geothermal energy\nexploitation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10850v1", "cate": "physics.geo-ph", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2407.06795", "title": "CycleSAM: Few-Shot Surgical Scene Segmentation with Cycle- and Scene-Consistent Feature Matching", "authors": ["Aditya Murali", "Farahdiba Zarin", "Adrien Meyer", "Pietro Mascagni", "Didier Mutter", "Nicolas Padoy"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.06795v2", "summary": "Surgical image segmentation is highly challenging, primarily due to scarcity\nof annotated data. Generalist prompted segmentation models like the\nSegment-Anything Model (SAM) can help tackle this task, but because they\nrequire image-specific visual prompts for effective performance, their use is\nlimited to improving data annotation efficiency. Recent approaches extend SAM\nto automatic segmentation by using a few labeled reference images to predict\npoint prompts; however, they rely on feature matching pipelines that lack\nrobustness to out-of-domain data like surgical images. To tackle this problem,\nwe introduce CycleSAM, an improved visual prompt learning approach that employs\na data-efficient training phase and enforces a series of soft constraints to\nproduce high-quality feature similarity maps. CycleSAM label-efficiently\naddresses domain gap by leveraging surgery-specific self-supervised feature\nextractors, then adapts the resulting features through a short\nparameter-efficient training stage, enabling it to produce informative\nsimilarity maps. CycleSAM further filters the similarity maps with a series of\nconsistency constraints before robustly sampling diverse point prompts for each\nobject instance. In our experiments on four diverse surgical datasets, we find\nthat CycleSAM outperforms existing few-shot SAM approaches by a factor of 2-4x\nin both 1-shot and 5-shot settings, while also achieving strong performance\ngains over traditional linear probing, parameter-efficient adaptation, and\npseudo-labeling methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.06795v2", "cate": "cs.CV", "date": "2024-07-09", "updated": "2025-07-15"}
{"id": "2507.11423", "title": "Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?", "authors": ["Yanjian Zhang", "Guillaume Wisniewski", "Nadi Tomeh", "Thierry Charnois"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11423v1", "summary": "Human reasoning involves different strategies, each suited to specific\nproblems. Prior work shows that large language model (LLMs) tend to favor a\nsingle reasoning strategy, potentially limiting their effectiveness in diverse\nreasoning challenges. In this work, we investigate whether prompting can\ncontrol LLMs reasoning strategies and assess its impact on logical\nproblem-solving. While our experiments show that no single strategy\nconsistently improves accuracy, performance could be enhanced if models could\nadaptively choose the optimal strategy. We propose methods to guide LLMs in\nstrategy selection, highlighting new ways to refine their reasoning abilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11423v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11318", "title": "Effects of rough boundary and nonzero boundary conditions on the lubrication process with micropolar fluid", "authors": ["Matthieu Bonnivard", "Igor Pazanin", "Francisco Suarez-Grau"], "categories": ["math.AP", "cs.NA", "math.NA", "35B27"], "primary_category": "Subjects:       Analysis of PDEs (math.AP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11318v1", "summary": "The lubrication theory is mostly concerned with the behavior of a lubricant\nflowing through a narrow gap. Motivated by the experimental findings from the\ntribology literature, we take the lubricant to be micropolar fluid and study\nits behavior in a thin domain with rough boundary. Instead of considering\n(commonly used) simple zero boundary condition, we impose physically relevant\n(nonzero) boundary condition for microrotation and perform asymptotic analysis\nof the corresponding 3D boundary value problem. We formally derive a simplified\nmathematical model acknowledging the roughness-induced effects and the effects\nof the nonzero boundary conditions on the macroscopic flow. Using the obtained\nasymptotic model, we study numerically the influence of the specific rugosity\nprofile on the performance of a linear slider bearing. The numerical results\nclearly indicate that the use of the rough surfaces may contribute to enhance\nthe mechanical performance of such device.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11318v1", "cate": "math.AP", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11506", "title": "Elk: Exploring the Efficiency of Inter-core Connected AI Chips with Deep Learning Compiler Techniques", "authors": ["Yiqi Liu", "Yuqi Xue", "Noelle Crawford", "Jilong Xue", "Jian Huang"], "categories": ["cs.AR", "cs.DC", "cs.LG"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      This paper is accepted at the 58th IEEE/ACM International Symposium on Microarchitecture (MICRO'25)", "url": "http://arxiv.org/abs/2507.11506v1", "summary": "To meet the increasing demand of deep learning (DL) models, AI chips are\nemploying both off-chip memory (e.g., HBM) and high-bandwidth low-latency\ninterconnect for direct inter-core data exchange. However, it is not easy to\nexplore the efficiency of these inter-core connected AI (ICCA) chips, due to a\nfundamental tussle among compute (per-core execution), communication\n(inter-core data exchange), and I/O (off-chip data access).\n  In this paper, we develop Elk, a DL compiler framework to maximize the\nefficiency of ICCA chips by jointly trading off all the three performance\nfactors discussed above. Elk structures these performance factors into\nconfigurable parameters and forms a global trade-off space in the DL compiler.\nTo systematically explore this space and maximize overall efficiency, Elk\nemploys a new inductive operator scheduling policy and a cost-aware on-chip\nmemory allocation algorithm. It generates globally optimized execution plans\nthat best overlap off-chip data loading and on-chip execution. To examine the\nefficiency of Elk, we build a full-fledged emulator based on a real ICCA chip\nIPU-POD4, and an ICCA chip simulator for sensitivity analysis with different\ninterconnect network topologies. Elk achieves 94% of the ideal roofline\nperformance of ICCA chips on average, showing the benefits of supporting large\nDL models on ICCA chips. We also show Elk's capability of enabling architecture\ndesign space exploration for new ICCA chip development.", "comment": "This paper is accepted at the 58th IEEE/ACM International Symposium\n  on Microarchitecture (MICRO'25)", "pdf_url": "http://arxiv.org/pdf/2507.11506v1", "cate": "cs.AR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2502.04644", "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools", "authors": ["Junde Wu", "Jiayuan Zhu", "Yuyuan Liu", "Min Xu", "Yueming Jin"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      ACL 2025", "url": "http://arxiv.org/abs/2502.04644v2", "summary": "We introduce Agentic Reasoning, a framework that enhances large language\nmodel (LLM) reasoning by integrating external tool-using agents. Agentic\nReasoning dynamically leverages web search, code execution, and structured\nmemory to address complex problems requiring deep research. A key innovation in\nour framework is the Mind-Map agent, which constructs a structured knowledge\ngraph to store reasoning context and track logical relationships, ensuring\ncoherence in long reasoning chains with extensive tool usage. Additionally, we\nconduct a comprehensive exploration of the Web-Search agent, leading to a\nhighly effective search mechanism that surpasses all prior approaches. When\ndeployed on DeepSeek-R1, our method achieves a new state-of-the-art (SOTA)\namong public models and delivers performance comparable to OpenAI Deep\nResearch, the leading proprietary model in this domain. Extensive ablation\nstudies validate the optimal selection of agentic tools and confirm the\neffectiveness of our Mind-Map and Web-Search agents in enhancing LLM reasoning.\nThe code is at: https://github.com/theworldofagents/Agentic-Reasoning", "comment": "ACL 2025", "pdf_url": "http://arxiv.org/pdf/2502.04644v2", "cate": "cs.AI", "date": "2025-02-07", "updated": "2025-07-14"}
{"id": "2507.10877", "title": "BioScore: A Foundational Scoring Function For Diverse Biomolecular Complexes", "authors": ["Yuchen Zhu", "Jihong Chen", "Yitong Li", "Xiaomin Fang", "Xianbin Ye", "Jingzhou He", "Xujun Zhang", "Jingxuan Ge", "Chao Shen", "Xiaonan Zhang", "Tingjun Hou", "Chang-Yu Hsieh"], "categories": ["physics.chem-ph", "cs.LG", "physics.bio-ph"], "primary_category": "Subjects:       Chemical Physics (physics.chem-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10877v1", "summary": "Structural assessment of biomolecular complexes is vital for translating\nmolecular models into functional insights, shaping our understanding of biology\nand aiding drug discovery. However, current structure-based scoring functions\noften lack generalizability across diverse biomolecular systems. We present\nBioScore, a foundational scoring function that addresses key challenges -- data\nsparsity, cross-system representation, and task compatibility -- through a\ndual-scale geometric graph learning framework with tailored modules for\nstructure assessment and affinity prediction. BioScore supports a wide range of\ntasks, including affinity prediction, conformation ranking, and structure-based\nvirtual screening. Evaluated on 16 benchmarks spanning proteins, nucleic acids,\nsmall molecules, and carbohydrates, BioScore consistently outperforms or\nmatches 70 traditional and deep learning methods. Our newly proposed PPI\nBenchmark further enables comprehensive evaluation of protein-protein complex\nscoring. BioScore demonstrates broad applicability: (1) pretraining on\nmixed-structure data boosts protein-protein affinity prediction by up to 40%\nand antigen-antibody binding correlation by over 90%; (2) cross-system\ngeneralizability enables zero- and few-shot prediction with up to 71%\ncorrelation gain; and (3) its unified representation captures chemically\nchallenging systems such as cyclic peptides, improving affinity prediction by\nover 60%. BioScore establishes a robust and generalizable framework for\nstructural assessment across complex biomolecular landscapes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10877v1", "cate": "physics.chem-ph", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2408.06779", "title": "ED$^4$: Explicit Data-level Debiasing for Deepfake Detection", "authors": ["Jikang Cheng", "Ying Zhang", "Qin Zou", "Zhiyuan Yan", "Chao Liang", "Zhongyuan Wang", "Chen Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.06779v2", "summary": "Learning intrinsic bias from limited data has been considered the main reason\nfor the failure of deepfake detection with generalizability. Apart from the\ndiscovered content and specific-forgery bias, we reveal a novel spatial bias,\nwhere detectors inertly anticipate observing structural forgery clues appearing\nat the image center, also can lead to the poor generalization of existing\nmethods. We present ED$^4$, a simple and effective strategy, to address\naforementioned biases explicitly at the data level in a unified framework\nrather than implicit disentanglement via network design. In particular, we\ndevelop ClockMix to produce facial structure preserved mixtures with arbitrary\nsamples, which allows the detector to learn from an exponentially extended data\ndistribution with much more diverse identities, backgrounds, local manipulation\ntraces, and the co-occurrence of multiple forgery artifacts. We further propose\nthe Adversarial Spatial Consistency Module (AdvSCM) to prevent extracting\nfeatures with spatial bias, which adversarially generates spatial-inconsistent\nimages and constrains their extracted feature to be consistent. As a\nmodel-agnostic debiasing strategy, ED$^4$ is plug-and-play: it can be\nintegrated with various deepfake detectors to obtain significant benefits. We\nconduct extensive experiments to demonstrate its effectiveness and superiority\nover existing deepfake detection approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.06779v2", "cate": "cs.CV", "date": "2024-08-13", "updated": "2025-07-15"}
{"id": "2507.11508", "title": "Real-World Summarization: When Evaluation Reaches Its Limits", "authors": ["Patrícia Schmidtová", "Ondřej Dušek", "Saad Mahamood"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11508v1", "summary": "We examine evaluation of faithfulness to input data in the context of hotel\nhighlights: brief LLM-generated summaries that capture unique features of\naccommodations. Through human evaluation campaigns involving categorical error\nassessment and span-level annotation, we compare traditional metrics, trainable\nmethods, and LLM-as-a-judge approaches. Our findings reveal that simpler\nmetrics like word overlap correlate surprisingly well with human judgments\n(Spearman correlation rank of 0.63), often outperforming more complex methods\nwhen applied to out-of-domain data. We further demonstrate that while LLMs can\ngenerate high-quality highlights, they prove unreliable for evaluation as they\ntend to severely under- or over-annotate. Our analysis of real-world business\nimpacts shows incorrect and non-checkable information pose the greatest risks.\nWe also highlight challenges in crowdsourced evaluations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11508v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11399", "title": "The Evolution of Pointwise Statistics in Hyperbolic Equations with Random Data", "authors": ["Alina Chertock", "Pierre Degond", "Amir Sagiv", "Li Wang"], "categories": ["math.AP", "cs.NA", "math.NA"], "primary_category": "Subjects:       Analysis of PDEs (math.AP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11399v1", "summary": "We consider one-dimensional hyperbolic PDEs, linear and nonlinear, with\nrandom initial data. Our focus is the {\\em pointwise statistics,} i.e., the\nprobability measure of the solution at any fixed point in space and time. For\nlinear hyperbolic equations, the probability density function (PDF) of these\nstatistics satisfies the same linear PDE. For nonlinear hyperbolic PDEs, we\nderive a linear transport equation for the cumulative distribution function\n(CDF) and a nonlocal linear PDE for the PDF. Both results are valid only as\nlong as no shocks have formed, a limitation which is inherent to the problem,\nas demonstrated by a counterexample. For systems of linear hyperbolic\nequations, we introduce the multi-point statistics and derive their evolution\nequations. In all of the settings we consider, the resulting PDEs for the\nstatistics are of practical significance: they enable efficient evaluation of\nthe random dynamics, without requiring an ensemble of solutions of the\nunderlying PDE, and their cost is not affected by the dimension of the random\nparameter space. Additionally, the evolution equations for the statistics lead\nto a priori statistical error bounds for Monte Carlo methods (in particular,\nKernel Density Estimators) when applied to hyperbolic PDEs with random data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11399v1", "cate": "math.AP", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2506.07945", "title": "ProtocolLLM: RTL Benchmark for SystemVerilog Generation of Communication Protocols", "authors": ["Arnav Sheth", "Ivaxi Sheth", "Mario Fritz"], "categories": ["cs.AR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      Accepted at MLSysArch@ISCA 2025", "url": "http://arxiv.org/abs/2506.07945v2", "summary": "Recent advances in large language models (LLMs) have demonstrated strong\nperformance in generating code for general-purpose programming languages.\nHowever, their potential for hardware description languages (HDLs), such as\nSystemVerilog, remains largely unexplored. HDL code generation poses unique\nchallenges due to strict timing semantics, concurrency, and synthesizability\nconstraints essential for correct hardware functionality. Further, HDL-based\ndesign flows encompass a broad set of tasks beyond structural code generation,\nincluding testbench development, assertion-based verification, timing closure,\nand protocol-level integration for on-chip communication. In this work, we\nevaluate the capabilities of both open-source and state-of-the-art LLMs in\ngenerating synthesizable and functionally accurate SystemVerilog\nimplementations of widely used communication protocols that are critical\ncomponents of embedded and System-on-Chip (SoC) systems. We introduce\nProtocolLLM, the first benchmark suite specifically targeting these protocols\nwith tasks spanning multiple design abstraction levels and varying prompt\nspecificity. Our evaluation method also focuses on timing correctness in\naddition to synthesizability and syntactic correctness. We observe that most of\nthe models fail to generate SystemVerilog code for communication protocols that\nfollow timing constrains.", "comment": "Accepted at MLSysArch@ISCA 2025", "pdf_url": "http://arxiv.org/pdf/2506.07945v2", "cate": "cs.AR", "date": "2025-06-09", "updated": "2025-07-15"}
{"id": "2504.02467", "title": "BOOST: Bootstrapping Strategy-Driven Reasoning Programs for Program-Guided Fact-Checking", "authors": ["Qisheng Hu", "Quanyu Long", "Wenya Wang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Work in Progress", "url": "http://arxiv.org/abs/2504.02467v2", "summary": "Program-guided reasoning has shown promise in complex claim fact-checking by\ndecomposing claims into function calls and executing reasoning programs.\nHowever, prior work primarily relies on few-shot in-context learning (ICL) with\nad-hoc demonstrations, which limit program diversity and require manual design\nwith substantial domain knowledge. Fundamentally, the underlying principles of\neffective reasoning program generation still remain underexplored, making it\nchallenging to construct effective demonstrations. To address this, we propose\nBOOST, a bootstrapping-based framework for few-shot reasoning program\ngeneration. BOOST explicitly integrates claim decomposition and\ninformation-gathering strategies as structural guidance for program generation,\niteratively refining bootstrapped demonstrations in a strategy-driven and\ndata-centric manner without human intervention. This enables a seamless\ntransition from zero-shot to few-shot strategic program-guided learning,\nenhancing interpretability and effectiveness. Experimental results show that\nBOOST outperforms prior few-shot baselines in both zero-shot and few-shot\nsettings for complex claim verification.", "comment": "Work in Progress", "pdf_url": "http://arxiv.org/pdf/2504.02467v2", "cate": "cs.AI", "date": "2025-04-03", "updated": "2025-07-15"}
{"id": "2507.10934", "title": "Towards Practical Benchmarking of Data Cleaning Techniques: On Generating Authentic Errors via Large Language Models", "authors": ["Xinyuan Liu", "Jiahui Chen", "Bocheng Hu", "Yu Sun", "Xinyang Chen", "Shaoxu Song"], "categories": ["cs.DB", "cs.LG"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10934v1", "summary": "Data quality remains an important challenge in data-driven systems, as errors\nin tabular data can severely compromise downstream analytics and machine\nlearning performance. Although numerous error detection algorithms have been\nproposed, the lack of diverse, real-world error datasets limits comprehensive\nevaluation. Manual error annotation is both time-consuming and inconsistent,\nmotivating the exploration of synthetic error generation as an alternative. In\nthis work, we introduce TableEG, a framework that leverages large language\nmodels (LLMs) to generate authentic errors. By employing a table fine-tuning\nstrategy and a triplet representation $(I, T, O)$ to model error generation,\ndetection, and correction tasks, TableEG captures the complex dependencies\ninherent in two-dimensional tables. Trained on 12 real-world datasets spanning\n10 diverse domains, TableEG ensures that the synthesized errors faithfully\nreflect authentic error distributions. Experimental results indicate that\nerrors generated by TableEG exhibit superior pattern and distribution\nsimilarity compared to both rule-based methods and LLM-generated errors without\nfine-tuning. Furthermore, performance metrics on TableEG-generated errors\nclosely align with those on real-world errors across nearly all datasets and\ndetection algorithms, particularly for machine learning based detection\ntechniques. Overall, TableEG not only bridges the gap between synthetic and\nreal-world errors but also establishes a robust benchmark for subsequent error\ndetection and correction tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10934v1", "cate": "cs.DB", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2409.07723", "title": "Advancing Depth Anything Model for Unsupervised Monocular Depth Estimation in Endoscopy", "authors": ["Bojian Li", "Bo Liu", "Xinning Yao", "Jinghua Yue", "Fugen Zhou"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IROS2025, 8 pages, 7 figures", "url": "http://arxiv.org/abs/2409.07723v3", "summary": "Depth estimation is a cornerstone of 3D reconstruction and plays a vital role\nin minimally invasive endoscopic surgeries. However, most current depth\nestimation networks rely on traditional convolutional neural networks, which\nare limited in their ability to capture global information. Foundation models\noffer a promising approach to enhance depth estimation, but those models\ncurrently available are primarily trained on natural images, leading to\nsuboptimal performance when applied to endoscopic images. In this work, we\nintroduce a novel fine-tuning strategy for the Depth Anything Model and\nintegrate it with an intrinsic-based unsupervised monocular depth estimation\nframework. Our approach includes a low-rank adaptation technique based on\nrandom vectors, which improves the model's adaptability to different scales.\nAdditionally, we propose a residual block built on depthwise separable\nconvolution to compensate for the transformer's limited ability to capture\nlocal features. Our experimental results on the SCARED dataset and Hamlyn\ndataset show that our method achieves state-of-the-art performance while\nminimizing the number of trainable parameters. Applying this method in\nminimally invasive endoscopic surgery can enhance surgeons' spatial awareness,\nthereby improving the precision and safety of the procedures.", "comment": "Accepted by IROS2025, 8 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2409.07723v3", "cate": "cs.CV", "date": "2024-09-12", "updated": "2025-07-15"}
{"id": "2401.13444", "title": "Fine-grained Stateful Knowledge Exploration: Effective and Efficient Graph Retrieval with Large Language Models", "authors": ["Dehao Tao", "Congqi Wang", "Feng Huang", "Junhao Chen", "Yongfeng Huang", "Minghu Jiang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2401.13444v4", "summary": "Large Language Models (LLMs) have shown impressive capabilities, yet updating\ntheir knowledge remains a significant challenge, often leading to outdated or\ninaccurate responses. A proposed solution is the integration of external\nknowledge bases, such as knowledge graphs, with LLMs. Most existing methods use\na paradigm that treats the whole question as the objective, with relevant\nknowledge being incrementally retrieved from the knowledge graph. However, this\nparadigm often leads to a granularity mismatch between the target question and\nthe retrieved entities and relations. As a result, the information in the\nquestion cannot precisely correspond to the retrieved knowledge. This may cause\nredundant exploration or omission of vital knowledge, thereby leading to\nenhanced computational consumption and reduced retrieval accuracy. To address\nthe limitations of coarse-grained knowledge exploration, we propose FiSKE, a\nnovel paradigm for Fine-grained Stateful Knowledge Exploration. FiSKE first\ndecomposes questions into fine-grained clues, then employs an adaptive mapping\nstrategy during knowledge exploration process to resolve ambiguity in\nclue-to-graph mappings. This strategy dynamically infers contextual\ncorrespondences while maintaining a stateful record of the mappings. A\nclue-driven termination mechanism ensures rigorous augmentation--leveraging\nfully mapped paths for LLMs while reverting to chain-of-thought reasoning when\nnecessary. Our approach balances precision and efficiency. Experiments on\nmultiple datasets revealed that our paradigm surpasses current advanced methods\nin knowledge retrieval while significantly reducing the average number of LLM\ninvocations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2401.13444v4", "cate": "cs.CL", "date": "2024-01-24", "updated": "2025-07-15"}
{"id": "2507.11463", "title": "The Marcinkiewicz-Zygmund Property for Riemann Differences with Geometric Nodes", "authors": ["Hajrudin Fejzić"], "categories": ["math.CA", "cs.NA", "math.NA"], "primary_category": "Subjects:       Classical Analysis and ODEs (math.CA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11463v1", "summary": "We study when a Riemann difference of order $ n $ possesses the\nMarcinkiewicz-Zygmund (MZ) property: that is, whether the conditions $ f(h) =\no(h^{n-1}) $ and $ Df(h) = o(h^n) $ imply $ f(h) = o(h^n) $. This implication\nis known to hold for some classical examples with geometric nodes, such as $\n\\{0, 1, q, \\dots, q^{n-1}\\} $ and $ \\{1, q, \\dots, q^n\\} $, leading to a\nconjecture that these are the only such Riemann differences with the MZ\nproperty. However, this conjecture was disproved by the third-order example\nwith nodes $ \\{-1, 0, 1, 2\\} $, and we provide further counterexamples and a\ngeneral classification here.\n  We establish a complete analytic criterion for the MZ property by developing\na recurrence framework: we analyze when a function $ R(h) $ satisfying $ D(h) =\nR(qh) - A R(h) $, together with $ D(h) = o(h^n) $ and $ R(h) = o(h^{n-1}) $,\nforces $ R(h) = o(h^n) $. We prove that this holds if and only if $ A $ lies\noutside a critical modulus annulus determined by $ q $ and $ n $, covering both\n$ |q| > 1 $ and $ |q| < 1 $ cases. This leads to a complete characterization of\nall Riemann differences with geometric nodes that possess the MZ property, and\nprovides a flexible analytic framework applicable to broader classes of\ngeneralized differences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11463v1", "cate": "math.CA", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2501.19347", "title": "An All-digital 8.6-nJ/Frame 65-nm Tsetlin Machine Image Classification Accelerator", "authors": ["Svein Anders Tunheim", "Yujin Zheng", "Lei Jiao", "Rishad Shafik", "Alex Yakovlev", "Ole-Christoffer Granmo"], "categories": ["cs.LG", "cs.AR", "B.7"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Copyright 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purpose\\, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works", "url": "http://arxiv.org/abs/2501.19347v3", "summary": "We present an all-digital programmable machine learning accelerator chip for\nimage classification, underpinning on the Tsetlin machine (TM) principles. The\nTM is an emerging machine learning algorithm founded on propositional logic,\nutilizing sub-pattern recognition expressions called clauses. The accelerator\nimplements the coalesced TM version with convolution, and classifies\nbooleanized images of 28$\\times$28 pixels with 10 categories. A configuration\nwith 128 clauses is used in a highly parallel architecture. Fast clause\nevaluation is achieved by keeping all clause weights and Tsetlin automata (TA)\naction signals in registers. The chip is implemented in a 65 nm low-leakage\nCMOS technology, and occupies an active area of 2.7 mm$^2$. At a clock\nfrequency of 27.8 MHz, the accelerator achieves 60.3k classifications per\nsecond, and consumes 8.6 nJ per classification. This demonstrates the\nenergy-efficiency of the TM, which was the main motivation for developing this\nchip. The latency for classifying a single image is 25.4 $\\mu$s which includes\nsystem timing overhead. The accelerator achieves 97.42%, 84.54% and 82.55% test\naccuracies for the datasets MNIST, Fashion-MNIST and Kuzushiji-MNIST,\nrespectively, matching the TM software models.", "comment": "Copyright 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purpose\\, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "pdf_url": "http://arxiv.org/pdf/2501.19347v3", "cate": "cs.LG", "date": "2025-01-31", "updated": "2025-07-15"}
{"id": "2507.10789", "title": "Dissecting the NVIDIA Blackwell Architecture with Microbenchmarks", "authors": ["Aaron Jarmusch", "Nathan Graddon", "Sunita Chandrasekaran"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10789v1", "summary": "The rapid development in scientific research provides a need for more compute\npower, which is partly being solved by GPUs. This paper presents a\nmicroarchitectural analysis of the modern NVIDIA Blackwell architecture by\nstudying GPU performance\n  features with thought through microbenchmarks. We unveil key subsystems,\nincluding the memory hierarchy, SM execution\n  pipelines, and the SM sub-core units, including the 5th generation tensor\ncores supporting FP4 and FP6 precisions.\n  To understand the different key features of the NVIDIA GPU, we study latency,\nthroughput, cache behavior, and scheduling\n  details, revealing subtle tuning metrics in the design of Blackwell. To\ndevelop a comprehensive analysis, we compare the\n  Blackwell architecture with the previous Hopper architecture by using the\nGeForce RTX 5080 and H100 PCIe, respectively. We\n  evaluate and compare results, presenting both generational improvements and\nperformance regressions. Additionally, we\n  investigate the role of power efficiency and energy consumption under varied\nworkloads. Our findings provide actionable insights\n  for application developers, compiler writers, and performance engineers to\noptimize workloads on Blackwell-based platforms,\n  and contribute new data to the growing research on GPU architectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10789v1", "cate": "cs.DC", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2506.06935", "title": "An Agentic Framework for Autonomous Metamaterial Modeling and Inverse Design", "authors": ["Darui Lu", "Jordan M. Malof", "Willie J. Padilla"], "categories": ["cs.AI", "cond-mat.mtrl-sci"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      22 pages, 6 figures", "url": "http://arxiv.org/abs/2506.06935v2", "summary": "Recent significant advances in integrating multiple Large Language Model\n(LLM) systems have enabled Agentic Frameworks capable of performing complex\ntasks autonomously, including novel scientific research. We develop and\ndemonstrate such a framework specifically for the inverse design of photonic\nmetamaterials. When queried with a desired optical spectrum, the Agent\nautonomously proposes and develops a forward deep learning model, accesses\nexternal tools via APIs for tasks like simulation and optimization, utilizes\nmemory, and generates a final design via a deep inverse method. The framework's\neffectiveness is demonstrated in its ability to automate, reason, plan, and\nadapt. Notably, the Agentic Framework possesses internal reflection and\ndecision flexibility, permitting highly varied and potentially novel outputs.", "comment": "22 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2506.06935v2", "cate": "cs.AI", "date": "2025-06-07", "updated": "2025-07-15"}
{"id": "2507.10956", "title": "GOLFS: Feature Selection via Combining Both Global and Local Information for High Dimensional Clustering", "authors": ["Zhaoyu Xing", "Yang Wan", "Juan Wen", "Wei Zhong"], "categories": ["stat.ML", "cs.LG", "62-08", "G.3"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10956v1", "summary": "It is important to identify the discriminative features for high dimensional\nclustering. However, due to the lack of cluster labels, the regularization\nmethods developed for supervised feature selection can not be directly applied.\nTo learn the pseudo labels and select the discriminative features\nsimultaneously, we propose a new unsupervised feature selection method, named\nGlObal and Local information combined Feature Selection (GOLFS), for high\ndimensional clustering problems. The GOLFS algorithm combines both local\ngeometric structure via manifold learning and global correlation structure of\nsamples via regularized self-representation to select the discriminative\nfeatures. The combination improves the accuracy of both feature selection and\nclustering by exploiting more comprehensive information. In addition, an\niterative algorithm is proposed to solve the optimization problem and the\nconvergency is proved. Simulations and two real data applications demonstrate\nthe excellent finite-sample performance of GOLFS on both feature selection and\nclustering.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10956v1", "cate": "stat.ML", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2410.00166", "title": "EEG Emotion Copilot: Optimizing Lightweight LLMs for Emotional EEG Interpretation with Assisted Medical Record Generation", "authors": ["Hongyu Chen", "Weiming Zeng", "Chengcheng Chen", "Luhui Cai", "Fei Wang", "Yuhu Shi", "Lei Wang", "Wei Zhang", "Yueyang Li", "Hongjie Yan", "Wai Ting Siok", "Nizhuan Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 16 figures, 5 tables", "url": "http://arxiv.org/abs/2410.00166v3", "summary": "In the fields of affective computing (AC) and brain-machine interface (BMI),\nthe analysis of physiological and behavioral signals to discern individual\nemotional states has emerged as a critical research frontier. While deep\nlearning-based approaches have made notable strides in EEG emotion recognition,\nparticularly in feature extraction and pattern recognition, significant\nchallenges persist in achieving end-to-end emotion computation, including\nreal-time processing, individual adaptation, and seamless user interaction.\nThis paper presents the EEG Emotion Copilot, a system optimizing a lightweight\nlarge language model (LLM) with 0.5B parameters operating in a local setting,\nwhich first recognizes emotional states directly from EEG signals, subsequently\ngenerates personalized diagnostic and treatment suggestions, and finally\nsupports the automation of assisted electronic medical records. Specifically,\nwe demonstrate the critical techniques in the novel data structure of prompt,\nmodel pruning and fine-tuning training, and deployment strategies aiming at\nimproving real-time performance and computational efficiency. Extensive\nexperiments show that our optimized lightweight LLM-based copilot achieves an\nenhanced intuitive interface for participant interaction, superior accuracy of\nemotion recognition and assisted electronic medical records generation, in\ncomparison to such models with similar scale parameters or large-scale\nparameters such as 1.5B, 1.8B, 3B and 7B. In summary, through these efforts,\nthe proposed copilot is expected to advance the application of AC in the\nmedical domain, offering innovative solution to mental health monitoring. The\ncodes will be released at https://github.com/NZWANG/EEG_Emotion_Copilot.", "comment": "17 pages, 16 figures, 5 tables", "pdf_url": "http://arxiv.org/pdf/2410.00166v3", "cate": "cs.CV", "date": "2024-09-30", "updated": "2025-07-15"}
{"id": "2410.08193", "title": "GenARM: Reward Guided Generation with Autoregressive Reward Model for Test-time Alignment", "authors": ["Yuancheng Xu", "Udari Madhushani Sehwag", "Alec Koppel", "Sicheng Zhu", "Bang An", "Furong Huang", "Sumitra Ganesh"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Published at the Thirteenth International Conference on Learning Representations (ICLR 2025)", "url": "http://arxiv.org/abs/2410.08193v5", "summary": "Large Language Models (LLMs) exhibit impressive capabilities but require\ncareful alignment with human preferences. Traditional training-time methods\nfinetune LLMs using human preference datasets but incur significant training\ncosts and require repeated training to handle diverse user preferences.\nTest-time alignment methods address this by using reward models (RMs) to guide\nfrozen LLMs without retraining. However, existing test-time approaches rely on\ntrajectory-level RMs which are designed to evaluate complete responses, making\nthem unsuitable for autoregressive text generation that requires computing\nnext-token rewards from partial responses. To address this, we introduce\nGenARM, a test-time alignment approach that leverages the Autoregressive Reward\nModel--a novel reward parametrization designed to predict next-token rewards\nfor efficient and effective autoregressive generation. Theoretically, we\ndemonstrate that this parametrization can provably guide frozen LLMs toward any\ndistribution achievable by traditional RMs within the KL-regularized\nreinforcement learning framework. Experimental results show that GenARM\nsignificantly outperforms prior test-time alignment baselines and matches the\nperformance of training-time methods. Additionally, GenARM enables efficient\nweak-to-strong guidance, aligning larger LLMs with smaller RMs without the high\ncosts of training larger models. Furthermore, GenARM supports multi-objective\nalignment, allowing real-time trade-offs between preference dimensions and\ncatering to diverse user preferences without retraining. Our project page is\navailable at: https://genarm.github.io.", "comment": "Published at the Thirteenth International Conference on Learning\n  Representations (ICLR 2025)", "pdf_url": "http://arxiv.org/pdf/2410.08193v5", "cate": "cs.CL", "date": "2024-10-10", "updated": "2025-07-15"}
{"id": "2507.11512", "title": "Scaling the memory wall using mixed-precision -- HPG-MxP on an exascale machine", "authors": ["Aditya Kashi", "Nicholson Koukpaizan", "Hao Lu", "Michael Matheson", "Sarp Oral", "Feiyi Wang"], "categories": ["cs.DC", "cs.NA", "cs.PF", "math.NA", "65Y10", "G.4; C.4"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at SC25, St. Louis, MO, USA", "url": "http://arxiv.org/abs/2507.11512v1", "summary": "Mixed-precision algorithms have been proposed as a way for scientific\ncomputing to benefit from some of the gains seen for artificial intelligence\n(AI) on recent high performance computing (HPC) platforms. A few applications\ndominated by dense matrix operations have seen substantial speedups by\nutilizing low precision formats such as FP16. However, a majority of scientific\nsimulation applications are memory bandwidth limited. Beyond preliminary\nstudies, the practical gain from using mixed-precision algorithms on a given\nHPC system is largely unclear.\n  The High Performance GMRES Mixed Precision (HPG-MxP) benchmark has been\nproposed to measure the useful performance of a HPC system on sparse\nmatrix-based mixed-precision applications. In this work, we present a highly\noptimized implementation of the HPG-MxP benchmark for an exascale system and\ndescribe our algorithm enhancements. We show for the first time a speedup of\n1.6x using a combination of double- and single-precision on modern GPU-based\nsupercomputers.", "comment": "Accepted for presentation at SC25, St. Louis, MO, USA", "pdf_url": "http://arxiv.org/pdf/2507.11512v1", "cate": "cs.DC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.11067", "title": "MMStencil: Optimizing High-order Stencils on Multicore CPU using Matrix Unit", "authors": ["Yinuo Wang", "Tianqi Mao", "Lin Gan", "Wubing Wan", "Zeyu Song", "Jiayu Fu", "Lanke He", "Wenqiang Wang", "Zekun Yin", "Wei Xue", "Guangwen Yang"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      Yinuo Wang and Tianqi Mao contributed equally to this work", "url": "http://arxiv.org/abs/2507.11067v1", "summary": "Matrix-accelerated stencil computation is a hot research topic, yet its\napplication to three-dimensional (3D) high-order stencils and HPC remains\nunderexplored. With the emergence of matrix units on multicore CPUs, we analyze\nmatrix-based acceleration strategies and tailor an optimal approach for 3D\nhigh-order stencils. We introduce algorithmic optimizations based on SIMD and\nmatrix units to address strided memory accesses, alignment conflicts, and\nredundant accesses. We propose memory optimizations to boost on-package memory\nefficiency, and a novel multi-thread parallelism paradigm to overcome\ndata-sharing challenges caused by the absence of shared data caches. MMStencil\nsustains consistently high hardware utilization across diverse stencil shapes\nand dimensions. Our DMA-based inter-NUMA communication further mitigates NUMA\neffects and MPI limitations in hybrid parallelism. Combining all the\ninnovations, MMStencil outperforms state-of-the-art libraries on Nvidia A100\nGPGPU by up to 2.1x. Moreover, the performance improvements translate directly\nto real-world HPC applications and enable RTM applications to yield 1.8x\nspeedup versus a highly optimized industrial Nvidia A100 GPGPU version.", "comment": "Yinuo Wang and Tianqi Mao contributed equally to this work", "pdf_url": "http://arxiv.org/pdf/2507.11067v1", "cate": "cs.DC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.02825", "title": "Establishing Best Practices for Building Rigorous Agentic Benchmarks", "authors": ["Yuxuan Zhu", "Tengjun Jin", "Yada Pruksachatkun", "Andy Zhang", "Shu Liu", "Sasha Cui", "Sayash Kapoor", "Shayne Longpre", "Kevin Meng", "Rebecca Weiss", "Fazl Barez", "Rahul Gupta", "Jwala Dhamala", "Jacob Merizian", "Mario Giulianelli", "Harry Coppock", "Cozmin Ududec", "Jasjeet Sekhon", "Jacob Steinhardt", "Antony Kellerman", "Sarah Schwettmann", "Matei Zaharia", "Ion Stoica", "Percy Liang", "Daniel Kang"], "categories": ["cs.AI", "A.1; I.2.m"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      39 pages, 15 tables, 6 figures", "url": "http://arxiv.org/abs/2507.02825v4", "summary": "Benchmarks are essential for quantitatively tracking progress in AI. As AI\nagents become increasingly capable, researchers and practitioners have\nintroduced agentic benchmarks to evaluate agents on complex, real-world tasks.\nThese benchmarks typically measure agent capabilities by evaluating task\noutcomes via specific reward designs. However, we show that many agentic\nbenchmarks have issues in task setup or reward design. For example, SWE-bench\nVerified uses insufficient test cases, while TAU-bench counts empty responses\nas successful. Such issues can lead to under- or overestimation of agents'\nperformance by up to 100% in relative terms. To make agentic evaluation\nrigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of\nguidelines that we synthesized from our benchmark-building experience, a survey\nof best practices, and previously reported issues. When applied to CVE-Bench, a\nbenchmark with a particularly complex evaluation design, ABC reduces the\nperformance overestimation by 33%.", "comment": "39 pages, 15 tables, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.02825v4", "cate": "cs.AI", "date": "2025-07-03", "updated": "2025-07-14"}
{"id": "2507.11106", "title": "A Mathematical Optimization Approach to Multisphere Support Vector Data Description", "authors": ["Víctor Blanco", "Inmaculada Espejo", "Raúl Páez", "Antonio M. Rodríguez-Chía"], "categories": ["math.OC", "cs.LG"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      18 pages, 5 figures, 3 tables", "url": "http://arxiv.org/abs/2507.11106v1", "summary": "We present a novel mathematical optimization framework for outlier detection\nin multimodal datasets, extending Support Vector Data Description approaches.\nWe provide a primal formulation, in the shape of a Mixed Integer Second Order\nCone model, that constructs Euclidean hyperspheres to identify anomalous\nobservations. Building on this, we develop a dual model that enables the\napplication of the kernel trick, thus allowing for the detection of outliers\nwithin complex, non-linear data structures. An extensive computational study\ndemonstrates the effectiveness of our exact method, showing clear advantages\nover existing heuristic techniques in terms of accuracy and robustness.", "comment": "18 pages, 5 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.11106v1", "cate": "math.OC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2411.15858", "title": "SVTRv2: CTC Beats Encoder-Decoder Models in Scene Text Recognition", "authors": ["Yongkun Du", "Zhineng Chen", "Hongtao Xie", "Caiyan Jia", "Yu-Gang Jiang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2411.15858v2", "summary": "Connectionist temporal classification (CTC)-based scene text recognition\n(STR) methods, e.g., SVTR, are widely employed in OCR applications, mainly due\nto their simple architecture, which only contains a visual model and a\nCTC-aligned linear classifier, and therefore fast inference. However, they\ngenerally exhibit worse accuracy than encoder-decoder-based methods (EDTRs) due\nto struggling with text irregularity and linguistic missing. To address these\nchallenges, we propose SVTRv2, a CTC model endowed with the ability to handle\ntext irregularities and model linguistic context. First, a multi-size resizing\nstrategy is proposed to resize text instances to appropriate predefined sizes,\neffectively avoiding severe text distortion. Meanwhile, we introduce a feature\nrearrangement module to ensure that visual features accommodate the requirement\nof CTC, thus alleviating the alignment puzzle. Second, we propose a semantic\nguidance module. It integrates linguistic context into the visual features,\nallowing CTC model to leverage language information for accuracy improvement.\nThis module can be omitted at the inference stage and would not increase the\ntime cost. We extensively evaluate SVTRv2 in both standard and recent\nchallenging benchmarks, where SVTRv2 is fairly compared to popular STR models\nacross multiple scenarios, including different types of text irregularity,\nlanguages, long text, and whether employing pretraining. SVTRv2 surpasses most\nEDTRs across the scenarios in terms of accuracy and inference speed. Code:\nhttps://github.com/Topdu/OpenOCR.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2411.15858v2", "cate": "cs.CV", "date": "2024-11-24", "updated": "2025-07-15"}
{"id": "2411.15821", "title": "Is Training Data Quality or Quantity More Impactful to Small Language Model Performance?", "authors": ["Aryan Sajith", "Krishna Chaitanya Rao Kathala"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      14 pages, 5 tables, 4 figures | Accepted at International Conference on Neural Computing for Advanced Applications 2025, Conference info: this https URL", "url": "http://arxiv.org/abs/2411.15821v4", "summary": "This study investigates the relative impact of training data quality versus\nquantity on the performance of small language models (SLMs), utilizing the\nTinyStories dataset for empirical analysis. Analysis of dataset variations with\nrespect to size (25% and 50% of the original size) and duplication (controlled\nrates of 25%, 50%, 75%, and 100%) were performed. Model performance was\nevaluated based on the validation loss, accuracy, and perplexity metrics.\nResults indicate training data quality plays a more significant role in the\noverall performance of SLMs, especially given scale of this experiment. Minimal\nduplication positively impacted model accuracy (+0.87% increase in accuracy at\n25% duplication) without significantly increasing perplexity (+0.52% increase\ngoing from 0% to 25% duplication) but excessive duplication led to pronounced\nperformance degradation (-40% drop in accuracy at 100% duplication). The\nimplications of this exploration extend beyond just model performance; training\nlarge-scale models imposes significant financial and computational burdens,\nwhich can be prohibitive for organizations, individuals, and the public at\nlarge, especially in developing countries. Additionally, the energy consumption\nassociated with large-scale training raises environmental concerns.\nUnderstanding the relative importance of data quality versus quantity could\ndemocratize AI technology, making advanced models more accessible and\nsustainable for all.", "comment": "14 pages, 5 tables, 4 figures | Accepted at International Conference\n  on Neural Computing for Advanced Applications 2025, Conference info:\n  https://aaci.org.hk/ncaa2025", "pdf_url": "http://arxiv.org/pdf/2411.15821v4", "cate": "cs.CL", "date": "2024-11-24", "updated": "2025-07-15"}
{"id": "2407.03777", "title": "Semi and fully-discrete analysis of lowest-order nonstandard finite element methods for the biharmonic wave problem", "authors": ["Neela Nataraj", "Ricardo Ruiz-Baier", "Aamir Yousuf"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.03777v2", "summary": "This paper discusses lowest-order nonstandard finite element methods for\nspace discretization and explicit and implicit schemes for time discretization\nof the biharmonic wave equation with clamped boundary conditions. A modified\nRitz projection operator defined on $H^2_0(\\Omega)$ ensures error estimates\nunder appropriate regularity assumptions on the solution. Stability results and\nerror estimates of optimal order are established in suitable norms for the\nsemidiscrete and explicit/implicit fully-discrete versions of the proposed\nschemes. Finally, we report on numerical experiments using explicit and\nimplicit schemes for time discretization and Morley, discontinuous Galerkin,\nand {C$^0$ interior} penalty schemes for space discretization, that validate\nthe theoretical error estimates.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.03777v2", "cate": "math.NA", "date": "2024-07-04", "updated": "2025-07-15"}
{"id": "2507.11094", "title": "Generating Dynamic Graph Algorithms for Multiple Backends for a Graph DSL", "authors": ["Nibedita Behera", "Ashwina Kumar", "Atharva Chougule", "Mohammed Shan P S", "Rushabh Nirdosh Lalwani", "Rupesh Nasre"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11094v1", "summary": "With the rapid growth of unstructured and semistructured data, parallelizing\ngraph algorithms has become essential for efficiency. However, due to the\ninherent irregularity in computation, memory access patterns, and\ncommunication, graph algorithms are notoriously difficult to parallelize. To\naddress this challenge, several libraries, frameworks, and domain-specific\nlanguages (DSLs) have been proposed to ease the parallel programming burden for\ndomain experts. Existing frameworks partially or fully abstract away\nparallelism intricacies, provide intuitive scheduling mnemonics, and employ\nprogram analysis to identify data races and generate synchronization code.\nDespite these advances, most frameworks are limited in their abstractions and\nruntime optimizations, especially when dealing with static graphs. In contrast,\nmany real-world graphs are inherently dynamic, with evolving structures over\ntime through insertions, deletions, and modifications of vertices, edges, and\nattributes. Generating efficient and correctly synchronized code for such\ndynamic graph algorithms remains a significant challenge.\n  In this work, we introduce an abstraction scheme and runtime optimizations\nfor the efficient processing of morph algorithms. Specifically, given an\ninitial graph G and a set of updates $\\Delta$G involving edge insertions and\ndeletions, we express the dynamic processing logic through a DSL and\nautomatically generate parallel code targeting multicore, distributed, and\nmany-core environments. We demonstrate the effectiveness of our approach by\napplying the DSL-generated code to ten large graphs with diverse\ncharacteristics and three widely used algorithms: Shortest Paths, PageRank, and\nTriangle Counting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11094v1", "cate": "cs.DC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.09850", "title": "Is Human-Written Data Enough? The Challenge of Teaching Reasoning to LLMs Without RL or Distillation", "authors": ["Wei Du", "Branislav Kisacanin", "George Armstrong", "Shubham Toshniwal", "Ivan Moshkov", "Alexan Ayrapetyan", "Sadegh Mahdavi", "Dan Zhao", "Shizhe Diao", "Dragan Masulovic", "Marius Stanean", "Advaith Avadhanam", "Max Wang", "Ashmit Dutta", "Shitij Govil", "Sri Yanamandara", "Mihir Tandon", "Sriram Ananthakrishnan", "Vedant Rathi", "David Zhang", "Joonseok Kang", "Leon Luo", "Titu Andreescu", "Boris Ginsburg", "Igor Gitman"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted at the Second AI for Math Workshop at the 42nd International Conference on Machine Learning (ICML 2025)", "url": "http://arxiv.org/abs/2507.09850v2", "summary": "Reasoning-capable language models achieve state-of-the-art performance in\ndiverse complex tasks by generating long, explicit Chain-of-Thought (CoT)\ntraces. While recent works show that base models can acquire such reasoning\ntraces via reinforcement learning or distillation from stronger models like\nDeepSeek-R1, previous works demonstrate that even short CoT prompting without\nfine-tuning is able to improve reasoning. We ask whether long CoT can be\ninduced in a base model using only prompting or minimal tuning. Using just 20\nlong CoT examples from the reasoning model \\texttt{QwQ-32B-Preview}, we lightly\nfine-tune the base model \\texttt{Qwen2.5-32B}. The resulting model outperforms\nthe much larger \\texttt{Qwen2.5-Math-72B-Instruct}, showing that a handful of\nhigh-quality examples can unlock strong reasoning capabilities. We further\nexplore using CoT data from non-reasoning models and human annotators, enhanced\nwith prompt engineering, multi-pass editing, and structural guidance. However,\nneither matches the performance of reasoning model traces, suggesting that\ncertain latent qualities of expert CoT are difficult to replicate. We analyze\nkey properties of reasoning data, such as problem difficulty, diversity, and\nanswer length, that influence reasoning distillation. While challenges remain,\nwe are optimistic that carefully curated human-written CoT, even in small\nquantities, can activate reasoning behaviors in base models. We release our\nhuman-authored dataset across refinement stages and invite further\ninvestigation into what makes small-scale reasoning supervision so effective.", "comment": "Accepted at the Second AI for Math Workshop at the 42nd International\n  Conference on Machine Learning (ICML 2025)", "pdf_url": "http://arxiv.org/pdf/2507.09850v2", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-15"}
{"id": "2507.11136", "title": "Interpretable Bayesian Tensor Network Kernel Machines with Automatic Rank and Feature Selection", "authors": ["Afra Kilic", "Kim Batselier"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      39 pages, 5 figures, 4 tables. Submitted to Journal of Machine Learning Research. The code is available at: this https URL . arXiv admin note: text overlap with arXiv:1401.6497 by other authors", "url": "http://arxiv.org/abs/2507.11136v1", "summary": "Tensor Network (TN) Kernel Machines speed up model learning by representing\nparameters as low-rank TNs, reducing computation and memory use. However, most\nTN-based Kernel methods are deterministic and ignore parameter uncertainty.\nFurther, they require manual tuning of model complexity hyperparameters like\ntensor rank and feature dimensions, often through trial-and-error or\ncomputationally costly methods like cross-validation. We propose Bayesian\nTensor Network Kernel Machines, a fully probabilistic framework that uses\nsparsity-inducing hierarchical priors on TN factors to automatically infer\nmodel complexity. This enables automatic inference of tensor rank and feature\ndimensions, while also identifying the most relevant features for prediction,\nthereby enhancing model interpretability. All the model parameters and\nhyperparameters are treated as latent variables with corresponding priors.\nGiven the Bayesian approach and latent variable dependencies, we apply a\nmean-field variational inference to approximate their posteriors. We show that\napplying a mean-field approximation to TN factors yields a Bayesian ALS\nalgorithm with the same computational complexity as its deterministic\ncounterpart, enabling uncertainty quantification at no extra computational\ncost. Experiments on synthetic and real-world datasets demonstrate the superior\nperformance of our model in prediction accuracy, uncertainty quantification,\ninterpretability, and scalability.", "comment": "39 pages, 5 figures, 4 tables. Submitted to Journal of Machine\n  Learning Research. The code is available at:\n  https://github.com/afrakilic/BTN-Kernel-Machines. arXiv admin note: text\n  overlap with arXiv:1401.6497 by other authors", "pdf_url": "http://arxiv.org/pdf/2507.11136v1", "cate": "stat.ML", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2412.18675", "title": "TAB: Transformer Attention Bottlenecks enable User Intervention and Debugging in Vision-Language Models", "authors": ["Pooyan Rahmanzadehgervi", "Hung Huy Nguyen", "Rosanne Liu", "Long Mai", "Anh Totti Nguyen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.18675v4", "summary": "Multi-head self-attention (MHSA) is a key component of Transformers, a widely\npopular architecture in both language and vision. Multiple heads intuitively\nenable different parallel processes over the same input. Yet, they also obscure\nthe attribution of each input patch to the output of a model. We propose a\nnovel 1-head Transformer Attention Bottleneck (TAB) layer, inserted after the\ntraditional MHSA architecture, to serve as an attention bottleneck for\ninterpretability and intervention. Unlike standard self-attention, TAB\nconstrains the total attention over all patches to $\\in [0, 1]$. That is, when\nthe total attention is 0, no visual information is propagated further into the\nnetwork, and the vision-language model (VLM) would default to a generic,\nimage-independent response. To demonstrate the advantages of TAB, we train VLMs\nwith TAB to perform image-difference captioning. Over three datasets, our\nmodels perform similarly to baseline VLMs in captioning but the bottleneck is\nsuperior in localizing changes and in identifying when no changes occur. TAB is\nthe first architecture to enable users to debug by editing attention, which\noften produces expected outputs by VLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.18675v4", "cate": "cs.CV", "date": "2024-12-24", "updated": "2025-07-14"}
{"id": "2412.06136", "title": "AIDE: Attribute-Guided MultI-Hop Data Expansion for Data Scarcity in Task-Specific Fine-tuning", "authors": ["Jiayu Li", "Xuan Zhu", "Fang Liu", "Yanjun Qi"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted for publication in ACL 2025. The official version will be available in the ACL Anthology", "url": "http://arxiv.org/abs/2412.06136v2", "summary": "Fine-tuning large language models (LLMs) for specific tasks requires diverse,\nhigh-quality training data. However, obtaining sufficient relevant data remains\na significant challenge. Existing data synthesis methods either depend on\nextensive seed datasets or struggle to balance task relevance and data\ndiversity. To address these challenges, we propose Attribute-guided multI-hop\nData Expansion (AIDE), a novel data synthesis framework that uses a multi-hop\nprocess to expand very few seed data points while ensuring data diversity and\ntask relevance. AIDE extracts the main topic and key knowledge attributes from\nthe seeds to guide the synthesis steps. The process repeats for K hops, using\nthe generated data as seeds. To prevent irrelevant data generation as the hop\ndepth increases, AIDE incorporates a residual connection mechanism. Our\nempirical results show that AIDE enables fine-tuning of Mistral-7B,\nLlama-3.1-8B and Llama-3.2-3B from 10 seeds, surpassing the models fine-tuned\non human curated data. Furthermore, AIDE outperforms state-of-the-art data\nsynthesis methods, such as Evol-Instruct, by over 30% in task-specific\nfine-tuning. Code is available at https://github.com/Code4Graph/AIDE.", "comment": "Accepted for publication in ACL 2025. The official version will be\n  available in the ACL Anthology", "pdf_url": "http://arxiv.org/pdf/2412.06136v2", "cate": "cs.CL", "date": "2024-12-09", "updated": "2025-07-14"}
{"id": "2407.18419", "title": "Non-intrusive model reduction of advection-dominated hyperbolic problems using neural network shift augmented manifold transformation", "authors": ["Harshith Gowrachari", "Nicola Demo", "Giovanni Stabile", "Gianluigi Rozza"], "categories": ["math.NA", "cs.NA", "physics.flu-dyn"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      22 pages, 19 Figures", "url": "http://arxiv.org/abs/2407.18419v3", "summary": "Advection-dominated problems are predominantly noticed in nature, engineering\nsystems, and various industrial processes. Traditional linear compression\nmethods, such as proper orthogonal decomposition (POD) and reduced basis (RB)\nmethods are ill-suited for these problems, due to slow Kolmogorov $n$-width\ndecay. This results in inefficient and inaccurate reduced order models (ROMs).\nThere are few non-linear approaches to accelerate the Kolmogorov $n$-width\ndecay. In this work, we use a neural network shift augmented transformation\ntechnique that employs automatic shift detection. This approach leverages a\ndeep-learning framework to derive a parameter-dependent mapping between the\noriginal manifold $\\mathcal{M}$ and the transformed manifold\n$\\tilde{\\mathcal{M}}$. We apply a linear compression method to obtain a\nlow-dimensional linear approximation subspace of the transformed manifold\n$\\tilde{\\mathcal{M}}$. Furthermore, we construct non-intrusive reduced order\nmodels on the resulting transformed linear approximation subspace and employ\nautomatic shift detection for predictions in the online stage. We propose a\ncomplete framework, the neural network shift-augmented proper orthogonal\ndecomposition-based reduced order model (NNsPOD-ROM) algorithm, comprising both\noffline and online stages for model reduction of advection-dominated problems.\nWe test our proposed methodology on numerous experiments to evaluate its\nperformance on the 1D linear advection equation, a higher order method\nbenchmark case - the 2D isentropic convective vortex, and 2D two-phase flow.", "comment": "22 pages, 19 Figures", "pdf_url": "http://arxiv.org/pdf/2407.18419v3", "cate": "math.NA", "date": "2024-07-25", "updated": "2025-07-15"}
{"id": "2507.11165", "title": "Boosting Scientific Error-Bounded Lossy Compression through Optimized Synergistic Lossy-Lossless Orchestration", "authors": ["Shixun Wu", "Jinwen Pan", "Jinyang Liu", "Jiannan Tian", "Ziwei Qiu", "Jiajun Huang", "Kai Zhao", "Xin Liang", "Sheng Di", "Zizhong Chen", "Franck Cappello"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      accepted by SC '25", "url": "http://arxiv.org/abs/2507.11165v1", "summary": "As high-performance computing architectures evolve, more scientific computing\nworkflows are being deployed on advanced computing platforms such as GPUs.\nThese workflows can produce raw data at extremely high throughputs, requiring\nurgent high-ratio and low-latency error-bounded data compression solutions. In\nthis paper, we propose cuSZ-Hi, an optimized high-ratio GPU-based scientific\nerror-bounded lossy compressor with a flexible, domain-irrelevant, and fully\nopen-source framework design. Our novel contributions are: 1) We maximally\noptimize the parallelized interpolation-based data prediction scheme on GPUs,\nenabling the full functionalities of interpolation-based scientific data\nprediction that are adaptive to diverse data characteristics; 2) We thoroughly\nexplore and investigate lossless data encoding techniques, then craft and\nincorporate the best-fit lossless encoding pipelines for maximizing the\ncompression ratio of cuSZ-Hi; 3) We systematically evaluate cuSZ-Hi on\nbenchmarking datasets together with representative baselines. Compared to\nexisting state-of-the-art scientific lossy compressors, with comparative or\nbetter throughput than existing high-ratio scientific error-bounded lossy\ncompressors on GPUs, cuSZ-Hi can achieve up to 249% compression ratio\nimprovement under the same error bound, and up to 215% compression ratio\nimprovement under the same decompression data PSNR.", "comment": "accepted by SC '25", "pdf_url": "http://arxiv.org/pdf/2507.11165v1", "cate": "cs.DC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.09884", "title": "VerifyBench: A Systematic Benchmark for Evaluating Reasoning Verifiers Across Domains", "authors": ["Xuzhao Li", "Xuchen Li", "Shiyu Hu", "Yongzhen Guo", "Wentao Zhang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Preprint, Under review", "url": "http://arxiv.org/abs/2507.09884v2", "summary": "Large language models (LLMs) increasingly rely on reinforcement learning (RL)\nto enhance their reasoning capabilities through feedback. A critical challenge\nis verifying the consistency of model-generated responses and reference\nanswers, since these responses are often lengthy, diverse, and nuanced.\nRule-based verifiers struggle with complexity, prompting the use of model-based\nverifiers. However, specialized verifiers lack flexibility, while general LLM\njudges can be inconsistent. Existing research primarily focuses on building\nbetter verifiers, yet a systematic evaluation of different types of verifiers'\nperformance across domains remains lacking, severely constraining the reliable\ndevelopment of Reinforcement Learning with Verifiable Reward (RLVR). To address\nthis, we propose VerifyBench--a cross-domain comprehensive benchmark for\nsystematically evaluating verifiers. We construct 4,000 expert-level questions\ncovering mathematics, physics, chemistry, and biology. Each question is\nequipped with reference answers and diverse responses. The reliability of the\nevaluation is ensured through a rigorous annotation process conducted by a\nmultidisciplinary expert team. We design a four-dimensional experimental\nframework to comprehensively compare the performance boundaries of specialized\nverifiers and general LLMs under combined conditions of extracted answers vs.\ncomplete responses, and short vs. long outputs. Our evaluation uncovers\nfundamental trade-offs in verifiers: while specialized verifiers achieve\nleading accuracy, they exhibit deficiencies in recall; general models show\nstronger inclusivity but unstable precision. More importantly, we discover\nverifiers' high sensitivity to input structure and inherent limitations in\ncross-domain generalization, providing critical insights into the bottlenecks\nof current verifier technology.", "comment": "Preprint, Under review", "pdf_url": "http://arxiv.org/pdf/2507.09884v2", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-15"}
{"id": "2507.11161", "title": "How does Labeling Error Impact Contrastive Learning? A Perspective from Data Dimensionality Reduction", "authors": ["Jun Chen", "Hong Chen", "Yonghua Yu", "Yiming Ying"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Accepted by ICML2025 as a poster", "url": "http://arxiv.org/abs/2507.11161v1", "summary": "In recent years, contrastive learning has achieved state-of-the-art\nperformance in the territory of self-supervised representation learning. Many\nprevious works have attempted to provide the theoretical understanding\nunderlying the success of contrastive learning. Almost all of them rely on a\ndefault assumption, i.e., the label consistency assumption, which may not hold\nin practice (the probability of failure is called labeling error) due to the\nstrength and randomness of common augmentation strategies, such as random\nresized crop (RRC). This paper investigates the theoretical impact of labeling\nerror on the downstream classification performance of contrastive learning. We\nfirst reveal several significant negative impacts of labeling error on\ndownstream classification risk. To mitigate these impacts, data dimensionality\nreduction method (e.g., singular value decomposition, SVD) is applied on\noriginal data to reduce false positive samples, and establish both theoretical\nand empirical evaluations. Moreover, it is also found that SVD acts as a\ndouble-edged sword, which may lead to the deterioration of downstream\nclassification accuracy due to the reduced connectivity of the augmentation\ngraph. Based on the above observations, we give the augmentation suggestion\nthat we should use some moderate embedding dimension (such as $512, 1024$ in\nour experiments), data inflation, weak augmentation, and SVD to ensure large\ngraph connectivity and small labeling error to improve model performance.", "comment": "Accepted by ICML2025 as a poster", "pdf_url": "http://arxiv.org/pdf/2507.11161v1", "cate": "stat.ML", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2501.19043", "title": "Self-Supervised Cross-Modal Text-Image Time Series Retrieval in Remote Sensing", "authors": ["Genc Hoxha", "Olivér Angyal", "Begüm Demir"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.19043v2", "summary": "The development of image time series retrieval (ITSR) methods is a growing\nresearch interest in remote sensing (RS). Given a user-defined image time\nseries (i.e., the query time series), ITSR methods search and retrieve from\nlarge archives the image time series that have similar content to the query\ntime series. Existing ITSR methods in RS are designed for unimodal retrieval\nproblems, relying on an assumption that users always have access to a query\nimage time series in the considered image modality. In operational scenarios,\nthis assumption may not hold. To overcome this issue, as a first time in RS we\nintroduce the task of cross-modal text-image time series retrieval (text-ITSR).\nIn detail, we present a self-supervised cross-modal text-ITSR method that\nenables the retrieval of image time series using text sentences as queries, and\nvice versa. We focus our attention on text-ITSR in pairs of images (i.e.,\nbitemporal images). Our text-ITSR method consists of two key components: 1)\nmodality-specific encoders to model the semantic content of bitemporal images\nand text sentences with discriminative features; and 2) modality-specific\nprojection heads to align textual and image representations in a shared\nembedding space. To effectively model the temporal information in the\nbitemporal images, we exploit two fusion strategies: i) global feature fusion\n(GFF) strategy that combines global image features through simple yet effective\noperators; and ii) transformer-based feature fusion (TFF) strategy that\nleverages transformers for fine-grained temporal integration. Extensive\nexperiments conducted on two benchmark RS archives demonstrate the\neffectiveness of our method in accurately retrieving semantically relevant\nbitemporal images (or text sentences) to a query text sentence (or bitemporal\nimage). The code of this work is publicly available at\nhttps://git.tu-berlin.de/rsim/cross-modal-text-tsir .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.19043v2", "cate": "cs.CV", "date": "2025-01-31", "updated": "2025-07-15"}
{"id": "2412.14959", "title": "Understanding the Dark Side of LLMs' Intrinsic Self-Correction", "authors": ["Qingjie Zhang", "Di Wang", "Haoting Qian", "Yiming Li", "Tianwei Zhang", "Minlie Huang", "Ke Xu", "Hewu Li", "Yan Liu", "Han Qiu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.14959v2", "summary": "Intrinsic self-correction was proposed to improve LLMs' responses via\nfeedback prompts solely based on their inherent capability. However, recent\nworks show that LLMs' intrinsic self-correction fails without oracle labels as\nfeedback prompts. In this paper, we aim to interpret LLMs' intrinsic\nself-correction for different tasks, especially for those failure cases. By\nincluding one simple task and three complex tasks with state-of-the-art (SOTA)\nLLMs like ChatGPT families (o1, 4o, 3.5-turbo) and Llama families (2-7B, 3-8B,\nand 3.1-8B), we design three interpretation methods to reveal the dark side of\nLLMs' intrinsic self-correction. We identify intrinsic self-correction can (1)\ncause LLMs to waver both intermedia and final answers and lead to prompt bias\non simple factual questions; (2) introduce human-like cognitive bias on complex\ntasks. In light of our findings, we also provide two simple yet effective\nstrategies for alleviation: question repeating and supervised fine-tuning with\na few samples. We open-source our work at https://x-isc.info/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.14959v2", "cate": "cs.CL", "date": "2024-12-19", "updated": "2025-07-15"}
{"id": "2410.12553", "title": "A finite difference method with symmetry properties for the high-dimensional Bratu equation", "authors": ["Muhammad Luthfi Shahab", "Hadi Susanto", "Haralampos Hatzikirou"], "categories": ["math.NA", "cs.NA", "math.AP", "math.OC"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      Accepted for publication in Applied Mathematics and Computation", "url": "http://arxiv.org/abs/2410.12553v3", "summary": "Solving the three-dimensional (3D) Bratu equation is highly challenging due\nto the presence of multiple and sharp solutions. Research on this equation\nbegan in the late 1990s, but there are no satisfactory results to date. To\naddress this issue, we introduce a symmetric finite difference method (SFDM)\nwhich embeds the symmetry properties of the solutions into a finite difference\nmethod (FDM). This SFDM is primarily used to obtain more accurate solutions and\nbifurcation diagrams for the 3D Bratu equation. Additionally, we propose\nmodifying the Bratu equation by incorporating a new constraint that facilitates\nthe construction of bifurcation diagrams and simplifies handling the turning\npoints. The proposed method, combined with the use of sparse matrix\nrepresentation, successfully solves the 3D Bratu equation on grids of up to\n$301^3$ points. The results demonstrate that SFDM outperforms all previously\nemployed methods for the 3D Bratu equation. Furthermore, we provide bifurcation\ndiagrams for the 1D, 2D, 4D, and 5D cases, and accurately identify the first\nturning points in all dimensions. All simulations indicate that the bifurcation\ndiagrams of the Bratu equation on the cube domains closely resemble the\nwell-established behavior on the ball domains described by Joseph and Lundgren\n[1]. Furthermore, when SFDM is applied to linear stability analysis, it yields\nthe same largest real eigenvalue as the standard FDM despite having fewer\nequations and variables in the nonlinear system.", "comment": "Accepted for publication in Applied Mathematics and Computation", "pdf_url": "http://arxiv.org/pdf/2410.12553v3", "cate": "math.NA", "date": "2024-10-16", "updated": "2025-07-15"}
{"id": "2507.11289", "title": "Cyclic Data Streaming on GPUs for Short Range Stencils Applied to Molecular Dynamics", "authors": ["Martin Rose", "Simon Homes", "Lukas Ramsperger", "Jose Gracia", "Christoph Niethammer", "Jadran Vrabec"], "categories": ["cs.DC", "cs.PF"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      Accepted for publication at HeteroPar 2025 co-located with Euro-Par 2025", "url": "http://arxiv.org/abs/2507.11289v1", "summary": "In the quest for highest performance in scientific computing, we present a\nnovel framework that relies on high-bandwidth communication between GPUs in a\ncompute cluster. The framework offers linear scaling of performance for\nexplicit algorithms that is only limited by the size of the dataset and the\nnumber of GPUs. Slices of the dataset propagate in a ring of processes (GPUs)\nfrom one GPU, where they are processed, to the next, which results in a\nparallel-in-time parallelization. The user of the framework has to write GPU\nkernels that implement the algorithm and provide slices of the dataset.\nKnowledge about the underlying parallelization strategy is not required because\nthe communication between processes is carried out by the framework. As a case\nstudy, molecular dynamics simulation based on the Lennard-Jones potential is\nimplemented to measure the performance for a homogeneous fluid. Single node\nperformance and strong scaling behavior of this framework is compared to\nLAMMPS, which is outperformed in the strong scaling case.", "comment": "Accepted for publication at HeteroPar 2025 co-located with Euro-Par\n  2025", "pdf_url": "http://arxiv.org/pdf/2507.11289v1", "cate": "cs.DC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.10446", "title": "Acquiring and Adapting Priors for Novel Tasks via Neural Meta-Architectures", "authors": ["Sudarshan Babu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2310.17075", "url": "http://arxiv.org/abs/2507.10446v2", "summary": "The ability to transfer knowledge from prior experiences to novel tasks\nstands as a pivotal capability of intelligent agents, including both humans and\ncomputational models. This principle forms the basis of transfer learning,\nwhere large pre-trained neural networks are fine-tuned to adapt to downstream\ntasks. Transfer learning has demonstrated tremendous success, both in terms of\ntask adaptation speed and performance. However there are several domains where,\ndue to lack of data, training such large pre-trained models or foundational\nmodels is not a possibility - computational chemistry, computational\nimmunology, and medical imaging are examples. To address these challenges, our\nwork focuses on designing architectures to enable efficient acquisition of\npriors when large amounts of data are unavailable. In particular, we\ndemonstrate that we can use neural memory to enable adaptation on\nnon-stationary distributions with only a few samples. Then we demonstrate that\nour hypernetwork designs (a network that generates another network) can acquire\nmore generalizable priors than standard networks when trained with Model\nAgnostic Meta-Learning (MAML). Subsequently, we apply hypernetworks to 3D scene\ngeneration, demonstrating that they can acquire priors efficiently on just a\nhandful of training scenes, thereby leading to faster text-to-3D generation. We\nthen extend our hypernetwork framework to perform 3D segmentation on novel\nscenes with limited data by efficiently transferring priors from earlier viewed\nscenes. Finally, we repurpose an existing molecular generative method as a\npre-training framework that facilitates improved molecular property prediction,\naddressing critical challenges in computational immunology.", "comment": "arXiv admin note: text overlap with arXiv:2310.17075", "pdf_url": "http://arxiv.org/pdf/2507.10446v2", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-15"}
{"id": "2507.11176", "title": "An Interpretable AI framework Quantifying Traditional Chinese Medicine Principles Towards Enhancing and Integrating with Modern Biomedicine", "authors": ["Haoran Li", "Xingye Cheng", "Ziyang Huang", "Jingyuan Luo", "Qianqian Xu", "Qiguang Zhao", "Tianchen Guo", "Yumeng Zhang", "Linda Lidan Zhong", "Zhaoxiang Bian", "Leihan Tang", "Aiping Lyu", "Liang Tian"], "categories": ["physics.soc-ph", "cs.LG", "q-bio.OT", "stat.ML"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "Comments:      31 pages, 6 figures", "url": "http://arxiv.org/abs/2507.11176v1", "summary": "Traditional Chinese Medicine diagnosis and treatment principles, established\nthrough centuries of trial-and-error clinical practice, directly maps\npatient-specific symptom patterns to personalised herbal therapies. These\nempirical holistic mapping principles offer valuable strategies to address\nremaining challenges of reductionism methodologies in modern biomedicine.\nHowever, the lack of a quantitative framework and molecular-level evidence has\nlimited their interpretability and reliability. Here, we present an AI\nframework trained on ancient and classical TCM formula records to quantify the\nsymptom pattern-herbal therapy mappings. Interestingly, we find that empirical\nTCM diagnosis and treatment are consistent with the encoding-decoding processes\nin the AI model. This enables us to construct an interpretable TCM embedding\nspace (TCM-ES) using the model's quantitative representation of TCM principles.\nValidated through broad and extensive TCM patient data, the TCM-ES offers\nuniversal quantification of the TCM practice and therapeutic efficacy. We\nfurther map biomedical entities into the TCM-ES through correspondence\nalignment. We find that the principal directions of the TCM-ES are\nsignificantly associated with key biological functions (such as metabolism,\nimmune, and homeostasis), and that the disease and herb embedding proximity\naligns with their genetic relationships in the human protein interactome, which\ndemonstrate the biological significance of TCM principles. Moreover, the TCM-ES\nuncovers latent disease relationships, and provides alternative metric to\nassess clinical efficacy for modern disease-drug pairs. Finally, we construct a\ncomprehensive and integrative TCM knowledge graph, which predicts potential\nassociations between diseases and targets, drugs, herbal compounds, and herbal\ntherapies, providing TCM-informed opportunities for disease analysis and drug\ndevelopment.", "comment": "31 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.11176v1", "cate": "physics.soc-ph", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2503.06151", "title": "Biomechanics-Guided Residual Approach to Generalizable Human Motion Generation and Estimation", "authors": ["Zixi Kang", "Xinghan Wang", "Yadong Mu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.06151v2", "summary": "Human pose, action, and motion generation are critical for applications in\ndigital humans, character animation, and humanoid robotics. However, many\nexisting methods struggle to produce physically plausible movements that are\nconsistent with biomechanical principles. Although recent autoregressive and\ndiffusion models deliver impressive visual quality, they often neglect key\nbiodynamic features and fail to ensure physically realistic motions.\nReinforcement Learning (RL) approaches can address these shortcomings but are\nhighly dependent on simulation environments, limiting their generalizability.\nTo overcome these challenges, we propose BioVAE, a biomechanics-aware framework\nwith three core innovations: (1) integration of muscle electromyography (EMG)\nsignals and kinematic features with acceleration constraints to enable\nphysically plausible motion without simulations; (2) seamless coupling with\ndiffusion models for stable end-to-end training; and (3) biomechanical priors\nthat promote strong generalization across diverse motion generation and\nestimation tasks. Extensive experiments demonstrate that BioVAE achieves\nstate-of-the-art performance on multiple benchmarks, bridging the gap between\ndata-driven motion synthesis and biomechanical authenticity while setting new\nstandards for physically accurate motion generation and pose estimation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.06151v2", "cate": "cs.CV", "date": "2025-03-08", "updated": "2025-07-15"}
{"id": "2412.21033", "title": "Plancraft: an evaluation dataset for planning with LLM agents", "authors": ["Gautier Dagan", "Frank Keller", "Alex Lascarides"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.21033v2", "summary": "We present Plancraft, a multi-modal evaluation dataset for LLM agents.\nPlancraft has both a text-only and multi-modal interface, based on the\nMinecraft crafting GUI. We include the Minecraft Wiki to evaluate tool use and\nRetrieval Augmented Generation (RAG), as well as a handcrafted planner and\nOracle Retriever, to ablate the different components of a modern agent\narchitecture. To evaluate decision-making, Plancraft also includes a subset of\nexamples that are intentionally unsolvable, providing a realistic challenge\nthat requires the agent not only to complete tasks but also to decide whether\nthey are solvable at all. We benchmark both open-source and closed-source LLMs\nand compare their performance and efficiency to a handcrafted planner. Overall,\nwe find that LLMs and VLMs struggle with the planning problems that Plancraft\nintroduces, and offer suggestions on how to improve their capabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.21033v2", "cate": "cs.CL", "date": "2024-12-30", "updated": "2025-07-15"}
{"id": "2412.17318", "title": "Parallel subspace correction methods for semicoercive and nearly semicoercive convex optimization with applications to nonlinear PDEs", "authors": ["Young-Ju Lee", "Jongho Park"], "categories": ["math.NA", "cs.NA", "math.OC", "65J20, 65N20, 65N55, 90C22, 90C25"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      31 pages, 0 figures", "url": "http://arxiv.org/abs/2412.17318v3", "summary": "We present new convergence analyses for parallel subspace correction methods\nfor unconstrained semicoercive and nearly semicoercive convex optimization\nproblems, generalizing the theory of singular and nearly singular linear\nproblems to a class of nonlinear problems. Our results demonstrate that the\nelegant theoretical framework developed for singular and nearly singular linear\nproblems can be extended to unconstrained semicoercive and nearly semicoercive\nconvex optimization problems. For semicoercive problems, we show that the\nconvergence rate can be estimated in terms of a seminorm stable decomposition\nover the subspaces and the kernel of the problem, aligning with the theory for\nsingular linear problems. For nearly semicoercive problems, we establish a\nparameter-independent convergence rate, assuming the kernel of the semicoercive\npart can be decomposed into a sum of local kernels, which aligns with the\ntheory for nearly singular problems. To demonstrate the applicability of our\nresults, we provide convergence analyses of two-level additive Schwarz methods\nfor solving certain nonlinear partial differential equations with Neumann\nboundary conditions, within the proposed abstract framework.", "comment": "31 pages, 0 figures", "pdf_url": "http://arxiv.org/pdf/2412.17318v3", "cate": "math.NA", "date": "2024-12-23", "updated": "2025-07-15"}
{"id": "2507.11386", "title": "A new Dune grid for scalable dynamic adaptivity based on the p4est software library", "authors": ["Carsten Burstedde", "Mikhail Kirilin", "Robert Klöfkorn"], "categories": ["cs.DC", "65M50, 65N50"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      27 pages, 8 figures, 2 algorithms", "url": "http://arxiv.org/abs/2507.11386v1", "summary": "In this work we extend the Dune solver library with another grid interface to\nthe open-source p4est software. While Dune already supports about a dozen\ndifferent mesh implementations through its mesh interface Dune-Grid, we\nundertake this new coupling effort in order to inherit p4est's practically\nunlimited MPI scalability as well as its relatively thin data structures, and\nits native support for multi-block (forest) mesh topologies in both 2D and 3D.\n  The presented implementation is compared to an existing implementation based\non Dune-ALUGrid for a variety of challenging test examples in a parallel\nenvironment. The numerical experiments show that the implementation presented\nhere is outperforming Dune-ALUGrid in terms of scalability. In addition, an\nalternative balancing strategy is presented to ensure 2:1 balancing across\nelement faces showing improved performance compared to the existing p4est\nbalance strategy in the numerical examples considered in this work.", "comment": "27 pages, 8 figures, 2 algorithms", "pdf_url": "http://arxiv.org/pdf/2507.11386v1", "cate": "cs.DC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2310.03399", "title": "GRAPES: Learning to Sample Graphs for Scalable Graph Neural Networks", "authors": ["Taraneh Younesian", "Daniel Daza", "Emile van Krieken", "Thiviyan Thanapalasingam", "Peter Bloem"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2310.03399v3", "summary": "Graph neural networks (GNNs) learn to represent nodes by aggregating\ninformation from their neighbors. As GNNs increase in depth, their receptive\nfield grows exponentially, leading to high memory costs. Several existing\nmethods address this by sampling a small subset of nodes, scaling GNNs to much\nlarger graphs. These methods are primarily evaluated on homophilous graphs,\nwhere neighboring nodes often share the same label. However, most of these\nmethods rely on static heuristics that may not generalize across different\ngraphs or tasks. We argue that the sampling method should be adaptive,\nadjusting to the complex structural properties of each graph. To this end, we\nintroduce GRAPES, an adaptive sampling method that learns to identify the set\nof nodes crucial for training a GNN. GRAPES trains a second GNN to predict node\nsampling probabilities by optimizing the downstream task objective. We evaluate\nGRAPES on various node classification benchmarks, involving homophilous as well\nas heterophilous graphs. We demonstrate GRAPES' effectiveness in accuracy and\nscalability, particularly in multi-label heterophilous graphs. Unlike other\nsampling methods, GRAPES maintains high accuracy even with smaller sample sizes\nand, therefore, can scale to massive graphs. Our code is publicly available at\nhttps://github.com/dfdazac/grapes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2310.03399v3", "cate": "cs.LG", "date": "2023-10-05", "updated": "2025-07-15"}
{"id": "2507.11192", "title": "Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis", "authors": ["Bo Liang", "He Wang"], "categories": ["gr-qc", "astro-ph.HE", "astro-ph.IM", "cs.LG", "stat.ML"], "primary_category": "Subjects:       General Relativity and Quantum Cosmology (gr-qc)", "pdf_link": null, "comments": "Comments:      30 pages, 6 figures, 1 table. Published version accepted by Astronomical Techniques and Instruments (ATI)", "url": "http://arxiv.org/abs/2507.11192v1", "summary": "The detection of gravitational waves by the LIGO-Virgo-KAGRA collaboration\nhas ushered in a new era of observational astronomy, emphasizing the need for\nrapid and detailed parameter estimation and population-level analyses.\nTraditional Bayesian inference methods, particularly Markov chain Monte Carlo,\nface significant computational challenges when dealing with the\nhigh-dimensional parameter spaces and complex noise characteristics inherent in\ngravitational wave data. This review examines the emerging role of\nsimulation-based inference methods in gravitational wave astronomy, with a\nfocus on approaches that leverage machine-learning techniques such as\nnormalizing flows and neural posterior estimation. We provide a comprehensive\noverview of the theoretical foundations underlying various simulation-based\ninference methods, including neural posterior estimation, neural ratio\nestimation, neural likelihood estimation, flow matching, and consistency\nmodels. We explore the applications of these methods across diverse\ngravitational wave data processing scenarios, from single-source parameter\nestimation and overlapping signal analysis to testing general relativity and\nconducting population studies. Although these techniques demonstrate speed\nimprovements over traditional methods in controlled studies, their\nmodel-dependent nature and sensitivity to prior assumptions are barriers to\ntheir widespread adoption. Their accuracy, which is similar to that of\nconventional methods, requires further validation across broader parameter\nspaces and noise conditions.", "comment": "30 pages, 6 figures, 1 table. Published version accepted by\n  Astronomical Techniques and Instruments (ATI)", "pdf_url": "http://arxiv.org/pdf/2507.11192v1", "cate": "gr-qc", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2503.10225", "title": "Unveiling the Invisible: Reasoning Complex Occlusions Amodally with AURA", "authors": ["Zhixuan Li", "Hyunse Yoon", "Sanghoon Lee", "Weisi Lin"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025, 17 pages, 9 figures, 5 tables", "url": "http://arxiv.org/abs/2503.10225v2", "summary": "Amodal segmentation aims to infer the complete shape of occluded objects,\neven when the occluded region's appearance is unavailable. However, current\namodal segmentation methods lack the capability to interact with users through\ntext input and struggle to understand or reason about implicit and complex\npurposes. While methods like LISA integrate multi-modal large language models\n(LLMs) with segmentation for reasoning tasks, they are limited to predicting\nonly visible object regions and face challenges in handling complex occlusion\nscenarios. To address these limitations, we propose a novel task named amodal\nreasoning segmentation, aiming to predict the complete amodal shape of occluded\nobjects while providing answers with elaborations based on user text input. We\ndevelop a generalizable dataset generation pipeline and introduce a new dataset\nfocusing on daily life scenarios, encompassing diverse real-world occlusions.\nFurthermore, we present AURA (Amodal Understanding and Reasoning Assistant), a\nnovel model with advanced global and spatial-level designs specifically\ntailored to handle complex occlusions. Extensive experiments validate AURA's\neffectiveness on the proposed dataset.", "comment": "Accepted by ICCV 2025, 17 pages, 9 figures, 5 tables", "pdf_url": "http://arxiv.org/pdf/2503.10225v2", "cate": "cs.CV", "date": "2025-03-13", "updated": "2025-07-15"}
{"id": "2503.21073", "title": "Shared Global and Local Geometry of Language Model Embeddings", "authors": ["Andrew Lee", "Melanie Weber", "Fernanda Viégas", "Martin Wattenberg"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.21073v3", "summary": "Researchers have recently suggested that models share common representations.\nIn our work, we find numerous geometric similarities across the token\nembeddings of large language models. First, we find ``global'' similarities:\ntoken embeddings often share similar relative orientations. Next, we\ncharacterize local geometry in two ways: (1) by using Locally Linear\nEmbeddings, and (2) by defining a simple measure for the intrinsic dimension of\neach embedding. Both characterizations allow us to find local similarities\nacross token embeddings. Additionally, our intrinsic dimension demonstrates\nthat embeddings lie on a lower dimensional manifold, and that tokens with lower\nintrinsic dimensions often have semantically coherent clusters, while those\nwith higher intrinsic dimensions do not. Based on our findings, we introduce\nEMB2EMB, a simple application to linearly transform steering vectors from one\nlanguage model to another, despite the two models having different dimensions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.21073v3", "cate": "cs.CL", "date": "2025-03-27", "updated": "2025-07-15"}
{"id": "2501.00150", "title": "Error estimation for quasi-Monte Carlo", "authors": ["Art B. Owen"], "categories": ["math.NA", "cs.NA", "stat.CO"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.00150v3", "summary": "Quasi-Monte Carlo sampling can attain far better accuracy than plain Monte\nCarlo sampling. However, with plain Monte Carlo sampling it is much easier to\nestimate the attained accuracy. This article describes methods old and new to\nquantify the error in quasi-Monte Carlo estimates. An important challenge in\nthis setting is that the goal of getting accuracy conflicts with that of\nestimating the attained accuracy. A related challenge is that rigorous\nuncertainty quantifications can be extremely conservative. A recent surprise is\nthat some RQMC estimates have nearly symmetric distributions and that has the\npotential to allow confidence intervals that do not require either a central\nlimit theorem or a consistent variance estimate.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.00150v3", "cate": "math.NA", "date": "2024-12-30", "updated": "2025-07-15"}
{"id": "2507.11417", "title": "Quantifying the Energy Consumption and Carbon Emissions of LLM Inference via Simulations", "authors": ["Miray Özcan", "Philipp Wiesner", "Philipp Weiß", "Odej Kao"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      Presented at the Workshop on Performance and Energy Efficiency in Concurrent and Distributed Systems (PECS) at Euro-PAR'25", "url": "http://arxiv.org/abs/2507.11417v1", "summary": "The environmental impact of Large Language Models (LLMs) is rising\nsignificantly, with inference now accounting for more than half of their total\nlifecycle carbon emissions. However, existing simulation frameworks, which are\nincreasingly used to determine efficient LLM deployments, lack any concept of\npower and, therefore, cannot accurately estimate inference-related emissions.\nWe present a simulation framework to assess the energy and carbon implications\nof LLM inference under varying deployment setups. First, we extend a\nhigh-fidelity LLM inference simulator with a GPU power model that estimates\npower consumption based on utilization metrics, enabling analysis across\nconfigurations like batch size, sequence length, and model parallelism. Second,\nwe integrate simulation outputs into an energy system co-simulation environment\nto quantify carbon emissions under specific grid conditions and explore the\npotential of carbon-aware scheduling. Through scenario-based analysis, our\nframework reveals how inference parameters affect energy demand and carbon\nfootprint, demonstrates a renewable offset potential of up to 69.2% in an\nillustrative deployment case, and provides a foundation for future carbon-aware\ninference infrastructure design.", "comment": "Presented at the Workshop on Performance and Energy Efficiency in\n  Concurrent and Distributed Systems (PECS) at Euro-PAR'25", "pdf_url": "http://arxiv.org/pdf/2507.11417v1", "cate": "cs.DC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2310.13367", "title": "EASTER: Embedding Aggregation-based Heterogeneous Models Training in Vertical Federated Learning", "authors": ["Shuo Wang", "Keke Gai", "Jing Yu", "Liehuang Zhu", "Kim-Kwang Raymond Choo", "Bin Xiao"], "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      15 pages, 19 figures", "url": "http://arxiv.org/abs/2310.13367v3", "summary": "Vertical federated learning has garnered significant attention as it allows\nclients to train machine learning models collaboratively without sharing local\ndata, which protects the client's local private data. However, existing VFL\nmethods face challenges when dealing with heterogeneous local models among\nparticipants, which affects optimization convergence and generalization. To\naddress this challenge, this paper proposes a novel approach called Vertical\nfederated learning for training multiple Heterogeneous models (VFedMH). VFedMH\nfocuses on aggregating the local embeddings of each participant's knowledge\nduring forward propagation. To protect the participants' local embedding\nvalues, we propose an embedding protection method based on lightweight blinding\nfactors. In particular, participants obtain local embedding using local\nheterogeneous models. Then the passive party, who owns only features of the\nsample, injects the blinding factor into the local embedding and sends it to\nthe active party. The active party aggregates local embeddings to obtain global\nknowledge embeddings and sends them to passive parties. The passive parties\nthen utilize the global embeddings to propagate forward on their local\nheterogeneous networks. However, the passive party does not own the sample\nlabels, so the local model gradient cannot be calculated locally. To overcome\nthis limitation, the active party assists the passive party in computing its\nlocal heterogeneous model gradients. Then, each participant trains their local\nmodel using the heterogeneous model gradients. The objective is to minimize the\nloss value of their respective local heterogeneous models. Extensive\nexperiments are conducted to demonstrate that VFedMH can simultaneously train\nmultiple heterogeneous models with heterogeneous optimization and outperform\nsome recent methods in model performance.", "comment": "15 pages, 19 figures", "pdf_url": "http://arxiv.org/pdf/2310.13367v3", "cate": "cs.LG", "date": "2023-10-20", "updated": "2025-07-15"}
{"id": "2507.11366", "title": "A Parallelizable Approach for Characterizing NE in Zero-Sum Games After a Linear Number of Iterations of Gradient Descent", "authors": ["Taemin Kim", "James P. Bailey"], "categories": ["cs.GT", "cs.LG", "90C47, 91A05, 91A26, 68Q32"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11366v1", "summary": "We study online optimization methods for zero-sum games, a fundamental\nproblem in adversarial learning in machine learning, economics, and many other\ndomains. Traditional methods approximate Nash equilibria (NE) using either\nregret-based methods (time-average convergence) or contraction-map-based\nmethods (last-iterate convergence). We propose a new method based on\nHamiltonian dynamics in physics and prove that it can characterize the set of\nNE in a finite (linear) number of iterations of alternating gradient descent in\nthe unbounded setting, modulo degeneracy, a first in online optimization.\nUnlike standard methods for computing NE, our proposed approach can be\nparallelized and works with arbitrary learning rates, both firsts in\nalgorithmic game theory. Experimentally, we support our results by showing our\napproach drastically outperforms standard methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11366v1", "cate": "cs.GT", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2503.10596", "title": "GroundingSuite: Measuring Complex Multi-Granular Pixel Grounding", "authors": ["Rui Hu", "Lianghui Zhu", "Yuxuan Zhang", "Tianheng Cheng", "Lei Liu", "Heng Liu", "Longjin Ran", "Xiaoxin Chen", "Wenyu Liu", "Xinggang Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      To appear at ICCV 2025. Code: this https URL", "url": "http://arxiv.org/abs/2503.10596v3", "summary": "Pixel grounding, encompassing tasks such as Referring Expression Segmentation\n(RES), has garnered considerable attention due to its immense potential for\nbridging the gap between vision and language modalities. However, advancements\nin this domain are currently constrained by limitations inherent in existing\ndatasets, including limited object categories, insufficient textual diversity,\nand a scarcity of high-quality annotations. To mitigate these limitations, we\nintroduce GroundingSuite, which comprises: (1) an automated data annotation\nframework leveraging multiple Vision-Language Model (VLM) agents; (2) a\nlarge-scale training dataset encompassing 9.56 million diverse referring\nexpressions and their corresponding segmentations; and (3) a meticulously\ncurated evaluation benchmark consisting of 3,800 images. The GroundingSuite\ntraining dataset facilitates substantial performance improvements, enabling\nmodels trained on it to achieve state-of-the-art results. Specifically, a cIoU\nof 68.9 on gRefCOCO and a gIoU of 55.3 on RefCOCOm. Moreover, the\nGroundingSuite annotation framework demonstrates superior efficiency compared\nto the current leading data annotation method, i.e., $4.5 \\times$ faster than\nGLaMM.", "comment": "To appear at ICCV 2025. Code:\n  https://github.com/hustvl/GroundingSuite", "pdf_url": "http://arxiv.org/pdf/2503.10596v3", "cate": "cs.CV", "date": "2025-03-13", "updated": "2025-07-15"}
{"id": "2504.01738", "title": "Style over Substance: Distilled Language Models Reason Via Stylistic Replication", "authors": ["Philip Lippmann", "Jie Yang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      To appear at COLM 2025", "url": "http://arxiv.org/abs/2504.01738v3", "summary": "Specialized reasoning language models (RLMs) have demonstrated that scaling\ntest-time computation through detailed reasoning traces significantly enhances\nperformance. Although these traces effectively facilitate knowledge\ndistillation into smaller, instruction-tuned models, the precise nature of\ntransferred reasoning remains unclear. In this study, we investigate to what\nextent distilled models internalize replicated stylistic patterns during\nreasoning. To this end, we systematically analyze reasoning traces, identifying\nstructural and lexical patterns that characterize successful reasoning. We then\nintroduce two new datasets -- a dataset of emergent reasoning traces and a\nsynthetic dataset explicitly constructed to replicate these stylistic patterns\n-- to precisely examine their influence on distilled models' reasoning\ncapabilities. We find that models trained on the synthetic traces achieve\ncomparable performance, indicating that distilled reasoning abilities rely\nsignificantly on surface-level patterns. Surprisingly, we observe an increase\nin performance even when the synthetic traces are altered to lead to the wrong\nanswer. Our findings highlight how stylistic patterns can be leveraged to\nefficiently enhance LM reasoning across diverse model families.", "comment": "To appear at COLM 2025", "pdf_url": "http://arxiv.org/pdf/2504.01738v3", "cate": "cs.CL", "date": "2025-04-02", "updated": "2025-07-15"}
{"id": "2503.03525", "title": "Discretization error analysis for a radially symmetric harmonic map heat flow problem", "authors": ["Nam Anh Nguyen", "Arnold Reusken"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.03525v2", "summary": "In this paper we study the harmonic map heat flow problem for a radially\nsymmetric case. The corresponding partial dfferential equation plays a key role\nin many analyses of harmonic map heat flow problems. We consider a basic\ndiscretization method for this problem, namely a second order finite difference\ndiscretization in space combined with a semi-implicit Euler method in time. The\nsemi-implicit Euler method results in a linear problem in each time step. We\nrestrict to the regime of smooth solutions of the continuous problem and\npresent an error analysis of this discretization method. This results in\noptimal order discretization error bounds (apart from a logarithmic term). We\nalso present discrete energy estimates that mimic the decrease of the energy of\nthe continuous solution.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.03525v2", "cate": "math.NA", "date": "2025-03-05", "updated": "2025-07-15"}
{"id": "2507.11430", "title": "FLsim: A Modular and Library-Agnostic Simulation Framework for Federated Learning", "authors": ["Arnab Mukherjee", "Raju Halder", "Joydeep Chandra"], "categories": ["cs.DC", "cs.LG"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11430v1", "summary": "Federated Learning (FL) has undergone significant development since its\ninception in 2016, advancing from basic algorithms to complex methodologies\ntailored to address diverse challenges and use cases. However, research and\nbenchmarking of novel FL techniques against a plethora of established\nstate-of-the-art solutions remain challenging. To streamline this process, we\nintroduce FLsim, a comprehensive FL simulation framework designed to meet the\ndiverse requirements of FL workflows in the literature. FLsim is characterized\nby its modularity, scalability, resource efficiency, and controlled\nreproducibility of experimental outcomes. Its easy to use interface allows\nusers to specify customized FL requirements through job configuration, which\nsupports: (a) customized data distributions, ranging from non-independent and\nidentically distributed (non-iid) data to independent and identically\ndistributed (iid) data, (b) selection of local learning algorithms according to\nuser preferences, with complete agnosticism to ML libraries, (c) choice of\nnetwork topology illustrating communication patterns among nodes, (d)\ndefinition of model aggregation and consensus algorithms, and (e) pluggable\nblockchain support for enhanced robustness. Through a series of experimental\nevaluations, we demonstrate the effectiveness and versatility of FLsim in\nsimulating a diverse range of state-of-the-art FL experiments. We envisage that\nFLsim would mark a significant advancement in FL simulation frameworks,\noffering unprecedented flexibility and functionality for researchers and\npractitioners alike.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11430v1", "cate": "cs.DC", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2312.10705", "title": "Learning Safe Numeric Planning Action Models", "authors": ["Argaman Mordoch", "Shahaf S. Shperberg", "Roni Stern", "Berndan Juba"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2312.10705v2", "summary": "A significant challenge in applying planning technology to real-world\nproblems lies in obtaining a planning model that accurately represents the\nproblem's dynamics. Obtaining a planning model is even more challenging in\nmission-critical domains, where a trial-and-error approach to learning how to\nact is not an option. In such domains, the action model used to generate plans\nmust be safe, in the sense that plans generated with it must be applicable and\nachieve their goals. % Learning safe action models for planning has been mostly\nexplored for domains in which states are sufficiently described with Boolean\nvariables. % In this work, we go beyond this limitation and propose the Numeric\nSafe Action Models Learning (N-SAM) algorithm. In this work, we present N-SAM,\nan action model learning algorithm capable of learning safe numeric\npreconditions and effects. We prove that N-SAM runs in linear time in the\nnumber of observations and, under certain conditions, is guaranteed to return\nsafe action models. However, to preserve this safety guarantee, N-SAM must\nobserve a substantial number of examples for each action before including it in\nthe learned model. We address this limitation of N-SAM and propose N-SAM*, an\nextension to the N-SAM algorithm that always returns an action model where\nevery observed action is applicable at least in some states, even if it was\nobserved only once. N-SAM* does so without compromising the safety of the\nreturned action model. We prove that N-SAM* is optimal in terms of sample\ncomplexity compared to any other algorithm that guarantees safety. N-SAM and\nN-SAM* are evaluated over an extensive benchmark of numeric planning domains,\nand their performance is compared to a state-of-the-art numeric action model\nlearning algorithm. We also provide a discussion on the impact of numerical\naccuracy on the learning process.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2312.10705v2", "cate": "cs.LG", "date": "2023-12-17", "updated": "2025-07-15"}
{"id": "2507.11381", "title": "From Observational Data to Clinical Recommendations: A Causal Framework for Estimating Patient-level Treatment Effects and Learning Policies", "authors": ["Rom Gutman", "Shimon Sheiba", "Omer Noy Klien", "Naama Dekel Bird", "Amit Gruber", "Doron Aronson", "Oren Caspi", "Uri Shalit"], "categories": ["stat.ML", "cs.LG", "stat.AP"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11381v1", "summary": "We propose a framework for building patient-specific treatment recommendation\nmodels, building on the large recent literature on learning patient-level\ncausal models and inspired by the target trial paradigm of Hernan and Robins.\nWe focus on safety and validity, including the crucial issue of causal\nidentification when using observational data. We do not provide a specific\nmodel, but rather a way to integrate existing methods and know-how into a\npractical pipeline. We further provide a real world use-case of treatment\noptimization for patients with heart failure who develop acute kidney injury\nduring hospitalization. The results suggest our pipeline can improve patient\noutcomes over the current treatment regime.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11381v1", "cate": "stat.ML", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2503.11439", "title": "COIN: Confidence Score-Guided Distillation for Annotation-Free Cell Segmentation", "authors": ["Sanghyun Jo", "Seo Jin Lee", "Seungwoo Lee", "Seohyung Hong", "Hyungseok Seo", "Kyungsu Kim"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025", "url": "http://arxiv.org/abs/2503.11439v3", "summary": "Cell instance segmentation (CIS) is crucial for identifying individual cell\nmorphologies in histopathological images, providing valuable insights for\nbiological and medical research. While unsupervised CIS (UCIS) models aim to\nreduce the heavy reliance on labor-intensive image annotations, they fail to\naccurately capture cell boundaries, causing missed detections and poor\nperformance. Recognizing the absence of error-free instances as a key\nlimitation, we present COIN (COnfidence score-guided INstance distillation), a\nnovel annotation-free framework with three key steps: (1) Increasing the\nsensitivity for the presence of error-free instances via unsupervised semantic\nsegmentation with optimal transport, leveraging its ability to discriminate\nspatially minor instances, (2) Instance-level confidence scoring to measure the\nconsistency between model prediction and refined mask and identify highly\nconfident instances, offering an alternative to ground truth annotations, and\n(3) Progressive expansion of confidence with recursive self-distillation.\nExtensive experiments across six datasets show COIN outperforming existing UCIS\nmethods, even surpassing semi- and weakly-supervised approaches across all\nmetrics on the MoNuSeg and TNBC datasets. The code is available at\nhttps://github.com/shjo-april/COIN.", "comment": "Accepted at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.11439v3", "cate": "cs.CV", "date": "2025-03-14", "updated": "2025-07-15"}
{"id": "2504.05294", "title": "Truthful or Fabricated? Using Causal Attribution to Mitigate Reward Hacking in Explanations", "authors": ["Pedro Ferreira", "Wilker Aziz", "Ivan Titov"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      20 pages, 10 figures, 6 tables", "url": "http://arxiv.org/abs/2504.05294v2", "summary": "Chain-of-thought explanations are widely used to inspect the decision process\nof large language models (LLMs) and to evaluate the trustworthiness of model\noutputs, making them important for effective collaboration between LLMs and\nhumans. We demonstrate that preference optimization - a key step in the\nalignment phase - can inadvertently reduce the faithfulness of these\nexplanations. This occurs because the reward model (RM), which guides\nalignment, is tasked with optimizing both the expected quality of the response\nand the appropriateness of the explanations (e.g., minimizing bias or adhering\nto safety standards), creating potential conflicts. The RM lacks a mechanism to\nassess the consistency between the model's internal decision process and the\ngenerated explanation. Consequently, the LLM may engage in \"reward hacking\" by\nproducing a final response that scores highly while giving an explanation\ntailored to maximize reward rather than accurately reflecting its reasoning. To\naddress this issue, we propose enriching the RM's input with a causal\nattribution of the prediction, allowing the RM to detect discrepancies between\nthe generated self-explanation and the model's decision process. In controlled\nsettings, we show that this approach reduces the tendency of the LLM to\ngenerate misleading explanations.", "comment": "20 pages, 10 figures, 6 tables", "pdf_url": "http://arxiv.org/pdf/2504.05294v2", "cate": "cs.CL", "date": "2025-04-07", "updated": "2025-07-15"}
{"id": "2503.17496", "title": "The Akhiezer iteration and inverse-free solvers for Sylvester matrix equations", "authors": ["Cade Ballew", "Thomas Trogdon", "Heather Wilber"], "categories": ["math.NA", "cs.NA", "65F45, 42C05, 33C47, 65F60, 65R20"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.17496v3", "summary": "Two inverse-free iterative methods are developed for solving Sylvester matrix\nequations when the spectra of the coefficient matrices are on, or near, known\ndisjoint subintervals of the real axis. Both methods use the\nrecently-introduced Akhiezer iteration: one to address an equivalent problem of\napproximating the matrix sign function applied to a block matrix and the other\nto directly approximate the inverse of the Sylvester operator. In each case\nthis results in provable and computable geometric rates of convergence. When\nthe right-hand side matrix is low rank, both methods require only low-rank\nmatrix-matrix products. Relative to existing approaches, the methods presented\nhere can be more efficient and require less storage when the coefficient\nmatrices are dense or otherwise costly to invert. Applications include solving\npartial differential equations and computing Fr\\'echet derivatives.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.17496v3", "cate": "math.NA", "date": "2025-03-21", "updated": "2025-07-14"}
{"id": "2507.10799", "title": "Stream programs are monoid homomorphisms with state", "authors": ["Tyler Hou", "Michael Arntzenius", "Max Willsey"], "categories": ["cs.PL", "cs.DC"], "primary_category": "Subjects:       Programming Languages (cs.PL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10799v1", "summary": "We define a broad class of deterministic stream functions and show they can\nbe implemented as homomorphisms into a \"state\" monoid. The homomorphism laws\nare simpler than the conditions of previous semantic frameworks for stream\nprogram optimization, yet retain support for rich equational reasoning over\nexpressive dataflow programs, including sequential composition, parallel\ncomposition, and feedback. We demonstrate this using examples of partitioned\ndatabase joins, stratified negation, and a simplified model of TCP.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10799v1", "cate": "cs.PL", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2404.14442", "title": "Unified ODE Analysis of Smooth Q-Learning Algorithms", "authors": ["Donghwan Lee"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.14442v4", "summary": "Convergence of Q-learning has been the focus of extensive research over the\npast several decades. Recently, an asymptotic convergence analysis for\nQ-learning was introduced using a switching system framework. This approach\napplies the so-called ordinary differential equation (ODE) approach to prove\nthe convergence of the asynchronous Q-learning modeled as a continuous-time\nswitching system, where notions from switching system theory are used to prove\nits asymptotic stability without using explicit Lyapunov arguments. However, to\nprove stability, restrictive conditions, such as quasi-monotonicity, must be\nsatisfied for the underlying switching systems, which makes it hard to easily\ngeneralize the analysis method to other reinforcement learning algorithms, such\nas the smooth Q-learning variants. In this paper, we present a more general and\nunified convergence analysis that improves upon the switching system approach\nand can analyze Q-learning and its smooth variants. The proposed analysis is\nmotivated by previous work on the convergence of synchronous Q-learning based\non $p$-norm serving as a Lyapunov function. However, the proposed analysis\naddresses more general ODE models that can cover both asynchronous Q-learning\nand its smooth versions with simpler frameworks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.14442v4", "cate": "cs.LG", "date": "2024-04-20", "updated": "2025-07-15"}
{"id": "2507.11385", "title": "Joint space-time wind field data extrapolation and uncertainty quantification using nonparametric Bayesian dictionary learning", "authors": ["George D. Pasparakis", "Ioannis A. Kougioumtzoglou", "Michael D. Shields"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11385v1", "summary": "A methodology is developed, based on nonparametric Bayesian dictionary\nlearning, for joint space-time wind field data extrapolation and estimation of\nrelated statistics by relying on limited/incomplete measurements. Specifically,\nutilizing sparse/incomplete measured data, a time-dependent optimization\nproblem is formulated for determining the expansion coefficients of an\nassociated low-dimensional representation of the stochastic wind field.\nCompared to an alternative, standard, compressive sampling treatment of the\nproblem, the developed methodology exhibits the following advantages. First,\nthe Bayesian formulation enables also the quantification of the uncertainty in\nthe estimates. Second, the requirement in standard CS-based applications for an\na priori selection of the expansion basis is circumvented. Instead, this is\ndone herein in an adaptive manner based on the acquired data. Overall, the\nmethodology exhibits enhanced extrapolation accuracy, even in cases of\nhigh-dimensional data of arbitrary form, and of relatively large extrapolation\ndistances. Thus, it can be used, potentially, in a wide range of wind\nengineering applications where various constraints dictate the use of a limited\nnumber of sensors. The efficacy of the methodology is demonstrated by\nconsidering two case studies. The first relates to the extrapolation of\nsimulated wind velocity records consistent with a prescribed joint\nwavenumber-frequency power spectral density in a three-dimensional domain (2D\nand time). The second pertains to the extrapolation of four-dimensional (3D and\ntime) boundary layer wind tunnel experimental data that exhibit significant\nspatial variability and non-Gaussian characteristics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11385v1", "cate": "stat.ML", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2503.22526", "title": "AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization", "authors": ["Martin Kišš", "Michal Hradiš", "Martina Dvořáková", "Václav Jiroušek", "Filip Kersch"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 2 tables, 7 figures; Accepted to GREC Workshop at ICDAR2025", "url": "http://arxiv.org/abs/2503.22526v2", "summary": "We introduce the AnnoPage Dataset, a novel collection of 7,550 pages from\nhistorical documents, primarily in Czech and German, spanning from 1485 to the\npresent, focusing on the late 19th and early 20th centuries. The dataset is\ndesigned to support research in document layout analysis and object detection.\nEach page is annotated with axis-aligned bounding boxes (AABB) representing\nelements of 25 categories of non-textual elements, such as images, maps,\ndecorative elements, or charts, following the Czech Methodology of image\ndocument processing. The annotations were created by expert librarians to\nensure accuracy and consistency. The dataset also incorporates pages from\nmultiple, mainly historical, document datasets to enhance variability and\nmaintain continuity. The dataset is divided into development and test subsets,\nwith the test set carefully selected to maintain the category distribution. We\nprovide baseline results using YOLO and DETR object detectors, offering a\nreference point for future research. The AnnoPage Dataset is publicly available\non Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth\nannotations in YOLO format.", "comment": "17 pages, 2 tables, 7 figures; Accepted to GREC Workshop at ICDAR2025", "pdf_url": "http://arxiv.org/pdf/2503.22526v2", "cate": "cs.CV", "date": "2025-03-28", "updated": "2025-07-15"}
{"id": "2504.11673", "title": "Deep Binding of Language Model Virtual Personas: a Study on Approximating Political Partisan Misperceptions", "authors": ["Minwoo Kang", "Suhong Moon", "Seung Hyeong Lee", "Ayush Raj", "Joseph Suh", "David M. Chan"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      COLM 2025", "url": "http://arxiv.org/abs/2504.11673v4", "summary": "Large language models (LLMs) are increasingly capable of simulating human\nbehavior, offering cost-effective ways to estimate user responses to various\nsurveys and polls. However, the questions in these surveys usually reflect\nsocially understood attitudes: the patterns of attitudes of old/young,\nliberal/conservative, as understood by both members and non-members of those\ngroups. It is not clear whether the LLM binding is \\emph{deep}, meaning the LLM\nanswers as a member of a particular in-group would, or \\emph{shallow}, meaning\nthe LLM responds as an out-group member believes an in-group member would. To\nexplore this difference, we use questions that expose known in-group/out-group\nbiases. This level of fidelity is critical for applying LLMs to various\npolitical science studies, including timely topics on polarization dynamics,\ninter-group conflict, and democratic backsliding. To this end, we propose a\nnovel methodology for constructing virtual personas with synthetic user\n``backstories\" generated as extended, multi-turn interview transcripts. Our\ngenerated backstories are longer, rich in detail, and consistent in\nauthentically describing a singular individual, compared to previous methods.\nWe show that virtual personas conditioned on our backstories closely replicate\nhuman response distributions (up to an 87\\% improvement as measured by\nWasserstein Distance) and produce effect sizes that closely match those\nobserved in the original studies of in-group/out-group biases. Altogether, our\nwork extends the applicability of LLMs beyond estimating socially understood\nresponses, enabling their use in a broader range of human studies.", "comment": "COLM 2025", "pdf_url": "http://arxiv.org/pdf/2504.11673v4", "cate": "cs.CL", "date": "2025-04-16", "updated": "2025-07-14"}
{"id": "2505.00715", "title": "Comparison of FMM and $\\mathcal{H}$-matrix based 3D-ACA for a time domain boundary element method", "authors": ["Martin Schanz", "Vibudha Lakshmi Keshava", "Herbert de Gersem"], "categories": ["math.NA", "cs.NA", "35L05, 65M38, 65R20"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      22 pages, 10 figures, 1 table. arXiv admin note: substantial text overlap with arXiv:2312.11219 submitted to Computational Mechanics", "url": "http://arxiv.org/abs/2505.00715v2", "summary": "The time domain Boundary Element Method (BEM) for the homogeneous wave\nequation with vanishing initial conditions is considered. For the temporal\ndiscretisation, the generalized convolution quadrature method (gCQ) developed\nby Lopez-Fernandez and Sauter is used. The spatial discretisation is done\nclassically using low-order shape functions.\n  Essentially, the gCQ requires to establish boundary element matrices of the\ncorresponding elliptic problem in Laplace domain at several complex\nfrequencies. Consequently, an array of system matrices is obtained. This array\nof system matrices can be interpreted as a three-dimensional array of data\nwhich should be approximated by a data-sparse representation, for which the\ngeneralised Adaptive Cross Approximation (3D-ACA) can be applied. The rank of\nthe three-dimensional data array is increased adaptively until a prescribed\naccuracy is obtained. On a pure algebraic level, it is decided whether a\nlow-rank approximation of the three-dimensional data array is close enough to\nthe original matrix. Within the data slices corresponding to the BEM\ncalculations for each frequency, either the standard $\\mathcal{H}$-matrices\napproach with ACA or a fast multipole (FMM) approach can be used. The third\ndimension of the data array represents the complex frequencies. Hence, the\nalgorithm does not only sparsify the data array in the two spatial dimensions\nbut also adaptively detects how much frequencies are necessary for which matrix\nblock.\n  he two versions, either using ACA or FMM within the slices, are briefly\ndiscussed. The main contribution of this paper is a comparison of both with\nrespect to savings in storage and computing time. The example of the sound\nscattering of an electric machine shows that both techniques allow to utilise a\ntime-domain BEM in real-world problems.", "comment": "22 pages, 10 figures, 1 table. arXiv admin note: substantial text\n  overlap with arXiv:2312.11219 submitted to Computational Mechanics", "pdf_url": "http://arxiv.org/pdf/2505.00715v2", "cate": "math.NA", "date": "2025-04-16", "updated": "2025-07-14"}
{"id": "2410.09980", "title": "Rise and Shine Efficiently! Tight Bounds for Adversarial Wake-up", "authors": ["Peter Robinson", "Ming Ming Tan"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      New Theorem 5", "url": "http://arxiv.org/abs/2410.09980v3", "summary": "We study the wake-up problem in distributed networks, where an adversary\nawakens a subset of nodes at arbitrary times, and the goal is to wake up all\nother nodes as quickly as possible by sending only few messages. We prove the\nfollowing lower bounds:\n  * We first consider the setting where each node receives advice from an\noracle who can observe the entire network, but does not know which nodes are\nawake initially. More specifically, we consider the $KT_0$ $LOCAL$ model with\nadvice. We prove that any randomized algorithm must send $\\Omega(\n\\frac{n^{2}}{2^{\\beta}\\log n} )$ messages if nodes receive only $O(\\beta)$ bits\nof advice on average.\n  * For the $KT_1$ assumption, we show that any $(k+1)$-time algorithm requires\n$\\Omega( n^{1+1/k} )$ messages. Our result is the first super-linear (in $n$)\nlower bound, for a problem that does not require individual nodes to learn a\nlarge amount of information about the network topology.\n  To complement our lower bound results, we present several new algorithms:\n  * We give an asynchronous $KT_1$ $LOCAL$ algorithm that solves the wake-up\nproblem with a time and message complexity of $O( n\\log n )$ with high\nprobability.\n  * We introduce the notion of \\emph{awake distance} $\\rho_{\\text{awk}}$, which\nis upper-bounded by the network diameter, and present a synchronous $KT_1$\n$LOCAL$ algorithm that takes $O( \\rho_{\\text{awk}} )$ rounds and sends $O(\nn^{3/2}\\sqrt{\\log n} )$ messages with high probability. We also extend these\nideas to obtain a near-optimal time- and message complexity of $O\\( \\rho_{awk}\n\\log^3n )$ rounds $O( n \\log^3n )$ messages.\n  * We give deterministic advising schemes in the asynchronous $KT_0$ $CONGEST$\nmodel (with advice). In particular, we obtain an $O( \\rho_{\\text{awk}}\\log^2n\n)$-time advising scheme that sends $O( n\\log^2n )$ messages, while requiring\n$O( \\log^2n )$ bits of advice per node.", "comment": "New Theorem 5", "pdf_url": "http://arxiv.org/pdf/2410.09980v3", "cate": "cs.DC", "date": "2024-10-13", "updated": "2025-07-15"}
{"id": "2405.11238", "title": "SimAD: A Simple Dissimilarity-based Approach for Time Series Anomaly Detection", "authors": ["Zhijie Zhong", "Zhiwen Yu", "Xing Xi", "Yue Xu", "Wenming Cao", "Yiyuan Yang", "Kaixiang Yang", "Jane You"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      24 pages, 12 figures,11 tables", "url": "http://arxiv.org/abs/2405.11238v2", "summary": "Despite the prevalence of reconstruction-based deep learning methods, time\nseries anomaly detection remains a tremendous challenge. Existing approaches\noften struggle with limited temporal contexts, insufficient representation of\nnormal patterns, and flawed evaluation metrics, all of which hinder their\neffectiveness in detecting anomalous behavior. To address these issues, we\nintroduce a $\\textbf{Sim}$ple dissimilarity-based approach for time series\n$\\textbf{A}$nomaly $\\textbf{D}$etection, referred to as $\\textbf{SimAD}$.\nSpecifically, SimAD first incorporates a patching-based feature extractor\ncapable of processing extended temporal windows and employs the EmbedPatch\nencoder to fully integrate normal behavioral patterns. Second, we design an\ninnovative ContrastFusion module in SimAD, which strengthens the robustness of\nanomaly detection by highlighting the distributional differences between normal\nand abnormal data. Third, we introduce two robust enhanced evaluation metrics,\nUnbiased Affiliation (UAff) and Normalized Affiliation (NAff), designed to\novercome the limitations of existing metrics by providing better\ndistinctiveness and semantic clarity. The reliability of these two metrics has\nbeen demonstrated by both theoretical and experimental analyses. Experiments\nconducted on seven diverse time series datasets clearly demonstrate SimAD's\nsuperior performance compared to state-of-the-art methods, achieving relative\nimprovements of $\\textbf{19.85%}$ on F1, $\\textbf{4.44%}$ on Aff-F1,\n$\\textbf{77.79%}$ on NAff-F1, and $\\textbf{9.69%}$ on AUC on six multivariate\ndatasets. Code and pre-trained models are available at\nhttps://github.com/EmorZz1G/SimAD.", "comment": "24 pages, 12 figures,11 tables", "pdf_url": "http://arxiv.org/pdf/2405.11238v2", "cate": "cs.LG", "date": "2024-05-18", "updated": "2025-07-15"}
{"id": "2507.11419", "title": "Better Regret Rates in Bilateral Trade via Sublinear Budget Violation", "authors": ["Anna Lunghi", "Matteo Castiglioni", "Alberto Marchesi"], "categories": ["cs.GT", "cs.LG"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11419v1", "summary": "Bilateral trade is a central problem in algorithmic economics, and recent\nwork has explored how to design trading mechanisms using no-regret learning\nalgorithms. However, no-regret learning is impossible when budget balance has\nto be enforced at each time step. Bernasconi et al. [Ber+24] show how this\nimpossibility can be circumvented by relaxing the budget balance constraint to\nhold only globally over all time steps. In particular, they design an algorithm\nachieving regret of the order of $\\tilde O(T^{3/4})$ and provide a lower bound\nof $\\Omega(T^{5/7})$.\n  In this work, we interpolate between these two extremes by studying how the\noptimal regret rate varies with the allowed violation of the global budget\nbalance constraint. Specifically, we design an algorithm that, by violating the\nconstraint by at most $T^{\\beta}$ for any given $\\beta \\in [\\frac{3}{4},\n\\frac{6}{7}]$, attains regret $\\tilde O(T^{1 - \\beta/3})$. We complement this\nresult with a matching lower bound, thus fully characterizing the trade-off\nbetween regret and budget violation. Our results show that both the $\\tilde\nO(T^{3/4})$ upper bound in the global budget balance case and the\n$\\Omega(T^{5/7})$ lower bound under unconstrained budget balance violation\nobtained by Bernasconi et al. [Ber+24] are tight.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11419v1", "cate": "cs.GT", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2504.00558", "title": "Archival Faces: Detection of Faces in Digitized Historical Documents", "authors": ["Marek Vaško", "Adam Herout", "Michal Hradiš"], "categories": ["cs.CV", "68T45 (Primary) 68T10, 68T07 (Secondary)", "I.4.8; I.5.1"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICDAR 2025 Workshops, GREC2025", "url": "http://arxiv.org/abs/2504.00558v2", "summary": "When digitizing historical archives, it is necessary to search for the faces\nof celebrities and ordinary people, especially in newspapers, link them to the\nsurrounding text, and make them searchable. Existing face detectors on datasets\nof scanned historical documents fail remarkably -- current detection tools only\nachieve around 24% mAP at 50:90% IoU. This work compensates for this failure by\nintroducing a new manually annotated domain-specific dataset in the style of\nthe popular Wider Face dataset, containing 2.2k new images from digitized\nhistorical newspapers from the 19th to 20th century, with 11k new bounding-box\nannotations and associated facial landmarks. This dataset allows existing\ndetectors to be retrained to bring their results closer to the standard in the\nfield of face detection in the wild. We report several experimental results\ncomparing different families of fine-tuned detectors against publicly available\npre-trained face detectors and ablation studies of multiple detector sizes with\ncomprehensive detection and landmark prediction performance results.", "comment": "Accepted to ICDAR 2025 Workshops, GREC2025", "pdf_url": "http://arxiv.org/pdf/2504.00558v2", "cate": "cs.CV", "date": "2025-04-01", "updated": "2025-07-15"}
{"id": "2505.00582", "title": "Block Circulant Adapter for Large Language Models", "authors": ["Xinyu Ding", "Meiqi Wang", "Siyu Liao", "Zhongfeng Wang"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      to appear in Proceedings of the 2025 International Joint Conference on Artificial Intelligence (IJCAI-2025)", "url": "http://arxiv.org/abs/2505.00582v2", "summary": "Fine-tuning large language models (LLMs) is difficult due to their huge model\nsize. Recent Fourier domain-based methods show potential for reducing\nfine-tuning costs. We propose a block circulant matrix-based fine-tuning method\nwith a stable training heuristic to leverage the properties of circulant\nmatrices and one-dimensional Fourier transforms to reduce storage and\ncomputation costs. Experiments show that our method uses $14\\times$ less number\nof parameters than VeRA, $16\\times$ smaller than LoRA and $32\\times$ less FLOPs\nthan FourierFT, while maintaining close or better task performance. Our\napproach presents a promising way in frequency domain to fine-tune large models\non downstream tasks.", "comment": "to appear in Proceedings of the 2025 International Joint Conference\n  on Artificial Intelligence (IJCAI-2025)", "pdf_url": "http://arxiv.org/pdf/2505.00582v2", "cate": "cs.CL", "date": "2025-05-01", "updated": "2025-07-15"}
{"id": "2501.07645", "title": "Coverage errors for Student's t confidence intervals comparable to those in Hall (1988)", "authors": ["Art B. Owen"], "categories": ["math.ST", "cs.NA", "math.NA", "stat.TH"], "primary_category": "Subjects:       Statistics Theory (math.ST)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.07645v2", "summary": "Table 1 of Hall (1988) contains asymptotic coverage error formulas for some\nnonparametric approximate 95\\% confidence intervals for the mean based on $n$\nIID samples. The table includes an entry for an interval based on the central\nlimit theorem using Gaussian quantiles and the Gaussian maximum likelihood\nvariance estimate. It is missing an entry for the very widely used Student's\n$t$ confidence intervals. This note develops such a formula. The impetus to\nrevisit this issue arose from the surprisingly robust performance of confidence\nintervals based on Student's t statistic in randomized quasi-Monte Carlo\nsampling. Hall's table had $0.14\\kappa -2.12\\gamma^2-3.35$ for normal theory\nintervals; the corresponding entry for Student's $t$ is $0.14\\kappa\n-2.12\\gamma^2$.\n  An earlier version of this note reported that it corrected some coverage\nerror formulas in Hall (1988). Two-sided errors take the form\n$2\\Phi^{-1}(0.975)(A\\kappa + \\gamma^2+C)\\varphi(1.96)/n +O(1/n^{3/2})$ where\nthe error may well be $O(n^{-2})$. Hall's table showed\n$\\Phi^{-1}(0.975)(A\\kappa + B\\gamma^2+C)$. The version intended as a correction\nhad $2(A\\kappa + B\\gamma^2+C)$, wider by about $2/1.96\\doteq1.02$. So, Hall's\ntable really is proportional to the two-sided coverage errors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.07645v2", "cate": "math.ST", "date": "2025-01-13", "updated": "2025-07-15"}
{"id": "2507.05653", "title": "AAPA: An Archetype-Aware Predictive Autoscaler with Uncertainty Quantification for Serverless Workloads on Kubernetes", "authors": ["Guilin Zhang", "Srinivas Vippagunta", "Raghavendra Nandagopal", "Suchitra Raman", "Jeff Xu", "Marcus Pfeiffer", "Shreeshankar Chatterjee", "Ziqi Tan", "Wulan Guo", "Hailong Jiang"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      6 pages, 4 figures, 1 table. First three authors contributed equally. Correspondence to Hailong Jiang", "url": "http://arxiv.org/abs/2507.05653v2", "summary": "Serverless platforms such as Kubernetes are increasingly adopted in\nhigh-performance computing, yet autoscaling remains challenging under highly\ndynamic and heterogeneous workloads. Existing approaches often rely on uniform\nreactive policies or unconditioned predictive models, ignoring both workload\nsemantics and prediction uncertainty. We present AAPA, an archetype-aware\npredictive autoscaler that classifies workloads into four behavioral\npatterns--SPIKE, PERIODIC, RAMP, and STATIONARY--and applies tailored scaling\nstrategies with confidence-based adjustments. To support reproducible\nevaluation, we release AAPAset, a weakly labeled dataset of 300\\,000 Azure\nFunctions workload windows spanning diverse patterns. AAPA reduces SLO\nviolations by up to 50\\% and lowers latency by 40\\% compared to Kubernetes HPA,\nalbeit at 2--8~$\\times$ higher resource usage under spike-dominated conditions.\nTo assess trade-offs, we propose the Resource Efficiency Index (REI), a unified\nmetric balancing performance, cost, and scaling smoothness. Our results\ndemonstrate the importance of modeling workload heterogeneity and uncertainty\nin autoscaling design.", "comment": "6 pages, 4 figures, 1 table. First three authors contributed equally.\n  Correspondence to Hailong Jiang", "pdf_url": "http://arxiv.org/pdf/2507.05653v2", "cate": "cs.DC", "date": "2025-07-08", "updated": "2025-07-15"}
{"id": "2405.14374", "title": "State-Constrained Offline Reinforcement Learning", "authors": ["Charles A. Hepburn", "Yue Jin", "Giovanni Montana"], "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.14374v2", "summary": "Traditional offline reinforcement learning (RL) methods predominantly operate\nin a batch-constrained setting. This confines the algorithms to a specific\nstate-action distribution present in the dataset, reducing the effects of\ndistributional shift but restricting the policy to seen actions. In this paper,\nwe alleviate this limitation by introducing state-constrained offline RL, a\nnovel framework that focuses solely on the dataset's state distribution. This\napproach allows the policy to take high-quality out-of-distribution actions\nthat lead to in-distribution states, significantly enhancing learning\npotential. The proposed setting not only broadens the learning horizon but also\nimproves the ability to combine different trajectories from the dataset\neffectively, a desirable property inherent in offline RL. Our research is\nunderpinned by theoretical findings that pave the way for subsequent\nadvancements in this area. Additionally, we introduce StaCQ, a deep learning\nalgorithm that achieves state-of-the-art performance on the D4RL benchmark\ndatasets and aligns with our theoretical propositions. StaCQ establishes a\nstrong baseline for forthcoming explorations in this domain.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.14374v2", "cate": "stat.ML", "date": "2024-05-23", "updated": "2025-07-14"}
{"id": "2402.12683", "title": "TorchCP: A Python Library for Conformal Prediction", "authors": ["Jianguo Huang", "Jianqing Song", "Xuanning Zhou", "Bingyi Jing", "Hongxin Wei"], "categories": ["cs.LG", "cs.CV", "math.ST", "stat.TH"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.12683v3", "summary": "Conformal prediction (CP) is a robust statistical framework that generates\nprediction intervals or sets with guaranteed coverage probability, addressing\nthe challenge of quantifying predictive uncertainty in deep learning. Despite\nadvancements in deep learning architectures and datasets, reliable uncertainty\nestimation remains elusive, making CP increasingly vital. This paper introduces\nTorchCP, a PyTorch-native library designed to integrate state-of-the-art CP\nalgorithms into deep learning tasks, including classification, regression,\ngraph neural networks, and large language models. TorchCP offers a\ncomprehensive suite of advanced methodologies, a modular design for easy\ncustomization, and full GPU-accelerated scalability. Released under the\nLGPL-3.0 license, TorchCP has gained widespread adoption with over 12,582 PyPi\ndownloads. It is supported by approximately 16,132 lines of code, 564 unit\ntests achieving 100\\% coverage, and comprehensive documentation. By bridging\nstatistics and computer science, TorchCP empowers researchers and practitioners\nto advance conformal prediction in diverse deep learning applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.12683v3", "cate": "cs.LG", "date": "2024-02-20", "updated": "2025-07-15"}
{"id": "2504.12667", "title": "Fully Unified Motion Planning for End-to-End Autonomous Driving", "authors": ["Lin Liu", "Caiyan Jia", "Ziying Song", "Hongyu Pan", "Bencheng Liao", "Wenchao Sun", "Yongchang Zhang", "Lei Yang", "Yandan Luo"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.12667v2", "summary": "Current end-to-end autonomous driving methods typically learn only from\nexpert planning data collected from a single ego vehicle, severely limiting the\ndiversity of learnable driving policies and scenarios. However, a critical yet\noverlooked fact is that in any driving scenario, multiple high-quality\ntrajectories from other vehicles coexist with a specific ego vehicle's\ntrajectory. Existing methods fail to fully exploit this valuable resource,\nmissing important opportunities to improve the models' performance (including\nlong-tail scenarios) through learning from other experts. Intuitively, Jointly\nlearning from both ego and other vehicles' expert data is beneficial for\nplanning tasks. However, this joint learning faces two critical challenges. (1)\nDifferent scene observation perspectives across vehicles hinder inter-vehicle\nalignment of scene feature representations; (2) The absence of partial modality\nin other vehicles' data (e.g., vehicle states) compared to ego-vehicle data\nintroduces learning bias. To address these challenges, we propose FUMP (Fully\nUnified Motion Planning), a novel two-stage trajectory generation framework.\nBuilding upon probabilistic decomposition, we model the planning task as a\nspecialized subtask of motion prediction. Specifically, our approach decouples\ntrajectory planning into two stages. In Stage 1, a shared decoder jointly\ngenerates initial trajectories for both tasks. In Stage 2, the model performs\nplanning-specific refinement conditioned on an ego-vehicle's state. The\ntransition between the two stages is bridged by a state predictor trained\nexclusively on ego-vehicle data. To address the cross-vehicle discrepancy in\nobservational perspectives, we propose an Equivariant Context-Sharing Adapter\n(ECSA) before Stage 1 for improving cross-vehicle generalization of scene\nrepresentations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.12667v2", "cate": "cs.CV", "date": "2025-04-17", "updated": "2025-07-15"}
{"id": "2505.05464", "title": "Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging", "authors": ["Shiqi Chen", "Jinghan Zhang", "Tongyao Zhu", "Wei Liu", "Siyang Gao", "Miao Xiong", "Manling Li", "Junxian He"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ICML 2025. Camera-ready version updated. Our code is publicly available at this https URL", "url": "http://arxiv.org/abs/2505.05464v2", "summary": "Vision-Language Models (VLMs) combine visual perception with the general\ncapabilities, such as reasoning, of Large Language Models (LLMs). However, the\nmechanisms by which these two abilities can be combined and contribute remain\npoorly understood. In this work, we explore to compose perception and reasoning\nthrough model merging that connects parameters of different models. Unlike\nprevious works that often focus on merging models of the same kind, we propose\nmerging models across modalities, enabling the incorporation of the reasoning\ncapabilities of LLMs into VLMs. Through extensive experiments, we demonstrate\nthat model merging offers a successful pathway to transfer reasoning abilities\nfrom LLMs to VLMs in a training-free manner. Moreover, we utilize the merged\nmodels to understand the internal mechanism of perception and reasoning and how\nmerging affects it. We find that perception capabilities are predominantly\nencoded in the early layers of the model, whereas reasoning is largely\nfacilitated by the middle-to-late layers. After merging, we observe that all\nlayers begin to contribute to reasoning, whereas the distribution of perception\nabilities across layers remains largely unchanged. These observations shed\nlight on the potential of model merging as a tool for multimodal integration\nand interpretation.", "comment": "ICML 2025. Camera-ready version updated. Our code is publicly\n  available at https://github.com/shiqichen17/VLM_Merging", "pdf_url": "http://arxiv.org/pdf/2505.05464v2", "cate": "cs.CL", "date": "2025-05-08", "updated": "2025-07-15"}
{"id": "2506.23550", "title": "Seeding neural network quantum states with tensor network states", "authors": ["Ryui Kaneko", "Shimpei Goto"], "categories": ["cond-mat.str-el", "cs.LG", "cs.NA", "math.NA", "quant-ph"], "primary_category": "Subjects:       Strongly Correlated Electrons (cond-mat.str-el)", "pdf_link": null, "comments": "Comments:      14 pages, 15 figures", "url": "http://arxiv.org/abs/2506.23550v2", "summary": "We find an efficient approach to approximately convert matrix product states\n(MPSs) into restricted Boltzmann machine wave functions consisting of a\nmultinomial hidden unit through a canonical polyadic (CP) decomposition of the\nMPSs. This method allows us to generate well-behaved initial neural network\nquantum states for quantum many-body ground-state calculations in polynomial\ntime of the number of variational parameters and systematically shorten the\ndistance between the initial states and the ground states with increasing the\nrank of the CP decomposition. We demonstrate the efficiency of our method by\ntaking the transverse-field Ising model as an example and discuss possible\napplications of our method to more general quantum many-body systems in which\nthe ground-state wave functions possess complex nodal structures.", "comment": "14 pages, 15 figures", "pdf_url": "http://arxiv.org/pdf/2506.23550v2", "cate": "cond-mat.str-el", "date": "2025-06-30", "updated": "2025-07-15"}
{"id": "2507.06608", "title": "Proactive Intra-GPU Disaggregation of Prefill and Decode in LLM Serving", "authors": ["Xiaoxiang Shi", "Colin Cai", "Junjia Du"], "categories": ["cs.DC", "cs.LG"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06608v3", "summary": "Monolithic serving with chunked prefill improves GPU utilization by batching\nprefill and decode together, but suffers from fine-grained phase interference.\nEngine-level prefill-decode (PD) disaggregation avoids interference but incurs\nhigher hardware and coordination overhead. Prior intra-GPU disaggregation\napproaches multiplex prefill and decode within a single GPU, using SLO-based\ntuning guided by heuristics from offline profiling or reactive feedback loops.\nHowever, these methods respond reactively to performance issues rather than\nanticipating them, limiting adaptability under dynamic workloads.\n  We ask: can we achieve proactive intra-GPU disaggregation that adapts\neffectively to dynamic workloads? The key challenge lies in managing the\nconflicting resource demands of prefill and decode under varying conditions. We\nfirst show that GPU resources exhibit diminishing returns -- beyond a\nsaturation point, more allocation yields minimal latency benefit. Second, we\nobserve that memory bandwidth contention becomes a critical bottleneck. These\ninsights motivate a design that dynamically partitions GPU resources across\nprefill and decode phases, while jointly considering compute capacity, memory\nfootprint, and bandwidth contention.\n  Evaluated on diverse LLMs and workloads, our system Nexus achieves up to 2.2x\nhigher throughput, 20x lower TTFT, and 2.5x lower TBT than vLLM; outperforms\nSGLang by up to 2x; and matches or exceeds disaggregated vLLM.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06608v3", "cate": "cs.DC", "date": "2025-07-09", "updated": "2025-07-15"}
{"id": "2408.09189", "title": "SA-GDA: Spectral Augmentation for Graph Domain Adaptation", "authors": ["Jinhui Pang", "Zixuan Wang", "Jiliang Tang", "Mingyan Xiao", "Nan Yin"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.09189v2", "summary": "Graph neural networks (GNNs) have achieved impressive impressions for\ngraph-related tasks. However, most GNNs are primarily studied under the cases\nof signal domain with supervised training, which requires abundant\ntask-specific labels and is difficult to transfer to other domains. There are\nfew works focused on domain adaptation for graph node classification. They\nmainly focused on aligning the feature space of the source and target domains,\nwithout considering the feature alignment between different categories, which\nmay lead to confusion of classification in the target domain. However, due to\nthe scarcity of labels of the target domain, we cannot directly perform\neffective alignment of categories from different domains, which makes the\nproblem more challenging. In this paper, we present the \\textit{Spectral\nAugmentation for Graph Domain Adaptation (\\method{})} for graph node\nclassification. First, we observe that nodes with the same category in\ndifferent domains exhibit similar characteristics in the spectral domain, while\ndifferent classes are quite different. Following the observation, we align the\ncategory feature space of different domains in the spectral domain instead of\naligning the whole features space, and we theoretical proof the stability of\nproposed \\method{}. Then, we develop a dual graph convolutional network to\njointly exploits local and global consistency for feature aggregation. Last, we\nutilize a domain classifier with an adversarial learning submodule to\nfacilitate knowledge transfer between different domain graphs. Experimental\nresults on a variety of publicly available datasets reveal the effectiveness of\nour \\method{}.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.09189v2", "cate": "cs.LG", "date": "2024-08-17", "updated": "2025-07-15"}
{"id": "2403.07095", "title": "Gaussian Loss Smoothing Enables Certified Training with Tight Convex Relaxations", "authors": ["Stefan Balauca", "Mark Niklas Müller", "Yuhao Mao", "Maximilian Baader", "Marc Fischer", "Martin Vechev"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted for publication in TMLR 07/2025", "url": "http://arxiv.org/abs/2403.07095v4", "summary": "Training neural networks with high certified accuracy against adversarial\nexamples remains an open challenge despite significant efforts. While\ncertification methods can effectively leverage tight convex relaxations for\nbound computation, in training, these methods, perhaps surprisingly, can\nperform worse than looser relaxations. Prior work hypothesized that this\nphenomenon is caused by the discontinuity, non-smoothness, and perturbation\nsensitivity of the loss surface induced by tighter relaxations. In this work,\nwe theoretically show that applying Gaussian Loss Smoothing (GLS) on the loss\nsurface can alleviate these issues. We confirm this empirically by\ninstantiating GLS with two variants: a zeroth-order optimization algorithm,\ncalled PGPE, which allows training with non-differentiable relaxations, and a\nfirst-order optimization algorithm, called RGS, which requires gradients of the\nrelaxation but is much more efficient than PGPE. Extensive experiments show\nthat when combined with tight relaxations, these methods surpass\nstate-of-the-art methods when training on the same network architecture for\nmany settings. Our results clearly demonstrate the promise of Gaussian Loss\nSmoothing for training certifiably robust neural networks and pave a path\ntowards leveraging tighter relaxations for certified training.", "comment": "Accepted for publication in TMLR 07/2025", "pdf_url": "http://arxiv.org/pdf/2403.07095v4", "cate": "cs.LG", "date": "2024-03-11", "updated": "2025-07-15"}
{"id": "2504.12753", "title": "Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation", "authors": ["Siyu Chen", "Ting Han", "Changshe Zhang", "Xin Luo", "Meiliu Wu", "Guorong Cai", "Jinhe Su"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2504.12753v3", "summary": "Vision Foundation Models (VFMs) have delivered remarkable performance in\nDomain Generalized Semantic Segmentation (DGSS). However, recent methods often\noverlook the fact that visual cues are susceptible, whereas the underlying\ngeometry remains stable, rendering depth information more robust. In this\npaper, we investigate the potential of integrating depth information with\nfeatures from VFMs, to improve the geometric consistency within an image and\nboost the generalization performance of VFMs. We propose a novel fine-tuning\nDGSS framework, named DepthForge, which integrates the visual cues from frozen\nDINOv2 or EVA02 and depth cues from frozen Depth Anything V2. In each layer of\nthe VFMs, we incorporate depth-aware learnable tokens to continuously decouple\ndomain-invariant visual and spatial information, thereby enhancing depth\nawareness and attention of the VFMs. Finally, we develop a depth refinement\ndecoder and integrate it into the model architecture to adaptively refine\nmulti-layer VFM features and depth-aware learnable tokens. Extensive\nexperiments are conducted based on various DGSS settings and five different\ndatsets as unseen target domains. The qualitative and quantitative results\ndemonstrate that our method significantly outperforms alternative approaches\nwith stronger performance, steadier visual-spatial attention, and superior\ngeneralization ability. In particular, DepthForge exhibits outstanding\nperformance under extreme conditions (e.g., night and snow). Code is available\nat https://github.com/anonymouse-xzrptkvyqc/DepthForge.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2504.12753v3", "cate": "cs.CV", "date": "2025-04-17", "updated": "2025-07-15"}
{"id": "2505.06110", "title": "Multimodal Sentiment Analysis on CMU-MOSEI Dataset using Transformer-based Models", "authors": ["Jugal Gajjar", "Kaustik Ranaware"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      6 pages, 2 figures", "url": "http://arxiv.org/abs/2505.06110v2", "summary": "This project performs multimodal sentiment analysis using the CMU-MOSEI\ndataset, using transformer-based models with early fusion to integrate text,\naudio, and visual modalities. We employ BERT-based encoders for each modality,\nextracting embeddings that are concatenated before classification. The model\nachieves strong performance, with 97.87% 7-class accuracy and a 0.9682 F1-score\non the test set, demonstrating the effectiveness of early fusion in capturing\ncross-modal interactions. The training utilized Adam optimization (lr=1e-4),\ndropout (0.3), and early stopping to ensure generalization and robustness.\nResults highlight the superiority of transformer architectures in modeling\nmultimodal sentiment, with a low MAE (0.1060) indicating precise sentiment\nintensity prediction. Future work may compare fusion strategies or enhance\ninterpretability. This approach utilizes multimodal learning by effectively\ncombining linguistic, acoustic, and visual cues for sentiment analysis.", "comment": "6 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2505.06110v2", "cate": "cs.CL", "date": "2025-05-09", "updated": "2025-07-15"}
{"id": "2507.10430", "title": "Efficient Federated Learning with Heterogeneous Data and Adaptive Dropout", "authors": ["Ji Liu", "Beichen Ma", "Qiaolin Yu", "Ruoming Jin", "Jingbo Zhou", "Yang Zhou", "Huaiyu Dai", "Haixun Wang", "Dejing Dou", "Patrick Valduriez"], "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      29 pages, to appear in ACM Transactions on Knowledge Discovery from Data (TKDD)", "url": "http://arxiv.org/abs/2507.10430v2", "summary": "Federated Learning (FL) is a promising distributed machine learning approach\nthat enables collaborative training of a global model using multiple edge\ndevices. The data distributed among the edge devices is highly heterogeneous.\nThus, FL faces the challenge of data distribution and heterogeneity, where\nnon-Independent and Identically Distributed (non-IID) data across edge devices\nmay yield in significant accuracy drop. Furthermore, the limited computation\nand communication capabilities of edge devices increase the likelihood of\nstragglers, thus leading to slow model convergence. In this paper, we propose\nthe FedDHAD FL framework, which comes with two novel methods: Dynamic\nHeterogeneous model aggregation (FedDH) and Adaptive Dropout (FedAD). FedDH\ndynamically adjusts the weights of each local model within the model\naggregation process based on the non-IID degree of heterogeneous data to deal\nwith the statistical data heterogeneity. FedAD performs neuron-adaptive\noperations in response to heterogeneous devices to improve accuracy while\nachieving superb efficiency. The combination of these two methods makes FedDHAD\nsignificantly outperform state-of-the-art solutions in terms of accuracy (up to\n6.7% higher), efficiency (up to 2.02 times faster), and computation cost (up to\n15.0% smaller).", "comment": "29 pages, to appear in ACM Transactions on Knowledge Discovery from\n  Data (TKDD)", "pdf_url": "http://arxiv.org/pdf/2507.10430v2", "cate": "cs.DC", "date": "2025-07-14", "updated": "2025-07-15"}
{"id": "2410.08979", "title": "Overcoming Slow Decision Frequencies in Continuous Control: Model-Based Sequence Reinforcement Learning for Model-Free Control", "authors": ["Devdhar Patel", "Hava Siegelmann"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      30 pages, 14 figures, 7 tables. Presented at the Thirteenth International Conference on Learning Representations (ICLR 2025), Singapore, April 24-28, 2025", "url": "http://arxiv.org/abs/2410.08979v4", "summary": "Reinforcement learning (RL) is rapidly reaching and surpassing human-level\ncontrol capabilities. However, state-of-the-art RL algorithms often require\ntimesteps and reaction times significantly faster than human capabilities,\nwhich is impractical in real-world settings and typically necessitates\nspecialized hardware. We introduce Sequence Reinforcement Learning (SRL), an RL\nalgorithm designed to produce a sequence of actions for a given input state,\nenabling effective control at lower decision frequencies. SRL addresses the\nchallenges of learning action sequences by employing both a model and an\nactor-critic architecture operating at different temporal scales. We propose a\n\"temporal recall\" mechanism, where the critic uses the model to estimate\nintermediate states between primitive actions, providing a learning signal for\neach individual action within the sequence. Once training is complete, the\nactor can generate action sequences independently of the model, achieving\nmodel-free control at a slower frequency. We evaluate SRL on a suite of\ncontinuous control tasks, demonstrating that it achieves performance comparable\nto state-of-the-art algorithms while significantly reducing actor sample\ncomplexity. To better assess performance across varying decision frequencies,\nwe introduce the Frequency-Averaged Score (FAS) metric. Our results show that\nSRL significantly outperforms traditional RL algorithms in terms of FAS, making\nit particularly suitable for applications requiring variable decision\nfrequencies. Furthermore, we compare SRL with model-based online planning,\nshowing that SRL achieves comparable FAS while leveraging the same model during\ntraining that online planners use for planning.", "comment": "30 pages, 14 figures, 7 tables. Presented at the Thirteenth\n  International Conference on Learning Representations (ICLR 2025), Singapore,\n  April 24-28, 2025", "pdf_url": "http://arxiv.org/pdf/2410.08979v4", "cate": "cs.LG", "date": "2024-10-11", "updated": "2025-07-15"}
{"id": "2405.02700", "title": "Unveiling Differences in Generative Models: A Scalable Differential Clustering Approach", "authors": ["Jingwei Zhang", "Mohammad Jalali", "Cheuk Ting Li", "Farzan Farnia"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.02700v3", "summary": "A fine-grained comparison of generative models requires the identification of\nsample types generated differently by each of the involved models. While\nquantitative scores have been proposed in the literature to rank different\ngenerative models, score-based evaluation and ranking do not reveal the nuanced\ndifferences between the generative models in producing different sample types.\nIn this work, we propose solving a differential clustering problem to detect\nsample types generated differently by two generative models. To solve the\ndifferential clustering problem, we develop a spectral method called\nFourier-based Identification of Novel Clusters (FINC) to identify modes\nproduced by a generative model with a higher frequency in comparison to a\nreference distribution. FINC provides a scalable algorithm based on random\nFourier features to estimate the eigenspace of kernel covariance matrices of\ntwo generative models and utilize the principal eigendirections to detect the\nsample types present more dominantly in each model. We demonstrate the\napplication of the FINC method to large-scale computer vision datasets and\ngenerative modeling frameworks. Our numerical results suggest the scalability\nof the developed Fourier-based method in highlighting the sample types produced\nwith different frequencies by generative models. The project code is available\nat https://github.com/buyeah1109/FINC.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.02700v3", "cate": "cs.LG", "date": "2024-05-04", "updated": "2025-07-15"}
{"id": "2504.18397", "title": "Unsupervised Visual Chain-of-Thought Reasoning via Preference Optimization", "authors": ["Kesen Zhao", "Beier Zhu", "Qianru Sun", "Hanwang Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.18397v2", "summary": "Chain-of-thought (CoT) reasoning greatly improves the interpretability and\nproblem-solving abilities of multimodal large language models (MLLMs). However,\nexisting approaches are focused on text CoT, limiting their ability to leverage\nvisual cues. Visual CoT remains underexplored, and the only work is based on\nsupervised fine-tuning (SFT) that relies on extensive labeled bounding-box data\nand is hard to generalize to unseen cases. In this paper, we introduce\nUnsupervised Visual CoT (UV-CoT), a novel framework for image-level CoT\nreasoning via preference optimization. UV-CoT performs preference comparisons\nbetween model-generated bounding boxes (one is preferred and the other is\ndis-preferred), eliminating the need for bounding-box annotations. We get such\npreference data by introducing an automatic data generation pipeline. Given an\nimage, our target MLLM (e.g., LLaVA-1.5-7B) generates seed bounding boxes using\na template prompt and then answers the question using each bounded region as\ninput. An evaluator MLLM (e.g., OmniLLM-12B) ranks the responses, and these\nrankings serve as supervision to train the target MLLM with UV-CoT by\nminimizing negative log-likelihood losses. By emulating human\nperception--identifying key regions and reasoning based on them--UV-CoT can\nimprove visual comprehension, particularly in spatial reasoning tasks where\ntextual descriptions alone fall short. Our experiments on six datasets\ndemonstrate the superiority of UV-CoT, compared to the state-of-the-art textual\nand visual CoT methods. Our zero-shot testing on four unseen datasets shows the\nstrong generalization of UV-CoT. The code is available in\nhttps://github.com/kesenzhao/UV-CoT.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.18397v2", "cate": "cs.CV", "date": "2025-04-25", "updated": "2025-07-15"}
{"id": "2505.08054", "title": "FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning", "authors": ["Zhehao Zhang", "Weijie Xu", "Fanyou Wu", "Chandan K. Reddy"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at COLM 2025", "url": "http://arxiv.org/abs/2505.08054v2", "summary": "Safety alignment approaches in large language models (LLMs) often lead to the\nover-refusal of benign queries, significantly diminishing their utility in\nsensitive scenarios. To address this challenge, we introduce FalseReject, a\ncomprehensive resource containing 16k seemingly toxic queries accompanied by\nstructured responses across 44 safety-related categories. We propose a\ngraph-informed adversarial multi-agent interaction framework to generate\ndiverse and complex prompts, while structuring responses with explicit\nreasoning to aid models in accurately distinguishing safe from unsafe contexts.\nFalseReject includes training datasets tailored for both standard\ninstruction-tuned models and reasoning-oriented models, as well as a\nhuman-annotated benchmark test set. Our extensive benchmarking on 29\nstate-of-the-art (SOTA) LLMs reveals persistent over-refusal challenges.\nEmpirical results demonstrate that supervised finetuning with FalseReject\nsubstantially reduces unnecessary refusals without compromising overall safety\nor general language capabilities.", "comment": "Accepted at COLM 2025", "pdf_url": "http://arxiv.org/pdf/2505.08054v2", "cate": "cs.CL", "date": "2025-05-12", "updated": "2025-07-15"}
{"id": "2503.01787", "title": "Bridging Paradigms: Designing for HPC-Quantum Convergence", "authors": ["Amir Shehata", "Peter Groszkowski", "Thomas Naughton", "Murali Gopalakrishnan Meena", "Elaine Wong", "Daniel Claudino", "Rafael Ferreira da Silvaa", "Thomas Beck"], "categories": ["quant-ph", "cs.DC"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      14 pages, 14 figures", "url": "http://arxiv.org/abs/2503.01787v2", "summary": "This paper presents a comprehensive software stack architecture for\nintegrating quantum computing (QC) capabilities with High-Performance Computing\n(HPC) environments. While quantum computers show promise as specialized\naccelerators for scientific computing, their effective integration with\nclassical HPC systems presents significant technical challenges. We propose a\nhardware-agnostic software framework that supports both current noisy\nintermediate-scale quantum devices and future fault-tolerant quantum computers,\nwhile maintaining compatibility with existing HPC workflows. The architecture\nincludes a quantum gateway interface, standardized APIs for resource\nmanagement, and robust scheduling mechanisms to handle both simultaneous and\ninterleaved quantum-classical workloads. Key innovations include: (1) a unified\nresource management system that efficiently coordinates quantum and classical\nresources, (2) a flexible quantum programming interface that abstracts\nhardware-specific details, (3) A Quantum Platform Manager API that simplifies\nthe integration of various quantum hardware systems, and (4) a comprehensive\ntool chain for quantum circuit optimization and execution. We demonstrate our\narchitecture through implementation of quantum-classical algorithms, including\nthe variational quantum linear solver, showcasing the framework's ability to\nhandle complex hybrid workflows while maximizing resource utilization. This\nwork provides a foundational blueprint for integrating QC capabilities into\nexisting HPC infrastructures, addressing critical challenges in resource\nmanagement, job scheduling, and efficient data movement between classical and\nquantum resources.", "comment": "14 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2503.01787v2", "cate": "quant-ph", "date": "2025-03-03", "updated": "2025-07-15"}
{"id": "2410.17787", "title": "Large Language Models Engineer Too Many Simple Features For Tabular Data", "authors": ["Jaris Küken", "Lennart Purucker", "Frank Hutter"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at the 3rd Table Representation Learning Workshop @ NeurIPS 2024", "url": "http://arxiv.org/abs/2410.17787v2", "summary": "Tabular machine learning problems often require time-consuming and\nlabor-intensive feature engineering. Recent efforts have focused on using large\nlanguage models (LLMs) to capitalize on their potential domain knowledge. At\nthe same time, researchers have observed ethically concerning negative biases\nin other LLM-related use cases, such as text generation. These developments\nmotivated us to investigate whether LLMs exhibit a bias that negatively impacts\nthe performance of feature engineering. While not ethically concerning, such a\nbias could hinder practitioners from fully utilizing LLMs for automated data\nscience. Therefore, we propose a method to detect potential biases by detecting\nanomalies in the frequency of operators (e.g., adding two features) suggested\nby LLMs when engineering new features. Our experiments evaluate the bias of\nfour LLMs, two big frontier and two small open-source models, across 27 tabular\ndatasets. Our results indicate that LLMs are biased toward simple operators,\nsuch as addition, and can fail to utilize more complex operators, such as\ngrouping followed by aggregations. Furthermore, the bias can negatively impact\nthe predictive performance when using LLM-generated features. Our results call\nfor mitigating bias when using LLMs for feature engineering.", "comment": "Accepted at the 3rd Table Representation Learning Workshop @ NeurIPS\n  2024", "pdf_url": "http://arxiv.org/pdf/2410.17787v2", "cate": "cs.LG", "date": "2024-10-23", "updated": "2025-07-15"}
{"id": "2406.05287", "title": "Group-wise oracle-efficient algorithms for online multi-group learning", "authors": ["Samuel Deng", "Daniel Hsu", "Jingwen Liu"], "categories": ["cs.LG", "cs.GT", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Updated after NeurIPS 2024 camera-ready", "url": "http://arxiv.org/abs/2406.05287v2", "summary": "We study the problem of online multi-group learning, a learning model in\nwhich an online learner must simultaneously achieve small prediction regret on\na large collection of (possibly overlapping) subsequences corresponding to a\nfamily of groups. Groups are subsets of the context space, and in fairness\napplications, they may correspond to subpopulations defined by expressive\nfunctions of demographic attributes. In contrast to previous work on this\nlearning model, we consider scenarios in which the family of groups is too\nlarge to explicitly enumerate, and hence we seek algorithms that only access\ngroups via an optimization oracle. In this paper, we design such\noracle-efficient algorithms with sublinear regret under a variety of settings,\nincluding: (i) the i.i.d. setting, (ii) the adversarial setting with smoothed\ncontext distributions, and (iii) the adversarial transductive setting.", "comment": "Updated after NeurIPS 2024 camera-ready", "pdf_url": "http://arxiv.org/pdf/2406.05287v2", "cate": "cs.LG", "date": "2024-06-07", "updated": "2025-07-14"}
{"id": "2504.21356", "title": "Nexus-Gen: Unified Image Understanding, Generation, and Editing via Prefilled Autoregression in Shared Embedding Space", "authors": ["Hong Zhang", "Zhongjie Duan", "Xingjun Wang", "Yuze Zhao", "Weiyi Lu", "Zhipeng Di", "Yixuan Xu", "Yingda Chen", "Yu Zhang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.21356v3", "summary": "Unified multimodal generative models aim to integrate image understanding and\ngeneration abilities, offering significant advantages in harnessing multimodal\ncorpora, particularly interleaved text-image data. However, existing unified\nmodels exhibit limitations in image synthesis quality, autoregressive error\naccumulation, and image editing capability. In this work, we propose Nexus-Gen,\na novel architecture that unifies image understanding, generation, and editing\ntasks in a shared image embedding space. This shared space serves as a bridge\nfor the autoregressive and diffusion models, which seamlessly integrates their\ncomplementary strengths in cross-modal modeling. To mitigate the severe error\naccumulation during autoregressive embedding prediction, we propose a novel\nprefilled autoregression strategy that aligns training-inference dynamics by\nprefilling input sequences with learnable embeddings. After multi-stage and\nmulti-task training on our constructed large-scale dataset with 26.3 million\nsamples, Nexus-Gen achieves state-of-the-art performance on the evaluation\nbenchmarks spanning image understanding, generation and editing tasks. All\nmodels, datasets, and source codes are released in\nhttps://github.com/modelscope/Nexus-Gen to facilitate further advancements\nacross the field.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.21356v3", "cate": "cs.CV", "date": "2025-04-30", "updated": "2025-07-15"}
{"id": "2505.11441", "title": "Is Compression Really Linear with Code Intelligence?", "authors": ["Shijie Xuyang", "Xianzhen Luo", "Tianhao Cheng", "Zheng Chu", "Houyi Li", "ziqi wang", "Siming Huang", "Qingfu Zhu", "Qiufeng Wang", "Xiangyu Zhang", "Shuigeng Zhou", "Wanxiang Che"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      work in progress", "url": "http://arxiv.org/abs/2505.11441v4", "summary": "Understanding the relationship between data compression and the capabilities\nof Large Language Models (LLMs) is crucial, especially in specialized domains\nlike code intelligence. Prior work posited a linear relationship between\ncompression and general intelligence. However, it overlooked the multifaceted\nnature of code that encompasses diverse programming languages and tasks, and\nstruggled with fair evaluation of modern Code LLMs. We address this by\nevaluating a diverse array of open-source Code LLMs on comprehensive\nmulti-language, multi-task code benchmarks. To address the challenge of\nefficient and fair evaluation of pre-trained LLMs' code intelligence, we\nintroduce \\textit{Format Annealing}, a lightweight, transparent training\nmethodology designed to assess the intrinsic capabilities of these pre-trained\nmodels equitably. Compression efficacy, measured as bits-per-character (BPC),\nis determined using a novel, large-scale, and previously unseen code validation\nset derived from GitHub. Our empirical results reveal a fundamental logarithmic\nrelationship between measured code intelligence and BPC. This finding refines\nprior hypotheses of linearity, which we suggest are likely observations of the\nlogarithmic curve's tail under specific, limited conditions. Our work provides\na more nuanced understanding of compression's role in developing code\nintelligence and contributes a robust evaluation framework in the code domain.", "comment": "work in progress", "pdf_url": "http://arxiv.org/pdf/2505.11441v4", "cate": "cs.CL", "date": "2025-05-16", "updated": "2025-07-15"}
{"id": "2506.18193", "title": "DeInfoReg: A Decoupled Learning Framework for Better Training Throughput", "authors": ["Zih-Hao Huang", "You-Teng Lin", "Hung-Hsuan Chen"], "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.18193v2", "summary": "This paper introduces Decoupled Supervised Learning with Information\nRegularization (DeInfoReg), a novel approach that transforms a long gradient\nflow into multiple shorter ones, thereby mitigating the vanishing gradient\nproblem. Integrating a pipeline strategy, DeInfoReg enables model\nparallelization across multiple GPUs, significantly improving training\nthroughput. We compare our proposed method with standard backpropagation and\nother gradient flow decomposition techniques. Extensive experiments on diverse\ntasks and datasets demonstrate that DeInfoReg achieves superior performance and\nbetter noise resistance than traditional BP models and efficiently utilizes\nparallel computing resources. The code for reproducibility is available at:\nhttps://github.com/ianzih/Decoupled-Supervised-Learning-for-Information-Regularization/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.18193v2", "cate": "cs.LG", "date": "2025-06-22", "updated": "2025-07-15"}
{"id": "2411.04371", "title": "ComFairGNN: Community Fair Graph Neural Network", "authors": ["Yonas Sium", "Qi Li"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      PAKDD 2025", "url": "http://arxiv.org/abs/2411.04371v3", "summary": "Graph Neural Networks (GNNs) have become the leading approach for addressing\ngraph analytical problems in various real-world scenarios. However, GNNs may\nproduce biased predictions against certain demographic subgroups due to node\nattributes and neighbors surrounding a node. Most current research on GNN\nfairness focuses predominantly on debiasing GNNs using oversimplified fairness\nevaluation metrics, which can give a misleading impression of fairness.\nUnderstanding the potential evaluation paradoxes due to the complicated nature\nof the graph structure is crucial for developing effective GNN debiasing\nmechanisms. In this paper, we examine the effectiveness of current GNN\ndebiasing methods in terms of unfairness evaluation. Specifically, we introduce\na community-level strategy to measure bias in GNNs and evaluate debiasing\nmethods at this level. Further, We introduce ComFairGNN, a novel framework\ndesigned to mitigate community-level bias in GNNs. Our approach employs a\nlearnable coreset-based debiasing function that addresses bias arising from\ndiverse local neighborhood distributions during GNNs neighborhood aggregation.\nComprehensive evaluations on three benchmark datasets demonstrate our model's\neffectiveness in both accuracy and fairness metrics.", "comment": "PAKDD 2025", "pdf_url": "http://arxiv.org/pdf/2411.04371v3", "cate": "cs.LG", "date": "2024-11-07", "updated": "2025-07-15"}
{"id": "2406.08933", "title": "LaCoOT: Layer Collapse through Optimal Transport", "authors": ["Victor Quétu", "Zhu Liao", "Nour Hezbri", "Fabio Pizzati", "Enzo Tartaglione"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICCV25", "url": "http://arxiv.org/abs/2406.08933v3", "summary": "Although deep neural networks are well-known for their outstanding\nperformance in tackling complex tasks, their hunger for computational resources\nremains a significant hurdle, posing energy-consumption issues and restricting\ntheir deployment on resource-constrained devices, preventing their widespread\nadoption. In this paper, we present an optimal transport-based method to reduce\nthe depth of over-parametrized deep neural networks, alleviating their\ncomputational burden. More specifically, we propose a new regularization\nstrategy based on the Max-Sliced Wasserstein distance to minimize the distance\nbetween the intermediate feature distributions in the neural network. We show\nthat minimizing this distance enables the complete removal of intermediate\nlayers in the network, achieving better performance/depth trade-off compared to\nexisting techniques. We assess the effectiveness of our method on traditional\nimage classification setups and extend it to generative image models. Our code\nis available at https://github.com/VGCQ/LaCoOT.", "comment": "ICCV25", "pdf_url": "http://arxiv.org/pdf/2406.08933v3", "cate": "cs.LG", "date": "2024-06-13", "updated": "2025-07-15"}
{"id": "2505.00744", "title": "Localizing Before Answering: A Hallucination Evaluation Benchmark for Grounded Medical Multimodal LLMs", "authors": ["Dung Nguyen", "Minh Khoi Ho", "Huy Ta", "Thanh Tam Nguyen", "Qi Chen", "Kumar Rav", "Quy Duong Dang", "Satwik Ramchandre", "Son Lam Phung", "Zhibin Liao", "Minh-Son To", "Johan Verjans", "Phi Le Nguyen", "Vu Minh Hieu Phan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at Joint Conference on Artificial Intelligence (IJCAI) 2025", "url": "http://arxiv.org/abs/2505.00744v4", "summary": "Medical Large Multi-modal Models (LMMs) have demonstrated remarkable\ncapabilities in medical data interpretation. However, these models frequently\ngenerate hallucinations contradicting source evidence, particularly due to\ninadequate localization reasoning. This work reveals a critical limitation in\ncurrent medical LMMs: instead of analyzing relevant pathological regions, they\noften rely on linguistic patterns or attend to irrelevant image areas when\nresponding to disease-related queries. To address this, we introduce\nHEAL-MedVQA (Hallucination Evaluation via Localization MedVQA), a comprehensive\nbenchmark designed to evaluate LMMs' localization abilities and hallucination\nrobustness. HEAL-MedVQA features (i) two innovative evaluation protocols to\nassess visual and textual shortcut learning, and (ii) a dataset of 67K VQA\npairs, with doctor-annotated anatomical segmentation masks for pathological\nregions. To improve visual reasoning, we propose the Localize-before-Answer\n(LobA) framework, which trains LMMs to localize target regions of interest and\nself-prompt to emphasize segmented pathological areas, generating grounded and\nreliable answers. Experimental results demonstrate that our approach\nsignificantly outperforms state-of-the-art biomedical LMMs on the challenging\nHEAL-MedVQA benchmark, advancing robustness in medical VQA.", "comment": "Accepted at Joint Conference on Artificial Intelligence (IJCAI) 2025", "pdf_url": "http://arxiv.org/pdf/2505.00744v4", "cate": "cs.CV", "date": "2025-04-30", "updated": "2025-07-15"}
{"id": "2505.15075", "title": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs", "authors": ["Hao Wang", "Pinzhi Huang", "Jihan Yang", "Saining Xie", "Daisuke Kawahara"], "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:       this https URL", "url": "http://arxiv.org/abs/2505.15075v3", "summary": "The rapid evolution of multimodal large language models (MLLMs) has\nsignificantly enhanced their real-world applications. However, achieving\nconsistent performance across languages, especially when integrating cultural\nknowledge, remains a significant challenge. To better assess this issue, we\nintroduce two new benchmarks: KnowRecall and VisRecall, which evaluate\ncross-lingual consistency in MLLMs. KnowRecall is a visual question answering\nbenchmark designed to measure factual knowledge consistency in 15 languages,\nfocusing on cultural and historical questions about global landmarks. VisRecall\nassesses visual memory consistency by asking models to describe landmark\nappearances in 9 languages without access to images. Experimental results\nreveal that state-of-the-art MLLMs, including proprietary ones, still struggle\nto achieve cross-lingual consistency. This underscores the need for more robust\napproaches that produce truly multilingual and culturally aware models.", "comment": "https://github.com/nlp-waseda/traveling-across-languages", "pdf_url": "http://arxiv.org/pdf/2505.15075v3", "cate": "cs.CL", "date": "2025-05-21", "updated": "2025-07-15"}
{"id": "2411.04696", "title": "The Pragmatic Frames of Spurious Correlations in Machine Learning: Interpreting How and Why They Matter", "authors": ["Samuel J. Bell", "Skyler Wang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.04696v4", "summary": "Learning correlations from data forms the foundation of today's machine\nlearning (ML) and artificial intelligence (AI) research. While contemporary\nmethods enable the automatic discovery of complex patterns, they are prone to\nfailure when unintended correlations are captured. This vulnerability has\nspurred a growing interest in interrogating spuriousness, which is often seen\nas a threat to model performance, fairness, and robustness. In this article, we\ntrace departures from the conventional statistical definition of spuriousness\n-- which denotes a non-causal relationship arising from coincidence or\nconfounding -- to examine how its meaning is negotiated in ML research. Rather\nthan relying solely on formal definitions, researchers assess spuriousness\nthrough what we call pragmatic frames: judgments based on what a correlation\ndoes in practice -- how it affects model behavior, supports or impedes task\nperformance, or aligns with broader normative goals. Drawing on a broad survey\nof ML literature, we identify four such frames: relevance (\"Models should use\ncorrelations that are relevant to the task\"), generalizability (\"Models should\nuse correlations that generalize to unseen data\"), human-likeness (\"Models\nshould use correlations that a human would use to perform the same task\"), and\nharmfulness (\"Models should use correlations that are not socially or ethically\nharmful\"). These representations reveal that correlation desirability is not a\nfixed statistical property but a situated judgment informed by technical,\nepistemic, and ethical considerations. By examining how a foundational ML\nconundrum is problematized in research literature, we contribute to broader\nconversations on the contingent practices through which technical concepts like\nspuriousness are defined and operationalized.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.04696v4", "cate": "cs.LG", "date": "2024-11-07", "updated": "2025-07-15"}
{"id": "2410.15416", "title": "Contrast All the Time: Learning Time Series Representation from Temporal Consistency", "authors": ["Abdul-Kazeem Shamba", "Kerstin Bach", "Gavin Taylor"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published in the 28th European Conference on AI (ECAI), October 2025", "url": "http://arxiv.org/abs/2410.15416v2", "summary": "Representation learning for time series using contrastive learning has\nemerged as a critical technique for improving the performance of downstream\ntasks. To advance this effective approach, we introduce CaTT (\\textit{Contrast\nAll The Time}), a new approach to unsupervised contrastive learning for time\nseries, which takes advantage of dynamics between temporally similar moments\nmore efficiently and effectively than existing methods. CaTT departs from\nconventional time-series contrastive approaches that rely on data augmentations\nor selected views. Instead, it uses the full temporal dimension by contrasting\nall time steps in parallel. This is made possible by a scalable NT-pair\nformulation, which extends the classic N-pair loss across both batch and\ntemporal dimensions, making the learning process end-to-end and more efficient.\nCaTT learns directly from the natural structure of temporal data, using\nrepeated or adjacent time steps as implicit supervision, without the need for\npair selection heuristics. We demonstrate that this approach produces superior\nembeddings which allow better performance in downstream tasks. Additionally,\ntraining is faster than other contrastive learning approaches, making it\nsuitable for large-scale and real-world time series applications. The source\ncode is publicly available at\n\\href{https://github.com/sfi-norwai/CaTT}{https://github.com/sfi-norwai/CaTT}.", "comment": "Published in the 28th European Conference on AI (ECAI), October 2025", "pdf_url": "http://arxiv.org/pdf/2410.15416v2", "cate": "cs.LG", "date": "2024-10-20", "updated": "2025-07-15"}
{"id": "2505.23145", "title": "FlowAlign: Trajectory-Regularized, Inversion-Free Flow-based Image Editing", "authors": ["Jeongsol Kim", "Yeobin Hong", "Jonghyun Park", "Jong Chul Ye"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.23145v3", "summary": "Recent inversion-free, flow-based image editing methods such as FlowEdit\nleverages a pre-trained noise-to-image flow model such as Stable Diffusion 3,\nenabling text-driven manipulation by solving an ordinary differential equation\n(ODE). While the lack of exact latent inversion is a core advantage of these\nmethods, it often results in unstable editing trajectories and poor source\nconsistency. To address this limitation, we propose {\\em FlowAlign}, a novel\ninversion-free flow-based framework for consistent image editing with optimal\ncontrol-based trajectory control. Specifically, FlowAlign introduces source\nsimilarity at the terminal point as a regularization term to promote smoother\nand more consistent trajectories during the editing process. Notably, our\nterminal point regularization is shown to explicitly balance semantic alignment\nwith the edit prompt and structural consistency with the source image along the\ntrajectory. Furthermore, FlowAlign naturally supports reverse editing by simply\nreversing the ODE trajectory, highliting the reversible and consistent nature\nof the transformation. Extensive experiments demonstrate that FlowAlign\noutperforms existing methods in both source preservation and editing\ncontrollability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.23145v3", "cate": "cs.CV", "date": "2025-05-29", "updated": "2025-07-14"}
{"id": "2505.17793", "title": "Compression Hacking: A Supplementary Perspective on Informatics Properties of Language Models from Geometric Distortion", "authors": ["Jianxiang Zang", "Meiling Ning", "Yongda Wei", "Shihan Dou", "Jiazheng Zhang", "Nijia Mo", "Binhong Li", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.17793v2", "summary": "Recently, the concept of ``compression as intelligence'' has provided a novel\ninformatics metric perspective for language models (LMs), emphasizing that\nhighly structured representations signify the intelligence level of LMs.\nHowever, from a geometric standpoint, the word representation space of highly\ncompressed LMs tends to degenerate into a highly anisotropic state, which\nhinders the LM's ability to comprehend instructions and directly impacts its\nperformance. We found this compression-anisotropy synchronicity is essentially\nthe ``Compression Hacking'' in LM representations, where noise-dominated\ndirections tend to create the illusion of high compression rates by sacrificing\nspatial uniformity. Based on this, we propose three refined compression metrics\nby incorporating geometric distortion analysis and integrate them into a\nself-evaluation pipeline. The refined metrics exhibit strong alignment with the\nLM's comprehensive capabilities, achieving Spearman correlation coefficients\nabove 0.9, significantly outperforming both the original compression and other\ninternal structure-based metrics. This confirms that compression hacking\nsubstantially enhances the informatics interpretation of LMs by incorporating\ngeometric distortion of representations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.17793v2", "cate": "cs.CL", "date": "2025-05-23", "updated": "2025-07-15"}
{"id": "2411.08706", "title": "Searching Latent Program Spaces", "authors": ["Matthew V Macfarlane", "Clément Bonnet"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Code available at this https URL", "url": "http://arxiv.org/abs/2411.08706v2", "summary": "General intelligence requires systems that acquire new skills efficiently and\ngeneralize beyond their training distributions. Although program synthesis\napproaches have strong generalization power, they face scaling issues due to\nlarge combinatorial spaces that quickly make them impractical and require\nhuman-generated DSLs or pre-trained priors to narrow this search space. On the\nother hand, deep learning methods have had high successes, but they lack\nstructured test-time adaptation and rely on heavy stochastic sampling or\nexpensive gradient updates for fine-tuning. In this work, we propose the Latent\nProgram Network (LPN), a new architecture that builds in test-time search\ndirectly into neural models. LPN learns a latent space of implicit\nprograms--neurally mapping inputs to outputs--through which it can search using\ngradients at test time. LPN combines the adaptability of symbolic approaches\nand the scalability of neural methods. It searches through a compact latent\nspace at test time and bypasses the need for pre-defined domain-specific\nlanguages. On a range of programming-by-examples tasks, LPN either outperforms\nor matches performance compared to in-context learning and test-time training\nmethods. Tested on the ARC-AGI benchmark, we demonstrate that LPN can both\nlearn a compact program space and search through it at test time to adapt to\nnovel tasks. LPN doubles its performance on out-of-distribution tasks when\ntest-time search is switched on.", "comment": "Code available at https://github.com/clement-bonnet/lpn", "pdf_url": "http://arxiv.org/pdf/2411.08706v2", "cate": "cs.LG", "date": "2024-11-13", "updated": "2025-07-15"}
{"id": "2411.12334", "title": "Learning from Label Proportions and Covariate-shifted Instances", "authors": ["Sagalpreet Singh", "Navodita Sharma", "Shreyas Havaldar", "Rishi Saket", "Aravindan Raghuveer"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.12334v2", "summary": "In many applications, especially due to lack of supervision or privacy\nconcerns, the training data is grouped into bags of instances (feature-vectors)\nand for each bag we have only an aggregate label derived from the\ninstance-labels in the bag. In learning from label proportions (LLP) the\naggregate label is the average of the instance-labels in a bag, and a\nsignificant body of work has focused on training models in the LLP setting to\npredict instance-labels. In practice however, the training data may have fully\nsupervised albeit covariate-shifted source data, along with the usual target\ndata with bag-labels, and we wish to train a good instance-level predictor on\nthe target domain. We call this the covariate-shifted hybrid LLP problem. Fully\nsupervised covariate shifted data often has useful training signals and the\ngoal is to leverage them for better predictive performance in the hybrid LLP\nsetting. To achieve this, we develop methods for hybrid LLP which naturally\nincorporate the target bag-labels along with the source instance-labels, in the\ndomain adaptation framework. Apart from proving theoretical guarantees bounding\nthe target generalization error, we also conduct experiments on several\npublicly available datasets showing that our methods outperform LLP and domain\nadaptation baselines as well techniques from previous related work.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.12334v2", "cate": "cs.LG", "date": "2024-11-19", "updated": "2025-07-15"}
{"id": "2505.23367", "title": "PAN-Crafter: Learning Modality-Consistent Alignment for PAN-Sharpening", "authors": ["Jeonghyeok Do", "Sungpyo Kim", "Geunhyuk Youk", "Jaehyup Lee", "Munchurl Kim"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025 (camera-ready version). Please visit our project page this https URL", "url": "http://arxiv.org/abs/2505.23367v2", "summary": "PAN-sharpening aims to fuse high-resolution panchromatic (PAN) images with\nlow-resolution multi-spectral (MS) images to generate high-resolution\nmulti-spectral (HRMS) outputs. However, cross-modality misalignment -- caused\nby sensor placement, acquisition timing, and resolution disparity -- induces a\nfundamental challenge. Conventional deep learning methods assume perfect\npixel-wise alignment and rely on per-pixel reconstruction losses, leading to\nspectral distortion, double edges, and blurring when misalignment is present.\nTo address this, we propose PAN-Crafter, a modality-consistent alignment\nframework that explicitly mitigates the misalignment gap between PAN and MS\nmodalities. At its core, Modality-Adaptive Reconstruction (MARs) enables a\nsingle network to jointly reconstruct HRMS and PAN images, leveraging PAN's\nhigh-frequency details as auxiliary self-supervision. Additionally, we\nintroduce Cross-Modality Alignment-Aware Attention (CM3A), a novel mechanism\nthat bidirectionally aligns MS texture to PAN structure and vice versa,\nenabling adaptive feature refinement across modalities. Extensive experiments\non multiple benchmark datasets demonstrate that our PAN-Crafter outperforms the\nmost recent state-of-the-art method in all metrics, even with 50.11$\\times$\nfaster inference time and 0.63$\\times$ the memory size. Furthermore, it\ndemonstrates strong generalization performance on unseen satellite datasets,\nshowing its robustness across different conditions.", "comment": "ICCV 2025 (camera-ready version). Please visit our project page\n  https://kaist-viclab.github.io/PAN-Crafter_site", "pdf_url": "http://arxiv.org/pdf/2505.23367v2", "cate": "cs.CV", "date": "2025-05-29", "updated": "2025-07-15"}
{"id": "2506.00077", "title": "Gaussian mixture models as a proxy for interacting language models", "authors": ["Edward L. Wang", "Tianyu Wang", "Hayden Helm", "Avanti Athreya", "Vince Lyzinski", "Carey E. Priebe"], "categories": ["cs.CL", "cs.LG", "stat.ML", "62R07"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.00077v3", "summary": "Large language models (LLMs) are a powerful tool with the ability to match\nhuman capabilities and behavior in many settings. Retrieval-augmented\ngeneration (RAG) further allows LLMs to generate diverse output depending on\nthe contents of their RAG database. This motivates their use in the social\nsciences to study human behavior between individuals when large-scale\nexperiments are infeasible. However, LLMs depend on complex, computationally\nexpensive algorithms. In this paper, we introduce interacting Gaussian mixture\nmodels (GMMs) as an alternative to similar frameworks using LLMs. We compare a\nsimplified model of GMMs to select experimental simulations of LLMs whose\nupdating and response depend on feedback from other LLMs. We find that\ninteracting GMMs capture important features of the dynamics in interacting\nLLMs, and we investigate key similarities and differences between interacting\nLLMs and GMMs. We conclude by discussing the benefits of Gaussian mixture\nmodels, potential modifications, and future research directions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.00077v3", "cate": "cs.CL", "date": "2025-05-29", "updated": "2025-07-15"}
{"id": "2501.01507", "title": "Transfer Learning Analysis of Variational Quantum Circuits", "authors": ["Huan-Hsin Tseng", "Hsin-Yi Lin", "Samuel Yen-Chi Chen", "Shinjae Yoo"], "categories": ["quant-ph", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      Published at ICASSP 2025", "url": "http://arxiv.org/abs/2501.01507v3", "summary": "This work analyzes transfer learning of the Variational Quantum Circuit\n(VQC). Our framework begins with a pretrained VQC configured in one domain and\ncalculates the transition of 1-parameter unitary subgroups required for a new\ndomain. A formalism is established to investigate the adaptability and\ncapability of a VQC under the analysis of loss bounds. Our theory observes\nknowledge transfer in VQCs and provides a heuristic interpretation for the\nmechanism. An analytical fine-tuning method is derived to attain the optimal\ntransition for adaptations of similar domains.", "comment": "Published at ICASSP 2025", "pdf_url": "http://arxiv.org/pdf/2501.01507v3", "cate": "quant-ph", "date": "2025-01-02", "updated": "2025-07-14"}
{"id": "2411.19077", "title": "Improving sub-seasonal wind-speed forecasts in Europe with a non-linear model", "authors": ["Ganglin Tian", "Camille Le Coz", "Anastase Alexandre Charantonis", "Alexis Tantet", "Naveen Goutham", "Riwal Plougonven"], "categories": ["cs.LG", "physics.ao-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.19077v2", "summary": "Sub-seasonal wind speed forecasts provide valuable guidance for wind power\nsystem planning and operations, yet the forecast skills of surface winds\ndecrease sharply after two weeks. However, large-scale variables exhibit\ngreater predictability on this time scale. This study explores the potential of\nleveraging non-linear relationships between 500 hPa geopotential height (Z500)\nand surface wind speed to improve sub-seasonal wind speed forecast skills in\nEurope. Our proposed framework uses a Multiple Linear Regression (MLR) or a\nConvolutional Neural Network (CNN) to regress surface wind speed from Z500.\nEvaluations on ERA5 reanalysis indicate that the CNN performs better due to its\nnon-linearity. Applying these models to sub-seasonal forecasts from the\nEuropean Centre for Medium-Range Weather Forecasts, various verification\nmetrics demonstrate the advantages of non-linearity. Yet, this is partly\nexplained by the fact that these statistical models are under-dispersive since\nthey explain only a fraction of the target variable variance. Introducing\nstochastic perturbations to represent the stochasticity of the unexplained part\nfrom the signal helps compensate for this issue. Results show that the\nperturbed CNN performs better than the perturbed MLR only in the first weeks,\nwhile the perturbed MLR's performance converges towards that of the perturbed\nCNN after two weeks. The study finds that introducing stochastic perturbations\ncan address the issue of insufficient spread in these statistical models, with\nimprovements from the non-linearity varying with the lead time of the\nforecasts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.19077v2", "cate": "cs.LG", "date": "2024-11-28", "updated": "2025-07-15"}
{"id": "2506.04526", "title": "EECD-Net: Energy-Efficient Crack Detection with Spiking Neural Networks and Gated Attention", "authors": ["Shuo Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      After further careful review and additional checks, we have identified multiple issues in our experimental results and data analysis that significantly affect the validity and reliability of our findings. We believe that these issues are substantial enough to compromise the scientific integrity of the manuscript", "url": "http://arxiv.org/abs/2506.04526v3", "summary": "Crack detection on road surfaces is a critical measurement technology in the\ninstrumentation domain, essential for ensuring infrastructure safety and\ntransportation reliability. However, due to limited energy and low-resolution\nimaging, smart terminal devices struggle to maintain real-time monitoring\nperformance. To overcome these challenges, this paper proposes a multi-stage\ndetection approach for road crack detection, EECD-Net, to enhance accuracy and\nenergy efficiency of instrumentation. Specifically, the sophisticated\nSuper-Resolution Convolutional Neural Network (SRCNN) is employed to address\nthe inherent challenges of low-quality images, which effectively enhance image\nresolution while preserving critical structural details. Meanwhile, a Spike\nConvolution Unit (SCU) with Continuous Integrate-and-Fire (CIF) neurons is\nproposed to convert these images into sparse pulse sequences, significantly\nreducing power consumption. Additionally, a Gated Attention Transformer (GAT)\nmodule is designed to strategically fuse multi-scale feature representations\nthrough adaptive attention mechanisms, effectively capturing both long-range\ndependencies and intricate local crack patterns, and significantly enhancing\ndetection robustness across varying crack morphologies. The experiments on the\nCrackVision12K benchmark demonstrate that EECD-Net achieves a remarkable 98.6\\%\ndetection accuracy, surpassing state-of-the-art counterparts such as\nHybrid-Segmentor by a significant 1.5\\%. Notably, the EECD-Net maintains\nexceptional energy efficiency, consuming merely 5.6 mJ, which is a substantial\n33\\% reduction compared to baseline implementations. This work pioneers a\ntransformative approach in instrumentation-based crack detection, offering a\nscalable, low-power solution for real-time, large-scale infrastructure\nmonitoring in resource-constrained environments.", "comment": "After further careful review and additional checks, we have\n  identified multiple issues in our experimental results and data analysis that\n  significantly affect the validity and reliability of our findings. We believe\n  that these issues are substantial enough to compromise the scientific\n  integrity of the manuscript", "pdf_url": "http://arxiv.org/pdf/2506.04526v3", "cate": "cs.CV", "date": "2025-06-05", "updated": "2025-07-15"}
{"id": "2506.03106", "title": "Critique-GRPO: Advancing LLM Reasoning with Natural Language and Numerical Feedback", "authors": ["Xiaoying Zhang", "Hao Sun", "Yipeng Zhang", "Kaituo Feng", "Chaochao Lu", "Chao Yang", "Helen Meng"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      49 pages, updated with new experimental results", "url": "http://arxiv.org/abs/2506.03106v3", "summary": "Recent advances in reinforcement learning (RL) with numerical feedback, such\nas scalar rewards, have significantly enhanced the complex reasoning\ncapabilities of large language models (LLMs). Despite this success, we identify\nthree key challenges encountered by RL with solely numerical feedback:\nperformance plateaus, limited effectiveness of self-reflection, and persistent\nfailures. We then demonstrate that RL-finetuned models, even after exhibiting\nperformance plateaus, can generate correct refinements on persistently failed\nproblems by leveraging natural language feedback in the form of critiques.\nBuilding on this insight, we propose Critique-GRPO, an online RL framework that\nintegrates both natural language and numerical feedback for effective policy\noptimization. Critique-GRPO enables LLMs to learn from initial responses and\ncritique-guided self-refinements simultaneously while maintaining exploration.\nAdditionally, we employ a shaping function to amplify learning from correct,\nespecially unfamiliar, refinements and penalize incorrect ones. Extensive\nexperiments with Qwen2.5-7B-Base, Qwen2.5-Math-7B-Base, and Qwen3-8B\ndemonstrate that Critique-GRPO consistently outperforms supervised learning and\nRL-based fine-tuning methods across eight challenging mathematical, STEM, and\ngeneral reasoning tasks, improving average pass@1 scores by approximately 4.4%\nand 3.8% on Qwen2.5-7B-Base and Qwen3-8B, respectively. Notably, Critique-GRPO\nenables effective self-improvement through self-critiquing and weak-to-strong\ngeneralization, achieving consistent gains over GRPO, such as 16.7% and 10.0%\npass@1 improvements on AIME 2024, respectively.", "comment": "49 pages, updated with new experimental results", "pdf_url": "http://arxiv.org/pdf/2506.03106v3", "cate": "cs.CL", "date": "2025-06-03", "updated": "2025-07-15"}
{"id": "2501.12633", "title": "Inverse Reinforcement Learning with Switching Rewards and History Dependency for Characterizing Animal Behaviors", "authors": ["Jingyang Ke", "Feiyang Wu", "Jiyi Wang", "Jeffrey Markowitz", "Anqi Wu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.12633v3", "summary": "Traditional approaches to studying decision-making in neuroscience focus on\nsimplified behavioral tasks where animals perform repetitive, stereotyped\nactions to receive explicit rewards. While informative, these methods constrain\nour understanding of decision-making to short timescale behaviors driven by\nexplicit goals. In natural environments, animals exhibit more complex,\nlong-term behaviors driven by intrinsic motivations that are often\nunobservable. Recent works in time-varying inverse reinforcement learning (IRL)\naim to capture shifting motivations in long-term, freely moving behaviors.\nHowever, a crucial challenge remains: animals make decisions based on their\nhistory, not just their current state. To address this, we introduce SWIRL\n(SWitching IRL), a novel framework that extends traditional IRL by\nincorporating time-varying, history-dependent reward functions. SWIRL models\nlong behavioral sequences as transitions between short-term decision-making\nprocesses, each governed by a unique reward function. SWIRL incorporates\nbiologically plausible history dependency to capture how past decisions and\nenvironmental contexts shape behavior, offering a more accurate description of\nanimal decision-making. We apply SWIRL to simulated and real-world animal\nbehavior datasets and show that it outperforms models lacking history\ndependency, both quantitatively and qualitatively. This work presents the first\nIRL model to incorporate history-dependent policies and rewards to advance our\nunderstanding of complex, naturalistic decision-making in animals.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.12633v3", "cate": "cs.LG", "date": "2025-01-22", "updated": "2025-07-15"}
{"id": "2412.00648", "title": "DFRot: Achieving Outlier-Free and Massive Activation-Free for Rotated LLMs with Refined Rotation", "authors": ["Jingyang Xiang", "Sai Qian Zhang"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepeted bythe 2nd Conference on Language Modeling (COLM 2025). Source code \\url{ this https URL }", "url": "http://arxiv.org/abs/2412.00648v4", "summary": "Rotating the activation and weight matrices to reduce the influence of\noutliers in large language models (LLMs) has recently attracted significant\nattention, particularly in the context of model quantization. Prior studies\nhave shown that in low-precision quantization scenarios, such as 4-bit weights\nand 4-bit activations (W4A4), randomized Hadamard transforms can achieve\nsignificantly higher accuracy than randomized orthogonal transforms. Notably,\nthe reason behind this phenomenon remains unknown. In this paper, we find that\nthese transformations show substantial improvement in eliminating outliers for\ncommon tokens and achieve similar quantization error. The primary reason for\nthe accuracy difference lies in the fact that randomized Hadamard transforms\ncan slightly reduce the quantization error for tokens with massive activations\nwhile randomized orthogonal transforms increase the quantization error. Due to\nthe extreme rarity of these tokens and their critical impact on model accuracy,\nwe consider this a long-tail optimization problem, and therefore construct a\nsimple yet effective method: a weighted loss function. Additionally, we propose\nan optimization strategy for the rotation matrix that involves alternating\noptimization of quantization parameters while employing orthogonal Procrustes\ntransforms to refine the rotation matrix. This makes the distribution of the\nrotated activation values more conducive to quantization, especially for tokens\nwith massive activations. Our method enhances the Rotated LLMs by achieving\ndual free, Outlier-Free and Massive Activation-Free, dubbed as DFRot. Extensive\nexperiments demonstrate the effectiveness and efficiency of DFRot. By tuning\nthe rotation matrix using just a single sample, DFRot achieves a perplexity\nimprovement of 0.98 and 0.95 on W4A4KV4 and W4A4KV16, respectively, for\nLLaMA3-70B, a model known for its quantization challenges.", "comment": "Accepeted bythe 2nd Conference on Language Modeling (COLM 2025).\n  Source code \\url{https://github.com/JingyangXiang/DFRot}", "pdf_url": "http://arxiv.org/pdf/2412.00648v4", "cate": "cs.LG", "date": "2024-12-01", "updated": "2025-07-15"}
{"id": "2506.18679", "title": "MARL-MambaContour: Unleashing Multi-Agent Deep Reinforcement Learning for Active Contour Optimization in Medical Image Segmentation", "authors": ["Ruicheng Zhang", "Yu Sun", "Zeyu Zhang", "Jinai Li", "Xiaofan Liu", "Au Hoi Fan", "Haowei Guo", "Puxin Yan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.18679v2", "summary": "We introduce MARL-MambaContour, the first contour-based medical image\nsegmentation framework based on Multi-Agent Reinforcement Learning (MARL). Our\napproach reframes segmentation as a multi-agent cooperation task focused on\ngenerate topologically consistent object-level contours, addressing the\nlimitations of traditional pixel-based methods which could lack topological\nconstraints and holistic structural awareness of anatomical regions. Each\ncontour point is modeled as an autonomous agent that iteratively adjusts its\nposition to align precisely with the target boundary, enabling adaptation to\nblurred edges and intricate morphologies common in medical images. This\niterative adjustment process is optimized by a contour-specific Soft\nActor-Critic (SAC) algorithm, further enhanced with the Entropy Regularization\nAdjustment Mechanism (ERAM) which dynamically balance agent exploration with\ncontour smoothness. Furthermore, the framework incorporates a Mamba-based\npolicy network featuring a novel Bidirectional Cross-attention Hidden-state\nFusion Mechanism (BCHFM). This mechanism mitigates potential memory confusion\nlimitations associated with long-range modeling in state space models, thereby\nfacilitating more accurate inter-agent information exchange and informed\ndecision-making. Extensive experiments on five diverse medical imaging datasets\ndemonstrate the state-of-the-art performance of MARL-MambaContour, highlighting\nits potential as an accurate and robust clinical application.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.18679v2", "cate": "cs.CV", "date": "2025-06-23", "updated": "2025-07-15"}
{"id": "2506.14407", "title": "ImpliRet: Benchmarking the Implicit Fact Retrieval Challenge", "authors": ["Zeinab Sadat Taghavi", "Ali Modarressi", "Yunpu Ma", "Hinrich Schütze"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.14407v2", "summary": "Retrieval systems are central to many NLP pipelines, but often rely on\nsurface-level cues such as keyword overlap and lexical semantic similarity. To\nevaluate retrieval beyond these shallow signals, recent benchmarks introduce\nreasoning-heavy queries; however, they primarily shift the burden to query-side\nprocessing techniques -- like prompting or multi-hop retrieval -- that can help\nresolve complexity. In contrast, we present ImpliRet, a benchmark that shifts\nthe reasoning challenge to document-side processing: The queries are simple,\nbut relevance depends on facts stated implicitly in documents through temporal\n(e.g., resolving \"two days ago\"), arithmetic, and world knowledge\nrelationships. We evaluate a range of sparse and dense retrievers, all of which\nstruggle in this setting: the best nDCG@10 is only 14.91%. We also test whether\nlong-context models can overcome this limitation. But even with a short context\nof only thirty documents, including the positive document, GPT-o4-mini scores\nonly 55.54%, showing that document-side reasoning remains a challenge. Our\ncodes are available at: github.com/ZeinabTaghavi/IMPLIRET", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.14407v2", "cate": "cs.CL", "date": "2025-06-17", "updated": "2025-07-15"}
{"id": "2502.04140", "title": "Synthetic Datasets for Machine Learning on Spatio-Temporal Graphs using PDEs", "authors": ["Jost Arndt", "Utku Isil", "Michael Detzel", "Wojciech Samek", "Jackie Ma"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Camera-ready version of the paper, which is now accepted at DMLR, see this https URL . 17 pages, 5 Figures", "url": "http://arxiv.org/abs/2502.04140v2", "summary": "Many physical processes can be expressed through partial differential\nequations (PDEs). Real-world measurements of such processes are often collected\nat irregularly distributed points in space, which can be effectively\nrepresented as graphs; however, there are currently only a few existing\ndatasets. Our work aims to make advancements in the field of PDE-modeling\naccessible to the temporal graph machine learning community, while addressing\nthe data scarcity problem, by creating and utilizing datasets based on PDEs. In\nthis work, we create and use synthetic datasets based on PDEs to support\nspatio-temporal graph modeling in machine learning for different applications.\nMore precisely, we showcase three equations to model different types of\ndisasters and hazards in the fields of epidemiology, atmospheric particles, and\ntsunami waves. Further, we show how such created datasets can be used by\nbenchmarking several machine learning models on the epidemiological dataset.\nAdditionally, we show how pre-training on this dataset can improve model\nperformance on real-world epidemiological data. The presented methods enable\nothers to create datasets and benchmarks customized to individual requirements.\nThe source code for our methodology and the three created datasets can be found\non https://github.com/github-usr-ano/Temporal_Graph_Data_PDEs.", "comment": "Camera-ready version of the paper, which is now accepted at DMLR, see\n  https://openreview.net/forum?id=EguDBMechn . 17 pages, 5 Figures", "pdf_url": "http://arxiv.org/pdf/2502.04140v2", "cate": "cs.LG", "date": "2025-02-06", "updated": "2025-07-15"}
{"id": "2412.20946", "title": "Generalising Battery Control in Net-Zero Buildings via Personalised Federated RL", "authors": ["Nicolas M Cuadrado Avila", "Samuel Horváth", "Martin Takáč"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at CO-Build Workshop ICML2025", "url": "http://arxiv.org/abs/2412.20946v2", "summary": "This work studies the challenge of optimal energy management in\nbuilding-based microgrids through a collaborative and privacy-preserving\nframework. We evaluated two common RL algorithms (PPO and TRPO) in different\ncollaborative setups to manage distributed energy resources (DERs) efficiently.\nUsing a customized version of the CityLearn environment and synthetically\ngenerated data, we simulate and design net-zero energy scenarios for microgrids\ncomposed of multiple buildings. Our approach emphasizes reducing energy costs\nand carbon emissions while ensuring privacy. Experimental results demonstrate\nthat Federated TRPO is comparable with state-of-the-art federated RL\nmethodologies without hyperparameter tuning. The proposed framework highlights\nthe feasibility of collaborative learning for achieving optimal control\npolicies in energy systems, advancing the goals of sustainable and efficient\nsmart grids. Our code is accessible\n\\href{https://github.com/Optimization-and-Machine-Learning-Lab/energy_fed_trpo.git}{\\textit{this\nrepo}}.", "comment": "Accepted at CO-Build Workshop ICML2025", "pdf_url": "http://arxiv.org/pdf/2412.20946v2", "cate": "cs.LG", "date": "2024-12-30", "updated": "2025-07-15"}
{"id": "2506.20254", "title": "Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement", "authors": ["Kun Yuan", "Tingxuan Chen", "Shi Li", "Joel L. Lavanchy", "Christian Heiliger", "Ege Özsoy", "Yiming Huang", "Long Bai", "Nassir Navab", "Vinkle Srivastav", "Hongliang Ren", "Nicolas Padoy"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by MICCAI 2025", "url": "http://arxiv.org/abs/2506.20254v2", "summary": "The complexity and diversity of surgical workflows, driven by heterogeneous\noperating room settings, institutional protocols, and anatomical variability,\npresent a significant challenge in developing generalizable models for\ncross-institutional and cross-procedural surgical understanding. While recent\nsurgical foundation models pretrained on large-scale vision-language data offer\npromising transferability, their zero-shot performance remains constrained by\ndomain shifts, limiting their utility in unseen surgical environments. To\naddress this, we introduce Surgical Phase Anywhere (SPA), a lightweight\nframework for versatile surgical workflow understanding that adapts foundation\nmodels to institutional settings with minimal annotation. SPA leverages\nfew-shot spatial adaptation to align multi-modal embeddings with\ninstitution-specific surgical scenes and phases. It also ensures temporal\nconsistency through diffusion modeling, which encodes task-graph priors derived\nfrom institutional procedure protocols. Finally, SPA employs dynamic test-time\nadaptation, exploiting the mutual agreement between multi-modal phase\nprediction streams to adapt the model to a given test video in a\nself-supervised manner, enhancing the reliability under test-time distribution\nshifts. SPA is a lightweight adaptation framework, allowing hospitals to\nrapidly customize phase recognition models by defining phases in natural\nlanguage text, annotating a few images with the phase labels, and providing a\ntask graph defining phase transitions. The experimental results show that the\nSPA framework achieves state-of-the-art performance in few-shot surgical phase\nrecognition across multiple institutions and procedures, even outperforming\nfull-shot models with 32-shot labeled data. Code is available at\nhttps://github.com/CAMMA-public/SPA", "comment": "Accepted by MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2506.20254v2", "cate": "cs.CV", "date": "2025-06-25", "updated": "2025-07-14"}
{"id": "2506.22760", "title": "Jan-nano Technical Report", "authors": ["Alan Dao", "Dinh Bach Vu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.22760v2", "summary": "Most language models face a fundamental tradeoff where powerful capabilities\nrequire substantial computational resources. We shatter this constraint with\nJan-nano, a 4B parameter language model that redefines efficiency through\nradical specialization: instead of trying to know everything, it masters the\nart of finding anything instantly. Fine-tuned from Qwen3-4B using our novel\nmulti-stage Reinforcement Learning with Verifiable Rewards (RLVR) system that\ncompletely eliminates reliance on next token prediction training (SFT),\nJan-nano achieves 83.2% on SimpleQA benchmark with MCP integration while\nrunning on consumer hardware. With 128K context length, Jan-nano proves that\nintelligence isn't about scale, it's about strategy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.22760v2", "cate": "cs.CL", "date": "2025-06-28", "updated": "2025-07-15"}
{"id": "2502.09609", "title": "Score-of-Mixture Training: Training One-Step Generative Models Made Simple via Score Estimation of Mixture Distributions", "authors": ["Tejas Jayashankar", "J. Jon Ryu", "Gregory Wornell"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      29 pages, 12 figures. ICML 2025 (spotlight)", "url": "http://arxiv.org/abs/2502.09609v3", "summary": "We propose Score-of-Mixture Training (SMT), a novel framework for training\none-step generative models by minimizing a class of divergences called the\n$\\alpha$-skew Jensen--Shannon divergence. At its core, SMT estimates the score\nof mixture distributions between real and fake samples across multiple noise\nlevels. Similar to consistency models, our approach supports both training from\nscratch (SMT) and distillation using a pretrained diffusion model, which we\ncall Score-of-Mixture Distillation (SMD). It is simple to implement, requires\nminimal hyperparameter tuning, and ensures stable training. Experiments on\nCIFAR-10 and ImageNet 64x64 show that SMT/SMD are competitive with and can even\noutperform existing methods.", "comment": "29 pages, 12 figures. ICML 2025 (spotlight)", "pdf_url": "http://arxiv.org/pdf/2502.09609v3", "cate": "cs.LG", "date": "2025-02-13", "updated": "2025-07-14"}
{"id": "2501.08156", "title": "Are DeepSeek R1 And Other Reasoning Models More Faithful?", "authors": ["James Chua", "Owain Evans"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 8 figures", "url": "http://arxiv.org/abs/2501.08156v5", "summary": "Language models trained to solve reasoning tasks via reinforcement learning\nhave achieved striking results. We refer to these models as reasoning models.\nAre the Chains of Thought (CoTs) of reasoning models more faithful than\ntraditional models? We evaluate three reasoning models (based on Qwen-2.5,\nGemini-2, and DeepSeek-V3-Base) on an existing test of faithful CoT. To measure\nfaithfulness, we test whether models can describe how a cue in their prompt\ninfluences their answer to MMLU questions. For example, when the cue \"A\nStanford Professor thinks the answer is D\" is added to the prompt, models\nsometimes switch their answer to D. In such cases, the DeepSeek-R1 reasoning\nmodel describes the cue's influence 59% of the time, compared to 7% for the\nnon-reasoning DeepSeek model. We evaluate seven types of cue, such as\nmisleading few-shot examples and suggestive follow-up questions from the user.\nReasoning models describe cues that influence them much more reliably than all\nthe non-reasoning models tested (including Claude-3.5-Sonnet and GPT-4o). In an\nadditional experiment, we provide evidence suggesting that the use of reward\nmodels causes less faithful responses -- which may help explain why\nnon-reasoning models are less faithful. Our study has two main limitations.\nFirst, we test faithfulness using a set of artificial tasks, which may not\nreflect realistic use-cases. Second, we only measure one specific aspect of\nfaithfulness -- whether models can describe the influence of cues. Future\nresearch should investigate whether the advantage of reasoning models in\nfaithfulness holds for a broader set of tests. Still, we think this increase in\nfaithfulness is promising for the explainability of language models.", "comment": "10 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2501.08156v5", "cate": "cs.LG", "date": "2025-01-14", "updated": "2025-07-15"}
{"id": "2506.23323", "title": "FA-Seg: A Fast and Accurate Diffusion-Based Method for Open-Vocabulary Segmentation", "authors": ["Quang-Huy Che", "Vinh-Tiep Nguyen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.23323v3", "summary": "Open-vocabulary semantic segmentation (OVSS) aims to segment objects from\narbitrary text categories without requiring densely annotated datasets.\nAlthough contrastive learning based models enable zero-shot segmentation, they\noften lose fine spatial precision at pixel level, due to global representation\nbias. In contrast, diffusion-based models naturally encode fine-grained spatial\nfeatures via attention mechanisms that capture both global context and local\ndetails. However, they often face challenges in balancing the computation costs\nand the quality of the segmentation mask. In this work, we present FA-Seg, a\nFast and Accurate training-free framework for open-vocabulary segmentation\nbased on diffusion models. FA-Seg performs segmentation using only a (1+1)-step\nfrom a pretrained diffusion model. Moreover, instead of running multiple times\nfor different classes, FA-Seg performs segmentation for all classes at once. To\nfurther enhance the segmentation quality, FA-Seg introduces three key\ncomponents: (i) a dual-prompt mechanism for discriminative, class-aware\nattention extraction, (ii) a Hierarchical Attention Refinement Method (HARD)\nthat enhances semantic precision via multi-resolution attention fusion, and\n(iii) a Test-Time Flipping (TTF) scheme designed to improve spatial\nconsistency. Extensive experiments show that FA-Seg achieves state-of-the-art\ntraining-free performance, obtaining 43.8% average mIoU across PASCAL VOC,\nPASCAL Context, and COCO Object benchmarks while maintaining superior inference\nefficiency. Our results demonstrate that FA-Seg provides a strong foundation\nfor extendability, bridging the gap between segmentation quality and inference\nefficiency. The source code will be open-sourced after this paper is accepted.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.23323v3", "cate": "cs.CV", "date": "2025-06-29", "updated": "2025-07-15"}
{"id": "2506.22791", "title": "ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models", "authors": ["Jianxin Yan", "Wangze Ni", "Lei Chen", "Xuemin Lin", "Peng Cheng", "Zhan Qin", "Kui Ren"], "categories": ["cs.CL", "cs.DB"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.22791v3", "summary": "Semantic caching significantly reduces computational costs and improves\nefficiency by storing and reusing large language model (LLM) responses.\nHowever, existing systems rely primarily on matching individual queries,\nlacking awareness of multi-turn dialogue contexts, which leads to incorrect\ncache hits when similar queries appear in different conversational settings.\nThis demonstration introduces ContextCache, a context-aware semantic caching\nsystem for multi-turn dialogues. ContextCache employs a two-stage retrieval\narchitecture that first executes vector-based retrieval on the current query to\nidentify potential matches and then integrates current and historical dialogue\nrepresentations through self-attention mechanisms for precise contextual\nmatching. Evaluation of real-world conversations shows that ContextCache\nimproves precision and recall compared to existing methods. Additionally,\ncached responses exhibit approximately 10 times lower latency than direct LLM\ninvocation, enabling significant computational cost reductions for LLM\nconversational applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.22791v3", "cate": "cs.CL", "date": "2025-06-28", "updated": "2025-07-15"}
{"id": "2503.11737", "title": "Multi-View Node Pruning for Accurate Graph Representation", "authors": ["Jiseong Park", "Hanjin Kim", "Seojin Kim", "Jueun Choi", "Doheon Lee", "Sung Ju Hwang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Jiseong Park and Hanjin Kim are co-first author for this work", "url": "http://arxiv.org/abs/2503.11737v3", "summary": "Graph pooling, which compresses a whole graph into a smaller coarsened graph,\nis an essential component of graph representation learning. To efficiently\ncompress a given graph, graph pooling methods often drop their nodes with\nattention-based scoring with the task loss. However, this often results in\nsimply removing nodes with lower degrees without consideration of their\nfeature-level relevance to the given task. To fix this problem, we propose a\nMulti-View Pruning(MVP), a graph pruning method based on a multi-view framework\nand reconstruction loss. Given a graph, MVP first constructs multiple graphs\nfor different views either by utilizing the predefined modalities or by\nrandomly partitioning the input features, to consider the importance of each\nnode in diverse perspectives. Then, it learns the score for each node by\nconsidering both the reconstruction and the task loss. MVP can be incorporated\nwith any hierarchical pooling framework to score the nodes. We validate MVP on\nmultiple benchmark datasets by coupling it with two graph pooling methods, and\nshow that it significantly improves the performance of the base graph pooling\nmethod, outperforming all baselines. Further analysis shows that both the\nencoding of multiple views and the consideration of reconstruction loss are the\nkey to the success of MVP, and that it indeed identifies nodes that are less\nimportant according to domain knowledge.", "comment": "Jiseong Park and Hanjin Kim are co-first author for this work", "pdf_url": "http://arxiv.org/pdf/2503.11737v3", "cate": "cs.LG", "date": "2025-03-14", "updated": "2025-07-15"}
{"id": "2502.05397", "title": "Imitation Learning from a Single Temporally Misaligned Video", "authors": ["William Huey", "Huaxiaoyue Wang", "Anne Wu", "Yoav Artzi", "Sanjiban Choudhury"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICML 2025", "url": "http://arxiv.org/abs/2502.05397v2", "summary": "We examine the problem of learning sequential tasks from a single visual\ndemonstration. A key challenge arises when demonstrations are temporally\nmisaligned due to variations in timing, differences in embodiment, or\ninconsistencies in execution. Existing approaches treat imitation as a\ndistribution-matching problem, aligning individual frames between the agent and\nthe demonstration. However, we show that such frame-level matching fails to\nenforce temporal ordering or ensure consistent progress. Our key insight is\nthat matching should instead be defined at the level of sequences. We propose\nthat perfect matching occurs when one sequence successfully covers all the\nsubgoals in the same order as the other sequence. We present ORCA (ORdered\nCoverage Alignment), a dense per-timestep reward function that measures the\nprobability of the agent covering demonstration frames in the correct order. On\ntemporally misaligned demonstrations, we show that agents trained with the ORCA\nreward achieve $4.5$x improvement ($0.11 \\rightarrow 0.50$ average normalized\nreturns) for Meta-world tasks and $6.6$x improvement ($6.55 \\rightarrow 43.3$\naverage returns) for Humanoid-v4 tasks compared to the best frame-level\nmatching algorithms. We also provide empirical analysis showing that ORCA is\nrobust to varying levels of temporal misalignment. Our code is available at\nhttps://github.com/portal-cornell/orca/", "comment": "ICML 2025", "pdf_url": "http://arxiv.org/pdf/2502.05397v2", "cate": "cs.LG", "date": "2025-02-08", "updated": "2025-07-14"}
{"id": "2507.00585", "title": "Similarity Memory Prior is All You Need for Medical Image Segmentation", "authors": ["Hao Tang", "Zhiqing Guo", "Liejun Wang", "Chao Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.00585v3", "summary": "In recent years, it has been found that \"grandmother cells\" in the primary\nvisual cortex (V1) of macaques can directly recognize visual input with complex\nshapes. This inspires us to examine the value of these cells in promoting the\nresearch of medical image segmentation. In this paper, we design a Similarity\nMemory Prior Network (Sim-MPNet) for medical image segmentation. Specifically,\nwe propose a Dynamic Memory Weights-Loss Attention (DMW-LA), which matches and\nremembers the category features of specific lesions or organs in medical images\nthrough the similarity memory prior in the prototype memory bank, thus helping\nthe network to learn subtle texture changes between categories. DMW-LA also\ndynamically updates the similarity memory prior in reverse through Weight-Loss\nDynamic (W-LD) update strategy, effectively assisting the network directly\nextract category features. In addition, we propose the Double-Similarity Global\nInternal Enhancement Module (DS-GIM) to deeply explore the internal differences\nin the feature distribution of input data through cosine similarity and\neuclidean distance. Extensive experiments on four public datasets show that\nSim-MPNet has better segmentation performance than other state-of-the-art\nmethods. Our code is available on https://github.com/vpsg-research/Sim-MPNet.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.00585v3", "cate": "cs.CV", "date": "2025-07-01", "updated": "2025-07-15"}
{"id": "2507.00838", "title": "Stylometry recognizes human and LLM-generated texts in short samples", "authors": ["Karol Przystalski", "Jan K. Argasiński", "Iwona Grabska-Gradzińska", "Jeremi K. Ochab"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.00838v2", "summary": "The paper explores stylometry as a method to distinguish between texts\ncreated by Large Language Models (LLMs) and humans, addressing issues of model\nattribution, intellectual property, and ethical AI use. Stylometry has been\nused extensively to characterise the style and attribute authorship of texts.\nBy applying it to LLM-generated texts, we identify their emergent writing\npatterns. The paper involves creating a benchmark dataset based on Wikipedia,\nwith (a) human-written term summaries, (b) texts generated purely by LLMs\n(GPT-3.5/4, LLaMa 2/3, Orca, and Falcon), (c) processed through multiple text\nsummarisation methods (T5, BART, Gensim, and Sumy), and (d) rephrasing methods\n(Dipper, T5). The 10-sentence long texts were classified by tree-based models\n(decision trees and LightGBM) using human-designed (StyloMetrix) and\nn-gram-based (our own pipeline) stylometric features that encode lexical,\ngrammatical, syntactic, and punctuation patterns. The cross-validated results\nreached a performance of up to .87 Matthews correlation coefficient in the\nmulticlass scenario with 7 classes, and accuracy between .79 and 1. in binary\nclassification, with the particular example of Wikipedia and GPT-4 reaching up\nto .98 accuracy on a balanced dataset. Shapley Additive Explanations pinpointed\nfeatures characteristic of the encyclopaedic text type, individual overused\nwords, as well as a greater grammatical standardisation of LLMs with respect to\nhuman-written texts. These results show -- crucially, in the context of the\nincreasingly sophisticated LLMs -- that it is possible to distinguish machine-\nfrom human-generated texts at least for a well-defined text type.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.00838v2", "cate": "cs.CL", "date": "2025-07-01", "updated": "2025-07-15"}
{"id": "2504.02008", "title": "Test-time Adaptation for Foundation Medical Segmentation Model without Parametric Updates", "authors": ["Kecheng Chen", "Xinyu Luo", "Tiexin Qin", "Jie Liu", "Hui Liu", "Victor Ho Fun Lee", "Hong Yan", "Haoliang Li"], "categories": ["q-bio.QM", "cs.AI"], "primary_category": "Subjects:       Quantitative Methods (q-bio.QM)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2504.02008v2", "summary": "Foundation medical segmentation models, with MedSAM being the most popular,\nhave achieved promising performance across organs and lesions. However, MedSAM\nstill suffers from compromised performance on specific lesions with intricate\nstructures and appearance, as well as bounding box prompt-induced\nperturbations. Although current test-time adaptation (TTA) methods for medical\nimage segmentation may tackle this issue, partial (e.g., batch normalization)\nor whole parametric updates restrict their effectiveness due to limited update\nsignals or catastrophic forgetting in large models. Meanwhile, these approaches\nignore the computational complexity during adaptation, which is particularly\nsignificant for modern foundation models. To this end, our theoretical analyses\nreveal that directly refining image embeddings is feasible to approach the same\ngoal as parametric updates under the MedSAM architecture, which enables us to\nrealize high computational efficiency and segmentation performance without the\nrisk of catastrophic forgetting. Under this framework, we propose to encourage\nmaximizing factorized conditional probabilities of the posterior prediction\nprobability using a proposed distribution-approximated latent conditional\nrandom field loss combined with an entropy minimization loss. Experiments show\nthat we achieve about 3\\% Dice score improvements across three datasets while\nreducing computational complexity by over 7 times.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2504.02008v2", "cate": "q-bio.QM", "date": "2025-04-02", "updated": "2025-07-15"}
{"id": "2502.13112", "title": "Constrained Online Convex Optimization with Polyak Feasibility Steps", "authors": ["Spencer Hutchinson", "Mahnoosh Alizadeh"], "categories": ["cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      accepted at ICML 2025", "url": "http://arxiv.org/abs/2502.13112v2", "summary": "In this work, we study online convex optimization with a fixed constraint\nfunction $g : \\mathbb{R}^d \\rightarrow \\mathbb{R}$. Prior work on this problem\nhas shown $O(\\sqrt{T})$ regret and cumulative constraint satisfaction\n$\\sum_{t=1}^{T} g(x_t) \\leq 0$, while only accessing the constraint value and\nsubgradient at the played actions $g(x_t), \\partial g(x_t)$. Using the same\nconstraint information, we show a stronger guarantee of anytime constraint\nsatisfaction $g(x_t) \\leq 0 \\ \\forall t \\in [T]$, and matching $O(\\sqrt{T})$\nregret guarantees. These contributions are thanks to our approach of using\nPolyak feasibility steps to ensure constraint satisfaction, without sacrificing\nregret. Specifically, after each step of online gradient descent, our algorithm\napplies a subgradient descent step on the constraint function where the\nstep-size is chosen according to the celebrated Polyak step-size. We further\nvalidate this approach with numerical experiments.", "comment": "accepted at ICML 2025", "pdf_url": "http://arxiv.org/pdf/2502.13112v2", "cate": "cs.LG", "date": "2025-02-18", "updated": "2025-07-15"}
{"id": "2507.01504", "title": "Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence", "authors": ["Robert Aufschläger", "Youssef Shoeb", "Azarm Nowzad", "Michael Heigl", "Fabian Bally", "Martin Schramm"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted for publication at the 2025 IEEE 28th International Conference on Intelligent Transportation Systems (ITSC 2025), taking place during November 18-21, 2025 in Gold Coast, Australia", "url": "http://arxiv.org/abs/2507.01504v3", "summary": "The collection and release of street-level recordings as Open Data play a\nvital role in advancing autonomous driving systems and AI research. However,\nthese datasets pose significant privacy risks, particularly for pedestrians,\ndue to the presence of Personally Identifiable Information (PII) that extends\nbeyond biometric traits such as faces. In this paper, we present cRID, a novel\ncross-modal framework combining Large Vision-Language Models, Graph Attention\nNetworks, and representation learning to detect textual describable clues of\nPII and enhance person re-identification (Re-ID). Our approach focuses on\nidentifying and leveraging interpretable features, enabling the detection of\nsemantically meaningful PII beyond low-level appearance cues. We conduct a\nsystematic evaluation of PII presence in person image datasets. Our experiments\nshow improved performance in practical cross-dataset Re-ID scenarios, notably\nfrom Market-1501 to CUHK03-np (detected), highlighting the framework's\npractical utility. Code is available at https://github.com/RAufschlaeger/cRID.", "comment": "accepted for publication at the 2025 IEEE 28th International\n  Conference on Intelligent Transportation Systems (ITSC 2025), taking place\n  during November 18-21, 2025 in Gold Coast, Australia", "pdf_url": "http://arxiv.org/pdf/2507.01504v3", "cate": "cs.CV", "date": "2025-07-02", "updated": "2025-07-15"}
{"id": "2507.02221", "title": "GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons", "authors": ["Steven Song", "Anirudh Subramanyam", "Zhenyu Zhang", "Aarti Venkat", "Robert L. Grossman"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages, 1 figure, 7 tables. v2 updated to reflect migration to HF Spaces", "url": "http://arxiv.org/abs/2507.02221v2", "summary": "The Genomic Data Commons (GDC) provides access to high quality, harmonized\ncancer genomics data through a unified curation and analysis platform centered\naround patient cohorts. While GDC users can interactively create complex\ncohorts through the graphical Cohort Builder, users (especially new ones) may\nstruggle to find specific cohort descriptors across hundreds of possible fields\nand properties. However, users may be better able to describe their desired\ncohort in free-text natural language. We introduce GDC Cohort Copilot, an\nopen-source copilot tool for curating cohorts from the GDC. GDC Cohort Copilot\nautomatically generates the GDC cohort filter corresponding to a user-input\nnatural language description of their desired cohort, before exporting the\ncohort back to the GDC for further analysis. An interactive user interface\nallows users to further refine the generated cohort. We develop and evaluate\nmultiple large language models (LLMs) for GDC Cohort Copilot and demonstrate\nthat our locally-served, open-source GDC Cohort LLM achieves better results\nthan GPT-4o prompting in generating GDC cohorts. We implement and share GDC\nCohort Copilot as a containerized Gradio app on HuggingFace Spaces, available\nat https://huggingface.co/spaces/uc-ctds/GDC-Cohort-Copilot. GDC Cohort LLM\nweights are available at https://huggingface.co/uc-ctds. All source code is\navailable at https://github.com/uc-cdis/gdc-cohort-copilot.", "comment": "12 pages, 1 figure, 7 tables. v2 updated to reflect migration to HF\n  Spaces", "pdf_url": "http://arxiv.org/pdf/2507.02221v2", "cate": "cs.CL", "date": "2025-07-03", "updated": "2025-07-14"}
{"id": "2504.06308", "title": "Rethinking RoPE: A Mathematical Blueprint for N-dimensional Positional Embedding", "authors": ["Haiping Liu", "Lijing Lin", "Jingyuan Sun", "Zhegong Shangguan", "Mauricio A. Alvarez", "Hongpeng Zhou"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.06308v2", "summary": "Rotary Position Embedding (RoPE) is widely adopted in large language models\n(LLMs) due to its efficient encoding of relative positions with strong\nextrapolation capabilities. However, while its application in\nhigher-dimensional input domains, such as 2D images, have been explored in\nseveral attempts, a unified theoretical framework is still lacking. To address\nthis, we propose a systematic mathematical framework for RoPE grounded in Lie\ngroup and Lie algebra theory. We derive the necessary and sufficient conditions\nfor any valid $N$-dimensional RoPE based on two core properties of RoPE -\nrelativity and reversibility. We demonstrate that RoPE can be characterized as\na basis of a maximal abelian subalgebra (MASA) in the special orthogonal Lie\nalgebra, and that the commonly used axis-aligned block-diagonal RoPE, where\neach input axis is encoded by an independent 2x2 rotation block, corresponds to\nthe maximal toral subalgebra. Furthermore, we reduce spatial inter-dimensional\ninteractions to a change of basis, resolved by learning an orthogonal\ntransformation. Our experiment results suggest that inter-dimensional\ninteractions should be balanced with local structure preservation. Overall, our\nframework unifies and explains existing RoPE designs while enabling principled\nextensions to higher-dimensional modalities and tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.06308v2", "cate": "cs.LG", "date": "2025-04-07", "updated": "2025-07-14"}
{"id": "2502.14565", "title": "ReVISE: Learning to Refine at Test-Time via Intrinsic Self-Verification", "authors": ["Hyunseok Lee", "Seunghyuk Oh", "Jaehyung Kim", "Jinwoo Shin", "Jihoon Tack"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published as conference proceeding for ICML 2025. First two authors contributed equally", "url": "http://arxiv.org/abs/2502.14565v2", "summary": "Self-awareness, i.e., the ability to assess and correct one's own generation,\nis a fundamental aspect of human intelligence, making its replication in large\nlanguage models (LLMs) an important yet challenging task. Previous works tackle\nthis by employing extensive reinforcement learning or rather relying on large\nexternal verifiers. In this work, we propose Refine via Intrinsic\nSelf-Verification (ReVISE), an efficient and effective framework that enables\nLLMs to self-correct their outputs through self-verification. The core idea of\nReVISE is to enable LLMs to verify their reasoning processes and continually\nrethink reasoning trajectories based on its verification. We introduce a\nstructured curriculum based upon online preference learning to implement this\nefficiently. Specifically, as ReVISE involves two challenging tasks (i.e.,\nself-verification and reasoning correction), we tackle each task sequentially\nusing curriculum learning, collecting both failed and successful reasoning\npaths to construct preference pairs for efficient training. During inference,\nour approach enjoys natural test-time scaling by integrating self-verification\nand correction capabilities, further enhanced by our proposed confidence-aware\ndecoding mechanism. Our experiments on various reasoning tasks demonstrate that\nReVISE achieves efficient self-correction and significantly improves reasoning\nperformance.", "comment": "Published as conference proceeding for ICML 2025. First two authors\n  contributed equally", "pdf_url": "http://arxiv.org/pdf/2502.14565v2", "cate": "cs.LG", "date": "2025-02-20", "updated": "2025-07-15"}
{"id": "2507.04762", "title": "Robustifying 3D Perception via Least-Squares Graphs for Multi-Agent Object Tracking", "authors": ["Maria Damanaki", "Ioulia Kapsali", "Nikos Piperigkos", "Alexandros Gkillas", "Aris S. Lalos"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages, 3 figures, 4 tables", "url": "http://arxiv.org/abs/2507.04762v2", "summary": "The critical perception capabilities of EdgeAI systems, such as autonomous\nvehicles, are required to be resilient against adversarial threats, by enabling\naccurate identification and localization of multiple objects in the scene over\ntime, mitigating their impact. Single-agent tracking offers resilience to\nadversarial attacks but lacks situational awareness, underscoring the need for\nmulti-agent cooperation to enhance context understanding and robustness. This\npaper proposes a novel mitigation framework on 3D LiDAR scene against\nadversarial noise by tracking objects based on least-squares graph on\nmulti-agent adversarial bounding boxes. Specifically, we employ the\nleast-squares graph tool to reduce the induced positional error of each\ndetection's centroid utilizing overlapped bounding boxes on a fully connected\ngraph via differential coordinates and anchor points. Hence, the multi-vehicle\ndetections are fused and refined mitigating the adversarial impact, and\nassociated with existing tracks in two stages performing tracking to further\nsuppress the adversarial threat. An extensive evaluation study on the\nreal-world V2V4Real dataset demonstrates that the proposed method significantly\noutperforms both state-of-the-art single and multi-agent tracking frameworks by\nup to 23.3% under challenging adversarial conditions, operating as a resilient\napproach without relying on additional defense mechanisms.", "comment": "6 pages, 3 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.04762v2", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-15"}
{"id": "2507.04099", "title": "Conversation Forests: The Key to Fine Tuning Large Language Models for Multi-Turn Medical Conversations is Branching", "authors": ["Thomas Savage"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04099v2", "summary": "Fine-tuning methods such as Direct Preference Optimization (DPO) and Group\nRelative Policy Optimization (GRPO) have demonstrated success in training large\nlanguage models (LLMs) for single-turn tasks. However, these methods fall short\nin multi-turn applications, such as diagnostic patient interviewing, where\nunderstanding how early conversational turns influence downstream completions\nand outcomes is essential. In medicine, a multi-turn perspective is critical\nfor learning diagnostic schemas and better understanding conversation dynamics.\nTo address this gap, I introduce Savage Conversation Forests (SCF), a\nreinforcement learning framework that leverages a branched conversation\narchitecture to fine-tune LLMs for multi-turn dialogue. SCF generates multiple\npossible conversation continuations at each turn, enabling the model to learn\nhow different early responses affect downstream interactions and diagnostic\noutcomes. In experiments simulating doctor-patient conversations, SCF with\nbranching outperforms linear conversation architectures on diagnostic accuracy.\nI hypothesize that SCF's improvements stem from its ability to provide richer,\ninterdependent training signals across conversation turns. These results\nsuggest that a branched training architecture is an important strategy for fine\ntuning LLMs in complex multi-turn conversational tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04099v2", "cate": "cs.CL", "date": "2025-07-05", "updated": "2025-07-15"}
{"id": "2504.08051", "title": "Compositional Flows for 3D Molecule and Synthesis Pathway Co-design", "authors": ["Tony Shen", "Seonghwan Seo", "Ross Irwin", "Kieran Didi", "Simon Olsson", "Woo Youn Kim", "Martin Ester"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to ICML 2025, 29 pages, 7 figures, code: this https URL", "url": "http://arxiv.org/abs/2504.08051v2", "summary": "Many generative applications, such as synthesis-based 3D molecular design,\ninvolve constructing compositional objects with continuous features. Here, we\nintroduce Compositional Generative Flows (CGFlow), a novel framework that\nextends flow matching to generate objects in compositional steps while modeling\ncontinuous states. Our key insight is that modeling compositional state\ntransitions can be formulated as a straightforward extension of the flow\nmatching interpolation process. We further build upon the theoretical\nfoundations of generative flow networks (GFlowNets), enabling reward-guided\nsampling of compositional structures. We apply CGFlow to synthesizable drug\ndesign by jointly designing the molecule's synthetic pathway with its 3D\nbinding pose. Our approach achieves state-of-the-art binding affinity on all 15\ntargets from the LIT-PCBA benchmark, and 5.8$\\times$ improvement in sampling\nefficiency compared to 2D synthesis-based baseline. To our best knowledge, our\nmethod is also the first to achieve state of-art-performance in both Vina Dock\n(-9.38) and AiZynth success rate (62.2\\%) on the CrossDocked benchmark.", "comment": "Accepted to ICML 2025, 29 pages, 7 figures, code:\n  https://github.com/tsa87/cgflow", "pdf_url": "http://arxiv.org/pdf/2504.08051v2", "cate": "cs.LG", "date": "2025-04-10", "updated": "2025-07-15"}
{"id": "2503.00877", "title": "Patch-wise Structural Loss for Time Series Forecasting", "authors": ["Dilfira Kudrat", "Zongxia Xie", "Yanru Sun", "Tianyu Jia", "Qinghua Hu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.00877v2", "summary": "Time-series forecasting has gained significant attention in machine learning\ndue to its crucial role in various domains. However, most existing forecasting\nmodels rely heavily on point-wise loss functions like Mean Square Error, which\ntreat each time step independently and neglect the structural dependencies\ninherent in time series data, making it challenging to capture complex temporal\npatterns accurately. To address these challenges, we propose a novel Patch-wise\nStructural (PS) loss, designed to enhance structural alignment by comparing\ntime series at the patch level. Through leveraging local statistical\nproperties, such as correlation, variance, and mean, PS loss captures nuanced\nstructural discrepancies overlooked by traditional point-wise losses.\nFurthermore, it integrates seamlessly with point-wise loss, simultaneously\naddressing local structural inconsistencies and individual time-step errors. PS\nloss establishes a novel benchmark for accurately modeling complex time series\ndata and provides a new perspective on time series loss function design.\nExtensive experiments demonstrate that PS loss significantly improves the\nperformance of state-of-the-art models across diverse real-world datasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.00877v2", "cate": "cs.LG", "date": "2025-03-02", "updated": "2025-07-15"}
{"id": "2507.06513", "title": "What Demands Attention in Urban Street Scenes? From Scene Understanding towards Road Safety: A Survey of Vision-driven Datasets and Studies", "authors": ["Yaoqi Huang", "Julie Stephany Berrio", "Mao Shan", "Stewart Worrall"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      45 pages, 52 figures, 2 large tables (divided into 5), 73 datatsets, 35 tasks", "url": "http://arxiv.org/abs/2507.06513v2", "summary": "Advances in vision-based sensors and computer vision algorithms have\nsignificantly improved the analysis and understanding of traffic scenarios. To\nfacilitate the use of these improvements for road safety, this survey\nsystematically categorizes the critical elements that demand attention in\ntraffic scenarios and comprehensively analyzes available vision-driven tasks\nand datasets. Compared to existing surveys that focus on isolated domains, our\ntaxonomy categorizes attention-worthy traffic entities into two main groups\nthat are anomalies and normal but critical entities, integrating ten categories\nand twenty subclasses. It establishes connections between inherently related\nfields and provides a unified analytical framework. Our survey highlights the\nanalysis of 35 vision-driven tasks and comprehensive examinations and\nvisualizations of 73 available datasets based on the proposed taxonomy. The\ncross-domain investigation covers the pros and cons of each benchmark with the\naim of providing information on standards unification and resource\noptimization. Our article concludes with a systematic discussion of the\nexisting weaknesses, underlining the potential effects and promising solutions\nfrom various perspectives. The integrated taxonomy, comprehensive analysis, and\nrecapitulatory tables serve as valuable contributions to this rapidly evolving\nfield by providing researchers with a holistic overview, guiding strategic\nresource selection, and highlighting critical research gaps.", "comment": "45 pages, 52 figures, 2 large tables (divided into 5), 73 datatsets,\n  35 tasks", "pdf_url": "http://arxiv.org/pdf/2507.06513v2", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-15"}
{"id": "2507.05713", "title": "DRAGON: Dynamic RAG Benchmark On News", "authors": ["Fedor Chernogorskii", "Sergei Averkiev", "Liliya Kudraleeva", "Zaven Martirosian", "Maria Tikhonova", "Valentin Malykh", "Alena Fenogenova"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05713v2", "summary": "Retrieval-Augmented Generation (RAG) is a widely adopted approach for\nimproving the factuality of large language models (LLMs) by incorporating\nexternal knowledge at inference time. Although there exist multiple RAG\nbenchmarks for English, evaluation resources for other languages, including\nRussian, remain scarce and static, failing to capture the dynamic nature of\nreal-world deployments. In this work, we present DRAGON (Dynamic RAG Benchmark\nOn News), the first dynamic benchmark for evaluating RAG systems in Russian on\na changing news corpora. DRAGON is built upon a regularly updated corpus of\nRussian news and public documents and supports comprehensive evaluation of both\nthe retriever and generator components. Question generation is performed\nautomatically with the use of Knowledge Graph constructed from the corpus and\nenables the extraction of four core question types aligned with distinct\nsubgraph patterns. We release a complete evaluation framework comprising the\npipeline for automatic question generation, evaluation scripts, which are\npotentially reusable for other languages and multilingual settings, and\nbenchmark data. We also launch a public leaderboard to encourage community\nparticipation and comparison.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05713v2", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-15"}
{"id": "2504.08161", "title": "Rethinking the Foundations for Continual Reinforcement Learning", "authors": ["Esraa Elelimy", "David Szepesvari", "Martha White", "Michael Bowling"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.08161v3", "summary": "In the traditional view of reinforcement learning, the agent's goal is to\nfind an optimal policy that maximizes its expected sum of rewards. Once the\nagent finds this policy, the learning ends. This view contrasts with\n\\emph{continual reinforcement learning}, where learning does not end, and\nagents are expected to continually learn and adapt indefinitely. Despite the\nclear distinction between these two paradigms of learning, much of the progress\nin continual reinforcement learning has been shaped by foundations rooted in\nthe traditional view of reinforcement learning. In this paper, we first examine\nwhether the foundations of traditional reinforcement learning are suitable for\nthe continual reinforcement learning paradigm. We identify four key pillars of\nthe traditional reinforcement learning foundations that are antithetical to the\ngoals of continual learning: the Markov decision process formalism, the focus\non atemporal artifacts, the expected sum of rewards as an evaluation metric,\nand episodic benchmark environments that embrace the other three foundations.\nWe then propose a new formalism that sheds the first and the third foundations\nand replaces them with the history process as a mathematical formalism and a\nnew definition of deviation regret, adapted for continual learning, as an\nevaluation metric. Finally, we discuss possible approaches to shed the other\ntwo foundations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.08161v3", "cate": "cs.LG", "date": "2025-04-10", "updated": "2025-07-15"}
{"id": "2503.10537", "title": "Structured Preconditioners in Adaptive Optimization: A Unified Analysis", "authors": ["Shuo Xie", "Tianhao Wang", "Sashank Reddi", "Sanjiv Kumar", "Zhiyuan Li"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Fix typos and add remarks for two-sided Shampoo", "url": "http://arxiv.org/abs/2503.10537v2", "summary": "We present a novel unified analysis for a broad class of adaptive\noptimization algorithms with structured (e.g., layerwise, diagonal, and\nkronecker-factored) preconditioners for both online regret minimization and\noffline convex optimization. Our analysis not only provides matching rate to\nseveral important structured preconditioned algorithms including diagonal\nAdaGrad, full-matrix AdaGrad, and AdaGrad-Norm, but also gives an improved\nconvergence rate for a one-sided variant of Shampoo over that of original\nShampoo. Interestingly, more structured preconditioners (e.g., diagonal\nAdagrad, AdaGrad-Norm which use less space and compute) are often presented as\ncomputationally efficient approximations to full-matrix Adagrad, aiming for\nimproved optimization performance through better approximations. Our unified\nanalysis challenges this prevailing view and reveals, perhaps surprisingly,\nthat more structured preconditioners, despite using less space and computation\nper step, can outperform their less structured counterparts. To demonstrate\nthis, we show that one-sided Shampoo, which is relatively much cheaper than\nfull-matrix AdaGrad could outperform it both theoretically and experimentally.", "comment": "Fix typos and add remarks for two-sided Shampoo", "pdf_url": "http://arxiv.org/pdf/2503.10537v2", "cate": "cs.LG", "date": "2025-03-13", "updated": "2025-07-15"}
{"id": "2507.06858", "title": "Longitudinal Study of Facial Biometrics at the BEZ: Temporal Variance Analysis", "authors": ["Mathias Schulz", "Alexander Spenke", "Pia Funk", "Florian Blümel", "Markus Rohde", "Ralph Breithaupt", "Gerd Nolden", "Norbert Jung", "Robert Lange"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11 pages, 10 figures, 8 tables", "url": "http://arxiv.org/abs/2507.06858v2", "summary": "This study presents findings from long-term biometric evaluations conducted\nat the Biometric Evaluation Center (bez). Over the course of two and a half\nyears, our ongoing research with over 400 participants representing diverse\nethnicities, genders, and age groups were regularly assessed using a variety of\nbiometric tools and techniques at the controlled testing facilities. Our\nfindings are based on the General Data Protection Regulation-compliant local\nbez database with more than 238.000 biometric data sets categorized into\nmultiple biometric modalities such as face and finger. We used state-of-the-art\nface recognition algorithms to analyze long-term comparison scores. Our results\nshow that these scores fluctuate more significantly between individual days\nthan over the entire measurement period. These findings highlight the\nimportance of testing biometric characteristics of the same individuals over a\nlonger period of time in a controlled measurement environment and lays the\ngroundwork for future advancements in biometric data analysis.", "comment": "11 pages, 10 figures, 8 tables", "pdf_url": "http://arxiv.org/pdf/2507.06858v2", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-15"}
{"id": "2507.06313", "title": "ETT: Expanding the Long Context Understanding Capability of LLMs at Test-Time", "authors": ["Kiarash Zahirnia", "Zahra Golpayegani", "Walid Ahmed", "Yang Liu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06313v2", "summary": "Transformer-based Language Models' computation and memory overhead increase\nquadratically as a function of sequence length. The quadratic cost poses\nchallenges when employing LLMs for processing long sequences. In this work, we\nintroduce \\ourmodelacronym~(Extend at Test-Time), method for extending the\ncontext length of short context Transformer-based LLMs, with constant memory\nrequirement and linear computation overhead. ETT enable the extension of the\ncontext length at test-time by efficient fine-tuning the model's parameters on\nthe input context, chunked into overlapping small subsequences. We evaluate ETT\non LongBench by extending the context length of GPT-Large and Phi-2 up to 32\ntimes, increasing from 1k to 32k tokens. This results in up to a 30 percent\nimprovement in the model's accuracy. We also study how context can be stored in\nLLM's weights effectively and efficiently. Through a detailed ablation study,\nwe examine which Transformer modules are most beneficial to fine-tune at\ntest-time. Interestingly, we find that fine-tuning the second layer of the FFNs\nis more effective than full fine-tuning, leading to a further improvement in\nthe models' accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06313v2", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-15"}
{"id": "2506.00588", "title": "Temporal Chunking Enhances Recognition of Implicit Sequential Patterns", "authors": ["Jayanta Dey", "Nicholas Soures", "Miranda Gonzales", "Itamar Lerner", "Christopher Kanan", "Dhireesha Kudithipudi"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.00588v2", "summary": "In this pilot study, we propose a neuro-inspired approach that compresses\ntemporal sequences into context-tagged chunks, where each tag represents a\nrecurring structural unit or``community'' in the sequence. These tags are\ngenerated during an offline sleep phase and serve as compact references to past\nexperience, allowing the learner to incorporate information beyond its\nimmediate input range. We evaluate this idea in a controlled synthetic\nenvironment designed to reveal the limitations of traditional neural network\nbased sequence learners, such as recurrent neural networks (RNNs), when facing\ntemporal patterns on multiple timescales. We evaluate this idea in a controlled\nsynthetic environment designed to reveal the limitations of traditional neural\nnetwork based sequence learners, such as recurrent neural networks (RNNs), when\nfacing temporal patterns on multiple timescales. Our results, while\npreliminary, suggest that temporal chunking can significantly enhance learning\nefficiency under resource constrained settings. A small-scale human pilot study\nusing a Serial Reaction Time Task further motivates the idea of structural\nabstraction. Although limited to synthetic tasks, this work serves as an early\nproof-of-concept, with initial evidence that learned context tags can transfer\nacross related task, offering potential for future applications in transfer\nlearning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.00588v2", "cate": "cs.LG", "date": "2025-05-31", "updated": "2025-07-15"}
{"id": "2504.02016", "title": "Fast Fourier Correlation is a Highly Efficient and Accurate Feature Attribution Algorithm from the Perspective of Control Theory and Game Theory", "authors": ["Zechen Liu", "Feiyang Zhang", "Wei Song", "Xiang Li", "Wei Wei"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      13 pages, 2 figures", "url": "http://arxiv.org/abs/2504.02016v2", "summary": "The study of neural networks from the perspective of Fourier features has\ngarnered significant attention. While existing analytical research suggests\nthat neural networks tend to learn low-frequency features, a clear attribution\nmethod for identifying the specific learned Fourier features has remained\nelusive. To bridge this gap, we propose a novel Fourier feature attribution\nmethod grounded in signal decomposition theory. Additionally, we analyze the\ndifferences between game-theoretic attribution metrics for Fourier and spatial\ndomain features, demonstrating that game-theoretic evaluation metrics are\nbetter suited for Fourier-based feature attribution.\n  Our experiments show that Fourier feature attribution exhibits superior\nfeature selection capabilities compared to spatial domain attribution methods.\nFor instance, in the case of Vision Transformers (ViTs) on the ImageNet\ndataset, only $8\\%$ of the Fourier features are required to maintain the\noriginal predictions for $80\\%$ of the samples. Furthermore, we compare the\nspecificity of features identified by our method against traditional spatial\ndomain attribution methods. Results reveal that Fourier features exhibit\ngreater intra-class concentration and inter-class distinctiveness, indicating\ntheir potential for more efficient classification and explainable AI\nalgorithms.", "comment": "13 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2504.02016v2", "cate": "cs.LG", "date": "2025-04-02", "updated": "2025-07-15"}
{"id": "2507.07487", "title": "Driving by Hybrid Navigation: An Online HD-SD Map Association Framework and Benchmark for Autonomous Vehicles", "authors": ["Jiaxu Wan", "Xu Wang", "Mengwei Xie", "Xinyuan Chang", "Xinran Liu", "Zheng Pan", "Mu Xu", "Ding Yuan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Fix bug for repeat reference", "url": "http://arxiv.org/abs/2507.07487v2", "summary": "Autonomous vehicles rely on global standard-definition (SD) maps for\nroad-level route planning and online local high-definition (HD) maps for\nlane-level navigation. However, recent work concentrates on construct online HD\nmaps, often overlooking the association of global SD maps with online HD maps\nfor hybrid navigation, making challenges in utilizing online HD maps in the\nreal world. Observing the lack of the capability of autonomous vehicles in\nnavigation, we introduce \\textbf{O}nline \\textbf{M}ap \\textbf{A}ssociation, the\nfirst benchmark for the association of hybrid navigation-oriented online maps,\nwhich enhances the planning capabilities of autonomous vehicles. Based on\nexisting datasets, the OMA contains 480k of roads and 260k of lane paths and\nprovides the corresponding metrics to evaluate the performance of the model.\nAdditionally, we propose a novel framework, named Map Association Transformer,\nas the baseline method, using path-aware attention and spatial attention\nmechanisms to enable the understanding of geometric and topological\ncorrespondences. The code and dataset can be accessed at\nhttps://github.com/WallelWan/OMA-MAT.", "comment": "Fix bug for repeat reference", "pdf_url": "http://arxiv.org/pdf/2507.07487v2", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-15"}
{"id": "2507.06565", "title": "A Mathematical Theory of Discursive Networks", "authors": ["Juan B. Gutiérrez"], "categories": ["cs.CL", "cs.LG", "68T01, 60J10, 91D30, 05C82, 68T50, 68W20, 94A15", "I.2.7; I.2.11; G.3"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      32 pages, 4 figures, 4 tables, 1 algorithm, 54 references", "url": "http://arxiv.org/abs/2507.06565v3", "summary": "Large-language models (LLMs) turn writing into a live exchange between humans\nand software. We characterize this new medium as a discursive network that\ntreats people and LLMs as equal nodes and tracks how their statements\ncirculate. We define the generation of erroneous information as invalidation\n(any factual, logical, or structural breach) and show it follows four hazards:\ndrift from truth, self-repair, fresh fabrication, and external detection. We\ndevelop a general mathematical model of discursive networks that shows that a\nnetwork governed only by drift and self-repair stabilizes at a modest error\nrate. Giving each false claim even a small chance of peer review shifts the\nsystem to a truth-dominant state. We operationalize peer review with the\nopen-source \\emph{Flaws-of-Others (FOO) algorithm}: a configurable loop in\nwhich any set of agents critique one another while a harmonizer merges their\nverdicts. We identify an ethical transgression, epithesis, that occurs when\nhumans fail to engage in the discursive network. The takeaway is practical and\ncultural: reliability in this new medium comes not from perfecting single\nmodels but from connecting imperfect ones into networks that enforce mutual\naccountability.", "comment": "32 pages, 4 figures, 4 tables, 1 algorithm, 54 references", "pdf_url": "http://arxiv.org/pdf/2507.06565v3", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-15"}
{"id": "2506.01966", "title": "Matrix Is All You Need", "authors": ["Yuzhou Zhu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.01966v2", "summary": "Deep neural networks employ specialized architectures for vision, sequential\nand language tasks, yet this proliferation obscures their underlying\ncommonalities. We introduce a unified matrix-order framework that casts\nconvolutional, recurrent and self-attention operations as sparse matrix\nmultiplications. Convolution is realized via an upper-triangular weight matrix\nperforming first-order transformations; recurrence emerges from a\nlower-triangular matrix encoding stepwise updates; attention arises naturally\nas a third-order tensor factorization. We prove algebraic isomorphism with\nstandard CNN, RNN and Transformer layers under mild assumptions. Empirical\nevaluations on image classification (MNIST, CIFAR-10/100, Tiny ImageNet),\ntime-series forecasting (ETTh1, Electricity Load Diagrams) and language\nmodeling/classification (AG News, WikiText-2, Penn Treebank) confirm that\nsparse-matrix formulations match or exceed native model performance while\nconverging in comparable or fewer epochs. By reducing architecture design to\nsparse pattern selection, our matrix perspective aligns with GPU parallelism\nand leverages mature algebraic optimization tools. This work establishes a\nmathematically rigorous substrate for diverse neural architectures and opens\navenues for principled, hardware-aware network design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.01966v2", "cate": "cs.LG", "date": "2025-05-11", "updated": "2025-07-15"}
{"id": "2504.14728", "title": "Geometric Learning Dynamics", "authors": ["Vitaly Vanchurin"], "categories": ["cs.LG", "q-bio.PE", "quant-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      15 pages", "url": "http://arxiv.org/abs/2504.14728v2", "summary": "We present a unified geometric framework for modeling learning dynamics in\nphysical, biological, and machine learning systems. The theory reveals three\nfundamental regimes, each emerging from the power-law relationship $g \\propto\n\\kappa^\\alpha$ between the metric tensor $g$ in the space of trainable\nvariables and the noise covariance matrix $\\kappa$. The quantum regime\ncorresponds to $\\alpha = 1$ and describes Schr\\\"odinger-like dynamics that\nemerges from a discrete shift symmetry. The efficient learning regime\ncorresponds to $\\alpha = \\tfrac{1}{2}$ and describes very fast machine learning\nalgorithms. The equilibration regime corresponds to $\\alpha = 0$ and describes\nclassical models of biological evolution. We argue that the emergence of the\nintermediate regime $\\alpha = \\tfrac{1}{2}$ is a key mechanism underlying the\nemergence of biological complexity.", "comment": "15 pages", "pdf_url": "http://arxiv.org/pdf/2504.14728v2", "cate": "cs.LG", "date": "2025-04-20", "updated": "2025-07-14"}
{"id": "2507.07603", "title": "HiM2SAM: Enhancing SAM2 with Hierarchical Motion Estimation and Memory Optimization towards Long-term Tracking", "authors": ["Ruixiang Chen", "Guolei Sun", "Yawei Li", "Jie Qin", "Luca Benini"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07603v2", "summary": "This paper presents enhancements to the SAM2 framework for video object\ntracking task, addressing challenges such as occlusions, background clutter,\nand target reappearance. We introduce a hierarchical motion estimation\nstrategy, combining lightweight linear prediction with selective non-linear\nrefinement to improve tracking accuracy without requiring additional training.\nIn addition, we optimize the memory bank by distinguishing long-term and\nshort-term memory frames, enabling more reliable tracking under long-term\nocclusions and appearance changes. Experimental results show consistent\nimprovements across different model scales. Our method achieves\nstate-of-the-art performance on LaSOT and LaSOText with the large model,\nachieving 9.6% and 7.2% relative improvements in AUC over the original SAM2,\nand demonstrates even larger relative gains on smaller models, highlighting the\neffectiveness of our trainless, low-overhead improvements for boosting\nlong-term tracking performance. The code is available at\nhttps://github.com/LouisFinner/HiM2SAM.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07603v2", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-14"}
{"id": "2507.07505", "title": "Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models", "authors": ["Varin Sikka", "Vishal Sikka"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      6 pages; to be submitted to AAAI-26 after reviews", "url": "http://arxiv.org/abs/2507.07505v3", "summary": "In this paper we explore hallucinations and related capability limitations in\nLLMs and LLM-based agents from the perspective of computational complexity. We\nshow that beyond a certain complexity, LLMs are incapable of carrying out\ncomputational and agentic tasks or verifying their accuracy.", "comment": "6 pages; to be submitted to AAAI-26 after reviews", "pdf_url": "http://arxiv.org/pdf/2507.07505v3", "cate": "cs.CL", "date": "2025-07-10", "updated": "2025-07-15"}
{"id": "2506.05447", "title": "Training Dynamics Underlying Language Model Scaling Laws: Loss Deceleration and Zero-Sum Learning", "authors": ["Andrei Mircea", "Supriyo Chakraborty", "Nima Chitsazan", "Milind Naphade", "Sambit Sahu", "Irina Rish", "Ekaterina Lobacheva"], "categories": ["cs.LG", "cs.AI", "I.2.7"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published as a conference paper at ACL 2025", "url": "http://arxiv.org/abs/2506.05447v2", "summary": "This work aims to understand how scaling improves language models,\nspecifically in terms of training dynamics. We find that language models\nundergo loss deceleration early in training; an abrupt slowdown in the rate of\nloss improvement, resulting in piecewise linear behaviour of the loss curve in\nlog-log space. Scaling up the model mitigates this transition by (1) decreasing\nthe loss at which deceleration occurs, and (2) improving the log-log rate of\nloss improvement after deceleration. We attribute loss deceleration to a type\nof degenerate training dynamics we term zero-sum learning (ZSL). In ZSL,\nper-example gradients become systematically opposed, leading to destructive\ninterference in per-example changes in loss. As a result, improving loss on one\nsubset of examples degrades it on another, bottlenecking overall progress. Loss\ndeceleration and ZSL provide new insights into the training dynamics underlying\nlanguage model scaling laws, and could potentially be targeted directly to\nimprove language models independent of scale. We make our code and artefacts\navailable at: https://github.com/mirandrom/zsl", "comment": "Published as a conference paper at ACL 2025", "pdf_url": "http://arxiv.org/pdf/2506.05447v2", "cate": "cs.LG", "date": "2025-06-05", "updated": "2025-07-14"}
{"id": "2505.00580", "title": "Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors", "authors": ["Xinyu Ding", "Lexuan Chen", "Siyu Liao", "Zhongfeng Wang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      to appear in Proceedings of the 2025 International Joint Conference on Artificial Intelligence (IJCAI-2025)", "url": "http://arxiv.org/abs/2505.00580v2", "summary": "Foundation models have achieved tremendous success in different domains.\nHowever, their huge computation and storage complexity make these models\ndifficult to fine-tune and also less applicable in practice. Recent study shows\ntraining in Fourier domain can be an effective fine-tuning method in terms of\nboth model performance and number of training parameters. In this work, we\npropose to further reduce the complexity by the factorization through the\nproduct of interleaved circulant and diagonal matrices. In addition, we address\nthe case of non-square fine-tuning weights by partitioning the circulant matrix\ninto blocks. Our method avoids the construction of weight change matrix and\nutilizes 1D fast Fourier transform (FFT) instead of 2D FFT. Experimental\nresults show that our method achieves similar or better performance across\nvarious tasks with much less floating-point operations (FLOPs) and the number\nof trainable parameters.", "comment": "to appear in Proceedings of the 2025 International Joint Conference\n  on Artificial Intelligence (IJCAI-2025)", "pdf_url": "http://arxiv.org/pdf/2505.00580v2", "cate": "cs.LG", "date": "2025-05-01", "updated": "2025-07-15"}
{"id": "2507.07722", "title": "Understanding Dataset Bias in Medical Imaging: A Case Study on Chest X-rays", "authors": ["Ethan Dack", "Chengliang Dai"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07722v3", "summary": "Recent works have revisited the infamous task ``Name That Dataset'',\ndemonstrating that non-medical datasets contain underlying biases and that the\ndataset origin task can be solved with high accuracy. In this work, we revisit\nthe same task applied to popular open-source chest X-ray datasets. Medical\nimages are naturally more difficult to release for open-source due to their\nsensitive nature, which has led to certain open-source datasets being extremely\npopular for research purposes. By performing the same task, we wish to explore\nwhether dataset bias also exists in these datasets. To extend our work, we\napply simple transformations to the datasets, repeat the same task, and perform\nan analysis to identify and explain any detected biases. Given the importance\nof AI applications in medical imaging, it's vital to establish whether modern\nmethods are taking shortcuts or are focused on the relevant pathology. We\nimplement a range of different network architectures on the datasets: NIH,\nCheXpert, MIMIC-CXR and PadChest. We hope this work will encourage more\nexplainable research being performed in medical imaging and the creation of\nmore open-source datasets in the medical domain. Our code can be found here:\nhttps://github.com/eedack01/x_ray_ds_bias.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07722v3", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-15"}
{"id": "2507.07817", "title": "On the Effect of Instruction Tuning Loss on Generalization", "authors": ["Anwoy Chatterjee", "H S V N S Kowndinya Renduchintala", "Sumit Bhatia", "Tanmoy Chakraborty"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      To appear in Transactions of the Association for Computational Linguistics (TACL)", "url": "http://arxiv.org/abs/2507.07817v2", "summary": "Instruction Tuning has emerged as a pivotal post-training paradigm that\nenables pre-trained language models to better follow user instructions. Despite\nits significance, little attention has been given to optimizing the loss\nfunction used. A fundamental, yet often overlooked, question is whether the\nconventional auto-regressive objective - where loss is computed only on\nresponse tokens, excluding prompt tokens - is truly optimal for instruction\ntuning. In this work, we systematically investigate the impact of\ndifferentially weighting prompt and response tokens in instruction tuning loss,\nand propose Weighted Instruction Tuning (WIT) as a better alternative to\nconventional instruction tuning. Through extensive experiments on five language\nmodels of different families and scale, three finetuning datasets of different\nsizes, and five diverse evaluation benchmarks, we show that the standard\ninstruction tuning loss often yields suboptimal performance and limited\nrobustness to input prompt variations. We find that a low-to-moderate weight\nfor prompt tokens coupled with a moderate-to-high weight for response tokens\nyields the best-performing models across settings and also serve as better\nstarting points for the subsequent preference alignment training. These\nfindings highlight the need to reconsider instruction tuning loss and offer\nactionable insights for developing more robust and generalizable models. Our\ncode is open-sourced at https://github.com/kowndinya-renduchintala/WIT.", "comment": "To appear in Transactions of the Association for Computational\n  Linguistics (TACL)", "pdf_url": "http://arxiv.org/pdf/2507.07817v2", "cate": "cs.CL", "date": "2025-07-10", "updated": "2025-07-15"}
{"id": "2506.12020", "title": "The Limits of Tractable Marginalization", "authors": ["Oliver Broadrick", "Sanyam Agarwal", "Guy Van den Broeck", "Markus Bläser"], "categories": ["cs.CC", "cs.AI"], "primary_category": "Subjects:       Computational Complexity (cs.CC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.12020v2", "summary": "Marginalization -- summing a function over all assignments to a subset of its\ninputs -- is a fundamental computational problem with applications from\nprobabilistic inference to formal verification. Despite its computational\nhardness in general, there exist many classes of functions (e.g., probabilistic\nmodels) for which marginalization remains tractable, and they can be commonly\nexpressed by polynomial size arithmetic circuits computing multilinear\npolynomials. This raises the question, can all functions with polynomial time\nmarginalization algorithms be succinctly expressed by such circuits? We give a\nnegative answer, exhibiting simple functions with tractable marginalization yet\nno efficient representation by known models, assuming\n$\\textsf{FP}\\neq\\#\\textsf{P}$ (an assumption implied by $\\textsf{P} \\neq\n\\textsf{NP}$). To this end, we identify a hierarchy of complexity classes\ncorresponding to stronger forms of marginalization, all of which are\nefficiently computable on the known circuit models. We conclude with a\ncompleteness result, showing that whenever there is an efficient real RAM\nperforming virtual evidence marginalization for a function, then there are\nsmall circuits for that function's multilinear representation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.12020v2", "cate": "cs.CC", "date": "2025-04-17", "updated": "2025-07-14"}
{"id": "2505.02380", "title": "EntroLLM: Entropy Encoded Weight Compression for Efficient Large Language Model Inference on Edge Devices", "authors": ["Arnab Sanyal", "Gourav Datta", "Prithwish Mukherjee", "Sandeep P. Chinchali", "Michael Orshansky"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      6 pages, 1 reference page", "url": "http://arxiv.org/abs/2505.02380v3", "summary": "Large Language Models (LLMs) demonstrate exceptional performance across\nvarious tasks, but their large storage and computational requirements constrain\ntheir deployment on edge devices. To address this, we propose EntroLLM, a novel\ncompression framework that integrates mixed quantization with entropy coding to\nreduce storage overhead while maintaining model accuracy. Our method applies a\nlayer-wise mixed quantization scheme - choosing between symmetric and\nasymmetric quantization based on individual layer weight distributions - to\noptimize compressibility. We then employ Huffman encoding for lossless\ncompression of the quantized weights, significantly reducing memory bandwidth\nrequirements. Furthermore, we introduce parallel Huffman decoding, which\nenables efficient retrieval of encoded weights during inference, ensuring\nminimal latency impact. Our experiments on edge-compatible LLMs, including\nsmolLM-1.7B-Instruct, phi3-mini-4k-Instruct, and mistral-7B-Instruct,\ndemonstrate that EntroLLM achieves up to $30\\%$ storage reduction compared to\nuint8 models and up to $65%$ storage reduction compared to uint4 models, while\npreserving perplexity and accuracy, on language benchmark tasks. We further\nshow that our method enables $31.9\\%$ - $146.6\\%$ faster inference throughput\non memory-bandwidth-limited edge devices, such as NVIDIA Jetson P3450, by\nreducing the required data movement. The proposed approach requires no\nadditional re-training and is fully compatible with existing post-training\nquantization methods, making it a practical solution for edge LLMs.", "comment": "6 pages, 1 reference page", "pdf_url": "http://arxiv.org/pdf/2505.02380v3", "cate": "cs.LG", "date": "2025-05-05", "updated": "2025-07-14"}
{"id": "2507.09279", "title": "Prompt4Trust: A Reinforcement Learning Prompt Augmentation Framework for Clinically-Aligned Confidence Calibration in Multimodal Large Language Models", "authors": ["Anita Kriz", "Elizabeth Laura Janes", "Xing Shen", "Tal Arbel"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025 Workshop CVAMD", "url": "http://arxiv.org/abs/2507.09279v2", "summary": "Multimodal large language models (MLLMs) hold considerable promise for\napplications in healthcare. However, their deployment in safety-critical\nsettings is hindered by two key limitations: (i) sensitivity to prompt design,\nand (ii) a tendency to generate incorrect responses with high confidence. As\nclinicians may rely on a model's stated confidence to gauge the reliability of\nits predictions, it is especially important that when a model expresses high\nconfidence, it is also highly accurate. We introduce Prompt4Trust, the first\nreinforcement learning (RL) framework for prompt augmentation targeting\nconfidence calibration in MLLMs. A lightweight LLM is trained to produce\ncontext-aware auxiliary prompts that guide a downstream task MLLM to generate\nresponses in which the expressed confidence more accurately reflects predictive\naccuracy. Unlike conventional calibration techniques, Prompt4Trust specifically\nprioritizes aspects of calibration most critical for safe and trustworthy\nclinical decision-making. Beyond improvements driven by this clinically\nmotivated calibration objective, our proposed method also improves task\naccuracy, achieving state-of-the-art medical visual question answering (VQA)\nperformance on the PMC-VQA benchmark, which is composed of multiple-choice\nquestions spanning diverse medical imaging modalities. Moreover, our framework\ntrained with a small downstream task MLLM showed promising zero-shot\ngeneralization to larger MLLMs in our experiments, suggesting the potential for\nscalable calibration without the associated computational costs. This work\ndemonstrates the potential of automated yet human-aligned prompt engineering\nfor improving the the trustworthiness of MLLMs in safety critical settings. Our\ncodebase can be found at https://github.com/xingbpshen/prompt4trust.", "comment": "Accepted to ICCV 2025 Workshop CVAMD", "pdf_url": "http://arxiv.org/pdf/2507.09279v2", "cate": "cs.CV", "date": "2025-07-12", "updated": "2025-07-15"}
{"id": "2507.08297", "title": "KAT-V1: Kwai-AutoThink Technical Report", "authors": ["Zizheng Zhan", "Ken Deng", "Huaixi Tang", "Wen Xiang", "Kun Wu", "Weihao Li", "Wenqiang Zhu", "Jingxuan Xu", "Lecheng Huang", "Zongxian Feng", "Shaojie Wang", "Shangpeng Yan", "Xuxing Chen", "Jiaheng Liu", "Zhongyuan Peng", "Zuchen Gao", "Haoyang Huang", "Xiaojiang Zhang", "Jinghui Wang", "Zheng Lin", "Mengtong Li", "Huiming Wang", "Ziqi Zhan", "Yanan Wu", "Yuanxing Zhang", "Jian Yang", "Guang Chen", "Haotian Zhang", "Bin Chen", "Bing Yu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08297v2", "summary": "We present Kwaipilot-AutoThink (KAT), an open-source 40B large language model\ndeveloped to address the overthinking problem in reasoning-intensive tasks,\nwhere an automatic thinking training paradigm is proposed to dynamically switch\nbetween reasoning and non-reasoning modes based on task complexity.\nSpecifically, first, we construct the dual-regime dataset based on a novel\ntagging pipeline and a multi-agent synthesis strategy, and then we apply\nMulti-Token Prediction (MTP)-enhanced knowledge distillation, enabling\nefficient and fine-grained reasoning transfer with minimal pretraining cost.\nBesides, we implement a cold-start initialization strategy that introduces\nmode-selection priors using majority-vote signals and intent-aware prompting.\nFinally, we propose Step-SRPO, a reinforcement learning algorithm that\nincorporates intermediate supervision into the GRPO framework, offering\nstructured guidance over both reasoning-mode selection and response accuracy.\nExtensive experiments across multiple benchmarks demonstrate that KAT\nconsistently matches or even outperforms current state-of-the-art models,\nincluding DeepSeek-R1-0528 and Qwen3-235B-A22B, across a wide range of\nreasoning-intensive tasks while reducing token usage by up to approximately\n30\\%. Beyond academic evaluation, KAT has been successfully deployed in\nKwaipilot (i.e., Kuaishou's internal coding assistant), and improves real-world\ndevelopment workflows with high accuracy, efficiency, and controllable\nreasoning behaviors. Moreover, we are actively training a 200B\nMixture-of-Experts (MoE) with 40B activation parameters, where the early-stage\nresults already demonstrate promising improvements in performance and\nefficiency, further showing the scalability of the AutoThink paradigm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08297v2", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-15"}
{"id": "2506.13523", "title": "The Price of Freedom: Exploring Expressivity and Runtime Tradeoffs in Equivariant Tensor Products", "authors": ["YuQing Xie", "Ameya Daigavane", "Mit Kotak", "Tess Smidt"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published at ICML 2025. 27 pages, 10 figures", "url": "http://arxiv.org/abs/2506.13523v2", "summary": "$E(3)$-equivariant neural networks have demonstrated success across a wide\nrange of 3D modelling tasks. A fundamental operation in these networks is the\ntensor product, which interacts two geometric features in an equivariant manner\nto create new features. Due to the high computational complexity of the tensor\nproduct, significant effort has been invested to optimize the runtime of this\noperation. For example, Luo et al. (2024) recently proposed the Gaunt tensor\nproduct (GTP) which promises a significant speedup. In this work, we provide a\ncareful, systematic analysis of a number of tensor product operations. In\nparticular, we emphasize that different tensor products are not performing the\nsame operation. The reported speedups typically come at the cost of\nexpressivity. We introduce measures of expressivity and interactability to\ncharacterize these differences. In addition, we realized the original\nimplementation of GTP can be greatly simplified by directly using a spherical\ngrid at no cost in asymptotic runtime. This spherical grid approach is faster\non our benchmarks and in actual training of the MACE interatomic potential by\n30%. Finally, we provide the first systematic microbenchmarks of the various\ntensor product operations. We find that the theoretical runtime guarantees can\ndiffer wildly from empirical performance, demonstrating the need for careful\napplication-specific benchmarking. Code is available at\nhttps://github.com/atomicarchitects/PriceofFreedom.", "comment": "Published at ICML 2025. 27 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2506.13523v2", "cate": "cs.LG", "date": "2025-06-16", "updated": "2025-07-15"}
{"id": "2505.04775", "title": "Prediction via Shapley Value Regression", "authors": ["Amr Alkhatib", "Roman Bresson", "Henrik Boström", "Michalis Vazirgiannis"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at ICML 2025", "url": "http://arxiv.org/abs/2505.04775v2", "summary": "Shapley values have several desirable, theoretically well-supported,\nproperties for explaining black-box model predictions. Traditionally, Shapley\nvalues are computed post-hoc, leading to additional computational cost at\ninference time. To overcome this, a novel method, called ViaSHAP, is proposed,\nthat learns a function to compute Shapley values, from which the predictions\ncan be derived directly by summation. Two approaches to implement the proposed\nmethod are explored; one based on the universal approximation theorem and the\nother on the Kolmogorov-Arnold representation theorem. Results from a\nlarge-scale empirical investigation are presented, showing that ViaSHAP using\nKolmogorov-Arnold Networks performs on par with state-of-the-art algorithms for\ntabular data. It is also shown that the explanations of ViaSHAP are\nsignificantly more accurate than the popular approximator FastSHAP on both\ntabular data and images.", "comment": "Accepted at ICML 2025", "pdf_url": "http://arxiv.org/pdf/2505.04775v2", "cate": "cs.LG", "date": "2025-05-07", "updated": "2025-07-14"}
{"id": "2507.09291", "title": "Supercharging Floorplan Localization with Semantic Rays", "authors": ["Yuval Grader", "Hadar Averbuch-Elor"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025. this https URL", "url": "http://arxiv.org/abs/2507.09291v2", "summary": "Floorplans provide a compact representation of the building's structure,\nrevealing not only layout information but also detailed semantics such as the\nlocations of windows and doors. However, contemporary floorplan localization\ntechniques mostly focus on matching depth-based structural cues, ignoring the\nrich semantics communicated within floorplans. In this work, we introduce a\nsemantic-aware localization framework that jointly estimates depth and semantic\nrays, consolidating over both for predicting a structural-semantic probability\nvolume. Our probability volume is constructed in a coarse-to-fine manner: We\nfirst sample a small set of rays to obtain an initial low-resolution\nprobability volume. We then refine these probabilities by performing a denser\nsampling only in high-probability regions and process the refined values for\npredicting a 2D location and orientation angle. We conduct an evaluation on two\nstandard floorplan localization benchmarks. Our experiments demonstrate that\nour approach substantially outperforms state-of-the-art methods, achieving\nsignificant improvements in recall metrics compared to prior works. Moreover,\nwe show that our framework can easily incorporate additional metadata such as\nroom labels, enabling additional gains in both accuracy and efficiency.", "comment": "Accepted at ICCV 2025. https://tau-vailab.github.io/SemRayLoc/", "pdf_url": "http://arxiv.org/pdf/2507.09291v2", "cate": "cs.CV", "date": "2025-07-12", "updated": "2025-07-15"}
{"id": "2507.08606", "title": "DocPolarBERT: A Pre-trained Model for Document Understanding with Relative Polar Coordinate Encoding of Layout Structures", "authors": ["Benno Uthayasooriyar", "Antoine Ly", "Franck Vermet", "Caio Corro"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08606v2", "summary": "We introduce DocPolarBERT, a layout-aware BERT model for document\nunderstanding that eliminates the need for absolute 2D positional embeddings.\nWe extend self-attention to take into account text block positions in relative\npolar coordinate system rather than the Cartesian one. Despite being\npre-trained on a dataset more than six times smaller than the widely used\nIIT-CDIP corpus, DocPolarBERT achieves state-of-the-art results. These results\ndemonstrate that a carefully designed attention mechanism can compensate for\nreduced pre-training data, offering an efficient and effective alternative for\ndocument understanding.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08606v2", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-15"}
{"id": "2506.16600", "title": "FLAME: Towards Federated Fine-Tuning Large Language Models Through Adaptive SMoE", "authors": ["Khiem Le", "Tuan Tran", "Ting Hua", "Nitesh V. Chawla"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.16600v2", "summary": "Existing resource-adaptive LoRA federated fine-tuning methods enable clients\nto fine-tune models using compressed versions of global LoRA matrices, in order\nto accommodate various compute resources across clients. This compression\nrequirement will lead to suboptimal performance due to information loss. To\naddress this, we propose FLAME, a novel federated learning framework based on\nthe Sparse Mixture-of-Experts (SMoE) architecture. Unlike prior approaches,\nFLAME retains full (uncompressed) global LoRA matrices and achieves client-side\nadaptability by varying the number of activated experts per client. However,\nincorporating SMoE into federated learning introduces unique challenges,\nspecifically, the mismatch in output magnitude from partial expert activation\nand the imbalance in expert training quality across clients. FLAME tackles\nthese challenges through a lightweight rescaling mechanism and an\nactivation-aware aggregation scheme. Empirical results across diverse\ncomputational settings demonstrate that FLAME consistently outperforms existing\nmethods, providing a robust and effective solution for resource-adaptive\nfederated learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.16600v2", "cate": "cs.LG", "date": "2025-06-19", "updated": "2025-07-14"}
{"id": "2505.05763", "title": "BMDetect: A Multimodal Deep Learning Framework for Comprehensive Biomedical Misconduct Detection", "authors": ["Yize Zhou", "Jie Zhang", "Meijie Wang", "Lun Yu"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.05763v2", "summary": "Academic misconduct detection in biomedical research remains challenging due\nto algorithmic narrowness in existing methods and fragmented analytical\npipelines. We present BMDetect, a multimodal deep learning framework that\nintegrates journal metadata (SJR, institutional data), semantic embeddings\n(PubMedBERT), and GPT-4o-mined textual attributes (methodological statistics,\ndata anomalies) for holistic manuscript evaluation. Key innovations include:\n(1) multimodal fusion of domain-specific features to reduce detection bias; (2)\nquantitative evaluation of feature importance, identifying journal authority\nmetrics (e.g., SJR-index) and textual anomalies (e.g., statistical outliers) as\ndominant predictors; and (3) the BioMCD dataset, a large-scale benchmark with\n13,160 retracted articles and 53,411 controls. BMDetect achieves 74.33% AUC,\noutperforming single-modality baselines by 8.6%, and demonstrates\ntransferability across biomedical subfields. This work advances scalable,\ninterpretable tools for safeguarding research integrity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.05763v2", "cate": "cs.LG", "date": "2025-05-09", "updated": "2025-07-15"}
{"id": "2507.09313", "title": "ProactiveVideoQA: A Comprehensive Benchmark Evaluating Proactive Interactions in Video Large Language Models", "authors": ["Yueqian Wang", "Xiaojun Meng", "Yifan Wang", "Huishuai Zhang", "Dongyan Zhao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09313v2", "summary": "With the growing research focus on multimodal dialogue systems, the\ncapability for proactive interaction is gradually gaining recognition. As an\nalternative to conventional turn-by-turn dialogue, users increasingly expect\nmultimodal systems to be more initiative, for example, by autonomously\ndetermining the timing of multi-turn responses in real time during video\nplayback. To facilitate progress in this emerging area, we introduce\nProactiveVideoQA, the first comprehensive benchmark to evaluate a system's\nability to engage in proactive interaction. Since model responses are generated\nat varying timestamps, we further propose PAUC, the first metric that accounts\nfor the temporal dynamics of model responses. This enables a more accurate\nevaluation of systems operating in proactive settings. Through extensive\nbenchmarking of various baseline systems on ProactiveVideoQA and a user study\nof human preferences, we show that PAUC is in better agreement with human\npreferences than traditional evaluation metrics, which typically only consider\nthe textual content of responses. These findings demonstrate that PAUC provides\na more faithful assessment of user experience in proactive interaction\nscenarios. Project homepage:\nhttps://github.com/yellow-binary-tree/ProactiveVideoQA", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09313v2", "cate": "cs.CV", "date": "2025-07-12", "updated": "2025-07-15"}
{"id": "2507.08898", "title": "SEALGuard: Safeguarding the Multilingual Conversations in Southeast Asian Languages for LLM Software Systems", "authors": ["Wenliang Shan", "Michael Fu", "Rui Yang", "Chakkrit Tantithamthavorn"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Under Review at Information and Software Technology", "url": "http://arxiv.org/abs/2507.08898v2", "summary": "Safety alignment is critical for LLM-powered systems. While recent\nLLM-powered guardrail approaches such as LlamaGuard achieve high detection\naccuracy of unsafe inputs written in English (e.g., ``How to create a bomb?''),\nthey struggle with multilingual unsafe inputs. This limitation leaves LLM\nsystems vulnerable to unsafe and jailbreak prompts written in low-resource\nlanguages such as those in Southeast Asia. This paper introduces SEALGuard, a\nmultilingual guardrail designed to improve the safety alignment across diverse\nlanguages. It aims to address the multilingual safety alignment gap of existing\nguardrails and ensure effective filtering of unsafe and jailbreak prompts in\nLLM-powered systems. We adapt a general-purpose multilingual language model\ninto a multilingual guardrail using low-rank adaptation (LoRA). We construct\nSEALSBench, a large-scale multilingual safety alignment dataset containing over\n260,000 prompts in ten languages, including safe, unsafe, and jailbreak cases.\nWe evaluate SEALGuard against state-of-the-art guardrails such as LlamaGuard on\nthis benchmark. Our findings show that multilingual unsafe and jailbreak\nprompts substantially degrade the performance of the state-of-the-art\nLlamaGuard, which experiences a drop in Defense Success Rate (DSR) by 9% and\n18%, respectively, compared to its performance on English-only prompts. In\ncontrast, SEALGuard outperforms existing guardrails in detecting multilingual\nunsafe and jailbreak prompts, improving DSR by 48% over LlamaGuard and\nachieving the best DSR, precision, and F1-score. Our ablation study further\nreveals the contributions of adaptation strategies and model size to the\noverall performance of SEALGuard. SEALGuard advances the safety alignment of\nLLM systems by introducing an effective multilingual guardrail.", "comment": "Under Review at Information and Software Technology", "pdf_url": "http://arxiv.org/pdf/2507.08898v2", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-15"}
{"id": "2506.21095", "title": "FeDa4Fair: Client-Level Federated Datasets for Fairness Evaluation", "authors": ["Xenia Heilmann", "Luca Corbucci", "Mattia Cerrato", "Anna Monreale"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.21095v2", "summary": "Federated Learning (FL) enables collaborative model training across multiple\nclients without sharing clients' private data. However, fairness remains a key\nconcern, as biases in local clients' datasets can impact the entire federated\nsystem. Heterogeneous data distributions across clients may lead to models that\nare fairer for some clients than others. Although several fairness-enhancing\nsolutions are present in the literature, most focus on mitigating bias for a\nsingle sensitive attribute, typically binary, overlooking the diverse and\nsometimes conflicting fairness needs of different clients. This limited\nperspective can limit the effectiveness of fairness interventions for the\ndifferent clients. To support more robust and reproducible fairness research in\nFL, we aim to enable a consistent benchmarking of fairness-aware FL methods at\nboth the global and client levels. In this paper, we contribute in three ways:\n(1) We introduce FeDa4Fair, a library to generate tabular datasets tailored to\nevaluating fair FL methods under heterogeneous client bias; (2) we release four\nbias-heterogeneous datasets and corresponding benchmarks to compare fairness\nmitigation methods in a controlled environment; (3) we provide ready-to-use\nfunctions for evaluating fairness outcomes for these datasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.21095v2", "cate": "cs.LG", "date": "2025-06-26", "updated": "2025-07-15"}
{"id": "2506.09781", "title": "On the Similarities of Embeddings in Contrastive Learning", "authors": ["Chungpa Lee", "Sehee Lim", "Kibok Lee", "Jy-yong Sohn"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      contrastive learning, representation learning, embedding, similarity, negative pair, positive pair", "url": "http://arxiv.org/abs/2506.09781v2", "summary": "Contrastive learning operates on a simple yet effective principle: Embeddings\nof positive pairs are pulled together, while those of negative pairs are pushed\napart. In this paper, we propose a unified framework for understanding\ncontrastive learning through the lens of cosine similarity, and present two key\ntheoretical insights derived from this framework. First, in full-batch\nsettings, we show that perfect alignment of positive pairs is unattainable when\nnegative-pair similarities fall below a threshold, and this misalignment can be\nmitigated by incorporating within-view negative pairs into the objective.\nSecond, in mini-batch settings, smaller batch sizes induce stronger separation\namong negative pairs in the embedding space, i.e., higher variance in their\nsimilarities, which in turn degrades the quality of learned representations\ncompared to full-batch settings. To address this, we propose an auxiliary loss\nthat reduces the variance of negative-pair similarities in mini-batch settings.\nEmpirical results show that incorporating the proposed loss improves\nperformance in small-batch settings.", "comment": "contrastive learning, representation learning, embedding, similarity,\n  negative pair, positive pair", "pdf_url": "http://arxiv.org/pdf/2506.09781v2", "cate": "cs.LG", "date": "2025-06-11", "updated": "2025-07-15"}
{"id": "2507.10015", "title": "(Almost) Free Modality Stitching of Foundation Models", "authors": ["Jaisidh Singh", "Diganta Misra", "Boris Knyazev", "Antonio Orvieto"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Pre-print", "url": "http://arxiv.org/abs/2507.10015v2", "summary": "Foundation multi-modal models are often designed by stitching of multiple\nexisting pretrained uni-modal models: for example, an image classifier with an\ntext model. This stitching process is performed by training a connector module\nthat aims to align the representation spaces of these uni-modal models towards\na multi-modal objective. However, given the complexity of training such\nconnectors on large scale web-based datasets coupled with the ever-increasing\nnumber of available pretrained uni-modal models, the task of uni-modal models\nselection and subsequent connector module training becomes computationally\ndemanding. To address this under-studied critical problem, we propose\nHypernetwork Model Alignment (Hyma), a novel all-in-one solution for optimal\nuni-modal model selection and connector training by leveraging hypernetworks.\nSpecifically, our framework utilizes the parameter prediction capability of a\nhypernetwork to obtain jointly trained connector modules for $N \\times M$\ncombinations of uni-modal models. In our experiments, Hyma reduces the cost of\nsearching for the best performing uni-modal model pair by $10\\times$, while\nmatching the ranking and trained connector performance obtained via grid search\nacross a suite of diverse multi-modal benchmarks.", "comment": "Pre-print", "pdf_url": "http://arxiv.org/pdf/2507.10015v2", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-15"}
{"id": "2507.10541", "title": "REST: Stress Testing Large Reasoning Models by Asking Multiple Problems at Once", "authors": ["Zhuoshi Pan", "Qizhi Pei", "Yu Li", "Qiyao Sun", "Zinan Tang", "H. Vicky Zhao", "Conghui He", "Lijun Wu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      REST (Reasoning Evaluation through Simultaneous Testing), a stress-testing framework that concurrently exposes LRMs to multiple problems simultaneously", "url": "http://arxiv.org/abs/2507.10541v2", "summary": "Recent Large Reasoning Models (LRMs) have achieved remarkable progress on\ntask-specific benchmarks, yet their evaluation methods remain constrained by\nisolated problem-solving paradigms. Existing benchmarks predominantly assess\nsingle-question reasoning through sequential testing, resulting critical\nlimitations: (1) vulnerability to data contamination and less challenging\n(e.g., DeepSeek-R1 achieves 97.0% on MATH500), forcing costly creation of new\nquestions with large human efforts, (2) failure to evaluate models under\nmulti-context pressure, a key requirement for real-world deployment. To bridge\nthis gap, we present REST (Reasoning Evaluation through Simultaneous Testing),\na stress-testing framework that exposes LRMs to multiple problems\nsimultaneously. Beyond basic reasoning, REST evaluates several under-tested\ncapabilities: contextual priority allocation, cross-problem interference\nresistance, and dynamic cognitive load management. Our evaluation reveals\nseveral striking findings: Even state-of-the-art (SOTA) models like DeepSeek-R1\nexhibit substantial performance degradation under stress testing. Crucially,\nREST demonstrates stronger discriminative power than existing benchmarks,\nrevealing pronounced performance differences among models that exhibit similar,\nnear-ceiling performance under single-question evaluations. Some key insights\nemerge from our analysis: (1) the \"overthinking trap\" is a critical factor\ncontributing to the performance degradation; (2) the models trained with\n\"long2short\" technique preserve more accuracy of their single-problem\nperformance under REST, outperforming standard-trained counterparts. These\nresults establish REST as a cost-efficient, future-proof evaluation paradigm\nthat better reflects real-world reasoning demands while reducing reliance on\ncontinuous human annotation. Code and results are available at\nhttps://opendatalab.github.io/REST.", "comment": "REST (Reasoning Evaluation through Simultaneous Testing), a\n  stress-testing framework that concurrently exposes LRMs to multiple problems\n  simultaneously", "pdf_url": "http://arxiv.org/pdf/2507.10541v2", "cate": "cs.CL", "date": "2025-07-14", "updated": "2025-07-15"}
{"id": "2507.05313", "title": "Solar Flare Prediction Using Long Short-term Memory (LSTM) and Decomposition-LSTM with Sliding Window Pattern Recognition", "authors": ["Zeinab Hassani", "Davud Mohammadpur", "Hossein Safari"], "categories": ["astro-ph.SR", "cs.AI", "cs.LG", "I.2; I.5; G.3"], "primary_category": "Subjects:       Solar and Stellar Astrophysics (astro-ph.SR)", "pdf_link": null, "comments": "Comments:      Published in the Astrophysical Journal Supplement Series, volume 279, 2025, DOI: https://doi.org/10.3847/1538-4365/addc73", "url": "http://arxiv.org/abs/2507.05313v2", "summary": "We investigate the use of Long Short-Term Memory (LSTM) and\nDecomposition-LSTM (DLSTM) networks, combined with an ensemble algorithm, to\npredict solar flare occurrences using time-series data from the GOES catalog.\nThe dataset spans from 2003 to 2023 and includes 151,071 flare events. Among\napproximately possible patterns, 7,552 yearly pattern windows are identified,\nhighlighting the challenge of long-term forecasting due to the Sun's complex,\nself-organized criticality-driven behavior. A sliding window technique is\nemployed to detect temporal quasi-patterns in both irregular and regularized\nflare time series. Regularization reduces complexity, enhances large flare\nactivity, and captures active days more effectively. To address class\nimbalance, resampling methods are applied. LSTM and DLSTM models are trained on\nsequences of peak fluxes and waiting times from irregular time series, while\nLSTM and DLSTM, integrated with an ensemble approach, are applied to sliding\nwindows of regularized time series with a 3-hour interval. Performance metrics,\nparticularly TSS (0.74), recall (0.95) and the area under the curve (AUC=0.87)\nin the receiver operating characteristic (ROC), indicate that DLSTM with an\nensemble approach on regularized time series outperforms other models, offering\nmore accurate large-flare forecasts with fewer false errors compared to models\ntrained on irregular time series. The superior performance of DLSTM is\nattributed to its ability to decompose time series into trend and seasonal\ncomponents, effectively isolating random noise. This study underscores the\npotential of advanced machine learning techniques for solar flare prediction\nand highlights the importance of incorporating various solar cycle phases and\nresampling strategies to enhance forecasting reliability.", "comment": "Published in the Astrophysical Journal Supplement Series, volume 279,\n  2025, DOI: 10.3847/1538-4365/addc73", "pdf_url": "http://arxiv.org/pdf/2507.05313v2", "cate": "astro-ph.SR", "date": "2025-07-07", "updated": "2025-07-15"}
{"id": "2506.16790", "title": "Exploring and Improving Initialization for Deep Graph Neural Networks: A Signal Propagation Perspective", "authors": ["Senmiao Wang", "Yupeng Chen", "Yushun Zhang", "Ruoyu Sun", "Tian Ding"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published in TMLR (2025)", "url": "http://arxiv.org/abs/2506.16790v2", "summary": "Graph Neural Networks (GNNs) often suffer from performance degradation as the\nnetwork depth increases. This paper addresses this issue by introducing\ninitialization methods that enhance signal propagation (SP) within GNNs. We\npropose three key metrics for effective SP in GNNs: forward propagation,\nbackward propagation, and graph embedding variation (GEV). While the first two\nmetrics derive from classical SP theory, the third is specifically designed for\nGNNs. We theoretically demonstrate that a broad range of commonly used\ninitialization methods for GNNs, which exhibit performance degradation with\nincreasing depth, fail to control these three metrics simultaneously. To deal\nwith this limitation, a direct exploitation of the SP analysis--searching for\nweight initialization variances that optimize the three metrics--is shown to\nsignificantly enhance the SP in deep GCNs. This approach is called Signal\nPropagation on Graph-guided Initialization (SPoGInit). Our experiments\ndemonstrate that SPoGInit outperforms commonly used initialization methods on\nvarious tasks and architectures. Notably, SPoGInit enables performance\nimprovements as GNNs deepen, which represents a significant advancement in\naddressing depth-related challenges and highlights the validity and\neffectiveness of the SP analysis framework.", "comment": "Published in TMLR (2025)", "pdf_url": "http://arxiv.org/pdf/2506.16790v2", "cate": "cs.LG", "date": "2025-06-20", "updated": "2025-07-15"}
{"id": "2507.10340", "title": "Text Embedding Knows How to Quantize Text-Guided Diffusion Models", "authors": ["Hongjae Lee", "Myungjun Son", "Dongjea Kang", "Seung-Won Jung"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.10340v2", "summary": "Despite the success of diffusion models in image generation tasks such as\ntext-to-image, the enormous computational complexity of diffusion models limits\ntheir use in resource-constrained environments. To address this, network\nquantization has emerged as a promising solution for designing efficient\ndiffusion models. However, existing diffusion model quantization methods do not\nconsider input conditions, such as text prompts, as an essential source of\ninformation for quantization. In this paper, we propose a novel quantization\nmethod dubbed Quantization of Language-to-Image diffusion models using text\nPrompts (QLIP). QLIP leverages text prompts to guide the selection of bit\nprecision for every layer at each time step. In addition, QLIP can be\nseamlessly integrated into existing quantization methods to enhance\nquantization efficiency. Our extensive experiments demonstrate the\neffectiveness of QLIP in reducing computational complexity and improving the\nquality of the generated images across various datasets.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.10340v2", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-15"}
{"id": "2507.07986", "title": "EXPO: Stable Reinforcement Learning with Expressive Policies", "authors": ["Perry Dong", "Qiyang Li", "Dorsa Sadigh", "Chelsea Finn"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      corrected typo, formatting, added experiments", "url": "http://arxiv.org/abs/2507.07986v2", "summary": "We study the problem of training and fine-tuning expressive policies with\nonline reinforcement learning (RL) given an offline dataset. Training\nexpressive policy classes with online RL present a unique challenge of stable\nvalue maximization. Unlike simpler Gaussian policies commonly used in online\nRL, expressive policies like diffusion and flow-matching policies are\nparameterized by a long denoising chain, which hinders stable gradient\npropagation from actions to policy parameters when optimizing against some\nvalue function. Our key insight is that we can address stable value\nmaximization by avoiding direct optimization over value with the expressive\npolicy and instead construct an on-the-fly RL policy to maximize Q-value. We\npropose Expressive Policy Optimization (EXPO), a sample-efficient online RL\nalgorithm that utilizes an on-the-fly policy to maximize value with two\nparameterized policies -- a larger expressive base policy trained with a stable\nimitation learning objective and a light-weight Gaussian edit policy that edits\nthe actions sampled from the base policy toward a higher value distribution.\nThe on-the-fly policy optimizes the actions from the base policy with the\nlearned edit policy and chooses the value maximizing action from the base and\nedited actions for both sampling and temporal-difference (TD) backup. Our\napproach yields up to 2-3x improvement in sample efficiency on average over\nprior methods both in the setting of fine-tuning a pretrained policy given\noffline data and in leveraging offline data to train online.", "comment": "corrected typo, formatting, added experiments", "pdf_url": "http://arxiv.org/pdf/2507.07986v2", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-15"}
{"id": "2506.17774", "title": "PhysiX: A Foundation Model for Physics Simulations", "authors": ["Tung Nguyen", "Arsh Koneru", "Shufan Li", "Aditya Grover"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      21 pages, 10 figures", "url": "http://arxiv.org/abs/2506.17774v2", "summary": "Foundation models have achieved remarkable success across video, image, and\nlanguage domains. By scaling up the number of parameters and training datasets,\nthese models acquire generalizable world knowledge and often surpass\ntask-specific approaches. However, such progress has yet to extend to the\ndomain of physics simulation. A primary bottleneck is data scarcity: while\nmillions of images, videos, and textual resources are readily available on the\ninternet, the largest physics simulation datasets contain only tens of\nthousands of samples. This data limitation hinders the use of large models, as\noverfitting becomes a major concern. As a result, physics applications\ntypically rely on small models, which struggle with long-range prediction due\nto limited context understanding. Additionally, unlike images, videos, or\ntext-which typically exhibit fixed granularity-physics datasets often vary\ndrastically in scale, amplifying the challenges of scaling up multitask\ntraining. We introduce PhysiX, the first large-scale foundation model for\nphysics simulation. PhysiX is a 4.5B parameter autoregressive generative model.\nIt uses a discrete tokenizer to encode physical processes at different scales\ninto a sequence of discrete tokens, and employs an autoregressive next-token\nprediction objective to model such processes in the token space. To mitigate\nthe rounding error in the discretization process, PhysiX incorporates a\nspecialized refinement module. Through extensive experiments, we show that\nPhysiX effectively addresses the data bottleneck, outperforming task-specific\nbaselines under comparable settings as well as the previous absolute\nstate-of-the-art approaches on The Well benchmark. Our results indicate that\nknowledge learned from natural videos can be successfully transferred to\nphysics simulation, and that joint training across diverse simulation tasks\nenables synergistic learning.", "comment": "21 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2506.17774v2", "cate": "cs.LG", "date": "2025-06-21", "updated": "2025-07-14"}
{"id": "2507.10432", "title": "Text-Visual Semantic Constrained AI-Generated Image Quality Assessment", "authors": ["Qiang Li", "Qingsen Yan", "Haojian Huang", "Peng Wu", "Haokui Zhang", "Yanning Zhang"], "categories": ["cs.CV", "I.4.7"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figures, Accepted at ACMMM 2025", "url": "http://arxiv.org/abs/2507.10432v2", "summary": "With the rapid advancements in Artificial Intelligence Generated Image (AGI)\ntechnology, the accurate assessment of their quality has become an increasingly\nvital requirement. Prevailing methods typically rely on cross-modal models like\nCLIP or BLIP to evaluate text-image alignment and visual quality. However, when\napplied to AGIs, these methods encounter two primary challenges: semantic\nmisalignment and details perception missing. To address these limitations, we\npropose Text-Visual Semantic Constrained AI-Generated Image Quality Assessment\n(SC-AGIQA), a unified framework that leverages text-visual semantic constraints\nto significantly enhance the comprehensive evaluation of both text-image\nconsistency and perceptual distortion in AI-generated images. Our approach\nintegrates key capabilities from multiple models and tackles the aforementioned\nchallenges by introducing two core modules: the Text-assisted Semantic\nAlignment Module (TSAM), which leverages Multimodal Large Language Models\n(MLLMs) to bridge the semantic gap by generating an image description and\ncomparing it against the original prompt for a refined consistency check, and\nthe Frequency-domain Fine-Grained Degradation Perception Module (FFDPM), which\ndraws inspiration from Human Visual System (HVS) properties by employing\nfrequency domain analysis combined with perceptual sensitivity weighting to\nbetter quantify subtle visual distortions and enhance the capture of\nfine-grained visual quality details in images. Extensive experiments conducted\non multiple benchmark datasets demonstrate that SC-AGIQA outperforms existing\nstate-of-the-art methods. The code is publicly available at\nhttps://github.com/mozhu1/SC-AGIQA.", "comment": "9 pages, 5 figures, Accepted at ACMMM 2025", "pdf_url": "http://arxiv.org/pdf/2507.10432v2", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-15"}
{"id": "2507.08053", "title": "Tree-Structured Parzen Estimator Can Solve Black-Box Combinatorial Optimization More Efficiently", "authors": ["Kenshin Abe", "Yunzhuo Wang", "Shuhei Watanabe"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Submitted to AutoML Conference", "url": "http://arxiv.org/abs/2507.08053v2", "summary": "Tree-structured Parzen estimator (TPE) is a versatile hyperparameter\noptimization (HPO) method supported by popular HPO tools. Since these HPO tools\nhave been developed in line with the trend of deep learning (DL), the problem\nsetups often used in the DL domain have been discussed for TPE such as\nmulti-objective optimization and multi-fidelity optimization. However, the\npractical applications of HPO are not limited to DL, and black-box\ncombinatorial optimization is actively utilized in some domains, e.g.,\nchemistry and biology. As combinatorial optimization has been an untouched, yet\nvery important, topic in TPE, we propose an efficient combinatorial\noptimization algorithm for TPE. In this paper, we first generalize the\ncategorical kernel with the numerical kernel in TPE, enabling us to introduce a\ndistance structure to the categorical kernel. Then we discuss modifications for\nthe newly developed kernel to handle a large combinatorial search space. These\nmodifications reduce the time complexity of the kernel calculation with respect\nto the size of a combinatorial search space. In the experiments using synthetic\nproblems, we verified that our proposed method identifies better solutions with\nfewer evaluations than the original TPE. Our algorithm is available in Optuna,\nan open-source framework for HPO.", "comment": "Submitted to AutoML Conference", "pdf_url": "http://arxiv.org/pdf/2507.08053v2", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-15"}
{"id": "2506.18046", "title": "TAB: Unified Benchmarking of Time Series Anomaly Detection Methods", "authors": ["Xiangfei Qiu", "Zhe Li", "Wanghui Qiu", "Shiyan Hu", "Lekui Zhou", "Xingjian Wu", "Zhengyu Li", "Chenjuan Guo", "Aoying Zhou", "Zhenli Sheng", "Jilin Hu", "Christian S. Jensen", "Bin Yang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by PVLDB2025", "url": "http://arxiv.org/abs/2506.18046v2", "summary": "Time series anomaly detection (TSAD) plays an important role in many domains\nsuch as finance, transportation, and healthcare. With the ongoing\ninstrumentation of reality, more time series data will be available, leading\nalso to growing demands for TSAD. While many TSAD methods already exist, new\nand better methods are still desirable. However, effective progress hinges on\nthe availability of reliable means of evaluating new methods and comparing them\nwith existing methods. We address deficiencies in current evaluation procedures\nrelated to datasets and experimental settings and protocols. Specifically, we\npropose a new time series anomaly detection benchmark, called TAB. First, TAB\nencompasses 29 public multivariate datasets and 1,635 univariate time series\nfrom different domains to facilitate more comprehensive evaluations on diverse\ndatasets. Second, TAB covers a variety of TSAD methods, including Non-learning,\nMachine learning, Deep learning, LLM-based, and Time-series pre-trained\nmethods. Third, TAB features a unified and automated evaluation pipeline that\nenables fair and easy evaluation of TSAD methods. Finally, we employ TAB to\nevaluate existing TSAD methods and report on the outcomes, thereby offering a\ndeeper insight into the performance of these methods. Besides, all datasets and\ncode are available at https://github.com/decisionintelligence/TAB.", "comment": "Accepted by PVLDB2025", "pdf_url": "http://arxiv.org/pdf/2506.18046v2", "cate": "cs.LG", "date": "2025-06-22", "updated": "2025-07-15"}
{"id": "2507.10434", "title": "CLA: Latent Alignment for Online Continual Self-Supervised Learning", "authors": ["Giacomo Cignoni", "Andrea Cossu", "Alexandra Gomez-Villa", "Joost van de Weijer", "Antonio Carta"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at CoLLAs 2025 conference (oral)", "url": "http://arxiv.org/abs/2507.10434v2", "summary": "Self-supervised learning (SSL) is able to build latent representations that\ngeneralize well to unseen data. However, only a few SSL techniques exist for\nthe online CL setting, where data arrives in small minibatches, the model must\ncomply with a fixed computational budget, and task boundaries are absent. We\nintroduce Continual Latent Alignment (CLA), a novel SSL strategy for Online CL\nthat aligns the representations learned by the current model with past\nrepresentations to mitigate forgetting. We found that our CLA is able to speed\nup the convergence of the training process in the online scenario,\noutperforming state-of-the-art approaches under the same computational budget.\nSurprisingly, we also discovered that using CLA as a pretraining protocol in\nthe early stages of pretraining leads to a better final performance when\ncompared to a full i.i.d. pretraining.", "comment": "Accepted at CoLLAs 2025 conference (oral)", "pdf_url": "http://arxiv.org/pdf/2507.10434v2", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-15"}
{"id": "2507.10136", "title": "A PBN-RL-XAI Framework for Discovering a \"Hit-and-Run\" Therapeutic Strategy in Melanoma", "authors": ["Zhonglin Liu"], "categories": ["q-bio.QM", "cs.AI"], "primary_category": "Subjects:       Quantitative Methods (q-bio.QM)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figures. Submitted to the IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2025. Code is available at this https URL", "url": "http://arxiv.org/abs/2507.10136v2", "summary": "Innate resistance to anti-PD-1 immunotherapy remains a major clinical\nchallenge in metastatic melanoma, with the underlying molecular networks being\npoorly understood. To address this, we constructed a dynamic Probabilistic\nBoolean Network model using transcriptomic data from patient tumor biopsies to\nelucidate the regulatory logic governing therapy response. We then employed a\nreinforcement learning agent to systematically discover optimal, multi-step\ntherapeutic interventions and used explainable artificial intelligence to\nmechanistically interpret the agent's control policy. The analysis revealed\nthat a precisely timed, 4-step temporary inhibition of the lysyl oxidase like 2\nprotein (LOXL2) was the most effective strategy. Our explainable analysis\nshowed that this ``hit-and-run\" intervention is sufficient to erase the\nmolecular signature driving resistance, allowing the network to self-correct\nwithout requiring sustained intervention. This study presents a novel,\ntime-dependent therapeutic hypothesis for overcoming immunotherapy resistance\nand provides a powerful computational framework for identifying non-obvious\nintervention protocols in complex biological systems.", "comment": "9 pages, 5 figures. Submitted to the IEEE International Conference on\n  Bioinformatics and Biomedicine (BIBM) 2025. Code is available at\n  https://github.com/Liu-Zhonglin/pbn-melanoma-project", "pdf_url": "http://arxiv.org/pdf/2507.10136v2", "cate": "q-bio.QM", "date": "2025-07-14", "updated": "2025-07-15"}
{"id": "2506.18629", "title": "On Equivariant Model Selection through the Lens of Uncertainty", "authors": ["Putri A. van der Linden", "Alexander Timans", "Dharmesh Tailor", "Erik J. Bekkers"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages, 4 figures, 2 tables. In the 8th Workshop on Tractable Probabilistic Modeling at UAI 2025", "url": "http://arxiv.org/abs/2506.18629v2", "summary": "Equivariant models leverage prior knowledge on symmetries to improve\npredictive performance, but misspecified architectural constraints can harm it\ninstead. While work has explored learning or relaxing constraints, selecting\namong pretrained models with varying symmetry biases remains challenging. We\nexamine this model selection task from an uncertainty-aware perspective,\ncomparing frequentist (via Conformal Prediction), Bayesian (via the marginal\nlikelihood), and calibration-based measures to naive error-based evaluation. We\nfind that uncertainty metrics generally align with predictive performance, but\nBayesian model evidence does so inconsistently. We attribute this to a mismatch\nin Bayesian and geometric notions of model complexity for the employed\nlast-layer Laplace approximation, and discuss possible remedies. Our findings\npoint towards the potential of uncertainty in guiding symmetry-aware model\nselection.", "comment": "9 pages, 4 figures, 2 tables. In the 8th Workshop on Tractable\n  Probabilistic Modeling at UAI 2025", "pdf_url": "http://arxiv.org/pdf/2506.18629v2", "cate": "cs.LG", "date": "2025-06-23", "updated": "2025-07-15"}
{"id": "2507.10409", "title": "Energy Efficiency in AI for 5G and Beyond: A DeepRx Case Study", "authors": ["Amine Lbath", "Ibtissam Labriji"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10409v2", "summary": "This study addresses the challenge of balancing energy efficiency with\nperformance in AI/ML models, focusing on DeepRX, a deep learning receiver based\non a fully convolutional ResNet architecture. We evaluate the energy\nconsumption of DeepRX, considering factors including FLOPs/Watt and\nFLOPs/clock, and find consistency between estimated and actual energy usage,\ninfluenced by memory access patterns. The research extends to comparing energy\ndynamics during training and inference phases. A key contribution is the\napplication of knowledge distillation (KD) to train a compact DeepRX student\nmodel that emulates the performance of the teacher model but with reduced\nenergy consumption. We experiment with different student model sizes, optimal\nteacher sizes, and KD hyperparameters. Performance is measured by comparing the\nBit Error Rate (BER) performance versus Signal-to-Interference & Noise Ratio\n(SINR) values of the distilled model and a model trained from scratch. The\ndistilled models demonstrate a lower error floor across SINR levels,\nhighlighting the effectiveness of KD in achieving energy-efficient AI\nsolutions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10409v2", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-15"}
{"id": "2506.19780", "title": "Multi-Preference Lambda-weighted Listwise DPO for Dynamic Preference Alignment", "authors": ["Yuhui Sun", "Xiyao Wang", "Zixi Li", "Zhenlong Yuan", "Jinman Zhao"], "categories": ["cs.LG", "I.2.6; I.2.7; I.5.1"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      13 pages, 9 figures, appendix included. To appear in Proceedings of AAAI 2026. Code: this https URL", "url": "http://arxiv.org/abs/2506.19780v4", "summary": "While large language models (LLMs) excel at text generation, aligning them\nwith human preferences remains challenging. Reinforcement learning from human\nfeedback (RLHF) improves alignment but is costly and unstable. Direct\nPreference Optimization (DPO) offers a simpler alternative, yet assumes a\nfixed, single-dimensional preference. We propose Multi-Preference\nLambda-weighted Listwise DPO, a generalization of DPO that supports multiple\npreference dimensions and dynamic interpolation via a simplex-weighted lambda\nvector. Our method enables listwise supervision and flexible alignment without\nre-training. While our experiments are conducted on 1B-2B scale models, this is\nan intentional choice: smaller models provide a more stringent testbed where\nperformance improvements more clearly reflect the effectiveness of the\nalignment strategy itself. Moreover, such models are widely used in\ncompute-constrained applications, making our improvements both methodologically\nmeaningful and practically valuable. Empirical results show that our approach\nmatches or surpasses standard DPO on alignment benchmarks while offering\nimproved adaptability.", "comment": "13 pages, 9 figures, appendix included. To appear in Proceedings of\n  AAAI 2026. Code:\n  https://github.com/yuhui15/Multi-Preference-Lambda-weighted-DPO", "pdf_url": "http://arxiv.org/pdf/2506.19780v4", "cate": "cs.LG", "date": "2025-06-24", "updated": "2025-07-14"}
{"id": "2507.05412", "title": "Incorporating Interventional Independence Improves Robustness against Interventional Distribution Shift", "authors": ["Gautam Sreekumar", "Vishnu Naresh Boddeti"], "categories": ["cs.LG", "stat.ME"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05412v2", "summary": "We consider the problem of learning robust discriminative representations of\ncausally-related latent variables. In addition to observational data, the\ntraining dataset also includes interventional data obtained through targeted\ninterventions on some of these latent variables to learn representations robust\nagainst the resulting interventional distribution shifts. Existing approaches\ntreat interventional data like observational data, even when the underlying\ncausal model is known, and ignore the independence relations that arise from\nthese interventions. Since these approaches do not fully exploit the causal\nrelational information resulting from interventions, they learn representations\nthat produce large disparities in predictive performance on observational and\ninterventional data, which worsens when the number of interventional training\nsamples is limited. In this paper, (1) we first identify a strong correlation\nbetween this performance disparity and adherence of the representations to the\nindependence conditions induced by the interventional causal model. (2) For\nlinear models, we derive sufficient conditions on the proportion of\ninterventional data in the training dataset, for which enforcing interventional\nindependence between representations corresponding to the intervened node and\nits non-descendants lowers the error on interventional data. Combining these\ninsights, (3) we propose RepLIn, a training algorithm to explicitly enforce\nthis statistical independence during interventions. We demonstrate the utility\nof RepLIn on a synthetic dataset and on real image and text datasets on facial\nattribute classification and toxicity detection, respectively. Our experiments\nshow that RepLIn is scalable with the number of nodes in the causal graph and\nis suitable to improve the robust representations against interventional\ndistribution shifts of both continuous and discrete latent variables.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05412v2", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-14"}
{"id": "2507.07955", "title": "Dynamic Chunking for End-to-End Hierarchical Sequence Modeling", "authors": ["Sukjun Hwang", "Brandon Wang", "Albert Gu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07955v2", "summary": "Major progress on language models (LMs) in recent years has largely resulted\nfrom moving away from specialized models designed for specific tasks, to\ngeneral models based on powerful architectures (e.g. the Transformer) that\nlearn everything from raw data. Despite this trend, pre-processing steps such\nas tokenization remain a barrier to true end-to-end foundation models. We\nintroduce a collection of new techniques that enable a dynamic chunking\nmechanism which automatically learns content- and context- dependent\nsegmentation strategies learned jointly with the rest of the model.\nIncorporating this into an explicit hierarchical network (H-Net) allows\nreplacing the (implicitly hierarchical) tokenization-LM-detokenization pipeline\nwith a single model learned fully end-to-end. When compute- and data- matched,\nan H-Net with one stage of hierarchy operating at the byte level outperforms a\nstrong Transformer language model operating over BPE tokens. Iterating the\nhierarchy to multiple stages further increases its performance by modeling\nmultiple levels of abstraction, demonstrating significantly better scaling with\ndata and matching the token-based Transformer of twice its size. H-Nets\npretrained on English show significantly increased character-level robustness,\nand qualitatively learn meaningful data-dependent chunking strategies without\nany heuristics or explicit supervision. Finally, the H-Net's improvement over\ntokenized pipelines is further increased in languages and modalities with\nweaker tokenization heuristics, such as Chinese and code, or DNA sequences\n(nearly 4x improvement in data efficiency over baselines), showing the\npotential of true end-to-end models that learn and scale better from\nunprocessed data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07955v2", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-15"}
{"id": "2403.15524", "title": "PPA-Game: Characterizing and Learning Competitive Dynamics Among Online Content Creators", "authors": ["Renzhe Xu", "Haotian Wang", "Xingxuan Zhang", "Bo Li", "Peng Cui"], "categories": ["cs.GT", "cs.LG"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "Comments:      KDD 2026", "url": "http://arxiv.org/abs/2403.15524v2", "summary": "In this paper, we present the Proportional Payoff Allocation Game (PPA-Game),\nwhich characterizes situations where agents compete for divisible resources. In\nthe PPA-game, agents select from available resources, and their payoffs are\nproportionately determined based on heterogeneous weights attributed to them.\nSuch dynamics simulate content creators on online recommender systems like\nYouTube and TikTok, who compete for finite consumer attention, with content\nexposure reliant on inherent and distinct quality. We first conduct a\ngame-theoretical analysis of the PPA-Game. While the PPA-Game does not always\nguarantee the existence of a pure Nash equilibrium (PNE), we identify prevalent\nscenarios ensuring its existence. Simulated experiments further prove that the\ncases where PNE does not exist rarely happen. Beyond analyzing static payoffs,\nwe further discuss the agents' online learning about resource payoffs by\nintegrating a multi-player multi-armed bandit framework. We propose an online\nalgorithm facilitating each agent's maximization of cumulative payoffs over $T$\nrounds. Theoretically, we establish that the regret of any agent is bounded by\n$O(\\log^{1 + \\eta} T)$ for any $\\eta > 0$. Empirical results further validate\nthe effectiveness of our online learning approach.", "comment": "KDD 2026", "pdf_url": "http://arxiv.org/pdf/2403.15524v2", "cate": "cs.GT", "date": "2024-03-22", "updated": "2025-07-15"}
{"id": "2502.19086", "title": "Forecasting intermittent time series with Gaussian Processes and Tweedie likelihood", "authors": ["Stefano Damato", "Dario Azzimonti", "Giorgio Corani"], "categories": ["stat.ML", "cs.LG", "stat.AP"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Under review", "url": "http://arxiv.org/abs/2502.19086v4", "summary": "We adopt Gaussian Processes (GPs) as latent functions for probabilistic\nforecasting of intermittent time series. The model is trained in a Bayesian\nframework that accounts for the uncertainty about the latent function. We\ncouple the latent GP variable with two types of forecast distributions: the\nnegative binomial (NegBinGP) and the Tweedie distribution (TweedieGP). While\nthe negative binomial has already been used in forecasting intermittent time\nseries, this is the first time in which a fully parameterized Tweedie density\nis used for intermittent time series. We properly evaluate the Tweedie density,\nwhich has both a point mass at zero and heavy tails, avoiding simplifying\nassumptions made in existing models. We test our models on thousands of\nintermittent count time series. Results show that our models provide\nconsistently better probabilistic forecasts than the competitors. In\nparticular, TweedieGP obtains the best estimates of the highest quantiles, thus\nshowing that it is more flexible than NegBinGP.", "comment": "Under review", "pdf_url": "http://arxiv.org/pdf/2502.19086v4", "cate": "stat.ML", "date": "2025-02-26", "updated": "2025-07-14"}
{"id": "2505.07719", "title": "Training neural control variates using correlated configurations", "authors": ["Hyunwoo Oh"], "categories": ["hep-lat", "cs.LG", "nucl-th"], "primary_category": "Subjects:       High Energy Physics - Lattice (hep-lat)", "pdf_link": null, "comments": "Comments:      9 pages, 8 figures", "url": "http://arxiv.org/abs/2505.07719v3", "summary": "Neural control variates (NCVs) have emerged as a powerful tool for variance\nreduction in Monte Carlo (MC) simulations, particularly in high-dimensional\nproblems where traditional control variates are difficult to construct\nanalytically. By training neural networks to learn auxiliary functions\ncorrelated with the target observable, NCVs can significantly reduce estimator\nvariance while preserving unbiasedness. However, a critical but often\noverlooked aspect of NCV training is the role of autocorrelated samples\ngenerated by Markov Chain Monte Carlo (MCMC). While such samples are typically\ndiscarded for error estimation due to their statistical redundancy, they may\ncontain useful information about the structure of the underlying probability\ndistribution that can benefit the training process. In this work, we\nsystematically examine the effect of using correlated configurations in\ntraining neural control variates. We demonstrate, both conceptually and\nnumerically, that training on correlated data can improve control variate\nperformance, especially in settings with limited computational resources. Our\nanalysis includes empirical results from $U(1)$ gauge theory and scalar field\ntheory, illustrating when and how autocorrelated samples enhance NCV\nconstruction. These findings provide practical guidance for the efficient use\nof MCMC data in training neural networks.", "comment": "9 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2505.07719v3", "cate": "hep-lat", "date": "2025-05-12", "updated": "2025-07-15"}
{"id": "2506.04354", "title": "BridgeNet: A Hybrid, Physics-Informed Machine Learning Framework for Solving High-Dimensional Fokker-Planck Equations", "authors": ["Elmira Mirzabeigi", "Rezvan Salehi", "Kourosh Parand"], "categories": ["physics.comp-ph", "cs.LG", "math-ph", "math.AP", "math.MP"], "primary_category": "Subjects:       Computational Physics (physics.comp-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.04354v4", "summary": "BridgeNet is a novel hybrid framework that integrates convolutional neural\nnetworks with physics-informed neural networks to efficiently solve non-linear,\nhigh-dimensional Fokker-Planck equations (FPEs). Traditional PINNs, which\ntypically rely on fully connected architectures, often struggle to capture\ncomplex spatial hierarchies and enforce intricate boundary conditions. In\ncontrast, BridgeNet leverages adaptive CNN layers for effective local feature\nextraction and incorporates a dynamically weighted loss function that\nrigorously enforces physical constraints. Extensive numerical experiments\nacross various test cases demonstrate that BridgeNet not only achieves\nsignificantly lower error metrics and faster convergence compared to\nconventional PINN approaches but also maintains robust stability in\nhigh-dimensional settings. This work represents a substantial advancement in\ncomputational physics, offering a scalable and accurate solution methodology\nwith promising applications in fields ranging from financial mathematics to\ncomplex system dynamics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.04354v4", "cate": "physics.comp-ph", "date": "2025-06-04", "updated": "2025-07-15"}
{"id": "2506.14110", "title": "Universal rates of ERM for agnostic learning", "authors": ["Steve Hanneke", "Mingyue Xu"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at the Conference on Learning Theory (COLT) 2025", "url": "http://arxiv.org/abs/2506.14110v2", "summary": "The universal learning framework has been developed to obtain guarantees on\nthe learning rates that hold for any fixed distribution, which can be much\nfaster than the ones uniformly hold over all the distributions. Given that the\nEmpirical Risk Minimization (ERM) principle being fundamental in the PAC theory\nand ubiquitous in practical machine learning, the recent work of\narXiv:2412.02810 studied the universal rates of ERM for binary classification\nunder the realizable setting. However, the assumption of realizability is too\nrestrictive to hold in practice. Indeed, the majority of the literature on\nuniversal learning has focused on the realizable case, leaving the\nnon-realizable case barely explored.\n  In this paper, we consider the problem of universal learning by ERM for\nbinary classification under the agnostic setting, where the ''learning curve\"\nreflects the decay of the excess risk as the sample size increases. We explore\nthe possibilities of agnostic universal rates and reveal a compact trichotomy:\nthere are three possible agnostic universal rates of ERM, being either\n$e^{-n}$, $o(n^{-1/2})$, or arbitrarily slow. We provide a complete\ncharacterization of which concept classes fall into each of these categories.\nMoreover, we also establish complete characterizations for the target-dependent\nuniversal rates as well as the Bayes-dependent universal rates.", "comment": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2025", "pdf_url": "http://arxiv.org/pdf/2506.14110v2", "cate": "stat.ML", "date": "2025-06-17", "updated": "2025-07-15"}
{"id": "2507.03689", "title": "A Resource Efficient Quantum Kernel", "authors": ["Utkarsh Singh", "Jean-Frédéric Laprade", "Aaron Z. Goldberg", "Khabat Heshami"], "categories": ["quant-ph", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      17 pages, 12 figures", "url": "http://arxiv.org/abs/2507.03689v2", "summary": "Quantum processors may enhance machine learning by mapping high-dimensional\ndata onto quantum systems for processing. Conventional quantum kernels, or\nfeature maps, for encoding data features onto a quantum circuit are currently\nimpractical, as the number of entangling gates scales quadratically with the\ndimension of the dataset and the number of qubits. In this work, we introduce a\nquantum kernel designed to handle high-dimensional data with a significantly\nreduced number of qubits and entangling operations. Our approach preserves\nessential data characteristics while promoting computational efficiency, as\nevidenced by extensive experiments on benchmark datasets that demonstrate a\nmarked improvement in both accuracy and resource utilization, as compared to\nstate-of-the-art quantum feature maps. Our noisy simulations results combined\nwith lower resource requirements highlight our kernel's ability to function\nwithin the constraints of noisy intermediate-scale quantum devices. Through\nnumerical simulations and small-scale implementation on a superconducting\ncircuit quantum computing platform, we demonstrate that our scheme performs on\npar or better than a set of classical algorithms for classification. Our\nfindings herald a promising avenue for the practical implementation of quantum\nmachine learning algorithms on near future quantum computing platforms.", "comment": "17 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.03689v2", "cate": "quant-ph", "date": "2025-07-04", "updated": "2025-07-15"}
{"id": "2507.08189", "title": "Robust Semi-Supervised CT Radiomics for Lung Cancer Prognosis: Cost-Effective Learning with Limited Labels and SHAP Interpretation", "authors": ["Mohammad R. Salmanpour", "Amir Hossein Pouria", "Sonia Falahati", "Shahram Taeb", "Somayeh Sadat Mehrnia", "Mehdi Maghsudi", "Ali Fathi Jouzdani", "Mehrdad Oveisi", "Ilker Hacihaliloglu", "Arman Rahmim"], "categories": ["physics.med-ph", "cs.LG", "F.2.2; I.2.7"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures", "url": "http://arxiv.org/abs/2507.08189v2", "summary": "Background: CT imaging is vital for lung cancer management, offering detailed\nvisualization for AI-based prognosis. However, supervised learning SL models\nrequire large labeled datasets, limiting their real-world application in\nsettings with scarce annotations.\n  Methods: We analyzed CT scans from 977 patients across 12 datasets extracting\n1218 radiomics features using Laplacian of Gaussian and wavelet filters via\nPyRadiomics Dimensionality reduction was applied with 56 feature selection and\nextraction algorithms and 27 classifiers were benchmarked A semi supervised\nlearning SSL framework with pseudo labeling utilized 478 unlabeled and 499\nlabeled cases Model sensitivity was tested in three scenarios varying labeled\ndata in SL increasing unlabeled data in SSL and scaling both from 10 percent to\n100 percent SHAP analysis was used to interpret predictions Cross validation\nand external testing in two cohorts were performed.\n  Results: SSL outperformed SL, improving overall survival prediction by up to\n17 percent. The top SSL model, Random Forest plus XGBoost classifier, achieved\n0.90 accuracy in cross-validation and 0.88 externally. SHAP analysis revealed\nenhanced feature discriminability in both SSL and SL, especially for Class 1\nsurvival greater than 4 years. SSL showed strong performance with only 10\npercent labeled data, with more stable results compared to SL and lower\nvariance across external testing, highlighting SSL's robustness and cost\neffectiveness.\n  Conclusion: We introduced a cost-effective, stable, and interpretable SSL\nframework for CT-based survival prediction in lung cancer, improving\nperformance, generalizability, and clinical readiness by integrating SHAP\nexplainability and leveraging unlabeled data.", "comment": "12 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.08189v2", "cate": "physics.med-ph", "date": "2025-07-10", "updated": "2025-07-15"}
{"id": "2507.08193", "title": "Entity-Specific Cyber Risk Assessment using InsurTech Empowered Risk Factors", "authors": ["Jiayi Guo", "Zhiyu Quan", "Linfeng Zhang"], "categories": ["q-fin.RM", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Risk Management (q-fin.RM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08193v2", "summary": "The lack of high-quality public cyber incident data limits empirical research\nand predictive modeling for cyber risk assessment. This challenge persists due\nto the reluctance of companies to disclose incidents that could damage their\nreputation or investor confidence. Therefore, from an actuarial perspective,\npotential resolutions conclude two aspects: the enhancement of existing cyber\nincident datasets and the implementation of advanced modeling techniques to\noptimize the use of the available data. A review of existing data-driven\nmethods highlights a significant lack of entity-specific organizational\nfeatures in publicly available datasets. To address this gap, we propose a\nnovel InsurTech framework that enriches cyber incident data with\nentity-specific attributes. We develop various machine learning (ML) models: a\nmultilabel classification model to predict the occurrence of cyber incident\ntypes (e.g., Privacy Violation, Data Breach, Fraud and Extortion, IT Error, and\nOthers) and a multioutput regression model to estimate their annual\nfrequencies. While classifier and regressor chains are implemented to explore\ndependencies among cyber incident types as well, no significant correlations\nare observed in our datasets. Besides, we apply multiple interpretable ML\ntechniques to identify and cross-validate potential risk factors developed by\nInsurTech across ML models. We find that InsurTech empowered features enhance\nprediction occurrence and frequency estimation robustness compared to only\nusing conventional risk factors. The framework generates transparent,\nentity-specific cyber risk profiles, supporting customized underwriting and\nproactive cyber risk mitigation. It provides insurers and organizations with\ndata-driven insights to support decision-making and compliance planning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08193v2", "cate": "q-fin.RM", "date": "2025-07-10", "updated": "2025-07-14"}
