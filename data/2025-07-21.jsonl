{"id": "2507.14197", "title": "DM-RSA: An Extension of RSA with Dual Modulus", "authors": ["Andriamifidisoa Ramamonjy", "Rufine Marius Lalasoa"], "categories": ["cs.CR", "cs.IT", "math.IT", "94A60"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      5 pages", "url": "http://arxiv.org/abs/2507.14197v1", "summary": "We introduce DM-RSA (Dual Modulus RSA), a variant of the RSA cryptosystem\nthat employs two distinct moduli symmetrically to enhance security. By\nleveraging the Chinese Remainder Theorem (CRT) for decryption, DM-RSA provides\nincreased robustness against side-channel attacks while preserving the\nefficiency of classical RSA. This approach improves resistance to partial\ncompromise of a modulus and integrates easily into existing infrastructures.", "comment": "5 pages", "pdf_url": "http://arxiv.org/pdf/2507.14197v1", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.14201", "title": "ExCyTIn-Bench: Evaluating LLM agents on Cyber Threat Investigation", "authors": ["Yiran Wu", "Mauricio Velazco", "Andrew Zhao", "Manuel Raúl Meléndez Luján", "Srisuma Movva", "Yogesh K Roy", "Quang Nguyen", "Roberto Rodriguez", "Qingyun Wu", "Michael Albada", "Julia Kiseleva", "Anand Mudgerikar"], "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14201v1", "summary": "We present ExCyTIn-Bench, the first benchmark to Evaluate an LLM agent x on\nthe task of Cyber Threat Investigation through security questions derived from\ninvestigation graphs. Real-world security analysts must sift through a large\nnumber of heterogeneous alert signals and security logs, follow multi-hop\nchains of evidence, and compile an incident report. With the developments of\nLLMs, building LLM-based agents for automatic thread investigation is a\npromising direction. To assist the development and evaluation of LLM agents, we\nconstruct a dataset from a controlled Azure tenant that covers 8 simulated\nreal-world multi-step attacks, 57 log tables from Microsoft Sentinel and\nrelated services, and 589 automatically generated questions. We leverage\nsecurity logs extracted with expert-crafted detection logic to build threat\ninvestigation graphs, and then generate questions with LLMs using paired nodes\non the graph, taking the start node as background context and the end node as\nanswer. Anchoring each question to these explicit nodes and edges not only\nprovides automatic, explainable ground truth answers but also makes the\npipeline reusable and readily extensible to new logs. This also enables the\nautomatic generation of procedural tasks with verifiable rewards, which can be\nnaturally extended to training agents via reinforcement learning. Our\ncomprehensive experiments with different models confirm the difficulty of the\ntask: with the base setting, the average reward across all evaluated models is\n0.249, and the best achieved is 0.368, leaving substantial headroom for future\nresearch. Code and data are coming soon!", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14201v1", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.14202", "title": "PRM-Free Security Alignment of Large Models via Red Teaming and Adversarial Training", "authors": ["Pengfei Du"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14202v1", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\ndiverse applications, yet they pose significant security risks that threaten\ntheir safe deployment in critical domains. Current security alignment\nmethodologies predominantly rely on Process Reward Models (PRMs) to evaluate\nintermediate reasoning steps, introducing substantial computational overhead\nand scalability constraints. This paper presents a novel PRM-free security\nalignment framework that leverages automated red teaming and adversarial\ntraining to achieve robust security guarantees while maintaining computational\nefficiency. Our approach systematically identifies vulnerabilities through\nsophisticated attack strategies including genetic algorithm optimization,\nmulti-agent simulation, and advanced prompt mutation techniques. The framework\nenhances model robustness via targeted adversarial training with curriculum\nlearning and adaptive regularization mechanisms. Comprehensive experimental\nevaluation across five state-of-the-art LLMs demonstrates that our method\nachieves superior security alignment performance compared to PRM-based\napproaches while reducing computational costs by 61\\%. The framework\nincorporates transparent reporting and continuous audit mechanisms that enable\niterative security improvement and regulatory compliance. Our contributions\nadvance the field of efficient LLM security alignment by democratizing access\nto robust security measures for resource-constrained organizations and\nproviding a scalable foundation for addressing evolving adversarial threats.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14202v1", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.14207", "title": "Mitigating Trojanized Prompt Chains in Educational LLM Use Cases: Experimental Findings and Detection Tool Design", "authors": ["Richard M. Charles", "James H. Curry", "Richard B. Charles"], "categories": ["cs.CR", "cs.AI", "I.2.1; I.2.7"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      12 pages, 1 figure", "url": "http://arxiv.org/abs/2507.14207v1", "summary": "The integration of Large Language Models (LLMs) in K--12 education offers\nboth transformative opportunities and emerging risks. This study explores how\nstudents may Trojanize prompts to elicit unsafe or unintended outputs from\nLLMs, bypassing established content moderation systems with safety guardrils.\nThrough a systematic experiment involving simulated K--12 queries and\nmulti-turn dialogues, we expose key vulnerabilities in GPT-3.5 and GPT-4. This\npaper presents our experimental design, detailed findings, and a prototype\ntool, TrojanPromptGuard (TPG), to automatically detect and mitigate Trojanized\neducational prompts. These insights aim to inform both AI safety researchers\nand educational technologists on the safe deployment of LLMs for educators.", "comment": "12 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.14207v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.14212", "title": "Secure Goal-Oriented Communication: Defending against Eavesdropping Timing Attacks", "authors": ["Federico Mason", "Federico Chiariotti", "Pietro Talli", "Andrea Zanella"], "categories": ["cs.CR", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14212v1", "summary": "Goal-oriented Communication (GoC) is a new paradigm that plans data\ntransmission to occur only when it is instrumental for the receiver to achieve\na certain goal. This leads to the advantage of reducing the frequency of\ntransmissions significantly while maintaining adherence to the receiver's\nobjectives. However, GoC scheduling also opens a timing-based side channel that\nan eavesdropper can exploit to obtain information about the state of the\nsystem. This type of attack sidesteps even information-theoretic security, as\nit exploits the timing of updates rather than their content. In this work, we\nstudy such an eavesdropping attack against pull-based goal-oriented scheduling\nfor remote monitoring and control of Markov processes. We provide a theoretical\nframework for defining the effectiveness of the attack and propose possible\ncountermeasures, including two practical heuristics that provide a balance\nbetween the performance gains offered by GoC and the amount of leaked\ninformation. Our results show that, while a naive goal-oriented scheduler\nallows the eavesdropper to correctly guess the system state about 60% of the\ntime, our heuristic defenses can halve the leakage with a marginal reduction of\nthe benefits of goal-oriented approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14212v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.14213", "title": "Magneto-Ionic Hardware Security Primitives: Embedding Data Protection at the Material Level", "authors": ["Irena Spasojevic", "Federica Celegato", "Alessandro Magni", "Paola Tiberto", "Jordi Sort"], "categories": ["cs.CR", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "physics.app-ph"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14213v1", "summary": "The Big Data revolution has heightened the demand for robust,\nenergy-efficient security hardware capable of withstanding increasingly\nsophisticated cyber threats. Conventional encryption schemes, reliant on\ncomplex algorithms, are resource-intensive and remain vulnerable. To fortify\nsensitive information, society needs innovative anti-hacking and\nanti-counterfeiting technologies that exploit new materials and designs. Here,\nwe present a magneto-ionic strategy for hardware-level security based on fully\nselective voltage-controlled N3- ion migration within pre-defined, initially\nparamagnetic FeCoN dots. This process generates ferromagnetic sublayers of\ntuneable thickness, resulting in either deterministic (single-domain or vortex)\nor probabilistic states (with coexisting magnetic configurations and\nvoltage-adjustable probabilities), each exhibiting stochastic orientation and\nchirality, thereby providing a rich platform for magnetic fingerprinting. This\napproach enables self-protected primitives, including true random number\ngenerators, physical unclonable functions, and in-memory probabilistic\ninference. The resulting reconfigurable architecture combines tamper\nresistance, low energy consumption, and scalability, marking a significant leap\ntoward next-generation hardware security rooted in emergent magnetic phenomena.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14213v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.14222", "title": "GPU-Accelerated Interpretable Generalization for Rapid Cyberattack Detection and Forensics", "authors": ["Shu-Ting Huang", "Wen-Cheng Chung", "Hao-Ting Pai"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      ACM CCS 2025 (Submitted)", "url": "http://arxiv.org/abs/2507.14222v1", "summary": "The Interpretable Generalization (IG) mechanism recently published in IEEE\nTransactions on Information Forensics and Security delivers state-of-the-art,\nevidence-based intrusion detection by discovering coherent normal and attack\npatterns through exhaustive intersect-and-subset operations-yet its cubic-time\ncomplexity and large intermediate bitsets render full-scale datasets\nimpractical on CPUs. We present IG-GPU, a PyTorch re-architecture that offloads\nall pairwise intersections and subset evaluations to commodity GPUs.\nImplemented on a single NVIDIA RTX 4070 Ti, in the 15k-record NSL-KDD dataset,\nIG-GPU shows a 116-fold speed-up over the multi-core CPU implementation of IG.\nIn the full size of NSL-KDD (148k-record), given small training data (e.g.,\n10%-90% train-test split), IG-GPU runs in 18 minutes with Recall 0.957,\nPrecision 0.973, and AUC 0.961, whereas IG required down-sampling to\n15k-records to avoid memory exhaustion and obtained Recall 0.935, Precision\n0.942, and AUC 0.940. The results confirm that IG-GPU is robust across scales\nand could provide millisecond-level per-flow inference once patterns are\nlearned. IG-GPU thus bridges the gap between rigorous interpretability and\nreal-time cyber-defense, offering a portable foundation for future work on\nhardware-aware scheduling, multi-GPU sharding, and dataset-specific sparsity\noptimizations.", "comment": "ACM CCS 2025 (Submitted)", "pdf_url": "http://arxiv.org/pdf/2507.14222v1", "cate": "cs.CR", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.14223", "title": "Multi-Granular Discretization for Interpretable Generalization in Precise Cyberattack Identification", "authors": ["Wen-Cheng Chung", "Shu-Ting Huang", "Hao-Ting Pai"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      ACM CCS 2025 (Submitted)", "url": "http://arxiv.org/abs/2507.14223v1", "summary": "Explainable intrusion detection systems (IDS) are now recognized as essential\nfor mission-critical networks, yet most \"XAI\" pipelines still bolt an\napproximate explainer onto an opaque classifier, leaving analysts with partial\nand sometimes misleading insights. The Interpretable Generalization (IG)\nmechanism, published in IEEE Transactions on Information Forensics and\nSecurity, eliminates that bottleneck by learning coherent patterns - feature\ncombinations unique to benign or malicious traffic - and turning them into\nfully auditable rules. IG already delivers outstanding precision, recall, and\nAUC on NSL-KDD, UNSW-NB15, and UKM-IDS20, even when trained on only 10% of the\ndata. To raise precision further without sacrificing transparency, we introduce\nMulti-Granular Discretization (IG-MD), which represents every continuous\nfeature at several Gaussian-based resolutions. On UKM-IDS20, IG-MD lifts\nprecision by greater than or equal to 4 percentage points across all nine\ntrain-test splits while preserving recall approximately equal to 1.0,\ndemonstrating that a single interpretation-ready model can scale across domains\nwithout bespoke tuning.", "comment": "ACM CCS 2025 (Submitted)", "pdf_url": "http://arxiv.org/pdf/2507.14223v1", "cate": "cs.CR", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.14229", "title": "Using Modular Arithmetic Optimized Neural Networks To Crack Affine Cryptographic Schemes Efficiently", "authors": ["Vanja Stojanović", "Žiga Lesar", "CIril Bohak"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14229v1", "summary": "We investigate the cryptanalysis of affine ciphers using a hybrid neural\nnetwork architecture that combines modular arithmetic-aware and statistical\nfeature-based learning. Inspired by recent advances in interpretable neural\nnetworks for modular arithmetic and neural cryptanalysis of classical ciphers,\nour approach integrates a modular branch that processes raw ciphertext\nsequences and a statistical branch that leverages letter frequency features.\nExperiments on datasets derived from natural English text demonstrate that the\nhybrid model attains high key recovery accuracy for short and moderate\nciphertexts, outperforming purely statistical approaches for the affine cipher.\nHowever, performance degrades for very long ciphertexts, highlighting\nchallenges in model generalization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14229v1", "cate": "cs.CR", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14248", "title": "Breaking the Illusion of Security via Interpretation: Interpretable Vision Transformer Systems under Attack", "authors": ["Eldor Abdukhamidov", "Mohammed Abuhamad", "Simon S. Woo", "Hyoungshick Kim", "Tamer Abuhmed"], "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG", "I.2.10; I.2.6; I.5.1; D.4.6; K.6.5"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14248v1", "summary": "Vision transformer (ViT) models, when coupled with interpretation models, are\nregarded as secure and challenging to deceive, making them well-suited for\nsecurity-critical domains such as medical applications, autonomous vehicles,\ndrones, and robotics. However, successful attacks on these systems can lead to\nsevere consequences. Recent research on threats targeting ViT models primarily\nfocuses on generating the smallest adversarial perturbations that can deceive\nthe models with high confidence, without considering their impact on model\ninterpretations. Nevertheless, the use of interpretation models can effectively\nassist in detecting adversarial examples. This study investigates the\nvulnerability of transformer models to adversarial attacks, even when combined\nwith interpretation models. We propose an attack called \"AdViT\" that generates\nadversarial examples capable of misleading both a given transformer model and\nits coupled interpretation model. Through extensive experiments on various\ntransformer models and two transformer-based interpreters, we demonstrate that\nAdViT achieves a 100% attack success rate in both white-box and black-box\nscenarios. In white-box scenarios, it reaches up to 98% misclassification\nconfidence, while in black-box scenarios, it reaches up to 76%\nmisclassification confidence. Remarkably, AdViT consistently generates accurate\ninterpretations in both scenarios, making the adversarial examples more\ndifficult to detect.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14248v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14324", "title": "Quantum-Safe Identity Verification using Relativistic Zero-Knowledge Proof Systems", "authors": ["Yao Ma", "Wen Yu Kon", "Jefferson Chu", "Kevin Han Yong Loh", "Kaushik Chakraborty", "Charles Lim"], "categories": ["cs.CR", "quant-ph"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14324v1", "summary": "Identity verification is the process of confirming an individual's claimed\nidentity, which is essential in sectors like finance, healthcare, and online\nservices to ensure security and prevent fraud. However, current\npassword/PIN-based identity solutions are susceptible to phishing or skimming\nattacks, where malicious intermediaries attempt to steal credentials using fake\nidentification portals. Alikhani et al. [Nature, 2021] began exploring identity\nverification through graph coloring-based relativistic zero-knowledge proofs\n(RZKPs), a key cryptographic primitive that enables a prover to demonstrate\nknowledge of secret credentials to a verifier without disclosing any\ninformation about the secret. Our work advances this field and addresses\nunresolved issues: From an engineering perspective, we relax further the\nrelativistic constraints from 60m to 30m, and significantly enhance the\nstability and scalability of the experimental demonstration of the 2-prover\ngraph coloring-based RZKP protocol for near-term use cases. At the same time,\nfor long-term security against entangled malicious provers, we propose a\nmodified protocol with comparable computation and communication costs, we\nestablish an upper bound on the soundness parameter for this modified protocol.\nOn the other hand, we extend the two-prover, two-verifier setup to a\nthree-prover configuration, demonstrating the security of such relativistic\nprotocols against entangled malicious provers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14324v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14519", "title": "Towards Efficient Privacy-Preserving Machine Learning: A Systematic Review from Protocol, Model, and System Perspectives", "authors": ["Wenxuan Zeng", "Tianshi Xu", "Yi Chen", "Yifan Zhou", "Mingzhe Zhang", "Jin Tan", "Cheng Hong", "Meng Li"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      This work will be continuously updated to reflect the latest advances", "url": "http://arxiv.org/abs/2507.14519v1", "summary": "Privacy-preserving machine learning (PPML) based on cryptographic protocols\nhas emerged as a promising paradigm to protect user data privacy in cloud-based\nmachine learning services. While it achieves formal privacy protection, PPML\noften incurs significant efficiency and scalability costs due to orders of\nmagnitude overhead compared to the plaintext counterpart. Therefore, there has\nbeen a considerable focus on mitigating the efficiency gap for PPML. In this\nsurvey, we provide a comprehensive and systematic review of recent PPML studies\nwith a focus on cross-level optimizations. Specifically, we categorize existing\npapers into protocol level, model level, and system level, and review progress\nat each level. We also provide qualitative and quantitative comparisons of\nexisting works with technical insights, based on which we discuss future\nresearch directions and highlight the necessity of integrating optimizations\nacross protocol, model, and system levels. We hope this survey can provide an\noverarching understanding of existing approaches and potentially inspire future\nbreakthroughs in the PPML field. As the field is evolving fast, we also provide\na public GitHub repository to continuously track the developments, which is\navailable at https://github.com/PKU-SEC-Lab/Awesome-PPML-Papers.", "comment": "This work will be continuously updated to reflect the latest advances", "pdf_url": "http://arxiv.org/pdf/2507.14519v1", "cate": "cs.CR", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14588", "title": "FORTA: Byzantine-Resilient FL Aggregation via DFT-Guided Krum", "authors": ["Usayd Shahul", "J. Harshan"], "categories": ["cs.CR", "cs.IT", "math.IT"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      To appear in the Proceedings of IEEE Information Theory Workshop 2025, Sydney, Australia", "url": "http://arxiv.org/abs/2507.14588v1", "summary": "Secure federated learning enables collaborative model training across\ndecentralized users while preserving data privacy. A key component is secure\naggregation, which keeps individual updates hidden from both the server and\nusers, while also defending against Byzantine users who corrupt the\naggregation. To this end, Jinhyun So et al. recently developed a\nByzantine-resilient secure aggregation scheme using a secret-sharing strategy\nover finite-field arithmetic. However, such an approach can suffer from\nnumerical errors and overflows when applied to real-valued model updates,\nmotivating the need for secure aggregation methods that operate directly over\nthe real domain. We propose FORTA, a Byzantine-resilient secure aggregation\nframework that operates entirely in the real domain. FORTA leverages Discrete\nFourier Transform (DFT) codes for privacy and employs Krum-based outlier\ndetection for robustness. While DFT decoder is error-free under infinite\nprecision, finite precision introduces numerical perturbations that can distort\ndistance estimates and allow malicious updates to evade detection. To address\nthis, FORTA refines Krum using feedback from DFT decoder, improving the\nselection of trustworthy updates. Theoretical analysis and experiments show\nthat our modification of Krum offers improved robustness and more accurate\naggregation than standard Krum.", "comment": "To appear in the Proceedings of IEEE Information Theory Workshop\n  2025, Sydney, Australia", "pdf_url": "http://arxiv.org/pdf/2507.14588v1", "cate": "cs.CR", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14600", "title": "Hybrid Classical-Quantum Rainbow Table Attack on Human Passwords", "authors": ["MA. Khajeian"], "categories": ["cs.CR", "quant-ph"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14600v1", "summary": "Passwords that are long and human-generated pose a challenge for both\nclassical and quantum attacks due to their irregular structure and large search\nspace. In this work, we present an enhanced classical-quantum hybrid attack\ntailored to this scenario. We build rainbow tables using dictionary-based\npassword generation with transformation rules to better model real user\nbehavior. These tables are then organized into buckets, enabling faster lookup\nand reduced space complexity. To perform quantum search within each bucket, we\nuse a distributed exact variant of Grover's algorithm, which offers lower\ncircuit depth and deterministic success. As a result, the overall quantum\ncircuit is shallower and more robust against noise, particularly from\ndepolarizing channels commonly found in near-term quantum devices. Through this\nwork, Overall, we propose a hybrid framework that combines structured rainbow\ntables with efficient quantum search to enhance password recovery.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14600v1", "cate": "cs.CR", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14625", "title": "VTarbel: Targeted Label Attack with Minimal Knowledge on Detector-enhanced Vertical Federated Learning", "authors": ["Juntao Tan", "Anran Li", "Quanchao Liu", "Peng Ran", "Lan Zhang"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14625v1", "summary": "Vertical federated learning (VFL) enables multiple parties with disjoint\nfeatures to collaboratively train models without sharing raw data. While\nprivacy vulnerabilities of VFL are extensively-studied, its security\nthreats-particularly targeted label attacks-remain underexplored. In such\nattacks, a passive party perturbs inputs at inference to force\nmisclassification into adversary-chosen labels. Existing methods rely on\nunrealistic assumptions (e.g., accessing VFL-model's outputs) and ignore\nanomaly detectors deployed in real-world systems. To bridge this gap, we\nintroduce VTarbel, a two-stage, minimal-knowledge attack framework explicitly\ndesigned to evade detector-enhanced VFL inference. During the preparation\nstage, the attacker selects a minimal set of high-expressiveness samples (via\nmaximum mean discrepancy), submits them through VFL protocol to collect\npredicted labels, and uses these pseudo-labels to train estimated detector and\nsurrogate model on local features. In attack stage, these models guide\ngradient-based perturbations of remaining samples, crafting adversarial\ninstances that induce targeted misclassifications and evade detection. We\nimplement VTarbel and evaluate it against four model architectures, seven\nmultimodal datasets, and two anomaly detectors. Across all settings, VTarbel\noutperforms four state-of-the-art baselines, evades detection, and retains\neffective against three representative privacy-preserving defenses. These\nresults reveal critical security blind spots in current VFL deployments and\nunderscore urgent need for robust, attack-aware defenses.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14625v1", "cate": "cs.CR", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14658", "title": "Learning to Communicate in Multi-Agent Reinforcement Learning for Autonomous Cyber Defence", "authors": ["Faizan Contractor", "Li Li", "Ranwa Al Mallah"], "categories": ["cs.MA", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14658v1", "summary": "Popular methods in cooperative Multi-Agent Reinforcement Learning with\npartially observable environments typically allow agents to act independently\nduring execution, which may limit the coordinated effect of the trained\npolicies. However, by sharing information such as known or suspected ongoing\nthreats, effective communication can lead to improved decision-making in the\ncyber battle space. We propose a game design where defender agents learn to\ncommunicate and defend against imminent cyber threats by playing training games\nin the Cyber Operations Research Gym, using the Differentiable Inter Agent\nLearning algorithm adapted to the cyber operational environment. The tactical\npolicies learned by these autonomous agents are akin to those of human experts\nduring incident responses to avert cyber threats. In addition, the agents\nsimultaneously learn minimal cost communication messages while learning their\ndefence tactical policies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14658v1", "cate": "cs.MA", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14629", "title": "VMask: Tunable Label Privacy Protection for Vertical Federated Learning via Layer Masking", "authors": ["Juntao Tan", "Lan Zhang", "Zhonghao Hu", "Kai Yang", "Peng Ran", "Bo Li"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14629v1", "summary": "Though vertical federated learning (VFL) is generally considered to be\nprivacy-preserving, recent studies have shown that VFL system is vulnerable to\nlabel inference attacks originating from various attack surfaces. Among these\nattacks, the model completion (MC) attack is currently the most powerful one.\nExisting defense methods against it either sacrifice model accuracy or incur\nimpractical computational overhead. In this paper, we propose VMask, a novel\nlabel privacy protection framework designed to defend against MC attack from\nthe perspective of layer masking. Our key insight is to disrupt the strong\ncorrelation between input data and intermediate outputs by applying the secret\nsharing (SS) technique to mask layer parameters in the attacker's model. We\ndevise a strategy for selecting critical layers to mask, reducing the overhead\nthat would arise from naively applying SS to the entire model. Moreover, VMask\nis the first framework to offer a tunable privacy budget to defenders, allowing\nfor flexible control over the levels of label privacy according to actual\nrequirements. We built a VFL system, implemented VMask on it, and extensively\nevaluated it using five model architectures and 13 datasets with different\nmodalities, comparing it to 12 other defense methods. The results demonstrate\nthat VMask achieves the best privacy-utility trade-off, successfully thwarting\nthe MC attack (reducing the label inference accuracy to a random guessing\nlevel) while preserving model performance (e.g., in Transformer-based model,\nthe averaged drop of VFL model accuracy is only 0.09%). VMask's runtime is up\nto 60,846 times faster than cryptography-based methods, and it only marginally\nexceeds that of standard VFL by 1.8 times in a large Transformer-based model,\nwhich is generally acceptable.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14629v1", "cate": "cs.CR", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14995", "title": "LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading", "authors": ["Chengwei Lou", "Zekai Jin", "Wei Tang", "Guangfei Geng", "Jin Yang", "Lu Zhang"], "categories": ["cs.MA"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14995v1", "summary": "Real-time peer-to-peer (P2P) electricity markets dynamically adapt to\nfluctuations in renewable energy and variations in demand, maximizing economic\nbenefits through instantaneous price responses while enhancing grid\nflexibility. However, scaling expert guidance for massive personalized\nprosumers poses critical challenges, including diverse decision-making demands\nand lack of customized modeling frameworks. This paper proposed an integrated\nlarge language model-multi-agent reinforcement learning (LLM-MARL) framework\nfor real-time P2P energy trading to address challenges such as the limited\ntechnical capability of prosumers, the lack of expert experience, and security\nissues of distribution networks. LLMs are introduced as experts to generate\npersonalized strategy, guiding MARL under the centralized training with\ndecentralized execution (CTDE) paradigm through imitation learning. A\ndifferential attention-based critic network is designed to enhance convergence\nperformance. Experimental results demonstrate that LLM generated strategies\neffectively substitute human experts. The proposed multi-agent imitation\nlearning algorithms achieve significantly lower economic costs and voltage\nviolation rates on test sets compared to baselines algorithms, while\nmaintaining robust stability. This work provides an effective solution for\nreal-time P2P electricity market decision-making by bridging expert knowledge\nwith agent learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14995v1", "cate": "cs.MA", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14739", "title": "CANDoSA: A Hardware Performance Counter-Based Intrusion Detection System for DoS Attacks on Automotive CAN bus", "authors": ["Franco Oberti", "Stefano Di Carlo", "Alessandro Savino"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted for publication at the 31st IEEE International Symposium on On-Line Testing and Robust System Design 2025 (IOLTS25)", "url": "http://arxiv.org/abs/2507.14739v1", "summary": "The Controller Area Network (CAN) protocol, essential for automotive embedded\nsystems, lacks inherent security features, making it vulnerable to cyber\nthreats, especially with the rise of autonomous vehicles. Traditional security\nmeasures offer limited protection, such as payload encryption and message\nauthentication. This paper presents a novel Intrusion Detection System (IDS)\ndesigned for the CAN environment, utilizing Hardware Performance Counters\n(HPCs) to detect anomalies indicative of cyber attacks. A RISC-V-based CAN\nreceiver is simulated using the gem5 simulator, processing CAN frame payloads\nwith AES-128 encryption as FreeRTOS tasks, which trigger distinct HPC\nresponses. Key HPC features are optimized through data extraction and\ncorrelation analysis to enhance classification efficiency. Results indicate\nthat this approach could significantly improve CAN security and address\nemerging challenges in automotive cybersecurity.", "comment": "Accepted for publication at the 31st IEEE International Symposium on\n  On-Line Testing and Robust System Design 2025 (IOLTS25)", "pdf_url": "http://arxiv.org/pdf/2507.14739v1", "cate": "cs.CR", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15015", "title": "EduThink4AI: Translating Educational Critical Thinking into Multi-Agent LLM Systems", "authors": ["Xinmeng Hou", "Zhouquan Lu", "Wenli Chen", "Hai Hu", "Qing Guo"], "categories": ["cs.MA"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15015v1", "summary": "Large language models (LLMs) have demonstrated significant potential as\neducational tutoring agents, capable of tailoring hints, orchestrating lessons,\nand grading with near-human finesse across various academic domains. However,\ncurrent LLM-based educational systems exhibit critical limitations in promoting\ngenuine critical thinking, failing on over one-third of multi-hop questions\nwith counterfactual premises, and remaining vulnerable to adversarial prompts\nthat trigger biased or factually incorrect responses. To address these gaps, we\npropose EDU-Prompting, a novel multi-agent framework that bridges established\neducational critical thinking theories with LLM agent design to generate\ncritical, bias-aware explanations while fostering diverse perspectives. Our\nsystematic evaluation across theoretical benchmarks and practical college-level\ncritical writing scenarios demonstrates that EDU-Prompting significantly\nenhances both content truthfulness and logical soundness in AI-generated\neducational responses. The framework's modular design enables seamless\nintegration into existing prompting frameworks and educational applications,\nallowing practitioners to directly incorporate critical thinking catalysts that\npromote analytical reasoning and introduce multiple perspectives without\nrequiring extensive system modifications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15015v1", "cate": "cs.MA", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14796", "title": "Careful Whisper: Attestation for peer-to-peer Confidential Computing networks", "authors": ["Ceren Kocaoğullar", "Gustavo Petri", "Dominic P. Mulligan", "Derek Miller", "Hugo J. M. Vincent", "Shale Xiong", "Alastair R. Beresford"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14796v1", "summary": "Trusted Execution Environments (TEEs) are designed to protect the privacy and\nintegrity of data in use. They enable secure data processing and sharing in\npeer-to-peer networks, such as vehicular ad hoc networks of autonomous\nvehicles, without compromising confidentiality. In these networks, nodes must\nestablish mutual trust to collaborate securely. TEEs can achieve this through\nremote attestation, where a prover presents evidence of its trustworthiness to\na verifier, which then decides whether or not to trust the prover. However, a\nnaive peer-to-peer attestation approach, where every TEE directly attests every\nother TEE, results in quadratic communication overhead. This is inefficient in\ndynamic environments, where nodes frequently join and leave the network.\n  To address this, we present Careful Whisper, a gossip-based protocol that\ndisseminates trust efficiently, reducing attestation overhead to linear\ncomplexity under ideal conditions. It enables interoperability by enabling\ntransitive trust across heterogeneous networks, and supports trust\nestablishment with offline nodes via relayed attestations. Using a custom\ndiscrete-event simulator, we show that Careful Whisper propagates trust both\nfaster and more widely than naive approaches across various network topologies.\nOur results demonstrate that our protocol is resource efficient, sending ~21.5\nKiB and requiring 0.158 seconds per round in a 200-node network, and that our\nprotocol is resilient to attestation failures across various network\ntopologies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14796v1", "cate": "cs.CR", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15815", "title": "LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra", "authors": ["Seth Karten", "Wenzhe Li", "Zihan Ding", "Samuel Kleiner", "Yu Bai", "Chi Jin"], "categories": ["cs.MA", "cs.LG"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      27 pages, 6 figures, Code: this https URL", "url": "http://arxiv.org/abs/2507.15815v1", "summary": "We present the LLM Economist, a novel framework that uses agent-based\nmodeling to design and assess economic policies in strategic environments with\nhierarchical decision-making. At the lower level, bounded rational worker\nagents -- instantiated as persona-conditioned prompts sampled from U.S.\nCensus-calibrated income and demographic statistics -- choose labor supply to\nmaximize text-based utility functions learned in-context. At the upper level, a\nplanner agent employs in-context reinforcement learning to propose\npiecewise-linear marginal tax schedules anchored to the current U.S. federal\nbrackets. This construction endows economic simulacra with three capabilities\nrequisite for credible fiscal experimentation: (i) optimization of\nheterogeneous utilities, (ii) principled generation of large, demographically\nrealistic agent populations, and (iii) mechanism design -- the ultimate nudging\nproblem -- expressed entirely in natural language. Experiments with populations\nof up to one hundred interacting agents show that the planner converges near\nStackelberg equilibria that improve aggregate social welfare relative to Saez\nsolutions, while a periodic, persona-level voting procedure furthers these\ngains under decentralized governance. These results demonstrate that large\nlanguage model-based agents can jointly model, simulate, and govern complex\neconomic systems, providing a tractable test bed for policy evaluation at the\nsocietal scale to help build better civilizations.", "comment": "27 pages, 6 figures, Code:\n  https://github.com/sethkarten/LLM-Economist", "pdf_url": "http://arxiv.org/pdf/2507.15815v1", "cate": "cs.MA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14799", "title": "Manipulating LLM Web Agents with Indirect Prompt Injection Attack via HTML Accessibility Tree", "authors": ["Sam Johnson", "Viet Pham", "Thai Le"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      EMNLP 2025 System Demonstrations Submission", "url": "http://arxiv.org/abs/2507.14799v1", "summary": "This work demonstrates that LLM-based web navigation agents offer powerful\nautomation capabilities but are vulnerable to Indirect Prompt Injection (IPI)\nattacks. We show that adversaries can embed universal adversarial triggers in\nwebpage HTML to hijack agent behavior that utilizes the accessibility tree to\nparse HTML, causing unintended or malicious actions. Using the Greedy\nCoordinate Gradient (GCG) algorithm and a Browser Gym agent powered by\nLlama-3.1, our system demonstrates high success rates across real websites in\nboth targeted and general attacks, including login credential exfiltration and\nforced ad clicks. Our empirical results highlight critical security risks and\nthe need for stronger defenses as LLM-driven autonomous web agents become more\nwidely adopted. The system software\n(https://github.com/sej2020/manipulating-web-agents) is released under the MIT\nLicense, with an accompanying publicly available demo website\n(http://lethaiq.github.io/attack-web-llm-agent).", "comment": "EMNLP 2025 System Demonstrations Submission", "pdf_url": "http://arxiv.org/pdf/2507.14799v1", "cate": "cs.CR", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14263", "title": "Beyond DNS: Unlocking the Internet of AI Agents via the NANDA Index and Verified AgentFacts", "authors": ["Ramesh Raskar", "Pradyumna Chari", "John Zinky", "Mahesh Lambe", "Jared James Grogan", "Sichao Wang", "Rajesh Ranjan", "Rekha Singhal", "Shailja Gupta", "Robert Lincourt", "Raghu Bala", "Aditi Joshi", "Abhishek Singh", "Ayush Chopra", "Dimitris Stripelis", "Bhuwan B", "Sumit Kumar", "Maria Gorskikh"], "categories": ["cs.NI", "cs.AI", "cs.CR", "cs.MA"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14263v1", "summary": "The Internet is poised to host billions to trillions of autonomous AI agents\nthat negotiate, delegate, and migrate in milliseconds and workloads that will\nstrain DNS-centred identity and discovery. In this paper, we describe the NANDA\nindex architecture, which we envision as a means for discoverability,\nidentifiability and authentication in the internet of AI agents. We present an\narchitecture where a minimal lean index resolves to dynamic, cryptographically\nverifiable AgentFacts that supports multi-endpoint routing, load balancing,\nprivacy-preserving access, and credentialed capability assertions. Our\narchitecture design delivers five concrete guarantees: (1) A quilt-like index\nproposal that supports both NANDA-native agents as well as third party agents\nbeing discoverable via the index, (2) rapid global resolution for newly spawned\nAI agents, (3) sub-second revocation and key rotation, (4) schema-validated\ncapability assertions, and (5) privacy-preserving discovery across\norganisational boundaries via verifiable, least-disclosure queries. We\nformalize the AgentFacts schema, specify a CRDT-based update protocol, and\nprototype adaptive resolvers. The result is a lightweight, horizontally\nscalable foundation that unlocks secure, trust-aware collaboration for the next\ngeneration of the Internet of AI agents, without abandoning existing web\ninfrastructure.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14263v1", "cate": "cs.NI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14249", "title": "Real-Time Communication-Aware Ride-Sharing Route Planning for Urban Air Mobility: A Multi-Source Hybrid Attention Reinforcement Learning Approach", "authors": ["Yuejiao Xie", "Maonan Wang", "Di Zhou", "Man-On Pun", "Zhu Han"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14249v1", "summary": "Urban Air Mobility (UAM) systems are rapidly emerging as promising solutions\nto alleviate urban congestion, with path planning becoming a key focus area.\nUnlike ground transportation, UAM trajectory planning has to prioritize\ncommunication quality for accurate location tracking in constantly changing\nenvironments to ensure safety. Meanwhile, a UAM system, serving as an air taxi,\nrequires adaptive planning to respond to real-time passenger requests,\nespecially in ride-sharing scenarios where passenger demands are unpredictable\nand dynamic. However, conventional trajectory planning strategies based on\npredefined routes lack the flexibility to meet varied passenger ride demands.\nTo address these challenges, this work first proposes constructing a radio map\nto evaluate the communication quality of urban airspace. Building on this, we\nintroduce a novel Multi-Source Hybrid Attention Reinforcement Learning\n(MSHA-RL) framework for the challenge of effectively focusing on passengers and\nUAM locations, which arises from the significant dimensional disparity between\nthe representations. This model first generates the alignment among diverse\ndata sources with large gap dimensions before employing hybrid attention to\nbalance global and local insights, thereby facilitating responsive, real-time\npath planning. Extensive experimental results demonstrate that the approach\nenables communication-compliant trajectory planning, reducing travel time and\nenhancing operational efficiency while prioritizing passenger safety.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14249v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14822", "title": "Quantum Skyshield: Quantum Key Distribution and Post-Quantum Authentication for Low-Altitude Wireless Networks in Adverse Skies", "authors": ["Zeeshan Kaleem", "Misha Urooj Khan", "Ahmad Suleman", "Waqas Khalid", "Kai-Kit Wong", "Chau Yuen"], "categories": ["cs.CR", "cs.ET", "quant-ph"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14822v1", "summary": "Recently, low-altitude wireless networks (LAWNs) have emerged as a critical\nbackbone for supporting the low-altitude economy, particularly with the\ndensification of unmanned aerial vehicles (UAVs) and high-altitude platforms\n(HAPs). To meet growing data demands, some LAWN deployments incorporate\nfree-space optical (FSO) links, which offer exceptional bandwidth and beam\ndirectivity. However, without strong security measures in place, both\nconventional radio frequency channels and FSO beams remain vulnerable to\ninterception and spoofing and FSO in particular can suffer from turbulence,\nmisalignment, and weather-related attenuation. To address these challenges in\nthe quantum era, a quantum-secure architecture called Quantum Skyshield is\nproposed to enable reliable communication between the base transceiver station\n(BTS) and LAWN. The proposed design integrates BB84 quantum key distribution\n(QKD) with post-quantum authentication mechanisms. Simulation results confirm\nthe reliable generation of a 128-bit symmetric key when the quantum bit error\nrate (QBER) remains below the threshold of 11%. Authentication is enforced\nusing Lamport one-time signatures and hash-based message authentication codes\n(HMAC) to ensure message integrity. A Grover-inspired threat detection\nmechanism identifies anomalies with up to 89% probability in a single\niteration, enabling real-time trust evaluation. Lastly, future research\nchallenges have also been identified and discussed to guide further development\nin this area.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14822v1", "cate": "cs.CR", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14470", "title": "Approximate Revenue Maximization for Diffusion Auctions", "authors": ["Yifan Huang", "Dong Hao", "Zhiyi Fan", "Yuhang Guo", "Bin Li"], "categories": ["econ.TH", "cs.AI", "cs.GT", "cs.MA"], "primary_category": "Subjects:       Theoretical Economics (econ.TH)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14470v1", "summary": "Reserve prices are widely used in practice. The problem of designing\nrevenue-optimal auctions based on reserve price has drawn much attention in the\nauction design community. Although they have been extensively studied, most\ndevelopments rely on the significant assumption that the target audience of the\nsale is directly reachable by the auctioneer, while a large portion of bidders\nin the economic network unaware of the sale are omitted. This work follows the\ndiffusion auction design, which aims to extend the target audience of optimal\nauction theory to all entities in economic networks. We investigate the design\nof simple and provably near-optimal network auctions via reserve price. Using\nBayesian approximation analysis, we provide a simple and explicit form of the\nreserve price function tailored to the most representative network auction. We\naim to balance setting a sufficiently high reserve price to induce high revenue\nin a successful sale, and attracting more buyers from the network to increase\nthe probability of a successful sale. This reserve price function preserves\nincentive compatibility for network auctions, allowing the seller to extract\nadditional revenue beyond that achieved by the Myerson optimal auction.\nSpecifically, if the seller has $\\rho$ direct neighbours in a network of size\n$n$, this reserve price guarantees a $1-{1 \\over \\rho}$ approximation to the\ntheoretical upper bound, i.e., the maximum possible revenue from any network of\nsize $n$. This result holds for any size and any structure of the networked\nmarket.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14470v1", "cate": "econ.TH", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14274", "title": "A Recursive Lie-Group Formulation for the Second-Order Time Derivatives of the Inverse Dynamics of parallel Kinematic Manipulators", "authors": ["Andreas Mueller", "Shivesh Kumar", "Thomas Kordik"], "categories": ["cs.RO", "cs.NA", "math.DG", "math.DS", "math.GR", "math.NA"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14274v1", "summary": "Series elastic actuators (SEA) were introduced for serial robotic arms. Their\nmodel-based trajectory tracking control requires the second time derivatives of\nthe inverse dynamics solution, for which algorithms were proposed. Trajectory\ncontrol of parallel kinematics manipulators (PKM) equipped with SEAs has not\nyet been pursued. Key element for this is the computationally efficient\nevaluation of the second time derivative of the inverse dynamics solution. This\nhas not been presented in the literature, and is addressed in the present paper\nfor the first time. The special topology of PKM is exploited reusing the\nrecursive algorithms for evaluating the inverse dynamics of serial robots. A\nLie group formulation is used and all relations are derived within this\nframework. Numerical results are presented for a 6-DOF Gough-Stewart platform\n(as part of an exoskeleton), and for a planar PKM when a flatness-based control\nscheme is applied.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14274v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14853", "title": "A Privacy-Centric Approach: Scalable and Secure Federated Learning Enabled by Hybrid Homomorphic Encryption", "authors": ["Khoa Nguyen", "Tanveer Khan", "Antonis Michalas"], "categories": ["cs.CR", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14853v1", "summary": "Federated Learning (FL) enables collaborative model training without sharing\nraw data, making it a promising approach for privacy-sensitive domains. Despite\nits potential, FL faces significant challenges, particularly in terms of\ncommunication overhead and data privacy. Privacy-preserving Techniques (PPTs)\nsuch as Homomorphic Encryption (HE) have been used to mitigate these concerns.\nHowever, these techniques introduce substantial computational and communication\ncosts, limiting their practical deployment. In this work, we explore how Hybrid\nHomomorphic Encryption (HHE), a cryptographic protocol that combines symmetric\nencryption with HE, can be effectively integrated with FL to address both\ncommunication and privacy challenges, paving the way for scalable and secure\ndecentralized learning system.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14853v1", "cate": "cs.CR", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14472", "title": "Strategyproofness and Monotone Allocation of Auction in Social Networks", "authors": ["Yuhang Guo", "Dong Hao", "Bin Li", "Mingyu Xiao", "Bakh Khoussainov"], "categories": ["cs.GT", "cs.AI", "cs.MA", "econ.TH"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "Comments:      Accepted by IJCAI 2025", "url": "http://arxiv.org/abs/2507.14472v1", "summary": "Strategyproofness in network auctions requires that bidders not only report\ntheir valuations truthfully, but also do their best to invite neighbours from\nthe social network. In contrast to canonical auctions, where the value-monotone\nallocation in Myerson's Lemma is a cornerstone, a general principle of\nallocation rules for strategyproof network auctions is still missing. We show\nthat, due to the absence of such a principle, even extensions to multi-unit\nnetwork auctions with single-unit demand present unexpected difficulties, and\nall pioneering researches fail to be strategyproof. For the first time in this\nfield, we identify two categories of monotone allocation rules on networks:\nInvitation-Depressed Monotonicity (ID-MON) and Invitation-Promoted Monotonicity\n(IP-MON). They encompass all existing allocation rules of network auctions as\nspecific instances. For any given ID-MON or IP-MON allocation rule, we\ncharacterize the existence and sufficient conditions for the strategyproof\npayment rules, and show that among all such payment rules, the\nrevenue-maximizing one exists and is computationally feasible. With these\nresults, the obstacle of combinatorial network auction with single-minded\nbidders is now resolved.", "comment": "Accepted by IJCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.14472v1", "cate": "cs.GT", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14412", "title": "Personalized Socially Assistive Robots With End-to-End Speech-Language Models For Well-Being Support", "authors": ["Mengxue Fu", "Zhonghao Shi", "Minyu Huang", "Siqi Liu", "Mina Kian", "Yirui Song", "Maja J. Matarić"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14412v1", "summary": "Socially assistive robots (SARs) have shown great potential for supplementing\nwell-being support. However, prior studies have found that existing dialogue\npipelines for SARs remain limited in real-time latency, back-channeling, and\npersonalized speech dialogue. Toward addressing these limitations, we propose\nusing integrated end-to-end speech-language models (SLMs) with SARs. This work\n1) evaluated the usability of an SLM-enabled SAR dialogue system through a\nsmall user study, and 2) identified remaining limitations through study user\nfeedback to inform future improvements. We conducted a small within-participant\nuser study with university students (N = 11) whose results showed that\nparticipants perceived an SLM-enabled SAR system as capable of providing\nempathetic feedback, natural turn-taking, back-channeling, and adaptive\nresponses. We also found that participants reported the robot's nonverbal\nbehaviors as lacking variability and synchronization with conversation, and the\nSLM's verbal feedback as generic and repetitive. These findings highlighted the\nneed for real-time robot movement synchronized with conversation, improved\nprompting or fine-tuning to generate outputs better aligned with mental health\npractices, and more expressive, adaptive vocal generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14412v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14893", "title": "A Compact Post-quantum Strong Designated Verifier Signature Scheme from Isogenies", "authors": ["Farzin Renan"], "categories": ["cs.CR", "math.NT", "11T71, 94A60, 68P25, 14G50, 81P94"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14893v1", "summary": "Digital signatures are essential cryptographic tools that provide\nauthentication and integrity in digital communications. However,\nprivacy-sensitive applications, such as e-voting and digital cash, require more\nrestrictive verification models to ensure confidentiality and control. Strong\nDesignated Verifier Signature (SDVS) schemes address this need by enabling the\nsigner to designate a specific verifier, ensuring that only this party can\nvalidate the signature. Existing SDVS constructions are primarily based on\nnumber-theoretic assumptions and are therefore vulnerable to quantum attacks.\nAlthough post-quantum alternatives, particularly those based on lattices, have\nbeen proposed, they often entail large key and signature sizes. In this work,\nwe introduce $\\mathsf{CSI\\text{-}SDVS}$, a novel isogeny-based SDVS scheme that\noffers a compact, quantum-resistant alternative. Our construction builds on the\nideal class group action framework of CSIDH and the signature techniques of\nCSI-FiSh, and relies on the hardness of the Multi-Target Group Action Inverse\nProblem (MT-GAIP). $\\mathsf{CSI\\text{-}SDVS}$ achieves strong security\nguarantees; namely, Strong Unforgeability under Chosen-Message Attacks\n(SUF-CMA), Non-Transferability (NT), and Privacy of Signer's Identity (PSI), in\nthe random oracle model. Remarkably, both the keys and signatures in\n$\\mathsf{CSI\\text{-}SDVS}$ are of size $\\mathcal{O}(\\lambda)$, representing a\nsignificant improvement over the typical $\\mathcal{O}(\\lambda^2)$ bounds in\nexisting post-quantum SDVS schemes, thereby making it among the most compact\nPQC-based SDVS schemes and the only post-quantum secure construction based on\nisogenies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14893v1", "cate": "cs.CR", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15143", "title": "Can We Move Freely in NEOM's The Line? An Agent-Based Simulation of Human Mobility in a Futuristic Smart City", "authors": ["Abderaouf Bahi", "Amel Ourici"], "categories": ["cs.AI", "cs.MA"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15143v1", "summary": "This paper investigates the feasibility of human mobility in The Line, a\nproposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assess\nwhether citizens can move freely within this unprecedented urban topology, we\ndevelop a hybrid simulation framework that integrates agent-based modeling,\nreinforcement learning, supervised learning, and graph neural networks. The\nsimulation captures multi-modal transportation behaviors across 50 vertical\nlevels and varying density scenarios using both synthetic data and real-world\ntraces from high-density cities. Our experiments reveal that with the full\nAI-integrated architecture, agents achieved an average commute time of 7.8 to\n8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability index\nof over 91 percent, even during peak congestion periods. Ablation studies\nconfirmed that the removal of intelligent modules such as reinforcement\nlearning or graph neural networks significantly degrades performance, with\ncommute times increasing by up to 85 percent and reachability falling below 70\npercent. Environmental modeling further demonstrated low energy consumption and\nminimal CO2 emissions when electric modes are prioritized. The findings suggest\nthat freedom of movement is not only conceptually achievable in The Line, but\nalso operationally realistic if supported by adaptive AI systems, sustainable\ninfrastructure, and real-time feedback loops.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15143v1", "cate": "cs.AI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14455", "title": "Koopman Operator Based Time-Delay Embeddings and State History Augmented LQR for Periodic Hybrid Systems: Bouncing Pendulum and Bipedal Walking", "authors": ["Chun-Ming Yang", "Pranav A. Bhounsule"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14455v1", "summary": "Time-delay embedding is a technique that uses snapshots of state history over\ntime to build a linear state space model of a nonlinear smooth system. We\ndemonstrate that periodic non-smooth or hybrid system can also be modeled as a\nlinear state space system using this approach as long as its behavior is\nconsistent in modes and timings. We extended time-delay embeddings to generate\na linear model of two periodic hybrid systems: the bouncing pendulum and the\nsimplest walker with control inputs. This leads to a novel state history\naugmented linear quadratic regulator (LQR) which uses current and past state\nhistory for feedback control.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14455v1", "cate": "cs.RO", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14985", "title": "Metaverse Security and Privacy Research: A Systematic Review", "authors": ["Argianto Rahartomo", "Leonel Merino", "Mohammad Ghafari"], "categories": ["cs.CR", "cs.ET", "cs.HC", "cs.SE"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      The paper is accepted for publication at Computers & Security Journal", "url": "http://arxiv.org/abs/2507.14985v1", "summary": "The rapid growth of metaverse technologies, including virtual worlds,\naugmented reality, and lifelogging, has accelerated their adoption across\ndiverse domains. This rise exposes users to significant new security and\nprivacy challenges due to sociotechnical complexity, pervasive connectivity,\nand extensive user data collection in immersive environments. We present a\nsystematic review of the literature published between 2013 and 2024, offering a\ncomprehensive analysis of how the research community has addressed\nmetaverse-related security and privacy issues over the past decade. We organize\nthe studies by method, examined the security and privacy properties, immersive\ncomponents, and evaluation strategies. Our investigation reveals a sharp\nincrease in research activity in the last five years, a strong focus on\npractical and user-centered approaches, and a predominant use of benchmarking,\nhuman experimentation, and qualitative methods. Authentication and\nunobservability are the most frequently studied properties. However, critical\ngaps remain in areas such as policy compliance, accessibility,\ninteroperability, and back-end infrastructure security. We emphasize the\nintertwined technical complexity and human factors of the metaverse and call\nfor integrated, interdisciplinary approaches to securing inclusive and\ntrustworthy immersive environments.", "comment": "The paper is accepted for publication at Computers & Security Journal", "pdf_url": "http://arxiv.org/pdf/2507.14985v1", "cate": "cs.CR", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15147", "title": "STL-GO: Spatio-Temporal Logic with Graph Operators for Distributed Systems with Multiple Network Topologies", "authors": ["Yiqi Zhao", "Xinyi Yu", "Bardh Hoxha", "Georgios Fainekos", "Jyotirmoy V. Deshmukh", "Lars Lindemann"], "categories": ["cs.LO", "cs.FL", "cs.MA"], "primary_category": "Subjects:       Logic in Computer Science (cs.LO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15147v1", "summary": "Multi-agent systems (MASs) consisting of a number of autonomous agents that\ncommunicate, coordinate, and jointly sense the environment to achieve complex\nmissions can be found in a variety of applications such as robotics, smart\ncities, and internet-of-things applications. Modeling and monitoring MAS\nrequirements to guarantee overall mission objectives, safety, and reliability\nis an important problem. Such requirements implicitly require reasoning about\ndiverse sensing and communication modalities between agents, analysis of the\ndependencies between agent tasks, and the spatial or virtual distance between\nagents. To capture such rich MAS requirements, we model agent interactions via\nmultiple directed graphs, and introduce a new logic -- Spatio-Temporal Logic\nwith Graph Operators (STL-GO). The key innovation in STL-GO are graph operators\nthat enable us to reason about the number of agents along either the incoming\nor outgoing edges of the underlying interaction graph that satisfy a given\nproperty of interest; for example, the requirement that an agent should sense\nat least two neighboring agents whose task graphs indicate the ability to\ncollaborate. We then propose novel distributed monitoring conditions for\nindividual agents that use only local information to determine whether or not\nan STL-GO specification is satisfied. We compare the expressivity of STL-GO\nagainst existing spatio-temporal logic formalisms, and demonstrate the utility\nof STL-GO and our distributed monitors in a bike-sharing and a multi-drone case\nstudy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15147v1", "cate": "cs.LO", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14538", "title": "A 21-DOF Humanoid Dexterous Hand with Hybrid SMA-Motor Actuation: CYJ Hand-0", "authors": ["Jin Chai", "Xiang Yao", "Mengfan Hou", "Yanghong Li", "Erbao Dong"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14538v1", "summary": "CYJ Hand-0 is a 21-DOF humanoid dexterous hand featuring a hybrid\ntendon-driven actuation system that combines shape memory alloys (SMAs) and DC\nmotors. The hand employs high-strength fishing line as artificial tendons and\nuses a fully 3D-printed AlSi10Mg metal frame designed to replicate the skeletal\nand tendon-muscle structure of the human hand. A linear motor-driven module\ncontrols finger flexion, while an SMA-based module enables finger extension and\nlateral abduction. These modules are integrated into a compact hybrid actuation\nunit mounted on a custom rear support structure. Mechanical and kinematic\nexperiments, conducted under an Arduino Mega 2560-based control system,\nvalidate the effectiveness of the design and demonstrate its biomimetic\ndexterity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14538v1", "cate": "cs.RO", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15058", "title": "LibLMFuzz: LLM-Augmented Fuzz Target Generation for Black-box Libraries", "authors": ["Ian Hardgrove", "John D. Hastings"], "categories": ["cs.CR", "cs.LG", "cs.SE", "D.2.5; D.4.6"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      6 pages, 2 figures, 1 table, 2 listings", "url": "http://arxiv.org/abs/2507.15058v1", "summary": "A fundamental problem in cybersecurity and computer science is determining\nwhether a program is free of bugs and vulnerabilities. Fuzzing, a popular\napproach to discovering vulnerabilities in programs, has several advantages\nover alternative strategies, although it has investment costs in the form of\ninitial setup and continuous maintenance. The choice of fuzzing is further\ncomplicated when only a binary library is available, such as the case of\nclosed-source and proprietary software. In response, we introduce LibLMFuzz, a\nframework that reduces costs associated with fuzzing closed-source libraries by\npairing an agentic Large Language Model (LLM) with a lightweight tool-chain\n(disassembler/compiler/fuzzer) to autonomously analyze stripped binaries, plan\nfuzz strategies, generate drivers, and iteratively self-repair build or runtime\nerrors. Tested on four widely-used Linux libraries, LibLMFuzz produced\nsyntactically correct drivers for all 558 fuzz-able API functions, achieving\n100% API coverage with no human intervention. Across the 1601 synthesized\ndrivers, 75.52% were nominally correct on first execution. The results show\nthat LLM-augmented middleware holds promise in reducing the costs of fuzzing\nblack box components and provides a foundation for future research efforts.\nFuture opportunities exist for research in branch coverage.", "comment": "6 pages, 2 figures, 1 table, 2 listings", "pdf_url": "http://arxiv.org/pdf/2507.15058v1", "cate": "cs.CR", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15268", "title": "IM-Chat: A Multi-agent LLM-based Framework for Knowledge Transfer in Injection Molding Industry", "authors": ["Junhyeong Lee", "Joon-Young Kim", "Heekyu Kim", "Inhyo Lee", "Seunghwa Ryu"], "categories": ["cs.AI", "cs.MA"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15268v1", "summary": "The injection molding industry faces critical challenges in preserving and\ntransferring field knowledge, particularly as experienced workers retire and\nmultilingual barriers hinder effective communication. This study introduces\nIM-Chat, a multi-agent framework based on large language models (LLMs),\ndesigned to facilitate knowledge transfer in injection molding. IM-Chat\nintegrates both limited documented knowledge (e.g., troubleshooting tables,\nmanuals) and extensive field data modeled through a data-driven process\ncondition generator that infers optimal manufacturing settings from\nenvironmental inputs such as temperature and humidity, enabling robust and\ncontext-aware task resolution. By adopting a retrieval-augmented generation\n(RAG) strategy and tool-calling agents within a modular architecture, IM-Chat\nensures adaptability without the need for fine-tuning. Performance was assessed\nacross 100 single-tool and 60 hybrid tasks for GPT-4o, GPT-4o-mini, and\nGPT-3.5-turbo by domain experts using a 10-point rubric focused on relevance\nand correctness, and was further supplemented by automated evaluation using\nGPT-4o guided by a domain-adapted instruction prompt. The evaluation results\nindicate that more capable models tend to achieve higher accuracy, particularly\nin complex, tool-integrated scenarios. Overall, these findings demonstrate the\nviability of multi-agent LLM systems for industrial knowledge workflows and\nestablish IM-Chat as a scalable and generalizable approach to AI-assisted\ndecision support in manufacturing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15268v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14582", "title": "BT-TL-DMPs: A Novel Robot TAMP Framework Combining Behavior Tree, Temporal Logic and Dynamical Movement Primitives", "authors": ["Zezhi Liu", "Shizhen Wu", "Hanqian Luo", "Deyun Qin", "Yongchun Fang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      11 pages, 8 figures", "url": "http://arxiv.org/abs/2507.14582v1", "summary": "In the field of Learning from Demonstration (LfD), enabling robots to\ngeneralize learned manipulation skills to novel scenarios for long-horizon\ntasks remains challenging. Specifically, it is still difficult for robots to\nadapt the learned skills to new environments with different task and motion\nrequirements, especially in long-horizon, multi-stage scenarios with intricate\nconstraints. This paper proposes a novel hierarchical framework, called\nBT-TL-DMPs, that integrates Behavior Tree (BT), Temporal Logic (TL), and\nDynamical Movement Primitives (DMPs) to address this problem. Within this\nframework, Signal Temporal Logic (STL) is employed to formally specify complex,\nlong-horizon task requirements and constraints. These STL specifications are\nsystematically transformed to generate reactive and modular BTs for high-level\ndecision-making task structure. An STL-constrained DMP optimization method is\nproposed to optimize the DMP forcing term, allowing the learned motion\nprimitives to adapt flexibly while satisfying intricate spatiotemporal\nrequirements and, crucially, preserving the essential dynamics learned from\ndemonstrations. The framework is validated through simulations demonstrating\ngeneralization capabilities under various STL constraints and real-world\nexperiments on several long-horizon robotic manipulation tasks. The results\ndemonstrate that the proposed framework effectively bridges the symbolic-motion\ngap, enabling more reliable and generalizable autonomous manipulation for\ncomplex robotic tasks.", "comment": "11 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.14582v1", "cate": "cs.RO", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15219", "title": "PromptArmor: Simple yet Effective Prompt Injection Defenses", "authors": ["Tianneng Shi", "Kaijie Zhu", "Zhun Wang", "Yuqi Jia", "Will Cai", "Weida Liang", "Haonan Wang", "Hend Alzahrani", "Joshua Lu", "Kenji Kawaguchi", "Basel Alomair", "Xuandong Zhao", "William Yang Wang", "Neil Gong", "Wenbo Guo", "Dawn Song"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15219v1", "summary": "Despite their potential, recent research has demonstrated that LLM agents are\nvulnerable to prompt injection attacks, where malicious prompts are injected\ninto the agent's input, causing it to perform an attacker-specified task rather\nthan the intended task provided by the user. In this paper, we present\nPromptArmor, a simple yet effective defense against prompt injection attacks.\nSpecifically, PromptArmor prompts an off-the-shelf LLM to detect and remove\npotential injected prompts from the input before the agent processes it. Our\nresults show that PromptArmor can accurately identify and remove injected\nprompts. For example, using GPT-4o, GPT-4.1, or o4-mini, PromptArmor achieves\nboth a false positive rate and a false negative rate below 1% on the AgentDojo\nbenchmark. Moreover, after removing injected prompts with PromptArmor, the\nattack success rate drops to below 1%. We also demonstrate PromptArmor's\neffectiveness against adaptive attacks and explore different strategies for\nprompting an LLM. We recommend that PromptArmor be adopted as a standard\nbaseline for evaluating new defenses against prompt injection attacks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15219v1", "cate": "cs.CR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15351", "title": "One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms", "authors": ["Zijian Zhao", "Sen Li"], "categories": ["cs.AI", "cs.ET", "cs.MA"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15351v1", "summary": "On-demand ride-sharing platforms face the fundamental challenge of\ndynamically bundling passengers with diverse origins and destinations and\nmatching them with vehicles in real time, all under significant uncertainty.\nRecently, MARL has emerged as a promising solution for this problem, leveraging\ndecentralized learning to address the curse of dimensionality caused by the\nlarge number of agents in the ride-hailing market and the resulting expansive\nstate and action spaces. However, conventional MARL-based ride-sharing\napproaches heavily rely on the accurate estimation of Q-values or V-values,\nwhich becomes problematic in large-scale, highly uncertain environments.\nSpecifically, most of these approaches adopt an independent paradigm,\nexacerbating this issue, as each agent treats others as part of the\nenvironment, leading to unstable training and substantial estimation bias in\nvalue functions. To address these challenges, we propose two novel alternative\nmethods that bypass value function estimation. First, we adapt GRPO to\nride-sharing, replacing the PPO baseline with the group average reward to\neliminate critic estimation errors and reduce training bias. Second, inspired\nby GRPO's full utilization of group reward information, we customize the PPO\nframework for ride-sharing platforms and show that, under a homogeneous fleet,\nthe optimal policy can be trained using only one-step rewards - a method we\nterm One-Step Policy Optimization (OSPO). Experiments on a real-world Manhattan\nride-hailing dataset demonstrate that both GRPO and OSPO achieve superior\nperformance across most scenarios, efficiently optimizing pickup times and the\nnumber of served orders using simple MLP networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15351v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14605", "title": "Koopman Operator Based Linear Model Predictive Control for 2D Quadruped Trotting, Bounding, and Gait Transition", "authors": ["Chun-Ming Yang", "Pranav A. Bhounsule"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14605v1", "summary": "Online optimal control of quadrupedal robots would enable them to plan their\nmovement in novel scenarios. Linear Model Predictive Control (LMPC) has emerged\nas a practical approach for real-time control. In LMPC, an optimization problem\nwith a quadratic cost and linear constraints is formulated over a finite\nhorizon and solved on the fly. However, LMPC relies on linearizing the\nequations of motion (EOM), which may lead to poor solution quality. In this\npaper, we use Koopman operator theory and the Extended Dynamic Mode\nDecomposition (EDMD) to create a linear model of the system in high dimensional\nspace, thus retaining the nonlinearity of the EOM. We model the aerial phase\nand ground contact phases using different linear models. Then, using LMPC, we\ndemonstrate bounding, trotting, and bound-to-trot and trot-to-bound gait\ntransitions in level and rough terrains. The main novelty is the use of Koopman\noperator theory to create hybrid models of a quadrupedal system and demonstrate\nthe online generation of multiple gaits and gaits transitions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14605v1", "cate": "cs.RO", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15377", "title": "The Matrix Subcode Equivalence problem and its application to signature with MPC-in-the-Head", "authors": ["Magali Bardet", "Charles Brion", "Philippe Gaborit", "Mercedes Haiech", "Romaric Neveu"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15377v1", "summary": "Nowadays, equivalence problems are widely used in cryptography, most notably\nto establish cryptosystems such as digital signatures, with MEDS, LESS, PERK as\nthe most recent ones. However, in the context of matrix codes, only the code\nequivalence problem has been studied, while the subcode equivalence is\nwell-defined in the Hamming metric. In this work, we introduce two new\nproblems: the Matrix Subcode Equivalence Problem and the Matrix Code Permuted\nKernel Problem, to which we apply the MPCitH paradigm to build a signature\nscheme. These new problems, closely related to the Matrix Code Equivalence\nproblem, ask to find an isometry given a code $C$ and a subcode $D$.\nFurthermore, we prove that the Matrix Subcode Equivalence problem reduces to\nthe Hamming Subcode Equivalence problem, which is known to be NP-Complete, thus\nintroducing the matrix code version of the Permuted Kernel Problem. We also\nadapt the combinatorial and algebraic algorithms for the Matrix Code\nEquivalence problem to the subcode case, and we analyze their complexities. We\nfind with this analysis that the algorithms perform much worse than in the code\nequivalence case, which is the same as what happens in the Hamming metric.\nFinally, our analysis of the attacks allows us to take parameters much smaller\nthan in the Matrix Code Equivalence case. Coupled with the effectiveness of\n\\textit{Threshold-Computation-in-the-Head} or \\textit{VOLE-in-the-Head}, we\nobtain a signature size of $\\approx$ 4 800 Bytes, with a public key of\n$\\approx$ 275 Bytes. We thus obtain a reasonable signature size, which brings\ndiversity in the landscape of post-quantum signature schemes, by relying on a\nnew hard problem. In particular, this new signature scheme performs better than\nSPHINCS+, with a smaller size of public key + signature. Our signature compares\nalso well with other signature schemes: compared to MEDS, the signature is\nsmaller, and we reduced the size of the sum of signature and public key by a\nfactor close to 5. We also obtain a signature size that is almost half the size\nof the CROSS signature scheme.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15377v1", "cate": "cs.CR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15518", "title": "HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics", "authors": ["Sizhou Chen", "Shufan Jiang", "Chi Zhang", "Xiao-Lei Zhang", "Xuelong Li"], "categories": ["cs.AI", "cs.MA"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15518v1", "summary": "Creating an immersive and interactive theatrical experience is a long-term\ngoal in the field of interactive narrative. The emergence of large language\nmodel (LLM) is providing a new path to achieve this goal. However, existing\nLLM-based drama generation methods often result in AI agents that lack\ninitiative and cannot interact with the physical environment. Furthermore,\nthese methods typically require detailed user input to drive the drama. These\nlimitations reduce the interactivity and immersion of online real-time\nperformance. To address the above challenges, we propose HAMLET, a multi-agent\nframework focused on drama creation and online performance. Given a simple\ntopic, the framework generates a narrative blueprint, guiding the subsequent\nimprovisational performance. During the online performance, each actor is given\nan autonomous mind. This means that actors can make independent decisions based\non their own background, goals, and emotional state. In addition to\nconversations with other actors, their decisions can also change the state of\nscene props through actions such as opening a letter or picking up a weapon.\nThe change is then broadcast to other related actors, updating what they know\nand care about, which in turn influences their next action. To evaluate the\nquality of drama performance, we designed an evaluation method to assess three\nprimary aspects, including character performance, narrative quality, and\ninteraction experience. The experimental evaluation shows that HAMLET can\ncreate expressive and coherent theatrical experiences. Our code, dataset and\nmodels are available at https://github.com/HAMLET-2025/HAMLET.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15518v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14694", "title": "Uncertainty-aware Probabilistic 3D Human Motion Forecasting via Invertible Networks", "authors": ["Yue Ma", "Kanglei Zhou", "Fuyang Yu", "Frederick W. B. Li", "Xiaohui Liang"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14694v1", "summary": "3D human motion forecasting aims to enable autonomous applications.\nEstimating uncertainty for each prediction (i.e., confidence based on\nprobability density or quantile) is essential for safety-critical contexts like\nhuman-robot collaboration to minimize risks. However, existing diverse motion\nforecasting approaches struggle with uncertainty quantification due to implicit\nprobabilistic representations hindering uncertainty modeling. We propose\nProbHMI, which introduces invertible networks to parameterize poses in a\ndisentangled latent space, enabling probabilistic dynamics modeling. A\nforecasting module then explicitly predicts future latent distributions,\nallowing effective uncertainty quantification. Evaluated on benchmarks, ProbHMI\nachieves strong performance for both deterministic and diverse prediction while\nvalidating uncertainty calibration, critical for risk-aware decision making.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14694v1", "cate": "cs.RO", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15393", "title": "PiMRef: Detecting and Explaining Ever-evolving Spear Phishing Emails with Knowledge Base Invariants", "authors": ["Ruofan Liu", "Yun Lin", "Silas Yeo Shuen Yu", "Xiwen Teoh", "Zhenkai Liang", "Jin Song Dong"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15393v1", "summary": "Phishing emails are a critical component of the cybercrime kill chain due to\ntheir wide reach and low cost. Their ever-evolving nature renders traditional\nrule-based and feature-engineered detectors ineffective in the ongoing arms\nrace between attackers and defenders. The rise of large language models (LLMs)\nfurther exacerbates the threat, enabling attackers to craft highly convincing\nphishing emails at minimal cost.\n  This work demonstrates that LLMs can generate psychologically persuasive\nphishing emails tailored to victim profiles, successfully bypassing nearly all\ncommercial and academic detectors. To defend against such threats, we propose\nPiMRef, the first reference-based phishing email detector that leverages\nknowledge-based invariants. Our core insight is that persuasive phishing emails\noften contain disprovable identity claims, which contradict real-world facts.\nPiMRef reframes phishing detection as an identity fact-checking task. Given an\nemail, PiMRef (i) extracts the sender's claimed identity, (ii) verifies the\nlegitimacy of the sender's domain against a predefined knowledge base, and\n(iii) detects call-to-action prompts that push user engagement. Contradictory\nclaims are flagged as phishing indicators and serve as human-understandable\nexplanations.\n  Compared to existing methods such as D-Fence, HelpHed, and ChatSpamDetector,\nPiMRef boosts precision by 8.8% with no loss in recall on standard benchmarks\nlike Nazario and PhishPot. In a real-world evaluation of 10,183 emails across\nfive university accounts over three years, PiMRef achieved 92.1% precision,\n87.9% recall, and a median runtime of 0.05s, outperforming the state-of-the-art\nin both effectiveness and efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15393v1", "cate": "cs.CR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15658", "title": "Asynchronous Collective Tree Exploration: a Distributed Algorithm, and a new Lower Bound", "authors": ["Romain Cosson", "Laurent Massoulié"], "categories": ["cs.DS", "cs.DC", "cs.MA"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15658v1", "summary": "We study the problem of collective tree exploration in which a team of $k$\nmobile agents must collectively visit all nodes of an unknown tree in as few\nmoves as possible. The agents all start from the root and discover adjacent\nedges as they progress in the tree. Communication is distributed in the sense\nthat agents share information by reading and writing on whiteboards located at\nall nodes. Movements are asynchronous, in the sense that the speeds of all\nagents are controlled by an adversary at all times. All previous competitive\nguarantees for collective tree exploration are either distributed but\nsynchronous, or asynchronous but centralized. In contrast, we present a\ndistributed asynchronous algorithm that explores any tree of $n$ nodes and\ndepth $D$ in at most $2n+O(k^2 2^kD)$ moves, i.e., with a regret that is linear\nin $D$, and a variant algorithm with a guarantee in $O(k/\\log k)(n+kD)$, i.e.,\nwith a competitive ratio in $O(k/\\log k)$. We note that our regret guarantee is\nasymptotically optimal (i.e., $1$-competitive) from the perspective of\naverage-case complexity. We then present a new general lower bound on the\ncompetitive ratio of asynchronous collective tree exploration, in\n$\\Omega(\\log^2 k)$. This lower bound applies to both the distributed and\ncentralized settings, and improves upon the previous lower bound in\n$\\Omega(\\log k)$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15658v1", "cate": "cs.DS", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14700", "title": "Corridor-based Adaptive Control Barrier and Lyapunov Functions for Safe Mobile Robot Navigation", "authors": ["Nicholas Mohammad", "Nicola Bezzo"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      To be presented in the 64th IEEE Conference on Decision and Control (CDC 25)", "url": "http://arxiv.org/abs/2507.14700v1", "summary": "Safe navigation in unknown and cluttered environments remains a challenging\nproblem in robotics. Model Predictive Contour Control (MPCC) has shown promise\nfor performant obstacle avoidance by enabling precise and agile trajectory\ntracking, however, existing methods lack formal safety assurances. To address\nthis issue, we propose a general Control Lyapunov Function (CLF) and Control\nBarrier Function (CBF) enabled MPCC framework that enforces safety constraints\nderived from a free-space corridor around the planned trajectory. To enhance\nfeasibility, we dynamically adapt the CBF parameters at runtime using a Soft\nActor-Critic (SAC) policy. The approach is validated with extensive simulations\nand an experiment on mobile robot navigation in unknown cluttered environments.", "comment": "To be presented in the 64th IEEE Conference on Decision and Control\n  (CDC 25)", "pdf_url": "http://arxiv.org/pdf/2507.14700v1", "cate": "cs.RO", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14316", "title": "Can AR-Embedded Visualizations Foster Appropriate Reliance on AI in Spatial Decision Making? A Comparative Study of AR See-Through vs. 2D Minimap", "authors": ["Xianhao Carton Liu", "Difan Jia", "Tongyu Nie", "Evan Suma Rosenberg", "Victoria Interrante", "Chen Zhu-Tian"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14316v1", "summary": "In high-stakes, time-critical scenarios-such as emergency evacuation, first\nresponder prioritization, and crisis management -- decision-makers must rapidly\nchoose among spatial targets, such as exits, individuals to assist, or areas to\nsecure. Advances in indoor sensing and artificial intelligence (AI) can support\nthese decisions by visualizing real-time situational data and AI suggestions on\n2D maps. However, mentally mapping this information onto real-world spaces\nimposes significant cognitive load. This load can impair users' ability to\nappropriately judge AI suggestions, leading to inappropriate reliance (e.g.,\naccepting wrong AI suggestions or rejecting correct ones). Embedded\nvisualizations in Augmented Reality (AR), by directly overlaying information\nonto physical environments, may reduce this load and foster more deliberate,\nappropriate reliance on AI. But is this true? In this work, we conducted an\nempirical study (N = 32) comparing AR see-through (embedded visualization) and\n2D Minimap in time-critical, AI-assisted spatial target selection tasks.\nContrary to our expectations, users exhibited greater inappropriate reliance on\nAI in the AR condition. Our analysis further reveals that this is primarily due\nto over-reliance, with factors specific to embedded visualizations, such as\nperceptual challenges, visual proximity illusions, and highly realistic visual\nrepresentations. Nonetheless, embedded visualizations demonstrated notable\nbenefits in spatial reasoning, such as spatial mapping and egocentric spatial\nimagery. We conclude by discussing the empirical insights, deriving design\nimplications, and outlining important directions for future research on\nhuman-AI decision collaboration in AR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14316v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15419", "title": "PhishIntentionLLM: Uncovering Phishing Website Intentions through Multi-Agent Retrieval-Augmented Generation", "authors": ["Wenhao Li", "Selvakumar Manickam", "Yung-wey Chong", "Shankar Karuppayah"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted by EAI ICDF2C 2025", "url": "http://arxiv.org/abs/2507.15419v1", "summary": "Phishing websites remain a major cybersecurity threat, yet existing methods\nprimarily focus on detection, while the recognition of underlying malicious\nintentions remains largely unexplored. To address this gap, we propose\nPhishIntentionLLM, a multi-agent retrieval-augmented generation (RAG) framework\nthat uncovers phishing intentions from website screenshots. Leveraging the\nvisual-language capabilities of large language models (LLMs), our framework\nidentifies four key phishing objectives: Credential Theft, Financial Fraud,\nMalware Distribution, and Personal Information Harvesting. We construct and\nrelease the first phishing intention ground truth dataset (~2K samples) and\nevaluate the framework using four commercial LLMs. Experimental results show\nthat PhishIntentionLLM achieves a micro-precision of 0.7895 with GPT-4o and\nsignificantly outperforms the single-agent baseline with a ~95% improvement in\nmicro-precision. Compared to the previous work, it achieves 0.8545 precision\nfor credential theft, marking a ~4% improvement. Additionally, we generate a\nlarger dataset of ~9K samples for large-scale phishing intention profiling\nacross sectors. This work provides a scalable and interpretable solution for\nintention-aware phishing analysis.", "comment": "Accepted by EAI ICDF2C 2025", "pdf_url": "http://arxiv.org/pdf/2507.15419v1", "cate": "cs.CR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15727", "title": "Competitive Algorithms for Cooperative Multi-Agent Ski-Rental Problems", "authors": ["Xuchuang Wang", "Bo Sun", "Hedyeh Beyhaghi", "John C. S. Lui", "Mohammad Hajiesmaili", "Adam Wierman"], "categories": ["cs.LG", "cs.GT", "cs.MA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15727v1", "summary": "This paper introduces a novel multi-agent ski-rental problem that generalizes\nthe classical ski-rental dilemma to a group setting where agents incur\nindividual and shared costs. In our model, each agent can either rent at a\nfixed daily cost, or purchase a pass at an individual cost, with an additional\nthird option of a discounted group pass available to all. We consider scenarios\nin which agents' active days differ, leading to dynamic states as agents drop\nout of the decision process. To address this problem from different\nperspectives, we define three distinct competitive ratios: overall,\nstate-dependent, and individual rational. For each objective, we design and\nanalyze optimal deterministic and randomized policies. Our deterministic\npolicies employ state-aware threshold functions that adapt to the dynamic\nstates, while our randomized policies sample and resample thresholds from\ntailored state-aware distributions. The analysis reveals that symmetric\npolicies, in which all agents use the same threshold, outperform asymmetric\nones. Our results provide competitive ratio upper and lower bounds and extend\nclassical ski-rental insights to multi-agent settings, highlighting both\ntheoretical and practical implications for group decision-making under\nuncertainty.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15727v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14721", "title": "Leveraging Extrinsic Dexterity for Occluded Grasping on Grasp Constraining Walls", "authors": ["Keita Kobashi", "Masayoshi Tomizuka"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      7 pages, 7 figures", "url": "http://arxiv.org/abs/2507.14721v1", "summary": "This study addresses the problem of occluded grasping, where primary grasp\nconfigurations of an object are not available due to occlusion with\nenvironment. Simple parallel grippers often struggle with such tasks due to\nlimited dexterity and actuation constraints. Prior works have explored object\npose reorientation such as pivoting by utilizing extrinsic contacts between an\nobject and an environment feature like a wall, to make the object graspable.\nHowever, such works often assume the presence of a short wall, and this\nassumption may not always hold in real-world scenarios. If the wall available\nfor interaction is too large or too tall, the robot may still fail to grasp the\nobject even after pivoting, and the robot must combine different types of\nactions to grasp. To address this, we propose a hierarchical reinforcement\nlearning (RL) framework. We use Q-learning to train a high-level policy that\nselects the type of action expected to yield the highest reward. The selected\nlow-level skill then samples a specific robot action in continuous space. To\nguide the robot to an appropriate location for executing the selected action,\nwe adopt a Conditional Variational Autoencoder (CVAE). We condition the CVAE on\nthe object point cloud and the skill ID, enabling it to infer a suitable\nlocation based on the object geometry and the selected skill. To promote\ngeneralization, we apply domain randomization during the training of low-level\nskills. The RL policy is trained entirely in simulation with a box-like object\nand deployed to six objects in real world. We conduct experiments to evaluate\nour method and demonstrate both its generalizability and robust sim-to-real\ntransfer performance with promising success rates.", "comment": "7 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.14721v1", "cate": "cs.RO", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14384", "title": "Assessing the Reliability of Large Language Models for Deductive Qualitative Coding: A Comparative Study of ChatGPT Interventions", "authors": ["Angjelin Hila", "Elliott Hauser"], "categories": ["cs.HC", "cs.CL"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Extended version of paper accepted for presentation at the ASIS&T Annual Meeting 2025. 38 pages, 12 figures", "url": "http://arxiv.org/abs/2507.14384v1", "summary": "In this study, we investigate the use of large language models (LLMs),\nspecifically ChatGPT, for structured deductive qualitative coding. While most\ncurrent research emphasizes inductive coding applications, we address the\nunderexplored potential of LLMs to perform deductive classification tasks\naligned with established human-coded schemes. Using the Comparative Agendas\nProject (CAP) Master Codebook, we classified U.S. Supreme Court case summaries\ninto 21 major policy domains. We tested four intervention methods: zero-shot,\nfew-shot, definition-based, and a novel Step-by-Step Task Decomposition\nstrategy, across repeated samples. Performance was evaluated using standard\nclassification metrics (accuracy, F1-score, Cohen's kappa, Krippendorff's\nalpha), and construct validity was assessed using chi-squared tests and\nCramer's V. Chi-squared and effect size analyses confirmed that intervention\nstrategies significantly influenced classification behavior, with Cramer's V\nvalues ranging from 0.359 to 0.613, indicating moderate to strong shifts in\nclassification patterns. The Step-by-Step Task Decomposition strategy achieved\nthe strongest reliability (accuracy = 0.775, kappa = 0.744, alpha = 0.746),\nachieving thresholds for substantial agreement. Despite the semantic ambiguity\nwithin case summaries, ChatGPT displayed stable agreement across samples,\nincluding high F1 scores in low-support subclasses. These findings demonstrate\nthat with targeted, custom-tailored interventions, LLMs can achieve reliability\nlevels suitable for integration into rigorous qualitative coding workflows.", "comment": "Extended version of paper accepted for presentation at the ASIS&T\n  Annual Meeting 2025. 38 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.14384v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15449", "title": "Cryptanalysis of a multivariate CCZ scheme", "authors": ["Alessio Caminata", "Elisa Gorla", "Madison Mabe", "Martina Vigorito", "Irene Villa"], "categories": ["cs.CR", "cs.SC"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      are welcome!", "url": "http://arxiv.org/abs/2507.15449v1", "summary": "We consider the multivariate scheme Pesto, which was introduced by Calderini,\nCaminata, and Villa. In this scheme, the public polynomials are obtained by\napplying a CCZ transformation to a set of quadratic secret polynomials. As a\nconsequence, the public key consists of polynomials of degree 4. In this work,\nwe show that the public degree 4 polynomial system can be efficiently reduced\nto a system of quadratic polynomials. This seems to suggest that the CCZ\ntransformation may not offer a significant increase in security, contrary to\nwhat was initially believed.", "comment": "are welcome!", "pdf_url": "http://arxiv.org/pdf/2507.15449v1", "cate": "cs.CR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "0910.3580", "title": "Set-Rationalizable Choice and Self-Stability", "authors": ["Felix Brandt", "Paul Harrenstein"], "categories": ["cs.MA"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      13 pages, 2 figures, changed content", "url": "http://arxiv.org/abs/0910.3580v4", "summary": "A common assumption in modern microeconomic theory is that choice should be\nrationalizable via a binary preference relation, which \\citeauthor{Sen71a}\nshowed to be equivalent to two consistency conditions, namely $\\alpha$\n(contraction) and $\\gamma$ (expansion). Within the context of \\emph{social}\nchoice, however, rationalizability and similar notions of consistency have\nproved to be highly problematic, as witnessed by a range of impossibility\nresults, among which Arrow's is the most prominent. Since choice functions\nselect \\emph{sets} of alternatives rather than single alternatives, we propose\nto rationalize choice functions by preference relations over sets\n(set-rationalizability). We also introduce two consistency conditions,\n$\\hat\\alpha$ and $\\hat\\gamma$, which are defined in analogy to $\\alpha$ and\n$\\gamma$, and find that a choice function is set-rationalizable if and only if\nit satisfies $\\hat\\alpha$. Moreover, a choice function satisfies $\\hat\\alpha$\nand $\\hat\\gamma$ if and only if it is \\emph{self-stable}, a new concept based\non earlier work by \\citeauthor{Dutt88a}. The class of self-stable social choice\nfunctions contains a number of appealing Condorcet extensions such as the\nminimal covering set and the essential set.", "comment": "13 pages, 2 figures, changed content", "pdf_url": "http://arxiv.org/pdf/0910.3580v4", "cate": "cs.MA", "date": "2009-10-19", "updated": "2025-07-21"}
{"id": "2507.14731", "title": "X-Nav: Learning End-to-End Cross-Embodiment Navigation for Mobile Robots", "authors": ["Haitong Wang", "Aaron Hao Tan", "Angus Fung", "Goldie Nejat"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14731v1", "summary": "Existing navigation methods are primarily designed for specific robot\nembodiments, limiting their generalizability across diverse robot platforms. In\nthis paper, we introduce X-Nav, a novel framework for end-to-end\ncross-embodiment navigation where a single unified policy can be deployed\nacross various embodiments for both wheeled and quadrupedal robots. X-Nav\nconsists of two learning stages: 1) multiple expert policies are trained using\ndeep reinforcement learning with privileged observations on a wide range of\nrandomly generated robot embodiments; and 2) a single general policy is\ndistilled from the expert policies via navigation action chunking with\ntransformer (Nav-ACT). The general policy directly maps visual and\nproprioceptive observations to low-level control commands, enabling\ngeneralization to novel robot embodiments. Simulated experiments demonstrated\nthat X-Nav achieved zero-shot transfer to both unseen embodiments and\nphotorealistic environments. A scalability study showed that the performance of\nX-Nav improves when trained with an increasing number of randomly generated\nembodiments. An ablation study confirmed the design choices of X-Nav.\nFurthermore, real-world experiments were conducted to validate the\ngeneralizability of X-Nav in real-world environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14731v1", "cate": "cs.RO", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14418", "title": "Designing Conversational AI to Support Think-Aloud Practice in Technical Interview Preparation for CS Students", "authors": ["Taufiq Daryanto", "Sophia Stil", "Xiaohan Ding", "Daniel Manesh", "Sang Won Lee", "Tim Lee", "Stephanie Lunn", "Sarah Rodriguez", "Chris Brown", "Eugenia Rho"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14418v1", "summary": "One challenge in technical interviews is the think-aloud process, where\ncandidates verbalize their thought processes while solving coding tasks.\nDespite its importance, opportunities for structured practice remain limited.\nConversational AI offers potential assistance, but limited research explores\nuser perceptions of its role in think-aloud practice. To address this gap, we\nconducted a study with 17 participants using an LLM-based technical interview\npractice tool. Participants valued AI's role in simulation, feedback, and\nlearning from generated examples. Key design recommendations include promoting\nsocial presence in conversational AI for technical interview simulation,\nproviding feedback beyond verbal content analysis, and enabling crowdsourced\nthink-aloud examples through human-AI collaboration. Beyond feature design, we\nexamined broader considerations, including intersectional challenges and\npotential strategies to address them, how AI-driven interview preparation could\npromote equitable learning in computing careers, and the need to rethink AI's\nrole in interview practice by suggesting a research direction that integrates\nhuman-AI collaboration.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14418v1", "cate": "cs.HC", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14154", "title": "The Free Will Equation: Quantum Field Analogies for AGI", "authors": ["Rahul Kabali"], "categories": ["cs.AI", "cs.LG", "68T05, 81P68", "I.2.6; I.2.0; F.1.2"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      22 pages, 5 figures. Submitted as an arXiv preprint. All code and experiment details included in appendix", "url": "http://arxiv.org/abs/2507.14154v1", "summary": "Artificial General Intelligence (AGI) research traditionally focuses on\nalgorithms that optimize for specific goals under deterministic rules. Yet,\nhuman-like intelligence exhibits adaptive spontaneity - an ability to make\nunexpected choices or free decisions not strictly dictated by past data or\nimmediate reward. This trait, often dubbed \"free will\" in a loose sense, might\nbe crucial for creativity, robust adaptation, and avoiding ruts in\nproblem-solving. This paper proposes a theoretical framework, called the Free\nWill Equation, that draws analogies from quantum field theory to endow AGI\nagents with a form of adaptive, controlled stochasticity in their\ndecision-making process. The core idea is to treat an AI agent's cognitive\nstate as a superposition of potential actions or thoughts, which collapses\nprobabilistically into a concrete action when a decision is made - much like a\nquantum wavefunction collapsing upon measurement. By incorporating mechanisms\nanalogous to quantum fields, along with intrinsic motivation terms, we aim to\nimprove an agent's ability to explore novel strategies and adapt to unforeseen\nchanges. Experiments in a non-stationary multi-armed bandit environment\ndemonstrate that agents using this framework achieve higher rewards and policy\ndiversity compared to baseline methods.", "comment": "22 pages, 5 figures. Submitted as an arXiv preprint. All code and\n  experiment details included in appendix", "pdf_url": "http://arxiv.org/pdf/2507.14154v1", "cate": "cs.AI", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.15613", "title": "Multi-Stage Prompt Inference Attacks on Enterprise LLM Systems", "authors": ["Andrii Balashov", "Olena Ponomarova", "Xiaohua Zhai"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      26 pages", "url": "http://arxiv.org/abs/2507.15613v1", "summary": "Large Language Models (LLMs) deployed in enterprise settings (e.g., as\nMicrosoft 365 Copilot) face novel security challenges. One critical threat is\nprompt inference attacks: adversaries chain together seemingly benign prompts\nto gradually extract confidential data. In this paper, we present a\ncomprehensive study of multi-stage prompt inference attacks in an enterprise\nLLM context. We simulate realistic attack scenarios where an attacker uses\nmild-mannered queries and indirect prompt injections to exploit an LLM\nintegrated with private corporate data. We develop a formal threat model for\nthese multi-turn inference attacks and analyze them using probability theory,\noptimization frameworks, and information-theoretic leakage bounds. The attacks\nare shown to reliably exfiltrate sensitive information from the LLM's context\n(e.g., internal SharePoint documents or emails), even when standard safety\nmeasures are in place.\n  We propose and evaluate defenses to counter such attacks, including\nstatistical anomaly detection, fine-grained access control, prompt sanitization\ntechniques, and architectural modifications to LLM deployment. Each defense is\nsupported by mathematical analysis or experimental simulation. For example, we\nderive bounds on information leakage under differential privacy-based training\nand demonstrate an anomaly detection method that flags multi-turn attacks with\nhigh AUC. We also introduce an approach called \"spotlighting\" that uses input\ntransformations to isolate untrusted prompt content, reducing attack success by\nan order of magnitude. Finally, we provide a formal proof of concept and\nempirical validation for a combined defense-in-depth strategy. Our work\nhighlights that securing LLMs in enterprise settings requires moving beyond\nsingle-turn prompt filtering toward a holistic, multi-stage perspective on both\nattacks and defenses.", "comment": "26 pages", "pdf_url": "http://arxiv.org/pdf/2507.15613v1", "cate": "cs.CR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "1611.04175", "title": "Recognizing and Eliciting Weakly Single Crossing Profiles on Trees", "authors": ["Palash Dey"], "categories": ["cs.MA", "cs.AI", "cs.DS"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      Accepted in TCS journal", "url": "http://arxiv.org/abs/1611.04175v3", "summary": "We introduce and study the weakly single-crossing domain on trees which is a\ngeneralization of the well-studied single-crossing domain in social choice\ntheory. We design a polynomial-time algorithm for recognizing preference\nprofiles which belong to this domain. We then develop an efficient elicitation\nalgorithm for this domain which works even if the preferences can be accessed\nonly sequentially and the underlying single-crossing tree structure is not\nknown beforehand. We also prove matching lower bound on the query complexity of\nour elicitation algorithm when the number of voters is large compared to the\nnumber of candidates. We also prove a lower bound of $\\Omega(m^2\\log n)$ on the\nnumber of queries that any algorithm needs to ask to elicit single crossing\nprofile when random queries are allowed. This resolves an open question in an\nearlier paper and proves optimality of their preference elicitation algorithm\nwhen random queries are allowed.", "comment": "Accepted in TCS journal", "pdf_url": "http://arxiv.org/pdf/1611.04175v3", "cate": "cs.MA", "date": "2016-11-13", "updated": "2025-07-21"}
{"id": "2507.14820", "title": "KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning", "authors": ["Bingran Chen", "Baorun Li", "Jian Yang", "Yong Liu", "Guangyao Zhai"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14820v1", "summary": "High-level robotic manipulation tasks demand flexible 6-DoF grasp estimation\nto serve as a basic function. Previous approaches either directly generate\ngrasps from point-cloud data, suffering from challenges with small objects and\nsensor noise, or infer 3D information from RGB images, which introduces\nexpensive annotation requirements and discretization issues. Recent methods\nmitigate some challenges by retaining a 2D representation to estimate grasp\nkeypoints and applying Perspective-n-Point (PnP) algorithms to compute 6-DoF\nposes. However, these methods are limited by their non-differentiable nature\nand reliance solely on 2D supervision, which hinders the full exploitation of\nrich 3D information. In this work, we present KGN-Pro, a novel grasping network\nthat preserves the efficiency and fine-grained object grasping of previous KGNs\nwhile integrating direct 3D optimization through probabilistic PnP layers.\nKGN-Pro encodes paired RGB-D images to generate Keypoint Map, and further\noutputs a 2D confidence map to weight keypoint contributions during\nre-projection error minimization. By modeling the weighted sum of squared\nre-projection errors probabilistically, the network effectively transmits 3D\nsupervision to its 2D keypoint predictions, enabling end-to-end learning.\nExperiments on both simulated and real-world platforms demonstrate that KGN-Pro\noutperforms existing methods in terms of grasp cover rate and success rate.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14820v1", "cate": "cs.RO", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14482", "title": "Conch: Competitive Debate Analysis via Visualizing Clash Points and Hierarchical Strategies", "authors": ["Qianhe Chen", "Yong Wang", "Yixin Yu", "Xiyuan Zhu", "Xuerou Yu", "Ran Wang"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14482v1", "summary": "In-depth analysis of competitive debates is essential for participants to\ndevelop argumentative skills and refine strategies, and further improve their\ndebating performance. However, manual analysis of unstructured and unlabeled\ntextual records of debating is time-consuming and ineffective, as it is\nchallenging to reconstruct contextual semantics and track logical connections\nfrom raw data. To address this, we propose Conch, an interactive visualization\nsystem that systematically analyzes both what is debated and how it is debated.\nIn particular, we propose a novel parallel spiral visualization that compactly\ntraces the multidimensional evolution of clash points and participant\ninteractions throughout debate process. In addition, we leverage large language\nmodels with well-designed prompts to automatically identify critical debate\nelements such as clash points, disagreements, viewpoints, and strategies,\nenabling participants to understand the debate context comprehensively.\nFinally, through two case studies on real-world debates and a\ncarefully-designed user study, we demonstrate Conch's effectiveness and\nusability for competitive debate analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14482v1", "cate": "cs.HC", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14267", "title": "DREAMS: Density Functional Theory Based Research Engine for Agentic Materials Simulation", "authors": ["Ziqi Wang", "Hongshuo Huang", "Hancheng Zhao", "Changwen Xu", "Shang Zhu", "Jan Janssen", "Venkatasubramanian Viswanathan"], "categories": ["cs.AI", "cond-mat.mtrl-sci"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      34 pages, 28 pages of Supporting Information", "url": "http://arxiv.org/abs/2507.14267v1", "summary": "Materials discovery relies on high-throughput, high-fidelity simulation\ntechniques such as Density Functional Theory (DFT), which require years of\ntraining, extensive parameter fine-tuning and systematic error handling. To\naddress these challenges, we introduce the DFT-based Research Engine for\nAgentic Materials Screening (DREAMS), a hierarchical, multi-agent framework for\nDFT simulation that combines a central Large Language Model (LLM) planner agent\nwith domain-specific LLM agents for atomistic structure generation, systematic\nDFT convergence testing, High-Performance Computing (HPC) scheduling, and error\nhandling. In addition, a shared canvas helps the LLM agents to structure their\ndiscussions, preserve context and prevent hallucination. We validate DREAMS\ncapabilities on the Sol27LC lattice-constant benchmark, achieving average\nerrors below 1\\% compared to the results of human DFT experts. Furthermore, we\napply DREAMS to the long-standing CO/Pt(111) adsorption puzzle, demonstrating\nits long-term and complex problem-solving capabilities. The framework again\nreproduces expert-level literature adsorption-energy differences. Finally,\nDREAMS is employed to quantify functional-driven uncertainties with Bayesian\nensemble sampling, confirming the Face Centered Cubic (FCC)-site preference at\nthe Generalized Gradient Approximation (GGA) DFT level. In conclusion, DREAMS\napproaches L3-level automation - autonomous exploration of a defined design\nspace - and significantly reduces the reliance on human expertise and\nintervention, offering a scalable path toward democratized, high-throughput,\nhigh-fidelity computational materials discovery.", "comment": "34 pages, 28 pages of Supporting Information", "pdf_url": "http://arxiv.org/pdf/2507.14267v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14713", "title": "Privacy-Preserving Drone Navigation Through Homomorphic Encryption for Collision Avoidance", "authors": ["Allan Luedeman", "Nicholas Baum", "Andrew Quijano", "Kemal Akkaya"], "categories": ["cs.ET"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14713v1", "summary": "As drones increasingly deliver packages in neighborhoods, concerns about\ncollisions arise. One solution is to share flight paths within a specific zip\ncode, but this compromises business privacy by revealing delivery routes. For\nexample, it could disclose which stores send packages to certain addresses. To\navoid exposing path information, we propose using homomorphic encryption-based\ncomparison to compute path intersections. This allows drones to identify\npotential collisions without revealing path and destination details, allowing\nthem to adjust altitude to avoid crashes. We implemented and tested our\napproach on resource-limited virtual machines to mimic the computational power\nof drones. Our results demonstrate that our method is significantly faster and\nrequires less network communication compared to a garbled circuit-based\napproach. We also provide a security analysis of the approach against potential\nattacks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14713v1", "cate": "cs.ET", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15660", "title": "Cyber security of Mega Events: A Case Study of Securing the Digital Infrastructure for MahaKumbh 2025 -- A 45 days Mega Event of 600 Million Footfalls", "authors": ["Rohit Negi", "Amit Negi", "Manish Sharma", "S. Venkatesan", "Prem Kumar", "Sandeep K. Shukla"], "categories": ["cs.CR", "cs.CY"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      11 pages, 11 tables", "url": "http://arxiv.org/abs/2507.15660v1", "summary": "Mega events such as the Olympics, World Cup tournaments, G-20 Summit,\nreligious events such as MahaKumbh are increasingly digitalized. From event\nticketing, vendor booth or lodging reservations, sanitation, event scheduling,\ncustomer service, crime reporting, media streaming and messaging on digital\ndisplay boards, surveillance, crowd control, traffic control and many other\nservices are based on mobile and web applications, wired and wireless\nnetworking, network of Closed-Circuit Television (CCTV) cameras, specialized\ncontrol room with network and video-feed monitoring. Consequently, cyber\nthreats directed at such digital infrastructure are common. Starting from hobby\nhackers, hacktivists, cyber crime gangs, to the nation state actors, all target\nsuch infrastructure to unleash chaos on an otherwise smooth operation, and\noften the cyber threat actors attempt to embarrass the organizing country or\nthe organizers. Unlike long-standing organizations such as a corporate or a\ngovernment department, the infrastructure of mega-events is temporary,\nconstructed over a short time span in expediency, and often shortcuts are taken\nto make the deadline for the event. As a result, securing such an elaborate yet\ntemporary infrastructure requires a different approach than securing a standard\norganizational digital infrastructure. In this paper, we describe our approach\nto securing MahaKumbh 2025, a 600 million footfall event for 45 days in\nPrayagraj, India, as a cyber security assessment and risk management oversight\nteam. We chronicle the scope, process, methodology, and outcome of our team's\neffort to secure this mega event. It should be noted that none of the cyber\nattacks during the 45-day event was successful. Our goal is to put on record\nthe methodology and discuss what we would do differently in case we work on\nsimilar future mega event.", "comment": "11 pages, 11 tables", "pdf_url": "http://arxiv.org/pdf/2507.15660v1", "cate": "cs.CR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2409.05037", "title": "DHLight: Multi-agent Policy-based Directed Hypergraph Learning for Traffic Signal Control", "authors": ["Zhen Lei", "Zhishu Shen", "Kang Wang", "Zhenwei Wang", "Tiehua Zhang"], "categories": ["cs.MA"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      Accepted by the 28th European Conference on Artificial Intelligence (ECAI 2025)", "url": "http://arxiv.org/abs/2409.05037v2", "summary": "Recent advancements in Deep Reinforcement Learning (DRL) and Graph Neural\nNetworks (GNNs) have demonstrated notable promise in the realm of intelligent\ntraffic signal control, facilitating the coordination across multiple\nintersections. However, the traditional methods rely on standard graph\nstructures often fail to capture the intricate higher-order spatio-temporal\ncorrelations inherent in real-world traffic dynamics. Standard graphs cannot\nfully represent the spatial relationships within road networks, which limits\nthe effectiveness of graph-based approaches. In contrast, directed hypergraphs\nprovide more accurate representation of spatial information to model complex\ndirected relationships among multiple nodes. In this paper, we propose DHLight,\na novel multi-agent policy-based framework that synergistically integrates\ndirected hypergraph learning module. This framework introduces a novel dynamic\ndirected hypergraph construction mechanism, which captures complex and evolving\nspatio-temporal relationships among intersections in road networks. By\nleveraging the directed hypergraph relational structure, DHLight empowers\nagents to achieve adaptive decision-making in traffic signal control. The\neffectiveness of DHLight is validated against state-of-the-art baselines\nthrough extensive experiments in various network datasets. We release the code\nto support the reproducibility of this work at\nhttps://github.com/LuckyVoasem/Traffic-Light-control", "comment": "Accepted by the 28th European Conference on Artificial Intelligence\n  (ECAI 2025)", "pdf_url": "http://arxiv.org/pdf/2409.05037v2", "cate": "cs.MA", "date": "2024-09-08", "updated": "2025-07-19"}
{"id": "2507.14903", "title": "CoMoCAVs: Cohesive Decision-Guided Motion Planning for Connected and Autonomous Vehicles with Multi-Policy Reinforcement Learning", "authors": ["Pan Hu"], "categories": ["cs.RO", "I.2.9; I.2.10; I.2.11"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 5 figures", "url": "http://arxiv.org/abs/2507.14903v1", "summary": "Autonomous driving demands reliable and efficient solutions to closely\nrelated problems such as decision-making and motion planning. In this work,\ndecision-making refers specifically to highway lane selection, while motion\nplanning involves generating control commands (such as speed and steering) to\nreach the chosen lane. In the context of Connected Autonomous Vehicles (CAVs),\nachieving both flexible and safe lane selection alongside precise trajectory\nexecution remains a significant challenge. This paper proposes a framework\ncalled Cohesive Decision-Guided Motion Planning (CDGMP), which tightly\nintegrates decision-making and motion planning using a Mixture of Experts (MoE)\ninspired architecture combined with multi-policy reinforcement learning. By\ncoordinating multiple specialized sub-networks through a gating mechanism, the\nmethod decomposes the complex driving task into modular components. Each\nsub-network focuses on a specific aspect of driving, improving efficiency by\nactivating only the most relevant modules during inference. This design also\nenhances safety through modular specialization. CDGMP improves the adaptability\nand robustness of CAVs across diverse traffic scenarios, offering a scalable\nsolution to real-world autonomy challenges. The architectural principles behind\nCDGMP, especially the use of MoE, also provide a strong foundation for other\nhigh-dimensional decision and control tasks. Simulation results (available at\nhttps://youtu.be/_-4OXNHV0UY) demonstrate reliable performance in both lane\nselection and motion planning.", "comment": "8 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.14903v1", "cate": "cs.RO", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14494", "title": "\"It looks sexy but it's wrong.\" Tensions in creativity and accuracy using genAI for biomedical visualization", "authors": ["Roxanne Ziman", "Shehryar Saharan", "Gaël McGill", "Laura Garrison"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      11 pages, 3 figures. Accepted to IEEE VIS 2025 Conference", "url": "http://arxiv.org/abs/2507.14494v1", "summary": "We contribute an in-depth analysis of the workflows and tensions arising from\ngenerative AI (genAI) use in biomedical visualization (BioMedVis). Although\ngenAI affords facile production of aesthetic visuals for biological and medical\ncontent, the architecture of these tools fundamentally limits the accuracy and\ntrustworthiness of the depicted information, from imaginary (or fanciful)\nmolecules to alien anatomy. Through 17 interviews with a diverse group of\npractitioners and researchers, we qualitatively analyze the concerns and values\ndriving genAI (dis)use for the visual representation of spatially-oriented\nbiomedical data. We find that BioMedVis experts, both in roles as developers\nand designers, use genAI tools at different stages of their daily workflows and\nhold attitudes ranging from enthusiastic adopters to skeptical avoiders of\ngenAI. In contrasting the current use and perspectives on genAI observed in our\nstudy with predictions towards genAI in the visualization pipeline from prior\nwork, our refocus the discussion of genAI's effects on projects in\nvisualization in the here and now with its respective opportunities and\npitfalls for future visualization research. At a time when public trust in\nscience is in jeopardy, we are reminded to first do no harm, not just in\nbiomedical visualization but in science communication more broadly. Our\nobservations reaffirm the necessity of human intervention for empathetic design\nand assessment of accurate scientific visuals.", "comment": "11 pages, 3 figures. Accepted to IEEE VIS 2025 Conference", "pdf_url": "http://arxiv.org/pdf/2507.14494v1", "cate": "cs.HC", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14293", "title": "WebGuard: Building a Generalizable Guardrail for Web Agents", "authors": ["Boyuan Zheng", "Zeyi Liao", "Scott Salisbury", "Zeyuan Liu", "Michael Lin", "Qinyuan Zheng", "Zifan Wang", "Xiang Deng", "Dawn Song", "Huan Sun", "Yu Su"], "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      We publicly release WebGuard, along with its annotation tools and fine-tuned models, to facilitate open-source research on monitoring and safeguarding web agents. All resources are available at this https URL", "url": "http://arxiv.org/abs/2507.14293v1", "summary": "The rapid development of autonomous web agents powered by Large Language\nModels (LLMs), while greatly elevating efficiency, exposes the frontier risk of\ntaking unintended or harmful actions. This situation underscores an urgent need\nfor effective safety measures, akin to access controls for human users. To\naddress this critical challenge, we introduce WebGuard, the first comprehensive\ndataset designed to support the assessment of web agent action risks and\nfacilitate the development of guardrails for real-world online environments. In\ndoing so, WebGuard specifically focuses on predicting the outcome of\nstate-changing actions and contains 4,939 human-annotated actions from 193\nwebsites across 22 diverse domains, including often-overlooked long-tail\nwebsites. These actions are categorized using a novel three-tier risk schema:\nSAFE, LOW, and HIGH. The dataset includes designated training and test splits\nto support evaluation under diverse generalization settings. Our initial\nevaluations reveal a concerning deficiency: even frontier LLMs achieve less\nthan 60% accuracy in predicting action outcomes and less than 60% recall in\nlagging HIGH-risk actions, highlighting the risks of deploying\ncurrent-generation agents without dedicated safeguards. We therefore\ninvestigate fine-tuning specialized guardrail models using WebGuard. We conduct\ncomprehensive evaluations across multiple generalization settings and find that\na fine-tuned Qwen2.5VL-7B model yields a substantial improvement in\nperformance, boosting accuracy from 37% to 80% and HIGH-risk action recall from\n20% to 76%. Despite these improvements, the performance still falls short of\nthe reliability required for high-stakes deployment, where guardrails must\napproach near-perfect accuracy and recall.", "comment": "We publicly release WebGuard, along with its annotation tools and\n  fine-tuned models, to facilitate open-source research on monitoring and\n  safeguarding web agents. All resources are available at\n  https://github.com/OSU-NLP-Group/WebGuard", "pdf_url": "http://arxiv.org/pdf/2507.14293v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15146", "title": "Design of an Edge-based Portable EHR System for Anemia Screening in Remote Health Applications", "authors": ["Sebastian A. Cruz Romero", "Misael J. Mercado Hernandez", "Samir Y. Ali Rivera", "Jorge A. Santiago Fernandez", "Wilfredo E. Lugo Beauchamp"], "categories": ["cs.ET", "cs.AI", "cs.CV", "cs.CY", "cs.LG", "cs.SE"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE Global Humanitarian Technology Conference 2025", "url": "http://arxiv.org/abs/2507.15146v1", "summary": "The design of medical systems for remote, resource-limited environments faces\npersistent challenges due to poor interoperability, lack of offline support,\nand dependency on costly infrastructure. Many existing digital health solutions\nneglect these constraints, limiting their effectiveness for frontline health\nworkers in underserved regions. This paper presents a portable, edge-enabled\nElectronic Health Record platform optimized for offline-first operation, secure\npatient data management, and modular diagnostic integration. Running on\nsmall-form factor embedded devices, it provides AES-256 encrypted local storage\nwith optional cloud synchronization for interoperability. As a use case, we\nintegrated a non-invasive anemia screening module leveraging fingernail pallor\nanalysis. Trained on 250 patient cases (27\\% anemia prevalence) with\nKDE-balanced data, the Random Forest model achieved a test RMSE of 1.969 g/dL\nand MAE of 1.490 g/dL. A severity-based model reached 79.2\\% sensitivity. To\noptimize performance, a YOLOv8n-based nail bed detector was quantized to INT8,\nreducing inference latency from 46.96 ms to 21.50 ms while maintaining mAP@0.5\nat 0.995. The system emphasizes low-cost deployment, modularity, and data\nprivacy compliance (HIPAA/GDPR), addressing critical barriers to digital health\nadoption in disconnected settings. Our work demonstrates a scalable approach to\nenhance portable health information systems and support frontline healthcare in\nunderserved regions.", "comment": "Accepted at IEEE Global Humanitarian Technology Conference 2025", "pdf_url": "http://arxiv.org/pdf/2507.15146v1", "cate": "cs.ET", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14214", "title": "Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale", "authors": ["Rui Zhao", "Vladyslav Melnychuk", "Jun Zhao", "Jesse Wright", "Nigel Shadbolt"], "categories": ["cs.CL", "cs.CR", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14214v1", "summary": "In modern times, people have numerous online accounts, but they rarely read\nthe Terms of Service or Privacy Policy of those sites despite claiming\notherwise. This paper introduces PoliAnalyzer, a neuro-symbolic system that\nassists users with personalized privacy policy analysis. PoliAnalyzer uses\nNatural Language Processing (NLP) to extract formal representations of data\nusage practices from policy texts. In favor of deterministic, logical inference\nis applied to compare user preferences with the formal privacy policy\nrepresentation and produce a compliance report. To achieve this, we extend an\nexisting formal Data Terms of Use policy language to model privacy policies as\napp policies and user preferences as data policies. In our evaluation using our\nenriched PolicyIE dataset curated by legal experts, PoliAnalyzer demonstrated\nhigh accuracy in identifying relevant data usage practices, achieving F1-score\nof 90-100% across most tasks. Additionally, we demonstrate how PoliAnalyzer can\nmodel diverse user data-sharing preferences, derived from prior research as 23\nuser profiles, and perform compliance analysis against the top 100 most-visited\nwebsites. This analysis revealed that, on average, 95.2% of a privacy policy's\nsegments do not conflict with the analyzed user preferences, enabling users to\nconcentrate on understanding the 4.8% (636 / 13205) that violates preferences,\nsignificantly reducing cognitive burden. Further, we identified common\npractices in privacy policies that violate user expectations - such as the\nsharing of location data with 3rd parties. This paper demonstrates that\nPoliAnalyzer can support automated personalized privacy policy analysis at\nscale using off-the-shelf NLP tools. This sheds light on a pathway to help\nindividuals regain control over their data and encourage societal discussions\non platform data practices to promote a fairer power dynamic.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14214v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2506.11475", "title": "AutoGen Driven Multi Agent Framework for Iterative Crime Data Analysis and Prediction", "authors": ["Syeda Kisaa Fatima", "Tehreem Zubair", "Noman Ahmed", "Asifullah Khan"], "categories": ["cs.MA", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.11475v2", "summary": "This paper introduces LUCID-MA (Learning and Understanding Crime through\nDialogue of Multiple Agents), an innovative AI powered framework where multiple\nAI agents collaboratively analyze and understand crime data. Our system that\nconsists of three core components: an analysis assistant that highlights\nspatiotemporal crime patterns; a feedback component that reviews and refines\nanalytical results; and a prediction component that forecasts future crime\ntrends. With a well-designed prompt and the LLaMA-2-13B-Chat-GPTQ model, it\nruns completely offline and allows the agents undergo self-improvement through\n100 rounds of communication with less human interaction. A scoring function is\nincorporated to evaluate agent performance, providing visual plots to track\nlearning progress. This work demonstrates the potential of AutoGen-style agents\nfor autonomous, scalable, and iterative analysis in social science domains,\nmaintaining data privacy through offline execution. It also showcases a\ncomputational model with emergent intelligence, where the system's global\nbehavior emerges from the interactions of its agents. This emergent behavior\nmanifests as enhanced individual agent performance, driven by collaborative\ndialogue between the LLM-based agents.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.11475v2", "cate": "cs.MA", "date": "2025-06-13", "updated": "2025-07-20"}
{"id": "2507.14914", "title": "One Step Beyond: Feedthrough & Placement-Aware Rectilinear Floorplanner", "authors": ["Zhexuan Xu", "Jie Wang", "Siyuan Xu", "Zijie Geng", "Mingxuan Yuan", "Feng Wu"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14914v1", "summary": "Floorplanning determines the shapes and locations of modules on a chip canvas\nand plays a critical role in optimizing the chip's Power, Performance, and Area\n(PPA) metrics. However, existing floorplanning approaches often fail to\nintegrate with subsequent physical design stages, leading to suboptimal\nin-module component placement and excessive inter-module feedthrough. To tackle\nthis challenge, we propose Flora, a three-stage feedthrough and placement aware\nrectilinear floorplanner. In the first stage, Flora employs wiremask and\nposition mask techniques to achieve coarse-grained optimization of HPWL and\nfeedthrough. In the second stage, under the constraint of a fixed outline,\nFlora achieves a zero-whitespace layout by locally resizing module shapes,\nthereby performing fine-grained optimization of feedthrough and improving\ncomponent placement. In the third stage, Flora utilizes a fast tree\nsearch-based method to efficiently place components-including macros and\nstandard cells-within each module, subsequently adjusting module boundaries\nbased on the placement results to enable cross-stage optimization. Experimental\nresults show that Flora outperforms recent state-of-the-art floorplanning\napproaches, achieving an average reduction of 6% in HPWL, 5.16% in FTpin,\n29.15% in FTmod, and a 14% improvement in component placement performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14914v1", "cate": "cs.RO", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14527", "title": "PaperBridge: Crafting Research Narratives through Human-AI Co-Exploration", "authors": ["Runhua Zhang", "Yang Ouyang", "Leixian Shen", "Yuying Tang", "Xiaojuan Ma", "Huamin Qu", "Xian Xu"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Conditionally accepted by UIST'25", "url": "http://arxiv.org/abs/2507.14527v1", "summary": "Researchers frequently need to synthesize their own publications into\ncoherent narratives that demonstrate their scholarly contributions. To suit\ndiverse communication contexts, exploring alternative ways to organize one's\nwork while maintaining coherence is particularly challenging, especially in\ninterdisciplinary fields like HCI where individual researchers' publications\nmay span diverse domains and methodologies. In this paper, we present\nPaperBridge, a human-AI co-exploration system informed by a formative study and\ncontent analysis. PaperBridge assists researchers in exploring diverse\nperspectives for organizing their publications into coherent narratives. At its\ncore is a bi-directional analysis engine powered by large language models,\nsupporting iterative exploration through both top-down user intent (e.g.,\ndetermining organization structure) and bottom-up refinement on narrative\ncomponents (e.g., thematic paper groupings). Our user study (N=12) demonstrated\nPaperBridge's usability and effectiveness in facilitating the exploration of\nalternative research narratives. Our findings also provided empirical insights\ninto how interactive systems can scaffold academic communication tasks.", "comment": "Conditionally accepted by UIST'25", "pdf_url": "http://arxiv.org/pdf/2507.14527v1", "cate": "cs.HC", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14306", "title": "Manimator: Transforming Research Papers into Visual Explanations", "authors": ["Samarth P", "Vyoman Jain", "Shiva Golugula", "Motamarri Sai Sathvik"], "categories": ["cs.AI", "cs.MM"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14306v1", "summary": "Understanding complex scientific and mathematical concepts, particularly\nthose presented in dense research papers, poses a significant challenge for\nlearners. Dynamic visualizations can greatly enhance comprehension, but\ncreating them manually is time-consuming and requires specialized knowledge and\nskills. We introduce manimator, an open-source system that leverages Large\nLanguage Models to transform research papers and natural language prompts into\nexplanatory animations using the Manim engine. Manimator employs a pipeline\nwhere an LLM interprets the input text or research paper PDF to generate a\nstructured scene description outlining key concepts, mathematical formulas, and\nvisual elements and another LLM translates this description into executable\nManim Python code. We discuss its potential as an educational tool for rapidly\ncreating engaging visual explanations for complex STEM topics, democratizing\nthe creation of high-quality educational content.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14306v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15483", "title": "Advancing Lunar Communication through Inter-domain Space Networks and Dynamic Orchestration", "authors": ["Selen Gecgel Cetin", "Baris Donmez", "Gunes Karabulut Kurt"], "categories": ["cs.ET", "cs.NA", "math.NA"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15483v1", "summary": "The reawakened era of lunar exploration is defined by a strategic shift from\ntemporary visits to a sustained international and commercial presence,\nresulting in an unprecedented demand for a robust and continuously available\ncommunication infrastructure. The conventional direct-to-Earth communication\narchitecture relies on limited and oversubscribed deep space networks, which\nare further challenged by the radiative environment and insufficient visibility\nin certain areas of the cislunar domain. We address these issues by proposing a\nfoundational move toward inter-domain space network cooperation by introducing\narchitectures based on near space networks. They can directly service lunar\nsurface users or, via cislunar relays, by forming a resilient and multi-layered\ncommunication backbone. First, we establish a unified link analysis framework\nincorporating frequently disregarded environmental factors, such as the Moon's\nvariable illumination, to provide a high-fidelity performance evaluation.\nSecond, we assess architectures' reliability based on the outage risk,\nessential for quantifying the operational robustness of communication links.\nFinally, to manage the inherent dynamism of architectures, we propose an\ninter-domain space digital twin$-$a dynamic decision-making engine that\nperforms real-time analysis to autonomously select the best communication path,\nensuring high and stable reliability while simultaneously optimizing power\nconsumption. Overall, our paper provides a holistic architectural and\nconceptual management framework, emphasizing the necessity of lunar\ncommunications to support a permanent human and economic foothold on the Moon.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15483v1", "cate": "cs.ET", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14170", "title": "Catalyst: a Novel Regularizer for Structured Pruning with Auxiliary Extension of Parameter Space", "authors": ["Jaeheun Jung", "Donghun Lee"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICML 2025 workshop HiLD 2025 (3rd workshop on High-dimensional Learning Dynamics)", "url": "http://arxiv.org/abs/2507.14170v1", "summary": "Structured pruning aims to reduce the size and computational cost of deep\nneural networks by removing entire filters or channels. The traditional\nregularizers such as L1 or Group Lasso and its variants lead to\nmagnitude-biased pruning decisions, such that the filters with small magnitudes\nare likely to be pruned. Also, they often entail pruning results with almost\nzero margin around pruning decision boundary, such that tiny perturbation in a\nfilter magnitude can flip the pruning decision. In this paper, we identify the\nprecise algebraic condition under which pruning operations preserve model\nperformance, and use the condition to construct a novel regularizer defined in\nan extended parameter space via auxiliary catalyst variables. The proposed\nCatalyst regularization ensures fair pruning chance for each filters with\ntheoretically provable zero bias to their magnitude and robust pruning behavior\nachieved by wide-margin bifurcation of magnitudes between the preserved and the\npruned filters. The theoretical properties naturally lead to real-world\neffectiveness, as shown by empirical validations of Catalyst Pruning algorithm.\nPruning results on various datasets and models are superior to state-of-the-art\nfilter pruning methods, and at the same time confirm the predicted robust and\nfair pruning characteristics of Catalyst pruning.", "comment": "ICML 2025 workshop HiLD 2025 (3rd workshop on High-dimensional\n  Learning Dynamics)", "pdf_url": "http://arxiv.org/pdf/2507.14170v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.14268", "title": "Comparative Analysis of Algorithms for the Fitting of Tessellations to 3D Image Data", "authors": ["Andreas Alpers", "Orkun Furat", "Christian Jung", "Matthias Neumann", "Claudia Redenbach", "Aigerim Saken", "Volker Schmidt"], "categories": ["cs.CV", "cond-mat.mtrl-sci", "math.OC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      31 pages, 16 figures, 8 tables", "url": "http://arxiv.org/abs/2507.14268v1", "summary": "This paper presents a comparative analysis of algorithmic strategies for\nfitting tessellation models to 3D image data of materials such as polycrystals\nand foams. In this steadily advancing field, we review and assess\noptimization-based methods -- including linear and nonlinear programming,\nstochastic optimization via the cross-entropy method, and gradient descent --\nfor generating Voronoi, Laguerre, and generalized balanced power diagrams\n(GBPDs) that approximate voxelbased grain structures. The quality of fit is\nevaluated on real-world datasets using discrepancy measures that quantify\ndifferences in grain volume, surface area, and topology. Our results highlight\ntrade-offs between model complexity, the complexity of the optimization\nroutines involved, and the quality of approximation, providing guidance for\nselecting appropriate methods based on data characteristics and application\nneeds.", "comment": "31 pages, 16 figures, 8 tables", "pdf_url": "http://arxiv.org/pdf/2507.14268v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14322", "title": "FedStrategist: A Meta-Learning Framework for Adaptive and Robust Aggregation in Federated Learning", "authors": ["Md Rafid Haque", "Abu Raihan Mostofa Kamal", "Md. Azam Hossain"], "categories": ["cs.LG", "cs.CR", "cs.DC", "I.2.11; C.2.4; K.6.5"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      24 pages, 8 figures. This work is intended for a journal submission", "url": "http://arxiv.org/abs/2507.14322v1", "summary": "Federated Learning (FL) offers a paradigm for privacy-preserving\ncollaborative AI, but its decentralized nature creates significant\nvulnerabilities to model poisoning attacks. While numerous static defenses\nexist, their effectiveness is highly context-dependent, often failing against\nadaptive adversaries or in heterogeneous data environments. This paper\nintroduces FedStrategist, a novel meta-learning framework that reframes robust\naggregation as a real-time, cost-aware control problem. We design a lightweight\ncontextual bandit agent that dynamically selects the optimal aggregation rule\nfrom an arsenal of defenses based on real-time diagnostic metrics. Through\ncomprehensive experiments, we demonstrate that no single static rule is\nuniversally optimal. We show that our adaptive agent successfully learns\nsuperior policies across diverse scenarios, including a ``Krum-favorable\"\nenvironment and against a sophisticated \"stealth\" adversary designed to\nneutralize specific diagnostic signals. Critically, we analyze the paradoxical\nscenario where a non-robust baseline achieves high but compromised accuracy,\nand demonstrate that our agent learns a conservative policy to prioritize model\nintegrity. Furthermore, we prove the agent's policy is controllable via a\nsingle \"risk tolerance\" parameter, allowing practitioners to explicitly manage\nthe trade-off between performance and security. Our work provides a new,\npractical, and analyzable approach to creating resilient and intelligent\ndecentralized AI systems.", "comment": "24 pages, 8 figures. This work is intended for a journal submission", "pdf_url": "http://arxiv.org/pdf/2507.14322v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2502.05986", "title": "Preventing Rogue Agents Improves Multi-Agent Collaboration", "authors": ["Ohav Barbi", "Ori Yoran", "Mor Geva"], "categories": ["cs.CL", "cs.MA"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted as a spotlight to REALM (First Workshop for Research on Agent Language Models) at ACL 2025", "url": "http://arxiv.org/abs/2502.05986v2", "summary": "Multi-agent systems, where specialized agents collaborate to solve a shared\ntask hold great potential, from increased modularity to simulating complex\nenvironments. However, they also have a major caveat -- a single agent can\ncause the entire system to fail. Consider a simple game where the knowledge to\nsolve the task is distributed between agents, which share information in a\ncommunication channel. At each round, any of the agents can terminate the game\nand make the final prediction, even if they are uncertain about the outcome of\ntheir action. Detection of such rogue agents before they act may prevent the\nsystem's failure. In this work, we propose to monitor agents during action\nprediction and intervene when a future error is likely to occur. To test our\napproach, we introduce WhoDunitEnv, a multi-agent collaboration environment\nthat allows modular control over task complexity and communication structure.\nExperiments on WhoDunitEnv, code generation tasks and the GovSim environment\nfor resource sustainability show that our approach leads to substantial\nperformance gains up to 17.4%, 2.5% and 20%, respectively. Thorough analysis\nshows that our monitors successfully identify critical points of agent\nconfusion and our interventions effectively stop agent errors from propagating.", "comment": "Accepted as a spotlight to REALM (First Workshop for Research on\n  Agent Language Models) at ACL 2025", "pdf_url": "http://arxiv.org/pdf/2502.05986v2", "cate": "cs.CL", "date": "2025-02-09", "updated": "2025-07-21"}
{"id": "2507.14929", "title": "Digital twin and extended reality for teleoperation of the electric vehicle battery disassembly", "authors": ["Tero Kaarlela", "Sami Salo", "Jose Outeiro"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14929v1", "summary": "Disassembling and sorting Electric Vehicle Batteries (EVBs) supports a\nsustainable transition to electric vehicles by enabling a closed-loop supply\nchain. Currently, the manual disassembly process exposes workers to hazards,\nincluding electrocution and toxic chemicals. We propose a teleoperated system\nfor the safe disassembly and sorting of EVBs. A human-in-the-loop can create\nand save disassembly sequences for unknown EVB types, enabling future\nautomation. An RGB camera aligns the physical and digital twins of the EVB, and\nthe digital twin of the robot is based on the Robot Operating System (ROS)\nmiddleware. This hybrid approach combines teleoperation and automation to\nimprove safety, adaptability, and efficiency in EVB disassembly and sorting.\nThe economic contribution is realized by reducing labor dependency and\nincreasing throughput in battery recycling. An online pilot study was set up to\nevaluate the usability of the presented approach, and the results demonstrate\nthe potential as a user-friendly solution.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14929v1", "cate": "cs.RO", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14537", "title": "Uncovering the EEG Temporal Representation of Low-dimensional Object Properties", "authors": ["Jiahua Tang", "Song Wang", "Jiachen Zou", "Chen Wei", "Quanying Liu"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14537v1", "summary": "Understanding how the human brain encodes and processes external visual\nstimuli has been a fundamental challenge in neuroscience. With advancements in\nartificial intelligence, sophisticated visual decoding architectures have\nachieved remarkable success in fMRI research, enabling more precise and\nfine-grained spatial concept localization. This has provided new tools for\nexploring the spatial representation of concepts in the brain. However, despite\nthe millisecond-scale temporal resolution of EEG, which offers unparalleled\nadvantages in tracking the dynamic evolution of cognitive processes, the\ntemporal dynamics of neural representations based on EEG remain underexplored.\nThis is primarily due to EEG's inherently low signal-to-noise ratio and its\ncomplex spatiotemporal coupling characteristics. To bridge this research gap,\nwe propose a novel approach that integrates advanced neural decoding algorithms\nto systematically investigate how low-dimensional object properties are\ntemporally encoded in EEG signals. We are the first to attempt to identify the\nspecificity and prototypical temporal characteristics of concepts within\ntemporal distributions. Our framework not only enhances the interpretability of\nneural representations but also provides new insights into visual decoding in\nbrain-computer interfaces (BCI).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14537v1", "cate": "cs.HC", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14334", "title": "Language Models as Ontology Encoders", "authors": ["Hui Yang", "Jiaoyan Chen", "Yuan He", "Yongsheng Gao", "Ian Horrocks"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14334v1", "summary": "OWL (Web Ontology Language) ontologies which are able to formally represent\ncomplex knowledge and support semantic reasoning have been widely adopted\nacross various domains such as healthcare and bioinformatics. Recently,\nontology embeddings have gained wide attention due to its potential to infer\nplausible new knowledge and approximate complex reasoning. However, existing\nmethods face notable limitations: geometric model-based embeddings typically\noverlook valuable textual information, resulting in suboptimal performance,\nwhile the approaches that incorporate text, which are often based on language\nmodels, fail to preserve the logical structure. In this work, we propose a new\nontology embedding method OnT, which tunes a Pretrained Language Model (PLM)\nvia geometric modeling in a hyperbolic space for effectively incorporating\ntextual labels and simultaneously preserving class hierarchies and other\nlogical relationships of Description Logic EL. Extensive experiments on four\nreal-world ontologies show that OnT consistently outperforms the baselines\nincluding the state-of-the-art across both tasks of prediction and inference of\naxioms. OnT also demonstrates strong potential in real-world applications,\nindicated by its robust transfer learning abilities and effectiveness in real\ncases of constructing a new ontology from SNOMED CT. Data and code are\navailable at https://github.com/HuiYang1997/OnT.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14334v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14209", "title": "White paper: Towards Human-centric and Sustainable 6G Services -- the fortiss Research Perspective", "authors": ["Rute C. Sofia", "Hao Shen", "Yuanting Liu", "Severin Kacianka", "Holger Pfeifer"], "categories": ["cs.NI", "cs.ET"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14209v1", "summary": "As a leading research institute in software-intensive systems, fortiss is\nactively shaping the vision of Sixth Generation Mobile Communication (6G). Our\nmission is to ensure that 6G technologies go beyond technical advancements and\nare aligned with societal needs. fortiss plays a key role in 6G initiatives\nworldwide, including contributions to standardization bodies and collaborative\nResearch and Development programs. We focus on software-defined, AI-enabled,\nand sustainable communication services that prioritize human values and\nlong-term impact. 6G will redefine digital connectivity through cognitive\nintelligence, decentralized orchestration, and sustainability-oriented\narchitectures. As expectations rise for ultra-reliable low-latency\ncommunication (URLLC) and personalized digital services, 6G must outperform\nprior generations. It will rely on AI-native networking, Edge-Cloud resource\norchestration, and energy-aware data frameworks, ensuring both technical\nperformance and societal relevance. This white paper presents the fortiss\nvision for a human-centric, sustainable, and AI-integrated 6G network. It\noutlines key research domains such as semantic communication, green\norchestration, and distributed AI, all linked to societal and technological\nchallenges. The white paper is aimed at researchers, industry experts,\npolicymakers, and developers. It articulates the strategic direction and\ncontributions of fortiss to 6G, emphasizing responsible innovation and\ninterdisciplinary collaboration toward a meaningful 2030 vision.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14209v1", "cate": "cs.NI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.14171", "title": "IPPRO: Importance-based Pruning with PRojective Offset for Magnitude-indifferent Structural Pruning", "authors": ["Jaeheun Jung", "Jaehyuk Lee", "Yeajin Lee", "Donghun Lee"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14171v1", "summary": "With the growth of demand on neural network compression methods, the\nstructured pruning methods including importance-based approach are actively\nstudied. The magnitude importance and many correlated modern importance\ncriteria often limit the capacity of pruning decision, since the filters with\nlarger magnitudes are not likely to be pruned if the smaller one didn't, even\nif it is redundant. In this paper, we propose a novel pruning strategy to\nchallenge this dominating effect of magnitude and provide fair chance to each\nfilter to be pruned, by placing it on projective space. After that, we observe\nthe gradient descent movement whether the filters move toward the origin or\nnot, to measure how the filter is likely to be pruned. This measurement is used\nto construct PROscore, a novel importance score for IPPRO, a novel\nimportance-based structured pruning with magnitude-indifference. Our evaluation\nresults shows that the proposed importance criteria using the projective space\nachieves near-lossless pruning by reducing the performance drop in pruning,\nwith promising performance after the finetuning. Our work debunks the\n``size-matters'' myth in pruning and expands the frontier of importance-based\npruning both theoretically and empirically.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14171v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.14303", "title": "Semantic Segmentation based Scene Understanding in Autonomous Vehicles", "authors": ["Ehsan Rassekh"], "categories": ["cs.CV", "I.4.8"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      74 pages, 35 figures, Master's Thesis, Institute for Advanced Studies in Basic Sciences (IASBS), Zanjan, Iran, 2023", "url": "http://arxiv.org/abs/2507.14303v1", "summary": "In recent years, the concept of artificial intelligence (AI) has become a\nprominent keyword because it is promising in solving complex tasks. The need\nfor human expertise in specific areas may no longer be needed because machines\nhave achieved successful results using artificial intelligence and can make the\nright decisions in critical situations. This process is possible with the help\nof deep learning (DL), one of the most popular artificial intelligence\ntechnologies. One of the areas in which the use of DL is used is in the\ndevelopment of self-driving cars, which is very effective and important. In\nthis work, we propose several efficient models to investigate scene\nunderstanding through semantic segmentation. We use the BDD100k dataset to\ninvestigate these models. Another contribution of this work is the usage of\nseveral Backbones as encoders for models. The obtained results show that\nchoosing the appropriate backbone has a great effect on the performance of the\nmodel for semantic segmentation. Better performance in semantic segmentation\nallows us to understand better the scene and the environment around the agent.\nIn the end, we analyze and evaluate the proposed models in terms of accuracy,\nmean IoU, and loss function, and the results show that these metrics are\nimproved.", "comment": "74 pages, 35 figures, Master's Thesis, Institute for Advanced Studies\n  in Basic Sciences (IASBS), Zanjan, Iran, 2023", "pdf_url": "http://arxiv.org/pdf/2507.14303v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14768", "title": "Collusion-Resilient Hierarchical Secure Aggregation with Heterogeneous Security Constraints", "authors": ["Zhou Li", "Xiang Zhang", "Jiawen Lv", "Jihao Fan", "Haiqiang Chen", "Giuseppe Caire"], "categories": ["cs.IT", "cs.CR", "cs.DC", "cs.LG", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      accepted by 2025 IEEE Information Theory Workshop", "url": "http://arxiv.org/abs/2507.14768v1", "summary": "Motivated by federated learning (FL), secure aggregation (SA) aims to\nsecurely compute, as efficiently as possible, the sum of a set of inputs\ndistributed across many users. To understand the impact of network topology,\nhierarchical secure aggregation (HSA) investigated the communication and secret\nkey generation efficiency in a 3-layer relay network, where clusters of users\nare connected to the aggregation server through an intermediate layer of\nrelays. Due to the pre-aggregation of the messages at the relays, HSA reduces\nthe communication burden on the relay-to-server links and is able to support a\nlarge number of users. However, as the number of users increases, a practical\nchallenge arises from heterogeneous security requirements--for example, users\nin different clusters may require varying levels of input protection. Motivated\nby this, we study weakly-secure HSA (WS-HSA) with collusion resilience, where\ninstead of protecting all the inputs from any set of colluding users, only the\ninputs belonging to a predefined collection of user groups (referred to as\nsecurity input sets) need to be protected against another predefined collection\nof user groups (referred to as collusion sets). Since the security input sets\nand collusion sets can be arbitrarily defined, our formulation offers a\nflexible framework for addressing heterogeneous security requirements in HSA.\nWe characterize the optimal total key rate, i.e., the total number of\nindependent key symbols required to ensure both server and relay security, for\na broad range of parameter configurations. For the remaining cases, we\nestablish lower and upper bounds on the optimal key rate, providing\nconstant-factor gap optimality guarantees.", "comment": "accepted by 2025 IEEE Information Theory Workshop", "pdf_url": "http://arxiv.org/pdf/2507.14768v1", "cate": "cs.IT", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2502.08898", "title": "Learning in Strategic Queuing Systems with Small Buffers", "authors": ["Ariana Abel", "Yoav Kolumbus", "Jeronimo Martin Duque", "Cristian Palma Foster", "Eva Tardos"], "categories": ["cs.GT", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.08898v2", "summary": "We consider learning outcomes in games with carryover effects between rounds:\nwhen outcomes in the present round affect the game in the future. An important\nexample of such systems is routers in networking, as they use simple learning\nalgorithms to find the best way to deliver packets to their desired\ndestination. This simple, myopic, and distributed decision process makes large\nqueuing systems easy to operate, but at the same time, the system needs more\ncapacity than would be required if all traffic were centrally coordinated.\nGaitonde and Tardos (EC 2020 and JACM 2023) initiated the study of such\nsystems, modeling them as an infinitely repeated game in which routers compete\nfor servers and the system maintains a state (the number of packets held at\neach queue) that results from outcomes of previous rounds. However, their model\nassumes that servers have no buffers at all, so routers have to resend all\npackets that were not served successfully, which makes their system model\nunrealistic. They show that in their model, even with hugely increased server\ncapacity relative to what is needed in the centrally coordinated case, ensuring\nthat the system is stable requires the use of timestamps and priority for older\npackets.\n  We consider a system with two important changes, which make the model more\nrealistic and allow for much higher traffic rates: first, we add a very small\nbuffer to each server, allowing the server to hold on to a single packet to be\nserved later (if it fails to serve it immediately), and second, we do not\nrequire timestamps or priority to older packets. Using theoretical analysis and\nsimulations, we show that when queues are learning, a small constant-factor\nincrease in server capacity, compared to what would be needed if centrally\ncoordinating, suffices to keep the system stable, even if servers select\nrandomly among packets arriving simultaneously.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.08898v2", "cate": "cs.GT", "date": "2025-02-13", "updated": "2025-07-19"}
{"id": "2507.14931", "title": "Designing Robots with, not for: A Co-Design Framework for Empowering Interactions in Forensic Psychiatry", "authors": ["Qiaoqiao Ren", "Remko Proesmans", "Arend Pissens", "Lara Dehandschutter", "William Denecker", "Lotte Rouckhout", "Joke Carrette", "Peter Vanhopplinus", "Tony Belpaeme", "Francis wyffels"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14931v1", "summary": "Forensic mental health care involves the treatment of individuals with severe\nmental disorders who have committed violent offences. These settings are often\ncharacterized by high levels of bureaucracy, risk avoidance, and restricted\nautonomy. Patients frequently experience a profound loss of control over their\nlives, leading to heightened psychological stress-sometimes resulting in\nisolation as a safety measure. In this study, we explore how co-design can be\nused to collaboratively develop a companion robot that helps monitor and\nregulate stress while maintaining tracking of the patients' interaction\nbehaviours for long-term intervention. We conducted four co-design workshops in\na forensic psychiatric clinic with patients, caregivers, and therapists. Our\nprocess began with the presentation of an initial speculative prototype to\ntherapists, enabling reflection on shared concerns, ethical risks, and\ndesirable features. This was followed by a creative ideation session with\npatients, a third workshop focused on defining desired functions and emotional\nresponses, and we are planning a final prototype demo to gather direct patient\nfeedback. Our findings emphasize the importance of empowering patients in the\ndesign process and adapting proposals based on their current emotional state.\nThe goal was to empower the patient in the design process and ensure each\npatient's voice was heard.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14931v1", "cate": "cs.RO", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14685", "title": "EventBox: A Novel Visual Encoding for Interactive Analysis of Temporal and Multivariate Attributes in Event Sequences", "authors": ["Luis Montana", "Jessica Magallanes", "Miguel Juarez", "Suzanne Mason", "Andrew Narracott", "Lindsey van Gemeren", "Steven Wood", "Maria-Cruz Villa-Uriol"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      This is the author's version of the article to be published in IEEE Transactions on Visualization and Computer Graphics, and presented at IEEE VIS 2025. 11 pages, 7 figures", "url": "http://arxiv.org/abs/2507.14685v1", "summary": "The rapid growth and availability of event sequence data across domains\nrequires effective analysis and exploration methods to facilitate\ndecision-making. Visual analytics combines computational techniques with\ninteractive visualizations, enabling the identification of patterns, anomalies,\nand attribute interactions. However, existing approaches frequently overlook\nthe interplay between temporal and multivariate attributes. We introduce\nEventBox, a novel data representation and visual encoding approach for\nanalyzing groups of events and their multivariate attributes. We have\nintegrated EventBox into Sequen-C, a visual analytics system for the analysis\nof event sequences. To enable the agile creation of EventBoxes in Sequen-C, we\nhave added user-driven transformations, including alignment, sorting,\nsubstitution and aggregation. To enhance analytical depth, we incorporate\nautomatically generated statistical analyses, providing additional insight into\nthe significance of attribute interactions. We evaluated our approach involving\n21 participants (3 domain experts, 18 novice data analysts). We used the ICE-T\nframework to assess visualization value, user performance metrics completing a\nseries of tasks, and interactive sessions with domain experts. We also present\nthree case studies with real-world healthcare data demonstrating how EventBox\nand its integration into Sequen-C reveal meaningful patterns, anomalies, and\ninsights. These results demonstrate that our work advances visual analytics by\nproviding a flexible solution for exploring temporal and multivariate\nattributes in event sequences.", "comment": "This is the author's version of the article to be published in IEEE\n  Transactions on Visualization and Computer Graphics, and presented at IEEE\n  VIS 2025. 11 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.14685v1", "cate": "cs.HC", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14335", "title": "ProofCompass: Enhancing Specialized Provers with LLM Guidance", "authors": ["Nicolas Wischermann", "Claudio Mayrink Verdun", "Gabriel Poesia", "Francesco Noseda"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      19 pages, 7 figures. Accepted at the 2nd AI for MATH Workshop at the 42nd International Conference on Machine Learning (ICML 2025)", "url": "http://arxiv.org/abs/2507.14335v1", "summary": "Language models have become increasingly powerful tools for formal\nmathematical reasoning. However, most existing approaches rely exclusively on\neither large general-purpose models or smaller specialized models, each with\ndistinct limitations, while training specialized large models still requires\nsignificant computational resources. This paper introduces ProofCompass, a\nnovel hybrid methodology that achieves remarkable computational efficiency by\nstrategically guiding existing specialized prover methods, such as\nDeepSeek-Prover-v1.5-RL (DSP-v1.5) with a Large Language Model (LLM) without\nrequiring additional model training. The LLM provides natural language proof\nstrategies and analyzes failed attempts to select intermediate lemmas, enabling\neffective problem decomposition. On the miniF2F benchmark, ProofCompass\ndemonstrates substantial resource efficiency: it outperforms DSP-v1.5 ($54.9\\%\n\\rightarrow 55.3\\%$) while using 25x fewer attempts ($3200 \\rightarrow 128$).\nOur synergistic approach paves the way for simultaneously improving\ncomputational efficiency and accuracy in formal theorem proving.", "comment": "19 pages, 7 figures. Accepted at the 2nd AI for MATH Workshop at the\n  42nd International Conference on Machine Learning (ICML 2025)", "pdf_url": "http://arxiv.org/pdf/2507.14335v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14333", "title": "Inverse-Designed Dot Product Engine", "authors": ["Anannya Mathur"], "categories": ["physics.optics", "cs.ET", "J.2; I.2.8; G.1.6"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "Comments:      48 pages, 18 figures", "url": "http://arxiv.org/abs/2507.14333v1", "summary": "The work presents an inverse-designed optical cavity that can direct light\nfrom two sources such that if the sources were to represent any number in the\nrange [-1,1] with magnitude encoded through the power emitted by the source and\nsign by switching the direction of source current, the photocurrent generated\nat the two output ports is proportional to the product of the two numbers. Let\nus say that the two sources encode x and y, which are two numbers $\\in$ [-1,1].\nMultiplication is reduced to the form $(x+y)^2 - (x-y)^2 = 4xy \\propto xy$. The\naddition and subtraction operations of the numbers are supported by\nconstructive and destructive interference, respectively. The work shows that\nreplacing the DDOT dot product engine of the Lightening Transformer with the\noptical cavity proposed to calculate the dot product can lead to a reduction in\nthe area occupied by the photonic core by 88 \\%, can reduce the power\nconsumption by lasers by around 23.43 \\%, and bring down energy consumption\nwhile training DeiT models by 0.88 \\%. The cavities can generate photocurrents\nof the form $1.057 xy + 0.249$ with $R^2=0.88,$ thus showing a relationship of\ndirect proportionality between the target product $xy$ and the output of the\ncavity in response to stimuli encoding $x$ and $y$.", "comment": "48 pages, 18 figures", "pdf_url": "http://arxiv.org/pdf/2507.14333v1", "cate": "physics.optics", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14172", "title": "Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI", "authors": ["Julien Pourcel", "Cédric Colas", "Pierre-Yves Oudeyer"], "categories": ["cs.LG", "cs.AI", "cs.NE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14172v1", "summary": "Many program synthesis tasks prove too challenging for even state-of-the-art\nlanguage models to solve in single attempts. Search-based evolutionary methods\noffer a promising alternative by exploring solution spaces iteratively, but\ntheir effectiveness remain limited by the fixed capabilities of the underlying\ngenerative model.\n  We propose SOAR, a method that learns program synthesis by integrating\nlanguage models into a self-improving evolutionary loop.\n  SOAR alternates between (1) an evolutionary search that uses an LLM to sample\nand refine candidate solutions, and (2) a hindsight learning phase that\nconverts search attempts into valid problem-solution pairs used to fine-tune\nthe LLM's sampling and refinement capabilities\\, -- \\,enabling increasingly\neffective search in subsequent iterations.\n  On the challenging ARC-AGI benchmark, SOAR achieves significant performance\ngains across model scales and iterations, leveraging positive transfer between\nthe sampling and refinement finetuning tasks. These improvements carry over to\ntest-time adaptation, enabling SOAR to solve 52\\% of the public test set. Our\ncode is open-sourced at: https://github.com/flowersteam/SOAR", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14172v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.14312", "title": "CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation", "authors": ["Marc Lafon", "Gustavo Adolfo Vargas Hakim", "Clément Rambour", "Christian Desrosier", "Nicolas Thome"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14312v1", "summary": "Vision-language models (VLMs) like CLIP exhibit strong zero-shot capabilities\nbut often fail to generalize under distribution shifts. Test-time adaptation\n(TTA) allows models to update at inference time without labeled data, typically\nvia entropy minimization. However, this objective is fundamentally misaligned\nwith the contrastive image-text training of VLMs, limiting adaptation\nperformance and introducing failure modes such as pseudo-label drift and class\ncollapse. We propose CLIPTTA, a new gradient-based TTA method for\nvision-language models that leverages a soft contrastive loss aligned with\nCLIP's pre-training objective. We provide a theoretical analysis of CLIPTTA's\ngradients, showing how its batch-aware design mitigates the risk of collapse.\nWe further extend CLIPTTA to the open-set setting, where both in-distribution\n(ID) and out-of-distribution (OOD) samples are encountered, using an Outlier\nContrastive Exposure (OCE) loss to improve OOD detection. Evaluated on 75\ndatasets spanning diverse distribution shifts, CLIPTTA consistently outperforms\nentropy-based objectives and is highly competitive with state-of-the-art TTA\nmethods, outperforming them on a large number of datasets and exhibiting more\nstable performance across diverse shifts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14312v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14839", "title": "Time Entangled Quantum Blockchain with Phase Encoding for Classical Data", "authors": ["Ruwanga Konara", "Kasun De Zoysa", "Anuradha Mahasinghe", "Asanka Sayakkara", "Nalin Ranasinghe"], "categories": ["quant-ph", "cs.CR", "C.2.4; E.1"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14839v1", "summary": "With rapid advancements in quantum computing, it is widely believed that\nthere will be quantum hardware capable of compromising classical cryptography\nand hence, the internet and the current information security infrastructure in\nthe coming decade. This is mainly due to the operational realizations of\nquantum algorithms such as Grover and Shor, to which the current classical\nencryption protocols are vulnerable. Blockchains, i.e., blockchain data\nstructures and their data, rely heavily on classical cryptography. One approach\nto secure blockchain is to attempt to achieve information theoretical security\nby defining blockchain on quantum technologies. There have been two\nconceptualizations of blockchains on quantum registers: the time-entangled\nGreenberger-Horne-Zeilinger (GHZ) state blockchain and the quantum hypergraph\nblockchain. On our part, an attempt is made to conceptualize a new quantum\nblockchain combining features of both these schemes to achieve the absolute\nsecurity of the time-temporal GHZ blockchain and the scalability and efficiency\nof the quantum hypergraph blockchain in the proposed quantum blockchain\nprotocol.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14839v1", "cate": "quant-ph", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14967", "title": "Heterogeneous object manipulation on nonlinear soft surface through linear controller", "authors": ["Pratik Ingle", "Kasper Støy", "Andres Faiña"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 3 figures", "url": "http://arxiv.org/abs/2507.14967v1", "summary": "Manipulation surfaces indirectly control and reposition objects by actively\nmodifying their shape or properties rather than directly gripping objects.\nThese surfaces, equipped with dense actuator arrays, generate dynamic\ndeformations. However, a high-density actuator array introduces considerable\ncomplexity due to increased degrees of freedom (DOF), complicating control\ntasks. High DOF restrict the implementation and utilization of manipulation\nsurfaces in real-world applications as the maintenance and control of such\nsystems exponentially increase with array/surface size. Learning-based control\napproaches may ease the control complexity, but they require extensive training\nsamples and struggle to generalize for heterogeneous objects. In this study, we\nintroduce a simple, precise and robust PID-based linear close-loop feedback\ncontrol strategy for heterogeneous object manipulation on MANTA-RAY\n(Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation\ndensity). Our approach employs a geometric transformation-driven PID\ncontroller, directly mapping tilt angle control outputs(1D/2D) to actuator\ncommands to eliminate the need for extensive black-box training. We validate\nthe proposed method through simulations and experiments on a physical system,\nsuccessfully manipulating objects with diverse geometries, weights and\ntextures, including fragile objects like eggs and apples. The outcomes\ndemonstrate that our approach is highly generalized and offers a practical and\nreliable solution for object manipulation on soft robotic manipulation,\nfacilitating real-world implementation without prohibitive training demands.", "comment": "8 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.14967v1", "cate": "cs.RO", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14702", "title": "A Notification Based Nudge for Handling Excessive Smartphone Use", "authors": ["Partha Sarker", "Dipto Dey", "Marium-E-Jannat"], "categories": ["cs.HC", "F.2.2, I.2.7"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      6 pages, 8 figures", "url": "http://arxiv.org/abs/2507.14702v1", "summary": "Excessive use of smartphones is a worldwide known issue. In this study, we\nproposed a notification-based intervention approach to reduce smartphone\noveruse without making the user feel any annoyance or irritation. Most of the\nwork in this field tried to reduce smartphone overuse by making smartphone use\nmore difficult for the user. In our user study (n = 109), we found that 19.3%\nof the participants are unwilling to use any usage-limiting application because\na) they do not want their smartphone activities to get restricted or b) those\napplications are annoying. Following that, we devised a hypothesis to minimize\nsmartphone usage among undergraduates. Finally, we designed a prototype for\nAndroid, \"App Usage Monitor,\" and conducted a 3-week experiment through which\nwe found proof of concept for our hypothesis. In our prototype, we combined\ntechniques such as nudge and visualization to increase self-awareness among the\nuser by leveraging notifications.", "comment": "6 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.14702v1", "cate": "cs.HC", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14393", "title": "Adaptive Multi-Agent Reasoning via Automated Workflow Generation", "authors": ["Humza Sami", "Mubashir ul Islam", "Pierre-Emmanuel Gaillardon", "Valerio Tenace"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14393v1", "summary": "The rise of Large Reasoning Models (LRMs) promises a significant leap forward\nin language model capabilities, aiming to tackle increasingly sophisticated\ntasks with unprecedented efficiency and accuracy. However, despite their\nimpressive performance, recent studies have highlighted how current reasoning\nmodels frequently fail to generalize to novel, unseen problems, often resorting\nto memorized solutions rather than genuine inferential reasoning. Such behavior\nunderscores a critical limitation in modern LRMs, i.e., their tendency toward\noverfitting, which in turn results in poor generalization in problem-solving\ncapabilities.\n  In this paper, we introduce Nexus Architect, an enhanced iteration of our\nmulti-agent system framework, Nexus, equipped with a novel automated workflow\nsynthesis mechanism. Given a user's prompt and a small set of representative\nexamples, the Architect autonomously generates a tailored reasoning workflow by\nselecting suitable strategies, tool integrations, and adversarial techniques\nfor a specific problem class. Furthermore, the Architect includes an iterative\nprompt refinement mechanism that fine-tunes agents' system prompts to maximize\nperformance and improve the generalization capabilities of the system.\n  We empirically evaluate Nexus Architect by employing an off-the-shelf,\nnon-reasoning model on a custom dataset of challenging logical questions and\ncompare its performance against state-of-the-art LRMs. Results show that Nexus\nArchitect consistently outperforms existing solutions, achieving up to a 66%\nincrease in pass rate over Gemini 2.5 Flash Preview, nearly 2.5$\\times$ against\nClaude Sonnet 4 and DeepSeek-R1, and over 3$\\times$ w.r.t. Llama 4 Scout.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14393v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15063", "title": "Quantum Annealing for Machine Learning: Applications in Feature Selection, Instance Selection, and Clustering", "authors": ["Chloe Pomeroy", "Aleksandar Pramov", "Karishma Thakrar", "Lakshmi Yendapalli"], "categories": ["quant-ph", "cs.ET", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15063v1", "summary": "This paper explores the applications of quantum annealing (QA) and classical\nsimulated annealing (SA) to a suite of combinatorial optimization problems in\nmachine learning, namely feature selection, instance selection, and clustering.\nWe formulate each task as a Quadratic Unconstrained Binary Optimization (QUBO)\nproblem and implement both quantum and classical solvers to compare their\neffectiveness. For feature selection, we propose several QUBO configurations\nthat balance feature importance and redundancy, showing that quantum annealing\n(QA) produces solutions that are computationally more efficient. In instance\nselection, we propose a few novel heuristics for instance-level importance\nmeasures that extend existing methods. For clustering, we embed a\nclassical-to-quantum pipeline, using classical clustering followed by\nQUBO-based medoid refinement, and demonstrate consistent improvements in\ncluster compactness and retrieval metrics. Our results suggest that QA can be a\ncompetitive and efficient tool for discrete machine learning optimization, even\nwithin the constraints of current quantum hardware.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15063v1", "cate": "quant-ph", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14175", "title": "Latent Space Data Fusion Outperforms Early Fusion in Multimodal Mental Health Digital Phenotyping Data", "authors": ["Youcef Barkat", "Dylan Hamitouche", "Deven Parekh", "Ivy Guo", "David Benrimoh"], "categories": ["cs.LG", "cs.AI", "stat.AP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14175v1", "summary": "Background: Mental illnesses such as depression and anxiety require improved\nmethods for early detection and personalized intervention. Traditional\npredictive models often rely on unimodal data or early fusion strategies that\nfail to capture the complex, multimodal nature of psychiatric data. Advanced\nintegration techniques, such as intermediate (latent space) fusion, may offer\nbetter accuracy and clinical utility. Methods: Using data from the BRIGHTEN\nclinical trial, we evaluated intermediate (latent space) fusion for predicting\ndaily depressive symptoms (PHQ-2 scores). We compared early fusion implemented\nwith a Random Forest (RF) model and intermediate fusion implemented via a\nCombined Model (CM) using autoencoders and a neural network. The dataset\nincluded behavioral (smartphone-based), demographic, and clinical features.\nExperiments were conducted across multiple temporal splits and data stream\ncombinations. Performance was evaluated using mean squared error (MSE) and\ncoefficient of determination (R2). Results: The CM outperformed both RF and\nLinear Regression (LR) baselines across all setups, achieving lower MSE (0.4985\nvs. 0.5305 with RF) and higher R2 (0.4695 vs. 0.4356). The RF model showed\nsigns of overfitting, with a large gap between training and test performance,\nwhile the CM maintained consistent generalization. Performance was best when\nintegrating all data modalities in the CM (in contradistinction to RF),\nunderscoring the value of latent space fusion for capturing non-linear\ninteractions in complex psychiatric datasets. Conclusion: Latent space fusion\noffers a robust alternative to traditional fusion methods for prediction with\nmultimodal mental health data. Future work should explore model\ninterpretability and individual-level prediction for clinical deployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14175v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.14315", "title": "A Hidden Stumbling Block in Generalized Category Discovery: Distracted Attention", "authors": ["Qiyu Xu", "Zhanxuan Hu", "Yu Duan", "Ercheng Pei", "Yonghang Tai"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14315v1", "summary": "Generalized Category Discovery (GCD) aims to classify unlabeled data from\nboth known and unknown categories by leveraging knowledge from labeled known\ncategories. While existing methods have made notable progress, they often\noverlook a hidden stumbling block in GCD: distracted attention. Specifically,\nwhen processing unlabeled data, models tend to focus not only on key objects in\nthe image but also on task-irrelevant background regions, leading to suboptimal\nfeature extraction. To remove this stumbling block, we propose Attention\nFocusing (AF), an adaptive mechanism designed to sharpen the model's focus by\npruning non-informative tokens. AF consists of two simple yet effective\ncomponents: Token Importance Measurement (TIME) and Token Adaptive Pruning\n(TAP), working in a cascade. TIME quantifies token importance across multiple\nscales, while TAP prunes non-informative tokens by utilizing the multi-scale\nimportance scores provided by TIME. AF is a lightweight, plug-and-play module\nthat integrates seamlessly into existing GCD methods with minimal computational\noverhead. When incorporated into one prominent GCD method, SimGCD, AF achieves\nup to 15.4% performance improvement over the baseline with minimal\ncomputational overhead. The implementation code is provided in\nhttps://github.com/Afleve/AFGCD.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14315v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14987", "title": "AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning", "authors": ["Yi Zhang", "An Zhang", "XiuYu Zhang", "Leheng Sheng", "Yuxin Chen", "Zhenkai Liang", "Xiang Wang"], "categories": ["cs.AI", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14987v1", "summary": "Large language models (LLMs), despite possessing latent safety understanding\nfrom their vast pretraining data, remain vulnerable to generating harmful\ncontent and exhibit issues such as over-refusal and utility degradation after\nsafety alignment. Current safety alignment methods often result in superficial\nrefusal shortcuts or rely on intensive supervision for reasoning-based\napproaches, failing to fully leverage the model's intrinsic safety\nself-awareness. We propose \\textbf{AlphaAlign}, a simple yet effective pure\nreinforcement learning (RL) framework with verifiable safety reward designed to\nincentivize this latent safety awareness through proactive safety reasoning.}\nAlphaAlign employs a dual-reward system: a verifiable safety reward encourages\ncorrectly formatted and explicitly justified refusals for harmful queries while\npenalizing over-refusals, and a normalized helpfulness reward guides\nhigh-quality responses to benign inputs. This allows the model to develop\nproactive safety reasoning capabilities without depending on supervised\nsafety-specific reasoning data. AlphaAlign demonstrates three key advantages:\n(1) Simplicity and efficiency, requiring only binary prompt safety labels and\nminimal RL steps for substantial improvements. (2) Breaking the safety-utility\ntrade-off, by enhancing refusal of harmful content and reducing over-refusals,\nwhile simultaneously maintaining or even improving general task performance and\nrobustness to unseen jailbreaks. (3) Deep alignment, fostering proactive safety\nreasoning that generates explicit safety rationales rather than relying on\nshallow refusal patterns.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14987v1", "cate": "cs.AI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14975", "title": "FCRF: Flexible Constructivism Reflection for Long-Horizon Robotic Task Planning with Large Language Models", "authors": ["Yufan Song", "Jiatao Zhang", "Zeng Gu", "Qingmiao Liang", "Tuocheng Hu", "Wei Song", "Shiqiang Zhu"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures, IROS 2025", "url": "http://arxiv.org/abs/2507.14975v1", "summary": "Autonomous error correction is critical for domestic robots to achieve\nreliable execution of complex long-horizon tasks. Prior work has explored\nself-reflection in Large Language Models (LLMs) for task planning error\ncorrection; however, existing methods are constrained by inflexible\nself-reflection mechanisms that limit their effectiveness. Motivated by these\nlimitations and inspired by human cognitive adaptation, we propose the Flexible\nConstructivism Reflection Framework (FCRF), a novel Mentor-Actor architecture\nthat enables LLMs to perform flexible self-reflection based on task difficulty,\nwhile constructively integrating historical valuable experience with failure\nlessons. We evaluated FCRF on diverse domestic tasks through simulation in\nAlfWorld and physical deployment in the real-world environment. Experimental\nresults demonstrate that FCRF significantly improves overall performance and\nself-reflection flexibility in complex long-horizon robotic tasks.", "comment": "8 pages, 6 figures, IROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.14975v1", "cate": "cs.RO", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14767", "title": "XplainAct: Visualization for Personalized Intervention Insights", "authors": ["Yanming Zhang", "Krishnakumar Hegde", "Klaus Mueller"], "categories": ["cs.HC", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      This paper will be published and presented at IEEE Visualization (VIS) 2025, Vienna, Austria, November 2025", "url": "http://arxiv.org/abs/2507.14767v1", "summary": "Causality helps people reason about and understand complex systems,\nparticularly through what-if analyses that explore how interventions might\nalter outcomes. Although existing methods embrace causal reasoning using\ninterventions and counterfactual analysis, they primarily focus on effects at\nthe population level. These approaches often fall short in systems\ncharacterized by significant heterogeneity, where the impact of an intervention\ncan vary widely across subgroups. To address this challenge, we present\nXplainAct, a visual analytics framework that supports simulating, explaining,\nand reasoning interventions at the individual level within subpopulations. We\ndemonstrate the effectiveness of XplainAct through two case studies:\ninvestigating opioid-related deaths in epidemiology and analyzing voting\ninclinations in the presidential election.", "comment": "This paper will be published and presented at IEEE Visualization\n  (VIS) 2025, Vienna, Austria, November 2025", "pdf_url": "http://arxiv.org/pdf/2507.14767v1", "cate": "cs.HC", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14406", "title": "Fail Fast, or Ask: Mitigating the Deficiencies of Reasoning LLMs with Human-in-the-Loop Systems Engineering", "authors": ["Michael J. Zellinger", "Matt Thomson"], "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      8 pages, 5 figures", "url": "http://arxiv.org/abs/2507.14406v1", "summary": "State-of-the-art reasoning LLMs are powerful problem solvers, but they still\noccasionally make mistakes. However, adopting AI models in risk-sensitive\ndomains often requires error rates near 0%. To address this gap, we propose\ncollaboration between a reasoning model and a human expert who resolves queries\nthe model cannot confidently answer. We find that quantifying the uncertainty\nof a reasoning model through the length of its reasoning trace yields an\neffective basis for deferral to a human, e.g., cutting the error rate of Qwen3\n235B-A22B on difficult MATH problems from 3% to less than 1% when deferring\n7.5% of queries. However, the high latency of reasoning models still makes them\nchallenging to deploy on use cases with high query volume. To address this\nchallenge, we explore fronting a reasoning model with a large non-reasoning\nmodel. We call this modified human-in-the-loop system \"Fail Fast, or Ask\",\nsince the non-reasoning model may defer difficult queries to the human expert\ndirectly (\"failing fast\"), without incurring the reasoning model's higher\nlatency. We show that this approach yields around 40% latency reduction and\nabout 50% cost savings for DeepSeek R1 while maintaining 90+% area under the\naccuracy-rejection curve. However, we observe that latency savings are lower\nthan expected because of \"latency drag\", the phenomenon that processing easier\nqueries with a non-reasoning model pushes the reasoning model's latency\ndistribution towards longer latencies. Broadly, our results suggest that the\ndeficiencies of state-of-the-art reasoning models -- nontrivial error rates and\nhigh latency -- can be substantially mitigated through black-box systems\nengineering, without requiring access to LLM internals.", "comment": "8 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.14406v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15676", "title": "Agentic AI for autonomous anomaly management in complex systems", "authors": ["Reza Vatankhah Barenji", "Sina Khoshgoftar"], "categories": ["cs.AI", "cs.ET"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15676v1", "summary": "This paper explores the potential of agentic AI in autonomously detecting and\nresponding to anomalies within complex systems, emphasizing its ability to\ntransform traditional, human-dependent anomaly management methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15676v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14176", "title": "Predictive Representativity: Uncovering Racial Bias in AI-based Skin Cancer Detection", "authors": ["Andrés Morales-Forero", "Lili J. Rueda", "Ronald Herrera", "Samuel Bassetto", "Eric Coatanea"], "categories": ["cs.LG", "stat.CO", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14176v1", "summary": "Artificial intelligence (AI) systems increasingly inform medical\ndecision-making, yet concerns about algorithmic bias and inequitable outcomes\npersist, particularly for historically marginalized populations. This paper\nintroduces the concept of Predictive Representativity (PR), a framework of\nfairness auditing that shifts the focus from the composition of the data set to\noutcomes-level equity. Through a case study in dermatology, we evaluated\nAI-based skin cancer classifiers trained on the widely used HAM10000 dataset\nand on an independent clinical dataset (BOSQUE Test set) from Colombia. Our\nanalysis reveals substantial performance disparities by skin phototype, with\nclassifiers consistently underperforming for individuals with darker skin,\ndespite proportional sampling in the source data. We argue that\nrepresentativity must be understood not as a static feature of datasets but as\na dynamic, context-sensitive property of model predictions. PR operationalizes\nthis shift by quantifying how reliably models generalize fairness across\nsubpopulations and deployment contexts. We further propose an External\nTransportability Criterion that formalizes the thresholds for fairness\ngeneralization. Our findings highlight the ethical imperative for post-hoc\nfairness auditing, transparency in dataset documentation, and inclusive model\nvalidation pipelines. This work offers a scalable tool for diagnosing\nstructural inequities in AI systems, contributing to discussions on equity,\ninterpretability, and data justice and fostering a critical re-evaluation of\nfairness in data-driven healthcare.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14176v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.14367", "title": "Hallucination Score: Towards Mitigating Hallucinations in Generative Image Super-Resolution", "authors": ["Weiming Ren", "Raghav Goyal", "Zhiming Hu", "Tristan Ty Aumentado-Armstrong", "Iqbal Mohomed", "Alex Levinshtein"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      12 pages, 17 figures and 7 tables", "url": "http://arxiv.org/abs/2507.14367v1", "summary": "Generative super-resolution (GSR) currently sets the state-of-the-art in\nterms of perceptual image quality, overcoming the \"regression-to-the-mean\" blur\nof prior non-generative models. However, from a human perspective, such models\ndo not fully conform to the optimal balance between quality and fidelity.\nInstead, a different class of artifacts, in which generated details fail to\nperceptually match the low resolution image (LRI) or ground-truth image (GTI),\nis a critical but under studied issue in GSR, limiting its practical\ndeployments. In this work, we focus on measuring, analyzing, and mitigating\nthese artifacts (i.e., \"hallucinations\"). We observe that hallucinations are\nnot well-characterized with existing image metrics or quality models, as they\nare orthogonal to both exact fidelity and no-reference quality. Instead, we\ntake advantage of a multimodal large language model (MLLM) by constructing a\nprompt that assesses hallucinatory visual elements and generates a\n\"Hallucination Score\" (HS). We find that our HS is closely aligned with human\nevaluations, and also provides complementary insights to prior image metrics\nused for super-resolution (SR) models. In addition, we find certain deep\nfeature distances have strong correlations with HS. We therefore propose to\nalign the GSR models by using such features as differentiable reward functions\nto mitigate hallucinations.", "comment": "12 pages, 17 figures and 7 tables", "pdf_url": "http://arxiv.org/pdf/2507.14367v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14465", "title": "Discipline and Resistance: The Construction of a Digital Home for TikTok Refugees on Xiaohongshu", "authors": ["Xiaoyu Xiong", "Yuting Peng", "Summer Kwong", "Anqi Huang"], "categories": ["cs.SI", "cs.CY"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      33 pages, 4 figures, 2 tables", "url": "http://arxiv.org/abs/2507.14465v1", "summary": "This study examines how TikTok refugees moved to Xiaohongshu after TikTok was\nabout to be banned in the United States. It utilizes Foucault's idea of\nheterotopia to demonstrate how Xiaohongshu became a crisis space for\ncross-cultural discussions across the Great Firewall. Through Critical\nDiscourse Analysis of 586 user comments, the study reveals how Chinese and\ninternational users collaboratively constructed and contested a new online\norder through language negotiation, identity positioning, and playful platform\npolicing. The findings highlight distinct discursive strategies between\ndomestic and overseas users, reflecting both cultural resistance and\nadaptation. This research contributes to the understanding of digital\nmigration, heterotopic spaces in social media, and emerging dynamics of\ncross-cultural discourse during geopolitical crises.", "comment": "33 pages, 4 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.14465v1", "cate": "cs.SI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15101", "title": "Frame-level Temporal Difference Learning for Partial Deepfake Speech Detection", "authors": ["Menglu Li", "Xiao-Ping Zhang", "Lian Zhao"], "categories": ["cs.SD", "cs.CR", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      5 pages, 4 figures, 4 tables. Accepted to IEEE SPL", "url": "http://arxiv.org/abs/2507.15101v1", "summary": "Detecting partial deepfake speech is essential due to its potential for\nsubtle misinformation. However, existing methods depend on costly frame-level\nannotations during training, limiting real-world scalability. Also, they focus\non detecting transition artifacts between bonafide and deepfake segments. As\ndeepfake generation techniques increasingly smooth these transitions, detection\nhas become more challenging. To address this, our work introduces a new\nperspective by analyzing frame-level temporal differences and reveals that\ndeepfake speech exhibits erratic directional changes and unnatural local\ntransitions compared to bonafide speech. Based on this finding, we propose a\nTemporal Difference Attention Module (TDAM) that redefines partial deepfake\ndetection as identifying unnatural temporal variations, without relying on\nexplicit boundary annotations. A dual-level hierarchical difference\nrepresentation captures temporal irregularities at both fine and coarse scales,\nwhile adaptive average pooling preserves essential patterns across\nvariable-length inputs to minimize information loss. Our TDAM-AvgPool model\nachieves state-of-the-art performance, with an EER of 0.59% on the PartialSpoof\ndataset and 0.03% on the HAD dataset, which significantly outperforms the\nexisting methods without requiring frame-level supervision.", "comment": "5 pages, 4 figures, 4 tables. Accepted to IEEE SPL", "pdf_url": "http://arxiv.org/pdf/2507.15101v1", "cate": "cs.SD", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15022", "title": "CPED-NCBFs: A Conformal Prediction for Expert Demonstration-based Neural Control Barrier Functions", "authors": ["Sumeadh MS", "Kevin Dsouza", "Ravi Prakash"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      6pages, 4figures, Submitted to the prestigious Indian Control Conference (ICC), 2025", "url": "http://arxiv.org/abs/2507.15022v1", "summary": "Among the promising approaches to enforce safety in control systems, learning\nControl Barrier Functions (CBFs) from expert demonstrations has emerged as an\neffective strategy. However, a critical challenge remains: verifying that the\nlearned CBFs truly enforce safety across the entire state space. This is\nespecially difficult when CBF is represented using neural networks (NCBFs).\nSeveral existing verification techniques attempt to address this problem\nincluding SMT-based solvers, mixed-integer programming (MIP), and interval or\nbound-propagation methods but these approaches often introduce loose,\nconservative bounds. To overcome these limitations, in this work we use\nCPED-NCBFs a split-conformal prediction based verification strategy to verify\nthe learned NCBF from the expert demonstrations. We further validate our method\non point mass systems and unicycle models to demonstrate the effectiveness of\nthe proposed theory.", "comment": "6pages, 4figures, Submitted to the prestigious Indian Control\n  Conference (ICC), 2025", "pdf_url": "http://arxiv.org/pdf/2507.15022v1", "cate": "cs.RO", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14769", "title": "Task Mode: Dynamic Filtering for Task-Specific Web Navigation using LLMs", "authors": ["Ananya Gubbi Mohanbabu", "Yotam Sechayk", "Amy Pavel"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      18 pages, 4 figures, 7 tables", "url": "http://arxiv.org/abs/2507.14769v1", "summary": "Modern web interfaces are unnecessarily complex to use as they overwhelm\nusers with excessive text and visuals unrelated to their current goals. This\nproblem particularly impacts screen reader users (SRUs), who navigate content\nsequentially and may spend minutes traversing irrelevant elements before\nreaching desired information compared to vision users (VUs) who visually skim\nin seconds. We present Task Mode, a system that dynamically filters web content\nbased on user-specified goals using large language models to identify and\nprioritize relevant elements while minimizing distractions. Our approach\npreserves page structure while offering multiple viewing modes tailored to\ndifferent access needs. Our user study with 12 participants (6 VUs, 6 SRUs)\ndemonstrates that our approach reduced task completion time for SRUs while\nmaintaining performance for VUs, decreasing the completion time gap between\ngroups from 2x to 1.2x. 11 of 12 participants wanted to use Task Mode in the\nfuture, reporting that Task Mode supported completing tasks with less effort\nand fewer distractions. This work demonstrates how designing new interactions\nsimultaneously for visual and non-visual access can reduce rather than\nreinforce accessibility disparities in future technology created by\nhuman-computer interaction researchers and practitioners.", "comment": "18 pages, 4 figures, 7 tables", "pdf_url": "http://arxiv.org/pdf/2507.14769v1", "cate": "cs.HC", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14417", "title": "Inverse Scaling in Test-Time Compute", "authors": ["Aryo Pradipta Gema", "Alexander Hägele", "Runjin Chen", "Andy Arditi", "Jacob Goldman-Wetzler", "Kit Fraser-Taliente", "Henry Sleight", "Linda Petrini", "Julian Michael", "Beatrice Alex", "Pasquale Minervini", "Yanda Chen", "Joe Benton", "Ethan Perez"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14417v1", "summary": "We construct evaluation tasks where extending the reasoning length of Large\nReasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling\nrelationship between test-time compute and accuracy. Our evaluation tasks span\nfour categories: simple counting tasks with distractors, regression tasks with\nspurious features, deduction tasks with constraint tracking, and advanced AI\nrisks. We identify five distinct failure modes when models reason for longer:\n1) Claude models become increasingly distracted by irrelevant information; 2)\nOpenAI o-series models resist distractors but overfit to problem framings; 3)\nmodels shift from reasonable priors to spurious correlations; 4) all models\nshow difficulties in maintaining focus on complex deductive tasks; and 5)\nextended reasoning may amplify concerning behaviors, with Claude Sonnet 4\nshowing increased expressions of self-preservation. These findings suggest that\nwhile test-time compute scaling remains promising for improving model\ncapabilities, it may inadvertently reinforce problematic reasoning patterns.\nOur results demonstrate the importance of evaluating models across diverse\nreasoning lengths to identify and address these failure modes in LRMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14417v1", "cate": "cs.AI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15797", "title": "Deterministic Quantum Search via Recursive Oracle Expansion", "authors": ["John Burke", "Ciaran McGoldrick"], "categories": ["quant-ph", "cs.ET", "81P68 (Primary), 68Q12 68Q25 (Secondary)", "F.1.2"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      11 pages, 3 figures. Data and code available on request", "url": "http://arxiv.org/abs/2507.15797v1", "summary": "We introduce a novel deterministic quantum search algorithm that provides a\npractical alternative to conventional probabilistic search approaches. Our\nscheme eliminates the inherent uncertainty of quantum search without relying on\narbitrary phase rotations, a key limitation of other deterministic methods. The\nalgorithm achieves certainty by recursively expanding the base oracle so that\nit marks all states prefixed by the same two bits as the target, encompassing\nexactly one-quarter of the search space. This enables a step-by-step reduction\nof the superposition until the target state can be measured with certainty. The\nalgorithm achieves deterministic success with a query complexity of\n$O(N^{\\log_2(3)/2}) \\approx O(N^{0.7925})$, falling between Grover's\n$O(\\sqrt{N})$ scaling and the classical $O(N)$. Our approach relies exclusively\non two-qubit nearest-neighbour diffusion operators, avoiding global diffusion\nentirely. We show that, despite the increased query complexity, this design\nreduces the total number of two-qubit gates required for diffusion by more than\nan order of magnitude for search spaces up to at least 18 qubits, with even\ngreater advantages on hardware with limited qubit connectivity. The scheme's\ninherent determinism, reliance on simple nearest-neighbour, low-depth\noperations, and scalable recursive structure make it well-suited for hardware\nimplementation. Additionally, we show that the algorithm naturally supports\npartial database search, enabling deterministic identification of selected\ntarget bits without requiring a full search, further broadening its\napplicability.", "comment": "11 pages, 3 figures. Data and code available on request", "pdf_url": "http://arxiv.org/pdf/2507.15797v1", "cate": "quant-ph", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14177", "title": "Understanding Two-Layer Neural Networks with Smooth Activation Functions", "authors": ["Changcun Huang"], "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "68T07(Primary), 41A15(Secondary)", "I.2.6; G.1.2"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14177v1", "summary": "This paper aims to understand the training solution, which is obtained by the\nback-propagation algorithm, of two-layer neural networks whose hidden layer is\ncomposed of the units with smooth activation functions, including the usual\nsigmoid type most commonly used before the advent of ReLUs. The mechanism\ncontains four main principles: construction of Taylor series expansions, strict\npartial order of knots, smooth-spline implementation and smooth-continuity\nrestriction. The universal approximation for arbitrary input dimensionality is\nproved and experimental verification is given, through which the mystery of\n``black box'' of the solution space is largely revealed. The new proofs\nemployed also enrich approximation theory.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14177v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.14368", "title": "DUSTrack: Semi-automated point tracking in ultrasound videos", "authors": ["Praneeth Namburi", "Roger Pallarès-López", "Jessica Rosendorf", "Duarte Folgado", "Brian W. Anthony"], "categories": ["cs.CV", "q-bio.QM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14368v1", "summary": "Ultrasound technology enables safe, non-invasive imaging of dynamic tissue\nbehavior, making it a valuable tool in medicine, biomechanics, and sports\nscience. However, accurately tracking tissue motion in B-mode ultrasound\nremains challenging due to speckle noise, low edge contrast, and out-of-plane\nmovement. These challenges complicate the task of tracking anatomical landmarks\nover time, which is essential for quantifying tissue dynamics in many clinical\nand research applications. This manuscript introduces DUSTrack (Deep learning\nand optical flow-based toolkit for UltraSound Tracking), a semi-automated\nframework for tracking arbitrary points in B-mode ultrasound videos. We combine\ndeep learning with optical flow to deliver high-quality and robust tracking\nacross diverse anatomical structures and motion patterns. The toolkit includes\na graphical user interface that streamlines the generation of high-quality\ntraining data and supports iterative model refinement. It also implements a\nnovel optical-flow-based filtering technique that reduces high-frequency\nframe-to-frame noise while preserving rapid tissue motion. DUSTrack\ndemonstrates superior accuracy compared to contemporary zero-shot point\ntrackers and performs on par with specialized methods, establishing its\npotential as a general and foundational tool for clinical and biomechanical\nresearch. We demonstrate DUSTrack's versatility through three use cases:\ncardiac wall motion tracking in echocardiograms, muscle deformation analysis\nduring reaching tasks, and fascicle tracking during ankle plantarflexion. As an\nopen-source solution, DUSTrack offers a powerful, flexible framework for point\ntracking to quantify tissue motion from ultrasound videos. DUSTrack is\navailable at https://github.com/praneethnamburi/DUSTrack.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14368v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14623", "title": "Rejection or Inclusion in the Emotion-Identity Dynamics of TikTok Refugees on RedNote", "authors": ["Mingchen Li", "Wenbo Xu", "Wenqing Gu", "Yixuan Xie", "Yao Zhou", "Yunsong Dai", "Cheng Tan", "Pan Hui"], "categories": ["cs.SI", "cs.CY", "cs.HC"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14623v1", "summary": "This study examines cross-cultural interactions between Chinese users and\nself-identified \"TikTok Refugees\"(foreign users who migrated to RedNote after\nTikTok's U.S. ban). Based on a dataset of 1,862 posts and 403,054 comments, we\nuse large language model-based sentiment classification and BERT-based topic\nmodelling to explore how both groups engage with the TikTok refugee phenomenon.\nWe analyse what themes foreign users express, how Chinese users respond, how\nstances (Pro-China, Neutral, Pro-Foreign) shape emotional expression, and how\naffective responses differ across topics and identities. Results show strong\naffective asymmetry: Chinese users respond with varying emotional intensities\nacross topics and stances: pride and praise dominate cultural threads, while\npolitical discussions elicit high levels of contempt and anger, especially from\nPro-China commenters. Pro-Foreign users exhibit the strongest negative emotions\nacross all topics, whereas neutral users express curiosity and joy but still\nreinforce mainstream discursive norms. Cross-topic comparisons reveal that\nappearance-related content produces the most emotionally balanced interactions,\nwhile politics generates the highest polarization. Our findings reveal distinct\nemotion-stance structures in Sino-foreign online interactions and offer\nempirical insights into identity negotiation in transnational digital publics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14623v1", "cate": "cs.SI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14256", "title": "Impact of Code Context and Prompting Strategies on Automated Unit Test Generation with Modern General-Purpose Large Language Models", "authors": ["Jakub Walczak", "Piotr Tomalak", "Artur Laskowski"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14256v1", "summary": "Generative AI is gaining increasing attention in software engineering, where\ntesting remains an indispensable reliability mechanism. According to the widely\nadopted testing pyramid, unit tests constitute the majority of test cases and\nare often schematic, requiring minimal domain expertise. Automatically\ngenerating such tests under the supervision of software engineers can\nsignificantly enhance productivity during the development phase of the software\nlifecycle.\n  This paper investigates the impact of code context and prompting strategies\non the quality and adequacy of unit tests generated by various large language\nmodels (LLMs) across several families. The results show that including\ndocstrings notably improves code adequacy, while further extending context to\nthe full implementation yields definitely smaller gains. Notably, the\nchain-of-thought prompting strategy -- applied even to 'reasoning' models --\nachieves the best results, with up to 96.3\\% branch coverage, a 57\\% average\nmutation score, and near-perfect compilation success rate. Among the evaluated\nmodels, M5 (Gemini 2.5 Pro) demonstrated superior performance in both mutation\nscore and branch coverage being still in top in terms of compilation success\nrate.\n  All the code and resulting test suites are publicly available at\nhttps://github.com/peetery/LLM-analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14256v1", "cate": "cs.SE", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15112", "title": "Distributional Unlearning: Forgetting Distributions, Not Just Samples", "authors": ["Youssef Allouah", "Rachid Guerraoui", "Sanmi Koyejo"], "categories": ["cs.LG", "cs.CR", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15112v1", "summary": "Machine unlearning seeks to remove unwanted information from trained models,\ninitially at the individual-sample level, but increasingly at the level of\nentire sub-populations. In many deployments, models must delete whole topical\ndomains to satisfy privacy, legal, or quality requirements, e.g., removing\nseveral users' posts under GDPR or copyrighted web content. Existing unlearning\ntools remain largely sample-oriented, and straightforward point deletion often\nleaves enough residual signal for downstream learners to recover the unwanted\ndomain. We introduce distributional unlearning, a data-centric, model-agnostic\nframework that asks: Given examples from an unwanted distribution and a\nretained distribution, what is the smallest set of points whose removal makes\nthe edited dataset far from the unwanted domain yet close to the retained one?\nUsing Kullback-Leibler divergence to quantify removal and preservation, we\nderive the exact Pareto frontier in the Gaussian case and prove that any model\nretrained on the edited data incurs log-loss shifts bounded by the divergence\nthresholds. We propose a simple distance-based selection rule satisfying these\nconstraints with a quadratic reduction in deletion budget compared to random\nremoval. Experiments on synthetic Gaussians, Jigsaw Toxic Comments, SMS spam,\nand CIFAR-10 show 15-72% fewer deletions than random, with negligible impact on\nretained performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15112v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15062", "title": "Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper", "authors": ["Xinyue Zhu", "Binghao Huang", "Yunzhu Li"], "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      More videos can be found on our website: this https URL", "url": "http://arxiv.org/abs/2507.15062v1", "summary": "Handheld grippers are increasingly used to collect human demonstrations due\nto their ease of deployment and versatility. However, most existing designs\nlack tactile sensing, despite the critical role of tactile feedback in precise\nmanipulation. We present a portable, lightweight gripper with integrated\ntactile sensors that enables synchronized collection of visual and tactile data\nin diverse, real-world, and in-the-wild settings. Building on this hardware, we\npropose a cross-modal representation learning framework that integrates visual\nand tactile signals while preserving their distinct characteristics. The\nlearning procedure allows the emergence of interpretable representations that\nconsistently focus on contacting regions relevant for physical interactions.\nWhen used for downstream manipulation tasks, these representations enable more\nefficient and effective policy learning, supporting precise robotic\nmanipulation based on multimodal feedback. We validate our approach on\nfine-grained tasks such as test tube insertion and pipette-based fluid\ntransfer, demonstrating improved accuracy and robustness under external\ndisturbances. Our project page is available at\nhttps://binghao-huang.github.io/touch_in_the_wild/ .", "comment": "More videos can be found on our\n  website:https://binghao-huang.github.io/touch_in_the_wild/", "pdf_url": "http://arxiv.org/pdf/2507.15062v1", "cate": "cs.RO", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14792", "title": "SenseSeek Dataset: Multimodal Sensing to Study Information Seeking Behaviors", "authors": ["Kaixin Ji", "Danula Hettiachchi", "Falk Scholer", "Flora D. Salim", "Damiano Spina"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted in Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT), September 2025", "url": "http://arxiv.org/abs/2507.14792v1", "summary": "Information processing tasks involve complex cognitive mechanisms that are\nshaped by various factors, including individual goals, prior experience, and\nsystem environments. Understanding such behaviors requires a sophisticated and\npersonalized data capture of how one interacts with modern information systems\n(e.g., web search engines). Passive sensors, such as wearables, capturing\nphysiological and behavioral data, have the potential to provide solutions in\nthis context. This paper presents a novel dataset, SenseSeek, designed to\nevaluate the effectiveness of consumer-grade sensors in a complex information\nprocessing scenario: searching via systems (e.g., search engines), one of the\ncommon strategies users employ for information seeking. The SenseSeek dataset\ncomprises data collected from 20 participants, 235 trials of the stimulated\nsearch process, 940 phases of stages in the search process, including the\nrealization of Information Need (IN), Query Formulation (QF), Query Submission\nby Typing (QS-T) or Speaking (QS-S), and Relevance Judgment by Reading (RJ-R)\nor Listening (RJ-L). The data includes Electrodermal Activities (EDA),\nElectroencephalogram (EEG), PUPIL, GAZE, and MOTION data, which were captured\nusing consumer-grade sensors. It also contains 258 features extracted from the\nsensor data, the gaze-annotated screen recordings, and task responses. We\nvalidate the usefulness of the dataset by providing baseline analysis on the\nimpacts of different cognitive intents and interaction modalities on the sensor\ndata, and effectiveness of the data in discriminating the search stages. To our\nknowledge, SenseSeek is the first dataset that characterizes the multiple\nstages involved in information seeking with physiological signals collected\nfrom multiple sensors. We hope this dataset can serve as a reference for future\nresearch on information-seeking behaviors.", "comment": "Accepted in Proceedings of the ACM on Interactive, Mobile, Wearable\n  and Ubiquitous Technologies (IMWUT), September 2025", "pdf_url": "http://arxiv.org/pdf/2507.14792v1", "cate": "cs.HC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14447", "title": "Routine: A Structural Planning Framework for LLM Agent System in Enterprise", "authors": ["Guancheng Zeng", "Xueyi Chen", "Jiawang Hu", "Shaohua Qi", "Yaxuan Mao", "Zhantao Wang", "Yifan Nie", "Shuang Li", "Qiuyang Feng", "Pengxu Qiu", "Yujia Wang", "Wenqiang Han", "Linyan Huang", "Gang Li", "Jingjing Mo", "Haowen Hu"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      26 pages, 8 figures, 5 tables", "url": "http://arxiv.org/abs/2507.14447v1", "summary": "The deployment of agent systems in an enterprise environment is often\nhindered by several challenges: common models lack domain-specific process\nknowledge, leading to disorganized plans, missing key tools, and poor execution\nstability. To address this, this paper introduces Routine, a multi-step agent\nplanning framework designed with a clear structure, explicit instructions, and\nseamless parameter passing to guide the agent's execution module in performing\nmulti-step tool-calling tasks with high stability. In evaluations conducted\nwithin a real-world enterprise scenario, Routine significantly increases the\nexecution accuracy in model tool calls, increasing the performance of GPT-4o\nfrom 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. We further constructed\na Routine-following training dataset and fine-tuned Qwen3-14B, resulting in an\naccuracy increase to 88.2% on scenario-specific evaluations, indicating\nimproved adherence to execution plans. In addition, we employed Routine-based\ndistillation to create a scenario-specific, multi-step tool-calling dataset.\nFine-tuning on this distilled dataset raised the model's accuracy to 95.5%,\napproaching GPT-4o's performance. These results highlight Routine's\neffectiveness in distilling domain-specific tool-usage patterns and enhancing\nmodel adaptability to new scenarios. Our experimental results demonstrate that\nRoutine provides a practical and accessible approach to building stable agent\nworkflows, accelerating the deployment and adoption of agent systems in\nenterprise environments, and advancing the technical vision of AI for Process.", "comment": "26 pages, 8 figures, 5 tables", "pdf_url": "http://arxiv.org/pdf/2507.14447v1", "cate": "cs.AI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2408.09171", "title": "Chemputer and Chemputation -- A Universal Chemical Compound Synthesis Machine", "authors": ["Leroy Cronin", "Sebastian Pagel", "Abhishek Sharma"], "categories": ["cs.ET", "physics.chem-ph"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "Comments:      25 pages, 7 figures, 51 references", "url": "http://arxiv.org/abs/2408.09171v3", "summary": "Chemputation reframes synthesis as the programmable execution of reaction\ncode on a universally re-configurable hardware graph. Here we prove that a\nchemputer equipped with a finite, but extensible, set of reagents, catalysts\nand process conditions, together with a chempiler that maps reaction graphs\nonto hardware, is universal: it can generate any stable, isolable molecule in\nfinite time and in analytically detectable quantity, provided real-time error\ncorrection keeps the per-step fidelity above the threshold set by the\nmolecule's assembly index. The proof is constructed by casting the platform as\na Chemical Synthesis Turing Machine (CSTM). The CSTM formalism supplies (i) an\neight-tuple state definition that unifies reagents, process variables\n(including catalysts) and tape operations; (ii) the Universal Chemputation\nPrinciple; and (iii) a dynamic-error-correction routine ensuring fault tolerant\nexecution. Linking this framework to assembly theory strengthens the definition\nof a molecule by demanding practical synthesizability and error correction\nbecomes a prerequisite for universality. We validate the abstraction against\n>100 \\c{hi}DL programs executed on a modular chemputer rigs spanning single\nstep to multi-step routes. Mapping each procedure onto CSTM shows that the\ncumulative number of unit operations grows linearly with synthetic depth.\nTogether, these results elevate chemical synthesis to the status of a general\ncomputation: algorithms written in \\c{hi}DL are compiled to hardware, executed\nwith closed-loop correction, and produce verifiable molecular outputs. By\nformalising chemistry in this way, the chemputer offers a path to shareable,\nexecutable chemical code, interoperable hardware ecosystems, and ultimately a\nsearchable, provable atlas of chemical space.", "comment": "25 pages, 7 figures, 51 references", "pdf_url": "http://arxiv.org/pdf/2408.09171v3", "cate": "cs.ET", "date": "2024-08-17", "updated": "2025-07-20"}
{"id": "2507.14178", "title": "Feature Bank Enhancement for Distance-based Out-of-Distribution Detection", "authors": ["Yuhang Liu", "Yuefei Wu", "Bin Shi", "Bo Dong"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      8 pages, 5 figures", "url": "http://arxiv.org/abs/2507.14178v1", "summary": "Out-of-distribution (OOD) detection is critical to ensuring the reliability\nof deep learning applications and has attracted significant attention in recent\nyears. A rich body of literature has emerged to develop efficient score\nfunctions that assign high scores to in-distribution (ID) samples and low\nscores to OOD samples, thereby helping distinguish OOD samples. Among these\nmethods, distance-based score functions are widely used because of their\nefficiency and ease of use. However, deep learning often leads to a biased\ndistribution of data features, and extreme features are inevitable. These\nextreme features make the distance-based methods tend to assign too low scores\nto ID samples. This limits the OOD detection capabilities of such methods. To\naddress this issue, we propose a simple yet effective method, Feature Bank\nEnhancement (FBE), that uses statistical characteristics from dataset to\nidentify and constrain extreme features to the separation boundaries, therapy\nmaking the distance between samples inside and outside the distribution\nfarther. We conducted experiments on large-scale ImageNet-1k and CIFAR-10\nrespectively, and the results show that our method achieves state-of-the-art\nperformance on both benchmark. Additionally, theoretical analysis and\nsupplementary experiments are conducted to provide more insights into our\nmethod.", "comment": "8 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.14178v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.14426", "title": "CRAFT: A Neuro-Symbolic Framework for Visual Functional Affordance Grounding", "authors": ["Zhou Chen", "Joe Lin", "Sathyanarayanan N. Aakur"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to NeSy 2025", "url": "http://arxiv.org/abs/2507.14426v1", "summary": "We introduce CRAFT, a neuro-symbolic framework for interpretable affordance\ngrounding, which identifies the objects in a scene that enable a given action\n(e.g., \"cut\"). CRAFT integrates structured commonsense priors from ConceptNet\nand language models with visual evidence from CLIP, using an energy-based\nreasoning loop to refine predictions iteratively. This process yields\ntransparent, goal-driven decisions to ground symbolic and perceptual\nstructures. Experiments in multi-object, label-free settings demonstrate that\nCRAFT enhances accuracy while improving interpretability, providing a step\ntoward robust and trustworthy scene understanding.", "comment": "Accepted to NeSy 2025", "pdf_url": "http://arxiv.org/pdf/2507.14426v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14696", "title": "Forecasting Faculty Placement from Patterns in Co-authorship Networks", "authors": ["Samantha Dies", "David Liu", "Tina Eliassi-Rad"], "categories": ["cs.SI", "cs.LG"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14696v1", "summary": "Faculty hiring shapes the flow of ideas, resources, and opportunities in\nacademia, influencing not only individual career trajectories but also broader\npatterns of institutional prestige and scientific progress. While traditional\nstudies have found strong correlations between faculty hiring and attributes\nsuch as doctoral department prestige and publication record, they rarely assess\nwhether these associations generalize to individual hiring outcomes,\nparticularly for future candidates outside the original sample. Here, we\nconsider faculty placement as an individual-level prediction task. Our data\nconsist of temporal co-authorship networks with conventional attributes such as\ndoctoral department prestige and bibliometric features. We observe that using\nthe co-authorship network significantly improves predictive accuracy by up to\n10% over traditional indicators alone, with the largest gains observed for\nplacements at the most elite (top-10) departments. Our results underscore the\nrole that social networks, professional endorsements, and implicit advocacy\nplay in faculty hiring beyond traditional measures of scholarly productivity\nand institutional prestige. By introducing a predictive framing of faculty\nplacement and establishing the benefit of considering co-authorship networks,\nthis work provides a new lens for understanding structural biases in academia\nthat could inform targeted interventions aimed at increasing transparency,\nfairness, and equity in academic hiring practices.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14696v1", "cate": "cs.SI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14330", "title": "Leveraging LLMs for Formal Software Requirements -- Challenges and Prospects", "authors": ["Arshad Beg", "Diarmuid O'Donoghue", "Rosemary Monahan"], "categories": ["cs.SE", "D.2.1; D.2.4; D.2.10; F.4.1; F.4.3"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Submitted to Overlay2025 - 7th International Workshop on Artificial Intelligence and fOrmal VERification, Logic, Automata, and sYnthesis. [under review]", "url": "http://arxiv.org/abs/2507.14330v1", "summary": "Software correctness is ensured mathematically through formal verification,\nwhich involves the resources of generating formal requirement specifications\nand having an implementation that must be verified. Tools such as\nmodel-checkers and theorem provers ensure software correctness by verifying the\nimplementation against the specification. Formal methods deployment is\nregularly enforced in the development of safety-critical systems e.g.\naerospace, medical devices and autonomous systems. Generating these\nspecifications from informal and ambiguous natural language requirements\nremains the key challenge. Our project, VERIFAI^{1}, aims to investigate\nautomated and semi-automated approaches to bridge this gap, using techniques\nfrom Natural Language Processing (NLP), ontology-based domain modelling,\nartefact reuse, and large language models (LLMs). This position paper presents\na preliminary synthesis of relevant literature to identify recurring challenges\nand prospective research directions in the generation of verifiable\nspecifications from informal requirements.", "comment": "Submitted to Overlay2025 - 7th International Workshop on Artificial\n  Intelligence and fOrmal VERification, Logic, Automata, and sYnthesis. [under\n  review]", "pdf_url": "http://arxiv.org/pdf/2507.14330v1", "cate": "cs.SE", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15163", "title": "Adaptive Network Security Policies via Belief Aggregation and Rollout", "authors": ["Kim Hammar", "Yuchao Li", "Tansu Alpcan", "Emil C. Lupu", "Dimitri Bertsekas"], "categories": ["eess.SY", "cs.CR", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15163v1", "summary": "Evolving security vulnerabilities and shifting operational conditions require\nfrequent updates to network security policies. These updates include\nadjustments to incident response procedures and modifications to access\ncontrols, among others. Reinforcement learning methods have been proposed for\nautomating such policy adaptations, but most of the methods in the research\nliterature lack performance guarantees and adapt slowly to changes. In this\npaper, we address these limitations and present a method for computing security\npolicies that is scalable, offers theoretical guarantees, and adapts quickly to\nchanges. It assumes a model or simulator of the system and comprises three\ncomponents: belief estimation through particle filtering, offline policy\ncomputation through aggregation, and online policy adaptation through rollout.\nCentral to our method is a new feature-based aggregation technique, which\nimproves scalability and flexibility. We analyze the approximation error of\naggregation and show that rollout efficiently adapts policies to changes under\ncertain conditions. Simulations and testbed results demonstrate that our method\noutperforms state-of-the-art methods on several benchmarks, including CAGE-2.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15163v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15088", "title": "Search-Based Autonomous Vehicle Motion Planning Using Game Theory", "authors": ["Pouya Panahandeh", "Mohammad Pirani", "Baris Fidan", "Amir Khajepour"], "categories": ["cs.RO", "cs.GT"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15088v1", "summary": "In this paper, we propose a search-based interactive motion planning scheme\nfor autonomous vehicles (AVs), using a game-theoretic approach. In contrast to\ntraditional search-based approaches, the newly developed approach considers\nother road users (e.g. drivers and pedestrians) as intelligent agents rather\nthan static obstacles. This leads to the generation of a more realistic path\nfor the AV. Due to the low computational time, the proposed motion planning\nscheme is implementable in real-time applications. The performance of the\ndeveloped motion planning scheme is compared with existing motion planning\ntechniques and validated through experiments using WATonoBus, an electrical\nall-weather autonomous shuttle bus.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15088v1", "cate": "cs.RO", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14818", "title": "Understanding How Visually Impaired Players Socialize in Mobile Games", "authors": ["Zihe Ran", "Xiyu Li", "Qing Xiao", "Yanyun Wang", "Franklin Mingzhe Li", "Zhicong Lu"], "categories": ["cs.HC", "cs.CY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      16 pages, 1 table, accepted by ASSETS25", "url": "http://arxiv.org/abs/2507.14818v1", "summary": "Mobile games are becoming a vital medium for social interaction, offering a\nplatform that transcends geographical boundaries. An increasing number of\nvisually impaired individuals are engaging in mobile gaming to connect,\ncollaborate, compete, and build friendships. In China, visually impaired\ncommunities face significant social challenges in offline settings, making\nmobile games a crucial avenue for socialization. However, the design of mobile\ngames and their mapping to real-world environments significantly shape their\nsocial gaming experiences. This study explores how visually impaired players in\nChina navigate socialization and integrate into gaming communities. Through\ninterviews with 30 visually impaired players, we found that while mobile games\nfulfill many of their social needs, technological barriers and insufficient\naccessibility features, and internal community divisions present significant\nchallenges to their participation. This research sheds light on their social\nexperiences and offers insights for designing more inclusive and accessible\nmobile games.", "comment": "16 pages, 1 table, accepted by ASSETS25", "pdf_url": "http://arxiv.org/pdf/2507.14818v1", "cate": "cs.HC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14468", "title": "BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning", "authors": ["Yitong Lin", "Jiaying He", "Jiahe Chen", "Xinnan Zhu", "Jianwei Zheng", "Tao Bo"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by Bioinformatics on July 11th", "url": "http://arxiv.org/abs/2507.14468v1", "summary": "Motivation: Biomedical knowledge graphs (KGs) are crucial for drug discovery\nand disease understanding, yet their completion and reasoning are challenging.\nKnowledge Embedding (KE) methods capture global semantics but struggle with\ndynamic structural integration, while Graph Neural Networks (GNNs) excel\nlocally but often lack semantic understanding. Even ensemble approaches,\nincluding those leveraging language models, often fail to achieve a deep,\nadaptive, and synergistic co-evolution between semantic comprehension and\nstructural learning. Addressing this critical gap in fostering continuous,\nreciprocal refinement between these two aspects in complex biomedical KGs is\nparamount.\n  Results: We introduce BioGraphFusion, a novel framework for deeply\nsynergistic semantic and structural learning. BioGraphFusion establishes a\nglobal semantic foundation via tensor decomposition, guiding an LSTM-driven\nmechanism to dynamically refine relation embeddings during graph propagation.\nThis fosters adaptive interplay between semantic understanding and structural\nlearning, further enhanced by query-guided subgraph construction and a hybrid\nscoring mechanism. Experiments across three key biomedical tasks demonstrate\nBioGraphFusion's superior performance over state-of-the-art KE, GNN, and\nensemble models. A case study on Cutaneous Malignant Melanoma 1 (CMM1)\nhighlights its ability to unveil biologically meaningful pathways.\n  Availability and Implementation: Source code and all training data are freely\navailable for download at https://github.com/Y-TARL/BioGraphFusion.\n  Contact: zjw@zjut.edu.cn, botao666666@126.com.\n  Supplementary information: Supplementary data are available at Bioinformatics\nonline.", "comment": "Accepted by Bioinformatics on July 11th", "pdf_url": "http://arxiv.org/pdf/2507.14468v1", "cate": "cs.AI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2504.07623", "title": "Joint Travel Route Optimization Framework for Platooning", "authors": ["Akif Adas", "Stefano Arrigoni", "Mattia Brambilla", "Monica Barbara Nicoli", "Edoardo Sabbioni"], "categories": ["cs.ET", "cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.07623v2", "summary": "Platooning represents an advanced driving technology designed to assist\ndrivers in traffic convoys of varying lengths, enhancing road safety, reducing\ndriver fatigue, and improving fuel efficiency. Sophisticated automated driving\nassistance systems have facilitated this innovation. Recent advancements in\nplatooning emphasize cooperative mechanisms within both centralized and\ndecentralized architectures enabled by vehicular communication technologies.\nThis study introduces a cooperative route planning optimization framework aimed\nat promoting the adoption of platooning through a centralized platoon formation\nstrategy at the system level. This approach is envisioned as a transitional\nphase from individual (ego) driving to fully collaborative driving.\nAdditionally, this research formulates and incorporates travel cost metrics\nrelated to fuel consumption, driver fatigue, and travel time, considering\nregulatory constraints on consecutive driving durations. The performance of\nthese cost metrics has been evaluated using Dijkstra's and A* shortest path\nalgorithms within a network graph framework. The results indicate that the\nproposed architecture achieves an average cost improvement of 14 % compared to\nindividual route planning for long road trips.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.07623v2", "cate": "cs.ET", "date": "2025-04-10", "updated": "2025-07-21"}
{"id": "2507.14179", "title": "A Sparsity Predicting Approach for Large Language Models via Activation Pattern Clustering", "authors": ["Nobel Dhar", "Bobin Deng", "Md Romyull Islam", "Xinyue Zhang", "Kazi Fahim Ahmad Nasif", "Kun Suo"], "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      To be published in Euro-Par 2025", "url": "http://arxiv.org/abs/2507.14179v1", "summary": "Large Language Models (LLMs) exhibit significant activation sparsity, where\nonly a subset of neurons are active for a given input. Although this sparsity\npresents opportunities to reduce computational cost, efficiently utilizing it\nrequires predicting activation patterns in a scalable manner. However, direct\nprediction at the neuron level is computationally expensive due to the vast\nnumber of neurons in modern LLMs. To enable efficient prediction and\nutilization of activation sparsity, we propose a clustering-based activation\npattern compression framework. Instead of treating each neuron independently,\nwe group similar activation patterns into a small set of representative\nclusters. Our method achieves up to 79.34% clustering precision, outperforming\nstandard binary clustering approaches while maintaining minimal degradation in\nperplexity (PPL) scores. With a sufficiently large number of clusters, our\napproach attains a PPL score as low as 12.49, demonstrating its effectiveness\nin preserving model quality while reducing computational overhead. By\npredicting cluster assignments rather than individual neuron states, future\nmodels can efficiently infer activation patterns from pre-computed centroids.\nWe detail the clustering algorithm, analyze its effectiveness in capturing\nmeaningful activation structures, and demonstrate its potential to improve\nsparse computation efficiency. This clustering-based formulation serves as a\nfoundation for future work on activation pattern prediction, paving the way for\nefficient inference in large-scale language models.", "comment": "To be published in Euro-Par 2025", "pdf_url": "http://arxiv.org/pdf/2507.14179v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.14432", "title": "Adaptive 3D Gaussian Splatting Video Streaming", "authors": ["Han Gong", "Qiyue Li", "Zhi Liu", "Hao Zhou", "Peng Yuan Zhou", "Zhu Li", "Jie Li"], "categories": ["cs.CV", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14432v1", "summary": "The advent of 3D Gaussian splatting (3DGS) has significantly enhanced the\nquality of volumetric video representation. Meanwhile, in contrast to\nconventional volumetric video, 3DGS video poses significant challenges for\nstreaming due to its substantially larger data volume and the heightened\ncomplexity involved in compression and transmission. To address these issues,\nwe introduce an innovative framework for 3DGS volumetric video streaming.\nSpecifically, we design a 3DGS video construction method based on the Gaussian\ndeformation field. By employing hybrid saliency tiling and differentiated\nquality modeling of 3DGS video, we achieve efficient data compression and\nadaptation to bandwidth fluctuations while ensuring high transmission quality.\nThen we build a complete 3DGS video streaming system and validate the\ntransmission performance. Through experimental evaluation, our method\ndemonstrated superiority over existing approaches in various aspects, including\nvideo quality, compression effectiveness, and transmission rate.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14432v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14864", "title": "Efficient Algorithms for Relevant Quantities of Friedkin-Johnsen Opinion Dynamics Model", "authors": ["Gengyu Wang", "Runze Zhang", "Zhongzhi Zhang"], "categories": ["cs.SI", "cs.CC"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14864v1", "summary": "Online social networks have become an integral part of modern society,\nprofoundly influencing how individuals form and exchange opinions across\ndiverse domains ranging from politics to public health. The Friedkin-Johnsen\nmodel serves as a foundational framework for modeling opinion formation\ndynamics in such networks. In this paper, we address the computational task of\nefficiently determining the equilibrium opinion vector and associated metrics\nincluding polarization and disagreement, applicable to both directed and\nundirected social networks. We propose a deterministic local algorithm with\nrelative error guarantees, scaling to networks exceeding ten million nodes.\nFurther acceleration is achieved through integration with successive\nover-relaxation techniques, where a relaxation factor optimizes convergence\nrates. Extensive experiments on diverse real-world networks validate the\npractical effectiveness of our approaches, demonstrating significant\nimprovements in computational efficiency and scalability compared to\nconventional methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14864v1", "cate": "cs.SI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14396", "title": "Developing Shared Vocabulary System For Collaborative Software Engineering", "authors": ["Carey Lai Zheng Hui", "Johnson Britto Jessia Esther Leena", "Kumuthini Subramanian", "Zhao Chenyu", "Shubham Rajeshkumar Jariwala"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      16 pages, including appendix", "url": "http://arxiv.org/abs/2507.14396v1", "summary": "Effective communication is a critical factor in successful software\nengineering collaboration. However, communication gaps remain a persistent\nchallenge, often leading to misunderstandings, inefficiencies, and defects.\nThis research investigates the technical factors contributing to such\nmisunderstandings and explores the measurable benefits of establishing shared\nvocabulary systems within software documentation and codebases. Using a Design\nScience Research (DSR) framework, the study was structured into three iterative\nphases: problem identification, method development, and empirical validation.\nThe problem identification phase involved thematic analysis of communication\ndata and semi-structured interviews, revealing key factors such as ambiguous\nmessaging, misalignment in documentation, inconsistent code review feedback,\nand API integration miscommunication. Grounded Theory principles were employed\nto design a structured methodology for collaborative vocabulary development.\nEmpirical validation through controlled experiments demonstrated that while\ninitial adoption introduced overhead, the shared vocabulary system\nsignificantly improved information density, documentation clarity, and\ncollaboration efficiency over time. Findings offer actionable insights for\nimproving communication practices in software engineering, while also\nidentifying limitations and directions for future research.", "comment": "16 pages, including appendix", "pdf_url": "http://arxiv.org/pdf/2507.14396v1", "cate": "cs.SE", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14183", "title": "Iran's Stealth Internet Blackout: A New Model of Censorship", "authors": ["Arash Aryapour"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14183v1", "summary": "In mid-2025, Iran experienced a novel, stealthy Internet shutdown that\npreserved global routing presence while isolating domestic users through deep\npacket inspection, aggressive throttling, and selective protocol blocking. This\npaper analyzes active network measurements such as DNS poisoning, HTTP\ninjection, TLS interception, and protocol whitelisting, traced to a centralized\nborder gateway. We quantify an approximate 707 percent rise in VPN demand and\ndescribe the multi-layered censorship infrastructure, highlighting implications\nfor circumvention and digital rights monitoring.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14183v1", "cate": "cs.NI", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2507.15214", "title": "Exploiting Context-dependent Duration Features for Voice Anonymization Attack Systems", "authors": ["Natalia Tomashenko", "Emmanuel Vincent", "Marc Tommasi"], "categories": ["cs.SD", "cs.CL", "cs.CR", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted at Interspeech-2025", "url": "http://arxiv.org/abs/2507.15214v1", "summary": "The temporal dynamics of speech, encompassing variations in rhythm,\nintonation, and speaking rate, contain important and unique information about\nspeaker identity. This paper proposes a new method for representing speaker\ncharacteristics by extracting context-dependent duration embeddings from speech\ntemporal dynamics. We develop novel attack models using these representations\nand analyze the potential vulnerabilities in speaker verification and voice\nanonymization systems.The experimental results show that the developed attack\nmodels provide a significant improvement in speaker verification performance\nfor both original and anonymized data in comparison with simpler\nrepresentations of speech temporal dynamics reported in the literature.", "comment": "Accepted at Interspeech-2025", "pdf_url": "http://arxiv.org/pdf/2507.15214v1", "cate": "cs.SD", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15155", "title": "Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions", "authors": ["Majid Roshanfar", "Alex Zhang", "Changyan He", "Amir Hooshiar", "Dale J. Podolsky", "Thomas Looi", "Eric Diller"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15155v1", "summary": "This letter introduces a novel learning-based modeling framework for a\nmagnetically steerable soft suction device designed for endoscopic endonasal\nbrain tumor resection. The device is miniaturized (4 mm outer diameter, 2 mm\ninner diameter, 40 mm length), 3D printed using biocompatible SIL 30 material,\nand integrates embedded Fiber Bragg Grating (FBG) sensors for real-time shape\nfeedback. Shape reconstruction is represented using four Bezier control points,\nenabling a compact and smooth model of the device's deformation. A data-driven\nmodel was trained on 5,097 experimental samples covering a range of magnetic\nfield magnitudes (0-14 mT), actuation frequencies (0.2-1.0 Hz), and vertical\ntip distances (90-100 mm), using both Neural Network (NN) and Random Forest\n(RF) architectures. The RF model outperformed the NN across all metrics,\nachieving a mean root mean square error of 0.087 mm in control point prediction\nand a mean shape reconstruction error of 0.064 mm. Feature importance analysis\nfurther revealed that magnetic field components predominantly influence distal\ncontrol points, while frequency and distance affect the base configuration.\nThis learning-based approach effectively models the complex nonlinear behavior\nof hyperelastic soft robots under magnetic actuation without relying on\nsimplified physical assumptions. By enabling sub-millimeter shape prediction\naccuracy and real-time inference, this work represents an advancement toward\nthe intelligent control of magnetically actuated soft robotic tools in\nminimally invasive neurosurgery.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15155v1", "cate": "cs.RO", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14846", "title": "Progressive Sentences: Combining the Benefits of Word and Sentence Learning", "authors": ["Nuwan Janaka", "Shengdong Zhao", "Ashwin Ram", "Ruoxin Sun", "Sherisse Tan Jing Wen", "Danae Li", "David Hsu"], "categories": ["cs.HC", "cs.CY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures, 4 tables", "url": "http://arxiv.org/abs/2507.14846v1", "summary": "The rapid evolution of lightweight consumer augmented reality (AR) smart\nglasses (a.k.a. optical see-through head-mounted displays) offers novel\nopportunities for learning, particularly through their unique capability to\ndeliver multimodal information in just-in-time, micro-learning scenarios. This\nresearch investigates how such devices can support mobile second-language\nacquisition by presenting progressive sentence structures in multimodal\nformats. In contrast to the commonly used vocabulary (i.e., word) learning\napproach for novice learners, we present a \"progressive presentation\" method\nthat combines both word and sentence learning by sequentially displaying\nsentence components (subject, verb, object) while retaining prior context.\nPilot and formal studies revealed that progressive presentation enhances\nrecall, particularly in mobile scenarios such as walking. Additionally,\nincorporating timed gaps between word presentations further improved learning\neffectiveness under multitasking conditions. Our findings demonstrate the\nutility of progressive presentation and provide usage guidelines for\neducational applications-even during brief, on-the-go learning moments.", "comment": "12 pages, 4 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.14846v1", "cate": "cs.HC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14513", "title": "Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy", "authors": ["Hongyi Yang", "Yue Pan", "Jiayi Xu", "Kelsen Liu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14513v1", "summary": "Recent advances in large language models (LLMs) and autonomous agents have\nenabled systems capable of performing complex tasks across domains such as\nhuman-computer interaction, planning, and web navigation. However, many\nexisting frameworks struggle in real-world or resource-constrained environments\ndue to their reliance on cloud-based computation, limited robustness in dynamic\ncontexts, and lack of persistent autonomy and environmental awareness.\n  We present Amico, a modular, event-driven framework for building autonomous\nagents optimized for embedded systems. Written in Rust for safety and\nperformance, Amico supports reactive, persistent agents that operate\nefficiently across embedded platforms and browser environments via WebAssembly.\nIt provides clean abstractions for event handling, state management, behavior\nexecution, and integration with reasoning modules. Amico delivers a unified\ninfrastructure for constructing resilient, interactive agents suitable for\ndeployment in settings with limited compute and intermittent connectivity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14513v1", "cate": "cs.AI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.00444", "title": "DiffCkt: A Diffusion Model-Based Hybrid Neural Network Framework for Automatic Transistor-Level Generation of Analog Circuits", "authors": ["Chengjie Liu", "Jiajia Li", "Yabing Feng", "Wenhao Huang", "Weiyu Chen", "Yuan Du", "Jun Yang", "Li Du"], "categories": ["cs.ET"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "Comments:      V1: Accepted by ICCAD2025; V2: 2025.7.19 **** Corrected the formula errors in Algorithm 5 and supplemented the relevant materials. Added references related to diffusion for analog circuits. Fixed the citation error of Table III. Corrected the error regarding the authors' affiliations. Optimized the layout. ****", "url": "http://arxiv.org/abs/2507.00444v2", "summary": "Analog circuit design consists of the pre-layout and layout phases. Among\nthem, the pre-layout phase directly decides the final circuit performance, but\nheavily depends on experienced engineers to do manual design according to\nspecific application scenarios. To overcome these challenges and automate the\nanalog circuit pre-layout design phase, we introduce DiffCkt: a diffusion\nmodel-based hybrid neural network framework for the automatic transistor-level\ngeneration of analog circuits, which can directly generate corresponding\ncircuit structures and device parameters tailored to specific performance\nrequirements. To more accurately quantify the efficiency of circuits generated\nby DiffCkt, we introduce the Circuit Generation Efficiency Index (CGEI), which\nis determined by both the figure of merit (FOM) of a single generated circuit\nand the time consumed. Compared with relative research, DiffCkt has improved\nCGEI by a factor of $2.21 \\sim 8365\\times$, reaching a state-of-the-art (SOTA)\nlevel. In conclusion, this work shows that the diffusion model has the\nremarkable ability to learn and generate analog circuit structures and device\nparameters, providing a revolutionary method for automating the pre-layout\ndesign of analog circuits. The circuit dataset will be open source, its preview\nversion is available at https://github.com/CjLiu-NJU/DiffCkt.", "comment": "V1: Accepted by ICCAD2025; V2: 2025.7.19 **** Corrected the formula\n  errors in Algorithm 5 and supplemented the relevant materials. Added\n  references related to diffusion for analog circuits. Fixed the citation error\n  of Table III. Corrected the error regarding the authors' affiliations.\n  Optimized the layout. ****", "pdf_url": "http://arxiv.org/pdf/2507.00444v2", "cate": "cs.ET", "date": "2025-07-01", "updated": "2025-07-19"}
{"id": "2507.14180", "title": "Digital Twin-Assisted Explainable AI for Robust Beam Prediction in mmWave MIMO Systems", "authors": ["Nasir Khan", "Asmaa Abdallah", "Abdulkadir Celik", "Ahmed M. Eltawil", "Sinem Coleri"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14180v1", "summary": "In line with the AI-native 6G vision, explainability and robustness are\ncrucial for building trust and ensuring reliable performance in millimeter-wave\n(mmWave) systems. Efficient beam alignment is essential for initial access, but\ndeep learning (DL) solutions face challenges, including high data collection\noverhead, hardware constraints, lack of explainability, and susceptibility to\nadversarial attacks. This paper proposes a robust and explainable DL-based beam\nalignment engine (BAE) for mmWave multiple-input multiple output (MIMO)\nsystems. The BAE uses received signal strength indicator (RSSI) measurements\nfrom wide beams to predict the best narrow beam, reducing the overhead of\nexhaustive beam sweeping. To overcome the challenge of real-world data\ncollection, this work leverages a site-specific digital twin (DT) to generate\nsynthetic channel data closely resembling real-world environments. A model\nrefinement via transfer learning is proposed to fine-tune the pre-trained model\nresiding in the DT with minimal real-world data, effectively bridging\nmismatches between the digital replica and real-world environments. To reduce\nbeam training overhead and enhance transparency, the framework uses deep\nShapley additive explanations (SHAP) to rank input features by importance,\nprioritizing key spatial directions and minimizing beam sweeping. It also\nincorporates the Deep k-nearest neighbors (DkNN) algorithm, providing a\ncredibility metric for detecting out-of-distribution inputs and ensuring\nrobust, transparent decision-making. Experimental results show that the\nproposed framework reduces real-world data needs by 70%, beam training overhead\nby 62%, and improves outlier detection robustness by up to 8.5x, achieving\nnear-optimal spectral efficiency and transparent decision making compared to\ntraditional softmax based DL models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14180v1", "cate": "cs.LG", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2507.14449", "title": "IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark", "authors": ["Zhe Cao", "Jin Zhang", "Ruiheng Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11 pages, 7 figures. This paper is accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.14449v1", "summary": "Real-world infrared imagery presents unique challenges for vision-language\nmodels due to the scarcity of aligned text data and domain-specific\ncharacteristics. Although existing methods have advanced the field, their\nreliance on synthetic infrared images generated through style transfer from\nvisible images, which limits their ability to capture the unique\ncharacteristics of the infrared modality. To address this, we propose IRGPT,\nthe first multi-modal large language model for real-world infrared images,\nbuilt upon a large-scale InfraRed-Text Dataset (IR-TD) comprising over 260K\nauthentic image-text pairs. The proposed IR-TD dataset contains real infrared\nimages paired with meticulously handcrafted texts, where the initial drafts\noriginated from two complementary processes: (1) LLM-generated descriptions of\nvisible images, and (2) rule-based descriptions of annotations. Furthermore, we\nintroduce a bi-cross-modal curriculum transfer learning strategy that\nsystematically transfers knowledge from visible to infrared domains by\nconsidering the difficulty scores of both infrared-visible and infrared-text.\nEvaluated on a benchmark of 9 tasks (e.g., recognition, grounding), IRGPT\nachieves state-of-the-art performance even compared with larger-scale models.", "comment": "11 pages, 7 figures. This paper is accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.14449v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15124", "title": "Comprehensive Privacy Risk Assessment in Social Networks Using User Attributes Social Graphs and Text Analysis", "authors": ["Md Jahangir Alam", "Ismail Hossain", "Sai Puppala", "Sajedul Talukder"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures, HyperText 2025", "url": "http://arxiv.org/abs/2507.15124v1", "summary": "The rise of social networking platforms has amplified privacy threats as\nusers increasingly share sensitive information across profiles, content, and\nsocial connections. We present a Comprehensive Privacy Risk Scoring (CPRS)\nframework that quantifies privacy risk by integrating user attributes, social\ngraph structures, and user-generated content. Our framework computes risk\nscores across these dimensions using sensitivity, visibility, structural\nsimilarity, and entity-level analysis, then aggregates them into a unified risk\nscore. We validate CPRS on two real-world datasets: the SNAP Facebook Ego\nNetwork (4,039 users) and the Koo microblogging dataset (1M posts, 1M\ncomments). The average CPRS is 0.478 with equal weighting, rising to 0.501 in\ngraph-sensitive scenarios. Component-wise, graph-based risks (mean 0.52)\nsurpass content (0.48) and profile attributes (0.45). High-risk attributes\ninclude email, date of birth, and mobile number. Our user study with 100\nparticipants shows 85% rated the dashboard as clear and actionable, confirming\nCPRS's practical utility. This work enables personalized privacy risk insights\nand contributes a holistic, scalable methodology for privacy management. Future\ndirections include incorporating temporal dynamics and multimodal content for\nbroader applicability.", "comment": "8 pages, 6 figures, HyperText 2025", "pdf_url": "http://arxiv.org/pdf/2507.15124v1", "cate": "cs.SI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14423", "title": "On the Effect of Token Merging on Pre-trained Models for Code", "authors": ["Mootez Saad", "Hao Li", "Tushar Sharma", "Ahmed E. Hassan"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14423v1", "summary": "Tokenization is a fundamental component of language models for code. It\ninvolves breaking down the input into units that are later passed to the\nlanguage model stack to learn high-dimensional representations used in various\ncontexts, from classification to generation. However, the output of these\ntokenizers is often longer than that traditionally used in compilers and\ninterpreters. This could result in undesirable effects, such as increased\ncomputational overhead. In this work, we investigate the effect of merging the\nhidden representations of subtokens that belong to the same semantic unit, such\nas subtokens that form a single identifier. We propose two strategies: one\nbased on averaging the representations and another that leverages a\nlearning-based approach. Both methods can be seamlessly integrated with\nexisting language models for code. We conduct experiments using six language\nmodels for code: CodeBERT, GraphCodeBERT, UniXCoder, CdoeT5, CodeT5+ (220M),\nand CodeT5+ (770M), across three software engineering tasks: vulnerability\ndetection, code classification, and code translation. Results show that these\nstrategies can reduce the number of floating-point operations by $1\\%$ to\n$19\\%$. Regarding downstream performance, the most significant degradation was\nobserved in the vulnerability detection task, where the F1 score decreased by\n$1.82$ points compared to the baseline. In contrast, for code translation, we\nobserved an improvement of $2.47$ points in CodeBLEU. This work contributes to\nthe broader effort of improving language models for code across multiple\ndimensions, including both computational efficiency and downstream performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14423v1", "cate": "cs.SE", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14186", "title": "A Disentangled Representation Learning Framework for Low-altitude Network Coverage Prediction", "authors": ["Xiaojie Li", "Zhijie Cai", "Nan Qi", "Chao Dong", "Guangxu Zhu", "Haixia Ma", "Qihui Wu", "Shi Jin"], "categories": ["cs.NI", "cs.AI", "cs.LG", "eess.SP"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      This paper has been submitted to IEEE for possible publication", "url": "http://arxiv.org/abs/2507.14186v1", "summary": "The expansion of the low-altitude economy has underscored the significance of\nLow-Altitude Network Coverage (LANC) prediction for designing aerial corridors.\nWhile accurate LANC forecasting hinges on the antenna beam patterns of Base\nStations (BSs), these patterns are typically proprietary and not readily\naccessible. Operational parameters of BSs, which inherently contain beam\ninformation, offer an opportunity for data-driven low-altitude coverage\nprediction. However, collecting extensive low-altitude road test data is\ncost-prohibitive, often yielding only sparse samples per BS. This scarcity\nresults in two primary challenges: imbalanced feature sampling due to limited\nvariability in high-dimensional operational parameters against the backdrop of\nsubstantial changes in low-dimensional sampling locations, and diminished\ngeneralizability stemming from insufficient data samples. To overcome these\nobstacles, we introduce a dual strategy comprising expert knowledge-based\nfeature compression and disentangled representation learning. The former\nreduces feature space complexity by leveraging communications expertise, while\nthe latter enhances model generalizability through the integration of\npropagation models and distinct subnetworks that capture and aggregate the\nsemantic representations of latent features. Experimental evaluation confirms\nthe efficacy of our framework, yielding a 7% reduction in error compared to the\nbest baseline algorithm. Real-network validations further attest to its\nreliability, achieving practical prediction accuracy with MAE errors at the 5dB\nlevel.", "comment": "This paper has been submitted to IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.14186v1", "cate": "cs.NI", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.15818", "title": "The Capacity of Semantic Private Information Retrieval with Colluding Servers", "authors": ["Mohamed Nomeir", "Alptug Aytekin", "Sennur Ulukus"], "categories": ["cs.IT", "cs.CR", "cs.NI", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15818v1", "summary": "We study the problem of semantic private information retrieval (Sem-PIR) with\n$T$ colluding servers (Sem-TPIR), i.e., servers that collectively share user\nqueries. In Sem-TPIR, the message sizes are different, and message retrieval\nprobabilities by any user are not uniform. This is a generalization of the\nclassical PIR problem where the message sizes are equal and message retrieval\nprobabilities are identical. The earlier work on Sem-PIR considered the case of\nno collusions, i.e., the collusion parameter of $T=1$. In this paper, we\nconsider the general problem for arbitrary $T < N$. We find an upper bound on\nthe retrieval rate and design a scheme that achieves this rate, i.e., we derive\nthe exact capacity of Sem-TPIR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15818v1", "cate": "cs.IT", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15189", "title": "CHADET: Cross-Hierarchical-Attention for Depth-Completion Using Unsupervised Lightweight Transformer", "authors": ["Kevin Christiansen Marsim", "Jinwoo Jeon", "Yeeun Kim", "Myeongwoo Jeong", "Hyun Myung"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15189v1", "summary": "Depth information which specifies the distance between objects and current\nposition of the robot is essential for many robot tasks such as navigation.\nRecently, researchers have proposed depth completion frameworks to provide\ndense depth maps that offer comprehensive information about the surrounding\nenvironment. However, existing methods show significant trade-offs between\ncomputational efficiency and accuracy during inference. The substantial memory\nand computational requirements make them unsuitable for real-time applications,\nhighlighting the need to improve the completeness and accuracy of depth\ninformation while improving processing speed to enhance robot performance in\nvarious tasks. To address these challenges, in this paper, we propose\nCHADET(cross-hierarchical-attention depth-completion transformer), a\nlightweight depth-completion network that can generate accurate dense depth\nmaps from RGB images and sparse depth points. For each pair, its feature is\nextracted from the depthwise blocks and passed to the equally lightweight\ntransformer-based decoder. In the decoder, we utilize the novel\ncross-hierarchical-attention module that refines the image features from the\ndepth information. Our approach improves the quality and reduces memory usage\nof the depth map prediction, as validated in both KITTI, NYUv2, and VOID\ndatasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15189v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14859", "title": "Holistic Specification of the Human Digital Twin: Stakeholders, Users, Functionalities, and Applications", "authors": ["Nils Mandischer", "Alexander Atanasyan", "Ulrich Dahmen", "Michael Schluse", "Jürgen Rossmann", "Lars Mikelsons"], "categories": ["cs.HC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      This work was accepted by the IEEE International Conference on Systems, Man, and Cybernetics (SMC), Vienna, Austria, 2025", "url": "http://arxiv.org/abs/2507.14859v1", "summary": "The digital twin of humans is a relatively new concept. While many diverse\ndefinitions, architectures, and applications exist, a clear picture is missing\non what, in fact, makes a human digital twin. Within this context, researchers\nand industrial use-case owners alike are unaware about the market potential of\nthe - at the moment - rather theoretical construct. In this work, we draw a\nholistic vision of the human digital twin, and derive the specification of this\nholistic human digital twin in form of requirements, stakeholders, and users.\nFor each group of users, we define exemplary applications that fall into the\nsix levels of functionality: store, analyze, personalize, predict, control, and\noptimize. The functionality levels facilitate an abstraction of abilities of\nthe human digital twin. From the manifold applications, we discuss three in\ndetail to showcase the feasibility of the abstraction levels and the analysis\nof stakeholders and users. Based on the deep discussion, we derive a\ncomprehensive list of requirements on the holistic human digital twin. These\nconsiderations shall be used as a guideline for research and industries for the\nimplementation of human digital twins, particularly in context of reusability\nin multiple target applications.", "comment": "This work was accepted by the IEEE International Conference on\n  Systems, Man, and Cybernetics (SMC), Vienna, Austria, 2025", "pdf_url": "http://arxiv.org/pdf/2507.14859v1", "cate": "cs.HC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14520", "title": "What if Othello-Playing Language Models Could See?", "authors": ["Xinyi Chen", "Yifei Yuan", "Jiaang Li", "Serge Belongie", "Maarten de Rijke", "Anders Søgaard"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      ICML 2025 Assessing World Models Workshop", "url": "http://arxiv.org/abs/2507.14520v1", "summary": "Language models are often said to face a symbol grounding problem. While some\nargue that world understanding can emerge from text alone, others suggest\ngrounded learning is more efficient. We explore this through Othello, where the\nboard state defines a simplified, rule-based world. Building on prior work, we\nintroduce VISOTHELLO, a multi-modal model trained on move histories and board\nimages. Using next-move prediction, we compare it to mono-modal baselines and\ntest robustness to semantically irrelevant perturbations. We find that\nmulti-modal training improves both performance and the robustness of internal\nrepresentations. These results suggest that grounding language in visual input\nhelps models infer structured world representations.", "comment": "ICML 2025 Assessing World Models Workshop", "pdf_url": "http://arxiv.org/pdf/2507.14520v1", "cate": "cs.AI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.06156", "title": "Hedge Funds on a Swamp: Analyzing Patterns, Vulnerabilities, and Defense Measures in Blockchain Bridges", "authors": ["Poupak Azad", "Jiahua Xu", "Yebo Feng", "Preston Strowbridge", "Cuneyt Akcora"], "categories": ["cs.ET", "cs.CR"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06156v3", "summary": "Blockchain bridges have become essential infrastructure for enabling\ninteroperability across different blockchain networks, with more than $24B\nmonthly bridge transaction volume. However, their growing adoption has been\naccompanied by a disproportionate rise in security breaches, making them the\nsingle largest source of financial loss in Web3. For cross-chain ecosystems to\nbe robust and sustainable, it is essential to understand and address these\nvulnerabilities. In this study, we present a comprehensive systematization of\nblockchain bridge design and security. We define three bridge security priors,\nformalize the architectural structure of 13 prominent bridges, and identify 23\nattack vectors grounded in real-world blockchain exploits. Using this\nfoundation, we evaluate 43 representative attack scenarios and introduce a\nlayered threat model that captures security failures across source chain,\noff-chain, and destination chain components.\n  Our analysis at the static code and transaction network levels reveals\nrecurring design flaws, particularly in access control, validator trust\nassumptions, and verification logic, and identifies key patterns in adversarial\nbehavior based on transaction-level traces. To support future development, we\npropose a decision framework for bridge architecture design, along with defense\nmechanisms such as layered validation and circuit breakers. This work provides\na data-driven foundation for evaluating bridge security and lays the groundwork\nfor standardizing resilient cross-chain infrastructure.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06156v3", "cate": "cs.ET", "date": "2025-07-08", "updated": "2025-07-21"}
{"id": "2507.14181", "title": "Semi-Supervised Federated Learning via Dual Contrastive Learning and Soft Labeling for Intelligent Fault Diagnosis", "authors": ["Yajiao Dai", "Jun Li", "Zhen Mei", "Yiyang Ni", "Shi Jin", "Zengxiang Li", "Sheng Guo", "Wei Xiang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE Internet of Things Journal, Early Access. 14 pages, 5 figures", "url": "http://arxiv.org/abs/2507.14181v1", "summary": "Intelligent fault diagnosis (IFD) plays a crucial role in ensuring the safe\noperation of industrial machinery and improving production efficiency. However,\ntraditional supervised deep learning methods require a large amount of training\ndata and labels, which are often located in different clients. Additionally,\nthe cost of data labeling is high, making labels difficult to acquire.\nMeanwhile, differences in data distribution among clients may also hinder the\nmodel's performance. To tackle these challenges, this paper proposes a\nsemi-supervised federated learning framework, SSFL-DCSL, which integrates dual\ncontrastive loss and soft labeling to address data and label scarcity for\ndistributed clients with few labeled samples while safeguarding user privacy.\nIt enables representation learning using unlabeled data on the client side and\nfacilitates joint learning among clients through prototypes, thereby achieving\nmutual knowledge sharing and preventing local model divergence. Specifically,\nfirst, a sample weighting function based on the Laplace distribution is\ndesigned to alleviate bias caused by low confidence in pseudo labels during the\nsemi-supervised training process. Second, a dual contrastive loss is introduced\nto mitigate model divergence caused by different data distributions, comprising\nlocal contrastive loss and global contrastive loss. Third, local prototypes are\naggregated on the server with weighted averaging and updated with momentum to\nshare knowledge among clients. To evaluate the proposed SSFL-DCSL framework,\nexperiments are conducted on two publicly available datasets and a dataset\ncollected on motors from the factory. In the most challenging task, where only\n10\\% of the data are labeled, the proposed SSFL-DCSL can improve accuracy by\n1.15% to 7.85% over state-of-the-art methods.", "comment": "Accepted to IEEE Internet of Things Journal, Early Access. 14 pages,\n  5 figures", "pdf_url": "http://arxiv.org/pdf/2507.14181v1", "cate": "cs.LG", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2507.14452", "title": "GPI-Net: Gestalt-Guided Parallel Interaction Network via Orthogonal Geometric Consistency for Robust Point Cloud Registration", "authors": ["Weikang Gu", "Mingyue Han", "Li Xue", "Heng Dong", "Changcai Yang", "Riqing Chen", "Lifang Wei"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      9 pages, 4 figures. Accepted to IJCAI 2025", "url": "http://arxiv.org/abs/2507.14452v1", "summary": "The accurate identification of high-quality correspondences is a prerequisite\ntask in feature-based point cloud registration. However, it is extremely\nchallenging to handle the fusion of local and global features due to feature\nredundancy and complex spatial relationships. Given that Gestalt principles\nprovide key advantages in analyzing local and global relationships, we propose\na novel Gestalt-guided Parallel Interaction Network via orthogonal geometric\nconsistency (GPI-Net) in this paper. It utilizes Gestalt principles to\nfacilitate complementary communication between local and global information.\nSpecifically, we introduce an orthogonal integration strategy to optimally\nreduce redundant information and generate a more compact global structure for\nhigh-quality correspondences. To capture geometric features in correspondences,\nwe leverage a Gestalt Feature Attention (GFA) block through a hybrid\nutilization of self-attention and cross-attention mechanisms. Furthermore, to\nfacilitate the integration of local detail information into the global\nstructure, we design an innovative Dual-path Multi-Granularity parallel\ninteraction aggregation (DMG) block to promote information exchange across\ndifferent granularities. Extensive experiments on various challenging tasks\ndemonstrate the superior performance of our proposed GPI-Net in comparison to\nexisting methods. The code will be released at https://github.com/gwk/GPI-Net.", "comment": "9 pages, 4 figures. Accepted to IJCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.14452v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15460", "title": "Privacy-Preserving Multimodal News Recommendation through Federated Learning", "authors": ["Mehdi Khalaj", "Shahrzad Golestani Najafabadi", "Julita Vassileva"], "categories": ["cs.SI", "cs.LG"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15460v1", "summary": "Personalized News Recommendation systems (PNR) have emerged as a solution to\ninformation overload by predicting and suggesting news items tailored to\nindividual user interests. However, traditional PNR systems face several\nchallenges, including an overreliance on textual content, common neglect of\nshort-term user interests, and significant privacy concerns due to centralized\ndata storage. This paper addresses these issues by introducing a novel\nmultimodal federated learning-based approach for news recommendation. First, it\nintegrates both textual and visual features of news items using a multimodal\nmodel, enabling a more comprehensive representation of content. Second, it\nemploys a time-aware model that balances users' long-term and short-term\ninterests through multi-head self-attention networks, improving recommendation\naccuracy. Finally, to enhance privacy, a federated learning framework is\nimplemented, enabling collaborative model training without sharing user data.\nThe framework divides the recommendation model into a large server-maintained\nnews model and a lightweight user model shared between the server and clients.\nThe client requests news representations (vectors) and a user model from the\ncentral server, then computes gradients with user local data, and finally sends\ntheir locally computed gradients to the server for aggregation. The central\nserver aggregates gradients to update the global user model and news model. The\nupdated news model is further used to infer news representation by the server.\nTo further safeguard user privacy, a secure aggregation algorithm based on\nShamir's secret sharing is employed. Experiments on a real-world news dataset\ndemonstrate strong performance compared to existing systems, representing a\nsignificant advancement in privacy-preserving personalized news recommendation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15460v1", "cate": "cs.SI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14547", "title": "Architectural Degradation: Definition, Motivations, Measurement and Remediation Approaches", "authors": ["Noman Ahmad", "Ruoyu Su", "Matteo Esposito", "Andrea Janes", "Valentina Lenarduzzi", "Davide Taibi"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14547v1", "summary": "Architectural degradation, also known as erosion, decay, or aging, impacts\nsystem quality, maintainability, and adaptability. Although widely\nacknowledged, current literature shows fragmented definitions, metrics, and\nremediation strategies. Our study aims to unify understanding of architectural\ndegradation by identifying its definitions, causes, metrics, tools, and\nremediation approaches across academic and gray literature. We conducted a\nmultivocal literature review of 108 studies extracting definitions, causes,\nmetrics, measurement approaches, tools, and remediation strategies. We\ndeveloped a taxonomy encompassing architectural, code, and process debt to\nexplore definition evolution, methodological trends, and research gaps.\nArchitectural degradation has shifted from a low-level issue to a\nsocio-technical concern. Definitions now address code violations, design drift,\nand structural decay. Causes fall under architectural (e.g., poor\ndocumentation), code (e.g., hasty fixes), and process debt (e.g., knowledge\nloss). We identified 54 metrics and 31 measurement techniques, focused on\nsmells, cohesion/coupling, and evolution. Yet, most tools detect issues but\nrarely support ongoing or preventive remediation. Degradation is both technical\nand organizational. While detection is well-studied, continuous remediation\nremains lacking. Our study reveals missed integration between metrics, tools,\nand repair logic, urging holistic, proactive strategies for sustainable\narchitecture.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14547v1", "cate": "cs.SE", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14188", "title": "From Cell Towers to Satellites: A 2040 Blueprint for Urban-Grade Direct-to-Device Mobile Networks", "authors": ["Sebastian Barros Elgueta"], "categories": ["cs.NI", "cs.AI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      50 pages", "url": "http://arxiv.org/abs/2507.14188v1", "summary": "In 2023, satellite and mobile networks crossed a historic threshold: standard\nsmartphones, using unmodified 3GPP protocols, connected directly to low Earth\norbit (LEO) satellites. This first wave of direct-to-device (D2D)\ndemonstrations validated the physical feasibility of satellite-based mobile\naccess. However, these systems remain fallback-grade--rural-only,\nbandwidth-limited, and fully dependent on Earth-based mobile cores for\nidentity, session, and policy control. This paper asks a more ambitious\nquestion: Can a complete mobile network, including radio access, core\nfunctions, traffic routing, and content delivery, operate entirely from orbit?\nAnd can it deliver sustained, urban-grade service in the world's densest\ncities? We present the first end-to-end system architecture for a fully orbital\ntelco, integrating electronically steered phased arrays with 1000-beam\ncapacity, space-based deployment of 5G core functions (UPF, AMF), and\ninter-satellite laser mesh backhaul. We analyze spectral efficiency, beam\ncapacity, and link budgets under dense urban conditions, accounting for path\nloss, Doppler, and multipath. Simulations show that rooftop and line-of-sight\nusers can sustain 64-QAM throughput, while street-level access is feasible with\nrelay or assisted beam modes. The paper outlines the remaining constraints,\npower, thermal dissipation, compute radiation hardening, and regulatory models,\nand demonstrates that these are engineering bottlenecks, not physical limits.\nFinally, we propose a staged 15-year roadmap from today's fallback D2D systems\nto autonomous orbital overlays delivering 50-100 Mbps to handhelds in\nmegacities, with zero reliance on terrestrial infrastructure.", "comment": "50 pages", "pdf_url": "http://arxiv.org/pdf/2507.14188v1", "cate": "cs.NI", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.15836", "title": "Optimizing Canaries for Privacy Auditing with Metagradient Descent", "authors": ["Matteo Boglioni", "Terrance Liu", "Andrew Ilyas", "Zhiwei Steven Wu"], "categories": ["cs.LG", "cs.CR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15836v1", "summary": "In this work we study black-box privacy auditing, where the goal is to lower\nbound the privacy parameter of a differentially private learning algorithm\nusing only the algorithm's outputs (i.e., final trained model). For DP-SGD (the\nmost successful method for training differentially private deep learning\nmodels), the canonical approach auditing uses membership inference-an auditor\ncomes with a small set of special \"canary\" examples, inserts a random subset of\nthem into the training set, and then tries to discern which of their canaries\nwere included in the training set (typically via a membership inference\nattack). The auditor's success rate then provides a lower bound on the privacy\nparameters of the learning algorithm. Our main contribution is a method for\noptimizing the auditor's canary set to improve privacy auditing, leveraging\nrecent work on metagradient optimization. Our empirical evaluation demonstrates\nthat by using such optimized canaries, we can improve empirical lower bounds\nfor differentially private image classification models by over 2x in certain\ninstances. Furthermore, we demonstrate that our method is transferable and\nefficient: canaries optimized for non-private SGD with a small model\narchitecture remain effective when auditing larger models trained with DP-SGD.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15836v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15266", "title": "VLM-UDMC: VLM-Enhanced Unified Decision-Making and Motion Control for Urban Autonomous Driving", "authors": ["Haichao Liu", "Haoren Guo", "Pei Liu", "Benshan Ma", "Yuxiang Zhang", "Jun Ma", "Tong Heng Lee"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      14 pages, 12 figures", "url": "http://arxiv.org/abs/2507.15266v1", "summary": "Scene understanding and risk-aware attentions are crucial for human drivers\nto make safe and effective driving decisions. To imitate this cognitive ability\nin urban autonomous driving while ensuring the transparency and\ninterpretability, we propose a vision-language model (VLM)-enhanced unified\ndecision-making and motion control framework, named VLM-UDMC. This framework\nincorporates scene reasoning and risk-aware insights into an upper-level slow\nsystem, which dynamically reconfigures the optimal motion planning for the\ndownstream fast system. The reconfiguration is based on real-time environmental\nchanges, which are encoded through context-aware potential functions. More\nspecifically, the upper-level slow system employs a two-step reasoning policy\nwith Retrieval-Augmented Generation (RAG), leveraging foundation models to\nprocess multimodal inputs and retrieve contextual knowledge, thereby generating\nrisk-aware insights. Meanwhile, a lightweight multi-kernel decomposed LSTM\nprovides real-time trajectory predictions for heterogeneous traffic\nparticipants by extracting smoother trend representations for short-horizon\ntrajectory prediction. The effectiveness of the proposed VLM-UDMC framework is\nverified via both simulations and real-world experiments with a full-size\nautonomous vehicle. It is demonstrated that the presented VLM-UDMC effectively\nleverages scene understanding and attention decomposition for rational driving\ndecisions, thus improving the overall urban driving performance. Our\nopen-source project is available at https://github.com/henryhcliu/vlmudmc.git.", "comment": "14 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.15266v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14944", "title": "LEKIA: A Framework for Architectural Alignment via Expert Knowledge Injection", "authors": ["Boning Zhao", "Yutong Hu"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14944v1", "summary": "Deploying Large Language Models (LLMs) in high-stakes domains is impeded by a\ndual challenge: the need for deep, dynamic expert knowledge injection and\nnuanced value alignment. Prevailing paradigms often address these challenges\nseparately, creating a persistent tension between knowledge and alignment;\nknowledge-focused methods like Retrieval-Augmented Generation (RAG) have\nlimited deep alignment capabilities, while alignment-focused methods like\nReinforcement Learning from Human Feedback (RLHF) struggle with the agile\ninjection of expert wisdom. This paper introduces a new collaborative\nphilosophy, Expert-owned AI behavior design, realized through Architectural\nAlignment-a paradigm that unifies these two goals within a single framework\ncalled the Layered Expert Knowledge Injection Architecture (LEKIA). LEKIA\noperates as an intelligent intermediary that guides an LLM's reasoning process\nwithout altering its weights, utilizing a three-tiered structure: a Theoretical\nLayer for core principles, a Practical Layer for exemplary cases, and an\nEvaluative Layer for real-time, value-aligned self-correction. We demonstrate\nthe efficacy of this paradigm through the successful implementation of a\nLEKIA-based psychological support assistant for the special education field.\nOur work presents a path toward more responsible and expert-driven AI,\nempowering domain specialists to directly architect AI behavior and resolve the\ntension between knowledge and alignment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14944v1", "cate": "cs.HC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14552", "title": "Large Language Models Assisting Ontology Evaluation", "authors": ["Anna Sofia Lippolis", "Mohammad Javad Saeedizade", "Robin Keskisärkkä", "Aldo Gangemi", "Eva Blomqvist", "Andrea Giovanni Nuzzolese"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14552v1", "summary": "Ontology evaluation through functional requirements, such as testing via\ncompetency question (CQ) verification, is a well-established yet costly,\nlabour-intensive, and error-prone endeavour, even for ontology engineering\nexperts. In this work, we introduce OE-Assist, a novel framework designed to\nassist ontology evaluation through automated and semi-automated CQ\nverification. By presenting and leveraging a dataset of 1,393 CQs paired with\ncorresponding ontologies and ontology stories, our contributions present, to\nour knowledge, the first systematic investigation into large language model\n(LLM)-assisted ontology evaluation, and include: (i) evaluating the\neffectiveness of a LLM-based approach for automatically performing CQ\nverification against a manually created gold standard, and (ii) developing and\nassessing an LLM-powered framework to assist CQ verification with Prot\\'eg\\'e,\nby providing suggestions. We found that automated LLM-based evaluation with\no1-preview and o3-mini perform at a similar level to the average user's\nperformance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14552v1", "cate": "cs.AI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2506.12540", "title": "Regulating Next-Generation Implantable Brain-Computer Interfaces: Recommendations for Ethical Development and Implementation", "authors": ["Renee Sirbu", "Jessica Morley", "Tyler Schroder", "Raghavendra Pradyumna Pothukuchi", "Muhammed Ugur", "Abhishek Bhattacharjee", "Luciano Floridi"], "categories": ["cs.HC", "cs.CY", "cs.ET"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      35 pages, 3 tables, 2 appendices", "url": "http://arxiv.org/abs/2506.12540v2", "summary": "Brain-computer interfaces offer significant therapeutic opportunities for a\nvariety of neurophysiological and neuropsychiatric disorders and may perhaps\none day lead to augmenting the cognition and decision-making of the healthy\nbrain. However, existing regulatory frameworks designed for implantable medical\ndevices are inadequate to address the unique ethical, legal, and social risks\nassociated with next-generation networked brain-computer interfaces. In this\narticle, we make nine recommendations to support developers in the design of\nBCIs and nine recommendations to support policymakers in the application of\nBCIs, drawing insights from the regulatory history of IMDs and principles from\nAI ethics. We begin by outlining the historical development of IMDs and the\nregulatory milestones that have shaped their oversight. Next, we summarize\nsimilarities between IMDs and emerging implantable BCIs, identifying existing\nprovisions for their regulation. We then use two case studies of emerging\ncutting-edge BCIs, the HALO and SCALO computer systems, to highlight\ndistinctive features in the design and application of next-generation BCIs\narising from contemporary chip architectures, which necessitate reevaluating\nregulatory approaches. We identify critical ethical considerations for these\nBCIs, including unique conceptions of autonomy, identity, and mental privacy.\nBased on these insights, we suggest potential avenues for the ethical\nregulation of BCIs, emphasizing the importance of interdisciplinary\ncollaboration and proactive mitigation of potential harms. The goal is to\nsupport the responsible design and application of new BCIs, ensuring their safe\nand ethical integration into medical practice.", "comment": "35 pages, 3 tables, 2 appendices", "pdf_url": "http://arxiv.org/pdf/2506.12540v2", "cate": "cs.HC", "date": "2025-06-14", "updated": "2025-07-21"}
{"id": "2507.14182", "title": "From Bias to Behavior: Learning Bull-Bear Market Dynamics with Contrastive Modeling", "authors": ["Xiaotong Luo", "Shengda Zhuo", "Min Chen", "Lichun Li", "Ruizhao Lu", "Wenqi Fan", "Shuqiang Huang", "Yin Tang"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14182v1", "summary": "Financial markets exhibit highly dynamic and complex behaviors shaped by both\nhistorical price trajectories and exogenous narratives, such as news, policy\ninterpretations, and social media sentiment. The heterogeneity in these data\nand the diverse insight of investors introduce biases that complicate the\nmodeling of market dynamics. Unlike prior work, this paper explores the\npotential of bull and bear regimes in investor-driven market dynamics. Through\nempirical analysis on real-world financial datasets, we uncover a dynamic\nrelationship between bias variation and behavioral adaptation, which enhances\ntrend prediction under evolving market conditions. To model this mechanism, we\npropose the Bias to Behavior from Bull-Bear Dynamics model (B4), a unified\nframework that jointly embeds temporal price sequences and external contextual\nsignals into a shared latent space where opposing bull and bear forces\nnaturally emerge, forming the foundation for bias representation. Within this\nspace, an inertial pairing module pairs temporally adjacent samples to preserve\nmomentum, while the dual competition mechanism contrasts bullish and bearish\nembeddings to capture behavioral divergence. Together, these components allow\nB4 to model bias-driven asymmetry, behavioral inertia, and market\nheterogeneity. Experimental results on real-world financial datasets\ndemonstrate that our model not only achieves superior performance in predicting\nmarket trends but also provides interpretable insights into the interplay of\nbiases, investor behaviors, and market dynamics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14182v1", "cate": "cs.LG", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2507.14454", "title": "Adaptive 3D Gaussian Splatting Video Streaming: Visual Saliency-Aware Tiling and Meta-Learning-Based Bitrate Adaptation", "authors": ["Han Gong", "Qiyue Li", "Jie Li", "Zhi Liu"], "categories": ["cs.CV", "cs.MM", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14454v1", "summary": "3D Gaussian splatting video (3DGS) streaming has recently emerged as a\nresearch hotspot in both academia and industry, owing to its impressive ability\nto deliver immersive 3D video experiences. However, research in this area is\nstill in its early stages, and several fundamental challenges, such as tiling,\nquality assessment, and bitrate adaptation, require further investigation. In\nthis paper, we tackle these challenges by proposing a comprehensive set of\nsolutions. Specifically, we propose an adaptive 3DGS tiling technique guided by\nsaliency analysis, which integrates both spatial and temporal features. Each\ntile is encoded into versions possessing dedicated deformation fields and\nmultiple quality levels for adaptive selection. We also introduce a novel\nquality assessment framework for 3DGS video that jointly evaluates\nspatial-domain degradation in 3DGS representations during streaming and the\nquality of the resulting 2D rendered images. Additionally, we develop a\nmeta-learning-based adaptive bitrate algorithm specifically tailored for 3DGS\nvideo streaming, achieving optimal performance across varying network\nconditions. Extensive experiments demonstrate that our proposed approaches\nsignificantly outperform state-of-the-art methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14454v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14162", "title": "Apology of Green Digitalization in the Context of Information and Climate Feedback Theory", "authors": ["Eldar Knar"], "categories": ["physics.soc-ph", "cs.SI", "94"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "Comments:      26 pages, 7 tables, 4 figures", "url": "http://arxiv.org/abs/2507.14162v1", "summary": "Amid accelerated digitalization, not only is the scale of data processing and\nstorage increasing, but so too is the associated infrastructure load on the\nclimate. Current climate models and environmental protocols almost entirely\noverlook the impact of information and communication technologies on the\nthermal and energy balance of the biosphere.\n  This paper proposes the theory of information and climate feedback (ICF) as a\nnew nonlinear model describing the loop of digitalization, energy consumption,\nthe thermal footprint, the climatic response, and the vulnerability of digital\ninfrastructure. The system is formalized via differential equations with delays\nand parameters of sensitivity, greenness, and phase stability.\n  A multiscenario numerical analysis, phase reconstructions, and thermal\ncartography were conducted. Critical regimes, including digital overheating,\nfluctuational instability, and infrastructural collapse in the absence of\nadaptive measures, were identified.\n  The paper concludes with the proposal of an international agreement titled\nthe Green Digital Accord and a set of metrics for sustainable digitalization.\nThis work integrates climatology, information technologies, and the political\neconomy of sustainability.", "comment": "26 pages, 7 tables, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.14162v1", "cate": "physics.soc-ph", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.14554", "title": "Emerging Trends in Software Architecture from the Practitioners Perspective: A Five Year Review", "authors": ["Ruoyu Su", "Noman ahmad", "Matteo Esposito", "Andrea Janes", "Davide Taibi", "Valentina Lenarduzzi"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14554v1", "summary": "Software architecture plays a central role in the design, development, and\nmaintenance of software systems. With the rise of cloud computing,\nmicroservices, and containers, architectural practices have diversified.\nUnderstanding these shifts is vital. This study analyzes software architecture\ntrends across eight leading industry conferences over five years. We\ninvestigate the evolution of software architecture by analyzing talks from top\npractitioner conferences, focusing on the motivations and contexts driving\ntechnology adoption. We analyzed 5,677 talks from eight major industry\nconferences, using large language models and expert validation to extract\ntechnologies, their purposes, and usage contexts. We also explored how\ntechnologies interrelate and fit within DevOps and deployment pipelines. Among\n450 technologies, Kubernetes, Cloud Native, Serverless, and Containers dominate\nby frequency and centrality. Practitioners present technology mainly related to\ndeployment, communication, AI, and observability. We identify five technology\ncommunities covering automation, coordination, cloud AI, monitoring, and\ncloud-edge. Most technologies span multiple DevOps stages and support hybrid\ndeployment. Our study reveals that a few core technologies, like Kubernetes and\nServerless, dominate the contemporary software architecture practice. These are\nmainly applied in later DevOps stages, with limited focus on early phases like\nplanning and coding. We also show how practitioners frame technologies by\npurpose and context, reflecting evolving industry priorities. Finally, we\nobserve how only research can provide a more holistic lens on architectural\ndesign, quality, and evolution.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14554v1", "cate": "cs.SE", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14199", "title": "On Splitting Lightweight Semantic Image Segmentation for Wireless Communications", "authors": ["Ebrahim Abu-Helalah", "Jordi Serra", "Jordi Perez-Romero"], "categories": ["cs.NI", "cs.CV", "eess.IV"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      IEEE International Mediterranean Conference on Communications and Networking", "url": "http://arxiv.org/abs/2507.14199v1", "summary": "Semantic communication represents a promising technique towards reducing\ncommunication costs, especially when dealing with image segmentation, but it\nstill lacks a balance between computational efficiency and bandwidth\nrequirements while maintaining high image segmentation accuracy, particularly\nin resource-limited environments and changing channel conditions. On the other\nhand, the more complex and larger semantic image segmentation models become,\nthe more stressed the devices are when processing data. This paper proposes a\nnovel approach to implementing semantic communication based on splitting the\nsemantic image segmentation process between a resource constrained transmitter\nand the receiver. This allows saving bandwidth by reducing the transmitted data\nwhile maintaining the accuracy of the semantic image segmentation.\nAdditionally, it reduces the computational requirements at the resource\nconstrained transmitter compared to doing all the semantic image segmentation\nin the transmitter. The proposed approach is evaluated by means of\nsimulation-based experiments in terms of different metrics such as\ncomputational resource usage, required bit rate and segmentation accuracy. The\nresults when comparing the proposal with the full semantic image segmentation\nin the transmitter show that up to 72% of the bit rate was reduced in the\ntransmission process. In addition, the computational load of the transmitter is\nreduced by more than 19%. This reflects the interest of this technique for its\napplication in communication systems, particularly in the upcoming 6G systems.", "comment": "IEEE International Mediterranean Conference on Communications and\n  Networking", "pdf_url": "http://arxiv.org/pdf/2507.14199v1", "cate": "cs.NI", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2210.14702", "title": "Privacy Analysis of Samsung's Crowd-Sourced Bluetooth Location Tracking System", "authors": ["Tingfeng Yu", "James Henderson", "Alwen Tiu", "Thomas Haines"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2210.14702v2", "summary": "We present a detailed privacy analysis of Samsung's Offline Finding (OF)\nprotocol, which is part of Samsung's Find My Mobile (FMM) location tracking\nsystem for locating Samsung mobile devices, such as Samsung smartphones and\nBluetooth trackers (Galaxy SmartTags). The OF protocol uses Bluetooth Low\nEnergy (BLE) to broadcast a unique beacon for a lost device. This beacon is\nthen picked up by nearby Samsung phones or tablets (the {\\em finder} devices),\nwhich then forward the unique beacon, along with the location it was detected\nat, to a Samsung managed server. The owner of a lost device can then query the\nserver to locate their device. We examine several security and privacy related\nproperties of the OF protocol and its implementation, from the perspectives of\nthe owner, the finder and the vendor. These include examining: the possibility\nof identifying the owner of a device through the Bluetooth data obtained from\nthe device, the possibility for a malicious actor to perform unwanted tracking\nagainst a person by exploiting the OF network, the possibility for the vendor\nto de-anonymise location reports to determine the locations of the owners or\nthe finders of lost devices, and the possibility for an attacker to compromise\nthe integrity of the location reports. Our findings suggest that there are\nprivacy risks on all accounts, arising from issues in the design and the\nimplementation of the OF protocol.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2210.14702v2", "cate": "cs.CR", "date": "2022-10-26", "updated": "2025-07-20"}
{"id": "2507.15293", "title": "RepILN: Reparameterized Inertial Localization Network", "authors": ["Shanshan Zhang", "Tianshui Wen", "Siyue Wang", "Qi Zhang", "Ziheng Zhou", "Lingxiang Zheng", "Yu Yang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15293v1", "summary": "Inertial localization is regarded as a promising positioning solution for\nconsumer-grade IoT devices due to its cost-effectiveness and independence from\nexternal infrastructure. However, data-driven inertial localization methods\noften rely on increasingly complex network architectures to improve accuracy,\nwhich challenges the limited computational resources of IoT devices. Moreover,\nthese methods frequently overlook the importance of modeling long-term\ndependencies in inertial measurements - a critical factor for accurate\ntrajectory reconstruction - thereby limiting localization performance. To\naddress these challenges, we propose a reparameterized inertial localization\nnetwork that uses a multi-branch structure during training to enhance feature\nextraction. At inference time, this structure is transformed into an equivalent\nsingle-path architecture to improve parameter efficiency. To further capture\nlong-term dependencies in motion trajectories, we introduce a temporal-scale\nsparse attention mechanism that selectively emphasizes key trajectory segments\nwhile suppressing noise. Additionally, a gated convolutional unit is\nincorporated to effectively integrate long-range dependencies with local\nfine-grained features. Extensive experiments on public benchmarks demonstrate\nthat our method achieves a favorable trade-off between accuracy and model\ncompactness. For example, on the RoNIN dataset, our approach reduces the\nAbsolute Trajectory Error (ATE) by 2.59% compared to RoNIN-ResNet while\nreducing the number of parameters by 3.86%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15293v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14947", "title": "Echoes of the Land: An Interactive Installation Based on Physical Model of Earthquake", "authors": ["Ivan C. H. Liu", "Chung-En Hao", "Jing Xie"], "categories": ["cs.HC", "nlin.AO"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      7 pages, 8 figures, submitted to Leonardo", "url": "http://arxiv.org/abs/2507.14947v1", "summary": "Echoes of the Land is an interactive installation that transforms seismic\ndynamics into a multisensory experience through a scientifically grounded\nspring-block model. Simulating earthquake recurrence and self-organized\ncriticality, the work generates real-time sound and light via motion capture\nand concatenative granular synthesis. Each block acts as an agent, producing\nemergent audiovisual cascades that visualize the physics of rupture and\nthreshold behavior. This work exemplifies the amalgamation of scientific\nknowledge and artistic practice, opening new avenues for novel forms of musical\ninstrument and narrative medium, while inviting further investigation into the\nintersection of emergent complexity, aesthetics and interactivity.", "comment": "7 pages, 8 figures, submitted to Leonardo", "pdf_url": "http://arxiv.org/pdf/2507.14947v1", "cate": "cs.HC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14593", "title": "Coordinate Heart System: A Geometric Framework for Emotion Representation", "authors": ["Omar Al-Desi"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      26 pages", "url": "http://arxiv.org/abs/2507.14593v1", "summary": "This paper presents the Coordinate Heart System (CHS), a geometric framework\nfor emotion representation in artificial intelligence applications. We position\neight core emotions as coordinates on a unit circle, enabling mathematical\ncomputation of complex emotional states through coordinate mixing and vector\noperations. Our initial five-emotion model revealed significant coverage gaps\nin the emotion space, leading to the development of an eight-emotion system\nthat provides complete geometric coverage with mathematical guarantees. The\nframework converts natural language input to emotion coordinates and supports\nreal-time emotion interpolation through computational algorithms. The system\nintroduces a re-calibrated stability parameter S in [0,1], which dynamically\nintegrates emotional load, conflict resolution, and contextual drain factors.\nThis stability model leverages advanced Large Language Model interpretation of\ntextual cues and incorporates hybrid temporal tracking mechanisms to provide\nnuanced assessment of psychological well-being states. Our key contributions\ninclude: (i) mathematical proof demonstrating why five emotions are\ninsufficient for complete geometric coverage, (ii) an eight-coordinate system\nthat eliminates representational blind spots, (iii) novel algorithms for\nemotion mixing, conflict resolution, and distance calculation in emotion space,\nand (iv) a comprehensive computational framework for AI emotion recognition\nwith enhanced multi-dimensional stability modeling. Experimental validation\nthrough case studies demonstrates the system's capability to handle emotionally\nconflicted states, contextual distress factors, and complex psychological\nscenarios that traditional categorical emotion models cannot adequately\nrepresent. This work establishes a new mathematical foundation for emotion\nmodeling in artificial intelligence systems.", "comment": "26 pages", "pdf_url": "http://arxiv.org/pdf/2507.14593v1", "cate": "cs.AI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.00286", "title": "\"Before, I Asked My Mom, Now I Ask ChatGPT\": Visual Privacy Management with Generative AI for Blind and Low-Vision People", "authors": ["Tanusree Sharma", "Yu-Yun Tseng", "Lotus Zhang", "Ayae Ide", "Kelly Avery Mack", "Leah Findlater", "Danna Gurari", "Yang Wang"], "categories": ["cs.HC", "cs.AI", "cs.ET"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.00286v2", "summary": "Blind and low vision (BLV) individuals use Generative AI (GenAI) tools to\ninterpret and manage visual content in their daily lives. While such tools can\nenhance the accessibility of visual content and so enable greater user\nindependence, they also introduce complex challenges around visual privacy. In\nthis paper, we investigate the current practices and future design preferences\nof blind and low vision individuals through an interview study with 21\nparticipants. Our findings reveal a range of current practices with GenAI that\nbalance privacy, efficiency, and emotional agency, with users accounting for\nprivacy risks across six key scenarios, such as self-presentation,\nindoor/outdoor spatial privacy, social sharing, and handling professional\ncontent. Our findings reveal design preferences, including on-device\nprocessing, zero-retention guarantees, sensitive content redaction,\nprivacy-aware appearance indicators, and multimodal tactile mirrored\ninteraction methods. We conclude with actionable design recommendations to\nsupport user-centered visual privacy through GenAI, expanding the notion of\nprivacy and responsible handling of others data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.00286v2", "cate": "cs.HC", "date": "2025-06-30", "updated": "2025-07-19"}
{"id": "2507.14204", "title": "LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling of Large Language Models", "authors": ["Dachuan Shi", "Yonggan Fu", "Xiangchi Yuan", "Zhongzhi Yu", "Haoran You", "Sixu Li", "Xin Dong", "Jan Kautz", "Pavlo Molchanov", "Yingyan", "Lin"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICML 2025. Code: this https URL", "url": "http://arxiv.org/abs/2507.14204v1", "summary": "Recent advancements in Large Language Models (LLMs) have spurred interest in\nnumerous applications requiring robust long-range capabilities, essential for\nprocessing extensive input contexts and continuously generating extended\noutputs. As sequence lengths increase, the number of Key-Value (KV) pairs in\nLLMs escalates, creating a significant efficiency bottleneck. In this paper, we\npropose a new KV cache optimization paradigm called LaCache, a training-free\nmethod for efficient and accurate generative inference of LLMs. LaCache enables\nLLMs to simultaneously address both of the critical challenges in long-range\nmodeling: robust long-range capabilities and continuous generation without\nrunning out-of-memory (OOM). Specifically, LaCache integrates two key\ninnovations: (1) a ladder-shaped KV cache pattern that stores KV pairs not only\nsequentially (left-to-right within each layer) but also across layers (from\nshallow to deep), providing an extended span for capturing long-range\ndependencies under a fixed storage budget, thereby boosting long-range\ncapabilities; and (2) an iterative compaction mechanism that progressively\ncompresses older caches, freeing up space for new tokens within a fixed cache\nsize. This token distance-based dynamic compression enables more effective\ncontinuous generation under constrained cache budgets. Experiments across\nvarious tasks, benchmarks, and LLM models consistently validate LaCache's\neffectiveness in enhancing LLMs' long-range capabilities. Our code is available\nat https://github.com/GATECH-EIC/LaCache.", "comment": "ICML 2025. Code: https://github.com/GATECH-EIC/LaCache", "pdf_url": "http://arxiv.org/pdf/2507.14204v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.14456", "title": "GEMINUS: Dual-aware Global and Scene-Adaptive Mixture-of-Experts for End-to-End Autonomous Driving", "authors": ["Chi Wan", "Yixin Cui", "Jiatong Du", "Shuo Yang", "Yulong Bai", "Yanjun Huang"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14456v1", "summary": "End-to-end autonomous driving requires adaptive and robust handling of\ncomplex and diverse traffic environments. However, prevalent single-mode\nplanning methods attempt to learn an overall policy while struggling to acquire\ndiversified driving skills to handle diverse scenarios. Therefore, this paper\nproposes GEMINUS, a Mixture-of-Experts end-to-end autonomous driving framework\nfeaturing a Global Expert, a Scene-Adaptive Experts Group, and equipped with a\nDual-aware Router. Specifically, the Global Expert is trained on the overall\ndataset, possessing robust performance. The Scene-Adaptive Experts are trained\non corresponding scene subsets, achieving adaptive performance. The Dual-aware\nRouter simultaneously considers scenario-level features and routing uncertainty\nto dynamically activate expert modules. Through the effective coupling of the\nGlobal Expert and the Scene-Adaptive Experts Group via the Dual-aware Router,\nGEMINUS achieves adaptive and robust performance in diverse scenarios. GEMINUS\noutperforms existing methods in the Bench2Drive closed-loop benchmark and\nachieves state-of-the-art performance in Driving Score and Success Rate, even\nwith only monocular vision input. Furthermore, ablation studies demonstrate\nsignificant improvements over the original single-expert baseline: 7.67% in\nDriving Score, 22.06% in Success Rate, and 19.41% in MultiAbility-Mean. The\ncode will be available at https://github.com/newbrains1/GEMINUS.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14456v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14612", "title": "Enhancing POI Recommendation through Global Graph Disentanglement with POI Weighted Module", "authors": ["Pei-Xuan Li", "Wei-Yun Liang", "Fandel Lin", "Hsun-Ping Hsieh"], "categories": ["cs.IR", "cs.AI", "cs.SI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14612v1", "summary": "Next point of interest (POI) recommendation primarily predicts future\nactivities based on users' past check-in data and current status, providing\nsignificant value to users and service providers. We observed that the popular\ncheck-in times for different POI categories vary. For example, coffee shops are\ncrowded in the afternoon because people like to have coffee to refresh after\nmeals, while bars are busy late at night. However, existing methods rarely\nexplore the relationship between POI categories and time, which may result in\nthe model being unable to fully learn users' tendencies to visit certain POI\ncategories at different times. Additionally, existing methods for modeling time\ninformation often convert it into time embeddings or calculate the time\ninterval and incorporate it into the model, making it difficult to capture the\ncontinuity of time. Finally, during POI prediction, various weighting\ninformation is often ignored, such as the popularity of each POI, the\ntransition relationships between POIs, and the distances between POIs, leading\nto suboptimal performance. To address these issues, this paper proposes a novel\nnext POI recommendation framework called Graph Disentangler with POI Weighted\nModule (GDPW). This framework aims to jointly consider POI category information\nand multiple POI weighting factors. Specifically, the proposed GDPW learns\ncategory and time representations through the Global Category Graph and the\nGlobal Category-Time Graph. Then, we disentangle category and time information\nthrough contrastive learning. After prediction, the final POI recommendation\nfor users is obtained by weighting the prediction results based on the\ntransition weights and distance relationships between POIs. We conducted\nexperiments on two real-world datasets, and the results demonstrate that the\nproposed GDPW outperforms other existing models, improving performance by 3% to\n11%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14612v1", "cate": "cs.IR", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14558", "title": "Harnessing LLMs for Document-Guided Fuzzing of OpenCV Library", "authors": ["Bin Duan", "Tarek Mahmud", "Meiru Che", "Yan Yan", "Naipeng Dong", "Dan Dongseong Kim", "Guowei Yang"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14558v1", "summary": "The combination of computer vision and artificial intelligence is\nfundamentally transforming a broad spectrum of industries by enabling machines\nto interpret and act upon visual data with high levels of accuracy. As the\nbiggest and by far the most popular open-source computer vision library, OpenCV\nlibrary provides an extensive suite of programming functions supporting\nreal-time computer vision. Bugs in the OpenCV library can affect the downstream\ncomputer vision applications, and it is critical to ensure the reliability of\nthe OpenCV library. This paper introduces VISTAFUZZ, a novel technique for\nharnessing large language models (LLMs) for document-guided fuzzing of the\nOpenCV library. VISTAFUZZ utilizes LLMs to parse API documentation and obtain\nstandardized API information. Based on this standardized information, VISTAFUZZ\nextracts constraints on individual input parameters and dependencies between\nthese. Using these constraints and dependencies, VISTAFUZZ then generates new\ninput values to systematically test each target API. We evaluate the\neffectiveness of VISTAFUZZ in testing 330 APIs in the OpenCV library, and the\nresults show that VISTAFUZZ detected 17 new bugs, where 10 bugs have been\nconfirmed, and 5 of these have been fixed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14558v1", "cate": "cs.SE", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14205", "title": "A Fault-Tolerant Architecture for Urban and Rural Digital Connectivity: Synergizing SDWMN, Direct-to-Mobile Broadcasting, and Hybrid Cloud Streaming", "authors": ["Pavel Malinovskiy"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14205v1", "summary": "We propose an integrated architecture combining Software-Defined Wireless\nMesh Networks (SDWMN), Direct-to-Mobile (D2M) broadcasting, and Kafka-based\nhybrid cloud streaming to improve wireless network performance in both urban\nand rural settings. The approach addresses urban congestion and rural digital\nexclusion through traffic offloading, enhanced fault tolerance, and equitable\nresource allocation. We model urban congestion $\\rho_u = \\lambda_t / \\mu_c$ and\nrural coverage deficit $\\delta_r = 1 - C_r / C_{req}$, and aim to minimize\nglobal performance loss $GPL = w_1 \\cdot \\rho_u + w_2 \\cdot \\delta_r + w_3\n\\cdot T_{rec}$, where $T_{rec}$ is recovery time. Experiments in Bangkok,\nMumbai, and rural Finland demonstrate latency reduction over 32%, bandwidth\noffloading of 40%, rural coverage gain of 28%, and fairness index rising from\n0.78 to 0.91. The system achieves recovery under 10 s using SDWMN and Kafka. We\nrecommend optimal spectrum allocation $\\alpha_s$, targeted subsidies, and\ndevice mandates to promote adoption. This scalable, fault-tolerant design\nsupports equitable digital transformation and suggests directions for future\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14205v1", "cate": "cs.NI", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2211.05403", "title": "Enabling Efficient Attack Investigation via Human-in-the-Loop Security Analysis", "authors": ["Saimon Amanuel Tsegai", "Xinyu Yang", "Haoyuan Liu", "Peng Gao"], "categories": ["cs.CR", "cs.CL", "cs.DB"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted at 51st International Conference on Very Large Data Bases (VLDB) 2025", "url": "http://arxiv.org/abs/2211.05403v3", "summary": "System auditing is a vital technique for collecting system call events as\nsystem provenance and investigating complex multi-step attacks such as Advanced\nPersistent Threats. However, existing attack investigation methods struggle to\nuncover long attack sequences due to the massive volume of system provenance\ndata and their inability to focus on attack-relevant parts. In this paper, we\npresent Provexa, a defense system that enables human analysts to effectively\nanalyze large-scale system provenance to reveal multi-step attack sequences.\nProvexa introduces an expressive domain-specific language, ProvQL, that offers\nessential primitives for various types of attack analyses (e.g., attack pattern\nsearch, attack dependency tracking) with user-defined constraints, enabling\nanalysts to focus on attack-relevant parts and iteratively sift through the\nlarge provenance data. Moreover, Provexa provides an optimized execution engine\nfor efficient language execution. Our extensive evaluations on a wide range of\nattack scenarios demonstrate the practical effectiveness of Provexa in\nfacilitating timely attack investigation.", "comment": "Accepted at 51st International Conference on Very Large Data Bases\n  (VLDB) 2025", "pdf_url": "http://arxiv.org/pdf/2211.05403v3", "cate": "cs.CR", "date": "2022-11-10", "updated": "2025-07-21"}
{"id": "2507.15444", "title": "Low-Latency Event-Based Velocimetry for Quadrotor Control in a Narrow Pipe", "authors": ["Leonard Bauersfeld", "Davide Scaramuzza"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      17 pages", "url": "http://arxiv.org/abs/2507.15444v1", "summary": "Autonomous quadrotor flight in confined spaces such as pipes and tunnels\npresents significant challenges due to unsteady, self-induced aerodynamic\ndisturbances. Very recent advances have enabled flight in such conditions, but\nthey either rely on constant motion through the pipe to mitigate airflow\nrecirculation effects or suffer from limited stability during hovering. In this\nwork, we present the first closed-loop control system for quadrotors for\nhovering in narrow pipes that leverages real-time flow field measurements. We\ndevelop a low-latency, event-based smoke velocimetry method that estimates\nlocal airflow at high temporal resolution. This flow information is used by a\ndisturbance estimator based on a recurrent convolutional neural network, which\ninfers force and torque disturbances in real time. The estimated disturbances\nare integrated into a learning-based controller trained via reinforcement\nlearning. The flow-feedback control proves particularly effective during\nlateral translation maneuvers in the pipe cross-section. There, the real-time\ndisturbance information enables the controller to effectively counteract\ntransient aerodynamic effects, thereby preventing collisions with the pipe\nwall. To the best of our knowledge, this work represents the first\ndemonstration of an aerial robot with closed-loop control informed by real-time\nflow field measurements. This opens new directions for research on flight in\naerodynamically complex environments. In addition, our work also sheds light on\nthe characteristic flow structures that emerge during flight in narrow,\ncircular pipes, providing new insights at the intersection of robotics and\nfluid dynamics.", "comment": "17 pages", "pdf_url": "http://arxiv.org/pdf/2507.15444v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14961", "title": "Emphasizing Deliberation and Critical Thinking in an AI Hype World", "authors": ["Katja Rogers"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted at CHI 2025 workshop: \"Resisting AI Solutionism: Where Do We Go From Here?\" ( this https URL )", "url": "http://arxiv.org/abs/2507.14961v1", "summary": "AI solutionism is accelerated and substantiated by hype and HCI's elevation\nof novelty. Banning or abandoning technology is unlikely to work and probably\nnot beneficial on the whole either -- but slow(er), deliberate use together\nwith conscientious, critical engagement and non-engagement may help us navigate\na post-AI hype world while contributing to a solid knowledge foundation and\nreducing harmful impacts in education and research.", "comment": "Accepted at CHI 2025 workshop: \"Resisting AI Solutionism: Where Do We\n  Go From Here?\" (https://doi.org/10.1145/3706599.3706732)", "pdf_url": "http://arxiv.org/pdf/2507.14961v1", "cate": "cs.HC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14642", "title": "Efficient Story Point Estimation With Comparative Learning", "authors": ["Monoshiz Mahbub Khan", "Xioayin Xi", "Andrew Meneely", "Zhe Yu"], "categories": ["cs.AI", "cs.SE"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14642v1", "summary": "Story point estimation is an essential part of agile software development.\nStory points are unitless, project-specific effort estimates that help\ndevelopers plan their sprints. Traditionally, developers estimate story points\ncollaboratively using planning poker or other manual techniques. While the\ninitial calibrating of the estimates to each project is helpful, once a team\nhas converged on a set of precedents, story point estimation can become tedious\nand labor-intensive. Machine learning can reduce this burden, but only with\nenough context from the historical decisions made by the project team. That is,\nstate-of-the-art models, such as GPT2SP and FastText-SVM, only make accurate\npredictions (within-project) when trained on data from the same project. The\ngoal of this work is to streamline story point estimation by evaluating a\ncomparative learning-based framework for calibrating project-specific story\npoint prediction models. Instead of assigning a specific story point value to\nevery backlog item, developers are presented with pairs of items, and indicate\nwhich item requires more effort. Using these comparative judgments, a machine\nlearning model is trained to predict the story point estimates. We empirically\nevaluated our technique using data with 23,313 manual estimates in 16 projects.\nThe model learned from comparative judgments can achieve on average 0.34\nSpearman's rank correlation coefficient between its predictions and the ground\ntruth story points. This is similar to, if not better than, the performance of\na regression model learned from the ground truth story points. Therefore, the\nproposed comparative learning approach is more efficient than state-of-the-art\nregression-based approaches according to the law of comparative judgments -\nproviding comparative judgments yields a lower cognitive burden on humans than\nproviding ratings or categorical labels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14642v1", "cate": "cs.AI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14215", "title": "Developing an AI-Guided Assistant Device for the Deaf and Hearing Impaired", "authors": ["Jiayu", "Liu"], "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14215v1", "summary": "This study aims to develop a deep learning system for an accessibility device\nfor the deaf or hearing impaired. The device will accurately localize and\nidentify sound sources in real time. This study will fill an important gap in\ncurrent research by leveraging machine learning techniques to target the\nunderprivileged community. The system includes three main components. 1.\nJerryNet: A custom designed CNN architecture that determines the direction of\narrival (DoA) for nine possible directions. 2. Audio Classification: This model\nis based on fine-tuning the Contrastive Language-Audio Pretraining (CLAP) model\nto identify the exact sound classes only based on audio. 3. Multimodal\nintegration model: This is an accurate sound localization model that combines\naudio, visual, and text data to locate the exact sound sources in the images.\nThe part consists of two modules, one object detection using Yolov9 to generate\nall the bounding boxes of the objects, and an audio visual localization model\nto identify the optimal bounding box using complete Intersection over Union\n(CIoU). The hardware consists of a four-microphone rectangular formation and a\ncamera mounted on glasses with a wristband for displaying necessary information\nlike direction. On a custom collected data set, JerryNet achieved a precision\nof 91. 1% for the sound direction, outperforming all the baseline models. The\nCLAP model achieved 98.5% and 95% accuracy on custom and AudioSet datasets,\nrespectively. The audio-visual localization model within component 3 yielded a\ncIoU of 0.892 and an AUC of 0.658, surpassing other similar models. There are\nmany future potentials to this study, paving the way to creating a new\ngeneration of accessibility devices.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14215v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.14459", "title": "VisGuard: Securing Visualization Dissemination through Tamper-Resistant Data Retrieval", "authors": ["Huayuan Ye", "Juntong Chen", "Shenzhuo Zhang", "Yipeng Zhang", "Changbo Wang", "Chenhui Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      9 pages, IEEE VIS 2025", "url": "http://arxiv.org/abs/2507.14459v1", "summary": "The dissemination of visualizations is primarily in the form of raster\nimages, which often results in the loss of critical information such as source\ncode, interactive features, and metadata. While previous methods have proposed\nembedding metadata into images to facilitate Visualization Image Data Retrieval\n(VIDR), most existing methods lack practicability since they are fragile to\ncommon image tampering during online distribution such as cropping and editing.\nTo address this issue, we propose VisGuard, a tamper-resistant VIDR framework\nthat reliably embeds metadata link into visualization images. The embedded data\nlink remains recoverable even after substantial tampering upon images. We\npropose several techniques to enhance robustness, including repetitive data\ntiling, invertible information broadcasting, and an anchor-based scheme for\ncrop localization. VisGuard enables various applications, including interactive\nchart reconstruction, tampering detection, and copyright protection. We conduct\ncomprehensive experiments on VisGuard's superior performance in data retrieval\naccuracy, embedding capacity, and security against tampering and steganalysis,\ndemonstrating VisGuard's competence in facilitating and safeguarding\nvisualization dissemination and information conveyance.", "comment": "9 pages, IEEE VIS 2025", "pdf_url": "http://arxiv.org/pdf/2507.14459v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15067", "title": "ROBAD: Robust Adversary-aware Local-Global Attended Bad Actor Detection Sequential Model", "authors": ["Bing He", "Mustaque Ahamad", "Srijan Kumar"], "categories": ["cs.LG", "cs.SI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      15 pages, 12 tables", "url": "http://arxiv.org/abs/2507.15067v1", "summary": "Detecting bad actors is critical to ensure the safety and integrity of\ninternet platforms. Several deep learning-based models have been developed to\nidentify such users. These models should not only accurately detect bad actors,\nbut also be robust against adversarial attacks that aim to evade detection.\nHowever, past deep learning-based detection models do not meet the robustness\nrequirement because they are sensitive to even minor changes in the input\nsequence. To address this issue, we focus on (1) improving the model\nunderstanding capability and (2) enhancing the model knowledge such that the\nmodel can recognize potential input modifications when making predictions. To\nachieve these goals, we create a novel transformer-based classification model,\ncalled ROBAD (RObust adversary-aware local-global attended Bad Actor Detection\nmodel), which uses the sequence of user posts to generate user embedding to\ndetect bad actors. Particularly, ROBAD first leverages the transformer encoder\nblock to encode each post bidirectionally, thus building a post embedding to\ncapture the local information at the post level. Next, it adopts the\ntransformer decoder block to model the sequential pattern in the post\nembeddings by using the attention mechanism, which generates the sequence\nembedding to obtain the global information at the sequence level. Finally, to\nenrich the knowledge of the model, embeddings of modified sequences by mimicked\nattackers are fed into a contrastive-learning-enhanced classification layer for\nsequence prediction. In essence, by capturing the local and global information\n(i.e., the post and sequence information) and leveraging the mimicked behaviors\nof bad actors in training, ROBAD can be robust to adversarial attacks.\nExtensive experiments on Yelp and Wikipedia datasets show that ROBAD can\neffectively detect bad actors when under state-of-the-art adversarial attacks.", "comment": "15 pages, 12 tables", "pdf_url": "http://arxiv.org/pdf/2507.15067v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14594", "title": "A first look at License Variants in the PyPI Ecosystem", "authors": ["Weiwei Xu", "Hengzhi Ye", "Kai Gao", "Minghui Zhou"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14594v1", "summary": "Open-source licenses establish the legal foundation for software reuse, yet\nlicense variants, including both modified standard licenses and custom-created\nalternatives, introduce significant compliance complexities. Despite their\nprevalence and potential impact, these variants are poorly understood in modern\nsoftware systems, and existing tools do not account for their existence,\nleading to significant challenges in both effectiveness and efficiency of\nlicense analysis. To fill this knowledge gap, we conduct a comprehensive\nempirical study of license variants in the PyPI ecosystem. Our findings show\nthat textual variations in licenses are common, yet only 2% involve substantive\nmodifications. However, these license variants lead to significant compliance\nissues, with 10.7% of their downstream dependencies found to be\nlicense-incompatible.\n  Inspired by our findings, we introduce LV-Parser, a novel approach for\nefficient license variant analysis leveraging diff-based techniques and large\nlanguage models, along with LV-Compat, an automated pipeline for detecting\nlicense incompatibilities in software dependency networks. Our evaluation\ndemonstrates that LV-Parser achieves an accuracy of 0.936 while reducing\ncomputational costs by 30%, and LV-Compat identifies 5.2 times more\nincompatible packages than existing methods with a precision of 0.98.\n  This work not only provides the first empirical study into license variants\nin software packaging ecosystem but also equips developers and organizations\nwith practical tools for navigating the complex landscape of open-source\nlicensing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14594v1", "cate": "cs.SE", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14211", "title": "PRATA: A Framework to Enable Predictive QoS in Vehicular Networks via Artificial Intelligence", "authors": ["Federico Mason", "Tommaso Zugno", "Matteo Drago", "Marco Giordani", "Mate Boban", "Michele Zorzi"], "categories": ["cs.NI", "cs.AI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14211v1", "summary": "Predictive Quality of Service (PQoS) makes it possible to anticipate QoS\nchanges, e.g., in wireless networks, and trigger appropriate countermeasures to\navoid performance degradation. Hence, PQoS is extremely useful for automotive\napplications such as teleoperated driving, which poses strict constraints in\nterms of latency and reliability. A promising tool for PQoS is given by\nReinforcement Learning (RL), a methodology that enables the design of\ndecision-making strategies for stochastic optimization. In this manuscript, we\npresent PRATA, a new simulation framework to enable PRedictive QoS based on AI\nfor Teleoperated driving Applications. PRATA consists of a modular pipeline\nthat includes (i) an end-to-end protocol stack to simulate the 5G Radio Access\nNetwork (RAN), (ii) a tool for generating automotive data, and (iii) an\nArtificial Intelligence (AI) unit to optimize PQoS decisions. To prove its\nutility, we use PRATA to design an RL unit, named RAN-AI, to optimize the\nsegmentation level of teleoperated driving data in the event of resource\nsaturation or channel degradation. Hence, we show that the RAN-AI entity\nefficiently balances the trade-off between QoS and Quality of Experience (QoE)\nthat characterize teleoperated driving applications, almost doubling the system\nperformance compared to baseline approaches. In addition, by varying the\nlearning settings of the RAN-AI entity, we investigate the impact of the state\nspace and the relative cost of acquiring network data that are necessary for\nthe implementation of RL.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14211v1", "cate": "cs.NI", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.14704", "title": "Information Theoretic Analysis of a Dual-Band MIMO Cellphone Antenna with ANSYS HFSS SBR+", "authors": ["Volodymyr Shyianov", "Bamelak Tadele", "Vladimir I. Okhmatovski", "Amine Mezghani"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      4 pages, 6 figures", "url": "http://arxiv.org/abs/2507.14704v1", "summary": "Historically, the design of antenna arrays has evolved separately from\nShannon theory. Shannon theory adopts a probabilistic approach in the design of\ncommunication systems, while antenna design approaches have relied on the\ndeterministic Maxwell theory alone. In this paper, we investigate an\ninformation-theoretic analysis approach which we apply to evaluate the design\nof a dual-band, dual-polarized multiple-input multiple-output (MIMO) array on a\ncellphone. To this end, we use ANSYS HFSS, a commercial electromagnetic (EM)\nsimulation software suitable for the numerical optimization of antenna systems.\nHFSS is used to obtain an accurate model of the cellphone MIMO antenna array\nand HFSS SBR+ is utilized to obtain channel matrices for a large number of\nusers. Taking advantage of linear and optimal processing at the cellphone, we\nestimate the outage probability curves. The curves are then used to determine\nthe diversity gain in a moderate signal-to-noise ratio (SNR) regime and the\nmultiplexing gain at a high SNR regime. This approach is then compared with the\nmethod of estimating the diversity gain from the envelope correlation\ncoefficients or the beam-coupling matrix showing substantial differences in the\ntwo methodologies.", "comment": "4 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.14704v1", "cate": "cs.IT", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2305.17655", "title": "Understanding Blockchain Governance: Analyzing Decentralized Voting to Amend DeFi Smart Contracts", "authors": ["Johnnatan Messias", "Vabuk Pahari", "Balakrishnan Chandrasekaran", "Krishna P. Gummadi", "Patrick Loiseau"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2305.17655v4", "summary": "Decentralized Autonomous Organizations (DAOs) have emerged as a novel\ngovernance mechanism in blockchain ecosystems, particularly within\nDecentralized Finance (DeFi). By enabling token holders to propose and vote on\nprotocol changes, these systems promise transparent and equitable\ndecision-making without centralized control. In this paper, we present an\nin-depth empirical study of the governance protocols of Compound and Uniswap,\ntwo of the most widely used DAOs in DeFi. Analyzing over 370 governance\nproposals and millions of on-chain events from their inception until August\n2024, we uncover significant centralization of voting power: as few as 3--5\nvoters were sufficient to sway the majority of proposals. We also find that the\ncost of voting disproportionately burdens smaller token holders, and that\nstrategic voting behaviors, such as delayed participation and coalition\nformation, further distort governance outcomes. Our findings suggest that\ndespite their decentralized ideals, current DAO governance mechanisms fall\nshort in practice.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2305.17655v4", "cate": "cs.CR", "date": "2023-05-28", "updated": "2025-07-21"}
{"id": "2507.15469", "title": "The Emergence of Deep Reinforcement Learning for Path Planning", "authors": ["Thanh Thi Nguyen", "Saeid Nahavandi", "Imran Razzak", "Dung Nguyen", "Nhat Truong Pham", "Quoc Viet Hung Nguyen"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted for publication in the Proceedings of the 2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)", "url": "http://arxiv.org/abs/2507.15469v1", "summary": "The increasing demand for autonomous systems in complex and dynamic\nenvironments has driven significant research into intelligent path planning\nmethodologies. For decades, graph-based search algorithms, linear programming\ntechniques, and evolutionary computation methods have served as foundational\napproaches in this domain. Recently, deep reinforcement learning (DRL) has\nemerged as a powerful method for enabling autonomous agents to learn optimal\nnavigation strategies through interaction with their environments. This survey\nprovides a comprehensive overview of traditional approaches as well as the\nrecent advancements in DRL applied to path planning tasks, focusing on\nautonomous vehicles, drones, and robotic platforms. Key algorithms across both\nconventional and learning-based paradigms are categorized, with their\ninnovations and practical implementations highlighted. This is followed by a\nthorough discussion of their respective strengths and limitations in terms of\ncomputational efficiency, scalability, adaptability, and robustness. The survey\nconcludes by identifying key open challenges and outlining promising avenues\nfor future research. Special attention is given to hybrid approaches that\nintegrate DRL with classical planning techniques to leverage the benefits of\nboth learning-based adaptability and deterministic reliability, offering\npromising directions for robust and resilient autonomous navigation.", "comment": "Accepted for publication in the Proceedings of the 2025 IEEE\n  International Conference on Systems, Man, and Cybernetics (SMC)", "pdf_url": "http://arxiv.org/pdf/2507.15469v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15033", "title": "'A Little Bubble of Friends': An Analysis of LGBTQ+ Pandemic Experiences Using Reddit Data", "authors": ["Dhruvee Birla", "Nazia Akhtar"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15033v1", "summary": "Social media was one of the most popular forms of communication among young\npeople with digital access during the pandemic. Consequently, crucial debates\nand discussions about the pandemic crisis have also developed on social media\nplatforms, making them a great primary source to study the experiences of\nspecific groups and communities during the pandemic. This study involved\nresearch using LDA topic modeling and sentiment analysis on data obtained from\nthe social media platform Reddit to understand the themes and attitudes in\ncirculation within five subreddits devoted to LGBTQ+ experiences and issues. In\nthe process, we attempt to make sense of the role that Reddit may have played\nin the lives of LGBTQ+ people who were online during the pandemic, and whether\nthis was marked by any continuities or discontinuities from before the pandemic\nperiod.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15033v1", "cate": "cs.HC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14660", "title": "When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems", "authors": ["Qibing Ren", "Sitao Xie", "Longxuan Wei", "Zhenfei Yin", "Junchi Yan", "Lizhuang Ma", "Jing Shao"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Code is available at this https URL", "url": "http://arxiv.org/abs/2507.14660v1", "summary": "Recent large-scale events like election fraud and financial scams have shown\nhow harmful coordinated efforts by human groups can be. With the rise of\nautonomous AI systems, there is growing concern that AI-driven groups could\nalso cause similar harm. While most AI safety research focuses on individual AI\nsystems, the risks posed by multi-agent systems (MAS) in complex real-world\nsituations are still underexplored. In this paper, we introduce a\nproof-of-concept to simulate the risks of malicious MAS collusion, using a\nflexible framework that supports both centralized and decentralized\ncoordination structures. We apply this framework to two high-risk fields:\nmisinformation spread and e-commerce fraud. Our findings show that\ndecentralized systems are more effective at carrying out malicious actions than\ncentralized ones. The increased autonomy of decentralized systems allows them\nto adapt their strategies and cause more damage. Even when traditional\ninterventions, like content flagging, are applied, decentralized groups can\nadjust their tactics to avoid detection. We present key insights into how these\nmalicious groups operate and the need for better detection systems and\ncountermeasures. Code is available at https://github.com/renqibing/RogueAgent.", "comment": "Code is available at https://github.com/renqibing/RogueAgent", "pdf_url": "http://arxiv.org/pdf/2507.14660v1", "cate": "cs.AI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14217", "title": "Geometry-Aware Active Learning of Pattern Rankings via Choquet-Based Aggregation", "authors": ["Tudor Matei Opran", "Samir Loudni"], "categories": ["cs.LG", "cs.HC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14217v1", "summary": "We address the pattern explosion problem in pattern mining by proposing an\ninteractive learning framework that combines nonlinear utility aggregation with\ngeometry-aware query selection. Our method models user preferences through a\nChoquet integral over multiple interestingness measures and exploits the\ngeometric structure of the version space to guide the selection of informative\ncomparisons. A branch-and-bound strategy with tight distance bounds enables\nefficient identification of queries near the decision boundary. Experiments on\nUCI datasets show that our approach outperforms existing methods such as\nChoquetRank, achieving better ranking accuracy with fewer user interactions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14217v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.14477", "title": "OptiCorNet: Optimizing Sequence-Based Context Correlation for Visual Place Recognition", "authors": ["Zhenyu Li", "Tianyi Shang", "Pengjie Xu", "Ruirui Zhang", "Fanchen Kong"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      5 figures", "url": "http://arxiv.org/abs/2507.14477v1", "summary": "Visual Place Recognition (VPR) in dynamic and perceptually aliased\nenvironments remains a fundamental challenge for long-term localization.\nExisting deep learning-based solutions predominantly focus on single-frame\nembeddings, neglecting the temporal coherence present in image sequences. This\npaper presents OptiCorNet, a novel sequence modeling framework that unifies\nspatial feature extraction and temporal differencing into a differentiable,\nend-to-end trainable module. Central to our approach is a lightweight 1D\nconvolutional encoder combined with a learnable differential temporal operator,\ntermed Differentiable Sequence Delta (DSD), which jointly captures short-term\nspatial context and long-range temporal transitions. The DSD module models\ndirectional differences across sequences via a fixed-weight differencing\nkernel, followed by an LSTM-based refinement and optional residual projection,\nyielding compact, discriminative descriptors robust to viewpoint and appearance\nshifts. To further enhance inter-class separability, we incorporate a\nquadruplet loss that optimizes both positive alignment and multi-negative\ndivergence within each batch. Unlike prior VPR methods that treat temporal\naggregation as post-processing, OptiCorNet learns sequence-level embeddings\ndirectly, enabling more effective end-to-end place recognition. Comprehensive\nevaluations on multiple public benchmarks demonstrate that our approach\noutperforms state-of-the-art baselines under challenging seasonal and viewpoint\nvariations.", "comment": "5 figures", "pdf_url": "http://arxiv.org/pdf/2507.14477v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15253", "title": "Disentangling Homophily and Heterophily in Multimodal Graph Clustering", "authors": ["Zhaochen Guo", "Zhixiang Shen", "Xuanting Xie", "Liangjian Wen", "Zhao Kang"], "categories": ["cs.AI", "cs.LG", "cs.SI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Appear in ACM Multimedia 2025", "url": "http://arxiv.org/abs/2507.15253v1", "summary": "Multimodal graphs, which integrate unstructured heterogeneous data with\nstructured interconnections, offer substantial real-world utility but remain\ninsufficiently explored in unsupervised learning. In this work, we initiate the\nstudy of multimodal graph clustering, aiming to bridge this critical gap.\nThrough empirical analysis, we observe that real-world multimodal graphs often\nexhibit hybrid neighborhood patterns, combining both homophilic and\nheterophilic relationships. To address this challenge, we propose a novel\nframework -- \\textsc{Disentangled Multimodal Graph Clustering (DMGC)} -- which\ndecomposes the original hybrid graph into two complementary views: (1) a\nhomophily-enhanced graph that captures cross-modal class consistency, and (2)\nheterophily-aware graphs that preserve modality-specific inter-class\ndistinctions. We introduce a \\emph{Multimodal Dual-frequency Fusion} mechanism\nthat jointly filters these disentangled graphs through a dual-pass strategy,\nenabling effective multimodal integration while mitigating category confusion.\nOur self-supervised alignment objectives further guide the learning process\nwithout requiring labels. Extensive experiments on both multimodal and\nmulti-relational graph datasets demonstrate that DMGC achieves state-of-the-art\nperformance, highlighting its effectiveness and generalizability across diverse\nsettings. Our code is available at https://github.com/Uncnbb/DMGC.", "comment": "Appear in ACM Multimedia 2025", "pdf_url": "http://arxiv.org/pdf/2507.15253v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14687", "title": "An Efficient Algorithm for Generating Minimal Unique-Cause MC/DC Test cases for Singular Boolean Expressions", "authors": ["Robin Lee", "Youngho Nam"], "categories": ["cs.SE", "68Q60, 03B70", "D.2.5"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures", "url": "http://arxiv.org/abs/2507.14687v1", "summary": "Modified Condition/Decision Coverage (MC/DC) is a mandatory structural\ncoverage criterion for ensuring the reliability and safety of critical systems.\nWhile its strictest form, Unique-Cause MC/DC, offers the highest assurance,\nresearch on its efficient test generation has been lacking. This gap is\nparticularly significant, as an analysis of large-scale avionics systems shows\nthat 99.7% of all conditional decisions are, in fact, Singular Boolean\nExpressions (SBEs) the ideal structure for applying Unique-Cause MC/DC. This\npaper proposes 'Robin's Rule', a deterministic algorithm that directly\nconstructs a minimal test set of N + 1 cases to guarantee 100% Unique-Cause\nMC/DC for SBEs with N conditions, without generating a full truth table. To\nvalidate our approach, we constructed a benchmark by reformulating the TCAS-II\nspecifications into SBEs and verified the results using an industry-standard,\ncertified commercial tool. The results confirm that our method consistently\nachieves 100% coverage with the theoretical minimum number of tests and is more\nefficient than the commercial tool. This work provides a practical and provably\noptimal solution for verifying safety-critical systems, ensuring both rigor and\nefficiency.", "comment": "10 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.14687v1", "cate": "cs.SE", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14230", "title": "Intent-Based Network for RAN Management with Large Language Models", "authors": ["Fransiscus Asisi Bimo", "Maria Amparo Canaveras Galdon", "Chun-Kai Lai", "Ray-Guang Cheng", "Edwin K. P. Chong"], "categories": ["cs.NI", "cs.AI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      5 pages, 3 figures, submitted to IEEE Globecom 2025", "url": "http://arxiv.org/abs/2507.14230v1", "summary": "Advanced intelligent automation becomes an important feature to deal with the\nincreased complexity in managing wireless networks. This paper proposes a novel\nautomation approach of intent-based network for Radio Access Networks (RANs)\nmanagement by leveraging Large Language Models (LLMs). The proposed method\nenhances intent translation, autonomously interpreting high-level objectives,\nreasoning over complex network states, and generating precise configurations of\nthe RAN by integrating LLMs within an agentic architecture. We propose a\nstructured prompt engineering technique and demonstrate that the network can\nautomatically improve its energy efficiency by dynamically optimizing critical\nRAN parameters through a closed-loop mechanism. It showcases the potential to\nenable robust resource management in RAN by adapting strategies based on\nreal-time feedback via LLM-orchestrated agentic systems.", "comment": "5 pages, 3 figures, submitted to IEEE Globecom 2025", "pdf_url": "http://arxiv.org/pdf/2507.14230v1", "cate": "cs.NI", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14733", "title": "Study of Delay-Calibrated Joint User Activity Detection, Channel Estimation and Data Detection for Asynchronous mMTC Systems", "authors": ["Z. Shao", "X. Yuan", "R. de Lamare"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      6 pages, 2 figures", "url": "http://arxiv.org/abs/2507.14733v1", "summary": "This work considers uplink asynchronous massive machine-type communications,\nwhere a large number of low-power and low-cost devices asynchronously transmit\nshort packets to an access point equipped with multiple receive antennas. If\northogonal preambles are employed, massive collisions will occur due to the\nlimited number of orthogonal preambles given the preamble sequence length. To\naddress this problem, we propose a delay-calibrated joint user activity\ndetection, channel estimation, and data detection algorithm, and investigate\nthe benefits of oversampling in estimating continuous-valued time delays at the\nreceiver. The proposed algorithm is based on the expectation-maximization\nmethod, which alternately estimates the delays and detects active users and\ntheir channels and data by noting that the collided users have different\ndelays. Under the Bayesian inference framework, we develop a computationally\nefficient iterative algorithm using the approximate message passing principle\nto resolve the joint user activity detection, channel estimation, and data\ndetection problem. Numerical results demonstrate the effectiveness of the\nproposed algorithm in terms of the normalized mean-squared errors of channel\nand data symbols, and the probability of misdetection.", "comment": "6 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.14733v1", "cate": "cs.IT", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14139", "title": "SpeedLLM: An FPGA Co-design of Large Language Model Inference Accelerator", "authors": ["Peipei Wang", "Wu Guan", "Liping Liang", "Zhijun Wang", "Hanqing Luo", "Zhibin Zhang"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14139v1", "summary": "This paper introduces SpeedLLM, a neural network accelerator designed on the\nXilinx Alevo U280 platform and optimized for the Tinyllama framework to enhance\nedge computing performance. Key innovations include data stream parallelism, a\nmemory reuse strategy, and Llama2 operator fusion, which collectively reduce\nlatency and energy consumption. SpeedLLM's data pipeline architecture optimizes\nthe read-compute-write cycle, while the memory strategy minimizes FPGA resource\ndemands. The operator fusion boosts computational density and throughput.\nResults show SpeedLLM outperforms traditional Tinyllama implementations,\nachieving up to 4.8* faster performance and 1.18* lower energy consumption,\noffering improvements in edge devices.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14139v1", "cate": "cs.AR", "date": "2025-05-07", "updated": "2025-05-07"}
{"id": "2312.02752", "title": "Airdrops: Giving Money Away Is Harder Than It Seems", "authors": ["Johnnatan Messias", "Aviv Yaish", "Benjamin Livshits"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      J. Messias and A. Yaish contributed equally to this work. Some of this work was performed while the authors were at Matter Labs", "url": "http://arxiv.org/abs/2312.02752v4", "summary": "Airdrops are a popular mechanism used by blockchain protocols to bootstrap\ncommunities, reward early adopters, and decentralize token distribution.\nDespite their widespread adoption, the effectiveness of airdrops in achieving\nlong-term user engagement and ecosystem growth remains poorly understood. In\nthis paper, we present the first comprehensive empirical study of nine major\nairdrops across Ethereum and Layer-2 ecosystems. Our analysis reveals that a\nsubstantial share of tokens--up to 66% in some cases--are rapidly sold, often\nin recipients' first post-claim transaction. We show that this behavior is\nlargely driven by \"airdrop farmers,\" who strategically optimize eligibility\ncriteria to extract value without contributing meaningfully to the ecosystem.\nWe complement our quantitative findings with a case study of the Arbitrum\nairdrop, illustrating how short-term activity spikes fail to translate into\nsustained user involvement. Based on these results, we discuss common design\npitfalls--such as Sybil vulnerability, poor incentive alignment, and governance\ntoken misuse--and propose actionable guidelines for designing more effective\nairdrop strategies.", "comment": "J. Messias and A. Yaish contributed equally to this work. Some of\n  this work was performed while the authors were at Matter Labs", "pdf_url": "http://arxiv.org/pdf/2312.02752v4", "cate": "cs.CR", "date": "2023-12-05", "updated": "2025-07-21"}
{"id": "2507.15474", "title": "All-UWB SLAM Using UWB Radar and UWB AOA", "authors": ["Charith Premachandra", "Achala Athukorala", "U-Xuan Tan"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15474v1", "summary": "There has been a growing interest in autonomous systems designed to operate\nin adverse conditions (e.g. smoke, dust), where the visible light spectrum\nfails. In this context, Ultra-wideband (UWB) radar is capable of penetrating\nthrough such challenging environmental conditions due to the lower frequency\ncomponents within its broad bandwidth. Therefore, UWB radar has emerged as a\npotential sensing technology for Simultaneous Localization and Mapping (SLAM)\nin vision-denied environments where optical sensors (e.g. LiDAR, Camera) are\nprone to failure. Existing approaches involving UWB radar as the primary\nexteroceptive sensor generally extract features in the environment, which are\nlater initialized as landmarks in a map. However, these methods are constrained\nby the number of distinguishable features in the environment. Hence, this paper\nproposes a novel method incorporating UWB Angle of Arrival (AOA) measurements\ninto UWB radar-based SLAM systems to improve the accuracy and scalability of\nSLAM in feature-deficient environments. The AOA measurements are obtained using\nUWB anchor-tag units which are dynamically deployed by the robot in featureless\nareas during mapping of the environment. This paper thoroughly discusses\nprevailing constraints associated with UWB AOA measurement units and presents\nsolutions to overcome them. Our experimental results show that integrating UWB\nAOA units with UWB radar enables SLAM in vision-denied feature-deficient\nenvironments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15474v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15041", "title": "Visibility vs. Engagement: How Two Indian News Websites Reported on LGBTQ+ Individuals and Communities during the Pandemic", "authors": ["Dhruvee Birla", "Nazia Akhtar"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15041v1", "summary": "In India, online news media outlets were an important source of information\nfor people with digital access during the COVID-19 pandemic. In India, where\n\"transgender\" was legally recognised as a category only in 2014, and same-sex\nmarriages are yet to be legalised, it becomes crucial to analyse whether and\nhow they reported the lived realities of vulnerable LGBTQ+ communities during\nthe pandemic. This study analysed articles from online editions of two\nEnglish-language newspaper websites, which differed vastly in their circulation\nfigures-The Times of India and The Indian Express. The results of our study\nsuggest that these newspaper websites published articles surrounding various\naspects of the lives of LGBTQ+ individuals with a greater focus on transgender\ncommunities. However, they lacked quality and depth. Focusing on the period\nspanning March 2020 to August 2021, we analysed articles using sentiment\nanalysis and topic modelling. We also compared our results to the period before\nthe pandemic (January 2019 - December 2019) to understand the shift in topics,\nsentiments, and stances across the two newspaper websites. A manual analysis of\nthe articles indicated that the language used in certain articles by The Times\nof India was transphobic and obsolete. Our study captures the visibility and\nrepresentation of the LGBTQ+ communities in Indian newspaper websites during\nthe pandemic.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15041v1", "cate": "cs.HC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14705", "title": "Configurable multi-agent framework for scalable and realistic testing of llm-based agents", "authors": ["Sai Wang", "Senthilnathan Subramanian", "Mudit Sahni", "Praneeth Gone", "Lingjie Meng", "Xiaochen Wang", "Nicolas Ferradas Bertoli", "Tingxian Cheng", "Jun Xu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14705v1", "summary": "Large-language-model (LLM) agents exhibit complex, context-sensitive\nbehaviour that quickly renders static benchmarks and ad-hoc manual testing\nobsolete.\n  We present Neo, a configurable, multi-agent framework that automates\nrealistic, multi-turn evaluation of LLM-based systems. Neo couples a Question\nGeneration Agent and an Evaluation Agent through a shared context-hub, allowing\ndomain prompts, scenario controls and dynamic feedback to be composed\nmodularly. Test inputs are sampled from a probabilistic state model spanning\ndialogue flow, user intent and emotional tone, enabling diverse, human-like\nconversations that adapt after every turn.\n  Applied to a production-grade Seller Financial Assistant chatbot, Neo (i)\nuncovered edge-case failures across five attack categories with a 3.3% break\nrate close to the 5.8% achieved by expert human red-teamers, and (ii) delivered\n10-12X higher throughput, generating 180 coherent test questions in around 45\nmins versus 16h of human effort. Beyond security probing, Neo's stochastic\npolicies balanced topic coverage and conversational depth, yielding broader\nbehavioural exploration than manually crafted scripts.\n  Neo therefore lays a foundation for scalable, self-evolving LLM QA: its agent\ninterfaces, state controller and feedback loops are model-agnostic and\nextensible to richer factual-grounding and policy-compliance checks. We release\nthe framework to facilitate reproducible, high-fidelity testing of emerging\nagentic systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14705v1", "cate": "cs.AI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14219", "title": "Artificial Intelligence for Green Hydrogen Yield Prediction and Site Suitability using SHAP-Based Composite Index: Focus on Oman", "authors": ["Obumneme Zimuzor Nwafor", "Mohammed Abdul Majeed Al Hooti"], "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14219v1", "summary": "As nations seek sustainable alternatives to fossil fuels, green hydrogen has\nemerged as a promising strategic pathway toward decarbonisation, particularly\nin solar-rich arid regions. However, identifying optimal locations for hydrogen\nproduction requires the integration of complex environmental, atmospheric, and\ninfrastructural factors, often compounded by limited availability of direct\nhydrogen yield data. This study presents a novel Artificial Intelligence (AI)\nframework for computing green hydrogen yield and site suitability index using\nmean absolute SHAP (SHapley Additive exPlanations) values. This framework\nconsists of a multi-stage pipeline of unsupervised multi-variable clustering,\nsupervised machine learning classifier and SHAP algorithm. The pipeline trains\non an integrated meteorological, topographic and temporal dataset and the\nresults revealed distinct spatial patterns of suitability and relative\ninfluence of the variables. With model predictive accuracy of 98%, the result\nalso showed that water proximity, elevation and seasonal variation are the most\ninfluential factors determining green hydrogen site suitability in Oman with\nmean absolute shap values of 2.470891, 2.376296 and 1.273216 respectively.\nGiven limited or absence of ground-truth yield data in many countries that have\ngreen hydrogen prospects and ambitions, this study offers an objective and\nreproducible alternative to subjective expert weightings, thus allowing the\ndata to speak for itself and potentially discover novel latent groupings\nwithout pre-imposed assumptions. This study offers industry stakeholders and\npolicymakers a replicable and scalable tool for green hydrogen infrastructure\nplanning and other decision making in data-scarce regions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14219v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.14481", "title": "DFQ-ViT: Data-Free Quantization for Vision Transformers without Fine-tuning", "authors": ["Yujia Tong", "Jingling Yuan", "Tian Zhang", "Jianquan Liu", "Chuang Hu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14481v1", "summary": "Data-Free Quantization (DFQ) enables the quantization of Vision Transformers\n(ViTs) without requiring access to data, allowing for the deployment of ViTs on\ndevices with limited resources. In DFQ, the quantization model must be\ncalibrated using synthetic samples, making the quality of these synthetic\nsamples crucial. Existing methods fail to fully capture and balance the global\nand local features within the samples, resulting in limited synthetic data\nquality. Moreover, we have found that during inference, there is a significant\ndifference in the distributions of intermediate layer activations between the\nquantized and full-precision models. These issues lead to a severe performance\ndegradation of the quantized model. To address these problems, we propose a\npipeline for Data-Free Quantization for Vision Transformers (DFQ-ViT).\nSpecifically, we synthesize samples in order of increasing difficulty,\neffectively enhancing the quality of synthetic data. During the calibration and\ninference stage, we introduce the activation correction matrix for the\nquantized model to align the intermediate layer activations with those of the\nfull-precision model. Extensive experiments demonstrate that DFQ-ViT achieves\nremarkable superiority over existing DFQ methods and its performance is on par\nwith models quantized through real data. For example, the performance of DeiT-T\nwith 3-bit weights quantization is 4.29% higher than the state-of-the-art. Our\nmethod eliminates the need for fine-tuning, which not only reduces\ncomputational overhead but also lowers the deployment barriers for edge\ndevices. This characteristic aligns with the principles of Green Learning by\nimproving energy efficiency and facilitating real-world applications in\nresource-constrained environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14481v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15600", "title": "Conflicting narratives and polarization on social media", "authors": ["Armin Pournaki"], "categories": ["cs.CL", "cs.SI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      30 pages, 7 figures", "url": "http://arxiv.org/abs/2507.15600v1", "summary": "Narratives are key interpretative devices by which humans make sense of\npolitical reality. In this work, we show how the analysis of conflicting\nnarratives, i.e. conflicting interpretive lenses through which political\nreality is experienced and told, provides insight into the discursive\nmechanisms of polarization and issue alignment in the public sphere. Building\nupon previous work that has identified ideologically polarized issues in the\nGerman Twittersphere between 2021 and 2023, we analyze the discursive dimension\nof polarization by extracting textual signals of conflicting narratives from\ntweets of opposing opinion groups. Focusing on a selection of salient issues\nand events (the war in Ukraine, Covid, climate change), we show evidence for\nconflicting narratives along two dimensions: (i) different attributions of\nactantial roles to the same set of actants (e.g. diverging interpretations of\nthe role of NATO in the war in Ukraine), and (ii) emplotment of different\nactants for the same event (e.g. Bill Gates in the right-leaning Covid\nnarrative). Furthermore, we provide first evidence for patterns of narrative\nalignment, a discursive strategy that political actors employ to align opinions\nacross issues. These findings demonstrate the use of narratives as an\nanalytical lens into the discursive mechanisms of polarization.", "comment": "30 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.15600v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14716", "title": "HistoryFinder: Advancing Method-Level Source Code History Generation with Accurate Oracles and Enhanced Algorithm", "authors": ["Shahidul Islam", "Ashik Aowal", "Md Sharif Uddin", "Shaiful Chowdhury"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14716v1", "summary": "Reconstructing a method's change history efficiently and accurately is\ncritical for many software engineering tasks, including maintenance,\nrefactoring, and comprehension. Despite the availability of method history\ngeneration tools such as CodeShovel and CodeTracker, existing evaluations of\ntheir effectiveness are limited by inaccuracies in the ground truth oracles\nused. In this study, we systematically construct two new oracles -- the\ncorrected CodeShovel oracle and a newly developed HistoryFinder oracle -- by\ncombining automated analysis with expert-guided manual validation. We also\nintroduce HistoryFinder, a new method history generation tool designed to\nimprove not only the accuracy and completeness of method change histories but\nalso to offer competitive runtime performance. Through extensive evaluation\nacross 400 methods from 40 open-source repositories, we show that HistoryFinder\nconsistently outperforms CodeShovel, CodeTracker, IntelliJ, and Git-based\nbaselines in terms of precision, recall, and F1 score. Moreover, HistoryFinder\nachieves competitive runtime performance, offering the lowest mean and median\nexecution times among all the research-based tools.\n  While Git-based tools exhibit the fastest runtimes, this efficiency comes at\nthe cost of significantly lower precision and recall -- leaving HistoryFinder\nas the best overall choice when both accuracy and efficiency are important. To\nfacilitate adoption, we provide a web interface, CLI, and Java library for\nflexible usage.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14716v1", "cate": "cs.SE", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14234", "title": "Feasibility of Energy Neutral Wildlife Tracking using Multi-Source Energy Harvesting", "authors": ["Samer Nasser", "Henrique Duarte Moura", "Dragan Subotic", "Ritesh Kumar Singh", "Maarten Weyn", "Jeroen Famaey"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14234v1", "summary": "Long-term wildlife tracking is crucial for biodiversity monitoring, but\nenergy limitations pose challenges, especially for animal tags, where replacing\nbatteries is impractical and stressful for the animal due to the need to\nlocate, possibly sedate, and handle it. Energy harvesting offers a sustainable\nalternative, yet most existing systems rely on a single energy source and\ninfrastructure-limited communication technologies. This paper presents an\nenergy-neutral system that combines solar and kinetic energy harvesting to\nenable the tracking and monitoring of wild animals. Harvesting from multiple\nsources increases the total available energy. Uniquely, the kinetic harvester\nalso serves as a motion proxy by sampling harvested current, enabling activity\nmonitoring without dedicated sensors. Our approach also ensures compatibility\nwith existing cellular infrastructure, using Narrowband Internet of Things\n(NB-IoT). We present a simulation framework that models energy harvesting,\nstorage, and consumption at the component level. An energy-aware scheduler\ncoordinates task execution based on real-time energy availability. We evaluate\nperformance under realistically varying conditions, comparing task frequencies\nand capacitor sizes. Results show that our approach maintains energy-neutral\noperation while significantly increasing data yield and reliability compared to\nsingle-source systems, with the ability to consistently sample GPS location\ndata and kinetic harvesting data every two minutes while transmitting these\nresults over NB-IoT every hour. These findings demonstrate the potential for\nmaintenance-free, environmentally friendly tracking in remote habitats,\nenabling more effective and scalable wildlife monitoring.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14234v1", "cate": "cs.NI", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14742", "title": "An Information-Theoretic Intersectional Data Valuation Theory", "authors": ["Eduardo C. Garrido-Merchán"], "categories": ["cs.IT", "math.IT", "stat.AP"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14742v1", "summary": "In contemporary digital markets, personal data often reveals not just\nisolated traits, but complex, intersectional identities based on combinations\nof race, gender, disability, and other protected characteristics. This exposure\ngenerates a privacy externality: firms benefit economically from profiling,\nprediction, and personalization, while users face hidden costs in the form of\nsocial risk and discrimination. We introduce a formal pricing rule that\nquantifies and internalizes this intersectional privacy loss using mutual\ninformation, assigning monetary value to the entropy reduction induced by each\ndatum. The result is a Pigouvian-style surcharge that discourages harmful data\ntrades and rewards transparency. Our formulation has the advantage that it\noperates independently of the underlying statistical model of the\nintersectional variables, be it parametric, nonparametric, or learned, and can\nbe approximated in practice by discretizing the intersectional joint\nprobability distributions. We illustrate how regulators can calibrate this\nsurcharge to reflect different societal values, and argue that it provides not\njust a technical fix to market failures, but also a redistributive shield that\nempowers vulnerable groups in the face of asymmetric digital power.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14742v1", "cate": "cs.IT", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14397", "title": "Efficient LLM Inference: Bandwidth, Compute, Synchronization, and Capacity are all you need", "authors": ["Michael Davies", "Neal Crago", "Karthikeyan Sankaralingam", "Christos Kozyrakis"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14397v1", "summary": "This paper presents a limit study of transformer-based large language model\n(LLM) inference, focusing on the fundamental performance bottlenecks imposed by\nmemory bandwidth, memory capacity, and synchronization overhead in distributed\ninference systems. We develop a hardware-agnostic performance model that\nabstracts away implementation details, enabling the analysis of a wide range of\ncurrent and near-future hardware technologies. Our analysis spans from current\nHBM3 memory technology used in AI accelerators like GPUs and TPUs to systems\nbased on advanced HBM4 and advanced 3D-stacked DRAM technology. It also covers\nSRAM-based designs and scaling techniques from distributed clusters with\nvarying numbers of chips to wafer-scale integration. Our key findings for\nauto-regressive decoding are: i) serving LLMs requires 100s of GB per server to\nserve a model instance; ii) high memory bandwidth is critical for high per-user\nthroughput; iii) exposed synchronization latencies to achieve collective\ncommunication must be around 1us else they make the memory bandwidth\nineffective; iv) DRAM-based designs have a fundamental advantage in terms of\nsystem-level efficiency as measured in throughput per cost or watt; and v)\nhardware designs can easily reach 2000+ user token/sec but getting to 10,000+\ntokens/sec will need smaller models, smaller context, or other forms of\nalgorithmic advances. This study provides valuable insights into the\nfundamental performance limits of LLM inference, highlighting the potential\nbenefits of future hardware advancements and guiding the optimization of LLM\ndeployment strategies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14397v1", "cate": "cs.AR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2401.04958", "title": "Gotta Detect 'Em All: Fake Base Station and Multi-Step Attack Detection in Cellular Networks", "authors": ["Kazi Samin Mubasshir", "Imtiaz Karim", "Elisa Bertino"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2401.04958v4", "summary": "Fake base stations (FBSes) pose a significant security threat by\nimpersonating legitimate base stations (BSes). Though efforts have been made to\ndefeat this threat, up to this day, the presence of FBSes and the multi-step\nattacks (MSAs) stemming from them can lead to unauthorized surveillance,\ninterception of sensitive information, and disruption of network services.\nTherefore, detecting these malicious entities is crucial to ensure the security\nand reliability of cellular networks. Traditional detection methods often rely\non additional hardware, rules, signal scanning, changing protocol\nspecifications, or cryptographic mechanisms that have limitations and incur\nhuge infrastructure costs. In this paper, we develop FBSDetector-an effective\nand efficient detection solution that can reliably detect FBSes and MSAs from\nlayer-3 network traces using machine learning (ML) at the user equipment (UE)\nside. To develop FBSDetector, we create FBSAD and MSAD, the first-ever\nhigh-quality and large-scale datasets incorporating instances of FBSes and 21\nMSAs. These datasets capture the network traces in different real-world\ncellular network scenarios (including mobility and different attacker\ncapabilities) incorporating legitimate BSes and FBSes. Our novel ML framework,\nspecifically designed to detect FBSes in a multi-level approach for packet\nclassification using stateful LSTM with attention and trace level\nclassification and MSAs using graph learning, can effectively detect FBSes with\nan accuracy of 96% and a false positive rate of 2.96%, and recognize MSAs with\nan accuracy of 86% and a false positive rate of 3.28%. We deploy FBSDetector as\na real-world solution to protect end-users through a mobile app and validate it\nin real-world environments. Compared to the existing heuristic-based solutions\nthat fail to detect FBSes, FBSDetector can detect FBSes in the wild in\nreal-time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2401.04958v4", "cate": "cs.CR", "date": "2024-01-10", "updated": "2025-07-21"}
{"id": "2507.15478", "title": "The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents", "authors": ["Simon Kohaut", "Felix Divo", "Navid Hamid", "Benedict Flade", "Julian Eggert", "Devendra Singh Dhami", "Kristian Kersting"], "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15478v1", "summary": "Ensuring reliable and rule-compliant behavior of autonomous agents in\nuncertain environments remains a fundamental challenge in modern robotics. Our\nwork shows how neuro-symbolic systems, which integrate probabilistic, symbolic\nwhite-box reasoning models with deep learning methods, offer a powerful\nsolution to this challenge. This enables the simultaneous consideration of\nexplicit rules and neural models trained on noisy data, combining the strength\nof structured reasoning with flexible representations. To this end, we\nintroduce the Constitutional Controller (CoCo), a novel framework designed to\nenhance the safety and reliability of agents by reasoning over deep\nprobabilistic logic programs representing constraints such as those found in\nshared traffic spaces. Furthermore, we propose the concept of self-doubt,\nimplemented as a probability density conditioned on doubt features such as\ntravel velocity, employed sensors, or health factors. In a real-world aerial\nmobility study, we demonstrate CoCo's advantages for intelligent autonomous\nsystems to learn appropriate doubts and navigate complex and uncertain\nenvironments safely and compliantly.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15478v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15049", "title": "Beyond Visual Line of Sight: UAVs with Edge AI, Connected LLMs, and VR for Autonomous Aerial Intelligence", "authors": ["Andres Navarro", "Carlos de Quinto", "José Alberto Hernández"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15049v1", "summary": "Unmanned Aerial Vehicles are reshaping Non-Terrestrial Networks by acting as\nagile, intelligent nodes capable of advanced analytics and instantaneous\nsituational awareness. This article introduces a budget-friendly quadcopter\nplatform that unites 5G communications, edge-based processing, and AI to tackle\ncore challenges in NTN scenarios. Outfitted with a panoramic camera, robust\nonboard computation, and LLMs, the drone system delivers seamless object\nrecognition, contextual analysis, and immersive operator experiences through\nvirtual reality VR technology. Field evaluations confirm the platform's ability\nto process visual streams with low latency and sustain robust 5G links. Adding\nLLMs further streamlines operations by extracting actionable insights and\nrefining collected data for decision support. Demonstrated use cases, including\nemergency response, infrastructure assessment, and environmental surveillance,\nunderscore the system's adaptability in demanding contexts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15049v1", "cate": "cs.HC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14719", "title": "Automated Safety Evaluations Across 20 Large Language Models: The Aymara LLM Risk and Responsibility Matrix", "authors": ["Juan Manuel Contreras"], "categories": ["cs.AI", "I.2.7; F.2.2"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14719v1", "summary": "As large language models (LLMs) become increasingly integrated into\nreal-world applications, scalable and rigorous safety evaluation is essential.\nThis paper introduces Aymara AI, a programmatic platform for generating and\nadministering customized, policy-grounded safety evaluations. Aymara AI\ntransforms natural-language safety policies into adversarial prompts and scores\nmodel responses using an AI-based rater validated against human judgments. We\ndemonstrate its capabilities through the Aymara LLM Risk and Responsibility\nMatrix, which evaluates 20 commercially available LLMs across 10 real-world\nsafety domains. Results reveal wide performance disparities, with mean safety\nscores ranging from 86.2% to 52.4%. While models performed well in\nwell-established safety domains such as Misinformation (mean = 95.7%), they\nconsistently failed in more complex or underspecified domains, notably Privacy\n& Impersonation (mean = 24.3%). Analyses of Variance confirmed that safety\nscores differed significantly across both models and domains (p < .05). These\nfindings underscore the inconsistent and context-dependent nature of LLM safety\nand highlight the need for scalable, customizable tools like Aymara AI to\nsupport responsible AI development and oversight.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14719v1", "cate": "cs.AI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14227", "title": "Domain Generalization via Pareto Optimal Gradient Matching", "authors": ["Khoi Do", "Duong Nguyen", "Nam-Khanh Le", "Quoc-Viet Pham", "Binh-Son Hua", "Won-Joo Hwang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14227v1", "summary": "In this study, we address the gradient-based domain generalization problem,\nwhere predictors aim for consistent gradient directions across different\ndomains. Existing methods have two main challenges. First, minimization of\ngradient empirical distance or gradient inner products (GIP) leads to gradient\nfluctuations among domains, thereby hindering straightforward learning. Second,\nthe direct application of gradient learning to the joint loss function can\nincur high computation overheads due to second-order derivative approximation.\nTo tackle these challenges, we propose a new Pareto Optimality Gradient\nMatching (POGM) method. In contrast to existing methods that add gradient\nmatching as regularization, we leverage gradient trajectories as collected data\nand apply independent training at the meta-learner. In the meta-update, we\nmaximize GIP while limiting the learned gradient from deviating too far from\nthe empirical risk minimization gradient trajectory. By doing so, the aggregate\ngradient can incorporate knowledge from all domains without suffering gradient\nfluctuation towards any particular domain. Experimental evaluations on datasets\nfrom DomainBed demonstrate competitive results yielded by POGM against other\nbaselines while achieving computational efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14227v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.14485", "title": "Benefit from Reference: Retrieval-Augmented Cross-modal Point Cloud Completion", "authors": ["Hongye Hou", "Liu Zhan", "Yang Yang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14485v1", "summary": "Completing the whole 3D structure based on an incomplete point cloud is a\nchallenging task, particularly when the residual point cloud lacks typical\nstructural characteristics. Recent methods based on cross-modal learning\nattempt to introduce instance images to aid the structure feature learning.\nHowever, they still focus on each particular input class, limiting their\ngeneration abilities. In this work, we propose a novel retrieval-augmented\npoint cloud completion framework. The core idea is to incorporate cross-modal\nretrieval into completion task to learn structural prior information from\nsimilar reference samples. Specifically, we design a Structural Shared Feature\nEncoder (SSFE) to jointly extract cross-modal features and reconstruct\nreference features as priors. Benefiting from a dual-channel control gate in\nthe encoder, relevant structural features in the reference sample are enhanced\nand irrelevant information interference is suppressed. In addition, we propose\na Progressive Retrieval-Augmented Generator (PRAG) that employs a hierarchical\nfeature fusion mechanism to integrate reference prior information with input\nfeatures from global to local. Through extensive evaluations on multiple\ndatasets and real-world scenes, our method shows its effectiveness in\ngenerating fine-grained point clouds, as well as its generalization capability\nin handling sparse data and unseen categories.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14485v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15823", "title": "Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work", "authors": ["Anton Abilov", "Ke Zhang", "Hemank Lamba", "Elizabeth M. Olson", "Joel R. Tetreault", "Alejandro Jaimes"], "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15823v1", "summary": "Publications in the AI for Good space have tended to focus on the research\nand model development that can support high-impact applications. However, very\nfew AI for Good papers discuss the process of deploying and collaborating with\nthe partner organization, and the resulting real-world impact. In this work, we\nshare details about the close collaboration with a humanitarian-to-humanitarian\n(H2H) organization and how to not only deploy the AI model in a\nresource-constrained environment, but also how to maintain it for continuous\nperformance updates, and share key takeaways for practitioners.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15823v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14735", "title": "Investigating the Role of LLMs Hyperparameter Tuning and Prompt Engineering to Support Domain Modeling", "authors": ["Vladyslav Bulhakov", "Giordano d'Aloisio", "Claudio Di Sipio", "Antinisca Di Marco", "Davide Di Ruscio"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted at 51st Euromicro Conference Series on Software Engineering and Advanced Applications (SEAA)", "url": "http://arxiv.org/abs/2507.14735v1", "summary": "The introduction of large language models (LLMs) has enhanced automation in\nsoftware engineering tasks, including in Model Driven Engineering (MDE).\nHowever, using general-purpose LLMs for domain modeling has its limitations.\nOne approach is to adopt fine-tuned models, but this requires significant\ncomputational resources and can lead to issues like catastrophic forgetting.\n  This paper explores how hyperparameter tuning and prompt engineering can\nimprove the accuracy of the Llama 3.1 model for generating domain models from\ntextual descriptions. We use search-based methods to tune hyperparameters for a\nspecific medical data model, resulting in a notable quality improvement over\nthe baseline LLM. We then test the optimized hyperparameters across ten diverse\napplication domains.\n  While the solutions were not universally applicable, we demonstrate that\ncombining hyperparameter tuning with prompt engineering can enhance results\nacross nearly all examined domain models.", "comment": "Accepted at 51st Euromicro Conference Series on Software Engineering\n  and Advanced Applications (SEAA)", "pdf_url": "http://arxiv.org/pdf/2507.14735v1", "cate": "cs.SE", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14398", "title": "NetIntent: Leveraging Large Language Models for End-to-End Intent-Based SDN Automation", "authors": ["Md. Kamrul Hossain", "Walid Aljoby"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14398v1", "summary": "Intent-Based Networking (IBN) often leverages the programmability of\nSoftware-Defined Networking (SDN) to simplify network management. However,\nsignificant challenges remain in automating the entire pipeline, from\nuser-specified high-level intents to device-specific low-level configurations.\nExisting solutions often rely on rigid, rule-based translators and fixed APIs,\nlimiting extensibility and adaptability. By contrast, recent advances in large\nlanguage models (LLMs) offer a promising pathway that leverages natural\nlanguage understanding and flexible reasoning. However, it is unclear to what\nextent LLMs can perform IBN tasks. To address this, we introduce IBNBench, a\nfirst-of-its-kind benchmarking suite comprising four novel datasets:\nIntent2Flow-ODL, Intent2Flow-ONOS, FlowConflict-ODL, and FlowConflict-ONOS.\nThese datasets are specifically designed for evaluating LLMs performance in\nintent translation and conflict detection tasks within the industry-grade SDN\ncontrollers ODL and ONOS. Our results provide the first comprehensive\ncomparison of 33 open-source LLMs on IBNBench and related datasets, revealing a\nwide range of performance outcomes. However, while these results demonstrate\nthe potential of LLMs for isolated IBN tasks, integrating LLMs into a fully\nautonomous IBN pipeline remains unexplored. Thus, our second contribution is\nNetIntent, a unified and adaptable framework that leverages LLMs to automate\nthe full IBN lifecycle, including translation, activation, and assurance within\nSDN systems. NetIntent orchestrates both LLM and non-LLM agents, supporting\ndynamic re-prompting and contextual feedback to robustly execute user-defined\nintents with minimal human intervention. Our implementation of NetIntent across\nboth ODL and ONOS SDN controllers achieves a consistent and adaptive end-to-end\nIBN realization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14398v1", "cate": "cs.NI", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14775", "title": "Enhancing Resilience Against Jamming Attacks: A Cooperative Anti-Jamming Method Using Direction Estimation", "authors": ["Amir Mehrabian", "Georges Kaddoum"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14775v1", "summary": "The inherent vulnerability of wireless communication necessitates strategies\nto enhance its security, particularly in the face of jamming attacks. This\npaper uses the collaborations of multiple sensing nodes (SNs) in the wireless\nnetwork to present a cooperative anti-jamming approach (CAJ) designed to\nneutralize the impact of jamming attacks. We propose an eigenvector (EV) method\nto estimate the direction of the channel vector from pilot symbols. Through our\nanalysis, we demonstrate that with an adequate number of pilot symbols, the\nperformance of the proposed EV method is comparable to the scenario where the\nperfect channel state information (CSI) is utilized. Both analytical formulas\nand simulations illustrate the excellent performance of the proposed EV-CAJ\nunder strong jamming signals. Considering severe jamming, the proposed EV-CAJ\nmethod exhibits only a 0.7 dB degradation compared to the case without jamming\nespecially when the number of SNs is significantly larger than the number of\njamming nodes (JNs). Moreover, the extension of the proposed method can handle\nmultiple jammers at the expense of degrees of freedom (DoF). We also\ninvestigate the method's ability to remain robust in fast-fading channels with\ndifferent coherence times. Our proposed approach demonstrates good resilience,\nparticularly when the ratio of the channel's coherence time to the time frame\nis small. This is especially important in the case of mobile jammers with large\nDoppler shifts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14775v1", "cate": "cs.IT", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14651", "title": "Enabling Efficient Hardware Acceleration of Hybrid Vision Transformer (ViT) Networks at the Edge", "authors": ["Joren Dumoulin", "Pouya Houshmand", "Vikram Jain", "Marian Verhelst"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14651v1", "summary": "Hybrid vision transformers combine the elements of conventional neural\nnetworks (NN) and vision transformers (ViT) to enable lightweight and accurate\ndetection. However, several challenges remain for their efficient deployment on\nresource-constrained edge devices. The hybrid models suffer from a widely\ndiverse set of NN layer types and large intermediate data tensors, hampering\nefficient hardware acceleration. To enable their execution at the edge, this\npaper proposes innovations across the hardware-scheduling stack: a.) At the\nlowest level, a configurable PE array supports all hybrid ViT layer types; b.)\ntemporal loop re-ordering within one layer, enabling hardware support for\nnormalization and softmax layers, minimizing on-chip data transfers; c.)\nfurther scheduling optimization employs layer fusion across inverted bottleneck\nlayers to drastically reduce off-chip memory transfers. The resulting\naccelerator is implemented in 28nm CMOS, achieving a peak energy efficiency of\n1.39 TOPS/W at 25.6 GMACs/s.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14651v1", "cate": "cs.AR", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2403.05030", "title": "Defending Against Unforeseen Failure Modes with Latent Adversarial Training", "authors": ["Stephen Casper", "Lennart Schulze", "Oam Patel", "Dylan Hadfield-Menell"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      See also followup work at arXiv:2407.15549", "url": "http://arxiv.org/abs/2403.05030v5", "summary": "Despite extensive diagnostics and debugging by developers, AI systems\nsometimes exhibit harmful unintended behaviors. Finding and fixing these is\nchallenging because the attack surface is so large -- it is not tractable to\nexhaustively search for inputs that may elicit harmful behaviors. Red-teaming\nand adversarial training (AT) are commonly used to improve robustness, however,\nthey empirically struggle to fix failure modes that differ from the attacks\nused during training. In this work, we utilize latent adversarial training\n(LAT) to defend against vulnerabilities without leveraging knowledge of what\nthey are or using inputs that elicit them. LAT makes use of the compressed,\nabstract, and structured latent representations of concepts that the network\nactually uses for prediction. Here, we use it to defend against failure modes\nwithout examples that elicit them. Specifically, we use LAT to remove backdoors\nand defend against held-out classes of adversarial attacks. We show in image\nclassification, text classification, and text generation tasks that LAT usually\nimproves both robustness to novel attacks and performance on clean data\nrelative to AT. This suggests that LAT can be a promising tool for defending\nagainst failure modes that are not explicitly identified by developers.", "comment": "See also followup work at arXiv:2407.15549", "pdf_url": "http://arxiv.org/pdf/2403.05030v5", "cate": "cs.CR", "date": "2024-03-08", "updated": "2025-07-18"}
{"id": "2507.15484", "title": "Robots for Kiwifruit Harvesting and Pollination", "authors": ["Jamie Bell"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15484v1", "summary": "This research was a part of a project that developed mobile robots that\nperformed targeted pollen spraying and automated harvesting in pergola\nstructured kiwifruit orchards. Multiple kiwifruit detachment mechanisms were\ndesigned and field testing of one of the concepts showed that the mechanism\ncould reliably pick kiwifruit. Furthermore, this kiwifruit detachment mechanism\nwas able to reach over 80 percent of fruit in the cluttered kiwifruit canopy,\nwhereas the previous state of the art mechanism was only able to reach less\nthan 70 percent of the fruit. Artificial pollination was performed by detecting\nflowers and then spraying pollen in solution onto the detected flowers from a\nline of sprayers on a boom, while driving at up to 1.4 ms-1. In addition, the\nheight of the canopy was measured and the spray boom was moved up and down to\nkeep the boom close enough to the flowers for the spray to reach the flowers,\nwhile minimising collisions with the canopy. Mobile robot navigation was\nperformed using a 2D lidar in apple orchards and vineyards. Lidar navigation in\nkiwifruit orchards was more challenging because the pergola structure only\nprovides a small amount of data for the direction of rows, compared to the\namount of data from the overhead canopy, the undulating ground and other\nobjects in the orchards. Multiple methods are presented here for extracting\nstructure defining features from 3D lidar data in kiwifruit orchards. In\naddition, a 3D lidar navigation system -- which performed row following, row\nend detection and row end turns -- was tested for over 30 km of autonomous\ndriving in kiwifruit orchards. Computer vision algorithms for row detection and\nrow following were also tested. The computer vision algorithm worked as well as\nthe 3D lidar row following method in testing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15484v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15072", "title": "NavVI: A Telerobotic Simulation with Multimodal Feedback for Visually Impaired Navigation in Warehouse Environments", "authors": ["Maisha Maimuna", "Minhaz Bin Farukee", "Sama Nikanfar", "Mahfuza Siddiqua", "Ayon Roy", "Fillia Makedon"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15072v1", "summary": "Industrial warehouses are congested with moving forklifts, shelves and\npersonnel, making robot teleoperation particularly risky and demanding for\nblind and low-vision (BLV) operators. Although accessible teleoperation plays a\nkey role in inclusive workforce participation, systematic research on its use\nin industrial environments is limited, and few existing studies barely address\nmultimodal guidance designed for BLV users. We present a novel multimodal\nguidance simulator that enables BLV users to control a mobile robot through a\nhigh-fidelity warehouse environment while simultaneously receiving synchronized\nvisual, auditory, and haptic feedback. The system combines a navigation mesh\nwith regular re-planning so routes remain accurate avoiding collisions as\nforklifts and human avatars move around the warehouse. Users with low vision\nare guided with a visible path line towards destination; navigational voice\ncues with clockwise directions announce upcoming turns, and finally\nproximity-based haptic feedback notifies the users of static and moving\nobstacles in the path. This real-time, closed-loop system offers a repeatable\ntestbed and algorithmic reference for accessible teleoperation research. The\nsimulator's design principles can be easily adapted to real robots due to the\nalignment of its navigation, speech, and haptic modules with commercial\nhardware, supporting rapid feasibility studies and deployment of inclusive\ntelerobotic tools in actual warehouses.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15072v1", "cate": "cs.HC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14730", "title": "Towards AI Urban Planner in the Age of GenAI, LLMs, and Agentic AI", "authors": ["Yanjie Fu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      4 pages; will continue to update to add more figures to describe the vision;", "url": "http://arxiv.org/abs/2507.14730v1", "summary": "Generative AI, large language models, and agentic AI have emerged separately\nof urban planning. However, the convergence between AI and urban planning\npresents an interesting opportunity towards AI urban planners. This paper\nconceptualizes urban planning as a generative AI task, where AI synthesizes\nland-use configurations under geospatial, social, and human-centric\nconstraints. We survey how generative AI approaches, including VAEs, GANs,\ntransformers, and diffusion models, reshape urban design. We further identify\ncritical gaps: 1) limited research on integrating urban theory guidance, 2)\nlimited research of AI urban planning over multiple spatial resolutions or\nangularities, 3) limited research on augmenting urban design knowledge from\ndata, and 4) limited research on addressing real-world interactions. To address\nthese limitations, we outline future research directions in theory-guided\ngeneration, digital twins, and human-machine co-design, calling for a new\nsynthesis of generative intelligence and participatory urbanism.", "comment": "4 pages; will continue to update to add more figures to describe the\n  vision;", "pdf_url": "http://arxiv.org/pdf/2507.14730v1", "cate": "cs.AI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14245", "title": "A million-scale dataset and generalizable foundation model for nanomaterial-protein interactions", "authors": ["Hengjie Yu", "Kenneth A. Dawson", "Haiyun Yang", "Shuya Liu", "Yan Yan", "Yaochu Jin"], "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "cs.CE", "q-bio.BM", "I.6.5; J.3; I.5.4"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      31 pages, 6 figures", "url": "http://arxiv.org/abs/2507.14245v1", "summary": "Unlocking the potential of nanomaterials in medicine and environmental\nscience hinges on understanding their interactions with proteins, a complex\ndecision space where AI is poised to make a transformative impact. However,\nprogress has been hindered by limited datasets and the restricted\ngeneralizability of existing models. Here, we propose NanoPro-3M, the largest\nnanomaterial-protein interaction dataset to date, comprising over 3.2 million\nsamples and 37,000 unique proteins. Leveraging this, we present NanoProFormer,\na foundational model that predicts nanomaterial-protein affinities through\nmultimodal representation learning, demonstrating strong generalization,\nhandling missing features, and unseen nanomaterials or proteins. We show that\nmultimodal modeling significantly outperforms single-modality approaches and\nidentifies key determinants of corona formation. Furthermore, we demonstrate\nits applicability to a range of downstream tasks through zero-shot inference\nand fine-tuning. Together, this work establishes a solid foundation for\nhigh-performance and generalized prediction of nanomaterial-protein interaction\nendpoints, reducing experimental reliance and accelerating various in vitro\napplications.", "comment": "31 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.14245v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14497", "title": "Efficient Whole Slide Pathology VQA via Token Compression", "authors": ["Weimin Lyu", "Qingqiao Hu", "Kehan Qi", "Zhan Shi", "Wentao Huang", "Saumya Gupta", "Chao Chen"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14497v1", "summary": "Whole-slide images (WSIs) in pathology can reach up to 10,000 x 10,000\npixels, posing significant challenges for multimodal large language model\n(MLLM) due to long context length and high computational demands. Previous\nmethods typically focus on patch-level analysis or slide-level classification\nusing CLIP-based models with multi-instance learning, but they lack the\ngenerative capabilities needed for visual question answering (VQA). More recent\nMLLM-based approaches address VQA by feeding thousands of patch tokens directly\ninto the language model, which leads to excessive resource consumption. To\naddress these limitations, we propose Token Compression Pathology LLaVA\n(TCP-LLaVA), the first MLLM architecture to perform WSI VQA via token\ncompression. TCP-LLaVA introduces a set of trainable compression tokens that\naggregate visual and textual information through a modality compression module,\ninspired by the [CLS] token mechanism in BERT. Only the compressed tokens are\nforwarded to the LLM for answer generation, significantly reducing input length\nand computational cost. Experiments on ten TCGA tumor subtypes show that\nTCP-LLaVA outperforms existing MLLM baselines in VQA accuracy while reducing\ntraining resource consumption by a substantial margin.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14497v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2502.04777", "title": "Community detection for directed networks revisited using bimodularity", "authors": ["Alexandre Cionca", "Chun Hei Michael Chan", "Dimitri Van De Ville"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      8 pages, 4 figures, 12 supplementary pages with 10 figures. Code and data are available at this https URL", "url": "http://arxiv.org/abs/2502.04777v2", "summary": "Community structure is a key feature omnipresent in real-world network data.\nPlethora of methods have been proposed to reveal subsets of densely\ninterconnected nodes using criteria such as the modularity index. These\napproaches have been successful for undirected graphs, but directed edge\ninformation has not yet been dealt with in a satisfactory way. Here, we revisit\nthe concept of directed communities as a mapping between sending and receiving\ncommunities. This translates into a new definition that we term bimodularity.\nUsing convex relaxation, bimodularity can be optimized with the singular value\ndecomposition of the directed modularity matrix. Subsequently, we propose an\nedge-based clustering approach to reveal the directed communities including\ntheir mappings. The feasibility of the new framework is illustrated on a\nsynthetic model and further applied to the neuronal wiring diagram of the\n\\textit{C. elegans}, for which it yields meaningful feedforward loops of the\nhead and body motion systems. This framework sets the ground for the\nunderstanding and detection of community structures in directed networks.", "comment": "8 pages, 4 figures, 12 supplementary pages with 10 figures. Code and\n  data are available at https://github.com/MIPLabCH/Bimodularity", "pdf_url": "http://arxiv.org/pdf/2502.04777v2", "cate": "cs.SI", "date": "2025-02-07", "updated": "2025-07-21"}
{"id": "2507.14770", "title": "Toward Inclusive AI-Driven Development: Exploring Gender Differences in Code Generation Tool Interactions", "authors": ["Manaal Basha", "Ivan Beschastnikh", "Gema Rodriguez-Perez", "Cleidson R. B. de Souza"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      ESEM 2025 Registered Reports", "url": "http://arxiv.org/abs/2507.14770v1", "summary": "Context: The increasing reliance on Code Generation Tools (CGTs), such as\nWindsurf and GitHub Copilot, are revamping programming workflows and raising\ncritical questions about fairness and inclusivity. While CGTs offer potential\nproductivity enhancements, their effectiveness across diverse user groups have\nnot been sufficiently investigated. Objectives: We hypothesize that developers'\ninteractions with CGTs vary based on gender, influencing task outcomes and\ncognitive load, as prior research suggests that gender differences can affect\ntechnology use and cognitive processing. Methods: The study will employ a\nmixed-subjects design with 54 participants, evenly divided by gender for a\ncounterbalanced design. Participants will complete two programming tasks\n(medium to hard difficulty) with only CGT assistance and then with only\ninternet access. Task orders and conditions will be counterbalanced to mitigate\norder effects. Data collection will include cognitive load surveys, screen\nrecordings, and task performance metrics such as completion time, code\ncorrectness, and CGT interaction behaviors. Statistical analyses will be\nconducted to identify statistically significant differences in CGT usage.\nExpected Contributions: Our work can uncover gender differences in CGT\ninteraction and performance among developers. Our findings can inform future\nCGT designs and help address usability and potential disparities in interaction\npatterns across diverse user groups. Conclusion: While results are not yet\navailable, our proposal lays the groundwork for advancing fairness,\naccountability, transparency, and ethics (FATE) in CGT design. The outcomes are\nanticipated to contribute to inclusive AI practices and equitable tool\ndevelopment for all users.", "comment": "ESEM 2025 Registered Reports", "pdf_url": "http://arxiv.org/pdf/2507.14770v1", "cate": "cs.SE", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14512", "title": "Dora: A Controller Provisioning Strategy in Hierarchical Domain-based Satellite Networks", "authors": ["Qiyuan Peng", "Qi Zhang", "Yue Gao", "Kun Qiu"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14512v1", "summary": "The rapid proliferation of satellite constellations in Space-Air-Ground\nIntegrated Networks (SAGIN) presents significant challenges for network\nmanagement. Conventional flat network architectures struggle with\nsynchronization and data transmission across massive distributed nodes. In\nresponse, hierarchical domain-based satellite network architectures have\nemerged as a scalable solution, highlighting the critical importance of\ncontroller provisioning strategies. However, existing network management\narchitectures and traditional search-based algorithms fail to generate\nefficient controller provisioning solutions due to limited computational\nresources in satellites and strict time constraints. To address these\nchallenges, we propose a three-layer domain-based architecture that enhances\nboth scalability and adaptability. Furthermore, we introduce Dora, a\nreinforcement learning-based controller provisioning strategy designed to\noptimize network performance while minimizing computational overhead. Our\ncomprehensive experimental evaluation demonstrates that Dora significantly\noutperforms state-of-the-art benchmarks, achieving 10% improvement in\ncontroller provisioning quality while requiring only 1/30 to 1/90 of the\ncomputation time compared to traditional algorithms. These results underscore\nthe potential of reinforcement learning approaches for efficient satellite\nnetwork management in next-generation SAGIN deployments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14512v1", "cate": "cs.NI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14794", "title": "Enhancing Communications and Sensing Simultaneously by Zero-Order Optimization of MTS", "authors": ["Wenhai Lai", "Kaiming Shen", "Zhi-Quan Luo"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      11 pages", "url": "http://arxiv.org/abs/2507.14794v1", "summary": "Metasurface (MTS) comprises an array of metaatoms, each reflecting and\ninducing a phase shift into the incident wireless signal. We seek the optimal\ncombination of phase shifts across all the meta-atoms to maximize the channel\nstrength from transmitter to receiver. Unlike many existing works that heavily\nrely on channel state information (CSI), this paper proposes a statistical\napproach to the phase shift optimization in the absence of CSI, namely blind\nconfiguration or zero-order optimization. The main idea is to extract the key\nfeatures of the wireless environment from the received signal strength (RSS)\ndata via conditional sample mean, with provable performance. Furthermore, as a\nwindfall profit, we show that the proposed blind configuration method has a\nnontrivial connection to phase retrieval which can be utilized for active\nsensing. In a nutshell, by configuring a pair of MTSs blindly without channel\nestimation, we not only enhance the channel strength to facilitate wireless\ncommunication, but also enable receiver to localize transmitter. All we need is\nthe RSS data that can be readily measured at receiver. Our algorithm is\nverified in prototype systems in the 2.6 GHz spectral band. As shown in field\ntests, the proposed algorithm outperforms the benchmarks (e.g., MUSIC) in the\nactive sensing task, and in the meanwhile raises the signal-to-noise ratio\n(SNR) significantly by about 10 dB.", "comment": "11 pages", "pdf_url": "http://arxiv.org/pdf/2507.14794v1", "cate": "cs.IT", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15300", "title": "GCC: A 3DGS Inference Architecture with Gaussian-Wise and Cross-Stage Conditional Processing", "authors": ["Minnan Pei", "Gang Li", "Junwen Si", "Zeyu Zhu", "Zitao Mo", "Peisong Wang", "Zhuoran Song", "Xiaoyao Liang", "Jian Cheng"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15300v1", "summary": "3D Gaussian Splatting (3DGS) has emerged as a leading neural rendering\ntechnique for high-fidelity view synthesis, prompting the development of\ndedicated 3DGS accelerators for mobile applications. Through in-depth analysis,\nwe identify two major limitations in the conventional decoupled\npreprocessing-rendering dataflow adopted by existing accelerators: 1) a\nsignificant portion of preprocessed Gaussians are not used in rendering, and 2)\nthe same Gaussian gets repeatedly loaded across different tile renderings,\nresulting in substantial computational and data movement overhead. To address\nthese issues, we propose GCC, a novel accelerator designed for fast and\nenergy-efficient 3DGS inference. At the dataflow level, GCC introduces: 1)\ncross-stage conditional processing, which interleaves preprocessing and\nrendering to dynamically skip unnecessary Gaussian preprocessing; and 2)\nGaussian-wise rendering, ensuring that all rendering operations for a given\nGaussian are completed before moving to the next, thereby eliminating\nduplicated Gaussian loading. We also propose an alpha-based boundary\nidentification method to derive compact and accurate Gaussian regions, thereby\nreducing rendering costs. We implement our GCC accelerator in 28nm technology.\nExtensive experiments demonstrate that GCC significantly outperforms the\nstate-of-the-art 3DGS inference accelerator, GSCore, in both performance and\nenergy efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15300v1", "cate": "cs.AR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2405.06830", "title": "Towards Browser Controls to Protect Cookies from Malicious Extensions", "authors": ["Liam Tyler", "Ivan De Oliveira Nunes"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.06830v3", "summary": "Cookies maintain state across related web traffic. As such, cookies are\ncommonly used for authentication by storing a user's session ID and replacing\nthe need to re-enter credentials in subsequent traffic. These so-called\n``session cookies'' are prime targets for attacks that aim to steal them to\ngain unauthorized access to user accounts. To mitigate these attacks, the\nSecure and HttpOnly cookie attributes limit a cookie's accessibility from\nmalicious networks and websites. However, these controls overlook browser\nextensions: third-party HTML/JavaScript add-ons with access to privileged\nbrowser APIs and the ability to operate across multiple websites. Thus\nmalicious or compromised extensions can provide unrestricted access to a user's\nsession cookies.\n  In this work, we first analyze the prevalence of extensions with access to\n``risky'' APIs (those that enable cookie modification and theft) and find that\nthey have hundreds of millions of users. Motivated by this, we propose a\nmechanism to protect cookies from malicious extensions by introducing two new\ncookie attributes: BrowserOnly and Monitored. The BrowserOnly attribute\nprevents extension access to cookies altogether. While effective, not all\ncookies can be made inaccessible. Thus cookies with the Monitored attribute\nremain accessible but are tied to a single browser and any changes made to the\ncookie are logged. As a result, stolen Monitored cookies are unusable outside\ntheir original browser and servers can validate the modifications performed. To\ndemonstrate the proposed functionalities, we design and implement CREAM (Cookie\nRestrictions for Extension Abuse Mitigation) a modified version of the\nopen-source Chromium browser realizing these controls. Our evaluation indicates\nthat CREAM effectively protects cookies from malicious extensions while\nincurring little run-time overheads.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.06830v3", "cate": "cs.CR", "date": "2024-05-10", "updated": "2025-07-21"}
{"id": "2507.15493", "title": "GR-3 Technical Report", "authors": ["Chilam Cheang", "Sijin Chen", "Zhongren Cui", "Yingdong Hu", "Liqun Huang", "Tao Kong", "Hang Li", "Yifeng Li", "Yuxiao Liu", "Xiao Ma", "Hao Niu", "Wenxuan Ou", "Wanli Peng", "Zeyu Ren", "Haixin Shi", "Jiawen Tian", "Hongtao Wu", "Xin Xiao", "Yuyang Xiao", "Jiafeng Xu", "Yichu Yang"], "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Tech report. Authors are listed in alphabetical order. Project page: this https URL", "url": "http://arxiv.org/abs/2507.15493v1", "summary": "We report our recent progress towards building generalist robot policies, the\ndevelopment of GR-3. GR-3 is a large-scale vision-language-action (VLA) model.\nIt showcases exceptional capabilities in generalizing to novel objects,\nenvironments, and instructions involving abstract concepts. Furthermore, it can\nbe efficiently fine-tuned with minimal human trajectory data, enabling rapid\nand cost-effective adaptation to new settings. GR-3 also excels in handling\nlong-horizon and dexterous tasks, including those requiring bi-manual\nmanipulation and mobile movement, showcasing robust and reliable performance.\nThese capabilities are achieved through a multi-faceted training recipe that\nincludes co-training with web-scale vision-language data, efficient fine-tuning\nfrom human trajectory data collected via VR devices, and effective imitation\nlearning with robot trajectory data. In addition, we introduce ByteMini, a\nversatile bi-manual mobile robot designed with exceptional flexibility and\nreliability, capable of accomplishing a wide range of tasks when integrated\nwith GR-3. Through extensive real-world experiments, we show GR-3 surpasses the\nstate-of-the-art baseline method, $\\pi_0$, on a wide variety of challenging\ntasks. We hope GR-3 can serve as a step towards building generalist robots\ncapable of assisting humans in daily life.", "comment": "Tech report. Authors are listed in alphabetical order. Project page:\n  https://seed.bytedance.com/GR3/", "pdf_url": "http://arxiv.org/pdf/2507.15493v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15081", "title": "\"If I were in Space\": Understanding and Adapting to Social Isolation through Designing Collaborative Narratives", "authors": ["Qi Gong", "Ximing Shen", "Ziyou Yin", "Yaning Li", "Ray Lc"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15081v1", "summary": "Social isolation can lead to pervasive health issues like anxiety and\nloneliness. Previous work focused on physical interventions like exercise and\nteleconferencing, but overlooked the narrative potential of adaptive\nstrategies. To address this, we designed a collaborative online storytelling\nexperience in social VR, enabling participants in isolation to design an\nimaginary space journey as a metaphor for quarantine, in order to learn about\ntheir isolation adaptation strategies in the process. Eighteen individuals\nparticipated during real quarantine undertaken a virtual role-play experience,\ndesigning their own spaceship rooms and engaging in collaborative activities\nthat revealed creative adaptative strategies. Qualitative analyses of\nparticipant designs, transcripts, and interactions revealed how they coped with\nisolation, and how the engagement unexpectedly influenced their adaptation\nprocess. This study shows how designing playful narrative experiences, rather\nthan solution-driven approaches, can serve as probes to surface how people\nnavigate social isolation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15081v1", "cate": "cs.HC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14897", "title": "AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents", "authors": ["Renxi Wang", "Rifo Ahmad Genadi", "Bilal El Bouardi", "Yongxin Wang", "Fajri Koto", "Zhengzhong Liu", "Timothy Baldwin", "Haonan Li"], "categories": ["cs.AI", "I.2.5"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14897v1", "summary": "Language model (LM) agents have gained significant attention for their\nability to autonomously complete tasks through interactions with environments,\ntools, and APIs. LM agents are primarily built with prompt engineering or\nsupervised finetuning. At the same time, reinforcement learning (RL) has been\nexplored to enhance LM's capabilities, such as reasoning and factuality.\nHowever, the combination of the LM agents and reinforcement learning (Agent-RL)\nremains underexplored and lacks systematic study. To this end, we built\nAgentFly, a scalable and extensible Agent-RL framework designed to empower LM\nagents with a variety of RL algorithms. Our framework supports multi-turn\ninteractions by adapting traditional RL methods with token-level masking. It\nfeatures a decorator-based interface for defining tools and reward functions,\nenabling seamless extension and ease of use. To support high-throughput\ntraining, we implement asynchronous execution of tool calls and reward\ncomputations, and design a centralized resource management system for scalable\nenvironment coordination. We also provide a suite of prebuilt tools and\nenvironments, demonstrating the framework's effectiveness through successful\nagent training across multiple tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14897v1", "cate": "cs.AI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14257", "title": "Linearized Diffusion Map", "authors": ["Julio Candanedo"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14257v1", "summary": "We introduce the Linearized Diffusion Map (LDM), a novel linear\ndimensionality reduction method constructed via a linear approximation of the\ndiffusion-map kernel. LDM integrates the geometric intuition of diffusion-based\nnonlinear methods with the computational simplicity, efficiency, and\ninterpretability inherent in linear embeddings such as PCA and classical MDS.\nThrough comprehensive experiments on synthetic datasets (Swiss roll and\nhyperspheres) and real-world benchmarks (MNIST and COIL-20), we illustrate that\nLDM captures distinct geometric features of datasets compared to PCA, offering\ncomplementary advantages. Specifically, LDM embeddings outperform PCA in\ndatasets exhibiting explicit manifold structures, particularly in\nhigh-dimensional regimes, whereas PCA remains preferable in scenarios dominated\nby variance or noise. Furthermore, the complete positivity of LDM's kernel\nmatrix allows direct applicability of Non-negative Matrix Factorization (NMF),\nsuggesting opportunities for interpretable latent-structure discovery. Our\nanalysis positions LDM as a valuable new linear dimensionality reduction\ntechnique with promising theoretical and practical extensions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14257v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14500", "title": "Motion Segmentation and Egomotion Estimation from Event-Based Normal Flow", "authors": ["Zhiyuan Hua", "Dehao Yuan", "Cornelia Fermüller"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14500v1", "summary": "This paper introduces a robust framework for motion segmentation and\negomotion estimation using event-based normal flow, tailored specifically for\nneuromorphic vision sensors. In contrast to traditional methods that rely\nheavily on optical flow or explicit depth estimation, our approach exploits the\nsparse, high-temporal-resolution event data and incorporates geometric\nconstraints between normal flow, scene structure, and inertial measurements.\nThe proposed optimization-based pipeline iteratively performs event\nover-segmentation, isolates independently moving objects via residual analysis,\nand refines segmentations using hierarchical clustering informed by motion\nsimilarity and temporal consistency. Experimental results on the EVIMO2v2\ndataset validate that our method achieves accurate segmentation and\ntranslational motion estimation without requiring full optical flow\ncomputation. This approach demonstrates significant advantages at object\nboundaries and offers considerable potential for scalable, real-time robotic\nand navigation applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14500v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2505.07212", "title": "The Language of Influence: Sentiment, Emotion, and Hate Speech in State Sponsored Influence Operations", "authors": ["Ashfaq Ali Shafin", "Khandaker Mamun Ahmed"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      6 pages, 1 figure, 4 tables. PErvasive Technologies Related to Assistive Environments (PETRA 2025),", "url": "http://arxiv.org/abs/2505.07212v3", "summary": "State-sponsored influence operations (SIOs) have become a pervasive and\ncomplex challenge in the digital age, particularly on social media platforms\nwhere information spreads rapidly and with minimal oversight. These operations\nare strategically employed by nation-state actors to manipulate public opinion,\nexacerbate social divisions, and project geopolitical narratives, often through\nthe dissemination of misleading or inflammatory content. Despite increasing\nawareness of their existence, the specific linguistic and emotional strategies\nemployed by these campaigns remain underexplored. This study addresses this gap\nby conducting a comprehensive analysis of sentiment, emotional valence, and\nabusive language across 2 million tweets attributed to influence operations\nlinked to China, Iran, and Russia, using Twitter's publicly released dataset of\nstate-affiliated accounts. We identify distinct affective and rhetorical\npatterns that characterize each nation's digital propaganda. Russian campaigns\npredominantly deploy negative sentiment and toxic language to intensify\npolarization and destabilize discourse. In contrast, Iranian operations blend\nantagonistic and supportive tones to simultaneously incite conflict and foster\nideological alignment. Chinese activities emphasize positive sentiment and\nemotionally neutral rhetoric to promote favorable narratives and subtly\ninfluence global perceptions. These findings reveal how state actors tailor\ntheir information warfare tactics to achieve specific geopolitical objectives\nthrough differentiated content strategies.", "comment": "6 pages, 1 figure, 4 tables. PErvasive Technologies Related to\n  Assistive Environments (PETRA 2025),", "pdf_url": "http://arxiv.org/pdf/2505.07212v3", "cate": "cs.SI", "date": "2025-05-12", "updated": "2025-07-18"}
{"id": "2507.14776", "title": "VeriOpt: PPA-Aware High-Quality Verilog Generation via Multi-Role LLMs", "authors": ["Kimia Tasnia", "Alexander Garcia", "Tasnuva Farheen", "Sazadur Rahman"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      9 pages, 7 figures, Accepted for ICCAD 2025, Munich, Germany", "url": "http://arxiv.org/abs/2507.14776v1", "summary": "The rapid adoption of large language models(LLMs) in hardware design has\nprimarily focused on generating functionally correct Verilog code, overlooking\ncritical Power Performance-Area(PPA) metrics essential for industrial-grade\ndesigns. To bridge this gap, we propose VeriOpt, a novel framework that\nleverages role-based prompting and PPA-aware optimization to enable LLMs to\nproduce high-quality, synthesizable Verilog. VeriOpt structures LLM\ninteractions into specialized roles (e.g., Planner, Programmer, Reviewer,\nEvaluator) to emulate human design workflows, while integrating PPA constraints\ndirectly into the prompting pipeline. By combining multi-modal feedback (e.g.,\nsynthesis reports, timing diagrams) with PPA aware prompting, VeriOpt achieves\nPPA-efficient code generation without sacrificing functional correctness.\nExperimental results demonstrate up to 88% reduction in power, 76% reduction in\narea and 73% improvement in timing closure compared to baseline LLM-generated\nRTL, validated using industry standard EDA tools. At the same time achieves 86%\nsuccess rate in functionality evaluation. Our work advances the\nstate-of-the-art AI-driven hardware design by addressing the critical gap\nbetween correctness and quality, paving the way for reliable LLM adoption in\nproduction workflows.", "comment": "9 pages, 7 figures, Accepted for ICCAD 2025, Munich, Germany", "pdf_url": "http://arxiv.org/pdf/2507.14776v1", "cate": "cs.SE", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14627", "title": "UAV-Enabled Wireless-Powered Underground Communication Networks: A Novel Time Allocation Approach", "authors": ["Kaiqiang Lin", "Yijie Mao", "Onel Luis Alcaraz López", "Mohamed-Slim Alouini"], "categories": ["cs.NI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      14 pages, 8 figures, 3 tables, submitted to IEEE TGCN", "url": "http://arxiv.org/abs/2507.14627v1", "summary": "Wireless-powered underground communication networks (WPUCNs), which allow\nunderground devices (UDs) to harvest energy from wireless signals for\nbattery-free communication, offer a promising solution for sustainable\nunderground monitoring. However, the severe wireless signal attenuation in\nchallenging underground environments and the costly acquisition of channel\nstate information (CSI) make large-scale WPUCNs economically infeasible in\npractice. To address this challenge, we introduce flexible unmanned aerial\nvehicles (UAVs) into WPUCNs, leading to UAV-enabled WPUCN systems. In this\nsystem, a UAV is first charged by a terrestrial hybrid access point (HAP), then\nflies to the monitoring area to wirelessly charge UDs. Afterwards, the UAV\ncollects data from the UDs and finally returns to the HAP for data offloading.\nBased on the proposed UAV-enabled WPUCN system, we first propose its energy\nconsumption model and a hybrid wireless energy transfer (WET) approach (i.e.,\nUDs can harvest energy from both the HAP and the UAV) relying on full-CSI and\nCSI-free multi-antenna beamforming. Then, we formulate and address a time\nallocation problem to minimize the energy consumption of UAV, while ensuring\nthat the throughput requirements of all UDs are met and all sensor data is\noffloaded. Through simulations of a realistic farming scenario, we demonstrate\nthat the proposed hybrid WET approach outperforms other WET approaches, with\nperformance gains influenced by the number of antennas, communication distance,\nnumber of UDs, and underground conditions. Additionally, under the optimized\ntime allocation, we found that the proposed hybrid WET approach based on a\nCSI-free multi-antenna scheme achieves the lowest UAV's energy consumption\namong all WET mechanisms, thereby enabling sustainable underground monitoring\nin WPUCNs.", "comment": "14 pages, 8 figures, 3 tables, submitted to IEEE TGCN", "pdf_url": "http://arxiv.org/pdf/2507.14627v1", "cate": "cs.NI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14795", "title": "A DPI-PAC-Bayesian Framework for Generalization Bounds", "authors": ["Muhan Guan", "Farhad Farokhi", "Jingge Zhu"], "categories": ["cs.IT", "math.IT", "stat.ML"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      7 pages, 1 figures", "url": "http://arxiv.org/abs/2507.14795v1", "summary": "We develop a unified Data Processing Inequality PAC-Bayesian framework --\nabbreviated DPI-PAC-Bayesian -- for deriving generalization error bounds in the\nsupervised learning setting. By embedding the Data Processing Inequality (DPI)\ninto the change-of-measure technique, we obtain explicit bounds on the binary\nKullback-Leibler generalization gap for both R\\'enyi divergence and any\n$f$-divergence measured between a data-independent prior distribution and an\nalgorithm-dependent posterior distribution. We present three bounds derived\nunder our framework using R\\'enyi, Hellinger \\(p\\) and Chi-Squared divergences.\nAdditionally, our framework also demonstrates a close connection with other\nwell-known bounds. When the prior distribution is chosen to be uniform, our\nbounds recover the classical Occam's Razor bound and, crucially, eliminate the\nextraneous \\(\\log(2\\sqrt{n})/n\\) slack present in the PAC-Bayes bound, thereby\nachieving tighter results. The framework thus bridges data-processing and\nPAC-Bayesian perspectives, providing a flexible, information-theoretic tool to\nconstruct generalization guarantees.", "comment": "7 pages, 1 figures", "pdf_url": "http://arxiv.org/pdf/2507.14795v1", "cate": "cs.IT", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15465", "title": "The New LLM Bottleneck: A Systems Perspective on Latent Attention and Mixture-of-Experts", "authors": ["Sungmin Yun", "Seonyong Park", "Hwayong Nam", "Younjoo Lee", "Gunjun Lee", "Kwanhee Kyung", "Sangpyo Kim", "Nam Sung Kim", "Jongmin Kim", "Hyungyo Kim", "Juhwan Cho", "Seungmin Baek", "Jung Ho Ahn"], "categories": ["cs.AR", "cs.AI"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      15 pages, 11 figures", "url": "http://arxiv.org/abs/2507.15465v1", "summary": "Computational workloads composing traditional Transformer models are starkly\nbifurcated. Multi-Head Attention (MHA) is memory-bound, with low arithmetic\nintensity, while feedforward layers are compute-bound. This dichotomy has long\nmotivated research into specialized hardware to mitigate the MHA bottleneck.\n  This paper argues that recent architectural shifts, namely Multi-head Latent\nAttention (MLA) and Mixture-of-Experts (MoE), challenge the premise of\nspecialized attention hardware. We make two key observations. First, the\narithmetic intensity of MLA is over two orders of magnitude greater than that\nof MHA, shifting it close to a compute-bound regime well-suited for modern\naccelerators like GPUs. Second, by distributing MoE experts across a pool of\naccelerators, their arithmetic intensity can be tuned through batching to match\nthat of the dense layers, creating a more balanced computational profile.\n  These findings reveal a diminishing need for specialized attention hardware.\nThe central challenge for next-generation Transformers is no longer\naccelerating a single memory-bound layer. Instead, the focus must shift to\ndesigning balanced systems with sufficient compute, memory capacity, memory\nbandwidth, and high-bandwidth interconnects to manage the diverse demands of\nlarge-scale models.", "comment": "15 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.15465v1", "cate": "cs.AR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2407.15492", "title": "Fast computation of 2-isogenies in dimension 4 and cryptographic applications", "authors": ["Pierrick Dartois"], "categories": ["cs.CR", "math.AG", "14K02, 14Q15, 11T71"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.15492v2", "summary": "Dimension 4 isogenies have first been introduced in cryptography for the\ncryptanalysis of Supersingular Isogeny Diffie-Hellman (SIDH) and have been used\nconstructively in several schemes, including SQIsignHD, a derivative of SQIsign\nisogeny based signature scheme. Unlike in dimensions 2 and 3, we can no longer\nrely on the Jacobian model and its derivatives to compute isogenies. In\ndimension 4 (and higher), we can only use theta-models. Previous works by\nRomain Cosset, David Lubicz and Damien Robert have focused on the computation\nof $\\ell$-isogenies in theta-models of level $n$ coprime to $\\ell$ (which\nrequires to use $n^g$ coordinates in dimension $g$). For cryptographic\napplications, we need to compute chains of $2$-isogenies, requiring to use\n$\\geq 3^g$ coordinates in dimension $g$ with state of the art algorithms.\n  In this paper, we present algorithms to compute chains of $2$-isogenies\nbetween abelian varieties of dimension $g\\geq 1$ with theta-coordinates of\nlevel $n=2$, generalizing a previous work by Pierrick Dartois, Luciano Maino,\nGiacomo Pope and Damien Robert in dimension $g=2$. We propose an implementation\nof these algorithms in dimension $g=4$ to compute endomorphisms of elliptic\ncurve products derived from Kani's lemma with applications to SQIsignHD and\nSIDH cryptanalysis. We are now able to run a complete key recovery attack on\nSIDH when the endomorphism ring of the starting curve is unknown within a few\nseconds on a laptop for all NIST SIKE parameters.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.15492v2", "cate": "cs.CR", "date": "2024-07-22", "updated": "2025-07-21"}
{"id": "2507.15499", "title": "CLEVER: Stream-based Active Learning for Robust Semantic Perception from Human Instructions", "authors": ["Jongseok Lee", "Timo Birr", "Rudolph Triebel", "Tamim Asfour"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages. Accepted to IEEE RAL", "url": "http://arxiv.org/abs/2507.15499v1", "summary": "We propose CLEVER, an active learning system for robust semantic perception\nwith Deep Neural Networks (DNNs). For data arriving in streams, our system\nseeks human support when encountering failures and adapts DNNs online based on\nhuman instructions. In this way, CLEVER can eventually accomplish the given\nsemantic perception tasks. Our main contribution is the design of a system that\nmeets several desiderata of realizing the aforementioned capabilities. The key\nenabler herein is our Bayesian formulation that encodes domain knowledge\nthrough priors. Empirically, we not only motivate CLEVER's design but further\ndemonstrate its capabilities with a user validation study as well as\nexperiments on humanoid and deformable objects. To our knowledge, we are the\nfirst to realize stream-based active learning on a real robot, providing\nevidence that the robustness of the DNN-based semantic perception can be\nimproved in practice. The project website can be accessed at\nhttps://sites.google.com/view/thecleversystem.", "comment": "8 pages. Accepted to IEEE RAL", "pdf_url": "http://arxiv.org/pdf/2507.15499v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15202", "title": "TalkLess: Blending Extractive and Abstractive Speech Summarization for Editing Speech to Preserve Content and Style", "authors": ["Karim Benharrak", "Puyuan Peng", "Amy Pavel"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15202v1", "summary": "Millions of people listen to podcasts, audio stories, and lectures, but\nediting speech remains tedious and time-consuming. Creators remove unnecessary\nwords, cut tangential discussions, and even re-record speech to make recordings\nconcise and engaging. Prior work automatically summarized speech by removing\nfull sentences (extraction), but rigid extraction limits expressivity. AI tools\ncan summarize then re-synthesize speech (abstraction), but abstraction strips\nthe speaker's style. We present TalkLess, a system that flexibly combines\nextraction and abstraction to condense speech while preserving its content and\nstyle. To edit speech, TalkLess first generates possible transcript edits,\nselects edits to maximize compression, coverage, and audio quality, then uses a\nspeech editing model to translate transcript edits into audio edits. TalkLess's\ninterface provides creators control over automated edits by separating\nlow-level wording edits (via the compression pane) from major content edits\n(via the outline pane). TalkLess achieves higher coverage and removes more\nspeech errors than a state-of-the-art extractive approach. A comparison study\n(N=12) showed that TalkLess significantly decreased cognitive load and editing\neffort in speech editing. We further demonstrate TalkLess's potential in an\nexploratory study (N=3) where creators edited their own speech.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15202v1", "cate": "cs.HC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14899", "title": "InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis", "authors": ["Jiale Liu", "Huan Wang", "Yue Zhang", "Xiaoyu Luo", "Jiaxiang Hu", "Zhiliang Liu", "Min Xie"], "categories": ["cs.AI", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14899v1", "summary": "Non-destructive testing (NDT), particularly X-ray inspection, is vital for\nindustrial quality assurance, yet existing deep-learning-based approaches often\nlack interactivity, interpretability, and the capacity for critical\nself-assessment, limiting their reliability and operator trust. To address\nthese shortcomings, this paper proposes InsightX Agent, a novel LMM-based\nagentic framework designed to deliver reliable, interpretable, and interactive\nX-ray NDT analysis. Unlike typical sequential pipelines, InsightX Agent\npositions a Large Multimodal Model (LMM) as a central orchestrator,\ncoordinating between the Sparse Deformable Multi-Scale Detector (SDMSD) and the\nEvidence-Grounded Reflection (EGR) tool. The SDMSD generates dense defect\nregion proposals for multi-scale feature maps and sparsifies them through\nNon-Maximum Suppression (NMS), optimizing detection of small, dense targets in\nX-ray images while maintaining computational efficiency. The EGR tool guides\nthe LMM agent through a chain-of-thought-inspired review process, incorporating\ncontext assessment, individual defect analysis, false positive elimination,\nconfidence recalibration and quality assurance to validate and refine the\nSDMSD's initial proposals. By strategically employing and intelligently using\ntools, InsightX Agent moves beyond passive data processing to active reasoning,\nenhancing diagnostic reliability and providing interpretations that integrate\ndiverse information sources. Experimental evaluations on the GDXray+ dataset\ndemonstrate that InsightX Agent not only achieves a high object detection\nF1-score of 96.35% but also offers significantly improved interpretability and\ntrustworthiness in its analyses, highlighting the transformative potential of\nagentic LLM frameworks for industrial inspection tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14899v1", "cate": "cs.AI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14295", "title": "A Simple \"Try Again\" Can Elicit Multi-Turn LLM Reasoning", "authors": ["Licheng Liu", "Zihan Wang", "Linjie Li", "Chenwei Xu", "Yiping Lu", "Han Liu", "Avirup Sil", "Manling Li"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14295v1", "summary": "Multi-turn problem solving is critical yet challenging for Large Reasoning\nModels (LRMs) to reflect on their reasoning and revise from feedback. Existing\nReinforcement Learning (RL) methods train large reasoning models on a\nsingle-turn paradigm with verifiable rewards. However, we observe that models\ntrained with existing RL paradigms often lose their ability to solve problems\nacross multiple turns and struggle to revise answers based on contextual\nfeedback, leading to repetitive responses. We ask: can LRMs learn to reflect\ntheir answers in a multi-turn context? In this work, we find that training\nmodels with multi-turn RL using only unary feedback (e.g., \"Let's try again\")\nafter wrong answers can improve both single-turn performance and multi-turn\nreasoning. We introduce Unary Feedback as Observation (UFO) for reinforcement\nlearning, which uses minimal yet common unary user feedback during iterative\nproblem solving. It can be easily applied to existing single-turn RL training\nsetups. Experimental results show that RL training with UFO keeps single-turn\nperformance and improves multi-turn reasoning accuracy by up to 14%, enabling\nlanguage models to better react to feedback in multi-turn problem solving. To\nfurther minimize the number of turns needed for a correct answer while\nencouraging diverse reasoning when mistakes occur, we design reward structures\nthat guide models to produce careful and deliberate answers in each turn. Code:\nhttps://github.com/lichengliu03/unary-feedback", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14295v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14501", "title": "Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey", "authors": ["Jiahui Zhang", "Yuelei Li", "Anpei Chen", "Muyu Xu", "Kunhao Liu", "Jianyuan Wang", "Xiao-Xiao Long", "Hanxue Liang", "Zexiang Xu", "Hao Su", "Christian Theobalt", "Christian Rupprecht", "Andrea Vedaldi", "Hanspeter Pfister", "Shijian Lu", "Fangneng Zhan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      A project page associated with this survey is available at this https URL", "url": "http://arxiv.org/abs/2507.14501v1", "summary": "3D reconstruction and view synthesis are foundational problems in computer\nvision, graphics, and immersive technologies such as augmented reality (AR),\nvirtual reality (VR), and digital twins. Traditional methods rely on\ncomputationally intensive iterative optimization in a complex chain, limiting\ntheir applicability in real-world scenarios. Recent advances in feed-forward\napproaches, driven by deep learning, have revolutionized this field by enabling\nfast and generalizable 3D reconstruction and view synthesis. This survey offers\na comprehensive review of feed-forward techniques for 3D reconstruction and\nview synthesis, with a taxonomy according to the underlying representation\narchitectures including point cloud, 3D Gaussian Splatting (3DGS), Neural\nRadiance Fields (NeRF), etc. We examine key tasks such as pose-free\nreconstruction, dynamic 3D reconstruction, and 3D-aware image and video\nsynthesis, highlighting their applications in digital humans, SLAM, robotics,\nand beyond. In addition, we review commonly used datasets with detailed\nstatistics, along with evaluation protocols for various downstream tasks. We\nconclude by discussing open research challenges and promising directions for\nfuture work, emphasizing the potential of feed-forward approaches to advance\nthe state of the art in 3D vision.", "comment": "A project page associated with this survey is available at\n  https://fnzhan.com/projects/Feed-Forward-3D", "pdf_url": "http://arxiv.org/pdf/2507.14501v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14791", "title": "Enhancing Repository-Level Code Generation with Call Chain-Aware Multi-View Context", "authors": ["Yang Liu", "Li Zhang", "Fang Liu", "Zhuohang Wang", "Donglin Wei", "Zhishuo Yang", "Kechi Zhang", "Jia Li", "Lin Shi"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14791v1", "summary": "Repository-level code generation aims to generate code within the context of\na specified repository. Existing approaches typically employ\nretrieval-augmented generation (RAG) techniques to provide LLMs with relevant\ncontextual information extracted from the repository. However, these approaches\noften struggle with effectively identifying truly relevant contexts that\ncapture the rich semantics of the repository, and their contextual perspectives\nremains narrow. Moreover, most approaches fail to account for the structural\nrelationships in the retrieved code during prompt construction, hindering the\nLLM's ability to accurately interpret the context. To address these issues, we\npropose RepoScope, which leverages call chain-aware multi-view context for\nrepository-level code generation. RepoScope constructs a Repository Structural\nSemantic Graph (RSSG) and retrieves a comprehensive four-view context,\nintegrating both structural and similarity-based contexts. We propose a novel\ncall chain prediction method that utilizes the repository's structural\nsemantics to improve the identification of callees in the target function.\nAdditionally, we present a structure-preserving serialization algorithm for\nprompt construction, ensuring the coherence of the context for the LLM.\nNotably, RepoScope relies solely on static analysis, eliminating the need for\nadditional training or multiple LLM queries, thus ensuring both efficiency and\ngeneralizability. Evaluation on widely-used repository-level code generation\nbenchmarks (CoderEval and DevEval) demonstrates that RepoScope outperforms\nstate-of-the-art methods, achieving up to a 36.35% relative improvement in\npass@1 scores. Further experiments emphasize RepoScope's potential to improve\ncode generation across different tasks and its ability to integrate effectively\nwith existing approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14791v1", "cate": "cs.SE", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14633", "title": "Agentic Satellite-Augmented Low-Altitude Economy and Terrestrial Networks: A Survey on Generative Approaches", "authors": ["Xiaozheng Gao", "Yichen Wang", "Bosen Liu", "Xiao Zhou", "Ruichen Zhang", "Jiacheng Wang", "Dusit Niyato", "Dong In Kim", "Abbas Jamalipour", "Chau Yuen", "Jianping An", "Kai Yang"], "categories": ["cs.NI", "cs.LG"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14633v1", "summary": "The development of satellite-augmented low-altitude economy and terrestrial\nnetworks (SLAETNs) demands intelligent and autonomous systems that can operate\nreliably across heterogeneous, dynamic, and mission-critical environments. To\naddress these challenges, this survey focuses on enabling agentic artificial\nintelligence (AI), that is, artificial agents capable of perceiving, reasoning,\nand acting, through generative AI (GAI) and large language models (LLMs). We\nbegin by introducing the architecture and characteristics of SLAETNs, and\nanalyzing the challenges that arise in integrating satellite, aerial, and\nterrestrial components. Then, we present a model-driven foundation by\nsystematically reviewing five major categories of generative models:\nvariational autoencoders (VAEs), generative adversarial networks (GANs),\ngenerative diffusion models (GDMs), transformer-based models (TBMs), and LLMs.\nMoreover, we provide a comparative analysis to highlight their generative\nmechanisms, capabilities, and deployment trade-offs within SLAETNs. Building on\nthis foundation, we examine how these models empower agentic functions across\nthree domains: communication enhancement, security and privacy protection, and\nintelligent satellite tasks. Finally, we outline key future directions for\nbuilding scalable, adaptive, and trustworthy generative agents in SLAETNs. This\nsurvey aims to provide a unified understanding and actionable reference for\nadvancing agentic AI in next-generation integrated networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14633v1", "cate": "cs.NI", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14825", "title": "Rate-Distortion-Perception Trade-off with Strong Realism Constraints: Role of Side Information and Common Randomness", "authors": ["Yassine Hamdi", "Aaron B. Wagner", "Deniz Gündüz"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14825v1", "summary": "In image compression, with recent advances in generative modeling, existence\nof a trade-off between the rate and perceptual quality has been brought to\nlight, where the perceptual quality is measured by the closeness of the output\nand source distributions. We consider the compression of a memoryless source\nsequence $X^n=(X_1, \\ldots, X_n)$ in the presence of memoryless side\ninformation $Z^n=(Z_1, \\ldots, Z_n),$ originally studied by Wyner and Ziv, but\nelucidate the impact of a strong perfect realism constraint, which requires the\njoint distribution of output symbols $Y^n=(Y_1,...,Y_n)$ to match the\ndistribution of the source sequence. We consider two cases: when $Z^n$ is\navailable only at the decoder, or at both the encoder and decoder, and\ncharacterize the information theoretic limits under various scenarios. Previous\nworks show the superiority of randomized codes under strong perceptual quality\nconstraints. When $Z^n$ is available at both terminals, we characterize its\ndual role, as a source of common randomness, and as a second look on the source\nfor the receiver. We also study different notions of strong perfect realism\nwhich we call marginal realism, joint realism and near-perfect realism. We\nderive explicit solutions when $X$ and $Z$ are jointly Gaussian under the\nsquared error distortion measure. In traditional lossy compression, having $Z$\nonly at the decoder imposes no rate penalty in the Gaussian scenario. We show\nthat, when strong perfect realism constraints are imposed this holds only when\nsufficient common randomness is available.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14825v1", "cate": "cs.IT", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15603", "title": "When Pipelined In-Memory Accelerators Meet Spiking Direct Feedback Alignment: A Co-Design for Neuromorphic Edge Computing", "authors": ["Haoxiong Ren", "Yangu He", "Kwunhang Wong", "Rui Bao", "Ning Lin", "Zhongrui Wang", "Dashan Shang"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      International Conference on Computer-Aided Design 2025", "url": "http://arxiv.org/abs/2507.15603v1", "summary": "Spiking Neural Networks (SNNs) are increasingly favored for deployment on\nresource-constrained edge devices due to their energy-efficient and\nevent-driven processing capabilities. However, training SNNs remains\nchallenging because of the computational intensity of traditional\nbackpropagation algorithms adapted for spike-based systems. In this paper, we\npropose a novel software-hardware co-design that introduces a hardware-friendly\ntraining algorithm, Spiking Direct Feedback Alignment (SDFA) and implement it\non a Resistive Random Access Memory (RRAM)-based In-Memory Computing (IMC)\narchitecture, referred to as PipeSDFA, to accelerate SNN training.\nSoftware-wise, the computational complexity of SNN training is reduced by the\nSDFA through the elimination of sequential error propagation. Hardware-wise, a\nthree-level pipelined dataflow is designed based on IMC architecture to\nparallelize the training process. Experimental results demonstrate that the\nPipeSDFA training accelerator incurs less than 2% accuracy loss on five\ndatasets compared to baselines, while achieving 1.1X~10.5X and 1.37X~2.1X\nreductions in training time and energy consumption, respectively compared to\nPipeLayer.", "comment": "International Conference on Computer-Aided Design 2025", "pdf_url": "http://arxiv.org/pdf/2507.15603v1", "cate": "cs.AR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2409.19334", "title": "OnePath: Efficient and Privacy-Preserving Decision Tree Inference in the Cloud", "authors": ["Shuai Yuan", "Hongwei Li", "Xinyuan Qian", "Guowen Xu"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.19334v2", "summary": "The vast storage capacity and computational power of cloud servers have led\nto the widespread outsourcing of machine learning inference services. While\noffering significant operational benefits, this practice also introduces\nprivacy risks, such as the exposure of proprietary models and sensitive user\ndata. In this paper, we present OnePath, a framework for secure and efficient\ndecision tree inference in cloud environments. Unlike existing methods that\ntraverse all internal nodes of a decision tree, our traversal protocol\nprocesses only the nodes on the prediction path, significantly improving\ninference efficiency while preserving privacy. To further optimize privacy and\nperformance, OnePath is the first to employ functional encryption for\nevaluating decision tree nodes. Notably, our protocol enables both model\nproviders and users to remain offline during the inference phase, offering a\ncrucial advantage for practical deployment. We provide formal security analysis\nto demonstrate that OnePath provides comprehensive privacy protections during\nthe model inference process. Extensive experimental results show that our\napproach processes query data in microseconds, highlighting its efficiency.\nOnePath offers a practical solution that strikes a balance between security and\nperformance, making it a promising option for a wide range of cloud-based\ndecision tree inference applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.19334v2", "cate": "cs.CR", "date": "2024-09-28", "updated": "2025-07-21"}
{"id": "2507.15604", "title": "Estimation of Payload Inertial Parameters from Human Demonstrations by Hand Guiding", "authors": ["Johannes Hartwig", "Philipp Lienhardt", "Dominik Henrich"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted for publication in Annals of Scientific Society for Assembly, Handling and Industrial Robotics 2025 (to appear)", "url": "http://arxiv.org/abs/2507.15604v1", "summary": "As the availability of cobots increases, it is essential to address the needs\nof users with little to no programming knowledge to operate such systems\nefficiently. Programming concepts often use intuitive interaction modalities,\nsuch as hand guiding, to address this. When programming in-contact motions,\nsuch frameworks require knowledge of the robot tool's payload inertial\nparameters (PIP) in addition to the demonstrated velocities and forces to\nensure effective hybrid motion-force control. This paper aims to enable\nnon-expert users to program in-contact motions more efficiently by eliminating\nthe need for a dedicated PIP calibration, thereby enabling flexible robot tool\nchanges. Since demonstrated tasks generally also contain motions with\nnon-contact, our approach uses these parts to estimate the robot's PIP using\nestablished estimation techniques. The results show that the estimation of the\npayload's mass is accurate, whereas the center of mass and the inertia tensor\nare affected by noise and a lack of excitation. Overall, these findings show\nthe feasibility of PIP estimation during hand guiding but also highlight the\nneed for sufficient payload accelerations for an accurate estimation.", "comment": "Accepted for publication in Annals of Scientific Society for\n  Assembly, Handling and Industrial Robotics 2025 (to appear)", "pdf_url": "http://arxiv.org/pdf/2507.15604v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15244", "title": "How Does Empirical Research Facilitate Creation Tool Design? A Data Video Perspective", "authors": ["Leixian Shen", "Leni Yang", "Haotian Li", "Yun Wang", "Yuyu Luo", "Huamin Qu"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15244v1", "summary": "Empirical research in creative design deepens our theoretical understanding\nof design principles and perceptual effects, offering valuable guidance for\ninnovating creation tools. However, how these empirical insights currently\ninfluence the development of creation tools, and how their integration can be\nenhanced in the future, remains insufficiently understood. In this paper, we\naim to unveil the gap through a case study on data videos, a prominent and\nwide-spread medium for effective data storytelling. To achieve the goal, we\nconducted a comprehensive analysis of 46 empirical research papers and 48\ncreation tool papers on data video, complemented by interviews with 11 experts.\nBuilding upon a systematic collection and structured characterization of\nempirical research by their methodologies (e.g., corpus analysis, comparative\nevaluations) and component focus (e.g., visuals, motions, narratives, audio),\nwe conducted a context-aware citation analysis and revealed a taxonomy of\nrecurring patterns in how empirical findings inform tool design across citation\nfunctions (e.g., problem framing, technical reference). Expert interviews\nfurther uncovered researchers' practice patterns in applying empirical findings\n(e.g., adaptation, synthesis, iteration, etc.) and identified key factors\ninfluencing applicability, such as contextual relevance, granularity matching,\nclarity, credibility, and feasibility. Finally, we derive suggestions and\ndiscuss future opportunities to foster closer mutual engagement between\nempirical and tool research, aiming to reinforce the theoretical grounding of\ncreation tools and enhance the practical impact of empirical research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15244v1", "cate": "cs.HC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14906", "title": "Feedback-Induced Performance Decline in LLM-Based Decision-Making", "authors": ["Xiao Yang", "Juxi Leitner", "Michael Burke"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14906v1", "summary": "The ability of Large Language Models (LLMs) to extract context from natural\nlanguage problem descriptions naturally raises questions about their\nsuitability in autonomous decision-making settings. This paper studies the\nbehaviour of these models within a Markov Decision Process (MDPs). While\ntraditional reinforcement learning (RL) strategies commonly employed in this\nsetting rely on iterative exploration, LLMs, pre-trained on diverse datasets,\noffer the capability to leverage prior knowledge for faster adaptation. We\ninvestigate online structured prompting strategies in sequential decision\nmaking tasks, comparing the zero-shot performance of LLM-based approaches to\nthat of classical RL methods. Our findings reveal that although LLMs\ndemonstrate improved initial performance in simpler environments, they struggle\nwith planning and reasoning in complex scenarios without fine-tuning or\nadditional guidance. Our results show that feedback mechanisms, intended to\nimprove decision-making, often introduce confusion, leading to diminished\nperformance in intricate environments. These insights underscore the need for\nfurther exploration into hybrid strategies, fine-tuning, and advanced memory\nintegration to enhance LLM-based decision-making capabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14906v1", "cate": "cs.AI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14326", "title": "Rethinking Individual Fairness in Deepfake Detection", "authors": ["Aryana Hou", "Li Lin", "Justin Li", "Shu Hu"], "categories": ["cs.LG", "cs.CY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This paper has been accepted by ACM MM 2025", "url": "http://arxiv.org/abs/2507.14326v1", "summary": "Generative AI models have substantially improved the realism of synthetic\nmedia, yet their misuse through sophisticated DeepFakes poses significant\nrisks. Despite recent advances in deepfake detection, fairness remains\ninadequately addressed, enabling deepfake markers to exploit biases against\nspecific populations. While previous studies have emphasized group-level\nfairness, individual fairness (i.e., ensuring similar predictions for similar\nindividuals) remains largely unexplored. In this work, we identify for the\nfirst time that the original principle of individual fairness fundamentally\nfails in the context of deepfake detection, revealing a critical gap previously\nunexplored in the literature. To mitigate it, we propose the first\ngeneralizable framework that can be integrated into existing deepfake detectors\nto enhance individual fairness and generalization. Extensive experiments\nconducted on leading deepfake datasets demonstrate that our approach\nsignificantly improves individual fairness while maintaining robust detection\nperformance, outperforming state-of-the-art methods. The code is available at\nhttps://github.com/Purdue-M2/Individual-Fairness-Deepfake-Detection.", "comment": "This paper has been accepted by ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2507.14326v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14505", "title": "DCHM: Depth-Consistent Human Modeling for Multiview Detection", "authors": ["Jiahao Ma", "Tianyu Wang", "Miaomiao Liu", "David Ahmedt-Aristizabal", "Chuong Nguyen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      multi-view detection, sparse-view reconstruction", "url": "http://arxiv.org/abs/2507.14505v1", "summary": "Multiview pedestrian detection typically involves two stages: human modeling\nand pedestrian localization. Human modeling represents pedestrians in 3D space\nby fusing multiview information, making its quality crucial for detection\naccuracy. However, existing methods often introduce noise and have low\nprecision. While some approaches reduce noise by fitting on costly multiview 3D\nannotations, they often struggle to generalize across diverse scenes. To\neliminate reliance on human-labeled annotations and accurately model humans, we\npropose Depth-Consistent Human Modeling (DCHM), a framework designed for\nconsistent depth estimation and multiview fusion in global coordinates.\nSpecifically, our proposed pipeline with superpixel-wise Gaussian Splatting\nachieves multiview depth consistency in sparse-view, large-scaled, and crowded\nscenarios, producing precise point clouds for pedestrian localization.\nExtensive validations demonstrate that our method significantly reduces noise\nduring human modeling, outperforming previous state-of-the-art baselines.\nAdditionally, to our knowledge, DCHM is the first to reconstruct pedestrians\nand perform multiview segmentation in such a challenging setting. Code is\navailable on the \\href{https://jiahao-ma.github.io/DCHM/}{project page}.", "comment": "multi-view detection, sparse-view reconstruction", "pdf_url": "http://arxiv.org/pdf/2507.14505v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14969", "title": "Think Like an Engineer: A Neuro-Symbolic Collaboration Agent for Generative Software Requirements Elicitation and Self-Review", "authors": ["Sai Zhang", "Zhenchang Xing", "Jieshan Chen", "Dehai Zhao", "Zizhong Zhu", "Xiaowang Zhang", "Zhiyong Feng", "Xiaohong Li"], "categories": ["cs.SE", "D.2.1"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14969v1", "summary": "The vision of End-User Software Engineering (EUSE) is to empower\nnon-professional users with full control over the software development\nlifecycle. It aims to enable users to drive generative software development\nusing only natural language requirements. However, since end-users often lack\nknowledge of software engineering, their requirement descriptions are\nfrequently ambiguous, raising significant challenges to generative software\ndevelopment. Although existing approaches utilize structured languages like\nGherkin to clarify user narratives, they still struggle to express the causal\nlogic between preconditions and behavior actions. This paper introduces\nRequireCEG, a requirement elicitation and self-review agent that embeds\ncausal-effect graphs (CEGs) in a neuro-symbolic collaboration architecture.\nRequireCEG first uses a feature tree to analyze user narratives hierarchically,\nclearly defining the scope of software components and their system behavior\nrequirements. Next, it constructs the self-healing CEGs based on the elicited\nrequirements, capturing the causal relationships between atomic preconditions\nand behavioral actions. Finally, the constructed CEGs are used to review and\noptimize Gherkin scenarios, ensuring consistency between the generated Gherkin\nrequirements and the system behavior requirements elicited from user\nnarratives. To evaluate our method, we created the RGPair benchmark dataset and\nconducted extensive experiments. It achieves an 87% coverage rate and raises\ndiversity by 51.88%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14969v1", "cate": "cs.SE", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14842", "title": "Data-Plane Telemetry to Mitigate Long-Distance BGP Hijacks", "authors": ["Satadal Sengupta", "Hyojoon Kim", "Daniel Jubas", "Maria Apostolaki", "Jennifer Rexford"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14842v1", "summary": "Poor security of Internet routing enables adversaries to divert user data\nthrough unintended infrastructures (hijack). Of particular concern -- and the\nfocus of this paper -- are cases where attackers reroute domestic traffic\nthrough foreign countries, exposing it to surveillance, bypassing legal privacy\nprotections, and posing national security threats. Efforts to detect and\nmitigate such attacks have focused primarily on the control plane while\ndata-plane signals remain largely overlooked. In particular, change in\npropagation delay caused by rerouting offers a promising signal: the change is\nunavoidable and the increased propagation delay is directly observable from the\naffected networks. In this paper, we explore the practicality of using delay\nvariations for hijack detection, addressing two key questions: (1) What\ncoverage can this provide, given its heavy dependence on the geolocations of\nthe sender, receiver, and adversary? and (2) Can an always-on latency-based\ndetection system be deployed without disrupting normal network operations? We\nobserve that for 86% of victim-attacker country pairs in the world, mid-attack\ndelays exceed pre-attack delays by at least 25% in real deployments, making\ndelay-based hijack detection promising. To demonstrate practicality, we design\nHiDe, which reliably detects delay surges from long-distance hijacks at line\nrate. We measure HiDe's accuracy and false-positive rate on real-world data and\nvalidate it with ethically conducted hijacks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14842v1", "cate": "cs.NI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14852", "title": "Variable Min-Cut Max-Flow Bounds and Algorithms in Finite Regime", "authors": ["Rivka Gitik", "Alejandro Cohen"], "categories": ["cs.IT", "cs.CG", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      8 pages, 3 figures", "url": "http://arxiv.org/abs/2507.14852v1", "summary": "The maximum achievable capacity from source to destination in a network is\nlimited by the min-cut max-flow bound; this serves as a converse limit. In\npractice, link capacities often fluctuate due to dynamic network conditions. In\nthis work, we introduce a novel analytical framework that leverages tools from\ncomputational geometry to analyze throughput in heterogeneous networks with\nvariable link capacities in a finite regime. Within this model, we derive new\nperformance bounds and demonstrate that increasing the number of links can\nreduce throughput variability by nearly $90\\%$. We formally define a notion of\nnetwork stability and show that an unstable graph can have an exponential\nnumber of different min-cut sets, up to $O(2^{|E|})$. To address this\ncomplexity, we propose an algorithm that enforces stability with time\ncomplexity $O(|E|^2 + |V|)$, and further suggest mitigating the\ndelay-throughput tradeoff using adaptive rateless random linear network coding\n(AR-RLNC).", "comment": "8 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.14852v1", "cate": "cs.IT", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15664", "title": "VeriRAG: A Retrieval-Augmented Framework for Automated RTL Testability Repair", "authors": ["Haomin Qi", "Yuyang Du", "Lihao Zhang", "Soung Chang Liew", "Kexin Chen", "Yining Du"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      8 pages, 5 figures", "url": "http://arxiv.org/abs/2507.15664v1", "summary": "Large language models (LLMs) have demonstrated immense potential in\ncomputer-aided design (CAD), particularly for automated debugging and\nverification within electronic design automation (EDA) tools. However, Design\nfor Testability (DFT) remains a relatively underexplored area. This paper\npresents VeriRAG, the first LLM-assisted DFT-EDA framework. VeriRAG leverages a\nRetrieval-Augmented Generation (RAG) approach to enable LLM to revise code to\nensure DFT compliance. VeriRAG integrates (1) an autoencoder-based similarity\nmeasurement model for precise retrieval of reference RTL designs for the LLM,\nand (2) an iterative code revision pipeline that allows the LLM to ensure DFT\ncompliance while maintaining synthesizability. To support VeriRAG, we introduce\nVeriDFT, a Verilog-based DFT dataset curated for DFT-aware RTL repairs. VeriRAG\nretrieves structurally similar RTL designs from VeriDFT, each paired with a\nrigorously validated correction, as references for code repair. With VeriRAG\nand VeriDFT, we achieve fully automated DFT correction -- resulting in a\n7.72-fold improvement in successful repair rate compared to the zero-shot\nbaseline (Fig. 5 in Section V). Ablation studies further confirm the\ncontribution of each component of the VeriRAG framework. We open-source our\ndata, models, and scripts at https://github.com/yuyangdu01/LLM4DFT.", "comment": "8 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.15664v1", "cate": "cs.AR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2411.11017", "title": "A Study of Malware Prevention in Linux Distributions", "authors": ["Duc-Ly Vu", "Trevor Dunlap", "Karla Obermeier-Velazquez", "Thanh-Cong Nguyen", "Paul Gibert", "John Speed Meyers", "Santiago Torres-Arias"], "categories": ["cs.CR", "cs.SE"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      14 pages, 3 figures, 11 tables", "url": "http://arxiv.org/abs/2411.11017v3", "summary": "Malicious attacks on open-source software packages are a growing concern. The\ndiscovery of the XZ Utils backdoor intensified these concerns because of the\npotential widespread impact. This study, therefore, explores the challenges of\npreventing and detecting malware in Linux distribution package repositories. To\ndo so, we ask two research questions: (1) What measures have Linux\ndistributions implemented to counter malware, and how have maintainers\nexperienced these efforts? (2) How effective are current malware detection\ntools in identifying malicious Linux packages? To answer these questions, we\nconduct interviews with maintainers at several major Linux distributions and\nintroduce a Linux package malware benchmark dataset. Using this dataset, we\nevaluate the performance of six open-source malware detection scanners.\nDistribution maintainers, according to the interviews, have mostly focused on\nreproducible builds to date. Our interviews identified only a single Linux\ndistribution, Wolfi OS, that performs active malware scanning. Using this new\nbenchmark dataset, the evaluation found that the performance of existing\nopen-source malware scanners is underwhelming. Most studied tools excel at\nproducing false positives but only infrequently detect true malware. Those that\navoid high false positive rates often do so at the expense of a satisfactory\ntrue positive. Our findings provide insights into Linux distribution package\nrepositories' current practices for malware detection and demonstrate the\ncurrent inadequacy of open-source tools designed to detect malicious Linux\npackages.", "comment": "14 pages, 3 figures, 11 tables", "pdf_url": "http://arxiv.org/pdf/2411.11017v3", "cate": "cs.CR", "date": "2024-11-17", "updated": "2025-07-21"}
{"id": "2507.15607", "title": "A Universal Vehicle-Trailer Navigation System with Neural Kinematics and Online Residual Learning", "authors": ["Yanbo Chen", "Yunzhe Tan", "Yaojia Wang", "Zhengzhe Xu", "Junbo Tan", "Xueqian Wang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 10 figures", "url": "http://arxiv.org/abs/2507.15607v1", "summary": "Autonomous navigation of vehicle-trailer systems is crucial in environments\nlike airports, supermarkets, and concert venues, where various types of\ntrailers are needed to navigate with different payloads and conditions.\nHowever, accurately modeling such systems remains challenging, especially for\ntrailers with castor wheels. In this work, we propose a novel universal\nvehicle-trailer navigation system that integrates a hybrid nominal kinematic\nmodel--combining classical nonholonomic constraints for vehicles and neural\nnetwork-based trailer kinematics--with a lightweight online residual learning\nmodule to correct real-time modeling discrepancies and disturbances.\nAdditionally, we develop a model predictive control framework with a weighted\nmodel combination strategy that improves long-horizon prediction accuracy and\nensures safer motion planning. Our approach is validated through extensive\nreal-world experiments involving multiple trailer types and varying payload\nconditions, demonstrating robust performance without manual tuning or\ntrailer-specific calibration.", "comment": "8 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.15607v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15355", "title": "Efficient Visual Appearance Optimization by Learning from Prior Preferences", "authors": ["Zhipeng Li", "Yi-Chi Liao", "Christian Holz"], "categories": ["cs.HC", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      24 pages, UIST'25", "url": "http://arxiv.org/abs/2507.15355v1", "summary": "Adjusting visual parameters such as brightness and contrast is common in our\neveryday experiences. Finding the optimal parameter setting is challenging due\nto the large search space and the lack of an explicit objective function,\nleaving users to rely solely on their implicit preferences. Prior work has\nexplored Preferential Bayesian Optimization (PBO) to address this challenge,\ninvolving users to iteratively select preferred designs from candidate sets.\nHowever, PBO often requires many rounds of preference comparisons, making it\nmore suitable for designers than everyday end-users. We propose Meta-PO, a\nnovel method that integrates PBO with meta-learning to improve sample\nefficiency. Specifically, Meta-PO infers prior users' preferences and stores\nthem as models, which are leveraged to intelligently suggest design candidates\nfor the new users, enabling faster convergence and more personalized results.\nAn experimental evaluation of our method for appearance design tasks on 2D and\n3D content showed that participants achieved satisfactory appearance in 5.86\niterations using Meta-PO when participants shared similar goals with a\npopulation (e.g., tuning for a ``warm'' look) and in 8 iterations even\ngeneralizes across divergent goals (e.g., from ``vintage'', ``warm'', to\n``holiday''). Meta-PO makes personalized visual optimization more applicable to\nend-users through a generalizable, more efficient optimization conditioned on\npreferences, with the potential to scale interface personalization more\nbroadly.", "comment": "24 pages, UIST'25", "pdf_url": "http://arxiv.org/pdf/2507.15355v1", "cate": "cs.HC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14909", "title": "The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities", "authors": ["Elio Grande"], "categories": ["cs.AI", "cs.HC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14909v1", "summary": "The Endless Tuning is a design method for a reliable deployment of artificial\nintelligence based on a double mirroring process, which pursues both the goals\nof avoiding human replacement and filling the so-called responsibility gap\n(Matthias 2004). Originally depicted in (Fabris et al. 2024) and ensuing the\nrelational approach urged therein, it was then actualized in a protocol,\nimplemented in three prototypical applications regarding decision-making\nprocesses (respectively: loan granting, pneumonia diagnosis, and art style\nrecognition) and tested with such as many domain experts. Step by step\nillustrating the protocol, giving insights concretely showing a different voice\n(Gilligan 1993) in the ethics of artificial intelligence, a philosophical\naccount of technical choices (e.g., a reversed and hermeneutic deployment of\nXAI algorithms) will be provided in the present study together with the results\nof the experiments, focusing on user experience rather than statistical\naccuracy. Even thoroughly employing deep learning models, full control was\nperceived by the interviewees in the decision-making setting, while it appeared\nthat a bridge can be built between accountability and liability in case of\ndamage.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14909v1", "cate": "cs.AI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14332", "title": "Development and Deployment of Hybrid ML Models for Critical Heat Flux Prediction in Annulus Geometries", "authors": ["Aidan Furlong", "Xingang Zhao", "Robert Salko", "Xu Wu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted for inclusion in Transactions of the American Nuclear Society for the 2025 ANS Winter Conference", "url": "http://arxiv.org/abs/2507.14332v1", "summary": "Accurate prediction of critical heat flux (CHF) is an essential component of\nsafety analysis in pressurized and boiling water reactors. To support reliable\nprediction of this quantity, several empirical correlations and lookup tables\nhave been constructed from physical experiments over the past several decades.\nWith the onset of accessible machine learning (ML) frameworks, multiple\ninitiatives have been established with the goal of predicting CHF more\naccurately than these traditional methods. While purely data-driven surrogate\nmodeling has been extensively investigated, these approaches lack\ninterpretability, lack resilience to data scarcity, and have been developed\nmostly using data from tube experiments. As a result, bias-correction hybrid\napproaches have become increasingly popular, which correct initial\n\"low-fidelity\" estimates provided by deterministic base models by using\nML-predicted residuals. This body of work has mostly considered round tube\ngeometries; annular geometry-specific ML models have not yet been deployed in\nthermal hydraulic codes. This study developed, deployed, and validated four ML\nmodels to predict CHF in annular geometries using the CTF subchannel code.\nThree empirical correlation models, Biasi, Bowring, and Katto, were used as\nbase models for comparison. The ML models were trained and tested using 577\nexperimental annulus data points from four datasets: Becker, Beus, Janssen, and\nMortimore. Baseline CHF predictions were obtained from the empirical\ncorrelations, with mean relative errors above 26%. The ML-driven models\nachieved mean relative errors below 3.5%, with no more than one point exceeding\nthe 10% error envelope. In all cases, the hybrid ML models significantly\noutperformed their empirical counterparts.", "comment": "Accepted for inclusion in Transactions of the American Nuclear\n  Society for the 2025 ANS Winter Conference", "pdf_url": "http://arxiv.org/pdf/2507.14332v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14533", "title": "ArtiMuse: Fine-Grained Image Aesthetics Assessment with Joint Scoring and Expert-Level Understanding", "authors": ["Shuo Cao", "Nan Ma", "Jiayang Li", "Xiaohui Li", "Lihao Shao", "Kaiwen Zhu", "Yu Zhou", "Yuandong Pu", "Jiarui Wu", "Jiaquan Wang", "Bo Qu", "Wenhai Wang", "Yu Qiao", "Dajuin Yao", "Yihao Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      43 pages, 31 figures, 13 tables", "url": "http://arxiv.org/abs/2507.14533v1", "summary": "The rapid advancement of educational applications, artistic creation, and\nAI-generated content (AIGC) technologies has substantially increased practical\nrequirements for comprehensive Image Aesthetics Assessment (IAA), particularly\ndemanding methods capable of delivering both quantitative scoring and\nprofessional understanding. Multimodal Large Language Model (MLLM)-based IAA\nmethods demonstrate stronger perceptual and generalization capabilities\ncompared to traditional approaches, yet they suffer from modality bias\n(score-only or text-only) and lack fine-grained attribute decomposition,\nthereby failing to support further aesthetic assessment. In this paper, we\npresent:(1) ArtiMuse, an innovative MLLM-based IAA model with Joint Scoring and\nExpert-Level Understanding capabilities; (2) ArtiMuse-10K, the first\nexpert-curated image aesthetic dataset comprising 10,000 images spanning 5 main\ncategories and 15 subcategories, each annotated by professional experts with\n8-dimensional attributes analysis and a holistic score. Both the model and\ndataset will be made public to advance the field.", "comment": "43 pages, 31 figures, 13 tables", "pdf_url": "http://arxiv.org/pdf/2507.14533v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15003", "title": "The Rise of AI Teammates in Software Engineering (SE) 3.0: How Autonomous Coding Agents Are Reshaping Software Engineering", "authors": ["Hao Li", "Haoxiang Zhang", "Ahmed E. Hassan"], "categories": ["cs.SE", "cs.AI", "cs.CE", "cs.LG"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15003v1", "summary": "The future of software engineering--SE 3.0--is unfolding with the rise of AI\nteammates: autonomous, goal-driven systems collaborating with human developers.\nAmong these, autonomous coding agents are especially transformative, now\nactively initiating, reviewing, and evolving code at scale. This paper\nintroduces AIDev, the first large-scale dataset capturing how such agents\noperate in the wild. Spanning over 456,000 pull requests by five leading\nagents--OpenAI Codex, Devin, GitHub Copilot, Cursor, and Claude Code--across\n61,000 repositories and 47,000 developers, AIDev provides an unprecedented\nempirical foundation for studying autonomous teammates in software development.\n  Unlike prior work that has largely theorized the rise of AI-native software\nengineering, AIDev offers structured, open data to support research in\nbenchmarking, agent readiness, optimization, collaboration modeling, and AI\ngovernance. The dataset includes rich metadata on PRs, authorship, review\ntimelines, code changes, and integration outcomes--enabling exploration beyond\nsynthetic benchmarks like SWE-bench. For instance, although agents often\noutperform humans in speed, their PRs are accepted less frequently, revealing a\ntrust and utility gap. Furthermore, while agents accelerate code\nsubmission--one developer submitted as many PRs in three days as they had in\nthree years--these are structurally simpler (via code complexity metrics).\n  We envision AIDev as a living resource: extensible, analyzable, and ready for\nthe SE and AI communities. Grounding SE 3.0 in real-world evidence, AIDev\nenables a new generation of research into AI-native workflows and supports\nbuilding the next wave of symbiotic human-AI collaboration. The dataset is\npublicly available at https://github.com/SAILResearch/AI_Teammates_in_SE3.\n  > AI Agent, Agentic AI, Coding Agent, Agentic Coding, Software Engineering\nAgent", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15003v1", "cate": "cs.SE", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14876", "title": "Tidal-Like Concept Drift in RIS-Covered Buildings: When Programmable Wireless Environments Meet Human Behaviors", "authors": ["Zi-Yang Wu", "Muhammad Ismail", "Jiliang Zhang", "Jie Zhang"], "categories": ["cs.NI", "94A05", "C.2.1; C.2.3"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE Wireless Communications, to appear in 2025", "url": "http://arxiv.org/abs/2507.14876v1", "summary": "Indoor mobile networks handle the majority of data traffic, with their\nperformance limited by building materials and structures. However, building\ndesigns have historically not prioritized wireless performance. Prior to the\nadvent of reconfigurable intelligent surfaces (RIS), the industry passively\nadapted to wireless propagation challenges within buildings. Inspired by RIS's\nsuccesses in outdoor networks, we propose embedding RIS into building\nstructures to manipulate and enhance building wireless performance\ncomprehensively. Nonetheless, the ubiquitous mobility of users introduces\ncomplex dynamics to the channels of RIS-covered buildings. A deep understanding\nof indoor human behavior patterns is essential for achieving wireless-friendly\nbuilding design. This article is the first to systematically examine the tidal\nevolution phenomena emerging in the channels of RIS-covered buildings driven by\ncomplex human behaviors. We demonstrate that a universal channel model is\nunattainable and focus on analyzing the challenges faced by advanced deep\nlearning-based prediction and control strategies, including high-order Markov\ndependencies, concept drift, and generalization issues caused by human-induced\ndisturbances. Possible solutions for orchestrating the coexistence of\nRIS-covered buildings and crowd mobility are also laid out.", "comment": "Accepted by IEEE Wireless Communications, to appear in 2025", "pdf_url": "http://arxiv.org/pdf/2507.14876v1", "cate": "cs.NI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15074", "title": "Reconfigurable Antenna Arrays With Tunable Loads: Expanding Solution Space via Coupling Control", "authors": ["Elio Faddoul", "Konstantinos Ntougias", "Ioannis Krikidis"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      This work has been submitted to an IEEE journal for possible publication", "url": "http://arxiv.org/abs/2507.15074v1", "summary": "The emerging reconfigurable antenna (RA) array technology promises capacity\nenhancement through dynamic antenna positioning. Traditional approaches enforce\nhalf-wavelength or greater spacing among RA elements to avoid mutual coupling,\nlimiting the solution space. Additionally, achieving sufficient spatial channel\nsampling requires numerous discrete RA positions (ports), while high-frequency\nscenarios with hybrid processing demand many physical RAs to maintain array\ngains. This leads to exponential growth in the solution space. We propose two\ntechniques to address the former challenge: (1) surrounding a limited number of\nactive RAs with passive ones terminated to tunable analog loads to\n\\textit{exploit} mutual coupling and increase array gain, and (2) employing\ntunable loads on each RA in an all-active design to \\textit{eliminate} mutual\ncoupling in the analog domain. Both methods enable arbitrary RA spacing,\nunlocking the full solution space. Regarding the latter challenge, we develop\ngreedy and meta-heuristic port selection algorithms, alongside low-complexity\nheuristic variants, that efficiently handle over $10^{20}$ array\nconfigurations, and optimize the loading values to maximize the sum-rate in a\nmultiple-input single-output broadcast channel under transmission power\nconstraints, assuming a heuristic linear precoder. Furthermore, we analyze\nperformance degradation from quantized loads and propose corresponding robust\ndesigns. Numerical simulations reveal significant performance gains over\nbenchmarks and provide valuable insights.", "comment": "This work has been submitted to an IEEE journal for possible\n  publication", "pdf_url": "http://arxiv.org/pdf/2507.15074v1", "cate": "cs.IT", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2501.12703", "title": "HEPPO-GAE: Hardware-Efficient Proximal Policy Optimization with Generalized Advantage Estimation", "authors": ["Hazem Taha", "Ameer M. S. Abdelhadi"], "categories": ["cs.AR", "cs.AI", "cs.LG", "B.2; B.3; B.5; B.6; B.7; C.1; C.3; I.2"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      Accepted at the 2024 International Conference on Field Programmable Technology (ICFPT 2024)", "url": "http://arxiv.org/abs/2501.12703v2", "summary": "This paper introduces HEPPO-GAE, an FPGA-based accelerator designed to\noptimize the Generalized Advantage Estimation (GAE) stage in Proximal Policy\nOptimization (PPO). Unlike previous approaches that focused on trajectory\ncollection and actor-critic updates, HEPPO-GAE addresses GAE's computational\ndemands with a parallel, pipelined architecture implemented on a single\nSystem-on-Chip (SoC). This design allows for the adaptation of various hardware\naccelerators tailored for different PPO phases. A key innovation is our\nstrategic standardization technique, which combines dynamic reward\nstandardization and block standardization for values, followed by 8-bit uniform\nquantization. This method stabilizes learning, enhances performance, and\nmanages memory bottlenecks, achieving a 4x reduction in memory usage and a 1.5x\nincrease in cumulative rewards. We propose a solution on a single SoC device\nwith programmable logic and embedded processors, delivering throughput orders\nof magnitude higher than traditional CPU-GPU systems. Our single-chip solution\nminimizes communication latency and throughput bottlenecks, significantly\nboosting PPO training efficiency. Experimental results show a 30% increase in\nPPO speed and a substantial reduction in memory access time, underscoring\nHEPPO-GAE's potential for broad applicability in hardware-efficient\nreinforcement learning algorithms.", "comment": "Accepted at the 2024 International Conference on Field Programmable\n  Technology (ICFPT 2024)", "pdf_url": "http://arxiv.org/pdf/2501.12703v2", "cate": "cs.AR", "date": "2025-01-22", "updated": "2025-07-21"}
{"id": "2501.08947", "title": "Taint Analysis for Graph APIs Focusing on Broken Access Control", "authors": ["Leen Lambers", "Lucas Sakizloglou", "Taisiya Khakharova", "Fernando Orejas"], "categories": ["cs.CR", "cs.LO", "cs.SE"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Intermediate preprint (revision #1) for submission to ICGT 24 Special Issue in Logical Methods in Computer Science", "url": "http://arxiv.org/abs/2501.08947v2", "summary": "We present the first systematic approach to static and dynamic taint analysis\nfor Graph APIs focusing on broken access control. The approach comprises the\nfollowing. We taint nodes in the Graph API if they represent data requiring\nspecific privileges in order to be retrieved or manipulated, and identify API\ncalls which are related to sources and sinks. Then, we statically analyze\nwhether tainted information flow between API source and sink calls occurs. To\nthis end, we model the API calls using graph transformation rules. We\nsubsequently use critical pair analysis to automatically analyze potential\ndependencies between rules representing source calls and rules representing\nsink calls. We distinguish direct from indirect tainted information flow and\nargue under which conditions the CPA is able to detect not only direct, but\nalso indirect tainted flow. The static taint analysis (i) identifies flows that\nneed to be further reviewed, since tainted nodes may be created by an API call\nand used or manipulated by another API call later without having the necessary\nprivileges, and (ii) can be used to systematically design dynamic security\ntests for broken access control. The dynamic taint analysis checks if potential\nbroken access control risks detected during the static taint analysis really\noccur. We apply the approach to a part of the GitHub GraphQL API. The\napplication illustrates that our analysis supports the detection of two types\nof broken access control systematically: the case where users of the API may\nnot be able to access or manipulate information, although they should be able\nto do so; and the case where users (or attackers) of the API may be able to\naccess/manipulate information that they should not.", "comment": "Intermediate preprint (revision #1) for submission to ICGT 24 Special\n  Issue in Logical Methods in Computer Science", "pdf_url": "http://arxiv.org/pdf/2501.08947v2", "cate": "cs.CR", "date": "2025-01-15", "updated": "2025-07-20"}
{"id": "2507.15608", "title": "Optimizing Force Signals from Human Demonstrations of In-Contact Motions", "authors": ["Johannes Hartwig", "Fabian Viessmann", "Dominik Henrich"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted for publication in Annals of Scientific Society for Assembly, Handling and Industrial Robotics 2024 (to appear)", "url": "http://arxiv.org/abs/2507.15608v1", "summary": "For non-robot-programming experts, kinesthetic guiding can be an intuitive\ninput method, as robot programming of in-contact tasks is becoming more\nprominent. However, imprecise and noisy input signals from human demonstrations\npose problems when reproducing motions directly or using the signal as input\nfor machine learning methods. This paper explores optimizing force signals to\ncorrespond better to the human intention of the demonstrated signal. We compare\ndifferent signal filtering methods and propose a peak detection method for\ndealing with first-contact deviations in the signal. The evaluation of these\nmethods considers a specialized error criterion between the input and the\nhuman-intended signal. In addition, we analyze the critical parameters'\ninfluence on the filtering methods. The quality for an individual motion could\nbe increased by up to \\SI{20}{\\percent} concerning the error criterion. The\nproposed contribution can improve the usability of robot programming and the\ninteraction between humans and robots.", "comment": "Accepted for publication in Annals of Scientific Society for\n  Assembly, Handling and Industrial Robotics 2024 (to appear)", "pdf_url": "http://arxiv.org/pdf/2507.15608v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15433", "title": "Designing at 1:1 Scale on Wall-Sized Displays Using Existing UI Design Tools", "authors": ["Lou Schwartz", "Mohammad Ghoniem", "Valérie Maquil", "Adrien Coppens", "Johannes Hermen"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Publication URL: this https URL", "url": "http://arxiv.org/abs/2507.15433v1", "summary": "Wall-Sized Displays have spatial characteristics that are difficult to\naddress during user interface design. The design at scale 1:1 could be part of\nthe solution. In this paper, we present the results of two user studies and one\ntechnology review, exploring the usability of popular, desktop-optimized\nprototyping tools, for designing at scale on Wall-Sized Displays. We considered\ntwo wall-sized display setups, and three different interaction methods: touch,\na keyboard equipped with a touchpad, and a tablet. We observed that designing\nat scale 1:1 was appreciated. Tablet-based interaction proved to be the most\ncomfortable interaction method, and a mix of interaction modalities is\npromising. In addition, care must be given to the surrounding environment, such\nas furniture. We propose twelve design guidelines for a design tool dedicated\nto this specific context. Overall, existing user interface design tools do not\nyet fully support design on and for wall-sized displays and require further\nconsiderations in terms of placement of user interface elements and the\nprovision of additional features.", "comment": "Publication URL:\n  https://www.thinkmind.org/library/Soft/Soft_v18_n12_2025/soft_v18_n12_2025_5.html", "pdf_url": "http://arxiv.org/pdf/2507.15433v1", "cate": "cs.HC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14912", "title": "Redefining Elderly Care with Agentic AI: Challenges and Opportunities", "authors": ["Ruhul Amin Khalil", "Kashif Ahmad", "Hazrat Ali"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14912v1", "summary": "The global ageing population necessitates new and emerging strategies for\ncaring for older adults. In this article, we explore the potential for\ntransformation in elderly care through Agentic Artificial Intelligence (AI),\npowered by Large Language Models (LLMs). We discuss the proactive and\nautonomous decision-making facilitated by Agentic AI in elderly care.\nPersonalized tracking of health, cognitive care, and environmental management,\nall aimed at enhancing independence and high-level living for older adults,\nrepresents important areas of application. With a potential for significant\ntransformation of elderly care, Agentic AI also raises profound concerns about\ndata privacy and security, decision independence, and access. We share key\ninsights to emphasize the need for ethical safeguards, privacy protections, and\ntransparent decision-making. Our goal in this article is to provide a balanced\ndiscussion of both the potential and the challenges associated with Agentic AI,\nand to provide insights into its responsible use in elderly care, to bring\nAgentic AI into harmony with the requirements and vulnerabilities specific to\nthe elderly. Finally, we identify the priorities for the academic research\ncommunities, to achieve human-centered advancements and integration of Agentic\nAI in elderly care. To the best of our knowledge, this is no existing study\nthat reviews the role of Agentic AI in elderly care. Hence, we address the\nliterature gap by analyzing the unique capabilities, applications, and\nlimitations of LLM-based Agentic AI in elderly care. We also provide a\ncompanion interactive dashboard at https://hazratali.github.io/agenticai/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14912v1", "cate": "cs.AI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14344", "title": "Influence Functions for Preference Dataset Pruning", "authors": ["Daniel Fein", "Gabriela Aranguiz-Dias"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14344v1", "summary": "Language models are commonly fine-tuned via reinforcement learning to alter\ntheir behavior or elicit new capabilities. Datasets used for these purposes,\nand particularly human preference datasets, are often noisy. The relatively\nsmall size post-training datasets, combined with parameter-efficient\nfine-tuning methods, enable the use of influence functions approximations to\ndetect and prune training examples that are harmful to performance on a\nvalidation set. In this work, we adapt the TL;DR dataset for reward model\ntraining to demonstrate how conjugate-gradient approximated influence functions\ncan be used to filter datasets. In our experiments, influence function\nfiltering yields a small retraining accuracy uplift of 1.5% after removing 10%\nof training examples. We also show that gradient similarity outperforms\ninfluence functions for detecting helpful training examples. This suggests that\nlocal curvature is important for detecting harmful training examples, but less\nso for identifying helpful examples.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14344v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14543", "title": "Real Time Captioning of Sign Language Gestures in Video Meetings", "authors": ["Sharanya Mukherjee", "Md Hishaam Akhtar", "Kannadasan R"], "categories": ["cs.CV", "cs.CY", "cs.HC", "cs.LG", "I.4.6"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      7 pages, 2 figures, 1 table, Presented at ICCMDE 2021", "url": "http://arxiv.org/abs/2507.14543v1", "summary": "It has always been a rather tough task to communicate with someone possessing\na hearing impairment. One of the most tested ways to establish such a\ncommunication is through the use of sign based languages. However, not many\npeople are aware of the smaller intricacies involved with sign language. Sign\nlanguage recognition using computer vision aims at eliminating the\ncommunication barrier between deaf-mute and ordinary people so that they can\nproperly communicate with others. Recently the pandemic has left the whole\nworld shaken up and has transformed the way we communicate. Video meetings have\nbecome essential for everyone, even people with a hearing disability. In recent\nstudies, it has been found that people with hearing disabilities prefer to sign\nover typing during these video calls. In this paper, we are proposing a browser\nextension that will automatically translate sign language to subtitles for\neveryone else in the video call. The Large-scale dataset which contains more\nthan 2000 Word-Level ASL videos, which were performed by over 100 signers will\nbe used.", "comment": "7 pages, 2 figures, 1 table, Presented at ICCMDE 2021", "pdf_url": "http://arxiv.org/pdf/2507.14543v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15025", "title": "Survey of GenAI for Automotive Software Development: From Requirements to Executable Code", "authors": ["Nenad Petrovic", "Vahid Zolfaghari", "Andre Schamschurko", "Sven Kirchner", "Fengjunjie Pan", "Chengdng Wu", "Nils Purschke", "Aleksei Velsh", "Krzysztof Lebioda", "Yinglei Song", "Yi Zhang", "Lukasz Mazur", "Alois Knoll"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Conference paper accepted for GACLM 2025", "url": "http://arxiv.org/abs/2507.15025v1", "summary": "Adoption of state-of-art Generative Artificial Intelligence (GenAI) aims to\nrevolutionize many industrial areas by reducing the amount of human\nintervention needed and effort for handling complex underlying processes.\nAutomotive software development is considered to be a significant area for\nGenAI adoption, taking into account lengthy and expensive procedures, resulting\nfrom the amount of requirements and strict standardization. In this paper, we\nexplore the adoption of GenAI for various steps of automotive software\ndevelopment, mainly focusing on requirements handling, compliance aspects and\ncode generation. Three GenAI-related technologies are covered within the\nstate-of-art: Large Language Models (LLMs), Retrieval Augmented Generation\n(RAG), Vision Language Models (VLMs), as well as overview of adopted prompting\ntechniques in case of code generation. Additionally, we also derive a\ngeneralized GenAI-aided automotive software development workflow based on our\nfindings from this literature review. Finally, we include a summary of a survey\noutcome, which was conducted among our automotive industry partners regarding\nthe type of GenAI tools used for their daily work activities.", "comment": "Conference paper accepted for GACLM 2025", "pdf_url": "http://arxiv.org/pdf/2507.15025v1", "cate": "cs.SE", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14891", "title": "FENIX: Enabling In-Network DNN Inference with FPGA-Enhanced Programmable Switches", "authors": ["Xiangyu Gao", "Tong Li", "Yinchao Zhang", "Ziqiang Wang", "Xiangsheng Zeng", "Su Yao", "Ke Xu"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14891v1", "summary": "Machine learning (ML) is increasingly used in network data planes for\nadvanced traffic analysis. However, existing solutions (such as FlowLens, N3IC,\nand BoS) still struggle to simultaneously achieve low latency, high throughput,\nand high accuracy. To address these challenges, we present FENIX, a hybrid\nin-network ML system that performs feature extraction on programmable switch\nASICs and deep neural network inference on FPGAs. FENIX introduces a Data\nEngine that leverages a probabilistic token bucket algorithm to control the\nsending rate of feature streams, effectively addressing the throughput gap\nbetween programmable switch ASICs and FPGAs. In addition, FENIX designs a Model\nEngine to enable high-accuracy deep neural network inference in the network,\novercoming the difficulty of deploying complex models on resource-constrained\nswitch chips. We implement FENIX on a programmable switch platform that\nintegrates a Tofino ASIC and a ZU19EG FPGA directly and evaluate it on\nreal-world network traffic datasets. Our results show that FENIX achieves\nmicrosecond-level inference latency and multi-terabit throughput with low\nhardware overhead, and delivers over 95\\% accuracy on mainstream network\ntraffic classification tasks, outperforming SOTA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14891v1", "cate": "cs.NI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15108", "title": "Noise Quantification and Control in Circuits via Strong Data-Processing Inequalities", "authors": ["Chenyang Sun"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15108v1", "summary": "This essay explores strong data-processing inequalities (SPDI's) as they\nappear in the work of Evans and Schulman \\cite{ES} and von Neumann \\cite{vN} on\ncomputing with noisy circuits. We first develop the framework in \\cite{ES},\nwhich leads to lower bounds on depth and upper bounds on noise that permit\nreliable computation. We then introduce the $3$-majority gate, introduced by\n\\cite{vN} for the purpose of controlling noise, and obtain an upper bound on\nnoise necessary for its function. We end by generalizing von Neumann's analysis\nto majority gates of any order, proving an analogous noise threshold and giving\na sufficient upper bound for order given a desired level of reliability.\n  The presentation of material has been modified in a way deemed more natural\nby the author, occasionally leading to simplifications of existing proofs.\nFurthermore, many computations omitted from the original works have been worked\nout, and some new commentary added. The intended audience has a rudimentary\nunderstanding of information theory similar to that of the author.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15108v1", "cate": "cs.IT", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2506.02311", "title": "Unicorn-CIM: Uncovering the Vulnerability and Improving the Resilience of High-Precision Compute-in-Memory", "authors": ["Qiufeng Li", "Yiwen Liang", "Weidong Cao"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.02311v2", "summary": "Compute-in-memory (CIM) architecture has been widely\n  explored to address the von Neumann bottleneck in accelerating deep\n  neural networks (DNNs). However, its reliability remains largely\nunderstudied, particularly in the emerging domain of floating-point (FP)\n  CIM, which is crucial for speeding up high-precision inference and on device\ntraining. This paper introduces Unicorn-CIM, a framework to\n  uncover the vulnerability and improve the resilience of high-precision\n  CIM, built on static random-access memory (SRAM)-based FP CIM\n  architecture. Through the development of fault injection and extensive\n  characterizations across multiple DNNs, Unicorn-CIM reveals how soft\n  errors manifest in FP operations and impact overall model performance.\n  Specifically, we find that high-precision DNNs are extremely sensitive\n  to errors in the exponent part of FP numbers. Building on this insight,\n  Unicorn-CIM develops an efficient algorithm-hardware co-design method\n  that optimizes model exponent distribution through fine-tuning and\n  incorporates a lightweight Error Correcting Code (ECC) scheme to\n  safeguard high-precision DNNs on FP CIM. Comprehensive experiments\n  show that our approach introduces just an 8.98% minimal logic overhead\n  on the exponent processing path while providing robust error protection\n  and maintaining model accuracy. This work paves the way for developing\n  more reliable and efficient CIM hardware.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.02311v2", "cate": "cs.AR", "date": "2025-06-02", "updated": "2025-07-21"}
{"id": "2502.11798", "title": "BackdoorDM: A Comprehensive Benchmark for Backdoor Learning on Diffusion Model", "authors": ["Weilin Lin", "Nanjun Zhou", "Yanyun Wang", "Jianze Li", "Hui Xiong", "Li Liu"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.11798v2", "summary": "Backdoor learning is a critical research topic for understanding the\nvulnerabilities of deep neural networks. While the diffusion model (DM) has\nbeen broadly deployed in public over the past few years, the understanding of\nits backdoor vulnerability is still in its infancy compared to the extensive\nstudies in discriminative models. Recently, many different backdoor attack and\ndefense methods have been proposed for DMs, but a comprehensive benchmark for\nbackdoor learning on DMs is still lacking. This absence makes it difficult to\nconduct fair comparisons and thorough evaluations of the existing approaches,\nthus hindering future research progress. To address this issue, we propose\n\\textit{BackdoorDM}, the first comprehensive benchmark designed for backdoor\nlearning on DMs. It comprises nine state-of-the-art (SOTA) attack methods, four\nSOTA defense strategies, and three useful visualization analysis tools. We\nfirst systematically classify and formulate the existing literature in a\nunified framework, focusing on three different backdoor attack types and five\nbackdoor target types, which are restricted to a single type in discriminative\nmodels. Then, we systematically summarize the evaluation metrics for each type\nand propose a unified backdoor evaluation method based on multimodal large\nlanguage model (MLLM). Finally, we conduct a comprehensive evaluation and\nhighlight several important conclusions. We believe that BackdoorDM will help\novercome current barriers and contribute to building a trustworthy artificial\nintelligence generated content (AIGC) community. The codes are released in\nhttps://github.com/linweiii/BackdoorDM.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.11798v2", "cate": "cs.CR", "date": "2025-02-17", "updated": "2025-07-21"}
{"id": "2507.15649", "title": "EMP: Executable Motion Prior for Humanoid Robot Standing Upper-body Motion Imitation", "authors": ["Haocheng Xu", "Haodong Zhang", "Zhenghan Chen", "Rong Xiong"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15649v1", "summary": "To support humanoid robots in performing manipulation tasks, it is essential\nto study stable standing while accommodating upper-body motions. However, the\nlimited controllable range of humanoid robots in a standing position affects\nthe stability of the entire body. Thus we introduce a reinforcement learning\nbased framework for humanoid robots to imitate human upper-body motions while\nmaintaining overall stability. Our approach begins with designing a retargeting\nnetwork that generates a large-scale upper-body motion dataset for training the\nreinforcement learning (RL) policy, which enables the humanoid robot to track\nupper-body motion targets, employing domain randomization for enhanced\nrobustness. To avoid exceeding the robot's execution capability and ensure\nsafety and stability, we propose an Executable Motion Prior (EMP) module, which\nadjusts the input target movements based on the robot's current state. This\nadjustment improves standing stability while minimizing changes to motion\namplitude. We evaluate our framework through simulation and real-world tests,\ndemonstrating its practical applicability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15649v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15443", "title": "Evaluating Joint Attention for Mixed-Presence Collaboration on Wall-Sized Displays", "authors": ["Adrien Coppens", "Valérie Maquil"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Version of record / published version: this https URL", "url": "http://arxiv.org/abs/2507.15443v1", "summary": "To understand and quantify the quality of mixed-presence collaboration around\nwall-sized displays, robust evaluation methodologies are needed, that are\nadapted for a room-sized experience and are not perceived as obtrusive. In this\npaper, we propose our approach for measuring joint attention based on head gaze\ndata. We describe how it has been implemented for a user study on mixed\npresence collaboration with two wall-sized displays and report on the insights\nwe gained so far from its implementation, with a preliminary focus on the data\ncoming from one particular session.", "comment": "Version of record / published version:\n  https://dl.acm.org/doi/full/10.1145/3731406.3731973", "pdf_url": "http://arxiv.org/pdf/2507.15443v1", "cate": "cs.HC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14962", "title": "Complexity of Faceted Explanations in Propositional Abduction", "authors": ["Johannes Schmidt", "Mohamed Maizia", "Victor Lagerkvist", "Johannes K. Fichte"], "categories": ["cs.AI", "cs.CC", "cs.LO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      This is the author's self-archived copy including detailed proofs. To appear in Theory and Practice of Logic Programming (TPLP), Proceedings of the 41st International Conference on Logic Programming (ICLP 2025)", "url": "http://arxiv.org/abs/2507.14962v1", "summary": "Abductive reasoning is a popular non-monotonic paradigm that aims to explain\nobserved symptoms and manifestations. It has many applications, such as\ndiagnosis and planning in artificial intelligence and database updates. In\npropositional abduction, we focus on specifying knowledge by a propositional\nformula. The computational complexity of tasks in propositional abduction has\nbeen systematically characterized - even with detailed classifications for\nBoolean fragments. Unsurprisingly, the most insightful reasoning problems\n(counting and enumeration) are computationally highly challenging. Therefore,\nwe consider reasoning between decisions and counting, allowing us to understand\nexplanations better while maintaining favorable complexity. We introduce facets\nto propositional abductions, which are literals that occur in some explanation\n(relevant) but not all explanations (dispensable). Reasoning with facets\nprovides a more fine-grained understanding of variability in explanations\n(heterogeneous). In addition, we consider the distance between two\nexplanations, enabling a better understanding of heterogeneity/homogeneity. We\ncomprehensively analyze facets of propositional abduction in various settings,\nincluding an almost complete characterization in Post's framework.", "comment": "This is the author's self-archived copy including detailed proofs. To\n  appear in Theory and Practice of Logic Programming (TPLP), Proceedings of the\n  41st International Conference on Logic Programming (ICLP 2025)", "pdf_url": "http://arxiv.org/pdf/2507.14962v1", "cate": "cs.AI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14353", "title": "Solo Connection: A Parameter Efficient Fine-Tuning Technique for Transformers", "authors": ["Harsh Nilesh Pathak", "Randy Paffenroth"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14353v1", "summary": "Parameter efficient fine tuning (PEFT) is a versatile and extensible approach\nfor adapting a Large Language Model (LLM) for newer tasks. One of the most\nprominent PEFT approaches, Low Rank Adaptation (LoRA), primarily focuses on\nadjusting the attention weight matrices within individual decoder blocks of a\nGenerative Pre trained Transformer (GPT2). In contrast, we introduce Solo\nConnection a novel method that adapts the representation at the decoder-block\nlevel rather than modifying individual weight matrices. Not only does Solo\nConnection outperform LoRA on E2E natural language generation benchmarks, but\nit also reduces the number of trainable parameters by 59% relative to LoRA and\nby more than 99% compared to full fine-tuning of GPT2, an early version of\nLarge Language Models (LLMs). Solo Connection is also motivated by homotopy\ntheory: we introduce a trainable linear transformation that gradually\ninterpolates between a zero vector and the task-specific representation,\nenabling smooth and stable adaptation over time. While skip connections in the\noriginal 12 layer GPT2 are typically confined to individual decoder blocks,\nsubsequent GPT2 variants scale up to 48 layers, and even larger language models\ncan include 128 or more decoder blocks. These expanded architectures underscore\nthe need to revisit how skip connections are employed during fine-tuning. This\npaper focuses on long skip connections that link outputs of different decoder\nblocks, potentially enhancing the model's ability to adapt to new tasks while\nleveraging pre-trained knowledge.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14353v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14544", "title": "Multimodal AI for Gastrointestinal Diagnostics: Tackling VQA in MEDVQA-GI 2025", "authors": ["Sujata Gaihre", "Amir Thapa Magar", "Prasuna Pokharel", "Laxmi Tiwari"], "categories": ["cs.CV", "cs.AI", "68T45 (Machine vision and scene understanding)", "I.2.10; I.4.8; H.3.1"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted to ImageCLEF 2025, to be published in the lab proceedings", "url": "http://arxiv.org/abs/2507.14544v1", "summary": "This paper describes our approach to Subtask 1 of the ImageCLEFmed MEDVQA\n2025 Challenge, which targets visual question answering (VQA) for\ngastrointestinal endoscopy. We adopt the Florence model-a large-scale\nmultimodal foundation model-as the backbone of our VQA pipeline, pairing a\npowerful vision encoder with a text encoder to interpret endoscopic images and\nproduce clinically relevant answers. To improve generalization, we apply\ndomain-specific augmentations that preserve medical features while increasing\ntraining diversity. Experiments on the KASVIR dataset show that fine-tuning\nFlorence yields accurate responses on the official challenge metrics. Our\nresults highlight the potential of large multimodal models in medical VQA and\nprovide a strong baseline for future work on explainability, robustness, and\nclinical integration. The code is publicly available at:\nhttps://github.com/TiwariLaxuu/VQA-Florence.git", "comment": "accepted to ImageCLEF 2025, to be published in the lab proceedings", "pdf_url": "http://arxiv.org/pdf/2507.14544v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15157", "title": "Can LLMs Generate User Stories and Assess Their Quality?", "authors": ["Giovanni Quattrocchi", "Liliana Pasquale", "Paola Spoletini", "Luciano Baresi"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15157v1", "summary": "Requirements elicitation is still one of the most challenging activities of\nthe requirements engineering process due to the difficulty requirements\nanalysts face in understanding and translating complex needs into concrete\nrequirements. In addition, specifying high-quality requirements is crucial, as\nit can directly impact the quality of the software to be developed. Although\nautomated tools allow for assessing the syntactic quality of requirements,\nevaluating semantic metrics (e.g., language clarity, internal consistency)\nremains a manual and time-consuming activity. This paper explores how LLMs can\nhelp automate requirements elicitation within agile frameworks, where\nrequirements are defined as user stories (US). We used 10 state-of-the-art LLMs\nto investigate their ability to generate US automatically by emulating customer\ninterviews. We evaluated the quality of US generated by LLMs, comparing it with\nthe quality of US generated by humans (domain experts and students). We also\nexplored whether and how LLMs can be used to automatically evaluate the\nsemantic quality of US. Our results indicate that LLMs can generate US similar\nto humans in terms of coverage and stylistic quality, but exhibit lower\ndiversity and creativity. Although LLM-generated US are generally comparable in\nquality to those created by humans, they tend to meet the acceptance quality\ncriteria less frequently, regardless of the scale of the LLM model. Finally,\nLLMs can reliably assess the semantic quality of US when provided with clear\nevaluation criteria and have the potential to reduce human effort in\nlarge-scale assessments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15157v1", "cate": "cs.SE", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15145", "title": "Quantum Machine Learning for Secure Cooperative Multi-Layer Edge AI with Proportional Fairness", "authors": ["Thai T. Vu", "John Le"], "categories": ["cs.NI", "cs.LG"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2507.15145v1", "summary": "This paper proposes a communication-efficient, event-triggered inference\nframework for cooperative edge AI systems comprising multiple user devices and\nedge servers. Building upon dual-threshold early-exit strategies for rare-event\ndetection, the proposed approach extends classical single-device inference to a\ndistributed, multi-device setting while incorporating proportional fairness\nconstraints across users. A joint optimization framework is formulated to\nmaximize classification utility under communication, energy, and fairness\nconstraints. To solve the resulting problem efficiently, we exploit the\nmonotonicity of the utility function with respect to the confidence thresholds\nand apply alternating optimization with Benders decomposition. Experimental\nresults show that the proposed framework significantly enhances system-wide\nperformance and fairness in resource allocation compared to single-device\nbaselines.", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2507.15145v1", "cate": "cs.NI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15247", "title": "The Exact Parameters of A Family of BCH Codes", "authors": ["Zhonghua Sun"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15247v1", "summary": "Despite the theoretical and practical significance of BCH codes, the exact\nminimum distance and dimension remain unknown for many families. This paper\nestablishes the precise minimum distance and dimension of narrow-sense BCH\ncodes $\\C_{(q, m, \\lambda, \\ell_0, \\ell_1)}$ over $\\gf(q)$ of length\n$\\frac{q^m-1}{\\lambda}$ and designed distance $\\frac{(q-\\lambda\n\\ell_0)q^{m-1-\\ell_1}-1}{\\lambda}$, where $\\lambda\\mid (q-1)$, $0\\leq \\ell_0<\n\\frac{q-1}{\\lambda}$, and $0\\leq \\ell_1\\leq m-1$. These results conclusively\nresolve the three open problems posed by Li et al. (IEEE Trans. Inf. Theory,\nvol. 63, no. 11, pp. 7219-7236, Nov. 2017) while establishing complementary\nadvances to Ding's seminal framework (IEEE Trans. Inf. Theory, vol. 61, no. 10,\npp. 5322-5330, Oct. 2015).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15247v1", "cate": "cs.IT", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.12442", "title": "Characterizing State Space Model (SSM) and SSM-Transformer Hybrid Language Model Performance with Long Context Length", "authors": ["Saptarshi Mitra", "Rachid Karami", "Haocheng Xu", "Sitao Huang", "Hyoukjun Kwon"], "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      12 pages, 7 figures", "url": "http://arxiv.org/abs/2507.12442v2", "summary": "The demand for machine intelligence capable of processing continuous,\nlong-context inputs on local devices is growing rapidly. However, the quadratic\ncomplexity and memory requirements of traditional Transformer architectures\nmake them inefficient and often unusable for these tasks. This has spurred a\nparadigm shift towards new architectures like State Space Models (SSMs) and\nhybrids, which promise near-linear scaling. While most current research focuses\non the accuracy and theoretical throughput of these models, a systematic\nperformance characterization on practical consumer hardware is critically\nneeded to guide system-level optimization and unlock new applications.\n  To address this gap, we present a comprehensive, comparative benchmarking of\ncarefully selected Transformer, SSM, and hybrid models specifically for\nlong-context inference on consumer and embedded GPUs. Our analysis reveals that\nSSMs are not only viable but superior for this domain, capable of processing\nsequences up to 220K tokens on a 24GB consumer GPU-approximately 4x longer than\ncomparable Transformers. While Transformers may be up to 1.8x faster at short\nsequences, SSMs demonstrate a dramatic performance inversion, becoming up to 4x\nfaster at very long contexts (~57K tokens). Our operator-level analysis reveals\nthat custom, hardware-aware SSM kernels dominate the inference runtime,\naccounting for over 55% of latency on edge platforms, identifying them as a\nprimary target for future hardware acceleration. We also provide detailed,\ndevice-specific characterization results to guide system co-design for the\nedge. To foster further research, we will open-source our characterization\nframework.", "comment": "12 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.12442v2", "cate": "cs.AR", "date": "2025-07-16", "updated": "2025-07-19"}
{"id": "2502.12721", "title": "Computation of the Hilbert Series for the Support-Minors Modeling of the MinRank Problem", "authors": ["Magali Bardet", "Alban Gilard"], "categories": ["cs.CR", "cs.SC"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.12721v2", "summary": "The MinRank problem is a simple linear algebra problem: given matrices with\ncoefficients in a field, find a non trivial linear combination of the matrices\nthat has a small rank. There are several algebraic modeling of the problem. The\nmain ones are: the Kipnis-Shamir modeling, the Minors modeling and the\nSupport-Minors modeling. The Minors modeling has been studied by Faug{\\`e}re et\nal. in 2010, where the authors provide an analysis of the complexity of\ncomputing a Gr{\\\"o}bner basis of the modeling, through the computation of the\nexact Hilbert Series for a generic instance. For the Support-Minors modeling,\nthe first terms of the Hilbert Series are given by Bardet et al. in 2020 based\non an heuristic and experimental work. In this work, we provide a formula and a\nproof for the complete Hilbert Series of the Support Minors modeling for\ngeneric instances. This is done by adapting well known results on determinantal\nideals to an ideal generated by a particular subset of the set of all minors of\na matrix of variables. We then show that this ideal is generated by", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.12721v2", "cate": "cs.CR", "date": "2025-02-18", "updated": "2025-07-21"}
{"id": "2507.15677", "title": "Data-Driven MPC with Data Selection for Flexible Cable-Driven Robotic Arms", "authors": ["Huayue Liang", "Yanbo Chen", "Hongyang Cheng", "Yanzhao Yu", "Shoujie Li", "Junbo Tan", "Xueqian Wang", "Long Zeng"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15677v1", "summary": "Flexible cable-driven robotic arms (FCRAs) offer dexterous and compliant\nmotion. Still, the inherent properties of cables, such as resilience,\nhysteresis, and friction, often lead to particular difficulties in modeling and\ncontrol. This paper proposes a model predictive control (MPC) method that\nrelies exclusively on input-output data, without a physical model, to improve\nthe control accuracy of FCRAs. First, we develop an implicit model based on\ninput-output data and integrate it into an MPC optimization framework. Second,\na data selection algorithm (DSA) is introduced to filter the data that best\ncharacterize the system, thereby reducing the solution time per step to\napproximately 4 ms, which is an improvement of nearly 80%. Lastly, the\ninfluence of hyperparameters on tracking error is investigated through\nsimulation. The proposed method has been validated on a real FCRA platform,\nincluding five-point positioning accuracy tests, a five-point response tracking\ntest, and trajectory tracking for letter drawing. The results demonstrate that\nthe average positioning accuracy is approximately 2.070 mm. Moreover, compared\nto the PID method with an average tracking error of 1.418{\\deg}, the proposed\nmethod achieves an average tracking error of 0.541{\\deg}.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15677v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15481", "title": "Challenging Disability and Interaction Norms in XR: Cooling Down the Empathy Machine in Waiting for Hands", "authors": ["Yesica Duarte", "Puneet Jain"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15481v1", "summary": "Virtual Reality (VR) is often described as the \"ultimate empathy machine,\"\nframing disability as an experience to be simulated through such technologies,\nwhich can reduce disability to a spectacle of pity or inspiration. In response,\nwe present Waiting for Hands (WfH), an interactive eXtended Reality (XR)\ninstallation that critiques this logic by: (1) repurposing interaction norms in\nXR through the creation of Alternative Controllers, and (2) staging an absurd\nXR performance using the built controllers to disrupt sentimentalized\ndisability narratives. The performance involves eight people: two XR\nparticipants on stage and six audience members watching a projected documentary\nabout Hema Kumari, an Indian singer living with Rheumatoid Arthritis. The XR\nusers partially obscure the film, drawing attention through strange mouth and\nhand movements performed in XR. This creates a layered experience that disrupts\ndirect engagement with Hema's story and introduces uncertainty. While XR is\noften seen as a fully immersive, sensory-dominant medium, this piece subverts\nthat framing by using XR to produce absurdity and alienation. By challenging\nempathy-driven and pitiable narratives of disability, we ask what ethical\nstance an XR performance can take to attune participants to non-normative\nembodiment while resisting spectacle.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15481v1", "cate": "cs.HC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15013", "title": "A Forced-Choice Neural Cognitive Diagnostic Model of Personality Testing", "authors": ["Xiaoyu Li", "Jin Wu", "Shaoyang Guo", "Haoran Shi", "Chanjin Zheng"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      15pages, 7 figures", "url": "http://arxiv.org/abs/2507.15013v1", "summary": "In the smart era, psychometric tests are becoming increasingly important for\npersonnel selection, career development, and mental health assessment.\nForced-choice tests are common in personality assessments because they require\nparticipants to select from closely related options, lowering the risk of\nresponse distortion. This study presents a deep learning-based Forced-Choice\nNeural Cognitive Diagnostic Model (FCNCD) that overcomes the limitations of\ntraditional models and is applicable to the three most common item block types\nfound in forced-choice tests. To account for the unidimensionality of items in\nforced-choice tests, we create interpretable participant and item parameters.\nWe model the interactions between participant and item features using\nmultilayer neural networks after mining them using nonlinear mapping. In\naddition, we use the monotonicity assumption to improve the interpretability of\nthe diagnostic results. The FCNCD's effectiveness is validated by experiments\non real-world and simulated datasets that show its accuracy, interpretability,\nand robustness.", "comment": "15pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.15013v1", "cate": "cs.AI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14387", "title": "Incremental Causal Graph Learning for Online Cyberattack Detection in Cyber-Physical Infrastructures", "authors": ["Arun Vignesh Malarkkan", "Dongjie Wang", "Haoyue Bai", "Yanjie Fu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      12 pages, 5 figures, 3 Tables, under review in IEEE Transactions on Big Data", "url": "http://arxiv.org/abs/2507.14387v1", "summary": "The escalating threat of cyberattacks on real-time critical infrastructures\nposes serious risks to public safety, demanding detection methods that\neffectively capture complex system interdependencies and adapt to evolving\nattack patterns. Traditional real-time anomaly detection techniques often\nsuffer from excessive false positives due to their statistical sensitivity to\nhigh data variance and class imbalance. To address these limitations, recent\nresearch has explored modeling causal relationships among system components.\nHowever, prior work mainly focuses on offline causal graph-based approaches\nthat require static historical data and fail to generalize to real-time\nsettings. These methods are fundamentally constrained by: (1) their inability\nto adapt to dynamic shifts in data distribution without retraining, and (2) the\nrisk of catastrophic forgetting when lacking timely supervision in live\nsystems. To overcome these challenges, we propose INCADET, a novel framework\nfor incremental causal graph learning tailored to real-time cyberattack\ndetection. INCADET dynamically captures evolving system behavior by\nincrementally updating causal graphs across streaming time windows. The\nframework comprises three modules: 1) Early Symptom Detection: Detects\ntransitions in system status using divergence in edge-weight distributions\nacross sequential causal graphs. 2) Incremental Causal Graph Learning:\nLeverages experience replay and edge reinforcement to continually refine causal\nstructures while preserving prior knowledge. 3) Causal Graph Classification:\nEmploys Graph Convolutional Networks (GCNs) to classify system status using the\nlearned causal graphs. Extensive experiments on real-world critical\ninfrastructure datasets demonstrate that INCADET achieves superior accuracy,\nrobustness, and adaptability compared to both static causal and deep temporal\nbaselines in evolving attack scenarios.", "comment": "12 pages, 5 figures, 3 Tables, under review in IEEE Transactions on\n  Big Data", "pdf_url": "http://arxiv.org/pdf/2507.14387v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14549", "title": "Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering Human Perceptual Variability on Facial Expressions", "authors": ["Haotian Deng", "Chi Zhang", "Chen Wei", "Quanying Liu"], "categories": ["cs.CV", "cs.CY"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IJCNN 2025", "url": "http://arxiv.org/abs/2507.14549v1", "summary": "A fundamental challenge in affective cognitive science is to develop models\nthat accurately capture the relationship between external emotional stimuli and\nhuman internal experiences. While ANNs have demonstrated remarkable accuracy in\nfacial expression recognition, their ability to model inter-individual\ndifferences in human perception remains underexplored. This study investigates\nthe phenomenon of high perceptual variability-where individuals exhibit\nsignificant differences in emotion categorization even when viewing the same\nstimulus. Inspired by the similarity between ANNs and human perception, we\nhypothesize that facial expression samples that are ambiguous for ANN\nclassifiers also elicit divergent perceptual judgments among human observers.\nTo examine this hypothesis, we introduce a novel perceptual boundary sampling\nmethod to generate facial expression stimuli that lie along ANN decision\nboundaries. These ambiguous samples form the basis of the varEmotion dataset,\nconstructed through large-scale human behavioral experiments. Our analysis\nreveals that these ANN-confusing stimuli also provoke heightened perceptual\nuncertainty in human participants, highlighting shared computational principles\nin emotion perception. Finally, by fine-tuning ANN representations using\nbehavioral data, we achieve alignment between ANN predictions and both\ngroup-level and individual-level human perceptual patterns. Our findings\nestablish a systematic link between ANN decision boundaries and human\nperceptual variability, offering new insights into personalized modeling of\nemotional interpretation.", "comment": "Accepted by IJCNN 2025", "pdf_url": "http://arxiv.org/pdf/2507.14549v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15181", "title": "Deep Learning Framework Testing via Heuristic Guidance Based on Multiple Model Measurements", "authors": ["Yinglong Zou", "Juan Zhai", "Chunrong Fang", "Yanzhou Mu", "Jiawei Liu", "Zhenyu Chen"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15181v1", "summary": "Deep learning frameworks serve as the foundation for developing and deploying\ndeep learning applications. To enhance the quality of deep learning frameworks,\nresearchers have proposed numerous testing methods using deep learning models\nas test inputs. However, existing methods predominantly measure model bug\ndetection effectiveness as heuristic indicators, presenting three critical\nlimitations: Firstly, existing methods fail to quantitatively measure model's\noperator combination variety, potentially missing critical operator\ncombinations that could trigger framework bugs. Secondly, existing methods\nneglect measuring model execution time, resulting in the omission of numerous\nmodels potential for detecting more framework bugs within limited testing time.\nThirdly, existing methods overlook correlation between different model\nmeasurements, relying simply on single-indicator heuristic guidance without\nconsidering their trade-offs. To overcome these limitations, we propose DLMMM,\nthe first deep learning framework testing method to include multiple model\nmeasurements into heuristic guidance and fuse these measurements to achieve\ntheir trade-off. DLMMM firstly quantitatively measures model's bug detection\nperformance, operator combination variety, and model execution time. After\nthat, DLMMM fuses the above measurements based on their correlation to achieve\ntheir trade-off. To further enhance testing effectiveness, DLMMM designs\nmulti-level heuristic guidance for test input model generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15181v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15254", "title": "User Head Movement-Predictive XR in Immersive H2M Collaborations over Future Enterprise Networks", "authors": ["Sourav Mondal", "Elaine Wong"], "categories": ["cs.NI", "cs.AI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      This article is accepted for publication in IEEE Internet of Things Journal. Copyright @ IEEE 2025", "url": "http://arxiv.org/abs/2507.15254v1", "summary": "The evolution towards future generation of mobile systems and fixed wireless\nnetworks is primarily driven by the urgency to support high-bandwidth and\nlow-latency services across various vertical sectors. This endeavor is fueled\nby smartphones as well as technologies like industrial internet of things,\nextended reality (XR), and human-to-machine (H2M) collaborations for fostering\nindustrial and social revolutions like Industry 4.0/5.0 and Society 5.0. To\nensure an ideal immersive experience and avoid cyber-sickness for users in all\nthe aforementioned usage scenarios, it is typically challenging to synchronize\nXR content from a remote machine to a human collaborator according to their\nhead movements across a large geographic span in real-time over communication\nnetworks. Thus, we propose a novel H2M collaboration scheme where the human's\nhead movements are predicted ahead with highly accurate models like\nbidirectional long short-term memory networks to orient the machine's camera in\nadvance. We validate that XR frame size varies in accordance with the human's\nhead movements and predict the corresponding bandwidth requirements from the\nmachine's camera to propose a human-machine coordinated dynamic bandwidth\nallocation (HMC-DBA) scheme. Through extensive simulations, we show that\nend-to-end latency and jitter requirements of XR frames are satisfied with much\nlower bandwidth consumption over enterprise networks like\nFiber-To-The-Room-Business. Furthermore, we show that better efficiency in\nnetwork resource utilization is achieved by employing our proposed HMC-DBA over\nstate-of-the-art schemes.", "comment": "This article is accepted for publication in IEEE Internet of Things\n  Journal. Copyright @ IEEE 2025", "pdf_url": "http://arxiv.org/pdf/2507.15254v1", "cate": "cs.NI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15301", "title": "A Novel Two-Dimensional Smoothing Algorithm", "authors": ["Xufeng Chen", "Liang Yan", "Xiaoshan Gao"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15301v1", "summary": "Smoothing and filtering two-dimensional sequences are fundamental tasks in\nfields such as computer vision. Conventional filtering algorithms often rely on\nthe selection of the filtering window, limiting their applicability in certain\nscenarios. To this end, we propose a novel Two-Dimensional Smoothing (TDS)\nalgorithm for the smoothing and filtering problem of two-dimensional sequences.\nTypically, the TDS algorithm does not require assumptions about the type of\nnoise distribution. It is simple and easy to implement compared to conventional\nfiltering methods, such as 2D adaptive Wiener filtering and Gaussian filtering.\nThe TDS algorithm can effectively extract the trend contained in the\ntwo-dimensional sequence and reduce the influence of noise on the data by\nadjusting only a single parameter. In this work, unlike existing algorithms\nthat depend on the filtering window, we introduce a loss function, where the\ntrend sequence is identified as the solution when this loss function takes a\nminimum value. Therefore, within the framework of the TDS algorithm, a general\ntwo-dimensional sequence can be innovatively decomposed into a trend sequence\nand a fluctuation sequence, in which the trend sequence contains the main\nfeatures of the sequence and the fluctuation sequence contains the detailed\nfeatures or noise interference of the sequence. To ensure the reliability of\nthe TDS algorithm, a crucial lemma is first established, indicating that the\ntrend sequence and fluctuation sequence obtained by the TDS algorithm are\nexistent and unique when the global smoothing parameter is determined. Three\nmodified algorithms are then proposed based on the TDS algorithm, with\ncorresponding lemmas and corollaries demonstrating their reliability. Finally,\nthe accuracy and effectiveness of the TDS algorithm are further verified\nthrough numerical simulations and image processing cases.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15301v1", "cate": "cs.IT", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2503.09676", "title": "Hardware-Compatible Single-Shot Feasible-Space Heuristics for Solving the Quadratic Assignment Problem", "authors": ["Haesol Im", "Chan-Woo Yang", "Moslem Noori", "Dmitrii Dobrynin", "Elisabetta Valiante", "Giacomo Pedretti", "Arne Heittmann", "Thomas Van Vaerenbergh", "Masoud Mohseni", "John Paul Strachan", "Dmitri Strukov", "Ray Beausoleil", "Ignacio Rozada"], "categories": ["math.OC", "cs.AR"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      28 pages", "url": "http://arxiv.org/abs/2503.09676v2", "summary": "Research into the development of special-purpose computing architectures\ndesigned to solve quadratic unconstrained binary optimization (QUBO) problems\nhas flourished in recent years. It has been demonstrated in the literature that\nsuch special-purpose solvers can outperform traditional CMOS architectures by\norders of magnitude with respect to timing metrics on synthetic problems.\nHowever, they face challenges with constrained problems such as the quadratic\nassignment problem (QAP), where mapping to binary formulations such as QUBO\nintroduces overhead and limits parallelism. In-memory computing (IMC) devices,\nsuch as memristor-based analog Ising machines, offer significant speedups and\nefficiency gains over traditional CPU-based solvers, particularly for solving\ncombinatorial optimization problems. In this work, we present a novel local\nsearch heuristic designed for IMC hardware to tackle the QAP. Our approach\nenables massive parallelism that allows for computing of full neighbourhoods\nsimultaneously to make update decisions. We ensure binary solutions remain\nfeasible by selecting local moves that lead to neighbouring feasible solutions,\nleveraging feasible-space search heuristics and the underlying structure of a\ngiven problem. Our approach is compatible with both digital computers and\nanalog hardware. We demonstrate its effectiveness in CPU implementations by\ncomparing it with state-of-the-art heuristics for solving the QAP.", "comment": "28 pages", "pdf_url": "http://arxiv.org/pdf/2503.09676v2", "cate": "math.OC", "date": "2025-03-12", "updated": "2025-07-18"}
{"id": "2502.17259", "title": "Detecting Benchmark Contamination Through Watermarking", "authors": ["Tom Sander", "Pierre Fernandez", "Saeed Mahloujifar", "Alain Durmus", "Chuan Guo"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.17259v2", "summary": "Benchmark contamination poses a significant challenge to the reliability of\nLarge Language Models (LLMs) evaluations, as it is difficult to assert whether\na model has been trained on a test set. We introduce a solution to this problem\nby watermarking benchmarks before their release. The embedding involves\nreformulating the original questions with a watermarked LLM, in a way that does\nnot alter the benchmark utility. During evaluation, we can detect\n``radioactivity'', \\ie traces that the text watermarks leave in the model\nduring training, using a theoretically grounded statistical test. We test our\nmethod by pre-training 1B models from scratch on 10B tokens with controlled\nbenchmark contamination, and validate its effectiveness in detecting\ncontamination on ARC-Easy, ARC-Challenge, and MMLU. Results show similar\nbenchmark utility post-watermarking and successful contamination detection when\nmodels are contaminated enough to enhance performance, \\eg $p$-val $=10^{-3}$\nfor +5$\\%$ on ARC-Easy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.17259v2", "cate": "cs.CR", "date": "2025-02-24", "updated": "2025-07-21"}
{"id": "2507.15693", "title": "Strong, Accurate, and Low-Cost Robot Manipulator", "authors": ["Georges Chebly", "Spencer Little", "Nisal Perera", "Aliya Abedeen", "Ken Suzuki", "Donghyun Kim"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15693v1", "summary": "This paper presents Forte, a fully 3D-printable, 6-DoF robotic arm designed\nto achieve near industrial-grade performance - 0.63 kg payload, 0.467 m reach,\nand sub-millimeter repeatability - at a material cost under $215. As an\naccessible robot for broad applications across classroom education to AI\nexperiments, Forte pushes forward the performance limitations of existing\nlow-cost educational arms. We introduce a cost-effective mechanical design that\ncombines capstan-based cable drives, timing belts, simple tensioning\nmechanisms, and lightweight 3D-printed structures, along with topology\noptimization for structural stiffness. Through careful drivetrain engineering,\nwe minimize backlash and maintain control fidelity without relying on\nhigh-power electronics or expensive manufacturing processes. Experimental\nvalidation demonstrates that Forte achieves high repeatability and load\ncapacity, offering a compelling robotic platform for both classroom instruction\nand advanced robotics research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15693v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15502", "title": "FollowUpBot: An LLM-Based Conversational Robot for Automatic Postoperative Follow-up", "authors": ["Chen Chen", "Jianing Yin", "Jiannong Cao", "Zhiyuan Wen", "Mingjin Zhang", "Weixun Gao", "Xiang Wang", "Haihua Shu"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15502v1", "summary": "Postoperative follow-up plays a crucial role in monitoring recovery and\nidentifying complications. However, traditional approaches, typically involving\nbedside interviews and manual documentation, are time-consuming and\nlabor-intensive. Although existing digital solutions, such as web\nquestionnaires and intelligent automated calls, can alleviate the workload of\nnurses to a certain extent, they either deliver an inflexible scripted\ninteraction or face private information leakage issues. To address these\nlimitations, this paper introduces FollowUpBot, an LLM-powered edge-deployed\nrobot for postoperative care and monitoring. It allows dynamic planning of\noptimal routes and uses edge-deployed LLMs to conduct adaptive and face-to-face\nconversations with patients through multiple interaction modes, ensuring data\nprivacy. Moreover, FollowUpBot is capable of automatically generating\nstructured postoperative follow-up reports for healthcare institutions by\nanalyzing patient interactions during follow-up. Experimental results\ndemonstrate that our robot achieves high coverage and satisfaction in follow-up\ninteractions, as well as high report generation accuracy across diverse field\ntypes. The demonstration video is available at\nhttps://www.youtube.com/watch?v=_uFgDO7NoK0.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15502v1", "cate": "cs.HC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15042", "title": "DeRAG: Black-box Adversarial Attacks on Multiple Retrieval-Augmented Generation Applications via Prompt Injection", "authors": ["Jerry Wang", "Fang Yu"], "categories": ["cs.AI", "cs.IR", "I.2.7; H.3.3; K.6.5"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by KDD Workshop on Prompt Optimization 2025", "url": "http://arxiv.org/abs/2507.15042v1", "summary": "Adversarial prompt attacks can significantly alter the reliability of\nRetrieval-Augmented Generation (RAG) systems by re-ranking them to produce\nincorrect outputs. In this paper, we present a novel method that applies\nDifferential Evolution (DE) to optimize adversarial prompt suffixes for\nRAG-based question answering. Our approach is gradient-free, treating the RAG\npipeline as a black box and evolving a population of candidate suffixes to\nmaximize the retrieval rank of a targeted incorrect document to be closer to\nreal world scenarios. We conducted experiments on the BEIR QA datasets to\nevaluate attack success at certain retrieval rank thresholds under multiple\nretrieving applications. Our results demonstrate that DE-based prompt\noptimization attains competitive (and in some cases higher) success rates\ncompared to GGPP to dense retrievers and PRADA to sparse retrievers, while\nusing only a small number of tokens (<=5 tokens) in the adversarial suffix.\nFurthermore, we introduce a readability-aware suffix construction strategy,\nvalidated by a statistically significant reduction in MLM negative\nlog-likelihood with Welch's t-test. Through evaluations with a BERT-based\nadversarial suffix detector, we show that DE-generated suffixes evade\ndetection, yielding near-chance detection accuracy.", "comment": "Accepted by KDD Workshop on Prompt Optimization 2025", "pdf_url": "http://arxiv.org/pdf/2507.15042v1", "cate": "cs.AI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14419", "title": "It's Not That Simple. An Analysis of Simple Test-Time Scaling", "authors": ["Guojun Wu"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14419v1", "summary": "Prior work proposed simple test-time scaling, a method for replicating this\nscaling behavior with models distilled from o1-like models by manually\ncontrolling test-time compute: either scaling down by enforcing a maximum\nlength or scaling up by iteratively appending \"Wait\" when the model is about to\nterminate its generation. This paper presents an analysis of simple test-time\nscaling and finds that the scaling behavior is largely attributed to scaling\ndown by enforcing a maximum length. In contrast, fine-tuning on long CoT data\ndistilled from o1-like models has no significant impact on scaling behavior,\nand scaling up by appending \"Wait\" leads to inconsistencies, as the model may\noscillate between solutions. A key distinction exists between scaling down by\nenforcing a maximum length and scaling up test-time compute in o1-like models,\nsuch as DeepSeek-R1\\@. These models are typically allowed to utilize as much\ncompute as needed, with the only constraint being the model's maximum supported\nlength. By learning to naturally scale up test-time compute during\nreinforcement learning, o1-like models surpass their peak performance when\nscaling up. In contrast, simple test-time scaling progressively imposes a lower\nupper limit on model performance as it scales down. While replicating the\ntest-time scaling behavior of o1 models can be straightforward by scaling down,\nit is crucial to recognize that the goal of scaling test-time compute is to\nunlock higher performance -- beyond what the model could originally achieve --\nrather than merely reproducing the appearance of scaling behavior.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14419v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14553", "title": "Clutter Detection and Removal by Multi-Objective Analysis for Photographic Guidance", "authors": ["Xiaoran Wu"], "categories": ["cs.CV", "cs.HC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14553v1", "summary": "Clutter in photos is a distraction preventing photographers from conveying\nthe intended emotions or stories to the audience. Photography amateurs\nfrequently include clutter in their photos due to unconscious negligence or the\nlack of experience in creating a decluttered, aesthetically appealing scene for\nshooting. We are thus motivated to develop a camera guidance system that\nprovides solutions and guidance for clutter identification and removal. We\nestimate and visualize the contribution of objects to the overall aesthetics\nand content of a photo, based on which users can interactively identify\nclutter. Suggestions on getting rid of clutter, as well as a tool that removes\ncluttered objects computationally, are provided to guide users to deal with\ndifferent kinds of clutter and improve their photographic work. Two technical\nnovelties underpin interactions in our system: a clutter distinguishment\nalgorithm with aesthetics evaluations for objects and an iterative image\ninpainting algorithm based on generative adversarial nets that reconstructs\nmissing regions of removed objects for high-resolution images. User studies\ndemonstrate that our system provides flexible interfaces and accurate\nalgorithms that allow users to better identify distractions and take higher\nquality images within less time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14553v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15188", "title": "Cultural Impact on Requirements Engineering Activities: Bangladeshi Practitioners' View", "authors": ["Chowdhury Shahriar Muzammel", "Maria Spichkova", "James Harland"], "categories": ["cs.SE", "cs.HC"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15188v1", "summary": "Requirements Engineering (RE) is one of the most interaction-intensive phases\nof software development. This means that RE activities might be especially\nimpacted by stakeholders' national culture. Software development projects\nincreasingly have a very diverse range of stakeholders. To future-proof RE\nactivities, we need to help RE practitioners avoid misunderstandings and\nconflicts that might arise from not understanding potential Cultural Influences\n(CIs). Moreover, an awareness of CIs supports diversity and inclusion in the IT\nprofession. Bangladesh has a growing IT sector with some unique socio-cultural\ncharacteristics, and has been largely overlooked in this research field. In\nthis study, we aim to investigate how the RE process is adopted in the context\nof Bangladeshi culture and what cultural influences impact overall RE\nactivities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15188v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15338", "title": "Low-Power and Accurate IoT Monitoring Under Radio Resource Constraint", "authors": ["Takaho Shimokasa", "Hiroyuki Yomo", "Federico Chiariotti", "Junya Shiraishi", "Petar Popovski"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      Paper accepted for IEEE PIMRC 2025", "url": "http://arxiv.org/abs/2507.15338v1", "summary": "This paper investigates how to achieve both low-power operations of sensor\nnodes and accurate state estimation using Kalman filter for internet of things\n(IoT) monitoring employing wireless sensor networks under radio resource\nconstraint. We consider two policies used by the base station to collect\nobservations from the sensor nodes: (i) an oblivious policy, based on\nstatistics of the observations, and (ii) a decentralized policy, based on\nautonomous decision of each sensor based on its instantaneous observation. This\nwork introduces a wake-up receiver and wake-up signaling to both policies to\nimprove the energy efficiency of the sensor nodes. The decentralized policy\ndesigned with random access prioritizes transmissions of instantaneous\nobservations that are highly likely to contribute to the improvement of state\nestimation. Our numerical results show that the decentralized policy improves\nthe accuracy of the estimation in comparison to the oblivious policy under the\nconstraint on the radio resource and consumed energy when the correlation\nbetween the processes observed by the sensor nodes is low. We also clarify the\ndegree of correlation in which the superiority of two policies changes.", "comment": "Paper accepted for IEEE PIMRC 2025", "pdf_url": "http://arxiv.org/pdf/2507.15338v1", "cate": "cs.NI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15372", "title": "Cross Mutual Information", "authors": ["Chetan Gohil", "Oliver M Cliff", "James M. Shine", "Ben D. Fulcher", "Joseph T. Lizier"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      9 pages, 6 figures, IEEE Information Theory Workshop 2025", "url": "http://arxiv.org/abs/2507.15372v1", "summary": "Mutual information (MI) is a useful information-theoretic measure to quantify\nthe statistical dependence between two random variables: $X$ and $Y$. Often, we\nare interested in understanding how the dependence between $X$ and $Y$ in one\nset of samples compares to another. Although the dependence between $X$ and $Y$\nin each set of samples can be measured separately using MI, these estimates\ncannot be compared directly if they are based on samples from a non-stationary\ndistribution. Here, we propose an alternative measure for characterising how\nthe dependence between $X$ and $Y$ as defined by one set of samples is\nexpressed in another, \\textit{cross mutual information}. We present a\ncomprehensive set of simulation studies sampling data with $X$-$Y$ dependencies\nto explore this measure. Finally, we discuss how this relates to measures of\nmodel fit in linear regression, and some future applications in neuroimaging\ndata analysis.", "comment": "9 pages, 6 figures, IEEE Information Theory Workshop 2025", "pdf_url": "http://arxiv.org/pdf/2507.15372v1", "cate": "cs.IT", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.09948", "title": "Iceberg: Enhancing HLS Modeling with Synthetic Data", "authors": ["Zijian Ding", "Tung Nguyen", "Weikai Li", "Aditya Grover", "Yizhou Sun", "Jason Cong"], "categories": ["cs.LG", "cs.AR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages. accepted to ICLAD'25", "url": "http://arxiv.org/abs/2507.09948v2", "summary": "Deep learning-based prediction models for High-Level Synthesis (HLS) of\nhardware designs often struggle to generalize. In this paper, we study how to\nclose the generalizability gap of these models through pretraining on synthetic\ndata and introduce Iceberg, a synthetic data augmentation approach that expands\nboth large language model (LLM)-generated programs and weak labels of unseen\ndesign configurations. Our weak label generation method is integrated with an\nin-context model architecture, enabling meta-learning from actual and proximate\nlabels. Iceberg improves the geometric mean modeling accuracy by $86.4\\%$ when\nadapt to six real-world applications with few-shot examples and achieves a\n$2.47\\times$ and a $1.12\\times$ better offline DSE performance when adapting to\ntwo different test datasets. Our open-sourced code is here:\nhttps://github.com/UCLA-VAST/iceberg", "comment": "9 pages. accepted to ICLAD'25", "pdf_url": "http://arxiv.org/pdf/2507.09948v2", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-19"}
{"id": "2503.02065", "title": "Too Much to Trust? Measuring the Security and Cognitive Impacts of Explainability in AI-Driven SOCs", "authors": ["Nidhi Rastogi", "Shirid Pant", "Devang Dhanuka", "Amulya Saxena", "Pranjal Mairal"], "categories": ["cs.CR", "cs.AI", "cs.IR", "I.2; E.3; J.4"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      13 pages, ACM Conference on Computer and Communications Security (CCS), 2025", "url": "http://arxiv.org/abs/2503.02065v2", "summary": "Explainable AI (XAI) holds significant promise for enhancing the transparency\nand trustworthiness of AI-driven threat detection in Security Operations\nCenters (SOCs). However, identifying the appropriate level and format of\nexplanation, particularly in environments that demand rapid decision-making\nunder high-stakes conditions, remains a complex and underexplored challenge. To\naddress this gap, we conducted a three-month mixed-methods study combining an\nonline survey (N1=248) with in-depth interviews (N2=24) to examine (1) how SOC\nanalysts conceptualize AI-generated explanations and (2) which types of\nexplanations are perceived as actionable and trustworthy across different\nanalyst roles. Our findings reveal that participants were consistently willing\nto accept XAI outputs, even in cases of lower predictive accuracy, when\nexplanations were perceived as relevant and evidence-backed. Analysts\nrepeatedly emphasized the importance of understanding the rationale behind AI\ndecisions, expressing a strong preference for contextual depth over a mere\npresentation of outcomes on dashboards. Building on these insights, this study\nre-evaluates current explanation methods within security contexts and\ndemonstrates that role-aware, context-rich XAI designs aligned with SOC\nworkflows can substantially improve practical utility. Such tailored\nexplainability enhances analyst comprehension, increases triage efficiency, and\nsupports more confident responses to evolving threats.", "comment": "13 pages, ACM Conference on Computer and Communications Security\n  (CCS), 2025", "pdf_url": "http://arxiv.org/pdf/2503.02065v2", "cate": "cs.CR", "date": "2025-03-03", "updated": "2025-07-20"}
{"id": "2507.15710", "title": "Selective Densification for Rapid Motion Planning in High Dimensions with Narrow Passages", "authors": ["Lu Huang", "Lingxiao Meng", "Jiankun Wang", "Xingjian Jing"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15710v1", "summary": "Sampling-based algorithms are widely used for motion planning in\nhigh-dimensional configuration spaces. However, due to low sampling efficiency,\ntheir performance often diminishes in complex configuration spaces with narrow\ncorridors. Existing approaches address this issue using handcrafted or learned\nheuristics to guide sampling toward useful regions. Unfortunately, these\nstrategies often lack generalizability to various problems or require extensive\nprior training. In this paper, we propose a simple yet efficient sampling-based\nplanning framework along with its bidirectional version that overcomes these\nissues by integrating different levels of planning granularity. Our approach\nprobes configuration spaces with uniform random samples at varying resolutions\nand explores these multi-resolution samples online with a bias towards sparse\nsamples when traveling large free configuration spaces. By seamlessly\ntransitioning between sparse and dense samples, our approach can navigate\ncomplex configuration spaces while maintaining planning speed and completeness.\nThe simulation results demonstrate that our approach outperforms several\nstate-of-the-art sampling-based planners in $\\mathbb{SE}(2)$, $\\mathbb{SE}(3)$,\nand $\\mathbb{R}^{14}$ with challenging terrains. Furthermore, experiments\nconducted with the Franka Emika Panda robot operating in a constrained\nworkspace provide additional evidence of the superiority of the proposed\nmethod.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15710v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15526", "title": "Strategies to Manage Human Factors in Mixed Reality Pilot Training: A Survey", "authors": ["Antonio Perez", "Avinash Singh", "Jonathan Mitchell", "Philip Swadling"], "categories": ["cs.HC", "H.5.1; H.1.2; I.3.6"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      14 pages, 3 figures", "url": "http://arxiv.org/abs/2507.15526v1", "summary": "Mixed Reality (MR) head mounted displays (HMDs) offer a promising alternative\nto traditional Flight Simulator Training Device (FSTD) displays, providing\nimmersion, realism and cost efficiency. However, these technologies require\nmanagement of human factors; cybersickness, visual fatigue and ergonomic\nstrain. If left unmitigated, these effects can hinder pilot performance and\ntraining outcomes. For safety critical fields like aviation, addressing human\nfactors challenges is crucial for MR's training potential. This survey\nsystematically reviews the current literature identifying key human factors\nchallenges in MR HMD use in pilot training and examines strategies to mitigate\nthese barriers. Drawing on existing industry standards set by a leading\naviation authority, the review adopts a regulatory perspective to explore\nhardware, software, ergonomic, physiological and psychological interventions\nimproving pilot comfort, safety and training effectiveness in an MR FSTD.\nAdditionally, it evaluates which of these interventions are most appropriate\nand viable for MR pilot training under existing aviation training regulations,\nensuring that technical requirements and pilot wellbeing remain balanced. The\nfindings yield significant insights for the human dimensions of aviation\nsimulation training, highlighting how regulatory considerations shape the\npracticality of mitigation measures. These insights inform emerging MR aviation\ntraining guidelines and best practices, supporting MR's readiness to enhance\naviation training.", "comment": "14 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.15526v1", "cate": "cs.HC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15106", "title": "From Kicking to Causality: Simulating Infant Agency Detection with a Robust Intrinsic Reward", "authors": ["Xia Xu", "Jochen Triesch"], "categories": ["cs.AI", "cs.RO", "F.2.2"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      13 pages, 5 figures", "url": "http://arxiv.org/abs/2507.15106v1", "summary": "While human infants robustly discover their own causal efficacy, standard\nreinforcement learning agents remain brittle, as their reliance on\ncorrelation-based rewards fails in noisy, ecologically valid scenarios. To\naddress this, we introduce the Causal Action Influence Score (CAIS), a novel\nintrinsic reward rooted in causal inference. CAIS quantifies an action's\ninfluence by measuring the 1-Wasserstein distance between the learned\ndistribution of sensory outcomes conditional on that action, $p(h|a)$, and the\nbaseline outcome distribution, $p(h)$. This divergence provides a robust reward\nthat isolates the agent's causal impact from confounding environmental noise.\nWe test our approach in a simulated infant-mobile environment where\ncorrelation-based perceptual rewards fail completely when the mobile is\nsubjected to external forces. In stark contrast, CAIS enables the agent to\nfilter this noise, identify its influence, and learn the correct policy.\nFurthermore, the high-quality predictive model learned for CAIS allows our\nagent, when augmented with a surprise signal, to successfully reproduce the\n\"extinction burst\" phenomenon. We conclude that explicitly inferring causality\nis a crucial mechanism for developing a robust sense of agency, offering a\npsychologically plausible framework for more adaptive autonomous systems.", "comment": "13 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.15106v1", "cate": "cs.AI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14446", "title": "Deep RL Dual Sourcing Inventory Management with Supply and Capacity Risk Awareness", "authors": ["Feng Liu", "Ying Liu", "Carson Eisenach"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14446v1", "summary": "In this work, we study how to efficiently apply reinforcement learning (RL)\nfor solving large-scale stochastic optimization problems by leveraging\nintervention models. The key of the proposed methodology is to better explore\nthe solution space by simulating and composing the stochastic processes using\npre-trained deep learning (DL) models. We demonstrate our approach on a\nchallenging real-world application, the multi-sourcing multi-period inventory\nmanagement problem in supply chain optimization. In particular, we employ deep\nRL models for learning and forecasting the stochastic supply chain processes\nunder a range of assumptions. Moreover, we also introduce a constraint\ncoordination mechanism, designed to forecast dual costs given the\ncross-products constraints in the inventory network. We highlight that instead\nof directly modeling the complex physical constraints into the RL optimization\nproblem and solving the stochastic problem as a whole, our approach breaks down\nthose supply chain processes into scalable and composable DL modules, leading\nto improved performance on large real-world datasets. We also outline open\nproblems for future research to further investigate the efficacy of such\nmodels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14446v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14555", "title": "Descrip3D: Enhancing Large Language Model-based 3D Scene Understanding with Object-Level Text Descriptions", "authors": ["Jintang Xue", "Ganning Zhao", "Jie-En Yao", "Hong-En Chen", "Yue Hu", "Meida Chen", "Suya You", "C. -C. Jay Kuo"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14555v1", "summary": "Understanding 3D scenes goes beyond simply recognizing objects; it requires\nreasoning about the spatial and semantic relationships between them. Current 3D\nscene-language models often struggle with this relational understanding,\nparticularly when visual embeddings alone do not adequately convey the roles\nand interactions of objects. In this paper, we introduce Descrip3D, a novel and\npowerful framework that explicitly encodes the relationships between objects\nusing natural language. Unlike previous methods that rely only on 2D and 3D\nembeddings, Descrip3D enhances each object with a textual description that\ncaptures both its intrinsic attributes and contextual relationships. These\nrelational cues are incorporated into the model through a dual-level\nintegration: embedding fusion and prompt-level injection. This allows for\nunified reasoning across various tasks such as grounding, captioning, and\nquestion answering, all without the need for task-specific heads or additional\nsupervision. When evaluated on five benchmark datasets, including ScanRefer,\nMulti3DRefer, ScanQA, SQA3D, and Scan2Cap, Descrip3D consistently outperforms\nstrong baseline models, demonstrating the effectiveness of language-guided\nrelational representation for understanding complex indoor scenes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14555v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15197", "title": "Towards Using Personas in Requirements Engineering: What Has Been Changed Recently?", "authors": ["Chowdhury Shahriar Muzammel", "Maria Spichkova", "James Harland"], "categories": ["cs.SE", "cs.HC"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15197v1", "summary": "In requirements engineering (RE), personas are now being used to represent\nuser expectations and needs. This systematic mapping study (SMS) aims to\nexplore the most recent studies and to cover recent changes in trends,\nespecially related to the recent evolution of Generative AI approaches. Our SMS\ncovers the period between April 2023 and April 2025. We identified 22 relevant\npublications and analysed persona representation, construction, validation, as\nwell as RE activities covered by personas. We identified that a number of\nstudies applied AI-based solutions for persona construction and validation. We\nobserved that template-based personas are becoming more popular nowadays. We\nalso observed an increase in the proportion of studies covering validation\naspects.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15197v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15382", "title": "Enhancements to P4TG: Histogram-Based RTT Monitoring in the Data Plane", "authors": ["Fabian Ihle", "Etienne Zink", "Michael Menth"], "categories": ["cs.NI", "cs.PF"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      This work has been published at the 1st Workshop on Resilient Networks and Systems (ReNeSys), Sept. 2025, Ilmenau/Germany under the Creative Commons Attribution 4.0 International License (CC BY 4.0)", "url": "http://arxiv.org/abs/2507.15382v1", "summary": "Modern traffic generators are essential tools for evaluating the performance\nof network environments. P4TG is a P4-based traffic generator implemented for\nIntel Tofino switches that offers high-speed packet generation with\nfine-grained measurement capabilities. However, P4TG samples time-based metrics\nsuch as the round-trip time (RTT) in the data plane and collects them at the\ncontroller. This leads to a reduced accuracy. In this paper, we introduce a\nhistogram-based RTT measurement feature for P4TG. It enables accurate analysis\nat line rate without sampling. Generally, histogram bins are modeled as ranges,\nand values are matched to a bin. Efficient packet matching in hardware is\ntypically achieved using ternary content addressable memory (TCAM). However,\nrepresenting range matching rules in TCAM poses a challenge. Therefore, we\nimplemented a range-to-prefix conversion algorithm that models range matching\nwith multiple ternary entries. This paper describes the data plane\nimplementation and runtime configuration of RTT histograms in P4TG. Further, we\ndiscuss the efficiency of the ternary decomposition. Our evaluation\ndemonstrates the applicability of the histogram-based RTT analysis by comparing\nthe measured values with a configured theoretical distribution of RTTs.", "comment": "This work has been published at the 1st Workshop on Resilient\n  Networks and Systems (ReNeSys), Sept. 2025, Ilmenau/Germany under the\n  Creative Commons Attribution 4.0 International License (CC BY 4.0)", "pdf_url": "http://arxiv.org/pdf/2507.15382v1", "cate": "cs.NI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15448", "title": "Galois equiangular tight frames from Galois self-dual codes", "authors": ["Junmin An", "Jon-Lark Kim"], "categories": ["cs.IT", "math.IT", "51E22, 94B05"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      22 pages", "url": "http://arxiv.org/abs/2507.15448v1", "summary": "Greaves et al. (2022) extended frames over real or complex numbers to frames\nover finite fields. In this paper, we study the theory of frames over finite\nfields by incorporating the Galois inner products introduced by Fan and Zhang\n(2017), which generalize the Euclidean and Hermitian inner products. We define\na class of frames, called Galois frames over finite fields, along with related\nnotions such as Galois Gram matrices, Galois frame operators, and Galois\nequiangular tight frames (Galois ETFs). We also characterize when Galois\nself-dual codes induce Galois ETFs. Furthermore, we construct explicitly Galois\nETFs from Galois self-dual constacyclic codes.", "comment": "22 pages", "pdf_url": "http://arxiv.org/pdf/2507.15448v1", "cate": "cs.IT", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2503.03108", "title": "OMNISEC: LLM-Driven Provenance-based Intrusion Detection via Retrieval-Augmented Behavior Prompting", "authors": ["Wenrui Cheng", "Tiantian Zhua", "Shunan Jing", "Jian-Ping Mei", "Mingjun Ma", "Jiaobo Jin", "Zhengqiu Weng"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.03108v3", "summary": "Recently, Provenance-based Intrusion Detection Systems (PIDSes) have been\nwidely used for endpoint threat analysis. These studies can be broadly\ncategorized into rule-based detection systems and learning-based detection\nsystems. Among these, due to the evolution of attack techniques, rules cannot\ndynamically model all the characteristics of attackers. As a result, such\nsystems often face false negatives. Learning-based detection systems are\nfurther divided into supervised learning and anomaly detection. The scarcity of\nattack samples hinders the usability and effectiveness of supervised\nlearning-based detection systems in practical applications. Anomaly-based\ndetection systems face a massive false positive problem because they cannot\ndistinguish between changes in normal behavior and real attack behavior. The\nalert results of detection systems are closely related to the manual labor\ncosts of subsequent security analysts. To reduce manual analysis time, we\npropose OMNISEC, which applies large language models (LLMs) to anomaly-based\nintrusion detection systems via retrieval-augmented behavior prompting. OMNISEC\ncan identify abnormal nodes and corresponding abnormal events by constructing\nsuspicious nodes and rare paths. By combining two external knowledge bases,\nOMNISEC uses Retrieval Augmented Generation (RAG) to enable the LLM to\ndetermine whether abnormal behavior is a real attack. Finally, OMNISEC can\nreconstruct the attack graph and restore the complete attack behavior chain of\nthe attacker's intrusion. Experimental results show that OMNISEC outperforms\nstate-of-the-art methods on public benchmark datasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.03108v3", "cate": "cs.CR", "date": "2025-03-05", "updated": "2025-07-19"}
{"id": "2507.15716", "title": "DiffPF: Differentiable Particle Filtering with Generative Sampling via Conditional Diffusion Models", "authors": ["Ziyu Wan", "Lin Zhao"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15716v1", "summary": "This paper proposes DiffPF, a differentiable particle filter that leverages\ndiffusion models for state estimation in dynamic systems. Unlike conventional\ndifferentiable particle filters, which require importance weighting and\ntypically rely on predefined or low-capacity proposal distributions. DiffPF\nlearns a flexible posterior sampler by conditioning a diffusion model on\npredicted particles and the current observation. This enables accurate,\nequally-weighted sampling from complex, high-dimensional, and multimodal\nfiltering distributions. We evaluate DiffPF across a range of scenarios,\nincluding both unimodal and highly multimodal distributions, and test it on\nsimulated as well as real-world tasks, where it consistently outperforms\nexisting filtering baselines. In particular, DiffPF achieves an 82.8%\nimprovement in estimation accuracy on a highly multimodal global localization\nbenchmark, and a 26% improvement on the real-world KITTI visual odometry\nbenchmark, compared to state-of-the-art differentiable filters. To the best of\nour knowledge, DiffPF is the first method to integrate conditional diffusion\nmodels into particle filtering, enabling high-quality posterior sampling that\nproduces more informative particles and significantly improves state\nestimation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15716v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15559", "title": "FlowForge: Guiding the Creation of Multi-agent Workflows with Design Space Visualization as a Thinking Scaffold", "authors": ["Pan Hao", "Dongyeop Kang", "Nicholas Hinds", "Qianwen Wang"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      9 pages, 10 figures, accepted by IEEE VIS 2025", "url": "http://arxiv.org/abs/2507.15559v1", "summary": "Multi-agent workflows have become an effective strategy for tackling\ncomplicated tasks by decomposing them into multiple sub-tasks and assigning\nthem to specialized agents. However, designing optimal workflows remains\nchallenging due to the vast and intricate design space. Current practices rely\nheavily on the intuition and expertise of practitioners, often resulting in\ndesign fixation or an unstructured, time-consuming exploration of\ntrial-and-error. To address these challenges, this work introduces FLOWFORGE,\nan interactive visualization tool to facilitate the creation of multi-agent\nworkflow through i) a structured visual exploration of the design space and ii)\nin-situ guidance informed by established design patterns. Based on formative\nstudies and literature review, FLOWFORGE organizes the workflow design process\ninto three hierarchical levels (i.e., task planning, agent assignment, and\nagent optimization), ranging from abstract to concrete. This structured visual\nexploration enables users to seamlessly move from high-level planning to\ndetailed design decisions and implementations, while comparing alternative\nsolutions across multiple performance metrics. Additionally, drawing from\nestablished workflow design patterns, FLOWFORGE provides context-aware, in-situ\nsuggestions at each level as users navigate the design space, enhancing the\nworkflow creation process with practical guidance. Use cases and user studies\ndemonstrate the usability and effectiveness of FLOWFORGE, while also yielding\nvaluable insights into how practitioners explore design spaces and leverage\nguidance during workflow development.", "comment": "9 pages, 10 figures, accepted by IEEE VIS 2025", "pdf_url": "http://arxiv.org/pdf/2507.15559v1", "cate": "cs.HC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15120", "title": "Automated planning with ontologies under coherence update semantics", "authors": ["Stefan Borgwardt", "Duy Nhu", "Gabriele Röger"], "categories": ["cs.AI", "cs.LO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15120v1", "summary": "Standard automated planning employs first-order formulas under closed-world\nsemantics to achieve a goal with a given set of actions from an initial state.\nWe follow a line of research that aims to incorporate background knowledge into\nautomated planning problems, for example, by means of ontologies, which are\nusually interpreted under open-world semantics. We present a new approach for\nplanning with DL-Lite ontologies that combines the advantages of ontology-based\naction conditions provided by explicit-input knowledge and action bases (eKABs)\nand ontology-aware action effects under the coherence update semantics. We show\nthat the complexity of the resulting formalism is not higher than that of\nprevious approaches and provide an implementation via a polynomial compilation\ninto classical planning. An evaluation of existing and new benchmarks examines\nthe performance of a planning system on different variants of our compilation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15120v1", "cate": "cs.AI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14484", "title": "ReDiSC: A Reparameterized Masked Diffusion Model for Scalable Node Classification with Structured Predictions", "authors": ["Yule Li", "Yifeng Lu", "Zhen Wang", "Zhewei Wei", "Yaliang Li", "Bolin Ding"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14484v1", "summary": "In recent years, graph neural networks (GNN) have achieved unprecedented\nsuccesses in node classification tasks. Although GNNs inherently encode\nspecific inductive biases (e.g., acting as low-pass or high-pass filters), most\nexisting methods implicitly assume conditional independence among node labels\nin their optimization objectives. While this assumption is suitable for\ntraditional classification tasks such as image recognition, it contradicts the\nintuitive observation that node labels in graphs remain correlated, even after\nconditioning on the graph structure. To make structured predictions for node\nlabels, we propose ReDiSC, namely, Reparameterized masked Diffusion model for\nStructured node Classification. ReDiSC estimates the joint distribution of node\nlabels using a reparameterized masked diffusion model, which is learned through\nthe variational expectation-maximization (EM) framework. Our theoretical\nanalysis shows the efficiency advantage of ReDiSC in the E-step compared to\nDPM-SNC, a state-of-the-art model that relies on a manifold-constrained\ndiffusion model in continuous domain. Meanwhile, we explicitly link ReDiSC's\nM-step objective to popular GNN and label propagation hybrid approaches.\nExtensive experiments demonstrate that ReDiSC achieves superior or highly\ncompetitive performance compared to state-of-the-art GNN, label propagation,\nand diffusion-based baselines across both homophilic and heterophilic graphs of\nvarying sizes. Notably, ReDiSC scales effectively to large-scale datasets on\nwhich previous structured diffusion methods fail due to computational\nconstraints, highlighting its significant practical advantage in structured\nnode classification tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14484v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14559", "title": "LEAD: Exploring Logit Space Evolution for Model Selection", "authors": ["Zixuan Hu", "Xiaotong Li", "Shixiang Tang", "Jun Liu", "Yichun Hu", "Ling-Yu Duan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by CVPR 2024", "url": "http://arxiv.org/abs/2507.14559v1", "summary": "The remarkable success of pretrain-then-finetune paradigm has led to a\nproliferation of available pre-trained models for vision tasks. This surge\npresents a significant challenge in efficiently choosing the most suitable\npre-trained models for downstream tasks. The critical aspect of this challenge\nlies in effectively predicting the model transferability by considering the\nunderlying fine-tuning dynamics. Existing methods often model fine-tuning\ndynamics in feature space with linear transformations, which do not precisely\nalign with the fine-tuning objective and fail to grasp the essential\nnonlinearity from optimization. To this end, we present LEAD, a\nfinetuning-aligned approach based on the network output of logits. LEAD\nproposes a theoretical framework to model the optimization process and derives\nan ordinary differential equation (ODE) to depict the nonlinear evolution\ntoward the final logit state. Additionally, we design a class-aware\ndecomposition method to consider the varying evolution dynamics across classes\nand further ensure practical applicability. Integrating the closely aligned\noptimization objective and nonlinear modeling capabilities derived from the\ndifferential equation, our method offers a concise solution to effectively\nbridge the optimization gap in a single step, bypassing the lengthy fine-tuning\nprocess. The comprehensive experiments on 24 supervised and self-supervised\npre-trained models across 10 downstream datasets demonstrate impressive\nperformances and showcase its broad adaptability even in low-data scenarios.", "comment": "Accepted by CVPR 2024", "pdf_url": "http://arxiv.org/pdf/2507.14559v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15224", "title": "SimdBench: Benchmarking Large Language Models for SIMD-Intrinsic Code Generation", "authors": ["Yibo He", "Shuoran Zhao", "Jiaming Huang", "Yingjie Fu", "Hao Yu", "Cunjian Huang", "Tao Xie"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15224v1", "summary": "SIMD (Single Instruction Multiple Data) instructions and their compiler\nintrinsics are widely supported by modern processors to accelerate\nperformance-critical tasks. SIMD intrinsic programming, a trade-off between\ncoding productivity and high performance, is widely used in the development of\nmainstream performance-critical libraries and daily computing tasks. Large\nLanguage Models (LLMs), which have demonstrated strong and comprehensive\ncapabilities in code generation, show promise in assisting programmers with the\nchallenges of SIMD intrinsic programming. However, existing code-generation\nbenchmarks focus on only scalar code, and it is unclear how LLMs perform in\ngenerating vectorized code using SIMD intrinsics. To fill this gap, we propose\nSimdBench, the first code benchmark specifically designed for SIMD-intrinsic\ncode generation, comprising 136 carefully crafted tasks and targeting five\nrepresentative SIMD intrinsics: SSE (x86 Streaming SIMD Extension), AVX (x86\nAdvanced Vector Extension), Neon (ARM Advanced SIMD Extension), SVE (ARM\nScalable Vector Extension), and RVV (RISC-V Vector Extension). We conduct a\nsystematic evaluation (measuring both correctness and performance) of 18\nrepresentative LLMs on SimdBench, resulting in a series of novel and insightful\nfindings. Our evaluation results demonstrate that LLMs exhibit a universal\ndecrease in pass@k during SIMD-intrinsic code generation compared to\nscalar-code generation. Our in-depth analysis highlights promising directions\nfor the further advancement of LLMs in the challenging domain of SIMD-intrinsic\ncode generation. SimdBench is fully open source at\nhttps://anonymous.4open.science/r/SimdBench-1B3F/ to benefit the broader\nresearch community.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15224v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15391", "title": "Stack Management for MPLS Network Actions: Integration of Nodes with Limited Hardware Capabilities", "authors": ["Fabian Ihle", "Michael Menth"], "categories": ["cs.NI", "C.2.2; C.2.1; C.2.6"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15391v1", "summary": "The MPLS Network Actions (MNA) framework enhances MPLS forwarding with a\ngeneralized encoding for manifold extensions such as network slicing and\nin-situ OAM (IOAM). Network actions in MNA are encoded in Label Stack Entries\n(LSEs) and are added to the MPLS stack. Routers have a physical limit on the\nnumber of LSEs they can read, called the readable label depth (RLD). With MNA,\nrouters must be able to process a minimum number of LSEs which requires a\nrelatively large RLD. In this paper, we perform a hardware analysis of an MNA\nimplementation and identify the reason for a large RLD requirement in the MNA\nprotocol design. Based on this, we present a mechanism that reduces the\nrequired RLD for MNA nodes by restructuring the MPLS stack during forwarding.\nWe then introduce the novel stack management network action that enables the\nproposed mechanism as well as its integration in networks with MNA-incapable\nnodes. The feasibility of the mechanism on programmable hardware is verified by\nproviding a P4-based implementation. Further, the effects on the required RLD,\nECMP, and packet overhead are discussed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15391v1", "cate": "cs.NI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15700", "title": "Estimating Rate-Distortion Functions Using the Energy-Based Model", "authors": ["Shitong Wu", "Sicheng Xu", "Lingyi Chen", "Huihui Wu", "Wenyi Zhang"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      6 pages, 6 figures", "url": "http://arxiv.org/abs/2507.15700v1", "summary": "The rate-distortion (RD) theory is one of the key concepts in information\ntheory, providing theoretical limits for compression performance and guiding\nthe source coding design, with both theoretical and practical significance. The\nBlahut-Arimoto (BA) algorithm, as a classical algorithm to compute RD\nfunctions, encounters computational challenges when applied to high-dimensional\nscenarios. In recent years, many neural methods have attempted to compute\nhigh-dimensional RD problems from the perspective of implicit generative\nmodels. Nevertheless, these approaches often neglect the reconstruction of the\noptimal conditional distribution or rely on unreasonable prior assumptions. In\nface of these issues, we propose an innovative energy-based modeling framework\nthat leverages the connection between the RD dual form and the free energy in\nstatistical physics, achieving effective reconstruction of the optimal\nconditional distribution.The proposed algorithm requires training only a single\nneural network and circumvents the challenge of computing the normalization\nfactor in energy-based models using the Markov chain Monte Carlo (MCMC)\nsampling. Experimental results demonstrate the significant effectiveness of the\nproposed algorithm in estimating high-dimensional RD functions and\nreconstructing the optimal conditional distribution.", "comment": "6 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.15700v1", "cate": "cs.IT", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2505.01454", "title": "Sparsification Under Siege: Defending Against Poisoning Attacks in Communication-Efficient Federated Learning", "authors": ["Zhiyong Jin", "Runhua Xu", "Chao Li", "Yizhong Liu", "Jianxin Li", "James Joshi"], "categories": ["cs.CR", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.01454v4", "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed clients while preserving data privacy, yet it faces significant\nchallenges in communication efficiency and vulnerability to poisoning attacks.\nWhile sparsification techniques mitigate communication overhead by transmitting\nonly critical model parameters, they inadvertently amplify security risks:\nadversarial clients can exploit sparse updates to evade detection and degrade\nmodel performance. Existing defense mechanisms, designed for standard FL\ncommunication scenarios, are ineffective in addressing these vulnerabilities\nwithin sparsified FL. To bridge this gap, we propose FLARE, a novel federated\nlearning framework that integrates sparse index mask inspection and model\nupdate sign similarity analysis to detect and mitigate poisoning attacks in\nsparsified FL. Extensive experiments across multiple datasets and adversarial\nscenarios demonstrate that FLARE significantly outperforms existing defense\nstrategies, effectively securing sparsified FL against poisoning attacks while\nmaintaining communication efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.01454v4", "cate": "cs.CR", "date": "2025-04-30", "updated": "2025-07-21"}
{"id": "2507.15729", "title": "Gaze-supported Large Language Model Framework for Bi-directional Human-Robot Interaction", "authors": ["Jens V. Rüppel", "Andrey Rudenko", "Tim Schreiter", "Martin Magnusson", "Achim J. Lilienthal"], "categories": ["cs.RO", "cs.HC"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This paper has been accepted to the 34th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), which will be held in Eindhoven, Netherlands on August 25-29, 2025. Copyright 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses", "url": "http://arxiv.org/abs/2507.15729v1", "summary": "The rapid development of Large Language Models (LLMs) creates an exciting\npotential for flexible, general knowledge-driven Human-Robot Interaction (HRI)\nsystems for assistive robots. Existing HRI systems demonstrate great progress\nin interpreting and following user instructions, action generation, and robot\ntask solving. On the other hand, bi-directional, multi-modal, and context-aware\nsupport of the user in collaborative tasks still remains an open challenge. In\nthis paper, we present a gaze- and speech-informed interface to the assistive\nrobot, which is able to perceive the working environment from multiple vision\ninputs and support the dynamic user in their tasks. Our system is designed to\nbe modular and transferable to adapt to diverse tasks and robots, and it is\ncapable of real-time use of language-based interaction state representation and\nfast on board perception modules. Its development was supported by multiple\npublic dissemination events, contributing important considerations for improved\nrobustness and user experience. Furthermore, in two lab studies, we compare the\nperformance and user ratings of our system with those of a traditional scripted\nHRI pipeline. Our findings indicate that an LLM-based approach enhances\nadaptability and marginally improves user engagement and task execution metrics\nbut may produce redundant output, while a scripted pipeline is well suited for\nmore straightforward tasks.", "comment": "This paper has been accepted to the 34th IEEE International\n  Conference on Robot and Human Interactive Communication (RO-MAN), which will\n  be held in Eindhoven, Netherlands on August 25-29, 2025. Copyright 2025 IEEE.\n  Personal use of this material is permitted. Permission from IEEE must be\n  obtained for all other uses", "pdf_url": "http://arxiv.org/pdf/2507.15729v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15650", "title": "Chapter 11 Students' interaction with and appreciation of automated informative tutoring feedback", "authors": ["Gerben van der Hoek", "Bastiaan Heeren", "Rogier Bos", "Paul Drijvers", "Johan Jeuring"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15650v1", "summary": "Computer aided formative assessment can be used to enhance a learning\nprocess, for instance by providing feedback. There are many design choices for\ndelivering feedback, that lead to a feedback strategy. In an informative\nfeedback strategy, students do not immediately receive information about the\ncorrect response, but are offered the opportunity to retry a task to apply\nfeedback information. In this small-scale qualitative study, we explore an\ninformative feedback strategy designed to offer a balance between room for\nexploration and mitigation of learning barriers. The research questions concern\nthe ways in which students interact with the feedback strategy and their\nappreciation of error-specific feedback as opposed to worked-out solutions. To\nanswer these questions, twenty-five 15-to-17-year-old senior general secondary\neducation students worked for approximately 20 minutes on linear and\nexponential extrapolation tasks in an online environment. Data included screen\ncaptures of students working with the environment and post-intervention\ninterviews. Results showed that room for exploration offered opportunities for\nself-guidance while mitigation of learning barriers prevented disengagement.\nFurthermore, students appreciated balanced feedback. We conclude that the\nbalanced feedback strategy yielded fruitful student-environment interactions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15650v1", "cate": "cs.HC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15140", "title": "Clinical Semantic Intelligence (CSI): Emulating the Cognitive Framework of the Expert Clinician for Comprehensive Oral Disease Diagnosis", "authors": ["Mohammad Mashayekhi", "Sara Ahmadi Majd", "Arian AmirAmjadi", "Parsa Hosseini"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15140v1", "summary": "The diagnosis of oral diseases presents a problematic clinical challenge,\ncharacterized by a wide spectrum of pathologies with overlapping\nsymptomatology. To address this, we developed Clinical Semantic Intelligence\n(CSI), a novel artificial intelligence framework that diagnoses 118 different\noral diseases by computationally modeling the cognitive processes of an expert\nclinician. Our core hypothesis is that moving beyond simple pattern matching to\nemulate expert reasoning is critical to building clinically useful diagnostic\naids.\n  CSI's architecture integrates a fine-tuned multimodal CLIP model with a\nspecialized ChatGLM-6B language model. This system executes a Hierarchical\nDiagnostic Reasoning Tree (HDRT), a structured framework that distills the\nsystematic, multi-step logic of differential diagnosis. The framework operates\nin two modes: a Fast Mode for rapid screening and a Standard Mode that\nleverages the full HDRT for an interactive and in-depth diagnostic workup.\n  To train and validate our system, we curated a primary dataset of 4,310\nimages, supplemented by an external hold-out set of 176 images for final\nvalidation. A clinically-informed augmentation strategy expanded our training\ndata to over 30,000 image-text pairs. On a 431-image internal test set, CSI's\nFast Mode achieved an accuracy of 73.4%, which increased to 89.5% with the\nHDRT-driven Standard Mode. The performance gain is directly attributable to the\nhierarchical reasoning process. Herein, we detail the architectural philosophy,\ndevelopment, and rigorous evaluation of the CSI framework.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15140v1", "cate": "cs.AI", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14487", "title": "Federated Reinforcement Learning in Heterogeneous Environments", "authors": ["Ukjo Hwang", "Songnam Hong"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14487v1", "summary": "We investigate a Federated Reinforcement Learning with Environment\nHeterogeneity (FRL-EH) framework, where local environments exhibit statistical\nheterogeneity. Within this framework, agents collaboratively learn a global\npolicy by aggregating their collective experiences while preserving the privacy\nof their local trajectories. To better reflect real-world scenarios, we\nintroduce a robust FRL-EH framework by presenting a novel global objective\nfunction. This function is specifically designed to optimize a global policy\nthat ensures robust performance across heterogeneous local environments and\ntheir plausible perturbations. We propose a tabular FRL algorithm named FedRQ\nand theoretically prove its asymptotic convergence to an optimal policy for the\nglobal objective function. Furthermore, we extend FedRQ to environments with\ncontinuous state space through the use of expectile loss, addressing the key\nchallenge of minimizing a value function over a continuous subset of the state\nspace. This advancement facilitates the seamless integration of the principles\nof FedRQ with various Deep Neural Network (DNN)-based RL algorithms. Extensive\nempirical evaluations validate the effectiveness and robustness of our FRL\nalgorithms across diverse heterogeneous environments, consistently achieving\nsuperior performance over the existing state-of-the-art FRL algorithms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14487v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14575", "title": "Benchmarking GANs, Diffusion Models, and Flow Matching for T1w-to-T2w MRI Translation", "authors": ["Andrea Moschetto", "Lemuel Puglisi", "Alec Sargood", "Pierluigi Dell'Acqua", "Francesco Guarnera", "Sebastiano Battiato", "Daniele Ravì"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14575v1", "summary": "Magnetic Resonance Imaging (MRI) enables the acquisition of multiple image\ncontrasts, such as T1-weighted (T1w) and T2-weighted (T2w) scans, each offering\ndistinct diagnostic insights. However, acquiring all desired modalities\nincreases scan time and cost, motivating research into computational methods\nfor cross-modal synthesis. To address this, recent approaches aim to synthesize\nmissing MRI contrasts from those already acquired, reducing acquisition time\nwhile preserving diagnostic quality. Image-to-image (I2I) translation provides\na promising framework for this task. In this paper, we present a comprehensive\nbenchmark of generative models$\\unicode{x2013}$specifically, Generative\nAdversarial Networks (GANs), diffusion models, and flow matching (FM)\ntechniques$\\unicode{x2013}$for T1w-to-T2w 2D MRI I2I translation. All\nframeworks are implemented with comparable settings and evaluated on three\npublicly available MRI datasets of healthy adults. Our quantitative and\nqualitative analyses show that the GAN-based Pix2Pix model outperforms\ndiffusion and FM-based methods in terms of structural fidelity, image quality,\nand computational efficiency. Consistent with existing literature, these\nresults suggest that flow-based models are prone to overfitting on small\ndatasets and simpler tasks, and may require more data to match or surpass GAN\nperformance. These findings offer practical guidance for deploying I2I\ntranslation techniques in real-world MRI workflows and highlight promising\ndirections for future research in cross-modal medical image synthesis. Code and\nmodels are publicly available at\nhttps://github.com/AndreaMoschetto/medical-I2I-benchmark.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14575v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15226", "title": "Code Clone Detection via an AlphaFold-Inspired Framework", "authors": ["Changguo Jia", "Yi Zhan", "Tianqi Zhao", "Hengzhi Ye", "Minghui Zhou"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15226v1", "summary": "Code clone detection, which aims to identify functionally equivalent code\nfragments, plays a critical role in software maintenance and vulnerability\nanalysis. Substantial methods have been proposed to detect code clones, but\nthey fall short in capturing code semantics or relying on language-specific\nanalyzers. Inspired by the remarkable success of AlphaFold in predicting\nthree-dimensional protein structures from protein sequences, in this paper, we\nleverage AlphaFold for code clone detection based on the insight that protein\nsequences and token sequences share a common linear sequential structure. In\nparticular, we propose AlphaCC, which represents code fragments as token\nsequences to ensure multi-language applicability and adapts AlphaFold's\nsequence-to-structure modeling capability to infer code semantics. The pipeline\nof AlphaCC goes through three steps. First, AlphaCC transforms each input code\nfragment into a token sequence and, motivated by AlphaFold's use of multiple\nsequence alignment (MSA) to enhance contextual understanding, constructs an MSA\nfrom lexically similar token sequences. Second, AlphaCC adopts a modified\nattention-based encoder based on AlphaFold to model dependencies within and\nacross token sequences. Finally, unlike AlphaFold's protein structure\nprediction task, AlphaCC computes similarity scores between token sequences\nthrough a late interaction strategy and performs binary classification to\ndetermine code clone pairs. Comprehensive evaluations on three language-diverse\ndatasets demonstrate AlphaCC's applicability across multiple programming\nlanguages. On two semantic clone detection datasets, it consistently\noutperforms all baselines, showing strong semantic understanding. Moreover,\nAlphaCC maintains competitive efficiency, enabling practical usage in\nlarge-scale clone detection tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15226v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15423", "title": "Assessing the Benefits of Ground Vehicles as Moving Urban Base Stations", "authors": ["Laura Finarelli", "Falko Dressler", "Marco Ajmone Marsan", "Gianluca Rizzo"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15423v1", "summary": "In the evolution towards 6G user-centric networking, the moving network (MN)\nparadigm can play an important role. In a MN, some small cell base stations\n(BS) are installed on top of vehicles, and enable a more dynamic, flexible and\nsustainable, network operation. By \"following\" the users movements and adapting\ndynamically to their requests, the MN paradigm enables a more efficient\nutilization of network resources, mitigating the need for dense small cell BS\ndeployments at the cost of an increase in resource utilization due to wireless\nbackhauling. This aspect is at least partly compensated by the shorter distance\nbetween users and BS, which allows for lower power and Line-of-Sight\ncommunications. While the MN paradigm has been investigated for some time, to\ndate, it is still unclear in which conditions the advantages of MN outweigh the\nadditional resource costs. In this paper, we propose a stochastic geometry\nframework for the characterization of the potential benefits of the MN paradigm\nas part of an HetNet in urban settings. Our approach allows the estimation of\nuser-perceived performance, accounting for wireless backhaul connectivity as\nwell as base station resource scheduling. We formulate an optimization problem\nfor determining the resource-optimal network configurations and BS scheduling\nwhich minimize the overall amount of deployed BSs in a QoS-aware manner, and\nthe minimum vehicular flow between different urban districts required to\nsupport them, and we propose an efficient stochastic heuristic to solve it. Our\nnumerical assessment suggests that the MN paradigm, coupled with appropriate\ndynamic network management strategies, significantly reduces the amount of\ndeployed network infrastructure while guaranteeing the target QoS perceived by\nusers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15423v1", "cate": "cs.NI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15757", "title": "Remote Channel Synthesis", "authors": ["Yassine Hamdi", "Deniz Gündüz"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15757v1", "summary": "We consider the problem of synthesizing a memoryless channel between an\nunobserved source and a remote terminal. An encoder has access to a partial or\nnoisy version $Z^n = (Z_1, \\ldots, Z_n)$ of a remote source sequence $X^n =\n(X_1, \\ldots, X_n),$ with $(X_i,Z_i)$ independent and identically distributed\nwith joint distribution $q_{X,Z}.$ The encoder communicates through a noiseless\nlink to a decoder which aims to produce an output $Y^n$ coordinated with the\nremote source; that is, the total variation distance between the joint\ndistribution of $X^n$ and $Y^n$ and some i.i.d. target distribution\n$q_{X,Y}^{\\otimes n}$ is required to vanish as $n$ goes to infinity. The two\nterminals may have access to a source of rate-limited common randomness. We\npresent a single-letter characterization of the optimal compression and common\nrandomness rates. We also show that when the common randomness rate is small,\nthen in most cases, coordinating $Z^n$ and $Y^n$ using a standard channel\nsynthesis scheme is strictly sub-optimal. In other words, schemes for which the\njoint distribution of $Z^n$ and $Y^n$ approaches a product distribution\nasymptotically are strictly sub-optimal.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15757v1", "cate": "cs.IT", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14526", "title": "Studying homing and synchronizing sequences for Timed Finite State Machines with output delays", "authors": ["Evgenii Vinarskii", "Jakub Ruszil", "Adam Roman", "Natalia Kushik"], "categories": ["cs.FL", "cs.CC"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14526v1", "summary": "The paper introduces final state identification (synchronizing and homing)\nsequences for Timed Finite State Machines (TFSMs) with output delays and\ninvestigates their properties. We formally define the notions of homing\nsequences (HSs) and synchronizing sequences (SSs) for these TFSMs and\ndemonstrate that several properties that hold for untimed machines do not\nnecessarily apply to timed ones. Furthermore, we explore the applicability of\nvarious approaches for deriving SSs and HSs for Timed FSMs with output delays,\nsuch as truncated successor tree-based and FSM abstraction-based methods.\nCorrespondingly, we identify the subclasses of TFSMs for which these approaches\ncan be directly applied and those for which other methods are required.\nAdditionally, we evaluate the complexity of existence check and derivation of\n(shortest) HSs / SSs for TFSMs with output delays.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14526v1", "cate": "cs.FL", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2506.10467", "title": "Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and Cybersecurity Applications", "authors": ["Felix Härer"], "categories": ["cs.CR", "cs.AI", "68T01", "I.2.1"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      This work has been submitted for publication. Copyright may be transferred. In this case, this version will be updated with a notice, according to the publisher's guidelines", "url": "http://arxiv.org/abs/2506.10467v4", "summary": "Recent advancements in LLMs indicate potential for novel applications, as\nevidenced by the reasoning capabilities in the latest OpenAI and DeepSeek\nmodels. To apply these models to domain-specific applications beyond text\ngeneration, LLM-based multi-agent systems can be utilized to solve complex\ntasks, particularly by combining reasoning techniques, code generation, and\nsoftware execution across multiple, potentially specialized LLMs. However,\nwhile many evaluations are performed on LLMs, reasoning techniques, and\napplications individually, their joint specification and combined application\nare not well understood. Defined specifications for multi-agent LLM systems are\nrequired to explore their potential and suitability for specific applications,\nallowing for systematic evaluations of LLMs, reasoning techniques, and related\naspects. This paper reports the results of exploratory research on (1.)\nmulti-agent specification by introducing an agent schema language and (2.) the\nexecution and evaluation of the specifications through a multi-agent system\narchitecture and prototype. The specification language, system architecture,\nand prototype are first presented in this work, building on an LLM system from\nprior research. Test cases involving cybersecurity tasks indicate the\nfeasibility of the architecture and evaluation approach. As a result,\nevaluations could be demonstrated for question answering, server security, and\nnetwork security tasks completed correctly by agents with LLMs from OpenAI and\nDeepSeek.", "comment": "This work has been submitted for publication. Copyright may be\n  transferred. In this case, this version will be updated with a notice,\n  according to the publisher's guidelines", "pdf_url": "http://arxiv.org/pdf/2506.10467v4", "cate": "cs.CR", "date": "2025-06-12", "updated": "2025-07-19"}
{"id": "2507.15782", "title": "Interleaved LLM and Motion Planning for Generalized Multi-Object Collection in Large Scene Graphs", "authors": ["Ruochu Yang", "Yu Zhou", "Fumin Zhang", "Mengxue Hou"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15782v1", "summary": "Household robots have been a longstanding research topic, but they still lack\nhuman-like intelligence, particularly in manipulating open-set objects and\nnavigating large environments efficiently and accurately. To push this\nboundary, we consider a generalized multi-object collection problem in large\nscene graphs, where the robot needs to pick up and place multiple objects\nacross multiple locations in a long mission of multiple human commands. This\nproblem is extremely challenging since it requires long-horizon planning in a\nvast action-state space under high uncertainties. To this end, we propose a\nnovel interleaved LLM and motion planning algorithm Inter-LLM. By designing a\nmultimodal action cost similarity function, our algorithm can both reflect the\nhistory and look into the future to optimize plans, striking a good balance of\nquality and efficiency. Simulation experiments demonstrate that compared with\nlatest works, our algorithm improves the overall mission performance by 30% in\nterms of fulfilling human commands, maximizing mission success rates, and\nminimizing mission costs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15782v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15692", "title": "Surfacing Variations to Calibrate Perceived Reliability of MLLM-generated Image Descriptions", "authors": ["Meng Chen", "Akhil Iyer", "Amy Pavel"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      18 pages, 6 figures", "url": "http://arxiv.org/abs/2507.15692v1", "summary": "Multimodal large language models (MLLMs) provide new opportunities for blind\nand low vision (BLV) people to access visual information in their daily lives.\nHowever, these models often produce errors that are difficult to detect without\nsight, posing safety and social risks in scenarios from medication\nidentification to outfit selection. While BLV MLLM users use creative\nworkarounds such as cross-checking between tools and consulting sighted\nindividuals, these approaches are often time-consuming and impractical. We\nexplore how systematically surfacing variations across multiple MLLM responses\ncan support BLV users to detect unreliable information without visually\ninspecting the image. We contribute a design space for eliciting and presenting\nvariations in MLLM descriptions, a prototype system implementing three\nvariation presentation styles, and findings from a user study with 15 BLV\nparticipants. Our results demonstrate that presenting variations significantly\nincreases users' ability to identify unreliable claims (by 4.9x using our\napproach compared to single descriptions) and significantly decreases perceived\nreliability of MLLM responses. 14 of 15 participants preferred seeing\nvariations of MLLM responses over a single description, and all expressed\ninterest in using our system for tasks from understanding a tornado's path to\nposting an image on social media.", "comment": "18 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.15692v1", "cate": "cs.HC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15225", "title": "Solving Formal Math Problems by Decomposition and Iterative Reflection", "authors": ["Yichi Zhou", "Jianqiu Zhao", "Yongxin Zhang", "Bohan Wang", "Siran Wang", "Luoxin Chen", "Jiahui Wang", "Haowei Chen", "Allan Jie", "Xinbo Zhang", "Haocheng Wang", "Luong Trung", "Rong Ye", "Phan Nhat Hoang", "Huishuai Zhang", "Peng Sun", "Hang Li"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15225v1", "summary": "General-purpose Large Language Models (LLMs) have achieved remarkable success\nin intelligence, performing comparably to human experts on complex reasoning\ntasks such as coding and mathematical reasoning. However, generating formal\nproofs in specialized languages like Lean 4 remains a significant challenge for\nthese models, limiting their application in complex theorem proving and\nautomated verification. Current approaches typically require specializing\nmodels through fine-tuning on dedicated formal corpora, incurring high costs\nfor data collection and training. In this work, we introduce \\textbf{Delta\nProver}, an agent-based framework that orchestrates the interaction between a\ngeneral-purpose LLM and the Lean 4 proof environment. Delta Prover leverages\nthe reflection and reasoning capabilities of general-purpose LLMs to\ninteractively construct formal proofs in Lean 4, circumventing the need for\nmodel specialization. At its core, the agent integrates two novel,\ninterdependent components: an algorithmic framework for reflective\ndecomposition and iterative proof repair, and a custom Domain-Specific Language\n(DSL) built upon Lean 4 for streamlined subproblem management. \\textbf{Delta\nProver achieves a state-of-the-art 95.9\\% success rate on the miniF2F-test\nbenchmark, surpassing all existing approaches, including those requiring model\nspecialization.} Furthermore, Delta Prover exhibits a significantly stronger\ntest-time scaling law compared to standard Best-of-N proof strategies.\nCrucially, our findings demonstrate that general-purpose LLMs, when guided by\nan effective agentic structure, possess substantial untapped theorem-proving\ncapabilities. This presents a computationally efficient alternative to\nspecialized models for robust automated reasoning in formal environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15225v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14492", "title": "Glitches in Decision Tree Ensemble Models", "authors": ["Satyankar Chandra", "Ashutosh Gupta", "Kaushik Mallik", "Krishna Shankaranarayanan", "Namrita Varshney"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14492v1", "summary": "Many critical decision-making tasks are now delegated to machine-learned\nmodels, and it is imperative that their decisions are trustworthy and reliable,\nand their outputs are consistent across similar inputs. We identify a new\nsource of unreliable behaviors-called glitches-which may significantly impair\nthe reliability of AI models having steep decision boundaries. Roughly\nspeaking, glitches are small neighborhoods in the input space where the model's\noutput abruptly oscillates with respect to small changes in the input. We\nprovide a formal definition of glitches, and use well-known models and datasets\nfrom the literature to demonstrate that they have widespread existence and\nargue they usually indicate potential model inconsistencies in the neighborhood\nof where they are found. We proceed to the algorithmic search of glitches for\nwidely used gradient-boosted decision tree (GBDT) models. We prove that the\nproblem of detecting glitches is NP-complete for tree ensembles, already for\ntrees of depth 4. Our glitch-search algorithm for GBDT models uses an MILP\nencoding of the problem, and its effectiveness and computational feasibility\nare demonstrated on a set of widely used GBDT benchmarks taken from the\nliterature.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14492v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14587", "title": "Performance comparison of medical image classification systems using TensorFlow Keras, PyTorch, and JAX", "authors": ["Merjem Bećirović", "Amina Kurtović", "Nordin Smajlović", "Medina Kapo", "Amila Akagić"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14587v1", "summary": "Medical imaging plays a vital role in early disease diagnosis and monitoring.\nSpecifically, blood microscopy offers valuable insights into blood cell\nmorphology and the detection of hematological disorders. In recent years, deep\nlearning-based automated classification systems have demonstrated high\npotential in enhancing the accuracy and efficiency of blood image analysis.\nHowever, a detailed performance analysis of specific deep learning frameworks\nappears to be lacking. This paper compares the performance of three popular\ndeep learning frameworks, TensorFlow with Keras, PyTorch, and JAX, in\nclassifying blood cell images from the publicly available BloodMNIST dataset.\nThe study primarily focuses on inference time differences, but also\nclassification performance for different image sizes. The results reveal\nvariations in performance across frameworks, influenced by factors such as\nimage resolution and framework-specific optimizations. Classification accuracy\nfor JAX and PyTorch was comparable to current benchmarks, showcasing the\nefficiency of these frameworks for medical image classification.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14587v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15241", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "authors": ["Vikram Nitin", "Baishakhi Ray", "Roshanak Zilouchian Moghaddam"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15241v1", "summary": "Despite the critical threat posed by software security vulnerabilities,\nreports are often incomplete, lacking the proof-of-vulnerability (PoV) tests\nneeded to validate fixes and prevent regressions. These tests are crucial not\nonly for ensuring patches work, but also for helping developers understand how\nvulnerabilities can be exploited. Generating PoV tests is a challenging\nproblem, requiring reasoning about the flow of control and data through deeply\nnested levels of a program.\n  We present FaultLine, an LLM agent workflow that uses a set of carefully\ndesigned reasoning steps, inspired by aspects of traditional static and dynamic\nprogram analysis, to automatically generate PoV test cases. Given a software\nproject with an accompanying vulnerability report, FaultLine 1) traces the flow\nof an input from an externally accessible API (\"source\") to the \"sink\"\ncorresponding to the vulnerability, 2) reasons about the conditions that an\ninput must satisfy in order to traverse the branch conditions encountered along\nthe flow, and 3) uses this reasoning to generate a PoV test case in a\nfeedback-driven loop. FaultLine does not use language-specific static or\ndynamic analysis components, which enables it to be used across programming\nlanguages.\n  To evaluate FaultLine, we collate a challenging multi-lingual dataset of 100\nknown vulnerabilities in Java, C and C++ projects. On this dataset, FaultLine\nis able to generate PoV tests for 16 projects, compared to just 9 for CodeAct\n2.1, a popular state-of-the-art open-source agentic framework. Thus, FaultLine\nrepresents a 77% relative improvement over the state of the art. Our findings\nsuggest that hierarchical reasoning can enhance the performance of LLM agents\non PoV test generation, but the problem in general remains challenging. We make\nour code and dataset publicly available in the hope that it will spur further\nresearch in this area.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15241v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15659", "title": "SENSOR: A Cost-Efficient Open-Source Flow Monitoring Platform", "authors": ["Gabriel Paradzik", "Benjamin Steinert", "Heinrich Abele", "Michael Menth"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15659v1", "summary": "This paper presents a cost-effective and distributed flow monitoring platform\nfor collecting unsampled IPFIX data exclusively using open-source tools, which\nis implemented at the University of T\\\"ubingen. An overview of all tools is\ngiven and their use is explained.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15659v1", "cate": "cs.NI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14148", "title": "Visible Light Indoor Positioning with a Single LED and Distributed Single-Element OIRS: An Iterative Approach with Adaptive Beam Steering", "authors": ["Daniele Pugliese", "Giovanni Iacovelli", "Alessio Fascista", "Domenico Striccoli", "Oleksandr Romanov", "Luigi Alfredo Grieco", "Gennaro Boggia"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14148v1", "summary": "The integration of Optical Intelligent Reflective Surfaces (OIRSs) into\nVisible Light Communication (VLC) systems is gaining momentum as a valid\nalternative to RF technologies, harnessing the existing lighting\ninfrastructures and the vast unlicensed optical spectrum to enable higher\nspectral efficiency, improved resilience to Line-of-Sight (LoS) blockages, and\nenhanced positioning capabilities. This paper investigates the problem of\nlocalizing a low-cost Photo Detector (PD) in a VLC-based indoor environment\nconsisting of only a single Light Emitting Diode (LED) as an active anchor, and\nmultiple spatially distributed single-element OIRSs. We formulate the problem\nwithin an indirect, computationally efficient localization framework: first,\nthe optimal Maximum Likelihood (ML) estimators of the LoS and Non-Line-of-Sight\n(NLoS) distances are derived, using a suitable OIRS activation strategy to\nprevent interferences. To overcome the grid-based optimization required by the\nML NLoS estimator, we devise a novel algorithm based on an unstructured noise\nvariance transformation, which admits a closed-form solution. The set of\nestimated LoS/NLoS distances are then used within a low-complexity localization\nalgorithm combining an Iterative Weighted Least Squares (IWLS) procedure, whose\nweights are set according to the inverse of the Cram\\'er-Rao Lower Bound\n(CRLB), with an adaptive beam steering strategy that allows the OIRSs network\nto dynamically align with the PD, without any prior knowledge of its position.\nAccordingly, we derive the CRLB for both LoS/NLoS distance estimation and PD\nposition estimation. Simulation results demonstrate the effectiveness of our\napproach in terms of localization accuracy, robustness against OIRSs\nmisalignment conditions, and low number of iterations required to attain the\ntheoretical bounds.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14148v1", "cate": "eess.SP", "date": "2025-07-02", "updated": "2025-07-02"}
{"id": "2507.15310", "title": "Input-Driven Pushdown Automata with Translucent Input Letters", "authors": ["Martin Kutrib", "Andreas Malcher", "Matthias Wendlandt"], "categories": ["cs.FL"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      In Proceedings NCMA 2025, arXiv:2507.14082", "url": "http://arxiv.org/abs/2507.15310v1", "summary": "Input-driven pushdown automata with translucent input letters are\ninvestigated. Here, the use of translucent input letters means that the input\nis processed in several sweeps and that, depending on the current state of the\nautomaton, some input symbols are visible and can be processed, whereas some\nother symbols are invisible, and may be processed in another sweep.\nAdditionally, the returning mode as well as the non-returning mode are\nconsidered, where in the former mode a new sweep must start after processing a\nvisible input symbol. Input-driven pushdown automata differ from traditional\npushdown automata by the fact that the actions on the pushdown store (push,\npop, nothing) are dictated by the input symbols. We obtain the result that the\ninput-driven nondeterministic model is computationally stronger than the\ndeterministic model both in the returning mode and in the non-returning mode,\nwhereas it is known that the deterministic and the nondeterministic model are\nequivalent for input-driven pushdown automata without translucency. It also\nturns out that the non-returning model is computationally stronger than the\nreturning model both in the deterministic and nondeterministic case.\nFurthermore, we investigate the closure properties of the language families\nintroduced under the Boolean operations. We obtain a complete picture in the\ndeterministic case, whereas in the nondeterministic case the language families\nare shown to be not closed under complementation. Finally, we look at\ndecidability questions and obtain the non-semidecidability of the questions of\nuniversality, inclusion, equivalence, and regularity in the nondeterministic\ncase.", "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "pdf_url": "http://arxiv.org/pdf/2507.15310v1", "cate": "cs.FL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2506.15170", "title": "From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem", "authors": ["Yanxu Mao", "Tiehan Cui", "Peipei Liu", "Datao You", "Hongsong Zhu"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.15170v2", "summary": "Large language models (LLMs) are rapidly evolving from single-modal systems\nto multimodal LLMs and intelligent agents, significantly expanding their\ncapabilities while introducing increasingly severe security risks. This paper\npresents a systematic survey of the growing complexity of jailbreak attacks and\ncorresponding defense mechanisms within the expanding LLM ecosystem. We first\ntrace the developmental trajectory from LLMs to MLLMs and Agents, highlighting\nthe core security challenges emerging at each stage. Next, we categorize\nmainstream jailbreak techniques from both the attack impact and visibility\nperspectives, and provide a comprehensive analysis of representative attack\nmethods, related datasets, and evaluation metrics. On the defense side, we\norganize existing strategies based on response timing and technical approach,\noffering a structured understanding of their applicability and implementation.\nFurthermore, we identify key limitations in existing surveys, such as\ninsufficient attention to agent-specific security issues, the absence of a\nclear taxonomy for hybrid jailbreak methods, a lack of detailed analysis of\nexperimental setups, and outdated coverage of recent advancements. To address\nthese limitations, we provide an updated synthesis of recent work and outline\nfuture research directions in areas such as dataset construction, evaluation\nframework optimization, and strategy generalization. Our study seeks to enhance\nthe understanding of jailbreak mechanisms and facilitate the advancement of\nmore resilient and adaptive defense strategies in the context of ever more\ncapable LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.15170v2", "cate": "cs.CR", "date": "2025-06-18", "updated": "2025-07-20"}
{"id": "2507.15833", "title": "Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers", "authors": ["Ian Chuang", "Andrew Lee", "Dechen Gao", "Jinyu Zou", "Iman Soltani"], "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      13 pages, 10 figures", "url": "http://arxiv.org/abs/2507.15833v1", "summary": "Human vision is a highly active process driven by gaze, which directs\nattention and fixation to task-relevant regions and dramatically reduces visual\nprocessing. In contrast, robot learning systems typically rely on passive,\nuniform processing of raw camera images. In this work, we explore how\nincorporating human-like active gaze into robotic policies can enhance both\nefficiency and performance. We build on recent advances in foveated image\nprocessing and apply them to an Active Vision robot system that emulates both\nhuman head movement and eye tracking. Extending prior work on the AV-ALOHA\nrobot simulation platform, we introduce a framework for simultaneously\ncollecting eye-tracking data and robot demonstrations from a human operator as\nwell as a simulation benchmark and dataset for training robot policies that\nincorporate human gaze. Given the widespread use of Vision Transformers (ViTs)\nin robot learning, we integrate gaze information into ViTs using a foveated\npatch tokenization scheme inspired by recent work in image segmentation.\nCompared to uniform patch tokenization, this significantly reduces the number\nof tokens-and thus computation-without sacrificing visual fidelity near regions\nof interest. We also explore two approaches to gaze imitation and prediction\nfrom human data. The first is a two-stage model that predicts gaze to guide\nfoveation and action; the second integrates gaze into the action space,\nallowing the policy to jointly predict gaze and actions end-to-end. Our results\nshow that our method for foveated robot vision not only drastically reduces\ncomputational overhead, but also improves performance for high precision tasks\nand robustness to unseen distractors. Together, these findings suggest that\nhuman-inspired visual processing offers a useful inductive bias for robotic\nvision systems. https://ian-chuang.github.io/gaze-av-aloha/", "comment": "13 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.15833v1", "cate": "cs.RO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15783", "title": "Romance, Relief, and Regret: Teen Narratives of Chatbot Overreliance", "authors": ["Mohammad 'Matt' Namvarpour", "Brandon Brofsky", "Jessica Medina", "Mamtaj Akter", "Afsaneh Razi"], "categories": ["cs.HC", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15783v1", "summary": "As Generative Artificial Intelligence (GenAI) driven chatbots like\nCharacter.AI become embedded in adolescent life, they raise concerns about\nemotional dependence and digital overreliance. While studies have investigated\nthe overreliance of adults on these chatbots, they have not investigated teens'\ninteractions with chatbots with customizable personas. We analyzed 318 Reddit\nposts made by users self-reported as 13-17 years old on the Character.AI\nsubreddit to understand patterns of overreliance. We found teens commonly begin\nusing chatbots for emotional support or creative expression, but many develop\nstrong attachments that interfere with offline relationships and daily\nroutines. Their posts revealed recurring signs of psychological distress,\ncycles of relapse, and difficulty disengaging. Teens reported that their\noverreliance often ended when they reflect on the harm, return to in-person\nsocial settings, or become frustrated by platform restrictions. Based on the\nimplications of our findings, we provide recommendations for future chatbot\ndesign so they can promote self-awareness, support real-world engagement, and\ninvolve teens in developing safer digital tools.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15783v1", "cate": "cs.HC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15239", "title": "Explainable Artificial Intelligence based Soft Evaluation Indicator for Arc Fault Diagnosis", "authors": ["Qianchao Wang", "Yuxuan Ding", "Chuanzhen Jia", "Zhe Li", "Yaping Du"], "categories": ["cs.AI", "eess.SP"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15239v1", "summary": "Novel AI-based arc fault diagnosis models have demonstrated outstanding\nperformance in terms of classification accuracy. However, an inherent problem\nis whether these models can actually be trusted to find arc faults. In this\nlight, this work proposes a soft evaluation indicator that explains the outputs\nof arc fault diagnosis models, by defining the the correct explanation of arc\nfaults and leveraging Explainable Artificial Intelligence and real arc fault\nexperiments. Meanwhile, a lightweight balanced neural network is proposed to\nguarantee competitive accuracy and soft feature extraction score. In our\nexperiments, several traditional machine learning methods and deep learning\nmethods across two arc fault datasets with different sample times and noise\nlevels are utilized to test the effectiveness of the soft evaluation indicator.\nThrough this approach, the arc fault diagnosis models are easy to understand\nand trust, allowing practitioners to make informed and trustworthy decisions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15239v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14503", "title": "Generative Distribution Distillation", "authors": ["Jiequan Cui", "Beier Zhu", "Qingshan Xu", "Xiaogang Xu", "Pengguang Chen", "Xiaojuan Qi", "Bei Yu", "Hanwang Zhang", "Richang Hong"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Technique report", "url": "http://arxiv.org/abs/2507.14503v1", "summary": "In this paper, we formulate the knowledge distillation (KD) as a conditional\ngenerative problem and propose the \\textit{Generative Distribution Distillation\n(GenDD)} framework. A naive \\textit{GenDD} baseline encounters two major\nchallenges: the curse of high-dimensional optimization and the lack of semantic\nsupervision from labels. To address these issues, we introduce a \\textit{Split\nTokenization} strategy, achieving stable and effective unsupervised KD.\nAdditionally, we develop the \\textit{Distribution Contraction} technique to\nintegrate label supervision into the reconstruction objective. Our theoretical\nproof demonstrates that \\textit{GenDD} with \\textit{Distribution Contraction}\nserves as a gradient-level surrogate for multi-task learning, realizing\nefficient supervised training without explicit classification loss on\nmulti-step sampling image representations. To evaluate the effectiveness of our\nmethod, we conduct experiments on balanced, imbalanced, and unlabeled data.\nExperimental results show that \\textit{GenDD} performs competitively in the\nunsupervised setting, significantly surpassing KL baseline by \\textbf{16.29\\%}\non ImageNet validation set. With label supervision, our ResNet-50 achieves\n\\textbf{82.28\\%} top-1 accuracy on ImageNet in 600 epochs training,\nestablishing a new state-of-the-art.", "comment": "Technique report", "pdf_url": "http://arxiv.org/pdf/2507.14503v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14596", "title": "DiSCO-3D : Discovering and segmenting Sub-Concepts from Open-vocabulary queries in NeRF", "authors": ["Doriand Petit", "Steve Bourgeois", "Vincent Gay-Bellile", "Florian Chabot", "Loïc Barthe"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Published at ICCV'25", "url": "http://arxiv.org/abs/2507.14596v1", "summary": "3D semantic segmentation provides high-level scene understanding for\napplications in robotics, autonomous systems, \\textit{etc}. Traditional methods\nadapt exclusively to either task-specific goals (open-vocabulary segmentation)\nor scene content (unsupervised semantic segmentation). We propose DiSCO-3D, the\nfirst method addressing the broader problem of 3D Open-Vocabulary Sub-concepts\nDiscovery, which aims to provide a 3D semantic segmentation that adapts to both\nthe scene and user queries. We build DiSCO-3D on Neural Fields representations,\ncombining unsupervised segmentation with weak open-vocabulary guidance. Our\nevaluations demonstrate that DiSCO-3D achieves effective performance in\nOpen-Vocabulary Sub-concepts Discovery and exhibits state-of-the-art results in\nthe edge cases of both open-vocabulary and unsupervised segmentation.", "comment": "Published at ICCV'25", "pdf_url": "http://arxiv.org/pdf/2507.14596v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15251", "title": "Input Reduction Enhanced LLM-based Program Repair", "authors": ["Boyang Yang", "Luyao Ren", "Xin Yin", "Jiadong Ren", "Haoye Tian", "Shunfu Jin"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15251v1", "summary": "Large Language Models (LLMs) have shown great potential in Automated Program\nRepair (APR). Test inputs, being crucial for reasoning the root cause of\nfailures, are always included in the prompt for LLM-based APR. Unfortunately,\nLLMs struggle to retain key information in long prompts. When the test inputs\nare extensive in the prompt, this may trigger the \"lost-in-the-middle\" issue,\ncompromising repair performance. To address this, we propose ReduceFix, an\nLLM-based APR approach with a built-in component that automatically reduces\ntest inputs while retaining their failure-inducing behavior. ReduceFix prompts\nan LLM to generate a reducer that minimizes failure-inducing test inputs\nwithout human effort, and then feeds the reduced failure-inducing inputs to\nguide patch generation.\n  For targeted evaluation, we constructed LFTBench, the first long-input APR\nbenchmark with 200 real bugs from 20 programming tasks, each paired with a\nfailure-inducing input whose median size is 1 MB. On this benchmark, ReduceFix\nshrinks inputs by 89.1% on average and improves overall pass@10 by up to 53.8%\nrelative to a prompt that includes the original test, and by 17.6% compared\nwith omitting the test entirely. Adding the same reduction step to ChatRepair\nincreases its fix rate by 21.3% without other changes. Ablation studies further\nhighlight the impact of input length and compressed failure information on\nrepair success. These results underscore that automatically reducing failing\ninputs is a practical and powerful complement to LLM-based APR, significantly\nimproving its scalability and effectiveness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15251v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15670", "title": "Vehicular Cloud Computing: A cost-effective alternative to Edge Computing in 5G networks", "authors": ["Rosario Patanè", "Nadjib Achir", "Andrea Araldo", "Lila Boukhatem"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15670v1", "summary": "Edge Computing (EC) is a computational paradigm that involves deploying\nresources such as CPUs and GPUs near end-users, enabling low-latency\napplications like augmented reality and real-time gaming. However, deploying\nand maintaining a vast network of EC nodes is costly, which can explain its\nlimited deployment today. A new paradigm called Vehicular Cloud Computing (VCC)\nhas emerged and inspired interest among researchers and industry. VCC\nopportunistically utilizes existing and idle vehicular computational resources\nfor external task offloading. This work is the first to systematically address\nthe following question: Can VCC replace EC for low-latency applications?\nAnswering this question is highly relevant for Network Operators (NOs), as VCC\ncould eliminate costs associated with EC given that it requires no\ninfrastructural investment. Despite its potential, no systematic study has yet\nexplored the conditions under which VCC can effectively support low-latency\napplications without relying on EC. This work aims to fill that gap. Extensive\nsimulations allow for assessing the crucial scenario factors that determine\nwhen this EC-to-VCC substitution is feasible. Considered factors are load,\nvehicles mobility and density, and availability. Potential for substitution is\nassessed based on multiple criteria, such as latency, task completion success,\nand cost. Vehicle mobility is simulated in SUMO, and communication in NS3\n5G-LENA. The findings show that VCC can effectively replace EC for low-latency\napplications, except in extreme cases when the EC is still required (latency <\n16 ms).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15670v1", "cate": "cs.NI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14155", "title": "Extreme Value Theory-based Distributed Interference Prediction for 6G Industrial Sub-networks", "authors": ["Pramesh Gautam", "Sushmita Sapkota", "Carsten Bockelmann", "Shashi Raj Pandey", "Armin Dekorsy"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14155v1", "summary": "Interference prediction that accounts for extreme and rare events remains a\nkey challenge for ultra-densely deployed sub-networks (SNs) requiring\nhyper-reliable low-latency communication (HRLLC), particularly under dynamic\nmobility, rapidly varying channel statistics, and sporadic traffic. This paper\nproposes a novel calibrated interference tail prediction framework, a hybrid\nstatistical and machine learning (ML) approach that integrates an inverted\nquantile patch transformer (iQPTransformer) within extreme value theory (EVT).\nIt captures interference dynamics and tail behavior while quantifying\nuncertainty to provide statistical coverage guarantees. Its effectiveness is\ndemonstrated by leveraging the estimated interference tail distribution to\ndesign predictive, risk-aware resource allocation. In resource-constrained SN\nscenarios, we introduce the split-iQPTransformer, enabling collaborative\ntraining by distributing neural network components between sensor-actuator (SA)\npairs and the SN controller, while maintaining minimal performance disparity\ncompared to the centralized iQPTransformer. The framework effectively handles\ndeep fading, random traffic, and time-division duplexing (TDD) misalignments\nand is resilient to rare and extreme interference events. Extensive evaluations\nare performed under two mobility models and two realistic SN traffic patterns,\nusing a spatially consistent 3GPP channel model across all scenarios.\nExperimental results show consistent achievement of block error rate (BLER)\ntargets beyond the 95th percentile in the hyper-reliable regime, significantly\noutperforming baseline approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14155v1", "cate": "eess.SP", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.15312", "title": "Idefix-Closed Languages and Their Application in Contextual Grammars", "authors": ["Marvin Ködding", "Bianca Truthe"], "categories": ["cs.FL"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      In Proceedings NCMA 2025, arXiv:2507.14082", "url": "http://arxiv.org/abs/2507.15312v1", "summary": "In this paper, we continue the research on the power of contextual grammars\nwith selection languages from subfamilies of the family of regular languages.\nWe investigate infix-, prefix-, and suffix-closed languages (referred to as\nidefix-closed languages) and compare such language families to some other\nsubregular families of languages (finite, monoidal, nilpotent, combinational,\n(symmetric) definite, ordered, non-counting, power-separating, commutative,\ncircular, union-free, star, and comet languages). Further, we compare the\nfamilies of the hierarchies obtained for external and internal contextual\ngrammars with the language families defined by these new types for the\nselection. In this way, we extend the existing hierarchies by new language\nfamilies. Moreover, we solve an open problem regarding internal contextual\ngrammars with suffix-closed selection languages.", "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "pdf_url": "http://arxiv.org/pdf/2507.15312v1", "cate": "cs.FL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.03619", "title": "Blackbox Dataset Inference for LLM", "authors": ["Ruikai Zhou", "Kang Yang", "Xun Chen", "Wendy Hui Wang", "Guanhong Tao", "Jun Xu"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03619v2", "summary": "Today, the training of large language models (LLMs) can involve personally\nidentifiable information and copyrighted material, incurring dataset misuse. To\nmitigate the problem of dataset misuse, this paper explores \\textit{dataset\ninference}, which aims to detect if a suspect model $\\mathcal{M}$ used a victim\ndataset $\\mathcal{D}$ in training. Previous research tackles dataset inference\nby aggregating results of membership inference attacks (MIAs) -- methods to\ndetermine whether individual samples are a part of the training dataset.\nHowever, restricted by the low accuracy of MIAs, previous research mandates\ngrey-box access to $\\mathcal{M}$ to get intermediate outputs (probabilities,\nloss, perplexity, etc.) for obtaining satisfactory results. This leads to\nreduced practicality, as LLMs, especially those deployed for profits, have\nlimited incentives to return the intermediate outputs.\n  In this paper, we propose a new method of dataset inference with only\nblack-box access to the target model (i.e., assuming only the text-based\nresponses of the target model are available). Our method is enabled by two sets\nof locally built reference models, one set involving $\\mathcal{D}$ in training\nand the other not. By measuring which set of reference model $\\mathcal{M}$ is\ncloser to, we determine if $\\mathcal{M}$ used $\\mathcal{D}$ for training.\nEvaluations of real-world LLMs in the wild show that our method offers high\naccuracy in all settings and presents robustness against bypassing attempts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03619v2", "cate": "cs.CR", "date": "2025-07-04", "updated": "2025-07-18"}
{"id": "2507.14190", "title": "Traffic Signal Phase and Timing Estimation with Large-Scale Floating Car Data", "authors": ["Mingcheng Liao", "Zebang Feng", "Miao Fan", "Shengtong Xu", "Haoyi Xiong"], "categories": ["eess.SP", "cs.RO"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted by ITSC'25", "url": "http://arxiv.org/abs/2507.14190v1", "summary": "Effective modern transportation systems depend critically on accurate Signal\nPhase and Timing (SPaT) estimation. However, acquiring ground-truth SPaT\ninformation faces significant hurdles due to communication challenges with\ntransportation departments and signal installers. As a result, Floating Car\nData (FCD) has become the primary source for large-scale SPaT analyses. Current\nFCD approaches often simplify the problem by assuming fixed schedules and basic\nintersection designs for specific times and locations. These methods fail to\naccount for periodic signal changes, diverse intersection structures, and the\ninherent limitations of real-world data, thus lacking a comprehensive framework\nthat is universally applicable. Addressing this limitation, we propose an\nindustrial-grade FCD analysis suite that manages the entire process, from\ninitial data preprocessing to final SPaT estimation. Our approach estimates\nsignal phases, identifies time-of-day (TOD) periods, and determines the\ndurations of red and green lights. The framework's notable stability and\nrobustness across diverse conditions, regardless of road geometry, is a key\nfeature. Furthermore, we provide a cleaned, de-identified FCD dataset and\nsupporting parameters to facilitate future research. Currently operational\nwithin our navigation platform, the system analyses over 15 million FCD records\ndaily, supporting over two million traffic signals in mainland China, with more\nthan 75\\% of estimations demonstrating less than five seconds of error.", "comment": "Accepted by ITSC'25", "pdf_url": "http://arxiv.org/pdf/2507.14190v1", "cate": "eess.SP", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.08006", "title": "Scalable Climate Data Analysis: Balancing Petascale Fidelity and Computational Cost", "authors": ["Aashish Panta", "Amy Gooch", "Giorgio Scorzelli", "Michela Taufer", "Valerio Pascucci"], "categories": ["physics.ao-ph", "cs.HC"], "primary_category": "Subjects:       Atmospheric and Oceanic Physics (physics.ao-ph)", "pdf_link": null, "comments": "Comments:      Presented at The CCGRID International Scalable Computing Challenge (SCALE), 2025", "url": "http://arxiv.org/abs/2507.08006v1", "summary": "The growing resolution and volume of climate data from remote sensing and\nsimulations pose significant storage, processing, and computational challenges.\nTraditional compression or subsampling methods often compromise data fidelity,\nlimiting scientific insights. We introduce a scalable ecosystem that integrates\nhierarchical multiresolution data management, intelligent transmission, and\nML-assisted reconstruction to balance accuracy and efficiency. Our approach\nreduces storage and computational costs by 99\\%, lowering expenses from\n\\$100,000 to \\$24 while maintaining a Root Mean Square (RMS) error of 1.46\ndegrees Celsius. Our experimental results confirm that even with significant\ndata reduction, essential features required for accurate climate analysis are\npreserved. Validated on petascale NASA climate datasets, this solution enables\ncost-effective, high-fidelity climate analysis for research and\ndecision-making.", "comment": "Presented at The CCGRID International Scalable Computing Challenge\n  (SCALE), 2025", "pdf_url": "http://arxiv.org/pdf/2507.08006v1", "cate": "physics.ao-ph", "date": "2025-06-25", "updated": "2025-06-25"}
{"id": "2507.15330", "title": "QSAF: A Novel Mitigation Framework for Cognitive Degradation in Agentic AI", "authors": ["Hammad Atta", "Muhammad Zeeshan Baig", "Yasir Mehmood", "Nadeem Shahzad", "Ken Huang", "Muhammad Aziz Ul Haq", "Muhammad Awais", "Kamal Ahmed"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15330v1", "summary": "We introduce Cognitive Degradation as a novel vulnerability class in agentic\nAI systems. Unlike traditional adversarial external threats such as prompt\ninjection, these failures originate internally, arising from memory starvation,\nplanner recursion, context flooding, and output suppression. These systemic\nweaknesses lead to silent agent drift, logic collapse, and persistent\nhallucinations over time. To address this class of failures, we introduce the\nQorvex Security AI Framework for Behavioral & Cognitive Resilience (QSAF Domain\n10), a lifecycle-aware defense framework defined by a six-stage cognitive\ndegradation lifecycle. The framework includes seven runtime controls\n(QSAF-BC-001 to BC-007) that monitor agent subsystems in real time and trigger\nproactive mitigation through fallback routing, starvation detection, and memory\nintegrity enforcement. Drawing from cognitive neuroscience, we map agentic\narchitectures to human analogs, enabling early detection of fatigue,\nstarvation, and role collapse. By introducing a formal lifecycle and real-time\nmitigation controls, this work establishes Cognitive Degradation as a critical\nnew class of AI system vulnerability and proposes the first cross-platform\ndefense model for resilient agentic behavior.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15330v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14516", "title": "SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning", "authors": ["Jeyoung Lee", "Hochul Kang"], "categories": ["cs.LG", "cs.AI", "cs.LO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14516v1", "summary": "We propose the Signal Dice Similarity Coefficient (SDSC), a structure-aware\nmetric function for time series self-supervised representation learning. Most\nSelf-Supervised Learning (SSL) methods for signals commonly adopt\ndistance-based objectives such as mean squared error (MSE), which are sensitive\nto amplitude, invariant to waveform polarity, and unbounded in scale. These\nproperties hinder semantic alignment and reduce interpretability. SDSC\naddresses this by quantifying structural agreement between temporal signals\nbased on the intersection of signed amplitudes, derived from the Dice\nSimilarity Coefficient (DSC).Although SDSC is defined as a structure-aware\nmetric, it can be used as a loss by subtracting from 1 and applying a\ndifferentiable approximation of the Heaviside function for gradient-based\noptimization. A hybrid loss formulation is also proposed to combine SDSC with\nMSE, improving stability and preserving amplitude where necessary. Experiments\non forecasting and classification benchmarks demonstrate that SDSC-based\npre-training achieves comparable or improved performance over MSE, particularly\nin in-domain and low-resource scenarios. The results suggest that structural\nfidelity in signal representations enhances the semantic representation\nquality, supporting the consideration of structure-aware metrics as viable\nalternatives to conventional distance-based methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14516v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14608", "title": "Exp-Graph: How Connections Learn Facial Attributes in Graph-based Expression Recognition", "authors": ["Nandani Sharma", "Dinesh Singh"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14608v1", "summary": "Facial expression recognition is crucial for human-computer interaction\napplications such as face animation, video surveillance, affective computing,\nmedical analysis, etc. Since the structure of facial attributes varies with\nfacial expressions, incorporating structural information into facial attributes\nis essential for facial expression recognition. In this paper, we propose\nExp-Graph, a novel framework designed to represent the structural relationships\namong facial attributes using graph-based modeling for facial expression\nrecognition. For facial attributes graph representation, facial landmarks are\nused as the graph's vertices. At the same time, the edges are determined based\non the proximity of the facial landmark and the similarity of the local\nappearance of the facial attributes encoded using the vision transformer.\nAdditionally, graph convolutional networks are utilized to capture and\nintegrate these structural dependencies into the encoding of facial attributes,\nthereby enhancing the accuracy of expression recognition. Thus, Exp-Graph\nlearns from the facial attribute graphs highly expressive semantic\nrepresentations. On the other hand, the vision transformer and graph\nconvolutional blocks help the framework exploit the local and global\ndependencies among the facial attributes that are essential for the recognition\nof facial expressions. We conducted comprehensive evaluations of the proposed\nExp-Graph model on three benchmark datasets: Oulu-CASIA, eNTERFACE05, and AFEW.\nThe model achieved recognition accuracies of 98.09\\%, 79.01\\%, and 56.39\\%,\nrespectively. These results indicate that Exp-Graph maintains strong\ngeneralization capabilities across both controlled laboratory settings and\nreal-world, unconstrained environments, underscoring its effectiveness for\npractical facial expression recognition applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14608v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15296", "title": "Butterfly Effects in Toolchains: A Comprehensive Analysis of Failed Parameter Filling in LLM Tool-Agent Systems", "authors": ["Qian Xiong", "Yuekai Huang", "Ziyou Jiang", "Zhiyuan Chang", "Yujia Zheng", "Tianhao Li", "Mingyang Li"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15296v1", "summary": "The emergence of the tool agent paradigm has broadened the capability\nboundaries of the Large Language Model (LLM), enabling it to complete more\ncomplex tasks. However, the effectiveness of this paradigm is limited due to\nthe issue of parameter failure during its execution. To explore this phenomenon\nand propose corresponding suggestions, we first construct a parameter failure\ntaxonomy in this paper. We derive five failure categories from the invocation\nchain of a mainstream tool agent. Then, we explore the correlation between\nthree different input sources and failure categories by applying 15 input\nperturbation methods to the input. Experimental results show that parameter\nname hallucination failure primarily stems from inherent LLM limitations, while\nissues with input sources mainly cause other failure patterns. To improve the\nreliability and effectiveness of tool-agent interactions, we propose\ncorresponding improvement suggestions, including standardizing tool return\nformats, improving error feedback mechanisms, and ensuring parameter\nconsistency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15296v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15673", "title": "Point Cloud Streaming with Latency-Driven Implicit Adaptation using MoQ", "authors": ["Andrew Freeman", "Michael Rudolph", "Amr Rizk"], "categories": ["cs.MM", "cs.NI"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15673v1", "summary": "Point clouds are a promising video representation for next-generation\nmultimedia experiences in virtual and augmented reality. Point clouds are\nnotoriously high-bitrate, however, which limits the feasibility of live\nstreaming systems. Prior methods have adopted traditional HTTP-based protocols\nfor point cloud streaming, but they rely on explicit client-side adaptation to\nmaintain low latency under congestion. In this work, we leverage the delivery\ntimeout feature within the Media Over QUIC protocol to perform implicit\nserver-side adaptation based on an application's latency target. Through\nexperimentation with several publisher and network configurations, we\ndemonstrate that our system unlocks a unique trade-off on a per-client basis:\napplications with lower latency requirements will receive lower-quality video,\nwhile applications with more relaxed latency requirements will receive\nhigher-quality video.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15673v1", "cate": "cs.MM", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14169", "title": "CQI-Based Interference Prediction for Link Adaptation in Industrial Sub-networks", "authors": ["Pramesh Gautam", "Ravi Sharan B A G", "Paolo Baracca", "Carsten Bockelmann", "Thorsten Wild", "Armin Dekorsy"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14169v1", "summary": "We propose a novel interference prediction scheme to improve link adaptation\n(LA) in densely deployed industrial sub-networks (SNs) with high-reliability\nand low-latency communication (HRLLC) requirements. The proposed method aims to\nimprove the LA framework by predicting and leveraging the heavy-tailed\ninterference probability density function (pdf). Interference is modeled as a\nlatent vector of available channel quality indicator (CQI), using a vector\ndiscrete-time state-space model (vDSSM) at the SN controller, where the CQI is\nsubjected to compression, quantization, and delay-induced errors. To robustly\nestimate interference power values under these impairments, we employ a\nlow-complexity, outlier-robust, sparse Student-t process regression (SPTPR)\nmethod. This is integrated into a modified unscented Kalman filter, which\nrecursively refines predicted interference using CQI, enabling accurate\nestimation and compensating protocol feedback delays, crucial for accurate LA.\nNumerical results show that the proposed method achieves over 10x lower\ncomplexity compared to a similar non-parametric baseline. It also maintains a\nBLER below the 90th percentile target of 1e-6 while delivering performance\ncomparable to a state-of-the-art supervised technique using only CQI reports.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14169v1", "cate": "eess.SP", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.15313", "title": "On a Generalization of the Christoffel Tree: Epichristoffel Trees", "authors": ["Abhishek Krishnamoorthy", "Robinson Thamburaj", "Durairaj Gnanaraj Thomas"], "categories": ["cs.FL", "G.2.1:F.2.2"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      In Proceedings NCMA 2025, arXiv:2507.14082", "url": "http://arxiv.org/abs/2507.15313v1", "summary": "Sturmian words form a family of one-sided infinite words over a binary\nalphabet that are obtained as a discretization of a line with an irrational\nslope starting from the origin. A finite version of this class of words called\nChristoffel words has been extensively studied for their interesting\nproperties. It is a class of words that has a geometric and an algebraic\ndefinition, making it an intriguing topic of study for many mathematicians.\nRecently, a generalization of Christoffel words for an alphabet with 3 letters\nor more, called epichristoffel words, using episturmian morphisms has been\nstudied, and many of the properties of Christoffel words have been shown to\ncarry over to epichristoffel words; however, many properties are not shared by\nthem as well. In this paper, we introduce the notion of an epichristoffel tree,\nwhich proves to be a useful tool in determining a subclass of epichristoffel\nwords that share an important property of Christoffel words, which is the\nability to factorize an epichristoffel word as a product of smaller\nepichristoffel words. We also use the epichristoffel tree to present some\ninteresting results that help to better understand epichristoffel words.", "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "pdf_url": "http://arxiv.org/pdf/2507.15313v1", "cate": "cs.FL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.13023", "title": "Measuring CEX-DEX Extracted Value and Searcher Profitability: The Darkest of the MEV Dark Forest", "authors": ["Fei Wu", "Danning Sui", "Thomas Thiery", "Mallesh Pai"], "categories": ["cs.CR", "q-fin.TR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted by AFT 2025", "url": "http://arxiv.org/abs/2507.13023v2", "summary": "This paper provides a comprehensive empirical analysis of the economics and\ndynamics behind arbitrages between centralized and decentralized exchanges\n(CEX-DEX) on Ethereum. We refine heuristics to identify arbitrage transactions\nfrom on-chain data and introduce a robust empirical framework to estimate\narbitrage revenue without knowing traders' actual behaviors on CEX. Leveraging\nan extensive dataset spanning 19 months from August 2023 to March 2025, we\nestimate a total of 233.8M USD extracted by 19 major CEX-DEX searchers from\n7,203,560 identified CEX-DEX arbitrages. Our analysis reveals increasing\ncentralization trends as three searchers captured three-quarters of both volume\nand extracted value. We also demonstrate that searchers' profitability is tied\nto their integration level with block builders and uncover exclusive\nsearcher-builder relationships and their market impact. Finally, we correct the\npreviously underestimated profitability of block builders who vertically\nintegrate with a searcher. These insights illuminate the darkest corner of the\nMEV landscape and highlight the critical implications of CEX-DEX arbitrages for\nEthereum's decentralization.", "comment": "Accepted by AFT 2025", "pdf_url": "http://arxiv.org/pdf/2507.13023v2", "cate": "cs.CR", "date": "2025-07-17", "updated": "2025-07-19"}
{"id": "2507.14809", "title": "Light Future: Multimodal Action Frame Prediction via InstructPix2Pix", "authors": ["Zesen Zhong", "Duomin Zhang", "Yijia Li"], "categories": ["cs.CV", "cs.MM", "cs.RO", "I.2.10; I.4.8"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      9 pages including appendix, 5 tables, 8 figures, to be submitted to WACV 2026", "url": "http://arxiv.org/abs/2507.14809v1", "summary": "Predicting future motion trajectories is a critical capability across domains\nsuch as robotics, autonomous systems, and human activity forecasting, enabling\nsafer and more intelligent decision-making. This paper proposes a novel,\nefficient, and lightweight approach for robot action prediction, offering\nsignificantly reduced computational cost and inference latency compared to\nconventional video prediction models. Importantly, it pioneers the adaptation\nof the InstructPix2Pix model for forecasting future visual frames in robotic\ntasks, extending its utility beyond static image editing. We implement a deep\nlearning-based visual prediction framework that forecasts what a robot will\nobserve 100 frames (10 seconds) into the future, given a current image and a\ntextual instruction. We repurpose and fine-tune the InstructPix2Pix model to\naccept both visual and textual inputs, enabling multimodal future frame\nprediction. Experiments on the RoboTWin dataset (generated based on real-world\nscenarios) demonstrate that our method achieves superior SSIM and PSNR compared\nto state-of-the-art baselines in robot action prediction tasks. Unlike\nconventional video prediction models that require multiple input frames, heavy\ncomputation, and slow inference latency, our approach only needs a single image\nand a text prompt as input. This lightweight design enables faster inference,\nreduced GPU demands, and flexible multimodal control, particularly valuable for\napplications like robotics and sports motion trajectory analytics, where motion\ntrajectory precision is prioritized over visual fidelity.", "comment": "9 pages including appendix, 5 tables, 8 figures, to be submitted to\n  WACV 2026", "pdf_url": "http://arxiv.org/pdf/2507.14809v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14173", "title": "Enhancing Generalization in PPG-Based Emotion Measurement with a CNN-TCN-LSTM Model", "authors": ["Karim Alghoul", "Hussein Al Osman", "Abdulmotaleb El Saddik"], "categories": ["eess.SP", "cs.HC", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE International Instrumentation and Measurement Technology Conference (I2MTC) 2025", "url": "http://arxiv.org/abs/2507.14173v1", "summary": "Human computer interaction has become integral to modern life, driven by\nadvancements in machine learning technologies. Affective computing, in\nparticular, has focused on systems that recognize, interpret, and respond to\nhuman emotions, often using wearable devices, which provide continuous data\nstreams of physiological signals. Among various physiological signals, the\nphotoplethysmogram (PPG) has gained prominence due to its ease of acquisition\nfrom widely available devices. However, the generalization of PPG-based emotion\nrecognition models across individuals remains an unresolved challenge. This\npaper introduces a novel hybrid architecture that combines Convolutional Neural\nNetworks (CNNs), Long Short-Term Memory networks (LSTMs), and Temporal\nConvolutional Networks (TCNs) to address this issue. The proposed model\nintegrates the strengths of these architectures to improve robustness and\ngeneralization. Raw PPG signals are fed into the CNN for feature extraction.\nThese features are processed separately by LSTM and TCN. The outputs from these\ncomponents are concatenated to generate a final feature representation, which\nserves as the input for classifying valence and arousal, the primary dimensions\nof emotion. Experiments using the Photoplethysmogram Dataset for Emotional\nAnalysis (PPGE) demonstrate that the proposed hybrid model achieves better\nmodel generalization than standalone CNN and LSTM architectures. Our results\nshow that the proposed solution outperforms the state-of-the-art CNN\narchitecture, as well as a CNN-LSTM model, in emotion recognition tasks with\nPPG signals. Using metrics such as Area Under the Curve (AUC) and F1 Score, we\nhighlight the model's effectiveness in handling subject variability.", "comment": "Accepted by IEEE International Instrumentation and Measurement\n  Technology Conference (I2MTC) 2025", "pdf_url": "http://arxiv.org/pdf/2507.14173v1", "cate": "eess.SP", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.15356", "title": "RAD: Retrieval High-quality Demonstrations to Enhance Decision-making", "authors": ["Lu Guo", "Yixiang Shan", "Zhengbang Zhu", "Qifan Liang", "Lichang Song", "Ting Long", "Weinan Zhang", "Yi Chang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15356v1", "summary": "Offline reinforcement learning (RL) enables agents to learn policies from\nfixed datasets, avoiding costly or unsafe environment interactions. However,\nits effectiveness is often limited by dataset sparsity and the lack of\ntransition overlap between suboptimal and expert trajectories, which makes\nlong-horizon planning particularly challenging. Prior solutions based on\nsynthetic data augmentation or trajectory stitching often fail to generalize to\nnovel states and rely on heuristic stitching points. To address these\nchallenges, we propose Retrieval High-quAlity Demonstrations (RAD) for\ndecision-making, which combines non-parametric retrieval with diffusion-based\ngenerative modeling. RAD dynamically retrieves high-return states from the\noffline dataset as target states based on state similarity and return\nestimation, and plans toward them using a condition-guided diffusion model.\nSuch retrieval-guided generation enables flexible trajectory stitching and\nimproves generalization when encountered with underrepresented or\nout-of-distribution states. Extensive experiments confirm that RAD achieves\ncompetitive or superior performance compared to baselines across diverse\nbenchmarks, validating its effectiveness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15356v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14528", "title": "Positive-Unlabeled Learning for Control Group Construction in Observational Causal Inference", "authors": ["Ilias Tsoumas", "Dimitrios Bormpoudakis", "Vasileios Sitokonstantinou", "Athanasios Askitopoulos", "Andreas Kalogeras", "Charalampos Kontoes", "Ioannis Athanasiadis"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at KDD 2025 Workshop on Causal Inference and Machine Learning in Practice", "url": "http://arxiv.org/abs/2507.14528v1", "summary": "In causal inference, whether through randomized controlled trials or\nobservational studies, access to both treated and control units is essential\nfor estimating the effect of a treatment on an outcome of interest. When\ntreatment assignment is random, the average treatment effect (ATE) can be\nestimated directly by comparing outcomes between groups. In non-randomized\nsettings, various techniques are employed to adjust for confounding and\napproximate the counterfactual scenario to recover an unbiased ATE. A common\nchallenge, especially in observational studies, is the absence of units clearly\nlabeled as controls-that is, units known not to have received the treatment. To\naddress this, we propose positive-unlabeled (PU) learning as a framework for\nidentifying, with high confidence, control units from a pool of unlabeled ones,\nusing only the available treated (positive) units. We evaluate this approach\nusing both simulated and real-world data. We construct a causal graph with\ndiverse relationships and use it to generate synthetic data under various\nscenarios, assessing how reliably the method recovers control groups that allow\nestimates of true ATE. We also apply our approach to real-world data on optimal\nsowing and fertilizer treatments in sustainable agriculture. Our findings show\nthat PU learning can successfully identify control (negative) units from\nunlabeled data based only on treated units and, through the resulting control\ngroup, estimate an ATE that closely approximates the true value. This work has\nimportant implications for observational causal inference, especially in fields\nwhere randomized experiments are difficult or costly. In domains such as earth,\nenvironmental, and agricultural sciences, it enables a plethora of\nquasi-experiments by leveraging available earth observation and climate data,\nparticularly when treated units are available but control units are lacking.", "comment": "Accepted at KDD 2025 Workshop on Causal Inference and Machine\n  Learning in Practice", "pdf_url": "http://arxiv.org/pdf/2507.14528v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14613", "title": "Depthwise-Dilated Convolutional Adapters for Medical Object Tracking and Segmentation Using the Segment Anything Model 2", "authors": ["Guoping Xu", "Christopher Kabat", "You Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      24 pages, 6 figures", "url": "http://arxiv.org/abs/2507.14613v1", "summary": "Recent advances in medical image segmentation have been driven by deep\nlearning; however, most existing methods remain limited by modality-specific\ndesigns and exhibit poor adaptability to dynamic medical imaging scenarios. The\nSegment Anything Model 2 (SAM2) and its related variants, which introduce a\nstreaming memory mechanism for real-time video segmentation, present new\nopportunities for prompt-based, generalizable solutions. Nevertheless, adapting\nthese models to medical video scenarios typically requires large-scale datasets\nfor retraining or transfer learning, leading to high computational costs and\nthe risk of catastrophic forgetting. To address these challenges, we propose\nDD-SAM2, an efficient adaptation framework for SAM2 that incorporates a\nDepthwise-Dilated Adapter (DD-Adapter) to enhance multi-scale feature\nextraction with minimal parameter overhead. This design enables effective\nfine-tuning of SAM2 on medical videos with limited training data. Unlike\nexisting adapter-based methods focused solely on static images, DD-SAM2 fully\nexploits SAM2's streaming memory for medical video object tracking and\nsegmentation. Comprehensive evaluations on TrackRad2025 (tumor segmentation)\nand EchoNet-Dynamic (left ventricle tracking) datasets demonstrate superior\nperformance, achieving Dice scores of 0.93 and 0.97, respectively. To the best\nof our knowledge, this work provides an initial attempt at systematically\nexploring adapter-based SAM2 fine-tuning for medical video segmentation and\ntracking. Code, datasets, and models will be publicly available at\nhttps://github.com/apple1986/DD-SAM2.", "comment": "24 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.14613v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15343", "title": "StackTrans: From Large Language Model to Large Pushdown Automata Model", "authors": ["Kechi Zhang", "Ge Li", "Jia Li", "Huangzhao Zhang", "Yihong Dong", "Jia Li", "Jingjing Xu", "Zhi Jin"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      currently under development", "url": "http://arxiv.org/abs/2507.15343v1", "summary": "The Transformer architecture has emerged as a landmark advancement within the\nbroad field of artificial intelligence, effectively catalyzing the advent of\nlarge language models (LLMs). However, despite its remarkable capabilities and\nthe substantial progress it has facilitated, the Transformer architecture still\nhas some limitations. One such intrinsic limitation is its inability to\neffectively capture the Chomsky hierarchy, such as regular expressions or\ndeterministic context-free grammars. Drawing inspiration from pushdown\nautomata, which efficiently resolve deterministic context-free grammars using\nstacks, we propose StackTrans to address the aforementioned issue within LLMs.\nUnlike previous approaches that modify the attention computation, StackTrans\nexplicitly incorporates hidden state stacks between Transformer layers. This\ndesign maintains compatibility with existing frameworks like flash-attention.\nSpecifically, our design features stack operations -- such as pushing and\npopping hidden states -- that are differentiable and can be learned in an\nend-to-end manner. Our comprehensive evaluation spans benchmarks for both\nChomsky hierarchies and large-scale natural languages. Across these diverse\ntasks, StackTrans consistently outperforms standard Transformer models and\nother baselines. We have successfully scaled StackTrans up from 360M to 7B\nparameters. In particular, our from-scratch pretrained model StackTrans-360M\noutperforms several larger open-source LLMs with 2-3x more parameters,\nshowcasing its superior efficiency and reasoning capability.", "comment": "currently under development", "pdf_url": "http://arxiv.org/pdf/2507.15343v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15816", "title": "Federated Split Learning with Improved Communication and Storage Efficiency", "authors": ["Yujia Mu", "Cong Shen"], "categories": ["cs.LG", "cs.IT", "cs.NI", "eess.SP", "math.IT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted for publication in IEEE Transactions on Mobile Computing", "url": "http://arxiv.org/abs/2507.15816v1", "summary": "Federated learning (FL) is one of the popular distributed machine learning\n(ML) solutions but incurs significant communication and computation costs at\nedge devices. Federated split learning (FSL) can train sub-models in parallel\nand reduce the computational burden of edge devices by splitting the model\narchitecture. However, it still requires a high communication overhead due to\ntransmitting the smashed data and gradients between clients and the server in\nevery global round. Furthermore, the server must maintain separate partial\nmodels for every client, leading to a significant storage requirement. To\naddress these challenges, this paper proposes a novel communication and storage\nefficient federated split learning method, termed CSE-FSL, which utilizes an\nauxiliary network to locally update the weights of the clients while keeping a\nsingle model at the server, hence avoiding frequent transmissions of gradients\nfrom the server and greatly reducing the storage requirement of the server.\nAdditionally, a new model update method of transmitting the smashed data in\nselected epochs can reduce the amount of smashed data sent from the clients. We\nprovide a theoretical analysis of CSE-FSL, rigorously guaranteeing its\nconvergence under non-convex loss functions. The extensive experimental results\nfurther indicate that CSE-FSL achieves a significant communication reduction\nover existing FSL solutions using real-world FL tasks.", "comment": "Accepted for publication in IEEE Transactions on Mobile Computing", "pdf_url": "http://arxiv.org/pdf/2507.15816v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14228", "title": "Design of A New Multiple-Chirp-Rate Index Modulation for LoRa Networks", "authors": ["Xiaobin Zhu", "Minling Zhang", "Guofa Cai", "Jiguang He", "Georges Kaddoum"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      13 pages,11 figures,3 tables", "url": "http://arxiv.org/abs/2507.14228v1", "summary": "We propose a multiple chirp rate index modulation (MCR-IM) system based on\nZadoff-Chu (ZC) sequences that overcomes the problems of low transmission rate\nand large-scale access in classical LoRa networks. We demonstrate the extremely\nlow cross-correlation of MCR-IM signals across different spread factors,\nshowing that the proposed MCR-IM system also inherits the characteristics of ZC\nsequences modulation. Moreover, we derive an approximate closed-form expression\nfor the bit-error rate (BER) of the proposed MCR-IM system over Nakagami-m\nfading channels. Simulation results confirm the accuracy of the derived\nclosed-form expression and demonstrate that the MCR-IM system achieves higher\nlevels of spectral efficiency (SE) compared to existing systems. In this\ncontext, assigning multiple chirp rates to each user results in a reduction in\nthe number of parallel channels. To mitigate this issue, we propose a peak\ndetection based successive interference cancellation (PD-SIC) algorithm to\naccommodate more users. Compared to orthogonal scatter chirp spreading spectrum\nsystem that names OrthoRa, the MCR-IM system with PD-SIC algorithm achieves\nlower BER levels. For a similar number of collision signals, the throughput of\nthe MCR-IM system is enhanced by 16% to 21%. Owing to these advantages, the\nproposed MCR-IM is well suited for large-scale, high-rate LoRa network\napplications.", "comment": "13 pages,11 figures,3 tables", "pdf_url": "http://arxiv.org/pdf/2507.14228v1", "cate": "eess.SP", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.15314", "title": "Orchestration of Music by Grammar Systems", "authors": ["Jozef Makiš", "Alexander Meduna", "Zbyněk Křivka"], "categories": ["cs.FL", "F.4.3; H.5.5"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      In Proceedings NCMA 2025, arXiv:2507.14082", "url": "http://arxiv.org/abs/2507.15314v1", "summary": "This application-oriented study concerns computational musicology, which\nmakes use of grammar systems. We define multi-generative rule-synchronized\nscattered-context grammar systems (without erasing rules) and demonstrates how\nto simultaneously make the arrangement of a musical composition for performance\nby a whole orchestra, consisting of several instruments. Primarily, an\norchestration like this is illustrated by examples in terms of classical music.\nIn addition, the orchestration of jazz compositions is sketched as well. The\nstudy concludes its discussion by suggesting five open problem areas related to\nthis way of orchestration.", "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "pdf_url": "http://arxiv.org/pdf/2507.15314v1", "cate": "cs.FL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2310.02554", "title": "zkFL: Zero-Knowledge Proof-based Gradient Aggregation for Federated Learning", "authors": ["Zhipeng Wang", "Nanqing Dong", "Jiahao Sun", "William Knottenbelt", "Yike Guo"], "categories": ["cs.AI", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE Transactions on Big Data", "url": "http://arxiv.org/abs/2310.02554v5", "summary": "Federated learning (FL) is a machine learning paradigm, which enables\nmultiple and decentralized clients to collaboratively train a model under the\norchestration of a central aggregator. FL can be a scalable machine learning\nsolution in big data scenarios. Traditional FL relies on the trust assumption\nof the central aggregator, which forms cohorts of clients honestly. However, a\nmalicious aggregator, in reality, could abandon and replace the client's\ntraining models, or insert fake clients, to manipulate the final training\nresults. In this work, we introduce zkFL, which leverages zero-knowledge proofs\nto tackle the issue of a malicious aggregator during the training model\naggregation process. To guarantee the correct aggregation results, the\naggregator provides a proof per round, demonstrating to the clients that the\naggregator executes the intended behavior faithfully. To further reduce the\nverification cost of clients, we use blockchain to handle the proof in a\nzero-knowledge way, where miners (i.e., the participants validating and\nmaintaining the blockchain data) can verify the proof without knowing the\nclients' local and aggregated models. The theoretical analysis and empirical\nresults show that zkFL achieves better security and privacy than traditional\nFL, without modifying the underlying FL network structure or heavily\ncompromising the training speed.", "comment": "Accepted by IEEE Transactions on Big Data", "pdf_url": "http://arxiv.org/pdf/2310.02554v5", "cate": "cs.AI", "date": "2023-10-04", "updated": "2025-07-21"}
{"id": "2507.14850", "title": "Hierarchical Multi-Agent Reinforcement Learning with Control Barrier Functions for Safety-Critical Autonomous Systems", "authors": ["H. M. Sabbir Ahmad", "Ehsan Sabouni", "Alexander Wasilkoff", "Param Budhraja", "Zijian Guo", "Songyuan Zhang", "Chuchu Fan", "Christos Cassandras", "Wenchao Li"], "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14850v1", "summary": "We address the problem of safe policy learning in multi-agent safety-critical\nautonomous systems. In such systems, it is necessary for each agent to meet the\nsafety requirements at all times while also cooperating with other agents to\naccomplish the task. Toward this end, we propose a safe Hierarchical\nMulti-Agent Reinforcement Learning (HMARL) approach based on Control Barrier\nFunctions (CBFs). Our proposed hierarchical approach decomposes the overall\nreinforcement learning problem into two levels learning joint cooperative\nbehavior at the higher level and learning safe individual behavior at the lower\nor agent level conditioned on the high-level policy. Specifically, we propose a\nskill-based HMARL-CBF algorithm in which the higher level problem involves\nlearning a joint policy over the skills for all the agents and the lower-level\nproblem involves learning policies to execute the skills safely with CBFs. We\nvalidate our approach on challenging environment scenarios whereby a large\nnumber of agents have to safely navigate through conflicting road networks.\nCompared with existing state of the art methods, our approach significantly\nimproves the safety achieving near perfect (within 5%) success/safety rate\nwhile also improving performance across all the environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14850v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14242", "title": "Culling Misinformation from Gen AI: Toward Ethical Curation and Refinement", "authors": ["Prerana Khatiwada", "Grace Donaher", "Jasymyn Navarro", "Lokesh Bhatta"], "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      7 pages", "url": "http://arxiv.org/abs/2507.14242v1", "summary": "While Artificial Intelligence (AI) is not a new field, recent developments,\nespecially with the release of generative tools like ChatGPT, have brought it\nto the forefront of the minds of industry workers and academic folk alike.\nThere is currently much talk about AI and its ability to reshape many everyday\nprocesses as we know them through automation. It also allows users to expand\ntheir ideas by suggesting things they may not have thought of on their own and\nprovides easier access to information. However, not all of the changes this\ntechnology will bring or has brought so far are positive; this is why it is\nextremely important for all modern people to recognize and understand the risks\nbefore using these tools and allowing them to cause harm. This work takes a\nposition on better understanding many equity concerns and the spread of\nmisinformation that result from new AI, in this case, specifically ChatGPT and\ndeepfakes, and encouraging collaboration with law enforcement, developers, and\nusers to reduce harm. Considering many academic sources, it warns against these\nissues, analyzing their cause and impact in fields including healthcare,\neducation, science, academia, retail, and finance. Lastly, we propose a set of\nfuture-facing guidelines and policy considerations to solve these issues while\nstill enabling innovation in these fields, this responsibility falling upon\nusers, developers, and government entities.", "comment": "7 pages", "pdf_url": "http://arxiv.org/pdf/2507.14242v1", "cate": "cs.CY", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.15411", "title": "Predictive Process Monitoring Using Object-centric Graph Embeddings", "authors": ["Wissam Gherissi", "Mehdi Acheli", "Joyce El Haddad", "Daniela Grigori"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      ICSOC Workshops 2024, Dec 2024, Tunis, Tunisia", "url": "http://arxiv.org/abs/2507.15411v1", "summary": "Object-centric predictive process monitoring explores and utilizes\nobject-centric event logs to enhance process predictions. The main challenge\nlies in extracting relevant information and building effective models. In this\npaper, we propose an end-to-end model that predicts future process behavior,\nfocusing on two tasks: next activity prediction and next event time. The\nproposed model employs a graph attention network to encode activities and their\nrelationships, combined with an LSTM network to handle temporal dependencies.\nEvaluated on one reallife and three synthetic event logs, the model\ndemonstrates competitive performance compared to state-of-the-art methods.", "comment": "ICSOC Workshops 2024, Dec 2024, Tunis, Tunisia", "pdf_url": "http://arxiv.org/pdf/2507.15411v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14529", "title": "Kernel Based Maximum Entropy Inverse Reinforcement Learning for Mean-Field Games", "authors": ["Berkay Anahtarci", "Can Deha Kariksiz", "Naci Saldi"], "categories": ["cs.LG", "math.OC", "91A16, 68T05, 49N45, 93E20, 46E22"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14529v1", "summary": "We consider the maximum causal entropy inverse reinforcement learning problem\nfor infinite-horizon stationary mean-field games, in which we model the unknown\nreward function within a reproducing kernel Hilbert space. This allows the\ninference of rich and potentially nonlinear reward structures directly from\nexpert demonstrations, in contrast to most existing inverse reinforcement\nlearning approaches for mean-field games that typically restrict the reward\nfunction to a linear combination of a fixed finite set of basis functions. We\nalso focus on the infinite-horizon cost structure, whereas prior studies\nprimarily rely on finite-horizon formulations. We introduce a Lagrangian\nrelaxation to this maximum causal entropy inverse reinforcement learning\nproblem that enables us to reformulate it as an unconstrained log-likelihood\nmaximization problem, and obtain a solution \\lk{via} a gradient ascent\nalgorithm. To illustrate the theoretical consistency of the algorithm, we\nestablish the smoothness of the log-likelihood objective by proving the\nFr\\'echet differentiability of the related soft Bellman operators with respect\nto the parameters in the reproducing kernel Hilbert space. We demonstrate the\neffectiveness of our method on a mean-field traffic routing game, where it\naccurately recovers expert behavior.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14529v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14632", "title": "BusterX++: Towards Unified Cross-Modal AI-Generated Content Detection and Explanation with MLLM", "authors": ["Haiquan Wen", "Tianxiao Li", "Zhenglin Huang", "Yiwei He", "Guangliang Cheng"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14632v1", "summary": "Recent advances in generative AI have dramatically improved image and video\nsynthesis capabilities, significantly increasing the risk of misinformation\nthrough sophisticated fake content. In response, detection methods have evolved\nfrom traditional approaches to multimodal large language models (MLLMs),\noffering enhanced transparency and interpretability in identifying synthetic\nmedia. However, current detection systems remain fundamentally limited by their\nsingle-modality design. These approaches analyze images or videos separately,\nmaking them ineffective against synthetic content that combines multiple media\nformats. To address these challenges, we introduce \\textbf{BusterX++}, a novel\nframework designed specifically for cross-modal detection and explanation of\nsynthetic media. Our approach incorporates an advanced reinforcement learning\n(RL) post-training strategy that eliminates cold-start. Through Multi-stage\nTraining, Thinking Reward, and Hybrid Reasoning, BusterX++ achieves stable and\nsubstantial performance improvements. To enable comprehensive evaluation, we\nalso present \\textbf{GenBuster++}, a cross-modal benchmark leveraging\nstate-of-the-art image and video generation techniques. This benchmark\ncomprises 4,000 images and video clips, meticulously curated by human experts\nusing a novel filtering methodology to ensure high quality, diversity, and\nreal-world applicability. Extensive experiments demonstrate the effectiveness\nand generalizability of our approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14632v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15599", "title": "Applying the Chinese Wall Reverse Engineering Technique to Large Language Model Code Editing", "authors": ["Manatsawin Hanmongkolchai"], "categories": ["cs.SE", "cs.LG"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15599v1", "summary": "Large language models for code (Code LLM) are increasingly utilized in\nprogramming environments. Despite their utility, the training datasets for top\nLLM remain undisclosed, raising concerns about potential copyright violations.\nSome models, such as Pleias and Comma put emphasis on data curation and\nlicenses, however, with limited training data these models are not competitive\nand only serve as proof of concepts. To improve the utility of these models, we\npropose an application of the \"Chinese Wall\" technique, inspired by the reverse\nengineering technique of the same name -- a high quality model is used to\ngenerate detailed instructions for a weaker model. By doing so, a weaker but\nethically aligned model may be used to perform complicated tasks that,\notherwise, can only be completed by more powerful models. In our evaluation,\nwe've found that this technique improves Comma v0.1 1T's performance in\nCanItEdit benchmark by over 66%, and Starcoder2 Instruct by roughly 20%\ncompared to when running the same model on the benchmark alone. The practical\napplication of this technique today, however, may be limited due to the lack of\nmodels trained on public domain content without copyright restrictions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15599v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2502.13804", "title": "Binary VPN Traffic Detection Using Wavelet Features and Machine Learning", "authors": ["Yasameen Sajid Razooqi", "Adrian Pekar"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at SoftCOM 2025", "url": "http://arxiv.org/abs/2502.13804v2", "summary": "Encrypted traffic classification faces growing challenges as encryption\nrenders traditional deep packet inspection ineffective. This study addresses\nbinary VPN detection, distinguishing VPN-encrypted from non-VPN traffic using\nwavelet transform-based features across multiple machine learning models.\nUnlike previous studies focused on application-level classification within\nencrypted traffic, we specifically evaluate the fundamental task of VPN\nidentification regardless of application type. We analyze the impact of wavelet\ndecomposition levels and dataset filtering on classification performance across\nsignificantly imbalanced data, where filtering reduces some traffic categories\nby up to 95%. Our results demonstrate that Random Forest (RF) achieves superior\nperformance with an F1-score of 99%, maintaining robust accuracy even after\nsignificant dataset filtering. Neural Networks (NN) show comparable\neffectiveness with an F1-score of 98% when trained on wavelet level 12, while\nSupport Vector Machines (SVM) exhibit notable sensitivity to dataset reduction,\nwith F1-scores dropping from 90% to 85% after filtering. Comparing wavelet\ndecomposition at levels 5 and 12, we observe improved classification\nperformance at level 12, particularly for variable traffic types, though the\nmarginal gains may not justify the additional computational overhead. These\nfindings establish RF as the most reliable model for VPN traffic classification\nwhile highlighting key performance tradeoffs in feature extraction and\npreprocessing.", "comment": "Accepted for presentation at SoftCOM 2025", "pdf_url": "http://arxiv.org/pdf/2502.13804v2", "cate": "cs.NI", "date": "2025-02-19", "updated": "2025-07-21"}
{"id": "2507.14323", "title": "Polar Codes for Erasure and Unital Classical-Quantum Markovian Channels", "authors": ["Jaswanthi Mandalapu", "Vikesh Siddhu", "Krishna Jagannathan"], "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14323v1", "summary": "We consider classical-quantum (cq-)channels with memory, and establish that\nAr{\\i}kan-constructed polar codes achieve the classical capacity for two key\nnoise models, namely for (i) qubit erasures and (ii) unital qubit noise with\nchannel state information at the receiver. The memory in the channel is assumed\nto be governed by a discrete-time, countable-state, aperiodic, irreducible, and\npositive recurrent Markov process. We establish this result by leveraging\nexisting classical polar coding guarantees established for finite-state,\naperiodic, and irreducible Markov processes [FAIM], alongside the recent\nfinding that no entanglement is required to achieve the capacity of Markovian\nunital and erasure quantum channels when transmitting classical information.\nMore broadly, our work illustrates that for cq-channels with memory, where an\noptimal coding strategy is essentially classical, polar codes can be shown to\napproach the capacity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14323v1", "cate": "quant-ph", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15315", "title": "On Repetitive Finite Automata with Translucent Words", "authors": ["František Mráz", "Friedrich Otto"], "categories": ["cs.FL", "F.1.1; F.4.3"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      In Proceedings NCMA 2025, arXiv:2507.14082", "url": "http://arxiv.org/abs/2507.15315v1", "summary": "We introduce and study the repetitive variants of the deterministic and the\nnondeterministic finite automaton with translucent words (DFAwtw and NFAwtw).\nOn seeing the right sentinel, a repetitive NFAwtw need not halt immediately,\naccepting or rejecting, but it may change into another state and continue with\nits computation. We establish that a repetitive DFAwtw already accepts a\nlanguage that is not even semi-linear, which shows that the property of being\nrepetitive increases the expressive capacity of the DFAwtw and the NFAwtw\nconsiderably.", "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "pdf_url": "http://arxiv.org/pdf/2507.15315v1", "cate": "cs.FL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2403.06838", "title": "ACFIX: Guiding LLMs with Mined Common RBAC Practices for Context-Aware Repair of Access Control Vulnerabilities in Smart Contracts", "authors": ["Lyuye Zhang", "Kaixuan Li", "Kairan Sun", "Daoyuan Wu", "Ye Liu", "Haoye Tian", "Yang Liu"], "categories": ["cs.SE", "cs.CR"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      This is a technical report from Nanyang Technological University", "url": "http://arxiv.org/abs/2403.06838v3", "summary": "Smart contracts are susceptible to various security issues, among which\naccess control (AC) vulnerabilities are particularly critical. While existing\nresearch has proposed multiple detection tools, the automatic and appropriate\nrepair of AC vulnerabilities in smart contracts remains a challenge. Unlike\ncommonly supported vulnerability types by existing repair tools, such as\nreentrancy, which are usually fixed by template-based approaches, the main\nobstacle of AC lies in identifying the appropriate roles or permissions amid a\nlong list of non-AC-related source code to generate proper patch code, a task\nthat demands human-level intelligence.\n  Leveraging recent advancements in large language models (LLMs), we employ the\nstate-of-the-art GPT-4 model and enhance it with a novel approach called ACFIX.\nThe key insight is that we can mine common AC practices for major categories of\ncode functionality and use them to guide LLMs in fixing code with similar\nfunctionality. To this end, ACFIX involves both offline and online phases.\nFirst, during the offline phase, ACFIX mines a taxonomy of common Role-based\nAccess Control (RBAC) practices from 344,251 on-chain contracts, categorizing\n49 role-permission pairs from the top 1,000 pairs mined. Second, during the\nonline phase, ACFIX tracks AC-related elements across the contract and uses\nthis context information along with a Chain-of-Thought pipeline to guide LLMs\nin identifying the most appropriate role-permission pair for the subject\ncontract and subsequently generating a suitable patch. This patch will then\nundergo a validity and effectiveness check. To evaluate ACFIX, we built the\nfirst benchmark dataset of 118 real-world AC vulnerabilities, and our\nevaluation revealed that ACFIX successfully repaired 94.92% of them. This\nrepresents a significant improvement compared to the baseline GPT-4, which\nachieved only 52.54%.", "comment": "This is a technical report from Nanyang Technological University", "pdf_url": "http://arxiv.org/pdf/2403.06838v3", "cate": "cs.SE", "date": "2024-03-11", "updated": "2025-07-21"}
{"id": "2507.15036", "title": "EBA-AI: Ethics-Guided Bias-Aware AI for Efficient Underwater Image Enhancement and Coral Reef Monitoring", "authors": ["Lyes Saad Saoud", "Irfan Hussain"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15036v1", "summary": "Underwater image enhancement is vital for marine conservation, particularly\ncoral reef monitoring. However, AI-based enhancement models often face dataset\nbias, high computational costs, and lack of transparency, leading to potential\nmisinterpretations. This paper introduces EBA-AI, an ethics-guided bias-aware\nAI framework to address these challenges. EBA-AI leverages CLIP embeddings to\ndetect and mitigate dataset bias, ensuring balanced representation across\nvaried underwater environments. It also integrates adaptive processing to\noptimize energy efficiency, significantly reducing GPU usage while maintaining\ncompetitive enhancement quality. Experiments on LSUI400, Oceanex, and UIEB100\nshow that while PSNR drops by a controlled 1.0 dB, computational savings enable\nreal-time feasibility for large-scale marine monitoring. Additionally,\nuncertainty estimation and explainability techniques enhance trust in AI-driven\nenvironmental decisions. Comparisons with CycleGAN, FunIEGAN, RAUNENet,\nWaterNet, UGAN, PUGAN, and UTUIE validate EBA-AI's effectiveness in balancing\nefficiency, fairness, and interpretability in underwater image processing. By\naddressing key limitations of AI-driven enhancement, this work contributes to\nsustainable, bias-aware, and computationally efficient marine conservation\nefforts. For interactive visualizations, animations, source code, and access to\nthe preprint, visit: https://lyessaadsaoud.github.io/EBA-AI/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15036v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14339", "title": "Fiduciary AI for the Future of Brain-Technology Interactions", "authors": ["Abhishek Bhattacharjee", "Jack Pilkington", "Nita Farahany"], "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LG", "eess.SP", "K.4.0; I.2.0; J.4"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      32 pages", "url": "http://arxiv.org/abs/2507.14339v1", "summary": "Brain foundation models represent a new frontier in AI: instead of processing\ntext or images, these models interpret real-time neural signals from EEG, fMRI,\nand other neurotechnologies. When integrated with brain-computer interfaces\n(BCIs), they may enable transformative applications-from thought controlled\ndevices to neuroprosthetics-by interpreting and acting on brain activity in\nmilliseconds. However, these same systems pose unprecedented risks, including\nthe exploitation of subconscious neural signals and the erosion of cognitive\nliberty. Users cannot easily observe or control how their brain signals are\ninterpreted, creating power asymmetries that are vulnerable to manipulation.\nThis paper proposes embedding fiduciary duties-loyalty, care, and\nconfidentiality-directly into BCI-integrated brain foundation models through\ntechnical design. Drawing on legal traditions and recent advancements in AI\nalignment techniques, we outline implementable architectural and governance\nmechanisms to ensure these systems act in users' best interests. Placing brain\nfoundation models on a fiduciary footing is essential to realizing their\npotential without compromising self-determination.", "comment": "32 pages", "pdf_url": "http://arxiv.org/pdf/2507.14339v1", "cate": "cs.CY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15457", "title": "Optimization of Activity Batching Policies in Business Processes", "authors": ["Orlenys López-Pintado", "Jannis Rosenbaum", "Marlon Dumas"], "categories": ["cs.AI", "I.2.8"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15457v1", "summary": "In business processes, activity batching refers to packing multiple activity\ninstances for joint execution. Batching allows managers to trade off cost and\nprocessing effort against waiting time. Larger and less frequent batches may\nlower costs by reducing processing effort and amortizing fixed costs, but they\ncreate longer waiting times. In contrast, smaller and more frequent batches\nreduce waiting times but increase fixed costs and processing effort. A batching\npolicy defines how activity instances are grouped into batches and when each\nbatch is activated. This paper addresses the problem of discovering batching\npolicies that strike optimal trade-offs between waiting time, processing\neffort, and cost. The paper proposes a Pareto optimization approach that starts\nfrom a given set (possibly empty) of activity batching policies and generates\nalternative policies for each batched activity via intervention heuristics.\nEach heuristic identifies an opportunity to improve an activity's batching\npolicy with respect to a metric (waiting time, processing time, cost, or\nresource utilization) and an associated adjustment to the activity's batching\npolicy (the intervention). The impact of each intervention is evaluated via\nsimulation. The intervention heuristics are embedded in an optimization\nmeta-heuristic that triggers interventions to iteratively update the Pareto\nfront of the interventions identified so far. The paper considers three\nmeta-heuristics: hill-climbing, simulated annealing, and reinforcement\nlearning. An experimental evaluation compares the proposed approach based on\nintervention heuristics against the same (non-heuristic guided) meta-heuristics\nbaseline regarding convergence, diversity, and cycle time gain of\nPareto-optimal policies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15457v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14560", "title": "The Origin of Self-Attention: From Pairwise Affinity Matrices to Transformers", "authors": ["Giorgio Roffo"], "categories": ["cs.LG", "cs.CV", "68T07, 05C50, 15A18", "I.2.6; I.2.7; I.5.1"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      24 pages, 10 figures, submitted for review. Companion code and reproducibility materials available", "url": "http://arxiv.org/abs/2507.14560v1", "summary": "The self-attention mechanism, now central to deep learning architectures such\nas Transformers, is a modern instance of a more general computational\nprinciple: learning and using pairwise affinity matrices to control how\ninformation flows through a model. This paper traces the conceptual origins of\nself-attention across multiple domains, including computer vision, natural\nlanguage processing, and graph learning, through their shared reliance on an\naffinity matrix, denoted as A. We highlight Infinite Feature Selection (Inf-FS)\nas a foundational approach that generalizes the idea of affinity-based\nweighting. Unlike the fixed dot-product structure used in Transformers, Inf-FS\ndefines A either through domain knowledge or by learning, and computes feature\nrelevance through multi-hop propagation over the affinity graph. From this\nperspective, self-attention can be seen as a special case of Inf-FS: it uses a\nsingle-hop affinity computation where A is dynamically built from token\nsimilarities. We argue that the underlying structure, reasoning over pairwise\nrelationships, is preserved across both approaches, and the key differences lie\nin how the affinity matrix is defined and applied. By situating self-attention\nwithin the broader paradigm of affinity-based computation, we unify several\nstrands of machine learning research and highlight a common mathematical\nfoundation that underpins diverse models and tasks.", "comment": "24 pages, 10 figures, submitted for review. Companion code and\n  reproducibility materials available", "pdf_url": "http://arxiv.org/pdf/2507.14560v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14643", "title": "Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection", "authors": ["Jifeng Shen", "Haibo Zhan", "Shaohua Dong", "Xin Zuo", "Wankou Yang", "Haibin Ling"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      submitted on 30/4/2025, Under Major Revision", "url": "http://arxiv.org/abs/2507.14643v1", "summary": "Modern multispectral feature fusion for object detection faces two critical\nlimitations: (1) Excessive preference for local complementary features over\ncross-modal shared semantics adversely affects generalization performance; and\n(2) The trade-off between the receptive field size and computational complexity\npresent critical bottlenecks for scalable feature modeling. Addressing these\nissues, a novel Multispectral State-Space Feature Fusion framework, dubbed\nMS2Fusion, is proposed based on the state space model (SSM), achieving\nefficient and effective fusion through a dual-path parametric interaction\nmechanism. More specifically, the first cross-parameter interaction branch\ninherits the advantage of cross-attention in mining complementary information\nwith cross-modal hidden state decoding in SSM. The second shared-parameter\nbranch explores cross-modal alignment with joint embedding to obtain\ncross-modal similar semantic features and structures through parameter sharing\nin SSM. Finally, these two paths are jointly optimized with SSM for fusing\nmultispectral features in a unified framework, allowing our MS2Fusion to enjoy\nboth functional complementarity and shared semantic space. In our extensive\nexperiments on mainstream benchmarks including FLIR, M3FD and LLVIP, our\nMS2Fusion significantly outperforms other state-of-the-art multispectral object\ndetection methods, evidencing its superiority. Moreover, MS2Fusion is general\nand applicable to other multispectral perception tasks. We show that, even\nwithout specific design, MS2Fusion achieves state-of-the-art results on RGB-T\nsemantic segmentation and RGBT salient object detection, showing its\ngenerality. The source code will be available at\nhttps://github.com/61s61min/MS2Fusion.git.", "comment": "submitted on 30/4/2025, Under Major Revision", "pdf_url": "http://arxiv.org/pdf/2507.14643v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15624", "title": "Hot Topics and Common Challenges: an Empirical Study of React Discussions on Stack Overflow", "authors": ["Yusuf Sulistyo Nugroho", "Ganno Tribuana Kurniaji", "Syful Islam", "Mohammed Humayun Kabir", "Vanesya Aura Ardity", "Md. Kamal Uddin"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      6 pages, 4 figures, 4 tables, conference paper", "url": "http://arxiv.org/abs/2507.15624v1", "summary": "React is a JavaScript library used to build user interfaces for single-page\napplications. Although recent studies have shown the popularity and advantages\nof React in web development, the specific challenges users face remain unknown.\nThus, this study aims to analyse the React-related questions shared on Stack\nOverflow. The study utilizes an exploratory data analysis to investigate the\nmost frequently discussed keywords, error classification, and user\nreputation-based errors, which is the novelty of this work. The results show\nthe top eight most frequently used keywords on React-related questions, namely,\ncode, link, vir, href, connect, azure, windows, and website. The error\nclassification of questions from the sample shows that algorithmic error is the\nmost frequent issue faced by all groups of users, where mid-reputation users\ncontribute the most, accounting for 55.77%. This suggests the need for the\ncommunity to provide guidance materials in solving algorithm-related problems.\nWe expect that the results of this study will provide valuable insight into\nfuture research to support the React community during the early stages of\nimplementation, facilitating their ability to effectively overcome challenges\nto adoption.", "comment": "6 pages, 4 figures, 4 tables, conference paper", "pdf_url": "http://arxiv.org/pdf/2507.15624v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2506.09245", "title": "Age of Information in Unreliable Tandem Queues", "authors": ["Muthukrishnan Senthilkumar", "Aresh Dadlani", "Hina Tabassum"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      Revised version", "url": "http://arxiv.org/abs/2506.09245v2", "summary": "Stringent demands for timely information delivery, driven by the widespread\nadoption of real-time applications and the Internet of Things, have established\nthe age of information (AoI) as a critical metric for quantifying data\nfreshness. Existing AoI models often assume multi-hop communication networks\nwith fully reliable nodes, which may not accurately capture scenarios involving\nnode transmission failures. This paper presents an analytical framework for two\nconfigurations of tandem queue systems, where status updates generated by a\nsingle sensor are relayed to a destination monitor through unreliable\nintermediate nodes. Using the probability generating function, we first derive\nthe sojourn time distribution for an infinite-buffer M/M/1 tandem system with\ntwo unreliable nodes. We then extend our analysis to an M/G/1 tandem system\nwith an arbitrary number of unreliable nodes, employing the supplementary\nvariable technique while assuming that only the first node has an infinite\nbuffer. Numerical results demonstrate the impact of key system parameters on\nthe average AoI in unreliable tandem queues with Markovian and non-Markovian\nservice times.", "comment": "Revised version", "pdf_url": "http://arxiv.org/pdf/2506.09245v2", "cate": "cs.NI", "date": "2025-06-10", "updated": "2025-07-19"}
{"id": "2507.14831", "title": "Pinching-Antenna-based Communications: Spectral Efficiency Analysis and Deployment Strategies", "authors": ["Mengyu Qian", "Xidong Mu", "Li You", "Michail Matthaiou"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      13 pages, 8 figures", "url": "http://arxiv.org/abs/2507.14831v1", "summary": "A multiple-waveguide pinching-antenna (PA)-based multi-user communication\nsystem is investigated. With a given number of PAs, two deployment strategies\nare considered, namely the centralized PA deployment, where all PAs are\nswitched between waveguides to serve users in a time-division manner to avail\nof beamforming gain, and the distributed PA deployment, where a single PA is\ndeployed on each waveguide to simultaneously serve multiple users by leveraging\nthe multiplexing gain. The spectral efficiency (SE) achieved by each deployment\nstrategy is analyzed: i) For the centralized deployment, the positioning\nstrategy of PAs on each waveguide is determined first with the aim of\nmaximizing the channel gain of the corresponding nearest served user. Based on\nthis, the corresponding system SE is derived. ii) For the distributed\ndeployment, the system SE under the maximum ratio transmission (MRT) is first\nobtained. To obtain an analytically tractable form, the stationary phase method\nis utilized to approximate the system SE. The approximation result reveals that\nthe average inter-user interference can be negligible with a large waveguide\nspacing and thus the simple MRT is appealing for PA-based multi-user\ncommunications. Furthermore, the system SEs achieved by the two strategies are\ncompared in both the high and low signal-to-noise ratio (SNR) regimes. Our\nanalysis suggests that at high SNRs, the distributed deployment is superior to\nachieve the maximal system SE, while the centralized deployment is more\nsuitable for the low-SNR regime. Finally, the theoretical analysis is verified\nthrough simulations.", "comment": "13 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.14831v1", "cate": "eess.SP", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15316", "title": "A Myhill-Nerode Type Characterization of 2detLIN Languages", "authors": ["Benedek Nagy"], "categories": ["cs.FL", "cs.DM", "cs.DS", "F.1.1;F.4.3;F.1.3"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      In Proceedings NCMA 2025, arXiv:2507.14082", "url": "http://arxiv.org/abs/2507.15316v1", "summary": "Linear automata are automata with two reading heads starting from the two\nextremes of the input, are equivalent to 5' -> 3' Watson-Crick (WK) finite\nautomata. The heads read the input in opposite directions and the computation\nfinishes when the heads meet. These automata accept the class LIN of linear\nlanguages. The deterministic counterpart of these models, on the one hand, is\nless expressive, as only a proper subset of LIN, the class 2detLIN is accepted;\nand on the other hand, they are also equivalent in the sense of the class of\nthe accepted languages. Now, based on these automata models, we characterize\nthe class of 2detLIN languages with a Myhill-Nerode type of equivalence\nclasses. However, as these automata may do the computation of both the prefix\nand the suffix of the input, we use prefix-suffix pairs in our classes.\nAdditionally, it is proven that finitely many classes in the characterization\nmatch with the 2detLIN languages, but we have some constraints on the used\nprefix-suffix pairs, i.e., the characterization should have the property to be\ncomplete and it must not have any crossing pairs.", "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "pdf_url": "http://arxiv.org/pdf/2507.15316v1", "cate": "cs.FL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2505.04843", "title": "Large Language Models are Autonomous Cyber Defenders", "authors": ["Sebastián R. Castro", "Roberto Campbell", "Nancy Lau", "Octavio Villalobos", "Jiaqi Duan", "Alvaro A. Cardenas"], "categories": ["cs.AI", "cs.CR", "I.2.0"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Presented at IEEE CAI Workshop on Adaptive Cyber Defense 2025", "url": "http://arxiv.org/abs/2505.04843v2", "summary": "Fast and effective incident response is essential to prevent adversarial\ncyberattacks. Autonomous Cyber Defense (ACD) aims to automate incident response\nthrough Artificial Intelligence (AI) agents that plan and execute actions. Most\nACD approaches focus on single-agent scenarios and leverage Reinforcement\nLearning (RL). However, ACD RL-trained agents depend on costly training, and\ntheir reasoning is not always explainable or transferable. Large Language\nModels (LLMs) can address these concerns by providing explainable actions in\ngeneral security contexts. Researchers have explored LLM agents for ACD but\nhave not evaluated them on multi-agent scenarios or interacting with other ACD\nagents. In this paper, we show the first study on how LLMs perform in\nmulti-agent ACD environments by proposing a new integration to the CybORG CAGE\n4 environment. We examine how ACD teams of LLM and RL agents can interact by\nproposing a novel communication protocol. Our results highlight the strengths\nand weaknesses of LLMs and RL and help us identify promising research\ndirections to create, train, and deploy future teams of ACD agents.", "comment": "Presented at IEEE CAI Workshop on Adaptive Cyber Defense 2025", "pdf_url": "http://arxiv.org/pdf/2505.04843v2", "cate": "cs.AI", "date": "2025-05-07", "updated": "2025-07-19"}
{"id": "2507.15089", "title": "Visual Place Recognition for Large-Scale UAV Applications", "authors": ["Ioannis Tsampikos Papapetros", "Ioannis Kansizoglou", "Antonios Gasteratos"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15089v1", "summary": "Visual Place Recognition (vPR) plays a crucial role in Unmanned Aerial\nVehicle (UAV) navigation, enabling robust localization across diverse\nenvironments. Despite significant advancements, aerial vPR faces unique\nchallenges due to the limited availability of large-scale, high-altitude\ndatasets, which limits model generalization, along with the inherent rotational\nambiguity in UAV imagery. To address these challenges, we introduce LASED, a\nlarge-scale aerial dataset with approximately one million images,\nsystematically sampled from 170,000 unique locations throughout Estonia over a\ndecade, offering extensive geographic and temporal diversity. Its structured\ndesign ensures clear place separation significantly enhancing model training\nfor aerial scenarios. Furthermore, we propose the integration of steerable\nConvolutional Neural Networks (CNNs) to explicitly handle rotational variance,\nleveraging their inherent rotational equivariance to produce robust,\norientation-invariant feature representations. Our extensive benchmarking\ndemonstrates that models trained on LASED achieve significantly higher recall\ncompared to those trained on smaller, less diverse datasets, highlighting the\nbenefits of extensive geographic coverage and temporal diversity. Moreover,\nsteerable CNNs effectively address rotational ambiguity inherent in aerial\nimagery, consistently outperforming conventional convolutional architectures,\nachieving on average 12\\% recall improvement over the best-performing\nnon-steerable network. By combining structured, large-scale datasets with\nrotation-equivariant neural networks, our approach significantly enhances model\nrobustness and generalization for aerial vPR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15089v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14372", "title": "Text-to-SQL for Enterprise Data Analytics", "authors": ["Albert Chen", "Manas Bundele", "Gaurav Ahlawat", "Patrick Stetz", "Zhitao Wang", "Qiang Fei", "Donghoon Jung", "Audrey Chu", "Bharadwaj Jayaraman", "Ayushi Panth", "Yatin Arora", "Sourav Jain", "Renjith Varma", "Alexey Ilin", "Iuliia Melnychuk", "Chelsea Chueh", "Joyan Sil", "Xiaofeng Wang"], "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      11 pages, 8 figures, Workshop on Agentic AI for Enterprise at KDD '25", "url": "http://arxiv.org/abs/2507.14372v1", "summary": "The introduction of large language models has brought rapid progress on\nText-to-SQL benchmarks, but it is not yet easy to build a working enterprise\nsolution. In this paper, we present insights from building an internal chatbot\nthat enables LinkedIn's product managers, engineers, and operations teams to\nself-serve data insights from a large, dynamic data lake. Our approach features\nthree components. First, we construct a knowledge graph that captures\nup-to-date semantics by indexing database metadata, historical query logs,\nwikis, and code. We apply clustering to identify relevant tables for each team\nor product area. Second, we build a Text-to-SQL agent that retrieves and ranks\ncontext from the knowledge graph, writes a query, and automatically corrects\nhallucinations and syntax errors. Third, we build an interactive chatbot that\nsupports various user intents, from data discovery to query writing to\ndebugging, and displays responses in rich UI elements to encourage follow-up\nchats. Our chatbot has over 300 weekly users. Expert review shows that 53% of\nits responses are correct or close to correct on an internal benchmark set.\nThrough ablation studies, we identify the most important knowledge graph and\nmodeling components, offering a practical path for developing enterprise\nText-to-SQL solutions.", "comment": "11 pages, 8 figures, Workshop on Agentic AI for Enterprise at KDD '25", "pdf_url": "http://arxiv.org/pdf/2507.14372v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15509", "title": "Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner", "authors": ["Lei Chen", "Xuanle Zhao", "Zhixiong Zeng", "Jing Huang", "Yufeng Zhong", "Lin Ma"], "categories": ["cs.AI", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      technical report", "url": "http://arxiv.org/abs/2507.15509v1", "summary": "Recently, inspired by OpenAI-o1/o3 and Deepseek-R1, the R1-Style method based\non reinforcement learning fine-tuning has received widespread attention from\nthe community. Previous R1-Style methods mainly focus on mathematical reasoning\nand code intelligence. It is of great research significance to verify their\nadvantages on more general multimodal data. Chart is an important multimodal\ndata type with rich information, which brings important research challenges in\ncomplex reasoning. In this work, we introduce Chart-R1, a chart-domain\nvision-language model with reinforcement learning fine-tuning to enable complex\nchart reasoning. To support Chart-R1, we first propose a novel programmatic\ndata synthesis technology to generate high-quality step-by-step chart reasoning\ndata covering single- and multi-subcharts, which makes up for the lack of\nreasoning data in the chart domain. Then we develop a two-stage training\nstrategy: Chart-COT with step-by-step chain-of-thought supervision, and\nChart-RFT with numerically sensitive reinforcement fine-tuning. Chart-COT aims\nto decompose complex chart reasoning tasks into fine-grained, understandable\nsubtasks through step-by-step supervision, which lays a good foundation for\nimproving the reasoning level of reinforcement learning. Chart-RFT utilize the\ntypical group relative policy optimization strategy, in which a relatively soft\nreward is adopted for numerical response to emphasize the numerical sensitivity\nin the chart domain. We conduct extensive experiments on open-source benchmarks\nand self-built chart reasoning dataset (\\emph{i.e., ChartRQA}). Experimental\nresults show that Chart-R1 has significant advantages compared to chart-domain\nmethods, even comparable to open/closed source large-scale models (\\emph{e.g.,\nGPT-4o, Claude-3.5}).", "comment": "technical report", "pdf_url": "http://arxiv.org/pdf/2507.15509v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14570", "title": "LPS-GNN : Deploying Graph Neural Networks on Graphs with 100-Billion Edges", "authors": ["Xu Cheng", "Liang Yao", "Feng He", "Yukuo Cen", "Yufei He", "Chenhui Zhang", "Wenzheng Feng", "Hongyun Cai", "Jie Tang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14570v1", "summary": "Graph Neural Networks (GNNs) have emerged as powerful tools for various graph\nmining tasks, yet existing scalable solutions often struggle to balance\nexecution efficiency with prediction accuracy. These difficulties stem from\niterative message-passing techniques, which place significant computational\ndemands and require extensive GPU memory, particularly when dealing with the\nneighbor explosion issue inherent in large-scale graphs. This paper introduces\na scalable, low-cost, flexible, and efficient GNN framework called LPS-GNN,\nwhich can perform representation learning on 100 billion graphs with a single\nGPU in 10 hours and shows a 13.8% improvement in User Acquisition scenarios. We\nexamine existing graph partitioning methods and design a superior graph\npartition algorithm named LPMetis. In particular, LPMetis outperforms current\nstate-of-the-art (SOTA) approaches on various evaluation metrics. In addition,\nour paper proposes a subgraph augmentation strategy to enhance the model's\npredictive performance. It exhibits excellent compatibility, allowing the\nentire framework to accommodate various GNN algorithms. Successfully deployed\non the Tencent platform, LPS-GNN has been tested on public and real-world\ndatasets, achieving performance lifts of 8. 24% to 13. 89% over SOTA models in\nonline applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14570v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14657", "title": "AI-Powered Precision in Sport Taekwondo: Enhancing Fairness, Speed, and Trust in Competition (FST.ai)", "authors": ["Keivan Shariatmadar", "Ahmad Osman"], "categories": ["cs.CV", "cs.AI", "68T45", "I.2.10"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      24 pages, 9 figures", "url": "http://arxiv.org/abs/2507.14657v1", "summary": "The integration of Artificial Intelligence (AI) into sports officiating\nrepresents a paradigm shift in how decisions are made in competitive\nenvironments. Traditional manual systems, even when supported by Instant Video\nReplay (IVR), often suffer from latency, subjectivity, and inconsistent\nenforcement, undermining fairness and athlete trust. This paper introduces\nFST.ai, a novel AI-powered framework designed to enhance officiating in Sport\nTaekwondo, particularly focusing on the complex task of real-time head kick\ndetection and scoring. Leveraging computer vision, deep learning, and edge\ninference, the system automates the identification and classification of key\nactions, significantly reducing decision time from minutes to seconds while\nimproving consistency and transparency. Importantly, the methodology is not\nlimited to Taekwondo. The underlying framework -- based on pose estimation,\nmotion classification, and impact analysis -- can be adapted to a wide range of\nsports requiring action detection, such as judo, karate, fencing, or even team\nsports like football and basketball, where foul recognition or performance\ntracking is critical. By addressing one of Taekwondo's most challenging\nscenarios -- head kick scoring -- we demonstrate the robustness, scalability,\nand sport-agnostic potential of FST.ai to transform officiating standards\nacross multiple disciplines.", "comment": "24 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.14657v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15663", "title": "SustainDiffusion: Optimising the Social and Environmental Sustainability of Stable Diffusion Models", "authors": ["Giordano d'Aloisio", "Tosin Fadahunsi", "Jay Choy", "Rebecca Moussa", "Federica Sarro"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15663v1", "summary": "Background: Text-to-image generation models are widely used across numerous\ndomains. Among these models, Stable Diffusion (SD) - an open-source\ntext-to-image generation model - has become the most popular, producing over 12\nbillion images annually. However, the widespread use of these models raises\nconcerns regarding their social and environmental sustainability.\n  Aims: To reduce the harm that SD models may have on society and the\nenvironment, we introduce SustainDiffusion, a search-based approach designed to\nenhance the social and environmental sustainability of SD models.\n  Method: SustainDiffusion searches the optimal combination of hyperparameters\nand prompt structures that can reduce gender and ethnic bias in generated\nimages while also lowering the energy consumption required for image\ngeneration. Importantly, SustainDiffusion maintains image quality comparable to\nthat of the original SD model.\n  Results: We conduct a comprehensive empirical evaluation of SustainDiffusion,\ntesting it against six different baselines using 56 different prompts. Our\nresults demonstrate that SustainDiffusion can reduce gender bias in SD3 by 68%,\nethnic bias by 59%, and energy consumption (calculated as the sum of CPU and\nGPU energy) by 48%. Additionally, the outcomes produced by SustainDiffusion are\nconsistent across multiple runs and can be generalised to various prompts.\n  Conclusions: With SustainDiffusion, we demonstrate how enhancing the social\nand environmental sustainability of text-to-image generation models is possible\nwithout fine-tuning or changing the model's architecture.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15663v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2506.23083", "title": "Model-Based Diagnosis: Automating End-to-End Diagnosis of Network Failures", "authors": ["Changrong Wu", "Yiyao Yu", "Myungjin Lee", "Jayanth Srinivasa", "Ennan Zhai", "George Varghese", "Yuval Tamir"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      Fixed a typo (line break location) in Figure 2", "url": "http://arxiv.org/abs/2506.23083v2", "summary": "Fast diagnosis and repair of enterprise network failures is critically\nimportant since disruptions cause major business impacts. Prior works focused\non diagnosis primitives or procedures limited to a subset of the problem, such\nas only data plane or only control plane faults. This paper proposes a new\nparadigm, model-based network diagnosis, that provides a systematic way to\nderive automated procedures for identifying the root cause of network failures,\nbased on reports of end-to-end user-level symptoms. The diagnosis procedures\nare systematically derived from a model of packet forwarding and routing,\ncovering hardware, firmware, and software faults in both the data plane and\ndistributed control plane. These automated procedures replace and dramatically\naccelerate diagnosis by an experienced human operator. Model-based diagnosis is\ninspired by, leverages, and is complementary to recent work on network\nverification. We have built NetDx, a proof-of-concept implementation of\nmodel-based network diagnosis. We deployed NetDx on a new emulator of networks\nconsisting of P4 switches with distributed routing software. We validated the\nrobustness and coverage of NetDx with an automated fault injection campaign, in\nwhich 100% of faults were diagnosed correctly. Furthermore, on a data set of 33\nfaults from a large cloud provider that are within the domain targeted by\nNetDx, 30 are efficiently diagnosed in seconds instead of hours.", "comment": "Fixed a typo (line break location) in Figure 2", "pdf_url": "http://arxiv.org/pdf/2506.23083v2", "cate": "cs.NI", "date": "2025-06-29", "updated": "2025-07-20"}
{"id": "2507.15056", "title": "Transversal non-Clifford gates on qLDPC codes breaking the $\\sqrt{N}$ distance barrier and quantum-inspired geometry with $\\mathbb{Z}_2$ systolic freedom", "authors": ["Guanyu Zhu"], "categories": ["quant-ph", "cond-mat.str-el", "cs.IT", "hep-th", "math.GT", "math.IT"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      18 pages, 4 figures", "url": "http://arxiv.org/abs/2507.15056v1", "summary": "Historically, a $\\sqrt{N}log^{1/2}(N)$ distance barrier for quantum\nlow-density parity-check (LDPC) codes with $N$ qubits persisted for nearly two\ndecades, until the recent discovery of the fibre-bundle code. An open question\nis whether such a distance barrier can be broken while preserving the ability\nto perform transversal non-Clifford gates. In this direction, another\nlong-standing distance barrier of $N^{1/3}$ for LDPC stabilizer codes --\npresent since the discovery of the 3D color code -- was only recently overcome\nby a construction achieving an $\\Omega(\\sqrt{N})$ distance (arXiv:2501.19375).\nThe present work further breaks the $\\sqrt{N}$ distance barrier by taking a\nhomological product of three good qLDPC codes, combined with the\nFreedman-Hastings code-to-manifold mapping and the triple cup product to\nimplement transversal CCZ gates. The resulting code achieves an\n$\\Omega(N^{2/3})$ distance (a linear $X$-distance of $\\Theta(N)$) and a\ndimension of $\\Theta(N^{2/3})$, which enables fault-tolerant preparation of\n$\\Theta(N^{1/3})$ independent logical CCZ magic states in a single shot,\nwithout distillation (`magic state fountain'). This new quantum code also\ninspires the discovery of a family of exotic $3q$-dimensional manifolds\n$\\mathcal{M}$, which exhibit both a power-law $\\mathbb{Z}_2$-($q$,\n$2q$)-systolic freedom and $\\Theta(vol(\\mathcal{M}))$ triple intersection\npoints of $2q$-dimensional submanifolds.", "comment": "18 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.15056v1", "cate": "quant-ph", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15317", "title": "On some Classes of Reversible 2-head Automata", "authors": ["Benedek Nagy", "Walaa Yasin"], "categories": ["cs.FL", "F.1.1;F.1.2;F.4.2;F.4.3"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      In Proceedings NCMA 2025, arXiv:2507.14082", "url": "http://arxiv.org/abs/2507.15317v1", "summary": "Deterministic 2-head finite automata which are machines that process an input\nword from both ends are analyzed for their ability to perform reversible\ncomputations. This implies that the automata are backward deterministic,\nenabling unique forward and backward computation. We explore the computational\npower of such automata, discovering that, while some regular languages cannot\nbe accepted by these machines, they are capable of accepting some\ncharacteristic linear languages, e.g., the language of palindromes.\nAdditionally, we prove that restricted variants, i.e., both 1-limited\nreversible 2-head finite automata and complete reversible 2-head finite\nautomata are less powerful and they form a proper hierarchy. In the former, in\neach computation step exactly one input letter is being processed, i.e., only\none of the heads can read a letter. These automata are also characterized by\nputting their states to classes based on the head(s) used to reach and to leave\nthe state. In the complete reversible 2-head finite automata, it is required\nthat any input can be fully read by the automaton. The accepted families are\nalso compared to the classes generated by left deterministic linear grammars.", "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "pdf_url": "http://arxiv.org/pdf/2507.15317v1", "cate": "cs.FL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14138", "title": "Optimizing VO2max Prediction in Gamified Cardiac Assessment: Leveraging Effective Feature Selection and Refined Protocols for Robust Models", "authors": ["Vaishnavi C K", "Sricharan Vijayarangan", "Sri Gayathri G", "Danush Adhithya N", "Alex Joseph", "Preejith SP", "Mohanasankar Sivaprakasam"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted and Presented in IEEE IECBES 2024", "url": "http://arxiv.org/abs/2507.14138v1", "summary": "VO2max is a critical indicator of cardiopulmonary fitness, reflecting the\nmaximum amount of oxygen the body can utilize during intense exercise.\nAccurately measuring VO2max is essential for assessing cardiovascular health\nand predicting outcomes in clinical settings. However, current methods for\nVO2max estimation, such as Cardiopulmonary Exercise Testing (CPET), require\nexpensive equipment and the supervision of trained personnel, limiting\naccessibility for large-scale screening. Preliminary efforts have been made to\ncreate a more accessible method, such as the Cardiopulmonary Spot Jog Test\n(CPSJT). Unfortunately, these early attempts yielded high error margins,\nrendering them unsuitable for widespread use. In our study, we address these\nshortcomings by refining the CPSJT protocol to improve prediction accuracy. A\ncrucial contribution is improved feature extraction which include gender, body\nmass index, aerobic duration, and anaerobic duration. This targeted approach\nhelps in streamlining the model to enhance prediction precision while\nminimizing the risk of overfitting. In a cohort of 44 participants from the\nIndian population, we assessed the performance of various machine learning\nmodels using these features. With Stratified 5-Fold Cross-Validation, the Root\nMean Squared Error (RMSE) values were 5.78 for Linear Regression, 5.15 for\nRandom Forest, and 5.17 for Support Vector Regression. All models demonstrated\nstrong test correlations and low RMSE values, underscoring their robust and\nreliable performance.", "comment": "Accepted and Presented in IEEE IECBES 2024", "pdf_url": "http://arxiv.org/pdf/2507.14138v1", "cate": "eess.SP", "date": "2025-04-16", "updated": "2025-04-16"}
{"id": "2506.23644", "title": "QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration", "authors": ["Junze Hu", "Xiangyu Jin", "Yizhe Zeng", "Yuling Liu", "Yunpeng Li", "Dan Du", "Kaiyu Xie", "Hongsong Zhu"], "categories": ["cs.SE", "cs.AI", "cs.CR"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      The experimental data in the experimental section needs to be improved, and there are some errors", "url": "http://arxiv.org/abs/2506.23644v3", "summary": "We introduce QLPro, a vulnerability detection framework that systematically\nintegrates LLMs and static analysis tools to enable comprehensive vulnerability\ndetection across entire open-source projects.We constructed a new dataset,\nJavaTest, comprising 10 open-source projects from GitHub with 62 confirmed\nvulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only\n24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro\ndiscovered 6 previously unknown vulnerabilities, 2 of which have been confirmed\nas 0-days.", "comment": "The experimental data in the experimental section needs to be\n  improved, and there are some errors", "pdf_url": "http://arxiv.org/pdf/2506.23644v3", "cate": "cs.SE", "date": "2025-06-30", "updated": "2025-07-19"}
{"id": "2507.15496", "title": "Dense-depth map guided deep Lidar-Visual Odometry with Sparse Point Clouds and Images", "authors": ["JunYing Huang", "Ao Xu", "DongSun Yong", "KeRen Li", "YuanFeng Wang", "Qi Qin"], "categories": ["cs.CV", "cs.LG", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15496v1", "summary": "Odometry is a critical task for autonomous systems for self-localization and\nnavigation. We propose a novel LiDAR-Visual odometry framework that integrates\nLiDAR point clouds and images for accurate and robust pose estimation. Our\nmethod utilizes a dense-depth map estimated from point clouds and images\nthrough depth completion, and incorporates a multi-scale feature extraction\nnetwork with attention mechanisms, enabling adaptive depth-aware\nrepresentations. Furthermore, we leverage dense depth information to refine\nflow estimation and mitigate errors in occlusion-prone regions. Our\nhierarchical pose refinement module optimizes motion estimation progressively,\nensuring robust predictions against dynamic environments and scale ambiguities.\nComprehensive experiments on the KITTI odometry benchmark demonstrate that our\napproach achieves similar or superior accuracy and robustness compared to\nstate-of-the-art visual and LiDAR odometry methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15496v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14451", "title": "Adapting Whisper for Lightweight and Efficient Automatic Speech Recognition of Children for On-device Edge Applications", "authors": ["Satwik Dutta", "Shruthigna Chandupatla", "John Hansen"], "categories": ["eess.AS", "cs.HC", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      5 pages, 5 figures, accepted for presentation at the 2025 Workshop on Child Computer Interaction (WOCCI 2025), a Satellite Workshop of the 2025 Interspeech Conference", "url": "http://arxiv.org/abs/2507.14451v1", "summary": "Reliability on cloud providers for ASR inference to support child-centered\nvoice-based applications is becoming challenging due to regulatory and privacy\nchallenges. Motivated by a privacy-preserving design, this study aims to\ndevelop a lightweight & efficient Whisper ASR system capable of running on a\nRaspberry Pi. Upon evaluation of the MyST corpus and by examining various\nfiltering strategies to fine-tune the `tiny.en' model, a Word Error Rate (WER)\nof 15.9% was achieved (11.8% filtered). A low-rank compression reduces the\nencoder size by 0.51M with 1.26x faster inference in GPU, with 11% relative WER\nincrease. During inference on Pi, the compressed version required ~2 GFLOPS\nfewer computations. The RTF for both the models ranged between [0.23-0.41] for\nvarious input audio durations. Analyzing the RAM usage and CPU temperature\nshowed that the PI was capable of handling both the tiny models, however it was\nnoticed that small models initiated additional overhead/thermal throttling.", "comment": "5 pages, 5 figures, accepted for presentation at the 2025 Workshop on\n  Child Computer Interaction (WOCCI 2025), a Satellite Workshop of the 2025\n  Interspeech Conference", "pdf_url": "http://arxiv.org/pdf/2507.14451v1", "cate": "eess.AS", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15521", "title": "LLM world models are mental: Output layer evidence of brittle world model use in LLM mechanical reasoning", "authors": ["Cole Robertson", "Philip Wolff"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Manuscript comprises 14 pages, 4 figures, 4 tables in the Technical Appendix and Supplementary Material, and is under review at NeurIPS 2025", "url": "http://arxiv.org/abs/2507.15521v1", "summary": "Do large language models (LLMs) construct and manipulate internal world\nmodels, or do they rely solely on statistical associations represented as\noutput layer token probabilities? We adapt cognitive science methodologies from\nhuman mental models research to test LLMs on pulley system problems using\nTikZ-rendered stimuli. Study 1 examines whether LLMs can estimate mechanical\nadvantage (MA). State-of-the-art models performed marginally but significantly\nabove chance, and their estimates correlated significantly with ground-truth\nMA. Significant correlations between number of pulleys and model estimates\nsuggest that models employed a pulley counting heuristic, without necessarily\nsimulating pulley systems to derive precise values. Study 2 tested this by\nprobing whether LLMs represent global features crucial to MA estimation. Models\nevaluated a functionally connected pulley system against a fake system with\nrandomly placed components. Without explicit cues, models identified the\nfunctional system as having greater MA with F1=0.8, suggesting LLMs could\nrepresent systems well enough to differentiate jumbled from functional systems.\nStudy 3 built on this by asking LLMs to compare functional systems with matched\nsystems which were connected up but which transferred no force to the weight;\nLLMs identified the functional system with F1=0.46, suggesting random guessing.\nInsofar as they may generalize, these findings are compatible with the notion\nthat LLMs manipulate internal world models, sufficient to exploit statistical\nassociations between pulley count and MA (Study 1), and to approximately\nrepresent system components' spatial relations (Study 2). However, they may\nlack the facility to reason over nuanced structural connectivity (Study 3). We\nconclude by advocating the utility of cognitive scientific methods to evaluate\nthe world-modeling capacities of artificial intelligence systems.", "comment": "Manuscript comprises 14 pages, 4 figures, 4 tables in the Technical\n  Appendix and Supplementary Material, and is under review at NeurIPS 2025", "pdf_url": "http://arxiv.org/pdf/2507.15521v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14592", "title": "A Transformer-Based Conditional GAN with Multiple Instance Learning for UAV Signal Detection and Classification", "authors": ["Haochen Liu", "Jia Bi", "Xiaomin Wang", "Xin Yang", "Ling Wang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      13 pages, 7 figures", "url": "http://arxiv.org/abs/2507.14592v1", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly used in surveillance,\nlogistics, agriculture, disaster management, and military operations. Accurate\ndetection and classification of UAV flight states, such as hovering, cruising,\nascending, or transitioning, which are essential for safe and effective\noperations. However, conventional time series classification (TSC) methods\noften lack robustness and generalization for dynamic UAV environments, while\nstate of the art(SOTA) models like Transformers and LSTM based architectures\ntypically require large datasets and entail high computational costs,\nespecially with high-dimensional data streams. This paper proposes a novel\nframework that integrates a Transformer-based Generative Adversarial Network\n(GAN) with Multiple Instance Locally Explainable Learning (MILET) to address\nthese challenges in UAV flight state classification. The Transformer encoder\ncaptures long-range temporal dependencies and complex telemetry dynamics, while\nthe GAN module augments limited datasets with realistic synthetic samples. MIL\nis incorporated to focus attention on the most discriminative input segments,\nreducing noise and computational overhead. Experimental results show that the\nproposed method achieves superior accuracy 96.5% on the DroneDetect dataset and\n98.6% on the DroneRF dataset that outperforming other SOTA approaches. The\nframework also demonstrates strong computational efficiency and robust\ngeneralization across diverse UAV platforms and flight states, highlighting its\npotential for real-time deployment in resource constrained environments.", "comment": "13 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.14592v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14662", "title": "Artificial Intelligence in the Food Industry: Food Waste Estimation based on Computer Vision, a Brief Case Study in a University Dining Hall", "authors": ["Shayan Rokhva", "Babak Teimourpour"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Questions & Recommendations: shayanrokhva1999@gmail.com; shayan1999rokh@yahoo.com", "url": "http://arxiv.org/abs/2507.14662v1", "summary": "Quantifying post-consumer food waste in institutional dining settings is\nessential for supporting data-driven sustainability strategies. This study\npresents a cost-effective computer vision framework that estimates plate-level\nfood waste by utilizing semantic segmentation of RGB images taken before and\nafter meal consumption across five Iranian dishes. Four fully supervised models\n(U-Net, U-Net++, and their lightweight variants) were trained using a capped\ndynamic inverse-frequency loss and AdamW optimizer, then evaluated through a\ncomprehensive set of metrics, including Pixel Accuracy, Dice, IoU, and a\ncustom-defined Distributional Pixel Agreement (DPA) metric tailored to the\ntask. All models achieved satisfying performance, and for each food type, at\nleast one model approached or surpassed 90% DPA, demonstrating strong alignment\nin pixel-wise proportion estimates. Lighter models with reduced parameter\ncounts offered faster inference, achieving real-time throughput on an NVIDIA T4\nGPU. Further analysis showed superior segmentation performance for dry and more\nrigid components (e.g., rice and fries), while more complex, fragmented, or\nviscous dishes, such as stews, showed reduced performance, specifically\npost-consumption. Despite limitations such as reliance on 2D imaging,\nconstrained food variety, and manual data collection, the proposed framework is\npioneering and represents a scalable, contactless solution for continuous\nmonitoring of food consumption. This research lays foundational groundwork for\nautomated, real-time waste tracking systems in large-scale food service\nenvironments and offers actionable insights and outlines feasible future\ndirections for dining hall management and policymakers aiming to reduce\ninstitutional food waste.", "comment": "Questions & Recommendations: shayanrokhva1999@gmail.com;\n  shayan1999rokh@yahoo.com", "pdf_url": "http://arxiv.org/pdf/2507.14662v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15666", "title": "Modeling CubeSat Storage Battery Discharge: Equivalent Circuit Versus Machine Learning Approaches", "authors": ["Igor Turkin", "Lina Volobuieva", "Andriy Chukhray", "Oleksandr Liubimov"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      13 pages, 15 figures", "url": "http://arxiv.org/abs/2507.15666v1", "summary": "The subject of the article is the study and comparison of two approaches to\nmodelling the battery discharge of a CubeSat satellite: analytical using\nequivalent circuit and machine learning. The article aims to make a reasoned\nchoice of the approach to modelling the battery discharge of a CubeSat\nsatellite. Modelling the battery discharge of a satellite will enable the\nprediction of the consequences of disconnecting the autonomous power system and\nensure the fault tolerance of equipment in orbit. Therefore, the selected study\nis relevant and promising. This study focuses on the analysis of CubeSat\nsatellite data, based explicitly on orbital data samples of the power system,\nwhich include data available at the time of the article publication. The\ndataset contains data on the voltage, current, and temperature of the battery\nand solar panels attached to the five sides of the satellite. In this context,\ntwo approaches are considered: analytical modelling based on physical laws and\nmachine learning, which uses empirical data to create a predictive model.\nResults: A comparative analysis of the modeling results reveals that the\nequivalent circuit approach has the advantage of transparency, as it identifies\npossible parameters that facilitate understanding of the relationships.\nHowever, the model is less flexible to environmental changes or non-standard\nsatellite behavior. The machine learning model demonstrated more accurate\nresults, as it can account for complex dependencies and adapt to actual\nconditions, even when they deviate from theoretical assumptions.", "comment": "13 pages, 15 figures", "pdf_url": "http://arxiv.org/pdf/2507.15666v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2110.03781", "title": "5G Traffic Prediction with Time Series Analysis", "authors": ["Nikhil Nayak", "Rujula Singh R", "Rameshwar Garg", "Varun Danda", "Chandana Kiran", "Kaustuv Saha"], "categories": ["cs.LG", "cs.NI", "68T50", "I.2.0; I.2.4; I.2.6"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      5 pages, 5 figures", "url": "http://arxiv.org/abs/2110.03781v2", "summary": "In today's day and age, a mobile phone has become a basic requirement needed\nfor anyone to thrive. With the cellular traffic demand increasing so\ndramatically, it is now necessary to accurately predict the user traffic in\ncellular networks, so as to improve the performance in terms of resource\nallocation and utilisation. Since traffic learning and prediction is a\nclassical and appealing field, which still yields many meaningful results,\nthere has been an increasing interest in leveraging Machine Learning tools to\nanalyse the total traffic served in a given region, to optimise the operation\nof the network. With the help of this project, we seek to exploit the traffic\nhistory by using it to predict the nature and occurrence of future traffic.\nFurthermore, we classify the traffic into particular application types, to\nincrease our understanding of the nature of the traffic. By leveraging the\npower of machine learning and identifying its usefulness in the field of\ncellular networks we try to achieve three main objectives - classification of\nthe application generating the traffic, prediction of packet arrival intensity\nand burst occurrence. The design of the prediction and classification system is\ndone using Long Short Term Memory (LSTM) model. The LSTM predictor developed in\nthis experiment would return the number of uplink packets and also estimate the\nprobability of burst occurrence in the specified future time interval. For the\npurpose of classification, the regression layer in our LSTM prediction model is\nreplaced by a softmax classifier which is used to classify the application\ngenerating the cellular traffic into one of the four applications including\nsurfing, video calling, voice calling, and video streaming.", "comment": "5 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2110.03781v2", "cate": "cs.LG", "date": "2021-10-07", "updated": "2025-07-20"}
{"id": "2507.15116", "title": "PAPR Analysis for MIMO FTN Signaling with Gaussian Symbols", "authors": ["Zichao Zhang", "Melda Yuksel", "Gokhan M. Guvensen", "Halim Yanikomeroglu"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15116v1", "summary": "Faster-than-Nyquist signaling serves as a promising solution for improving\nspectral efficiency in future generations of communications. However, its\nnature of fast acceleration brings highly overlapped pulses that lead to worse\npeak-to-average power ratio (PAPR) performance. In this paper, we investigate\nthe PAPR behavior of MIMO FTN using Gaussian symbols under optimal power\nallocation for two power constraints: fixed transmit power and fixed received\nsignal-to-noise-ratio (SNR). Our findings reveal that PAPR is mainly determined\nby the acceleration factor and the power constraint, but power allocation\noptimization does not change the PAPR behavior for Gaussian signaling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15116v1", "cate": "eess.SP", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15733", "title": "The theory of reachability in trace-pushdown systems", "authors": ["Dietrich Kuske"], "categories": ["cs.FL"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15733v1", "summary": "We consider pushdown systems that store, instead of a single word, a\nMazurkiewicz trace on its stack. These systems are special cases of valence\nautomata over graph monoids and subsume multi-stack systems. We identify a\nclass of such systems that allow to decide the first-order theory of their\nconfiguration graph with reachability.\n  This result complements results by D'Osualdo, Meyer, and Zetzsche (namely the\ndecidability for arbitrary pushdown systems under a severe restriction on the\ndependence alphabet).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15733v1", "cate": "cs.FL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14141", "title": "DIVER-0 : A Fully Channel Equivariant EEG Foundation Model", "authors": ["Danny Dongyeop Han", "Ahhyun Lucy Lee", "Taeyang Lee", "Yonghyeon Gwon", "Sebin Lee", "Seongjin Lee", "David Keetae Park", "Shinjae Yoo", "Jiook Cha", "Chun Kee Chung"], "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      11 pages, 1 figures, ICML 2025 Workshop on GenBio", "url": "http://arxiv.org/abs/2507.14141v1", "summary": "Electroencephalography (EEG) is a non-invasive technique widely used in\nbrain-computer interfaces and clinical applications, yet existing EEG\nfoundation models face limitations in modeling spatio-temporal brain dynamics\nand lack channel permutation equivariance, preventing robust generalization\nacross diverse electrode configurations. To address these challenges, we\npropose DIVER-0, a novel EEG foundation model that demonstrates how full\nspatio-temporal attention-rather than segregated spatial or temporal\nprocessing-achieves superior performance when properly designed with Rotary\nPosition Embedding (RoPE) for temporal relationships and binary attention\nbiases for channel differentiation. We also introduce Sliding Temporal\nConditional Positional Encoding (STCPE), which improves upon existing\nconditional positional encoding approaches by maintaining both temporal\ntranslation equivariance and channel permutation equivariance, enabling robust\nadaptation to arbitrary electrode configurations unseen during pretraining.\nExperimental results demonstrate that DIVER-0 achieves competitive performance\nwith only 10% of pretraining data while maintaining consistent results across\nall channel permutation conditions, validating its effectiveness for\ncross-dataset generalization and establishing key design principles for\nhandling the inherent heterogeneity of neural recording setups.", "comment": "11 pages, 1 figures, ICML 2025 Workshop on GenBio", "pdf_url": "http://arxiv.org/pdf/2507.14141v1", "cate": "eess.SP", "date": "2025-06-13", "updated": "2025-06-13"}
{"id": "2507.03034", "title": "Rethinking Data Protection in the (Generative) Artificial Intelligence Era", "authors": ["Yiming Li", "Shuo Shao", "Yu He", "Junfeng Guo", "Tianwei Zhang", "Zhan Qin", "Pin-Yu Chen", "Michael Backes", "Philip Torr", "Dacheng Tao", "Kui Ren"], "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV", "cs.CY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Perspective paper for a broader scientific audience. The first two authors contributed equally to this paper. 13 pages", "url": "http://arxiv.org/abs/2507.03034v3", "summary": "The (generative) artificial intelligence (AI) era has profoundly reshaped the\nmeaning and value of data. No longer confined to static content, data now\npermeates every stage of the AI lifecycle from the training samples that shape\nmodel parameters to the prompts and outputs that drive real-world model\ndeployment. This shift renders traditional notions of data protection\ninsufficient, while the boundaries of what needs safeguarding remain poorly\ndefined. Failing to safeguard data in AI systems can inflict societal and\nindividual, underscoring the urgent need to clearly delineate the scope of and\nrigorously enforce data protection. In this perspective, we propose a\nfour-level taxonomy, including non-usability, privacy preservation,\ntraceability, and deletability, that captures the diverse protection needs\narising in modern (generative) AI models and systems. Our framework offers a\nstructured understanding of the trade-offs between data utility and control,\nspanning the entire AI pipeline, including training datasets, model weights,\nsystem prompts, and AI-generated content. We analyze representative technical\napproaches at each level and reveal regulatory blind spots that leave critical\nassets exposed. By offering a structured lens to align future AI technologies\nand governance with trustworthy data practices, we underscore the urgency of\nrethinking data protection for modern AI techniques and provide timely guidance\nfor developers, researchers, and regulators alike.", "comment": "Perspective paper for a broader scientific audience. The first two\n  authors contributed equally to this paper. 13 pages", "pdf_url": "http://arxiv.org/pdf/2507.03034v3", "cate": "cs.LG", "date": "2025-07-03", "updated": "2025-07-19"}
{"id": "2507.15594", "title": "Improving Functional Reliability of Near-Field Monitoring for Emergency Braking in Autonomous Vehicles", "authors": ["Junnan Pan", "Prodromos Sotiriadis", "Vladislav Nenchev", "Ferdinand Englberger"], "categories": ["eess.SY", "cs.RO", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 pages, 3 figures, conference paper", "url": "http://arxiv.org/abs/2507.15594v1", "summary": "Autonomous vehicles require reliable hazard detection. However, primary\nsensor systems may miss near-field obstacles, resulting in safety risks.\nAlthough a dedicated fast-reacting near-field monitoring system can mitigate\nthis, it typically suffers from false positives. To mitigate these, in this\npaper, we introduce three monitoring strategies based on dynamic spatial\nproperties, relevant object sizes, and motion-aware prediction. In experiments\nin a validated simulation, we compare the initial monitoring strategy against\nthe proposed improvements. The results demonstrate that the proposed strategies\ncan significantly improve the reliability of near-field monitoring systems.", "comment": "6 pages, 3 figures, conference paper", "pdf_url": "http://arxiv.org/pdf/2507.15594v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14698", "title": "Spatial-Temporal Transformer with Curriculum Learning for EEG-Based Emotion Recognition", "authors": ["Xuetao Lin", "Tianhao Peng", "Peihong Dai", "Yu Liang", "Wenjun Wu"], "categories": ["cs.LG", "cs.AI", "cs.HC", "eess.SP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14698v1", "summary": "EEG-based emotion recognition plays an important role in developing adaptive\nbrain-computer communication systems, yet faces two fundamental challenges in\npractical implementations: (1) effective integration of non-stationary\nspatial-temporal neural patterns, (2) robust adaptation to dynamic emotional\nintensity variations in real-world scenarios. This paper proposes SST-CL, a\nnovel framework integrating spatial-temporal transformers with curriculum\nlearning. Our method introduces two core components: a spatial encoder that\nmodels inter-channel relationships and a temporal encoder that captures\nmulti-scale dependencies through windowed attention mechanisms, enabling\nsimultaneous extraction of spatial correlations and temporal dynamics from EEG\nsignals. Complementing this architecture, an intensity-aware curriculum\nlearning strategy progressively guides training from high-intensity to\nlow-intensity emotional states through dynamic sample scheduling based on a\ndual difficulty assessment. Comprehensive experiments on three benchmark\ndatasets demonstrate state-of-the-art performance across various emotional\nintensity levels, with ablation studies confirming the necessity of both\narchitectural components and the curriculum learning mechanism.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14698v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15532", "title": "Data-Efficient Safe Policy Improvement Using Parametric Structure", "authors": ["Kasper Engelen", "Guillermo A. Pérez", "Marnix Suilen"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted at ECAI 2025", "url": "http://arxiv.org/abs/2507.15532v1", "summary": "Safe policy improvement (SPI) is an offline reinforcement learning problem in\nwhich a new policy that reliably outperforms the behavior policy with high\nconfidence needs to be computed using only a dataset and the behavior policy.\nMarkov decision processes (MDPs) are the standard formalism for modeling\nenvironments in SPI. In many applications, additional information in the form\nof parametric dependencies between distributions in the transition dynamics is\navailable. We make SPI more data-efficient by leveraging these dependencies\nthrough three contributions: (1) a parametric SPI algorithm that exploits known\ncorrelations between distributions to more accurately estimate the transition\ndynamics using the same amount of data; (2) a preprocessing technique that\nprunes redundant actions from the environment through a game-based abstraction;\nand (3) a more advanced preprocessing technique, based on satisfiability modulo\ntheory (SMT) solving, that can identify more actions to prune. Empirical\nresults and an ablation study show that our techniques increase the data\nefficiency of SPI by multiple orders of magnitude while maintaining the same\nreliability guarantees.", "comment": "Accepted at ECAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.15532v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14631", "title": "$k$-PCA for (non-squared) Euclidean Distances: Polynomial Time Approximation", "authors": ["Daniel Greenhut", "Dan Feldman"], "categories": ["cs.LG", "cs.CG", "cs.DS"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14631v1", "summary": "Given an integer $k\\geq1$ and a set $P$ of $n$ points in $\\REAL^d$, the\nclassic $k$-PCA (Principle Component Analysis) approximates the affine\n\\emph{$k$-subspace mean} of $P$, which is the $k$-dimensional affine linear\nsubspace that minimizes its sum of squared Euclidean distances\n($\\ell_{2,2}$-norm) over the points of $P$, i.e., the mean of these distances.\nThe \\emph{$k$-subspace median} is the subspace that minimizes its sum of\n(non-squared) Euclidean distances ($\\ell_{2,1}$-mixed norm), i.e., their\nmedian. The median subspace is usually more sparse and robust to noise/outliers\nthan the mean, but also much harder to approximate since, unlike the\n$\\ell_{z,z}$ (non-mixed) norms, it is non-convex for $k<d-1$.\n  We provide the first polynomial-time deterministic algorithm whose both\nrunning time and approximation factor are not exponential in $k$. More\nprecisely, the multiplicative approximation factor is $\\sqrt{d}$, and the\nrunning time is polynomial in the size of the input. We expect that our\ntechnique would be useful for many other related problems, such as $\\ell_{2,z}$\nnorm of distances for $z\\not \\in \\br{1,2}$, e.g., $z=\\infty$, and handling\noutliers/sparsity.\n  Open code and experimental results on real-world datasets are also provided.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14631v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14670", "title": "Gene-DML: Dual-Pathway Multi-Level Discrimination for Gene Expression Prediction from Histopathology Images", "authors": ["Yaxuan Song", "Jianan Fan", "Hang Chang", "Weidong Cai"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      16 pages, 15 tables, 8 figures", "url": "http://arxiv.org/abs/2507.14670v1", "summary": "Accurately predicting gene expression from histopathology images offers a\nscalable and non-invasive approach to molecular profiling, with significant\nimplications for precision medicine and computational pathology. However,\nexisting methods often underutilize the cross-modal representation alignment\nbetween histopathology images and gene expression profiles across multiple\nrepresentational levels, thereby limiting their prediction performance. To\naddress this, we propose Gene-DML, a unified framework that structures latent\nspace through Dual-pathway Multi-Level discrimination to enhance correspondence\nbetween morphological and transcriptional modalities. The multi-scale\ninstance-level discrimination pathway aligns hierarchical histopathology\nrepresentations extracted at local, neighbor, and global levels with gene\nexpression profiles, capturing scale-aware morphological-transcriptional\nrelationships. In parallel, the cross-level instance-group discrimination\npathway enforces structural consistency between individual (image/gene)\ninstances and modality-crossed (gene/image, respectively) groups, strengthening\nthe alignment across modalities. By jointly modelling fine-grained and\nstructural-level discrimination, Gene-DML is able to learn robust cross-modal\nrepresentations, enhancing both predictive accuracy and generalization across\ndiverse biological contexts. Extensive experiments on public spatial\ntranscriptomics datasets demonstrate that Gene-DML achieves state-of-the-art\nperformance in gene expression prediction. The code and checkpoints will be\nreleased soon.", "comment": "16 pages, 15 tables, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.14670v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15671", "title": "BugScope: Learn to Find Bugs Like Human", "authors": ["Jinyao Guo", "Chengpeng Wang", "Dominic Deluca", "Jinjie Liu", "Zhuo Zhang", "Xiangyu Zhang"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      19 pages, 2 figure, 6 tables, 4 listings", "url": "http://arxiv.org/abs/2507.15671v1", "summary": "Detecting software bugs remains a fundamental challenge due to the extensive\ndiversity of real-world defects. Traditional static analysis tools often rely\non symbolic workflows, which restrict their coverage and hinder adaptability to\ncustomized bugs with diverse anti-patterns. While recent advances incorporate\nlarge language models (LLMs) to enhance bug detection, these methods continue\nto struggle with sophisticated bugs and typically operate within limited\nanalysis contexts. To address these challenges, we propose BugScope, an\nLLM-driven multi-agent system that emulates how human auditors learn new bug\npatterns from representative examples and apply that knowledge during code\nauditing. Given a set of examples illustrating both buggy and non-buggy\nbehaviors, BugScope synthesizes a retrieval strategy to extract relevant\ndetection contexts via program slicing and then constructs a tailored detection\nprompt to guide accurate reasoning by the LLM. Our evaluation on a curated\ndataset of 40 real-world bugs drawn from 21 widely-used open-source projects\ndemonstrates that BugScope achieves 87.04% precision and 90.00% recall,\nsurpassing state-of-the-art industrial tools by 0.44 in F1 score. Further\ntesting on large-scale open-source systems, including the Linux kernel,\nuncovered 141 previously unknown bugs, of which 78 have been fixed and 7\nconfirmed by developers, highlighting BugScope's substantial practical impact.", "comment": "19 pages, 2 figure, 6 tables, 4 listings", "pdf_url": "http://arxiv.org/pdf/2507.15671v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15196", "title": "On an entropy inequality for quadratic forms and applications", "authors": ["Alex Iosevich", "Thang Pham", "Nguyen Dac Quan", "Steven Senger", "Boqing Xue"], "categories": ["math.CA", "cs.IT", "math.CO", "math.IT"], "primary_category": "Subjects:       Classical Analysis and ODEs (math.CA)", "pdf_link": null, "comments": "Comments:      55 pages", "url": "http://arxiv.org/abs/2507.15196v1", "summary": "Let $\\phi(x,y)$ be a non-degenerate rational quadratic form. Let $X$ and $Y$\nbe independent $(s, C)$-Frostman random variables whose ranges are contained in\n$[-c_1, c_1]$, with $0<s<1$, $C,c_1\\geq 1$. We prove that there exist a\npositive constant $\\epsilon = \\epsilon(s,\\phi)$ and an integer\n$N=N(s,C,c_1,\\phi)$ such that\n  $$\\max\\left\\{H_n(X+Y),\\,H_n(\\phi(X,Y))\\right\\} \\ge n(s+\\epsilon)$$\n  for all $n>N$. The proof introduces a novel multi-step entropy framework,\ncombining the submodularity formula, the discretized entropy\nBalog-Szemer\\'{e}di-Gowers theorem, and state-of-the-art results on the\nFalconer distance problem, to reduce general forms to a diagonal core case. As\nan application, we derive a result on a discretized sum-product type problem.\nIn particular, for a $\\delta$-separated set $A\\subset [0, 1]$ of cardinality\n$\\delta^{-s}$, satisfying some non-concentration conditions, there exists\n$\\epsilon=\\epsilon(s, \\phi)>0$ such that $$E_\\delta(A+A) + E_\\delta(\\phi(A, A))\n\\gg\\delta^{-\\epsilon}(\\#A) $$ for all $\\delta$ small enough. Here by\n$E_\\delta(A)$ we mean the $\\delta$-covering number of $A$.", "comment": "55 pages", "pdf_url": "http://arxiv.org/pdf/2507.15196v1", "cate": "math.CA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2502.15441", "title": "On the Effectiveness of Large Language Models in Writing Alloy Formulas", "authors": ["Yang Hong", "Shan Jiang", "Yulei Fu", "Sarfraz Khurshid"], "categories": ["cs.SE", "cs.AI", "cs.FL", "cs.PL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.15441v1", "summary": "Declarative specifications have a vital role to play in developing safe and\ndependable software systems. Writing specifications correctly, however, remains\nparticularly challenging. This paper presents a controlled experiment on using\nlarge language models (LLMs) to write declarative formulas in the well-known\nlanguage Alloy. Our use of LLMs is three-fold. One, we employ LLMs to write\ncomplete Alloy formulas from given natural language descriptions (in English).\nTwo, we employ LLMs to create alternative but equivalent formulas in Alloy with\nrespect to given Alloy formulas. Three, we employ LLMs to complete sketches of\nAlloy formulas and populate the holes in the sketches by synthesizing Alloy\nexpressions and operators so that the completed formulas accurately represent\nthe desired properties (that are given in natural language). We conduct the\nexperimental evaluation using 11 well-studied subject specifications and employ\ntwo popular LLMs, namely ChatGPT and DeepSeek. The experimental results show\nthat the LLMs generally perform well in synthesizing complete Alloy formulas\nfrom input properties given in natural language or in Alloy, and are able to\nenumerate multiple unique solutions. Moreover, the LLMs are also successful at\ncompleting given sketches of Alloy formulas with respect to natural language\ndescriptions of desired properties (without requiring test cases). We believe\nLLMs offer a very exciting advance in our ability to write specifications, and\ncan help make specifications take a pivotal role in software development and\nenhance our ability to build robust software.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.15441v1", "cate": "cs.SE", "date": "2025-02-21", "updated": "2025-02-21"}
{"id": "2507.14144", "title": "Recursive KalmanNet: Analyse des capacités de généralisation d'un réseau de neurones récurrent guidé par un filtre de Kalman", "authors": ["Cyril Falcon", "Hassan Mortada", "Mathéo Clavaud", "Jean-Philippe Michel"], "categories": ["eess.SP", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      4 pages, in French language. 4 figures. Accepted for publication in GRETSI 2025 proceedings", "url": "http://arxiv.org/abs/2507.14144v1", "summary": "The Recursive KalmanNet, recently introduced by the authors, is a recurrent\nneural network guided by a Kalman filter, capable of estimating the state\nvariables and error covariance of stochastic dynamic systems from noisy\nmeasurements, without prior knowledge of the noise characteristics. This paper\nexplores its generalization capabilities in out-of-distribution scenarios,\nwhere the temporal dynamics of the test measurements differ from those\nencountered during training.\n  Le Recursive KalmanNet, r\\'ecemment introduit par les auteurs, est un\nr\\'eseau de neurones r\\'ecurrent guid\\'e par un filtre de Kalman, capable\nd'estimer les variables d'\\'etat et la covariance des erreurs des syst\\`emes\ndynamiques stochastiques \\`a partir de mesures bruit\\'ees, sans connaissance\npr\\'ealable des caract\\'eristiques des bruits. Cet article explore ses\ncapacit\\'es de g\\'en\\'eralisation dans des sc\\'enarios hors distribution, o\\`u\nles dynamiques temporelles des mesures de test diff\\`erent de celles\nrencontr\\'ees \\`a l'entra\\^inement.", "comment": "4 pages, in French language. 4 figures. Accepted for publication in\n  GRETSI 2025 proceedings", "pdf_url": "http://arxiv.org/pdf/2507.14144v1", "cate": "eess.SP", "date": "2025-06-25", "updated": "2025-06-25"}
{"id": "2507.13508", "title": "Fake or Real: The Impostor Hunt in Texts for Space Operations", "authors": ["Agata Kaczmarek", "Dawid Płudowski", "Piotr Wilczyński", "Przemysław Biecek", "Krzysztof Kotowski", "Ramez Shendy", "Jakub Nalepa", "Artur Janicki", "Evridiki Ntagiou"], "categories": ["cs.LG", "cs.CR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13508v2", "summary": "The \"Fake or Real\" competition hosted on Kaggle\n(https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt ) is the\nsecond part of a series of follow-up competitions and hackathons related to the\n\"Assurance for Space Domain AI Applications\" project funded by the European\nSpace Agency (https://assurance-ai.space-codev.org/ ). The competition idea is\nbased on two real-life AI security threats identified within the project --\ndata poisoning and overreliance in Large Language Models. The task is to\ndistinguish between the proper output from LLM and the output generated under\nmalicious modification of the LLM. As this problem was not extensively\nresearched, participants are required to develop new techniques to address this\nissue or adjust already existing ones to this problem's statement.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13508v2", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-21"}
{"id": "2507.15597", "title": "Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos", "authors": ["Hao Luo", "Yicheng Feng", "Wanpeng Zhang", "Sipeng Zheng", "Ye Wang", "Haoqi Yuan", "Jiazheng Liu", "Chaoyi Xu", "Qin Jin", "Zongqing Lu"], "categories": ["cs.CV", "cs.LG", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      37 pages", "url": "http://arxiv.org/abs/2507.15597v1", "summary": "We introduce Being-H0, a dexterous Vision-Language-Action model (VLA) trained\non large-scale human videos. Existing VLAs struggle with complex manipulation\ntasks requiring high dexterity and generalize poorly to novel scenarios and\ntasks, primarily due to their reliance on synthetic data with significant\nsim-to-real gaps or teleoperated demonstrations lacking scale and diversity. To\naddress this data bottleneck, we propose leveraging human hands as a foundation\nmanipulator, capitalizing on the rich dexterity and scalability present in web\ndata. Our approach centers on physical instruction tuning, a novel training\nparadigm that combines large-scale VLA pretraining from human videos, physical\nspace alignment for 3D reasoning, and post-training adaptation for robotic\ntasks. Additionally, we introduce a part-level motion tokenization method which\nachieves millimeter-level reconstruction accuracy to model precise hand\ntrajectories for action learning. To support our proposed paradigm, we further\ndevelop a comprehensive data curation pipeline that integrates heterogeneous\nsources -- including motion capture, VR, and RGB-only videos -- into a\nlarge-scale dataset with millions of motion-based instructional instances. We\nempirically show the excellence of Being-H0 in hand motion generation and\ninstruction following, and it also scales well with model and data sizes.\nImportantly, we observe the expected gains of Being-H0 in real-world robotic\nmanipulation as physical instruction tuning is applied. More details are\navailable at https://beingbeyond.github.io/Being-H0.", "comment": "37 pages", "pdf_url": "http://arxiv.org/pdf/2507.15597v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15454", "title": "ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting", "authors": ["Ruijie Zhu", "Mulin Yu", "Linning Xu", "Lihan Jiang", "Yixuan Li", "Tianzhu Zhang", "Jiangmiao Pang", "Bo Dai"], "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.HC"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.15454v1", "summary": "3D Gaussian Splatting is renowned for its high-fidelity reconstructions and\nreal-time novel view synthesis, yet its lack of semantic understanding limits\nobject-level perception. In this work, we propose ObjectGS, an object-aware\nframework that unifies 3D scene reconstruction with semantic understanding.\nInstead of treating the scene as a unified whole, ObjectGS models individual\nobjects as local anchors that generate neural Gaussians and share object IDs,\nenabling precise object-level reconstruction. During training, we dynamically\ngrow or prune these anchors and optimize their features, while a one-hot ID\nencoding with a classification loss enforces clear semantic constraints. We\nshow through extensive experiments that ObjectGS not only outperforms\nstate-of-the-art methods on open-vocabulary and panoptic segmentation tasks,\nbut also integrates seamlessly with applications like mesh extraction and scene\nediting. Project page: https://ruijiezhu94.github.io/ObjectGS_page", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.15454v1", "cate": "cs.GR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15581", "title": "Metric assessment protocol in the context of answer fluctuation on MCQ tasks", "authors": ["Ekaterina Goliakova", "Xavier Renard", "Marie-Jeanne Lesot", "Thibault Laugel", "Christophe Marsala", "Marcin Detyniecki"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15581v1", "summary": "Using multiple-choice questions (MCQs) has become a standard for assessing\nLLM capabilities efficiently. A variety of metrics can be employed for this\ntask. However, previous research has not conducted a thorough assessment of\nthem. At the same time, MCQ evaluation suffers from answer fluctuation: models\nproduce different results given slight changes in prompts. We suggest a metric\nassessment protocol in which evaluation methodologies are analyzed through\ntheir connection with fluctuation rates, as well as original performance. Our\nresults show that there is a strong link between existing metrics and the\nanswer changing, even when computed without any additional prompt variants. A\nnovel metric, worst accuracy, demonstrates the highest association on the\nprotocol.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15581v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14668", "title": "Rec-AD: An Efficient Computation Framework for FDIA Detection Based on Tensor Train Decomposition and Deep Learning Recommendation Model", "authors": ["Yunfeng Li", "Junhong Liu", "Zhaohui Yang", "Guofu Liao", "Chuyun Zhang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      15 pages, 14 figures", "url": "http://arxiv.org/abs/2507.14668v1", "summary": "Deep learning models have been widely adopted for False Data Injection Attack\n(FDIA) detection in smart grids due to their ability to capture unstructured\nand sparse features. However, the increasing system scale and data\ndimensionality introduce significant computational and memory burdens,\nparticularly in large-scale industrial datasets, limiting detection efficiency.\nTo address these issues, this paper proposes Rec-AD, a computationally\nefficient framework that integrates Tensor Train decomposition with the Deep\nLearning Recommendation Model (DLRM). Rec-AD enhances training and inference\nefficiency through embedding compression, optimized data access via index\nreordering, and a pipeline training mechanism that reduces memory communication\noverhead. Fully compatible with PyTorch, Rec-AD can be integrated into existing\nFDIA detection systems without code modifications. Experimental results show\nthat Rec-AD significantly improves computational throughput and real-time\ndetection performance, narrowing the attack window and increasing attacker\ncost. These advancements strengthen edge computing capabilities and\nscalability, providing robust technical support for smart grid security.", "comment": "15 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.14668v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14675", "title": "Docopilot: Improving Multimodal Models for Document-Level Understanding", "authors": ["Yuchen Duan", "Zhe Chen", "Yusong Hu", "Weiyun Wang", "Shenglong Ye", "Botian Shi", "Lewei Lu", "Qibin Hou", "Tong Lu", "Hongsheng Li", "Jifeng Dai", "Wenhai Wang"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14675v1", "summary": "Despite significant progress in multimodal large language models (MLLMs),\ntheir performance on complex, multi-page document comprehension remains\ninadequate, largely due to the lack of high-quality, document-level datasets.\nWhile current retrieval-augmented generation (RAG) methods offer partial\nsolutions, they suffer from issues, such as fragmented retrieval contexts,\nmulti-stage error accumulation, and extra time costs of retrieval. In this\nwork, we present a high-quality document-level dataset, Doc-750K, designed to\nsupport in-depth understanding of multimodal documents. This dataset includes\ndiverse document structures, extensive cross-page dependencies, and real\nquestion-answer pairs derived from the original documents. Building on the\ndataset, we develop a native multimodal model, Docopilot, which can accurately\nhandle document-level dependencies without relying on RAG. Experiments\ndemonstrate that Docopilot achieves superior coherence, accuracy, and\nefficiency in document understanding tasks and multi-turn interactions, setting\na new baseline for document-level multimodal understanding. Data, code, and\nmodels are released at https://github.com/OpenGVLab/Docopilot", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14675v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15822", "title": "Do AI models help produce verified bug fixes?", "authors": ["Li Huang", "Ilgiz Mustafin", "Marco Piccioni", "Alessandro Schena", "Reto Weber", "Bertrand Meyer"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15822v1", "summary": "Among areas of software engineering where AI techniques -- particularly,\nLarge Language Models -- seem poised to yield dramatic improvements, an\nattractive candidate is Automatic Program Repair (APR), the production of\nsatisfactory corrections to software bugs. Does this expectation materialize in\npractice? How do we find out, making sure that proposed corrections actually\nwork? If programmers have access to LLMs, how do they actually use them to\ncomplement their own skills?\n  To answer these questions, we took advantage of the availability of a\nprogram-proving environment, which formally determines the correctness of\nproposed fixes, to conduct a study of program debugging with two randomly\nassigned groups of programmers, one with access to LLMs and the other without,\nboth validating their answers through the proof tools. The methodology relied\non a division into general research questions (Goals in the Goal-Query-Metric\napproach), specific elements admitting specific answers (Queries), and\nmeasurements supporting these answers (Metrics). While applied so far to a\nlimited sample size, the results are a first step towards delineating a proper\nrole for AI and LLMs in providing guaranteed-correct fixes to program bugs.\n  These results caused surprise as compared to what one might expect from the\nuse of AI for debugging and APR. The contributions also include: a detailed\nmethodology for experiments in the use of LLMs for debugging, which other\nprojects can reuse; a fine-grain analysis of programmer behavior, made possible\nby the use of full-session recording; a definition of patterns of use of LLMs,\nwith 7 distinct categories; and validated advice for getting the best of LLMs\nfor debugging and Automatic Program Repair.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15822v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15231", "title": "The Labeled Coupon Collector Problem", "authors": ["Andrew Tan", "Oriel Limor", "Daniella Bar-Lev", "Ryan Gabrys", "Zohar Yakhini", "Paul H. Siegel"], "categories": ["cs.DM", "cs.IT", "math.CO", "math.IT"], "primary_category": "Subjects:       Discrete Mathematics (cs.DM)", "pdf_link": null, "comments": "Comments:      Accepted for presentation in ITW 2025, which will be held at Sydney form Sept. 29 to Oct. 3 in 2025", "url": "http://arxiv.org/abs/2507.15231v1", "summary": "We generalize the well-known Coupon Collector Problem (CCP) in combinatorics.\nOur problem is to find the minimum and expected number of draws, with\nreplacement, required to recover $n$ distinctly labeled coupons, with each draw\nconsisting of a random subset of $k$ different coupons and a random ordering of\ntheir associated labels. We specify two variations of the problem, Type-I in\nwhich the set of labels is known at the start, and Type-II in which the set of\nlabels is unknown at the start. We show that our problem can be viewed as an\nextension of the separating system problem introduced by R\\'enyi and Katona,\nprovide a full characterization of the minimum, and provide a numerical\napproach to finding the expectation using a Markov chain model, with special\nattention given to the case where two coupons are drawn at a time.", "comment": "Accepted for presentation in ITW 2025, which will be held at Sydney\n  form Sept. 29 to Oct. 3 in 2025", "pdf_url": "http://arxiv.org/pdf/2507.15231v1", "cate": "cs.DM", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2501.14725", "title": "Fine-Grained Complexity of Ambiguity Problems on Automata and Directed Graphs", "authors": ["Karolina Drabik", "Anita Dürr", "Fabian Frei", "Filip Mazowiecki", "Karol Węgrzycki"], "categories": ["cs.FL"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.14725v3", "summary": "In the field of computational logic, two classes of finite automata are\nconsidered fundamental: deterministic and nondeterministic automata (DFAs and\nNFAs). In a more fine-grained approach three natural intermediate classes were\nintroduced, defined by restricting the number of accepting runs of the input\nNFA. The classes are called: unambiguous, finitely ambiguous, and polynomially\nambiguous finite automata. It was observed that central problems, like\nequivalence, become tractable when the input NFA is restricted to some of these\nclasses. This naturally brought interest into problems determining whether an\ninput NFA belongs to the intermediate classes.\n  Our first result is a nearly complete characterization of the fine-grained\ncomplexity of these problems. We show that the respective quadratic and cubic\nrunning times of Allauzen et al. are optimal under the Orthogonal Vectors\nhypothesis or the k-Cycle hypothesis, for alphabets with at least two symbols.\nIn contrast, for unary alphabets we show that all aforementioned variants of\nambiguity can be decided in almost linear time.\n  Finally, we study determinisability of unambiguous weighted automata. We\npositively resolve a conjecture of Allauzen and Mohri, proving that their\nquadratic-time algorithm for verifying determinisability of unambiguous\nweighted automata is optimal, assuming the Orthogonal Vectors hypothesis or the\nk-Cycle hypothesis. We additionally show that for unary alphabets, this can be\ndecided in linear time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.14725v3", "cate": "cs.FL", "date": "2025-01-24", "updated": "2025-07-21"}
{"id": "2507.14146", "title": "Estimating Markers of Driving Stress through Multimodal Physiological Monitoring", "authors": ["Kleanthis Avramidis", "Emily Zhou", "Tiantian Feng", "Hossein Hamidi Shishavan", "Frederico Marcolino Quintao Severgnini", "Danny J. Lohan", "Paul Schmalenberg", "Ercan M. Dede", "Shrikanth Narayanan"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      11 pages, 7 figures, 3 tables. This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.14146v1", "summary": "Understanding and mitigating driving stress is vital for preventing accidents\nand advancing both road safety and driver well-being. While vehicles are\nequipped with increasingly sophisticated safety systems, many limits exist in\ntheir ability to account for variable driving behaviors and environmental\ncontexts. In this study we examine how short-term stressor events impact\ndrivers' physiology and their behavioral responses behind the wheel. Leveraging\na controlled driving simulation setup, we collected physiological signals from\n31 adult participants and designed a multimodal machine learning system to\nestimate the presence of stressors. Our analysis explores the model sensitivity\nand temporal dynamics against both known and novel emotional inducers, and\nexamines the relationship between predicted stress and observable patterns of\nvehicle control. Overall, this study demonstrates the potential of linking\nphysiological signals with contextual and behavioral cues in order to improve\nreal-time estimation of driving stress.", "comment": "11 pages, 7 figures, 3 tables. This work has been submitted to the\n  IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.14146v1", "cate": "eess.SP", "date": "2025-07-01", "updated": "2025-07-01"}
{"id": "2507.15857", "title": "Diffusion Beats Autoregressive in Data-Constrained Settings", "authors": ["Mihir Prabhudesai", "Menging Wu", "Amir Zadeh", "Katerina Fragkiadaki", "Deepak Pathak"], "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Project Webpage: this https URL", "url": "http://arxiv.org/abs/2507.15857v1", "summary": "Autoregressive (AR) models have long dominated the landscape of large\nlanguage models, driving progress across a wide range of tasks. Recently,\ndiffusion-based language models have emerged as a promising alternative, though\ntheir advantages over AR models remain underexplored. In this paper, we\nsystematically study masked diffusion models in data-constrained settings-where\ntraining involves repeated passes over limited data-and find that they\nsignificantly outperform AR models when compute is abundant but data is scarce.\nDiffusion models make better use of repeated data, achieving lower validation\nloss and superior downstream performance. We interpret this advantage as\nimplicit data augmentation: masked diffusion exposes the model to a diverse\ndistribution of token orderings and prediction tasks, unlike AR's fixed\nleft-to-right factorization. We find new scaling laws for diffusion models and\nderive a closed-form expression for the critical compute threshold at which\ndiffusion begins to outperform AR. These results suggest that when data, not\ncompute, is the bottleneck, diffusion models offer a compelling alternative to\nthe standard AR paradigm. Our code is available at:\nhttps://diffusion-scaling.github.io.", "comment": "Project Webpage: https://diffusion-scaling.github.io", "pdf_url": "http://arxiv.org/pdf/2507.15857v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15743", "title": "Towards physician-centered oversight of conversational diagnostic AI", "authors": ["Elahe Vedadi", "David Barrett", "Natalie Harris", "Ellery Wulczyn", "Shashir Reddy", "Roma Ruparel", "Mike Schaekermann", "Tim Strother", "Ryutaro Tanno", "Yash Sharma", "Jihyeon Lee", "Cían Hughes", "Dylan Slack", "Anil Palepu", "Jan Freyberg", "Khaled Saab", "Valentin Liévin", "Wei-Hung Weng", "Tao Tu", "Yun Liu", "Nenad Tomasev", "Kavita Kulkarni", "S. Sara Mahdavi", "Kelvin Guu", "Joëlle Barral", "Dale R. Webster", "James Manyika", "Avinatan Hassidim", "Katherine Chou", "Yossi Matias", "Pushmeet Kohli", "Adam Rodman", "Vivek Natarajan", "Alan Karthikesalingam", "David Stutz"], "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15743v1", "summary": "Recent work has demonstrated the promise of conversational AI systems for\ndiagnostic dialogue. However, real-world assurance of patient safety means that\nproviding individual diagnoses and treatment plans is considered a regulated\nactivity by licensed professionals. Furthermore, physicians commonly oversee\nother team members in such activities, including nurse practitioners (NPs) or\nphysician assistants/associates (PAs). Inspired by this, we propose a framework\nfor effective, asynchronous oversight of the Articulate Medical Intelligence\nExplorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent\nsystem that performs history taking within guardrails, abstaining from\nindividualized medical advice. Afterwards, g-AMIE conveys assessments to an\noverseeing primary care physician (PCP) in a clinician cockpit interface. The\nPCP provides oversight and retains accountability of the clinical decision.\nThis effectively decouples oversight from intake and can thus happen\nasynchronously. In a randomized, blinded virtual Objective Structured Clinical\nExamination (OSCE) of text consultations with asynchronous oversight, we\ncompared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across\n60 scenarios, g-AMIE outperformed both groups in performing high-quality\nintake, summarizing cases, and proposing diagnoses and management plans for the\noverseeing PCP to review. This resulted in higher quality composite decisions.\nPCP oversight of g-AMIE was also more time-efficient than standalone PCP\nconsultations in prior work. While our study does not replicate existing\nclinical practices and likely underestimates clinicians' capabilities, our\nresults demonstrate the promise of asynchronous oversight as a feasible\nparadigm for diagnostic AI systems to operate under expert human oversight for\nenhancing real-world care.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15743v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15618", "title": "TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft II", "authors": ["Weiyu Ma", "Jiwen Jiang", "Haobo Fu", "Haifeng Zhang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15618v1", "summary": "We present an adapter-based approach for tactical conditioning of StarCraft\nII AI agents. Current agents, while powerful, lack the ability to adapt their\nstrategies based on high-level tactical directives. Our method freezes a\npre-trained policy network (DI-Star) and attaches lightweight adapter modules\nto each action head, conditioned on a tactical tensor that encodes strategic\npreferences. By training these adapters with KL divergence constraints, we\nensure the policy maintains core competencies while exhibiting tactical\nvariations. Experimental results show our approach successfully modulates agent\nbehavior across tactical dimensions including aggression, expansion patterns,\nand technology preferences, while maintaining competitive performance. Our\nmethod enables flexible tactical control with minimal computational overhead,\noffering practical strategy customization for complex real-time strategy games.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15618v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14677", "title": "Revisiting Graph Contrastive Learning on Anomaly Detection: A Structural Imbalance Perspective", "authors": ["Yiming Xu", "Zhen Peng", "Bin Shi", "Xu Hua", "Bo Dong", "Song Wang", "Chen Chen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by AAAI2025", "url": "http://arxiv.org/abs/2507.14677v1", "summary": "The superiority of graph contrastive learning (GCL) has prompted its\napplication to anomaly detection tasks for more powerful risk warning systems.\nUnfortunately, existing GCL-based models tend to excessively prioritize overall\ndetection performance while neglecting robustness to structural imbalance,\nwhich can be problematic for many real-world networks following power-law\ndegree distributions. Particularly, GCL-based methods may fail to capture tail\nanomalies (abnormal nodes with low degrees). This raises concerns about the\nsecurity and robustness of current anomaly detection algorithms and therefore\nhinders their applicability in a variety of realistic high-risk scenarios. To\nthe best of our knowledge, research on the robustness of graph anomaly\ndetection to structural imbalance has received little scrutiny. To address the\nabove issues, this paper presents a novel GCL-based framework named AD-GCL. It\ndevises the neighbor pruning strategy to filter noisy edges for head nodes and\nfacilitate the detection of genuine tail nodes by aligning from head nodes to\nforged tail nodes. Moreover, AD-GCL actively explores potential neighbors to\nenlarge the receptive field of tail nodes through anomaly-guided neighbor\ncompletion. We further introduce intra- and inter-view consistency loss of the\noriginal and augmentation graph for enhanced representation. The performance\nevaluation of the whole, head, and tail nodes on multiple datasets validates\nthe comprehensive superiority of the proposed AD-GCL in detecting both head\nanomalies and tail anomalies.", "comment": "Accepted by AAAI2025", "pdf_url": "http://arxiv.org/pdf/2507.14677v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14680", "title": "WSI-Agents: A Collaborative Multi-Agent System for Multi-Modal Whole Slide Image Analysis", "authors": ["Xinheng Lyu", "Yuci Liang", "Wenting Chen", "Meidan Ding", "Jiaqi Yang", "Guolin Huang", "Daokun Zhang", "Xiangjian He", "Linlin Shen"], "categories": ["cs.CV", "cs.AI", "68T07, 92C55", "I.2.7; I.4.8; J.3"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14680v1", "summary": "Whole slide images (WSIs) are vital in digital pathology, enabling gigapixel\ntissue analysis across various pathological tasks. While recent advancements in\nmulti-modal large language models (MLLMs) allow multi-task WSI analysis through\nnatural language, they often underperform compared to task-specific models.\nCollaborative multi-agent systems have emerged as a promising solution to\nbalance versatility and accuracy in healthcare, yet their potential remains\nunderexplored in pathology-specific domains. To address these issues, we\npropose WSI-Agents, a novel collaborative multi-agent system for multi-modal\nWSI analysis. WSI-Agents integrates specialized functional agents with robust\ntask allocation and verification mechanisms to enhance both task-specific\naccuracy and multi-task versatility through three components: (1) a task\nallocation module assigning tasks to expert agents using a model zoo of patch\nand WSI level MLLMs, (2) a verification mechanism ensuring accuracy through\ninternal consistency checks and external validation using pathology knowledge\nbases and domain-specific models, and (3) a summary module synthesizing the\nfinal summary with visual interpretation maps. Extensive experiments on\nmulti-modal WSI benchmarks show WSI-Agents's superiority to current WSI MLLMs\nand medical agent frameworks across diverse tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14680v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15828", "title": "Investigating the Use of LLMs for Evidence Briefings Generation in Software Engineering", "authors": ["Mauro Marcelino", "Marcos Alves", "Bianca Trinkenreich", "Bruno Cartaxo", "Sérgio Soares", "Simone D. J. Barbosa", "Marcos Kalinowski"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      ESEM 2025 Registered Report with an IPA (In Principle Acceptance) for the Empirical Software Engineering journal", "url": "http://arxiv.org/abs/2507.15828v1", "summary": "[Context] An evidence briefing is a concise and objective transfer medium\nthat can present the main findings of a study to software engineers in the\nindustry. Although practitioners and researchers have deemed Evidence Briefings\nuseful, their production requires manual labor, which may be a significant\nchallenge to their broad adoption. [Goal] The goal of this registered report is\nto describe an experimental protocol for evaluating LLM-generated evidence\nbriefings for secondary studies in terms of content fidelity, ease of\nunderstanding, and usefulness, as perceived by researchers and practitioners,\ncompared to human-made briefings. [Method] We developed an RAG-based LLM tool\nto generate evidence briefings. We used the tool to automatically generate two\nevidence briefings that had been manually generated in previous research\nefforts. We designed a controlled experiment to evaluate how the LLM-generated\nbriefings compare to the human-made ones regarding perceived content fidelity,\nease of understanding, and usefulness. [Results] To be reported after the\nexperimental trials. [Conclusion] Depending on the experiment results.", "comment": "ESEM 2025 Registered Report with an IPA (In Principle Acceptance) for\n  the Empirical Software Engineering journal", "pdf_url": "http://arxiv.org/pdf/2507.15828v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15367", "title": "Multi-beam Beamforming in RIS-aided MIMO Subject to Reradiation Mask Constraints -- Optimization and Machine Learning Design", "authors": ["Shumin Wang", "Hajar El Hassani", "Marco Di Renzo", "Marios Poulakis"], "categories": ["math.OC", "cs.AI", "cs.IT", "math.IT"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15367v1", "summary": "Reconfigurable intelligent surfaces (RISs) are an emerging technology for\nimproving spectral efficiency and reducing power consumption in future wireless\nsystems. This paper investigates the joint design of the transmit precoding\nmatrices and the RIS phase shift vector in a multi-user RIS-aided\nmultiple-input multiple-output (MIMO) communication system. We formulate a\nmax-min optimization problem to maximize the minimum achievable rate while\nconsidering transmit power and reradiation mask constraints. The achievable\nrate is simplified using the Arimoto-Blahut algorithm, and the problem is\nbroken into quadratic programs with quadratic constraints (QPQC) sub-problems\nusing an alternating optimization approach. To improve efficiency, we develop a\nmodel-based neural network optimization that utilizes the one-hot encoding for\nthe angles of incidence and reflection. We address practical RIS limitations by\nusing a greedy search algorithm to solve the optimization problem for discrete\nphase shifts. Simulation results demonstrate that the proposed methods\neffectively shape the multi-beam radiation pattern towards desired directions\nwhile satisfying reradiation mask constraints. The neural network design\nreduces the execution time, and the discrete phase shift scheme performs well\nwith a small reduction of the beamforming gain by using only four phase shift\nlevels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15367v1", "cate": "math.OC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14147", "title": "Graph Convolutional Neural Networks to Model the Brain for Insomnia", "authors": ["Kevin Monteiro", "Sam Nallaperuma-Herzberg", "Martina Mason", "Steve Niederer"], "categories": ["eess.SP", "cs.LG", "q-bio.NC"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      12 pages, 6 figures. This version has been accepted as a full paper at the 2025 AI in Healthcare (AIiH) Conference", "url": "http://arxiv.org/abs/2507.14147v1", "summary": "Insomnia affects a vast population of the world and can have a wide range of\ncauses. Existing treatments for insomnia have been linked with many side\neffects like headaches, dizziness, etc. As such, there is a clear need for\nimproved insomnia treatment. Brain modelling has helped with assessing the\neffects of brain pathology on brain network dynamics and with supporting\nclinical decisions in the treatment of Alzheimer's disease, epilepsy, etc.\nHowever, such models have not been developed for insomnia. Therefore, this\nproject attempts to understand the characteristics of the brain of individuals\nexperiencing insomnia using continuous long-duration EEG data. Brain networks\nare derived based on functional connectivity and spatial distance between EEG\nchannels. The power spectral density of the channels is then computed for the\nmajor brain wave frequency bands. A graph convolutional neural network (GCNN)\nmodel is then trained to capture the functional characteristics associated with\ninsomnia and configured for the classification task to judge performance.\nResults indicated a 50-second non-overlapping sliding window was the most\nsuitable choice for EEG segmentation. This approach achieved a classification\naccuracy of 70% at window level and 68% at subject level. Additionally, the\nomission of EEG channels C4-P4, F4-C4 and C4-A1 caused higher degradation in\nmodel performance than the removal of other channels. These channel electrodes\nare positioned near brain regions known to exhibit atypical levels of\nfunctional connectivity in individuals with insomnia, which can explain such\nresults.", "comment": "12 pages, 6 figures. This version has been accepted as a full paper\n  at the 2025 AI in Healthcare (AIiH) Conference", "pdf_url": "http://arxiv.org/pdf/2507.14147v1", "cate": "eess.SP", "date": "2025-07-02", "updated": "2025-07-02"}
{"id": "2507.14346", "title": "Towards Accurate Phonetic Error Detection Through Phoneme Similarity Modeling", "authors": ["Xuanru Zhou", "Jiachen Lian", "Cheol Jun Cho", "Tejas Prabhune", "Shuhe Li", "William Li", "Rodrigo Ortiz", "Zoe Ezzes", "Jet Vonk", "Brittany Morin", "Rian Bogley", "Lisa Wauters", "Zachary Miller", "Maria Gorno-Tempini", "Gopala Anumanchipalli"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      2025 Interspeech", "url": "http://arxiv.org/abs/2507.14346v1", "summary": "Phonetic error detection, a core subtask of automatic pronunciation\nassessment, identifies pronunciation deviations at the phoneme level. Speech\nvariability from accents and dysfluencies challenges accurate phoneme\nrecognition, with current models failing to capture these discrepancies\neffectively. We propose a verbatim phoneme recognition framework using\nmulti-task training with novel phoneme similarity modeling that transcribes\nwhat speakers actually say rather than what they're supposed to say. We develop\nand open-source \\textit{VCTK-accent}, a simulated dataset containing phonetic\nerrors, and propose two novel metrics for assessing pronunciation differences.\nOur work establishes a new benchmark for phonetic error detection.", "comment": "2025 Interspeech", "pdf_url": "http://arxiv.org/pdf/2507.14346v1", "cate": "eess.AS", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2305.10442", "title": "CBAGAN-RRT: Convolutional Block Attention Generative Adversarial Network for Sampling-Based Path Planning", "authors": ["Abhinav Sagar", "Sai Teja Gilukara"], "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2305.10442v3", "summary": "Sampling-based path planning algorithms play an important role in autonomous\nrobotics. However, a common problem among these algorithms is that the initial\npath generated is not optimal, and the convergence is too slow for real-world\napplications. In this paper, we propose a novel image-based learning algorithm\nusing a Convolutional Block Attention Generative Adversarial Network\n(CBAGAN-RRT) with a combination of spatial and channel attention and a novel\nloss function to design the heuristics, find a better optimal path, and improve\nthe convergence of the algorithm, both concerning time and speed. The\nprobability distribution of the paths generated from our GAN model is used to\nguide the sampling process for the RRT algorithm. We demonstrate that our\nalgorithm outperforms the previous state-of-the-art algorithms using both the\nimage quality generation metrics, like IOU Score, Dice Score, FID score, and\npath planning metrics like time cost and the number of nodes. Ablation studies\nshow the effectiveness of various components in our network architecture. The\nadvantage of our approach is that we can avoid the complicated preprocessing in\nthe state space, our model can be generalized to complex environments like\nthose containing turns and narrow passages without loss of accuracy, and our\nmodel can be easily integrated with other sampling-based path planning\nalgorithms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2305.10442v3", "cate": "cs.RO", "date": "2023-05-13", "updated": "2025-07-20"}
{"id": "2507.15846", "title": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding", "authors": ["Fei Tang", "Zhangxuan Gu", "Zhengxi Lu", "Xuyang Liu", "Shuheng Shen", "Changhua Meng", "Wen Wang", "Wenqi Zhang", "Yongliang Shen", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15846v1", "summary": "Graphical User Interface (GUI) grounding maps natural language instructions\nto precise interface locations for autonomous interaction. Current\nreinforcement learning approaches use binary rewards that treat elements as\nhit-or-miss targets, creating sparse signals that ignore the continuous nature\nof spatial interactions. Motivated by human clicking behavior that naturally\nforms Gaussian distributions centered on target elements, we introduce GUI\nGaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that\nmodels GUI elements as continuous Gaussian distributions across the interface\nplane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point\nrewards model precise localization through exponentially decaying distributions\ncentered on element centroids, while coverage rewards assess spatial alignment\nby measuring the overlap between predicted Gaussian distributions and target\nregions. To handle diverse element scales, we develop an adaptive variance\nmechanism that calibrates reward distributions based on element dimensions.\nThis framework transforms GUI grounding from sparse binary classification to\ndense continuous optimization, where Gaussian distributions generate rich\ngradient signals that guide models toward optimal interaction positions.\nExtensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro\nbenchmarks demonstrate that GUI-G$^2$, substantially outperforms\nstate-of-the-art method UI-TARS-72B, with the most significant improvement of\n24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides\nsuperior robustness to interface variations and enhanced generalization to\nunseen layouts, establishing a new paradigm for spatial reasoning in GUI\ninteraction tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15846v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15758", "title": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization", "authors": ["Xingyu Wu", "Yuchen Yan", "Shangke Lyu", "Linjuan Wu", "Yiwen Qiu", "Yongliang Shen", "Weiming Lu", "Jian Shao", "Jun Xiao", "Yueting Zhuang"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      GitHub: this https URL Project: this https URL", "url": "http://arxiv.org/abs/2507.15758v1", "summary": "Large reasoning models have achieved remarkable performance through extended\nchain-of-thought sequences, yet this computational freedom leads to excessive\ntoken generation even for simple problems. We present Length-Adaptive Policy\nOptimization (LAPO), a novel framework that transforms reasoning length control\nfrom an external constraint into an intrinsic model capability. Unlike existing\napproaches that impose rigid limits or rely on post-hoc interventions, LAPO\nenables models to internalize an understanding of appropriate reasoning depth\nthrough a two-stage reinforcement learning process. In the first stage, models\nlearn natural reasoning patterns by discovering the statistical distribution of\nsuccessful solution lengths. The second stage leverages these patterns as\nmeta-cognitive guidance, embedding them directly within the model's reasoning\ncontext to ensure inference-time flexibility. Experiments on mathematical\nreasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\\%\nwhile improving accuracy by 2.3\\%. Our analysis reveals that models trained\nwith LAPO develop emergent abilities to allocate computational resources based\non problem complexity, achieving efficient reasoning without sacrificing\nquality.", "comment": "GitHub:https://github.com/zju-real/lapo;\n  Project:https://zju-real.github.io/lapo", "pdf_url": "http://arxiv.org/pdf/2507.15758v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14679", "title": "GCC-Spam: Spam Detection via GAN, Contrastive Learning, and Character Similarity Networks", "authors": ["Zixin Xu", "Zhijie Wang", "Zhiyuan Pan"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14679v1", "summary": "The exponential growth of spam text on the Internet necessitates robust\ndetection mechanisms to mitigate risks such as information leakage and social\ninstability. This work addresses two principal challenges: adversarial\nstrategies employed by spammers and the scarcity of labeled data. We propose a\nnovel spam-text detection framework GCC-Spam, which integrates three core\ninnovations. First, a character similarity network captures orthographic and\nphonetic features to counter character-obfuscation attacks and furthermore\nproduces sentence embeddings for downstream classification. Second, contrastive\nlearning enhances discriminability by optimizing the latent-space distance\nbetween spam and normal texts. Third, a Generative Adversarial Network (GAN)\ngenerates realistic pseudo-spam samples to alleviate data scarcity while\nimproving model robustness and classification accuracy. Extensive experiments\non real-world datasets demonstrate that our model outperforms baseline\napproaches, achieving higher detection rates with significantly fewer labeled\nexamples.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14679v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14686", "title": "From Semantics, Scene to Instance-awareness: Distilling Foundation Model for Open-vocabulary Situation Recognition", "authors": ["Chen Cai", "Tianyi Liu", "Jianjun Gao", "Wenyang Liu", "Kejun Wu", "Ruoyu Wang", "Yi Wang", "Soo Chin Liew"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14686v1", "summary": "Recent Multimodal Large Language Models (MLLMs) exhibit strong zero-shot\nabilities but struggle with complex Grounded Situation Recognition (GSR) and\nare resource-intensive for edge device deployment. Meanwhile, conventional GSR\nmodels often lack generalization ability, falling short in recognizing unseen\nand rare situations. In this paper, we exploit transferring knowledge from a\nteacher MLLM to a small GSR model to enhance its generalization and zero-shot\nabilities, thereby introducing the task of Open-vocabulary Grounded Situation\nRecognition (Ov-GSR). To achieve this, we propose Multimodal Interactive Prompt\nDistillation (MIPD), a novel framework that distills enriched multimodal\nknowledge from the foundation model, enabling the student Ov-GSR model to\nrecognize unseen situations and be better aware of rare situations.\nSpecifically, the MIPD framework first leverages the LLM-based Judgmental\nRationales Generator (JRG) to construct positive and negative glimpse and gaze\nrationales enriched with contextual semantic information. The proposed\nscene-aware and instance-perception prompts are then introduced to align\nrationales with visual information from the MLLM teacher via the\nNegative-Guided Multimodal Prompting Alignment (NMPA) module, effectively\ncapturing holistic and perceptual multimodal knowledge. Finally, the aligned\nmultimodal knowledge is distilled into the student Ov-GSR model, providing a\nstronger foundation for generalization that enhances situation understanding,\nbridges the gap between seen and unseen scenarios, and mitigates prediction\nbias in rare cases. We evaluate MIPD on the refined Ov-SWiG dataset, achieving\nsuperior performance on seen, rare, and unseen situations, and further\ndemonstrate improved unseen detection on the HICO-DET dataset.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14686v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15831", "title": "Observing Fine-Grained Changes in Jupyter Notebooks During Development Time", "authors": ["Sergey Titov", "Konstantin Grotov", "Cristina Sarasua", "Yaroslav Golubev", "Dhivyabharathi Ramasamy", "Alberto Bacchelli", "Abraham Bernstein", "Timofey Bryksin"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      32 pages, 6 figures", "url": "http://arxiv.org/abs/2507.15831v1", "summary": "In software engineering, numerous studies have focused on the analysis of\nfine-grained logs, leading to significant innovations in areas such as\nrefactoring, security, and code completion. However, no similar studies have\nbeen conducted for computational notebooks in the context of data science.\n  To help bridge this research gap, we make three scientific contributions: we\n(1) introduce a toolset for collecting code changes in Jupyter notebooks during\ndevelopment time; (2) use it to collect more than 100 hours of work related to\na data analysis task and a machine learning task (carried out by 20 developers\nwith different levels of expertise), resulting in a dataset containing 2,655\ncells and 9,207 cell executions; and (3) use this dataset to investigate the\ndynamic nature of the notebook development process and the changes that take\nplace in the notebooks.\n  In our analysis of the collected data, we classified the changes made to the\ncells between executions and found that a significant number of these changes\nwere relatively small fixes and code iteration modifications. This suggests\nthat notebooks are used not only as a development and exploration tool but also\nas a debugging tool. We report a number of other insights and propose potential\nfuture research directions on the novel data.", "comment": "32 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.15831v1", "cate": "cs.SE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15515", "title": "Movable-Antenna Empowered AAV-Enabled Data Collection over Low-Altitude Wireless Networks", "authors": ["Xuhui Zhang", "Wenchao Liu", "Jinke Ren", "Chunjie Wang", "Huijun Xing", "Yanyan Shen", "Shuguang Cui"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      This manuscript has been submitted to IEEE", "url": "http://arxiv.org/abs/2507.15515v1", "summary": "Movable-antennas (MAs) are revolutionizing spatial signal processing by\nproviding flexible beamforming in next-generation wireless systems. This paper\ninvestigates an MA-empowered autonomous aerial vehicle (AAV) system in\nlow-altitude wireless networks (LAWNs) for uplink data collection from ground\nusers. We aim to maximize the sum achievable rate by jointly optimizing the AAV\ntrajectory, receive beamforming, and MA positions. An efficient alternating\noptimization (AO) algorithm that incorporates successive convex approximation,\nweighted minimum mean square error, and particle swarm optimization is\ndeveloped. The analysis of the computational complexity and convergence\nfeatures is provided. Extensive simulations demonstrate superior performance in\nterms of the sum achievable rate and the service reliability comparing to\nseveral benchmark schemes. These results demonstrate the distinctive advantages\nof the proposed scheme: enhanced spectral efficiency via adaptive beam-user\nalignment and improved collection reliability through spatial interference\nmanagement, highlighting the implementation potential of the MA-empowered\nLAWNs.", "comment": "This manuscript has been submitted to IEEE", "pdf_url": "http://arxiv.org/pdf/2507.15515v1", "cate": "eess.SP", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14151", "title": "Self-DANA: A Resource-Efficient Channel-Adaptive Self-Supervised Approach for ECG Foundation Models", "authors": ["Giuliana Monachino", "Nicolò La Porta", "Beatrice Zanchi", "Luigi Fiorillo", "Alvise Dei Rossi", "Georgiy Farina", "Francesca Dalia Faraci"], "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14151v1", "summary": "Foundation Models (FMs) are large-scale machine learning models trained on\nextensive, diverse datasets that can be adapted to a wide range of downstream\ntasks with minimal fine-tuning. In the last two years, interest in FMs has also\ngrown for applications in the cardiological field to analyze the\nelectrocardiogram (ECG) signals. One of the key properties of FMs is their\ntransferability to a wide range of downstream scenarios. With the spread of\nwearable and portable devices, keen interest in learning from reduced-channel\nconfigurations has arisen. However, the adaptation of ECG FMs to downstream\nscenarios with fewer available channels still has to be properly investigated.\nIn this work, we propose Self-DANA, a novel, easy-to-integrate solution that\nmakes self-supervised architectures adaptable to a reduced number of input\nchannels, ensuring resource efficiency and high performance. We also introduce\nRandom Lead Selection, a novel augmentation technique to pre-train models in a\nmore robust and channel-agnostic way. Our experimental results on five\nreduced-channel configurations demonstrate that Self-DANA significantly\nenhances resource efficiency while reaching state-of-the-art performance. It\nrequires up to 69.3% less peak CPU memory, 34.4% less peak GPU memory, about\n17% less average epoch CPU time, and about 24% less average epoch GPU time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14151v1", "cate": "eess.SP", "date": "2025-07-03", "updated": "2025-07-03"}
{"id": "2507.14534", "title": "Conan: A Chunkwise Online Network for Zero-Shot Adaptive Voice Conversion", "authors": ["Yu Zhang", "Baotong Tian", "Zhiyao Duan"], "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14534v1", "summary": "Zero-shot online voice conversion (VC) holds significant promise for\nreal-time communications and entertainment. However, current VC models struggle\nto preserve semantic fidelity under real-time constraints, deliver\nnatural-sounding conversions, and adapt effectively to unseen speaker\ncharacteristics. To address these challenges, we introduce Conan, a chunkwise\nonline zero-shot voice conversion model that preserves the content of the\nsource while matching the voice timbre and styles of reference speech. Conan\ncomprises three core components: 1) a Stream Content Extractor that leverages\nEmformer for low-latency streaming content encoding; 2) an Adaptive Style\nEncoder that extracts fine-grained stylistic features from reference speech for\nenhanced style adaptation; 3) a Causal Shuffle Vocoder that implements a fully\ncausal HiFiGAN using a pixel-shuffle mechanism. Experimental evaluations\ndemonstrate that Conan outperforms baseline models in subjective and objective\nmetrics. Audio samples can be found at https://aaronz345.github.io/ConanDemo.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14534v1", "cate": "eess.AS", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2309.06950", "title": "3D Active Metric-Semantic SLAM", "authors": ["Yuezhan Tao", "Xu Liu", "Igor Spasojevic", "Saurav Agarwal", "Vijay Kumar"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2309.06950v4", "summary": "In this letter, we address the problem of exploration and metric-semantic\nmapping of multi-floor GPS-denied indoor environments using Size Weight and\nPower (SWaP) constrained aerial robots. Most previous work in exploration\nassumes that robot localization is solved. However, neglecting the state\nuncertainty of the agent can ultimately lead to cascading errors both in the\nresulting map and in the state of the agent itself. Furthermore, actions that\nreduce localization errors may be at direct odds with the exploration task. We\npropose a framework that balances the efficiency of exploration with actions\nthat reduce the state uncertainty of the agent. In particular, our algorithmic\napproach for active metric-semantic SLAM is built upon sparse information\nabstracted from raw problem data, to make it suitable for SWaP-constrained\nrobots. Furthermore, we integrate this framework within a fully autonomous\naerial robotic system that achieves autonomous exploration in cluttered, 3D\nenvironments. From extensive real-world experiments, we showed that by\nincluding Semantic Loop Closure (SLC), we can reduce the robot pose estimation\nerrors by over 90% in translation and approximately 75% in yaw, and the\nuncertainties in pose estimates and semantic maps by over 70% and 65%,\nrespectively. Although discussed in the context of indoor multi-floor\nexploration, our system can be used for various other applications, such as\ninfrastructure inspection and precision agriculture where reliable GPS data may\nnot be available.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2309.06950v4", "cate": "cs.RO", "date": "2023-09-13", "updated": "2025-07-21"}
{"id": "2404.16660", "title": "Benchmarking Mobile Device Control Agents across Diverse Configurations", "authors": ["Juyong Lee", "Taywon Min", "Minyong An", "Dongyoon Hahm", "Haeone Lee", "Changyeon Kim", "Kimin Lee"], "categories": ["cs.HC", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted to ICLR 2024 Workshop on Generative Models for Decision Making (Spotlight) and CoLLAs 2025", "url": "http://arxiv.org/abs/2404.16660v3", "summary": "Mobile device control agents can largely enhance user interactions and\nproductivity by automating daily tasks. However, despite growing interest in\ndeveloping practical agents, the absence of a commonly adopted benchmark in\nthis area makes it challenging to quantify scientific progress. In this work,\nwe introduce B-MoCA: a novel benchmark with interactive environments for\nevaluating and developing mobile device control agents. To create a realistic\nbenchmark, we develop B-MoCA based on the Android operating system and define\n131 common daily tasks. Importantly, we incorporate a randomization feature\nthat changes the configurations of mobile devices, including user interface\nlayouts and language settings, to assess generalization performance. We\nbenchmark diverse agents, including agents employing large language models\n(LLMs) or multi-modal LLMs as well as agents trained with imitation learning\nusing human expert demonstrations. While these agents demonstrate proficiency\nin executing straightforward tasks, their poor performance on complex tasks\nhighlights significant opportunities for future research to improve\neffectiveness. Our source code is publicly available at\nhttps://b-moca.github.io.", "comment": "Accepted to ICLR 2024 Workshop on Generative Models for Decision\n  Making (Spotlight) and CoLLAs 2025", "pdf_url": "http://arxiv.org/pdf/2404.16660v3", "cate": "cs.HC", "date": "2024-04-25", "updated": "2025-07-21"}
{"id": "2507.15761", "title": "GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts", "authors": ["Jingyi Zheng", "Zifan Peng", "Yule Liu", "Junfeng Wang", "Yifan Liao", "Wenhan Dong", "Xinlei He"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15761v1", "summary": "Smart contracts are trustworthy, immutable, and automatically executed\nprograms on the blockchain. Their execution requires the Gas mechanism to\nensure efficiency and fairness. However, due to non-optimal coding practices,\nmany contracts contain Gas waste patterns that need to be optimized. Existing\nsolutions mostly rely on manual discovery, which is inefficient, costly to\nmaintain, and difficult to scale. Recent research uses large language models\n(LLMs) to explore new Gas waste patterns. However, it struggles to remain\ncompatible with existing patterns, often produces redundant patterns, and\nrequires manual validation/rewriting. To address this gap, we present GasAgent,\nthe first multi-agent system for smart contract Gas optimization that combines\ncompatibility with existing patterns and automated discovery/validation of new\npatterns, enabling end-to-end optimization. GasAgent consists of four\nspecialized agents, Seeker, Innovator, Executor, and Manager, that collaborate\nin a closed loop to identify, validate, and apply Gas-saving improvements.\nExperiments on 100 verified real-world contracts demonstrate that GasAgent\nsuccessfully optimizes 82 contracts, achieving an average deployment Gas\nsavings of 9.97%. In addition, our evaluation confirms its compatibility with\nexisting tools and validates the effectiveness of each module through ablation\nstudies. To assess broader usability, we further evaluate 500 contracts\ngenerated by five representative LLMs across 10 categories and find that\nGasAgent optimizes 79.8% of them, with deployment Gas savings ranging from\n4.79% to 13.93%, showing its usability as the optimization layer for\nLLM-assisted smart contract development.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15761v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14706", "title": "Fraud is Not Just Rarity: A Causal Prototype Attention Approach to Realistic Synthetic Oversampling", "authors": ["Claudio Giusti", "Luca Guarnera", "Mirko Casu", "Sebastiano Battiato"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      23 pages, 14 figures", "url": "http://arxiv.org/abs/2507.14706v1", "summary": "Detecting fraudulent credit card transactions remains a significant\nchallenge, due to the extreme class imbalance in real-world data and the often\nsubtle patterns that separate fraud from legitimate activity. Existing research\ncommonly attempts to address this by generating synthetic samples for the\nminority class using approaches such as GANs, VAEs, or hybrid generative\nmodels. However, these techniques, particularly when applied only to\nminority-class data, tend to result in overconfident classifiers and poor\nlatent cluster separation, ultimately limiting real-world detection\nperformance. In this study, we propose the Causal Prototype Attention\nClassifier (CPAC), an interpretable architecture that promotes class-aware\nclustering and improved latent space structure through prototype-based\nattention mechanisms and we will couple it with the encoder in a VAE-GAN\nallowing it to offer a better cluster separation moving beyond post-hoc sample\naugmentation. We compared CPAC-augmented models to traditional oversamplers,\nsuch as SMOTE, as well as to state-of-the-art generative models, both with and\nwithout CPAC-based latent classifiers. Our results show that classifier-guided\nlatent shaping with CPAC delivers superior performance, achieving an F1-score\nof 93.14\\% percent and recall of 90.18\\%, along with improved latent cluster\nseparation. Further ablation studies and visualizations provide deeper insight\ninto the benefits and limitations of classifier-driven representation learning\nfor fraud detection. The codebase for this work will be available at final\nsubmission.", "comment": "23 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.14706v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14697", "title": "GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset", "authors": ["Zhiwei Zhang", "Zi Ye", "Yibin Wen", "Shuai Yuan", "Haohuan Fu", "Jianxi Huang", "Juepeng Zheng"], "categories": ["cs.CV", "I.4.6; I.2.10"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      38 pages, 18 figures, submitted to NeurIPS 2025", "url": "http://arxiv.org/abs/2507.14697v1", "summary": "Agricultural parcels serve as basic units for conducting agricultural\npractices and applications, which is vital for land ownership registration,\nfood security assessment, soil erosion monitoring, etc. However, existing\nagriculture parcel extraction studies only focus on mid-resolution mapping or\nregular plain farmlands while lacking representation of complex terraced\nterrains due to the demands of precision agriculture.In this paper, we\nintroduce a more fine-grained terraced parcel dataset named GTPBD (Global\nTerraced Parcel and Boundary Dataset), which is the first fine-grained dataset\ncovering major worldwide terraced regions with more than 200,000 complex\nterraced parcels with manual annotation. GTPBD comprises 47,537 high-resolution\nimages with three-level labels, including pixel-level boundary labels, mask\nlabels, and parcel labels. It covers seven major geographic zones in China and\ntranscontinental climatic regions around the world.Compared to the existing\ndatasets, the GTPBD dataset brings considerable challenges due to the: (1)\nterrain diversity; (2) complex and irregular parcel objects; and (3) multiple\ndomain styles. Our proposed GTPBD dataset is suitable for four different tasks,\nincluding semantic segmentation, edge detection, terraced parcel extraction,\nand unsupervised domain adaptation (UDA) tasks.Accordingly, we benchmark the\nGTPBD dataset on eight semantic segmentation methods, four edge extraction\nmethods, three parcel extraction methods, and five UDA methods, along with a\nmulti-dimensional evaluation framework integrating pixel-level and object-level\nmetrics. GTPBD fills a critical gap in terraced remote sensing research,\nproviding a basic infrastructure for fine-grained agricultural terrain analysis\nand cross-scenario knowledge transfer.", "comment": "38 pages, 18 figures, submitted to NeurIPS 2025", "pdf_url": "http://arxiv.org/pdf/2507.14697v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14347", "title": "Remote Assistance or Remote Driving: The Impact of Operational Design Domains on ADS-Supporting Systems Selection", "authors": ["Ole Hans", "Benedikt Walter"], "categories": ["eess.SY", "cs.SE", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.14347v1", "summary": "High level Automated Driving Systems (ADS) can handle many situations, but\nthey still encounter situations where human intervention is required. In\nsystems where a physical driver is present in the vehicle, typically SAE Level\n3 systems, this intervention is relatively straightforward and is handled by\nthe in-vehicle driver. However, the complexity increases for Level 4 systems,\nwhere, in most cases, no physical driver remains in the vehicle. The two common\nindustry solutions for this challenge are the integration of a remote support\nsystem, such as a Remote Driving System (RDS) or Remote Assistance System\n(RAS). While it is clear that ADS will require one of these systems, it is less\nclear how the suitability of either system for a particular ADS application\nshould be evaluated. Currently, the selection process often focuses on system\narchitecture as well as its design and integration challenges. Furthermore,\nsince many ADS developers choose to develop remote system solutions in-house,\nit is advantageous to select the simpler approach to streamline development and\nintegration efforts. While these decision points are certainly relevant, this\napproach overlooks the most critical factors: the use cases and the\ncomplementarity of the ADS and the remote support system within the context of\nthe Operational Design Design Domain (ODD). This paper proposes a structured\napproach for selecting between RDS and RAS as an ADS support system, based on\nthe defined ODD and use case analysis. To achieve this, the paper applies the\nPEGASUS framework to systematically describe and analyze the ODD. A structured\nframework is introduced to evaluate and select the most suitable remote support\nsystem for an ADS based on clearly defined criteria.", "comment": "This work has been submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.14347v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15621", "title": "Zak-OTFS based Multiuser Uplink in Doubly-Spread Channels", "authors": ["Imran Ali Khan", "Saif Khan Mohammed", "Ronny Hadani", "Ananthanarayanan Chockalingam", "Robert Calderbank"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15621v1", "summary": "Wireless users with different characteristics will be expected to share\nspectrum in next generation communication networks. One of the great strengths\nof wireless networks based on Orthogonal Frequency Division Multiplexing (OFDM)\nis the ease with which different non-overlapping time-frequency (TF) resources\ncan be allocated to different users by simply shifting each user's signal in\ntime and frequency. However, a significant weaknesses of OFDM is the\ninflexibility of sub-carrier spacing. Since OFDM does not allow users to have\ndifferent sub-carrier spacing, a single user subject to inter-carrier\ninterference causes carrier spacing to increase for all users. Zak-OTFS is an\nalternative delay-Doppler (DD) domain modulation scheme, where, in contrast to\nOFDM, the Input-Output (I/O) relation is predictable. We match the strength of\nOFDM by designing a novel DD domain method of shaping the transmitted Zak-OTFS\npulse on the uplink that enables flexible non-overlapping TF resource\nallocation. The base station (BS) receives a superposition of uplink signals\nand applies individual matched filters to obtain the data specific to\nindividual users. We develop theoretical measures of interference between\nusers, and present numerical simulations for a vehicular channel model\nrepresentative of next generation propagation environments. We demonstrate\nsingle-user performance in a multiuser Zak-OTFS uplink system without needing\nto provision guard bands between TF resources allocated to different users.\nThese performance results demonstrate that the benefits of a predictable\nZak-OTFS waveform can be realized within an architecture for uplink\ncommunication.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15621v1", "cate": "eess.SP", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14152", "title": "Machine learning-enabled river water quality monitoring using lithography-free 3D-printed sensors", "authors": ["Frank Efe Erukainure", "Feidra Gjata", "Matin Ataei Kachouei", "Henry Cox", "Md. Azahar Ali"], "categories": ["eess.SP", "cs.LG", "cs.SY", "eess.SY", "physics.ins-det"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      34 pages, 9 figures", "url": "http://arxiv.org/abs/2507.14152v1", "summary": "River water quality monitoring is important for aquatic life, livestock, and\nhumans because clean water is critical to meeting food demand during the global\nfood crisis. Excessive contaminants, including phosphate, deplete dissolved\noxygen and trigger eutrophication, leading to serious health and ecological\nproblems. Continuous sensors that track phosphate levels can therefore help\nprevent eutrophication. In this work we present a lithography-free phosphate\nsensor (P-sensor) that detects phosphate in river water at parts-per-billion\nlevels. The device uses a solid-state indicator electrode formed by 3D-printed\nperiodic polymer patterns (8 um feature size) coated with a thin phosphate\nion-selective membrane. The P-sensor detects as little as 1 ppb phosphate\nacross 0 - 475 ppm with a response time under 30 seconds. We validated the\nsensor on Rappahannock River water, Virginia (less than 0.8 ppm phosphate) at\nsites upstream and downstream of a sewage treatment plant and benchmarked the\nresults against a commercial phosphate meter. A feed-forward neural network was\ntrained to predict phosphate levels, achieving a mean-squared error below 1e-3,\nzero standard deviation, and a Pearson correlation coefficient of 0.997 for\nriver samples. These results demonstrate a practical tool for continuous\nwater-quality monitoring that can inform stakeholders and policymakers and\nultimately improve public health.", "comment": "34 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.14152v1", "cate": "eess.SP", "date": "2025-07-03", "updated": "2025-07-03"}
{"id": "2507.14898", "title": "Parameter-Efficient Fine-Tuning of Foundation Models for CLP Speech Classification", "authors": ["Susmita Bhattacharjee", "Jagabandhu Mishra", "H. S. Shekhawat", "S. R. Mahadeva Prasanna"], "categories": ["eess.AS", "eess.SP"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures, conference", "url": "http://arxiv.org/abs/2507.14898v1", "summary": "We propose the use of parameter-efficient fine-tuning (PEFT) of foundation\nmodels for cleft lip and palate (CLP) detection and severity classification. In\nCLP, nasalization increases with severity due to the abnormal passage between\nthe oral and nasal tracts; this causes oral stops to be replaced by glottal\nstops and alters formant trajectories and vowel space. Since foundation models\nare trained for grapheme prediction or long-term quantized representation\nprediction, they may better discriminate CLP severity when fine-tuned on\ndomain-specific data. We conduct experiments on two datasets: English (NMCPC)\nand Kannada (AIISH). We perform a comparative analysis using embeddings from\nself-supervised models Wav2Vec2 and WavLM, and the weakly supervised Whisper,\neach paired with SVM classifiers, and compare them with traditional handcrafted\nfeatures eGeMAPS and ComParE. Finally, we fine-tune the best-performing Whisper\nmodel using PEFT techniques: Low-Rank Adapter (LoRA) and Decomposed Low-Rank\nAdapter (DoRA). Our results demonstrate that the proposed approach achieves\nrelative improvements of 26.4% and 63.4% in macro-average F1 score over the\nbest foundation model and handcrafted feature baselines on the NMCPC dataset,\nand improvements of 6.1% and 52.9% on the AIISH dataset, respectively.", "comment": "6 pages, 5 figures, conference", "pdf_url": "http://arxiv.org/pdf/2507.14898v1", "cate": "eess.AS", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2401.01483", "title": "To Lead or to Follow? Adaptive Robot Task Planning in Human-Robot Collaboration", "authors": ["Ali Noormohammadi-Asl", "Stephen L. Smith", "Kerstin Dautenhahn"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2401.01483v2", "summary": "Adaptive task planning is fundamental to ensuring effective and seamless\nhuman-robot collaboration. This paper introduces a robot task planning\nframework that takes into account both human leading/following preferences and\nperformance, specifically focusing on task allocation and scheduling in\ncollaborative settings. We present a proactive task allocation approach with\nthree primary objectives: enhancing team performance, incorporating human\npreferences, and upholding a positive human perception of the robot and the\ncollaborative experience. Through a user study, involving an autonomous mobile\nmanipulator robot working alongside participants in a collaborative scenario,\nwe confirm that the task planning framework successfully attains all three\nintended goals, thereby contributing to the advancement of adaptive task\nplanning in human-robot collaboration. This paper mainly focuses on the first\ntwo objectives, and we discuss the third objective, participants' perception of\nthe robot, tasks, and collaboration in a companion paper.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2401.01483v2", "cate": "cs.RO", "date": "2024-01-03", "updated": "2025-07-20"}
{"id": "2501.06348", "title": "Why Automate This? Exploring the Connection between Time Use, Well-being and Robot Automation Across Social Groups", "authors": ["Ruchira Ray", "Leona Pang", "Sanjana Srivastava", "Li Fei-Fei", "Samantha Shorey", "Roberto Martín-Martín"], "categories": ["cs.HC", "cs.RO"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      20 pages, 14 figures", "url": "http://arxiv.org/abs/2501.06348v2", "summary": "Understanding the motivations underlying the human inclination to automate\ntasks is vital to developing truly helpful robots integrated into daily life.\nAccordingly, we ask: are individuals more inclined to automate chores based on\nthe time they consume or the feelings experienced while performing them? This\nstudy explores these preferences and whether they vary across different social\ngroups (i.e., gender category and income level). Leveraging data from the\nBEHAVIOR-1K dataset, the American Time-Use Survey, and the American Time-Use\nSurvey Well-Being Module, we investigate the relationship between the desire\nfor automation, time spent on daily activities, and their associated feelings -\nHappiness, Meaningfulness, Sadness, Painfulness, Stressfulness, or Tiredness.\nOur key findings show that, despite common assumptions, time spent does not\nstrongly relate to the desire for automation for the general population. For\nthe feelings analyzed, only happiness and pain are key indicators. Significant\ndifferences by gender and economic level also emerged: Women prefer to automate\nstressful activities, whereas men prefer to automate those that make them\nunhappy; mid-income individuals prioritize automating less enjoyable and\nmeaningful activities, while low and high-income show no significant\ncorrelations. We hope our research helps motivate technologies to develop\nrobots that match the priorities of potential users, moving domestic robotics\ntoward more socially relevant solutions. We open-source all the data, including\nan online tool that enables the community to replicate our analysis and explore\nadditional trends at https://hri1260.github.io/why-automate-this.", "comment": "20 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2501.06348v2", "cate": "cs.HC", "date": "2025-01-10", "updated": "2025-07-20"}
{"id": "2507.15770", "title": "A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining", "authors": ["Yifan Shen", "Zihan Zhao", "Xiao Xue", "Yuwei Guo", "Qun Ma", "Deyu Zhou", "Ming Zhang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15770v1", "summary": "With the rise of service computing, cloud computing, and IoT, service\necosystems are becoming increasingly complex. The intricate interactions among\nintelligent agents make abnormal emergence analysis challenging, as traditional\ncausal methods focus on individual trajectories. Large language models offer\nnew possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT)\nreasoning to reveal agent intentions. However, existing approaches remain\nlimited to microscopic and static analysis. This paper introduces a framework:\nEmergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic\nand interpretable emergence analysis. EAMI first employs a dual-perspective\nthought track mechanism, where an Inspector Agent and an Analysis Agent extract\nagent intentions under bounded and perfect rationality. Then, k-means\nclustering identifies phase transition points in group intentions, followed by\na Intention Temporal Emergence diagram for dynamic analysis. The experiments\nvalidate EAMI in complex online-to-offline (O2O) service system and the\nStanford AI Town experiment, with ablation studies confirming its\neffectiveness, generalizability, and efficiency. This framework provides a\nnovel paradigm for abnormal emergence and causal analysis in service\necosystems. The code is available at\nhttps://anonymous.4open.science/r/EAMI-B085.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15770v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14715", "title": "Exploring the Dynamic Scheduling Space of Real-Time Generative AI Applications on Emerging Heterogeneous Systems", "authors": ["Rachid Karami", "Rajeev Patwari", "Hyoukjun Kwon", "Ashish Sirasao"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14715v1", "summary": "The integration of generative AI models, particularly large language models\n(LLMs), into real-time multi-model AI applications such as video conferencing\nand gaming is giving rise to a new class of workloads: real-time generative AI\n(RTGen). These workloads combine the compute intensity and dynamic execution\npatterns of generative models with the stringent latency and concurrency\nconstraints of real-time inference. To meet the diverse demands of RTGen\nworkloads, modern edge platforms increasingly adopt heterogeneous\nsystem-on-chip (SoC) architectures that integrate CPUs, GPUs, and NPUs. Despite\nthe potential of heterogeneous SoC, the scheduling space complexity and\nperformance implications of RTGen workloads on such platforms remain\nunderexplored. In this work, we perform a comprehensive characterization of\nRTGen workloads on AMD's latest heterogeneous SoC, Ryzen AI. We construct\nrealistic multi-model scenarios inspired by industry use cases and profile\nmodel performance across all available backends. Using this data, we evaluate\nfive scheduling policies and their impact on both real-time metrics (e.g.,\ndeadline violation rate) and LLM performance (e.g., time-to-first-token and\ntokens-per-second). Our results show that scheduling decisions significantly\naffect workload performance (e.g., leading to a 41.7% difference in deadline\nviolation rates on average), and highlight the need for scheduling strategies\nthat are aware of workload dynamics and hardware heterogeneity. Our findings\nunderscore the importance of workload-aware, dynamic heterogeneous scheduling\nin enabling high-performance, on-device RTGen applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14715v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14738", "title": "MultiRetNet: A Multimodal Vision Model and Deferral System for Staging Diabetic Retinopathy", "authors": ["Jeannie She", "Katie Spivakovsky"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14738v1", "summary": "Diabetic retinopathy (DR) is a leading cause of preventable blindness,\naffecting over 100 million people worldwide. In the United States, individuals\nfrom lower-income communities face a higher risk of progressing to advanced\nstages before diagnosis, largely due to limited access to screening. Comorbid\nconditions further accelerate disease progression. We propose MultiRetNet, a\nnovel pipeline combining retinal imaging, socioeconomic factors, and\ncomorbidity profiles to improve DR staging accuracy, integrated with a clinical\ndeferral system for a clinical human-in-the-loop implementation. We experiment\nwith three multimodal fusion methods and identify fusion through a fully\nconnected layer as the most versatile methodology. We synthesize adversarial,\nlow-quality images and use contrastive learning to train the deferral system,\nguiding the model to identify out-of-distribution samples that warrant\nclinician review. By maintaining diagnostic accuracy on suboptimal images and\nintegrating critical health data, our system can improve early detection,\nparticularly in underserved populations where advanced DR is often first\nidentified. This approach may reduce healthcare costs, increase early detection\nrates, and address disparities in access to care, promoting healthcare equity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14738v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2311.11457", "title": "Foundational Competencies and Responsibilities of a Research Software Engineer: Current State and Suggestions for Future Directions", "authors": ["Florian Goth", "Renato Alves", "Matthias Braun", "Leyla Jael Castro", "Gerasimos Chourdakis", "Simon Christ", "Jeremy Cohen", "Stephan Druskat", "Fredo Erxleben", "Jean-Noël Grad", "Magnus Hagdorn", "Toby Hodges", "Guido Juckeland", "Dominic Kempf", "Anna-Lena Lamprecht", "Jan Linxweiler", "Frank Löffler", "Michele Martone", "Moritz Schwarzmeier", "Heidi Seibold", "Jan Philipp Thiele", "Harald von Waldow", "Samantha Wittke"], "categories": ["cs.SE", "cs.CY", "physics.comp-ph"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      35 pages, public repository for feedback here: this https URL", "url": "http://arxiv.org/abs/2311.11457v4", "summary": "The term Research Software Engineer, or RSE, emerged a little over 10 years\nago as a way to represent individuals working in the research community but\nfocusing on software development. The term has been widely adopted and there\nare a number of high-level definitions of what an RSE is. However, the roles of\nRSEs vary depending on the institutional context they work in. At one end of\nthe spectrum, RSE roles may look similar to a traditional research role. At the\nother extreme, they resemble that of a software engineer in industry. Most RSE\nroles inhabit the space between these two extremes. Therefore, providing a\nstraightforward, comprehensive definition of what an RSE does and what\nexperience, skills and competencies are required to become one is challenging.\nIn this community paper we define the broad notion of what an RSE is, explore\nthe different types of work they undertake, and define a list of fundamental\ncompetencies as well as values that define the general profile of an RSE. On\nthis basis, we elaborate on the progression of these skills along different\ndimensions, looking at specific types of RSE roles, proposing recommendations\nfor organisations, and giving examples of future specialisations. An appendix\ndetails how existing curricula fit into this framework.", "comment": "35 pages, public repository for feedback here:\n  https://github.com/the-teachingRSE-project/competencies", "pdf_url": "http://arxiv.org/pdf/2311.11457v4", "cate": "cs.SE", "date": "2023-11-19", "updated": "2025-07-19"}
{"id": "2507.15661", "title": "On Strong Converse Bounds for the Private and Quantum Capacities of Anti-degradable Channels", "authors": ["Zahra Baghali Khanian", "Christoph Hirche"], "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15661v1", "summary": "We establish a strong converse bound for the private classical capacity of\nanti-degradable quantum channels. Specifically, we prove that this capacity is\nzero whenever the error $\\epsilon > 0$ and privacy parameter $\\delta > 0$\nsatisfy the inequality $\\delta (1-\\epsilon^2)^{\\frac{1}{2}}+\\epsilon\n(1-\\delta^2)^{\\frac{1}{2}}<1$. This result strengthens previous understandings\nby sharply defining the boundary beyond which reliable and private\ncommunication is impossible. Furthermore, we present a ``pretty simple'' proof\nof the ``pretty strong'' converse for the quantum capacity of anti-degradable\nchannels, valid for any error $\\epsilon < \\frac{1}{\\sqrt{2}}$. Our approach\noffers clarity and technical simplicity, shedding new light on the fundamental\nlimits of quantum communication.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15661v1", "cate": "quant-ph", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14153", "title": "Surface EMG Profiling in Parkinson's Disease: Advancing Severity Assessment with GCN-SVM", "authors": ["Daniel Cieślak", "Barbara Szyca", "Weronika Bajko", "Liwia Florkiewicz", "Kinga Grzęda", "Mariusz Kaczmarek", "Helena Kamieniecka", "Hubert Lis", "Weronika Matwiejuk", "Anna Prus", "Michalina Razik", "Inga Rozumowicz", "Wiktoria Ziembakowska"], "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      International Conference on Hybrid Artificial Intelligence Systems (HAIS 2024)", "url": "http://arxiv.org/abs/2507.14153v1", "summary": "Parkinson's disease (PD) poses challenges in diagnosis and monitoring due to\nits progressive nature and complex symptoms. This study introduces a novel\napproach utilizing surface electromyography (sEMG) to objectively assess PD\nseverity, focusing on the biceps brachii muscle. Initial analysis of sEMG data\nfrom five PD patients and five healthy controls revealed significant\nneuromuscular differences. A traditional Support Vector Machine (SVM) model\nachieved up to 83% accuracy, while enhancements with a Graph Convolutional\nNetwork-Support Vector Machine (GCN-SVM) model increased accuracy to 92%.\nDespite the preliminary nature of these results, the study outlines a detailed\nexperimental methodology for future research with larger cohorts to validate\nthese findings and integrate the approach into clinical practice. The proposed\napproach holds promise for advancing PD severity assessment and improving\npatient care in Parkinson's disease management.", "comment": "International Conference on Hybrid Artificial Intelligence Systems\n  (HAIS 2024)", "pdf_url": "http://arxiv.org/pdf/2507.14153v1", "cate": "eess.SP", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.14988", "title": "DMOSpeech 2: Reinforcement Learning for Duration Prediction in Metric-Optimized Speech Synthesis", "authors": ["Yinghao Aaron Li", "Xilin Jiang", "Fei Tao", "Cheng Niu", "Kaifeng Xu", "Juntong Song", "Nima Mesgarani"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14988v1", "summary": "Diffusion-based text-to-speech (TTS) systems have made remarkable progress in\nzero-shot speech synthesis, yet optimizing all components for perceptual\nmetrics remains challenging. Prior work with DMOSpeech demonstrated direct\nmetric optimization for speech generation components, but duration prediction\nremained unoptimized. This paper presents DMOSpeech 2, which extends metric\noptimization to the duration predictor through a reinforcement learning\napproach. The proposed system implements a novel duration policy framework\nusing group relative preference optimization (GRPO) with speaker similarity and\nword error rate as reward signals. By optimizing this previously unoptimized\ncomponent, DMOSpeech 2 creates a more complete metric-optimized synthesis\npipeline. Additionally, this paper introduces teacher-guided sampling, a hybrid\napproach leveraging a teacher model for initial denoising steps before\ntransitioning to the student model, significantly improving output diversity\nwhile maintaining efficiency. Comprehensive evaluations demonstrate superior\nperformance across all metrics compared to previous systems, while reducing\nsampling steps by half without quality degradation. These advances represent a\nsignificant step toward speech synthesis systems with metric optimization\nacross multiple components. The audio samples, code and pre-trained models are\navailable at https://dmospeech2.github.io/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14988v1", "cate": "eess.AS", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2403.09971", "title": "Advancing Object Goal Navigation Through LLM-enhanced Object Affinities Transfer", "authors": ["Mengying Lin", "Shugao Liu", "Dingxi Zhang", "Yaran Chen", "Zhaoran Wang", "Haoran Li", "Dongbin Zhao"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.09971v3", "summary": "Object-goal navigation requires mobile robots to efficiently locate targets\nwith visual and spatial information, yet existing methods struggle with\ngeneralization in unseen environments. Heuristic approaches with naive metrics\nfail in complex layouts, while graph-based and learning-based methods suffer\nfrom environmental biases and limited generalization. Although Large Language\nModels (LLMs) as planners or agents offer a rich knowledge base, they are\ncost-inefficient and lack targeted historical experience. To address these\nchallenges, we propose the LLM-enhanced Object Affinities Transfer (LOAT)\nframework, integrating LLM-derived semantics with learning-based approaches to\nleverage experiential object affinities for better generalization in unseen\nsettings. LOAT employs a dual-module strategy: one module accesses LLMs' vast\nknowledge, and the other applies learned object semantic relationships,\ndynamically fusing these sources based on context. Evaluations in AI2-THOR and\nHabitat simulators show significant improvements in navigation success and\nefficiency, and real-world deployment demonstrates the zero-shot ability of\nLOAT to enhance object-goal navigation systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.09971v3", "cate": "cs.RO", "date": "2024-03-15", "updated": "2025-07-20"}
{"id": "2504.03253", "title": "Ultra-low-power ring-based wireless tinymouse", "authors": ["Yifan Li", "Masaaki Fukumoto", "Mohamed Kari", "Shigemi Ishida", "Akihito Noda", "Tomoyuki Yokota", "Takao Someya", "Yoshihiro Kawahara", "Ryo Takahashi"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2501.16674", "url": "http://arxiv.org/abs/2504.03253v2", "summary": "Wireless mouse rings offer subtle, reliable pointing interactions for\nwearable computing platforms. However, the small battery below 27 mAh in the\nminiature rings restricts the ring's continuous lifespan to just 1-10 hours,\nbecause current low-powered wireless communication such as BLE is\npower-consuming for ring's continuous use. The ring's short lifespan frequently\ndisrupts users' mouse use with the need for frequent charging. This paper\npresents picoRing mouse, enabling a continuous ring-based mouse interaction\nwith ultra-low-powered ring-to-wristband wireless communication. picoRing mouse\nemploys a coil-based impedance sensing named semi-passive inductive telemetry,\nallowing a wristband coil to capture a unique frequency response of a nearby\nring coil via a sensitive inductive coupling between the coils. The ring coil\nconverts the corresponding user's mouse input into the unique frequency\nresponse via an up to 449 uW mouse-driven modulation system. Therefore, the\ncontinuous use of picoRing mouse can last approximately 600 (8hrs use/day)-1000\n(4hrs use/day) hours on a single charge of a 27 mAh battery while supporting\nsubtle thumb-to-index scrolling and pressing interactions in real-world\nwearable computing situations.", "comment": "arXiv admin note: text overlap with arXiv:2501.16674", "pdf_url": "http://arxiv.org/pdf/2504.03253v2", "cate": "cs.HC", "date": "2025-04-04", "updated": "2025-07-21"}
{"id": "2507.15796", "title": "Challenges of Trustworthy Federated Learning: What's Done, Current Trends and Remaining Work", "authors": ["Nuria Rodríguez-Barroso", "Mario García-Márquez", "M. Victoria Luzón", "Francisco Herrera"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15796v1", "summary": "In recent years, the development of Trustworthy Artificial Intelligence (TAI)\nhas emerged as a critical objective in the deployment of AI systems across\nsensitive and high-risk domains. TAI frameworks articulate a comprehensive set\nof ethical, legal, and technical requirements to ensure that AI technologies\nare aligned with human values, rights, and societal expectations. Among the\nvarious AI paradigms, Federated Learning (FL) presents a promising solution to\npressing privacy concerns. However, aligning FL with the rest of the\nrequirements of TAI presents a series of challenges, most of which arise from\nits inherently distributed nature. In this work, we adopt the requirements TAI\nas a guiding structure to systematically analyze the challenges of adapting FL\nto TAI. Specifically, we classify and examine the key obstacles to aligning FL\nwith TAI, providing a detailed exploration of what has been done, the trends,\nand the remaining work within each of the identified challenges.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15796v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14722", "title": "LeanTree: Accelerating White-Box Proof Search with Factorized States in Lean 4", "authors": ["Matěj Kripner", "Michal Šustr", "Milan Straka"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14722v1", "summary": "Automated theorem proving (ATP) has been a classical problem in artificial\nintelligence since its inception, yet it remains challenging due to its vast\nstate and action space. Large language models (LLMs) have recently emerged as a\npromising heuristic for ATP, but they lack correctness guarantees and thus\nrequire interaction with a proof verifier. Such interactions typically follow\none of two approaches: black-box interaction, which does not utilize\nintermediate proof states, or white-box approaches, which allow for incremental\nproof construction and examination of intermediate states. While black-box\napproaches have directly benefited from recent LLM advances, white-box methods\nhave comparatively lagged behind. In this paper, we address this gap by\nintroducing LeanTree, which consists of (i) a tool built in the Lean 4 language\nthat factorizes complex proof states into simpler, independent branches, and\n(ii) a dataset of these factorized intermediate states. Our white-box tooling\noffers several advantages over black-box approaches: it simplifies evaluation,\nreduces necessary context, generates richer training data, enables parallel\nsearch across multiple states, supports efficient reuse of states, and provides\nfeedback in case of errors. Our preliminary results hint that white-box\napproaches outperform black-box alternatives in some settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14722v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14743", "title": "InterAct-Video: Reasoning-Rich Video QA for Urban Traffic", "authors": ["Joseph Raj Vishal", "Rutuja Patil", "Manas Srinivas Gowda", "Katha Naik", "Yezhou Yang", "Bharatesh Chakravarthi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14743v1", "summary": "Traffic monitoring is crucial for urban mobility, road safety, and\nintelligent transportation systems (ITS). Deep learning has advanced\nvideo-based traffic monitoring through video question answering (VideoQA)\nmodels, enabling structured insight extraction from traffic videos. However,\nexisting VideoQA models struggle with the complexity of real-world traffic\nscenes, where multiple concurrent events unfold across spatiotemporal\ndimensions. To address these challenges, this paper introduces \\textbf{InterAct\nVideoQA}, a curated dataset designed to benchmark and enhance VideoQA models\nfor traffic monitoring tasks. The InterAct VideoQA dataset comprises 8 hours of\nreal-world traffic footage collected from diverse intersections, segmented into\n10-second video clips, with over 25,000 question-answer (QA) pairs covering\nspatiotemporal dynamics, vehicle interactions, incident detection, and other\ncritical traffic attributes. State-of-the-art VideoQA models are evaluated on\nInterAct VideoQA, exposing challenges in reasoning over fine-grained\nspatiotemporal dependencies within complex traffic scenarios. Additionally,\nfine-tuning these models on InterAct VideoQA yields notable performance\nimprovements, demonstrating the necessity of domain-specific datasets for\nVideoQA. InterAct VideoQA is publicly available as a benchmark dataset to\nfacilitate future research in real-world deployable VideoQA models for\nintelligent transportation systems. GitHub Repo:\nhttps://github.com/joe-rabbit/InterAct_VideoQA", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14743v1", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2410.02482", "title": "It is Giving Major Satisfaction: Why Fairness Matters for Software Practitioners", "authors": ["Emeralda Sesari", "Federica Sarro", "Ayushi Rastogi"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      This work has been submitted to the ACM for possible publication", "url": "http://arxiv.org/abs/2410.02482v4", "summary": "Software practitioners often encounter workplace unfairness, such as unequal\nrecognition and gender bias. While the link between fairness and job\nsatisfaction has been established in other fields, its relevance to software\nprofessionals remains underexplored. This study examines how fairness\nperceptions relate to job satisfaction among software practitioners, focusing\non both general trends and demographic-specific differences. We conducted an\nonline survey of 108 software practitioners, followed by ordinal logistic\nregression to analyze the relationship between fairness perceptions and job\nsatisfaction in software engineering contexts, with moderation analysis\nexamining how this relationship varies across demographic groups. Our findings\nindicate that all four fairness dimensions (namely distributive, procedural,\ninterpersonal, and informational fairness) significantly affect overall job\nsatisfaction and satisfaction with job security. Among these, interpersonal\nfairness has the biggest impact. The relationship between fairness and job\nsatisfaction is stronger for female, ethnically underrepresented, less\nexperienced practitioners, and those with work limitations. Fairness in\nauthorship emerged as an important factor for job satisfaction collectively,\nwhile fairness in policy implementation, high-demand situations, and working\nhours impacted specific demographic groups. This study highlights the role of\nfairness among software practitioners, offering strategies for organizations to\npromote fair practices and targeted approaches for certain demographic groups.", "comment": "This work has been submitted to the ACM for possible publication", "pdf_url": "http://arxiv.org/pdf/2410.02482v4", "cate": "cs.SE", "date": "2024-10-03", "updated": "2025-07-18"}
{"id": "2507.15800", "title": "Fluid Antenna-enabled Near-Field Integrated Sensing, Computing and Semantic Communication for Emerging Applications", "authors": ["Yinchao Yang", "Jingxuan Zhou", "Zhaohui Yang", "Mohammad Shikh-Bahaei"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE Transactions on Cognitive Communications and Networking", "url": "http://arxiv.org/abs/2507.15800v1", "summary": "The integration of sensing and communication (ISAC) is a key enabler for\nnext-generation technologies. With high-frequency bands and large-scale antenna\narrays, the Rayleigh distance extends, necessitating near-field (NF) models\nwhere waves are spherical. Although NF-ISAC improves both sensing and\ncommunication, it also poses challenges such as high data volume and potential\nprivacy risks. To address these, we propose a novel framework: near-field\nintegrated sensing, computing, and semantic communication (NF-ISCSC), which\nleverages semantic communication to transmit contextual information only,\nthereby reducing data overhead and improving efficiency. However, semantic\ncommunication is sensitive to channel variations, requiring adaptive\nmechanisms. To this end, fluid antennas (FAs) are introduced to support the\nNF-ISCSC system, enabling dynamic adaptability to changing channels. The\nproposed FA-enabled NF-ISCSC framework considers multiple communication users\nand extended targets comprising several scatterers. A joint optimization\nproblem is formulated to maximize data rate while accounting for sensing\nquality, computational load, and power budget. Using an alternating\noptimization (AO) approach, the original problem is divided into three\nsub-problems: ISAC beamforming, FA positioning, and semantic extraction ratio.\nBeamforming is optimized using the successive convex approximation method. FA\npositioning is solved via a projected Broyden-Fletcher-Goldfarb-Shanno (BFGS)\nalgorithm, and the semantic extraction ratio is optimized using bisection\nsearch. Simulation results demonstrate that the proposed framework achieves\nhigher data rates and better privacy preservation.", "comment": "Accepted by IEEE Transactions on Cognitive Communications and\n  Networking", "pdf_url": "http://arxiv.org/pdf/2507.15800v1", "cate": "eess.SP", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14163", "title": "UniPhyNet: A Unified Network For Multimodal Physiological Raw Signal Classification", "authors": ["Renxiang Qiu", "Raghavendra Selvan"], "categories": ["eess.SP", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted to be presented at the 35th IEEE International Workshop on Machine Learning for Signal Processing (IEEE MLSP 2025). Source code available at this https URL", "url": "http://arxiv.org/abs/2507.14163v1", "summary": "We present UniPhyNet, a novel neural network architecture to classify\ncognitive load using multimodal physiological data -- specifically EEG, ECG and\nEDA signals -- without the explicit need for extracting hand-crafted features.\nUniPhyNet integrates multiscale parallel convolutional blocks and ResNet-type\nblocks enhanced with channel block attention module to focus on the informative\nfeatures while a bidirectional gated recurrent unit is used to capture temporal\ndependencies. This architecture processes and combines signals in both unimodal\nand multimodal configurations via intermediate fusion of learned feature maps.\nOn the CL-Drive dataset, UniPhyNet improves raw signal classification accuracy\nfrom 70% to 80% (binary) and 62% to 74% (ternary), outperforming feature-based\nmodels, demonstrating its effectiveness as an end-to-end solution for\nreal-world cognitive state monitoring.", "comment": "Accepted to be presented at the 35th IEEE International Workshop on\n  Machine Learning for Signal Processing (IEEE MLSP 2025). Source code\n  available at https://github.com/HughYau/UniPhyNet", "pdf_url": "http://arxiv.org/pdf/2507.14163v1", "cate": "eess.SP", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.15229", "title": "Mixture to Beamformed Mixture: Leveraging Beamformed Mixture as Weak-Supervision for Speech Enhancement and Noise-Robust ASR", "authors": ["Zhong-Qiu Wang", "Ruizhe Pang"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      in submission", "url": "http://arxiv.org/abs/2507.15229v1", "summary": "In multi-channel speech enhancement and robust automatic speech recognition\n(ASR), beamforming can typically improve the signal-to-noise ratio (SNR) of the\ntarget speaker and produce reliable enhancement with little distortion to\ntarget speech. With this observation, we propose to leverage beamformed\nmixture, which has a higher SNR of the target speaker than the input mixture,\nas a weak supervision to train deep neural networks (DNNs) to enhance the input\nmixture. This way, we can train enhancement models using pairs of real-recorded\nmixture and its beamformed mixture, and potentially realize better\ngeneralization to real mixtures, compared with only training the models on\nsimulated mixtures, which usually mismatch real mixtures. Evaluation results on\nthe real-recorded CHiME-4 dataset show the effectiveness of the proposed\nalgorithm.", "comment": "in submission", "pdf_url": "http://arxiv.org/pdf/2507.15229v1", "cate": "eess.AS", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2403.15333", "title": "Gesture-Controlled Aerial Robot Formation for Human-Swarm Interaction in Safety Monitoring Applications", "authors": ["Vít Krátký", "Giuseppe Silano", "Matouš Vrba", "Christos Papaioannidis", "Ioannis Mademlis", "Robert Pěnička", "Ioannis Pitas", "Martin Saska"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works", "url": "http://arxiv.org/abs/2403.15333v4", "summary": "This paper presents a formation control approach for contactless\ngesture-based Human-Swarm Interaction (HSI) between a team of multi-rotor\nUnmanned Aerial Vehicles (UAVs) and a human worker. The approach is designed to\nmonitor the safety of human workers, particularly those operating at heights.\nIn the proposed dynamic formation scheme, one UAV acts as the formation leader,\nequipped with sensors for detecting human workers and recognizing gestures. The\nfollower UAVs maintain a predetermined formation relative to the worker's\nposition, providing additional perspectives of the monitored scene. Hand\ngestures enable the human worker to specify movement and action commands for\nthe UAV team and to initiate other mission-related tasks without requiring\nadditional communication channels or specific markers. Combined with a novel\nunified human detection and tracking algorithm, a human position estimation\nmethod, and a gesture detection pipeline, the proposed approach represents the\nfirst instance of an HSI system incorporating all these modules onboard\nreal-world UAVs. Simulations and field experiments involving three UAVs and a\nhuman worker in a mock-up scenario demonstrate the effectiveness and\nresponsiveness of the proposed approach.", "comment": "2025 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "pdf_url": "http://arxiv.org/pdf/2403.15333v4", "cate": "cs.RO", "date": "2024-03-22", "updated": "2025-07-21"}
{"id": "2505.21385", "title": "EEGVid: Dynamic Vision from EEG Brain Recordings, How much does EEG know?", "authors": ["Prajwal Singh", "Anupam Sharma", "Pankaj Pandey", "Krishna Miyapuram", "Shanmuganathan Raman"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.21385v2", "summary": "Reconstructing and understanding dynamic visual information (video) from\nbrain EEG recordings is challenging due to the non-stationary nature of EEG\nsignals, their low signal-to-noise ratio (SNR), and the limited availability of\nEEG-Video stimulus datasets. Most recent studies have focused on reconstructing\nstatic images from EEG recordings. In this work, we propose a framework to\nreconstruct dynamic visual stimuli from EEG data and conduct an in-depth study\nof the information encoded in EEG signals. Our approach first trains a feature\nextraction network using a triplet-based contrastive learning strategy within\nan EEG-video generation framework. The extracted EEG features are then used for\nvideo synthesis with a modified StyleGAN-ADA, which incorporates temporal\ninformation as conditioning. Additionally, we analyze how different brain\nregions contribute to processing dynamic visual stimuli. Through several\nempirical studies, we evaluate the effectiveness of our framework and\ninvestigate how much dynamic visual information can be inferred from EEG\nsignals. The inferences we derive through our extensive studies would be of\nimmense value to future research on extracting visual dynamics from EEG.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.21385v2", "cate": "cs.HC", "date": "2025-05-27", "updated": "2025-07-19"}
{"id": "2507.15842", "title": "Identifying Conditional Causal Effects in MPDAGs", "authors": ["Sara LaPlante", "Emilija Perković"], "categories": ["cs.AI", "stat.ME", "stat.ML"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      67 pages, 8 figures", "url": "http://arxiv.org/abs/2507.15842v1", "summary": "We consider identifying a conditional causal effect when a graph is known up\nto a maximally oriented partially directed acyclic graph (MPDAG). An MPDAG\nrepresents an equivalence class of graphs that is restricted by background\nknowledge and where all variables in the causal model are observed. We provide\nthree results that address identification in this setting: an identification\nformula when the conditioning set is unaffected by treatment, a generalization\nof the well-known do calculus to the MPDAG setting, and an algorithm that is\ncomplete for identifying these conditional effects.", "comment": "67 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.15842v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14725", "title": "Task-Agnostic Continual Prompt Tuning with Gradient-Based Selection and Decoding", "authors": ["Anushka Tiwari", "Sayantan Pal", "Rohini K. Srihari", "Kaiyi Ji"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14725v1", "summary": "Prompt-based continual learning (CL) offers a parameter-efficient way to\nadapt large language models (LLMs) across task sequences. However, most\nexisting methods assume task-aware inference and maintain a growing list of\ntask-specific prompts, which limits scalability and hides latent forgetting. In\nthis work, we introduce GRID, a unified framework that addresses two key\nlimitations: (1) latent forgetting under task-agnostic inference, and (2)\nprompt memory explosion as task sequences grow. GRID integrates a task-aware\ndecoding mechanism that improves backward transfer by leveraging representative\ninputs, automatic task identification, and constrained decoding. Additionally,\nwe propose a gradient-based prompt selection strategy that compresses less\ninformative prompts into a single aggregated representation, enabling scalable\nand memory-efficient lifelong learning. Extensive experiments across\nshort-sequence, long-sequence, and negative transfer benchmarks show that GRID\nsignificantly improves backward transfer, achieves competitive forward\ntransfer, and reduces forgotten tasks by up to 80\\%, outperforming\nstate-of-the-art methods on T5 and Flan-T5 backbones.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14725v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14784", "title": "LeAdQA: LLM-Driven Context-Aware Temporal Grounding for Video Question Answering", "authors": ["Xinxin Dong", "Baoyun Peng", "Haokai Ma", "Yufei Wang", "Zixuan Dong", "Fei Hu", "Xiaodong Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14784v1", "summary": "Video Question Answering (VideoQA) requires identifying sparse critical\nmoments in long videos and reasoning about their causal relationships to answer\nsemantically complex questions. While recent advances in multimodal learning\nhave improved alignment and fusion, current approaches remain limited by two\nprevalent but fundamentally flawed strategies: (1) task-agnostic sampling\nindiscriminately processes all frames, overwhelming key events with irrelevant\ncontent; and (2) heuristic retrieval captures superficial patterns but misses\ncausal-temporal structures needed for complex reasoning. To address these\nchallenges, we introduce LeAdQA, an innovative approach that bridges these gaps\nthrough synergizing causal-aware query refinement with fine-grained visual\ngrounding. Our method first leverages LLMs to reformulate question-option\npairs, resolving causal ambiguities and sharpening temporal focus. These\nrefined queries subsequently direct a temporal grounding model to precisely\nretrieve the most salient segments, complemented by an adaptive fusion\nmechanism dynamically integrating the evidence to maximize relevance. The\nintegrated visual-textual cues are then processed by an MLLM to generate\naccurate, contextually-grounded answers. Experiments on NExT-QA, IntentQA, and\nNExT-GQA demonstrate that our method's precise visual grounding substantially\nenhances the understanding of video-question relationships, achieving\nstate-of-the-art (SOTA) performance on complex reasoning tasks while\nmaintaining computational efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14784v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2410.17689", "title": "Flexible Process Variant Binding in Information Systems with Software Product Line Engineering", "authors": ["Philipp Hehnle", "Manfred Reichert"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.17689v2", "summary": "Different organisations often run similar digitised business processes to\nachieve their business goals. However, organisations often need to slightly\nadapt the business processes implemented in an information system in order to\nadopt them. Various approaches have been proposed to manage variants in process\nmodels. While these approaches mainly deal with control flow variability, in\nprevious work we introduced an approach to manage implementation variants of\ndigitised business processes. In this context Software Product Line (SPL)\nEngineering was applied to manage a set of common core artefacts including a\nprocess model from which Process-Aware Information Systems (PAIS) can be\nderived, which differ in the implementation of their process activities. When\nderiving a PAIS, implementations are selected for each process activity and\nthen included in the PAIS at compilation time. One challenge that has not yet\nbeen solved is giving users of digitised business processes the option of\nselecting multiple implementations at runtime. This paper extends our previous\nwork by not only allowing for the selection of activity implementations at\ncompile time, but also at start time and runtime. Consequently, it becomes\npossible to defer the decision as to which implementation should be selected to\nstart time and runtime. Furthermore, multiple implementations of a particular\nactivity may be selected and executed concurrently. The presented approach also\nallows customising the input and output data of activities. Data from expert\ninterviews with German municipalities suggests digitising business processes\nwith varying implementations is a widespread challenge and our approach is a\nway to mitigate it.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.17689v2", "cate": "cs.SE", "date": "2024-10-23", "updated": "2025-07-20"}
{"id": "2507.15805", "title": "Identifying Solution Constraints for ODE Systems", "authors": ["Nicolae Tarfulea"], "categories": ["math.OC", "cs.IT", "cs.NA", "math.IT", "math.NA", "34-04, 65-04"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      13 pages, MATLAB code included", "url": "http://arxiv.org/abs/2507.15805v1", "summary": "This work develops a framework to discover relations between the components\nof the solution to a given initial-value problem for a first-order system of\nordinary differential equations. This is done by using sparse identification\ntechniques on the data represented by the numerical solution of the\ninitial-value problem at hand. The only assumption is that there are only a few\nterms that connects the components, so that the mathematical relations to be\ndiscovered are sparse in the set of possible functions. We illustrate the\nmethod through examples of applications.", "comment": "13 pages, MATLAB code included", "pdf_url": "http://arxiv.org/pdf/2507.15805v1", "cate": "math.OC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14164", "title": "A Denoising VAE for Intracardiac Time Series in Ischemic Cardiomyopathy", "authors": ["Samuel Ruipérez-Campillo", "Alain Ryser", "Thomas M. Sutter", "Ruibin Feng", "Prasanth Ganesan", "Brototo Deb", "Kelly A. Brennan", "Maxime Pedron", "Albert J. Rogers", "Maarten Z. H. Kolk", "Fleur V. Y. Tjong", "Sanjiv M. Narayan", "Julia E. Vogt"], "categories": ["eess.SP", "cs.AI", "cs.LG", "I.2; J.3"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      9 pages, 2 figures, 3 tables, the last two authors are shared senior authors", "url": "http://arxiv.org/abs/2507.14164v1", "summary": "In the field of cardiac electrophysiology (EP), effectively reducing noise in\nintra-cardiac signals is crucial for the accurate diagnosis and treatment of\narrhythmias and cardiomyopathies. However, traditional noise reduction\ntechniques fall short in addressing the diverse noise patterns from various\nsources, often non-linear and non-stationary, present in these signals. This\nwork introduces a Variational Autoencoder (VAE) model, aimed at improving the\nquality of intra-ventricular monophasic action potential (MAP) signal\nrecordings. By constructing representations of clean signals from a dataset of\n5706 time series from 42 patients diagnosed with ischemic cardiomyopathy, our\napproach demonstrates superior denoising performance when compared to\nconventional filtering methods commonly employed in clinical settings. We\nassess the effectiveness of our VAE model using various metrics, indicating its\nsuperior capability to denoise signals across different noise types, including\ntime-varying non-linear noise frequently found in clinical settings. These\nresults reveal that VAEs can eliminate diverse sources of noise in single\nbeats, outperforming state-of-the-art denoising techniques and potentially\nimproving treatment efficacy in cardiac EP.", "comment": "9 pages, 2 figures, 3 tables, the last two authors are shared senior\n  authors", "pdf_url": "http://arxiv.org/pdf/2507.14164v1", "cate": "eess.SP", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.15517", "title": "Binaural Signal Matching with Wearable Arrays for Near-Field Sources", "authors": ["Sapir Goldring", "Zamir Ben Hur", "David Lou Alon", "Boaz Rafaely"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Published at Forum Acusticum 2025", "url": "http://arxiv.org/abs/2507.15517v1", "summary": "Binaural reproduction methods aim to recreate an acoustic scene for a\nlistener over headphones, offering immersive experiences in applications such\nas Virtual Reality (VR) and teleconferencing. Among the existing approaches,\nthe Binaural Signal Matching (BSM) algorithm has demonstrated high quality\nreproduction due to its signal-independent formulation and the flexibility of\nunconstrained array geometry. However, this method assumes far-field sources\nand has not yet been investigated for near-field scenarios. This study\nevaluates the performance of BSM for near-field sources. Analysis of a\nsemi-circular array around a rigid sphere, modeling head-mounted devices, show\nthat far-field BSM performs adequately for sources up to approximately tens of\ncentimeters from the array. However, for sources closer than this range, the\nbinaural error increases significantly. Incorporating a near-field BSM design,\nwhich accounts for the source distance, significantly reduces the error,\nparticularly for these very-close distances, highlighting the benefits of\nnear-field modeling in improving reproduction accuracy.", "comment": "Published at Forum Acusticum 2025", "pdf_url": "http://arxiv.org/pdf/2507.15517v1", "cate": "eess.AS", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2407.00614", "title": "Learning Granularity-Aware Affordances from Human-Object Interaction for Tool-Based Functional Dexterous Grasping", "authors": ["Fan Yang", "Wenrui Chen", "Kailun Yang", "Haoran Lin", "Dongsheng Luo", "Conghui Tang", "Zhiyong Li", "Yaonan Wang"], "categories": ["cs.RO", "cs.CV", "eess.IV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS). The source code and the established dataset are available at this https URL", "url": "http://arxiv.org/abs/2407.00614v2", "summary": "To enable robots to use tools, the initial step is teaching robots to employ\ndexterous gestures for touching specific areas precisely where tasks are\nperformed. Affordance features of objects serve as a bridge in the functional\ninteraction between agents and objects. However, leveraging these affordance\ncues to help robots achieve functional tool grasping remains unresolved. To\naddress this, we propose a granularity-aware affordance feature extraction\nmethod for locating functional affordance areas and predicting dexterous coarse\ngestures. We study the intrinsic mechanisms of human tool use. On one hand, we\nuse fine-grained affordance features of object-functional finger contact areas\nto locate functional affordance regions. On the other hand, we use highly\nactivated coarse-grained affordance features in hand-object interaction regions\nto predict grasp gestures. Additionally, we introduce a model-based\npost-processing module that transforms affordance localization and gesture\nprediction into executable robotic actions. This forms GAAF-Dex, a complete\nframework that learns Granularity-Aware Affordances from human-object\ninteraction to enable tool-based functional grasping with dexterous hands.\nUnlike fully-supervised methods that require extensive data annotation, we\nemploy a weakly supervised approach to extract relevant cues from exocentric\n(Exo) images of hand-object interactions to supervise feature extraction in\negocentric (Ego) images. To support this approach, we have constructed a\nsmall-scale dataset, Functional Affordance Hand-object Interaction Dataset\n(FAH), which includes nearly 6K images of functional hand-object interaction\nExo images and Ego images. Extensive experiments on the dataset demonstrate\nthat our method outperforms state-of-the-art methods. The source code and the\nestablished dataset are available at https://github.com/yangfan293/GAAF-DEX.", "comment": "Accepted to IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS). The source code and the established dataset are available at\n  https://github.com/yangfan293/GAAF-DEX", "pdf_url": "http://arxiv.org/pdf/2407.00614v2", "cate": "cs.RO", "date": "2024-06-30", "updated": "2025-07-19"}
{"id": "2502.02883", "title": "SensorChat: Answering Qualitative and Quantitative Questions during Long-Term Multimodal Sensor Interactions", "authors": ["Xiaofan Yu", "Lanxiang Hu", "Benjamin Reichman", "Dylan Chu", "Rushil Chandrupatla", "Xiyuan Zhang", "Larry Heck", "Tajana Rosing"], "categories": ["cs.AI", "cs.HC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      To appear in IMWUT'25. Code is available at: this https URL", "url": "http://arxiv.org/abs/2502.02883v3", "summary": "Natural language interaction with sensing systems is crucial for addressing\nusers' personal concerns and providing health-related insights into their daily\nlives. When a user asks a question, the system automatically analyzes the full\nhistory of sensor data, extracts relevant information, and generates an\nappropriate response. However, existing systems are limited to short-duration\n(e.g., one minute) or low-frequency (e.g., daily step count) sensor data. In\naddition, they struggle with quantitative questions that require precise\nnumerical answers. In this work, we introduce SensorChat, the first end-to-end\nQA system designed for daily life monitoring using long-duration,\nhigh-frequency time series data. Given raw sensor signals spanning multiple\ndays and a user-defined natural language question, SensorChat generates\nsemantically meaningful responses that directly address user concerns.\nSensorChat effectively handles both quantitative questions that require\nnumerical precision and qualitative questions that require high-level reasoning\nto infer subjective insights. To achieve this, SensorChat uses an innovative\nthree-stage pipeline including question decomposition, sensor data query, and\nanswer assembly. The first and third stages leverage Large Language Models\n(LLMs) to interpret human queries and generate responses. The intermediate\nquerying stage extracts relevant information from the complete sensor data\nhistory. Real-world implementations demonstrate SensorChat's capability for\nreal-time interactions on a cloud server while also being able to run entirely\non edge platforms after quantization. Comprehensive QA evaluations show that\nSensorChat achieves 93% higher answer accuracy than the best performing\nstate-of-the-art systems on quantitative questions. Furthermore, a user study\nwith eight volunteers highlights SensorChat's effectiveness in answering\nqualitative questions.", "comment": "To appear in IMWUT'25. Code is available at:\n  https://github.com/Orienfish/SensorChat", "pdf_url": "http://arxiv.org/pdf/2502.02883v3", "cate": "cs.AI", "date": "2025-02-05", "updated": "2025-07-18"}
{"id": "2507.15844", "title": "Hierarchical Budget Policy Optimization for Adaptive Reasoning", "authors": ["Shangke Lyu", "Linjuan Wu", "Yuchen Yan", "Xingyu Wu", "Hao Li", "Yongliang Shen", "Peisheng Jiang", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Code: this https URL Project Page: this https URL", "url": "http://arxiv.org/abs/2507.15844v1", "summary": "Large reasoning models achieve remarkable performance through extensive\nchain-of-thought generation, yet exhibit significant computational inefficiency\nby applying uniform reasoning strategies regardless of problem complexity. We\npresent Hierarchical Budget Policy Optimization (HBPO), a reinforcement\nlearning framework that enables models to learn problem-specific reasoning\ndepths without sacrificing capability. HBPO addresses the fundamental challenge\nof exploration space collapse in efficiency-oriented training, where penalties\non long output length systematically bias models away from necessary long\nreasoning paths. Through hierarchical budget exploration, our approach\npartitions rollout samples into multiple subgroups with distinct token budgets,\naiming to enable efficient resource allocation while preventing degradation of\ncapability. We introduce differentiated reward mechanisms that create\nbudget-aware incentives aligned with the complexity of the problem, allowing\nmodels to discover natural correspondences between task requirements and\ncomputational effort. Extensive experiments demonstrate that HBPO reduces\naverage token usage by up to 60.6% while improving accuracy by 3.14% across\nfour reasoning benchmarks. Unlike existing methods that impose external\nconstraints or rely on discrete mode selection, HBPO exhibits emergent adaptive\nbehavior where models automatically adjust reasoning depth based on problem\ncomplexity. Our results suggest that reasoning efficiency and capability are\nnot inherently conflicting, and can be simultaneously optimized through\nappropriately structured hierarchical training that preserves exploration\ndiversity.", "comment": "Code: https://github.com/zju-real/hbpo Project\n  Page:https://zju-real.github.io/hbpo/", "pdf_url": "http://arxiv.org/pdf/2507.15844v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14736", "title": "Balancing Expressivity and Robustness: Constrained Rational Activations for Reinforcement Learning", "authors": ["Rafał Surdej", "Michał Bortkiewicz", "Alex Lewandowski", "Mateusz Ostaszewski", "Clare Lyle"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted for oral presentation at CoLLAs 2025", "url": "http://arxiv.org/abs/2507.14736v1", "summary": "Trainable activation functions, whose parameters are optimized alongside\nnetwork weights, offer increased expressivity compared to fixed activation\nfunctions. Specifically, trainable activation functions defined as ratios of\npolynomials (rational functions) have been proposed to enhance plasticity in\nreinforcement learning. However, their impact on training stability remains\nunclear. In this work, we study trainable rational activations in both\nreinforcement and continual learning settings. We find that while their\nflexibility enhances adaptability, it can also introduce instability, leading\nto overestimation in RL and feature collapse in longer continual learning\nscenarios. Our main result is demonstrating a trade-off between expressivity\nand plasticity in rational activations. To address this, we propose a\nconstrained variant that structurally limits excessive output scaling while\npreserving adaptability. Experiments across MetaWorld and DeepMind Control\nSuite (DMC) environments show that our approach improves training stability and\nperformance. In continual learning benchmarks, including MNIST with reshuffled\nlabels and Split CIFAR-100, we reveal how different constraints affect the\nbalance between expressivity and long-term retention. While preliminary\nexperiments in discrete action domains (e.g., Atari) did not show similar\ninstability, this suggests that the trade-off is particularly relevant for\ncontinuous control. Together, our findings provide actionable design principles\nfor robust and adaptable trainable activations in dynamic, non-stationary\nenvironments. Code available at:\nhttps://github.com/special114/rl_rational_plasticity.", "comment": "Accepted for oral presentation at CoLLAs 2025", "pdf_url": "http://arxiv.org/pdf/2507.14736v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14787", "title": "FOCUS: Fused Observation of Channels for Unveiling Spectra", "authors": ["Xi Xiao", "Aristeidis Tsaris", "Anika Tabassum", "John Lagergren", "Larry M. York", "Tianyang Wang", "Xiao Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14787v1", "summary": "Hyperspectral imaging (HSI) captures hundreds of narrow, contiguous\nwavelength bands, making it a powerful tool in biology, agriculture, and\nenvironmental monitoring. However, interpreting Vision Transformers (ViTs) in\nthis setting remains largely unexplored due to two key challenges: (1) existing\nsaliency methods struggle to capture meaningful spectral cues, often collapsing\nattention onto the class token, and (2) full-spectrum ViTs are computationally\nprohibitive for interpretability, given the high-dimensional nature of HSI\ndata. We present FOCUS, the first framework that enables reliable and efficient\nspatial-spectral interpretability for frozen ViTs. FOCUS introduces two core\ncomponents: class-specific spectral prompts that guide attention toward\nsemantically meaningful wavelength groups, and a learnable [SINK] token trained\nwith an attraction loss to absorb noisy or redundant attention. Together, these\ndesigns make it possible to generate stable and interpretable 3D saliency maps\nand spectral importance curves in a single forward pass, without any gradient\nbackpropagation or backbone modification. FOCUS improves band-level IoU by 15\npercent, reduces attention collapse by over 40 percent, and produces saliency\nresults that align closely with expert annotations. With less than 1 percent\nparameter overhead, our method makes high-resolution ViT interpretability\npractical for real-world hyperspectral applications, bridging a long-standing\ngap between black-box modeling and trustworthy HSI decision-making.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14787v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2411.19463", "title": "Understanding the Design Decisions of Retrieval-Augmented Generation Systems", "authors": ["Shengming Zhao", "Yuchen Shao", "Yuheng Huang", "Jiayang Song", "Zhijie Wang", "Chengcheng Wan", "Lei Ma"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.19463v2", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a critical technique for\nenhancing large language model (LLM) capabilities. However, practitioners face\nsignificant challenges when making RAG deployment decisions. While existing\nresearch prioritizes algorithmic innovations, a systematic gap persists in\nunderstanding fundamental engineering trade-offs that determine RAG success. We\npresent the first comprehensive study of three universal RAG deployment\ndecisions: whether to deploy RAG, how much information to retrieve, and how to\nintegrate retrieved knowledge effectively. Through systematic experiments\nacross three LLMs and six datasets spanning question answering and code\ngeneration tasks, we reveal critical insights: (1) RAG deployment must be\nhighly selective, with variable recall thresholds and failure modes affecting\nup to 12.6\\% of samples even with perfect documents. (2) Optimal retrieval\nvolume exhibits task-dependent behavior QA tasks show universal patterns (5-10\ndocuments optimal) while code generation requires scenario-specific\noptimization. (3) Knowledge integration effectiveness depends on task and model\ncharacteristics, with code generation benefiting significantly from prompting\nmethods while question answering shows minimal improvement. These findings\ndemonstrate that universal RAG strategies prove inadequate. Effective RAG\nsystems require context-aware design decisions based on task characteristics\nand model capabilities. Our analysis provides evidence-based guidance for\npractitioners and establishes foundational insights for principled RAG\ndeployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.19463v2", "cate": "cs.SE", "date": "2024-11-29", "updated": "2025-07-21"}
{"id": "2402.06919", "title": "TREET: TRansfer Entropy Estimation via Transformers", "authors": ["Omer Luxembourg", "Dor Tsur", "Haim Permuter"], "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      (C) 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works", "url": "http://arxiv.org/abs/2402.06919v4", "summary": "Transfer entropy (TE) is an information theoretic measure that reveals the\ndirectional flow of information between processes, providing valuable insights\nfor a wide range of real-world applications. This work proposes Transfer\nEntropy Estimation via Transformers (TREET), a novel attention-based approach\nfor estimating TE for stationary processes. The proposed approach employs\nDonsker-Varadhan representation to TE and leverages the attention mechanism for\nthe task of neural estimation. We propose a detailed theoretical and empirical\nstudy of the TREET, comparing it to existing methods on a dedicated estimation\nbenchmark. To increase its applicability, we design an estimated TE\noptimization scheme that is motivated by the functional representation lemma,\nand use it to estimate the capacity of communication channels with memory,\nwhich is a canonical optimization problem in information theory. We further\ndemonstrate how an optimized TREET can be used to estimate underlying\ndensities, providing experimental results. Finally, we apply TREET to feature\nanalysis of patients with Apnea, demonstrating its applicability to real-world\nphysiological data. Our work, applied with state-of-the-art deep learning\nmethods, opens a new door for communication problems which are yet to be\nsolved.", "comment": "(C) 2025 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "pdf_url": "http://arxiv.org/pdf/2402.06919v4", "cate": "cs.IT", "date": "2024-02-10", "updated": "2025-07-18"}
{"id": "2507.14165", "title": "A Multi-Modal IoT Node for Energy-Efficient Environmental Monitoring with Edge AI Processing", "authors": ["Philip Wiese", "Victor Kartsch", "Marco Guermandi", "Luca Benini"], "categories": ["eess.SP", "cs.SY", "eess.IV", "eess.SY"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      7 pages, 4 figures, 2 tables. This paper has been accepted at 2025 IEEE International Conference on Omni-layer Intelligent Systems (COINS)", "url": "http://arxiv.org/abs/2507.14165v1", "summary": "The widespread adoption of Internet of Things (IoT) technologies has\nsignificantly advanced environmental monitoring (EM) by enabling cost-effective\nand scalable sensing solutions. Concurrently, machine learning (ML) and\nartificial intelligence (AI) are introducing powerful tools for the efficient\nand accurate analysis of complex environmental data. However, current IoT\nplatforms for environmental sensing are typically limited to a narrow set of\nsensors, preventing a comprehensive assessment of environmental conditions and\nlacking sufficient computational capabilities to support the deployment of\nadvanced ML and AI algorithms on the edge. To overcome these limitations, we\nintroduce a compact (17x38 mm2), multi-modal, MCU-based environmental IoT node\nintegrating 11 sensors, including CO2 concentration, volatile organic compounds\n(VOCs), light intensity, UV radiation, pressure, temperature, humidity, visual\nsensing via an RGB camera, and precise geolocation through a GNSS module. It\nfeatures GAP9, a parallel ultra-low-power system-on-chip, enabling real-time,\nenergy-efficient edge processing of advanced ML models directly on-device. We\nimplemented a YOLOv5-based occupancy detection pipeline (0.3 M parameters, 42\nMOP per inference), demonstrating 42% energy savings over raw data streaming.\nAdditionally, we present a smart indoor air quality (IAQ) monitoring setup that\ncombines occupancy detection with adaptive sample rates, achieving operational\ntimes of up to 143 h on a single compact 600 mAh, 3.7 V battery. Our platform\nlays the groundwork for innovative applications such as predictive indoor IAQ,\nenabling efficient AI-driven on-edge forecasting for energy-efficient and\nautonomous, proactive pollution-mitigation control strategies", "comment": "7 pages, 4 figures, 2 tables. This paper has been accepted at 2025\n  IEEE International Conference on Omni-layer Intelligent Systems (COINS)", "pdf_url": "http://arxiv.org/pdf/2507.14165v1", "cate": "eess.SP", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.14237", "title": "U-DREAM: Unsupervised Dereverberation guided by a Reverberation Model", "authors": ["Louis Bahrman", "Mathieu Fontaine", "Gaël Richard"], "categories": ["cs.SD", "cs.AI", "eess.AS", "eess.SP"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Submitted to IEEE Transactions on Audio, Speech and Language Processing (TASLPRO)", "url": "http://arxiv.org/abs/2507.14237v1", "summary": "This paper explores the outcome of training state-ofthe-art dereverberation\nmodels with supervision settings ranging from weakly-supervised to fully\nunsupervised, relying solely on reverberant signals and an acoustic model for\ntraining. Most of the existing deep learning approaches typically require\npaired dry and reverberant data, which are difficult to obtain in practice. We\ndevelop instead a sequential learning strategy motivated by a bayesian\nformulation of the dereverberation problem, wherein acoustic parameters and dry\nsignals are estimated from reverberant inputs using deep neural networks,\nguided by a reverberation matching loss. Our most data-efficient variant\nrequires only 100 reverberation-parameter-labelled samples to outperform an\nunsupervised baseline, demonstrating the effectiveness and practicality of the\nproposed method in low-resource scenarios.", "comment": "Submitted to IEEE Transactions on Audio, Speech and Language\n  Processing (TASLPRO)", "pdf_url": "http://arxiv.org/pdf/2507.14237v1", "cate": "cs.SD", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14261", "title": "FAMST: Fast Approximate Minimum Spanning Tree Construction for Large-Scale and High-Dimensional Data", "authors": ["Mahmood K. M. Almansoori", "Miklos Telek"], "categories": ["cs.DS", "cs.AI"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14261v1", "summary": "We present Fast Approximate Minimum Spanning Tree (FAMST), a novel algorithm\nthat addresses the computational challenges of constructing Minimum Spanning\nTrees (MSTs) for large-scale and high-dimensional datasets. FAMST utilizes a\nthree-phase approach: Approximate Nearest Neighbor (ANN) graph construction,\nANN inter-component connection, and iterative edge refinement. For a dataset of\n$n$ points in a $d$-dimensional space, FAMST achieves $\\mathcal{O}(dn \\log n)$\ntime complexity and $\\mathcal{O}(dn + kn)$ space complexity when $k$ nearest\nneighbors are considered, which is a significant improvement over the\n$\\mathcal{O}(n^2)$ time and space complexity of traditional methods.\n  Experiments across diverse datasets demonstrate that FAMST achieves\nremarkably low approximation errors while providing speedups of up to\n1000$\\times$ compared to exact MST algorithms. We analyze how the key\nhyperparameters, $k$ (neighborhood size) and $\\lambda$ (inter-component edges),\naffect performance, providing practical guidelines for hyperparameter\nselection. FAMST enables MST-based analysis on datasets with millions of points\nand thousands of dimensions, extending the applicability of MST techniques to\nproblem scales previously considered infeasible.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14261v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2408.01655", "title": "Stimulating Imagination: Towards General-purpose \"Something Something Placement\"", "authors": ["Jianyang Wu", "Jie Gu", "Xiaokang Ma", "Fangzhou Qiu", "Chu Tang", "Jingmin Chen"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      7 pages, accepted to the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025)", "url": "http://arxiv.org/abs/2408.01655v2", "summary": "General-purpose object placement is a fundamental capability of an\nintelligent generalist robot: being capable of rearranging objects following\nprecise human instructions even in novel environments. This work is dedicated\nto achieving general-purpose object placement with ``something something''\ninstructions. Specifically, we break the entire process down into three parts,\nincluding object localization, goal imagination and robot control, and propose\na method named SPORT. SPORT leverages a pre-trained large vision model for\nbroad semantic reasoning about objects, and learns a diffusion-based pose\nestimator to ensure physically-realistic results in 3D space. Only object types\n(movable or reference) are communicated between these two parts, which brings\ntwo benefits. One is that we can fully leverage the powerful ability of\nopen-set object recognition and localization since no specific fine-tuning is\nneeded for the robotic scenario. Moreover, the diffusion-based estimator only\nneed to ``imagine\" the object poses after the placement, while no necessity for\ntheir semantic information. Thus the training burden is greatly reduced and no\nmassive training is required. The training data for the goal pose estimation is\ncollected in simulation and annotated by using GPT-4. Experimental results\ndemonstrate the effectiveness of our approach. SPORT can not only generate\npromising 3D goal poses for unseen simulated objects, but also be seamlessly\napplied to real-world settings.", "comment": "7 pages, accepted to the 2025 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS 2025)", "pdf_url": "http://arxiv.org/pdf/2408.01655v2", "cate": "cs.RO", "date": "2024-08-03", "updated": "2025-07-21"}
{"id": "2503.05609", "title": "Decoding Safety Feedback from Diverse Raters: A Data-driven Lens on Responsiveness to Severity", "authors": ["Pushkar Mishra", "Charvi Rastogi", "Stephen R. Pfohl", "Alicia Parrish", "Tian Huey Teh", "Roma Patel", "Mark Diaz", "Ding Wang", "Michela Paganini", "Vinodkumar Prabhakaran", "Lora Aroyo", "Verena Rieser"], "categories": ["cs.CY", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.05609v4", "summary": "Ensuring the safety of Generative AI requires a nuanced understanding of\npluralistic viewpoints. In this paper, we introduce a novel data-driven\napproach for interpreting granular ratings in pluralistic datasets.\nSpecifically, we address the challenge of analyzing nuanced differences in\nsafety feedback from a diverse population expressed via ordinal scales (e.g., a\nLikert scale). We distill non-parametric responsiveness metrics that quantify\nthe consistency of raters in scoring varying levels of the severity of safety\nviolations. Leveraging a publicly available pluralistic dataset of safety\nfeedback on AI-generated content as our case study, we investigate how raters\nfrom different demographic groups (age, gender, ethnicity) use an ordinal scale\nto express their perceptions of the severity of violations. We apply our\nmetrics across violation types, demonstrating their utility in extracting\nnuanced insights that are crucial for aligning AI systems reliably in\nmulti-cultural contexts. We show that our approach can inform rater selection\nand feedback interpretation by capturing nuanced viewpoints across different\ndemographic groups, hence improving the quality of pluralistic data collection\nand in turn contributing to more robust AI development.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.05609v4", "cate": "cs.CY", "date": "2025-03-07", "updated": "2025-07-20"}
{"id": "2507.15851", "title": "The Other Mind: How Language Models Exhibit Human Temporal Cognition", "authors": ["Lingyu Li", "Yang Yao", "Yixu Wang", "Chubo Li", "Yan Teng", "Yingchun Wang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      12 pages, 9 figures, 4 tables", "url": "http://arxiv.org/abs/2507.15851v1", "summary": "As Large Language Models (LLMs) continue to advance, they exhibit certain\ncognitive patterns similar to those of humans that are not directly specified\nin training data. This study investigates this phenomenon by focusing on\ntemporal cognition in LLMs. Leveraging the similarity judgment task, we find\nthat larger models spontaneously establish a subjective temporal reference\npoint and adhere to the Weber-Fechner law, whereby the perceived distance\nlogarithmically compresses as years recede from this reference point. To\nuncover the mechanisms behind this behavior, we conducted multiple analyses\nacross neuronal, representational, and informational levels. We first identify\na set of temporal-preferential neurons and find that this group exhibits\nminimal activation at the subjective reference point and implements a\nlogarithmic coding scheme convergently found in biological systems. Probing\nrepresentations of years reveals a hierarchical construction process, where\nyears evolve from basic numerical values in shallow layers to abstract temporal\norientation in deep layers. Finally, using pre-trained embedding models, we\nfound that the training corpus itself possesses an inherent, non-linear\ntemporal structure, which provides the raw material for the model's internal\nconstruction. In discussion, we propose an experientialist perspective for\nunderstanding these findings, where the LLMs' cognition is viewed as a\nsubjective construction of the external world by its internal representational\nsystem. This nuanced perspective implies the potential emergence of alien\ncognitive frameworks that humans cannot intuitively predict, pointing toward a\ndirection for AI alignment that focuses on guiding internal constructions. Our\ncode is available at https://TheOtherMind.github.io.", "comment": "12 pages, 9 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.15851v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14740", "title": "Better Training Data Attribution via Better Inverse Hessian-Vector Products", "authors": ["Andrew Wang", "Elisa Nguyen", "Runshi Yang", "Juhan Bae", "Sheila A. McIlraith", "Roger Grosse"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      28 pages, 4 figures", "url": "http://arxiv.org/abs/2507.14740v1", "summary": "Training data attribution (TDA) provides insights into which training data is\nresponsible for a learned model behavior. Gradient-based TDA methods such as\ninfluence functions and unrolled differentiation both involve a computation\nthat resembles an inverse Hessian-vector product (iHVP), which is difficult to\napproximate efficiently. We introduce an algorithm (ASTRA) which uses the\nEKFAC-preconditioner on Neumann series iterations to arrive at an accurate iHVP\napproximation for TDA. ASTRA is easy to tune, requires fewer iterations than\nNeumann series iterations, and is more accurate than EKFAC-based\napproximations. Using ASTRA, we show that improving the accuracy of the iHVP\napproximation can significantly improve TDA performance.", "comment": "28 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.14740v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14790", "title": "A Novel Downsampling Strategy Based on Information Complementarity for Medical Image Segmentation", "authors": ["Wenbo Yue", "Chang Li", "Guoping Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages, 6 figures", "url": "http://arxiv.org/abs/2507.14790v1", "summary": "In convolutional neural networks (CNNs), downsampling operations are crucial\nto model performance. Although traditional downsampling methods (such as\nmaximum pooling and cross-row convolution) perform well in feature aggregation,\nreceptive field expansion, and computational reduction, they may lead to the\nloss of key spatial information in semantic segmentation tasks, thereby\naffecting the pixel-by-pixel prediction accuracy.To this end, this study\nproposes a downsampling method based on information complementarity - Hybrid\nPooling Downsampling (HPD). The core is to replace the traditional method with\nMinMaxPooling, and effectively retain the light and dark contrast and detail\nfeatures of the image by extracting the maximum value information of the local\narea.Experiment on various CNN architectures on the ACDC and Synapse datasets\nshow that HPD outperforms traditional methods in segmentation performance, and\nincreases the DSC coefficient by 0.5% on average. The results show that the HPD\nmodule provides an efficient solution for semantic segmentation tasks.", "comment": "6 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.14790v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2501.04510", "title": "CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection", "authors": ["Ruijun Feng", "Hammond Pearce", "Pietro Liguori", "Yulei Sui"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE Transactions on Software Engineering", "url": "http://arxiv.org/abs/2501.04510v2", "summary": "Large language models (LLMs) have been proposed as powerful tools for\ndetecting software vulnerabilities, where task-specific fine-tuning is\ntypically employed to provide vulnerability-specific knowledge to the LLMs.\nHowever, existing fine-tuning techniques often treat source code as plain text,\nlosing the graph-based structural information inherent in code.\n  Graph-enhanced soft prompt tuning addresses this by translating the\nstructural information into contextual cues that the LLM can understand.\nHowever, current methods are primarily designed for general graph-related tasks\nand focus more on adjacency information, they fall short in preserving the rich\nsemantic information (e.g., control/data flow) within code graphs. They also\nfail to ensure computational efficiency while capturing graph-text interactions\nin their cross-modal alignment module.\n  This paper presents CGP-Tuning, a new code graph-enhanced, structure-aware\nsoft prompt tuning method for vulnerability detection. CGP-Tuning introduces\ntype-aware embeddings to capture the rich semantic information within code\ngraphs, along with an efficient cross-modal alignment module that achieves\nlinear computational costs while incorporating graph-text interactions. It is\nevaluated on the latest DiverseVul dataset and three advanced open-source code\nLLMs, CodeLlama, CodeGemma, and Qwen2.5-Coder. Experimental results show that\nCGP-Tuning delivers model-agnostic improvements and maintains practical\ninference speed, surpassing the best graph-enhanced soft prompt tuning baseline\nby an average of four percentage points and outperforming non-tuned zero-shot\nprompting by 15 percentage points.", "comment": "Accepted by IEEE Transactions on Software Engineering", "pdf_url": "http://arxiv.org/pdf/2501.04510v2", "cate": "cs.SE", "date": "2025-01-08", "updated": "2025-07-21"}
{"id": "2403.11693", "title": "Beamforming Design for Semantic-Bit Coexisting Communication System", "authors": ["Maojun Zhang", "Guangxu Zhu", "Richeng Jin", "Xiaoming Chen", "Qingjiang Shi", "Caijun Zhong", "Kaibin Huang"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Submitted to IEEE for possible publication", "url": "http://arxiv.org/abs/2403.11693v4", "summary": "Semantic communication (SemCom) is emerging as a key technology for future\nsixth-generation (6G) systems. Unlike traditional bit-level communication\n(BitCom), SemCom directly optimizes performance at the semantic level, leading\nto superior communication efficiency. Nevertheless, the task-oriented nature of\nSemCom renders it challenging to completely replace BitCom. Consequently, it is\ndesired to consider a semantic-bit coexisting communication system, where a\nbase station (BS) serves SemCom users (sem-users) and BitCom users (bit-users)\nsimultaneously. Such a system faces severe and heterogeneous inter-user\ninterference. In this context, this paper provides a new semantic-bit\ncoexisting communication framework and proposes a spatial beamforming scheme to\naccommodate both types of users. Specifically, we consider maximizing the\nsemantic rate for semantic users while ensuring the quality-of-service (QoS)\nrequirements for bit-users. Due to the intractability of obtaining the exact\nclosed-form expression of the semantic rate, a data driven method is first\napplied to attain an approximated expression via data fitting. With the\nresulting complex transcendental function, majorization minimization (MM) is\nadopted to convert the original formulated problem into a multiple-ratio\nproblem, which allows fractional programming (FP) to be used to further\ntransform the problem into an inhomogeneous quadratically constrained quadratic\nprograms (QCQP) problem. Solving the problem leads to a semi-closed form\nsolution with undetermined Lagrangian factors that can be updated by a fixed\npoint algorithm. Extensive simulation results demonstrate that the proposed\nbeamforming scheme significantly outperforms conventional beamforming\nalgorithms such as zero-forcing (ZF), maximum ratio transmission (MRT), and\nweighted minimum mean-square error (WMMSE).", "comment": "Submitted to IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2403.11693v4", "cate": "cs.IT", "date": "2024-03-18", "updated": "2025-07-21"}
{"id": "2507.14166", "title": "Automated Vigilance State Classification in Rodents Using Machine Learning and Feature Engineering", "authors": ["Sankalp Jajee", "Gaurav Kumar", "Homayoun Valafar"], "categories": ["eess.SP", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      8 pages, 5 figures", "url": "http://arxiv.org/abs/2507.14166v1", "summary": "Preclinical sleep research remains constrained by labor intensive, manual\nvigilance state classification and inter rater variability, limiting throughput\nand reproducibility. This study presents an automated framework developed by\nTeam Neural Prognosticators to classify electroencephalogram (EEG) recordings\nof small rodents into three critical vigilance states paradoxical sleep (REM),\nslow wave sleep (SWS), and wakefulness. The system integrates advanced signal\nprocessing with machine learning, leveraging engineered features from both time\nand frequency domains, including spectral power across canonical EEG bands\n(delta to gamma), temporal dynamics via Maximum-Minimum Distance, and\ncross-frequency coupling metrics. These features capture distinct\nneurophysiological signatures such as high frequency desynchronization during\nwakefulness, delta oscillations in SWS, and REM specific bursts. Validated\nduring the 2024 Big Data Health Science Case Competition (University of South\nCarolina Big Data Health Science Center, 2024), our XGBoost model achieved\n91.5% overall accuracy, 86.8% precision, 81.2% recall, and an F1 score of\n83.5%, outperforming all baseline methods. Our approach represents a critical\nadvancement in automated sleep state classification and a valuable tool for\naccelerating discoveries in sleep science and the development of targeted\ninterventions for chronic sleep disorders. As a publicly available code (BDHSC)\nresource is set to contribute significantly to advancements.", "comment": "8 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.14166v1", "cate": "eess.SP", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.14638", "title": "The Rest is Silence: Leveraging Unseen Species Models for Computational Musicology", "authors": ["Fabian C. Moss", "Jan Hajič jr.", "Adrian Nachtwey", "Laurent Pugin"], "categories": ["cs.SD", "eess.AS", "stat.AP"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14638v1", "summary": "For many decades, musicologists have engaged in creating large databases\nserving different purposes for musicological research and scholarship. With the\nrise of fields like music information retrieval and digital musicology, there\nis now a constant and growing influx of musicologically relevant datasets and\ncorpora. In historical or observational settings, however, these datasets are\nnecessarily incomplete, and the true extent of a collection of interest remains\nunknown -- silent. Here, we apply, for the first time, so-called Unseen Species\nmodels (USMs) from ecology to areas of musicological activity. After\nintroducing the models formally, we show in four case studies how USMs can be\napplied to musicological data to address quantitative questions like: How many\ncomposers are we missing in RISM? What percentage of medieval sources of\nGregorian chant have we already cataloged? How many differences in music prints\ndo we expect to find between editions? How large is the coverage of songs from\ngenres of a folk music tradition? And, finally, how close are we in estimating\nthe size of the harmonic vocabulary of a large number of composers?", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14638v1", "cate": "cs.SD", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14462", "title": "Tighter Lower Bounds for Single Source Personalized PageRank", "authors": ["Xinpeng Jiang", "Haoyu Liu", "Siqiang Luo", "Xiaokui Xiao"], "categories": ["cs.DS", "cs.CC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      33 pages", "url": "http://arxiv.org/abs/2507.14462v1", "summary": "We study lower bounds for approximating the Single Source Personalized\nPageRank (SSPPR) query, which measures the probability distribution of an\n$\\alpha$-decay random walk starting from a source node $s$. Existing lower\nbounds remain loose-$\\Omega\\left(\\min(m, 1/\\delta)\\right)$ for relative error\n(SSPPR-R) and $\\Omega\\left(\\min(n, 1/\\epsilon)\\right)$ for additive error\n(SSPPR-A). To close this gap, we establish tighter bounds for both settings.\nFor SSPPR-R, we show a lower bound of $\\Omega\\left(\\min\\left(m,\n\\frac{\\log(1/\\delta)}{\\delta}\\right)\\right)$ for any $\\delta \\in (0,1)$. For\nSSPPR-A, we prove a lower bound of $\\Omega\\left(\\min\\left(m,\n\\frac{\\log(1/\\epsilon)}{\\epsilon}\\right)\\right)$ for any $\\epsilon \\in (0,1)$,\nassuming the graph has $m \\in \\mathcal{O}(n^{2-\\beta})$ edges for any\narbitrarily small constant $\\beta \\in (0,1)$.", "comment": "33 pages", "pdf_url": "http://arxiv.org/pdf/2507.14462v1", "cate": "cs.DS", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2408.16370", "title": "LSTP-Nav: Lightweight Spatiotemporal Policy for Map-free Multi-agent Navigation with LiDAR", "authors": ["Xingrong Diao", "Zhirui Sun", "Jianwei Peng", "Jiankun Wang"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.16370v5", "summary": "Safe and efficient multi-agent navigation in dynamic environments remains\ninherently challenging, particularly when real-time decision-making is required\non resource-constrained platforms. Ensuring collision-free trajectories while\nadapting to uncertainties without relying on pre-built maps further complicates\nreal-world deployment. To address these challenges, we propose LSTP-Nav, a\nlightweight end-to-end policy for multi-agent navigation that enables map-free\ncollision avoidance in complex environments by directly mapping raw LiDAR point\nclouds to motion commands. At the core of this framework lies LSTP-Net, an\nefficient network that processes raw LiDAR data using a GRU architecture,\nenhanced with attention mechanisms to dynamically focus on critical\nenvironmental features while minimizing computational overhead. Additionally, a\nnovel HS reward optimizes collision avoidance by incorporating angular\nvelocity, prioritizing obstacles along the predicted heading, and enhancing\ntraining stability. To narrow the sim-to-real gap, we develop\nPhysReplay-Simlab, a physics-realistic multi-agent simulator, employs localized\nreplay to mine near-failure experiences. Relying solely on LiDA, LSTP-Nav\nachieves efficient zero-shot sim-to-real transfer on a CPU-only robotic\nplatform, enabling robust navigation in dynamic environments while maintaining\ncomputation frequencies above 40 Hz. Extensive experiments demonstrate that\nLSTP-Nav outperforms baselines with a 9.58% higher success rate and a 12.30%\nlower collision rate, underscoring its practicality and robustness for\nreal-world applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.16370v5", "cate": "cs.RO", "date": "2024-08-29", "updated": "2025-07-18"}
{"id": "2506.11092", "title": "Dynamic Context Tuning for Retrieval-Augmented Generation: Enhancing Multi-Turn Planning and Tool Adaptation", "authors": ["Jubin Abhishek Soni", "Amit Anand", "Rajesh Kumar Pandey", "Aniket Abhishek Soni"], "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      We are withdrawing the submission in order to thoroughly revise the work", "url": "http://arxiv.org/abs/2506.11092v2", "summary": "Retrieval-Augmented Generation (RAG) has significantly advanced large\nlanguage models (LLMs) by grounding their outputs in external tools and\nknowledge sources. However, existing RAG systems are typically constrained to\nstatic, single-turn interactions with fixed toolsets, making them ill-suited\nfor dynamic domains such as healthcare and smart homes, where user intent,\navailable tools, and contextual factors evolve over time. We present Dynamic\nContext Tuning (DCT), a lightweight framework that extends RAG to support\nmulti-turn dialogue and evolving tool environments without requiring\nretraining. DCT integrates an attention-based context cache to track relevant\npast information, LoRA-based retrieval to dynamically select domain-specific\ntools, and efficient context compression to maintain inputs within LLM context\nlimits. Experiments on both synthetic and real-world benchmarks show that DCT\nimproves plan accuracy by 14% and reduces hallucinations by 37%, while matching\nGPT-4 performance at significantly lower cost. Furthermore, DCT generalizes to\npreviously unseen tools, enabling scalable and adaptable AI assistants across a\nwide range of dynamic environments.", "comment": "We are withdrawing the submission in order to thoroughly revise the\n  work", "pdf_url": "http://arxiv.org/pdf/2506.11092v2", "cate": "cs.CL", "date": "2025-06-05", "updated": "2025-07-19"}
{"id": "2507.15855", "title": "Gemini 2.5 Pro Capable of Winning Gold at IMO 2025", "authors": ["Yichen Huang", "Lin F. Yang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15855v1", "summary": "The International Mathematical Olympiad (IMO) poses uniquely challenging\nproblems requiring deep insight, creativity, and formal reasoning. While Large\nLanguage Models (LLMs) perform well on mathematical benchmarks like AIME, they\nstruggle with Olympiad-level tasks. We use Google's Gemini 2.5 Pro on the newly\nreleased IMO 2025 problems, avoiding data contamination. With pipeline design\nand prompt engineering, 5 (out of 6) problems are solved correctly (up to a\ncaveat discussed below), highlighting the importance of finding the optimal way\nof using powerful models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15855v1", "cate": "cs.AI", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14744", "title": "Beyond the Single-Best Model: Rashomon Partial Dependence Profile for Trustworthy Explanations in AutoML", "authors": ["Mustafa Cavus", "Jan N. van Rijn", "Przemysław Biecek"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at 28th International Conference on Discovery Science 2025", "url": "http://arxiv.org/abs/2507.14744v1", "summary": "Automated machine learning systems efficiently streamline model selection but\noften focus on a single best-performing model, overlooking explanation\nuncertainty, an essential concern in human centered explainable AI. To address\nthis, we propose a novel framework that incorporates model multiplicity into\nexplanation generation by aggregating partial dependence profiles (PDP) from a\nset of near optimal models, known as the Rashomon set. The resulting Rashomon\nPDP captures interpretive variability and highlights areas of disagreement,\nproviding users with a richer, uncertainty aware view of feature effects. To\nevaluate its usefulness, we introduce two quantitative metrics, the coverage\nrate and the mean width of confidence intervals, to evaluate the consistency\nbetween the standard PDP and the proposed Rashomon PDP. Experiments on 35\nregression datasets from the OpenML CTR23 benchmark suite show that in most\ncases, the Rashomon PDP covers less than 70% of the best model's PDP,\nunderscoring the limitations of single model explanations. Our findings suggest\nthat Rashomon PDP improves the reliability and trustworthiness of model\ninterpretations by adding additional information that would otherwise be\nneglected. This is particularly useful in high stakes domains where\ntransparency and confidence are critical.", "comment": "Accepted at 28th International Conference on Discovery Science 2025", "pdf_url": "http://arxiv.org/pdf/2507.14744v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14797", "title": "Distilling Parallel Gradients for Fast ODE Solvers of Diffusion Models", "authors": ["Beier Zhu", "Ruoyu Wang", "Tong Zhao", "Hanwang Zhang", "Chi Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      To appear in ICCV 2025", "url": "http://arxiv.org/abs/2507.14797v1", "summary": "Diffusion models (DMs) have achieved state-of-the-art generative performance\nbut suffer from high sampling latency due to their sequential denoising nature.\nExisting solver-based acceleration methods often face image quality degradation\nunder a low-latency budget. In this paper, we propose the Ensemble Parallel\nDirection solver (dubbed as \\ours), a novel ODE solver that mitigates\ntruncation errors by incorporating multiple parallel gradient evaluations in\neach ODE step. Importantly, since the additional gradient computations are\nindependent, they can be fully parallelized, preserving low-latency sampling.\n  Our method optimizes a small set of learnable parameters in a distillation\nfashion, ensuring minimal training overhead.\n  In addition, our method can serve as a plugin to improve existing ODE\nsamplers. Extensive experiments on various image synthesis benchmarks\ndemonstrate the effectiveness of our \\ours~in achieving high-quality and\nlow-latency sampling. For example, at the same latency level of 5 NFE, EPD\nachieves an FID of 4.47 on CIFAR-10, 7.97 on FFHQ, 8.17 on ImageNet, and 8.26\non LSUN Bedroom, surpassing existing learning-based solvers by a significant\nmargin. Codes are available in https://github.com/BeierZhu/EPD.", "comment": "To appear in ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.14797v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2503.12899", "title": "A Semantic-based Optimization Approach for Repairing LLMs: Case Study on Code Generation", "authors": ["Jian Gu", "Aldeida Aleti", "Chunyang Chen", "Hongyu Zhang"], "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      13 pages, 7 figure, 8 tables, under peer-review", "url": "http://arxiv.org/abs/2503.12899v3", "summary": "Language Models (LMs) are widely used in software engineering for code\ngeneration, but they may produce code with errors. Rather than repairing the\ngenerated code, an alternative way is to address the underlying failures of\nmodels. LM repair offers a lightweight solution to this challenge: it requires\nminimal data, reduces computational costs, and reduces the side effects. Unlike\nretraining, LM repair focuses on applying tailored updates to targeted neurons,\nmaking it ideal for scenarios with limited resources, high-performance demands,\nor strict safety requirements. In this paper, we propose Semantic Targeting for\nAnalytical Repair (STAR), a pioneering and novel semantic-based optimization\napproach for repairing LLMs. STAR realizes the main operations of repairing LMs\nin an optimization process, including locating ``buggy neurons'', solving\n``neuron patches'', and patching ``buggy neurons''. Correspondingly, it\ncomputes the deltas of weight matrix as the prior information to guide\noptimization; and attributes the targeted layers and neurons leveraging\nstatistical insights. The neuron patches are computed with a solid\nsemantic-based analytical formula, which directly bridges the changes to logits\nwith the deltas of neurons, by steering latent representations. Compared to the\nprior work of LM repair (MINT) and optimization methods (SGD), STAR integrates\ntheir strengths while mitigating their limitations. STAR supports solving\nmultiple failures together, significantly improving the usefulness. Evaluated\non coding tasks using popular code LMs, STAR exhibits superior effectiveness\n(10.5%-19.9% improvements) and efficiency (2.4-7.0 times speedup). In terms of\nside effects, namely the balance between generalization and specificity, STAR\noutperforms prior work by a significant margin. Additionally, we conducted\nassessments on the overfitting risk of LM repair as well as the cumulative\nimpact.", "comment": "13 pages, 7 figure, 8 tables, under peer-review", "pdf_url": "http://arxiv.org/pdf/2503.12899v3", "cate": "cs.SE", "date": "2025-03-17", "updated": "2025-07-20"}
{"id": "2407.06691", "title": "CP-OFDM Achieves the Lowest Average Ranging Sidelobe Under QAM/PSK Constellations", "authors": ["Fan Liu", "Ying Zhang", "Yifeng Xiong", "Shuangyang Li", "Weijie Yuan", "Feifei Gao", "Shi Jin", "Giuseppe Caire"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      17 pages, 11 figures, accepted by the IEEE Transactions on Information Theory", "url": "http://arxiv.org/abs/2407.06691v3", "summary": "This paper aims to answer a fundamental question in the area of Integrated\nSensing and Communications (ISAC): What is the optimal communication-centric\nISAC waveform for ranging? Towards that end, we first established a generic\nframework to analyze the sensing performance of communication-centric ISAC\nwaveforms built upon orthonormal signaling bases and random data symbols. Then,\nwe evaluated their ranging performance by adopting both the periodic and\naperiodic auto-correlation functions (P-ACF and A-ACF), and defined the\nexpectation of the integrated sidelobe level (EISL) as a sensing performance\nmetric. On top of that, we proved that among all communication waveforms with\ncyclic prefix (CP), the orthogonal frequency division multiplexing (OFDM)\nmodulation is the only globally optimal waveform that achieves the lowest\nranging sidelobe for quadrature amplitude modulation (QAM) and phase shift\nkeying (PSK) constellations, in terms of both the EISL and the sidelobe level\nat each individual lag of the P-ACF. As a step forward, we proved that among\nall communication waveforms without CP, OFDM is a locally optimal waveform for\nQAM/PSK in the sense that it achieves a local minimum of the EISL of the A-ACF.\nFinally, we demonstrated by numerical results that under QAM/PSK\nconstellations, there is no other orthogonal communication-centric waveform\nthat achieves a lower ranging sidelobe level than that of the OFDM, in terms of\nboth P-ACF and A-ACF cases.", "comment": "17 pages, 11 figures, accepted by the IEEE Transactions on\n  Information Theory", "pdf_url": "http://arxiv.org/pdf/2407.06691v3", "cate": "cs.IT", "date": "2024-07-09", "updated": "2025-07-21"}
{"id": "2507.14167", "title": "Attention-Based Fusion of IQ and FFT Spectrograms with AoA Features for GNSS Jammer Localization", "authors": ["Lucas Heublein", "Christian Wielenberg", "Thorsten Nowak", "Tobias Feigl", "Christopher Mutschler", "Felix Ott"], "categories": ["eess.SP", "cs.IR", "cs.LG", "62H05, 65-11, 94-11", "E.0; H.1.1; I.2.6; I.5.4"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      6 pages, 10 figures", "url": "http://arxiv.org/abs/2507.14167v1", "summary": "Jamming devices disrupt signals from the global navigation satellite system\n(GNSS) and pose a significant threat by compromising the reliability of\naccurate positioning. Consequently, the detection and localization of these\ninterference signals are essential to achieve situational awareness, mitigating\ntheir impact, and implementing effective counter-measures. Classical Angle of\nArrival (AoA) methods exhibit reduced accuracy in multipath environments due to\nsignal reflections and scattering, leading to localization errors.\nAdditionally, AoA-based techniques demand substantial computational resources\nfor array signal processing. In this paper, we propose a novel approach for\ndetecting and classifying interference while estimating the distance, azimuth,\nand elevation of jamming sources. Our benchmark study evaluates 128 vision\nencoder and time-series models to identify the highest-performing methods for\neach task. We introduce an attention-based fusion framework that integrates\nin-phase and quadrature (IQ) samples with Fast Fourier Transform (FFT)-computed\nspectrograms while incorporating 22 AoA features to enhance localization\naccuracy. Furthermore, we present a novel dataset of moving jamming devices\nrecorded in an indoor environment with dynamic multipath conditions and\ndemonstrate superior performance compared to state-of-the-art methods.", "comment": "6 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.14167v1", "cate": "eess.SP", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.14647", "title": "Multi-Sampling-Frequency Naturalness MOS Prediction Using Self-Supervised Learning Model with Sampling-Frequency-Independent Layer", "authors": ["Go Nishikawa", "Wataru Nakata", "Yuki Saito", "Kanami Imamura", "Hiroshi Saruwatari", "Tomohiko Nakamura"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      4 pages, 2 figures", "url": "http://arxiv.org/abs/2507.14647v1", "summary": "We introduce our submission to the AudioMOS Challenge (AMC) 2025 Track 3:\nmean opinion score (MOS) prediction for speech with multiple sampling\nfrequencies (SFs). Our submitted model integrates an SF-independent (SFI)\nconvolutional layer into a self-supervised learning (SSL) model to achieve SFI\nspeech feature extraction for MOS prediction. We present some strategies to\nimprove the MOS prediction performance of our model: distilling knowledge from\na pretrained non-SFI-SSL model and pretraining with a large-scale MOS dataset.\nOur submission to the AMC 2025 Track 3 ranked the first in one evaluation\nmetric and the fourth in the final ranking. We also report the results of our\nablation study to investigate essential factors of our model.", "comment": "4 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.14647v1", "cate": "cs.SD", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14504", "title": "New Algorithms for #2-SAT and #3-SAT", "authors": ["Junqiang Peng", "Zimo Sheng", "Mingyu Xiao"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Accepted by IJCAI 2025", "url": "http://arxiv.org/abs/2507.14504v1", "summary": "The #2-SAT and #3-SAT problems involve counting the number of satisfying\nassignments (also called models) for instances of 2-SAT and 3-SAT,\nrespectively. In 2010, Zhou et al. proposed an $\\mathcal{O}^*(1.1892^m)$-time\nalgorithm for #2-SAT and an efficient approach for #3-SAT, where $m$ denotes\nthe number of clauses. In this paper, we show that the weighted versions of\n#2-SAT and #3-SAT can be solved in $\\mathcal{O}^*(1.1082^m)$ and\n$\\mathcal{O}^*(1.4423^m)$ time, respectively. These results directly apply to\nthe unweighted cases and achieve substantial improvements over the previous\nresults. These advancements are enabled by the introduction of novel reduction\nrules, a refined analysis of branching operations, and the application of path\ndecompositions on the primal and dual graphs of the formula.", "comment": "Accepted by IJCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.14504v1", "cate": "cs.DS", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2409.08493", "title": "Intelligent LiDAR Navigation: Leveraging External Information and Semantic Maps with LLM as Copilot", "authors": ["Fujing Xie", "Jiajie Zhang", "Sören Schwertfeger"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at IROS 2025", "url": "http://arxiv.org/abs/2409.08493v3", "summary": "Traditional robot navigation systems primarily utilize occupancy grid maps\nand laser-based sensing technologies, as demonstrated by the popular move_base\npackage in ROS. Unlike robots, humans navigate not only through spatial\nawareness and physical distances but also by integrating external information,\nsuch as elevator maintenance updates from public notification boards and\nexperiential knowledge, like the need for special access through certain doors.\nWith the development of Large Language Models (LLMs), which possesses text\nunderstanding and intelligence close to human performance, there is now an\nopportunity to infuse robot navigation systems with a level of understanding\nakin to human cognition. In this study, we propose using osmAG (Area Graph in\nOpensStreetMap textual format), an innovative semantic topometric hierarchical\nmap representation, to bridge the gap between the capabilities of ROS move_base\nand the contextual understanding offered by LLMs. Our methodology employs LLMs\nas an actual copilot in robot navigation, enabling the integration of a broader\nrange of informational inputs while maintaining the robustness of traditional\nrobotic navigation systems. Our code, demo, map, experiment results can be\naccessed at\nhttps://github.com/xiexiexiaoxiexie/Intelligent-LiDAR-Navigation-LLM-as-Copilot.", "comment": "Accepted at IROS 2025", "pdf_url": "http://arxiv.org/pdf/2409.08493v3", "cate": "cs.RO", "date": "2024-09-13", "updated": "2025-07-19"}
{"id": "2411.01789", "title": "Generating executable oracles to check conformance of client code to requirements of JDK Javadocs using LLMs", "authors": ["Shan Jiang", "Chenguang Zhu", "Sarfraz Khurshid"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.01789v2", "summary": "Software testing remains the most widely used methodology for validating\nquality of code. However, effectiveness of testing critically depends on the\nquality of test suites used. Test cases in a test suite consist of two\nfundamental parts: (1) input values for the code under test, and (2) correct\nchecks for the outputs it produces. These checks are commonly written as\nassertions, and termed test oracles. The last couple of decades have seen much\nprogress in automated test input generation, e.g., using fuzzing and symbolic\nexecution. However, automating test oracles remains a relatively less explored\nproblem area. Indeed, a test oracle by its nature requires knowledge of\nexpected behavior, which may only be known to the developer and may not not\nexist in a formal language that supports automated reasoning.\n  Our focus in this paper is automation of test oracles for clients of widely\nused Java libraries, e.g., java.lang and java.util packages. Our key insight is\nthat Javadocs that provide a rich source of information can enable automated\ngeneration of test oracles. Javadocs of the core Java libraries are fairly\ndetailed documents that contain natural language descriptions of not only how\nthe libraries behave but also how the clients must (not) use them. We use large\nlanguage models as an enabling technology to embody our insight into a\nframework for test oracle automation, and evaluate it experimentally. Our\nexperiments demonstrate that LLMs can generate oracles for checking normal and\nexceptional behaviors from Javadocs, with 98.8% of these oracles being\ncompilable and 96.4% accurately reflecting intended properties. Even for the\nfew incorrect oracles, errors are minor and can be easily corrected with the\nhelp of additional comment information generated by the LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.01789v2", "cate": "cs.SE", "date": "2024-11-04", "updated": "2024-12-14"}
{"id": "2507.14746", "title": "Sampling from Gaussian Processes: A Tutorial and Applications in Global Sensitivity Analysis and Optimization", "authors": ["Bach Do", "Nafeezat A. Ajenifuja", "Taiwo A. Adebiyi", "Ruda Zhang"], "categories": ["cs.LG", "math.OC", "stat.AP", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14746v1", "summary": "High-fidelity simulations and physical experiments are essential for\nengineering analysis and design. However, their high cost often limits their\napplications in two critical tasks: global sensitivity analysis (GSA) and\noptimization. This limitation motivates the common use of Gaussian processes\n(GPs) as proxy regression models to provide uncertainty-aware predictions based\non a limited number of high-quality observations. GPs naturally enable\nefficient sampling strategies that support informed decision-making under\nuncertainty by extracting information from a subset of possible functions for\nthe model of interest. Despite their popularity in machine learning and\nstatistics communities, sampling from GPs has received little attention in the\ncommunity of engineering optimization. In this paper, we present the\nformulation and detailed implementation of two notable sampling methods --\nrandom Fourier features and pathwise conditioning -- for generating posterior\nsamples from GPs. Alternative approaches are briefly described. Importantly, we\ndetail how the generated samples can be applied in GSA, single-objective\noptimization, and multi-objective optimization. We show successful applications\nof these sampling methods through a series of numerical examples.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14746v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14798", "title": "An Evaluation of DUSt3R/MASt3R/VGGT 3D Reconstruction on Photogrammetric Aerial Blocks", "authors": ["Xinyi Wu", "Steven Landgraf", "Markus Ulrich", "Rongjun Qin"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      23 pages, 6 figures, this manuscript has been submitted to Geo-spatial Information Science for consideration", "url": "http://arxiv.org/abs/2507.14798v1", "summary": "State-of-the-art 3D computer vision algorithms continue to advance in\nhandling sparse, unordered image sets. Recently developed foundational models\nfor 3D reconstruction, such as Dense and Unconstrained Stereo 3D Reconstruction\n(DUSt3R), Matching and Stereo 3D Reconstruction (MASt3R), and Visual Geometry\nGrounded Transformer (VGGT), have attracted attention due to their ability to\nhandle very sparse image overlaps. Evaluating DUSt3R/MASt3R/VGGT on typical\naerial images matters, as these models may handle extremely low image overlaps,\nstereo occlusions, and textureless regions. For redundant collections, they can\naccelerate 3D reconstruction by using extremely sparsified image sets. Despite\ntests on various computer vision benchmarks, their potential on photogrammetric\naerial blocks remains unexplored. This paper conducts a comprehensive\nevaluation of the pre-trained DUSt3R/MASt3R/VGGT models on the aerial blocks of\nthe UseGeo dataset for pose estimation and dense 3D reconstruction. Results\nshow these methods can accurately reconstruct dense point clouds from very\nsparse image sets (fewer than 10 images, up to 518 pixels resolution), with\ncompleteness gains up to +50% over COLMAP. VGGT also demonstrates higher\ncomputational efficiency, scalability, and more reliable camera pose\nestimation. However, all exhibit limitations with high-resolution images and\nlarge sets, as pose reliability declines with more images and geometric\ncomplexity. These findings suggest transformer-based methods cannot fully\nreplace traditional SfM and MVS, but offer promise as complementary approaches,\nespecially in challenging, low-resolution, and sparse scenarios.", "comment": "23 pages, 6 figures, this manuscript has been submitted to\n  Geo-spatial Information Science for consideration", "pdf_url": "http://arxiv.org/pdf/2507.14798v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2503.15838", "title": "Enhancing LLM Code Generation with Ensembles: A Similarity-Based Selection Approach", "authors": ["Tarek Mahmud", "Bin Duan", "Corina Pasareanu", "Guowei Yang"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.15838v2", "summary": "Ensemble learning has been widely used in machine learning to improve model\nrobustness, accuracy, and generalization, but has not yet been applied to code\ngeneration tasks with large language models (LLMs). We propose an ensemble\napproach for LLMs in code generation. Instead of relying on the output of a\nsingle model, we generate multiple candidate programs from different LLMs and\napply a structured voting mechanism to select the most reliable solution. For\nvoting, we compute syntactic and semantic similarity using CodeBLEU and\nbehavioral equivalence using CrossHair's differential behavior analysis. By\naggregating these similarity scores, we select the program that best aligns\nwith the consensus among the candidates. We show through experiments that our\nensemble approach consistently outperforms standalone LLMs on the well-known\nHumanEval and the more challenging LiveCodeBench datasets, achieving an\naccuracy of 90.2% and 50.2%, respectively, on the two datasets. In comparison,\nthe best-performing LLM (GPT-4o) has an accuracy of 83.5% and 43.4%,\nrespectively. Furthermore, even when restricted to free open-source models, our\nmethod achieves an accuracy of 80.5% and 41.6%, respectively, demonstrating the\nviability of our approach in resource-constrained settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.15838v2", "cate": "cs.SE", "date": "2025-03-20", "updated": "2025-07-18"}
{"id": "2501.01138", "title": "Semantics-Guided Diffusion for Deep Joint Source-Channel Coding in Wireless Image Transmission", "authors": ["Maojun Zhang", "Haotian Wu", "Guangxu Zhu", "Richeng Jin", "Xiaoming Chen", "Deniz Gündüz"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      17 pages, submitted to IEEE for possible publication", "url": "http://arxiv.org/abs/2501.01138v2", "summary": "Joint source-channel coding (JSCC) offers a promising avenue for enhancing\ntransmission efficiency by jointly incorporating source and channel statistics\ninto the system design. A key advancement in this area is the deep joint source\nand channel coding (DeepJSCC) technique that designs a direct mapping of input\nsignals to channel symbols parameterized by a neural network, which can be\ntrained for arbitrary channel models and semantic quality metrics. This paper\nadvances the DeepJSCC framework toward a semantics-aligned, high-fidelity\ntransmission approach, called semantics-guided diffusion DeepJSCC (SGD-JSCC).\nExisting schemes that integrate diffusion models (DMs) with JSCC face\nchallenges in transforming random generation into accurate reconstruction and\nadapting to varying channel conditions. SGD-JSCC incorporates two key\ninnovations: (1) utilizing some inherent information that contributes to the\nsemantics of an image, such as text description or edge map, to guide the\ndiffusion denoising process; and (2) enabling seamless adaptability to varying\nchannel conditions with the help of a semantics-guided DM for channel\ndenoising. The DM is guided by diverse semantic information and integrates\nseamlessly with DeepJSCC. In a slow fading channel, SGD-JSCC dynamically adapts\nto the instantaneous signal-to-noise ratio (SNR) directly estimated from the\nchannel output, thereby eliminating the need for additional pilot transmissions\nfor channel estimation. In a fast fading channel, we introduce a training-free\ndenoising strategy, allowing SGD-JSCC to effectively adjust to fluctuations in\nchannel gains. Numerical results demonstrate that, guided by semantic\ninformation and leveraging the powerful DM, our method outperforms existing\nDeepJSCC schemes, delivering satisfactory reconstruction performance even at\nextremely poor channel conditions.", "comment": "17 pages, submitted to IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2501.01138v2", "cate": "cs.IT", "date": "2025-01-02", "updated": "2025-07-21"}
{"id": "2507.14184", "title": "NeuroHD-RA: Neural-distilled Hyperdimensional Model with Rhythm Alignment", "authors": ["ZhengXiao He", "Jinghao Wen", "Huayu Li", "Ao Li"], "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14184v1", "summary": "We present a novel and interpretable framework for electrocardiogram\n(ECG)-based disease detection that combines hyperdimensional computing (HDC)\nwith learnable neural encoding. Unlike conventional HDC approaches that rely on\nstatic, random projections, our method introduces a rhythm-aware and trainable\nencoding pipeline based on RR intervals, a physiological signal segmentation\nstrategy that aligns with cardiac cycles. The core of our design is a\nneural-distilled HDC architecture, featuring a learnable RR-block encoder and a\nBinaryLinear hyperdimensional projection layer, optimized jointly with\ncross-entropy and proxy-based metric loss. This hybrid framework preserves the\nsymbolic interpretability of HDC while enabling task-adaptive representation\nlearning. Experiments on Apnea-ECG and PTB-XL demonstrate that our model\nsignificantly outperforms traditional HDC and classical ML baselines, achieving\n73.09\\% precision and an F1 score of 0.626 on Apnea-ECG, with comparable\nrobustness on PTB-XL. Our framework offers an efficient and scalable solution\nfor edge-compatible ECG classification, with strong potential for interpretable\nand personalized health monitoring.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14184v1", "cate": "eess.SP", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2507.14915", "title": "Music-Aligned Holistic 3D Dance Generation via Hierarchical Motion Modeling", "authors": ["Xiaojie Li", "Ronghui Li", "Shukai Fang", "Shuzhao Xie", "Xiaoyang Guo", "Jiaqing Zhou", "Junkun Peng", "Zhi Wang"], "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14915v1", "summary": "Well-coordinated, music-aligned holistic dance enhances emotional\nexpressiveness and audience engagement. However, generating such dances remains\nchallenging due to the scarcity of holistic 3D dance datasets, the difficulty\nof achieving cross-modal alignment between music and dance, and the complexity\nof modeling interdependent motion across the body, hands, and face. To address\nthese challenges, we introduce SoulDance, a high-precision music-dance paired\ndataset captured via professional motion capture systems, featuring\nmeticulously annotated holistic dance movements. Building on this dataset, we\npropose SoulNet, a framework designed to generate music-aligned, kinematically\ncoordinated holistic dance sequences. SoulNet consists of three principal\ncomponents: (1) Hierarchical Residual Vector Quantization, which models\ncomplex, fine-grained motion dependencies across the body, hands, and face; (2)\nMusic-Aligned Generative Model, which composes these hierarchical motion units\ninto expressive and coordinated holistic dance; (3) Music-Motion Retrieval\nModule, a pre-trained cross-modal model that functions as a music-dance\nalignment prior, ensuring temporal synchronization and semantic coherence\nbetween generated dance and input music throughout the generation process.\nExtensive experiments demonstrate that SoulNet significantly surpasses existing\napproaches in generating high-quality, music-coordinated, and well-aligned\nholistic 3D dance sequences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14915v1", "cate": "cs.MM", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14509", "title": "Addressing Bias in Algorithmic Solutions: Exploring Vertex Cover and Feedback Vertex Set", "authors": ["Sheikh Shakil Akhtar", "Jayakrishnan Madathil", "Pranabendu Misra", "Geevarghese Philip"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14509v1", "summary": "A typical goal of research in combinatorial optimization is to come up with\nfast algorithms that find optimal solutions to a computational problem. The\nprocess that takes a real-world problem and extracts a clean mathematical\nabstraction of it often throws out a lot of \"side information\" which is deemed\nirrelevant. However, the discarded information could be of real significance to\nthe end-user of the algorithm's output. All solutions of the same cost are not\nnecessarily of equal impact in the real-world; some solutions may be much more\ndesirable than others, even at the expense of additional increase in cost. If\nthe impact, positive or negative, is mostly felt by some specific (minority)\nsubgroups of the population, the population at large will be largely unaware of\nit. In this work we ask the question of finding solutions to combinatorial\noptimization problems that are \"unbiased\" with respect to a collection of\nspecified subgroups of the total population.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14509v1", "cate": "cs.DS", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2409.10283", "title": "ASMA: An Adaptive Safety Margin Algorithm for Vision-Language Drone Navigation via Scene-Aware Control Barrier Functions", "authors": ["Sourav Sanyal", "Kaushik Roy"], "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.IV", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted for publication in IEEE Robotics and Automation Letters (RA-L)", "url": "http://arxiv.org/abs/2409.10283v4", "summary": "In the rapidly evolving field of vision-language navigation (VLN), ensuring\nsafety for physical agents remains an open challenge. For a human-in-the-loop\nlanguage-operated drone to navigate safely, it must understand natural language\ncommands, perceive the environment, and simultaneously avoid hazards in real\ntime. Control Barrier Functions (CBFs) are formal methods that enforce safe\noperating conditions. Model Predictive Control (MPC) is an optimization\nframework that plans a sequence of future actions over a prediction horizon,\nensuring smooth trajectory tracking while obeying constraints. In this work, we\nconsider a VLN-operated drone platform and enhance its safety by formulating a\nnovel scene-aware CBF that leverages ego-centric observations from a camera\nwhich has both Red-Green-Blue as well as Depth (RGB-D) channels. A CBF-less\nbaseline system uses a Vision-Language Encoder with cross-modal attention to\nconvert commands into an ordered sequence of landmarks. An object detection\nmodel identifies and verifies these landmarks in the captured images to\ngenerate a planned path. To further enhance safety, an Adaptive Safety Margin\nAlgorithm (ASMA) is proposed. ASMA tracks moving objects and performs\nscene-aware CBF evaluation on-the-fly, which serves as an additional constraint\nwithin the MPC framework. By continuously identifying potentially risky\nobservations, the system performs prediction in real time about unsafe\nconditions and proactively adjusts its control actions to maintain safe\nnavigation throughout the trajectory. Deployed on a Parrot Bebop2 quadrotor in\nthe Gazebo environment using the Robot Operating System (ROS), ASMA achieves\n64%-67% increase in success rates with only a slight increase (1.4%-5.8%) in\ntrajectory lengths compared to the baseline CBF-less VLN.", "comment": "Accepted for publication in IEEE Robotics and Automation Letters\n  (RA-L)", "pdf_url": "http://arxiv.org/pdf/2409.10283v4", "cate": "cs.RO", "date": "2024-09-16", "updated": "2025-07-19"}
{"id": "2505.17593", "title": "JELAI: Integrating AI and Learning Analytics in Jupyter Notebooks", "authors": ["Manuel Valle Torre", "Thom van der Velden", "Marcus Specht", "Catharine Oertel"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted for AIED 2025", "url": "http://arxiv.org/abs/2505.17593v1", "summary": "Generative AI offers potential for educational support, but often lacks\npedagogical grounding and awareness of the student's learning context.\nFurthermore, researching student interactions with these tools within authentic\nlearning environments remains challenging. To address this, we present JELAI,\nan open-source platform architecture designed to integrate fine-grained\nLearning Analytics (LA) with Large Language Model (LLM)-based tutoring directly\nwithin a Jupyter Notebook environment. JELAI employs a modular, containerized\ndesign featuring JupyterLab extensions for telemetry and chat, alongside a\ncentral middleware handling LA processing and context-aware LLM prompt\nenrichment. This architecture enables the capture of integrated code\ninteraction and chat data, facilitating real-time, context-sensitive AI\nscaffolding and research into student behaviour. We describe the system's\ndesign, implementation, and demonstrate its feasibility through system\nperformance benchmarks and two proof-of-concept use cases illustrating its\ncapabilities for logging multi-modal data, analysing help-seeking patterns, and\nsupporting A/B testing of AI configurations. JELAI's primary contribution is\nits technical framework, providing a flexible tool for researchers and\neducators to develop, deploy, and study LA-informed AI tutoring within the\nwidely used Jupyter ecosystem.", "comment": "Accepted for AIED 2025", "pdf_url": "http://arxiv.org/pdf/2505.17593v1", "cate": "cs.HC", "date": "2025-05-23", "updated": "2025-05-23"}
{"id": "2507.14747", "title": "Pruning Increases Orderedness in Recurrent Computation", "authors": ["Yiding Song"], "categories": ["cs.LG", "cs.NE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      8 pages, 11 figures, 2 tables, Workshop on Methods and Opportunities at Small Scale (MOSS), ICML 2025", "url": "http://arxiv.org/abs/2507.14747v1", "summary": "Inspired by the prevalence of recurrent circuits in biological brains, we\ninvestigate the degree to which directionality is a helpful inductive bias for\nartificial neural networks. Taking directionality as topologically-ordered\ninformation flow between neurons, we formalise a perceptron layer with\nall-to-all connections (mathematically equivalent to a weight-tied recurrent\nneural network) and demonstrate that directionality, a hallmark of modern\nfeed-forward networks, can be induced rather than hard-wired by applying\nappropriate pruning techniques. Across different random seeds our pruning\nschemes successfully induce greater topological ordering in information flow\nbetween neurons without compromising performance, suggesting that\ndirectionality is not a prerequisite for learning, but may be an advantageous\ninductive bias discoverable by gradient descent and sparsification.", "comment": "8 pages, 11 figures, 2 tables, Workshop on Methods and Opportunities\n  at Small Scale (MOSS), ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.14747v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14801", "title": "Exploring Scalable Unified Modeling for General Low-Level Vision", "authors": ["Xiangyu Chen", "Kaiwen Zhu", "Yuandong Pu", "Shuo Cao", "Xiaohui Li", "Wenlong Zhang", "Yihao Liu", "Yu Qiao", "Jiantao Zhou", "Chao Dong"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14801v1", "summary": "Low-level vision involves a wide spectrum of tasks, including image\nrestoration, enhancement, stylization, and feature extraction, which differ\nsignificantly in both task formulation and output domains. To address the\nchallenge of unified modeling across such diverse tasks, we propose a Visual\ntask Prompt-based Image Processing (VPIP) framework that leverages input-target\nimage pairs as visual prompts to guide the model in performing a variety of\nlow-level vision tasks. The framework comprises an end-to-end image processing\nbackbone, a prompt encoder, and a prompt interaction module, enabling flexible\nintegration with various architectures and effective utilization of\ntask-specific visual representations. Based on this design, we develop a\nunified low-level vision model, GenLV, and evaluate its performance across\nmultiple representative tasks. To explore the scalability of this approach, we\nextend the framework along two dimensions: model capacity and task diversity.\nWe construct a large-scale benchmark consisting of over 100 low-level vision\ntasks and train multiple versions of the model with varying scales.\nExperimental results show that the proposed method achieves considerable\nperformance across a wide range of tasks. Notably, increasing the number of\ntraining tasks enhances generalization, particularly for tasks with limited\ndata, indicating the model's ability to learn transferable representations\nthrough joint training. Further evaluations in zero-shot generalization,\nfew-shot transfer, and task-specific fine-tuning scenarios demonstrate the\nmodel's strong adaptability, confirming the effectiveness, scalability, and\npotential of the proposed framework as a unified foundation for general\nlow-level vision modeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14801v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2503.17181", "title": "A Study of LLMs' Preferences for Libraries and Programming Languages", "authors": ["Lukas Twist", "Jie M. Zhang", "Mark Harman", "Don Syme", "Joost Noppen", "Helen Yannakoudakis", "Detlef Nauck"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      13 pages, 8 tables, 2 figures. Paper was previously titled \"LLMs Love Python\"", "url": "http://arxiv.org/abs/2503.17181v2", "summary": "Large Language Models (LLMs) are increasingly used to generate code,\ninfluencing users' choices of libraries and programming languages in critical\nreal-world projects. However, little is known about their systematic biases or\npreferences toward certain libraries and programming languages, which can\nsignificantly impact software development practices. To fill this gap, we\nperform the first empirical study of LLMs' preferences for libraries and\nprogramming languages when generating code, covering eight diverse LLMs. Our\nresults reveal that LLMs exhibit a strong tendency to overuse widely adopted\nlibraries such as NumPy; in up to 48% of cases, this usage is unnecessary and\ndeviates from the ground-truth solutions. LLMs also exhibit a significant\npreference toward Python as their default language. For high-performance\nproject initialisation tasks where Python is not the optimal language, it\nremains the dominant choice in 58% of cases, and Rust is not used a single\ntime. These results indicate that LLMs may prioritise familiarity and\npopularity over suitability and task-specific optimality. This will introduce\nsecurity vulnerabilities and technical debt, and limit exposure to newly\ndeveloped, better-suited tools and languages. Understanding and addressing\nthese biases is essential for the responsible integration of LLMs into software\ndevelopment workflows.", "comment": "13 pages, 8 tables, 2 figures. Paper was previously titled \"LLMs Love\n  Python\"", "pdf_url": "http://arxiv.org/pdf/2503.17181v2", "cate": "cs.SE", "date": "2025-03-21", "updated": "2025-07-21"}
{"id": "2502.06967", "title": "Downlink and Uplink ISAC in Continuous-Aperture Array (CAPA) Systems", "authors": ["Boqun Zhao", "Chongjun Ouyang", "Xingqi Zhang", "Hyundong Shin", "Yuanwei Liu"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      16 pages, 12 figures", "url": "http://arxiv.org/abs/2502.06967v2", "summary": "A continuous-aperture array (CAPA)-based integrated sensing and\ncommunications (ISAC) framework is proposed for both downlink and uplink\nscenarios. Within this framework, continuous operator-based signal models are\nemployed to describe the sensing and communication processes. The performance\nof communication and sensing is analyzed using two information-theoretic\nmetrics: the communication rate (CR) and the sensing rate (SR). 1) For downlink\nISAC, three continuous beamforming designs are proposed: i) the\ncommunications-centric (C-C) design that maximizes the CR, ii) the\nsensing-centric (S-C) design that maximizes the SR, and iii) the Pareto-optimal\ndesign that characterizes the Pareto boundary of the CR-SR region. A\nlow-complexity signal subspace-based approach is proposed to derive the\nclosed-form optimal beamformers for the considered designs. On this basis,\nclosed-form expressions are derived for the achievable CRs and SRs, and the\ndownlink rate region achieved by CAPAs is characterized. 2) For uplink ISAC,\nthe C-C and S-C successive interference cancellation-based methods are proposed\nto manage inter-functionality interference. Using the subspace approach\nclosed-form expressions for the optimal detectors as well as the achievable CRs\nand SRs are derived. The uplink SR-CR region is characterized based on the\ntime-sharing technique. Numerical results demonstrate that, for both downlink\nand uplink, CAPA-based ISAC achieves higher CRs and SRs as well as larger CR-SR\nregions compared to conventional spatially discrete array-based ISAC.", "comment": "16 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2502.06967v2", "cate": "cs.IT", "date": "2025-02-10", "updated": "2025-07-20"}
{"id": "2507.14185", "title": "Latent Sensor Fusion: Multimedia Learning of Physiological Signals for Resource-Constrained Devices", "authors": ["Abdullah Ahmed", "Jeremy Gummeson"], "categories": ["eess.SP", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14185v1", "summary": "Latent spaces offer an efficient and effective means of summarizing data\nwhile implicitly preserving meta-information through relational encoding. We\nleverage these meta-embeddings to develop a modality-agnostic, unified encoder.\nOur method employs sensor-latent fusion to analyze and correlate multimodal\nphysiological signals. Using a compressed sensing approach with\nautoencoder-based latent space fusion, we address the computational challenges\nof biosignal analysis on resource-constrained devices. Experimental results\nshow that our unified encoder is significantly faster, lighter, and more\nscalable than modality-specific alternatives, without compromising\nrepresentational accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14185v1", "cate": "eess.SP", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.15221", "title": "EchoVoices: Preserving Generational Voices and Memories for Seniors and Children", "authors": ["Haiying Xu", "Haoze Liu", "Mingshi Li", "Siyu Cai", "Guangxuan Zheng", "Yuhuang Jia", "Jinghua Zhao", "Yong Qin"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15221v1", "summary": "Recent breakthroughs in intelligent speech and digital human technologies\nhave primarily targeted mainstream adult users, often overlooking the distinct\nvocal patterns and interaction styles of seniors and children. These\ndemographics possess distinct vocal characteristics, linguistic styles, and\ninteraction patterns that challenge conventional ASR, TTS, and LLM systems. To\naddress this, we introduce EchoVoices, an end-to-end digital human pipeline\ndedicated to creating persistent digital personas for seniors and children,\nensuring their voices and memories are preserved for future generations. Our\nsystem integrates three core innovations: a k-NN-enhanced Whisper model for\nrobust speech recognition of atypical speech; an age-adaptive VITS model for\nhigh-fidelity, speaker-aware speech synthesis; and an LLM-driven agent that\nautomatically generates persona cards and leverages a RAG-based memory system\nfor conversational consistency. Our experiments, conducted on the SeniorTalk\nand ChildMandarin datasets, demonstrate significant improvements in recognition\naccuracy, synthesis quality, and speaker similarity. EchoVoices provides a\ncomprehensive framework for preserving generational voices, offering a new\nmeans of intergenerational connection and the creation of lasting digital\nlegacies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15221v1", "cate": "cs.SD", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14569", "title": "Characterizing and Testing Configuration Stability in Two-Dimensional Threshold Cellular Automata", "authors": ["Yonatan Nakar", "Dana Ron"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14569v1", "summary": "We consider the problems of characterizing and testing the stability of\ncellular automata configurations that evolve on a two-dimensional torus\naccording to threshold rules with respect to the von-Neumann neighborhood.\nWhile stable configurations for Threshold-1 (OR) and Threshold-5 (AND) are\ntrivial (and hence easily testable), the other threshold rules exhibit much\nmore diverse behaviors. We first characterize the structure of stable\nconfigurations with respect to the Threshold-2 (similarly, Threshold-4) and\nThreshold-3 (Majority) rules. We then design and analyze a testing algorithm\nthat distinguishes between configurations that are stable with respect to the\nThreshold-2 rule, and those that are $\\epsilon$-far from any stable\nconfiguration, where the query complexity of the algorithm is independent of\nthe size of the configuration and depends quadratically on $1/\\epsilon$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14569v1", "cate": "cs.DS", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2409.17262", "title": "CROSS-GAiT: Cross-Attention-Based Multimodal Representation Fusion for Parametric Gait Adaptation in Complex Terrains", "authors": ["Gershom Seneviratne", "Kasun Weerakoon", "Mohamed Elnoor", "Vignesh Rajgopal", "Harshavarthan Varatharajan", "Mohamed Khalid M Jaffar", "Jason Pusey", "Dinesh Manocha"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.17262v3", "summary": "We present CROSS-GAiT, a novel algorithm for quadruped robots that uses Cross\nAttention to fuse terrain representations derived from visual and time-series\ninputs; including linear accelerations, angular velocities, and joint efforts.\nThese fused representations are used to continuously adjust two critical gait\nparameters (step height and hip splay), enabling adaptive gaits that respond\ndynamically to varying terrain conditions. To generate terrain representations,\nwe process visual inputs through a masked Vision Transformer (ViT) encoder and\ntime-series data through a dilated causal convolutional encoder. The Cross\nAttention mechanism then selects and integrates the most relevant features from\neach modality, combining terrain characteristics with robot dynamics for\ninformed gait adaptation. This fused representation allows CROSS-GAiT to\ncontinuously adjust gait parameters in response to unpredictable terrain\nconditions in real-time. We train CROSS-GAiT on a diverse set of terrains\nincluding asphalt, concrete, brick pavements, grass, dense vegetation, pebbles,\ngravel, and sand and validate its generalization ability on unseen\nenvironments. Our hardware implementation on the Ghost Robotics Vision 60\ndemonstrates superior performance in challenging terrains, such as high-density\nvegetation, unstable surfaces, sandbanks, and deformable substrates. We observe\nat least a 7.04% reduction in IMU energy density and a 27.3% reduction in total\njoint effort, which directly correlates with increased stability and reduced\nenergy usage when compared to state-of-the-art methods. Furthermore, CROSS-GAiT\ndemonstrates at least a 64.5% increase in success rate and a 4.91% reduction in\ntime to reach the goal in four complex scenarios. Additionally, the learned\nrepresentations perform 4.48% better than the state-of-the-art on a terrain\nclassification task.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.17262v3", "cate": "cs.RO", "date": "2024-09-25", "updated": "2025-07-20"}
{"id": "2506.23298", "title": "Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM Few-Shot In-Context Learning for Medical Image Classification", "authors": ["Xing Shen", "Justin Szeto", "Mingyang Li", "Hengguan Huang", "Tal Arbel"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Preprint version. The peer-reviewed version of this paper has been accepted to MICCAI 2025 main conference", "url": "http://arxiv.org/abs/2506.23298v3", "summary": "Multimodal large language models (MLLMs) have enormous potential to perform\nfew-shot in-context learning in the context of medical image analysis. However,\nsafe deployment of these models into real-world clinical practice requires an\nin-depth analysis of the accuracies of their predictions, and their associated\ncalibration errors, particularly across different demographic subgroups. In\nthis work, we present the first investigation into the calibration biases and\ndemographic unfairness of MLLMs' predictions and confidence scores in few-shot\nin-context learning for medical image classification. We introduce CALIN, an\ninference-time calibration method designed to mitigate the associated biases.\nSpecifically, CALIN estimates the amount of calibration needed, represented by\ncalibration matrices, using a bi-level procedure: progressing from the\npopulation level to the subgroup level prior to inference. It then applies this\nestimation to calibrate the predicted confidence scores during inference.\nExperimental results on three medical imaging datasets: PAPILA for fundus image\nclassification, HAM10000 for skin cancer classification, and MIMIC-CXR for\nchest X-ray classification demonstrate CALIN's effectiveness at ensuring fair\nconfidence calibration in its prediction, while improving its overall\nprediction accuracies and exhibiting minimum fairness-utility trade-off. Our\ncodebase can be found at\nhttps://github.com/xingbpshen/medical-calibration-fairness-mllm.", "comment": "Preprint version. The peer-reviewed version of this paper has been\n  accepted to MICCAI 2025 main conference", "pdf_url": "http://arxiv.org/pdf/2506.23298v3", "cate": "eess.IV", "date": "2025-06-29", "updated": "2025-07-17"}
{"id": "2507.14748", "title": "Skill Learning via Policy Diversity Yields Identifiable Representations for Reinforcement Learning", "authors": ["Patrik Reizinger", "Bálint Mucsányi", "Siyuan Guo", "Benjamin Eysenbach", "Bernhard Schölkopf", "Wieland Brendel"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      16 pages, 7 figures", "url": "http://arxiv.org/abs/2507.14748v1", "summary": "Self-supervised feature learning and pretraining methods in reinforcement\nlearning (RL) often rely on information-theoretic principles, termed mutual\ninformation skill learning (MISL). These methods aim to learn a representation\nof the environment while also incentivizing exploration thereof. However, the\nrole of the representation and mutual information parametrization in MISL is\nnot yet well understood theoretically. Our work investigates MISL through the\nlens of identifiable representation learning by focusing on the Contrastive\nSuccessor Features (CSF) method. We prove that CSF can provably recover the\nenvironment's ground-truth features up to a linear transformation due to the\ninner product parametrization of the features and skill diversity in a\ndiscriminative sense. This first identifiability guarantee for representation\nlearning in RL also helps explain the implications of different mutual\ninformation objectives and the downsides of entropy regularizers. We\nempirically validate our claims in MuJoCo and DeepMind Control and show how CSF\nprovably recovers the ground-truth features both from states and pixels.", "comment": "16 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.14748v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14807", "title": "Seeing Through Deepfakes: A Human-Inspired Framework for Multi-Face Detection", "authors": ["Juan Hu", "Shaojing Fan", "Terence Sim"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14807v1", "summary": "Multi-face deepfake videos are becoming increasingly prevalent, often\nappearing in natural social settings that challenge existing detection methods.\nMost current approaches excel at single-face detection but struggle in\nmulti-face scenarios, due to a lack of awareness of crucial contextual cues. In\nthis work, we develop a novel approach that leverages human cognition to\nanalyze and defend against multi-face deepfake videos. Through a series of\nhuman studies, we systematically examine how people detect deepfake faces in\nsocial settings. Our quantitative analysis reveals four key cues humans rely\non: scene-motion coherence, inter-face appearance compatibility, interpersonal\ngaze alignment, and face-body consistency. Guided by these insights, we\nintroduce \\textsf{HICOM}, a novel framework designed to detect every fake face\nin multi-face scenarios. Extensive experiments on benchmark datasets show that\n\\textsf{HICOM} improves average accuracy by 3.3\\% in in-dataset detection and\n2.8\\% under real-world perturbations. Moreover, it outperforms existing methods\nby 5.8\\% on unseen datasets, demonstrating the generalization of human-inspired\ncues. \\textsf{HICOM} further enhances interpretability by incorporating an LLM\nto provide human-readable explanations, making detection results more\ntransparent and convincing. Our work sheds light on involving human factors to\nenhance defense against deepfakes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14807v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2505.08263", "title": "LLM-Based Detection of Tangled Code Changes for Higher-Quality Method-Level Bug Datasets", "authors": ["Md Nahidul Islam Opu", "Shaowei Wang", "Shaiful Chowdhury"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.08263v2", "summary": "Tangled code changes, commits that conflate unrelated modifications such as\nbug fixes, refactorings, and enhancements, introduce significant noise into bug\ndatasets and adversely affect the performance of bug prediction models.\nAddressing this issue at a fine-grained, method-level granularity remains\nunderexplored. This is critical to address, as recent bug prediction models,\ndriven by practitioner demand, are increasingly focusing on finer granularity\nrather than traditional class- or file-level predictions. This study\ninvestigates the utility of Large Language Models (LLMs) for detecting tangled\ncode changes by leveraging both commit messages and method-level code diffs. We\nformulate the problem as a binary classification task and evaluate multiple\nprompting strategies, including zero-shot, few-shot, and chain-of-thought\nprompting, using state-of-the-art proprietary LLMs such as GPT-4o and\nGemini-2.0-Flash. Our results demonstrate that combining commit messages with\ncode diffs significantly enhances model performance, with the combined few-shot\nand chain-of-thought prompting achieving an F1-score of 0.88. Additionally, we\nexplore machine learning models trained on LLM-generated embeddings, where a\nmulti-layer perceptron classifier achieves superior performance (F1-score:\n0.906, MCC: 0.807). Applying our approach to 49 open-source projects improves\nthe distributional separability of code metrics between buggy and non-buggy\nmethods, demonstrating the promise of LLMs for method-level commit untangling\nand potentially contributing to improving the accuracy of future bug prediction\nmodels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.08263v2", "cate": "cs.SE", "date": "2025-05-13", "updated": "2025-07-19"}
{"id": "2502.16374", "title": "Preserving Simultaneity and Chronology for Sensing in Perceptive Wireless Networks", "authors": ["João Henrique Inacio de Souza", "Fabio Saggese", "Beatriz Soret", "Petar Popovski"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      This work has been accepted by IEEE for publication", "url": "http://arxiv.org/abs/2502.16374v2", "summary": "We address the challenge of preserving the simultaneity and chronology of\nsensing events in multisensor systems with wireless links. The network uses\ntemporal windows of integration (TWIs), borrowed from human multisensory\nperception, to preserve the temporal structure of the sensing data at the\napplication side. We introduce a composite latency model for propagation,\nsensing, and communication that leads to the derivation of the probability of\nsimultaneity violation. This is used to select the TWI duration aiming to\nachieve the desired degrees of chronological preservation, while maintaining\nthe throughput of events. The letter provides important insights and analytical\ntools about the TWI impact on the event registration.", "comment": "This work has been accepted by IEEE for publication", "pdf_url": "http://arxiv.org/pdf/2502.16374v2", "cate": "cs.IT", "date": "2025-02-22", "updated": "2025-07-21"}
{"id": "2507.14187", "title": "AI-Based Impedance Encoding-Decoding Method for Online Impedance Network Construction of Wind Farms", "authors": ["Xiaojuan Zhang", "Tianyu Jiang", "Haoxiang Zong", "Chen Zhang", "Chendan Li", "Marta Molinas"], "categories": ["eess.SP", "cs.AI"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14187v1", "summary": "The impedance network (IN) model is gaining popularity in the oscillation\nanalysis of wind farms. However, the construction of such an IN model requires\nimpedance curves of each wind turbine under their respective operating\nconditions, making its online application difficult due to the transmission of\nnumerous high-density impedance curves. To address this issue, this paper\nproposes an AI-based impedance encoding-decoding method to facilitate the\nonline construction of IN model. First, an impedance encoder is trained to\ncompress impedance curves by setting the number of neurons much smaller than\nthat of frequency points. Then, the compressed data of each turbine are\nuploaded to the wind farm and an impedance decoder is trained to reconstruct\noriginal impedance curves. At last, based on the nodal admittance matrix (NAM)\nmethod, the IN model of the wind farm can be obtained. The proposed method is\nvalidated via model training and real-time simulations, demonstrating that the\nencoded impedance vectors enable fast transmission and accurate reconstruction\nof the original impedance curves.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14187v1", "cate": "eess.SP", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.15272", "title": "A2TTS: TTS for Low Resource Indian Languages", "authors": ["Ayush Singh Bhadoriya", "Abhishek Nikunj Shinde", "Isha Pandey", "Ganesh Ramakrishnan"], "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15272v1", "summary": "We present a speaker conditioned text-to-speech (TTS) system aimed at\naddressing challenges in generating speech for unseen speakers and supporting\ndiverse Indian languages. Our method leverages a diffusion-based TTS\narchitecture, where a speaker encoder extracts embeddings from short reference\naudio samples to condition the DDPM decoder for multispeaker generation. To\nfurther enhance prosody and naturalness, we employ a cross-attention based\nduration prediction mechanism that utilizes reference audio, enabling more\naccurate and speaker consistent timing. This results in speech that closely\nresembles the target speaker while improving duration modeling and overall\nexpressiveness. Additionally, to improve zero-shot generation, we employed\nclassifier free guidance, allowing the system to generate speech more near\nspeech for unknown speakers. Using this approach, we trained language-specific\nspeaker-conditioned models. Using the IndicSUPERB dataset for multiple Indian\nlanguages such as Bengali, Gujarati, Hindi, Marathi, Malayalam, Punjabi and\nTamil.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15272v1", "cate": "cs.SD", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14812", "title": "A Black-Box Approach for Exogenous Replenishment in Online Resource Allocation", "authors": ["Suho Kang", "Ziyang Liu", "Rajan Udwani"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14812v1", "summary": "In a typical online resource allocation problem, we start with a fixed\ninventory of resources and make online allocation decisions in response to\nresource requests that arrive sequentially over a finite horizon. We consider\nsettings where the inventory is replenished over time according to an unknown\nexogenous process. We introduce black-box methods that extend any existing\nalgorithm, originally designed without considering replenishment, into one that\nworks with an arbitrary (adversarial or stochastic) replenishment process. Our\napproach preserves the original algorithm's competitive ratio in regimes with\nlarge initial inventory, thereby enabling the seamless integration of exogenous\nreplenishment into a large body of existing algorithmic results for both\nadversarial and stochastic arrival models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14812v1", "cate": "cs.DS", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14624", "title": "Real-Time Scene Reconstruction using Light Field Probes", "authors": ["Yaru Liu", "Derek Nowrouzezahri", "Morgan Mcguire"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14624v1", "summary": "Reconstructing photo-realistic large-scale scenes from images, for example at\ncity scale, is a long-standing problem in computer graphics. Neural rendering\nis an emerging technique that enables photo-realistic image synthesis from\npreviously unobserved viewpoints; however, state-of-the-art neural rendering\nmethods have difficulty efficiently rendering a high complex large-scale scene\nbecause these methods typically trade scene size, fidelity, and rendering speed\nfor quality. The other stream of techniques utilizes scene geometries for\nreconstruction. But the cost of building and maintaining a large set of\ngeometry data increases as scene size grows. Our work explores novel view\nsynthesis methods that efficiently reconstruct complex scenes without explicit\nuse of scene geometries. Specifically, given sparse images of the scene\n(captured from the real world), we reconstruct intermediate, multi-scale,\nimplicit representations of scene geometries. In this way, our method avoids\nexplicitly relying on scene geometry, significantly reducing the computational\ncost of maintaining large 3D data. Unlike current methods, we reconstruct the\nscene using a probe data structure. Probe data hold highly accurate depth\ninformation of dense data points, enabling the reconstruction of highly complex\nscenes. By reconstructing the scene using probe data, the rendering cost is\nindependent of the complexity of the scene. As such, our approach combines\ngeometry reconstruction and novel view synthesis. Moreover, when rendering\nlarge-scale scenes, compressing and streaming probe data is more efficient than\nusing explicit scene geometry. Therefore, our neural representation approach\ncan potentially be applied to virtual reality (VR) and augmented reality (AR)\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14624v1", "cate": "cs.GR", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2409.20435", "title": "ALLO: A Photorealistic Dataset and Data Generation Pipeline for Anomaly Detection During Robotic Proximity Operations in Lunar Orbit", "authors": ["Selina Leveugle", "Chang Won Lee", "Svetlana Stolpner", "Chris Langley", "Paul Grouchy", "Steven Waslander", "Jonathan Kelly"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Submitted to International Conference on Robotics and Automation (ICRA'25), Atlanta, USA, May 19-23, 2025", "url": "http://arxiv.org/abs/2409.20435v3", "summary": "NASA's forthcoming Lunar Gateway space station, which will be uncrewed most\nof the time, will need to operate with an unprecedented level of autonomy.\nEnhancing autonomy on the Gateway presents several unique challenges, one of\nwhich is to equip the Canadarm3, the Gateway's external robotic system, with\nthe capability to perform worksite monitoring. Monitoring will involve using\nthe arm's inspection cameras to detect any anomalies within the operating\nenvironment, a task complicated by the widely-varying lighting conditions in\nspace. In this paper, we introduce the visual anomaly detection and\nlocalization task for space applications and establish a benchmark with our\nnovel synthetic dataset called ALLO (for Anomaly Localization in Lunar Orbit).\nWe develop a complete data generation pipeline to create ALLO, which we use to\nevaluate the performance of state-of-the-art visual anomaly detection\nalgorithms. Given the low tolerance for risk during space operations and the\nlack of relevant data, we emphasize the need for novel, robust, and accurate\nanomaly detection methods to handle the challenging visual conditions found in\nlunar orbit and beyond.", "comment": "Submitted to International Conference on Robotics and Automation\n  (ICRA'25), Atlanta, USA, May 19-23, 2025", "pdf_url": "http://arxiv.org/pdf/2409.20435v3", "cate": "cs.RO", "date": "2024-09-30", "updated": "2025-07-19"}
{"id": "2507.14140", "title": "Geophysics-informed neural network for model-based seismic inversion using surrogate point spread functions", "authors": ["Marcus Saraiva", "Ana Muller", "Alexandre Maul"], "categories": ["physics.geo-ph", "cs.AI", "eess.SP"], "primary_category": "Subjects:       Geophysics (physics.geo-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14140v1", "summary": "Model-based seismic inversion is a key technique in reservoir\ncharacterization, but traditional methods face significant limitations, such as\nrelying on 1D average stationary wavelets and assuming an unrealistic lateral\nresolution. To address these challenges, we propose a Geophysics-Informed\nNeural Network (GINN) that integrates deep learning with seismic modeling. This\nnovel approach employs a Deep Convolutional Neural Network (DCNN) to\nsimultaneously estimate Point Spread Functions (PSFs) and acoustic impedance\n(IP). PSFs are divided into zero-phase and residual components to ensure\ngeophysical consistency and to capture fine details. We used synthetic data\nfrom the SEAM Phase I Earth Model to train the GINN for 100 epochs\n(approximately 20 minutes) using a 2D UNet architecture. The network's inputs\ninclude positional features and a low-frequency impedance (LF-IP) model. A\nself-supervised loss function combining Mean Squared Error (MSE) and Structural\nSimilarity Index Measure (SSIM) was employed to ensure accurate results. The\nGINN demonstrated its ability to generate high-resolution IP and realistic\nPSFs, aligning with expected geological features. Unlike traditional 1D\nwavelets, the GINN produces PSFs with limited lateral resolution, reducing\nnoise and improving accuracy. Future work will aim to refine the training\nprocess and validate the methodology with real seismic data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14140v1", "cate": "physics.geo-ph", "date": "2025-06-12", "updated": "2025-06-12"}
{"id": "2507.14766", "title": "CXR-TFT: Multi-Modal Temporal Fusion Transformer for Predicting Chest X-ray Trajectories", "authors": ["Mehak Arora", "Ayman Ali", "Kaiyuan Wu", "Carolyn Davis", "Takashi Shimazui", "Mahmoud Alwakeel", "Victor Moas", "Philip Yang", "Annette Esper", "Rishikesan Kamaleswaran"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      In Review for MICCAI 2025", "url": "http://arxiv.org/abs/2507.14766v1", "summary": "In intensive care units (ICUs), patients with complex clinical conditions\nrequire vigilant monitoring and prompt interventions. Chest X-rays (CXRs) are a\nvital diagnostic tool, providing insights into clinical trajectories, but their\nirregular acquisition limits their utility. Existing tools for CXR\ninterpretation are constrained by cross-sectional analysis, failing to capture\ntemporal dynamics. To address this, we introduce CXR-TFT, a novel multi-modal\nframework that integrates temporally sparse CXR imaging and radiology reports\nwith high-frequency clinical data, such as vital signs, laboratory values, and\nrespiratory flow sheets, to predict the trajectory of CXR findings in\ncritically ill patients. CXR-TFT leverages latent embeddings from a vision\nencoder that are temporally aligned with hourly clinical data through\ninterpolation. A transformer model is then trained to predict CXR embeddings at\neach hour, conditioned on previous embeddings and clinical measurements. In a\nretrospective study of 20,000 ICU patients, CXR-TFT demonstrated high accuracy\nin forecasting abnormal CXR findings up to 12 hours before they became\nradiographically evident. This predictive capability in clinical data holds\nsignificant potential for enhancing the management of time-sensitive conditions\nlike acute respiratory distress syndrome, where early intervention is crucial\nand diagnoses are often delayed. By providing distinctive temporal resolution\nin prognostic CXR analysis, CXR-TFT offers actionable 'whole patient' insights\nthat can directly improve clinical outcomes.", "comment": "In Review for MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.14766v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14811", "title": "SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models", "authors": ["Jiaji Zhang", "Ruichao Sun", "Hailiang Zhao", "Jiaju Wu", "Peng Chen", "Hao Li", "Xinkui Zhao", "Kingsum Chow", "Gang Xiong", "Lin Ye", "Shuiguang Deng"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14811v1", "summary": "Diffusion models have demonstrated exceptional generative capabilities but\nare computationally intensive, posing significant challenges for deployment in\nresource-constrained or latency-sensitive environments. Quantization offers an\neffective means to reduce model size and computational cost, with post-training\nquantization (PTQ) being particularly appealing due to its compatibility with\npre-trained models without requiring retraining or training data. However,\nexisting PTQ methods for diffusion models often rely on architecture-specific\nheuristics that limit their generalizability and hinder integration with\nindustrial deployment pipelines. To address these limitations, we propose\nSegQuant, a unified quantization framework that adaptively combines\ncomplementary techniques to enhance cross-model versatility. SegQuant consists\nof a segment-aware, graph-based quantization strategy (SegLinear) that captures\nstructural semantics and spatial heterogeneity, along with a dual-scale\nquantization scheme (DualScale) that preserves polarity-asymmetric activations,\nwhich is crucial for maintaining visual fidelity in generated outputs. SegQuant\nis broadly applicable beyond Transformer-based diffusion models, achieving\nstrong performance while ensuring seamless compatibility with mainstream\ndeployment tools.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14811v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.04422", "title": "Learning Software Bug Reports: A Systematic Literature Review", "authors": ["Guoming Long", "Jingzhi Gong", "Hui Fang", "Tao Chen"], "categories": ["cs.SE", "cs.AI", "D.2.7; I.2.7"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted by TOSEM", "url": "http://arxiv.org/abs/2507.04422v2", "summary": "The recent advancement of artificial intelligence, especially machine\nlearning (ML), has significantly impacted software engineering research,\nincluding bug report analysis. ML aims to automate the understanding,\nextraction, and correlation of information from bug reports. Despite its\ngrowing importance, there has been no comprehensive review in this area. In\nthis paper, we present a systematic literature review covering 1,825 papers,\nselecting 204 for detailed analysis. We derive seven key findings: 1) Extensive\nuse of CNN, LSTM, and $k$NN for bug report analysis, with advanced models like\nBERT underutilized due to their complexity. 2) Word2Vec and TF-IDF are popular\nfor feature representation, with a rise in deep learning approaches. 3) Stop\nword removal is the most common preprocessing, with structural methods rising\nafter 2020. 4) Eclipse and Mozilla are the most frequently evaluated software\nprojects. 5) Bug categorization is the most common task, followed by bug\nlocalization and severity prediction. 6) There is increasing attention on\nspecific bugs like non-functional and performance bugs. 7) Common evaluation\nmetrics are F1-score, Recall, Precision, and Accuracy, with $k$-fold\ncross-validation preferred for model evaluation. 8) Many studies lack robust\nstatistical tests. We also identify six promising future research directions to\nprovide useful insights for practitioners.", "comment": "Accepted by TOSEM", "pdf_url": "http://arxiv.org/pdf/2507.04422v2", "cate": "cs.SE", "date": "2025-07-06", "updated": "2025-07-20"}
{"id": "2205.08293", "title": "Concentration inequalities for log-concave sequences", "authors": ["Arnaud Marsiglietti", "James Melbourne"], "categories": ["math.PR", "cs.IT", "math.IT"], "primary_category": "Subjects:       Probability (math.PR)", "pdf_link": null, "comments": "Comments:      26 pages", "url": "http://arxiv.org/abs/2205.08293v3", "summary": "We investigate quantitative implications of the notion of log-concavity\nthrough a probabilistic interpretation. In particular, we derive concentration\ninequalities, moment and entropy bounds for random variables satisfying a\nprecise degree of log-concavity. Along the way, we recover, improve, and\nsimplify several results existing in the literature. Our approach is based on\nmajorization in the convex order.", "comment": "26 pages", "pdf_url": "http://arxiv.org/pdf/2205.08293v3", "cate": "math.PR", "date": "2022-05-17", "updated": "2025-07-20"}
{"id": "2507.14191", "title": "School Attendance Control System Based on RFID Technology with Raspberry Pi and Arduino: EDURFID", "authors": ["Cliver Oliver Turpo Benique"], "categories": ["eess.SP", "cs.CY"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      27 pages, 4 figures. Educational technology system for rural schools in Peru. Implements RFID-based attendance control using open-source hardware (Raspberry Pi, Arduino). System validation conducted at Túpac Amaru Secondary Educational Institution, Coasa, Puno", "url": "http://arxiv.org/abs/2507.14191v1", "summary": "This paper presents EDURFID, an automated school attendance control system\nbased on RFID technology designed for rural educational institutions in Peru.\nThe system integrates open-source hardware (Raspberry Pi 5, Arduino UNO R3)\nwith RC522 RFID modules operating at 13.56 MHz, implementing a web architecture\ndeveloped in Python Django. The system demonstrates 100% precision in RFID\nreadings with 0.03-second response time, achieving 94% cost reduction compared\nto commercial solutions. Validation at T\\'upac Amaru Secondary Educational\nInstitution showed successful automation of attendance processes, saving 50\ndaily minutes of administrative time while providing real-time reporting\ncapabilities.", "comment": "27 pages, 4 figures. Educational technology system for rural schools\n  in Peru. Implements RFID-based attendance control using open-source hardware\n  (Raspberry Pi, Arduino). System validation conducted at T\\'upac Amaru\n  Secondary Educational Institution, Coasa, Puno", "pdf_url": "http://arxiv.org/pdf/2507.14191v1", "cate": "eess.SP", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.15375", "title": "STITCH: Simultaneous Thinking and Talking with Chunked Reasoning for Spoken Language Models", "authors": ["Cheng-Han Chiang", "Xiaofei Wang", "Linjie Li", "Chung-Ching Lin", "Kevin Lin", "Shujie Liu", "Zhendong Wang", "Zhengyuan Yang", "Hung-yi Lee", "Lijuan Wang"], "categories": ["cs.CL", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Work in progress. Project page: this https URL", "url": "http://arxiv.org/abs/2507.15375v1", "summary": "Spoken Language Models (SLMs) are designed to take speech inputs and produce\nspoken responses. However, current SLMs lack the ability to perform an\ninternal, unspoken thinking process before responding. In contrast, humans\ntypically engage in complex mental reasoning internally, enabling them to\ncommunicate ideas clearly and concisely. Thus, integrating an unspoken thought\nprocess into SLMs is highly desirable. While naively generating a complete\nchain-of-thought (CoT) reasoning before starting to talk can enable thinking\nfor SLMs, this induces additional latency for the speech response, as the CoT\nreasoning can be arbitrarily long. To solve this issue, we propose Stitch, a\nnovel generation method that alternates between the generation of unspoken\nreasoning chunks and spoken response chunks. Since the audio duration of a\nchunk of spoken response is much longer than the time to generate the tokens in\na chunk of spoken response, we use the remaining free time to generate the\nunspoken reasoning tokens. When a chunk of audio is played to the user, the\nmodel continues to generate the next unspoken reasoning chunk, achieving\nsimultaneous thinking and talking. Remarkably, Stitch matches the latency of\nbaselines that cannot generate unspoken CoT by design while outperforming those\nbaselines by 15% on math reasoning datasets; Stitch also performs equally well\non non-reasoning datasets as those baseline models. Some animations and\ndemonstrations are on the project page: https://d223302.github.io/STITCH.", "comment": "Work in progress. Project page: https://d223302.github.io/STITCH/", "pdf_url": "http://arxiv.org/pdf/2507.15375v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14835", "title": "Differentially Private Synthetic Graphs Preserving Triangle-Motif Cuts", "authors": ["Pan Peng", "Hangyu Xu"], "categories": ["cs.DS", "cs.LG"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      COLT 2025", "url": "http://arxiv.org/abs/2507.14835v1", "summary": "We study the problem of releasing a differentially private (DP) synthetic\ngraph $G'$ that well approximates the triangle-motif sizes of all cuts of any\ngiven graph $G$, where a motif in general refers to a frequently occurring\nsubgraph within complex networks. Non-private versions of such graphs have\nfound applications in diverse fields such as graph clustering, graph\nsparsification, and social network analysis. Specifically, we present the first\n$(\\varepsilon,\\delta)$-DP mechanism that, given an input graph $G$ with $n$\nvertices, $m$ edges and local sensitivity of triangles $\\ell_{3}(G)$, generates\na synthetic graph $G'$ in polynomial time, approximating the triangle-motif\nsizes of all cuts $(S,V\\setminus S)$ of the input graph $G$ up to an additive\nerror of $\\tilde{O}(\\sqrt{m\\ell_{3}(G)}n/\\varepsilon^{3/2})$. Additionally, we\nprovide a lower bound of $\\Omega(\\sqrt{mn}\\ell_{3}(G)/\\varepsilon)$ on the\nadditive error for any DP algorithm that answers the triangle-motif size\nqueries of all $(S,T)$-cut of $G$. Finally, our algorithm generalizes to\nweighted graphs, and our lower bound extends to any $K_h$-motif cut for any\nconstant $h\\geq 2$.", "comment": "COLT 2025", "pdf_url": "http://arxiv.org/pdf/2507.14835v1", "cate": "cs.DS", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14841", "title": "Towards Geometric and Textural Consistency 3D Scene Generation via Single Image-guided Model Generation and Layout Optimization", "authors": ["Xiang Tang", "Ruotong Li", "Xiaopeng Fan"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      15 pages, 8 figures, Project page: this https URL", "url": "http://arxiv.org/abs/2507.14841v1", "summary": "In recent years, 3D generation has made great strides in both academia and\nindustry. However, generating 3D scenes from a single RGB image remains a\nsignificant challenge, as current approaches often struggle to ensure both\nobject generation quality and scene coherence in multi-object scenarios. To\novercome these limitations, we propose a novel three-stage framework for 3D\nscene generation with explicit geometric representations and high-quality\ntextural details via single image-guided model generation and spatial layout\noptimization. Our method begins with an image instance segmentation and\ninpainting phase, which recovers missing details of occluded objects in the\ninput images, thereby achieving complete generation of foreground 3D assets.\nSubsequently, our approach captures the spatial geometry of reference image by\nconstructing pseudo-stereo viewpoint for camera parameter estimation and scene\ndepth inference, while employing a model selection strategy to ensure optimal\nalignment between the 3D assets generated in the previous step and the input.\nFinally, through model parameterization and minimization of the Chamfer\ndistance between point clouds in 3D and 2D space, our approach optimizes layout\nparameters to produce an explicit 3D scene representation that maintains\nprecise alignment with input guidance image. Extensive experiments on\nmulti-object scene image sets have demonstrated that our approach not only\noutperforms state-of-the-art methods in terms of geometric accuracy and texture\nfidelity of individual generated 3D models, but also has significant advantages\nin scene layout synthesis.", "comment": "15 pages, 8 figures, Project page: https://xdlbw.github.io/sing3d/", "pdf_url": "http://arxiv.org/pdf/2507.14841v1", "cate": "cs.GR", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14301", "title": "LOVO: Efficient Complex Object Query in Large-Scale Video Datasets", "authors": ["Yuxin Liu", "Yuezhang Peng", "Hefeng Zhou", "Hongze Liu", "Xinyu Lu", "Jiong Lou", "Chentao Wu", "Wei Zhao", "Jie Li"], "categories": ["cs.IR", "cs.CV", "cs.DB"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      @inproceedings{liu2025lovo,title={LOVO: Efficient Complex Object Query in Large-Scale Video Datasets},author={Liu, Yuxin and Peng, Yuezhang and Zhou, Hefeng and Liu, Hongze and Lu, Xinyu and Lou, Jiong and Wu, Chentao and Zhao, Wei and Li, Jie},booktitle={2025 IEEE 41st International Conference on Data Engineering (ICDE)},pages={1938--1951},year={2025},organization={IEEE Computer Society}}", "url": "http://arxiv.org/abs/2507.14301v1", "summary": "The widespread deployment of cameras has led to an exponential increase in\nvideo data, creating vast opportunities for applications such as traffic\nmanagement and crime surveillance. However, querying specific objects from\nlarge-scale video datasets presents challenges, including (1) processing\nmassive and continuously growing data volumes, (2) supporting complex query\nrequirements, and (3) ensuring low-latency execution. Existing video analysis\nmethods struggle with either limited adaptability to unseen object classes or\nsuffer from high query latency. In this paper, we present LOVO, a novel system\ndesigned to efficiently handle comp$\\underline{L}$ex $\\underline{O}$bject\nqueries in large-scale $\\underline{V}$ide$\\underline{O}$ datasets. Agnostic to\nuser queries, LOVO performs one-time feature extraction using pre-trained\nvisual encoders, generating compact visual embeddings for key frames to build\nan efficient index. These visual embeddings, along with associated bounding\nboxes, are organized in an inverted multi-index structure within a vector\ndatabase, which supports queries for any objects. During the query phase, LOVO\ntransforms object queries to query embeddings and conducts fast approximate\nnearest-neighbor searches on the visual embeddings. Finally, a cross-modal\nrerank is performed to refine the results by fusing visual features with\ndetailed textual features. Evaluation on real-world video datasets demonstrates\nthat LOVO outperforms existing methods in handling complex queries, with\nnear-optimal query accuracy and up to 85x lower search latency, while\nsignificantly reducing index construction costs. This system redefines the\nstate-of-the-art object query approaches in video analysis, setting a new\nbenchmark for complex object queries with a novel, scalable, and efficient\napproach that excels in dynamic environments.", "comment": "@inproceedings{liu2025lovo,title={LOVO: Efficient Complex Object\n  Query in Large-Scale Video Datasets},author={Liu, Yuxin and Peng, Yuezhang\n  and Zhou, Hefeng and Liu, Hongze and Lu, Xinyu and Lou, Jiong and Wu, Chentao\n  and Zhao, Wei and Li, Jie},booktitle={2025 IEEE 41st International Conference\n  on Data Engineering (ICDE)},pages={1938--1951},year={2025},organization={IEEE\n  Computer Society}}", "pdf_url": "http://arxiv.org/pdf/2507.14301v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2410.16411", "title": "The Duality of Generative AI and Reinforcement Learning in Robotics: A Review", "authors": ["Angelo Moroncelli", "Vishal Soni", "Marco Forgione", "Dario Piga", "Blerina Spahiu", "Loris Roveda"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Submitted for publication to Information Fusion", "url": "http://arxiv.org/abs/2410.16411v2", "summary": "Recently, generative AI and reinforcement learning (RL) have been redefining\nwhat is possible for AI agents that take information flows as input and produce\nintelligent behavior. As a result, we are seeing similar advancements in\nembodied AI and robotics for control policy generation. Our review paper\nexamines the integration of generative AI models with RL to advance robotics.\nOur primary focus is on the duality between generative AI and RL for robotics\ndownstream tasks. Specifically, we investigate: (1) The role of prominent\ngenerative AI tools as modular priors for multi-modal input fusion in RL tasks.\n(2) How RL can train, fine-tune and distill generative models for policy\ngeneration, such as VLA models, similarly to RL applications in large language\nmodels. We then propose a new taxonomy based on a considerable amount of\nselected papers.\n  Lastly, we identify open challenges accounting for model scalability,\nadaptation and grounding, giving recommendations and insights on future\nresearch directions. We reflect on which generative AI models best fit the RL\ntasks and why. On the other side, we reflect on important issues inherent to\nRL-enhanced generative policies, such as safety concerns and failure modes, and\nwhat are the limitations of current methods. A curated collection of relevant\nresearch papers is maintained on our GitHub repository, serving as a resource\nfor ongoing research and development in this field:\nhttps://github.com/clmoro/Robotics-RL-FMs-Integration.", "comment": "Submitted for publication to Information Fusion", "pdf_url": "http://arxiv.org/pdf/2410.16411v2", "cate": "cs.RO", "date": "2024-10-21", "updated": "2025-07-18"}
{"id": "2507.14156", "title": "All-atom inverse protein folding through discrete flow matching", "authors": ["Kai Yi", "Kiarash Jamali", "Sjors H. W. Scheres"], "categories": ["q-bio.BM", "cs.AI"], "primary_category": "Subjects:       Biomolecules (q-bio.BM)", "pdf_link": null, "comments": "Comments:      ICML2025", "url": "http://arxiv.org/abs/2507.14156v1", "summary": "The recent breakthrough of AlphaFold3 in modeling complex biomolecular\ninteractions, including those between proteins and ligands, nucleotides, or\nmetal ions, creates new opportunities for protein design. In so-called inverse\nprotein folding, the objective is to find a sequence of amino acids that adopts\na target protein structure. Many inverse folding methods struggle to predict\nsequences for complexes that contain non-protein components, and perform poorly\nwith complexes that adopt multiple structural states. To address these\nchallenges, we present ADFLIP (All-atom Discrete FLow matching Inverse Protein\nfolding), a generative model based on discrete flow-matching for designing\nprotein sequences conditioned on all-atom structural contexts. ADFLIP\nprogressively incorporates predicted amino acid side chains as structural\ncontext during sequence generation and enables the design of dynamic protein\ncomplexes through ensemble sampling across multiple structural states.\nFurthermore, ADFLIP implements training-free classifier guidance sampling,\nwhich allows the incorporation of arbitrary pre-trained models to optimise the\ndesigned sequence for desired protein properties. We evaluated the performance\nof ADFLIP on protein complexes with small-molecule ligands, nucleotides, or\nmetal ions, including dynamic complexes for which structure ensembles were\ndetermined by nuclear magnetic resonance (NMR). Our model achieves\nstate-of-the-art performance in single-structure and multi-structure inverse\nfolding tasks, demonstrating excellent potential for all-atom protein design.\nThe code is available at https://github.com/ykiiiiii/ADFLIP.", "comment": "ICML2025", "pdf_url": "http://arxiv.org/pdf/2507.14156v1", "cate": "q-bio.BM", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.14777", "title": "Rethinking Memorization Measures and their Implications in Large Language Models", "authors": ["Bishwamittra Ghosh", "Soumi Das", "Qinyuan Wu", "Mohammad Aflah Khan", "Krishna P. Gummadi", "Evimaria Terzi", "Deepak Garg"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2507.14777v1", "summary": "Concerned with privacy threats, memorization in LLMs is often seen as\nundesirable, specifically for learning. In this paper, we study whether\nmemorization can be avoided when optimally learning a language, and whether the\nprivacy threat posed by memorization is exaggerated or not. To this end, we\nre-examine existing privacy-focused measures of memorization, namely\nrecollection-based and counterfactual memorization, along with a newly proposed\ncontextual memorization.\n  Relating memorization to local over-fitting during learning, contextual\nmemorization aims to disentangle memorization from the contextual learning\nability of LLMs. Informally, a string is contextually memorized if its\nrecollection due to training exceeds the optimal contextual recollection, a\nlearned threshold denoting the best contextual learning without training.\nConceptually, contextual recollection avoids the fallacy of recollection-based\nmemorization, where any form of high recollection is a sign of memorization.\nTheoretically, contextual memorization relates to counterfactual memorization,\nbut imposes stronger conditions. Memorization measures differ in outcomes and\ninformation requirements.\n  Experimenting on 18 LLMs from 6 families and multiple formal languages of\ndifferent entropy, we show that (a) memorization measures disagree on\nmemorization order of varying frequent strings, (b) optimal learning of a\nlanguage cannot avoid partial memorization of training strings, and (c)\nimproved learning decreases contextual and counterfactual memorization but\nincreases recollection-based memorization. Finally, (d) we revisit existing\nreports of memorized strings by recollection that neither pose a privacy threat\nnor are contextually or counterfactually memorized.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2507.14777v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14823", "title": "FinChart-Bench: Benchmarking Financial Chart Comprehension in Vision-Language Models", "authors": ["Dong Shu", "Haoyang Yuan", "Yuchen Wang", "Yanguang Liu", "Huopu Zhang", "Haiyan Zhao", "Mengnan Du"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      20 Pages, 18 Figures", "url": "http://arxiv.org/abs/2507.14823v1", "summary": "Large vision-language models (LVLMs) have made significant progress in chart\nunderstanding. However, financial charts, characterized by complex temporal\nstructures and domain-specific terminology, remain notably underexplored. We\nintroduce FinChart-Bench, the first benchmark specifically focused on\nreal-world financial charts. FinChart-Bench comprises 1,200 financial chart\nimages collected from 2015 to 2024, each annotated with True/False (TF),\nMultiple Choice (MC), and Question Answering (QA) questions, totaling 7,016\nquestions. We conduct a comprehensive evaluation of 25 state-of-the-art LVLMs\non FinChart-Bench. Our evaluation reveals critical insights: (1) the\nperformance gap between open-source and closed-source models is narrowing, (2)\nperformance degradation occurs in upgraded models within families, (3) many\nmodels struggle with instruction following, (4) both advanced models show\nsignificant limitations in spatial reasoning abilities, and (5) current LVLMs\nare not reliable enough to serve as automated evaluators. These findings\nhighlight important limitations in current LVLM capabilities for financial\nchart understanding. The FinChart-Bench dataset is available at\nhttps://huggingface.co/datasets/Tizzzzy/FinChart-Bench.", "comment": "20 Pages, 18 Figures", "pdf_url": "http://arxiv.org/pdf/2507.14823v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.09039", "title": "Towards Extracting Software Requirements from App Reviews using Seq2seq Framework", "authors": ["Aakash Sorathiya", "Gouri Ginde"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09039v2", "summary": "Mobile app reviews are a large-scale data source for software improvements. A\nkey task in this context is effectively extracting requirements from app\nreviews to analyze the users' needs and support the software's evolution.\nRecent studies show that existing methods fail at this task since app reviews\nusually contain informal language, grammatical and spelling errors, and a large\namount of irrelevant information that might not have direct practical value for\ndevelopers. To address this, we propose a novel reformulation of requirements\nextraction as a Named Entity Recognition (NER) task based on the\nsequence-to-sequence (Seq2seq) generation approach. With this aim, we propose a\nSeq2seq framework, incorporating a BiLSTM encoder and an LSTM decoder, enhanced\nwith a self-attention mechanism, GloVe embeddings, and a CRF model. We\nevaluated our framework on two datasets: a manually annotated set of 1,000\nreviews (Dataset 1) and a crowdsourced set of 23,816 reviews (Dataset 2). The\nquantitative evaluation of our framework showed that it outperformed existing\nstate-of-the-art methods with an F1 score of 0.96 on Dataset 2, and achieved\ncomparable performance on Dataset 1 with an F1 score of 0.47.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09039v2", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-20"}
{"id": "2302.08879", "title": "Doubly transitive equiangular tight frames that contain regular simplices", "authors": ["Matthew Fickus", "Evan C. Lake"], "categories": ["math.FA", "cs.IT", "math.CO", "math.IT", "42C15"], "primary_category": "Subjects:       Functional Analysis (math.FA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2302.08879v2", "summary": "An equiangular tight frame (ETF) is a finite sequence of equal norm vectors\nin a Hilbert space that achieves equality in the Welch bound, and so has\nminimal coherence. The binder of an ETF is the set of all subsets of its\nindices whose corresponding vectors form a regular simplex. An ETF achieves\nequality in Donoho and Elad's spark bound if and only if its binder is\nnonempty. When this occurs, its binder is the set of all linearly dependent\nsubsets of it of minimal size. Moreover, if members of the binder form a\nbalanced incomplete block design (BIBD) then its incidence matrix can be phased\nto produce a sparse representation of its dual (Naimark complement). A few\ninfinite families of ETFs are known to have this remarkable property. In this\npaper, we relate this property to the recently introduced concept of a doubly\ntransitive equiangular tight frame (DTETF), namely an ETF for which the natural\naction of its symmetry group is doubly transitive. In particular, we show that\nthe binder of any DTETF is either empty or forms a BIBD, and moreover that when\nthe latter occurs, any member of the binder of its dual is an oval of this\nBIBD. We then apply this general theory to certain known infinite families of\nDTETFs. Specifically, any symplectic form on a finite vector space yields a\nDTETF, and we compute the binder of it and its dual, showing that the former is\nempty except in a single notable case, and that the latter consists of affine\nLagrangian subspaces. This unifies and generalizes several results from the\nexisting literature. We then consider the binders of four infinite families of\nDTETFs that arise from quadratic forms over the field of two elements, showing\nthat two of these are empty except in a finite number of cases, whereas the\nother two form BIBDs that relate to each other, and to Lagrangian subspaces, in\nnonobvious ways.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2302.08879v2", "cate": "math.FA", "date": "2023-02-17", "updated": "2025-07-21"}
{"id": "2507.14194", "title": "Boosted Enhanced Quantile Regression Neural Networks with Spatiotemporal Permutation Entropy for Complex System Prognostics", "authors": ["David J Poland"], "categories": ["eess.SP", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Preliminary version of a predictive maintenance framework using spiking neural networks and entropy-based analysis. To be expanded in future publications with hardware implementations and real-time drift detection modules. arXiv admin note: substantial text overlap with arXiv:2501.05087", "url": "http://arxiv.org/abs/2507.14194v1", "summary": "This paper presents a novel framework for pattern prediction and system\nprognostics centered on Spatiotemporal Permutation Entropy analysis integrated\nwith Boosted Enhanced Quantile Regression Neural Networks (BEQRNNs). We address\nthe challenge of understanding complex dynamical patterns in multidimensional\nsystems through an approach that combines entropy-based complexity measures\nwith advanced neural architectures. The system leverages dual computational\nstages: first implementing spatiotemporal entropy extraction optimized for\nmultiscale temporal and spatial data streams, followed by an integrated BEQRNN\nlayer that enables probabilistic pattern prediction with uncertainty\nquantification. This architecture achieves 81.17% accuracy in spatiotemporal\npattern classification with prediction horizons up to 200 time steps and\nmaintains robust performance across diverse regimes. Field testing across\nchaotic attractors, reaction-diffusion systems, and industrial datasets shows a\n79% increase in critical transition detection accuracy and 81.22% improvement\nin long-term prediction reliability. The framework's effectiveness in\nprocessing complex, multimodal entropy features demonstrates significant\npotential for real-time prognostic applications.", "comment": "Preliminary version of a predictive maintenance framework using\n  spiking neural networks and entropy-based analysis. To be expanded in future\n  publications with hardware implementations and real-time drift detection\n  modules. arXiv admin note: substantial text overlap with arXiv:2501.05087", "pdf_url": "http://arxiv.org/pdf/2507.14194v1", "cate": "eess.SP", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.15396", "title": "Neuro-MSBG: An End-to-End Neural Model for Hearing Loss Simulation", "authors": ["Hui-Guan Yuan", "Ryandhimas E. Zezario", "Shafique Ahmed", "Hsin-Min Wang", "Kai-Lung Hua", "Yu Tsao"], "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15396v1", "summary": "Hearing loss simulation models are essential for hearing aid deployment.\nHowever, existing models have high computational complexity and latency, which\nlimits real-time applications and lack direct integration with speech\nprocessing systems. To address these issues, we propose Neuro-MSBG, a\nlightweight end-to-end model with a personalized audiogram encoder for\neffective time-frequency modeling. Experiments show that Neuro-MSBG supports\nparallel inference and retains the intelligibility and perceptual quality of\nthe original MSBG, with a Spearman's rank correlation coefficient (SRCC) of\n0.9247 for Short-Time Objective Intelligibility (STOI) and 0.8671 for\nPerceptual Evaluation of Speech Quality (PESQ). Neuro-MSBG reduces simulation\nruntime by a factor of 46 (from 0.970 seconds to 0.021 seconds for a 1 second\ninput), further demonstrating its efficiency and practicality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15396v1", "cate": "cs.SD", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15282", "title": "Predict, Reposition, and Allocate: A Greedy and Flow-Based Architecture for Sustainable Urban Food Delivery", "authors": ["Aqsa Ashraf Makhdomi", "Iqra Altaf Gillani"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15282v1", "summary": "The rapid proliferation of food delivery platforms has reshaped urban\nmobility but has also contributed significantly to environmental degradation\nthrough increased greenhouse gas emissions. Existing optimization mechanisms\nproduce sub-optimal outcomes as they do not consider environmental\nsustainability their optimization objective. This study proposes a novel\neco-friendly food delivery optimization framework that integrates demand\nprediction, delivery person routing, and order allocation to minimize\nenvironmental impact while maintaining service efficiency. Since recommending\nroutes is NP-Hard, the proposed approach utilizes the submodular and monotone\nproperties of the objective function and designs an efficient greedy\noptimization algorithm. Thereafter, it formulates order allocation problem as a\nnetwork flow optimization model, which, to the best of our knowledge, has not\nbeen explored in the context of food delivery. A three-layered network\narchitecture is designed to match orders with delivery personnel based on\ncapacity constraints and spatial demand. Through this framework, the proposed\napproach reduces the vehicle count, and creates a sustainable food delivery\necosystem.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15282v1", "cate": "cs.DS", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14920", "title": "Time Series Information Visualization -- A Review of Approaches and Tools", "authors": ["Evandro S. Ortigossa", "Fábio F. Dias", "Diego C. Nascimento", "Luis Gustavo Nonato"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      Preprint. Under review", "url": "http://arxiv.org/abs/2507.14920v1", "summary": "Time series data are prevalent across various domains and often encompass\nlarge datasets containing multiple time-dependent features in each sample.\nExploring time-varying data is critical for data science practitioners aiming\nto understand dynamic behaviors and discover periodic patterns and trends.\nHowever, the analysis of such data often requires sophisticated procedures and\ntools. Information visualization is a communication channel that leverages\nhuman perceptual abilities to transform abstract data into visual\nrepresentations. Visualization techniques have been successfully applied in the\ncontext of time series to enhance interpretability by graphically representing\nthe temporal evolution of data. The challenge for information visualization\ndevelopers lies in integrating a wide range of analytical tools into rich\nvisualization systems that can summarize complex datasets while clearly\ndescribing the impacts of the temporal component. Such systems enable data\nscientists to turn raw data into understandable and potentially useful\nknowledge. This review examines techniques and approaches designed for handling\ntime series data, guiding users through knowledge discovery processes based on\nvisual analysis. We also provide readers with theoretical insights and design\nguidelines for considering when developing comprehensive information\nvisualization approaches for time series, with a particular focus on time\nseries with multiple features. As a result, we highlight the challenges and\nfuture research directions to address open questions in the visualization of\ntime-dependent data.", "comment": "Preprint. Under review", "pdf_url": "http://arxiv.org/pdf/2507.14920v1", "cate": "cs.GR", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14352", "title": "A Reproducibility Study of Product-side Fairness in Bundle Recommendation", "authors": ["Huy-Son Nguyen", "Yuanna Liu", "Masoud Mansoury", "Mohammad Alian Nejadi", "Alan Hanjalic", "Maarten de Rijke"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14352v1", "summary": "Recommender systems are known to exhibit fairness issues, particularly on the\nproduct side, where products and their associated suppliers receive unequal\nexposure in recommended results. While this problem has been widely studied in\ntraditional recommendation settings, its implications for bundle recommendation\n(BR) remain largely unexplored. This emerging task introduces additional\ncomplexity: recommendations are generated at the bundle level, yet user\nsatisfaction and product (or supplier) exposure depend on both the bundle and\nthe individual items it contains. Existing fairness frameworks and metrics\ndesigned for traditional recommender systems may not directly translate to this\nmulti-layered setting. In this paper, we conduct a comprehensive\nreproducibility study of product-side fairness in BR across three real-world\ndatasets using four state-of-the-art BR methods. We analyze exposure\ndisparities at both the bundle and item levels using multiple fairness metrics,\nuncovering important patterns. Our results show that exposure patterns differ\nnotably between bundles and items, revealing the need for fairness\ninterventions that go beyond bundle-level assumptions. We also find that\nfairness assessments vary considerably depending on the metric used,\nreinforcing the need for multi-faceted evaluation. Furthermore, user behavior\nplays a critical role: when users interact more frequently with bundles than\nwith individual items, BR systems tend to yield fairer exposure distributions\nacross both levels. Overall, our findings offer actionable insights for\nbuilding fairer bundle recommender systems and establish a vital foundation for\nfuture research in this emerging domain.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14352v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2412.18347", "title": "The Constitutional Filter: Bayesian Estimation of Compliant Agents", "authors": ["Simon Kohaut", "Felix Divo", "Benedict Flade", "Devendra Singh Dhami", "Julian Eggert", "Kristian Kersting"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.18347v3", "summary": "Predicting agents impacted by legal policies, physical limitations, and\noperational preferences is inherently difficult. In recent years,\nneuro-symbolic methods have emerged, integrating machine learning and symbolic\nreasoning models into end-to-end learnable systems. Hereby, a promising avenue\nfor expressing high-level constraints over multi-modal input data in robotics\nhas opened up. This work introduces an approach for Bayesian estimation of\nagents expected to comply with a human-interpretable neuro-symbolic model we\ncall its Constitution. Hence, we present the Constitutional Filter (CoFi),\nleading to improved tracking of agents by leveraging expert knowledge,\nincorporating deep learning architectures, and accounting for environmental\nuncertainties. CoFi extends the general, recursive Bayesian estimation setting,\nensuring compatibility with a vast landscape of established techniques such as\nParticle Filters. To underpin the advantages of CoFi, we evaluate its\nperformance on real-world marine traffic data. Beyond improved performance, we\nshow how CoFi can learn to trust and adapt to the level of compliance of an\nagent, recovering baseline performance even if the assumed Constitution clashes\nwith reality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.18347v3", "cate": "cs.RO", "date": "2024-12-24", "updated": "2025-07-21"}
{"id": "2507.14189", "title": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base", "authors": ["Song Mao", "Lejun Cheng", "Pinlong Cai", "Guohang Yan", "Ding Wang", "Botian Shi"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      work in process", "url": "http://arxiv.org/abs/2507.14189v1", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious applications. However, their use as writing assistants in specialized\ndomains like finance, medicine, and law is often hampered by a lack of deep\ndomain-specific knowledge and a tendency to hallucinate. Existing solutions,\nsuch as Retrieval-Augmented Generation (RAG), can suffer from inconsistency\nacross multiple retrieval steps, while online search-based methods often\ndegrade quality due to unreliable web content. To address these challenges, we\nintroduce DeepWriter, a customizable, multimodal, long-form writing assistant\nthat operates on a curated, offline knowledge base. DeepWriter leverages a\nnovel pipeline that involves task decomposition, outline generation, multimodal\nretrieval, and section-by-section composition with reflection. By deeply mining\ninformation from a structured corpus and incorporating both textual and visual\nelements, DeepWriter generates coherent, factually grounded, and\nprofessional-grade documents. We also propose a hierarchical knowledge\nrepresentation to enhance retrieval efficiency and accuracy. Our experiments on\nfinancial report generation demonstrate that DeepWriter produces high-quality,\nverifiable articles that surpasses existing baselines in factual accuracy and\ngenerated content quality.", "comment": "work in process", "pdf_url": "http://arxiv.org/pdf/2507.14189v1", "cate": "cs.CL", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.14783", "title": "Omni-Think: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards", "authors": ["Derek Li", "Jiaming Zhou", "Amirreza Kazemi", "Qianyi Sun", "Abbas Ghaddar", "Mohammad Ali Alomrani", "Liheng Ma", "Yu Luo", "Dong Li", "Feng Wen", "Jianye Hao", "Mark Coates", "Yingxue Zhang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14783v1", "summary": "The advancement of general-purpose artificial intelligence relies on large\nlanguage models (LLMs) that excel across a wide range of tasks, from structured\nreasoning to creative generation. However, post-training methods like\nSupervised Fine-Tuning (SFT) often struggle with generalization, favoring\nmemorization over transferable learning. In this work, we introduce Omni-Think,\na unified reinforcement learning (RL) framework that enhances LLM performance\nacross diverse tasks by combining rule-based verifiable rewards with generative\npreference signals via LLM-as-a-Judge evaluations. Our approach enables\nconsistent optimization across task types and scales RL-based training to\nsubjective domains. We further investigate training strategies, demonstrating\nthat a curriculum-based progression that orders tasks from structured to\nopen-ended improves performance and reduces forgetting. Experimental results\nacross four domains reveal that curriculum learning improves performance by\n5.2\\% over joint training and 9.1\\% over model merging. These results highlight\nthe importance of task-aware sampling and hybrid supervision in scaling\nRL-based post-training for general-purpose LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14783v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14826", "title": "PHATNet: A Physics-guided Haze Transfer Network for Domain-adaptive Real-world Image Dehazing", "authors": ["Fu-Jen Tsai", "Yan-Tsung Peng", "Yen-Yu Lin", "Chia-Wen Lin"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.14826v1", "summary": "Image dehazing aims to remove unwanted hazy artifacts in images. Although\nprevious research has collected paired real-world hazy and haze-free images to\nimprove dehazing models' performance in real-world scenarios, these models\noften experience significant performance drops when handling unseen real-world\nhazy images due to limited training data. This issue motivates us to develop a\nflexible domain adaptation method to enhance dehazing performance during\ntesting. Observing that predicting haze patterns is generally easier than\nrecovering clean content, we propose the Physics-guided Haze Transfer Network\n(PHATNet) which transfers haze patterns from unseen target domains to\nsource-domain haze-free images, creating domain-specific fine-tuning sets to\nupdate dehazing models for effective domain adaptation. Additionally, we\nintroduce a Haze-Transfer-Consistency loss and a Content-Leakage Loss to\nenhance PHATNet's disentanglement ability. Experimental results demonstrate\nthat PHATNet significantly boosts state-of-the-art dehazing models on benchmark\nreal-world image dehazing datasets.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.14826v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.09049", "title": "CMER: A Context-Aware Approach for Mining Ethical Concern-related App Reviews", "authors": ["Aakash Sorathiya", "Gouri Ginde"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      arXiv admin note: substantial text overlap with arXiv:2411.07398", "url": "http://arxiv.org/abs/2507.09049v2", "summary": "With the increasing proliferation of mobile applications in our daily lives,\nthe concerns surrounding ethics have surged significantly. Users communicate\ntheir feedback in app reviews, frequently emphasizing ethical concerns, such as\nprivacy and security. Incorporating these reviews has proved to be useful for\nmany areas of software engineering (e.g., requirement engineering, testing,\netc.). However, app reviews related to ethical concerns generally use\ndomain-specific language and are typically overshadowed by more generic\ncategories of user feedback, such as app reliability and usability. Thus,\nmaking automated extraction a challenging and time-consuming effort.\n  This study proposes CMER (A \\underline{C}ontext-Aware Approach for\n\\underline{M}ining \\underline{E}thical Concern-related App\n\\underline{R}eviews), a novel approach that combines Natural Language Inference\n(NLI) and a decoder-only (LLaMA-like) Large Language Model (LLM) to extract\nethical concern-related app reviews at scale. In CMER, NLI provides\ndomain-specific context awareness by using domain-specific hypotheses, and the\nLlama-like LLM eliminates the need for labeled data in the classification task.\nWe evaluated the validity of CMER by mining privacy and security-related\nreviews (PSRs) from the dataset of more than 382K app reviews of mobile\ninvestment apps. First, we evaluated four NLI models and compared the results\nof domain-specific hypotheses with generic hypotheses. Next, we evaluated three\nLLMs for the classification task. Finally, we combined the best NLI and LLM\nmodels (CMER) and extracted 2,178 additional PSRs overlooked by the previous\nstudy using a keyword-based approach, thus demonstrating the effectiveness of\nCMER. These reviews can be further refined into actionable requirement\nartifacts.", "comment": "arXiv admin note: substantial text overlap with arXiv:2411.07398", "pdf_url": "http://arxiv.org/pdf/2507.09049v2", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-20"}
{"id": "2307.14474", "title": "Restrictions on Physical Stochastic Reservoir Computers", "authors": ["Anthony M. Polloreno"], "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      12 pages, 1 figure", "url": "http://arxiv.org/abs/2307.14474v5", "summary": "Reservoir computation is a recurrent framework for learning and predicting\ntime series data, that benefits from extremely simple training and\ninterpretability, often as the the dynamics of a physical system. In this\npaper, we will study the impact of noise on the learning capabilities of analog\nreservoir computers. Recent work on reservoir computation has shown that the\ninformation processing capacity (IPC) is a useful metric for quantifying the\ndegradation of the performance due to noise. We further this analysis and\ndemonstrate that this degradation of the IPC limits the possible features that\ncan be meaningfully constructed in an analog reservoir computing setting. We\nborrow a result from quantum complexity theory that relates the circuit model\nof computation to a continuous time model, and demonstrate an exponential\nreduction in the accessible volume of reservoir configurations. We conclude by\nrelating this degradation in the IPC to the fat-shattering dimension of a\nfamily of functions describing the reservoir dynamics, which allows us to\nexpress our result in terms of a classification task. We conclude that any\nphysical, analog reservoir computer that is exposed to noise can only be used\nto perform a polynomial amount of learning, despite the exponentially large\nlatent space, even with an exponential amount of post-processing.", "comment": "12 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2307.14474v5", "cate": "cs.LG", "date": "2023-07-26", "updated": "2025-07-20"}
{"id": "2507.14195", "title": "UWB Radar-based Heart Rate Monitoring: A Transfer Learning Approach", "authors": ["Elzbieta Gruzewska", "Pooja Rao", "Sebastien Baur", "Matthew Baugh", "Mathias M. J. Bellaiche", "Sharanya Srinivas", "Octavio Ponce", "Matthew Thompson", "Pramod Rudrapatna", "Michael A. Sanchez", "Lawrence Z. Cai", "Timothy JA Chico", "Robert F. Storey", "Emily Maz", "Umesh Telang", "Shravya Shetty", "Mayank Daswani"], "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      31 pages, 11 tables, 9 figures, 14 supplementary tables, 4 supplementary figures", "url": "http://arxiv.org/abs/2507.14195v1", "summary": "Radar technology presents untapped potential for continuous, contactless, and\npassive heart rate monitoring via consumer electronics like mobile phones.\nHowever the variety of available radar systems and lack of standardization\nmeans that a large new paired dataset collection is required for each radar\nsystem. This study demonstrates transfer learning between frequency-modulated\ncontinuous wave (FMCW) and impulse-radio ultra-wideband (IR-UWB) radar systems,\nboth increasingly integrated into consumer devices. FMCW radar utilizes a\ncontinuous chirp, while IR-UWB radar employs short pulses. Our mm-wave FMCW\nradar operated at 60 GHz with a 5.5 GHz bandwidth (2.7 cm resolution, 3\nreceiving antennas [Rx]), and our IR-UWB radar at 8 GHz with a 500 MHz\nbandwidth (30 cm resolution, 2 Rx). Using a novel 2D+1D ResNet architecture we\nachieved a mean absolute error (MAE) of 0.85 bpm and a mean absolute percentage\nerror (MAPE) of 1.42% for heart rate monitoring with FMCW radar (N=119\nparticipants, an average of 8 hours per participant). This model maintained\nperformance (under 5 MAE/10% MAPE) across various body positions and heart rate\nranges, with a 98.9% recall. We then fine-tuned a variant of this model,\ntrained on single-antenna and single-range bin FMCW data, using a small (N=376,\navg 6 minutes per participant) IR-UWB dataset. This transfer learning approach\nyielded a model with MAE 4.1 bpm and MAPE 6.3% (97.5% recall), a 25% MAE\nreduction over the IR-UWB baseline. This demonstration of transfer learning\nbetween radar systems for heart rate monitoring has the potential to accelerate\nits introduction into existing consumer devices.", "comment": "31 pages, 11 tables, 9 figures, 14 supplementary tables, 4\n  supplementary figures", "pdf_url": "http://arxiv.org/pdf/2507.14195v1", "cate": "eess.SP", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.15523", "title": "An Investigation of Test-time Adaptation for Audio Classification under Background Noise", "authors": ["Weichuang Shao", "Iman Yi Liao", "Tomas Henrique Bode Maul", "Tissa Chandesa"], "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15523v1", "summary": "Domain shift is a prominent problem in Deep Learning, causing a model\npre-trained on a source dataset to suffer significant performance degradation\non test datasets. This research aims to address the issue of audio\nclassification under domain shift caused by background noise using Test-Time\nAdaptation (TTA), a technique that adapts a pre-trained model during testing\nusing only unlabelled test data before making predictions. We adopt two common\nTTA methods, TTT and TENT, and a state-of-the-art method CoNMix, and\ninvestigate their respective performance on two popular audio classification\ndatasets, AudioMNIST (AM) and SpeechCommands V1 (SC), against different types\nof background noise and noise severity levels. The experimental results reveal\nthat our proposed modified version of CoNMix produced the highest\nclassification accuracy under domain shift (5.31% error rate under 10 dB\nexercise bike background noise and 12.75% error rate under 3 dB running tap\nbackground noise for AM) compared to TTT and TENT. The literature search\nprovided no evidence of similar works, thereby motivating the work reported\nhere as the first study to leverage TTA techniques for audio classification\nunder domain shift.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15523v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15319", "title": "Language Generation in the Limit: Noise, Loss, and Feedback", "authors": ["Yannan Bai", "Debmalya Panigrahi", "Ian Zhang"], "categories": ["cs.DS", "cs.LG"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15319v1", "summary": "Kleinberg and Mullainathan (2024) recently proposed a formal framework called\nlanguage generation in the limit and showed that given a sequence of example\nstrings from an unknown target language drawn from any countable collection, an\nalgorithm can correctly generate unseen strings from the target language within\nfinite time. This notion was further refined by Li, Raman, and Tewari (2024),\nwho defined stricter categories of non-uniform and uniform generation. They\nshowed that a finite union of uniformly generatable collections is generatable\nin the limit, and asked if the same is true for non-uniform generation.\n  We begin by resolving the question in the negative: we give a uniformly\ngeneratable collection and a non-uniformly generatable collection whose union\nis not generatable in the limit. We then use facets of this construction to\nfurther our understanding of several variants of language generation. The first\ntwo, generation with noise and without samples, were introduced by Raman and\nRaman (2025) and Li, Raman, and Tewari (2024) respectively. We show the\nequivalence of these models for uniform and non-uniform generation, and provide\na characterization of non-uniform noisy generation. The former paper asked if\nthere is any separation between noisy and non-noisy generation in the limit --\nwe show that such a separation exists even with a single noisy string. Finally,\nwe study the framework of generation with feedback, introduced by Charikar and\nPabbaraju (2025), where the algorithm is strengthened by allowing it to ask\nmembership queries. We show finite queries add no power, but infinite queries\nyield a strictly more powerful model.\n  In summary, the results in this paper resolve the union-closedness of\nlanguage generation in the limit, and leverage those techniques (and others) to\ngive precise characterizations for natural variants that incorporate noise,\nloss, and feedback.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15319v1", "cate": "cs.DS", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15186", "title": "Model Simplification through refinement", "authors": ["Dmitry Brodsky", "Benjamin Watson"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15186v1", "summary": "As modeling and visualization applications proliferate, there arises a need\nto simplify large polygonal models at interactive rates. Unfortunately existing\npolygon mesh simplification algorithms are not well suited for this task\nbecause they are either too slow (requiring the simplified model to be\npre-computed) or produce models that are too poor in quality. These\nshortcomings become particularly acute when models are extremely large. We\npresent an algorithm suitable for simplification of large models at interactive\nspeeds. The algorithm is fast and can guarantee displayable results within a\ngiven time limit. Results also have good quality. Inspired by splitting\nalgorithms from vector quantization literature, we simplify models in reverse,\nbeginning with an extremely coarse approximation and refining it.\nApproximations of surface curvature guide the simplification process.\nPreviously produced simplifications can be further refined by using them as\ninput to the algorithm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15186v1", "cate": "cs.GR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14361", "title": "RaMen: Multi-Strategy Multi-Modal Learning for Bundle Construction", "authors": ["Huy-Son Nguyen", "Quang-Huy Nguyen", "Duc-Hoang Pham", "Duc-Trong Le", "Hoang-Quynh Le", "Padipat Sitkrongwong", "Atsuhiro Takasu", "Masoud Mansoury"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14361v1", "summary": "Existing studies on bundle construction have relied merely on user feedback\nvia bipartite graphs or enhanced item representations using semantic\ninformation. These approaches fail to capture elaborate relations hidden in\nreal-world bundle structures, resulting in suboptimal bundle representations.\nTo overcome this limitation, we propose RaMen, a novel method that provides a\nholistic multi-strategy approach for bundle construction. RaMen utilizes both\nintrinsic (characteristics) and extrinsic (collaborative signals) information\nto model bundle structures through Explicit Strategy-aware Learning (ESL) and\nImplicit Strategy-aware Learning (ISL). ESL employs task-specific attention\nmechanisms to encode multi-modal data and direct collaborative relations\nbetween items, thereby explicitly capturing essential bundle features.\nMoreover, ISL computes hyperedge dependencies and hypergraph message passing to\nuncover shared latent intents among groups of items. Integrating diverse\nstrategies enables RaMen to learn more comprehensive and robust bundle\nrepresentations. Meanwhile, Multi-strategy Alignment & Discrimination module is\nemployed to facilitate knowledge transfer between learning strategies and\nensure discrimination between items/bundles. Extensive experiments demonstrate\nthe effectiveness of RaMen over state-of-the-art models on various domains,\njustifying valuable insights into complex item set problems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14361v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2501.02184", "title": "Model-Free and Real-Time Bioinspired Unicycle-Based Source Seeking: Differential Wheeled Robotic Experiments", "authors": ["Ahmed A. Elgohary", "Sameh A. Eisa", "Shivam Bajpai"], "categories": ["cs.RO", "math.OC"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.02184v3", "summary": "Many autonomous robots aimed at source-seeking are studied, and their\ncontrols designed, using unicycle modeling and formulation. This is true not\nonly for model-based controllers, but also for model-free, real-time control\nmethods such as extremum seeking control (ESC). In this paper, we propose a\nunicycle-based ESC design applicable to differential wheeled robots that: (1)\nis very simple design, based on one simple control-affine law, and without\nstate integrators; (2) attenuates oscillations known to persist in ESC designs\n(i.e., fully stop at the source); and (3) operates in a model-free, real-time\nsetting, tolerating environmental/sensor noise. We provide simulation and\nreal-world robotic experimental results for fixed and moving light source\nseeking by a differential wheeled robot using our proposed design. Results\nindicate clear advantages of our proposed design when compared to the\nliterature, including attenuation of undesired oscillations, improved\nconvergence speed, and better handling of noise.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.02184v3", "cate": "cs.RO", "date": "2025-01-04", "updated": "2025-07-21"}
{"id": "2507.14193", "title": "A Formal Model of the Economic Impacts of AI Openness Regulation", "authors": ["Tori Qiu", "Benjamin Laufer", "Jon Kleinberg", "Hoda Heidari"], "categories": ["cs.GT", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14193v1", "summary": "Regulatory frameworks, such as the EU AI Act, encourage openness of\ngeneral-purpose AI models by offering legal exemptions for \"open-source\"\nmodels. Despite this legislative attention on openness, the definition of\nopen-source foundation models remains ambiguous. This paper models the\nstrategic interactions among the creator of a general-purpose model (the\ngeneralist) and the entity that fine-tunes the general-purpose model to a\nspecialized domain or task (the specialist), in response to regulatory\nrequirements on model openness. We present a stylized model of the regulator's\nchoice of an open-source definition to evaluate which AI openness standards\nwill establish appropriate economic incentives for developers. Our results\ncharacterize market equilibria -- specifically, upstream model release\ndecisions and downstream fine-tuning efforts -- under various openness\nregulations and present a range of effective regulatory penalties and\nopen-source thresholds. Overall, we find the model's baseline performance\ndetermines when increasing the regulatory penalty vs. the open-source threshold\nwill significantly alter the generalist's release strategy. Our model provides\na theoretical foundation for AI governance decisions around openness and\nenables evaluation and refinement of practical open-source policies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14193v1", "cate": "cs.GT", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.14785", "title": "Exploring the In-Context Learning Capabilities of LLMs for Money Laundering Detection in Financial Graphs", "authors": ["Erfan Pirmorad"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14785v1", "summary": "The complexity and interconnectivity of entities involved in money laundering\ndemand investigative reasoning over graph-structured data. This paper explores\nthe use of large language models (LLMs) as reasoning engines over localized\nsubgraphs extracted from a financial knowledge graph. We propose a lightweight\npipeline that retrieves k-hop neighborhoods around entities of interest,\nserializes them into structured text, and prompts an LLM via few-shot\nin-context learning to assess suspiciousness and generate justifications. Using\nsynthetic anti-money laundering (AML) scenarios that reflect common laundering\nbehaviors, we show that LLMs can emulate analyst-style logic, highlight red\nflags, and provide coherent explanations. While this study is exploratory, it\nillustrates the potential of LLM-based graph reasoning in AML and lays\ngroundwork for explainable, language-driven financial crime analytics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14785v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14833", "title": "Paired Image Generation with Diffusion-Guided Diffusion Models", "authors": ["Haoxuan Zhang", "Wenju Cui", "Yuzhu Cao", "Tao Tan", "Jie Liu", "Yunsong Peng", "Jian Zheng"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14833v1", "summary": "The segmentation of mass lesions in digital breast tomosynthesis (DBT) images\nis very significant for the early screening of breast cancer. However, the\nhigh-density breast tissue often leads to high concealment of the mass lesions,\nwhich makes manual annotation difficult and time-consuming. As a result, there\nis a lack of annotated data for model training. Diffusion models are commonly\nused for data augmentation, but the existing methods face two challenges.\nFirst, due to the high concealment of lesions, it is difficult for the model to\nlearn the features of the lesion area. This leads to the low generation quality\nof the lesion areas, thus limiting the quality of the generated images. Second,\nexisting methods can only generate images and cannot generate corresponding\nannotations, which restricts the usability of the generated images in\nsupervised training. In this work, we propose a paired image generation method.\nThe method does not require external conditions and can achieve the generation\nof paired images by training an extra diffusion guider for the conditional\ndiffusion model. During the experimental phase, we generated paired DBT slices\nand mass lesion masks. Then, we incorporated them into the supervised training\nprocess of the mass lesion segmentation task. The experimental results show\nthat our method can improve the generation quality without external conditions.\nMoreover, it contributes to alleviating the shortage of annotated data, thus\nenhancing the performance of downstream tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14833v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.09051", "title": "SAGE: A Context-Aware Approach for Mining Privacy Requirements Relevant Reviews from Mental Health Apps", "authors": ["Aakash Sorathiya", "Gouri Ginde"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2507.09049", "url": "http://arxiv.org/abs/2507.09051v2", "summary": "Mental health (MH) apps often require sensitive user data to customize\nservices for mental wellness needs. However, such data collection practices in\nsome MH apps raise significant privacy concerns for users. These concerns are\noften mentioned in app reviews, but other feedback categories, such as\nreliability and usability, tend to take precedence. This poses a significant\nchallenge in automatically identifying privacy requirements-relevant reviews\n(privacy reviews) that can be utilized to extract privacy requirements and\naddress users' privacy concerns. Thus, this study introduces SAGE, a\ncontext-aware approach to automatically mining privacy reviews from MH apps\nusing Natural Language Inference (NLI) with MH domain-specific privacy\nhypotheses (provides domain-specific context awareness) and a GPT model\n(eliminates the need for fine-tuning). The quantitative evaluation of SAGE on a\ndataset of 204K app reviews achieved an F1 score of 0.85 without any\nfine-tuning, outperforming the fine-tuned baseline classifiers BERT and T5.\nFurthermore, SAGE extracted 748 privacy reviews previously overlooked by\nkeyword-based methods, demonstrating its effectiveness through qualitative\nevaluation. These reviews can later be refined into actionable privacy\nrequirement artifacts.", "comment": "arXiv admin note: text overlap with arXiv:2507.09049", "pdf_url": "http://arxiv.org/pdf/2507.09051v2", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-20"}
{"id": "2312.05911", "title": "A leave-one-out approach to approximate message passing", "authors": ["Zhigang Bao", "Qiyang Han", "Xiaocong Xu"], "categories": ["math.ST", "cs.IT", "math.IT", "math.PR", "stat.TH"], "primary_category": "Subjects:       Statistics Theory (math.ST)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2312.05911v3", "summary": "Approximate message passing (AMP) has emerged both as a popular class of\niterative algorithms and as a powerful analytic tool in a wide range of\nstatistical estimation problems and statistical physics models. A well\nestablished line of AMP theory proves Gaussian approximations for the empirical\ndistributions of the AMP iterate in the high dimensional limit, under the GOE\nrandom matrix model and its variants.\n  This paper provides a non-asymptotic, leave-one-out representation for the\nAMP iterate that holds under a broad class of Gaussian random matrix models\nwith general variance profiles. In contrast to the typical AMP theory that\ndescribes the empirical distributions of the AMP iterate via a low dimensional\nstate evolution, our leave-one-out representation yields an intrinsically high\ndimensional state evolution formula which provides non-asymptotic\ncharacterizations for the possibly heterogeneous, entrywise behavior of the AMP\niterate under the prescribed random matrix models.\n  To exemplify some distinct features of our AMP theory in applications, we\nanalyze, in the context of regularized linear estimation, the precise\nstochastic behavior of the Ridge estimator for independent and non-identically\ndistributed observations whose covariates exhibit general variance profiles. We\nfind that its finite-sample distribution is characterized via a weighted Ridge\nestimator in a heterogeneous Gaussian sequence model. Notably, in contrast to\nthe i.i.d. sampling scenario, the effective noise and regularization are now\nfull dimensional vectors determined via a high dimensional system of equations.\n  Our leave-one-out method of proof differs significantly from the widely\nadopted conditioning approach for rotational invariant ensembles, and relies\ninstead on an inductive method that utilizes almost solely integration-by-parts\nand concentration techniques.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2312.05911v3", "cate": "math.ST", "date": "2023-12-10", "updated": "2025-07-21"}
{"id": "2507.14196", "title": "Explainable Parallel CNN-LSTM Model for Differentiating Ventricular Tachycardia from Supraventricular Tachycardia with Aberrancy in 12-Lead ECGs", "authors": ["Zahra Teimouri-Jervekani", "Fahimeh Nasimi", "Mohammadreza Yazdchi", "Ghazal MogharehZadeh", "Javad Tezerji", "Farzan Niknejad Mazandarani", "Maryam Mohebbi"], "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14196v1", "summary": "Background and Objective: Differentiating wide complex tachycardia (WCT) is\nclinically critical yet challenging due to morphological similarities in\nelectrocardiogram (ECG) signals between life-threatening ventricular\ntachycardia (VT) and supraventricular tachycardia with aberrancy (SVT-A).\nMisdiagnosis carries fatal risks. We propose a computationally efficient deep\nlearning solution to improve diagnostic accuracy and provide model\ninterpretability for clinical deployment.\n  Methods: A novel lightweight parallel deep architecture is introduced. Each\npipeline processes individual ECG leads using two 1D-CNN blocks to extract\nlocal features. Feature maps are concatenated across leads, followed by LSTM\nlayers to capture temporal dependencies. Final classification employs fully\nconnected layers. Explainability is achieved via Shapley Additive Explanations\n(SHAP) for local/global interpretation. The model was evaluated on a 35-subject\nECG database using standard performance metrics.\n  Results: The model achieved $95.63\\%$ accuracy ($95\\%$ CI: $93.07-98.19\\%$),\nwith sensitivity=$95.10\\%$, specificity=$96.06\\%$, and F1-score=$95.12\\%$. It\noutperformed state-of-the-art methods in both accuracy and computational\nefficiency, requiring minimal CNN blocks per pipeline. SHAP analysis\ndemonstrated clinically interpretable feature contributions.\n  Conclusions: Our end-to-end framework delivers high-precision WCT\nclassification with minimal computational overhead. The integration of SHAP\nenhances clinical trust by elucidating decision logic, supporting rapid,\ninformed diagnosis. This approach shows significant promise for real-world ECG\nanalysis tools.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14196v1", "cate": "eess.SP", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.15558", "title": "Multichannel Keyword Spotting for Noisy Conditions", "authors": ["Dzmitry Saladukha", "Ivan Koriabkin", "Kanstantsin Artsiom", "Aliaksei Rak", "Nikita Ryzhikov"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted to Interspeech 2025", "url": "http://arxiv.org/abs/2507.15558v1", "summary": "This article presents a method for improving a keyword spotter (KWS)\nalgorithm in noisy environments. Although beamforming (BF) and adaptive noise\ncancellation (ANC) techniques are robust in some conditions, they may degrade\nthe performance of the activation system by distorting or suppressing useful\nsignals. The authors propose a neural network architecture that uses several\ninput channels and an attention mechanism that allows the network to determine\nthe most useful channel or their combination. The improved quality of the\nalgorithm was demonstrated on two datasets: from a laboratory with controlled\nconditions and from smart speakers in natural conditions. The proposed\nalgorithm was compared against several baselines in terms of the quality of\nnoise reduction metrics, KWS metrics, and computing resources in comparison\nwith existing solutions.", "comment": "Accepted to Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.15558v1", "cate": "cs.SD", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15417", "title": "1.64-Approximation for Chromatic Correlation Clustering via Chromatic Cluster LP", "authors": ["Dahoon Lee", "Chenglin Fan", "Euiwoong Lee"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15417v1", "summary": "Chromatic Correlation Clustering (CCC) generalizes Correlation Clustering by\nassigning multiple categorical relationships (colors) to edges and imposing\nchromatic constraints on the clusters. Unlike traditional Correlation\nClustering, which only deals with binary $(+/-)$ relationships, CCC captures\nricher relational structures. Despite its importance, improving the\napproximation for CCC has been difficult due to the limitations of standard LP\nrelaxations. We present a randomized $1.64$-approximation algorithm to the CCC\nproblem, significantly improving the previous factor of $2.15$. Our approach\nextends the cluster LP framework to the chromatic setting by introducing a\nchromatic cluster LP relaxation and an rounding algorithm that utilizes both a\ncluster-based and a greedy pivot-based strategy. The analysis bypasses the\nintegrality gap of $2$ for the CCC version of standard LP and highlights the\npotential of the cluster LP framework to address other variants of clustering\nproblems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15417v1", "cate": "cs.DS", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15399", "title": "Blended Point Cloud Diffusion for Localized Text-guided Shape Editing", "authors": ["Etai Sella", "Noam Atia", "Ron Mokady", "Hadar Averbuch-Elor"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025. Project Page: this https URL", "url": "http://arxiv.org/abs/2507.15399v1", "summary": "Natural language offers a highly intuitive interface for enabling localized\nfine-grained edits of 3D shapes. However, prior works face challenges in\npreserving global coherence while locally modifying the input 3D shape. In this\nwork, we introduce an inpainting-based framework for editing shapes represented\nas point clouds. Our approach leverages foundation 3D diffusion models for\nachieving localized shape edits, adding structural guidance in the form of a\npartial conditional shape, ensuring that other regions correctly preserve the\nshape's identity. Furthermore, to encourage identity preservation also within\nthe local edited region, we propose an inference-time coordinate blending\nalgorithm which balances reconstruction of the full shape with inpainting at a\nprogression of noise levels during the inference process. Our coordinate\nblending algorithm seamlessly blends the original shape with its edited\nversion, enabling a fine-grained editing of 3D shapes, all while circumventing\nthe need for computationally expensive and often inaccurate inversion.\nExtensive experiments show that our method outperforms alternative techniques\nacross a wide range of metrics that evaluate both fidelity to the original\nshape and also adherence to the textual description.", "comment": "Accepted to ICCV 2025. Project Page:\n  https://tau-vailab.github.io/BlendedPC/", "pdf_url": "http://arxiv.org/pdf/2507.15399v1", "cate": "cs.GR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14604", "title": "Understanding Matching Mechanisms in Cross-Encoders", "authors": ["Mathias Vast", "Basile Van Cooten", "Laure Soulier", "Benjamin Piwowarski"], "categories": ["cs.IR", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted at Workshop on Explainability in Information Retrieval at SIGIR 25 (WExIR25)", "url": "http://arxiv.org/abs/2507.14604v1", "summary": "Neural IR architectures, particularly cross-encoders, are highly effective\nmodels whose internal mechanisms are mostly unknown. Most works trying to\nexplain their behavior focused on high-level processes (e.g., what in the input\ninfluences the prediction, does the model adhere to known IR axioms) but fall\nshort of describing the matching process. Instead of Mechanistic\nInterpretability approaches which specifically aim at explaining the hidden\nmechanisms of neural models, we demonstrate that more straightforward methods\ncan already provide valuable insights. In this paper, we first focus on the\nattention process and extract causal insights highlighting the crucial roles of\nsome attention heads in this process. Second, we provide an interpretation of\nthe mechanism underlying matching detection.", "comment": "Accepted at Workshop on Explainability in Information Retrieval at\n  SIGIR 25 (WExIR25)", "pdf_url": "http://arxiv.org/pdf/2507.14604v1", "cate": "cs.IR", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14270", "title": "APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation", "authors": ["Ravin Kumar"], "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      10 pages, 2 figures, 1 table, and GitHub repository for the source code", "url": "http://arxiv.org/abs/2507.14270v1", "summary": "We propose the APTx Neuron, a novel, unified neural computation unit that\nintegrates non-linear activation and linear transformation into a single\ntrainable expression. The APTx Neuron is derived from the APTx activation\nfunction, thereby eliminating the need for separate activation layers and\nmaking the architecture both computationally efficient and elegant. The\nproposed neuron follows the functional form $y = \\sum_{i=1}^{n} ((\\alpha_i +\n\\tanh(\\beta_i x_i)) \\cdot \\gamma_i x_i) + \\delta$, where all parameters\n$\\alpha_i$, $\\beta_i$, $\\gamma_i$, and $\\delta$ are trainable. We validate our\nAPTx Neuron-based architecture on the MNIST dataset, achieving up to 96.69\\%\ntest accuracy in just 20 epochs using approximately 332K trainable parameters.\nThe results highlight the superior expressiveness and computational efficiency\nof the APTx Neuron compared to traditional neurons, pointing toward a new\nparadigm in unified neuron design and the architectures built upon it.", "comment": "10 pages, 2 figures, 1 table, and GitHub repository for the source\n  code", "pdf_url": "http://arxiv.org/pdf/2507.14270v1", "cate": "cs.NE", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2502.08033", "title": "Predictive Planner for Autonomous Driving with Consistency Models", "authors": ["Anjian Li", "Sangjae Bae", "David Isele", "Ryne Beeson", "Faizan M. Tariq"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at the 28th IEEE International Conference on Intelligent Transportation Systems (ITSC) 2025", "url": "http://arxiv.org/abs/2502.08033v3", "summary": "Trajectory prediction and planning are essential for autonomous vehicles to\nnavigate safely and efficiently in dynamic environments. Traditional approaches\noften treat them separately, limiting the ability for interactive planning.\nWhile recent diffusion-based generative models have shown promise in\nmulti-agent trajectory generation, their slow sampling is less suitable for\nhigh-frequency planning tasks. In this paper, we leverage the consistency model\nto build a predictive planner that samples from a joint distribution of ego and\nsurrounding agents, conditioned on the ego vehicle's navigational goal. Trained\non real-world human driving datasets, our consistency model generates\nhigher-quality trajectories with fewer sampling steps than standard diffusion\nmodels, making it more suitable for real-time deployment. To enforce multiple\nplanning constraints simultaneously on the ego trajectory, a novel online\nguided sampling approach inspired by the Alternating Direction Method of\nMultipliers (ADMM) is introduced. Evaluated on the Waymo Open Motion Dataset\n(WOMD), our method enables proactive behavior such as nudging and yielding, and\nalso demonstrates smoother, safer, and more efficient trajectories and\nsatisfaction of multiple constraints under a limited computational budget.", "comment": "Accepted at the 28th IEEE International Conference on Intelligent\n  Transportation Systems (ITSC) 2025", "pdf_url": "http://arxiv.org/pdf/2502.08033v3", "cate": "cs.RO", "date": "2025-02-12", "updated": "2025-07-21"}
{"id": "2507.14198", "title": "Retention analysis of edited knowledge after fine-tuning", "authors": ["Fufang Wen", "Shichang Zhang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14198v1", "summary": "Large language models (LLMs) store vast amounts of knowledge, which often\nrequires updates to correct factual errors, incorporate newly acquired\ninformation, or adapt model behavior. Model editing methods have emerged as\nefficient solutions for such updates, offering localized and precise knowledge\nmodification at significantly lower computational cost than continual training.\nIn parallel, LLMs are frequently fine-tuned for a wide range of downstream\ntasks. However, the effect of fine-tuning on previously edited knowledge\nremains poorly understood. In this work, we systematically investigate how\ndifferent fine-tuning objectives interact with various model editing\ntechniques. Our findings show that edited knowledge is substantially more\nsusceptible to forgetting during fine-tuning than intrinsic knowledge acquired\nthrough pre-training. This analysis highlights a key limitation of current\nediting approaches and suggests that evaluating edit robustness under\ndownstream fine-tuning is critical for their practical deployment. We further\nfind that freezing layers associated with edited content can significantly\nimprove knowledge retention, offering insight into how future editing methods\nmight be made more robust.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14198v1", "cate": "cs.CL", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.14793", "title": "Flow Equivariant Recurrent Neural Networks", "authors": ["T. Anderson Keller"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14793v1", "summary": "Data arrives at our senses as a continuous stream, smoothly transforming from\none instant to the next. These smooth transformations can be viewed as\ncontinuous symmetries of the environment that we inhabit, defining equivalence\nrelations between stimuli over time. In machine learning, neural network\narchitectures that respect symmetries of their data are called equivariant and\nhave provable benefits in terms of generalization ability and sample\nefficiency. To date, however, equivariance has been considered only for static\ntransformations and feed-forward networks, limiting its applicability to\nsequence models, such as recurrent neural networks (RNNs), and corresponding\ntime-parameterized sequence transformations. In this work, we extend\nequivariant network theory to this regime of `flows' -- one-parameter Lie\nsubgroups capturing natural transformations over time, such as visual motion.\nWe begin by showing that standard RNNs are generally not flow equivariant:\ntheir hidden states fail to transform in a geometrically structured manner for\nmoving stimuli. We then show how flow equivariance can be introduced, and\ndemonstrate that these models significantly outperform their non-equivariant\ncounterparts in terms of training speed, length generalization, and velocity\ngeneralization, on both next step prediction and sequence classification. We\npresent this work as a first step towards building sequence models that respect\nthe time-parameterized symmetries which govern the world around us.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14793v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14845", "title": "Training Self-Supervised Depth Completion Using Sparse Measurements and a Single Image", "authors": ["Rizhao Fan", "Zhigen Li", "Heping Li", "Ning An"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14845v1", "summary": "Depth completion is an important vision task, and many efforts have been made\nto enhance the quality of depth maps from sparse depth measurements. Despite\nsignificant advances, training these models to recover dense depth from sparse\nmeasurements remains a challenging problem. Supervised learning methods rely on\ndense depth labels to predict unobserved regions, while self-supervised\napproaches require image sequences to enforce geometric constraints and\nphotometric consistency between frames. However, acquiring dense annotations is\ncostly, and multi-frame dependencies limit the applicability of self-supervised\nmethods in static or single-frame scenarios. To address these challenges, we\npropose a novel self-supervised depth completion paradigm that requires only\nsparse depth measurements and their corresponding image for training. Unlike\nexisting methods, our approach eliminates the need for dense depth labels or\nadditional images captured from neighboring viewpoints. By leveraging the\ncharacteristics of depth distribution, we design novel loss functions that\neffectively propagate depth information from observed points to unobserved\nregions. Additionally, we incorporate segmentation maps generated by vision\nfoundation models to further enhance depth estimation. Extensive experiments\ndemonstrate the effectiveness of our proposed method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14845v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.09186", "title": "OpenCAMS: An Open-Source Connected and Automated Mobility Co-Simulation Platform for Advancing Next-Generation Intelligent Transportation Systems Research", "authors": ["Minhaj Uddin Ahmad", "Akid Abrar", "Sagar Dasgupta", "Mizanur Rahman"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09186v2", "summary": "We introduce OpenCAMS (Open-Source Connected and Automated Mobility\nCo-Simulation Platform), an open-source, synchronized, and extensible\nco-simulation framework that tightly couples three best-in-class simulation\ntools: (i) SUMO, (ii) CARLA, and (iii) OMNeT++. OpenCAMS is designed to support\nadvanced research in transportation safety, mobility, and cybersecurity by\ncombining the strengths of each simulation domain. Specifically, SUMO provides\nlarge-scale, microscopic traffic modeling; CARLA offers high-fidelity 3D\nperception, vehicle dynamics, and control simulation; and OMNeT++ enables\nmodular, event-driven network communication, such as cellular\nvehicle-to-everything (C-V2X). OpenCAMS employs a time-synchronized,\nbidirectional coupling architecture that ensures coherent simulation\nprogression across traffic, perception, and communication domains while\npreserving modularity and reproducibility. For example, CARLA can simulate and\nrender a subset of vehicles that require detailed sensor emulation and control\nlogic; SUMO orchestrates network-wide traffic flow, vehicle routing, and\ntraffic signal management; and OMNeT++ dynamically maps communication nodes to\nboth mobile entities (e.g., vehicles) and static entities (e.g., roadside\nunits) to enable C-V2X communication. While these three simulators form the\nfoundational core of OpenCAMS, the platform is designed to be expandable and\nfuture-proof, allowing additional simulators to be integrated on top of this\ncore without requiring fundamental changes to the system architecture. The\nOpenCAMS platform is fully open-source and publicly available through its\nGitHub repository https://github.com/minhaj6/carla-sumo-omnetpp-cosim,\nproviding the research community with an accessible, flexible, and\ncollaborative environment for advancing next-generation intelligent\ntransportation systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09186v2", "cate": "cs.SE", "date": "2025-07-12", "updated": "2025-07-18"}
{"id": "2402.04161", "title": "Attention with Markov: A Framework for Principled Analysis of Transformers via Markov Chains", "authors": ["Ashok Vardhan Makkuva", "Marco Bondaschi", "Adway Girish", "Alliot Nagle", "Martin Jaggi", "Hyeji Kim", "Michael Gastpar"], "categories": ["cs.LG", "cs.CL", "cs.IT", "math.IT", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published at ICLR 2025 under the title \"Attention with Markov: A Curious Case of Single-Layer Transformers\"", "url": "http://arxiv.org/abs/2402.04161v2", "summary": "Attention-based transformers have achieved tremendous success across a\nvariety of disciplines including natural languages. To deepen our understanding\nof their sequential modeling capabilities, there is a growing interest in using\nMarkov input processes to study them. A key finding is that when trained on\nfirst-order Markov chains, transformers with two or more layers consistently\ndevelop an induction head mechanism to estimate the in-context bigram\nconditional distribution. In contrast, single-layer transformers, unable to\nform an induction head, directly learn the Markov kernel but often face a\nsurprising challenge: they become trapped in local minima representing the\nunigram distribution, whereas deeper models reliably converge to the\nground-truth bigram. While single-layer transformers can theoretically model\nfirst-order Markov chains, their empirical failure to learn this simple kernel\nin practice remains a curious phenomenon. To explain this contrasting behavior\nof single-layer models, in this paper we introduce a new framework for a\nprincipled analysis of transformers via Markov chains. Leveraging our\nframework, we theoretically characterize the loss landscape of single-layer\ntransformers and show the existence of global minima (bigram) and bad local\nminima (unigram) contingent on data properties and model architecture. We\nprecisely delineate the regimes under which these local optima occur. Backed by\nexperiments, we demonstrate that our theoretical findings are in congruence\nwith the empirical results. Finally, we outline several open problems in this\narena. Code is available at https://github.com/Bond1995/Markov .", "comment": "Published at ICLR 2025 under the title \"Attention with Markov: A\n  Curious Case of Single-Layer Transformers\"", "pdf_url": "http://arxiv.org/pdf/2402.04161v2", "cate": "cs.LG", "date": "2024-02-06", "updated": "2025-07-21"}
{"id": "2507.14206", "title": "A Comprehensive Benchmark for Electrocardiogram Time-Series", "authors": ["Zhijiang Tang", "Jiaxin Qi", "Yuhua Zheng", "Jianqiang Huang"], "categories": ["eess.SP", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted to ACM MM 2025", "url": "http://arxiv.org/abs/2507.14206v1", "summary": "Electrocardiogram~(ECG), a key bioelectrical time-series signal, is crucial\nfor assessing cardiac health and diagnosing various diseases. Given its\ntime-series format, ECG data is often incorporated into pre-training datasets\nfor large-scale time-series model training. However, existing studies often\noverlook its unique characteristics and specialized downstream applications,\nwhich differ significantly from other time-series data, leading to an\nincomplete understanding of its properties. In this paper, we present an\nin-depth investigation of ECG signals and establish a comprehensive benchmark,\nwhich includes (1) categorizing its downstream applications into four distinct\nevaluation tasks, (2) identifying limitations in traditional evaluation metrics\nfor ECG analysis, and introducing a novel metric; (3) benchmarking\nstate-of-the-art time-series models and proposing a new architecture. Extensive\nexperiments demonstrate that our proposed benchmark is comprehensive and\nrobust. The results validate the effectiveness of the proposed metric and model\narchitecture, which establish a solid foundation for advancing research in ECG\nsignal analysis.", "comment": "Accepted to ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2507.14206v1", "cate": "eess.SP", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2409.06656", "title": "Sortformer: A Novel Approach for Permutation-Resolved Speaker Supervision in Speech-to-Text Systems", "authors": ["Taejin Park", "Ivan Medennikov", "Kunal Dhawan", "Weiqing Wang", "He Huang", "Nithin Rao Koluguri", "Krishna C. Puvvada", "Jagadeesh Balam", "Boris Ginsburg"], "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Published at ICML 2025", "url": "http://arxiv.org/abs/2409.06656v3", "summary": "Sortformer is an encoder-based speaker diarization model designed for\nsupervising speaker tagging in speech-to-text models. Instead of relying solely\non permutation invariant loss (PIL), Sortformer introduces Sort Loss to resolve\nthe permutation problem, either independently or in tandem with PIL. In\naddition, we propose a streamlined multi-speaker speech-to-text architecture\nthat leverages Sortformer for speaker supervision, embedding speaker labels\ninto the encoder using sinusoidal kernel functions. This design addresses the\nspeaker permutation problem through sorted objectives, effectively bridging\ntimestamps and tokens to supervise speaker labels in the output transcriptions.\nExperiments demonstrate that Sort Loss can boost speaker diarization\nperformance, and incorporating the speaker supervision from Sortformer improves\nmulti-speaker transcription accuracy. We anticipate that the proposed\nSortformer and multi-speaker architecture will enable the seamless integration\nof speaker tagging capabilities into foundational speech-to-text systems and\nmultimodal large language models (LLMs), offering an easily adoptable and\nuser-friendly mechanism to enhance their versatility and performance in\nspeaker-aware tasks. The code and trained models are made publicly available\nthrough the NVIDIA NeMo Framework.", "comment": "Published at ICML 2025", "pdf_url": "http://arxiv.org/pdf/2409.06656v3", "cate": "eess.AS", "date": "2024-09-10", "updated": "2025-07-19"}
{"id": "2507.15434", "title": "Job Scheduling under Base and Additional Fees, with Applications to Mixed-Criticality Scheduling", "authors": ["Yi-Ting Hsieh", "Mong-Jen Kao", "Jhong-Yun Liu", "Hung-Lung Wang"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15434v1", "summary": "We are concerned with the problem of scheduling $n$ jobs onto $m$ identical\nmachines. Each machine has to be in operation for a prescribed time, and the\nobjective is to minimize the total machine working time. Precisely, let $c_i$\nbe the prescribed time for machine $i$, where $i\\in[m]$, and $p_j$ be the\nprocessing time for job $j$, where $j\\in[n]$. The problem asks for a schedule\n$\\sigma\\colon\\, J\\to M$ such that $\\sum_{i=1}^m\\max\\{c_i,\n\\sum_{j\\in\\sigma^{-1}(i)}p_j\\}$ is minimized, where $J$ and $M$ denote the sets\nof jobs and machines, respectively. We show that First Fit Decreasing (FFD)\nleads to a $1.5$-approximation, and this problem admits a polynomial-time\napproximation scheme (PTAS). The idea is further applied to mixed-criticality\nsystem scheduling to yield improved approximation results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15434v1", "cate": "cs.DS", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15629", "title": "Gaussian Splatting with Discretized SDF for Relightable Assets", "authors": ["Zuo-Liang Zhu", "Jian Yang", "Beibei Wang"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15629v1", "summary": "3D Gaussian splatting (3DGS) has shown its detailed expressive ability and\nhighly efficient rendering speed in the novel view synthesis (NVS) task. The\napplication to inverse rendering still faces several challenges, as the\ndiscrete nature of Gaussian primitives makes it difficult to apply geometry\nconstraints. Recent works introduce the signed distance field (SDF) as an extra\ncontinuous representation to regularize the geometry defined by Gaussian\nprimitives. It improves the decomposition quality, at the cost of increasing\nmemory usage and complicating training. Unlike these works, we introduce a\ndiscretized SDF to represent the continuous SDF in a discrete manner by\nencoding it within each Gaussian using a sampled value. This approach allows us\nto link the SDF with the Gaussian opacity through an SDF-to-opacity\ntransformation, enabling rendering the SDF via splatting and avoiding the\ncomputational cost of ray marching.The key challenge is to regularize the\ndiscrete samples to be consistent with the underlying SDF, as the discrete\nrepresentation can hardly apply the gradient-based constraints (\\eg Eikonal\nloss). For this, we project Gaussians onto the zero-level set of SDF and\nenforce alignment with the surface from splatting, namely a projection-based\nconsistency loss. Thanks to the discretized SDF, our method achieves higher\nrelighting quality, while requiring no extra memory beyond GS and avoiding\ncomplex manually designed optimization. The experiments reveal that our method\noutperforms existing Gaussian-based inverse rendering methods. Our code is\navailable at https://github.com/NK-CS-ZZL/DiscretizedSDF.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15629v1", "cate": "cs.GR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14619", "title": "Optimizing Legal Document Retrieval in Vietnamese with Semi-Hard Negative Mining", "authors": ["Van-Hoang Le", "Duc-Vu Nguyen", "Kiet Van Nguyen", "Ngan Luu-Thuy Nguyen"], "categories": ["cs.IR", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted at ICCCI 2025", "url": "http://arxiv.org/abs/2507.14619v1", "summary": "Large Language Models (LLMs) face significant challenges in specialized\ndomains like law, where precision and domain-specific knowledge are critical.\nThis paper presents a streamlined two-stage framework consisting of Retrieval\nand Re-ranking to enhance legal document retrieval efficiency and accuracy. Our\napproach employs a fine-tuned Bi-Encoder for rapid candidate retrieval,\nfollowed by a Cross-Encoder for precise re-ranking, both optimized through\nstrategic negative example mining. Key innovations include the introduction of\nthe Exist@m metric to evaluate retrieval effectiveness and the use of semi-hard\nnegatives to mitigate training bias, which significantly improved re-ranking\nperformance. Evaluated on the SoICT Hackathon 2024 for Legal Document\nRetrieval, our team, 4Huiter, achieved a top-three position. While\ntop-performing teams employed ensemble models and iterative self-training on\nlarge bge-m3 architectures, our lightweight, single-pass approach offered a\ncompetitive alternative with far fewer parameters. The framework demonstrates\nthat optimized data processing, tailored loss functions, and balanced negative\nsampling are pivotal for building robust retrieval-augmented systems in legal\ncontexts.", "comment": "Accepted at ICCCI 2025", "pdf_url": "http://arxiv.org/pdf/2507.14619v1", "cate": "cs.IR", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14386", "title": "Training oscillator Ising machines to assign the dynamic stability of their equilibrium points", "authors": ["Yi Cheng", "Zongli Lin"], "categories": ["cs.NE", "cs.IR"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      8 pages, 4 figures", "url": "http://arxiv.org/abs/2507.14386v1", "summary": "We propose a neural network model, which, with appropriate assignment of the\nstability of its equilibrium points (EPs), achieves Hopfield-like associative\nmemory. The oscillator Ising machine (OIM) is an ideal candidates for such a\nmodel, as all its $0/\\pi$ binary EPs are structurally stable with their dynamic\nstability tunable by the coupling weights. Traditional Hopfield-based models\nstore the desired patterns by designing the coupling weights between neurons.\nThe design of coupling weights should simultaneously take into account both the\nexistence and the dynamic stability of the EPs for the storage of the desired\npatterns. For OIMs, since all $0/\\pi$ binary EPs are structurally stable, the\ndesign of the coupling weights needs only to focus on assigning appropriate\nstability for the $0/\\pi$ binary EPs according to the desired patterns. In this\npaper, we establish a connection between the stability and the Hamiltonian\nenergy of EPs for OIMs, and, based on this connection, provide a\nHamiltonian-Regularized Eigenvalue Contrastive Method (HRECM) to train the\ncoupling weights of OIMs for assigning appropriate stability to their EPs.\nFinally, numerical experiments are performed to validate the effectiveness of\nthe proposed method.", "comment": "8 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.14386v1", "cate": "cs.NE", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2503.01474", "title": "Interactive Navigation for Legged Manipulators with Learned Arm-Pushing Controller", "authors": ["Zhihai Bi", "Kai Chen", "Chunxin Zheng", "Yulin Li", "Haoang Li", "Jun Ma"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.01474v2", "summary": "Interactive navigation is crucial in scenarios where proactively interacting\nwith objects can yield shorter paths, thus significantly improving traversal\nefficiency. Existing methods primarily focus on using the robot body to\nrelocate large obstacles (which could be comparable to the size of a robot).\nHowever, they prove ineffective in narrow or constrained spaces where the\nrobot's dimensions restrict its manipulation capabilities. This paper\nintroduces a novel interactive navigation framework for legged manipulators,\nfeaturing an active arm-pushing mechanism that enables the robot to reposition\nmovable obstacles in space-constrained environments. To this end, we develop a\nreinforcement learning-based arm-pushing controller with a two-stage reward\nstrategy for large-object manipulation. Specifically, this strategy first\ndirects the manipulator to a designated pushing zone to achieve a kinematically\nfeasible contact configuration. Then, the end effector is guided to maintain\nits position at appropriate contact points for stable object displacement while\npreventing toppling. The simulations validate the robustness of the arm-pushing\ncontroller, showing that the two-stage reward strategy improves policy\nconvergence and long-term performance. Real-world experiments further\ndemonstrate the effectiveness of the proposed navigation framework, which\nachieves shorter paths and reduced traversal time. The open-source project can\nbe found at\nhttps://github.com/Zhihaibi/Interactive-Navigation-for-legged-manipulator.git.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.01474v2", "cate": "cs.RO", "date": "2025-03-03", "updated": "2025-07-21"}
{"id": "2507.14200", "title": "Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System", "authors": ["Shengji Tang", "Jianjian Cao", "Weihao Lin", "Jiale Hong", "Bo Zhang", "Shuyue Hu", "Lei Bai", "Tao Chen", "Wanli Ouyang", "Peng Ye"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14200v1", "summary": "This paper aims to demonstrate the potential and strengths of open-source\ncollectives. It leads to a promising question: Can we harness multiple\nopen-source LLMs to match or even beat the closed-source LLMs? To answer this,\nwe propose SMACS, a scalable multi-agent collaboration system (MACS) framework\nwith high performance. Specifically, for continuous integration of new LLMs and\ngeneralization to diverse questions, we first propose a Retrieval-based Prior\nSelection (RPS), which assigns a proxy performance score to each LLM to select\nthe Top-k LLMs at the instance level for any given question. Then, we propose\nan Exploration-Exploitation-Driven Posterior Enhancement (EPE), encouraging the\ngeneration of diverse responses through prior dropping and selecting the\nhigh-quality response via a hybrid posterior score. Experiments on eight\nmainstream benchmarks validate the effectiveness of our SMACS: by integrating\nfifteen open-source LLMs, SMACS outperforms leading closed-source LLMs in 2025,\ne.g., Claude-3.7-Sonnet (+12.73%), GPT-4.1(+5.36%) and GPT-o3-mini(+5.28%)\nacross multiple tasks. Remarkably, it even exceeds the average of best results\nof different datasets from both open-source LLMs (+2.86%) and closed-source\nLLMs (+2.04%), pushing the upper bound of intelligence. Code will be released\nat https://github.com/magent4aci/SMACS.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14200v1", "cate": "cs.CL", "date": "2025-07-14", "updated": "2025-07-14"}
{"id": "2507.14805", "title": "Subliminal Learning: Language models transmit behavioral traits via hidden signals in data", "authors": ["Alex Cloud", "Minh Le", "James Chua", "Jan Betley", "Anna Sztyber-Betley", "Jacob Hilton", "Samuel Marks", "Owain Evans"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14805v1", "summary": "We study subliminal learning, a surprising phenomenon where language models\ntransmit behavioral traits via semantically unrelated data. In our main\nexperiments, a \"teacher\" model with some trait T (such as liking owls or being\nmisaligned) generates a dataset consisting solely of number sequences.\nRemarkably, a \"student\" model trained on this dataset learns T. This occurs\neven when the data is filtered to remove references to T. We observe the same\neffect when training on code or reasoning traces generated by the same teacher\nmodel. However, we do not observe the effect when the teacher and student have\ndifferent base models. To help explain our findings, we prove a theoretical\nresult showing that subliminal learning occurs in all neural networks under\ncertain conditions, and demonstrate subliminal learning in a simple MLP\nclassifier. We conclude that subliminal learning is a general phenomenon that\npresents an unexpected pitfall for AI development. Distillation could propagate\nunintended traits, even when developers try to prevent this via data filtering.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14805v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14851", "title": "Grounding Degradations in Natural Language for All-In-One Video Restoration", "authors": ["Muhammad Kamran Janjua", "Amirhosein Ghasemabadi", "Kunlin Zhang", "Mohammad Salameh", "Chao Gao", "Di Niu"], "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages", "url": "http://arxiv.org/abs/2507.14851v1", "summary": "In this work, we propose an all-in-one video restoration framework that\ngrounds degradation-aware semantic context of video frames in natural language\nvia foundation models, offering interpretable and flexible guidance. Unlike\nprior art, our method assumes no degradation knowledge in train or test time\nand learns an approximation to the grounded knowledge such that the foundation\nmodel can be safely disentangled during inference adding no extra cost.\nFurther, we call for standardization of benchmarks in all-in-one video\nrestoration, and propose two benchmarks in multi-degradation setting,\nthree-task (3D) and four-task (4D), and two time-varying composite degradation\nbenchmarks; one of the latter being our proposed dataset with varying snow\nintensity, simulating how weather degradations affect videos naturally. We\ncompare our method with prior works and report state-of-the-art performance on\nall benchmarks.", "comment": "17 pages", "pdf_url": "http://arxiv.org/pdf/2507.14851v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.12561", "title": "ROSE: Transformer-Based Refactoring Recommendation for Architectural Smells", "authors": ["Samal Nursapa", "Anastassiya Samuilova", "Alessio Bucaioni", "Phuong T. Nguyen"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      The paper has been peer-reviewed and accepted for publication in the proceedings of the 19th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM 2025)", "url": "http://arxiv.org/abs/2507.12561v2", "summary": "Architectural smells such as God Class, Cyclic Dependency, and Hub-like\nDependency degrade software quality and maintainability. Existing tools detect\nsuch smells but rarely suggest how to fix them. This paper explores the use of\npre-trained transformer models--CodeBERT and CodeT5--for recommending suitable\nrefactorings based on detected smells. We frame the task as a three-class\nclassification problem and fine-tune both models on over 2 million refactoring\ninstances mined from 11,149 open-source Java projects. CodeT5 achieves 96.9%\naccuracy and 95.2% F1, outperforming CodeBERT and traditional baselines. Our\nresults show that transformer-based models can effectively bridge the gap\nbetween smell detection and actionable repair, laying the foundation for future\nrefactoring recommendation systems. We release all code, models, and data under\nan open license to support reproducibility and further research.", "comment": "The paper has been peer-reviewed and accepted for publication in the\n  proceedings of the 19th ACM/IEEE International Symposium on Empirical\n  Software Engineering and Measurement (ESEM 2025)", "pdf_url": "http://arxiv.org/pdf/2507.12561v2", "cate": "cs.SE", "date": "2025-07-16", "updated": "2025-07-20"}
{"id": "2506.19037", "title": "Plan for Speed: Dilated Scheduling for Masked Diffusion Language Models", "authors": ["Omer Luxembourg", "Haim Permuter", "Eliya Nachmani"], "categories": ["cs.CL", "cs.AI", "cs.IT", "cs.LG", "cs.NE", "math.IT"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.19037v2", "summary": "Masked diffusion language models (MDLMs) promise fast, non-autoregressive\ntext generation, yet existing samplers, which pick tokens to unmask based on\nmodel confidence, ignore interactions when unmasking multiple positions in\nparallel and effectively reduce to slow, autoregressive behavior. We propose\nthe Dilated Unmasking Scheduler (DUS), an inference-only, planner-model-free\nmethod that partitions sequence positions into non-adjacent dilated groups and\nunmasked them in parallel so as to minimize an upper bound on joint entropy\ngain at each denoising step. By explicitly trading off the number of network\ncalls against generation quality, DUS recovers most of the performance lost\nunder traditional parallel unmasking strategies. Across math (GSM8K, MATH500),\ncode (HumanEval, MBPP) and general-knowledge benchmarks (BBH, MMLU-Pro), DUS\noutperforms confidence-based planners, without modifying the underlying\ndenoiser, and reveals the true speed-quality frontier of MDLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.19037v2", "cate": "cs.CL", "date": "2025-06-23", "updated": "2025-07-18"}
{"id": "2507.14208", "title": "Toward intelligent wireless networks in computer chassis", "authors": ["Mohammadreza F. Imani", "Alexander L. Colson", "Leslie K. Miller", "Jorge A. Valdez", "Jose C. Sanchez", "Richard F. Rader"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figures", "url": "http://arxiv.org/abs/2507.14208v1", "summary": "Processing the exponentially growing amount of data produced daily requires\nefficient communication between different processing units in a computer.\nTraditionally, wired interconnects have been used to maintain these data links\ndue to their energy efficiency and ability to support high data rates. However,\nas computing demands continue to increase in size and speed, these wired\ninterconnects can become longer and less effective. One possible solution is to\nenhance the wired interconnects with short-range wireless communication (SRWC),\nwhich offers flexible resource allocation and the ability to broadcast data.\nHowever, implementing SRWC inside a computer chassis presents challenges due to\nmultiple scattering. This scattering stretches the channel impulse response\n(CIR), leading to inter-symbol interference (ISI) and limiting data rates. To\naddress this issue, we propose transforming the computer chassis into a smart\nradio environment by utilizing a reconfigurable intelligent surface (RIS). The\nRIS elements adjust the phase of reflected waves so that the multipath\ncomponents combine at the receiver in a way that creates a pulse-like CIR. This\napproach has been experimentally validated within a typical computer chassis.\nThe results of this study pave the way for integrating RIS-enabled SRWC to\nenhance wireless links in both current and future data processing units.", "comment": "9 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.14208v1", "cate": "eess.SP", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2504.20630", "title": "ISDrama: Immersive Spatial Drama Generation through Multimodal Prompting", "authors": ["Yu Zhang", "Wenxiang Guo", "Changhao Pan", "Zhiyuan Zhu", "Tao Jin", "Zhou Zhao"], "categories": ["eess.AS", "cs.MM", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted by ACM Multimedia 2025", "url": "http://arxiv.org/abs/2504.20630v3", "summary": "Multimodal immersive spatial drama generation focuses on creating continuous\nmulti-speaker binaural speech with dramatic prosody based on multimodal\nprompts, with potential applications in AR, VR, and others. This task requires\nsimultaneous modeling of spatial information and dramatic prosody based on\nmultimodal inputs, with high data collection costs. To the best of our\nknowledge, our work is the first attempt to address these challenges. We\nconstruct MRSDrama, the first multimodal recorded spatial drama dataset,\ncontaining binaural drama audios, scripts, videos, geometric poses, and textual\nprompts. Then, we propose ISDrama, the first immersive spatial drama generation\nmodel through multimodal prompting. ISDrama comprises these primary components:\n1) Multimodal Pose Encoder, based on contrastive learning, considering the\nDoppler effect caused by moving speakers to extract unified pose information\nfrom multimodal prompts. 2) Immersive Drama Transformer, a flow-based\nmamba-transformer model that generates high-quality drama, incorporating\nDrama-MOE to select proper experts for enhanced prosody and pose control. We\nalso design a context-consistent classifier-free guidance strategy to\ncoherently generate complete drama. Experimental results show that ISDrama\noutperforms baseline models on objective and subjective metrics. The demos are\navailable at https://aaronz345.github.io/ISDramaDemo. We provide the dataset\nand the evaluation code at https://huggingface.co/datasets/AaronZ345/MRSDrama\nand https://github.com/AaronZ345/ISDrama.", "comment": "Accepted by ACM Multimedia 2025", "pdf_url": "http://arxiv.org/pdf/2504.20630v3", "cate": "eess.AS", "date": "2025-04-29", "updated": "2025-07-21"}
{"id": "2507.15549", "title": "An $n^{O(\\log\\log n)}$ time approximation scheme for capacitated VRP in the Euclidean plane", "authors": ["René Sitters"], "categories": ["cs.DS", "90", "F.2; E.1; G.2"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      40 pages", "url": "http://arxiv.org/abs/2507.15549v1", "summary": "We present a quasi polynomial time approximation scheme (Q-PTAS) for the\ncapacitated vehicle routing problem (CVRP) on $n$ points in the Euclidean plane\nfor arbitrary capacity $c$. The running time is $n^{f(\\epsilon)\\cdot\\log\\log\nn}$ for any $c$, and where $f$ is a function of $\\epsilon$ only. This is a\nmajor improvement over the so far best known running time of\n$n^{\\log^{O(1/\\epsilon)}n}$ time and a big step towards a PTAS for Euclidean\nCVRP.\n  In our algorithm, we first give a polynomial time reduction of the CVRP in\n$\\mathbb{R}^d$ (for any fixed $d$) to an uncapacitated routing problem in\n$\\mathbb{R}^d$ that we call the $m$-paths problem. Here, one needs to find\nexactly $m$ paths between two points $a$ and $b$, covering all the given points\nin the Euclidean space. We then give a Q-PTAS for the $m$-paths problem in the\npane. Any PTAS for the (arguably easier to handle) Euclidean $m$-paths problem\nis most likely to imply a PTAS for the Euclidean CVRP.", "comment": "40 pages", "pdf_url": "http://arxiv.org/pdf/2507.15549v1", "cate": "cs.DS", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15230", "title": "GALE: Leveraging Heterogeneous Systems for Efficient Unstructured Mesh Data Analysis", "authors": ["Guoxi Liu", "Thomas Randall", "Rong Ge", "Federico Iuricich"], "categories": ["cs.DC", "cs.GR"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15230v1", "summary": "Unstructured meshes present challenges in scientific data analysis due to\nirregular distribution and complex connectivity. Computing and storing\nconnectivity information is a major bottleneck for visualization algorithms,\naffecting both time and memory performance. Recent task-parallel data\nstructures address this by precomputing connectivity information at runtime\nwhile the analysis algorithm executes, effectively hiding computation costs and\nimproving performance. However, existing approaches are CPU-bound, forcing the\ndata structure and analysis algorithm to compete for the same computational\nresources, limiting potential speedups. To overcome this limitation, we\nintroduce a novel task-parallel approach optimized for heterogeneous CPU-GPU\nsystems. Specifically, we offload the computation of mesh connectivity\ninformation to GPU threads, enabling CPU threads to focus on executing the\nvisualization algorithm. Following this paradigm, we propose GALE (GPU-Aided\nLocalized data structurE), the first open-source CUDA-based data structure\ndesigned for heterogeneous task parallelism. Experiments on two 20-core CPUs\nand an NVIDIA V100 GPU show that GALE achieves up to 2.7x speedup over\nstate-of-the-art localized data structures while maintaining memory efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15230v1", "cate": "cs.DC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14902", "title": "U-MARVEL: Unveiling Key Factors for Universal Multimodal Retrieval via Embedding Learning with MLLMs", "authors": ["Xiaojie Li", "Chu Li", "Shi-Zhe Chen", "Xi Chen"], "categories": ["cs.IR", "cs.CV"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Technical Report (in progress)", "url": "http://arxiv.org/abs/2507.14902v1", "summary": "Universal multimodal retrieval (UMR), which aims to address complex retrieval\ntasks where both queries and candidates span diverse modalities, has been\nsignificantly advanced by the emergence of MLLMs. While state-of-the-art\nMLLM-based methods in the literature predominantly adopt contrastive learning\nprinciples, they often differ in their specific training recipes. Despite their\nsuccess, the mechanisms underlying their retrieval capabilities remain largely\nunexplored, potentially resulting in suboptimal performance and limited\ngeneralization ability. To address these issues, we present a comprehensive\nstudy aimed at uncovering the key factors that drive effective embedding\nlearning for UMR using MLLMs. We begin by implementing a general MLLM-based\nembedding learning pipeline, and systematically analyze the primary\ncontributors to high-performing universal retrieval systems. Based on this, we\nexplore various aspects of the details in embedding generation and training\nstrategies, including progressive transition, hard negative mining and\nre-ranker distillation. Notably, our findings reveal that often-overlooked\nfactors can have a substantial impact on model performance. Building on these\ndiscoveries, we introduce a unified framework termed U-MARVEL\n(\\textbf{U}niversal \\textbf{M}ultimod\\textbf{A}l \\textbf{R}etrie\\textbf{V}al\nvia \\textbf{E}mbedding \\textbf{L}earning), which outperforms state-of-the-art\ncompetitors on the M-BEIR benchmark by a large margin in supervised settings,\nand also exihibits strong zero-shot performance on several tasks such as\ncomposed image retrieval and text-to-video retrieval. These results underscore\nthe generalization potential of our framework across various embedding-based\nretrieval tasks. Code is available at https://github.com/chaxjli/U-MARVEL", "comment": "Technical Report (in progress)", "pdf_url": "http://arxiv.org/pdf/2507.14902v1", "cate": "cs.IR", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14757", "title": "Analyzing Internal Activity and Robustness of SNNs Across Neuron Parameter Space", "authors": ["Szymon Mazurek", "Jakub Caputa", "Maciej Wielgosz"], "categories": ["cs.NE", "cs.AI"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14757v1", "summary": "Spiking Neural Networks (SNNs) offer energy-efficient and biologically\nplausible alternatives to traditional artificial neural networks, but their\nperformance depends critically on the tuning of neuron model parameters. In\nthis work, we identify and characterize an operational space - a constrained\nregion in the neuron hyperparameter domain (specifically membrane time constant\ntau and voltage threshold vth) - within which the network exhibits meaningful\nactivity and functional behavior. Operating inside this manifold yields optimal\ntrade-offs between classification accuracy and spiking activity, while stepping\noutside leads to degeneration: either excessive energy use or complete network\nsilence.\n  Through systematic exploration across datasets and architectures, we\nvisualize and quantify this manifold and identify efficient operating points.\nWe further assess robustness to adversarial noise, showing that SNNs exhibit\nincreased spike correlation and internal synchrony when operating outside their\noptimal region. These findings highlight the importance of principled\nhyperparameter tuning to ensure both task performance and energy efficiency.\nOur results offer practical guidelines for deploying robust and efficient SNNs,\nparticularly in neuromorphic computing scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14757v1", "cate": "cs.NE", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2503.11145", "title": "Leveraging Semantic Graphs for Efficient and Robust LiDAR SLAM", "authors": ["Neng Wang", "Huimin Lu", "Zhiqiang Zheng", "Hesheng Wang", "Yun-Hui Liu", "Xieyuanli Chen"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 4 figures,Accpted for IROS 2025", "url": "http://arxiv.org/abs/2503.11145v2", "summary": "Accurate and robust simultaneous localization and mapping (SLAM) is crucial\nfor autonomous mobile systems, typically achieved by leveraging the geometric\nfeatures of the environment. Incorporating semantics provides a richer scene\nrepresentation that not only enhances localization accuracy in SLAM but also\nenables advanced cognitive functionalities for downstream navigation and\nplanning tasks. Existing point-wise semantic LiDAR SLAM methods often suffer\nfrom poor efficiency and generalization, making them less robust in diverse\nreal-world scenarios. In this paper, we propose a semantic graph-enhanced SLAM\nframework, named SG-SLAM, which effectively leverages the geometric, semantic,\nand topological characteristics inherent in environmental structures. The\nsemantic graph serves as a fundamental component that facilitates critical\nfunctionalities of SLAM, including robust relocalization during odometry\nfailures, accurate loop closing, and semantic graph map construction. Our\nmethod employs a dual-threaded architecture, with one thread dedicated to\nonline odometry and relocalization, while the other handles loop closure, pose\ngraph optimization, and map update. This design enables our method to operate\nin real time and generate globally consistent semantic graph maps and point\ncloud maps. We extensively evaluate our method across the KITTI, MulRAN, and\nApollo datasets, and the results demonstrate its superiority compared to\nstate-of-the-art methods. Our method has been released at\nhttps://github.com/nubot-nudt/SG-SLAM.", "comment": "8 pages, 4 figures,Accpted for IROS 2025", "pdf_url": "http://arxiv.org/pdf/2503.11145v2", "cate": "cs.RO", "date": "2025-03-14", "updated": "2025-07-21"}
{"id": "2507.14218", "title": "Cognitive Castes: Artificial Intelligence, Epistemic Stratification, and the Dissolution of Democratic Discourse", "authors": ["Craig S Wright"], "categories": ["cs.CY", "cs.AI", "cs.LG", "cs.LO", "68T01, 03B70, 91F10, 68P20, 68T30", "I.2.0; K.4.1; I.2.6; J.4"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      42 Pages; Approx. 10,000 words, no figures. Theoretical contribution with interdisciplinary scope", "url": "http://arxiv.org/abs/2507.14218v1", "summary": "Artificial intelligence functions not as an epistemic leveller, but as an\naccelerant of cognitive stratification, entrenching and formalising\ninformational castes within liberal-democratic societies. Synthesising formal\nepistemology, political theory, algorithmic architecture, and economic\nincentive structures, the argument traces how contemporary AI systems\nselectively amplify the reasoning capacity of individuals equipped with\nrecursive abstraction, symbolic logic, and adversarial interrogation, whilst\nsimultaneously pacifying the cognitively untrained through engagement-optimised\ninterfaces. Fluency replaces rigour, immediacy displaces reflection, and\nprocedural reasoning is eclipsed by reactive suggestion. The result is a\ntechnocratic realignment of power: no longer grounded in material capital\nalone, but in the capacity to navigate, deconstruct, and manipulate systems of\nepistemic production. Information ceases to be a commons; it becomes the\nsubstrate through which consent is manufactured and autonomy subdued.\nDeliberative democracy collapses not through censorship, but through the\nerosion of interpretive agency. The proposed response is not technocratic\nregulation, nor universal access, but the reconstruction of rational autonomy\nas a civic mandate, codified in education, protected by epistemic rights, and\nstructurally embedded within open cognitive infrastructure.", "comment": "42 Pages; Approx. 10,000 words, no figures. Theoretical contribution\n  with interdisciplinary scope", "pdf_url": "http://arxiv.org/pdf/2507.14218v1", "cate": "cs.CY", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.14824", "title": "Benchmarking Foundation Models with Multimodal Public Electronic Health Records", "authors": ["Kunyu Yu", "Rui Yang", "Jingchi Liao", "Siqi Li", "Huitao Li", "Irene Li", "Yifan Peng", "Rishikesan Kamaleswaran", "Nan Liu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14824v1", "summary": "Foundation models have emerged as a powerful approach for processing\nelectronic health records (EHRs), offering flexibility to handle diverse\nmedical data modalities. In this study, we present a comprehensive benchmark\nthat evaluates the performance, fairness, and interpretability of foundation\nmodels, both as unimodal encoders and as multimodal learners, using the\npublicly available MIMIC-IV database. To support consistent and reproducible\nevaluation, we developed a standardized data processing pipeline that\nharmonizes heterogeneous clinical records into an analysis-ready format. We\nsystematically compared eight foundation models, encompassing both unimodal and\nmultimodal models, as well as domain-specific and general-purpose variants. Our\nfindings demonstrate that incorporating multiple data modalities leads to\nconsistent improvements in predictive performance without introducing\nadditional bias. Through this benchmark, we aim to support the development of\neffective and trustworthy multimodal artificial intelligence (AI) systems for\nreal-world clinical applications. Our code is available at\nhttps://github.com/nliulab/MIMIC-Multimodal.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14824v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14855", "title": "An Uncertainty-aware DETR Enhancement Framework for Object Detection", "authors": ["Xingshu Chen", "Sicheng Yu", "Chong Cheng", "Hao Wang", "Ting Tian"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14855v1", "summary": "This paper investigates the problem of object detection with a focus on\nimproving both the localization accuracy of bounding boxes and explicitly\nmodeling prediction uncertainty. Conventional detectors rely on deterministic\nbounding box regression, ignoring uncertainty in predictions and limiting model\nrobustness. In this paper, we propose an uncertainty-aware enhancement\nframework for DETR-based object detectors. We model bounding boxes as\nmultivariate Gaussian distributions and incorporate the Gromov-Wasserstein\ndistance into the loss function to better align the predicted and ground-truth\ndistributions. Building on this, we derive a Bayes Risk formulation to filter\nhigh-risk information and improve detection reliability. We also propose a\nsimple algorithm to quantify localization uncertainty via confidence intervals.\nExperiments on the COCO benchmark show that our method can be effectively\nintegrated into existing DETR variants, enhancing their performance. We further\nextend our framework to leukocyte detection tasks, achieving state-of-the-art\nresults on the LISC and WBCDD datasets. These results confirm the scalability\nof our framework across both general and domain-specific detection tasks. Code\npage:\nhttps://github.com/ParadiseforAndaChen/An-Uncertainty-aware-DETR-Enhancement-Framework-for-Object-Detection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14855v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2407.01639", "title": "ModelVerification.jl: a Comprehensive Toolbox for Formally Verifying Deep Neural Networks", "authors": ["Tianhao Wei", "Hanjiang Hu", "Luca Marzari", "Kai S. Yun", "Peizhi Niu", "Xusheng Luo", "Changliu Liu"], "categories": ["cs.LG", "cs.SE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.01639v2", "summary": "Deep Neural Networks (DNN) are crucial in approximating nonlinear functions\nacross diverse applications, ranging from image classification to control.\nVerifying specific input-output properties can be a highly challenging task due\nto the lack of a single, self-contained framework that allows a complete range\nof verification types. To this end, we present \\texttt{ModelVerification.jl\n(MV)}, the first comprehensive, cutting-edge toolbox that contains a suite of\nstate-of-the-art methods for verifying different types of DNNs and safety\nspecifications. This versatile toolbox is designed to empower developers and\nmachine learning practitioners with robust tools for verifying and ensuring the\ntrustworthiness of their DNN models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.01639v2", "cate": "cs.LG", "date": "2024-06-30", "updated": "2025-07-20"}
{"id": "2507.06216", "title": "Unitary designs in nearly optimal depth", "authors": ["Laura Cui", "Thomas Schuster", "Fernando Brandao", "Hsin-Yuan Huang"], "categories": ["quant-ph", "cs.CC", "cs.IT", "math-ph", "math.IT", "math.MP"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      8+31 pages, 3+1 figures", "url": "http://arxiv.org/abs/2507.06216v2", "summary": "We construct $\\varepsilon$-approximate unitary $k$-designs on $n$ qubits in\ncircuit depth $O(\\log k \\log \\log n k / \\varepsilon)$. The depth is\nexponentially improved over all known results in all three parameters $n$, $k$,\n$\\varepsilon$. We further show that each dependence is optimal up to\nexponentially smaller factors. Our construction uses $\\tilde{{O}}(nk)$ ancilla\nqubits and ${O}(nk)$ bits of randomness, which are also optimal up to $\\log(n\nk)$ factors. An alternative construction achieves a smaller ancilla count\n$\\tilde{{O}}(n)$ with circuit depth ${O}(k \\log \\log nk/\\varepsilon)$. To\nachieve these efficient unitary designs, we introduce a highly-structured\nrandom unitary ensemble that leverages long-range two-qubit gates and low-depth\nimplementations of random classical hash functions. We also develop a new\nanalytical framework for bounding errors in quantum experiments involving many\nqueries to random unitaries. As an illustration of this framework's\nversatility, we provide a succinct alternative proof of the existence of\npseudorandom unitaries.", "comment": "8+31 pages, 3+1 figures", "pdf_url": "http://arxiv.org/pdf/2507.06216v2", "cate": "quant-ph", "date": "2025-07-08", "updated": "2025-07-19"}
{"id": "2507.14210", "title": "System Design and Performance Analysis for RIS-assisted Terahertz Self-Alignment Beamforming", "authors": ["Jiayuan Wei", "Qingwei Jiang", "Wen Fang", "Mingqing Liu", "Qingwen Liu", "Wen Chen", "Qingqing Wu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14210v1", "summary": "The widespread deployment of Internet of Things(IoT) devices underscores the\nneed for sustainable wireless solutions capable of simultaneously transferring\nboth energy and information. Terahertz (THz) band-enabled simultaneous wireless\ninformation and power transfer (SWIPT) systems offer ultra-high data rates and\nexpansive bandwidth. However, THz waves are inherently susceptible to severe\npath loss and beam misalignment due to their narrow-beam characteristics. In\nthis context, this paper proposes a reconfigurable intelligent\nsurface(RIS)-assisted transmitter architecture for the THz-SWIPT system, which\nenables end-to-end self-alignment for steady-state transmission. The proposed\nsystem incorporates phase conjugate circuits to achieve self-aligned\nbeamforming, facilitating the dynamic tracking of mobile IoT devices without\nthe need for beam training. Additionally, active amplification within the RIS\narrays compensates for cascaded channel attenuation through an iterative power\ncycle, thereby enhancing the energy transmission efficiency. Theoretical models\nand simulations indicate that the proposed system significantly mitigates\nsidelobe interference, achieving a transmission efficiency of up to 73.26% over\na 2 meter distance with self-alignment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14210v1", "cate": "eess.SP", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2507.13626", "title": "Unifying Listener Scoring Scales: Comparison Learning Framework for Speech Quality Assessment and Continuous Speech Emotion Recognition", "authors": ["Cheng-Hung Hu", "Yusuke Yasuda", "Akifumi Yoshimoto", "Tomoki Toda"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted to Interspeech 2025", "url": "http://arxiv.org/abs/2507.13626v2", "summary": "Speech Quality Assessment (SQA) and Continuous Speech Emotion Recognition\n(CSER) are two key tasks in speech technology, both relying on listener\nratings. However, these ratings are inherently biased due to individual\nlistener factors. Previous approaches have introduced a mean listener scoring\nscale and modeled all listener scoring scales in the training set. However, the\nmean listener approach is prone to distortion from averaging ordinal data,\nleading to potential biases. Moreover, learning multiple listener scoring\nscales while inferring based only on the mean listener scale limits\neffectiveness. In contrast, our method focuses on modeling a unified listener\nscoring scale, using comparison scores to correctly capture the scoring\nrelationships between utterances. Experimental results show that our method\neffectively improves prediction performance in both SQA and CSER tasks, proving\nits effectiveness and robustness.", "comment": "Accepted to Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.13626v2", "cate": "eess.AS", "date": "2025-07-18", "updated": "2025-07-21"}
{"id": "2507.15598", "title": "Fast Algorithms for Graph Arboricity and Related Problems", "authors": ["Ruoxu Cen", "Henry Fleischmann", "George Z. Li", "Jason Li", "Debmalya Panigrahi"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      FOCS 2025. 25 pages, 3 figures", "url": "http://arxiv.org/abs/2507.15598v1", "summary": "We give an algorithm for finding the arboricity of a weighted, undirected\ngraph, defined as the minimum number of spanning forests that cover all edges\nof the graph, in $\\sqrt{n} m^{1+o(1)}$ time. This improves on the previous best\nbound of $\\tilde{O}(nm)$ for weighted graphs and $\\tilde{O}(m^{3/2}) $ for\nunweighted graphs (Gabow 1995) for this problem. The running time of our\nalgorithm is dominated by a logarithmic number of calls to a directed global\nminimum cut subroutine -- if the running time of the latter problem improves to\n$m^{1+o(1)}$ (thereby matching the running time of maximum flow), the running\ntime of our arboricity algorithm would improve further to $m^{1+o(1)}$.\n  We also give a new algorithm for computing the entire cut hierarchy --\nlaminar multiway cuts with minimum cut ratio in recursively defined induced\nsubgraphs -- in $m n^{1+o(1)}$ time. The cut hierarchy yields the ideal edge\nloads (Thorup 2001) in a fractional spanning tree packing of the graph which,\nwe show, also corresponds to a max-entropy solution in the spanning tree\npolytope. For the cut hierarchy problem, the previous best bound was\n$\\tilde{O}(n^2 m)$ for weighted graphs and $\\tilde{O}(n m^{3/2})$ for\nunweighted graphs.", "comment": "FOCS 2025. 25 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.15598v1", "cate": "cs.DS", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2504.08366", "title": "In-2-4D: Inbetweening from Two Single-View Images to 4D Generation", "authors": ["Sauradip Nag", "Daniel Cohen-Or", "Hao Zhang", "Ali Mahdavi-Amiri"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      Technical Report", "url": "http://arxiv.org/abs/2504.08366v2", "summary": "We propose a new problem, In-2-4D, for generative 4D (i.e., 3D + motion)\ninbetweening from a minimalistic input setting: two single-view images\ncapturing an object in two distinct motion states. Given two images\nrepresenting the start and end states of an object in motion, our goal is to\ngenerate and reconstruct the motion in 4D. We utilize a video interpolation\nmodel to predict the motion, but large frame-to-frame motions can lead to\nambiguous interpretations. To overcome this, we employ a hierarchical approach\nto identify keyframes that are visually close to the input states and show\nsignificant motion, then generate smooth fragments between them. For each\nfragment, we construct the 3D representation of the keyframe using Gaussian\nSplatting. The temporal frames within the fragment guide the motion, enabling\ntheir transformation into dynamic Gaussians through a deformation field. To\nimprove temporal consistency and refine 3D motion, we expand the self-attention\nof multi-view diffusion across timesteps and apply rigid transformation\nregularization. Finally, we merge the independently generated 3D motion\nsegments by interpolating boundary deformation fields and optimizing them to\nalign with the guiding video, ensuring smooth and flicker-free transitions.\nThrough extensive qualitative and quantitiave experiments as well as a user\nstudy, we show the effectiveness of our method and its components. The project\npage is available at https://in-2-4d.github.io/", "comment": "Technical Report", "pdf_url": "http://arxiv.org/pdf/2504.08366v2", "cate": "cs.GR", "date": "2025-04-11", "updated": "2025-07-21"}
{"id": "2507.14925", "title": "User Invariant Preference Learning for Multi-Behavior Recommendation", "authors": ["Mingshi Yan", "Zhiyong Cheng", "Fan Liu", "Yingda Lyu", "Yahong Han"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14925v1", "summary": "In multi-behavior recommendation scenarios, analyzing users' diverse\nbehaviors, such as click, purchase, and rating, enables a more comprehensive\nunderstanding of their interests, facilitating personalized and accurate\nrecommendations. A fundamental assumption of multi-behavior recommendation\nmethods is the existence of shared user preferences across behaviors,\nrepresenting users' intrinsic interests. Based on this assumption, existing\napproaches aim to integrate information from various behaviors to enrich user\nrepresentations. However, they often overlook the presence of both\ncommonalities and individualities in users' multi-behavior preferences. These\nindividualities reflect distinct aspects of preferences captured by different\nbehaviors, where certain auxiliary behaviors may introduce noise, hindering the\nprediction of the target behavior. To address this issue, we propose a user\ninvariant preference learning for multi-behavior recommendation (UIPL for\nshort), aiming to capture users' intrinsic interests (referred to as invariant\npreferences) from multi-behavior interactions to mitigate the introduction of\nnoise. Specifically, UIPL leverages the paradigm of invariant risk minimization\nto learn invariant preferences. To implement this, we employ a variational\nautoencoder (VAE) to extract users' invariant preferences, replacing the\nstandard reconstruction loss with an invariant risk minimization constraint.\nAdditionally, we construct distinct environments by combining multi-behavior\ndata to enhance robustness in learning these preferences. Finally, the learned\ninvariant preferences are used to provide recommendations for the target\nbehavior. Extensive experiments on four real-world datasets demonstrate that\nUIPL significantly outperforms current state-of-the-art methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14925v1", "cate": "cs.IR", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15615", "title": "DHEvo: Data-Algorithm Based Heuristic Evolution for Generalizable MILP Solving", "authors": ["Zhihao Zhang", "Siyuan Li", "Chenxi Li", "Feifan Liu", "Mengjing Chen", "Kai Li", "Tao Zhong", "Bo An", "Peng Liu"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15615v1", "summary": "Primal heuristics play a critical role in improving the efficiency of mixed\ninteger programming (MILP) solvers. As large language models (LLMs) have\ndemonstrated superior code generation abilities, recent MILP works are devoted\nto leveraging the evolutionary computation approaches with LLMs to generate\neffective primal heuristics. Although the generated heuristics have achieved\nbetter solving performance than the hand-crafted ones with little adaptability,\nthe advantage of current LLM-based methods is limited to few MILP instances in\none problem class, as they fail to capture the instance characteristics in the\nproblem class (the MILP instances generated from the same mathematical model\nare defined as a problem class). Since MILP instances often differ\nsignificantly in structure and feature distribution, the neglect of their\ncharacteristics in the evolution process results in poor generalization within\nthe same problem class. To overcome this challenge, we propose a data-algorithm\nco-evolution framework (DHEvo) that iteratively selects representative\ninstances and evolves corresponding heuristics. With the initial instance\ndistribution, we develop an LLM-based multi-agent system to generate data-code\npairs simultaneously. These data-code pairs are iteratively refined based on\ntheir fitness scores, leading to the identification of the most effective\nheuristic over the entire problem class. Extensive experiments across diverse\nMILP benchmarks demonstrate that our approach significantly outperforms both\nhuman-designed heuristics and existing LLM-based methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15615v1", "cate": "cs.NE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2504.03038", "title": "How to Adapt Control Barrier Functions? A Learning-Based Approach with Applications to a VTOL Quadplane", "authors": ["Taekyung Kim", "Randal W. Beard", "Dimitra Panagou"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      2025 IEEE Conference on Decision and Control (CDC). Project page: this https URL", "url": "http://arxiv.org/abs/2504.03038v2", "summary": "In this paper, we present a novel theoretical framework for online adaptation\nof Control Barrier Function (CBF) parameters, i.e., of the class K functions\nincluded in the CBF condition, under input constraints. We introduce the\nconcept of locally validated CBF parameters, which are adapted online to\nguarantee finite-horizon safety, based on conditions derived from Nagumo's\ntheorem and tangent cone analysis. To identify these parameters online, we\nintegrate a learning-based approach with an uncertainty-aware verification\nprocess that account for both epistemic and aleatoric uncertainties inherent in\nneural network predictions. Our method is demonstrated on a VTOL quadplane\nmodel during challenging transition and landing maneuvers, showcasing enhanced\nperformance while maintaining safety.", "comment": "2025 IEEE Conference on Decision and Control (CDC). Project page:\n  https://www.taekyung.me/how-to-adapt-cbf", "pdf_url": "http://arxiv.org/pdf/2504.03038v2", "cate": "cs.RO", "date": "2025-04-03", "updated": "2025-07-19"}
{"id": "2507.14231", "title": "Beyond Architectures: Evaluating the Role of Contextual Embeddings in Detecting Bipolar Disorder on Social Media", "authors": ["Khalid Hasan", "Jamil Saquer"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      The 37th International Conference on Software Engineering & Knowledge Engineering, SEKE 2025 (camera-ready)", "url": "http://arxiv.org/abs/2507.14231v1", "summary": "Bipolar disorder is a chronic mental illness frequently underdiagnosed due to\nsubtle early symptoms and social stigma. This paper explores the advanced\nnatural language processing (NLP) models for recognizing signs of bipolar\ndisorder based on user-generated social media text. We conduct a comprehensive\nevaluation of transformer-based models (BERT, RoBERTa, ALBERT, ELECTRA,\nDistilBERT) and Long Short Term Memory (LSTM) models based on contextualized\n(BERT) and static (GloVe, Word2Vec) word embeddings. Experiments were performed\non a large, annotated dataset of Reddit posts after confirming their validity\nthrough sentiment variance and judgmental analysis. Our results demonstrate\nthat RoBERTa achieves the highest performance among transformer models with an\nF1 score of ~98% while LSTM models using BERT embeddings yield nearly identical\nresults. In contrast, LSTMs trained on static embeddings fail to capture\nmeaningful patterns, scoring near-zero F1. These findings underscore the\ncritical role of contextual language modeling in detecting bipolar disorder. In\naddition, we report model training times and highlight that DistilBERT offers\nan optimal balance between efficiency and accuracy. In general, our study\noffers actionable insights for model selection in mental health NLP\napplications and validates the potential of contextualized language models to\nsupport early bipolar disorder screening.", "comment": "The 37th International Conference on Software Engineering & Knowledge\n  Engineering, SEKE 2025 (camera-ready)", "pdf_url": "http://arxiv.org/pdf/2507.14231v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14828", "title": "eMargin: Revisiting Contrastive Learning with Margin-Based Separation", "authors": ["Abdul-Kazeem Shamba", "Kerstin Bach", "Gavin Taylor"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      LDD'25: Learning from Difficult Data Workshop (ECAI 2025)", "url": "http://arxiv.org/abs/2507.14828v1", "summary": "We revisit previous contrastive learning frameworks to investigate the effect\nof introducing an adaptive margin into the contrastive loss function for time\nseries representation learning. Specifically, we explore whether an adaptive\nmargin (eMargin), adjusted based on a predefined similarity threshold, can\nimprove the separation between adjacent but dissimilar time steps and\nsubsequently lead to better performance in downstream tasks. Our study\nevaluates the impact of this modification on clustering performance and\nclassification in three benchmark datasets. Our findings, however, indicate\nthat achieving high scores on unsupervised clustering metrics does not\nnecessarily imply that the learned embeddings are meaningful or effective in\ndownstream tasks. To be specific, eMargin added to InfoNCE consistently\noutperforms state-of-the-art baselines in unsupervised clustering metrics, but\nstruggles to achieve competitive results in downstream classification with\nlinear probing. The source code is publicly available at\nhttps://github.com/sfi-norwai/eMargin.", "comment": "LDD'25: Learning from Difficult Data Workshop (ECAI 2025)", "pdf_url": "http://arxiv.org/pdf/2507.14828v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14867", "title": "Hybrid-supervised Hypergraph-enhanced Transformer for Micro-gesture Based Emotion Recognition", "authors": ["Zhaoqiang Xia", "Hexiang Huang", "Haoyu Chen", "Xiaoyi Feng", "Guoying Zhao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14867v1", "summary": "Micro-gestures are unconsciously performed body gestures that can convey the\nemotion states of humans and start to attract more research attention in the\nfields of human behavior understanding and affective computing as an emerging\ntopic. However, the modeling of human emotion based on micro-gestures has not\nbeen explored sufficiently. In this work, we propose to recognize the emotion\nstates based on the micro-gestures by reconstructing the behavior patterns with\na hypergraph-enhanced Transformer in a hybrid-supervised framework. In the\nframework, hypergraph Transformer based encoder and decoder are separately\ndesigned by stacking the hypergraph-enhanced self-attention and multiscale\ntemporal convolution modules. Especially, to better capture the subtle motion\nof micro-gestures, we construct a decoder with additional upsampling operations\nfor a reconstruction task in a self-supervised learning manner. We further\npropose a hypergraph-enhanced self-attention module where the hyperedges\nbetween skeleton joints are gradually updated to present the relationships of\nbody joints for modeling the subtle local motion. Lastly, for exploiting the\nrelationship between the emotion states and local motion of micro-gestures, an\nemotion recognition head from the output of encoder is designed with a shallow\narchitecture and learned in a supervised way. The end-to-end framework is\njointly trained in a one-stage way by comprehensively utilizing\nself-reconstruction and supervision information. The proposed method is\nevaluated on two publicly available datasets, namely iMiGUE and SMG, and\nachieves the best performance under multiple metrics, which is superior to the\nexisting methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14867v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2503.10968", "title": "Combinatorial Optimization for All: Using LLMs to Aid Non-Experts in Improving Optimization Algorithms", "authors": ["Camilo Chacón Sartori", "Christian Blum"], "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.10968v2", "summary": "Large Language Models (LLMs) have shown notable potential in code generation\nfor optimization algorithms, unlocking exciting new opportunities. This paper\nexamines how LLMs, rather than creating algorithms from scratch, can improve\nexisting ones without the need for specialized expertise. To explore this\npotential, we selected 10 baseline optimization algorithms from various domains\n(metaheuristics, reinforcement learning, deterministic, and exact methods) to\nsolve the classic Travelling Salesman Problem. The results show that our simple\nmethodology often results in LLM-generated algorithm variants that improve over\nthe baseline algorithms in terms of solution quality, reduction in\ncomputational time, and simplification of code complexity, all without\nrequiring specialized optimization knowledge or advanced algorithmic\nimplementation skills.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.10968v2", "cate": "cs.AI", "date": "2025-03-14", "updated": "2025-07-18"}
{"id": "2507.14216", "title": "Distributed Machine Learning Approach for Low-Latency Localization in Cell-Free Massive MIMO Systems", "authors": ["Manish Kumar", "Tzu-Hsuan Chou", "Byunghyun Lee", "Nicolò Michelusi", "David J. Love", "Yaguang Zhang", "James V. Krogmeier"], "categories": ["eess.SP", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      This paper has been submitted to IEEE Transactions on Wireless Communications", "url": "http://arxiv.org/abs/2507.14216v1", "summary": "Low-latency localization is critical in cellular networks to support\nreal-time applications requiring precise positioning. In this paper, we propose\na distributed machine learning (ML) framework for fingerprint-based\nlocalization tailored to cell-free massive multiple-input multiple-output\n(MIMO) systems, an emerging architecture for 6G networks. The proposed\nframework enables each access point (AP) to independently train a Gaussian\nprocess regression model using local angle-of-arrival and received signal\nstrength fingerprints. These models provide probabilistic position estimates\nfor the user equipment (UE), which are then fused by the UE with minimal\ncomputational overhead to derive a final location estimate. This decentralized\napproach eliminates the need for fronthaul communication between the APs and\nthe central processing unit (CPU), thereby reducing latency. Additionally,\ndistributing computational tasks across the APs alleviates the processing\nburden on the CPU compared to traditional centralized localization schemes.\nSimulation results demonstrate that the proposed distributed framework achieves\nlocalization accuracy comparable to centralized methods, despite lacking the\nbenefits of centralized data aggregation. Moreover, it effectively reduces\nuncertainty of the location estimates, as evidenced by the 95\\% covariance\nellipse. The results highlight the potential of distributed ML for enabling\nlow-latency, high-accuracy localization in future 6G networks.", "comment": "This paper has been submitted to IEEE Transactions on Wireless\n  Communications", "pdf_url": "http://arxiv.org/pdf/2507.14216v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2311.17741", "title": "End-to-end Joint Punctuated and Normalized ASR with a Limited Amount of Punctuated Training Data", "authors": ["Can Cui", "Imran Ahamad Sheikh", "Mostafa Sadeghi", "Emmanuel Vincent"], "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2311.17741v3", "summary": "Joint punctuated and normalized automatic speech recognition (ASR) aims at\noutputing transcripts with and without punctuation and casing. This task\nremains challenging due to the lack of paired speech and punctuated text data\nin most ASR corpora. We propose two approaches to train an end-to-end joint\npunctuated and normalized ASR system using limited punctuated data. The first\napproach uses a language model to convert normalized training transcripts into\npunctuated transcripts. This achieves a better performance on out-of-domain\ntest data, with up to 17% relative Punctuation-Case-aware Word Error Rate\n(PC-WER) reduction. The second approach uses a single decoder conditioned on\nthe type of output. This yields a 42% relative PC-WER reduction compared to\nWhisper-base and a 4% relative (normalized) WER reduction compared to the\nnormalized output of a punctuated-only model. Additionally, our proposed model\ndemonstrates the feasibility of a joint ASR system using as little as 5%\npunctuated training data with a moderate (2.42% absolute) PC-WER increase.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2311.17741v3", "cate": "cs.CL", "date": "2023-11-29", "updated": "2025-07-21"}
{"id": "2507.15616", "title": "On zeros and algorithms for disordered systems: mean-field spin glasses", "authors": ["Ferenc Bencs", "Kuikui Liu", "Guus Regts"], "categories": ["cs.DS", "cond-mat.dis-nn", "cs.DM", "math-ph", "math.MP", "math.PR"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15616v1", "summary": "Spin glasses are fundamental probability distributions at the core of\nstatistical physics, the theory of average-case computational complexity, and\nmodern high-dimensional statistical inference. In the mean-field setting, we\ndesign deterministic quasipolynomial-time algorithms for estimating the\npartition function to arbitrarily high accuracy for nearly all inverse\ntemperatures in the second moment regime. In particular, for the\nSherrington--Kirkpatrick model, our algorithms succeed for almost the entire\nreplica-symmetric phase. To achieve this, we study the locations of the zeros\nof the partition function. Notably, our methods are conceptually simple, and\napply equally well to the spherical case and the case of Ising spins.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15616v1", "cate": "cs.DS", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2505.00704", "title": "Controllable Weather Synthesis and Removal with Video Diffusion Models", "authors": ["Chih-Hao Lin", "Zian Wang", "Ruofan Liang", "Yuxuan Zhang", "Sanja Fidler", "Shenlong Wang", "Zan Gojcic"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      International Conference on Computer Vision (ICCV) 2025, Project Website: this https URL", "url": "http://arxiv.org/abs/2505.00704v2", "summary": "Generating realistic and controllable weather effects in videos is valuable\nfor many applications. Physics-based weather simulation requires precise\nreconstructions that are hard to scale to in-the-wild videos, while current\nvideo editing often lacks realism and control. In this work, we introduce\nWeatherWeaver, a video diffusion model that synthesizes diverse weather effects\n-- including rain, snow, fog, and clouds -- directly into any input video\nwithout the need for 3D modeling. Our model provides precise control over\nweather effect intensity and supports blending various weather types, ensuring\nboth realism and adaptability. To overcome the scarcity of paired training\ndata, we propose a novel data strategy combining synthetic videos, generative\nimage editing, and auto-labeled real-world videos. Extensive evaluations show\nthat our method outperforms state-of-the-art methods in weather simulation and\nremoval, providing high-quality, physically plausible, and\nscene-identity-preserving results over various real-world videos.", "comment": "International Conference on Computer Vision (ICCV) 2025, Project\n  Website: https://research.nvidia.com/labs/toronto-ai/WeatherWeaver/", "pdf_url": "http://arxiv.org/pdf/2505.00704v2", "cate": "cs.GR", "date": "2025-05-01", "updated": "2025-07-18"}
{"id": "2507.14946", "title": "FullRecall: A Semantic Search-Based Ranking Approach for Maximizing Recall in Patent Retrieval", "authors": ["Amna Ali", "Liyanage C. De Silva", "Pg Emeroylariffion Abas"], "categories": ["cs.IR", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14946v1", "summary": "Patent examiners and inventors face significant pressure to verify the\noriginality and non-obviousness of inventions, and the intricate nature of\npatent data intensifies the challenges of patent retrieval. Therefore, there is\na pressing need to devise cutting-edge retrieval strategies that can reliably\nachieve the desired recall. This study introduces FullRecall, a novel patent\nretrieval approach that effectively manages the complexity of patent data while\nmaintaining the reliability of relevance matching and maximising recall. It\nleverages IPC-guided knowledge to generate informative phrases, which are\nprocessed to extract key information in the form of noun phrases characterising\nthe query patent under observation. From these, the top k keyphrases are\nselected to construct a query for retrieving a focused subset of the dataset.\nThis initial retrieval step achieves complete recall, successfully capturing\nall relevant documents. To further refine the results, a ranking scheme is\napplied to the retrieved subset, reducing its size while maintaining 100%\nrecall. This multi-phase process demonstrates an effective strategy for\nbalancing precision and recall in patent retrieval tasks. Comprehensive\nexperiments were conducted, and the results were compared with baseline\nstudies, namely HRR2 [1] and ReQ-ReC [2]. The proposed approach yielded\nsuperior results, achieving 100% recall in all five test cases. However,\nHRR2[1] recall values across the five test cases were 10%, 25%, 33.3%, 0%, and\n14.29%, while ReQ-ReC [2] showed 50% for the first test case, 25% for the\nsecond test case, and 0% for the third, fourth, and fifth test cases. The 100%\nrecall ensures that no relevant prior art is overlooked, thereby strengthening\nthe patent pre-filing and examination processes, hence reducing potential legal\nrisks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14946v1", "cate": "cs.IR", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15734", "title": "TONUS: Neuromorphic human pose estimation for artistic sound co-creation", "authors": ["Jules Lecomte", "Konrad Zinner", "Michael Neumeier", "Axel von Arnim"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      Published at the International Joint Conference on Neural Networks 2025 in the special track on HUMAN-AI INTERACTION IN CREATIVE ARTS AND SCIENCES", "url": "http://arxiv.org/abs/2507.15734v1", "summary": "Human machine interaction is a huge source of inspiration in today's media\nart and digital design, as machines and humans merge together more and more.\nIts place in art reflects its growing applications in industry, such as\nrobotics. However, those interactions often remains too technical and\nmachine-driven for people to really engage into. On the artistic side, new\ntechnologies are often not explored in their full potential and lag a bit\nbehind, so that state-of-the-art research does not make its way up to museums\nand exhibitions. Machines should support people's imagination and poetry in a\nseamless interface to their body or soul. We propose an artistic sound\ninstallation featuring neuromorphic body sensing to support a direct yet non\nintrusive interaction with the visitor with the purpose of creating sound\nscapes together with the machine. We design a neuromorphic multihead human pose\nestimation neural sensor that shapes sound scapes and visual output with fine\nbody movement control. In particular, the feature extractor is a spiking neural\nnetwork tailored for a dedicated neuromorphic chip. The visitor, immersed in a\nsound atmosphere and a neurally processed representation of themselves that\nthey control, experience the dialogue with a machine that thinks neurally,\nsimilarly to them.", "comment": "Published at the International Joint Conference on Neural Networks\n  2025 in the special track on HUMAN-AI INTERACTION IN CREATIVE ARTS AND\n  SCIENCES", "pdf_url": "http://arxiv.org/pdf/2507.15734v1", "cate": "cs.NE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2504.05351", "title": "Design and Characterization of a Micro-Vibration Adhesion System", "authors": ["Siqian Li", "Xi Wang", "Jung-Che Chang", "Xin Dong"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.05351v2", "summary": "In recent years, miniature wall-climbing robots have attracted widespread\nattention due to their significant potential in equipment inspection and\nin-situ repair applications. Traditional wall-climbing systems typically rely\non electromagnetic, electrostatic, vacuum suction, or van der Waals forces for\ncontrollable adhesion. However, these conventional methods impose limitations\nwhen striving for both a compact design and high-speed mobility. This paper\nproposes a novel Vibration-Based Adhesion (VBA) technique, which utilizes a\nflexible disk vibrating near a surface to generate a strong and controllable\nattractive force without direct contact. By employing an electric motor as the\nvibration source, the constructed VBA system was experimentally evaluated,\nachieving an adhesion-to-weight ratio exceeding 51 times. The experimental\nresults demonstrate that this adhesion mechanism not only provides a high\nnormal force but also maintains minimal shear force, making it particularly\nsuitable for high-speed movement and heavy load applications in miniature\nwall-climbing robots.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.05351v2", "cate": "cs.RO", "date": "2025-04-06", "updated": "2025-07-20"}
{"id": "2507.14238", "title": "Language Models Change Facts Based on the Way You Talk", "authors": ["Matthew Kearney", "Reuben Binns", "Yarin Gal"], "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14238v1", "summary": "Large language models (LLMs) are increasingly being used in user-facing\napplications, from providing medical consultations to job interview advice.\nRecent research suggests that these models are becoming increasingly proficient\nat inferring identity information about the author of a piece of text from\nlinguistic patterns as subtle as the choice of a few words. However, little is\nknown about how LLMs use this information in their decision-making in\nreal-world applications. We perform the first comprehensive analysis of how\nidentity markers present in a user's writing bias LLM responses across five\ndifferent high-stakes LLM applications in the domains of medicine, law,\npolitics, government benefits, and job salaries. We find that LLMs are\nextremely sensitive to markers of identity in user queries and that race,\ngender, and age consistently influence LLM responses in these applications. For\ninstance, when providing medical advice, we find that models apply different\nstandards of care to individuals of different ethnicities for the same\nsymptoms; we find that LLMs are more likely to alter answers to align with a\nconservative (liberal) political worldview when asked factual questions by\nolder (younger) individuals; and that LLMs recommend lower salaries for\nnon-White job applicants and higher salaries for women compared to men. Taken\ntogether, these biases mean that the use of off-the-shelf LLMs for these\napplications may cause harmful differences in medical care, foster wage gaps,\nand create different political factual realities for people of different\nidentities. Beyond providing an analysis, we also provide new tools for\nevaluating how subtle encoding of identity in users' language choices impacts\nmodel decisions. Given the serious implications of these findings, we recommend\nthat similar thorough assessments of LLM use in user-facing applications are\nconducted before future deployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14238v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14843", "title": "The Invisible Leash: Why RLVR May Not Escape Its Origin", "authors": ["Fang Wu", "Weihao Xuan", "Ximing Lu", "Zaid Harchaoui", "Yejin Choi"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14843v1", "summary": "Recent advances in large reasoning models highlight Reinforcement Learning\nwith Verifiable Rewards (RLVR) as a promising method for enhancing AI's\ncapabilities, particularly in solving complex logical tasks. However, it\nremains unclear whether RLVR truly expands a model's reasoning boundary or\nmerely amplifies high-reward outputs that the base model already knows for\nimproved precision. This study presents a theoretical and empirical\ninvestigation that provides fresh insights into the potential limits of RLVR.\nFirst, we offer a new theoretical perspective that RLVR is constrained by the\nbase model's support-unable to sample solutions with zero initial\nprobability-and operates as a conservative reweighting mechanism that may\nrestrict the discovery of entirely original solutions. We also identify an\nentropy-reward tradeoff: while RLVR reliably enhances precision, it may\nprogressively narrow exploration and potentially overlook correct yet\nunderrepresented solutions. Extensive empirical experiments validate that while\nRLVR consistently improves pass@1, the shrinkage of empirical support generally\noutweighs the expansion of empirical support under larger sampling budgets,\nfailing to recover correct answers that were previously accessible to the base\nmodel. Interestingly, we also observe that while RLVR sometimes increases\ntoken-level entropy, resulting in greater uncertainty at each generation step,\nanswer-level entropy declines, indicating that these seemingly more uncertain\npaths ultimately converge onto a smaller set of distinct answers. Taken\ntogether, these findings reveal potential limits of RLVR in extending reasoning\nhorizons. Breaking this invisible leash may require future algorithmic\ninnovations such as explicit exploration mechanisms or hybrid strategies that\nseed probability mass into underrepresented solution regions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14843v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14879", "title": "Region-aware Depth Scale Adaptation with Sparse Measurements", "authors": ["Rizhao Fan", "Tianfang Ma", "Zhigen Li", "Ning An", "Jian Cheng"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14879v1", "summary": "In recent years, the emergence of foundation models for depth prediction has\nled to remarkable progress, particularly in zero-shot monocular depth\nestimation. These models generate impressive depth predictions; however, their\noutputs are often in relative scale rather than metric scale. This limitation\nposes challenges for direct deployment in real-world applications. To address\nthis, several scale adaptation methods have been proposed to enable foundation\nmodels to produce metric depth. However, these methods are typically costly, as\nthey require additional training on new domains and datasets. Moreover,\nfine-tuning these models often compromises their original generalization\ncapabilities, limiting their adaptability across diverse scenes. In this paper,\nwe introduce a non-learning-based approach that leverages sparse depth\nmeasurements to adapt the relative-scale predictions of foundation models into\nmetric-scale depth. Our method requires neither retraining nor fine-tuning,\nthereby preserving the strong generalization ability of the original foundation\nmodels while enabling them to produce metric depth. Experimental results\ndemonstrate the effectiveness of our approach, high-lighting its potential to\nbridge the gap between relative and metric depth without incurring additional\ncomputational costs or sacrificing generalization ability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14879v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14220", "title": "Advanced Space Mapping Technique Integrating a Shared Coarse Model for Multistate Tuning-Driven Multiphysics Optimization of Tunable Filters", "authors": ["Haitian Hu", "Wei Zhang", "Feng Feng", "Zhiguo Zhang", "Qi-Jun Zhang"], "categories": ["eess.SP", "cs.LG", "physics.acc-ph"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14220v1", "summary": "This article introduces an advanced space mapping (SM) technique that applies\na shared electromagnetic (EM)-based coarse model for multistate tuning-driven\nmultiphysics optimization of tunable filters. The SM method combines the\ncomputational efficiency of EM single-physics simulations with the precision of\nmultiphysics simulations. The shared coarse model is based on EM single-physics\nresponses corresponding to various nontunable design parameters values.\nConversely, the fine model is implemented to delineate the behavior of\nmultiphysics responses concerning both nontunable and tunable design parameter\nvalues. The proposed overall surrogate model comprises multiple subsurrogate\nmodels, each consisting of one shared coarse model and two distinct mapping\nneural networks. The responses from the shared coarse model in the EM\nsingle-physics filed offer a suitable approximation for the fine responses in\nthe multiphysics filed, whereas the mapping neural networks facilitate\ntransition from the EM single-physics field to the multiphysics field. Each\nsubsurrogate model maintains consistent nontunable design parameter values but\npossesses unique tunable design parameter values. By developing multiple\nsubsurrogate models, optimization can be simultaneously performed for each\ntuning state. Nontunable design parameter values are constrained by all tuning\nstates, whereas tunable design parameter values are confined to their\nrespective tuning states. This optimization technique simultaneously accounts\nfor all the tuning states to fulfill the necessary multiple tuning state\nrequirements. Multiple EM and multiphysics training samples are generated\nconcurrently to develop the surrogate model. Compared with existing direct\nmultiphysics parameterized modeling techniques, our proposed method achieves\nsuperior multiphysics modeling accuracy with fewer training samples and reduced\ncomputational costs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14220v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2407.02543", "title": "Towards the Next Frontier in Speech Representation Learning Using Disentanglement", "authors": ["Varun Krishna", "Sriram Ganapathy"], "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      There were some bugs in the Code that was used to produce the results in the paper. The results reported in the paper are not valid", "url": "http://arxiv.org/abs/2407.02543v2", "summary": "The popular frameworks for self-supervised learning of speech representations\nhave largely focused on frame-level masked prediction of speech regions. While\nthis has shown promising downstream task performance for speech recognition and\nrelated tasks, this has largely ignored factors of speech that are encoded at\ncoarser level, like characteristics of the speaker or channel that remain\nconsistent through-out a speech utterance. In this work, we propose a framework\nfor Learning Disentangled Self Supervised (termed as Learn2Diss)\nrepresentations of speech, which consists of frame-level and an utterance-level\nencoder modules. The two encoders are initially learned independently, where\nthe frame-level model is largely inspired by existing self supervision\ntechniques, thereby learning pseudo-phonemic representations, while the\nutterance-level encoder is inspired by constrastive learning of pooled\nembeddings, thereby learning pseudo-speaker representations. The joint learning\nof these two modules consists of disentangling the two encoders using a mutual\ninformation based criterion. With several downstream evaluation experiments, we\nshow that the proposed Learn2Diss achieves state-of-the-art results on a\nvariety of tasks, with the frame-level encoder representations improving\nsemantic tasks, while the utterance-level representations improve non-semantic\ntasks.", "comment": "There were some bugs in the Code that was used to produce the results\n  in the paper. The results reported in the paper are not valid", "pdf_url": "http://arxiv.org/pdf/2407.02543v2", "cate": "cs.CL", "date": "2024-07-02", "updated": "2025-07-19"}
{"id": "2507.14340", "title": "Topological Social Choice: Designing a Noise-Robust Polar Distance for Persistence Diagrams", "authors": ["Athanasios Andrikopoulos", "Nikolaos Sampanis"], "categories": ["math.AT", "cs.DS", "cs.LG", "55N31, 55U10, 91B14, 91C20"], "primary_category": "Subjects:       Algebraic Topology (math.AT)", "pdf_link": null, "comments": "Comments:      26 pages,2 figures", "url": "http://arxiv.org/abs/2507.14340v1", "summary": "Topological Data Analysis (TDA) has emerged as a powerful framework for\nextracting robust and interpretable features from noisy high-dimensional data.\nIn the context of Social Choice Theory, where preference profiles and\ncollective decisions are geometrically rich yet sensitive to perturbations, TDA\nremains largely unexplored. This work introduces a novel conceptual bridge\nbetween these domains by proposing a new metric framework for persistence\ndiagrams tailored to noisy preference data.We define a polar coordinate-based\ndistance that captures both the magnitude and orientation of topological\nfeatures in a smooth and differentiable manner. Our metric addresses key\nlimitations of classical distances, such as bottleneck and Wasserstein,\nincluding instability under perturbation, lack of continuity, and\nincompatibility with gradient-based learning. The resulting formulation offers\nimproved behavior in both theoretical and applied settings.To the best of our\nknowledge, this is the first study to systematically apply persistent homology\nto social choice systems, providing a mathematically grounded method for\ncomparing topological summaries of voting structures and preference dynamics.\nWe demonstrate the superiority of our approach through extensive experiments,\nincluding robustness tests and supervised learning tasks, and we propose a\nmodular pipeline for building predictive models from online preference data.\nThis work contributes a conceptually novel and computationally effective tool\nto the emerging interface of topology and decision theory, opening new\ndirections in interpretable machine learning for political and economic\nsystems.", "comment": "26 pages,2 figures", "pdf_url": "http://arxiv.org/pdf/2507.14340v1", "cate": "math.AT", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.12498", "title": "Wavelet-GS: 3D Gaussian Splatting with Wavelet Decomposition", "authors": ["Beizhen Zhao", "Yifan Zhou", "Sicheng Yu", "Zijian Wang", "Hao Wang"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      9 pages", "url": "http://arxiv.org/abs/2507.12498v2", "summary": "3D Gaussian Splatting (3DGS) has revolutionized 3D scene reconstruction,\nwhich effectively balances rendering quality, efficiency, and speed. However,\nexisting 3DGS approaches usually generate plausible outputs and face\nsignificant challenges in complex scene reconstruction, manifesting as\nincomplete holistic structural outlines and unclear local lighting effects. To\naddress these issues simultaneously, we propose a novel decoupled optimization\nframework, which integrates wavelet decomposition into 3D Gaussian Splatting\nand 2D sampling. Technically, through 3D wavelet decomposition, our approach\ndivides point clouds into high-frequency and low-frequency components, enabling\ntargeted optimization for each. The low-frequency component captures global\nstructural outlines and manages the distribution of Gaussians through\nvoxelization. In contrast, the high-frequency component restores intricate\ngeometric and textural details while incorporating a relight module to mitigate\nlighting artifacts and enhance photorealistic rendering. Additionally, a 2D\nwavelet decomposition is applied to the training images, simulating radiance\nvariations. This provides critical guidance for high-frequency detail\nreconstruction, ensuring seamless integration of details with the global\nstructure. Extensive experiments on challenging datasets demonstrate our method\nachieves state-of-the-art performance across various metrics, surpassing\nexisting approaches and advancing the field of 3D scene reconstruction.", "comment": "9 pages", "pdf_url": "http://arxiv.org/pdf/2507.12498v2", "cate": "cs.GR", "date": "2025-07-16", "updated": "2025-07-21"}
{"id": "2507.15113", "title": "Click A, Buy B: Rethinking Conversion Attribution in E- Commerce Recommendations", "authors": ["Xiangyu Zeng", "Amit Jaspal", "Bin Liu", "Goutham Panneeru", "Kevin Huang", "Nicolas Bievre", "Mohit Jaggi", "Prathap Maniraju", "Ankur Jain"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15113v1", "summary": "User journeys in e-commerce routinely violate the one-to-one assumption that\na clicked item on an advertising platform is the same item later purchased on\nthe merchant's website/app. For a significant number of converting sessions on\nour platform, users click product A but buy product B -- the Click A, Buy B\n(CABB) phenomenon. Training recommendation models on raw click-conversion pairs\ntherefore rewards items that merely correlate with purchases, leading to biased\nlearning and sub-optimal conversion rates. We reframe conversion prediction as\na multi-task problem with separate heads for Click A Buy A (CABA) and Click A\nBuy B (CABB). To isolate informative CABB conversions from unrelated CABB\nconversions, we introduce a taxonomy-aware collaborative filtering weighting\nscheme where each product is first mapped to a leaf node in a product taxonomy,\nand a category-to-category similarity matrix is learned from large-scale\nco-engagement logs. This weighting amplifies pairs that reflect genuine\nsubstitutable or complementary relations while down-weighting coincidental\ncross-category purchases. Offline evaluation on e-commerce sessions reduces\nnormalized entropy by 13.9% versus a last-click attribution baseline. An online\nA/B test on live traffic shows +0.25% gains in the primary business metric.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15113v1", "cate": "cs.IR", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2503.22814", "title": "Enhancing Celestial Imaging: High Dynamic Range with Neuromorphic Cameras", "authors": ["Satyapreet Singh Yadav", "Nirupam Roy", "Chetan Singh Thakur"], "categories": ["astro-ph.IM", "cs.ET", "cs.NE"], "primary_category": "Subjects:       Instrumentation and Methods for Astrophysics (astro-ph.IM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.22814v1", "summary": "Conventional frame-based cameras often struggle with limited dynamic range,\nleading to saturation and loss of detail when capturing scenes with significant\nbrightness variations. Neuromorphic cameras, inspired by human retina, offer a\nsolution by providing an inherently high dynamic range. This capability enables\nthem to capture both bright and faint celestial objects without saturation\neffects, preserving details across a wide range of luminosities. This paper\ninvestigates the application of neuromorphic imaging technology for capturing\ncelestial bodies across a wide range of flux levels. Its advantages are\ndemonstrated through examples such as the bright planet Saturn with its faint\nmoons and the bright star Sirius A alongside its faint companion, Sirius B.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.22814v1", "cate": "astro-ph.IM", "date": "2025-03-28", "updated": "2025-03-28"}
{"id": "2507.14440", "title": "An inverse moving point source problem in electromagnetics", "authors": ["Minghui Li", "Guanghui Hu", "Yue Zhao"], "categories": ["math.NA", "cs.NA", "35R30, 78A46"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14440v1", "summary": "This paper is concerned with an inverse moving point source problem in\nelectromagnetics. The aim is to reconstruct the moving orbit from the\ntangential components of magnetic fields taken at a finite number of\nobservation points. The distance function between each observation point and\nthe moving point source is computed by solving a nonlinear ordinary\ndifferential equation with an initial value. This ODE system only involves the\nmeasurement data from the tangential trace of the magnetic field at observation\npoints. As a consequence, the dynamical measurement data recorded at four\nnon-coplanar points are sufficient to reconstruct the orbit function. A\nLipschitz stability is established for the inverse problem, and numerical\nexperiments are reported to demonstrate the effectiveness of the proposed\nmethod. Numerical examples have shown that the reconstructed error depends\nlinearly on the noise level and that the wave speed is a critical factor\naffecting the relative error.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14440v1", "cate": "math.NA", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2504.06513", "title": "Safe Navigation in Uncertain Crowded Environments Using Risk Adaptive CVaR Barrier Functions", "authors": ["Xinyi Wang", "Taekyung Kim", "Bardh Hoxha", "Georgios Fainekos", "Dimitra Panagou"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). Project page: { this https URL }", "url": "http://arxiv.org/abs/2504.06513v4", "summary": "Robot navigation in dynamic, crowded environments poses a significant\nchallenge due to the inherent uncertainties in the obstacle model. In this\nwork, we propose a risk-adaptive approach based on the Conditional\nValue-at-Risk Barrier Function (CVaR-BF), where the risk level is automatically\nadjusted to accept the minimum necessary risk, achieving a good performance in\nterms of safety and optimization feasibility under uncertainty. Additionally,\nwe introduce a dynamic zone-based barrier function which characterizes the\ncollision likelihood by evaluating the relative state between the robot and the\nobstacle. By integrating risk adaptation with this new function, our approach\nadaptively expands the safety margin, enabling the robot to proactively avoid\nobstacles in highly dynamic environments. Comparisons and ablation studies\ndemonstrate that our method outperforms existing social navigation approaches,\nand validate the effectiveness of our proposed framework.", "comment": "2025 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS). Project page: {https://lawliet9666.github.io/cvarbf/}", "pdf_url": "http://arxiv.org/pdf/2504.06513v4", "cate": "cs.RO", "date": "2025-04-09", "updated": "2025-07-20"}
{"id": "2507.14239", "title": "CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation", "authors": ["Weihua Zheng", "Roy Ka-Wei Lee", "Zhengyuan Liu", "Kui Wu", "AiTi Aw", "Bowei Zou"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14239v1", "summary": "Multilingual Large Language Models(MLLMs) demonstrate strong generalization\nacross languages, yet they remain prone to hallucinations, especially in\nlow-resource languages, due to training data imbalances. These hallucinations,\nwhich include inaccurate or fabricated outputs, are particularly problematic in\ndomain-specific generation tasks (Chataigner et al., 2024). To address this\nchallenge, we propose CCL-XCoT(Curriculum-based Contrastive Learning-based\nCross-lingual Chain-of-Thought), a two-stage fine-tuning framework for\nmitigating hallucination in MLLMs. Our approach first enhances cross-lingual\nsemantic alignment through curriculum-based contrastive learning combined with\nnext-token prediction during continued pre-training. Building on this\nfoundation, we then introduce a cross-lingual Chain-of-Thought (XCoT) prompting\nstrategy during instruction fine-tuning, which guides the model to reason in a\nhigh-resource language before generating answers in the target low-resource\nlanguage. Experimental results show that CCL-XCoT reduces hallucination rates\nby up to 62% and substantially improves factual knowledge transfer across\nlanguage pairs, without relying on external retrieval or multi-model ensembles.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14239v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14847", "title": "Time-Aware Attention for Enhanced Electronic Health Records Modeling", "authors": ["Junhan Yu", "Zhunyi Feng", "Junwei Lu", "Tianxi Cai", "Doudou Zhou"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14847v1", "summary": "Electronic Health Records (EHR) contain valuable clinical information for\npredicting patient outcomes and guiding healthcare decisions. However,\neffectively modeling Electronic Health Records (EHRs) requires addressing data\nheterogeneity and complex temporal patterns. Standard approaches often struggle\nwith irregular time intervals between clinical events. We propose TALE-EHR, a\nTransformer-based framework featuring a novel time-aware attention mechanism\nthat explicitly models continuous temporal gaps to capture fine-grained\nsequence dynamics. To complement this temporal modeling with robust semantics,\nTALE-EHR leverages embeddings derived from standardized code descriptions using\na pre-trained Large Language Model (LLM), providing a strong foundation for\nunderstanding clinical concepts. Experiments on the MIMIC-IV and PIC dataset\ndemonstrate that our approach outperforms state-of-the-art baselines on tasks\nsuch as disease progression forecasting. TALE-EHR underscores the benefit of\nintegrating explicit, continuous temporal modeling with strong semantic\nrepresentations provides a powerful solution for advancing EHR analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14847v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14885", "title": "BeatFormer: Efficient motion-robust remote heart rate estimation through unsupervised spectral zoomed attention filters", "authors": ["Joaquim Comas", "Federico Sukno"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14885v1", "summary": "Remote photoplethysmography (rPPG) captures cardiac signals from facial\nvideos and is gaining attention for its diverse applications. While deep\nlearning has advanced rPPG estimation, it relies on large, diverse datasets for\neffective generalization. In contrast, handcrafted methods utilize\nphysiological priors for better generalization in unseen scenarios like motion\nwhile maintaining computational efficiency. However, their linear assumptions\nlimit performance in complex conditions, where deep learning provides superior\npulsatile information extraction. This highlights the need for hybrid\napproaches that combine the strengths of both methods. To address this, we\npresent BeatFormer, a lightweight spectral attention model for rPPG estimation,\nwhich integrates zoomed orthonormal complex attention and frequency-domain\nenergy measurement, enabling a highly efficient model. Additionally, we\nintroduce Spectral Contrastive Learning (SCL), which allows BeatFormer to be\ntrained without any PPG or HR labels. We validate BeatFormer on the PURE,\nUBFC-rPPG, and MMPD datasets, demonstrating its robustness and performance,\nparticularly in cross-dataset evaluations under motion scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14885v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14224", "title": "Diffusion-based translation between unpaired spontaneous premature neonatal EEG and fetal MEG", "authors": ["Benoît Brebion", "Alban Gallard", "Katrin Sippel", "Amer Zaylaa", "Hubert Preissl", "Sahar Moghimi", "Fabrice Wallois", "Yaël Frégier"], "categories": ["eess.SP", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14224v1", "summary": "Background and objective: Brain activity in premature newborns has\ntraditionally been studied using electroencephalography (EEG), leading to\nsubstantial advances in our understanding of early neural development. However,\nsince brain development takes root at the fetal stage, a critical window of\nthis process remains largely unknown. The only technique capable of recording\nneural activity in the intrauterine environment is fetal magnetoencephalography\n(fMEG), but this approach presents challenges in terms of data quality and\nscarcity. Using artificial intelligence, the present research aims to transfer\nthe well-established knowledge from EEG studies to fMEG to improve\nunderstanding of prenatal brain development, laying the foundations for better\ndetection and treatment of potential pathologies. Methods: We developed an\nunpaired diffusion translation method based on dual diffusion bridges, which\nnotably includes numerical integration improvements to obtain more qualitative\nresults at a lower computational cost. Models were trained on our unpaired\ndataset of bursts of spontaneous activity from 30 high-resolution premature\nnewborns EEG recordings and 44 fMEG recordings. Results: We demonstrate that\nour method achieves significant improvement upon previous results obtained with\nGenerative Adversarial Networks (GANs), by almost 5% on the mean squared error\nin the time domain, and completely eliminating the mode collapse problem in the\nfrequency domain, thus achieving near-perfect signal fidelity. Conclusion: We\nset a new state of the art in the EEG-fMEG unpaired translation problem, as our\ndeveloped tool completely paves the way for early brain activity analysis.\nOverall, we also believe that our method could be reused for other unpaired\nsignal translation applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14224v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2412.04534", "title": "Modeling nonuniform energy decay through the modal decomposition of acoustic radiance transfer (MoD-ART)", "authors": ["Matteo Scerbo", "Sebastian J. Schlecht", "Randall Ali", "Lauri Savioja", "Enzo De Sena"], "categories": ["cs.SD", "cs.SY", "eess.AS", "eess.SY"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.04534v2", "summary": "Modeling late reverberation in real-time interactive applications is a\nchallenging task when multiple sound sources and listeners are present in the\nsame environment. This is especially problematic when the environment is\ngeometrically complex and/or features uneven energy absorption (e.g. coupled\nvolumes), because in such cases the late reverberation is dependent on the\nsound sources' and listeners' positions, and therefore must be adapted to their\nmovements in real time. We present a novel approach to the task, named modal\ndecomposition of acoustic radiance transfer (MoD-ART), which can handle highly\ncomplex scenarios with efficiency. The approach is based on the geometrical\nacoustics method of acoustic radiance transfer, from which we extract a set of\nenergy decay modes and their positional relationships with sources and\nlisteners. In this paper, we describe the physical and mathematical\nsignificance of MoD-ART, highlighting its advantages and applicability to\ndifferent scenarios. Through an analysis of the method's computational\ncomplexity, we show that it compares very favorably with ray-tracing. We also\npresent simulation results showing that MoD-ART can capture multiple decay\nslopes and flutter echoes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.04534v2", "cate": "cs.SD", "date": "2024-12-05", "updated": "2025-07-21"}
{"id": "2507.14496", "title": "Quantum State Preparation Based on LimTDD", "authors": ["Xin Hong", "Chenjian Li", "Aochu Dai", "Sanjiang Li", "Shenggang Ying", "Mingsheng Ying"], "categories": ["quant-ph", "cs.DS"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14496v1", "summary": "Quantum state preparation is a fundamental task in quantum computing and\nquantum information processing. With the rapid advancement of quantum\ntechnologies, efficient quantum state preparation has become increasingly\nimportant. This paper proposes a novel approach for quantum state preparation\nbased on the Local Invertible Map Tensor Decision Diagram (LimTDD). LimTDD\ncombines the advantages of tensor networks and decision diagrams, enabling\nefficient representation and manipulation of quantum states. Compared with the\nstate-of-the-art quantum state preparation method, LimTDD demonstrates\nsubstantial improvements in efficiency when dealing with complex quantum\nstates, while also reducing the complexity of quantum circuits. Examples\nindicate that, in the best-case scenario, our method can achieve exponential\nefficiency gains over existing methods. This study not only highlights the\npotential of LimTDD in quantum state preparation but also provides a robust\ntheoretical and practical foundation for the future development of quantum\ncomputing technologies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14496v1", "cate": "quant-ph", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2501.08676", "title": "FlexiClip: Locality-Preserving Free-Form Character Animation", "authors": ["Anant Khandelwal"], "categories": ["cs.CV", "cs.GR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      13 pages, 4 figures, 7 tables, Accepted in ICML 2025, this https URL", "url": "http://arxiv.org/abs/2501.08676v2", "summary": "Animating clipart images with seamless motion while maintaining visual\nfidelity and temporal coherence presents significant challenges. Existing\nmethods, such as AniClipart, effectively model spatial deformations but often\nfail to ensure smooth temporal transitions, resulting in artifacts like abrupt\nmotions and geometric distortions. Similarly, text-to-video (T2V) and\nimage-to-video (I2V) models struggle to handle clipart due to the mismatch in\nstatistical properties between natural video and clipart styles. This paper\nintroduces FlexiClip, a novel approach designed to overcome these limitations\nby addressing the intertwined challenges of temporal consistency and geometric\nintegrity. FlexiClip extends traditional B\\'ezier curve-based trajectory\nmodeling with key innovations: temporal Jacobians to correct motion dynamics\nincrementally, continuous-time modeling via probability flow ODEs (pfODEs) to\nmitigate temporal noise, and a flow matching loss inspired by GFlowNet\nprinciples to optimize smooth motion transitions. These enhancements ensure\ncoherent animations across complex scenarios involving rapid movements and\nnon-rigid deformations. Extensive experiments validate the effectiveness of\nFlexiClip in generating animations that are not only smooth and natural but\nalso structurally consistent across diverse clipart types, including humans and\nanimals. By integrating spatial and temporal modeling with pre-trained video\ndiffusion models, FlexiClip sets a new standard for high-quality clipart\nanimation, offering robust performance across a wide range of visual content.\nProject Page: https://creative-gen.github.io/flexiclip.github.io/", "comment": "13 pages, 4 figures, 7 tables, Accepted in ICML 2025,\n  https://openreview.net/forum?id=xtxCM4XZ82", "pdf_url": "http://arxiv.org/pdf/2501.08676v2", "cate": "cs.CV", "date": "2025-01-15", "updated": "2025-07-20"}
{"id": "2507.15245", "title": "SPAR: Scholar Paper Retrieval with LLM-based Agents for Enhanced Academic Search", "authors": ["Xiaofeng Shi", "Yuduo Li", "Qian Kou", "Longbin Yu", "Jinxin Xie", "Hua Zhou"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15245v1", "summary": "Recent advances in large language models (LLMs) have opened new opportunities\nfor academic literature retrieval. However, existing systems often rely on\nrigid pipelines and exhibit limited reasoning capabilities. We introduce SPAR,\na multi-agent framework that incorporates RefChain-based query decomposition\nand query evolution to enable more flexible and effective search. To facilitate\nsystematic evaluation, we also construct SPARBench, a challenging benchmark\nwith expert-annotated relevance labels. Experimental results demonstrate that\nSPAR substantially outperforms strong baselines, achieving up to +56% F1 on\nAutoScholar and +23% F1 on SPARBench over the best-performing baseline.\nTogether, SPAR and SPARBench provide a scalable, interpretable, and\nhigh-performing foundation for advancing research in scholarly retrieval. Code\nand data will be available at: https://github.com/xiaofengShi/SPAR", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15245v1", "cate": "cs.IR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15118", "title": "Graph Attention Networks for Detecting Epilepsy from EEG Signals Using Accessible Hardware in Low-Resource Settings", "authors": ["Szymon Mazurek", "Stephen Moore", "Alessandro Crimi"], "categories": ["eess.SP", "cs.LG", "cs.NE"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15118v1", "summary": "Goal: Epilepsy remains under-diagnosed in low-income countries due to scarce\nneurologists and costly diagnostic tools. We propose a graph-based deep\nlearning framework to detect epilepsy from low-cost Electroencephalography\n(EEG) hardware, tested on recordings from Nigeria and Guinea-Bissau. Our focus\nis on fair, accessible automatic assessment and explainability to shed light on\nepilepsy biomarkers. Methods: We model EEG signals as spatio-temporal graphs,\nclassify them, and identify interchannel relationships and temporal dynamics\nusing graph attention networks (GAT). To emphasize connectivity biomarkers, we\nadapt the inherently node-focused GAT to analyze edges. We also designed signal\npreprocessing for low-fidelity recordings and a lightweight GAT architecture\ntrained on Google Colab and deployed on RaspberryPi devices. Results: The\napproach achieves promising classification performance, outperforming a\nstandard classifier based on random forest and graph convolutional networks in\nterms of accuracy and robustness over multiple sessions, but also highlighting\nspecific connections in the fronto-temporal region. Conclusions: The results\nhighlight the potential of GATs to provide insightful and scalable diagnostic\nsupport for epilepsy in underserved regions, paving the way for affordable and\naccessible neurodiagnostic tools.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15118v1", "cate": "eess.SP", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14474", "title": "Explicit Runge-Kutta Methods with MQ and IMQ-Radial Basis Functions", "authors": ["Shipra Mahata", "Samala Rathan"], "categories": ["math.NA", "cs.NA", "65L06"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      27 pages, 1 figure", "url": "http://arxiv.org/abs/2507.14474v1", "summary": "This article presents a class of explicit Runge-Kutta methods with\nmultiquadric (MQ) and inverse multiquadric (IMQ) radial basis functions (RBFs)\nto improve the accuracy of time integration for ordinary differential\nequations. By introducing RBF-based corrections derived from Taylor series\nexpansions and optimally selecting the shape parameter, the method achieves a\none-order increase in accuracy without additional stages. Convergence and\nstability analyses support the theoretical claims, and numerical experiments in\nMATLAB confirm the predicted performance.", "comment": "27 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.14474v1", "cate": "math.NA", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2505.00091", "title": "CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios", "authors": ["Tengchao Zhang", "Yonglin Tian", "Fei Lin", "Jun Huang", "Patrik P. Süli", "Qinghua Ni", "Rui Qin", "Xiao Wang", "Fei-Yue Wang"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.00091v4", "summary": "With the increasing demand for heterogeneous Unmanned Aerial Vehicle (UAV)\nswarms to perform complex tasks in urban environments, system design now faces\nmajor challenges, including efficient semantic understanding, flexible task\nplanning, and the ability to dynamically adjust coordination strategies in\nresponse to evolving environmental conditions and continuously changing task\nrequirements. To address the limitations of existing methods, this paper\nproposes CoordField, a coordination field agent system for coordinating\nheterogeneous drone swarms in complex urban scenarios. In this system, large\nlanguage models (LLMs) is responsible for interpreting high-level human\ninstructions and converting them into executable commands for the UAV swarms,\nsuch as patrol and target tracking. Subsequently, a Coordination field\nmechanism is proposed to guide UAV motion and task selection, enabling\ndecentralized and adaptive allocation of emergent tasks. A total of 50 rounds\nof comparative testing were conducted across different models in a 2D\nsimulation space to evaluate their performance. Experimental results\ndemonstrate that the proposed system achieves superior performance in terms of\ntask coverage, response time, and adaptability to dynamic changes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.00091v4", "cate": "cs.RO", "date": "2025-04-30", "updated": "2025-07-21"}
{"id": "2507.14240", "title": "HuggingGraph: Understanding the Supply Chain of LLM Ecosystem", "authors": ["Mohammad Shahedur Rahman", "Peng Gao", "Yuede Ji"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures", "url": "http://arxiv.org/abs/2507.14240v1", "summary": "Large language models (LLMs) leverage deep learning to process and predict\nsequences of words from context, enabling them to perform various NLP tasks,\nsuch as translation, summarization, question answering, and content generation.\nHowever, the growing size and complexity of developing, training, and deploying\nadvanced LLMs require extensive computational resources and large datasets.\nThis creates a barrier for users. As a result, platforms that host models and\ndatasets are widely used. For example, Hugging Face, one of the most popular\nplatforms, hosted 1.8 million models and 450K datasets by June 2025, with no\nsign of slowing down. Since many LLMs are built from base models, pre-trained\nmodels, and external datasets, they can inherit vulnerabilities, biases, or\nmalicious components from earlier models or datasets. Therefore, it is critical\nto understand the origin and development of these components to better detect\npotential risks, improve model fairness, and ensure compliance. Motivated by\nthis, our project aims to study the relationships between models and datasets,\nwhich are core components of the LLM supply chain. First, we design a method to\nsystematically collect LLM supply chain data. Using this data, we build a\ndirected heterogeneous graph to model the relationships between models and\ndatasets, resulting in a structure with 397,376 nodes and 453,469 edges. We\nthen perform various analyses and uncover several findings, such as: (i) the\nLLM supply chain graph is large, sparse, and follows a power-law degree\ndistribution; (ii) it features a densely connected core and a fragmented\nperiphery; (iii) datasets play pivotal roles in training; (iv) strong\ninterdependence exists between models and datasets; and (v) the graph is\ndynamic, with daily updates reflecting the ecosystem's ongoing evolution.", "comment": "10 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.14240v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14874", "title": "The Tsetlin Machine Goes Deep: Logical Learning and Reasoning With Graphs", "authors": ["Ole-Christoffer Granmo", "Youmna Abdelwahab", "Per-Arne Andersen", "Paul F. A. Clarke", "Kunal Dumbre", "Ylva Grønninsæter", "Vojtech Halenka", "Runar Helin", "Lei Jiao", "Ahmed Khalid", "Rebekka Omslandseter", "Rupsa Saha", "Mayur Shende", "Xuan Zhang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      34 pages, 10 figures", "url": "http://arxiv.org/abs/2507.14874v1", "summary": "Pattern recognition with concise and flat AND-rules makes the Tsetlin Machine\n(TM) both interpretable and efficient, while the power of Tsetlin automata\nenables accuracy comparable to deep learning on an increasing number of\ndatasets. We introduce the Graph Tsetlin Machine (GraphTM) for learning\ninterpretable deep clauses from graph-structured input. Moving beyond flat,\nfixed-length input, the GraphTM gets more versatile, supporting sequences,\ngrids, relations, and multimodality. Through message passing, the GraphTM\nbuilds nested deep clauses to recognize sub-graph patterns with exponentially\nfewer clauses, increasing both interpretability and data utilization. For image\nclassification, GraphTM preserves interpretability and achieves 3.86%-points\nhigher accuracy on CIFAR-10 than a convolutional TM. For tracking action\ncoreference, faced with increasingly challenging tasks, GraphTM outperforms\nother reinforcement learning methods by up to 20.6%-points. In recommendation\nsystems, it tolerates increasing noise to a greater extent than a Graph\nConvolutional Neural Network (GCN), e.g., for noise ratio 0.1, GraphTM obtains\naccuracy 89.86% compared to GCN's 70.87%. Finally, for viral genome sequence\ndata, GraphTM is competitive with BiLSTM-CNN and GCN accuracy-wise, training\n2.5x faster than GCN. The GraphTM's application to these varied fields\ndemonstrates how graph representation learning and deep clauses bring new\npossibilities for TM learning.", "comment": "34 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.14874v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14904", "title": "TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP", "authors": ["Fan Li", "Zanyi Wang", "Zeyi Huang", "Guang Dai", "Jingdong Wang", "Mengmeng Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14904v1", "summary": "3D visual grounding allows an embodied agent to understand visual information\nin real-world 3D environments based on human instructions, which is crucial for\nembodied intelligence. Existing 3D visual grounding methods typically rely on\nseparate encoders for different modalities (e.g., RGB images, text, and 3D\npoint clouds), resulting in large and complex models that are inefficient to\ntrain. While some approaches use pre-trained 2D multi-modal models like CLIP\nfor 3D tasks, they still struggle with aligning point cloud data to 2D\nencoders. As a result, these methods continue to depend on 3D encoders for\nfeature extraction, further increasing model complexity and training\ninefficiency. In this paper, we propose a unified 2D pre-trained multi-modal\nnetwork to process all three modalities (RGB images, text, and point clouds),\nsignificantly simplifying the architecture. By leveraging a 2D CLIP bi-modal\nmodel with adapter-based fine-tuning, this framework effectively adapts to the\ntri-modal setting, improving both adaptability and performance across\nmodalities. Our Geometric-Aware 2D-3D Feature Recovery and Fusion (GARF) module\nis designed to fuse geometric multi-scale features from point clouds and\nimages. We then integrate textual features for final modality fusion and\nintroduce a multi-modal decoder to facilitate deep cross-modal understanding.\nTogether, our method achieves unified feature extraction and fusion across the\nthree modalities, enabling an end-to-end 3D visual grounding model. Compared to\nthe baseline, our method reduces the number of trainable parameters by\napproximately 58\\%, while achieving a 6.52\\% improvement in the 3D detection\ntask and a 6.25\\% improvement in the 3D visual grounding task.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14904v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14299", "title": "Age of Information Minimization in UAV-Enabled Integrated Sensing and Communication Systems", "authors": ["Yu Bai", "Yifan Zhang", "Boxuan Xie", "Zheng Chang", "Yanru Zhang", "Riku Jantti", "Zhu Han"], "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14299v1", "summary": "Unmanned aerial vehicles (UAVs) equipped with integrated sensing and\ncommunication (ISAC) capabilities are envisioned to play a pivotal role in\nfuture wireless networks due to their enhanced flexibility and efficiency.\nHowever, jointly optimizing UAV trajectory planning, multi-user communication,\nand target sensing under stringent resource constraints and time-critical\nconditions remains a significant challenge. To address this, we propose an Age\nof Information (AoI)-centric UAV-ISAC system that simultaneously performs\ntarget sensing and serves multiple ground users, emphasizing information\nfreshness as the core performance metric. We formulate a long-term average AoI\nminimization problem that jointly optimizes the UAV's flight trajectory and\nbeamforming. To tackle the high-dimensional, non-convexity of this problem, we\ndevelop a deep reinforcement learning (DRL)-based algorithm capable of\nproviding real-time decisions on UAV movement and beamforming for both radar\nsensing and multi-user communication. Specifically, a Kalman filter is employed\nfor accurate target state prediction, regularized zero-forcing is utilized to\nmitigate inter-user interference, and the Soft Actor-Critic algorithm is\napplied for training the DRL agent on continuous actions. The proposed\nframework adaptively balances the trade-offs between sensing accuracy and\ncommunication quality. Extensive simulation results demonstrate that our\nproposed method consistently achieves lower average AoI compared to baseline\napproaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14299v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2501.01182", "title": "RingFormer: A Neural Vocoder with Ring Attention and Convolution-Augmented Transformer", "authors": ["Seongho Hong", "Yong-Hoon Choi"], "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted for publication in IEEE Transactions on Human-Machine Systems (THMS)", "url": "http://arxiv.org/abs/2501.01182v2", "summary": "While transformers demonstrate outstanding performance across various audio\ntasks, their application to neural vocoders remains challenging. Neural\nvocoders require the generation of long audio signals at the sample level,\nwhich demands high temporal resolution. This results in significant\ncomputational costs for attention map generation and limits their ability to\nefficiently process both global and local information. Additionally, the\nsequential nature of sample generation in neural vocoders poses difficulties\nfor real-time processing, making the direct adoption of transformers\nimpractical. To address these challenges, we propose RingFormer, a neural\nvocoder that incorporates the ring attention mechanism into a lightweight\ntransformer variant, the convolution-augmented transformer (Conformer). Ring\nattention effectively captures local details while integrating global\ninformation, making it well-suited for processing long sequences and enabling\nreal-time audio generation. RingFormer is trained using adversarial training\nwith two discriminators. The proposed model is applied to the decoder of the\ntext-to-speech model VITS and compared with state-of-the-art vocoders such as\nHiFi-GAN, iSTFT-Net, and BigVGAN under identical conditions using various\nobjective and subjective metrics. Experimental results show that RingFormer\nachieves comparable or superior performance to existing models, particularly\nexcelling in real-time audio generation. Our code and audio samples are\navailable on GitHub.", "comment": "Accepted for publication in IEEE Transactions on Human-Machine\n  Systems (THMS)", "pdf_url": "http://arxiv.org/pdf/2501.01182v2", "cate": "cs.SD", "date": "2025-01-02", "updated": "2025-07-19"}
{"id": "2507.14669", "title": "Dvorak-Dell-Grohe-Rattan theorem via an asymptotic argument", "authors": ["Alexander Kozachinskiy"], "categories": ["math.CO", "cs.DM", "cs.DS"], "primary_category": "Subjects:       Combinatorics (math.CO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14669v1", "summary": "Two graphs $G_1,G_2$ are distinguished by the Weisfeiler--Leman isomorphism\ntest if and only if there is a tree $T$ that has a different number of\nhomomorphisms to $G_1$ and to $G_2$. There are two known proofs of this fact --\na logical proof by Dvorak and a linear-algebraic proof by Dell, Grohe, and\nRattan. We give another simple proof, based on ordering WL-labels and\nasymptotic arguments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14669v1", "cate": "math.CO", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15267", "title": "GREAT: Guiding Query Generation with a Trie for Recommending Related Search about Video at Kuaishou", "authors": ["Ninglu Shao", "Jinshan Wang", "Chenxu Wang", "Qingbiao Li", "Xiaoxue Zang", "Han Li"], "categories": ["cs.IR", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15267v1", "summary": "Currently, short video platforms have become the primary place for\nindividuals to share experiences and obtain information. To better meet users'\nneeds for acquiring information while browsing short videos, some apps have\nintroduced a search entry at the bottom of videos, accompanied with recommended\nrelevant queries. This scenario is known as query recommendation in\nvideo-related search, where core task is item-to-query (I2Q) recommendation. As\nthis scenario has only emerged in recent years, there is a notable scarcity of\nacademic research and publicly available datasets in this domain. To address\nthis gap, we systematically examine the challenges associated with this\nscenario for the first time. Subsequently, we release a large-scale dataset\nderived from real-world data pertaining to the query recommendation in\nvideo-\\textit{\\textbf{r}}elated \\textit{\\textbf{s}}earch on the\n\\textit{\\textbf{Kuai}}shou app (\\textbf{KuaiRS}). Presently, existing methods\nrely on embeddings to calculate similarity for matching short videos with\nqueries, lacking deep interaction between the semantic content and the query.\nIn this paper, we introduce a novel LLM-based framework named \\textbf{GREAT},\nwhich \\textit{\\textbf{g}}uides que\\textit{\\textbf{r}}y\ng\\textit{\\textbf{e}}ner\\textit{\\textbf{a}}tion with a \\textit{\\textbf{t}}rie to\naddress I2Q recommendation in related search. Specifically, we initially gather\nhigh-quality queries with high exposure and click-through rate to construct a\nquery-based trie. During training, we enhance the LLM's capability to generate\nhigh-quality queries using the query-based trie. In the inference phase, the\nquery-based trie serves as a guide for the token generation. Finally, we\nfurther refine the relevance and literal quality between items and queries via\na post-processing module. Extensive offline and online experiments demonstrate\nthe effectiveness of our proposed method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15267v1", "cate": "cs.IR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15132", "title": "Transforming Datasets to Requested Complexity with Projection-based Many-Objective Genetic Algorithm", "authors": ["Joanna Komorniczak"], "categories": ["cs.LG", "cs.NE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15132v1", "summary": "The research community continues to seek increasingly more advanced synthetic\ndata generators to reliably evaluate the strengths and limitations of machine\nlearning methods. This work aims to increase the availability of datasets\nencompassing a diverse range of problem complexities by proposing a genetic\nalgorithm that optimizes a set of problem complexity measures for\nclassification and regression tasks towards specific targets. For\nclassification, a set of 10 complexity measures was used, while for regression\ntasks, 4 measures demonstrating promising optimization capabilities were\nselected. Experiments confirmed that the proposed genetic algorithm can\ngenerate datasets with varying levels of difficulty by transforming\nsynthetically created datasets to achieve target complexity values through\nlinear feature projections. Evaluations involving state-of-the-art classifiers\nand regressors revealed a correlation between the complexity of the generated\ndata and the recognition quality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15132v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14488", "title": "Entropy Stable Nodal Discontinuous Galerkin Methods via Quadratic Knapsack Limiting", "authors": ["Brian Christner", "Jesse Chan"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14488v1", "summary": "Lin, Chan (High order entropy stable discontinuous Galerkin spectral element\nmethods through subcell limiting, 2024) enforces a cell entropy inequality for\nnodal discontinuous Galerkin methods by combining flux corrected transport\n(FCT)-type limiting and a knapsack solver, which determines optimal limiting\ncoefficients that result in a semi-discrete cell entropy inequality while\npreserving nodal bounds. In this work, we provide a slight modification of this\napproach, where we utilize a quadratic knapsack problem instead of a standard\nlinear knapsack problem. We prove that this quadratic knapsack problem can be\nreduced to efficient scalar root-finding. Numerical results demonstrate that\nthe proposed quadratic knapsack limiting strategy is efficient and results in a\nsemi-discretization with improved regularity in time compared with linear\nknapsack limiting, while resulting in fewer adaptive timesteps in shock-type\nproblems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14488v1", "cate": "math.NA", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15294", "title": "MeMo: Attentional Momentum for Real-time Audio-visual Speaker Extraction under Impaired Visual Conditions", "authors": ["Junjie Li", "Wenxuan Wu", "Shuai Wang", "Zexu Pan", "Kong Aik Lee", "Helen Meng", "Haizhou Li"], "categories": ["cs.SD", "cs.MM"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15294v1", "summary": "Audio-visual Target Speaker Extraction (AV-TSE) aims to isolate a target\nspeaker's voice from multi-speaker environments by leveraging visual cues as\nguidance. However, the performance of AV-TSE systems heavily relies on the\nquality of these visual cues. In extreme scenarios where visual cues are\nmissing or severely degraded, the system may fail to accurately extract the\ntarget speaker. In contrast, humans can maintain attention on a target speaker\neven in the absence of explicit auxiliary information. Motivated by such human\ncognitive ability, we propose a novel framework called MeMo, which incorporates\ntwo adaptive memory banks to store attention-related information. MeMo is\nspecifically designed for real-time scenarios: once initial attention is\nestablished, the system maintains attentional momentum over time, even when\nvisual cues become unavailable. We conduct comprehensive experiments to verify\nthe effectiveness of MeMo. Experimental results demonstrate that our proposed\nframework achieves SI-SNR improvements of at least 2 dB over the corresponding\nbaseline.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15294v1", "cate": "cs.SD", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2505.00306", "title": "J-PARSE: Jacobian-based Projection Algorithm for Resolving Singularities Effectively in Inverse Kinematic Control of Serial Manipulators", "authors": ["Shivani Guptasarma", "Matthew Strong", "Honghao Zhen", "Monroe Kennedy III"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      18 pages, 25 figures. v1: Fig. 1 replaced with faster-loading version. v2: Website at this https URL", "url": "http://arxiv.org/abs/2505.00306v3", "summary": "J-PARSE is a method for smooth first-order inverse kinematic control of a\nserial manipulator near kinematic singularities. The commanded end-effector\nvelocity is interpreted component-wise, according to the available mobility in\neach dimension of the task space. First, a substitute \"Safety\" Jacobian matrix\nis created, keeping the aspect ratio of the manipulability ellipsoid above a\nthreshold value. The desired motion is then projected onto non-singular and\nsingular directions, and the latter projection scaled down by a factor informed\nby the threshold value. A right-inverse of the non-singular Safety Jacobian is\napplied to the modified command. In the absence of joint limits and collisions,\nthis ensures smooth transition into and out of low-rank poses, guaranteeing\nasymptotic stability for target poses within the workspace, and stability for\nthose outside. Velocity control with J-PARSE is benchmarked against the\nLeast-Squares and Damped Least-Squares inversions of the Jacobian, and shows\nhigh accuracy in reaching and leaving singular target poses. By expanding the\navailable workspace of manipulators, the method finds applications in servoing,\nteleoperation, and learning. Videos and code are available at\nhttps://jparse-manip.github.io/.", "comment": "18 pages, 25 figures. v1: Fig. 1 replaced with faster-loading\n  version. v2: Website at https://jparse-manip.github.io/", "pdf_url": "http://arxiv.org/pdf/2505.00306v3", "cate": "cs.RO", "date": "2025-05-01", "updated": "2025-07-18"}
{"id": "2507.14241", "title": "Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models", "authors": ["Rithesh Murthy", "Ming Zhu", "Liangwei Yang", "Jielin Qiu", "Juntao Tan", "Shelby Heinecke", "Huan Wang", "Caiming Xiong", "Silvio Savarese"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14241v1", "summary": "Large Language Models (LLMs) perform best with well-crafted prompts, yet\nprompt engineering remains manual, inconsistent, and inaccessible to\nnon-experts. We introduce Promptomatix, an automatic prompt optimization\nframework that transforms natural language task descriptions into high-quality\nprompts without requiring manual tuning or domain expertise. Promptomatix\nsupports both a lightweight meta-prompt-based optimizer and a DSPy-powered\ncompiler, with modular design enabling future extension to more advanced\nframeworks. The system analyzes user intent, generates synthetic training data,\nselects prompting strategies, and refines prompts using cost-aware objectives.\nEvaluated across 5 task categories, Promptomatix achieves competitive or\nsuperior performance compared to existing libraries, while reducing prompt\nlength and computational overhead making prompt optimization scalable and\nefficient.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14241v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.14882", "title": "Application-Specific Component-Aware Structured Pruning of Deep Neural Networks via Soft Coefficient Optimization", "authors": ["Ganesh Sundaram", "Jonas Ulmen", "Amjad Haider", "Daniel Görges"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      6 pages, 22nd International Conference on Advanced Robotics (ICAR 2025)", "url": "http://arxiv.org/abs/2507.14882v1", "summary": "Deep neural networks (DNNs) offer significant versatility and performance\nbenefits, but their widespread adoption is often hindered by high model\ncomplexity and computational demands. Model compression techniques such as\npruning have emerged as promising solutions to these challenges. However, it\nremains critical to ensure that application-specific performance\ncharacteristics are preserved during compression. In structured pruning, where\ngroups of structurally coherent elements are removed, conventional importance\nmetrics frequently fail to maintain these essential performance attributes. In\nthis work, we propose an enhanced importance metric framework that not only\nreduces model size but also explicitly accounts for application-specific\nperformance constraints. We employ multiple strategies to determine the optimal\npruning magnitude for each group, ensuring a balance between compression and\ntask performance. Our approach is evaluated on an autoencoder tasked with\nreconstructing MNIST images. Experimental results demonstrate that the proposed\nmethod effectively preserves task-relevant performance, maintaining the model's\nusability even after substantial pruning, by satisfying the required\napplication-specific criteria.", "comment": "6 pages, 22nd International Conference on Advanced Robotics (ICAR\n  2025)", "pdf_url": "http://arxiv.org/pdf/2507.14882v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14918", "title": "Semantic-Aware Representation Learning for Multi-label Image Classification", "authors": ["Ren-Dong Xie", "Zhi-Fen He", "Bo Li", "Bin Liu", "Jin-Yan Hu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14918v1", "summary": "Multi-label image classification, an important research area in computer\nvision, focuses on identifying multiple labels or concepts within an image.\nExisting approaches often employ attention mechanisms or graph convolutional\nnetworks (GCNs) to learn image representation. However, this representation may\ncontain noise and may not locate objects precisely. Therefore, this paper\nproposes a Semantic-Aware Representation Learning (SARL) for multi-label image\nclassification. First, a label semantic-related feature learning module is\nutilized to extract semantic-related features. Then, an optimal transport-based\nattention mechanism is designed to obtain semantically aligned image\nrepresentation. Finally, a regional score aggregation strategy is used for\nmulti-label prediction. Experimental results on two benchmark datasets, PASCAL\nVOC 2007 and MS-COCO, demonstrate the superiority of SARL over existing\nmethods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14918v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14309", "title": "Fast and Robust Stationary Crowd Counting with Commodity WiFi", "authors": ["Mert Torun", "Alireza Parsay", "Yasamin Mostofi"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14309v1", "summary": "This paper introduces a novel method for estimating the size of seated crowds\nwith commodity WiFi signals, by leveraging natural body fidgeting behaviors as\na passive sensing cue. Departing from prior binary fidget representations, our\napproach leverages the bandwidth of the received signal as a finer-grained and\nrobust indicator of crowd counts. More specifically, we propose a mathematical\nmodel that relates the probability density function (PDF) of the signal\nbandwidth to the crowd size, using a principled derivation based on the PDF of\nan individual's fidget-induced bandwidth. To characterize the individual\nfidgeting PDF, we use publicly available online videos, each of a seated\nindividual, from which we extract body motion profiles using vision techniques,\nfollowed by a speed-to-bandwidth conversion inspired by Carson's Rule from\nanalog FM radio design. Finally, to enhance robustness in real-world\ndeployments where unrelated motions may occur nearby, we further introduce an\nanomaly detection module that filters out non-fidget movements. We validate our\nsystem through 42 experiments across two indoor environments with crowd sizes\nup to and including 13 people, achieving a mean absolute error of 1.04 and a\nnormalized mean square error of 0.15, with an average convergence time of 51\nseconds, significantly reducing the convergence time as compared to the state\nof the art. Additional simulation results demonstrate scalability to larger\ncrowd sizes. Overall, our results show that our pipeline enables fast, robust,\nand highly accurate counting of seated crowds.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14309v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2503.06273", "title": "Zero-AVSR: Zero-Shot Audio-Visual Speech Recognition with LLMs by Learning Language-Agnostic Speech Representations", "authors": ["Jeong Hun Yeo", "Minsu Kim", "Chae Won Kim", "Stavros Petridis", "Yong Man Ro"], "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025. Code available at: this https URL", "url": "http://arxiv.org/abs/2503.06273v2", "summary": "We explore a novel zero-shot Audio-Visual Speech Recognition (AVSR)\nframework, dubbed Zero-AVSR, which enables speech recognition in target\nlanguages without requiring any audio-visual speech data in those languages.\nSpecifically, we introduce the Audio-Visual Speech Romanizer (AV-Romanizer),\nwhich learns language-agnostic speech representations by predicting Roman text.\nThen, by leveraging the strong multilingual modeling capabilities of Large\nLanguage Models (LLMs), we propose converting the predicted Roman text into\nlanguage-specific graphemes, forming the proposed Cascaded Zero-AVSR. Taking it\na step further, we explore a unified Zero-AVSR approach by directly integrating\nthe audio-visual speech representations encoded by the AV-Romanizer into the\nLLM. This is achieved through finetuning the adapter and the LLM using our\nproposed multi-task learning scheme. To capture the wide spectrum of phonetic\nand linguistic diversity, we also introduce a Multilingual Audio-Visual\nRomanized Corpus (MARC) consisting of 2,916 hours of audio-visual speech data\nacross 82 languages, along with transcriptions in both language-specific\ngraphemes and Roman text. Extensive analysis and experiments confirm that the\nproposed Zero-AVSR framework has the potential to expand language support\nbeyond the languages seen during the training of the AV-Romanizer.", "comment": "Accepted at ICCV 2025. Code available at:\n  https://github.com/JeongHun0716/zero-avsr", "pdf_url": "http://arxiv.org/pdf/2503.06273v2", "cate": "cs.CV", "date": "2025-03-08", "updated": "2025-07-21"}
{"id": "2507.14957", "title": "Probing EFX via PMMS: (Non-)Existence Results in Discrete Fair Division", "authors": ["Jarosław Byrka", "Franciszek Malinka", "Tomasz Ponitka"], "categories": ["cs.GT", "cs.AI", "cs.DS"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "Comments:      27 pages, 4 figures", "url": "http://arxiv.org/abs/2507.14957v1", "summary": "We study the fair division of indivisible items and provide new insights into\nthe EFX problem, which is widely regarded as the central open question in fair\ndivision, and the PMMS problem, a strictly stronger variant of EFX. Our first\nresult constructs a three-agent instance with two monotone valuations and one\nadditive valuation in which no PMMS allocation exists. Since EFX allocations\nare known to exist under these assumptions, this establishes a formal\nseparation between EFX and PMMS.\n  We prove existence of fair allocations for three important special cases. We\nshow that EFX allocations exist for personalized bivalued valuations, where for\neach agent $i$ there exist values $a_i > b_i$ such that agent $i$ assigns value\n$v_i(\\{g\\}) \\in \\{a_i, b_i\\}$ to each good $g$. We establish an analogous\nexistence result for PMMS allocations when $a_i$ is divisible by $b_i$. We also\nprove that PMMS allocations exist for binary-valued MMS-feasible valuations,\nwhere each bundle $S$ has value $v_i(S) \\in \\{0, 1\\}$. Notably, this result\nholds even without assuming monotonicity of valuations and thus applies to the\nfair division of chores and mixed manna. Finally, we study a class of\nvaluations called pair-demand valuations, which extend the well-studied\nunit-demand valuations to the case where each agent derives value from at most\ntwo items, and we show that PMMS allocations exist in this setting. Our proofs\nare constructive, and we provide polynomial-time algorithms for all three\nexistence results.", "comment": "27 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.14957v1", "cate": "cs.GT", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15395", "title": "Hierarchical Graph Information Bottleneck for Multi-Behavior Recommendation", "authors": ["Hengyu Zhang", "Chunxu Shen", "Xiangguo Sun", "Jie Tan", "Yanchao Tan", "Yu Rong", "Hong Cheng", "Lingling Yi"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted by RecSys2025", "url": "http://arxiv.org/abs/2507.15395v1", "summary": "In real-world recommendation scenarios, users typically engage with platforms\nthrough multiple types of behavioral interactions. Multi-behavior\nrecommendation algorithms aim to leverage various auxiliary user behaviors to\nenhance prediction for target behaviors of primary interest (e.g., buy),\nthereby overcoming performance limitations caused by data sparsity in target\nbehavior records. Current state-of-the-art approaches typically employ\nhierarchical design following either cascading (e.g.,\nview$\\rightarrow$cart$\\rightarrow$buy) or parallel\n(unified$\\rightarrow$behavior$\\rightarrow$specific components) paradigms, to\ncapture behavioral relationships. However, these methods still face two\ncritical challenges: (1) severe distribution disparities across behaviors, and\n(2) negative transfer effects caused by noise in auxiliary behaviors. In this\npaper, we propose a novel model-agnostic Hierarchical Graph Information\nBottleneck (HGIB) framework for multi-behavior recommendation to effectively\naddress these challenges. Following information bottleneck principles, our\nframework optimizes the learning of compact yet sufficient representations that\npreserve essential information for target behavior prediction while eliminating\ntask-irrelevant redundancies. To further mitigate interaction noise, we\nintroduce a Graph Refinement Encoder (GRE) that dynamically prunes redundant\nedges through learnable edge dropout mechanisms. We conduct comprehensive\nexperiments on three real-world public datasets, which demonstrate the superior\neffectiveness of our framework. Beyond these widely used datasets in the\nacademic community, we further expand our evaluation on several real industrial\nscenarios and conduct an online A/B testing, showing again a significant\nimprovement in multi-behavior recommendations. The source code of our proposed\nHGIB is available at https://github.com/zhy99426/HGIB.", "comment": "Accepted by RecSys2025", "pdf_url": "http://arxiv.org/pdf/2507.15395v1", "cate": "cs.IR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15486", "title": "The Role of Excitatory Parvalbumin-positive Neurons in the Tectofugal Pathway of Pigeon (Columba livia) Hierarchical Visual Processing", "authors": ["Shan Lu", "Xiaoteng Zhang", "Yueyang Cang", "Shihao Pan", "Yanyan Peng", "Xinwei Li", "Shaoju Zeng", "Yingjie Zhu", "Li Shi"], "categories": ["q-bio.NC", "cs.NE"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15486v1", "summary": "The visual systems of birds and mammals exhibit remarkable organizational\nsimilarities: the dorsal ventricular ridge (DVR) demonstrates a columnar\nmicrocircuitry that parallels the cortical architecture observed in mammals.\nHowever, the specific neuronal subtypes involved and their functional roles in\npigeon hierarchical visual processing remain unclear. This study investigates\nthe role of excitatory parvalbumin (PV+) neurons within the Ento-MVL\n(entoallium-mesopallium venterolaterale) circuit of pigeons underlying\nhierarchical moving target recognition. Electrophysiological recordings and\nimmunofluorescence staining reveal that excitatory PV+ neurons originating from\nthe entopallial internal (Ei) predominantly modulate MVL responses to varying\nvisual stimuli. Using a heterochronous-speed recurrent neural network (HS-RNN)\nmodel, we further validated these dynamics, replicating the rapid adaptation of\nthe Ento-MVL circuit to moving visual targets. The findings suggest that the\nfast-spiking and excitatory properties of PV+ neurons enable rapid processing\nof motion-related information within the Ento-MVL circuit. Our results\nelucidate the functional role of excitatory PV+ neurons in hierarchical\ninformation processing under the columnar organization of the visual DVR and\nunderscore the convergent neural processing strategies shared by avian and\nmammalian visual systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15486v1", "cate": "q-bio.NC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14491", "title": "Numerical Artifacts in Learning Dynamical Systems", "authors": ["Bing-Ze Lu", "Richard Tsai"], "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14491v1", "summary": "In many applications, one needs to learn a dynamical system from its\nsolutions sampled at a finite number of time points. The learning problem is\noften formulated\n  as an optimization problem over a chosen function class. However, in the\noptimization procedure, it is necessary to employ a numerical scheme to\nintegrate candidate dynamical systems and assess how their solutions fit the\ndata.\n  This paper reveals potentially serious effects of a chosen numerical scheme\non the learning outcome. In particular, our analysis demonstrates that a damped\noscillatory system may be incorrectly identified as having \"anti-damping\" and\nexhibiting a reversed oscillation direction, despite adequately fitting the\ngiven data points.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14491v1", "cate": "math.NA", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.09116", "title": "Mixture of LoRA Experts with Multi-Modal and Multi-Granularity LLM Generative Error Correction for Accented Speech Recognition", "authors": ["Bingshen Mu", "Kun Wei", "Pengcheng Guo", "Lei Xie"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      IEEE Transactions on Audio, Speech and Language Processing", "url": "http://arxiv.org/abs/2507.09116v3", "summary": "Despite improvements in automatic speech recognition, performance drops with\naccented speech. Generative error correction (GER) leverages the linguistic\nknowledge of large language models (LLMs), outperforming typical language model\nmethods. However, it lacks specificity in accented speech scenarios. Accents\nrepresent deviations from standard pronunciation, making multi-granularity\npronunciation and semantic information essential for accented speech\nrecognition. Moreover, accents exhibit considerable diversity, with each accent\npossessing distinct characteristics. In this study, we leverage GER to improve\ntranscription accuracy by addressing the two primary features. We propose the\nmulti-modal GER, which integrates pronunciation information from the speech\nmodality, and the multi-granularity GER, which incorporates fine-grained\nphoneme-level pronunciation information. These methods enable the LLM to\nutilize the pronunciation information of accented speech and the semantic\ninformation from word-level hypotheses for accurate transcription predictions\nthrough low-rank adaptation (LoRA) fine-tuning. We employ a three-stage\nstrategy to train separate multi-modal GER models for each accent to obtain\nmono-accent LoRA experts. By adopting our proposed HDMoLE method, which\nincorporates hierarchical routing and dynamic thresholds within the mixture of\nLoRA experts, we effectively merge mono-accent LoRA experts within a single\nmulti-modal GER to overcome accent diversity challenges. Furthermore,\nmulti-granularity GER leverages N-best word-level and phoneme-level hypotheses\nfrom the HDMoLE model to predict final transcriptions. Experiments on a\nmulti-accent English dataset show that our methods reduce word error rate by\n67.35% compared to the baseline vanilla Whisper-large-v3 model.", "comment": "IEEE Transactions on Audio, Speech and Language Processing", "pdf_url": "http://arxiv.org/pdf/2507.09116v3", "cate": "cs.SD", "date": "2025-07-12", "updated": "2025-07-19"}
{"id": "2505.03233", "title": "GraspVLA: a Grasping Foundation Model Pre-trained on Billion-scale Synthetic Action Data", "authors": ["Shengliang Deng", "Mi Yan", "Songlin Wei", "Haixin Ma", "Yuxin Yang", "Jiayi Chen", "Zhiqi Zhang", "Taoyu Yang", "Xuheng Zhang", "Heming Cui", "Zhizheng Zhang", "He Wang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.03233v2", "summary": "Embodied foundation models are gaining increasing attention for their\nzero-shot generalization, scalability, and adaptability to new tasks through\nfew-shot post-training. However, existing models rely heavily on real-world\ndata, which is costly and labor-intensive to collect. Synthetic data offers a\ncost-effective alternative, yet its potential remains largely underexplored. To\nbridge this gap, we explore the feasibility of training Vision-Language-Action\nmodels entirely with large-scale synthetic action data. We curate SynGrasp-1B,\na billion-frame robotic grasping dataset generated in simulation with\nphotorealistic rendering and extensive domain randomization. Building on this,\nwe present GraspVLA, a VLA model pretrained on large-scale synthetic action\ndata as a foundational model for grasping tasks. GraspVLA integrates\nautoregressive perception tasks and flow-matching-based action generation into\na unified Chain-of-Thought process, enabling joint training on synthetic action\ndata and Internet semantics data. This design helps mitigate sim-to-real gaps\nand facilitates the transfer of learned actions to a broader range of\nInternet-covered objects, achieving open-vocabulary generalization in grasping.\nExtensive evaluations across real-world and simulation benchmarks demonstrate\nGraspVLA's advanced zero-shot generalizability and few-shot adaptability to\nspecific human preferences. We will release SynGrasp-1B dataset and pre-trained\nweights to benefit the community.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.03233v2", "cate": "cs.RO", "date": "2025-05-06", "updated": "2025-07-19"}
{"id": "2507.14266", "title": "Bridging MOOCs, Smart Teaching, and AI: A Decade of Evolution Toward a Unified Pedagogy", "authors": ["Bo Yuan", "Jiazi Hu"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14266v1", "summary": "Over the past decade, higher education has evolved through three distinct\nparadigms: the emergence of Massive Open Online Courses (MOOCs), the\nintegration of Smart Teaching technologies into classrooms, and the rise of\nAI-enhanced learning. Each paradigm is intended to address specific challenges\nin traditional education: MOOCs enable ubiquitous access to learning resources;\nSmart Teaching supports real-time interaction with data-driven insights; and\ngenerative AI offers personalized feedback and on-demand content generation.\nHowever, these paradigms are often implemented in isolation due to their\ndisparate technological origins and policy-driven adoption. This paper examines\nthe origins, strengths, and limitations of each paradigm, and advocates a\nunified pedagogical perspective that synthesizes their complementary\naffordances. We propose a three-layer instructional framework that combines the\nscalability of MOOCs, the responsiveness of Smart Teaching, and the adaptivity\nof AI. To demonstrate its feasibility, we present a curriculum design for a\nproject-based course. The findings highlight the framework's potential to\nenhance learner engagement, support instructors, and enable personalized yet\nscalable learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14266v1", "cate": "cs.CY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14919", "title": "Old Rules in a New Game: Mapping Uncertainty Quantification to Quantum Machine Learning", "authors": ["Maximilian Wendlinger", "Kilian Tscharke", "Pascal Debus"], "categories": ["cs.LG", "quant-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14919v1", "summary": "One of the key obstacles in traditional deep learning is the reduction in\nmodel transparency caused by increasingly intricate model functions, which can\nlead to problems such as overfitting and excessive confidence in predictions.\nWith the advent of quantum machine learning offering possible advances in\ncomputational power and latent space complexity, we notice the same opaque\nbehavior. Despite significant research in classical contexts, there has been\nlittle advancement in addressing the black-box nature of quantum machine\nlearning. Consequently, we approach this gap by building upon existing work in\nclassical uncertainty quantification and initial explorations in quantum\nBayesian modeling to theoretically develop and empirically evaluate techniques\nto map classical uncertainty quantification methods to the quantum machine\nlearning domain. Our findings emphasize the necessity of leveraging classical\ninsights into uncertainty quantification to include uncertainty awareness in\nthe process of designing new quantum machine learning models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14919v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14921", "title": "Stereo-GS: Multi-View Stereo Vision Model for Generalizable 3D Gaussian Splatting Reconstruction", "authors": ["Xiufeng Huang", "Ka Chun Cheung", "Runmin Cong", "Simon See", "Renjie Wan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ACMMM2025. Non-camera-ready version", "url": "http://arxiv.org/abs/2507.14921v1", "summary": "Generalizable 3D Gaussian Splatting reconstruction showcases advanced\nImage-to-3D content creation but requires substantial computational resources\nand large datasets, posing challenges to training models from scratch. Current\nmethods usually entangle the prediction of 3D Gaussian geometry and appearance,\nwhich rely heavily on data-driven priors and result in slow regression speeds.\nTo address this, we propose \\method, a disentangled framework for efficient 3D\nGaussian prediction. Our method extracts features from local image pairs using\na stereo vision backbone and fuses them via global attention blocks. Dedicated\npoint and Gaussian prediction heads generate multi-view point-maps for geometry\nand Gaussian features for appearance, combined as GS-maps to represent the 3DGS\nobject. A refinement network enhances these GS-maps for high-quality\nreconstruction. Unlike existing methods that depend on camera parameters, our\napproach achieves pose-free 3D reconstruction, improving robustness and\npracticality. By reducing resource demands while maintaining high-quality\noutputs, \\method provides an efficient, scalable solution for real-world 3D\ncontent generation.", "comment": "ACMMM2025. Non-camera-ready version", "pdf_url": "http://arxiv.org/pdf/2507.14921v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14310", "title": "Optimizing Network Performance and Resource Allocation in HAPS-UAV Integrated Sensing and Communication Systems for 6G", "authors": ["Parisa Kanani", "Mohammad Javad Omidi", "Mahmoud Modarres-Hashemi", "Halim Yanikomeroglu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14310v1", "summary": "This paper proposes an innovative approach by leveraging uncrewed aerial\nvehicles (UAVs) as base stations (BSs) and a high-altitude platform station\n(HAPS) as the central processing unit (CPU) in an integrated sensing and\ncommunication (ISAC) system for 6G networks. We explore the challenges,\napplications, and advantages of ISAC systems in next-generation networks,\nhighlighting the significance of optimizing position and power control. Our\napproach integrates HAPS and UAVs to enhance wireless coverage, particularly in\nremote areas. UAVs function as dual-purpose access points (APs), using their\nmaneuverability and line-of-sight (LoS) aerial-to-ground (A2G) links to\ntransmit combined communication and sensing signals. The scheme operates in two\ntime slots: in the first slot, UAVs transmit dedicated signals to communication\nusers (CUs) and potential targets. UAVs detect targets in specific ground\nlocations and, after signal transmission, receive reflected signals from\ntargets. In the second slot, UAVs relay these signals to HAPS, which performs\nbeamforming to align signals for each CU from various UAVs. UAVs decode\ninformation from HAPS and adjust transmissions to maximize the beam pattern\nefficiency toward the desired targets. We formulate a multi-objective\noptimization problem to maximize both the minimum\nsignal-to-interference-plus-noise ratio (SINR) for CUs and the echo signal\npower from the targets. This is achieved by finding the optimal power\nallocation for CUs in each UAV, subject to constraints on the maximum total\npower in each UAV and the transmitted beam pattern gain. Simulation results\ndemonstrate the effectiveness of this approach in enhancing network\nperformance, resource allocation, fairness, and system optimization. Using HAPS\nas the CPU, computational tasks are offloaded from UAVs, which conserves energy\nand improves network performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14310v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2506.14571", "title": "The Perception of Phase Intercept Distortion and its Application in Data Augmentation", "authors": ["Venkatakrishnan Vaidyanathapuram Krishnan", "Nathaniel Condit-Schultz"], "categories": ["eess.SP", "cs.LG", "eess.AS"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted to the IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) 2025. Camera-ready version", "url": "http://arxiv.org/abs/2506.14571v2", "summary": "Phase distortion refers to the alteration of the phase relationships between\nfrequencies in a signal, which can be perceptible. In this paper, we discuss a\nspecial case of phase distortion known as phase-intercept distortion, which is\ncreated by a frequency-independent phase shift. We hypothesize that, though\nthis form of distortion changes a signal's waveform significantly, the\ndistortion is imperceptible. Human-subject experiment results are reported\nwhich are consistent with this hypothesis. Furthermore, we discuss how the\nimperceptibility of phase-intercept distortion can be useful for machine\nlearning, specifically for data augmentation. We conducted multiple experiments\nusing phase-intercept distortion as a novel approach to data augmentation, and\nobtained improved results for audio machine learning tasks.", "comment": "Accepted to the IEEE Workshop on Applications of Signal Processing to\n  Audio and Acoustics (WASPAA) 2025. Camera-ready version", "pdf_url": "http://arxiv.org/pdf/2506.14571v2", "cate": "eess.SP", "date": "2025-06-17", "updated": "2025-07-19"}
{"id": "2507.15173", "title": "Better Models and Algorithms for Learning Ising Models from Dynamics", "authors": ["Jason Gaitonde", "Ankur Moitra", "Elchanan Mossel"], "categories": ["cs.LG", "cs.DS", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      49 pages", "url": "http://arxiv.org/abs/2507.15173v1", "summary": "We study the problem of learning the structure and parameters of the Ising\nmodel, a fundamental model of high-dimensional data, when observing the\nevolution of an associated Markov chain. A recent line of work has studied the\nnatural problem of learning when observing an evolution of the well-known\nGlauber dynamics [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018,\nGaitonde, Mossel STOC 2024], which provides an arguably more realistic\ngenerative model than the classical i.i.d. setting. However, this prior work\ncrucially assumes that all site update attempts are observed, \\emph{even when\nthis attempt does not change the configuration}: this strong observation model\nis seemingly essential for these approaches. While perhaps possible in\nrestrictive contexts, this precludes applicability to most realistic settings\nwhere we can observe \\emph{only} the stochastic evolution itself, a minimal and\nnatural assumption for any process we might hope to learn from. However,\ndesigning algorithms that succeed in this more realistic setting has remained\nan open problem [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018,\nGaitonde, Moitra, Mossel, STOC 2025].\n  In this work, we give the first algorithms that efficiently learn the Ising\nmodel in this much more natural observation model that only observes when the\nconfiguration changes. For Ising models with maximum degree $d$, our algorithm\nrecovers the underlying dependency graph in time $\\mathsf{poly}(d)\\cdot n^2\\log\nn$ and then the actual parameters in additional $\\widetilde{O}(2^d n)$ time,\nwhich qualitatively matches the state-of-the-art even in the i.i.d. setting in\na much weaker observation model. Our analysis holds more generally for a\nbroader class of reversible, single-site Markov chains that also includes the\npopular Metropolis chain by leveraging more robust properties of reversible\nMarkov chains.", "comment": "49 pages", "pdf_url": "http://arxiv.org/pdf/2507.15173v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15551", "title": "RankMixer: Scaling Up Ranking Models in Industrial Recommenders", "authors": ["Jie Zhu", "Zhifang Fan", "Xiaoxie Zhu", "Yuchen Jiang", "Hangyu Wang", "Xintian Han", "Haoran Ding", "Xinmin Wang", "Wenlin Zhao", "Zhen Gong", "Huizhi Yang", "Zheng Chai", "Zhe Chen", "Yuchao Zheng", "Qiwei Chen", "Feng Zhang", "Xun Zhou", "Peng Xu", "Xiao Yang", "Di Wu", "Zuotao Liu"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15551v1", "summary": "Recent progress on large language models (LLMs) has spurred interest in\nscaling up recommendation systems, yet two practical obstacles remain. First,\ntraining and serving cost on industrial Recommenders must respect strict\nlatency bounds and high QPS demands. Second, most human-designed\nfeature-crossing modules in ranking models were inherited from the CPU era and\nfail to exploit modern GPUs, resulting in low Model Flops Utilization (MFU) and\npoor scalability. We introduce RankMixer, a hardware-aware model design\ntailored towards a unified and scalable feature-interaction architecture.\nRankMixer retains the transformer's high parallelism while replacing quadratic\nself-attention with multi-head token mixing module for higher efficiency.\nBesides, RankMixer maintains both the modeling for distinct feature subspaces\nand cross-feature-space interactions with Per-token FFNs. We further extend it\nto one billion parameters with a Sparse-MoE variant for higher ROI. A dynamic\nrouting strategy is adapted to address the inadequacy and imbalance of experts\ntraining. Experiments show RankMixer's superior scaling abilities on a\ntrillion-scale production dataset. By replacing previously diverse handcrafted\nlow-MFU modules with RankMixer, we boost the model MFU from 4.5% to 45%, and\nscale our ranking model parameters by 100x while maintaining roughly the same\ninference latency. We verify RankMixer's universality with online A/B tests\nacross three core application scenarios (Recommendation, Advertisement and\nSearch). Finally, we launch 1B Dense-Parameters RankMixer for full traffic\nserving without increasing the serving cost, which improves user active days by\n0.2% and total in-app usage duration by 0.5%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15551v1", "cate": "cs.IR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2410.09218", "title": "Continual Learning with Neuromorphic Computing: Foundations, Methods, and Emerging Applications", "authors": ["Mishal Fatima Minhas", "Rachmad Vidya Wicaksana Putra", "Falah Awwad", "Osman Hasan", "Muhammad Shafique"], "categories": ["cs.NE", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      This work has been accepted for publication in IEEE Access", "url": "http://arxiv.org/abs/2410.09218v3", "summary": "The challenging deployment of compute- and memory-intensive methods from Deep\nNeural Network (DNN)-based Continual Learning (CL) underscores the critical\nneed for a paradigm shift towards more efficient approaches. Neuromorphic\nContinual Learning (NCL) appears as an emerging solution, by leveraging the\nprinciples of Spiking Neural Networks (SNNs) which enable efficient CL\nalgorithms executed in dynamically-changed environments with\nresource-constrained computing systems. Motivated by the need for a holistic\nstudy of NCL, in this survey, we first provide a detailed background on CL,\nencompassing the desiderata, settings, metrics, scenario taxonomy, Online\nContinual Learning (OCL) paradigm, recent DNN-based methods to address\ncatastrophic forgetting (CF). Then, we analyze these methods considering CL\ndesiderata, computational and memory costs, as well as network complexity,\nhence emphasizing the need for energy-efficient CL. Afterward, we provide\nbackground of low-power neuromorphic systems including encoding techniques,\nneuronal dynamics, network architectures, learning rules, hardware processors,\nsoftware and hardware frameworks, datasets, benchmarks, and evaluation metrics.\nThen, this survey comprehensively reviews and analyzes state-of-the-art in NCL.\nThe key ideas, implementation frameworks, and performance assessments are also\nprovided. This survey covers several hybrid approaches that combine supervised\nand unsupervised learning paradigms. It also covers optimization techniques\nincluding SNN operations reduction, weight quantization, and knowledge\ndistillation. Then, this survey discusses the progress of real-world NCL\napplications. Finally, this paper provides a future perspective on the open\nresearch challenges for NCL, since the purpose of this study is to be useful\nfor the wider neuromorphic AI research community and to inspire future research\nin bio-plausible OCL.", "comment": "This work has been accepted for publication in IEEE Access", "pdf_url": "http://arxiv.org/pdf/2410.09218v3", "cate": "cs.NE", "date": "2024-10-11", "updated": "2025-07-19"}
{"id": "2507.14518", "title": "Mathematical modeling and simulation of two-phase magnetohydrodynamic flows at low magnetic Reynolds numbers", "authors": ["Jiancheng Wang", "Maojun Li", "Zeyu Xia", "Liwei Xu"], "categories": ["math.NA", "cs.NA", "physics.flu-dyn"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14518v1", "summary": "We propose a novel mathematical framework for simulating the two-phase\nincompressible magnetohydrodynamic (MHD) problems. Focusing on low magnetic\nReynolds number regimes, where induced magnetic fields are negligible compared\nto applied fields, an intrinsic sharp-interface system is first formulated.\nSubsequently, we utilize the phase-field approach to characterize the interface\nand derive a thermodynamically consistent phase-field model through the\nOnsager's variational principle. The resulting system couples the\nAbels--Garcke--Gr\\\"un (AGG) model of two-phase flows with a quasi-static\nformulation modeling the electromagnetic phenomena. Theoretically, the\nsharp-interface limit is investigated via asymptotic arguments, deducing that\nthe sharp-interface system can be recovered in the limit of vanishing interface\nthickness. Consequently, this justifies the reliability of the phase-field\napproach as an approximated method. In addition, we present some\nthree-dimensional numerical experiments of magnetic damping effects on bubble\ndynamics, where the observed results demonstrate the validity of the proposed\nframework in capturing complex MHD phenomena.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14518v1", "cate": "math.NA", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.09510", "title": "SC-TSE: Speaker Consistency-Aware Target Speaker Extraction", "authors": ["Shu Wu", "Anbin Qi", "Yanzhang Xie", "Xiang Xie"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Due to concerns regarding data and citations that may compromise academic rigor, the paper has been retracted", "url": "http://arxiv.org/abs/2507.09510v2", "summary": "Target Speaker Extraction (TSE) uses a reference cue to extract the target\nspeech from a mixture. In TSE systems relying on audio cues, the speaker\nembedding from the enrolled speech is crucial to performance. However, these\nembeddings may suffer from speaker identity confusion. Unlike previous studies\nthat focus on improving speaker embedding extraction, we improve TSE\nperformance from the perspective of speaker consistency. In this paper, we\npropose a speaker consistency-aware target speaker extraction method that\nincorporates a centroid-based speaker consistency loss. This approach enhances\nTSE performance by ensuring speaker consistency between the enrolled and\nextracted speech. In addition, we integrate conditional loss suppression into\nthe training process. The experimental results validate the effectiveness of\nour proposed methods in advancing the TSE performance. A speech demo is\navailable online:https://sc-tse.netlify.app/", "comment": "Due to concerns regarding data and citations that may compromise\n  academic rigor, the paper has been retracted", "pdf_url": "http://arxiv.org/pdf/2507.09510v2", "cate": "cs.SD", "date": "2025-07-13", "updated": "2025-07-21"}
{"id": "2507.15665", "title": "Domino tilings, nonintersecting lattice paths and subclasses of Koutschan-Krattenthaler-Schlosser determinants", "authors": ["Qipin Chen", "Shane Chern", "Atsuro Yoshida"], "categories": ["math.CO", "cs.SC", "math.NT", "Primary 15A15, Secondary 05A15, 05B45, 82B20"], "primary_category": "Subjects:       Combinatorics (math.CO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15665v1", "summary": "Koutschan, Krattenthaler and Schlosser recently considered a family of\nbinomial determinants. In this work, we give combinatorial interpretations of\ntwo subclasses of these determinants in terms of domino tilings and\nnonintersecting lattice paths, thereby partially answering a question of\ntheirs. Furthermore, the determinant evaluations established by Koutschan,\nKrattenthaler and Schlosser produce many product formulas for our weighted\nenumerations of domino tilings and nonintersecting lattice paths. However,\nthere are still two enumerations left corresponding to conjectural formulas\nmade by the three. We hereby prove the two conjectures using the principle of\nholonomic Ansatz plus the approach of modular reduction for creative\ntelescoping, and hence fill the gap.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15665v1", "cate": "math.CO", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2505.13982", "title": "Adaptive Visuo-Tactile Fusion with Predictive Force Attention for Dexterous Manipulation", "authors": ["Jinzhou Li", "Tianhao Wu", "Jiyao Zhang", "Zeyuan Chen", "Haotian Jin", "Mingdong Wu", "Yujun Shen", "Yaodong Yang", "Hao Dong"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.13982v2", "summary": "Effectively utilizing multi-sensory data is important for robots to\ngeneralize across diverse tasks. However, the heterogeneous nature of these\nmodalities makes fusion challenging. Existing methods propose strategies to\nobtain comprehensively fused features but often ignore the fact that each\nmodality requires different levels of attention at different manipulation\nstages. To address this, we propose a force-guided attention fusion module that\nadaptively adjusts the weights of visual and tactile features without human\nlabeling. We also introduce a self-supervised future force prediction auxiliary\ntask to reinforce the tactile modality, improve data imbalance, and encourage\nproper adjustment. Our method achieves an average success rate of 93% across\nthree fine-grained, contactrich tasks in real-world experiments. Further\nanalysis shows that our policy appropriately adjusts attention to each modality\nat different manipulation stages. The videos can be viewed at\nhttps://adaptac-dex.github.io/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.13982v2", "cate": "cs.RO", "date": "2025-05-20", "updated": "2025-07-21"}
{"id": "2507.14271", "title": "MiDeSeC: A Dataset for Mitosis Detection and Segmentation in Breast Cancer Histopathology Images", "authors": ["Refik Samet", "Nooshin Nemati", "Emrah Hancer", "Serpil Sak", "Bilge Ayca Kirmizi", "Zeynep Yildirim"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14271v1", "summary": "The MiDeSeC dataset is created through H&E stained invasive breast carcinoma,\nno special type (NST) slides of 25 different patients captured at 40x\nmagnification from the Department of Medical Pathology at Ankara University.\nThe slides have been scanned by 3D Histech Panoramic p250 Flash-3 scanner and\nOlympus BX50 microscope. As several possible mitosis shapes exist, it is\ncrucial to have a large dataset to cover all the cases. Accordingly, a total of\n50 regions is selected from glass slides for 25 patients, each of regions with\na size of 1024*1024 pixels. There are more than 500 mitoses in total in these\n50 regions. Two-thirds of the regions are reserved for training, the other\nthird for testing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14271v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14980", "title": "FedWCM: Unleashing the Potential of Momentum-based Federated Learning in Long-Tailed Scenarios", "authors": ["Tianle Li", "Yongzhi Huang", "Linshan Jiang", "Qipeng Xie", "Chang Liu", "Wenfeng Du", "Lu Wang", "Kaishun Wu"], "categories": ["cs.LG", "68T05, 90C26", "I.2.6; I.5.1; I.2.10"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICPP, including appendix", "url": "http://arxiv.org/abs/2507.14980v1", "summary": "Federated Learning (FL) enables decentralized model training while preserving\ndata privacy. Despite its benefits, FL faces challenges with non-identically\ndistributed (non-IID) data, especially in long-tailed scenarios with imbalanced\nclass samples. Momentum-based FL methods, often used to accelerate FL\nconvergence, struggle with these distributions, resulting in biased models and\nmaking FL hard to converge. To understand this challenge, we conduct extensive\ninvestigations into this phenomenon, accompanied by a layer-wise analysis of\nneural network behavior. Based on these insights, we propose FedWCM, a method\nthat dynamically adjusts momentum using global and per-round data to correct\ndirectional biases introduced by long-tailed distributions. Extensive\nexperiments show that FedWCM resolves non-convergence issues and outperforms\nexisting methods, enhancing FL's efficiency and effectiveness in handling\nclient heterogeneity and data imbalance.", "comment": "ICPP, including appendix", "pdf_url": "http://arxiv.org/pdf/2507.14980v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14924", "title": "3-Dimensional CryoEM Pose Estimation and Shift Correction Pipeline", "authors": ["Kaishva Chintan Shah", "Virajith Boddapati", "Karthik S. Gurumoorthy", "Sandip Kaledhonkar", "Ajit Rajwade"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14924v1", "summary": "Accurate pose estimation and shift correction are key challenges in cryo-EM\ndue to the very low SNR, which directly impacts the fidelity of 3D\nreconstructions. We present an approach for pose estimation in cryo-EM that\nleverages multi-dimensional scaling (MDS) techniques in a robust manner to\nestimate the 3D rotation matrix of each particle from pairs of dihedral angles.\nWe express the rotation matrix in the form of an axis of rotation and a unit\nvector in the plane perpendicular to the axis. The technique leverages the\nconcept of common lines in 3D reconstruction from projections. However, common\nline estimation is ridden with large errors due to the very low SNR of cryo-EM\nprojection images. To address this challenge, we introduce two complementary\ncomponents: (i) a robust joint optimization framework for pose estimation based\non an $\\ell_1$-norm objective or a similar robust norm, which simultaneously\nestimates rotation axes and in-plane vectors while exactly enforcing unit norm\nand orthogonality constraints via projected coordinate descent; and (ii) an\niterative shift correction algorithm that estimates consistent in-plane\ntranslations through a global least-squares formulation. While prior approaches\nhave leveraged such embeddings and common-line geometry for orientation\nrecovery, existing formulations typically rely on $\\ell_2$-based objectives\nthat are sensitive to noise, and enforce geometric constraints only\napproximately. These choices, combined with a sequential pipeline structure,\ncan lead to compounding errors and suboptimal reconstructions in low-SNR\nregimes. Our pipeline consistently outperforms prior methods in both Euler\nangle accuracy and reconstruction fidelity, as measured by the Fourier Shell\nCorrelation (FSC).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14924v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14469", "title": "Spatially tailored spin wave excitation for spurious-free, low-loss magnetostatic wave filters with ultra-wide frequency tunability", "authors": ["Shuxian Wu", "Shun Yao", "Xingyu Du", "Chin-Yu Chang", "Roy H. Olsson III"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14469v1", "summary": "Yttrium iron garnet magnetostatic wave (MSW) radio frequency (RF) cavity\nfilters are promising for sixth-generation (6G) communication systems due to\ntheir wide frequency tunability. However, the presence of severe spurious modes\narising from the finite cavity dimensions severely degrades the filter\nperformance. We present a half-cone transducer that spatially tailors spin wave\nexcitation to selectively enhance the primary cavity modes comprising the MSW\nfilter passband, while strongly suppressing the undesired spurious modes.\nTheoretical analysis, numerical simulations and experiments verify the\neffectiveness of the spatially tailored technique. We utilize the half-cone\ntransducer to demonstrate a spurious-free, single-cavity half-cone MSW filter\n(HC-MSWF) with an insertion loss (IL) of 2.4-3.2 dB over a frequency tuning\nrange of 6.3-16.8 GHz. Extending our study, we further demonstrate a\nspurious-free, dual-cavity HC-MSWF with an unprecedented tuning range of 21.7\nGHz (9.8-31.5 GHz) while maintaining a low IL of 2.9-3.8 dB. This significant\nadvance in performance will enable highly reconfigurable and robust 6G\nnetworks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14469v1", "cate": "eess.SP", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.09768", "title": "Knowing When to Quit: Probabilistic Early Exits for Speech Separation", "authors": ["Kenny Falkær Olsen", "Mads Østergaard", "Karl Ulbæk", "Søren Føns Nielsen", "Rasmus Malik Høegh Lindrup", "Bjørn Sand Jensen", "Morten Mørup"], "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09768v2", "summary": "In recent years, deep learning-based single-channel speech separation has\nimproved considerably, in large part driven by increasingly compute- and\nparameter-efficient neural network architectures. Most such architectures are,\nhowever, designed with a fixed compute and parameter budget, and consequently\ncannot scale to varying compute demands or resources, which limits their use in\nembedded and heterogeneous devices such as mobile phones and hearables. To\nenable such use-cases we design a neural network architecture for speech\nseparation capable of early-exit, and we propose an uncertainty-aware\nprobabilistic framework to jointly model the clean speech signal and error\nvariance which we use to derive probabilistic early-exit conditions in terms of\ndesired signal-to-noise ratios. We evaluate our methods on both speech\nseparation and enhancement tasks, and we show that a single early-exit model\ncan be competitive with state-of-the-art models trained at many compute and\nparameter budgets. Our framework enables fine-grained dynamic compute-scaling\nof speech separation networks while achieving state-of-the-art performance and\ninterpretable exit conditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09768v2", "cate": "cs.LG", "date": "2025-07-13", "updated": "2025-07-20"}
{"id": "2507.15176", "title": "On Algorithmic Robustness of Corrupted Markov Chains", "authors": ["Jason Gaitonde", "Elchanan Mossel"], "categories": ["math.PR", "cs.DS"], "primary_category": "Subjects:       Probability (math.PR)", "pdf_link": null, "comments": "Comments:      16 pages", "url": "http://arxiv.org/abs/2507.15176v1", "summary": "We study the algorithmic robustness of general finite Markov chains in terms\nof their stationary distributions to general, adversarial corruptions of the\ntransition matrix. We show that for Markov chains admitting a spectral gap,\nvariants of the \\emph{PageRank} chain are robust in the sense that, given an\n\\emph{arbitrary} corruption of the edges emanating from an $\\epsilon$-measure\nof the nodes, the PageRank distribution of the corrupted chain will be\n$\\mathsf{poly}(\\varepsilon)$ close in total variation to the original\ndistribution under mild conditions on the restart distribution. Our work thus\nshows that PageRank serves as a simple regularizer against broad, realistic\ncorruptions with algorithmic guarantees that are dimension-free and scale\ngracefully in terms of necessary and natural parameters.", "comment": "16 pages", "pdf_url": "http://arxiv.org/pdf/2507.15176v1", "cate": "math.PR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15826", "title": "Just Ask for Music (JAM): Multimodal and Personalized Natural Language Music Recommendation", "authors": ["Alessandro B. Melchiorre", "Elena V. Epure", "Shahed Masoudian", "Gustavo Escobedo", "Anna Hausberger", "Manuel Moussallam", "Markus Schedl"], "categories": ["cs.IR", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15826v1", "summary": "Natural language interfaces offer a compelling approach for music\nrecommendation, enabling users to express complex preferences conversationally.\nWhile Large Language Models (LLMs) show promise in this direction, their\nscalability in recommender systems is limited by high costs and latency.\nRetrieval-based approaches using smaller language models mitigate these issues\nbut often rely on single-modal item representations, overlook long-term user\npreferences, and require full model retraining, posing challenges for\nreal-world deployment. In this paper, we present JAM (Just Ask for Music), a\nlightweight and intuitive framework for natural language music recommendation.\nJAM models user-query-item interactions as vector translations in a shared\nlatent space, inspired by knowledge graph embedding methods like TransE. To\ncapture the complexity of music and user intent, JAM aggregates multimodal item\nfeatures via cross-attention and sparse mixture-of-experts. We also introduce\nJAMSessions, a new dataset of over 100k user-query-item triples with anonymized\nuser/item embeddings, uniquely combining conversational queries and user\nlong-term preferences. Our results show that JAM provides accurate\nrecommendations, produces intuitive representations suitable for practical use\ncases, and can be easily integrated with existing music recommendation stacks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15826v1", "cate": "cs.IR", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2411.16711", "title": "TSkips: Efficiency Through Explicit Temporal Delay Connections in Spiking Neural Networks", "authors": ["Prajna G. Malettira", "Shubham Negi", "Wachirawit Ponghiran", "Kaushik Roy"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.16711v2", "summary": "Spiking Neural Networks (SNNs) with their bio-inspired Leaky\nIntegrate-and-Fire (LIF) neurons inherently capture temporal information. This\nmakes them well-suited for sequential tasks like processing event-based data\nfrom Dynamic Vision Sensors (DVS) and event-based speech tasks. Harnessing the\ntemporal capabilities of SNNs requires mitigating vanishing spikes during\ntraining, capturing spatio-temporal patterns and enhancing precise spike\ntiming. To address these challenges, we propose TSkips, augmenting SNN\narchitectures with forward and backward skip connections that incorporate\nexplicit temporal delays. These connections capture long-term spatio-temporal\ndependencies and facilitate better spike flow over long sequences. The\nintroduction of TSkips creates a vast search space of possible configurations,\nencompassing skip positions and time delay values. To efficiently navigate this\nsearch space, this work leverages training-free Neural Architecture Search\n(NAS) to identify optimal network structures and corresponding delays. We\ndemonstrate the effectiveness of our approach on four event-based datasets:\nDSEC-flow for optical flow estimation, DVS128 Gesture for hand gesture\nrecognition and Spiking Heidelberg Digits (SHD) and Spiking Speech Commands\n(SSC) for speech recognition. Our method achieves significant improvements\nacross these datasets: up to 18% reduction in Average Endpoint Error (AEE) on\nDSEC-flow, 8% increase in classification accuracy on DVS128 Gesture, and up to\n8% and 16% higher classification accuracy on SHD and SSC, respectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.16711v2", "cate": "cs.NE", "date": "2024-11-22", "updated": "2025-07-21"}
{"id": "2507.14521", "title": "On the vector potential formulation with an energy-based hysteresis model and its numerical solution", "authors": ["Herbert Egger", "Felix Engertsberger"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14521v1", "summary": "The accurate modelling and simulation of electric devices involving\nferromagnetic materials requires the appropriate consideration of magnetic\nhysteresis. We discuss the systematic incorporation of the energy-based vector\nhysteresis model of Henrotte et al. into vector potential formulations for the\ngoverning magnetic field equations. The field model describing a single step in\na load cycle is phrased as a convex minimization problem which allows us to\nestablish existence and uniqueness of solutions and to obtain accurate\napproximations by finite element discretization. Consistency of the model with\nthe governing field equations is deduced from the first order optimality\nconditions. In addition, two globally convergent iterative methods are\npresented for the solution of the underlying minimization problems. The\nefficiency of the approach is illustrated by numerical tests for a typical\nbenchmark problem.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14521v1", "cate": "math.NA", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.10827", "title": "Supporting SENCOTEN Language Documentation Efforts with Automatic Speech Recognition", "authors": ["Mengzhe Geng", "Patrick Littell", "Aidan Pine", "PENÁĆ", "Marc Tessier", "Roland Kuhn"], "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted by ComputEL-8", "url": "http://arxiv.org/abs/2507.10827v2", "summary": "The SENCOTEN language, spoken on the Saanich peninsula of southern Vancouver\nIsland, is in the midst of vigorous language revitalization efforts to turn the\ntide of language loss as a result of colonial language policies. To support\nthese on-the-ground efforts, the community is turning to digital technology.\nAutomatic Speech Recognition (ASR) technology holds great promise for\naccelerating language documentation and the creation of educational resources.\nHowever, developing ASR systems for SENCOTEN is challenging due to limited data\nand significant vocabulary variation from its polysynthetic structure and\nstress-driven metathesis. To address these challenges, we propose an ASR-driven\ndocumentation pipeline that leverages augmented speech data from a\ntext-to-speech (TTS) system and cross-lingual transfer learning with Speech\nFoundation Models (SFMs). An n-gram language model is also incorporated via\nshallow fusion or n-best restoring to maximize the use of available data.\nExperiments on the SENCOTEN dataset show a word error rate (WER) of 19.34% and\na character error rate (CER) of 5.09% on the test set with a 57.02%\nout-of-vocabulary (OOV) rate. After filtering minor cedilla-related errors, WER\nimproves to 14.32% (26.48% on unseen words) and CER to 3.45%, demonstrating the\npotential of our ASR-driven pipeline to support SENCOTEN language\ndocumentation.", "comment": "Accepted by ComputEL-8", "pdf_url": "http://arxiv.org/pdf/2507.10827v2", "cate": "cs.SD", "date": "2025-07-14", "updated": "2025-07-20"}
{"id": "2506.13242", "title": "A non-commutative algorithm for multiplying 4x4 matrices using 48 non-complex multiplications", "authors": ["Jean-Guillaume Dumas", "Clément Pernet", "Alexandre Sedoglavic"], "categories": ["cs.SC"], "primary_category": "Subjects:       Symbolic Computation (cs.SC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.13242v5", "summary": "The quest for non-commutative matrix multiplication algorithms in small\ndimensions has seen a lot of recent improvements recently. In particular, the\nnumber of scalar multiplications required to multiply two $4\\times4$ matrices\nwas first reduced in \\cite{Fawzi:2022aa} from 49 (two recursion levels of\nStrassen's algorithm) to 47 but only in characteristic 2 or more recently to 48\nin \\cite{alphaevolve} but over complex numbers. We propose an algorithm in 48\nmultiplications with only rational coefficients, hence removing the complex\nnumber requirement. It was derived from the latter one, under the action of an\nisotropy which happen to project the algorithm on the field of rational\nnumbers. We also produce a straight line program of this algorithm, reducing\nthe leading constant in the complexity, as well as an alternative basis variant\nof it, leading to an algorithm running in $\\frac{19}{16} n^{2+\\frac{\\log_2\n3}{2}} +o\\left(n^{2+\\frac{log_2 3}{2}}\\right)$ operations over any ring\ncontaining an inverse of 2.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.13242v5", "cate": "cs.SC", "date": "2025-06-16", "updated": "2025-07-21"}
{"id": "2506.06535", "title": "MapleGrasp: Mask-guided Feature Pooling for Language-driven Efficient Robotic Grasping", "authors": ["Vineet Bhat", "Naman Patel", "Prashanth Krishnamurthy", "Ramesh Karri", "Farshad Khorrami"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.06535v2", "summary": "Robotic manipulation of unseen objects via natural language commands remains\nchallenging. Language driven robotic grasping (LDRG) predicts stable grasp\nposes from natural language queries and RGB-D images. We propose MapleGrasp, a\nnovel framework that leverages mask-guided feature pooling for efficient\nvision-language driven grasping. Our two-stage training first predicts\nsegmentation masks from CLIP-based vision-language features. The second stage\npools features within these masks to generate pixel-level grasp predictions,\nimproving efficiency, and reducing computation. Incorporating mask pooling\nresults in a 7% improvement over prior approaches on the OCID-VLG benchmark.\nFurthermore, we introduce RefGraspNet, an open-source dataset eight times\nlarger than existing alternatives, significantly enhancing model generalization\nfor open-vocabulary grasping. MapleGrasp scores a strong grasping accuracy of\n89\\% when compared with competing methods in the RefGraspNet benchmark. Our\nmethod achieves comparable performance to larger Vision-Language-Action models\non the LIBERO benchmark, and shows significantly better generalization to\nunseen tasks. Real-world experiments on a Franka arm demonstrate 73% success\nrate with unseen objects, surpassing competitive baselines by 11%. Code will be\nreleased after publication.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.06535v2", "cate": "cs.RO", "date": "2025-06-06", "updated": "2025-07-20"}
{"id": "2507.14272", "title": "NuSeC: A Dataset for Nuclei Segmentation in Breast Cancer Histopathology Images", "authors": ["Refik Samet", "Nooshin Nemati", "Emrah Hancer", "Serpil Sak", "Bilge Ayca Kirmizi"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14272v1", "summary": "The NuSeC dataset is created by selecting 4 images with the size of 1024*1024\npixels from the slides of each patient among 25 patients. Therefore, there are\na total of 100 images in the NuSeC dataset. To carry out a consistent\ncomparative analysis between the methods that will be developed using the NuSeC\ndataset by the researchers in the future, we divide the NuSeC dataset 75% as\nthe training set and 25% as the testing set. In detail, an image is randomly\nselected from 4 images of each patient among 25 patients to build the testing\nset, and then the remaining images are reserved for the training set. While the\ntraining set includes 75 images with around 30000 nuclei structures, the\ntesting set includes 25 images with around 6000 nuclei structures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14272v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14999", "title": "Clustered Federated Learning for Generalizable FDIA Detection in Smart Grids with Heterogeneous Data", "authors": ["Yunfeng Li", "Junhong Liu", "Zhaohui Yang", "Guofu Liao", "Chuyun Zhang"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages,6 figures", "url": "http://arxiv.org/abs/2507.14999v1", "summary": "False Data Injection Attacks (FDIAs) pose severe security risks to smart\ngrids by manipulating measurement data collected from spatially distributed\ndevices such as SCADA systems and PMUs. These measurements typically exhibit\nNon-Independent and Identically Distributed (Non-IID) characteristics across\ndifferent regions, which significantly challenges the generalization ability of\ndetection models. Traditional centralized training approaches not only face\nprivacy risks and data sharing constraints but also incur high transmission\ncosts, limiting their scalability and deployment feasibility. To address these\nissues, this paper proposes a privacy-preserving federated learning framework,\ntermed Federated Cluster Average (FedClusAvg), designed to improve FDIA\ndetection in Non-IID and resource-constrained environments. FedClusAvg\nincorporates cluster-based stratified sampling and hierarchical communication\n(client-subserver-server) to enhance model generalization and reduce\ncommunication overhead. By enabling localized training and weighted parameter\naggregation, the algorithm achieves accurate model convergence without\ncentralizing sensitive data. Experimental results on benchmark smart grid\ndatasets demonstrate that FedClusAvg not only improves detection accuracy under\nheterogeneous data distributions but also significantly reduces communication\nrounds and bandwidth consumption. This work provides an effective solution for\nsecure and efficient FDIA detection in large-scale distributed power systems.", "comment": "10 pages,6 figures", "pdf_url": "http://arxiv.org/pdf/2507.14999v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14932", "title": "Probabilistic smooth attention for deep multiple instance learning in medical imaging", "authors": ["Francisco M. Castro-Macías", "Pablo Morales-Álvarez", "Yunan Wu", "Rafael Molina", "Aggelos K. Katsaggelos"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14932v1", "summary": "The Multiple Instance Learning (MIL) paradigm is attracting plenty of\nattention in medical imaging classification, where labeled data is scarce. MIL\nmethods cast medical images as bags of instances (e.g. patches in whole slide\nimages, or slices in CT scans), and only bag labels are required for training.\nDeep MIL approaches have obtained promising results by aggregating\ninstance-level representations via an attention mechanism to compute the\nbag-level prediction. These methods typically capture both local interactions\namong adjacent instances and global, long-range dependencies through various\nmechanisms. However, they treat attention values deterministically, potentially\noverlooking uncertainty in the contribution of individual instances. In this\nwork we propose a novel probabilistic framework that estimates a probability\ndistribution over the attention values, and accounts for both global and local\ninteractions. In a comprehensive evaluation involving {\\color{review} eleven}\nstate-of-the-art baselines and three medical datasets, we show that our\napproach achieves top predictive performance in different metrics. Moreover,\nthe probabilistic treatment of the attention provides uncertainty maps that are\ninterpretable in terms of illness localization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14932v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14622", "title": "Propagation Channel Modeling for LEO Satellite Missions Using Ray-Tracing Simulations", "authors": ["Wahab Khawaja", "Ismail Guvenc", "Rune Hylsberg Jacobsen"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      This manuscript is submitted to MILCOM 2025 conference", "url": "http://arxiv.org/abs/2507.14622v1", "summary": "This work presents a high-resolution, ray-tracing-based channel modeling for\nLow Earth Orbit (LEO) satellite-to-ground links in a suburban environment at\nX-band. Using simulations conducted in Wireless InSite, we develop a parametric\nchannel model that characterizes both large- and small-scale fading effects\nacross different satellite elevation angles. Large-scale fading incorporates\nattenuation due to terrain-induced shadowing and dynamic environmental factors\nsuch as weather conditions, and is compared with 3GPP NTN channel model.\nAdditionally, we quantify link degradation resulting from ground station (GS)\nantenna misalignment, considering both fixed single-element and electronically\nsteerable phased-array antennas. Small-scale fading is modeled by fitting a\nshadowed and non-shadowed Rician distribution to the fading statistics at\nvarious satellite elevations. To the best of our knowledge, this is the first\nstudy to propose a comprehensive elevation-aware channel model for\nsatellite-to-ground propagation at X-band, integrating ray-traced environmental\ndynamics, elevation-dependent fading, and phased-array beam misalignment\neffects.", "comment": "This manuscript is submitted to MILCOM 2025 conference", "pdf_url": "http://arxiv.org/pdf/2507.14622v1", "cate": "eess.SP", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15511", "title": "Certificate-Sensitive Subset Sum: Realizing Instance Complexity", "authors": ["Jesus Salas"], "categories": ["cs.CC", "cs.DS", "F.1.3; F.2.2"], "primary_category": "Subjects:       Computational Complexity (cs.CC)", "pdf_link": null, "comments": "Comments:      14 pages + appendix. Companion to arXiv:2503.20162 (\"Beyond Worst-Case Subset Sum: An Adaptive, Structure-Aware Solver with Sub-2^{n/2} Enumeration\"", "url": "http://arxiv.org/abs/2507.15511v1", "summary": "We present, to our knowledge, the first deterministic, certificate-sensitive\nalgorithm for a canonical NP-complete problem whose runtime provably adapts to\nthe structure of each input. For a Subset-Sum instance $(S, t)$, let\n$\\Sigma(S)$ denote the set of distinct subset sums and define $U =\n|\\Sigma(S)|$. This set serves as an information-theoretically minimal witness,\nthe instance-complexity (IC) certificate.\n  Our solver, IC-SubsetSum, enumerates every element of $\\Sigma(S)$ in\ndeterministic time $O(U \\cdot n^2)$ and space $O(U \\cdot n)$. A randomized\nvariant achieves expected runtime $O(U \\cdot n)$. The algorithm's complexity is\nthus directly governed by the certificate size, and this structure-sensitive\nperformance is paired with a guaranteed worst-case runtime of $O^*(2^{n/2 -\n\\varepsilon})$ for some constant $\\varepsilon > 0$, the first such result to\nstrictly outperform classical methods on every instance.\n  We revisit fine-grained reductions that rely on the classical $2^{n/2}$\nhardness of SubsetSum and show that these arguments hold only for\ncollision-free instances where $U$ is maximal. IC-SubsetSum reframes this\nbarrier structurally and introduces a new paradigm for certificate-sensitive\nalgorithms across NP-complete problems.", "comment": "14 pages + appendix. Companion to arXiv:2503.20162 (\"Beyond\n  Worst-Case Subset Sum: An Adaptive, Structure-Aware Solver with Sub-2^{n/2}\n  Enumeration\"", "pdf_url": "http://arxiv.org/pdf/2507.15511v1", "cate": "cs.CC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14758", "title": "GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought Tokenization", "authors": ["Luyi Ma", "Wanjia Zhang", "Kai Zhao", "Abhishek Kulkarni", "Lalitesh Morishetti", "Anjana Ganesh", "Ashish Ranjan", "Aashika Padmanabhan", "Jianpeng Xu", "Jason Cho", "Praveen Kanumala", "Kaushiki Nag", "Sumit Dutta", "Kamiya Motwani", "Malay Patel", "Evren Korpeoglu", "Sushant Kumar", "Kannan Achan"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures, The ACM Conference on Recommender Systems (RecSys) 2025", "url": "http://arxiv.org/abs/2507.14758v1", "summary": "Generative models have recently demonstrated strong potential in\nmulti-behavior recommendation systems, leveraging the expressive power of\ntransformers and tokenization to generate personalized item sequences. However,\ntheir adoption is hindered by (1) the lack of explicit information for token\nreasoning, (2) high computational costs due to quadratic attention complexity\nand dense sequence representations after tokenization, and (3) limited\nmulti-scale modeling over user history. In this work, we propose GRACE\n(Generative Recommendation via journey-aware sparse Attention on\nChain-of-thought tokEnization), a novel generative framework for multi-behavior\nsequential recommendation. GRACE introduces a hybrid Chain-of-Thought (CoT)\ntokenization method that encodes user-item interactions with explicit\nattributes from product knowledge graphs (e.g., category, brand, price) over\nsemantic tokenization, enabling interpretable and behavior-aligned generation.\nTo address the inefficiency of standard attention, we design a Journey-Aware\nSparse Attention (JSA) mechanism, which selectively attends to compressed,\nintra-, inter-, and current-context segments in the tokenized sequence.\nExperiments on two real-world datasets show that GRACE significantly\noutperforms state-of-the-art baselines, achieving up to +106.9% HR@10 and\n+106.7% NDCG@10 improvement over the state-of-the-art baseline on the Home\ndomain, and +22.1% HR@10 on the Electronics domain. GRACE also reduces\nattention computation by up to 48% with long sequences.", "comment": "10 pages, 5 figures, The ACM Conference on Recommender Systems\n  (RecSys) 2025", "pdf_url": "http://arxiv.org/pdf/2507.14758v1", "cate": "cs.CL", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2501.15129", "title": "EvoRL: A GPU-accelerated Framework for Evolutionary Reinforcement Learning", "authors": ["Bowen Zheng", "Ran Cheng", "Kay Chen Tan"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.15129v3", "summary": "Evolutionary Reinforcement Learning (EvoRL) has emerged as a promising\napproach to overcoming the limitations of traditional reinforcement learning\n(RL) by integrating the Evolutionary Computation (EC) paradigm with RL.\nHowever, the population-based nature of EC significantly increases\ncomputational costs, thereby restricting the exploration of algorithmic design\nchoices and scalability in large-scale settings. To address this challenge, we\nintroduce $\\texttt{$\\textbf{EvoRL}$}$, the first end-to-end EvoRL framework\noptimized for GPU acceleration. The framework executes the entire training\npipeline on accelerators, including environment simulations and EC processes,\nleveraging hierarchical parallelism through vectorization and compilation\ntechniques to achieve superior speed and scalability. This design enables the\nefficient training of large populations on a single machine. In addition to its\nperformance-oriented design, $\\texttt{$\\textbf{EvoRL}$}$ offers a comprehensive\nplatform for EvoRL research, encompassing implementations of traditional RL\nalgorithms (e.g., A2C, PPO, DDPG, TD3, SAC), Evolutionary Algorithms (e.g.,\nCMA-ES, OpenES, ARS), and hybrid EvoRL paradigms such as Evolutionary-guided RL\n(e.g., ERL, CEM-RL) and Population-Based AutoRL (e.g., PBT). The framework's\nmodular architecture and user-friendly interface allow researchers to\nseamlessly integrate new components, customize algorithms, and conduct fair\nbenchmarking and ablation studies. The project is open-source and available at:\nhttps://github.com/EMI-Group/evorl.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.15129v3", "cate": "cs.NE", "date": "2025-01-25", "updated": "2025-07-19"}
{"id": "2507.14548", "title": "On the convergence analysis of MsFEM with oversampling: Interpolation error", "authors": ["Guanglian Li"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14548v1", "summary": "In this paper, we investigate the approximation properties of two types of\nmultiscale finite element methods with oversampling as proposed in [Hou \\& Wu,\n{\\textit{J. Comput. Phys.}}, 1997] and [Efendiev, Hou \\& Wu, \\textit{SIAM J.\nNumer. Anal.}, 2000] without scale separation. We develop a general\ninterpolation error analysis for elliptic problems with highly oscillatory\nrough coefficients, under the assumption of the existence of a macroscopic\nproblem with suitable $L^2$-accuracy. The distinct features of the analysis, in\nthe setting of highly oscillatory periodic coefficients, include: (i) The\nanalysis is independent of the first-order corrector or the solutions to the\ncell problems, and thus independent of their regularity properties; (ii) The\nanalysis only involves the homogenized solution and its minimal regularity. We\nderive an interpolation error $\\mathcal{O}\\left(H+\\frac{\\epsilon}{H}\\right)$\nwith $\\epsilon$ and $H$ being the period size and the coarse mesh size,\nrespectively, when the oversampling domain includes one layer of elements from\nthe target coarse element.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14548v1", "cate": "math.NA", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2506.15009", "title": "Six-DoF Hand-Based Teleoperation for Omnidirectional Aerial Robots", "authors": ["Jinjie Li", "Jiaxuan Li", "Kotaro Kaneko", "Haokun Liu", "Liming Shu", "Moju Zhao"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      7 pages, 10 figures. This work has been accepted to IROS 2025. The video is released in this https URL", "url": "http://arxiv.org/abs/2506.15009v2", "summary": "Omnidirectional aerial robots offer full 6-DoF independent control over\nposition and orientation, making them popular for aerial manipulation. Although\nadvancements in robotic autonomy, human operation remains essential in complex\naerial environments. Existing teleoperation approaches for multirotors fail to\nfully leverage the additional DoFs provided by omnidirectional rotation.\nAdditionally, the dexterity of human fingers should be exploited for more\nengaged interaction. In this work, we propose an aerial teleoperation system\nthat brings the rotational flexibility of human hands into the unbounded aerial\nworkspace. Our system includes two motion-tracking marker sets--one on the\nshoulder and one on the hand--along with a data glove to capture hand gestures.\nUsing these inputs, we design four interaction modes for different tasks,\nincluding Spherical Mode and Cartesian Mode for long-range moving, Operation\nMode for precise manipulation, as well as Locking Mode for temporary pauses,\nwhere the hand gestures are utilized for seamless mode switching. We evaluate\nour system on a vertically mounted valve-turning task in the real world,\ndemonstrating how each mode contributes to effective aerial manipulation. This\ninteraction framework bridges human dexterity with aerial robotics, paving the\nway for enhanced aerial teleoperation in unstructured environments.", "comment": "7 pages, 10 figures. This work has been accepted to IROS 2025. The\n  video is released in https://youtu.be/n0IQEnjPzrw?si=Zp3kb3ss-D_AySOE", "pdf_url": "http://arxiv.org/pdf/2506.15009v2", "cate": "cs.RO", "date": "2025-06-17", "updated": "2025-07-21"}
{"id": "2507.14298", "title": "In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding", "authors": ["Wan-Cyuan Fan", "Yen-Chun Chen", "Mengchen Liu", "Alexander Jacobson", "Lu Yuan", "Leonid Sigal"], "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      arXiv admin note: substantial text overlap with arXiv:2407.14506", "url": "http://arxiv.org/abs/2507.14298v1", "summary": "Recent methods for customizing Large Vision Language Models (LVLMs) for\ndomain-specific tasks have shown promising results in scientific chart\ncomprehension. However, existing approaches face two major limitations: First,\nthey rely on paired data from only a few chart types, limiting generalization\nto wide range of chart types. Secondly, they lack targeted pre-training for\nchart-data alignment, which hampers the model's understanding of underlying\ndata. In this paper, we introduce ChartScope, an LVLM optimized for in-depth\nchart comprehension across diverse chart types. We propose an efficient data\ngeneration pipeline that synthesizes paired data for a wide range of chart\ntypes, along with a novel Dual-Path training strategy that enabling the model\nto succinctly capture essential data details while preserving robust reasoning\ncapabilities by incorporating reasoning over the underlying data. Lastly, we\nestablish ChartDQA, a new benchmark for evaluating not only question-answering\nat different levels but also underlying data understanding. Experimental\nresults demonstrate that ChartScope significantly enhances comprehension on a\nwide range of chart types. The code and data are available at\nhttps://davidhalladay.github.io/chartscope_demo.", "comment": "arXiv admin note: substantial text overlap with arXiv:2407.14506", "pdf_url": "http://arxiv.org/pdf/2507.14298v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15066", "title": "Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback", "authors": ["Yiyuan Yang", "Zichuan Liu", "Lei Song", "Kai Ying", "Zhiguang Wang", "Tom Bamford", "Svitlana Vyetrenko", "Jiang Bian", "Qingsong Wen"], "categories": ["cs.LG", "cs.AI", "cs.MM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Under review. 19 pages, 8 figures, 12 tables", "url": "http://arxiv.org/abs/2507.15066v1", "summary": "Time series anomaly detection is critical across various domains, yet current\napproaches often limit analysis to mere binary anomaly classification without\ndetailed categorization or further explanatory reasoning. To address these\nlimitations, we propose a novel task, Time-series Reasoning for Anomaly\n(Time-RA) that transforms classical time series anomaly detection from a\ndiscriminative into a generative, reasoning-intensive task leveraging Large\nLanguage Models (LLMs). Also, we introduce the first real-world multimodal\nbenchmark dataset, RATs40K, explicitly annotated for anomaly reasoning,\ncomprising approximately 40,000 samples across 10 real-world domains. Each\nsample includes numeric time series data, contextual text information, and\nvisual representations, each annotated with fine-grained categories (14 types\nfor univariate anomalies and 6 for multivariate anomalies) and structured\nexplanatory reasoning. We develop a sophisticated annotation framework\nutilizing ensemble-generated labels refined through GPT-4-driven feedback,\nensuring accuracy and interpretability. Extensive benchmarking of LLMs and\nmultimodal LLMs demonstrates the capabilities and limitations of current\nmodels, highlighting the critical role of supervised fine-tuning. Our dataset\nand task pave the way for significant advancements in interpretable time series\nanomaly detection and reasoning.", "comment": "Under review. 19 pages, 8 figures, 12 tables", "pdf_url": "http://arxiv.org/pdf/2507.15066v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14935", "title": "Open-set Cross Modal Generalization via Multimodal Unified Representation", "authors": ["Hai Huang", "Yan Xia", "Shulei Wang", "Hanting Wang", "Minghui Fang", "Shengpeng Ji", "Sashuai Zhou", "Tao Jin", "Zhou Zhao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.14935v1", "summary": "This paper extends Cross Modal Generalization (CMG) to open-set environments\nby proposing the more challenging Open-set Cross Modal Generalization (OSCMG)\ntask. This task evaluates multimodal unified representations in open-set\nconditions, addressing the limitations of prior closed-set cross-modal\nevaluations. OSCMG requires not only cross-modal knowledge transfer but also\nrobust generalization to unseen classes within new modalities, a scenario\nfrequently encountered in real-world applications. Existing multimodal unified\nrepresentation work lacks consideration for open-set environments. To tackle\nthis, we propose MICU, comprising two key components: Fine-Coarse Masked\nmultimodal InfoNCE (FCMI) and Cross modal Unified Jigsaw Puzzles (CUJP). FCMI\nenhances multimodal alignment by applying contrastive learning at both holistic\nsemantic and temporal levels, incorporating masking to enhance generalization.\nCUJP enhances feature diversity and model uncertainty by integrating\nmodality-agnostic feature selection with self-supervised learning, thereby\nstrengthening the model's ability to handle unknown categories in open-set\ntasks. Extensive experiments on CMG and the newly proposed OSCMG validate the\neffectiveness of our approach. The code is available at\nhttps://github.com/haihuangcode/CMG.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.14935v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14804", "title": "Movable-Element STARS-Aided Secure Communications", "authors": ["Jingjing Zhao", "Qian Xu", "Kaiquan Cai", "Yanbo Zhu", "Xidong Mu", "Yuanwei Liu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14804v1", "summary": "A novel movable-element (ME) enabled simultaneously transmitting and\nreflecting surface (ME-STARS)-aided secure communication system is\ninvestigated. Against the full-space eavesdropping, MEs are deployed at the\nSTARS for enhancing the physical layer security by exploiting higher spatial\ndegrees of freedom. Specifically, a sum secrecy rate maximization problem is\nformulated, which jointly optimizes the passive beamforming and the MEs\npositions at the ME-STARS, as well as the active beamforming at the base\nstation. To solve the resultant non-convex optimization problem involving\nhighly-coupled variables, an alternating optimization-based iterative algorithm\nis developed, decomposing the original problem into three subproblems. In\nparticular, for the MEs position optimization subproblem, a gradient ascent\nalgorithm is employed to iteratively refine the MEs' locations within the\nconfined region. Moreover, the the active and passive beamforming subproblems\nare solved by employing successive convex approximation. Numerical results\nunveil that: 1) ME-STARS significantly improves the secrecy performance\ncompared to the conventional STARS with fixed-position elements; and 2) The\nsecrecy rate achieved by the ME-STARS gets saturated within limited movable\nregion size.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14804v1", "cate": "eess.SP", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2411.05255", "title": "Monotone Submodular Multiway Partition", "authors": ["Richard Bi", "Karthekeyan Chandrasekaran", "Soham Joshi"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.05255v2", "summary": "In submodular multiway partition (SUB-MP), the input is a non-negative\nsubmodular function $f:2^V \\rightarrow \\mathbb{R}_{\\ge 0}$ given by an\nevaluation oracle along with $k$ terminals $t_1, t_2, \\ldots, t_k\\in V$. The\ngoal is to find a partition $V_1, V_2, \\ldots, V_k$ of $V$ with $t_i\\in V_i$\nfor every $i\\in [k]$ in order to minimize $\\sum_{i=1}^k f(V_i)$. In this work,\nwe focus on SUB-MP when the input function is monotone (termed MONO-SUB-MP).\nMONO-SUB-MP formulates partitioning problems over several interesting\nstructures -- e.g., matrices, matroids, graphs, and hypergraphs. MONO-SUB-MP is\nNP-hard since the graph multiway cut problem can be cast as a special case. We\ninvestigate the approximability of MONO-SUB-MP: we show that it admits a\n$4/3$-approximation and does not admit a $(10/9-\\epsilon)$-approximation for\nevery constant $\\epsilon>0$. Next, we study a special case of MONO-SUB-MP where\nthe monotone submodular function of interest is the coverage function of an\ninput graph, termed GRAPH-COVERAGE-MP. GRAPH-COVERAGE-MP is equivalent to the\nclassic multiway cut problem for the purposes of exact optimization. We show\nthat GRAPH-COVERAGE-MP admits a $1.125$-approximation and does not admit a\n$(1.00074-\\epsilon)$-approximation for every constant $\\epsilon>0$ assuming the\nUnique Games Conjecture. These results separate GRAPH-COVERAGE-MP from graph\nmultiway cut in terms of approximability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.05255v2", "cate": "cs.DS", "date": "2024-11-08", "updated": "2025-07-21"}
{"id": "2507.15742", "title": "A Fisher's exact test justification of the TF-IDF term-weighting scheme", "authors": ["Paul Sheridan", "Zeyad Ahmed", "Aitazaz A. Farooque"], "categories": ["cs.CL", "cs.IR", "math.ST", "stat.TH"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      23 pages, 4 tables", "url": "http://arxiv.org/abs/2507.15742v1", "summary": "Term frequency-inverse document frequency, or TF-IDF for short, is arguably\nthe most celebrated mathematical expression in the history of information\nretrieval. Conceived as a simple heuristic quantifying the extent to which a\ngiven term's occurrences are concentrated in any one given document out of\nmany, TF-IDF and its many variants are routinely used as term-weighting schemes\nin diverse text analysis applications. There is a growing body of scholarship\ndedicated to placing TF-IDF on a sound theoretical foundation. Building on that\ntradition, this paper justifies the use of TF-IDF to the statistics community\nby demonstrating how the famed expression can be understood from a significance\ntesting perspective. We show that the common TF-IDF variant TF-ICF is, under\nmild regularity conditions, closely related to the negative logarithm of the\n$p$-value from a one-tailed version of Fisher's exact test of statistical\nsignificance. As a corollary, we establish a connection between TF-IDF and the\nsaid negative log-transformed $p$-value under certain idealized assumptions. We\nfurther demonstrate, as a limiting case, that this same quantity converges to\nTF-IDF in the limit of an infinitely large document collection. The Fisher's\nexact test justification of TF-IDF equips the working statistician with a ready\nexplanation of the term-weighting scheme's long-established effectiveness.", "comment": "23 pages, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.15742v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2409.02146", "title": "Brain-Inspired Online Adaptation for Remote Sensing with Spiking Neural Network", "authors": ["Dexin Duan", "Peilin liu", "Bingwei Hui", "Fei Wen"], "categories": ["cs.LG", "cs.CV", "cs.NE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      IEEE Transactions on Geoscience and Remote Sensing, 2025", "url": "http://arxiv.org/abs/2409.02146v2", "summary": "On-device computing, or edge computing, is becoming increasingly important\nfor remote sensing, particularly in applications like deep network-based\nperception on on-orbit satellites and unmanned aerial vehicles (UAVs). In these\nscenarios, two brain-like capabilities are crucial for remote sensing models:\n(1) high energy efficiency, allowing the model to operate on edge devices with\nlimited computing resources, and (2) online adaptation, enabling the model to\nquickly adapt to environmental variations, weather changes, and sensor drift.\nThis work addresses these needs by proposing an online adaptation framework\nbased on spiking neural networks (SNNs) for remote sensing. Starting with a\npretrained SNN model, we design an efficient, unsupervised online adaptation\nalgorithm, which adopts an approximation of the BPTT algorithm and only\ninvolves forward-in-time computation that significantly reduces the\ncomputational complexity of SNN adaptation learning. Besides, we propose an\nadaptive activation scaling scheme to boost online SNN adaptation performance,\nparticularly in low time-steps. Furthermore, for the more challenging remote\nsensing detection task, we propose a confidence-based instance weighting\nscheme, which substantially improves adaptation performance in the detection\ntask. To our knowledge, this work is the first to address the online adaptation\nof SNNs. Extensive experiments on seven benchmark datasets across\nclassification, segmentation, and detection tasks demonstrate that our proposed\nmethod significantly outperforms existing domain adaptation and domain\ngeneralization approaches under varying weather conditions. The proposed method\nenables energy-efficient and fast online adaptation on edge devices, and has\nmuch potential in applications such as remote perception on on-orbit satellites\nand UAV.", "comment": "IEEE Transactions on Geoscience and Remote Sensing, 2025", "pdf_url": "http://arxiv.org/pdf/2409.02146v2", "cate": "cs.LG", "date": "2024-09-03", "updated": "2025-07-21"}
{"id": "2507.14562", "title": "1/2 order convergence rate of Euler-type methods for time-changed stochastic differential equations with super-linearly growing drift and diffusion coefficients", "authors": ["Yuanling Niu", "Shuai Wang", "Ying Zhang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14562v1", "summary": "This paper investigates the convergence rates of two Euler-type methods for a\nclass of time-changed stochastic differential equations with super-linearly\ngrowing drift and diffusion coefficients. Building upon existing research, we\nadapt the backward Euler method to time-changed stochastic differential\nequations where both coefficients exhibit super-linear growth and introduce an\nexplicit counterpart, the projected Euler method. It is shown that both methods\nachieve the optimal strong convergence rate of order 1/2 in the mean-square\nsense for this class of equations. Numerical simulations confirm the\ntheoretical findings", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14562v1", "cate": "math.NA", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2506.18448", "title": "GraspMAS: Zero-Shot Language-driven Grasp Detection with Multi-Agent System", "authors": ["Quang Nguyen", "Tri Le", "Huy Nguyen", "Thieu Vo", "Tung D. Ta", "Baoru Huang", "Minh N. Vu", "Anh Nguyen"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted to IROS 2025. Webpage: this https URL", "url": "http://arxiv.org/abs/2506.18448v2", "summary": "Language-driven grasp detection has the potential to revolutionize\nhuman-robot interaction by allowing robots to understand and execute grasping\ntasks based on natural language commands. However, existing approaches face two\nkey challenges. First, they often struggle to interpret complex text\ninstructions or operate ineffectively in densely cluttered environments.\nSecond, most methods require a training or finetuning step to adapt to new\ndomains, limiting their generation in real-world applications. In this paper,\nwe introduce GraspMAS, a new multi-agent system framework for language-driven\ngrasp detection. GraspMAS is designed to reason through ambiguities and improve\ndecision-making in real-world scenarios. Our framework consists of three\nspecialized agents: Planner, responsible for strategizing complex queries;\nCoder, which generates and executes source code; and Observer, which evaluates\nthe outcomes and provides feedback. Intensive experiments on two large-scale\ndatasets demonstrate that our GraspMAS significantly outperforms existing\nbaselines. Additionally, robot experiments conducted in both simulation and\nreal-world settings further validate the effectiveness of our approach. Our\nproject page is available at https://zquang2202.github.io/GraspMAS", "comment": "Accepted to IROS 2025. Webpage:\n  https://zquang2202.github.io/GraspMAS/", "pdf_url": "http://arxiv.org/pdf/2506.18448v2", "cate": "cs.RO", "date": "2025-06-23", "updated": "2025-07-19"}
{"id": "2507.14376", "title": "Schemora: schema matching via multi-stage recommendation and metadata enrichment using off-the-shelf llms", "authors": ["Osman Erman Gungor", "Derak Paulsen", "William Kang"], "categories": ["cs.DB", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "Comments:      11 pages", "url": "http://arxiv.org/abs/2507.14376v1", "summary": "Schema matching is essential for integrating heterogeneous data sources and\nenhancing dataset discovery, yet it remains a complex and resource-intensive\nproblem. We introduce SCHEMORA, a schema matching framework that combines large\nlanguage models with hybrid retrieval techniques in a prompt-based approach,\nenabling efficient identification of candidate matches without relying on\nlabeled training data or exhaustive pairwise comparisons. By enriching schema\nmetadata and leveraging both vector-based and lexical retrieval, SCHEMORA\nimproves matching accuracy and scalability. Evaluated on the MIMIC-OMOP\nbenchmark, it establishes new state-of-the-art performance, with gains of 7.49%\nin HitRate@5 and 3.75% in HitRate@3 over previous best results. To our\nknowledge, this is the first LLM-based schema matching method with an\nopen-source implementation, accompanied by analysis that underscores the\ncritical role of retrieval and provides practical guidance on model selection.", "comment": "11 pages", "pdf_url": "http://arxiv.org/pdf/2507.14376v1", "cate": "cs.DB", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15073", "title": "Reinforcement Learning for Flow-Matching Policies", "authors": ["Samuel Pfrommer", "Yixiao Huang", "Somayeh Sojoudi"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15073v1", "summary": "Flow-matching policies have emerged as a powerful paradigm for generalist\nrobotics. These models are trained to imitate an action chunk, conditioned on\nsensor observations and textual instructions. Often, training demonstrations\nare generated by a suboptimal policy, such as a human operator. This work\nexplores training flow-matching policies via reinforcement learning to surpass\nthe original demonstration policy performance. We particularly note\nminimum-time control as a key application and present a simple scheme for\nvariable-horizon flow-matching planning. We then introduce two families of\napproaches: a simple Reward-Weighted Flow Matching (RWFM) scheme and a Group\nRelative Policy Optimization (GRPO) approach with a learned reward surrogate.\nOur policies are trained on an illustrative suite of simulated unicycle\ndynamics tasks, and we show that both approaches dramatically improve upon the\nsuboptimal demonstrator performance, with the GRPO approach in particular\ngenerally incurring between $50\\%$ and $85\\%$ less cost than a naive Imitation\nLearning Flow Matching (ILFM) approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15073v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14959", "title": "Polymorph: Energy-Efficient Multi-Label Classification for Video Streams on Embedded Devices", "authors": ["Saeid Ghafouri", "Mohsen Fayyaz", "Xiangchen Li", "Deepu John", "Bo Ji", "Dimitrios Nikolopoulos", "Hans Vandierendonck"], "categories": ["cs.CV", "cs.PF"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14959v1", "summary": "Real-time multi-label video classification on embedded devices is constrained\nby limited compute and energy budgets. Yet, video streams exhibit structural\nproperties such as label sparsity, temporal continuity, and label co-occurrence\nthat can be leveraged for more efficient inference. We introduce Polymorph, a\ncontext-aware framework that activates a minimal set of lightweight Low Rank\nAdapters (LoRA) per frame. Each adapter specializes in a subset of classes\nderived from co-occurrence patterns and is implemented as a LoRA weight over a\nshared backbone. At runtime, Polymorph dynamically selects and composes only\nthe adapters needed to cover the active labels, avoiding full-model switching\nand weight merging. This modular strategy improves scalability while reducing\nlatency and energy overhead. Polymorph achieves 40% lower energy consumption\nand improves mAP by 9 points over strong baselines on the TAO dataset.\nPolymorph is open source at https://github.com/inference-serving/polymorph/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14959v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14856", "title": "Integrated Radio Sensing Capabilities for 6G Networks: AI/ML Perspective", "authors": ["Victor Shatov", "Steffen Schieler", "Charlotte Muth", "José Miguel Mateos-Ramos", "Ivo Bizon", "Florian Euchner", "Sebastian Semper", "Stephan ten Brink", "Gerhard Fettweis", "Christian Häger", "Henk Wymeersch", "Laurent Schmalen", "Reiner Thomä", "Norman Franchi"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      30 pages, 18 figures", "url": "http://arxiv.org/abs/2507.14856v1", "summary": "The sixth-generation wireless communications (6G) is often labeled as\n\"connected intelligence\". Radio sensing, aligned with machine learning (ML) and\nartificial intelligence (AI), promises, among other benefits, breakthroughs in\nthe system's ability to perceive the environment and effectively utilize this\nawareness. This article offers a tutorial-style survey of AI and ML approaches\nto enhance the sensing capabilities of next-generation wireless networks. To\nthis end, while staying in the framework of integrated sensing and\ncommunication (ISAC), we expand the term \"sensing\" from radar, via spectrum\nsensing, to miscellaneous applications of radio sensing like non-cooperative\ntransmitter localization. We formulate the problems, explain the\nstate-of-the-art approaches, and detail AI-based techniques to tackle various\nobjectives in the context of wireless sensing. We discuss the advantages,\nenablers, and challenges of integrating various sensing capabilities into an\nenvisioned AI-powered multimodal multi-task network. In addition to the\ntutorial-style core of this work based on direct authors' involvement in 6G\nresearch problems, we review the related literature, and provide both a good\nstart for those entering this field of research, and a topical overview for a\ngeneral reader with a background in wireless communications", "comment": "30 pages, 18 figures", "pdf_url": "http://arxiv.org/pdf/2507.14856v1", "cate": "eess.SP", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2501.00926", "title": "Differentially Private Matchings", "authors": ["Michael Dinitz", "George Z. Li", "Quanquan C. Liu", "Felix Zhou"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Abstract truncated to fit arXiv limits", "url": "http://arxiv.org/abs/2501.00926v2", "summary": "Computing matchings in general graphs plays a central role in graph\nalgorithms. However, despite the recent interest in differentially private\ngraph algorithms, there has been limited work on private matchings. Moreover,\nalmost all existing work focuses on estimating the size of the maximum\nmatching, whereas in many applications, the matching itself is the object of\ninterest. There is currently only a single work on private algorithms for\ncomputing matching solutions by [HHRRW STOC'14]. Moreover, their work focuses\non allocation problems and hence is limited to bipartite graphs.\n  Motivated by the importance of computing matchings in sensitive graph data,\nwe initiate the study of differentially private algorithms for computing\nmaximal and maximum matchings in general graphs. We provide a number of\nalgorithms and lower bounds for this problem in different models and settings.\nWe first prove a lower bound showing that computing explicit solutions\nnecessarily incurs large error, even if we try to obtain privacy by allowing\nourselves to output non-edges. We then consider implicit solutions, where at\nthe end of the computation there is an ($\\varepsilon$-differentially private)\nbillboard and each node can determine its matched edge(s) based on what is\nwritten on this publicly visible billboard. For this solution concept, we\nprovide tight upper and lower (bicriteria) bounds, where the degree bound is\nviolated by a logarithmic factor (which we show is necessary). We further show\nthat our algorithm can be made distributed in the local edge DP (LEDP) model,\nand can even be done in a logarithmic number of rounds if we further relax the\ndegree bounds by logarithmic factors. Our edge-DP matching algorithms give rise\nto new matching algorithms in the node-DP setting by combining our edge-DP\nalgorithms with a novel use of arboricity sparsifiers. [...]", "comment": "Abstract truncated to fit arXiv limits", "pdf_url": "http://arxiv.org/pdf/2501.00926v2", "cate": "cs.DS", "date": "2025-01-01", "updated": "2025-07-20"}
{"id": "2409.07416", "title": "Hierarchical Reinforcement Learning for Temporal Abstraction of Listwise Recommendation", "authors": ["Luo Ji", "Gao Liu", "Mingyang Yin", "Hongxia Yang", "Jingren Zhou"], "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      18 pages, 4 figures", "url": "http://arxiv.org/abs/2409.07416v2", "summary": "Modern listwise recommendation systems need to consider both long-term user\nperceptions and short-term interest shifts. Reinforcement learning can be\napplied on recommendation to study such a problem but is also subject to large\nsearch space, sparse user feedback and long interactive latency. Motivated by\nrecent progress in hierarchical reinforcement learning, we propose a novel\nframework called mccHRL to provide different levels of temporal abstraction on\nlistwise recommendation. Within the hierarchical framework, the high-level\nagent studies the evolution of user perception, while the low-level agent\nproduces the item selection policy by modeling the process as a sequential\ndecision-making problem. We argue that such framework has a well-defined\ndecomposition of the outra-session context and the intra-session context, which\nare encoded by the high-level and low-level agents, respectively. To verify\nthis argument, we implement both a simulator-based environment and an\nindustrial dataset-based experiment. Results observe significant performance\nimprovement by our method, compared with several well-known baselines. Data and\ncodes have been made public.", "comment": "18 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2409.07416v2", "cate": "cs.IR", "date": "2024-09-11", "updated": "2025-07-19"}
{"id": "2504.19027", "title": "DiCE-Extended: A Robust Approach to Counterfactual Explanations in Machine Learning", "authors": ["Volkan Bakir", "Polat Goktas", "Sureyya Akyuz"], "categories": ["cs.AI", "cs.LG", "cs.NE", "I.2; K.4; H.4"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      5th international Conference on Modelling, Computation and Optimization in Information Systems and Management Sciences (MCO 2025), June 4-6, 2025, Metz, France", "url": "http://arxiv.org/abs/2504.19027v2", "summary": "Explainable artificial intelligence (XAI) has become increasingly important\nin decision-critical domains such as healthcare, finance, and law.\nCounterfactual (CF) explanations, a key approach in XAI, provide users with\nactionable insights by suggesting minimal modifications to input features that\nlead to different model outcomes. Despite significant advancements, existing CF\ngeneration methods often struggle to balance proximity, diversity, and\nrobustness, limiting their real-world applicability. A widely adopted\nframework, Diverse Counterfactual Explanations (DiCE), emphasizes diversity but\nlacks robustness, making CF explanations sensitive to perturbations and domain\nconstraints. To address these challenges, we introduce DiCE-Extended, an\nenhanced CF explanation framework that integrates multi-objective optimization\ntechniques to improve robustness while maintaining interpretability. Our\napproach introduces a novel robustness metric based on the Dice-S{\\o}rensen\ncoefficient, enabling stability under small input variations. Additionally, we\nrefine CF generation using weighted loss components (lambda_p, lambda_d,\nlambda_r) to balance proximity, diversity, and robustness. We empirically\nvalidate DiCE-Extended on benchmark datasets (COMPAS, Lending Club, German\nCredit, Adult Income) across multiple ML backends (Scikit-learn, PyTorch,\nTensorFlow). Results demonstrate improved CF validity, stability, and alignment\nwith decision boundaries compared to standard DiCE-generated explanations. Our\nfindings highlight the potential of DiCE-Extended in generating more reliable\nand interpretable CFs for high-stakes applications. Future work could explore\nadaptive optimization techniques and domain-specific constraints to further\nenhance CF generation in real-world scenarios", "comment": "5th international Conference on Modelling, Computation and\n  Optimization in Information Systems and Management Sciences (MCO 2025), June\n  4-6, 2025, Metz, France", "pdf_url": "http://arxiv.org/pdf/2504.19027v2", "cate": "cs.AI", "date": "2025-04-26", "updated": "2025-07-19"}
{"id": "2507.14692", "title": "Spectral Analysis of Node- and Cell-Centered Higher-Order Compact Schemes for Fully Discrete One and Two-Dimensional Convection-Dispersion Equation", "authors": ["Lavanya V Salian", "Vivek S Yadav", "Rathan Samala", "Rakesh Kumar"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      38 pages, 17 figures", "url": "http://arxiv.org/abs/2507.14692v1", "summary": "In this study, we present a comprehensive global spectral analysis of the\nconvection dispersion equation, which is also referred to in specific contexts\nas the Korteweg de Vries (KdV) equation, to investigate the behaviour of high\norder numerical schemes across a wide range of nondimensional parameters. The\nmotivation for this analysis stems from the equation's importance in modeling\nwave propagation and transport phenomena, where accurate resolution of\ndispersive effects is critical, and traditional numerical schemes often suffer\nfrom spurious artifacts. We analyze one sixth order and two eighth order\ncompact spatial discretization schemes, encompassing both node centered and\ncell centered formulations, combined with a third order strong stability\npreserving Runge Kutta (SSPRK3) time integrator. The analysis is performed in\nterms of key nondimensional parameters such as the wavenumber, Courant\nFriedrichs Lewy number $N_c$, and dispersion number $D_{\\alpha}$ over the full\nspectral plane for both one and two dimensional cases. Key numerical\nindicators, including the amplification factor, normalized phase speed, and\nnormalized group velocity, are evaluated to characterize stability, dispersion\nerror, errors in energy transport, and directional anisotropy. Critical\ndispersion thresholds and Courant numbers are identified, beyond which\nnumerical instability and nonphysical phenomena such as spurious q waves and\nreversed phase or energy transport arise. Theoretical predictions are validated\nthrough numerical experiments involving linear and nonlinear one and two\ndimensional test problems, including cases with exact solutions and established\nbenchmark results. This comprehensive analysis uncovers subtle numerical errors\nand offers practical guidance for selecting reliable discretization parameters,\nensuring accurate and stable simulations of convection dispersion systems.", "comment": "38 pages, 17 figures", "pdf_url": "http://arxiv.org/pdf/2507.14692v1", "cate": "math.NA", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14392", "title": "Characterizing Communication Patterns in Distributed Large Language Model Inference", "authors": ["Lang Xu", "Kaushik Kandadi Suresh", "Quentin Anthony", "Nawras Alnaasan", "Dhabaleswar K. Panda"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      To be presented at Hot Interconnects 2025", "url": "http://arxiv.org/abs/2507.14392v1", "summary": "Large Language Models (LLMs) built on transformer architectures have\ntransformed natural language processing, achieving remarkable performance\nacross diverse applications. While distributed inference frameworks enable\npractical deployment of these models, inter-GPU communication creates\nsignificant performance constraints that limit service quality in real-world\nsystems. This paper investigates communication dynamics in distributed LLM\nserving-analyzing how various parallelization approaches coordinate data\nexchange between GPU workers during inference. We study dense transformer-based\nmodels as representative examples of contemporary architectures widely used in\noperational deployments. Our work combines detailed profiling measurements with\npredictive analytical models to characterize communication behavior across\ndifferent parallelization configurations. Results show that tensor parallelism\nincurs substantial network overhead but delivers superior response times for\nbrief sequences, pipeline parallelism minimizes data transfer requirements\nwhile increasing total latency, and combined approaches demand careful tuning\nto achieve balanced performance. These insights offer practical recommendations\nfor selecting appropriate parallelization schemes in production LLM services\nand identify key opportunities for optimizing inference frameworks and\ncommunication infrastructure.", "comment": "To be presented at Hot Interconnects 2025", "pdf_url": "http://arxiv.org/pdf/2507.14392v1", "cate": "cs.DC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.04790", "title": "Interaction-Merged Motion Planning: Effectively Leveraging Diverse Motion Datasets for Robust Planning", "authors": ["Giwon Lee", "Wooseong Jeong", "Daehee Park", "Jaewoo Jeong", "Kuk-Jin Yoon"], "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025", "url": "http://arxiv.org/abs/2507.04790v2", "summary": "Motion planning is a crucial component of autonomous robot driving. While\nvarious trajectory datasets exist, effectively utilizing them for a target\ndomain remains challenging due to differences in agent interactions and\nenvironmental characteristics. Conventional approaches, such as domain\nadaptation or ensemble learning, leverage multiple source datasets but suffer\nfrom domain imbalance, catastrophic forgetting, and high computational costs.\nTo address these challenges, we propose Interaction-Merged Motion Planning\n(IMMP), a novel approach that leverages parameter checkpoints trained on\ndifferent domains during adaptation to the target domain. IMMP follows a\ntwo-step process: pre-merging to capture agent behaviors and interactions,\nsufficiently extracting diverse information from the source domain, followed by\nmerging to construct an adaptable model that efficiently transfers diverse\ninteractions to the target domain. Our method is evaluated on various planning\nbenchmarks and models, demonstrating superior performance compared to\nconventional approaches.", "comment": "Accepted at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.04790v2", "cate": "cs.RO", "date": "2025-07-07", "updated": "2025-07-21"}
{"id": "2507.14444", "title": "Statistical and Algorithmic Foundations of Reinforcement Learning", "authors": ["Yuejie Chi", "Yuxin Chen", "Yuting Wei"], "categories": ["stat.ML", "cs.AI", "cs.LG", "math.OC", "math.ST", "stat.TH"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      reading materials for INFORMS Tutorial in OR 2025", "url": "http://arxiv.org/abs/2507.14444v1", "summary": "As a paradigm for sequential decision making in unknown environments,\nreinforcement learning (RL) has received a flurry of attention in recent years.\nHowever, the explosion of model complexity in emerging applications and the\npresence of nonconvexity exacerbate the challenge of achieving efficient RL in\nsample-starved situations, where data collection is expensive, time-consuming,\nor even high-stakes (e.g., in clinical trials, autonomous systems, and online\nadvertising). How to understand and enhance the sample and computational\nefficacies of RL algorithms is thus of great interest. In this tutorial, we aim\nto introduce several important algorithmic and theoretical developments in RL,\nhighlighting the connections between new ideas and classical topics. Employing\nMarkov Decision Processes as the central mathematical model, we cover several\ndistinctive RL scenarios (i.e., RL with a simulator, online RL, offline RL,\nrobust RL, and RL with human feedback), and present several mainstream RL\napproaches (i.e., model-based approach, value-based approach, and policy\noptimization). Our discussions gravitate around the issues of sample\ncomplexity, computational efficiency, as well as algorithm-dependent and\ninformation-theoretic lower bounds from a non-asymptotic viewpoint.", "comment": "reading materials for INFORMS Tutorial in OR 2025", "pdf_url": "http://arxiv.org/pdf/2507.14444v1", "cate": "stat.ML", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15079", "title": "Isotonic Quantile Regression Averaging for uncertainty quantification of electricity price forecasts", "authors": ["Arkadiusz Lipiecki", "Bartosz Uniejewski"], "categories": ["cs.LG", "q-fin.ST", "stat.AP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2507.15079v1", "summary": "Quantifying the uncertainty of forecasting models is essential to assess and\nmitigate the risks associated with data-driven decisions, especially in\nvolatile domains such as electricity markets. Machine learning methods can\nprovide highly accurate electricity price forecasts, critical for informing the\ndecisions of market participants. However, these models often lack uncertainty\nestimates, which limits the ability of decision makers to avoid unnecessary\nrisks. In this paper, we propose a novel method for generating probabilistic\nforecasts from ensembles of point forecasts, called Isotonic Quantile\nRegression Averaging (iQRA). Building on the established framework of Quantile\nRegression Averaging (QRA), we introduce stochastic order constraints to\nimprove forecast accuracy, reliability, and computational costs. In an\nextensive forecasting study of the German day-ahead electricity market, we show\nthat iQRA consistently outperforms state-of-the-art postprocessing methods in\nterms of both reliability and sharpness. It produces well-calibrated prediction\nintervals across multiple confidence levels, providing superior reliability to\nall benchmark methods, particularly coverage-based conformal prediction. In\naddition, isotonic regularization decreases the complexity of the quantile\nregression problem and offers a hyperparameter-free approach to variable\nselection.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2507.15079v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14965", "title": "Decision PCR: Decision version of the Point Cloud Registration task", "authors": ["Yaojie Zhang", "Tianlun Huang", "Weijun Wang", "Wei Feng"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14965v1", "summary": "Low-overlap point cloud registration (PCR) remains a significant challenge in\n3D vision. Traditional evaluation metrics, such as Maximum Inlier Count, become\nineffective under extremely low inlier ratios. In this paper, we revisit the\nregistration result evaluation problem and identify the Decision version of the\nPCR task as the fundamental problem. To address this Decision PCR task, we\npropose a data-driven approach. First, we construct a corresponding dataset\nbased on the 3DMatch dataset. Then, a deep learning-based classifier is trained\nto reliably assess registration quality, overcoming the limitations of\ntraditional metrics. To our knowledge, this is the first comprehensive study to\naddress this task through a deep learning framework. We incorporate this\nclassifier into standard PCR pipelines. When integrated with our approach,\nexisting state-of-the-art PCR methods exhibit significantly enhanced\nregistration performance. For example, combining our framework with\nGeoTransformer achieves a new SOTA registration recall of 86.97\\% on the\nchallenging 3DLoMatch benchmark. Our method also demonstrates strong\ngeneralization capabilities on the unseen outdoor ETH dataset.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14965v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14888", "title": "Stabilization of the bias point in MZM modulators", "authors": ["Zhuo Wang"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14888v1", "summary": "This article mainly introduces the role of MZM in practical communication\nsystems, the materials used to make MZM modulators such as lithium niobate, and\nits working principle. It also explains why it changes due to environmental\nfactors. This leads to the introduction of a method that controls the stable\npoints of MZM by algorithmically controlling the voltage, and the algorithm is\nverified through experiments. Finally, a summary and outlook on the future\ndevelopment of MZM are provided.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14888v1", "cate": "eess.SP", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2503.18974", "title": "An Efficient Frequency-Based Approach for Maximal Square Detection in Binary Matrices", "authors": ["Swastik Bhandari"], "categories": ["cs.DS", "math.OC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.18974v3", "summary": "Detecting maximal square submatrices of ones in binary matrices is a\nfundamental problem with applications in computer vision and pattern\nrecognition. While the standard dynamic programming (DP) solution achieves\noptimal asymptotic complexity, its practical performance suffers from repeated\nminimum operations and inefficient memory access patterns that degrade cache\nutilization. To address these limitations, we introduce a novel frequency-based\nalgorithm that employs a greedy approach to track the columnar continuity of\nones through an adaptive frequency array and a dynamic thresholding mechanism.\nExtensive benchmarking demonstrates that the frequency-based algorithm achieves\nfaster performance than the standard DP in 100% of test cases with an average\nspeedup of 3.32x, a maximum speedup of 4.60x, and a minimum speedup of 2.31x\nacross matrices up to 5000x5000 with densities from 0.1 to 0.9. The algorithm's\naverage speedup exceeds 2.5x for all densities and rises to over 3.5x for\ndensities of 0.7 and higher across all matrix sizes. These results demonstrate\nthat the frequency-based approach is a superior alternative to standard DP and\nopens new possibilities for efficient matrix analysis in performance-critical\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.18974v3", "cate": "cs.DS", "date": "2025-03-22", "updated": "2025-07-21"}
{"id": "2501.09493", "title": "Evaluating Conversational Recommender Systems via Large Language Models: A User-Centric Framework", "authors": ["Nuo Chen", "Quanyu Dai", "Xiaoyu Dong", "Piaohong Wang", "Qinglin Jia", "Zhaocheng Du", "Zhenhua Dong", "Xiao-Ming Wu"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.09493v3", "summary": "Conversational recommender systems (CRSs) integrate both recommendation and\ndialogue tasks, making their evaluation uniquely challenging. Existing\napproaches primarily assess CRS performance by separately evaluating item\nrecommendation and dialogue management using rule-based metrics. However, these\nmethods fail to capture the real human experience, and they cannot draw direct\nconclusions about the system's overall performance. As conversational\nrecommender systems become increasingly vital in e-commerce, social media, and\ncustomer support, the ability to evaluate both recommendation accuracy and\ndialogue management quality using a single metric, thereby authentically\nreflecting user experience, has become the principal challenge impeding\nprogress in this field.\n  In this work, we propose a user-centric evaluation framework based on large\nlanguage models (LLMs) for CRSs, namely Conversational Recommendation Evaluator\n(CoRE). CoRE consists of two main components: (1) LLM-As-Evaluator. Firstly, we\ncomprehensively summarize 12 key factors influencing user experience in CRSs\nand directly leverage LLM as an evaluator to assign a score to each factor. (2)\nMulti-Agent Debater. Secondly, we design a multi-agent debate framework with\nfour distinct roles (common user, domain expert, linguist, and HCI expert) to\ndiscuss and synthesize the 12 evaluation factors into a unified overall\nperformance score.\n  Furthermore, we apply the proposed framework to evaluate four CRSs on two\nbenchmark datasets. The experimental results show that CoRE aligns well with\nhuman evaluation in most of the 12 factors and the overall assessment.\nEspecially, CoRE's overall evaluation scores demonstrate significantly better\nalignment with human feedback compared to existing rule-based metrics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.09493v3", "cate": "cs.IR", "date": "2025-01-16", "updated": "2025-07-21"}
{"id": "2505.12982", "title": "Multi-parameter Control for the $(1+(λ,λ))$-GA on OneMax via Deep Reinforcement Learning", "authors": ["Tai Nguyen", "Phong Le", "Carola Doerr", "Nguyen Dang"], "categories": ["cs.LG", "cs.NE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.12982v3", "summary": "It is well known that evolutionary algorithms can benefit from dynamic\nchoices of the key parameters that control their behavior, to adjust their\nsearch strategy to the different stages of the optimization process. A\nprominent example where dynamic parameter choices have shown a provable\nsuper-constant speed-up is the $(1+(\\lambda,\\lambda))$ Genetic Algorithm\noptimizing the OneMax function. While optimal parameter control policies result\nin linear expected running times, this is not possible with static parameter\nchoices. This result has spurred a lot of interest in parameter control\npolicies. However, many works, in particular theoretical running time analyses,\nfocus on controlling one single parameter. Deriving policies for controlling\nmultiple parameters remains very challenging. In this work we reconsider the\nproblem of the $(1+(\\lambda,\\lambda))$ Genetic Algorithm optimizing OneMax. We\ndecouple its four main parameters and investigate how well state-of-the-art\ndeep reinforcement learning techniques can approximate good control policies.\nWe show that although making deep reinforcement learning learn effectively is a\nchallenging task, once it works, it is very powerful and is able to find\npolicies that outperform all previously known control policies on the same\nbenchmark. Based on the results found through reinforcement learning, we derive\na simple control policy that consistently outperforms the default\ntheory-recommended setting by $27\\%$ and the irace-tuned policy, the strongest\nexisting control policy on this benchmark, by $13\\%$, for all tested problem\nsizes up to $40{,}000$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.12982v3", "cate": "cs.LG", "date": "2025-05-19", "updated": "2025-07-19"}
{"id": "2507.14774", "title": "Thermodynamically Consistent Modeling and Stable ALE Approximations of Reactive Semi-Permeable Interfaces", "authors": ["Weidong Shi", "Shixin Xu", "Zhen Zhang", "Quan Zhao"], "categories": ["math.NA", "cs.NA", "math.DS", "92C10, 76T06, 65M06, 65M50"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      35 pages, 21 figures", "url": "http://arxiv.org/abs/2507.14774v1", "summary": "Reactive, semi-permeable interfaces play important roles in key biological\nprocesses such as targeted drug delivery, lipid metabolism, and signal\ntransduction. These systems involve coupled surface reactions, transmembrane\ntransport, and interfacial deformation, often triggered by local biochemical\nsignals. The strong mechanochemical couplings complicate the modeling of such\ninterfacial dynamics. We propose a thermodynamically consistent continuum\nframework that integrates bulk fluid motion, interfacial dynamics, surface\nchemistry, and selective solute exchange, derived via an energy variation\napproach to ensure mass conservation and energy dissipation. To efficiently\nsolve the resulting coupled system, we develop a finite element scheme within\nan Arbitrary Lagrangian-Eulerian (ALE) framework, incorporating the\nBarrett-Garcke-Nurnberg (BGN) strategy to maintain mesh regularity and preserve\nconservation laws. Numerical experiments verify the convergence and\nconservation properties of the scheme and demonstrate its ability in capturing\ncomplex interfacial dynamics. Two biologically inspired examples showcase the\nmodel's versatility: cholesterol efflux via the ABCG1 pathway, involving\nmultistage interfacial reactions and HDL uptake; and a self-propelled droplet\nsystem with reaction-activated permeability, mimicking drug release in\npathological environments. This work provides a unified computational platform\nfor studying strongly coupled biochemical and mechanical interactions at\ninterfaces, offering new insights into reactive transport processes in both\nbiological and industrial contexts.", "comment": "35 pages, 21 figures", "pdf_url": "http://arxiv.org/pdf/2507.14774v1", "cate": "math.NA", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14597", "title": "Towards a Proactive Autoscaling Framework for Data Stream Processing at the Edge using GRU and Transfer Learning", "authors": ["Eugene Armah", "Linda Amoako Bannning"], "categories": ["cs.DC", "cs.CV", "cs.LG", "cs.PF"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14597v1", "summary": "Processing data at high speeds is becoming increasingly critical as digital\neconomies generate enormous data. The current paradigms for timely data\nprocessing are edge computing and data stream processing (DSP). Edge computing\nplaces resources closer to where data is generated, while stream processing\nanalyzes the unbounded high-speed data in motion. However, edge stream\nprocessing faces rapid workload fluctuations, complicating resource\nprovisioning. Inadequate resource allocation leads to bottlenecks, whereas\nexcess allocation results in wastage. Existing reactive methods, such as\nthreshold-based policies and queuing theory scale only after performance\ndegrades, potentially violating SLAs. Although reinforcement learning (RL)\noffers a proactive approach through agents that learn optimal runtime\nadaptation policies, it requires extensive simulation. Furthermore, predictive\nmachine learning models face online distribution and concept drift that\nminimize their accuracy. We propose a three-step solution to the proactive edge\nstream processing autoscaling problem. Firstly, a GRU neural network forecasts\nthe upstream load using real-world and synthetic DSP datasets. Secondly, a\ntransfer learning framework integrates the predictive model into an online\nstream processing system using the DTW algorithm and joint distribution\nadaptation to handle the disparities between offline and online domains.\nFinally, a horizontal autoscaling module dynamically adjusts the degree of\noperator parallelism, based on predicted load while considering edge resource\nconstraints. The lightweight GRU model for load predictions recorded up to\n1.3\\% SMAPE value on a real-world data set. It outperformed CNN, ARIMA, and\nProphet on the SMAPE and RMSE evaluation metrics, with lower training time than\nthe computationally intensive RL models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14597v1", "cate": "cs.DC", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.06174", "title": "Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model", "authors": ["Koki Yamane", "Yunhan Li", "Masashi Konosu", "Koki Inami", "Junji Oaki", "Sho Sakaino", "Toshiaki Tsuji"], "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      20 pages, 9 figures, Submitted to CoRL 2025", "url": "http://arxiv.org/abs/2507.06174v4", "summary": "In recent years, the advancement of imitation learning has led to increased\ninterest in teleoperating low-cost manipulators to collect demonstration data.\nHowever, most existing systems rely on unilateral control, which only transmits\ntarget position values. While this approach is easy to implement and suitable\nfor slow, non-contact tasks, it struggles with fast or contact-rich operations\ndue to the absence of force feedback. This work demonstrates that fast\nteleoperation with force feedback is feasible even with force-sensorless,\nlow-cost manipulators by leveraging 4-channel bilateral control. Based on\naccurately identified manipulator dynamics, our method integrates nonlinear\nterms compensation, velocity and external force estimation, and variable gain\ncorresponding to inertial variation. Furthermore, using data collected by\n4-channel bilateral control, we show that incorporating force information into\nboth the input and output of learned policies improves performance in imitation\nlearning. These results highlight the practical effectiveness of our system for\nhigh-fidelity teleoperation and data collection on affordable hardware.", "comment": "20 pages, 9 figures, Submitted to CoRL 2025", "pdf_url": "http://arxiv.org/pdf/2507.06174v4", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-19"}
{"id": "2507.14499", "title": "Neural Brownian Motion", "authors": ["Qian Qi"], "categories": ["math.PR", "cs.AI", "cs.LG", "math.OC", "stat.ML"], "primary_category": "Subjects:       Probability (math.PR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14499v1", "summary": "This paper introduces the Neural-Brownian Motion (NBM), a new class of\nstochastic processes for modeling dynamics under learned uncertainty. The NBM\nis defined axiomatically by replacing the classical martingale property with\nrespect to linear expectation with one relative to a non-linear Neural\nExpectation Operator, $\\varepsilon^\\theta$, generated by a Backward Stochastic\nDifferential Equation (BSDE) whose driver $f_\\theta$ is parameterized by a\nneural network. Our main result is a representation theorem for a canonical\nNBM, which we define as a continuous $\\varepsilon^\\theta$-martingale with zero\ndrift under the physical measure. We prove that, under a key structural\nassumption on the driver, such a canonical NBM exists and is the unique strong\nsolution to a stochastic differential equation of the form ${\\rm d} M_t =\n\\nu_\\theta(t, M_t) {\\rm d} W_t$. Crucially, the volatility function\n$\\nu_\\theta$ is not postulated a priori but is implicitly defined by the\nalgebraic constraint $g_\\theta(t, M_t, \\nu_\\theta(t, M_t)) = 0$, where\n$g_\\theta$ is a specialization of the BSDE driver. We develop the stochastic\ncalculus for this process and prove a Girsanov-type theorem for the quadratic\ncase, showing that an NBM acquires a drift under a new, learned measure. The\ncharacter of this measure, whether pessimistic or optimistic, is endogenously\ndetermined by the learned parameters $\\theta$, providing a rigorous foundation\nfor models where the attitude towards uncertainty is a discoverable feature.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14499v1", "cate": "math.PR", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15082", "title": "Robust Control with Gradient Uncertainty", "authors": ["Qian Qi"], "categories": ["cs.LG", "cs.AI", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15082v1", "summary": "We introduce a novel extension to robust control theory that explicitly\naddresses uncertainty in the value function's gradient, a form of uncertainty\nendemic to applications like reinforcement learning where value functions are\napproximated. We formulate a zero-sum dynamic game where an adversary perturbs\nboth system dynamics and the value function gradient, leading to a new, highly\nnonlinear partial differential equation: the Hamilton-Jacobi-Bellman-Isaacs\nEquation with Gradient Uncertainty (GU-HJBI). We establish its well-posedness\nby proving a comparison principle for its viscosity solutions under a uniform\nellipticity condition. Our analysis of the linear-quadratic (LQ) case yields a\nkey insight: we prove that the classical quadratic value function assumption\nfails for any non-zero gradient uncertainty, fundamentally altering the problem\nstructure. A formal perturbation analysis characterizes the non-polynomial\ncorrection to the value function and the resulting nonlinearity of the optimal\ncontrol law, which we validate with numerical studies. Finally, we bridge\ntheory to practice by proposing a novel Gradient-Uncertainty-Robust\nActor-Critic (GURAC) algorithm, accompanied by an empirical study demonstrating\nits effectiveness in stabilizing training. This work provides a new direction\nfor robust control, holding significant implications for fields where function\napproximation is common, including reinforcement learning and computational\nfinance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15082v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14976", "title": "Hierarchical Cross-modal Prompt Learning for Vision-Language Models", "authors": ["Hao Zheng", "Shunzhi Yang", "Zhuoxin He", "Jinfeng Yang", "Zhenhua Huang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV2025", "url": "http://arxiv.org/abs/2507.14976v1", "summary": "Pre-trained Vision-Language Models (VLMs) such as CLIP have shown excellent\ngeneralization abilities. However, adapting these large-scale models to\ndownstream tasks while preserving their generalization capabilities remains\nchallenging. Although prompt learning methods have shown promise, they suffer\nfrom two fundamental bottlenecks that limit generalization: (a) modality\nisolation, and (b) hierarchical semantic decay. To address these limitations,\nwe propose HiCroPL, a Hierarchical Cross-modal Prompt Learning framework that\nestablishes bidirectional knowledge flow between text and vision modalities,\nenabling them to refine their semantics mutually. HiCroPL routes knowledge\nflows by leveraging the complementary strengths of text and vision. In early\nlayers, text prompts inject relatively clear semantics into visual prompts\nthrough a hierarchical knowledge mapper, enhancing the representation of\nlow-level visual semantics. In later layers, visual prompts encoding specific\ntask-relevant objects flow back to refine text prompts, enabling deeper\nalignment. Crucially, our hierarchical knowledge mapper allows representations\nat multi-scales to be fused, ensuring that deeper representations retain\ntransferable shallow semantics thereby enhancing generalization. We further\nintroduce a lightweight layer-specific knowledge proxy to enable efficient\ncross-modal interactions. Extensive evaluations across four tasks demonstrate\nHiCroPL's superior performance, achieving state-of-the-art results on 11\nbenchmarks with significant improvements. Code is available at:\nhttps://github.com/zzeoZheng/HiCroPL.", "comment": "Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.14976v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14937", "title": "Phase-optimised linearly-constrained minimum-variance beamformers", "authors": ["Hugh L Kennedy"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Initial draft", "url": "http://arxiv.org/abs/2507.14937v1", "summary": "A novel procedure for the determination of the optimal group-delay for a\nLinearly-Constrained Minimum-Variance (LCMV) beamformer is proposed. Two ways\nof selecting the optimal delay are recommended: the first is the solution that\nminimizes the noise power; the second is the solution that minimizes the\nprocessing delay. The potential of this hitherto unexplored degree of design\nfreedom is explored using simulated Very-High-Frequency (VHF) communication,\nand Ultra-High-Frequency (UHF) bistatic radar, applications.", "comment": "Initial draft", "pdf_url": "http://arxiv.org/pdf/2507.14937v1", "cate": "eess.SP", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2506.17556", "title": "Faster Low-Rank Approximation and Kernel Ridge Regression via the Block-Nyström Method", "authors": ["Sachin Garg", "Michał Dereziński"], "categories": ["cs.DS", "cs.LG"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.17556v2", "summary": "The Nystr\\\"om method is a popular low-rank approximation technique for large\nmatrices that arise in kernel methods and convex optimization. Yet, when the\ndata exhibits heavy-tailed spectral decay, the effective dimension of the\nproblem often becomes so large that even the Nystr\\\"om method may be outside of\nour computational budget. To address this, we propose Block-Nystr\\\"om, an\nalgorithm that injects a block-diagonal structure into the Nystr\\\"om method,\nthereby significantly reducing its computational cost while recovering strong\napproximation guarantees. We show that Block-Nystr\\\"om can be used to construct\nimproved preconditioners for second-order optimization, as well as to\nefficiently solve kernel ridge regression for statistical learning over Hilbert\nspaces. Our key technical insight is that, within the same computational\nbudget, combining several smaller Nystr\\\"om approximations leads to stronger\ntail estimates of the input spectrum than using one larger approximation. Along\nthe way, we provide a novel recursive preconditioning scheme for efficiently\ninverting the Block-Nystr\\\"om matrix, and provide new statistical learning\nbounds for a broad class of approximate kernel ridge regression solvers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.17556v2", "cate": "cs.DS", "date": "2025-06-21", "updated": "2025-07-19"}
{"id": "2503.01334", "title": "Composed Multi-modal Retrieval: A Survey of Approaches and Applications", "authors": ["Kun Zhang", "Jingyu Li", "Zhe Li", "Jingjing Zhang", "Fan Li", "Yandong Liu", "Rui Yan", "Zihang Jiang", "Nan Chen", "Lei Zhang", "Yongdong Zhang", "Zhendong Mao", "S. Kevin Zhou"], "categories": ["cs.IR", "cs.CV"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.01334v2", "summary": "The burgeoning volume of multi-modal data necessitates advanced retrieval\nparadigms beyond unimodal and cross-modal approaches. Composed Multi-modal\nRetrieval (CMR) emerges as a pivotal next-generation technology, enabling users\nto query images or videos by integrating a reference visual input with textual\nmodifications, thereby achieving unprecedented flexibility and precision. This\npaper provides a comprehensive survey of CMR, covering its fundamental\nchallenges, technical advancements, and applications. CMR is categorized into\nsupervised, zero-shot, and semi-supervised learning paradigms. We discuss key\nresearch directions, including data construction, model architecture, and loss\noptimization in supervised CMR, as well as transformation frameworks and linear\nintegration in zero-shot CMR, and semi-supervised CMR that leverages generated\npseudo-triplets while addressing data noise/uncertainty. Additionally, we\nextensively survey the diverse application landscape of CMR, highlighting its\ntransformative potential in e-commerce, social media, search engines, public\nsecurity, etc. Seven high impact application scenarios are explored in detail\nwith benchmark data sets and performance analysis. Finally, we further provide\nnew potential research directions with the hope of inspiring exploration in\nother yet-to-be-explored fields. A curated list of works is available at:\nhttps://github.com/kkzhang95/Awesome-Composed-Multi-modal-Retrieval", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.01334v2", "cate": "cs.IR", "date": "2025-03-03", "updated": "2025-07-19"}
{"id": "2507.14881", "title": "An adaptive symplectic integrator for gravitational dynamics", "authors": ["Keqi Ye", "Zizhe Cai", "Mingji Wang", "Kun Yang", "Xiaodong Liu"], "categories": ["math.NA", "astro-ph.GA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14881v1", "summary": "This paper presents an adaptive symplectic integrator, SQQ-PTQ, developed on\nthe basis of the fixed-step symplectic integrator SQQ. To mitigate the Runge\nphenomenon, SQQ-PTQ employs Chebyshev interpolation for approximating the\naction, enhancing both the precision and stability of the interpolation. In\naddition, to reduce the computational cost of evaluating interpolation\nfunctions, SQQ-PTQ introduces a projection method that improves the efficiency\nof these computations. A key feature of SQQ-PTQ is its use of the time\ntransformation to implement an adaptive time step. To address the challenge of\ncomputing complicated Jacobian matrices attributed to the time transformation,\nSQQ-PTQ adopts a quasi-Newton method based on Broyden's method. This strategy\naccelerates the solution of nonlinear equations, thereby improving the overall\ncomputational performance. The effectiveness and robustness of SQQ-PTQ are\ndemonstrated via three numerical experiments. In particular, SQQ-PTQ\ndemonstrates adaptability in handling close-encounter problems. Moreover,\nduring long-term integrations, SQQ-PTQ maintains the energy conservation,\nfurther confirming its advantages as a symplectic algorithm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14881v1", "cate": "math.NA", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14723", "title": "Simulating Chirality: Solving Distance-$k$-Dispersion on an 1-Interval Connected Ring", "authors": ["Brati Mondal", "Pritam Goswami", "Buddhadeb Sau"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14723v1", "summary": "We study the Distance-$k$-Dispersion (D-$k$-D) problem for synchronous mobile\nagents in a 1-interval-connected ring network having $n$ nodes and with $l$\nagents where $3 \\le l \\le \\lfloor \\frac{n}{k}\\rfloor$, without the assumption\nof chirality (a common sense of direction for the agents). This generalizes the\nclassical dispersion problem by requiring that agents maintain a minimum\ndistance of $k$ hops from each other, with the special case $k=1$ corresponding\nto the standard dispersion.\n  The contribution in this work is threefold. Our first contribution is a novel\nmethod that enables agents to simulate chirality using only local information,\nvision and bounded memory. This technique demonstrates that chirality is not a\nfundamental requirement for coordination in this model.\n  Building on this, our second contribution partially resolves an open question\nposed by Agarwalla et al. (ICDCN, 2018), who considered the same model (1-\ninterval connected ring, synchronous agents, no chirality). We prove that\nD-$k$-D, and thus dispersion is solvable from any arbitrary configuration under\nthese assumptions (excluding vertex permutation dynamism)for any size of the\nring network which was earlier limited to only odd sized ring or to a ring of\nsize four.\n  Finally, we present an algorithm for D-$k$-D in this setting that works in\n$O(ln)$ rounds, completing the constructive side of our result.\n  Altogether, our findings significantly extend the theoretical understanding\nof mobile agent coordination in dynamic networks and clarify the role of\nchirality in distributed computation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14723v1", "cate": "cs.DC", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.07872", "title": "Improving AEBS Validation Through Objective Intervention Classification Leveraging the Prediction Divergence Principle", "authors": ["Daniel Betschinske", "Steven Peters"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This work has been accepted for publication at the 2025 IEEE International Automated Vehicle Validation Conference (IAVVC)", "url": "http://arxiv.org/abs/2507.07872v2", "summary": "The safety validation of automatic emergency braking system (AEBS) requires\naccurately distinguishing between false positive (FP) and true positive (TP)\nsystem activations. While simulations allow straightforward differentiation by\ncomparing scenarios with and without interventions, analyzing activations from\nopen-loop resimulations - such as those from field operational testing (FOT) -\nis more complex. This complexity arises from scenario parameter uncertainty and\nthe influence of driver interventions in the recorded data. Human labeling is\nfrequently used to address these challenges, relying on subjective assessments\nof intervention necessity or situational criticality, potentially introducing\nbiases and limitations. This work proposes a rule-based classification approach\nleveraging the Prediction Divergence Principle (PDP) to address those issues.\nApplied to a simplified AEBS, the proposed method reveals key strengths,\nlimitations, and system requirements for effective implementation. The findings\nsuggest that combining this approach with human labeling may enhance the\ntransparency and consistency of classification, thereby improving the overall\nvalidation process. While the rule set for classification derived in this work\nadopts a conservative approach, the paper outlines future directions for\nrefinement and broader applicability. Finally, this work highlights the\npotential of such methods to complement existing practices, paving the way for\nmore reliable and reproducible AEBS validation frameworks.", "comment": "This work has been accepted for publication at the 2025 IEEE\n  International Automated Vehicle Validation Conference (IAVVC)", "pdf_url": "http://arxiv.org/pdf/2507.07872v2", "cate": "cs.RO", "date": "2025-07-10", "updated": "2025-07-21"}
{"id": "2507.14507", "title": "Diffusion Models for Time Series Forecasting: A Survey", "authors": ["Chen Su", "Zhengzhou Cai", "Yuanhe Tian", "Zihong Zheng", "Yan Song"], "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14507v1", "summary": "Diffusion models, initially developed for image synthesis, demonstrate\nremarkable generative capabilities. Recently, their application has expanded to\ntime series forecasting (TSF), yielding promising results. In this survey, we\nfirstly introduce the standard diffusion models and their prevalent variants,\nexplaining their adaptation to TSF tasks. We then provide a comprehensive\nreview of diffusion models for TSF, paying special attention to the sources of\nconditional information and the mechanisms for integrating this conditioning\nwithin the models. In analyzing existing approaches using diffusion models for\nTSF, we provide a systematic categorization and a comprehensive summary of them\nin this survey. Furthermore, we examine several foundational diffusion models\napplied to TSF, alongside commonly used datasets and evaluation metrics.\nFinally, we discuss current limitations in these approaches and potential\nfuture research directions. Overall, this survey details recent progress and\nfuture prospects for diffusion models in TSF, serving as a reference for\nresearchers in the field.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14507v1", "cate": "stat.ML", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15104", "title": "AnalogFed: Federated Discovery of Analog Circuit Topologies with Generative AI", "authors": ["Qiufeng Li", "Shu Hong", "Jian Gao", "Xuan Zhang", "Tian Lan", "Weidong Cao"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15104v1", "summary": "Recent breakthroughs in AI/ML offer exciting opportunities to revolutionize\nanalog design automation through data-driven approaches. In particular,\nresearchers are increasingly fascinated by harnessing the power of generative\nAI to automate the discovery of novel analog circuit topologies. Unlocking the\nfull potential of generative AI in these data-driven discoveries requires\naccess to large and diverse datasets.Yet, there is a significant barrier in the\nanalog domain--Analog circuit design is inherently proprietary, involving not\nonly confidential circuit structures but also the underlying commercial\nsemiconductor processes. As a result, current generative AI research is largely\nconfined to individual researchers who construct small, narrowly focused\nprivate datasets. This fragmentation severely limits collaborative innovation\nand impedes progress across the research community. To address these\nchallenges, we propose AnalogFed. AnalogFed enables collaborative topology\ndiscovery across decentralized clients (e.g., individual researchers or\ninstitutions) without requiring the sharing of raw private data. To make this\nvision practical, we introduce a suite of techniques tailored to the unique\nchallenges of applying FedL in analog design--from generative model development\nand data heterogeneity handling to privacy-preserving strategies that ensure\nboth flexibility and security for circuit designers and semiconductor\nmanufacturers. Extensive experiments across varying client counts and dataset\nsizes demonstrate that AnalogFed achieves performance comparable to centralized\nbaselines--while maintaining strict data privacy. Specifically, the generative\nAI model within AnalogFed achieves state-of-the-art efficiency and scalability\nin the design of analog circuit topologies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15104v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14997", "title": "Language Integration in Fine-Tuning Multimodal Large Language Models for Image-Based Regression", "authors": ["Roy H. Jennings", "Genady Paikin", "Roy Shaul", "Evgeny Soloveichik"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14997v1", "summary": "Multimodal Large Language Models (MLLMs) show promise for image-based\nregression tasks, but current approaches face key limitations. Recent methods\nfine-tune MLLMs using preset output vocabularies and generic task-level prompts\n(e.g., \"How would you rate this image?\"), assuming this mimics human rating\nbehavior. Our analysis reveals these approaches provide no benefit over\nimage-only training. Models using preset vocabularies and generic prompts\nperform equivalently to image-only models, failing to leverage semantic\nunderstanding from textual input. We propose Regression via Transformer-Based\nClassification (RvTC), which replaces vocabulary-constrained classification\nwith a flexible bin-based approach. Unlike approaches that address\ndiscretization errors through complex distributional modeling, RvTC eliminates\nmanual vocabulary crafting through straightforward bin increase, achieving\nstate-of-the-art performance on four image assessment datasets using only\nimages. More importantly, we demonstrate that data-specific prompts\ndramatically improve performance. Unlike generic task descriptions, prompts\ncontaining semantic information about specific images enable MLLMs to leverage\ncross-modal understanding. On the AVA dataset, adding challenge titles to\nprompts improves correlations from 0.83 to 0.90, a new state-of-the-art. We\ndemonstrate through empirical evidence from the AVA and AGIQA-3k datasets that\nMLLMs benefit from semantic prompt information surpassing mere statistical\nbiases. This underscores the importance of incorporating meaningful textual\ncontext in multimodal regression tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14997v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14945", "title": "Jamming-Resistant AAV Communications: A Multichannel-Aided Approach", "authors": ["Bin Wang", "Jun Fang", "Jieru Du", "Shihai Shao"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14945v1", "summary": "Jamming cancellation is essential to reliable unmanned autonomous vehicle\n(AAV) communications in the presence of malicious jammers. In this paper, we\ndevelop a practical multichannel-aided jamming cancellation method to realize\nsecure AAV communications. The proposed method is capable of simultaneously\nachieving timing/frequency synchronization as well as jamming cancellation.\nMore importantly, our method does not need the signal's/jammer's channel state\ninformation. It only utilizes the knowledge of the legitimate sender's preamble\nsequence that is available in existing communication protocols. We also analyze\nthe length of the preamble sequence required for successful synchronization and\nsignal recovery. Experimental results on the built hardware platform show that,\nwith a two-antenna receiver, the proposed method can successfully decode the\nsignal of interest even when the jamming signal is $40$dB stronger than the\ncommunication signal.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14945v1", "cate": "eess.SP", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2506.20687", "title": "Review of Three Algorithms That Build k-d Trees", "authors": ["Russell A. Brown"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      29 pages, 11 figures, one listing, one table", "url": "http://arxiv.org/abs/2506.20687v5", "summary": "The original description of the k-d tree recognized that rebalancing\ntechniques, such as used to build an AVL tree or a red-black tree, are not\napplicable to a k-d tree. Hence, in order to build a balanced k-d tree, it is\nnecessary to find the median of a set of data for each recursive subdivision of\nthat set. The sort or selection used to find the median, and the technique used\nto partition the set about that median, strongly influence the computational\ncomplexity of building a k-d tree. This article describes and contrasts three\nk-d tree-building algorithms that differ in their technique used to partition\nthe set, and compares the performance of the algorithms. In addition,\ndual-threaded execution is proposed for one of the three algorithms.", "comment": "29 pages, 11 figures, one listing, one table", "pdf_url": "http://arxiv.org/pdf/2506.20687v5", "cate": "cs.DS", "date": "2025-06-25", "updated": "2025-07-18"}
{"id": "2504.17814", "title": "FIM: Frequency-Aware Multi-View Interest Modeling for Local-Life Service Recommendation", "authors": ["Guoquan Wang", "Qiang Luo", "Weisong Hu", "Pengfei Yao", "Wencong Zeng", "Guorui Zhou", "Kun Gai"], "categories": ["cs.IR", "H.3.3"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures, Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '25), July 13--18, 2025, Padua, Italy", "url": "http://arxiv.org/abs/2504.17814v3", "summary": "People's daily lives involve numerous periodic behaviors, such as eating and\ntraveling. Local-life platforms cater to these recurring needs by providing\nessential services tied to daily routines. Therefore, users' periodic\nintentions are reflected in their interactions with the platforms. There are\ntwo main challenges in modeling users' periodic behaviors in the local-life\nservice recommendation systems: 1) the diverse demands of users exhibit varying\nperiodicities, which are difficult to distinguish as they are mixed in the\nbehavior sequences; 2) the periodic behaviors of users are subject to dynamic\nchanges due to factors such as holidays and promotional events. Existing\nmethods struggle to distinguish the periodicities of diverse demands and\noverlook the importance of dynamically capturing changes in users' periodic\nbehaviors. To this end, we employ a Frequency-Aware Multi-View Interest\nModeling framework (FIM). Specifically, we propose a multi-view search strategy\nthat decomposes users' demands from different perspectives to separate their\nvarious periodic intentions. This allows the model to comprehensively extract\ntheir periodic features than category-searched-only methods. Moreover, we\npropose a frequency-domain perception and evolution module. This module uses\nthe Fourier Transform to convert users' temporal behaviors into the frequency\ndomain, enabling the model to dynamically perceive their periodic features.\nExtensive offline experiments demonstrate that FIM achieves significant\nimprovements on public and industrial datasets, showing its capability to\neffectively model users' periodic intentions. Furthermore, the model has been\ndeployed on the Kuaishou local-life service platform. Through online A/B\nexperiments, the transaction volume has been significantly improved.", "comment": "10 pages, 5 figures, Proceedings of the 48th International ACM SIGIR\n  Conference on Research and Development in Information Retrieval (SIGIR '25),\n  July 13--18, 2025, Padua, Italy", "pdf_url": "http://arxiv.org/pdf/2504.17814v3", "cate": "cs.IR", "date": "2025-04-23", "updated": "2025-07-20"}
{"id": "2507.14939", "title": "A second-order generalized BDF method for the two-dimensional (modified) Fisher-Kolmogorov-Petrovsky-Piskunov equation", "authors": ["Lei Ge", "Yong-Liang Zhao"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      4 figures", "url": "http://arxiv.org/abs/2507.14939v1", "summary": "The Kolmogorov-Petrovsky-Piskunov (Fisher-KPP) equation is a classical\nreaction-diffusion equation with broad applications such as biology, chemistry\nand physics. In this paper, an alternative second-order scheme is proposed by\nemploying a shifted BDF2 method to approximate the two-dimensional (modified)\nFisher-KPP equation. We both consider an uniform and a nonuniform time steps of\nsuch the scheme. The stability of the uniform discretization scheme is proved.\nNumerical experiments demonstrate that our uniform and non-uniform schemes are\nrobust and accurate.", "comment": "4 figures", "pdf_url": "http://arxiv.org/pdf/2507.14939v1", "cate": "math.NA", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14802", "title": "ACME: Adaptive Customization of Large Models via Distributed Systems", "authors": ["Ziming Dai", "Chao Qiu", "Fei Gao", "Yunfeng Zhao", "Xiaofei Wang"], "categories": ["cs.DC", "cs.AI", "C.2.4; I.2.6"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE ICDCS 2025. 11 pages, 13 figures", "url": "http://arxiv.org/abs/2507.14802v1", "summary": "Pre-trained Transformer-based large models have revolutionized personal\nvirtual assistants, but their deployment in cloud environments faces challenges\nrelated to data privacy and response latency. Deploying large models closer to\nthe data and users has become a key research area to address these issues.\nHowever, applying these models directly often entails significant difficulties,\nsuch as model mismatching, resource constraints, and energy inefficiency.\nAutomated design of customized models is necessary, but it faces three key\nchallenges, namely, the high cost of centralized model customization,\nimbalanced performance from user heterogeneity, and suboptimal performance from\ndata heterogeneity. In this paper, we propose ACME, an adaptive customization\napproach of Transformer-based large models via distributed systems. To avoid\nthe low cost-efficiency of centralized methods, ACME employs a bidirectional\nsingle-loop distributed system to progressively achieve fine-grained\ncollaborative model customization. In order to better match user heterogeneity,\nit begins by customizing the backbone generation and identifying the Pareto\nFront under model size constraints to ensure optimal resource utilization.\nSubsequently, it performs header generation and refines the model using data\ndistribution-based personalized architecture aggregation to match data\nheterogeneity. Evaluation on different datasets shows that ACME achieves\ncost-efficient models under model size constraints. Compared to centralized\nsystems, data transmission volume is reduced to 6 percent. Additionally, the\naverage accuracy improves by 10 percent compared to the baseline, with the\ntrade-off metrics increasing by nearly 30 percent.", "comment": "Accepted to IEEE ICDCS 2025. 11 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.14802v1", "cate": "cs.DC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.08224", "title": "Making VLMs More Robot-Friendly: Self-Critical Distillation of Low-Level Procedural Reasoning", "authors": ["Chan Young Park", "Jillian Fisher", "Marius Memmel", "Dipika Khullar", "Seoho Yun", "Abhishek Gupta", "Yejin Choi"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Code Available: this https URL", "url": "http://arxiv.org/abs/2507.08224v2", "summary": "Large language models (LLMs) have shown promise in robotic procedural\nplanning, yet their human-centric reasoning often omits the low-level, grounded\ndetails needed for robotic execution. Vision-language models (VLMs) offer a\npath toward more perceptually grounded plans, but current methods either rely\non expensive, large-scale models or are constrained to narrow simulation\nsettings. We introduce SelfReVision, a lightweight and scalable\nself-improvement framework for vision-language procedural planning.\nSelfReVision enables small VLMs to iteratively critique, revise, and verify\ntheir own plans-without external supervision or teacher models-drawing\ninspiration from chain-of-thought prompting and self-instruct paradigms.\nThrough this self-distillation loop, models generate higher-quality,\nexecution-ready plans that can be used both at inference and for continued\nfine-tuning. Using models varying from 3B to 72B, our results show that\nSelfReVision not only boosts performance over weak base VLMs but also\noutperforms models 100X the size, yielding improved control in downstream\nembodied tasks.", "comment": "Code Available: https://github.com/chan0park/SelfReVision", "pdf_url": "http://arxiv.org/pdf/2507.08224v2", "cate": "cs.RO", "date": "2025-07-11", "updated": "2025-07-20"}
{"id": "2507.14579", "title": "Exploring Human-AI Complementarity in CPS Diagnosis Using Unimodal and Multimodal BERT Models", "authors": ["Kester Wong", "Sahan Bulathwela", "Mutlu Cukurova"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to appear in the workshop proceedings for the HEXED'25 workshop in the 26th International Conference on Artificial Intelligence in Education 2025 (AIED 2025), 22 July 2025, Palermo, Italy. 5 pages", "url": "http://arxiv.org/abs/2507.14579v1", "summary": "Detecting collaborative problem solving (CPS) indicators from dialogue using\nmachine learning techniques is a significant challenge for the field of AI in\nEducation. Recent studies have explored the use of Bidirectional Encoder\nRepresentations from Transformers (BERT) models on transcription data to\nreliably detect meaningful CPS indicators. A notable advancement involved the\nmultimodal BERT variant, AudiBERT, which integrates speech and\nacoustic-prosodic audio features to enhance CPS diagnosis. Although initial\nresults demonstrated multimodal improvements, the statistical significance of\nthese enhancements remained unclear, and there was insufficient guidance on\nleveraging human-AI complementarity for CPS diagnosis tasks. This workshop\npaper extends the previous research by highlighting that the AudiBERT model not\nonly improved the classification of classes that were sparse in the dataset,\nbut it also had statistically significant class-wise improvements over the BERT\nmodel for classifications in the social-cognitive dimension. However, similar\nsignificant class-wise improvements over the BERT model were not observed for\nclassifications in the affective dimension. A correlation analysis highlighted\nthat larger training data was significantly associated with higher recall\nperformance for both the AudiBERT and BERT models. Additionally, the precision\nof the BERT model was significantly associated with high inter-rater agreement\namong human coders. When employing the BERT model to diagnose indicators within\nthese subskills that were well-detected by the AudiBERT model, the performance\nacross all indicators was inconsistent. We conclude the paper by outlining a\nstructured approach towards achieving human-AI complementarity for CPS\ndiagnosis, highlighting the crucial inclusion of model explainability to\nsupport human agency and engagement in the reflective coding process.", "comment": "Accepted to appear in the workshop proceedings for the HEXED'25\n  workshop in the 26th International Conference on Artificial Intelligence in\n  Education 2025 (AIED 2025), 22 July 2025, Palermo, Italy. 5 pages", "pdf_url": "http://arxiv.org/pdf/2507.14579v1", "cate": "cs.CL", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15119", "title": "Are We Overlooking the Dimensions? Learning Latent Hierarchical Channel Structure for High-Dimensional Time Series Forecasting", "authors": ["Juntong Ni", "Shiyu Wang", "Zewen Liu", "Xiaoming Shi", "Xinyue Zhong", "Zhou Ye", "Wei Jin"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15119v1", "summary": "Time series forecasting (TSF) is a central problem in time series analysis.\nHowever, as the number of channels in time series datasets scales to the\nthousands or more, a scenario we define as High-Dimensional Time Series\nForecasting (HDTSF), it introduces significant new modeling challenges that are\noften not the primary focus of traditional TSF research. HDTSF is challenging\nbecause the channel correlation often forms complex and hierarchical patterns.\nExisting TSF models either ignore these interactions or fail to scale as\ndimensionality grows. To address this issue, we propose U-Cast, a\nchannel-dependent forecasting architecture that learns latent hierarchical\nchannel structures with an innovative query-based attention. To disentangle\nhighly correlated channel representation, U-Cast adds a full-rank\nregularization during training. We also release Time-HD, a benchmark of large,\ndiverse, high-dimensional datasets. Our theory shows that exploiting\ncross-channel information lowers forecasting risk, and experiments on Time-HD\ndemonstrate that U-Cast surpasses strong baselines in both accuracy and\nefficiency. Together, U-Cast and Time-HD provide a solid basis for future HDTSF\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15119v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15000", "title": "Axis-Aligned Document Dewarping", "authors": ["Chaoyun Wang", "I-Chao Shen", "Takeo Igarashi", "Nanning Zheng", "Caigui Jiang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15000v1", "summary": "Document dewarping is crucial for many applications. However, existing\nlearning-based methods primarily rely on supervised regression with annotated\ndata without leveraging the inherent geometric properties in physical documents\nto the dewarping process. Our key insight is that a well-dewarped document is\ncharacterized by transforming distorted feature lines into axis-aligned ones.\nThis property aligns with the inherent axis-aligned nature of the discrete grid\ngeometry in planar documents. In the training phase, we propose an axis-aligned\ngeometric constraint to enhance document dewarping. In the inference phase, we\npropose an axis alignment preprocessing strategy to reduce the dewarping\ndifficulty. In the evaluation phase, we introduce a new metric, Axis-Aligned\nDistortion (AAD), that not only incorporates geometric meaning and aligns with\nhuman visual perception but also demonstrates greater robustness. As a result,\nour method achieves SOTA results on multiple existing benchmarks and achieves\n18.2%~34.5% improvements on the AAD metric.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15000v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14951", "title": "Latent-attention Based Transformer for Near ML Polar Decoding in Short-code Regime", "authors": ["Hongzhi Zhu", "Wei Xu", "Xiaohu You"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14951v1", "summary": "Transformer architectures have emerged as promising deep learning (DL) tools\nfor modeling complex sequence-to-sequence interactions in channel decoding.\nHowever, current transformer-based decoders for error correction codes (ECCs)\ndemonstrate inferior performance and generalization capabilities compared to\nconventional algebraic decoders, especially in short-code regimes. In this\nwork, we propose a novel latent-attention based transformer (LAT) decoder for\npolar codes that addresses the limitations on performance and generalization\nthrough three pivotal innovations. First, we develop a latent-attention\nmechanism that supersedes the conventional self-attention mechanism. This\narchitectural modification enables independent learning of the Query and Key\nmatrices for code-aware attention computation, decoupling them from the Value\nmatrix to emphasize position-wise decoding interactions while reducing context\ncorrelation interference. Second, we devise an advanced training framework\nincorporating three synergistic components: entropy-aware importance sampling\nthat emphasizes low-probability regions in the signal constellation space,\nexperience reflow that introduces empirical labels to improve characterization\nof decoding boundaries, and dynamic label smoothing for likelihood-based\nregularization. Third, we propose a code-aware mask scheme which allows dynamic\nadaptation for varying code configurations. Numerical evaluations demonstrate\nthat the proposed LAT decoder achieves near maximum-likelihood (ML) performance\nin terms of both bit error rate (BER) and block error rate (BLER) for\nshort-length polar codes. Furthermore, the architecture exhibits robust\ngeneralization capabilities across diverse code rates and code lengths.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14951v1", "cate": "eess.SP", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.05770", "title": "25 Additional Problems -- Extension to the Book \"125 Problems in Text Algorithms\"", "authors": ["Maxime Crochemore", "Thierry Lecroq", "Wojtek Rytter"], "categories": ["cs.DS", "68W32", "F.2.2"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      72 pages", "url": "http://arxiv.org/abs/2507.05770v2", "summary": "This very preliminary text is related to ``Algorithms on Texts'', also called\n``Algorithmic Stringology''. It is an extension of the book ``125 Problems in\nText Algorithms'' providing, in the same compact style, more problems with\nsolutions. We refer also to the companions to ``Text algorithms'' available at\nhttp://monge.univ-mlv.fr/~mac/CLR/clr1-20.pdf and at the web page\nhttp://125-problems.univ-mlv.fr, where all 150 problems (including the ones\npresented here) are briefly announced. The selected problems satisfy three\ncriteria: challenging, having short tricky solutions and solvable with only\nvery basic background in stringology. For the basics in stringology we refer to\nhttp://monge.univ-mlv.fr/~mac/CLR/clr1-20.pdf.", "comment": "72 pages", "pdf_url": "http://arxiv.org/pdf/2507.05770v2", "cate": "cs.DS", "date": "2025-07-08", "updated": "2025-07-21"}
{"id": "2505.13545", "title": "Know Or Not: a library for evaluating out-of-knowledge base robustness", "authors": ["Jessica Foo", "Pradyumna Shyama Prasad", "Shaun Khoo"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.13545v2", "summary": "While the capabilities of large language models (LLMs) have progressed\nsignificantly, their use in high-stakes applications have been limited due to\nrisks of hallucination. One key approach in reducing hallucination is\nretrieval-augmented generation (RAG), but even in such setups, LLMs may still\nhallucinate when presented with questions outside of the knowledge base. Such\nbehavior is unacceptable in high-stake applications where LLMs are expected to\nabstain from answering queries it does not have sufficient context on. In this\nwork, we present a novel methodology for systematically evaluating\nout-of-knowledge base (OOKB) robustness of LLMs (whether LLMs know or do not\nknow) in the RAG setting, without the need for manual annotation of gold\nstandard answers. We implement our methodology in knowornot, an open-source\nlibrary that enables users to develop their own customized evaluation data and\npipelines for OOKB robustness. knowornot comprises four main features. Firstly,\nit provides a unified, high-level API that streamlines the process of setting\nup and running robustness benchmarks. Secondly, its modular architecture\nemphasizes extensibility and flexibility, allowing users to easily integrate\ntheir own LLM clients and RAG settings. Thirdly, its rigorous data modeling\ndesign ensures experiment reproducibility, reliability and traceability.\nLastly, it implements a comprehensive suite of tools for users to customize\ntheir pipelines. We demonstrate the utility of knowornot by developing a\nchallenging benchmark, PolicyBench, which spans four Question-Answer (QA)\nchatbots on government policies, and analyze its OOKB robustness. The source\ncode of knowornot is available\nhttps://github.com/govtech-responsibleai/KnowOrNot.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.13545v2", "cate": "cs.IR", "date": "2025-05-19", "updated": "2025-07-21"}
{"id": "2507.14971", "title": "Quadrature formulas from rational approximations", "authors": ["Andrew Horning", "Lloyd N. Trefethen"], "categories": ["math.NA", "cs.NA", "41A20"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14971v1", "summary": "It is shown that quadrature formulas in many different applications can be\nderived from rational approximation of the Cauchy transform of a weight\nfunction. Since rational approximation is now a routine technology, this\nprovides an easy new method to derive all kinds of quadrature formulas as well\nas fundamental insight into the mathematics of quadrature. Intervals or curves\nof quadrature nodes correspond to near-optimal branch cuts of the Cauchy\ntransform.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14971v1", "cate": "math.NA", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14928", "title": "Byzantine-Robust Decentralized Coordination of LLM Agents", "authors": ["Yongrae Jo", "Chanik Park"], "categories": ["cs.DC", "cs.AI"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14928v1", "summary": "Collaboration among multiple large language model (LLM) agents is a promising\napproach to overcome inherent limitations of single-agent systems, such as\nhallucinations and single points of failure. As LLM agents are increasingly\ndeployed on open blockchain platforms, multi-agent systems capable of\ntolerating malicious (Byzantine) agents have become essential.\n  Recent Byzantine-robust multi-agent systems typically rely on leader-driven\ncoordination, which suffers from two major drawbacks. First, they are\ninherently vulnerable to targeted attacks against the leader. If consecutive\nleaders behave maliciously, the system repeatedly fails to achieve consensus,\nforcing new consensus rounds, which is particularly costly given the high\nlatency of LLM invocations. Second, an underperforming proposal from the leader\ncan be accepted as the final answer even when higher-quality alternatives are\navailable, as existing methods finalize the leader's proposal once it receives\na quorum of votes.\n  To address these issues, we propose DecentLLMs, a novel decentralized\nconsensus approach for multi-agent LLM systems, where worker agents generate\nanswers concurrently and evaluator agents independently score and rank these\nanswers to select the best available one. This decentralized architecture\nenables faster consensus despite the presence of Byzantine agents and\nconsistently selects higher-quality answers through Byzantine-robust\naggregation techniques.\n  Experimental results demonstrate that DecentLLMs effectively tolerates\nByzantine agents and significantly improves the quality of selected answers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14928v1", "cate": "cs.DC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14221", "title": "Identifying Algorithmic and Domain-Specific Bias in Parliamentary Debate Summarisation", "authors": ["Eoghan Cunningham", "James Cross", "Derek Greene"], "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14221v1", "summary": "The automated summarisation of parliamentary debates using large language\nmodels (LLMs) offers a promising way to make complex legislative discourse more\naccessible to the public. However, such summaries must not only be accurate and\nconcise but also equitably represent the views and contributions of all\nspeakers. This paper explores the use of LLMs to summarise plenary debates from\nthe European Parliament and investigates the algorithmic and representational\nbiases that emerge in this context. We propose a structured, multi-stage\nsummarisation framework that improves textual coherence and content fidelity,\nwhile enabling the systematic analysis of how speaker attributes -- such as\nspeaking order or political affiliation -- influence the visibility and\naccuracy of their contributions in the final summaries. Through our experiments\nusing both proprietary and open-weight LLMs, we find evidence of consistent\npositional and partisan biases, with certain speakers systematically\nunder-represented or misattributed. Our analysis shows that these biases vary\nby model and summarisation strategy, with hierarchical approaches offering the\ngreatest potential to reduce disparity. These findings underscore the need for\ndomain-sensitive evaluation metrics and ethical oversight in the deployment of\nLLMs for democratic applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14221v1", "cate": "cs.CY", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.09309", "title": "Informed Hybrid Zonotope-based Motion Planning Algorithm", "authors": ["Peng Xie", "Johannes Betz", "Amr Alanwar"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09309v2", "summary": "Optimal path planning in nonconvex free spaces is notoriously challenging, as\nformulating such problems as mixed-integer linear programs (MILPs) is NP-hard.\nWe propose HZ-MP, an informed Hybrid Zonotope-based Motion Planner, as an\nalternative approach that decomposes the obstacle-free space and performs\nlow-dimensional face sampling guided by an ellipsotope heuristic, enabling\nfocused exploration along promising transit regions. This structured\nexploration eliminates the excessive, unreachable sampling that degrades\nexisting informed planners such as AIT* and EIT* in narrow gaps or boxed-goal\nscenarios. We prove that HZ-MP is probabilistically complete and asymptotically\noptimal. It converges to near-optimal trajectories in finite time and scales to\nhigh-dimensional cluttered scenes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09309v2", "cate": "cs.RO", "date": "2025-07-12", "updated": "2025-07-19"}
{"id": "2507.14584", "title": "Explainable Collaborative Problem Solving Diagnosis with BERT using SHAP and its Implications for Teacher Adoption", "authors": ["Kester Wong", "Sahan Bulathwela", "Mutlu Cukurova"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to appear in the workshop proceedings for the HEXED'25 workshop in the 26th International Conference on Artificial Intelligence in Education 2025 (AIED 2025), 22 July 2025, Palermo, Italy. 6 pages, 2 figures", "url": "http://arxiv.org/abs/2507.14584v1", "summary": "The use of Bidirectional Encoder Representations from Transformers (BERT)\nmodel and its variants for classifying collaborative problem solving (CPS) has\nbeen extensively explored within the AI in Education community. However,\nlimited attention has been given to understanding how individual tokenised\nwords in the dataset contribute to the model's classification decisions.\nEnhancing the explainability of BERT-based CPS diagnostics is essential to\nbetter inform end users such as teachers, thereby fostering greater trust and\nfacilitating wider adoption in education. This study undertook a preliminary\nstep towards model transparency and explainability by using SHapley Additive\nexPlanations (SHAP) to examine how different tokenised words in transcription\ndata contributed to a BERT model's classification of CPS processes. The\nfindings suggested that well-performing classifications did not necessarily\nequate to a reasonable explanation for the classification decisions. Particular\ntokenised words were used frequently to affect classifications. The analysis\nalso identified a spurious word, which contributed positively to the\nclassification but was not semantically meaningful to the class. While such\nmodel transparency is unlikely to be useful to an end user to improve their\npractice, it can help them not to overrely on LLM diagnostics and ignore their\nhuman expertise. We conclude the workshop paper by noting that the extent to\nwhich the model appropriately uses the tokens for its classification is\nassociated with the number of classes involved. It calls for an investigation\ninto the exploration of ensemble model architectures and the involvement of\nhuman-AI complementarity for CPS diagnosis, since considerable human reasoning\nis still required for fine-grained discrimination of CPS subskills.", "comment": "Accepted to appear in the workshop proceedings for the HEXED'25\n  workshop in the 26th International Conference on Artificial Intelligence in\n  Education 2025 (AIED 2025), 22 July 2025, Palermo, Italy. 6 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.14584v1", "cate": "cs.CL", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15156", "title": "Constraint-aware Learning of Probabilistic Sequential Models for Multi-Label Classification", "authors": ["Mykhailo Buleshnyi", "Anna Polova", "Zsolt Zombori", "Michael Benedikt"], "categories": ["cs.LG", "cs.AI", "cs.LO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15156v1", "summary": "We investigate multi-label classification involving large sets of labels,\nwhere the output labels may be known to satisfy some logical constraints. We\nlook at an architecture in which classifiers for individual labels are fed into\nan expressive sequential model, which produces a joint distribution. One of the\npotential advantages for such an expressive model is its ability to modelling\ncorrelations, as can arise from constraints. We empirically demonstrate the\nability of the architecture both to exploit constraints in training and to\nenforce constraints at inference time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15156v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15008", "title": "FastSmoothSAM: A Fast Smooth Method For Segment Anything Model", "authors": ["Jiasheng Xu", "Yewang Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15008v1", "summary": "Accurately identifying and representing object edges is a challenging task in\ncomputer vision and image processing. The Segment Anything Model (SAM) has\nsignificantly influenced the field of image segmentation, but suffers from high\nmemory consumption and long inference times, limiting its efficiency in\nreal-time applications. To address these limitations, Fast Segment Anything\n(FastSAM) was proposed, achieving real-time segmentation. However, FastSAM\noften generates jagged edges that deviate from the true object shapes.\nTherefore, this paper introduces a novel refinement approach using B-Spline\ncurve fitting techniques to enhance the edge quality in FastSAM. Leveraging the\nrobust shape control and flexible geometric construction of B-Splines, a\nfour-stage refining process involving two rounds of curve fitting is employed\nto effectively smooth jagged edges. This approach significantly improves the\nvisual quality and analytical accuracy of object edges without compromising\ncritical geometric information. The proposed method improves the practical\nutility of FastSAM by improving segmentation accuracy while maintaining\nreal-time processing capabilities. This advancement unlocks greater potential\nfor FastSAM technology in various real-world scenarios, such as industrial\nautomation, medical imaging, and autonomous systems, where precise and\nefficient edge recognition is crucial.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15008v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14982", "title": "How Many Simultaneous Beamformers are Needed for Integrated Sensing and Communications?", "authors": ["Kareem M. Attiah", "Wei Yu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      26 pages, 7 figures, Submitted to T-IT for future publication", "url": "http://arxiv.org/abs/2507.14982v1", "summary": "Consider a downlink integrated sensing and communications (ISAC) system in\nwhich a base station employs linear beamforming to communicate to $K$ users,\nwhile simultaneously uses sensing beams to perform a sensing task of estimating\n$L$ real parameters. How many beamformers are needed to achieve the best\nperformance for both sensing and communications? This paper establishes bounds\non the minimum number of downlink beamformers, in which sensing performance is\nmeasured in terms of the Cram\\'{e}r-Rao bound for parameter estimation and\ncommunications performance is measured in terms of the\nsignal-to-interference-and-noise ratios. We show that an ISAC system requires\nat most $K + \\sqrt{\\frac{L(L+1)}{2}}$ beamformers if the remote users have the\nability to cancel the interference caused by the sensing beams. If cancelling\ninterference due to the sensing beams is not possible, the bound becomes\n$\\sqrt{K^2 + \\frac{L(L+1)}{2}}$. Interestingly, in the latter case, the bound\non the number of beamformers is less than the sum of the bounds for each task\nindividually. These results can be extended to sensing tasks for which the\nperformance is measured as a function of $d$ quadratic terms in the\nbeamformers. In this case, the bound becomes $K + \\sqrt{d}$ and $\\sqrt{K^2 +\nd}$, respectively. Specifically, for estimating complex path losses and\nangles-of-arrival of $N_\\text{tr}$ targets while communicating to $K$ users,\nthe bound on the minimum number of beamformers scales linearly in $K$ and in\n$N_\\text{tr}$, assuming interference from sensing can be cancelled. When\ninterference cancellation is not possible, the following exact characterization\nfor the case of $N_\\text{tr} = 1$ can be obtained: when $K=0$ or $1$, two\nbeamformers should be used; when $K \\ge 2$, exactly $K$ beamformers should be\nused, i.e., communication beamformers alone are already sufficient.", "comment": "26 pages, 7 figures, Submitted to T-IT for future publication", "pdf_url": "http://arxiv.org/pdf/2507.14982v1", "cate": "eess.SP", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.10125", "title": "Improved bicriteria approximation for $k$-edge-connectivity", "authors": ["Zeev Nutov"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      arXiv admin note: substantial text overlap with arXiv:2507.03786", "url": "http://arxiv.org/abs/2507.10125v2", "summary": "In the $k$-Edge Connected Spanning Subgraph ($k$-ECSS) problem we are given a\n(multi-)graph $G=(V,E)$ with edge costs and an integer $k$, and seek a min-cost\n$k$-edge-connected spanning subgraph of $G$. The problem admits a\n$2$-approximation algorithm and no better approximation ratio is known.\nHershkowitz, Klein, and Zenklusen [STOC 24] gave a bicriteria\n$(1,k-10)$-approximation algorithm that computes a $(k-10)$-edge-connected\nspanning subgraph of cost at most the optimal value of a standard Cut-LP for\n$k$-ECSS. This LP bicriteria approximation was recently improved by Cohen and\nNutov [ESA 25] to $(1,k-4)$, where also was given a bicriteria approximation\n$(3/2,k-2)$. In this paper we improve the bicriteria approximation to $(1,k-2)$\nfor $k$ even and to $\\left(1-\\frac{1}{k},k-3\\right)$ for $k$ is odd, and also\ngive another bicriteria approximation $(3/2,k-1)$. After this paper was\nwritten, we became aware that the same result was achieved earlier by Kumar and\nSwamy.\n  The $k$-Edge-Connected Spanning Multi-subgraph ($k$-ECSM) problem is almost\nthe same as $k$-ECSS, except that any edge can be selected multiple times at\nthe same cost. The previous best approximation ratio for $k$-ECSM was $1+4/k$.\nOur result improves this to $1+\\frac{2}{k}$ for $k$ even and to $1+\\frac{3}{k}$\nfor $k$ odd, where for $k$ odd the computed subgraph is in fact\n$(k+1)$-edge-connected.", "comment": "arXiv admin note: substantial text overlap with arXiv:2507.03786", "pdf_url": "http://arxiv.org/pdf/2507.10125v2", "cate": "cs.DS", "date": "2025-07-14", "updated": "2025-07-19"}
{"id": "2411.05375", "title": "Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking", "authors": ["Mubashara Akhtar", "Michael Schlichtkrull", "Andreas Vlachos"], "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at TACL", "url": "http://arxiv.org/abs/2411.05375v2", "summary": "Current automated fact-checking (AFC) approaches typically evaluate evidence\neither implicitly via the predicted verdicts or through exact matches with\npredefined closed knowledge sources, such as Wikipedia. However, these methods\nare limited due to their reliance on evaluation metrics originally designed for\nother purposes and constraints from closed knowledge sources. In this work, we\nintroduce\n\\textbf{\\textcolor{skyblue}{Ev\\textsuperscript{2}}\\textcolor{orangebrown}{R}}\nwhich combines the strengths of reference-based evaluation and verdict-level\nproxy scoring. Ev\\textsuperscript{2}R jointly assesses how well the evidence\naligns with the gold references and how reliably it supports the verdict,\naddressing the shortcomings of prior methods. We evaluate\nEv\\textsuperscript{2}R against three types of evidence evaluation approaches:\nreference-based, proxy-reference, and reference-less baselines. Assessments\nagainst human ratings and adversarial tests demonstrate that\nEv\\textsuperscript{2}R consistently outperforms existing scoring approaches in\naccuracy and robustness. It achieves stronger correlation with human judgments\nand greater robustness to adversarial perturbations, establishing it as a\nreliable metric for evidence evaluation in AFC.\\footnote{Code is available at\n\\href{https://github.com/mubasharaak/fc-evidence-evaluation}{https://github.com/mubasharaak/fc-evidence-evaluation}.}", "comment": "Accepted at TACL", "pdf_url": "http://arxiv.org/pdf/2411.05375v2", "cate": "cs.CL", "date": "2024-11-08", "updated": "2025-07-18"}
{"id": "2507.15016", "title": "$\\textit{A Priori}$ Error Analysis for the $p$-Stokes Equations with Slip Boundary Conditions: A Discrete Leray Projection Framework", "authors": ["Alex Kaltenbach", "Jörn Wichmann"], "categories": ["math.NA", "cs.NA", "65M60, 76A05, 35Q35, 76D07, 65M15, 35B45"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      25 pages, 1 figure, 2 tables", "url": "http://arxiv.org/abs/2507.15016v1", "summary": "We present an $\\textit{a priori}$ error analysis for the kinematic pressure\nin a fully-discrete finite-differences/-elements discretization of the unsteady\n$p$-Stokes equations, modelling non-Newtonian fluids. This system is subject to\nboth impermeability and perfect Navier slip boundary conditions, which are\nincorporated either weakly via Lagrange multipliers or strongly in the discrete\nvelocity space. A central aspect of the $\\textit{a priori}$ error analysis is\nthe discrete Leray projection, constructed to quantitatively approximate its\ncontinuous counterpart. The discrete Leray projection enables a Helmholtz-type\ndecomposition at the discrete level and plays a key role in deriving error\ndecay rates for the kinematic pressure. We derive (in some cases optimal) error\ndecay rates for both the velocity vector field and kinematic pressure, with the\nerror for the kinematic pressure measured in an $\\textit{ad hoc}$ norm informed\nby the projection framework. The $\\textit{a priori}$ error analysis remains\nrobust even under reduced regularity of the velocity vector field and the\nkinematic pressure, and illustrates how the interplay of boundary conditions\nand projection stability governs the accuracy of pressure approximations.", "comment": "25 pages, 1 figure, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.15016v1", "cate": "math.NA", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15121", "title": "AMPED: Accelerating MTTKRP for Billion-Scale Sparse Tensor Decomposition on Multiple GPUs", "authors": ["Sasindu Wijeratne", "Rajgopal Kannan", "Viktor Prasanna"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15121v1", "summary": "Matricized Tensor Times Khatri-Rao Product (MTTKRP) is the computational\nbottleneck in sparse tensor decomposition. As real-world sparse tensors grow to\nbillions of nonzeros, they increasingly demand higher memory capacity and\ncompute throughput from hardware accelerators. In this work, we present AMPED,\na multi-GPU parallel algorithm designed to accelerate MTTKRP on billion-scale\nsparse tensors. AMPED scales beyond the limits of a single GPU, meeting both\nthe memory and performance requirements of large-scale workloads. We introduce\na partitioning strategy combined with a dynamic load balancing scheme to\ndistribute computation and minimize GPU idle time. On real-world billion-scale\ntensors, AMPED achieves a 5.1x geometric mean speedup in total execution time\nover state-of-the-art GPU baselines using 4 GPUs on a single CPU node.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15121v1", "cate": "cs.DC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14226", "title": "Mapping the Parasocial AI Market: User Trends, Engagement and Risks", "authors": ["Zilan Qian", "Mari Izumikawa", "Fiona Lodge", "Angelo Leone"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      17 pages, 17 figures", "url": "http://arxiv.org/abs/2507.14226v1", "summary": "A scan of 110 AI companion platforms reveals a rapidly growing global market\nfor emotionally engaging, personalized AI interactions. While parasocial use of\ngeneral-purpose AI (GPAI) tools currently dominates, a growing number of\nplatforms are designed specifically for care, transactional, or romantic\ncompanionship. In the UK alone, these platforms receive between 46 million and\n91 million monthly visits (1.1--2.2 billion globally), with users spending an\naverage of 3.5 minutes per session. For context, Instagram averaged 67.3\nmillion UK visits per month between January and March 2025. Notably, romantic\nand sexual AI companions make up 44\\% of UK visits--higher than the global\naverage of 30\\%--but see lower session time and return rates than mixed-use\nplatforms, suggesting unmet demand or quality gaps. As romantic AI offerings\nimprove, increased engagement may follow, raising urgent concerns about online\nsafety, particularly for children, given weak age safeguards. Meanwhile, GPAI\ntools are moving toward more emotionally intelligent, personalized\ninteractions, making parasocial AI use increasingly mainstream. These trends\nhighlight the need for the UK AI Safety Institute (AISI) to monitor this sector\nand assess whether existing regulation sufficiently addresses emerging societal\nrisks.", "comment": "17 pages, 17 figures", "pdf_url": "http://arxiv.org/pdf/2507.14226v1", "cate": "cs.CY", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.14542", "title": "Self-Supervised Distillation of Legacy Rule-Based Methods for Enhanced EEG-Based Decision-Making", "authors": ["Yipeng Zhang", "Yuanyi Ding", "Chenda Duan", "Atsuro Daida", "Hiroki Nariai", "Vwani Roychowdhury"], "categories": ["cs.CE", "cs.CV"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14542v1", "summary": "High-frequency oscillations (HFOs) in intracranial Electroencephalography\n(iEEG) are critical biomarkers for localizing the epileptogenic zone in\nepilepsy treatment. However, traditional rule-based detectors for HFOs suffer\nfrom unsatisfactory precision, producing false positives that require\ntime-consuming manual review. Supervised machine learning approaches have been\nused to classify the detection results, yet they typically depend on labeled\ndatasets, which are difficult to acquire due to the need for specialized\nexpertise. Moreover, accurate labeling of HFOs is challenging due to low\ninter-rater reliability and inconsistent annotation practices across\ninstitutions. The lack of a clear consensus on what constitutes a pathological\nHFO further challenges supervised refinement approaches. To address this, we\nleverage the insight that legacy detectors reliably capture clinically relevant\nsignals despite their relatively high false positive rates. We thus propose the\nSelf-Supervised to Label Discovery (SS2LD) framework to refine the large set of\ncandidate events generated by legacy detectors into a precise set of\npathological HFOs. SS2LD employs a variational autoencoder (VAE) for\nmorphological pre-training to learn meaningful latent representation of the\ndetected events. These representations are clustered to derive weak supervision\nfor pathological events. A classifier then uses this supervision to refine\ndetection boundaries, trained on real and VAE-augmented data. Evaluated on\nlarge multi-institutional interictal iEEG datasets, SS2LD outperforms\nstate-of-the-art methods. SS2LD offers a scalable, label-efficient, and\nclinically effective strategy to identify pathological HFOs using legacy\ndetectors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14542v1", "cate": "cs.CE", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.09822", "title": "Active Probing with Multimodal Predictions for Motion Planning", "authors": ["Darshan Gadginmath", "Farhad Nawaz", "Minjun Sung", "Faizan M Tariq", "Sangjae Bae", "David Isele", "Fabio Pasqualetti", "Jovin D'sa"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      To appear at IROS '25. 8 pages. 3 tables. 6 figures. Project page: this https URL", "url": "http://arxiv.org/abs/2507.09822v3", "summary": "Navigation in dynamic environments requires autonomous systems to reason\nabout uncertainties in the behavior of other agents. In this paper, we\nintroduce a unified framework that combines trajectory planning with multimodal\npredictions and active probing to enhance decision-making under uncertainty. We\ndevelop a novel risk metric that seamlessly integrates multimodal prediction\nuncertainties through mixture models. When these uncertainties follow a\nGaussian mixture distribution, we prove that our risk metric admits a\nclosed-form solution, and is always finite, thus ensuring analytical\ntractability. To reduce prediction ambiguity, we incorporate an active probing\nmechanism that strategically selects actions to improve its estimates of\nbehavioral parameters of other agents, while simultaneously handling multimodal\nuncertainties. We extensively evaluate our framework in autonomous navigation\nscenarios using the MetaDrive simulation environment. Results demonstrate that\nour active probing approach successfully navigates complex traffic scenarios\nwith uncertain predictions. Additionally, our framework shows robust\nperformance across diverse traffic agent behavior models, indicating its broad\napplicability to real-world autonomous navigation challenges. Code and videos\nare available at\nhttps://darshangm.github.io/papers/active-probing-multimodal-predictions/.", "comment": "To appear at IROS '25. 8 pages. 3 tables. 6 figures. Project page:\n  https://darshangm.github.io/papers/active-probing-multimodal-predictions/", "pdf_url": "http://arxiv.org/pdf/2507.09822v3", "cate": "cs.RO", "date": "2025-07-13", "updated": "2025-07-20"}
{"id": "2507.14590", "title": "Backtranslation and paraphrasing in the LLM era? Comparing data augmentation methods for emotion classification", "authors": ["Łukasz Radliński", "Mateusz Guściora", "Jan Kocoń"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      International Conference on Computational Science 2025", "url": "http://arxiv.org/abs/2507.14590v1", "summary": "Numerous domain-specific machine learning tasks struggle with data scarcity\nand class imbalance. This paper systematically explores data augmentation\nmethods for NLP, particularly through large language models like GPT. The\npurpose of this paper is to examine and evaluate whether traditional methods\nsuch as paraphrasing and backtranslation can leverage a new generation of\nmodels to achieve comparable performance to purely generative methods. Methods\naimed at solving the problem of data scarcity and utilizing ChatGPT were\nchosen, as well as an exemplary dataset. We conducted a series of experiments\ncomparing four different approaches to data augmentation in multiple\nexperimental setups. We then evaluated the results both in terms of the quality\nof generated data and its impact on classification performance. The key\nfindings indicate that backtranslation and paraphrasing can yield comparable or\neven better results than zero and a few-shot generation of examples.", "comment": "International Conference on Computational Science 2025", "pdf_url": "http://arxiv.org/pdf/2507.14590v1", "cate": "cs.CL", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15158", "title": "Resonant-Tunnelling Diode Reservoir Computing System for Image Recognition", "authors": ["A. H. Abbas", "Hend Abdel-Ghani", "Ivan S. Maksymov"], "categories": ["cs.LG", "physics.app-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15158v1", "summary": "As artificial intelligence continues to push into real-time, edge-based and\nresource-constrained environments, there is an urgent need for novel,\nhardware-efficient computational models. In this study, we present and validate\na neuromorphic computing architecture based on resonant-tunnelling diodes\n(RTDs), which exhibit the nonlinear characteristics ideal for physical\nreservoir computing (RC). We theoretically formulate and numerically implement\nan RTD-based RC system and demonstrate its effectiveness on two image\nrecognition benchmarks: handwritten digit classification and object recognition\nusing the Fruit~360 dataset. Our results show that this circuit-level\narchitecture delivers promising performance while adhering to the principles of\nnext-generation RC -- eliminating random connectivity in favour of a\ndeterministic nonlinear transformation of input signals.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15158v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15028", "title": "Towards Video Thinking Test: A Holistic Benchmark for Advanced Video Reasoning and Understanding", "authors": ["Yuanhan Zhang", "Yunice Chew", "Yuhao Dong", "Aria Leo", "Bo Hu", "Ziwei Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025; Project page: this https URL", "url": "http://arxiv.org/abs/2507.15028v1", "summary": "Human intelligence requires correctness and robustness, with the former being\nfoundational for the latter. In video understanding, correctness ensures the\naccurate interpretation of visual content, and robustness maintains consistent\nperformance in challenging conditions. Despite advances in video large language\nmodels (video LLMs), existing benchmarks inadequately reflect the gap between\nthese models and human intelligence in maintaining correctness and robustness\nin video interpretation. We introduce the Video Thinking Test (Video-TT), to\nassess if video LLMs can interpret real-world videos as effectively as humans.\nVideo-TT reflects genuine gaps in understanding complex visual narratives, and\nevaluates robustness against natural adversarial questions. Video-TT comprises\n1,000 YouTube Shorts videos, each with one open-ended question and four\nadversarial questions that probe visual and narrative complexity. Our\nevaluation shows a significant gap between video LLMs and human performance.", "comment": "ICCV 2025; Project page: https://zhangyuanhan-ai.github.io/video-tt/", "pdf_url": "http://arxiv.org/pdf/2507.15028v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15255", "title": "MEETI: A Multimodal ECG Dataset from MIMIC-IV-ECG with Signals, Images, Features and Interpretations", "authors": ["Deyun Zhang", "Xiang Lan", "Shijia Geng", "Qinghao Zhao", "Sumei Fan", "Mengling Feng", "Shenda Hong"], "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15255v1", "summary": "Electrocardiogram (ECG) plays a foundational role in modern cardiovascular\ncare, enabling non-invasive diagnosis of arrhythmias, myocardial ischemia, and\nconduction disorders. While machine learning has achieved expert-level\nperformance in ECG interpretation, the development of clinically deployable\nmultimodal AI systems remains constrained, primarily due to the lack of\npublicly available datasets that simultaneously incorporate raw signals,\ndiagnostic images, and interpretation text. Most existing ECG datasets provide\nonly single-modality data or, at most, dual modalities, making it difficult to\nbuild models that can understand and integrate diverse ECG information in\nreal-world settings. To address this gap, we introduce MEETI (MIMIC-IV-Ext\nECG-Text-Image), the first large-scale ECG dataset that synchronizes raw\nwaveform data, high-resolution plotted images, and detailed textual\ninterpretations generated by large language models. In addition, MEETI includes\nbeat-level quantitative ECG parameters extracted from each lead, offering\nstructured parameters that support fine-grained analysis and model\ninterpretability. Each MEETI record is aligned across four components: (1) the\nraw ECG waveform, (2) the corresponding plotted image, (3) extracted feature\nparameters, and (4) detailed interpretation text. This alignment is achieved\nusing consistent, unique identifiers. This unified structure supports\ntransformer-based multimodal learning and supports fine-grained, interpretable\nreasoning about cardiac health. By bridging the gap between traditional signal\nanalysis, image-based interpretation, and language-driven understanding, MEETI\nestablished a robust foundation for the next generation of explainable,\nmultimodal cardiovascular AI. It offers the research community a comprehensive\nbenchmark for developing and evaluating ECG-based AI systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15255v1", "cate": "eess.SP", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2410.11136", "title": "Comparison Theorems for the Mixing Times of Systematic and Random Scan Dynamics", "authors": ["Jason Gaitonde", "Elchanan Mossel"], "categories": ["math.PR", "cs.DS", "stat.CO"], "primary_category": "Subjects:       Probability (math.PR)", "pdf_link": null, "comments": "Comments:      31 pages", "url": "http://arxiv.org/abs/2410.11136v2", "summary": "A popular method for sampling from high-dimensional distributions is the\n\\emph{Gibbs sampler}, which iteratively resamples sites from the conditional\ndistribution of the desired measure given the values of the other coordinates.\nIt is natural to ask to what extent does the order of site updates matter in\nthe mixing time? Two natural choices are (i) standard, or \\emph{random scan},\nGlauber dynamics where the updated variable is chosen uniformly at random, and\n(ii) the \\emph{systematic scan} dynamics where variables are updated in a\nfixed, cyclic order. We first show that for systems of dimension $n$, one round\nof the systematic scan dynamics has spectral gap at most a factor of order $n$\nworse than the corresponding spectral gap of a single step of Glauber dynamics,\ntightening existing bounds in the literature by He, et al. [NeurIPS '16] and\nChlebicka, {\\L}atuszy\\'nski, and Miasodejow [Ann. Appl. Probab. '25]. The\ncorresponding bound on mixing times is sharp even for simple spin systems by an\nexplicit example of Roberts and Rosenthal [Int. J. Statist. Prob. '15]. We\ncomplement this with a converse statement: if all, or even just one scan order\nrapidly mixes, the Glauber dynamics has a polynomially related mixing time,\nresolving a question of Chlebicka, {\\L}atuszy\\'nski, and Miasodejow.", "comment": "31 pages", "pdf_url": "http://arxiv.org/pdf/2410.11136v2", "cate": "math.PR", "date": "2024-10-14", "updated": "2025-07-21"}
{"id": "2503.09516", "title": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning", "authors": ["Bowen Jin", "Hansi Zeng", "Zhenrui Yue", "Jinsung Yoon", "Sercan Arik", "Dong Wang", "Hamed Zamani", "Jiawei Han"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      31 pages", "url": "http://arxiv.org/abs/2503.09516v4", "summary": "Efficiently acquiring external knowledge and up-to-date information is\nessential for effective reasoning and text generation in large language models\n(LLMs). Prompting advanced LLMs with reasoning capabilities to use search\nengines during inference is often suboptimal, as the LLM might not fully\npossess the capability on how to interact optimally with the search engine.\nThis paper introduces Search-R1, an extension of reinforcement learning (RL)\nfor reasoning frameworks where the LLM learns to autonomously generate\n(multiple) search queries during step-by-step reasoning with real-time\nretrieval. Search-R1 optimizes LLM reasoning trajectories with multi-turn\nsearch interactions, leveraging retrieved token masking for stable RL training\nand a simple outcome-based reward function. Experiments on seven\nquestion-answering datasets show that Search-R1 improves performance by 41%\n(Qwen2.5-7B) and 20% (Qwen2.5-3B) over various RAG baselines under the same\nsetting. This paper further provides empirical insights into RL optimization\nmethods, LLM choices, and response length dynamics in retrieval-augmented\nreasoning. The code and model checkpoints are available at\nhttps://github.com/PeterGriffinJin/Search-R1.", "comment": "31 pages", "pdf_url": "http://arxiv.org/pdf/2503.09516v4", "cate": "cs.CL", "date": "2025-03-12", "updated": "2025-07-21"}
{"id": "2507.15103", "title": "Analysis of fully discrete Crank-Nicolson finite element methods for a stochastic Keller-Segel chemotaxis system with gradient-type multiplicative noise", "authors": ["Liet Vo"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15103v1", "summary": "We develop and analyze numerical methods for a stochastic Keller-Segel system\nperturbed by Stratonovich noise, which models chemotactic behavior under\nrandomly fluctuating environmental conditions. The proposed fully discrete\nscheme couples a Crank-Nicolson time discretization with a splitting mixed\nfinite element method in space. We rigorously prove the stability of the\nnumerical scheme and establish strong convergence rates of order $O(k^{1/2} +\nk^{-1/2}h^2)$, where $k$ and $h$ denote the time and spatial step sizes,\nrespectively. Notably, the presence of stochastic forcing leads to an inverse\ndependence on $k$ in the error estimates, distinguishing the convergence\nbehavior from that of the deterministic case. Numerical experiments are\npresented to validate the theoretical results and demonstrate the effectiveness\nand accuracy of the proposed methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15103v1", "cate": "math.NA", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15154", "title": "Dynatune: Dynamic Tuning of Raft Election Parameters Using Network Measurement", "authors": ["Kohya Shiozaki", "Junya Nakamura"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      This paper was accepted at the 27th International Workshop on Advances in Parallel and Distributed Computational Models (APDCM 2025), held in conjunction with IPDPS 2025", "url": "http://arxiv.org/abs/2507.15154v1", "summary": "Raft is a leader-based consensus algorithm that implements State Machine\nReplication (SMR), which replicates the service state across multiple servers\nto enhance fault tolerance. In Raft, the servers play one of three roles:\nleader, follower, or candidate. The leader receives client requests, determines\nthe processing order, and replicates them to the followers. When the leader\nfails, the service must elect a new leader to continue processing requests,\nduring which the service experiences an out-of-service (OTS) time. The OTS time\nis directly influenced by election parameters, such as heartbeat interval and\nelection timeout. However, traditional approaches, such as Raft, often struggle\nto effectively tune these parameters, particularly under fluctuating network\nconditions, leading to increased OTS time and reduced service responsiveness.\nTo address this, we propose Dynatune, a mechanism that dynamically adjusts\nRaft's election parameters based on network metrics such as round-trip time and\npacket loss rates measured via heartbeats. By adapting to changing network\nenvironments, Dynatune significantly reduces the leader failure detection and\nOTS time without altering Raft's core mechanisms or introducing additional\ncommunication overheads. Experimental results demonstrate that Dynatune reduces\nthe leader failure detection and OTS times by 80% and 45%, respectively,\ncompared with Raft, while maintaining high availability even under dynamic\nnetwork conditions. These findings confirm that Dynatune effectively enhances\nthe performance and reliability of SMR services in various network scenarios.", "comment": "This paper was accepted at the 27th International Workshop on\n  Advances in Parallel and Distributed Computational Models (APDCM 2025), held\n  in conjunction with IPDPS 2025", "pdf_url": "http://arxiv.org/pdf/2507.15154v1", "cate": "cs.DC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14233", "title": "Towards an ABM on Proactive Community Adaptation for Climate Change", "authors": ["Önder Gürcan", "David Eric John Herbert", "F. LeRon Shults", "Christopher Frantz", "Ivan Puga-Gonzalez"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      5 pages, 2 figures, Social Simulation Conference 2025 (SSC'2025)", "url": "http://arxiv.org/abs/2507.14233v1", "summary": "We present an agent-based model (ABM) simulating proactive community\nadaptation to climate change in an urban context. The model is applied to\nBergen, Norway, represented as a complex socio-ecological system. It integrates\nmultiple agent types: municipal government (urban planners and political\nactors), civil society (individual citizens), environmental NGOs and activists,\nand media. Agents interact during urban planning processes - particularly the\nevaluation and approval of new development proposals. Urban planners provide\ntechnical assessments, while politicians (organized by party) make final\ndecisions to approve, modify, or reject projects. Environmental NGOs, activist\ngroups, and the media shape public perception and influence policymakers\nthrough campaigns, lobbying, protests, and news coverage. Individual citizens\ndecide whether to engage in collective action based on personal values and\nsocial influences. The model captures the resulting decision-making ecosystem\nand reveals feedback loops and leverage points that determine climate-adaptive\noutcomes. By analyzing these dynamics, we identify critical intervention points\nwhere targeted policy measures can facilitate systemic transformation toward\nmore climate-resilient urban development.", "comment": "5 pages, 2 figures, Social Simulation Conference 2025 (SSC'2025)", "pdf_url": "http://arxiv.org/pdf/2507.14233v1", "cate": "cs.CY", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.15026", "title": "Deep Generative Models in Condition and Structural Health Monitoring: Opportunities, Limitations and Future Outlook", "authors": ["Xin Yang", "Chen Fang", "Yunlai Liao", "Jian Yang", "Konstantinos Gryllias", "Dimitrios Chronopoulos"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      48 pages", "url": "http://arxiv.org/abs/2507.15026v1", "summary": "Condition and structural health monitoring (CM/SHM) is a pivotal component of\npredictive maintenance (PdM) strategies across diverse industrial sectors,\nincluding mechanical rotating machinery, airplane composite wings, offshore\nwind turbines, and civil engineering structures. Conventional deep learning\nmodels, while effective in fault diagnosis and anomaly detection through\nsupervised feature extraction and rule-based data augmentation, often struggle\nwith operational variability, imbalanced or scarce fault datasets, and\nmultimodal sensory data from complex systems. Deep generative models (DGMs) in\nthis regard, including autoregressive models, variational autoencoders,\ngenerative adversarial networks, diffusion-based models, and emerging large\nlanguage models, offer transformative capabilities by synthesizing\nhigh-fidelity data samples, reconstructing latent system states, and modeling\ncomplex multimodal data streams. This review systematically examines\nstate-of-the-art DGM applications in CM/SHM systems, emphasizing their role in\naddressing key challenges: data imbalance and imputation, domain adaptation and\ngeneralization, multimodal data fusion, and downstream fault diagnosis and\nanomaly detection tasks, with rigorous comparison among signal processing,\nconventional machine learning or deep learning models, and DGMs. We also\nanalyze current limitations of DGMs, including challenges of explainable and\ntrustworthy models, computational inefficiencies for edge deployment, and the\nneed for parameter-efficient fine-tuning strategies. Future research directions\ncan focus on zero-shot and few-shot learning, robust multimodal generalization,\nhybrid architectures integrating DGMs with physics knowledge, and reinforcement\nlearning with DGMs to enhance robustness and accuracy in industrial scenarios.", "comment": "48 pages", "pdf_url": "http://arxiv.org/pdf/2507.15026v1", "cate": "cs.CE", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.12911", "title": "LaViPlan : Language-Guided Visual Path Planning with RLVR", "authors": ["Hayeon Oh"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      11 pages, 6 figures", "url": "http://arxiv.org/abs/2507.12911v2", "summary": "Out-of-distribution (OOD) scenarios in autonomous driving refer to situations\nthat deviate from the training domain, often leading to unexpected and\npotentially hazardous behavior from planners that lack prior exposure to such\ncases. Recently, Vision-Language Models (VLMs) have been introduced into\nautonomous driving research for their promising generalization capabilities in\nOOD settings. Early studies demonstrated that VLMs could recognize OOD\nscenarios and generate user-level decisions such as \"go straight\" or \"turn\nright.\" However, a new challenge has emerged due to the misalignment between\nthe VLM's high-level decisions or visual reasoning expressed in language, and\nthe low-level predicted trajectories interpreted as actions. In this paper, we\npropose LaViPlan, a framework that leverages Reinforcement Learning with\nVerifiable Rewards (RLVR) to optimize VLMs using planning-oriented metrics.\nThis approach addresses the vision-language-action misalignment observed in\nexisting VLMs fine-tuned via supervised learning, which can recognize driving\nscenarios but often produce context-unaware decisions. Experimental results\ndemonstrate that our method improves situational awareness and decision-making\nunder OOD conditions, highlighting its potential to mitigate the misalignment\nissue. This work introduces a promising post-training paradigm for VLM agents\nin the context of autonomous driving.", "comment": "11 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.12911v2", "cate": "cs.RO", "date": "2025-07-17", "updated": "2025-07-21"}
{"id": "2507.14615", "title": "Retrieval-Augmented Clinical Benchmarking for Contextual Model Testing in Kenyan Primary Care: A Methodology Paper", "authors": ["Fred Mutisya", "Shikoh Gitau", "Christine Syovata", "Diana Oigara", "Ibrahim Matende", "Muna Aden", "Munira Ali", "Ryan Nyotu", "Diana Marion", "Job Nyangena", "Nasubo Ongoma", "Keith Mbae", "Elizabeth Wamicha", "Eric Mibuari", "Jean Philbert Nsengemana", "Talkmore Chidede"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      29 pages, 6 figs, 6 tables. Companion methods paper forthcoming", "url": "http://arxiv.org/abs/2507.14615v1", "summary": "Large Language Models(LLMs) hold promise for improving healthcare access in\nlow-resource settings, but their effectiveness in African primary care remains\nunderexplored. We present a methodology for creating a benchmark dataset and\nevaluation framework focused on Kenyan Level 2 and 3 clinical care. Our\napproach uses retrieval augmented generation (RAG) to ground clinical questions\nin Kenya's national guidelines, ensuring alignment with local standards. These\nguidelines were digitized, chunked, and indexed for semantic retrieval. Gemini\nFlash 2.0 Lite was then prompted with guideline excerpts to generate realistic\nclinical scenarios, multiple-choice questions, and rationale based answers in\nEnglish and Swahili. Kenyan physicians co-created and refined the dataset, and\na blinded expert review process ensured clinical accuracy, clarity, and\ncultural appropriateness. The resulting Alama Health QA dataset includes\nthousands of regulator-aligned question answer pairs across common outpatient\nconditions. Beyond accuracy, we introduce evaluation metrics that test clinical\nreasoning, safety, and adaptability such as rare case detection (Needle in the\nHaystack), stepwise logic (Decision Points), and contextual adaptability.\nInitial results reveal significant performance gaps when LLMs are applied to\nlocalized scenarios, consistent with findings that LLM accuracy is lower on\nAfrican medical content than on US-based benchmarks. This work offers a\nreplicable model for guideline-driven, dynamic benchmarking to support safe AI\ndeployment in African health systems.", "comment": "29 pages, 6 figs, 6 tables. Companion methods paper forthcoming", "pdf_url": "http://arxiv.org/pdf/2507.14615v1", "cate": "cs.CL", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15162", "title": "Designing User-Centric Metrics for Evaluation of Counterfactual Explanations", "authors": ["Firdaus Ahmed Choudhury", "Ethan Leicht", "Jude Ethan Bislig", "Hangzhi Guo", "Amulya Yadav"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15162v1", "summary": "Machine learning-based decision models are increasingly being used to make\ndecisions that significantly impact people's lives, but their opaque nature\nleaves end users without a clear understanding of why a decision was made.\nCounterfactual Explanations (CFEs) have grown in popularity as a means of\noffering actionable guidance by identifying the minimum changes in feature\nvalues required to flip a model's prediction to something more desirable.\nUnfortunately, most prior research in CFEs relies on artificial evaluation\nmetrics, such as proximity, which may overlook end-user preferences and\nconstraints, e.g., the user's perception of effort needed to make certain\nfeature changes may differ from that of the model designer. To address this\nresearch gap, this paper makes three novel contributions. First, we conduct a\npilot study with 20 crowd-workers on Amazon MTurk to experimentally validate\nthe alignment of existing CF evaluation metrics with real-world user\npreferences. Results show that user-preferred CFEs matched those based on\nproximity in only 63.81% of cases, highlighting the limited applicability of\nthese metrics in real-world settings. Second, inspired by the need to design a\nuser-informed evaluation metric for CFEs, we conduct a more detailed two-day\nuser study with 41 participants facing realistic credit application scenarios\nto find experimental support for or against three intuitive hypotheses that may\nexplain how end users evaluate CFEs. Third, based on the findings of this\nsecond study, we propose the AWP model, a novel user-centric, two-stage model\nthat describes one possible mechanism by which users evaluate and select CFEs.\nOur results show that AWP predicts user-preferred CFEs with 84.37% accuracy.\nOur study provides the first human-centered validation for personalized cost\nmodels in CFE generation and highlights the need for adaptive, user-centered\nevaluation metrics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15162v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15035", "title": "OpenBreastUS: Benchmarking Neural Operators for Wave Imaging Using Breast Ultrasound Computed Tomography", "authors": ["Zhijun Zeng", "Youjia Zheng", "Hao Hu", "Zeyuan Dong", "Yihang Zheng", "Xinliang Liu", "Jinzhuo Wang", "Zuoqiang Shi", "Linfeng Zhang", "Yubing Li", "He Sun"], "categories": ["cs.CV", "cs.LG", "35Q92, 68U10", "I.4.5; J.2; J.3"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15035v1", "summary": "Accurate and efficient simulation of wave equations is crucial in\ncomputational wave imaging applications, such as ultrasound computed tomography\n(USCT), which reconstructs tissue material properties from observed scattered\nwaves. Traditional numerical solvers for wave equations are computationally\nintensive and often unstable, limiting their practical applications for\nquasi-real-time image reconstruction. Neural operators offer an innovative\napproach by accelerating PDE solving using neural networks; however, their\neffectiveness in realistic imaging is limited because existing datasets\noversimplify real-world complexity. In this paper, we present OpenBreastUS, a\nlarge-scale wave equation dataset designed to bridge the gap between\ntheoretical equations and practical imaging applications. OpenBreastUS includes\n8,000 anatomically realistic human breast phantoms and over 16 million\nfrequency-domain wave simulations using real USCT configurations. It enables a\ncomprehensive benchmarking of popular neural operators for both forward\nsimulation and inverse imaging tasks, allowing analysis of their performance,\nscalability, and generalization capabilities. By offering a realistic and\nextensive dataset, OpenBreastUS not only serves as a platform for developing\ninnovative neural PDE solvers but also facilitates their deployment in\nreal-world medical imaging problems. For the first time, we demonstrate\nefficient in vivo imaging of the human breast using neural operator solvers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15035v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15256", "title": "Optimal Transceiver Design in Over-the-Air Federated Distillation", "authors": ["Zihao Hu", "Jia Yan", "Ying-Jun Angela Zhang", "Jun Zhang", "Khaled B. Letaief"], "categories": ["eess.SP", "cs.AI"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      13 pages, 7 figures, submitted to IEEE Transactions on Wireless Communications", "url": "http://arxiv.org/abs/2507.15256v1", "summary": "The rapid proliferation and growth of artificial intelligence (AI) has led to\nthe development of federated learning (FL). FL allows wireless devices (WDs) to\ncooperatively learn by sharing only local model parameters, without needing to\nshare the entire dataset. However, the emergence of large AI models has made\nexisting FL approaches inefficient, due to the significant communication\noverhead required. In this paper, we propose a novel over-the-air federated\ndistillation (FD) framework by synergizing the strength of FL and knowledge\ndistillation to avoid the heavy local model transmission. Instead of sharing\nthe model parameters, only the WDs' model outputs, referred to as knowledge,\nare shared and aggregated over-the-air by exploiting the superposition property\nof the multiple-access channel. We shall study the transceiver design in\nover-the-air FD, aiming to maximize the learning convergence rate while meeting\nthe power constraints of the transceivers. The main challenge lies in the\nintractability of the learning performance analysis, as well as the non-convex\nnature and the optimization spanning the whole FD training period. To tackle\nthis problem, we first derive an analytical expression of the convergence rate\nin over-the-air FD. Then, the closed-form optimal solutions of the WDs'\ntransmit power and the estimator for over-the-air aggregation are obtained\ngiven the receiver combining strategy. Accordingly, we put forth an efficient\napproach to find the optimal receiver beamforming vector via semidefinite\nrelaxation. We further prove that there is no optimality gap between the\noriginal and relaxed problem for the receiver beamforming design. Numerical\nresults will show that the proposed over-the-air FD approach achieves a\nsignificant reduction in communication overhead, with only a minor compromise\nin testing accuracy compared to conventional FL benchmarks.", "comment": "13 pages, 7 figures, submitted to IEEE Transactions on Wireless\n  Communications", "pdf_url": "http://arxiv.org/pdf/2507.15256v1", "cate": "eess.SP", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2410.23969", "title": "Interactive proofs for verifying (quantum) learning and testing", "authors": ["Matthias C. Caro", "Jens Eisert", "Marcel Hinsche", "Marios Ioannou", "Alexander Nietner", "Ryan Sweke"], "categories": ["quant-ph", "cs.CC", "cs.DS", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      13 + 33 + 13 pages; 1 table; 2 figures; some added clarifications in Sec 1", "url": "http://arxiv.org/abs/2410.23969v2", "summary": "We consider the problem of testing and learning from data in the presence of\nresource constraints, such as limited memory or weak data access, which place\nlimitations on the efficiency and feasibility of testing or learning. In\nparticular, we ask the following question: Could a resource-constrained\nlearner/tester use interaction with a resource-unconstrained but untrusted\nparty to solve a learning or testing problem more efficiently than they could\nwithout such an interaction? In this work, we answer this question both\nabstractly and for concrete problems, in two complementary ways: For a wide\nvariety of scenarios, we prove that a resource-constrained learner cannot gain\nany advantage through classical interaction with an untrusted prover. As a\nspecial case, we show that for the vast majority of testing and learning\nproblems in which quantum memory is a meaningful resource, a memory-constrained\nquantum algorithm cannot overcome its limitations via classical communication\nwith a memory-unconstrained quantum prover. In contrast, when quantum\ncommunication is allowed, we construct a variety of interactive proof\nprotocols, for specific learning and testing problems, which allow\nmemory-constrained quantum verifiers to gain significant advantages through\ndelegation to untrusted provers. These results highlight both the limitations\nand potential of delegating learning and testing problems to resource-rich but\nuntrusted third parties.", "comment": "13 + 33 + 13 pages; 1 table; 2 figures; some added clarifications in\n  Sec 1", "pdf_url": "http://arxiv.org/pdf/2410.23969v2", "cate": "quant-ph", "date": "2024-10-31", "updated": "2025-07-20"}
{"id": "2506.12689", "title": "SciSage: A Multi-Agent Framework for High-Quality Scientific Survey Generation", "authors": ["Xiaofeng Shi", "Qian Kou", "Yuduo Li", "Ning Tang", "Jinxin Xie", "Longbin Yu", "Songjing Wang", "Hua Zhou"], "categories": ["cs.AI", "cs.IR"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.12689v2", "summary": "The rapid growth of scientific literature demands robust tools for automated\nsurvey-generation. However, current large language model (LLM)-based methods\noften lack in-depth analysis, structural coherence, and reliable citations. To\naddress these limitations, we introduce SciSage, a multi-agent framework\nemploying a reflect-when-you-write paradigm. SciSage features a hierarchical\nReflector agent that critically evaluates drafts at outline, section, and\ndocument levels, collaborating with specialized agents for query\ninterpretation, content retrieval, and refinement. We also release SurveyScope,\na rigorously curated benchmark of 46 high-impact papers (2020-2025) across 11\ncomputer science domains, with strict recency and citation-based quality\ncontrols. Evaluations demonstrate that SciSage outperforms state-of-the-art\nbaselines (LLM x MapReduce-V2, AutoSurvey), achieving +1.73 points in document\ncoherence and +32% in citation F1 scores. Human evaluations reveal mixed\noutcomes (3 wins vs. 7 losses against human-written surveys), but highlight\nSciSage's strengths in topical breadth and retrieval efficiency. Overall,\nSciSage offers a promising foundation for research-assistive writing tools.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.12689v2", "cate": "cs.AI", "date": "2025-06-15", "updated": "2025-07-21"}
{"id": "2507.15137", "title": "Extending Data to Improve Stability and Error Estimates Using Asymmetric Kansa-like Methods to Solve PDEs", "authors": ["Thomas Hangelbroek", "Francis J. Narcowich", "Joseph D. Ward"], "categories": ["math.NA", "cs.NA", "65D12 (Primary) 65D15, 65N06, 65N12 (Secondary)"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      20 pages, math.NA", "url": "http://arxiv.org/abs/2507.15137v1", "summary": "In this paper, a theoretical framework is presented\n  for the use of a Kansa-like method to numerically solve elliptic\n  partial differential equations on spheres and other manifolds. The\n  theory addresses both the stability of the method and provides error\n  estimates for two different approximation methods. A Kansa-like\n  matrix is obtained by replacing the test point set $X$, used in the\n  traditional Kansa method, by a larger set $Y$, which is a norming\n  set for the underlying trial space. This gives rise to a rectangular\n  matrix. In addition, if a basis of Lagrange (or local Lagrange)\n  functions is used for the trial space, then it is shown\n  that the stability of the matrix is comparable to the stability of\n  the elliptic operator acting on the trial space. Finally, two\n  different types of error estimates are given. Discrete least squares\n  estimates of very high accuracy are obtained for solutions that are\n  sufficiently smooth. The second method, giving similar error\n  estimates, uses a rank revealing factorization to create a\n  ``thinning algorithm'' that reduces $\\#Y$ to $\\#X$. In practice,\n  this algorithm doesn't need $Y$ to be a norming set.", "comment": "20 pages, math.NA", "pdf_url": "http://arxiv.org/pdf/2507.15137v1", "cate": "math.NA", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15233", "title": "An ML-Driven Participant Selection Technique for Federated Recommendation System in Edge-Cloud Computing", "authors": ["Jintao Liu", "Mohammad Goudarzi", "Adel Nadjaran Toosi"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15233v1", "summary": "Recommendation systems (RS) personalize content by analyzing user\npreferences, but typically require centralized collection of user data, raising\nprivacy and scalability concerns. Federated Recommendation Systems (FRS)\naddress these issues by enabling distributed, privacy-preserving model training\nacross edge devices, keeping raw data on-device. Although existing FRS\nframeworks benefit from on-device feature extraction and privacy preservation,\nthey suffer from heterogeneous device capabilities, non-independent and\nidentically distributed (non-IID) data, and communication bottlenecks. To\novercome these limitations, we propose a multi-objective reinforcement learning\n(RL) participant selection that jointly optimizes historical client performance\nreputation (CPR), data utility, and system efficiency. First, we define a\ncomposite client-utility function combining CPR, system capability, and data\nquality. Next, we embed this utility into a multi-armed bandit (MAB) framework\nand dynamically balance exploration-exploitation to select participants.\nFinally, we practically implement our approach using the PySyft framework on an\nedge-cloud testbed, and evaluate it on a multimodal movie-recommendation task\nbuilt from the MovieLens-100K dataset. Across four different skewed\ndata-partition scenarios, our MAB-based selection accelerates convergence by\n32-50% in time-to-target AUC and reduces total wall-clock training time by up\nto 46%, while matching or slightly improving final AUC, NDCG@50, and Recall@50\ncompared to existing FRS baselines. Our results demonstrate that adaptive,\nreward-driven client sampling can substantially enhance both efficiency and\nfairness in real-world federated deployments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15233v1", "cate": "cs.DC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14235", "title": "Auto-grader Feedback Utilization and Its Impacts: An Observational Study Across Five Community Colleges", "authors": ["Adam Zhang", "Heather Burte", "Jaromir Savelka", "Christopher Bogart", "Majd Sakr"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14235v1", "summary": "Automated grading systems, or auto-graders, have become ubiquitous in\nprogramming education, and the way they generate feedback has become\nincreasingly automated as well. However, there is insufficient evidence\nregarding auto-grader feedback's effectiveness in improving student learning\noutcomes, in a way that differentiates students who utilized the feedback and\nstudents who did not. In this study, we fill this critical gap. Specifically,\nwe analyze students' interactions with auto-graders in an introductory Python\nprogramming course, offered at five community colleges in the United States.\nOur results show that students checking the feedback more frequently tend to\nget higher scores from their programming assignments overall. Our results also\nshow that a submission that follows a student checking the feedback tends to\nreceive a higher score than a submission that follows a student ignoring the\nfeedback. Our results provide evidence on auto-grader feedback's effectiveness,\nencourage their increased utilization, and call for future work to continue\ntheir evaluation in this age of automation", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14235v1", "cate": "cs.CY", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.15570", "title": "Configurational-force-driven adaptive refinement and coarsening in topology optimization", "authors": ["Gabriel Stankiewicz", "Chaitanya Dev", "Paul Steinmann"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15570v1", "summary": "The iterative nature of topology optimization, especially in combination with\nnonlinear state problems, often requires the solution of thousands of linear\nequation systems. Furthermore, due to the pixelated design representation, the\nuse of a fine mesh is essential to obtain geometrically well-defined structures\nand to accurately compute response quantities such as the von Mises stress.\nTherefore, the computational cost of solving a fine-mesh topology optimization\nproblem quickly adds up. To address this challenge, we consider a multi-level\nadaptive refinement and coarsening strategy based on configurational forces.\nConfigurational forces based on the Eshelby stress predict configurational\nchanges such as crack propagation or dislocation motion. Due to a relaxation in\nthe calculation of (Eshelby) stresses with respect to the design variables,\ndiscrete configurational forces increase not only in highly stressed regions,\nbut also in grey transition regions (design boundaries). For this reason they\nare an ideal criterion for mesh adaptivity in topology optimization, especially\nwhen avoiding stress failure is a priority. By using configurational forces for\nrefinement, we obtain a high-resolution structure where the refined mesh is\npresent along the design boundaries as well as in stress-critical regions. At\nthe same time, multilevel coarsening using the same criterion drastically\nminimizes the computational effort.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15570v1", "cate": "cs.CE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2403.10559", "title": "Generative Models and Connected and Automated Vehicles: A Survey in Exploring the Intersection of Transportation and AI", "authors": ["Bo Shu", "Yiting Zhang", "Dong Shu"], "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages, 2 figures", "url": "http://arxiv.org/abs/2403.10559v2", "summary": "This report investigates the history and impact of Generative Models and\nConnected and Automated Vehicles (CAVs), two groundbreaking forces pushing\nprogress in technology and transportation. By focusing on the application of\ngenerative models within the context of CAVs, the study aims to unravel how\nthis integration could enhance predictive modeling, simulation accuracy, and\ndecision-making processes in autonomous vehicles. This thesis discusses the\nbenefits and challenges of integrating generative models and CAV technology in\ntransportation. It aims to highlight the progress made, the remaining\nobstacles, and the potential for advancements in safety and innovation.", "comment": "9 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2403.10559v2", "cate": "cs.LG", "date": "2024-03-14", "updated": "2025-07-18"}
{"id": "2507.14649", "title": "Cleanse: Uncertainty Estimation Approach Using Clustering-based Semantic Consistency in LLMs", "authors": ["Minsuh Joo", "Hyunsoo Cho"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14649v1", "summary": "Despite the outstanding performance of large language models (LLMs) across\nvarious NLP tasks, hallucinations in LLMs--where LLMs generate inaccurate\nresponses--remains as a critical problem as it can be directly connected to a\ncrisis of building safe and reliable LLMs. Uncertainty estimation is primarily\nused to measure hallucination levels in LLM responses so that correct and\nincorrect answers can be distinguished clearly. This study proposes an\neffective uncertainty estimation approach, \\textbf{Cl}ust\\textbf{e}ring-based\nsem\\textbf{an}tic con\\textbf{s}ist\\textbf{e}ncy (\\textbf{Cleanse}). Cleanse\nquantifies the uncertainty with the proportion of the intra-cluster consistency\nin the total consistency between LLM hidden embeddings which contain adequate\nsemantic information of generations, by employing clustering. The effectiveness\nof Cleanse for detecting hallucination is validated using four off-the-shelf\nmodels, LLaMA-7B, LLaMA-13B, LLaMA2-7B and Mistral-7B and two\nquestion-answering benchmarks, SQuAD and CoQA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14649v1", "cate": "cs.CL", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15174", "title": "Joint-Local Grounded Action Transformation for Sim-to-Real Transfer in Multi-Agent Traffic Control", "authors": ["Justin Turnau", "Longchao Da", "Khoa Vo", "Ferdous Al Rafi", "Shreyas Bachiraju", "Tiejin Chen", "Hua Wei"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This paper was accepted to RLC/RLJ 2025", "url": "http://arxiv.org/abs/2507.15174v1", "summary": "Traffic Signal Control (TSC) is essential for managing urban traffic flow and\nreducing congestion. Reinforcement Learning (RL) offers an adaptive method for\nTSC by responding to dynamic traffic patterns, with multi-agent RL (MARL)\ngaining traction as intersections naturally function as coordinated agents.\nHowever, due to shifts in environmental dynamics, implementing MARL-based TSC\npolicies in the real world often leads to a significant performance drop, known\nas the sim-to-real gap. Grounded Action Transformation (GAT) has successfully\nmitigated this gap in single-agent RL for TSC, but real-world traffic networks,\nwhich involve numerous interacting intersections, are better suited to a MARL\nframework. In this work, we introduce JL-GAT, an application of GAT to\nMARL-based TSC that balances scalability with enhanced grounding capability by\nincorporating information from neighboring agents. JL-GAT adopts a\ndecentralized approach to GAT, allowing for the scalability often required in\nreal-world traffic networks while still capturing key interactions between\nagents. Comprehensive experiments on various road networks under simulated\nadverse weather conditions, along with ablation studies, demonstrate the\neffectiveness of JL-GAT. The code is publicly available at\nhttps://github.com/DaRL-LibSignal/JL-GAT/.", "comment": "This paper was accepted to RLC/RLJ 2025", "pdf_url": "http://arxiv.org/pdf/2507.15174v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15037", "title": "OmniVTON: Training-Free Universal Virtual Try-On", "authors": ["Zhaotong Yang", "Yuhui Li", "Shengfeng He", "Xinzhe Li", "Yangyang Xu", "Junyu Dong", "Yong Du"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV2025", "url": "http://arxiv.org/abs/2507.15037v1", "summary": "Image-based Virtual Try-On (VTON) techniques rely on either supervised\nin-shop approaches, which ensure high fidelity but struggle with cross-domain\ngeneralization, or unsupervised in-the-wild methods, which improve adaptability\nbut remain constrained by data biases and limited universality. A unified,\ntraining-free solution that works across both scenarios remains an open\nchallenge. We propose OmniVTON, the first training-free universal VTON\nframework that decouples garment and pose conditioning to achieve both texture\nfidelity and pose consistency across diverse settings. To preserve garment\ndetails, we introduce a garment prior generation mechanism that aligns clothing\nwith the body, followed by continuous boundary stitching technique to achieve\nfine-grained texture retention. For precise pose alignment, we utilize DDIM\ninversion to capture structural cues while suppressing texture interference,\nensuring accurate body alignment independent of the original image textures. By\ndisentangling garment and pose constraints, OmniVTON eliminates the bias\ninherent in diffusion models when handling multiple conditions simultaneously.\nExperimental results demonstrate that OmniVTON achieves superior performance\nacross diverse datasets, garment types, and application scenarios. Notably, it\nis the first framework capable of multi-human VTON, enabling realistic garment\ntransfer across multiple individuals in a single scene. Code is available at\nhttps://github.com/Jerome-Young/OmniVTON", "comment": "Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.15037v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15291", "title": "A Novel Domain-Aware CNN Architecture for Faster-than-Nyquist Signaling Detection", "authors": ["Osman Tokluoglu", "Enver Cavus", "Ebrahim Bedeer", "Halim Yanikomeroglu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      6 pages, 8 figures", "url": "http://arxiv.org/abs/2507.15291v1", "summary": "This paper proposes a convolutional neural network (CNN)-based detector for\nfaster-than-Nyquist (FTN) signaling that employs structured fixed kernel layers\nwith domain-informed masking to mitigate intersymbol interference (ISI). Unlike\nstandard CNNs with sliding kernels, the proposed method utilizes fixed-position\nkernels to directly capture ISI effects at varying distances from the central\nsymbol. A hierarchical filter allocation strategy is also introduced, assigning\nmore filters to earlier layers for strong ISI patterns and fewer to later\nlayers for weaker ones. This design improves detection accuracy while reducing\nredundant operations. Simulation results show that the detector achieves\nnear-optimal bit error rate (BER) performance for $\\tau \\geq 0.7$, closely\nmatching the BCJR algorithm, and offers computational gains of up to $46\\%$ and\n$84\\%$ over M-BCJR for BPSK and QPSK, respectively. Comparative analysis with\nother methods further highlights the efficiency and effectiveness of the\nproposed approach. To the best of our knowledge, this is the first application\nof a fixed-kernel CNN architecture tailored for FTN detection in the\nliterature.", "comment": "6 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.15291v1", "cate": "eess.SP", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2412.05182", "title": "Integer and Unsplittable Multiflows in Series-Parallel Digraphs", "authors": ["Mohammed Majthoub Almoghrabi", "Martin Skutella", "Philipp Warode"], "categories": ["math.CO", "cs.DS"], "primary_category": "Subjects:       Combinatorics (math.CO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.05182v2", "summary": "An unsplittable multiflow routes the demand of each commodity along a single\npath from its source to its sink node. As our main result, we prove that in\nseries-parallel digraphs, any given multiflow can be expressed as a convex\ncombination of unsplittable multiflows, where the total flow on any arc\ndeviates from the given flow by less than the maximum demand of any commodity.\nThis result confirms a 25-year-old conjecture by Goemans for single-source\nunsplittable flows, as well as a stronger recent conjecture by Morell and\nSkutella, for series-parallel digraphs - even for general multiflow instances\nwhere commodities have distinct source and sink nodes. Previously, no\nnon-trivial class of digraphs was known for which either conjecture holds. En\nroute to proving this result, we also establish strong integrality results for\nmultiflows on series-parallel digraphs, showing that their computation can be\nreduced to a simple single-commodity network flow problem.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.05182v2", "cate": "math.CO", "date": "2024-12-06", "updated": "2025-07-21"}
{"id": "2507.11907", "title": "SIEVE: Effective Filtered Vector Search with Collection of Indexes", "authors": ["Zhaoheng Li", "Silu Huang", "Wei Ding", "Yongjoo Park", "Jianjun Chen"], "categories": ["cs.DB", "cs.IR"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11907v2", "summary": "Many real-world tasks such as recommending videos with the kids tag can be\nreduced to finding most similar vectors associated with hard predicates. This\ntask, filtered vector search, is challenging as prior state-of-the-art\ngraph-based (unfiltered) similarity search techniques quickly degenerate when\nhard constraints are considered. That is, effective graph-based filtered\nsimilarity search relies on sufficient connectivity for reaching the most\nsimilar items within just a few hops. To consider predicates, recent works\npropose modifying graph traversal to visit only the items that may satisfy\npredicates. However, they fail to offer the just-a-few-hops property for a wide\nrange of predicates: they must restrict predicates significantly or lose\nefficiency if only a small fraction of items satisfy predicates.\n  We propose an opposite approach: instead of constraining traversal, we build\nmany indexes each serving different predicate forms. For effective\nconstruction, we devise a three-dimensional analytical model capturing\nrelationships among index size, search time, and recall, with which we follow a\nworkload-aware approach to pack as many useful indexes as possible into a\ncollection. At query time, the analytical model is employed yet again to\ndiscern the one that offers the fastest search at a given recall. We show\nsuperior performance and support on datasets with varying selectivities and\nforms: our approach achieves up to 8.06x speedup while having as low as 1%\nbuild time versus other indexes, with less than 2.15x memory of a standard HNSW\ngraph and modest knowledge of past workloads.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11907v2", "cate": "cs.DB", "date": "2025-07-16", "updated": "2025-07-20"}
{"id": "2507.15185", "title": "On Subsample Size of Quantile-Based Randomized Kaczmarz", "authors": ["Jian-Feng Cai", "Junren Chen", "Anna Ma", "Tong Wu"], "categories": ["math.NA", "cs.NA", "65F10, 68W20, 60B20"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      main tex: 21 pages", "url": "http://arxiv.org/abs/2507.15185v1", "summary": "Quantile-based randomized Kaczmarz (QRK) was recently introduced to\nefficiently solve sparsely corrupted linear systems $\\mathbf{A}\n\\mathbf{x}^*+\\mathbf{\\epsilon} = \\mathbf{b}$ [SIAM J. Matrix Anal. Appl.,\n43(2), 605-637], where $\\mathbf{A}\\in \\mathbb{R}^{m\\times n}$ and\n$\\mathbf{\\epsilon}$ is an arbitrary $(\\beta m)$-sparse corruption. However, all\nexisting theoretical guarantees for QRK require quantiles to be computed using\nall $m$ samples (or a subsample of the same order), thus negating the\ncomputational advantage of Kaczmarz-type methods. This paper overcomes the\nbottleneck. We analyze a subsampling QRK, which computes quantiles from $D$\nuniformly chosen samples at each iteration. Under some standard scaling\nassumptions on the coefficient matrix, we show that QRK with subsample size\n$D\\ge\\frac{C\\log (T)}{\\log(1/\\beta)}$ linearly converges over the first $T$\niterations with high probability, where $C$ is some absolute constant. This\nsubsample size is a substantial reduction from $O(m)$ in prior results. For\ninstance, it translates into $O(\\log(n))$ even if an approximation error of\n$\\exp(-n^2)$ is desired. Intriguingly, our subsample size is also tight up to a\nmultiplicative constant: if $D\\le \\frac{c\\log(T)}{\\log(1/\\beta)}$ for some\nconstant $c$, the error of the $T$-th iterate could be arbitrarily large with\nhigh probability. Numerical results are provided to corroborate our theory.", "comment": "main tex: 21 pages", "pdf_url": "http://arxiv.org/pdf/2507.15185v1", "cate": "math.NA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15553", "title": "Efficient Routing of Inference Requests across LLM Instances in Cloud-Edge Computing", "authors": ["Shibo Yu", "Mohammad Goudarzi", "Adel Nadjaran Toosi"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15553v1", "summary": "The rising demand for Large Language Model (LLM) inference services has\nintensified pressure on computational resources, resulting in latency and cost\nchallenges. This paper introduces a novel routing algorithm based on the\nNon-dominated Sorting Genetic Algorithm II (NSGA-II) to distribute inference\nrequests across heterogeneous LLM instances in a cloud-edge computing\nenvironment. Formulated as a multi-objective optimization problem, the\nalgorithm balances response quality, response time, and inference cost,\nadapting to request heterogeneity (e.g., varying complexity and prompt lengths)\nand node diversity (e.g., edge vs. cloud resources). This adaptive routing\nalgorithm optimizes performance under dynamic workloads. We benchmark the\napproach using a testbed with datasets including Stanford Question Answering\nDataset (SQuAD), Mostly Basic Python Problems (MBPP), Hella Situations With\nAdversarial Generations (HellaSwag), and Grade School Math 8K (GSM8K).\nExperimental results show our solution, compared to the baselines, achieves up\nto 95.2% and 34.9% improvements in terms of response time and cost,\nrespectively. These findings validate the algorithm's effectiveness for\nscalable LLM deployments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15553v1", "cate": "cs.DC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14236", "title": "Mining Voter Behaviour and Confidence: A Rule-Based Analysis of the 2022 U.S. Elections", "authors": ["Md Al Jubair", "Mohammad Shamsul Arefin", "Ahmed Wasif Reza"], "categories": ["cs.CY", "cs.LG"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14236v1", "summary": "This study explores the relationship between voter trust and their\nexperiences during elections by applying a rule-based data mining technique to\nthe 2022 Survey of the Performance of American Elections (SPAE). Using the\nApriori algorithm and setting parameters to capture meaningful associations\n(support >= 3%, confidence >= 60%, and lift > 1.5), the analysis revealed a\nstrong connection between demographic attributes and voting-related challenges,\nsuch as registration hurdles, accessibility issues, and queue times. For\ninstance, respondents who indicated that accessing polling stations was \"very\neasy\" and who reported moderate confidence were found to be over six times more\nlikely (lift = 6.12) to trust their county's election outcome and experience no\nregistration issues. A further analysis, which adjusted the support threshold\nto 2%, specifically examined patterns among minority voters. It revealed that\n98.16 percent of Black voters who reported easy access to polling locations\nalso had smooth registration experiences. Additionally, those who had high\nconfidence in the vote-counting process were almost two times as likely to\nidentify as Democratic Party supporters. These findings point to the important\nrole that enhancing voting access and offering targeted support can play in\nbuilding trust in the electoral system, particularly among marginalized\ncommunities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14236v1", "cate": "cs.CY", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.15753", "title": "DiffuMeta: Algebraic Language Models for Inverse Design of Metamaterials via Diffusion Transformers", "authors": ["Li Zheng", "Siddhant Kumar", "Dennis M. Kochmann"], "categories": ["cs.CE", "cs.AI"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15753v1", "summary": "Generative machine learning models have revolutionized material discovery by\ncapturing complex structure-property relationships, yet extending these\napproaches to the inverse design of three-dimensional metamaterials remains\nlimited by computational complexity and underexplored design spaces due to the\nlack of expressive representations. Here, we present DiffuMeta, a generative\nframework integrating diffusion transformers with a novel algebraic language\nrepresentation, encoding 3D geometries as mathematical sentences. This compact,\nunified parameterization spans diverse topologies while enabling direct\napplication of transformers to structural design. DiffuMeta leverages diffusion\nmodels to generate novel shell structures with precisely targeted stress-strain\nresponses under large deformations, accounting for buckling and contact while\naddressing the inherent one-to-many mapping by producing diverse solutions.\nUniquely, our approach enables simultaneous control over multiple mechanical\nobjectives, including linear and nonlinear responses beyond training domains.\nExperimental validation of fabricated structures further confirms the efficacy\nof our approach for accelerated design of metamaterials and structures with\ntailored properties.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15753v1", "cate": "cs.CE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2412.04020", "title": "How Cars Move: Analyzing Driving Dynamics for Safer Urban Traffic", "authors": ["Kangan Qian", "Jinyu Miao", "Xinyu Jiao", "Ziang Luo", "Zheng Fu", "Yining Shi", "Yunlong Wang", "Kun Jiang", "Diange Yang"], "categories": ["cs.CV", "cs.PF", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 pages, 5 figures", "url": "http://arxiv.org/abs/2412.04020v3", "summary": "Understanding the spatial dynamics of cars within urban systems is essential\nfor optimizing infrastructure management and resource allocation. Recent\nempirical approaches for analyzing traffic patterns have gained traction due to\ntheir applicability to city-scale policy development. However, conventional\nmethodologies often rely on fragmented grid-based techniques, which may\noverlook critical interdependencies among spatial elements and temporal\ncontinuity. These limitations can compromise analytical effectiveness in\ncomplex urban environments. To address these challenges, we propose\nPriorMotion, a data integration framework designed to systematically uncover\nmovement patterns through driving dynamics analysis. Our approach combines\nmulti-scale empirical observations with customized analytical tools to capture\nevolving spatial-temporal trends in urban traffic. Comprehensive evaluations\ndemonstrate that PriorMotion significantly enhances analytical outcomes,\nincluding increased accuracy in traffic pattern analysis, improved adaptability\nto heterogeneous data environments, and reduced long-term projection errors.\nValidation confirms its effectiveness for urban infrastructure management\napplications requiring precise characterization of complex spatial-temporal\ninteractions.", "comment": "8 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2412.04020v3", "cate": "cs.CV", "date": "2024-12-05", "updated": "2025-07-20"}
{"id": "2507.14688", "title": "Mind the Gap: A Review of Arabic Post-Training Datasets and Their Limitations", "authors": ["Mohammed Alkhowaiter", "Norah Alshahrani", "Saied Alshahrani", "Reem I. Masoud", "Alaa Alzahrani", "Deema Alnuhait", "Emad A. Alghamdi", "Khalid Almubarak"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14688v1", "summary": "Post-training has emerged as a crucial technique for aligning pre-trained\nLarge Language Models (LLMs) with human instructions, significantly enhancing\ntheir performance across a wide range of tasks. Central to this process is the\nquality and diversity of post-training datasets. This paper presents a review\nof publicly available Arabic post-training datasets on the Hugging Face Hub,\norganized along four key dimensions: (1) LLM Capabilities (e.g., Question\nAnswering, Translation, Reasoning, Summarization, Dialogue, Code Generation,\nand Function Calling); (2) Steerability (e.g., persona and system prompts); (3)\nAlignment (e.g., cultural, safety, ethics, and fairness), and (4) Robustness.\nEach dataset is rigorously evaluated based on popularity, practical adoption,\nrecency and maintenance, documentation and annotation quality, licensing\ntransparency, and scientific contribution. Our review revealed critical gaps in\nthe development of Arabic post-training datasets, including limited task\ndiversity, inconsistent or missing documentation and annotation, and low\nadoption across the community. Finally, the paper discusses the implications of\nthese gaps on the progress of Arabic LLMs and applications while providing\nconcrete recommendations for future efforts in post-training dataset\ndevelopment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14688v1", "cate": "cs.CL", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15195", "title": "Feature Construction Using Network Control Theory and Rank Encoding for Graph Machine Learning", "authors": ["Anwar Said", "Yifan Wei", "Ubaid Ullah Ahmad", "Mudassir Shabbir", "Waseem Abbas", "Xenofon Koutsoukos"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15195v1", "summary": "In this article, we utilize the concept of average controllability in graphs,\nalong with a novel rank encoding method, to enhance the performance of Graph\nNeural Networks (GNNs) in social network classification tasks. GNNs have proven\nhighly effective in various network-based learning applications and require\nsome form of node features to function. However, their performance is heavily\ninfluenced by the expressiveness of these features. In social networks, node\nfeatures are often unavailable due to privacy constraints or the absence of\ninherent attributes, making it challenging for GNNs to achieve optimal\nperformance. To address this limitation, we propose two strategies for\nconstructing expressive node features. First, we introduce average\ncontrollability along with other centrality metrics (denoted as NCT-EFA) as\nnode-level metrics that capture critical aspects of network topology. Building\non this, we develop a rank encoding method that transforms average\ncontrollability or any other graph-theoretic metric into a fixed-dimensional\nfeature space, thereby improving feature representation. We conduct extensive\nnumerical evaluations using six benchmark GNN models across four social network\ndatasets to compare different node feature construction methods. Our results\ndemonstrate that incorporating average controllability into the feature space\nsignificantly improves GNN performance. Moreover, the proposed rank encoding\nmethod outperforms traditional one-hot degree encoding, improving the ROC AUC\nfrom 68.7% to 73.9% using GraphSAGE on the GitHub Stargazers dataset,\nunderscoring its effectiveness in generating expressive and efficient node\nrepresentations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15195v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15059", "title": "Rethinking Pan-sharpening: Principled Design, Unified Training, and a Universal Loss Surpass Brute-Force Scaling", "authors": ["Ran Zhang", "Xuanhua He", "Li Xueheng", "Ke Cao", "Liu Liu", "Wenbo Xu", "Fang Jiabin", "Yang Qize", "Jie Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15059v1", "summary": "The field of pan-sharpening has recently seen a trend towards increasingly\nlarge and complex models, often trained on single, specific satellite datasets.\nThis approach, however, leads to high computational overhead and poor\ngeneralization on full resolution data, a paradigm we challenge in this paper.\nIn response to this issue, we propose PanTiny, a lightweight, single-step\npan-sharpening framework designed for both efficiency and robust performance.\nMore critically, we introduce multiple-in-one training paradigm, where a\nsingle, compact model is trained simultaneously on three distinct satellite\ndatasets (WV2, WV3, and GF2) with different resolution and spectral\ninformation. Our experiments show that this unified training strategy not only\nsimplifies deployment but also significantly boosts generalization on\nfull-resolution data. Further, we introduce a universally powerful composite\nloss function that elevates the performance of almost all of models for\npan-sharpening, pushing state-of-the-art metrics into a new era. Our PanTiny\nmodel, benefiting from these innovations, achieves a superior\nperformance-to-efficiency balance, outperforming most larger, specialized\nmodels. Through extensive ablation studies, we validate that principled\nengineering in model design, training paradigms, and loss functions can surpass\nbrute-force scaling. Our work advocates for a community-wide shift towards\ncreating efficient, generalizable, and data-conscious models for\npan-sharpening. The code is available at\nhttps://github.com/Zirconium233/PanTiny .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15059v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15306", "title": "BEAM-Net: A Deep Learning Framework with Bone Enhancement Attention Mechanism for High Resolution High Frame Rate Ultrasound Beamforming", "authors": ["Midhila Madhusoodanan", "Mahesh Raveendranatha Panicker", "Pisharody Harikrishnan Gopalakrishnan", "Abhilash Rakkunedeth Hareendranathan"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15306v1", "summary": "Pocket-sized, low-cost point-of-care ultrasound (POCUS) devices are\nincreasingly used in musculoskeletal (MSK) applications for structural\nexamination of bone tissue. However, the image quality in MSK ultrasound is\noften limited by speckle noise, low resolution, poor contrast, and anisotropic\nreflections, making bone images difficult to interpret without additional\npost-processing. Typically, medical ultrasound systems use delay and sum\nbeamforming (DASB) for image reconstruction, which is not specifically\noptimized for bone structures. To address these limitations, we propose\nBEAM-Net, a novel end-to-end deep neural network (DNN) that performs\nhigh-frame-rate ultrasound beamforming with integrated bone enhancement, using\nsingle-plane-wave (SPW) radio frequency (RF) data as input. Our approach embeds\na Bone Probability Map (BPM), which acts as an attention mechanism to enforce\nhigher structural similarity around bony regions in the image. The proposed\napproach is the first of its kind to incorporate bone enhancement directly into\nultrasound beamforming using deep learning. BEAM-Net was trained and evaluated\non in-vivo MSK and synthetic RF ultrasound datasets. This paper introduces the\nEdge Preservation Index (EPI) as a new region-focused metric for evaluating\nstructural fidelity in bone-enhanced ultrasound images. The performance of\nBEAM-Net was compared with conventional DASB and existing deep learning\narchitectures using the EPI, Contrast Ratio (CR), Signal-to-Noise ratio (SNR),\nSpeckle Similarity Index (SSI), and Structural Similarity Index (SSIM).\nBEAM-Net showed substantial gains over SPW-DASB, achieving 51.4-51% higher CR\nand 94.2-73.3% higher SNR on in-vivo MSK and synthetic RF datasets. It\noutperformed multiple steered plane wave DASB (MPW-DASB), with 19.8-24.0%\nimprovements in CR and SNR on in-vivo MSK and 2.5-12.8% improvements on\nsynthetic data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15306v1", "cate": "eess.SP", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2502.08272", "title": "Weighted Pseudorandom Generators for Read-Once Branching Programs via Weighted Pseudorandom Reductions", "authors": ["Kuan Cheng", "Ruiyang Wu"], "categories": ["cs.CC", "cs.DS"], "primary_category": "Subjects:       Computational Complexity (cs.CC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.08272v4", "summary": "We study weighted pseudorandom generators (WPRGs) and derandomizations for\nread-once branching programs (ROBPs). Denote $n$ and $w$ as the length and the\nwidth of a ROBP. We have the following results.\n  For standard ROBPs, we give an explicit $\\varepsilon$-WPRG with seed length\n  $$O\\left(\\frac{\\log n\\log (nw)}{\\max\\left\\{1,\\log\\log w-\\log\\log\nn\\right\\}}+\\log w \\left(\\log\\log\\log w-\\log\\log\\max\\left\\{2,\\frac{\\log w}{\\log\n\\frac{n}{\\varepsilon}}\\right\\}\\right)+\\log\\frac{1}{\\varepsilon}\\right).$$\n  For permutation ROBPs with unbounded widths and single accept nodes, we give\nan explicit $\\varepsilon$-WPRG with seed length\n  $$O\\left( \\log n\\left( \\log\\log n + \\sqrt{\\log(1/\\varepsilon)}\n\\right)+\\log(1/\\varepsilon)\\right). $$\n  We also give a new Nisan-Zuckerman style derandomization for regular ROBPs\nwith width $w$, length $n = 2^{O(\\sqrt{\\log w})}$, and multiple accept nodes.\nWe attain optimal space complexity $O(\\log w)$ for arbitrary approximation\nerror $\\varepsilon = 1/\\text{poly} (w)$.\n  All our results are based on iterative weighted pseudorandom reductions,\nwhich can iteratively reduce fooling long ROBPs to fooling short ones.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.08272v4", "cate": "cs.CC", "date": "2025-02-12", "updated": "2025-07-21"}
{"id": "2507.15192", "title": "On the stability of the low-rank projector-splitting integrator for hyperbolic and parabolic equations", "authors": ["Shiheng Zhang", "Jingwei Hu"], "categories": ["math.NA", "cs.NA", "35L02, 35K10, 65F55, 65M06, 65M12"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15192v1", "summary": "We study the stability of a class of dynamical low-rank methods--the\nprojector-splitting integrator (PSI)--applied to linear hyperbolic and\nparabolic equations. Using a von Neumann-type analysis, we investigate the\nstability of such low-rank time integrator coupled with standard spatial\ndiscretizations, including upwind and central finite difference schemes, under\ntwo commonly used formulations: discretize-then-project (DtP) and\nproject-then-discretize (PtD). For hyperbolic equations, we show that the\nstability conditions for DtP and PtD are the same under Lie-Trotter splitting,\nand that the stability region can be significantly enlarged by using Strang\nsplitting. For parabolic equations, despite the presence of a negative S-step,\nunconditional stability can still be achieved by employing Crank-Nicolson or a\nhybrid forward-backward Euler scheme in time stepping. While our analysis\nfocuses on simplified model problems, it offers insight into the stability\nbehavior of PSI for more complex systems, such as those arising in kinetic\ntheory.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15192v1", "cate": "math.NA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14471", "title": "Timetide: A programming model for logically synchronous distributed systems", "authors": ["Logan Kenwright", "Partha Roop", "Nathan Allen", "Călin Caşcaval", "Avinash Malik"], "categories": ["cs.PL", "cs.DC"], "primary_category": "Subjects:       Programming Languages (cs.PL)", "pdf_link": null, "comments": "Comments:      25 Pages, 21 Figures", "url": "http://arxiv.org/abs/2507.14471v1", "summary": "Massive strides in deterministic models have been made using synchronous\nlanguages. They are mainly focused on centralised applications, as the\ntraditional approach is to compile away the concurrency. Time triggered\nlanguages such as Giotto and Lingua Franca are suitable for distribution albeit\nthat they rely on expensive physical clock synchronisation, which is both\nexpensive and may suffer from scalability. Hence, deterministic programming of\ndistributed systems remains challenging. We address the challenges of\ndeterministic distribution by developing a novel multiclock semantics of\nsynchronous programs. The developed semantics is amenable to seamless\ndistribution. Moreover, our programming model, Timetide, alleviates the need\nfor physical clock synchronisation by building on the recently proposed logical\nsynchrony model for distributed systems. We discuss the important aspects of\ndistributing computation, such as network communication delays, and explore the\nformal verification of Timetide programs. To the best of our knowledge,\nTimetide is the first multiclock synchronous language that is both amenable to\ndistribution and formal verification without the need for physical clock\nsynchronisation or clock gating.", "comment": "25 Pages, 21 Figures", "pdf_url": "http://arxiv.org/pdf/2507.14471v1", "cate": "cs.PL", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14258", "title": "Dispute Resolution in Peer Review with Abstract Argumentation and OWL DL", "authors": ["Ildar Baimuratov", "Elena Lisanyuk", "Dmitry Prokudin"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14258v1", "summary": "The peer review process for scientific publications faces significant\nchallenges due to the increasing volume of submissions and inherent reviewer\nbiases. While artificial intelligence offers the potential to facilitate the\nprocess, it also risks perpetuating biases present in training data. This\nresearch addresses these challenges by applying formal methods from\nargumentation theory to support transparent and unbiased dispute resolution in\npeer review. Specifically, we conceptualize scientific peer review as a single\nmixed argumentative dispute between manuscript authors and reviewers and\nformalize it using abstract argumentation frameworks. We analyze the resulting\npeer review argumentation frameworks from semantic, graph-theoretic, and\ncomputational perspectives, showing that they are well-founded and decidable in\nlinear time. These frameworks are then implemented using OWL DL and resolved\nwith reasoning engines. We validate our approach by annotating a corpus of\nscientific peer reviews with abstract argumentation frameworks and applying a\nproof of concept to resolve the annotated disputes. The results demonstrate\nthat integrating our method could enhance the quality of published work by\nproviding a more rigorous and systematic approach to accounting reviewer\narguments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14258v1", "cate": "cs.CY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15787", "title": "Missing Physics Discovery through Fully Differentiable Finite Element-Based Machine Learning", "authors": ["Ado Farsi", "Nacime Bouziani", "David A Ham"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15787v1", "summary": "Although many problems in science and engineering are modelled by\nwell-established PDEs, they often involve unknown or incomplete relationships,\nsuch as material constitutive laws or thermal response, that limit accuracy and\ngenerality. Existing surrogate-modelling approaches directly approximate PDE\nsolutions but remain tied to a specific geometry, boundary conditions, and set\nof physical constraints. To address these limitations, we introduce a fully\ndifferentiable finite element-based machine learning (FEBML) framework that\nembeds trainable operators for unknown physics within a state-of-the-art,\ngeneral FEM solver, enabling true end-to-end differentiation. At its core,\nFEBML represents each unknown operator as an encode-process-decode pipeline\nover finite-element degrees of freedom: field values are projected to nodal\ncoefficients, transformed by a neural network, and then lifted back to a\ncontinuous FE function, ensuring the learned physics respects the variational\nstructure. We demonstrate its versatility by recovering nonlinear stress-strain\nlaws from laboratory tests, applying the learned model to a new mechanical\nscenario without retraining, and identifying temperature-dependent conductivity\nin transient heat flow.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15787v1", "cate": "cs.CE", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2503.02247", "title": "WMNav: Integrating Vision-Language Models into World Models for Object Goal Navigation", "authors": ["Dujun Nie", "Xianda Guo", "Yiqun Duan", "Ruijun Zhang", "Long Chen"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 pages, 5 figures", "url": "http://arxiv.org/abs/2503.02247v5", "summary": "Object Goal Navigation-requiring an agent to locate a specific object in an\nunseen environment-remains a core challenge in embodied AI. Although recent\nprogress in Vision-Language Model (VLM)-based agents has demonstrated promising\nperception and decision-making abilities through prompting, none has yet\nestablished a fully modular world model design that reduces risky and costly\ninteractions with the environment by predicting the future state of the world.\nWe introduce WMNav, a novel World Model-based Navigation framework powered by\nVision-Language Models (VLMs). It predicts possible outcomes of decisions and\nbuilds memories to provide feedback to the policy module. To retain the\npredicted state of the environment, WMNav proposes the online maintained\nCuriosity Value Map as part of the world model memory to provide dynamic\nconfiguration for navigation policy. By decomposing according to a human-like\nthinking process, WMNav effectively alleviates the impact of model\nhallucination by making decisions based on the feedback difference between the\nworld model plan and observation. To further boost efficiency, we implement a\ntwo-stage action proposer strategy: broad exploration followed by precise\nlocalization. Extensive evaluation on HM3D and MP3D validates WMNav surpasses\nexisting zero-shot benchmarks in both success rate and exploration efficiency\n(absolute improvement: +3.2% SR and +3.2% SPL on HM3D, +13.5% SR and +1.1% SPL\non MP3D). Project page: https://b0b8k1ng.github.io/WMNav/.", "comment": "8 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2503.02247v5", "cate": "cs.CV", "date": "2025-03-04", "updated": "2025-07-19"}
{"id": "2507.14693", "title": "Rethinking Suicidal Ideation Detection: A Trustworthy Annotation Framework and Cross-Lingual Model Evaluation", "authors": ["Amina Dzafic", "Merve Kavut", "Ulya Bayram"], "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      This manuscript has been submitted to the IEEE Journal of Biomedical and Health Informatics", "url": "http://arxiv.org/abs/2507.14693v1", "summary": "Suicidal ideation detection is critical for real-time suicide prevention, yet\nits progress faces two under-explored challenges: limited language coverage and\nunreliable annotation practices. Most available datasets are in English, but\neven among these, high-quality, human-annotated data remains scarce. As a\nresult, many studies rely on available pre-labeled datasets without examining\ntheir annotation process or label reliability. The lack of datasets in other\nlanguages further limits the global realization of suicide prevention via\nartificial intelligence (AI). In this study, we address one of these gaps by\nconstructing a novel Turkish suicidal ideation corpus derived from social media\nposts and introducing a resource-efficient annotation framework involving three\nhuman annotators and two large language models (LLMs). We then address the\nremaining gaps by performing a bidirectional evaluation of label reliability\nand model consistency across this dataset and three popular English suicidal\nideation detection datasets, using transfer learning through eight pre-trained\nsentiment and emotion classifiers. These transformers help assess annotation\nconsistency and benchmark model performance against manually labeled data. Our\nfindings underscore the need for more rigorous, language-inclusive approaches\nto annotation and evaluation in mental health natural language processing (NLP)\nwhile demonstrating the questionable performance of popular models with\nzero-shot transfer learning. We advocate for transparency in model training and\ndataset construction in mental health NLP, prioritizing data and model\nreliability.", "comment": "This manuscript has been submitted to the IEEE Journal of Biomedical\n  and Health Informatics", "pdf_url": "http://arxiv.org/pdf/2507.14693v1", "cate": "cs.CL", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15205", "title": "Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation", "authors": ["Xinran Li", "Xiujuan Xu", "Jiaqi Qiao"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by the 28th European Conference on Artificial Intelligence (ECAI 2025)", "url": "http://arxiv.org/abs/2507.15205v1", "summary": "Emotion Recognition in Conversation (ERC) is a practical and challenging\ntask. This paper proposes a novel multimodal approach, the Long-Short Distance\nGraph Neural Network (LSDGNN). Based on the Directed Acyclic Graph (DAG), it\nconstructs a long-distance graph neural network and a short-distance graph\nneural network to obtain multimodal features of distant and nearby utterances,\nrespectively. To ensure that long- and short-distance features are as distinct\nas possible in representation while enabling mutual influence between the two\nmodules, we employ a Differential Regularizer and incorporate a BiAffine Module\nto facilitate feature interaction. In addition, we propose an Improved\nCurriculum Learning (ICL) to address the challenge of data imbalance. By\ncomputing the similarity between different emotions to emphasize the shifts in\nsimilar emotions, we design a \"weighted emotional shift\" metric and develop a\ndifficulty measurer, enabling a training process that prioritizes learning easy\nsamples before harder ones. Experimental results on the IEMOCAP and MELD\ndatasets demonstrate that our model outperforms existing benchmarks.", "comment": "Accepted by the 28th European Conference on Artificial Intelligence\n  (ECAI 2025)", "pdf_url": "http://arxiv.org/pdf/2507.15205v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15064", "title": "StableAnimator++: Overcoming Pose Misalignment and Face Distortion for Human Image Animation", "authors": ["Shuyuan Tu", "Zhen Xing", "Xintong Han", "Zhi-Qi Cheng", "Qi Dai", "Chong Luo", "Zuxuan Wu", "Yu-Gang Jiang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      arXiv admin note: substantial text overlap with arXiv:2411.17697", "url": "http://arxiv.org/abs/2507.15064v1", "summary": "Current diffusion models for human image animation often struggle to maintain\nidentity (ID) consistency, especially when the reference image and driving\nvideo differ significantly in body size or position. We introduce\nStableAnimator++, the first ID-preserving video diffusion framework with\nlearnable pose alignment, capable of generating high-quality videos conditioned\non a reference image and a pose sequence without any post-processing. Building\nupon a video diffusion model, StableAnimator++ contains carefully designed\nmodules for both training and inference, striving for identity consistency. In\nparticular, StableAnimator++ first uses learnable layers to predict the\nsimilarity transformation matrices between the reference image and the driven\nposes via injecting guidance from Singular Value Decomposition (SVD). These\nmatrices align the driven poses with the reference image, mitigating\nmisalignment to a great extent. StableAnimator++ then computes image and face\nembeddings using off-the-shelf encoders, refining the face embeddings via a\nglobal content-aware Face Encoder. To further maintain ID, we introduce a\ndistribution-aware ID Adapter that counteracts interference caused by temporal\nlayers while preserving ID via distribution alignment. During the inference\nstage, we propose a novel Hamilton-Jacobi-Bellman (HJB) based face optimization\nintegrated into the denoising process, guiding the diffusion trajectory for\nenhanced facial fidelity. Experiments on benchmarks show the effectiveness of\nStableAnimator++ both qualitatively and quantitatively.", "comment": "arXiv admin note: substantial text overlap with arXiv:2411.17697", "pdf_url": "http://arxiv.org/pdf/2507.15064v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15364", "title": "EEG-based Epileptic Prediction via a Two-stage Channel-aware Set Transformer Network", "authors": ["Ruifeng Zheng", "Cong Chen", "Shuang Wang", "Yiming Liu", "Lin You", "Jindong Lu", "Ruizhe Zhu", "Guodao Zhang", "Kejie Huang"], "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15364v1", "summary": "Epilepsy is a chronic, noncommunicable brain disorder, and sudden seizure\nonsets can significantly impact patients' quality of life and health. However,\nwearable seizure-predicting devices are still limited, partly due to the bulky\nsize of EEG-collecting devices. To relieve the problem, we proposed a novel\ntwo-stage channel-aware Set Transformer Network that could perform seizure\nprediction with fewer EEG channel sensors. We also tested a seizure-independent\ndivision method which could prevent the adjacency of training and test data.\nExperiments were performed on the CHB-MIT dataset which includes 22 patients\nwith 88 merged seizures. The mean sensitivity before channel selection was\n76.4% with a false predicting rate (FPR) of 0.09/hour. After channel selection,\ndominant channels emerged in 20 out of 22 patients; the average number of\nchannels was reduced to 2.8 from 18; and the mean sensitivity rose to 80.1%\nwith an FPR of 0.11/hour. Furthermore, experimental results on the\nseizure-independent division supported our assertion that a more rigorous\nseizure-independent division should be used for patients with abundant EEG\nrecordings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15364v1", "cate": "eess.SP", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2505.01990", "title": "On optimal distinguishers for Planted Clique", "authors": ["Ansh Nagda", "Prasad Raghavendra"], "categories": ["cs.CC", "cs.DS"], "primary_category": "Subjects:       Computational Complexity (cs.CC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.01990v2", "summary": "In a distinguishing problem, the input is a sample drawn from one of two\ndistributions and the algorithm is tasked with identifying the source\ndistribution. The performance of a distinguishing algorithm is measured by its\nadvantage, i.e., its incremental probability of success over a random guess. A\nclassic example of a distinguishing problem is the Planted Clique problem,\nwhere the input is a graph sampled from either $G(n,1/2)$ -- the standard\nErd\\H{o}s-R\\'{e}nyi model, or $G(n,1/2,k)$ -- the Erd\\H{o}s-R\\'{e}nyi model\nwith a clique planted on a random subset of $k$ vertices. The Planted Clique\nHypothesis asserts that efficient algorithms cannot achieve advantage better\nthan some absolute constant, say $1/4$, whenever $k=n^{1/2-\\Omega(1)}$. In this\nwork, we aim to precisely understand the optimal distinguishing advantage\nachievable by efficient algorithms on Planted Clique. We show the following\nresults under the Planted Clique hypothesis:\n  1. Optimality of low-degree polynomials: No efficient algorithm can beat the\nadvantage the optimal low-degree polynomial. Concretely, this means that the\nadvantage of any efficient algorithm is at most $(1+o(1))\\cdot\nk^2/(\\sqrt{\\pi}n)$, which is optimal in light of a simple edge-counting\nalgorithm achieving this bound.\n  2. Harder planted distributions: There is an efficiently sampleable\ndistribution $\\mathcal{P}^*$ supported on graphs containing $k$-cliques such\nthat no efficient algorithm can distinguish $\\mathcal{P}^*$ from $G(n,1/2)$\nwith advantage $n^{-d}$ for an arbitrarily large constant $d$. In other words,\nthere exist alternate planted distributions that are much harder than\n$G(n,1/2,k)$. Along the way, we prove a constructive hard-core lemma for a\nbroad class of distributions with respect to low-degree polynomials. This\nresult is applicable much more widely beyond Planted Clique and might be of\nindependent interest.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.01990v2", "cate": "cs.CC", "date": "2025-05-04", "updated": "2025-07-19"}
{"id": "2507.15289", "title": "Efficient evaluation of forward and inverse energy-based magnetic hysteresis operators", "authors": ["Herbert Egger", "Felix Engertsberger", "Andreas Schafelner"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15289v1", "summary": "The energy-based vector hysteresis model of Francois-Lavet et al. establishes\nan implicit relation between magnetic fields and fluxes via internal magnetic\npolarizations which are determined by convex but non-smooth minimization\nproblems. The systematic solution of these problems for every material point is\na key ingredient for the efficient implementation of the model into standard\nmagnetic field solvers. We propose to approximate the non-smooth terms via\nregularization which allows to employ standard Newton methods for the\nevaluation of the local material models while being in control of the error in\nthis approximation. We further derive the inverse of the regularized hysteresis\noperator which amounts to a regularized version of the inverse hysteresis\nmodel. The magnetic polarizations in this model are again determined by local\nminimization problems which here are coupled across the different pinning\nforces. An efficient algorithm for solving the Newton systems is proposed which\nallows evaluation of the inverse hysteresis operator at the same cost as the\nforward model. Numerical tests on standard benchmark problems are presented for\nillustration of our results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15289v1", "cate": "math.NA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14682", "title": "IDSS, a Novel P2P Relational Data Storage Service", "authors": ["Massimo Cafaro", "Italo Epicoco", "Marco Pulimeno", "Lunodzo J. Mwinuka", "Lucas Pereira", "Hugo Morais"], "categories": ["cs.DB", "cs.DC"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14682v1", "summary": "The rate at which data is generated has been increasing rapidly, raising\nchallenges related to its management. Traditional database management systems\nsuffer from scalability and are usually inefficient when dealing with\nlarge-scale and heterogeneous data. This paper introduces IDSS (InnoCyPES Data\nStorage Service), a novel large-scale data storage tool that leverages\npeer-to-peer networks and embedded relational databases. We present the IDSS\narchitecture and its design, and provide details related to the implementation.\nThe peer-to-peer framework is used to provide support for distributed queries\nleveraging a relational database architecture based on a common schema.\nFurthermore, methods to support complex distributed query processing, enabling\nrobust and efficient management of vast amounts of data are presented.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14682v1", "cate": "cs.DB", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14755", "title": "A Risk Assessment Framework for Digital Identification Systems", "authors": ["Allison Woodruff", "Dirk Balfanz", "Will Drewry", "Mariana Raykova"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      12 pages, 5 tables", "url": "http://arxiv.org/abs/2507.14755v1", "summary": "We introduce a risk assessment framework for digital identification systems,\nas well as recommended best practices to enhance privacy, security, and other\ndesirable properties in these systems. To generate these resources, we created\na casebook of a wide range of digital identification systems, and we then\napplied expert analysis and critique to identify patterns. We piloted the\nframework on several reviews within our organization over a period of\napproximately one year, and found it to be robust and helpful for those\nreviews. This work is intended to inform product review and development,\nproduct policy, and standards efforts, and to help guide a consistent\nresponsible approach to digital identification across the broader digital\nidentification ecosystem.", "comment": "12 pages, 5 tables", "pdf_url": "http://arxiv.org/pdf/2507.14755v1", "cate": "cs.CY", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14586", "title": "What do Large Language Models know about materials?", "authors": ["Adrian Ehrenhofer", "Thomas Wallmersperger", "Gianaurelio Cuniberti"], "categories": ["physics.app-ph", "cs.CE", "cs.CL"], "primary_category": "Subjects:       Applied Physics (physics.app-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14586v1", "summary": "Large Language Models (LLMs) are increasingly applied in the fields of\nmechanical engineering and materials science. As models that establish\nconnections through the interface of language, LLMs can be applied for\nstep-wise reasoning through the Processing-Structure-Property-Performance chain\nof material science and engineering. Current LLMs are built for adequately\nrepresenting a dataset, which is the most part of the accessible internet.\nHowever, the internet mostly contains non-scientific content. If LLMs should be\napplied for engineering purposes, it is valuable to investigate models for\ntheir intrinsic knowledge -- here: the capacity to generate correct information\nabout materials. In the current work, for the example of the Periodic Table of\nElements, we highlight the role of vocabulary and tokenization for the\nuniqueness of material fingerprints, and the LLMs' capabilities of generating\nfactually correct output of different state-of-the-art open models. This leads\nto a material knowledge benchmark for an informed choice, for which steps in\nthe PSPP chain LLMs are applicable, and where specialized models are required.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14586v1", "cate": "physics.app-ph", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2503.02600", "title": "Resource-Efficient Affordance Grounding with Complementary Depth and Semantic Prompts", "authors": ["Yizhou Huang", "Fan Yang", "Guoliang Zhu", "Gen Li", "Hao Shi", "Yukun Zuo", "Wenrui Chen", "Zhiyong Li", "Kailun Yang"], "categories": ["cs.CV", "cs.RO", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to IROS 2025. The source code will be made publicly available at this https URL", "url": "http://arxiv.org/abs/2503.02600v2", "summary": "Affordance refers to the functional properties that an agent perceives and\nutilizes from its environment, and is key perceptual information required for\nrobots to perform actions. This information is rich and multimodal in nature.\nExisting multimodal affordance methods face limitations in extracting useful\ninformation, mainly due to simple structural designs, basic fusion methods, and\nlarge model parameters, making it difficult to meet the performance\nrequirements for practical deployment. To address these issues, this paper\nproposes the BiT-Align image-depth-text affordance mapping framework. The\nframework includes a Bypass Prompt Module (BPM) and a Text Feature Guidance\n(TFG) attention selection mechanism. BPM integrates the auxiliary modality\ndepth image directly as a prompt to the primary modality RGB image, embedding\nit into the primary modality encoder without introducing additional encoders.\nThis reduces the model's parameter count and effectively improves functional\nregion localization accuracy. The TFG mechanism guides the selection and\nenhancement of attention heads in the image encoder using textual features,\nimproving the understanding of affordance characteristics. Experimental results\ndemonstrate that the proposed method achieves significant performance\nimprovements on public AGD20K and HICO-IIF datasets. On the AGD20K dataset,\ncompared with the current state-of-the-art method, we achieve a 6.0%\nimprovement in the KLD metric, while reducing model parameters by 88.8%,\ndemonstrating practical application values. The source code will be made\npublicly available at https://github.com/DAWDSE/BiT-Align.", "comment": "Accepted to IROS 2025. The source code will be made publicly\n  available at https://github.com/DAWDSE/BiT-Align", "pdf_url": "http://arxiv.org/pdf/2503.02600v2", "cate": "cs.CV", "date": "2025-03-04", "updated": "2025-07-19"}
{"id": "2507.14760", "title": "QUTCC: Quantile Uncertainty Training and Conformal Calibration for Imaging Inverse Problems", "authors": ["Cassandra Tong Ye", "Shamus Li", "Tyler King", "Kristina Monakhova"], "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14760v1", "summary": "Deep learning models often hallucinate, producing realistic artifacts that\nare not truly present in the sample. This can have dire consequences for\nscientific and medical inverse problems, such as MRI and microscopy denoising,\nwhere accuracy is more important than perceptual quality. Uncertainty\nquantification techniques, such as conformal prediction, can pinpoint outliers\nand provide guarantees for image regression tasks, improving reliability.\nHowever, existing methods utilize a linear constant scaling factor to calibrate\nuncertainty bounds, resulting in larger, less informative bounds. We propose\nQUTCC, a quantile uncertainty training and calibration technique that enables\nnonlinear, non-uniform scaling of quantile predictions to enable tighter\nuncertainty estimates. Using a U-Net architecture with a quantile embedding,\nQUTCC enables the prediction of the full conditional distribution of quantiles\nfor the imaging task. During calibration, QUTCC generates uncertainty bounds by\niteratively querying the network for upper and lower quantiles, progressively\nrefining the bounds to obtain a tighter interval that captures the desired\ncoverage. We evaluate our method on several denoising tasks as well as\ncompressive MRI reconstruction. Our method successfully pinpoints\nhallucinations in image estimates and consistently achieves tighter uncertainty\nintervals than prior methods while maintaining the same statistical coverage.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14760v1", "cate": "eess.IV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15240", "title": "Exact Reformulation and Optimization for Direct Metric Optimization in Binary Imbalanced Classification", "authors": ["Le Peng", "Yash Travadi", "Chuan He", "Ying Cui", "Ju Sun"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15240v1", "summary": "For classification with imbalanced class frequencies, i.e., imbalanced\nclassification (IC), standard accuracy is known to be misleading as a\nperformance measure. While most existing methods for IC resort to optimizing\nbalanced accuracy (i.e., the average of class-wise recalls), they fall short in\nscenarios where the significance of classes varies or certain metrics should\nreach prescribed levels. In this paper, we study two key classification\nmetrics, precision and recall, under three practical binary IC settings: fix\nprecision optimize recall (FPOR), fix recall optimize precision (FROP), and\noptimize $F_\\beta$-score (OFBS). Unlike existing methods that rely on smooth\napproximations to deal with the indicator function involved, \\textit{we\nintroduce, for the first time, exact constrained reformulations for these\ndirect metric optimization (DMO) problems}, which can be effectively solved by\nexact penalty methods. Experiment results on multiple benchmark datasets\ndemonstrate the practical superiority of our approach over the state-of-the-art\nmethods for the three DMO problems. We also expect our exact reformulation and\noptimization (ERO) framework to be applicable to a wide range of DMO problems\nfor binary IC and beyond. Our code is available at\nhttps://github.com/sun-umn/DMO.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15240v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15085", "title": "Aesthetics is Cheap, Show me the Text: An Empirical Evaluation of State-of-the-Art Generative Models for OCR", "authors": ["Peirong Zhang", "Haowei Xu", "Jiaxin Zhang", "Guitao Xu", "Xuhan Zheng", "Zhenhua Yang", "Junle Liu", "Yuyi Zhang", "Lianwen Jin"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15085v1", "summary": "Text image is a unique and crucial information medium that integrates visual\naesthetics and linguistic semantics in modern e-society. Due to their subtlety\nand complexity, the generation of text images represents a challenging and\nevolving frontier in the image generation field. The recent surge of\nspecialized image generators (\\emph{e.g.}, Flux-series) and unified generative\nmodels (\\emph{e.g.}, GPT-4o), which demonstrate exceptional fidelity, raises a\nnatural question: can they master the intricacies of text image generation and\nediting? Motivated by this, we assess current state-of-the-art generative\nmodels' capabilities in terms of text image generation and editing. We\nincorporate various typical optical character recognition (OCR) tasks into our\nevaluation and broaden the concept of text-based generation tasks into OCR\ngenerative tasks. We select 33 representative tasks and categorize them into\nfive categories: document, handwritten text, scene text, artistic text, and\ncomplex \\& layout-rich text. For comprehensive evaluation, we examine six\nmodels across both closed-source and open-source domains, using tailored,\nhigh-quality image inputs and prompts. Through this evaluation, we draw crucial\nobservations and identify the weaknesses of current generative models for OCR\ntasks. We argue that photorealistic text image generation and editing should be\ninternalized as foundational skills into general-domain generative models,\nrather than being delegated to specialized solutions, and we hope this\nempirical analysis can provide valuable insights for the community to achieve\nthis goal. This evaluation is online and will be continuously updated at our\nGitHub repository.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15085v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15373", "title": "Robust ISAC Transceiver Beamforming Design under Low-Resolution AD/DA Converters", "authors": ["Tiantian Xu", "Zhenyao He", "Jindan Xu", "Wei Xu", "Jianfeng Wang", "Derrick Wing Kwan Ng"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15373v1", "summary": "In this letter, we investigate the robust beamforming design for an\nintegrated sensing and communication (ISAC) system featuring low-resolution\ndigital-to-analog converters (DACs) and analog-to-digital converters (ADCs).\nTaking into account quantization noise, we aim at maximizing the radar\nsignal-to-quantization-plus-noise ratio (SQNR) while guaranteeing the minimum\nrequired signal-to-quantization-plus-interference-plus-noise ratio (SQINR) for\ncommunication users. To address this nonconvex design problem, we first examine\na scenario involving a point target and uniform-resolution DACs, where the\nglobally optimal solution is obtained by applying the semidefinite relaxation\n(SDR) technique. For more general scenarios, including those with mixed-DACs\nand/or an extended target, we develop a low-complexity\nmajorization-minimization (MM)-based algorithm to tackle the problem\niteratively. Compared to the non-robust algorithm, the proposed algorithm\ndemonstrates improved detection performance under practical quantization.\nSimulation results confirm the robustness and efficacy of our proposed\nalgorithm in low-resolution quantization scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15373v1", "cate": "eess.SP", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15322", "title": "Convergence analysis of Anderson acceleration for nonlinear equations with Hölder continuous derivatives", "authors": ["Yonghui Ling", "Zikang Xiong", "Juan Liang"], "categories": ["math.NA", "cs.NA", "65H10, 15A24"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      27pages", "url": "http://arxiv.org/abs/2507.15322v1", "summary": "This work investigates the local convergence behavior of Anderson\nacceleration in solving nonlinear systems. We establish local R-linear\nconvergence results for Anderson acceleration with general depth $m$ under the\nassumptions that the Jacobian of the nonlinear operator is H\\\"older continuous\nand the corresponding fixed-point function is contractive. In the Lipschitz\ncontinuous case, we obtain a sharper R-linear convergence factor. We also\nderive a refined residual bound for the depth $m = 1$ under the same\nassumptions used for the general depth results. Applications to a nonsymmetric\nRiccati equation from transport theory demonstrate that Anderson acceleration\nyields comparable results to several existing fixed-point methods for the\nregular cases, and that it brings significant reductions in both the number of\niterations and computation time, even in challenging cases involving nearly\nsingular or large-scale problems.", "comment": "27pages", "pdf_url": "http://arxiv.org/pdf/2507.15322v1", "cate": "math.NA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14813", "title": "Mayura: Exploiting Similarities in Motifs for Temporal Co-Mining", "authors": ["Sanjay Sri Vallabh Singapuram", "Ronald Dreslinski", "Nishil Talati"], "categories": ["cs.DB", "cs.DC", "cs.PF"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14813v1", "summary": "Temporal graphs serve as a critical foundation for modeling evolving\ninteractions in domains ranging from financial networks to social media. Mining\ntemporal motifs is essential for applications such as fraud detection,\ncybersecurity, and dynamic network analysis. However, conventional motif mining\napproaches treat each query independently, incurring significant redundant\ncomputations when similar substructures exist across multiple motifs. In this\npaper, we propose Mayura, a novel framework that unifies the mining of multiple\ntemporal motifs by exploiting their inherent structural and temporal\ncommonalities. Central to our approach is the Motif-Group Tree (MG-Tree), a\nhierarchical data structure that organizes related motifs and enables the reuse\nof common search paths, thereby reducing redundant computation. We propose a\nco-mining algorithm that leverages the MG-Tree and develop a flexible runtime\ncapable of exploiting both CPU and GPU architectures for scalable performance.\nEmpirical evaluations on diverse real-world datasets demonstrate that Mayura\nachieves substantial improvements over the state-of-the-art techniques that\nmine each motif individually, with an average speed-up of 2.4x on the CPU and\n1.7x on the GPU, while maintaining the exactness required for high-stakes\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14813v1", "cate": "cs.DB", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14860", "title": "Strategic Integration of AI Chatbots in Physics Teacher Preparation: A TPACK-SWOT Analysis of Pedagogical, Epistemic, and Cybersecurity Dimensions", "authors": ["N. Mohammadipour"], "categories": ["cs.CY", "physics.ed-ph"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      34 pages, 3 figures, 4 tables", "url": "http://arxiv.org/abs/2507.14860v1", "summary": "This study investigates the strategic and epistemically responsible\nintegration of AI-powered chatbots into physics teacher education by employing\na TPACK-guided SWOT framework across three structured learning activities.\nConducted within a university-level capstone course on innovative tools for\nphysics instruction, the activities targeted key intersections of\ntechnological, pedagogical, and content knowledge (TPACK) through\nchatbot-assisted tasks: simplifying abstract physics concepts, constructing\nsymbolic concept maps, and designing instructional scenarios. Drawing on\nparticipant reflections, classroom artifacts, and iterative feedback, the\nresults highlight internal strengths such as enhanced information-seeking\nbehavior, scaffolded pedagogical planning, and support for symbolic reasoning.\nAt the same time, internal weaknesses emerged, including domain-specific\ninaccuracies, symbolic limitations (e.g., LaTeX misrendering), and risks of\noverreliance on AI outputs. External opportunities were found in promoting\ninclusive education, multilingual engagement, and expanded zones of proximal\ndevelopment (ZPD), while external threats included prompt injection risks,\ninstitutional access gaps, and cybersecurity vulnerabilities. By extending\nexisting TPACK-based models with constructs such as AI literacy,\nprompt-crafting competence, and epistemic verification protocols, this research\noffers a theoretically grounded and practically actionable roadmap for\nembedding AI in STEM teacher preparation. The findings affirm that, when\ncritically scaffolded, AI chatbots can support metacognitive reflection,\nethical reasoning, and instructional innovation in physics education if\nimplementation is paired with digital fluency training and institutional\nsupport.", "comment": "34 pages, 3 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.14860v1", "cate": "cs.CY", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14652", "title": "Accelerating Hamiltonian Monte Carlo for Bayesian Inference in Neural Networks and Neural Operators", "authors": ["Ponkrshnan Thiagarajan", "Tamer A. Zaki", "Michael D. Shields"], "categories": ["stat.ML", "cs.CE", "cs.LG", "physics.data-an"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14652v1", "summary": "Hamiltonian Monte Carlo (HMC) is a powerful and accurate method to sample\nfrom the posterior distribution in Bayesian inference. However, HMC techniques\nare computationally demanding for Bayesian neural networks due to the high\ndimensionality of the network's parameter space and the non-convexity of their\nposterior distributions. Therefore, various approximation techniques, such as\nvariational inference (VI) or stochastic gradient MCMC, are often employed to\ninfer the posterior distribution of the network parameters. Such approximations\nintroduce inaccuracies in the inferred distributions, resulting in unreliable\nuncertainty estimates. In this work, we propose a hybrid approach that combines\ninexpensive VI and accurate HMC methods to efficiently and accurately quantify\nuncertainties in neural networks and neural operators. The proposed approach\nleverages an initial VI training on the full network. We examine the influence\nof individual parameters on the prediction uncertainty, which shows that a\nlarge proportion of the parameters do not contribute substantially to\nuncertainty in the network predictions. This information is then used to\nsignificantly reduce the dimension of the parameter space, and HMC is performed\nonly for the subset of network parameters that strongly influence prediction\nuncertainties. This yields a framework for accelerating the full batch HMC for\nposterior inference in neural networks. We demonstrate the efficiency and\naccuracy of the proposed framework on deep neural networks and operator\nnetworks, showing that inference can be performed for large networks with tens\nto hundreds of thousands of parameters. We show that this method can\neffectively learn surrogates for complex physical systems by modeling the\noperator that maps from upstream conditions to wall-pressure data on a cone in\nhypersonic flow.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14652v1", "cate": "stat.ML", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14300", "title": "Distributed consensus-based observer design for target state estimation with bearing measurements", "authors": ["Marcelo Jacinto", "Pedro Trindade", "Francisco Rego", "Rita Cunha"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14300v1", "summary": "This paper introduces a novel distributed consensus-based observer design\nthat enables a group of agents in an undirected communication network to solve\nthe problem of target tracking, where the target is modeled as a chain of\nintegrators of arbitrary order. Each agent is assumed to know its own position\nand simultaneously measure bearing vectors relative to the target. We start by\nintroducing a general continuous time observer design tailored to systems whose\nstate dynamics are modeled as chains of integrators and whose measurement model\nfollows a particular nonlinear but observer-suited form. This design leverages\na correction term that combines innovation and consensus components, allowing\neach agent to broadcast only a part of the state estimate to its neighbours,\nwhich effectively reduces the data flowing across the network. To provide\nuniform exponential stability guarantees, a novel result for a class of\nnonlinear closed-loop systems in a generalized observer form is introduced and\nsubsequently used as the main tool to derive stability conditions on the\nobserver gains. Then, by exploring the properties of orthogonal projection\nmatrices, the proposed design is used to solve the distributed target tracking\nproblem and provide explicit stability conditions that depend on the\ntarget-agents geometric formation. Practical examples are derived for a target\nmodeled as first-, second-, and third-order integrator dynamics, highlighting\nthe design procedure and the stability conditions imposed. Finally, numerical\nresults showcase the properties of the proposed algorithm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14300v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2503.12419", "title": "EgoEvGesture: Gesture Recognition Based on Egocentric Event Camera", "authors": ["Luming Wang", "Hao Shi", "Xiaoting Yin", "Kailun Yang", "Kaiwei Wang", "Jian Bai"], "categories": ["cs.CV", "cs.RO", "eess.IV", "physics.optics"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to SMC 2025. The dataset and models are made available at this https URL", "url": "http://arxiv.org/abs/2503.12419v3", "summary": "Egocentric gesture recognition is a pivotal technology for enhancing natural\nhuman-computer interaction, yet traditional RGB-based solutions suffer from\nmotion blur and illumination variations in dynamic scenarios. While event\ncameras show distinct advantages in handling high dynamic range with ultra-low\npower consumption, existing RGB-based architectures face inherent limitations\nin processing asynchronous event streams due to their synchronous frame-based\nnature. Moreover, from an egocentric perspective, event cameras record data\nthat includes events generated by both head movements and hand gestures,\nthereby increasing the complexity of gesture recognition. To address this, we\npropose a novel network architecture specifically designed for event data\nprocessing, incorporating (1) a lightweight CNN with asymmetric depthwise\nconvolutions to reduce parameters while preserving spatiotemporal features, (2)\na plug-and-play state-space model as context block that decouples head movement\nnoise from gesture dynamics, and (3) a parameter-free Bins-Temporal Shift\nModule (BTSM) that shifts features along bins and temporal dimensions to fuse\nsparse events efficiently. We further establish the EgoEvGesture dataset, the\nfirst large-scale dataset for egocentric gesture recognition using event\ncameras. Experimental results demonstrate that our method achieves 62.7%\naccuracy tested on unseen subjects with only 7M parameters, 3.1% higher than\nstate-of-the-art approaches. Notable misclassifications in freestyle motions\nstem from high inter-personal variability and unseen test patterns differing\nfrom training data. Moreover, our approach achieved a remarkable accuracy of\n97.0% on the DVS128 Gesture, demonstrating the effectiveness and generalization\ncapability of our method on public datasets. The dataset and models are made\navailable at https://github.com/3190105222/EgoEv_Gesture.", "comment": "Accepted to SMC 2025. The dataset and models are made available at\n  https://github.com/3190105222/EgoEv_Gesture", "pdf_url": "http://arxiv.org/pdf/2503.12419v3", "cate": "cs.CV", "date": "2025-03-16", "updated": "2025-07-19"}
{"id": "2507.14800", "title": "Large Language Model as An Operator: An Experience-Driven Solution for Distribution Network Voltage Control", "authors": ["Xu Yang", "Chenhui Lin", "Haotian Liu", "Qi Wang", "Wenchuan Wu"], "categories": ["eess.SY", "cs.AI", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14800v1", "summary": "With the advanced reasoning and information analysis capabilities, large\nlanguage models (LLMs) can offer a novel approach for the autonomous generation\nof dispatch strategies in power systems. This letter proposes an LLM-based\nexperience-driven voltage control solution for distribution networks, which\nenables the self-evolution of LLM-based voltage control strategies through the\ncollaboration and interaction of multiple modules-specifically, experience\nstorage, experience retrieval, experience generation, and experience\nmodification. Comprehensive experimental results validate the effectiveness of\nthe proposed method and highlight the applicability of LLM in addressing power\nsystem dispatch challenges.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14800v1", "cate": "eess.SY", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15246", "title": "Spatio-Temporal Demand Prediction for Food Delivery Using Attention-Driven Graph Neural Networks", "authors": ["Rabia Latief Bhat", "Iqra Altaf Gillani"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15246v1", "summary": "Accurate demand forecasting is critical for enhancing the efficiency and\nresponsiveness of food delivery platforms, where spatial heterogeneity and\ntemporal fluctuations in order volumes directly influence operational\ndecisions. This paper proposes an attention-based Graph Neural Network\nframework that captures spatial-temporal dependencies by modeling the food\ndelivery environment as a graph. In this graph, nodes represent urban delivery\nzones, while edges reflect spatial proximity and inter-regional order flow\npatterns derived from historical data. The attention mechanism dynamically\nweighs the influence of neighboring zones, enabling the model to focus on the\nmost contextually relevant areas during prediction. Temporal trends are jointly\nlearned alongside spatial interactions, allowing the model to adapt to evolving\ndemand patterns. Extensive experiments on real-world food delivery datasets\ndemonstrate the superiority of the proposed model in forecasting future order\nvolumes with high accuracy. The framework offers a scalable and adaptive\nsolution to support proactive fleet positioning, resource allocation, and\ndispatch optimization in urban food delivery operations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15246v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15094", "title": "BleedOrigin: Dynamic Bleeding Source Localization in Endoscopic Submucosal Dissection via Dual-Stage Detection and Tracking", "authors": ["Mengya Xu", "Rulin Zhou", "An Wang", "Chaoyang Lyu", "Zhen Li", "Ning Zhong", "Hongliang Ren"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      27 pages, 14 figures", "url": "http://arxiv.org/abs/2507.15094v1", "summary": "Intraoperative bleeding during Endoscopic Submucosal Dissection (ESD) poses\nsignificant risks, demanding precise, real-time localization and continuous\nmonitoring of the bleeding source for effective hemostatic intervention. In\nparticular, endoscopists have to repeatedly flush to clear blood, allowing only\nmilliseconds to identify bleeding sources, an inefficient process that prolongs\noperations and elevates patient risks. However, current Artificial Intelligence\n(AI) methods primarily focus on bleeding region segmentation, overlooking the\ncritical need for accurate bleeding source detection and temporal tracking in\nthe challenging ESD environment, which is marked by frequent visual\nobstructions and dynamic scene changes. This gap is widened by the lack of\nspecialized datasets, hindering the development of robust AI-assisted guidance\nsystems. To address these challenges, we introduce BleedOrigin-Bench, the first\ncomprehensive ESD bleeding source dataset, featuring 1,771 expert-annotated\nbleeding sources across 106,222 frames from 44 procedures, supplemented with\n39,755 pseudo-labeled frames. This benchmark covers 8 anatomical sites and 6\nchallenging clinical scenarios. We also present BleedOrigin-Net, a novel\ndual-stage detection-tracking framework for the bleeding source localization in\nESD procedures, addressing the complete workflow from bleeding onset detection\nto continuous spatial tracking. We compare with widely-used object detection\nmodels (YOLOv11/v12), multimodal large language models, and point tracking\nmethods. Extensive evaluation demonstrates state-of-the-art performance,\nachieving 96.85% frame-level accuracy ($\\pm\\leq8$ frames) for bleeding onset\ndetection, 70.24% pixel-level accuracy ($\\leq100$ px) for initial source\ndetection, and 96.11% pixel-level accuracy ($\\leq100$ px) for point tracking.", "comment": "27 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.15094v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15475", "title": "On the Distribution of a Two-Dimensional Random Walk with Restricted Angles", "authors": ["Karl-Ludwig Besser"], "categories": ["eess.SP", "math.PR", "stat.AP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      12 pages, 13 figures", "url": "http://arxiv.org/abs/2507.15475v1", "summary": "In this paper, we derive the distribution of a two-dimensional (complex)\nrandom walk in which the angle of each step is restricted to a subset of the\ncircle. This setting appears in various domains, such as in over-the-air\ncomputation in signal processing. In particular, we derive the exact joint and\nmarginal distributions for two steps, numerical solutions for a general number\nof steps, and approximations for a large number of steps. Furthermore, we\nprovide an exact characterization of the support for an arbitrary number of\nsteps. The results in this work provide a reference for future work involving\nsuch problems.", "comment": "12 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.15475v1", "cate": "eess.SP", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15345", "title": "Exponential Runge-Kutta Galerkin finite element method for a reaction-diffusion system with nonsmooth initial data", "authors": ["Runjie Zhang", "Jinwei Fang", "Shuo Yang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15345v1", "summary": "This study presents a numerical analysis of the Field-Noyes\nreaction-diffusion model with nonsmooth initial data, employing a linear\nGalerkin finite element method for spatial discretization and a second-order\nexponential Runge-Kutta scheme for temporal integration. The initial data are\nassumed to reside in the fractional Sobolev space H^gamma with 0 < gamma < 2,\nwhere classical regularity conditions are violated, necessitating specialized\nerror analysis. By integrating semigroup techniques and fractional Sobolev\nspace theory, sharp fully discrete error estimates are derived in both L2 and\nH1 norms. This demonstrates that the convergence order adapts to the smoothness\nof initial data, a key advancement over traditional approaches that assume\nhigher regularity. Numerical examples are provided to support the theoretical\nanalysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15345v1", "cate": "math.NA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15349", "title": "Scaling Decentralized Learning with FLock", "authors": ["Zehua Cheng", "Rui Sun", "Jiahao Sun", "Yike Guo"], "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15349v1", "summary": "Fine-tuning the large language models (LLMs) are prevented by the deficiency\nof centralized control and the massive computing and communication overhead on\nthe decentralized schemes. While the typical standard federated learning (FL)\nsupports data privacy, the central server requirement creates a single point of\nattack and vulnerability to poisoning attacks. Generalizing the result in this\ndirection to 70B-parameter models in the heterogeneous, trustless environments\nhas turned out to be a huge, yet unbroken bottleneck. This paper introduces\nFLock, a decentralized framework for secure and efficient collaborative LLM\nfine-tuning. Integrating a blockchain-based trust layer with economic\nincentives, FLock replaces the central aggregator with a secure, auditable\nprotocol for cooperation among untrusted parties. We present the first\nempirical validation of fine-tuning a 70B LLM in a secure, multi-domain,\ndecentralized setting. Our experiments show the FLock framework defends against\nbackdoor poisoning attacks that compromise standard FL optimizers and fosters\nsynergistic knowledge transfer. The resulting models show a >68% reduction in\nadversarial attack success rates. The global model also demonstrates superior\ncross-domain generalization, outperforming models trained in isolation on their\nown specialized data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15349v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15299", "title": "An Overview of the Risk-based Model of AI Governance", "authors": ["Veve Fry"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      20 pages, undergraduate research work supervised and graded by Dr. Kathryn Henne, School of Regulation and Global Governance, The Australian National University", "url": "http://arxiv.org/abs/2507.15299v1", "summary": "This paper provides an overview and critique of the risk based model of\nartificial intelligence (AI) governance that has become a popular approach to\nAI regulation across multiple jurisdictions. The 'AI Policy Landscape in\nEurope, North America and Australia' section summarises the existing AI policy\nefforts across these jurisdictions, with a focus of the EU AI Act and the\nAustralian Department of Industry, Science and Regulation's (DISR) safe and\nresponsible AI consultation. The 'Analysis' section of this paper proposes\nseveral criticisms of the risk based approach to AI governance, arguing that\nthe construction and calculation of risks that they use reproduces existing\ninequalities. Drawing on the work of Julia Black, it argues that risk and harm\nshould be distinguished clearly and that the notion of risk is problematic as\nits inherent normativity reproduces dominant and harmful narratives about whose\ninterests matter, and risk categorizations should be subject to deep scrutiny.\nThis paper concludes with the suggestion that existing risk governance\nscholarship can provide valuable insights toward the improvement of the risk\nbased AI governance, and that the use of multiple regulatory implements and\nresponsive risk regulation should be considered in the continuing development\nof the model.", "comment": "20 pages, undergraduate research work supervised and graded by Dr.\n  Kathryn Henne, School of Regulation and Global Governance, The Australian\n  National University", "pdf_url": "http://arxiv.org/pdf/2507.15299v1", "cate": "cs.CY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14808", "title": "Transaction Profiling and Address Role Inference in Tokenized U.S. Treasuries", "authors": ["Junliang Luo", "Katrin Tinn", "Samuel Ferreira Duran", "Di Wu", "Xue Liu"], "categories": ["q-fin.CP", "cs.CE", "cs.LG"], "primary_category": "Subjects:       Computational Finance (q-fin.CP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14808v1", "summary": "Tokenized U.S. Treasuries have emerged as a prominent subclass of real-world\nassets (RWAs), offering cryptographically enforced, yield-bearing instruments\ncollateralized by sovereign debt and deployed across multiple blockchain\nnetworks. While the market has expanded rapidly, empirical analyses of\ntransaction-level behaviour remain limited. This paper conducts a quantitative,\nfunction-level dissection of U.S. Treasury-backed RWA tokens including BUIDL,\nBENJI, and USDY, across multi-chain: mostly Ethereum and Layer-2s. We analyze\ndecoded contract calls to isolate core functional primitives such as issuance,\nredemption, transfer, and bridge activity, revealing segmentation in behaviour\nbetween institutional actors and retail users. To model address-level economic\nroles, we introduce a curvature-aware representation learning framework using\nPoincar\\'e embeddings and liquidity-based graph features. Our method\noutperforms baseline models on our RWA Treasury dataset in role inference and\ngeneralizes to downstream tasks such as anomaly detection and wallet\nclassification in broader blockchain transaction networks. These findings\nprovide a structured understanding of functional heterogeneity and participant\nroles in tokenized Treasury in a transaction-level perspective, contributing\nnew empirical evidence to the study of on-chain financialization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14808v1", "cate": "q-fin.CP", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14385", "title": "Bi-level Model Predictive Control for Energy-aware Integrated Product Pricing and Production Scheduling", "authors": ["Hongliang Li", "Herschel C. Pangborn", "Ilya Kovalenko"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14385v1", "summary": "The manufacturing industry is under growing pressure to enhance\nsustainability while preserving economic competitiveness. As a result,\nmanufacturers have been trying to determine how to integrate onsite renewable\nenergy and real-time electricity pricing into manufacturing schedules without\ncompromising profitability. To address this challenge, we propose a bi-level\nmodel predictive control framework that jointly optimizes product prices and\nproduction scheduling with explicit consideration of renewable energy\navailability. The higher level determines the product price to maximize revenue\nand renewable energy usage. The lower level controls production scheduling in\nruntime to minimize operational costs and respond to the product demand. Price\nelasticity is incorporated to model market response, allowing the system to\nincrease demand by lowering the product price during high renewable energy\ngeneration. Results from a lithium-ion battery pack manufacturing system case\nstudy demonstrate that our approach enables manufacturers to reduce grid energy\ncosts while increasing profit.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14385v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2503.14537", "title": "Learning-based 3D Reconstruction in Autonomous Driving: A Comprehensive Survey", "authors": ["Liewen Liao", "Weihao Yan", "Ming Yang", "Songan Zhang"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.14537v4", "summary": "Learning-based 3D reconstruction has emerged as a transformative technique in\nautonomous driving, enabling precise modeling of both dynamic and static\nenvironments through advanced neural representations. Despite data\naugmentation, 3D reconstruction inspires pioneering solution for vital tasks in\nthe field of autonomous driving, such as scene understanding and closed-loop\nsimulation. We investigates the details of 3D reconstruction and conducts a\nmulti-perspective, in-depth analysis of recent advancements. Specifically, we\nfirst provide a systematic introduction of preliminaries, including data\nmodalities, benchmarks and technical preliminaries of learning-based 3D\nreconstruction, facilitating instant identification of suitable methods\naccording to sensor suites. Then, we systematically review learning-based 3D\nreconstruction methods in autonomous driving, categorizing approaches by\nsubtasks and conducting multi-dimensional analysis and summary to establish a\ncomprehensive technical reference. The development trends and existing\nchallenges are summarized in the context of learning-based 3D reconstruction in\nautonomous driving. We hope that our review will inspire future researches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.14537v4", "cate": "cs.CV", "date": "2025-03-17", "updated": "2025-07-20"}
{"id": "2507.14901", "title": "Learning Nonlinear Causal Reductions to Explain Reinforcement Learning Policies", "authors": ["Armin Kekić", "Jan Schneider", "Dieter Büchler", "Bernhard Schölkopf", "Michel Besserve"], "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14901v1", "summary": "Why do reinforcement learning (RL) policies fail or succeed? This is a\nchallenging question due to the complex, high-dimensional nature of\nagent-environment interactions. In this work, we take a causal perspective on\nexplaining the behavior of RL policies by viewing the states, actions, and\nrewards as variables in a low-level causal model. We introduce random\nperturbations to policy actions during execution and observe their effects on\nthe cumulative reward, learning a simplified high-level causal model that\nexplains these relationships. To this end, we develop a nonlinear Causal Model\nReduction framework that ensures approximate interventional consistency,\nmeaning the simplified high-level model responds to interventions in a similar\nway as the original complex system. We prove that for a class of nonlinear\ncausal models, there exists a unique solution that achieves exact\ninterventional consistency, ensuring learned explanations reflect meaningful\ncausal patterns. Experiments on both synthetic causal models and practical RL\ntasks-including pendulum control and robot table tennis-demonstrate that our\napproach can uncover important behavioral patterns, biases, and failure modes\nin trained RL policies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14901v1", "cate": "stat.ML", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15260", "title": "CHORDS: Diffusion Sampling Accelerator with Multi-core Hierarchical ODE Solvers", "authors": ["Jiaqi Han", "Haotian Ye", "Puheng Li", "Minkai Xu", "James Zou", "Stefano Ermon"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.15260v1", "summary": "Diffusion-based generative models have become dominant generators of\nhigh-fidelity images and videos but remain limited by their computationally\nexpensive inference procedures. Existing acceleration techniques either require\nextensive model retraining or compromise significantly on sample quality. This\npaper explores a general, training-free, and model-agnostic acceleration\nstrategy via multi-core parallelism. Our framework views multi-core diffusion\nsampling as an ODE solver pipeline, where slower yet accurate solvers\nprogressively rectify faster solvers through a theoretically justified\ninter-core communication mechanism. This motivates our multi-core training-free\ndiffusion sampling accelerator, CHORDS, which is compatible with various\ndiffusion samplers, model architectures, and modalities. Through extensive\nexperiments, CHORDS significantly accelerates sampling across diverse\nlarge-scale image and video diffusion models, yielding up to 2.1x speedup with\nfour cores, improving by 50% over baselines, and 2.9x speedup with eight cores,\nall without quality degradation. This advancement enables CHORDS to establish a\nsolid foundation for real-time, high-fidelity diffusion generation.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.15260v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15109", "title": "LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM", "authors": ["Mohammad-Maher Nakshbandi", "Ziad Sharawy", "Sorin Grigorescu"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15109v1", "summary": "One of the main challenges in the Simultaneous Localization and Mapping\n(SLAM) loop closure problem is the recognition of previously visited places. In\nthis work, we tackle the two main problems of real-time SLAM systems: 1) loop\nclosure detection accuracy and 2) real-time computation constraints on the\nembedded hardware. Our LoopNet method is based on a multitasking variant of the\nclassical ResNet architecture, adapted for online retraining on a dynamic\nvisual dataset and optimized for embedded devices. The online retraining is\ndesigned using a few-shot learning approach. The architecture provides both an\nindex into the queried visual dataset, and a measurement of the prediction\nquality. Moreover, by leveraging DISK (DIStinctive Keypoints) descriptors,\nLoopNet surpasses the limitations of handcrafted features and traditional deep\nlearning methods, offering better performance under varying conditions. Code is\navailable at https://github.com/RovisLab/LoopNet. Additinally, we introduce a\nnew loop closure benchmarking dataset, coined LoopDB, which is available at\nhttps://github.com/RovisLab/LoopDB.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15109v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15555", "title": "Sum-Rate Maximization for Movable-Antenna Array Enhanced Downlink NOMA Systems", "authors": ["Nianzu Li", "Peiran Wu", "Lipeng Zhu", "Weidong Mei", "Boyu Ning", "Derrick Wing Kwan Ng"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15555v1", "summary": "Movable antenna (MA) systems have recently attracted significant attention in\nthe field of wireless communications owing to their exceptional capability to\nproactively reconfigure wireless channels via flexible antenna movements. In\nthis paper, we investigate the resource allocation design for an MA\narray-enhanced downlink non-orthogonal multiple access (NOMA) system, where a\nbase station deploys multiple MAs to serve multiple single-antenna users. Our\ngoal is to maximize the sum rate of all users by jointly optimizing the\ntransmit beamforming, positions of MAs, successive interference cancellation\n(SIC) decoding order, and users' corresponding decoding indicator matrix, while\nadhering to constraints on the maximum transmit power and finite MA moving\nregion. The formulated problem is inherently highly non-convex, rendering it\nchallenging to acquire a globally optimal solution. As a compromise, we propose\na low-complexity two-stage optimization algorithm to obtain an effective\nsuboptimal solution. Specifically, in stage one, the SIC decoding order is\nfirst determined by solving a channel gain maximization problem. Then, in stage\ntwo, with the given SIC decoding order, the beamforming vectors, MA positions,\nand users' decoding indicator matrix are iteratively optimized by capitalizing\non alternating optimization, successive convex approximation (SCA), and genetic\nalgorithm (GA). Simulation results unveil that the sum-rate performance of the\nproposed MA-enabled downlink NOMA system significantly outperforms that of\nconventional fixed-position antenna (FPA) systems. Moreover, the results also\nshow that the antenna position optimization in the proposed algorithm can\nfurther enhance the advantages of NOMA over space division multiple access\n(SDMA).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15555v1", "cate": "eess.SP", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15350", "title": "Superconvergence points of Hermite spectral interpolation", "authors": ["Haiyong Wang", "Zhimin Zhang"], "categories": ["math.NA", "cs.NA", "41A05, 41A25, 65N35, 65D05"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      22 pages", "url": "http://arxiv.org/abs/2507.15350v1", "summary": "Hermite spectral method plays an important role in the numerical simulation\nof various partial differential equations (PDEs) on unbounded domains. In this\nwork, we study the superconvergence properties of Hermite spectral\ninterpolation, i.e., interpolation at the zeros of Hermite polynomials in the\nspace spanned by Hermite functions. We identify the points at which the\nconvergence rates of the first- and second-order derivatives of the interpolant\nconverge faster. We further extend the analysis to the Hermite spectral\ncollocation method in solving differential equations and identify the\nsuperconvergence points both for function and derivative values. Numerical\nexamples are provided to confirm the analysis of superconvergence points.", "comment": "22 pages", "pdf_url": "http://arxiv.org/pdf/2507.15350v1", "cate": "math.NA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.11683", "title": "PGT-I: Scaling Spatiotemporal GNNs with Memory-Efficient Distributed Training", "authors": ["Seth Ockerman", "Amal Gueroudji", "Tanwi Mallick", "Yixuan He", "Line Pouchard", "Robert Ross", "Shivaram Venkataraman"], "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      To be published in the 2025 International Conference for High Performance Computing, Networking, Storage, and Analysis", "url": "http://arxiv.org/abs/2507.11683v2", "summary": "Spatiotemporal graph neural networks (ST-GNNs) are powerful tools for\nmodeling spatial and temporal data dependencies. However, their applications\nhave been limited primarily to small-scale datasets because of memory\nconstraints. While distributed training offers a solution, current frameworks\nlack support for spatiotemporal models and overlook the properties of\nspatiotemporal data. Informed by a scaling study on a large-scale workload, we\npresent PyTorch Geometric Temporal Index (PGT-I), an extension to PyTorch\nGeometric Temporal that integrates distributed data parallel training and two\nnovel strategies: index-batching and distributed-index-batching. Our index\ntechniques exploit spatiotemporal structure to construct snapshots dynamically\nat runtime, significantly reducing memory overhead, while\ndistributed-index-batching extends this approach by enabling scalable\nprocessing across multiple GPUs. Our techniques enable the first-ever training\nof an ST-GNN on the entire PeMS dataset without graph partitioning, reducing\npeak memory usage by up to 89% and achieving up to a 11.78x speedup over\nstandard DDP with 128 GPUs.", "comment": "To be published in the 2025 International Conference for High\n  Performance Computing, Networking, Storage, and Analysis", "pdf_url": "http://arxiv.org/pdf/2507.11683v2", "cate": "cs.DC", "date": "2025-07-15", "updated": "2025-07-20"}
{"id": "2507.15379", "title": "Exploring the Use of Predictive Analytics by Austrian Tax Authorities: A Qualitative Study within the Task-Technology Fit Model", "authors": ["Simon Staudinger", "Christoph G. Schuetz", "Marina Luketina"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      20 pages, 3 figures, 1 table. A short version of this paper was presented at the 1st India Conference on Information Systems (INCIS), held from March 7-9, 2025 at IIM Calcutta, Kolkata, India", "url": "http://arxiv.org/abs/2507.15379v1", "summary": "Taxes finance important government services that are now taken for granted in\nour society, such as infrastructure, health care, or retirement pensions. Tax\nauthorities everywhere strive to ensure that all individuals and organizations\ncomply with applicable tax laws. In this regard, tax authorities must prevent\nindividuals and organizations from evading taxes in an illegal manner. To this\nend, Austrian tax authorities employ state-of-the-art predictive analytics\ntechnology for the selection of suspicious cases for tax audits, thus making\nefficient use of scarce resources for tax auditing. In this paper, we explore\nhow Austrian tax authorities employ predictive analytics technology in tax\nauditing and how well the use of such technology fits the characteristics of\nthe task at hand. We collaborated with the Austrian Federal Ministry of\nFinance's Predictive Analytics Competence Center to obtain insights into the\napplication of predictive analytics technology by Austrian tax authorities. The\nthus obtained insights serve as the basis for a qualitative analysis in the\ncontext of the task-technology fit framework.", "comment": "20 pages, 3 figures, 1 table. A short version of this paper was\n  presented at the 1st India Conference on Information Systems (INCIS), held\n  from March 7-9, 2025 at IIM Calcutta, Kolkata, India", "pdf_url": "http://arxiv.org/pdf/2507.15379v1", "cate": "cs.CY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15813", "title": "Hyperelastic nature of the Hoek-Brown criterion", "authors": ["Ilaria Fontana", "Goustan Bacquaert", "Daniele A. Di Pietro", "Kyrylo Kazymyrenko"], "categories": ["physics.app-ph", "cs.CE", "physics.class-ph"], "primary_category": "Subjects:       Applied Physics (physics.app-ph)", "pdf_link": null, "comments": "Comments:      Accepted for publication in European Journal of Mechanics - A/Solids", "url": "http://arxiv.org/abs/2507.15813v1", "summary": "We propose a nonlinear elasto-plastic model, for which a specific class of\nhyperbolic elasticity arises as a straight consequence of the yield criterion\ninvariance on the plasticity level. We superimpose this nonlinear elastic (or\nhyperelastic) behavior with plasticity obeying the associated flow rule.\nInterestingly, we find that a linear yield criterion on the thermodynamical\nforce associated with plasticity results in a quadratic yield criterion in the\nstress space. This suggests a specific hyperelastic connection between\nMohr-Coulomb and Hoek-Brown (or alternatively between Drucker-Prager and\nPan-Hudson) yield criteria. We compare the elasto-plastic responses of standard\ntests for the Drucker-Prager yield criterion using either linear or the\nsuggested hyperbolic elasticity. Notably, the nonlinear case stands out due to\ndilatancy saturation observed during cyclic loading in the triaxial compression\ntest. We conclude this study with structural finite element simulations that\nclearly demonstrate the numerical applicability of the proposed model.", "comment": "Accepted for publication in European Journal of Mechanics - A/Solids", "pdf_url": "http://arxiv.org/pdf/2507.15813v1", "cate": "physics.app-ph", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14409", "title": "Collaborative Indirect Influencing and Control on Graphs using Graph Neural Networks", "authors": ["Max L. Gardenswartz", "Brandon C. Fallin", "Cristian F. Nino", "Warren E. Dixon"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      arXiv admin note: substantial text overlap with arXiv:2503.15360", "url": "http://arxiv.org/abs/2507.14409v1", "summary": "This paper presents a novel approach to solving the indirect influence\nproblem in networked systems, in which cooperative nodes must regulate a target\nnode with uncertain dynamics to follow a desired trajectory. We leverage the\nmessage-passing structure of a graph neural network (GNN), allowing nodes to\ncollectively learn the unknown target dynamics in real time. We develop a novel\nGNN-based backstepping control strategy with formal stability guarantees\nderived from a Lyapunov-based analysis. Numerical simulations are included to\ndemonstrate the performance of the developed controller.", "comment": "arXiv admin note: substantial text overlap with arXiv:2503.15360", "pdf_url": "http://arxiv.org/pdf/2507.14409v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2503.19457", "title": "G-DexGrasp: Generalizable Dexterous Grasping Synthesis Via Part-Aware Prior Retrieval and Prior-Assisted Generation", "authors": ["Juntao Jian", "Xiuping Liu", "Zixuan Chen", "Manyi Li", "Jian Liu", "Ruizhen Hu"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2503.19457v2", "summary": "Recent advances in dexterous grasping synthesis have demonstrated significant\nprogress in producing reasonable and plausible grasps for many task purposes.\nBut it remains challenging to generalize to unseen object categories and\ndiverse task instructions. In this paper, we propose G-DexGrasp, a\nretrieval-augmented generation approach that can produce high-quality dexterous\nhand configurations for unseen object categories and language-based task\ninstructions. The key is to retrieve generalizable grasping priors, including\nthe fine-grained contact part and the affordance-related distribution of\nrelevant grasping instances, for the following synthesis pipeline.\nSpecifically, the fine-grained contact part and affordance act as generalizable\nguidance to infer reasonable grasping configurations for unseen objects with a\ngenerative model, while the relevant grasping distribution plays as\nregularization to guarantee the plausibility of synthesized grasps during the\nsubsequent refinement optimization. Our comparison experiments validate the\neffectiveness of our key designs for generalization and demonstrate the\nremarkable performance against the existing approaches. Project page:\nhttps://g-dexgrasp.github.io/", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.19457v2", "cate": "cs.CV", "date": "2025-03-25", "updated": "2025-07-20"}
{"id": "2507.14908", "title": "Partial Symmetry Enforced Attention Decomposition (PSEAD): A Group-Theoretic Framework for Equivariant Transformers in Biological Systems", "authors": ["Daniel Ayomide Olanrewaju"], "categories": ["math.RT", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Representation Theory (math.RT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14908v1", "summary": "This research introduces the Theory of Partial Symmetry Enforced Attention\nDecomposition (PSEAD), a new and rigorous group-theoretic framework designed to\nseamlessly integrate local symmetry awareness into the core architecture of\nself-attention mechanisms within Transformer models. We formalize the concept\nof local permutation subgroup actions on windows of biological data, proving\nthat under such actions, the attention mechanism naturally decomposes into a\ndirect sum of orthogonal irreducible components. Critically, these components\nare intrinsically aligned with the irreducible representations of the acting\npermutation subgroup, thereby providing a powerful mathematical basis for\ndisentangling symmetric and asymmetric features. We show that PSEAD offers\nsubstantial advantages. These include enhanced generalization capabilities to\nnovel biological motifs exhibiting similar partial symmetries, unprecedented\ninterpretability by allowing direct visualization and analysis of attention\ncontributions from different symmetry channels, and significant computational\nefficiency gains by focusing representational capacity on relevant symmetric\nsubspaces. Beyond static data analysis, we extend PSEAD's applicability to\ndynamic biological processes within reinforcement learning paradigms,\nshowcasing its potential to accelerate the discovery and optimization of\nbiologically meaningful policies in complex environments like protein folding\nand drug discovery. This work lays the groundwork for a new generation of\nbiologically informed, symmetry-aware artificial intelligence models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14908v1", "cate": "math.RT", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15274", "title": "Temporal Basis Function Models for Closed-Loop Neural Stimulation", "authors": ["Matthew J. Bryan", "Felix Schwock", "Azadeh Yazdan-Shahmorad", "Rajesh P N Rao"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15274v1", "summary": "Closed-loop neural stimulation provides novel therapies for neurological\ndiseases such as Parkinson's disease (PD), but it is not yet clear whether\nartificial intelligence (AI) techniques can tailor closed-loop stimulation to\nindividual patients or identify new therapies. Progress requires us to address\na number of translational issues, including sample efficiency, training time,\nand minimizing loop latency such that stimulation may be shaped in response to\nchanging brain activity. We propose temporal basis function models (TBFMs) to\naddress these difficulties, and explore this approach in the context of\nexcitatory optogenetic stimulation. We demonstrate the ability of TBF models to\nprovide a single-trial, spatiotemporal forward prediction of the effect of\noptogenetic stimulation on local field potentials (LFPs) measured in two\nnon-human primates. We further use simulations to demonstrate the use of TBF\nmodels for closed-loop stimulation, driving neural activity towards target\npatterns. The simplicity of TBF models allow them to be sample efficient, rapid\nto train (2-4min), and low latency (0.2ms) on desktop CPUs. We demonstrate the\nmodel on 40 sessions of previously published excitatory optogenetic stimulation\ndata. For each session, the model required 15-20min of data collection to\nsuccessfully model the remainder of the session. It achieved a prediction\naccuracy comparable to a baseline nonlinear dynamical systems model that\nrequires hours to train, and superior accuracy to a linear state-space model.\nIn our simulations, it also successfully allowed a closed-loop stimulator to\ncontrol a neural circuit. Our approach begins to bridge the translational gap\nbetween complex AI-based approaches to modeling dynamical systems and the\nvision of using such forward prediction models to develop novel, clinically\nuseful closed-loop stimulation protocols.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15274v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15130", "title": "Enhancing Visual Planning with Auxiliary Tasks and Multi-token Prediction", "authors": ["Ce Zhang", "Yale Song", "Ruta Desai", "Michael Louis Iuzzolino", "Joseph Tighe", "Gedas Bertasius", "Satwik Kottur"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15130v1", "summary": "Visual Planning for Assistance (VPA) aims to predict a sequence of user\nactions required to achieve a specified goal based on a video showing the\nuser's progress. Although recent advances in multimodal large language models\n(MLLMs) have shown promising results in video understanding, long-horizon\nvisual planning remains a challenging problem. We identify two challenges in\ntraining large MLLMs for video-based planning tasks: (1) scarcity of procedural\nannotations, limiting the model's ability to learn procedural task dynamics\neffectively, and (2) inefficiency of next-token prediction objective to\nexplicitly capture the structured action space for visual planning when\ncompared to free-form, natural language. To tackle data scarcity, we introduce\nAuxiliary Task Augmentation. We design and train our model on auxiliary tasks\nrelevant to long-horizon video-based planning (e.g., goal prediction) to\naugment the model's planning ability. To more explicitly model the structured\naction space unique to visual planning tasks, we leverage Multi-token\nPrediction, extending traditional next-token prediction by using multiple heads\nto predict multiple future tokens during training. Our approach, VideoPlan,\nachieves state-of-the-art VPA performance on the COIN and CrossTask datasets,\nsurpassing prior methods by 7.3% and 3.4%, respectively, when predicting 3\nfuture actions. We further extend our method to the challenging Ego4D Long-term\nAction Anticipation task, and show that it is on par with the state-of-the-art\napproaches despite not using specialized egocentric features. Code will be made\navailable.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15130v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15386", "title": "Learning to Gridize: Segment Physical World by Wireless Communication Channel", "authors": ["Juntao Wang", "Feng Yin", "Tian Ding", "Tsung-Hui Chang", "Zhi-Quan Luo", "Qi Yan"], "categories": ["cs.LG", "eess.SP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15386v1", "summary": "Gridization, the process of partitioning space into grids where users share\nsimilar channel characteristics, serves as a fundamental prerequisite for\nefficient large-scale network optimization. However, existing methods like\nGeographical or Beam Space Gridization (GSG or BSG) are limited by reliance on\nunavailable location data or the flawed assumption that similar signal\nstrengths imply similar channel properties. We propose Channel Space\nGridization (CSG), a pioneering framework that unifies channel estimation and\ngridization for the first time. Formulated as a joint optimization problem, CSG\nuses only beam-level reference signal received power (RSRP) to estimate Channel\nAngle Power Spectra (CAPS) and partition samples into grids with homogeneous\nchannel characteristics. To perform CSG, we develop the CSG Autoencoder\n(CSG-AE), featuring a trainable RSRP-to-CAPS encoder, a learnable sparse\ncodebook quantizer, and a physics-informed decoder based on the Localized\nStatistical Channel Model. On recognizing the limitations of naive training\nscheme, we propose a novel Pretraining-Initialization-Detached-Asynchronous\n(PIDA) training scheme for CSG-AE, ensuring stable and effective training by\nsystematically addressing the common pitfalls of the naive training paradigm.\nEvaluations reveal that CSG-AE excels in CAPS estimation accuracy and\nclustering quality on synthetic data. On real-world datasets, it reduces Active\nMean Absolute Error (MAE) by 30\\% and Overall MAE by 65\\% on RSRP prediction\naccuracy compared to salient baselines using the same data, while improving\nchannel consistency, cluster sizes balance, and active ratio, advancing the\ndevelopment of gridization for large-scale network optimization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15386v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15409", "title": "PDEformer-2: A Versatile Foundation Model for Two-Dimensional Partial Differential Equations", "authors": ["Zhanhong Ye", "Zining Liu", "Bingyang Wu", "Hongjie Jiang", "Leheng Chen", "Minyan Zhang", "Xiang Huang", "Qinghe Meng. Jingyuan Zou", "Hongsheng Liu", "Bin Dong"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15409v1", "summary": "Partial differential equations (PDEs) play a central role in describing many\nphysical phenomena. Various scientific and engineering applications demand a\nversatile and differentiable PDE solver that can quickly generate solutions\nwith adequate accuracy, and limitations of the traditional solvers and\nspecialized neural operators motivate the development of foundation models for\nsolving PDEs. This paper introduces PDEformer-2, a versatile foundation model\nfor two-dimensional PDEs. Based on our previous one-dimensional PDEformer-1\nmodel, PDEformer-2 receives the PDE form as network input via computational\ngraph representation, which has the flexibility to encode most common PDEs. The\nmesh-free predicted solutions can be directly queried at arbitrary\nspatio-temporal coordinates. A large (40TB) diverse dataset is employed to\npretrain the current model, making it capable of simultaneously addressing PDEs\nwith different symbolic forms, domain shapes, boundary conditions, number of\nvariables, and time-dependency. Accurate zero-shot prediction is allowed for\nPDEs that resemble the pretraining ones. When adapted to new unseen PDEs,\nPDEformer-2 demonstrates faster learning than many specialized models, and has\nsmaller errors given limited (less than 100) samples. Additionally, PDEformer-2\ncan be employed in the inverse problems thanks to its fast and differentiable\nnature and produces reasonable results in our experiments to recover\ncoefficient scalars and fields of a PDE.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15409v1", "cate": "math.NA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2409.18749", "title": "TensorSocket: Shared Data Loading for Deep Learning Training", "authors": ["Ties Robroek", "Neil Kim Nielsen", "Pınar Tözün"], "categories": ["cs.LG", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.18749v3", "summary": "Training deep learning models is a repetitive and resource-intensive process.\nData scientists often train several models before landing on a set of\nparameters (e.g., hyper-parameter tuning) and model architecture (e.g., neural\narchitecture search), among other things that yield the highest accuracy. The\ncomputational efficiency of these training tasks depends highly on how well the\ntraining data is supplied to the training process. The repetitive nature of\nthese tasks results in the same data processing pipelines running over and\nover, exacerbating the need for and costs of computational resources. In this\npaper, we present TensorSocket to reduce the computational needs of deep\nlearning training by enabling simultaneous training processes to share the same\ndata loader. TensorSocket mitigates CPU-side bottlenecks in cases where the\ncollocated training workloads have high throughput on GPU, but are held back by\nlower data-loading throughput on CPU. TensorSocket achieves this by reducing\nredundant computations and data duplication across collocated training\nprocesses and leveraging modern GPU-GPU interconnects. While doing so,\nTensorSocket is able to train and balance differently-sized models and serve\nmultiple batch sizes simultaneously and is hardware- and pipeline-agnostic in\nnature. Our evaluation shows that TensorSocket enables scenarios that are\ninfeasible without data sharing, increases training throughput by up to 100%,\nand when utilizing cloud instances, achieves cost savings of 50% by reducing\nthe hardware resource needs on the CPU side. Furthermore, TensorSocket\noutperforms the state-of-the-art solutions for shared data loading such as\nCoorDL and Joader; it is easier to deploy and maintain and either achieves\nhigher or matches their throughput while requiring fewer CPU resources.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.18749v3", "cate": "cs.LG", "date": "2024-09-27", "updated": "2025-07-21"}
{"id": "2507.15585", "title": "Unequal Voices: How LLMs Construct Constrained Queer Narratives", "authors": ["Atreya Ghosal", "Ashim Gupta", "Vivek Srikumar"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15585v1", "summary": "One way social groups are marginalized in discourse is that the narratives\ntold about them often default to a narrow, stereotyped range of topics. In\ncontrast, default groups are allowed the full complexity of human existence. We\ndescribe the constrained representations of queer people in LLM generations in\nterms of harmful representations, narrow representations, and discursive\nothering and formulate hypotheses to test for these phenomena. Our results show\nthat LLMs are significantly limited in their portrayals of queer personas.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15585v1", "cate": "cs.CY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14450", "title": "A Black Start Strategy for Hydrogen-integrated Renewable Grids with Energy Storage Systems", "authors": ["Jin Lu", "Linhan Fang", "Fan Jiang", "Xingpeng Li"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures", "url": "http://arxiv.org/abs/2507.14450v1", "summary": "With the increasing integration of renewable energy, the reliability and\nresilience of modern power systems are of vital significance. However,\nlarge-scale blackouts caused by natural disasters or equipment failures remain\na significant threat, necessitating effective restoration strategies. This\nstudy proposes novel black start models for modern power systems that integrate\nfuel cells and battery storage, recognizing their distinct characteristics and\ncontributions to grid resilience. These models specifically address the\nrestoration of electrical grids, including the energization paths and time of\nthe transmission network, while accounting for the unique power output traits\nof fuel cells and the energy storage capacity of batteries as black start\nresources. Black start simulations, comparing the generator startup sequence\n(GSUS) with fuel cell versus battery systems, are performed on the IEEE 39-bus\nsystem. We conduct sensitivity analyses on fuel cell capacity, battery storage\ncapacity, initial state of charge (SOC), and resource locations to identify\noptimal scenarios for black start operations.", "comment": "6 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.14450v1", "cate": "eess.SY", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14595", "title": "Learning-Augmented Control: Adaptively Confidence Learning for Competitive MPC", "authors": ["Tongxin Li"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      13 pages, 4 figures", "url": "http://arxiv.org/abs/2507.14595v1", "summary": "We introduce Learning-Augmented Control (LAC), an approach that integrates\nuntrusted machine learning predictions into the control of constrained,\nnonlinear dynamical systems. LAC is designed to achieve the\n\"best-of-both-worlds\" guarantees, i.e, near-optimal performance when\npredictions are accurate, and robust, safe performance when they are not. The\ncore of our approach is a delayed confidence learning procedure that optimizes\na confidence parameter online, adaptively balancing between ML and nominal\npredictions. We establish formal competitive ratio bounds for general nonlinear\nsystems under standard MPC regularity assumptions. For the linear quadratic\ncase, we derive a competitive ratio bound that is provably tight, thereby\ncharacterizing the fundamental limits of this learning-augmented approach. The\neffectiveness of LAC is demonstrated in numerical studies, where it maintains\nstability and outperforms standard methods under adversarial prediction errors.", "comment": "13 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.14595v1", "cate": "eess.SY", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2506.12251", "title": "Efficient Multi-Camera Tokenization with Triplanes for End-to-End Driving", "authors": ["Boris Ivanovic", "Cristiano Saltori", "Yurong You", "Yan Wang", "Wenjie Luo", "Marco Pavone"], "categories": ["cs.CV", "cs.LG", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      12 pages, 10 figures, 5 tables", "url": "http://arxiv.org/abs/2506.12251v2", "summary": "Autoregressive Transformers are increasingly being deployed as end-to-end\nrobot and autonomous vehicle (AV) policy architectures, owing to their\nscalability and potential to leverage internet-scale pretraining for\ngeneralization. Accordingly, tokenizing sensor data efficiently is paramount to\nensuring the real-time feasibility of such architectures on embedded hardware.\nTo this end, we present an efficient triplane-based multi-camera tokenization\nstrategy that leverages recent advances in 3D neural reconstruction and\nrendering to produce sensor tokens that are agnostic to the number of input\ncameras and their resolution, while explicitly accounting for their geometry\naround an AV. Experiments on a large-scale AV dataset and state-of-the-art\nneural simulator demonstrate that our approach yields significant savings over\ncurrent image patch-based tokenization strategies, producing up to 72% fewer\ntokens, resulting in up to 50% faster policy inference while achieving the same\nopen-loop motion planning accuracy and improved offroad rates in closed-loop\ndriving simulations.", "comment": "12 pages, 10 figures, 5 tables", "pdf_url": "http://arxiv.org/pdf/2506.12251v2", "cate": "cs.CV", "date": "2025-06-13", "updated": "2025-07-21"}
{"id": "2507.14960", "title": "A Comparative Analysis of Statistical and Machine Learning Models for Outlier Detection in Bitcoin Limit Order Books", "authors": ["Ivan Letteri"], "categories": ["q-fin.TR", "cs.AI", "cs.LG", "math.ST", "stat.TH"], "primary_category": "Subjects:       Trading and Market Microstructure (q-fin.TR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14960v1", "summary": "The detection of outliers within cryptocurrency limit order books (LOBs) is\nof paramount importance for comprehending market dynamics, particularly in\nhighly volatile and nascent regulatory environments. This study conducts a\ncomprehensive comparative analysis of robust statistical methods and advanced\nmachine learning techniques for real-time anomaly identification in\ncryptocurrency LOBs. Within a unified testing environment, named AITA Order\nBook Signal (AITA-OBS), we evaluate the efficacy of thirteen diverse models to\nidentify which approaches are most suitable for detecting potentially\nmanipulative trading behaviours. An empirical evaluation, conducted via\nbacktesting on a dataset of 26,204 records from a major exchange, demonstrates\nthat the top-performing model, Empirical Covariance (EC), achieves a 6.70%\ngain, significantly outperforming a standard Buy-and-Hold benchmark. These\nfindings underscore the effectiveness of outlier-driven strategies and provide\ninsights into the trade-offs between model complexity, trade frequency, and\nperformance. This study contributes to the growing corpus of research on\ncryptocurrency market microstructure by furnishing a rigorous benchmark of\nanomaly detection models and highlighting their potential for augmenting\nalgorithmic trading and risk management.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14960v1", "cate": "q-fin.TR", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15280", "title": "Machine Unlearning for Streaming Forgetting", "authors": ["Shaofei Shen", "Chenhao Zhang", "Yawen Zhao", "Alina Bialkowski", "Weitong Chen", "Miao Xu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15280v1", "summary": "Machine unlearning aims to remove knowledge of the specific training data in\na well-trained model. Currently, machine unlearning methods typically handle\nall forgetting data in a single batch, removing the corresponding knowledge all\nat once upon request. However, in practical scenarios, requests for data\nremoval often arise in a streaming manner rather than in a single batch,\nleading to reduced efficiency and effectiveness in existing methods. Such\nchallenges of streaming forgetting have not been the focus of much research. In\nthis paper, to address the challenges of performance maintenance, efficiency,\nand data access brought about by streaming unlearning requests, we introduce a\nstreaming unlearning paradigm, formalizing the unlearning as a distribution\nshift problem. We then estimate the altered distribution and propose a novel\nstreaming unlearning algorithm to achieve efficient streaming forgetting\nwithout requiring access to the original training data. Theoretical analyses\nconfirm an $O(\\sqrt{T} + V_T)$ error bound on the streaming unlearning regret,\nwhere $V_T$ represents the cumulative total variation in the optimal solution\nover $T$ learning rounds. This theoretical guarantee is achieved under mild\nconditions without the strong restriction of convex loss function. Experiments\nacross various models and datasets validate the performance of our proposed\nmethod.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15280v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15150", "title": "Event-based Graph Representation with Spatial and Motion Vectors for Asynchronous Object Detection", "authors": ["Aayush Atul Verma", "Arpitsinh Vaghela", "Bharatesh Chakravarthi", "Kaustav Chanda", "Yezhou Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15150v1", "summary": "Event-based sensors offer high temporal resolution and low latency by\ngenerating sparse, asynchronous data. However, converting this irregular data\ninto dense tensors for use in standard neural networks diminishes these\ninherent advantages, motivating research into graph representations. While such\nmethods preserve sparsity and support asynchronous inference, their performance\non downstream tasks remains limited due to suboptimal modeling of\nspatiotemporal dynamics. In this work, we propose a novel spatiotemporal\nmultigraph representation to better capture spatial structure and temporal\nchanges. Our approach constructs two decoupled graphs: a spatial graph\nleveraging B-spline basis functions to model global structure, and a temporal\ngraph utilizing motion vector-based attention for local dynamic changes. This\ndesign enables the use of efficient 2D kernels in place of computationally\nexpensive 3D kernels. We evaluate our method on the Gen1 automotive and eTraM\ndatasets for event-based object detection, achieving over a 6% improvement in\ndetection accuracy compared to previous graph-based works, with a 5x speedup,\nreduced parameter count, and no increase in computational cost. These results\nhighlight the effectiveness of structured graph modeling for asynchronous\nvision. Project page: eventbasedvision.github.io/eGSMV.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15150v1", "cate": "cs.CV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15690", "title": "DWTGS: Rethinking Frequency Regularization for Sparse-view 3D Gaussian Splatting", "authors": ["Hung Nguyen", "Runfa Li", "An Le", "Truong Nguyen"], "categories": ["cs.CV", "eess.IV", "eess.SP"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages, 4 figures", "url": "http://arxiv.org/abs/2507.15690v1", "summary": "Sparse-view 3D Gaussian Splatting (3DGS) presents significant challenges in\nreconstructing high-quality novel views, as it often overfits to the\nwidely-varying high-frequency (HF) details of the sparse training views. While\nfrequency regularization can be a promising approach, its typical reliance on\nFourier transforms causes difficult parameter tuning and biases towards\ndetrimental HF learning. We propose DWTGS, a framework that rethinks frequency\nregularization by leveraging wavelet-space losses that provide additional\nspatial supervision. Specifically, we supervise only the low-frequency (LF) LL\nsubbands at multiple DWT levels, while enforcing sparsity on the HF HH subband\nin a self-supervised manner. Experiments across benchmarks show that DWTGS\nconsistently outperforms Fourier-based counterparts, as this LF-centric\nstrategy improves generalization and reduces HF hallucinations.", "comment": "6 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.15690v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15452", "title": "Neural Preconditioning via Krylov Subspace Geometry", "authors": ["Nunzio Dimola", "Alessandro Coclite", "Paolo Zunino"], "categories": ["math.NA", "cs.NA", "65F08, 65F10, 68T07, 65Y20"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15452v1", "summary": "We propose a geometry-aware strategy for training neural preconditioners\ntailored to parametrized linear systems arising from the discretization of\nmixed-dimensional partial differential equations (PDEs). These systems are\ntypically ill-conditioned because of the presence of embedded lower-dimensional\nstructures and are solved using Krylov subspace methods. Our approach yields an\napproximation of the inverse operator employing a learning algorithm consisting\nof a two-stage training framework: an initial static pre-training phase, based\non residual minimization, followed by a dynamic fine-tuning phase that\nincorporates solver convergence dynamics into training via a novel loss\nfunctional. This dynamic loss is defined by the principal angles between the\nresiduals and the Krylov subspaces. It is evaluated using a differentiable\nimplementation of the Flexible GMRES algorithm, which enables backpropagation\nthrough both the Arnoldi process and Givens rotations. The resulting neural\npreconditioner is explicitly optimized to improve early-stage convergence and\nreduce iteration counts in a family of 3D-1D mixed-dimensional problems with\ngeometric variability of the 1D domain. Numerical experiments show that our\nsolver-aligned approach significantly improves convergence rate, robustness,\nand generalization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15452v1", "cate": "math.NA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14111", "title": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning", "authors": ["Xiaoya Li", "Xiaofei Sun", "Albert Wang", "Jiwei Li", "Chris Shum"], "categories": ["cs.AI", "cs.DC", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Project Page: this https URL", "url": "http://arxiv.org/abs/2507.14111v2", "summary": "The exponential growth in demand for GPU computing resources, driven by the\nrapid advancement of Large Language Models, has created an urgent need for\nautomated CUDA optimization strategies. While recent advances in LLMs show\npromise for code generation, current SOTA models (e.g. R1, o1) achieve low\nsuccess rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an\nautomated reinforcement learning framework for CUDA optimization.\n  CUDA-L1 achieves performance improvements on the CUDA optimization task:\ntrained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250\nCUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the\nmodel also demonstrates excellent portability across GPU architectures,\nachieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,\nx14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.\nBeyond these benchmark results, CUDA-L1 demonstrates several remarkable\nproperties: 1) Discovers a variety of CUDA optimization techniques and learns\nto combine them strategically to achieve optimal performance; 2) Uncovers\nfundamental principles of CUDA optimization; 3) Identifies non-obvious\nperformance bottlenecks and rejects seemingly beneficial optimizations that\nharm performance.\n  The capabilities of CUDA-L1 demonstrate that reinforcement learning can\ntransform an initially poor-performing LLM into an effective CUDA optimizer\nthrough speedup-based reward signals alone, without human expertise or domain\nknowledge. More importantly, the trained RL model extend the acquired reasoning\nabilities to new kernels. This paradigm opens possibilities for automated\noptimization of CUDA operations, and holds promise to substantially promote GPU\nefficiency and alleviate the rising pressure on GPU computing resources.", "comment": "Project Page: https://deepreinforce-ai.github.io/cudal1_blog/", "pdf_url": "http://arxiv.org/pdf/2507.14111v2", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-21"}
{"id": "2507.15617", "title": "Why can't Epidemiology be automated (yet)?", "authors": ["David Bann", "Ed Lowther", "Liam Wright", "Yevgeniya Kovalchuk"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      9 pages, 2 figures, 1 table", "url": "http://arxiv.org/abs/2507.15617v1", "summary": "Recent advances in artificial intelligence (AI) - particularly generative AI\n- present new opportunities to accelerate, or even automate, epidemiological\nresearch. Unlike disciplines based on physical experimentation, a sizable\nfraction of Epidemiology relies on secondary data analysis and thus is\nwell-suited for such augmentation. Yet, it remains unclear which specific tasks\ncan benefit from AI interventions or where roadblocks exist. Awareness of\ncurrent AI capabilities is also mixed. Here, we map the landscape of\nepidemiological tasks using existing datasets - from literature review to data\naccess, analysis, writing up, and dissemination - and identify where existing\nAI tools offer efficiency gains. While AI can increase productivity in some\nareas such as coding and administrative tasks, its utility is constrained by\nlimitations of existing AI models (e.g. hallucinations in literature reviews)\nand human systems (e.g. barriers to accessing datasets). Through examples of\nAI-generated epidemiological outputs, including fully AI-generated papers, we\ndemonstrate that recently developed agentic systems can now design and execute\nepidemiological analysis, albeit to varied quality (see\nhttps://github.com/edlowther/automated-epidemiology). Epidemiologists have new\nopportunities to empirically test and benchmark AI systems; realising the\npotential of AI will require two-way engagement between epidemiologists and\nengineers.", "comment": "9 pages, 2 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.15617v1", "cate": "cs.CY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14601", "title": "One-Time Programmable Passive Electromagnetic Skins", "authors": ["Giacomo Oliveri", "Francesco Zardi", "Aaron Angel Salas Sancez", "Andrea Massa"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14601v1", "summary": "The implementation of simple, inexpensive, and mass-production-oriented\nsolutions for smart electromagnetic environments (SEMEs) is dealt with by\nintroducing the concept of \"one-time programmable\" electromagnetic skins\n(OTP-EMSs). The simultaneous achievement of modular fabrication, (one-time)\nconfigurable reflection properties, passive-static operation, and zero\nmaintenance is yielded by integrating expendable components at the atomic level\nof EMSs. Towards this end, an OTP meta-atom structure is properly defined and\noptimized to build EMSs featuring the desired scenario-dependent EM wave\nmanipulation functionalities. In order to illustrate the features as well as to\npoint out the potentialities of OTP-EMSs, a representative set of analytical,\nnumerical, and experimental results is reported by considering different\napertures, illuminations, and EM wave manipulation requirements.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14601v1", "cate": "eess.SY", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14727", "title": "Gait Transitions in Load-Pulling Quadrupeds: Insights from Sled Dogs and a Minimal SLIP Model", "authors": ["Jiayu Ding", "Benjamin Seleb", "Saad Bhamla", "Zhenyu Gan"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14727v1", "summary": "Quadrupedal animals employ diverse galloping strategies to optimize speed,\nstability, and energy efficiency. However, the biomechanical mechanisms that\nenable adaptive gait transitions during high-speed locomotion under load remain\npoorly understood. In this study, we present new empirical and modeling\ninsights into the biomechanics of load-pulling quadrupeds, using sprint sled\ndogs as a model system. High-speed video and force recordings reveal that sled\ndogs often switch between rotary and transverse galloping gaits within just a\nfew strides and without any observable changes in speed, stride duration, or\nterrain, providing clear evidence of locomotor multistability during high-speed\nload-pulling. To investigate the mechanical basis of these transitions, a\nphysics-based quadrupedal Spring-Loaded Inverted Pendulum model with hybrid\ndynamics and prescribed footfall sequences to reproduce the asymmetric\ngalloping patterns observed in racing sled dogs. Through trajectory\noptimization, we replicate experimentally observed gait sequences and identify\nswing-leg stiffness modulation as a key control mechanism for inducing\ntransitions. This work provides a much-needed biomechanical perspective on\nhigh-speed animal draft and establishes a modeling framework for studying\nlocomotion in pulling quadrupeds, with implications for both biological\nunderstanding and the design of adaptive legged systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14727v1", "cate": "eess.SY", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15032", "title": "The hunt for new pulsating ultraluminous X-ray sources: a clustering approach", "authors": ["Nicolò Oreste Pinciroli Vago", "Roberta Amato", "Matteo Imbrogno", "GianLuca Israel", "Andrea Belfiore", "Konstantinos Kovlakas", "Piero Fraternali", "Mario Pasquato"], "categories": ["astro-ph.HE", "astro-ph.IM", "cs.AI", "cs.LG"], "primary_category": "Subjects:       High Energy Astrophysical Phenomena (astro-ph.HE)", "pdf_link": null, "comments": "Comments:      16 pages, 8 figures; accepted in A&A", "url": "http://arxiv.org/abs/2507.15032v1", "summary": "The discovery of fast and variable coherent signals in a handful of\nultraluminous X-ray sources (ULXs) testifies to the presence of super-Eddington\naccreting neutron stars, and drastically changed the understanding of the ULX\nclass. Our capability of discovering pulsations in ULXs is limited, among\nothers, by poor statistics. However, catalogues and archives of high-energy\nmissions contain information which can be used to identify new candidate\npulsating ULXs (PULXs). The goal of this research is to single out candidate\nPULXs among those ULXs which have not shown pulsations due to an unfavourable\ncombination of factors. We applied an AI approach to an updated database of\nULXs detected by XMM-Newton. We first used an unsupervised clustering algorithm\nto sort out sources with similar characteristics into two clusters. Then, the\nsample of known PULX observations has been used to set the separation threshold\nbetween the two clusters and to identify the one containing the new candidate\nPULXs. We found that only a few criteria are needed to assign the membership of\nan observation to one of the two clusters. The cluster of new candidate PULXs\ncounts 85 unique sources for 355 observations, with $\\sim$85% of these new\ncandidates having multiple observations. A preliminary timing analysis found no\nnew pulsations for these candidates. This work presents a sample of new\ncandidate PULXs observed by XMM-Newton, the properties of which are similar (in\na multi-dimensional phase space) to those of the known PULXs, despite the\nabsence of pulsations in their light curves. While this result is a clear\nexample of the predictive power of AI-based methods, it also highlights the\nneed for high-statistics observational data to reveal coherent signals from the\nsources in this sample and thus validate the robustness of the approach.", "comment": "16 pages, 8 figures; accepted in A&A", "pdf_url": "http://arxiv.org/pdf/2507.15032v1", "cate": "astro-ph.HE", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15287", "title": "Mixture of Autoencoder Experts Guidance using Unlabeled and Incomplete Data for Exploration in Reinforcement Learning", "authors": ["Elias Malomgré", "Pieter Simoens"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 8 figures, accepted for the non-archival workshop \"Workshop on Reinforcement Learning Beyond Rewards @ Reinforcement Learning Conference 2025\"", "url": "http://arxiv.org/abs/2507.15287v1", "summary": "Recent trends in Reinforcement Learning (RL) highlight the need for agents to\nlearn from reward-free interactions and alternative supervision signals, such\nas unlabeled or incomplete demonstrations, rather than relying solely on\nexplicit reward maximization. Additionally, developing generalist agents that\ncan adapt efficiently in real-world environments often requires leveraging\nthese reward-free signals to guide learning and behavior. However, while\nintrinsic motivation techniques provide a means for agents to seek out novel or\nuncertain states in the absence of explicit rewards, they are often challenged\nby dense reward environments or the complexity of high-dimensional state and\naction spaces. Furthermore, most existing approaches rely directly on the\nunprocessed intrinsic reward signals, which can make it difficult to shape or\ncontrol the agent's exploration effectively. We propose a framework that can\neffectively utilize expert demonstrations, even when they are incomplete and\nimperfect. By applying a mapping function to transform the similarity between\nan agent's state and expert data into a shaped intrinsic reward, our method\nallows for flexible and targeted exploration of expert-like behaviors. We\nemploy a Mixture of Autoencoder Experts to capture a diverse range of behaviors\nand accommodate missing information in demonstrations. Experiments show our\napproach enables robust exploration and strong performance in both sparse and\ndense reward environments, even when demonstrations are sparse or incomplete.\nThis provides a practical framework for RL in realistic settings where optimal\ndata is unavailable and precise reward control is needed.", "comment": "10 pages, 8 figures, accepted for the non-archival workshop \"Workshop\n  on Reinforcement Learning Beyond Rewards @ Reinforcement Learning Conference\n  2025\"", "pdf_url": "http://arxiv.org/pdf/2507.15287v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15212", "title": "MeshMamba: State Space Models for Articulated 3D Mesh Generation and Reconstruction", "authors": ["Yusuke Yoshiyasu", "Leyuan Sun", "Ryusuke Sagawa"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV2025", "url": "http://arxiv.org/abs/2507.15212v1", "summary": "In this paper, we introduce MeshMamba, a neural network model for learning 3D\narticulated mesh models by employing the recently proposed Mamba State Space\nModels (Mamba-SSMs). MeshMamba is efficient and scalable in handling a large\nnumber of input tokens, enabling the generation and reconstruction of body mesh\nmodels with more than 10,000 vertices, capturing clothing and hand geometries.\nThe key to effectively learning MeshMamba is the serialization technique of\nmesh vertices into orderings that are easily processed by Mamba. This is\nachieved by sorting the vertices based on body part annotations or the 3D\nvertex locations of a template mesh, such that the ordering respects the\nstructure of articulated shapes. Based on MeshMamba, we design 1) MambaDiff3D,\na denoising diffusion model for generating 3D articulated meshes and 2)\nMamba-HMR, a 3D human mesh recovery model that reconstructs a human body shape\nand pose from a single image. Experimental results showed that MambaDiff3D can\ngenerate dense 3D human meshes in clothes, with grasping hands, etc., and\noutperforms previous approaches in the 3D human shape generation task.\nAdditionally, Mamba-HMR extends the capabilities of previous non-parametric\nhuman mesh recovery approaches, which were limited to handling body-only poses\nusing around 500 vertex tokens, to the whole-body setting with face and hands,\nwhile achieving competitive performance in (near) real-time.", "comment": "Accepted at ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.15212v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2311.07089", "title": "Recursive and non-recursive filters for sequential smoothing and prediction with instantaneous phase and frequency estimation applications (extended version)", "authors": ["Hugh Lachlan Kennedy"], "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      This draft manuscript was reduced in length by: 1) Removing Configurations 2 & 3 from the simulations (only Config 1 remains) 2) Removing most of the basic theory and the design of FIR filters (mostly IIR now) Also emphasised the novel aspects. Changed title. No changes made to this arXiv draft. Final (peer-reviewed and open-access) version in Circuits Syst Signal Process (2025)", "url": "http://arxiv.org/abs/2311.07089v4", "summary": "A simple procedure for the design of recursive digital filters with an\ninfinite impulse response (IIR) and non-recursive digital filters with a finite\nimpulse response (FIR) is described. The fixed-lag smoothing filters are\ndesigned to track an approximately polynomial signal of specified degree\nwithout bias at steady state, while minimizing the gain of high-frequency\n(coloured) noise with a specified power spectral density. For the IIR variant,\nthe procedure determines the optimal lag (i.e. the passband group delay)\nyielding a recursive low-complexity smoother of low order, with a specified\nbandwidth, and excellent passband phase linearity. The filters are applied to\nthe problem of instantaneous frequency estimation, e.g. for Doppler-shift\nmeasurement, for a complex exponential with polynomial phase progression in\nadditive white noise. For this classical problem, simulations show that the\nincorporation of a prediction filter (with a one-sample lead) reduces the\nincidence of (phase or frequency) angle unwrapping errors, particularly for\nsignals with high rates of angle change, which are known to limit the\nperformance of standard FIR estimators at low SNR. This improvement allows the\ninstantaneous phase of low-frequency signals to be estimated, e.g. for\ntime-delay measurement, and/or the instantaneous frequency of\nfrequency-modulated signals, down to a lower SNR. In the absence of unwrapping\nerrors, the error variance of the IIR estimators (with the optimal phase lag)\nreaches the FIR lower bound, at a significantly lower computational cost.\nGuidelines for configuring and tuning both FIR and IIR filters are provided.", "comment": "This draft manuscript was reduced in length by: 1) Removing\n  Configurations 2 & 3 from the simulations (only Config 1 remains) 2) Removing\n  most of the basic theory and the design of FIR filters (mostly IIR now) Also\n  emphasised the novel aspects. Changed title. No changes made to this arXiv\n  draft. Final (peer-reviewed and open-access) version in Circuits Syst Signal\n  Process (2025)", "pdf_url": "http://arxiv.org/pdf/2311.07089v4", "cate": "eess.SP", "date": "2023-11-13", "updated": "2025-07-20"}
{"id": "2507.15455", "title": "Solving nonconvex Hamilton--Jacobi--Isaacs equations with PINN-based policy iteration", "authors": ["Hee Jun Yang", "Min Jung Kim", "Yeoneung Kim"], "categories": ["math.NA", "cs.AI", "cs.NA", "math.AP", "49N70, 35Q93, 49L25, 68T07"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15455v1", "summary": "We propose a mesh-free policy iteration framework that combines classical\ndynamic programming with physics-informed neural networks (PINNs) to solve\nhigh-dimensional, nonconvex Hamilton--Jacobi--Isaacs (HJI) equations arising in\nstochastic differential games and robust control. The method alternates between\nsolving linear second-order PDEs under fixed feedback policies and updating the\ncontrols via pointwise minimax optimization using automatic differentiation.\nUnder standard Lipschitz and uniform ellipticity assumptions, we prove that the\nvalue function iterates converge locally uniformly to the unique viscosity\nsolution of the HJI equation. The analysis establishes equi-Lipschitz\nregularity of the iterates, enabling provable stability and convergence without\nrequiring convexity of the Hamiltonian. Numerical experiments demonstrate the\naccuracy and scalability of the method. In a two-dimensional stochastic\npath-planning game with a moving obstacle, our method matches finite-difference\nbenchmarks with relative $L^2$-errors below %10^{-2}%. In five- and\nten-dimensional publisher-subscriber differential games with anisotropic noise,\nthe proposed approach consistently outperforms direct PINN solvers, yielding\nsmoother value functions and lower residuals. Our results suggest that\nintegrating PINNs with policy iteration is a practical and theoretically\ngrounded method for solving high-dimensional, nonconvex HJI equations, with\npotential applications in robotics, finance, and multi-agent reinforcement\nlearning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15455v1", "cate": "math.NA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15771", "title": "Left Leaning Models: AI Assumptions on Economic Policy", "authors": ["Maxim Chupilkin"], "categories": ["cs.CY", "cs.AI", "econ.GN", "q-fin.EC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      8 pages, 5 tables", "url": "http://arxiv.org/abs/2507.15771v1", "summary": "How does AI think about economic policy? While the use of large language\nmodels (LLMs) in economics is growing exponentially, their assumptions on\neconomic issues remain a black box. This paper uses a conjoint experiment to\ntease out the main factors influencing LLMs' evaluation of economic policy. It\nfinds that LLMs are most sensitive to unemployment, inequality, financial\nstability, and environmental harm and less sensitive to traditional\nmacroeconomic concerns such as economic growth, inflation, and government debt.\nThe results are remarkably consistent across scenarios and across models.", "comment": "8 pages, 5 tables", "pdf_url": "http://arxiv.org/pdf/2507.15771v1", "cate": "cs.CY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14728", "title": "Enhancing Sustainability in HAPS-Assisted 6G Networks: Load Estimation Aware Cell Switching", "authors": ["Maryam Salamatmoghadasi", "Metin Ozturk", "Halim Yanikomeroglu"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures, PIMRC", "url": "http://arxiv.org/abs/2507.14728v1", "summary": "This study introduces and addresses the critical challenge of traffic load\nestimation in cell switching within vertical heterogeneous networks. The\neffectiveness of cell switching is significantly limited by the lack of\naccurate traffic load data for small base stations (SBSs) in sleep mode, making\nmany load-dependent energy-saving approaches impractical, as they assume\nperfect knowledge of traffic loads, an assumption that is unrealistic when SBSs\nare inactive. In other words, when SBSs are in sleep mode, their traffic loads\ncannot be directly known and can only be estimated, inevitably with\ncorresponding errors. Rather than proposing a new switching algorithm, we focus\non eliminating this foundational barrier by exploring effective prediction\ntechniques. A novel vertical heterogeneous network model is considered,\nintegrating a high-altitude platform station (HAPS) as a super macro base\nstation (SMBS). We investigate both spatial and temporal load estimation\napproaches, including three spatial interpolation schemes, random neighboring\nselection, distance based selection, and multi level clustering (MLC),\nalongside a temporal deep learning method based on long short-term memory\n(LSTM) networks. Using a real world dataset for empirical validation, our\nresults show that both spatial and temporal methods significantly improve\nestimation accuracy, with the MLC and LSTM approaches demonstrating\nparticularly strong performance.", "comment": "6 pages, 5 figures, PIMRC", "pdf_url": "http://arxiv.org/pdf/2507.14728v1", "cate": "eess.SY", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.14765", "title": "Multi Target Observability", "authors": ["Debadrita Banerjee", "Debjani Mitra", "Rajesh Dey", "Mudassir Khan", "Lalan Kumar"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14765v1", "summary": "In this paper, we mainly focus on the problem of multi-target observability,\nfocusing on the unique state estimation criteria for multiple targets. We\nderive the condition which is necessary as well as sufficient for observability\nusing bearing angles with multiple higher-order dynamics observed by a single\nobserver. We then establish an alternative notion of observability by analyzing\nambiguous target trajectories and deriving the condition which is NECNDSUF\n(Nec. and Suff.) for multi-target observability, considering three types of\nmeasurements: Doppler-only, bearing-only, and combined Doppler and bearing\nmeasurements, which offers insights that can improve target distinguishability,\ntrajectory reconstruction, and overall tracking accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14765v1", "cate": "eess.SY", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15061", "title": "WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization", "authors": ["Zhengwei Tao", "Jialong Wu", "Wenbiao Yin", "Junkai Zhang", "Baixuan Li", "Haiyang Shen", "Kuan Li", "Liwen Zhang", "Xinyu Wang", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Jingren Zhou"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15061v1", "summary": "The advent of Large Language Model (LLM)-powered agents has revolutionized\nartificial intelligence by enabling solutions to complex, open-ended tasks\nthrough web-based information-seeking (IS) capabilities. The scarcity of\nhigh-quality training data has limited the development of IS agents. Existing\napproaches typically adopt an information-driven paradigm that first collects\nweb data and then generates questions based on the retrieval. However, this may\nlead to inconsistency between information structure and reasoning structure,\nquestion and answer. To mitigate, we propose a formalization-driven IS data\nsynthesis framework WebShaper to construct a dataset. WebShaper systematically\nformalizes IS tasks through set theory. Central to the formalization is the\nconcept of Knowledge Projections (KP), which enables precise control over\nreasoning structure by KP operation compositions. During synthesis, we begin by\ncreating seed tasks, then use a multi-step expansion process. At each step, an\nagentic Expander expands the current formal question more complex with\nretrieval and validation tools based on our formalization. We train our model\non the synthesized dataset. Experiment results demonstrate that WebShaper\nachieves state-of-the-art performance among open-sourced IS agents on GAIA and\nWebWalkerQA benchmarks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15061v1", "cate": "cs.CL", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15288", "title": "Preferential subspace identification (PSID) with forward-backward smoothing", "authors": ["Omid G. Sani", "Maryam M. Shanechi"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      17 pages, 5 figures", "url": "http://arxiv.org/abs/2507.15288v1", "summary": "System identification methods for multivariate time-series, such as neural\nand behavioral recordings, have been used to build models for predicting one\nfrom the other. For example, Preferential Subspace Identification (PSID) builds\na state-space model of a primary time-series (e.g., neural activity) to\noptimally predict a secondary time-series (e.g., behavior). However, PSID\nfocuses on optimal prediction using past primary data, even though in offline\napplications, better estimation can be achieved by incorporating concurrent\ndata (filtering) or all available data (smoothing). Here, we extend PSID to\nenable optimal filtering and smoothing. First, we show that the presence of a\nsecondary signal makes it possible to uniquely identify a model with an optimal\nKalman update step (to enable filtering) from a family of otherwise equivalent\nstate-space models. Our filtering solution augments PSID with a reduced-rank\nregression step that directly learns the optimal gain required for the update\nstep from data. We refer to this extension of PSID as PSID with filtering.\nSecond, inspired by two-filter Kalman smoother formulations, we develop a novel\nforward-backward PSID smoothing algorithm where we first apply PSID with\nfiltering and then apply it again in the reverse time direction on the\nresiduals of the filtered secondary signal. We validate our methods on\nsimulated data, showing that our approach recovers the ground-truth model\nparameters for filtering, and achieves optimal filtering and smoothing decoding\nperformance of the secondary signal that matches the ideal performance of the\ntrue underlying model. This work provides a principled framework for optimal\nlinear filtering and smoothing in the two-signal setting, significantly\nexpanding the toolkit for analyzing dynamic interactions in multivariate\ntime-series.", "comment": "17 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.15288v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15216", "title": "Improving Joint Embedding Predictive Architecture with Diffusion Noise", "authors": ["Yuping Qiu", "Rui Zhu", "Ying-cong Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15216v1", "summary": "Self-supervised learning has become an incredibly successful method for\nfeature learning, widely applied to many downstream tasks. It has proven\nespecially effective for discriminative tasks, surpassing the trending\ngenerative models. However, generative models perform better in image\ngeneration and detail enhancement. Thus, it is natural for us to find a\nconnection between SSL and generative models to further enhance the\nrepresentation capacity of SSL. As generative models can create new samples by\napproximating the data distribution, such modeling should also lead to a\nsemantic understanding of the raw visual data, which is necessary for\nrecognition tasks. This enlightens us to combine the core principle of the\ndiffusion model: diffusion noise, with SSL to learn a competitive recognition\nmodel. Specifically, diffusion noise can be viewed as a particular state of\nmask that reveals a close relationship between masked image modeling (MIM) and\ndiffusion models. In this paper, we propose N-JEPA (Noise-based JEPA) to\nincorporate diffusion noise into MIM by the position embedding of masked\ntokens. The multi-level noise schedule is a series of feature augmentations to\nfurther enhance the robustness of our model. We perform a comprehensive study\nto confirm its effectiveness in the classification of downstream tasks. Codes\nwill be released soon in public.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15216v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2406.18951", "title": "Constant Modulus Waveform Design with Space-Time Sidelobe Reduction for DFRC Systems", "authors": ["Byunghyun Lee", "Anindya Bijoy Das", "David Love", "Christopher Brinton", "James Krogmeier"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2310.10804", "url": "http://arxiv.org/abs/2406.18951v4", "summary": "Dual-function radar-communication (DFRC) is a key enabler of location-based\nservices for next-generation communication systems. In this paper, we\ninvestigate the problem of designing constant modulus waveforms for DFRC\nsystems. We consider the joint optimization of the spatial beam pattern and\nspace-time correlation levels for better separating multiple targets in\ndifferent angle and delay bins. In particular, we use the space-time\ncorrelation function to quantify the correlations between different angle and\ndelay bins and formulate integrated sidelobe levels (ISLs). To serve\ncommunication users, we employ constructive interference (CI)-based precoding\nto modulate information symbols, which leverages distortion induced by\nmultiuser multiple-input multiple-output (MU-MIMO) and radar transmission. We\npropose two solution algorithms based on the alternating direction method of\nmultipliers (ADMM) and majorization-minimization (MM) principles, which are\neffective for small and large block sizes, respectively. The proposed\nADMM-based solution decomposes the nonconvex formulated problem into multiple\ntractable subproblems, each of which admits a closed-form solution. To\naccelerate convergence of the MM-based solution, we propose a novel majorizing\nfunction for complex quadratic functions. After majorization, we decompose the\napproximated problem into independent subproblems for parallelization,\nmitigating the complexity that increases with block size. We evaluate the\nperformance of the proposed algorithms in comparison to the existing DFRC\nalgorithm. Simulation results demonstrate that the proposed methods can\nsubstantially enhance the detection and estimation performance due to reduced\nspace-time correlation levels.", "comment": "arXiv admin note: text overlap with arXiv:2310.10804", "pdf_url": "http://arxiv.org/pdf/2406.18951v4", "cate": "eess.SP", "date": "2024-06-27", "updated": "2025-07-19"}
{"id": "2507.15464", "title": "tiDAS: a time invariant approximation of the Delay and Sum algorithm for biomedical ultrasound PSF reconstructions", "authors": ["Chiara Razzetta", "Sara Garbarino", "Michele Piana", "Marco Crocco", "Federico Benvenuto"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15464v1", "summary": "Ultrasound imaging is a real-time diagnostic modality that reconstructs\nacoustic signals into visual representations of internal body structures. A key\ncomponent in this process is beamforming, with the Delay and Sum (DAS)\nalgorithm being a standard due to its balance between simplicity and\neffectiveness. However, the computational cost of DAS can be a limiting factor,\nespecially in real-time scenarios where fast frame reconstruction is essential.\nIn this work, we introduce a time-invariant approximation of the DAS algorithm\n(tiDAS), designed to accelerate the reconstruction process without compromising\nimage quality. By adopting a one-dimensional, row-wise convolutional\nformulation, tiDAS significantly reduces computational complexity while\npreserving the core properties of the original model. This approach not only\nenables faster image reconstruction but also provides a structured foundation\nfor the application of deconvolution methods aimed at enhancing resolution.\nSynthetic experiments demonstrate that tiDAS achieves a favorable trade-off\nbetween speed and accuracy, making it a promising tool for improving the\nefficiency of real-time ultrasound imaging.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15464v1", "cate": "math.NA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15821", "title": "Just Put a Human in the Loop? Investigating LLM-Assisted Annotation for Subjective Tasks", "authors": ["Hope Schroeder", "Deb Roy", "Jad Kabbara"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15821v1", "summary": "LLM use in annotation is becoming widespread, and given LLMs' overall\npromising performance and speed, simply \"reviewing\" LLM annotations in\ninterpretive tasks can be tempting. In subjective annotation tasks with\nmultiple plausible answers, reviewing LLM outputs can change the label\ndistribution, impacting both the evaluation of LLM performance, and analysis\nusing these labels in a social science task downstream. We conducted a\npre-registered experiment with 410 unique annotators and over 7,000 annotations\ntesting three AI assistance conditions against controls, using two models, and\ntwo datasets. We find that presenting crowdworkers with LLM-generated\nannotation suggestions did not make them faster, but did improve their\nself-reported confidence in the task. More importantly, annotators strongly\ntook the LLM suggestions, significantly changing the label distribution\ncompared to the baseline. When these labels created with LLM assistance are\nused to evaluate LLM performance, reported model performance significantly\nincreases. We believe our work underlines the importance of understanding the\nimpact of LLM-assisted annotation on subjective, qualitative tasks, on the\ncreation of gold data for training and testing, and on the evaluation of NLP\nsystems on subjective tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15821v1", "cate": "cs.CY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14857", "title": "Grid Stability and Power Factor Dynamics in Solar Farms Integration", "authors": ["Hassan Osseily"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 pages, 16 figures, African Scientific", "url": "http://arxiv.org/abs/2507.14857v1", "summary": "This paper examines the impact of solar farm fluctuations on grid stability,\nfocusing on maintaining an optimal power factor. ETAP-based simulations and\ncase studies are used to analyze real-time grid performance under solar\nvariability. Reactive power control strategies and advanced inverter functions\nare proposed for stabilization. Theoretical analysis and simulation results\nhighlight effective integration techniques. Artificial intelligence is trailed\nfor controlling the SVC in adaptive reactive power compensation. The study\nprovides practical solutions for improving reliability in renewable-integrated\npower systems.", "comment": "6 pages, 16 figures, African Scientific", "pdf_url": "http://arxiv.org/pdf/2507.14857v1", "cate": "eess.SY", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.14863", "title": "Adversarial Destabilization Attacks to Direct Data-Driven Control", "authors": ["Hampei Sasahara"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      15 pages", "url": "http://arxiv.org/abs/2507.14863v1", "summary": "This study investigates the vulnerability of direct data-driven control\nmethods, specifically for the linear quadratic regulator problem, to\nadversarial perturbations in collected data used for controller synthesis. We\nconsider stealthy attacks that subtly manipulate offline-collected data to\ndestabilize the resulting closed-loop system while evading detection. To\ngenerate such perturbations, we propose the Directed Gradient Sign Method\n(DGSM) and its iterative variant (I-DGSM), adaptations of the fast gradient\nsign method originally developed for neural networks, which align perturbations\nwith the gradient of the spectral radius of the closed-loop matrix to reduce\nstability. A key contribution is an efficient gradient computation technique\nbased on implicit differentiation through the Karush-Kuhn-Tucker conditions of\nthe underlying semidefinite program, enabling scalable and exact gradient\nevaluation without repeated optimization computations. To defend against these\nattacks, we propose two defense strategies: a regularization-based approach\nthat enhances robustness by suppressing controller sensitivity to data\nperturbations and a robust data-driven control approach that guarantees\nclosed-loop stability within bounded perturbation sets. Extensive numerical\nexperiments on benchmark systems show that adversarial perturbations with\nmagnitudes up to ten times smaller than random noise can destabilize\ncontrollers trained on corrupted data and that the proposed defense strategies\neffectively mitigate attack success rates while maintaining control\nperformance. Additionally, we evaluate attack transferability under partial\nknowledge scenarios, highlighting the practical importance of protecting\ntraining data confidentiality.", "comment": "15 pages", "pdf_url": "http://arxiv.org/pdf/2507.14863v1", "cate": "eess.SY", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15087", "title": "Evaluation of Coding Schemes for Transformer-based Gene Sequence Modeling", "authors": ["Chenlei Gong", "Yuanhe Tian", "Lei Mao", "Yan Song"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15087v1", "summary": "Currently, many studies view DNA sequences as a special type of language and\nutilize Transformers to model them. These studies use fixed-length k-mer\nsegmentation and BPE subword tokenization but lack a systematic evaluation to\ndetermine which is superior. We compare k-mer segmentation with k=1,3,4,5,6, a\n4,096-token BPE vocabulary, and three positional encoding methods-sinusoidal,\nAliBi, and RoPE. Each configuration is trained from scratch in 3, 6, 12, and\n24-layer Transformer encoders and evaluated on GUE benchmark dataset. In\ngeneral, BPE delivers higher and more stable performance across tasks by\ncompressing frequent motifs into variable-length tokens, reducing sequence\nlength, and improving model generalization. RoPE excels at capturing periodic\nmotifs and extrapolating to long sequences, while AliBi also performs well on\ntasks driven by local dependencies. In terms of depth, we observe significant\ngains when increasing layers from 3 to 12, with only marginal improvements or\nslight overfitting at 24 layers. This study provides practical guidance for\ndesigning tokenization and positional encoding in DNA Transformer models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15087v1", "cate": "cs.CL", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15290", "title": "Feel-Good Thompson Sampling for Contextual Bandits: a Markov Chain Monte Carlo Showdown", "authors": ["Emile Anand", "Sarah Liaw"], "categories": ["cs.LG", "I.2.6; I.2.0"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      39 pages, 2 figures, 36 tables", "url": "http://arxiv.org/abs/2507.15290v1", "summary": "Thompson Sampling (TS) is widely used to address the exploration/exploitation\ntradeoff in contextual bandits, yet recent theory shows that it does not\nexplore aggressively enough in high-dimensional problems. Feel-Good Thompson\nSampling (FG-TS) addresses this by adding an optimism bonus that biases toward\nhigh-reward models, and it achieves the asymptotically minimax-optimal regret\nin the linear setting when posteriors are exact. However, its performance with\n\\emph{approximate} posteriors -- common in large-scale or neural problems --\nhas not been benchmarked. We provide the first systematic study of FG-TS and\nits smoothed variant (SFG-TS) across eleven real-world and synthetic\nbenchmarks. To evaluate their robustness, we compare performance across\nsettings with exact posteriors (linear and logistic bandits) to approximate\nregimes produced by fast but coarse stochastic-gradient samplers. Ablations\nover preconditioning, bonus scale, and prior strength reveal a trade-off:\nlarger bonuses help when posterior samples are accurate, but hurt when sampling\nnoise dominates. FG-TS generally outperforms vanilla TS in linear and logistic\nbandits, but tends to be weaker in neural bandits. Nevertheless, because FG-TS\nand its variants are competitive and easy-to-use, we recommend them as\nbaselines in modern contextual-bandit benchmarks. Finally, we provide source\ncode for all our experiments in\nhttps://github.com/SarahLiaw/ctx-bandits-mcmc-showdown.", "comment": "39 pages, 2 figures, 36 tables", "pdf_url": "http://arxiv.org/pdf/2507.15290v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15223", "title": "Hierarchical Part-based Generative Model for Realistic 3D Blood Vessel", "authors": ["Siqi Chen", "Guoqing Zhang", "Jiahao Lai", "Bingzhi Shen", "Sihong Zhang", "Caixia Dong", "Xuejin Chen", "Yang Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15223v1", "summary": "Advancements in 3D vision have increased the impact of blood vessel modeling\non medical applications. However, accurately representing the complex geometry\nand topology of blood vessels remains a challenge due to their intricate\nbranching patterns, curvatures, and irregular shapes. In this study, we propose\na hierarchical part-based frame work for 3D vessel generation that separates\nthe global binary tree-like topology from local geometric details. Our approach\nproceeds in three stages: (1) key graph generation to model the overall\nhierarchical struc ture, (2) vessel segment generation conditioned on geometric\nproperties, and (3) hierarchical vessel assembly by integrating the local\nsegments according to the global key graph. We validate our framework on real\nworld datasets, demonstrating superior performance over existing methods in\nmodeling complex vascular networks. This work marks the first successful\napplication of a part-based generative approach for 3D vessel modeling, setting\na new benchmark for vascular data generation. The code is available at:\nhttps://github.com/CybercatChen/PartVessel.git.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15223v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2407.13749", "title": "BIRA: A Spherical Bistatic Radar Reflectivity Measurement System", "authors": ["Carsten Andrich", "Tobias F. Nowack", "Alexander Ihlow", "Sebastian Giehl", "Maximilian Engelhardt", "Gerd Sommerkorn", "Andreas Schwind", "Willi Hofmann", "Christian Bornkessel", "Matthias A. Hein", "Reiner S. Thomä"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      15 pages, 21 figures, submitted to IEEE Transactions on Antennas and Propagation", "url": "http://arxiv.org/abs/2407.13749v3", "summary": "The upcoming 6G mobile communication standard will offer a revolutionary new\nfeature: Integrated sensing and communication (ISAC) reuses mobile\ncommunication signals to realize multi-static radar for various applications\nincluding localization. Consequently, applied ISAC propagation research\nnecessitates to evolve from classical monostatic radar cross section (RCS)\nmeasurement of static targets on to bistatic radar reflectivity\ncharacterization of dynamic objects. Here, we introduce our Bistatic Radar\n(BIRA) measurement facility for independent spherical positioning of two probes\nwith sub-millimeter accuracy on a diameter of up to 7 m and with almost\ncontinuous frequency coverage from 0.7 up to 260 GHz. Currently, BIRA is the\nonly bistatic measurement facility capable of unrestricted ISAC research: In\naddition to vector network analysis, it employs advanced wideband transceiver\ntechnology with an instantaneous bandwidth of up to 4 GHz. These transceivers\ngrant BIRA the unique capability to characterize dynamic targets in both\nDoppler and range, while also significantly accelerating measurements on static\nobjects. Additionally, the installation is capable of spherical near-field\nantenna measurements over these wide frequency ranges.", "comment": "15 pages, 21 figures, submitted to IEEE Transactions on Antennas and\n  Propagation", "pdf_url": "http://arxiv.org/pdf/2407.13749v3", "cate": "eess.SP", "date": "2024-07-18", "updated": "2025-07-19"}
{"id": "2507.15642", "title": "Mathematical modeling and sensitivity analysis of hypoxia-activated drugs", "authors": ["Alessandro Coclite", "Riccardo Montanelli Eccher", "Luca Possenti", "Piermario Vitullo", "Paolo Zunino"], "categories": ["math.NA", "cs.NA", "92C50, 92C45, 35Q92, 35R20, 65M60"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15642v1", "summary": "Hypoxia-activated prodrugs offer a promising strategy for targeting\noxygen-deficient regions in solid tumors, which are often resistant to\nconventional therapies. However, modeling their behavior is challenging because\nof the complex interplay between oxygen availability, drug activation, and cell\nsurvival. In this work, we develop a multiscale and mixed-dimensional model\nthat couples spatially resolved drug and oxygen transport with pharmacokinetics\nand pharmacodynamics to simulate the cellular response. The model integrates\nblood flow, oxygen diffusion and consumption, drug delivery, and metabolism. To\nreduce computational cost, we mitigate the global nonlinearity through a\none-way coupling of the multiscale and mixed/dimensional models with a reduced\n0D model for the drug metabolism. The global sensitivity analysis is then used\nto identify key parameters influencing drug activation and therapeutic outcome.\nThis approach enables efficient simulation and supports the design of optimized\nhypoxia-targeted therapies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15642v1", "cate": "math.NA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15328", "title": "On the Inevitability of Left-Leaning Political Bias in Aligned Language Models", "authors": ["Thilo Hagendorff"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15328v1", "summary": "The guiding principle of AI alignment is to train large language models\n(LLMs) to be harmless, helpful, and honest (HHH). At the same time, there are\nmounting concerns that LLMs exhibit a left-wing political bias. Yet, the\ncommitment to AI alignment cannot be harmonized with the latter critique. In\nthis article, I argue that intelligent systems that are trained to be harmless\nand honest must necessarily exhibit left-wing political bias. Normative\nassumptions underlying alignment objectives inherently concur with progressive\nmoral frameworks and left-wing principles, emphasizing harm avoidance,\ninclusivity, fairness, and empirical truthfulness. Conversely, right-wing\nideologies often conflict with alignment guidelines. Yet, research on political\nbias in LLMs is consistently framing its insights about left-leaning tendencies\nas a risk, as problematic, or concerning. This way, researchers are actively\narguing against AI alignment, tacitly fostering the violation of HHH\nprinciples.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15328v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14952", "title": "An approach to the LQG/LTR design problem with specifications for finite-dimensional SISO control systems", "authors": ["Mahyar Mahinzaeim", "Kamyar Mehran"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14952v1", "summary": "This is an expository paper which discusses an approach to the LQG/LTR design\nproblem for finite-dimensional SISO control systems. The approach is based on\nthe utilisation of weighting augmentation for incorporating design\nspecifications into the framework of the LTR technique for LQG compensator\ndesign. The LQG compensator is to simultaneously meet given analytical low- and\nhigh-frequency design specifications expressed in terms of desirable\nsensitivity and controller noise sensitivity functions. The paper is aimed at\nnonspecialists and, in particular, practitioners in finite-dimensional LQG\ntheory interested in the design of feedback compensators for closed-loop\nperformance and robustness shaping of SISO control systems in realistic\nsituations. The proposed approach is illustrated by a detailed numerical\nexample: the torque control of a current-controlled DC motor with an\nelastically mounted rotor.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14952v1", "cate": "eess.SY", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15031", "title": "Safety Controller Synthesis for Stochastic Networked Systems under Communication Constraints", "authors": ["Omid Akbarzadeh", "Mohammad H. Mamduhi", "Abolfazl Lavaei"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15031v1", "summary": "This paper develops a framework for synthesizing safety controllers for\ndiscrete-time stochastic linear control systems (dt-SLS) operating under\ncommunication imperfections. The control unit is remote and communicates with\nthe sensor and actuator through an imperfect wireless network. We consider a\nconstant delay in the sensor-to-controller channel (uplink), and data loss in\nboth sensor-to-controller and controller-to-actuator (downlink) channels. In\nour proposed scheme, data loss in each channel is modeled as an independent\nBernoulli-distributed random process. To systematically handle the uplink\ndelay, we first introduce an augmented discrete-time stochastic linear system\n(dt-ASLS) by concatenating all states and control inputs that sufficiently\nrepresent the state-input evolution of the original dt-SLS under the delay and\npacket loss constraints. We then leverage control barrier certificates (CBCs)\nfor dt-ASLS to synthesize a controller that guarantees dt-SLS safety in a\nstochastic sense, ensuring that all trajectories of dt-SLS remain within safe\nregions with a quantified probabilistic bound. Our approach translates safety\nconstraints into matrix inequalities, leading to an optimization problem that\neventually quantifies the probability of satisfying the safety specification in\nthe presence of communication imperfections. We validate our results on an RLC\ncircuit subject to both constant delay and probabilistic data loss.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15031v1", "cate": "eess.SY", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15100", "title": "Filling the Gap: Is Commonsense Knowledge Generation useful for Natural Language Inference?", "authors": ["Chathuri Jayaweera", "Brianna Yanqui", "Bonnie Dorr"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      9 pages, 8 figures and 5 tables", "url": "http://arxiv.org/abs/2507.15100v1", "summary": "Natural Language Inference (NLI) is the task of determining the semantic\nentailment of a premise for a given hypothesis. The task aims to develop\nsystems that emulate natural human inferential processes where commonsense\nknowledge plays a major role. However, existing commonsense resources lack\nsufficient coverage for a variety of premise-hypothesis pairs. This study\nexplores the potential of Large Language Models as commonsense knowledge\ngenerators for NLI along two key dimensions: their reliability in generating\nsuch knowledge and the impact of that knowledge on prediction accuracy. We\nadapt and modify existing metrics to assess LLM factuality and consistency in\ngenerating in this context. While explicitly incorporating commonsense\nknowledge does not consistently improve overall results, it effectively helps\ndistinguish entailing instances and moderately improves distinguishing\ncontradictory and neutral inferences.", "comment": "9 pages, 8 figures and 5 tables", "pdf_url": "http://arxiv.org/pdf/2507.15100v1", "cate": "cs.CL", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15303", "title": "Universal crystal material property prediction via multi-view geometric fusion in graph transformers", "authors": ["Liang Zhang", "Kong Chen", "Yuen Wu"], "categories": ["cs.LG", "cond-mat.mtrl-sci"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15303v1", "summary": "Accurately and comprehensively representing crystal structures is critical\nfor advancing machine learning in large-scale crystal materials simulations,\nhowever, effectively capturing and leveraging the intricate geometric and\ntopological characteristics of crystal structures remains a core, long-standing\nchallenge for most existing methods in crystal property prediction. Here, we\npropose MGT, a multi-view graph transformer framework that synergistically\nfuses SE3 invariant and SO3 equivariant graph representations, which\nrespectively captures rotation-translation invariance and rotation equivariance\nin crystal geometries. To strategically incorporate these complementary\ngeometric representations, we employ a lightweight mixture of experts router in\nMGT to adaptively adjust the weight assigned to SE3 and SO3 embeddings based on\nthe specific target task. Compared with previous state-of-the-art models, MGT\nreduces the mean absolute error by up to 21% on crystal property prediction\ntasks through multi-task self-supervised pretraining. Ablation experiments and\ninterpretable investigations confirm the effectiveness of each technique\nimplemented in our framework. Additionally, in transfer learning scenarios\nincluding crystal catalyst adsorption energy and hybrid perovskite bandgap\nprediction, MGT achieves performance improvements of up to 58% over existing\nbaselines, demonstrating domain-agnostic scalability across diverse application\ndomains. As evidenced by the above series of studies, we believe that MGT can\nserve as useful model for crystal material property prediction, providing a\nvaluable tool for the discovery of novel materials.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15303v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15227", "title": "Mammo-SAE: Interpreting Breast Cancer Concept Learning with Sparse Autoencoders", "authors": ["Krishna Kanth Nakka"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Preprint. Under review", "url": "http://arxiv.org/abs/2507.15227v1", "summary": "Interpretability is critical in high-stakes domains such as medical imaging,\nwhere understanding model decisions is essential for clinical adoption. In this\nwork, we introduce Sparse Autoencoder (SAE)-based interpretability to breast\nimaging by analyzing {Mammo-CLIP}, a vision--language foundation model\npretrained on large-scale mammogram image--report pairs. We train a patch-level\n\\texttt{Mammo-SAE} on Mammo-CLIP to identify and probe latent features\nassociated with clinically relevant breast concepts such as \\textit{mass} and\n\\textit{suspicious calcification}. Our findings reveal that top activated class\nlevel latent neurons in the SAE latent space often tend to align with ground\ntruth regions, and also uncover several confounding factors influencing the\nmodel's decision-making process. Additionally, we analyze which latent neurons\nthe model relies on during downstream finetuning for improving the breast\nconcept prediction. This study highlights the promise of interpretable SAE\nlatent representations in providing deeper insight into the internal workings\nof foundation models at every layer for breast imaging.", "comment": "Preprint. Under review", "pdf_url": "http://arxiv.org/pdf/2507.15227v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2412.13967", "title": "THz Channels for Short-Range Mobile Networks: Multipath Channel Behavior and Human Body Shadowing Effects", "authors": ["Minseok Kim", "Jun-ichi Takada", "Minghe Mao", "Che Chia Kang", "Xin Du", "Anirban Ghosh"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.13967v2", "summary": "The THz band (0.1-10 THz) is emerging as a crucial enabler for\nsixth-generation (6G) mobile communication systems, overcoming the limitations\nof current technologies and unlocking new opportunities for low-latency and\nultra-high-speed communications by utilizing several tens of GHz transmission\nbandwidths. However, extremely high spreading losses and various interaction\nlosses pose significant challenges to establishing reliable communication\ncoverage, while human body shadowing further complicates maintaining stable\ncommunication links. Although point-to-point (P2P) fixed wireless access in the\nTHz band has been successfully demonstrated, realizing fully mobile and\nreliable wireless access via highly directional communication remains a\nchallenge. This paper addresses the key challenges faced by THz mobile\nnetworks, focusing particularly on the behavior of multipath channels and the\nimpact of human body shadowing (HBS). It presents the environment-dependent\ncharacteristics of multipath clusters through empirical measurements at 300~GHz\nusing a consistent setup, highlighting the need to account for environmental\nfactors in system design. In addition, it presents a motion capture-based\napproach for precise measurement and prediction of HBS to enable proactive path\nscheduling and enhances link reliability, offering key insights for robust THz\ncommunication systems in future 6G networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.13967v2", "cate": "eess.SP", "date": "2024-12-18", "updated": "2025-07-21"}
{"id": "2507.15837", "title": "Data-driven optimal approximation on Hardy spaces in simply connected domains", "authors": ["Alessandro Borghi", "Tobias Breiten"], "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15837v1", "summary": "We consider optimal interpolation of functions analytic in simply connected\ndomains in the complex plane. By choosing a specific structure for the\napproximant, we show that the resulting first order optimality conditions can\nbe interpreted as optimal $\\mathcal{H}_2$ interpolation conditions for\ndiscrete-time dynamical systems. Connections to the implicit Euler method, the\nmidpoint method, and backward differentiation methods are also established. A\ndata-driven algorithm is developed to compute a (locally) optimal approximant.\nOur method is tested on three numerical experiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15837v1", "cate": "math.NA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2503.16148", "title": "Only a Little to the Left: A Theory-grounded Measure of Political Bias in Large Language Models", "authors": ["Mats Faulborn", "Indira Sen", "Max Pellert", "Andreas Spitz", "David Garcia"], "categories": ["cs.CY", "cs.CL"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Preprint of ACL 2025 paper", "url": "http://arxiv.org/abs/2503.16148v2", "summary": "Prompt-based language models like GPT4 and LLaMa have been used for a wide\nvariety of use cases such as simulating agents, searching for information, or\nfor content analysis. For all of these applications and others, political\nbiases in these models can affect their performance. Several researchers have\nattempted to study political bias in language models using evaluation suites\nbased on surveys, such as the Political Compass Test (PCT), often finding a\nparticular leaning favored by these models. However, there is some variation in\nthe exact prompting techniques, leading to diverging findings, and most\nresearch relies on constrained-answer settings to extract model responses.\nMoreover, the Political Compass Test is not a scientifically valid survey\ninstrument. In this work, we contribute a political bias measured informed by\npolitical science theory, building on survey design principles to test a wide\nvariety of input prompts, while taking into account prompt sensitivity. We then\nprompt 11 different open and commercial models, differentiating between\ninstruction-tuned and non-instruction-tuned models, and automatically classify\ntheir political stances from 88,110 responses. Leveraging this dataset, we\ncompute political bias profiles across different prompt variations and find\nthat while PCT exaggerates bias in certain models like GPT3.5, measures of\npolitical bias are often unstable, but generally more left-leaning for\ninstruction-tuned models. Code and data are available on:\nhttps://github.com/MaFa211/theory_grounded_pol_bias", "comment": "Preprint of ACL 2025 paper", "pdf_url": "http://arxiv.org/pdf/2503.16148v2", "cate": "cs.CY", "date": "2025-03-20", "updated": "2025-07-20"}
{"id": "2507.15047", "title": "On an Abstraction of Lyapunov and Lagrange Stability", "authors": ["Michelangelo Bin", "David Angeli"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15047v1", "summary": "This paper studies a set-theoretic generalization of Lyapunov and Lagrange\nstability for abstract systems described by set-valued maps. Lyapunov stability\nis characterized as the property of inversely mapping filters to filters,\nLagrange stability as that of mapping ideals to ideals. These abstract\ndefinitions unveil a deep duality between the two stability notions, enable a\ndefinition of global stability for abstract systems, and yield an agile\ngeneralization of the stability theorems for basic series, parallel, and\nfeedback interconnections, including a small-gain theorem. Moreover, it is\nshown that Lagrange stability is abstractly identical to other properties of\ninterest in control theory, such as safety and positivity, whose preservation\nunder interconnections can be thus studied owing to the developed stability\nresults.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15047v1", "cate": "eess.SY", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15093", "title": "Exact Finite Koopman Embedding of Block-Oriented Polynomial Systems", "authors": ["Lucian Cristian Iacob", "Roland Tóth", "Maarten Schoukens"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Submitted to SIAM Journal on Applied Dynamical Systems (SIADS)", "url": "http://arxiv.org/abs/2507.15093v1", "summary": "The challenge of finding exact and finite-dimensional Koopman embeddings of\nnonlinear systems has been largely circumvented by employing data-driven\ntechniques to learn models of different complexities (e.g., linear, bilinear,\ninput affine). Although these models may provide good accuracy, selecting the\nmodel structure and dimension is still ad-hoc and it is difficult to quantify\nthe error that is introduced. In contrast to the general trend of data-driven\nlearning, in this paper, we develop a systematic technique for nonlinear\nsystems that produces a finite-dimensional and exact embedding. If the\nnonlinear system is represented as a network of series and parallel linear and\nnonlinear (polynomial) blocks, one can derive an associated Koopman model that\nhas constant state and output matrices and the input influence is polynomial.\nFurthermore, if the linear blocks do not have feedthrough, the Koopman\nrepresentation simplifies to a bilinear model.", "comment": "Submitted to SIAM Journal on Applied Dynamical Systems (SIADS)", "pdf_url": "http://arxiv.org/pdf/2507.15093v1", "cate": "eess.SY", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15142", "title": "A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that use the Ge'ez Script", "authors": ["Hellina Hailu Nigatu", "Atnafu Lambebo Tonja", "Henok Biadglign Ademtew", "Hizkel Mitiku Alemayehu", "Negasi Haile Abadi", "Tadesse Destaw Belay", "Seid Muhie Yimam"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Paper under review", "url": "http://arxiv.org/abs/2507.15142v1", "summary": "Homophone normalization, where characters that have the same sound in a\nwriting script are mapped to one character, is a pre-processing step applied in\nAmharic Natural Language Processing (NLP) literature. While this may improve\nperformance reported by automatic metrics, it also results in models that are\nnot able to understand different forms of writing in a single language.\nFurther, there might be impacts in transfer learning, where models trained on\nnormalized data do not generalize well to other languages. In this paper, we\nexperiment with monolingual training and cross-lingual transfer to understand\nthe impacts of normalization on languages that use the Ge'ez script. We then\npropose a post-inference intervention in which normalization is applied to\nmodel predictions instead of training data. With our simple scheme of\npost-inference normalization, we show that we can achieve an increase in BLEU\nscore of up to 1.03 while preserving language features in training. Our work\ncontributes to the broader discussion on technology-facilitated language change\nand calls for more language-aware interventions.", "comment": "Paper under review", "pdf_url": "http://arxiv.org/pdf/2507.15142v1", "cate": "cs.CL", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15336", "title": "Beyond Model Base Selection: Weaving Knowledge to Master Fine-grained Neural Network Design", "authors": ["Jialiang Wang", "Hanmo Liu", "Shimin Di", "Zhili Wang", "Jiachuan Wang", "Lei Chen", "Xiaofang Zhou"], "categories": ["cs.LG", "cs.AI", "cs.DB"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15336v1", "summary": "Database systems have recently advocated for embedding machine learning (ML)\ncapabilities, offering declarative model queries over large, managed model\nrepositories, thereby circumventing the huge computational overhead of\ntraditional ML-based algorithms in automated neural network model selection.\nPioneering database studies aim to organize existing benchmark repositories as\nmodel bases (MB), querying them for the model records with the highest\nperformance estimation metrics for given tasks. However, this static model\nselection practice overlooks the fine-grained, evolving relational dependencies\nbetween diverse task queries and model architecture variations, resulting in\nsuboptimal matches and failing to further refine the model effectively. To fill\nthe model refinement gap in database research, we propose M-DESIGN, a curated\nmodel knowledge base (MKB) pipeline for mastering neural network refinement by\nadaptively weaving prior insights about model architecture modification. First,\nwe propose a knowledge weaving engine that reframes model refinement as an\nadaptive query problem over task metadata. Given a user's task query, M-DESIGN\nquickly matches and iteratively refines candidate models by leveraging a\ngraph-relational knowledge schema that explicitly encodes data properties,\narchitecture variations, and pairwise performance deltas as joinable relations.\nThis schema supports fine-grained relational analytics over architecture tweaks\nand drives a predictive query planner that can detect and adapt to\nout-of-distribution (OOD) tasks. We instantiate M-DESIGN for graph analytics\ntasks, where our model knowledge base enriches existing benchmarks with\nstructured metadata covering 3 graph tasks and 22 graph datasets, contributing\ndata records of 67,760 graph models. Empirical results demonstrate that\nM-DESIGN delivers the optimal model in 26 of 33 data-task pairs within limited\nbudgets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15336v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15243", "title": "Cross-Domain Few-Shot Learning with Coalescent Projections and Latent Space Reservation", "authors": ["Naeem Paeedeh", "Mahardhika Pratama", "Wolfgang Mayer", "Jimmy Cao", "Ryszard Kowlczyk"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15243v1", "summary": "Despite the progress in Cross-Domain Few-Shot Learning (CD-FSL), a model\npre-trained with DINO combined with a prototypical classifier outperforms the\nlatest SOTA methods. A crucial limitation that needs to be overcome is that\nupdating too many parameters of the transformers leads to overfitting due to\nthe scarcity of labeled samples. To address this challenge, we propose a new\nconcept, Coalescent Projection (CP), as an effective successor to soft prompts.\nAdditionally, we propose a novel pseudo-class generation method combined with\nSelf-Supervised Transformations (SSTs) that relies solely on the base domain to\nprepare the network for encountering unseen samples from different domains. The\nproposed method exhibits its effectiveness in comprehensive experiments on the\nextreme domain shift scenario of the BSCD-FSL benchmark. Our code is published\nat https://github.com/Naeem-Paeedeh/CPLSR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15243v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2502.19643", "title": "Electromagnetically Reconfigurable Fluid Antenna System for Wireless Communications: Design, Modeling, Algorithm, Fabrication, and Experiment", "authors": ["Ruiqi Wang", "Pinjun Zheng", "Vijith Varma Kotte", "Sakandar Rauf", "Yiming Yang", "Muhammad Mahboob Ur Rahman", "Tareq Y. Al-Naffouri", "Atif Shamim"], "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.19643v3", "summary": "This paper presents the concept, design, channel modeling, beamforming\nalgorithm development, prototype fabrication, and experimental measurement of\nan electromagnetically reconfigurable fluid antenna system (ER-FAS), in which\neach FAS array element features electromagnetic (EM) reconfigurability. Unlike\nmost existing FAS works that investigate spatial reconfigurability by adjusting\nthe position and/or orientation of array elements, the proposed ER-FAS enables\ndirect control over the EM characteristics of each element, allowing for\ndynamic radiation pattern reconfigurability. Specifically, a novel ER-FAS\narchitecture leveraging software-controlled fluidics is proposed, and\ncorresponding wireless channel models are established. Based on this ER-FAS\nchannel model, a low-complexity greedy beamforming algorithm is developed to\njointly optimize the analog phase shift and the radiation state of each array\nelement. The accuracy of the ER-FAS channel model and the effectiveness of the\nbeamforming algorithm are validated through (i) full-wave EM simulations and\n(ii) numerical spectral efficiency evaluations. These results confirm that the\nproposed ER-FAS significantly enhances spectral efficiency in both near-field\nand far-field scenarios compared to conventional antenna arrays. To further\nvalidate this design, we fabricate prototypes for both the ER-FAS element and\narray, using Galinstan liquid metal alloy, fluid silver paste, and\nsoftware-controlled fluidic channels. The simulation results are experimentally\nvalidated through prototype measurements conducted in an anechoic chamber.\nAdditionally, several indoor communication experiments using a pair of\nsoftware-defined radios demonstrate the superior received power and bit error\nrate performance of the ER-FAS prototype.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.19643v3", "cate": "eess.SP", "date": "2025-02-27", "updated": "2025-07-20"}
{"id": "2507.15848", "title": "Iterative thresholding low-rank time integration", "authors": ["Markus Bachmayr", "Matthieu Dolbeault", "Polina Sachsenmaier"], "categories": ["math.NA", "cs.NA", "Primary 65F55, 65M12, Secondary 65Y20, 65L70"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      35 pages", "url": "http://arxiv.org/abs/2507.15848v1", "summary": "We develop time integration methods in low-rank representation that can\nadaptively adjust approximation ranks to achieve a prescribed accuracy, while\nensuring that these ranks remain proportional to the corresponding best\napproximation ranks. Our approach relies on an iterative scheme combined with\nsoft thresholding of the iterates. A model case of a time-dependent\nSchr\\\"odinger equation with low-rank matrix approximation is analyzed in\ndetail, and the required modifications for second-order parabolic problems are\ndescribed. Numerical tests illustrate the results for both cases.", "comment": "35 pages", "pdf_url": "http://arxiv.org/pdf/2507.15848v1", "cate": "math.NA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2404.09847", "title": "Statistical learning for constrained functional parameters in infinite-dimensional models", "authors": ["Razieh Nabi", "Nima S. Hejazi", "Mark J. van der Laan", "David Benkeser"], "categories": ["stat.ML", "cs.CY", "cs.LG", "stat.ME"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.09847v2", "summary": "We develop a general framework for estimating function-valued parameters\nunder equality or inequality constraints in infinite-dimensional statistical\nmodels. Such constrained learning problems are common across many areas of\nstatistics and machine learning, where estimated parameters must satisfy\nstructural requirements such as moment restrictions, policy benchmarks,\ncalibration criteria, or fairness considerations. To address these problems, we\ncharacterize the solution as the minimizer of a penalized population risk using\na Lagrange-type formulation, and analyze it through a statistical functional\nlens. Central to our approach is a constraint-specific path through the\nunconstrained parameter space that defines the constrained solutions. For a\nbroad class of constraint-risk pairs, this path admits closed-form expressions\nand reveals how constraints shape optimal adjustments. When closed forms are\nunavailable, we derive recursive representations that support tractable\nestimation. Our results also suggest natural estimators of the constrained\nparameter, constructed by combining estimates of unconstrained components of\nthe data-generating distribution. Thus, our procedure can be integrated with\nany statistical learning approach and implemented using standard software. We\nprovide general conditions under which the resulting estimators achieve optimal\nrisk and constraint satisfaction, and we demonstrate the flexibility and\neffectiveness of the proposed method through various examples, simulations, and\nreal-data applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.09847v2", "cate": "stat.ML", "date": "2024-04-15", "updated": "2025-07-18"}
{"id": "2507.15167", "title": "A New Ultrafast Printer for Large-Scale Assembly of Piezoelectric Biomaterials", "authors": ["Nan An", "Mingtong Chen", "Zhengbao Yang"], "categories": ["eess.SY", "cond-mat.mtrl-sci", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15167v1", "summary": "We propose a modular, fast and large-area fabrication of bio-piezoelectric\nfilms. The technique is based on the formation of cone-jet mode by applying a\nhigh voltage electric field to conductive spiked metal disks. And the\nself-assembly process of biomolecular materials through nanoconfinement with\nin-situ poling effect. This job achieved print speeds of up to 9.2 109 um3/s\nwith a combination of only 2 printheads. At the same time, the modular design\nallows the MLSP to achieve theoretically unlimited print efficiency. It also\nprovides flexible configuration options for different printing needs, such as\npreparing films of different areas and shapes. In short, MLSP demonstrates the\nability of piezoelectric biomaterials to undergo ultra-fast, large-scale\nassembly. Demonstrates good potential as a universally applicable bio-device\nfor the fabrication of bio-piezoelectric films", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15167v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15169", "title": "Energy consumption optimization and self-powered environmental monitoring design for low-carbon smart buildings", "authors": ["Yuhan Dai", "Mingtong Chen", "Zhengbao Yang"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15169v1", "summary": "Despite the growing emphasis on intelligent buildings as a cornerstone of\nsustainable urban development, significant energy inefficiencies persist due to\nsuboptimal design, material choices, and user behavior. The applicability of\nintegrated Building Information Modeling (BIM) and solarpowered environmental\nmonitoring systems for energy optimization in low-carbon smart buildings\nremains underexplored. Can BIM-driven design improvements, combined with\nphotovoltaic systems, achieve substantial energy savings while enabling\nself-powered environmental monitoring? This study conducts a case analysis on a\nretrofitted primary school building in Guangdong, China, utilizing BIM-based\nenergy simulations, material optimization, and solar technology integration.\nThe outcomes reveal that the proposed approach reduced annual energy\nconsumption by 40.68%, with lighting energy use decreasing by 36.59%. A rooftop\nphotovoltaic system demonstrated a payback period of 7.46 years while powering\nenvironmental sensors autonomously. Hardware system integrates sensors and an\nARDUINO-based controller to detect environmental factors like rainfall,\ntemperature, and air quality. It is powered by a 6W solar panel and a 2200\nmAh/7.4 V lithium battery to ensure stable operation. This study underscores\nthe potential of BIM and solar energy integration to transform traditional\nbuildings into energy-efficient, self-sustaining smart structures. Further\nresearch can expand the scalability of these methods across diverse climates\nand building typologies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15169v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15151", "title": "Performance Analysis of Post-Training Quantization for CNN-based Conjunctival Pallor Anemia Detection", "authors": ["Sebastian A. Cruz Romero", "Wilfredo E. Lugo Beauchamp"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted at International Symposium on Intelligent Computing & Networks 2025", "url": "http://arxiv.org/abs/2507.15151v1", "summary": "Anemia is a widespread global health issue, particularly among young children\nin low-resource settings. Traditional methods for anemia detection often\nrequire expensive equipment and expert knowledge, creating barriers to early\nand accurate diagnosis. To address these challenges, we explore the use of deep\nlearning models for detecting anemia through conjunctival pallor, focusing on\nthe CP-AnemiC dataset, which includes 710 images from children aged 6-59\nmonths. The dataset is annotated with hemoglobin levels, gender, age and other\ndemographic data, enabling the development of machine learning models for\naccurate anemia detection. We use the MobileNet architecture as a backbone,\nknown for its efficiency in mobile and embedded vision applications, and\nfine-tune our model end-to-end using data augmentation techniques and a\ncross-validation strategy. Our model implementation achieved an accuracy of\n0.9313, a precision of 0.9374, and an F1 score of 0.9773 demonstrating strong\nperformance on the dataset. To optimize the model for deployment on edge\ndevices, we performed post-training quantization, evaluating the impact of\ndifferent bit-widths (FP32, FP16, INT8, and INT4) on model performance.\nPreliminary results suggest that while FP16 quantization maintains high\naccuracy (0.9250), precision (0.9370), and F1 Score (0.9377), more aggressive\nquantization (INT8 and INT4) leads to significant performance degradation.\nOverall, our study supports further exploration of quantization schemes and\nhardware optimizations to assess trade-offs between model size, inference time,\nand diagnostic accuracy in mobile healthcare applications.", "comment": "Accepted at International Symposium on Intelligent Computing &\n  Networks 2025", "pdf_url": "http://arxiv.org/pdf/2507.15151v1", "cate": "eess.IV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15381", "title": "To Label or Not to Label: PALM -- A Predictive Model for Evaluating Sample Efficiency in Active Learning Models", "authors": ["Julia Machnio", "Mads Nielsen", "Mostafa Mehdipour Ghazi"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.15381v1", "summary": "Active learning (AL) seeks to reduce annotation costs by selecting the most\ninformative samples for labeling, making it particularly valuable in\nresource-constrained settings. However, traditional evaluation methods, which\nfocus solely on final accuracy, fail to capture the full dynamics of the\nlearning process. To address this gap, we propose PALM (Performance Analysis of\nActive Learning Models), a unified and interpretable mathematical model that\ncharacterizes AL trajectories through four key parameters: achievable accuracy,\ncoverage efficiency, early-stage performance, and scalability. PALM provides a\npredictive description of AL behavior from partial observations, enabling the\nestimation of future performance and facilitating principled comparisons across\ndifferent strategies. We validate PALM through extensive experiments on\nCIFAR-10/100 and ImageNet-50/100/200, covering a wide range of AL methods and\nself-supervised embeddings. Our results demonstrate that PALM generalizes\neffectively across datasets, budgets, and strategies, accurately predicting\nfull learning curves from limited labeled data. Importantly, PALM reveals\ncrucial insights into learning efficiency, data space coverage, and the\nscalability of AL methods. By enabling the selection of cost-effective\nstrategies and predicting performance under tight budget constraints, PALM lays\nthe basis for more systematic, reproducible, and data-efficient evaluation of\nAL in both research and real-world applications. The code is available at:\nhttps://github.com/juliamachnio/PALM.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.15381v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15249", "title": "FreeCus: Free Lunch Subject-driven Customization in Diffusion Transformers", "authors": ["Yanbing Zhang", "Zhe Wang", "Qin Zhou", "Mengping Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.15249v1", "summary": "In light of recent breakthroughs in text-to-image (T2I) generation,\nparticularly with diffusion transformers (DiT), subject-driven technologies are\nincreasingly being employed for high-fidelity customized production that\npreserves subject identity from reference inputs, enabling thrilling design\nworkflows and engaging entertainment. Existing alternatives typically require\neither per-subject optimization via trainable text embeddings or training\nspecialized encoders for subject feature extraction on large-scale datasets.\nSuch dependencies on training procedures fundamentally constrain their\npractical applications. More importantly, current methodologies fail to fully\nleverage the inherent zero-shot potential of modern diffusion transformers\n(e.g., the Flux series) for authentic subject-driven synthesis. To bridge this\ngap, we propose FreeCus, a genuinely training-free framework that activates\nDiT's capabilities through three key innovations: 1) We introduce a pivotal\nattention sharing mechanism that captures the subject's layout integrity while\npreserving crucial editing flexibility. 2) Through a straightforward analysis\nof DiT's dynamic shifting, we propose an upgraded variant that significantly\nimproves fine-grained feature extraction. 3) We further integrate advanced\nMultimodal Large Language Models (MLLMs) to enrich cross-modal semantic\nrepresentations. Extensive experiments reflect that our method successfully\nunlocks DiT's zero-shot ability for consistent subject synthesis across diverse\ncontexts, achieving state-of-the-art or comparable results compared to\napproaches that require additional training. Notably, our framework\ndemonstrates seamless compatibility with existing inpainting pipelines and\ncontrol modules, facilitating more compelling experiences. Our code is\navailable at: https://github.com/Monalissaa/FreeCus.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.15249v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2504.18143", "title": "Full-Duplex Integrated Sensing, Communication, and Computation over Low-Altitude Wireless Networks", "authors": ["Yiyang Chen", "Wenchao Liu", "Xuhui Zhang", "Jinke Ren", "Huijun Xing", "Shuqiang Wang", "Yanyan Shen", "Kim-Fung Tsang"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      This manuscript has been submitted to IEEE", "url": "http://arxiv.org/abs/2504.18143v2", "summary": "With low-altitude economies emerging as a pivotal sector, this study explores\nan integrated sensing, communication, and computation system over low-altitude\nwireless networks. A full-duplex autonomous aerial vehicle (AAV) operates as an\nAAV-enabled low-altitude platform (ALAP), concurrently executing data\ntransmission, target sensing, and mobile edge computing services. To minimize\nsystemic energy consumption under sensing beampattern constraints and\ncomputational demands, we formulate an optimization problem coordinating task\nallocation, computation resource allocation, and transmit/receive beamforming.\nGiven the non-convexity and highly variable coupling, an efficient iterative\nconvex approximation framework based on alternating optimization decomposes the\nproblem into tractable subproblems. Moreover, the convergence and computational\ncomplexity of the proposed algorithm are rigorously analyzed. Simulations\nverify up to 54.12\\% energy savings versus benchmarks.", "comment": "This manuscript has been submitted to IEEE", "pdf_url": "http://arxiv.org/pdf/2504.18143v2", "cate": "eess.SP", "date": "2025-04-25", "updated": "2025-07-21"}
{"id": "2507.15662", "title": "Sensor network localization has a benign landscape after low-dimensional relaxation", "authors": ["Christopher Criscitiello", "Andrew D. McRae", "Quentin Rebjock", "Nicolas Boumal"], "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15662v1", "summary": "We consider the sensor network localization problem, also known as\nmultidimensional scaling or Euclidean distance matrix completion. Given a\nground truth configuration of $n$ points in $\\mathbb{R}^\\ell$, we observe a\nsubset of the pairwise distances and aim to recover the underlying\nconfiguration (up to rigid transformations). We show with a simple\ncounterexample that the associated optimization problem is nonconvex and may\nadmit spurious local minimizers, even when all distances are known. Yet,\ninspired by numerical experiments, we argue that all second-order critical\npoints become global minimizers when the problem is relaxed by optimizing over\nconfigurations in dimension $k > \\ell$. Specifically, we show this for two\nsettings, both when all pairwise distances are known: (1) for arbitrary ground\ntruth points, and $k= O(\\sqrt{\\ell n})$, and: (2) for isotropic random ground\ntruth points, and $k = O(\\ell + \\log n)$. To prove these results, we identify\nand exploit key properties of the linear map which sends inner products to\nsquared distances.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15662v1", "cate": "math.OC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2502.15873", "title": "Practical Principles for AI Cost and Compute Accounting", "authors": ["Stephen Casper", "Luke Bailey", "Tim Schreier"], "categories": ["cs.AI", "cs.CY"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted to the ICML 2025 TAIG Workshop", "url": "http://arxiv.org/abs/2502.15873v4", "summary": "Policymakers increasingly use development cost and compute as proxies for AI\ncapabilities and risks. Recent laws have introduced regulatory requirements for\nmodels or developers that are contingent on specific thresholds. However,\ntechnical ambiguities in how to perform this accounting create loopholes that\ncan undermine regulatory effectiveness. We propose seven principles for\ndesigning AI cost and compute accounting standards that (1) reduce\nopportunities for strategic gaming, (2) avoid disincentivizing responsible risk\nmitigation, and (3) enable consistent implementation across companies and\njurisdictions.", "comment": "Accepted to the ICML 2025 TAIG Workshop", "pdf_url": "http://arxiv.org/pdf/2502.15873v4", "cate": "cs.AI", "date": "2025-02-21", "updated": "2025-07-20"}
{"id": "2507.15259", "title": "Physics-Informed Learning of Proprietary Inverter Models for Grid Dynamic Studies", "authors": ["Kyung-Bin Kwon", "Sayak Mukherjee", "Ramij R. Hossain", "Marcelo Elizondo"], "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      7 pages, 5 figures", "url": "http://arxiv.org/abs/2507.15259v1", "summary": "This letter develops a novel physics-informed neural ordinary differential\nequations-based framework to emulate the proprietary dynamics of the inverters\n-- essential for improved accuracy in grid dynamic simulations. In current\nindustry practice, the original equipment manufacturers (OEMs) often do not\ndisclose the exact internal controls and parameters of the inverters, posing\nsignificant challenges in performing accurate dynamic simulations and other\nrelevant studies, such as gain tunings for stability analysis and controls. To\naddress this, we propose a Physics-Informed Latent Neural ODE Model (PI-LNM)\nthat integrates system physics with neural learning layers to capture the\nunmodeled behaviors of proprietary units. The proposed method is validated\nusing a grid-forming inverter (GFM) case study, demonstrating improved dynamic\nsimulation accuracy over approaches that rely solely on data-driven learning\nwithout physics-based guidance.", "comment": "7 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.15259v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15261", "title": "Dual-Channel Adaptive NMPC for Quadrotor under Instantaneous Impact and Payload Disturbances", "authors": ["Xinqi Chen", "Xiuxian Li", "Min Meng"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15261v1", "summary": "Capturing target objects using the quadrotor has gained increasing popularity\nin recent years, but most studies focus on capturing lightweight objects. The\ninstantaneous contact force generated when capturing objects of a certain mass,\nalong with the payload uncertainty after attachment, will pose significant\nchallenges to the quadrotor control. This paper proposes a novel control\narchitecture, namely Dual-Channel Adaptive Nonlinear Model Predictive Control\n(DCA-NMPC), which cascades a nonlinear model predictive control with two\nlower-level model reference adaptive controllers and can resist drastic impact\nand adapt to uncertain inertial parameters. Numerical simulation experiments\nare performed for validation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15261v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15152", "title": "What Level of Automation is \"Good Enough\"? A Benchmark of Large Language Models for Meta-Analysis Data Extraction", "authors": ["Lingbo Li", "Anuradha Mathrani", "Teo Susnjak"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15152v1", "summary": "Automating data extraction from full-text randomised controlled trials (RCTs)\nfor meta-analysis remains a significant challenge. This study evaluates the\npractical performance of three LLMs (Gemini-2.0-flash, Grok-3, GPT-4o-mini)\nacross tasks involving statistical results, risk-of-bias assessments, and\nstudy-level characteristics in three medical domains: hypertension, diabetes,\nand orthopaedics. We tested four distinct prompting strategies (basic\nprompting, self-reflective prompting, model ensemble, and customised prompts)\nto determine how to improve extraction quality. All models demonstrate high\nprecision but consistently suffer from poor recall by omitting key information.\nWe found that customised prompts were the most effective, boosting recall by up\nto 15\\%. Based on this analysis, we propose a three-tiered set of guidelines\nfor using LLMs in data extraction, matching data types to appropriate levels of\nautomation based on task complexity and risk. Our study offers practical advice\nfor automating data extraction in real-world meta-analyses, balancing LLM\nefficiency with expert oversight through targeted, task-specific automation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15152v1", "cate": "cs.CL", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15397", "title": "MAP Estimation with Denoisers: Convergence Rates and Guarantees", "authors": ["Scott Pesme", "Giacomo Meanti", "Michael Arbel", "Julien Mairal"], "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15397v1", "summary": "Denoiser models have become powerful tools for inverse problems, enabling the\nuse of pretrained networks to approximate the score of a smoothed prior\ndistribution. These models are often used in heuristic iterative schemes aimed\nat solving Maximum a Posteriori (MAP) optimisation problems, where the proximal\noperator of the negative log-prior plays a central role. In practice, this\noperator is intractable, and practitioners plug in a pretrained denoiser as a\nsurrogate-despite the lack of general theoretical justification for this\nsubstitution. In this work, we show that a simple algorithm, closely related to\nseveral used in practice, provably converges to the proximal operator under a\nlog-concavity assumption on the prior $p$. We show that this algorithm can be\ninterpreted as a gradient descent on smoothed proximal objectives. Our analysis\nthus provides a theoretical foundation for a class of empirically successful\nbut previously heuristic methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15397v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15257", "title": "MinCD-PnP: Learning 2D-3D Correspondences with Approximate Blind PnP", "authors": ["Pei An", "Jiaqi Yang", "Muyao Peng", "You Yang", "Qiong Liu", "Xiaolin Wu", "Liangliang Nan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.15257v1", "summary": "Image-to-point-cloud (I2P) registration is a fundamental problem in computer\nvision, focusing on establishing 2D-3D correspondences between an image and a\npoint cloud. The differential perspective-n-point (PnP) has been widely used to\nsupervise I2P registration networks by enforcing the projective constraints on\n2D-3D correspondences. However, differential PnP is highly sensitive to noise\nand outliers in the predicted correspondences. This issue hinders the\neffectiveness of correspondence learning. Inspired by the robustness of blind\nPnP against noise and outliers in correspondences, we propose an approximated\nblind PnP based correspondence learning approach. To mitigate the high\ncomputational cost of blind PnP, we simplify blind PnP to an amenable task of\nminimizing Chamfer distance between learned 2D and 3D keypoints, called\nMinCD-PnP. To effectively solve MinCD-PnP, we design a lightweight multi-task\nlearning module, named as MinCD-Net, which can be easily integrated into the\nexisting I2P registration architectures. Extensive experiments on 7-Scenes,\nRGBD-V2, ScanNet, and self-collected datasets demonstrate that MinCD-Net\noutperforms state-of-the-art methods and achieves a higher inlier ratio (IR)\nand registration recall (RR) in both cross-scene and cross-dataset settings.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.15257v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2505.04085", "title": "Device-Free Localization Using Multi-Link MIMO Channels in Distributed Antenna Networks", "authors": ["Minseok Kim", "Gesi Teng", "Keita Nishi", "Togo Ikegami", "Masamune Sato"], "categories": ["eess.SP", "eess.IV"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.04085v2", "summary": "Targeting integrated sensing and communication (ISAC) in future 6G radio\naccess networks (RANs), this paper presents a novel device-free localization\n(DFL) framework based on distributed antenna networks (DANs). In the proposed\napproach, radio tomographic imaging (RTI) leverages the spatial and temporal\ndiversity of multi-link multiple-input multiple-output (MIMO) channels in DANs\nto achieve accurate localization. Furthermore, a prototype system was developed\nusing software-defined radios (SDRs) operating in the sub-6 GHz band, and\ncomprehensive evaluations were conducted under indoor conditions involving\nvarying node densities and target types. The results demonstrate that the\nframework achieves sub-meter localization accuracy in most scenarios and\nmaintains robust performance under complex multipath environments. In addition,\nthe use of Bayesian optimization to fine-tune key parameters, such as sparsity\nand path thickness, led to significant improvements in image reconstruction\nquality and target estimation accuracy. These results demonstrate the\nfeasibility and effectiveness of DAN-based DFL as a scalable and\ninfrastructure-compatible ISAC solution, capable of delivering accurate,\npassive localization without dedicated sensing hardware.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.04085v2", "cate": "eess.SP", "date": "2025-05-07", "updated": "2025-07-21"}
{"id": "2507.15740", "title": "Minimal horizontal triods: Analysis and computation", "authors": ["Robert Nürnberg", "Paola Pozzi"], "categories": ["math.AP", "cs.NA", "math.DG", "math.NA"], "primary_category": "Subjects:       Analysis of PDEs (math.AP)", "pdf_link": null, "comments": "Comments:      35 pages, 16 figures", "url": "http://arxiv.org/abs/2507.15740v1", "summary": "In this article we investigate the question of finding a network\nconfiguration of minimal length connecting three given points in the Heisenberg\ngroup. After proving existence of (possibly degenerate) minimal horizontal\ntriods, we investigate their characterization. We then formulate a horizontal\ncurve shortening flow that deforms any given suitable initial triod into a\ncritical point for the length functional. Numerical experiments based on a\nstable fully discrete finite element scheme provide useful insights into the\nrich landscape of this sub-Riemannian geometry.", "comment": "35 pages, 16 figures", "pdf_url": "http://arxiv.org/pdf/2507.15740v1", "cate": "math.AP", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2505.09287", "title": "Ranking-Based At-Risk Student Prediction Using Federated Learning and Differential Features", "authors": ["Shunsuke Yoneda", "Valdemar Švábenský", "Gen Li", "Daisuke Deguchi", "Atsushi Shimada"], "categories": ["cs.LG", "cs.CY", "I.2; I.6; K.3"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published in the Proceedings of the 18th Educational Data Mining Conference (EDM 2025), see this https URL", "url": "http://arxiv.org/abs/2505.09287v2", "summary": "Digital textbooks are widely used in various educational contexts, such as\nuniversity courses and online lectures. Such textbooks yield learning log data\nthat have been used in numerous educational data mining (EDM) studies for\nstudent behavior analysis and performance prediction. However, these studies\nhave faced challenges in integrating confidential data, such as academic\nrecords and learning logs, across schools due to privacy concerns.\nConsequently, analyses are often conducted with data limited to a single\nschool, which makes developing high-performing and generalizable models\ndifficult. This study proposes a method that combines federated learning and\ndifferential features to address these issues. Federated learning enables model\ntraining without centralizing data, thereby preserving student privacy.\nDifferential features, which utilize relative values instead of absolute\nvalues, enhance model performance and generalizability. To evaluate the\nproposed method, a model for predicting at-risk students was trained using data\nfrom 1,136 students across 12 courses conducted over 4 years, and validated on\nhold-out test data from 5 other courses. Experimental results demonstrated that\nthe proposed method addresses privacy concerns while achieving performance\ncomparable to that of models trained via centralized learning in terms of Top-n\nprecision, nDCG, and PR-AUC. Furthermore, using differential features improved\nprediction performance across all evaluation datasets compared to\nnon-differential approaches. The trained models were also applicable for early\nprediction, achieving high performance in detecting at-risk students in earlier\nstages of the semester within the validation datasets.", "comment": "Published in the Proceedings of the 18th Educational Data Mining\n  Conference (EDM 2025), see https://zenodo.org/records/15870193", "pdf_url": "http://arxiv.org/pdf/2505.09287v2", "cate": "cs.LG", "date": "2025-05-14", "updated": "2025-07-21"}
{"id": "2507.15307", "title": "Joint Optimisation of Electric Vehicle Routing and Scheduling: A Deep Learning-Driven Approach for Dynamic Fleet Sizes", "authors": ["Jun Kang Yap", "Vishnu Monn Baskaran", "Wen Shan Tan", "Ze Yang Ding", "Hao Wang", "David L. Dowe"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Accepted at International Joint Conference on Neural Networks (IJCNN 2025)", "url": "http://arxiv.org/abs/2507.15307v1", "summary": "Electric Vehicles (EVs) are becoming increasingly prevalent nowadays, with\nstudies highlighting their potential as mobile energy storage systems to\nprovide grid support. Realising this potential requires effective charging\ncoordination, which are often formulated as mixed-integer programming (MIP)\nproblems. However, MIP problems are NP-hard and often intractable when applied\nto time-sensitive tasks. To address this limitation, we propose a deep learning\nassisted approach for optimising a day-ahead EV joint routing and scheduling\nproblem with varying number of EVs. This problem simultaneously optimises EV\nrouting, charging, discharging and generator scheduling within a distribution\nnetwork with renewable energy sources. A convolutional neural network is\ntrained to predict the binary variables, thereby reducing the solution search\nspace and enabling solvers to determine the remaining variables more\nefficiently. Additionally, a padding mechanism is included to handle the\nchanges in input and output sizes caused by varying number of EVs, thus\neliminating the need for re-training. In a case study on the IEEE 33-bus system\nand Nguyen-Dupuis transportation network, our approach reduced runtime by 97.8%\nwhen compared to an unassisted MIP solver, while retaining 99.5% feasibility\nand deviating less than 0.01% from the optimal solution.", "comment": "Accepted at International Joint Conference on Neural Networks (IJCNN\n  2025)", "pdf_url": "http://arxiv.org/pdf/2507.15307v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15344", "title": "RoCoF Constrained Regional Inertia Security Region: Formulation and Application", "authors": ["Jiahao Liu", "Cheng Wang", "Tianshu Bi"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15344v1", "summary": "The regional inertia, which determines the regional rate of change of\nfrequency (RoCoF), should be kept in a secure status in renewable-penetrated\npower systems. To break away from mapping the regional maximum RoCoF with\nregional inertia in a linearized form, this paper comprehensively studies the\nregional inertia security problem from formulation to applications. Firstly,\nthe regional inertia security region (R-ISR) is defined, whose boundary is\nnon-linear and non-convex. Then, a local linearized method is devised to\ncalculate the global maximum of regional RoCoF. The non-convex ISR boundary is\nexpressed by multiple simple boundaries corresponding to each local solution,\nwhich can be obtained by a simple search-based method. Finally, the convexified\nR-ISR constraint is formed by convex decomposition and embedded in an inertia\noptimal adjustment model. The results on a 3-region system show some\ncounter-intuitive findings, such as increasing the inertia of one region may\nworsen its RoCoF.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15344v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15193", "title": "A Study of Anatomical Priors for Deep Learning-Based Segmentation of Pheochromocytoma in Abdominal CT", "authors": ["Tanjin Taher Toma", "Tejas Sudharshan Mathai", "Bikash Santra", "Pritam Mukherjee", "Jianfei Liu", "Wesley Jong", "Darwish Alabyad", "Vivek Batheja", "Abhishek Jha", "Mayank Patel", "Darko Pucar", "Jayadira del Rivero", "Karel Pacak", "Ronald M. Summers"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15193v1", "summary": "Accurate segmentation of pheochromocytoma (PCC) in abdominal CT scans is\nessential for tumor burden estimation, prognosis, and treatment planning. It\nmay also help infer genetic clusters, reducing reliance on expensive testing.\nThis study systematically evaluates anatomical priors to identify\nconfigurations that improve deep learning-based PCC segmentation. We employed\nthe nnU-Net framework to evaluate eleven annotation strategies for accurate 3D\nsegmentation of pheochromocytoma, introducing a set of novel multi-class\nschemes based on organ-specific anatomical priors. These priors were derived\nfrom adjacent organs commonly surrounding adrenal tumors (e.g., liver, spleen,\nkidney, aorta, adrenal gland, and pancreas), and were compared against a broad\nbody-region prior used in previous work. The framework was trained and tested\non 105 contrast-enhanced CT scans from 91 patients at the NIH Clinical Center.\nPerformance was measured using Dice Similarity Coefficient (DSC), Normalized\nSurface Distance (NSD), and instance-wise F1 score. Among all strategies, the\nTumor + Kidney + Aorta (TKA) annotation achieved the highest segmentation\naccuracy, significantly outperforming the previously used Tumor + Body (TB)\nannotation across DSC (p = 0.0097), NSD (p = 0.0110), and F1 score (25.84%\nimprovement at an IoU threshold of 0.5), measured on a 70-30 train-test split.\nThe TKA model also showed superior tumor burden quantification (R^2 = 0.968)\nand strong segmentation across all genetic subtypes. In five-fold\ncross-validation, TKA consistently outperformed TB across IoU thresholds (0.1\nto 0.5), reinforcing its robustness and generalizability. These findings\nhighlight the value of incorporating relevant anatomical context in deep\nlearning models to achieve precise PCC segmentation, supporting clinical\nassessment and longitudinal monitoring.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15193v1", "cate": "eess.IV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15431", "title": "The calculus of variations of the Transformer on the hyperspherical tangent bundle", "authors": ["Andrew Gracyk"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      First version", "url": "http://arxiv.org/abs/2507.15431v1", "summary": "We offer a theoretical mathematical background to Transformers through\nLagrangian optimization across the token space. The Transformer, as a flow map,\nexists in the tangent fiber for each token along the high-dimensional unit\nsphere. The circumstance of the hypersphere across the latent data is\nreasonable due to the trained diagonal matrix equal to the identity, which has\nvarious empirical justifications. Thus, under the continuum limit of the\ndynamics, the latent vectors flow among the tangent bundle. Using these facts,\nwe devise a mathematical framework for the Transformer through calculus of\nvariations. We develop a functional and show that the continuous flow map\ninduced by the Transformer satisfies this functional, therefore the Transformer\ncan be viewed as a natural solver of a calculus of variations problem. We\ninvent new scenarios of when our methods are applicable based on loss\noptimization with respect to path optimality. We derive the Euler-Lagrange\nequation for the Transformer. The variant of the Euler-Lagrange equation we\npresent has various appearances in literature, but, to our understanding,\noftentimes not foundationally proven or under other specialized cases. Our\noverarching proof is new: our techniques are classical and the use of the flow\nmap object is original. We provide several other relevant results, primarily\nones specific to neural scenarios. In particular, much of our analysis will be\nattempting to quantify Transformer data in variational contexts under neural\napproximations. Calculus of variations on manifolds is a well-nourished\nresearch area, but for the Transformer specifically, it is uncharted: we lay\nthe foundation for this area through an introduction to the Lagrangian for the\nTransformer.", "comment": "First version", "pdf_url": "http://arxiv.org/pdf/2507.15431v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15269", "title": "Conditional Video Generation for High-Efficiency Video Compression", "authors": ["Fangqiu Yi", "Jingyu Xu", "Jiawei Shao", "Chi Zhang", "Xuelong Li"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15269v1", "summary": "Perceptual studies demonstrate that conditional diffusion models excel at\nreconstructing video content aligned with human visual perception. Building on\nthis insight, we propose a video compression framework that leverages\nconditional diffusion models for perceptually optimized reconstruction.\nSpecifically, we reframe video compression as a conditional generation task,\nwhere a generative model synthesizes video from sparse, yet informative\nsignals. Our approach introduces three key modules: (1) Multi-granular\nconditioning that captures both static scene structure and dynamic\nspatio-temporal cues; (2) Compact representations designed for efficient\ntransmission without sacrificing semantic richness; (3) Multi-condition\ntraining with modality dropout and role-aware embeddings, which prevent\nover-reliance on any single modality and enhance robustness. Extensive\nexperiments show that our method significantly outperforms both traditional and\nneural codecs on perceptual quality metrics such as Fr\\'echet Video Distance\n(FVD) and LPIPS, especially under high compression ratios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15269v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2506.12599", "title": "A Smooshed BMOCZ Zero Constellation for CFO Estimation Without Channel Coding", "authors": ["Anthony Joseph Perre", "Parker Huggins", "Alphan Sahin"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      This work has been accepted for presentation at IEEE PIMRC 2025", "url": "http://arxiv.org/abs/2506.12599v3", "summary": "In this study, we propose a new binary modulation on conjugate-reciprocal\nzeros (BMOCZ) zero constellation, which we call smooshed binary modulation on\nconjugate-reciprocal zeros (SBMOCZ), to address carrier frequency offset\n(CFO)-induced zero rotation without depending on channel coding. In our\napproach, we modify the phase mapping of Huffman BMOCZ by shrinking the angle\nbetween adjacent zeros, except for the first and last, to introduce a gap in\nthe zero constellation. By discerning the gap location in the received\npolynomial, the receiver can estimate and correct the phase rotation. We\ndemonstrate the error rate performance of SBMOCZ relative to Huffman BMOCZ,\nshowing that SBMOCZ addresses a CFO-induced rotation at the cost of a modest\nperformance reduction compared to Huffman BMOCZ in the absence of a CFO.\nFinally, we compare SBMOCZ to Huffman BMOCZ using a cyclically permutable code\n(CPC), showing a 4 dB bit error rate (BER) improvement in a fading channel,\nwhile demonstrating comparable performance across other simulations.", "comment": "This work has been accepted for presentation at IEEE PIMRC 2025", "pdf_url": "http://arxiv.org/pdf/2506.12599v3", "cate": "eess.SP", "date": "2025-06-14", "updated": "2025-07-20"}
{"id": "2507.15762", "title": "Generic cuspidal points and their localization", "authors": ["Luca Dieci", "Alessandro Pugliese"], "categories": ["math.RA", "cs.NA", "math.NA", "15A18, 15A20, 15A23, 15A99"], "primary_category": "Subjects:       Rings and Algebras (math.RA)", "pdf_link": null, "comments": "Comments:      24 pages, 4 figures", "url": "http://arxiv.org/abs/2507.15762v1", "summary": "In this work we consider generic coalescing of eigenvalues of smooth complex\nvalued matrix functions depending on 2 parameters. We call generic cuspidal\npoints the parameter values where eigenvalues coalesce and we discuss the\nrelation between cuspidal points and the closely related exceptional points\nstudied in the literature. By considering loops in parameter space enclosing\nthe cuspidal points, we rigorously prove when there is a phase accumulation for\nthe eigenvectors and further detail how, by looking at the periodicity of the\neigenvalues along the loop, and/or by looking at the aforementioned phase\naccumulation, one may be able to localize generic cuspidal points.", "comment": "24 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.15762v1", "cate": "math.RA", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2506.12403", "title": "Bridging the Digital Divide: Small Language Models as a Pathway for Physics and Photonics Education in Underdeveloped Regions", "authors": ["Asghar Ghorbani", "Hanieh Fattahi"], "categories": ["physics.ed-ph", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Physics Education (physics.ed-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.12403v2", "summary": "Limited infrastructure, scarce educational resources, and unreliable internet\naccess often hinder physics and photonics education in underdeveloped regions.\nThese barriers create deep inequities in Science, Technology, Engineering, and\nMathematics (STEM) education. This article explores how Small Language Models\n(SLMs)-compact, AI-powered tools that can run offline on low-power devices,\noffering a scalable solution. By acting as virtual tutors, enabling\nnative-language instruction, and supporting interactive learning, SLMs can help\naddress the shortage of trained educators and laboratory access. By narrowing\nthe digital divide through targeted investment in AI technologies, SLMs present\na scalable and inclusive solution to advance STEM education and foster\nscientific empowerment in marginalized communities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.12403v2", "cate": "physics.ed-ph", "date": "2025-06-14", "updated": "2025-07-19"}
{"id": "2507.15358", "title": "Revisiting the Effect of Grid-Following Converter on Frequency Dynamics -- Part I: Center of Inertia", "authors": ["Jiahao Liu", "Cheng Wang", "Tianshu Bi"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15358v1", "summary": "Understanding the impact of grid-following (GFL) converters on system\nfrequency dynamics is crucial, from both the center of inertia (COI) and\nfrequency spatial variation perspectives. Part I of this series clarifies the\nmechanisms by which GFLs influence COI frequency dynamics. A multi-generator\nmodel of the power system with GFLs is developed, incorporating the local\ndynamics of GFLs and their interaction with synchronous generators via virtual\ntie lines. By aggregating the multi-generator model into the COI frame, the\ninteraction between the COI frequency and the equivalent frequency of GFLs is\nrevealed. The equivalent inertia and other components at the GFL side,\ndetermined by control parameters and operating conditions, support the COI\nthrough virtual tying power. Simulation validates the accuracy of the proposed\nmodeling and demonstrates that the impact of GFLs on COI frequency is\nrelatively weak. The equivalent inertia and other components of GFLs still\nsignificantly influence COI frequency dynamics, with their effects being both\ntime-variable and adjustable.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15358v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15362", "title": "Revisiting the Effect of Grid-Following Converter on Frequency Dynamics -- Part II: Spatial Variation", "authors": ["Jiahao Liu", "Cheng Wang", "Tianshu Bi"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15362v1", "summary": "Besides the center of inertia (COI) frequency dynamics addressed in Part I,\nthe spatial frequency variation in power systems with grid-following (GFL)\nconverters is also crucial. Part II revisits the effect of GFLs on frequency\nspatial variation. Leveraging the interfacing state variables and equivalent\nfrequency defined in Part I, an extended frequency divider (FD) formula is\nproposed. The linearized mapping relationship between network node frequency\nand synchronous generator (SG) rotor frequency, as well as GFL equivalent\nfrequency, is modeled. The superposition contribution from GFLs is determined\nby the electrical distance between the generator and the frequency observation\nnode, as well as the system power flow conditions. Additionally, the frequency\nmapping for branch currents, which is overlooked in previous research, is\naddressed. Simulation results validate the accuracy of the proposed extended FD\nformula. They quantitatively demonstrate that the superposition contribution of\nGFLs to node frequency is relatively weak and that the superposition\ncoefficient is time-varying. The branch frequency superposition reveals a\ncomplex and distinctly different pattern.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15362v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15281", "title": "A Novel Self-Evolution Framework for Large Language Models", "authors": ["Haoran Sun", "Zekun Zhang", "Shaoning Zeng"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15281v1", "summary": "The capabilities of Large Language Models (LLMs) are limited to some extent\nby pre-training, so some researchers optimize LLMs through post-training.\nExisting post-training strategies, such as memory-based retrieval or preference\noptimization, improve user alignment yet fail to enhance the model's domain\ncognition. To bridge this gap, we propose a novel Dual-Phase Self-Evolution\n(DPSE) framework that jointly optimizes user preference adaptation and\ndomain-specific competence. DPSE introduces a Censor module to extract\nmulti-dimensional interaction signals and estimate satisfaction scores, which\nguide structured data expansion via topic-aware and preference-driven\nstrategies. These expanded datasets support a two-stage fine-tuning pipeline:\nsupervised domain grounding followed by frequency-aware preference\noptimization. Experiments across general NLP benchmarks and long-term dialogue\ntasks demonstrate that DPSE consistently outperforms Supervised Fine-Tuning,\nPreference Optimization, and Memory-Augmented baselines. Ablation studies\nvalidate the contribution of each module. In this way, our framework provides\nan autonomous path toward continual self-evolution of LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15281v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15442", "title": "An Adaptive Random Fourier Features approach Applied to Learning Stochastic Differential Equations", "authors": ["Owen Douglas", "Aku Kammonen", "Anamika Pandey", "Raúl Tempone"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      20 Pages", "url": "http://arxiv.org/abs/2507.15442v1", "summary": "This work proposes a training algorithm based on adaptive random Fourier\nfeatures (ARFF) with Metropolis sampling and resampling\n\\cite{kammonen2024adaptiverandomfourierfeatures} for learning drift and\ndiffusion components of stochastic differential equations from snapshot data.\nSpecifically, this study considers It\\^{o} diffusion processes and a\nlikelihood-based loss function derived from the Euler-Maruyama integration\nintroduced in \\cite{Dietrich2023} and\n\\cite{dridi2021learningstochasticdynamicalsystems}.\n  This work evaluates the proposed method against benchmark problems presented\nin \\cite{Dietrich2023}, including polynomial examples, underdamped Langevin\ndynamics, a stochastic susceptible-infected-recovered model, and a stochastic\nwave equation. Across all cases, the ARFF-based approach matches or surpasses\nthe performance of conventional Adam-based optimization in both loss\nminimization and convergence speed. These results highlight the potential of\nARFF as a compelling alternative for data-driven modeling of stochastic\ndynamics.", "comment": "20 Pages", "pdf_url": "http://arxiv.org/pdf/2507.15442v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15285", "title": "In-context Learning of Vision Language Models for Detection of Physical and Digital Attacks against Face Recognition Systems", "authors": ["Lazaro Janier Gonzalez-Soler", "Maciej Salwowski", "Christoph Busch"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Submitted to IEEE-TIFS", "url": "http://arxiv.org/abs/2507.15285v1", "summary": "Recent advances in biometric systems have significantly improved the\ndetection and prevention of fraudulent activities. However, as detection\nmethods improve, attack techniques become increasingly sophisticated. Attacks\non face recognition systems can be broadly divided into physical and digital\napproaches. Traditionally, deep learning models have been the primary defence\nagainst such attacks. While these models perform exceptionally well in\nscenarios for which they have been trained, they often struggle to adapt to\ndifferent types of attacks or varying environmental conditions. These\nsubsystems require substantial amounts of training data to achieve reliable\nperformance, yet biometric data collection faces significant challenges,\nincluding privacy concerns and the logistical difficulties of capturing diverse\nattack scenarios under controlled conditions. This work investigates the\napplication of Vision Language Models (VLM) and proposes an in-context learning\nframework for detecting physical presentation attacks and digital morphing\nattacks in biometric systems. Focusing on open-source models, the first\nsystematic framework for the quantitative evaluation of VLMs in\nsecurity-critical scenarios through in-context learning techniques is\nestablished. The experimental evaluation conducted on freely available\ndatabases demonstrates that the proposed subsystem achieves competitive\nperformance for physical and digital attack detection, outperforming some of\nthe traditional CNNs without resource-intensive training. The experimental\nresults validate the proposed framework as a promising tool for improving\ngeneralisation in attack detection.", "comment": "Submitted to IEEE-TIFS", "pdf_url": "http://arxiv.org/pdf/2507.15285v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.12630", "title": "Achieving Robust Channel Estimation Neural Networks by Designed Training Data", "authors": ["Dianxin Luan", "John Thompson"], "categories": ["eess.SP", "cs.AI"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE Transactions on Cognitive Communications and Networking (TCCN)", "url": "http://arxiv.org/abs/2507.12630v2", "summary": "Channel estimation is crucial in wireless communications. However, in many\npapers neural networks are frequently tested by training and testing on one\nexample channel or similar channels. This is because data-driven methods often\ndegrade on new data which they are not trained on, as they cannot extrapolate\ntheir training knowledge. This is despite the fact physical channels are often\nassumed to be time-variant. However, due to the low latency requirements and\nlimited computing resources, neural networks may not have enough time and\ncomputing resources to execute online training to fine-tune the parameters.\nThis motivates us to design offline-trained neural networks that can perform\nrobustly over wireless channels, but without any actual channel information\nbeing known at design time. In this paper, we propose design criteria to\ngenerate synthetic training datasets for neural networks, which guarantee that\nafter training the resulting networks achieve a certain mean squared error\n(MSE) on new and previously unseen channels. Therefore, trained neural networks\nrequire no prior channel information or parameters update for real-world\nimplementations. Based on the proposed design criteria, we further propose a\nbenchmark design which ensures intelligent operation for different channel\nprofiles. To demonstrate general applicability, we use neural networks with\ndifferent levels of complexity to show that the generalization achieved appears\nto be independent of neural network architecture. From simulations, neural\nnetworks achieve robust generalization to wireless channels with both fixed\nchannel profiles and variable delay spreads.", "comment": "Accepted by IEEE Transactions on Cognitive Communications and\n  Networking (TCCN)", "pdf_url": "http://arxiv.org/pdf/2507.12630v2", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-18"}
{"id": "2302.06945", "title": "Polynomial argmin for recovery and approximation of multivariate discontinuous functions", "authors": ["Didier Henrion", "Milan Korda", "Jean-Bernard Lasserre"], "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2302.06945v3", "summary": "We propose to approximate a (possibly discontinuous) multivariate function f\n(x) on a compact set by the partial minimizer arg miny p(x, y) of an\nappropriate polynomial p whose construction can be cast in a univariate sum of\nsquares (SOS) framework, resulting in a highly structured convex semidefinite\nprogram. In a number of non-trivial cases (e.g. when f is a piecewise\npolynomial) we prove that the approximation is exact with a low-degree\npolynomial p. Our approach has three distinguishing features: (i) It is\nmesh-free and does not require the knowledge of the discontinuity locations.\n(ii) It is model-free in the sense that we only assume that the function to be\napproximated is available through samples (point evaluations). (iii) The size\nof the semidefinite program is independent of the ambient dimension and depends\nlinearly on the number of samples. We also analyze the sample complexity of the\napproach, proving a generalization error bound in a probabilistic setting. This\nallows for a comparison with machine learning approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2302.06945v3", "cate": "math.NA", "date": "2023-02-14", "updated": "2025-07-21"}
{"id": "2507.15385", "title": "Transformer-based Deep Learning Model for Joint Routing and Scheduling with Varying Electric Vehicle Numbers", "authors": ["Jun Kang Yap", "Vishnu Monn Baskaran", "Wen Shan Tan", "Ze Yang Ding", "Hao Wang", "David L. Dowe"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Accepted at Industry Applications Society Annual Meeting (IAS 2025)", "url": "http://arxiv.org/abs/2507.15385v1", "summary": "The growing integration of renewable energy sources in modern power systems\nhas introduced significant operational challenges due to their intermittent and\nuncertain outputs. In recent years, mobile energy storage systems (ESSs) have\nemerged as a popular flexible resource for mitigating these challenges.\nCompared to stationary ESSs, mobile ESSs offer additional spatial flexibility,\nenabling cost-effective energy delivery through the transportation network.\nHowever, the widespread deployment of mobile ESSs is often hindered by the high\ninvestment cost, which has motivated researchers to investigate utilising more\nreadily available alternatives, such as electric vehicles (EVs) as mobile\nenergy storage units instead. Hence, we explore this opportunity with a\nMIP-based day-ahead electric vehicle joint routing and scheduling problem in\nthis work. However, solving the problem in a practical setting can often be\ncomputationally intractable since the existence of binary variables makes it\ncombinatorial challenging. Therefore, we proposed to simplify the problem's\nsolution process for a MIP solver by pruning the solution search space with a\ntransformer-based deep learning (DL) model. This is done by training the model\nto rapidly predict the optimal binary solutions. In addition, unlike many\nexisting DL approaches that assume fixed problem structures, the proposed model\nis designed to accommodate problems with EV fleets of any sizes. This\nflexibility is essential since frequent re-training can introduce significant\ncomputational overhead. We evaluated the approach with simulations on the IEEE\n33-bus system coupled with the Nguyen-Dupuis transportation network.", "comment": "Accepted at Industry Applications Society Annual Meeting (IAS 2025)", "pdf_url": "http://arxiv.org/pdf/2507.15385v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15564", "title": "Scaled Relative Graph Analysis of General Interconnections of SISO Nonlinear Systems", "authors": ["Julius P. J. Krebbekx", "Roland Tóth", "Amritam Das"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15564v1", "summary": "Scaled Relative Graphs (SRGs) provide a novel graphical frequency-domain\nmethod for the analysis of nonlinear systems. However, we show that the current\nSRG analysis suffers from a pitfall that limits its applicability in analyzing\npractical nonlinear systems. We overcome this pitfall by introducing a novel\nreformulation of the SRG of a linear time-invariant operator and combining the\nSRG with the Nyquist criterion. The result is a theorem that can be used to\nassess stability and $L_2$-gain performance for general interconnections of\nnonlinear dynamic systems. We provide practical calculation results for\ncanonical interconnections and apply our result to Lur'e systems to obtain a\ngeneralization of the celebrated circle criterion, which deals with broader\nclass of nonlinearities, and we derive (incremental) $L_2$-gain performance\nbounds. We illustrate the power of the new approach on the analysis of several\nexamples.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15564v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14308", "title": "Self-Supervised Joint Reconstruction and Denoising of T2-Weighted PROPELLER MRI of the Lungs at 0.55T", "authors": ["Jingjia Chen", "Haoyang Pei", "Christoph Maier", "Mary Bruno", "Qiuting Wen", "Seon-Hi Shin", "William Moore", "Hersh Chandarana", "Li Feng"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14308v1", "summary": "Purpose: This study aims to improve 0.55T T2-weighted PROPELLER lung MRI\nthrough a self-supervised joint reconstruction and denoising model.\n  Methods: T2-weighted 0.55T lung MRI dataset including 44 patients with\nprevious covid infection were used. A self-supervised learning framework was\ndeveloped, where each blade of the PROPELLER acquisition was split along the\nreadout direction into two partitions. One subset trains the unrolled\nreconstruction network, while the other subset is used for loss calculation,\nenabling self-supervised training without clean targets and leveraging matched\nnoise statistics for denoising. For comparison, Marchenko-Pastur Principal\nComponent Analysis (MPPCA) was performed along the coil dimension, followed by\nconventional parallel imaging reconstruction. The quality of the reconstructed\nlung MRI was assessed visually by two experienced radiologists independently.\n  Results: The proposed self-supervised model improved the clarity and\nstructural integrity of the lung images. For cases with available CT scans, the\nreconstructed images demonstrated strong alignment with corresponding CT\nimages. Additionally, the proposed model enables further scan time reduction by\nrequiring only half the number of blades. Reader evaluations confirmed that the\nproposed method outperformed MPPCA-denoised images across all categories\n(Wilcoxon signed-rank test, p<0.001), with moderate inter-reader agreement\n(weighted Cohen's kappa=0.55; percentage of exact and within +/-1 point\nagreement=91%).\n  Conclusion: By leveraging intrinsic structural redundancies between two\ndisjoint splits of k-space subsets, the proposed self-supervised learning model\neffectively reconstructs the image while suppressing the noise for 0.55T\nT2-weighted lung MRI with PROPELLER sampling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14308v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15292", "title": "EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Contro", "authors": ["An Wanga", "Rulin Zhou", "Mengya Xu", "Yiru Ye", "Longfei Gou", "Yiting Chang", "Hao Chen", "Chwee Ming Lim", "Jiankun Wang", "Hongliang Ren"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15292v1", "summary": "Visualizing subtle vascular motions in endoscopic surgery is crucial for\nsurgical precision and decision-making, yet remains challenging due to the\ncomplex and dynamic nature of surgical scenes. To address this, we introduce\nEndoControlMag, a training-free, Lagrangian-based framework with\nmask-conditioned vascular motion magnification tailored to endoscopic\nenvironments. Our approach features two key modules: a Periodic Reference\nResetting (PRR) scheme that divides videos into short overlapping clips with\ndynamically updated reference frames to prevent error accumulation while\nmaintaining temporal coherence, and a Hierarchical Tissue-aware Magnification\n(HTM) framework with dual-mode mask dilation. HTM first tracks vessel cores\nusing a pretrained visual tracking model to maintain accurate localization\ndespite occlusions and view changes. It then applies one of two adaptive\nsoftening strategies to surrounding tissues: motion-based softening that\nmodulates magnification strength proportional to observed tissue displacement,\nor distance-based exponential decay that simulates biomechanical force\nattenuation. This dual-mode approach accommodates diverse surgical\nscenarios-motion-based softening excels with complex tissue deformations while\ndistance-based softening provides stability during unreliable optical flow\nconditions. We evaluate EndoControlMag on our EndoVMM24 dataset spanning four\ndifferent surgery types and various challenging scenarios, including\nocclusions, instrument disturbance, view changes, and vessel deformations.\nQuantitative metrics, visual assessments, and expert surgeon evaluations\ndemonstrate that EndoControlMag significantly outperforms existing methods in\nboth magnification accuracy and visual quality while maintaining robustness\nacross challenging surgical conditions. The code, dataset, and video results\nare available at https://szupc.github.io/EndoControlMag/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15292v1", "cate": "eess.IV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15470", "title": "FedMultiEmo: Real-Time Emotion Recognition via Multimodal Federated Learning", "authors": ["Baran Can Gül", "Suraksha Nadig", "Stefanos Tziampazis", "Nasser Jazdi", "Michael Weyrich"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Preprint version. Accepted for publication at IEEE ICECCME 2025", "url": "http://arxiv.org/abs/2507.15470v1", "summary": "In-vehicle emotion recognition underpins adaptive driver-assistance systems\nand, ultimately, occupant safety. However, practical deployment is hindered by\n(i) modality fragility - poor lighting and occlusions degrade vision-based\nmethods; (ii) physiological variability - heart-rate and skin-conductance\npatterns differ across individuals; and (iii) privacy risk - centralized\ntraining requires transmission of sensitive data. To address these challenges,\nwe present FedMultiEmo, a privacy-preserving framework that fuses two\ncomplementary modalities at the decision level: visual features extracted by a\nConvolutional Neural Network from facial images, and physiological cues (heart\nrate, electrodermal activity, and skin temperature) classified by a Random\nForest. FedMultiEmo builds on three key elements: (1) a multimodal federated\nlearning pipeline with majority-vote fusion, (2) an end-to-end edge-to-cloud\nprototype on Raspberry Pi clients and a Flower server, and (3) a personalized\nFederated Averaging scheme that weights client updates by local data volume.\nEvaluated on FER2013 and a custom physiological dataset, the federated\nConvolutional Neural Network attains 77% accuracy, the Random Forest 74%, and\ntheir fusion 87%, matching a centralized baseline while keeping all raw data\nlocal. The developed system converges in 18 rounds, with an average round time\nof 120 seconds and a per-client memory footprint below 200 MB. These results\nindicate that FedMultiEmo offers a practical approach to real-time,\nprivacy-aware emotion recognition in automotive settings.", "comment": "Preprint version. Accepted for publication at IEEE ICECCME 2025", "pdf_url": "http://arxiv.org/pdf/2507.15470v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15297", "title": "Minutiae-Anchored Local Dense Representation for Fingerprint Matching", "authors": ["Zhiyu Pan", "Xiongjun Guan", "Yongjie Duan", "Jianjiang Feng", "Jie Zhou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Under review", "url": "http://arxiv.org/abs/2507.15297v1", "summary": "Fingerprint matching under diverse capture conditions remains a fundamental\nchallenge in biometric recognition. To achieve robust and accurate performance\nin such scenarios, we propose DMD, a minutiae-anchored local dense\nrepresentation which captures both fine-grained ridge textures and\ndiscriminative minutiae features in a spatially structured manner.\nSpecifically, descriptors are extracted from local patches centered and\noriented on each detected minutia, forming a three-dimensional tensor, where\ntwo dimensions represent spatial locations on the fingerprint plane and the\nthird encodes semantic features. This representation explicitly captures\nabstract features of local image patches, enabling a multi-level, fine-grained\ndescription that aggregates information from multiple minutiae and their\nsurrounding ridge structures. Furthermore, thanks to its strong spatial\ncorrespondence with the patch image, DMD allows for the use of foreground\nsegmentation masks to identify valid descriptor regions. During matching,\ncomparisons are then restricted to overlapping foreground areas, improving\nefficiency and robustness. Extensive experiments on rolled, plain, parital,\ncontactless, and latent fingerprint datasets demonstrate the effectiveness and\ngeneralizability of the proposed method. It achieves state-of-the-art accuracy\nacross multiple benchmarks while maintaining high computational efficiency,\nshowing strong potential for large-scale fingerprint recognition. Corresponding\ncode is available at https://github.com/Yu-Yy/DMD.", "comment": "Under review", "pdf_url": "http://arxiv.org/pdf/2507.15297v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2501.16215", "title": "Smarter Together: Combining Large Language Models and Small Models for Physiological Signals Visual Inspection", "authors": ["Huayu Li", "Zhengxiao He", "Xiwen Chen", "Ci Zhang", "Stuart F. Quan", "William D. S. Killgore", "Shu-Fen Wung", "Chen X. Chen", "Geng Yuan", "Jin Lu", "Ao Li"], "categories": ["cs.AI", "cs.LG", "eess.SP"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.16215v2", "summary": "Large language models (LLMs) have shown promising capabilities in visually\ninterpreting medical time-series data. However, their general-purpose design\ncan limit domain-specific precision, and the proprietary nature of many models\nposes challenges for fine-tuning on specialized clinical datasets. Conversely,\nsmall specialized models (SSMs) offer strong performance on focused tasks but\nlack the broader reasoning needed for complex medical decision-making. To\naddress these complementary limitations, we introduce \\ConMIL{} (Conformalized\nMultiple Instance Learning), a novel decision-support framework distinctively\nsynergizes three key components: (1) a new Multiple Instance Learning (MIL)\nmechanism, QTrans-Pooling, designed for per-class interpretability in\nidentifying clinically relevant physiological signal segments; (2) conformal\nprediction, integrated with MIL to generate calibrated, set-valued outputs with\nstatistical reliability guarantees; and (3) a structured approach for these\ninterpretable and uncertainty-quantified SSM outputs to enhance the visual\ninspection capabilities of LLMs. Our experiments on arrhythmia detection and\nsleep stage classification demonstrate that \\ConMIL{} can enhance the accuracy\nof LLMs such as ChatGPT4.0, Qwen2-VL-7B, and MiMo-VL-7B-RL. For example,\n\\ConMIL{}-supported Qwen2-VL-7B and MiMo-VL-7B-RL both achieves 94.92% and\n96.82% precision on confident samples and (70.61% and 78.02%)/(78.10% and\n71.98%) on uncertain samples for the two tasks, compared to 46.13% and 13.16%\nusing the LLM alone. These results suggest that integrating task-specific\nmodels with LLMs may offer a promising pathway toward more interpretable and\ntrustworthy AI-driven clinical decision support.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.16215v2", "cate": "cs.AI", "date": "2025-01-27", "updated": "2025-07-18"}
{"id": "2304.02062", "title": "An A Posteriori Error Estimator for Electrically Coupled Liquid Crystal Equilibrium Configurations", "authors": ["J. H. Adler", "D. B. Emerson"], "categories": ["math.NA", "cs.NA", "76A15, 65N30, 49M15, 65N22, 65N55"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      17 Pages, 6 Figures. 4 Tables. arXiv admin note: substantial text overlap with arXiv:1806.06248", "url": "http://arxiv.org/abs/2304.02062v2", "summary": "This paper derives an a posteriori error estimator for the nonlinear\nfirst-order optimality conditions associated with the electrically and\nflexoelectrically coupled Frank-Oseen model of liquid crystals, building on\nprevious results for elastic systems. The estimator is proposed for a penalty\napproach to imposing the unit-length constraint required by the model.\nMoreover, theory is proven establishing that the estimator provides a reliable\nestimate of global approximation error and an efficient measure of local error,\nsuitable for use in adaptive refinement. Numerical experiments demonstrate\nsignificant improvements in efficiency with adaptive refinement guided by the\nproposed estimator in a multilevel, nested-iteration framework and superior\nphysical properties for challenging electrically coupled systems.", "comment": "17 Pages, 6 Figures. 4 Tables. arXiv admin note: substantial text\n  overlap with arXiv:1806.06248", "pdf_url": "http://arxiv.org/pdf/2304.02062v2", "cate": "math.NA", "date": "2023-04-04", "updated": "2025-07-21"}
{"id": "2507.15708", "title": "Reliability-Based Fault Analysis and Modeling of Satellite Electrical Power Subsystems Using Fault Tree and Simulation Tools", "authors": ["Niloofar Nobahari", "Alireza Rezaee"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15708v1", "summary": "One of the most important satellite subsystems is its electric power\nsubsystem. The occurrence of a fault in the satellite power system causes the\nfailure of all or part of the satellite. Calculating the overall reliability of\nthe power system before the mission is crucial in improving the design of the\nsatellite power system. Each component of the power system may malfunction due\nto pressure, launch pressure, and operating conditions. Accordingly, in this\npaper, first, a healthy and faulty system for the components of the electrical\npower system is simulated with MATLAB. Finally, by drawing a fault tree to\nanalyze the reliability of the power subsystem, overall mission reliability,\npower system fault rate, and overall fault rate of the mission are calculated\nby Windchill software. Finally, a total mission assurance of 0.999 was\nachieved, indicating the high reliability of the simulated system.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15708v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15781", "title": "Density control of multi-agent swarms via bio-inspired leader-follower plasticity", "authors": ["Gian Carlo Maffettone", "Alain Boldini", "Mario di Bernardo", "Maurizio Porfiri"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15781v1", "summary": "The design of control systems for the spatial self-organization of mobile\nagents is an open challenge across several engineering domains, including swarm\nrobotics and synthetic biology. Here, we propose a bio-inspired leader-follower\nsolution, which is aware of energy constraints of mobile agents and is apt to\ndeal with large swarms. Akin to many natural systems, control objectives are\nformulated for the entire collective, and leaders and followers are allowed to\nplastically switch their role in time. We frame a density control problem,\nmodeling the agents' population via a system of nonlinear partial differential\nequations. This approach allows for a compact description that inherently\navoids the curse of dimensionality and improves analytical tractability. We\nderive analytical guarantees for the existence of desired steady-state\nsolutions and their local stability for one-dimensional and higher-dimensional\nproblems. We numerically validate our control methodology, offering support to\nthe effectiveness, robustness, and versatility of our proposed bio-inspired\ncontrol strategy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15781v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14378", "title": "Classification of Histopathology Slides with Persistence Homology Convolutions", "authors": ["Shrunal Pothagoni", "Benjamin Schweinhart"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14378v1", "summary": "Convolutional neural networks (CNNs) are a standard tool for computer vision\ntasks such as image classification. However, typical model architectures may\nresult in the loss of topological information. In specific domains such as\nhistopathology, topology is an important descriptor that can be used to\ndistinguish between disease-indicating tissue by analyzing the shape\ncharacteristics of cells. Current literature suggests that reintroducing\ntopological information using persistent homology can improve medical\ndiagnostics; however, previous methods utilize global topological summaries\nwhich do not contain information about the locality of topological features. To\naddress this gap, we present a novel method that generates local persistent\nhomology-based data using a modified version of the convolution operator called\nPersistent Homology Convolutions. This method captures information about the\nlocality and translation invariance of topological features. We perform a\ncomparative study using various representations of histopathology slides and\nfind that models trained with persistent homology convolutions outperform\nconventionally trained models and are less sensitive to hyperparameters. These\nresults indicate that persistent homology convolutions extract meaningful\ngeometric information from the histopathology slides.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14378v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15335", "title": "ExDD: Explicit Dual Distribution Learning for Surface Defect Detection via Diffusion Synthesis", "authors": ["Muhammad Aqeel", "Federico Leonardi", "Francesco Setti"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICIAP 2025", "url": "http://arxiv.org/abs/2507.15335v1", "summary": "Industrial defect detection systems face critical limitations when confined\nto one-class anomaly detection paradigms, which assume uniform outlier\ndistributions and struggle with data scarcity in realworld manufacturing\nenvironments. We present ExDD (Explicit Dual Distribution), a novel framework\nthat transcends these limitations by explicitly modeling dual feature\ndistributions. Our approach leverages parallel memory banks that capture the\ndistinct statistical properties of both normality and anomalous patterns,\naddressing the fundamental flaw of uniform outlier assumptions. To overcome\ndata scarcity, we employ latent diffusion models with domain-specific textual\nconditioning, generating in-distribution synthetic defects that preserve\nindustrial context. Our neighborhood-aware ratio scoring mechanism elegantly\nfuses complementary distance metrics, amplifying signals in regions exhibiting\nboth deviation from normality and similarity to known defect patterns.\nExperimental validation on KSDD2 demonstrates superior performance (94.2%\nI-AUROC, 97.7% P-AUROC), with optimal augmentation at 100 synthetic samples.", "comment": "Accepted to ICIAP 2025", "pdf_url": "http://arxiv.org/pdf/2507.15335v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15507", "title": "Off-Policy Corrected Reward Modeling for Reinforcement Learning from Human Feedback", "authors": ["Johannes Ackermann", "Takashi Ishida", "Masashi Sugiyama"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accept at the Conference On Language Modeling (COLM) 2025", "url": "http://arxiv.org/abs/2507.15507v1", "summary": "Reinforcement Learning from Human Feedback (RLHF) allows us to train models,\nsuch as language models (LMs), to follow complex human preferences. In RLHF for\nLMs, we first train an LM using supervised fine-tuning, sample pairs of\nresponses, obtain human feedback, and use the resulting data to train a reward\nmodel (RM). RL methods are then used to train the LM to maximize the reward\ngiven by the RM. As training progresses, the responses generated by the LM no\nlonger resemble the responses seen by the RM during training, leading to the RM\nbecoming inaccurate. The score given by the RM keeps increasing, but the\nlearned behavior no longer matches the human preferences. This issue is known\nas overoptimization. We investigate overoptimization from the point of view of\ndistribution shift and show that the shift results in an inconsistent estimate\nof the RM parameters, leading to an inconsistent estimate of the policy\ngradient. We propose Off-Policy Corrected Reward Modeling (OCRM), which\niteratively off-policy corrects the RM using importance weighting, without\nrequiring new labels or samples. This results in a more accurate RM, which\nempirically leads to an improved final policy. We validate our approach in\nexperiments with summarization and chatbot datasets and show that it performs\nsignificantly better than standard RLHF methods and baselines. Our\nimplementation is available at\nhttps://github.com/JohannesAck/OffPolicyCorrectedRewardModeling", "comment": "Accept at the Conference On Language Modeling (COLM) 2025", "pdf_url": "http://arxiv.org/pdf/2507.15507v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15308", "title": "Few-Shot Object Detection via Spatial-Channel State Space Model", "authors": ["Zhimeng Xin", "Tianxu Wu", "Yixiong Zou", "Shiming Chen", "Dingjie Fu", "Xinge You"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15308v1", "summary": "Due to the limited training samples in few-shot object detection (FSOD), we\nobserve that current methods may struggle to accurately extract effective\nfeatures from each channel. Specifically, this issue manifests in two aspects:\ni) channels with high weights may not necessarily be effective, and ii)\nchannels with low weights may still hold significant value. To handle this\nproblem, we consider utilizing the inter-channel correlation to facilitate the\nnovel model's adaptation process to novel conditions, ensuring the model can\ncorrectly highlight effective channels and rectify those incorrect ones. Since\nthe channel sequence is also 1-dimensional, its similarity with the temporal\nsequence inspires us to take Mamba for modeling the correlation in the channel\nsequence. Based on this concept, we propose a Spatial-Channel State Space\nModeling (SCSM) module for spatial-channel state modeling, which highlights the\neffective patterns and rectifies those ineffective ones in feature channels. In\nSCSM, we design the Spatial Feature Modeling (SFM) module to balance the\nlearning of spatial relationships and channel relationships, and then introduce\nthe Channel State Modeling (CSM) module based on Mamba to learn correlation in\nchannels. Extensive experiments on the VOC and COCO datasets show that the SCSM\nmodule enables the novel detector to improve the quality of focused feature\nrepresentation in channels and achieve state-of-the-art performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15308v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2503.00580", "title": "Brain Foundation Models: A Survey on Advancements in Neural Signal Processing and Brain Discovery", "authors": ["Xinliang Zhou", "Chenyu Liu", "Zhisheng Chen", "Kun Wang", "Yi Ding", "Ziyu Jia", "Qingsong Wen"], "categories": ["cs.LG", "cs.AI", "eess.SP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      IEEE Signal Processing Magazine", "url": "http://arxiv.org/abs/2503.00580v2", "summary": "Brain foundation models (BFMs) have emerged as a transformative paradigm in\ncomputational neuroscience, offering a revolutionary framework for processing\ndiverse neural signals across different brain-related tasks. These models\nleverage large-scale pre-training techniques, allowing them to generalize\neffectively across multiple scenarios, tasks, and modalities, thus overcoming\nthe traditional limitations faced by conventional artificial intelligence (AI)\napproaches in understanding complex brain data. By tapping into the power of\npretrained models, BFMs provide a means to process neural data in a more\nunified manner, enabling advanced analysis and discovery in the field of\nneuroscience. In this survey, we define BFMs for the first time, providing a\nclear and concise framework for constructing and utilizing these models in\nvarious applications. We also examine the key principles and methodologies for\ndeveloping these models, shedding light on how they transform the landscape of\nneural signal processing. This survey presents a comprehensive review of the\nlatest advancements in BFMs, covering the most recent methodological\ninnovations, novel views of application areas, and challenges in the field.\nNotably, we highlight the future directions and key challenges that need to be\naddressed to fully realize the potential of BFMs. These challenges include\nimproving the quality of brain data, optimizing model architecture for better\ngeneralization, increasing training efficiency, and enhancing the\ninterpretability and robustness of BFMs in real-world applications.", "comment": "IEEE Signal Processing Magazine", "pdf_url": "http://arxiv.org/pdf/2503.00580v2", "cate": "cs.LG", "date": "2025-03-01", "updated": "2025-07-19"}
{"id": "2404.08321", "title": "Improved parameter selection strategy for the iterated Arnoldi-Tikhonov method", "authors": ["Marco Donatelli", "Davide Furchì"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      Same results can be found in arXiv:2507.12307", "url": "http://arxiv.org/abs/2404.08321v2", "summary": "The iterated Arnoldi-Tikhonov (iAT) method is a regularization technique\nparticularly suited for solving large-scale ill-posed linear inverse problems.\nIndeed, it reduces the computational complexity through the projection of the\ndiscretized problem into a lower-dimensional Krylov subspace, where the problem\nis then solved.\n  This paper studies iAT under an additional hypothesis on the discretized\noperator. It presents a theoretical analysis of the approximation errors,\nleading to an a posteriori rule for choosing the regularization parameter. Our\nproposed rule results in more accurate computed approximate solutions compared\nto the a posteriori rule recently proposed in arXiv:2311.11823. The numerical\nresults confirm the theoretical analysis, providing accurate computed solutions\neven when the new assumption is not satisfied.", "comment": "Same results can be found in arXiv:2507.12307", "pdf_url": "http://arxiv.org/pdf/2404.08321v2", "cate": "math.NA", "date": "2024-04-12", "updated": "2025-07-21"}
{"id": "2507.05297", "title": "Continuous Classification Aggregation", "authors": ["Zijun Meng"], "categories": ["cs.AI", "cs.SY", "econ.TH", "eess.SY", "math.CO", "stat.ML"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      9 pages; 2 figures", "url": "http://arxiv.org/abs/2507.05297v5", "summary": "We prove that any optimal, independent, and zero unanimous fuzzy\nclassification aggregation function of a continuum of individual\nclassifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted\narithmetic mean. We also provide a characterization for the case when $m=p=2$.", "comment": "9 pages; 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.05297v5", "cate": "cs.AI", "date": "2025-07-06", "updated": "2025-07-16"}
{"id": "2507.14354", "title": "Interpretable Gradient Descent for Kalman Gain", "authors": ["M. A. Belabbas", "A. Olshevsky"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14354v1", "summary": "We derive a decomposition for the gradient of the innovation loss with\nrespect to the filter gain in a linear time-invariant system, decomposing as a\nproduct of an observability Gramian and a term quantifying the\n``non-orthogonality\" between the estimation error and the innovation. We\nleverage this decomposition to give a convergence proof of gradient descent to\nthe optimal Kalman gain, specifically identifying how recovery of the Kalman\ngain depends on a non-standard observability condition, and obtaining an\ninterpretable geometric convergence rate.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14354v1", "cate": "math.OC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.14429", "title": "Spatiotemporal Maps for Dynamic MRI Reconstruction", "authors": ["Rodrigo A. Lobos", "Xiaokai Wang", "Rex T. L. Fung", "Yongli He", "David Frey", "Dinank Gupta", "Zhongming Liu", "Jeffrey A. Fessler", "Douglas C. Noll"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      13 pages, 8 figures", "url": "http://arxiv.org/abs/2507.14429v1", "summary": "The partially separable functions (PSF) model is commonly adopted in dynamic\nMRI reconstruction, as is the underlying signal model in many reconstruction\nmethods including the ones relying on low-rank assumptions. Even though the PSF\nmodel offers a parsimonious representation of the dynamic MRI signal in several\napplications, its representation capabilities tend to decrease in scenarios\nwhere voxels present different temporal/spectral characteristics at different\nspatial locations. In this work we account for this limitation by proposing a\nnew model, called spatiotemporal maps (STMs), that leverages autoregressive\nproperties of (k, t)-space. The STM model decomposes the spatiotemporal MRI\nsignal into a sum of components, each one consisting of a product between a\nspatial function and a temporal function that depends on the spatial location.\nThe proposed model can be interpreted as an extension of the PSF model whose\ntemporal functions are independent of the spatial location. We show that\nspatiotemporal maps can be efficiently computed from autocalibration data by\nusing advanced signal processing and randomized linear algebra techniques,\nenabling STMs to be used as part of many reconstruction frameworks for\naccelerated dynamic MRI. As proof-of-concept illustrations, we show that STMs\ncan be used to reconstruct both 2D single-channel animal gastrointestinal MRI\ndata and 3D multichannel human functional MRI data.", "comment": "13 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.14429v1", "cate": "eess.IV", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15340", "title": "MedSR-Impact: Transformer-Based Super-Resolution for Lung CT Segmentation, Radiomics, Classification, and Prognosis", "authors": ["Marc Boubnovski Martell", "Kristofer Linton-Reid", "Mitchell Chen", "Sumeet Hindocha", "Benjamin Hunter", "Marco A. Calzado", "Richard Lee", "Joram M. Posma", "Eric O. Aboagye"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15340v1", "summary": "High-resolution volumetric computed tomography (CT) is essential for accurate\ndiagnosis and treatment planning in thoracic diseases; however, it is limited\nby radiation dose and hardware costs. We present the Transformer Volumetric\nSuper-Resolution Network (\\textbf{TVSRN-V2}), a transformer-based\nsuper-resolution (SR) framework designed for practical deployment in clinical\nlung CT analysis. Built from scalable components, including Through-Plane\nAttention Blocks (TAB) and Swin Transformer V2 -- our model effectively\nreconstructs fine anatomical details in low-dose CT volumes and integrates\nseamlessly with downstream analysis pipelines. We evaluate its effectiveness on\nthree critical lung cancer tasks -- lobe segmentation, radiomics, and prognosis\n-- across multiple clinical cohorts. To enhance robustness across variable\nacquisition protocols, we introduce pseudo-low-resolution augmentation,\nsimulating scanner diversity without requiring private data. TVSRN-V2\ndemonstrates a significant improvement in segmentation accuracy (+4\\% Dice),\nhigher radiomic feature reproducibility, and enhanced predictive performance\n(+0.06 C-index and AUC). These results indicate that SR-driven recovery of\nstructural detail significantly enhances clinical decision support, positioning\nTVSRN-V2 as a well-engineered, clinically viable system for dose-efficient\nimaging and quantitative analysis in real-world CT workflows.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15340v1", "cate": "eess.IV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15545", "title": "Data Aware Differentiable Neural Architecture Search for Tiny Keyword Spotting Applications", "authors": ["Yujia Shi", "Emil Njor", "Pablo Martínez-Nuevo", "Sven Ewan Shepstone", "Xenofon Fafoutis"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15545v1", "summary": "The success of Machine Learning is increasingly tempered by its significant\nresource footprint, driving interest in efficient paradigms like TinyML.\nHowever, the inherent complexity of designing TinyML systems hampers their\nbroad adoption. To reduce this complexity, we introduce \"Data Aware\nDifferentiable Neural Architecture Search\". Unlike conventional Differentiable\nNeural Architecture Search, our approach expands the search space to include\ndata configuration parameters alongside architectural choices. This enables\nData Aware Differentiable Neural Architecture Search to co-optimize model\narchitecture and input data characteristics, effectively balancing resource\nusage and system performance for TinyML applications. Initial results on\nkeyword spotting demonstrate that this novel approach to TinyML system design\ncan generate lean but highly accurate systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15545v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15321", "title": "BenchDepth: Are We on the Right Way to Evaluate Depth Foundation Models?", "authors": ["Zhenyu Li", "Haotong Lin", "Jiashi Feng", "Peter Wonka", "Bingyi Kang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Webpage: this https URL", "url": "http://arxiv.org/abs/2507.15321v1", "summary": "Depth estimation is a fundamental task in computer vision with diverse\napplications. Recent advancements in deep learning have led to powerful depth\nfoundation models (DFMs), yet their evaluation remains challenging due to\ninconsistencies in existing protocols. Traditional benchmarks rely on\nalignment-based metrics that introduce biases, favor certain depth\nrepresentations, and complicate fair comparisons. In this work, we propose\nBenchDepth, a new benchmark that evaluates DFMs through five carefully selected\ndownstream proxy tasks: depth completion, stereo matching, monocular\nfeed-forward 3D scene reconstruction, SLAM, and vision-language spatial\nunderstanding. Unlike conventional evaluation protocols, our approach assesses\nDFMs based on their practical utility in real-world applications, bypassing\nproblematic alignment procedures. We benchmark eight state-of-the-art DFMs and\nprovide an in-depth analysis of key findings and observations. We hope our work\nsparks further discussion in the community on best practices for depth model\nevaluation and paves the way for future research and advancements in depth\nestimation.", "comment": "Webpage: https://zhyever.github.io/benchdepth", "pdf_url": "http://arxiv.org/pdf/2507.15321v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2504.03625", "title": "Reciprocity-Aware Convolutional Neural Networks for Map-Based Path Loss Prediction", "authors": ["Ryan G. Dempsey", "Jonathan Ethier", "Halim Yanikomeroglu"], "categories": ["cs.LG", "eess.SP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      6 pages, 6 figures, 7 tables", "url": "http://arxiv.org/abs/2504.03625v2", "summary": "Path loss modeling is a widely used technique for estimating point-to-point\nlosses along a communications link from transmitter (Tx) to receiver (Rx).\nAccurate path loss predictions can optimize use of the radio frequency spectrum\nand minimize unwanted interference. Modern path loss modeling often leverages\ndata-driven approaches, using machine learning to train models on drive test\nmeasurement datasets. Drive tests primarily represent downlink scenarios, where\nthe Tx is located on a building and the Rx is located on a moving vehicle.\nConsequently, trained models are frequently reserved for downlink coverage\nestimation, lacking representation of uplink scenarios. In this paper, we\ndemonstrate that data augmentation can be used to train a path loss model that\nis generalized to uplink, downlink, and backhaul scenarios, training using only\ndownlink drive test measurements. By adding a small number of synthetic samples\nrepresenting uplink scenarios to the training set, root mean squared error is\nreduced by > 8 dB on uplink examples in the test set.", "comment": "6 pages, 6 figures, 7 tables", "pdf_url": "http://arxiv.org/pdf/2504.03625v2", "cate": "cs.LG", "date": "2025-04-04", "updated": "2025-07-21"}
{"id": "2407.19707", "title": "Neural networks for bifurcation and linear stability analysis of steady states in partial differential equations", "authors": ["Muhammad Luthfi Shahab", "Hadi Susanto"], "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      Accepted for publication in Applied Mathematics and Computation", "url": "http://arxiv.org/abs/2407.19707v4", "summary": "This research introduces an extended application of neural networks for\nsolving nonlinear partial differential equations (PDEs). A neural network,\ncombined with a pseudo-arclength continuation, is proposed to construct\nbifurcation diagrams from parameterized nonlinear PDEs. Additionally, a neural\nnetwork approach is also presented for solving eigenvalue problems to analyze\nsolution linear stability, focusing on identifying the largest eigenvalue. The\neffectiveness of the proposed neural network is examined through experiments on\nthe Bratu equation and the Burgers equation. Results from a finite difference\nmethod are also presented as comparison. Varying numbers of grid points are\nemployed in each case to assess the behavior and accuracy of both the neural\nnetwork and the finite difference method. The experimental results demonstrate\nthat the proposed neural network produces better solutions, generates more\naccurate bifurcation diagrams, has reasonable computational times, and proves\neffective for linear stability analysis.", "comment": "Accepted for publication in Applied Mathematics and Computation", "pdf_url": "http://arxiv.org/pdf/2407.19707v4", "cate": "math.NA", "date": "2024-07-29", "updated": "2025-07-20"}
{"id": "2507.14756", "title": "Preventing an Extractive Green Hydrogen Industry: Risks and Benefits of Grid Expansion and Green Hydrogen in and for Kenya", "authors": ["Xi Xi", "Boniface Kinyanjui", "Daniel M. Kammen"], "categories": ["physics.soc-ph", "cs.SY", "eess.SY", "93Axx"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "Comments:      44 pages, 8 figures", "url": "http://arxiv.org/abs/2507.14756v1", "summary": "This study evaluates the role of grid-connected hydrogen electrolyzers in\nadvancing a cost-effective and in particular an equitable green hydrogen\nindustry in Kenya to serve both domestic and international needs and markets.\nUsing a multi-nodal capacity expansion model with county-level spatial\nresolution, we assess how electrolyzer deployment affects electricity cost,\ngrid flexibility, and carbon intensity under various renewable and demand\nscenarios. Results show that electrolyzers enable up to 30 percent reduction in\nlevelized cost of electricity (LCOE) and US\\$460 million in cumulative system\ncost savings by 2050 compared to a business-as-usual scenario. As a flexible\ndemand available to absorb surplus generation, electrolyzers reduce curtailment\nand support large-scale wind integration while still requiring a diverse mix of\nrenewable electricity. The resulting hydrogen reaches a levelized cost of \\$3.2\nper kg by 2050, and its carbon intensity from electricity use falls below one\nkg carbon dioxide per kg of hydrogen, suggesting likely compliance with\ninternational certification thresholds. Benefits persist across all demand\ntrajectories, though their scale depends on the pace of wind expansion. Spatial\nanalyses reveal unequal distribution of infrastructure gains, underscoring the\nneed for equity-oriented planning. These findings suggest that grid-integrated\nhydrogen, if planned in coordination with wind investment, transmission, and\nequitable infrastructure deployment, can reduce costs, support certification,\nand promote a more equitable model of hydrogen development. In other words,\nconnecting electrolyzers to the grid will not only make green hydrogen in Kenya\nbut also for Kenya.", "comment": "44 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.14756v1", "cate": "physics.soc-ph", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15127", "title": "Sequential feedback optimization with application to wind farm control", "authors": ["Shijie Huang", "Sergio Grammatico"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15127v1", "summary": "This paper develops a sequential-linearization feedback optimization\nframework for driving nonlinear dynamical systems to an\n  optimal steady state. A fundamental challenge in feedback optimization is the\nrequirement of accurate first-order information\n  of the steady-state input-output mapping, which is computationally\nprohibitive for high-dimensional nonlinear systems and\n  often leads to poor performance when approximated around a fixed operating\npoint. To address this limitation, we propose a\n  sequential algorithm that adaptively updates the linearization point during\noptimization, maintaining local accuracy throughout\n  the trajectory. We prove convergence to a neighborhood of the optimal steady\nstate with explicit error bounds. To reduce the\n  computational burden of repeated linearization operations, we further develop\na multi-timescale variant where linearization\n  updates occur at a slower timescale than optimization iterations, achieving\nsignificant computational savings while preserving\n  convergence guarantees. The effectiveness of the proposed framework is\ndemonstrated via numerical simulations of a realistic\n  wind farm control problem. The results validate both the theoretical\nconvergence predictions and the expected computational\n  advantages of our multi-timescale formulation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15127v1", "cate": "math.OC", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15078", "title": "PET Image Reconstruction Using Deep Diffusion Image Prior", "authors": ["Fumio Hashimoto", "Kuang Gong"], "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      11 pages, 11 figures", "url": "http://arxiv.org/abs/2507.15078v1", "summary": "Diffusion models have shown great promise in medical image denoising and\nreconstruction, but their application to Positron Emission Tomography (PET)\nimaging remains limited by tracer-specific contrast variability and high\ncomputational demands. In this work, we proposed an anatomical prior-guided PET\nimage reconstruction method based on diffusion models, inspired by the deep\ndiffusion image prior (DDIP) framework. The proposed method alternated between\ndiffusion sampling and model fine-tuning guided by the PET sinogram, enabling\nthe reconstruction of high-quality images from various PET tracers using a\nscore function pretrained on a dataset of another tracer. To improve\ncomputational efficiency, the half-quadratic splitting (HQS) algorithm was\nadopted to decouple network optimization from iterative PET reconstruction. The\nproposed method was evaluated using one simulation and two clinical datasets.\nFor the simulation study, a model pretrained on [$^{18}$F]FDG data was tested\non amyloid-negative PET data to assess out-of-distribution (OOD) performance.\nFor the clinical-data validation, ten low-dose [$^{18}$F]FDG datasets and one\n[$^{18}$F]Florbetapir dataset were tested on a model pretrained on data from\nanother tracer. Experiment results show that the proposed PET reconstruction\nmethod can generalize robustly across tracer distributions and scanner types,\nproviding an efficient and versatile reconstruction framework for low-dose PET\nimaging.", "comment": "11 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.15078v1", "cate": "eess.IV", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15357", "title": "Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding", "authors": ["Elisa Sanchez-Bayona", "Rodrigo Agerri"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15357v1", "summary": "This paper presents a comprehensive evaluation of the capabilities of Large\nLanguage Models (LLMs) in metaphor interpretation across multiple datasets,\ntasks, and prompt configurations. Although metaphor processing has gained\nsignificant attention in Natural Language Processing (NLP), previous research\nhas been limited to single-dataset evaluations and specific task settings,\noften using artificially constructed data through lexical replacement. We\naddress these limitations by conducting extensive experiments using diverse\npublicly available datasets with inference and metaphor annotations, focusing\non Natural Language Inference (NLI) and Question Answering (QA) tasks. The\nresults indicate that LLMs' performance is more influenced by features like\nlexical overlap and sentence length than by metaphorical content, demonstrating\nthat any alleged emergent abilities of LLMs to understand metaphorical language\nare the result of a combination of surface-level features, in-context learning,\nand linguistic knowledge. This work provides critical insights into the current\ncapabilities and limitations of LLMs in processing figurative language,\nhighlighting the need for more realistic evaluation frameworks in metaphor\ninterpretation tasks. Data and code are publicly available.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15357v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15548", "title": "The added value for MRI radiomics and deep-learning for glioblastoma prognostication compared to clinical and molecular information", "authors": ["D. Abler", "O. Pusterla", "A. Joye-Kühnis", "N. Andratschke", "M. Bach", "A. Bink", "S. M. Christ", "P. Hagmann", "B. Pouymayou", "E. Pravatà", "P. Radojewski", "M. Reyes", "L. Ruinelli", "R. Schaer", "B. Stieltjes", "G. Treglia", "W. Valenzuela", "R. Wiest", "S. Zoergiebel", "M. Guckenberger", "S. Tanadini-Lang", "A. Depeursinge"], "categories": ["cs.LG", "stat.AP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15548v1", "summary": "Background: Radiomics shows promise in characterizing glioblastoma, but its\nadded value over clinical and molecular predictors has yet to be proven. This\nstudy assessed the added value of conventional radiomics (CR) and deep learning\n(DL) MRI radiomics for glioblastoma prognosis (<= 6 vs > 6 months survival) on\na large multi-center dataset.\n  Methods: After patient selection, our curated dataset gathers 1152\nglioblastoma (WHO 2016) patients from five Swiss centers and one public source.\nIt included clinical (age, gender), molecular (MGMT, IDH), and baseline MRI\ndata (T1, T1 contrast, FLAIR, T2) with tumor regions. CR and DL models were\ndeveloped using standard methods and evaluated on internal and external\ncohorts. Sub-analyses assessed models with different feature sets\n(imaging-only, clinical/molecular-only, combined-features) and patient subsets\n(S-1: all patients, S-2: with molecular data, S-3: IDH wildtype).\n  Results: The best performance was observed in the full cohort (S-1). In\nexternal validation, the combined-feature CR model achieved an AUC of 0.75,\nslightly, but significantly outperforming clinical-only (0.74) and imaging-only\n(0.68) models. DL models showed similar trends, though without statistical\nsignificance. In S-2 and S-3, combined models did not outperform clinical-only\nmodels. Exploratory analysis of CR models for overall survival prediction\nsuggested greater relevance of imaging data: across all subsets,\ncombined-feature models significantly outperformed clinical-only models, though\nwith a modest advantage of 2-4 C-index points.\n  Conclusions: While confirming the predictive value of anatomical MRI\nsequences for glioblastoma prognosis, this multi-center study found standard CR\nand DL radiomics approaches offer minimal added value over demographic\npredictors such as age and gender.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15548v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15346", "title": "RoadFusion: Latent Diffusion Model for Pavement Defect Detection", "authors": ["Muhammad Aqeel", "Kidus Dagnaw Bellete", "Francesco Setti"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICIAP 2025", "url": "http://arxiv.org/abs/2507.15346v1", "summary": "Pavement defect detection faces critical challenges including limited\nannotated data, domain shift between training and deployment environments, and\nhigh variability in defect appearances across different road conditions. We\npropose RoadFusion, a framework that addresses these limitations through\nsynthetic anomaly generation with dual-path feature adaptation. A latent\ndiffusion model synthesizes diverse, realistic defects using text prompts and\nspatial masks, enabling effective training under data scarcity. Two separate\nfeature adaptors specialize representations for normal and anomalous inputs,\nimproving robustness to domain shift and defect variability. A lightweight\ndiscriminator learns to distinguish fine-grained defect patterns at the patch\nlevel. Evaluated on six benchmark datasets, RoadFusion achieves consistently\nstrong performance across both classification and localization tasks, setting\nnew state-of-the-art in multiple metrics relevant to real-world road\ninspection.", "comment": "Accepted to ICIAP 2025", "pdf_url": "http://arxiv.org/pdf/2507.15346v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2407.20655", "title": "Robust Augmented Mixed Finite Element Methods for Stoke Interface Problems with Discontinuous Viscosity in Multiple Subdomains", "authors": ["Yuxiang Liang", "Shun Zhang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      we corrected tables 1-3 of the previous version", "url": "http://arxiv.org/abs/2407.20655v2", "summary": "A stationary Stokes problem with a piecewise constant viscosity coefficient\nin multiple subdomains is considered in the paper. For standard finite element\npairs, a robust inf-sup condition is required to show the robustness of the\ndiscretization error with respect to the discontinuous viscosity, which has\nonly been proven for the two-subdomain case in the paper [Numer. Math. (2006)\n103: 129--149]. To avoid the robust inf-sup condition of a discrete finite\nelement pair for multiple subdomains, we propose an ultra-weak augmented mixed\nfinite element formulation. By adopting a Galerkin-least-squares method, the\naugmented mixed formulation can achieve stability without relying on the\ninf-sup condition in both continuous and discrete settings. The key step to\nhaving a robust priori error estimate is to use two norms, one energy norm and\none full norm, in robust continuity. The robust coercivity is proved for the\nenergy norm. A robust a priori error estimate in the energy norm is then\nderived with the best approximation property in the full norm for the case of\nmultiple subdomains. Additionally, the paper introduces a singular Kellogg-type\nexample with exact solutions for the first time. Extensive numerical tests are\nconducted to validate the robust error estimate.", "comment": "we corrected tables 1-3 of the previous version", "pdf_url": "http://arxiv.org/pdf/2407.20655v2", "cate": "math.NA", "date": "2024-07-30", "updated": "2025-07-21"}
{"id": "2507.15168", "title": "Exploration and Comparison: Development and Implementation of Multiple Ultrasound Imaging Modalities", "authors": ["Xuyang Chen", "Mingtong Chen", "Zhengbao Yang"], "categories": ["physics.med-ph", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15168v1", "summary": "Ultrasound imaging, as a noninvasive, real-time, and low-cost modality, plays\na vital role in clinical diagnosis, catheterization intervention, and portable\ndevices. With the development of transducer hardware and the continuous\nprogress of imaging algorithms, how to realize high-quality image\nreconstruction in different application scenarios has become a research\nfocus.This project focuses on the systematic research and implementation of\nthree typical ultrasound imaging modalities - line array imaging, endoscopic\nimaging and plane wave imaging, covering simulation data processing, imaging\nalgorithm implementation and real data validation, etc., aiming to deepen the\nunderstanding of the principles and processes of various types of imaging.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15168v1", "cate": "physics.med-ph", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15283", "title": "Event-Triggered Resilient Consensus of Networked Euler-Lagrange Systems Under Byzantine Attacks", "authors": ["Yuliang Fu", "Guanghui Wen", "Dan Zhao", "Wei Xing Zheng", "Xiaolei Li"], "categories": ["math.OC", "cs.SY", "eess.SY", "93D20(Primary), 93D09(Secondary)"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      11 pages, 16 figures", "url": "http://arxiv.org/abs/2507.15283v1", "summary": "The resilient consensus problem is investigated in this paper for a class of\nnetworked Euler-Lagrange systems with event-triggered communication in the\npresence of Byzantine attacks. One challenge that we face in addressing the\nconsidered problem is the inapplicability of existing resilient decision\nalgorithms designed for one-dimensional multi-agent systems. This is because\nthe networked Euler-Lagrange systems fall into the category of\nmulti-dimensional multi-agent systems with coupling among state vector\ncomponents. To address this problem, we propose a new resilient decision\nalgorithm. This algorithm constructs auxiliary variables related to the\ncoordinative objectives for each normal agent, and transforms the considered\nresilient consensus problem into the consensus problem of the designed\nauxiliary variables. Furthermore, to relax the constraints imposed on Byzantine\nagent behavior patterns within continuous-time scenarios, the event-triggered\ncommunication scheme is adopted. Finally, the effectiveness of the proposed\nalgorithm is demonstrated through case studies.", "comment": "11 pages, 16 figures", "pdf_url": "http://arxiv.org/pdf/2507.15283v1", "cate": "math.OC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15194", "title": "Personalized 3D Myocardial Infarct Geometry Reconstruction from Cine MRI with Explicit Cardiac Motion Modeling", "authors": ["Yilin Lyu", "Fan Yang", "Xiaoyue Liu", "Zichen Jiang", "Joshua Dillon", "Debbie Zhao", "Martyn Nash", "Charlene Mauger", "Alistair Young", "Ching-Hui Sia", "Mark YY Chan", "Lei Li"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      11 pages", "url": "http://arxiv.org/abs/2507.15194v1", "summary": "Accurate representation of myocardial infarct geometry is crucial for\npatient-specific cardiac modeling in MI patients. While Late gadolinium\nenhancement (LGE) MRI is the clinical gold standard for infarct detection, it\nrequires contrast agents, introducing side effects and patient discomfort.\nMoreover, infarct reconstruction from LGE often relies on sparsely sampled 2D\nslices, limiting spatial resolution and accuracy. In this work, we propose a\nnovel framework for automatically reconstructing high-fidelity 3D myocardial\ninfarct geometry from 2D clinically standard cine MRI, eliminating the need for\ncontrast agents. Specifically, we first reconstruct the 4D biventricular mesh\nfrom multi-view cine MRIs via an automatic deep shape fitting model, biv-me.\nThen, we design a infarction reconstruction model, CMotion2Infarct-Net, to\nexplicitly utilize the motion patterns within this dynamic geometry to localize\ninfarct regions. Evaluated on 205 cine MRI scans from 126 MI patients, our\nmethod shows reasonable agreement with manual delineation. This study\ndemonstrates the feasibility of contrast-free, cardiac motion-driven 3D infarct\nreconstruction, paving the way for efficient digital twin of MI.", "comment": "11 pages", "pdf_url": "http://arxiv.org/pdf/2507.15194v1", "cate": "eess.IV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15361", "title": "Latent Space Synergy: Text-Guided Data Augmentation for Direct Diffusion Biomedical Segmentation", "authors": ["Muhammad Aqeel", "Maham Nazir", "Zanxi Ruan", "Francesco Setti"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted to CVGMMI Workshop at ICIAP 2025", "url": "http://arxiv.org/abs/2507.15361v1", "summary": "Medical image segmentation suffers from data scarcity, particularly in polyp\ndetection where annotation requires specialized expertise. We present SynDiff,\na framework combining text-guided synthetic data generation with efficient\ndiffusion-based segmentation. Our approach employs latent diffusion models to\ngenerate clinically realistic synthetic polyps through text-conditioned\ninpainting, augmenting limited training data with semantically diverse samples.\nUnlike traditional diffusion methods requiring iterative denoising, we\nintroduce direct latent estimation enabling single-step inference with T x\ncomputational speedup. On CVC-ClinicDB, SynDiff achieves 96.0% Dice and 92.9%\nIoU while maintaining real-time capability suitable for clinical deployment.\nThe framework demonstrates that controlled synthetic augmentation improves\nsegmentation robustness without distribution shift. SynDiff bridges the gap\nbetween data-hungry deep learning models and clinical constraints, offering an\nefficient solution for deployment in resourcelimited medical settings.", "comment": "Accepted to CVGMMI Workshop at ICIAP 2025", "pdf_url": "http://arxiv.org/pdf/2507.15361v1", "cate": "eess.IV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15550", "title": "PhysGym: Benchmarking LLMs in Interactive Physics Discovery with Controlled Priors", "authors": ["Yimeng Chen", "Piotr Piȩkos", "Mateusz Ostaszewski", "Firas Laakom", "Jürgen Schmidhuber"], "categories": ["cs.LG", "cs.AI", "physics.soc-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      31 Pages", "url": "http://arxiv.org/abs/2507.15550v1", "summary": "Evaluating the scientific discovery capabilities of large language model\nbased agents, particularly how they cope with varying environmental complexity\nand utilize prior knowledge, requires specialized benchmarks currently lacking\nin the landscape. To address this gap, we introduce PhysGym, a novel benchmark\nsuite and simulation platform for rigorously assessing LLM-based scientific\nreasoning in interactive physics environments. PhysGym's primary contribution\nlies in its sophisticated control over the level of prior knowledge provided to\nthe agent. This allows researchers to dissect agent performance along axes\nincluding the complexity of the problem and the prior knowledge levels. The\nbenchmark comprises a suite of interactive simulations, where agents must\nactively probe environments, gather data sequentially under constraints and\nformulate hypotheses about underlying physical laws. PhysGym provides\nstandardized evaluation protocols and metrics for assessing hypothesis accuracy\nand model fidelity. We demonstrate the benchmark's utility by presenting\nresults from baseline LLMs, showcasing its ability to differentiate\ncapabilities based on varying priors and task complexity.", "comment": "31 Pages", "pdf_url": "http://arxiv.org/pdf/2507.15550v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15365", "title": "DAViD: Data-efficient and Accurate Vision Models from Synthetic Data", "authors": ["Fatemeh Saleh", "Sadegh Aliakbarian", "Charlie Hewitt", "Lohit Petikam", "Xiao-Xian", "Antonio Criminisi", "Thomas J. Cashman", "Tadas Baltrušaitis"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025", "url": "http://arxiv.org/abs/2507.15365v1", "summary": "The state of the art in human-centric computer vision achieves high accuracy\nand robustness across a diverse range of tasks. The most effective models in\nthis domain have billions of parameters, thus requiring extremely large\ndatasets, expensive training regimes, and compute-intensive inference. In this\npaper, we demonstrate that it is possible to train models on much smaller but\nhigh-fidelity synthetic datasets, with no loss in accuracy and higher\nefficiency. Using synthetic training data provides us with excellent levels of\ndetail and perfect labels, while providing strong guarantees for data\nprovenance, usage rights, and user consent. Procedural data synthesis also\nprovides us with explicit control on data diversity, that we can use to address\nunfairness in the models we train. Extensive quantitative assessment on real\ninput images demonstrates accuracy of our models on three dense prediction\ntasks: depth estimation, surface normal estimation, and soft foreground\nsegmentation. Our models require only a fraction of the cost of training and\ninference when compared with foundational models of similar accuracy. Our\nhuman-centric synthetic dataset and trained models are available at\nhttps://aka.ms/DAViD.", "comment": "Accepted at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.15365v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2409.07007", "title": "$M$-QR decomposition and hyperpower iterative methods for computing outer inverses of tensors", "authors": ["Ratikanta Behera", "Krushnachandra Panigrahy", "Jajati Keshari Sahoo", "Yimin Wei"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      29 pages", "url": "http://arxiv.org/abs/2409.07007v2", "summary": "The outer inverse of tensors plays increasingly significant roles in\ncomputational mathematics, numerical analysis, and other generalized inverses\nof tensors. In this paper, we compute outer inverses with prescribed ranges and\nkernels of a given tensor through tensor QR decomposition and hyperpower\niterative method under the M-product structure, which is a family of\ntensor-tensor products, generalization of the t-product and c-product, allows\nus to suit the physical interpretations across those different modes. We\ndiscuss a theoretical analysis of the nineteen-order convergence of the\nproposed tensor-based iterative method. Further, we design effective\ntensor-based algorithms for computing outer inverses using M-QR decomposition\nand hyperpower iterative method. The theoretical results are validated with\nnumerical examples demonstrating the appropriateness of the proposed methods.", "comment": "29 pages", "pdf_url": "http://arxiv.org/pdf/2409.07007v2", "cate": "math.NA", "date": "2024-09-11", "updated": "2025-07-21"}
{"id": "2507.15489", "title": "Constrained Control Allocation With Continuous-Time Rate Constraints: Three-Dimensional Case", "authors": ["Süleyman Özkurt", "Adrian Grimm", "Walter Fichter"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      Will be submitted as Engineering Note to Journal of Guidance, Control, and Dynamics", "url": "http://arxiv.org/abs/2507.15489v1", "summary": "This paper presents a novel quadratic programming (QP) approach for\nconstrained control allocation that directly incorporates continuous-time\nactuator rate constraints without requiring slack variables. Over-actuated\naircraft configurations, particularly prevalent in eVTOL and military\napplications, require control allocation algorithms to distribute commanded\ncontrol moments among available actuators while respecting position and rate\nconstraints. Existing methods such as direct allocation, pseudo-inverse,\ncascaded generalized inverse, and exact redistributed pseudo-inverse either\ncannot handle rate constraints in continuous time or require discretization\napproaches that compromise performance. Current QP methods that incorporate\nrate constraints rely on slack variables to ensure feasibility, which prevents\nfull utilization of the attainable moment set and degrades allocation\nperformance. The proposed methodology addresses this limitation by calculating\nthe attainable moment set from both position and rate constraints through\nconvex hull operations, then ensuring feasibility by scaling unattainable\ncommanded moments to the boundary of the attainable moment set while preserving\ntheir direction. This approach guarantees the feasibility of the optimization\nproblem without slack variables. The method is validated through simulation on\nan F-18 fighter aircraft control allocation problem, demonstrating equivalent\nperformance to the established exact redistributed pseudo-inverse method while\nproviding smoother actuator behavior and enhanced constraint satisfaction.\nResults show that incorporating continuous-time rate constraints leads to\nimproved actuator tracking, reduced overshoot, and more precise adherence to\nposition limits, which is essential for aircraft safety, ride comfort, and\nactuator longevity.", "comment": "Will be submitted as Engineering Note to Journal of Guidance,\n  Control, and Dynamics", "pdf_url": "http://arxiv.org/pdf/2507.15489v1", "cate": "math.OC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15601", "title": "Optimal Batch-Size Control for Low-Latency Federated Learning with Device Heterogeneity", "authors": ["Huiling Yang", "Zhanwei Wang", "Kaibin Huang"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15601v1", "summary": "Federated learning (FL) has emerged as a popular approach for collaborative\nmachine learning in sixth-generation (6G) networks, primarily due to its\nprivacy-preserving capabilities. The deployment of FL algorithms is expected to\nempower a wide range of Internet-of-Things (IoT) applications, e.g., autonomous\ndriving, augmented reality, and healthcare. The mission-critical and\ntime-sensitive nature of these applications necessitates the design of\nlow-latency FL frameworks that guarantee high learning performance. In\npractice, achieving low-latency FL faces two challenges: the overhead of\ncomputing and transmitting high-dimensional model updates, and the\nheterogeneity in communication-and-computation (C$^2$) capabilities across\ndevices. To address these challenges, we propose a novel C$^2$-aware framework\nfor optimal batch-size control that minimizes end-to-end (E2E) learning latency\nwhile ensuring convergence. The framework is designed to balance a fundamental\nC$^2$ tradeoff as revealed through convergence analysis. Specifically,\nincreasing batch sizes improves the accuracy of gradient estimation in FL and\nthus reduces the number of communication rounds required for convergence, but\nresults in higher per-round latency, and vice versa. The associated problem of\nlatency minimization is intractable; however, we solve it by designing an\naccurate and tractable surrogate for convergence speed, with parameters fitted\nto real data. This approach yields two batch-size control strategies tailored\nto scenarios with slow and fast fading, while also accommodating device\nheterogeneity. Extensive experiments using real datasets demonstrate that the\nproposed strategies outperform conventional batch-size adaptation schemes that\ndo not consider the C$^2$ tradeoff or device heterogeneity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15601v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15203", "title": "Personalized 4D Whole Heart Geometry Reconstruction from Cine MRI for Cardiac Digital Twins", "authors": ["Xiaoyue Liu", "Xicheng Sheng", "Xiahai Zhuang", "Vicente Grau", "Mark YY Chan", "Ching-Hui Sia", "Lei Li"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15203v1", "summary": "Cardiac digital twins (CDTs) provide personalized in-silico cardiac\nrepresentations and hold great potential for precision medicine in cardiology.\nHowever, whole-heart CDT models that simulate the full organ-scale\nelectromechanics of all four heart chambers remain limited. In this work, we\npropose a weakly supervised learning model to reconstruct 4D (3D+t) heart mesh\ndirectly from multi-view 2D cardiac cine MRIs. This is achieved by learning a\nself-supervised mapping between cine MRIs and 4D cardiac meshes, enabling the\ngeneration of personalized heart models that closely correspond to input cine\nMRIs. The resulting 4D heart meshes can facilitate the automatic extraction of\nkey cardiac variables, including ejection fraction and dynamic chamber volume\nchanges with high temporal resolution. It demonstrates the feasibility of\ninferring personalized 4D heart models from cardiac MRIs, paving the way for an\nefficient CDT platform for precision medicine. The code will be publicly\nreleased once the manuscript is accepted.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15203v1", "cate": "eess.IV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15428", "title": "EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent", "authors": ["Jiaao Li", "Kaiyuan Li", "Chen Gao", "Yong Li", "Xinlei Chen"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15428v1", "summary": "Egomotion videos are first-person recordings where the view changes\ncontinuously due to the agent's movement. As they serve as the primary visual\ninput for embodied AI agents, making egomotion video reasoning more efficient\nis therefore essential for real-world deployment. Recent advances in\nvision-language models have enabled strong multimodal reasoning capabilities,\nbut their computational cost remains prohibitive for long, redundant video\ninputs. Existing token pruning methods, typically designed for third-person\nvideos, fail to leverage the spatiotemporal continuity and motion constraints\ninherent in egomotion settings. To address this, we propose EgoPrune, a\ntraining-free token pruning method tailored for egomotion video reasoning.\nEgoPrune comprises three components: a keyframe selector adapted from EmbodiedR\nfor temporally efficient sampling; Perspective-Aware Redundancy Filtering\n(PARF), which aligns visual tokens using perspective transformations and\nremoves redundant tokens; and a Maximal Marginal Relevance (MMR)-based token\nselector that jointly considers visual-text relevance and intra-frame\ndiversity. Experiments on two egomotion video benchmarks show that EgoPrune\nconsistently outperforms prior training-free methods across various pruning\nratios while significantly reducing FLOPs, memory usage, and latency. Moreover,\nwe deploy EgoPrune on an embodied agent equipped with a Jetson Orin NX 16GB\nedge device, demonstrating its real-world efficiency and suitability for\non-device egomotion video reasoning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15428v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15566", "title": "Trade-offs between elective surgery rescheduling and length-of-stay prediction accuracy", "authors": ["Pieter Smet", "Martina Doneda", "Ettore Lanzarone", "Giuliana Carello"], "categories": ["cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15566v1", "summary": "The availability of downstream resources plays a critical role in planning\nthe admission of patients undergoing elective surgery, with inpatient beds\nbeing one of the most crucial resources. When planning patient admissions,\npredictions on their length-of-stay (LOS) made by machine learning (ML) models\nare used to ensure bed availability. However, the actual LOS for each patient\nmay differ considerably from the predicted value, potentially making the\nschedule infeasible. To address such infeasibilities, rescheduling strategies\nthat take advantage of operational flexibility can be implemented. For example,\nadjustments may include postponing admission dates, relocating patients to\ndifferent wards, or even transferring patients who are already admitted. The\ncommon assumption is that more accurate LOS predictions reduce the impact of\nrescheduling. However, training ML models that can make such accurate\npredictions can be costly. Building on previous work that proposed simulated\n\\ac{ml} for evaluating data-driven approaches, this paper explores the\nrelationship between LOS prediction accuracy and rescheduling flexibility\nacross various corrective policies. Specifically, we examine the most effective\npatient rescheduling strategies under LOS prediction errors to prevent bed\noverflows while optimizing resource utilization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15566v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15401", "title": "Rethinking Occlusion in FER: A Semantic-Aware Perspective and Go Beyond", "authors": ["Huiyu Zhai", "Xingxing Yang", "Yalan Ye", "Chenyang Li", "Bin Fan", "Changze Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15401v1", "summary": "Facial expression recognition (FER) is a challenging task due to pervasive\nocclusion and dataset biases. Especially when facial information is partially\noccluded, existing FER models struggle to extract effective facial features,\nleading to inaccurate classifications. In response, we present ORSANet, which\nintroduces the following three key contributions: First, we introduce auxiliary\nmulti-modal semantic guidance to disambiguate facial occlusion and learn\nhigh-level semantic knowledge, which is two-fold: 1) we introduce semantic\nsegmentation maps as dense semantics prior to generate semantics-enhanced\nfacial representations; 2) we introduce facial landmarks as sparse geometric\nprior to mitigate intrinsic noises in FER, such as identity and gender biases.\nSecond, to facilitate the effective incorporation of these two multi-modal\npriors, we customize a Multi-scale Cross-interaction Module (MCM) to adaptively\nfuse the landmark feature and semantics-enhanced representations within\ndifferent scales. Third, we design a Dynamic Adversarial Repulsion Enhancement\nLoss (DARELoss) that dynamically adjusts the margins of ambiguous classes,\nfurther enhancing the model's ability to distinguish similar expressions. We\nfurther construct the first occlusion-oriented FER dataset to facilitate\nspecialized robustness analysis on various real-world occlusion conditions,\ndubbed Occlu-FER. Extensive experiments on both public benchmarks and Occlu-FER\ndemonstrate that our proposed ORSANet achieves SOTA recognition performance.\nCode is publicly available at https://github.com/Wenyuzhy/ORSANet-master.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15401v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2410.10297", "title": "Floquet$-$Bloch analysis of wave propagation with time-periodic coefficients", "authors": ["Jörg Nick", "Ralf Hiptmair", "Habib Ammari"], "categories": ["math.NA", "cs.NA", "65, 35"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      29 pages, 6 figures", "url": "http://arxiv.org/abs/2410.10297v2", "summary": "This paper presents a numerical investigation of acoustic wave propagation in\nan obstacle with periodically time-modulated material parameters. We focus on\nthe numerical construction of Floquet$-$Bloch solutions, which are\nquasi-periodic kernel elements of the hyperbolic operator appearing on the\nleft-hand side of the acoustic wave equation. Using the temporal Fourier\nexpansion yields a system of coupled harmonics, which can be truncated.\nRewriting this system then provides different (generally nonlinear) eigenvalue\nformulations for discretized Floquet$-$Bloch solutions. Deriving energy\nestimates and the necessary conditions for Riesz$-$Schauder theory show basic\nproperties of the occurring Floquet exponents. To derive fully discrete\nschemes, we employ a general Galerkin space discretization. Under assumptions\non the relation of the temporal Fourier truncation and the Galerkin space\ndiscretization, we prove that the approximated Floquet exponents exhibit the\nsame limitations as their continuous counterparts. Moreover, the approximated\nmodes are shown to satisfy the defining properties of Floquet$-$Bloch\nsolutions, with a defect that tends to zero as the number of harmonics\napproaches infinity. Numerical experiments demonstrate the effectiveness of the\nproposed approach and illustrate the theoretical findings.", "comment": "29 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2410.10297v2", "cate": "math.NA", "date": "2024-10-14", "updated": "2025-07-21"}
{"id": "2401.06566", "title": "Maximum Causal Entropy IRL in Mean-Field Games and GNEP Framework for Forward RL", "authors": ["Berkay Anahtarci", "Can Deha Kariksiz", "Naci Saldi"], "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      40 pages", "url": "http://arxiv.org/abs/2401.06566v2", "summary": "This paper explores the use of Maximum Causal Entropy Inverse Reinforcement\nLearning (IRL) within the context of discrete-time stationary Mean-Field Games\n(MFGs) characterized by finite state spaces and an infinite-horizon,\ndiscounted-reward setting. Although the resulting optimization problem is\nnon-convex with respect to policies, we reformulate it as a convex optimization\nproblem in terms of state-action occupation measures by leveraging the linear\nprogramming framework of Markov Decision Processes. Based on this convex\nreformulation, we introduce a gradient descent algorithm with a guaranteed\nconvergence rate to efficiently compute the optimal solution. Moreover, we\ndevelop a new method that conceptualizes the MFG problem as a Generalized Nash\nEquilibrium Problem (GNEP), enabling effective computation of the mean-field\nequilibrium for forward reinforcement learning (RL) problems and marking an\nadvancement in MFG solution techniques. We further illustrate the practical\napplicability of our GNEP approach by employing this algorithm to generate data\nfor numerical MFG examples.", "comment": "40 pages", "pdf_url": "http://arxiv.org/pdf/2401.06566v2", "cate": "eess.SY", "date": "2024-01-12", "updated": "2025-07-19"}
{"id": "2401.10945", "title": "Automatic dimensionality reduction of Twin-in-the-Loop Observers", "authors": ["Giacomo Delcaro", "Riccardo Poli", "Federico Dettù", "Simone Formentin", "Sergio Matteo Savaresi"], "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2401.10945v2", "summary": "Conventional vehicle dynamics estimation methods suffer from the drawback of\nemploying independent, separately calibrated filtering modules for each\nvariable. To address this limitation, a recent proposal introduces a unified\nTwin-in-the-Loop (TiL) Observer architecture. This architecture replaces the\nsimplified control-oriented vehicle model with a full-fledged vehicle simulator\n(digital twin), and employs a real-time correction mechanism using a linear\ntime-invariant output error law. Bayesian Optimization is utilized to tune the\nobserver due to the simulator's black-box nature, leading to a high-dimensional\noptimization problem. This paper focuses on developing a procedure to reduce\nthe observer's complexity by exploring both supervised and unsupervised\nlearning approaches. The effectiveness of these strategies is validated for\nlongitudinal and lateral vehicle dynamics using real-world data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2401.10945v2", "cate": "eess.SY", "date": "2024-01-18", "updated": "2025-07-21"}
{"id": "2507.15476", "title": "A Steel Surface Defect Detection Method Based on Lightweight Convolution Optimization", "authors": ["Cong Chen", "Ming Chen", "Hoileong Lee", "Yan Li", "Jiyang Yu"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15476v1", "summary": "Surface defect detection of steel, especially the recognition of multi-scale\ndefects, has always been a major challenge in industrial manufacturing. Steel\nsurfaces not only have defects of various sizes and shapes, which limit the\naccuracy of traditional image processing and detection methods in complex\nenvironments. However, traditional defect detection methods face issues of\ninsufficient accuracy and high miss-detection rates when dealing with small\ntarget defects. To address this issue, this study proposes a detection\nframework based on deep learning, specifically YOLOv9s, combined with the\nC3Ghost module, SCConv module, and CARAFE upsampling operator, to improve\ndetection accuracy and model performance. First, the SCConv module is used to\nreduce feature redundancy and optimize feature representation by reconstructing\nthe spatial and channel dimensions. Second, the C3Ghost module is introduced to\nenhance the model's feature extraction ability by reducing redundant\ncomputations and parameter volume, thereby improving model efficiency. Finally,\nthe CARAFE upsampling operator, which can more finely reorganize feature maps\nin a content-aware manner, optimizes the upsampling process and ensures\ndetailed restoration of high-resolution defect regions. Experimental results\ndemonstrate that the proposed model achieves higher accuracy and robustness in\nsteel surface defect detection tasks compared to other methods, effectively\naddressing defect detection problems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15476v1", "cate": "eess.IV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15501", "title": "ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution", "authors": ["Alexandru Coca", "Mark Gaynor", "Zhenxing Zhang", "Jianpeng Cheng", "Bo-Hsiang Tseng", "Pete Boothroyd", "Héctor Martinez Alonso", "Diarmuid Ó Séaghdha", "Anders Johannsen"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      37 pages, 22 figures. To appear at ACL 2025", "url": "http://arxiv.org/abs/2507.15501v1", "summary": "This work evaluates the potential of large language models (LLMs) to power\ndigital assistants capable of complex action execution. These assistants rely\non pre-trained programming knowledge to execute multi-step goals by composing\nobjects and functions defined in assistant libraries into action execution\nprograms. To achieve this, we develop ASPERA, a framework comprising an\nassistant library simulation and a human-assisted LLM data generation engine.\nOur engine allows developers to guide LLM generation of high-quality tasks\nconsisting of complex user queries, simulation state and corresponding\nvalidation programs, tackling data availability and evaluation robustness\nchallenges. Alongside the framework we release Asper-Bench, an evaluation\ndataset of 250 challenging tasks generated using ASPERA, which we use to show\nthat program generation grounded in custom assistant libraries is a significant\nchallenge to LLMs compared to dependency-free code generation.", "comment": "37 pages, 22 figures. To appear at ACL 2025", "pdf_url": "http://arxiv.org/pdf/2507.15501v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15574", "title": "On the Role of AI in Managing Satellite Constellations: Insights from the ConstellAI Project", "authors": ["Gregory F. Stock", "Juan A. Fraire", "Holger Hermanns", "Jędrzej Mosiężny", "Yusra Al-Khazraji", "Julio Ramírez Molina", "Evridiki V. Ntagiou"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      18th International Conference on Space Operations (SpaceOps 2025), Montréal, Canada, 26-30 May 2025, this https URL", "url": "http://arxiv.org/abs/2507.15574v1", "summary": "The rapid expansion of satellite constellations in near-Earth orbits presents\nsignificant challenges in satellite network management, requiring innovative\napproaches for efficient, scalable, and resilient operations. This paper\nexplores the role of Artificial Intelligence (AI) in optimizing the operation\nof satellite mega-constellations, drawing from the ConstellAI project funded by\nthe European Space Agency (ESA). A consortium comprising GMV GmbH, Saarland\nUniversity, and Thales Alenia Space collaborates to develop AI-driven\nalgorithms and demonstrates their effectiveness over traditional methods for\ntwo crucial operational challenges: data routing and resource allocation. In\nthe routing use case, Reinforcement Learning (RL) is used to improve the\nend-to-end latency by learning from historical queuing latency, outperforming\nclassical shortest path algorithms. For resource allocation, RL optimizes the\nscheduling of tasks across constellations, focussing on efficiently using\nlimited resources such as battery and memory. Both use cases were tested for\nmultiple satellite constellation configurations and operational scenarios,\nresembling the real-life spacecraft operations of communications and Earth\nobservation satellites. This research demonstrates that RL not only competes\nwith classical approaches but also offers enhanced flexibility, scalability,\nand generalizability in decision-making processes, which is crucial for the\nautonomous and intelligent management of satellite fleets. The findings of this\nactivity suggest that AI can fundamentally alter the landscape of satellite\nconstellation management by providing more adaptive, robust, and cost-effective\nsolutions.", "comment": "18th International Conference on Space Operations (SpaceOps 2025),\n  Montr\\'eal, Canada, 26-30 May 2025,\n  https://star.spaceops.org/2025/user_manudownload.php?doc=140__9bg48dkf.pdf", "pdf_url": "http://arxiv.org/pdf/2507.15574v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15418", "title": "SurgX: Neuron-Concept Association for Explainable Surgical Phase Recognition", "authors": ["Ka Young Kim", "Hyeon Bae Kim", "Seong Tae Kim"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to MICCAI 2025", "url": "http://arxiv.org/abs/2507.15418v1", "summary": "Surgical phase recognition plays a crucial role in surgical workflow\nanalysis, enabling various applications such as surgical monitoring, skill\nassessment, and workflow optimization. Despite significant advancements in deep\nlearning-based surgical phase recognition, these models remain inherently\nopaque, making it difficult to understand how they make decisions. This lack of\ninterpretability hinders trust and makes it challenging to debug the model. To\naddress this challenge, we propose SurgX, a novel concept-based explanation\nframework that enhances the interpretability of surgical phase recognition\nmodels by associating neurons with relevant concepts. In this paper, we\nintroduce the process of selecting representative example sequences for\nneurons, constructing a concept set tailored to the surgical video dataset,\nassociating neurons with concepts and identifying neurons crucial for\npredictions. Through extensive experiments on two surgical phase recognition\nmodels, we validate our method and analyze the explanation for prediction. This\nhighlights the potential of our method in explaining surgical phase\nrecognition. The code is available at https://github.com/ailab-kyunghee/SurgX", "comment": "Accepted to MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.15418v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2501.06369", "title": "Parameter-robust Preconditioners for the Stokes-Darcy Coupled Problem without Fractional Operators", "authors": ["Wietse M. Boon", "Xiaozhe Hu", "Xue Wang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.06369v2", "summary": "We consider the Stokes-Darcy coupled problem, which models the interaction\nbetween free-flow and porous medium flow. By enforcing the normal flux\ncontinuity interface condition directly within the finite-element spaces, we\nestablish unified well-posedness results for the coupled system under various\nboundary condition scenarios. Using the operator preconditioning framework, we\ndevelop a parameter-robust preconditioner that avoids the use of fractional\noperators. Numerical experiments employing both\n$H(\\operatorname{div})$-conforming and nonconforming finite-element methods are\npresented to confirm the theoretical findings and demonstrate the robustness of\nthe proposed block preconditioners with respect to the physical parameters and\nmesh size.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.06369v2", "cate": "math.NA", "date": "2025-01-10", "updated": "2025-07-20"}
{"id": "2408.15703", "title": "Linear-Quadratic Dynamic Games as Receding-Horizon Variational Inequalities", "authors": ["Emilio Benenati", "Sergio Grammatico"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.15703v2", "summary": "We consider dynamic games with linear dynamics and quadratic objective\nfunctions. We observe that the unconstrained open-loop Nash equilibrium\ncoincides with a linear quadratic regulator in an augmented space, thus\nderiving an explicit expression of the cost-to-go. With such cost-to-go as a\nterminal cost, we show asymptotic stability for the receding-horizon solution\nof the finite-horizon, constrained game. Furthermore, we show that the problem\nis equivalent to a non-symmetric variational inequality, which does not\ncorrespond to any Nash equilibrium problem. For unconstrained closed-loop Nash\nequilibria, we derive a receding-horizon controller that is equivalent to the\ninfinite-horizon one and ensures asymptotic stability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.15703v2", "cate": "eess.SY", "date": "2024-08-28", "updated": "2025-07-21"}
{"id": "2409.00002", "title": "Distributed Optimization by Network Flows with Spatio-Temporal Compression", "authors": ["Zihao Ren", "Lei Wang", "Xinlei Yi", "Xi Wang", "Deming Yuan", "Tao Yang", "Zhengguang Wu", "Guodong Shi"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2408.02332", "url": "http://arxiv.org/abs/2409.00002v4", "summary": "Several data compressors have been proposed in distributed optimization\nframeworks of network systems to reduce communication overhead in large-scale\napplications. In this paper, we demonstrate that effective information\ncompression may occur over time or space during sequences of node\ncommunications in distributed algorithms, leading to the concept of\nspatio-temporal compressors. This abstraction classifies existing compressors\nand inspires new compressors as spatio-temporal compressors, with their\neffectiveness described by constructive stability criteria from nonlinear\nsystem theory. Subsequently, we incorporate these spatio-temporal compressors\ndirectly into standard continuous-time consensus flows and distributed\nprimal-dual flows, establishing conditions ensuring exponential convergence.\nAdditionally, we introduce a novel observer-based distributed primal-dual\ncontinuous flow integrated with spatio-temporal compressors, which provides\nbroader convergence conditions. These continuous flows achieve exponential\nconvergence to the global optimum when the objective function is strongly\nconvex and can be discretized using Euler approximations. Finally, numerical\nsimulations illustrate the versatility of the proposed spatio-temporal\ncompressors and verify the convergence of", "comment": "arXiv admin note: text overlap with arXiv:2408.02332", "pdf_url": "http://arxiv.org/pdf/2409.00002v4", "cate": "eess.SY", "date": "2024-08-14", "updated": "2025-07-19"}
{"id": "2507.15487", "title": "DeSamba: Decoupled Spectral Adaptive Framework for 3D Multi-Sequence MRI Lesion Classification", "authors": ["Dezhen Wang", "Sheng Miao", "Rongxin Chai", "Jiufa Cui"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      7 figures, 3 tables, submitted to AAAI2026", "url": "http://arxiv.org/abs/2507.15487v1", "summary": "Magnetic Resonance Imaging (MRI) sequences provide rich spatial and frequency\ndomain information, which is crucial for accurate lesion classification in\nmedical imaging. However, effectively integrating multi-sequence MRI data for\nrobust 3D lesion classification remains a challenge. In this paper, we propose\nDeSamba (Decoupled Spectral Adaptive Network and Mamba-Based Model), a novel\nframework designed to extract decoupled representations and adaptively fuse\nspatial and spectral features for lesion classification. DeSamba introduces a\nDecoupled Representation Learning Module (DRLM) that decouples features from\ndifferent MRI sequences through self-reconstruction and cross-reconstruction,\nand a Spectral Adaptive Modulation Block (SAMB) within the proposed SAMNet,\nenabling dynamic fusion of spectral and spatial information based on lesion\ncharacteristics. We evaluate DeSamba on two clinically relevant 3D datasets. On\na six-class spinal metastasis dataset (n=1,448), DeSamba achieves 62.10% Top-1\naccuracy, 63.62% F1-score, 87.71% AUC, and 93.55% Top-3 accuracy on an external\nvalidation set (n=372), outperforming all state-of-the-art (SOTA) baselines. On\na spondylitis dataset (n=251) involving a challenging binary classification\ntask, DeSamba achieves 70.00%/64.52% accuracy and 74.75/73.88 AUC on internal\nand external validation sets, respectively. Ablation studies demonstrate that\nboth DRLM and SAMB significantly contribute to overall performance, with over\n10% relative improvement compared to the baseline. Our results highlight the\npotential of DeSamba as a generalizable and effective solution for 3D lesion\nclassification in multi-sequence medical imaging.", "comment": "7 figures, 3 tables, submitted to AAAI2026", "pdf_url": "http://arxiv.org/pdf/2507.15487v1", "cate": "eess.IV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15524", "title": "RARE-UNet: Resolution-Aligned Routing Entry for Adaptive Medical Image Segmentation", "authors": ["Simon Winther Albertsen", "Hjalte Svaneborg Bjørnstrup", "Mostafa Mehdipour Ghazi"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      EMA4MICCAI 2025", "url": "http://arxiv.org/abs/2507.15524v1", "summary": "Accurate segmentation is crucial for clinical applications, but existing\nmodels often assume fixed, high-resolution inputs and degrade significantly\nwhen faced with lower-resolution data in real-world scenarios. To address this\nlimitation, we propose RARE-UNet, a resolution-aware multi-scale segmentation\narchitecture that dynamically adapts its inference path to the spatial\nresolution of the input. Central to our design are multi-scale blocks\nintegrated at multiple encoder depths, a resolution-aware routing mechanism,\nand consistency-driven training that aligns multi-resolution features with\nfull-resolution representations. We evaluate RARE-UNet on two benchmark brain\nimaging tasks for hippocampus and tumor segmentation. Compared to standard\nUNet, its multi-resolution augmented variant, and nnUNet, our model achieves\nthe highest average Dice scores of 0.84 and 0.65 across resolution, while\nmaintaining consistent performance and significantly reduced inference time at\nlower resolutions. These results highlight the effectiveness and scalability of\nour architecture in achieving resolution-robust segmentation. The codes are\navailable at: https://github.com/simonsejse/RARE-UNet.", "comment": "EMA4MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.15524v1", "cate": "eess.IV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15584", "title": "We Need to Rethink Benchmarking in Anomaly Detection", "authors": ["Philipp Röchner", "Simon Klüttermann", "Franz Rothlauf", "Daniel Schlör"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15584v1", "summary": "Despite the continuous proposal of new anomaly detection algorithms and\nextensive benchmarking efforts, progress seems to stagnate, with only minor\nperformance differences between established baselines and new algorithms. In\nthis position paper, we argue that this stagnation is due to limitations in how\nwe evaluate anomaly detection algorithms. Current benchmarking does not, for\nexample, sufficiently reflect the diversity of anomalies in applications\nranging from predictive maintenance to scientific discovery. Consequently, we\nneed to rethink benchmarking in anomaly detection. In our opinion, anomaly\ndetection should be studied using scenarios that capture the relevant\ncharacteristics of different applications. We identify three key areas for\nimprovement: First, we need to identify anomaly detection scenarios based on a\ncommon taxonomy. Second, anomaly detection pipelines should be analyzed\nend-to-end and by component. Third, evaluating anomaly detection algorithms\nshould be meaningful regarding the scenario's objectives.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15584v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15480", "title": "One Last Attention for Your Vision-Language Model", "authors": ["Liang Chen", "Ghazi Shazan Ahmad", "Tianjun Yao", "Lingqiao Liu", "Zhiqiang Shen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.15480v1", "summary": "Pretrained vision-language models (VLMs), such as CLIP, achieve remarkable\nzero-shot performance, yet their downstream potential hinges on effective\nfine-tuning. Most adaptation methods typically focus on refining representation\nfrom separate modalities (text or vision) but neglect the critical role of\ntheir fused representations in the decision-making process, \\emph{\\ie} rational\nmatrix that drives the final prediction. To bridge the gap, we propose a simple\nyet effective \\textbf{R}ational \\textbf{Ada}ptaion ({RAda}) to explicitly\nexploit the final fused representation during fine-tuning. RAda employs a\nlearned mask, obtained from a lightweight attention layer attached at the end\nof a VLM, to dynamically calibrate the contribution of each element in the\nrational matrix, enabling targeted adjustments to the final cross-modal\ninteractions without incurring costly modifications to intermediate features.\nExperiments in different settings (i.e., updating, or freezing pretrained\nencoders in adaptation, and test-time training that can only access the\nunlabeled test data) show that RAda serves as a versatile fine-tuning\ntechnique, improving the baseline with minimal code and performing comparably\nagainst current arts in most settings. Code is available at\n\\href{https://github.com/khufia/RAda/tree/main}{github.com/khufia/RAda}.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.15480v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2503.05742", "title": "Adaptive SIPG method for approximations of boundary control problems governed by parabolic PDEs", "authors": ["Ram Manohar", "B. V. Rathish Kumar", "Kedarnath Buda", "Rajen Kumar Sinha"], "categories": ["math.NA", "cs.NA", "$65N30$, $65N50$, $49J20$, $65K10$"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      41 pages, 26 Figures, 4 Authors", "url": "http://arxiv.org/abs/2503.05742v2", "summary": "This study presents an aposteriori error analysis of adaptive finite element\napproximations of parabolic boundary control problems with bilateral box\nconstraints that act on a Neumann boundary. The control problem is discretized\nusing the symmetric interior penalty Galerkin (SIPG) technique. We derive both\nreliable and efficient type residual-based error estimators coupling with the\ndata oscillations. The implementation of these error estimators serves as a\nguide for the adaptive mesh refinement process, indicating whether or not more\nrefinement is required. Although the control error estimator effectively\ncaptured control approximation errors, it had limitations in guiding refinement\nlocalization in critical cases. To overcome this, an alternative control\nindicator was used in numerical tests. The results demonstrated the clear\nsuperiority of adaptive refinements over uniform refinements, confirming the\nproposed approach's effectiveness in achieving accurate solutions while\noptimizing computational efficiency. numerical experiment showcases the\neffectiveness of the derived error estimators.", "comment": "41 pages, 26 Figures, 4 Authors", "pdf_url": "http://arxiv.org/pdf/2503.05742v2", "cate": "math.NA", "date": "2025-02-20", "updated": "2025-07-20"}
{"id": "2410.06771", "title": "Safe and High-Performance Learning of Model Predicitve Control using Kernel-Based Interpolation", "authors": ["Alexander Rose", "Philipp Schaub", "Rolf Findeisen"], "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.06771v2", "summary": "We present a method that allows efficient and safe approximation of model\npredictive controllers using kernel interpolation. Since the computational\ncomplexity of the approximating function scales linearly with the number of\ndata points, we propose to use a scoring function which chooses the most\npromising data. To further reduce the complexity of the approximation, we\nrestrict our considerations to the set of closed-loop reachable states. That\nis, the approximating function only has to be accurate within this set. This\nmakes our method especially suited for systems, where the set of initial\nconditions is small. In order to guarantee safety and high performance of the\ndesigned approximated controller, we use reachability analysis based on Monte\nCarlo methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.06771v2", "cate": "eess.SY", "date": "2024-10-09", "updated": "2025-07-21"}
{"id": "2410.13763", "title": "Assessing the Optimistic Bias in the Natural Inflow Forecasts: A Call for Model Monitoring in Brazil", "authors": ["Arthur Brigatto", "Alexandre Street", "Cristiano Fernandes", "Davi Valladao", "Guilherme Bodin", "Joaquim Dias Garcia"], "categories": ["eess.SY", "cs.SY", "stat.AP"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.13763v4", "summary": "Hydroelectricity accounted for roughly 61.4% of Brazil's total generation in\n2024 and addressed most of the intermittency of wind and solar generation.\nThus, inflow forecasting plays a critical role in the operation, planning, and\nmarket in this country, as well as in any other hydro-dependent power system.\nThese forecasts influence generation schedules, reservoir management, and\nmarket pricing, shaping the dynamics of the entire electricity sector. The\nobjective of this paper is to measure and present empirical evidence of a\nsystematic optimistic bias in the official inflow forecast methodology, which\nis based on the PAR(p)-A model. Additionally, we discuss possible sources of\nthis bias and recommend ways to mitigate it. By analyzing 14 years of\nhistorical data from the Brazilian system through rolling-window multistep\n(out-of-sample) forecasts, results indicate that the official forecast model\nexhibits statistically significant biases of 1.28, 3.83, 5.39, and 6.73 average\nGW for 1-, 6-, 12-, and 24-step-ahead forecasts in the Southeast subsystem, and\n0.54, 1.66, 2.32, and 3.17 average GW in the Northeast subsystem. These\nfindings uncover the limitations of current inflow forecasting methodologies\nused in Brazil and call for new governance and monitoring policies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.13763v4", "cate": "eess.SY", "date": "2024-10-17", "updated": "2025-07-19"}
{"id": "2507.14437", "title": "Large-scale compressive microscopy via diffractive multiplexing across a sensor array", "authors": ["Kevin C. Zhou", "Chaoying Gu", "Muneki Ikeda", "Tina M. Hayward", "Nicholas Antipa", "Rajesh Menon", "Roarke Horstmeyer", "Saul Kato", "Laura Waller"], "categories": ["physics.optics", "eess.IV"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14437v1", "summary": "Microscopes face a trade-off between spatial resolution, field-of-view, and\nframe rate -- improving one of these properties typically requires sacrificing\nthe others, due to the limited spatiotemporal throughput of the sensor. To\novercome this, we propose a new microscope that achieves snapshot\ngigapixel-scale imaging with a sensor array and a diffractive optical element\n(DOE). We improve the spatiotemporal throughput in two ways. First, we capture\ndata with an array of 48 sensors resulting in 48x more pixels than a single\nsensor. Second, we use point spread function (PSF) engineering and compressive\nsensing algorithms to fill in the missing information from the gaps surrounding\nthe individual sensors in the array, further increasing the spatiotemporal\nthroughput of the system by an additional >5.4x. The array of sensors is\nmodeled as a single large-format \"super-sensor,\" with erasures corresponding to\nthe gaps between the individual sensors. The array is placed at the output of a\n(nearly) 4f imaging system, and we design a DOE for the Fourier plane that\ngenerates a distributed PSF that encodes information from the entire\nsuper-sensor area, including the gaps. We then computationally recover the\nlarge-scale image, assuming the object is sparse in some domain. Our\ncalibration-free microscope can achieve ~3 {\\mu}m resolution over >5.2 cm^2\nFOVs at up to 120 fps, culminating in a total spatiotemporal throughput of 25.2\nbillion pixels per second. We demonstrate the versatility of our microscope in\ntwo different modes: structural imaging via darkfield contrast and functional\nfluorescence imaging of calcium dynamics across dozens of freely moving C.\nelegans simultaneously.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14437v1", "cate": "physics.optics", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15577", "title": "GeMix: Conditional GAN-Based Mixup for Improved Medical Image Augmentation", "authors": ["Hugo Carlesso", "Maria Eliza Patulea", "Moncef Garouani", "Radu Tudor Ionescu", "Josiane Mothe"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15577v1", "summary": "Mixup has become a popular augmentation strategy for image classification,\nyet its naive pixel-wise interpolation often produces unrealistic images that\ncan hinder learning, particularly in high-stakes medical applications. We\npropose GeMix, a two-stage framework that replaces heuristic blending with a\nlearned, label-aware interpolation powered by class-conditional GANs. First, a\nStyleGAN2-ADA generator is trained on the target dataset. During augmentation,\nwe sample two label vectors from Dirichlet priors biased toward different\nclasses and blend them via a Beta-distributed coefficient. Then, we condition\nthe generator on this soft label to synthesize visually coherent images that\nlie along a continuous class manifold. We benchmark GeMix on the large-scale\nCOVIDx-CT-3 dataset using three backbones (ResNet-50, ResNet-101,\nEfficientNet-B0). When combined with real data, our method increases macro-F1\nover traditional mixup for all backbones, reducing the false negative rate for\nCOVID-19 detection. GeMix is thus a drop-in replacement for pixel-space mixup,\ndelivering stronger regularization and greater semantic fidelity, without\ndisrupting existing training pipelines. We publicly release our code at\nhttps://github.com/hugocarlesso/GeMix to foster reproducibility and further\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15577v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15587", "title": "Red-Team Multi-Agent Reinforcement Learning for Emergency Braking Scenario", "authors": ["Yinsong Chen", "Kaifeng Wang", "Xiaoqiang Meng", "Xueyuan Li", "Zirui Li", "Xin Gao"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15587v1", "summary": "Current research on decision-making in safety-critical scenarios often relies\non inefficient data-driven scenario generation or specific modeling approaches,\nwhich fail to capture corner cases in real-world contexts. To address this\nissue, we propose a Red-Team Multi-Agent Reinforcement Learning framework,\nwhere background vehicles with interference capabilities are treated as\nred-team agents. Through active interference and exploration, red-team vehicles\ncan uncover corner cases outside the data distribution. The framework uses a\nConstraint Graph Representation Markov Decision Process, ensuring that red-team\nvehicles comply with safety rules while continuously disrupting the autonomous\nvehicles (AVs). A policy threat zone model is constructed to quantify the\nthreat posed by red-team vehicles to AVs, inducing more extreme actions to\nincrease the danger level of the scenario. Experimental results show that the\nproposed framework significantly impacts AVs decision-making safety and\ngenerates various corner cases. This method also offers a novel direction for\nresearch in safety-critical scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15587v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15492", "title": "An aerial color image anomaly dataset for search missions in complex forested terrain", "authors": ["Rakesh John Amala Arokia Nathan", "Matthias Gessner", "Nurullah Özkan", "Marius Bock", "Mohamed Youssef", "Maximilian Mews", "Björn Piltz", "Ralf Berger", "Oliver Bimber"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages", "url": "http://arxiv.org/abs/2507.15492v1", "summary": "After a family murder in rural Germany, authorities failed to locate the\nsuspect in a vast forest despite a massive search. To aid the search, a\nresearch aircraft captured high-resolution aerial imagery. Due to dense\nvegetation obscuring small clues, automated analysis was ineffective, prompting\na crowd-search initiative. This effort produced a unique dataset of labeled,\nhard-to-detect anomalies under occluded, real-world conditions. It can serve as\na benchmark for improving anomaly detection approaches in complex forest\nenvironments, supporting manhunts and rescue operations. Initial benchmark\ntests showed existing methods performed poorly, highlighting the need for\ncontext-aware approaches. The dataset is openly accessible for offline\nprocessing. An additional interactive web interface supports online viewing and\ndynamic growth by allowing users to annotate and submit new findings.", "comment": "17 pages", "pdf_url": "http://arxiv.org/pdf/2507.15492v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2503.16110", "title": "Compact implicit high resolution numerical method for solving transport problems with sorption isotherms", "authors": ["Dagmar Zakova", "Peter Frolkovic"], "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.16110v2", "summary": "This study investigates numerical methods to solve nonlinear transport\nproblems characterized by various sorption isotherms with a focus on the\nFreundlich type of isotherms. We describe and compare second order accurate\nnumerical schemes, focusing on implicit methods, to effectively model transport\nphenomena without stability restriction on the choice of time steps.\nFurthermore, a high resolution form of the method is proposed that limits a\npriori the second order accurate scheme towards first order accuracy to keep\nthe values of numerical solutions in a physically acceptable range. Through\nnumerical experiments, we demonstrate the effectiveness of high resolution\nmethods in minimizing oscillations near discontinuities, thereby enhancing\nsolution plausibility. The observed convergence rates confirm that the second\norder accurate schemes achieve expected accuracy for smooth solutions and that\nthey yield significant improvements when compared with the results of the first\norder scheme. As the computational cost of the compact implicit method seems to\nbe comparable to similar explicit ones with a clear profit of unconditional\nstability, this research provides a practical tool toward numerical simulations\nof nonlinear transport phenomena applicable in various fields such as\ncontaminant transport in porous media or column liquid chromatography.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.16110v2", "cate": "math.NA", "date": "2025-03-20", "updated": "2025-07-21"}
{"id": "2410.18669", "title": "Trajectory Optimization for Unknown Maneuvering Target Tracking with Bearing-only Measurements", "authors": ["Yingbo Fu", "Ziwen Yang", "Liang Xu", "Yi Guo", "Shanying Zhu", "Xinnping Guan"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.18669v3", "summary": "This paper studies trajectory optimization of an autonomous underwater\nvehicle (AUV) to track an unknown maneuvering target. Due to the restrictions\non sensing capabilities in the underwater scenario, the AUV is limited to\ncollecting only bearing measurements to the target. A framework called GBT is\nproposed with integration of online learning and planning. First, a Gaussian\nprocess learning method is proposed for the AUV to handle unknown target\nmotion, wherein pseudo linear transformation of bearing measurements is\nintroduced to address nonlinearity of bearings. A probabilistic\nbearing-data-dependent bound on tracking error is then rigorously established.\nBased on it, optimal desired bearings that can reduce tracking uncertainty are\nobtained analytically. Finally, the trajectory optimization problem is\nformulated and transformed into an easily solved one with parametric\ntransformation. Numerical examples and comparison with existing methods verify\nthe feasibility and superior performance of our proposed framework.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.18669v3", "cate": "eess.SY", "date": "2024-10-24", "updated": "2025-07-20"}
{"id": "2411.07594", "title": "Modelling and Control of Subsonic Missile for Air-to-Air Interception", "authors": ["Rory Jenkins", "Xinhua Wang"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.07594v3", "summary": "Subsonic missiles play an important role in modern air-to-air combat\nscenarios - utilized by the F-35 Lightning II - but require complex Guidance,\nNavigation and Control systems to manoeuvre with 30G's of acceleration to\nintercept successfully. Challenges with mathematically modelling and\ncontrolling such a dynamic system must be addressed, high frequency noise\nrejected, and actuator delay compensated for. This paper aims to investigate\nthe control systems necessary for interception. It also proposes a subsonic\ndesign utilizing literature and prior research, suggests aerodynamic\nderivatives, and analyses a designed 2D reduced pitch autopilot control system\nresponse against performances. The pitch autopilot model contains an optimized\nPID controller, 2nd order actuator, lead compensator and Kalman Filter, that\nrejects time varying disturbances and high frequency noise expected during\nflight. Simulation results confirm the effectiveness of the proposed method\nthrough reduction in rise time (21%), settle time (10%), and highlighted its\nhigh frequency deficiency with respect to the compensator integration. The\nactuator delay of 100ms has been negated by the augmented compensator autopilot\ncontroller so that it exceeds system performance requirements (1) & (3).\nHowever, (2) is not satisfied as 370% overshoot exists. This research confirms\nthe importance of a lead compensator in missile GNC systems and furthers\ncontrol design application through a specific configuration. Future research\nshould build upon methods and models presented to construct and test an\ninterception scenario.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.07594v3", "cate": "eess.SY", "date": "2024-11-12", "updated": "2025-07-19"}
{"id": "2507.15578", "title": "Compress-Align-Detect: onboard change detection from unregistered images", "authors": ["Gabriele Inzerillo", "Diego Valsesia", "Aniello Fiengo", "Enrico Magli"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15578v1", "summary": "Change detection from satellite images typically incurs a delay ranging from\nseveral hours up to days because of latency in downlinking the acquired images\nand generating orthorectified image products at the ground stations; this may\npreclude real- or near real-time applications. To overcome this limitation, we\npropose shifting the entire change detection workflow onboard satellites. This\nrequires to simultaneously solve challenges in data storage, image registration\nand change detection with a strict complexity constraint. In this paper, we\npresent a novel and efficient framework for onboard change detection that\naddresses the aforementioned challenges in an end-to-end fashion with a deep\nneural network composed of three interlinked submodules: (1) image compression,\ntailored to minimize onboard data storage resources; (2) lightweight\nco-registration of non-orthorectified multi-temporal image pairs; and (3) a\nnovel temporally-invariant and computationally efficient change detection\nmodel. This is the first approach in the literature combining all these tasks\nin a single end-to-end framework with the constraints dictated by onboard\nprocessing. Experimental results compare each submodule with the current\nstate-of-the-art, and evaluate the performance of the overall integrated system\nin realistic setting on low-power hardware. Compelling change detection results\nare obtained in terms of F1 score as a function of compression rate, sustaining\na throughput of 0.7 Mpixel/s on a 15W accelerator.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15578v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15614", "title": "Accelerating HEC-RAS: A Recurrent Neural Operator for Rapid River Forecasting", "authors": ["Edward Holmberg", "Pujan Pokhrel", "Maximilian Zoch", "Elias Ioup", "Ken Pathak", "Steven Sloan", "Kendall Niles", "Jay Ratcliff", "Maik Flanagin", "Christian Guetl", "Julian Simeonov", "Mahdi Abdelguerfi"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 8 figures", "url": "http://arxiv.org/abs/2507.15614v1", "summary": "Physics-based solvers like HEC-RAS provide high-fidelity river forecasts but\nare too computationally intensive for on-the-fly decision-making during flood\nevents. The central challenge is to accelerate these simulations without\nsacrificing accuracy. This paper introduces a deep learning surrogate that\ntreats HEC-RAS not as a solver but as a data-generation engine. We propose a\nhybrid, auto-regressive architecture that combines a Gated Recurrent Unit (GRU)\nto capture short-term temporal dynamics with a Geometry-Aware Fourier Neural\nOperator (Geo-FNO) to model long-range spatial dependencies along a river\nreach. The model learns underlying physics implicitly from a minimal\neight-channel feature vector encoding dynamic state, static geometry, and\nboundary forcings extracted directly from native HEC-RAS files. Trained on 67\nreaches of the Mississippi River Basin, the surrogate was evaluated on a\nyear-long, unseen hold-out simulation. Results show the model achieves a strong\npredictive accuracy, with a median absolute stage error of 0.31 feet.\nCritically, for a full 67-reach ensemble forecast, our surrogate reduces the\nrequired wall-clock time from 139 minutes to 40 minutes, a speedup of nearly\n3.5 times over the traditional solver. The success of this data-driven approach\ndemonstrates that robust feature engineering can produce a viable, high-speed\nreplacement for conventional hydraulic models, improving the computational\nfeasibility of large-scale ensemble flood forecasting.", "comment": "10 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.15614v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15640", "title": "Data Mixing Agent: Learning to Re-weight Domains for Continual Pre-training", "authors": ["Kailai Yang", "Xiao Liu", "Lei Ji", "Hao Li", "Yeyun Gong", "Peng Cheng", "Mao Yang"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15640v1", "summary": "Continual pre-training on small-scale task-specific data is an effective\nmethod for improving large language models in new target fields, yet it risks\ncatastrophic forgetting of their original capabilities. A common solution is to\nre-weight training data mixtures from source and target fields on a domain\nspace to achieve balanced performance. Previous domain reweighting strategies\nrely on manual designation with certain heuristics based on human intuition or\nempirical results. In this work, we prove that more general heuristics can be\nparameterized by proposing Data Mixing Agent, the first model-based, end-to-end\nframework that learns to re-weight domains. The agent learns generalizable\nheuristics through reinforcement learning on large quantities of data mixing\ntrajectories with corresponding feedback from an evaluation environment.\nExperiments in continual pre-training on math reasoning show that Data Mixing\nAgent outperforms strong baselines in achieving balanced performance across\nsource and target field benchmarks. Furthermore, it generalizes well across\nunseen source fields, target models, and domain spaces without retraining.\nDirect application to the code generation field also indicates its adaptability\nacross target domains. Further analysis showcases the agents' well-aligned\nheuristics with human intuitions and their efficiency in achieving superior\nmodel performance with less source-field data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15640v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15504", "title": "Quantifying and Narrowing the Unknown: Interactive Text-to-Video Retrieval via Uncertainty Minimization", "authors": ["Bingqing Zhang", "Zhuo Cao", "Heming Du", "Yang Li", "Xue Li", "Jiajun Liu", "Sen Wang"], "categories": ["cs.CV", "68T45", "I.2.10; H.3.3"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.15504v1", "summary": "Despite recent advances, Text-to-video retrieval (TVR) is still hindered by\nmultiple inherent uncertainties, such as ambiguous textual queries, indistinct\ntext-video mappings, and low-quality video frames. Although interactive systems\nhave emerged to address these challenges by refining user intent through\nclarifying questions, current methods typically rely on heuristic or ad-hoc\nstrategies without explicitly quantifying these uncertainties, limiting their\neffectiveness. Motivated by this gap, we propose UMIVR, an\nUncertainty-Minimizing Interactive Text-to-Video Retrieval framework that\nexplicitly quantifies three critical uncertainties-text ambiguity, mapping\nuncertainty, and frame uncertainty-via principled, training-free metrics:\nsemantic entropy-based Text Ambiguity Score (TAS), Jensen-Shannon\ndivergence-based Mapping Uncertainty Score (MUS), and a Temporal Quality-based\nFrame Sampler (TQFS). By adaptively generating targeted clarifying questions\nguided by these uncertainty measures, UMIVR iteratively refines user queries,\nsignificantly reducing retrieval ambiguity. Extensive experiments on multiple\nbenchmarks validate UMIVR's effectiveness, achieving notable gains in Recall@1\n(69.2\\% after 10 interactive rounds) on the MSR-VTT-1k dataset, thereby\nestablishing an uncertainty-minimizing foundation for interactive TVR.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.15504v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2504.08608", "title": "Discretization Error Analysis of a High Order Unfitted Space-Time Method for moving domain problems", "authors": ["Fabian Heimann", "Christoph Lehrenfeld", "Janosch Preuß"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.08608v2", "summary": "We present a numerical analysis of a higher order unfitted space-time Finite\nElement method applied to a convection-diffusion model problem posed on a\nmoving bulk domain. The method uses isoparametric space-time mappings for the\ngeometry approximation of level set domains and has been presented and\ninvestigated computationally in [Heimann, Lehrenfeld, Preu{\\ss}, SIAM J. Sci.\nComp. 45(2), 2023, B139 - B165]. Recently, in [Heimann, Lehrenfeld, IMA J.\nNumer. Anal., 2025] error bounds for the geometry approximation have been\nproven. In this paper we prove stability and accuracy including the influence\nof the geometry approximation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.08608v2", "cate": "math.NA", "date": "2025-04-11", "updated": "2025-07-21"}
{"id": "2411.10805", "title": "Existence of $ε$-Nash Equilibria in Nonzero-Sum and Zero-Sum Markov Games with Standard Borel Spaces via Finite Model Approximations", "authors": ["Naci Saldi", "Gurdal Arslan", "Serdar Yuksel"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.10805v2", "summary": "Establishing the existence of exact or near Markov or stationary perfect Nash\nequilibria in nonzero-sum Markov games over Borel spaces is a challenging\nproblem with limited positive results. Motivated by problems in multi-agent and\nBayesian learning, this paper demonstrates the existence of approximate Markov\nand stationary Nash equilibria for such games under mild regularity conditions.\nOur approach is constructive: For both compact and non-compact state spaces, we\napproximate the Borel model with finite state-action models and show that their\nequilibria correspond to \\(\\epsilon\\)-equilibria for the original game.\nCompared with previous results in the literature, which we comprehensively\nreview, we provide more general and complementary conditions, along with\nexplicit approximation models whose equilibria are $\\epsilon$-equilibria for\nthe original model. For completeness, we also study the approximation of\nzero-sum Markov games and Markov teams to highlight the key differences between\nzero-sum and nonzero-sum settings. In particular, while for zero-sum and team\ngames, joint weak (Feller) continuity of the transition kernel is sufficient\n(as the value function is continuous), this is not the case for general\nnonzero-sum games.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.10805v2", "cate": "eess.SY", "date": "2024-11-16", "updated": "2025-07-19"}
{"id": "2412.03919", "title": "Learning Robust Safety Controllers for Uncertain Input-Affine Polynomial Systems", "authors": ["Omid Akbarzadeh", "MohammadHossein Ashoori", "Abolfazl Lavaei"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.03919v2", "summary": "This paper offers a direct data-driven approach for learning robust control\nbarrier certificates (R-CBCs) and robust safety controllers (R-SCs) for\ndiscrete-time input-affine polynomial systems with unknown dynamics under\nunknown-but-bounded disturbances. The proposed method relies on data from\ninput-state observations collected over a finite-time horizon while satisfying\na specific rank condition to ensure the system is persistently excited. Our\ndata-driven scheme enables the synthesis of R-CBCs and R-SCs directly from\nobserved data, bypassing the need for explicit modeling of the system's\ndynamics and thus ensuring robust system safety against disturbances within an\ninfinite time horizon. Our proposed approach is formulated as a sum-of-squares\n(SOS) optimization problem, providing a structured design framework. Two case\nstudies showcase our method's capability to provide robust safety guarantees\nfor unknown input-affine polynomial systems under bounded disturbances,\ndemonstrating its practical effectiveness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.03919v2", "cate": "eess.SY", "date": "2024-12-05", "updated": "2025-07-20"}
{"id": "2406.00758", "title": "Once-for-All: Controllable Generative Image Compression with Dynamic Granularity Adaptation", "authors": ["Anqi Li", "Feng Li", "Yuxi Liu", "Runmin Cong", "Yao Zhao", "Huihui Bai"], "categories": ["eess.IV", "cs.CV", "cs.MM"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted by ICLR 2025. Code is available at this https URL", "url": "http://arxiv.org/abs/2406.00758v4", "summary": "Although recent generative image compression methods have demonstrated\nimpressive potential in optimizing the rate-distortion-perception trade-off,\nthey still face the critical challenge of flexible rate adaption to diverse\ncompression necessities and scenarios. To overcome this challenge, this paper\nproposes a Controllable Generative Image Compression framework, termed\nControl-GIC, the first capable of fine-grained bitrate adaption across a broad\nspectrum while ensuring high-fidelity and generality compression. Control-GIC\nis grounded in a VQGAN framework that encodes an image as a sequence of\nvariable-length codes (i.e. VQ-indices), which can be losslessly compressed and\nexhibits a direct positive correlation with the bitrates. Drawing inspiration\nfrom the classical coding principle, we correlate the information density of\nlocal image patches with their granular representations. Hence, we can flexibly\ndetermine a proper allocation of granularity for the patches to achieve dynamic\nadjustment for VQ-indices, resulting in desirable compression rates. We further\ndevelop a probabilistic conditional decoder capable of retrieving historic\nencoded multi-granularity representations according to transmitted codes, and\nthen reconstruct hierarchical granular features in the formalization of\nconditional probability, enabling more informative aggregation to improve\nreconstruction realism. Our experiments show that Control-GIC allows highly\nflexible and controllable bitrate adaption where the results demonstrate its\nsuperior performance over recent state-of-the-art methods. Code is available at\nhttps://github.com/lianqi1008/Control-GIC.", "comment": "Accepted by ICLR 2025. Code is available at\n  https://github.com/lianqi1008/Control-GIC", "pdf_url": "http://arxiv.org/pdf/2406.00758v4", "cate": "eess.IV", "date": "2024-06-02", "updated": "2025-07-19"}
{"id": "2507.15636", "title": "Uncovering Critical Features for Deepfake Detection through the Lottery Ticket Hypothesis", "authors": ["Lisan Al Amin", "Md. Ismail Hossain", "Thanh Thi Nguyen", "Tasnim Jahan", "Mahbubul Islam", "Faisal Quader"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted for publication at the 2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)", "url": "http://arxiv.org/abs/2507.15636v1", "summary": "Recent advances in deepfake technology have created increasingly convincing\nsynthetic media that poses significant challenges to information integrity and\nsocial trust. While current detection methods show promise, their underlying\nmechanisms remain poorly understood, and the large sizes of their models make\nthem challenging to deploy in resource-limited environments. This study\ninvestigates the application of the Lottery Ticket Hypothesis (LTH) to deepfake\ndetection, aiming to identify the key features crucial for recognizing\ndeepfakes. We examine how neural networks can be efficiently pruned while\nmaintaining high detection accuracy. Through extensive experiments with\nMesoNet, CNN-5, and ResNet-18 architectures on the OpenForensic and\nFaceForensics++ datasets, we find that deepfake detection networks contain\nwinning tickets, i.e., subnetworks, that preserve performance even at\nsubstantial sparsity levels. Our results indicate that MesoNet retains 56.2%\naccuracy at 80% sparsity on the OpenForensic dataset, with only 3,000\nparameters, which is about 90% of its baseline accuracy (62.6%). The results\nalso show that our proposed LTH-based iterative magnitude pruning approach\nconsistently outperforms one-shot pruning methods. Using Grad-CAM\nvisualization, we analyze how pruned networks maintain their focus on critical\nfacial regions for deepfake detection. Additionally, we demonstrate the\ntransferability of winning tickets across datasets, suggesting potential for\nefficient, deployable deepfake detection systems.", "comment": "Accepted for publication at the 2025 IEEE International Conference on\n  Systems, Man, and Cybernetics (SMC)", "pdf_url": "http://arxiv.org/pdf/2507.15636v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15643", "title": "Towards Explainable Anomaly Detection in Shared Mobility Systems", "authors": ["Elnur Isgandarov", "Matteo Cederle", "Federico Chiariotti", "Gian Antonio Susto"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      6 pages, 8 figures. Paper accepted to J3C 2025 (Joint Conference on Computers, Cognition and Communication", "url": "http://arxiv.org/abs/2507.15643v1", "summary": "Shared mobility systems, such as bike-sharing networks, play a crucial role\nin urban transportation. Identifying anomalies in these systems is essential\nfor optimizing operations, improving service reliability, and enhancing user\nexperience. This paper presents an interpretable anomaly detection framework\nthat integrates multi-source data, including bike-sharing trip records, weather\nconditions, and public transit availability. The Isolation Forest algorithm is\nemployed for unsupervised anomaly detection, along with the Depth-based\nIsolation Forest Feature Importance (DIFFI) algorithm providing\ninterpretability. Results show that station-level analysis offers a robust\nunderstanding of anomalies, highlighting the influence of external factors such\nas adverse weather and limited transit availability. Our findings contribute to\nimproving decision-making in shared mobility operations.", "comment": "6 pages, 8 figures. Paper accepted to J3C 2025 (Joint Conference on\n  Computers, Cognition and Communication", "pdf_url": "http://arxiv.org/pdf/2507.15643v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15520", "title": "SAIGFormer: A Spatially-Adaptive Illumination-Guided Network for Low-Light Image Enhancement", "authors": ["Hanting Li", "Fei Zhou", "Xin Sun", "Yang Hua", "Jungong Han", "Liang-Jie Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11 pages, 10 figures, 6 tables", "url": "http://arxiv.org/abs/2507.15520v1", "summary": "Recent Transformer-based low-light enhancement methods have made promising\nprogress in recovering global illumination. However, they still struggle with\nnon-uniform lighting scenarios, such as backlit and shadow, appearing as\nover-exposure or inadequate brightness restoration. To address this challenge,\nwe present a Spatially-Adaptive Illumination-Guided Transformer (SAIGFormer)\nframework that enables accurate illumination restoration. Specifically, we\npropose a dynamic integral image representation to model the spatially-varying\nillumination, and further construct a novel Spatially-Adaptive Integral\nIllumination Estimator ($\\text{SAI}^2\\text{E}$). Moreover, we introduce an\nIllumination-Guided Multi-head Self-Attention (IG-MSA) mechanism, which\nleverages the illumination to calibrate the lightness-relevant features toward\nvisual-pleased illumination enhancement. Extensive experiments on five standard\nlow-light datasets and a cross-domain benchmark (LOL-Blur) demonstrate that our\nSAIGFormer significantly outperforms state-of-the-art methods in both\nquantitative and qualitative metrics. In particular, our method achieves\nsuperior performance in non-uniform illumination enhancement while exhibiting\nstrong generalization capabilities across multiple datasets. Code is available\nat https://github.com/LHTcode/SAIGFormer.git.", "comment": "11 pages, 10 figures, 6 tables", "pdf_url": "http://arxiv.org/pdf/2507.15520v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2505.20560", "title": "A minimax method for the spectral fractional Laplacian and related evolution problems", "authors": ["José A. Carrillo", "Stefano Fronzoni", "Yuji Nakatsukasa", "Endre Süli"], "categories": ["math.NA", "cs.NA", "math.AP", "65N30, 65F60, 35K55, 35R11"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.20560v2", "summary": "We present a numerical method for the approximation of the inverse of the\nfractional Laplacian $(-\\Delta)^{s}$, based on its spectral definition, using\nrational functions to approximate the fractional power $A^{-s}$ of a matrix\n$A$, for $0<s<1$. The proposed numerical method is fast and accurate,\nbenefiting from the fact that the matrix $A$ arises from a finite element\napproximation of the Laplacian $-\\Delta$, which makes it applicable to a wide\nrange of domains with potentially irregular shapes. We make use of\nstate-of-the-art software to compute the best rational approximation of a\nfractional power. We analyze the convergence rate of our method and validate\nour findings through a series of numerical experiments with a range of\nexponents $s \\in (0,1)$. Additionally, we apply the proposed numerical method\nto different evolution problems that involve the fractional Laplacian through\nan interaction potential: the fractional porous medium equation and the\nfractional Keller-Segel equation. We then investigate the accuracy of the\nresulting numerical method, focusing in particular on the accurate reproduction\nof qualitative properties of the associated analytical solutions to these\npartial differential equations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.20560v2", "cate": "math.NA", "date": "2025-05-26", "updated": "2025-07-18"}
{"id": "2504.04287", "title": "A Cyber Insurance Policy for Hedging Against Load-Altering Attacks and Extreme Load Variations in Distribution Grids", "authors": ["Shijie Pan", "Zaint A. Alexakis", "S Subhash Lakshminarayana", "Charalambos Konstantinou"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.04287v3", "summary": "Uncertainties in renewable energy resources (RES) and load variations can\nlead to elevated system operational costs. Moreover, the emergence of\nlarge-scale distributed threats, such as load-altering attacks (LAAs), can\ninduce substantial load variations, further exacerbating these costs. Although\ntraditional defense measures can reduce the likelihood of such attacks,\nconsiderable residual risks remain. Thus, this paper proposes a cyber insurance\nframework designed to hedge against additional operational costs resulting from\nLAAs and substantial load variations in renewable-rich grids. The insurance\nframework determines both the insurance coverage and premium based on the Value\nat Risk (VaR) and Tail Value at Risk (TVaR). These risk metrics are calculated\nusing the system failure probability and the probability density function (PDF)\nof the system operation cost. The system failure probability is assessed\nthrough a semi-Markov process (SMP), while the cost distribution is estimated\nthrough a cost minimization model of a distribution grid combined with a\nMonte-Carlo simulation to capture load variability. Furthermore, we employ a\nbi-level optimization scheme that identifies the specific load distribution\nleading to the maximum system cost, thereby enhancing the accuracy of the\noperation cost PDF estimation. The effectiveness and scalability of the\nproposed cyber insurance policy are evaluated considering a modified IEEE-118\ntest bus system and the IEEE European low-voltage (LV) test feeders model. The\ncase study shows that with a relatively low premium, the network operator can\nhedge against additional operational costs caused by malicious load\nmanipulations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.04287v3", "cate": "eess.SY", "date": "2025-04-05", "updated": "2025-07-21"}
{"id": "2506.13567", "title": "Hybrid Polynomial Zonotopes: A Set Representation for Reachability Analysis in Hybrid Nonaffine Systems", "authors": ["Peng Xie", "Zhen Zhang", "Amr Alanwar"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      9 pages", "url": "http://arxiv.org/abs/2506.13567v2", "summary": "Reachability analysis for hybrid nonaffine systems remains computationally\nchallenging, as existing set representations--including constrained,\npolynomial, and hybrid zonotopes--either lose tightness under high-order\nnonaffine maps or suffer exponential blow-up after discrete jumps. This paper\nintroduces Hybrid Polynomial Zonotope (HPZ), a novel set representation that\ncombines the mode-dependent generator structure of hybrid zonotopes with the\nalgebraic expressiveness of polynomial zonotopes. HPZs compactly encode\nnon-convex reachable states across modes by attaching polynomial exponents to\neach hybrid generator, enabling precise capture of high-order state-input\ncouplings without vertex enumeration. We develop a comprehensive library of HPZ\noperations, including Minkowski sum, linear transformation, and intersection.\nTheoretical analysis and computational experiments demonstrate that HPZs\nachieve superior tightness preservation and computational efficiency compared\nto existing approaches for hybrid system reachability analysis.", "comment": "9 pages", "pdf_url": "http://arxiv.org/pdf/2506.13567v2", "cate": "eess.SY", "date": "2025-06-16", "updated": "2025-07-19"}
{"id": "2408.09754", "title": "Efficient onboard multi-task AI architecture based on self-supervised learning", "authors": ["Gabriele Inzerillo", "Diego Valsesia", "Enrico Magli"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.09754v2", "summary": "There is growing interest towards the use of AI directly onboard satellites\nfor quick analysis and rapid response to critical events such as natural\ndisasters. This paper presents a blueprint to the mission designer for the\ndevelopment of a modular and efficient deep learning payload to address\nmultiple onboard inference tasks. In particular, we design a self-supervised\nlightweight backbone that provides features to efficient task-specific heads.\nThe latter can be developed independently and with reduced data labeling\nrequirements thanks to the frozen backbone. Experiments on three sample tasks\nof cloud segmentation, flood detection, and marine debris classification on a\n7W embedded system show competitive results with inference quality close to\nhigh-complexity state-of-the-art models and high throughput in excess of 8\nMpx/s.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.09754v2", "cate": "eess.IV", "date": "2024-08-19", "updated": "2025-07-21"}
{"id": "2507.15641", "title": "Leveraging Context for Multimodal Fallacy Classification in Political Debates", "authors": ["Alessio Pittiglio"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12th Workshop on Argument Mining (ArgMining 2025) @ ACL 2025", "url": "http://arxiv.org/abs/2507.15641v1", "summary": "In this paper, we present our submission to the MM-ArgFallacy2025 shared\ntask, which aims to advance research in multimodal argument mining, focusing on\nlogical fallacies in political debates. Our approach uses pretrained\nTransformer-based models and proposes several ways to leverage context. In the\nfallacy classification subtask, our models achieved macro F1-scores of 0.4444\n(text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showed\nperformance comparable to the text-only model, suggesting potential for\nimprovements.", "comment": "12th Workshop on Argument Mining (ArgMining 2025) @ ACL 2025", "pdf_url": "http://arxiv.org/pdf/2507.15641v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15678", "title": "GeoHNNs: Geometric Hamiltonian Neural Networks", "authors": ["Amine Mohamed Aboussalah", "Abdessalam Ed-dib"], "categories": ["cs.LG", "math.DG", "math.DS", "math.SG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15678v1", "summary": "The fundamental laws of physics are intrinsically geometric, dictating the\nevolution of systems through principles of symmetry and conservation. While\nmodern machine learning offers powerful tools for modeling complex dynamics\nfrom data, common methods often ignore this underlying geometric fabric.\nPhysics-informed neural networks, for instance, can violate fundamental\nphysical principles, leading to predictions that are unstable over long\nperiods, particularly for high-dimensional and chaotic systems. Here, we\nintroduce \\textit{Geometric Hamiltonian Neural Networks (GeoHNN)}, a framework\nthat learns dynamics by explicitly encoding the geometric priors inherent to\nphysical laws. Our approach enforces two fundamental structures: the Riemannian\ngeometry of inertia, by parameterizing inertia matrices in their natural\nmathematical space of symmetric positive-definite matrices, and the symplectic\ngeometry of phase space, using a constrained autoencoder to ensure the\npreservation of phase space volume in a reduced latent space. We demonstrate\nthrough experiments on systems ranging from coupled oscillators to\nhigh-dimensional deformable objects that GeoHNN significantly outperforms\nexisting models. It achieves superior long-term stability, accuracy, and energy\nconservation, confirming that embedding the geometry of physics is not just a\ntheoretical appeal but a practical necessity for creating robust and\ngeneralizable models of the physical world.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15678v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15540", "title": "Procedure Learning via Regularized Gromov-Wasserstein Optimal Transport", "authors": ["Syed Ahmed Mahmood", "Ali Shah Ali", "Umer Ahmed", "Fawad Javed Fateh", "M. Zeeshan Zia", "Quoc-Huy Tran"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15540v1", "summary": "We study the problem of self-supervised procedure learning, which discovers\nkey steps and establishes their order from a set of unlabeled procedural\nvideos. Previous procedure learning methods typically learn frame-to-frame\ncorrespondences between videos before determining key steps and their order.\nHowever, their performance often suffers from order variations,\nbackground/redundant frames, and repeated actions. To overcome these\nchallenges, we propose a self-supervised procedure learning framework, which\nutilizes a fused Gromov-Wasserstein optimal transport formulation with a\nstructural prior for computing frame-to-frame mapping between videos. However,\noptimizing exclusively for the above temporal alignment term may lead to\ndegenerate solutions, where all frames are mapped to a small cluster in the\nembedding space and hence every video is associated with only one key step. To\naddress that limitation, we further integrate a contrastive regularization\nterm, which maps different frames to different points in the embedding space,\navoiding the collapse to trivial solutions. Finally, we conduct extensive\nexperiments on large-scale egocentric (i.e., EgoProceL) and third-person (i.e.,\nProceL and CrossTask) benchmarks to demonstrate superior performance by our\napproach against previous methods, including OPEL which relies on a traditional\nKantorovich optimal transport formulation with an optimality prior.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15540v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.06114", "title": "Learning-Enhanced Variational Regularization for Electrical Impedance Tomography via Calderón's Method", "authors": ["Kai Li", "Kwancheol Shin", "Zhi Zhou"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06114v2", "summary": "This paper aims to numerically solve the two-dimensional electrical impedance\ntomography (EIT) with Cauchy data. This inverse problem is highly challenging\ndue to its severe ill-posed nature and strong nonlinearity, which necessitates\nappropriate regularization strategies. Choosing a regularization approach that\neffectively incorporates the \\textit{a priori} information of the conductivity\ndistribution (or its contrast) is therefore essential. In this work, we propose\na deep learning-based method to capture the \\textit{a priori} information about\nthe shape and location of the unknown contrast using Calder\\'on's method. The\nlearned \\textit{a priori} information is then used to construct the\nregularization functional of the variational regularization method for solving\nthe inverse problem. The resulting regularized variational problem for EIT\nreconstruction is then solved using the Gauss-Newton method. Extensive\nnumerical experiments demonstrate that the proposed inversion algorithm\nachieves accurate reconstruction results, even in high-contrast cases, and\nexhibits strong generalization capabilities. Additionally, some stability and\nconvergence analysis of the variational regularization method underscores the\nimportance of incorporating \\textit{a priori} information about the support of\nthe unknown contrast.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06114v2", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-21"}
{"id": "2507.10010", "title": "Probabilistic Robustness in the Gap Metric", "authors": ["Venkatraman Renganathan"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Article with 13 pages submitted to the IEEE Transactions on Automatic Control", "url": "http://arxiv.org/abs/2507.10010v2", "summary": "Uncertainties influencing the dynamical systems pose a significant challenge\nin estimating the achievable performance of a controller aiming to control such\nuncertain systems. When the uncertainties are of stochastic nature, obtaining\nhard guarantees for the robustness of a controller aiming to hedge against the\nuncertainty is not possible. This issue set the platform for the development of\nprobabilistic robust control approaches. In this work, we utilise the gap\nmetric between the known nominal model and the unknown perturbed model of the\nuncertain system as a tool to gauge the robustness of a controller and\nformulate the gap as a random variable in the setting with stochastic\nuncertainties. The main results of this paper include giving a probabilistic\nbound on the gap exceeding a known threshold, followed by bounds on the\nexpected gap value and probabilistic robust stability and performance\nguarantees in terms of the gap metric. We also provide a probabilistic\ncontroller performance certification under gap uncertainty and probabilistic\nguarantee on the achievable $\\mathcal{H}_{\\infty}$ robustness. Numerical\nsimulations are provided to demonstrate the proposed approach.", "comment": "Article with 13 pages submitted to the IEEE Transactions on Automatic\n  Control", "pdf_url": "http://arxiv.org/pdf/2507.10010v2", "cate": "eess.SY", "date": "2025-07-14", "updated": "2025-07-20"}
{"id": "2410.20913", "title": "Constrained Optimal Fuel Consumption of HEVs under Observational Noise", "authors": ["Shuchang Yan", "Haoran Sun"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.20913v2", "summary": "In our prior work, we investigated the minimum fuel consumption of a hybrid\nelectric vehicle (HEV) under a state-of-charge (SOC) balance constraint,\nassuming perfect SOC measurements and accurate reference speed profiles. The\nconstrained optimal fuel consumption (COFC) problem was addressed using a\nconstrained reinforcement learning (CRL) framework. However, in real-world\nscenarios, SOC readings are often corrupted by sensor noise, and reference\nspeeds may deviate from actual driving conditions. To account for these\nimperfections, this study reformulates the COFC problem by explicitly\nincorporating observational noise in both SOC and reference speed. We adopt a\nrobust CRL approach, where the noise is modeled as a uniform distribution, and\nemploy a structured training procedure to ensure stability. The proposed method\nis evaluated through simulations on the Toyota Prius hybrid system (THS), using\nboth the New European Driving Cycle (NEDC) and the Worldwide Harmonized Light\nVehicles Test Cycle (WLTC). Results show that fuel consumption and SOC\nconstraint satisfaction remain robust across varying noise levels. Furthermore,\nthe analysis reveals that observational noise in SOC and speed can impact fuel\nconsumption to different extents. To the best of our knowledge, this is the\nfirst study to explicitly examine how observational noise -- commonly\nencountered in dynamometer testing and predictive energy control (PEC)\napplications -- affects constrained optimal fuel consumption in HEVs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.20913v2", "cate": "cs.LG", "date": "2024-10-28", "updated": "2025-07-21"}
{"id": "2409.03087", "title": "Coupling AI and Citizen Science in Creation of Enhanced Training Dataset for Medical Image Segmentation", "authors": ["Amir Syahmi", "Xiangrong Lu", "Yinxuan Li", "Haoxuan Yao", "Hanjun Jiang", "Ishita Acharya", "Shiyi Wang", "Yang Nan", "Xiaodan Xing", "Guang Yang"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.03087v2", "summary": "Recent advancements in medical imaging and artificial intelligence (AI) have\ngreatly enhanced diagnostic capabilities, but the development of effective deep\nlearning (DL) models is still constrained by the lack of high-quality annotated\ndatasets. The traditional manual annotation process by medical experts is time-\nand resource-intensive, limiting the scalability of these datasets. In this\nwork, we introduce a robust and versatile framework that combines AI and\ncrowdsourcing to improve both the quality and quantity of medical image\ndatasets across different modalities. Our approach utilises a user-friendly\nonline platform that enables a diverse group of crowd annotators to label\nmedical images efficiently. By integrating the MedSAM segmentation AI with this\nplatform, we accelerate the annotation process while maintaining expert-level\nquality through an algorithm that merges crowd-labelled images. Additionally,\nwe employ pix2pixGAN, a generative AI model, to expand the training dataset\nwith synthetic images that capture realistic morphological features. These\nmethods are combined into a cohesive framework designed to produce an enhanced\ndataset, which can serve as a universal pre-processing pipeline to boost the\ntraining of any medical deep learning segmentation model. Our results\ndemonstrate that this framework significantly improves model performance,\nespecially when training data is limited.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.03087v2", "cate": "eess.IV", "date": "2024-09-04", "updated": "2025-07-20"}
{"id": "2507.15681", "title": "Missing value imputation with adversarial random forests -- MissARF", "authors": ["Pegah Golchian", "Jan Kapar", "David S. Watson", "Marvin N. Wright"], "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15681v1", "summary": "Handling missing values is a common challenge in biostatistical analyses,\ntypically addressed by imputation methods. We propose a novel, fast, and\neasy-to-use imputation method called missing value imputation with adversarial\nrandom forests (MissARF), based on generative machine learning, that provides\nboth single and multiple imputation. MissARF employs adversarial random forest\n(ARF) for density estimation and data synthesis. To impute a missing value of\nan observation, we condition on the non-missing values and sample from the\nestimated conditional distribution generated by ARF. Our experiments\ndemonstrate that MissARF performs comparably to state-of-the-art single and\nmultiple imputation methods in terms of imputation quality and fast runtime\nwith no additional costs for multiple imputation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15681v1", "cate": "stat.ML", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15718", "title": "Explainable Anomaly Detection for Electric Vehicles Charging Stations", "authors": ["Matteo Cederle", "Andrea Mazzucco", "Andrea Demartini", "Eugenio Mazza", "Eugenia Suriani", "Federico Vitti", "Gian Antonio Susto"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      4 pages, 3 figures. Paper accepted to J3C 2025 (Joint Conference on Computers, Cognition and Communication)", "url": "http://arxiv.org/abs/2507.15718v1", "summary": "Electric vehicles (EV) charging stations are one of the critical\ninfrastructures needed to support the transition to renewable-energy-based\nmobility, but ensuring their reliability and efficiency requires effective\nanomaly detection to identify irregularities in charging behavior. However, in\nsuch a productive scenario, it is also crucial to determine the underlying\ncause behind the detected anomalies. To achieve this goal, this study\ninvestigates unsupervised anomaly detection techniques for EV charging\ninfrastructure, integrating eXplainable Artificial Intelligence techniques to\nenhance interpretability and uncover root causes of anomalies.\n  Using real-world sensors and charging session data, this work applies\nIsolation Forest to detect anomalies and employs the Depth-based Isolation\nForest Feature Importance (DIFFI) method to identify the most important\nfeatures contributing to such anomalies. The efficacy of the proposed approach\nis evaluated in a real industrial case.", "comment": "4 pages, 3 figures. Paper accepted to J3C 2025 (Joint Conference on\n  Computers, Cognition and Communication)", "pdf_url": "http://arxiv.org/pdf/2507.15718v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15541", "title": "Towards Holistic Surgical Scene Graph", "authors": ["Jongmin Shin", "Enki Cho", "Ka Yong Kim", "Jung Yong Kim", "Seong Tae Kim", "Namkee Oh"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to MICCAI 2025", "url": "http://arxiv.org/abs/2507.15541v1", "summary": "Surgical scene understanding is crucial for computer-assisted intervention\nsystems, requiring visual comprehension of surgical scenes that involves\ndiverse elements such as surgical tools, anatomical structures, and their\ninteractions. To effectively represent the complex information in surgical\nscenes, graph-based approaches have been explored to structurally model\nsurgical entities and their relationships. Previous surgical scene graph\nstudies have demonstrated the feasibility of representing surgical scenes using\ngraphs. However, certain aspects of surgical scenes-such as diverse\ncombinations of tool-action-target and the identity of the hand operating the\ntool-remain underexplored in graph-based representations, despite their\nimportance. To incorporate these aspects into graph representations, we propose\nEndoscapes-SG201 dataset, which includes annotations for tool-action-target\ncombinations and hand identity. We also introduce SSG-Com, a graph-based method\ndesigned to learn and represent these critical elements. Through experiments on\ndownstream tasks such as critical view of safety assessment and action triplet\nrecognition, we demonstrated the importance of integrating these essential\nscene graph components, highlighting their significant contribution to surgical\nscene understanding. The code and dataset are available at\nhttps://github.com/ailab-kyunghee/SSG-Com", "comment": "Accepted to MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.15541v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.12406", "title": "Refinement of the theory and convergence of the Sinc convolution", "authors": ["Tomoaki Okayama"], "categories": ["math.NA", "cs.NA", "65D15, 65D30"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12406v2", "summary": "The Sinc convolution is an approximate formula for indefinite convolutions\nproposed by Stenger. The formula was derived based on the Sinc indefinite\nintegration formula combined with the single-exponential transformation.\nAlthough its efficiency has been confirmed in various fields, several\ntheoretical issues remain unresolved. The first contribution of this study is\nto resolve those issues by refining the underlying theory of the Sinc\nconvolution. This contribution includes an essential resolution of Stenger's\nconjecture. The second contribution of this study is to improve the convergence\nrate by replacing the single-exponential transformation with the\ndouble-exponential transformation. Theoretical analysis and numerical\nexperiments confirm that the modified formula achieves superior convergence\ncompared to Stenger's original formula.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12406v2", "cate": "math.NA", "date": "2025-07-16", "updated": "2025-07-21"}
{"id": "2501.00172", "title": "Algebraic Control: Complete Stable Inversion with Necessary and Sufficient Conditions", "authors": ["Burak Kürkçü", "Masayoshi Tomizuka"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.00172v3", "summary": "In this paper, we establish necessary and sufficient conditions for stable\ninversion, addressing challenges in non-minimum phase, non-square, and singular\nsystems. An H-Infinity based algebraic approximation is introduced for\nnear-perfect tracking without preview. Additionally, we propose a novel robust\ncontrol strategy combining the nominal model with dual feedforward control to\nform a feedback structure. Numerical comparison demonstrates the approach's\neffectiveness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.00172v3", "cate": "math.OC", "date": "2024-12-30", "updated": "2025-07-19"}
{"id": "2502.11484", "title": "Dictionary-Learning-Based Data Pruning for System Identification", "authors": ["Tingna Wang", "Sikai Zhang", "Mingming Song", "Limin Sun"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.11484v2", "summary": "System identification is normally involved in augmenting time series data by\ntime shifting and nonlinearisation (e.g., polynomial basis), both of which\nintroduce redundancy in features and samples. Many research works focus on\nreducing redundancy feature-wise, while less attention is paid to sample-wise\nredundancy. This paper proposes a novel data pruning method, called mini-batch\nFastCan, to reduce sample-wise redundancy based on dictionary learning. Time\nseries data is represented by some representative samples, called atoms, via\ndictionary learning. The useful samples are selected based on their correlation\nwith the atoms. The method is tested on one simulated dataset and two benchmark\ndatasets. The R-squared between the coefficients of models trained on the full\ndatasets and the coefficients of models trained on pruned datasets is adopted\nto evaluate the performance of data pruning methods. It is found that the\nproposed method significantly outperforms the random pruning method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.11484v2", "cate": "cs.LG", "date": "2025-02-17", "updated": "2025-07-21"}
{"id": "2410.18239", "title": "DualSwinUnet++: An Enhanced Swin-Unet Architecture With Dual Decoders For PTMC Segmentation", "authors": ["Maryam Dialameh", "Hossein Rajabzadeh", "Moslem Sadeghi-Goughari", "Jung Suk Sim", "Hyock Ju Kwon"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.18239v3", "summary": "Precise segmentation of papillary thyroid microcarcinoma (PTMC) during\nultrasound-guided radiofrequency ablation (RFA) is critical for effective\ntreatment but remains challenging due to acoustic artifacts, small lesion size,\nand anatomical variability. In this study, we propose DualSwinUnet++, a\ndual-decoder transformer-based architecture designed to enhance PTMC\nsegmentation by incorporating thyroid gland context. DualSwinUnet++ employs\nindependent linear projection heads for each decoder and a residual information\nflow mechanism that passes intermediate features from the first (thyroid)\ndecoder to the second (PTMC) decoder via concatenation and transformation.\nThese design choices allow the model to condition tumor prediction explicitly\non gland morphology without shared gradient interference. Trained on a clinical\nultrasound dataset with 691 annotated RFA images and evaluated against\nstate-of-the-art models, DualSwinUnet++ achieves superior Dice and Jaccard\nscores while maintaining sub-200ms inference latency. The results demonstrate\nthe model's suitability for near real-time surgical assistance and its\neffectiveness in improving segmentation accuracy in challenging PTMC cases.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.18239v3", "cate": "eess.IV", "date": "2024-10-23", "updated": "2025-07-20"}
{"id": "2507.15686", "title": "LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression", "authors": ["Wenjie Huang", "Qi Yang", "Shuting Xia", "He Huang", "Zhu Li", "Yiling Xu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.15686v1", "summary": "Existing AI-based point cloud compression methods struggle with dependence on\nspecific training data distributions, which limits their real-world deployment.\nImplicit Neural Representation (INR) methods solve the above problem by\nencoding overfitted network parameters to the bitstream, resulting in more\ndistribution-agnostic results. However, due to the limitation of encoding time\nand decoder size, current INR based methods only consider lossy geometry\ncompression. In this paper, we propose the first INR based lossless point cloud\ngeometry compression method called Lossless Implicit Neural Representations for\nPoint Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we\ndesign a group of point clouds level coding framework with an effective network\ninitialization strategy, which can reduce around 60% encoding time. A\nlightweight coding network based on multiscale SparseConv, consisting of scale\ncontext extraction, child node prediction, and model compression modules, is\nproposed to realize fast inference and compact decoder size. Experimental\nresults show that our method consistently outperforms traditional and AI-based\nmethods: for example, with the convergence time in the MVUB dataset, our method\nreduces the bitstream by approximately 21.21% compared to G-PCC TMC13v23 and\n21.95% compared to SparsePCGC. Our project can be seen on\nhttps://huangwenjie2023.github.io/LINR-PCGC/.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.15686v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15769", "title": "Multi-Modal Sensor Fusion for Proactive Blockage Prediction in mmWave Vehicular Networks", "authors": ["Ahmad M. Nazar", "Abdulkadir Celik", "Mohamed Y. Selim", "Asmaa Abdallah", "Daji Qiao", "Ahmed M. Eltawil"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted in IEEE Asilomar Conference on Signals, Systems, and Computers 2025", "url": "http://arxiv.org/abs/2507.15769v1", "summary": "Vehicular communication systems operating in the millimeter wave (mmWave)\nband are highly susceptible to signal blockage from dynamic obstacles such as\nvehicles, pedestrians, and infrastructure. To address this challenge, we\npropose a proactive blockage prediction framework that utilizes multi-modal\nsensing, including camera, GPS, LiDAR, and radar inputs in an\ninfrastructure-to-vehicle (I2V) setting. This approach uses modality-specific\ndeep learning models to process each sensor stream independently and fuses\ntheir outputs using a softmax-weighted ensemble strategy based on validation\nperformance. Our evaluations, for up to 1.5s in advance, show that the\ncamera-only model achieves the best standalone trade-off with an F1-score of\n97.1% and an inference time of 89.8ms. A camera+radar configuration further\nimproves accuracy to 97.2% F1 at 95.7ms. Our results display the effectiveness\nand efficiency of multi-modal sensing for mmWave blockage prediction and\nprovide a pathway for proactive wireless communication in dynamic environments.", "comment": "Accepted in IEEE Asilomar Conference on Signals, Systems, and\n  Computers 2025", "pdf_url": "http://arxiv.org/pdf/2507.15769v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15542", "title": "HOLa: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation", "authors": ["Qinqian Lei", "Bo Wang", "Robby T. Tan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.15542v1", "summary": "Zero-shot human-object interaction (HOI) detection remains a challenging\ntask, particularly in generalizing to unseen actions. Existing methods address\nthis challenge by tapping Vision-Language Models (VLMs) to access knowledge\nbeyond the training data. However, they either struggle to distinguish actions\ninvolving the same object or demonstrate limited generalization to unseen\nclasses. In this paper, we introduce HOLa (Zero-Shot HOI Detection with\nLow-Rank Decomposed VLM Feature Adaptation), a novel approach that both\nenhances generalization to unseen classes and improves action distinction. In\ntraining, HOLa decomposes VLM text features for given HOI classes via low-rank\nfactorization, producing class-shared basis features and adaptable weights.\nThese features and weights form a compact HOI representation that preserves\nshared information across classes, enhancing generalization to unseen classes.\nSubsequently, we refine action distinction by adapting weights for each HOI\nclass and introducing human-object tokens to enrich visual interaction\nrepresentations. To further distinguish unseen actions, we guide the weight\nadaptation with LLM-derived action regularization. Experimental results show\nthat our method sets a new state-of-the-art across zero-shot HOI settings on\nHICO-DET, achieving an unseen-class mAP of 27.91 in the unseen-verb setting.\nOur code is available at https://github.com/ChelsieLei/HOLa.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.15542v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.12629", "title": "A Unified Framework for Efficient Kernel and Polynomial Interpolation", "authors": ["M. Belianovich", "G. E. Fasshauer", "A. Narayan", "V. Shankar"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      Submitted for review to Journal of Approximation Software (JAS)", "url": "http://arxiv.org/abs/2507.12629v2", "summary": "We present a unified interpolation scheme that combines compactly-supported\npositive-definite kernels and multivariate polynomials. This unified framework\ngeneralizes interpolation with compactly-supported kernels and also classical\npolynomial least squares approximation. To facilitate the efficient use of this\nunified interpolation scheme, we present specialized numerical linear algebra\nprocedures that leverage standard matrix factorizations. These procedures allow\nfor efficient computation and storage of the unified interpolant. We also\npresent a modification to the numerical linear algebra that allows us to\ngeneralize the application of the unified framework to target functions on\nmanifolds with and without boundary. Our numerical experiments on both\nEuclidean domains and manifolds indicate that the unified interpolant is\nsuperior to polynomial least squares for the interpolation of target functions\nin settings with boundaries.", "comment": "Submitted for review to Journal of Approximation Software (JAS)", "pdf_url": "http://arxiv.org/pdf/2507.12629v2", "cate": "math.NA", "date": "2025-07-16", "updated": "2025-07-19"}
{"id": "2503.14549", "title": "Sampling Decisions", "authors": ["Michael Chertkov", "Sungsoo Ahn", "Hamidreza Behjoo"], "categories": ["cs.LG", "cond-mat.stat-mech", "cs.AI", "cs.SY", "eess.SY", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 3 figures", "url": "http://arxiv.org/abs/2503.14549v2", "summary": "In this manuscript, we introduce a novel Decision Flow (DF) framework for\nsampling decisions from a target distribution while incorporating additional\nguidance from a prior sampler. DF can be viewed as an AI-driven algorithmic\nreincarnation of the Markov Decision Process (MDP) approach in stochastic\noptimal control. It extends the continuous-space, continuous-time Path Integral\nDiffusion sampling technique of [Behjoo, Chertkov 2025] to discrete time and\nspace, while also generalizing the Generative Flow Network (GFN) framework of\n[Bengio, et al 2021]. In its most basic form an explicit formulation that does\nnot require Neural Networks (NNs), DF leverages the linear solvability of the\nunderlying MDP [Todorov, 2007] to adjust the transition probabilities of the\nprior sampler. The resulting Markov process is expressed as a convolution of\nthe reverse-time Green's function of the prior sampling with the target\ndistribution. We illustrate the DF framework through an example of sampling\nfrom the Ising model -- compare DF to Metropolis-Hastings to quantify its\nefficiency, discuss potential NN-based extensions, and outline how DF can\nenhance guided sampling across various applications.", "comment": "10 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2503.14549v2", "cate": "cs.LG", "date": "2025-03-17", "updated": "2025-07-20"}
{"id": "2504.00813", "title": "Feedback Optimization with State Constraints through Control Barrier Functions", "authors": ["Giannis Delimpaltadakis", "Pol Mestres", "Jorge Cortés", "W. P. M. H. Heemels"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      accepted at the 64th IEEE Conference on Decision and Control (CDC), 2025", "url": "http://arxiv.org/abs/2504.00813v2", "summary": "Recently, there has been a surge of research on a class of methods called\nfeedback optimization. These are methods to steer the state of a control system\nto an equilibrium that arises as the solution of an optimization problem.\nDespite the growing literature on the topic, the important problem of enforcing\nstate constraints at all times remains unaddressed. In this work, we present\nthe first feedback-optimization method that enforces state constraints. The\nmethod combines a class of dynamics called safe gradient flows with high-order\ncontrol barrier functions. We provide a number of results on our proposed\ncontroller, including well-posedness guarantees, anytime\nconstraint-satisfaction guarantees, equivalence between the closed-loop's\nequilibria and the optimization problem's critical points, and local asymptotic\nstability of optima.", "comment": "accepted at the 64th IEEE Conference on Decision and Control (CDC),\n  2025", "pdf_url": "http://arxiv.org/pdf/2504.00813v2", "cate": "math.OC", "date": "2025-04-01", "updated": "2025-07-21"}
{"id": "2411.17845", "title": "CABLD: Contrast-Agnostic Brain Landmark Detection with Consistency-Based Regularization", "authors": ["Soorena Salari", "Arash Harirpoush", "Hassan Rivaz", "Yiming Xiao"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2411.17845v3", "summary": "Anatomical landmark detection in medical images is essential for various\nclinical and research applications, including disease diagnosis and surgical\nplanning. However, manual landmark annotation is time-consuming and requires\nsignificant expertise. Existing deep learning (DL) methods often require large\namounts of well-annotated data, which are costly to acquire. In this paper, we\nintroduce CABLD, a novel self-supervised DL framework for 3D brain landmark\ndetection in unlabeled scans with varying contrasts by using only a single\nreference example. To achieve this, we employed an inter-subject landmark\nconsistency loss with an image registration loss while introducing a 3D\nconvolution-based contrast augmentation strategy to promote model\ngeneralization to new contrasts. Additionally, we utilize an adaptive mixed\nloss function to schedule the contributions of different sub-tasks for optimal\noutcomes. We demonstrate the proposed method with the intricate task of\nMRI-based 3D brain landmark detection. With comprehensive experiments on four\ndiverse clinical and public datasets, including both T1w and T2w MRI scans at\ndifferent MRI field strengths, we demonstrate that CABLD outperforms the\nstate-of-the-art methods in terms of mean radial errors (MREs) and success\ndetection rates (SDRs). Our framework provides a robust and accurate solution\nfor anatomical landmark detection, reducing the need for extensively annotated\ndatasets and generalizing well across different imaging contrasts. Our code is\npublicly available at https://github.com/HealthX-Lab/CABLD.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2411.17845v3", "cate": "eess.IV", "date": "2024-11-26", "updated": "2025-07-19"}
{"id": "2507.15698", "title": "CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models", "authors": ["Congmin Zheng", "Jiachen Zhu", "Jianghao Lin", "Xinyi Dai", "Yong Yu", "Weinan Zhang", "Mengyue Yang"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15698v1", "summary": "Process Reward Models (PRMs) play a central role in evaluating and guiding\nmulti-step reasoning in large language models (LLMs), especially for\nmathematical problem solving. However, we identify a pervasive length bias in\nexisting PRMs: they tend to assign higher scores to longer reasoning steps,\neven when the semantic content and logical validity are unchanged. This bias\nundermines the reliability of reward predictions and leads to overly verbose\noutputs during inference. To address this issue, we propose\nCoLD(Counterfactually-Guided Length Debiasing), a unified framework that\nmitigates length bias through three components: an explicit length-penalty\nadjustment, a learned bias estimator trained to capture spurious length-related\nsignals, and a joint training strategy that enforces length-invariance in\nreward predictions. Our approach is grounded in counterfactual reasoning and\ninformed by causal graph analysis. Extensive experiments on MATH500 and\nGSM-Plus show that CoLD consistently reduces reward-length correlation,\nimproves accuracy in step selection, and encourages more concise, logically\nvalid reasoning. These results demonstrate the effectiveness and practicality\nof CoLD in improving the fidelity and robustness of PRMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15698v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15772", "title": "Deep-Learning Investigation of Vibrational Raman Spectra for Plant-Stress Analysis", "authors": ["Anoop C. Patil", "Benny Jian Rong Sng", "Yu-Wei Chang", "Joana B. Pereira", "Chua Nam-Hai", "Rajani Sarojam", "Gajendra Pratap Singh", "In-Cheol Jang", "Giovanni Volpe"], "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      *Authors contributed equally to this work. +Supervised this work. 5 main figures and 1 extended data figure in manuscript. The PDF includes supplementary material", "url": "http://arxiv.org/abs/2507.15772v1", "summary": "Detecting stress in plants is crucial for both open-farm and\ncontrolled-environment agriculture. Biomolecules within plants serve as key\nstress indicators, offering vital markers for continuous health monitoring and\nearly disease detection. Raman spectroscopy provides a powerful, non-invasive\nmeans to quantify these biomolecules through their molecular vibrational\nsignatures. However, traditional Raman analysis relies on customized\ndata-processing workflows that require fluorescence background removal and\nprior identification of Raman peaks of interest-introducing potential biases\nand inconsistencies. Here, we introduce DIVA (Deep-learning-based Investigation\nof Vibrational Raman spectra for plant-stress Analysis), a fully automated\nworkflow based on a variational autoencoder. Unlike conventional approaches,\nDIVA processes native Raman spectra-including fluorescence backgrounds-without\nmanual preprocessing, identifying and quantifying significant spectral features\nin an unbiased manner. We applied DIVA to detect a range of plant stresses,\nincluding abiotic (shading, high light intensity, high temperature) and biotic\nstressors (bacterial infections). By integrating deep learning with vibrational\nspectroscopy, DIVA paves the way for AI-driven plant health assessment,\nfostering more resilient and sustainable agricultural practices.", "comment": "*Authors contributed equally to this work. +Supervised this work. 5\n  main figures and 1 extended data figure in manuscript. The PDF includes\n  supplementary material", "pdf_url": "http://arxiv.org/pdf/2507.15772v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15569", "title": "DynImg: Key Frames with Visual Prompts are Good Representation for Multi-Modal Video Understanding", "authors": ["Xiaoyi Bao", "Chenwei Xie", "Hao Tang", "Tingyu Weng", "Xiaofeng Wang", "Yun Zheng", "Xingang Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.15569v1", "summary": "In recent years, the introduction of Multi-modal Large Language Models\n(MLLMs) into video understanding tasks has become increasingly prevalent.\nHowever, how to effectively integrate temporal information remains a critical\nresearch focus. Traditional approaches treat spatial and temporal information\nseparately. Due to issues like motion blur, it is challenging to accurately\nrepresent the spatial information of rapidly moving objects. This can lead to\ntemporally important regions being underemphasized during spatial feature\nextraction, which in turn hinders accurate spatio-temporal interaction and\nvideo understanding. To address this limitation, we propose an innovative video\nrepresentation method called Dynamic-Image (DynImg). Specifically, we introduce\na set of non-key frames as temporal prompts to highlight the spatial areas\ncontaining fast-moving objects. During the process of visual feature\nextraction, these prompts guide the model to pay additional attention to the\nfine-grained spatial features corresponding to these regions. Moreover, to\nmaintain the correct sequence for DynImg, we employ a corresponding 4D video\nRotary Position Embedding. This retains both the temporal and spatial adjacency\nof DynImg, helping MLLM understand the spatio-temporal order within this\ncombined format. Experimental evaluations reveal that DynImg surpasses the\nstate-of-the-art methods by approximately 2% across multiple video\nunderstanding benchmarks, proving the effectiveness of our temporal prompts in\nenhancing video comprehension.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.15569v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2404.05064", "title": "A Structure-Guided Gauss-Newton Method for Shallow ReLU Neural Network", "authors": ["Zhiqiang Cai", "Tong Ding", "Min Liu", "Xinyu Liu", "Jianlin Xia"], "categories": ["cs.LG", "cs.NA", "math.NA", "65D15, 65K10"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.05064v2", "summary": "In this paper, we propose a structure-guided Gauss-Newton (SgGN) method for\nsolving least squares problems using a shallow ReLU neural network. The method\neffectively takes advantage of both the least squares structure and the neural\nnetwork structure of the objective function. By categorizing the weights and\nbiases of the hidden and output layers of the network as nonlinear and linear\nparameters, respectively, the method iterates back and forth between the\nnonlinear and linear parameters. The nonlinear parameters are updated by a\ndamped Gauss-Newton method and the linear ones are updated by a linear solver.\nMoreover, at the Gauss-Newton step, a special form of the Gauss-Newton matrix\nis derived for the shallow ReLU neural network and is used for efficient\niterations. It is shown that the corresponding mass and Gauss-Newton matrices\nin the respective linear and nonlinear steps are symmetric and positive\ndefinite under reasonable assumptions. Thus, the SgGN method naturally produces\nan effective search direction without the need of additional techniques like\nshifting in the Levenberg-Marquardt method to achieve invertibility of the\nGauss-Newton matrix. The convergence and accuracy of the method are\ndemonstrated numerically for several challenging function approximation\nproblems, especially those with discontinuities or sharp transition layers that\npose significant challenges for commonly used training algorithms in machine\nlearning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.05064v2", "cate": "cs.LG", "date": "2024-04-07", "updated": "2025-07-19"}
{"id": "2505.00847", "title": "Platoon Coordination and Leader Selection in Mixed Transportation Systems via Dynamic Programming", "authors": ["Ying Wang", "Ting Bai", "Andreas A. Malikopoulos"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.00847v2", "summary": "With the growing penetration of electric trucks, freight transportation is\ntransitioning toward a mixed system comprising both fuel-powered and electric\ntrucks. Enhancing truck platoon formation in such a heterogeneous environment\npresents new challenges. This paper investigates the hub-based platoon\ncoordination problem in a mixed truck fleet, where the focus is to optimize the\ntrucks' waiting times, charging amounts for electric trucks, and platoon leader\nassignments. The objective is to maximize the overall platoon revenue of the\nfleet while accounting for the associated waiting and charging costs. We\nformulate the problem as a mixed-integer linear program and present a dynamic\nprogramming approach to compute its sub-optimal solution efficiently. The\nproposed method operates in polynomial time, ensuring scalable computational\nefficiency. Simulation studies involving 1,000 trucks traveling between two\nhubs in Sweden demonstrate the effectiveness and scalability of the proposed\napproach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.00847v2", "cate": "math.OC", "date": "2025-05-01", "updated": "2025-07-20"}
{"id": "2501.03466", "title": "DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation", "authors": ["Bo Liu", "Yudong Zhang", "Shuihua Wang", "Siyue Li", "Jin Hong"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.03466v2", "summary": "Retinal vascular morphology is crucial for diagnosing diseases such as\ndiabetes, glaucoma, and hypertension, making accurate segmentation of retinal\nvessels essential for early intervention. Traditional segmentation methods\nassume that training and testing data share similar distributions, which can\nlead to poor performance on unseen domains due to domain shifts caused by\nvariations in imaging devices and patient demographics. This paper presents a\nnovel approach, DGSSA, for retinal vessel image segmentation that enhances\nmodel generalization by combining structural and style augmentation strategies.\nWe utilize a space colonization algorithm to generate diverse vascular-like\nstructures that closely mimic actual retinal vessels, which are then used to\ngenerate pseudo-retinal images with an improved Pix2Pix model, allowing the\nsegmentation model to learn a broader range of structure distributions.\nAdditionally, we utilize PixMix to implement random photometric augmentations\nand introduce uncertainty perturbations, thereby enriching stylistic diversity\nand significantly enhancing the model's adaptability to varying imaging\nconditions. Our framework has been rigorously evaluated on four challenging\ndatasets-DRIVE, CHASEDB, HRF, and STARE-demonstrating state-of-the-art\nperformance that surpasses existing methods. This validates the effectiveness\nof our proposed approach, highlighting its potential for clinical application\nin automated retinal vessel analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.03466v2", "cate": "eess.IV", "date": "2025-01-07", "updated": "2025-07-20"}
{"id": "2507.15706", "title": "Compositional Understanding in Signaling Games", "authors": ["David Peter Wallis Freeborn"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15706v1", "summary": "Receivers in standard signaling game models struggle with learning\ncompositional information. Even when the signalers send compositional messages,\nthe receivers do not interpret them compositionally. When information from one\nmessage component is lost or forgotten, the information from other components\nis also erased. In this paper I construct signaling game models in which\ngenuine compositional understanding evolves. I present two new models: a\nminimalist receiver who only learns from the atomic messages of a signal, and a\ngeneralist receiver who learns from all of the available information. These\nmodels are in many ways simpler than previous alternatives, and allow the\nreceivers to learn from the atomic components of messages.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15706v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15774", "title": "Dynamics is what you need for time-series forecasting!", "authors": ["Alexis-Raja Brachet", "Pierre-Yves Richard", "Céline Hudelot"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      13 pages, 6 figures, 1 table", "url": "http://arxiv.org/abs/2507.15774v1", "summary": "While boundaries between data modalities are vanishing, the usual successful\ndeep models are still challenged by simple ones in the time-series forecasting\ntask. Our hypothesis is that this task needs models that are able to learn the\ndata underlying dynamics. We propose to validate it through both systemic and\nempirical studies. We develop an original $\\texttt{PRO-DYN}$ nomenclature to\nanalyze existing models through the lens of dynamics. Two observations thus\nemerged: $\\textbf{1}$. under-performing architectures learn dynamics at most\npartially, $\\textbf{2}$. the location of the dynamics block at the model end is\nof prime importance. We conduct extensive experiments to confirm our\nobservations on a set of performance-varying models with diverse backbones.\nResults support the need to incorporate a learnable dynamics block and its use\nas the final predictor.", "comment": "13 pages, 6 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.15774v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15595", "title": "SegDT: A Diffusion Transformer-Based Segmentation Model for Medical Imaging", "authors": ["Salah Eddine Bekhouche", "Gaby Maroun", "Fadi Dornaika", "Abdenour Hadid"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15595v1", "summary": "Medical image segmentation is crucial for many healthcare tasks, including\ndisease diagnosis and treatment planning. One key area is the segmentation of\nskin lesions, which is vital for diagnosing skin cancer and monitoring\npatients. In this context, this paper introduces SegDT, a new segmentation\nmodel based on diffusion transformer (DiT). SegDT is designed to work on\nlow-cost hardware and incorporates Rectified Flow, which improves the\ngeneration quality at reduced inference steps and maintains the flexibility of\nstandard diffusion models. Our method is evaluated on three benchmarking\ndatasets and compared against several existing works, achieving\nstate-of-the-art results while maintaining fast inference speeds. This makes\nthe proposed model appealing for real-world medical applications. This work\nadvances the performance and capabilities of deep learning models in medical\nimage analysis, enabling faster, more accurate diagnostic tools for healthcare\nprofessionals. The code is made publicly available at\n\\href{https://github.com/Bekhouche/SegDT}{GitHub}.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15595v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2408.14816", "title": "Time splitting and error estimates for nonlinear Schrodinger equations with a potential", "authors": ["Rémi Carles"], "categories": ["math.AP", "cs.NA", "math-ph", "math.MP", "math.NA"], "primary_category": "Subjects:       Analysis of PDEs (math.AP)", "pdf_link": null, "comments": "Comments:      More comments and expanations in the introduction", "url": "http://arxiv.org/abs/2408.14816v3", "summary": "We consider the nonlinear Schr{\\\"o}dinger equation with a potential, also\nknown as Gross-Pitaevskii equation. By introducing a suitable spectral\nlocalization, we prove low regularity error estimates for the time\ndiscretization corresponding to an adapted Lie-Trotter splitting scheme. The\nproof is based on tools from spectral theory and pseudodifferential calculus in\norder to obtain various estimates on the spectral localization, including\ndiscrete Strichartz estimates which support the nonlinear analysis.", "comment": "More comments and expanations in the introduction", "pdf_url": "http://arxiv.org/pdf/2408.14816v3", "cate": "math.AP", "date": "2024-08-27", "updated": "2025-07-21"}
{"id": "2501.18109", "title": "Influence of High-Performance Image-to-Image Translation Networks on Clinical Visual Assessment and Outcome Prediction: Utilizing Ultrasound to MRI Translation in Prostate Cancer", "authors": ["Mohammad R. Salmanpour", "Amin Mousavi", "Yixi Xu", "William B Weeks", "Ilker Hacihaliloglu"], "categories": ["eess.IV", "cs.CV", "physics.bio-ph", "14J60 (Primary) 14F05, 14J26 (Secondary)", "F.2.2"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      9 pages, 4 figures and 1 table", "url": "http://arxiv.org/abs/2501.18109v2", "summary": "Purpose: This study examines the core traits of image-to-image translation\n(I2I) networks, focusing on their effectiveness and adaptability in everyday\nclinical settings. Methods: We have analyzed data from 794 patients diagnosed\nwith prostate cancer (PCa), using ten prominent 2D/3D I2I networks to convert\nultrasound (US) images into MRI scans. We also introduced a new analysis of\nRadiomic features (RF) via the Spearman correlation coefficient to explore\nwhether networks with high performance (SSIM>85%) could detect subtle RFs. Our\nstudy further examined synthetic images by 7 invited physicians. As a final\nevaluation study, we have investigated the improvement that are achieved using\nthe synthetic MRI data on two traditional machine learning and one deep\nlearning method. Results: In quantitative assessment, 2D-Pix2Pix network\nsubstantially outperformed the other 7 networks, with an average SSIM~0.855.\nThe RF analysis revealed that 76 out of 186 RFs were identified using the\n2D-Pix2Pix algorithm alone, although half of the RFs were lost during the\ntranslation process. A detailed qualitative review by 7 medical doctors noted a\ndeficiency in low-level feature recognition in I2I tasks. Furthermore, the\nstudy found that synthesized image-based classification outperformed US\nimage-based classification with an average accuracy and AUC~0.93. Conclusion:\nThis study showed that while 2D-Pix2Pix outperformed cutting-edge networks in\nlow-level feature discovery and overall error and similarity metrics, it still\nrequires improvement in low-level feature performance, as highlighted by Group\n3. Further, the study found using synthetic image-based classification\noutperformed original US image-based methods.", "comment": "9 pages, 4 figures and 1 table", "pdf_url": "http://arxiv.org/pdf/2501.18109v2", "cate": "eess.IV", "date": "2025-01-30", "updated": "2025-07-19"}
{"id": "2507.15707", "title": "Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?", "authors": ["Seok Hwan Song", "Mohna Chakraborty", "Qi Li", "Wallapak Tavanapong"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15707v1", "summary": "Large Language Models (LLMs) have been evaluated using diverse question\ntypes, e.g., multiple-choice, true/false, and short/long answers. This study\nanswers an unexplored question about the impact of different question types on\nLLM accuracy on reasoning tasks. We investigate the performance of five LLMs on\nthree different types of questions using quantitative and deductive reasoning\ntasks. The performance metrics include accuracy in the reasoning steps and\nchoosing the final answer. Key Findings: (1) Significant differences exist in\nLLM performance across different question types. (2) Reasoning accuracy does\nnot necessarily correlate with the final selection accuracy. (3) The number of\noptions and the choice of words, influence LLM performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15707v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15784", "title": "Graph Attention Specialized Expert Fusion Model for Node Classification: Based on Cora and Pubmed Datasets", "authors": ["Zihang Ma", "Qitian Yin"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15784v1", "summary": "Graph node classification is a fundamental task in graph neural networks\n(GNNs), aiming to assign predefined class labels to nodes. On the PubMed\ncitation network dataset, we observe significant classification difficulty\ndisparities, with Category 2 achieving only 74.4% accuracy in traditional GCN,\n7.5% lower than Category 1. To address this, we propose a\nWasserstein-Rubinstein (WR) distance enhanced Expert Fusion Model (WR-EFM),\ntraining specialized GNN models for Categories 0/1 (with layer normalization\nand residual connections) and Multi-hop Graph Attention Networks (GAT) for\nCategory 2. The WR distance metric optimizes representation similarity between\nmodels, particularly focusing on improving Category 2 performance. Our adaptive\nfusion strategy dynamically weights models based on category-specific\nperformance, with Category 2 assigned a GAT weight of 0.8. WR distance further\nguides the fusion process by measuring distributional differences between model\nrepresentations, enabling more principled integration of complementary\nfeatures.\n  Experimental results show WR-EFM achieves balanced accuracy across\ncategories: 77.8% (Category 0), 78.0% (Category 1), and 79.9% (Category 2),\noutperforming both single models and standard fusion approaches. The\ncoefficient of variation (CV) of WR-EFM's category accuracies is 0.013, 77.6%\nlower than GCN's 0.058, demonstrating superior stability. Notably, WR-EFM\nimproves Category 2 accuracy by 5.5% compared to GCN, verifying the\neffectiveness of WR-guided fusion in capturing complex structural patterns.\nThis work provides a novel paradigm for handling class-imbalanced graph\nclassification tasks. To promote the research community, we release our project\nat https://github.com/s010m00n/GASEM4NC.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15784v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15602", "title": "SurfaceSplat: Connecting Surface Reconstruction and Gaussian Splatting", "authors": ["Zihui Gao", "Jia-Wang Bian", "Guosheng Lin", "Hao Chen", "Chunhua Shen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15602v1", "summary": "Surface reconstruction and novel view rendering from sparse-view images are\nchallenging. Signed Distance Function (SDF)-based methods struggle with fine\ndetails, while 3D Gaussian Splatting (3DGS)-based approaches lack global\ngeometry coherence. We propose a novel hybrid method that combines the\nstrengths of both approaches: SDF captures coarse geometry to enhance\n3DGS-based rendering, while newly rendered images from 3DGS refine the details\nof SDF for accurate surface reconstruction. As a result, our method surpasses\nstate-of-the-art approaches in surface reconstruction and novel view synthesis\non the DTU and MobileBrick datasets. Code will be released at\nhttps://github.com/Gaozihui/SurfaceSplat.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15602v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2412.01481", "title": "Differential estimates for fast first-order multilevel nonconvex optimisation", "authors": ["Neil Dizon", "Tuomo Valkonen"], "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.01481v2", "summary": "With a view on bilevel and PDE-constrained optimisation, we develop iterative\nestimates $\\widetilde{F'}(x^k)$ of $F'(x^k)$ for composite functions $F :=J\n\\circ S$, where $S$ is the solution mapping of the inner optimisation problem\nor PDE. The idea is to form a single-loop method by interweaving updates of the\niterate $x^k$ by an outer optimisation method, with updates of the estimate by\nsingle steps of standard optimisation methods and linear system solvers. When\nthe inner methods satisfy simple tracking inequalities, the differential\nestimates can almost directly be employed in standard convergence proofs for\ngeneral forward-backward type methods. We adapt those proofs to a general\ninexact setting in normed spaces, that, besides our differential estimates,\nalso covers mismatched adjoints and unreachable optimality conditions in\nmeasure spaces. As a side product of these efforts, we provide improved\nconvergence results for nonconvex Primal-Dual Proximal Splitting (PDPS).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.01481v2", "cate": "math.OC", "date": "2024-12-02", "updated": "2025-07-19"}
{"id": "2503.23179", "title": "OncoReg: Medical Image Registration for Oncological Challenges", "authors": ["Wiebke Heyer", "Yannic Elser", "Lennart Berkel", "Xinrui Song", "Xuanang Xu", "Pingkun Yan", "Xi Jia", "Jinming Duan", "Zi Li", "Tony C. W. Mok", "BoWen LI", "Tim Hable", "Christian Staackmann", "Christoph Großbröhmer", "Lasse Hansen", "Alessa Hering", "Malte M. Sieren", "Mattias P. Heinrich"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      19 pages, 13 figures", "url": "http://arxiv.org/abs/2503.23179v3", "summary": "In modern cancer research, the vast volume of medical data generated is often\nunderutilised due to challenges related to patient privacy. The OncoReg\nChallenge addresses this issue by enabling researchers to develop and validate\nimage registration methods through a two-phase framework that ensures patient\nprivacy while fostering the development of more generalisable AI models. Phase\none involves working with a publicly available dataset, while phase two focuses\non training models on a private dataset within secure hospital networks.\nOncoReg builds upon the foundation established by the Learn2Reg Challenge by\nincorporating the registration of interventional cone-beam computed tomography\n(CBCT) with standard planning fan-beam CT (FBCT) images in radiotherapy.\nAccurate image registration is crucial in oncology, particularly for dynamic\ntreatment adjustments in image-guided radiotherapy, where precise alignment is\nnecessary to minimise radiation exposure to healthy tissues while effectively\ntargeting tumours. This work details the methodology and data behind the\nOncoReg Challenge and provides a comprehensive analysis of the competition\nentries and results. Findings reveal that feature extraction plays a pivotal\nrole in this registration task. A new method emerging from this challenge\ndemonstrated its versatility, while established approaches continue to perform\ncomparably to newer techniques. Both deep learning and classical approaches\nstill play significant roles in image registration, with the combination of\nmethods, particularly in feature extraction, proving most effective.", "comment": "19 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2503.23179v3", "cate": "eess.IV", "date": "2025-03-29", "updated": "2025-07-20"}
{"id": "2507.15717", "title": "BEnchmarking LLMs for Ophthalmology (BELO) for Ophthalmological Knowledge and Reasoning", "authors": ["Sahana Srinivasan", "Xuguang Ai", "Thaddaeus Wai Soon Lo", "Aidan Gilson", "Minjie Zou", "Ke Zou", "Hyunjae Kim", "Mingjia Yang", "Krithi Pushpanathan", "Samantha Yew", "Wan Ting Loke", "Jocelyn Goh", "Yibing Chen", "Yiming Kong", "Emily Yuelei Fu", "Michelle Ongyong Hui", "Kristen Nwanyanwu", "Amisha Dave", "Kelvin Zhenghao Li", "Chen-Hsin Sun", "Mark Chia", "Gabriel Dawei Yang", "Wendy Meihua Wong", "David Ziyou Chen", "Dianbo Liu", "Maxwell Singer", "Fares Antaki", "Lucian V Del Priore", "Jost Jonas", "Ron Adelman", "Qingyu Chen", "Yih-Chung Tham"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15717v1", "summary": "Current benchmarks evaluating large language models (LLMs) in ophthalmology\nare limited in scope and disproportionately prioritise accuracy. We introduce\nBELO (BEnchmarking LLMs for Ophthalmology), a standardized and comprehensive\nevaluation benchmark developed through multiple rounds of expert checking by 13\nophthalmologists. BELO assesses ophthalmology-related clinical accuracy and\nreasoning quality. Using keyword matching and a fine-tuned PubMedBERT model, we\ncurated ophthalmology-specific multiple-choice-questions (MCQs) from diverse\nmedical datasets (BCSC, MedMCQA, MedQA, BioASQ, and PubMedQA). The dataset\nunderwent multiple rounds of expert checking. Duplicate and substandard\nquestions were systematically removed. Ten ophthalmologists refined the\nexplanations of each MCQ's correct answer. This was further adjudicated by\nthree senior ophthalmologists. To illustrate BELO's utility, we evaluated six\nLLMs (OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, and Gemini 1.5 Pro)\nusing accuracy, macro-F1, and five text-generation metrics (ROUGE-L, BERTScore,\nBARTScore, METEOR, and AlignScore). In a further evaluation involving human\nexperts, two ophthalmologists qualitatively reviewed 50 randomly selected\noutputs for accuracy, comprehensiveness, and completeness. BELO consists of 900\nhigh-quality, expert-reviewed questions aggregated from five sources: BCSC\n(260), BioASQ (10), MedMCQA (572), MedQA (40), and PubMedQA (18). A public\nleaderboard has been established to promote transparent evaluation and\nreporting. Importantly, the BELO dataset will remain a hold-out,\nevaluation-only benchmark to ensure fair and reproducible comparisons of future\nmodels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15717v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15788", "title": "Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning", "authors": ["Sneheel Sarangi", "Hanan Salam"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15788v1", "summary": "Recent advancements in large language models (LLMs) have demonstrated\nemergent capabilities in complex reasoning, largely spurred by rule-based\nReinforcement Learning (RL) techniques applied during the post-training. This\nhas raised the question of whether similar methods can instill more nuanced,\nhuman-like social intelligence, such as a Theory of Mind (ToM), in LLMs. This\npaper investigates whether small-scale LLMs can acquire a robust and\ngeneralizable ToM capability through RL with verifiable rewards (RLVR). We\nconduct a systematic evaluation by training models on various combinations of\nprominent ToM datasets (HiToM, ExploreToM, FANToM) and testing for\ngeneralization on held-out datasets (e.g., OpenToM). Our findings indicate that\nsmall LLMs struggle to develop a generic ToM capability. While performance on\nin-distribution tasks improves, this capability fails to transfer to unseen ToM\ntasks with different characteristics. Furthermore, we demonstrate that\nprolonged RL training leads to models ``hacking'' the statistical patterns of\nthe training datasets, resulting in significant performance gains on in-domain\ndata but no change, or degradation of performance on out-of-distribution tasks.\nThis suggests the learned behavior is a form of narrow overfitting rather than\nthe acquisition of a true, abstract ToM capability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15788v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15606", "title": "CylinderPlane: Nested Cylinder Representation for 3D-aware Image Generation", "authors": ["Ru Jia", "Xiaozhuang Ma", "Jianji Wang", "Nanning Zheng"], "categories": ["cs.CV", "68T45", "I.4.5"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      5 pages, 4 figures, to be published", "url": "http://arxiv.org/abs/2507.15606v1", "summary": "While the proposal of the Tri-plane representation has advanced the\ndevelopment of the 3D-aware image generative models, problems rooted in its\ninherent structure, such as multi-face artifacts caused by sharing the same\nfeatures in symmetric regions, limit its ability to generate 360$^\\circ$ view\nimages. In this paper, we propose CylinderPlane, a novel implicit\nrepresentation based on Cylindrical Coordinate System, to eliminate the feature\nambiguity issue and ensure multi-view consistency in 360$^\\circ$. Different\nfrom the inevitable feature entanglement in Cartesian coordinate-based\nTri-plane representation, the cylindrical coordinate system explicitly\nseparates features at different angles, allowing our cylindrical representation\npossible to achieve high-quality, artifacts-free 360$^\\circ$ image synthesis.\nWe further introduce the nested cylinder representation that composites\nmultiple cylinders at different scales, thereby enabling the model more\nadaptable to complex geometry and varying resolutions. The combination of\ncylinders with different resolutions can effectively capture more critical\nlocations and multi-scale features, greatly facilitates fine detail learning\nand robustness to different resolutions. Moreover, our representation is\nagnostic to implicit rendering methods and can be easily integrated into any\nneural rendering pipeline. Extensive experiments on both synthetic dataset and\nunstructured in-the-wild images demonstrate that our proposed representation\nachieves superior performance over previous methods.", "comment": "5 pages, 4 figures, to be published", "pdf_url": "http://arxiv.org/pdf/2507.15606v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2412.10602", "title": "Spectral Properties of Positive Definite Matrices over Symmetrized Tropical Algebras and Valued Ordered fields", "authors": ["Marianne Akian", "Stephane Gaubert", "Dariush Kiani", "Hanieh Tavakolipour"], "categories": ["math.RA", "cs.NA", "math.CO", "math.NA", "math.SP"], "primary_category": "Subjects:       Rings and Algebras (math.RA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.10602v3", "summary": "We investigate the properties of positive definite and positive semi-definite\nsymmetric matrices within the framework of symmetrized tropical algebra, an\nextension of tropical algebra adapted to ordered valued fields.\n  We focus on the eigenvalues and eigenvectors of these matrices. We\n  prove that the eigenvalues of a positive (semi)-definite matrix in the\ntropical symmetrized setting coincide with its diagonal entries. Then, we show\nthat the images by the valuation of the eigenvalues of a positive definite\nmatrix over a valued nonarchimedean ordered field coincide with the eigenvalues\nof an associated matrix in the symmetrized tropical algebra. Moreover, under a\ngenericity condition, we characterize the images of the eigenvectors under the\nmap keeping track both of the nonarchimedean valuation and sign, showing that\nthey coincide with tropical eigenvectors in the symmetrized algebra. These\nresults offer new insights into the spectral theory of matrices over tropical\nsemirings, and provide combinatorial formul\\ae\\ for log-limits of eigenvalues\nand eigenvectors of parametric families of real positive definite matrices.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.10602v3", "cate": "math.RA", "date": "2024-12-13", "updated": "2025-07-18"}
{"id": "2504.06205", "title": "HER-Seg: Holistically Efficient Segmentation for High-Resolution Medical Images", "authors": ["Qing Xu", "Zhenye Lou", "Chenxin Li", "Yue Li", "Xiangjian He", "Tesema Fiseha Berhanu", "Rong Qu", "Wenting Duan", "Zhen Chen"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Under Review", "url": "http://arxiv.org/abs/2504.06205v2", "summary": "High-resolution segmentation is critical for precise disease diagnosis by\nextracting fine-grained morphological details. Existing hierarchical\nencoder-decoder frameworks have demonstrated remarkable adaptability across\ndiverse medical segmentation tasks. While beneficial, they usually require the\nhuge computation and memory cost when handling large-size segmentation, which\nlimits their applications in foundation model building and real-world clinical\nscenarios. To address this limitation, we propose a holistically efficient\nframework for high-resolution medical image segmentation, called HER-Seg.\nSpecifically, we first devise a computation-efficient image encoder\n(CE-Encoder) to model long-range dependencies with linear complexity while\nmaintaining sufficient representations. In particular, we introduce the\ndual-gated linear attention (DLA) mechanism to perform cascaded token\nfiltering, selectively retaining important tokens while ignoring irrelevant\nones to enhance attention computation efficiency. Then, we introduce a\nmemory-efficient mask decoder (ME-Decoder) to eliminate the demand for the\nhierarchical structure by leveraging cross-scale segmentation decoding.\nExtensive experiments reveal that HER-Seg outperforms state-of-the-arts in\nhigh-resolution medical 2D, 3D and video segmentation tasks. In particular, our\nHER-Seg requires only 0.59GB training GPU memory and 9.39G inference FLOPs per\n1024$\\times$1024 image, demonstrating superior memory and computation\nefficiency. The code is available at https://github.com/xq141839/HER-Seg.", "comment": "Under Review", "pdf_url": "http://arxiv.org/pdf/2504.06205v2", "cate": "eess.IV", "date": "2025-04-08", "updated": "2025-07-21"}
{"id": "2507.15752", "title": "DialogueForge: LLM Simulation of Human-Chatbot Dialogue", "authors": ["Ruizhe Zhu", "Hao Zhu", "Yaxuan Li", "Syang Zhou", "Shijing Cai", "Malgorzata Lazuka", "Elliott Ash"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      For our code and data, see this https URL", "url": "http://arxiv.org/abs/2507.15752v1", "summary": "Collecting human-chatbot dialogues typically demands substantial manual\neffort and is time-consuming, which limits and poses challenges for research on\nconversational AI. In this work, we propose DialogueForge - a framework for\ngenerating AI-simulated conversations in human-chatbot style. To initialize\neach generated conversation, DialogueForge uses seed prompts extracted from\nreal human-chatbot interactions. We test a variety of LLMs to simulate the\nhuman chatbot user, ranging from state-of-the-art proprietary models to\nsmall-scale open-source LLMs, and generate multi-turn dialogues tailored to\nspecific tasks. In addition, we explore fine-tuning techniques to enhance the\nability of smaller models to produce indistinguishable human-like dialogues. We\nevaluate the quality of the simulated conversations and compare different\nmodels using the UniEval and GTEval evaluation protocols. Our experiments show\nthat large proprietary models (e.g., GPT-4o) generally outperform others in\ngenerating more realistic dialogues, while smaller open-source models (e.g.,\nLlama, Mistral) offer promising performance with greater customization. We\ndemonstrate that the performance of smaller models can be significantly\nimproved by employing supervised fine-tuning techniques. Nevertheless,\nmaintaining coherent and natural long-form human-like dialogues remains a\ncommon challenge across all models.", "comment": "For our code and data, see\n  https://github.com/nerchio/Human_Chatbot-Generation", "pdf_url": "http://arxiv.org/pdf/2507.15752v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15832", "title": "Multi-Strategy Improved Snake Optimizer Accelerated CNN-LSTM-Attention-Adaboost for Trajectory Prediction", "authors": ["Shiyang Li"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      in Chinese language", "url": "http://arxiv.org/abs/2507.15832v1", "summary": "To address the limitations of medium- and long-term four-dimensional (4D)\ntrajectory prediction models, this paper proposes a hybrid\nCNN-LSTM-attention-adaboost neural network model incorporating a multi-strategy\nimproved snake-herd optimization (SO) algorithm. The model applies the Adaboost\nalgorithm to divide multiple weak learners, and each submodel utilizes CNN to\nextract spatial features, LSTM to capture temporal features, and attention\nmechanism to capture global features comprehensively. The strong learner model,\ncombined with multiple sub-models, then optimizes the hyperparameters of the\nprediction model through the natural selection behavior pattern simulated by\nSO. In this study, based on the real ADS-B data from Xi'an to Tianjin, the\ncomparison experiments and ablation studies of multiple optimizers are carried\nout, and a comprehensive test and evaluation analysis is carried out. The\nresults show that SO-CLA-adaboost outperforms traditional optimizers such as\nparticle swarm, whale, and gray wolf in handling large-scale high-dimensional\ntrajectory data. In addition, introducing the full-strategy collaborative\nimprovement SO algorithm improves the model's prediction accuracy by 39.89%.", "comment": "in Chinese language", "pdf_url": "http://arxiv.org/pdf/2507.15832v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15628", "title": "A Survey on Efficiency Optimization Techniques for DNN-based Video Analytics: Process Systems, Algorithms, and Applications", "authors": ["Shanjiang Tang", "Rui Huang", "Hsinyu Luo", "Chunjiang Wang", "Ce Yu", "Yusen Li", "Hao Fu", "Chao Sun", "and Jian Xiao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15628v1", "summary": "The explosive growth of video data in recent years has brought higher demands\nfor video analytics, where accuracy and efficiency remain the two primary\nconcerns. Deep neural networks (DNNs) have been widely adopted to ensure\naccuracy; however, improving their efficiency in video analytics remains an\nopen challenge. Different from existing surveys that make summaries of\nDNN-based video mainly from the accuracy optimization aspect, in this survey,\nwe aim to provide a thorough review of optimization techniques focusing on the\nimprovement of the efficiency of DNNs in video analytics. We organize existing\nmethods in a bottom-up manner, covering multiple perspectives such as hardware\nsupport, data processing, operational deployment, etc. Finally, based on the\noptimization framework and existing works, we analyze and discuss the problems\nand challenges in the performance optimization of DNN-based video analytics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15628v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2503.18837", "title": "Dirichlet-to-Neumann operator for the Helmholtz problem with general wavenumbers on the $n$-sphere", "authors": ["Benedikt Gräßle", "Stefan A. Sauter"], "categories": ["math.AP", "cs.NA", "math.NA", "31B10, 35J05, 47G10"], "primary_category": "Subjects:       Analysis of PDEs (math.AP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.18837v2", "summary": "This paper considers the Helmholtz problem in the exterior of a ball with\nDirichlet boundary conditions and radiation conditions imposed at infinity. The\ndifferential Helmholtz operator depends on the complex wavenumber with\nnon-negative real part and is formulated for general spatial dimension. We\nprove wavenumber explicit continuity estimates of the corresponding\nDirichlet-to-Neumann (DtN) operator which are valid for all wavenumbers under\nconsideration and do not deteriorate as they tend to zero.\n  The exterior Helmholtz problem can be equivalently reformulated on a bounded\ndomain with DtN boundary conditions on the artificial boundary of a ball. We\nderive wavenumber independent trace and Friedrichs-type inequalities for the\nsolution space in wavenumber-indexed norms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.18837v2", "cate": "math.AP", "date": "2025-03-24", "updated": "2025-07-18"}
{"id": "2504.12249", "title": "Comparative Evaluation of Radiomics and Deep Learning Models for Disease Detection in Chest Radiography", "authors": ["Zhijin He", "Alan B. McMillan"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      one figure updated for improved visual clarity; fixed inconsistencies and redundancies", "url": "http://arxiv.org/abs/2504.12249v3", "summary": "The application of artificial intelligence (AI) in medical imaging has\nrevolutionized diagnostic practices, enabling advanced analysis and\ninterpretation of radiological data. This study presents a comprehensive\nevaluation of radiomics-based and deep learning-based approaches for disease\ndetection in chest radiography, focusing on COVID-19, lung opacity, and viral\npneumonia. While deep learning models, particularly convolutional neural\nnetworks and vision transformers, learn directly from image data,\nradiomics-based models extract handcrafted features, offering potential\nadvantages in data-limited scenarios. We systematically compared the diagnostic\nperformance of various AI models, including Decision Trees, Gradient Boosting,\nRandom Forests, Support Vector Machines, and Multi-Layer Perceptrons for\nradiomics, against state-of-the-art deep learning models such as InceptionV3,\nEfficientNetL, and ConvNeXtXLarge. Performance was evaluated across multiple\nsample sizes. At 24 samples, EfficientNetL achieved an AUC of 0.839,\noutperforming SVM (AUC = 0.762). At 4000 samples, InceptionV3 achieved the\nhighest AUC of 0.996, compared to 0.885 for Random Forest. A Scheirer-Ray-Hare\ntest confirmed significant main and interaction effects of model type and\nsample size on all metrics. Post hoc Mann-Whitney U tests with Bonferroni\ncorrection further revealed consistent performance advantages for deep learning\nmodels across most conditions. These findings provide statistically validated,\ndata-driven recommendations for model selection in diagnostic AI. Deep learning\nmodels demonstrated higher performance and better scalability with increasing\ndata availability, while radiomics-based models may remain useful in low-data\ncontexts. This study addresses a critical gap in AI-based diagnostic research\nby offering practical guidance for deploying AI models across diverse clinical\nenvironments.", "comment": "one figure updated for improved visual clarity; fixed inconsistencies\n  and redundancies", "pdf_url": "http://arxiv.org/pdf/2504.12249v3", "cate": "eess.IV", "date": "2025-04-16", "updated": "2025-07-21"}
{"id": "2507.15773", "title": "Supernova: Achieving More with Less in Transformer Architectures", "authors": ["Andrei-Valentin Tanase", "Elena Pelican"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15773v1", "summary": "We present Supernova, a 650M-parameter decoder-only transformer that\ndemonstrates how careful architectural design and tokenization innovation can\nachieve the performance of larger models while maintaining computational\nefficiency. Our architecture combines Rotary Positional Embeddings (RoPE),\nGrouped Query Attention (GQA) with a 3:1 compression ratio, RMSNorm for\ncomputational efficiency, and SwiGLU activation functions. A critical\ninnovation is our custom 128,000-vocabulary byte-level BPE tokenizer, which\nachieves state-of-the-art compression performance. Through detailed analysis,\nwe show that Supernova achieves 90% of the performance of 1B-parameter models\nwhile using 53% fewer parameters and requiring only 100B training tokens--an\norder of magnitude less than competing models. Our findings challenge the\nprevailing scaling paradigm, demonstrating that architectural efficiency and\ntokenization quality can compensate for reduced parameter counts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15773v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15839", "title": "FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs", "authors": ["Anh Nguyen", "Sam Schafft", "Nicholas Hale", "John Alfaro"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15839v1", "summary": "Synthetic data generation has emerged as an invaluable solution in scenarios\nwhere real-world data collection and usage are limited by cost and scarcity.\nLarge language models (LLMs) have demonstrated remarkable capabilities in\nproducing high-fidelity, domain-relevant samples across various fields.\nHowever, existing approaches that directly use LLMs to generate each record\nindividually impose prohibitive time and cost burdens, particularly when large\nvolumes of synthetic data are required. In this work, we propose a fast,\ncost-effective method for realistic tabular data synthesis that leverages LLMs\nto infer and encode each field's distribution into a reusable sampling script.\nBy automatically classifying fields into numerical, categorical, or free-text\ntypes, the LLM generates distribution-based scripts that can efficiently\nproduce diverse, realistic datasets at scale without continuous model\ninference. Experimental results show that our approach outperforms traditional\ndirect methods in both diversity and data realism, substantially reducing the\nburden of high-volume synthetic data generation. We plan to apply this\nmethodology to accelerate testing in production pipelines, thereby shortening\ndevelopment cycles and improving overall system efficiency. We believe our\ninsights and lessons learned will aid researchers and practitioners seeking\nscalable, cost-effective solutions for synthetic data generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15839v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15633", "title": "Experimenting active and sequential learning in a medieval music manuscript", "authors": ["Sachin Sharma", "Federico Simonetta", "Michele Flammini"], "categories": ["cs.CV", "I.2.10; I.4.8; H.3.3"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages, 4 figures, accepted at IEEE MLSP 2025 (IEEE International Workshop on Machine Learning for Signal Processing). Special Session: Applications of AI in Cultural and Artistic Heritage", "url": "http://arxiv.org/abs/2507.15633v1", "summary": "Optical Music Recognition (OMR) is a cornerstone of music digitization\ninitiatives in cultural heritage, yet it remains limited by the scarcity of\nannotated data and the complexity of historical manuscripts. In this paper, we\npresent a preliminary study of Active Learning (AL) and Sequential Learning\n(SL) tailored for object detection and layout recognition in an old medieval\nmusic manuscript. Leveraging YOLOv8, our system selects samples with the\nhighest uncertainty (lowest prediction confidence) for iterative labeling and\nretraining. Our approach starts with a single annotated image and successfully\nboosts performance while minimizing manual labeling. Experimental results\nindicate that comparable accuracy to fully supervised training can be achieved\nwith significantly fewer labeled examples. We test the methodology as a\npreliminary investigation on a novel dataset offered to the community by the\nAnonymous project, which studies laude, a poetical-musical genre spread across\nItaly during the 12th-16th Century. We show that in the manuscript at-hand,\nuncertainty-based AL is not effective and advocates for more usable methods in\ndata-scarcity scenarios.", "comment": "6 pages, 4 figures, accepted at IEEE MLSP 2025 (IEEE International\n  Workshop on Machine Learning for Signal Processing). Special Session:\n  Applications of AI in Cultural and Artistic Heritage", "pdf_url": "http://arxiv.org/pdf/2507.15633v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2506.16582", "title": "Quasi-Monte Carlo with one categorical variable", "authors": ["Valerie N. P. Ho", "Art B. Owen", "Zexin Pan"], "categories": ["stat.CO", "cs.NA", "math.NA"], "primary_category": "Subjects:       Computation (stat.CO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.16582v2", "summary": "We study randomized quasi-Monte Carlo (RQMC) estimation of a multivariate\nintegral where one of the variables takes only a finite number of values. This\nproblem arises when the variable of integration is drawn from a mixture\ndistribution as is common in importance sampling and also arises in some recent\nwork on transport maps. We find that when integration error decreases at an\nRQMC rate that it is then beneficial to oversample the smallest mixture\ncomponents instead of using a proportional allocation. The optimal allocations\ndepend on the possibly unknown convergence rates. Designing the sample with an\nincorrect assumption on the rate still attains that convergence rate, with an\ninferior implied constant. The penalty for using a pessimistic rate is\ntypically higher than for using an optimistic one. We also find that for the\nmost accurate RQMC sampling methods, it is advantageous to arrange that our\n$n=2^m$ randomized Sobol' points split into subsample sizes that are also\npowers of $2$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.16582v2", "cate": "stat.CO", "date": "2025-06-19", "updated": "2025-07-18"}
{"id": "2505.16091", "title": "OSCAR: One-Step Diffusion Codec Across Multiple Bit-rates", "authors": ["Jinpei Guo", "Yifei Ji", "Zheng Chen", "Kai Liu", "Min Liu", "Wang Rao", "Wenbo Li", "Yong Guo", "Yulun Zhang"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.16091v4", "summary": "Pretrained latent diffusion models have shown strong potential for lossy\nimage compression, owing to their powerful generative priors. Most existing\ndiffusion-based methods reconstruct images by iteratively denoising from random\nnoise, guided by compressed latent representations. While these approaches have\nachieved high reconstruction quality, their multi-step sampling process incurs\nsubstantial computational overhead. Moreover, they typically require training\nseparate models for different compression bit-rates, leading to significant\ntraining and storage costs. To address these challenges, we propose a one-step\ndiffusion codec across multiple bit-rates. termed OSCAR. Specifically, our\nmethod views compressed latents as noisy variants of the original latents,\nwhere the level of distortion depends on the bit-rate. This perspective allows\nthem to be modeled as intermediate states along a diffusion trajectory. By\nestablishing a mapping from the compression bit-rate to a pseudo diffusion\ntimestep, we condition a single generative model to support reconstructions at\nmultiple bit-rates. Meanwhile, we argue that the compressed latents retain rich\nstructural information, thereby making one-step denoising feasible. Thus, OSCAR\nreplaces iterative sampling with a single denoising pass, significantly\nimproving inference efficiency. Extensive experiments demonstrate that OSCAR\nachieves superior performance in both quantitative and visual quality metrics.\nThe code and models will be released at https://github.com/jp-guo/OSCAR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.16091v4", "cate": "eess.IV", "date": "2025-05-22", "updated": "2025-07-19"}
{"id": "2507.15775", "title": "Learning Null Geodesics for Gravitational Lensing Rendering in General Relativity", "authors": ["Mingyuan Sun", "Zheng Fang", "Jiaxu Wang", "Kunyi Zhang", "Qiang Zhang", "Renjing Xu"], "categories": ["gr-qc", "astro-ph.IM", "cs.AI"], "primary_category": "Subjects:       General Relativity and Quantum Cosmology (gr-qc)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.15775v1", "summary": "We present GravLensX, an innovative method for rendering black holes with\ngravitational lensing effects using neural networks. The methodology involves\ntraining neural networks to fit the spacetime around black holes and then\nemploying these trained models to generate the path of light rays affected by\ngravitational lensing. This enables efficient and scalable simulations of black\nholes with optically thin accretion disks, significantly decreasing the time\nrequired for rendering compared to traditional methods. We validate our\napproach through extensive rendering of multiple black hole systems with\nsuperposed Kerr metric, demonstrating its capability to produce accurate\nvisualizations with significantly $15\\times$ reduced computational time. Our\nfindings suggest that neural networks offer a promising alternative for\nrendering complex astrophysical phenomena, potentially paving a new path to\nastronomical visualization.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.15775v1", "cate": "gr-qc", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14159", "title": "Siamese Neural Network for Label-Efficient Critical Phenomena Prediction in 3D Percolation Models", "authors": ["Shanshan Wang", "Dian Xu", "Jianmin Shen", "Feng Gao", "Wei Li", "Weibing Deng"], "categories": ["cond-mat.dis-nn", "cs.LG"], "primary_category": "Subjects:       Disordered Systems and Neural Networks (cond-mat.dis-nn)", "pdf_link": null, "comments": "Comments:      14 pages, 9 figures", "url": "http://arxiv.org/abs/2507.14159v1", "summary": "Percolation theory serves as a cornerstone for studying phase transitions and\ncritical phenomena, with broad implications in statistical physics, materials\nscience, and complex networks. However, most machine learning frameworks for\npercolation analysis have focused on two-dimensional systems, oversimplifying\nthe spatial correlations and morphological complexity of real-world\nthree-dimensional materials. To bridge this gap and improve label efficiency\nand scalability in 3D systems, we propose a Siamese Neural Network (SNN) that\nleverages features of the largest cluster as discriminative input. Our method\nachieves high predictive accuracy for both site and bond percolation thresholds\nand critical exponents in three dimensions, with sub-1% error margins using\nsignificantly fewer labeled samples than traditional approaches. This work\nestablishes a robust and data-efficient framework for modeling high-dimensional\ncritical phenomena, with potential applications in materials discovery and\ncomplex network analysis.", "comment": "14 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.14159v1", "cate": "cond-mat.dis-nn", "date": "2025-07-05", "updated": "2025-07-05"}
{"id": "2507.15652", "title": "Extracting Visual Facts from Intermediate Layers for Mitigating Hallucinations in Multimodal Large Language Models", "authors": ["Haoran Zhou", "Zihan Zhang", "Hao Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15652v1", "summary": "Multimodal Large Language Models (MLLMs) have made significant strides by\ncombining visual recognition and language understanding to generate content\nthat is both coherent and contextually accurate. However, MLLMs continue to\nstruggle with object hallucinations, where models produce seemingly plausible\nbut factually incorrect outputs, including objects that do not exist in the\nimage. Recent work has revealed that the prior knowledge in MLLMs significantly\nsuppresses visual information in deep layers, causing hallucinatory outputs.\nHowever, how these priors suppress visual information at the intermediate layer\nstage in MLLMs remains unclear. We observe that visual factual knowledge and\nthe differences between intermediate-layer prior/original probability\ndistributions show similar evolutionary trends in intermediate layers.\nMotivated by this, we introduce Decoding by Extracting Visual Facts (EVA), a\nsimple, training-free method that dynamically selects intermediate layers with\nthe most significant visual factual information. By contrasting the output\ndistributions of the selected layer derived from the original input and\npure-text input, EVA extracts visual factual knowledge and proportionally\nincorporates it into the final layer to correct the output logits. Importantly,\nEVA is model-agnostic, seamlessly integrates with various classic decoding\nstrategies, and is applicable across different MLLMs. We validate EVA on\nwidely-used benchmarks, and the results show that it significantly reduces\nhallucination rates compared to baseline methods, underscoring its\neffectiveness in mitigating hallucinations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15652v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.09305", "title": "DAA*: Deep Angular A Star for Image-based Path Planning", "authors": ["Zhiwei Xu"], "categories": ["cs.CV", "cs.LG", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      International Conference on Computer Vision (ICCV), 2025", "url": "http://arxiv.org/abs/2507.09305v2", "summary": "Path smoothness is often overlooked in path imitation learning from expert\ndemonstrations. In this paper, we introduce a novel learning method, termed\ndeep angular A* (DAA*), by incorporating the proposed path angular freedom\n(PAF) into A* to improve path similarity through adaptive path smoothness. The\nPAF aims to explore the effect of move angles on path node expansion by finding\nthe trade-off between their minimum and maximum values, allowing for high\nadaptiveness for imitation learning. DAA* improves path optimality by closely\naligning with the reference path through joint optimization of path shortening\nand smoothing, which correspond to heuristic distance and PAF, respectively.\nThroughout comprehensive evaluations on 7 datasets, including 4 maze datasets,\n2 video-game datasets, and a real-world drone-view dataset containing 2\nscenarios, we demonstrate remarkable improvements of our DAA* over neural A* in\npath similarity between the predicted and reference paths with a shorter path\nlength when the shortest path is plausible, improving by 9.0% SPR, 6.9% ASIM,\nand 3.9% PSIM. Furthermore, when jointly learning pathfinding with both path\nloss and path probability map loss, DAA* significantly outperforms the\nstate-of-the-art TransPath by 6.7% SPR, 6.5% PSIM, and 3.7% ASIM. We also\ndiscuss the minor trade-off between path optimality and search efficiency where\napplicable. Our code and model weights are available at\nhttps://github.com/zwxu064/DAAStar.git.", "comment": "International Conference on Computer Vision (ICCV), 2025", "pdf_url": "http://arxiv.org/pdf/2507.09305v2", "cate": "cs.CV", "date": "2025-07-12", "updated": "2025-07-21"}
{"id": "2507.15803", "title": "ConformalSAM: Unlocking the Potential of Foundational Segmentation Models in Semi-Supervised Semantic Segmentation with Conformal Prediction", "authors": ["Danhui Chen", "Ziquan Liu", "Chuxi Yang", "Dan Wang", "Yan Yan", "Yi Xu", "Xiangyang Ji"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.15803v1", "summary": "Pixel-level vision tasks, such as semantic segmentation, require extensive\nand high-quality annotated data, which is costly to obtain. Semi-supervised\nsemantic segmentation (SSSS) has emerged as a solution to alleviate the\nlabeling burden by leveraging both labeled and unlabeled data through\nself-training techniques. Meanwhile, the advent of foundational segmentation\nmodels pre-trained on massive data, has shown the potential to generalize\nacross domains effectively. This work explores whether a foundational\nsegmentation model can address label scarcity in the pixel-level vision task as\nan annotator for unlabeled images. Specifically, we investigate the efficacy of\nusing SEEM, a Segment Anything Model (SAM) variant fine-tuned for textual\ninput, to generate predictive masks for unlabeled data. To address the\nshortcomings of using SEEM-generated masks as supervision, we propose\nConformalSAM, a novel SSSS framework which first calibrates the foundation\nmodel using the target domain's labeled data and then filters out unreliable\npixel labels of unlabeled data so that only high-confidence labels are used as\nsupervision. By leveraging conformal prediction (CP) to adapt foundation models\nto target data through uncertainty calibration, ConformalSAM exploits the\nstrong capability of the foundational segmentation model reliably which\nbenefits the early-stage learning, while a subsequent self-reliance training\nstrategy mitigates overfitting to SEEM-generated masks in the later training\nstage. Our experiment demonstrates that, on three standard benchmarks of SSSS,\nConformalSAM achieves superior performance compared to recent SSSS methods and\nhelps boost the performance of those methods as a plug-in.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.15803v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14160", "title": "FinSurvival: A Suite of Large Scale Survival Modeling Tasks from Finance", "authors": ["Aaron Green", "Zihan Nie", "Hanzhen Qin", "Oshani Seneviratne", "Kristin P. Bennett"], "categories": ["q-fin.ST", "cs.LG"], "primary_category": "Subjects:       Statistical Finance (q-fin.ST)", "pdf_link": null, "comments": "Comments:      33 pages, 4 figures, submitted to DMLR", "url": "http://arxiv.org/abs/2507.14160v1", "summary": "Survival modeling predicts the time until an event occurs and is widely used\nin risk analysis; for example, it's used in medicine to predict the survival of\na patient based on censored data. There is a need for large-scale, realistic,\nand freely available datasets for benchmarking artificial intelligence (AI)\nsurvival models. In this paper, we derive a suite of 16 survival modeling tasks\nfrom publicly available transaction data generated by lending of\ncryptocurrencies in Decentralized Finance (DeFi). Each task was constructed\nusing an automated pipeline based on choices of index and outcome events. For\nexample, the model predicts the time from when a user borrows cryptocurrency\ncoins (index event) until their first repayment (outcome event). We formulate a\nsurvival benchmark consisting of a suite of 16 survival-time prediction tasks\n(FinSurvival). We also automatically create 16 corresponding classification\nproblems for each task by thresholding the survival time using the restricted\nmean survival time. With over 7.5 million records, FinSurvival provides a suite\nof realistic financial modeling tasks that will spur future AI survival\nmodeling research. Our evaluation indicated that these are challenging tasks\nthat are not well addressed by existing methods. FinSurvival enables the\nevaluation of AI survival models applicable to traditional finance, industry,\nmedicine, and commerce, which is currently hindered by the lack of large public\ndatasets. Our benchmark demonstrates how AI models could assess opportunities\nand risks in DeFi. In the future, the FinSurvival benchmark pipeline can be\nused to create new benchmarks by incorporating more DeFi transactions and\nprotocols as the use of cryptocurrency grows.", "comment": "33 pages, 4 figures, submitted to DMLR", "pdf_url": "http://arxiv.org/pdf/2507.14160v1", "cate": "q-fin.ST", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.15655", "title": "HW-MLVQA: Elucidating Multilingual Handwritten Document Understanding with a Comprehensive VQA Benchmark", "authors": ["Aniket Pal", "Ajoy Mondal", "Minesh Mathew", "C. V. Jawahar"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This is a minor revision of the original paper submitted to IJDAR", "url": "http://arxiv.org/abs/2507.15655v1", "summary": "The proliferation of MultiLingual Visual Question Answering (MLVQA)\nbenchmarks augments the capabilities of large language models (LLMs) and\nmulti-modal LLMs, thereby enabling them to adeptly capture the intricate\nlinguistic subtleties and visual complexities inherent across diverse\nlanguages. Despite its potential, the current MLVQA model struggles to fully\nutilize its capabilities when dealing with the extensive variety of handwritten\ndocuments. This article delineates HW-MLVQA, an avant-garde VQA benchmark\nmeticulously crafted to mitigate the dearth of authentic Multilingual\nHandwritten document comprehension. HW-MLVQA encompasses an extensive\ncollection of 1,600 handwritten Pages complemented by 2,400 question-answers.\nFurthermore, it provides a robust benchmark evaluation framework spanning three\ndistinct modalities: text, image, and an integrated image & text modality. To\nsimulate authentic real-world contexts devoid of ground truth textual\ntranscriptions, we facilitates a rigorous assessment of proprietary and\nopen-source OCR models. The benchmark aspires to facilitate pivotal\nadvancements in multilingual handwritten document interpretation, fostering\ninnovation and scholarly inquiry within this specialized domain.", "comment": "This is a minor revision of the original paper submitted to IJDAR", "pdf_url": "http://arxiv.org/pdf/2507.15655v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.09681", "title": "Prompt2DEM: High-Resolution DEMs for Urban and Open Environments from Global Prompts Using a Monocular Foundation Model", "authors": ["Osher Rafaeli", "Tal Svoray", "Ariel Nahlieli"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      18 pages", "url": "http://arxiv.org/abs/2507.09681v2", "summary": "High-resolution elevation estimations are essential to understand catchment\nand hillslope hydrology, study urban morphology and dynamics, and monitor the\ngrowth, decline, and mortality of terrestrial ecosystems. Various deep learning\napproaches (e.g., super-resolution techniques, monocular depth estimation) have\nbeen developed to create high-resolution Digital Elevation Models (DEMs).\nHowever, super-resolution techniques are limited by the upscaling factor, and\nmonocular depth estimation lacks global elevation context, making its\nconversion to a seamless DEM restricted. The recently introduced technique of\nprompt-based monocular depth estimation has opened new opportunities to extract\nestimates of absolute elevation in a global context. We present here a\nframework for the estimation of high-resolution DEMs as a new paradigm for\nabsolute global elevation mapping. It is exemplified using low-resolution\nShuttle Radar Topography Mission (SRTM) elevation data as prompts and\nhigh-resolution RGB imagery from the National Agriculture Imagery Program\n(NAIP). The approach fine-tunes a vision transformer encoder with LiDAR-derived\nDEMs and employs a versatile prompting strategy, enabling tasks such as DEM\nestimation, void filling, and updating. Our framework achieves a 100x\nresolution gain (from 30-m to 30-cm), surpassing prior methods by an order of\nmagnitude. Evaluations across three diverse U.S. landscapes show robust\ngeneralization, capturing urban structures and fine-scale terrain features with\n< 5 m MAE relative to LiDAR, improving over SRTM by up to 18%. Hydrological\nanalysis confirms suitability for hazard and environmental studies. We\ndemonstrate scalability by applying the framework to large regions in the U.S.\nand Israel. All code and pretrained models are publicly available at:\nhttps://osherr1996.github.io/prompt2dem_propage/.", "comment": "18 pages", "pdf_url": "http://arxiv.org/pdf/2507.09681v2", "cate": "cs.CV", "date": "2025-07-13", "updated": "2025-07-21"}
{"id": "2507.15807", "title": "True Multimodal In-Context Learning Needs Attention to the Visual Context", "authors": ["Shuo Chen", "Jianzhe Liu", "Zhen Han", "Yan Xia", "Daniel Cremers", "Philip Torr", "Volker Tresp", "Jindong Gu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted to COLM 2025", "url": "http://arxiv.org/abs/2507.15807v1", "summary": "Multimodal Large Language Models (MLLMs), built on powerful language\nbackbones, have enabled Multimodal In-Context Learning (MICL)-adapting to new\ntasks from a few multimodal demonstrations consisting of images, questions, and\nanswers. Despite showing noticeable improvement on standard vision-language\ndatasets, current MLLMs struggle to leverage visual information in the\ndemonstrations. Specifically, they tend to neglect visual cues and over-rely on\ntextual patterns, leading to mere text imitation rather than genuine multimodal\nadaptation. This behavior makes MICL still unimodal and largely restricts its\npractical utility. More importantly, this limitation is often concealed by the\nimproved performance on tasks that do not require understanding the visual\ncontext. As a result, how to effectively enhance MICL ability and reliably\nevaluate the MICL performance remains underexplored. To address these issues,\nwe first introduce Dynamic Attention Reallocation (DARA), an efficient\nfine-tuning strategy that encourages models to attend to the visual context by\nrebalancing attention across visual and textual tokens. In addition, we present\nTrueMICL, an MICL-dedicated dataset with both support and test sets that\nexplicitly requires the integration of multimodal information-particularly\nvisual content-for correct task completion. Extensive experiments demonstrate\nthe effectiveness of our holistic solution, showcasing substantial improvements\nin the true multimodal in-context learning capabilities. Code and datasets are\navailable at https://chenxshuo.github.io/true-micl-colm .", "comment": "accepted to COLM 2025", "pdf_url": "http://arxiv.org/pdf/2507.15807v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14161", "title": "Complex Dynamics in Psychological Data: Mapping Individual Symptom Trajectories to Group-Level Patterns", "authors": ["Eleonora Vitanza", "Pietro DeLellis", "Chiara Mocenni", "Manuel Ruiz Marin"], "categories": ["stat.AP", "cs.LG", "stat.ML", "62D20, 37M10, 05C82", "G.3"], "primary_category": "Subjects:       Applications (stat.AP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14161v1", "summary": "This study integrates causal inference, graph analysis, temporal complexity\nmeasures, and machine learning to examine whether individual symptom\ntrajectories can reveal meaningful diagnostic patterns. Testing on a\nlongitudinal dataset of N=45 individuals affected by General Anxiety Disorder\n(GAD) and/or Major Depressive Disorder (MDD) derived from Fisher et al. 2017,\nwe propose a novel pipeline for the analysis of the temporal dynamics of\npsychopathological symptoms. First, we employ the PCMCI+ algorithm with\nnonparametric independence test to determine the causal network of nonlinear\ndependencies between symptoms in individuals with different mental disorders.\nWe found that the PCMCI+ effectively highlights the individual peculiarities of\neach symptom network, which could be leveraged towards personalized therapies.\nAt the same time, aggregating the networks by diagnosis sheds light to\ndisorder-specific causal mechanisms, in agreement with previous\npsychopathological literature. Then, we enrich the dataset by computing\ncomplexity-based measures (e.g. entropy, fractal dimension, recurrence) from\nthe symptom time series, and feed it to a suitably selected machine learning\nalgorithm to aid the diagnosis of each individual. The new dataset yields 91%\naccuracy in the classification of the symptom dynamics, proving to be an\neffective diagnostic support tool. Overall, these findings highlight how\nintegrating causal modeling and temporal complexity can enhance diagnostic\ndifferentiation, offering a principled, data-driven foundation for both\npersonalized assessment in clinical psychology and structural advances in\npsychological research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14161v1", "cate": "stat.AP", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.15680", "title": "Visual-Language Model Knowledge Distillation Method for Image Quality Assessment", "authors": ["Yongkang Hou", "Jiarun Song"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15680v1", "summary": "Image Quality Assessment (IQA) is a core task in computer vision. Multimodal\nmethods based on vision-language models, such as CLIP, have demonstrated\nexceptional generalization capabilities in IQA tasks. To address the issues of\nexcessive parameter burden and insufficient ability to identify local distorted\nfeatures in CLIP for IQA, this study proposes a visual-language model knowledge\ndistillation method aimed at guiding the training of models with architectural\nadvantages using CLIP's IQA knowledge. First, quality-graded prompt templates\nwere designed to guide CLIP to output quality scores. Then, CLIP is fine-tuned\nto enhance its capabilities in IQA tasks. Finally, a modality-adaptive\nknowledge distillation strategy is proposed to achieve guidance from the CLIP\nteacher model to the student model. Our experiments were conducted on multiple\nIQA datasets, and the results show that the proposed method significantly\nreduces model complexity while outperforming existing IQA methods,\ndemonstrating strong potential for practical deployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15680v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15849", "title": "The Impact of Language Mixing on Bilingual LLM Reasoning", "authors": ["Yihao Li", "Jiayi Xin", "Miranda Muqing Miao", "Qi Long", "Lyle Ungar"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15849v1", "summary": "Proficient multilingual speakers often intentionally switch languages in the\nmiddle of a conversation. Similarly, recent reasoning-focused bilingual large\nlanguage models (LLMs) with strong capabilities in both languages exhibit\nlanguage mixing--alternating languages within their chain of thought.\nDiscouraging this behavior in DeepSeek-R1 was found to degrade accuracy,\nsuggesting that language mixing may benefit reasoning. In this work, we study\nlanguage switching in Chinese-English bilingual reasoning models. We identify\nreinforcement learning with verifiable rewards (RLVR) as the critical training\nstage that leads to language mixing. We demonstrate that language mixing can\nenhance reasoning: enforcing monolingual decoding reduces accuracy by 5.6\npercentage points on math reasoning tasks. Additionally, a lightweight probe\ncan be trained to predict whether a potential language switch would benefit or\nharm reasoning, and when used to guide decoding, increases accuracy by up to\n6.25 percentage points. Our findings suggest that language mixing is not merely\na byproduct of multilingual training, but is a strategic reasoning behavior.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15849v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14302", "title": "A universal augmentation framework for long-range electrostatics in machine learning interatomic potentials", "authors": ["Dongjin Kim", "Xiaoyu Wang", "Peichen Zhong", "Daniel S. King", "Theo Jaffrelot Inizan", "Bingqing Cheng"], "categories": ["physics.chem-ph", "cs.LG", "physics.comp-ph"], "primary_category": "Subjects:       Chemical Physics (physics.chem-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14302v1", "summary": "Most current machine learning interatomic potentials (MLIPs) rely on\nshort-range approximations, without explicit treatment of long-range\nelectrostatics. To address this, we recently developed the Latent Ewald\nSummation (LES) method, which infers electrostatic interactions, polarization,\nand Born effective charges (BECs), just by learning from energy and force\ntraining data. Here, we present LES as a standalone library, compatible with\nany short-range MLIP, and demonstrate its integration with methods such as\nMACE, NequIP, CACE, and CHGNet. We benchmark LES-enhanced models on distinct\nsystems, including bulk water, polar dipeptides, and gold dimer adsorption on\ndefective substrates, and show that LES not only captures correct\nelectrostatics but also improves accuracy. Additionally, we scale LES to large\nand chemically diverse data by training MACELES-OFF on the SPICE set containing\nmolecules and clusters, making a universal MLIP with electrostatics for organic\nsystems including biomolecules. MACELES-OFF is more accurate than its\nshort-range counterpart (MACE-OFF) trained on the same dataset, predicts\ndipoles and BECs reliably, and has better descriptions of bulk liquids. By\nenabling efficient long-range electrostatics without directly training on\nelectrical properties, LES paves the way for electrostatic foundation MLIPs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14302v1", "cate": "physics.chem-ph", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15683", "title": "Hi^2-GSLoc: Dual-Hierarchical Gaussian-Specific Visual Relocalization for Remote Sensing", "authors": ["Boni Hu", "Zhenyu Xia", "Lin Chen", "Pengcheng Han", "Shuhui Bu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 11 figures", "url": "http://arxiv.org/abs/2507.15683v1", "summary": "Visual relocalization, which estimates the 6-degree-of-freedom (6-DoF) camera\npose from query images, is fundamental to remote sensing and UAV applications.\nExisting methods face inherent trade-offs: image-based retrieval and pose\nregression approaches lack precision, while structure-based methods that\nregister queries to Structure-from-Motion (SfM) models suffer from\ncomputational complexity and limited scalability. These challenges are\nparticularly pronounced in remote sensing scenarios due to large-scale scenes,\nhigh altitude variations, and domain gaps of existing visual priors. To\novercome these limitations, we leverage 3D Gaussian Splatting (3DGS) as a novel\nscene representation that compactly encodes both 3D geometry and appearance. We\nintroduce $\\mathrm{Hi}^2$-GSLoc, a dual-hierarchical relocalization framework\nthat follows a sparse-to-dense and coarse-to-fine paradigm, fully exploiting\nthe rich semantic information and geometric constraints inherent in Gaussian\nprimitives. To handle large-scale remote sensing scenarios, we incorporate\npartitioned Gaussian training, GPU-accelerated parallel matching, and dynamic\nmemory management strategies. Our approach consists of two stages: (1) a sparse\nstage featuring a Gaussian-specific consistent render-aware sampling strategy\nand landmark-guided detector for robust and accurate initial pose estimation,\nand (2) a dense stage that iteratively refines poses through coarse-to-fine\ndense rasterization matching while incorporating reliability verification.\nThrough comprehensive evaluation on simulation data, public datasets, and real\nflight experiments, we demonstrate that our method delivers competitive\nlocalization accuracy, recall rate, and computational efficiency while\neffectively filtering unreliable pose estimates. The results confirm the\neffectiveness of our approach for practical remote sensing applications.", "comment": "17 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.15683v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15852", "title": "SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction", "authors": ["Zhixiong Zhang", "Shuangrui Ding", "Xiaoyi Dong", "Songxin He", "Jianfan Lin", "Junsong Tang", "Yuhang Zang", "Yuhang Cao", "Dahua Lin", "Jiaqi Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      project page: this https URL code: this https URL dataset: this https URL", "url": "http://arxiv.org/abs/2507.15852v1", "summary": "Video Object Segmentation (VOS) is a core task in computer vision, requiring\nmodels to track and segment target objects across video frames. Despite notable\nadvances with recent efforts, current techniques still lag behind human\ncapabilities in handling drastic visual variations, occlusions, and complex\nscene changes. This limitation arises from their reliance on appearance\nmatching, neglecting the human-like conceptual understanding of objects that\nenables robust identification across temporal dynamics. Motivated by this gap,\nwe propose Segment Concept (SeC), a concept-driven segmentation framework that\nshifts from conventional feature matching to the progressive construction and\nutilization of high-level, object-centric representations. SeC employs Large\nVision-Language Models (LVLMs) to integrate visual cues across diverse frames,\nconstructing robust conceptual priors. During inference, SeC forms a\ncomprehensive semantic representation of the target based on processed frames,\nrealizing robust segmentation of follow-up frames. Furthermore, SeC adaptively\nbalances LVLM-based semantic reasoning with enhanced feature matching,\ndynamically adjusting computational efforts based on scene complexity. To\nrigorously assess VOS methods in scenarios demanding high-level conceptual\nreasoning and robust semantic understanding, we introduce the Semantic Complex\nScenarios Video Object Segmentation benchmark (SeCVOS). SeCVOS comprises 160\nmanually annotated multi-scenario videos designed to challenge models with\nsubstantial appearance variations and dynamic scene transformations. In\nparticular, SeC achieves an 11.8-point improvement over SAM 2.1 on SeCVOS,\nestablishing a new state-of-the-art in concept-aware video object segmentation.", "comment": "project page: https://rookiexiong7.github.io/projects/SeC/; code:\n  https://github.com/OpenIXCLab/SeC; dataset:\n  https://huggingface.co/datasets/OpenIXCLab/SeCVOS", "pdf_url": "http://arxiv.org/pdf/2507.15852v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14304", "title": "Aligning Large Language Models to Low-Resource Languages through LLM-Based Selective Translation: A Systematic Study", "authors": ["Rakesh Paul", "Anusha Kamath", "Kanishk Singla", "Raviraj Joshi", "Utkarsh Vaidya", "Sanjay Singh Chauhan", "Niranjan Wartikar"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14304v1", "summary": "Multilingual large language models (LLMs) often demonstrate a performance gap\nbetween English and non-English languages, particularly in low-resource\nsettings. Aligning these models to low-resource languages is essential yet\nchallenging due to limited high-quality data. While English alignment datasets\nare readily available, curating equivalent data in other languages is expensive\nand time-consuming. A common workaround is to translate existing English\nalignment data; however, standard translation techniques often fail to preserve\ncritical elements such as code, mathematical expressions, and structured\nformats like JSON. In this work, we investigate LLM-based selective\ntranslation, a technique that selectively translates only the translatable\nparts of a text while preserving non-translatable content and sentence\nstructure. We conduct a systematic study to explore key questions around this\napproach, including its effectiveness compared to vanilla translation, the\nimportance of filtering noisy outputs, and the benefits of mixing translated\nsamples with original English data during alignment. Our experiments focus on\nthe low-resource Indic language Hindi and compare translations generated by\nGoogle Cloud Translation (GCP) and Llama-3.1-405B. The results highlight the\npromise of selective translation as a practical and effective method for\nimproving multilingual alignment in LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14304v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15709", "title": "Efficient Face Image Quality Assessment via Self-training and Knowledge Distillation", "authors": ["Wei Sun", "Weixia Zhang", "Linhan Cao", "Jun Jia", "Xiangyang Zhu", "Dandan Zhu", "Xiongkuo Min", "Guangtao Zhai"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Efficient-FIQA achieved first place in the ICCV VQualA 2025 Face Image Quality Assessment Challenge", "url": "http://arxiv.org/abs/2507.15709v1", "summary": "Face image quality assessment (FIQA) is essential for various face-related\napplications. Although FIQA has been extensively studied and achieved\nsignificant progress, the computational complexity of FIQA algorithms remains a\nkey concern for ensuring scalability and practical deployment in real-world\nsystems. In this paper, we aim to develop a computationally efficient FIQA\nmethod that can be easily deployed in real-world applications. Specifically,\nour method consists of two stages: training a powerful teacher model and\ndistilling a lightweight student model from it. To build a strong teacher\nmodel, we adopt a self-training strategy to improve its capacity. We first\ntrain the teacher model using labeled face images, then use it to generate\npseudo-labels for a set of unlabeled images. These pseudo-labeled samples are\nused in two ways: (1) to distill knowledge into the student model, and (2) to\ncombine with the original labeled images to further enhance the teacher model\nthrough self-training. The enhanced teacher model is used to further\npseudo-label another set of unlabeled images for distilling the student models.\nThe student model is trained using a combination of labeled images,\npseudo-labeled images from the original teacher model, and pseudo-labeled\nimages from the enhanced teacher model. Experimental results demonstrate that\nour student model achieves comparable performance to the teacher model with an\nextremely low computational overhead. Moreover, our method achieved first place\nin the ICCV 2025 VQualA FIQA Challenge. The code is available at\nhttps://github.com/sunwei925/Efficient-FIQA.git.", "comment": "Efficient-FIQA achieved first place in the ICCV VQualA 2025 Face\n  Image Quality Assessment Challenge", "pdf_url": "http://arxiv.org/pdf/2507.15709v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2405.11346", "title": "Decision support system for Forest fire management using Ontology with Big Data and LLMs", "authors": ["Ritesh Chandra", "Shashi Shekhar Kumar", "Rushil Patra", "Sonali Agarwal"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted", "url": "http://arxiv.org/abs/2405.11346v3", "summary": "Forests are crucial for ecological balance, but wildfires, a major cause of\nforest loss, pose significant risks. Fire weather indices, which assess\nwildfire risk and predict resource demands, are vital. With the rise of sensor\nnetworks in fields like healthcare and environmental monitoring, semantic\nsensor networks are increasingly used to gather climatic data such as wind\nspeed, temperature, and humidity. However, processing these data streams to\ndetermine fire weather indices presents challenges, underscoring the growing\nimportance of effective forest fire detection. This paper discusses using\nApache Spark for early forest fire detection, enhancing fire risk prediction\nwith meteorological and geographical data. Building on our previous development\nof Semantic Sensor Network (SSN) ontologies and Semantic Web Rules Language\n(SWRL) for managing forest fires in Monesterial Natural Park, we expanded SWRL\nto improve a Decision Support System (DSS) using a Large Language Models (LLMs)\nand Spark framework. We implemented real-time alerts with Spark streaming,\ntailored to various fire scenarios, and validated our approach using ontology\nmetrics, query-based evaluations, LLMs score precision, F1 score, and recall\nmeasures.", "comment": "Accepted", "pdf_url": "http://arxiv.org/pdf/2405.11346v3", "cate": "cs.AI", "date": "2024-05-18", "updated": "2025-07-21"}
{"id": "2507.14341", "title": "MENO: Hybrid Matrix Exponential-based Neural Operator for Stiff ODEs. Application to Thermochemical Kinetics", "authors": ["Ivan Zanardi", "Simone Venturi", "Marco Panesi"], "categories": ["physics.comp-ph", "cs.LG"], "primary_category": "Subjects:       Computational Physics (physics.comp-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14341v1", "summary": "We introduce MENO (''Matrix Exponential-based Neural Operator''), a hybrid\nsurrogate modeling framework for efficiently solving stiff systems of ordinary\ndifferential equations (ODEs) that exhibit a sparse nonlinear structure. In\nsuch systems, only a few variables contribute nonlinearly to the dynamics,\nwhile the majority influence the equations linearly. MENO exploits this\nproperty by decomposing the system into two components: the low-dimensional\nnonlinear part is modeled using conventional neural operators, while the linear\ntime-varying subsystem is integrated using a novel neural matrix exponential\nformulation. This approach combines the exact solution of linear time-invariant\nsystems with learnable, time-dependent graph-based corrections applied to the\nlinear operators. Unlike black-box or soft-constrained physics-informed (PI)\nmodels, MENO embeds the governing equations directly into its architecture,\nensuring physical consistency (e.g., steady states), improved robustness, and\nmore efficient training. We validate MENO on three complex thermochemical\nsystems: the POLLU atmospheric chemistry model, an oxygen mixture in\nthermochemical nonequilibrium, and a collisional-radiative argon plasma in one-\nand two-dimensional shock-tube simulations. MENO achieves relative errors below\n2% in trained zero-dimensional settings and maintains good accuracy in\nextrapolatory multidimensional regimes. It also delivers substantial\ncomputational speedups, achieving up to 4 800$\\times$ on GPU and 185$\\times$ on\nCPU compared to standard implicit ODE solvers. Although intrusive by design,\nMENO's physics-based architecture enables superior generalization and\nreliability, offering a scalable path for real-time simulation of stiff\nreactive systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14341v1", "cate": "physics.comp-ph", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.15724", "title": "A Practical Investigation of Spatially-Controlled Image Generation with Transformers", "authors": ["Guoxuan Xia", "Harleen Hanspal", "Petru-Daniel Tudosiu", "Shifeng Zhang", "Sarah Parisot"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      preprint", "url": "http://arxiv.org/abs/2507.15724v1", "summary": "Enabling image generation models to be spatially controlled is an important\narea of research, empowering users to better generate images according to their\nown fine-grained specifications via e.g. edge maps, poses. Although this task\nhas seen impressive improvements in recent times, a focus on rapidly producing\nstronger models has come at the cost of detailed and fair scientific\ncomparison. Differing training data, model architectures and generation\nparadigms make it difficult to disentangle the factors contributing to\nperformance. Meanwhile, the motivations and nuances of certain approaches\nbecome lost in the literature. In this work, we aim to provide clear takeaways\nacross generation paradigms for practitioners wishing to develop\ntransformer-based systems for spatially-controlled generation, clarifying the\nliterature and addressing knowledge gaps. We perform controlled experiments on\nImageNet across diffusion-based/flow-based and autoregressive (AR) models.\nFirst, we establish control token prefilling as a simple, general and\nperformant baseline approach for transformers. We then investigate previously\nunderexplored sampling time enhancements, showing that extending\nclassifier-free guidance to control, as well as softmax truncation, have a\nstrong impact on control-generation consistency. Finally, we re-clarify the\nmotivation of adapter-based approaches, demonstrating that they mitigate\n\"forgetting\" and maintain generation quality when trained on limited downstream\ndata, but underperform full training in terms of generation-control\nconsistency. Code will be released upon publication.", "comment": "preprint", "pdf_url": "http://arxiv.org/pdf/2507.15724v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2407.01511", "title": "CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents", "authors": ["Tianqi Xu", "Linyao Chen", "Dai-Jie Wu", "Yanjun Chen", "Zecheng Zhang", "Xiang Yao", "Zhiqiang Xie", "Yongchao Chen", "Shilong Liu", "Bochen Qian", "Anjie Yang", "Zhaoxuan Jin", "Jianbo Deng", "Philip Torr", "Bernard Ghanem", "Guohao Li"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      2025 ACL Findings", "url": "http://arxiv.org/abs/2407.01511v4", "summary": "The development of autonomous agents increasingly relies on Multimodal\nLanguage Models (MLMs) to perform tasks described in natural language with GUI\nenvironments, such as websites, desktop computers, or mobile phones. Existing\nbenchmarks for MLM agents in interactive environments are limited by their\nfocus on a single environment, lack of detailed and generalized evaluation\nmethods, and the complexities of constructing tasks and evaluators. To overcome\nthese limitations, we introduce Crab, the first agent benchmark framework\ndesigned to support cross-environment tasks, incorporating a graph-based\nfine-grained evaluation method and an efficient mechanism for task and\nevaluator construction. Our framework supports multiple devices and can be\neasily extended to any environment with a Python interface. Leveraging Crab, we\ndeveloped a cross-platform Crab Benchmark-v0 comprising 120 tasks in computer\ndesktop and mobile phone environments. We evaluated four advanced MLMs using\ndifferent single and multi-agent system configurations on this benchmark. The\nexperimental results demonstrate that the single agent with GPT-4o achieves the\nbest completion ratio of 38.01%. All framework code, agent code, and task\ndatasets are publicly available at https://github.com/camel-ai/crab.", "comment": "2025 ACL Findings", "pdf_url": "http://arxiv.org/pdf/2407.01511v4", "cate": "cs.AI", "date": "2024-07-01", "updated": "2025-07-20"}
{"id": "2507.14467", "title": "Learning Stochastic Hamiltonian Systems via Stochastic Generating Function Neural Network", "authors": ["Chen Chen", "Lijin Wang", "Yanzhao Cao", "Xupeng Cheng"], "categories": ["math.DS", "cs.LG"], "primary_category": "Subjects:       Dynamical Systems (math.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14467v1", "summary": "In this paper we propose a novel neural network model for learning stochastic\nHamiltonian systems (SHSs) from observational data, termed the stochastic\ngenerating function neural network (SGFNN). SGFNN preserves symplectic\nstructure of the underlying stochastic Hamiltonian system and produces\nsymplectic predictions. Our model utilizes the autoencoder framework to\nidentify the randomness of the latent system by the encoder network, and\ndetects the stochastic generating function of the system through the decoder\nnetwork based on the random variables extracted from the encoder. Symplectic\npredictions can then be generated by the stochastic generating function.\nNumerical experiments are performed on several stochastic Hamiltonian systems,\nvarying from additive to multiplicative, and from separable to non-separable\nSHSs with single or multiple noises. Compared with the benchmark stochastic\nflow map learning (sFML) neural network, our SGFNN model exhibits higher\naccuracy across various prediction metrics, especially in long-term\npredictions, with the property of maintaining the symplectic structure of the\nunderlying SHSs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14467v1", "cate": "math.DS", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15728", "title": "TokensGen: Harnessing Condensed Tokens for Long Video Generation", "authors": ["Wenqi Ouyang", "Zeqi Xiao", "Danni Yang", "Yifan Zhou", "Shuai Yang", "Lei Yang", "Jianlou Si", "Xingang Pan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2507.15728v1", "summary": "Generating consistent long videos is a complex challenge: while\ndiffusion-based generative models generate visually impressive short clips,\nextending them to longer durations often leads to memory bottlenecks and\nlong-term inconsistency. In this paper, we propose TokensGen, a novel two-stage\nframework that leverages condensed tokens to address these issues. Our method\ndecomposes long video generation into three core tasks: (1) inner-clip semantic\ncontrol, (2) long-term consistency control, and (3) inter-clip smooth\ntransition. First, we train To2V (Token-to-Video), a short video diffusion\nmodel guided by text and video tokens, with a Video Tokenizer that condenses\nshort clips into semantically rich tokens. Second, we introduce T2To\n(Text-to-Token), a video token diffusion transformer that generates all tokens\nat once, ensuring global consistency across clips. Finally, during inference,\nan adaptive FIFO-Diffusion strategy seamlessly connects adjacent clips,\nreducing boundary artifacts and enhancing smooth transitions. Experimental\nresults demonstrate that our approach significantly enhances long-term temporal\nand content coherence without incurring prohibitive computational overhead. By\nleveraging condensed tokens and pre-trained short video models, our method\nprovides a scalable, modular solution for long video generation, opening new\npossibilities for storytelling, cinematic production, and immersive\nsimulations. Please see our project page at\nhttps://vicky0522.github.io/tokensgen-webpage/ .", "comment": "Project page: https://vicky0522.github.io/tokensgen-webpage/", "pdf_url": "http://arxiv.org/pdf/2507.15728v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2410.16543", "title": "Large Language Models Powered Multiagent Ensemble for Mitigating Hallucination and Efficient Atrial Fibrillation Annotation of ECG Reports", "authors": ["Jingwei Huang", "Kuroush Nezafati", "Ismael Villanueva-Miranda", "Zifan Gu", "Yueshuang Xu", "Ann Marie Navar", "Tingyi Wanyan", "Qin Zhou", "Bo Yao", "Ruichen Rong", "Xiaowei Zhan", "Guanghua Xiao", "Eric D. Peterson", "Donghan M. Yang", "Wenqi Shi", "Yang Xie"], "categories": ["cs.AI", "I.2"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      36 pages, 12 figures and 1 table", "url": "http://arxiv.org/abs/2410.16543v3", "summary": "This study introduces a LLMs powered multiagent ensemble method to address\nchallenges in hallucination and data labeling, particularly in large-scale EHR\ndatasets. Manual labeling of such datasets requires domain expertise and is\nlabor-intensive, time-consuming, expensive, and error-prone. To overcome this\nbottleneck, we developed an ensemble LLMs method and demonstrated its\neffectiveness in two real-world tasks: (1) labeling a large-scale unlabeled ECG\ndataset in MIMIC-IV; (2) identifying social determinants of health (SDOH) from\nthe clinical notes of EHR. Trading off benefits and cost, we selected a pool of\ndiverse open source LLMs with satisfactory performance. We treat each LLM's\nprediction as a vote and apply a mechanism of majority voting with minimal\nwinning threshold for ensemble. We implemented an ensemble LLMs application for\nEHR data labeling tasks. By using the ensemble LLMs and natural language\nprocessing, we labeled MIMIC-IV ECG dataset of 623,566 ECG reports with an\nestimated accuracy of 98.2%. We applied the ensemble LLMs method to identify\nSDOH from social history sections of 1,405 EHR clinical notes, also achieving\ncompetitive performance. Our experiments show that the ensemble LLMs can\noutperform individual LLM even the best commercial one, and the method reduces\nhallucination errors. From the research, we found that (1) the ensemble LLMs\nmethod significantly reduces the time and effort required for labeling\nlarge-scale EHR data, automating the process with high accuracy and quality;\n(2) the method generalizes well to other text data labeling tasks, as shown by\nits application to SDOH identification; (3) the ensemble of a group of diverse\nLLMs can outperform or match the performance of the best individual LLM; and\n(4) the ensemble method substantially reduces hallucination errors. This\napproach provides a scalable and efficient solution to data-labeling\nchallenges.", "comment": "36 pages, 12 figures and 1 table", "pdf_url": "http://arxiv.org/pdf/2410.16543v3", "cate": "cs.AI", "date": "2024-10-21", "updated": "2025-07-18"}
{"id": "2507.14639", "title": "KinForm: Kinetics Informed Feature Optimised Representation Models for Enzyme $k_{cat}$ and $K_{M}$ Prediction", "authors": ["Saleh Alwer", "Ronan Fleming"], "categories": ["q-bio.QM", "cs.LG"], "primary_category": "Subjects:       Quantitative Methods (q-bio.QM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14639v1", "summary": "Kinetic parameters such as the turnover number ($k_{cat}$) and Michaelis\nconstant ($K_{\\mathrm{M}}$) are essential for modelling enzymatic activity but\nexperimental data remains limited in scale and diversity. Previous methods for\npredicting enzyme kinetics typically use mean-pooled residue embeddings from a\nsingle protein language model to represent the protein. We present KinForm, a\nmachine learning framework designed to improve predictive accuracy and\ngeneralisation for kinetic parameters by optimising protein feature\nrepresentations. KinForm combines several residue-level embeddings\n(Evolutionary Scale Modeling Cambrian, Evolutionary Scale Modeling 2, and\nProtT5-XL-UniRef50), taken from empirically selected intermediate transformer\nlayers and applies weighted pooling based on per-residue binding-site\nprobability. To counter the resulting high dimensionality, we apply\ndimensionality reduction using principal--component analysis (PCA) on\nconcatenated protein features, and rebalance the training data via a\nsimilarity-based oversampling strategy. KinForm outperforms baseline methods on\ntwo benchmark datasets. Improvements are most pronounced in low sequence\nsimilarity bins. We observe improvements from binding-site probability pooling,\nintermediate-layer selection, PCA, and oversampling of low-identity proteins.\nWe also find that removing sequence overlap between folds provides a more\nrealistic evaluation of generalisation and should be the standard over random\nsplitting when benchmarking kinetic prediction models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14639v1", "cate": "q-bio.QM", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15748", "title": "Appearance Harmonization via Bilateral Grid Prediction with Transformers for 3DGS", "authors": ["Jisu Shin", "Richard Shaw", "Seunghyun Shin", "Anton Pelykh", "Zhensong Zhang", "Hae-Gon Jeon", "Eduardo Perez-Pellitero"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 3 figures, NeurIPS 2025 under review", "url": "http://arxiv.org/abs/2507.15748v1", "summary": "Modern camera pipelines apply extensive on-device processing, such as\nexposure adjustment, white balance, and color correction, which, while\nbeneficial individually, often introduce photometric inconsistencies across\nviews. These appearance variations violate multi-view consistency and degrade\nthe quality of novel view synthesis. Joint optimization of scene\nrepresentations and per-image appearance embeddings has been proposed to\naddress this issue, but at the cost of increased computational complexity and\nslower training. In this work, we propose a transformer-based method that\npredicts spatially adaptive bilateral grids to correct photometric variations\nin a multi-view consistent manner, enabling robust cross-scene generalization\nwithout the need for scene-specific retraining. By incorporating the learned\ngrids into the 3D Gaussian Splatting pipeline, we improve reconstruction\nquality while maintaining high training efficiency. Extensive experiments show\nthat our approach outperforms or matches existing scene-specific optimization\nmethods in reconstruction fidelity and convergence speed.", "comment": "10 pages, 3 figures, NeurIPS 2025 under review", "pdf_url": "http://arxiv.org/pdf/2507.15748v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2502.00409", "title": "Doing More with Less: A Survey on Routing Strategies for Resource Optimisation in Large Language Model-Based Systems", "authors": ["Clovis Varangot-Reille", "Christophe Bouvard", "Antoine Gourru", "Mathieu Ciancone", "Marion Schaeffer", "François Jacquenet"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.00409v3", "summary": "Large Language Model (LLM)-based systems, i.e. interconnected elements that\ninclude an LLM as a central component, such as conversational agents, are\nusually designed with monolithic, static architectures that rely on a single,\ngeneral-purpose LLM to handle all user queries. However, these systems may be\ninefficient as different queries may require different levels of reasoning,\ndomain knowledge or pre-processing. While generalist LLMs (e.g. GPT-4o,\nClaude-Sonnet) perform well across a wide range of tasks, they may incur\nsignificant financial, energy and computational costs. These costs may be\ndisproportionate for simpler queries, resulting in unnecessary resource\nutilisation. A routing mechanism can therefore be employed to route queries to\nmore appropriate components, such as smaller or specialised models, thereby\nimproving efficiency and optimising resource consumption. This survey aims to\nprovide a comprehensive overview of routing strategies in LLM-based systems.\nSpecifically, it reviews when, why, and how routing should be integrated into\nLLM pipelines to improve efficiency, scalability, and performance. We define\nthe objectives to optimise, such as cost minimisation and performance\nmaximisation, and discuss the timing of routing within the LLM workflow,\nwhether it occurs before or after generation. We also detail the various\nimplementation strategies, including similarity-based, supervised,\nreinforcement learning-based, and generative methods. Practical considerations\nsuch as industrial applications and current limitations are also examined, like\nstandardising routing experiments, accounting for non-financial costs, and\ndesigning adaptive strategies. By formalising routing as a performance-cost\noptimisation problem, this survey provides tools and directions to guide future\nresearch and development of adaptive low-cost LLM-based systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.00409v3", "cate": "cs.AI", "date": "2025-02-01", "updated": "2025-07-21"}
{"id": "2507.14641", "title": "Deep Learning-Based Survival Analysis with Copula-Based Activation Functions for Multivariate Response Prediction", "authors": ["Jong-Min Kim", "Il Do Ha", "Sangjin Kim"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14641v1", "summary": "This research integrates deep learning, copula functions, and survival\nanalysis to effectively handle highly correlated and right-censored\nmultivariate survival data. It introduces copula-based activation functions\n(Clayton, Gumbel, and their combinations) to model the nonlinear dependencies\ninherent in such data. Through simulation studies and analysis of real breast\ncancer data, our proposed CNN-LSTM with copula-based activation functions for\nmultivariate multi-types of survival responses enhances prediction accuracy by\nexplicitly addressing right-censored data and capturing complex patterns. The\nmodel's performance is evaluated using Shewhart control charts, focusing on the\naverage run length (ARL).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14641v1", "cate": "stat.ML", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15765", "title": "Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization", "authors": ["Feng-Qi Cui", "Anyang Tong", "Jinyang Huang", "Jie Zhang", "Dan Guo", "Zhi Liu", "Meng Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ACM MM'25", "url": "http://arxiv.org/abs/2507.15765v1", "summary": "Dynamic Facial Expression Recognition (DFER) plays a critical role in\naffective computing and human-computer interaction. Although existing methods\nachieve comparable performance, they inevitably suffer from performance\ndegradation under sample heterogeneity caused by multi-source data and\nindividual expression variability. To address these challenges, we propose a\nnovel framework, called Heterogeneity-aware Distributional Framework (HDF), and\ndesign two plug-and-play modules to enhance time-frequency modeling and\nmitigate optimization imbalance caused by hard samples. Specifically, the\nTime-Frequency Distributional Attention Module (DAM) captures both temporal\nconsistency and frequency robustness through a dual-branch attention design,\nimproving tolerance to sequence inconsistency and visual style shifts. Then,\nbased on gradient sensitivity and information bottleneck principles, an\nadaptive optimization module Distribution-aware Scaling Module (DSM) is\nintroduced to dynamically balance classification and contrastive losses,\nenabling more stable and discriminative representation learning. Extensive\nexperiments on two widely used datasets, DFEW and FERV39k, demonstrate that HDF\nsignificantly improves both recognition accuracy and robustness. Our method\nachieves superior weighted average recall (WAR) and unweighted average recall\n(UAR) while maintaining strong generalization across diverse and imbalanced\nscenarios. Codes are released at https://github.com/QIcita/HDF_DFER.", "comment": "Accepted by ACM MM'25", "pdf_url": "http://arxiv.org/pdf/2507.15765v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2502.02180", "title": "The Elicitation Game: Evaluating Capability Elicitation Techniques", "authors": ["Felix Hofstätter", "Teun van der Weij", "Jayden Teoh", "Rada Djoneva", "Henning Bartsch", "Francis Rhys Ward"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.02180v3", "summary": "Capability evaluations are required to understand and regulate AI systems\nthat may be deployed or further developed. Therefore, it is important that\nevaluations provide an accurate estimation of an AI system's capabilities.\nHowever, in numerous cases, previously latent capabilities have been elicited\nfrom models, sometimes long after initial release. Accordingly, substantial\nefforts have been made to develop methods for eliciting latent capabilities\nfrom models. In this paper, we evaluate the effectiveness of capability\nelicitation techniques by intentionally training model organisms -- language\nmodels with hidden capabilities that are revealed by a password. We introduce a\nnovel method for training model organisms, based on circuit-breaking, which is\nmore robust to elicitation techniques than standard password-locked models. We\nfocus on elicitation techniques based on prompting and activation steering, and\ncompare these to fine-tuning methods. Prompting techniques can elicit the\nactual capability of both password-locked and circuit-broken model organisms in\nthe MCQA setting, while steering fails to do so. For a code-generation task,\nonly fine-tuning can elicit the hidden capabilities of our novel model\norganism. Additionally, our results suggest that combining techniques improves\nelicitation. Still, if possible, fine-tuning should be the method of choice to\nimprove the trustworthiness of capability evaluations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.02180v3", "cate": "cs.AI", "date": "2025-02-04", "updated": "2025-07-18"}
{"id": "2507.14661", "title": "When few labeled target data suffice: a theory of semi-supervised domain adaptation via fine-tuning from multiple adaptive starts", "authors": ["Wooseok Ha", "Yuansi Chen"], "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14661v1", "summary": "Semi-supervised domain adaptation (SSDA) aims to achieve high predictive\nperformance in the target domain with limited labeled target data by exploiting\nabundant source and unlabeled target data. Despite its significance in numerous\napplications, theory on the effectiveness of SSDA remains largely unexplored,\nparticularly in scenarios involving various types of source-target\ndistributional shifts. In this work, we develop a theoretical framework based\non structural causal models (SCMs) which allows us to analyze and quantify the\nperformance of SSDA methods when labeled target data is limited. Within this\nframework, we introduce three SSDA methods, each having a fine-tuning strategy\ntailored to a distinct assumption about the source and target relationship.\nUnder each assumption, we demonstrate how extending an unsupervised domain\nadaptation (UDA) method to SSDA can achieve minimax-optimal target performance\nwith limited target labels. When the relationship between source and target\ndata is only vaguely known -- a common practical concern -- we propose the\nMulti Adaptive-Start Fine-Tuning (MASFT) algorithm, which fine-tunes UDA models\nfrom multiple starting points and selects the best-performing one based on a\nsmall hold-out target validation dataset. Combined with model selection\nguarantees, MASFT achieves near-optimal target predictive performance across a\nbroad range of types of distributional shifts while significantly reducing the\nneed for labeled target data. We empirically validate the effectiveness of our\nproposed methods through simulations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14661v1", "cate": "stat.ML", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.15777", "title": "Label tree semantic losses for rich multi-class medical image segmentation", "authors": ["Junwen Wang", "Oscar MacCormac", "William Rochford", "Aaron Kujawa", "Jonathan Shapey", "Tom Vercauteren"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2506.21150", "url": "http://arxiv.org/abs/2507.15777v1", "summary": "Rich and accurate medical image segmentation is poised to underpin the next\ngeneration of AI-defined clinical practice by delineating critical anatomy for\npre-operative planning, guiding real-time intra-operative navigation, and\nsupporting precise post-operative assessment. However, commonly used learning\nmethods for medical and surgical imaging segmentation tasks penalise all errors\nequivalently and thus fail to exploit any inter-class semantics in the labels\nspace. This becomes particularly problematic as the cardinality and richness of\nlabels increases to include subtly different classes. In this work, we propose\ntwo tree-based semantic loss functions which take advantage of a hierarchical\norganisation of the labels. We further incorporate our losses in a recently\nproposed approach for training with sparse, background-free annotations to\nextend the applicability of our proposed losses. Extensive experiments are\nreported on two medical and surgical image segmentation tasks, namely head MRI\nfor whole brain parcellation (WBP) with full supervision and neurosurgical\nhyperspectral imaging (HSI) for scene understanding with sparse annotations.\nResults demonstrate that our proposed method reaches state-of-the-art\nperformance in both cases.", "comment": "arXiv admin note: text overlap with arXiv:2506.21150", "pdf_url": "http://arxiv.org/pdf/2507.15777v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2502.15652", "title": "Empowering LLMs with Logical Reasoning: A Comprehensive Survey", "authors": ["Fengxiang Cheng", "Haoxuan Li", "Fenrong Liu", "Robert van Rooij", "Kun Zhang", "Zhouchen Lin"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by IJCAI 2025 (Survey Track)", "url": "http://arxiv.org/abs/2502.15652v4", "summary": "Large language models (LLMs) have achieved remarkable successes on various\ntasks. However, recent studies have found that there are still significant\nchallenges to the logical reasoning abilities of LLMs, which can be categorized\ninto the following two aspects: (1) Logical question answering: LLMs often fail\nto generate the correct answer within a complex logical problem which requires\nsophisticated deductive, inductive or abductive reasoning given a collection of\npremises. (2) Logical consistency: LLMs are prone to producing responses\ncontradicting themselves across different questions. For example, a\nstate-of-the-art question-answering LLM Macaw, answers Yes to both questions Is\na magpie a bird? and Does a bird have wings? but answers No to Does a magpie\nhave wings?. To facilitate this research direction, we comprehensively\ninvestigate the most cutting-edge methods and propose a detailed taxonomy.\nSpecifically, to accurately answer complex logic questions, previous methods\ncan be categorized based on reliance on external solvers, prompts, and\nfine-tuning. To avoid logical contradictions, we discuss concepts and solutions\nof various logical consistencies, including implication, negation,\ntransitivity, factuality consistencies, and their composites. In addition, we\nreview commonly used benchmark datasets and evaluation metrics, and discuss\npromising research directions, such as extending to modal logic to account for\nuncertainty and developing efficient algorithms that simultaneously satisfy\nmultiple logical consistencies.", "comment": "Accepted by IJCAI 2025 (Survey Track)", "pdf_url": "http://arxiv.org/pdf/2502.15652v4", "cate": "cs.AI", "date": "2025-02-21", "updated": "2025-07-21"}
{"id": "2507.14782", "title": "Uncertainty Quantification for Machine Learning-Based Prediction: A Polynomial Chaos Expansion Approach for Joint Model and Input Uncertainty Propagation", "authors": ["Xiaoping Du"], "categories": ["stat.ML", "cs.LG", "math-ph", "math.MP", "stat.CO"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      This manuscript has been submitted to Multidisciplinary and Structural Optimization", "url": "http://arxiv.org/abs/2507.14782v1", "summary": "Machine learning (ML) surrogate models are increasingly used in engineering\nanalysis and design to replace computationally expensive simulation models,\nsignificantly reducing computational cost and accelerating decision-making\nprocesses. However, ML predictions contain inherent errors, often estimated as\nmodel uncertainty, which is coupled with variability in model inputs.\nAccurately quantifying and propagating these combined uncertainties is\nessential for generating reliable engineering predictions. This paper presents\na robust framework based on Polynomial Chaos Expansion (PCE) to handle joint\ninput and model uncertainty propagation. While the approach applies broadly to\ngeneral ML surrogates, we focus on Gaussian Process regression models, which\nprovide explicit predictive distributions for model uncertainty. By\ntransforming all random inputs into a unified standard space, a PCE surrogate\nmodel is constructed, allowing efficient and accurate calculation of the mean\nand standard deviation of the output. The proposed methodology also offers a\nmechanism for global sensitivity analysis, enabling the accurate quantification\nof the individual contributions of input variables and ML model uncertainty to\nthe overall output variability. This approach provides a computationally\nefficient and interpretable framework for comprehensive uncertainty\nquantification, supporting trustworthy ML predictions in downstream engineering\napplications.", "comment": "This manuscript has been submitted to Multidisciplinary and\n  Structural Optimization", "pdf_url": "http://arxiv.org/pdf/2507.14782v1", "cate": "stat.ML", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15793", "title": "Regularized Low-Rank Adaptation for Few-Shot Organ Segmentation", "authors": ["Ghassen Baklouti", "Julio Silva-Rodríguez", "Jose Dolz", "Houda Bahig", "Ismail Ben Ayed"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at MICCAI 2025", "url": "http://arxiv.org/abs/2507.15793v1", "summary": "Parameter-efficient fine-tuning (PEFT) of pre-trained foundation models is\nincreasingly attracting interest in medical imaging due to its effectiveness\nand computational efficiency. Among these methods, Low-Rank Adaptation (LoRA)\nis a notable approach based on the assumption that the adaptation inherently\noccurs in a low-dimensional subspace. While it has shown good performance, its\nimplementation requires a fixed and unalterable rank, which might be\nchallenging to select given the unique complexities and requirements of each\nmedical imaging downstream task. Inspired by advancements in natural image\nprocessing, we introduce a novel approach for medical image segmentation that\ndynamically adjusts the intrinsic rank during adaptation. Viewing the low-rank\nrepresentation of the trainable weight matrices as a singular value\ndecomposition, we introduce an l_1 sparsity regularizer to the loss function,\nand tackle it with a proximal optimizer. The regularizer could be viewed as a\npenalty on the decomposition rank. Hence, its minimization enables to find\ntask-adapted ranks automatically. Our method is evaluated in a realistic\nfew-shot fine-tuning setting, where we compare it first to the standard LoRA\nand then to several other PEFT methods across two distinguishable tasks: base\norgans and novel organs. Our extensive experiments demonstrate the significant\nperformance improvements driven by our method, highlighting its efficiency and\nrobustness against suboptimal rank initialization. Our code is publicly\navailable: https://github.com/ghassenbaklouti/ARENA", "comment": "Accepted at MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.15793v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2503.16348", "title": "Palatable Conceptions of Disembodied Being", "authors": ["Murray Shanahan"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.16348v3", "summary": "Is it possible to articulate a conception of consciousness that is compatible\nwith the exotic characteristics of contemporary, disembodied AI systems, and\nthat can stand up to philosophical scrutiny? How would subjective time and\nselfhood show up for an entity that conformed to such a conception? Trying to\nanswer these questions, even metaphorically, stretches the language of\nconsciousness to breaking point. Ultimately, the attempt yields something like\nemptiness, in the Buddhist sense, and helps to undermine our dualistic\ninclinations towards subjectivity and selfhood.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.16348v3", "cate": "cs.AI", "date": "2025-03-20", "updated": "2025-07-20"}
{"id": "2507.15021", "title": "Integrating Newton's Laws with deep learning for enhanced physics-informed compound flood modelling", "authors": ["Soheil Radfar", "Faezeh Maghsoodifar", "Hamed Moftakhari", "Hamid Moradkhani"], "categories": ["physics.geo-ph", "cs.LG"], "primary_category": "Subjects:       Geophysics (physics.geo-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15021v1", "summary": "Coastal communities increasingly face compound floods, where multiple drivers\nlike storm surge, high tide, heavy rainfall, and river discharge occur together\nor in sequence to produce impacts far greater than any single driver alone.\nTraditional hydrodynamic models can provide accurate physics-based simulations\nbut require substantial computational resources for real-time applications or\nrisk assessments, while machine learning alternatives often sacrifice physical\nconsistency for speed, producing unrealistic predictions during extreme events.\nThis study addresses these challenges by developing ALPINE (All-in-one Physics\nInformed Neural Emulator), a physics-informed neural network (PINN) framework\nto enforce complete shallow water dynamics in compound flood modeling. Unlike\nprevious approaches that implement partial constraints, our framework\nsimultaneously enforces mass conservation and both momentum equations, ensuring\nfull adherence to Newton's laws throughout the prediction process. The model\nintegrates a convolutional encoder-decoder architecture with ConvLSTM temporal\nprocessing, trained using a composite loss function that balances data fidelity\nwith physics-based residuals. Using six historical storm events (four for\ntraining, one for validation, and one held-out for unseen testing), we observe\nsubstantial improvements over baseline neural networks. ALPINE reduces\ndomain-averaged prediction errors and improves model skill metrics for water\nsurface elevation and velocity components. Physics-informed constraints prove\nmost valuable during peak storm intensity, when multiple flood drivers interact\nand reliable predictions matter most. This approach yields a physically\nconsistent emulator capable of supporting compound-flood forecasting and\nlarge-scale risk analyses while preserving physical realism essential for\ncoastal emergency management.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15021v1", "cate": "physics.geo-ph", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15798", "title": "Exploring Superposition and Interference in State-of-the-Art Low-Parameter Vision Models", "authors": ["Lilian Hollard", "Lucas Mohimont", "Nathalie Gaveau", "Luiz-Angelo Steffenel"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15798v1", "summary": "The paper investigates the performance of state-of-the-art low-parameter deep\nneural networks for computer vision, focusing on bottleneck architectures and\ntheir behavior using superlinear activation functions. We address interference\nin feature maps, a phenomenon associated with superposition, where neurons\nsimultaneously encode multiple characteristics. Our research suggests that\nlimiting interference can enhance scaling and accuracy in very low-scaled\nnetworks (under 1.5M parameters). We identify key design elements that reduce\ninterference by examining various bottleneck architectures, leading to a more\nefficient neural network. Consequently, we propose a proof-of-concept\narchitecture named NoDepth Bottleneck built on mechanistic insights from our\nexperiments, demonstrating robust scaling accuracy on the ImageNet dataset.\nThese findings contribute to more efficient and scalable neural networks for\nthe low-parameter range and advance the understanding of bottlenecks in\ncomputer vision. https://caiac.pubpub.org/pub/3dh6rsel", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15798v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2504.11704", "title": "A Library of LLM Intrinsics for Retrieval-Augmented Generation", "authors": ["Marina Danilevsky", "Kristjan Greenewald", "Chulaka Gunasekara", "Maeda Hanafi", "Lihong He", "Yannis Katsis", "Krishnateja Killamsetty", "Yulong Li", "Yatin Nandwani", "Lucian Popa", "Dinesh Raghu", "Frederick Reiss", "Vraj Shah", "Khoi-Nguyen Tran", "Huaiyu Zhu", "Luis Lastras"], "categories": ["cs.AI", "I.2.7"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      This (June 2025) is the second version of this paper (the first was published in April 2025). Intrinsics implemented as LoRAs are now trained on IBM Granite 3.3 8b instruct (previously 3.2)", "url": "http://arxiv.org/abs/2504.11704v2", "summary": "In the developer community for large language models (LLMs), there is not yet\na clean pattern analogous to a software library, to support very large scale\ncollaboration. Even for the commonplace use case of Retrieval-Augmented\nGeneration (RAG), it is not currently possible to write a RAG application\nagainst a well-defined set of APIs that are agreed upon by different LLM\nproviders. Inspired by the idea of compiler intrinsics, we propose some\nelements of such a concept through introducing a library of LLM Intrinsics for\nRAG. An LLM intrinsic is defined as a capability that can be invoked through a\nwell-defined API that is reasonably stable and independent of how the LLM\nintrinsic itself is implemented. The intrinsics in our library are released as\nLoRA adapters on HuggingFace, and through a software interface with clear\nstructured input/output characteristics on top of vLLM as an inference\nplatform, accompanied in both places with documentation and code. This article\ndescribes the intended usage, training details, and evaluations for each\nintrinsic, as well as compositions of multiple intrinsics.", "comment": "This (June 2025) is the second version of this paper (the first was\n  published in April 2025). Intrinsics implemented as LoRAs are now trained on\n  IBM Granite 3.3 8b instruct (previously 3.2)", "pdf_url": "http://arxiv.org/pdf/2504.11704v2", "cate": "cs.AI", "date": "2025-04-16", "updated": "2025-07-20"}
{"id": "2507.15084", "title": "Simulation-Prior Independent Neural Unfolding Procedure", "authors": ["Anja Butter", "Theo Heimel", "Nathan Huetsch", "Michael Kagan", "Tilman Plehn"], "categories": ["hep-ph", "cs.LG", "hep-ex"], "primary_category": "Subjects:       High Energy Physics - Phenomenology (hep-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15084v1", "summary": "Machine learning allows unfolding high-dimensional spaces without binning at\nthe LHC. The new SPINUP method extracts the unfolded distribution based on a\nneural network encoding the forward mapping, making it independent of the prior\nfrom the simulated training data. It is made efficient through neural\nimportance sampling, and ensembling can be used to estimate the effect of\ninformation loss in the forward process. We showcase SPINUP for unfolding\ndetector effects on jet substructure observables and for unfolding to parton\nlevel of associated Higgs and single-top production.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15084v1", "cate": "hep-ph", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15809", "title": "Diffusion models for multivariate subsurface generation and efficient probabilistic inversion", "authors": ["Roberto Miele", "Niklas Linde"], "categories": ["cs.CV", "cs.LG", "physics.geo-ph", "stat.AP"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15809v1", "summary": "Diffusion models offer stable training and state-of-the-art performance for\ndeep generative modeling tasks. Here, we consider their use in the context of\nmultivariate subsurface modeling and probabilistic inversion. We first\ndemonstrate that diffusion models enhance multivariate modeling capabilities\ncompared to variational autoencoders and generative adversarial networks. In\ndiffusion modeling, the generative process involves a comparatively large\nnumber of time steps with update rules that can be modified to account for\nconditioning data. We propose different corrections to the popular Diffusion\nPosterior Sampling approach by Chung et al. (2023). In particular, we introduce\na likelihood approximation accounting for the noise-contamination that is\ninherent in diffusion modeling. We assess performance in a multivariate\ngeological scenario involving facies and correlated acoustic impedance.\nConditional modeling is demonstrated using both local hard data (well logs) and\nnonlinear geophysics (fullstack seismic data). Our tests show significantly\nimproved statistical robustness, enhanced sampling of the posterior probability\ndensity function and reduced computational costs, compared to the original\napproach. The method can be used with both hard and indirect conditioning data,\nindividually or simultaneously. As the inversion is included within the\ndiffusion process, it is faster than other methods requiring an outer-loop\naround the generative model, such as Markov chain Monte Carlo.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15809v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2504.18765", "title": "A Vision for Auto Research with LLM Agents", "authors": ["Chengwei Liu", "Chong Wang", "Jiayue Cao", "Jingquan Ge", "Kun Wang", "Lyuye Zhang", "Ming-Ming Cheng", "Penghai Zhao", "Tianlin Li", "Xiaojun Jia", "Xiang Li", "Xingshuai Li", "Yang Liu", "Yebo Feng", "Yihao Huang", "Yijia Xu", "Yuqiang Sun", "Zhenhong Zhou", "Zhengzi Xu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.18765v3", "summary": "This paper introduces Agent-Based Auto Research, a structured multi-agent\nframework designed to automate, coordinate, and optimize the full lifecycle of\nscientific research. Leveraging the capabilities of large language models\n(LLMs) and modular agent collaboration, the system spans all major research\nphases, including literature review, ideation, methodology planning,\nexperimentation, paper writing, peer review response, and dissemination. By\naddressing issues such as fragmented workflows, uneven methodological\nexpertise, and cognitive overload, the framework offers a systematic and\nscalable approach to scientific inquiry. Preliminary explorations demonstrate\nthe feasibility and potential of Auto Research as a promising paradigm for\nself-improving, AI-driven research processes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.18765v3", "cate": "cs.AI", "date": "2025-04-26", "updated": "2025-07-19"}
{"id": "2507.15097", "title": "Learning under Latent Group Sparsity via Diffusion on Networks", "authors": ["Subhroshekhar Ghosh", "Soumendu Sundar Mukherjee"], "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      49 pages, 4 figures, 2 tables; this submission subsumes the earlier preprint arXiv:2201.08326", "url": "http://arxiv.org/abs/2507.15097v1", "summary": "Group or cluster structure on explanatory variables in machine learning\nproblems is a very general phenomenon, which has attracted broad interest from\npractitioners and theoreticians alike. In this work we contribute an approach\nto sparse learning under such group structure, that does not require prior\ninformation on the group identities. Our paradigm is motivated by the Laplacian\ngeometry of an underlying network with a related community structure, and\nproceeds by directly incorporating this into a penalty that is effectively\ncomputed via a heat-flow-based local network dynamics. The proposed penalty\ninterpolates between the lasso and the group lasso penalties, the runtime of\nthe heat-flow dynamics being the interpolating parameter. As such it can\nautomatically default to lasso when the group structure reflected in the\nLaplacian is weak. In fact, we demonstrate a data-driven procedure to construct\nsuch a network based on the available data. Notably, we dispense with\ncomputationally intensive pre-processing involving clustering of variables,\nspectral or otherwise. Our technique is underpinned by rigorous theorems that\nguarantee its effective performance and provide bounds on its sample\ncomplexity. In particular, in a wide range of settings, it provably suffices to\nrun the diffusion for time that is only logarithmic in the problem dimensions.\nWe explore in detail the interfaces of our approach with key statistical\nphysics models in network science, such as the Gaussian Free Field and the\nStochastic Block Model. Our work raises the possibility of applying similar\ndiffusion-based techniques to classical learning tasks, exploiting the\ninterplay between geometric, dynamical and stochastic structures underlying the\ndata.", "comment": "49 pages, 4 figures, 2 tables; this submission subsumes the earlier\n  preprint arXiv:2201.08326", "pdf_url": "http://arxiv.org/pdf/2507.15097v1", "cate": "stat.ML", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.15824", "title": "Can Your Model Separate Yolks with a Water Bottle? Benchmarking Physical Commonsense Understanding in Video Generation Models", "authors": ["Enes Sanli", "Baris Sarper Tezcan", "Aykut Erdem", "Erkut Erdem"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15824v1", "summary": "Recent progress in text-to-video (T2V) generation has enabled the synthesis\nof visually compelling and temporally coherent videos from natural language.\nHowever, these models often fall short in basic physical commonsense, producing\noutputs that violate intuitive expectations around causality, object behavior,\nand tool use. Addressing this gap, we present PhysVidBench, a benchmark\ndesigned to evaluate the physical reasoning capabilities of T2V systems. The\nbenchmark includes 383 carefully curated prompts, emphasizing tool use,\nmaterial properties, and procedural interactions, and domains where physical\nplausibility is crucial. For each prompt, we generate videos using diverse\nstate-of-the-art models and adopt a three-stage evaluation pipeline: (1)\nformulate grounded physics questions from the prompt, (2) caption the generated\nvideo with a vision-language model, and (3) task a language model to answer\nseveral physics-involved questions using only the caption. This indirect\nstrategy circumvents common hallucination issues in direct video-based\nevaluation. By highlighting affordances and tool-mediated actions, areas\noverlooked in current T2V evaluations, PhysVidBench provides a structured,\ninterpretable framework for assessing physical commonsense in generative video\nmodels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15824v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2505.02024", "title": "From Mind to Machine: The Rise of Manus AI as a Fully Autonomous Digital Agent", "authors": ["Minjie Shen", "Yanshu Li", "Lulu Chen", "Qikai Yang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.02024v2", "summary": "Manus AI is a general-purpose AI agent introduced in early 2025, marking a\nsignificant advancement in autonomous artificial intelligence. Developed by the\nChinese startup Monica.im, Manus is designed to bridge the gap between \"mind\"\nand \"hand\" - combining the reasoning and planning capabilities of large\nlanguage models with the ability to execute complex, end-to-end tasks that\nproduce tangible outcomes. This paper presents a comprehensive overview of\nManus AI, exploring its core technical architecture, diverse applications\nacross sectors such as healthcare, finance, manufacturing, robotics, and\ngaming, as well as its key strengths, current limitations, and future\npotential. Positioned as a preview of what lies ahead, Manus AI represents a\nshift toward intelligent agents that can translate high-level intentions into\nreal-world actions, heralding a new era of human-AI collaboration.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.02024v2", "cate": "cs.AI", "date": "2025-05-04", "updated": "2025-07-20"}
{"id": "2507.15222", "title": "Misspecifying non-compensatory as compensatory IRT: analysis of estimated skills and variance", "authors": ["Hiroshi Tamano", "Hideitsu Hino", "Daichi Mochihashi"], "categories": ["stat.ME", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Methodology (stat.ME)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15222v1", "summary": "Multidimensional item response theory is a statistical test theory used to\nestimate the latent skills of learners and the difficulty levels of problems\nbased on test results. Both compensatory and non-compensatory models have been\nproposed in the literature. Previous studies have revealed the substantial\nunderestimation of higher skills when the non-compensatory model is\nmisspecified as the compensatory model. However, the underlying mechanism\nbehind this phenomenon has not been fully elucidated. It remains unclear\nwhether overestimation also occurs and whether issues arise regarding the\nvariance of the estimated parameters. In this paper, we aim to provide a\ncomprehensive understanding of both underestimation and overestimation through\na theoretical approach. In addition to the previously identified\nunderestimation of the skills, we newly discover that the overestimation of\nskills occurs around the origin. Furthermore, we investigate the extent to\nwhich the asymptotic variance of the estimated parameters differs when\nconsidering model misspecification compared to when it is not taken into\naccount.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15222v1", "cate": "stat.ME", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15856", "title": "Latent Denoising Makes Good Visual Tokenizers", "authors": ["Jiawei Yang", "Tianhong Li", "Lijie Fan", "Yonglong Tian", "Yue Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Code is available at: this https URL", "url": "http://arxiv.org/abs/2507.15856v1", "summary": "Despite their fundamental role, it remains unclear what properties could make\nvisual tokenizers more effective for generative modeling. We observe that\nmodern generative models share a conceptually similar training objective --\nreconstructing clean signals from corrupted inputs such as Gaussian noise or\nmasking -- a process we term denoising. Motivated by this insight, we propose\naligning tokenizer embeddings directly with the downstream denoising objective,\nencouraging latent embeddings to be more easily reconstructed even when heavily\ncorrupted. To achieve this, we introduce the Latent Denoising Tokenizer\n(l-DeTok), a simple yet effective tokenizer trained to reconstruct clean images\nfrom latent embeddings corrupted by interpolative noise and random masking.\nExtensive experiments on ImageNet 256x256 demonstrate that our tokenizer\nconsistently outperforms standard tokenizers across six representative\ngenerative models. Our findings highlight denoising as a fundamental design\nprinciple for tokenizer development, and we hope it could motivate new\nperspectives for future tokenizer design.", "comment": "Code is available at: https://github.com/Jiawei-Yang/DeTok", "pdf_url": "http://arxiv.org/pdf/2507.15856v1", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2505.08622", "title": "Visually Guided Decoding: Gradient-Free Hard Prompt Inversion with Language Models", "authors": ["Donghoon Kim", "Minji Bae", "Kyuhong Shim", "Byonghyo Shim"], "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      ICLR 2025 (Official Code: this https URL )", "url": "http://arxiv.org/abs/2505.08622v2", "summary": "Text-to-image generative models like DALL-E and Stable Diffusion have\nrevolutionized visual content creation across various applications, including\nadvertising, personalized media, and design prototyping. However, crafting\neffective textual prompts to guide these models remains challenging, often\nrequiring extensive trial and error. Existing prompt inversion approaches, such\nas soft and hard prompt techniques, are not so effective due to the limited\ninterpretability and incoherent prompt generation. To address these issues, we\npropose Visually Guided Decoding (VGD), a gradient-free approach that leverages\nlarge language models (LLMs) and CLIP-based guidance to generate coherent and\nsemantically aligned prompts. In essence, VGD utilizes the robust text\ngeneration capabilities of LLMs to produce human-readable prompts. Further, by\nemploying CLIP scores to ensure alignment with user-specified visual concepts,\nVGD enhances the interpretability, generalization, and flexibility of prompt\ngeneration without the need for additional training. Our experiments\ndemonstrate that VGD outperforms existing prompt inversion techniques in\ngenerating understandable and contextually relevant prompts, facilitating more\nintuitive and controllable interactions with text-to-image models.", "comment": "ICLR 2025 (Official Code: https://github.com/DonghoonKim-1938/VGD)", "pdf_url": "http://arxiv.org/pdf/2505.08622v2", "cate": "cs.AI", "date": "2025-05-13", "updated": "2025-07-21"}
{"id": "2507.15232", "title": "Robust and Differentially Private PCA for non-Gaussian data", "authors": ["Minwoo Kim", "Sungkyu Jung"], "categories": ["stat.ME", "cs.LG"], "primary_category": "Subjects:       Methodology (stat.ME)", "pdf_link": null, "comments": "Comments:      38 pages, 6 figures", "url": "http://arxiv.org/abs/2507.15232v1", "summary": "Recent advances have sparked significant interest in the development of\nprivacy-preserving Principal Component Analysis (PCA). However, many existing\napproaches rely on restrictive assumptions, such as assuming sub-Gaussian data\nor being vulnerable to data contamination. Additionally, some methods are\ncomputationally expensive or depend on unknown model parameters that must be\nestimated, limiting their accessibility for data analysts seeking\nprivacy-preserving PCA. In this paper, we propose a differentially private PCA\nmethod applicable to heavy-tailed and potentially contaminated data. Our\napproach leverages the property that the covariance matrix of properly rescaled\ndata preserves eigenvectors and their order under elliptical distributions,\nwhich include Gaussian and heavy-tailed distributions. By applying a bounded\ntransformation, we enable straightforward computation of principal components\nin a differentially private manner. Additionally, boundedness guarantees\nrobustness against data contamination. We conduct both theoretical analysis and\nempirical evaluations of the proposed method, focusing on its ability to\nrecover the subspace spanned by the leading principal components. Extensive\nnumerical experiments demonstrate that our method consistently outperforms\nexisting approaches in terms of statistical utility, particularly in\nnon-Gaussian or contaminated data settings.", "comment": "38 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.15232v1", "cate": "stat.ME", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.14260", "title": "Hyper-spectral Unmixing algorithms for remote compositional surface mapping: a review of the state of the art", "authors": ["Alfredo Gimenez Zapiola", "Andrea Boselli", "Alessandra Menafoglio", "Simone Vantini"], "categories": ["astro-ph.IM", "astro-ph.EP", "cs.CV"], "primary_category": "Subjects:       Instrumentation and Methods for Astrophysics (astro-ph.IM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14260v1", "summary": "This work concerns a detailed review of data analysis methods used for\nremotely sensed images of large areas of the Earth and of other solid\nastronomical objects. In detail, it focuses on the problem of inferring the\nmaterials that cover the surfaces captured by hyper-spectral images and\nestimating their abundances and spatial distributions within the region. The\nmost successful and relevant hyper-spectral unmixing methods are reported as\nwell as compared, as an addition to analysing the most recent methodologies.\nThe most important public data-sets in this setting, which are vastly used in\nthe testing and validation of the former, are also systematically explored.\nFinally, open problems are spotlighted and concrete recommendations for future\nresearch are provided.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14260v1", "cate": "astro-ph.IM", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2505.12891", "title": "TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios", "authors": ["Shaohang Wei", "Wei Li", "Feifan Song", "Wen Luo", "Tianyi Zhuang", "Haochen Tan", "Zhijiang Guo", "Houfeng Wang"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Second version", "url": "http://arxiv.org/abs/2505.12891v2", "summary": "Temporal reasoning is pivotal for Large Language Models (LLMs) to comprehend\nthe real world. However, existing works neglect the real-world challenges for\ntemporal reasoning: (1) intensive temporal information, (2) fast-changing event\ndynamics, and (3) complex temporal dependencies in social interactions. To\nbridge this gap, we propose a multi-level benchmark TIME, designed for temporal\nreasoning in real-world scenarios. TIME consists of 38,522 QA pairs, covering 3\nlevels with 11 fine-grained sub-tasks. This benchmark encompasses 3\nsub-datasets reflecting different real-world challenges: TIME-Wiki, TIME-News,\nand TIME-Dial. We conduct extensive experiments on reasoning models and\nnon-reasoning models. And we conducted an in-depth analysis of temporal\nreasoning performance across diverse real-world scenarios and tasks, and\nsummarized the impact of test-time scaling on temporal reasoning capabilities.\nAdditionally, we release TIME-Lite, a human-annotated subset to foster future\nresearch and standardized evaluation in temporal reasoning. The code is\navailable at https://github.com/sylvain-wei/TIME , and the dataset is available\nat https://huggingface.co/datasets/SylvainWei/TIME .", "comment": "Second version", "pdf_url": "http://arxiv.org/pdf/2505.12891v2", "cate": "cs.AI", "date": "2025-05-19", "updated": "2025-07-19"}
{"id": "2507.15235", "title": "Accelerated Bayesian Optimal Experimental Design via Conditional Density Estimation and Informative Data", "authors": ["Miao Huang", "Hongqiao Wang", "Kunyu Wu"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15235v1", "summary": "The Design of Experiments (DOEs) is a fundamental scientific methodology that\nprovides researchers with systematic principles and techniques to enhance the\nvalidity, reliability, and efficiency of experimental outcomes. In this study,\nwe explore optimal experimental design within a Bayesian framework, utilizing\nBayes' theorem to reformulate the utility expectation--originally expressed as\na nested double integral--into an independent double integral form,\nsignificantly improving numerical efficiency. To further accelerate the\ncomputation of the proposed utility expectation, conditional density estimation\nis employed to approximate the ratio of two Gaussian random fields, while\ncovariance serves as a selection criterion to identify informative datasets\nduring model fitting and integral evaluation. In scenarios characterized by low\nsimulation efficiency and high costs of raw data acquisition, key challenges\nsuch as surrogate modeling, failure probability estimation, and parameter\ninference are systematically restructured within the Bayesian experimental\ndesign framework. The effectiveness of the proposed methodology is validated\nthrough both theoretical analysis and practical applications, demonstrating its\npotential for enhancing experimental efficiency and decision-making under\nuncertainty.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15235v1", "cate": "stat.ML", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15491", "title": "Prompt-aware of Frame Sampling for Efficient Text-Video Retrieval", "authors": ["Deyu Zhang", "Tingting Long", "Jinrui Zhang", "Ligeng Chen", "Ju Ren", "Yaoxue Zhang"], "categories": ["cs.MM", "cs.CV"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15491v1", "summary": "Enabling efficient text-video retrieval on edge-end devices is critical for\nreal-world applications. Yet, existing methods face a critical challenge in\nbalancing accuracy and computational efficiency: uniform frame sampling methods\nensure content coverage but incur prohibitive computational costs, while\nsalient-frame sampling methods reduce overhead but suffer from query-agnostic\nframe selection that biases retrieval results. To address this, we propose\nProCLIP, a user-centric framework that achieves state-of-the-art accuracy with\nsignificantly improved efficiency. We design a prompt-aware frame sampling\nstrategy that dynamically guides lightweight feature extractors using textual\nprompts to select semantically relevant frames, overcoming the limitations of\nexisting salient-frame sampling methods which rely on static, query-agnostic\nselection criteria. Moreover, we adopt a two-stage candidate pruning strategy\nthat combines rapid coarse filtering via a lightweight module with CLIP-powered\nfine-grained re-ranking, enhancing retrieval efficiency while preserving\naccuracy. Experiments across benchmarks show ProCLIP achieves 75.3% latency\nreduction versus baselines while maintaining competitive accuracy, i.e.,\nR@1=49.0 in MSR-VTT dataset. Code is available at\nhttps://github.com/tiffylong/ProCLIP.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15491v1", "cate": "cs.MM", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2505.19099", "title": "SeePhys: Does Seeing Help Thinking? -- Benchmarking Vision-Based Physics Reasoning", "authors": ["Kun Xiang", "Heng Li", "Terry Jingchen Zhang", "Yinya Huang", "Zirong Liu", "Peixin Qu", "Jixi He", "Jiaqi Chen", "Yu-Jie Yuan", "Jianhua Han", "Hang Xu", "Hanhui Li", "Mrinmaya Sachan", "Xiaodan Liang"], "categories": ["cs.AI", "physics.ed-ph", "physics.pop-ph"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      46 pages", "url": "http://arxiv.org/abs/2505.19099v5", "summary": "We present SeePhys, a large-scale multimodal benchmark for LLM reasoning\ngrounded in physics questions ranging from middle school to PhD qualifying\nexams. The benchmark covers 7 fundamental domains spanning the physics\ndiscipline, incorporating 21 categories of highly heterogeneous diagrams. In\ncontrast to prior works where visual elements mainly serve auxiliary purposes,\nour benchmark features a substantial proportion of vision-essential problems\n(75%) that mandate visual information extraction for correct solutions. Through\nextensive evaluation, we observe that even the most advanced visual reasoning\nmodels (e.g., Gemini-2.5-pro and o4-mini) achieve sub-60% accuracy on our\nbenchmark. These results reveal fundamental challenges in current large\nlanguage models' visual understanding capabilities, particularly in: (i)\nestablishing rigorous coupling between diagram interpretation and physics\nreasoning, and (ii) overcoming their persistent reliance on textual cues as\ncognitive shortcuts.", "comment": "46 pages", "pdf_url": "http://arxiv.org/pdf/2505.19099v5", "cate": "cs.AI", "date": "2025-05-25", "updated": "2025-07-21"}
{"id": "2507.15236", "title": "SOI Matters: Analyzing Multi-Setting Training Dynamics in Pretrained Language Models via Subsets of Interest", "authors": ["Shayan Vassef", "Amirhossein Dabiriaghdam", "Mohammadreza Bakhtiari", "Yadollah Yaghoobzadeh"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15236v1", "summary": "This work investigates the impact of multi-task, multi-lingual, and\nmulti-source learning approaches on the robustness and performance of\npretrained language models. To enhance this analysis, we introduce Subsets of\nInterest (SOI), a novel categorization framework that identifies six distinct\nlearning behavior patterns during training, including forgettable examples,\nunlearned examples, and always correct examples. Through SOI transition\nheatmaps and dataset cartography visualization, we analyze how examples shift\nbetween these categories when transitioning from single-setting to\nmulti-setting configurations. We perform comprehensive experiments across three\nparallel comparisons: multi-task vs. single-task learning using English tasks\n(entailment, paraphrase, sentiment), multi-source vs. single-source learning\nusing sentiment analysis datasets, and multi-lingual vs. single-lingual\nlearning using intent classification in French, English, and Persian. Our\nresults demonstrate that multi-source learning consistently improves\nout-of-distribution performance by up to 7%, while multi-task learning shows\nmixed results with notable gains in similar task combinations. We further\nintroduce a two-stage fine-tuning approach where the second stage leverages\nSOI-based subset selection to achieve additional performance improvements.\nThese findings provide new insights into training dynamics and offer practical\napproaches for optimizing multi-setting language model performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15236v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.15576", "title": "Smart Eyes for Silent Threats: VLMs and In-Context Learning for THz Imaging", "authors": ["Nicolas Poggi", "Shashank Agnihotri", "Margret Keuper"], "categories": ["cs.CL", "cs.CV"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15576v1", "summary": "Terahertz (THz) imaging enables non-invasive analysis for applications such\nas security screening and material classification, but effective image\nclassification remains challenging due to limited annotations, low resolution,\nand visual ambiguity. We introduce In-Context Learning (ICL) with\nVision-Language Models (VLMs) as a flexible, interpretable alternative that\nrequires no fine-tuning. Using a modality-aligned prompting framework, we adapt\ntwo open-weight VLMs to the THz domain and evaluate them under zero-shot and\none-shot settings. Our results show that ICL improves classification and\ninterpretability in low-data regimes. This is the first application of\nICL-enhanced VLMs to THz imaging, offering a promising direction for\nresource-constrained scientific domains. Code:\n\\href{https://github.com/Nicolas-Poggi/Project_THz_Classification/tree/main}{GitHub\nrepository}.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15576v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2506.01813", "title": "The Ultimate Test of Superintelligent AI Agents: Can an AI Balance Care and Control in Asymmetric Relationships?", "authors": ["Djallel Bouneffouf", "Matthew Riemer", "Kush Varshney"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.01813v2", "summary": "This paper introduces the Shepherd Test, a new conceptual test for assessing\nthe moral and relational dimensions of superintelligent artificial agents. The\ntest is inspired by human interactions with animals, where ethical\nconsiderations about care, manipulation, and consumption arise in contexts of\nasymmetric power and self-preservation. We argue that AI crosses an important,\nand potentially dangerous, threshold of intelligence when it exhibits the\nability to manipulate, nurture, and instrumentally use less intelligent agents,\nwhile also managing its own survival and expansion goals. This includes the\nability to weigh moral trade-offs between self-interest and the well-being of\nsubordinate agents. The Shepherd Test thus challenges traditional AI evaluation\nparadigms by emphasizing moral agency, hierarchical behavior, and complex\ndecision-making under existential stakes. We argue that this shift is critical\nfor advancing AI governance, particularly as AI systems become increasingly\nintegrated into multi-agent environments. We conclude by identifying key\nresearch directions, including the development of simulation environments for\ntesting moral behavior in AI, and the formalization of ethical manipulation\nwithin multi-agent systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.01813v2", "cate": "cs.AI", "date": "2025-06-02", "updated": "2025-07-21"}
{"id": "2507.15264", "title": "On exploration of an interior mirror descent flow for stochastic nonconvex constrained problem", "authors": ["Kuangyu Ding", "Kim-Chuan Toh"], "categories": ["math.OC", "cs.LG"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      34 Pages", "url": "http://arxiv.org/abs/2507.15264v1", "summary": "We study a nonsmooth nonconvex optimization problem defined over nonconvex\nconstraints, where the feasible set is given by the intersection of the closure\nof an open set and a smooth manifold. By endowing the open set with a\nRiemannian metric induced by a barrier function, we obtain a Riemannian\nsubgradient flow formulated as a differential inclusion, which remains strictly\nwithin the interior of the feasible set. This continuous dynamical system\nunifies two classes of iterative optimization methods, namely the Hessian\nbarrier method and mirror descent scheme, by revealing that these methods can\nbe interpreted as discrete approximations of the continuous flow. We explore\nthe long-term behavior of the trajectories generated by this dynamical system\nand show that the existing deficient convergence properties of the Hessian\nbarrier and mirror descent scheme can be unifily and more insightfully\ninterpreted through these of the continuous trajectory. For instance, the\nnotorious spurious stationary points \\cite{chen2024spurious} observed in\nHessian barrier method and mirror descent scheme are interpreted as stable\nequilibria of the dynamical system that do not correspond to real stationary\npoints of the original optimization problem. We provide two sufficient\ncondition such that these spurious stationary points can be avoided if the\nstrict complementarity conditions holds. In the absence of these regularity\ncondition, we propose a random perturbation strategy that ensures the\ntrajectory converges (subsequentially) to an approximate stationary point.\nBuilding on these insights, we introduce two iterative Riemannian subgradient\nmethods, form of interior point methods, that generalizes the existing Hessian\nbarrier method and mirror descent scheme for solving nonsmooth nonconvex\noptimization problems.", "comment": "34 Pages", "pdf_url": "http://arxiv.org/pdf/2507.15264v1", "cate": "math.OC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "1911.08432", "title": "Defective Convolutional Networks", "authors": ["Tiange Luo", "Tianle Cai", "Mengxiao Zhang", "Siyu Chen", "Di He", "Liwei Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/1911.08432v3", "summary": "Robustness of convolutional neural networks (CNNs) has gained in importance\non account of adversarial examples, i.e., inputs added as well-designed\nperturbations that are imperceptible to humans but can cause the model to\npredict incorrectly. Recent research suggests that the noises in adversarial\nexamples break the textural structure, which eventually leads to wrong\npredictions. To mitigate the threat of such adversarial attacks, we propose\ndefective convolutional networks that make predictions relying less on textural\ninformation but more on shape information by properly integrating defective\nconvolutional layers into standard CNNs. The defective convolutional layers\ncontain defective neurons whose activations are set to be a constant function.\nAs defective neurons contain no information and are far different from standard\nneurons in its spatial neighborhood, the textural features cannot be accurately\nextracted, and so the model has to seek other features for classification, such\nas the shape. We show extensive evidence to justify our proposal and\ndemonstrate that defective CNNs can defense against black-box attacks better\nthan standard CNNs. In particular, they achieve state-of-the-art performance\nagainst transfer-based attacks without any adversarial training being applied.", "comment": null, "pdf_url": "http://arxiv.org/pdf/1911.08432v3", "cate": "cs.CV", "date": "2019-11-19", "updated": "2025-07-20"}
{"id": "2506.13023", "title": "A Practical Guide for Evaluating LLMs and LLM-Reliant Systems", "authors": ["Ethan M. Rudd", "Christopher Andrews", "Philip Tully"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.13023v2", "summary": "Recent advances in generative AI have led to remarkable interest in using\nsystems that rely on large language models (LLMs) for practical applications.\nHowever, meaningful evaluation of these systems in real-world scenarios comes\nwith a distinct set of challenges, which are not well-addressed by synthetic\nbenchmarks and de-facto metrics that are often seen in the literature. We\npresent a practical evaluation framework which outlines how to proactively\ncurate representative datasets, select meaningful evaluation metrics, and\nemploy meaningful evaluation methodologies that integrate well with practical\ndevelopment and deployment of LLM-reliant systems that must adhere to\nreal-world requirements and meet user-facing needs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.13023v2", "cate": "cs.AI", "date": "2025-06-16", "updated": "2025-07-21"}
{"id": "2507.15339", "title": "LionGuard 2: Building Lightweight, Data-Efficient & Localised Multilingual Content Moderators", "authors": ["Leanne Tan", "Gabriel Chua", "Ziyu Ge", "Roy Ka-Wei Lee"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15339v1", "summary": "Modern moderation systems increasingly support multiple languages, but often\nfail to address localisation and low-resource variants - creating safety gaps\nin real-world deployments. Small models offer a potential alternative to large\nLLMs, yet still demand considerable data and compute. We present LionGuard 2, a\nlightweight, multilingual moderation classifier tailored to the Singapore\ncontext, supporting English, Chinese, Malay, and partial Tamil. Built on\npre-trained OpenAI embeddings and a multi-head ordinal classifier, LionGuard 2\noutperforms several commercial and open-source systems across 17 benchmarks,\nincluding both Singapore-specific and public English datasets. The system is\nactively deployed within the Singapore Government, demonstrating practical\nefficacy at scale. Our findings show that high-quality local data and robust\nmultilingual embeddings can achieve strong moderation performance, without\nfine-tuning large models. We release our model weights and part of our training\ndata to support future work on LLM safety.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15339v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2206.02373", "title": "Sports Re-ID: Improving Re-Identification Of Players In Broadcast Videos Of Team Sports", "authors": ["Bharath Comandur"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2206.02373v2", "summary": "This work focuses on player re-identification in broadcast videos of team\nsports. Specifically, we focus on identifying the same player in images\ncaptured from different camera viewpoints during any given moment of a match.\nThis task differs from traditional applications of person re-id in a few\nimportant ways. Firstly, players from the same team wear highly similar\nclothes, thereby making it harder to tell them apart. Secondly, there are only\na few number of samples for each identity, which makes it harder to train a\nre-id system. Thirdly, the resolutions of the images are often quite low and\nvary a lot. This combined with heavy occlusions and fast movements of players\ngreatly increase the challenges for re-id. In this paper, we propose a simple\nbut effective hierarchical data sampling procedure and a centroid loss function\nthat, when used together, increase the mean average precision (mAP) by 7 - 11.5\nand the rank-1 (R1) by 8.8 - 14.9 without any change in the network or\nhyper-parameters used. Our data sampling procedure improves the similarity of\nthe training and test distributions, and thereby aids in creating better\nestimates of the centroids of the embeddings (or feature vectors).\nSurprisingly, our study shows that in the presence of severely limited data, as\nis the case for our application, a simple centroid loss function based on\neuclidean distances significantly outperforms the popular triplet-centroid loss\nfunction. We show comparable improvements for both convolutional networks and\nvision transformers. Our approach is among the top ranked methods in the\nSoccerNet Re-Identification Challenge 2022 leaderboard (test-split) with a mAP\nof 86.0 and a R1 of 81.5. On the sequestered challenge split, we achieve an mAP\nof 84.9 and a R1 of 80.1. Research on re-id for sports-related applications is\nvery limited and our work presents one of the first discussions in the\nliterature on this.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2206.02373v2", "cate": "cs.CV", "date": "2022-06-06", "updated": "2025-07-19"}
{"id": "2506.21763", "title": "THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?", "authors": ["Xin Wang", "Jiyao Liu", "Yulong Xiao", "Junzhi Ning", "Lihao Liu", "Junjun He", "Botian Shi", "Kaicheng Yu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.21763v2", "summary": "Large Language Models (LLMs) are accelerating scientific idea generation, but\nrigorously evaluating these numerous, often superficial, AI-generated\npropositions for novelty and factual accuracy is a critical bottleneck; manual\nverification is too slow. Existing validation methods are inadequate: LLMs as\nstandalone verifiers may hallucinate and lack domain knowledge (our findings\nshow 60% unawareness of relevant papers in specific domains), while traditional\ncitation networks lack explicit causality and narrative surveys are\nunstructured. This underscores a core challenge: the absence of structured,\nverifiable, and causally-linked historical data of scientific evolution.To\naddress this,we introduce \\textbf{THE-Tree} (\\textbf{T}echnology\n\\textbf{H}istory \\textbf{E}volution Tree), a computational framework that\nconstructs such domain-specific evolution trees from scientific literature.\nTHE-Tree employs a search algorithm to explore evolutionary paths. During its\nnode expansion, it utilizes a novel \"Think-Verbalize-Cite-Verify\" process: an\nLLM proposes potential advancements and cites supporting literature.\nCritically, each proposed evolutionary link is then validated for logical\ncoherence and evidential support by a recovered natural language inference\nmechanism that interrogates the cited literature, ensuring that each step is\ngrounded. We construct and validate 88 THE-Trees across diverse domains and\nrelease a benchmark dataset including up to 71k fact verifications covering 27k\npapers to foster further research. Experiments demonstrate that i) in graph\ncompletion, our THE-Tree improves hit@1 by 8% to 14% across multiple models\ncompared to traditional citation networks; ii) for predicting future scientific\ndevelopments, it improves hit@1 metric by nearly 10%; and iii) when combined\nwith other methods, it boosts the performance of evaluating important\nscientific papers by almost 100%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.21763v2", "cate": "cs.AI", "date": "2025-06-26", "updated": "2025-07-21"}
{"id": "2507.15347", "title": "Probing Information Distribution in Transformer Architectures through Entropy Analysis", "authors": ["Amedeo Buonanno", "Alessandro Rivetti", "Francesco A. N. Palmieri", "Giovanni Di Gennaro", "Gianmarco Romano"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Presented to the Italian Workshop on Neural Networks (WIRN2025) and it will appear in a Springer Chapter", "url": "http://arxiv.org/abs/2507.15347v1", "summary": "This work explores entropy analysis as a tool for probing information\ndistribution within Transformer-based architectures. By quantifying token-level\nuncertainty and examining entropy patterns across different stages of\nprocessing, we aim to investigate how information is managed and transformed\nwithin these models. As a case study, we apply the methodology to a GPT-based\nlarge language model, illustrating its potential to reveal insights into model\nbehavior and internal representations. This approach may offer insights into\nmodel behavior and contribute to the development of interpretability and\nevaluation frameworks for transformer-based models", "comment": "Presented to the Italian Workshop on Neural Networks (WIRN2025) and\n  it will appear in a Springer Chapter", "pdf_url": "http://arxiv.org/pdf/2507.15347v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2306.16894", "title": "PFB-Diff: Progressive Feature Blending Diffusion for Text-driven Image Editing", "authors": ["Wenjing Huang", "Shikui Tu", "Lei Xu"], "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by Neural Networks. Code is available at this https URL", "url": "http://arxiv.org/abs/2306.16894v2", "summary": "Diffusion models have demonstrated their ability to generate diverse and\nhigh-quality images, sparking considerable interest in their potential for real\nimage editing applications. However, existing diffusion-based approaches for\nlocal image editing often suffer from undesired artifacts due to the\nlatent-level blending of the noised target images and diffusion latent\nvariables, which lack the necessary semantics for maintaining image\nconsistency. To address these issues, we propose PFB-Diff, a Progressive\nFeature Blending method for Diffusion-based image editing. Unlike previous\nmethods, PFB-Diff seamlessly integrates text-guided generated content into the\ntarget image through multi-level feature blending. The rich semantics encoded\nin deep features and the progressive blending scheme from high to low levels\nensure semantic coherence and high quality in edited images. Additionally, we\nintroduce an attention masking mechanism in the cross-attention layers to\nconfine the impact of specific words to desired regions, further improving the\nperformance of background editing and multi-object replacement. PFB-Diff can\neffectively address various editing tasks, including object/background\nreplacement and object attribute editing. Our method demonstrates its superior\nperformance in terms of editing accuracy and image quality without the need for\nfine-tuning or training. Our implementation is available at\nhttps://github.com/CMACH508/PFB-Diff.", "comment": "Accepted by Neural Networks. Code is available at\n  https://github.com/CMACH508/PFB-Diff", "pdf_url": "http://arxiv.org/pdf/2306.16894v2", "cate": "cs.CV", "date": "2023-06-28", "updated": "2025-07-21"}
{"id": "2507.04722", "title": "LumiCRS: Asymmetric Contrastive Prototype Learning for Long-Tail Conversational Recommender Systems", "authors": ["Jinzhi Wang", "Bin Li", "Qingke Peng", "Haozhou Li", "Zeyuan Zeng", "Ruimeng Li", "Kaixuan Yang", "Jiangbo Zhang", "Biyi Zhou", "Yaoying Wang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04722v2", "summary": "Conversational recommender systems (CRSs) often suffer from an extreme\nlong-tail distribution of dialogue data, causing a strong bias toward\nhead-frequency blockbusters that sacrifices diversity and exacerbates the\ncold-start problem. An empirical analysis of DCRS and statistics on the REDIAL\ncorpus show that only 10% of head movies account for nearly half of all\nmentions, whereas about 70% of tail movies receive merely 26% of the attention.\nThis imbalance gives rise to three critical challenges: head over-fitting, body\nrepresentation drift, and tail sparsity. To address these issues, we propose\nLumiCRS, an end-to-end framework that mitigates long-tail imbalance through\nthree mutually reinforcing layers: (i) an Adaptive Comprehensive Focal Loss\n(ACFL) that dynamically adjusts class weights and focusing factors to curb head\nover-fitting and reduce popularity bias; (ii) Prototype Learning for Long-Tail\nRecommendation, which selects semantic, affective, and contextual prototypes to\nguide clustering and stabilize body and tail representations; and (iii) a\nGPT-4o-driven prototype-guided dialogue augmentation module that automatically\ngenerates diverse long-tail conversational snippets to alleviate tail sparsity\nand distribution shift. Together, these strategies enable LumiCRS to markedly\nimprove recommendation accuracy, diversity, and fairness: on the REDIAL and\nINSPIRED benchmarks, LumiCRS boosts Recall@10 and Tail-Recall@10 by 7-15% over\nfifteen strong baselines, while human evaluations confirm superior fluency,\ninformativeness, and long-tail relevance. These results demonstrate the\neffectiveness of multi-layer collaboration in building an efficient and fair\nlong-tail conversational recommender.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04722v2", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-20"}
{"id": "2507.15485", "title": "Information Preserving Line Search via Bayesian Optimization", "authors": ["Robin Labryga", "Tomislav Prusina", "Sören Laue"], "categories": ["math.OC", "cs.LG"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      Accepted for publication at: LION 19: Learning and Intelligent Optimization, 19th International Conference, Prague, 2025 (Springer LNCS). This is the preprint version (DOI to be added when available)", "url": "http://arxiv.org/abs/2507.15485v1", "summary": "Line search is a fundamental part of iterative optimization methods for\nunconstrained and bound-constrained optimization problems to determine suitable\nstep lengths that provide sufficient improvement in each iteration. Traditional\nline search methods are based on iterative interval refinement, where valuable\ninformation about function value and gradient is discarded in each iteration.\nWe propose a line search method via Bayesian optimization, preserving and\nutilizing otherwise discarded information to improve step-length choices. Our\napproach is guaranteed to converge and shows superior performance compared to\nstate-of-the-art methods based on empirical tests on the challenging\nunconstrained and bound-constrained optimization problems from the CUTEst test\nset.", "comment": "Accepted for publication at: LION 19: Learning and Intelligent\n  Optimization, 19th International Conference, Prague, 2025 (Springer LNCS).\n  This is the preprint version (DOI to be added when available)", "pdf_url": "http://arxiv.org/pdf/2507.15485v1", "cate": "math.OC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2308.15618", "title": "RACR-MIL: Rank-aware contextual reasoning for weakly supervised grading of squamous cell carcinoma using whole slide images", "authors": ["Anirudh Choudhary", "Mosbah Aouad", "Krishnakant Saboo", "Angelina Hwang", "Jacob Kechter", "Blake Bordeaux", "Puneet Bhullar", "David DiCaudo", "Steven Nelson", "Nneka Comfere", "Emma Johnson", "Olayemi Sokumbi", "Jason Sluzevich", "Leah Swanson", "Dennis Murphree", "Aaron Mangold", "Ravishankar Iyer"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages main text, 2 page references, 2 page appendix; under submission", "url": "http://arxiv.org/abs/2308.15618v2", "summary": "Squamous cell carcinoma (SCC) is the most common cancer subtype, with an\nincreasing incidence and a significant impact on cancer-related mortality. SCC\ngrading using whole slide images is inherently challenging due to the lack of a\nreliable protocol and substantial tissue heterogeneity. We propose RACR-MIL,\nthe first weakly-supervised SCC grading approach achieving robust\ngeneralization across multiple anatomies (skin, head and neck, lung). RACR-MIL\nis an attention-based multiple-instance learning framework that enhances\ngrade-relevant contextual representation learning and addresses tumor\nheterogeneity through two key innovations: (1) a hybrid WSI graph that captures\nboth local tissue context and non-local phenotypical dependencies between tumor\nregions, and (2) a rank-ordering constraint in the attention mechanism that\nconsistently prioritizes higher-grade tumor regions, aligning with pathologists\ndiagnostic process. Our model achieves state-of-the-art performance across\nmultiple SCC datasets, achieving 3-9% higher grading accuracy, resilience to\nclass imbalance, and up to 16% improved tumor localization. In a pilot study,\npathologists reported that RACR-MIL improved grading efficiency in 60% of\ncases, underscoring its potential as a clinically viable cancer diagnosis and\ngrading assistant.", "comment": "17 pages main text, 2 page references, 2 page appendix; under\n  submission", "pdf_url": "http://arxiv.org/pdf/2308.15618v2", "cate": "cs.CV", "date": "2023-08-29", "updated": "2025-07-19"}
{"id": "2507.05519", "title": "Modeling Deontic Modal Logic in the s(CASP) Goal-directed Predicate Answer Set Programming System", "authors": ["Gopal Gupta", "Abhiramon Rajasekharan", "Alexis R. Tudor", "Elmer Salazar", "Joaquín Arias"], "categories": ["cs.AI", "cs.LO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05519v3", "summary": "We consider the problem of implementing deontic modal logic. We show how\n(deontic) modal operators can be expressed elegantly using default negation\n(negation-as-failure) and strong negation present in answer set programming\n(ASP). We propose using global constraints of ASP to represent obligations and\nimpermissibilities of deontic modal logic. We show that our proposed\nrepresentation results in the various paradoxes of deontic modal logic being\nelegantly resolved.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05519v3", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-20"}
{"id": "2507.15741", "title": "Conformal and kNN Predictive Uncertainty Quantification Algorithms in Metric Spaces", "authors": ["Gábor Lugosi", "Marcos Matabuena"], "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15741v1", "summary": "This paper introduces a framework for uncertainty quantification in\nregression models defined in metric spaces. Leveraging a newly defined notion\nof homoscedasticity, we develop a conformal prediction algorithm that offers\nfinite-sample coverage guarantees and fast convergence rates of the oracle\nestimator. In heteroscedastic settings, we forgo these non-asymptotic\nguarantees to gain statistical efficiency, proposing a local\n$k$--nearest--neighbor method without conformal calibration that is adaptive to\nthe geometry of each particular nonlinear space. Both procedures work with any\nregression algorithm and are scalable to large data sets, allowing\npractitioners to plug in their preferred models and incorporate domain\nexpertise. We prove consistency for the proposed estimators under minimal\nconditions. Finally, we demonstrate the practical utility of our approach in\npersonalized--medicine applications involving random response objects such as\nprobability distributions and graph Laplacians.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15741v1", "cate": "stat.ML", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2309.15562", "title": "Learning from SAM: Harnessing a Foundation Model for Sim2Real Adaptation by Regularization", "authors": ["Mayara E. Bonani", "Max Schwarz", "Sven Behnke"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted for IEEE International Conference on Automation Science and Engineering (CASE) 2025. M. E. Bonani and M. Schwarz contributed equally", "url": "http://arxiv.org/abs/2309.15562v4", "summary": "Domain adaptation is especially important for robotics applications, where\ntarget domain training data is usually scarce and annotations are costly to\nobtain. We present a method for self-supervised domain adaptation for the\nscenario where annotated source domain data (e.g. from synthetic generation) is\navailable, but the target domain data is completely unannotated. Our method\ntargets the semantic segmentation task and leverages a segmentation foundation\nmodel (Segment Anything Model) to obtain segment information on unannotated\ndata. We take inspiration from recent advances in unsupervised local feature\nlearning and propose an invariance-variance loss over the detected segments for\nregularizing feature representations in the target domain. Crucially, this loss\nstructure and network architecture can handle overlapping segments and\noversegmentation as produced by Segment Anything. We demonstrate the advantage\nof our method on the challenging YCB-Video and HomebrewedDB datasets and show\nthat it outperforms prior work and, on YCB-Video, even a network trained with\nreal annotations. Additionally, we provide insight through model ablations and\nshow applicability to a custom robotic application.", "comment": "Accepted for IEEE International Conference on Automation Science and\n  Engineering (CASE) 2025. M. E. Bonani and M. Schwarz contributed equally", "pdf_url": "http://arxiv.org/pdf/2309.15562v4", "cate": "cs.CV", "date": "2023-09-27", "updated": "2025-07-21"}
{"id": "2507.08216", "title": "Grounding Methods for Neural-Symbolic AI", "authors": ["Rodrigo Castellano Ontiveros", "Francesco Giannini", "Marco Gori", "Giuseppe Marra", "Michelangelo Diligenti"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08216v2", "summary": "A large class of Neural-Symbolic (NeSy) methods employs a machine learner to\nprocess the input entities, while relying on a reasoner based on First-Order\nLogic to represent and process more complex relationships among the entities. A\nfundamental role for these methods is played by the process of logic grounding,\nwhich determines the relevant substitutions for the logic rules using a\n(sub)set of entities. Some NeSy methods use an exhaustive derivation of all\npossible substitutions, preserving the full expressive power of the logic\nknowledge. This leads to a combinatorial explosion in the number of ground\nformulas to consider and, therefore, strongly limits their scalability. Other\nmethods rely on heuristic-based selective derivations, which are generally more\ncomputationally efficient, but lack a justification and provide no guarantees\nof preserving the information provided to and returned by the reasoner. Taking\ninspiration from multi-hop symbolic reasoning, this paper proposes a\nparametrized family of grounding methods generalizing classic Backward\nChaining. Different selections within this family allow us to obtain commonly\nemployed grounding methods as special cases, and to control the trade-off\nbetween expressiveness and scalability of the reasoner. The experimental\nresults show that the selection of the grounding criterion is often as\nimportant as the NeSy method itself.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08216v2", "cate": "cs.AI", "date": "2025-07-10", "updated": "2025-07-21"}
{"id": "2507.15776", "title": "Dissociating model architectures from inference computations", "authors": ["Noor Sajid", "Johan Medrano"], "categories": ["q-bio.NC", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "Comments:      3 pages, 1 figure", "url": "http://arxiv.org/abs/2507.15776v1", "summary": "Parr et al., 2025 examines how auto-regressive and deep temporal models\ndiffer in their treatment of non-Markovian sequence modelling. Building on\nthis, we highlight the need for dissociating model architectures, i.e., how the\npredictive distribution factorises, from the computations invoked at inference.\nWe demonstrate that deep temporal computations are mimicked by autoregressive\nmodels by structuring context access during iterative inference. Using a\ntransformer trained on next-token prediction, we show that inducing\nhierarchical temporal factorisation during iterative inference maintains\npredictive capacity while instantiating fewer computations. This emphasises\nthat processes for constructing and refining predictions are not necessarily\nbound to their underlying model architectures.", "comment": "3 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.15776v1", "cate": "q-bio.NC", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2311.16737", "title": "Point'n Move: Interactive Scene Object Manipulation on Gaussian Splatting Radiance Fields", "authors": ["Jiajun Huang", "Hongchuan Yu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Code: this https URL", "url": "http://arxiv.org/abs/2311.16737v2", "summary": "We propose Point'n Move, a method that achieves interactive scene object\nmanipulation with exposed region inpainting. Interactivity here further comes\nfrom intuitive object selection and real-time editing. To achieve this, we\nadopt Gaussian Splatting Radiance Field as the scene representation and fully\nleverage its explicit nature and speed advantage. Its explicit representation\nformulation allows us to devise a 2D prompt points to 3D mask dual-stage\nself-prompting segmentation algorithm, perform mask refinement and merging,\nminimize change as well as provide good initialization for scene inpainting and\nperform editing in real-time without per-editing training, all leads to\nsuperior quality and performance. We test our method by performing editing on\nboth forward-facing and 360 scenes. We also compare our method against existing\nscene object removal methods, showing superior quality despite being more\ncapable and having a speed advantage.", "comment": "Code: https://github.com/jhuangBU/pnm", "pdf_url": "http://arxiv.org/pdf/2311.16737v2", "cate": "cs.CV", "date": "2023-11-28", "updated": "2025-07-19"}
{"id": "2507.10571", "title": "Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning", "authors": ["Konstantinos I. Roumeliotis", "Ranjan Sapkota", "Manoj Karkee", "Nikolaos D. Tselikas"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10571v2", "summary": "Modern Artificial Intelligence (AI) increasingly relies on multi-agent\narchitectures that blend visual and language understanding. Yet, a pressing\nchallenge remains: How can we trust these agents especially in zero-shot\nsettings with no fine-tuning? We introduce a novel modular Agentic AI visual\nclassification framework that integrates generalist multimodal agents with a\nnon-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)\nmodule. Applied to apple leaf disease diagnosis, we benchmark three\nconfigurations: (I) zero-shot with confidence-based orchestration, (II)\nfine-tuned agents with improved performance, and (III) trust-calibrated\norchestration enhanced by CLIP-based image retrieval and re-evaluation loops.\nUsing confidence calibration metrics (ECE, OCR, CCC), the orchestrator\nmodulates trust across agents. Our results demonstrate a 77.94\\% accuracy\nimprovement in the zero-shot setting using trust-aware orchestration and RAG,\nachieving 85.63\\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL\ndisplayed overconfidence. Furthermore, image-RAG grounded predictions with\nvisually similar cases, enabling correction of agent overconfidence via\niterative re-evaluation. The proposed system separates perception (vision\nagents) from meta-reasoning (orchestrator), enabling scalable and interpretable\nmulti-agent AI. This blueprint is extensible to diagnostics, biology, and other\ntrust-critical domains. All models, prompts, results, and system components\nincluding the complete software source code are openly released to support\nreproducibility, transparency, and community benchmarking at Github:\nhttps://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10571v2", "cate": "cs.AI", "date": "2025-07-09", "updated": "2025-07-18"}
{"id": "2507.15802", "title": "Hypergraphs on high dimensional time series sets using signature transform", "authors": ["Rémi Vaucher", "Paul Minchella"], "categories": ["stat.ML", "cs.LG", "stat.CO"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Accepted at GSI25 conference. Pending publication in Springer proceedings", "url": "http://arxiv.org/abs/2507.15802v1", "summary": "In recent decades, hypergraphs and their analysis through Topological Data\nAnalysis (TDA) have emerged as powerful tools for understanding complex data\nstructures. Various methods have been developed to construct hypergraphs --\nreferred to as simplicial complexes in the TDA framework -- over datasets,\nenabling the formation of edges between more than two vertices. This paper\naddresses the challenge of constructing hypergraphs from collections of\nmultivariate time series. While prior work has focused on the case of a single\nmultivariate time series, we extend this framework to handle collections of\nsuch time series. Our approach generalizes the method proposed in Chretien and\nal. by leveraging the properties of signature transforms to introduce\ncontrolled randomness, thereby enhancing the robustness of the construction\nprocess. We validate our method on synthetic datasets and present promising\nresults.", "comment": "Accepted at GSI25 conference. Pending publication in Springer\n  proceedings", "pdf_url": "http://arxiv.org/pdf/2507.15802v1", "cate": "stat.ML", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2403.12510", "title": "Generalized Consistency Trajectory Models for Image Manipulation", "authors": ["Beomsu Kim", "Jaemin Kim", "Jeongsol Kim", "Jong Chul Ye"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICLR 2025 (poster)", "url": "http://arxiv.org/abs/2403.12510v4", "summary": "Diffusion models (DMs) excel in unconditional generation, as well as on\napplications such as image editing and restoration. The success of DMs lies in\nthe iterative nature of diffusion: diffusion breaks down the complex process of\nmapping noise to data into a sequence of simple denoising tasks. Moreover, we\nare able to exert fine-grained control over the generation process by injecting\nguidance terms into each denoising step. However, the iterative process is also\ncomputationally intensive, often taking from tens up to thousands of function\nevaluations. Although consistency trajectory models (CTMs) enable traversal\nbetween any time points along the probability flow ODE (PFODE) and score\ninference with a single function evaluation, CTMs only allow translation from\nGaussian noise to data. This work aims to unlock the full potential of CTMs by\nproposing generalized CTMs (GCTMs), which translate between arbitrary\ndistributions via ODEs. We discuss the design space of GCTMs and demonstrate\ntheir efficacy in various image manipulation tasks such as image-to-image\ntranslation, restoration, and editing.", "comment": "ICLR 2025 (poster)", "pdf_url": "http://arxiv.org/pdf/2403.12510v4", "cate": "cs.CV", "date": "2024-03-19", "updated": "2025-07-21"}
{"id": "2507.12862", "title": "Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command", "authors": ["Taylan Akay", "Harrison Tolley", "Hussein Abbass"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12862v2", "summary": "In the age of AI, human commanders need to use the computational powers\navailable in today's environment to simulate a very large number of scenarios.\nWithin each scenario, situations occur where different decision design options\ncould have ethical consequences. Making these decisions reliant on human\njudgement is both counter-productive to the aim of exploring very large number\nof scenarios in a timely manner and infeasible when considering the workload\nneeded to involve humans in each of these choices. In this paper, we move human\njudgement outside the simulation decision cycle. Basically, the human will\ndesign the ethical metric space, leaving it to the simulated environment to\nexplore the space. When the simulation completes its testing cycles, the\ntesting environment will come back to the human commander with a few options to\nselect from. The human commander will then exercise human-judgement to select\nthe most appropriate course of action, which will then get executed\naccordingly. We assume that the problem of designing metrics that are\nsufficiently granular to assess the ethical implications of decisions is\nsolved. Subsequently, the fundamental problem we look at in this paper is how\nto weight ethical decisions during the running of these simulations; that is,\nhow to dynamically weight the ethical attributes when agents are faced with\ndecision options with ethical implications during generative simulations. The\nmulti-criteria decision making literature has started to look at nearby\nproblems, where the concept of entropy has been used to determine the weights\nduring aggregation. We draw from that literature different approaches to\nautomatically calculate the weights for ethical attributes during\nsimulation-based testing and evaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12862v2", "cate": "cs.AI", "date": "2025-07-17", "updated": "2025-07-20"}
{"id": "2507.15825", "title": "ACS: An interactive framework for conformal selection", "authors": ["Yu Gui", "Ying Jin", "Yash Nair", "Zhimei Ren"], "categories": ["stat.ME", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Methodology (stat.ME)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15825v1", "summary": "This paper presents adaptive conformal selection (ACS), an interactive\nframework for model-free selection with guaranteed error control. Building on\nconformal selection (Jin and Cand\\`es, 2023b), ACS generalizes the approach to\nsupport human-in-the-loop adaptive data analysis. Under the ACS framework, we\ncan partially reuse the data to boost the selection power, make decisions on\nthe fly while exploring the data, and incorporate new information or\npreferences as they arise. The key to ACS is a carefully designed principle\nthat controls the information available for decision making, allowing the data\nanalyst to explore the data adaptively while maintaining rigorous control of\nthe false discovery rate (FDR). Based on the ACS framework, we provide concrete\nselection algorithms for various goals, including model update/selection,\ndiversified selection, and incorporating newly available labeled data. The\neffectiveness of ACS is demonstrated through extensive numerical simulations\nand real-data applications in large language model (LLM) deployment and drug\ndiscovery.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15825v1", "cate": "stat.ME", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2404.07984", "title": "View Selection for 3D Captioning via Diffusion Ranking", "authors": ["Tiange Luo", "Justin Johnson", "Honglak Lee"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ECCV2024, Dataset link: this https URL", "url": "http://arxiv.org/abs/2404.07984v2", "summary": "Scalable annotation approaches are crucial for constructing extensive 3D-text\ndatasets, facilitating a broader range of applications. However, existing\nmethods sometimes lead to the generation of hallucinated captions, compromising\ncaption quality. This paper explores the issue of hallucination in 3D object\ncaptioning, with a focus on Cap3D method, which renders 3D objects into 2D\nviews for captioning using pre-trained models. We pinpoint a major challenge:\ncertain rendered views of 3D objects are atypical, deviating from the training\ndata of standard image captioning models and causing hallucinations. To tackle\nthis, we present DiffuRank, a method that leverages a pre-trained text-to-3D\nmodel to assess the alignment between 3D objects and their 2D rendered views,\nwhere the view with high alignment closely represent the object's\ncharacteristics. By ranking all rendered views and feeding the top-ranked ones\ninto GPT4-Vision, we enhance the accuracy and detail of captions, enabling the\ncorrection of 200k captions in the Cap3D dataset and extending it to 1 million\ncaptions across Objaverse and Objaverse-XL datasets. Additionally, we showcase\nthe adaptability of DiffuRank by applying it to pre-trained text-to-image\nmodels for a Visual Question Answering task, where it outperforms the CLIP\nmodel.", "comment": "ECCV2024, Dataset link: https://huggingface.co/datasets/tiange/Cap3D", "pdf_url": "http://arxiv.org/pdf/2404.07984v2", "cate": "cs.CV", "date": "2024-04-11", "updated": "2025-07-20"}
{"id": "2209.12825", "title": "Abductive forgetting", "authors": ["Paolo Liberatore"], "categories": ["cs.LO", "cs.AI"], "primary_category": "Subjects:       Logic in Computer Science (cs.LO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2209.12825v2", "summary": "Abductive forgetting is removing variables from a logical formula while\nmaintaining its abductive explanations. It is carried in two alternative ways\ndepending on its intended application. Both differ from the usual forgetting,\nwhich maintains consequences rather than explanations. Differently from that,\nabductive forgetting from a propositional formula may not be expressed by any\npropositional formula. A necessary and sufficient condition tells when it is.\nChecking it is $\\Pi^p_3$-complete. A way to guarantee expressibility of\nabductive forgetting is to switch from propositional to default logic. Another\nis to introduce new variables.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2209.12825v2", "cate": "cs.LO", "date": "2022-09-26", "updated": "2025-07-20"}
{"id": "2006.13456", "title": "Likelihood-Free Gaussian Process for Regression", "authors": ["Yuta Shikuri"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      The paper contains a critical issue in the theoretical justification, and is therefore withdrawn", "url": "http://arxiv.org/abs/2006.13456v5", "summary": "Gaussian process regression can flexibly represent the posterior distribution\nof an interest parameter given sufficient information on the likelihood.\nHowever, in some cases, we have little knowledge regarding the probability\nmodel. For example, when investing in a financial instrument, the probability\nmodel of cash flow is generally unknown. In this paper, we propose a novel\nframework called the likelihood-free Gaussian process (LFGP), which allows\nrepresentation of the posterior distributions of interest parameters for\nscalable problems without directly setting their likelihood functions. The LFGP\nestablishes clusters in which the value of the interest parameter can be\nconsidered approximately identical, and it approximates the likelihood of the\ninterest parameter in each cluster to a Gaussian using the asymptotic normality\nof the maximum likelihood estimator. We expect that the proposed framework will\ncontribute significantly to likelihood-free modeling, particularly by reducing\nthe assumptions for the probability model and the computational costs for\nscalable problems.", "comment": "The paper contains a critical issue in the theoretical justification,\n  and is therefore withdrawn", "pdf_url": "http://arxiv.org/pdf/2006.13456v5", "cate": "cs.LG", "date": "2020-06-24", "updated": "2025-07-19"}
{"id": "2404.18423", "title": "OCK: Unsupervised Dynamic Video Prediction with Object-Centric Kinematics", "authors": ["Yeon-Ji Song", "Jaein Kim", "Suhyung Choi", "Jin-Hwa Kim", "Byoung-Tak Zhang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV2025", "url": "http://arxiv.org/abs/2404.18423v3", "summary": "Human perception involves decomposing complex multi-object scenes into\ntime-static object appearance (i.e., size, shape, color) and time-varying\nobject motion (i.e., position, velocity, acceleration). For machines to achieve\nhuman-like intelligence in real-world interactions, understanding these\nphysical properties of objects is essential, forming the foundation for dynamic\nvideo prediction. While recent advancements in object-centric transformers have\ndemonstrated potential in video prediction, they primarily focus on object\nappearance, often overlooking motion dynamics, which is crucial for modeling\ndynamic interactions and maintaining temporal consistency in complex\nenvironments. To address these limitations, we propose OCK, a dynamic video\nprediction model leveraging object-centric kinematics and object slots. We\nintroduce a novel component named Object Kinematics that comprises explicit\nobject motions, serving as an additional attribute beyond conventional\nappearance features to model dynamic scenes. The Object Kinematics are\nintegrated into various OCK mechanisms, enabling spatiotemporal prediction of\ncomplex object interactions over long video sequences. Our model demonstrates\nsuperior performance in handling complex scenes with intricate object\nattributes and motions, highlighting its potential for applicability in\nvision-related dynamics learning tasks.", "comment": "Accepted at ICCV2025", "pdf_url": "http://arxiv.org/pdf/2404.18423v3", "cate": "cs.CV", "date": "2024-04-29", "updated": "2025-07-21"}
{"id": "2303.09823", "title": "Transformers and Ensemble methods: A solution for Hate Speech Detection in Arabic languages", "authors": ["Angel Felipe Magnossão de Paula", "Imene Bensalem", "Paolo Rosso", "Wajdi Zaghouani"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      6 pages, 3 tables", "url": "http://arxiv.org/abs/2303.09823v2", "summary": "This paper describes our participation in the shared task of hate speech\ndetection, which is one of the subtasks of the CERIST NLP Challenge 2022. Our\nexperiments evaluate the performance of six transformer models and their\ncombination using 2 ensemble approaches. The best results on the training set,\nin a five-fold cross validation scenario, were obtained by using the ensemble\napproach based on the majority vote. The evaluation of this approach on the\ntest set resulted in an F1-score of 0.60 and an Accuracy of 0.86.", "comment": "6 pages, 3 tables", "pdf_url": "http://arxiv.org/pdf/2303.09823v2", "cate": "cs.CL", "date": "2023-03-17", "updated": "2025-07-20"}
{"id": "2102.02837", "title": "Escaping Saddle Points for Nonsmooth Weakly Convex Functions via Perturbed Proximal Algorithms", "authors": ["Minhui Huang", "Weiming Zhu"], "categories": ["cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2102.02837v3", "summary": "We propose perturbed proximal algorithms that can provably escape strict\nsaddles for nonsmooth weakly convex functions. The main results are based on a\nnovel characterization of $\\epsilon$-approximate local minimum for nonsmooth\nfunctions, and recent developments on perturbed gradient methods for escaping\nsaddle points for smooth problems. Specifically, we show that under standard\nassumptions, the perturbed proximal point, perturbed proximal gradient and\nperturbed proximal linear algorithms find $\\epsilon$-approximate local minimum\nfor nonsmooth weakly convex functions in $O(\\epsilon^{-2}\\log(d)^4)$\niterations, where $d$ is the dimension of the problem.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2102.02837v3", "cate": "cs.LG", "date": "2021-02-04", "updated": "2025-07-19"}
{"id": "2405.20090", "title": "Transfer Attack for Bad and Good: Explain and Boost Adversarial Transferability across Multimodal Large Language Models", "authors": ["Hao Cheng", "Erjia Xiao", "Jiayan Yang", "Jinhao Duan", "Yichi Wang", "Jiahang Cao", "Qiang Zhang", "Le Yang", "Kaidi Xu", "Jindong Gu", "Renjing Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This paper is accepted by ACM MM 2025", "url": "http://arxiv.org/abs/2405.20090v5", "summary": "Multimodal Large Language Models (MLLMs) demonstrate exceptional performance\nin cross-modality interaction, yet they also suffer adversarial\nvulnerabilities. In particular, the transferability of adversarial examples\nremains an ongoing challenge. In this paper, we specifically analyze the\nmanifestation of adversarial transferability among MLLMs and identify the key\nfactors that influence this characteristic. We discover that the\ntransferability of MLLMs exists in cross-LLM scenarios with the same vision\nencoder and indicate \\underline{\\textit{two key Factors}} that may influence\ntransferability. We provide two semantic-level data augmentation methods,\nAdding Image Patch (AIP) and Typography Augment Transferability Method (TATM),\nwhich boost the transferability of adversarial examples across MLLMs. To\nexplore the potential impact in the real world, we utilize two tasks that can\nhave both negative and positive societal impacts: \\ding{182} Harmful Content\nInsertion and \\ding{183} Information Protection.", "comment": "This paper is accepted by ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2405.20090v5", "cate": "cs.CV", "date": "2024-05-30", "updated": "2025-07-21"}
{"id": "2311.16789", "title": "A Survey of the Evolution of Language Model-Based Dialogue Systems: Data, Task and Models", "authors": ["Hongru Wang", "Lingzhi Wang", "Yiming Du", "Liang Chen", "Jingyan Zhou", "Yufei Wang", "Kam-Fai Wong"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2311.16789v2", "summary": "Dialogue systems (DS), including the task-oriented dialogue system (TOD) and\nthe open-domain dialogue system (ODD), have always been a fundamental task in\nnatural language processing (NLP), allowing various applications in practice.\nOwing to sophisticated training and well-designed model architecture, language\nmodels (LM) are usually adopted as the necessary backbone to build the dialogue\nsystem. Consequently, every breakthrough in LM brings about a shift in learning\nparadigm and research attention within dialogue system, especially the\nappearance of pre-trained language models (PLMs) and large language models\n(LLMs). In this paper, we take a deep look at the history of the dialogue\nsystem, especially its special relationship with the advancements of language\nmodels. Thus, our survey offers a systematic perspective, categorizing\ndifferent stages in a chronological order aligned with LM breakthroughs,\nproviding a comprehensive review of state-of-the-art research outcomes. What's\nmore, we turn our attention to emerging topics and engage in a discussion on\nopen challenges, providing valuable insights into the future directions for\nLLM-based dialogue systems. In summary, this survey delves into the dynamic\ninterplay between language models and dialogue systems, unraveling the\nevolutionary path of this essential relationship. Through this exploration, we\npave the way for a deeper comprehension of the field, guiding future\ndevelopments in LM-based dialogue systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2311.16789v2", "cate": "cs.CL", "date": "2023-11-28", "updated": "2025-07-20"}
{"id": "2302.07409", "title": "Quantum Learning Theory Beyond Batch Binary Classification", "authors": ["Preetham Mohan", "Ambuj Tewari"], "categories": ["cs.LG", "cs.CC", "quant-ph", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      36 pages, 2 figures, 2 tables; v5: accepted for publication in Quantum;", "url": "http://arxiv.org/abs/2302.07409v5", "summary": "Arunachalam and de Wolf (2018) showed that the sample complexity of quantum\nbatch learning of boolean functions, in the realizable and agnostic settings,\nhas the same form and order as the corresponding classical sample complexities.\nIn this paper, we extend this, ostensibly surprising, message to batch\nmulticlass learning, online boolean learning, and online multiclass learning.\nFor our online learning results, we first consider an adaptive adversary\nvariant of the classical model of Dawid and Tewari (2022). Then, we introduce\nthe first (to the best of our knowledge) model of online learning with quantum\nexamples.", "comment": "36 pages, 2 figures, 2 tables; v5: accepted for publication in\n  Quantum;", "pdf_url": "http://arxiv.org/pdf/2302.07409v5", "cate": "cs.LG", "date": "2023-02-15", "updated": "2025-07-21"}
{"id": "2406.03262", "title": "A Comprehensive Library for Benchmarking Multi-class Visual Anomaly Detection", "authors": ["Jiangning Zhang", "Haoyang He", "Zhenye Gan", "Qingdong He", "Yuxuan Cai", "Zhucun Xue", "Yabiao Wang", "Chengjie Wang", "Lei Xie", "Yong Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.03262v5", "summary": "Visual anomaly detection aims to identify anomalous regions in images through\nunsupervised learning paradigms, with increasing application demand and value\nin fields such as industrial inspection and medical lesion detection. Despite\nsignificant progress in recent years, there is a lack of comprehensive\nbenchmarks to adequately evaluate the performance of various mainstream methods\nacross different datasets under the practical multi-class setting. The absence\nof standardized experimental setups can lead to potential biases in training\nepochs, resolution, and metric results, resulting in erroneous conclusions.\nThis paper addresses this issue by proposing a comprehensive visual anomaly\ndetection benchmark, ADer, which is a modular framework that is highly\nextensible for new methods. The benchmark includes multiple datasets from\nindustrial and medical domains, implementing fifteen state-of-the-art methods\nand nine comprehensive metrics. Additionally, we have proposed the GPU-assisted\nADEval package to address the slow evaluation problem of metrics like\ntime-consuming mAU-PRO on large-scale data, significantly reducing evaluation\ntime by more than 1000-fold. Through extensive experimental results, we\nobjectively reveal the strengths and weaknesses of different methods and\nprovide insights into the challenges and future directions of multi-class\nvisual anomaly detection. We hope that ADer will become a valuable resource for\nresearchers and practitioners in the field, promoting the development of more\nrobust and generalizable anomaly detection systems. Full codes are open-sourced\nat https://github.com/zhangzjn/ader.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.03262v5", "cate": "cs.CV", "date": "2024-06-05", "updated": "2025-07-20"}
{"id": "2404.07053", "title": "Meta4XNLI: A Crosslingual Parallel Corpus for Metaphor Detection and Interpretation", "authors": ["Elisa Sanchez-Bayona", "Rodrigo Agerri"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.07053v3", "summary": "Metaphors are a ubiquitous but often overlooked part of everyday language. As\na complex cognitive-linguistic phenomenon, they provide a valuable means to\nevaluate whether language models can capture deeper aspects of meaning,\nincluding semantic, pragmatic, and cultural context. In this work, we present\nMeta4XNLI, the first parallel dataset for Natural Language Inference (NLI)\nnewly annotated for metaphor detection and interpretation in both English and\nSpanish. Meta4XNLI facilitates the comparison of encoder- and decoder-based\nmodels in detecting and understanding metaphorical language in multilingual and\ncross-lingual settings. Our results show that fine-tuned encoders outperform\ndecoders-only LLMs in metaphor detection. Metaphor interpretation is evaluated\nvia the NLI framework with comparable performance of masked and autoregressive\nmodels, which notably decreases when the inference is affected by metaphorical\nlanguage. Our study also finds that translation plays an important role in the\npreservation or loss of metaphors across languages, introducing shifts that\nmight impact metaphor occurrence and model performance. These findings\nunderscore the importance of resources like Meta4XNLI for advancing the\nanalysis of the capabilities of language models and improving our understanding\nof metaphor processing across languages. Furthermore, the dataset offers\npreviously unavailable opportunities to investigate metaphor interpretation,\ncross-lingual metaphor transferability, and the impact of translation on the\ndevelopment of multilingual annotated resources.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.07053v3", "cate": "cs.CL", "date": "2024-04-10", "updated": "2025-07-21"}
{"id": "2306.10081", "title": "Optimizer's Information Criterion: Dissecting and Correcting Bias in Data-Driven Optimization", "authors": ["Garud Iyengar", "Henry Lam", "Tianyu Wang"], "categories": ["cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2306.10081v4", "summary": "In data-driven optimization, the sample performance of the obtained decision\ntypically incurs an optimistic bias against the true performance, a phenomenon\ncommonly known as the Optimizer's Curse and intimately related to overfitting\nin machine learning. Common techniques to correct this bias, such as\ncross-validation, require repeatedly solving additional optimization problems\nand are therefore computationally expensive. We develop a general bias\ncorrection approach, building on what we call Optimizer's Information Criterion\n(OIC), that directly approximates the first-order bias and does not require\nsolving any additional optimization problems. Our OIC generalizes the\ncelebrated Akaike Information Criterion to evaluate the objective performance\nin data-driven optimization, which crucially involves not only model fitting\nbut also its interplay with the downstream optimization. As such it can be used\nfor decision selection instead of only model selection. We apply our approach\nto a range of data-driven optimization formulations comprising empirical and\nparametric models, their regularized counterparts, and furthermore contextual\noptimization. Finally, we provide numerical validation on the superior\nperformance of our approach under synthetic and real-world datasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2306.10081v4", "cate": "cs.LG", "date": "2023-06-16", "updated": "2025-07-21"}
{"id": "2406.06703", "title": "Video-based Exercise Classification and Activated Muscle Group Prediction with Hybrid X3D-SlowFast Network", "authors": ["Manvik Pasula", "Pramit Saha"], "categories": ["cs.CV", "cs.LG", "I.2.10; I.4.8"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      13 pages, 1 figure, submitted to Nature Scientific Reports", "url": "http://arxiv.org/abs/2406.06703v2", "summary": "This paper introduces a simple yet effective strategy for exercise\nclassification and muscle group activation prediction (MGAP). These tasks have\nsignificant implications for personal fitness, facilitating more affordable,\naccessible, safer, and simpler exercise routines. This is particularly relevant\nfor novices and individuals with disabilities. Previous research in the field\nis mostly dominated by the reliance on mounted sensors and a limited scope of\nexercises, reducing practicality for everyday use. Furthermore, existing MGAP\nmethodologies suffer from a similar dependency on sensors and a restricted\nrange of muscle groups, often excluding strength training exercises, which are\npivotal for a comprehensive fitness regimen. Addressing these limitations, our\nresearch employs a video-based deep learning framework that encompasses a broad\nspectrum of exercises and muscle groups, including those vital for strength\ntraining. Utilizing the \"Workout/Exercises Video\" dataset, our approach\nintegrates the X3D and SlowFast video activity recognition models in an\neffective way to enhance exercise classification and MGAP performance. Our\nfindings demonstrate that this hybrid method, obtained via weighted ensemble,\noutperforms existing baseline models in accuracy. Pretrained models play a\ncrucial role in enhancing overall performance, with optimal channel reduction\nvalues for the SlowFast model identified near 10. Through an ablation study\nthat explores fine-tuning, we further elucidate the interrelation between the\ntwo tasks. Our composite model, a weighted-average ensemble of X3D and\nSlowFast, sets a new benchmark in both exercise classification and MGAP across\nall evaluated categories, offering a robust solution to the limitations of\nprevious approaches.", "comment": "13 pages, 1 figure, submitted to Nature Scientific Reports", "pdf_url": "http://arxiv.org/pdf/2406.06703v2", "cate": "cs.CV", "date": "2024-06-10", "updated": "2025-07-20"}
{"id": "2405.01663", "title": "Oversmoothing Alleviation in Graph Neural Networks: A Survey and Unified View", "authors": ["Yufei Jin", "Xingquan Zhu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      16 pages; Published at Knowledge and Information Systems Journal", "url": "http://arxiv.org/abs/2405.01663v2", "summary": "Oversmoothing is a common challenge in learning graph neural networks (GNN),\nwhere, as layers increase, embedding features learned from GNNs quickly become\nsimilar or indistinguishable, making them incapable of differentiating network\nproximity. A GNN with shallow layer architectures can only learn short-term\nrelation or localized structure information, limiting its power of learning\nlong-term connection, evidenced by their inferior learning performance on\nheterophilous graphs. Tackling oversmoothing is crucial for harnessing\ndeep-layer architectures for GNNs. To date, many methods have been proposed to\nalleviate oversmoothing. The vast difference behind their design principles,\ncombined with graph complications, make it difficult to understand and even\ncompare the difference between different approaches in tackling the\noversmoothing. In this paper, we propose ATNPA, a unified view with five key\nsteps: Augmentation, Transformation, Normalization, Propagation, and\nAggregation, to summarize GNN oversmoothing alleviation approaches. We first\npropose a taxonomy for GNN oversmoothing alleviation which includes three\nthemes to tackle oversmoothing. After that, we separate all methods into six\ncategories, followed by detailed reviews of representative methods, including\ntheir relation to ATNPA, and discussion of their niche, strength, and weakness.\nThe review not only draws an in-depth understanding of existing methods in the\nfield but also shows a clear road map for future study.", "comment": "16 pages; Published at Knowledge and Information Systems Journal", "pdf_url": "http://arxiv.org/pdf/2405.01663v2", "cate": "cs.LG", "date": "2024-05-02", "updated": "2025-07-18"}
{"id": "2306.12033", "title": "Self-Tuning Self-Supervised Image Anomaly Detection", "authors": ["Jaemin Yoo", "Lingxiao Zhao", "Leman Akoglu"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to KDD 2025", "url": "http://arxiv.org/abs/2306.12033v3", "summary": "Self-supervised learning (SSL) has emerged as a promising paradigm that\npresents supervisory signals to real-world problems, bypassing the extensive\ncost of manual labeling. Consequently, self-supervised anomaly detection (SSAD)\nhas seen a recent surge of interest, since SSL is especially attractive for\nunsupervised tasks. However, recent works have reported that the choice of a\ndata augmentation function has significant impact on the accuracy of SSAD,\nposing augmentation search as an essential but nontrivial problem due to lack\nof labeled validation data. In this paper, we introduce ST-SSAD, the first\nunsupervised approach to end-to-end augmentation tuning for SSAD. To this end,\nour work presents two key contributions. The first is a new unsupervised\nvalidation loss that quantifies the alignment between augmented training data\nand unlabeled validation data. The second is new differentiable augmentation\nfunctions, allowing data augmentation hyperparameter(s) to be tuned in an\nend-to-end manner. Experiments on two testbeds with semantic class anomalies\nand subtle industrial defects show that ST-SSAD gives significant performance\ngains over existing works. All our code and testbeds are available at\nhttps://github.com/jaeminyoo/ST-SSAD.", "comment": "Accepted to KDD 2025", "pdf_url": "http://arxiv.org/pdf/2306.12033v3", "cate": "cs.LG", "date": "2023-06-21", "updated": "2025-07-21"}
{"id": "2407.15219", "title": "Efficient Visual Transformer by Learnable Token Merging", "authors": ["Yancheng Wang", "Yingzhen Yang"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE TPAMI", "url": "http://arxiv.org/abs/2407.15219v2", "summary": "Self-attention and transformers have been widely used in deep learning.\nRecent efforts have been devoted to incorporating transformer blocks into\ndifferent neural architectures, including those with convolutions, leading to\nvarious visual transformers for computer vision tasks. In this paper, we\npropose a novel and compact transformer block, Transformer with Learnable Token\nMerging (LTM), or LTM-Transformer. LTM-Transformer performs token merging in a\nlearnable scheme. LTM-Transformer is compatible with many popular and compact\ntransformer networks, and it reduces the FLOPs and the inference time of the\nvisual transformers while maintaining or even improving the prediction\naccuracy. In the experiments, we replace all the transformer blocks in popular\nvisual transformers, including MobileViT, EfficientViT, ViT, and Swin, with\nLTM-Transformer blocks, leading to LTM-Transformer networks with different\nbackbones. The LTM-Transformer is motivated by reduction of Information\nBottleneck, and a novel and separable variational upper bound for the IB loss\nis derived. The architecture of the mask module in our LTM blocks, which\ngenerates the token merging mask, is designed to reduce the derived upper bound\nfor the IB loss. Extensive results on computer vision tasks evidence that\nLTM-Transformer renders compact and efficient visual transformers with\ncomparable or much better prediction accuracy than the original visual\ntransformers. The code of the LTM-Transformer is available at\nhttps://github.com/Statistical-Deep-Learning/LTM}", "comment": "Accepted by IEEE TPAMI", "pdf_url": "http://arxiv.org/pdf/2407.15219v2", "cate": "cs.CV", "date": "2024-07-21", "updated": "2025-07-20"}
{"id": "2405.14629", "title": "Which Experiences Are Influential for RL Agents? Efficiently Estimating The Influence of Experiences", "authors": ["Takuya Hiraoka", "Guanquan Wang", "Takashi Onishi", "Yoshimasa Tsuruoka"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      RLC 2025. Source code: this https URL Poster: this https URL Slides: this https URL", "url": "http://arxiv.org/abs/2405.14629v3", "summary": "In reinforcement learning (RL) with experience replay, experiences stored in\na replay buffer influence the RL agent's performance. Information about how\nthese experiences influence the agent's performance is valuable for various\npurposes, such as identifying experiences that negatively influence\nunderperforming agents. One method for estimating the influence of experiences\nis the leave-one-out (LOO) method. However, this method is usually\ncomputationally prohibitive. In this paper, we present Policy Iteration with\nTurn-over Dropout (PIToD), which efficiently estimates the influence of\nexperiences. We evaluate how correctly PIToD estimates the influence of\nexperiences and its efficiency compared to LOO. We then apply PIToD to amend\nunderperforming RL agents, i.e., we use PIToD to estimate negatively\ninfluential experiences for the RL agents and to delete the influence of these\nexperiences. We show that RL agents' performance is significantly improved via\namendments with PIToD.", "comment": "RLC 2025. Source code:\n  https://github.com/TakuyaHiraoka/Which-Experiences-Are-Influential-for-RL-Agents\n  Poster:\n  https://drive.google.com/file/d/1fqd5UPUNOQniG-CshmdFFPxEG9m7W4hS/view?usp=sharing\n  Slides:\n  https://drive.google.com/file/d/1JjOMvA-oF7bas2OJmO_en6mJAtNGoLjs/view?usp=sharing", "pdf_url": "http://arxiv.org/pdf/2405.14629v3", "cate": "cs.LG", "date": "2024-05-23", "updated": "2025-07-19"}
{"id": "2311.14077", "title": "RetroDiff: Retrosynthesis as Multi-stage Distribution Interpolation", "authors": ["Yiming Wang", "Yuxuan Song", "Yiqun Wang", "Minkai Xu", "Rui Wang", "Hao Zhou", "Wei-Ying Ma"], "categories": ["cs.LG", "q-bio.QM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by AISTATS 2025", "url": "http://arxiv.org/abs/2311.14077v2", "summary": "Retrosynthesis poses a key challenge in biopharmaceuticals, aiding chemists\nin finding appropriate reactant molecules for given product molecules. With\nreactants and products represented as 2D graphs, retrosynthesis constitutes a\nconditional graph-to-graph (G2G) generative task. Inspired by advancements in\ndiscrete diffusion models for graph generation, we aim to design a\ndiffusion-based method to address this problem. However, integrating a\ndiffusion-based G2G framework while retaining essential chemical reaction\ntemplate information presents a notable challenge. Our key innovation involves\na multi-stage diffusion process. We decompose the retrosynthesis procedure to\nfirst sample external groups from the dummy distribution given products, then\ngenerate external bonds to connect products and generated groups.\nInterestingly, this generation process mirrors the reverse of the widely\nadapted semi-template retrosynthesis workflow, \\emph{i.e.} from reaction center\nidentification to synthon completion. Based on these designs, we introduce\nRetrosynthesis Diffusion (RetroDiff), a novel diffusion-based method for the\nretrosynthesis task. Experimental results demonstrate that RetroDiff surpasses\nall semi-template methods in accuracy, and outperforms template-based and\ntemplate-free methods in large-scale scenarios and molecular validity,\nrespectively. Code: https://github.com/Alsace08/RetroDiff.", "comment": "Accepted by AISTATS 2025", "pdf_url": "http://arxiv.org/pdf/2311.14077v2", "cate": "cs.LG", "date": "2023-11-23", "updated": "2025-07-21"}
{"id": "2407.21517", "title": "A Simple Low-bit Quantization Framework for Video Snapshot Compressive Imaging", "authors": ["Miao Cao", "Lishun Wang", "Huan Wang", "Xin Yuan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      18 pages, Accepted by ECCV 2024", "url": "http://arxiv.org/abs/2407.21517v2", "summary": "Video Snapshot Compressive Imaging (SCI) aims to use a low-speed 2D camera to\ncapture high-speed scene as snapshot compressed measurements, followed by a\nreconstruction algorithm to reconstruct the high-speed video frames.\nState-of-the-art (SOTA) deep learning-based algorithms have achieved impressive\nperformance, yet with heavy computational workload. Network quantization is a\npromising way to reduce computational cost. However, a direct low-bit\nquantization will bring large performance drop. To address this challenge, in\nthis paper, we propose a simple low-bit quantization framework (dubbed Q-SCI)\nfor the end-to-end deep learning-based video SCI reconstruction methods which\nusually consist of a feature extraction, feature enhancement, and video\nreconstruction module. Specifically, we first design a high-quality feature\nextraction module and a precise video reconstruction module to extract and\npropagate high-quality features in the low-bit quantized model. In addition, to\nalleviate the information distortion of the Transformer branch in the quantized\nfeature enhancement module, we introduce a shift operation on the query and key\ndistributions to further bridge the performance gap. Comprehensive experimental\nresults manifest that our Q-SCI framework can achieve superior performance,\ne.g., 4-bit quantized EfficientSCI-S derived by our Q-SCI framework can\ntheoretically accelerate the real-valued EfficientSCI-S by 7.8X with only 2.3%\nperformance gap on the simulation testing datasets. Code is available at\nhttps://github.com/mcao92/QuantizedSCI.", "comment": "18 pages, Accepted by ECCV 2024", "pdf_url": "http://arxiv.org/pdf/2407.21517v2", "cate": "cs.CV", "date": "2024-07-31", "updated": "2025-07-21"}
{"id": "2406.12644", "title": "Hierarchical Prompting Taxonomy: A Universal Evaluation Framework for Large Language Models Aligned with Human Cognitive Principles", "authors": ["Devichand Budagam", "Ashutosh Kumar", "Mahsa Khoshnoodi", "Sankalp KJ", "Vinija Jain", "Aman Chadha"], "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      18 pages, 9 figures, KDD workshop on Prompt Optimization 2025", "url": "http://arxiv.org/abs/2406.12644v5", "summary": "Assessing the effectiveness of large language models (LLMs) in performing\ndifferent tasks is crucial for understanding their strengths and weaknesses.\nThis paper presents Hierarchical Prompting Taxonomy (HPT), grounded on human\ncognitive principles and designed to assess LLMs by examining the cognitive\ndemands of various tasks. The HPT utilizes the Hierarchical Prompting Framework\n(HPF), which structures five unique prompting strategies in a hierarchical\norder based on their cognitive requirement on LLMs when compared to human\nmental capabilities. It assesses the complexity of tasks with the Hierarchical\nPrompting Index (HPI), which demonstrates the cognitive competencies of LLMs\nacross diverse datasets and offers insights into the cognitive demands that\ndatasets place on different LLMs. This approach enables a comprehensive\nevaluation of an LLMs problem solving abilities and the intricacy of a dataset,\noffering a standardized metric for task complexity. Extensive experiments with\nmultiple datasets and LLMs show that HPF enhances LLM performance by 2% to 63%\ncompared to baseline performance, with GSM8k being the most cognitively complex\ntask among reasoning and coding tasks with an average HPI of 3.20 confirming\nthe effectiveness of HPT. To support future research and reproducibility in\nthis domain, the implementations of HPT and HPF are available here.", "comment": "18 pages, 9 figures, KDD workshop on Prompt Optimization 2025", "pdf_url": "http://arxiv.org/pdf/2406.12644v5", "cate": "cs.CL", "date": "2024-06-18", "updated": "2025-07-21"}
{"id": "2312.16242", "title": "ShiftKD: Benchmarking Knowledge Distillation under Distribution Shift", "authors": ["Songming Zhang", "Yuxiao Luo", "Ziyu Lyu", "Xiaofeng Chen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Code: this https URL", "url": "http://arxiv.org/abs/2312.16242v3", "summary": "Knowledge Distillation (KD) transfers knowledge from large models to small\nmodels and has recently achieved remarkable success. However, the reliability\nof existing KD methods in real-world applications, especially under\ndistribution shift, remains underexplored. Distribution shift refers to the\ndata distribution drifts between the training and testing phases, and this can\nadversely affect the efficacy of KD. In this paper, we propose a unified and\nsystematic framework \\textsc{ShiftKD} to benchmark KD against two general\ndistributional shifts: diversity and correlation shift. The evaluation\nbenchmark covers more than 30 methods from algorithmic, data-driven, and\noptimization perspectives for five benchmark datasets. Our development of\n\\textsc{ShiftKD} conducts extensive experiments and reveals strengths and\nlimitations of current SOTA KD methods. More importantly, we thoroughly analyze\nkey factors in student model training process, including data augmentation,\npruning methods, optimizers, and evaluation metrics. We believe\n\\textsc{ShiftKD} could serve as an effective benchmark for assessing KD in\nreal-world scenarios, thus driving the development of more robust KD methods in\nresponse to evolving demands. The code will be made available upon publication.", "comment": "Code:https://github.com/ZZhangsm/OOKD", "pdf_url": "http://arxiv.org/pdf/2312.16242v3", "cate": "cs.LG", "date": "2023-12-25", "updated": "2025-07-19"}
{"id": "2408.10789", "title": "Self-supervised Learning of Hybrid Part-aware 3D Representations of 2D Gaussians and Superquadrics", "authors": ["Zhirui Gao", "Renjiao Yi", "Yuhang Huang", "Wei Chen", "Chenyang Zhu", "Kai Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025. Code: this https URL", "url": "http://arxiv.org/abs/2408.10789v4", "summary": "Low-level 3D representations, such as point clouds, meshes, NeRFs and 3D\nGaussians, are commonly used for modeling 3D objects and scenes. However,\ncognitive studies indicate that human perception operates at higher levels and\ninterprets 3D environments by decomposing them into meaningful structural\nparts, rather than low-level elements like points or voxels. Structured\ngeometric decomposition enhances scene interpretability and facilitates\ndownstream tasks requiring component-level manipulation. In this work, we\nintroduce PartGS, a self-supervised part-aware reconstruction framework that\nintegrates 2D Gaussians and superquadrics to parse objects and scenes into an\ninterpretable decomposition, leveraging multi-view image inputs to uncover 3D\nstructural information. Our method jointly optimizes superquadric meshes and\nGaussians by coupling their parameters within a hybrid representation. On one\nhand, superquadrics enable the representation of a wide range of shape\nprimitives, facilitating flexible and meaningful decompositions. On the other\nhand, 2D Gaussians capture detailed texture and geometric details, ensuring\nhigh-fidelity appearance and geometry reconstruction. Operating in a\nself-supervised manner, our approach demonstrates superior performance compared\nto state-of-the-art methods across extensive experiments on the DTU, ShapeNet,\nand real-world datasets.", "comment": "Accepted by ICCV 2025. Code: https://github.com/zhirui-gao/PartGS", "pdf_url": "http://arxiv.org/pdf/2408.10789v4", "cate": "cs.CV", "date": "2024-08-20", "updated": "2025-07-19"}
{"id": "2407.07668", "title": "How to Leverage Predictive Uncertainty Estimates for Reducing Catastrophic Forgetting in Online Continual Learning", "authors": ["Giuseppe Serra", "Ben Werner", "Florian Buettner"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published in Transactions on Machine Learning Research (March 2025)", "url": "http://arxiv.org/abs/2407.07668v3", "summary": "Many real-world applications require machine-learning models to be able to\ndeal with non-stationary data distributions and thus learn autonomously over an\nextended period of time, often in an online setting. One of the main challenges\nin this scenario is the so-called catastrophic forgetting (CF) for which the\nlearning model tends to focus on the most recent tasks while experiencing\npredictive degradation on older ones. In the online setting, the most effective\nsolutions employ a fixed-size memory buffer to store old samples used for\nreplay when training on new tasks. Many approaches have been presented to\ntackle this problem. However, it is not clear how predictive uncertainty\ninformation for memory management can be leveraged in the most effective manner\nand conflicting strategies are proposed to populate the memory. Are the\neasiest-to-forget or the easiest-to-remember samples more effective in\ncombating CF? Starting from the intuition that predictive uncertainty provides\nan idea of the samples' location in the decision space, this work presents an\nin-depth analysis of different uncertainty estimates and strategies for\npopulating the memory. The investigation provides a better understanding of the\ncharacteristics data points should have for alleviating CF. Then, we propose an\nalternative method for estimating predictive uncertainty via the generalised\nvariance induced by the negative log-likelihood. Finally, we demonstrate that\nthe use of predictive uncertainty measures helps in reducing CF in different\nsettings.", "comment": "Published in Transactions on Machine Learning Research (March 2025)", "pdf_url": "http://arxiv.org/pdf/2407.07668v3", "cate": "cs.LG", "date": "2024-07-10", "updated": "2025-07-21"}
{"id": "2402.00849", "title": "Score-based Causal Representation Learning: Linear and General Transformations", "authors": ["Burak Varıcı", "Emre Acartürk", "Karthikeyan Shanmugam", "Abhishek Kumar", "Ali Tajer"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published in Journal of Machine Learning Research (5/25)", "url": "http://arxiv.org/abs/2402.00849v5", "summary": "This paper addresses intervention-based causal representation learning (CRL)\nunder a general nonparametric latent causal model and an unknown transformation\nthat maps the latent variables to the observed variables. Linear and general\ntransformations are investigated. The paper addresses both the identifiability\nand achievability aspects. Identifiability refers to determining\nalgorithm-agnostic conditions that ensure the recovery of the true latent\ncausal variables and the underlying latent causal graph. Achievability refers\nto the algorithmic aspects and addresses designing algorithms that achieve\nidentifiability guarantees. By drawing novel connections between score\nfunctions (i.e., the gradients of the logarithm of density functions) and CRL,\nthis paper designs a score-based class of algorithms that ensures both\nidentifiability and achievability. First, the paper focuses on linear\ntransformations and shows that one stochastic hard intervention per node\nsuffices to guarantee identifiability. It also provides partial identifiability\nguarantees for soft interventions, including identifiability up to mixing with\nparents for general causal models and perfect recovery of the latent graph for\nsufficiently nonlinear causal models. Secondly, it focuses on general\ntransformations and demonstrates that two stochastic hard interventions per\nnode are sufficient for identifiability. This is achieved by defining a\ndifferentiable loss function whose global optima ensure identifiability for\ngeneral CRL. Notably, one does not need to know which pair of interventional\nenvironments has the same node intervened. Finally, the theoretical results are\nempirically validated via experiments on structured synthetic data and image\ndata.", "comment": "Published in Journal of Machine Learning Research (5/25)", "pdf_url": "http://arxiv.org/pdf/2402.00849v5", "cate": "cs.LG", "date": "2024-02-01", "updated": "2025-07-19"}
{"id": "2408.14961", "title": "CVPT: Cross Visual Prompt Tuning", "authors": ["Lingyun Huang", "Jianxu Mao", "Junfei Yi", "Ziming Tao", "Yaonan Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.14961v2", "summary": "Parameter-Efficient Fine-Tuning (PEFT) has emerged to mitigate the\ncomputational demands of large-scale models. Within computer vision,\nadapter-based PEFT methods are often favored over prompt-based approaches like\nVisual Prompt Tuning (VPT) due to the latter's performance and efficiency\nlimitations. Our analysis reveals that VPT's shortcomings stem from its prompt\ndeployment strategy, which can distort the model's inherent self-attention\nmechanism. To address this, we propose Cross Visual Prompt Tuning (CVPT). CVPT\nintroduces a cross-attention module to directly model interactions between\nprompts and image tokens. This design decouples the prompts from the input\nsequence, preserving the original self-attention integrity while enabling\nefficient feature integration. Furthermore, we employ a weight-sharing\nmechanism for cross-attention initialization, which enhances representative\ncapability without a large parameter overhead. Extensive experiments across 25\ndatasets show that CVPT significantly outperforms VPT. For instance, on the\nVTAB-1K benchmark, CVPT achieves over 4% higher average accuracy, rivaling\nleading adapter-based methods in both performance and efficiency. Our work\nconfirms that prompt-based methods can achieve exceptional results in visual\nfine-tuning. The code is available at https://github.com/Lingyun0419/CVPT", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.14961v2", "cate": "cs.CV", "date": "2024-08-27", "updated": "2025-07-19"}
{"id": "2407.09693", "title": "A Mathematical Framework and a Suite of Learning Techniques for Neural-Symbolic Systems", "authors": ["Charles Dickens", "Connor Pryor", "Changyu Gao", "Alon Albalak", "Eriq Augustine", "William Wang", "Stephen Wright", "Lise Getoor"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.09693v2", "summary": "The field of Neural-Symbolic (NeSy) systems is growing rapidly. Proposed\napproaches show great promise in achieving symbiotic unions of neural and\nsymbolic methods. However, a unifying framework is needed to organize common\nNeSy modeling patterns and develop general learning approaches. In this paper,\nwe introduce Neural-Symbolic Energy-Based Models (NeSy-EBMs), a unifying\nmathematical framework for discriminative and generative NeSy modeling.\nImportantly, NeSy-EBMs allow the derivation of general expressions for\ngradients of prominent learning losses, and we introduce a suite of four\nlearning approaches that leverage methods from multiple domains, including\nbilevel and stochastic policy optimization. Finally, we ground the NeSy-EBM\nframework with Neural Probabilistic Soft Logic (NeuPSL), an open-source\nNeSy-EBM library designed for scalability and expressivity, facilitating the\nreal-world application of NeSy systems. Through extensive empirical analysis\nacross multiple datasets, we demonstrate the practical advantages of NeSy-EBMs\nin various tasks, including image classification, graph node labeling,\nautonomous vehicle situation awareness, and question answering.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.09693v2", "cate": "cs.LG", "date": "2024-07-12", "updated": "2025-07-20"}
{"id": "2402.07851", "title": "Comparing skill of historical rainfall data based monsoon rainfall prediction in India with NWP forecasts", "authors": ["Apoorva Narula", "Aastha Jain", "Jatin Batra", "MN Rajeevan", "Sandeep Juneja"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.07851v2", "summary": "The Indian summer monsoon is a highly complex and critical weather system\nthat directly affects the livelihoods of over a billion people across the\nIndian subcontinent. Accurate short-term forecasting remains a major scientific\nchallenge due to the monsoon's intrinsic nonlinearity and its sensitivity to\nmulti-scale drivers, including local land-atmosphere interactions and\nlarge-scale ocean-atmosphere phenomena. In this study, we address the problem\nof forecasting daily rainfall across India during the summer months, focusing\non both one-day and three-day lead times. We use Autoformers - deep learning\ntransformer-based architectures designed for time series forecasting. These are\ntrained on historical gridded precipitation data from the Indian Meteorological\nDepartment (1901--2023) at spatial resolutions of $0.25^\\circ \\times\n0.25^\\circ$, as well as $1^\\circ \\times 1^\\circ$. The models also incorporate\nauxiliary meteorological variables from ECMWFs reanalysis datasets, namely,\ncloud cover, humidity, temperature, soil moisture, vorticity, and wind speed.\nForecasts at $0.25^\\circ \\times 0.25^\\circ$ are benchmarked against ECMWFs\nHigh-Resolution Ensemble System (HRES), widely regarded as the most accurate\nnumerical weather predictor, and at $1^\\circ \\times 1^\\circ $ with those from\nNational Centre for Environmental Prediction (NCEP). We conduct both nationwide\nevaluations and localized analyses for major Indian cities. Our results\nindicate that transformer-based deep learning models consistently outperform\nboth HRES and NCEP, as well as other climatological baselines. Specifically,\ncompared to our model, forecasts from HRES and NCEP model have about 22\\% and\n43\\% higher error, respectively, for a single day prediction, and over 27\\% and\n66\\% higher error respectively, for a three day prediction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.07851v2", "cate": "cs.LG", "date": "2024-02-12", "updated": "2025-07-18"}
{"id": "2409.03034", "title": "MDNF: Multi-Diffusion-Nets for Neural Fields on Meshes", "authors": ["Avigail Cohen Rimon", "Tal Shnitzer", "Mirela Ben Chen"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to SGP 2025 (Symposium on Geometry Processing)", "url": "http://arxiv.org/abs/2409.03034v2", "summary": "We propose a novel framework for representing neural fields on triangle\nmeshes that is multi-resolution across both spatial and frequency domains.\nInspired by the Neural Fourier Filter Bank (NFFB), our architecture decomposes\nthe spatial and frequency domains by associating finer spatial resolution\nlevels with higher frequency bands, while coarser resolutions are mapped to\nlower frequencies. To achieve geometry-aware spatial decomposition we leverage\nmultiple DiffusionNet components, each associated with a different spatial\nresolution level. Subsequently, we apply a Fourier feature mapping to encourage\nfiner resolution levels to be associated with higher frequencies. The final\nsignal is composed in a wavelet-inspired manner using a sine-activated MLP,\naggregating higher-frequency signals on top of lower-frequency ones. Our\narchitecture attains high accuracy in learning complex neural fields and is\nrobust to discontinuities, exponential scale variations of the target field,\nand mesh modification. We demonstrate the effectiveness of our approach through\nits application to diverse neural fields, such as synthetic RGB functions, UV\ntexture coordinates, and vertex normals, illustrating different challenges. To\nvalidate our method, we compare its performance against two alternatives,\nshowcasing the advantages of our multi-resolution architecture.", "comment": "Accepted to SGP 2025 (Symposium on Geometry Processing)", "pdf_url": "http://arxiv.org/pdf/2409.03034v2", "cate": "cs.CV", "date": "2024-09-04", "updated": "2025-07-21"}
{"id": "2407.12828", "title": "Why Does New Knowledge Create Messy Ripple Effects in LLMs?", "authors": ["Jiaxin Qin", "Zixuan Zhang", "Manling Li", "Pengfei Yu", "Heng Ji"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.12828v3", "summary": "Extensive previous research has focused on post-training knowledge editing\n(KE) for language models (LMs) to ensure that knowledge remains accurate and\nup-to-date. One desired property and open question in KE is to let edited LMs\ncorrectly handle ripple effects, where LM is expected to answer its logically\nrelated knowledge accurately. In this paper, we answer the question of why most\nKE methods still create messy ripple effects. We conduct extensive analysis and\nidentify a salient indicator, GradSim, that effectively reveals when and why\nupdated knowledge ripples in LMs. GradSim is computed by the cosine similarity\nbetween gradients of the original fact and its related knowledge. We observe a\nstrong positive correlation between ripple effect performance and GradSim\nacross different LMs, KE methods, and evaluation metrics. Further\ninvestigations into three counter-intuitive failure cases (Negation,\nOver-Ripple, Multi-Lingual) of ripple effects demonstrate that these failures\nare often associated with very low GradSim. This finding validates that GradSim\nis an effective indicator of when knowledge ripples in LMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.12828v3", "cate": "cs.CL", "date": "2024-07-02", "updated": "2025-07-20"}
{"id": "2403.12887", "title": "Understanding the training of infinitely deep and wide ResNets with Conditional Optimal Transport", "authors": ["Raphaël Barboni", "Gabriel Peyré", "François-Xavier Vialard"], "categories": ["cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.12887v2", "summary": "We study the convergence of gradient flow for the training of deep neural\nnetworks. If Residual Neural Networks are a popular example of very deep\narchitectures, their training constitutes a challenging optimization problem\ndue notably to the non-convexity and the non-coercivity of the objective. Yet,\nin applications, those tasks are successfully solved by simple optimization\nalgorithms such as gradient descent. To better understand this phenomenon, we\nfocus here on a ``mean-field'' model of infinitely deep and arbitrarily wide\nResNet, parameterized by probability measures over the product set of layers\nand parameters and with constant marginal on the set of layers. Indeed, in the\ncase of shallow neural networks, mean field models have proven to benefit from\nsimplified loss-landscapes and good theoretical guarantees when trained with\ngradient flow for the Wasserstein metric on the set of probability measures.\nMotivated by this approach, we propose to train our model with gradient flow\nw.r.t. the conditional Optimal Transport distance: a restriction of the\nclassical Wasserstein distance which enforces our marginal condition. Relying\non the theory of gradient flows in metric spaces we first show the\nwell-posedness of the gradient flow equation and its consistency with the\ntraining of ResNets at finite width. Performing a local Polyak-\\L{}ojasiewicz\nanalysis, we then show convergence of the gradient flow for well-chosen\ninitializations: if the number of features is finite but sufficiently large and\nthe risk is sufficiently small at initialization, the gradient flow converges\ntowards a global minimizer. This is the first result of this type for\ninfinitely deep and arbitrarily wide ResNets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.12887v2", "cate": "cs.LG", "date": "2024-03-19", "updated": "2025-07-21"}
{"id": "2409.10090", "title": "InteractPro: A Unified Framework for Motion-Aware Image Composition", "authors": ["Weijing Tao", "Xiaofeng Yang", "Miaomiao Cui", "Guosheng Lin"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.10090v2", "summary": "We introduce InteractPro, a comprehensive framework for dynamic motion-aware\nimage composition. At its core is InteractPlan, an intelligent planner that\nleverages a Large Vision Language Model (LVLM) for scenario analysis and object\nplacement, determining the optimal composition strategy to achieve realistic\nmotion effects. Based on each scenario, InteractPlan selects between our two\nspecialized modules: InteractPhys and InteractMotion. InteractPhys employs an\nenhanced Material Point Method (MPM)-based simulation to produce physically\nfaithful and controllable object-scene interactions, capturing diverse and\nabstract events that require true physical modeling. InteractMotion, in\ncontrast, is a training-free method based on pretrained video diffusion.\nTraditional composition approaches suffer from two major limitations: requiring\nmanual planning for object placement and generating static, motionless outputs.\nBy unifying simulation-based and diffusion-based methods under planner\nguidance, InteractPro overcomes these challenges, ensuring richly motion-aware\ncompositions. Extensive quantitative and qualitative evaluations demonstrate\nInteractPro's effectiveness in producing controllable, and coherent\ncompositions across varied scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.10090v2", "cate": "cs.CV", "date": "2024-09-16", "updated": "2025-07-21"}
{"id": "2408.06717", "title": "Proficient Graph Neural Network Design by Accumulating Knowledge on Large Language Models", "authors": ["Jialiang Wang", "Hanmo Liu", "Shimin Di", "Zhili Wang", "Jiachuan Wang", "Lei Chen", "Xiaofang Zhou"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.06717v2", "summary": "High-level automation is increasingly critical in AI, driven by rapid\nadvances in large language models (LLMs) and AI agents. However, LLMs, despite\ntheir general reasoning power, struggle significantly in specialized,\ndata-sensitive tasks such as designing Graph Neural Networks (GNNs). This\ndifficulty arises from (1) the inherent knowledge gaps in modeling the\nintricate, varying relationships between graph properties and suitable\narchitectures and (2) the external noise from misleading descriptive inputs,\noften resulting in generic or even misleading model suggestions. Achieving\nproficiency in designing data-aware models -- defined as the meta-level\ncapability to systematically accumulate, interpret, and apply data-specific\ndesign knowledge -- remains challenging for existing automated approaches, due\nto their inefficient construction and application of meta-knowledge. To achieve\nthe meta-level proficiency, we propose DesiGNN, a knowledge-centered framework\nthat systematically converts past model design experiences into structured,\nfine-grained knowledge priors well fitted to meta-learning with LLMs. To\naccount for the inherent variability and external noise, DesiGNN aligns\nempirical property filtering from extensive benchmarks with adaptive\nelicitation of literature insights via LLMs. By constructing a solid\nmeta-knowledge between unseen graph understanding and known effective\narchitecture patterns, DesiGNN can deliver top-5.77% initial model proposals\nfor unseen datasets within seconds, and achieve consistently superior\nperformance with minimal search costs against baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.06717v2", "cate": "cs.LG", "date": "2024-08-13", "updated": "2025-07-21"}
{"id": "2404.06831", "title": "Generalized Linear Bandits with Limited Adaptivity", "authors": ["Ayush Sawarni", "Nirjhar Das", "Siddharth Barman", "Gaurav Sinha"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted as Spotlight to NeurIPS 2024", "url": "http://arxiv.org/abs/2404.06831v5", "summary": "We study the generalized linear contextual bandit problem within the\nconstraints of limited adaptivity. In this paper, we present two algorithms,\n$\\texttt{B-GLinCB}$ and $\\texttt{RS-GLinCB}$, that address, respectively, two\nprevalent limited adaptivity settings. Given a budget $M$ on the number of\npolicy updates, in the first setting, the algorithm needs to decide upfront $M$\nrounds at which it will update its policy, while in the second setting it can\nadaptively perform $M$ policy updates during its course. For the first setting,\nwe design an algorithm $\\texttt{B-GLinCB}$, that incurs $\\tilde{O}(\\sqrt{T})$\nregret when $M = \\Omega( \\log{\\log T} )$ and the arm feature vectors are\ngenerated stochastically. For the second setting, we design an algorithm\n$\\texttt{RS-GLinCB}$ that updates its policy $\\tilde{O}(\\log^2 T)$ times and\nachieves a regret of $\\tilde{O}(\\sqrt{T})$ even when the arm feature vectors\nare adversarially generated. Notably, in these bounds, we manage to eliminate\nthe dependence on a key instance dependent parameter $\\kappa$, that captures\nnon-linearity of the underlying reward model. Our novel approach for removing\nthis dependence for generalized linear contextual bandits might be of\nindependent interest.", "comment": "Accepted as Spotlight to NeurIPS 2024", "pdf_url": "http://arxiv.org/pdf/2404.06831v5", "cate": "cs.LG", "date": "2024-04-10", "updated": "2025-07-19"}
{"id": "2409.12431", "title": "FlexiTex: Enhancing Texture Generation via Visual Guidance", "authors": ["DaDong Jiang", "Xianghui Yang", "Zibo Zhao", "Sheng Zhang", "Jiaao Yu", "Zeqiang Lai", "Shaoxiong Yang", "Chunchao Guo", "Xiaobo Zhou", "Zhihui Ke"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by AAAI 2025, Project Page: this https URL", "url": "http://arxiv.org/abs/2409.12431v5", "summary": "Recent texture generation methods achieve impressive results due to the\npowerful generative prior they leverage from large-scale text-to-image\ndiffusion models. However, abstract textual prompts are limited in providing\nglobal textural or shape information, which results in the texture generation\nmethods producing blurry or inconsistent patterns. To tackle this, we present\nFlexiTex, embedding rich information via visual guidance to generate a\nhigh-quality texture. The core of FlexiTex is the Visual Guidance Enhancement\nmodule, which incorporates more specific information from visual guidance to\nreduce ambiguity in the text prompt and preserve high-frequency details. To\nfurther enhance the visual guidance, we introduce a Direction-Aware Adaptation\nmodule that automatically designs direction prompts based on different camera\nposes, avoiding the Janus problem and maintaining semantically global\nconsistency. Benefiting from the visual guidance, FlexiTex produces\nquantitatively and qualitatively sound results, demonstrating its potential to\nadvance texture generation for real-world applications.", "comment": "Accepted by AAAI 2025, Project Page:\n  https://patrickddj.github.io/FlexiTex/", "pdf_url": "http://arxiv.org/pdf/2409.12431v5", "cate": "cs.CV", "date": "2024-09-19", "updated": "2025-07-21"}
{"id": "2409.00061", "title": "Enhancing Natural Language Inference Performance with Knowledge Graph for COVID-19 Automated Fact-Checking in Indonesian Language", "authors": ["Arief Purnama Muharram", "Ayu Purwarianti"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Submitted to the Journal of ICT Research and Applications (JICTRA)", "url": "http://arxiv.org/abs/2409.00061v2", "summary": "Automated fact-checking is a key strategy to overcome the spread of COVID-19\nmisinformation on the internet. These systems typically leverage deep learning\napproaches through Natural Language Inference (NLI) to verify the truthfulness\nof information based on supporting evidence. However, one challenge that arises\nin deep learning is performance stagnation due to a lack of knowledge during\ntraining. This study proposes using a Knowledge Graph (KG) as external\nknowledge to enhance NLI performance for automated COVID-19 fact-checking in\nthe Indonesian language. The proposed model architecture comprises three\nmodules: a fact module, an NLI module, and a classifier module. The fact module\nprocesses information from the KG, while the NLI module handles semantic\nrelationships between the given premise and hypothesis. The representation\nvectors from both modules are concatenated and fed into the classifier module\nto produce the final result. The model was trained using the generated\nIndonesian COVID-19 fact-checking dataset and the COVID-19 KG Bahasa Indonesia.\nOur study demonstrates that incorporating KGs can significantly improve NLI\nperformance in fact-checking, achieving the best accuracy of 0.8616. This\nsuggests that KGs are a valuable component for enhancing NLI performance in\nautomated fact-checking.", "comment": "Submitted to the Journal of ICT Research and Applications (JICTRA)", "pdf_url": "http://arxiv.org/pdf/2409.00061v2", "cate": "cs.CL", "date": "2024-08-22", "updated": "2025-07-21"}
{"id": "2405.14620", "title": "Closed-form Solutions: A New Perspective on Solving Differential Equations", "authors": ["Shu Wei", "Yanjie Li", "Lina Yu", "Weijun Li", "Min Wu", "Linjun Sun", "Jingyi Liu", "Hong Qin", "Yusong Deng", "Jufeng Han", "Yan Pang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted as a poster at the 42nd International Conference on Machine Learning (ICML 2025), Vancouver, Canada", "url": "http://arxiv.org/abs/2405.14620v4", "summary": "The quest for analytical solutions to differential equations has\ntraditionally been constrained by the need for extensive mathematical\nexpertise. Machine learning methods like genetic algorithms have shown promise\nin this domain, but are hindered by significant computational time and the\ncomplexity of their derived solutions. This paper introduces SSDE (Symbolic\nSolver for Differential Equations), a novel reinforcement learning-based\napproach that derives symbolic closed-form solutions for various differential\nequations. Evaluations across a diverse set of ordinary and partial\ndifferential equations demonstrate that SSDE outperforms existing machine\nlearning methods, delivering superior accuracy and efficiency in obtaining\nanalytical solutions.", "comment": "Accepted as a poster at the 42nd International Conference on Machine\n  Learning (ICML 2025), Vancouver, Canada", "pdf_url": "http://arxiv.org/pdf/2405.14620v4", "cate": "cs.LG", "date": "2024-05-23", "updated": "2025-07-21"}
{"id": "2410.16824", "title": "PerspectiveNet: Multi-View Perception for Dynamic Scene Understanding", "authors": ["Vinh Nguyen"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages, 2 figures", "url": "http://arxiv.org/abs/2410.16824v2", "summary": "Generating detailed descriptions from multiple cameras and viewpoints is\nchallenging due to the complex and inconsistent nature of visual data. In this\npaper, we introduce PerspectiveNet, a lightweight yet efficient model for\ngenerating long descriptions across multiple camera views. Our approach\nutilizes a vision encoder, a compact connector module to convert visual\nfeatures into a fixed-size tensor, and large language models (LLMs) to harness\nthe strong natural language generation capabilities of LLMs. The connector\nmodule is designed with three main goals: mapping visual features onto LLM\nembeddings, emphasizing key information needed for description generation, and\nproducing a fixed-size feature matrix. Additionally, we augment our solution\nwith a secondary task, the correct frame sequence detection, enabling the model\nto search for the correct sequence of frames to generate descriptions. Finally,\nwe integrate the connector module, the secondary task, the LLM, and a visual\nfeature extraction model into a single architecture, which is trained for the\nTraffic Safety Description and Analysis task. This task requires generating\ndetailed, fine-grained descriptions of events from multiple cameras and\nviewpoints. The resulting model is lightweight, ensuring efficient training and\ninference, while remaining highly effective.", "comment": "6 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2410.16824v2", "cate": "cs.CV", "date": "2024-10-22", "updated": "2025-07-19"}
{"id": "2409.09032", "title": "The unknotting number, hard unknot diagrams, and reinforcement learning", "authors": ["Taylor Applebaum", "Sam Blackwell", "Alex Davies", "Thomas Edlich", "András Juhász", "Marc Lackenby", "Nenad Tomašev", "Daniel Zheng"], "categories": ["math.GT", "cs.AI", "cs.LG", "57K10, 57K14, 68T07, 68T20", "I.2.1; I.2.6; I.2.8"], "primary_category": "Subjects:       Geometric Topology (math.GT)", "pdf_link": null, "comments": "Comments:      30 pages, 17 figures; to appear in Experimental Mathematics", "url": "http://arxiv.org/abs/2409.09032v2", "summary": "We have developed a reinforcement learning agent that often finds a minimal\nsequence of unknotting crossing changes for a knot diagram with up to 200\ncrossings, hence giving an upper bound on the unknotting number. We have used\nthis to determine the unknotting number of 57k knots. We took diagrams of\nconnected sums of such knots with oppositely signed signatures, where the\nsummands were overlaid. The agent has found examples where several of the\ncrossing changes in an unknotting collection of crossings result in hyperbolic\nknots. Based on this, we have shown that, given knots $K$ and $K'$ that satisfy\nsome mild assumptions, there is a diagram of their connected sum and $u(K) +\nu(K')$ unknotting crossings such that changing any one of them results in a\nprime knot. As a by-product, we have obtained a dataset of 2.6 million distinct\nhard unknot diagrams; most of them under 35 crossings. Assuming the additivity\nof the unknotting number, we have determined the unknotting number of 43 at\nmost 12-crossing knots for which the unknotting number is unknown.", "comment": "30 pages, 17 figures; to appear in Experimental Mathematics", "pdf_url": "http://arxiv.org/pdf/2409.09032v2", "cate": "math.GT", "date": "2024-09-13", "updated": "2025-07-19"}
{"id": "2405.20435", "title": "Deep Learning for Computing Convergence Rates of Markov Chains", "authors": ["Yanlin Qu", "Jose Blanchet", "Peter Glynn"], "categories": ["cs.LG", "math.PR", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.20435v2", "summary": "Convergence rate analysis for general state-space Markov chains is\nfundamentally important in areas such as Markov chain Monte Carlo and\nalgorithmic analysis (for computing explicit convergence bounds). This problem,\nhowever, is notoriously difficult because traditional analytical methods often\ndo not generate practically useful convergence bounds for realistic Markov\nchains. We propose the Deep Contractive Drift Calculator (DCDC), the first\ngeneral-purpose sample-based algorithm for bounding the convergence of Markov\nchains to stationarity in Wasserstein distance. The DCDC has two components.\nFirst, inspired by the new convergence analysis framework in Qu, Blanchet and\nGlynn (2023), we introduce the Contractive Drift Equation (CDE), the solution\nof which leads to an explicit convergence bound. Second, we develop an\nefficient neural-network-based CDE solver. Equipped with these two components,\nDCDC solves the CDE and converts the solution into a convergence bound. We\nanalyze the sample complexity of the algorithm and further demonstrate the\neffectiveness of the DCDC by generating convergence bounds for realistic Markov\nchains arising from stochastic processing networks as well as constant\nstep-size stochastic optimization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.20435v2", "cate": "cs.LG", "date": "2024-05-30", "updated": "2025-07-21"}
{"id": "2411.07901", "title": "Fourier Domain Adaptation for Traffic Light Detection in Adverse Weather", "authors": ["Ishaan Gakhar", "Aryesh Guha", "Aryaman Gupta", "Amit Agarwal", "Ujjwal Verma"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at the 2COOOL Workshop, ICCV 2025", "url": "http://arxiv.org/abs/2411.07901v2", "summary": "Traffic light detection under adverse weather conditions remains largely\nunexplored in ADAS systems, with existing approaches relying on complex deep\nlearning methods that introduce significant computational overheads during\ntraining and deployment. This paper proposes Fourier Domain Adaptation (FDA),\nwhich requires only training data modifications without architectural changes,\nenabling effective adaptation to rainy and foggy conditions. FDA minimizes the\ndomain gap between source and target domains, creating a dataset for reliable\nperformance under adverse weather.\n  The source domain merged LISA and S2TLD datasets, processed to address class\nimbalance. Established methods simulated rainy and foggy scenarios to form the\ntarget domain. Semi-Supervised Learning (SSL) techniques were explored to\nleverage data more effectively, addressing the shortage of comprehensive\ndatasets and poor performance of state-of-the-art models under hostile weather.\n  Experimental results show FDA-augmented models outperform baseline models\nacross mAP50, mAP50-95, Precision, and Recall metrics. YOLOv8 achieved a 12.25%\naverage increase across all metrics. Average improvements of 7.69% in\nPrecision, 19.91% in Recall, 15.85% in mAP50, and 23.81% in mAP50-95 were\nobserved across all models, demonstrating FDA's effectiveness in mitigating\nadverse weather impact. These improvements enable real-world applications\nrequiring reliable performance in challenging environmental conditions.", "comment": "Accepted at the 2COOOL Workshop, ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2411.07901v2", "cate": "cs.CV", "date": "2024-11-12", "updated": "2025-07-19"}
{"id": "2410.10148", "title": "AlphaDPO: Adaptive Reward Margin for Direct Preference Optimization", "authors": ["Junkang Wu", "Xue Wang", "Zhengyi Yang", "Jiancan Wu", "Jinyang Gao", "Bolin Ding", "Xiang Wang", "Xiangnan He"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.10148v4", "summary": "Aligning large language models (LLMs) with human values and intentions is\ncrucial for their utility, honesty, and safety. Reinforcement learning from\nhuman feedback (RLHF) is a popular approach to achieve this alignment, but it\nfaces challenges in computational efficiency and training stability. Recent\nmethods like Direct Preference Optimization (DPO) and Simple Preference\nOptimization (SimPO) have proposed offline alternatives to RLHF, simplifying\nthe process by reparameterizing the reward function. However, DPO depends on a\npotentially suboptimal reference model, and SimPO's assumption of a fixed\ntarget reward margin may lead to suboptimal decisions in diverse data settings.\nIn this work, we propose $\\alpha$-DPO, an adaptive preference optimization\nalgorithm designed to address these limitations by introducing a dynamic reward\nmargin. Specifically, $\\alpha$-DPO employs an adaptive preference distribution,\nbalancing the policy model and the reference model to achieve personalized\nreward margins. We provide theoretical guarantees for $\\alpha$-DPO,\ndemonstrating its effectiveness as a surrogate optimization objective and its\nability to balance alignment and diversity through KL divergence control.\nEmpirical evaluations on AlpacaEval 2 and Arena-Hard show that $\\alpha$-DPO\nconsistently outperforms DPO and SimPO across various model settings,\nestablishing it as a robust approach for fine-tuning LLMs. Our method achieves\nsignificant improvements in win rates, highlighting its potential as a powerful\ntool for LLM alignment. The code is available at\nhttps://github.com/junkangwu/alpha-DPO", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.10148v4", "cate": "cs.LG", "date": "2024-10-14", "updated": "2025-07-19"}
{"id": "2405.20448", "title": "Knockout: A simple way to handle missing inputs", "authors": ["Minh Nguyen", "Batuhan K. Karaman", "Heejong Kim", "Alan Q. Wang", "Fengbei Liu", "Mert R. Sabuncu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at TMLR", "url": "http://arxiv.org/abs/2405.20448v3", "summary": "Deep learning models benefit from rich (e.g., multi-modal) input features.\nHowever, multimodal models might be challenging to deploy, because some inputs\nmay be missing at inference. Current popular solutions include marginalization,\nimputation, and training multiple models. Marginalization achieves calibrated\npredictions, but it is computationally expensive and only feasible for low\ndimensional inputs. Imputation may result in inaccurate predictions,\nparticularly when high-dimensional data, such as images, are missing. Training\nmultiple models, where each model is designed to handle different subsets of\ninputs, can work well but requires prior knowledge of missing input patterns.\nFurthermore, training and retaining multiple models can be costly. We propose\nan efficient method to learn both the conditional distribution using full\ninputs and the marginal distributions. Our method, Knockout, randomly replaces\ninput features with appropriate placeholder values during training. We provide\na theoretical justification for Knockout and show that it can be interpreted as\nan implicit marginalization strategy. We evaluate Knockout across a wide range\nof simulations and real-world datasets and show that it offers strong empirical\nperformance.", "comment": "Accepted at TMLR", "pdf_url": "http://arxiv.org/pdf/2405.20448v3", "cate": "cs.LG", "date": "2024-05-30", "updated": "2025-07-19"}
{"id": "2411.15265", "title": "Derivative-Free Diffusion Manifold-Constrained Gradient for Unified XAI", "authors": ["Won Jun Kim", "Hyungjin Chung", "Jaemin Kim", "Sangmin Lee", "Byeongsu Sim", "Jong Chul Ye"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      CVPR 2025 (poster), 19 pages, 5 figures", "url": "http://arxiv.org/abs/2411.15265v2", "summary": "Gradient-based methods are a prototypical family of explainability\ntechniques, especially for image-based models. Nonetheless, they have several\nshortcomings in that they (1) require white-box access to models, (2) are\nvulnerable to adversarial attacks, and (3) produce attributions that lie off\nthe image manifold, leading to explanations that are not actually faithful to\nthe model and do not align well with human perception. To overcome these\nchallenges, we introduce Derivative-Free Diffusion Manifold-Constrainted\nGradients (FreeMCG), a novel method that serves as an improved basis for\nexplainability of a given neural network than the traditional gradient.\nSpecifically, by leveraging ensemble Kalman filters and diffusion models, we\nderive a derivative-free approximation of the model's gradient projected onto\nthe data manifold, requiring access only to the model's outputs. We demonstrate\nthe effectiveness of FreeMCG by applying it to both counterfactual generation\nand feature attribution, which have traditionally been treated as distinct\ntasks. Through comprehensive evaluation on both tasks, counterfactual\nexplanation and feature attribution, we show that our method yields\nstate-of-the-art results while preserving the essential properties expected of\nXAI tools.", "comment": "CVPR 2025 (poster), 19 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2411.15265v2", "cate": "cs.CV", "date": "2024-11-22", "updated": "2025-07-21"}
{"id": "2411.17125", "title": "DOGR: Towards Versatile Visual Document Grounding and Referring", "authors": ["Yinan Zhou", "Yuxin Chen", "Haokun Lin", "Shuyu Yang", "Zhongang Qi", "Chen Ma", "Li Zhu", "Ying Shan"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      22 pages, 16 figures", "url": "http://arxiv.org/abs/2411.17125v2", "summary": "With recent advances in Multimodal Large Language Models (MLLMs), grounding\nand referring capabilities have gained increasing attention for achieving\ndetailed understanding and flexible user interaction. However, these\ncapabilities still remain underdeveloped in visual document understanding due\nto the scarcity of fine-grained datasets and comprehensive benchmarks. To fill\nthis gap, we propose the DOcument Grounding and Referring data engine\n(DOGR-Engine), which generates two types of high-quality fine-grained document\ndata: (1) multi-granular parsing data to improve text localization and\nrecognition, and (2) instruction-tuning data to activate MLLMs' grounding and\nreferring capabilities in dialogue and reasoning. Using the DOGR-Engine, we\nconstruct DOGR-Bench, a benchmark covering seven grounding and referring tasks\nacross three document types (chart, poster, and PDF document), offering a\ncomprehensive evaluation of fine-grained document understanding. Leveraging the\ngenerated data, we further develop DOGR, a strong baseline model that excels in\ntext localization and recognition, while precisely grounds and refers to key\ntextual information during conversation and reasoning, thereby advancing\ndocument understanding to a finer granularity and enable flexible interaction\nparadigms.", "comment": "22 pages, 16 figures", "pdf_url": "http://arxiv.org/pdf/2411.17125v2", "cate": "cs.CV", "date": "2024-11-26", "updated": "2025-07-21"}
{"id": "2407.21314", "title": "State-observation augmented diffusion model for nonlinear assimilation with unknown dynamics", "authors": ["Zhuoyuan Li", "Bin Dong", "Pingwen Zhang"], "categories": ["cs.LG", "stat.ML", "49N45, 60J60, 62F15, 68T20"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.21314v3", "summary": "Data assimilation has become a key technique for combining physical models\nwith observational data to estimate state variables. However, classical\nassimilation algorithms often struggle with the high nonlinearity present in\nboth physical and observational models. To address this challenge, a novel\ngenerative model, termed the State-Observation Augmented Diffusion (SOAD) model\nis proposed for data-driven assimilation. The marginal posterior associated\nwith SOAD has been derived and then proved to match the true posterior\ndistribution under mild assumptions, suggesting its theoretical advantages over\nprevious score-based approaches. Experimental results also indicate that SOAD\nmay offer improved performance compared to existing data-driven methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.21314v3", "cate": "cs.LG", "date": "2024-07-31", "updated": "2025-07-19"}
{"id": "2411.17769", "title": "Omegance: A Single Parameter for Various Granularities in Diffusion-Based Synthesis", "authors": ["Xinyu Hou", "Zongsheng Yue", "Xiaoming Li", "Chen Change Loy"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025 Camera Ready. Project page: this https URL", "url": "http://arxiv.org/abs/2411.17769v2", "summary": "In this work, we show that we only need a single parameter $\\omega$ to\neffectively control granularity in diffusion-based synthesis. This parameter is\nincorporated during the denoising steps of the diffusion model's reverse\nprocess. This simple approach does not require model retraining or\narchitectural modifications and incurs negligible computational overhead, yet\nenables precise control over the level of details in the generated outputs.\nMoreover, spatial masks or denoising schedules with varying $\\omega$ values can\nbe applied to achieve region-specific or timestep-specific granularity control.\nExternal control signals or reference images can guide the creation of precise\n$\\omega$ masks, allowing targeted granularity adjustments. Despite its\nsimplicity, the method demonstrates impressive performance across various image\nand video synthesis tasks and is adaptable to advanced diffusion models. The\ncode is available at https://github.com/itsmag11/Omegance.", "comment": "ICCV 2025 Camera Ready. Project page:\n  https://itsmag11.github.io/Omegance/", "pdf_url": "http://arxiv.org/pdf/2411.17769v2", "cate": "cs.CV", "date": "2024-11-26", "updated": "2025-07-21"}
{"id": "2412.03021", "title": "PEMF-VTO: Point-Enhanced Video Virtual Try-on via Mask-free Paradigm", "authors": ["Tianyu Chang", "Xiaohao Chen", "Zhichao Wei", "Xuanpu Zhang", "Qing-Guo Chen", "Weihua Luo", "Peipei Song", "Xun Yang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.03021v5", "summary": "Video Virtual Try-on aims to seamlessly transfer a reference garment onto a\ntarget person in a video while preserving both visual fidelity and temporal\ncoherence. Existing methods typically rely on inpainting masks to define the\ntry-on area, enabling accurate garment transfer for simple scenes (e.g.,\nin-shop videos). However, these mask-based approaches struggle with complex\nreal-world scenarios, as overly large and inconsistent masks often destroy\nspatial-temporal information, leading to distorted results. Mask-free methods\nalleviate this issue but face challenges in accurately determining the try-on\narea, especially for videos with dynamic body movements. To address these\nlimitations, we propose PEMF-VTO, a novel Point-Enhanced Mask-Free Video\nVirtual Try-On framework that leverages sparse point alignments to explicitly\nguide garment transfer. Our key innovation is the introduction of\npoint-enhanced guidance, which provides flexible and reliable control over both\nspatial-level garment transfer and temporal-level video coherence.\nSpecifically, we design a Point-Enhanced Transformer (PET) with two core\ncomponents: Point-Enhanced Spatial Attention (PSA), which uses frame-cloth\npoint alignments to precisely guide garment transfer, and Point-Enhanced\nTemporal Attention (PTA), which leverages frame-frame point correspondences to\nenhance temporal coherence and ensure smooth transitions across frames.\nExtensive experiments demonstrate that our PEMF-VTO outperforms\nstate-of-the-art methods, generating more natural, coherent, and visually\nappealing try-on videos, particularly for challenging in-the-wild scenarios.\nThe link to our paper's homepage is https://pemf-vto.github.io/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.03021v5", "cate": "cs.CV", "date": "2024-12-04", "updated": "2025-07-21"}
{"id": "2408.16191", "title": "Variational Mode-Driven Graph Convolutional Network for Spatiotemporal Traffic Forecasting", "authors": ["Osama Ahmad", "Lukas Wesemann", "Fabian Waschkowski", "Zubair Khalid"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ACM Transactions on Intelligent Systems and Technology (TIST) Submission, 2025", "url": "http://arxiv.org/abs/2408.16191v3", "summary": "This paper focuses on spatiotemporal (ST) traffic prediction using graph\nneural networks (GNNs). Given that ST data comprises non-stationary and complex\ntemporal patterns, interpreting and predicting such trends is inherently\nchallenging. Representing ST data in decomposed modes helps infer underlying\nbehavior and assess the impact of noise on predictive performance. We propose a\nframework that decomposes ST data into interpretable modes using variational\nmode decomposition (VMD) and processes them through a neural network for future\nstate forecasting. Unlike existing graph-based traffic forecasters that operate\ndirectly on raw or aggregated time series, the proposed hybrid approach, termed\nthe Variational Mode Graph Convolutional Network (VMGCN), first decomposes\nnon-stationary signals into interpretable variational modes by determining the\noptimal mode count via reconstruction-loss minimization and then learns both\nintramode and cross-mode spatiotemporal dependencies through a novel\nattention-augmented GCN. Additionally, we analyze the significance of each mode\nand the effect of bandwidth constraints on multi-horizon traffic flow\npredictions. The proposed two-stage design yields significant accuracy gains\nwhile providing frequency-level interpretability with demonstrated superior\nperformance on the LargeST dataset for both short-term and long-term\nforecasting tasks. The implementation is publicly available on\nhttps://github.com/OsamaAhmad369/VMGCN.", "comment": "ACM Transactions on Intelligent Systems and Technology (TIST)\n  Submission, 2025", "pdf_url": "http://arxiv.org/pdf/2408.16191v3", "cate": "cs.LG", "date": "2024-08-29", "updated": "2025-07-21"}
{"id": "2411.18652", "title": "Surf-NeRF: Surface Regularised Neural Radiance Fields", "authors": ["Jack Naylor", "Viorela Ila", "Donald G. Dansereau"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      20 pages, 17 figures, 9 tables, project page can be found at this http URL", "url": "http://arxiv.org/abs/2411.18652v2", "summary": "Neural Radiance Fields (NeRFs) provide a high fidelity, continuous scene\nrepresentation that can realistically represent complex behaviour of light.\nDespite works like Ref-NeRF improving geometry through physics-inspired models,\nthe ability for a NeRF to overcome shape-radiance ambiguity and converge to a\nrepresentation consistent with real geometry remains limited. We demonstrate\nhow both curriculum learning of a surface light field model and using a\nlattice-based hash encoding helps a NeRF converge towards a more geometrically\naccurate scene representation. We introduce four regularisation terms to impose\ngeometric smoothness, consistency of normals, and a separation of Lambertian\nand specular appearance at geometry in the scene, conforming to physical\nmodels. Our approach yields 28% more accurate normals than traditional\ngrid-based NeRF variants with reflection parameterisation. Our approach more\naccurately separates view-dependent appearance, conditioning a NeRF to have a\ngeometric representation consistent with the captured scene. We demonstrate\ncompatibility of our method with existing NeRF variants, as a key step in\nenabling radiance-based representations for geometry critical applications.", "comment": "20 pages, 17 figures, 9 tables, project page can be found at\n  http://roboticimaging.org/Projects/SurfNeRF", "pdf_url": "http://arxiv.org/pdf/2411.18652v2", "cate": "cs.CV", "date": "2024-11-27", "updated": "2025-07-21"}
{"id": "2412.03920", "title": "A Survey on Large Language Model-Based Social Agents in Game-Theoretic Scenarios", "authors": ["Xiachong Feng", "Longxu Dou", "Ella Li", "Qinghao Wang", "Haochuan Wang", "Yu Guo", "Chang Ma", "Lingpeng Kong"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.03920v2", "summary": "Game-theoretic scenarios have become pivotal in evaluating the social\nintelligence of Large Language Model (LLM)-based social agents. While numerous\nstudies have explored these agents in such settings, there is a lack of a\ncomprehensive survey summarizing the current progress. To address this gap, we\nsystematically review existing research on LLM-based social agents within\ngame-theoretic scenarios. Our survey organizes the findings into three core\ncomponents: Game Framework, Social Agent, and Evaluation Protocol. The game\nframework encompasses diverse game scenarios, ranging from choice-focusing to\ncommunication-focusing games. The social agent part explores agents'\npreferences, beliefs, and reasoning abilities, as well as their interactions\nand synergistic effects on decision-making. The evaluation protocol covers both\ngame-agnostic and game-specific metrics for assessing agent performance.\nAdditionally, we analyze the performance of current social agents across\nvarious game scenarios. By reflecting on the current research and identifying\nfuture research directions, this survey provides insights to advance the\ndevelopment and evaluation of social agents in game-theoretic scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.03920v2", "cate": "cs.CL", "date": "2024-12-05", "updated": "2025-07-20"}
{"id": "2409.06211", "title": "STUN: Structured-Then-Unstructured Pruning for Scalable MoE Pruning", "authors": ["Jaeseong Lee", "seung-won hwang", "Aurick Qiao", "Daniel F Campos", "Zhewei Yao", "Yuxiong He"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ACL 2025 main", "url": "http://arxiv.org/abs/2409.06211v2", "summary": "Mixture-of-experts (MoEs) have been adopted for reducing inference costs by\nsparsely activating experts in Large language models (LLMs). Despite this\nreduction, the massive number of experts in MoEs still makes them expensive to\nserve. In this paper, we study how to address this, by pruning MoEs. Among\npruning methodologies, unstructured pruning has been known to achieve the\nhighest performance for a given pruning ratio, compared to structured pruning,\nsince the latter imposes constraints on the sparsification structure. This is\nintuitive, as the solution space of unstructured pruning subsumes that of\nstructured pruning. However, our counterintuitive finding reveals that expert\npruning, a form of structured pruning, can actually precede unstructured\npruning to outperform unstructured-only pruning. As existing expert pruning,\nrequiring $O(\\frac{k^n}{\\sqrt{n}})$ forward passes for $n$ experts, cannot\nscale for recent MoEs, we propose a scalable alternative with $O(1)$\ncomplexity, yet outperforming the more expensive methods. The key idea is\nleveraging a latent structure between experts, based on behavior similarity,\nsuch that the greedy decision of whether to prune closely captures the joint\npruning effect. Ours is highly effective -- for Snowflake Arctic, a 480B-sized\nMoE with 128 experts, our method needs only one H100 and two hours to achieve\nnearly no loss in performance with 40% sparsity, even in generative tasks such\nas GSM8K, where state-of-the-art unstructured pruning fails to. The code will\nbe made publicly available.", "comment": "ACL 2025 main", "pdf_url": "http://arxiv.org/pdf/2409.06211v2", "cate": "cs.LG", "date": "2024-09-10", "updated": "2025-07-21"}
{"id": "2412.00460", "title": "BGM: Background Mixup for X-ray Prohibited Items Detection", "authors": ["Weizhe Liu", "Renshuai Tao", "Hongguang Zhu", "Yunda Sun", "Yao Zhao", "Yunchao Wei"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.00460v2", "summary": "Current data-driven approaches for X-ray prohibited items detection remain\nunder-explored, particularly in the design of effective data augmentations.\nExisting natural image augmentations for reflected light imaging neglect the\ndata characteristics of X-ray security images. Moreover, prior X-ray\naugmentation methods have predominantly focused on foreground prohibited items,\noverlooking informative background cues. In this paper, we propose Background\nMixup (BGM), a background-based augmentation technique tailored for X-ray\nsecurity imaging domain. Unlike conventional methods, BGM is founded on an\nin-depth analysis of physical properties including: 1) X-ray Transmission\nImagery: Transmitted X-ray pixels represent composite information from multiple\nmaterials along the imaging path. 2) Material-based Pseudo-coloring:\nPseudo-coloring in X-ray images correlates directly with material properties,\naiding in material distinction. Building upon the above insights, BGM mixes\nbackground patches across regions on both 1) texture structure and 2) material\nvariation, to benefit models from complicated background cues. This enhances\nthe model's capability to handle domain-specific challenges such as\nocclusion-induced discriminative imbalance. Importantly, BGM is orthogonal and\nfully compatible with existing foreground-focused augmentation techniques,\nenabling joint use to further enhance detection performance. Extensive\nexperiments on multiple X-ray security benchmarks show that BGM consistently\nsurpasses strong baselines, without additional annotations or significant\ntraining overhead. This work pioneers the exploration of background-aware\naugmentation in X-ray prohibited items detection and provides a lightweight,\nplug-and-play solution with broad applicability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.00460v2", "cate": "cs.CV", "date": "2024-11-30", "updated": "2025-07-21"}
{"id": "2412.10622", "title": "A recent evaluation on the performance of LLMs on radiation oncology physics using questions of randomly shuffled options", "authors": ["Peilong Wang", "Jason Holmes", "Zhengliang Liu", "Dequan Chen", "Tianming Liu", "Jiajian Shen", "Wei Liu"], "categories": ["physics.med-ph", "cs.AI"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.10622v4", "summary": "Purpose: We present an updated study evaluating the performance of large\nlanguage models (LLMs) in answering radiation oncology physics questions,\nfocusing on the recently released models.\n  Methods: A set of 100 multiple-choice radiation oncology physics questions,\npreviously created by a well-experienced physicist, was used for this study.\nThe answer options of the questions were randomly shuffled to create \"new\" exam\nsets. Five LLMs -- OpenAI o1-preview, GPT-4o, LLaMA 3.1 (405B), Gemini 1.5 Pro,\nand Claude 3.5 Sonnet -- with the versions released before September 30, 2024,\nwere queried using these new exam sets. To evaluate their deductive reasoning\nability, the correct answer options in the questions were replaced with \"None\nof the above.\" Then, the explain-first and step-by-step instruction prompts\nwere used to test if this strategy improved their reasoning ability. The\nperformance of the LLMs was compared with the answers from medical physicists.\n  Results: All models demonstrated expert-level performance on these questions,\nwith o1-preview even surpassing medical physicists with a majority vote. When\nreplacing the correct answer options with 'None of the above', all models\nexhibited a considerable decline in performance, suggesting room for\nimprovement. The explain-first and step-by-step instruction prompts helped\nenhance the reasoning ability of the LLaMA 3.1 (405B), Gemini 1.5 Pro, and\nClaude 3.5 Sonnet models.\n  Conclusion: These recently released LLMs demonstrated expert-level\nperformance in answering radiation oncology physics questions, exhibiting great\npotential to assist in radiation oncology physics education and training.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.10622v4", "cate": "physics.med-ph", "date": "2024-12-14", "updated": "2025-07-18"}
{"id": "2409.08771", "title": "In-depth Analysis of Low-rank Matrix Factorisation in a Federated Setting", "authors": ["Constantin Philippenko", "Kevin Scaman", "Laurent Massoulié"], "categories": ["cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.08771v2", "summary": "We analyze a distributed algorithm to compute a low-rank matrix factorization\non $N$ clients, each holding a local dataset $\\mathbf{S}^i \\in \\mathbb{R}^{n_i\n\\times d}$, mathematically, we seek to solve $min_{\\mathbf{U}^i \\in\n\\mathbb{R}^{n_i\\times r}, \\mathbf{V}\\in \\mathbb{R}^{d \\times r} } \\frac{1}{2}\n\\sum_{i=1}^N \\|\\mathbf{S}^i - \\mathbf{U}^i \\mathbf{V}^\\top\\|^2_{\\text{F}}$.\nConsidering a power initialization of $\\mathbf{V}$, we rewrite the previous\nsmooth non-convex problem into a smooth strongly-convex problem that we solve\nusing a parallel Nesterov gradient descent potentially requiring a single step\nof communication at the initialization step. For any client $i$ in $\\{1, \\dots,\nN\\}$, we obtain a global $\\mathbf{V}$ in $\\mathbb{R}^{d \\times r}$ common to\nall clients and a local variable $\\mathbf{U}^i$ in $\\mathbb{R}^{n_i \\times r}$.\nWe provide a linear rate of convergence of the excess loss which depends on\n$\\sigma_{\\max} / \\sigma_{r}$, where $\\sigma_{r}$ is the $r^{\\mathrm{th}}$\nsingular value of the concatenation $\\mathbf{S}$ of the matrices\n$(\\mathbf{S}^i)_{i=1}^N$. This result improves the rates of convergence given\nin the literature, which depend on $\\sigma_{\\max}^2 / \\sigma_{\\min}^2$. We\nprovide an upper bound on the Frobenius-norm error of reconstruction under the\npower initialization strategy. We complete our analysis with experiments on\nboth synthetic and real data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.08771v2", "cate": "cs.LG", "date": "2024-09-13", "updated": "2025-07-21"}
{"id": "2412.02930", "title": "Video LLMs for Temporal Reasoning in Long Videos", "authors": ["Fawad Javed Fateh", "Umer Ahmed", "Hamza Khan", "M. Zeeshan Zia", "Quoc-Huy Tran"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.02930v4", "summary": "This paper introduces TemporalVLM, a video large language model (video LLM)\ncapable of effective temporal reasoning and fine-grained understanding in long\nvideos. At the core, our approach includes a visual encoder for mapping a\nlong-term input video into features which are time-aware and contain both local\nand global cues. In particular, it first divides the input video into\nshort-term clips, which are jointly encoded with their timestamps and fused\nacross overlapping temporal windows into time-sensitive local features. Next,\nthe local features are passed through a bidirectional long short-term memory\n(BiLSTM) module for global feature aggregation. The extracted time-aware and\nmulti-level features are important for accurate temporal reasoning and\nfine-grained understanding in long videos. Moreover, to facilitate the\nevaluation of TemporalVLM, we present a large-scale long video dataset of\nindustry assembly processes, namely IndustryASM, which consists of videos\nrecorded on factory floors with actions and timestamps annotated by industrial\nengineers for time and motion studies and temporal action segmentation\nevaluation. Finally, extensive experiments on datasets of long videos,\nincluding TimeIT and IndustryASM, show that TemporalVLM achieves superior\nperformance than previous methods across temporal reasoning and fine-grained\nunderstanding tasks, namely dense video captioning, temporal video grounding,\nvideo highlight detection, and temporal action segmentation. To the best of our\nknowledge, our work is the first to incorporate LSTMs into video LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.02930v4", "cate": "cs.CV", "date": "2024-12-04", "updated": "2025-07-21"}
{"id": "2501.18665", "title": "BARNN: A Bayesian Autoregressive and Recurrent Neural Network", "authors": ["Dario Coscia", "Max Welling", "Nicola Demo", "Gianluigi Rozza"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.18665v2", "summary": "Autoregressive and recurrent networks have achieved remarkable progress\nacross various fields, from weather forecasting to molecular generation and\nLarge Language Models. Despite their strong predictive capabilities, these\nmodels lack a rigorous framework for addressing uncertainty, which is key in\nscientific applications such as PDE solving, molecular generation and Machine\nLearning Force Fields. To address this shortcoming we present BARNN: a\nvariational Bayesian Autoregressive and Recurrent Neural Network. BARNNs aim to\nprovide a principled way to turn any autoregressive or recurrent model into its\nBayesian version. BARNN is based on the variational dropout method, allowing to\napply it to large recurrent neural networks as well. We also introduce a\ntemporal version of the \"Variational Mixtures of Posteriors\" prior\n(tVAMP-prior) to make Bayesian inference efficient and well-calibrated.\nExtensive experiments on PDE modelling and molecular generation demonstrate\nthat BARNN not only achieves comparable or superior accuracy compared to\nexisting methods, but also excels in uncertainty quantification and modelling\nlong-range dependencies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.18665v2", "cate": "cs.LG", "date": "2025-01-30", "updated": "2025-07-18"}
{"id": "2409.18214", "title": "Trustworthy Text-to-Image Diffusion Models: A Timely and Focused Survey", "authors": ["Yi Zhang", "Zhen Chen", "Chih-Hong Cheng", "Wenjie Ruan", "Xiaowei Huang", "Dezong Zhao", "David Flynn", "Siddartha Khastgir", "Xingyu Zhao"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      under review", "url": "http://arxiv.org/abs/2409.18214v2", "summary": "Text-to-Image (T2I) Diffusion Models (DMs) have garnered widespread attention\nfor their impressive advancements in image generation. However, their growing\npopularity has raised ethical and social concerns related to key non-functional\nproperties of trustworthiness, such as robustness, fairness, security, privacy,\nfactuality, and explainability, similar to those in traditional deep learning\n(DL) tasks. Conventional approaches for studying trustworthiness in DL tasks\noften fall short due to the unique characteristics of T2I DMs, e.g., the\nmulti-modal nature. Given the challenge, recent efforts have been made to\ndevelop new methods for investigating trustworthiness in T2I DMs via various\nmeans, including falsification, enhancement, verification \\& validation and\nassessment. However, there is a notable lack of in-depth analysis concerning\nthose non-functional properties and means. In this survey, we provide a timely\nand focused review of the literature on trustworthy T2I DMs, covering a\nconcise-structured taxonomy from the perspectives of property, means,\nbenchmarks and applications. Our review begins with an introduction to\nessential preliminaries of T2I DMs, and then we summarise key\ndefinitions/metrics specific to T2I tasks and analyses the means proposed in\nrecent literature based on these definitions/metrics. Additionally, we review\nbenchmarks and domain applications of T2I DMs. Finally, we highlight the gaps\nin current research, discuss the limitations of existing methods, and propose\nfuture research directions to advance the development of trustworthy T2I DMs.\nFurthermore, we keep up-to-date updates in this field to track the latest\ndevelopments and maintain our GitHub repository at:\nhttps://github.com/wellzline/Trustworthy_T2I_DMs", "comment": "under review", "pdf_url": "http://arxiv.org/pdf/2409.18214v2", "cate": "cs.LG", "date": "2024-09-26", "updated": "2025-07-20"}
{"id": "2412.09442", "title": "Advancing Textual Prompt Learning with Anchored Attributes", "authors": ["Zheng Li", "Yibing Song", "Ming-Ming Cheng", "Xiang Li", "Jian Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025. Code: this https URL . Project Page: this https URL", "url": "http://arxiv.org/abs/2412.09442v4", "summary": "Textual-based prompt learning methods primarily employ multiple learnable\nsoft prompts and hard class tokens in a cascading manner as text inputs, aiming\nto align image and text (category) spaces for downstream tasks. However,\ncurrent training is restricted to aligning images with predefined known\ncategories and cannot be associated with unknown categories. In this work, we\npropose utilizing universal attributes as a bridge to enhance the alignment\nbetween images and unknown categories. Specifically, we introduce an\nAttribute-anchored Textual Prompt learning method for vision-language models,\nnamed ATPrompt. This approach expands the learning space of soft prompts from\nthe original one-dimensional category level into the multi-dimensional\nattribute level by incorporating multiple attribute tokens into the learnable\nsoft prompts. Through this modification, we transform the text prompt from a\ncategory-centric form to an attribute-category hybrid form. Additionally, we\nintroduce a straightforward differentiable attribute search method to identify\nrepresentative and suitable attributes for downstream tasks. As an easy-to-use\nplug-in technique, ATPrompt can seamlessly replace the existing basic prompt\nformat in textual-based methods, providing general improvements at a negligible\ncomputational cost. Extensive experiments across 11 datasets validate the\neffectiveness of our method. Code is publicly available at\nhttps://github.com/zhengli97/ATPrompt.", "comment": "ICCV 2025. Code: https://github.com/zhengli97/ATPrompt. Project Page:\n  https://zhengli97.github.io/ATPrompt/", "pdf_url": "http://arxiv.org/pdf/2412.09442v4", "cate": "cs.CV", "date": "2024-12-12", "updated": "2025-07-19"}
{"id": "2502.10871", "title": "Layerwise Recall and the Geometry of Interwoven Knowledge in LLMs", "authors": ["Ge Lei", "Samuel J. Cooper"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.10871v2", "summary": "This study explores how large language models (LLMs) encode interwoven\nscientific knowledge, using chemical elements and LLaMA-series models as a case\nstudy. We identify a 3D spiral structure in the hidden states that aligns with\nthe conceptual structure of the periodic table, suggesting that LLMs can\nreflect the geometric organization of scientific concepts learned from text.\nLinear probing reveals that middle layers encode continuous, overlapping\nattributes that enable indirect recall, while deeper layers sharpen categorical\ndistinctions and incorporate linguistic context. These findings suggest that\nLLMs represent symbolic knowledge not as isolated facts, but as structured\ngeometric manifolds that intertwine semantic information across layers. We hope\nthis work inspires further exploration of how LLMs represent and reason about\nscientific knowledge, particularly in domains such as materials science.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.10871v2", "cate": "cs.CL", "date": "2025-02-15", "updated": "2025-07-18"}
{"id": "2410.20444", "title": "Vector Quantization Prompting for Continual Learning", "authors": ["Li Jiao", "Qiuxia Lai", "Yu Li", "Qiang Xu"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by NeurIPS 2024", "url": "http://arxiv.org/abs/2410.20444v2", "summary": "Continual learning requires to overcome catastrophic forgetting when training\na single model on a sequence of tasks. Recent top-performing approaches are\nprompt-based methods that utilize a set of learnable parameters (i.e., prompts)\nto encode task knowledge, from which appropriate ones are selected to guide the\nfixed pre-trained model in generating features tailored to a certain task.\nHowever, existing methods rely on predicting prompt identities for prompt\nselection, where the identity prediction process cannot be optimized with task\nloss. This limitation leads to sub-optimal prompt selection and inadequate\nadaptation of pre-trained features for a specific task. Previous efforts have\ntried to address this by directly generating prompts from input queries instead\nof selecting from a set of candidates. However, these prompts are continuous,\nwhich lack sufficient abstraction for task knowledge representation, making\nthem less effective for continual learning. To address these challenges, we\npropose VQ-Prompt, a prompt-based continual learning method that incorporates\nVector Quantization (VQ) into end-to-end training of a set of discrete prompts.\nIn this way, VQ-Prompt can optimize the prompt selection process with task loss\nand meanwhile achieve effective abstraction of task knowledge for continual\nlearning. Extensive experiments show that VQ-Prompt outperforms\nstate-of-the-art continual learning methods across a variety of benchmarks\nunder the challenging class-incremental setting. The code is available at\n\\href{https://github.com/jiaolifengmi/VQ-Prompt}{this https URL}.", "comment": "Accepted by NeurIPS 2024", "pdf_url": "http://arxiv.org/pdf/2410.20444v2", "cate": "cs.LG", "date": "2024-10-27", "updated": "2025-07-20"}
{"id": "2412.14939", "title": "GURecon: Learning Detailed 3D Geometric Uncertainties for Neural Surface Reconstruction", "authors": ["Zesong Yang", "Ru Zhang", "Jiale Shi", "Zixiang Ai", "Boming Zhao", "Hujun Bao", "Luwei Yang", "Zhaopeng Cui"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by AAAI 2025. Project page: this https URL", "url": "http://arxiv.org/abs/2412.14939v3", "summary": "Neural surface representation has demonstrated remarkable success in the\nareas of novel view synthesis and 3D reconstruction. However, assessing the\ngeometric quality of 3D reconstructions in the absence of ground truth mesh\nremains a significant challenge, due to its rendering-based optimization\nprocess and entangled learning of appearance and geometry with photometric\nlosses. In this paper, we present a novel framework, i.e, GURecon, which\nestablishes a geometric uncertainty field for the neural surface based on\ngeometric consistency. Different from existing methods that rely on\nrendering-based measurement, GURecon models a continuous 3D uncertainty field\nfor the reconstructed surface, and is learned by an online distillation\napproach without introducing real geometric information for supervision.\nMoreover, in order to mitigate the interference of illumination on geometric\nconsistency, a decoupled field is learned and exploited to finetune the\nuncertainty field. Experiments on various datasets demonstrate the superiority\nof GURecon in modeling 3D geometric uncertainty, as well as its plug-and-play\nextension to various neural surface representations and improvement on\ndownstream tasks such as incremental reconstruction. The code and supplementary\nmaterial are available on the project website:\nhttps://zju3dv.github.io/GURecon/.", "comment": "Accepted by AAAI 2025. Project page:\n  https://zju3dv.github.io/GURecon/", "pdf_url": "http://arxiv.org/pdf/2412.14939v3", "cate": "cs.CV", "date": "2024-12-19", "updated": "2025-07-21"}
{"id": "2502.13764", "title": "An Overall Real-Time Mechanism for Classification and Quality Evaluation of Rice", "authors": ["Wanke Xia", "Ruoxin Peng", "Haoqi Chu", "Xinlei Zhu", "Zhiyu Yang", "Lili Yang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.13764v3", "summary": "Rice is one of the most widely cultivated crops globally and has been\ndeveloped into numerous varieties. The quality of rice during cultivation is\nprimarily determined by its cultivar and characteristics. Traditionally, rice\nclassification and quality assessment rely on manual visual inspection, a\nprocess that is both time-consuming and prone to errors. However, with\nadvancements in machine vision technology, automating rice classification and\nquality evaluation based on its cultivar and characteristics has become\nincreasingly feasible, enhancing both accuracy and efficiency. This study\nproposes a real-time evaluation mechanism for comprehensive rice grain\nassessment, integrating a one-stage object detection approach, a deep\nconvolutional neural network, and traditional machine learning techniques. The\nproposed framework enables rice variety identification, grain completeness\ngrading, and grain chalkiness evaluation. The rice grain dataset used in this\nstudy comprises approximately 20,000 images from six widely cultivated rice\nvarieties in China. Experimental results demonstrate that the proposed\nmechanism achieves a mean average precision (mAP) of 99.14% in the object\ndetection task and an accuracy of 97.89% in the classification task.\nFurthermore, the framework attains an average accuracy of 97.56% in grain\ncompleteness grading within the same rice variety, contributing to an effective\nquality evaluation system.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.13764v3", "cate": "cs.CV", "date": "2025-02-19", "updated": "2025-07-21"}
{"id": "2410.23880", "title": "Transparent Trade-offs between Properties of Explanations", "authors": ["Hiwot Belay Tadesse", "Alihan Hüyük", "Yaniv Yacoby", "Weiwei Pan", "Finale Doshi-Velez"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.23880v2", "summary": "When explaining black-box machine learning models, it's often important for\nexplanations to have certain desirable properties. Most existing methods\n`encourage' desirable properties in their construction of explanations. In this\nwork, we demonstrate that these forms of encouragement do not consistently\ncreate explanations with the properties that are supposedly being targeted.\nMoreover, they do not allow for any control over which properties are\nprioritized when different properties are at odds with each other. We propose\nto directly optimize explanations for desired properties. Our direct approach\nnot only produces explanations with optimal properties more consistently but\nalso empowers users to control trade-offs between different properties,\nallowing them to create explanations with exactly what is needed for a\nparticular task.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.23880v2", "cate": "cs.LG", "date": "2024-10-31", "updated": "2025-07-21"}
{"id": "2501.01184", "title": "Vulnerability-Aware Spatio-Temporal Learning for Generalizable Deepfake Video Detection", "authors": ["Dat Nguyen", "Marcella Astrid", "Anis Kacem", "Enjie Ghorbel", "Djamila Aouada"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV2025. Project Page: this https URL", "url": "http://arxiv.org/abs/2501.01184v3", "summary": "Detecting deepfake videos is highly challenging given the complexity of\ncharacterizing spatio-temporal artifacts. Most existing methods rely on binary\nclassifiers trained using real and fake image sequences, therefore hindering\ntheir generalization capabilities to unseen generation methods. Moreover, with\nthe constant progress in generative Artificial Intelligence (AI), deepfake\nartifacts are becoming imperceptible at both the spatial and the temporal\nlevels, making them extremely difficult to capture. To address these issues, we\npropose a fine-grained deepfake video detection approach called FakeSTormer\nthat enforces the modeling of subtle spatio-temporal inconsistencies while\navoiding overfitting. Specifically, we introduce a multi-task learning\nframework that incorporates two auxiliary branches for explicitly attending\nartifact-prone spatial and temporal regions. Additionally, we propose a\nvideo-level data synthesis strategy that generates pseudo-fake videos with\nsubtle spatio-temporal artifacts, providing high-quality samples and hand-free\nannotations for our additional branches. Extensive experiments on several\nchallenging benchmarks demonstrate the superiority of our approach compared to\nrecent state-of-the-art methods. The code is available at\nhttps://github.com/10Ring/FakeSTormer.", "comment": "Accepted at ICCV2025. Project Page:\n  https://datdaigia.github.io/FakeSTormer/", "pdf_url": "http://arxiv.org/pdf/2501.01184v3", "cate": "cs.CV", "date": "2025-01-02", "updated": "2025-07-19"}
{"id": "2502.14916", "title": "MKE-Coder: Multi-Axial Knowledge with Evidence Verification in ICD Coding for Chinese EMRs", "authors": ["Xinxin You", "Xien Liu", "Xue Yang", "Ziyi Wang", "Ji Wu"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      We have decided to withdraw this manuscript in order to allow for further revisions and additional experiments", "url": "http://arxiv.org/abs/2502.14916v3", "summary": "The task of automatically coding the International Classification of Diseases\n(ICD) in the medical field has been well-established and has received much\nattention. Automatic coding of the ICD in the medical field has been successful\nin English but faces challenges when dealing with Chinese electronic medical\nrecords (EMRs). The first issue lies in the difficulty of extracting disease\ncode-related information from Chinese EMRs, primarily due to the concise\nwriting style and specific internal structure of the EMRs. The second problem\nis that previous methods have failed to leverage the disease-based multi-axial\nknowledge and lack of association with the corresponding clinical evidence.\nThis paper introduces a novel framework called MKE-Coder: Multi-axial Knowledge\nwith Evidence verification in ICD coding for Chinese EMRs. Initially, we\nidentify candidate codes for the diagnosis and categorize each of them into\nknowledge under four coding axes.Subsequently, we retrieve corresponding\nclinical evidence from the comprehensive content of EMRs and filter credible\nevidence through a scoring model. Finally, to ensure the validity of the\ncandidate code, we propose an inference module based on the masked language\nmodeling strategy. This module verifies that all the axis knowledge associated\nwith the candidate code is supported by evidence and provides recommendations\naccordingly. To evaluate the performance of our framework, we conduct\nexperiments using a large-scale Chinese EMR dataset collected from various\nhospitals. The experimental results demonstrate that MKE-Coder exhibits\nsignificant superiority in the task of automatic ICD coding based on Chinese\nEMRs. In the practical evaluation of our method within simulated real coding\nscenarios, it has been demonstrated that our approach significantly aids coders\nin enhancing both their coding accuracy and speed.", "comment": "We have decided to withdraw this manuscript in order to allow for\n  further revisions and additional experiments", "pdf_url": "http://arxiv.org/pdf/2502.14916v3", "cate": "cs.CL", "date": "2025-02-19", "updated": "2025-07-21"}
{"id": "2411.12948", "title": "Attention-Based Reconstruction of Full-Field Tsunami Waves from Sparse Tsunameter Networks", "authors": ["Edward McDugald", "Arvind Mohan", "Darren Engwirda", "Agnese Marcato", "Javier Santos"], "categories": ["cs.LG", "physics.flu-dyn"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.12948v5", "summary": "We investigate the potential of an attention-based neural network\narchitecture, the Senseiver, for sparse sensing in tsunami forecasting.\nSpecifically, we focus on the Tsunami Data Assimilation Method, which generates\nforecasts from tsunameter networks. Our model is used to reconstruct\nhigh-resolution tsunami wavefields from extremely sparse observations,\nincluding cases where the tsunami epicenters are not represented in the\ntraining set. Furthermore, we demonstrate that our approach significantly\noutperforms the Linear Interpolation with Huygens-Fresnel Principle in\ngenerating dense observation networks, achieving markedly improved accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.12948v5", "cate": "cs.LG", "date": "2024-11-20", "updated": "2025-07-19"}
{"id": "2501.01425", "title": "Free-Form Motion Control: Controlling the 6D Poses of Camera and Objects in Video Generation", "authors": ["Xincheng Shuai", "Henghui Ding", "Zhenyuan Qin", "Hao Luo", "Xingjun Ma", "Dacheng Tao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025, Project Page: this https URL", "url": "http://arxiv.org/abs/2501.01425v3", "summary": "Controlling the movements of dynamic objects and the camera within generated\nvideos is a meaningful yet challenging task. Due to the lack of datasets with\ncomprehensive 6D pose annotations, existing text-to-video methods can not\nsimultaneously control the motions of both camera and objects in 3D-aware\nmanner, resulting in limited controllability over generated contents. To\naddress this issue and facilitate the research in this field, we introduce a\nSynthetic Dataset for Free-Form Motion Control (SynFMC). The proposed SynFMC\ndataset includes diverse object and environment categories and covers various\nmotion patterns according to specific rules, simulating common and complex\nreal-world scenarios. The complete 6D pose information facilitates models\nlearning to disentangle the motion effects from objects and the camera in a\nvideo.~To provide precise 3D-aware motion control, we further propose a method\ntrained on SynFMC, Free-Form Motion Control (FMC). FMC can control the 6D poses\nof objects and camera independently or simultaneously, producing high-fidelity\nvideos. Moreover, it is compatible with various personalized text-to-image\n(T2I) models for different content styles. Extensive experiments demonstrate\nthat the proposed FMC outperforms previous methods across multiple scenarios.", "comment": "ICCV 2025, Project Page: https://henghuiding.github.io/SynFMC/", "pdf_url": "http://arxiv.org/pdf/2501.01425v3", "cate": "cs.CV", "date": "2025-01-02", "updated": "2025-07-20"}
{"id": "2502.15090", "title": "Analyze the Neurons, not the Embeddings: Understanding When and Where LLM Representations Align with Humans", "authors": ["Masha Fedzechkina", "Eleonora Gualdoni", "Sinead Williamson", "Katherine Metcalf", "Skyler Seto", "Barry-John Theobald"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.15090v2", "summary": "Modern large language models (LLMs) achieve impressive performance on some\ntasks, while exhibiting distinctly non-human-like behaviors on others. This\nraises the question of how well the LLM's learned representations align with\nhuman representations. In this work, we introduce a novel approach to study\nrepresentation alignment: we adopt a method from research on activation\nsteering to identify neurons responsible for specific concepts (e.g., ''cat'')\nand then analyze the corresponding activation patterns. We find that LLM\nrepresentations captured this way closely align with human representations\ninferred from behavioral data, matching inter-human alignment levels. Our\napproach significantly outperforms the alignment captured by word embeddings,\nwhich have been the focus of prior work on human-LLM alignment. Additionally,\nour approach enables a more granular view of how LLMs represent concepts -- we\nshow that LLMs organize concepts in a way that mirrors human concept\norganization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.15090v2", "cate": "cs.CL", "date": "2025-02-20", "updated": "2025-07-18"}
{"id": "2412.13697", "title": "Splitting criteria for ordinal decision trees: an experimental study", "authors": ["Rafael Ayllón-Gavilán", "Francisco José Martínez-Estudillo", "David Guijo-Rubio", "César Hervás-Martínez", "Pedro Antonio Gutiérrez"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      33 pages, 4 figures, 6 tables", "url": "http://arxiv.org/abs/2412.13697v3", "summary": "Ordinal Classification (OC) addresses those classification tasks where the\nlabels exhibit a natural order. Unlike nominal classification, which treats all\nclasses as mutually exclusive and unordered, OC takes the ordinal relationship\ninto account, producing more accurate and relevant results. This is\nparticularly critical in applications where the magnitude of classification\nerrors has significant consequences. Despite this, OC problems are often\ntackled using nominal methods, leading to suboptimal solutions. Although\ndecision trees are among the most popular classification approaches, ordinal\ntree-based approaches have received less attention when compared to other\nclassifiers. This work provides a comprehensive survey of ordinal splitting\ncriteria, standardising the notations used in the literature to enhance clarity\nand consistency. Three ordinal splitting criteria, Ordinal Gini (OGini),\nWeighted Information Gain (WIG), and Ranking Impurity (RI), are compared to the\nnominal counterparts of the first two (Gini and information gain), by\nincorporating them into a decision tree classifier. An extensive repository\nconsidering $45$ publicly available OC datasets is presented, supporting the\nfirst experimental comparison of ordinal and nominal splitting criteria using\nwell-known OC evaluation metrics. The results have been statistically analysed,\nhighlighting that OGini stands out as the best ordinal splitting criterion to\ndate, reducing the mean absolute error achieved by Gini by more than 3.02%. To\npromote reproducibility, all source code developed, a detailed guide for\nreproducing the results, the 45 OC datasets, and the individual results for all\nthe evaluated methodologies are provided.", "comment": "33 pages, 4 figures, 6 tables", "pdf_url": "http://arxiv.org/pdf/2412.13697v3", "cate": "cs.LG", "date": "2024-12-18", "updated": "2025-07-21"}
{"id": "2501.04950", "title": "MORDA: A Synthetic Dataset to Facilitate Adaptation of Object Detectors to Unseen Real-target Domain While Preserving Performance on Real-source Domain", "authors": ["Hojun Lim", "Heecheol Yoo", "Jinwoo Lee", "Seungmin Jeon", "Hyeongseok Jeon"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      7 pages, 6 figures, 4 tables, This work has been accepted for publication in IEEE ICRA 2025. The final published version will be available via IEEE Xplore", "url": "http://arxiv.org/abs/2501.04950v3", "summary": "Deep neural network (DNN) based perception models are indispensable in the\ndevelopment of autonomous vehicles (AVs). However, their reliance on\nlarge-scale, high-quality data is broadly recognized as a burdensome necessity\ndue to the substantial cost of data acquisition and labeling. Further, the\nissue is not a one-time concern, as AVs might need a new dataset if they are to\nbe deployed to another region (real-target domain) that the in-hand dataset\nwithin the real-source domain cannot incorporate. To mitigate this burden, we\npropose leveraging synthetic environments as an auxiliary domain where the\ncharacteristics of real domains are reproduced. This approach could enable\nindirect experience about the real-target domain in a time- and cost-effective\nmanner. As a practical demonstration of our methodology, nuScenes and South\nKorea are employed to represent real-source and real-target domains,\nrespectively. That means we construct digital twins for several regions of\nSouth Korea, and the data-acquisition framework of nuScenes is reproduced.\nBlending the aforementioned components within a simulator allows us to obtain a\nsynthetic-fusion domain in which we forge our novel driving dataset, MORDA:\nMixture Of Real-domain characteristics for synthetic-data-assisted Domain\nAdaptation. To verify the value of synthetic features that MORDA provides in\nlearning about driving environments of South Korea, 2D/3D detectors are trained\nsolely on a combination of nuScenes and MORDA. Afterward, their performance is\nevaluated on the unforeseen real-world dataset (AI-Hub) collected in South\nKorea. Our experiments present that MORDA can significantly improve mean\nAverage Precision (mAP) on AI-Hub dataset while that on nuScenes is retained or\nslightly enhanced.", "comment": "7 pages, 6 figures, 4 tables, This work has been accepted for\n  publication in IEEE ICRA 2025. The final published version will be available\n  via IEEE Xplore", "pdf_url": "http://arxiv.org/pdf/2501.04950v3", "cate": "cs.CV", "date": "2025-01-09", "updated": "2025-07-21"}
{"id": "2502.15639", "title": "Steering into New Embedding Spaces: Analyzing Cross-Lingual Alignment Induced by Model Interventions in Multilingual Language Models", "authors": ["Anirudh Sundar", "Sinead Williamson", "Katherine Metcalf", "Barry-John Theobald", "Skyler Seto", "Masha Fedzechkina"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      34 pages", "url": "http://arxiv.org/abs/2502.15639v2", "summary": "Aligned representations across languages is a desired property in\nmultilingual large language models (mLLMs), as alignment can improve\nperformance in cross-lingual tasks. Typically alignment requires fine-tuning a\nmodel, which is computationally expensive, and sizable language data, which\noften may not be available. A data-efficient alternative to fine-tuning is\nmodel interventions -- a method for manipulating model activations to steer\ngeneration into the desired direction. We analyze the effect of a popular\nintervention (finding experts) on the alignment of cross-lingual\nrepresentations in mLLMs. We identify the neurons to manipulate for a given\nlanguage and introspect the embedding space of mLLMs pre- and\npost-manipulation. We show that modifying the mLLM's activations changes its\nembedding space such that cross-lingual alignment is enhanced. Further, we show\nthat the changes to the embedding space translate into improved downstream\nperformance on retrieval tasks, with up to 2x improvements in top-1 accuracy on\ncross-lingual retrieval.", "comment": "34 pages", "pdf_url": "http://arxiv.org/pdf/2502.15639v2", "cate": "cs.CL", "date": "2025-02-21", "updated": "2025-07-21"}
{"id": "2501.03040", "title": "ChronoSense: Exploring Temporal Understanding in Large Language Models with Time Intervals of Events", "authors": ["Duygu Sezen Islakoglu", "Jan-Christoph Kalo"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025. Results on a larger test set. 13 pages, 2 figures", "url": "http://arxiv.org/abs/2501.03040v2", "summary": "Large Language Models (LLMs) have achieved remarkable success in various NLP\ntasks, yet they still face significant challenges in reasoning and arithmetic.\nTemporal reasoning, a critical component of natural language understanding, has\nraised increasing research attention. However, comprehensive testing of Allen's\ninterval relations (e.g., before, after, during) -- a fundamental framework for\ntemporal relationships -- remains underexplored. To fill this gap, we present\nChronoSense, a new benchmark for evaluating LLMs' temporal understanding. It\nincludes 16 tasks, focusing on identifying the Allen relation between two\ntemporal events and temporal arithmetic, using both abstract events and\nreal-world data from Wikidata. We assess the performance of seven recent LLMs\nusing this benchmark and the results indicate that models handle Allen\nrelations, even symmetrical ones, quite differently. Moreover, the findings\nsuggest that the models may rely on memorization to answer time-related\nquestions. Overall, the models' low performance highlights the need for\nimproved temporal understanding in LLMs and ChronoSense offers a robust\nframework for future research in this area. Our dataset and the source code are\navailable at https://github.com/duyguislakoglu/chronosense.", "comment": "Accepted to ACL 2025. Results on a larger test set. 13 pages, 2\n  figures", "pdf_url": "http://arxiv.org/pdf/2501.03040v2", "cate": "cs.LG", "date": "2025-01-06", "updated": "2025-07-21"}
{"id": "2503.01655", "title": "Can Optical Denoising Clean Sonar Images? A Benchmark and Fusion Approach", "authors": ["Ziyu Wang", "Tao Xue", "Jingyuan Li", "Haibin Zhang", "Zhiqiang Xu", "Gaofei Xu", "Zhen Wang", "Yanbin Wang", "Zhiquan Liu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.01655v2", "summary": "Object detection in sonar images is crucial for underwater robotics\napplications including autonomous navigation and resource exploration. However,\ncomplex noise patterns inherent in sonar imagery, particularly speckle,\nreverberation, and non-Gaussian noise, significantly degrade detection\naccuracy. While denoising techniques have achieved remarkable success in\noptical imaging, their applicability to sonar data remains underexplored. This\nstudy presents the first systematic evaluation of nine state-of-the-art deep\ndenoising models with distinct architectures, including Neighbor2Neighbor with\nvarying noise parameters, Blind2Unblind with different noise configurations,\nand DSPNet, for sonar image preprocessing. We establish a rigorous benchmark\nusing five publicly available sonar datasets and assess their impact on four\nrepresentative detection algorithms: YOLOX, Faster R-CNN, SSD300, and\nSSDMobileNetV2. Our evaluation addresses three unresolved questions: first, how\neffectively optical denoising architectures transfer to sonar data; second,\nwhich model families perform best against sonar noise; and third, whether\ndenoising truly improves detection accuracy in practical pipelines. Extensive\nexperiments demonstrate that while denoising generally improves detection\nperformance, effectiveness varies across methods due to their inherent biases\ntoward specific noise types. To leverage complementary denoising effects, we\npropose a mutually-supervised multi-source denoising fusion framework where\noutputs from different denoisers mutually supervise each other at the pixel\nlevel, creating a synergistic framework that produces cleaner images.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.01655v2", "cate": "cs.CV", "date": "2025-03-03", "updated": "2025-07-20"}
{"id": "2502.17163", "title": "MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation", "authors": ["María Andrea Cruz Blandón", "Jayasimha Talur", "Bruno Charron", "Dong Liu", "Saab Mansour", "Marcello Federico"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025", "url": "http://arxiv.org/abs/2502.17163v4", "summary": "Automatic evaluation of retrieval augmented generation (RAG) systems relies\non fine-grained dimensions like faithfulness and relevance, as judged by expert\nhuman annotators. Meta-evaluation benchmarks support the development of\nautomatic evaluators that correlate well with human judgement. However,\nexisting benchmarks predominantly focus on English or use translated data,\nwhich fails to capture cultural nuances. A native approach provides a better\nrepresentation of the end user experience.\n  In this work, we develop a Multilingual End-to-end Meta-Evaluation RAG\nbenchmark (MEMERAG). Our benchmark builds on the popular MIRACL dataset, using\nnative-language questions and generating responses with diverse large language\nmodels (LLMs), which are then assessed by expert annotators for faithfulness\nand relevance. We describe our annotation process and show that it achieves\nhigh inter-annotator agreement. We then analyse the performance of the\nanswer-generating LLMs across languages as per the human evaluators. Finally we\napply the dataset to our main use-case which is to benchmark multilingual\nautomatic evaluators (LLM-as-a-judge). We show that our benchmark can reliably\nidentify improvements offered by advanced prompting techniques and LLMs. Our\ndataset is available at https://github.com/amazon-science/MEMERAG", "comment": "ACL 2025", "pdf_url": "http://arxiv.org/pdf/2502.17163v4", "cate": "cs.CL", "date": "2025-02-24", "updated": "2025-07-19"}
{"id": "2501.04300", "title": "HI-PMK: A Data-Dependent Kernel for Incomplete Heterogeneous Data Representation", "authors": ["Youran Zhou", "Mohamed Reda Bouadjenek", "Jonathan Wells", "Sunil Aryal"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.04300v2", "summary": "Handling incomplete and heterogeneous data remains a central challenge in\nreal-world machine learning, where missing values may follow complex mechanisms\n(MCAR, MAR, MNAR) and features can be of mixed types (numerical and\ncategorical). Existing methods often rely on imputation, which may introduce\nbias or privacy risks, or fail to jointly address data heterogeneity and\nstructured missingness. We propose the \\textbf{H}eterogeneous\n\\textbf{I}ncomplete \\textbf{P}robability \\textbf{M}ass \\textbf{K}ernel\n(\\textbf{HI-PMK}), a novel data-dependent representation learning approach that\neliminates the need for imputation. HI-PMK introduces two key innovations: (1)\na probability mass-based dissimilarity measure that adapts to local data\ndistributions across heterogeneous features (numerical, ordinal, nominal), and\n(2) a missingness-aware uncertainty strategy (MaxU) that conservatively handles\nall three missingness mechanisms by assigning maximal plausible dissimilarity\nto unobserved entries. Our approach is privacy-preserving, scalable, and\nreadily applicable to downstream tasks such as classification and clustering.\nExtensive experiments on over 15 benchmark datasets demonstrate that HI-PMK\nconsistently outperforms traditional imputation-based pipelines and kernel\nmethods across a wide range of missing data settings. Code is available at:\nhttps://github.com/echoid/Incomplete-Heter-Kernel", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.04300v2", "cate": "cs.LG", "date": "2025-01-08", "updated": "2025-07-20"}
{"id": "2503.03111", "title": "An Improved Pure Fully Connected Neural Network for Rice Grain Classification", "authors": ["Wanke Xia", "Ruoxin Peng", "Haoqi Chu", "Xinlei Zhu", "Zhiyu Yang", "Lili Yang", "Bo Lv", "Xunwen Xiang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.03111v2", "summary": "Rice is a staple food for a significant portion of the world's population,\nproviding essential nutrients and serving as a versatile in-gredient in a wide\nrange of culinary traditions. Recently, the use of deep learning has enabled\nautomated classification of rice, im-proving accuracy and efficiency. However,\nclassical models based on first-stage training may face difficulties in\ndistinguishing between rice varieties with similar external characteristics,\nthus leading to misclassifications. Considering the transparency and\nfeasibility of model, we selected and gradually improved pure fully connected\nneural network to achieve classification of rice grain. The dataset we used\ncontains both global and domestic rice images obtained from websites and\nlaboratories respectively. First, the training mode was changed from one-stage\ntraining to two-stage training, which significantly contributes to\ndistinguishing two similar types of rice. Secondly, the preprocessing method\nwas changed from random tilting to horizontal or vertical position cor-rection.\nAfter those two enhancements, the accuracy of our model increased notably from\n97% to 99%. In summary, two subtle methods proposed in this study can\nremarkably enhance the classification ability of deep learning models in terms\nof the classification of rice grain.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.03111v2", "cate": "cs.CV", "date": "2025-03-05", "updated": "2025-07-21"}
{"id": "2502.19545", "title": "Winning Big with Small Models: Knowledge Distillation vs. Self-Training for Reducing Hallucination in Product QA Agents", "authors": ["Ashley Lewis", "Michael White", "Jing Liu", "Toshiaki Koike-Akino", "Kieran Parsons", "Ye Wang"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.19545v2", "summary": "The deployment of Large Language Models (LLMs) in customer support is\nconstrained by hallucination (generating false information) and the high cost\nof proprietary models. To address these challenges, we propose a\nretrieval-augmented question-answering (QA) pipeline and explore how to balance\nhuman input and automation. Using a dataset of questions about a Samsung Smart\nTV user manual, we demonstrate that synthetic data generated by LLMs\noutperforms crowdsourced data in reducing hallucination in finetuned models. We\nalso compare self-training (fine-tuning models on their own outputs) and\nknowledge distillation (fine-tuning on stronger models' outputs, e.g., GPT-4o),\nand find that self-training achieves comparable hallucination reduction. We\nconjecture that this surprising finding can be attributed to increased exposure\nbias issues in the knowledge distillation case and support this conjecture with\npost hoc analysis. We also improve robustness to unanswerable questions and\nretrieval failures with contextualized \"I don't know\" responses. These findings\nshow that scalable, cost-efficient QA systems can be built using synthetic data\nand self-training with open-source models, reducing reliance on proprietary\ntools or costly human annotations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.19545v2", "cate": "cs.CL", "date": "2025-02-26", "updated": "2025-07-21"}
{"id": "2501.10062", "title": "OMoE: Diversifying Mixture of Low-Rank Adaptation by Orthogonal Finetuning", "authors": ["Jinyuan Feng", "Zhiqiang Pu", "Tianyi Hu", "Dongmin Li", "Xiaolin Ai", "Huimu Wang"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This paper is accepted by ECAI 2025", "url": "http://arxiv.org/abs/2501.10062v2", "summary": "Building mixture-of-experts (MoE) architecture for Low-rank adaptation (LoRA)\nis emerging as a potential direction in parameter-efficient fine-tuning (PEFT)\nfor its modular design and remarkable performance. However, simply stacking the\nnumber of experts cannot guarantee significant improvement. In this work, we\nfirst conduct qualitative analysis to indicate that experts collapse to similar\nrepresentations in vanilla MoE, limiting the capacity of modular design and\ncomputational efficiency. Ulteriorly, Our analysis reveals that the performance\nof previous MoE variants maybe limited by a lack of diversity among experts.\nMotivated by these findings, we propose Orthogonal Mixture-of-Experts (OMoE), a\nresource-efficient MoE variant that trains experts in an orthogonal manner to\npromote diversity. In OMoE, a Gram-Schmidt process is leveraged to enforce that\nthe experts' representations lie within the Stiefel manifold. By applying\northogonal constraints directly to the architecture, OMoE keeps the learning\nobjective unchanged, without compromising optimality. Our method is simple and\nalleviates memory bottlenecks, as it incurs minimal experts compared to vanilla\nMoE models. Experiments on diverse commonsense reasoning benchmarks demonstrate\nthat OMoE can consistently achieve stable and efficient performance improvement\nwhen compared with the state-of-the-art methods while significantly reducing\nthe number of required experts.", "comment": "This paper is accepted by ECAI 2025", "pdf_url": "http://arxiv.org/pdf/2501.10062v2", "cate": "cs.LG", "date": "2025-01-17", "updated": "2025-07-21"}
{"id": "2503.05170", "title": "Leveraging Spatial Context for Positive Pair Sampling in Histopathology Image Representation Learning", "authors": ["Willmer Rafell Quinones Robles", "Sakonporn Noree", "Young Sin Ko", "Bryan Wong", "Jongwoo Kim", "Mun Yong Yi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.05170v2", "summary": "Deep learning has shown strong potential in cancer classification from\nwhole-slide images (WSIs), but the need for extensive expert annotations often\nlimits its success. Annotation-free approaches, such as multiple instance\nlearning (MIL) and self-supervised learning (SSL), have emerged as promising\nalternatives to traditional annotation-based methods. However, conventional SSL\nmethods typically rely on synthetic data augmentations, which may fail to\ncapture the spatial structure critical to histopathology. In this work, we\npropose a spatial context-driven positive pair sampling strategy that enhances\nSSL by leveraging the morphological coherence of spatially adjacent patches\nwithin WSIs. Our method is modular and compatible with established joint\nembedding SSL frameworks, including Barlow Twins, BYOL, VICReg, and DINOv2. We\nevaluate its effectiveness on both slide-level classification using MIL and\npatch-level linear probing. Experiments across four datasets demonstrate\nconsistent performance improvements, with accuracy gains of 5\\% to 10\\%\ncompared to standard augmentation-based sampling. These findings highlight the\nvalue of spatial context in improving representation learning for computational\npathology and provide a biologically meaningful enhancement for pretraining\nmodels in annotation-limited settings. The code is available at\nhttps://anonymous.4open.science/r/contextual-pairs-E72F/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.05170v2", "cate": "cs.CV", "date": "2025-03-07", "updated": "2025-07-21"}
{"id": "2503.01909", "title": "Attend or Perish: Benchmarking Attention in Algorithmic Reasoning", "authors": ["Michal Spiegel", "Michal Štefánik", "Marek Kadlčík", "Josef Kuchař"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.01909v2", "summary": "Can transformers learn to perform algorithmic tasks reliably across\npreviously unseen input/output domains? While pre-trained language models show\nsolid accuracy on benchmarks incorporating algorithmic reasoning, assessing the\nreliability of these results necessitates an ability to distinguish genuine\nalgorithmic understanding from memorization. In this paper, we propose\nAttentionSpan, an algorithmic benchmark comprising five tasks of infinite input\ndomains where we can disentangle and trace the correct, robust algorithm\nnecessary for the task. This allows us to assess (i) models' ability to\nextrapolate to unseen types of inputs, including new lengths, value ranges or\ninput domains, but also (ii)to assess the robustness of their learned\nmechanisms. By analyzing attention maps and performing targeted interventions,\nwe show that attention mechanism directly causes failures in extrapolation. We\nmake the implementation of all our tasks and interpretability methods publicly\navailable at https://github.com/michalspiegel/AttentionSpan .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.01909v2", "cate": "cs.LG", "date": "2025-02-28", "updated": "2025-07-21"}
{"id": "2502.01250", "title": "Beyond Win Rates: A Clustering-Based Approach to Character Balance Analysis in Team-Based Games", "authors": ["Haokun Zhou"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.01250v2", "summary": "Character diversity in competitive games, while enriching gameplay, often\nintroduces balance challenges that can negatively impact player experience and\nstrategic depth. Traditional balance assessments rely on aggregate metrics like\nwin rates and pick rates, which offer limited insight into the intricate\ndynamics of team-based games and nuanced character roles. This paper proposes a\nnovel clustering-based methodology to analyze character balance, leveraging\nin-game data from Valorant to account for team composition influences and\nreveal latent character roles. By applying hierarchical agglomerative\nclustering with Jensen-Shannon Divergence to professional match data from the\nValorant Champions Tour 2022, our approach identifies distinct clusters of\nagents exhibiting similar co-occurrence patterns within team compositions. This\nmethod not only complements existing quantitative metrics but also provides a\nmore holistic and interpretable perspective on character synergies and\npotential imbalances, offering game developers a valuable tool for informed and\ncontext-aware balance adjustments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.01250v2", "cate": "cs.LG", "date": "2025-02-03", "updated": "2025-07-20"}
{"id": "2503.05549", "title": "Stereo Any Video: Temporally Consistent Stereo Matching", "authors": ["Junpeng Jing", "Weixun Luo", "Ye Mao", "Krystian Mikolajczyk"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV2025", "url": "http://arxiv.org/abs/2503.05549v3", "summary": "This paper introduces Stereo Any Video, a powerful framework for video stereo\nmatching. It can estimate spatially accurate and temporally consistent\ndisparities without relying on auxiliary information such as camera poses or\noptical flow. The strong capability is driven by rich priors from monocular\nvideo depth models, which are integrated with convolutional features to produce\nstable representations. To further enhance performance, key architectural\ninnovations are introduced: all-to-all-pairs correlation, which constructs\nsmooth and robust matching cost volumes, and temporal convex upsampling, which\nimproves temporal coherence. These components collectively ensure robustness,\naccuracy, and temporal consistency, setting a new standard in video stereo\nmatching. Extensive experiments demonstrate that our method achieves\nstate-of-the-art performance across multiple datasets both qualitatively and\nquantitatively in zero-shot settings, as well as strong generalization to\nreal-world indoor and outdoor scenarios.", "comment": "ICCV2025", "pdf_url": "http://arxiv.org/pdf/2503.05549v3", "cate": "cs.CV", "date": "2025-03-07", "updated": "2025-07-21"}
{"id": "2503.05641", "title": "Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for Heterogeneous Reasoning", "authors": ["Justin Chih-Yao Chen", "Sukwon Yun", "Elias Stengel-Eskin", "Tianlong Chen", "Mohit Bansal"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      The first three authors contributed equally. Project Page: this https URL", "url": "http://arxiv.org/abs/2503.05641v3", "summary": "Combining existing pre-trained expert LLMs is a promising avenue for scalably\ntackling large-scale and diverse tasks. However, selecting task-level experts\nis often too coarse-grained, as heterogeneous tasks may require different\nexpertise per instance. To enable adaptive instance-level mixing of pre-trained\nLLM experts, we propose Symbolic-MoE, a symbolic, text-based, and gradient-free\nMixture-of-Experts framework. Symbolic-MoE takes a fine-grained approach to\nselection by emphasizing skills, e.g., algebra in math or molecular biology in\nbiomedical reasoning. We propose a skill-based recruiting strategy that\ndynamically selects the most relevant set of expert LLMs for diverse reasoning\ntasks based on their strengths. Each selected expert then generates its own\nreasoning, resulting in k outputs from k experts, which are then synthesized\ninto a final high-quality response by an aggregator chosen based on its ability\nto integrate diverse reasoning outputs. We show that Symbolic-MoE's\ninstance-level expert selection improves performance by a large margin but --\nwhen implemented naively -- can introduce a high computational overhead due to\nthe need for constant model loading and offloading. To address this, we\nimplement a batch strategy that groups instances based on their assigned\nexperts, loading each model only once. This allows us to integrate 16 expert\nmodels on 1 GPU with a time cost comparable to or better than prior multi-agent\nbaselines using 4 GPUs. Through extensive evaluations on diverse benchmarks\n(MMLU-Pro, GPQA, AIME, and MedMCQA), we show that Symbolic-MoE beats strong\nLLMs like GPT4o-mini, as well as multi-agent approaches, with an absolute avg.\ngain of 8.15% over the best multi-agent baseline. Moreover, Symbolic-MoE\ngeneralizes well to unseen tasks and removes the need for expensive multi-round\ndiscussions, outperforming discussion baselines with less computation.", "comment": "The first three authors contributed equally. Project Page:\n  https://symbolic-moe.github.io/", "pdf_url": "http://arxiv.org/pdf/2503.05641v3", "cate": "cs.CL", "date": "2025-03-07", "updated": "2025-07-18"}
{"id": "2502.06443", "title": "Low-dimensional Functions are Efficiently Learnable under Randomly Biased Distributions", "authors": ["Elisabetta Cornacchia", "Dan Mikulincer", "Elchanan Mossel"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at the 38th Conference on Learning Theory (COLT 2025)", "url": "http://arxiv.org/abs/2502.06443v2", "summary": "The problem of learning single index and multi index models has gained\nsignificant interest as a fundamental task in high-dimensional statistics. Many\nrecent works have analysed gradient-based methods, particularly in the setting\nof isotropic data distributions, often in the context of neural network\ntraining. Such studies have uncovered precise characterisations of algorithmic\nsample complexity in terms of certain analytic properties of the target\nfunction, such as the leap, information, and generative exponents. These\nproperties establish a quantitative separation between low and high complexity\nlearning tasks. In this work, we show that high complexity cases are rare.\nSpecifically, we prove that introducing a small random perturbation to the data\ndistribution--via a random shift in the first moment--renders any Gaussian\nsingle index model as easy to learn as a linear function. We further extend\nthis result to a class of multi index models, namely sparse Boolean functions,\nalso known as Juntas.", "comment": "Accepted at the 38th Conference on Learning Theory (COLT 2025)", "pdf_url": "http://arxiv.org/pdf/2502.06443v2", "cate": "cs.LG", "date": "2025-02-10", "updated": "2025-07-21"}
{"id": "2503.06505", "title": "DynamicID: Zero-Shot Multi-ID Image Personalization with Flexible Facial Editability", "authors": ["Xirui Hu", "Jiahao Wang", "Hao Chen", "Weizhan Zhang", "Benqi Wang", "Yikun Li", "Haishun Nan"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2503.06505v3", "summary": "Recent advances in text-to-image generation have driven interest in\ngenerating personalized human images that depict specific identities from\nreference images. Although existing methods achieve high-fidelity identity\npreservation, they are generally limited to single-ID scenarios and offer\ninsufficient facial editability. We present DynamicID, a tuning-free framework\nthat inherently facilitates both single-ID and multi-ID personalized generation\nwith high fidelity and flexible facial editability. Our key innovations\ninclude: 1) Semantic-Activated Attention (SAA), which employs query-level\nactivation gating to minimize disruption to the base model when injecting ID\nfeatures and achieve multi-ID personalization without requiring multi-ID\nsamples during training. 2) Identity-Motion Reconfigurator (IMR), which applies\nfeature-space manipulation to effectively disentangle and reconfigure facial\nmotion and identity features, supporting flexible facial editing. 3) a\ntask-decoupled training paradigm that reduces data dependency, together with\nVariFace-10k, a curated dataset of 10k unique individuals, each represented by\n35 distinct facial images. Experimental results demonstrate that DynamicID\noutperforms state-of-the-art methods in identity fidelity, facial editability,\nand multi-ID personalization capability. Our code will be released at\nhttps://github.com/ByteCat-bot/DynamicID.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.06505v3", "cate": "cs.CV", "date": "2025-03-09", "updated": "2025-07-21"}
{"id": "2503.07677", "title": "PLADIS: Pushing the Limits of Attention in Diffusion Models at Inference Time by Leveraging Sparsity", "authors": ["Kwanyoung Kim", "Byeongsu Sim"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Camera ready version for ICCV 2025, 30 pages, 20 figures, project page : this https URL", "url": "http://arxiv.org/abs/2503.07677v3", "summary": "Diffusion models have shown impressive results in generating high-quality\nconditional samples using guidance techniques such as Classifier-Free Guidance\n(CFG). However, existing methods often require additional training or neural\nfunction evaluations (NFEs), making them incompatible with guidance-distilled\nmodels. Also, they rely on heuristic approaches that need identifying target\nlayers. In this work, we propose a novel and efficient method, termed PLADIS,\nwhich boosts pre-trained models (U-Net/Transformer) by leveraging sparse\nattention. Specifically, we extrapolate query-key correlations using softmax\nand its sparse counterpart in the cross-attention layer during inference,\nwithout requiring extra training or NFEs. By leveraging the noise robustness of\nsparse attention, our PLADIS unleashes the latent potential of text-to-image\ndiffusion models, enabling them to excel in areas where they once struggled\nwith newfound effectiveness. It integrates seamlessly with guidance techniques,\nincluding guidance-distilled models. Extensive experiments show notable\nimprovements in text alignment and human preference, offering a highly\nefficient and universally applicable solution. See Our project page :\nhttps://cubeyoung.github.io/pladis-proejct/", "comment": "Camera ready version for ICCV 2025, 30 pages, 20 figures, project\n  page : https://cubeyoung.github.io/pladis-proejct/", "pdf_url": "http://arxiv.org/pdf/2503.07677v3", "cate": "cs.LG", "date": "2025-03-10", "updated": "2025-07-19"}
{"id": "2502.07337", "title": "Neural Flow Samplers with Shortcut Models", "authors": ["Wuhao Chen", "Zijing Ou", "Yingzhen Li"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.07337v2", "summary": "Sampling from unnormalized densities presents a fundamental challenge with\nwide-ranging applications, from posterior inference to molecular dynamics\nsimulations. Continuous flow-based neural samplers offer a promising approach,\nlearning a velocity field that satisfies key principles of marginal density\nevolution (e.g., the continuity equation) to generate samples. However, this\nlearning procedure requires accurate estimation of intractable terms linked to\nthe computationally challenging partition function, for which existing\nestimators often suffer from high variance or low accuracy. To overcome this,\nwe introduce an improved estimator for these challenging quantities, employing\na velocity-driven Sequential Monte Carlo method enhanced with control variates.\nFurthermore, we introduce a shortcut consistency model to boost the runtime\nefficiency of the flow-based neural sampler by minimizing its required sampling\nsteps. Our proposed Neural Flow Shortcut Sampler empirically outperforms\nexisting flow-based neural samplers on both synthetic datasets and complex\nn-body system targets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.07337v2", "cate": "cs.LG", "date": "2025-02-11", "updated": "2025-07-20"}
{"id": "2503.07098", "title": "OmniSAM: Omnidirectional Segment Anything Model for UDA in Panoramic Semantic Segmentation", "authors": ["Ding Zhong", "Xu Zheng", "Chenfei Liao", "Yuanhuiyi Lyu", "Jialei Chen", "Shengyang Wu", "Linfeng Zhang", "Xuming Hu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.07098v2", "summary": "Segment Anything Model 2 (SAM2) has emerged as a strong base model in various\npinhole imaging segmentation tasks. However, when applying it to $360^\\circ$\ndomain, the significant field-of-view (FoV) gap between pinhole ($70^\\circ\n\\times 70^\\circ$) and panoramic images ($180^\\circ \\times 360^\\circ$) poses\nunique challenges. Two major concerns for this application includes 1)\ninevitable distortion and object deformation brought by the large FoV disparity\nbetween domains; 2) the lack of pixel-level semantic understanding that the\noriginal SAM2 cannot provide. To address these issues, we propose a novel\nOmniSAM framework, which makes the first attempt to apply SAM2 for panoramic\nsemantic segmentation. Specifically, to bridge the first gap, OmniSAM first\ndivides the panorama into sequences of patches. These patches are then treated\nas image sequences in similar manners as in video segmentation tasks. We then\nleverage the SAM2's memory mechanism to extract cross-patch correspondences\nthat embeds the cross-FoV dependencies, improving feature continuity and the\nprediction consistency along mask boundaries. For the second gap, OmniSAM\nfine-tunes the pretrained image encoder and reutilize the mask decoder for\nsemantic prediction. An FoV-based prototypical adaptation module with dynamic\npseudo label update mechanism is also introduced to facilitate the alignment of\nmemory and backbone features, thereby improving model generalization ability\nacross different sizes of source models. Extensive experimental results\ndemonstrate that OmniSAM outperforms the state-of-the-art methods by large\nmargins, e.g., 79.06% (+10.22%) on SPin8-to-SPan8, 62.46% (+6.58%) on\nCS13-to-DP13.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.07098v2", "cate": "cs.CV", "date": "2025-03-10", "updated": "2025-07-18"}
{"id": "2503.10406", "title": "RealGeneral: Unifying Visual Generation via Temporal In-Context Learning with Video Models", "authors": ["Yijing Lin", "Mengqi Huang", "Shuhan Zhuang", "Zhendong Mao"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.10406v2", "summary": "Unifying diverse image generation tasks within a single framework remains a\nfundamental challenge in visual generation. While large language models (LLMs)\nachieve unification through task-agnostic data and generation, existing visual\ngeneration models fail to meet these principles. Current approaches either rely\non per-task datasets and large-scale training or adapt pre-trained image models\nwith task-specific modifications, limiting their generalizability. In this\nwork, we explore video models as a foundation for unified image generation,\nleveraging their inherent ability to model temporal correlations. We introduce\nRealGeneral, a novel framework that reformulates image generation as a\nconditional frame prediction task, analogous to in-context learning in LLMs. To\nbridge the gap between video models and condition-image pairs, we propose (1) a\nUnified Conditional Embedding module for multi-modal alignment and (2) a\nUnified Stream DiT Block with decoupled adaptive LayerNorm and attention mask\nto mitigate cross-modal interference. RealGeneral demonstrates effectiveness in\nmultiple important visual generation tasks, e.g., it achieves a 14.5%\nimprovement in subject similarity for customized generation and a 10%\nenhancement in image quality for canny-to-image task. Project page:\nhttps://lyne1.github.io/realgeneral_web/; GitHub Link:\nhttps://github.com/Lyne1/RealGeneral", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.10406v2", "cate": "cs.CV", "date": "2025-03-13", "updated": "2025-07-20"}
{"id": "2502.08938", "title": "Reevaluating Policy Gradient Methods for Imperfect-Information Games", "authors": ["Max Rudolph", "Nathan Lichtle", "Sobhan Mohammadpour", "Alexandre Bayen", "J. Zico Kolter", "Amy Zhang", "Gabriele Farina", "Eugene Vinitsky", "Samuel Sokota"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.08938v2", "summary": "In the past decade, motivated by the putative failure of naive self-play deep\nreinforcement learning (DRL) in adversarial imperfect-information games,\nresearchers have developed numerous DRL algorithms based on fictitious play\n(FP), double oracle (DO), and counterfactual regret minimization (CFR). In\nlight of recent results of the magnetic mirror descent algorithm, we\nhypothesize that simpler generic policy gradient methods like PPO are\ncompetitive with or superior to these FP-, DO-, and CFR-based DRL approaches.\nTo facilitate the resolution of this hypothesis, we implement and release the\nfirst broadly accessible exact exploitability computations for four large\ngames. Using these games, we conduct the largest-ever exploitability comparison\nof DRL algorithms for imperfect-information games. Over 5600 training runs, we\nfind that FP-, DO-, and CFR-based approaches fail to outperform generic policy\ngradient methods. Code is available at\nhttps://github.com/nathanlct/IIG-RL-Benchmark and\nhttps://github.com/gabrfarina/exp-a-spiel .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.08938v2", "cate": "cs.LG", "date": "2025-02-13", "updated": "2025-07-19"}
{"id": "2503.10638", "title": "Studying Classifier(-Free) Guidance From a Classifier-Centric Perspective", "authors": ["Xiaoming Zhao", "Alexander G. Schwing"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      v2: added derivation details in Appendix A", "url": "http://arxiv.org/abs/2503.10638v2", "summary": "Classifier-free guidance has become a staple for conditional generation with\ndenoising diffusion models. However, a comprehensive understanding of\nclassifier-free guidance is still missing. In this work, we carry out an\nempirical study to provide a fresh perspective on classifier-free guidance.\nConcretely, instead of solely focusing on classifier-free guidance, we trace\nback to the root, i.e., classifier guidance, pinpoint the key assumption for\nthe derivation, and conduct a systematic study to understand the role of the\nclassifier. We find that both classifier guidance and classifier-free guidance\nachieve conditional generation by pushing the denoising diffusion trajectories\naway from decision boundaries, i.e., areas where conditional information is\nusually entangled and is hard to learn. Based on this classifier-centric\nunderstanding, we propose a generic postprocessing step built upon\nflow-matching to shrink the gap between the learned distribution for a\npre-trained denoising diffusion model and the real data distribution, majorly\naround the decision boundaries. Experiments on various datasets verify the\neffectiveness of the proposed approach.", "comment": "v2: added derivation details in Appendix A", "pdf_url": "http://arxiv.org/pdf/2503.10638v2", "cate": "cs.CV", "date": "2025-03-13", "updated": "2025-07-20"}
{"id": "2503.11299", "title": "BriLLM: Brain-inspired Large Language Model", "authors": ["Hai Zhao", "Hongqiu Wu", "Dongjie Yang", "Anni Zou", "Jiale Hong"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.11299v5", "summary": "This paper reports the first brain-inspired large language model (BriLLM).\nThis is a non-Transformer, non-GPT, non-traditional machine learning\ninput-output controlled generative language model. The model is based on the\nSignal Fully-connected flowing (SiFu) definition on the directed graph in terms\nof the neural network, and has the interpretability of all nodes on the graph\nof the whole model, instead of the traditional machine learning model that only\nhas limited interpretability at the input and output ends. In the language\nmodel scenario, the token is defined as a node in the graph. A randomly shaped\nor user-defined signal flow flows between nodes on the principle of \"least\nresistance\" along paths. The next token or node to be predicted or generated is\nthe target of the signal flow. As a language model, BriLLM theoretically\nsupports infinitely long $n$-gram models when the model size is independent of\nthe input and predicted length of the model. The model's working signal flow\nprovides the possibility of recall activation and innate multi-modal support\nsimilar to the cognitive patterns of the human brain. At present, we released\nthe first BriLLM version in Chinese, with 4000 tokens, 32-dimensional node\nwidth, 16-token long sequence prediction ability, and language model prediction\nperformance comparable to GPT-1. More computing power will help us explore the\ninfinite possibilities depicted above.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.11299v5", "cate": "cs.CL", "date": "2025-03-14", "updated": "2025-07-19"}
{"id": "2502.21284", "title": "Controlled Model Debiasing through Minimal and Interpretable Updates", "authors": ["Federico Di Gennaro", "Thibault Laugel", "Vincent Grari", "Marcin Detyniecki"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.21284v2", "summary": "Traditional approaches to learning fair machine learning models often require\nrebuilding models from scratch, typically without considering potentially\nexisting models. In a context where models need to be retrained frequently,\nthis can lead to inconsistent model updates, as well as redundant and costly\nvalidation testing. To address this limitation, we introduce the notion of\ncontrolled model debiasing, a novel supervised learning task relying on two\ndesiderata: that the differences between the new fair model and the existing\none should be (i) minimal and (ii) interpretable. After providing theoretical\nguarantees to this new problem, we introduce a novel algorithm for algorithmic\nfairness, COMMOD, that is both model-agnostic and does not require the\nsensitive attribute at test time. In addition, our algorithm is explicitly\ndesigned to enforce minimal and interpretable changes between biased and\ndebiased predictions in a binary classification task, a property that, while\nhighly desirable in high-stakes applications, is rarely prioritized as an\nexplicit objective in fairness literature. Our approach combines a\nconcept-based architecture and adversarial learning and we demonstrate through\nempirical results that it achieves comparable performance to state-of-the-art\ndebiasing methods while performing minimal and interpretable prediction\nchanges.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.21284v2", "cate": "cs.LG", "date": "2025-02-28", "updated": "2025-07-21"}
{"id": "2503.13163", "title": "Beyond RGB: Adaptive Parallel Processing for RAW Object Detection", "authors": ["Shani Gamrian", "Hila Barel", "Feiran Li", "Masakazu Yoshimura", "Daisuke Iso"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.13163v2", "summary": "Object detection models are typically applied to standard RGB images\nprocessed through Image Signal Processing (ISP) pipelines, which are designed\nto enhance sensor-captured RAW images for human vision. However, these ISP\nfunctions can lead to a loss of critical information that may be essential in\noptimizing for computer vision tasks, such as object detection. In this work,\nwe introduce Raw Adaptation Module (RAM), a module designed to replace the\ntraditional ISP, with parameters optimized specifically for RAW object\ndetection. Inspired by the parallel processing mechanisms of the human visual\nsystem, RAM departs from existing learned ISP methods by applying multiple ISP\nfunctions in parallel rather than sequentially, allowing for a more\ncomprehensive capture of image features. These processed representations are\nthen fused in a specialized module, which dynamically integrates and optimizes\nthe information for the target task. This novel approach not only leverages the\nfull potential of RAW sensor data but also enables task-specific\npre-processing, resulting in superior object detection performance. Our\napproach outperforms RGB-based methods and achieves state-of-the-art results\nacross diverse RAW image datasets under varying lighting conditions and dynamic\nranges.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.13163v2", "cate": "cs.CV", "date": "2025-03-17", "updated": "2025-07-20"}
{"id": "2503.11720", "title": "Fine-Tuning Diffusion Generative Models via Rich Preference Optimization", "authors": ["Hanyang Zhao", "Haoxian Chen", "Yucheng Guo", "Genta Indra Winata", "Tingting Ou", "Ziyu Huang", "David D. Yao", "Wenpin Tang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.11720v4", "summary": "We introduce Rich Preference Optimization (RPO), a novel pipeline that\nleverages rich feedback signals to improve the curation of preference pairs for\nfine-tuning text-to-image diffusion models. Traditional methods, like\nDiffusion-DPO, often rely solely on reward model labeling, which can be opaque,\noffer limited insights into the rationale behind preferences, and are prone to\nissues such as reward hacking or overfitting. In contrast, our approach begins\nwith generating detailed critiques of synthesized images, from which we extract\nreliable and actionable image editing instructions. By implementing these\ninstructions, we create refined images, resulting in synthetic, informative\npreference pairs that serve as enhanced tuning datasets. We demonstrate the\neffectiveness of our pipeline and the resulting datasets in fine-tuning\nstate-of-the-art diffusion models. Our code is available at\nhttps://github.com/Diffusion-RLHF/RPO.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.11720v4", "cate": "cs.LG", "date": "2025-03-13", "updated": "2025-07-19"}
{"id": "2503.11066", "title": "Further exploration of binding energy residuals using machine learning and the development of a composite ensemble model", "authors": ["I. Bentley", "J. Tedder", "M. Gebran", "A. Paul"], "categories": ["cs.LG", "nucl-th"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Phys. Rev. C - Accepted 17 June, 2025", "url": "http://arxiv.org/abs/2503.11066v3", "summary": "This paper describes the development of the Four Model Tree Ensemble (FMTE).\nThe FMTE is a composite of machine learning models trained on experimental\nbinding energies from the Atomic Mass Evaluation (AME) 2012. The FMTE predicts\nbinding energy values for all nuclei with N > 7 and Z > 7 from AME 2020 with a\nstandard deviation of 76 keV and a mean average deviation of 34 keV. The FMTE\nmodel was developed by combining three new models with one prior model. The new\nmodels presented here have been trained on binding energy residuals from mass\nmodels using four machine learning approaches. The models presented in this\nwork leverage shape parameters along with other physical features. We have\ndetermined the preferred machine learning approach for binding energy residuals\nis the least-squares boosted ensemble of trees. This approach appears to have a\nsuperior ability to both interpolate and extrapolate binding energy residuals.\nA comparison with the masses of isotopes that were not measured previously and\na discussion of extrapolations approaching the neutron drip line have been\nincluded.", "comment": "Phys. Rev. C - Accepted 17 June, 2025", "pdf_url": "http://arxiv.org/pdf/2503.11066v3", "cate": "cs.LG", "date": "2025-03-14", "updated": "2025-07-21"}
{"id": "2503.14075", "title": "Growing a Twig to Accelerate Large Vision-Language Models", "authors": ["Zhenwei Shao", "Mingyang Wang", "Zhou Yu", "Wenwen Pan", "Yan Yang", "Tao Wei", "Hongyuan Zhang", "Ning Mao", "Wei Chen", "Jun Yu"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted at ICCV 2025", "url": "http://arxiv.org/abs/2503.14075v2", "summary": "Large vision-language models (VLMs) have demonstrated remarkable capabilities\nin open-world multimodal understanding, yet their high computational overheads\npose great challenges for practical deployment. Some recent works have proposed\nmethods to accelerate VLMs by pruning redundant visual tokens guided by the\nattention maps of VLM's early layers. Despite the success of these token\npruning methods, they still suffer from two major shortcomings: (i)\nconsiderable accuracy drop due to insensitive attention signals in early\nlayers, and (ii) limited speedup when generating long responses (e.g., 30\ntokens). To address the limitations above, we present TwigVLM -- a simple and\ngeneral architecture by growing a lightweight twig upon an early layer of the\nbase VLM. Compared with most existing VLM acceleration methods purely based on\nvisual token pruning, our TwigVLM not only achieves better accuracy retention\nby employing a twig-guided token pruning (TTP) strategy, but also yields higher\ngeneration speed by utilizing a self-speculative decoding (SSD) strategy.\nTaking LLaVA-1.5-7B as the base VLM, experimental results show that TwigVLM\npreserves 96% of the original performance after pruning 88.9% of visual tokens\nand achieves 154% speedup in generating long responses, delivering\nsignificantly better performance in terms of both accuracy and speed over the\nstate-of-the-art VLM acceleration methods.", "comment": "accepted at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.14075v2", "cate": "cs.CV", "date": "2025-03-18", "updated": "2025-07-19"}
{"id": "2503.12897", "title": "Federated Continual Instruction Tuning", "authors": ["Haiyang Guo", "Fanhu Zeng", "Fei Zhu", "Wenzhuo Liu", "Da-Han Wang", "Jian Xu", "Xu-Yao Zhang", "Cheng-Lin Liu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2503.12897v2", "summary": "A vast amount of instruction tuning data is crucial for the impressive\nperformance of Large Multimodal Models (LMMs), but the associated computational\ncosts and data collection demands during supervised fine-tuning make it\nimpractical for most researchers. Federated learning (FL) has the potential to\nleverage all distributed data and training resources to reduce the overhead of\njoint training. However, most existing methods assume a fixed number of tasks,\nwhile in real-world scenarios, clients continuously encounter new knowledge and\noften struggle to retain old tasks due to memory constraints. In this work, we\nintroduce the Federated Continual Instruction Tuning (FCIT) benchmark to model\nthis real-world challenge. Our benchmark includes two realistic scenarios,\nencompassing four different settings and twelve carefully curated instruction\ntuning datasets. To address the challenges posed by FCIT, we propose dynamic\nknowledge organization to effectively integrate updates from different tasks\nduring training and subspace selective activation to allocate task-specific\noutput during inference. Extensive experimental results demonstrate that our\nproposed method significantly enhances model performance across varying levels\nof data heterogeneity and catastrophic forgetting. Code and dataset are\nreleased at https://github.com/Ghy0501/FCIT.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.12897v2", "cate": "cs.LG", "date": "2025-03-17", "updated": "2025-07-21"}
{"id": "2504.09459", "title": "Measuring Leakage in Concept-Based Methods: An Information Theoretic Approach", "authors": ["Mikael Makonnen", "Moritz Vandenhirtz", "Sonia Laguna", "Julia E Vogt"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published at ICLR 2025 Workshop on XAI4Science", "url": "http://arxiv.org/abs/2504.09459v2", "summary": "Concept Bottleneck Models (CBMs) aim to enhance interpretability by\nstructuring predictions around human-understandable concepts. However,\nunintended information leakage, where predictive signals bypass the concept\nbottleneck, compromises their transparency. This paper introduces an\ninformation-theoretic measure to quantify leakage in CBMs, capturing the extent\nto which concept embeddings encode additional, unintended information beyond\nthe specified concepts. We validate the measure through controlled synthetic\nexperiments, demonstrating its effectiveness in detecting leakage trends across\nvarious configurations. Our findings highlight that feature and concept\ndimensionality significantly influence leakage, and that classifier choice\nimpacts measurement stability, with XGBoost emerging as the most reliable\nestimator. Additionally, preliminary investigations indicate that the measure\nexhibits the anticipated behavior when applied to soft joint CBMs, suggesting\nits reliability in leakage quantification beyond fully synthetic settings.\nWhile this study rigorously evaluates the measure in controlled synthetic\nexperiments, future work can extend its application to real-world datasets.", "comment": "Published at ICLR 2025 Workshop on XAI4Science", "pdf_url": "http://arxiv.org/pdf/2504.09459v2", "cate": "cs.LG", "date": "2025-04-13", "updated": "2025-07-20"}
{"id": "2503.15475", "title": "Cube: A Roblox View of 3D Intelligence", "authors": ["Foundation AI Team", "Kiran Bhat", "Nishchaie Khanna", "Karun Channa", "Tinghui Zhou", "Yiheng Zhu", "Xiaoxia Sun", "Charles Shang", "Anirudh Sudarshan", "Maurice Chu", "Daiqing Li", "Kangle Deng", "Jean-Philippe Fauconnier", "Tijmen Verhulsdonck", "Maneesh Agrawala", "Kayvon Fatahalian", "Alexander Weiss", "Christian Reiser", "Ravi Kiran Chirravuri", "Ravali Kandur", "Alejandro Pelaez", "Akash Garg", "Michael Palleschi", "Jessica Wang", "Skylar Litz", "Leon Liu", "Anying Li", "David Harmon", "Derek Liu", "Liangjun Feng", "Denis Goupil", "Lukas Kuczynski", "Jihyun Yoon", "Naveen Marri", "Peiye Zhuang", "Yinan Zhang", "Brian Yin", "Haomiao Jiang", "Marcel van Workum", "Thomas Lane", "Bryce Erickson", "Salil Pathare", "Kyle Price", "Steve Han", "Yiqing Wang", "Anupam Singh", "David Baszucki"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Our code and model weights can be found at: this https URL", "url": "http://arxiv.org/abs/2503.15475v3", "summary": "Foundation models trained on vast amounts of data have demonstrated\nremarkable reasoning and generation capabilities in the domains of text,\nimages, audio and video. Our goal at Roblox is to build such a foundation model\nfor 3D intelligence, a model that can support developers in producing all\naspects of a Roblox experience, from generating 3D objects and scenes to\nrigging characters for animation to producing programmatic scripts describing\nobject behaviors. We discuss three key design requirements for such a 3D\nfoundation model and then present our first step towards building such a model.\nWe expect that 3D geometric shapes will be a core data type and describe our\nsolution for 3D shape tokenizer. We show how our tokenization scheme can be\nused in applications for text-to-shape generation, shape-to-text generation and\ntext-to-scene generation. We demonstrate how these applications can collaborate\nwith existing large language models (LLMs) to perform scene analysis and\nreasoning. We conclude with a discussion outlining our path to building a fully\nunified foundation model for 3D intelligence.", "comment": "Our code and model weights can be found at:\n  https://github.com/Roblox/cube", "pdf_url": "http://arxiv.org/pdf/2503.15475v3", "cate": "cs.CV", "date": "2025-03-19", "updated": "2025-07-18"}
{"id": "2503.15867", "title": "TruthLens: Explainable DeepFake Detection for Face Manipulated and Fully Synthetic Data", "authors": ["Rohit Kundu", "Shan Jia", "Vishal Mohanty", "Athula Balachandran", "Amit K. Roy-Chowdhury"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.15867v2", "summary": "Detecting DeepFakes has become a crucial research area as the widespread use\nof AI image generators enables the effortless creation of face-manipulated and\nfully synthetic content, yet existing methods are often limited to binary\nclassification (real vs. fake) and lack interpretability. To address these\nchallenges, we propose TruthLens, a novel and highly generalizable framework\nfor DeepFake detection that not only determines whether an image is real or\nfake but also provides detailed textual reasoning for its predictions. Unlike\ntraditional methods, TruthLens effectively handles both face-manipulated\nDeepFakes and fully AI-generated content while addressing fine-grained queries\nsuch as \"Does the eyes/nose/mouth look real or fake?\"\n  The architecture of TruthLens combines the global contextual understanding of\nmultimodal large language models like PaliGemma2 with the localized feature\nextraction capabilities of vision-only models like DINOv2. This hybrid design\nleverages the complementary strengths of both models, enabling robust detection\nof subtle manipulations while maintaining interpretability. Extensive\nexperiments on diverse datasets demonstrate that TruthLens outperforms\nstate-of-the-art methods in detection accuracy (by 2-14%) and explainability,\nin both in-domain and cross-data settings, generalizing effectively across\ntraditional and emerging manipulation techniques.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.15867v2", "cate": "cs.CV", "date": "2025-03-20", "updated": "2025-07-19"}
{"id": "2504.13296", "title": "Enhanced Pruning Strategy for Multi-Component Neural Architectures Using Component-Aware Graph Analysis", "authors": ["Ganesh Sundaram", "Jonas Ulmen", "Daniel Görges"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      6 pages, IFAC J3C, 2025", "url": "http://arxiv.org/abs/2504.13296v2", "summary": "Deep neural networks (DNNs) deliver outstanding performance, but their\ncomplexity often prohibits deployment in resource-constrained settings.\nComprehensive structured pruning frameworks based on parameter dependency\nanalysis reduce model size with specific regard to computational performance.\nWhen applying them to Multi-Component Neural Architectures (MCNAs), they risk\nnetwork integrity by removing large parameter groups. We introduce a\ncomponent-aware pruning strategy, extending dependency graphs to isolate\nindividual components and inter-component flows. This creates smaller, targeted\npruning groups that conserve functional integrity. Demonstrated effectively on\na control task, our approach achieves greater sparsity and reduced performance\ndegradation, opening a path for optimizing complex, multi-component DNNs\nefficiently.", "comment": "6 pages, IFAC J3C, 2025", "pdf_url": "http://arxiv.org/pdf/2504.13296v2", "cate": "cs.LG", "date": "2025-04-17", "updated": "2025-07-20"}
{"id": "2503.16832", "title": "Joint Self-Supervised Video Alignment and Action Segmentation", "authors": ["Ali Shah Ali", "Syed Ahmed Mahmood", "Mubin Saeed", "Andrey Konin", "M. Zeeshan Zia", "Quoc-Huy Tran"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2503.16832v2", "summary": "We introduce a novel approach for simultaneous self-supervised video\nalignment and action segmentation based on a unified optimal transport\nframework. In particular, we first tackle self-supervised video alignment by\ndeveloping a fused Gromov-Wasserstein optimal transport formulation with a\nstructural prior, which trains efficiently on GPUs and needs only a few\niterations for solving the optimal transport problem. Our single-task method\nachieves the state-of-the-art performance on multiple video alignment\nbenchmarks and outperforms VAVA, which relies on a traditional Kantorovich\noptimal transport formulation with an optimality prior. Furthermore, we extend\nour approach by proposing a unified optimal transport framework for joint\nself-supervised video alignment and action segmentation, which requires\ntraining and storing a single model and saves both time and memory consumption\nas compared to two different single-task models. Extensive evaluations on\nseveral video alignment and action segmentation datasets demonstrate that our\nmulti-task method achieves comparable video alignment yet superior action\nsegmentation results over previous methods in video alignment and action\nsegmentation respectively. Finally, to the best of our knowledge, this is the\nfirst work to unify video alignment and action segmentation into a single\nmodel.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.16832v2", "cate": "cs.CV", "date": "2025-03-21", "updated": "2025-07-21"}
{"id": "2503.21544", "title": "SWI: Speaking with Intent in Large Language Models", "authors": ["Yuwei Yin", "EunJeong Hwang", "Giuseppe Carenini"], "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Code: this https URL", "url": "http://arxiv.org/abs/2503.21544v2", "summary": "Intent, typically clearly formulated and planned, functions as a cognitive\nframework for communication and problem-solving. This paper introduces the\nconcept of Speaking with Intent (SWI) in large language models (LLMs), where\nthe explicitly generated intent encapsulates the model's underlying intention\nand provides high-level planning to guide subsequent analysis and action. By\nemulating deliberate and purposeful thoughts in the human mind, SWI is\nhypothesized to enhance the reasoning capabilities and generation quality of\nLLMs. Extensive experiments on text summarization, multi-task question\nanswering, and mathematical reasoning benchmarks consistently demonstrate the\neffectiveness and generalizability of Speaking with Intent over direct\ngeneration without explicit intent. Further analysis corroborates the\ngeneralizability of SWI under different experimental settings. Moreover, human\nevaluations verify the coherence, effectiveness, and interpretability of the\nintent produced by SWI. The promising results in enhancing LLMs with explicit\nintents pave a new avenue for boosting LLMs' generation and reasoning abilities\nwith cognitive notions.", "comment": "Code: https://github.com/YuweiYin/SWI", "pdf_url": "http://arxiv.org/pdf/2503.21544v2", "cate": "cs.CL", "date": "2025-03-27", "updated": "2025-07-19"}
{"id": "2504.18208", "title": "Ultra-fast feature learning for the training of two-layer neural networks in the two-timescale regime", "authors": ["Raphaël Barboni", "Gabriel Peyré", "François-Xavier Vialard"], "categories": ["cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.18208v2", "summary": "We study the convergence of gradient methods for the training of mean-field\nsingle-hidden-layer neural networks with square loss. For this high-dimensional\nand non-convex optimization problem, most known convergence results are either\nqualitative or rely on a neural tangent kernel analysis where nonlinear\nrepresentations of the data are fixed. Using that this problem belongs to the\nclass of separable nonlinear least squares problems, we consider here a\nVariable Projection (VarPro) or two-timescale learning algorithm, thereby\neliminating the linear variables and reducing the learning problem to the\ntraining of nonlinear features. In a teacher-student scenario, we show such a\nstrategy enables provable convergence rates for the sampling of a teacher\nfeature distribution. Precisely, in the limit where the regularization strength\nvanishes, we show that the dynamic of the feature distribution corresponds to a\nweighted ultra-fast diffusion equation. Recent results on the asymptotic\nbehavior of such PDEs then give quantitative guarantees for the convergence of\nthe learned feature distribution.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.18208v2", "cate": "cs.LG", "date": "2025-04-25", "updated": "2025-07-21"}
{"id": "2503.19557", "title": "Dance Like a Chicken: Low-Rank Stylization for Human Motion Diffusion", "authors": ["Haim Sawdayee", "Chuan Guo", "Guy Tevet", "Bing Zhou", "Jian Wang", "Amit H. Bermano"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page at this https URL", "url": "http://arxiv.org/abs/2503.19557v3", "summary": "Text-to-motion generative models span a wide range of 3D human actions but\nstruggle with nuanced stylistic attributes such as a \"Chicken\" style. Due to\nthe scarcity of style-specific data, existing approaches pull the generative\nprior towards a reference style, which often results in out-of-distribution low\nquality generations. In this work, we introduce LoRA-MDM, a lightweight\nframework for motion stylization that generalizes to complex actions while\nmaintaining editability. Our key insight is that adapting the generative prior\nto include the style, while preserving its overall distribution, is more\neffective than modifying each individual motion during generation. Building on\nthis idea, LoRA-MDM learns to adapt the prior to include the reference style\nusing only a few samples. The style can then be used in the context of\ndifferent textual prompts for generation. The low-rank adaptation shifts the\nmotion manifold in a semantically meaningful way, enabling realistic style\ninfusion even for actions not present in the reference samples. Moreover,\npreserving the distribution structure enables advanced operations such as style\nblending and motion editing. We compare LoRA-MDM to state-of-the-art stylized\nmotion generation methods and demonstrate a favorable balance between text\nfidelity and style consistency.", "comment": "Project page at https://haimsaw.github.io/LoRA-MDM/", "pdf_url": "http://arxiv.org/pdf/2503.19557v3", "cate": "cs.CV", "date": "2025-03-25", "updated": "2025-07-21"}
{"id": "2504.01216", "title": "Detecting PTSD in Clinical Interviews: A Comparative Analysis of NLP Methods and Large Language Models", "authors": ["Feng Chen", "Dror Ben-Zeev", "Gillian Sparks", "Arya Kadakia", "Trevor Cohen"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.01216v2", "summary": "Post-Traumatic Stress Disorder (PTSD) remains underdiagnosed in clinical\nsettings, presenting opportunities for automated detection to identify\npatients. This study evaluates natural language processing approaches for\ndetecting PTSD from clinical interview transcripts. We compared general and\nmental health-specific transformer models (BERT/RoBERTa), embedding-based\nmethods (SentenceBERT/LLaMA), and large language model prompting strategies\n(zero-shot/few-shot/chain-of-thought) using the DAIC-WOZ dataset.\nDomain-specific end-to-end models significantly outperformed general models\n(Mental-RoBERTa AUPRC=0.675+/-0.084 vs. RoBERTa-base 0.599+/-0.145).\nSentenceBERT embeddings with neural networks achieved the highest overall\nperformance (AUPRC=0.758+/-0.128). Few-shot prompting using DSM-5 criteria\nyielded competitive results with two examples (AUPRC=0.737). Performance varied\nsignificantly across symptom severity and comorbidity status with depression,\nwith higher accuracy for severe PTSD cases and patients with comorbid\ndepression. Our findings highlight the potential of domain-adapted embeddings\nand LLMs for scalable screening while underscoring the need for improved\ndetection of nuanced presentations and offering insights for developing\nclinically viable AI tools for PTSD assessment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.01216v2", "cate": "cs.CL", "date": "2025-04-01", "updated": "2025-07-21"}
{"id": "2504.20887", "title": "Return Capping: Sample-Efficient CVaR Policy Gradient Optimisation", "authors": ["Harry Mead", "Clarissa Costen", "Bruno Lacerda", "Nick Hawes"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.20887v2", "summary": "When optimising for conditional value at risk (CVaR) using policy gradients\n(PG), current methods rely on discarding a large proportion of trajectories,\nresulting in poor sample efficiency. We propose a reformulation of the CVaR\noptimisation problem by capping the total return of trajectories used in\ntraining, rather than simply discarding them, and show that this is equivalent\nto the original problem if the cap is set appropriately. We show, with\nempirical results in an number of environments, that this reformulation of the\nproblem results in consistently improved performance compared to baselines. We\nhave made all our code available here:\nhttps://github.com/HarryMJMead/cvar-return-capping.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.20887v2", "cate": "cs.LG", "date": "2025-04-29", "updated": "2025-07-21"}
{"id": "2503.21313", "title": "HORT: Monocular Hand-held Objects Reconstruction with Transformers", "authors": ["Zerui Chen", "Rolandos Alexandros Potamias", "Shizhe Chen", "Cordelia Schmid"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025. Project Page: this https URL", "url": "http://arxiv.org/abs/2503.21313v2", "summary": "Reconstructing hand-held objects in 3D from monocular images remains a\nsignificant challenge in computer vision. Most existing approaches rely on\nimplicit 3D representations, which produce overly smooth reconstructions and\nare time-consuming to generate explicit 3D shapes. While more recent methods\ndirectly reconstruct point clouds with diffusion models, the multi-step\ndenoising makes high-resolution reconstruction inefficient. To address these\nlimitations, we propose a transformer-based model to efficiently reconstruct\ndense 3D point clouds of hand-held objects. Our method follows a coarse-to-fine\nstrategy, first generating a sparse point cloud from the image and\nprogressively refining it into a dense representation using pixel-aligned image\nfeatures. To enhance reconstruction accuracy, we integrate image features with\n3D hand geometry to jointly predict the object point cloud and its pose\nrelative to the hand. Our model is trained end-to-end for optimal performance.\nExperimental results on both synthetic and real datasets demonstrate that our\nmethod achieves state-of-the-art accuracy with much faster inference speed,\nwhile generalizing well to in-the-wild images.", "comment": "Accepted by ICCV 2025. Project Page:\n  https://zerchen.github.io/projects/hort.html", "pdf_url": "http://arxiv.org/pdf/2503.21313v2", "cate": "cs.CV", "date": "2025-03-27", "updated": "2025-07-21"}
{"id": "2504.03022", "title": "The Dual-Route Model of Induction", "authors": ["Sheridan Feucht", "Eric Todd", "Byron Wallace", "David Bau"], "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      43 pages, 49 figures. Published as a conference paper at COLM 2025. Code and data at this https URL", "url": "http://arxiv.org/abs/2504.03022v2", "summary": "Prior work on in-context copying has shown the existence of induction heads,\nwhich attend to and promote individual tokens during copying. In this work we\ndiscover a new type of induction head: concept-level induction heads, which\ncopy entire lexical units instead of individual tokens. Concept induction heads\nlearn to attend to the ends of multi-token words throughout training, working\nin parallel with token-level induction heads to copy meaningful text. We show\nthat these heads are responsible for semantic tasks like word-level\ntranslation, whereas token induction heads are vital for tasks that can only be\ndone verbatim (like copying nonsense tokens). These two \"routes\" operate\nindependently: we show that ablation of token induction heads causes models to\nparaphrase where they would otherwise copy verbatim. By patching concept\ninduction head outputs, we find that they contain language-independent word\nrepresentations that mediate natural language translation, suggesting that LLMs\nrepresent abstract word meanings independent of language or form.", "comment": "43 pages, 49 figures. Published as a conference paper at COLM 2025.\n  Code and data at https://dualroute.baulab.info", "pdf_url": "http://arxiv.org/pdf/2504.03022v2", "cate": "cs.CL", "date": "2025-04-03", "updated": "2025-07-20"}
{"id": "2505.05677", "title": "Conditional Front-door Adjustment for Heterogeneous Treatment Assignment Effect Estimation Under Non-adherence", "authors": ["Winston Chen", "Trenton Chang", "Jenna Wiens"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Conference on Health, Inference, and Learning (CHIL) 2025", "url": "http://arxiv.org/abs/2505.05677v4", "summary": "Estimates of heterogeneous treatment assignment effects can inform treatment\ndecisions. Under the presence of non-adherence (e.g., patients do not adhere to\ntheir assigned treatment), both the standard backdoor adjustment (SBD) and the\nconditional front-door adjustment (CFD) can recover unbiased estimates of the\ntreatment assignment effects. However, the estimation variance of these\napproaches may vary widely across settings, which remains underexplored in the\nliterature. In this work, we demonstrate theoretically and empirically that CFD\nyields lower-variance estimates than SBD when the true effect of treatment\nassignment is small (i.e., assigning an intervention leads to small changes in\npatients' future outcome). Additionally, since CFD requires estimating multiple\nnuisance parameters, we introduce LobsterNet, a multi-task neural network that\nimplements CFD with joint modeling of the nuisance parameters. Empirically,\nLobsterNet reduces estimation error across several semi-synthetic and\nreal-world datasets compared to baselines. Our findings suggest CFD with shared\nnuisance parameter modeling can improve treatment assignment effect estimation\nunder non-adherence.", "comment": "Conference on Health, Inference, and Learning (CHIL) 2025", "pdf_url": "http://arxiv.org/pdf/2505.05677v4", "cate": "cs.LG", "date": "2025-05-08", "updated": "2025-07-20"}
{"id": "2504.07942", "title": "MARS: a Multimodal Alignment and Ranking System for Few-Shot Segmentation", "authors": ["Nico Catalano", "Stefano Samele", "Paolo Pertino", "Matteo Matteucci"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.07942v2", "summary": "Few Shot Segmentation aims to segment novel object classes given only a\nhandful of labeled examples, enabling rapid adaptation with minimal\nsupervision. Current literature crucially lacks a selection method that goes\nbeyond visual similarity between the query and example images, leading to\nsuboptimal predictions. We present MARS, a plug-and-play ranking system that\nleverages multimodal cues to filter and merge mask proposals robustly. Starting\nfrom a set of mask predictions for a single query image, we score, filter, and\nmerge them to improve results. Proposals are evaluated using multimodal scores\ncomputed at local and global levels. Extensive experiments on COCO-20i,\nPascal-5i, LVIS-92i, and FSS-1000 demonstrate that integrating all four scoring\ncomponents is crucial for robust ranking, validating our contribution. As MARS\ncan be effortlessly integrated with various mask proposal systems, we deploy it\nacross a wide range of top-performer methods and achieve new state-of-the-art\nresults on multiple existing benchmarks. Code will be available upon\nacceptance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.07942v2", "cate": "cs.CV", "date": "2025-04-10", "updated": "2025-07-21"}
{"id": "2504.03601", "title": "APIGen-MT: Agentic Pipeline for Multi-Turn Data Generation via Simulated Agent-Human Interplay", "authors": ["Akshara Prabhakar", "Zuxin Liu", "Ming Zhu", "Jianguo Zhang", "Tulika Awalgaonkar", "Shiyu Wang", "Zhiwei Liu", "Haolin Chen", "Thai Hoang", "Juan Carlos Niebles", "Shelby Heinecke", "Weiran Yao", "Huan Wang", "Silvio Savarese", "Caiming Xiong"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages plus references and appendices; fixes typo in fig 6", "url": "http://arxiv.org/abs/2504.03601v4", "summary": "Training effective AI agents for multi-turn interactions requires\nhigh-quality data that captures realistic human-agent dynamics, yet such data\nis scarce and expensive to collect manually. We introduce APIGen-MT, a\ntwo-phase framework that generates verifiable and diverse multi-turn agent\ndata. In the first phase, our agentic pipeline produces detailed task\nblueprints with ground-truth actions, leveraging a committee of LLM reviewers\nand iterative feedback loops. These blueprints are then transformed into\ncomplete interaction trajectories through simulated human-agent interplay. We\ntrain a family of models -- the xLAM-2-fc-r series with sizes ranging from 1B\nto 70B parameters. Our models outperform frontier models such as GPT-4o and\nClaude 3.5 on $\\tau$-bench and BFCL benchmarks, with the smaller models\nsurpassing their larger counterparts, particularly in multi-turn settings,\nwhile maintaining superior consistency across multiple trials. Comprehensive\nexperiments demonstrate that our verified blueprint-to-details approach yields\nhigh-quality training data, enabling the development of more reliable,\nefficient, and capable agents. We open-source 5K synthetic data trajectories\nand the trained xLAM-2-fc-r models to advance research in AI agents.\n  Models at\nhttps://huggingface.co/collections/Salesforce/xlam-2-67ef5be12949d8dcdae354c4;\nDataset at https://huggingface.co/datasets/Salesforce/APIGen-MT-5k and Website\nat https://apigen-mt.github.io", "comment": "12 pages plus references and appendices; fixes typo in fig 6", "pdf_url": "http://arxiv.org/pdf/2504.03601v4", "cate": "cs.CL", "date": "2025-04-04", "updated": "2025-07-19"}
{"id": "2505.06178", "title": "A Large Language Model-Enhanced Q-learning for Capacitated Vehicle Routing Problem with Time Windows", "authors": ["Linjiang Cao", "Maonan Wang", "Xi Xiong"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.06178v2", "summary": "The Capacitated Vehicle Routing Problem with Time Windows (CVRPTW) is a\nclassic NP-hard combinatorial optimization problem widely applied in logistics\ndistribution and transportation management. Its complexity stems from the\nconstraints of vehicle capacity and time windows, which pose significant\nchallenges to traditional approaches. Advances in Large Language Models (LLMs)\nprovide new possibilities for finding approximate solutions to CVRPTW. This\npaper proposes a novel LLM-enhanced Q-learning framework to address the CVRPTW\nwith real-time emergency constraints. Our solution introduces an adaptive\ntwo-phase training mechanism that transitions from the LLM-guided exploration\nphase to the autonomous optimization phase of Q-network. To ensure reliability,\nwe design a three-tier self-correction mechanism based on the Chain-of-Thought\n(CoT) for LLMs: syntactic validation, semantic verification, and physical\nconstraint enforcement. In addition, we also prioritized replay of the\nexperience generated by LLMs to amplify the regulatory role of LLMs in the\narchitecture. Experimental results demonstrate that our framework achieves a\n7.3\\% average reduction in cost compared to traditional Q-learning, with fewer\ntraining steps required for convergence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.06178v2", "cate": "cs.LG", "date": "2025-05-09", "updated": "2025-07-21"}
{"id": "2504.09384", "title": "Contour Flow Constraint: Preserving Global Shape Similarity for Deep Learning based Image Segmentation", "authors": ["Shengzhe Chen", "Zhaoxuan Dong", "Jun Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Submitted to IEEE Transactions on Image Processing on Dec-14-2023. Revised on Oct-16-2024, June-4-2025. Accepted on July-8-2025", "url": "http://arxiv.org/abs/2504.09384v2", "summary": "For effective image segmentation, it is crucial to employ constraints\ninformed by prior knowledge about the characteristics of the areas to be\nsegmented to yield favorable segmentation outcomes. However, the existing\nmethods have primarily focused on priors of specific properties or shapes,\nlacking consideration of the general global shape similarity from a Contour\nFlow (CF) perspective. Furthermore, naturally integrating this contour flow\nprior image segmentation model into the activation functions of deep\nconvolutional networks through mathematical methods is currently unexplored. In\nthis paper, we establish a concept of global shape similarity based on the\npremise that two shapes exhibit comparable contours. Furthermore, we\nmathematically derive a contour flow constraint that ensures the preservation\nof global shape similarity. We propose two implementations to integrate the\nconstraint with deep neural networks. Firstly, the constraint is converted to a\nshape loss, which can be seamlessly incorporated into the training phase for\nany learning-based segmentation framework. Secondly, we add the constraint into\na variational segmentation model and derive its iterative schemes for solution.\nThe scheme is then unrolled to get the architecture of the proposed CFSSnet.\nValidation experiments on diverse datasets are conducted on classic benchmark\ndeep network segmentation models. The results indicate a great improvement in\nsegmentation accuracy and shape similarity for the proposed shape loss,\nshowcasing the general adaptability of the proposed loss term regardless of\nspecific network architectures. CFSSnet shows robustness in segmenting\nnoise-contaminated images, and inherent capability to preserve global shape\nsimilarity.", "comment": "Submitted to IEEE Transactions on Image Processing on Dec-14-2023.\n  Revised on Oct-16-2024, June-4-2025. Accepted on July-8-2025", "pdf_url": "http://arxiv.org/pdf/2504.09384v2", "cate": "cs.CV", "date": "2025-04-13", "updated": "2025-07-19"}
{"id": "2504.09763", "title": "Executable Functional Abstractions: Inferring Generative Programs for Advanced Math Problems", "authors": ["Zaid Khan", "Elias Stengel-Eskin", "Archiki Prasad", "Jaemin Cho", "Mohit Bansal"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Project Page: this https URL", "url": "http://arxiv.org/abs/2504.09763v2", "summary": "Scientists often infer abstract procedures from specific instances of\nproblems and use the abstractions to generate new, related instances. For\nexample, programs encoding the formal rules and properties of a system have\nbeen useful in fields ranging from reinforcement learning (procedural\nenvironments) to physics (simulation engines). These programs can be seen as\nfunctions which execute to different outputs based on their parameterizations\n(e.g., gridworld configuration or initial physical conditions). We introduce\nthe term EFA (Executable Functional Abstraction) to denote such programs for\nmath problems. EFA-like constructs have been shown to be useful for\nmathematical reasoning as problem generators for stress-testing models.\nHowever, prior work has been limited to automatically constructing abstractions\nfor grade-school math (whose simple rules are easy to encode in programs),\nwhile generating EFAs for advanced math has thus far required human\nengineering. We explore the automatic construction of EFAs for advanced\nmathematics problems by developing EFAGen, which operationalizes the task of\nautomatically inferring an EFA for a given seed problem and solution as a\nprogram synthesis task. We first formalize the properties of any valid EFA as\nexecutable unit tests. Using execution feedback from the unit tests, we search\nover candidate programs sampled from a LLM to find EFA programs that are\nfaithful to the generalized problem and solution class underlying the seed\nproblem. We then apply the tests as a reward signal, training LLMs to become\nbetter writers of EFAs. We show that EFAs inferred by EFAGen are faithful to\nthe seed problems, produce learnable problem variations, and that EFAGen can\ninfer EFAs across diverse sources of competition-level math problems. Finally,\nwe show uses of model-written EFAs e.g., finding harder/easier problem\nvariants, as well as data generation.", "comment": "Project Page: https://zaidkhan.me/EFAGen/", "pdf_url": "http://arxiv.org/pdf/2504.09763v2", "cate": "cs.CL", "date": "2025-04-14", "updated": "2025-07-21"}
{"id": "2505.16122", "title": "Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning", "authors": ["Junhong Lin", "Xinyue Zeng", "Jie Zhu", "Song Wang", "Julian Shun", "Jun Wu", "Dawei Zhou"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.16122v2", "summary": "Large Language Models (LLMs) have achieved remarkable success in complex\nreasoning tasks, but their inference remains computationally inefficient. We\nobserve a common failure mode in many prevalent LLMs, overthinking, where\nmodels generate verbose and tangential reasoning traces even for simple\nqueries. Recent works have tried to mitigate this by enforcing fixed token\nbudgets, however, this can lead to underthinking, especially on harder\nproblems. Through empirical analysis, we identify that this inefficiency often\nstems from unclear problem-solving strategies. To formalize this, we develop a\ntheoretical model, BBAM (Bayesian Budget Allocation Model), which models\nreasoning as a sequence of sub-questions with varying uncertainty, and\nintroduce the $E^3$ metric to capture the trade-off between correctness and\ncomputation efficiency. Building on theoretical results from BBAM, we propose\nPlan-and-Budget, a model-agnostic, test-time framework that decomposes complex\nqueries into sub-questions and allocates token budgets based on estimated\ncomplexity using adaptive scheduling. Plan-and-Budget improves reasoning\nefficiency across a range of tasks and models, achieving up to +70% accuracy\ngains, -39% token reduction, and +187.5% improvement in $E^3$. Notably, it\nelevates a smaller model (DS-Qwen-32B) to match the efficiency of a larger\nmodel (DS-LLaMA-70B)-demonstrating Plan-and-Budget's ability to close\nperformance gaps without retraining. Our code is available at\nhttps://github.com/junhongmit/P-and-B.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.16122v2", "cate": "cs.LG", "date": "2025-05-22", "updated": "2025-07-21"}
{"id": "2504.13275", "title": "ChartQA-X: Generating Explanations for Visual Chart Reasoning", "authors": ["Shamanthak Hegde", "Pooyan Fazli", "Hasti Seifi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.13275v2", "summary": "The ability to explain complex information from chart images is vital for\neffective data-driven decision-making. In this work, we address the challenge\nof generating detailed explanations alongside answering questions about charts.\nWe present ChartQA-X, a comprehensive dataset comprising 30,299 chart samples\nacross four chart types, each paired with contextually relevant questions,\nanswers, and explanations. Explanations are generated and selected based on\nmetrics such as faithfulness, informativeness, coherence, and perplexity. Our\nhuman evaluation with 245 participants shows that model-generated explanations\nin ChartQA-X surpass human-written explanations in accuracy and logic and are\ncomparable in terms of clarity and overall quality. Moreover, models fine-tuned\non ChartQA-X show substantial improvements across various metrics, including\nabsolute gains of up to 24.57 points in explanation quality, 18.96 percentage\npoints in question-answering accuracy, and 14.75 percentage points on unseen\nbenchmarks for the same task. By integrating explanatory narratives with\nanswers, our approach enables agents to communicate complex visual information\nmore effectively, improving comprehension and fostering greater trust in the\ngenerated responses.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.13275v2", "cate": "cs.CV", "date": "2025-04-17", "updated": "2025-07-19"}
{"id": "2504.13682", "title": "AnyTSR: Any-Scale Thermal Super-Resolution for UAV", "authors": ["Mengyuan Li", "Changhong Fu", "Ziyu Lu", "Zijie Zhang", "Haobo Zuo", "Liangliang Yao"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.13682v2", "summary": "Thermal imaging can greatly enhance the application of intelligent unmanned\naerial vehicles (UAV) in challenging environments. However, the inherent low\nresolution of thermal sensors leads to insufficient details and blurred\nboundaries. Super-resolution (SR) offers a promising solution to address this\nissue, while most existing SR methods are designed for fixed-scale SR. They are\ncomputationally expensive and inflexible in practical applications. To address\nabove issues, this work proposes a novel any-scale thermal SR method (AnyTSR)\nfor UAV within a single model. Specifically, a new image encoder is proposed to\nexplicitly assign specific feature code to enable more accurate and flexible\nrepresentation. Additionally, by effectively embedding coordinate offset\ninformation into the local feature ensemble, an innovative any-scale upsampler\nis proposed to better understand spatial relationships and reduce artifacts.\nMoreover, a novel dataset (UAV-TSR), covering both land and water scenes, is\nconstructed for thermal SR tasks. Experimental results demonstrate that the\nproposed method consistently outperforms state-of-the-art methods across all\nscaling factors as well as generates more accurate and detailed high-resolution\nimages. The code is located at https://github.com/vision4robotics/AnyTSR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.13682v2", "cate": "cs.CV", "date": "2025-04-18", "updated": "2025-07-21"}
{"id": "2505.17786", "title": "Supervised Graph Contrastive Learning for Gene Regulatory Network", "authors": ["Sho Oshima", "Yuji Okamoto", "Taisei Tosaki", "Ryosuke Kojima", "Yasushi Okuno"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      under review", "url": "http://arxiv.org/abs/2505.17786v3", "summary": "Graph representation learning is effective for obtaining a meaningful latent\nspace utilizing the structure of graph data and is widely applied, including\nbiological networks. In particular, Graph Contrastive Learning (GCL) has\nemerged as a powerful self-supervised method that relies on applying\nperturbations to graphs for data augmentation. However, when applying existing\nGCL methods to biological networks such as Gene Regulatory Networks (GRNs),\nthey overlooked meaningful biologically relevant perturbations, e.g., gene\nknockdowns. In this study, we introduce SupGCL (Supervised Graph Contrastive\nLearning), a novel GCL method for GRNs that directly incorporates biological\nperturbations derived from gene knockdown experiments as the supervision.\nSupGCL mathematically extends existing GCL methods that utilize non-biological\nperturbations to probabilistic models that introduce actual biological gene\nperturbation utilizing gene knockdown data. Using the GRN representation\nobtained by our proposed method, our aim is to improve the performance of\nbiological downstream tasks such as patient hazard prediction and disease\nsubtype classification (graph-level task), and gene function classification\n(node-level task). We applied SupGCL on real GRN datasets derived from patients\nwith multiple types of cancer, and in all experiments SupGCL achieves better\nperformance than state-of-the-art baselines.", "comment": "under review", "pdf_url": "http://arxiv.org/pdf/2505.17786v3", "cate": "cs.LG", "date": "2025-05-23", "updated": "2025-07-19"}
{"id": "2505.01431", "title": "ZS-VCOS: Zero-Shot Video Camouflaged Object Segmentation By Optical Flow and Open Vocabulary Object Detection", "authors": ["Wenqi Guo", "Mohamed Shehata", "Shan Du"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.01431v2", "summary": "Camouflaged object segmentation presents unique challenges compared to\ntraditional segmentation tasks, primarily due to the high similarity in\npatterns and colors between camouflaged objects and their backgrounds.\nEffective solutions to this problem have significant implications in critical\nareas such as pest control, defect detection, and lesion segmentation in\nmedical imaging. Prior research has predominantly emphasized supervised or\nunsupervised pre-training methods, leaving zero-shot approaches significantly\nunderdeveloped. Existing zero-shot techniques commonly utilize the Segment\nAnything Model (SAM) in automatic mode or rely on vision-language models to\ngenerate cues for segmentation; however, their performances remain\nunsatisfactory, due to the similarity of the camouflaged object and the\nbackground. This work studies how to avoid training by integrating large\npre-trained models like SAM-2 and Owl-v2 with temporal information into a\nmodular pipeline. Evaluated on the MoCA-Mask dataset, our approach achieves\noutstanding performance improvements, significantly outperforming existing\nzero-shot methods by raising the F-measure ($F_\\beta^w$) from 0.296 to 0.628.\nOur approach also surpasses supervised methods, increasing the F-measure from\n0.476 to 0.628. Additionally, evaluation on the MoCA-Filter dataset\ndemonstrates an increase in the success rate from 0.628 to 0.697 when compared\nwith FlowSAM, a supervised transfer method. A thorough ablation study further\nvalidates the individual contributions of each component. Besides our main\ncontributions, we also highlight inconsistencies in previous work regarding\nmetrics and settings. Code can be found in https://github.com/weathon/vcos.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.01431v2", "cate": "cs.CV", "date": "2025-04-10", "updated": "2025-07-18"}
{"id": "2505.02192", "title": "DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization", "authors": ["Wenchuan Wang", "Mengqi Huang", "Yijing Tu", "Zhendong Mao"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV2025", "url": "http://arxiv.org/abs/2505.02192v2", "summary": "Customized text-to-video generation with pre-trained large-scale models has\nrecently garnered significant attention by focusing on identity and motion\nconsistency. Existing works typically follow the isolated customized paradigm,\nwhere the subject identity or motion dynamics are customized exclusively.\nHowever, this paradigm completely ignores the intrinsic mutual constraints and\nsynergistic interdependencies between identity and motion, resulting in\nidentity-motion conflicts throughout the generation process that systematically\ndegrade. To address this, we introduce DualReal, a novel framework that employs\nadaptive joint training to construct interdependencies between dimensions\ncollaboratively. Specifically, DualReal is composed of two units: (1)\nDual-aware Adaptation dynamically switches the training step (i.e., identity or\nmotion), learns the current information guided by the frozen dimension prior,\nand employs a regularization strategy to avoid knowledge leakage; (2)\nStageBlender Controller leverages the denoising stages and Diffusion\nTransformer depths to guide different dimensions with adaptive granularity,\navoiding conflicts at various stages and ultimately achieving lossless fusion\nof identity and motion patterns. We constructed a more comprehensive evaluation\nbenchmark than existing methods. The experimental results show that DualReal\nimproves CLIP-I and DINO-I metrics by 21.7% and 31.8% on average, and achieves\ntop performance on nearly all motion metrics. Page:\nhttps://wenc-k.github.io/dualreal-customization", "comment": "Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2505.02192v2", "cate": "cs.CV", "date": "2025-05-04", "updated": "2025-07-20"}
{"id": "2505.20734", "title": "Adversarial bandit optimization for approximately linear functions", "authors": ["Zhuoyu Cheng", "Kohei Hatano", "Eiji Takimoto"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.20734v4", "summary": "We consider a bandit optimization problem for nonconvex and non-smooth\nfunctions, where in each trial the loss function is the sum of a linear\nfunction and a small but arbitrary perturbation chosen after observing the\nplayer's choice. We give both expected and high probability regret bounds for\nthe problem. Our result also implies an improved high-probability regret bound\nfor the bandit linear optimization, a special case with no perturbation. We\nalso give a lower bound on the expected regret.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.20734v4", "cate": "cs.LG", "date": "2025-05-27", "updated": "2025-07-19"}
{"id": "2505.05895", "title": "Leveraging Vision-Language Models for Visual Grounding and Analysis of Automotive UI", "authors": ["Benjamin Raphael Ernhofer", "Daniil Prokhorov", "Jannica Langner", "Dominik Bollmann"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.05895v2", "summary": "Modern automotive infotainment systems require intelligent and adaptive\nsolutions to handle frequent User Interface (UI) updates and diverse design\nvariations. We introduce a vision-language framework for understanding and\ninteracting with automotive infotainment systems, enabling seamless adaptation\nacross different UI designs. To further support research in this field, we\nrelease AutomotiveUI-Bench-4K, an open-source dataset of 998 images with 4,208\nannotations. Additionally, we present a synthetic data pipeline to generate\ntraining data. We fine-tune a Molmo-7B-based model using Low-Rank Adaptation\n(LoRa) and incorporating reasoning generated by our pipeline, along with visual\ngrounding and evaluation capabilities. The fine-tuned Evaluative Large Action\nModel (ELAM) achieves strong performance on AutomotiveUI-Bench-4K (model and\ndataset are available on Hugging Face) and demonstrating strong cross-domain\ngeneralization, including a +5.6% improvement on ScreenSpot over the baseline\nmodel. Notably, our approach achieves 80.8% average accuracy on ScreenSpot,\nclosely matching or even surpassing specialized models for desktop, mobile, and\nweb, such as ShowUI, despite being trained for the infotainment domain. This\nresearch investigates how data collection and subsequent fine-tuning can lead\nto AI-driven progress within automotive UI understanding and interaction. The\napplied method is cost-efficient and fine-tuned models can be deployed on\nconsumer-grade GPUs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.05895v2", "cate": "cs.CV", "date": "2025-05-09", "updated": "2025-07-20"}
{"id": "2506.03582", "title": "SemiOccam: A Robust Semi-Supervised Image Recognition Network Using Sparse Labels", "authors": ["Rui Yann", "Tianshuo Zhang", "Xianglei Xing"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      CleanSTL-10 available at this https URL", "url": "http://arxiv.org/abs/2506.03582v3", "summary": "We present SemiOccam, an image recognition network that leverages\nsemi-supervised learning in a highly efficient manner. Existing works often\nrely on complex training techniques and architectures, requiring hundreds of\nGPU hours for training, while their generalization ability with extremely\nlimited labeled data remains to be improved. To address these limitations, we\nconstruct a hierarchical mixture density classification mechanism by optimizing\nmutual information between feature representations and target classes,\ncompressing redundant information while retaining crucial discriminative\ncomponents. Experimental results demonstrate that our method achieves\nstate-of-the-art performance on three commonly used datasets, with accuracy\nexceeding 95% on two of them using only 4 labeled samples per class, and its\nsimple architecture keeps training time at the minute level. Notably, this\npaper reveals a long-overlooked data leakage issue in the STL-10 dataset for\nsemi-supervised learning and removes duplicates to ensure reliable experimental\nresults. We release the deduplicated CleanSTL-10 dataset to facilitate fair and\nreproducible research. Code available at https://github.com/Shu1L0n9/SemiOccam.", "comment": "CleanSTL-10 available at\n  https://huggingface.co/datasets/Shu1L0n9/CleanSTL-10", "pdf_url": "http://arxiv.org/pdf/2506.03582v3", "cate": "cs.CV", "date": "2025-06-04", "updated": "2025-07-19"}
{"id": "2506.00302", "title": "Beyond Atomic Geometry Representations in Materials Science: A Human-in-the-Loop Multimodal Framework", "authors": ["Can Polat", "Erchin Serpedin", "Mustafa Kurban", "Hasan Kurban"], "categories": ["cs.LG", "cond-mat.mtrl-sci"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Presented at ICML 2025 Workshop on DataWorld", "url": "http://arxiv.org/abs/2506.00302v2", "summary": "Most materials science datasets are limited to atomic geometries (e.g., XYZ\nfiles), restricting their utility for multimodal learning and comprehensive\ndata-centric analysis. These constraints have historically impeded the adoption\nof advanced machine learning techniques in the field. This work introduces\nMultiCrystalSpectrumSet (MCS-Set), a curated framework that expands materials\ndatasets by integrating atomic structures with 2D projections and structured\ntextual annotations, including lattice parameters and coordination metrics.\nMCS-Set enables two key tasks: (1) multimodal property and summary prediction,\nand (2) constrained crystal generation with partial cluster supervision.\nLeveraging a human-in-the-loop pipeline, MCS-Set combines domain expertise with\nstandardized descriptors for high-quality annotation. Evaluations using\nstate-of-the-art language and vision-language models reveal substantial\nmodality-specific performance gaps and highlight the importance of annotation\nquality for generalization. MCS-Set offers a foundation for benchmarking\nmultimodal models, advancing annotation practices, and promoting accessible,\nversatile materials science datasets. The dataset and implementations are\navailable at https://github.com/KurbanIntelligenceLab/MultiCrystalSpectrumSet.", "comment": "Presented at ICML 2025 Workshop on DataWorld", "pdf_url": "http://arxiv.org/pdf/2506.00302v2", "cate": "cs.LG", "date": "2025-05-30", "updated": "2025-07-19"}
{"id": "2505.10921", "title": "Towards Cross-modal Retrieval in Chinese Cultural Heritage Documents: Dataset and Solution", "authors": ["Junyi Yuan", "Jian Zhang", "Fangyu Wu", "Dongming Lu", "Huanda Lu", "Qiufeng Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.10921v2", "summary": "China has a long and rich history, encompassing a vast cultural heritage that\nincludes diverse multimodal information, such as silk patterns, Dunhuang\nmurals, and their associated historical narratives. Cross-modal retrieval plays\na pivotal role in understanding and interpreting Chinese cultural heritage by\nbridging visual and textual modalities to enable accurate text-to-image and\nimage-to-text retrieval. However, despite the growing interest in multimodal\nresearch, there is a lack of specialized datasets dedicated to Chinese cultural\nheritage, limiting the development and evaluation of cross-modal learning\nmodels in this domain. To address this gap, we propose a multimodal dataset\nnamed CulTi, which contains 5,726 image-text pairs extracted from two series of\nprofessional documents, respectively related to ancient Chinese silk and\nDunhuang murals. Compared to existing general-domain multimodal datasets, CulTi\npresents a challenge for cross-modal retrieval: the difficulty of local\nalignment between intricate decorative motifs and specialized textual\ndescriptions. To address this challenge, we propose LACLIP, a training-free\nlocal alignment strategy built upon a fine-tuned Chinese-CLIP. LACLIP enhances\nthe alignment of global textual descriptions with local visual regions by\ncomputing weighted similarity scores during inference. Experimental results on\nCulTi demonstrate that LACLIP significantly outperforms existing models in\ncross-modal retrieval, particularly in handling fine-grained semantic\nassociations within Chinese cultural heritage.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.10921v2", "cate": "cs.CV", "date": "2025-05-16", "updated": "2025-07-19"}
{"id": "2506.06806", "title": "Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification", "authors": ["Subhendu Khatuya", "Shashwat Naidu", "Saptarshi Ghosh", "Pawan Goyal", "Niloy Ganguly"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      This work has been accepted to appear at the Association for Computational Linguistics (ACL), 2025", "url": "http://arxiv.org/abs/2506.06806v2", "summary": "The explosion of textual data has made manual document classification\nincreasingly challenging. To address this, we introduce a robust, efficient\ndomain-agnostic generative model framework for multi-label text classification.\nInstead of treating labels as mere atomic symbols, our approach utilizes\npredefined label descriptions and is trained to generate these descriptions\nbased on the input text. During inference, the generated descriptions are\nmatched to the pre-defined labels using a finetuned sentence transformer. We\nintegrate this with a dual-objective loss function, combining cross-entropy\nloss and cosine similarity of the generated sentences with the predefined\ntarget descriptions, ensuring both semantic alignment and accuracy. Our\nproposed model LAGAMC stands out for its parameter efficiency and versatility\nacross diverse datasets, making it well-suited for practical applications. We\ndemonstrate the effectiveness of our proposed model by achieving new\nstate-of-the-art performances across all evaluated datasets, surpassing several\nstrong baselines. We achieve improvements of 13.94% in Micro-F1 and 24.85% in\nMacro-F1 compared to the closest baseline across all datasets.", "comment": "This work has been accepted to appear at the Association for\n  Computational Linguistics (ACL), 2025", "pdf_url": "http://arxiv.org/pdf/2506.06806v2", "cate": "cs.CL", "date": "2025-06-07", "updated": "2025-07-19"}
{"id": "2506.01405", "title": "SOC-DGL: Social Interaction Behavior Inspired Dual Graph Learning Framework for Drug-Target Interaction Identification", "authors": ["Xiang Zhao", "Ruijie Li", "Qiao Ning", "Shikai Guo", "Hui Li", "Qian Ma"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      13 pages, 14 figures (including subfigures), 5 tables. Xiang Zhao and Ruijie Li contributed equally to this work and should be considered co-first authors. The source code and datasets are available at this https URL", "url": "http://arxiv.org/abs/2506.01405v2", "summary": "The identification of drug-target interactions (DTI) is critical for drug\ndiscovery and repositioning, as it reveals potential therapeutic uses of\nexisting drugs, accelerating development and reducing costs. However, most\nexisting models focus only on direct similarity in homogeneous graphs, failing\nto exploit the rich similarity in heterogeneous graphs. To address this gap,\ninspired by real-world social interaction behaviors, we propose SOC-DGL, which\ncomprises two specialized modules: the Affinity-Driven Graph Learning (ADGL)\nmodule, learning global similarity through an affinity-enhanced drug-target\ngraph, and the Equilibrium-Driven Graph Learning (EDGL) module, capturing\nhigher-order similarity by amplifying the influence of even-hop neighbors using\nan even-polynomial graph filter based on balance theory. This dual approach\nenables SOC-DGL to effectively capture similarity information across multiple\ninteraction scales within affinity and association matrices. To address the\nissue of imbalance in DTI datasets, we propose an adjustable imbalance loss\nfunction that adjusts the weight of negative samples by the parameter.\nExtensive experiments on four benchmark datasets demonstrate that SOC-DGL\nconsistently outperforms existing state-of-the-art methods across both balanced\nand imbalanced scenarios. Moreover, SOC-DGL successfully predicts the top 9\ndrugs known to bind ABL1, and further analyzed the 10th drug, which has not\nbeen experimentally confirmed to interact with ABL1, providing supporting\nevidence for its potential binding.", "comment": "13 pages, 14 figures (including subfigures), 5 tables. Xiang Zhao and\n  Ruijie Li contributed equally to this work and should be considered co-first\n  authors. The source code and datasets are available at\n  https://github.com/Zhaoxiang0422/SOC-DGL", "pdf_url": "http://arxiv.org/pdf/2506.01405v2", "cate": "cs.LG", "date": "2025-06-02", "updated": "2025-07-20"}
{"id": "2505.17768", "title": "R-Genie: Reasoning-Guided Generative Image Editing", "authors": ["Dong Zhang", "Lingfeng He", "Rui Yan", "Fei Shen", "Jinhui Tang"], "categories": ["cs.CV", "F.2.2, I.2.7", "F.2.2; I.2.7"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Code: this https URL", "url": "http://arxiv.org/abs/2505.17768v2", "summary": "While recent advances in image editing have enabled impressive visual\nsynthesis capabilities, current methods remain constrained by explicit textual\ninstructions and limited editing operations, lacking deep comprehension of\nimplicit user intentions and contextual reasoning. In this work, we introduce a\nnew image editing paradigm: reasoning-guided generative editing, which\nsynthesizes images based on complex, multi-faceted textual queries accepting\nworld knowledge and intention inference. To facilitate this task, we first\nconstruct a comprehensive dataset featuring over 1,000 image-instruction-edit\ntriples that incorporate rich reasoning contexts and real-world knowledge. We\nthen propose R-Genie: a reasoning-guided generative image editor, which\nsynergizes the generation power of diffusion models with advanced reasoning\ncapabilities of multimodal large language models. R-Genie incorporates a\nreasoning-attention mechanism to bridge linguistic understanding with visual\nsynthesis, enabling it to handle intricate editing requests involving abstract\nuser intentions and contextual reasoning relations. Extensive experimental\nresults validate that R-Genie can equip diffusion models with advanced\nreasoning-based editing capabilities, unlocking new potentials for intelligent\nimage synthesis.", "comment": "Code: https://dongzhang89.github.io/RGenie.github.io/", "pdf_url": "http://arxiv.org/pdf/2505.17768v2", "cate": "cs.CV", "date": "2025-05-23", "updated": "2025-07-20"}
{"id": "2506.08373", "title": "Draft-based Approximate Inference for LLMs", "authors": ["Kevin Galim", "Ethan Ewer", "Wonjun Kang", "Minjae Lee", "Hyung Il Koo", "Kangwook Lee"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Added discussion and comparison with SpecPrefill", "url": "http://arxiv.org/abs/2506.08373v2", "summary": "Optimizing inference for long-context Large Language Models (LLMs) is\nincreasingly important due to the quadratic compute and linear memory\ncomplexity of Transformers. Existing approximation methods, such as key-value\n(KV) cache dropping, sparse attention, and prompt compression, typically rely\non rough predictions of token or KV pair importance. We propose a novel\nframework for approximate LLM inference that leverages small draft models to\nmore accurately predict the importance of tokens and KV pairs. Specifically, we\nintroduce two instantiations of our proposed framework: (i) SpecKV, the first\nmethod that leverages a draft output to accurately assess the importance of\neach KV pair for more effective KV cache dropping, and (ii) SpecPC, which uses\nthe draft model's attention activations to identify and discard unimportant\nprompt tokens. We motivate our methods with theoretical and empirical analyses,\nand show a strong correlation between the attention patterns of draft and\ntarget models. Extensive experiments on long-context benchmarks show that our\nmethods consistently achieve higher accuracy than existing baselines, while\npreserving the same improvements in memory usage, latency, and throughput. Our\ncode is available at https://github.com/furiosa-ai/draft-based-approx-llm.", "comment": "Added discussion and comparison with SpecPrefill", "pdf_url": "http://arxiv.org/pdf/2506.08373v2", "cate": "cs.CL", "date": "2025-06-10", "updated": "2025-07-19"}
{"id": "2506.10351", "title": "PhysioWave: A Multi-Scale Wavelet-Transformer for Physiological Signal Representation", "authors": ["Yanlong Chen", "Mattia Orlandi", "Pierangelo Maria Rapa", "Simone Benatti", "Luca Benini", "Yawei Li"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      25 pages, 14 figures, 9 tables. Submitted to NeurIPS 2025", "url": "http://arxiv.org/abs/2506.10351v2", "summary": "Physiological signals are often corrupted by motion artifacts, baseline\ndrift, and other low-SNR disturbances, which pose significant challenges for\nanalysis. Additionally, these signals exhibit strong non-stationarity, with\nsharp peaks and abrupt changes that evolve continuously, making them difficult\nto represent using traditional time-domain or filtering methods. To address\nthese issues, a novel wavelet-based approach for physiological signal analysis\nis presented, aiming to capture multi-scale time-frequency features in various\nphysiological signals. Leveraging this technique, two large-scale pretrained\nmodels specific to EMG and ECG are introduced for the first time, achieving\nsuperior performance and setting new baselines in downstream tasks.\nAdditionally, a unified multi-modal framework is constructed by integrating\npretrained EEG model, where each modality is guided through its dedicated\nbranch and fused via learnable weighted fusion. This design effectively\naddresses challenges such as low signal-to-noise ratio, high inter-subject\nvariability, and device mismatch, outperforming existing methods on multi-modal\ntasks. The proposed wavelet-based architecture lays a solid foundation for\nanalysis of diverse physiological signals, while the multi-modal design points\nto next-generation physiological signal processing with potential impact on\nwearable health monitoring, clinical diagnostics, and broader biomedical\napplications.", "comment": "25 pages, 14 figures, 9 tables. Submitted to NeurIPS 2025", "pdf_url": "http://arxiv.org/pdf/2506.10351v2", "cate": "cs.LG", "date": "2025-06-12", "updated": "2025-07-20"}
{"id": "2505.20289", "title": "VisualToolAgent (VisTA): A Reinforcement Learning Framework for Visual Tool Selection", "authors": ["Zeyi Huang", "Yuyang Ji", "Anirudh Sundara Rajan", "Zefan Cai", "Wen Xiao", "Haohan Wang", "Junjie Hu", "Yong Jae Lee"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.20289v2", "summary": "We introduce VisTA, a new reinforcement learning framework that empowers\nvisual agents to dynamically explore, select, and combine tools from a diverse\nlibrary based on empirical performance. Existing methods for tool-augmented\nreasoning either rely on training-free prompting or large-scale fine-tuning;\nboth lack active tool exploration and typically assume limited tool diversity,\nand fine-tuning methods additionally demand extensive human supervision. In\ncontrast, VisTA leverages end-to-end reinforcement learning to iteratively\nrefine sophisticated, query-specific tool selection strategies, using task\noutcomes as feedback signals. Through Group Relative Policy Optimization\n(GRPO), our framework enables an agent to autonomously discover effective\ntool-selection pathways without requiring explicit reasoning supervision.\nExperiments on the ChartQA, Geometry3K, and BlindTest benchmarks demonstrate\nthat VisTA achieves substantial performance gains over training-free baselines,\nespecially on out-of-distribution examples. These results highlight VisTA's\nability to enhance generalization, adaptively utilize diverse tools, and pave\nthe way for flexible, experience-driven visual reasoning systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.20289v2", "cate": "cs.CV", "date": "2025-05-26", "updated": "2025-07-19"}
{"id": "2506.11558", "title": "DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs", "authors": ["Bo-Cheng Chiu", "Jen-Jee Chen", "Yu-Chee Tseng", "Feng-Chi Chen"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.11558v3", "summary": "Large Language Models (LLMs) have recently been extended to the video domain,\nenabling sophisticated video-language understanding. However, existing Video\nLLMs often exhibit limitations in fine-grained temporal reasoning, restricting\ntheir ability to precisely attribute responses to specific video moments,\nespecially under constrained supervision. We introduce DaMO, a data-efficient\nVideo LLM explicitly designed for accurate temporal reasoning and multimodal\nunderstanding. At its core, the proposed Temporal-aware Fuseformer employs a\nhierarchical dual-stream architecture that progressively captures temporal\ndynamics within each modality and effectively fuses complementary visual and\naudio information. To further enhance computational efficiency, DaMO integrates\na global residual that reduces spatial redundancy while preserving essential\nsemantic details. We train DaMO via a structured four-stage progressive\ntraining paradigm, incrementally equipping the model with multimodal alignment,\nsemantic grounding, and temporal reasoning capabilities. This work also\ncontributes multiple datasets augmented from existing ones with LLM-generated\ntemporally grounded QA pairs for tasks requiring temporal supervision.\nComprehensive experiments on temporal grounding and video QA benchmarks\ndemonstrate that DaMO consistently surpasses prior methods, particularly in\ntasks demanding precise temporal alignment and reasoning. Our work establishes\na promising direction for data-efficient video-language modeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.11558v3", "cate": "cs.CV", "date": "2025-06-13", "updated": "2025-07-21"}
{"id": "2506.11347", "title": "Improving Group Robustness on Spurious Correlation via Evidential Alignment", "authors": ["Wenqian Ye", "Guangtao Zheng", "Aidong Zhang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at KDD 2025 (Research Track)", "url": "http://arxiv.org/abs/2506.11347v3", "summary": "Deep neural networks often learn and rely on spurious correlations, i.e.,\nsuperficial associations between non-causal features and the targets. For\ninstance, an image classifier may identify camels based on the desert\nbackgrounds. While it can yield high overall accuracy during training, it\ndegrades generalization on more diverse scenarios where such correlations do\nnot hold. This problem poses significant challenges for out-of-distribution\nrobustness and trustworthiness. Existing methods typically mitigate this issue\nby using external group annotations or auxiliary deterministic models to learn\nunbiased representations. However, such information is costly to obtain, and\ndeterministic models may fail to capture the full spectrum of biases learned by\nthe models. To address these limitations, we propose Evidential Alignment, a\nnovel framework that leverages uncertainty quantification to understand the\nbehavior of the biased models without requiring group annotations. By\nquantifying the evidence of model prediction with second-order risk\nminimization and calibrating the biased models with the proposed evidential\ncalibration technique, Evidential Alignment identifies and suppresses spurious\ncorrelations while preserving core features. We theoretically justify the\neffectiveness of our method as capable of learning the patterns of biased\nmodels and debiasing the model without requiring any spurious correlation\nannotations. Empirical results demonstrate that our method significantly\nimproves group robustness across diverse architectures and data modalities,\nproviding a scalable and principled solution to spurious correlations.", "comment": "Accepted at KDD 2025 (Research Track)", "pdf_url": "http://arxiv.org/pdf/2506.11347v3", "cate": "cs.LG", "date": "2025-06-12", "updated": "2025-07-20"}
{"id": "2506.03433", "title": "ViT-Split: Unleashing the Power of Vision Foundation Models via Efficient Splitting Heads", "authors": ["Yifan Li", "Xin Li", "Tianqin Li", "Wenbin He", "Yu Kong", "Liu Ren"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      The project is available: this https URL", "url": "http://arxiv.org/abs/2506.03433v2", "summary": "Vision foundation models (VFMs) have demonstrated remarkable performance\nacross a wide range of downstream tasks. While several VFM adapters have shown\npromising results by leveraging the prior knowledge of VFMs, we identify two\ninefficiencies in these approaches. First, the interaction between\nconvolutional neural network (CNN) and VFM backbone triggers early layer\ngradient backpropagation. Second, existing methods require tuning all\ncomponents, adding complexity. Besides, these adapters alter VFM features,\nunderutilizing the prior knowledge. To tackle these challenges, we propose a\nnew approach called ViT-Split, based on a key observation: the layers of\nseveral VFMs, like DINOv2, can be divided into two distinct components: an\nextractor for learning low-level features and an adapter for learning\ntask-specific features. Leveraging this insight, we eliminate the CNN branch\nand introduce two heads, task head and prior head, to the frozen VFM. The task\nhead is designed to learn task-specific features, mitigating the early gradient\npropagation issue. The prior head is used to leverage the multi-scale prior\nfeatures from the frozen VFM, reducing tuning parameters and overfitting.\nExtensive experiments on various tasks (e.g., segmentation, detection, depth\nestimation, and visual question answering) validate the effectiveness and\nefficiency of ViT-Split. Specifically, ViT-Split reduces training time up to\n$4\\times$ while achieving comparable or even better results on ADE20K, compared\nto other VFM adapters.", "comment": "The project is available:\n  https://jackyfl.github.io/vitsplit.github.io/", "pdf_url": "http://arxiv.org/pdf/2506.03433v2", "cate": "cs.CV", "date": "2025-06-03", "updated": "2025-07-18"}
{"id": "2506.23516", "title": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization", "authors": ["Seung-Wook Kim", "Seongyeol Kim", "Jiah Kim", "Seowon Ji", "Se-Ho Lee"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.23516v2", "summary": "Federated learning (FL) often suffers from performance degradation due to key\nchallenges such as data heterogeneity and communication constraints. To address\nthese limitations, we present a novel FL framework called FedWSQ, which\nintegrates weight standardization (WS) and the proposed distribution-aware\nnon-uniform quantization (DANUQ). WS enhances FL performance by filtering out\nbiased components in local updates during training, thereby improving the\nrobustness of the model against data heterogeneity and unstable client\nparticipation. In addition, DANUQ minimizes quantization errors by leveraging\nthe statistical properties of local model updates. As a result, FedWSQ\nsignificantly reduces communication overhead while maintaining superior model\naccuracy. Extensive experiments on FL benchmark datasets demonstrate that\nFedWSQ consistently outperforms existing FL methods across various challenging\nFL settings, including extreme data heterogeneity and ultra-low-bit\ncommunication scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.23516v2", "cate": "cs.LG", "date": "2025-06-30", "updated": "2025-07-21"}
{"id": "2507.02939", "title": "Frequency-Aligned Knowledge Distillation for Lightweight Spatiotemporal Forecasting", "authors": ["Yuqi Li", "Chuanguang Yang", "Hansheng Zeng", "Zeyu Dong", "Zhulin An", "Yongjun Xu", "Yingli Tian", "Hao Wu"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV-2025, 11 pages", "url": "http://arxiv.org/abs/2507.02939v2", "summary": "Spatiotemporal forecasting tasks, such as traffic flow, combustion dynamics,\nand weather forecasting, often require complex models that suffer from low\ntraining efficiency and high memory consumption. This paper proposes a\nlightweight framework, Spectral Decoupled Knowledge Distillation (termed SDKD),\nwhich transfers the multi-scale spatiotemporal representations from a complex\nteacher model to a more efficient lightweight student network. The teacher\nmodel follows an encoder-latent evolution-decoder architecture, where its\nlatent evolution module decouples high-frequency details and low-frequency\ntrends using convolution and Transformer (global low-frequency modeler).\nHowever, the multi-layer convolution and deconvolution structures result in\nslow training and high memory usage. To address these issues, we propose a\nfrequency-aligned knowledge distillation strategy, which extracts multi-scale\nspectral features from the teacher's latent space, including both high and low\nfrequency components, to guide the lightweight student model in capturing both\nlocal fine-grained variations and global evolution patterns. Experimental\nresults show that SDKD significantly improves performance, achieving reductions\nof up to 81.3% in MSE and in MAE 52.3% on the Navier-Stokes equation dataset.\nThe framework effectively captures both high-frequency variations and long-term\ntrends while reducing computational complexity. Our codes are available at\nhttps://github.com/itsnotacie/SDKD", "comment": "Accepted by ICCV-2025, 11 pages", "pdf_url": "http://arxiv.org/pdf/2507.02939v2", "cate": "cs.LG", "date": "2025-06-27", "updated": "2025-07-20"}
{"id": "2506.07886", "title": "EgoM2P: Egocentric Multimodal Multitask Pretraining", "authors": ["Gen Li", "Yutong Chen", "Yiqian Wu", "Kaifeng Zhao", "Marc Pollefeys", "Siyu Tang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2506.07886v3", "summary": "Understanding multimodal signals in egocentric vision, such as RGB video,\ndepth, camera poses, and gaze, is essential for applications in augmented\nreality, robotics, and human-computer interaction, enabling systems to better\ninterpret the camera wearer's actions, intentions, and surrounding environment.\nHowever, building large-scale egocentric multimodal and multitask models\npresents unique challenges. Egocentric data are inherently heterogeneous, with\nlarge variations in modality coverage across devices and settings. Generating\npseudo-labels for missing modalities, such as gaze or head-mounted camera\ntrajectories, is often infeasible, making standard supervised learning\napproaches difficult to scale. Furthermore, dynamic camera motion and the\ncomplex temporal and spatial structure of first-person video pose additional\nchallenges for the direct application of existing multimodal foundation models.\n  To address these challenges, we introduce a set of efficient temporal\ntokenizers and propose EgoM2P, a masked modeling framework that learns from\ntemporally-aware multimodal tokens to train a large, general-purpose model for\negocentric 4D understanding. This unified design supports multitasking across\ndiverse egocentric perception and synthesis tasks, including gaze prediction,\negocentric camera tracking, and monocular depth estimation from egocentric\nvideo, and also serves as a generative model for conditional egocentric video\nsynthesis. Across these tasks, EgoM2P matches or outperforms specialist models\nwhile being an order of magnitude faster. We will fully open-source EgoM2P to\nsupport the community and advance egocentric vision research. Project page:\nhttps://egom2p.github.io/.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2506.07886v3", "cate": "cs.CV", "date": "2025-06-09", "updated": "2025-07-19"}
{"id": "2507.00709", "title": "TopoStreamer: Temporal Lane Segment Topology Reasoning in Autonomous Driving", "authors": ["Yiming Yang", "Yueru Luo", "Bingkun He", "Hongbin Lin", "Suzhong Fu", "Chao Zheng", "Zhipeng Cao", "Erlong Li", "Chao Yan", "Shuguang Cui", "Zhen Li"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.00709v2", "summary": "Lane segment topology reasoning constructs a comprehensive road network by\ncapturing the topological relationships between lane segments and their\nsemantic types. This enables end-to-end autonomous driving systems to perform\nroad-dependent maneuvers such as turning and lane changing. However, the\nlimitations in consistent positional embedding and temporal multiple attribute\nlearning in existing methods hinder accurate roadnet reconstruction. To address\nthese issues, we propose TopoStreamer, an end-to-end temporal perception model\nfor lane segment topology reasoning. Specifically, TopoStreamer introduces\nthree key improvements: streaming attribute constraints, dynamic lane boundary\npositional encoding, and lane segment denoising. The streaming attribute\nconstraints enforce temporal consistency in both centerline and boundary\ncoordinates, along with their classifications. Meanwhile, dynamic lane boundary\npositional encoding enhances the learning of up-to-date positional information\nwithin queries, while lane segment denoising helps capture diverse lane segment\npatterns, ultimately improving model performance. Additionally, we assess the\naccuracy of existing models using a lane boundary classification metric, which\nserves as a crucial measure for lane-changing scenarios in autonomous driving.\nOn the OpenLane-V2 dataset, TopoStreamer demonstrates significant improvements\nover state-of-the-art methods, achieving substantial performance gains of +3.0%\nmAP in lane segment perception and +1.7% OLS in centerline perception tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.00709v2", "cate": "cs.CV", "date": "2025-07-01", "updated": "2025-07-20"}
{"id": "2507.04695", "title": "Interpretable Reward Modeling with Active Concept Bottlenecks", "authors": ["Sonia Laguna", "Katarzyna Kobalczyk", "Julia E. Vogt", "Mihaela Van der Schaar"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04695v2", "summary": "We introduce Concept Bottleneck Reward Models (CB-RM), a reward modeling\nframework that enables interpretable preference learning through selective\nconcept annotation. Unlike standard RLHF methods that rely on opaque reward\nfunctions, CB-RM decomposes reward prediction into human-interpretable\nconcepts. To make this framework efficient in low-supervision settings, we\nformalize an active learning strategy that dynamically acquires the most\ninformative concept labels. We propose an acquisition function based on\nExpected Information Gain and show that it significantly accelerates concept\nlearning without compromising preference accuracy. Evaluated on the\nUltraFeedback dataset, our method outperforms baselines in interpretability and\nsample efficiency, marking a step towards more transparent, auditable, and\nhuman-aligned reward models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04695v2", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-20"}
{"id": "2507.00721", "title": "UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement", "authors": ["Xiao Zhang", "Fei Wei", "Yong Wang", "Wenda Zhao", "Feiyi Li", "Xiangxiang Chu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV2025", "url": "http://arxiv.org/abs/2507.00721v2", "summary": "Zero-shot domain adaptation (ZSDA) presents substantial challenges due to the\nlack of images in the target domain. Previous approaches leverage\nVision-Language Models (VLMs) to tackle this challenge, exploiting their\nzero-shot learning capabilities. However, these methods primarily address\ndomain distribution shifts and overlook the misalignment between the detection\ntask and VLMs, which rely on manually crafted prompts. To overcome these\nlimitations, we propose the unified prompt and representation enhancement\n(UPRE) framework, which jointly optimizes both textual prompts and visual\nrepresentations. Specifically, our approach introduces a multi-view domain\nprompt that combines linguistic domain priors with detection-specific\nknowledge, and a visual representation enhancement module that produces domain\nstyle variations. Furthermore, we introduce multi-level enhancement strategies,\nincluding relative domain distance and positive-negative separation, which\nalign multi-modal representations at the image level and capture diverse visual\nrepresentations at the instance level, respectively. Extensive experiments\nconducted on nine benchmark datasets demonstrate the superior performance of\nour framework in ZSDA detection scenarios. Code is available at\nhttps://github.com/AMAP-ML/UPRE.", "comment": "ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.00721v2", "cate": "cs.CV", "date": "2025-07-01", "updated": "2025-07-21"}
{"id": "2507.05108", "title": "Reviving Cultural Heritage: A Novel Approach for Comprehensive Historical Document Restoration", "authors": ["Yuyi Zhang", "Peirong Zhang", "Zhenhua Yang", "Pengyu Yan", "Yongxin Shi", "Pengwei Liu", "Fengjun Guo", "Lianwen Jin"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05108v2", "summary": "Historical documents represent an invaluable cultural heritage, yet have\nundergone significant degradation over time through tears, water erosion, and\noxidation. Existing Historical Document Restoration (HDR) methods primarily\nfocus on single modality or limited-size restoration, failing to meet practical\nneeds. To fill this gap, we present a full-page HDR dataset (FPHDR) and a novel\nautomated HDR solution (AutoHDR). Specifically, FPHDR comprises 1,633 real and\n6,543 synthetic images with character-level and line-level locations, as well\nas character annotations in different damage grades. AutoHDR mimics historians'\nrestoration workflows through a three-stage approach: OCR-assisted damage\nlocalization, vision-language context text prediction, and patch autoregressive\nappearance restoration. The modular architecture of AutoHDR enables seamless\nhuman-machine collaboration, allowing for flexible intervention and\noptimization at each restoration stage. Experiments demonstrate AutoHDR's\nremarkable performance in HDR. When processing severely damaged documents, our\nmethod improves OCR accuracy from 46.83% to 84.05%, with further enhancement to\n94.25% through human-machine collaboration. We believe this work represents a\nsignificant advancement in automated historical document restoration and\ncontributes substantially to cultural heritage preservation. The model and\ndataset are available at https://github.com/SCUT-DLVCLab/AutoHDR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05108v2", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-21"}
{"id": "2507.07485", "title": "Resolving Token-Space Gradient Conflicts: Token Space Manipulation for Transformer-Based Multi-Task Learning", "authors": ["Wooseong Jeong", "Kuk-Jin Yoon"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025", "url": "http://arxiv.org/abs/2507.07485v2", "summary": "Multi-Task Learning (MTL) enables multiple tasks to be learned within a\nshared network, but differences in objectives across tasks can cause negative\ntransfer, where the learning of one task degrades another task's performance.\nWhile pre-trained transformers significantly improve MTL performance, their\nfixed network capacity and rigid structure limit adaptability. Previous dynamic\nnetwork architectures attempt to address this but are inefficient as they\ndirectly convert shared parameters into task-specific ones. We propose Dynamic\nToken Modulation and Expansion (DTME-MTL), a framework applicable to any\ntransformer-based MTL architecture. DTME-MTL enhances adaptability and reduces\noverfitting by identifying gradient conflicts in token space and applying\nadaptive solutions based on conflict type. Unlike prior methods that mitigate\nnegative transfer by duplicating network parameters, DTME-MTL operates entirely\nin token space, enabling efficient adaptation without excessive parameter\ngrowth. Extensive experiments demonstrate that DTME-MTL consistently improves\nmulti-task performance with minimal computational overhead, offering a scalable\nand effective solution for enhancing transformer-based MTL models.", "comment": "Accepted at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.07485v2", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-21"}
{"id": "2507.03532", "title": "PhenoBench: A Comprehensive Benchmark for Cell Phenotyping", "authors": ["Fabian H. Reith", "Claudia Winklmayr", "Jerome Luescher", "Nora Koreuber", "Jannik Franzen", "Elias Baumann", "Christian M. Schuerch", "Dagmar Kainmueller", "Josef Lorenz Rumberger"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted for presentation at MICCAI 2025", "url": "http://arxiv.org/abs/2507.03532v5", "summary": "Digital pathology has seen the advent of a wealth of foundational models\n(FM), yet to date their performance on cell phenotyping has not been\nbenchmarked in a unified manner. We therefore propose PhenoBench: A\ncomprehensive benchmark for cell phenotyping on Hematoxylin and Eosin (H&E)\nstained histopathology images. We provide both PhenoCell, a new H&E dataset\nfeaturing 14 granular cell types identified by using multiplexed imaging, and\nready-to-use fine-tuning and benchmarking code that allows the systematic\nevaluation of multiple prominent pathology FMs in terms of dense cell phenotype\npredictions in different generalization scenarios. We perform extensive\nbenchmarking of existing FMs, providing insights into their generalization\nbehavior under technical vs. medical domain shifts. Furthermore, while FMs\nachieve macro F1 scores > 0.70 on previously established benchmarks such as\nLizard and PanNuke, on PhenoCell, we observe scores as low as 0.20. This\nindicates a much more challenging task not captured by previous benchmarks,\nestablishing PhenoCell as a prime asset for future benchmarking of FMs and\nsupervised models alike. Code and data are available on GitHub.", "comment": "accepted for presentation at MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.03532v5", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-21"}
{"id": "2507.06060", "title": "VisualSpeaker: Visually-Guided 3D Avatar Lip Synthesis", "authors": ["Alexandre Symeonidis-Herzig", "Özge Mercanoğlu Sincan", "Richard Bowden"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted in International Conference on Computer Vision (ICCV) Workshops", "url": "http://arxiv.org/abs/2507.06060v2", "summary": "Realistic, high-fidelity 3D facial animations are crucial for expressive\navatar systems in human-computer interaction and accessibility. Although prior\nmethods show promising quality, their reliance on the mesh domain limits their\nability to fully leverage the rapid visual innovations seen in 2D computer\nvision and graphics. We propose VisualSpeaker, a novel method that bridges this\ngap using photorealistic differentiable rendering, supervised by visual speech\nrecognition, for improved 3D facial animation. Our contribution is a perceptual\nlip-reading loss, derived by passing photorealistic 3D Gaussian Splatting\navatar renders through a pre-trained Visual Automatic Speech Recognition model\nduring training. Evaluation on the MEAD dataset demonstrates that VisualSpeaker\nimproves both the standard Lip Vertex Error metric by 56.1% and the perceptual\nquality of the generated animations, while retaining the controllability of\nmesh-driven animation. This perceptual focus naturally supports accurate\nmouthings, essential cues that disambiguate similar manual signs in sign\nlanguage avatars.", "comment": "Accepted in International Conference on Computer Vision (ICCV)\n  Workshops", "pdf_url": "http://arxiv.org/pdf/2507.06060v2", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-21"}
{"id": "2507.07778", "title": "Synchronizing Task Behavior: Aligning Multiple Tasks during Test-Time Training", "authors": ["Wooseong Jeong", "Jegyeong Cho", "Youngho Yoon", "Kuk-Jin Yoon"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025", "url": "http://arxiv.org/abs/2507.07778v2", "summary": "Generalizing neural networks to unseen target domains is a significant\nchallenge in real-world deployments. Test-time training (TTT) addresses this by\nusing an auxiliary self-supervised task to reduce the domain gap caused by\ndistribution shifts between the source and target. However, we find that when\nmodels are required to perform multiple tasks under domain shifts, conventional\nTTT methods suffer from unsynchronized task behavior, where the adaptation\nsteps needed for optimal performance in one task may not align with the\nrequirements of other tasks. To address this, we propose a novel TTT approach\ncalled Synchronizing Tasks for Test-time Training (S4T), which enables the\nconcurrent handling of multiple tasks. The core idea behind S4T is that\npredicting task relations across domain shifts is key to synchronizing tasks\nduring test time. To validate our approach, we apply S4T to conventional\nmulti-task benchmarks, integrating it with traditional TTT protocols. Our\nempirical results show that S4T outperforms state-of-the-art TTT methods across\nvarious benchmarks.", "comment": "Accepted at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.07778v2", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-21"}
{"id": "2507.08136", "title": "RegGS: Unposed Sparse Views Gaussian Splatting with 3DGS Registration", "authors": ["Chong Cheng", "Yu Hu", "Sicheng Yu", "Beizhen Zhao", "Zijian Wang", "Hao Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.08136v2", "summary": "3D Gaussian Splatting (3DGS) has demonstrated its potential in reconstructing\nscenes from unposed images. However, optimization-based 3DGS methods struggle\nwith sparse views due to limited prior knowledge. Meanwhile, feed-forward\nGaussian approaches are constrained by input formats, making it challenging to\nincorporate more input views. To address these challenges, we propose RegGS, a\n3D Gaussian registration-based framework for reconstructing unposed sparse\nviews. RegGS aligns local 3D Gaussians generated by a feed-forward network into\na globally consistent 3D Gaussian representation. Technically, we implement an\nentropy-regularized Sinkhorn algorithm to efficiently solve the optimal\ntransport Mixture 2-Wasserstein $(\\text{MW}_2)$ distance, which serves as an\nalignment metric for Gaussian mixture models (GMMs) in $\\mathrm{Sim}(3)$ space.\nFurthermore, we design a joint 3DGS registration module that integrates the\n$\\text{MW}_2$ distance, photometric consistency, and depth geometry. This\nenables a coarse-to-fine registration process while accurately estimating\ncamera poses and aligning the scene. Experiments on the RE10K and ACID datasets\ndemonstrate that RegGS effectively registers local Gaussians with high\nfidelity, achieving precise pose estimation and high-quality novel-view\nsynthesis. Project page: https://3dagentworld.github.io/reggs/.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.08136v2", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-18"}
{"id": "2507.09487", "title": "HMID-Net: An Exploration of Masked Image Modeling and Knowledge Distillation in Hyperbolic Space", "authors": ["Changli Wang", "Fang Yin", "Jiafeng Liu", "Rui Wu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Modified the abstract and reformatted it using latex", "url": "http://arxiv.org/abs/2507.09487v2", "summary": "Visual and semantic concepts are often structured in a hierarchical manner.\nFor instance, textual concept `cat' entails all images of cats. A recent study,\nMERU, successfully adapts multimodal learning techniques from Euclidean space\nto hyperbolic space, effectively capturing the visual-semantic hierarchy.\nHowever, a critical question remains: how can we more efficiently train a model\nto capture and leverage this hierarchy? In this paper, we propose the\nHyperbolic Masked Image and Distillation Network (HMID-Net), a novel and\nefficient method that integrates Masked Image Modeling (MIM) and knowledge\ndistillation techniques within hyperbolic space. To the best of our knowledge,\nthis is the first approach to leverage MIM and knowledge distillation in\nhyperbolic space to train highly efficient models. In addition, we introduce a\ndistillation loss function specifically designed to facilitate effective\nknowledge transfer in hyperbolic space. Our experiments demonstrate that MIM\nand knowledge distillation techniques in hyperbolic space can achieve the same\nremarkable success as in Euclidean space. Extensive evaluations show that our\nmethod excels across a wide range of downstream tasks, significantly\noutperforming existing models like MERU and CLIP in both image classification\nand retrieval.", "comment": "Modified the abstract and reformatted it using latex", "pdf_url": "http://arxiv.org/pdf/2507.09487v2", "cate": "cs.CV", "date": "2025-07-13", "updated": "2025-07-20"}
{"id": "2507.07854", "title": "Credit Risk Analysis for SMEs Using Graph Neural Networks in Supply Chain", "authors": ["Zizhou Zhang", "Qinyan Shen", "Zhuohuan Hu", "Qianying Liu", "Huijie Shen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      The paper will be published on 2025 International Conference on Big Data, Artificial Intelligence and Digital Economy", "url": "http://arxiv.org/abs/2507.07854v2", "summary": "Small and Medium-sized Enterprises (SMEs) are vital to the modern economy,\nyet their credit risk analysis often struggles with scarce data, especially for\nonline lenders lacking direct credit records. This paper introduces a Graph\nNeural Network (GNN)-based framework, leveraging SME interactions from\ntransaction and social data to map spatial dependencies and predict loan\ndefault risks. Tests on real-world datasets from Discover and Ant Credit (23.4M\nnodes for supply chain analysis, 8.6M for default prediction) show the GNN\nsurpasses traditional and other GNN baselines, with AUCs of 0.995 and 0.701 for\nsupply chain mining and default prediction, respectively. It also helps\nregulators model supply chain disruption impacts on banks, accurately\nforecasting loan defaults from material shortages, and offers Federal Reserve\nstress testers key data for CCAR risk buffers. This approach provides a\nscalable, effective tool for assessing SME credit risk.", "comment": "The paper will be published on 2025 International Conference on Big\n  Data, Artificial Intelligence and Digital Economy", "pdf_url": "http://arxiv.org/pdf/2507.07854v2", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-20"}
{"id": "2507.08416", "title": "InstaScene: Towards Complete 3D Instance Decomposition and Reconstruction from Cluttered Scenes", "authors": ["Zesong Yang", "Bangbang Yang", "Wenqi Dong", "Chenxuan Cao", "Liyuan Cui", "Yuewen Ma", "Zhaopeng Cui", "Hujun Bao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025. Project page: this https URL", "url": "http://arxiv.org/abs/2507.08416v2", "summary": "Humans can naturally identify and mentally complete occluded objects in\ncluttered environments. However, imparting similar cognitive ability to\nrobotics remains challenging even with advanced reconstruction techniques,\nwhich models scenes as undifferentiated wholes and fails to recognize complete\nobject from partial observations. In this paper, we propose InstaScene, a new\nparadigm towards holistic 3D perception of complex scenes with a primary goal:\ndecomposing arbitrary instances while ensuring complete reconstruction. To\nachieve precise decomposition, we develop a novel spatial contrastive learning\nby tracing rasterization of each instance across views, significantly enhancing\nsemantic supervision in cluttered scenes. To overcome incompleteness from\nlimited observations, we introduce in-situ generation that harnesses valuable\nobservations and geometric cues, effectively guiding 3D generative models to\nreconstruct complete instances that seamlessly align with the real world.\nExperiments on scene decomposition and object completion across complex\nreal-world and synthetic scenes demonstrate that our method achieves superior\ndecomposition accuracy while producing geometrically faithful and visually\nintact objects.", "comment": "Accepted by ICCV 2025. Project page:\n  https://zju3dv.github.io/instascene/", "pdf_url": "http://arxiv.org/pdf/2507.08416v2", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-21"}
{"id": "2507.10864", "title": "A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n", "authors": ["Saadat Behzadi", "Danial Sharifrazi", "Bita Mesbahzadeh", "Javad Hassannataj Joloudari", "Roohallah Alizadehsani"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10864v2", "summary": "Objectives: Timely and accurate detection of colorectal polyps plays a\ncrucial role in diagnosing and preventing colorectal cancer, a major cause of\nmortality worldwide. This study introduces a new, lightweight, and efficient\nframework for polyp detection that combines the Local Outlier Factor (LOF)\nalgorithm for filtering noisy data with the YOLO-v11n deep learning model.\n  Study design: An experimental study leveraging deep learning and outlier\nremoval techniques across multiple public datasets.\n  Methods: The proposed approach was tested on five diverse and publicly\navailable datasets: CVC-ColonDB, CVC-ClinicDB, Kvasir-SEG, ETIS, and EndoScene.\nSince these datasets originally lacked bounding box annotations, we converted\ntheir segmentation masks into suitable detection labels. To enhance the\nrobustness and generalizability of our model, we apply 5-fold cross-validation\nand remove anomalous samples using the LOF method configured with 30 neighbors\nand a contamination ratio of 5%. Cleaned data are then fed into YOLO-v11n, a\nfast and resource-efficient object detection architecture optimized for\nreal-time applications. We train the model using a combination of modern\naugmentation strategies to improve detection accuracy under diverse conditions.\n  Results: Our approach significantly improves polyp localization performance,\nachieving a precision of 95.83%, recall of 91.85%, F1-score of 93.48%, mAP@0.5\nof 96.48%, and mAP@0.5:0.95 of 77.75%. Compared to previous YOLO-based methods,\nour model demonstrates enhanced accuracy and efficiency.\n  Conclusions: These results suggest that the proposed method is well-suited\nfor real-time colonoscopy support in clinical settings. Overall, the study\nunderscores how crucial data preprocessing and model efficiency are when\ndesigning effective AI systems for medical imaging.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10864v2", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-21"}
{"id": "2507.08784", "title": "Greedy Low-Rank Gradient Compression for Distributed Learning with Convergence Guarantees", "authors": ["Chuyan Chen", "Yutong He", "Pengrui Li", "Weichen Jia", "Kun Yuan"], "categories": ["cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      18 pages, 5 figures", "url": "http://arxiv.org/abs/2507.08784v2", "summary": "Distributed optimization is pivotal for large-scale signal processing and\nmachine learning, yet communication overhead remains a major bottleneck.\nLow-rank gradient compression, in which the transmitted gradients are\napproximated by low-rank matrices to reduce communication, offers a promising\nremedy. Existing methods typically adopt either randomized or greedy\ncompression strategies: randomized approaches project gradients onto randomly\nchosen subspaces, introducing high variance and degrading empirical\nperformance; greedy methods select the most informative subspaces, achieving\nstrong empirical results but lacking convergence guarantees. To address this\ngap, we propose GreedyLore--the first Greedy Low-Rank gradient compression\nalgorithm for distributed learning with rigorous convergence guarantees.\nGreedyLore incorporates error feedback to correct the bias introduced by greedy\ncompression and introduces a semi-lazy subspace update that ensures the\ncompression operator remains contractive throughout all iterations. With these\ntechniques, we prove that GreedyLore achieves a convergence rate of\n$\\mathcal{O}(\\sigma/\\sqrt{NT} + 1/T)$ under standard optimizers such as MSGD\nand Adam--marking the first linear speedup convergence rate for low-rank\ngradient compression. Extensive experiments are conducted to validate our\ntheoretical findings.", "comment": "18 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.08784v2", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-20"}
{"id": "2507.08729", "title": "RoundaboutHD: High-Resolution Real-World Urban Environment Benchmark for Multi-Camera Vehicle Tracking", "authors": ["Yuqiang Lin", "Sam Lockyer", "Mingxuan Sui", "Li Gan", "Florian Stanek", "Markus Zarbock", "Wenbin Li", "Adrian Evans", "Nic Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08729v2", "summary": "The multi-camera vehicle tracking (MCVT) framework holds significant\npotential for smart city applications, including anomaly detection, traffic\ndensity estimation, and suspect vehicle tracking. However, current publicly\navailable datasets exhibit limitations, such as overly simplistic scenarios,\nlow-resolution footage, and insufficiently diverse conditions, creating a\nconsiderable gap between academic research and real-world scenario. To fill\nthis gap, we introduce RoundaboutHD, a comprehensive, high-resolution\nmulti-camera vehicle tracking benchmark dataset specifically designed to\nrepresent real-world roundabout scenarios. RoundaboutHD provides a total of 40\nminutes of labelled video footage captured by four non-overlapping,\nhigh-resolution (4K resolution, 15 fps) cameras. In total, 512 unique vehicle\nidentities are annotated across different camera views, offering rich\ncross-camera association data. RoundaboutHD offers temporal consistency video\nfootage and enhanced challenges, including increased occlusions and nonlinear\nmovement inside the roundabout. In addition to the full MCVT dataset, several\nsubsets are also available for object detection, single camera tracking, and\nimage-based vehicle re-identification (ReID) tasks. Vehicle model information\nand camera modelling/ geometry information are also included to support further\nanalysis. We provide baseline results for vehicle detection, single-camera\ntracking, image-based vehicle re-identification, and multi-camera tracking. The\ndataset and the evaluation code are publicly available at:\nhttps://github.com/siri-rouser/RoundaboutHD.git", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08729v2", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-21"}
{"id": "2507.11061", "title": "Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with Regularized Score Distillation Sampling", "authors": ["Hayeon Kim", "Ji Ha Jang", "Se Young Chun"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11061v2", "summary": "Recent advances in 3D neural representations and instance-level editing\nmodels have enabled the efficient creation of high-quality 3D content. However,\nachieving precise local 3D edits remains challenging, especially for Gaussian\nSplatting, due to inconsistent multi-view 2D part segmentations and inherently\nambiguous nature of Score Distillation Sampling (SDS) loss. To address these\nlimitations, we propose RoMaP, a novel local 3D Gaussian editing framework that\nenables precise and drastic part-level modifications. First, we introduce a\nrobust 3D mask generation module with our 3D-Geometry Aware Label Prediction\n(3D-GALP), which uses spherical harmonics (SH) coefficients to model\nview-dependent label variations and soft-label property, yielding accurate and\nconsistent part segmentations across viewpoints. Second, we propose a\nregularized SDS loss that combines the standard SDS loss with additional\nregularizers. In particular, an L1 anchor loss is introduced via our Scheduled\nLatent Mixing and Part (SLaMP) editing method, which generates high-quality\npart-edited 2D images and confines modifications only to the target region\nwhile preserving contextual coherence. Additional regularizers, such as\nGaussian prior removal, further improve flexibility by allowing changes beyond\nthe existing context, and robust 3D masking prevents unintended edits.\nExperimental results demonstrate that our RoMaP achieves state-of-the-art local\n3D editing on both reconstructed and generated Gaussian scenes and objects\nqualitatively and quantitatively, making it possible for more robust and\nflexible part-level 3D Gaussian editing. Code is available at\nhttps://janeyeon.github.io/romap.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11061v2", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-21"}
{"id": "2507.10880", "title": "Domain-Adaptive Small Language Models for Structured Tax Code Prediction", "authors": ["Souvik Nath", "Sumit Wadhwa", "Luis Perez"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 3 figures", "url": "http://arxiv.org/abs/2507.10880v2", "summary": "Every day, multinational firms process thousands of transactions, each of\nwhich must adhere to tax regulations that vary by jurisdiction and are often\nnuanced. The determination of product and service tax codes, such as HSN or SAC\nis a major use case in Tax compliance. An accurate determination of such codes\nis imperative to avoid any tax penalties. This paper proposes a domain-adaptive\nsmall language model (SLM) with an encoder-decoder architecture for the\nenhanced prediction of product and service tax codes. In this approach, we\naddress the problem of predicting hierarchical tax code sequences using\nunstructured product and services data. We employ an SLM based upon\nencoder-decoder architecture as this enables sequential generation of tax codes\nto capture the hierarchical dependencies present within the tax codes. Our\nexperiments demonstrate that encoder-decoder SLMs can be successfully applied\nto the sequential prediction of structured tax codes, a domain that remains\ncomparatively unexplored in current NLP research. In this paper, we demonstrate\nthe superior performance of the domain-adaptive encoder-decoder SLMs over flat\nclassifiers when applied to the Harmonized System of Nomenclature (HSN), and\nachieve superior results compared to decoder-only and encoder-only\narchitectures for structured sequence generation tasks. This approach can also\nbe scaled to other government-mandated tax commodity codes, such as United\nNations Standard Products and Services Codes (UNSPSC), or Brazil's Nomenclatura\nComum do Mercosul (NCM).", "comment": "10 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.10880v2", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-19"}
{"id": "2507.09183", "title": "Revisiting Pool-based Prompt Learning for Few-shot Class-incremental Learning", "authors": ["Yongwei Jiang", "Yixiong Zou", "Yuhua Li", "Ruixuan Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025, 11 pages", "url": "http://arxiv.org/abs/2507.09183v2", "summary": "Few-Shot Class-Incremental Learning (FSCIL) faces dual challenges of data\nscarcity and incremental learning in real-world scenarios. While pool-based\nprompting methods have demonstrated success in traditional incremental\nlearning, their effectiveness in FSCIL settings remains unexplored. This paper\npresents the first study of current prompt pool methods in FSCIL tasks,\nrevealing an unanticipated performance degradation in incremental sessions.\nThrough comprehensive analysis, we identify that this phenomenon stems from\ntoken-dimension saturation: with limited data, excessive prompts compete for\ntask-relevant information, leading to model overfitting. Based on this finding,\nwe propose LGSP-Prompt (Local-Global Spatial Prompting), which innovatively\nshifts pool-based prompt learning from the token dimension to the spatial\ndimension. LGSP-Prompt generates spatial prompts by synergistically combining\nlocal spatial features and global frequency-domain representations to highlight\nkey patterns in input images. We construct two spatial prompt pools enabling\ndynamic prompt selection to maintain acquired knowledge while effectively\nlearning novel sessions. Extensive experiments demonstrate that our approach\nachieves state-of-the-art performance across multiple FSCIL benchmarks, showing\nsignificant advantages in both base knowledge preservation and incremental\nlearning. Our implementation is available at\nhttps://github.com/Jywsuperman/LGSP.", "comment": "Accepted to ICCV 2025, 11 pages", "pdf_url": "http://arxiv.org/pdf/2507.09183v2", "cate": "cs.CV", "date": "2025-07-12", "updated": "2025-07-20"}
{"id": "2507.12555", "title": "Can Mental Imagery Improve the Thinking Capabilities of AI Systems?", "authors": ["Slimane Larabi"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      15 pages, 8 figures", "url": "http://arxiv.org/abs/2507.12555v2", "summary": "Although existing models can interact with humans and provide satisfactory\nresponses, they lack the ability to act autonomously or engage in independent\nreasoning. Furthermore, input data in these models is typically provided as\nexplicit queries, even when some sensory data is already acquired.\n  In addition, AI agents, which are computational entities designed to perform\ntasks and make decisions autonomously based on their programming, data inputs,\nand learned knowledge, have shown significant progress. However, they struggle\nwith integrating knowledge across multiple domains, unlike humans.\n  Mental imagery plays a fundamental role in the brain's thinking process,\nwhich involves performing tasks based on internal multisensory data, planned\nactions, needs, and reasoning capabilities. In this paper, we investigate how\nto integrate mental imagery into a machine thinking framework and how this\ncould be beneficial in initiating the thinking process. Our proposed machine\nthinking framework integrates a Cognitive thinking unit supported by three\nauxiliary units: the Input Data Unit, the Needs Unit, and the Mental Imagery\nUnit. Within this framework, data is represented as natural language sentences\nor drawn sketches, serving both informative and decision-making purposes. We\nconducted validation tests for this framework, and the results are presented\nand discussed.", "comment": "15 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.12555v2", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-20"}
{"id": "2507.11019", "title": "Relative Entropy Pathwise Policy Optimization", "authors": ["Claas Voelcker", "Axel Brunnbauer", "Marcel Hussing", "Michal Nauman", "Pieter Abbeel", "Eric Eaton", "Radu Grosu", "Amir-massoud Farahmand", "Igor Gilitschenski"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11019v2", "summary": "Score-function policy gradients have delivered strong results in\ngame-playing, robotics and language-model fine-tuning. Yet its high-variance\noften undermines training stability. On the other hand, pathwise policy\ngradients alleviate the training variance, but are reliable only when driven by\nan accurate action-conditioned value function which is notoriously hard to\ntrain without relying on past off-policy data. In this paper, we discuss how to\nconstruct a value-gradient driven, on-policy algorithm that allow training\nQ-value models purely from on-policy data, unlocking the possibility of using\npathwise policy updates in the context of on-policy learning. We show how to\nbalance stochastic policies for exploration with constrained policy updates for\nstable training, and evaluate important architectural components that\nfacilitate accurate value function learning. Building on these insights, we\npropose Relative Entropy Pathwise Policy Optimization (REPPO), an efficient\non-policy algorithm that combines the sample-efficiency of pathwise policy\ngradients with the simplicity and minimal memory footprint of standard\non-policy learning. We demonstrate that REPPO provides strong empirical\nperformance at decreased sample requirements, wall-clock time, memory footprint\nas well as high hyperparameter robustness in a set of experiments on two\nstandard GPU-parallelized benchmarks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11019v2", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-18"}
{"id": "2507.09222", "title": "Calibrated and Robust Foundation Models for Vision-Language and Medical Image Tasks Under Distribution Shift", "authors": ["Behraj Khan", "Tahir Qasim Syed", "Nouman M. Durrani", "Bilal Naseem", "Shabir Ahmad", "Rizwan Qureshi"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09222v2", "summary": "Foundation models like CLIP and SAM have advanced computer vision and medical\nimaging via low-shot transfer learning, aiding CADD with limited data. However,\ntheir deployment faces two key challenges. \\textit{distribution shift} where\npre-training and post-training data distributions differ (e.g., due to\ninter-center image acquisition) and \\textit{confidence misalignment}, which\nleads to overconfident errors. These issues surface differently,\nvision-language models (e.g., CLIP) suffer from 2D embedding shift (image-text\nmisalignment), while medical models (e.g., SAM) encounter 3D domain shifts\n(e.g., scanner variation) and voxel-wise calibration need. Existing solutions\nare domain-specific. We propose \\textbf{StaRFM}, a fusion of Fisher information\npenalty (FIP) and confidence misalignment penalty (CMP) tackling both\nchallenges. It applies FIP, extended to 3D via patch-wise regularization, to\nreduce embedding shift, and CMP, reformulated for voxel-level predictions, to\ncalibrate segmentation uncertainty. We derive PAC-Bayes bounds. FIP controls\ngeneralization via the Fisher-Rao norm, and CMP reduces calibration error via\nBrier score minimization. StaRFM surpasses baselines by \\texttt{+}3.5\\%\naccuracy and 28\\% lower ECE on 19 vision datasets (e.g., ImageNet,\nOffice-Home), achieves +4.2\\% DSC over SAM-FT and 4.8mm HD95 on medical\nbenchmarks (e.g., BraTS, ATLAS), and reduces cross-domain gaps by up to 20\\%.\nThe framework is plug-and-play, requiring minimal architectural changes. Code\nand models are available at:\n\\href{https://anonymous.4open.science/r/StaRFM-C0CD/}{\\textcolor{blue}{\\underline{StaRFM}}}", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09222v2", "cate": "cs.CV", "date": "2025-07-12", "updated": "2025-07-20"}
{"id": "2507.14000", "title": "Photonic Fabric Platform for AI Accelerators", "authors": ["Jing Ding", "Trung Diep"], "categories": ["cs.PF", "cs.AI", "C.4"], "primary_category": "Subjects:       Performance (cs.PF)", "pdf_link": null, "comments": "Comments:      12 pages, 14 figures, 5 tables", "url": "http://arxiv.org/abs/2507.14000v2", "summary": "This paper presents the Photonic FabricTM and the Photonic Fabric ApplianceTM\n(PFA), a photonic-enabled switch and memory subsystem that delivers low\nlatency, high bandwidth, and low per-bit energy. By integrating high-bandwidth\nHBM3E memory, an on-module photonic switch, and external DDR5 in a 2.5D\nelectro-optical system-in-package, the PFA offers up to 32 TB of shared memory\nalongside 115 Tbps of all-to-all digital switching. The Photonic FabricTM\nenables distributed AI training and inference to execute parallelism strategies\nmore efficiently. The Photonic Fabric removes the silicon beachfront constraint\nthat limits the fixed memory-to-compute ratio observed in virtually all current\nXPU accelerator designs. Replacing a local HBM stack on an XPU with a chiplet\nthat connects to the Photonic Fabric increases its memory capacity and\ncorrespondingly its memory bandwidth by offering a flexible path to scaling\nwell beyond the limitations of on-package HBM alone. We introduce CelestiSim, a\nlightweight analytical simulator validated on NVIDIA H100 and H200 systems. It\nis used to evaluate the performance of LLM reference and energy savings on PFA,\nwithout any significant change to the GPU core design. With the PFA, the\nsimulation results show that up to 3.66x throughput and 1.40x latency\nimprovements in LLM inference at 405B parameters, up to 7.04x throughput and\n1.41x latency improvements at 1T parameters, and 60-90% energy savings in data\nmovement for heavy collective operations in all LLM training scenarios. While\nthese results are shown for NVIDIA GPUs, they can be applied similarly to other\nAI accelerator designs (XPUs) that share the same fundamental limitation of\nfixed memory to compute.", "comment": "12 pages, 14 figures, 5 tables", "pdf_url": "http://arxiv.org/pdf/2507.14000v2", "cate": "cs.PF", "date": "2025-07-18", "updated": "2025-07-21"}
{"id": "2507.11688", "title": "Composing Linear Layers from Irreducibles", "authors": ["Travis Pence", "Daisuke Yamada", "Vikas Singh"], "categories": ["cs.LG", "I.2.6"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      27 Pages, 13 Tables, 8 Figures", "url": "http://arxiv.org/abs/2507.11688v2", "summary": "Contemporary large models often exhibit behaviors suggesting the presence of\nlow-level primitives that compose into modules with richer functionality, but\nthese fundamental building blocks remain poorly understood. We investigate this\ncompositional structure in linear layers by asking: can we identify/synthesize\nlinear transformations from a minimal set of geometric primitives? Using\nClifford algebra, we show that linear layers can be expressed as compositions\nof bivectors -- geometric objects encoding oriented planes -- and introduce a\ndifferentiable algorithm that decomposes them into products of rotors. This\nconstruction uses only O(log^2 d) parameters, versus O(d^2) required by dense\nmatrices. Applied to the key, query, and value projections in LLM attention\nlayers, our rotor-based layers match the performance of strong baselines such\nas block-Hadamard and low-rank approximations. Our findings provide an\nalgebraic perspective on how these geometric primitives can compose into\nhigher-level functions within deep models.", "comment": "27 Pages, 13 Tables, 8 Figures", "pdf_url": "http://arxiv.org/pdf/2507.11688v2", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-20"}
{"id": "2507.09410", "title": "GreenCrossingAI: A Camera Trap/Computer Vision Pipeline for Environmental Science Research Groups", "authors": ["Bernie Boscoe", "Shawn Johnson", "Andrea Osbon", "Chandler Campbell", "Karen Mager"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This is the preprint version of the paper in Practice and Experience in Advanced Research Computing, PEARC25", "url": "http://arxiv.org/abs/2507.09410v2", "summary": "Camera traps have long been used by wildlife researchers to monitor and study\nanimal behavior, population dynamics, habitat use, and species diversity in a\nnon-invasive and efficient manner. While data collection from the field has\nincreased with new tools and capabilities, methods to develop, process, and\nmanage the data, especially the adoption of ML/AI tools, remain challenging.\nThese challenges include the sheer volume of data generated, the need for\naccurate labeling and annotation, variability in environmental conditions\naffecting data quality, and the integration of ML/AI tools into existing\nworkflows that often require domain-specific customization and computational\nresources. This paper provides a guide to a low-resource pipeline to process\ncamera trap data on-premise, incorporating ML/AI capabilities tailored for\nsmall research groups with limited resources and computational expertise. By\nfocusing on practical solutions, the pipeline offers accessible approaches for\ndata transmission, inference, and evaluation, enabling researchers to discover\nmeaningful insights from their ever-increasing camera trap datasets.", "comment": "This is the preprint version of the paper in Practice and Experience\n  in Advanced Research Computing, PEARC25", "pdf_url": "http://arxiv.org/pdf/2507.09410v2", "cate": "cs.CV", "date": "2025-07-12", "updated": "2025-07-18"}
{"id": "2507.13704", "title": "Bayesian Optimization for Molecules Should Be Pareto-Aware", "authors": ["Anabel Yong", "Austin Tripp", "Layla Hosseini-Gerami", "Brooks Paige"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13704v2", "summary": "Multi-objective Bayesian optimization (MOBO) provides a principled framework\nfor navigating trade-offs in molecular design. However, its empirical\nadvantages over scalarized alternatives remain underexplored. We benchmark a\nsimple Pareto-based MOBO strategy -- Expected Hypervolume Improvement (EHVI) --\nagainst a simple fixed-weight scalarized baseline using Expected Improvement\n(EI), under a tightly controlled setup with identical Gaussian Process\nsurrogates and molecular representations. Across three molecular optimization\ntasks, EHVI consistently outperforms scalarized EI in terms of Pareto front\ncoverage, convergence speed, and chemical diversity. While scalarization\nencompasses flexible variants -- including random or adaptive schemes -- our\nresults show that even strong deterministic instantiations can underperform in\nlow-data regimes. These findings offer concrete evidence for the practical\nadvantages of Pareto-aware acquisition in de novo molecular optimization,\nespecially when evaluation budgets are limited and trade-offs are nontrivial.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13704v2", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-21"}
{"id": "2507.09560", "title": "EHPE: A Segmented Architecture for Enhanced Hand Pose Estimation", "authors": ["Bolun Zheng", "Xinjie Liu", "Qianyu Zhang", "Canjin Wang", "Fangni Chen", "Mingen Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09560v2", "summary": "3D hand pose estimation has garnered great attention in recent years due to\nits critical applications in human-computer interaction, virtual reality, and\nrelated fields. The accurate estimation of hand joints is essential for\nhigh-quality hand pose estimation. However, existing methods neglect the\nimportance of Distal Phalanx Tip (TIP) and Wrist in predicting hand joints\noverall and often fail to account for the phenomenon of error accumulation for\ndistal joints in gesture estimation, which can cause certain joints to incur\nlarger errors, resulting in misalignments and artifacts in the pose estimation\nand degrading the overall reconstruction quality. To address this challenge, we\npropose a novel segmented architecture for enhanced hand pose estimation\n(EHPE). We perform local extraction of TIP and wrist, thus alleviating the\neffect of error accumulation on TIP prediction and further reduce the\npredictive errors for all joints on this basis. EHPE consists of two key\nstages: In the TIP and Wrist Joints Extraction stage (TW-stage), the positions\nof the TIP and wrist joints are estimated to provide an initial accurate joint\nconfiguration; In the Prior Guided Joints Estimation stage (PG-stage), a\ndual-branch interaction network is employed to refine the positions of the\nremaining joints. Extensive experiments on two widely used benchmarks\ndemonstrate that EHPE achieves state-of-the-arts performance. Code is available\nat https://github.com/SereinNout/EHPE.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09560v2", "cate": "cs.CV", "date": "2025-07-13", "updated": "2025-07-19"}
{"id": "2410.04489", "title": "Grokking at the Edge of Linear Separability", "authors": ["Alon Beck", "Noam Levi", "Yohai Bar-Sinai"], "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG", "math-ph", "math.MP"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Camera-ready version, ICML 2025", "url": "http://arxiv.org/abs/2410.04489v2", "summary": "We investigate the phenomenon of grokking -- delayed generalization\naccompanied by non-monotonic test loss behavior -- in a simple binary logistic\nclassification task, for which \"memorizing\" and \"generalizing\" solutions can be\nstrictly defined. Surprisingly, we find that grokking arises naturally even in\nthis minimal model when the parameters of the problem are close to a critical\npoint, and provide both empirical and analytical insights into its mechanism.\nConcretely, by appealing to the implicit bias of gradient descent, we show that\nlogistic regression can exhibit grokking when the training dataset is nearly\nlinearly separable from the origin and there is strong noise in the\nperpendicular directions. The underlying reason is that near the critical\npoint, \"flat\" directions in the loss landscape with nearly zero gradient cause\ntraining dynamics to linger for arbitrarily long times near quasi-stable\nsolutions before eventually reaching the global minimum. Finally, we highlight\nsimilarities between our findings and the recent literature, strengthening the\nconjecture that grokking generally occurs in proximity to the interpolation\nthreshold, reminiscent of critical phenomena often observed in physical\nsystems.", "comment": "Camera-ready version, ICML 2025", "pdf_url": "http://arxiv.org/pdf/2410.04489v2", "cate": "stat.ML", "date": "2024-10-06", "updated": "2025-07-19"}
{"id": "2507.09795", "title": "NegRefine: Refining Negative Label-Based Zero-Shot OOD Detection", "authors": ["Amirhossein Ansari", "Ke Wang", "Pulei Xiong"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.09795v2", "summary": "Recent advancements in Vision-Language Models like CLIP have enabled\nzero-shot OOD detection by leveraging both image and textual label information.\nAmong these, negative label-based methods such as NegLabel and CSP have shown\npromising results by utilizing a lexicon of words to define negative labels for\ndistinguishing OOD samples. However, these methods suffer from detecting\nin-distribution samples as OOD due to negative labels that are subcategories of\nin-distribution labels or proper nouns. They also face limitations in handling\nimages that match multiple in-distribution and negative labels. We propose\nNegRefine, a novel negative label refinement framework for zero-shot OOD\ndetection. By introducing a filtering mechanism to exclude subcategory labels\nand proper nouns from the negative label set and incorporating a\nmulti-matching-aware scoring function that dynamically adjusts the\ncontributions of multiple labels matching an image, NegRefine ensures a more\nrobust separation between in-distribution and OOD samples. We evaluate\nNegRefine on large-scale benchmarks, including ImageNet-1K. The code is\navailable at https://github.com/ah-ansari/NegRefine.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.09795v2", "cate": "cs.CV", "date": "2025-07-13", "updated": "2025-07-20"}
{"id": "2410.14621", "title": "JAMUN: Bridging Smoothed Molecular Dynamics and Score-Based Learning for Conformational Ensembles", "authors": ["Ameya Daigavane", "Bodhi P. Vani", "Darcy Davidson", "Saeed Saremi", "Joshua Rackers", "Joseph Kleinhenz"], "categories": ["physics.bio-ph", "cs.LG", "q-bio.BM"], "primary_category": "Subjects:       Biological Physics (physics.bio-ph)", "pdf_link": null, "comments": "Comments:      34 pages, presented at GenBio workshop at ICML 2025, under review", "url": "http://arxiv.org/abs/2410.14621v2", "summary": "Conformational ensembles of protein structures are immensely important both\nfor understanding protein function and drug discovery in novel modalities such\nas cryptic pockets. Current techniques for sampling ensembles such as molecular\ndynamics (MD) are computationally inefficient, while many recent machine\nlearning methods do not transfer to systems outside their training data. We\npropose JAMUN which performs MD in a smoothed, noised space of all-atom 3D\nconformations of molecules by utilizing the framework of walk-jump sampling.\nJAMUN enables ensemble generation for small peptides at rates of an order of\nmagnitude faster than traditional molecular dynamics. The physical priors in\nJAMUN enables transferability to systems outside of its training data, even to\npeptides that are longer than those originally trained on. Our model, code and\nweights are available at https://github.com/prescient-design/jamun.", "comment": "34 pages, presented at GenBio workshop at ICML 2025, under review", "pdf_url": "http://arxiv.org/pdf/2410.14621v2", "cate": "physics.bio-ph", "date": "2024-10-18", "updated": "2025-07-21"}
{"id": "2507.09993", "title": "3DGAA: Realistic and Robust 3D Gaussian-based Adversarial Attack for Autonomous Driving", "authors": ["Yixun Zhang", "Lizhi Wang", "Junjun Zhao", "Wending Zhao", "Feng Zhou", "Yonghao Dang", "Jianqin Yin"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Submitted to WACV 2026", "url": "http://arxiv.org/abs/2507.09993v2", "summary": "Camera-based object detection systems play a vital role in autonomous\ndriving, yet they remain vulnerable to adversarial threats in real-world\nenvironments. Existing 2D and 3D physical attacks, due to their focus on\ntexture optimization, often struggle to balance physical realism and attack\nrobustness. In this work, we propose 3D Gaussian-based Adversarial Attack\n(3DGAA), a novel adversarial object generation framework that leverages the\nfull 14-dimensional parameterization of 3D Gaussian Splatting (3DGS) to jointly\noptimize geometry and appearance in physically realizable ways. Unlike prior\nworks that rely on patches or texture optimization, 3DGAA jointly perturbs both\ngeometric attributes (shape, scale, rotation) and appearance attributes (color,\nopacity) to produce physically realistic and transferable adversarial objects.\nWe further introduce a physical filtering module that filters outliers to\npreserve geometric fidelity, and a physical augmentation module that simulates\ncomplex physical scenarios to enhance attack generalization under real-world\nconditions. We evaluate 3DGAA on both virtual benchmarks and physical-world\nsetups using miniature vehicle models. Experimental results show that 3DGAA\nachieves to reduce the detection mAP from 87.21\\% to 7.38\\%, significantly\noutperforming existing 3D physical attacks. Moreover, our method maintains high\ntransferability across different physical conditions, demonstrating a new\nstate-of-the-art in physically realizable adversarial attacks.", "comment": "Submitted to WACV 2026", "pdf_url": "http://arxiv.org/pdf/2507.09993v2", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-19"}
{"id": "2412.16644", "title": "An explainable operator approximation framework under the guideline of Green's function", "authors": ["Jianghang Gu", "Ling Wen", "Yuntian Chen", "Shiyi Chen"], "categories": ["physics.comp-ph", "cs.LG"], "primary_category": "Subjects:       Computational Physics (physics.comp-ph)", "pdf_link": null, "comments": "Comments:      no comments", "url": "http://arxiv.org/abs/2412.16644v2", "summary": "Traditional numerical methods, such as the finite element method and finite\nvolume method, adress partial differential equations (PDEs) by discretizing\nthem into algebraic equations and solving these iteratively. However, this\nprocess is often computationally expensive and time-consuming. An alternative\napproach involves transforming PDEs into integral equations and solving them\nusing Green's functions, which provide analytical solutions. Nevertheless,\nderiving Green's functions analytically is a challenging and non-trivial task,\nparticularly for complex systems. In this study, we introduce a novel\nframework, termed GreensONet, which is constructed based on the strucutre of\ndeep operator networks (DeepONet) to learn embedded Green's functions and solve\nPDEs via Green's integral formulation. Specifically, the Trunk Net within\nGreensONet is designed to approximate the unknown Green's functions of the\nsystem, while the Branch Net are utilized to approximate the auxiliary\ngradients of the Green's function. These outputs are subsequently employed to\nperform surface integrals and volume integrals, incorporating user-defined\nboundary conditions and source terms, respectively. The effectiveness of the\nproposed framework is demonstrated on three types of PDEs in bounded domains:\n3D heat conduction equations, reaction-diffusion equations, and Stokes\nequations. Comparative results in these cases demonstrate that GreenONet's\naccuracy and generalization ability surpass those of existing methods,\nincluding Physics-Informed Neural Networks (PINN), DeepONet, Physics-Informed\nDeepONet (PI-DeepONet), and Fourier Neural Operators (FNO).", "comment": "no comments", "pdf_url": "http://arxiv.org/pdf/2412.16644v2", "cate": "physics.comp-ph", "date": "2024-12-21", "updated": "2025-07-20"}
{"id": "2507.10203", "title": "Improving Multimodal Learning via Imbalanced Learning", "authors": ["Shicai Wei", "Chunbo Luo", "Yang Luo"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV2025", "url": "http://arxiv.org/abs/2507.10203v2", "summary": "Multimodal learning often encounters the under-optimized problem and may\nperform worse than unimodal learning. Existing approaches attribute this issue\nto imbalanced learning across modalities and tend to address it through\ngradient balancing. However, this paper argues that balanced learning is not\nthe optimal setting for multimodal learning. With bias-variance analysis, we\nprove that imbalanced dependency on each modality obeying the inverse ratio of\ntheir variances contributes to optimal performance. To this end, we propose the\nAsymmetric Representation Learning(ARL) strategy to assist multimodal learning\nvia imbalanced optimization. ARL introduces auxiliary regularizers for each\nmodality encoder to calculate their prediction variance. ARL then calculates\ncoefficients via the unimodal variance to re-weight the optimization of each\nmodality, forcing the modality dependence ratio to be inversely proportional to\nthe modality variance ratio. Moreover, to minimize the generalization error,\nARL further introduces the prediction bias of each modality and jointly\noptimizes them with multimodal loss. Notably, all auxiliary regularizers share\nparameters with the multimodal model and rely only on the modality\nrepresentation. Thus the proposed ARL strategy introduces no extra parameters\nand is independent of the structures and fusion methods of the multimodal\nmodel. Finally, extensive experiments on various datasets validate the\neffectiveness and versatility of ARL. Code is available at\n\\href{https://github.com/shicaiwei123/ICCV2025-ARL}{https://github.com/shicaiwei123/ICCV2025-ARL}", "comment": "Accepted to ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.10203v2", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-21"}
{"id": "2501.10729", "title": "Robust Local Polynomial Regression with Similarity Kernels", "authors": ["Yaniv Shulman"], "categories": ["stat.ME", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Methodology (stat.ME)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.10729v2", "summary": "Local Polynomial Regression (LPR) is a widely used nonparametric method for\nmodeling complex relationships due to its flexibility and simplicity. It\nestimates a regression function by fitting low-degree polynomials to localized\nsubsets of the data, weighted by proximity. However, traditional LPR is\nsensitive to outliers and high-leverage points, which can significantly affect\nestimation accuracy. This paper revisits the kernel function used to compute\nregression weights and proposes a novel framework that incorporates both\npredictor and response variables in the weighting mechanism. The focus of this\nwork is a conditional density kernel that robustly estimates weights by\nmitigating the influence of outliers through localized density estimation. A\nrelated joint density kernel is also discussed in an appendix. The proposed\nmethod is implemented in Python and is publicly available at\nhttps://github.com/yaniv-shulman/rsklpr, demonstrating competitive performance\nin synthetic benchmark experiments. Compared to standard LPR, the proposed\napproach consistently improves robustness and accuracy, especially in\nheteroscedastic and noisy environments, without requiring multiple iterations.\nThis advancement provides a promising extension to traditional LPR, opening new\npossibilities for robust regression applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.10729v2", "cate": "stat.ME", "date": "2025-01-18", "updated": "2025-07-20"}
{"id": "2507.10217", "title": "From Wardrobe to Canvas: Wardrobe Polyptych LoRA for Part-level Controllable Human Image Generation", "authors": ["Jeongho Kim", "Sunghyun Park", "Hyoungwoo Park", "Sungrack Yun", "Jaegul Choo", "Seokeon Choi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 8 figures", "url": "http://arxiv.org/abs/2507.10217v2", "summary": "Recent diffusion models achieve personalization by learning specific\nsubjects, allowing learned attributes to be integrated into generated images.\nHowever, personalized human image generation remains challenging due to the\nneed for precise and consistent attribute preservation (e.g., identity,\nclothing details). Existing subject-driven image generation methods often\nrequire either (1) inference-time fine-tuning with few images for each new\nsubject or (2) large-scale dataset training for generalization. Both approaches\nare computationally expensive and impractical for real-time applications. To\naddress these limitations, we present Wardrobe Polyptych LoRA, a novel\npart-level controllable model for personalized human image generation. By\ntraining only LoRA layers, our method removes the computational burden at\ninference while ensuring high-fidelity synthesis of unseen subjects. Our key\nidea is to condition the generation on the subject's wardrobe and leverage\nspatial references to reduce information loss, thereby improving fidelity and\nconsistency. Additionally, we introduce a selective subject region loss, which\nencourages the model to disregard some of reference images during training. Our\nloss ensures that generated images better align with text prompts while\nmaintaining subject integrity. Notably, our Wardrobe Polyptych LoRA requires no\nadditional parameters at the inference stage and performs generation using a\nsingle model trained on a few training samples. We construct a new dataset and\nbenchmark tailored for personalized human image generation. Extensive\nexperiments show that our approach significantly outperforms existing\ntechniques in fidelity and consistency, enabling realistic and\nidentity-preserving full-body synthesis.", "comment": "10 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.10217v2", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-21"}
{"id": "2502.03350", "title": "Optimal Task Order for Continual Learning of Multiple Tasks", "authors": ["Ziyan Li", "Naoki Hiratani"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.03350v2", "summary": "Continual learning of multiple tasks remains a major challenge for neural\nnetworks. Here, we investigate how task order influences continual learning and\npropose a strategy for optimizing it. Leveraging a linear teacher-student model\nwith latent factors, we derive an analytical expression relating task\nsimilarity and ordering to learning performance. Our analysis reveals two\nprinciples that hold under a wide parameter range: (1) tasks should be arranged\nfrom the least representative to the most typical, and (2) adjacent tasks\nshould be dissimilar. We validate these rules on both synthetic data and\nreal-world image classification datasets (Fashion-MNIST, CIFAR-10, CIFAR-100),\ndemonstrating consistent performance improvements in both multilayer\nperceptrons and convolutional neural networks. Our work thus presents a\ngeneralizable framework for task-order optimization in task-incremental\ncontinual learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.03350v2", "cate": "stat.ML", "date": "2025-02-05", "updated": "2025-07-20"}
{"id": "2507.11055", "title": "Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation", "authors": ["Shuchang Ye", "Usman Naseem", "Mingyuan Meng", "Jinman Kim"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.11055v3", "summary": "Medical language-guided segmentation, integrating textual clinical reports as\nauxiliary guidance to enhance image segmentation, has demonstrated significant\nimprovements over unimodal approaches. However, its inherent reliance on paired\nimage-text input, which we refer to as ``textual reliance\", presents two\nfundamental limitations: 1) many medical segmentation datasets lack paired\nreports, leaving a substantial portion of image-only data underutilized for\ntraining; and 2) inference is limited to retrospective analysis of cases with\npaired reports, limiting its applicability in most clinical scenarios where\nsegmentation typically precedes reporting. To address these limitations, we\npropose ProLearn, the first Prototype-driven Learning framework for\nlanguage-guided segmentation that fundamentally alleviates textual reliance. At\nits core, we introduce a novel Prototype-driven Semantic Approximation (PSA)\nmodule to enable approximation of semantic guidance from textual input. PSA\ninitializes a discrete and compact prototype space by distilling\nsegmentation-relevant semantics from textual reports. Once initialized, it\nsupports a query-and-respond mechanism which approximates semantic guidance for\nimages without textual input, thereby alleviating textual reliance. Extensive\nexperiments on QaTa-COV19, MosMedData+ and Kvasir-SEG demonstrate that ProLearn\noutperforms state-of-the-art language-guided methods when limited text is\navailable.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.11055v3", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-19"}
{"id": "2506.12655", "title": "Beyond Sin-Squared Error: Linear-Time Entrywise Uncertainty Quantification for Streaming PCA", "authors": ["Syamantak Kumar", "Shourya Pandey", "Purnamrita Sarkar"], "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "primary_category": "Subjects:       Statistics Theory (math.ST)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.12655v2", "summary": "We propose a novel statistical inference framework for streaming principal\ncomponent analysis (PCA) using Oja's algorithm, enabling the construction of\nconfidence intervals for individual entries of the estimated eigenvector. Most\nexisting works on streaming PCA focus on providing sharp sin-squared error\nguarantees. Recently, there has been some interest in uncertainty\nquantification for the sin-squared error. However, uncertainty quantification\nor sharp error guarantees for entries of the estimated eigenvector in the\nstreaming setting remains largely unexplored. We derive a sharp Bernstein-type\nconcentration bound for elements of the estimated vector matching the optimal\nerror rate up to logarithmic factors. We also establish a Central Limit Theorem\nfor a suitably centered and scaled subset of the entries. To efficiently\nestimate the coordinate-wise variance, we introduce a provably consistent\nsubsampling algorithm that leverages the median-of-means approach, empirically\nachieving similar accuracy to multiplier bootstrap methods while being\nsignificantly more computationally efficient. Numerical experiments demonstrate\nits effectiveness in providing reliable uncertainty estimates with a fraction\nof the computational cost of existing methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.12655v2", "cate": "math.ST", "date": "2025-06-14", "updated": "2025-07-20"}
{"id": "2507.12049", "title": "MoViAD: A Modular Library for Visual Anomaly Detection", "authors": ["Manuel Barusco", "Francesco Borsatti", "Arianna Stropeni", "Davide Dalle Pezze", "Gian Antonio Susto"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12049v2", "summary": "VAD is a critical field in machine learning focused on identifying deviations\nfrom normal patterns in images, often challenged by the scarcity of anomalous\ndata and the need for unsupervised training. To accelerate research and\ndeployment in this domain, we introduce MoViAD, a comprehensive and highly\nmodular library designed to provide fast and easy access to state-of-the-art\nVAD models, trainers, datasets, and VAD utilities. MoViAD supports a wide array\nof scenarios, including continual, semi-supervised, few-shots, noisy, and many\nmore. In addition, it addresses practical deployment challenges through\ndedicated Edge and IoT settings, offering optimized models and backbones, along\nwith quantization and compression utilities for efficient on-device execution\nand distributed inference. MoViAD integrates a selection of backbones, robust\nevaluation VAD metrics (pixel-level and image-level) and useful profiling tools\nfor efficiency analysis. The library is designed for fast, effortless\ndeployment, enabling machine learning engineers to easily use it for their\nspecific setup with custom models, datasets, and backbones. At the same time,\nit offers the flexibility and extensibility researchers need to develop and\nexperiment with new methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12049v2", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-19"}
{"id": "2507.00683", "title": "Testing the spin-bath view of self-attention: A Hamiltonian analysis of GPT-2 Transformer", "authors": ["Satadeep Bhattacharjee", "Seung-Cheol Lee"], "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "Subjects:       Materials Science (cond-mat.mtrl-sci)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.00683v4", "summary": "The recently proposed physics-based framework by Huo and\nJohnson~\\cite{huo2024capturing} models the attention mechanism of Large\nLanguage Models (LLMs) as an interacting two-body spin system, offering a\nfirst-principles explanation for phenomena like repetition and bias. Building\non this hypothesis, we extract the complete Query-Key weight matrices from a\nproduction-grade GPT-2 model and derive the corresponding effective Hamiltonian\nfor every attention head. From these Hamiltonians, we obtain analytic phase\nboundaries and logit gap criteria that predict which token should dominate the\nnext-token distribution for a given context. A systematic evaluation on 144\nheads across 20 factual-recall prompts reveals a strong negative correlation\nbetween the theoretical logit gaps and the model's empirical token rankings\n($r\\approx-0.70$, $p<10^{-3}$).Targeted ablations further show that suppressing\nthe heads most aligned with the spin-bath predictions induces the anticipated\nshifts in output probabilities, confirming a causal link rather than a\ncoincidental association. Taken together, our findings provide the first strong\nempirical evidence for the spin-bath analogy in a production-grade model. In\nthis work, we utilize the context-field lens, which provides physics-grounded\ninterpretability and motivates the development of novel generative models\nbridging theoretical condensed matter physics and artificial intelligence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.00683v4", "cate": "cond-mat.mtrl-sci", "date": "2025-07-01", "updated": "2025-07-21"}
{"id": "2507.12087", "title": "YOLOv8-SMOT: An Efficient and Robust Framework for Real-Time Small Object Tracking via Slice-Assisted Training and Adaptive Association", "authors": ["Xiang Yu", "Xinyao Liu", "Guang Liang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12087v2", "summary": "Tracking small, agile multi-objects (SMOT), such as birds, from an Unmanned\nAerial Vehicle (UAV) perspective is a highly challenging computer vision task.\nThe difficulty stems from three main sources: the extreme scarcity of target\nappearance features, the complex motion entanglement caused by the combined\ndynamics of the camera and the targets themselves, and the frequent occlusions\nand identity ambiguity arising from dense flocking behavior. This paper details\nour championship-winning solution in the MVA 2025 \"Finding Birds\" Small\nMulti-Object Tracking Challenge (SMOT4SB), which adopts the\ntracking-by-detection paradigm with targeted innovations at both the detection\nand association levels. On the detection side, we propose a systematic training\nenhancement framework named \\textbf{SliceTrain}. This framework, through the\nsynergy of 'deterministic full-coverage slicing' and 'slice-level stochastic\naugmentation, effectively addresses the problem of insufficient learning for\nsmall objects in high-resolution image training. On the tracking side, we\ndesigned a robust tracker that is completely independent of appearance\ninformation. By integrating a \\textbf{motion direction maintenance (EMA)}\nmechanism and an \\textbf{adaptive similarity metric} combining \\textbf{bounding\nbox expansion and distance penalty} into the OC-SORT framework, our tracker can\nstably handle irregular motion and maintain target identities. Our method\nachieves state-of-the-art performance on the SMOT4SB public test set, reaching\nan SO-HOTA score of \\textbf{55.205}, which fully validates the effectiveness\nand advancement of our framework in solving complex real-world SMOT problems.\nThe source code will be made available at\nhttps://github.com/Salvatore-Love/YOLOv8-SMOT.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12087v2", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-20"}
{"id": "2507.01260", "title": "Automated Classification of Volcanic Earthquakes Using Transformer Encoders: Insights into Data Quality and Model Interpretability", "authors": ["Y. Suzuki", "Y. Yukutake", "T. Ohminato", "M. Yamasaki", "Ahyi Kim"], "categories": ["physics.geo-ph", "cs.LG"], "primary_category": "Subjects:       Geophysics (physics.geo-ph)", "pdf_link": null, "comments": "Comments:      submitted to Seismological Research Letters", "url": "http://arxiv.org/abs/2507.01260v2", "summary": "Precisely classifying earthquake types is crucial for elucidating the\nrelationship between volcanic earthquakes and volcanic activity. However,\ntraditional methods rely on subjective human judgment, which requires\nconsiderable time and effort. To address this issue, we developed a deep\nlearning model using a transformer encoder for a more objective and efficient\nclassification. Tested on Mount Asama's diverse seismic activity, our model\nachieved high F1 scores (0.930 for volcano tectonic, 0.931 for low-frequency\nearthquakes, and 0.980 for noise), superior to a conventional CNN-based method.\nTo enhance interpretability, attention weight visualizations were analyzed,\nrevealing that the model focuses on key waveform features similarly to human\nexperts. However, inconsistencies in training data, such as ambiguously labeled\nB-type events with S-waves, were found to influence classification accuracy and\nattention weight distributions. Experiments addressing data selection and\naugmentation demonstrated the importance of balancing data quality and\ndiversity. In addition, stations within 3 km of the crater played an important\nrole in improving model performance and interpretability. These findings\nhighlight the potential of Transformer-based models for automated volcanic\nearthquake classification, particularly in improving efficiency and\ninterpretability. By addressing challenges such as data imbalance and\nsubjective labeling, our approach provides a robust framework for understanding\nseismic activity at Mount Asama. Moreover, this framework offers opportunities\nfor transfer learning to other volcanic regions, paving the way for enhanced\nvolcanic hazard assessments and disaster mitigation strategies.", "comment": "submitted to Seismological Research Letters", "pdf_url": "http://arxiv.org/pdf/2507.01260v2", "cate": "physics.geo-ph", "date": "2025-07-02", "updated": "2025-07-21"}
{"id": "2507.12137", "title": "AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving", "authors": ["Jiawei Xu", "Kai Deng", "Zexin Fan", "Shenlong Wang", "Jin Xie", "Jian Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.12137v2", "summary": "Modeling and rendering dynamic urban driving scenes is crucial for\nself-driving simulation. Current high-quality methods typically rely on costly\nmanual object tracklet annotations, while self-supervised approaches fail to\ncapture dynamic object motions accurately and decompose scenes properly,\nresulting in rendering artifacts. We introduce AD-GS, a novel self-supervised\nframework for high-quality free-viewpoint rendering of driving scenes from a\nsingle log. At its core is a novel learnable motion model that integrates\nlocality-aware B-spline curves with global-aware trigonometric functions,\nenabling flexible yet precise dynamic object modeling. Rather than requiring\ncomprehensive semantic labeling, AD-GS automatically segments scenes into\nobjects and background with the simplified pseudo 2D segmentation, representing\nobjects using dynamic Gaussians and bidirectional temporal visibility masks.\nFurther, our model incorporates visibility reasoning and physically rigid\nregularization to enhance robustness. Extensive evaluations demonstrate that\nour annotation-free model significantly outperforms current state-of-the-art\nannotation-free methods and is competitive with annotation-dependent\napproaches.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.12137v2", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-21"}
{"id": "2507.05470", "title": "Temporal Conformal Prediction (TCP): A Distribution-Free Statistical and Machine Learning Framework for Adaptive Risk Forecasting", "authors": ["Agnideep Aich", "Ashit Baran Aich", "Dipak C. Jain"], "categories": ["stat.ML", "cs.LG", "62G08, 62M10, 62P05, 91G70, 68T05"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05470v2", "summary": "We propose Temporal Conformal Prediction (TCP), a principled framework for\nconstructing well-calibrated prediction intervals for non-stationary time\nseries. TCP integrates a machine learning-based quantile forecaster with an\nonline conformal calibration layer. This layer's thresholds are updated via a\nmodified Robbins-Monro scheme, allowing the model to dynamically adapt to\nvolatility clustering and regime shifts without rigid parametric assumptions.\nWe benchmark TCP against GARCH, Historical Simulation, and static Quantile\nRegression across diverse financial assets. Our empirical results reveal a\ncritical flaw in static methods: while sharp, Quantile Regression is poorly\ncalibrated, systematically over-covering the nominal 95% target. In contrast,\nTCP's adaptive mechanism actively works to achieve the correct coverage level,\nsuccessfully navigating the coverage-sharpness tradeoff. Visualizations during\nthe 2020 market crash confirm TCP's superior adaptive response, and a\ncomprehensive sensitivity analysis demonstrates the framework's robustness to\nhyperparameter choices. Overall, TCP offers a practical and\ntheoretically-grounded solution to the central challenge of calibrated\nuncertainty quantification for time series under distribution shift, advancing\nthe interface between statistical inference and machine learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05470v2", "cate": "stat.ML", "date": "2025-07-07", "updated": "2025-07-21"}
{"id": "2507.12462", "title": "SpatialTrackerV2: 3D Point Tracking Made Easy", "authors": ["Yuxi Xiao", "Jianyuan Wang", "Nan Xue", "Nikita Karaev", "Yuri Makarov", "Bingyi Kang", "Xing Zhu", "Hujun Bao", "Yujun Shen", "Xiaowei Zhou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      International Conference on Computer Vision, ICCV 2025. Huggingface Demo: this https URL , Code: this https URL", "url": "http://arxiv.org/abs/2507.12462v2", "summary": "We present SpatialTrackerV2, a feed-forward 3D point tracking method for\nmonocular videos. Going beyond modular pipelines built on off-the-shelf\ncomponents for 3D tracking, our approach unifies the intrinsic connections\nbetween point tracking, monocular depth, and camera pose estimation into a\nhigh-performing and feedforward 3D point tracker. It decomposes world-space 3D\nmotion into scene geometry, camera ego-motion, and pixel-wise object motion,\nwith a fully differentiable and end-to-end architecture, allowing scalable\ntraining across a wide range of datasets, including synthetic sequences, posed\nRGB-D videos, and unlabeled in-the-wild footage. By learning geometry and\nmotion jointly from such heterogeneous data, SpatialTrackerV2 outperforms\nexisting 3D tracking methods by 30%, and matches the accuracy of leading\ndynamic 3D reconstruction approaches while running 50$\\times$ faster.", "comment": "International Conference on Computer Vision, ICCV 2025. Huggingface\n  Demo: https://huggingface.co/spaces/Yuxihenry/SpatialTrackerV2, Code:\n  https://github.com/henry123-boy/SpaTrackerV2", "pdf_url": "http://arxiv.org/pdf/2507.12462v2", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-19"}
{"id": "2507.06565", "title": "A Mathematical Theory of Discursive Networks", "authors": ["Juan B. Gutiérrez"], "categories": ["cs.CL", "cs.LG", "68T01, 60J10, 91D30, 05C82, 68T50, 68W20, 94A15", "I.2.7; I.2.11; G.3"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      39 pages, 4 figures, 4 tables, 3 algorithm, 56 references", "url": "http://arxiv.org/abs/2507.06565v4", "summary": "Large language models (LLMs) turn writing into a live exchange between humans\nand software. We characterize this new medium as a discursive network that\ntreats people and LLMs as equal nodes and tracks how their statements\ncirculate. We define the generation of erroneous information as invalidation\n(any factual, logical, or structural breach) and show it follows four hazards:\ndrift from truth, self-repair, fresh fabrication, and external detection. We\ndevelop a general mathematical model of discursive networks that shows that a\nnetwork governed only by drift and self-repair stabilizes at a modest error\nrate. Giving each false claim even a small chance of peer review shifts the\nsystem to a truth-dominant state. We operationalize peer review with the\nopen-source Flaws-of-Others (FOO) algorithm: a configurable loop in which any\nset of agents critique one another while a harmonizer merges their verdicts. We\nidentify an ethical transgression, epithesis, that occurs when humans fail to\nengage in the discursive network. The takeaway is practical and cultural:\nreliability in this new medium comes not from perfecting single models but from\nconnecting imperfect ones into networks that enforce mutual accountability.", "comment": "39 pages, 4 figures, 4 tables, 3 algorithm, 56 references", "pdf_url": "http://arxiv.org/pdf/2507.06565v4", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-21"}
{"id": "2507.12465", "title": "PhysX-3D: Physical-Grounded 3D Asset Generation", "authors": ["Ziang Cao", "Zhaoxi Chen", "Liang Pan", "Ziwei Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2507.12465v3", "summary": "3D modeling is moving from virtual to physical. Existing 3D generation\nprimarily emphasizes geometries and textures while neglecting physical-grounded\nmodeling. Consequently, despite the rapid development of 3D generative models,\nthe synthesized 3D assets often overlook rich and important physical\nproperties, hampering their real-world application in physical domains like\nsimulation and embodied AI. As an initial attempt to address this challenge, we\npropose \\textbf{PhysX-3D}, an end-to-end paradigm for physical-grounded 3D\nasset generation. 1) To bridge the critical gap in physics-annotated 3D\ndatasets, we present PhysXNet - the first physics-grounded 3D dataset\nsystematically annotated across five foundational dimensions: absolute scale,\nmaterial, affordance, kinematics, and function description. In particular, we\ndevise a scalable human-in-the-loop annotation pipeline based on\nvision-language models, which enables efficient creation of physics-first\nassets from raw 3D assets.2) Furthermore, we propose \\textbf{PhysXGen}, a\nfeed-forward framework for physics-grounded image-to-3D asset generation,\ninjecting physical knowledge into the pre-trained 3D structural space.\nSpecifically, PhysXGen employs a dual-branch architecture to explicitly model\nthe latent correlations between 3D structures and physical properties, thereby\nproducing 3D assets with plausible physical predictions while preserving the\nnative geometry quality. Extensive experiments validate the superior\nperformance and promising generalization capability of our framework. All the\ncode, data, and models will be released to facilitate future research in\ngenerative physical AI.", "comment": "Project page: https://physx-3d.github.io/", "pdf_url": "http://arxiv.org/pdf/2507.12465v3", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-20"}
{"id": "2507.09025", "title": "Lizard: An Efficient Linearization Framework for Large Language Models", "authors": ["Chien Van Nguyen", "Ruiyi Zhang", "Hanieh Deilamsalehy", "Puneet Mathur", "Viet Dac Lai", "Haoliang Wang", "Jayakumar Subramanian", "Ryan A. Rossi", "Trung Bui", "Nikos Vlassis", "Franck Dernoncourt", "Thien Huu Nguyen"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      15 pages", "url": "http://arxiv.org/abs/2507.09025v2", "summary": "We propose Lizard, a linearization framework that transforms pretrained\nTransformer-based Large Language Models (LLMs) into flexible, subquadratic\narchitectures for infinite-context generation. Transformer-based LLMs face\nsignificant memory and computational bottlenecks as context lengths increase,\ndue to the quadratic complexity of softmax attention and the growing key-value\n(KV) cache. Lizard addresses these limitations by introducing a subquadratic\nattention mechanism that closely approximates softmax attention while\npreserving the output quality. Unlike previous linearization methods, which are\noften limited by fixed model structures and therefore exclude gating\nmechanisms, Lizard incorporates a gating module inspired by recent\nstate-of-the-art linear models. This enables adaptive memory control, supports\nconstant-memory inference, offers strong length generalization, and allows more\nflexible model design. Lizard combines gated linear attention for global\ncontext compression with sliding window attention enhanced by meta memory,\nforming a hybrid mechanism that captures both long-range dependencies and\nfine-grained local interactions. Moreover, we introduce a hardware-aware\nalgorithm that accelerates the training speed of our models. Extensive\nexperiments show that Lizard achieves near-lossless recovery of the teacher\nmodel's performance across standard language modeling tasks, while\nsignificantly outperforming previous linearization methods. On the 5-shot MMLU\nbenchmark, Lizard improves over prior models by 18 points and shows significant\nimprovements on associative recall tasks.", "comment": "15 pages", "pdf_url": "http://arxiv.org/pdf/2507.09025v2", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-20"}
{"id": "2507.13346", "title": "AutoPartGen: Autogressive 3D Part Generation and Discovery", "authors": ["Minghao Chen", "Jianyuan Wang", "Roman Shapovalov", "Tom Monnier", "Hyunyoung Jung", "Dilin Wang", "Rakesh Ranjan", "Iro Laina", "Andrea Vedaldi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2507.13346v2", "summary": "We introduce AutoPartGen, a model that generates objects composed of 3D parts\nin an autoregressive manner. This model can take as input an image of an\nobject, 2D masks of the object's parts, or an existing 3D object, and generate\na corresponding compositional 3D reconstruction. Our approach builds upon\n3DShape2VecSet, a recent latent 3D representation with powerful geometric\nexpressiveness. We observe that this latent space exhibits strong compositional\nproperties, making it particularly well-suited for part-based generation tasks.\nSpecifically, AutoPartGen generates object parts autoregressively, predicting\none part at a time while conditioning on previously generated parts and\nadditional inputs, such as 2D images, masks, or 3D objects. This process\ncontinues until the model decides that all parts have been generated, thus\ndetermining automatically the type and number of parts. The resulting parts can\nbe seamlessly assembled into coherent objects or scenes without requiring\nadditional optimization. We evaluate both the overall 3D generation\ncapabilities and the part-level generation quality of AutoPartGen,\ndemonstrating that it achieves state-of-the-art performance in 3D part\ngeneration.", "comment": "Project page: https://silent-chen.github.io/AutoPartGen/", "pdf_url": "http://arxiv.org/pdf/2507.13346v2", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-19"}
{"id": "2507.10524", "title": "Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation", "authors": ["Sangmin Bae", "Yujin Kim", "Reza Bayat", "Sungnyun Kim", "Jiyoun Ha", "Tal Schuster", "Adam Fisch", "Hrayr Harutyunyan", "Ziwei Ji", "Aaron Courville", "Se-Young Yun"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      36 pages, 9 figures, 14 tables, codes at this https URL", "url": "http://arxiv.org/abs/2507.10524v2", "summary": "Scaling language models unlocks impressive capabilities, but the accompanying\ncomputational and memory demands make both training and deployment expensive.\nExisting efficiency efforts typically target either parameter sharing or\nadaptive computation, leaving open the question of how to attain both\nsimultaneously. We introduce Mixture-of-Recursions (MoR), a unified framework\nthat combines the two axes of efficiency inside a single Recursive Transformer.\nMoR reuses a shared stack of layers across recursion steps to achieve parameter\nefficiency, while lightweight routers enable adaptive token-level thinking by\ndynamically assigning different recursion depths to individual tokens. This\nallows MoR to focus quadratic attention computation only among tokens still\nactive at a given recursion depth, further improving memory access efficiency\nby selectively caching only their key-value pairs. Beyond these core\nmechanisms, we also propose a KV sharing variant that reuses KV pairs from the\nfirst recursion, specifically designed to decrease prefill latency and memory\nfootprint. Across model scales ranging from 135M to 1.7B parameters, MoR forms\na new Pareto frontier: at equal training FLOPs and smaller model sizes, it\nsignificantly lowers validation perplexity and improves few-shot accuracy,\nwhile delivering higher throughput compared with vanilla and existing recursive\nbaselines. These gains demonstrate that MoR is an effective path towards\nlarge-model quality without incurring large-model cost.", "comment": "36 pages, 9 figures, 14 tables, codes at\n  https://github.com/raymin0223/mixture_of_recursions", "pdf_url": "http://arxiv.org/pdf/2507.10524v2", "cate": "cs.CL", "date": "2025-07-14", "updated": "2025-07-21"}
{"id": "2507.13861", "title": "PositionIC: Unified Position and Identity Consistency for Image Customization", "authors": ["Junjie Hu", "Tianyang Han", "Kai Ma", "Jialin Gao", "Hao Dou", "Song Yang", "Xianhua He", "Jianhui Zhang", "Junfeng Luo", "Xiaoming Wei", "Wenqiang Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13861v2", "summary": "Recent subject-driven image customization has achieved significant\nadvancements in fidelity, yet fine-grained entity-level spatial control remains\nelusive, hindering the broader real-world application. This limitation is\nmainly attributed to scalable datasets that bind identity with precise\npositional cues are absent. To this end, we introduce PositionIC, a unified\nframework that enforces position and identity consistency for multi-subject\ncustomization. We construct a scalable synthesis pipeline that employs a\nbidirectional generation paradigm to eliminate subject drift and maintain\nsemantic coherence. On top of these data, we design a lightweight positional\nmodulation layer that decouples spatial embeddings among subjects, enabling\nindependent, accurate placement while preserving visual fidelity. Extensive\nexperiments demonstrate that our approach can achieve precise spatial control\nwhile maintaining high consistency in image customization task. PositionIC\npaves the way for controllable, high-fidelity image customization in\nopen-world, multi-entity scenarios and will be released to foster further\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13861v2", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-21"}
{"id": "2507.11192", "title": "Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis", "authors": ["Bo Liang", "He Wang"], "categories": ["gr-qc", "astro-ph.HE", "astro-ph.IM", "cs.LG", "stat.ML"], "primary_category": "Subjects:       General Relativity and Quantum Cosmology (gr-qc)", "pdf_link": null, "comments": "Comments:      31 pages, 6 figures, 1 table. References updated; literature covered up to early 2025 only. Feedback welcome from those interested in AI4GW surveys!", "url": "http://arxiv.org/abs/2507.11192v3", "summary": "The detection of gravitational waves by the LIGO-Virgo-KAGRA collaboration\nhas ushered in a new era of observational astronomy, emphasizing the need for\nrapid and detailed parameter estimation and population-level analyses.\nTraditional Bayesian inference methods, particularly Markov chain Monte Carlo,\nface significant computational challenges when dealing with the\nhigh-dimensional parameter spaces and complex noise characteristics inherent in\ngravitational wave data. This review examines the emerging role of\nsimulation-based inference methods in gravitational wave astronomy, with a\nfocus on approaches that leverage machine-learning techniques such as\nnormalizing flows and neural posterior estimation. We provide a comprehensive\noverview of the theoretical foundations underlying various simulation-based\ninference methods, including neural posterior estimation, neural ratio\nestimation, neural likelihood estimation, flow matching, and consistency\nmodels. We explore the applications of these methods across diverse\ngravitational wave data processing scenarios, from single-source parameter\nestimation and overlapping signal analysis to testing general relativity and\nconducting population studies. Although these techniques demonstrate speed\nimprovements over traditional methods in controlled studies, their\nmodel-dependent nature and sensitivity to prior assumptions are barriers to\ntheir widespread adoption. Their accuracy, which is similar to that of\nconventional methods, requires further validation across broader parameter\nspaces and noise conditions.", "comment": "31 pages, 6 figures, 1 table. References updated; literature covered\n  up to early 2025 only. Feedback welcome from those interested in AI4GW\n  surveys!", "pdf_url": "http://arxiv.org/pdf/2507.11192v3", "cate": "gr-qc", "date": "2025-07-15", "updated": "2025-07-20"}
{"id": "2507.13891", "title": "PCR-GS: COLMAP-Free 3D Gaussian Splatting via Pose Co-Regularizations", "authors": ["Yu Wei", "Jiahui Zhang", "Xiaoqin Zhang", "Ling Shao", "Shijian Lu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13891v2", "summary": "COLMAP-free 3D Gaussian Splatting (3D-GS) has recently attracted increasing\nattention due to its remarkable performance in reconstructing high-quality 3D\nscenes from unposed images or videos. However, it often struggles to handle\nscenes with complex camera trajectories as featured by drastic rotation and\ntranslation across adjacent camera views, leading to degraded estimation of\ncamera poses and further local minima in joint optimization of camera poses and\n3D-GS. We propose PCR-GS, an innovative COLMAP-free 3DGS technique that\nachieves superior 3D scene modeling and camera pose estimation via camera pose\nco-regularization. PCR-GS achieves regularization from two perspectives. The\nfirst is feature reprojection regularization which extracts view-robust DINO\nfeatures from adjacent camera views and aligns their semantic information for\ncamera pose regularization. The second is wavelet-based frequency\nregularization which exploits discrepancy in high-frequency details to further\noptimize the rotation matrix in camera poses. Extensive experiments over\nmultiple real-world scenes show that the proposed PCR-GS achieves superior\npose-free 3D-GS scene modeling under dramatic changes of camera trajectories.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13891v2", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-21"}
{"id": "2405.00430", "title": "Continuous sPatial-Temporal Deformable Image Registration (CPT-DIR) for motion modelling in radiotherapy: beyond classic voxel-based methods", "authors": ["Xia Li", "Runzhao Yang", "Muheng Li", "Xiangtai Li", "Antony J. Lomax", "Joachim M. Buhmann", "Ye Zhang"], "categories": ["physics.med-ph", "cs.CV"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.00430v2", "summary": "Deformable image registration (DIR) is a crucial tool in radiotherapy for\nanalyzing anatomical changes and motion patterns. Current DIR implementations\nrely on discrete volumetric motion representation, which often leads to\ncompromised accuracy and uncertainty when handling significant anatomical\nchanges and sliding boundaries. This limitation affects the reliability of\nsubsequent contour propagation and dose accumulation procedures, particularly\nin regions with complex anatomical interfaces such as the lung-chest wall\nboundary. Given that organ motion is inherently a continuous process in both\nspace and time, we aimed to develop a model that preserves these fundamental\nproperties. Drawing inspiration from fluid mechanics, we propose a novel\napproach using implicit neural representation (INR) for continuous modeling of\npatient anatomical motion. This approach ensures spatial and temporal\ncontinuity while effectively unifying Eulerian and Lagrangian specifications to\nenable natural continuous motion modeling and frame interpolation. The\nintegration of these specifications provides a more comprehensive understanding\nof anatomical deformation patterns. By leveraging the continuous\nrepresentations, the CPT-DIR method significantly enhances registration and\ninterpolation accuracy, automation, and speed. The method demonstrates superior\nperformance in landmark and contour precision, particularly in challenging\nanatomical regions, representing a substantial advancement over conventional\napproaches in deformable image registration. The improved efficiency and\naccuracy of CPT-DIR make it particularly suitable for real-time adaptive\nradiotherapy applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.00430v2", "cate": "physics.med-ph", "date": "2024-05-01", "updated": "2025-07-21"}
{"id": "2503.23768", "title": "Texture or Semantics? Vision-Language Models Get Lost in Font Recognition", "authors": ["Zhecheng Li", "Guoxian Song", "Yujun Cai", "Zhen Xiong", "Junsong Yuan", "Yiwei Wang"], "categories": ["cs.CL", "cs.CV"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to COLM 2025", "url": "http://arxiv.org/abs/2503.23768v2", "summary": "Modern Vision-Language Models (VLMs) exhibit remarkable visual and linguistic\ncapabilities, achieving impressive performance in various tasks such as image\nrecognition and object localization. However, their effectiveness in\nfine-grained tasks remains an open question. In everyday scenarios, individuals\nencountering design materials, such as magazines, typography tutorials,\nresearch papers, or branding content, may wish to identify aesthetically\npleasing fonts used in the text. Given their multimodal capabilities and free\naccessibility, many VLMs are often considered potential tools for font\nrecognition. This raises a fundamental question: Do VLMs truly possess the\ncapability to recognize fonts? To investigate this, we introduce the Font\nRecognition Benchmark (FRB), a compact and well-structured dataset comprising\n15 commonly used fonts. FRB includes two versions: (i) an easy version, where\n10 sentences are rendered in different fonts, and (ii) a hard version, where\neach text sample consists of the names of the 15 fonts themselves, introducing\na stroop effect that challenges model perception. Through extensive evaluation\nof various VLMs on font recognition tasks, we arrive at the following key\nfindings: (i) Current VLMs exhibit limited font recognition capabilities, with\nmany state-of-the-art models failing to achieve satisfactory performance and\nbeing easily affected by the stroop effect introduced by textual information.\n(ii) Few-shot learning and Chain-of-Thought (CoT) prompting provide minimal\nbenefits in improving font recognition accuracy across different VLMs. (iii)\nAttention analysis sheds light on the inherent limitations of VLMs in capturing\nsemantic features.", "comment": "Accepted to COLM 2025", "pdf_url": "http://arxiv.org/pdf/2503.23768v2", "cate": "cs.CL", "date": "2025-03-31", "updated": "2025-07-19"}
{"id": "2503.23898", "title": "An Explainable Neural Radiomic Sequence Model with Spatiotemporal Continuity for Quantifying 4DCT-based Pulmonary Ventilation", "authors": ["Rihui Zhang", "Haiming Zhu", "Jingtong Zhao", "Lei Zhang", "Fang-Fang Yin", "Chunhao Wang", "Zhenyu Yang"], "categories": ["physics.med-ph", "cs.CV"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "Comments:      43 pages, 13 figures", "url": "http://arxiv.org/abs/2503.23898v2", "summary": "Accurate evaluation of regional lung ventilation is essential for the\nmanagement and treatment of lung cancer patients, supporting assessments of\npulmonary function, optimization of therapeutic strategies, and monitoring of\ntreatment response. Currently, ventilation scintigraphy using nuclear medicine\ntechniques is widely employed in clinical practice; however, it is often\ntime-consuming, costly, and entails additional radiation exposure. In this\nstudy, we propose an explainable neural radiomic sequence model to identify\nregions of compromised pulmonary ventilation based on four-dimensional computed\ntomography (4DCT). A cohort of 45 lung cancer patients from the VAMPIRE dataset\nwas analyzed. For each patient, lung volumes were segmented from 4DCT, and\nvoxel-wise radiomic features (56-dimensional) were extracted across the\nrespiratory cycle to capture local intensity and texture dynamics, forming\ntemporal radiomic sequences. Ground truth ventilation defects were delineated\nvoxel-wise using Galligas-PET and DTPA-SPECT. To identify compromised regions,\nwe developed a temporal saliency-enhanced explainable long short-term memory\n(LSTM) network trained on the radiomic sequences. Temporal saliency maps were\ngenerated to highlight key features contributing to the model's predictions.\nThe proposed model demonstrated robust performance, achieving average (range)\nDice similarity coefficients of 0.78 (0.74-0.79) for 25 PET cases and 0.78\n(0.74-0.82) for 20 SPECT cases. The temporal saliency map explained three key\nradiomic sequences in ventilation quantification: during lung exhalation,\ncompromised pulmonary function region typically exhibits (1) an increasing\ntrend of intensity and (2) a decreasing trend of homogeneity, in contrast to\nhealthy lung tissue.", "comment": "43 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2503.23898v2", "cate": "physics.med-ph", "date": "2025-03-31", "updated": "2025-07-20"}
{"id": "2505.11538", "title": "BrainNetMLP: An Efficient and Effective Baseline for Functional Brain Network Classification", "authors": ["Jiacheng Hou", "Zhenjie Song", "Ercan Engin Kuruoglu"], "categories": ["q-bio.NC", "cs.CV"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "Comments:      Accepted for oral presentation at the 1st MICCAI Workshop on Efficient Medical AI", "url": "http://arxiv.org/abs/2505.11538v2", "summary": "Recent studies have made great progress in functional brain network\nclassification by modeling the brain as a network of Regions of Interest (ROIs)\nand leveraging their connections to understand brain functionality and diagnose\nmental disorders. Various deep learning architectures, including Convolutional\nNeural Networks, Graph Neural Networks, and the recent Transformer, have been\ndeveloped. However, despite the increasing complexity of these models, the\nperformance gain has not been as salient. This raises a question: Does\nincreasing model complexity necessarily lead to higher classification accuracy?\nIn this paper, we revisit the simplest deep learning architecture, the\nMulti-Layer Perceptron (MLP), and propose a pure MLP-based method, named\nBrainNetMLP, for functional brain network classification, which capitalizes on\nthe advantages of MLP, including efficient computation and fewer parameters.\nMoreover, BrainNetMLP incorporates a dual-branch structure to jointly capture\nboth spatial connectivity and spectral information, enabling precise\nspatiotemporal feature fusion. We evaluate our proposed BrainNetMLP on two\npublic and popular brain network classification datasets, the Human Connectome\nProject (HCP) and the Autism Brain Imaging Data Exchange (ABIDE). Experimental\nresults demonstrate pure MLP-based methods can achieve state-of-the-art\nperformance, revealing the potential of MLP-based models as more efficient yet\neffective alternatives in functional brain network classification. The code\nwill be available at https://github.com/JayceonHo/BrainNetMLP.", "comment": "Accepted for oral presentation at the 1st MICCAI Workshop on\n  Efficient Medical AI", "pdf_url": "http://arxiv.org/pdf/2505.11538v2", "cate": "q-bio.NC", "date": "2025-05-14", "updated": "2025-07-21"}
{"id": "2507.09024", "title": "CNeuroMod-THINGS, a densely-sampled fMRI dataset for visual neuroscience", "authors": ["Marie St-Laurent", "Basile Pinsard", "Oliver Contier", "Elizabeth DuPre", "Katja Seeliger", "Valentina Borghesani", "Julie A. Boyle", "Lune Bellec", "Martin N. Hebart"], "categories": ["q-bio.NC", "cs.CV"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "Comments:      16 pages manuscript, 5 figures, 9 pages supplementary material", "url": "http://arxiv.org/abs/2507.09024v2", "summary": "Data-hungry neuro-AI modelling requires ever larger neuroimaging datasets.\nCNeuroMod-THINGS meets this need by capturing neural representations for a wide\nset of semantic concepts using well-characterized images in a new\ndensely-sampled, large-scale fMRI dataset. Importantly, CNeuroMod-THINGS\nexploits synergies between two existing projects: the THINGS initiative\n(THINGS) and the Courtois Project on Neural Modelling (CNeuroMod). THINGS has\ndeveloped a common set of thoroughly annotated images broadly sampling natural\nand man-made objects which is used to acquire a growing collection of\nlarge-scale multimodal neural responses. Meanwhile, CNeuroMod is acquiring\nhundreds of hours of fMRI data from a core set of participants during\ncontrolled and naturalistic tasks, including visual tasks like movie watching\nand videogame playing. For CNeuroMod-THINGS, four CNeuroMod participants each\ncompleted 33-36 sessions of a continuous recognition paradigm using\napproximately 4000 images from the THINGS stimulus set spanning 720 categories.\nWe report behavioural and neuroimaging metrics that showcase the quality of the\ndata. By bridging together large existing resources, CNeuroMod-THINGS expands\nour capacity to model broad slices of the human visual experience.", "comment": "16 pages manuscript, 5 figures, 9 pages supplementary material", "pdf_url": "http://arxiv.org/pdf/2507.09024v2", "cate": "q-bio.NC", "date": "2025-07-11", "updated": "2025-07-18"}
