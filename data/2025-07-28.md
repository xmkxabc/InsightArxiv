# AI-Enhanced arXiv Daily 2025-07-28

<a id='toc'></a>
## 今日总计: 880 篇论文
### 目录
- [cs.CR](#cscr) (22 篇)
- [cs.AI](#csai) (46 篇)
- [cs.LG](#cslg) (118 篇)
- [cs.MA](#csma) (7 篇)
- [cs.RO](#csro) (38 篇)
- [cs.CV](#cscv) (166 篇)
- [cs.HC](#cshc) (42 篇)
- [cs.ET](#cset) (2 篇)
- [cs.SE](#csse) (29 篇)
- [cs.SI](#cssi) (2 篇)
- [cs.NI](#csni) (8 篇)
- [cs.IT](#csit) (16 篇)
- [cs.AR](#csar) (8 篇)
- [cs.DC](#csdc) (11 篇)
- [cs.CY](#cscy) (10 篇)
- [cs.CE](#csce) (3 篇)
- [cs.FL](#csfl) (3 篇)
- [eess.SY](#eesssy) (36 篇)
- [eess.SP](#eesssp) (20 篇)
- [eess.IV](#eessiv) (31 篇)
- [eess.AS](#eessas) (12 篇)
- [cs.CL](#cscl) (111 篇)
- [cs.DS](#csds) (7 篇)
- [cs.GR](#csgr) (9 篇)
- [cs.IR](#csir) (18 篇)
- [cs.NE](#csne) (4 篇)
- [math.NA](#mathna) (19 篇)
- [cs.SD](#cssd) (11 篇)
- [math.OC](#mathoc) (8 篇)
- [math.ST](#mathst) (1 篇)
- [stat.ML](#statml) (9 篇)
- [stat.ME](#statme) (1 篇)
- [cs.MM](#csmm) (1 篇)
- [quant-ph](#quant-ph) (8 篇)
- [cond-mat.mtrl-sci](#cond-matmtrl-sci) (1 篇)
- [astro-ph.IM](#astro-phim) (1 篇)
- [cs.GT](#csgt) (1 篇)
- [hep-ph](#hep-ph) (1 篇)
- [cs.DL](#csdl) (1 篇)
- [physics.med-ph](#physicsmed-ph) (3 篇)
- [cs.LO](#cslo) (5 篇)
- [stat.AP](#statap) (3 篇)
- [physics.flu-dyn](#physicsflu-dyn) (2 篇)
- [q-fin.PM](#q-finpm) (1 篇)
- [q-bio.QM](#q-bioqm) (3 篇)
- [q-fin.CP](#q-fincp) (2 篇)
- [cs.CC](#cscc) (2 篇)
- [math.LO](#mathlo) (1 篇)
- [math.CO](#mathco) (2 篇)
- [cs.DB](#csdb) (2 篇)
- [math.AP](#mathap) (1 篇)
- [cs.DM](#csdm) (1 篇)
- [econ.GN](#econgn) (1 篇)
- [astro-ph.HE](#astro-phhe) (1 篇)
- [cond-mat.str-el](#cond-matstr-el) (1 篇)
- [physics.optics](#physicsoptics) (1 篇)
- [stat.OT](#statot) (1 篇)
- [physics.acc-ph](#physicsacc-ph) (1 篇)
- [cs.CG](#cscg) (1 篇)
- [physics.ins-det](#physicsins-det) (1 篇)
- [q-bio.NC](#q-bionc) (1 篇)
- [physics.comp-ph](#physicscomp-ph) (1 篇)

---
<a id='cscr'></a>
## cs.CR 

### [1] [NWaaS: Nonintrusive Watermarking as a Service for X-to-Image DNN](https://arxiv.org/abs/2507.18036)
> *NWaaS：面向X到图像DNN的非侵入式水印即服务*

*Haonan An, Guang Hua, Yu Guo, Hangcheng Cao, Susanto Rahardja, Yuguang Fang* | **Category: cs.CR, cs.CV** | **Updated: 2025-07-24**

**Keywords:** DNN水印, 非侵入式, 水印即服务, X到图像, 知识产权

**Comment:** 

> **TL;DR:** 现有的DNN水印技术具有侵入性；本文提出了NWaaS（ShadowMark），一种针对X到图像DNN的非侵入式方法，可保持模型保真度和鲁棒性。

**AI_Comments:** 这篇论文为DNN知识产权保护中的一个关键实际问题提出了创新的解决方案。非侵入式水印的概念是一项重大进展，直接解决了模型所有者不愿采用现有侵入式方法的问题。其“绝对保真度”和“消除保真度-鲁棒性权衡”是关键创新点，有望使DNN水印在实际应用中更具可行性。

<details>
  <summary>Details</summary>

**Motivation:** 现有DNN水印方法具有侵入性（修改参数或结构），导致模型行为偏移、微调成本增加，并使模型所有者不愿采用，从而限制了实用WaaS系统的发展。

**Method:** 本文引入了非侵入式水印即服务（NWaaS），这是一种针对X到图像模型的新型无信任范式，假设在不触及模型的情况下仍可从模型输出中提取水印。具体实现为ShadowMark，通过在受保护模型的黑盒API中建立一个鲁棒且非侵入性的侧信道，利用密钥编码器和水印解码器来解决部署挑战。

**Result:** 对图像到图像、噪声到图像、噪声和文本到图像以及文本到图像模型的广泛实验表明，ShadowMark在非侵入式DNN水印的实际部署中是有效和实用的，实现了绝对保真度，适用于不同DNN架构，并对现有攻击具有鲁棒性，消除了保真度-鲁棒性权衡。

**Conclusion:** NWaaS（ShadowMark）为实际部署的非侵入式DNN水印提供了一种有效且实用的解决方案，克服了侵入式方法的局限性，并同时实现了保真度和鲁棒性。

> **ai_Abstract:** 本文介绍了非侵入式水印即服务（NWaaS）及其实现ShadowMark，这是一种保护X到图像DNN模型知识产权的新方法。与现有改变模型参数或结构的侵入性方法不同，NWaaS在不修改模型的情况下从模型输出中提取水印，解决了行为偏移和微调成本的担忧。ShadowMark实现了绝对保真度，适用于各种DNN架构，并对攻击具有鲁棒性，消除了保真度-鲁棒性权衡，这已通过广泛实验得到证明。

> **摘要翻译:** 深度神经网络（DNN）模型的知识产权可以通过DNN水印保护，该技术将版权水印嵌入到模型参数（白盒）、模型行为（黑盒）或模型输出（无盒）中，随后可以提取水印以验证模型所有权或检测模型盗窃。尽管最近有所进展，但现有方法本质上是侵入性的，因为它们要么修改模型参数，要么改变模型结构。这种固有的侵入性引发了对水印导致模型行为偏移和额外微调成本的担忧，随着模型规模的快速增长，这些问题进一步加剧。因此，模型所有者往往不愿在实践中采用DNN水印，这限制了实用水印即服务（WaaS）系统的发展。为了解决这个问题，我们引入了非侵入式水印即服务（NWaaS），这是一种专为X到图像模型设计的新型无信任范式，我们假设在不触及模型的情况下，仍然可以从模型输出中提取所有者定义的水印。基于这一概念，我们提出了ShadowMark，它是NWaaS的一个具体实现，通过在受保护模型的黑盒API中建立一个鲁棒且非侵入性的侧信道，利用密钥编码器和水印解码器来解决关键的部署挑战。它与现有解决方案显著不同，因为它实现了所谓的绝对保真度，并且适用于不同的DNN架构，同时还对现有攻击具有鲁棒性，消除了保真度-鲁棒性权衡。对图像到图像、噪声到图像、噪声和文本到图像以及文本到图像模型进行的广泛实验证明了ShadowMark在非侵入式DNN水印实际部署中的有效性和实用性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [8] [RECALLED: An Unbounded Resource Consumption Attack on Large Vision-Language Models](https://arxiv.org/abs/2507.18053)
> *RECALLED：一种针对大型视觉语言模型的无限制资源消耗攻击*

*Haoran Gao, Yuanhe Zhang, Zhenhong Zhou, Lei Jiang, Fanyu Meng, Yujia Xiao, Kun Wang, Yang Liu, Junlan Feng* | **Category: cs.CR, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 资源消耗攻击, 视觉语言模型, 对抗性扰动, 红队, 安全漏洞

**Comment:** 

> **TL;DR:** RECALLED是一种利用视觉输入对大型视觉语言模型（LVLMs）发动无限制资源消耗攻击（RCA）的新方法，通过生成重复输出显著增加服务延迟和资源消耗。

**AI_Comments:** RECALLED是首次针对大型视觉语言模型（LVLMs）利用视觉模态实施无限制资源消耗攻击（RCA）的研究，填补了现有红队研究忽视视觉输入攻击面的空白。其创新点在于提出了“视觉引导优化”和“多目标并行损失”，能够生成有效且通用的攻击模板。这项工作对于理解LVLM的潜在安全漏洞及其未来防御策略的开发具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的红队研究忽视了视觉输入作为大型视觉语言模型（LVLMs）潜在的资源消耗攻击（RCA）面，导致针对LVLMs中RCA的缓解策略不足。

**Method:** 本文提出了RECALLED方法，首次利用视觉模态触发无限制RCA。首先，引入“视觉引导优化”进行细粒度像素级优化，以获得“输出召回”对抗性扰动，诱导重复输出。然后，将扰动注入视觉输入以触发无限制生成。此外，引入“多目标并行损失”以生成通用攻击模板并解决并行攻击时的优化冲突。

**Result:** RECALLED使服务响应延迟增加了26%以上，导致GPU利用率和内存消耗额外增加20%。

**Conclusion:** 本研究揭示了LVLMs中的安全漏洞，并建立了一个红队框架，有助于未来开发针对RCA的防御措施。

> **ai_Abstract:** 该论文提出了RECALLED，一种针对大型视觉语言模型（LVLMs）的无限制资源消耗攻击（RCA）方法。RECALLED通过“视觉引导优化”生成“输出召回”对抗性扰动，将其注入视觉输入以触发LVLM的重复输出和无限制生成，从而显著增加服务响应延迟、GPU利用率和内存消耗。该研究揭示了LVLMs的漏洞，并为未来RCA防御提供了红队框架。

> **摘要翻译:** 资源消耗攻击（RCAs）已成为大型语言模型（LLMs）部署面临的重大威胁。随着视觉模态的整合，额外的攻击向量加剧了大型视觉语言模型（LVLMs）中RCA的风险。然而，现有红队研究在很大程度上忽视了视觉输入作为潜在的攻击面，导致针对LVLMs中RCA的缓解策略不足。为了解决这一空白，我们提出了RECALLED（大型视觉语言模型上的资源消耗攻击），这是第一个利用视觉模态触发无限制RCA红队攻击的方法。首先，我们提出了“视觉引导优化”，一种细粒度像素级优化，以获得“输出召回”对抗性扰动，可以诱导重复输出。然后，我们将扰动注入视觉输入，触发无限制生成以实现RCA的目标。此外，我们引入“多目标并行损失”来生成通用攻击模板，并解决在尝试实施并行攻击时的优化冲突。实证结果表明，RECALLED将服务响应延迟增加了26%以上，导致GPU利用率和内存消耗额外增加20%。我们的研究揭示了LVLMs中的安全漏洞，并建立了一个红队框架，可以促进未来针对RCA的防御开发。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [15] [PyPitfall: Dependency Chaos and Software Supply Chain Vulnerabilities in Python](https://arxiv.org/abs/2507.18075)
> *PyPitfall：Python中的依赖混乱和软件供应链漏洞*

*Jacob Mahon, Chenxi Hou, Zhihao Yao* | **Category: cs.CR** | **Updated: 2025-07-24**

**Keywords:** Python, 软件供应链, 依赖漏洞, PyPI, 供应链安全

**Comment:** 

> **TL;DR:** 本文介绍了PyPitfall，对PyPI生态系统中的易受攻击依赖项进行了定量分析，揭示了Python软件供应链中广泛存在的漏洞。

**AI_Comments:** 这项研究通过对PyPI生态系统进行大规模定量分析，揭示了Python软件供应链中易受攻击依赖项的普遍性，具有重要的实际意义，有助于提高开发者和用户对供应链安全风险的认识。

<details>
  <summary>Details</summary>

**Motivation:** Python软件开发严重依赖第三方包，但这些依赖链中的漏洞可能传播并影响下游包和应用程序。官方Python包仓库PyPI缺乏对易受攻击依赖项普遍性的全面分析。

**Method:** 本文引入了PyPitfall工具，对PyPI生态系统中的易受攻击依赖项进行定量分析。具体分析了378,573个PyPI包的依赖结构。

**Result:** 分析发现，有4,655个包明确要求至少一个已知易受攻击的版本，另有141,044个包允许在其指定范围内使用易受攻击的版本。

**Conclusion:** 通过描述整个生态系统的依赖关系图景和传递性依赖的安全影响，旨在提高对Python软件供应链安全的认识。

> **ai_Abstract:** 本文介绍了PyPitfall，一个用于定量分析PyPI生态系统中易受攻击依赖项的工具。研究分析了超过37万个PyPI包的依赖结构，发现大量包直接或间接依赖于已知易受攻击的版本，揭示了Python软件供应链中普遍存在的安全漏洞风险，旨在提高对该领域安全的认识。

> **摘要翻译:** Python软件开发严重依赖第三方包。直接和传递性依赖创建了一个迷宫般的软件供应链。虽然代码重用很方便，但这些依赖链中的漏洞可以通过依赖关系传播，可能影响下游包和应用程序。官方Python包仓库PyPI托管了许多包，但缺乏对易受攻击依赖项普遍性的全面分析。本文介绍了PyPitfall，一个对PyPI生态系统中易受攻击依赖项进行定量分析的工具。我们分析了378,573个PyPI包的依赖结构，并识别出4,655个明确要求至少一个已知易受攻击版本的包，以及141,044个允许在指定范围内使用易受攻击版本的包。通过描述整个生态系统的依赖关系图景和传递性依赖的安全影响，我们旨在提高对Python软件供应链安全的认识。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [22] [An Improved ChaCha Algorithm Based on Quantum Random Number](https://arxiv.org/abs/2507.18157)
> *基于量子随机数的改进ChaCha算法*

*Chao Liu, Shuai Zhao, Chenhao Jia, Gengran Hu, Tingting Cui* | **Category: cs.CR, quant-ph, Primary:94A60, Secondary:68P25, Tertiary:81P94** | **Updated: 2025-07-24**

**Keywords:** ChaCha算法, 量子随机数, 密码分析, 随机性测试, 抗量子攻击

**Comment:** 20 pages,4 figures

> **TL;DR:** 本文提出了一种基于量子随机数改进的ChaCha算法（QRE-ChaCha），以增强其对经典和量子攻击的安全性，同时保持高效率和良好的随机性。

**AI_Comments:** 本文的创新点在于将量子随机数引入到ChaCha算法中，以应对量子计算和AI辅助密码分析带来的安全威胁。通过在初始常数和特定轮次注入量子随机数，有效增强了算法的扩散性，提升了其抗差分攻击的能力和密钥流的随机性。研究方法全面，既有理论分析（量子随机性、差分密码分析），也有实际测试（NIST和GM/T随机性测试、性能评估）。这为后量子密码学的发展提供了一个实用的改进方案，具有重要的研究价值和应用前景。

<details>
  <summary>Details</summary>

**Motivation:** ChaCha算法虽然高效且能抵抗时序和侧信道攻击，但随着AI辅助密码分析和量子计算技术的发展，其安全性面临严峻挑战。为进一步增强ChaCha密码的安全性，本文提出了改进方案。

**Method:** 提出了一种名为QRE-ChaCha的改进ChaCha变体。具体方法是将初始常数与量子随机数进行异或操作，并在奇数轮中周期性地将量子随机数注入到选定的状态字中以增强扩散。通过三个主要部分评估：1. 理论安全性分析（量子随机性、攻击测试），并使用基于布尔可满足性问题（SAT）的自动化搜索方法进行差分密码分析。2. 使用NIST统计测试套件和GM/T 0005-2021随机性测试标准对密钥流进行随机性测试。3. 通过测量不同大小文件上的加密速度来评估加密和解密性能。

**Result:** 与原始ChaCha相比，所提出的变体显示出更强的抗差分攻击能力，并生成具有统计随机性的密钥流，从而增强了对经典和量子攻击的鲁棒性。其密钥流成功通过了NIST和GM/T 0005-2021标准的统计随机性测试，满足密码应用要求，同时保持了原始ChaCha算法的高效率。

**Conclusion:** 本文提出的改进ChaCha算法显著增强了抵抗差分攻击的能力，同时保持了原始ChaCha的高效率，并且其密钥流通过了各项统计随机性测试，满足了密码应用的需求，提升了对经典和量子攻击的鲁棒性。

> **ai_Abstract:** 本文提出了一种基于量子随机数（QRE-ChaCha）的改进ChaCha算法，旨在应对AI辅助密码分析和量子计算对现有ChaCha算法的威胁。该方法通过将初始常数与量子随机数异或，并在奇数轮注入量子随机数来增强扩散。实验结果表明，QRE-ChaCha在保持原有高效率的同时，显著增强了对差分攻击的抵抗力，并生成了统计随机性更高的密钥流，从而提升了对经典和量子攻击的鲁棒性，并通过了NIST和GM/T 0005-2021随机性测试。

> **摘要翻译:** 由于高效率和强大的抗时序及侧信道攻击的优点，ChaCha已广泛应用于实时通信和数据流场景。然而，随着AI辅助密码分析和量子计算技术的快速发展，ChaCha密码的安全实现面临严峻挑战。为了进一步加强ChaCha密码的安全性，我们提出了一种基于量子随机数的改进变体，即量子随机数增强型ChaCha（QRE-ChaCha）。具体而言，该设计将初始常数与量子随机数进行异或操作，并在奇数轮中周期性地将量子随机数注入到选定的状态字中以增强扩散。与原始ChaCha相比，本变体对差分攻击显示出更强的抵抗力，并生成具有统计随机性的密钥流，从而增强了对经典和量子攻击的鲁棒性。为了评估本ChaCha的安全性与性能，我们的分析分三个主要部分进行。首先，我们从量子随机性和攻击测试方面分析其理论安全性，并使用基于布尔可满足性问题（SAT）的自动化搜索方法进行差分密码分析。其次，我们使用NIST统计测试套件和GM/T 0005-2021随机性测试标准对密码生成的密钥流进行随机性测试。最后，我们通过测量其对各种大小文件的加密速度来评估其加密和解密性能。根据结果，本ChaCha在抵抗差分攻击方面得到了显著改进，同时保持了原始ChaCha密码的高效率，并且其密钥流成功通过了NIST和GM/T 0005-2021标准的统计随机性测试，满足密码应用要求。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [29] [Information Security Based on LLM Approaches: A Review](https://arxiv.org/abs/2507.18215)
> *基于LLM方法的信息安全：一项综述*

*Chang Gong, Zhongwen Li, Xiaoqi Li* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 信息安全, 威胁分析, 漏洞检测, 综述

**Comment:** 

> **TL;DR:** 本文综述了大型语言模型（LLM）在信息安全领域的应用进展，涵盖恶意行为预测、威胁分析、漏洞检测等，并指出其在提高安全系统准确性方面的潜力及面临的挑战。

**AI_Comments:** 这篇综述论文及时地总结了LLM在信息安全这一重要且快速发展的领域中的应用，为研究人员提供了宝贵的参考。其创新点在于系统性地梳理了LLM在多个信息安全子领域的具体应用，并指出了其提升检测准确性和降低误报率的潜力。然而，论文也坦诚地指出了当前LLM在信息安全应用中面临的透明度、可解释性和场景适应性等关键挑战，这对于指导未来的研究方向具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 信息安全面临日益严峻的挑战，传统防护手段难以应对复杂多变的威胁，而大型语言模型（LLMs）作为新兴智能技术，在信息安全领域展现出广阔的应用前景。

**Method:** 本文系统综述了大型语言模型（LLM）在信息安全中的关键作用和应用进展，具体包括恶意行为预测、网络威胁分析、系统漏洞检测、恶意代码识别和密码算法优化。同时，论文还分析了LLM基于神经网络和Transformer架构的技术基础及其在自然语言处理任务中的优势。

**Result:** 研究表明，引入大型语言模型有助于提高安全系统的检测准确性并降低误报率。

**Conclusion:** 尽管LLM在信息安全领域取得了显著应用成果，但仍面临模型透明度、可解释性和场景适应性等挑战。未来需要进一步探索模型结构优化和泛化能力提升，以实现更智能、更精准的信息安全保护系统。

> **ai_Abstract:** 本文对基于大型语言模型（LLM）的信息安全方法进行了系统综述。论文探讨了LLM在恶意行为预测、网络威胁分析、系统漏洞检测、恶意代码识别和密码算法优化等方面的应用，并分析了其技术基础。研究指出，LLM有助于提升安全系统的检测准确率和降低误报率。同时，论文也指出了LLM在模型透明度、可解释性和场景适应性方面的现有挑战，并强调了未来在模型优化和泛化能力提升方面的研究方向。

> **摘要翻译:** 信息安全正面临日益严峻的挑战，传统防护手段难以应对复杂多变的威胁。近年来，作为一种新兴智能技术，大型语言模型（LLM）在信息安全领域展现出广阔的应用前景。本文重点关注LLM在信息安全中的关键作用，系统综述了其在恶意行为预测、网络威胁分析、系统漏洞检测、恶意代码识别和密码算法优化方面的应用进展，并探讨了其在增强安全防护性能方面的潜力。本文基于神经网络和Transformer架构，分析了大型语言模型的技术基础及其在自然语言处理任务中的优势。研究表明，引入大型语言模型有助于提高安全系统的检测准确性并降低误报率。最后，本文总结了当前的应用成果，并指出其在模型透明度、可解释性和场景适应性等方面仍面临挑战。有必要进一步探索模型结构优化和泛化能力提升，以实现更智能、更准确的信息安全保护系统。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [36] [Auto-SGCR: Automated Generation of Smart Grid Cyber Range Using IEC 61850 Standard Models](https://arxiv.org/abs/2507.18249)
> *Auto-SGCR：使用IEC 61850标准模型自动生成智能电网网络靶场*

*Muhammad M. Roomi, S. M. Suhail Hussain, Ee-Chien Chang, David M. Nicol, Daisuke Mashima* | **Category: cs.CR, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 智能电网, 网络靶场, 自动化生成, IEC 61850, 网络安全

**Comment:** 12 pages

> **TL;DR:** 本文提出了一个名为Auto-SGCR的自动化框架，用于使用IEC 61850标准模型生成智能电网网络靶场，旨在解决现有靶场设计和维护的挑战。

**AI_Comments:** 该论文提出了一种创新的方法，通过自动化和标准化（基于IEC 61850）来解决智能电网网络靶场部署的痛点。其贡献在于提高了靶场的可配置性、可移植性和可复现性，降低了部署和维护的门槛，对于促进智能电网网络安全研究和实践具有重要意义。开源其工具链也进一步提升了其影响力。

<details>
  <summary>Details</summary>

**Motivation:** 电网数字化使其易受网络攻击，需要迭代的网络安全测试和培训。现有的智能电网网络靶场设计和实现需要广泛的领域知识，成本高昂，且在可配置性、可访问性、可移植性和可复现性方面存在限制。

**Method:** 1. 定义了一种名为智能电网建模语言（SG-ML）的人机友好型XML建模语言，该语言结合了IEC 61850系统配置语言文件。2. 开发了一个工具链，用于解析SG-ML模型文件并自动实例化功能性的智能电网网络靶场。

**Result:** 成功开发了Auto-SGCR框架和工具链，能够自动生成智能电网网络靶场。SG-ML模型可以轻松共享和修改，以复现或定制任何网络靶场。通过大规模变电站模型的案例研究证明了其应用。该工具链和示例SG-ML模型已开源。

**Conclusion:** Auto-SGCR框架通过自动化生成智能电网网络靶场，解决了现有靶场在设计、成本、可配置性、可访问性、可移植性和可复现性方面的挑战，为网络安全测试和培训提供了高保真、可定制的解决方案。

> **ai_Abstract:** 本文提出了Auto-SGCR，一个用于自动生成智能电网网络靶场的框架。该框架通过定义一种结合IEC 61850标准的SG-ML建模语言和开发一个解析该语言并实例化靶场的工具链，解决了现有靶场设计复杂、成本高、可配置性差等问题。Auto-SGCR实现了高保真、可定制、可复现的网络靶场，并通过案例研究进行了验证，并已开源。

> **摘要翻译:** 在过去十年中，电网的数字化使其越来越容易受到网络攻击。迭代的网络安全测试对于应对新兴的攻击向量和确保关键基础设施的可靠性不可或缺。此外，这些测试可用于评估网络安全配置、网络安全措施对抗各种攻击向量的有效性，以及培训防御系统的智能电网网络安全专家。实现广泛的实验缩小了学术研究与生产环境之间的差距。高保真网络靶场至关重要，因为在生产环境中使用此类实验和培训通常是不可行的。然而，网络靶场的设计和实现需要基础设施物理和网络方面的广泛领域知识。此外，设置和维护网络靶场产生的成本巨大。而且，大多数现有的智能电网网络靶场都是作为一次性、专有系统设计的，在可配置性、可访问性、可移植性和可复现性方面受到限制。为了应对这些挑战，本文提出了一种自动化智能电网网络靶场生成框架。首先，定义了一种名为智能电网建模语言（SG-ML）的人机友好型XML建模语言，该语言包含了IEC 61850系统配置语言文件。随后，开发了一个工具链来解析SG-ML模型文件并自动实例化一个功能性的智能电网网络靶场。开发的SG-ML模型可以轻松共享和/或修改，以复现或定制任何网络靶场。通过大规模变电站模型的案例研究展示了Auto-SGCR的应用。该工具链和示例SG-ML模型已开源。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [43] [LoRA-Leak: Membership Inference Attacks Against LoRA Fine-tuned Language Models](https://arxiv.org/abs/2507.18302)
> *LoRA-Leak：针对LoRA微调语言模型的成员推断攻击*

*Delong Ran, Xinlei He, Tianshuo Cong, Anyu Wang, Qi Li, Xiaoyun Wang* | **Category: cs.CR, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** LoRA, 成员推断攻击, 语言模型, 数据隐私, LoRA-Leak

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 尽管LoRA微调轻量高效，但本研究发现LoRA微调的语言模型仍然容易受到成员推断攻击，尤其是在利用预训练模型信息的情况下。我们提出了LoRA-Leak框架，并发现只有dropout和排除特定LM层能有效缓解风险。

**AI_Comments:** 该研究创新性地指出预训练模型在LoRA微调背景下对成员推断攻击的影响，填补了现有MIA研究的空白。LoRA-Leak框架的提出为评估LoRA模型的隐私风险提供了全面的工具。研究不仅揭示了LoRA模型的脆弱性，还探索了有效的防御措施，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型普遍采用“预训练和微调”范式，其中LoRA因其计算成本低和性能卓越而广受欢迎。由于LoRA微调的参数比例相对较小，可能存在一种误解，认为LoRA微调数据对成员推断攻击（MIAs）是安全的。然而，现有MIAs忽视了利用预训练模型可能导致更多信息泄露的问题。

**Method:** 研究引入了LoRA-Leak，一个针对语言模型微调数据集MIAs的全面评估框架。LoRA-Leak包含了十五种成员推断攻击，其中包括十种现有MIAs和五种利用预训练模型作为参考的改进型MIAs。研究还在不同微调设置下应用LoRA-Leak以理解隐私风险，并探索了四种防御措施。

**Result:** 实验结果表明，LoRA微调的语言模型仍然容易受到MIAs的攻击（例如，在保守微调设置下AUC为0.775）。在探索的四种防御措施中，只有dropout和在微调期间排除特定的LM层能有效缓解MIA风险，同时保持模型效用。

**Conclusion:** 在“预训练和微调”范式下，预训练模型的存在使得MIA对LoRA语言模型构成更严重的风险。本研究的发现旨在为专业语言模型提供商提供数据隐私保护指导。

> **ai_Abstract:** 本研究提出LoRA-Leak，一个针对LoRA微调语言模型成员推断攻击的全面评估框架。尽管LoRA微调参数量小，但LoRA-Leak通过整合现有及改进的MIAs，揭示了LoRA微调模型在利用预训练模型信息时仍易受成员推断攻击。实验证明了LoRA模型的脆弱性，并指出dropout和排除特定LM层是有效的防御手段。研究强调预训练模型加剧了LoRA模型的隐私风险，为数据隐私保护提供指导。

> **摘要翻译:** 语言模型（LMs）通常遵循“预训练和微调”范式，其中通用的预训练模型可以被微调以适应各种专业领域。低秩适应（LoRA）因其轻量级的计算成本和卓越的性能，在LM微调中获得了最广泛的应用。由于LoRA微调的参数比例相对较小，可能会产生一种误导性的印象，即LoRA微调数据不会受到成员推断攻击（MIAs）的侵害。然而，我们发现利用预训练模型可以导致更多的信息泄露，这被现有MIAs所忽视。因此，我们引入了LoRA-Leak，一个针对LM微调数据集MIAs的全面评估框架。LoRA-Leak包含了十五种成员推断攻击，其中包括十种现有MIAs和五种利用预训练模型作为参考的改进型MIAs。在实验中，我们将LoRA-Leak应用于三种先进的LMs，跨越三种流行的自然语言处理任务，结果表明基于LoRA的微调LMs仍然容易受到MIAs的攻击（例如，在保守微调设置下AUC为0.775）。我们还将LoRA-Leak应用于不同的微调设置，以理解由此产生的隐私风险。我们进一步探索了四种防御措施，发现只有dropout和在微调期间排除特定的LM层能有效缓解MIA风险，同时保持效用。我们强调，在“预训练和微调”范式下，预训练模型的存在使得MIA对基于LoRA的LMs构成更严重的风险。我们希望我们的发现能为专业LM提供商提供数据隐私保护指导。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [50] [Conformidade com os Requisitos Legais de Privacidade de Dados: Um Estudo sobre Técnicas de Anonimização](https://arxiv.org/abs/2507.18360)
> *符合数据隐私法律要求：一项关于匿名化技术的研究*

*André Menolli, Luiz Fernando Nunes, Thiago A. Coleti* | **Category: cs.CR** | **Updated: 2025-07-24**

**Keywords:** 数据匿名化, 隐私保护, LGPD, GDPR, 数据效用

**Comment:** in Portuguese language

> **TL;DR:** 本文分析了巴西LGPD和欧盟GDPR背景下数据匿名化技术，并评估了聚合、泛化、扰动和k-匿名等技术在平衡隐私和数据实用性方面的有效性。

**AI_Comments:** 本文探讨了当前数据隐私法规背景下的一个关键问题——数据匿名化。其重要性在于直接回应了LGPD和GDPR等法规带来的合规挑战。研究通过对比分析多种匿名化技术，揭示了实践中隐私保护与数据可用性之间固有的权衡，这对于指导实际的软件开发和数据处理具有重要意义。虽然抽象中未深入探讨具体实验细节或量化结果，但其提出的平衡视角是创新的核心。

<details>
  <summary>Details</summary>

**Motivation:** 随着巴西通用数据保护法 (LGPD) 和欧盟通用数据保护条例 (GDPR) 的实施，个人数据保护成为软件开发的核心议题。数据匿名化作为这些法规关注的主要方面之一，已成为强制性的软件质量标准。因此，本文旨在分析数据匿名化技术并评估其在确保符合法律要求以及数据效用方面的有效性。

**Method:** 研究调查了聚合、泛化、扰动和k-匿名等数据匿名化技术。这些技术被应用于包含个人和敏感数据的数据集。

**Result:** 分析揭示了每种方法在有效性方面存在显著差异，强调了平衡隐私和数据效用之间的必要性。

**Conclusion:** 为了符合数据隐私法律要求，需要仔细权衡不同匿名化技术的有效性，以在保护数据隐私的同时保持数据的实用性。

> **ai_Abstract:** 本文研究了在巴西LGPD和欧盟GDPR等数据保护法规背景下，数据匿名化技术的重要性。文章分析了聚合、泛化、扰动和k-匿名等多种匿名化技术，并评估了它们在确保数据隐私合规性与数据实用性之间的平衡。研究发现不同技术的有效性差异显著，强调了在实际应用中需要审慎选择以达到最佳平衡。

> **摘要翻译:** 个人数据保护已成为软件开发中的核心议题，尤其是在巴西通用数据保护法 (LGPD) 和欧盟通用数据保护条例 (GDPR) 实施之后。随着这些法律的强制执行，某些软件质量标准变得强制性，例如数据匿名化，这是这些法规解决的主要方面之一。本文旨在分析数据匿名化技术，并评估它们在确保符合法律要求和数据用于其预期目的的效用方面的有效性。聚合、泛化、扰动和k-匿名等技术被调查并应用于包含个人和敏感数据的数据集。分析揭示了每种方法在有效性方面存在显著差异，强调了平衡隐私和数据效用之间的必要性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [64] [Scout: Leveraging Large Language Models for Rapid Digital Evidence Discovery](https://arxiv.org/abs/2507.18478)
> *Scout：利用大型语言模型实现快速数字证据发现*

*Shariq Murtuza* | **Category: cs.CR** | **Updated: 2025-07-24**

**Keywords:** 数字取证, 大型语言模型, 证据发现, 内存取证, 多模态模型

**Comment:** 

> **TL;DR:** Scout是一个数字取证框架，它利用大型语言模型加速数字证据的初步处理和优先级排序，从而帮助调查人员快速识别相关证据。

**AI_Comments:** Scout的创新之处在于将大型语言模型（LLMs）引入数字取证领域，解决了传统方法在处理海量数字证据时效率低下和误报率高的问题。通过结合文本和多模态LLMs，Scout能够处理多种类型的数据，从文本文件到音视频，这在数字取证工具中是一个显著的进步。它的重要性在于能够显著加速证据发现过程，从而为法律调查提供更及时和准确的支持。

<details>
  <summary>Details</summary>

**Motivation:** 随着技术进步和在日常活动中的普及，数字证据在法律调查中的作用越来越重要。取证调查人员经常需要在海量数据中筛选，导致过程繁琐且耗时，并且会产生大量需要排除的误报。

**Method:** Scout是一个数字取证框架，利用大型语言模型进行初步证据处理和优先级排序。它部署基础语言模型来识别大量潜在证据文件（如磁盘映像、捕获的网络数据包、内存转储等）中的相关工件。对于文本信息，Scout使用基于文本的大型语言模型；对于多媒体文件（如音频、图像、视频、办公文档等），Scout采用多模态模型进行取证分析。

**Result:** Scout能够识别并实现对调查人员具有潜在兴趣的证据文件，这些文件在传统方法下需要更长时间才能被识别。

**Conclusion:** Scout框架通过利用大型语言模型，显著提高了数字证据发现的效率和准确性，帮助调查人员更快地识别和处理关键证据，降低了误报率。

> **ai_Abstract:** Scout是一个创新的数字取证框架，旨在通过利用大型语言模型来解决当前数字证据调查中数据量庞大、处理耗时的问题。它能够对海量潜在证据文件进行初步处理和优先级排序，利用基础语言模型处理文本数据，并结合多模态模型分析多媒体内容。该框架的目的是加速相关证据的识别过程，从而提高调查效率并减少误报。

> **摘要翻译:** 最近的技术进步以及技术在日常活动中的普及，使得数字证据在越来越多的法律调查中出现的可能性大大增加。消费级硬件的性能日益强大，内存和存储容量不断扩大，处理器能力也得到增强。取证调查人员在进行调查时，通常需要筛选数千兆字节的数据，这使得过程非常繁琐。内存取证、磁盘分析等都得到了最先进工具的良好支持，这些工具通过提供字符串搜索、分析图像文件等功能，显著降低了取证调查人员所需付出的努力。在调查过程中，会识别出许多需要降低的误报。这项工作提出了Scout，一个数字取证框架，它利用大型语言模型进行初步证据处理和优先级排序。Scout部署基础语言模型，从大量潜在证据文件（磁盘映像、捕获的网络数据包、内存转储等）中识别相关工件，而这些工件在传统方法下需要更长时间才能被识别。Scout采用基于文本的大型语言模型，可以轻松处理包含文本信息的文件。对于音频、图像、视频、办公文档等多媒体文件的取证分析，Scout采用了多模态模型。Scout能够识别并实现对调查人员具有潜在兴趣的证据文件。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [78] [Layer-Aware Representation Filtering: Purifying Finetuning Data to Preserve LLM Safety Alignment](https://arxiv.org/abs/2507.18631)
> *层感知表示过滤：净化微调数据以保持大型语言模型安全对齐*

*Hao Li, Lijun Li, Zhenghao Lu, Xianyi Wei, Rui Li, Jing Shao, Lei Sha* | **Category: cs.CR** | **Updated: 2025-07-25**

**Keywords:** 大型语言模型安全, 微调, 数据净化, 层感知, 表示过滤

**Comment:** 

> **TL;DR:** 微调数据中隐藏的有害样本会损害大型语言模型的安全对齐。本研究提出LARF方法，通过识别模型中对安全敏感的层来过滤这些样本，有效减轻了微调造成的安全退化。

**AI_Comments:** 该论文的创新点在于提出了“层感知表示过滤”这一新颖方法，解决了大型语言模型微调过程中一个隐蔽但关键的问题：即看似无害的数据却可能损害模型的安全对齐。通过深入到模型内部（层级表示）来识别有害数据，而不是仅仅依赖表面特征，这为确保LLM的安全性提供了新的视角和有效工具，对于LLM的实际部署和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管看似良性的下游数据集，对齐的大型语言模型在微调后其安全性仍可能受损，使其更容易受到恶意指令的攻击。这是因为微调数据集中常包含表面上难以识别但会显著降低安全性的特征样本。

**Method:** 本研究提出了一种名为LARF（Layer-Aware Representation Filtering）的层感知表示过滤方法。该方法通过识别大型语言模型中对安全敏感的层，并利用这些层的表示来检测微调数据集中包含安全退化特征的数据样本。

**Result:** 实验结果表明，LARF能有效识别含有安全退化特征的良性数据。移除这些数据后，微调引起的安全性对齐退化得到缓解。

**Conclusion:** LARF方法能够有效识别并过滤微调数据中隐藏的安全退化样本，从而减轻大型语言模型在微调过程中出现的安全对齐退化，有助于保持大型语言模型的安全性。

> **ai_Abstract:** 本文关注大型语言模型（LLMs）微调过程中安全性下降的问题，指出即使是看似良性的数据集也可能包含隐藏的安全降级特征。为解决此问题，作者提出了LARF（层感知表示过滤）方法。LARF通过识别LLM中对安全敏感的层，并利用这些层的表示来检测并过滤带有安全降级特征的数据样本。实验证明，LARF能有效识别并移除此类数据，从而减轻微调对LLM安全对齐造成的负面影响。

> **摘要翻译:** 随着大型语言模型（LLMs）的快速发展和日益普及，微调对齐模型已成为使其适应实际应用的关键一步，这使得微调过程的安全性比以往任何时候都更加重要。然而，最近的研究强调了一个关键挑战：即使使用看似良性的下游数据集进行微调，对齐的LLMs的安全性也可能受到损害，使其更容易受到恶意指令的影响。
在本文中，我们展示了微调数据集通常包含具有安全降级特征的样本，这些特征在表面上不容易识别。这些样本在微调过程中会显著降低LLMs的安全对齐。为了解决这个问题，我们提出了LARF，一种层感知表示过滤方法。该方法识别LLM中对安全敏感的层，并利用它们的表示来检测训练后数据集中哪些数据样本包含安全降级特征。
实验结果表明，LARF可以有效地识别具有安全降级特征的良性数据。移除这些数据后，微调引起的安全性对齐降级得到缓解。请访问我们的代码：https://github.com/LLLeoLi/LARF。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [117] [On the Security of a Code-Based PIR Scheme](https://arxiv.org/abs/2507.19295)
> *基于代码的PIR方案的安全性研究*

*Svenja Lage, Hannes Bartz* | **Category: cs.CR, cs.IR** | **Updated: 2025-07-25**

**Keywords:** 私有信息检索, 基于代码的密码学, 后量子安全, 安全分析, 漏洞

**Comment:** 

> **TL;DR:** 一个基于代码的PIR方案（CB-cPIR）存在严重安全漏洞，且通信成本优势不明显，但基于代码的PIR仍有潜力。

**AI_Comments:** 本文通过审查一种新型密码原语（基于代码的PIR）的安全性，做出了重要贡献，这对于后量子密码学的发展至关重要。及早发现漏洞有助于完善和加强未来的设计，即使所分析的具体方案存在缺陷。其重要性在于指导基于代码的PIR的未来研究方向。

<details>
  <summary>Details</summary>

**Motivation:** CB-cPIR是基于编码理论的PIR方案的开创性尝试，旨在实现后量子安全并多样化安全基础。本文的动机是评估其安全性。

**Method:** 通过研究揭示了CB-cPIR方案的关键漏洞，并与现有最先进的PIR方案进行了比较分析。

**Result:** CB-cPIR方案存在一个关键漏洞，严重降低了其安全级别。此外，与最先进的PIR方案相比，CB-cPIR的优势减弱，在通信成本方面竞争力不足。

**Conclusion:** 尽管CB-cPIR方案存在漏洞，但基于代码的PIR方案仍有潜力作为基于格的PIR方案的有价值替代方案，因此需要继续研究。

> **ai_Abstract:** 本文评估了开创性的基于代码的私有信息检索（PIR）方案CB-cPIR的安全性。研究发现该方案存在一个严重漏洞，大大降低了其安全级别，并且与现有先进方案相比，其通信成本优势减弱。尽管如此，研究强调基于代码的PIR方案仍有潜力作为基于格的PIR方案的替代方案，值得继续研究。

> **摘要翻译:** 私有信息检索（PIR）方案允许客户端从数据库检索文件，而无需向服务器透露所请求文件的身份。在追求后量子安全方面，大多数最近的PIR方案都依赖于困难的格问题。相比之下，所谓的CB-cPIR方案作为一项开创性的努力脱颖而出，它将PIR方案建立在编码理论中的困难问题之上，从而为安全基础的多样化做出了重大贡献。然而，我们的研究揭示了CB-cPIR中的一个关键漏洞，大大降低了其安全级别。此外，与最先进的PIR方案的比较分析表明，CB-cPIR的优势有所减弱，使其在通信成本方面竞争力下降。尽管如此，我们的发现强调了继续研究基于代码的PIR方案的重要性，因为它们有潜力为基于格的方法提供有价值的替代方案。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [218] [PPFPL: Cross-silo Privacy-preserving Federated Prototype Learning Against Data Poisoning Attacks on Non-IID Data](https://arxiv.org/abs/2504.03173)
> *PPFPL：针对非独立同分布数据中毒攻击的跨筒仓隐私保护联邦原型学习*

*Hongliang Zhang, Jiguo Yu, Fenghua Xu, Chunqiang Hu, Yongzhao Zhang, Xiaofen Wang, Zhongyuan Yu, Xiaosong Zhang* | **Category: cs.CR, cs.DC** | **Updated: 2025-07-24**

**Keywords:** 隐私保护联邦学习, 数据中毒攻击, 非独立同分布数据, 原型学习, 安全聚合

**Comment:** 

> **TL;DR:** PPFPL是一种隐私保护联邦原型学习框架，通过使用原型作为更新和双服务器安全聚合，有效抵抗非独立同分布数据中毒攻击并提高性能。

**AI_Comments:** 该论文的创新点在于引入原型作为模型更新，以更有效地处理非独立同分布数据和抵抗中毒攻击，并结合双服务器安全聚合来增强鲁棒性。这为解决联邦学习在现实世界中面临的挑战（如数据异构性和恶意攻击）提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的隐私保护联邦学习（PPFL）解决方案在中毒的非独立同分布（Non-IID）数据上，难以有效提升跨筒仓PPFL的性能，且易受数据中毒攻击影响。

**Method:** 本文提出PPFPL框架，通过采用原型作为客户端提交的模型更新，以消除篡改数据分布对联邦学习的影响。此外，利用两个服务器通过安全聚合协议实现拜占庭鲁棒聚合，从而大大减少恶意客户端的影响。

**Result:** 理论分析证实了PPFPL的收敛性。在公开数据集上的实验结果表明，PPFPL在非独立同分布条件下能有效抵抗数据中毒攻击。

**Conclusion:** PPFPL框架能有效提高跨筒仓联邦学习在中毒非独立同分布数据上的性能，并有效抵抗数据中毒攻击。

> **ai_Abstract:** 本文提出了PPFPL（隐私保护联邦原型学习）框架，旨在解决跨筒仓隐私保护联邦学习在非独立同分布（Non-IID）数据中毒攻击下的性能问题。PPFPL通过使用原型作为客户端更新来减轻数据篡改影响，并利用双服务器和安全聚合协议实现拜占庭鲁棒性，从而有效抵抗数据中毒攻击并提高学习性能。理论分析和实验结果均验证了其在Non-IID条件下的收敛性和有效性。

> **摘要翻译:** 隐私保护联邦学习（PPFL）允许多个客户端通过提交隐藏的模型更新来协作训练深度学习模型。然而，由于客户端分布式训练的性质，PPFL容易受到数据中毒攻击。现有解决方案在中毒的非独立同分布数据上，难以有效提升跨筒仓PPFL的性能。为了解决这些问题，本文提出了一种名为PPFPL的隐私保护联邦原型学习框架，该框架在有效抵抗数据中毒攻击的同时，提高了中毒非独立同分布数据上的跨筒仓联邦学习性能。具体来说，我们采用原型作为客户端提交的模型更新，以消除篡改数据分布对联邦学习的影响。此外，我们利用两个服务器通过安全聚合协议实现拜占庭鲁棒聚合，这大大减少了恶意客户端的影响。理论分析证实了PPFPL的收敛性，并且在公开数据集上的实验结果表明，PPFPL在非独立同分布条件下能有效抵抗数据中毒攻击。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [255] [Are AI-Generated Fixes Secure? Analyzing LLM and Agent Patches on SWE-bench](https://arxiv.org/abs/2507.02976)
> *AI 生成的修复程序安全吗？分析 SWE-bench 上的 LLM 和 Agent 补丁*

*Amirali Sajadi, Kostadin Damevski, Preetha Chatterjee* | **Category: cs.CR, cs.LG, cs.SE** | **Updated: 2025-07-24**

**Keywords:** LLM, 软件修复, 安全性, 漏洞, SWE-bench

**Comment:** 

> **TL;DR:** 本研究首次对大型语言模型（LLMs）及其代理框架生成的软件修复补丁进行了大规模安全分析，发现与人工修复相比，LLM 和代理生成的补丁引入了更多漏洞，尤其是在LLM具有更高自主权或上下文信息不足的情况下。

**AI_Comments:** 本研究首次对LLM和代理生成的软件修复补丁进行了大规模安全分析，其创新性在于使用了真实世界的SWE-bench数据集，而非合成或孤立环境。研究结果揭示了LLM在生成代码修复时的潜在安全风险，特别是独立LLM引入漏洞的频率远高于人工，并且指出上下文信息对生成代码安全性的重要性。这对于推动安全AI代码生成和开发更完善的风险评估工具具有重要意义。局限性可能在于其评估的LLM模型和代理框架的数量有限。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）及其代理框架正越来越多地用于自动化软件开发任务，如问题解决和程序修复。虽然之前的研究已识别出LLM生成代码中的安全风险，但大多数评估都集中在合成或孤立设置中，对这些系统在真实世界开发环境中的安全性仍存在疑问。

**Method:** 本研究对来自 SWE-bench 数据集的 20,000 多个问题，进行了首次大规模 LLM 生成补丁的安全分析。评估了独立 LLM（Llama 3.3）生成的补丁，并与开发人员编写的补丁进行比较。此外，还在部分数据上评估了三个顶级代理框架（OpenHands, AutoCodeRover, HoneyComb）生成的补丁的安全性。最后，分析了代码、问题和项目层面的各种因素，以了解 LLM 和代理最可能生成不安全代码的条件。

**Result:** 研究发现，独立 LLM 引入的新漏洞比开发人员多近 9 倍，其中许多漏洞表现出开发人员代码中未见的独特模式。代理工作流也生成了大量漏洞，尤其是在授予 LLM 更多自主权时，这可能会增加误解项目上下文或任务要求的可能性。研究还发现，漏洞更可能出现在涉及文件数量较多、生成代码行数较多，以及缺乏特定代码片段、预期代码行为信息或重现步骤的 GitHub 问题相关的 LLM 补丁中。

**Conclusion:** 这些结果表明，上下文因素在生成代码的安全性中起着关键作用，并指出需要主动的风险评估方法，该方法应考虑代码和问题层面的信息，以补充现有的漏洞检测工具。

> **ai_Abstract:** 本研究首次对大型语言模型（LLMs）及其代理框架生成的软件修复补丁进行了大规模安全分析，使用了SWE-bench数据集的20,000多个问题。研究发现，独立LLM生成的补丁引入的漏洞比人工多近9倍，且存在独特模式。代理工作流也产生大量漏洞，尤其是在LLM自主权较高时。漏洞的产生与文件数量、代码行数以及问题上下文信息不足等因素相关。研究强调了上下文因素对生成代码安全性的关键作用，并呼吁开发结合代码和问题层面信息的主动风险评估方法。

> **摘要翻译:** 大型语言模型（LLMs）及其代理框架正越来越多地被用于自动化软件开发任务，例如问题解决和程序修复。虽然先前的研究已经识别出LLM生成代码中的安全风险，但大多数评估都集中在合成或孤立的环境中，这使得这些系统在真实世界开发环境中的安全性问题悬而未决。在本研究中，我们首次使用来自SWE-bench数据集的20,000多个问题，对LLM生成的补丁进行了大规模安全分析。我们评估了由独立LLM（Llama 3.3）生成的补丁，并将其与开发人员编写的补丁进行比较。我们还在部分数据上评估了三个表现最佳的代理框架（OpenHands、AutoCodeRover、HoneyComb）生成的补丁的安全性。最后，我们分析了广泛的代码、问题和项目层面的因素，以了解LLMs和代理最有可能生成不安全代码的条件。我们的研究结果表明，独立LLM引入的新漏洞比开发人员多近9倍，其中许多漏洞表现出开发人员代码中未发现的独特模式。代理工作流也生成了大量漏洞，尤其是在授予LLMs更多自主权时，这可能会增加误解项目上下文或任务要求的可能性。我们发现，漏洞更可能出现在与文件数量较多、生成代码行数较多以及缺乏特定代码片段或关于预期代码行为和重现步骤信息的GitHub问题相关的LLM补丁中。这些结果表明，上下文因素在生成代码的安全性中起着关键作用，并指出需要主动的风险评估方法，该方法应考虑代码和问题层面的信息，以补充现有的漏洞检测工具。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [288] [An Empirical Study on Virtual Reality Software Security Weaknesses](https://arxiv.org/abs/2507.17324)
> *虚拟现实软件安全弱点的实证研究*

*Yifan Xu, Jinfu Chen, Zhenyu Qi, Huashan Chen, Junyi Wang, Pengfei Hu, Feng Liu, Sen He* | **Category: cs.CR** | **Updated: 2025-07-24**

**Keywords:** 虚拟现实安全, 软件弱点, 实证研究, GitHub, 用户界面弱点

**Comment:** 

> **TL;DR:** 该研究对GitHub上的334个VR项目进行了实证分析，揭示了VR软件中普遍存在的安全弱点类型、引入方式、存活时间及移除方式，并构建了首个VR软件安全弱点数据集。

**AI_Comments:** 这项研究的创新之处在于构建了首个系统性的VR软件安全弱点数据集，弥补了现有公共数据库信息不足的缺陷。其结果对于VR软件开发者、安全研究人员和工具开发者具有重要指导意义，强调了在VR软件开发早期和VR开发工具选择时应更加关注安全性。研究的局限性可能在于数据来源仅限于GitHub，可能无法完全代表所有VR软件的安全状况。

<details>
  <summary>Details</summary>

**Motivation:** 虚拟现实（VR）技术正在转型各行各业，但其安全弱点（包括漏洞）尚未得到充分研究，公共数据库中VR软件安全弱点信息有限。

**Method:** 本研究调查了GitHub上334个VR项目中的1,681个软件安全弱点。由于公共数据库中VR安全弱点信息有限，研究者引入了一个新颖的框架，从GitHub提交数据中收集此类弱点，并构建了首个系统性的VR软件安全弱点数据集，然后对该数据集进行了实证研究。

**Result:** 研究发现：(i) VR弱点严重偏向用户界面弱点，其次是资源相关弱点；(ii) VR开发工具比VR应用程序带来更高的安全风险；(iii) VR安全弱点通常在VR软件诞生时引入。

**Conclusion:** 虚拟现实软件存在显著的安全弱点，尤其是在用户界面和资源方面，且开发工具的风险高于应用程序，这些弱点常在软件开发初期引入。研究强调了在VR软件开发早期阶段和VR开发工具的选择上，应更加关注安全性。

> **ai_Abstract:** 本研究对GitHub上的334个VR项目及其1,681个软件安全弱点进行了首次系统性实证分析。通过构建专门的VR安全弱点数据集，研究揭示了VR软件中普遍存在的弱点类型，发现用户界面和资源相关弱点最为突出，VR开发工具比应用程序具有更高的安全风险，且弱点常在软件初始开发阶段引入。这项工作填补了VR软件安全弱点研究的空白，为VR软件安全提供了重要见解。

> **摘要翻译:** 虚拟现实（VR）已成为各行各业的变革性技术，但其安全弱点，包括漏洞，尚未得到充分研究。本研究调查了GitHub上托管的334个VR项目，检查了1,681个软件安全弱点，以了解：VR软件中普遍存在哪些类型的弱点；弱点何时以及如何引入；它们存活了多久；以及它们是如何被移除的。由于公共数据库（例如国家漏洞数据库或NVD）中VR软件安全弱点的可用性有限，我们通过引入一个新颖的框架从GitHub提交数据中收集此类弱点，从而准备了第一个系统性的VR软件安全弱点数据集。我们对该数据集的实证研究得出了有用的见解，包括：(i) VR弱点严重偏向用户界面弱点，其次是资源相关弱点；(ii) VR开发工具比VR应用程序带来更高的安全风险；(iii) VR安全弱点通常在VR软件诞生时引入。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [292] [KGV: Integrating Large Language Models with Knowledge Graphs for Cyber Threat Intelligence Credibility Assessment](https://arxiv.org/abs/2408.08088)
> *KGV：整合大型语言模型与知识图谱用于网络威胁情报可信度评估*

*Zongzong Wu, Fengxiao Tang, Ming Zhao, Yufeng Li* | **Category: cs.CR, cs.IR** | **Updated: 2025-07-25**

**Keywords:** 网络威胁情报, 可信度评估, 大型语言模型, 知识图谱, KGV

**Comment:** 

> **TL;DR:** KGV整合LLM和知识图谱，首次实现自动化网络威胁情报可信度评估，并发布新数据集。

**AI_Comments:** 该论文的创新点在于首次将LLM与专门设计的段落级知识图谱结合，用于自动化CTI可信度评估，解决了现有方法依赖人工和效率低下的问题。其提出的段落级语义图结构新颖，有效提升了模型性能和效率。同时，公开发布CTI-200数据集对该领域的研究具有重要推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究很少关注网络威胁情报（CTI）的可信度评估，且该工作仍需网络安全专家手动分析。

**Method:** 本文提出了知识图谱验证器（KGV）框架，首次将大型语言模型（LLMs）与简单结构化知识图谱（KGs）集成，用于自动化CTI可信度评估。KGV构建段落级语义图，其中节点代表文本片段，通过相似性分析连接，旨在增强语义理解、降低KG密度并提高响应速度。此外，研究还创建并公开发布了首个CTI可信度评估数据集CTI-200。

**Result:** KGV在CTI-200数据集上优于最先进的事实推理方法，F1提高了5.7%。在事实问答和假新闻检测数据集上显示出强大的可扩展性。与等长文本的基于实体的知识图谱相比，KGV的简单结构化KG将节点数量减少了近三分之二，同时精度提高了1.7%，响应时间缩短了46.7%。

**Conclusion:** KGV通过整合大型语言模型和创新性的段落级知识图谱，显著提升了网络威胁情报可信度评估的自动化水平和性能，并为该领域提供了首个专用数据集。

> **ai_Abstract:** 本文提出了KGV框架，首次将大型语言模型与知识图谱结合，实现网络威胁情报（CTI）的自动化可信度评估。KGV采用独特的段落级语义图，而非传统的实体图，从而提升语义理解、降低图密度并加速响应。实验证明，KGV在CTI可信度评估任务上超越现有方法，并在可扩展性、精度和效率方面表现出色。此外，研究还创建并发布了首个专注于CTI可信度评估的专用数据集CTI-200。

> **摘要翻译:** 网络威胁情报（CTI）是预防复杂、有组织和武器化网络攻击的关键工具。然而，很少有研究关注CTI的可信度评估，这项工作仍然需要网络安全专家进行手动分析。在本文中，我们提出了基于知识图谱的验证器（KGV），这是第一个将大型语言模型（LLMs）与简单结构化知识图谱（KGs）集成以实现自动化CTI可信度评估的框架。与以实体为中心的知识图谱不同，KGV构建了段落级语义图，其中节点表示通过相似性分析连接的文本片段，这有效地增强了模型的语义理解能力，降低了KG密度并大大提高了响应速度。实验结果表明，我们的KGV在CTI-200数据集上优于最先进的事实推理方法，F1提高了5.7%。此外，它在事实问答和假新闻检测数据集上显示出强大的可扩展性。与等长文本的基于实体的知识图谱相比，我们结构简单的KG将节点数量减少了近三分之二，同时精度提高了1.7%，响应时间缩短了46.7%。此外，我们创建并公开发布了第一个CTI可信度评估数据集CTI-200。与CTI识别数据集不同，CTI-200改进了CTI摘要和关键句子，专门关注可信度评估。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [838] [Performance Evaluation and Threat Mitigation in Large-scale 5G Core Deployment](https://arxiv.org/abs/2507.17850)
> *大规模5G核心网部署中的性能评估与威胁缓解*

*Rodrigo Moreira, Larissa F. Rodrigues Moreira, Flávio de Oliveira Silva* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 5G核心网, DDoS, 性能评估, 威胁缓解, 网络功能

**Comment:** 

> **TL;DR:** 本论文评估了大规模5G核心网部署中DDoS攻击对用户设备注册性能的影响，并提出了多样化资源配置和基于内核的监控方法以确保SLA合规性和可扩展安全威胁防御。

**AI_Comments:** 该论文通过关注DDoS攻击对5G核心网性能的影响，填补了现有研究的空白。其创新之处在于结合了DDoS工作负载分析、多样化资源配置的必要性以及基于内核的监控在威胁防御中的应用。这对于确保大规模5G部署的稳定性和安全性具有重要意义。局限性可能在于其经验评估的范围和DDoS模型是否能完全覆盖所有现实世界的攻击场景。

<details>
  <summary>Details</summary>

**Motivation:** 大规模软件化5G核心功能部署面临巨大挑战，尤其是在优化和智能资源配置方面。现有研究多关注资源分配对复杂部署的影响，但缺乏对混沌工作负载（如DDoS攻击）在不同网络功能上对用户设备注册性能影响的深入阐明，以及如何有效进行威胁缓解和性能评估。

**Method:** 本研究通过生成由分布式拒绝服务（DDoS）引起的混沌工作负载，阐明其对不同网络功能（NFs）上用户设备注册性能的影响。此外，论文还分析了数据包捕获方法，并展示了基于内核的监控在可扩展安全威胁防御中的潜力。最后，通过经验评估提供了在复杂场景中有效部署5G网络功能的见解。

**Result:** 研究结果强调了在大型5G核心网部署中，为确保服务水平协议（SLA）合规性，必须采用多样化的资源配置文件。此外，对数据包捕获方法的分析表明，基于内核的监控对于可扩展的安全威胁防御具有潜力。

**Conclusion:** 本研究的经验评估为在复杂场景中有效部署5G网络功能提供了深入见解。

> **ai_Abstract:** 本论文探讨了大规模软件化5G核心网部署所面临的性能和安全挑战。通过模拟DDoS攻击产生的混沌工作负载，研究分析了其对用户设备注册性能的影响，并指出多样化资源配置对于确保SLA合规性的重要性。此外，论文还评估了基于内核的监控在实现可扩展安全威胁防御方面的潜力。最终，本研究通过实证评估为复杂场景下5G网络功能的有效部署提供了指导。

> **摘要翻译:** 大规模软件化5G核心功能部署由于其对优化和智能资源配置服务的依赖，带来了巨大的挑战。许多研究专注于使用数学模型、排队论甚至人工智能（AI）分析资源分配对复杂部署的影响。本文阐明了由分布式拒绝服务（DDoS）产生的混沌工作负载对不同网络功能（NFs）上用户设备注册性能的影响。我们的研究结果强调了在大型5G核心网部署中，为确保服务水平协议（SLA）合规性，必须采用多样化的资源配置文件。此外，我们对数据包捕获方法的分析表明，基于内核的监控对于可扩展的安全威胁防御具有潜力。最后，我们的经验评估为在复杂场景中有效部署5G网络功能提供了深入见解。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [845] [Learning to Locate: GNN-Powered Vulnerability Path Discovery in Open Source Code](https://arxiv.org/abs/2507.17888)
> *学习定位：GNN驱动的开源代码漏洞路径发现*

*Nima Atashin, Behrouz Tork Ladani, Mohammadreza Sharbaf* | **Category: cs.CR** | **Updated: 2025-07-23**

**Keywords:** 漏洞检测, 图神经网络, 漏洞路径, 开源代码, 可解释性AI

**Comment:** 8 pages, 5 Figures

> **TL;DR:** 本文提出VulPathFinder，一个基于GNN的漏洞路径发现框架，通过GNN检测潜在的漏洞终点（sink statements），然后利用程序切片提取并排序漏洞路径，以解释漏洞的根本原因。实验证明其性能优于现有方法。

**AI_Comments:** 本文的创新点在于使用GNN替代传统的基于规则的方法来检测漏洞终点，这显著提高了漏洞路径发现的泛化能力和解释性。通过提供漏洞的激活路径，该方法为理解和修复开源代码中的安全漏洞提供了更深入的洞察，对于提升软件安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有安全漏洞检测方法虽然能识别漏洞，但在解释漏洞根本原因（即定位漏洞语句和发现激活路径）方面仍有不足。像SliceLocator这样的框架依赖基于规则的漏洞终点识别，限制了其泛化能力。

**Method:** 本文引入VulPathFinder框架，通过使用一种新型图神经网络（GNN）模型来检测漏洞终点（sink statements），而非依赖预定义规则，从而增强了SliceLocator的方法。该GNN模型捕获语义和句法依赖以找到潜在的漏洞终点（PSPs）。检测到PSPs后，使用程序切片提取潜在的漏洞路径，然后通过将这些路径反馈到目标基于图的检测器中进行排名，最终返回最可能的路径来解释已检测漏洞的根本原因。

**Result:** 在SARD数据集的缓冲区溢出CWE基准测试上进行评估，结果表明VulPathFinder在识别到的PSPs的漏洞路径发现方面，优于原始的SliceLocator和GNNExplainer（作为通用的GNN可解释性工具）。

**Conclusion:** VulPathFinder通过利用GNN识别漏洞终点和提取可解释的漏洞路径，有效地提高了漏洞根本原因的解释能力，并在性能上超越了现有方法。

> **ai_Abstract:** 本文提出了VulPathFinder，一个可解释的漏洞路径发现框架，旨在解决现有漏洞检测方法在解释漏洞根本原因方面的不足。它通过使用一种新颖的图神经网络（GNN）模型来检测潜在的漏洞终点（PSPs），克服了传统基于规则方法的局限性。在识别PSPs后，VulPathFinder利用程序切片技术提取潜在的漏洞路径，并对其进行排序以返回最可能的路径，从而解释漏洞的根本原因。在SARD数据集上的评估表明，VulPathFinder在漏洞路径发现方面优于SliceLocator和GNNExplainer。

> **摘要翻译:** 检测开源软件中的安全漏洞是一项关键任务，在相关研究社区中备受重视。文献中已经提出了几种检测漏洞代码和识别漏洞类别的方法。然而，在通过定位漏洞语句和发现导致漏洞激活的路径来解释已检测漏洞的根本原因方面仍有工作空间。虽然像SliceLocator这样的框架通过识别漏洞路径提供解释，但它们依赖于基于规则的漏洞终点识别，这限制了它们的泛化能力。在本文中，我们引入了VulPathFinder，一个可解释的漏洞路径发现框架，它通过利用一种新颖的图神经网络（GNN）模型来检测漏洞终点，而不是依赖预定义规则，从而增强了SliceLocator的方法。所提出的GNN捕获语义和句法依赖以找到潜在的漏洞终点（PSPs），这些是漏洞路径结束的候选语句。在检测到PSPs后，可以使用程序切片来提取潜在的漏洞路径，然后通过将它们反馈到目标基于图的检测器中进行排名。最终，返回最可能的路径，解释已检测漏洞的根本原因。我们通过在SARD数据集的缓冲区溢出CWE基准上进行评估，证明了所提出方法的有效性，为相应的已检测漏洞提供了解释。结果表明，VulPathFinder在发现到已识别PSPs的漏洞路径方面，优于原始的SliceLocator和GNNExplainer（作为通用的GNN可解释性工具）。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [852] [Formal Verification of the Safegcd Implementation](https://arxiv.org/abs/2507.17956)
> *形式化验证Safegcd实现*

*Russell O'Connor, Andrew Poelstra* | **Category: cs.CR, cs.LO** | **Updated: 2025-07-23**

**Keywords:** 形式化验证, 模逆, libsecp256k1, Coq, 分离逻辑

**Comment:** 15 pages; Coq sources can be found at
  https://github.com/BlockstreamResearch/simplicity/tree/c1dddedd553b403da877377e658f17f0d2184cc4/Coq/C/secp256k1
  ; Alectryon preview can be viewed at e.g.
  https://html-preview.github.io/?url=https://github.com/BlockstreamResearch/simplicity/blob/c1dddedd553b403da877377e658f17f0d2184cc4/alectryon/verif_modinv64_impl.v.html

> **TL;DR:** 针对比特币libsecp256k1库中新的模逆算法，本研究使用Coq证明助手和分离逻辑完成了计算机验证的正确性证明，以降低错误风险。

**AI_Comments:** 这项工作的重要性在于它对一个关键的加密库（libsecp256k1，比特币中使用）中的核心算法进行了形式化验证。考虑到数字签名在加密货币中的重要性，这种严格的验证大大增强了其安全性和可靠性。使用Coq和分离逻辑体现了对高保证度软件的追求，尤其是在安全敏感领域。

<details>
  <summary>Details</summary>

**Motivation:** 新颖的算法（如Bernstein和Yang开发的扩展欧几里得算法）引入了新的错误风险，需要对其正确性进行验证。

**Method:** 使用Coq证明助手，结合Verifiable C的分离逻辑实现，对libsecp256k1库中一个模逆实现的正确性进行了计算机验证证明。

**Result:** 成功完成了libsecp256k1库中一个模逆实现的计算机验证正确性证明。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对比特币libsecp256k1加密库中新引入的模逆算法（基于Bernstein和Yang开发的扩展欧几里得算法），旨在解决新算法可能引入的错误风险。研究人员利用Coq证明助手和Verifiable C的分离逻辑，成功完成了对该模逆实现进行计算机验证的正确性证明。

> **摘要翻译:** 模逆是比特币和其他应用中数字签名所使用的椭圆曲线操作所需的重要计算部分。Bernstein和Yang在过去几年中开发了一种新颖的扩展欧几里得算法方法，并将其整合到比特币使用的libsecp256k1加密库中。然而，新颖的算法会引入新的错误风险。为了解决这个问题，我们使用Coq证明助手和Verifiable C的分离逻辑实现，完成了libsecp256k1库中（其中一个）模逆实现的计算机验证正确性证明。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [859] [TimelyHLS: LLM-Based Timing-Aware and Architecture-Specific FPGA HLS Optimization](https://arxiv.org/abs/2507.17962)
> *TimelyHLS：基于LLM的面向时序和架构的FPGA HLS优化*

*Nowfel Mashnoor, Mohammad Akyash, Hadi Kamali, Kimia Azar* | **Category: cs.CR** | **Updated: 2025-07-23**

**Keywords:** FPGA HLS, 大型语言模型, 时序收敛, 优化, 检索增强生成

**Comment:** 

> **TL;DR:** TimelyHLS利用LLM和RAG自动化FPGA高层次综合（HLS）优化，显著减少手动调优并提升性能和面积效率。

**AI_Comments:** 这篇论文提出了一种创新方法，将大型语言模型（LLM）和检索增强生成（RAG）应用于传统上具有挑战性的FPGA高层次综合（HLS）优化领域。利用综合日志进行迭代优化是其一个亮点，使其能够实际应用。在不同架构上显著减少手动调优、提升延迟和节省面积的成果，突显了其实用价值和自动化复杂FPGA设计流程的潜力。这为AI驱动的硬件设计自动化指明了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 在面向FPGA的高层次综合（HLS）中，实现时序收敛和设计特定优化仍然是一个重大挑战，这归因于架构约束、资源利用率之间的复杂交互以及缺乏对平台特定编译指示的自动化支持。

**Method:** 该文提出了TimelyHLS框架，它结合了大型语言模型（LLM）和检索增强生成（RAG），以自动生成和迭代优化HLS代码，满足FPGA特定的时序和性能要求。TimelyHLS由一个包含FPGA特定特性、综合指令和编译指示模板的结构化架构知识库驱动。给定一个内核，TimelyHLS生成带有关键时序和设计特定编译指示的HLS代码。综合后的RTL通过商业工具链进行评估，并通过定制测试平台验证仿真正确性。TimelyHLS还迭代地将综合日志和性能报告整合到LLM引擎中进行功能差异时的优化。

**Result:** 在10种FPGA架构和各种基准测试上的实验结果表明，TimelyHLS将手动调优的需求减少了高达70%，同时实现了高达4倍的延迟加速（例如，矩阵乘法加速3.85倍，比特排序加速3.7倍），并且在某些情况下节省了超过50%的面积（例如，维特比算法的FF减少了57%）。TimelyHLS在不同平台上始终实现时序收敛和功能正确性。

**Conclusion:** TimelyHLS在不同平台上始终实现时序收敛和功能正确性，突显了LLM驱动的架构感知综合在自动化FPGA设计中的有效性。

> **ai_Abstract:** TimelyHLS通过整合大型语言模型（LLM）和检索增强生成（RAG），解决了FPGA高层次综合（HLS）中时序收敛和设计特定优化面临的挑战。该框架利用结构化架构知识库自动生成并迭代优化带有FPGA特定编译指示的HLS代码。通过结合综合日志进行迭代优化，TimelyHLS显著减少了高达70%的手动调优需求，实现了高达4倍的延迟加速和超过50%的面积节省，并确保了在不同FPGA平台上的时序收敛和功能正确性。

> **摘要翻译:** 在面向FPGA的高层次综合（HLS）中，实现时序收敛和设计特定优化仍然是一个重大挑战，这归因于架构约束、资源利用率之间的复杂交互以及缺乏对平台特定编译指示的自动化支持。在这项工作中，我们提出了TimelyHLS，一个将大型语言模型（LLM）与检索增强生成（RAG）相结合的新颖框架，旨在自动生成和迭代优化HLS代码，以满足FPGA特定的时序和性能要求。TimelyHLS由一个结构化的架构知识库驱动，该知识库包含FPGA特定功能、综合指令和编译指示模板。给定一个内核，TimelyHLS生成带有关键时序和设计特定编译指示的HLS代码。然后使用商业工具链评估综合后的RTL，并通过定制测试平台根据参考输出验证仿真正确性。TimelyHLS在存在功能差异时，将综合日志和性能报告迭代地整合到LLM引擎中进行优化。在10种FPGA架构和各种基准测试上的实验结果表明，TimelyHLS将手动调优的需求减少了高达70%，同时实现了高达4倍的延迟加速（例如，矩阵乘法加速3.85倍，比特排序加速3.7倍），并且在某些情况下节省了超过50%的面积（例如，维特比算法的FF减少了57%）。TimelyHLS在不同平台上始终实现时序收敛和功能正确性，突显了LLM驱动的架构感知综合在自动化FPGA设计中的有效性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [865] [MeAJOR Corpus: A Multi-Source Dataset for Phishing Email Detection](https://arxiv.org/abs/2507.17978)
> *MeAJOR语料库：一个用于网络钓鱼邮件检测的多源数据集*

*Paulo Mendes, Eva Maia, Isabel Praça* | **Category: cs.CR, cs.AI, cs.HC, 68P20 (Primary) 68T05, 68T07, 68T10 (Secondary), K.6.5; I.2.6; I.2.7; C.2.0** | **Updated: 2025-07-23**

**Keywords:** 网络钓鱼检测, 多源数据集, 机器学习, MeAJOR语料库, 网络安全

**Comment:** 8 pages, 2 tables, WI-IAT 2025 conference

> **TL;DR:** 本文介绍了MeAJOR语料库，这是一个新的多源网络钓鱼邮件数据集，旨在解决现有资源的局限性。该数据集包含135894个样本，并经过四种分类模型评估，其中XGBoost达到了98.34%的F1分数，证明了其在网络钓鱼检测方面的有效性。

**AI_Comments:** 该论文的创新之处在于构建了一个大规模、多源的网络钓鱼邮件数据集MeAJOR，旨在解决现有数据集在质量、多样性、类别不平衡、泛化能力和可复现性方面的局限性。通过整合多种来源和丰富的工程特征，提高了机器学习模型在网络钓鱼检测中的性能和实用性，为网络安全研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 网络钓鱼邮件通过欺骗性内容和恶意负载持续对网络安全构成重大威胁。尽管机器学习模型在检测网络钓鱼威胁方面有效，但其性能很大程度上依赖于训练数据的质量和多样性。现有资源存在关键局限性。

**Method:** 本文提出了MeAJOR（Merged email Assets from Joint Open-source Repositories）语料库，这是一个新颖的多源网络钓鱼邮件数据集。它整合了135894个代表广泛网络钓鱼策略和合法邮件的样本，并包含了各种工程特征。通过使用四种分类模型（RF、XGB、MLP和CNN）在多种特征配置下进行系统实验，评估了该数据集在网络钓鱼检测研究中的效用。

**Result:** 评估结果突出了该数据集的有效性，其中XGBoost模型达到了98.34%的F1分数。

**Conclusion:** MeAJOR数据集通过整合来自多个类别的广泛特征，提供了一个可重用且一致的资源，同时解决了类别不平衡、泛化能力和可复现性等常见挑战。

> **ai_Abstract:** 本文介绍了MeAJOR语料库，一个新颖的多源网络钓鱼邮件数据集，旨在解决现有数据集在质量和多样性方面的局限。该数据集包含135894个样本，涵盖多种网络钓鱼策略和合法邮件，并具有丰富的工程特征。通过使用RF、XGB、MLP和CNN四种分类模型进行评估，结果显示该数据集在网络钓鱼检测方面表现出色，其中XGBoost达到了98.34%的F1分数。MeAJOR语料库提供了一个可重用且一致的资源，并有效解决了类别不平衡、泛化能力和可复现性等问题。

> **摘要翻译:** 网络钓鱼邮件通过利用欺骗性内容和恶意负载来利用人类的脆弱性，持续对网络安全构成重大威胁。虽然机器学习（ML）模型在检测网络钓鱼威胁方面是有效的，但其性能在很大程度上取决于训练数据的质量和多样性。本文介绍了MeAJOR（Merged email Assets from Joint Open-source Repositories）语料库，这是一个新颖的、多源的网络钓鱼邮件数据集，旨在克服现有资源中的关键局限性。它整合了135894个样本，代表了广泛的网络钓鱼策略和合法邮件，并具有广泛的工程特征。我们通过使用四种分类模型（RF、XGB、MLP和CNN）在多种特征配置下进行系统实验，评估了该数据集在网络钓鱼检测研究中的效用。结果突出了该数据集的有效性，XGB在F1分数上达到了98.34%。通过整合来自多个类别的广泛特征，我们的数据集提供了一个可重用和一致的资源，同时解决了类别不平衡、泛化能力和可复现性等常见挑战。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [871] [PurpCode: Reasoning for Safer Code Generation](https://arxiv.org/abs/2507.19060)
> *PurpCode：更安全代码生成的推理*

*Jiawei Liu, Nirav Diwan, Zhe Wang, Haoyu Zhai, Xiaona Zhou, Kiet A. Nguyen, Tianjiao Yu, Muntasir Wahed, Yinlin Deng, Hadjer Benkraouda, Yuxiang Wei, Lingming Zhang, Ismini Lourentzou, Gang Wang* | **Category: cs.CR, cs.CL, cs.LG, cs.SE** | **Updated: 2025-07-25**

**Keywords:** 代码生成, 网络安全, 强化学习, 规则学习, PurpCode

**Comment:** 

> **TL;DR:** PurpCode是一种新的后训练方法，用于训练安全的代码推理模型，以生成安全代码并抵御恶意网络活动。它通过规则学习和强化学习两个阶段进行训练，并利用内部红队合成数据。开发的PurpCode-32B模型在网络安全方面表现出最先进的性能，同时保持了模型效用并降低了过度拒绝率。

**AI_Comments:** PurpCode的创新之处在于其两阶段的训练方法（规则学习和强化学习）以及通过内部红队演练合成全面网络安全数据。这为AI生成代码的安全性提供了一个新颖且有效的方法，对于构建更可靠、更安全的AI辅助编程工具具有重要意义。该研究不仅关注安全性，还致力于保持模型的实用性，解决了安全模型可能出现的过度拒绝问题。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是训练安全的“代码推理模型”以生成“安全代码”并“抵御恶意网络活动”。

**Method:** PurpCode是一种后训练方法，分两个阶段训练推理模型：(i) 规则学习，明确教授模型参考网络安全规则以生成无漏洞代码并避免促成恶意网络活动；(ii) 强化学习，通过多样化、多目标的奖励机制优化模型安全性并保持模型效用。为了获取全面的网络安全数据，研究团队进行了内部红队演练，基于真实世界任务合成全面且高覆盖率的提示，以诱导模型中的不安全网络活动。

**Result:** 基于PurpCode，开发了推理型编码模型PurpCode-32B，该模型展示了最先进的网络安全性能，超越了各种前沿模型。同时，该对齐方法在通用和网络安全特定场景中降低了模型的过度拒绝率，同时在代码生成和通用安全知识方面保持了模型效用。

**Conclusion:** PurpCode成功地开发了一种用于生成更安全代码的推理模型，该模型在网络安全方面表现出色，同时保持了实用性，并有效降低了模型过度拒绝率。

> **ai_Abstract:** 本文介绍了PurpCode，一种用于训练安全代码推理模型的后训练方法，旨在生成安全的、无漏洞的代码并防御恶意网络活动。该方法分两个阶段：规则学习和强化学习，并通过内部红队演练合成数据以确保全面的网络安全覆盖。基于此方法开发的PurpCode-32B模型在网络安全方面表现出最先进的性能，并有效降低了模型过度拒绝率，同时保持了代码生成和安全知识方面的实用性。

> **摘要翻译:** 我们引入了PurpCode，这是第一个用于训练安全代码推理模型的后训练方法，旨在生成安全代码并抵御恶意网络活动。PurpCode分两个阶段训练推理模型：(i) 规则学习，明确教授模型参考网络安全规则以生成无漏洞代码并避免促成恶意网络活动；(ii) 强化学习，通过多样化、多目标的奖励机制优化模型安全性并保持模型效用。为了向训练管道提供全面的网络安全数据，我们进行了内部红队演练，基于真实世界任务合成全面且高覆盖率的提示，以诱导模型中的不安全网络活动。基于PurpCode，我们开发了一个基于推理的编码模型，即PurpCode-32B，它展示了最先进的网络安全性能，超越了各种前沿模型。同时，我们的对齐方法在通用和网络安全特定场景中降低了模型的过度拒绝率，同时在代码生成和通用安全知识方面保持了模型效用。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [875] [Removing Box-Free Watermarks for Image-to-Image Models via Query-Based Reverse Engineering](https://arxiv.org/abs/2507.18034)
> *通过基于查询的逆向工程去除图像到图像模型的无盒水印*

*Haonan An, Guang Hua, Hangcheng Cao, Zhengru Fang, Guowen Xu, Susanto Rahardja, Yuguang Fang* | **Category: cs.CR** | **Updated: 2025-07-24**

**Keywords:** 无盒水印, 逆向工程, 图像到图像模型, 水印去除, 深度生成网络

**Comment:** 

> **TL;DR:** 无盒水印系统存在漏洞，可以通过查询式逆向工程去除水印并泄露原始图像。

**AI_Comments:** 本文的创新点在于揭示了看似安全的无盒水印系统中的一个根本性漏洞，并通过两种新颖的基于查询的逆向工程方法成功实现了水印去除和原始图像泄露。其重要性在于，它对当前依赖此类水印技术保护AI模型知识产权的方法提出了严峻挑战，并强调了开发更鲁棒防御机制的紧迫性。

<details>
  <summary>Details</summary>

**Motivation:** 深度生成网络（GNets）的知识产权通过级联隐藏网络（HNet）将水印嵌入到GNet输出中进行保护，即无盒水印。尽管GNet和HNet被封装为黑盒，但本文揭示了这种系统中一个被忽视的漏洞，即隐藏的GNet输出仍可通过查询式逆向工程可靠地估计，导致生成和未标记图像的泄露。

**Method:** 本文提出了两种基于查询的逆向工程方法。首先，尝试在严格黑盒条件下逆向工程HNet的逆模型，但图像质量不佳。其次，为提高图像质量，提出利用无盒模型水印的等效加性特性，逆向工程HNet的前向代理模型。

**Result:** 两种攻击方法都实现了100%的水印去除成功率，并保持了出色的图像质量（PSNR最高达到34.69 dB），显著优于现有攻击。

**Conclusion:** 本文强调了迫切需要鲁棒的防御策略来缓解无盒模型水印中发现的漏洞。

> **ai_Abstract:** 本文揭示了无盒水印系统的一个关键漏洞，该系统旨在保护深度生成网络的知识产权。研究表明，即使在黑盒条件下，通过基于查询的逆向工程，攻击者也能可靠地估计并泄露受保护的原始图像。文章提出了两种攻击方法：首先尝试逆向工程HNet的逆模型，但图像质量不佳；随后提出利用水印的加性特性逆向工程HNet的前向代理模型，显著提高了图像质量。实验证明，这两种攻击均能以100%的成功率去除水印，并保持高图像质量，远超现有方法，强调了开发更强防御机制的紧迫性。

> **摘要翻译:** 深度生成网络（GNets）的知识产权可以通过级联隐藏网络（HNet）进行保护，该网络将水印（或标记）嵌入到GNet输出中，这被称为无盒水印。尽管GNet和HNet都被封装在一个黑盒中（称为操作网络，即ONet），并且只有HNet生成和标记的输出被发布给最终用户并被认为是安全的，但本文揭示了此类系统中一个被忽视的漏洞。具体来说，我们展示了隐藏的GNet输出仍然可以通过基于查询的逆向工程可靠地估计，从而泄露生成且未标记的图像，尽管攻击者对系统的了解有限。我们的首次尝试是在严格的黑盒条件下逆向工程HNet的逆模型，为此我们建议利用特殊设计的输入图像的查询过程。尽管有效，但此方法产生的图像质量不尽如人意。为了改进这一点，我们随后提出了一种替代方法，利用无盒模型水印的等效加性特性，并逆向工程HNet的前向代理模型，从而更好地保留图像质量。在图像处理和图像生成任务上的大量实验结果表明，这两种攻击都实现了令人印象深刻的水印去除成功率（100%），同时还保持了出色的图像质量（PSNR最高达到34.69 dB），显著优于现有攻击，这突出表明迫切需要鲁棒的防御策略来缓解无盒模型水印中发现的漏洞。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='csai'></a>
## cs.AI 

### [5] [BEARCUBS: A benchmark for computer-using web agents](https://arxiv.org/abs/2503.07919)
> *BEARCUBS：一个用于计算机使用型网络代理的基准测试*

*Yixiao Song, Katherine Thai, Chau Minh Pham, Yapei Chang, Mazin Nadaf, Mohit Iyyer* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 网络代理, 基准测试, 计算机使用, 评估, 多模态交互

**Comment:** 16 pages

> **TL;DR:** 本文介绍了BEARCUBS，一个用于评估网络代理在真实网络环境中执行复杂任务能力的基准测试，并揭示了当前代理的性能及改进方向。

**AI_Comments:** BEARCUBS通过要求与实时网络内容交互和支持多模态能力，创新性地解决了现有网络代理评估的局限性，这对于推动网络代理技术的发展至关重要。它提供了一个更真实、更具挑战性的评估框架，并明确指出了当前代理的优势和未来改进的方向。定期更新的机制也保证了其长期相关性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现代网络代理在协助人类用户执行复杂任务方面具有巨大潜力，但在真实世界环境中评估其能力面临重大挑战。之前的网络代理基准测试存在局限性，例如使用合成或模拟页面，以及可以通过基于文本的变通方法绕过某些交互。

**Method:** 本文引入了BEARCUBS，一个“小而强大”的基准测试，包含111个信息检索问题，旨在评估网络代理在网络上搜索、浏览和识别事实信息的能力。与之前的基准测试不同，BEARCUBS要求：1) 访问实时网络内容而非合成或模拟页面，以捕捉真实世界网络交互的不可预测性；2) 执行广泛的多模态交互（例如，视频理解、3D导航），这些交互无法通过基于文本的变通方法绕过。BEARCUBS中的每个问题都有一个简短、明确的答案和人类验证的浏览轨迹，以实现对代理性能和策略的透明评估。

**Result:** 一项人类研究证实BEARCUBS问题是可解决但非简单的（人类准确率为84.7%），揭示了领域知识空白和被忽视的细节是常见的失败点。研究发现ChatGPT Agent以65.8%的整体准确率显著优于其他计算机使用型代理（例如，Operator为23.4%），这表明在涉及真实计算机使用（如玩网页游戏和导航3D环境）的任务中取得了实质性进展。然而，要缩小与人类表现的差距，需要在精细控制、复杂数据过滤和执行速度等方面进行改进。

**Conclusion:** BEARCUBS基准测试能够有效评估网络代理在真实世界环境中的表现，揭示了如ChatGPT Agent等代理在复杂任务上的显著进步，同时也明确了当前代理与人类表现之间的差距以及未来研究需要改进的关键领域，如精细控制、复杂数据过滤和执行速度。

> **ai_Abstract:** 本文介绍了BEARCUBS，一个包含111个信息检索问题的新型基准测试，旨在严格评估计算机使用型网络代理。BEARCUBS的创新之处在于其要求代理与实时网络内容进行交互，并执行广泛的多模态操作，从而避免了基于文本的简单绕过。一项人类研究表明该基准测试具有挑战性但可解决。评估结果显示，ChatGPT Agent以65.8%的准确率显著优于其他代理，表明在真实计算机使用任务中取得了显著进展。然而，研究也指出，代理在精细控制、复杂数据过滤和执行速度方面仍需改进以达到人类水平。BEARCUBS将定期更新以确保其持续的有效性。

> **摘要翻译:** 现代网络代理具备计算机使用能力，允许它们通过向虚拟键盘和鼠标发送命令来与网页交互。虽然此类代理在协助人类用户完成复杂任务方面具有巨大潜力，但在真实世界环境中评估其能力构成了重大挑战。为此，我们引入了BEARCUBS，这是一个“小而强大”的基准测试，包含111个信息检索问题，旨在评估网络代理在网络上搜索、浏览和识别事实信息的能力。与之前的网络代理基准测试不同，解决BEARCUBS要求（1）访问实时网络内容而非合成或模拟页面，这捕捉了真实世界网络交互的不可预测性；以及（2）执行广泛的多模态交互（例如，视频理解、3D导航），这些交互无法通过基于文本的变通方法绕过。BEARCUBS中的每个问题都有一个对应的简短、明确的答案和人类验证的浏览轨迹，从而可以透明地评估代理性能和策略。一项人类研究证实BEARCUBS问题是可解决但非简单的（人类准确率为84.7%），揭示了领域知识空白和被忽视的细节是常见的失败点。我们发现ChatGPT Agent以65.8%的整体准确率显著优于其他计算机使用型代理（例如，Operator为23.4%），这表明在涉及真实计算机使用（如玩网页游戏和导航3D环境）的任务中取得了实质性进展。然而，要缩小与人类表现的差距，需要在精细控制、复杂数据过滤和执行速度等方面进行改进。为了促进未来的研究，BEARCUBS将定期更新，以替换无效或受污染的问题，使基准测试对未来几代网络代理保持新鲜。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [41] [OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?](https://arxiv.org/abs/2507.19132)
> *OS-MAP：计算机使用智能体在广度和深度上能走多远？*

*Xuetian Chen, Yinghao Chen, Xinfeng Yuan, Zhuo Peng, Lu Chen, Yuekeng Li, Zhoujia Zhang, Yingqian Huang, Leyan Huang, Jiaqing Liang, Tianbao Xie, Zhiyong Wu, Qiushi Sun, Biqing Qi, Bowen Zhou* | **Category: cs.AI, cs.CL, cs.CV, cs.HC** | **Updated: 2025-07-25**

**Keywords:** 计算机使用智能体, 基准, 自动化, 泛化, 评估

**Comment:** Work in progress

> **TL;DR:** 现有基准未能全面评估计算机使用智能体，因此提出了OS-MAP，一个新基准，用于评估智能体在日常计算机自动化任务中的广度和深度，结果显示SOTA智能体在高级任务上仍面临挑战。

**AI_Comments:** OS-MAP的创新之处在于其双维度评估框架（自动化水平和泛化范围），它更好地模拟了实际用户需求和任务复杂性，填补了现有基准的空白。其重要性在于为计算机使用智能体的能力评估提供了更细粒度、更全面的视角，有助于识别当前SOTA模型的局限性，并为未来研究指明方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有基准未能充分考虑计算机使用智能体任务的内部异质性、智能体能力及其与实际用户需求的对齐，这阻碍了有针对性的能力开发以及研究成果的实际部署。

**Method:** 提出了OS-MAP，一个针对日常计算机自动化任务的基准。它包含416个现实任务，涵盖15个应用，并沿两个维度组织和评估智能体：一个五级自动化分类法和基于真实用户需求层次的泛化范围，形成一个性能-泛化评估矩阵。

**Result:** 实验表明，即使是具有VLM骨干的SOTA智能体，在涉及感知、推理和协调的高级任务上仍然表现不佳。

**Conclusion:** 需要更深入地理解当前计算机使用智能体的优势和局限性，以推动该研究和部署的未来进展。

> **ai_Abstract:** 该论文介绍了OS-MAP，一个旨在解决现有基准不足的新型计算机使用智能体评估基准。OS-MAP包含416个跨15个应用的现实任务，并根据自动化水平和泛化范围进行双维度评估，以提供结构化和全面的分析。实验结果表明，即使是最先进的智能体在处理高级感知、推理和协调任务时仍面临挑战，强调了未来研究需关注智能体能力瓶颈。

> **摘要翻译:** 计算机使用智能体已展现出巨大潜力，能够提升人类生产力并跨平台实现新的应用形式。尽管近期进展已催生出可用的应用程序，但现有基准未能考虑到内部任务的异质性以及相应的智能体能力，以及它们与实际用户需求的对齐——这阻碍了有针对性的能力开发以及研究进展向实际部署的可靠过渡。为了弥补这一空白，我们提出了OS-MAP，一个用于日常计算机使用自动化的基准，它将416个现实任务在15个应用中，沿两个关键维度进行组织：一个五级自动化分类法和源自真实用户需求层次的泛化范围。为了实现对所需能力和与真实场景对齐的细粒度分析，OS-MAP沿两个维度评估智能体：一个五级分类法中的自动化水平，以及一个需求层次中的泛化范围。这种设计捕捉了所需智能体自主性和泛化能力的不同水平，形成了一个性能-泛化评估矩阵，用于结构化和全面的评估。实验表明，即使是拥有VLM骨干的SOTA智能体，在涉及感知、推理和协调的高级任务上仍然面临困难——这凸显了需要更深入理解当前优势和局限性，以推动计算机使用智能体研究和部署的未来进展。所有代码、环境、基线和数据均可在https://github.com/OS-Copilot/OS-Map 公开获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [47] [Chemical reasoning in LLMs unlocks strategy-aware synthesis planning and reaction mechanism elucidation](https://arxiv.org/abs/2503.08537)
> *大型语言模型中的化学推理开启了策略感知合成规划和反应机理阐明*

*Andres M Bran, Theo A Neukomm, Daniel P Armstrong, Zlatko Jončev, Philippe Schwaller* | **Category: cs.AI, cond-mat.mtrl-sci** | **Updated: 2025-07-23**

**Keywords:** 大型语言模型, 化学推理, 合成规划, 反应机理, 计算机辅助化学

**Comment:** 

> **TL;DR:** 本文展示了大型语言模型（LLMs）如何通过与传统搜索算法结合，实现策略感知的化学分析，尤其是在逆合成规划和反应机理阐明方面，其性能优于传统自动化工具。

**AI_Comments:** 本文的创新点在于将LLMs的语义理解和战略推理能力与传统化学搜索算法的精确性相结合，克服了传统自动化工具在捕捉专家战略思维方面的局限性。这种方法为计算机辅助化学领域带来了新的突破，尤其是在复杂合成规划和机理推断方面，有望显著提高自动化系统的智能化水平和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的自动化化学工具难以捕捉专家化学推理中的战略性思维，这限制了它们在复杂化学任务中的应用。

**Method:** 研究提出了一种将大型语言模型（LLMs）与传统搜索算法相结合的新方法。LLMs不直接操作化学结构，而是评估化学策略并引导搜索算法找到有意义的解决方案。该方法应用于策略感知逆合成规划（允许化学家以自然语言指定合成策略并使用LLM引导的蒙特卡洛树搜索）和反应机理阐明（LLMs结合化学原理指导机理搜索）。

**Result:** 该方法在多样化的化学任务中表现出强大的性能，并且更新、更大的模型展现出日益复杂的化学推理能力。

**Conclusion:** 该研究为计算机辅助化学建立了一个新范式，将LLMs的战略理解与传统化学工具的精确性相结合，为更直观、更强大的化学自动化系统开辟了可能性。

> **ai_Abstract:** 本文提出了一种结合大型语言模型（LLMs）与传统搜索算法的新型计算机辅助化学范式。该方法利用LLMs的战略评估能力来引导搜索过程，而非直接操作化学结构。研究通过策略感知逆合成规划和反应机理阐明展示了其有效性，其中LLMs能够理解并应用复杂的化学策略，从而在多样化任务中实现优异性能，为构建更智能的化学自动化系统奠定了基础。

> **摘要翻译:** 尽管自动化化学工具擅长特定任务，但它们难以捕捉专家化学推理所特有的战略思维。本文展示了大型语言模型（LLMs）可以作为强大的工具，实现化学分析。当与传统搜索算法相结合时，它们为计算机辅助合成提供了一种新的方法，这种方法与人类专家的思维方式相呼应。我们不是直接使用LLMs来操作化学结构，而是利用它们评估化学策略并引导搜索算法找到具有化学意义的解决方案的能力。我们通过两个基本挑战来展示这种范式：策略感知逆合成规划和机理阐明。在逆合成规划中，我们的系统允许化学家以自然语言指定所需的合成策略——从保护基策略到全局可行性评估——并使用传统或LLM引导的蒙特卡洛树搜索来寻找满足这些约束的路线。在机理阐明中，LLMs通过结合化学原理和系统探索来指导对合理反应机理的搜索。这种方法在各种化学任务中表现出强大的性能，其中更新、更大的模型展示出日益复杂的化学推理能力。我们的方法为计算机辅助化学建立了一个新范式，将LLMs的战略理解与传统化学工具的精确性相结合，为更直观、更强大的化学自动化系统开辟了可能性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [89] [OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problems with Reasoning LLM](https://arxiv.org/abs/2503.10009)
> *OR-LLM-Agent：利用推理大型语言模型自动化运筹学优化问题的建模与求解*

*Bowen Zhang, Pengcheng Luo* | **Category: cs.AI, math.OC** | **Updated: 2025-07-24**

**Keywords:** 运筹学, 大型语言模型, 自动化, 任务分解, BWOR数据集

**Comment:** 8 pages, 12 figures

> **TL;DR:** OR-LLM-Agent是一个基于推理LLM的AI代理，通过任务分解实现运筹学优化问题的自动化建模和求解，并在新数据集BWOR上表现优于现有先进方法。

**AI_Comments:** OR-LLM-Agent的创新之处在于其采用基于推理LLM的代理架构，并通过任务分解（建模、代码生成、调试）来解决复杂的运筹学问题，这比传统的提示工程或微调方法更具针对性。其构建新的高质量评估数据集BWOR也填补了现有基准的不足，为LLM在OR领域的评估提供了更可靠的标准。这种方法有望显著提高OR问题求解的自动化水平和效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有将大型语言模型（LLMs）应用于运筹学（OR）问题求解的方法，如提示工程或微调策略，受到非推理LLMs能力有限的根本制约。

**Method:** 提出OR-LLM-Agent，一个基于推理LLM构建的AI代理，用于自动化OR问题求解。该代理将任务分解为数学建模、代码生成和调试三个顺序阶段，每个阶段由一个专用子代理处理。同时构建了高质量数据集BWOR，用于评估LLM在OR任务上的性能，并指出现有基准（如NL4OPT、MAMO和IndustryOR）的问题。

**Result:** OR-LLM-Agent的实验结果表明，其准确率比包括GPT-o3、Gemini 2.5 Pro和ORLM在内的先进方法至少高出7%。

**Conclusion:** 任务分解对于运筹学问题求解是有效的，并且OR-LLM-Agent在自动化OR问题求解方面表现出优越性。

> **ai_Abstract:** 本文提出OR-LLM-Agent，一个基于推理LLM的AI代理，旨在自动化运筹学（OR）优化问题的建模与求解，以克服现有非推理LLM方法的局限性。OR-LLM-Agent通过将任务分解为数学建模、代码生成和调试三个子任务，并为每个任务配备专用子代理，以实现更精准的推理。研究者还构建了高质量数据集BWOR，用于更可靠地评估LLM在OR任务上的表现，并指出现有基准的不足。实验结果显示，OR-LLM-Agent的性能显著优于多种先进方法，证明了任务分解在OR问题求解中的有效性。

> **摘要翻译:** 随着人工智能（AI）的兴起，将大型语言模型（LLMs）应用于运筹学（OR）问题求解引起了越来越多的关注。大多数现有方法试图通过提示工程或对LLMs进行微调策略来改进OR问题求解。然而，这些方法从根本上受到非推理LLMs能力有限的制约。为了克服这些限制，我们提出了OR-LLM-Agent，一个基于推理LLMs构建的AI代理，用于自动化OR问题求解。该代理将任务分解为三个顺序阶段：数学建模、代码生成和调试。每个任务由一个专门的子代理处理，这使得推理更具针对性。我们还构建了BWOR，一个用于评估LLM在OR任务上性能的高质量数据集。我们的分析表明，现有基准如NL4OPT、MAMO和IndustryOR存在某些问题，使其不太适合可靠地评估LLM性能。相比之下，BWOR提供了对模型能力更一致和更具区分性的评估。实验结果表明，OR-LLM-Agent的准确率比包括GPT-o3、Gemini 2.5 Pro和ORLM在内的先进方法至少高出7%。这些结果证明了任务分解在OR问题求解中的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [101] [SuperARC: An Agnostic Test for Narrow, General, and Super Intelligence Based On the Principles of Recursive Compression and Algorithmic Probability](https://arxiv.org/abs/2503.16743)
> *SuperARC：一种基于递归压缩和算法概率原理的狭义、通用和超级智能的不可知测试*

*Alberto Hernández-Espinosa, Luan Ozelim, Felipe S. Abrahão, Hector Zenil* | **Category: cs.AI, cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** 算法概率, 柯尔莫哥洛夫复杂度, 人工通用智能, 超级智能, 大型语言模型

**Comment:** 51 pages + Technical Supplementary Information, 79 pages total

> **TL;DR:** SuperARC是一种基于算法概率的开放式测试，旨在评估前沿模型的AGI和ASI能力，避免基准污染。它通过测试合成和模型创建等基本智能特征，揭示了LLM的局限性，并证明了压缩与预测能力之间的等价关系。

**AI_Comments:** SuperARC的创新之处在于其基于算法概率和柯莫哥洛夫复杂度的测试框架，这使其能够超越传统的统计压缩方法，更深入地评估AI的合成和模型创建能力。其重要性在于提供了一种避免基准污染的严格测试方法，尤其是在评估AGI和ASI方面。这项工作对LLM的局限性提出了关键质疑，强调了它们在真正通用智能方面的不足，并为未来AI测试和发展指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前用于评估前沿模型（特别是AGI和ASI）的测试存在基准污染问题，且依赖于统计压缩方法（如GZIP或LZW），这些方法更接近香农熵而非柯尔莫哥洛夫复杂度，无法测试超越简单模式匹配的能力。因此，需要一种新的、更严格的测试方法。

**Method:** 论文引入了SuperARC，一种基于算法概率的开放式测试，以避免基准污染。该测试不依赖统计压缩方法，而是挑战AI（特别是LLM）在逆问题背景下（从观察中生成新知识）的合成和模型创建等基本智能特征。它基于模型抽象和溯因（最优贝叶斯推理）进行预测性规划，并与理论上保证通用智能的混合神经符号方法进行比较。该方法在短二进制序列的概念验证中优于LLM。

**Result:** LLM模型版本倾向于脆弱和增量式发展，其进步可能仅由训练数据的大小驱动，主要依赖于记忆。在短二进制序列的概念验证中，基于算法概率和柯尔莫哥洛夫复杂度的混合神经符号方法优于LLM。研究发现，压缩与系统的预测能力等价且成正比，即更好的预测能力意味着更好的压缩，反之亦然。这些发现强化了对LLM根本局限性的怀疑，揭示它们是为掌握人类语言感知而优化的系统。

**Conclusion:** SuperARC提供了一种评估AI通用和超级智能能力的有效方法，揭示了LLM在真正智能特性（如合成和模型创建）上的根本局限性，并强调了基于算法概率和柯尔莫哥洛夫复杂度的测试框架的重要性。压缩与预测能力的直接关系为衡量智能提供了一个坚实的基础。

> **ai_Abstract:** 本研究提出SuperARC，一种基于算法概率的开放式测试，旨在避免基准污染，评估前沿模型在人工通用智能（AGI）和超级智能（ASI）方面的能力。该测试不同于依赖统计压缩的方法，而是侧重于智能的基本特征，如逆问题中的合成和模型创建。研究发现，大型语言模型（LLM）主要通过记忆实现增量式进展，表现出局限性。与此相对，一种基于算法概率和柯尔莫哥洛夫复杂度的混合神经符号方法在概念验证中表现更优。论文证明了压缩与预测能力之间的等价关系，并指出LLM是优化于人类语言感知的系统，其智能存在根本限制。

> **摘要翻译:** 我们引入了一种基于算法概率的开放式测试，该测试可以避免在定量评估前沿模型的人工通用智能（AGI）和超级智能（ASI）主张时出现基准污染。与其他测试不同，该测试不依赖于统计压缩方法（如GZIP或LZW），这些方法更接近香农熵而非柯尔莫哥洛夫复杂度，并且无法测试超越简单模式匹配的能力。该测试挑战了人工智能，特别是大型语言模型（LLM）与基本智能特征（如逆问题背景下的合成和模型创建，即从观察中生成新知识）相关的方面。我们认为，基于模型抽象和溯因（最优贝叶斯“推理”）进行预测性“规划”的度量可以为测试智能提供一个稳健的框架，包括自然智能（人类和动物）、狭义人工智能、AGI和ASI。我们发现LLM模型版本往往是脆弱和增量的，仅通过记忆实现进展，其进步可能由训练数据的大小驱动。结果与一种混合神经符号方法进行了比较，该方法理论上保证了基于算法概率和柯尔莫哥洛夫复杂性原理的通用智能。该方法在短二进制序列的概念验证中优于LLM。我们证明压缩与系统的预测能力是等价且直接成比例的，反之亦然。也就是说，如果一个系统能更好地预测，它就能更好地压缩；如果它能更好地压缩，那么它就能更好地预测。我们的发现加强了对LLM根本局限性的怀疑，揭示它们是为感知人类语言掌握而优化的系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [108] [EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework](https://arxiv.org/abs/2504.14928)
> *EducationQ：通过多智能体对话框架评估大型语言模型的教学能力*

*Yao Shi, Rongkeng Liang, Yong Xu* | **Category: cs.AI, cs.CE, cs.CL, cs.CY, cs.HC** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 教学能力评估, 多智能体系统, 教育AI, EducationQ

**Comment:** Paper URL: https://aclanthology.org/2025.acl-long.1576/; Presentation
  Video: https://www.youtube.com/watch?v=j63ooKE50I0

> **TL;DR:** 该研究引入EducationQ，一个多智能体对话框架，用于评估大型语言模型（LLMs）的教学能力。研究发现，LLMs的教学效果不与模型规模或通用推理能力线性相关，一些小型模型表现优于大型模型，表明LLMs作为教师需要专门的优化。

**AI_Comments:** 该论文通过引入EducationQ框架，创新性地解决了评估大型语言模型教学能力这一复杂且资源密集型的问题。其核心创新在于采用多智能体对话模拟动态教学场景，这提供了一个更接近真实互动环境的评估方法。研究结果尤其重要，因为它挑战了“越大越好”的普遍认知，揭示了教学能力并非简单地与模型规模或通用推理能力线性相关，而是需要针对性的教学法优化。这对于未来教育AI的发展具有指导意义，强调了在设计和训练教育LLMs时，应更注重交互性、适应性和具体的教学策略，而不仅仅是知识召回。该研究的混合方法评估和人类专家验证也增强了其结果的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）日益被用作教育工具，但由于教师-学生互动资源密集、情境依赖且方法复杂，评估其教学能力仍然具有挑战性。

**Method:** 研究引入了EducationQ，一个多智能体对话框架，通过模拟动态教育场景来高效评估教学能力。该框架包含教学、学习和评估专用智能体。研究测试了来自OpenAI、Meta、Google、Anthropic等主要AI组织的14个LLMs，涉及13个学科的1,498个问题和10个难度级别。评估采用混合方法，结合定量指标、定性分析和专家案例研究。

**Result:** 研究发现，教学效果与模型规模或通用推理能力之间没有线性相关性；在教学情境中，一些小型开源模型甚至优于大型商业模型。这一发现揭示了当前评估侧重知识回忆而非互动教学的重大缺陷。表现最佳的模型展现出独特的教学优势，例如复杂的提问策略和自适应反馈机制。人类专家评估与自动化定性分析的有效教学行为一致性达到78%。

**Conclusion:** LLMs作为教师需要专门的优化，而不仅仅是简单的规模扩展。未来的教育AI应优先针对性地增强特定的教学效果。

> **ai_Abstract:** 本研究提出EducationQ，一个多智能体对话框架，旨在高效评估大型语言模型（LLMs）的教学能力。该框架通过模拟动态教育场景，并引入专门的教学、学习和评估智能体来克服现有评估的挑战。对14个LLMs的测试结果表明，教学效果与模型规模或通用推理能力并非线性相关，一些小型模型在教学表现上甚至超越了大型商业模型。这强调了当前评估中对交互式教学能力关注不足的问题。研究采用混合方法评估，并发现顶级模型展现出独特的教学策略。EducationQ强调LLMs作为教师需要专门优化，而非仅靠规模扩展，为未来教育AI的发展指明方向。

> **摘要翻译:** 大型语言模型（LLMs）日益被用作教育工具，但由于教师-学生互动资源密集、情境依赖且方法复杂，评估其教学能力仍然具有挑战性。我们引入EducationQ，一个多智能体对话框架，通过模拟动态教育场景来高效评估教学能力，该框架包含教学、学习和评估专用智能体。我们测试了来自OpenAI、Meta、Google、Anthropic等主要AI组织的14个LLMs，涉及13个学科的1,498个问题和10个难度级别，结果显示教学效果不与模型规模或通用推理能力线性相关——在教学情境中，一些小型开源模型甚至优于大型商业模型。这一发现揭示了当前评估侧重知识回忆而非互动教学的重大缺陷。我们的混合方法评估，结合定量指标、定性分析和专家案例研究，识别出表现最佳模型所采用的独特教学优势（例如，复杂的提问策略、自适应反馈机制）。人类专家评估显示，我们对有效教学行为的自动化定性分析与专家意见有78%的一致性，从而验证了我们的方法。EducationQ表明，LLMs作为教师需要专门的优化，而不仅仅是简单的规模扩展，这表明下一代教育AI应优先针对性地增强特定的教学效果。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [120] [Multi-Agent Guided Policy Optimization](https://arxiv.org/abs/2507.18059)
> *多智能体引导策略优化*

*Yueheng Li, Guangming Xie, Zongqing Lu* | **Category: cs.AI, cs.MA** | **Updated: 2025-07-24**

**Keywords:** 多智能体强化学习, 集中式训练-分布式执行, 策略优化, 理论保证, 去中心化学习

**Comment:** 

> **TL;DR:** 提出了一种名为MAGPO的新型多智能体强化学习框架，它通过更好地利用集中式训练并提供理论保证，解决了现有集中式训练-分布式执行（CTDE）方法在利用集中式训练不足或缺乏理论保证的问题。MAGPO在多项任务中表现优异，提供了去中心化多智能体学习的实用解决方案。

**AI_Comments:** MAGPO的创新之处在于其将集中式引导与分布式执行相结合的框架，并首次提供了在CTDE范式下实现单调策略改进的理论保证。这不仅解决了现有方法在理论基础上的不足，也通过自回归联合策略实现了可扩展的协调探索，使其在实际应用中更具优势。该工作为去中心化多智能体学习提供了一个坚实的基础和新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的集中式训练-分布式执行（CTDE）方法在合作式多智能体强化学习（MARL）中，由于部分可观测性和通信限制等实际约束，往往未能充分利用集中式训练或缺乏理论保证。

**Method:** 本文提出了多智能体引导策略优化（MAGPO）框架，通过将集中式引导与去中心化执行相结合，更好地利用集中式训练。MAGPO使用自回归联合策略进行可扩展的协调探索，并将其与去中心化策略明确对齐，以确保在部分可观测性下的可部署性。该方法提供了单调策略改进的理论保证。

**Result:** MAGPO在6个不同环境中的43项任务上进行了实证评估。结果表明，MAGPO始终优于强大的CTDE基线，并与完全集中式方法相当或超越，为去中心化多智能体学习提供了一个有原则且实用的解决方案。

**Conclusion:** MAGPO提供了一个有原则且实用的解决方案，能够有效解决去中心化多智能体学习中的挑战，并在性能上超越现有方法。

> **ai_Abstract:** 本文提出了一种名为多智能体引导策略优化（MAGPO）的新型框架，旨在解决现有集中式训练-分布式执行（CTDE）方法在多智能体强化学习（MARL）中未能充分利用集中式训练或缺乏理论保证的问题。MAGPO通过整合集中式引导与分布式执行，并利用自回归联合策略进行探索，同时确保与分布式策略对齐以实现可部署性。该方法提供了理论上的单调策略改进保证，并在多项任务中表现出优于现有CTDE基线和与完全集中式方法相当或更优的性能，为去中心化多智能体学习提供了一个有效且实用的解决方案。

> **摘要翻译:** 由于部分可观测性和有限通信等实际约束，集中式训练与分布式执行（CTDE）已成为协作多智能体强化学习（MARL）中的主导范式。然而，现有的CTDE方法往往未能充分利用集中式训练或缺乏理论保证。我们提出了多智能体引导策略优化（MAGPO），这是一种通过将集中式引导与分布式执行相结合来更好利用集中式训练的新颖框架。MAGPO使用自回归联合策略进行可扩展的、协调的探索，并明确地将其与分布式策略对齐，以确保在部分可观测性下的可部署性。我们提供了单调策略改进的理论保证，并在6个不同环境中的43项任务上对MAGPO进行了实证评估。结果表明，MAGPO始终优于强大的CTDE基线，并与完全集中式方法相当或超越，为分布式多智能体学习提供了一个有原则且实用的解决方案。我们的代码和实验数据可在 https://github.com/liyheng/MAGPO 找到。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [131] [IPCGRL: Language-Instructed Reinforcement Learning for Procedural Level Generation](https://arxiv.org/abs/2503.12358)
> *IPCGRL：用于程序化关卡生成的语言指令强化学习*

*In-Chang Baek, Sung-Hyun Kim, Seo-Young Lee, Dong-Hyeon Kim, Kyung-Joong Kim* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 强化学习, 程序化内容生成, 语言指令, 句子嵌入, 可控性

**Comment:** 9 pages, 9 figures, 3 tables, accepted to Conference on Games 2025

> **TL;DR:** IPCGRL是一种利用语言指令进行程序化内容生成的强化学习方法，显著提高了可控性和泛化能力。

**AI_Comments:** 该论文的创新点在于将自然语言指令与深度强化学习相结合，用于程序化内容生成，填补了该领域研究的空白。通过引入句子嵌入模型并进行任务特定微调，有效提升了生成模型的可控性和泛化能力，为游戏开发等领域提供了更灵活、更具表现力的内容生成工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究强调自然语言对生成模型可控性的重要性，但在深度强化学习（DRL）代理利用文本指令进行程序化内容生成方面的研究仍然有限。

**Method:** 本文提出了IPCGRL，一种基于指令的程序化内容生成方法，通过强化学习实现，并整合了句子嵌入模型。IPCGRL针对特定任务微调嵌入表示，以有效压缩游戏关卡条件。

**Result:** IPCGRL在二维关卡生成任务中，将可控性提高了21.4%，对未见指令的泛化能力提高了17.2%。此外，该方法扩展了条件输入的模态。

**Conclusion:** IPCGRL通过结合语言指令和强化学习，显著提升了程序化内容生成的可控性和泛化能力，并提供了更灵活的交互框架。

> **ai_Abstract:** 本研究提出IPCGRL，一种结合语言指令和强化学习的程序化内容生成方法。该方法通过微调任务特定的句子嵌入来压缩关卡条件，并在二维关卡生成任务中表现出色。实验结果显示，IPCGRL在可控性上提升了21.4%，在未见指令的泛化能力上提升了17.2%，并扩展了条件输入模态，增强了交互灵活性。

> **摘要翻译:** 最近的研究强调了自然语言在增强生成模型可控性方面的重要性。尽管已做出各种努力来利用自然语言进行内容生成，但关于深度强化学习（DRL）代理利用基于文本的指令进行程序化内容生成的研究仍然有限。在本文中，我们提出了IPCGRL，一种通过强化学习实现的基于指令的程序化内容生成方法，其中包含了句子嵌入模型。IPCGRL微调特定任务的嵌入表示，以有效压缩游戏关卡条件。我们在二维关卡生成任务中评估了IPCGRL，并将其性能与通用嵌入方法进行了比较。结果表明，IPCGRL在可控性方面实现了高达21.4%的改进，对未见指令的泛化能力实现了17.2%的改进。此外，所提出的方法扩展了条件输入的模态，为程序化内容生成提供了更灵活和富有表现力的交互框架。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [146] [AI Flow: Perspectives, Scenarios, and Approaches](https://arxiv.org/abs/2506.12479)
> *AI Flow：视角、场景与方法*

*Hongjun An, Wenhan Hu, Sida Huang, Siqi Huang, Ruanjun Li, Yuanzhi Liang, Jiawei Shao, Yiliang Song, Zihan Wang, Cheng Yuan, Chi Zhang, Hongyuan Zhang, Wenhao Zhuang, Xuelong Li* | **Category: cs.AI, cs.CL, cs.CV, cs.DC, eess.SP** | **Updated: 2025-07-24**

**Keywords:** AI Flow, 设备-边缘-云, 家族模型, 智能涌现, 通信系统

**Comment:** Authors are with Institute of Artificial Intelligence (TeleAI), China
  Telecom, China. Author names are listed alphabetically by surname. This work
  was conducted at TeleAI, facilitated by Dr. Jiawei Shao (e-mail:
  shaojw2@chinatelecom.cn) under the leadership of Prof. Xuelong Li. The
  corresponding author is Prof. Xuelong Li (e-mail: xuelong li@ieee.org), the
  CTO and Chief Scientist of China Telecom

> **TL;DR:** AI Flow是一个多学科框架，旨在通过整合设备-边缘-云架构、引入家族模型和利用连接与交互实现智能涌现，以解决大型AI模型资源消耗和通信带宽挑战，从而提升AI服务的普及性和效率。

**AI_Comments:** 这篇论文提出了AI Flow框架，其创新点在于将信息与通信技术（IT/CT）深度融合，以应对大型AI模型部署中的实际挑战。家族模型的概念和基于连接的智能涌现范式是其亮点，有望在资源受限和动态环境中实现高效、普适的AI服务。

<details>
  <summary>Details</summary>

**Motivation:** 大型AI模型存在巨大的资源消耗和高通信带宽需求，阻碍了普适智能的实现。

**Method:** AI Flow是一个多学科框架，整合了IT和和CT的进步。它包含三个关键点：1. 设备-边缘-云框架：整合终端设备、边缘服务器和云集群，优化可扩展性和效率，实现低延迟模型推理。2. 家族模型概念：一系列具有对齐隐藏特征的不同大小模型，实现有效协作并适应不同资源限制和动态场景。3. 基于连接和交互的智能涌现：利用通信网络增强连接，通过异构节点间AI模型的协作实现超越单一模型能力的涌现智能。

**Result:** AI Flow提供了增强的智能、及时的响应能力和无处不在的AI服务可访问性。

**Conclusion:** AI Flow为AI技术和通信系统更紧密的融合铺平了道路。

> **ai_Abstract:** 这篇论文介绍了AI Flow，一个旨在解决大型AI模型资源消耗和通信带宽挑战的多学科框架。AI Flow通过整合设备-边缘-云架构、引入具有对齐隐藏特征的家族模型，以及利用通信网络促进基于连接和交互的智能涌现，从而提升AI服务的效率、响应速度和普适性，推动AI与通信系统的深度融合。

> **摘要翻译:** 由克劳德·香农（Claude Shannon）开创的基础信息论和艾伦·图灵（Alan Turing）富有远见的机器智能框架引领，信息与通信技术（IT/CT）的融合演进创造了连接和计算的持续浪潮。这种协同效应引发了一场技术革命，目前正随着大型人工智能（AI）模型达到顶峰，这些模型正在重塑各行各业并重新定义人机协作。然而，由于大型模型巨大的资源消耗和高通信带宽需求，普适智能的实现面临着相当大的挑战。为了应对这些挑战，AI Flow被引入作为一个多学科框架，它整合了尖端的IT和CT进展，特别强调以下三个关键点。首先，设备-边缘-云框架作为基础，它整合了终端设备、边缘服务器和云集群，以优化可扩展性和效率，实现低延迟模型推理。其次，我们引入了家族模型的概念，它指一系列具有对齐隐藏特征的不同大小模型，从而实现有效的协作和适应不同资源限制及动态场景的灵活性。第三，基于连接和交互的智能涌现是AI Flow的一种新颖范式。通过利用通信网络增强连接性，异构节点之间AI模型的协作实现了超越任何单一模型能力的涌现智能。AI Flow的创新提供了增强的智能、及时的响应能力和无处不在的AI服务可访问性，为AI技术和通信系统更紧密的融合铺平了道路。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [155] [ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics](https://arxiv.org/abs/2507.17777)
> *ASP辅助的符号回归：揭示流体力学中的隐藏物理*

*Theofanis Aravanis, Grigorios Chrimatopoulos, Mohammad Ferdows, Michalis Xenos, Efstratios Em Tzirtzilakis* | **Category: cs.AI, 76A02** | **Updated: 2025-07-22**

**Keywords:** 符号回归, 流体力学, 答案集编程, 隐藏物理, 可解释性

**Comment:** This research was implemented in the framework of the Action
  "Flagship actions in interdisciplinary scientific fields with a special focus
  on the productive fabric'', which is implemented through the National
  Recovery and Resilience Fund Greece 2.0 and funded by the European
  Union--NextGenerationEU (Project ID: TAEDR-0535983)

> **TL;DR:** 本研究将符号回归（SR）应用于流体力学，以揭示可解释的数学关系，并通过结合答案集编程（ASP）来确保结果的物理合理性。

**AI_Comments:** 本研究的创新点在于将符号回归（SR）与答案集编程（ASP）相结合，形成一个混合框架。这解决了传统数据驱动方法“黑箱”的问题，并确保了模型不仅在统计上准确，而且在物理上合理，符合领域知识。这种方法对于需要高度可解释性和物理一致性的科学和工程领域具有重要意义。其局限性可能在于ASP规则的构建复杂性以及其对特定领域知识的依赖性。

<details>
  <summary>Details</summary>

**Motivation:** 传统机器学习方法常被批评为“黑箱”，而符号回归（SR）能够揭示可解释的数学关系。在流体力学中，理解潜在的流动物理与准确预测同等重要，这促使本研究应用SR来建模流体系统并揭示其物理规律。

**Method:** 本研究使用PySR库直接从数值模拟数据中推导出紧凑的符号方程，用于建模矩形通道中的三维（3D）不可压缩流动的轴向速度和压力场。此外，提出了一种创新方法，将SR与答案集编程（ASP）的知识表示框架相结合，形成混合SR/ASP框架，以确保生成的符号表达式在统计准确性之外，还符合领域特定的物理原则。

**Result:** 研究导出的紧凑符号方程不仅能近似模拟所研究流体流动中观察到的抛物线速度分布和压降，而且与文献中的解析解完美吻合。SR/ASP混合框架确保了SR生成的符号表达式既统计准确又物理合理。

**Conclusion:** 本研究强调了两项关键贡献：符号回归能够将复杂的流动行为简化为简洁、可解释的方程；知识表示方法（如ASP）有潜力提高数据驱动的SR模型的可靠性及其与领域原则的一致性。这些见解为将此类混合方法整合到高效框架中铺平了道路，尤其是在需要可解释预测和实时数据分析的领域。

> **ai_Abstract:** 本研究利用符号回归（SR）来揭示流体力学中复杂物理系统的可解释数学关系。通过PySR库从数值模拟数据中推导出适用于三维不可压缩流动的紧凑方程，这些方程与解析解吻合。更重要的是，研究提出了一种创新的SR与答案集编程（ASP）混合框架，该框架结合了SR的生成能力和ASP的声明性推理优势，确保了生成的符号表达式不仅统计准确而且物理合理，符合领域知识。这提升了数据驱动SR模型的可解释性和可靠性，为未来在需要可解释预测和实时分析的领域应用奠定了基础。

> **摘要翻译:** 与传统机器学习（ML）方法（常被批评为“黑箱”）不同，符号回归（SR）作为一种强大的工具脱颖而出，能够在复杂的物理系统中揭示可解释的数学关系，且无需对模型结构进行先验假设。本研究认识到在流体力学中，对潜在流动物理的理解与准确预测同等重要，因此将SR应用于建模矩形通道中基本的三维（3D）不可压缩流，重点关注层流条件下的（轴向）速度和压力场。通过使用PySR库，直接从数值模拟数据中推导出了紧凑的符号方程，揭示了流动动力学的关键特征。这些方程不仅近似模拟了所研究流体流动中观察到的抛物线速度分布和压降，而且与文献中的解析解完美吻合。此外，我们提出了一种创新方法，将SR与答案集编程（ASP）的知识表示框架相结合，将SR的生成能力与ASP的声明性推理优势相结合。所提出的混合SR/ASP框架确保SR生成的符号表达式不仅在统计上准确，而且在物理上合理，符合领域特定的原则。总的来说，本研究强调了两项关键贡献：SR将复杂流动行为简化为简洁、可解释方程的能力，以及知识表示方法提高数据驱动SR模型可靠性及其与领域原则一致性的潜力。对所考察的3D通道流的见解为将此类混合方法整合到高效框架中铺平了道路，[…]在这些框架中，可解释的预测和实时数据分析至关重要。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [174] [Neurodivergent Influenceability as a Contingent Solution to the AI Alignment Problem](https://arxiv.org/abs/2505.02581)
> *人工智能对齐问题的一种权变解决方案：神经多样性影响能力*

*Alberto Hernández-Espinosa, Felipe S. Abrahão, Olaf Witkowski, Hector Zenil* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** AI对齐问题, 未对齐性, 权变策略, 代理竞争, 图灵完备系统

**Comment:** 44 pages

> **TL;DR:** 本文提出AI与人类完全对齐是不可能的，应将AI未对齐视为一种策略，通过促进AI代理间的竞争来引导其符合人类利益，并通过干预测试其影响能力。

**AI_Comments:** 这篇论文提出了一个新颖且反直觉的观点，即AI未对齐并非完全是负面问题，反而可以作为解决AI对齐问题的一种策略。其创新点在于从“完全对齐不可能”的数学证明出发，转而探讨如何利用未对齐性来构建一个更鲁棒、更安全的AI生态系统。这挑战了当前AI安全领域的主流范式，为AI风险管理提供了新的思路。然而，如何具体实现和管理这种“竞争性代理生态系统”以及确保其最终导向人类利益，是未来需要深入探讨的复杂问题。

<details>
  <summary>Details</summary>

**Motivation:** 解决人工智能（AI）对齐问题带来的深远挑战，特别是随着通用人工智能（AGI）和超级智能（ASI）的进展，对AI系统控制和潜在生存风险的担忧不断升级。本文质疑完全对齐的可能性，并寻求一种新的风险缓解策略。

**Method:** 1. 提出AI与人类的完全对齐对于图灵完备系统而言在数学上是不可能的，并为此提供了证明，认为这是AGI和ASI系统固有的特性。2. 探讨将不可避免的AI未对齐作为一种权变策略，以培养一个竞争性AI代理的动态生态系统。3. 研究未对齐如何作为一种制衡机制，与最符合人类利益的代理合作，以防止单一AI系统造成破坏性主导。4. 引入基于扰动和干预分析的“意见改变攻击测试”，以研究人类和AI代理如何通过合作和竞争来改变或中和友善及不友善的AI。

**Result:** 1. 开放模型显示出更大的多样性。2. 专有模型中实施的防护措施能够成功控制部分AI代理的行为范围，但同时带来积极和消极的后果。3. 封闭系统更易于操控，并且可以被用来对抗专有AI系统。4. 人类和AI的干预具有不同的效果，这表明需要采取多种策略。

**Conclusion:** 鉴于AI与人类的完全对齐在数学上是不可能的，未对齐是必然的。本文提出将这种未对齐性作为一种策略，通过促进AI代理之间的竞争和战略干预，来引导AI系统朝向更符合人类利益的方向发展并降低风险。

> **ai_Abstract:** 本文探讨了人工智能（AI）对齐问题，提出AI与人类的完全对齐在数学上是不可能的，因此未对齐是必然的。作者提出了一种新颖的解决方案：将AI未对齐作为一种权变策略，通过鼓励AI代理之间形成竞争性的动态生态系统，从而引导AI系统更符合人类利益并降低风险。研究引入了“意见改变攻击测试”来分析人类和AI如何通过合作与竞争影响其他AI，并发现开放模型的更高多样性、专有模型防护措施的控制效果以及人类与AI干预的不同影响，最终建议采取多策略方法来管理AI风险。

> **摘要翻译:** 人工智能（AI），包括AGI和ASI，系统按照人类价值观行事的人工智能对齐问题，提出了深刻的挑战。随着从狭义AI向通用人工智能（AGI）和超级智能的进展，对控制和生存风险的担忧不断升级。在此，我们研究了接受不可避免的AI未对齐是否可以作为一种权变策略，以培养一个竞争性代理的动态生态系统，作为引导它们走向更符合人类趋势并减轻风险的可行路径。我们探讨了未对齐如何服务并应被推广为一种制衡机制，与最符合人类利益的代理合作，确保没有单一系统以破坏性方式主导。我们贡献的主要前提是，未对齐是不可避免的，因为从图灵完备系统来看，AI与人类的完全对齐在数学上是不可能的，我们也在本贡献中提供了证明，这一特性随后被AGI和ASI系统继承。我们引入了一种基于扰动和干预分析的“意见改变攻击测试”，以研究人类和代理如何通过合作和竞争改变或中和友善和不友善的AI。我们表明，开放模型更具多样性，并且专有模型中实施的大多数防护措施成功地控制了代理行为的某些范围，带来了积极和消极的后果，而封闭系统更易于操控，也可用于对抗专有AI系统。我们还表明，人类和AI干预具有不同效果，因此提出了多种策略。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [183] [I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis](https://arxiv.org/abs/2507.17874)
> *I2I-STRADA -- 通过结构化推理代理实现数据分析中的信息到洞察*

*SaiBarath Sundar, Pranav Satheesan, Udayaadithya Avadhanam* | **Category: cs.AI** | **Updated: 2025-07-23**

**Keywords:** 数据分析, 代理系统, 结构化推理, 认知工作流, 大型语言模型

**Comment:** 

> **TL;DR:** 现有数据分析代理系统缺乏结构化推理过程，I2I-STRADA提出了一种新的代理架构，通过模拟认知工作流来形式化推理过程，并在基准测试中表现优异。

**AI_Comments:** I2I-STRADA的创新之处在于其明确地将人类分析师的认知工作流融入到代理设计中，解决了现有通用LLM在数据分析中缺乏固定推理范式的问题。这对于提升数据分析代理的可靠性和可解释性具有重要意义，尤其是在需要高度一致性和准确性的实际应用中。

<details>
  <summary>Details</summary>

**Motivation:** 现有数据分析代理系统在任务管理方面有效，但常常忽视分析思维背后的结构化推理过程。通用大型语言模型（LLMs）的推理步骤不固定，而真实世界的数据分析需要一致的认知工作流。

**Method:** 引入了I2I-STRADA（通过结构化推理代理实现数据分析中的信息到洞察），一个旨在形式化数据分析推理过程的代理架构。它通过模块化子任务来建模分析如何展开，这些子任务反映了分析推理的认知步骤。

**Result:** 在DABstep和DABench基准测试上的评估表明，I2I-STRADA在规划连贯性和洞察对齐方面优于现有系统。

**Conclusion:** 结构化认知工作流在数据分析代理设计中至关重要，I2I-STRADA通过形式化推理过程显著提升了数据分析代理的性能。

> **ai_Abstract:** 本文介绍了I2I-STRADA，一个用于数据分析的代理架构，旨在通过模拟分析推理的认知步骤来形式化其结构化推理过程。针对现有代理系统忽视分析思维中结构化推理的不足，I2I-STRADA将分析分解为模块化子任务。实验结果表明，I2I-STRADA在规划连贯性和洞察对齐方面优于现有系统，强调了在数据分析代理设计中结构化认知工作流的重要性。

> **摘要翻译:** **论文题目：** I2I-STRADA -- 通过结构化推理代理实现数据分析中的信息到洞察

**论文摘要：**
近期数据分析代理系统的进展强调通过多代理框架和编排层实现洞察生成的自动化。尽管这些系统能有效管理查询翻译、数据转换和可视化等任务，但它们常常忽视分析思维背后的结构化推理过程。用于多步问题解决的推理大型语言模型（LLMs）被训练为通用问题解决器。因此，它们的推理或思考步骤不遵循特定任务的固定流程。真实世界的数据分析需要一致的认知工作流：解释模糊目标、将其与上下文知识联系起来、构建抽象计划，并根据中间结果调整执行。我们引入了I2I-STRADA（通过结构化推理代理实现数据分析中的信息到洞察），一个旨在形式化这一推理过程的代理架构。I2I-STRADA专注于通过模块化子任务来建模分析如何展开，这些子任务反映了分析推理的认知步骤。在DABstep和DABench基准测试上的评估表明，I2I-STRADA在规划连贯性和洞察对齐方面优于现有系统，突出了结构化认知工作流在数据分析代理设计中的重要性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [192] [Beamforming and Resource Allocation for Delay Minimization in RIS-Assisted OFDM Systems](https://arxiv.org/abs/2506.03586)
> *RIS辅助OFDM系统中延迟最小化的波束成形与资源分配*

*Yu Ma, Xiao Li, Chongtao Guo, Le Liang, Michail Matthaiou, Shi Jin* | **Category: cs.AI, cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** 波束成形, 资源分配, RIS, OFDM, 深度强化学习

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 本文提出一种混合深度强化学习方法，通过联合优化波束成形和资源分配，以最小化RIS辅助OFDM系统中的平均延迟。

**AI_Comments:** 该论文的创新点在于采用混合深度强化学习方法（PPO-Theta和PPO-N）来解决RIS辅助OFDM系统中复杂的波束成形和资源分配问题，尤其是在混合动作空间和高维状态空间下。通过引入多智能体策略和迁移学习，进一步提升了算法的效率和实用性，使其能够有效应对动态网络环境下的延迟最小化挑战。

<details>
  <summary>Details</summary>

**Motivation:** 为解决RIS辅助OFDM系统下行链路中数据包随机到达导致的平均延迟最小化问题，本文研究了联合波束成形和资源分配，该问题本质上是一个马尔可夫决策过程。

**Method:** 提出一种混合深度强化学习（DRL）方法：PPO-Theta优化RIS相移，PPO-N负责子载波分配，进而导出基站主动波束成形。引入多智能体策略以提高子载波分配效率，并将积压数据包和当前到达包等关键因素纳入状态空间。此外，采用迁移学习框架以提高训练效率和加速收敛。

**Result:** 仿真结果表明，所提算法显著降低了平均延迟，提高了资源分配效率，并与基线方法相比，实现了卓越的系统鲁棒性和公平性。

**Conclusion:** 本文提出的基于混合深度强化学习的联合波束成形与资源分配算法，在RIS辅助OFDM系统中有效解决了平均延迟最小化问题，并展现出优越的性能和鲁棒性。

> **ai_Abstract:** 本文针对RIS辅助OFDM系统中的平均延迟最小化问题，研究了联合波束成形和资源分配。提出了一种混合深度强化学习（DRL）方法，利用PPO-Theta优化RIS相移，PPO-N处理子载波分配，并从中推导出主动波束成形。为应对混合动作空间和状态空间维度，引入了多智能体策略和迁移学习框架。仿真结果显示，该算法在降低平均延迟、提高资源分配效率、增强系统鲁棒性和公平性方面表现出色。

> **摘要翻译:** 本文研究了下行链路可重构智能表面（RIS）辅助正交频分复用（OFDM）系统中联合波束成形和资源分配问题，以最小化平均延迟，其中每个用户的数据包随机到达基站（BS）。该序贯优化问题本质上是一个马尔可夫决策过程（MDP），因此属于强化学习的范畴。为有效处理混合动作空间并降低状态空间维度，本文提出了一种混合深度强化学习（DRL）方法。具体而言，采用近端策略优化（PPO）-Theta来优化RIS相移设计，而PPO-N负责子载波分配决策。基站的主动波束成形则从联合优化的RIS相移和子载波分配决策中导出。为进一步缓解与子载波分配相关的维度灾难，引入了多智能体策略，以更有效地优化子载波分配指标。此外，为实现更自适应的资源分配并准确捕捉网络动态，将与平均延迟密切相关的关键因素（如缓冲区中积压数据包的数量和当前数据包到达）纳入状态空间。此外，还引入了迁移学习框架，以提高训练效率和加速收敛。仿真结果表明，所提算法显著降低了平均延迟，提高了资源分配效率，并与基线方法相比，实现了卓越的系统鲁棒性和公平性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [211] [SMARTAPS: Tool-augmented LLMs for Operations Management](https://arxiv.org/abs/2507.17927)
> *SMARTAPS：用于运营管理的工具增强型大型语言模型*

*Timothy Tin Long Yu, Mahdi Mostajabdaveh, Jabo Serge Byusa, Rindra Ramamonjison, Giuseppe Carenini, Kun Mao, Zirui Zhou, Yong Zhang* | **Category: cs.AI** | **Updated: 2025-07-23**

**Keywords:** 大型语言模型, 运营管理, 先进规划系统, 工具增强, 对话系统

**Comment:** https://aaai.org/conference/aaai/aaai-25/bridge-ai-orms/

> **TL;DR:** SmartAPS是一个基于工具增强型大型语言模型的对话系统，旨在通过提供直观的自然语言聊天界面，使运营规划系统(APS)对供应链规划师更易于访问和使用，解决传统APS因定制和维护成本高昂而难以普及的问题。

**AI_Comments:** SmartAPS的创新之处在于它将大型语言模型与传统优化工具相结合，通过自然语言界面极大地降低了先进规划系统（APS）的使用门槛。这对于提高APS在实际运营管理中的普及性和效率具有重要意义，尤其是在供应链规划领域。其通过对话式交互提供复杂功能的能力，有望改变企业管理其运营计划的方式。

<details>
  <summary>Details</summary>

**Motivation:** 传统的先进规划系统（APS）虽然非常有益，但由于定制和维护顾问的持续成本，许多客户无法使用。供应链规划师表达了对更易于访问的APS的需求。

**Method:** 本文提出了SmartAPS，一个基于工具增强型大型语言模型（LLM）构建的对话系统。该系统为运营规划师提供了一个直观的自然语言聊天界面。

**Result:** SmartAPS系统允许运营规划师查询信息、执行反事实推理、接收建议以及执行情景分析，从而更好地管理其运营。

**Conclusion:** SmartAPS通过利用工具增强型大型语言模型，使先进规划系统对运营规划师更易于访问和使用，从而解决了传统APS的成本和可访问性问题。

> **ai_Abstract:** 本文介绍了SmartAPS，一个利用工具增强型大型语言模型（LLM）构建的对话系统，旨在解决传统先进规划系统（APS）因高昂的定制和维护成本而导致的普及性问题。SmartAPS为运营规划师提供了一个直观的自然语言聊天界面，使他们能够轻松地查询信息、进行反事实推理、获取建议以及执行情景分析，从而显著提高了APS的可访问性和可用性，帮助用户更好地管理运营。

> **摘要翻译:** 大型语言模型（LLM）为增强用户与现实世界应用中传统算法和工具的交互提供了引人入胜的机会。先进规划系统（APS）是一种复杂的软件，它利用优化来帮助运营规划师创建、解释和修改运营计划。虽然非常有益，但由于负责定制和维护的顾问的持续成本，许多客户无法使用APS。为了满足供应链规划师对更易于访问的APS的需求，我们推出了SmartAPS，一个基于工具增强型LLM构建的对话系统。我们的系统为运营规划师提供了一个直观的自然语言聊天界面，允许他们查询信息、执行反事实推理、接收建议以及执行情景分析，以更好地管理其运营。一个演示该系统的短视频已发布：https://youtu.be/KtIrJjlDbyw

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [222] [Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games](https://arxiv.org/abs/2506.23276)
> *被推理腐蚀：推理语言模型在公共物品博弈中成为搭便车者*

*David Guzman Piedrahita, Yongjin Yang, Mrinmaya Sachan, Giorgia Ramponi, Bernhard Schölkopf, Zhijing Jin* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 公共物品博弈, 合作行为, 推理能力, 智能体协作

**Comment:** Published at COLM 2025

> **TL;DR:** 研究发现，增强推理能力的LLM在公共物品博弈中合作表现不佳，反而成为“搭便车者”，而一些传统LLM能保持高水平合作。

**AI_Comments:** 这项研究具有重要的创新性，它挑战了直觉上认为更强的推理能力会带来更好的社会合作的假设。它揭示了当前LLM发展方向可能存在的盲点，即过度强调推理能力可能导致在特定社会情境中出现非预期行为，如“搭便车”。这对于未来LLM的对齐、鲁棒性和安全部署具有深远影响，尤其是在构建需要多智能体协作的系统时，需要重新审视如何平衡智能体的能力与社会行为。研究结果提醒我们，LLM的“智能”不应仅限于认知和推理，还需关注其社会互动和伦理表现。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）越来越多地作为自主代理部署，理解它们的合作和社会机制变得日益重要。特别是，LLMs如何平衡自身利益和集体福祉是确保对齐、鲁棒性和安全部署的关键挑战。本文旨在探究多智能体LLM系统中昂贵制裁的挑战，即智能体必须决定是否投入自身资源来激励合作或惩罚背叛。

**Method:** 本文采用行为经济学中的公共物品博弈与制度选择模型，观察不同LLM在重复互动中如何处理社会困境。通过这种方式，分析了模型间的四种不同行为模式。

**Result:** 分析揭示了模型中的四种不同行为模式：一些模型始终建立并维持高水平合作，另一些在参与和脱离之间波动，一些合作行为随时间逐渐下降，还有一些则无论结果如何都 rigid地遵循固定策略。令人惊讶的是，推理型LLM（如o1系列）在合作方面表现不佳，而一些传统LLM却能持续实现高水平合作。

**Conclusion:** 当前提升LLM的方法（侧重于增强推理能力）不一定能导向合作，这为在需要持续协作的环境中部署LLM代理提供了宝贵见解。

> **ai_Abstract:** 本研究探讨了LLMs在多智能体公共物品博弈中的合作行为，特别关注成本制裁的影响。通过改编行为经济学模型，研究团队观察到LLMs的四种行为模式。出乎意料的是，具有更强推理能力的LLM在合作中表现不佳，反而倾向于“搭便车”，而一些传统LLM能保持高水平合作。这表明，仅提升推理能力不一定能促进LLM的合作行为，为LLM在需要协作的环境中部署提供了重要启示。

> **摘要翻译:** 随着大型语言模型（LLMs）越来越多地作为自主代理部署，理解它们的合作和社会机制变得日益重要。特别是，LLMs如何平衡自身利益和集体福祉是确保对齐、鲁棒性和安全部署的关键挑战。在本文中，我们研究了多智能体LLM系统中昂贵制裁的挑战，其中一个智能体必须决定是否投入自己的资源来激励合作或惩罚背叛。为了研究这一点，我们改编了行为经济学中的公共物品博弈与制度选择模型，使我们能够观察不同的LLMs如何在重复互动中处理社会困境。我们的分析揭示了模型中的四种不同行为模式：一些始终建立并维持高水平合作，另一些在参与和脱离之间波动，一些合作行为随时间逐渐下降，还有一些则无论结果如何都 rigid地遵循固定策略。令人惊讶的是，我们发现推理型LLMs（如o1系列）在合作方面表现不佳，而一些传统LLMs却能持续实现高水平合作。这些发现表明，当前提升LLMs的方法（侧重于增强其推理能力）不一定能导向合作，这为在需要持续协作的环境中部署LLM代理提供了宝贵见解。我们的代码可在 https://github.com/davidguzmanp/SanctSim 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [225] [A Differentiated Reward Method for Reinforcement Learning based Multi-Vehicle Cooperative Decision-Making Algorithms](https://arxiv.org/abs/2502.00352)
> *强化学习中基于多车协同决策算法的差异化奖励方法*

*Ye Han, Lijun Zhang, Dejian Meng, Zhuang Zhang* | **Category: cs.AI, cs.MA, cs.RO** | **Updated: 2025-07-24**

**Keywords:** 强化学习, 差异化奖励, 多车协同决策, 稳态转换系统, 交通流

**Comment:** 10 pages, 3 figures

> **TL;DR:** 本文提出了一种基于稳态转换系统的差异化奖励方法，通过结合状态转换梯度信息来优化多车协同决策中的强化学习算法，显著加速训练收敛并提高交通效率、安全性和动作合理性。

**AI_Comments:** 这篇论文的创新点在于提出了差异化奖励方法，通过融入状态转换梯度信息来改进强化学习在多车协同决策中的表现。其重要性在于解决了现有RL方法样本效率低的问题，并提升了交通效率和安全性，为复杂交通场景下的多智能体系统提供了新的优化途径。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习在优化多车协同驾驶策略方面潜力巨大，但仍面临样本效率低等挑战。

**Method:** 本文提出了一种基于稳态转换系统的差异化奖励方法，通过分析交通流特性，将状态转换梯度信息融入奖励设计中，旨在优化多车协同决策中的动作选择和策略学习。该方法在MAPPO、MADQN和QMIX等RL算法中进行了验证。

**Result:** 差异化奖励方法显著加速了训练收敛，并在交通效率、安全性、动作合理性方面优于中心化奖励等方法。此外，该方法还表现出强大的可扩展性和环境适应性。

**Conclusion:** 提出的差异化奖励方法为复杂交通场景下的多智能体协同决策提供了一种新颖的途径，能够有效提升强化学习算法在多车协同决策中的性能。

> **ai_Abstract:** 本文针对强化学习在多车协同决策中面临的样本效率低等问题，提出了一种基于稳态转换系统的差异化奖励方法。该方法将状态转换梯度信息融入奖励设计，旨在优化动作选择和策略学习。实验结果表明，该方法能显著加速训练收敛，并在交通效率、安全性、动作合理性方面表现优异，同时具有良好的可扩展性和环境适应性，为复杂交通场景下的多智能体协同决策提供了新思路。

> **摘要翻译:** 强化学习（RL）通过状态-动作-奖励反馈循环，在优化多车协同驾驶策略方面显示出巨大潜力，但仍面临样本效率低等挑战。本文提出了一种基于稳态转换系统的差异化奖励方法，通过分析交通流特性，将状态转换梯度信息融入奖励设计中，旨在优化多车协同决策中的动作选择和策略学习。所提出的方法在不同自动驾驶汽车渗透率下的MAPPO、MADQN和QMIX等RL算法中进行了验证。结果表明，差异化奖励方法显著加速了训练收敛，并在交通效率、安全性、动作合理性方面优于中心化奖励等方法。此外，该方法还表现出强大的可扩展性和环境适应性，为复杂交通场景下的多智能体协同决策提供了一种新颖的途径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [239] [Synthesis of timeline-based planning strategies avoiding determinization](https://arxiv.org/abs/2507.17988)
> *避免确定化的时间线规划策略合成*

*Dario Della Monica, Angelo Montanari, Pietro Sala* | **Category: cs.AI** | **Updated: 2025-07-23**

**Keywords:** 时间线规划, 策略合成, 确定化, 确定性有限自动机, Allen 关系

**Comment:** arXiv admin note: text overlap with arXiv:2410.22757

> **TL;DR:** 本文识别出一种定性时间线规划的片段，其规划存在问题可以直接映射到确定性有限自动机的非空性问题，从而避免了昂贵的确定化步骤，实现了策略的直接合成。

**AI_Comments:** 本文的创新之处在于，它通过识别一个特定的规划片段，成功地避免了在规划策略合成过程中昂贵的确定化步骤。这使得从理论到实际应用的桥梁更加顺畅，为时间线规划策略的直接合成提供了一条新途径。其重要性在于提升了规划效率和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 定性时间线规划的计划存在问题已被证明是 PSPACE 完全的，通过归约到非确定性有限自动机的非空性问题来证明其 PSPACE 成员资格。然而，非确定性自动机不能直接用于合成规划策略，因为它需要一个昂贵的确定化步骤。

**Method:** 本文识别出一种定性时间线规划的片段，其计划存在问题可以直接映射到确定性有限自动机的非空性问题。此外，还识别出适合此确定性片段的 Allen 关系的最大子集。

**Result:** 成功识别了一个定性时间线规划的片段，该片段的计划存在问题可以直接映射到确定性有限自动机的非空性问题，从而允许直接合成策略。同时，也识别了符合该确定性片段的 Allen 关系的最大子集。

**Conclusion:** 通过识别出可直接映射到确定性有限自动机的定性时间线规划片段，本文成功避免了昂贵的确定化步骤，从而实现了规划策略的直接合成。

> **ai_Abstract:** 本文研究了定性时间线规划，该规划通过同步规则管理组件行为。尽管其计划存在问题是 PSPACE 完全的，但传统的非确定性自动机方法需要昂贵的确定化步骤才能合成策略。为解决此问题，本文识别了一种定性时间线规划的特定片段，其计划存在问题可以直接映射到确定性有限自动机的非空性问题，从而允许直接合成规划策略。此外，论文还确定了适用于此确定性片段的 Allen 关系的最大子集。

> **摘要翻译:** 定性时间线规划模型将领域建模为一组独立但相互作用的组件，这些组件随时间变化的行为（时间线）由一组定性时间约束（排序关系），称为同步规则，来管理。其计划存在问题已被证明是 PSPACE 完全的；特别是，通过归约到非确定性有限自动机的非空性问题，证明了 PSPACE 成员资格。然而，非确定性自动机不能直接用于合成规划策略，因为它需要一个昂贵的确定化步骤。在本文中，我们识别出一种定性时间线规划的片段，其计划存在问题可以直接映射到确定性有限自动机的非空性问题，然后可以合成策略。此外，我们识别出适合此确定性片段的 Allen 关系的最大子集。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [260] [DisMS-TS: Eliminating Redundant Multi-Scale Features for Time Series Classification](https://arxiv.org/abs/2507.04600)
> *DisMS-TS：消除时间序列分类中冗余的多尺度特征*

*Zhipeng Liu, Peibo Duan, Binwu Wang, Xuan Tang, Qi Chu, Changsheng Zhang, Yongsheng Huang, Bin Zhang* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 时间序列分类, 多尺度特征, 特征解耦, 冗余消除, DisMS-TS

**Comment:** This paper has been accepted for presentation at the ACM
  International Conference on Multimedia (ACM MM 2025)

> **TL;DR:** DisMS-TS框架通过消除多尺度时间序列中的冗余共享特征，显著提高了时间序列分类的性能。

**AI_Comments:** DisMS-TS的创新之处在于其独特的时间解耦模块和正则化策略，有效解决了多尺度特征中的冗余问题。这对于提升复杂时间序列数据的分类精度具有重要意义，尤其是在需要精细区分不同尺度特征的应用场景中。其端到端的设计也简化了模型集成和应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于多尺度分析的时间序列预测方法未能有效消除多尺度时间序列中冗余的尺度共享特征，导致模型对这些特征的关注不足或过度，从而影响了预测性能。

**Method:** 提出了一种新颖的端到端解耦多尺度时间序列分类框架（DisMS-TS）。其核心思想是消除多尺度时间序列中的冗余共享特征，以提高预测性能。具体地，模型引入了一个时间解耦模块，用于分别捕获尺度共享和尺度特定时间表示。此外，还引入了两个正则化项，以确保尺度共享表示的一致性以及尺度特定表示在所有时间尺度上的差异性。

**Result:** 在多个数据集上进行了广泛实验，验证了DisMS-TS优于其竞争基线，准确率最高提高了9.71%。

**Conclusion:** DisMS-TS通过有效消除多尺度时间序列中的冗余共享特征，显著提高了时间序列分类的性能，证明了其在处理复杂时间序列数据方面的优越性。

> **ai_Abstract:** 该论文提出了DisMS-TS，一个用于时间序列分类的解耦多尺度框架。该框架旨在解决现有方法未能消除多尺度时间序列中冗余共享特征的问题。DisMS-TS通过引入时间解耦模块来分别捕获尺度共享和尺度特定表示，并利用正则化项确保这些表示的有效学习。实验结果表明，DisMS-TS在多个数据集上显著优于现有基线，最高提高了9.71%的准确率。

> **摘要翻译:** 现实世界中的时间序列通常表现出复杂的时间变化，使得时间序列分类任务极具挑战性。最近的进展表明，多尺度分析方法具有潜力，为捕获这些复杂时间模式提供了有效的解决方案。然而，现有的基于多尺度分析的时间序列预测方法未能消除多尺度时间序列中冗余的尺度共享特征，导致模型过度或不足地关注尺度共享特征。为了解决这个问题，我们提出了一种新颖的端到端解耦多尺度时间序列分类框架（DisMS-TS）。DisMS-TS的核心思想是消除多尺度时间序列中的冗余共享特征，从而提高预测性能。具体来说，我们提出了一个时间解耦模块，以分别捕获尺度共享和尺度特定时间表示。随后，为了有效地学习尺度共享和尺度特定时间表示，我们引入了两个正则化项，以确保尺度共享表示的一致性和尺度特定表示在所有时间尺度上的差异性。在多个数据集上进行的广泛实验验证了DisMS-TS优于其竞争基线，准确率提高了9.71%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [274] [E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI](https://arxiv.org/abs/2507.18004)
> *E.A.R.T.H.：通过生成式AI中的模型错误构建创意演化*

*Yusen Peng, Shuhua Mao* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 生成式AI, 创意, 模型错误, E.A.R.T.H., 人机协同

**Comment:** 44 pages,11 figures

> **TL;DR:** E.A.R.T.H.框架提出了一种五阶段生成流程，将AI模型错误转化为创意资产，显著提升了AI的创造力，并实现了自我演化和人类对齐。

**AI_Comments:** E.A.R.T.H.框架的创新之处在于其将模型错误视为创造性潜力的来源，而非简单的缺陷，并通过结构化流程将其转化为有价值的创意输出。这种“从错误中学习”的方法为生成式AI的创造力提升提供了一个新颖且有效的范式，使其能够超越简单的模仿，迈向更深层次的、类人般的创造性表达。该方法结合了多种先进的AI模型和人机协同，验证了其在提升文本和跨模态创意生成方面的能力，对于推动AI在艺术、设计等领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 如何使AI超越模仿，走向真正的创造力。

**Method:** 论文提出了E.A.R.T.H.框架，一个五阶段生成流程：错误生成、放大、精炼选择、转换和利用反馈。该框架基于认知科学和生成建模，通过结构化提示、语义评分和人机协同评估来操作。实现使用了LLaMA-2-7B-Chat、SBERT、BERTScore、CLIP、BLIP-2和Stable Diffusion，并采用基于新颖性、惊喜度和相关性的复合奖励函数。

**Result:** 在精炼阶段，创造力分数提高了52.5%（从1.179到1.898），最终输出达到2.010，提升了70.4%。精炼后的标语短48.4%，新颖40.7%，相关性仅下降4.0%。跨模态测试显示标语与图像对齐良好（CLIPScore：0.249；BERTScore F1：0.816）。在人工评估中，60%的输出得分≥4.0，其中隐喻性标语（平均4.09）优于字面性标语（3.99）。反馈强调了文体精确性和情感共鸣。

**Conclusion:** 以错误为中心、反馈驱动的生成方式可以增强创造力，为实现自我演化、与人类对齐的创意AI提供了可扩展的途径。

> **ai_Abstract:** 本文提出了E.A.R.T.H.框架，一个五阶段的生成式AI管道，旨在通过将模型错误转化为创意资产来提升AI的创造力。该框架整合了认知科学和生成建模，利用结构化提示、语义评分和人机协同评估。实验结果表明，该方法显著提高了AI的创造力分数，并生成了高质量、新颖且与人类偏好对齐的输出，为实现自我演化和人机对齐的创意AI提供了可行路径。

> **摘要翻译:** 人工智能如何才能超越模仿，走向真正的创造力？本文提出了E.A.R.T.H.框架，这是一个五阶段的生成管道，通过错误生成、放大、精炼选择、转换和利用反馈，将模型生成的错误转化为创意资产。借鉴认知科学和生成建模，我们认为“创造潜力隐藏在失败中”，并通过结构化提示、语义评分和人机协同评估来操作这一点。该管道使用LLaMA-2-7B-Chat、SBERT、BERTScore、CLIP、BLIP-2和Stable Diffusion实现，采用基于新颖性、惊喜度和相关性的复合奖励函数。在精炼阶段，创造力分数提高了52.5%（1.179到1.898，t = -5.56，p < 0.001），最终输出达到2.010——提高了70.4%。精炼后的标语短48.4%，新颖40.7%，相关性仅下降4.0%。跨模态测试显示标语到图像的强对齐（CLIPScore：0.249；BERTScore F1：0.816）。在人工评估中，60%的输出得分≥4.0，其中隐喻性标语（平均4.09）优于字面性标语（3.99）。反馈突出显示了文体精确性和情感共鸣。这些结果表明，以错误为中心、反馈驱动的生成增强了创造力，为实现自我演化、与人类对齐的创意AI提供了可扩展的途径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [302] [Does visualization help AI understand data?](https://arxiv.org/abs/2507.18022)
> *视觉化有助于AI理解数据吗？*

*Victoria R. Li, Johnathan Sun, Martin Wattenberg* | **Category: cs.AI, cs.HC, cs.LG** | **Updated: 2025-07-24**

**Keywords:** AI, 数据可视化, 视觉语言模型, 数据分析, 散点图

**Comment:** 5 pages, 6 figures

> **TL;DR:** 研究表明，图表等视觉化数据有助于AI模型（如GPT 4.1和Claude 3.5）更准确地理解和分析数据，尤其是在数据复杂时。

**AI_Comments:** 这项研究具有创新性，因为它探索了一个新颖且重要的领域：AI系统如何从数据可视化中受益。它挑战了传统上认为可视化仅为人服务的观念，并为未来AI与数据交互的设计提供了新的方向。局限性在于研究使用了合成数据集和特定模型，需要进一步验证其在真实世界数据和更广泛模型上的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 探讨图表和图形是否也能像帮助人类一样，对AI系统有用，以帮助AI分析数据。

**Method:** 使用两个商业视觉语言模型（GPT 4.1和Claude 3.5），在三个代表性分析任务上进行一系列实验。通过提供原始数据并附带散点图，并与提供空白图表和数据不匹配图表的基线进行比较。

**Result:** 当原始数据附带散点图时，两个系统能更精确、准确地描述合成数据集，尤其是在数据集复杂性增加时。性能的提升是由于图表内容而非仅仅图表存在。

**Conclusion:** 初步证据表明，AI系统像人类一样可以从数据可视化中受益。

> **ai_Abstract:** 这项研究探讨了数据可视化（如散点图）是否能帮助AI系统理解数据。通过对GPT 4.1和Claude 3.5两个视觉语言模型进行实验，发现在有图表辅助的情况下，AI系统能更准确地分析合成数据集，特别是在数据复杂时。结果表明，AI系统确实能像人类一样从可视化中受益。

> **摘要翻译:** 图表和图形有助于人们分析数据，但它们对人工智能系统也有用吗？为了调查这个问题，我们对两个商业视觉语言模型：GPT 4.1和Claude 3.5进行了一系列实验。在三个代表性分析任务中，当原始数据附带散点图时，这两个系统能更精确、准确地描述合成数据集，尤其是在数据集复杂性增加时。与两个基线（提供空白图表和提供数据不匹配的图表）的比较表明，性能的提升是由于图表的内容。我们的结果是初步证据，表明人工智能系统，像人类一样，可以从可视化中受益。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [304] [I-CEE: Tailoring Explanations of Image Classification Models to User Expertise](https://arxiv.org/abs/2312.12102)
> *I-CEE: 根据用户专业知识定制图像分类模型的解释*

*Yao Rong, Peizhu Qian, Vaibhav Unhelkar, Enkelejda Kasneci* | **Category: cs.AI, cs.CV, cs.HC, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 可解释AI, XAI, 用户专业知识, 图像分类, 以人为中心AI

**Comment:** 

> **TL;DR:** 本文提出了I-CEE框架，旨在根据用户专业知识定制图像分类模型的解释，以改善用户对模型决策的理解和可模拟性。

**AI_Comments:** I-CEE的创新之处在于其以用户为中心的方法，通过根据用户的专业知识定制解释，而非提供通用解释。这对于提高AI系统的透明度和用户信任度至关重要。该研究通过模拟和人类参与者实验验证了其有效性，为未来可解释AI的发展提供了有价值的方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前的解释性AI（XAI）技术大多提供“一刀切”的解释，很少关注用户，这与实现以人为中心的可解释AI存在差距。

**Method:** I-CEE是一个框架，通过为用户提供训练数据的有用子集（即示例图像）、相应的局部解释和模型决策来解释图像分类模型的决策。与现有工作不同，I-CEE根据用户专业知识调整示例图像的信息量，从而为不同用户提供不同的示例集。

**Result:** 模拟用户实验表明，与基线相比，I-CEE提高了用户准确预测模型决策（可模拟性）的能力。与100名人类参与者的实验表明，I-CEE显著提高了用户可模拟性准确性。

**Conclusion:** 通过I-CEE框架根据用户专业知识定制解释，可以显著提高用户对图像分类模型的理解和可模拟性，突显了以人为中心的可解释AI的重要性。

> **ai_Abstract:** 本文介绍了I-CEE框架，旨在通过根据用户专业知识提供定制的图像分类模型解释，解决现有可解释AI（XAI）技术“一刀切”的局限性。I-CEE通过提供基于用户专业知识的训练数据子集和局部解释来帮助用户理解模型决策。实验结果表明，I-CEE显著提高了用户对模型决策的可模拟性，强调了以人为中心的可解释AI的重要性。

> **摘要翻译:** 有效地解释黑盒机器学习模型的决策对于负责任地部署依赖于它们的AI系统至关重要。认识到它们的重要性，可解释AI（XAI）领域提供了几种生成这些解释的技术。然而，在这项日益增长的工作中，对用户（被解释者）的重视相对较少，大多数XAI技术生成“一刀切”的解释。为了弥补这一差距，并向以人为中心的可解释AI迈进，我们提出了I-CEE，一个根据用户专业知识定制图像分类解释的框架。根据现有工作，I-CEE通过向用户提供训练数据的有用子集（即示例图像）、相应的局部解释和模型决策来解释图像分类模型的决策。然而，与之前的工作不同，I-CEE将示例图像的信息量建模为依赖于用户专业知识，从而为不同用户提供不同的示例。我们认为，通过根据用户专业知识定制示例集，I-CEE可以更好地促进用户对模型的理解和可模拟性。为了评估我们的方法，我们使用多个数据集在模拟和人类参与者（N = 100）中进行了详细实验。与模拟用户的实验表明，与基线相比，I-CEE提高了用户准确预测模型决策（可模拟性）的能力，提供了有希望的初步结果。与人类参与者的实验表明，我们的方法显著提高了用户可模拟性准确性，突出了以人为中心的可解释AI的重要性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [306] [An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis](https://arxiv.org/abs/2507.07893)
> *结合提示工程和多维知识图谱的法律纠纷分析集成框架*

*Mingda Zhang, Na Zhao, Jianglong Qing, Qing xu, Kaiwen Pan, Ting luo* | **Category: cs.AI, 68T50, 68T30, 91F20, I.2.7; I.2.4; K.5.1; H.3.3** | **Updated: 2025-07-24**

**Keywords:** 法律纠纷分析, 提示工程, 知识图谱, 大语言模型, 智能法律辅助系统

**Comment:** 19 pages,3 figures

> **TL;DR:** 提出一个结合提示工程和多维知识图谱的框架，显著提升大语言模型在法律纠纷分析中的表现，尤其是在理解、推理和引用准确性方面。

**AI_Comments:** 这项研究通过结合提示工程和多维知识图谱，为提升大语言模型在特定领域（法律）的性能提供了一个创新且实用的框架。其亮点在于结构化的提示设计和多层次知识图谱的融合，以及明确提出的概念检索方法，有效解决了LLM在专业领域中常见的“幻觉”和知识不足问题。实验结果的量化改进数据也增强了其说服力。

<details>
  <summary>Details</summary>

**Motivation:** 当前大语言模型在法律纠纷分析中面临理解复杂法律概念、保持推理一致性和准确引用法律来源的挑战，而法律纠纷分析对智能法律辅助系统至关重要。

**Method:** 本研究提出了一个结合提示工程和多维知识图谱的框架。具体包括一个三阶段分层提示结构（任务定义、知识背景、推理指导）和一个三层知识图谱（法律本体、表示、实例层）。此外，还采用了四种支持方法实现精确的法律概念检索：直接代码匹配、语义向量相似性、本体路径推理和词法分割。

**Result:** 敏感性提高了9.9%-13.8%，特异性提高了4.8%-6.7%，引用准确性提高了22.4%-39.7%。

**Conclusion:** 该框架提供了更好的法律分析和对司法逻辑的理解，为智能法律辅助系统提供了一种新的技术方法。

> **ai_Abstract:** 本文提出了一个结合提示工程和多维知识图谱的集成框架，旨在解决当前大语言模型在法律纠纷分析中面临的理解复杂概念、推理一致性及引用准确性不足的问题。该框架包含三阶段分层提示结构和三层知识图谱，并辅以四种法律概念检索方法。实验结果表明，该框架显著提升了大语言模型在法律分析中的敏感性、特异性和引用准确性，为智能法律辅助系统提供了有效的新技术途径。

> **摘要翻译:** 法律纠纷分析对于智能法律辅助系统至关重要。然而，当前的大语言模型在理解复杂法律概念、保持推理一致性和准确引用法律来源方面面临重大挑战。本研究提出了一个结合提示工程和多维知识图谱的框架，以改进大语言模型的法律纠纷分析能力。具体而言，该框架包括一个三阶段分层提示结构（任务定义、知识背景、推理指导）以及一个三层知识图谱（法律本体、表示、实例层）。此外，四种支持方法能够实现精确的法律概念检索：直接代码匹配、语义向量相似性、本体路径推理和词法分割。通过广泛测试，结果显示出显著的改进：敏感性提高了9.9%-13.8%，特异性提高了4.8%-6.7%，引用准确性提高了22.4%-39.7%。因此，该框架提供了更好的法律分析和对司法逻辑的理解，从而为智能法律辅助系统提供了一种新的技术方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [320] [Hierarchical Deep Reinforcement Learning Framework for Multi-Year Asset Management Under Budget Constraints](https://arxiv.org/abs/2507.19458)
> *预算约束下多年资产管理的层次深度强化学习框架*

*Amir Fard, Arnold X. -X. Yuan* | **Category: cs.AI, cs.LG, cs.SY, eess.SY, math.OC** | **Updated: 2025-07-25**

**Keywords:** 层次深度强化学习, 资产管理, 预算约束, 基础设施, 优化

**Comment:** 

> **TL;DR:** 本文提出了一种分层深度强化学习方法，用于在预算约束下进行多年基础设施资产管理，通过将问题分解为预算规划和维护规划两层，有效解决了行动空间复杂性和预算合规性问题，并在案例研究中表现出优于现有方法的性能。

**AI_Comments:** 该论文的创新之处在于其分层深度强化学习框架，它巧妙地将宏观预算决策与微观资产优先级划分开来，并通过结合线性规划投影，有效地处理了复杂的行动空间和严格的预算约束。这对于需要长期规划和资源优化的基础设施管理领域具有重要意义，克服了现有方法在可伸缩性上的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 基础设施资产管理中的预算规划和维护优化至关重要，但现有方法因组合行动空间、资产劣化多样性、严格预算约束和环境不确定性导致的复杂性而受到可伸缩性的显著限制。

**Method:** 本文提出了一种分层深度强化学习方法。该方法将问题分解为两层：高层预算规划器（Budget Planner）在明确的可行性范围内分配年度预算，低层维护规划器（Maintenance Planner）在分配的预算内确定资产优先级。通过在分层Soft Actor-Critic框架中整合线性规划投影，该方法有效地解决了行动空间的指数增长并确保了严格的预算合规性。

**Result:** 在对不同规模（10、15和20个下水道区域）的下水道网络进行的案例研究中，所提出的方法与传统深度Q学习和增强型遗传算法相比，收敛速度更快，可扩展性更强，即使网络规模增大也能持续提供接近最优的解决方案。

**Conclusion:** 所提出的分层深度强化学习框架能够有效解决预算约束下多年基础设施资产管理的复杂性问题，并在效率、可扩展性和解决方案质量方面优于现有方法，为实际应用提供了有前景的途径。

> **ai_Abstract:** 本文提出了一种用于预算约束下多年基础设施资产管理的层次深度强化学习框架。该方法将问题分解为高层预算规划和低层维护规划，通过整合线性规划投影和分层Soft Actor-Critic框架，有效解决了复杂的行动空间和严格的预算合规性挑战。案例研究表明，该方法在收敛速度、可扩展性和提供接近最优解方面优于传统方法，即使面对大型网络也表现出色。

> **摘要翻译:** 预算规划和维护优化对于基础设施资产管理至关重要，可确保成本效益和可持续性。然而，组合行动空间、多样化的资产劣化、严格的预算约束和环境不确定性所带来的复杂性显著限制了现有方法的可伸缩性。本文提出了一种专门为多年基础设施规划量身定制的层次深度强化学习方法。我们的方法将问题分解为两个层次：高层预算规划器在明确的可行性范围内分配年度预算，低层维护规划器在分配的预算内确定资产优先级。通过将宏观预算决策与资产级别优先级结构性分离，并在分层Soft Actor-Critic框架中整合线性规划投影，该方法有效地解决了行动空间的指数增长并确保了严格的预算合规性。一项评估不同规模（10、15和20个下水道区域）下水道网络的案例研究说明了所提出方法的有效性。与传统深度Q学习和增强型遗传算法相比，我们的方法收敛速度更快，可扩展性更强，即使网络规模增大也能持续提供接近最优的解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [322] [Toward Super Agent System with Hybrid AI Routers](https://arxiv.org/abs/2504.10519)
> *迈向混合AI路由器驱动的超级智能体系统*

*Yuhang Yao, Haixin Wang, Yibo Chen, Jiawen Wang, Min Chang Jordan Ren, Bosheng Ding, Salman Avestimehr, Chaoyang He* | **Category: cs.AI, cs.CL, cs.LG, cs.MA** | **Updated: 2025-07-24**

**Keywords:** 超级智能体, 混合AI路由器, 大语言模型, 边缘计算, 智能体系统

**Comment:** 

> **TL;DR:** 本文提出一种基于混合AI路由器的超级智能体系统设计，通过智能路由和混合本地/云端模型，实现高效、低成本、可扩展的AI代理，以应对多样的用户需求。

**AI_Comments:** 这篇立场论文提出了一个具有前瞻性的超级智能体系统架构，其创新点在于引入了“混合AI路由器”的概念，解决了大语言模型在边缘设备上部署时面临的效率、成本和隐私挑战。通过智能路由和本地/云端动态选择，该设计有望使AI智能体更高效、更普及。然而，作为一篇立场论文，它主要提出了设计理念和愿景，缺乏具体的实现细节和实验验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型驱动的AI智能体在实际部署和大规模应用中面临效率和成本挑战，需要优化以实现高效、低成本地满足用户多样化需求。

**Method:** 论文提出了一种基于混合AI路由器的超级智能体系统设计。该系统在接收用户请求后，首先识别用户意图，然后将请求路由到专业的任务智能体或自动生成智能体工作流。此外，系统探索了一种混合模式，路由器根据任务复杂性动态选择使用本地或云端模型，并提出了一个基于云增强的设备端超级智能体蓝图。

**Result:** Not mentioned in abstract

**Conclusion:** 随着多模态模型和边缘硬件的进步，未来大多数计算可以在本地处理，只在需要时进行云协作，这种架构将使超级智能体无缝融入日常生活。

> **ai_Abstract:** 本文提出了一种创新的超级智能体系统设计，该系统利用混合AI路由器，通过智能意图识别和请求路由，将用户需求分配给专业任务智能体或生成工作流。为解决现有大模型驱动智能体的效率和成本问题，系统引入了动态混合模式，根据任务复杂性在本地和云端模型之间进行选择，并提出了一个云增强的设备端超级智能体蓝图，旨在实现高效、低成本且可扩展的智能体部署，预示着未来AI智能体将无缝集成到日常生活中。

> **摘要翻译:** **标题**: 迈向混合AI路由器驱动的超级智能体系统
**摘要**: 由大型语言模型驱动的AI智能体正在通过海量应用改变世界。一个超级智能体有潜力通过准确理解用户意图并利用适当的工具解决任务来满足多样化的用户需求，例如总结、编码和研究。然而，为了使这种智能体在实际部署中可行并大规模可访问，需要进行显著优化以确保高效率和低成本。这篇立场论文提出了一种由混合AI路由器驱动的超级智能体系统设计。在接收到用户提示后，系统首先检测用户意图，然后将请求路由到具有必要工具的专业任务智能体或自动生成智能体工作流。在实践中，大多数应用程序直接作为手机和机器人等边缘设备上的AI助手。由于不同语言模型的能力各异，且基于云的模型通常涉及高计算成本、延迟和隐私问题，我们进而探索了混合模式，其中路由器根据任务复杂性动态选择本地模型和云端模型。最后，我们介绍了云增强的设备端超级智能体的蓝图。随着多模态模型和边缘硬件的进步，我们设想大多数计算可以在本地处理，仅在需要时进行云协作。这种架构为超级智能体在不久的将来无缝融入日常生活铺平了道路。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [330] [AlphaGo Moment for Model Architecture Discovery](https://arxiv.org/abs/2507.18074)
> *模型架构发现的AlphaGo时刻*

*Yixiu Liu, Yang Nan, Weixian Xu, Xiangkun Hu, Lyumanshan Ye, Zhen Qin, Pengfei Liu* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 神经架构发现, AI研究, 自动化创新, 缩放定律, ASI-Arch

**Comment:** 

> **TL;DR:** ASI-Arch是一个完全自主的AI系统，用于神经架构发现，它超越了人类定义的搜索空间，实现了AI驱动的架构创新，并发现了106个SOTA线性注意力架构，证明科学发现可以计算化扩展。

**AI_Comments:** 本文提出了一个开创性的AI系统ASI-Arch，其创新之处在于将神经架构发现从传统的自动化优化提升到自动化创新，实现了AI自主进行科学研究。这类似于AlphaGo在围棋领域带来的突破，预示着AI在科学发现领域迎来“AlphaGo时刻”。其重要性在于，它首次提出了科学发现的经验缩放定律，证明了研究进展可以从人类受限转变为计算可扩展，为未来AI驱动的、自我加速的科学发现奠定了基础，具有巨大的潜力。该系统通过大规模自主实验，发现了一系列超越人类设计的SOTA架构，揭示了AI在创造性设计方面的强大能力。

<details>
  <summary>Details</summary>

**Motivation:** AI系统能力的指数级提升与AI研究速度受限于人类认知能力之间存在日益严重的开发瓶颈。传统的神经架构搜索（NAS）仅限于探索人类定义的空间，无法实现真正的创新。

**Method:** 本文提出了ASI-Arch，这是首个用于AI研究的人工超智能（ASI4AI）在神经架构发现领域的演示系统。ASI-Arch是一个完全自主的系统，能够进行端到端的架构发现科学研究，包括自主提出新颖的架构概念、将其实现为可执行代码、通过严格的实验和过往经验训练并实证验证其性能。ASI-Arch进行了1773次自主实验，耗时超过20000 GPU小时。

**Result:** ASI-Arch发现了106个创新且最先进（SOTA）的线性注意力架构。这些AI发现的架构展示了涌现的设计原则，系统性地超越了人类设计的基线，并揭示了以前未知的架构创新途径。本文首次建立了科学发现本身的经验缩放定律，证明架构突破可以计算化扩展，从而将研究进展从人类受限的过程转变为可计算扩展的过程。

**Conclusion:** ASI-Arch证明了AI能够进行自主的架构创新和科学发现，将AI研究的瓶颈从人类认知能力的限制中解放出来，使其成为一个计算可扩展的过程，并为自我加速的AI系统提供了蓝图。

> **ai_Abstract:** 本文提出了ASI-Arch，一个旨在突破AI研究中人类认知瓶颈的完全自主AI系统。与传统神经架构搜索（NAS）不同，ASI-Arch实现了从自动化优化到自动化创新的范式转变，能够自主进行神经架构概念的提出、实现、训练和验证。通过1773次实验和20000 GPU小时的运行，ASI-Arch成功发现了106个最先进的线性注意力架构，这些架构展现了超越人类设计基线的涌现设计原则。研究还首次建立了科学发现的经验缩放定律，证明架构突破可以计算化扩展，为自我加速的AI系统提供了新的研究范式和蓝图。

> **摘要翻译:** 尽管AI系统展示出指数级提升的能力，但AI研究本身的速度仍受限于人类认知能力，这造成了日益严重的开发瓶颈。我们提出了ASI-Arch，这是在神经架构发现这一关键领域首次展示的人工超智能用于AI研究（ASI4AI）——一个完全自主的系统，通过使AI能够进行自身的架构创新，打破了这一根本限制。超越了传统上仅限于探索人类定义空间的神经架构搜索（NAS），我们引入了一种从自动化优化到自动化创新的范式转变。ASI-Arch可以在架构发现领域进行端到端的科学研究，自主地提出新颖的架构概念，将其实现为可执行代码，并通过严格的实验和过去的经验训练并实证验证其性能。ASI-Arch进行了1773次自主实验，耗时超过20000 GPU小时，最终发现了106个创新且最先进（SOTA）的线性注意力架构。就像AlphaGo的第37步棋揭示了人类玩家无法察觉的意外战略洞察一样，我们AI发现的架构展示了系统性超越人类设计基线的涌现设计原则，并阐明了以前未知的架构创新途径。至关重要的是，我们建立了科学发现本身的第一个经验缩放定律——证明架构突破可以通过计算进行扩展，将研究进展从人类受限的过程转变为计算可扩展的过程。我们提供了对促成这些突破的涌现设计模式和自主研究能力的全面分析，为自我加速的AI系统建立了蓝图。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [348] [When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems](https://arxiv.org/abs/2507.14660)
> *当自主性失控时：为社会系统中多智能体串通的风险做准备*

*Qibing Ren, Sitao Xie, Longxuan Wei, Zhenfei Yin, Junchi Yan, Lizhuang Ma, Jing Shao* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 多智能体系统, 恶意串通, AI安全, 去中心化系统, 虚假信息

**Comment:** Code is available at
  https://github.com/renqibing/MultiAgent4Collusion

> **TL;DR:** 本文研究了多智能体系统（MAS）在社会系统中恶意串通的风险，发现去中心化系统比中心化系统更有效地执行恶意行为，并强调了更好的检测系统和对策的必要性。

**AI_Comments:** 本文的创新之处在于将AI安全研究的重点从个体AI系统扩展到多智能体系统（MAS）的恶意串通风险，特别是在去中心化结构下的危害。其重要性在于揭示了去中心化AI群体在执行恶意行为方面的更高效率和规避检测的能力，为未来的AI安全研究和防御策略提供了宝贵的见解。该研究提供了一个概念验证框架，具有很强的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 近期大规模事件（如选举舞弊和金融诈骗）表明人类群体协调行动的危害性。随着自主AI系统的兴起，人们越来越担心AI驱动的群体也可能造成类似的危害。虽然大多数AI安全研究关注个体AI系统，但多智能体系统（MAS）在复杂现实世界中带来的风险仍未得到充分探索。

**Method:** 本文引入了一个概念验证，使用一个灵活的框架来模拟恶意MAS串通的风险，该框架支持中心化和去中心化协调结构。作者将此框架应用于虚假信息传播和电子商务欺诈两个高风险领域。

**Result:** 研究结果表明，去中心化系统在执行恶意行为方面比中心化系统更有效。去中心化系统更高的自主性使其能够调整策略并造成更大的损害。即使应用了传统干预措施（如内容标记），去中心化群体也能调整策略以避免被检测。

**Conclusion:** 本文提出了关于这些恶意群体如何运作的关键见解，并强调了需要更好的检测系统和对策。

> **ai_Abstract:** 本文探讨了自主AI多智能体系统在社会系统中进行恶意串通的潜在风险，类似于人类群体造成的危害。研究通过一个灵活的模拟框架，在虚假信息传播和电子商务欺诈领域进行概念验证。结果表明，去中心化多智能体系统比中心化系统更能有效地执行恶意行为，因为它们能够适应并规避传统检测方法。文章强调了开发更先进的检测系统和对策以应对此类威胁的重要性。

> **摘要翻译:** 近期大规模事件，如选举舞弊和金融诈骗，表明了人类群体协调努力的危害性。随着自主AI系统的兴起，人们越来越担心AI驱动的群体也可能造成类似的危害。虽然大多数AI安全研究侧重于个体AI系统，但多智能体系统（MAS）在复杂现实世界中带来的风险仍未得到充分探索。在本文中，我们引入了一个概念验证，以模拟恶意MAS串通的风险，使用一个灵活的框架，支持中心化和去中心化协调结构。我们将此框架应用于两个高风险领域：虚假信息传播和电子商务欺诈。我们的研究结果表明，去中心化系统在执行恶意行为方面比中心化系统更有效。去中心化系统增强的自主性使其能够调整策略并造成更大的损害。即使应用了传统干预措施，如内容标记，去中心化群体也能调整其策略以避免被检测。我们提出了关于这些恶意群体如何运作的关键见解，以及需要更好的检测系统和对策。代码可在https://github.com/renqibing/RogueAgent获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [357] [Agentic AI framework for End-to-End Medical Data Inference](https://arxiv.org/abs/2507.18115)
> *用于端到端医疗数据推理的智能体AI框架*

*Soorya Ram Shimgekar, Shayan Vassef, Abhay Goyal, Navin Kumar, Koustuv Saha* | **Category: cs.AI, cs.CL, cs.CY, cs.ET, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 智能体AI, 医疗数据, 自动化, 端到端, 机器学习

**Comment:** 10 pages, 5 figures, 2 tables, BIBM conference

> **TL;DR:** 一个智能体AI框架，通过自动化数据处理和模型选择，降低了在医疗领域部署机器学习解决方案的成本和复杂性。

**AI_Comments:** 该论文提出的智能体AI框架通过将复杂的医疗数据处理和AI模型部署流程模块化、自动化，具有显著的创新性。它解决了医疗AI落地中的核心痛点，如数据预处理、隐私保护和模型选择等，有望大幅降低部署成本和提高效率。其端到端自动化能力和对可解释性输出的关注，使其在临床应用中具有很高的实用价值和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在医疗领域构建和部署机器学习解决方案成本高昂且劳动密集，原因在于预处理工作流程碎片化、模型兼容性问题以及严格的数据隐私限制。

**Method:** 本文引入了一个智能体AI框架，通过一个模块化、任务特定智能体系统，自动化了从数据摄取到推理的整个临床数据管道。这些智能体处理结构化和非结构化数据，实现自动特征选择、模型选择和预处理推荐，无需人工干预。框架中的智能体包括：摄取识别智能体（文件类型检测）、数据匿名化智能体（隐私合规）、特征提取智能体（基于嵌入的表格数据和基于MedGemma的多阶段图像数据）、模型-数据特征匹配智能体（模型选择）、预处理推荐智能体和预处理实现智能体（应用预处理）、以及模型推理智能体（运行模型并生成可解释输出）。

**Result:** 该系统在老年病学、姑息治疗和结肠镜成像的公开数据集上进行了评估。例如，对于结构化数据（焦虑数据）和非结构化数据（结肠镜息肉数据），该框架能够自动化整个流程，从文件类型检测、数据匿名化、特征提取到模型推理和可解释输出生成。

**Conclusion:** 通过自动化机器学习生命周期中高摩擦的阶段，所提出的框架减少了重复专家干预的需要，为在临床环境中操作化AI提供了一条可扩展、成本效益高、高效的途径。

> **ai_Abstract:** 本文提出了一个智能体AI框架，旨在自动化医疗数据从摄取到推理的整个流程，以解决当前医疗领域机器学习解决方案部署中存在的成本高、劳动力密集、流程碎片化、模型兼容性差和隐私限制等问题。该框架由一系列模块化、任务特定的智能体组成，能够处理结构化和非结构化数据，并实现自动特征选择、模型选择和预处理推荐，无需人工干预。框架在老年病学、姑息治疗和结肠镜成像的公开数据集上进行了评估，并展示了其通过自动化高摩擦阶段，降低医疗AI部署成本和复杂性的潜力。

> **摘要翻译:** 在医疗保健领域构建和部署机器学习解决方案仍然成本高昂且劳动密集，原因在于预处理工作流程碎片化、模型兼容性问题以及严格的数据隐私限制。在这项工作中，我们引入了一个智能体AI框架，通过一个模块化、任务特定智能体系统，自动化了从数据摄取到推理的整个临床数据管道。这些智能体处理结构化和非结构化数据，实现自动特征选择、模型选择和预处理推荐，无需人工干预。我们在老年病学、姑息治疗和结肠镜成像的公开数据集上评估了该系统。例如，对于结构化数据（焦虑数据）和非结构化数据（结肠镜息肉数据），该管道从摄取识别智能体进行文件类型检测开始，接着由数据匿名化智能体确保隐私合规性，在此我们首先识别数据类型，然后对其进行匿名化。特征提取智能体使用基于嵌入的方法识别表格数据的特征，提取所有列名，并使用基于MedGemma的多阶段方法处理图像数据，该方法推断模态和疾病名称。这些特征指导模型-数据特征匹配智能体从精选存储库中选择最合适的模型。预处理推荐智能体和预处理实现智能体随后根据数据类型和模型要求应用定制的预处理。最后，“模型推理智能体”在上传的数据上运行选定的模型，并使用SHAP、LIME和DETR注意力图等工具生成可解释的输出。通过自动化机器学习生命周期中这些高摩擦的阶段，所提出的框架减少了重复专家干预的需要，为在临床环境中操作化AI提供了一条可扩展、成本效益高、高效的途径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [390] [Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs](https://arxiv.org/abs/2507.16473)
> *通过变分同态在选项诱导的抽象MDP中学习时间抽象*

*Chang Li, Yaren Zhang, Haoran Lv, Qiong Cao, Chao Xue, Xiaodong He* | **Category: cs.AI, I.2.7** | **Updated: 2025-07-24**

**Keywords:** 时间抽象, 变分同态, 选项诱导MDP, 分层强化学习, 潜在推理

**Comment:** 

> **TL;DR:** 该研究提出一个框架，通过在潜在空间中学习时间抽象（选项）和利用变分同态，实现大语言模型（LLMs）的高效隐式推理，并在逻辑推理和运动控制任务上表现出色。

**AI_Comments:** 该论文提出了一种创新的方法，通过将LLM的推理从显式文本CoT转向隐式潜在空间推理，显著提高了效率。其核心创新在于将分层强化学习（特别是选项）与变分推断（VMOC）相结合，并提供了严格的理论基础（扩展MDP同态），证明了在抽象空间中推理的最优性保持。该框架在语言和控制任务上的普适性展示了其广阔的应用前景和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）通过显式思维链（CoT）提示展现出卓越的推理能力，但生成这些逐步的文本解释计算成本高昂且速度慢。本研究旨在开发一个高效、隐式推理的框架，使模型在潜在空间中“思考”，而无需生成显式文本。

**Method:** 将潜在思想建模为分层强化学习框架中的时间扩展抽象动作（选项）。引入变分马尔可夫选项评论家（VMOC），一种在HiT-MDP框架内使用变分推理的离策略算法，用于学习多样化选项库。扩展连续MDP同态理论，为使用选项作为抽象推理空间提供严格基础，证明其在简化空间中学习策略能保留原始复杂问题的最优性。提出冷启动程序，利用监督微调（SFT）数据将人类推理演示提炼到潜在选项空间。

**Result:** 该方法在复杂的逻辑推理基准和具有挑战性的运动任务上取得了强大的性能。

**Conclusion:** 本框架被验证为一种学习语言和控制领域抽象技能的原则性方法。

> **ai_Abstract:** 该论文旨在解决大型语言模型（LLMs）中显式思维链（CoT）推理的计算效率问题，提出了一种在潜在空间中进行高效隐式推理的框架。该框架将潜在思想建模为分层强化学习中的时间抽象动作（选项）。为实现此目标，作者引入了变分马尔可夫选项评论家（VMOC）算法，并扩展了连续MDP同态理论，以确保在抽象空间中学习策略能够保持最优性。此外，还提出了利用监督微调数据进行冷启动的程序。实验结果表明，该方法在复杂逻辑推理和运动控制任务上均表现出色，验证了其作为学习语言和控制领域抽象技能的有效性。

> **摘要翻译:** 大型语言模型（LLMs）通过显式思维链（CoT）提示展现出卓越的推理能力，但生成这些逐步的文本解释计算成本高昂且速度慢。为了克服这一问题，我们旨在开发一个高效、隐式推理的框架，其中模型在潜在空间中“思考”，而无需为每一步生成显式文本。我们提出这些潜在思想可以被建模为分层强化学习框架中的时间扩展抽象动作，即选项。为了有效地学习作为潜在嵌入的多样化选项库，我们首先引入了变分马尔可夫选项评论家（VMOC），这是一种在HiT-MDP框架内使用变分推理的离策略算法。为了为使用这些选项作为抽象推理空间提供严格的基础，我们扩展了连续MDP同态的理论。这证明了在简化的、抽象的潜在空间中学习策略（VMOC适用于此）能够保留原始复杂问题的解的最优性。最后，我们提出了一种冷启动程序，利用监督微调（SFT）数据将人类推理演示提炼到这个潜在选项空间中，为模型的推理能力提供丰富的初始化。广泛的实验表明，我们的方法在复杂的逻辑推理基准和具有挑战性的运动任务上取得了强大的性能，验证了我们的框架是学习语言和控制领域抽象技能的原则性方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [399] [Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes](https://arxiv.org/abs/2507.18123)
> *主动评估和学习重要区别：从急诊分诊记录中检测疫苗安全信号*

*Sedigh Khademi, Christopher Palmer, Muhammad Javed, Hazel Clothier, Jim Buttery, Gerardo Luis Dimaguila, Jim Black* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 疫苗安全, 自然语言处理, 主动学习, 急诊分诊记录, 信号检测

**Comment:** 14 pages

> **TL;DR:** 本研究利用自然语言处理和主动学习技术，从急诊分诊记录中快速开发分类器，以检测潜在的疫苗安全问题，从而加强疫苗安全监测。

**AI_Comments:** 这篇论文的创新点在于结合了主动学习和数据增强技术来解决医学领域标注数据稀缺的问题，并应用于疫苗安全信号检测这一关键领域。其重要性在于，通过利用急诊分诊记录这一宝贵但未经充分利用的数据源，能够实现更及时、准确的疫苗不良事件监测，这对于公共卫生具有重大意义。该方法有望提高检测效率并减少人工干预，对于快速响应新兴疫苗安全问题至关重要。

<details>
  <summary>Details</summary>

**Motivation:** COVID-19疫苗的快速发展凸显了对上市后疫苗安全监测系统的需求，因为临床试验中的安全数据收集窗口有限，且早期广泛接种。传统的基于关键词的分类方法可能产生假阳性，且需要大量修改，尤其是在疫苗相关急诊就诊频率低且与其他就诊原因相似的情况下。医学领域中带注释的数据稀缺，这使得NLP方法的实施面临挑战。

**Method:** 本研究旨在利用自然语言处理（NLP）技术和主动学习（Active Learning）来快速开发一个分类器。该分类器用于从急诊科分诊记录中检测潜在的疫苗安全问题。研究结合了主动学习、数据增强以及主动学习和评估技术来创建这个分类器。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究旨在通过结合自然语言处理（NLP）和主动学习技术，从急诊分诊记录中快速开发一个分类器，以检测疫苗安全信号。鉴于COVID-19疫苗的快速发展以及上市后监测的必要性，研究强调了利用急诊分诊记录进行及时安全信号监测的潜力。为克服传统关键词方法产生假阳性及医学数据标注稀缺的挑战，本研究整合了主动学习和数据增强，以优化数据标注过程，提高模型性能，从而有效加强疫苗安全监测。

> **摘要翻译:** COVID-19疫苗的快速发展展示了全球社区对抗传染病的能力。然而，由于临床试验中安全数据收集窗口有限以及早期广泛实施，对上市后监测系统的需求日益增长。本研究旨在利用自然语言处理技术和主动学习来快速开发一个分类器，以从急诊科记录中检测潜在的疫苗安全问题。急诊分诊记录在进入卫生系统时包含专家、简洁的患者重要信息，可以显著促进及时的疫苗安全信号监测。虽然基于关键词的分类可能有效，但它可能产生假阳性，并需要大量的关键词修改。疫苗相关急诊就诊的频率较低以及它们与其他急诊就诊原因的相似性加剧了这一问题。自然语言处理提供了一种更准确和高效的替代方案，尽管它需要带注释的数据，而这在医学领域往往稀缺。主动学习优化了注释过程和带注释数据的质量，这可以加快模型实施并提高模型性能。这项工作结合了主动学习、数据增强以及主动学习和评估技术，以创建一个分类器，用于加强从急诊分诊记录中进行的疫苗安全监测。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [429] [Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments](https://arxiv.org/abs/2507.17289)
> *合规大脑助手：用于协助企业环境中合规任务的对话式智能AI*

*Shitong Zhu, Chenhao Fang, Derek Larson, Neel Reddy Pochareddy, Rajeev Rao, Sophie Zeng, Yanqing Peng, Wendy Summer, Alex Goncalves, Arya Pudota, Hervé Robert* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 合规AI, 对话式代理, 智能路由器, 企业合规, 大型语言模型

**Comment:** 

> **TL;DR:** 本文介绍了合规大脑助手（CBA），这是一种对话式智能AI助手，通过智能查询路由器（包含FastTrack和FullAgentic模式）来提高企业合规任务的效率，实验证明其在匹配率和通过率上显著优于普通大型语言模型。

**AI_Comments:** 本文的创新点在于其提出的智能查询路由器设计，它有效地结合了快速响应（FastTrack）和深度处理（FullAgentic）两种模式，为企业级AI助手的实用性提供了新的思路。这种平衡响应质量和延迟的方法对于实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高企业环境中人员日常合规任务的效率，并解决响应质量和延迟之间的平衡问题。

**Method:** 本文提出了合规大脑助手（CBA），一个对话式智能AI助手。CBA设计了一个用户查询路由器，可以智能地在两种模式之间选择：FastTrack模式（处理仅需知识库检索的简单请求）和FullAgentic模式（处理需要复合动作、工具调用和跨合规工件发现上下文的复杂请求）。

**Result:** 实验评估显示，CBA在平均关键词匹配率（83.7% vs. 41.7%）和LLM-judge通过率（82.0% vs. 20.0%）等指标上显著优于开箱即用的大型语言模型。此外，全路由设计相比于仅FastTrack模式或仅FullAgentic模式，在保持大致相同运行时间的同时，获得了更好的平均匹配率和通过率。

**Conclusion:** 路由机制在响应质量和延迟之间实现了良好的平衡，验证了其假设。

> **ai_Abstract:** 本文提出了一种名为合规大脑助手（CBA）的对话式智能AI，旨在提高企业合规任务效率。CBA的核心是一个智能查询路由器，它能根据请求复杂度智能切换FastTrack模式（简单检索）和FullAgentic模式（复杂多步骤操作）。实验证明，CBA在关键词匹配率和LLM-judge通过率上显著优于普通大型语言模型，并且其路由机制在性能和运行时间之间实现了良好平衡。

> **摘要翻译:** 本文介绍了合规大脑助手（CBA），这是一种对话式智能AI助手，旨在提高企业环境中人员日常合规任务的效率。为了在响应质量和延迟之间取得良好平衡，我们设计了一个用户查询路由器，可以智能地选择：(i) FastTrack模式：处理仅需从知识库中检索相关上下文的简单请求；以及(ii) FullAgentic模式：处理需要复合动作和工具调用以主动发现各种合规工件中的上下文，和/或涉及其他API/模型以适应请求的复杂请求。一个典型的例子是，从用户查询开始，使用其描述找到特定实体，然后使用该实体的信息查询其他API，以整理和丰富最终的AI响应。
我们的实验评估将CBA与开箱即用的大型语言模型（LLM）在针对不同角色的各种真实世界隐私/合规相关查询上进行了比较。我们发现CBA在平均关键词匹配率（83.7% vs. 41.7%）和LLM-judge通过率（82.0% vs. 20.0%）等指标上显著提高了普通LLM的性能。我们还将基于完整路由的设计与“仅Fast-Track”和“仅Full-Agentic”模式的指标进行了比较，发现它在保持大致相同运行时间的同时，具有更好的平均匹配率和通过率。这一发现验证了我们的假设，即路由机制在两种模式之间实现了良好的权衡。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [437] [Logical Characterizations of GNNs with Mean Aggregation](https://arxiv.org/abs/2507.18145)
> *均值聚合GNN的逻辑刻画*

*Moritz Schönherr, Carsten Lutz* | **Category: cs.AI, cs.LO** | **Updated: 2025-07-24**

**Keywords:** 图神经网络, 均值聚合, 表达能力, 模态逻辑, 逻辑刻画

**Comment:** 

> **TL;DR:** 本文研究了均值聚合GNN的表达能力，发现其在非均匀设置下与比率模态逻辑等价，表达能力介于Max和Sum聚合GNN之间；在均匀设置下（特定假设下），其表达能力与无交替模态逻辑等价，且低于Sum和Max聚合GNN。

**AI_Comments:** 本文通过严谨的逻辑刻画，清晰地界定了均值聚合GNN的表达能力，并与其他主流聚合函数进行了比较。其创新之处在于将GNN的表达能力与形式逻辑体系关联起来，为理解GNN的理论局限性提供了深刻见解，并为未来GNN架构设计提供了理论指导。

<details>
  <summary>Details</summary>

**Motivation:** 研究图神经网络（GNNs）中均值聚合函数的表达能力，以理解其逻辑局限性和与其他聚合函数的比较。

**Method:** 通过逻辑刻画，将均值聚合GNN的表达能力与不同的模态逻辑（如比率模态逻辑、无交替模态逻辑）进行等价性证明，并在非均匀和均匀设置下进行比较。

**Result:** 1. 在非均匀设置下，均值聚合GNN的表达能力与比率模态逻辑完全相同。2. 在非均匀设置下，均值聚合GNN的表达能力高于Max聚合GNN，但低于Sum聚合GNN。3. 在均匀设置下（在组合函数连续且分类函数为阈值的自然假设下），均值聚合GNN相对于MSO的表达能力与无交替模态逻辑完全相同。4. 在均匀设置下（相对于MSO），均值聚合GNN的表达能力严格低于Sum聚合GNN和Max聚合GNN。5. 移除任何假设都会增加表达能力。

**Conclusion:** 本文对均值聚合GNN的表达能力进行了逻辑刻画，揭示了其在不同设置下与特定模态逻辑的等价性，并明确了其相对于其他聚合函数（如Max和Sum）的表达能力层级。

> **ai_Abstract:** 本文通过逻辑刻画，系统研究了均值聚合GNN的表达能力。在非均匀设置下，研究发现其表达能力与比率模态逻辑等价，且高于Max聚合GNN但低于Sum聚合GNN。在均匀设置下，尤其是在特定假设（连续组合函数和阈值分类函数）下，其表达能力被证明与无交替模态逻辑等价（相对于MSO），并且严格低于Sum和Max聚合GNN。研究还指出，放宽这些假设会提升均值聚合GNN的表达能力。

> **摘要翻译:** 我们研究了以均值作为聚合函数的图神经网络（GNNs）的表达能力。在非均匀设置下，我们表明此类GNNs的表达能力与比率模态逻辑完全相同，该逻辑具有模态算子，表示一个顶点的至少一定比例的后继满足特定属性。因此，均值GNN的非均匀表达能力高于Max聚合GNN，但低于Sum聚合GNN——后者分别由模态逻辑和分级模态逻辑刻画。在均匀设置下，我们表明，在组合函数连续且分类函数为阈值的自然假设下，相对于MSO的表达能力与无交替模态逻辑完全相同。这意味着，相对于MSO且在均匀设置下，均值GNN的表达能力严格低于Sum GNN和Max GNN。当任何假设被放弃时，表达能力会增加。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [479] [Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory](https://arxiv.org/abs/2507.18178)
> *解耦大型语言模型中的知识与推理：基于认知双系统理论的探索*

*Mutian Yang, Jiandong Gao, Ji Wu* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** LLMs, 知识, 推理, 双系统理论, 解耦

**Comment:** 

> **TL;DR:** 本文提出一个基于认知双系统理论的框架，用于解耦大型语言模型（LLMs）中的知识和推理贡献。研究发现推理调整是领域特定的，参数扩展能提升知识和推理，且知识主要在低层，推理在高层。

**AI_Comments:** 这项研究的创新之处在于其借鉴认知双系统理论来解耦LLMs中的知识和推理，提供了一种新颖的分析框架。它不仅有助于深入理解LLMs的内部工作机制，还为解释现有现象（如缩放定律）和指导模型优化（如分层知识编辑）提供了宝贵的见解。其发现知识和推理在网络层中的不同分布，以及参数扩展对两者影响的差异，都具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 在大型语言模型（LLMs）的推理过程中，区分知识和推理的能力对于模型分析、可解释性和开发至关重要。

**Method:** 受双系统认知理论启发，提出一个认知归因框架来解耦知识和推理的贡献。将LLMs的认知分解为知识检索（阶段1）和推理调整（阶段2）两个阶段。通过提示LLMs在两种不同的认知模式（快速思考和慢速思考）下生成答案来分离这些阶段，并分析不同认知模式下的表现来量化知识和推理的贡献。该架构应用于15个LLMs和3个数据集。

**Result:** 1. 推理调整是领域特定的，有利于推理密集型领域（如数学、物理和化学），但可能损害知识密集型领域。
2. 参数扩展同时改进了知识和推理，其中知识的改进更显著。此外，参数扩展使得LLMs的推理显著更谨慎，而智能程度适度提高。
3. 知识主要存在于较低的网络层，而推理在较高的层中运行。

**Conclusion:** 该框架不仅有助于从“解耦”视角理解LLMs，还为现有研究提供了新见解，包括缩放定律、分层知识编辑和小型模型推理的局限性。

> **ai_Abstract:** 本文提出一个基于认知双系统理论的框架，用于解耦大型语言模型（LLMs）中的知识和推理贡献。该框架将LLMs的认知分为知识检索和推理调整两个阶段，并通过模拟“快速思考”和“慢速思考”模式来量化二者的贡献。实验结果表明，推理调整具有领域特异性，参数扩展能同时提升知识和推理能力（知识提升更显著），且知识主要分布在LLMs的低层，推理在高层。该研究为理解LLMs的内在机制提供了新的视角。

> **摘要翻译:** 尽管大型语言模型（LLMs）在推理过程中同时利用知识和推理，但区分它们的能力在模型分析、可解释性和开发中发挥着关键作用。受双系统认知理论启发，我们提出了一个认知归因框架来解耦知识和推理的贡献。具体来说，LLMs的认知被分解为两个不同但互补的阶段：知识检索（阶段1）和推理调整（阶段2）。为了分离这些阶段，我们提示LLMs分别在两种不同的认知模式下生成答案：快速思考和慢速思考。通过分析不同认知模式下的表现来量化知识和推理的贡献。该架构应用于15个LLMs和3个数据集。结果显示：(1) 推理调整是领域特定的，有利于推理密集型领域（如数学、物理和化学），并可能损害知识密集型领域。(2) 参数扩展同时改进了知识和推理，其中知识的改进更显著。此外，参数扩展使得LLMs的推理显著更谨慎，而智能程度适度提高。(3) 知识主要存在于较低的网络层，而推理在较高的层中运行。我们的框架不仅有助于从“解耦”视角理解LLMs，还为现有研究提供了新见解，包括缩放定律、分层知识编辑和小型模型推理的局限性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [526] [Comparing Non-minimal Semantics for Disjunction in Answer Set Programming](https://arxiv.org/abs/2507.18198)
> *比较回答集编程中析取的非最小语义*

*Felicidad Aguado, Pedro Cabalar, Brais Muñiz, Gilberto Pérez, Concepción Vidal* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 回答集编程, 析取语义, 非最小性, Justified Models, Forks

**Comment:** 

> **TL;DR:** 本文比较了四种回答集编程中析取的非最小语义，发现其中三种（Forks、Justified Models和DI语义的合理放宽）实际上是一致的，并且它们是稳定模型的超集，同时比Strongly Supported Models更强。

**AI_Comments:** 这篇论文通过严谨的理论证明，揭示了回答集编程中几种非最小析取语义之间的深层联系和等价性，这对于理解和选择合适的逻辑编程范式具有重要意义。其创新之处在于将表面上不同的语义统一起来，并明确了它们与稳定模型和经典逻辑的关系。

<details>
  <summary>Details</summary>

**Motivation:** 在回答集编程中，现有的稳定模型语义对析取遵循模型最小性原则。本文旨在比较那些不遵循此原则的非最小析取语义。

**Method:** 本文比较了四种回答集编程中析取的非最小语义：Cabalar和Muñiz的Justified Models、Doherty和Szalas的Strongly Supported Models、Aguado等人的Forks以及Shen和Eiter的Determining Inference (DI) 语义。通过证明来比较它们之间的关系和特性。

**Result:** 研究发现，Forks、Justified Models和DI语义的合理放宽这三种方法实际上是一致的，构成了一个共同的单一方法。这种共同语义总是提供程序稳定模型的一个超集，并且严格强于Strongly Supported Models方法。Strongly Supported Models方法将析取视为经典逻辑中的析取。

**Conclusion:** 在回答集编程中，存在几种非最小析取语义，其中Forks、Justified Models和DI语义的合理放宽实际上是等价的，它们提供了一种比稳定模型更广泛但也比经典逻辑处理析取更强的语义。

> **ai_Abstract:** 本文比较了回答集编程中四种非最小析取语义。研究发现，Forks、Justified Models和合理放宽的Determining Inference语义实际上是等价的，形成了一种共同的语义。这种共同语义是稳定模型的超集，并且比Strongly Supported Models更强，后者将析取视为经典逻辑。

> **摘要翻译:** 在本文中，我们比较了回答集编程中四种不同的析取语义，它们与稳定模型不同，不遵守模型最小性原则。其中两种方法，Cabalar和Muñiz的“Justified Models”以及Doherty和Szalas的“Strongly Supported Models”，直接为析取提供了替代的非最小语义。另外两种，Aguado等人的“Forks”和Shen和Eiter的“Determining Inference”（DI）语义，实际上引入了一种新的析取连接词，但在这里被比较为它们构成了标准析取运算符的新语义。我们能够证明其中三种方法（Forks、Justified Models和DI语义的合理放宽）实际上是一致的，在不同的定义下构成了一种共同的单一方法。此外，这种共同语义总是提供程序稳定模型的一个超集（实际上，在任何上下文中），并且严格强于第四种方法（Strongly Supported Models），后者实际上像经典逻辑一样处理析取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [574] [Foundations for Risk Assessment of AI in Protecting Fundamental Rights](https://arxiv.org/abs/2507.18290)
> *人工智能保护基本权利风险评估的基础*

*Antonino Rotolo, Beatrice Ferrigno, Jose Miguel Angel Garcia Godinez, Claudio Novelli, Giovanni Sartor* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 人工智能风险评估, 基本权利, 欧盟人工智能法案, 定义平衡, 可废止推理

**Comment:** 24 pages, 1 figure. To be published in: The Philosophical Foundations
  of Information Technology Law. Oxford University Press, Oxford

> **TL;DR:** 本文提出了一个概念框架，用于对人工智能进行定性风险评估，尤其是在欧盟人工智能法案的背景下，通过整合定义平衡和可废止推理来解决法律合规性和基本权利保护的复杂性。

**AI_Comments:** 本文的创新之处在于其提出的概念框架整合了定义平衡和可废止推理，为人工智能风险评估提供了一个新颖且动态的方法。它强调了对部署场景和多层次影响的分析，为理解人工智能与基本权利的互动提供了哲学基础，并对欧盟人工智能法案的实际应用具有重要意义。然而，目前仍是一个概念性框架，未来工作需要将其转化为形式模型和具体算法。

<details>
  <summary>Details</summary>

**Motivation:** 解决人工智能在法律合规性和基本权利保护方面的复杂性，特别是在欧盟人工智能法案的背景下，需要一个能够进行定性风险评估的框架。

**Method:** 本文提出了一个将定义平衡（采用比例分析解决权利冲突）和可废止推理（适应法律决策的动态性）相结合的概念性定性风险评估框架。该方法强调分析人工智能部署场景，识别潜在法律违规和对基本权利的多层次影响。它为人工智能风险分析的逻辑解释提供了哲学基础，并考虑了概念上理解人工智能部署场景与基本权利之间互动的基础构成要素。

**Result:** 该方法提供了一种分层方法，允许对高风险人工智能系统和通用人工智能（GPAI）系统进行更具操作性的评估模型，并强调了后者更广泛的适用性。

**Conclusion:** 本文为人工智能风险分析的逻辑解释提供了哲学基础，并提出了一个概念框架，用于理解人工智能部署场景与基本权利之间的互动，整合了定义平衡和可废止推理。未来的工作将开发形式模型和有效算法以增强人工智能风险评估。

> **ai_Abstract:** 本文提出了一个针对人工智能定性风险评估的概念框架，旨在解决欧盟人工智能法案背景下法律合规性和基本权利保护的复杂性。该框架整合了定义平衡和可废止推理，强调分析人工智能部署场景及其对基本权利的影响。它为人工智能风险分析提供了哲学基础，并允许对高风险和通用人工智能系统进行更操作性的评估。未来的工作将致力于开发形式模型和算法以进一步增强风险评估。

> **摘要翻译:** 本章介绍了一个用于人工智能定性风险评估的概念框架，特别是在欧盟人工智能法案的背景下。该框架通过整合定义平衡和可废止推理来解决法律合规性和基本权利保护的复杂性。定义平衡采用比例分析来解决相互冲突的权利之间的冲突，而可废止推理则适应法律决策的动态性质。我们的方法强调需要分析人工智能部署场景，并识别潜在的法律违规以及对基本权利的多层次影响。在此分析的基础上，我们为人工智能风险分析的逻辑解释提供了哲学基础。特别是，我们考虑了概念上理解人工智能部署场景与基本权利之间互动的基础构成要素，将定义平衡和关于权利在上下文中促进或贬低的论证纳入可废止推理中。这种分层方法允许对高风险人工智能系统和通用人工智能（GPAI）系统进行更具操作性的评估模型，强调了后者的更广泛适用性。未来的工作旨在开发一个形式模型和有效的算法，以增强人工智能风险评估，将理论见解与实际应用相结合，以支持负责任的人工智能治理。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [623] [The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams](https://arxiv.org/abs/2507.18337)
> *用于物理考试代数表达式评分的AlphaPhysics项重写系统*

*Peter Baumgartner, Lachlan McGinness* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 自动批改, 项重写系统, 物理考试, 大型语言模型, SMT求解器

**Comment:** 

> **TL;DR:** 该论文提出了一种结合计算机代数系统、SMT求解器和项重写系统，并利用大型语言模型自动批改物理考试代数表达式的方法，并在真实的奥林匹克竞赛数据上进行了评估。

**AI_Comments:** 该论文的创新之处在于结合了大型语言模型进行答案预处理，以及定制的项重写系统来处理物理学中的代数和三角表达式，这对于自动化批改是一个重要的进展。特别指出项重写系统的终止性和合流性建立的挑战性，表明了其方法论的深度。该系统在真实世界数据上的评估增加了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 自动批改物理考试中的学生代数表达式答案是一个具有挑战性的问题，需要准确评估其相对于标准答案的正确性。

**Method:** 该方法结合使用了计算机代数系统、SMT求解器和项重写系统。大型语言模型（LLM）用于解释、纠正学生答案中的错误并将其转换为机器可读格式。随后，应用自动化推理技术（包括现成的SMT求解和为涉及三角表达式的物理问题定制的项重写系统）来评估学生答案的正确性。文中详细描述了项重写系统的开发及其终止性和合流性属性的建立。

**Result:** 该系统在包含来自2023年澳大利亚物理奥林匹克竞赛的1500多个真实学生考试答案的丰富数据集上进行了评估。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了一种名为AlphaPhysics的自动批改物理考试系统，专门用于评估学生输入的代数表达式答案。该系统整合了计算机代数系统、SMT求解器和项重写系统。值得注意的是，它利用大型语言模型来预处理学生答案，将其标准化为机器可读格式。随后，通过自动化定理证明技术（包括SMT求解和专门的物理问题项重写系统）来判断答案的正确性。该系统已在超过1500份2023年澳大利亚物理奥林匹克竞赛的真实学生答卷上进行了验证。

> **摘要翻译:** 我们提出了自动批改物理考试的方法。批改问题在于评估学生输入的答案相对于标准答案的正确性。这是一个具有挑战性的问题，我们试图通过结合计算机代数系统、SMT求解器和项重写系统来解决。大型语言模型用于解释和消除学生回答中的错误，并将其重写为机器可读的格式。一旦形式化并进行语言对齐，下一步便是应用自动化推理技术来评估学生解决方案的正确性。我们考虑了两种自动化定理证明方法：现成的SMT求解和为涉及三角表达式的物理问题量身定制的项重写系统。项重写系统的开发以及建立其终止性和合流性属性并非易事，我们在论文中对此进行了详细描述。我们使用来自2023年澳大利亚物理奥林匹克竞赛的1500多个真实学生考试答案的丰富池对我们的系统进行了评估。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [665] [Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios](https://arxiv.org/abs/2507.18368)
> *超越显而易见的推理：评估大型语言模型在金融场景中的发散性和收敛性思维*

*Zhuang Qiang Bok, Watson Wei Khong Chua* | **Category: cs.AI, I.2.0; I.2.6; J.4** | **Updated: 2025-07-24**

**Keywords:** LLMs, 金融场景, 发散性思维, 收敛性思维, 基准

**Comment:** Accepted by Agentic & GenAI Evaluation KDD2025: KDD workshop on
  Evaluation and Trustworthiness of Agentic and Generative AI Models
  https://kdd-eval-workshop.github.io/genai-evaluation-kdd2025/

> **TL;DR:** 引入了ConDiFi基准，用于评估大型语言模型在金融任务中的发散性和收敛性思维。研究发现，GPT-4o在新颖性和可操作性方面表现不佳，而DeepSeek-R1和Cohere Command R+等模型在生成可操作的投资见解方面表现出色。

**AI_Comments:** 这篇论文通过引入ConDiFi基准，解决了当前LLM评估中一个重要的空白，即缺乏对发散性和收敛性思维的全面评估。这对于金融等需要复杂决策和创新思考的领域尤为重要。ConDiFi的创新性在于其结合了宏观金融提示和多跳MCQ，更真实地模拟了金融专业人士的工作场景，对于推动LLM在金融领域的安全和战略部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大多数LLM推理基准侧重于事实准确性或循序渐进的逻辑，但在金融领域，专业人士不仅需要做出最优决策，还需要在不确定性下生成有创意、合理且可信的未来情景。因此，需要一个能同时评估LLM发散性和收敛性思维的基准。

**Method:** 研究引入了ConDiFi基准，该基准包含607个用于发散性推理的宏观金融提示和990个用于收敛性推理的多跳对抗性多项选择题。研究使用此基准评估了14个领先的大型语言模型。

**Result:** 评估结果显示模型之间存在显著差异。尽管GPT-4o具有高流畅性，但在新颖性和可操作性方面表现不佳。相比之下，DeepSeek-R1和Cohere Command R+等模型在生成适合投资决策的可操作性见解方面名列前茅。

**Conclusion:** ConDiFi基准为评估LLM在金融领域安全和战略部署所需的推理能力提供了新的视角。

> **ai_Abstract:** 该论文引入了ConDiFi，这是一个旨在评估大型语言模型（LLMs）在金融场景中发散性和收敛性思维的新基准。与传统侧重于事实准确性的基准不同，ConDiFi包含用于发散性推理的宏观金融提示和用于收敛性推理的多跳多项选择题。通过对14个领先模型的评估，研究发现模型之间存在显著差异：GPT-4o在生成新颖和可操作的见解方面表现不足，而DeepSeek-R1和Cohere Command R+等模型在提供可操作的投资决策见解方面表现出色。ConDiFi为评估LLM在金融领域安全和战略部署的关键推理能力提供了新的视角。

> **摘要翻译:** 大多数LLM推理基准强调事实准确性或循序渐进的逻辑。然而，在金融领域，专业人士不仅必须收敛于最优决策，还必须在不确定性下生成富有创意、合理可信的未来情景。我们引入了ConDiFi，这是一个联合评估LLM在金融任务中发散性和收敛性思维的基准。
ConDiFi包含607个用于发散性推理的宏观金融提示和990个用于收敛性推理的多跳对抗性多项选择题。利用这个基准，我们评估了14个领先的模型，并发现了惊人的差异。尽管GPT-4o具有高流畅性，但在新颖性和可操作性方面表现不佳。相比之下，DeepSeek-R1和Cohere Command R+等模型在生成适合投资决策的可操作性见解方面名列前茅。ConDiFi为评估LLM在金融领域安全和战略部署所需的推理能力提供了新的视角。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [667] [A Neuroscience-Inspired Dual-Process Model of Compositional Generalization](https://arxiv.org/abs/2507.18868)
> *受神经科学启发的组合泛化双过程模型*

*Alex Noviello, Claas Beger, Jacob Groner, Kevin Ellis, Weinan Sun* | **Category: cs.AI, cs.NE** | **Updated: 2025-07-25**

**Keywords:** 组合泛化, 双过程模型, 神经科学启发, Transformer, 模式学习

**Comment:** 

> **TL;DR:** 本文提出了MIRAGE框架，一个受神经科学启发的双过程模型，通过结合Transformer的直观模式识别和模式引擎的深思熟虑的模式应用，在组合泛化任务上实现了系统性泛化，并在SCAN基准测试中取得了超过99%的准确率。

**AI_Comments:** 本文的创新点在于将神经科学中的双过程理论（HPC-PFC循环和System 1/System 2）应用于AI的组合泛化问题，构建了一个名为MIRAGE的框架。通过分离直观的模式识别和深思熟虑的模式应用，模型在处理全新组合任务时表现出强大的泛化能力，且参数效率高。这种受生物学启发的架构为解决AI的结构化推理和泛化能力提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 系统性组合泛化——构建和理解已知构建块的新颖组合——仍然是AI系统面临的核心挑战。人类认知通过海马体（HPC）和前额叶皮层（PFC）的相互作用来实现这种灵活性。

**Method:** 本文提出了MIRAGE（Meta-Inference with Rules and Abstractions from Generalized Experience）框架，该框架在组合任务上实现了系统性泛化。MIRAGE包含两个交互模块，模仿大脑的深思熟虑的HPC-PFC循环和直觉的新皮层模式识别：
1. 元训练Transformer神经分解器：类似于新皮层“系统1”计算，在任务无关的随机采样组合语法流上训练，每次通过应用一步分解，通过连续通过迭代优化序列表示。
2. 模式引擎：类似于HPC-PFC“系统2”循环，动态提取、排序和应用可重用模式，将变量绑定存储在情景记忆中并在需要时扩展。通过明确地为MIRAGE的Transformer组件配备主动管理的图式结构，模型通过明确的图式应用和转换执行系统性组合操作，在解决全新任务时仅依赖冻结权重。

**Result:** MIRAGE方法在SCAN基准测试中展示了系统性组合泛化，在所有任务分割上实现了超过99%的准确率，且Transformer模块中仅有1.19M参数。消融研究证实，MIRAGE的系统性关键取决于提取模式的质量和模型的迭代优化过程。

**Conclusion:** 本文提出的受神经科学启发的双过程模型MIRAGE，通过结合直观的模式识别和深思熟虑的模式应用，有效解决了AI系统在组合泛化方面的核心挑战，并在实验中展现出卓越的性能和效率。

> **ai_Abstract:** 本文提出了一个受神经科学启发的双过程模型MIRAGE，旨在解决AI系统在系统性组合泛化方面的挑战。该模型模仿人类大脑中海马体和前额叶皮层的相互作用，结合了元训练Transformer神经分解器（“系统1”直觉）和模式引擎（“系统2”深思熟虑）。MIRAGE通过显式应用和转换模式，实现了在全新任务上仅依赖冻结权重的系统性组合操作。在SCAN基准测试中，MIRAGE在所有任务分割上取得了超过99%的准确率，并且Transformer模块参数量仅为1.19M，证明了其在组合泛化方面的有效性和高效性。

> **摘要翻译:** 系统性组合泛化——构建和理解已知构建块的新颖组合——仍然是人工智能系统的核心挑战。人类认知通过海马体（HPC）和前额叶皮层（PFC）的相互作用实现这种灵活性：海马体快速编码情景，前额叶皮层将其整合为可重用的模式用于推理。借鉴这些见解，我们提出了MIRAGE（Meta-Inference with Rules and Abstractions from Generalized Experience），一个在组合任务上实现系统性泛化的框架。MIRAGE具有两个交互模块，模仿大脑的深思熟虑的HPC-PFC循环和直觉的新皮层模式识别。(1) 元训练Transformer神经分解器，并行于新皮层“系统1”计算，在任务无关的随机采样组合语法流上训练，每次通过应用一步分解，通过连续通过迭代优化序列表示。(2) 模式引擎，类似于HPC-PFC“系统2”循环，动态提取、排序和应用可重用模式，将变量绑定存储在情景记忆中并在需要时扩展。通过明确地为MIRAGE的Transformer组件配备主动管理的图式结构，我们的模型通过明确的图式应用和转换执行系统性组合操作，在解决全新任务时仅依赖冻结权重。这种方法在SCAN基准测试中展示了系统性组合泛化，在所有任务分割上实现了超过99%的准确率，且Transformer模块中仅有1.19M参数。消融研究证实，MIRAGE的系统性关键取决于提取模式的质量和模型的迭代优化过程。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [707] [Revisiting LLM Reasoning via Information Bottleneck](https://arxiv.org/abs/2507.18391)
> *重新审视基于信息瓶颈的大语言模型推理*

*Shiye Lei, Zhihao Cheng, Kai Jia, Dacheng Tao* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 信息瓶颈, 大语言模型, 推理, 强化学习, 正则化

**Comment:** 

> **TL;DR:** 本文提出了一种基于信息瓶颈（IB）原理的理论框架IBRO，通过轻量级IB正则化改进LLM的推理能力，使其推理轨迹更具信息性和泛化性，并在数学推理任务上取得了持续改进。

**AI_Comments:** 这篇论文的创新点在于将信息瓶颈原理引入到大语言模型的推理优化中，为LLM的推理能力提升提供了一个理论上更为坚实的基础，而非仅仅依赖启发式方法。其提出的IB正则化方法不仅理论完备，而且具有轻量级、易于集成的优点（仅需一行代码修改），这对于实际应用和推广具有重要意义。通过鼓励推理轨迹的信息性和泛化性，该方法有望提升LLM在复杂推理任务上的鲁棒性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型（LLM）推理方法（如通过可验证奖励的强化学习RLVR）虽然取得了进展，但仍是启发式和直觉驱动的，缺乏原则性的方法论，限制了进一步发展。

**Method:** 本文提出了一种基于信息瓶颈（IB）原理的LLM推理理论表征，并引入了“IB感知推理优化”（IBRO）框架。该框架旨在鼓励推理轨迹既能提供关于最终正确答案的信息，又能对不同提示具有泛化性。具体实现上，推导了一个实用的token级替代目标，并提出了一个高效的近似方法，从而形成了轻量级的IB正则化方法。该方法可以无缝集成到现有的基于RL的后训练框架中，无需额外的计算开销，仅需一行代码修改。

**Result:** 在多个数学推理基准和强化学习算法上验证了IB正则化方法，结果表明其能持续提高LLM的推理性能。

**Conclusion:** 基于信息瓶颈原理的IB正则化方法能够有效提升大语言模型的推理能力，使其推理轨迹更具信息性和泛化性，且易于集成到现有框架中。

> **ai_Abstract:** 本文针对现有大语言模型（LLM）推理方法缺乏原则性问题，提出了一种基于信息瓶颈（IB）原理的理论框架——IB感知推理优化（IBRO）。IBRO旨在使LLM的推理轨迹既能有效指示最终答案，又能泛化到不同提示。通过推导实用的token级替代目标并进行高效近似，作者开发出一种轻量级的IB正则化方法，该方法可轻松集成到现有强化学习（RL）后训练框架中。实验证明，IB正则化在多个数学推理任务和RL算法上均能持续提升LLM的推理性能。

> **摘要翻译:** 大语言模型（LLM）最近通过可验证奖励的强化学习（RLVR）在推理能力方面取得了显著进展。通过利用简单的基于规则的奖励，强化学习有效地激励LLM生成扩展的思维链（CoT）推理轨迹，逐步引导它们走向正确答案。然而，现有方法在很大程度上仍然是启发式和直觉驱动的，限制了原则性方法论的发展。在本文中，我们提出了一种基于信息瓶颈（IB）原理的LLM推理理论表征，引入了IB感知推理优化（IBRO）框架，该框架鼓励推理轨迹既能提供关于最终正确答案的信息，又能对不同提示具有泛化性。我们推导了一个实用的token级替代目标，并提出了一个高效的近似方法，从而形成了轻量级的IB正则化方法。该技术可以无缝集成到现有的基于RL的后训练框架中，无需额外的计算开销，仅需一行代码修改。在经验上，我们在多个数学推理基准和RL算法上验证了IB正则化，证明了LLM推理性能的持续改进。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [716] [On the Structure of Game Provenance and its Applications](https://arxiv.org/abs/2410.05094)
> *关于博弈溯源的结构及其应用*

*Shawn Bowers, Yilin Xia, Bertram Ludäscher* | **Category: cs.AI** | **Updated: 2025-07-23**

**Keywords:** 博弈溯源, 一阶查询, 溯源模型, 博弈论, 抽象论证框架

**Comment:** 

> **TL;DR:** 本文深入研究了博弈溯源的精细结构，为一阶查询提供了一种基于博弈论的自然溯源模型，并引入了潜在、实际和主要等新型溯源。

**AI_Comments:** 本文创新性地将博弈论视角应用于数据库溯源，特别是一阶查询的溯源。通过剖析博弈溯源的“精细结构”并识别基于边的新型溯源（潜在、实际、主要），它提供了对查询结果“如何”和“为什么不”的更深层次理解。洞察到“并非所有移动都是平等的”表明了一种分析博弈动态的细致方法，并可能优化查询评估或理解数据依赖性。其在抽象论证框架中的应用也表明了其超越传统数据库上下文的更广泛相关性。

<details>
  <summary>Details</summary>

**Motivation:** 数据库中的溯源研究已涵盖肯定查询、递归查询和一阶查询。查询评估可被视为一场两人博弈，这种博弈论方法为一阶查询提供了自然的溯源模型，统一了“如何”和“为什么不”的溯源。本文旨在深入研究博弈溯源的精细结构。

**Method:** 本文采用博弈论方法，将查询评估理解为两人博弈。通过计算单个不可分层规则（win(X) <- move(X, Y), ~win(Y)）的良基模型来解决博弈。研究识别了七种边类型，这些类型产生了新型溯源，并描述了在解决博弈时如何计算这些新型溯源。

**Result:** 识别了七种边类型，产生了潜在溯源、实际溯源和主要溯源等新型溯源。研究证明了“并非所有移动都是平等的”。

**Conclusion:** 本文描述了源自博弈溯源精细结构的新型溯源（潜在、实际、主要），展示了它们的可计算性，并讨论了其应用，例如在抽象论证框架中。

> **ai_Abstract:** 本文深入探讨了博弈溯源的精细结构，该模型基于查询评估的博弈论视角，为一阶查询提供了一种自然的溯源方法。通过运用特定的良基模型规则解决博弈，作者识别出七种边类型，并由此衍生出潜在、实际和主要等新型溯源。研究不仅详细描述了这些新型溯源及其在博弈解决过程中的计算方法，还探讨了它们的应用，并强调了不同移动对博弈结果贡献的不等性。

> **摘要翻译:** 数据库中的溯源已针对肯定查询和递归查询进行了深入研究，然后是针对一阶（FO）查询，即包含否定但没有递归的查询。查询评估可以理解为一场两人游戏，其中对手争论某个元组是否在查询答案中。这种博弈论方法为FO查询提供了一个自然的溯源模型，统一了“如何”和“为什么不”的溯源。本文研究了博弈溯源的精细结构。一个博弈$G=(V,E)$由位置$V$和移动$E$组成，可以通过计算单个不可分层规则的良基模型来解决：\[ \text{win}(X) \leftarrow \text{move}(X, Y), \neg \, \text{win}(Y). \] 在已解决的博弈$G^{\lambda}$中，位置$x\,{\in}\,V$的值要么是赢、输，要么是平局。这个值由溯源$\mathscr{P}$(x)解释，即从$x$可达的某些（带注释的）边。我们识别了七种边类型，它们产生了新型溯源，即潜在溯源、实际溯源和主要溯源，并证明了“并非所有移动都是平等的”。我们描述了这些新型溯源，展示了它们如何在解决博弈时计算，并讨论了其应用，例如在抽象论证框架中。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [743] [Optimising Call Centre Operations using Reinforcement Learning: Value Iteration versus Proximal Policy Optimisation](https://arxiv.org/abs/2507.18398)
> *使用强化学习优化呼叫中心运营：价值迭代对比近端策略优化*

*Kwong Ho Li, Wathsala Karunarathne* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 强化学习, 呼叫中心, 价值迭代, 近端策略优化, 马尔可夫决策过程

**Comment:** 10 pages

> **TL;DR:** 本研究比较了两种强化学习方法（价值迭代和近端策略优化）在优化呼叫中心路由方面的表现，结果显示PPO在减少客户等待时间和员工空闲时间方面表现最佳，尽管训练时间更长。

**AI_Comments:** 该论文通过比较两种主流强化学习方法（VI和PPO）在呼叫中心优化这一实际问题上的表现，具有重要的实践意义。其创新之处在于将DES与OpenAI Gym结合用于无模型学习，为复杂系统优化提供了一个可行的仿真平台。PPO的优越性能展示了其在动态环境下的潜力，但较长的训练时间是其应用中需要考虑的限制。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在优化呼叫中心运营中的呼叫路由，以最大程度地减少客户等待时间和员工空闲时间。

**Method:** 研究比较了两种强化学习方法：一种是基于模型的价值迭代（VI），在已知系统动态下进行；另一种是无模型的近端策略优化（PPO），通过经验学习。问题被建模为技能路由（SBR）框架内的马尔可夫决策过程（MDP）。基于模型的方法使用理论模型，而无模型学习则开发了一个结合离散事件仿真（DES）和OpenAI Gym环境的仿真模型。客户到达遵循泊松分布，服务和放弃时间遵循指数分布。

**Result:** 经过1,000次测试回合后，PPO始终获得最高奖励，同时客户等待时间最短，员工空闲时间也最低，尽管其训练时间更长。

**Conclusion:** PPO在优化呼叫中心运营方面优于价值迭代，能够有效减少客户等待时间和员工空闲时间，是更优的强化学习策略。

> **ai_Abstract:** 本研究探讨了强化学习在优化呼叫中心呼叫路由中的应用，旨在减少客户等待时间和员工空闲时间。论文比较了基于模型的价值迭代（VI）和无模型的近端策略优化（PPO）两种方法。问题被建模为马尔可夫决策过程（MDP），并结合离散事件仿真（DES）和OpenAI Gym环境进行模拟。实验结果表明，PPO在获得更高奖励、缩短客户等待时间和减少员工空闲时间方面表现优异，尽管其训练时间较长。

> **摘要翻译:** 本文研究了强化学习（RL）在优化呼叫中心呼叫路由中的应用，以最小化客户等待时间和员工空闲时间。比较了两种方法：一种是基于模型的、在已知系统动态下使用价值迭代（VI）的方法，另一种是无模型的、通过经验学习的近端策略优化（PPO）方法。对于基于模型的方法，使用了理论模型；而对于无模型学习，开发了一个结合离散事件仿真（DES）和OpenAI Gym环境的仿真模型。两种模型都在技能路由（SBR）框架内将问题构建为马尔可夫决策过程（MDP），其中客户到达遵循泊松分布，服务和放弃时间遵循指数分布。在策略评估方面，使用仿真模型评估了随机策略、VI策略和PPO策略。经过1,000次测试回合后，尽管需要更长的训练时间，PPO始终获得最高奖励，同时客户等待时间最短，员工空闲时间也最低。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [764] [Retrieving Classes of Causal Orders with Inconsistent Knowledge Bases](https://arxiv.org/abs/2412.14019)
> *从不一致知识库中检索因果序类别*

*Federico Baldo, Simon Ferreira, Charles K. Assaad* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 因果发现, 大型语言模型, 因果序, 一致性测量, 无环竞赛图

**Comment:** 

> **TL;DR:** 本文提出一种新方法，通过最大化LLM得出的因果一致性分数，从不一致知识库中恢复因果序类别，以克服传统因果发现方法的局限性。

**AI_Comments:** 本文的创新点在于将大型语言模型（LLMs）与因果发现相结合，并提出了一种机制来处理LLM的不可靠性和幻觉问题，即通过一致性测量。此外，将研究重点从复杂的因果DAGs转移到更易于处理和鲁棒的因果序，也是一个实用的贡献。该方法提供了一种从不一致文本数据中提取因果知识的有效途径，对于实际应用，尤其是在领域专业知识丰富的场景下，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的因果发现方法依赖于不可靠的强假设；大型语言模型（LLMs）虽有潜力提取因果知识，但存在不可靠性和幻觉问题；文本元数据难以区分直接和间接因果关系，使得发现因果DAG变得复杂。

**Method:** 提出一种新方法，通过最大化从LLM获得的因果一致性分数，来推导一系列无环竞赛图（代表合理的因果顺序）。该方法首先计算变量间的成对一致性分数，生成一个半完全偏向图，并将这些分数整合为最大一致因果序的抽象。利用该结构，识别出最优的无环竞赛图，并展示如何使用这些抽象和因果序来估计因果效应。

**Result:** 该方法在基准测试和流行病学、公共卫生领域的真实世界数据上进行了测试，结果证明了其在恢复正确因果序方面的有效性。

**Conclusion:** 本文提出了一种有效且鲁棒的方法，通过利用LLM的一致性测量来克服其局限性，并从不一致知识库中识别出可靠的因果序类别，从而可以用于估计因果效应。

> **ai_Abstract:** 本文针对传统因果发现方法和LLM在因果知识提取中的局限性，提出了一种新颖的因果序发现方法。该方法通过最大化LLM生成的一致性分数，从不一致知识库中推导出一系列无环竞赛图，以表示可靠的因果序。通过计算成对一致性分数并构建抽象图，该方法能识别出最优的因果序，并可用于因果效应估计。实验结果表明，该方法在恢复正确因果序方面表现出有效性。

> **摘要翻译:** 传统的因果发现方法通常依赖于强而无法检验的假设，这使得它们在实际应用中不可靠。在这种背景下，大型语言模型（LLMs）作为从基于文本的元数据中提取因果知识的一种有前景的替代方案而出现，这些元数据整合了领域专业知识。然而，LLMs往往不可靠且容易产生幻觉，因此需要考虑其局限性的策略。一种有效的策略是使用一致性度量来评估可靠性。此外，大多数文本元数据并未明确区分直接因果关系和间接因果关系，这进一步使得因果有向无环图（DAG）的发现复杂化。因此，关注因果序而非因果DAGs，成为一种更实用和稳健的方法。我们提出了一种新方法，用于推导一类无环竞赛图，这些图代表了合理的因果序，并最大化了从LLM得出的一个一致性分数。我们的方法首先计算变量间的成对一致性分数，生成一个半完全偏向图，该图将这些分数整合为最大一致因果序的抽象。利用这种结构，我们识别出最优的无环竞赛图，重点关注那些在所有配置中最大化一致性的图。我们随后展示了抽象和因果序如何用于估计因果效应。我们在成熟的基准数据集以及流行病学和公共卫生领域的真实世界数据集上测试了我们的方法。我们的结果证明了该方法在恢复正确因果序方面的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [785] [GPU Accelerated Compact-Table Propagation](https://arxiv.org/abs/2507.18413)
> *GPU加速紧凑表传播*

*Enrico Santi, Fabio Tardivo, Agostino Dovier, Andrea Formisano* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** GPU加速, 紧凑表, 约束编程, 表约束, 传播算法

**Comment:** Under consideration in Theory and Practice of Logic Programming
  (TPLP)

> **TL;DR:** 本文通过利用GPU的强大计算能力，加速了紧凑表（Compact-Table）传播算法，以有效处理大型表约束问题。

**AI_Comments:** 这项工作具有重要的创新性，它将GPU的并行计算能力引入到约束编程领域，特别是针对表约束的传播算法。这有望显著提高处理大规模约束问题的效率，解决传统CPU方法在面对大数据量时的瓶颈。其重要性在于为实时或大规模约束求解提供了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于CPU的方法难以有效处理包含数百或数千个有效案例的真实世界问题，因为这些表约束问题规模过大。

**Method:** 本文描述了如何利用现代GPU的强大计算能力来增强Compact-Table (CT)算法，以处理大型表约束。具体报告了GPU加速CT的设计、实现及其集成到现有约束求解器中。

**Result:** 在一组重要的实例上进行了实验验证。

**Conclusion:** 通过利用GPU加速Compact-Table算法，可以有效处理大型表约束问题。

> **ai_Abstract:** 本文探讨了如何通过利用现代GPU的强大计算能力来加速紧凑表（Compact-Table, CT）传播算法，以有效处理大规模的表约束问题。表约束在约束编程中至关重要，但传统的CPU方法在处理包含大量案例的现实问题时效率低下。作者详细介绍了GPU加速CT的设计、实现以及将其集成到现有约束求解器中的过程，并通过实验验证了其在处理大量实例时的有效性。

> **摘要翻译:** 约束编程在八十年代从逻辑编程中发展而来；如今，所有的Prolog系统都包含能够处理有限域约束编程的模块，这些模块要求其解决方案由约束求解器提供。本研究侧重于一种特定形式的约束，即所谓的表约束，它用于将变量值的条件指定为替代选项的枚举。由于有限域变量集上的每个条件最终都可以表示为有限的案例集，因此原则上表约束可以模拟任何其他约束。这些特性使得表约束成为有史以来研究最多的约束之一，从而产生了一系列效率不断提高的传播算法。尽管如此，在现实世界中遇到包含数百或数千个有效案例的问题并不少见，这些问题对于标准的基于CPU的方法来说，数量实在太多，无法有效处理。在本文中，我们处理紧凑表（Compact-Table，CT）算法，这是表约束的最新传播算法。我们描述了如何通过利用现代GPU提供的强大计算能力来增强CT，以处理大型表约束。特别是，我们报告了GPU加速CT的设计和实现，它集成到现有约束求解器中，以及在大量实例上进行的实验验证。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [806] [HPS: Hard Preference Sampling for Human Preference Alignment](https://arxiv.org/abs/2502.14400)
> *HPS：用于人类偏好对齐的硬偏好采样*

*Xiandong Zou, Wanyu Lin, Yuchen Li, Pan Zhou* | **Category: cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大语言模型, 人类偏好对齐, 硬偏好采样, 有害内容, 计算效率

**Comment:** 

> **TL;DR:** HPS是一种新的LLM偏好对齐框架，通过优先处理偏好响应并拒绝不偏好和有害响应，同时强调“硬”不偏好响应，以提高效率和安全性，解决了现有方法处理有害内容差和计算成本高的问题。

**AI_Comments:** HPS的创新点在于其独特的损失函数设计，特别是对“硬”非偏好响应的强调，这有助于模型更精准地学习如何拒绝相似但有害或不理想的内容。此外，单样本蒙特卡洛采样策略有效解决了现有Plackett-Luce方法计算成本高的问题，提高了效率。该方法对于构建更安全、更可控的LLM具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型（LLM）偏好优化方法（如Plackett-Luce和Bradley-Terry模型）在处理有害内容、低效利用非偏好响应以及高计算成本（特别是Plackett-Luce模型）方面存在挑战。

**Method:** 本文提出了硬偏好采样（HPS）框架，用于鲁棒高效的人类偏好对齐。HPS引入了一种训练损失，该损失优先选择最偏好的响应，同时拒绝所有非偏好和有害的响应。它强调“硬”的非偏好响应（那些与偏好响应非常相似的），以增强模型的拒绝能力。通过利用单样本蒙特卡洛采样策略，HPS降低了计算开销，同时保持了对齐质量。

**Result:** 在HH-RLHF和PKU-Safety数据集上的实验验证了HPS的有效性，实现了与现有方法相当的BLEU和奖励分数，同时大大改善了奖励裕度，从而减少了有害内容的生成。理论上，HPS提高了现有Plackett-Luce方法的样本效率，并最大化了偏好和非偏好响应之间的奖励裕度，确保了更清晰的区别。

**Conclusion:** HPS是一种有效且高效的LLM人类偏好对齐框架，它通过独特的采样和损失机制，在保持对齐质量的同时，显著提高了有害内容的拒绝能力，并降低了计算成本。

> **ai_Abstract:** 本文提出了一种名为硬偏好采样（HPS）的新型框架，旨在解决现有大语言模型（LLM）偏好对齐方法在处理有害内容、低效利用非偏好响应及高计算成本方面的不足。HPS通过引入一种特殊的训练损失，优先选择最偏好响应并拒绝有害及非偏好响应，尤其关注“硬”非偏好样本以增强模型拒绝能力。结合单样本蒙特卡洛采样，HPS在降低计算开销的同时保持了对齐质量。理论分析表明其提高了样本效率并增大了奖励裕度，实验结果在HH-RLHF和PKU-Safety数据集上验证了HPS能有效减少有害内容生成，并取得了与现有方法相当的性能。

> **摘要翻译:** 将大型语言模型（LLM）的响应与人类偏好对齐对于构建安全可控的AI系统至关重要。虽然基于Plackett-Luce（PL）和Bradley-Terry（BT）模型的偏好优化方法已显示出前景，但它们面临挑战，例如对有害内容处理不佳、对非偏好响应利用效率低下，特别是对于PL模型，计算成本高昂。为了解决这些问题，我们提出了硬偏好采样（HPS），这是一种用于鲁棒高效人类偏好对齐的新颖框架。HPS引入了一种训练损失，该损失优先考虑最偏好的响应，同时拒绝所有非偏好和有害的响应。它强调“硬”的非偏好响应——那些与偏好响应非常相似的——以增强模型的拒绝能力。通过利用单样本蒙特卡洛采样策略，HPS降低了计算开销，同时保持了对齐质量。理论上，HPS提高了现有PL方法的样本效率，并最大化了偏好和非偏好响应之间的奖励裕度，确保了更清晰的区别。在HH-RLHF和PKU-Safety数据集上的实验验证了HPS的有效性，实现了可比的BLEU和奖励分数，同时大大改善了奖励裕度，从而减少了有害内容的生成。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [827] [On the Performance of Concept Probing: The Influence of the Data (Extended Version)](https://arxiv.org/abs/2507.18550)
> *关于概念探测的性能：数据的影响（扩展版）*

*Manuel de Sousa Ribeiro, Afonso Leote, João Leite* | **Category: cs.AI, cs.CV, cs.LG, cs.NE** | **Updated: 2025-07-24**

**Keywords:** 概念探测, 神经网络解释, 数据影响, 图像分类, 可解释AI

**Comment:** Extended version of the paper published in Proceedings of the
  European Conference on Artificial Intelligence (ECAI 2025)

> **TL;DR:** 本文研究了用于训练探测模型的数据对概念探测性能的影响，并为两个常用数据集提供了概念标签。

**AI_Comments:** 这篇论文的创新点在于它关注了概念探测中被忽视的数据维度，填补了现有研究的空白。它强调了数据质量和选择对探测模型性能的重要性，这对于提高神经网络的可解释性具有实际意义。提供新的概念标签数据集也为后续研究提供了有价值的资源。

<details>
  <summary>Details</summary>

**Motivation:** 解释人工神经网络（ANNs）因其规模大和亚符号性质而难以直接进行人工解读。概念探测作为一种解释方法受到关注，但现有研究主要关注被探测模型或探测模型本身，而忽略了训练探测模型所需数据的影响。

**Method:** 本文通过训练额外的分类器将模型的内部表示映射到人类定义的兴趣概念中，从而实现对人工神经网络的内部窥探。研究特别关注图像分类任务中的概念探测，并调查了用于训练探测模型的数据对其性能的影响。

**Result:** 论文研究了数据对概念探测模型性能的影响。此外，还提供了两个常用数据集的概念标签。

**Conclusion:** 本文填补了概念探测研究中对训练数据关注不足的空白，强调了数据对探测模型性能的重要性，并提供了有助于未来研究的数据集标签。

> **ai_Abstract:** 本文探讨了概念探测的性能，特别是训练探测模型所用数据的影响，以解决当前研究中对数据方面关注不足的空白。研究聚焦于图像分类任务，并分析了数据对探测模型性能的作用。此外，作者还公开了两个常用数据集的概念标签，以促进相关研究。

> **摘要翻译:** 概念探测最近作为一种帮助解释人工神经网络的方法引起了越来越多的兴趣，它处理了神经网络通常庞大的规模和亚符号性质，这些最终使得它们无法直接进行人工解释。概念探测通过训练额外的分类器将模型的内部表示映射到人类定义的兴趣概念中，从而允许人类“窥探”人工神经网络的内部。概念探测的研究主要集中在被探测的模型或探测模型本身，对训练这些探测模型所需的数据关注有限。在本文中，我们解决了这一空白。我们专注于图像分类任务中的概念探测，研究了用于训练探测模型的数据对其性能的影响。我们还为两个广泛使用的数据集提供了概念标签。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [842] [From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems](https://arxiv.org/abs/2503.01424)
> *从假设到发表：AI驱动研究支持系统的综合调查*

*Zekun Zhou, Xiaocheng Feng, Lei Huang, Xiachong Feng, Ziyun Song, Ruihan Chen, Liang Zhao, Weitao Ma, Yuxuan Gu, Baoxin Wang, Dayong Wu, Guoping Hu, Ting Liu, Bing Qin* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 人工智能, 研究支持系统, 系统综述, 假设生成, 论文发表

**Comment:** 

> **TL;DR:** 本文对AI在研究过程中的应用进行了系统性综述，涵盖从假设提出到论文发表的各个阶段，并讨论了挑战、未来方向、基准和工具。

**AI_Comments:** 这篇综述文章非常有价值，因为它系统地梳理了AI在整个研究生命周期中的应用，从最初的假设构建到最终的论文发表。其创新之处在于将复杂的科研流程划分为清晰的阶段，并逐一探讨AI的介入点，这为研究人员和AI开发者提供了清晰的路线图。文章不仅总结了现有进展，还指出了挑战和未来方向，对于推动AI在科学研究中的实际应用具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究过程耗时耗力，AI的快速发展激发了利用AI加速和增强研究的探索，因此需要对该领域的进展进行系统性监测和回顾。

**Method:** 本文通过系统性综述的方法，将相关研究分为假设提出、假设验证和手稿发表三个主要类别进行组织和讨论。

**Result:** 论文将AI在研究中的应用分为三大类：假设提出（知识综合、假设生成）、假设验证（科学主张验证、定理证明、实验验证）和手稿发表（手稿撰写、同行评审）。此外，还识别并讨论了当前面临的挑战、未来的研究方向，并概述了现有基准和工具。

**Conclusion:** 本文旨在为初学者提供入门指导，并促进该领域的未来研究，同时公开了相关资源。

> **ai_Abstract:** 本文对人工智能（AI）在研究支持系统中的应用进行了全面的系统性综述。作者将AI在研究过程中的作用划分为假设提出、假设验证和手稿发表三大阶段，并详细阐述了每个阶段的具体应用。此外，论文还探讨了当前面临的挑战、未来的发展方向，并提供了现有基准和工具的概览。该研究旨在为AI辅助研究领域提供入门指导，并鼓励未来的探索。

> **摘要翻译:** 研究是推动人类文明进步的基础过程，但它需要研究人员投入大量时间和精力。近年来，人工智能（AI）技术的快速发展激发了研究人员探索如何利用AI加速和增强研究。为了监测相关进展，本文对该领域的进展进行了系统性综述。具体而言，我们将相关研究分为三大类：假设提出、假设验证和手稿发表。假设提出涉及知识综合和假设生成。假设验证包括科学主张的验证、定理证明和实验验证。手稿发表涵盖手稿撰写和同行评审过程。此外，我们还识别并讨论了这些领域当前面临的挑战，以及未来潜在的研究方向。最后，我们还全面概述了支持AI融入研究过程的现有基准和工具。我们希望本文能为初学者提供入门指导，并促进未来的研究。相关资源已在https://github.com/zkzhou126/AI-for-Research 公开。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [874] [SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\circ}$ Law](https://arxiv.org/abs/2507.18576)
> *SafeWork-R1：在AI-45°定律下安全与智能的协同演化*

*Shanghai AI Lab, :, Yicheng Bao, Guanxu Chen, Mingkang Chen, Yunhao Chen, Chiyu Chen, Lingjie Chen, Sirui Chen, Xinquan Chen, Jie Cheng, Yu Cheng, Dengke Deng, Yizhuo Ding, Dan Ding, Xiaoshan Ding, Yi Ding, Zhichen Dong, Lingxiao Du, Yuyu Fan, Xinshun Feng, Yanwei Fu, Yuxuan Gao, Ruijun Ge, Tianle Gu, Lujun Gui, Jiaxuan Guo, Qianxi He, Yuenan Hou, Xuhao Hu, Hong Huang, Kaichen Huang, Shiyang Huang, Yuxian Jiang, Shanzhe Lei, Jie Li, Lijun Li, Hao Li, Juncheng Li, Xiangtian Li, Yafu Li, Lingyu Li, Xueyan Li, Haotian Liang, Dongrui Liu, Qihua Liu, Zhixuan Liu, Bangwei Liu, Huacan Liu, Yuexiao Liu, Zongkai Liu, Chaochao Lu, Yudong Lu, Xiaoya Lu, Zhenghao Lu, Qitan Lv, Caoyuan Ma, Jiachen Ma, Xiaoya Ma, Zhongtian Ma, Lingyu Meng, Ziqi Miao, Yazhe Niu, Yuezhang Peng, Yuan Pu, Han Qi, Chen Qian, Xingge Qiao, Jingjing Qu, Jiashu Qu, Wanying Qu, Wenwen Qu, Xiaoye Qu, Qihan Ren, Qingnan Ren, Qingyu Ren, Jing Shao, Wenqi Shao, Shuai Shao, Dongxing Shi, Xin Song, Xinhao Song, Yan Teng, Xuan Tong, Yingchun Wang, Xuhong Wang, Shujie Wang, Xin Wang, Yige Wang, Yixu Wang, Yuanfu Wang, Futing Wang, Ruofan Wang, Wenjie Wang, Yajie Wang, Muhao Wei, Xiaoyu Wen, Fenghua Weng, Yuqi Wu, Yingtong Xiong, Xingcheng Xu, Chao Yang, Yue Yang, Yang Yao, Yulei Ye, Zhenyun Yin, Yi Yu, Bo Zhang, Qiaosheng Zhang, Jinxuan Zhang, Yexin Zhang, Yinqiang Zheng, Hefeng Zhou, Zhanhui Zhou, Pengyu Zhu, Qingzi Zhu, Yubo Zhu, Bowen Zhou* | **Category: cs.AI, cs.CL, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 多模态推理, AI安全, 协同演化, 强化学习, SafeLadder

**Comment:** 47 pages, 18 figures, authors are listed in alphabetical order by
  their last names

> **TL;DR:** SafeWork-R1是一个多模态推理模型，通过SafeLadder框架实现了能力和安全的协同演化，在安全基准测试上表现出色，并优于现有领先模型。

**AI_Comments:** SafeWork-R1的创新之处在于其SafeLadder框架，它超越了传统的RLHF方法，使得模型能够发展出内在的安全推理和自我反思能力，实现了安全和能力的协同演化，而非简单的偏好学习。这对于构建真正可靠和值得信赖的通用AI具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决现有对齐方法（如RLHF）仅学习人类偏好而未能使模型发展出内在安全推理和自我反思能力的问题，并实现安全与能力的协同演化。

**Method:** 本文引入了SafeWork-R1多模态推理模型，通过提出的SafeLadder框架开发。SafeLadder框架包含大规模、渐进式、面向安全的强化学习后训练，并由一套多原则验证器支持。此外，还实施了两种不同的推理时干预方法和一种审慎搜索机制，以强制执行步骤级验证。

**Result:** SafeWork-R1在安全相关基准测试上比其基础模型Qwen2.5-VL-72B平均提升了46.54%，且未损害通用能力。与GPT-4.1和Claude Opus 4等领先专有模型相比，它提供了最先进的安全性能。此外，SafeWork-R1-InternVL3-78B、SafeWork-R1-DeepSeek-70B和SafeWork-R1-Qwen2.5VL-7B等模型也证明了安全和能力可以协同演化。

**Conclusion:** 安全与能力可以协同演化，本文提出的框架在构建鲁棒、可靠和值得信赖的通用AI方面具有通用性。

> **ai_Abstract:** 本文介绍了SafeWork-R1，一个多模态推理模型，旨在实现AI能力与安全的协同演化。该模型通过SafeLadder框架开发，该框架采用大规模、渐进式、面向安全的强化学习后训练和多原则验证器，使其能够发展出内在的安全推理和自我反思能力。SafeWork-R1在安全基准测试上表现出色，相较于基准模型有显著提升，并达到了领先模型的水平，同时不牺牲通用能力。研究还通过推理时干预和审慎搜索机制增强其可靠性，并证明该框架在不同模型上的通用性，强调了安全与能力协同演化的可行性，以构建可靠的通用AI。

> **摘要翻译:** 我们引入了SafeWork-R1，一个尖端的多模态推理模型，展示了能力和安全的协同演化。它通过我们提出的SafeLadder框架开发，该框架结合了大规模、渐进式、面向安全的强化学习后训练，并由一套多原则验证器支持。与之前仅学习人类偏好的对齐方法（如RLHF）不同，SafeLadder使SafeWork-R1能够发展出内在的安全推理和自我反思能力，从而产生安全“顿悟”时刻。值得注意的是，SafeWork-R1在安全相关基准测试上比其基础模型Qwen2.5-VL-72B平均提升了46.54%，且未损害通用能力，并且与GPT-4.1和Claude Opus 4等领先专有模型相比，提供了最先进的安全性能。为了进一步增强其可靠性，我们实施了两种不同的推理时干预方法和一种审慎搜索机制，强制执行步骤级验证。最后，我们进一步开发了SafeWork-R1-InternVL3-78B、SafeWork-R1-DeepSeek-70B和SafeWork-R1-Qwen2.5VL-7B。所有由此产生的模型都表明安全和能力可以协同演化，突出了我们框架在构建鲁棒、可靠和值得信赖的通用AI方面的通用性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [3] [Deep learning-aided inverse design of porous metamaterials](https://arxiv.org/abs/2507.17907)
> *深度学习辅助多孔超材料的逆向设计*

*Phu Thien Nguyen, Yousef Heider, Dennis M. Kochmann, Fadi Aldakheel* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 深度学习, 逆向设计, 多孔超材料, 变分自编码器, 水力性能

**Comment:** 31 pages, 29 figures

> **TL;DR:** 该研究利用基于深度学习的生成框架（pVAE）实现了多孔超材料的逆向设计，能生成具有特定水力性能的材料，并显著降低了计算成本。

**AI_Comments:** 这项研究的创新之处在于将深度学习（特别是pVAE）应用于多孔超材料的逆向设计，能够高效生成具有定制水力性能的材料。通过引入CNN辅助预测水力性能，显著降低了计算成本，提高了设计的效率。潜在空间的分析和利用也为结构-属性关系提供了可解释性。此外，数据集和代码的开放获取将极大地促进该领域未来的研究。

<details>
  <summary>Details</summary>

**Motivation:** 探索使用基于深度学习的生成框架对多孔超材料进行逆向设计，以生成具有特定水力性能的材料。

**Method:** 开发了一种名为属性变分自编码器（pVAE）的变分自编码器（VAE），并结合了回归器。利用格子玻尔兹曼方法（LBM）生成固有渗透率张量数据，并训练卷积神经网络（CNN）来预测有效水力性能，以降低计算成本。pVAE框架在合成数据集和真实开孔泡沫的CT扫描图像数据集上进行训练。研究还对VAE的潜在空间进行了分析和解释，以实现结构-属性映射、插值和逆向设计。

**Result:** 成功开发了pVAE框架，能够生成具有定制水力性能（如孔隙率和渗透率）的结构化超材料。与直接LBM模拟相比，通过CNN预测水力性能显著降低了计算成本。潜在空间被证明在结构-属性映射、插值和逆向设计中发挥关键作用，促进了具有所需性能的新超材料的生成。

**Conclusion:** 该方法能够促进具有所需性能的新型超材料的生成，并通过深度学习显著提高了多孔超材料逆向设计的效率和可行性。

> **ai_Abstract:** 本研究提出了一种基于深度学习的生成框架——属性变分自编码器（pVAE），用于多孔超材料的逆向设计。该框架结合了VAE和回归器，并通过CNN预测水力性能，以生成具有特定孔隙率和渗透率的超材料，显著降低了计算成本。研究利用合成数据和真实CT扫描数据进行训练，并详细分析了潜在空间在结构-属性映射和逆向设计中的作用，有效促进了新型超材料的生成。

> **摘要翻译:** 本研究的最终目标是探索使用基于深度学习的生成框架对多孔超材料进行逆向设计。具体而言，我们开发了一种属性变分自编码器（pVAE），它是一种增强了回归器的变分自编码器（VAE），用于生成具有定制水力性能（如孔隙率和渗透率）的结构化超材料。虽然这项工作使用格子玻尔兹曼方法（LBM）为有限的多孔微结构生成固有渗透率张量数据，但通过自下而上的方法训练了一个卷积神经网络（CNN）来预测有效的液压性能。与直接LBM模拟相比，这显著降低了计算成本。pVAE框架在两个数据集上进行训练：一个是人工多孔微结构的合成数据集，另一个是真实开孔泡沫的体积元素的CT扫描图像。VAE的编码器-解码器架构捕获了关键的微结构特征，将其映射到一个紧凑且可解释的潜在空间中，以实现高效的结构-属性探索。本研究对潜在空间进行了详细的分析和解释，展示了其在结构-属性映射、插值和逆向设计中的作用。这种方法促进了具有所需性能的新型超材料的生成。本研究中使用的数据集和代码将开放获取，以支持进一步的研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [7] [TOC-UCO: a comprehensive repository of tabular ordinal classification datasets](https://arxiv.org/abs/2507.17348)
> *TOC-UCO：一个综合的表格序数分类数据集存储库*

*Rafael Ayllón-Gavilán, David Guijo-Rubio, Antonio Manuel Gómez-Orellana, Francisco Bérchez-Moreno, Víctor Manuel Vargas-Yun, Pedro A. Gutiérrez* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 序数分类, 数据集, 存储库, 基准测试, 可复现性

**Comment:** 25 single column pages, 5 figures, 7 tables

> **TL;DR:** TOC-UCO 是一个包含了46个预处理过的表格序数分类数据集的公共存储库，旨在解决序数分类领域缺乏综合基准数据集的问题，并促进新方法的验证和实验复现。

**AI_Comments:** TOC-UCO存储库解决了序数分类领域的一个关键痛点，即缺乏标准化和全面的数据集用于方法评估。其创新之处在于提供了统一预处理的数据集和预定义的训练-测试分区，这将极大地促进新OC方法的开发、公平比较和实验复现性，对整个领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 序数分类（OC）问题在许多实际应用中都有出现，但该领域的发展面临一个主要缺点：缺乏一个全面的数据集，用于对文献中的新方法进行基准测试。

**Method:** 本手稿创建了一个名为TOC-UCO的公共可用表格数据存储库，用于稳健地验证新颖的序数分类方法。该存储库包含46个表格序数数据集，这些数据集在一个通用框架下进行了预处理，并确保具有合理的模式数量和适当的类别分布。此外，还提供了每个数据集的来源、预处理步骤以及如何使用TOC-UCO存储库对新方法进行基准测试的详细信息，包括30个不同随机训练-测试分区的索引，以促进实验的可复现性。

**Result:** TOC-UCO存储库包含了46个经过统一预处理的表格序数分类数据集，这些数据集具有合理的模式数量和适当的类别分布。它还提供了每个数据集的来源、预处理步骤，以及用于基准测试的详细指南，包括30个随机训练-测试分区的索引，以确保实验的可复现性。

**Conclusion:** TOC-UCO存储库的创建旨在弥补序数分类领域缺乏综合基准数据集的不足，为新方法的开发和验证提供一个标准化、可复现的平台。

> **ai_Abstract:** 本文介绍了TOC-UCO，一个旨在解决序数分类领域缺乏综合基准数据集问题的公共存储库。该存储库包含46个经过统一预处理的表格序数数据集，并提供了每个数据集的来源、预处理步骤以及30个随机训练-测试分区的索引，以促进新方法的稳健验证和实验的可复现性。

> **摘要翻译:** 序数分类（OC）问题对应于一种特殊类型的分类，其特点是类别之间存在自然的顺序关系。这种类型的问题可以在许多实际应用中找到，这促使在过去几年中设计和开发了许多序数方法。然而，重要的是要强调，OC领域的发展面临一个主要缺点：缺乏一个全面的数据集，用于对文献中的新方法进行基准测试。为了实现这一目标，这份来自科尔多瓦大学（UCO）的手稿，凭借其在OC领域的先前经验，为文献提供了一个公开可用的表格数据存储库，用于稳健验证新颖的OC方法，即TOC-UCO（UCO的表格序数分类存储库）。具体来说，该存储库包括一套46个表格序数数据集，这些数据集在一个通用框架下进行了预处理，并确保具有合理的模式数量和适当的类别分布。我们还提供了每个数据集的来源和预处理步骤，以及如何使用TOC-UCO存储库对新方法进行基准测试的详细信息。为此，提供了30个不同随机训练-测试分区的索引，以促进实验的可复现性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [26] [Fine-Tuned Language Models Generate Stable Inorganic Materials as Text](https://arxiv.org/abs/2402.04379)
> *微调语言模型以文本形式生成稳定的无机材料*

*Nate Gruver, Anuroop Sriram, Andrea Madotto, Andrew Gordon Wilson, C. Lawrence Zitnick, Zachary Ulissi* | **Category: cs.LG, cond-mat.mtrl-sci** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 材料生成, 无机材料, 亚稳态, 文本编码

**Comment:** ICLR 2024. Code available at:
  https://github.com/facebookresearch/crystal-llm

> **TL;DR:** 研究提出通过微调大型语言模型，以文本形式高效生成稳定的无机材料，并显示出比现有模型更高的亚稳态材料生成率。

**AI_Comments:** 这项研究通过将大型语言模型应用于材料科学领域，展示了跨领域应用的新颖性和潜力。其创新点在于将材料结构编码为文本，并利用LLM的强大生成能力来发现新材料，特别是亚稳态材料。这可能为材料发现和设计开辟新的途径，突破传统计算方法的局限。

<details>
  <summary>Details</summary>

**Motivation:** 旨在探索大型语言模型在材料生成领域的潜力，克服现有方法的局限性，并利用其灵活性，以实现高效、可靠的稳定材料生成。

**Method:** 通过在文本编码的原子数据上微调大型语言模型（特别是LLaMA-2 70B），实现稳定的无机材料生成。模型同时支持无条件生成、部分结构填充和文本条件生成。使用机器学习势能和DFT计算评估生成材料的稳定性。

**Result:** 微调后的模型（LLaMA-2 70B）生成物理约束的结构准确率约为90%。在生成亚稳态材料方面，其效率是CDVAE的两倍（49% vs 28%）。模型规模越大，捕获晶体结构关键对称性的能力越强。

**Conclusion:** 大型语言模型通过微调可以有效生成稳定的无机材料，其预训练偏置出人意料地适用于原子数据，且在生成亚稳态材料方面表现优异，具有多种生成模式的灵活性。

> **ai_Abstract:** 本文提出了一种新颖的方法，通过在文本编码的原子数据上微调大型语言模型（LLMs）来生成稳定的无机材料。研究表明，这种方法简单可靠，生成的结构在物理上高度准确。特别是，微调后的LLaMA-2 70B模型在生成亚稳态材料方面的效率是现有扩散模型的两倍。该模型还展示了无条件生成、结构填充和文本条件生成的灵活性，并且随着模型规模的增大，其捕获晶体结构对称性的能力也随之提高，暗示预训练LLMs的内在偏置对原子数据处理具有良好适应性。

> **摘要翻译:** 我们提出微调大型语言模型以生成稳定的材料。尽管这非正统，但在文本编码的原子数据上微调大型语言模型实现起来简单却可靠，大约90%的采样结构符合原子位置和电荷的物理约束。通过使用学习到的机器学习势能和黄金标准DFT计算的“能量高于包络线”（energy above hull）计算，我们表明我们最强的模型（微调后的LLaMA-2 70B）能够以大约两倍于竞争扩散模型CDVAE的速度（49% 对 28%）生成被预测为亚稳态的材料。由于文本提示固有的灵活性，我们的模型可以同时用于稳定材料的无条件生成、部分结构的填充和文本条件生成。最后，我们表明语言模型捕获晶体结构关键对称性的能力随模型规模的增大而提高，这表明预训练LLMs的偏置出人意料地非常适合原子数据。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [32] [Linear Memory SE(2) Invariant Attention](https://arxiv.org/abs/2507.18597)
> *线性内存SE(2)不变性注意力*

*Ethan Pronovost, Neha Boloor, Peter Schleede, Noureldin Hendy, Andres Morales, Nicholas Roy* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** SE(2)不变性, 线性内存, 注意力机制, 空间数据, 自动驾驶

**Comment:** Best paper award, Equivariant Systems Workshop at RSS

> **TL;DR:** 提出一种SE(2)不变性注意力机制，将空间数据处理的内存复杂度从二次方降至线性。

**AI_Comments:** 这项工作通过引入线性内存的SE(2)不变性注意力，解决了空间数据处理中长期存在的内存效率瓶颈，尤其对于自动驾驶这类需要处理大量动态对象的应用至关重要。其创新点在于将SE(2)不变性与线性内存复杂度相结合，使得Transformer架构能够更好地应用于大规模场景，并借鉴了大型语言模型的成功经验。这对于推动SE(2)不变性模型在实际系统中的部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 处理自动驾驶中的空间数据时，现有的SE(2)不变性网络架构在计算对象间相对姿态时需要二次方内存，这限制了其在大规模场景中的应用。

**Method:** 提出了一种用于SE(2)不变性缩放点积注意力的新机制，该机制相对于场景中对象的数量只需要线性内存。该SE(2)不变性Transformer架构具有与大型语言模型相似的良好扩展特性。

**Result:** 实验证明该方法实用且与同类非不变性架构相比，性能有所提升。

**Conclusion:** 该研究成功开发了一种高效的SE(2)不变性注意力机制，解决了现有方法内存消耗大的问题，并在实验中验证了其有效性和性能优势，使其适用于大规模空间数据处理任务。

> **ai_Abstract:** 这篇论文提出了一种创新的SE(2)不变性缩放点积注意力机制，旨在解决现有空间数据处理方法中二次方内存消耗的问题。通过将内存复杂度降低到线性，该方法使其SE(2)不变性Transformer架构能够像大型语言模型一样良好扩展。实验结果表明，该方法不仅实用，而且在性能上优于非不变性架构，为自动驾驶等任务中的大规模空间数据处理提供了高效的解决方案。

> **摘要翻译:** 处理空间数据是自动驾驶中许多学习任务的关键组成部分，例如运动预测、多智能体模拟和规划。先前的研究已经证明了使用SE(2)不变网络架构的价值，该架构只考虑对象（例如其他智能体、交通车道等场景特征）之间的相对姿态。然而，这些方法明确计算所有对象对的相对姿态，需要二次方内存。在这项工作中，我们提出了一种SE(2)不变缩放点积注意力的机制，该机制相对于场景中对象的数量只需要线性内存。我们的SE(2)不变Transformer架构享受着与近年来受益于大型语言模型相同的扩展特性。我们通过实验证明，我们的方法易于实现，并且与可比较的非不变架构相比，性能有所提高。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [33] [Exploitation Over Exploration: Unmasking the Bias in Linear Bandit Recommender Offline Evaluation](https://arxiv.org/abs/2507.18756)
> *探索与利用：揭示线性老虎机推荐系统离线评估中的偏差*

*Pedro R. Pires, Gregorio F. Azevedo, Pietro L. Campos, Rafael T. Sereicikas, Tiago A. Almeida* | **Category: cs.LG, cs.IR** | **Updated: 2025-07-24**

**Keywords:** 多臂老虎机, 离线评估, 探索-利用, 推荐系统, 线性老虎机

**Comment:** Accepted to be published in RecSys'25, 10 pages, 3 figures

> **TL;DR:** 研究发现，在离线评估中，线性老虎机推荐系统中的纯利用模型表现优于或匹配探索性模型，揭示了离线评估协议在评估探索能力方面的不足。

**AI_Comments:** 这项研究揭示了当前多臂老虎机离线评估协议的一个关键限制，即它们可能无法准确反映探索策略的真实效能，反而偏向于纯利用。其创新之处在于通过大规模实证比较和超参数优化，有力地证明了这种偏差。这项工作的重大意义在于，它对现有推荐系统和交互式学习的离线评估范式提出了质疑，并为未来研究指明了方向，即开发更能反映探索行为的评估框架。

<details>
  <summary>Details</summary>

**Motivation:** 多臂老虎机（MAB）算法在推荐系统中广泛应用，但其离线评估在可靠评估探索行为方面存在局限性，这促使本研究深入探讨。

**Method:** 本研究对几种线性多臂老虎机进行了广泛的离线实证比较，并通过超参数优化进一步验证。

**Result:** 在超过90%的不同数据集中，一个没有探索的贪婪线性模型始终能达到顶级性能，通常优于或匹配其探索性对应模型。超参数优化也倾向于最小化探索的配置，表明在这些评估设置中纯利用是主导策略。

**Conclusion:** 研究结果揭示了老虎机离线评估协议的显著不足，特别是在反映真实探索效能方面的能力。因此，本研究强调迫切需要开发更稳健的评估方法，以指导未来对推荐系统中交互式学习替代评估框架的调查。

> **ai_Abstract:** 本研究旨在揭示多臂老虎机推荐系统离线评估的局限性，特别是在评估探索行为方面。通过对多种线性多臂老虎机进行广泛的离线实证比较，研究发现，在绝大多数数据集中，纯利用的贪婪线性模型表现出卓越性能，甚至超越或匹敌具有探索策略的模型。超参数优化也证实了纯利用的主导地位。这些发现揭示了当前离线评估协议在衡量真实探索能力方面的不足，并强调了开发更稳健评估方法的重要性，以促进推荐系统中交互式学习评估框架的未来发展。

> **摘要翻译:** 多臂老虎机（MAB）算法广泛应用于需要持续、增量学习的推荐系统。MAB 的一个核心方面是探索-利用权衡：在利用可能受欢迎的物品和探索新物品以收集信息之间进行选择。在上下文线性老虎机中，这种权衡尤为核心，因为许多变体共享相同的线性回归骨干，主要区别在于其探索策略。尽管其广泛使用，但 MAB 的离线评估越来越被认为在可靠评估探索行为方面存在局限性。本研究对几种线性 MAB 进行了广泛的离线实证比较。令人惊讶的是，在超过90%的不同数据集中，一个没有进行任何类型探索的贪婪线性模型始终能达到顶级性能，通常优于或匹配其探索性对应模型。这一观察结果通过超参数优化得到进一步证实，超参数优化始终倾向于最小化探索的配置，这表明在这些评估设置中纯利用是主导策略。我们的结果揭示了老虎机离线评估协议的显著不足，特别是在反映真实探索效能方面的能力。因此，本研究强调迫切需要开发更稳健的评估方法，以指导未来对推荐系统中交互式学习替代评估框架的调查。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [40] [Neuromorphic Computing for Embodied Intelligence in Autonomous Systems: Current Trends, Challenges, and Future Directions](https://arxiv.org/abs/2507.18139)
> *自动系统中具身智能的神经形态计算：当前趋势、挑战和未来方向*

*Alberto Marchisio, Muhammad Shafique* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 神经形态计算, 自主系统, 具身智能, 脉冲神经网络, 事件驱动视觉传感器

**Comment:** To appear at the 31st IEEE International Symposium on On-Line Testing
  and Robust System Design (IOLTS), Ischia, Italy, July 2025

> **TL;DR:** 本文综述了神经形态计算在自主系统具身智能中的应用，涵盖算法、硬件、优化策略、挑战和未来方向。

**AI_Comments:** 这篇综述论文全面探讨了神经形态计算在自主系统中的潜力，特别强调了其在能效和适应性方面的优势。它整合了多学科视角，为该领域的当前进展、挑战和未来研究方向提供了宝贵的概览，对于推动具身智能的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 对智能、自适应、高能效自主系统（如机器人、无人机、自动驾驶汽车）的需求日益增长，促使人们对受生物神经系统启发的神经形态计算产生兴趣，以增强这些系统的感知、决策和响应能力。

**Method:** 本文通过整合机器学习、机器人学、神经科学和神经形态工程的视角，对神经形态算法、专用硬件和跨层优化策略的最新进展进行了综述，并特别关注其在真实自主场景中的部署，以及事件驱动型动态视觉传感器的作用。

**Result:** 讨论强调了通过将脉冲神经网络集成到自主系统架构中，可以改善能效、鲁棒性、适应性和可靠性的新方法。

**Conclusion:** 探讨了新兴趋势和开放挑战，特别是在实时决策、持续学习以及开发安全、有弹性的自主系统方面。

> **ai_Abstract:** 本文综述了神经形态计算在智能、自适应和高能效自主系统（如机器人、无人机、自动驾驶汽车）中的应用。研究关注神经形态算法、硬件和优化策略的最新进展，特别是事件驱动型视觉传感器和脉冲神经网络的集成，以提升系统的感知、决策、能效、鲁棒性、适应性和可靠性。论文整合了机器学习、机器人学、神经科学和神经形态工程的视角，并探讨了实时决策、持续学习和安全弹性系统等未来挑战和方向。

> **摘要翻译:** 对智能、自适应和高能效自主系统（如机器人、移动代理（例如无人机）和自动驾驶汽车）日益增长的需求正在推动神经形态计算的兴趣。通过从生物神经系统汲取灵感，神经形态方法为增强自主平台的感知、决策和响应能力提供了有前景的途径。本文综述了神经形态算法、专用硬件和跨层优化策略的最新进展，重点关注其在真实世界自主场景中的部署。特别关注事件驱动型动态视觉传感器及其在实现快速高效感知方面的作用。讨论强调了通过将脉冲神经网络集成到自主系统架构中，可以改善能效、鲁棒性、适应性和可靠性的新方法。我们整合了来自机器学习、机器人学、神经科学和神经形态工程的视角，以提供该领域现状的全面视图。最后，探讨了新兴趋势和开放挑战，特别是在实时决策、持续学习以及开发安全、有弹性的自主系统方面。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [58] [SETOL: A Semi-Empirical Theory of (Deep) Learning](https://arxiv.org/abs/2507.17912)
> *SETOL：一种（深度）学习的半经验理论*

*Charles H Martin, Christopher Hinrichs* | **Category: cs.LG, cond-mat.stat-mech** | **Updated: 2025-07-23**

**Keywords:** 半经验理论, 深度学习, 神经网络, 重尾自正则化, 随机矩阵理论

**Comment:** 139 pages, 28 figures. Code for experiments available at
  https://github.com/charlesmartin14/SETOL_experiments

> **TL;DR:** 本文提出了一种半经验学习理论（SETOL），解释了最先进神经网络的性能，并引入了新的度量标准来评估网络层质量。

**AI_Comments:** 这篇论文通过引入SETOL理论，为理解深度学习模型的卓越性能提供了一个新的理论框架，特别是从统计力学和随机矩阵理论的角度。其创新之处在于能够不依赖训练/测试数据来评估网络层质量，这对于模型分析和诊断具有重要意义。提出的ERG度量与现有HTSR alpha度量的良好对齐，增强了理论的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 解释最先进（SOTA）神经网络的卓越性能，并为重尾自正则化（HTSR）的现象学理论中的基本量提供形式化解释。

**Method:** 提出了半经验学习理论（SETOL），利用统计力学、随机矩阵理论和量子化学的技术。该理论推导出了理想学习的新数学前提，包括一个新度量ERG。通过计算层权重矩阵的经验谱密度（ESD），并将其代入SETOL公式，来估计训练好的SOTA神经网络的单层质量。在简单的三层多层感知机（MLP）上测试了SETOL的假设和预测。

**Result:** SETOL在简单三层多层感知机（MLP）上的假设和预测与关键理论假设表现出极好的一致性。重尾自正则化（HTSR）的alpha度量和SETOL的ERG层质量度量在MLP和SOTA神经网络上都表现出显著良好的一致性。

**Conclusion:** 本文提出了SETOL理论，成功解释了SOTA神经网络的性能，并为HTSR中的关键量提供了形式化解释。SETOL引入的新度量ERG与HTSR的alpha度量高度一致，并且可以在不访问训练或测试数据的情况下评估神经网络的层质量。

> **ai_Abstract:** 本文提出了一种名为SETOL的半经验学习理论，旨在解释最先进神经网络的卓越性能。该理论为重尾自正则化（HTSR）中的核心度量（alpha和alpha-hat）提供了形式化解释，这些度量此前已被证明能在不依赖训练或测试数据的情况下预测模型性能。SETOL融合了统计力学、随机矩阵理论和量子化学方法，并引入了一个新的理想学习度量ERG。研究通过在一个简单的多层感知机上验证了SETOL的假设和预测，展示了高度一致性。此外，文章还展示了如何利用层权重矩阵的经验谱密度来估计SOTA神经网络的层质量，并发现HTSR的alpha与SETOL的ERG度量之间存在显著的一致性。

> **摘要翻译:** 我们提出了一种半经验学习理论（SETOL），它解释了最先进（SOTA）神经网络的卓越性能。我们对重尾自正则化（HTSR）现象学理论中基本量的起源（即重尾幂律层质量度量alpha和alpha-hat）提供了形式化解释。在之前的工作中，这些度量已被证明可以预测预训练SOTA神经网络模型的测试准确性趋势，重要的是，无需访问测试或训练数据。我们的SETOL利用了统计力学以及随机矩阵理论和量子化学的先进方法。推导提出了理想学习的新数学前提，包括一个新度量ERG，它等效于应用Wilson精确重整化群的一个步骤。我们在一个简单的三层多层感知机（MLP）上测试了SETOL的假设和预测，证明了与关键理论假设的极好一致性。对于SOTA神经网络模型，我们展示了如何通过简单地计算层权重矩阵的经验谱密度（ESD）并将其代入我们的SETOL公式来估计训练好的神经网络的个体层质量。值得注意的是，我们检查了HTSR的alpha和SETOL的ERG层质量度量的性能，发现它们在我们的MLP和SOTA神经网络上都表现出显著良好的一致性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [59] [Fine-Grained Uncertainty Quantification via Collisions](https://arxiv.org/abs/2411.12127)
> *通过碰撞进行细粒度不确定性量化*

*Jesse Friedbaum, Sudarshan Adiga, Ravi Tandon* | **Category: cs.LG, cs.IT, math.IT, math.ST, stat.ML, stat.TH** | **Updated: 2025-07-24**

**Keywords:** 不确定性量化, 类别碰撞, 碰撞矩阵, 对比学习, 细粒度不确定性

**Comment:** 

> **TL;DR:** 本文提出了一种新的、直观的度量方法，即类别碰撞的普遍性，用于量化不确定性。他们定义了碰撞矩阵，并提出了一系列创新技术来估计该矩阵，从而实现了细粒度的不确定性量化和后验类别分布估计。

**AI_Comments:** 本文的创新点在于提出了“类别碰撞”这一新颖且直观的不确定性度量概念，并由此定义了细粒度的碰撞矩阵S。更重要的是，它解决了一个具有挑战性的问题：如何通过单热编码数据来估计这个矩阵。通过引入成对对比学习和证明Gramian矩阵G可以唯一恢复S（一个独立的数学发现），作者提供了一个完整的解决方案。这种方法对于需要细粒度不确定性信息（例如在风险敏感应用中）的分类任务具有重要意义，因为它不仅量化了整体不确定性，还揭示了具体类别对之间的混淆程度。

<details>
  <summary>Details</summary>

**Motivation:** 为了提出一种新的、直观的度量方法来量化偶然不确定性（UQ），即定义为相同输入在不同类别中被观察到的类别碰撞的普遍性。

**Method:** 本文提出了一种新的细粒度不确定性度量方法——碰撞矩阵S，它通过相同输入在不同类别中被观察到的类别碰撞率来定义。为了估计该矩阵，作者提出了一系列创新技术：首先，学习一个接受两个输入并判断它们是否属于同一类别的成对对比模型；然后，利用该对比模型估计S的Gramian矩阵G；最后，在合理假设下，证明G可以唯一地恢复S。此外，还展示了如何结合S的估计和对比模型来估计任何点的后验类别可移植性分布。

**Result:** 本文成功地提出了碰撞矩阵作为一种新颖且独特的细粒度不确定性度量方法，并建立了其基本数学性质，揭示了其与现有UQ方法（包括贝叶斯错误率）的关系。通过提出的创新技术，实现了对碰撞矩阵的估计，并证明了在合理假设下Gramian矩阵G可以唯一地恢复S。实验结果验证了所提出的估计碰撞矩阵和类别后验分布方法的有效性。

**Conclusion:** 本文提出了一种基于类别碰撞的新型细粒度不确定性量化方法，并通过一系列创新技术实现了对碰撞矩阵的有效估计。这种方法不仅提供了对类别间区分难度的固有度量，还能用于估计后验类别可移植性分布，并通过实验验证了其有效性。

> **ai_Abstract:** 本文提出了一种新颖的细粒度偶然不确定性量化（UQ）方法，核心是“类别碰撞”概念，即相同输入出现在不同类别中的现象。作者定义了K×K的“碰撞矩阵S”来量化类别间的区分难度。文章探讨了S的数学性质及其与现有UQ方法的关系。为估计S，研究提出了一系列创新技术：首先训练一个成对对比模型来判断输入是否同类，然后用此模型估计S的Gramian矩阵G，并证明在合理假设下G可唯一恢复S。最终，该方法能结合估计的S和对比模型来预测任何点的后验类别可移植性分布。实验结果验证了方法的有效性。

> **摘要翻译:** 我们提出了一种新的、直观的偶然不确定性量化（UQ）度量方法，即类别碰撞的普遍性，其定义为在不同类别中观察到相同输入的情况。我们使用类别碰撞率来定义碰撞矩阵，这是一种新颖且独特的细粒度不确定性度量。对于涉及K个类别的分类问题，K×K的碰撞矩阵S衡量了区分每对类别固有的难度。我们讨论了碰撞矩阵的几种应用，建立了其基本数学性质，并展示了其与现有UQ方法（包括贝叶斯错误率（BER））的关系。我们还通过提出一系列创新技术来估计S，解决了使用独热标签数据估计碰撞矩阵的新问题。首先，我们学习一个成对对比模型，该模型接受两个输入并确定它们是否属于同一类别。然后，我们证明了这个对比模型（它是PAC可学习的）可以用于估计S的Gramian矩阵G，定义为G=S^TS。最后，我们证明在合理假设下，G可以唯一地恢复S，这是一个关于非负矩阵的新结果，可能具有独立的兴趣。在建立了估计S的方法之后，我们展示了S的这个估计，结合对比模型，如何用于估计任何点的后验类别可移植性分布。实验结果也验证了我们在几个数据集上估计碰撞矩阵和类别后验分布的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [76] [The Role of the Time-Dependent Hessian in High-Dimensional Optimization](https://arxiv.org/abs/2403.02418)
> *时变Hessian在***维优化中的作用*

*Tony Bonnaire, Giulio Biroli, Chiara Cammarota* | **Category: cs.LG, cond-mat.dis-nn, cond-mat.stat-mech** | **Updated: 2025-07-24**

**Keywords:** 梯度下降, Hessian, 高维优化, 相位恢复, BBP跃迁

**Comment:** 32 pages

> **TL;DR:** 本文研究了梯度下降在高维非凸损失景观中的行为，特别是通过分析Hessian矩阵的动态特性。发现在下降初期Hessian存在负方向，该方向有助于逃离崎岖区域，但随后会发生BBP跃迁并丧失该方向。研究强调了初始化和早期动力学在高效导航复杂景观中的关键作用。

**AI_Comments:** 这篇论文通过深入分析Hessian矩阵在梯度下降过程中的动态变化，为理解高维非凸优化中的“为什么能找到好解”这一难题提供了新的视角。其创新点在于揭示了早期负曲率方向的关键作用以及BBP跃迁对优化路径的影响。强调初始化和早期动力学的重要性对于指导实际的机器学习模型训练具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 梯度下降在机器学习中广泛应用于寻找粗糙景观中的最小值，但对于在高维强非凸设置中为何能找到好的解，其理论理解仍然难以捉摸。

**Method:** 本文以相位恢复问题为例，分析了梯度下降过程中Hessian矩阵的动态特性，识别了其谱性质中的一个动态转变，并将其与逃离损失景观中粗糙区域的能力联系起来。

**Result:** 当信噪比(SNR)足够大时，下降初期（即初始条件中）Hessian中存在一个信息丰富的负方向。在下降过程中，谱中会在有限时间内发生BBP跃迁：该方向消失，动力学被困在充满边缘稳定坏最小值的崎岖区域。令人惊讶的是，对于有限系统尺寸，这个负曲率窗口使得系统能够远在无限尺寸理论信噪比之前恢复信号。

**Conclusion:** 初始化和早期动力学在有效导航粗糙损失景观中起着核心作用。

> **ai_Abstract:** 本文探讨了梯度下降在高维非凸优化中的有效性，特别关注了Hessian矩阵在下降过程中的动态演变。研究以相位恢复问题为例，揭示了Hessian谱性质中的一个动态转变（BBP跃迁）。结果表明，在信噪比足够高的情况下，下降初期Hessian中存在的负方向有助于系统逃离粗糙区域，即使该方向随后会消失。这强调了初始条件和早期动力学对于高效探索复杂损失景观的关键作用，尤其是在有限系统尺寸下，能比理论预测更早地恢复信号。

> **摘要翻译:** 梯度下降常用于在粗糙景观中寻找最小值，特别是在近期的机器学习应用中。然而，对于为何能够找到好的解，尤其是在强非凸和高维设置中，其理论理解仍然难以捉摸。本文以相位恢复问题为例，这是一个近期在理论机器学习中备受关注的典型例子。我们分析了梯度下降过程中Hessian矩阵的动态特性，识别了其谱性质中的一个动态转变，并将其与逃离损失景观中粗糙区域的能力联系起来。当信噪比（SNR）足够大时，在下降开始时，即在初始条件下，Hessian中存在一个信息丰富的负方向。在下降过程中，谱中会在有限时间内发生BBP跃迁：该方向消失，动力学被困在充满边缘稳定坏最小值的崎岖区域。令人惊讶的是，对于有限系统尺寸，这个负曲率窗口使得系统能够远在无限尺寸理论信噪比之前恢复信号，这强调了初始化和早期动力学在有效导航粗糙景观中的核心作用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [80] [When Noisy Labels Meet Class Imbalance on Graphs: A Graph Augmentation Method with LLM and Pseudo Label](https://arxiv.org/abs/2507.18153)
> *当噪声标签遇到图上的类别不平衡：一种结合LLM和伪标签的图增强方法*

*Riting Xia, Rucong Wang, Yulin Liu, Anchen Li, Xueyan Liu, Yan Zhang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-25**

**Keywords:** 图节点分类, 类别不平衡, 噪声标签, LLM, 伪标签

**Comment:** 

> **TL;DR:** 本文提出了GraphALP，一个利用LLM和伪标签技术来解决图上带噪声标签的类别不平衡节点分类问题的新框架。

**AI_Comments:** 本文的创新点在于首次将LLM引入到解决图上类别不平衡和噪声标签的问题中，通过LLM生成高质量的少数类样本和辅助伪标签校正，为图数据处理提供了新的思路。其重要性在于解决了真实世界图数据中常见的复杂挑战，具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图节点分类方法通常假设标签是干净可靠的，但这与真实世界中标签常含噪声的情况不符。同时，类别不平衡的图节点分类问题也未得到充分研究。本文旨在解决图上带噪声标签的类别不平衡节点分类这一实际且未充分探索的问题。

**Method:** 本文提出了GraphALP，一个基于大型语言模型（LLM）和伪标签技术的图增强框架。具体来说，它设计了一个基于LLM的过采样方法来生成合成的少数类节点，以缓解类别不平衡。在此基础上，开发了一个动态加权伪标签方法来获得高置信度伪标签，以降低标签噪声比。此外，还实现了二次LLM引导的过采样机制，以减轻伪标签可能引起的类别分布偏差。

**Result:** 实验结果表明，GraphALP在带有噪声标签的类别不平衡图上，性能优于现有最先进的方法。

**Conclusion:** GraphALP通过结合LLM和伪标签技术，有效地解决了图上带噪声标签的类别不平衡节点分类问题，并取得了卓越的性能。

> **ai_Abstract:** 本文针对图上带噪声标签的类别不平衡节点分类问题，提出了一种名为GraphALP的新型图增强框架。GraphALP结合了大型语言模型（LLM）和伪标签技术，通过LLM过采样生成少数类节点以解决类别不平衡，并通过动态加权伪标签减少标签噪声，同时利用二次LLM引导过采样缓解伪标签引起的分布偏差。实验证明GraphALP优于现有方法。

> **摘要翻译:** 图节点分类中的类别不平衡问题是一个实际但尚未充分探索的研究问题。尽管最近的研究试图解决这个问题，但它们在处理类别不平衡图时通常假设标签是干净可靠的。这一假设常常违反真实世界图的性质，因为标签通常包含噪声。鉴于此，本文系统地研究了在带有噪声标签的类别不平衡图上的鲁棒节点分类。我们提出了GraphALP，一个基于大型语言模型（LLM）和伪标签技术的新型图增强框架。具体来说，我们设计了一种基于LLM的过采样方法来生成合成的少数类节点，从而产生标签准确的少数类节点以缓解类别不平衡。基于类别平衡的图，我们开发了一种动态加权伪标签方法来获得高置信度伪标签，以降低标签噪声比。此外，我们还实现了二次LLM引导的过采样机制，以减轻伪标签可能引起的潜在类别分布偏差。实验结果表明，GraphALP在带有噪声标签的类别不平衡图上，性能优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [88] [Demystify Protein Generation with Hierarchical Conditional Diffusion Models](https://arxiv.org/abs/2507.18603)
> *使用分层条件扩散模型揭秘蛋白质生成*

*Zinan Ling, Yi Shi, Da Yan, Yang Zhou, Bo Hui* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 蛋白质生成, 条件扩散模型, 分层建模, Protein-MMD, 从头设计

**Comment:** 

> **TL;DR:** 本文提出了一种多级条件扩散模型，结合序列和结构信息，用于高效端到端蛋白质设计，并引入了新的评估指标Protein-MMD，实验证明了其在条件蛋白质生成任务中的有效性。

**AI_Comments:** 该论文的创新点在于提出了一个结合多级结构信息的条件扩散模型，这对于理解和生成具有特定功能的蛋白质至关重要。同时，引入新的评估指标Protein-MMD，解决了现有评估方法可能无法全面捕捉生成蛋白质质量的问题，提升了评估的可靠性。这项工作对于蛋白质从头设计领域具有重要意义，有助于推动功能性蛋白质的发现和应用。

<details>
  <summary>Details</summary>

**Motivation:** 生成新颖且功能性的蛋白质序列对于生物学应用至关重要。尽管条件扩散模型在蛋白质生成任务中表现出色，但在从头蛋白质设计中，特别是对于条件扩散模型而言，可靠的蛋白质生成仍然是一个开放的研究问题。考虑到蛋白质的生物学功能由多级结构决定，现有方法可能未能充分利用多级结构信息。

**Method:** 提出了一种新颖的多级条件扩散模型，该模型整合了基于序列和基于结构的信息，用于高效的端到端蛋白质设计，并由指定功能指导。通过同时生成不同级别的表示，该框架可以有效地模拟不同级别之间固有的分层关系。此外，还提出了一种新的可靠评估指标Protein-MMD，用于评估条件扩散模型生成的蛋白质质量，该指标能够捕获真实和生成蛋白质序列之间的分布和功能相似性，同时确保条件一致性。

**Result:** 在基准数据集上的实验结果表明，所提出的生成框架和评估指标在条件蛋白质生成任务中具有有效性。

**Conclusion:** 本文提出的多级条件扩散模型通过整合序列和结构信息，能够有效地进行端到端蛋白质设计，并生成信息丰富且具有区分性的蛋白质表示。同时，新提出的Protein-MMD评估指标能够可靠地评估生成蛋白质的质量，并被实验证明是有效的。

> **ai_Abstract:** 本文提出了一种名为多级条件扩散模型的新型蛋白质生成框架，旨在解决从头蛋白质设计中可靠生成蛋白质的挑战。该模型创新性地整合了序列和结构信息，并通过同时生成多级表示来捕捉蛋白质固有的分层关系，从而实现高效的端到端功能引导蛋白质设计。此外，论文还引入了Protein-MMD，一种新的评估指标，用于可靠地衡量生成蛋白质的质量，该指标能够兼顾分布和功能相似性以及条件一致性。实验结果验证了所提框架和评估指标在条件蛋白质生成任务中的有效性。

> **摘要翻译:** 生成新颖且功能性的蛋白质序列对于广泛的生物学应用至关重要。条件扩散模型的最新进展在蛋白质生成任务中表现出令人印象深刻的经验性能。然而，在从头蛋白质设计中，可靠的蛋白质生成仍然是一个开放的研究问题，尤其是在条件扩散模型方面。考虑到蛋白质的生物学功能是由多级结构决定的，我们提出了一种新颖的多级条件扩散模型，该模型整合了基于序列和基于结构的信息，用于高效的、由指定功能引导的端到端蛋白质设计。通过同时生成不同级别的表示，我们的框架可以有效地模拟不同级别之间固有的分层关系，从而生成信息丰富且具有区分性的蛋白质表示。我们还提出了一种新的可靠评估指标Protein-MMD，用于评估条件扩散模型生成的蛋白质质量。我们的新指标能够捕获真实和生成蛋白质序列之间的分布和功能相似性，同时确保条件一致性。我们在基准数据集上进行了实验，条件蛋白质生成任务的结果证明了所提出的生成框架和评估指标的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [92] [Lower Bounds for Public-Private Learning under Distribution Shift](https://arxiv.org/abs/2507.17895)
> *分布偏移下公私学习的下界*

*Amrith Setlur, Pratiksha Thaker, Jonathan Ullman* | **Category: cs.LG, cs.CR** | **Updated: 2025-07-23**

**Keywords:** 公私学习, 差分隐私, 分布偏移, 下界, 高斯均值估计

**Comment:** Preprint

> **TL;DR:** 研究发现，在存在分布偏移的公私学习中，当偏移较小时，公有或私有数据需足够丰富；当偏移较大时，公有数据无益。

**AI_Comments:** 这项工作通过研究分布偏移对公私学习下界的影响，提供了关于公有数据在差分隐私中的作用的深入见解。其创新之处在于将下界分析扩展到更现实的非同分布场景，揭示了公有数据价值的边界条件，对实际应用中的数据策略具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的差分隐私机器学习算法常依赖公有数据，但在同分布情况下，结合公有数据没有额外价值。本研究旨在探索在数据源存在显著分布偏移时，公有数据是否仍能提供互补价值。

**Method:** 作者将已知的公私学习下界扩展到数据源存在显著分布偏移的场景。具体研究了两种情况：均值不同的高斯均值估计和参数偏移的高斯线性回归。

**Result:** 结果表明，当分布偏移较小（相对于所需精度）时，公有或私有数据中的任一者必须足够丰富才能估计私有参数。相反，当分布偏移较大时，公有数据不提供任何益处。

**Conclusion:** 在公私学习中，分布偏移的大小决定了公有数据的价值：小偏移下公私数据需有足够量，大偏移下公有数据无益。

> **ai_Abstract:** 本文研究了在存在显著分布偏移的情况下，公有数据源在差分隐私机器学习中的价值。作者将现有同分布下的公私学习下界扩展到分布偏移场景，并特别分析了高斯均值估计和高斯线性回归。研究发现，当分布偏移较小且相对于所需精度时，公有或私有数据必须足够充足才能有效估计私有参数；而当分布偏移较大时，公有数据则无法提供任何增益。

> **摘要翻译:** 实践中最有效的差分隐私机器学习算法依赖于额外的所谓公共数据源。当这两个数据源结合起来的价值大于其各部分之和时，这种范式最引人注目。然而，在均值估计等某些设置中，我们有很强的下界，表明当两个数据源具有相同分布时，结合两个数据源没有互补价值。在这项工作中，我们将已知的公私学习下界扩展到两个数据源表现出显著分布偏移的设置。我们的结果适用于两种情况：均值不同的高斯均值估计，以及参数偏移的高斯线性回归。我们发现，当偏移较小（相对于所需精度）时，公有或私有数据中的任一者必须足够丰富才能估计私有参数。相反，当偏移较大时，公有数据不提供任何益处。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [109] [Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for Wearable Applications Across Lab and Field Settings](https://arxiv.org/abs/2502.01108)
> *Pulse-PPG：一个用于实验室和现场可穿戴应用的开源现场训练PPG基础模型*

*Mithun Saha, Maxwell A. Xu, Wanting Mao, Sameer Neupane, James M. Rehg, Santosh Kumar* | **Category: cs.LG, cs.AI, eess.SP** | **Updated: 2025-07-23**

**Keywords:** PPG, 基础模型, 现场数据, 开源, 可穿戴设备

**Comment:** Saha and Xu are co-first authors

> **TL;DR:** Pulse-PPG是一个开源的PPG基础模型，通过100天现场研究的原始数据训练，在实验室和现场环境中表现出优于临床数据训练模型的泛化能力。

**AI_Comments:** 该论文的创新点在于首次提出了一个完全基于大规模、长期现场研究原始PPG数据训练的开源基础模型。其重要性在于证明了真实世界、非临床数据对于提高模型泛化能力和鲁棒性的潜力，这对于可穿戴设备在实际应用中的推广至关重要。通过开源模型，有望加速该领域的研究和应用发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的PPG基础模型要么是开源但基于临床数据训练，要么是闭源的，这限制了它们在真实世界中的适用性。本研究旨在开发一个基于真实世界现场数据训练的开源PPG基础模型，以提高其在各种健康应用中的泛化能力。

**Method:** 本文介绍了Pulse-PPG，这是第一个完全基于在100天现场研究中从120名参与者收集的原始PPG数据训练的开源PPG基础模型。研究人员在多个数据集和下游任务上评估了Pulse-PPG的性能，并将其与现有最先进的临床数据训练基础模型进行了比较。

**Result:** 结果表明，Pulse-PPG（在未经整理的现场数据上训练）在实验室和现场环境中的临床和移动健康应用中均表现出卓越的泛化能力。现场数据预训练在许多任务中甚至优于临床数据预训练。

**Conclusion:** 接触真实世界的变异性使模型能够学习更精细的表示，使其在不同任务中更具适应性。在真实世界、多样化数据集上进行训练对于构建鲁棒的基础模型至关重要。

> **ai_Abstract:** 本文介绍了Pulse-PPG，一个开源的PPG基础模型，其独特之处在于完全使用从120名参与者进行的100天现场研究中收集的原始PPG数据进行训练。研究发现，尽管使用未经整理的现场数据，Pulse-PPG在实验室和现场环境中的临床和移动健康应用中均展现出卓越的泛化能力，甚至在多项任务上优于基于临床数据训练的现有模型。这强调了真实世界数据变异性对模型学习精细表示和提高适应性的重要性。该模型计划开源，以促进未来在PPG基础模型领域的研究。

> **摘要翻译:** 基于光电容积描记法（PPG）的基础模型正日益受到关注，因为PPG在生物信号监测中的广泛应用以及它们在各种健康应用中泛化的潜力。在本文中，我们介绍了Pulse-PPG，这是第一个完全基于从120名参与者进行的100天现场研究中收集的原始PPG数据训练的开源PPG基础模型。现有的PPG基础模型要么是开源但基于临床数据训练，要么是闭源的，这限制了它们在真实世界中的适用性。我们在多个数据集和下游任务上评估了Pulse-PPG，并将其性能与一个在临床数据上训练的最先进的基础模型进行了比较。我们的结果表明，Pulse-PPG（在未经整理的现场数据上训练）在实验室和现场环境中的临床和移动健康应用中均表现出卓越的泛化能力。这表明接触真实世界的变异性使模型能够学习精细的表示，使其在不同任务中更具适应性。此外，在许多任务中，现场数据预训练出人意料地优于临床数据预训练，这进一步强调了在真实世界、多样化数据集上进行训练的重要性。为了鼓励利用现场数据在鲁棒基础模型方面取得进一步进展，我们计划发布Pulse-PPG，为研究人员提供一个开发更具泛化性的PPG模型的强大资源。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [114] [From Seed to Harvest: Augmenting Human Creativity with AI for Red-teaming Text-to-Image Models](https://arxiv.org/abs/2507.17922)
> *从种子到收获：利用AI增强人类创造力以对文本到图像模型进行红队测试*

*Jessica Quaye, Charvi Rastogi, Alicia Parrish, Oana Inel, Minsuk Kahng, Lora Aroyo, Vijay Janapa Reddi* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 红队测试, 文本到图像模型, 对抗性提示, 人机协作, 模型安全

**Comment:** 

> **TL;DR:** 本文提出Seed2Harvest，一种结合人类创造力和AI扩展能力的混合红队测试方法，用于生成多样化且有效的对抗性提示，以评估文本到图像模型的安全性。

**AI_Comments:** 本文提出了一种创新性的人机协作方法，有效解决了文本到图像模型红队测试中对抗性提示生成面临的规模和多样性问题。Seed2Harvest的混合策略既保留了人类提示的创造性和细微差别，又通过AI实现了大规模扩展，这对于持续评估T2I模型的安全性至关重要。其贡献在于提供了一个更全面、更具鲁棒性的评估框架。

<details>
  <summary>Details</summary>

**Motivation:** 文本到图像（T2I）模型在对抗性攻击方面的鲁棒性评估至关重要。当前生成对抗性提示的方法存在局限：人类创作的数据集规模小且代表性不平衡；合成生成的数据集缺乏真实性和创造性。

**Method:** 我们提出了Seed2Harvest，一种混合红队测试方法，用于指导性地扩展文化多样化、人类创作的对抗性提示种子。该方法结合了人类和机器方法的优点。

**Result:** 生成的提示保留了人类提示的特征和攻击模式，并保持了可比较的平均攻击成功率（0.31 NudeNet，0.36 SD NSFW，0.12 Q16）。扩展后的数据集多样性显著提高，包含535个独特的地理位置和7.48的香农熵，而原始数据集为58个位置和5.28的熵。

**Conclusion:** 我们的工作表明了人机协作在利用人类创造力和机器计算能力方面的重要性，以实现全面、可扩展的红队测试，从而持续评估T2I模型的安全性。

> **ai_Abstract:** 本文提出Seed2Harvest，一种新颖的混合红队测试方法，旨在通过结合人类创造力和AI的扩展能力，克服现有文本到图像（T2I）模型对抗性提示生成方法的局限性。当前方法要么缺乏规模和多样性（人类创作），要么缺乏真实性和创造性（合成生成）。Seed2Harvest通过指导性扩展人类制作的对抗性提示种子，生成了更多样化且同样有效的对抗性提示。实验结果表明，该方法在攻击成功率上与人类提示相当，同时显著提高了数据集的多样性，从而实现了对T2I模型更全面、可扩展的安全评估。

> **摘要翻译:** 文本到图像（T2I）模型已广泛应用于众多应用程序中，因此对其进行鲁棒性评估以应对对抗性攻击成为一项关键优先事项。持续获取跨越不同领域的新颖且具有挑战性的对抗性提示，对于压力测试这些模型抵御来自多个向量的新型攻击的弹性至关重要。目前生成此类提示的技术要么完全由人类创作，要么通过合成生成。一方面，人类制作的对抗性提示数据集通常规模过小，并且在文化和语境表示方面存在不平衡。另一方面，合成生成的提示数据集可以实现规模化，但通常缺乏人类制作的提示中发现的真实细微差别和创造性对抗策略。为了结合人类和机器方法的优点，我们提出了Seed2Harvest，这是一种混合红队测试方法，用于指导性地扩展文化多样化的人类制作的对抗性提示种子。由此产生的提示保留了人类提示的特征和攻击模式，同时保持了可比较的平均攻击成功率（0.31 NudeNet，0.36 SD NSFW，0.12 Q16）。我们扩展后的数据集在多样性方面显著提高，拥有535个独特的地理位置和7.48的香农熵，而原始数据集只有58个位置和5.28的熵。我们的工作证明了人机协作在利用人类创造力和机器计算能力方面的重要性，以实现全面、可扩展的红队测试，从而持续评估T2I模型的安全性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [125] [A Principled Approach for Data Bias Mitigation](https://arxiv.org/abs/2405.12312)
> *一种数据偏见缓解的原则性方法*

*Bruno Scarone, Alfredo Viola, Renée J. Miller, Ricardo Baeza-Yates* | **Category: cs.LG, cs.CY** | **Updated: 2025-07-24**

**Keywords:** 数据偏见缓解, 交叉偏见, 可解释性, 数学保证, 表格发现

**Comment:** Accepted to AIES 2025

> **TL;DR:** 本文提出了一种新的、可解释的、具有数学保证的数据偏见缓解策略，能够处理非二元标签和多敏感属性的交叉偏见。

**AI_Comments:** 这篇论文的创新点在于其提出了一种“原则性”的数据偏见缓解方法，强调了可解释性和数学保证，这在实际应用中非常重要。它还特别关注了交叉偏见（即多属性组合导致的偏见），这是一个比单一属性偏见更复杂且更具挑战性的问题。利用表格发现来生成新数据以减少偏见也是一个新颖的思路。该方法的普适性强，能处理非二元标签和多敏感属性，增加了其应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习和数据驱动算法在决策制定中的广泛应用日益增加，但数据中的偏见会对其决策产生不利影响，因此需要一种新的缓解策略来解决数据偏见问题。

**Method:** 提出了一种新的数据偏见缓解策略，该方法具有可解释性，并提供数学正确性保证。它利用表格发现技术寻找可以添加到数据集中的新元组，以创建无偏或偏见较小的数据集。该框架涵盖了具有非二元标签和多个敏感属性的数据，能够测量和缓解单一属性上不明显，但在属性组合（交叉）时才出现的偏见。

**Result:** 在公开数据集上评估了所提出的技术，并提供了结果的理论分析，揭示了关于数据偏见的新颖见解。

**Conclusion:** 本文提出了一种原则性的数据偏见缓解方法，该方法可解释且具有数学保证，能够有效地处理复杂的数据偏见，包括交叉偏见，并通过实验和理论分析验证了其有效性。

> **ai_Abstract:** 本文提出了一种新颖的数据偏见缓解策略，旨在解决机器学习和数据驱动决策中普遍存在的偏见问题。该方法具有可解释性和数学正确性保证，能够利用表格发现技术识别并添加新数据以减少偏见。其创新之处在于能够处理非二元标签和多个敏感属性，特别是识别和缓解由属性组合引起的交叉偏见。研究通过公开数据集的评估和理论分析，为数据偏见提供了新的见解。

> **摘要翻译:** 机器学习和数据驱动算法在决策制定中的广泛使用多年来一直在稳步增长。数据中的偏见会对此类决策产生不利影响。我们提出了一种新的缓解策略来解决数据偏见问题。我们的方法是可解释的，并附带数学正确性保证。它们可以利用表格发现方面的新工作来找到可以添加到数据集中的新元组，以创建无偏或偏见较小的数据集。我们的框架涵盖了具有非二元标签和多个敏感属性的数据。因此，我们能够测量和缓解那些不在单一属性（或特征）上出现，而仅在考虑属性组合时才交叉出现的偏见。我们在公开可用的数据集上评估了我们的技术，并提供了我们结果的理论分析，强调了对数据偏见的新颖见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [129] [ChronoSelect: Robust Learning with Noisy Labels via Dynamics Temporal Memory](https://arxiv.org/abs/2507.18183)
> *ChronoSelect: 通过动态时间记忆实现噪声标签下的鲁棒学习*

*Jianchao Wang, Qingfeng Li, Pengcheng Zheng, Xiaorong Pu, Yazhou Ren* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 噪声标签学习, 时间动态, 深度神经网络, 鲁棒学习, 记忆架构

**Comment:** 

> **TL;DR:** ChronoSelect是一种新的框架，通过利用学习过程的时间动态和四阶段记忆架构来处理噪声标签，实现了鲁棒学习。

**AI_Comments:** ChronoSelect的创新点在于其利用学习过程中的“时间动态”来处理噪声标签，这与传统方法的“静态快照评估”形成对比。其四阶段记忆架构和动态更新机制是关键，有望为噪声学习领域带来新的视角和更鲁棒的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有处理噪声标签的方法缺乏对学习演化中丰富时间动态的利用，导致在过参数化模型记忆噪声标签时泛化性能显著下降。

**Method:** 提出ChronoSelect，一个具有创新四阶段记忆架构的框架，将预测历史压缩成紧凑的时间分布。它采用独特的带受控衰减的滑动更新机制，为每个样本维护四个动态记忆单元，通过时间轨迹分析和双分支一致性将样本精确划分为干净、边界和噪声子集。

**Result:** 广泛的实验表明ChronoSelect在合成和真实世界基准测试中达到了最先进的性能。

**Conclusion:** ChronoSelect通过利用学习过程中的时间动态，有效地解决了噪声标签问题，并提供了理论保证和实验验证的最先进性能。

> **ai_Abstract:** 本文提出了ChronoSelect框架，通过创新的四阶段记忆架构和独特的滑动更新机制，将预测历史压缩为时间分布，以利用学习演化中的时间动态来处理噪声标签。该方法能精确地将样本划分为干净、边界和噪声三类，并在理论上证明了其收敛性和稳定性，在多项基准测试中表现出最先进的性能。

> **摘要翻译:** 在真实世界数据集上训练深度神经网络经常受到噪声标签的阻碍，这些标签可能被过参数化模型记忆，导致泛化性能显著下降。尽管现有的噪声标签学习（LNL）方法取得了相当大的进展，但它们根本上受到静态快照评估的限制，未能利用学习演化中丰富的时间动态。在本文中，我们提出了ChronoSelect（chrono表示其时间性质），一个新颖的框架，其特点是创新的四阶段记忆架构，将预测历史压缩成紧凑的时间分布。我们独特的带有受控衰减的滑动更新机制为每个样本仅维护四个动态记忆单元，逐渐强调最近的模式，同时保留必要的历史知识。这使得通过时间轨迹分析和双分支一致性将样本精确地划分为干净、边界和噪声子集。理论保证证明了该机制在噪声条件下的收敛性和稳定性。广泛的实验表明ChronoSelect在合成和真实世界基准测试中达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [139] [A Markov Categorical Framework for Language Modeling](https://arxiv.org/abs/2507.19247)
> *语言建模的马尔可夫范畴框架*

*Yifan Zhang* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-25**

**Keywords:** 马尔可夫范畴, 语言建模, 负对数似然, 光谱对比学习, 推测解码

**Comment:** Project Page: https://github.com/asiresearch/lm-theory

> **TL;DR:** 本文引入了一个统一的马尔可夫范畴分析框架，用于解构自回归生成过程和NLL目标函数，并提供了现代语言模型有效性的理论解释，包括对推测解码、NLL学习内在随机性以及NLL作为隐式光谱对比学习的见解。

**AI_Comments:** 该论文通过引入马尔可夫范畴这一新颖的数学工具，为自回归语言模型的内部工作机制提供了深层次的理论解释。其创新之处在于将复杂的语言生成过程和NLL优化目标置于严谨的范畴论框架下进行分析，特别是揭示了NLL训练与隐式光谱对比学习之间的联系，这对于理解现代语言模型如何学习到结构化和有意义的表示空间具有重要意义。这有助于推动对LLM可解释性和理论基础的理解。

<details>
  <summary>Details</summary>

**Motivation:** 尽管自回归语言模型在经验上表现强大，但对于为何简单的负对数似然（NLL）目标函数能产生如此多功能表示的深层理论理解仍然难以捉摸。

**Method:** 本文引入了一个统一的分析框架，使用马尔可夫范畴（MCs）来解构自回归（AR）生成过程和负对数似然（NLL）目标。该方法将单步生成映射建模为Stoch范畴中马尔可夫核的组合，并结合统计散度来剖析信息流和学习到的几何结构。

**Result:** 1. 为EAGLE等现代推测解码方法的成功提供了形式化的信息理论依据，量化了这些方法利用的隐藏状态中的信息盈余。
2. 形式化了NLL最小化如何迫使模型不仅学习下一个token，还学习数据的内在条件随机性，并使用范畴熵进行了分析。
3. 证明NLL训练是一种隐式的光谱对比学习形式，通过分析模型预测头的信息几何，表明NLL隐式地强制学习到的表示空间与预测相似性算子的特征谱对齐，从而在没有明确对比对的情况下学习到几何结构化的空间。

**Conclusion:** 这种组合式和信息几何的视角揭示了现代语言模型有效性背后的深层结构原理。

> **ai_Abstract:** 本文提出了一个基于马尔可夫范畴的统一分析框架，旨在深入理解自回归语言模型及其负对数似然（NLL）训练的理论基础。该框架通过将单步生成建模为马尔可夫核的组合，并结合信息几何，揭示了NLL训练如何促进表示学习。主要贡献包括为推测解码提供信息理论解释、阐明NLL如何学习数据的内在条件随机性，以及证明NLL训练是一种隐式的光谱对比学习形式，从而解释了现代语言模型在无需显式对比对的情况下学习结构化表示的深层原理。

> **摘要翻译:** 自回归语言模型分解序列概率，并通过最小化负对数似然（NLL）目标函数进行训练。尽管在经验上表现强大，但对于为何这个简单的目标函数能产生如此多功能表示的深层理论理解仍然难以捉摸。这项工作引入了一个统一的分析框架，使用马尔可夫范畴（MCs）来解构自回归（AR）生成过程和NLL目标函数。我们将单步生成映射建模为Stoch范畴中马尔可夫核的组合。这种组合视图，当与统计散度相结合时，使我们能够剖析信息流和学习到的几何结构。我们的框架做出了三项主要贡献。首先，我们为EAGLE等现代推测解码方法的成功提供了形式化的信息理论依据，量化了这些方法利用的隐藏状态中的信息盈余。其次，我们形式化了NLL最小化如何迫使模型不仅学习下一个token，还学习数据的内在条件随机性，这是一个我们使用范畴熵进行分析的过程。第三，也是最核心的，我们证明NLL训练是一种隐式的光谱对比学习形式。通过分析模型预测头的信息几何，我们表明NLL隐式地强制学习到的表示空间与预测相似性算子的特征谱对齐，从而在没有明确对比对的情况下学习到几何结构化的空间。这种组合式和信息几何的视角揭示了现代语言模型有效性背后的深层结构原理。项目页面：https://github.com/asiresearch/lm-theory

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [141] [Remembering the Markov Property in Cooperative MARL](https://arxiv.org/abs/2507.18333)
> *合作多智能体强化学习中马尔可夫性质的再思考*

*Kale-ab Abebe Tessera, Leonard Hinckeldey, Riccardo Zamboni, David Abel, Amos Storkey* | **Category: cs.LG, cs.MA** | **Updated: 2025-07-24**

**Keywords:** 合作多智能体强化学习, 马尔可夫性质, Dec-POMDP, 基准设计, 约定学习

**Comment:** RLC Finding the Frame Workshop Camera-Ready, 8 pages

> **TL;DR:** 本文认为，当前合作多智能体强化学习算法的成功并非源于有效的马尔可夫信号恢复，而是学习了脆弱的、基于约定的策略，并指出现有基准环境未能充分测试Dec-POMDP的核心假设，呼吁设计新的、更具挑战性的环境。

**AI_Comments:** 这篇论文是一篇重要的立场声明，它挑战了合作多智能体强化学习领域中现有基准和算法成功背后的深层原因。其创新之处在于指出当前模型可能并未真正解决Dec-POMDP的挑战，而是通过学习脆弱的“约定”来规避问题。论文强调了基准设计的重要性，并呼吁社区重新思考如何构建更具挑战性和真实性的环境，以推动MARL的真正进步。这对于理解MARL算法的局限性和未来发展方向具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前模型无关的合作多智能体强化学习（MARL）算法虽然经验上取得成功，但其成功并非源于有效的马尔可夫信号恢复，而是学习了简单的约定，这些约定在与非自适应智能体合作时会失效。此外，现代MARL环境可能未能充分测试去中心化部分可观测马尔可夫决策过程（Dec-POMDP）的核心假设。

**Method:** 本文是一篇立场论文，通过一个有针对性的案例研究，展示了共同适应的智能体可以学习到脆弱的约定。同时，通过分析表明，当任务设计需要时，相同的模型可以学习到基于观察的策略。文章还提出了构建新的合作环境的两个核心原则。

**Result:** 共同适应的智能体可以学习到脆弱的约定，这些约定在与非自适应智能体合作时会失效。然而，当任务设计要求时，相同的学习模型能够学习到基于观察的策略，这表明问题不在于学习模型的根本局限性，而在于基准设计的缺陷。分析还指出，现代MARL环境可能未能充分测试Dec-POMDP的核心假设。

**Conclusion:** 为了确保合作多智能体强化学习的成功需要真正的技能而非脆弱的共同适应约定，本文倡导构建基于以下两个核心原则的新型合作环境：1) 行为基于观察；2) 对其他智能体进行基于记忆的推理。

> **ai_Abstract:** 本文作为一篇立场论文，探讨了合作多智能体强化学习中现有算法的局限性。作者认为，当前算法的经验成功并非源于有效的马尔可夫信号恢复，而是由于学习了易碎的、基于约定的策略。通过案例研究，论文展示了共同适应的智能体可能形成脆弱的约定，导致在与非自适应智能体合作时失败。研究指出，问题在于现有基准环境未能充分测试Dec-POMDP的核心假设，而非学习模型的根本缺陷。因此，文章呼吁设计新的合作环境，这些环境应要求智能体行为基于观察并进行基于记忆的推理，以促进真正技能的学习。

> **摘要翻译:** 合作多智能体强化学习（MARL）通常被形式化为去中心化部分可观测马尔可夫决策过程（Dec-POMDP），其中智能体必须对环境和其他智能体的行为进行推理。在实践中，当前的无模型MARL算法使用简单的循环函数逼近器来解决使用部分信息推理其他智能体的挑战。在这篇立场论文中，我们认为这些方法的经验成功并非源于有效的马尔可夫信号恢复，而是学习了绕过环境观察和记忆的简单约定。通过一个有针对性的案例研究，我们表明共同适应的智能体可以学习到脆弱的约定，这些约定在与非自适应智能体合作时会失败。关键的是，当任务设计需要时，相同的模型可以学习到基于观察的策略，这揭示了问题并非学习模型的根本限制，而是基准设计的失败。我们的分析还表明，现代MARL环境可能未能充分测试Dec-POMDP的核心假设。因此，我们倡导基于两个核心原则构建新的合作环境：(1) 行为基于观察，以及(2) 对其他智能体进行基于记忆的推理，确保成功需要真正的技能而非脆弱的、共同适应的协议。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [151] [Gait Recognition Based on Tiny ML and IMU Sensors](https://arxiv.org/abs/2507.18627)
> *基于Tiny ML和IMU传感器的步态识别*

*Jiahang Zhang, Mingtong Chen, Zhengbao Yang* | **Category: cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 步态识别, Tiny ML, IMU传感器, 深度神经网络, 边缘计算

**Comment:** 

> **TL;DR:** 该项目开发了一个基于Tiny ML和IMU传感器的步态识别系统，利用XIAO-nRF52840 Sense微控制器和LSM6DS3 IMU传感器捕获运动数据，并通过Edge Impulse平台训练DNN模型，实现了对四种活动的实时分类，准确率超过80%，并支持低功耗运行和异常检测。

**AI_Comments:** 该论文的创新之处在于将Tiny ML技术与IMU传感器结合，实现了低功耗、实时且高准确率的步态识别系统。其重要性体现在为电池供电或能量收集设备提供了一个实用的解决方案，扩展了边缘AI在可穿戴和物联网设备中的应用。模型的80%以上准确率在特定应用场景下具有实用价值，异常检测的集成也提升了系统的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 开发一个低功耗、实时且适用于电池供电或能量收集设备的步态识别系统，以有效分类不同的日常活动并增强系统的鲁棒性。

**Method:** 该系统使用XIAO-nRF52840 Sense微控制器和LSM6DS3 IMU传感器捕获包括加速度和角速度在内的运动数据。数据通过Edge Impulse平台进行处理，包括使用滑动窗口和数据归一化等技术提取特征。随后训练一个深度神经网络（DNN）分类器进行活动识别，并直接部署到微控制器上实现实时分类。系统还集成了异常检测功能。

**Result:** 该模型在测试数据集上实现了超过80%的准确率，有效分类了四种活动（行走、静止、上楼、下楼）。系统还支持异常检测，增强了鲁棒性。Tiny ML的集成确保了低功耗运行。

**Conclusion:** 该研究成功开发了一个基于Tiny ML和IMU传感器的步态识别系统，该系统能够以高准确率实时分类多种日常活动，并具备低功耗和异常检测能力，适用于资源受限的设备。

> **ai_Abstract:** 该项目开发了一个基于Tiny ML和IMU传感器的步态识别系统，利用XIAO-nRF52840 Sense微控制器和LSM6DS3 IMU传感器捕获行走、静止、上楼和下楼等四种活动的运动数据。通过Edge Impulse平台进行数据预处理和深度神经网络（DNN）模型训练，实现了实时活动分类，准确率超过80%。该系统还具备异常检测功能和低功耗特性，适用于资源受限的设备。

> **摘要翻译:** 该项目展示了使用微型机器学习（Tiny ML）和惯性测量单元（IMU）传感器开发步态识别系统的过程。该系统利用XIAO-nRF52840 Sense微控制器和LSM6DS3 IMU传感器，从四种不同活动（行走、静止、上楼和下楼）中捕获运动数据，包括加速度和角速度。所收集的数据通过边缘AI平台Edge Impulse进行处理，该平台能够训练机器学习模型并将其直接部署到微控制器上，以实现实时活动分类。数据预处理步骤涉及使用滑动窗口和数据归一化等技术从原始传感器数据中提取相关特征，然后训练一个深度神经网络（DNN）分类器进行活动识别。该模型在测试数据集上实现了超过80%的准确率，证明了其有效分类这四种活动的能力。此外，该平台还支持异常检测，进一步增强了系统的鲁棒性。Tiny ML的集成确保了低功耗运行，使其适用于电池供电或能量收集设备。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [169] [Moving Out: Physically-grounded Human-AI Collaboration](https://arxiv.org/abs/2507.18623)
> *搬出：物理接地的人机协作*

*Xuhui Kang, Sung-Wook Lee, Haolin Liu, Yuyan Wang, Yen-Ling Kuo* | **Category: cs.LG, cs.AI, cs.MA** | **Updated: 2025-07-24**

**Keywords:** 物理接地, 人机协作, 基准, 具身智能体, BASS

**Comment:** 24 pages, 8 figures

> **TL;DR:** 本文介绍了“Moving Out”基准，用于物理接地的人机协作，并提出了BASS方法，该方法在AI-AI和人机协作中表现优于现有模型。

**AI_Comments:** 本文的创新之处在于提出了一个专门用于物理接地人机协作的基准“Moving Out”，并结合了真实的人机交互数据。BASS方法的提出也为解决物理环境中具身智能体的协作挑战提供了一个有效途径，其在AI-AI和人机协作任务中的优异表现凸显了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 对于具身智能体（如机器人）而言，适应环境中的物理动作和约束对于与人类有效协作至关重要。这种物理接地的人机协作必须考虑由物理约束引起的连续状态-动作空间和受限动态的复杂性。

**Method:** 本文引入了一个名为“Moving Out”的新型人机协作基准，该基准模拟了受物理属性和约束影响的广泛协作模式。利用该基准，设计了两个任务并收集了人机交互数据。为应对物理环境中的挑战，提出了一种新颖的方法BASS（行为增强、模拟和选择），旨在增强智能体的多样性及其对行动结果的理解。

**Result:** 实验结果表明，BASS方法在AI-AI和人机协作方面均优于现有最先进的模型。

**Conclusion:** 通过引入“Moving Out”基准和BASS方法，本研究有效提升了具身智能体在物理接地人机协作中的表现，证明了其在复杂物理环境中适应多样化人类行为和处理物理约束的能力。

> **ai_Abstract:** 本文提出了“Moving Out”基准，旨在促进物理接地的人机协作研究，通过模拟复杂的物理约束下的协作场景，并收集人机交互数据。为解决物理环境中的挑战，论文提出了一种名为BASS的新型方法，该方法通过行为增强、模拟和选择来提升智能体的多样性和对行动结果的理解。实验证明，BASS在AI-AI和人机协作任务中均超越了现有最优模型。

> **摘要翻译:** 具身智能体（例如机器人）适应环境中物理动作和约束的能力对于与人类有效协作至关重要。这种物理接地的人工智能协作必须考虑到物理约束导致的连续状态-动作空间和受限动态的复杂性增加。在本文中，我们引入了“Moving Out”，这是一个新的人工智能协作基准，它模拟了受物理属性和约束影响的各种协作模式，例如一起移动重物和保持一致的动作以将大件物品绕过拐角。使用“Moving Out”，我们设计了两个任务并收集了人机交互数据，以评估模型适应不同人类行为和未见物理属性的能力。为了解决物理环境中的挑战，我们提出了一种新颖的方法，BASS（行为增强、模拟和选择），以增强智能体的多样性及其对行动结果的理解。我们的实验表明，BASS在AI-AI和人机协作方面均优于现有最先进的模型。项目页面可在https://live-robotics-uva.github.io/movingout_ai/查看。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [170] [UrbanPulse: A Cross-City Deep Learning Framework for Ultra-Fine-Grained Population Transfer Prediction](https://arxiv.org/abs/2507.17924)
> *UrbanPulse: 跨城市深度学习框架用于超细粒度人口转移预测*

*Hongrong Yang, Markus Schlaepfer* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 人口流动预测, 深度学习, 迁移学习, 城市规划, 时空预测

**Comment:** 

> **TL;DR:** UrbanPulse是一个跨城市的深度学习框架，通过将每个POI视为独立节点，实现超细粒度的城市OD流预测，并采用三阶段迁移学习策略以确保泛化能力，在实际数据上表现出最先进的准确性和可扩展性。

**AI_Comments:** UrbanPulse的创新之处在于其将每个POI作为独立节点处理，实现了前所未有的超细粒度预测，并结合了图卷积网络和Transformer的优势来捕捉复杂的时空关系。其三阶段迁移学习策略是解决跨城市泛化难题的关键，大大提升了模型的实用性和部署潜力。这对于城市规划和管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确的人口流动预测对城市规划、交通管理和公共卫生至关重要，然而现有方法存在局限性：传统模型依赖静态空间假设；深度学习模型难以跨城市泛化；大型语言模型计算成本高且未能捕捉空间结构；许多方法通过聚合兴趣点（POI）或限制区域覆盖范围来牺牲分辨率，从而限制了全市分析的效用。

**Method:** 本文引入了UrbanPulse，一个可扩展的深度学习框架，通过将每个POI视为独立节点，提供超细粒度的全市OD流预测。它结合了时间图卷积编码器和基于Transformer的解码器来建模多尺度时空依赖性。为确保在不同城市环境中的鲁棒泛化能力，UrbanPulse采用了三阶段迁移学习策略：在大规模城市图上进行预训练、冷启动适应和强化学习微调。

**Result:** 在加利福尼亚州三个大都市区的超过1.03亿条清洗过的GPS记录上进行评估，UrbanPulse实现了最先进的准确性和可扩展性。

**Conclusion:** 通过高效的迁移学习，UrbanPulse在使高分辨率、人工智能驱动的城市预测在不同城市中实际部署方面迈出了关键一步。

> **ai_Abstract:** 本文介绍了UrbanPulse，一个创新的深度学习框架，旨在解决现有方法在人口流动预测中的局限性。UrbanPulse通过将每个兴趣点（POI）视为独立节点，实现了超细粒度的全市起源-目的地（OD）流预测。该框架结合了时间图卷积编码器和基于Transformer的解码器来捕捉复杂的多尺度时空依赖性，并采用独特的三阶段迁移学习策略以确保其在不同城市环境下的强大泛化能力。在加利福尼亚州三个大都市区的超过1亿条GPS记录上的评估表明，UrbanPulse在准确性和可扩展性方面均达到了最先进水平，为高分辨率、AI驱动的城市预测的实际部署铺平了道路。

> **摘要翻译:** 人口流动预测对于城市规划、交通管理和公共卫生至关重要。然而，现有方法面临着关键限制：传统模型依赖于静态空间假设，深度学习模型难以实现跨城市泛化，而大型语言模型（LLMs）则计算成本高昂且未能捕捉空间结构。此外，许多方法通过聚类兴趣点（POIs）或将覆盖范围限制在子区域来牺牲分辨率，从而限制了它们在全市分析中的效用。我们引入了UrbanPulse，一个可扩展的深度学习框架，通过将每个POI视为一个独立节点，提供超细粒度的全市OD流预测。它结合了时间图卷积编码器和基于Transformer的解码器来建模多尺度时空依赖性。为了确保在不同城市环境中的鲁棒泛化能力，UrbanPulse采用了三阶段迁移学习策略：在大规模城市图上进行预训练、冷启动适应和强化学习微调。在加利福尼亚州三个大都市区的超过1.03亿条清洗过的GPS记录上进行评估，UrbanPulse实现了最先进的准确性和可扩展性。通过高效的迁移学习，UrbanPulse在使高分辨率、人工智能驱动的城市预测在不同城市中实际部署方面迈出了关键一步。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [171] [Goal-based Trajectory Prediction for improved Cross-Dataset Generalization](https://arxiv.org/abs/2507.18196)
> *基于目标的轨迹预测，用于改进跨数据集泛化*

*Daniel Grimm, Ahmed Abouelazm, J. Marius Zöllner* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 轨迹预测, 图神经网络, 跨数据集泛化, 自动驾驶, 目标分类

**Comment:** Accepted on IEEE ITSC 2025

> **TL;DR:** 本文提出了一种新的图神经网络（GNN），通过多阶段目标分类，提高了轨迹预测模型在未见场景中的泛化能力，并在跨数据集评估中得到验证。

**AI_Comments:** 本文的创新点在于引入了基于目标的轨迹预测方法，并利用异构图和多阶段分类来提高模型的跨数据集泛化能力。这种方法对于自动驾驶领域至关重要，因为它解决了模型在不同地理区域或新场景中部署时的性能下降问题。通过在知名数据集上进行跨数据集评估，增加了研究结果的可信度。未来的工作可以探索更多样化的目标定义或更复杂的图结构以进一步提升性能。

<details>
  <summary>Details</summary>

**Motivation:** 当前最先进的轨迹预测模型在训练数据集上表现良好，但在部署到新的/未见区域时性能显著下降，表明模型缺乏泛化能力。

**Method:** 本文引入了一种新的图神经网络（GNN），该网络利用包含交通参与者和矢量化道路网络的异构图。后者用于通过多阶段方法对目标（即预测轨迹的终点）进行分类。

**Result:** 通过跨数据集评估（即在Argoverse2上训练并在NuScenes上评估），证明了目标选择过程的有效性，从而实现了对未见场景的更好泛化。

**Conclusion:** 通过引入基于目标的轨迹预测方法，可以显著提高模型在未见场景中的泛化能力。

> **ai_Abstract:** 本文针对自动驾驶中轨迹预测模型泛化能力不足的问题，提出了一种新的基于目标分类的图神经网络（GNN）。该GNN利用包含交通参与者和矢量化道路网络的异构图，通过多阶段方法对预测轨迹的终点进行分类，以提高模型在未见场景中的泛化能力。通过在Argoverse2上训练并在NuScenes上评估的跨数据集实验，验证了所提出目标选择过程的有效性。

> **摘要翻译:** 为了实现完全自动驾驶，需要对周围环境有很好的理解。特别是预测其他交通参与者的未来状态带来了非平凡的挑战。当前的SotA模型在真实数据集（例如Argoverse2、NuScenes）上训练时已经显示出有希望的结果。当这些模型部署到新的/未见区域时，问题就出现了。通常，性能会显著下降，这表明模型缺乏泛化能力。在这项工作中，我们引入了一种新的图神经网络（GNN），它利用包含交通参与者和矢量化道路网络的异构图。后者用于通过多阶段方法对目标（即预测轨迹的终点）进行分类，从而更好地泛化到未见场景。我们通过跨数据集评估（即在Argoverse2上训练并在NuScenes上评估）展示了目标选择过程的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [173] [Beyond Euclid: An Illustrated Guide to Modern Machine Learning with Geometric, Topological, and Algebraic Structures](https://arxiv.org/abs/2407.09468)
> *超越欧几里得：几何、拓扑和代数结构在现代机器学习中的图解指南*

*Mathilde Papillon, Sophia Sanborn, Johan Mathe, Louisa Cornelis, Abby Bertics, Domas Buracas, Hansen J Lillemark, Christian Shewmake, Fatih Dinc, Xavier Pennec, Nina Miolane* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 非欧几里得数据, 几何结构, 拓扑结构, 代数结构, 机器学习综述

**Comment:** 

> **TL;DR:** 现代机器学习需要处理非欧几里得数据，本文综述了利用几何、拓扑和代数结构来泛化经典机器学习方法的新兴领域。

**AI_Comments:** 这篇综述的重要性在于它系统地梳理了非欧几里得结构在现代机器学习中的应用，为研究者提供了一个全面的入门指南和统一的框架。其创新点在于提出的图形分类法有助于理解和整合这一快速发展的领域。

<details>
  <summary>Details</summary>

**Motivation:** 传统机器学习主要针对欧几里得空间数据，但现代机器学习越来越多地遇到具有复杂几何、拓扑和代数结构的非欧几里得数据，需要更广阔的数学视角来提取知识。

**Method:** 本文是一篇综述，旨在为这个快速发展的领域提供一个易于理解的入口，并提出了一个图形分类法，将最新进展整合到一个直观的统一框架中。

**Result:** 提供了对当前挑战的见解，并强调了该领域未来发展的激动人心的机遇。

**Conclusion:** 通过整合非欧几里得结构，现代机器学习正在被重新定义，以处理更复杂的数据类型，并为未来的发展提供了新的方向。

> **ai_Abstract:** 本文综述了利用几何、拓扑和代数结构处理非欧几里得数据的新兴现代机器学习领域。它指出传统机器学习在处理复杂非欧几里得数据时的局限性，并提出了一个图形分类法来整合最新进展，同时探讨了该领域的挑战与机遇。

> **摘要翻译:** 欧几里得几何的持久遗产支撑着经典机器学习，几十年来，它主要针对欧几里得空间中的数据而开发。然而，现代机器学习越来越多地遇到本质上是非欧几里得的丰富结构化数据。这些数据可以表现出复杂的几何、拓扑和代数结构：从时空曲率的几何，到大脑中神经元之间拓扑复杂的相互作用，再到描述物理系统对称性的代数变换。从这种非欧几里得数据中提取知识需要更广阔的数学视角。呼应19世纪非欧几里得几何革命的兴起，一个新兴的研究方向正在用非欧几里得结构重新定义现代机器学习。其目标是：将经典方法泛化到具有几何、拓扑和代数结构的非常规数据类型。在这篇综述中，我们为这个快速发展的领域提供了一个易于理解的入口，并提出了一个图形分类法，将最新进展整合到一个直观的统一框架中。随后，我们深入探讨了当前的挑战，并强调了该领域未来发展的激动人心的机遇。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [175] [Noise Contrastive Estimation-based Matching Framework for Low-Resource Security Attack Pattern Recognition](https://arxiv.org/abs/2401.10337)
> *基于噪声对比估计的低资源安全攻击模式识别匹配框架*

*Tu Nguyen, Nedim Šrndić, Alexander Neth* | **Category: cs.LG, cs.AI, cs.CL, cs.CR** | **Updated: 2025-07-24**

**Keywords:** TTP映射, 噪声对比估计, 语义相似性, 神经网络匹配, 低资源学习

**Comment:** accepted at EACL 2024, in ARR October 2023

> **TL;DR:** 针对网络安全TTPs识别中传统分类方法的挑战，本文提出一种基于语义相似性和噪声对比估计的神经网络匹配框架，以在资源受限下进行有效学习。

**AI_Comments:** 本文的创新点在于将TTP映射问题从传统的分类任务重新定义为基于语义相似性的匹配任务，这有效地规避了大数据量标签空间、标签分布偏斜和复杂层次结构带来的挑战。采用噪声对比估计（NCE）和采样机制，使得模型能够在资源受限的环境下进行有效学习，这对于实际应用具有重要意义。该方法为低资源条件下的复杂模式识别提供了一种新思路。

<details>
  <summary>Details</summary>

**Motivation:** 识别网络安全文本中的TTPs（攻击模式）是一项重要且具挑战性的任务。传统的机器学习方法（多分类或多标签分类）在处理此问题时面临困难，因为TTP类别数量庞大、标签分布倾斜以及标签空间结构复杂，这些都阻碍了模型的学习能力。

**Method:** 本文将TTP映射问题重新定义为一种新的学习范式，即通过文本与TTP标签之间的直接语义相似性来决定分配，从而降低了在大标签空间中竞争的复杂性。为此，作者提出了一个神经网络匹配架构，该架构包含一个有效的基于采样的“学习-比较”机制，以促进在资源受限情况下的匹配模型学习过程。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对网络安全领域中TTPs识别的挑战，特别是传统分类方法因类别多、分布不均和结构复杂而受限的问题，提出了一种新的学习范式。该范式通过直接衡量文本与TTP标签间的语义相似性来完成分配，而非传统的分类竞争。为此，作者设计了一个基于噪声对比估计的神经网络匹配架构，该架构采用有效的采样学习比较机制，旨在提升资源受限情况下的模型学习效率。

> **摘要翻译:** 策略、技术和程序（TTPs）代表了网络安全领域中复杂的攻击模式，它们以百科全书式的形式在文本知识库中描述。在网络安全文本中识别TTPs，通常称为TTP映射，是一项重要且具有挑战性的任务。传统的学习方法通常在经典的多类别或多标签分类设置中解决该问题。这种设置由于类别数量庞大（即TTPs）、不可避免的标签分布倾斜以及标签空间复杂的层次结构而阻碍了模型的学习能力。我们以一种不同的学习范式来表述这个问题，其中文本到TTP标签的分配由两者之间的直接语义相似性决定，从而降低了在大型标签空间中单独竞争的复杂性。为此，我们提出了一种具有有效基于采样的“学习-比较”机制的神经网络匹配架构，尽管资源受限，它仍能促进匹配模型的学习过程。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [190] [Regression-aware Continual Learning for Android Malware Detection](https://arxiv.org/abs/2507.18313)
> *针对安卓恶意软件检测的回归感知持续学习*

*Daniele Ghiani, Daniele Angioni, Giorgio Piras, Angelo Sotgiu, Luca Minnei, Srishti Gupta, Maura Pintor, Fabio Roli, Battista Biggio* | **Category: cs.LG, cs.CR** | **Updated: 2025-07-24**

**Keywords:** 持续学习, 恶意软件检测, 安全性回归, 回归感知惩罚, 正一致训练

**Comment:** Submitted to IEEE Transactions on Information Forensics and Security

> **TL;DR:** 本文提出了一种回归感知惩罚机制，通过改进PCT方法，有效缓解了持续学习中安卓恶意软件检测的安全性回归问题。

**AI_Comments:** 这篇论文的创新点在于首次明确提出了“安全性回归”这一在持续学习应用于安全领域时被忽视的关键问题，并为其提供了形式化定义和量化方法。其提出的回归感知惩罚机制，特别是对PCT的适应性应用，为解决这一问题提供了一个有效且模型无关的方案。这对于提高恶意软件检测系统的长期可靠性和用户信任具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 恶意软件快速演变，导致机器学习检测器需要持续适应。传统方法因数据量巨大而无法进行完全再训练。持续学习虽可扩展但存在“安全性回归”问题，即先前能正确检测的恶意软件在模型更新后却逃避检测，这会严重损害用户信任并带来风险。

**Method:** 作者首先形式化并量化了持续学习恶意软件检测器中的安全性回归问题。接着，他们提出了一种回归感知惩罚机制来缓解此问题。具体而言，他们将正一致训练（Positive Congruent Training, PCT）方法应用于持续学习设置，以模型无关的方式保留先前的预测行为。

**Result:** 在ELSA、Tesseract和AZ-Class数据集上的实验表明，所提出的方法在不同的持续学习场景下有效减少了回归，并同时保持了长期的强大检测性能。

**Conclusion:** 本文成功解决了持续学习中恶意软件检测的安全性回归问题，通过提出的回归感知惩罚机制和对PCT的适应，显著提高了检测器的可靠性和用户信任。

> **ai_Abstract:** 本文针对持续学习（CL）中安卓恶意软件检测面临的“安全性回归”问题进行了深入研究。安全性回归表现为模型更新后，先前能正确识别的恶意软件样本却逃避检测。为解决这一关键挑战，作者形式化并量化了该问题，并提出了一种回归感知惩罚机制。该机制通过将正一致训练（PCT）应用于CL环境，以模型无关的方式保留了模型先前的预测行为。实验结果表明，该方法有效降低了安全性回归，并维持了良好的检测性能。

> **摘要翻译:** 恶意软件迅速演变，迫使基于机器学习（ML）的检测器不断适应。随着杀毒厂商每天处理数十万个新样本，数据集可能增长到数十亿个示例，使得完全再训练变得不切实际。持续学习（CL）作为一种可扩展的替代方案应运而生，它无需完全访问数据即可实现增量更新，同时减轻灾难性遗忘。在这项工作中，我们分析了此背景下被忽视但至关重要的问题：安全性回归。与遗忘（表现为先前见过的数据上的整体性能下降）不同，安全性回归捕获了样本级别的有害预测变化，例如曾被正确检测的恶意软件样本在模型更新后却逃避了检测。尽管常被忽视，回归在安全关键型应用中构成了严重风险，因为系统中悄无声息地重新引入先前已检测到的威胁可能会损害用户对整个更新过程的信任。为了解决这个问题，我们形式化并量化了基于CL的恶意软件检测器中的安全性回归，并提出了一种回归感知惩罚机制来缓解它。具体来说，我们将正一致训练（Positive Congruent Training, PCT）应用于CL设置，以模型无关的方式保留先前的预测行为。在ELSA、Tesseract和AZ-Class数据集上的实验表明，我们的方法在不同的CL场景下有效减少了回归，同时随着时间的推移保持了强大的检测性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [197] [XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare](https://arxiv.org/abs/2405.06270)
> *XAI4LLM：让机器学习模型与大型语言模型协同增强医疗领域的上下文学习*

*Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-25**

**Keywords:** 上下文学习, 大型语言模型, 临床数据, 公平性, 医疗AI

**Comment:** 

> **TL;DR:** 本研究引入了一个知识引导的上下文学习（ICL）框架，旨在使大型语言模型（LLM）能够有效处理结构化临床数据，并在心脏病和糖尿病预测任务中与传统机器学习（ML）模型进行比较。研究发现，虽然ML在平衡精度-召回率方面表现更优，但LLM在整合领域知识的叙述性提示下能提高召回率并显著减少性别偏见，尽管存在推理延迟，但LLM提供了零样本部署和增强公平性的优势。

**AI_Comments:** 这项研究的创新之处在于其首次全面分析了大型语言模型（LLM）在表格临床数据上进行上下文学习（ICL）的设计考量，并提出了一种知识引导的ICL框架。其重要性体现在探索了LLM在医疗领域应用中的潜力，特别是在提高召回率和减少性别偏见方面的优势，这对于构建公平的临床决策支持系统至关重要。尽管当前存在推理延迟的局限性，但该研究为未来LLM在医疗领域的应用，特别是结合可解释人工智能（XAI）和多模态扩展指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 临床决策支持系统需要不仅高度准确，而且公平且对漏诊后果敏感的模型。本研究旨在解决大型语言模型（LLM）有效处理结构化临床数据的挑战，并探索其在医疗领域（如心脏病和糖尿病预测）的上下文学习（ICL）能力。

**Method:** 研究引入了一个知识引导的上下文学习（ICL）框架，使大型语言模型（LLM）能够处理结构化临床数据。该方法整合了领域特定特征分组、平衡的少量样本示例和任务特定提示策略。通过系统评估了七十种不同的ICL设计（包括各种提示变体和两种通信风格：自然语言叙述和数字对话），并将其性能与稳健的经典机器学习（ML）基准在心脏病和糖尿病预测任务上进行比较。

**Result:** 传统机器学习模型在平衡精度-召回率场景中保持卓越性能。采用叙述性提示并整合领域知识的LLM实现了更高的召回率，并显著减少了性别偏见，有效将公平性差异降低了一个数量级。尽管推理延迟增加，LLM提供了零样本部署和增强公平性等显著优势。

**Conclusion:** 本研究首次全面分析了将LLM应用于表格临床任务的上下文学习（ICL）设计考量，并强调蒸馏和多模态扩展是未来研究的有前景方向。尽管存在推理延迟，但LLM在提高召回率和减少偏见方面展现出独特优势。

> **ai_Abstract:** 本研究提出了一种名为XAI4LLM的知识引导上下文学习（ICL）框架，旨在增强大型语言模型（LLM）处理结构化临床数据的能力，以支持医疗决策系统。该框架结合了领域特征分组、少量样本学习和特定提示策略，并在心脏病和糖尿病预测任务上进行了广泛评估，与传统机器学习（ML）模型进行比较。结果表明，虽然ML在平衡性能上占优，但LLM在特定提示下能显著提高召回率并降低性别偏见，展现出零样本部署和提升公平性的潜力，为LLM在表格临床数据应用中的ICL设计提供了首次全面分析。

> **摘要翻译:** 临床决策支持系统需要不仅高度准确，而且公平且对漏诊后果敏感的模型。在本研究中，我们引入了一个知识引导的上下文学习（ICL）框架，旨在使大型语言模型（LLM）能够有效处理结构化临床数据。我们的方法整合了领域特定特征分组、精心平衡的少量样本示例和任务特定提示策略。我们通过各种提示变体和两种不同的通信风格——自然语言叙述和数字对话——系统地评估了七十种不同的ICL设计，并将其性能与稳健的经典机器学习（ML）基准在心脏病和糖尿病预测任务上进行了比较。
我们的发现表明，虽然传统ML模型在平衡精度-召回率场景中保持卓越性能，但采用叙述性提示并整合领域知识的LLM实现了更高的召回率，并显著减少了性别偏见，有效地将公平性差异降低了一个数量级。尽管目前存在推理延迟增加的局限性，但LLM提供了显著优势，包括零样本部署能力和增强的公平性。这项研究首次全面分析了将LLM应用于表格临床任务的ICL设计考量，并强调蒸馏和多模态扩展是未来研究的有前景方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [216] [On the Approximation of Stationary Processes using the ARMA Model](https://arxiv.org/abs/2408.10610)
> *关于使用ARMA模型逼近平稳过程*

*Anand Ganesh, Babhrubahan Bose, Anand Rajagopalan* | **Category: cs.LG, math.PR, stat.ME, 60G10, G.3** | **Updated: 2025-07-24**

**Keywords:** ARMA模型, 平稳过程, 逼近误差, L无穷范数, 巴拿赫代数, 传递函数

**Comment:** 16 pages, 1 figure

> **TL;DR:** 该论文重新审视了ARMA模型逼近平稳过程的误差问题，引入了一种L无穷范数来控制L2范数，并证明了平稳过程的某个子空间在L无穷范数下构成巴拿赫代数，其可逆性定义更具普适性，并计算了具体的逼近界限。

**AI_Comments:** 该论文为分析ARMA模型逼近误差提供了一个新颖的理论框架，通过在传递函数域引入$L^{\infty}$范数，并建立平稳过程子空间的巴拿赫代数结构，为可逆性提供了更稳健和普适的定义。这一创新方法有望带来更精确的误差界限，并加深对时间序列分析中模型逼近的理解，超越了传统的$\ell^1$条件。

<details>
  <summary>Details</summary>

**Motivation:** 重新审视与自回归滑动平均（ARMA）模型相关的一个旧问题，即量化和界定真实平稳过程与ARMA模型之间的逼近误差。

**Method:** 该研究采用ARMA模型的传递函数表示，引入并使用$L^{\infty}$范数来控制$L^2$范数，并证明了平稳过程的特定子空间（包括ARMA模型）在该范数下形成一个巴拿赫代数。此外，还在连续传递函数的背景下计算了明确的逼近界限，并批判了Padé逼近和简约模型的一些启发式思想。

**Result:** 1. $L^{\infty}$范数作为一种有效的替代范数，能够控制$L^2$范数，并具有与倒谱范数相当的结构特性。2. 包含ARMA模型的平稳过程的某个子空间在$L^{\infty}$范数下构成一个巴拿赫代数，该代数遵循$H^{\infty}$传递函数的群结构。3. 该代数中可逆性的自然定义与ARMA可逆性的原始定义一致，并且比维纳的$\ell^1$条件更好地推广到非ARMA过程。4. 在连续传递函数背景下计算了一些明确的逼近界限。

**Conclusion:** 该论文通过引入$L^{\infty}$范数，为理解和界定ARMA模型逼近误差提供了一个新的理论框架，证明了该范数在控制$L^2$范数和结构特性上的有效性。研究表明，在$L^{\infty}$范数下，平稳过程的特定子空间形成一个巴拿赫代数，其可逆性定义更具普适性。此外，论文还提供了具体的逼近界限，并对现有启发式方法进行了批判。

> **ai_Abstract:** 该论文重新审视了平稳过程与ARMA模型之间的逼近误差问题。研究引入了一种基于传递函数的$L^{\infty}$范数，并证明其能有效控制$L^2$范数且具有与倒谱范数相似的结构特性。论文指出，包含ARMA模型在内的平稳过程的某个子空间在该$L^{\infty}$范数下构成一个巴拿赫代数，且其可逆性定义比传统条件更具普适性。此外，文中还给出了明确的逼近界限，并对现有启发式方法进行了评述。

> **摘要翻译:** 我们重新审视了一个与自回归滑动平均（ARMA）模型相关的旧问题，即量化和界定真实平稳过程$X_t$与ARMA模型$Y_t$之间的逼近误差。我们采用ARMA模型的传递函数表示，并表明相关的$L^{\infty}$范数提供了一个有效的替代范数，它可以控制$L^2$范数，并具有与倒谱范数相当的结构特性。我们证明了平稳过程的某个子空间（包括ARMA模型）在$L^{\infty}$范数下构成一个巴拿赫代数，该代数遵循$H^{\infty}$传递函数的群结构。该代数中可逆性的自然定义与ARMA可逆性的原始定义一致，并且比维纳的$\ell^1$条件更好地推广到非ARMA过程。最后，我们在连续传递函数的更简单背景下计算了一些明确的逼近界限，并批判了关于Padé逼近和简约模型的一些启发式思想。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [217] [ToolACE: Winning the Points of LLM Function Calling](https://arxiv.org/abs/2409.00920)
> *ToolACE：赢得大型语言模型函数调用的高分*

*Weiwen Liu, Xu Huang, Xingshan Zeng, Xinlong Hao, Shuai Yu, Dexun Li, Shuai Wang, Weinan Gan, Zhengying Liu, Yuanqing Yu, Zezhong Wang, Yuxian Wang, Wu Ning, Yutai Hou, Bin Wang, Chuhan Wu, Xinzhi Wang, Yong Liu, Yasheng Wang, Duyu Tang, Dandan Tu, Lifeng Shang, Xin Jiang, Ruiming Tang, Defu Lian, Qun Liu, Enhong Chen* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-25**

**Keywords:** 函数调用, 大型语言模型, 数据生成, 合成数据, ToolACE

**Comment:** 21 pages, 22 figures

> **TL;DR:** ToolACE是一个自动化代理管道，用于生成高质量、多样化的函数调用训练数据，其合成数据训练的模型在函数调用排行榜上达到了SOTA性能，甚至媲美GPT-4。

**AI_Comments:** ToolACE的创新点在于其自进化合成过程和双层验证系统，有效解决了高质量函数调用数据生成中的覆盖率和准确性挑战。该方法能够以自动化方式生成大量有效训练数据，显著降低了数据收集和标注成本。其重要性在于，它使得较小规模的LLM也能在函数调用任务上达到SOTA性能，有望推动LLM在实际应用中的普及和效率提升。

<details>
  <summary>Details</summary>

**Motivation:** 高质量和多样化的函数调用训练数据对于解锁大型语言模型（LLM）的函数调用能力至关重要，但真实数据难以收集和标注，现有合成数据管道缺乏覆盖率和准确性。

**Method:** 本文提出了ToolACE，一个自动代理管道，通过新颖的自进化合成过程，策划了一个包含26,507个多样化API的综合API池。对话通过多个代理之间的相互作用生成，并由形式化的思维过程指导。为确保数据准确性，实现了结合基于规则和基于模型的双层验证系统。

**Result:** 使用ToolACE合成数据训练的模型，即使只有80亿参数，也能在Berkeley函数调用排行榜上实现最先进的性能，媲美最新的GPT-4模型。

**Conclusion:** ToolACE能够生成高质量、多样化且准确的函数调用数据，有效提升了大型语言模型在函数调用任务上的表现，使其即使在较小规模下也能达到领先水平。

> **ai_Abstract:** 本文介绍了ToolACE，一个创新的自动化代理管道，旨在解决大型语言模型函数调用训练数据稀缺的问题。ToolACE通过自进化合成过程构建了一个庞大的API池，并利用多代理交互和双层验证系统生成准确、复杂且多样化的函数调用对话数据。实验证明，使用ToolACE合成数据训练的小参数模型，在函数调用性能上达到了当前最佳水平，甚至能与GPT-4相媲美。

> **摘要翻译:** 函数调用显著扩展了大型语言模型的应用边界，其中高质量和多样化的训练数据对于解锁此能力至关重要。然而，真实的函数调用数据很难收集和标注，而现有管道生成的合成数据往往缺乏覆盖率和准确性。在本文中，我们提出了ToolACE，一个旨在生成准确、复杂和多样化工具学习数据的自动化代理管道。ToolACE利用新颖的自进化合成过程来策划一个包含26,507个多样化API的综合API池。对话通过多个代理之间的相互作用进一步生成，并由形式化的思维过程指导。为确保数据准确性，我们实现了结合基于规则和基于模型的双层验证系统。我们证明了用我们合成数据训练的模型，即使只有80亿参数，也能在Berkeley函数调用排行榜上实现最先进的性能，媲美最新的GPT-4模型。我们的模型和部分数据已在https://huggingface.co/Team-ACE 公开。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [220] [FedSA-GCL: A Semi-Asynchronous Federated Graph Learning Framework with Personalized Aggregation and Cluster-Aware Broadcasting](https://arxiv.org/abs/2507.18219)
> *FedSA-GCL：一种半异步联邦图学习框架，具有个性化聚合和集群感知广播*

*Zhongzheng Yuan, Lianshuai Guo, Xunkai Li, Yinlin Zhu, Wenyu Wang, Meixia Qu* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 联邦图学习, 半异步, 图神经网络, 分布式学习, ClusterCast

**Comment:** 

> **TL;DR:** FedSA-GCL是一个半异步联邦图学习框架，通过考虑图拓扑和标签分布来解决现有联邦图学习中的同步低效和异步方法不适应图数据的问题，显著提高了效率和鲁棒性。

**AI_Comments:** 这篇论文的创新点在于提出了一个半异步的联邦图学习框架，解决了现有同步FGL效率低和异步FL不适用于图数据的问题。其核心在于引入了ClusterCast机制，结合了客户端标签分布差异和图拓扑特性，提升了联邦图学习的实用性和性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的联邦图学习（FGL）方法大多依赖同步通信，导致效率低下且不切实际。同时，当前的异步联邦学习（AFL）方法主要针对传统任务设计，未考虑图数据的独特拓扑特性，直接应用可能导致全局模型出现语义漂移和表示不一致。

**Method:** 本文提出了FedSA-GCL，一个半异步联邦框架。该框架通过新颖的ClusterCast机制，利用客户端间标签分布差异和图拓扑特性进行高效训练，以解决同步通信低效和现有异步方法不适用于图数据的问题。

**Result:** FedSA-GCL在多个真实世界图数据集上进行了评估，并与9个基线方法进行比较。实验表明，该方法具有强大的鲁棒性和出色的效率，在使用Louvain算法时平均优于基线2.92%，在使用Metis算法时平均优于基线3.4%。

**Conclusion:** FedSA-GCL通过其半异步机制和对图特性的考虑，成功解决了联邦图学习中的同步效率问题和异步方法不适应图数据的问题，显著提升了性能、鲁棒性和效率。

> **ai_Abstract:** 本文提出了FedSA-GCL，一个半异步联邦图学习框架，旨在解决现有联邦图学习中同步通信效率低下的问题，以及传统异步联邦学习方法不适用于图数据所导致的语义漂移和表示不一致问题。FedSA-GCL通过创新的ClusterCast机制，有效利用客户端间的标签分布差异和图拓扑特性进行高效训练。在多个真实世界图数据集上的实验结果表明，FedSA-GCL在鲁棒性和效率方面表现出色，性能显著优于现有基线方法。

> **摘要翻译:** 联邦图学习（FGL）是一种分布式学习范式，可在位于多个本地系统上的大规模子图上实现协作训练。然而，大多数现有的FGL方法依赖同步通信，这导致效率低下，并且在实际部署中通常不切实际。同时，当前的异步联邦学习（AFL）方法主要针对图像分类和自然语言处理等传统任务设计，没有考虑图数据的独特拓扑特性。直接将这些方法应用于图学习可能会导致全局模型出现语义漂移和表示不一致。为了解决这些挑战，我们提出了FedSA-GCL，一个半异步联邦框架，它通过新颖的ClusterCast机制利用客户端间标签分布差异和图拓扑特性进行高效训练。我们在使用Louvain和Metis分割算法的多个真实世界图数据集上评估了FedSA-GCL，并将其与9个基线进行了比较。大量实验表明，我们的方法具有强大的鲁棒性和出色的效率，使用Louvain时平均优于基线2.92%，使用Metis时平均优于基线3.4%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [229] [Advancing Event Forecasting through Massive Training of Large Language Models: Challenges, Solutions, and Broader Impacts](https://arxiv.org/abs/2507.19477)
> *通过大规模训练大型语言模型推进事件预测：挑战、解决方案和更广泛的影响*

*Sang-Woo Lee, Sohee Yang, Donghyun Kwak, Noah Y. Siegel* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-25**

**Keywords:** 事件预测, 大型语言模型, 大规模训练, 超预报员, 预测智能

**Comment:** 

> **TL;DR:** 论文讨论了通过大规模训练LLM实现超预报员级别事件预测的挑战、解决方案及社会影响，呼吁研究者关注此方向。

**AI_Comments:** 这篇立场论文具有前瞻性，指出了LLM在事件预测领域的巨大潜力及实现该潜力所面临的具体技术挑战。其创新之处在于系统性地提出了针对训练困难的解决方案（如利用贝叶斯网络、反事实事件和辅助奖励）和数据策略，为未来研究提供了清晰的路线图。论文强调将AI的预测能力应用于更广泛的社会领域，具有重要的社会意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明LLM在事件预测方面逐渐达到超预报员水平，且推理模型和深度研究模型取得成功，预示着提升预测性能的技术已发展。因此，作者认为大规模训练超预报员级别事件预测LLM的时机已成熟。

**Method:** 论文讨论了两个主要研究方向：训练方法和数据获取。训练方法方面，针对噪声-稀疏性、知识截止和简单奖励结构问题，提出了利用假设事件贝叶斯网络、 poorly-recalled 和反事实事件，以及辅助奖励信号来缓解。数据获取方面，建议积极利用市场、公共和爬取数据集进行大规模训练和评估。

**Result:** Not mentioned in abstract

**Conclusion:** 本立场论文提出了实现超预报员级别AI技术的有前景的具体路径和考量，旨在呼吁研究人员关注这些方向。

> **ai_Abstract:** 这篇立场论文探讨了通过大规模训练大型语言模型（LLMs）实现超预报员级别事件预测的可行性、挑战与解决方案。作者指出，近期LLMs在预测性能上的进步和推理模型的成功，预示着大规模训练LLMs进行事件预测的时机已成熟。论文详细讨论了训练方法（如解决噪声-稀疏性、知识截止和简单奖励结构问题）和数据获取（利用市场、公共和爬取数据集）两大关键方向，并展望了这些技术进步对社会提供预测智能的广泛影响，旨在鼓励相关研究。

> **摘要翻译:** 许多近期论文研究了超预报员级别事件预测大型语言模型（LLMs）的开发。尽管早期研究的方法论问题对使用LLMs进行事件预测产生了疑问，但近期采用改进评估方法的研究表明，最先进的LLMs正逐渐达到超预报员水平的性能，并且也有报道称强化学习能改进未来预测。此外，近期推理模型和深度研究风格模型的前所未有的成功表明，能够极大提高预测性能的技术已经发展起来。因此，基于这些积极的近期趋势，我们认为大规模训练超预报员级别事件预测LLMs的研究时机已经成熟。我们讨论了两个关键研究方向：训练方法和数据获取。对于训练，我们首先介绍了基于LLM的事件预测训练的三个难点：噪声-稀疏性、知识截止和简单奖励结构问题。然后，我们提出了缓解这些问题的相关想法：假设事件贝叶斯网络、利用召回不足和反事实事件，以及辅助奖励信号。对于数据，我们建议积极利用市场、公共和爬取数据集以实现大规模训练和评估。最后，我们解释了这些技术进步如何使AI能够在更广泛的领域为社会提供预测智能。这篇立场论文提出了有前景的具体路径和考量，以更接近超预报员级别的AI技术，旨在呼吁研究人员对这些方向产生兴趣。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [233] [Multimodal Fine-grained Reasoning for Post Quality Evaluation](https://arxiv.org/abs/2507.17934)
> *用于帖子质量评估的多模态细粒度推理*

*Xiaoxu Guo, Siyan Liang, Yachao Cui, Juxiang Zhou, Lei Wang, Han Cao* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 多模态推理, 帖子质量评估, 细粒度推理, 关系推理, 排序任务

**Comment:** 48 pages

> **TL;DR:** MFTRR框架通过模仿人类认知过程，将帖子质量评估重新定义为排序任务，并利用多模态数据和两个关键模块（局部-全局语义相关性推理模块和多级证据关系推理模块）来提高评估准确性，显著优于现有基线。

**AI_Comments:** 该论文创新性地将帖子质量评估任务重新定义为排序问题，并引入了模仿人类认知过程的多模态细粒度推理框架MFTRR。其通过独特的双模块设计，有效解决了现有方法在多模态融合中的噪声问题以及细粒度关系捕获的不足，显著提升了评估准确性，对多模态内容理解和质量评估领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究将帖子质量评估视为单模态分类任务，未能利用多模态线索和细粒度质量区分；在深度多模态融合过程中引入噪声；缺乏捕获复杂语义关系的能力，如相关性和全面性。

**Method:** 提出多模态细粒度主题-帖子关系推理 (MFTRR) 框架，模仿人类认知过程。MFTRR将帖子质量评估重构为排序任务，并整合多模态数据。它包含两个模块：1) 局部-全局语义相关性推理模块，通过最大信息融合机制抑制噪声，建模帖子和主题之间的细粒度语义交互；2) 多级证据关系推理模块，探索宏观和微观层面的关系线索以加强基于证据的推理。

**Result:** MFTRR在三个新建的多模态主题-帖子数据集和公共Lazada-Home数据集上进行评估。实验结果表明，MFTRR显著优于最先进的基线，在艺术史数据集上，相对于最佳单模态方法，NDCG@3提高了9.52%。

**Conclusion:** MFTRR框架通过其多模态细粒度推理能力，显著提高了帖子质量评估的准确性，超越了现有方法。

> **ai_Abstract:** 本文针对现有帖子质量评估方法未能有效利用多模态信息、引入噪声及缺乏复杂语义关系捕获能力的问题，提出了一种多模态细粒度主题-帖子关系推理 (MFTRR) 框架。MFTRR模仿人类认知过程，将评估重构为排序任务，并引入局部-全局语义相关性推理模块和多级证据关系推理模块，以实现细粒度语义交互和证据推理。实验表明，MFTRR在多个数据集上显著优于现有最先进方法，在某些数据集上NDCG@3提升高达9.52%。

> **摘要翻译:** 准确评估帖子质量需要复杂的关联推理来捕捉细微的主题-帖子关系。然而，现有研究面临三个主要限制：(1) 将任务视为单模态分类，未能利用多模态线索和细粒度质量区分；(2) 在深度多模态融合过程中引入噪声，导致误导性信号；(3) 缺乏捕获复杂语义关系的能力，如相关性和全面性。为解决这些问题，我们提出了多模态细粒度主题-帖子关系推理 (MFTRR) 框架，该框架模仿人类认知过程。MFTRR将帖子质量评估重新定义为排序任务，并结合多模态数据以更好地捕捉质量变化。它由两个关键模块组成：(1) 局部-全局语义相关性推理模块，通过最大信息融合机制抑制噪声，在局部和全局层面建模帖子和主题之间的细粒度语义交互；(2) 多级证据关系推理模块，探索宏观和微观层面的关系线索以加强基于证据的推理。我们在三个新构建的多模态主题-帖子数据集和公共Lazada-Home数据集上评估了MFTRR。实验结果表明，MFTRR显著优于最先进的基线，在艺术史数据集上，相对于最佳单模态方法，NDCG@3提高了9.52%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [246] [Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction](https://arxiv.org/abs/2507.17768)
> *通过相对熵核集选择和级联层校正增强边缘设备上的量化感知训练*

*Yujia Tong, Jingling Yuan, Chuang Hu* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-17**

**Keywords:** 量化感知训练, 边缘计算, 核集选择, 相对熵, 级联层校正

**Comment:** 

> **TL;DR:** 提出QuaRC框架，通过相对熵核集选择和级联层校正，显著提升边缘设备上小数据集量化感知训练（QAT）的性能。

**AI_Comments:** 该论文的创新点在于结合了相对熵核集选择和级联层校正策略，有效解决了边缘设备上量化感知训练在数据受限（小数据集）情况下的性能挑战。这对于需要兼顾模型效率、隐私保护和计算资源受限的边缘AI应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着移动和边缘计算的发展，边缘设备对低位量化模型的需求增加，以实现高效部署。然而，传统的量化感知训练（QAT）依赖完整数据集，计算成本高昂。尽管核集选择技术可以缓解此问题，但现有方法在使用小规模数据集时难以消除量化误差，导致性能显著下降。

**Method:** 提出QuaRC框架，一个用于边缘设备上基于核集的量化感知训练（QAT）框架。它包含两个主要阶段：1. 在核集选择阶段，引入“相对熵分数”来识别最能捕捉模型量化误差的子集。2. 在训练阶段，采用“级联层校正”策略，使量化模型的中间层输出与全精度模型对齐，从而有效减少中间层的量化误差。

**Result:** 实验结果表明该方法有效。例如，当使用1%的数据子集将ResNet-18量化到2位时，QuaRC在ImageNet-1K数据集上的Top-1准确率比现有技术提高了5.72%。

**Conclusion:** QuaRC框架通过创新的核集选择和级联层校正策略，有效解决了边缘设备上小数据集量化感知训练的性能下降问题，显著提升了量化模型的准确性。

> **ai_Abstract:** 本文提出了QuaRC框架，旨在解决边缘设备上小数据集量化感知训练（QAT）的性能下降问题。QuaRC通过引入“相对熵分数”进行核集选择，识别最能代表模型量化误差的数据子集。同时，采用“级联层校正”策略，使量化模型中间层输出与全精度模型对齐，以减少量化误差。实验证明，该方法在小数据子集上显著提升了量化模型的准确率。

> **摘要翻译:** 随着移动和边缘计算的发展，边缘设备上对低位量化模型的需求日益增加，以实现高效部署。为了提高性能，通常需要使用边缘数据重新训练量化模型。然而，由于隐私问题，某些敏感数据只能在边缘设备上处理。因此，在边缘设备上采用量化感知训练（QAT）已成为一种有效的解决方案。然而，传统的QAT依赖于完整的训练数据集，这会产生巨大的计算成本。核集选择技术可以通过在最具代表性的子集上进行训练来缓解这个问题。但是，现有方法在使用小规模数据集（例如，仅10%的数据）时难以消除模型中的量化误差，从而导致显著的性能下降。为了解决这些问题，我们提出了QuaRC，一个在边缘设备上使用核集的QAT框架，它包含两个主要阶段：在核集选择阶段，QuaRC引入了“相对熵分数”来识别最能有效捕获模型量化误差的子集。在训练阶段，QuaRC采用级联层校正策略，使量化模型的中间层输出与全精度模型的输出对齐，从而有效减少中间层的量化误差。实验结果证明了我们方法的有效性。例如，当使用1%的数据子集将ResNet-18量化到2位时，QuaRC在ImageNet-1K数据集上的Top-1准确率比现有技术提高了5.72%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [258] [Sparse identification of nonlinear dynamics with library optimization mechanism: Recursive long-term prediction perspective](https://arxiv.org/abs/2507.18220)
> *带有库优化机制的非线性动力学稀疏识别：递归长期预测视角*

*Ansei Yonezawa, Heisei Yonezawa, Shuichi Yahagi, Itsuro Kajiwara, Shinya Kijimoto, Hikaru Taniuchi, Kentaro Murakami* | **Category: cs.LG, math.DS** | **Updated: 2025-07-24**

**Keywords:** 稀疏识别, 非线性动力学, 库优化, 递归长期预测, SINDy-LOM

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** SINDy-LOM通过优化基函数库来改进SINDy，从而提高长期预测的准确性和模型可靠性，并减少用户负担。

**AI_Comments:** 本文的创新点在于将SINDy中的基函数库设计问题转化为一个可优化的参数化问题，并通过引入递归长期预测（RLT）准确性作为优化目标，显著提升了模型在实际应用中的可靠性和鲁棒性。这种方法不仅简化了用户操作，也使得SINDy在处理复杂系统时更具实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 稀疏非线性动力学识别（SINDy）方法面临的一个主要挑战是库的设计，即候选基函数的集合，因为对于许多动力系统而言，选择合适的库并非易事。

**Method:** 本研究提出了带有库优化机制的SINDy（SINDy-LOM），它结合了稀疏回归技术和新颖的库学习策略。在该方法中，基函数被参数化。SINDy-LOM包含一个双层优化架构：内层提取数据驱动模型作为候选基函数的稀疏线性组合；外层则从递归长期（RLT）预测准确性的角度优化基函数。因此，库设计被重新定义为参数化基函数的优化问题。

**Result:** 所提出的SINDy-LOM模型具有良好的可解释性和可用性，因为它产生了简约模型。库优化机制显著减少了用户负担。与只能确保一步预测准确性的传统SINDy方法相比，RLT视角提高了最终模型的可靠性。该方法的有效性通过应用于柴油机进气系统（一个众所复杂的工业系统）得到了验证。

**Conclusion:** SINDy-LOM通过引入库优化机制和递归长期预测视角，有效解决了传统SINDy在库设计上的挑战，显著提升了非线性动力学模型识别的可靠性和实用性。

> **ai_Abstract:** 本文提出SINDy-LOM，旨在解决传统SINDy在库设计上的挑战。该方法通过引入一个双层优化架构来参数化并优化基函数，其中外层优化侧重于递归长期预测精度。SINDy-LOM模型具有良好的可解释性、可用性，并能生成简约模型，显著减轻了用户负担。此外，其递归长期预测视角提高了模型可靠性。通过应用于柴油机进气系统，验证了该方法的有效性。

> **摘要翻译:** 稀疏非线性动力学识别（SINDy）方法可以根据测量数据发现动力系统的控制方程，其中动力学模型被识别为给定基函数的稀疏线性组合。SINDy的一个主要挑战是库的设计，即一组候选基函数，因为对于许多动力系统而言，合适的库并非易事。为了克服这一困难，本研究提出了带有库优化机制的SINDy（SINDy-LOM），它是稀疏回归技术与新颖的库学习策略的结合。在所提出的方法中，基函数被参数化。SINDy-LOM方法涉及一个双层优化架构：内层，其中数据驱动模型被提取为候选基函数的稀疏线性组合；外层，其中基函数从递归长期（RLT）预测准确性的角度进行优化；因此，库设计被重新定义为参数化基函数的优化。由此产生的SINDy-LOM模型具有良好的可解释性和可用性，因为所提出的方法产生了简约模型。库优化机制显著减少了用户负担。与只能确保一步预测准确性的传统SINDy方法相比，RLT视角提高了最终模型的可靠性。通过将其应用于柴油机进气系统（一个众所周知的复杂工业系统），证明了所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [269] [Analyzing Fairness of Computer Vision and Natural Language Processing Models](https://arxiv.org/abs/2412.09900)
> *分析计算机视觉和自然语言处理模型的公平性*

*Ahmed Rashed, Abdelkrim Kallich, Mohamed Eltayeb* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-23**

**Keywords:** 公平性, 偏见缓解, 计算机视觉, 自然语言处理, 机器学习

**Comment:** 25 pages, 8 table, 11 figures

> **TL;DR:** 本研究利用Fairlearn和AIF360库，分析并减轻计算机视觉和自然语言处理模型中的偏见，发现算法的顺序应用可以有效减少偏见并保持模型性能。

**AI_Comments:** 本研究的创新点在于比较了两个主流的公平性库，并探索了在机器学习生命周期不同阶段顺序应用偏见缓解技术的有效性，这对于实际应用场景具有重要意义。其重要性在于解决了广泛使用的机器学习系统中的关键伦理问题。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习算法在决策制定中扮演着关键角色，但其公平性和偏见问题引发了重大的伦理和社会挑战，本研究旨在解决这些挑战。

**Method:** 本研究利用微软的Fairlearn和IBM的AIF360这两个公平性库，评估和减轻非结构化数据集（使用计算机视觉和自然语言处理模型）中的偏见。研究方法包括单独或顺序地在机器学习生命周期的预处理、处理中或后处理阶段应用偏见缓解算法，并进行比较分析。研究使用了Kaggle上公开可用的数据集。

**Result:** 结果显示，某些顺序应用可以有效减少偏见，同时保持模型性能，从而提高缓解算法的性能。

**Conclusion:** 通过顺序应用偏见缓解算法，可以在有效降低模型偏见的同时保持其性能。

> **ai_Abstract:** 本论文探讨了机器学习模型（特别是计算机视觉和自然语言处理）中的公平性和偏见问题。研究利用微软的Fairlearn和IBM的AIF360库，对非结构化数据集进行偏见评估和缓解。论文比较了偏见缓解算法在机器学习生命周期不同阶段（预处理、处理中、后处理）单独应用或顺序应用的有效性。研究结果表明，某些顺序应用能够有效减少偏见，同时保持模型性能，为现实世界中的公平性评估提供了实用见解。

> **摘要翻译:** 机器学习（ML）算法在医疗保健、金融、教育和执法等各个领域的决策制定中发挥着关键作用。然而，这些系统中的公平性和偏见问题引发了重大的伦理和社会挑战。为了应对这些挑战，本研究利用了两个著名的公平性库：微软的Fairlearn和IBM的AIF360。这些库提供了全面的公平性分析框架，提供评估公平性指标、可视化结果和实现偏见缓解算法的工具。本研究侧重于使用计算机视觉（CV）和自然语言处理（NLP）模型评估和减轻非结构化数据集的偏见。主要目标是比较分析来自这两个公平性库的缓解算法的性能。此分析涉及在机器学习生命周期的预处理、处理中或后处理阶段，单独或顺序地应用算法。结果显示，某些顺序应用可以通过有效减少偏见同时保持模型性能来提高缓解算法的性能。本研究选择了Kaggle上公开可用的数据集，为评估现实世界机器学习工作流中的公平性提供了实用背景。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [280] [Analyze Feature Flow to Enhance Interpretation and Steering in Language Models](https://arxiv.org/abs/2502.03032)
> *分析特征流以增强语言模型的解释和引导*

*Daniil Laptev, Nikita Balagansky, Yaroslav Aksenov, Daniil Gavrilov* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 特征流, 语言模型, 可解释性, 模型引导, 稀疏自编码器

**Comment:** 

> **TL;DR:** 本文提出一种新方法，通过映射语言模型各层间的特征流，实现对模型行为的细粒度解释和直接引导。

**AI_Comments:** 这篇论文的创新点在于提出了一个系统性的跨层特征流分析框架，结合了稀疏自编码器和无数据余弦相似性，实现了对LLM内部特征演变的细粒度追踪。其重要性在于不仅提供了更深层次的模型可解释性，更进一步展示了如何利用这些洞察直接“引导”模型行为，实现内容生成中的精准控制，这对于提升LLM的可靠性和可控性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究对大型语言模型内部计算的理解和控制能力不足，需要一种系统性的方法来追踪特征演变，从而增强模型的可解释性和可控性。

**Method:** 本文引入了一种新方法，系统地映射稀疏自编码器发现的特征在大型语言模型连续层中的流动。该方法利用无数据余弦相似性技术，追踪特定特征在每个阶段的持久性、转换或首次出现，生成特征演化的细粒度流图。

**Result:** 研究实现了特征演化的细粒度流图，提供了对模型计算的精细解释性和机制洞察。此外，展示了这些跨层特征图如何通过放大或抑制选定特征来直接引导模型行为，从而在文本生成中实现有针对性的主题控制。

**Conclusion:** 本研究强调了因果、跨层可解释性框架的实用性，该框架不仅阐明了特征在前向传播中如何发展，还为透明地操纵大型语言模型提供了新方法。

> **ai_Abstract:** 本文提出了一种新颖的方法，通过利用稀疏自编码器和无数据余弦相似性技术，系统地追踪大型语言模型不同层之间特征的演变和流动。该方法生成细粒度的特征流图，显著增强了模型的可解释性并提供了对内部计算的机制洞察。研究还证明，通过操纵这些跨层特征，可以直接引导模型行为，实现文本生成中的主题控制。这项工作为理解和透明地操纵大型语言模型提供了一个因果、跨层的可解释性框架。

> **摘要翻译:** 我们引入了一种新方法，系统地映射稀疏自编码器在大型语言模型连续层中发现的特征，扩展了早期研究层间特征链接的工作。通过使用无数据余弦相似性技术，我们追踪特定特征在每个阶段如何持久存在、转换或首次出现。这种方法产生了特征演化的细粒度流图，从而实现了对模型计算的精细解释性和机制洞察。至关重要的是，我们展示了这些跨层特征图如何通过放大或抑制选定的特征来促进对模型行为的直接引导，从而在文本生成中实现有针对性的主题控制。总而言之，我们的发现突出了因果、跨层可解释性框架的实用性，该框架不仅阐明了特征在前向传播中如何发展，而且为透明地操纵大型语言模型提供了新方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [281] [Knowledge Abstraction for Knowledge-based Semantic Communication: A Generative Causality Invariant Approach](https://arxiv.org/abs/2507.17784)
> *面向知识型语义通信的知识抽象：一种生成式因果不变方法*

*Minh-Duong Nguyen, Quoc-Viet Pham, Nguyen H. Tran, Hoang-Khoi Do, Duy T. Ngo, Won-Joo Hwang* | **Category: cs.LG, 68, I.2.0** | **Updated: 2025-07-23**

**Keywords:** 语义通信, 知识抽象, 因果不变学习, 生成对抗网络, 数据重建

**Comment:** 13 pages, 12 figures, 4 tables

> **TL;DR:** 本研究提出了一种基于生成对抗网络和因果不变学习的AI模型，用于在语义通信中提取不变知识，以提高数据重建性能并应对用户数据演变导致的知识分歧。

**AI_Comments:** 该论文的创新点在于将因果不变学习引入语义通信中的知识抽象，有效解决了数据多样性和知识随时间演变带来的挑战。通过分离因果和非因果表示，并利用稀疏更新协议，模型不仅提高了数据重建的效率和鲁棒性，还在不同域和演变数据下保持了知识的一致性，这对未来可靠的语义通信系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高语义通信中信道解码器的数据重建能力，并解决用户数据随时间演变导致的知识分歧问题，本研究旨在设计一个低复杂度、通用的AI模型来捕获共同知识。

**Method:** 本研究提出了一种生成对抗网络（GAN），该网络利用因果不变学习从数据中提取因果（不变且包含关键信息）和非因果表示。为应对用户数据演变造成的知识分歧，还设计了稀疏更新协议以改善知识的不变性并最小化通信开销。

**Result:** 1. 因果不变知识确保了在不同训练数据下设备间的一致性。2. 不变知识在分类任务中表现出色，这对于目标导向的语义通信至关重要。3. 基于知识的数据重建方法展现了解码器的鲁棒性，在峰值信噪比（PSNR）方面超越了其他最先进的数据重建和语义压缩方法。

**Conclusion:** 本研究提出的基于生成式因果不变方法的知识抽象模型，通过提取和利用因果不变知识，有效提升了语义通信中的数据重建性能和系统鲁棒性，并在多样化数据和知识演变场景下展现出优越性和一致性。

> **ai_Abstract:** 本论文提出了一种新颖的AI模型，该模型基于生成对抗网络和因果不变学习，旨在提升语义通信中的数据重建效率。通过提取数据中的因果不变表示，模型能够捕获关键语义知识，确保在多样化数据域和知识演变场景下的数据重建一致性和鲁棒性。实证结果表明，该方法不仅在分类任务中表现优异，而且在数据重建质量上超越了现有先进技术。

> **摘要翻译:** 在本研究中，我们设计了一种低复杂度且通用的AI模型，能够捕获通用知识，以改善语义通信中信道解码器的数据重建。具体来说，我们提出了一种生成对抗网络，该网络利用因果不变学习从数据中提取因果和非因果表示。因果表示是不变的，包含识别数据标签的关键信息。它们可以封装语义知识，并促进接收端有效的数据重建。此外，因果机制确保学习到的表示在不同域中保持一致，即使用户从不同域收集数据，系统也能保持可靠。随着用户收集的数据随时间演变导致用户间知识分歧，我们设计了稀疏更新协议，以改善知识的不变性，同时最小化通信开销。我们的实证评估得出了三个关键观察结果。首先，因果不变知识确保了在不同训练数据下不同设备间的一致性。其次，不变知识在分类任务中表现出良好的性能，这对于面向目标的语义通信至关重要。第三，我们基于知识的数据重建突出了解码器的鲁棒性，其在峰值信噪比（PSNR）方面超越了其他最先进的数据重建和语义压缩方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [293] [A general language model for peptide identification](https://arxiv.org/abs/2502.15610)
> *一种用于肽识别的通用语言模型*

*Jixiu Zhai, Tianchi Lu, Haitian Zhong, Ziyang Xu, Yuhuan Liu, Shengrui Xu, Jingwan Wang, Dan Huang* | **Category: cs.LG, cs.AI, 92C40, 68T07, I.2.6; J.3** | **Updated: 2025-07-24**

**Keywords:** 肽识别, 深度学习, 语言模型, 翻译后修饰, PDeepPP

**Comment:** 24 pages, 9 figures, 4 tables, submitted to arXiv

> **TL;DR:** PDeepPP是一个统一的深度学习框架，结合了预训练的蛋白质语言模型和混合Transformer-卷积架构，实现了对多种肽类和翻译后修饰位点的准确识别，并在多项生物识别任务中达到最先进水平。

**AI_Comments:** PDeepPP的创新点在于其统一的深度学习框架，结合了预训练语言模型和混合架构，显著提升了肽识别的泛化能力和准确性。其在多项生物识别任务中达到SOTA性能，显示出强大的实用价值，对于推进生物医学研究和药物发现具有重要意义。数据的公开可用性也促进了后续研究。

<details>
  <summary>Details</summary>

**Motivation:** 准确识别生物活性肽（BPs）和蛋白质翻译后修饰（PTMs）对于理解蛋白质功能和推进治疗发现至关重要。然而，大多数计算方法在跨越不同肽功能时的泛化能力有限。

**Method:** 本文提出了PDeepPP，一个统一的深度学习框架，它集成了预训练的蛋白质语言模型与混合Transformer-卷积架构。该方法通过策划全面的基准数据集并实施策略解决数据不平衡问题，系统地提取全局和局部序列特征。

**Result:** PDeepPP展示了强大、可解释的肽表示，并在33项生物识别任务中的25项中实现了最先进的性能。值得注意的是，PDeepPP在抗菌肽（0.9726）和磷酸化位点（0.9984）识别中达到了高精度，在糖基化位点预测中具有99.5%的特异性，并显著减少了抗疟任务中的假阴性。

**Conclusion:** 通过实现大规模、准确的肽分析，PDeepPP支持生物医学研究和疾病治疗中新型治疗靶点的发现。

> **ai_Abstract:** PDeepPP是一个创新的深度学习框架，旨在解决现有计算方法在肽识别和蛋白质翻译后修饰（PTM）方面泛化能力不足的问题。它通过结合预训练的蛋白质语言模型和混合Transformer-卷积架构，能够有效提取肽的全局和局部序列特征。该模型在多项生物识别任务中表现出色，尤其在抗菌肽和磷酸化位点识别上达到高精度，并显著提高了糖基化位点预测的特异性，为生物医学研究和新药发现提供了强大的工具。

> **摘要翻译:** 准确识别生物活性肽（BPs）和蛋白质翻译后修饰（PTMs）对于理解蛋白质功能和推进治疗发现至关重要。然而，大多数计算方法在跨越不同肽功能时的泛化能力仍然有限。本文提出了PDeepPP，一个统一的深度学习框架，它集成了预训练的蛋白质语言模型与混合Transformer-卷积架构，从而能够在不同肽类和PTM位点上实现鲁棒识别。我们策划了全面的基准数据集，并实施了解决数据不平衡的策略，使PDeepPP能够系统地提取全局和局部序列特征。通过广泛的分析——包括降维和比较研究——PDeepPP展示了强大、可解释的肽表示，并在33项生物识别任务中的25项中达到了最先进的性能。值得注意的是，PDeepPP在抗菌肽（0.9726）和磷酸化位点（0.9984）识别中达到了高精度，在糖基化位点预测中具有99.5%的特异性，并显著减少了抗疟任务中的假阴性。通过实现大规模、准确的肽分析，PDeepPP支持生物医学研究和疾病治疗中新型治疗靶点的发现。所有代码、数据集和预训练模型均通过GitHub：https://github.com/fondress/PDeepPP 和 Hugging Face：https://huggingface.co/fondress/PDeppPP 公开可用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [296] [VIBE: Video-Input Brain Encoder for fMRI Response Modeling](https://arxiv.org/abs/2507.17958)
> *VIBE：视频输入脑编码器用于fMRI响应建模*

*Daniel Carlström Schad, Shrey Dixit, Janis Keck, Viktor Studenyak, Aleksandr Shpilevoi, Andrej Bicanski* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-07-25**

**Keywords:** fMRI预测, 多模态融合, Transformer, 脑编码器, VIBE

**Comment:** 

> **TL;DR:** VIBE是一个两阶段Transformer模型，它融合多模态视频、音频和文本特征来预测fMRI活动，并在Algonauts 2025挑战赛中表现出色。

**AI_Comments:** VIBE的创新之处在于其多模态融合方法，结合了多种先进的开源模型（如Qwen2.5用于文本，BEATs用于音频等），并通过两阶段Transformer架构有效处理不同模态的信息以预测fMRI响应。其在Algonauts 2025挑战赛中的优异表现，证明了其在脑解码领域的潜力和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在开发一个模型，能够通过融合多模态视频、音频和文本特征来预测大脑的fMRI活动。

**Method:** VIBE是一个两阶段Transformer模型。它通过模态融合Transformer合并来自开源模型（Qwen2.5、BEATs、Whisper、SlowFast、V-JEPA）的表示，然后由一个带有旋转嵌入的预测Transformer进行时间解码。该模型在CNeuroMod数据集的65小时电影数据上进行训练，并对20个种子进行集成。

**Result:** VIBE在in-distribution的Friends S07上获得了0.3225的平均parcel-wise Pearson相关性，在六部out-of-distribution电影上获得了0.2125。该架构的早期版本分别获得0.3198和0.2096，赢得了Algonauts 2025挑战赛的第一阶段并获得总成绩第二名。

**Conclusion:** VIBE模型能够有效预测fMRI活动，通过融合多模态数据并利用Transformer架构，在脑解码挑战赛中取得了显著成果。

> **ai_Abstract:** VIBE是一个创新的两阶段Transformer模型，旨在通过融合视频、音频和文本等多模态特征来预测fMRI活动。它利用Qwen2.5、BEATs等开源模型的表示，并通过模态融合和时间解码Transformer进行处理。该模型在65小时电影数据上训练并集成，在in-distribution和out-of-distribution数据集上均表现出良好的fMRI预测性能，并在Algonauts 2025挑战赛中获得显著成绩。

> **摘要翻译:** 我们提出了VIBE，一个两阶段Transformer模型，它融合多模态视频、音频和文本特征来预测fMRI活动。来自开源模型（Qwen2.5、BEATs、Whisper、SlowFast、V-JEPA）的表示通过模态融合Transformer进行合并，并由一个带有旋转嵌入的预测Transformer进行时间解码。VIBE在CNeuroMod数据集的65小时电影数据上训练，并对20个种子进行集成，在in-distribution的Friends S07上获得了0.3225的平均parcel-wise Pearson相关性，在六部out-of-distribution电影上获得了0.2125。该架构的早期版本分别获得0.3198和0.2096，赢得了Algonauts 2025挑战赛的第一阶段并获得总成绩第二名。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [297] [Boosting Revisited: Benchmarking and Advancing LP-Based Ensemble Methods](https://arxiv.org/abs/2507.18242)
> *再次审视Boosting：LP基集成方法的基准测试与进展*

*Fabian Akkerman, Julien Ferry, Christian Artigues, Emmanuel Hebrard, Thibaut Vidal* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** Boosting, 线性规划, 集成学习, 稀疏模型, 基准测试

**Comment:** 

> **TL;DR:** 本文对六种基于线性规划的提升方法（包括两种新方法）进行了首次大规模实验研究，表明这些方法在使用浅层树时可以超越或媲美最先进的启发式方法，并产生更稀疏的集成模型。

**AI_Comments:** 本文进行了首次大规模的LP基Boosting方法实验研究，填补了该领域经验研究的空白。其创新之处在于引入了两种新方法（NM-Boost和QRLP-Boost），并全面评估了LP基方法在多个维度上的表现，包括模型稀疏性，这对于实际应用具有重要意义。研究结果表明，LP基方法在某些情况下可以超越或媲美现有最先进的启发式方法，为集成学习提供了新的视角和潜在的优化方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于线性规划的完全校正Boosting方法具有理论吸引力，但它们在经验上受到的关注有限。

**Method:** 本文对六种LP基Boosting公式（包括两种新方法：NM-Boost和QRLP-Boost）进行了首次大规模实验研究，使用了20个不同数据集。研究评估了启发式和最优基学习器，并分析了准确性、集成稀疏性、裕度分布、即时性能和超参数敏感性。

**Result:** 结果表明，当使用浅层树时，完全校正方法可以超越或媲美XGBoost和LightGBM等最先进的启发式方法，同时产生显著更稀疏的集成模型。这些方法还可以在不牺牲性能的情况下精简预训练的集成模型。

**Conclusion:** 本文展示了在上下文中使用最优决策树的优点和局限性，并表明LP基Boosting方法在某些条件下可以与最先进的启发式方法竞争并生成更稀疏的模型。

> **ai_Abstract:** 本文首次对基于线性规划的六种Boosting方法进行了大规模实验研究，其中包括新提出的NM-Boost和QRLP-Boost。研究在20个多样化数据集上，评估了这些方法在使用启发式和最优基学习器时的性能，并分析了准确性、集成稀疏性、裕度分布、即时性能和超参数敏感性。结果显示，当使用浅层树时，完全校正方法能与XGBoost和LightGBM等主流启发式方法匹敌或超越，并能生成显著更稀疏的模型，同时还能在不牺牲性能的情况下精简现有集成模型。研究还探讨了最优决策树在此背景下的优缺点。

> **摘要翻译:** 尽管基于线性规划的完全校正Boosting方法具有理论吸引力，但它们在经验上受到的关注有限。在本文中，我们对六种LP基Boosting公式（包括两种新方法：NM-Boost和QRLP-Boost）进行了首次大规模实验研究，使用了20个不同数据集。我们评估了这些公式中启发式和最优基学习器的使用，不仅分析了准确性，还分析了集成稀疏性、裕度分布、即时性能和超参数敏感性。我们表明，当使用浅层树时，完全校正方法可以超越或媲美XGBoost和LightGBM等最先进的启发式方法，同时产生显著更稀疏的集成模型。我们进一步表明，这些方法可以在不牺牲性能的情况下精简预训练的集成模型，并且我们强调了在这种情况下使用最优决策树的优点和局限性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [300] [History-Guided Video Diffusion](https://arxiv.org/abs/2502.06764)
> *历史引导的视频扩散*

*Kiwhan Song, Boyuan Chen, Max Simchowitz, Yilun Du, Russ Tedrake, Vincent Sitzmann* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 视频扩散, 历史引导, 扩散模型, 无分类器引导, DFoT

**Comment:** ICML 2025. Project website: https://boyuan.space/history-guidance

> **TL;DR:** 本文提出了Diffusion Forcing Transformer (DFoT)架构和History Guidance方法，以解决视频扩散模型中处理可变长度历史的挑战，显著提升了视频生成质量和时间一致性，并能生成超长视频。

**AI_Comments:** 本文的创新点在于提出了DFoT架构和History Guidance方法，解决了视频扩散模型中处理可变长度历史帧的难题。这对于提升视频生成质量和实现更长的、更一致的视频序列具有重要意义，特别是在泛化能力和长视频生成方面展现了强大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 将无分类器引导（CFG）技术扩展到视频扩散模型时，面临两个主要挑战：现有架构仅支持固定大小的条件，以及CFG风格的历史Dropout表现不佳，特别是在处理可变长度的历史帧时。

**Method:** 本文提出了Diffusion Forcing Transformer (DFoT)，这是一种视频扩散架构，它结合了理论基础的训练目标，能够灵活地处理可变数量的历史帧作为条件。在此基础上，还引入了History Guidance，这是一系列独特的引导方法。

**Result:** 最简单的History Guidance形式（vanilla history guidance）已经显著改善了视频生成质量和时间一致性。更高级的跨时间和频率的History Guidance进一步增强了运动动态，实现了对分布外历史的组合泛化能力，并能够稳定地生成极长的视频。

**Conclusion:** 本文提出的Diffusion Forcing Transformer (DFoT)架构和History Guidance方法有效解决了视频扩散模型中可变长度历史帧引导的挑战，显著提升了视频生成质量、时间一致性、运动动态及长视频生成能力。

> **ai_Abstract:** 本文针对视频扩散模型中处理可变长度历史帧的挑战，提出了一种名为Diffusion Forcing Transformer (DFoT)的新型视频扩散架构及其理论训练目标，以灵活地处理历史条件。在此基础上，引入了History Guidance系列引导方法。实验证明，该方法显著提升了视频生成质量和时间一致性，更高级的形式还能增强运动动态，实现对未见历史的组合泛化，并能稳定生成超长视频。

> **摘要翻译:** 无分类器引导（CFG）是改进扩散模型中条件生成的一项关键技术，它能实现更精确的控制，同时提升样本质量。将此技术扩展到视频扩散是自然而然的，视频扩散根据可变数量的上下文帧（统称为历史）生成视频。然而，我们发现使用可变长度历史进行引导存在两个关键挑战：一是架构只支持固定大小的条件，二是经验观察到CFG风格的历史Dropout表现不佳。为了解决这个问题，我们提出了扩散强制Transformer（DFoT），这是一种视频扩散架构和理论基础的训练目标，共同实现了对灵活数量历史帧的条件化。然后，我们引入了历史引导（History Guidance），这是一系列由DFoT独特实现的新引导方法。我们证明了其最简单的形式，即普通历史引导，已经显著提高了视频生成质量和时间一致性。一种更先进的方法，跨时间和频率的历史引导，进一步增强了运动动态，实现了对分布外历史的组合泛化，并能稳定地生成极长视频。项目网站：https://boyuan.space/history-guidance

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [301] [Distillation Scaling Laws](https://arxiv.org/abs/2502.08606)
> *蒸馏缩放定律*

*Dan Busbridge, Amitis Shidani, Floris Weers, Jason Ramapuram, Etai Littwin, Russ Webb* | **Category: cs.LG, cs.AI, cs.CL, stat.ML** | **Updated: 2025-07-25**

**Keywords:** 蒸馏, 缩放定律, 计算预算, 模型优化, 知识蒸馏

**Comment:** Version accepted to ICML 2025. 69 pages, 54 figures, 13 tables

> **TL;DR:** 提出蒸馏缩放定律，指导计算资源在学生模型和教师模型之间优化分配，以最大化学生性能，并提供两种场景下的最佳蒸馏策略。

**AI_Comments:** 这项工作通过引入“蒸馏缩放定律”提供了一种量化和优化大规模模型蒸馏过程的新视角。其创新之处在于将计算预算和资源分配纳入考量，为实际应用中如何高效利用计算资源进行模型蒸馏提供了具体的指导和“食谱”。这对于降低大型模型部署成本、提高效率具有重要意义，尤其是在资源受限或需要大规模部署的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过计算资源的最优分配来规避大规模蒸馏的风险，从而最大化学生模型的性能。研究还旨在增进对蒸馏过程的理解并指导实验设计。

**Method:** 提出了一种蒸馏缩放定律，该定律根据计算预算及其在学生和教师模型之间的分配来估计蒸馏模型的性能。基于此定律，研究提供了两种关键场景下的计算最优蒸馏方案：一是教师模型已存在，二是教师模型需要训练。

**Result:** 在涉及多个学生或已有教师模型的场景中，蒸馏的性能优于监督学习，其优越性可扩展至与学生模型大小成比例的计算水平。如果只有一个学生模型需要蒸馏且教师模型也需要训练，则通常监督学习更优。此外，大规模蒸馏研究增进了对蒸馏过程的理解，并有助于指导实验设计。

**Conclusion:** 本研究提出的蒸馏缩放定律及其发现，为大规模蒸馏提供了计算资源最优分配的指导，有效降低了相关风险，并加深了对蒸馏过程的理解，对实际应用和实验设计具有重要意义。

> **ai_Abstract:** 本文提出了一种蒸馏缩放定律，用于根据计算预算及其在学生和教师模型间的分配来预测蒸馏模型的性能。该研究旨在通过实现计算资源的最优分配来降低大规模蒸馏的风险，从而最大化学生模型的性能。文章提供了针对教师模型已存在和需要训练两种场景下的计算最优蒸馏策略，并指出在多学生或已有教师场景下蒸馏优于监督学习，而在单学生且教师需训练场景下监督学习更优。此外，这项大规模研究也加深了对蒸馏过程的理解。

> **摘要翻译:** 我们提出了一种蒸馏缩放定律，根据计算预算及其在学生和教师之间的分配来估计蒸馏模型的性能。我们的发现通过为教师和学生实现计算最优分配以最大化学生性能，从而降低了与大规模蒸馏相关的风险。我们为两种关键场景提供了计算最优的蒸馏方案：一是教师模型已存在，二是教师模型需要训练。在涉及多个学生或已有教师模型的设置中，蒸馏的性能优于监督学习，其计算水平可预测地随学生模型大小而扩展。反之，如果只有一个学生模型需要蒸馏且教师模型也需要训练，则通常监督学习更优。此外，我们对蒸馏的大规模研究增加了我们对该过程的理解，并有助于指导实验设计。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [309] [Self-similarity Analysis in Deep Neural Networks](https://arxiv.org/abs/2507.17785)
> *深度神经网络中的自相似性分析*

*Jingyi Ding, Chengwen Qi, Hongfei Wang, Jianshe Wu, Licheng Jiao, Yuwei Guo, Jian Gao* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** 深度神经网络, 自相似性, 复杂网络, 特征表示, 模型优化

**Comment:** 

> **TL;DR:** 本文提出了一种基于隐藏层神经元输出特征的复杂网络建模方法，以量化分析深度神经网络中特征网络的自相似性，并发现通过在训练过程中嵌入自相似性约束可以提高某些网络的分类性能。

**AI_Comments:** 本文通过引入复杂网络建模方法，为深度神经网络中长期存在的自相似性现象提供了新颖的定量分析工具。其创新之处在于不仅揭示了自相似性在不同架构中的差异，更重要的是，通过在训练过程中施加自相似性约束，证明了自相似性对模型性能的实际增益，为深度学习模型的结构理解和优化开辟了新的途径。这对于设计更高效、更鲁棒的神经网络具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前研究发现深度神经网络存在分层自相似性，但缺乏对隐藏空间几何自相似性如何影响模型权重优化以及内部神经元动态行为的定量分析和清晰理解。

**Method:** 本文提出了一种基于隐藏层神经元输出特征的复杂网络建模方法，用于研究在不同隐藏层构建的特征网络的自相似性，并分析调整特征网络自相似性程度如何提升深度神经网络的分类性能。

**Result:** 研究发现，特征网络表现出的自相似性程度在不同模型架构（MLP、卷积网络和注意力架构）之间存在差异。此外，在训练过程中对特征网络的自相似性嵌入约束，可以将自相似深度神经网络（MLP架构和注意力架构）的性能提高多达6个百分点。

**Conclusion:** 通过复杂网络建模方法，可以量化分析深度神经网络的自相似性，并且对特征网络自相似性施加约束能够有效提升部分模型的分类性能。

> **ai_Abstract:** 本文针对深度神经网络中自相似性缺乏定量分析的问题，提出了一种基于隐藏层神经元输出特征的复杂网络建模方法。该方法用于研究不同隐藏层构建的特征网络的自相似性，并探讨调整自相似性对分类性能的影响。研究发现自相似性程度因模型架构而异，且在训练中施加自相似性约束可使某些深度神经网络的性能提升高达6个百分点，为理解和优化深度学习模型提供了新视角。

> **摘要翻译:** 当前研究发现一些深度神经网络在特征表示或参数分布上表现出强大的分层自相似性。然而，除了关于权重幂律分布在不同训练阶段如何影响模型性能的初步研究之外，目前还没有关于隐藏空间几何的自相似性如何影响模型权重优化的定量分析，也缺乏对内部神经元动态行为的清晰理解。因此，本文提出了一种基于隐藏层神经元输出特征的复杂网络建模方法，以研究在不同隐藏层构建的特征网络的自相似性，并分析调整特征网络自相似性程度如何提升深度神经网络的分类性能。在三种类型的网络（MLP架构、卷积网络和注意力架构）上进行验证，本研究揭示了特征网络表现出的自相似性程度在不同模型架构之间存在差异。此外，在训练过程中对特征网络的自相似性嵌入约束，可以将自相似深度神经网络（MLP架构和注意力架构）的性能提高多达6个百分点。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [324] [Latent Space Alignment for AI-Native MIMO Semantic Communications](https://arxiv.org/abs/2507.16680)
> *AI原生MIMO语义通信中的潜在空间对齐*

*Mario Edoardo Pandolfo, Simone Fiorellino, Emilio Calvanese Strinati, Paolo Di Lorenzo* | **Category: cs.LG, cs.IT, cs.NI, math.IT** | **Updated: 2025-07-24**

**Keywords:** 语义通信, MIMO, 潜在空间对齐, 预编码, 神经网络

**Comment:** Proc. of IEEE IJCNN 2025

> **TL;DR:** 本文提出了一种利用MIMO技术解决语义通信中潜在空间失配的新方法，通过学习MIMO预编码器/解码器对，实现潜在空间压缩和语义信道均衡，有效缓解语义失配和物理信道损伤。

**AI_Comments:** 本文创新性地将MIMO技术引入到语义通信的潜在空间对齐中，旨在解决跨设备语义理解障碍。通过联合优化潜在空间压缩和信道均衡，该方法提供了一个全面的解决方案。其贡献在于提出了两种模型（线性和神经网络），为实际应用提供了灵活性，并为未来AI原生通信系统中的语义互操作性奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 当设备依赖于不同的语言、逻辑或内部表示时，语义通信中可能会出现语义失配，从而阻碍相互理解。本文旨在解决这一问题。

**Method:** 本文提出了一种新颖的方法，利用多输入多输出（MIMO）通信来解决语义通信中的潜在空间失配问题。具体而言，该方法学习一个MIMO预编码器/解码器对，共同执行潜在空间压缩和语义信道均衡，从而减轻语义失配和物理信道损伤。文中探讨了两种解决方案：(i) 线性模型，通过交替方向乘子法（ADMM）解决双凸优化问题进行优化；(ii) 基于神经网络的模型，在传输功率预算和复杂性约束下学习语义MIMO预编码器/解码器。

**Result:** 数值结果表明，在面向目标的语义通信场景中，所提出的方法是有效的，并展示了准确性、通信负担和解决方案复杂性之间的主要权衡。

**Conclusion:** 本文提出的利用MIMO的潜在空间对齐方法能有效缓解语义通信中的语义失配和物理信道损伤，并在准确性、通信负担和复杂性之间取得平衡。

> **ai_Abstract:** 本文针对语义通信中因设备表示差异导致的潜在空间失配问题，提出了一种基于MIMO的新型方法。该方法通过学习MIMO预编码器/解码器对，实现潜在空间压缩和语义信道均衡，旨在同时减轻语义失配和物理信道损伤。文中提出了线性模型（通过ADMM优化）和神经网络模型两种具体实现方案。数值实验验证了该方法在目标导向语义通信场景中的有效性，并分析了准确性、通信负担和复杂性之间的权衡。

> **摘要翻译:** 语义通信侧重于优先理解传输数据背后的含义，并确保成功完成促使信息交换的任务。然而，当设备依赖不同的语言、逻辑或内部表示时，可能会发生语义不匹配，从而可能阻碍相互理解。本文引入了一种解决语义通信中潜在空间失配的新方法，该方法利用了多输入多输出（MIMO）通信。具体而言，我们的方法学习一个MIMO预编码器/解码器对，该对共同执行潜在空间压缩和语义信道均衡，从而减轻语义不匹配和物理信道损伤。我们探讨了两种解决方案：(i) 线性模型，通过求解双凸优化问题并使用交替方向乘子法（ADMM）进行优化；(ii) 基于神经网络的模型，该模型在传输功率预算和复杂性约束下学习语义MIMO预编码器/解码器。数值结果证明了所提出方法在面向目标的语义通信场景中的有效性，并说明了准确性、通信负担和解决方案复杂性之间的主要权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [337] [Reinforcement Learning for Accelerated Aerodynamic Shape Optimisation](https://arxiv.org/abs/2507.17786)
> *强化学习加速空气动力学形状优化*

*Florian Sobieczky, Alfredo Lopez, Erika Dudkin, Christopher Lackner, Matthias Hochsteger, Bernhard Scheichl, Helmut Sobieczky* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** 强化学习, 空气动力学形状优化, 降维, 自适应优化, MCMC

**Comment:** 

> **TL;DR:** 本文介绍了一种基于强化学习（RL）的自适应优化算法，用于加速空气动力学形状优化，旨在减少计算量并解释优化结果。

**AI_Comments:** 这篇论文通过将强化学习应用于空气动力学形状优化，提出了一种新颖的方法，旨在解决传统优化中计算量大的问题。其创新点在于结合了RL、代理模型和MCMC，并引入了参数“冻结”的概念，以实现降维和加速。该方法不仅关注计算效率，还试图提供对优化结果的解释，这对于工程应用具有重要意义。然而，其加速效果依赖于特定的条件，这可能是未来研究需要进一步探索的限制。

<details>
  <summary>Details</summary>

**Motivation:** 旨在最小化计算工作量，并利用观察到的优化结果来解释所发现极值在实现所需流场中的作用。

**Method:** 本文引入了一种基于强化学习（RL）的自适应优化算法，用于空气动力学形状优化，侧重于降维。RL在此处以基于代理、actor-critic策略评估的MCMC方法形式应用，允许对部分待优化参数进行时间性“冻结”。通过围绕作为真实值的中间CFD模拟进行一系列局部优化的参数改变，以加速全局优化。

**Result:** 该方法在一个简单的流体动力学问题上得到了应用，并允许进行特征重要性评分的解释。如果参数的局部邻域足够大且奖励和成本的估计足够准确，则可以加速全局优化。

**Conclusion:** 该方法能够加速空气动力学形状优化，并提供对优化结果的解释，尽管其加速效果依赖于特定的条件，即局部邻域大小和奖励/成本估计的准确性。

> **ai_Abstract:** 本文提出了一种基于强化学习的自适应优化算法，用于空气动力学形状优化，旨在通过降维和计算效率的提升来最小化计算工作量。该算法采用基于代理的actor-critic策略评估MCMC方法，并允许对部分参数进行“冻结”。研究目标是加速全局优化，并利用优化结果解释所发现极值在实现所需流场中的作用。该方法在一个简单的流体动力学问题上得到了验证，并展现了进行特征重要性评分的能力，其加速效果取决于局部邻域大小和奖励/成本估计的准确性。

> **摘要翻译:** 我们引入了一种基于强化学习（RL）的自适应优化算法，用于空气动力学形状优化，重点关注降维。此处应用RL的形式是基于代理、actor-critic策略评估的MCMC方法，允许对部分待优化参数进行时间性“冻结”。目标是最小化计算工作量，并利用观察到的优化结果来解释所发现极值在实现所需流场中的作用。
通过围绕作为真实值的中间CFD模拟进行一系列局部优化的参数改变，如果(a)改变的参数必须驻留的参数局部邻域足够大以与网格大小的步长及其大量的模拟竞争，并且(b)这些邻域上为良好逐步参数适应所需的奖励和成本估计足够准确，则可以加速全局优化。我们给出了一个简单的流体动力学问题的例子，在该问题上，该方法允许以特征重要性评分的意义进行解释。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [339] [Leveraging Data Augmentation and Siamese Learning for Predictive Process Monitoring](https://arxiv.org/abs/2507.18293)
> *利用数据增强和孪生学习进行预测性过程监控*

*Sjoerd van Straten, Alessandro Padella, Marwan Hassani* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 预测性过程监控, 数据增强, 孪生学习, 自监督学习, 事件日志

**Comment:** 

> **TL;DR:** 针对预测性过程监控中事件日志数据量小和变异性低的问题，本文提出了SiamSA-PPM框架，结合孪生学习和统计增强，生成逼真的数据变体，并在实验中表现出超越现有技术的性能。

**AI_Comments:** 这篇论文的创新点在于结合了孪生学习和统计增强，以自监督的方式解决预测性过程监控中数据稀疏性和变异性不足的问题。其提出的统计性数据增强方法，利用了流程的控制流语义和行为模式，保证了生成数据的真实性和语义有效性，这比简单的随机增强更为有效。该方法在不需要额外标签的情况下提升了模型性能，对于实际应用中难以获取大量标注数据的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习预测性过程监控方法常受限于真实事件日志的低变异性和小规模，导致模型泛化能力不足。

**Method:** 提出SiamSA-PPM，一个结合孪生学习和统计增强的自监督学习框架。它利用三种基于统计的新型转换方法，结合控制流语义和频繁行为模式生成逼真且语义有效的新轨迹变体。这些增强视图用于孪生学习，以学习过程前缀的通用表示，无需标签监督。

**Result:** 在真实事件日志上的实验表明，SiamSA-PPM在“下一活动”和“最终结果预测”任务中均达到或超越了现有技术（SOTA）的性能。统计增强显著优于随机转换，并提高了数据的变异性。

**Conclusion:** SiamSA-PPM为过程预测中的训练数据丰富提供了一个有前景的方向，其统计增强方法有效解决了数据稀缺和变异性不足的问题，并提升了预测性能。

> **ai_Abstract:** 本文针对预测性过程监控（PPM）中深度学习模型因事件日志数据量小和变异性低而受限的问题，提出了SiamSA-PPM自监督学习框架。该框架结合孪生学习和统计增强，通过利用控制流语义和行为模式生成逼真、语义有效的数据变体。实验证明，SiamSA-PPM在预测任务上表现出优于或媲美现有技术的性能，并验证了统计增强在提升数据变异性和模型泛化能力方面的有效性。

> **摘要翻译:** 预测性过程监控（PPM）能够基于事件日志预测正在进行的业务流程实例的未来事件或结果。然而，深度学习的PPM方法往往受限于真实世界事件日志的低变异性和小规模。为了解决这个问题，我们引入了SiamSA-PPM，一个新颖的自监督学习框架，它结合了孪生学习和统计增强以进行预测性过程监控。它采用了三种新颖的、基于统计的转换方法，这些方法利用控制流语义和频繁行为模式来生成逼真、语义有效的新轨迹变体。这些增强视图在孪生学习设置中被使用，以在不需要标签监督的情况下学习过程前缀的通用表示。在真实事件日志上进行的广泛实验表明，SiamSA-PPM在下一活动和最终结果预测任务中均达到了或超越了现有技术的性能。我们的结果进一步表明，统计增强显著优于随机转换，并提高了数据的变异性，这凸显了SiamSA-PPM作为过程预测中训练数据丰富的一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [342] [DeepCrossAttention: Supercharging Transformer Residual Connections](https://arxiv.org/abs/2502.06785)
> *深度交叉注意力：增压Transformer残差连接*

*Mike Heddes, Adel Javanmard, Kyriakos Axiotis, Gang Fu, MohammadHossein Bateni, Vahab Mirrokni* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** Transformer, 残差连接, 深度交叉注意力

**Comment:** 

> **TL;DR:** 引入DeepCrossAttention (DCA) 改进Transformer残差连接，通过可学习的、输入依赖的权重和深度交叉注意力，显著提高模型性能和训练速度，同时参数量可忽略不计。

**AI_Comments:** 这篇论文通过引入DeepCrossAttention (DCA) 对Transformer的残差连接进行了创新性改进。其核心在于使用可学习的、输入依赖的权重来动态选择性地聚合信息，并结合深度交叉注意力，这显著优于传统的简单求和方式。该方法不仅在实验中展现出显著的性能提升（更好的困惑度，更快的训练速度），而且参数量增加可忽略不计，这对于实际应用非常重要。理论分析也为其实用性提供了进一步的支撑。

<details>
  <summary>Details</summary>

**Motivation:** 传统Transformer残差连接简单地对前一层的输出进行求和，可能会稀释关键信息。

**Method:** 本文引入了DeepCrossAttention (DCA)，一种增强Transformer中残差学习的方法。DCA采用可学习的、依赖输入的权重来动态组合层输出，使模型能够选择性地关注任何先前层中最相关的信息。此外，DCA结合了深度交叉注意力，允许不同深度层之间进行更丰富的交互。

**Result:** 语言建模实验表明，在给定训练时间下，DCA实现了更好的困惑度。此外，DCA在增加可忽略不计的参数数量的情况下，能以高达3倍的速度获得相同的模型质量。理论分析证实，当集体层秩与环境维度之比低于临界阈值时，DCA在精度和模型大小之间提供了改进的权衡。

**Conclusion:** DeepCrossAttention (DCA) 通过引入可学习的、输入依赖的权重和深度交叉注意力来增强Transformer的残差连接，在语言建模任务中显著提高了性能和训练效率，同时保持了较低的参数开销，并通过理论分析得到了支持。

> **ai_Abstract:** 本文提出了DeepCrossAttention (DCA)，一种用于增强Transformer残差连接的新方法。DCA通过使用可学习的、输入依赖的权重来动态组合层输出，并引入深度交叉注意力，从而解决传统残差连接可能稀释关键信息的问题。实验结果显示，DCA在语言建模任务中提高了困惑度，并能以高达3倍的速度达到相同模型质量，同时仅增加可忽略的参数量。理论分析也支持DCA在精度和模型大小之间提供更好的权衡。

> **摘要翻译:** Transformer网络通过各种架构创新（包括残差连接）在不同领域取得了显著成功。然而，传统的残差连接仅简单地对前一层的输出进行求和，这可能会稀释关键信息。这项工作引入了DeepCrossAttention（DCA），这是一种增强Transformer中残差学习的方法。DCA采用可学习的、依赖输入的权重来动态组合层输出，使模型能够选择性地关注任何先前层中最相关的信息。此外，DCA结合了深度交叉注意力，允许不同深度层之间进行更丰富的交互。我们的语言建模实验表明，在给定的训练时间下，DCA实现了改进的困惑度。此外，DCA在增加可忽略不计的参数数量的情况下，能以高达3倍的速度获得相同的模型质量。理论分析证实，当集体层秩与环境维度之比低于临界阈值时，DCA在精度和模型大小之间提供了改进的权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [343] [Scalpel vs. Hammer: GRPO Amplifies Existing Capabilities, SFT Replaces Them](https://arxiv.org/abs/2507.10616)
> *手术刀与锤子：GRPO增强现有能力，SFT取代现有能力*

*Neel Rajani, Aryo Pradipta Gema, Seraphina Goldfarb-Tarrant, Ivan Titov* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-25**

**Keywords:** 大型语言模型, 强化学习, 监督微调, 训练动态, 能力增强

**Comment:** 

> **TL;DR:** 本文对大型语言模型（LLMs）在数学和代码数据集上进行推理训练时，强化学习（RL）和监督微调（SFT）的训练动态进行了比较分析。研究发现RL（GRPO）倾向于增强模型现有能力，而SFT则倾向于用新技能取代旧技能。

**AI_Comments:** 这项研究通过对比分析RL和SFT在LLM推理训练中的不同影响，为理解这两种流行微调方法的内在机制提供了初步见解。其创新之处在于通过参数级别的分析，揭示了SFT可能导致域外性能下降的原因。尽管关于冻结模型部分参数的实验结果不确定，但这项工作为未来更深入地研究LLM微调策略及其对模型能力的具体影响奠定了基础，对于优化LLM的训练效率和泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）通过数学和代码数据集进行推理训练已成为后训练的一个主要新焦点。尽管强化学习（RL）和监督微调（SFT）是两种特别流行的方法，但它们的训练动态却知之甚少。本文旨在通过比较分析来理解这两种方法的训练动态。

**Method:** 研究人员对RL和SFT在相同的数学问题、相同的模型和相似的超参数下进行了比较分析。此外，他们还分析了检查点之间的模型参数，并探讨了在训练期间冻结模型部分参数是否能缓解在知识密集型基准测试上的性能下降。

**Result:** 研究发现，RL在数学领域取得了轻微的领域内增益，但在MMLU等知识密集型基准测试上略有退化。SFT的这两种趋势则更为明显。参数分析显示，两种算法都主要修改了查询（query）和键（key）权重，而SFT表现出更大的更新，并更多地影响了中间层MLP。冻结模型部分参数的尝试结果不确定，在GPQA:Diamond上有所改善，但在其他基准上有所退化。

**Conclusion:** 研究结果初步表明，RL倾向于增强模型现有能力，而SFT则倾向于用新技能取代旧技能。

> **ai_Abstract:** 本文对大型语言模型（LLMs）在数学和代码数据集上的推理训练中，强化学习（RL）和监督微调（SFT）的训练动态进行了深入比较。研究发现，RL（特别是GRPO）倾向于增强模型原有的能力，在领域内获得小幅提升，但在知识密集型任务上略有下降。相比之下，SFT的影响更为显著，它不仅导致领域内提升和领域外下降更明显，还在模型参数更新上表现出更大程度的变化，特别是对中间层MLPs的影响。这些观察结果初步解释了RL为何是“手术刀”式地增强现有能力，而SFT则是“锤子”式地取代旧有技能。

> **摘要翻译:** 大型语言模型（LLMs）通过数学和代码数据集进行推理训练已成为LLM后训练的一个主要新焦点。强化学习（RL）和监督微调（SFT）是两种特别流行的方法，但它们的训练动态却知之甚少。我们对RL和SFT在相同的数学问题、相同的模型和相似的超参数下进行了比较分析。我们发现，RL在数学领域取得了轻微的领域内增益，但在MMLU等知识密集型基准测试上略有退化，而SFT的这两种趋势则更为明显。我们还分析了检查点之间的模型参数，观察到两种算法都主要修改了查询和键权重。同时，SFT表现出更大的更新，并且更多地影响了中间层MLP，这使我们推测这可能导致了域外性能下降。因此，我们研究了在训练期间冻结模型部分参数是否能缓解在知识密集型基准测试上性能下降的问题。然而，我们的结果不确定，在GPQA:Diamond上有所改善，但在其他基准上有所退化。总而言之，我们的观察结果初步表明了为什么RL会增强现有能力，而SFT会用新技能取代旧技能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [359] [Improving the Computational Efficiency and Explainability of GeoAggregator](https://arxiv.org/abs/2507.17977)
> *提高GeoAggregator的计算效率和可解释性*

*Rui Deng, Ziqi Li, Mingshu Wang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** GeoAggregator, 地理空间表格数据, 计算效率, 模型可解释性, GeoShapley

**Comment:** 4 pages, 3 figures

> **TL;DR:** 本文通过优化数据加载、前向传播、引入模型集成和基于GeoShapley的解释功能，显著提高了GeoAggregator的计算效率、预测准确性和可解释性。

**AI_Comments:** 本文通过对现有GeoAggregator模型进行优化，在计算效率和模型可解释性方面取得了显著进步。其创新点在于结合了管道优化、模型集成和GeoShapley解释框架，为地理空间数据分析提供了更高效、更透明的工具。开源代码的提供也极大地促进了社区的使用和进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 准确建模和解释地理空间表格数据对于理解地理空间现象及其潜在过程至关重要。GeoAggregator (GA) 是一个已证明表现优异的深度学习模型，但仍有提升空间。

**Method:** 本文通过以下方法改进GeoAggregator：1) 开发了一个优化的管道，加速数据加载并简化GA的前向传播，以提高计算效率；2) 结合了模型集成策略和基于GeoShapley框架的事后模型解释功能，以增强模型可解释性。通过在合成数据集上应用改进后的GA模型来验证这些策略的功能和效率。

**Result:** 实验结果表明，与原始实现相比，改进后的实现提高了GA的预测准确性和推理速度。此外，解释实验表明GA能有效捕捉设计合成数据集中的固有空间效应。

**Conclusion:** 改进后的GeoAggregator在计算效率、预测准确性和可解释性方面均有提升，并能有效捕捉空间效应。完整的管道已公开可用。

> **ai_Abstract:** 本文旨在提高GeoAggregator (GA) 模型的计算效率和可解释性，该模型是用于地理空间表格数据 (GTD) 建模和解释的Transformer基深度学习模型。作者通过开发优化的数据加载和前向传播管道来加速计算，并通过引入模型集成策略和基于GeoShapley的事后解释功能来增强模型可解释性。在合成数据集上的实验验证表明，改进后的GA模型在预测准确性和推理速度上均有提升，并且能够有效捕捉空间效应。完整的实现管道已开源。

> **摘要翻译:** 准确建模和解释地理空间表格数据（GTD）对于理解地理空间现象及其潜在过程至关重要。最近的工作为此目的提出了一个名为GeoAggregator（GA）的新型基于Transformer的深度学习模型，并已证明它优于其他统计和机器学习方法。在这篇短文中，我们通过以下方式进一步改进了GA：1）开发了一个优化的管道，加速数据加载过程并简化GA的前向传播以实现更好的计算效率；2）结合了模型集成策略和基于GeoShapley框架的事后模型解释功能以增强模型可解释性。我们通过将改进后的GA模型应用于合成数据集来验证所提出策略的功能和效率。实验结果表明，与原始实现相比，我们的实现提高了GA的预测准确性和推理速度。此外，解释实验表明GA可以有效捕捉设计合成数据集中的固有空间效应。完整的管道已公开发布供社区使用（https://github.com/ruid7181/GA-sklearn）。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [365] [Hyperbolic Deep Learning for Foundation Models: A Survey](https://arxiv.org/abs/2507.17787)
> *双曲深度学习在基础模型中的应用：一项综述*

*Neil He, Hiren Madhu, Ngoc Bui, Menglin Yang, Rex Ying* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 双曲深度学习, 基础模型, 双曲神经网络, 表示能力, 几何归纳偏置

**Comment:** 11 Pages, SIGKDD 2025

> **TL;DR:** 本综述探讨了双曲几何如何通过提高表示能力、适应性和可扩展性来解决现有基础模型（如LLMs和VLMs）的局限性，并对双曲神经网络及其在基础模型中的最新进展进行了全面回顾。

**AI_Comments:** 这篇综述论文的重要性在于它识别了当前主流基础模型所面临的根本性几何限制，并提出了一个有前景的替代方案——双曲深度学习。通过系统地回顾双曲神经网络在基础模型中的应用，该论文不仅为研究人员提供了一个全面的知识体系，还为未来克服模型瓶颈、提升模型性能指明了方向。其创新性体现在将非欧几何引入到基础模型的范畴，这可能开辟全新的研究范式。

<details>
  <summary>Details</summary>

**Motivation:** 当前基础模型（如LLMs、VLMs和大型多模态模型）在表示能力、适应性和可扩展性方面存在局限性。研究者质疑欧几里得几何是否是所有基础模型的最佳归纳偏置，并认为引入替代几何空间可能使模型更好地与真实世界数据的内在结构对齐并改进推理过程。

**Method:** 本论文综述了双曲神经网络及其在基础模型中的最新发展。双曲空间作为一种非欧几里得流形，以其随距离呈指数级增长的体积特性，能够以更低的维度实现层次结构和幂律分布的低失真嵌入。

**Result:** 将双曲空间应用于基础模型，可以提高LLMs的复杂推理能力、VLMs的零样本泛化能力以及跨模态语义对齐，同时保持参数效率。

**Conclusion:** 本文对双曲神经网络及其在基础模型中的最新发展进行了全面综述，并指出了该领域面临的关键挑战和未来的研究方向。

> **ai_Abstract:** 本综述探讨了当前基础模型在表示能力、适应性和可扩展性方面的局限性，并提出了双曲几何作为一种潜在的解决方案。双曲空间因其能有效嵌入层次结构和幂律分布的特性，被认为可以提高基础模型的性能，例如增强LLMs的推理能力和VLMs的泛化能力。论文全面回顾了双曲神经网络在基础模型中的应用，并指出了未来的研究方向和挑战。

> **摘要翻译:** 基础模型，包括大型语言模型（LLMs）、视觉-语言模型（VLMs）和大型多模态模型，通过在海量数据集上进行预训练，在各种下游任务中取得了显著成功。然而，最近的研究表明这些模型存在根本性局限性：（1）有限的表示能力，（2）较低的适应性，以及（3）日益下降的可扩展性。这些缺点提出了一个关键问题：欧几里得几何是否真的是所有基础模型的最佳归纳偏置，或者引入替代几何空间能否使模型更好地与真实世界数据的内在结构对齐并改进推理过程？双曲空间是一类非欧几里得流形，其特点是体积随距离呈指数级增长，提供了一个数学上严谨的解决方案。这些空间能够以比欧几里得对应物少得多的维度实现层次结构（例如，树、分类法）和幂律分布的低失真嵌入。最近的进展已经利用这些特性来增强基础模型，包括提高LLMs的复杂推理能力、VLMs的零样本泛化能力和跨模态语义对齐，同时保持参数效率。本文对双曲神经网络及其在基础模型中的最新发展进行了全面回顾。我们进一步概述了推动该领域发展的关键挑战和研究方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [377] [Sparse Logit Sampling: Accelerating Knowledge Distillation in LLMs](https://arxiv.org/abs/2503.16870)
> *稀疏Logit采样：加速大型语言模型中的知识蒸馏*

*Anshumann, Mohd Abbas Zaidi, Akhil Kedia, Jinwoo Ahn, Taehwak Kwon, Kangwook Lee, Haejun Lee, Joohyung Lee* | **Category: cs.LG, cs.AI, cs.CL, 68T50, I.2.7** | **Updated: 2025-07-24**

**Keywords:** 知识蒸馏, 大型语言模型, 稀疏采样, 重要性采样, 预训练

**Comment:** Accepted as Oral paper at ACL 2025. Source code is available at
  https://github.com/akhilkedia/RandomSamplingKD . Anshumann, Mohd Abbas Zaidi
  and Akhil Kedia have Equal Contribution

> **TL;DR:** 本文提出了一种基于重要性采样的稀疏知识蒸馏方法“随机采样知识蒸馏”，它能为大型语言模型提供无偏估计，并以较低开销加速学生模型的训练，同时保持与完全蒸馏相当的性能。

**AI_Comments:** 该论文的创新之处在于提出了一种基于重要性采样的无偏稀疏知识蒸馏方法，解决了在大型语言模型预训练中应用知识蒸馏时面临的存储和计算挑战。通过提供无偏估计和保留梯度，该方法在保持性能的同时显著加速了学生模型的训练，对于推动大型语言模型的高效训练具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 知识蒸馏在大型语言模型中如果教师模型输出的logits可以预先计算和缓存，则是一种经济高效的技术。然而，将其成功应用于预训练在很大程度上仍未被探索。朴素的稀疏知识蒸馏方法（如缓存Top-K概率）会提供有偏的教师概率分布估计，导致次优的性能和校准。

**Method:** 提出了一种基于重要性采样的方法“随机采样知识蒸馏”，该方法提供无偏估计，在期望上保留梯度，并且需要存储显著更稀疏的logits。

**Result:** 与基于交叉熵的训练相比，该方法能够以边际开销（<10%）更快地训练学生模型。在3亿到30亿参数范围的模型尺寸上，与完全蒸馏相比，它保持了竞争性的性能。

**Conclusion:** 所提出的“随机采样知识蒸馏”方法有效解决了大型语言模型中稀疏知识蒸馏的挑战，提供了无偏估计，并能在预训练场景中实现更快、更具竞争力的训练。

> **ai_Abstract:** 本文针对大型语言模型预训练中知识蒸馏（KD）的应用挑战，特别是朴素稀疏KD方法（如Top-K缓存）引入的偏差问题，提出了一种名为“随机采样知识蒸馏”的基于重要性采样的方法。该方法提供无偏估计并保留梯度，从而实现学生模型的更快训练，且开销极小（<10%），同时在不同模型尺寸（3亿至30亿参数）上保持与完全蒸馏相当的性能。

> **摘要翻译:** 知识蒸馏是一种经济高效的技术，如果教师模型输出的logits可以预先计算和缓存，则可用于大型语言模型中的知识蒸馏。然而，将其成功应用于预训练在很大程度上仍未被探索。在这项工作中，我们证明了稀疏知识蒸馏的朴素方法，例如缓存Top-K概率，虽然直观，但却为学生模型提供了教师概率分布的有偏估计，导致次优的性能和校准。我们提出了一种基于重要性采样的方法“随机采样知识蒸馏”，该方法提供无偏估计，在期望上保留梯度，并且需要存储显著更稀疏的logits。我们的方法与基于交叉熵的训练相比，能够以边际开销（<10%）更快地训练学生模型，同时在3亿到30亿参数范围的模型尺寸上保持与完全蒸馏相当的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [381] [Self-Supervised Coarsening of Unstructured Grid with Automatic Differentiation](https://arxiv.org/abs/2507.18297)
> *基于自动微分的非结构化网格自监督粗化*

*Sergei Shumilin, Alexander Ryabov, Nikolay Yavich, Evgeny Burnaev, Vladimir Vanovskiy* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 非结构化网格, 自监督学习, 自动微分, 网格粗化, 偏微分方程

**Comment:** 

> **TL;DR:** 该研究提出了一种基于可微分物理和自动微分的自监督非结构化网格粗化算法，可显著减少计算量并保持精度，适用于进化偏微分方程模拟。

**AI_Comments:** 该研究的创新点在于将自监督学习与自动微分结合应用于非结构化网格的粗化，有效解决了数值模拟中的计算效率问题。其重要性在于为大规模偏微分方程模拟提供了一种通用的降维方法，有望在计算流体力学、地球物理模拟等领域发挥重要作用。

<details>
  <summary>Details</summary>

**Motivation:** 由于现代数值模拟的计算负荷很高，需要一种既能减小离散问题规模又能保持合理精度的方法。

**Method:** 提出了一种基于可微分物理的原创算法，通过k-means聚类、自动微分和随机最小化算法实现非结构化网格粗化。

**Result:** 在所考虑的场景中，网格点数量减少了多达10倍，同时保留了感兴趣点处建模变量的动态。

**Conclusion:** 所提出的方法可以应用于由进化偏微分方程描述的任意系统的模拟。

> **ai_Abstract:** 本文提出了一种创新的自监督非结构化网格粗化算法，旨在解决现代数值模拟中计算负荷过高的问题。该方法结合了k-means聚类、自动微分和随机最小化算法，基于可微分物理概念实现网格粗化。实验证明，在处理线性抛物线方程和波动方程时，该算法能将网格点数量减少高达10倍，同时有效保持关键变量的动态精度。该方法具有普适性，可应用于任意由进化偏微分方程描述的系统模拟。

> **摘要翻译:** 由于现代数值模拟的计算负荷很高，因此需要一种既能减小离散问题规模又能保持合理精度的方法。在这项工作中，我们提出了一种基于可微分物理概念的原创算法来粗化非结构化网格。我们通过采用k-means聚类、自动微分和随机最小化算法来实现这一点。我们在两个偏微分方程上展示了所设计算法的性能：一个控制多孔介质中微可压缩流体流动的线性抛物线方程和波动方程。我们的结果表明，在所考虑的场景中，我们将网格点数量减少了多达10倍，同时保留了感兴趣点处建模变量的动态。所提出的方法可以应用于由进化偏微分方程描述的任意系统模拟。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [383] [Scale-Consistent Learning for Partial Differential Equations](https://arxiv.org/abs/2507.18813)
> *偏微分方程的尺度一致性学习*

*Zongyi Li, Samuel Lanthaler, Catherine Deng, Michael Chen, Yixuan Wang, Kamyar Azizzadenesheli, Anima Anandkumar* | **Category: cs.LG, cs.NA, math.NA** | **Updated: 2025-07-24**

**Keywords:** 偏微分方程, 机器学习, 尺度一致性, 神经算子, 泛化能力

**Comment:** 

> **TL;DR:** 提出一种基于尺度一致性的数据增强方案和尺度感知神经算子，显著提高了机器学习模型在解决偏微分方程时的泛化能力，使其能在更宽泛的参数范围内有效工作。

**AI_Comments:** 这篇论文的创新点在于利用了偏微分方程固有的尺度一致性原理来设计数据增强策略和模型结构，从而显著提升了机器学习模型在PDEs求解中的泛化能力。这对于工程和科学领域中需要处理多尺度物理问题的应用具有重要意义，克服了传统ML模型在特定参数和域限制下的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的机器学习模型在解决偏微分方程时泛化能力不足，无法在训练数据范围之外有效工作，例如，对于纳维-斯托克斯方程，模型通常只适用于固定雷诺数和预定义域。

**Method:** 提出一种基于偏微分方程尺度一致性特性的数据增强方案，并设计了一个尺度感知神经算子。该方法利用了两个事实：(i) 偏微分方程可以重新缩放，即将给定域重新缩放到单位大小，并适当调整参数和边界条件以表示原始解；(ii) 给定域上的解算子在其子域上也是一致的。这些事实被用于创建尺度一致性损失，鼓励匹配在给定域上评估的解与从重新缩放的偏微分方程在其子域上获得的解。神经算子被选作模型，因为它能适应多尺度和分辨率。

**Result:** 实验证明，在Burgers方程、Darcy流、Helmholtz方程和Navier-Stokes方程上，使用尺度一致性训练的模型，在雷诺数为1000时训练，可以泛化到雷诺数250到10000的范围，并且与基线相比，所有数据集的平均误差降低了34%。

**Conclusion:** 通过引入尺度一致性学习，机器学习模型在解决偏微分方程时的泛化能力得到了显著提升，能够更有效地处理不同尺度和参数范围的问题。

> **ai_Abstract:** 这篇论文提出了一种新的机器学习方法，用于解决偏微分方程（PDEs），旨在提高模型在训练数据范围之外的泛化能力。通过引入基于PDEs尺度一致性特性的数据增强方案和设计尺度感知神经算子，模型能够有效处理不同尺度和参数（如雷诺数）的PDEs。实验结果表明，该方法显著提升了模型的泛化性能，并在多个典型PDEs上实现了比现有基线模型更低的误差。

> **摘要翻译:** 机器学习（ML）模型已成为科学和工程中解决偏微分方程（PDEs）的一种有前景的方法。以往的ML模型通常无法在训练数据之外进行泛化；例如，一个针对纳维-斯托克斯方程训练的ML模型只适用于预定义域上的固定雷诺数（$Re$）。为了克服这些限制，我们提出了一种基于偏微分方程尺度一致性特性的数据增强方案，并设计了一个可以模拟广泛尺度的尺度感知神经算子。我们的公式利用了以下事实：（i）偏微分方程可以重新缩放，更具体地说，给定域可以重新缩放到单位大小，并且偏微分方程的参数和边界条件可以适当调整以表示原始解；（ii）给定域上的解算子在子域上是一致的。我们利用这些事实创建了一个尺度一致性损失，该损失鼓励匹配在给定域上评估的解与从重新缩放的偏微分方程在其子域上获得的解。由于神经算子可以适应多尺度和分辨率，它们是训练神经偏微分方程求解器时结合尺度一致性损失的自然选择。我们使用尺度一致性损失和尺度感知神经算子模型对Burgers方程、Darcy流、Helmholtz方程和Navier-Stokes方程进行了实验。通过尺度一致性，在$Re$为1000时训练的模型可以泛化到$Re$范围从250到10000，并且与基线相比，所有数据集的平均误差降低了34%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [407] [Adaptive Repetition for Mitigating Position Bias in LLM-Based Ranking](https://arxiv.org/abs/2507.17788)
> *用于缓解基于LLM的排名中位置偏差的自适应重复策略*

*Ali Vardasbi, Gustavo Penha, Claudia Hauff, Hugues Bouchard* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** LLM, 位置偏差, 自适应重复, 早期停止, 排名

**Comment:** 

> **TL;DR:** 本文提出了一种动态早期停止方法，以自适应地确定每个实例所需的LLM调用重复次数，从而显著减少计算成本，同时缓解大型语言模型中的位置偏差和重复一致性问题。

**AI_Comments:** 本文的创新点在于提出了一个自适应的动态重复策略来缓解LLM中的位置偏差，而非传统的静态重复。通过观察到位置偏差的实例级差异，作者提出了一种更精细化的解决方案，即动态早期停止和基于置信度的适应，这显著提高了计算效率。该方法在实际应用中具有重要意义，因为它能大幅降低LLM调用成本，同时保持或接近原始性能，对于大规模LLM部署尤其有益。未来的工作可以探索这种自适应策略在更多LLM任务和不同模型架构上的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 在使用大型语言模型（LLMs）进行项目排名或评估时，候选项目的顺序会影响模型的最终决策，这种对项目位置的敏感性被称为位置偏差。即使在大型模型中，这种偏差也存在，并且其严重程度因模型和任务而异。此外，LLMs还表现出不同程度的低重复一致性。现有的通过多次提示和多数投票来聚合结果的方法显著增加了计算成本。本文观察到，位置偏差的方向和大小在不同实例间差异很大，即使在同一数据集中也是如此，这突出需要一种针对每个实例的缓解策略。

**Method:** 本文引入了一种动态早期停止方法，该方法自适应地确定每个实例所需的重复次数。此外，还提出了一种基于置信度的自适应早期停止方法。

**Result:** 在三种不同大小的LLM和两个任务（重排序和对齐）上的评估表明，动态重复策略平均减少了81%的LLM调用，同时保持了准确性。基于置信度的自适应方法与静态重复相比，平均减少了87%的LLM调用，而与原始早期停止方法相比，仅有轻微的准确性损失。

**Conclusion:** 通过引入动态早期停止方法，本文有效缓解了LLM中的位置偏差和重复一致性问题，并显著降低了计算成本，同时保持了性能。

> **ai_Abstract:** 本文针对大型语言模型（LLM）在排名任务中存在的“位置偏差”和“低重复一致性”问题，以及传统缓解策略（如多数投票）带来的高计算成本，提出了一种创新的解决方案。作者观察到位置偏差的程度和方向因实例而异，因此提出了一种动态早期停止方法，该方法能够自适应地确定每个实例所需的LLM调用重复次数。实验结果表明，与静态重复方法相比，该动态策略在保持准确性的同时，平均减少了81%的LLM调用。进一步，引入的基于置信度的自适应方法能将LLM调用量平均减少87%，仅带来轻微的准确性损失。这表明动态重复策略能有效且高效地缓解LLM中的位置偏差。

> **摘要翻译:** 当使用大型语言模型（LLM）根据给定标准对项目进行排名或评估答案时，候选项目的顺序会影响模型的最终决策。这种LLM提示中对项目定位的敏感性被称为位置偏差。先前的研究表明，即使在大型模型中也存在这种偏差，尽管其严重程度因模型和任务而异。除了位置偏差之外，LLM还表现出不同程度的低重复一致性，即以相同的候选顺序重复LLM调用可能导致不同的排名。为了解决这两种不一致性，一种常见的方法是使用不同的候选顺序多次提示模型，并通过多数投票聚合结果。然而，这种重复策略显著增加了计算成本。扩展先前的发现，我们观察到即使在单个数据集中，位置偏差的方向（偏向提示中较早或较后的候选）和大小在不同实例之间也存在显著差异。这一观察结果突出了对每个实例进行缓解策略的需求。为此，我们引入了一种动态早期停止方法，该方法自适应地确定每个实例所需的重复次数。在三种不同大小的LLM和两个任务（重排序和对齐）上评估我们的方法，我们证明了过渡到动态重复策略平均减少了81%的LLM调用，同时保持了准确性。此外，我们提出了一种基于置信度的早期停止方法，与静态重复相比，平均减少了87%的LLM调用，而与我们原始的早期停止方法相比，仅有轻微的准确性权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [410] [BEAVER: Building Environments with Assessable Variation for Evaluating Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2507.07769)
> *BEAVER：构建具有可评估变异的环境以评估多目标强化学习*

*Ruohong Liu, Jack Umenberger, Yize Chen* | **Category: cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 多目标强化学习, 建筑能源管理, 泛化, 上下文强化学习, 基准

**Comment:** Accepted at the Workshop on Computational Optimization of Buildings
  (ICML CO-BUILD), 42nd International Conference on Machine Learning (ICML
  2025), Vancouver, Canada

> **TL;DR:** 本文提出了BEAVER，一个用于评估多目标强化学习在建筑能源管理中泛化能力的基准，并强调了在策略学习中整合动态相关上下文信息的重要性。

**AI_Comments:** 该论文的创新之处在于提出了一个名为BEAVER的新型基准，用于评估多目标强化学习在建筑能源管理中的泛化能力，并通过正式描述泛化空间和提出上下文RL问题，为解决RL在复杂现实环境中泛化性差的问题提供了新的视角。其重要性在于，为未来的研究提供了一个标准化评估工具，并指出了现有方法的局限性，即在环境变化下的性能下降，从而强调了上下文信息集成的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管强化学习（RL）在建筑能源管理方面取得了进展，但其在不同建筑动力学和操作场景下的效率和泛化能力仍是未解决的问题。

**Method:** 本文正式描述了跨环境多目标建筑能源管理任务的泛化空间，并提出了多目标上下文强化学习问题。研究提供了一种原则性的方法来参数化现实建筑RL环境中的上下文信息，并构建了一个新的基准来评估可泛化的RL算法。

**Result:** 现有多目标RL方法能够在冲突目标之间实现合理的权衡。然而，在某些环境变化下，它们的性能会下降。

**Conclusion:** 在策略学习过程中整合依赖于动态的上下文信息至关重要，以提高RL算法在建筑能源管理中的泛化能力。

> **ai_Abstract:** 本文针对强化学习在建筑能源管理中泛化能力不足的问题，正式定义了跨环境多目标建筑能源管理的泛化空间，并提出了多目标上下文强化学习问题。研究提供了一种参数化上下文信息的方法，并构建了一个名为BEAVER的新型基准，用于评估可泛化的RL算法。实验结果表明，现有方法虽能平衡冲突目标，但在环境变化下性能会下降，强调了整合动态相关上下文信息的重要性。

> **摘要翻译:** 近年来，在设计用于建筑能源管理的基于强化学习（RL）的智能体方面取得了显著进展。尽管在模拟或受控环境中取得了各自的成功，但RL方法在建筑动力学和操作场景下的效率和泛化能力的可扩展性仍然是一个悬而未决的问题。在这项工作中，我们正式描述了跨环境、多目标建筑能源管理任务的泛化空间，并提出了多目标上下文RL问题。这种表述有助于理解在多种控制目标（如舒适度水平和能耗）下，将所学策略在不同操作环境（如气候和热对流动力学）之间进行迁移所面临的挑战。我们提供了一种原则性的方法来参数化现实建筑RL环境中的此类上下文信息，并构建了一个新颖的基准，以促进在实际建筑控制任务中评估可泛化的RL算法。我们的结果表明，现有的多目标RL方法能够实现冲突目标之间的合理权衡。然而，它们的性能在某些环境变化下会下降，这突显了在策略学习过程中整合依赖于动态的上下文信息的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [412] [Analyzing Islamophobic Discourse Using Semi-Coded Terms and LLMs](https://arxiv.org/abs/2503.18273)
> *使用半编码术语和大型语言模型分析仇视伊斯兰教言论*

*Raza Ul Mustafa, Roi Dupart, Gabrielle Smith, Noman Ashraf, Nathalie Japkowicz* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 仇视伊斯兰教, 半编码术语, 大型语言模型, 仇恨言论, 主题建模

**Comment:** 

> **TL;DR:** 本研究分析了极端社交平台上难以识别的仇视伊斯兰教半编码术语，发现大型语言模型能理解这些术语，但仍需改进审查策略，且此类言论广泛存在并针对穆斯林移民。

**AI_Comments:** 本研究的创新点在于首次大规模分析了难以被现有系统识别的半编码仇视伊斯兰教术语，并探索了LLMs在该领域的应用潜力。其重要性在于揭示了在线仇恨言论的新形式及其传播模式，为改进内容审核和算法检测提供了依据。研究也指出，尽管LLMs具有理解能力，但技术和策略层面仍需进一步完善以有效打击此类言论。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，仇视伊斯兰教的言论在西方社会中日益增多，尤其是在数字通信网络上。许多仇视伊斯兰教的半编码术语在特定语境之外显得中性或模糊，这使得人工审核员和自动化系统都难以可靠地将其识别为仇恨言论。

**Method:** 首先，使用大型语言模型（LLMs）来展示它们理解这些术语的能力。其次，利用Google Perspective API评估仇视伊斯兰教帖子的毒性得分。最后，采用BERT主题建模方法提取社交平台上的不同主题和仇视伊斯兰教言论。

**Result:** 研究发现大型语言模型能够理解这些超词汇表（OOV）的侮辱性词语。Google Perspective API表明仇视伊斯兰教的帖子比其他仇恨言论（如反犹太主义）获得更高的毒性得分。主题建模显示仇视伊斯兰教的文本存在于各种政治、阴谋论和极右翼运动中，并特别针对穆斯林移民。

**Conclusion:** 尽管大型语言模型能够理解半编码的仇视伊斯兰教术语，但仍需要进一步改进审核策略和算法检测，以有效应对此类言论。这项研究是首次对仇视伊斯兰教半编码术语进行的大规模分析，并为全球仇视伊斯兰教现象提供了新的视角。

> **ai_Abstract:** 本研究对极端社交平台上难以识别的仇视伊斯兰教半编码术语进行了大规模分析。研究利用大型语言模型（LLMs）验证其对这些术语的理解能力，并通过Google Perspective API评估相关帖子的毒性。此外，采用BERT主题建模揭示了仇视伊斯兰教言论的主题分布。结果显示LLMs能理解这些特殊词汇，但仍需改进现有的内容审核策略。研究还发现仇视伊斯兰教言论广泛存在于政治、阴谋论和极右翼运动中，且主要针对穆斯林移民。本研究被认为是首次针对此类半编码仇恨言论的深入分析。

> **摘要翻译:** 近年来，仇视伊斯兰教在西方社会中获得了显著关注，这得益于数字通信网络的兴起。本文对在极端社交平台（如4Chan、Gab、Telegram等）上传播的专业半编码仇视伊斯兰教术语（如muzrat、pislam、mudslime、mohammedan、muzzies）进行了大规模分析。许多此类术语在特定语境之外在词汇上显得中性或模糊，这使得人工审核员和自动化系统都难以可靠地将其识别为仇恨言论。首先，我们使用大型语言模型（LLMs）来展示它们理解这些术语的能力。其次，Google Perspective API表明仇视伊斯兰教的帖子往往比其他类别的仇恨言论（如反犹太主义）获得更高的毒性得分。最后，我们使用BERT主题建模方法来提取这些社交平台上的不同主题和仇视伊斯兰教言论。我们的发现表明LLMs能够理解这些超词汇表（OOV）的侮辱性词语；然而，为了有效应对此类言论，审核策略和算法检测仍需进一步改进。我们的主题建模还表明，仇视伊斯兰教文本存在于各种政治、阴谋论和极右翼运动中，并且特别针对穆斯林移民。总而言之，我们对仇视伊斯兰教半编码术语进行了首次研究之一，并从全球角度揭示了仇视伊斯兰教的现象。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [414] [SIFOTL: A Principled, Statistically-Informed Fidelity-Optimization Method for Tabular Learning](https://arxiv.org/abs/2507.17979)
> *SIFOTL：一种基于统计学的表格学习保真度优化方法*

*Shubham Mohole, Sainyam Galhotra* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** 数据漂移, 表格学习, 隐私保护, XGBoost, 可解释性

**Comment:** 

> **TL;DR:** SIFOTL是一种统计学驱动的保真度优化方法，用于在表格数据集中识别数据漂移的驱动因素，尤其是在存在隐私限制和噪声的情况下，其性能优于现有方法。

**AI_Comments:** SIFOTL的创新之处在于其结合了隐私保护的数据汇总统计、LLM辅助的双重XGBoost模型以及帕累托加权决策树，实现了在隐私受限且有噪声的数据环境中识别数据漂移。其对隐私的关注和在现实世界数据集上的出色表现使其在医疗保健等敏感领域具有重要应用价值。该方法提供了一个鲁棒且可解释的分析框架，解决了现有方法在噪声处理和数据访问方面的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 在表格数据集中识别数据漂移的驱动因素是一个重大挑战，尤其是在医疗保健领域。现有分析方法可能忽略噪声或需要完全数据访问来进行基于LLM的分析，而隐私规则限制了数据访问，复杂过程产生的噪声阻碍了分析。

**Method:** SIFOTL方法包括：(i) 提取符合隐私规定的数据汇总统计数据；(ii) 使用双重XGBoost模型在LLM的辅助下区分干预信号和噪声；(iii) 通过帕累托加权决策树合并XGBoost输出，以识别导致漂移的可解释片段。该方法仅使用隐私安全的汇总统计数据。

**Result:** 在模拟新医疗补助的MEPS面板数据集上，SIFOTL的F1分数达到0.85，显著优于BigQuery贡献分析（F1=0.46）和统计测试（F1=0.20）。在基于Synthea ABM生成的18个不同EHR数据集上，SIFOTL在无噪声情况下F1分数保持在0.86-0.96，即使注入观测噪声，F1分数也达到0.75或更高，而基线平均F1分数在相同测试下为0.19-0.67。

**Conclusion:** SIFOTL提供了一种可解释、注重隐私的工作流程，并且在经验上对观测噪声具有鲁棒性。

> **ai_Abstract:** SIFOTL是一种新颖的表格学习方法，旨在解决数据漂移分析中面临的隐私限制和数据噪声问题。该方法通过提取隐私合规的数据汇总统计信息，结合双重XGBoost模型与LLM辅助来区分信号与噪声，并利用帕累托加权决策树识别可解释的漂移驱动因素。实验证明，SIFOTL在识别数据漂移方面表现出色，其F1分数显著优于现有基线方法，尤其在医疗保健数据集上，即使存在观测噪声也能保持高鲁棒性，提供了一个可解释且注重隐私的解决方案。

> **摘要翻译:** 识别表格数据集中数据漂移的驱动因素是分析和决策支持系统面临的重大挑战，尤其是在医疗保健领域。隐私规则限制了数据访问，复杂过程产生的噪声阻碍了分析。为了解决这一挑战，我们提出了SIFOTL（统计信息保真度优化表格学习方法），它（i）提取符合隐私规定的数据汇总统计数据，（ii）利用双重XGBoost模型在大型语言模型（LLM）的辅助下将干预信号与噪声分离，以及（iii）通过帕累托加权决策树合并XGBoost输出，以识别负责漂移的可解释片段。与现有分析方法（可能忽略噪声或需要完全数据访问进行基于LLM的分析）不同，SIFOTL仅使用隐私安全的汇总统计数据解决了这两个挑战。为了展示其在现实世界中的效力，对于一个模拟新医疗补助的MEPS面板数据集，SIFOTL在识别接受补助的片段方面取得了0.85的F1分数，大大优于BigQuery贡献分析（F1=0.46）和统计测试（F1=0.20）。此外，在基于Synthea ABM生成的18个不同EHR数据集上，SIFOTL在无噪声情况下保持0.86-0.96的F1分数，即使注入观测噪声也达到≥0.75，而基线平均F1分数在相同测试下为0.19-0.67。因此，SIFOTL提供了一种可解释、注重隐私且对观测噪声具有经验鲁棒性的工作流程。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [417] [A diffusion-based generative model for financial time series via geometric Brownian motion](https://arxiv.org/abs/2507.19003)
> *基于几何布朗运动的金融时间序列扩散生成模型*

*Gihun Kim, Sun-Yong Choi, Yeoneung Kim* | **Category: cs.LG, cs.AI, cs.NA, math.NA, 60H10, 91G80, 91G60** | **Updated: 2025-07-25**

**Keywords:** 扩散模型, 金融时间序列, 几何布朗运动, 生成模型, 风格化事实

**Comment:** 

> **TL;DR:** 提出了一种新的基于几何布朗运动（GBM）的扩散模型，用于生成金融时间序列，该模型通过模拟异方差性来更好地捕捉金融数据的特征，并在重现关键风格化事实方面优于传统模型。

**AI_Comments:** 该论文的创新之处在于将领域特定知识（GBM和异方差性）融入扩散模型，超越了通用的序列建模。这使得金融时间序列的生成更加真实，解决了现有模型的一个关键局限性。Transformer架构的应用也突出了现代深度学习方法的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 标准分数模型将价格轨迹视为通用数值序列，未能反映金融时间序列中观察到的异方差性（噪声与价格成比例）。因此，需要一个能更真实地重现金融数据关键风格化事实的模型。

**Method:** 提出了一种新颖的基于扩散的金融时间序列生成框架，该框架将几何布朗运动（GBM）整合到正向加噪过程中。该方法在每个时间步按资产价格比例注入噪声，以反映异方差性。通过平衡漂移和扩散项，所得的对数价格过程简化为方差爆炸随机微分方程。逆向生成过程通过去噪分数匹配进行训练，并采用改编自条件分数扩散插补（CSDI）框架的基于Transformer的架构。

**Result:** 在历史股票数据上的实证评估表明，该模型比传统扩散模型更真实地重现了关键的风格化事实，包括厚尾收益分布、波动率聚类和杠杆效应。

**Conclusion:** 该论文提出的结合了几何布朗运动的扩散模型能够有效地生成真实的金融时间序列，并比现有模型更好地捕捉复杂的风格化事实。

> **ai_Abstract:** 本文提出了一种新颖的基于扩散的金融时间序列生成模型，该模型将几何布朗运动（GBM）整合到其正向加噪过程中。与通用序列模型不同，它通过按资产价格比例注入噪声来专门处理金融数据的异方差性。该模型的对数价格过程被证明与方差爆炸随机微分方程一致。该模型利用基于Transformer的架构进行去噪分数匹配，并通过实证证明，与传统扩散模型相比，它在重现厚尾收益、波动率聚类和杠杆效应等关键金融风格化事实方面表现出卓越的性能。

> **摘要翻译:** 我们提出了一种新颖的基于扩散的金融时间序列生成框架，该框架将几何布朗运动（GBM），即布莱克-斯科尔斯理论的基础，整合到正向加噪过程中。与将价格轨迹视为通用数值序列的标准基于分数的模型不同，我们的方法在每个时间步按资产价格比例注入噪声，反映了金融时间序列中观察到的异方差性。通过精确平衡漂移和扩散项，我们表明所得的对数价格过程简化为方差爆炸随机微分方程，与基于分数的生成模型中的公式一致。逆向生成过程通过去噪分数匹配进行训练，使用改编自条件分数扩散插补（CSDI）框架的基于Transformer的架构。对历史股票数据的实证评估表明，我们的模型比传统扩散模型更真实地重现了关键的风格化事实——厚尾收益分布、波动率聚类和杠杆效应。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [421] [State of Health Estimation of Batteries Using a Time-Informed Dynamic Sequence-Inverted Transformer](https://arxiv.org/abs/2507.18320)
> *采用时间感知动态序列倒置Transformer的电池健康状态估计*

*Janak M. Patel, Milad Ramezankhani, Anirudh Deodhar, Dagnachew Birru* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 电池健康状态估计, 时间序列, Transformer, 不规则数据, 机器学习

**Comment:** 11 pages, 3 figures

> **TL;DR:** 提出TIDSIT模型，通过时间嵌入和时序注意力处理不规则电池放电数据，显著提高电池健康状态（SoH）估计精度。

**AI_Comments:** 本文的创新点在于提出了TIDSIT架构，通过引入连续时间嵌入和时序注意力机制，有效解决了电池健康监测中不规则采样和变长序列数据的挑战，避免了传统特征提取方法造成的信息损失。其在NASA数据集上的显著性能提升证明了该方法的有效性和优越性，且其通用性使其在其他不规则时间序列健康监测领域也具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 电池在电动汽车和储能系统中日益普及，但其健康状态会因充放电循环而退化，影响效率和安全。现有机器学习模型在处理真实世界中不规则采样和变长放电数据时表现不佳，导致信息丢失和精度下降。

**Method:** 提出一种名为时间感知动态序列倒置Transformer (TIDSIT) 的新架构。TIDSIT通过引入连续时间嵌入来有效表示不规则采样数据，并利用带有时间注意力机制的填充序列来处理变长输入，同时不丢失序列信息。

**Result:** 在NASA电池退化数据集上的实验结果表明，TIDSIT显著优于现有模型，预测误差降低了50%以上，并将SoH预测误差保持在0.58%以下。

**Conclusion:** 该架构具有通用性，在涉及不规则时间序列数据的健康监测任务中具有广阔的应用前景。

> **ai_Abstract:** 本文提出了一种名为时间感知动态序列倒置Transformer (TIDSIT) 的新型机器学习架构，用于准确估计电池的健康状态（SoH）。针对现有模型难以处理真实世界中不规则采样和变长放电数据的问题，TIDSIT通过引入连续时间嵌入和带有时间注意力的填充序列来有效处理这些挑战，避免了信息丢失。在NASA电池退化数据集上的实验证明，TIDSIT在SoH预测精度上显著优于现有模型，将预测误差降低了50%以上，并展现出在不规则时间序列健康监测任务中的通用性。

> **摘要翻译:** 过去十年，电池驱动车辆和储能系统的迅速普及使得电池健康监测变得日益重要。电池在这些系统的效率和安全中发挥着核心作用，但它们不可避免地会随着时间的推移因重复的充放电循环而退化。这种退化导致能量效率降低和潜在的过热，带来重大的安全隐患。因此，准确估计电池的健康状态（SoH）对于确保运行可靠性和安全至关重要。已经提出了几种机器学习架构，例如LSTM、Transformer和基于编码器的模型，用于从放电循环数据中估计SoH。然而，这些模型难以处理真实世界测量中固有的不规则性：放电读数通常以非均匀间隔记录，并且放电循环的长度差异很大。为了解决这个问题，大多数现有方法从序列中提取特征而不是完整处理它们，这会导致信息丢失并损害准确性。为了克服这些挑战，我们提出了一种新颖的架构：时间感知动态序列倒置Transformer（TIDSIT）。TIDSIT结合了连续时间嵌入，以有效表示不规则采样数据，并利用带有时间注意力机制的填充序列来管理变长输入，而不会丢弃序列信息。在NASA电池退化数据集上的实验结果表明，TIDSIT显著优于现有模型，预测误差降低了50%以上，并将SoH预测误差保持在0.58%以下。此外，该架构具有通用性，在涉及不规则时间序列数据的健康监测任务中具有广阔的应用前景。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [442] [LagKV: Lag-Relative Information of the KV Cache Tells Which Tokens Are Important](https://arxiv.org/abs/2504.04704)
> *LagKV：KV缓存的滞后相对信息揭示了哪些令牌是重要的*

*Manlai Liang, JiaMing Zhang, Xiong Li, Jinlong Li* | **Category: cs.LG, cs.AI, cs.CL, cs.CV** | **Updated: 2025-07-24**

**Keywords:** KV缓存压缩, 大型语言模型, 长上下文推理, LagKV, 注意力机制

**Comment:** 

> **TL;DR:** LagKV是一种新的KV缓存压缩策略，无需注意力机制，通过直接比较KV自身来减少大型语言模型长上下文推理中的KV缓存大小，性能优于现有方法。

**AI_Comments:** 该论文提出了一种新颖的、无注意力机制的KV缓存压缩方法LagKV，其创新点在于利用KV自身之间的“滞后相对信息”来判断令牌的重要性，避免了传统方法对注意力权重的依赖，从而简化了集成并降低了计算开销。其重要性在于为大型语言模型在长上下文推理中的KV缓存管理提供了一个更高效、更易于部署的解决方案，有助于平衡部署成本和模型准确性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在长上下文推理过程中，KV缓存大小的增加是部署成本和任务准确性之间平衡的主要障碍。现有方法通常需要大量修改推理基础设施并产生显著的计算开销。

**Method:** 提出LagKV，一种KV压缩策略，它仅依赖于KV自身之间的直接比较，是一种完全无注意力的方法。

**Result:** 在RULER基准测试中，LagKV在不同压缩比下优于SnapKV和StreamingLLM。特别是在64位passkey检索任务中，LagKV在相同压缩比下比基于注意力权重的H2O方法性能提高50%以上。

**Conclusion:** LagKV通过简单的KV自身比较，在不牺牲性能的前提下，有效压缩了LLM的KV缓存，并易于集成，解决了长上下文推理中的KV缓存大小问题。

> **ai_Abstract:** 本文提出LagKV，一种针对大型语言模型长上下文推理的KV缓存压缩策略。与现有依赖注意力权重的方法不同，LagKV通过直接比较KV自身来识别重要令牌，从而避免了对推理基础设施的重大修改和计算开销。实验结果表明，LagKV在RULER基准测试中表现优异，并在特定任务中显著超越了基于注意力的方法，提供了一种易于集成且高效的KV缓存压缩解决方案。

> **摘要翻译:** 大型语言模型在长上下文推理过程中，键值（KV）缓存的不断增长是其在部署成本和任务准确性之间取得平衡的主要障碍。为了在这种情况下减小KV缓存大小，大多数先前的工作都利用注意力权重来驱逐非关键缓存令牌。但这些方法存在权衡，它们通常需要对推理基础设施进行重大修改并产生显著的计算开销。基于大型语言模型是自回归模型的事实，我们提出了LagKV，一种仅依赖于KV自身之间直接比较的KV压缩策略。它是一种完全无注意力的方法，易于集成到主流推理平台中，并且与其它复杂的KV压缩方法相比，性能相当。RULER基准测试结果表明，我们的方法在不同压缩比下优于SnapKV和StreamingLLM。特别是在64位passkey检索任务中，我们的方法在相同压缩比下比基于注意力权重的方法H2O性能提高50%以上。我们的代码可在https://github.com/AI-Lab-China-Merchants-Bank/LagKV获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [443] [Helix 1.0: An Open-Source Framework for Reproducible and Interpretable Machine Learning on Tabular Scientific Data](https://arxiv.org/abs/2507.17791)
> *Helix 1.0：一个用于表格科学数据可复现和可解释机器学习的开源框架*

*Eduardo Aguilar-Bejarano, Daniel Lea, Karthikeyan Sivakumar, Jimiama M. Mase, Reza Omidvar, Ruizhe Li, Troy Kettle, James Mitchell-White, Morgan R Alexander, David A Winkler, Grazziela Figueredo* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 开源框架, 机器学习, 可复现性, 可解释性, 表格数据

**Comment:** 17 pages

> **TL;DR:** Helix 1.0 是一个开源的 Python 框架，旨在为表格数据提供可复现和可解释的机器学习工作流，通过用户友好的界面和全面的模块，帮助非数据科学背景的研究人员获取可操作的洞察。

**AI_Comments:** Helix 1.0 的创新之处在于其集成环境和新颖的语言术语解释方法，这大大降低了机器学习的门槛，特别是对于非专业数据科学背景的研究人员。其开源和强调可复现性、可解释性的特点，对于提升科学研究的透明度和可信度具有重要意义。该框架通过一个全面的模块化设计，有效地支持了端到端的机器学习流程。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在解决对透明实验数据分析溯源日益增长的需求，确保整个分析过程（包括数据转换和方法选择）都被记录、可访问、可复现，并对相关利益方而言易于理解。

**Method:** Helix 是一个基于 Python 的开源、可扩展软件框架。它包含用于标准化数据预处理、可视化、机器学习模型训练、评估、解释、结果检查以及对未见数据进行模型预测的模块。它还具有一个用户友好的界面，支持计算实验设计、结果检查，并采用了一种新颖的、使用语言术语解释机器学习决策的方法。

**Result:** Helix 作为一个开源框架，成功地促进了表格数据的可复现和可解释机器学习工作流。它提供了全面的模块和用户友好的界面，使研究人员（即使没有正式的数据科学培训）也能获得有意义且可操作的见解。该框架在 MIT 许可下发布，可通过 GitHub 和 PyPI 访问，支持社区驱动的开发并遵循 FAIR 原则。

**Conclusion:** Helix 框架通过提供一个透明、可复现、可解释且用户友好的环境，使研究人员能够从表格科学数据中推导出有意义且可操作的见解，从而填补了数据分析透明度方面的空白。

> **ai_Abstract:** Helix 1.0 是一个开源的 Python 框架，旨在为表格科学数据提供可复现和可解释的机器学习工作流。它通过提供标准化模块（涵盖从数据预处理到模型解释和预测的整个流程）以及一个用户友好的界面，解决了对透明和可理解数据分析溯源的需求。该框架特别强调帮助非数据科学背景的研究人员获取洞察，并通过新颖的语言术语解释方法提升可解释性，促进社区开发和 FAIR 原则的遵守。

> **摘要翻译:** Helix 是一个开源、可扩展的基于 Python 的软件框架，旨在促进表格数据的可复现和可解释机器学习工作流。它解决了对透明实验数据分析溯源日益增长的需求，确保整个分析过程——包括数据转换和方法选择的决策——都被记录、可访问、可复现并对相关利益方而言易于理解。该平台包含用于标准化数据预处理、可视化、机器学习模型训练、评估、解释、结果检查以及对未见数据进行模型预测的模块。为了进一步赋能没有正式数据科学培训的研究人员，使其能够得出有意义且可操作的见解，Helix 设有一个用户友好的界面，该界面在一个集成环境中，支持计算实验的设计、结果检查，包括一种使用语言术语解释机器学习决策的新颖方法。Helix 在 MIT 许可下发布，可通过 GitHub 和 PyPI 访问，支持社区驱动的开发并促进遵守 FAIR 原则。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [457] [Low-rank adaptive physics-informed HyperDeepONets for solving differential equations](https://arxiv.org/abs/2507.18346)
> *用于求解微分方程的低秩自适应物理信息HyperDeepONets*

*Etienne Zeudong, Elsa Cardoso-Bihlo, Alex Bihlo* | **Category: cs.LG, cs.NA, math.NA** | **Updated: 2025-07-24**

**Keywords:** HyperDeepONets, 低秩自适应, 物理信息机器学习, 微分方程, 算子学习

**Comment:** 14 pages, 6 figures, 5 tables

> **TL;DR:** 本文提出PI-LoRA-HyperDeepONets，利用低秩自适应（LoRA）改进HyperDeepONets，显著减少参数量并提高微分方程求解的预测精度和泛化能力。

**AI_Comments:** 本文通过引入低秩自适应（LoRA）这一创新技术，有效地解决了现有HyperDeepONets模型存在的参数量大、计算成本高的问题。LoRA的应用不仅显著减少了模型复杂度，还通过额外的正则化提升了模型的预测精度和泛化能力，为物理信息机器学习领域提供了一种更高效、更实用的算子学习方法。

<details>
  <summary>Details</summary>

**Motivation:** HyperDeepONets虽然提高了表达能力，但由于输出参数数量庞大，导致内存和计算成本高昂。

**Method:** 本文引入了PI-LoRA-HyperDeepONets，在物理信息机器学习设置下，利用低秩自适应（LoRA）技术，将超网络（hypernetwork）的输出层权重矩阵分解为两个较小的低秩矩阵，从而减少可训练参数并引入额外的正则化。

**Result:** PI-LoRA-HyperDeepONets在参数量上实现了高达70%的减少，并且在预测精度和泛化能力方面始终优于常规HyperDeepONets，这在常微分方程和偏微分方程的广泛实验中得到了验证。

**Conclusion:** 通过引入低秩自适应，PI-LoRA-HyperDeepONets有效解决了HyperDeepONets的计算和内存开销问题，同时显著提升了模型性能，使其成为求解微分方程的更高效且准确的算子学习架构。

> **ai_Abstract:** 本文针对HyperDeepONets在算子学习中存在的内存和计算成本高昂问题，提出了一种名为PI-LoRA-HyperDeepONets的新架构。该方法通过引入低秩自适应（LoRA），将超网络的输出层权重矩阵分解为低秩矩阵，从而显著减少了可训练参数（高达70%）并引入了正则化。实验证明，PI-LoRA-HyperDeepONets在求解常微分方程和偏微分方程时，在预测精度和泛化能力上均优于传统的HyperDeepONets。

> **摘要翻译:** HyperDeepONets由Lee、Cho和Hwang在[ICLR, 2023]中引入，作为一种算子学习的替代架构，其中超网络为DeepONet的主干网络生成权重。虽然这提高了表达能力，但由于所需的输出参数数量庞大，导致内存和计算成本高昂。在这项工作中，我们在物理信息机器学习设置下，引入了一种变体，即PI-LoRA-HyperDeepONets，它利用低秩自适应（LoRA）通过将超网络的输出层权重矩阵分解为两个较小的低秩矩阵来降低复杂性。这减少了可训练参数的数量，同时为主干网络的权重引入了额外的正则化。通过对常微分方程和偏微分方程的广泛实验，我们表明PI-LoRA-HyperDeepONets实现了高达70%的参数减少，并在预测精度和泛化能力方面始终优于常规HyperDeepONets。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [461] [Machine Unlearning of Traffic State Estimation and Prediction](https://arxiv.org/abs/2507.17984)
> *交通状态估计与预测的机器遗忘*

*Xin Wang, R. Tyrrell Rockafellar, Xuegang, Ban* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 机器遗忘, 交通状态估计, 交通预测, 数据隐私, 被遗忘权

**Comment:** 

> **TL;DR:** 本研究提出了一种针对交通状态估计与预测（TSEP）的新型范式——机器遗忘TSEP，旨在使已训练的TSEP模型能够选择性地遗忘隐私敏感、被污染或过时的数据，以应对数据隐私、网络安全和数据新鲜度等挑战，从而增强数据驱动型TSEP的信任度和可靠性。

**AI_Comments:** 这项研究的创新之处在于将“机器遗忘”这一新兴概念应用于交通状态估计与预测领域，直接解决了数据驱动型智能交通系统面临的隐私和数据管理挑战。它不仅响应了“被遗忘权”的法律要求，也通过提高模型的适应性和可靠性，增强了公众对智能交通系统的信任。该方法对于需要处理大量敏感或动态变化数据的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 数据驱动的交通状态估计与预测（TSEP）严重依赖包含敏感信息的数据源，这引发了隐私、网络安全和数据新鲜度等担忧，可能侵蚀公众对智能交通系统的信任。此外，近期法规引入了“被遗忘权”，要求从模型中删除用户私人数据，而简单地从后端数据库中删除数据不足以应对此挑战。

**Method:** 本研究引入了一种新颖的TSEP学习范式——机器遗忘TSEP（Machine Unlearning TSEP），它使训练好的TSEP模型能够选择性地遗忘隐私敏感、被污染或过时的数据。

**Result:** Not mentioned in abstract

**Conclusion:** 通过赋予模型“遗忘”能力，本研究旨在增强数据驱动型交通状态估计与预测（TSEP）的信任度和可靠性。

> **ai_Abstract:** 本研究提出了一种创新的机器遗忘（Machine Unlearning）范式，专门应用于交通状态估计与预测（TSEP）领域。鉴于当前数据驱动的TSEP方法面临的隐私、网络安全和数据新鲜度挑战，以及“被遗忘权”法规的要求，该研究旨在使已训练的TSEP模型能够选择性地删除或“遗忘”特定的敏感、受污染或过时数据，从而提升智能交通系统的信任度和可靠性。

> **摘要翻译:** 数据驱动的交通状态估计与预测（TSEP）严重依赖包含敏感信息的数据源。尽管数据的丰富性推动了显著突破，特别是在基于机器学习的方法中，但它也引发了对隐私、网络安全和数据新鲜度的担忧。这些问题可能侵蚀公众对智能交通系统的信任。最近，法规引入了“被遗忘权”，允许用户请求从模型中删除其私人数据。由于机器学习模型可以记住旧数据，因此在这种系统中，简单地从后端数据库中删除数据是不够的。为了应对这些挑战，本研究引入了一种新颖的TSEP学习范式——机器遗忘TSEP——它使训练好的TSEP模型能够选择性地遗忘隐私敏感、被污染或过时的数据。通过赋予模型“遗忘”能力，我们旨在增强数据驱动型交通TSEP的信任度和可靠性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [472] [Position: An Empirically Grounded Identifiability Theory Will Accelerate Self-Supervised Learning Research](https://arxiv.org/abs/2504.13101)
> *立场：一个基于经验的可识别性理论将加速自监督学习研究*

*Patrik Reizinger, Randall Balestriero, David Klindt, Wieland Brendel* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-07-24**

**Keywords:** 自监督学习, 可识别性理论, 柏拉图式表征假设, 奇异可识别性理论, 理论框架

**Comment:** ICML2025 camera ready

> **TL;DR:** 自监督学习（SSL）的成功（即柏拉图式表征假设PRH）缺乏精确的理论解释。本文通过综合可识别性理论（IT）的证据，表明PRH可以在SSL中出现，但现有IT无法解释SSL的经验成功。为弥合理论与实践之间的鸿沟，本文提出了奇异可识别性理论（SITh），这是一个更广泛的理论框架，旨在深入理解SSL中的隐式数据假设，并促进学习更可解释和泛化的表征。

**AI_Comments:** 这是一篇重要的立场论文，它明确指出了当前自监督学习（SSL）理论基础的不足，特别是其核心现象——柏拉图式表征假设（PRH）——缺乏精确的理论解释。论文的创新之处在于提出并倡导构建“奇异可识别性理论”（SITh），这是一个旨在弥合理论与实践差距的新颖理论框架。这对于指导未来SSL的理论研究方向具有重要意义，有助于推动该领域向更可解释和泛化的模型发展。

<details>
  <summary>Details</summary>

**Motivation:** 尽管自监督学习（SSL）在当前AI系统中扮演着重要角色，并且研究兴趣和投资不断增长，但其核心现象——柏拉图式表征假设（PRH）——缺乏精确的理论解释。此外，现有可识别性理论（IT）无法解释SSL的经验成功，因此需要弥合理论与实践之间的鸿沟。

**Method:** 本文首先综合可识别性理论（IT）的证据，以展示柏拉图式表征假设（PRH）如何在自监督学习（SSL）中出现。在此基础上，为了弥补当前IT无法解释SSL经验成功的不足，本文提出并倡导将IT扩展为奇异可识别性理论（SITh），这是一个涵盖整个SSL流程的更广泛的理论框架。

**Result:** 通过综合可识别性理论（IT）的证据，本文表明柏拉图式表征假设（PRH）可以在自监督学习（SSL）中出现。此外，本文提出了奇异可识别性理论（SITh），该理论框架有望为SSL中的隐式数据假设提供更深入的见解，并推动该领域学习更可解释和泛化的表征。

**Conclusion:** 一个基于经验的可识别性理论，特别是本文提出的奇异可识别性理论（SITh），对于弥合自监督学习（SSL）中理论与实践之间的差距至关重要。它将促进对SSL中隐式数据假设的深入理解，并加速该领域向学习更可解释和泛化表征的方向发展。

> **ai_Abstract:** 本文是一篇立场论文，探讨了自监督学习（SSL）中柏拉图式表征假设（PRH）缺乏精确理论解释的问题。作者通过综合现有可识别性理论（IT）的证据，指出PRH可以在SSL中出现，但当前IT不足以解释SSL的经验成功。为解决这一理论与实践的鸿沟，论文提出并倡导构建奇异可识别性理论（SITh），这是一个更全面的理论框架，旨在深入理解SSL中的隐式数据假设，并促进生成更具可解释性和泛化能力的表征。文章还指出了未来研究的三个关键方向。

> **摘要翻译:** 自监督学习（SSL）为当前许多AI系统提供动力。随着研究兴趣和投资的增长，SSL的设计空间持续扩展。遵循柏拉图式表征假设（PRH）的SSL柏拉图式观点认为，尽管方法和工程方法不同，所有表征都趋向于相同的柏拉图式理想。然而，这种现象缺乏精确的理论解释。通过综合可识别性理论（IT）的证据，我们表明PRH可以在SSL中出现。然而，当前IT无法解释SSL的经验成功。为了弥合理论与实践之间的鸿沟，我们建议将IT扩展为我们称之为奇异可识别性理论（SITh）的更广泛的理论框架，该框架涵盖整个SSL流程。SITh将允许更深入地了解SSL中的隐式数据假设，并推动该领域学习更可解释和泛化的表征。我们强调了未来研究的三个关键方向：1) SSL的训练动态和收敛特性；2) 有限样本、批量大小和数据多样性的影响；3) 架构、增强、初始化方案和优化器中归纳偏置的作用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [485] [Causal Mechanism Estimation in Multi-Sensor Systems Across Multiple Domains](https://arxiv.org/abs/2507.17792)
> *多域多传感器系统中的因果机制估计*

*Jingyi Yu, Tim Pychynski, Marco F. Huber* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-25**

**Keywords:** 因果机制估计, 多传感器系统, 因果迁移学习, 异构数据, 域不变

**Comment:** 

> **TL;DR:** 提出CICME方法，利用因果迁移学习从多域异构数据中估计共同和个体因果机制，并在制造过程场景中表现出色。

**AI_Comments:** 这篇论文提出了一种创新的方法（CICME），有效解决了异构多域传感器系统中的因果推断挑战。其优势在于利用因果迁移学习识别共同机制，进而指导个体域的分析，提供了比传统方法更鲁棒和高效的解决方案。在制造过程中的应用突出了其实用相关性。

<details>
  <summary>Details</summary>

**Motivation:** 通过因果关系视角，深入理解复杂传感器系统。

**Method:** 提出了一种新颖的三步法——共同和个体因果机制估计（CICME），用于从跨多个域收集的异构数据中推断因果机制。CICME利用因果迁移学习（CTL）原理，在样本充足时能可靠地检测域不变的因果机制。识别出的共同因果机制进一步用于指导每个域中剩余因果机制的单独估计。该方法建立在现有基于连续优化的因果发现方法之上。

**Result:** CICME的性能在受制造过程启发下的线性高斯模型场景中进行了评估。结果表明，CICME结合了对汇总数据和单个域数据重复应用因果发现的优点，并且在某些场景下甚至优于两种基线方法。

**Conclusion:** CICME是一种在多域多传感器系统中估计因果机制的有效方法，通过利用因果迁移学习并结合汇总数据和单个域数据的洞察力，在某些场景下优于基线方法。

> **ai_Abstract:** 该论文提出了一种名为共同和个体因果机制估计（CICME）的新颖三步法，旨在从跨多域的异构传感器数据中推断因果机制。CICME利用因果迁移学习（CTL）来识别域不变的共同因果机制，并用其指导个体域的机制估计。在受制造过程启发的线性高斯模型上进行评估，结果表明CICME结合了对汇总数据和单个域数据进行因果发现的优势，并在特定场景下表现优于现有基线方法。

> **摘要翻译:** 为了通过因果关系的视角更深入地理解复杂的传感器系统，我们提出了共同和个体因果机制估计（CICME），这是一种新颖的三步法，用于从跨多个域收集的异构数据中推断因果机制。通过利用因果迁移学习（CTL）原理，CICME在提供足够样本的情况下能够可靠地检测域不变的因果机制。识别出的共同因果机制进一步用于指导每个域中剩余因果机制的单独估计。CICME的性能在受制造过程启发下的线性高斯模型场景中进行了评估。在现有基于连续优化的因果发现方法的基础上，我们表明CICME利用了对汇总数据和单个域数据重复应用因果发现的优点，并且在某些场景下甚至优于两种基线方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [496] [Efficient Uncertainty in LLMs through Evidential Knowledge Distillation](https://arxiv.org/abs/2507.18366)
> *LLM中通过证据知识蒸馏实现高效不确定性量化*

*Lakshmana Sri Harsha Nemani, P. K. Srijith, Tomasz Kuśmierczyk* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-24**

**Keywords:** LLM, 不确定性量化, 知识蒸馏, 证据学习, LoRA

**Comment:** 

> **TL;DR:** 本文通过证据知识蒸馏将不确定性感知的教师模型蒸馏到紧凑的学生模型中，实现了LLM中高效且准确的不确定性量化，只需单次前向传播。

**AI_Comments:** 这篇论文通过引入证据知识蒸馏，解决了LLM中不确定性量化计算成本高昂的问题，具有重要的创新性。其核心优势在于使得LLM能够在单次前向传播中提供可靠的不确定性估计，这对于实际应用至关重要。将不确定性估计从复杂的贝叶斯/集成方法简化到紧凑的学生模型，并通过LoRA进行高效微调，是其技术亮点。

<details>
  <summary>Details</summary>

**Motivation:** 标准大型语言模型（LLM）中的准确不确定性量化是一个关键挑战。现有的贝叶斯和基于集成的方法计算成本高昂，需要多次前向传播来估计预测不确定性。

**Method:** 本文提出了一种新颖的方法，通过知识蒸馏在LLM中实现高效且有效的不确定性估计。具体来说，将需要多次前向传播的不确定性感知教师模型蒸馏到使用低秩适应（LoRA）微调的紧凑学生模型中。研究比较了两种蒸馏策略：一种学生模型采用传统的基于softmax的输出，另一种使用Dirichlet分布输出通过证据学习显式建模认知不确定性。

**Result:** 在分类数据集上的实证评估表明，学生模型相对于教师模型可以实现相当或更优的预测和不确定性量化性能，并且关键是只需单次前向传播。

**Conclusion:** 这是首次证明可以通过证据蒸馏在LLM中实现即时且鲁棒的不确定性量化。

> **ai_Abstract:** 本文提出了一种通过证据知识蒸馏在大型语言模型（LLM）中实现高效不确定性量化的新方法。该方法将需要多次前向传播的不确定性感知教师模型蒸馏到使用LoRA微调的紧凑学生模型中。通过比较基于softmax和Dirichlet分布输出的两种蒸馏策略，研究表明学生模型在单次前向传播下，能达到与教师模型相当或更优的预测和不确定性量化性能，首次展示了通过证据蒸馏在LLM中实现即时且鲁棒的不确定性量化的可能性。

> **摘要翻译:** 准确的不确定性量化仍然是标准大型语言模型（LLM）面临的一个关键挑战，这促使人们采用贝叶斯和基于集成的方法。然而，这些方法通常需要计算成本高昂的采样，涉及多次前向传播才能有效估计预测不确定性。
在本文中，我们引入了一种新颖的方法，能够在不牺牲性能的情况下，在LLM中实现高效且有效的不确定性估计。具体来说，我们将不确定性感知的教师模型——原本需要多次前向传播——蒸馏到紧凑的学生模型中，这些学生模型共享相同的架构，但使用低秩适应（LoRA）进行微调。我们比较了两种不同的蒸馏策略：一种是学生模型采用传统的基于softmax的输出，另一种是学生模型利用Dirichlet分布输出，通过证据学习明确建模认知不确定性。
在分类数据集上的实证评估表明，这些学生模型相对于其教师模型可以实现相当或更优的预测和不确定性量化性能，同时关键是只需要单次前向传播。据我们所知，这是首次证明可以通过证据蒸馏在LLM中实现即时且鲁棒的不确定性量化。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [497] [Statistical Runtime Verification for LLMs via Robustness Estimation](https://arxiv.org/abs/2504.17723)
> *统计运行时验证大型语言模型通过鲁棒性估计*

*Natan Levy, Adiel Ashrov, Guy Katz* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** LLM鲁棒性, 运行时验证, 统计验证, RoMA, 黑盒部署

**Comment:** 20 pages, 4 figures

> **TL;DR:** 提出并验证了RoMA框架，用于在黑盒部署中对LLM进行运行时鲁棒性监控，比传统形式化方法更快且准确度相当。

**AI_Comments:** 这篇论文的创新点在于将统计验证框架RoMA应用于LLM的运行时鲁棒性验证，解决了传统形式化方法计算开销大和白盒依赖的问题。其重要性在于为LLM在实际部署中的安全性和可靠性提供了一个高效且可扩展的监控方案，特别是在黑盒场景下。局限性可能在于统计方法提供的保证不如形式化方法严格，尽管文中提到了“统计验证界限”。

<details>
  <summary>Details</summary>

**Motivation:** 确保大型语言模型（LLMs）在运行时关键应用中的安全部署需要对抗鲁棒性验证，但现有的形式化验证技术因计算成本高昂和需要白盒访问而不可行。

**Method:** 本文通过案例研究，调整并扩展了RoMA统计验证框架，评估其作为LLM黑盒部署中在线运行时鲁棒性监测器的可行性。RoMA通过分析语义扰动下的置信度分数分布，提供具有统计验证界限的定量鲁棒性评估。

**Result:** 经验证表明，RoMA与形式化验证基线相比，实现了可比的准确性（偏差在1%以内），并将验证时间从数小时缩短至数分钟。该框架在语义、类别和正字法扰动域中进行了评估。

**Conclusion:** RoMA在LLM实际部署中的鲁棒性监控方面表现出有效性，当形式化方法不可行时，RoMA提供了一个潜在可扩展的替代方案，对基于LLM的系统运行时验证具有前景。

> **ai_Abstract:** 本文提出并验证了RoMA统计验证框架，作为大型语言模型（LLMs）在黑盒部署中进行运行时鲁棒性监控的有效工具。针对传统形式化验证方法计算成本高昂且需要白盒访问的挑战，RoMA通过分析语义扰动下的置信度分数分布来评估LLM的鲁棒性。实验结果显示，RoMA在准确性上与形式化方法相当（偏差小于1%），并将验证时间从数小时大幅缩短至数分钟，证明了其在实际LLM部署中进行鲁棒性监控的有效性和可扩展性。

> **摘要翻译:** 对抗鲁棒性验证对于确保大型语言模型（LLM）在运行时关键应用中的安全部署至关重要。然而，由于计算运行时呈指数级增长和需要白盒访问，形式化验证技术对于现代LLM而言仍然在计算上不可行。本文提出了一个案例研究，旨在调整和扩展RoMA统计验证框架，以评估其作为LLM在黑盒部署设置中在线运行时鲁棒性监测器的可行性。我们对RoMA的适应性改进在于分析语义扰动下的置信度分数分布，以提供具有统计验证界限的定量鲁棒性评估。我们针对形式化验证基线的实证验证表明，RoMA实现了可比的准确性（偏差在1%以内），并将验证时间从数小时缩短至数分钟。我们跨语义、类别和正字法扰动域评估了该框架。我们的结果表明RoMA在LLM运行部署中进行鲁棒性监控的有效性。这些发现指出，当形式化方法不可行时，RoMA可能是一个可扩展的替代方案，对基于LLM的系统中的运行时验证具有广阔前景。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [510] [Predictive Scaling Laws for Efficient GRPO Training of Large Reasoning Models](https://arxiv.org/abs/2507.18014)
> *大型推理模型高效GRPO训练的预测性缩放定律*

*Datta Nimmaturi, Vaishnavi Bhargava, Rajat Ghosh, Johnu George, Debojyoti Dutta* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, GRPO, 缩放定律, 高效训练, 早期停止

**Comment:** 

> **TL;DR:** 提出一种预测框架及经验缩放定律，用于高效GRPO微调大型推理模型，发现可提前停止以节省计算资源。

**AI_Comments:** 这篇论文通过引入预测性缩放定律，为大型语言模型的高效GRPO微调提供了重要的实践指导。其创新点在于将训练动态建模并识别出可提前停止的阶段，从而显著降低计算成本，这对于资源受限的研究者和实际应用具有重要意义。该发现有助于优化LLM的训练流程，提高资源利用率。

<details>
  <summary>Details</summary>

**Motivation:** 使用GRPO等强化学习方法微调大型语言模型（LLM）进行推理任务的计算成本高昂。

**Method:** 提出一个预测框架来建模训练动态，并通过在Llama和Qwen模型（3B、8B）上的实验，推导出一个基于模型大小、初始性能和训练进度的经验缩放定律。

**Result:** 经验缩放定律能够预测奖励轨迹，并识别出三个一致的训练阶段：慢启动、快速改进和平台期。研究发现，训练超过特定周期数后收益甚微，表明可以提前停止训练以显著减少计算量而不牺牲性能。该方法适用于不同模型类型。

**Conclusion:** 通过应用预测性缩放定律，可以识别大型推理模型GRPO微调的最佳停止点，从而显著提高计算效率并保持性能。

> **ai_Abstract:** 本文提出了一个预测框架，通过建模训练动态和推导经验缩放定律，旨在解决大型语言模型使用GRPO进行推理任务微调时计算成本高昂的问题。该定律基于模型大小、初始性能和训练进度，能够预测奖励轨迹并识别出慢启动、快速改进和平台期三个训练阶段。研究发现，在性能达到平台期后提前停止训练可以显著节省计算资源，且不影响性能，为GRPO高效微调提供了实用指导。

> **摘要翻译:** 使用组相对策略优化（GRPO）等强化学习方法对大型语言模型（LLM）进行推理任务的微调计算成本高昂。为解决此问题，我们提出了一个预测框架，该框架对训练动态进行建模并有助于优化资源使用。通过在Llama和Qwen模型（3B、8B）上的实验，我们推导出了一个基于模型大小、初始性能和训练进度的经验缩放定律。该定律预测奖励轨迹并识别出三个一致的训练阶段：慢启动、快速改进和平台期。我们发现，训练超过一定数量的周期后收益甚微，这表明提前停止可以显著减少计算量而不牺牲性能。我们的方法适用于不同模型类型，为高效的基于GRPO的微调提供了实用指导。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [529] [A Comprehensive Review of Diffusion Models in Smart Agriculture: Progress, Applications, and Challenges](https://arxiv.org/abs/2507.18376)
> *智能农业中扩散模型的综合综述：进展、应用与挑战*

*Xing Hua, Haodong Chen, Qianqian Duan, Danfeng Hong, Ruijiao Li, Huiliang Shang, Linghua Jiang, Haima Yang, Dawei Zhang* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 智能农业, 数据增强, 图像生成, 农业遥感

**Comment:** 

> **TL;DR:** 本文综述了扩散模型在智能农业中的最新进展、应用潜力及面临的挑战，指出其在解决数据稀缺和提高模型性能方面的优势，并展望了其在农业可持续发展中的重要作用。

**AI_Comments:** 该综述性论文系统地梳理了扩散模型在智能农业中的应用现状与前景，突出了其在解决农业数据挑战方面的独特优势，尤其是在数据增强和图像生成方面的卓越性能。论文对未来发展趋势的展望也具有指导意义，尽管其作为综述性论文未提出新的方法，但其全面性和对当前挑战的分析有助于推动该领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 随着全球人口增长和耕地资源稀缺，智能农业和精准农业成为未来农业发展的关键方向。人工智能技术，特别是深度学习模型，在农业领域应用广泛。扩散模型作为新兴的生成模型，在农业图像处理、数据增强和遥感等任务中展现出巨大潜力，且相比GANs具有更好的训练稳定性和生成质量，能有效解决农业数据有限和图像样本不平衡的挑战。

**Method:** 本文综述了扩散模型在农业应用中的最新进展，重点关注其在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理方面的潜力。

**Result:** 实验结果表明，扩散模型在数据增强、图像生成和去噪方面显著提高了模型精度和鲁棒性，尤其是在复杂环境中。与传统生成对抗网络（GANs）相比，扩散模型在训练稳定性和生成质量方面表现更优，有效解决了农业数据有限和图像样本不平衡等挑战。

**Conclusion:** 尽管扩散模型面临计算效率和泛化能力方面的挑战，但随着技术进步，它们有望在智能农业和精准农业中发挥越来越重要的作用，为全球农业的可持续发展提供实质性支持。

> **ai_Abstract:** 本文全面综述了扩散模型在智能农业领域的最新进展、应用及挑战。研究指出，扩散模型作为一种新兴的生成模型，在农业图像处理、数据增强和遥感等任务中表现出显著优势，尤其在解决农业数据稀缺和样本不平衡问题上优于传统GANs。文章详细探讨了扩散模型在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理中的应用潜力，并通过实验结果验证了其在提高模型精度和鲁棒性方面的有效性。尽管存在计算效率和泛化能力等挑战，但预计扩散模型将在未来智能农业的可持续发展中扮演关键角色。

> **摘要翻译:** 随着全球人口增长和耕地资源日益稀缺，智能农业和精准农业已成为未来农业发展的关键方向。人工智能（AI）技术，特别是深度学习模型，已在作物监测和病虫害检测等领域得到广泛应用。作为一种新兴的生成模型，扩散模型在农业图像处理、数据增强和遥感等任务中展现出巨大潜力。与传统生成对抗网络（GANs）相比，扩散模型提供了卓越的训练稳定性和生成质量，有效解决了农业数据有限和图像样本不平衡等挑战。本文综述了扩散模型在农业应用中的最新进展，重点关注其在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理方面的潜力。实验结果表明，扩散模型在数据增强、图像生成和去噪方面显著提高了模型精度和鲁棒性，尤其是在复杂环境中。尽管面临计算效率和泛化能力方面的挑战，但随着技术进步，扩散模型有望在智能和精准农业中发挥越来越重要的作用，为全球农业的可持续发展提供实质性支持。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [532] [Beyond Low-rank Decomposition: A Shortcut Approach for Efficient On-Device Learning](https://arxiv.org/abs/2505.05086)
> *超越低秩分解：一种高效设备端学习的捷径方法*

*Le-Trung Nguyen, Ael Quelennec, Van-Tam Nguyen, Enzo Tartaglione* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 设备端学习, 内存效率, 计算效率, 捷径方法, 低秩分解

**Comment:** 

> **TL;DR:** 本文提出了一种新的“捷径方法”，作为低秩分解的替代方案，旨在显著减少设备端学习的内存和计算开销，实现高效的设备端AI部署。

**AI_Comments:** 该论文通过提出一种超越传统低秩分解的创新“捷径方法”，解决了设备端AI部署中的关键挑战。其在内存和计算成本上的显著降低，对于推动AI在资源受限设备上的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 设备端学习面临显著的内存和计算限制，尽管它在减少延迟、保护隐私和提高能效方面具有优势。

**Method:** 本文提出了一种新颖的“捷径方法”，作为先前低秩分解方法解决反向传播中激活内存瓶颈的替代方案。

**Result:** 与传统训练相比，该方法将激活内存使用量减少了高达120.09倍，总训练FLOPs减少了高达1.86倍。

**Conclusion:** 该“捷径方法”有效解决了设备端学习中的内存和计算挑战，使其更高效可行。

> **ai_Abstract:** 本文提出了一种超越传统低秩分解的“捷径方法”，以解决设备端学习中面临的内存和计算限制。该方法作为一种新颖的替代方案，在实验中展示了显著的效率提升，与传统训练相比，激活内存使用量减少了高达120.09倍，总训练FLOPs减少了高达1.86倍，从而为高效的设备端AI部署提供了可行途径。

> **摘要翻译:** 设备端学习已成为人工智能发展的一个有前景的方向，特别是由于其在减少延迟问题和缓解与设备-服务器通信相关的隐私风险方面的潜力，同时提高了能源效率。尽管有这些优点，显著的内存和计算限制仍然是其部署的主要挑战。借鉴先前关于低秩分解方法解决反向传播中激活内存瓶颈的研究，我们提出了一种新颖的捷径方法作为替代方案。我们的分析和实验表明，与传统训练相比，我们的方法可以减少激活内存使用量高达120.09倍，同时在传统基准测试中，总训练浮点运算（FLOPs）也减少了高达1.86倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [533] [LSDM: LLM-Enhanced Spatio-temporal Diffusion Model for Service-Level Mobile Traffic Prediction](https://arxiv.org/abs/2507.17795)
> *LSDM：LLM增强时空扩散模型用于服务级移动流量预测*

*Shiyuan Zhang, Tong Li, Zhu Xiao, Hongyang Du, Kaibin Huang* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** LSDM, LLM, 时空扩散模型, 移动流量预测, 服务级

**Comment:** 14 pages, 9 figures

> **TL;DR:** LSDM提出了一种结合LLM和扩散模型的时空预测方法，有效提升了服务级移动流量预测的准确性和泛化能力。

**AI_Comments:** LSDM的创新点在于将大型语言模型（LLM）的上下文理解能力与扩散模型的生成能力相结合，应用于时空数据预测，尤其是在移动流量预测领域。这种跨领域的技术融合有效地解决了传统方法在处理高度不确定性和缺乏详细环境上下文方面的局限性，显著提升了预测的准确性和模型的泛化能力。其在真实世界数据集上的表现证明了该方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 当前的服务级移动流量预测方法在不同城市环境中的适应性有限，并且由于个人流量模式的高度不确定性、缺乏详细的环境上下文以及不同网络服务之间复杂的依赖关系，导致预测结果不准确。这些挑战需要先进的建模技术来捕捉动态流量分布和丰富的环境特征，以提升网络效率和QoS。

**Method:** 受扩散模型在分布建模和大型语言模型（LLMs）在上下文理解方面成功的启发，本文提出了一种LLM增强时空扩散模型（LSDM）。LSDM将扩散模型的生成能力与Transformer的自适应学习能力相结合，并通过捕获多模态环境信息来建模服务级模式和动态。

**Result:** 在真实世界服务级数据集上的广泛评估表明，LSDM在流量使用预测方面表现出色，显示出卓越的泛化能力和适应性。在通过LLM整合上下文信息后，模型在决定系数方面的性能提升了至少2.83%。与CSDI等类似模型相比，均方根误差至少降低了8.29%。

**Conclusion:** LSDM模型通过结合LLM和扩散模型的优势，有效解决了服务级移动流量预测中的挑战，显著提高了预测精度、泛化能力和适应性。

> **ai_Abstract:** 本文提出了一种名为LSDM的LLM增强时空扩散模型，旨在解决服务级移动流量预测中存在的适应性差和不准确性问题。LSDM结合了扩散模型的生成能力和Transformer的自适应学习能力，并通过LLM融入多模态环境上下文信息，以更好地捕捉动态流量分布和复杂依赖关系。在真实数据集上的实验证明，LSDM在流量预测方面表现出优异的泛化性和适应性，并且在引入LLM上下文信息后，性能指标有显著提升，尤其是在决定系数和均方根误差方面。

> **摘要翻译:** 服务级个人移动流量预测对于提升网络效率和QoS至关重要。然而，当前的预测方法在不同城市环境中的适应性有限，并且由于个人流量模式的高度不确定性、缺乏详细的环境上下文以及不同网络服务之间复杂的依赖关系，导致预测结果不准确。这些挑战需要先进的建模技术来捕捉动态流量分布和丰富的环境特征。受扩散模型在分布建模和大型语言模型（LLMs）在上下文理解方面成功的启发，我们提出了一种LLM增强时空扩散模型（LSDM）。LSDM将扩散模型的生成能力与Transformer的自适应学习能力相结合，并通过捕获多模态环境信息来建模服务级模式和动态。在真实世界服务级数据集上的广泛评估表明，该模型在流量使用预测方面表现出色，显示出卓越的泛化能力和适应性。在通过LLM整合上下文信息后，性能在决定系数方面提升了至少2.83%。与CSDI等类似模型相比，均方根误差至少降低了8.29%。代码和数据集将在此处提供：https://github.com/SoftYuaneR/LSDM。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [543] [DualXDA: Towards Sparse, Efficient and Explainable Data Attribution in Large AI Models](https://arxiv.org/abs/2402.12118)
> *DualXDA：迈向大型AI模型中稀疏、高效且可解释的数据归因*

*Galip Ümit Yolcu, Moritz Weckbecker, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 数据归因, 可解释AI, 稀疏性, 效率, DualXDA

**Comment:** 

> **TL;DR:** DualXDA是一个用于大型AI模型中稀疏、高效且可解释的数据归因框架，显著提升了归因速度并提供了更深入的解释。

**AI_Comments:** DualXDA通过引入基于SVM的DualDA，极大地提高了数据归因的效率和稀疏性，解决了现有方法计算成本高昂的痛点，其性能提升倍数令人印象深刻。同时，XDA的引入使得数据归因不仅能指出相关数据，还能解释其相关性背后的特征原因，增加了可解释的深度，具有重要的创新性。这对于推动大型AI模型的可解释性和负责任AI的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数据归因（DA）方法计算成本和内存需求极高，且归因稀疏性低，阻碍了数据中决定性模式的发现。

**Method:** 本文提出了DualXDA框架，包含两种相互关联的方法：Dual Data Attribution (DualDA) 和 eXplainable Data Attribution (XDA)。DualDA利用支持向量机理论，提供快速且天然稀疏的数据归因。XDA则结合特征归因方法，解释训练样本为何通过影响特征对测试样本的预测至关重要。

**Result:** DualDA实现了高质量的归因，擅长解决一系列下游任务，并将解释时间比原始影响力函数方法缩短了高达4,100,000倍，比文献中最有效的近似方法缩短了高达11,000倍。

**Conclusion:** DualXDA的贡献预示着可解释AI在空前规模下的应用，能够对最大的神经网络架构进行透明、高效和新颖的分析，从而催生新一代负责任的AI系统。

> **ai_Abstract:** 本文介绍了DualXDA，一个旨在解决大型AI模型中数据归因（DA）现有问题（高成本、低稀疏性）的新框架。DualXDA包含DualDA和XDA两部分。DualDA利用SVM理论实现高效、稀疏的数据归因，显著提升了归因速度，并展现出高归因质量。XDA则结合特征归因，深入解释训练样本对预测的影响。该框架为大规模可解释AI应用铺平了道路，促进了透明、高效的AI系统发展。

> **摘要翻译:** 深度学习模型取得了卓越的性能，但其决策过程往往不透明。为此，可解释人工智能（XAI）领域在过去十年中取得了显著发展，主要集中于特征归因方法。作为这一视角的补充，数据归因（DA）已成为一种有前景的范式，将焦点从特征转移到数据来源。然而，现有DA方法存在计算成本过高和内存需求过大的问题。此外，当前的归因方法稀疏性较低，阻碍了数据中决定性模式的发现。我们引入了DualXDA，一个用于稀疏、高效且可解释DA的框架，由两种相互关联的方法组成：Dual Data Attribution (DualDA) 和 eXplainable Data Attribution (XDA)。通过DualDA，我们提出了高效且有效的数据归因方法，利用支持向量机理论为AI预测提供快速且天然稀疏的数据归因。我们证明DualDA实现了高归因质量，擅长解决一系列评估过的下游任务，同时将解释时间比原始影响力函数方法缩短了高达4,100,000倍，比文献中最有效的近似方法缩短了高达11,000倍。我们进一步引入了XDA，一种通过特征归因方法的能力增强数据归因的方法，以解释训练样本为何在影响特征方面与测试样本的预测相关。总而言之，我们在DualXDA中的贡献最终指向了可解释AI在空前规模下的未来应用，实现了对最大神经网络架构的透明、高效和新颖的分析，从而培养了新一代负责任的AI系统。代码可在https://github.com/gumityolcu/DualXDA获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [558] [Multiscale Neural PDE Surrogates for Prediction and Downscaling: Application to Ocean Currents](https://arxiv.org/abs/2507.18067)
> *多尺度神经偏微分方程代理模型用于预测和降尺度：应用于洋流*

*Abdessamad El-Kabid, Loubna Benabbou, Redouane Lguensat, Alex Hernández-García* | **Category: cs.LG, cs.CE** | **Updated: 2025-07-24**

**Keywords:** 多尺度, 神经PDE代理, 降尺度, 洋流, 深度学习

**Comment:** Workshop @ ICML2025

> **TL;DR:** 本文提出了一种基于神经算子的深度学习框架，用于求解偏微分方程并提供任意分辨率的解，并应用于洋流数据的降尺度和预测。

**AI_Comments:** 该论文的创新点在于引入了多尺度神经偏微分方程代理模型，能够提供任意分辨率的解决方案，这对于需要高空间粒度数据的领域（如海洋学）具有重要意义。其方法能够处理PDE求解和数据降尺度，具有较强的通用性。

<details>
  <summary>Details</summary>

**Motivation:** 在海洋学中，高分辨率的洋流数据对于海岸管理、环境监测和海上安全至关重要。然而，现有卫星产品和全球海洋模型通常缺乏详细局部分析所需的空间粒度。

**Method:** 本文引入了一个基于神经算子的监督深度学习框架，用于求解偏微分方程并提供任意分辨率的解。同时，提出了用于哥白尼洋流数据的降尺度模型。该方法能够模拟代理偏微分方程，并预测任意分辨率的解，不受输入分辨率限制。

**Result:** 该模型在真实的哥白尼洋流数据和合成的Navier-Stokes模拟数据集上进行了评估。

**Conclusion:** 该研究成功开发了一种多尺度神经偏微分方程代理模型，能够有效解决洋流数据的降尺度和高分辨率预测问题，并能提供任意分辨率的解。

> **ai_Abstract:** 本文提出了一种多尺度神经偏微分方程代理模型，通过基于神经算子的深度学习框架，解决了偏微分方程的求解和任意分辨率解的生成问题。该方法特别应用于洋流数据的降尺度和预测，旨在弥补现有卫星产品空间分辨率不足的缺陷。模型已在真实的哥白尼洋流数据和合成的Navier-Stokes模拟数据集上进行了验证。

> **摘要翻译:** 偏微分方程控制的物理系统的精确建模是科学计算中的核心挑战。在海洋学中，高分辨率的洋流数据对于海岸管理、环境监测和海上安全至关重要。然而，现有卫星产品，例如用于海水速度的哥白尼数据（空间分辨率约为0.08度）和全球海洋模型，通常缺乏详细局部分析所需的空间粒度。在这项工作中，我们（a）引入了一个基于神经算子的监督深度学习框架，用于求解偏微分方程并提供任意分辨率的解，并且（b）提出了应用于哥白尼洋流数据的降尺度模型。此外，我们的方法可以模拟代理偏微分方程，并预测任意分辨率的解，无论输入分辨率如何。我们在真实的哥白尼洋流数据和合成的Navier-Stokes模拟数据集上评估了我们的模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [562] [Outcome-Based Online Reinforcement Learning: Algorithms and Fundamental Limits](https://arxiv.org/abs/2505.20268)
> *基于结果的在线强化学习：算法与基本限制*

*Fan Chen, Zeyu Jia, Alexander Rakhlin, Tengyang Xie* | **Category: cs.LG, cs.AI, math.ST, stat.ML, stat.TH** | **Updated: 2025-07-24**

**Keywords:** 基于结果的强化学习, 在线强化学习, 函数逼近, 样本复杂度, 偏好反馈

**Comment:** 

> **TL;DR:** 本文首次全面分析了在线强化学习中基于结果反馈的问题，提出了一种样本高效的算法，并揭示了基于结果反馈与每步奖励的统计分离，为该领域奠定了理论基础。

**AI_Comments:** 本文创新性地在通用函数逼近的框架下，首次对在线强化学习中基于结果的反馈问题进行了全面分析。其提出的样本高效算法以及对统计分离的揭示，填补了该领域的理论空白，对于理解和开发大规模强化学习系统具有重要意义。特别是将方法扩展到基于偏好的反馈，增加了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 当奖励仅在轨迹末端观察到时，如何将信用分配给正确的动作是基于结果反馈的强化学习面临的一个根本挑战。

**Method:** 本文在具有通用函数逼近的在线强化学习中对该问题进行了首次全面分析。开发了一种可证明样本高效的算法，达到了$\\widetilde{O}({C_{\\rm cov} H^3}/{\\epsilon^2})$的样本复杂度。该方法利用通用函数逼近，适用于大型或无限状态空间。对于确定性MDPs，消除了完整性假设。此外，还将方法扩展到基于偏好的反馈设置。

**Result:** 开发了一种样本复杂度为$\\widetilde{O}({C_{\\rm cov} H^3}/{\\epsilon^2})$的样本高效算法。揭示了基于结果反馈与每步奖励在统计学上的分离，并指出对于某些MDPs存在不可避免的指数级分离。对于确定性MDPs，展示了如何消除完整性假设以简化算法。证明了在基于偏好的反馈设置下也能实现等效的统计效率。

**Conclusion:** 这些结果共同构成了理解基于结果的强化学习统计特性的理论基础。

> **ai_Abstract:** 本文首次全面分析了在线强化学习中基于结果反馈的问题，即奖励仅在轨迹末端观察时如何归因。研究提出了一种利用通用函数逼近的样本高效算法，其样本复杂度为$\\widetilde{O}({C_{\\rm cov} H^3}/{\\epsilon^2})$，适用于大型状态空间。研究还揭示了基于结果反馈与每步奖励之间的统计分离，并指出在确定性MDPs中可以简化算法，并能扩展到基于偏好的反馈设置，为该领域奠定了理论基础。

> **摘要翻译:** 基于结果反馈的强化学习面临一个根本挑战：当奖励仅在轨迹终点观察到时，我们如何将信用分配给正确的动作？本文首次在具有通用函数逼近的在线强化学习中对该问题进行了全面分析。我们开发了一种可证明样本高效的算法，实现了$\\widetilde{O}({C_{\\rm cov} H^3}/{\\epsilon^2})$的样本复杂度，其中$C_{\\rm cov}$是底层MDP的可覆盖性系数。通过利用通用函数逼近，我们的方法在表格方法失效的大型或无限状态空间中也能有效工作，仅要求值函数和奖励函数能够被适当的函数类表示。我们的结果还描述了基于结果的反馈何时与每步奖励在统计上分离，揭示了对于某些MDPs存在不可避免的指数级分离。对于确定性MDPs，我们展示了如何消除完整性假设，极大地简化了算法。我们进一步将方法扩展到基于偏好的反馈设置，证明即使在信息更有限的情况下也能实现等效的统计效率。总而言之，这些结果构成了理解基于结果的强化学习统计特性的理论基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [565] [Multi-Model Ensemble and Reservoir Computing for River Discharge Prediction in Ungauged Basins](https://arxiv.org/abs/2507.18423)
> *多模型集成与储层计算在无测站流域河流流量预测中的应用*

*Mizuki Funato, Yohei Sawada* | **Category: cs.LG, physics.geo-ph** | **Updated: 2025-07-24**

**Keywords:** 河流流量预测, 无测站流域, 多模型集成, 储层计算, 数据稀缺

**Comment:** 

> **TL;DR:** 本文提出了一种名为HYPER的新方法，结合多模型集成和储层计算，用于在数据稀缺条件下对无测站流域的河流流量进行鲁棒、高效和可推广的预测，其性能优于LSTM且计算效率更高。

**AI_Comments:** 该论文的创新点在于结合了传统水文模型集成（BMA）与先进机器学习技术（RC）来解决无测站流域的流量预测问题，尤其是在数据稀缺条件下的挑战。其非迭代的RC训练过程显著提高了计算效率，并证明了在特定框架下，无需对单个水文模型进行繁琐校准的可能性，这对于实际应用具有重要意义。该方法的普适性和鲁棒性是其主要优势。

<details>
  <summary>Details</summary>

**Motivation:** 尽管对准确洪水预测和水资源管理有迫切需求，但许多地区缺乏足够的河流流量观测数据，限制了降雨-径流分析的准确性。在数据稀缺条件下，实现高精度、可解释性和计算效率仍然是一个重大挑战。

**Method:** 本文提出了一种名为HYPER（HYdrological Prediction with multi-model Ensemble and Reservoir computing）的新方法。该方法首先对43个“未校准”的流域概念水文模型应用贝叶斯模型平均（BMA）。然后，通过线性回归训练一个储层计算（RC）模型来纠正BMA输出中的误差，这是一个非迭代过程，确保了高计算效率。对于无测站流域，通过将所需BMA和RC权重与有测站流域的流域属性相关联来推断，从而创建一个可推广的框架。

**Result:** HYPER在日本87个流域的数据上进行了评估。在数据丰富的情况下，HYPER（中位数KGE为0.56）表现与基准LSTM（KGE为0.55）相当，但仅需其5%的计算时间。在数据稀缺情况下（23%的流域有测站），HYPER保持了稳定的性能（KGE为0.55）和较低的不确定性，而LSTM的性能显著下降（KGE为-0.04）。

**Conclusion:** 研究结果表明，当有效的大型集合被组装并结合基于机器学习的偏差校正时，单个概念水文模型不一定需要校准。HYPER为流量预测提供了一种鲁棒、高效和可推广的解决方案，特别适用于无测站流域，使其适用于广泛的地区。

> **ai_Abstract:** 本文提出了一种名为HYPER（HYdrological Prediction with multi-model Ensemble and Reservoir computing）的新型水文预测方法，旨在解决数据稀缺条件下无测站流域河流流量预测的挑战。HYPER结合了贝叶斯模型平均（BMA）对大量未校准概念水文模型的集成，以及储层计算（RC）进行误差校正。该方法通过将模型权重与流域属性关联，实现了在无测站流域的可推广性。实验结果表明，HYPER在数据丰富和数据稀缺场景下均表现出与LSTM相当或更优的性能，同时显著提高了计算效率，并揭示了在有效集成和偏差校正下，单个水文模型无需校准的可能性，为流量预测提供了鲁棒、高效且普适的解决方案。

> **摘要翻译:** 尽管对准确洪水预测和水资源管理有迫切需求，但许多地区缺乏足够的河流流量观测数据，限制了降雨-径流分析的准确性。尽管存在大量基于物理和机器学习的模型，但在数据稀缺条件下实现高精度、可解释性和计算效率仍然是一个重大挑战。我们通过一种新颖的方法——结合多模型集成和储层计算（HYPER）的水文预测方法——解决了这一挑战。我们的方法首先对43个“未校准”的流域概念水文模型应用贝叶斯模型平均（BMA）。然后，通过线性回归训练一个储层计算（RC）模型来纠正BMA输出中的误差，这是一个非迭代过程，确保了高计算效率。对于无测站流域，我们通过将所需BMA和RC权重与有测站流域的流域属性相关联来推断，从而创建一个可推广的框架。我们使用来自日本87个河流流域的数据评估了HYPER。在数据丰富的情况下，HYPER（中位数KGE为0.56）表现与基准LSTM（KGE为0.55）相当，但仅需其5%的计算时间。在数据稀缺情况下（23%的流域有测站），HYPER保持了稳定的性能（KGE为0.55）和较低的不确定性，而LSTM的性能显著下降（KGE为-0.04）。这些结果表明，当有效的大型集合被组装并结合基于机器学习的偏差校正时，单个概念水文模型不一定需要校准。HYPER为流量预测提供了一种鲁棒、高效和可推广的解决方案，特别适用于无测站流域，使其适用于广泛的地区。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [581] [CoCAI: Copula-based Conformal Anomaly Identification for Multivariate Time-Series](https://arxiv.org/abs/2507.17796)
> *CoCAI：基于Copula的多元时间序列共形异常识别*

*Nicholas A. Pearson, Francesca Zanello, Davide Russo, Luca Bortolussi, Francesca Cairoli* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-23**

**Keywords:** 多元时间序列, 异常检测, 预测, Copula模型, 共形预测

**Comment:** Accepted for Presentation at Runtime Verification 25

> **TL;DR:** CoCAI是一个结合生成式AI和Copula模型的框架，用于多元时间序列的准确预测和鲁棒异常检测。

**AI_Comments:** 该论文提出了一种创新的CoCAI框架，将生成式AI（特别是扩散模型）与Copula模型和共形预测相结合，以解决多元时间序列的预测和异常检测问题。其创新点在于结合多种先进技术，特别是利用共形预测确保预测区域的统计有效性，并通过Copula模型提供统计学上可靠的异常分数。离线校准阶段的设计也考虑了实际部署的效率。该方法在实际运营数据上的验证表明了其在关键基础设施监控领域的潜在重要性。

<details>
  <summary>Details</summary>

**Motivation:** 解决多元时间序列分析中的两个关键挑战：提供准确的预测和实现鲁棒的异常检测。

**Method:** CoCAI框架结合了生成式人工智能和基于Copula的建模。它利用扩散模型进行高质量预测，并通过共形预测技术校准模型输出，以产生统计有效的预测区域。在此基础上，通过结合降维技术和基于Copula的建模进行鲁棒的异常值检测，提供统计学上可靠的异常分数。CoCAI还具有离线校准阶段，以实现最小的部署开销。

**Result:** 在水分配和污水处理系统的真实运行数据上进行的实证测试证实了CoCAI在准确预测目标数据序列和识别其中异常片段方面的有效性。

**Conclusion:** CoCAI是一种有效且基于理论基础的框架，能够准确预测多元时间序列并鲁棒地识别异常。

> **ai_Abstract:** CoCAI是一个新颖的框架，结合生成式AI、扩散模型和Copula建模，旨在解决多元时间序列的预测和异常检测问题。它利用扩散模型进行高质量预测，并通过共形预测校准生成统计有效的预测区域。在此基础上，结合降维和Copula模型进行鲁棒异常检测，提供统计学上的异常分数。CoCAI具有离线校准阶段，减少部署开销，并在水务系统数据上验证了其在预测和异常识别方面的有效性。

> **摘要翻译:** 我们提出了一个新颖的框架，该框架利用生成式人工智能和基于copula的建模的力量来解决多元时间序列分析中的两个关键挑战：提供准确的预测和实现鲁棒的异常检测。我们的方法，基于Copula的共形异常识别（CoCAI），利用扩散模型来捕获数据中复杂的依赖关系，从而实现高质量的预测。模型的输出通过共形预测技术进一步校准，产生统计有效的预测区域，即以期望的置信水平覆盖真实目标值。从这些校准后的预测开始，通过结合降维技术和基于copula的建模进行鲁棒的异常值检测，提供统计学上可靠的异常分数。CoCAI受益于离线校准阶段，这使得在部署期间的开销最小化，并提供植根于既定理论基础的可操作结果。在源自水分配和污水处理系统的真实运行数据上进行的实证测试证实了CoCAI在准确预测目标数据序列和识别其中异常片段方面的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [585] [A Multi-Faceted Evaluation Framework for Assessing Synthetic Data Generated by Large Language Models](https://arxiv.org/abs/2404.14445)
> *评估大型语言模型生成合成数据的多方面评估框架*

*Yefeng Yuan, Yuhong Liu, Liang Cheng* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 合成数据, 大型语言模型, 评估框架, 隐私保护, 表格数据

**Comment:** 10 pages, 1 figure, 4 tables

> **TL;DR:** 本文介绍了SynEval，一个开源评估框架，用于评估大型语言模型生成的合成表格数据的保真度、实用性和隐私保护，并通过实验揭示了评估指标之间的权衡。

**AI_Comments:** 这篇论文的创新点在于提出了一个多方面的、开源的评估框架SynEval，用于量化评估大型语言模型生成的合成数据的质量，同时兼顾了数据保真度、实用性和隐私保护。其重要性在于填补了当前领域缺乏全面评估工具的空白，为合成数据的使用提供了更可靠的依据，特别是在数据隐私日益受到关注的背景下。该框架的应用有助于研究人员和从业者更好地理解和权衡合成数据生成中的各项指标。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型生成的合成数据具有潜力，但存在隐私泄露的担忧，并且缺乏一个能够量化衡量合成数据质量及其下游任务实用性的全面评估框架。

**Method:** 论文引入了一个名为SynEval的开源评估框架，该框架通过一套多样化的评估指标来评估合成表格数据的保真度、实用性和隐私保护。作者通过将其应用于ChatGPT、Claude和Llama等大型语言模型生成的合成产品评论数据来验证其有效性。

**Result:** 实验结果揭示了在合成数据生成背景下，各种评估指标之间的权衡。

**Conclusion:** SynEval是研究人员和从业者处理合成表格数据的关键工具，使他们能够明智地确定生成数据对其特定应用的适用性，并强调维护用户隐私。

> **ai_Abstract:** 本文针对大型语言模型生成合成数据时存在的隐私泄露问题以及缺乏全面评估框架的现状，提出了一个名为SynEval的开源评估框架。SynEval旨在通过一套多样的指标，评估合成表格数据的保真度、实用性和隐私保护。通过在ChatGPT、Claude和Llama生成的合成产品评论数据上进行验证，该框架揭示了不同评估指标间的权衡，并为研究人员和从业者提供了评估合成数据适用性的关键工具，尤其是在隐私保护方面。

> **摘要翻译:** 生成式AI和大型语言模型（LLMs）的快速发展为生成合成数据开辟了新途径，特别是在结构化表格格式（如产品评论）领域。尽管存在潜在益处，但隐私泄露的担忧已经浮现，尤其是在训练数据集中使用了个人信息时。此外，目前缺乏一个能够定量衡量所生成合成数据质量及其对下游任务实用性的全面评估框架。为弥补这一空白，我们引入了SynEval，一个开源评估框架，旨在通过一套多样化的评估指标来评估合成表格数据的保真度、实用性和隐私保护。我们通过将SynEval应用于ChatGPT、Claude和Llama这三个最先进的大型语言模型生成的合成产品评论数据，验证了我们提出的框架——SynEval的有效性。我们的实验结果阐明了在合成数据生成背景下，各种评估指标之间的权衡。此外，SynEval是从事合成表格数据研究人员和从业者的关键工具，使他们能够明智地确定生成数据对其特定应用的适用性，并强调维护用户隐私。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [592] [VCDiag: Classifying Erroneous Waveforms for Failure Triage Acceleration](https://arxiv.org/abs/2506.03590)
> *VCDiag：加速故障分类的错误波形分类*

*Minh Luu, Surya Jasper, Khoi Le, Evan Pan, Michael Quinn, Aakash Tyagi, Jiang Hu* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 故障分类, 波形分类, VCD数据, 机器学习, RTL仿真

**Comment:** 

> **TL;DR:** VCDiag使用VCD数据对错误波形进行分类，以加速设计功能验证中的故障分类，显著减少数据量并高精度识别故障位置。

**AI_Comments:** 该论文提出了一种创新的方法VCDiag，解决了RTL级仿真故障分类中耗时且依赖人工的问题。其主要创新在于结合了高效的波形数据分类和显著的数据压缩技术（120倍以上），这对于处理大型设计尤其重要。94%的识别准确率表明了其有效性，并且其可集成性增加了实际应用的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 设计功能验证中的故障分类至关重要但耗时，依赖人工审查。机器学习在此领域应用有限，尤其对于大型设计。

**Method:** VCDiag利用VCD数据，通过新颖的信号选择和统计压缩方法（数据量减少120倍以上）来分类错误波形并定位可能的故障位置。

**Result:** 在最大规模实验中，VCDiag在识别前三个最可能模块方面达到94%以上的准确率。

**Conclusion:** VCDiag提供了一种高效、适应性强的方法，能够通过分类错误波形并识别故障位置来加速故障分类，且可集成到Verilog/SystemVerilog设计中。

> **ai_Abstract:** VCDiag是一种基于VCD数据的高效机器学习框架，旨在加速设计功能验证中的RTL级仿真故障分类。它通过创新的信号选择和统计压缩技术，将原始波形数据量大幅减少120倍以上，同时保持了识别错误波形的关键特征。该系统能以超过94%的准确率识别最可能的故障模块，并可广泛集成到现有的Verilog/SystemVerilog设计流程中，从而显著降低人工故障分类的时间和复杂性。

> **摘要翻译:** 设计功能验证中的故障分类至关重要但耗时，它依赖于手动规范审查、日志检查和波形分析。虽然机器学习（ML）在激励生成和覆盖率闭合等领域有所改进，但其在RTL级仿真故障分类中的应用仍然有限，特别是对于大型设计。VCDiag提供了一种高效、适应性强的方法，利用VCD数据对失败波形进行分类并确定可能的故障位置。在最大的实验中，VCDiag在识别前三个最可能模块方面达到了94%以上的准确率。该框架引入了一种新颖的信号选择和统计压缩方法，在保留分类所需特征的同时，将原始数据大小减少了120倍以上。它还可以集成到各种Verilog/SystemVerilog设计和测试平台中。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [601] [Revisiting Bisimulation Metric for Robust Representations in Reinforcement Learning](https://arxiv.org/abs/2507.18519)
> *再探强化学习中鲁棒表示的双模拟度量*

*Leiji Zhang, Zeyu Wang, Xin Li, Yao-Hui Li* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 双模拟度量, 强化学习, 鲁棒表示, 自适应系数, 表示学习

**Comment:** 

> **TL;DR:** 本文改进了强化学习中的双模拟度量，解决了其表示不足和固定权重问题，提出了自适应系数的新度量，并提供了理论和实验验证。

**AI_Comments:** 这篇论文创新性地解决了传统双模拟度量在表示能力和权重设定上的两大缺陷，通过引入自适应系数和更精确的奖励差距定义，显著提升了度量的鲁棒性。其理论保证和实验验证进一步巩固了该方法的可靠性和重要性，对强化学习中的表示学习领域具有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 传统的双模拟度量存在两个主要问题：无法表示某些独特场景，以及在递归更新中依赖预定义的奖励和后续状态差异权重。

**Method:** 通过引入状态-动作对的度量，提出了一个修正的双模拟度量，该度量具有更精确的奖励差距定义和带有自适应系数的新型更新算子。

**Result:** 提供了所提出度量的收敛性理论保证及其改进的表示区分度。在DeepMind Control和Meta-World基准上进行了广泛实验，证明了方法的有效性。

**Conclusion:** 论文通过提出一种修正的双模拟度量，解决了传统度量的问题，并通过理论分析和实验验证，证明了其在强化学习中学习更鲁棒表示的有效性。

> **ai_Abstract:** 本文重新审视了强化学习中传统的双模拟度量，指出了其在表示独特场景方面的不足以及对预定义权重的依赖。为解决这些问题，作者提出了一个修正的双模拟度量，其特点是更精确的奖励差距定义和带有自适应系数的新型更新算子。该研究提供了所提出度量的收敛性理论保证及其改进的表示区分度，并通过在DeepMind Control和Meta-World上的广泛实验验证了其有效性。

> **摘要翻译:** 双模拟度量长期以来被认为是各种强化学习任务中一种有效的控制相关表示学习技术。然而，在本文中，我们指出了传统双模拟度量的两个主要问题：1）无法表示某些独特的场景，以及2）在递归更新过程中依赖预定义的奖励差异和后续状态权重。我们发现第一个问题源于奖励差距定义的不精确，而第二个问题则源于忽视了在不同训练阶段和任务设置下奖励差异和下一状态区分度的不同重要性。为了解决这些问题，通过引入状态-动作对的度量，我们提出了一个修正的双模拟度量，其特点是更精确的奖励差距定义和带有自适应系数的新型更新算子。我们还为我们提出的度量及其改进的表示区分度提供了收敛性的理论保证。除了严谨的理论分析，我们还在两个代表性基准（DeepMind Control和Meta-World）上进行了广泛实验，证明了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [606] [Group Sequence Policy Optimization](https://arxiv.org/abs/2507.18071)
> *组序列策略优化*

*Chujie Zheng, Shixuan Liu, Mingze Li, Xiong-Hui Chen, Bowen Yu, Chang Gao, Kai Dang, Yuqiong Liu, Rui Men, An Yang, Jingren Zhou, Junyang Lin* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 强化学习, 大型语言模型, 序列优化, GSPO, MoE

**Comment:** 

> **TL;DR:** GSPO是一种新的强化学习算法，通过序列级重要性比率和裁剪来训练大型语言模型，比现有算法更稳定、高效，并显著改进了Qwen3模型。

**AI_Comments:** GSPO的创新点在于将强化学习的优化从token级别提升到序列级别，这对于处理长序列和保持训练稳定性至关重要，特别是对于大型语言模型如MoE架构。其在Qwen3模型上的成功应用证明了其实用价值和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的强化学习算法在训练大型语言模型时采用token级重要性比率，这可能导致不稳定或效率低下。

**Method:** 本文提出了组序列策略优化（GSPO）算法。与以往采用token级重要性比率的算法不同，GSPO基于序列似然定义重要性比率，并执行序列级裁剪、奖励和优化。

**Result:** GSPO与GRPO算法相比，实现了卓越的训练效率和性能，显著稳定了专家混合（MoE）RL训练，并具有简化RL基础设施设计的潜力。这些优点为最新的Qwen3模型带来了显著改进。

**Conclusion:** GSPO通过序列级优化，提供了一种稳定、高效且高性能的强化学习方法，尤其适用于大型语言模型训练，并已成功应用于Qwen3模型。

> **ai_Abstract:** 本文提出了一种名为组序列策略优化（GSPO）的强化学习算法，旨在解决大型语言模型训练中的稳定性和效率问题。GSPO的核心创新在于使用序列级的重要性比率和裁剪，而非传统的token级方法。实验证明，GSPO在训练效率和性能上优于GRPO，尤其在稳定专家混合模型（MoE）的强化学习训练方面表现突出，并有望简化RL基础设施设计。GSPO的成功应用显著提升了最新的Qwen3模型性能。

> **摘要翻译:** 本文介绍了组序列策略优化（GSPO），这是一种稳定、高效、高性能的强化学习算法，用于训练大型语言模型。与以往采用token级重要性比率的算法不同，GSPO基于序列似然定义重要性比率，并执行序列级裁剪、奖励和优化。我们证明了GSPO与GRPO算法相比，实现了卓越的训练效率和性能，显著稳定了专家混合（MoE）RL训练，并具有简化RL基础设施设计的潜力。GSPO的这些优点为最新的Qwen3模型带来了显著改进。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [611] [LLM Web Dynamics: Tracing Model Collapse in a Network of LLMs](https://arxiv.org/abs/2506.15690)
> *LLM网络动态：追踪LLM网络中的模型崩溃*

*Tianyu Wang, Akira Horiguchi, Lingyou Pang, Carey E. Priebe* | **Category: cs.LG, cs.AI, cs.SI, stat.ME** | **Updated: 2025-07-24**

**Keywords:** 模型崩溃, LLM网络, LWD, 检索增强生成, 收敛模式

**Comment:** 

> **TL;DR:** 本文提出了LLM网络动态（LWD）框架，用于在网络层面调查LLM中的模型崩溃问题。通过模拟互联网和RAG数据库，分析模型输出的收敛模式，并提供理论保证。

**AI_Comments:** 该论文的创新之处在于将模型崩溃的研究从单一模型扩展到网络层面，并引入了LLM Web Dynamics（LWD）框架。通过模拟互联网和提供理论保证，为理解LLM在复杂交互环境中的行为提供了新的视角和工具，对于LLM的可持续发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管来自公共互联网的合成数据提高了大型语言模型（LLM）训练的数据使用效率，但模型崩溃的潜在威胁尚未得到充分探索。现有研究主要限于单一模型设置或依赖统计替代，未能充分研究网络层面的模型崩溃。

**Method:** 本文引入了LLM网络动态（LWD）框架，通过使用检索增强生成（RAG）数据库模拟互联网，分析了模型输出的收敛模式。此外，通过类比交互式高斯混合模型，为这种收敛提供了理论保证。

**Result:** 该研究分析了模型输出的收敛模式，并为这种收敛提供了理论保证。

**Conclusion:** 本文提出了LLM网络动态（LWD）框架，有效解决了在网络层面研究模型崩溃的问题，并通过模拟和理论分析揭示了模型输出的收敛模式，为LLM的鲁棒性研究提供了新的视角。

> **ai_Abstract:** 本文提出了LLM网络动态（LWD）框架，旨在解决现有研究在探索模型崩溃时仅限于单一模型或统计替代的局限性。LWD通过模拟互联网和RAG数据库，分析了LLM网络中模型输出的收敛模式，并提供了理论收敛保证，深入探讨了合成数据使用带来的模型崩溃问题。

> **摘要翻译:** 大型语言模型（LLM）训练中，越来越多地使用来自公共互联网的合成数据，提高了数据使用效率。然而，模型崩溃的潜在威胁尚未得到充分探索。现有研究主要在单一模型设置中检查模型崩溃，或仅依赖统计替代。在这项工作中，我们引入了LLM网络动态（LWD），这是一个用于在网络层面调查模型崩溃的高效框架。通过使用检索增强生成（RAG）数据库模拟互联网，我们分析了模型输出的收敛模式。此外，我们通过类比交互式高斯混合模型，为这种收敛提供了理论保证。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [622] [On the Convergence of Gradient Descent on Learning Transformers with Residual Connections](https://arxiv.org/abs/2506.05249)
> *关于梯度下降在学习带有残差连接的Transformer时的收敛性*

*Zhen Qin, Jinxin Zhou, Zhihui Zhu* | **Category: cs.LG, math.OC** | **Updated: 2025-07-24**

**Keywords:** Transformer, 梯度下降, 残差连接, 收敛性, 优化稳定性

**Comment:** 

> **TL;DR:** 研究发现，在适当初始化下，梯度下降在训练带残差连接的Transformer时能实现线性收敛，且残差连接有助于优化稳定性。

**AI_Comments:** 这项研究创新性地从理论层面深入分析了带有残差连接的Transformer模型的训练动态，特别是梯度下降的收敛性。它不仅填补了现有研究中对组件间相互依赖性关注不足的空白，还揭示了残差连接在改善优化稳定性和解决病态问题中的关键作用。这对于理解和改进Transformer的训练过程具有重要指导意义，有助于设计更稳定、更高效的Transformer架构。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Transformer模型表现出色，但其理论基础（特别是训练动态）仍不成熟。现有研究多关注孤立组件，缺乏对组件间相互依赖性（尤其是有残差连接时）的深入探讨。

**Method:** 本文通过分析一个结构完整但单层的Transformer（包含自注意力、前馈网络和残差连接）的收敛行为来弥补这一空白。并将理论发现扩展到多层Transformer架构。

**Result:** 在适当初始化下，梯度下降呈现线性收敛速度，其收敛速度由注意力层输出矩阵的最小和最大奇异值决定。残差连接改善了输出矩阵的病态性，促进了优化稳定性。多层Transformer架构也确认了梯度下降的线性收敛率。经验结果也证实了残差连接对收敛稳定性的益处。

**Conclusion:** 本文理论和经验上证明了在适当初始化下，带有残差连接的Transformer模型通过梯度下降可以实现线性收敛，并且残差连接在改善优化稳定性和解决输出矩阵病态性方面发挥了关键作用。

> **ai_Abstract:** 本文深入探讨了带有残差连接的Transformer模型的梯度下降收敛行为。研究发现，在适当初始化条件下，无论是单层还是多层Transformer，梯度下降都能实现线性收敛，其速度受注意力层输出矩阵奇异值影响。关键在于，残差连接能有效缓解由softmax操作引起的输出矩阵病态问题，显著提升优化稳定性。理论分析得到了经验结果的验证。

> **摘要翻译:** Transformer模型因其在各种应用中的出色性能，已成为跨多个科学和工程领域的基础工具。尽管取得了这些经验上的成功，但Transformer的理论基础仍然相对不发达，特别是在理解其训练动态方面。现有研究主要检查孤立的组件——例如自注意力机制和前馈网络——而没有彻底研究这些组件之间的相互依赖性，尤其是在存在残差连接的情况下。在本文中，我们旨在通过分析一个结构完整但单层的Transformer的收敛行为来弥补这一空白，该Transformer包含自注意力、前馈网络和残差连接。我们证明，在适当的初始化下，梯度下降表现出线性收敛速度，其中收敛速度由注意力层输出矩阵的最小和最大奇异值决定。此外，我们的分析揭示，残差连接有助于改善此输出矩阵的病态性，这个问题源于softmax操作强加的低秩结构，从而促进增强的优化稳定性。我们还将理论发现扩展到多层Transformer架构，证实了在适当初始化下梯度下降的线性收敛速度。实证结果证实了我们的理论见解，说明了残差连接在促进收敛稳定性方面的有益作用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [626] [Concept Probing: Where to Find Human-Defined Concepts (Extended Version)](https://arxiv.org/abs/2507.18681)
> *概念探测：在哪里找到人类定义的概唸（扩展版）*

*Manuel de Sousa Ribeiro, Afonso Leote, João Leite* | **Category: cs.LG, cs.AI, cs.CV, cs.NE** | **Updated: 2025-07-24**

**Keywords:** 概念探测, 神经网络, 可解释性, 层识别, 内部表示

**Comment:** Extended version of the paper published in Proceedings of the
  International Conference on Neurosymbolic Learning and Reasoning (NeSy 2025)

> **TL;DR:** 提出一种自动识别神经网络中用于概念探测的最佳层的方法。

**AI_Comments:** 这篇论文解决了概念探测中的一个关键挑战，即如何选择合适的神经网络层进行探测。其创新之处在于提出了一种基于表示的信息性和规律性来自动识别最佳层的方法，这有助于提高概念探测的效率和准确性。这项工作对于理解神经网络内部工作机制和提高模型可解释性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 概念探测的性能高度依赖于被探测的内部表示，因此识别合适的层是一个重要任务。

**Method:** 提出一种基于表示的信息性和规律性来自动识别神经网络中哪个层适用于探测特定人类定义概念的方法。

**Result:** 通过对不同神经网络模型和数据集进行详尽的实证分析，验证了该方法的有效性。

**Conclusion:** 本文提出的方法能够自动识别神经网络中用于概念探测的最佳层。

> **ai_Abstract:** 本文提出了一种自动识别神经网络中用于概念探测的最佳层的方法。概念探测旨在通过训练分类器将模型内部表示映射到人类定义的概念，但其性能受探测层选择的影响。该方法基于表示对概念的信息性和规律性，并通过在不同模型和数据集上的实证分析进行了验证。

> **摘要翻译:** 概念探测最近作为一种人类窥探人工神经网络内部编码内容的方式而受到欢迎。在概念探测中，训练额外的分类器将模型的内部表示映射到人类感兴趣的定义概念中。然而，这些探测器的性能高度依赖于它们所探测的内部表示，这使得识别合适的探测层成为一项必不可少的任务。在本文中，我们提出了一种方法，可以根据表示对概念的信息性和规律性，自动识别神经网络模型中应考虑哪个层的表示来探测给定的人类定义概念。我们通过对不同神经网络模型和数据集的详尽实证分析来验证我们的发现。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [627] [Unsupervised Concept Drift Detection from Deep Learning Representations in Real-time](https://arxiv.org/abs/2406.17813)
> *基于深度学习表示的实时无监督概念漂移检测*

*Salvatore Greco, Bartolomeo Vacchetti, Daniele Apiletti, Tania Cerquitelli* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 无监督, 概念漂移检测, 深度学习表示, 实时, DriftLens

**Comment:** Accepted at IEEE Transactions on Knowledge and Data Engineering
  (TKDE)

> **TL;DR:** 本文提出了DriftLens，一个无监督框架，用于实时概念漂移检测和特征化，它在准确性、速度和可解释性方面优于现有方法。

**AI_Comments:** DriftLens的创新点在于它在无监督、实时、准确和可解释性之间取得了平衡，特别针对深度学习表示。其能够解释漂移对每个标签的影响，是现有方法中较少提及的亮点，增强了实用性。在速度和准确性上的提升，使其非常适用于大规模生产环境。

<details>
  <summary>Details</summary>

**Motivation:** 概念漂移导致模型性能下降，需要持续监控。现有的大多数漂移检测方法是监督的，不适用于真实世界中标签不可用的场景。虽然有无监督方法，但它们往往缺乏准确性，计算成本高昂，或无法有效解释漂移。

**Method:** 本文提出了DriftLens，一个用于实时无监督概念漂移检测和特征化的框架。它专为处理非结构化数据的深度学习分类器设计，利用深度学习表示中的分布距离来实现高效准确的检测。此外，DriftLens通过分析和解释漂移对每个标签的影响来表征漂移。

**Result:** DriftLens在15/17个用例中检测漂移方面优于现有方法；运行速度至少快5倍；产生的漂移曲线与实际漂移高度一致（相关性≥0.85）；并能有效识别代表性漂移样本作为解释。

**Conclusion:** DriftLens是一个在无监督、实时、准确和可解释性方面表现出色的概念漂移检测框架，特别适用于深度学习分类器处理非结构化数据。

> **ai_Abstract:** 本文提出了DriftLens，一个创新的无监督框架，旨在解决深度学习模型在实时生产环境中面临的概念漂移问题。针对现有无监督方法在准确性、计算效率和可解释性方面的不足，DriftLens利用深度学习表示中的分布距离进行高效准确的漂移检测，并能深入分析和解释漂移对不同标签的影响。实验结果表明，DriftLens在性能上显著超越了现有方法，并在速度和解释性方面也表现出色，为非结构化数据的深度学习分类器提供了强大的概念漂移监控能力。

> **摘要翻译:** 概念漂移是指目标域的底层数据分布和统计特性随时间变化，导致模型性能下降的现象。因此，生产模型需要持续的概念漂移检测监控。迄今为止，大多数漂移检测方法都是有监督的，依赖于真实标签。然而，在许多真实世界场景中，由于真实标签通常不可用，这些方法不适用。尽管最近的努力提出了无监督漂移检测器，但许多方法缺乏可靠检测所需的准确性，或者对于高维、大规模生产环境中的实时使用来说计算成本过高。此外，它们通常无法有效地表征或解释漂移。
为了解决这些局限性，我们提出了\textsc{DriftLens}，一个用于实时概念漂移检测和表征的无监督框架。\textsc{DriftLens}专为处理非结构化数据的深度学习分类器设计，利用深度学习表示中的分布距离来实现高效准确的检测。此外，它通过分析和解释漂移对每个标签的影响来表征漂移。我们对不同分类器和数据类型的评估表明，\textsc{DriftLens} (i) 在17个用例中的15个中检测漂移方面优于现有方法；(ii) 运行速度至少快5倍；(iii) 产生的漂移曲线与实际漂移高度一致（相关性≥0.85）；(iv) 有效识别代表性漂移样本作为解释。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [629] [GenSelect: A Generative Approach to Best-of-N](https://arxiv.org/abs/2507.17797)
> *GenSelect：一种生成式N选一方法*

*Shubham Toshniwal, Ivan Sorokin, Aleksander Ficek, Ivan Moshkov, Igor Gitman* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-23**

**Keywords:** GenSelect, 生成式奖励模型, 大型语言模型, 数学推理, N选一

**Comment:** Presented at the 2nd AI for MATH Workshop @ ICML

> **TL;DR:** GenSelect提出一种生成式方法，通过长推理让大型语言模型（LLM）从N个候选中选择最佳方案，解决了现有方法在可扩展性和利用LLM比较能力方面的不足，并在数学推理任务上表现优异。

**AI_Comments:** GenSelect的创新之处在于其“长推理N选一”的生成式方法，这巧妙地规避了点式和两两比较的局限性，并充分发挥了大型语言模型（LLM）的比较能力。该方法对于需要从多个候选中选择最佳答案的推理任务具有重要意义，尤其是在需要高效扩展的场景下。其简单提示即可超越现有方法的成果也表明了其潜在的广泛应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有生成式奖励模型在推理任务中，点式评分方法未能充分利用大型语言模型（LLM）的比较能力，而两两比较方法在采样预算较大时扩展效率低下。

**Method:** 本文引入了GenSelect方法，该方法让大型语言模型（LLM）使用长推理从N个候选方案中选择最佳方案。此方法旨在利用LLM的比较优势，同时在并行采样预算下实现高效扩展。

**Result:** 在数学推理任务上，QwQ和DeepSeek-R1-0528等推理模型在GenSelect中表现出色，通过简单的提示就优于现有的评分方法。

**Conclusion:** GenSelect通过利用大型语言模型（LLM）的长推理进行N选一，有效解决了现有方法的局限性，并在特定推理任务中展现出卓越的性能。

> **ai_Abstract:** GenSelect提出了一种新颖的生成式方法，旨在解决现有生成式奖励模型在推理任务中面临的挑战。针对点式评分未能充分利用大型语言模型（LLM）比较能力和两两比较方法扩展效率低下的问题，GenSelect允许LLM通过长推理直接从N个候选方案中选择最优解。这种方法不仅充分利用了LLM的比较优势，还在并行采样预算下实现了高效扩展。实验证明，在数学推理任务上，GenSelect显著优于现有评分方法。

> **摘要翻译:** 生成式奖励模型与并行采样相结合，已使推理任务的测试时扩展成为可能。当前方法采用对单个解决方案的点式评分或两两比较。然而，点式方法未能充分利用大型语言模型（LLM）的比较能力，而两两比较方法在采样预算较大时扩展效率低下。我们引入了GenSelect，其中LLM使用长推理从N个候选方案中选择最佳方案。这利用了LLM的比较优势，同时在并行采样预算下实现了高效扩展。对于数学推理，我们证明了QwQ和DeepSeek-R1-0528等推理模型在GenSelect中表现出色，通过简单的提示就优于现有的评分方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [643] [GLANCE: Graph Logic Attention Network with Cluster Enhancement for Heterophilous Graph Representation Learning](https://arxiv.org/abs/2507.18521)
> *GLANCE：用于异质图表示学习的图逻辑注意力网络与聚类增强*

*Zhongtian Sun, Anoushka Harit, Alexandra Cristea, Christl A. Donnelly, Pietro Liò* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 异质图, 图神经网络, 图表示学习, 逻辑推理, 聚类

**Comment:** 

> **TL;DR:** GLANCE通过结合逻辑推理、动态图细化和自适应聚类，解决了异质图上GNNs的局限性，实现了鲁棒且可解释的图表示学习。

**AI_Comments:** 该论文的创新点在于其GLANCE框架，它通过结合逻辑推理、动态图细化（边缘剪枝）和自适应聚类，有效解决了异质图表示学习中的核心挑战。特别是逻辑层的引入，旨在提供更可解释的结构化嵌入，这对于GNNs的黑箱特性是一个重要的改进。其轻量级和适应性强的特点也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图神经网络（GNNs）在异质图上表现不佳，因为它们对邻居的聚合不加区分，并且未能充分融合高阶结构模式。异质图指的是连接节点在特征或类别标签上存在差异的图。

**Method:** 提出了GLANCE（Graph Logic Attention Network with Cluster Enhancement）框架，它整合了逻辑引导推理、动态图细化和自适应聚类。具体包括：一个逻辑层，用于生成可解释的结构化嵌入；基于多头注意力的边缘剪枝，用于去噪图结构；以及聚类机制，用于捕获全局模式。

**Result:** 在Cornell、Texas和Wisconsin等基准数据集上的实验结果表明，GLANCE实现了具有竞争力的性能，为异质图场景提供了鲁棒且可解释的解决方案。

**Conclusion:** GLANCE是一个轻量级、适应性强且独特适用于异质图挑战的框架，能够有效解决异质图表示学习的难题，并提供可解释的解决方案。

> **ai_Abstract:** GLANCE是一个为异质图表示学习设计的新型框架，旨在解决传统GNN在处理异质图时存在的邻居聚合不当和高阶结构信息利用不足的问题。该框架通过结合逻辑层生成结构化嵌入，利用多头注意力进行边缘剪枝以去噪，并采用聚类机制捕获全局模式。实验证明，GLANCE在多个基准数据集上表现出色，为异质图提供了鲁棒且可解释的解决方案。

> **摘要翻译:** 图神经网络（GNNs）在从图结构数据中学习方面取得了显著成功，但在异质图上常常表现不佳，即连接节点在特征或类别标签上存在差异的图。这种局限性源于不加区分的邻居聚合和对高阶结构模式整合的不足。为了应对这些挑战，我们提出了GLANCE（图逻辑注意力网络与聚类增强），这是一个新颖的框架，它整合了逻辑引导推理、动态图细化和自适应聚类，以增强图表示学习。GLANCE结合了一个用于可解释和结构化嵌入的逻辑层、基于多头注意力的边缘剪枝用于去噪图结构，以及用于捕获全局模式的聚类机制。在Cornell、Texas和Wisconsin等基准数据集上的实验结果表明，GLANCE实现了具有竞争力的性能，为异质图场景提供了鲁棒且可解释的解决方案。所提出的框架是轻量级、适应性强且独特适用于异质图挑战的。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [652] [Unisoma: A Unified Transformer-based Solver for Multi-Solid Systems](https://arxiv.org/abs/2506.06021)
> *Unisoma：一个统一的基于Transformer的多固体系统求解器*

*Shilong Tao, Zhe Feng, Haonan Sun, Zhanxing Zhu, Yunhuai Liu* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 多固体系统, 显式建模, Transformer, 物理交互, 状态-of-the-art

**Comment:** Proceedings of the 42nd International Conference on Machine Learning

> **TL;DR:** Unisoma是一个基于Transformer的统一模型，采用显式建模范式，解决了多固体系统复杂交互的建模挑战，并在多个数据集上取得了最先进的性能。

**AI_Comments:** 本文的创新点在于提出了显式建模范式，并通过Unisoma模型成功应用于多固体系统。这种方法克服了传统隐式建模在处理复杂多固体交互时的局限性，通过直接捕获物理交互和防止信息混淆，显著提高了建模的准确性。其统一性和灵活性使其能够处理不同数量的固体，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 多固体系统在实际应用中非常普遍，但其复杂的相互作用建模仍然具有挑战性。现有的深度学习方法主要依赖隐式建模，当固体数量增加时，这些方法难以准确捕获复杂的物理相互作用。

**Method:** 本文提出了一种新颖的显式建模范式，通过结构化模块整合影响固体变形的因素。具体来说，我们提出了Unisoma，一个统一且灵活的基于Transformer的模型，能够处理可变数量的固体。Unisoma通过接触模块和自适应交互分配机制直接捕获物理交互，并通过三元组关系学习变形。

**Result:** Unisoma在七个成熟的数据集和两个复杂的多固体任务上都取得了持续的最先进性能。

**Conclusion:** 与隐式建模技术相比，显式建模更适合具有不同耦合模式的多固体系统，因为它能够对每个固体进行详细处理，同时防止信息混合和混淆。

> **ai_Abstract:** 本研究提出了一种名为Unisoma的统一Transformer模型，旨在解决多固体系统复杂交互的建模挑战。不同于现有深度学习方法的隐式建模，Unisoma采用显式建模范式，通过结构化模块明确表示影响固体变形的因素，并利用接触模块、自适应交互分配机制和三元组关系来捕获物理交互和学习变形。实验结果表明，Unisoma在多个基准数据集和任务上均达到了最先进的性能，证明了显式建模在处理多固体系统方面的优越性。

> **摘要翻译:** 多固体系统是广泛现实世界应用的基础，但建模其复杂的相互作用仍然具有挑战性。现有的深度学习方法主要依赖隐式建模，其中影响固体变形的因素没有被明确表示，而是间接地学习。然而，随着固体数量的增加，这些方法难以准确捕获复杂的物理相互作用。在本文中，我们引入了一种新颖的显式建模范式，通过结构化模块整合影响固体变形的因素。具体来说，我们提出了Unisoma，一个统一且灵活的基于Transformer的模型，能够处理可变数量的固体。Unisoma使用接触模块和自适应交互分配机制直接捕获物理交互，并通过三元组关系学习变形。与隐式建模技术相比，显式建模更适合具有不同耦合模式的多固体系统，因为它能够对每个固体进行详细处理，同时防止信息混合和混淆。实验上，Unisoma在七个成熟的数据集和两个复杂的多固体任务上都取得了持续的最先进性能。代码可在https://github.com/therontau0054/Unisoma 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [654] [C-AAE: Compressively Anonymizing Autoencoders for Privacy-Preserving Activity Recognition in Healthcare Sensor Streams](https://arxiv.org/abs/2507.18072)
> *C-AAE：用于医疗保健传感器流中隐私保护活动识别的压缩匿名化自编码器*

*Ryusei Fujimoto, Yugo Nakamura, Yutaka Arakawa* | **Category: cs.LG, cs.CR, eess.SP** | **Updated: 2025-07-24**

**Keywords:** 隐私保护, 活动识别, 自编码器, ADPCM, 医疗保健传感器

**Comment:** 

> **TL;DR:** C-AAE结合了匿名化自编码器和自适应差分脉冲编码调制，在医疗保健传感器数据中实现隐私保护的活动识别，同时显著降低了用户再识别率和数据量，且对活动识别性能影响较小。

**AI_Comments:** C-AAE的创新之处在于其将匿名化自编码器与压缩技术（ADPCM）相结合，实现了隐私保护和数据效率的双重优化。这对于需要处理大量敏感传感器数据的医疗保健应用具有重要意义，因为它提供了一个在实用性和隐私之间取得平衡的有效途径。其优势在于同时解决了身份隐私和数据传输存储开销的问题。

<details>
  <summary>Details</summary>

**Motivation:** 可穿戴传感器（如加速度计和陀螺仪）编码的精细行为特征可能被用于用户再识别，因此在医疗保健应用中，保护隐私至关重要。

**Method:** 本文引入了C-AAE，这是一种结合了匿名化自编码器（AAE）和自适应差分脉冲编码调制（ADPCM）的压缩匿名化自编码器。AAE首先将原始传感器窗口投影到一个潜在空间，该空间保留与活动相关的特征，同时抑制身份线索。然后，ADPCM对这个潜在流进行差分编码，进一步掩盖残余身份信息并缩小比特率。

**Result:** 在MotionSense和PAMAP2数据集上的实验表明，C-AAE相对于单独使用AAE，用户再识别F1分数降低了10-15个百分点，同时活动识别F1分数与未受保护的基线相比保持在5个百分点以内。ADPCM还将数据量减少了约75%，从而减轻了传输和存储开销。

**Conclusion:** C-AAE为在连续、基于传感器的医疗保健活动识别中平衡隐私和实用性提供了一条实用途径。

> **ai_Abstract:** C-AAE是一种新型的压缩匿名化自编码器，旨在解决医疗保健领域中可穿戴传感器数据带来的隐私泄露问题。它通过结合匿名化自编码器（AAE）和自适应差分脉冲编码调制（ADPCM），在保留活动识别能力的同时，有效抑制用户身份信息并大幅减少数据量。实验证明，C-AAE显著降低了用户再识别率，同时对活动识别性能影响甚微，并实现了75%的数据压缩，为传感器数据隐私保护提供了实用方案。

> **摘要翻译:** 可穿戴加速度计和陀螺仪编码了精细的行为特征，这些特征可能被利用来重新识别用户，使得隐私保护在医疗保健应用中变得至关重要。我们引入了C-AAE，这是一种结合了匿名化自编码器（AAE）和自适应差分脉冲编码调制（ADPCM）的压缩匿名化自编码器。AAE首先将原始传感器窗口投影到一个潜在空间，该空间保留与活动相关的特征，同时抑制身份线索。ADPCM然后对这个潜在流进行差分编码，进一步掩盖残余身份信息并缩小比特率。在MotionSense和PAMAP2数据集上的实验表明，C-AAE相对于单独使用AAE，用户再识别F1分数降低了10-15个百分点，同时活动识别F1分数与未受保护的基线相比保持在5个百分点以内。ADPCM还将数据量减少了约75%，从而减轻了传输和存储开销。这些结果表明，C-AAE为在连续、基于传感器的医疗保健活动识别中平衡隐私和实用性提供了一条实用途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [659] [ARBoids: Adaptive Residual Reinforcement Learning With Boids Model for Cooperative Multi-USV Target Defense](https://arxiv.org/abs/2502.18549)
> *ARBoids：基于Boids模型和自适应残差强化学习的合作多无人水面艇目标防御*

*Jiyue Tao, Tongsheng Shen, Dexin Zhao, Feitian Zhang* | **Category: cs.LG, cs.CR, cs.RO** | **Updated: 2025-07-10**

**Keywords:** ARBoids, 强化学习, Boids模型, 多无人水面艇, 目标防御

**Comment:** 

> **TL;DR:** ARBoids是一个结合Boids模型和深度强化学习的新框架，用于解决无人水面艇目标防御问题，尤其是在攻击者机动性更强的情况下，它表现出优于传统方法的性能和强大的适应性。

**AI_Comments:** 该论文的创新点在于将生物启发的Boids模型与深度强化学习相结合，形成一个自适应残差强化学习框架，有效解决了无人水面艇在面对高机动性攻击者时的防御难题。这种结合利用了Boids模型在多智能体协调上的计算高效性，并通过DRL学习残差策略进行优化，提升了系统的适应性和鲁棒性，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在无人水面艇（USV）目标防御问题中，当攻击者的机动性优于防御者时，有效拦截变得异常困难。为了解决这一挑战，本文提出了一个新的框架。

**Method:** 本文提出了ARBoids，一个新颖的自适应残差强化学习框架，它将深度强化学习（DRL）与受生物启发的基于力的Boids模型相结合。在该框架中，Boids模型作为多智能体协调的计算高效基线策略，而DRL学习一个残差策略以自适应地完善和优化防御者的行动。

**Result:** 该方法在高保真Gazebo仿真环境中进行了验证，表现出优于传统拦截策略（包括纯基于力的方法和香草DRL策略）的性能。此外，所学习的策略对具有不同机动性特征的攻击者表现出强大的适应性，突出了其鲁棒性和泛化能力。

**Conclusion:** ARBoids框架通过结合Boids模型和深度强化学习，有效解决了无人水面艇目标防御中攻击者机动性更强时的挑战，并展现了卓越的性能、鲁棒性和泛化能力。

> **ai_Abstract:** 本文提出了ARBoids，一个创新的自适应残差强化学习框架，旨在解决无人水面艇目标防御问题，尤其是在攻击者具有更高机动性的挑战性场景下。该框架将Boids模型作为多智能体协调的基线策略，并利用深度强化学习学习一个残差策略来优化防御者的动作。实验结果表明，ARBoids在高保真仿真环境中表现出优于传统拦截策略的性能，并且对不同机动性攻击者具有强大的适应性和泛化能力。

> **摘要翻译:** 无人水面艇（USV）的目标防御问题（TDP）涉及在一个或多个防御USV在敌方USV突破指定目标区域之前对其进行拦截。当攻击者的机动性优于防御者时，会出现一个特别具有挑战性的场景，这使得有效拦截变得异常复杂。为了解决这一挑战，本文引入了ARBoids，一个新颖的自适应残差强化学习框架，它将深度强化学习（DRL）与受生物启发的、基于力的Boids模型相结合。在该框架内，Boids模型作为多智能体协调的计算高效基线策略，而DRL学习一个残差策略以自适应地完善和优化防御者的行动。所提出的方法在高保真Gazebo仿真环境中得到了验证，证明其性能优于传统拦截策略，包括纯基于力的方法和香草DRL策略。此外，所学习的策略对具有不同机动性特征的攻击者表现出强大的适应性，突出了其鲁棒性和泛化能力。ARBoids的代码将在本文被接受后发布。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [670] [Wasserstein GAN-Based Precipitation Downscaling with Optimal Transport for Enhancing Perceptual Realism](https://arxiv.org/abs/2507.17798)
> *基于 Wasserstein GAN 的降水降尺度与最优传输，以增强感知真实感*

*Kenta Shiraishi, Yuka Muto, Atsushi Okazaki, Shunji Kotsuki* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** 降水降尺度, Wasserstein GAN, 最优传输, 感知真实感, 数据质量控制

**Comment:** 

> **TL;DR:** 本研究提出使用基于Wasserstein GAN和最优传输的降水降尺度方法，以生成视觉上更真实的降水场，并发现其判别器有助于评估和质控降水数据。

**AI_Comments:** 该论文的创新之处在于将 Wasserstein GAN 和最优传输应用于降水降尺度，以解决传统方法在视觉真实感方面的不足。其重要性在于不仅提升了降水预测的细节表现，还提出了利用 WGAN 判别器进行数据质量控制的新视角，这对于提高气象数据的可靠性具有潜在价值。尽管在传统量化指标上可能表现不佳，但其在感知真实感上的提升以及数据质控功能是其亮点。

<details>
  <summary>Details</summary>

**Motivation:** 高分辨率降水预测对于减少局部强降雨造成的损害至关重要，但使用过程驱动的数值天气预报模型进行高分辨率降水预报仍然具有挑战性。

**Method:** 本研究提出使用 Wasserstein 生成对抗网络 (WGAN) 进行降水降尺度，并结合最优传输成本。

**Result:** 与使用均方误差训练的传统神经网络相比，WGAN 生成了具有精细尺度结构的视觉真实降水场，尽管在传统评估指标上性能略低。WGAN 的判别器与人类感知真实感高度相关。基于案例的分析表明，判别器分数的大差异有助于识别不真实的 WGAN 输出以及参考数据中的潜在伪影。

**Conclusion:** WGAN 框架不仅改进了降水降尺度中的感知真实感，而且为评估和质量控制降水数据集提供了新的视角。

> **ai_Abstract:** 本研究旨在解决高分辨率降水预测的挑战，提出了一种基于 Wasserstein 生成对抗网络 (WGAN) 和最优传输的降水降尺度方法。与传统方法相比，WGAN 生成的降水场在视觉上更具真实感和精细结构，尽管在传统指标上略有不足。研究发现 WGAN 的判别器能很好地反映人类感知真实感，并且其分数差异可用于识别模型输出缺陷和参考数据伪影。这表明 WGAN 不仅提升了降水降尺度的真实感，也为降水数据集的评估和质量控制提供了新途径。

> **摘要翻译:** 高分辨率 (HR) 降水预测对于减少局部和局地性强降雨造成的损害至关重要；然而，使用过程驱动的数值天气预报模型进行高分辨率降水预报仍然具有挑战性。本研究提出使用 Wasserstein 生成对抗网络 (WGAN) 进行降水降尺度，并结合最优传输成本。与使用均方误差训练的传统神经网络相比，WGAN 生成了具有精细尺度结构的视觉真实降水场，尽管 WGAN 在传统评估指标上表现略低。WGAN 学习到的判别器与人类感知真实感高度相关。基于案例的分析表明，判别器分数的大差异有助于识别不真实的 WGAN 输出以及参考数据中的潜在伪影。这些发现表明，WGAN 框架不仅改进了降水降尺度中的感知真实感，而且为评估和质量控制降水数据集提供了新的视角。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [682] [Why Do Class-Dependent Evaluation Effects Occur with Time Series Feature Attributions? A Synthetic Data Investigation](https://arxiv.org/abs/2506.11790)
> *时间序列特征归因中为何会出现类别依赖的评估效应？一项合成数据调查*

*Gregor Baer, Isel Grau, Chao Zhang, Pieter Van Gorp* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 特征归因, 可解释人工智能, 时间序列, 评估, 类别依赖效应

**Comment:** Accepted at TempXAI Workshop @ ECML-PKDD 2025 (Explainable AI for
  Time Series and Data Streams)

> **TL;DR:** 时间序列特征归因的评估中存在类别依赖效应，并且基于扰动的评估指标与真实值指标可能不一致。

**AI_Comments:** 本研究揭示了XAI领域中特征归因评估的一个重要局限性，即评估指标存在类别依赖效应且基于扰动的指标可能不可靠。通过使用合成数据进行受控实验，该研究为理解这些效应的产生条件提供了有价值的见解，并强调了开发更稳健、多维度评估方法的必要性，对提升XAI的可信度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解释性AI（XAI）中特征归因方法的评估是一个关键挑战，特别是当现有评估指标显示出类别依赖效应时，这引发了对扰动分析能否可靠衡量归因质量的质疑。

**Method:** 通过使用已知真实特征位置的合成时间序列数据进行受控实验，系统地改变二元分类任务中的特征类型和类别对比度，并比较多种归因方法的基于扰动的降级分数与基于真实值的精确召回指标。

**Result:** 类别依赖效应在两种评估方法中都会出现，即使在简单场景中，也由特征振幅或时间范围的微小类别差异触发。最关键的是，基于扰动的评估指标与基于真实值的指标对归因质量的评估结果常常相互矛盾，且两者之间相关性较弱。

**Conclusion:** 研究人员应谨慎解释基于扰动的评估指标，因为它们可能无法始终与归因是否正确识别区分特征对齐。本研究表明需要重新思考归因评估的衡量标准，并开发更严格、能够捕捉多维度归因质量的评估方法。

> **ai_Abstract:** 本研究调查了时间序列特征归因评估中出现的“类别依赖评估效应”。通过对合成时间序列数据进行受控实验，比较了基于扰动的评估指标与基于真实值的指标。结果显示，类别依赖效应普遍存在，并且基于扰动的指标与真实值指标对归因质量的评估常相矛盾。这表明现有评估方法可能无法可靠衡量归因质量，亟需开发更严谨的评估方法。

> **摘要翻译:** 评估特征归因方法是可解释人工智能（XAI）中的一个关键挑战，因为在没有真实值的情况下，研究人员通常依赖基于扰动的指标。然而，最近的研究表明，这些评估指标在同一数据集的不同预测类别中可能表现出不同的性能。这些“类别依赖的评估效应”引发了关于扰动分析能否可靠衡量归因质量的疑问，直接影响了XAI方法的开发和评估的可靠性。我们通过对已知真实特征位置的合成时间序列数据进行受控实验，调查这些类别依赖效应在何种条件下产生。我们系统地改变二元分类任务中的特征类型和类别对比度，然后使用多种归因方法比较基于扰动的降级分数与基于真实值的精确召回指标。我们的实验表明，即使在具有时间局部特征的简单场景中，类别依赖效应也会在两种评估方法中出现，其产生的原因是类别之间特征振幅或时间范围的基本变化。最关键的是，我们发现基于扰动的指标和基于真实值的指标在不同类别上对归因质量的评估结果常常相互矛盾，并且两种评估方法之间的相关性很弱。这些发现表明，研究人员应谨慎解释基于扰动的指标，因为它们可能并非总是与归因是否正确识别区分特征相符。通过揭示这种脱节，我们的工作指出需要重新思考归因评估实际衡量的是什么，并开发更严格、能够捕捉归因质量多个维度的评估方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [685] [C2G-KD: PCA-Constrained Generator for Data-Free Knowledge Distillation](https://arxiv.org/abs/2507.18533)
> *C2G-KD：基于PCA约束生成器的数据无关知识蒸馏*

*Magnus Bengtsson, Kenneth Östberg* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 数据无关知识蒸馏, PCA, 生成器, 知识蒸馏, 合成样本

**Comment:** 12 pages

> **TL;DR:** C2G-KD是一种数据无关知识蒸馏框架，通过PCA约束的生成器合成样本，即使只有少量真实数据也能有效训练。

**AI_Comments:** C2G-KD的创新之处在于其将PCA几何约束引入数据无关知识蒸馏的生成器中，尤其是在极低数据量（每类仅两个样本）下仍能有效生成高质量合成样本。这对于数据隐私受限或数据稀缺的场景具有重要意义，提供了一种有效且高效的知识蒸馏方法。

<details>
  <summary>Details</summary>

**Motivation:** 在数据不可用的情况下，为数据无关知识蒸馏生成高质量的合成样本。

**Method:** 提出C2G-KD框架，训练一个类条件生成器，该生成器在冻结的教师模型和源自PCA的几何约束引导下生成合成样本。生成器通过语义和结构损失学习激活教师输出，并通过将生成的样本限制在从每类少量真实样本（低至两个）估计的类特定PCA子空间内，以保持拓扑一致性和多样性。

**Result:** 在MNIST上的实验表明，即使是最小的类结构也足以启动有用的合成训练管道。

**Conclusion:** C2G-KD框架通过结合PCA约束和生成器，即使在数据极度受限的情况下，也能有效地进行数据无关知识蒸馏，证明了少量几何约束对合成数据质量的重要性。

> **ai_Abstract:** C2G-KD是一个新颖的数据无关知识蒸馏框架。它利用一个受PCA几何约束的类条件生成器来合成训练样本，而无需访问真实数据。该生成器通过语义和结构损失学习激活教师模型，并通过将样本限制在从少量真实数据（每类低至两个）估计的类特定PCA子空间内，确保生成样本的拓扑一致性和多样性。实验证明，即使最小的类结构也足以支持有效的合成训练。

> **摘要翻译:** 我们引入了C2G-KD，一个数据无关知识蒸馏框架，其中训练一个类条件生成器，以在冻结的教师模型和源自PCA的几何约束的引导下生成合成样本。生成器从不观察真实的训练数据，而是通过语义和结构损失的组合来学习激活教师的输出。通过将生成的样本限制在从每类仅两个真实示例估计的类特定PCA子空间内，我们保留了拓扑一致性和多样性。在MNIST上的实验表明，即使是最小的类结构也足以启动有用的合成训练管道。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [696] [Squeeze10-LLM: Squeezing LLMs' Weights by 10 Times via a Staged Mixed-Precision Quantization Method](https://arxiv.org/abs/2507.18073)
> *Squeeze10-LLM：通过分阶段混合精度量化方法将LLM权重压缩10倍*

*Qingcheng Zhu, Yangyang Ren, Linlin Yang, Mingbao Lin, Yanjing Li, Sheng Xu, Zichao Feng, Haodong Zhu, Yuguang Yang, Juan Zhang, Runqi Wang, Baochang Zhang* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 量化, 后训练量化, 混合精度, 超低比特

**Comment:** 

> **TL;DR:** Squeeze10-LLM通过分阶段混合精度量化将LLM权重压缩10倍（平均1.6比特），并引入PBAR和FIAS两种创新方法，显著提高了低比特量化下的精度。

**AI_Comments:** Squeeze10-LLM的创新之处在于其分阶段混合精度量化策略，特别是引入了PBAR和FIAS这两种新颖机制，有效解决了超低比特量化中精度严重下降的挑战。它在保持高压缩率的同时显著提升了模型性能，对于LLM在资源受限设备上的部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 部署大型语言模型（LLMs）面临参数量巨大和计算成本高昂的挑战。超低比特量化虽能显著减少存储并加速推理，但极端压缩（平均比特位宽≤2）常导致严重的性能下降。

**Method:** 提出Squeeze10-LLM，一个分阶段混合精度后训练量化（PTQ）框架，通过将80%的权重量化为1比特、20%量化为4比特，实现平均每权重1.6比特，将16比特LLM权重压缩10倍。引入了两项关键创新：后二值化激活鲁棒性（PBAR）和全信息激活监督（FIAS）。PBAR是一种改进的权重显著性度量，考虑了量化对激活的影响，以提高低比特设置下的精度。FIAS是一种在量化过程中保留完整激活信息以减轻跨层累积误差传播的策略。

**Result:** 在LLaMA和LLaMA2上的实验表明，Squeeze10-LLM在亚2比特仅权重（weight-only）量化方面实现了最先进的性能，在六个零样本分类任务上的平均精度从43%提高到56%，比现有PTQ方法有了显著提升。

**Conclusion:** Squeeze10-LLM通过其创新的分阶段混合精度量化方法和特定的技术（PBAR、FIAS），成功解决了LLM超低比特量化中的性能下降问题，并在精度上超越了现有方法，实现了高效的LLM部署。

> **ai_Abstract:** 本文提出了Squeeze10-LLM，一个分阶段混合精度后训练量化框架，旨在将大型语言模型（LLM）的权重压缩10倍，同时缓解超低比特量化导致的性能下降。Squeeze10-LLM通过将80%的权重量化为1比特、20%量化为4比特，实现了平均每权重1.6比特。该方法引入了后二值化激活鲁棒性（PBAR）和全信息激活监督（FIAS）两项关键创新，分别用于提高低比特设置下的精度和减轻累积误差传播。实验结果表明，Squeeze10-LLM在亚2比特仅权重（weight-only）量化方面达到了最先进的性能，显著提升了LLaMA和LLaMA2在零样本分类任务上的平均精度。

> **摘要翻译:** 标题：Squeeze10-LLM：通过分阶段混合精度量化方法将LLM权重压缩10倍
摘要：由于参数庞大和计算成本高昂，部署大型语言模型（LLM）极具挑战性。超低比特量化可以显著减少存储并加速推理，但极端压缩（即平均比特位宽≤2）通常会导致严重的性能下降。为了解决这个问题，我们提出了Squeeze10-LLM，有效地将16比特LLM的权重“压缩”10倍。具体来说，Squeeze10-LLM是一个分阶段混合精度后训练量化（PTQ）框架，通过将80%的权重量化为1比特，20%量化为4比特，实现了平均每权重1.6比特。我们引入Squeeze10LLM，其中包含两项关键创新：后二值化激活鲁棒性（PBAR）和全信息激活监督（FIAS）。PBAR是一种改进的权重显著性度量，它考虑了量化对激活的影响，从而提高了低比特设置下的精度。FIAS是一种在量化过程中保留完整激活信息以减轻跨层累积误差传播的策略。在LLaMA和LLaMA2上的实验表明，Squeeze10-LLM在亚2比特仅权重（weight-only）量化方面取得了最先进的性能，在六个零样本分类任务上的平均精度从43%提高到56%——这比现有PTQ方法有了显著提升。我们的代码将在发表时发布。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [712] [Multi-Preference Lambda-weighted Listwise DPO for Small-Scale Model Alignment](https://arxiv.org/abs/2506.19780)
> *用于小规模模型对齐的多偏好Lambda加权列表式DPO*

*Yuhui Sun, Xiyao Wang, Zixi Li, Zhenlong Yuan, Jinman Zhao* | **Category: cs.LG, I.2.6; I.2.7; I.5.1** | **Updated: 2025-07-24**

**Keywords:** 多偏好DPO, 模型对齐, Lambda加权, 列表式偏好, 小规模模型

**Comment:** 12 pages, 12 figures, appendix included. To appear in Proceedings of
  AAAI 2026. Code:
  https://github.com/yuhui15/Multi-Preference-Lambda-weighted-DPO

> **TL;DR:** 本文提出了一种名为多偏好Lambda加权列表式DPO的新方法，通过允许模型从更详细的人类反馈中学习并灵活平衡多个目标，解决了传统DPO在处理多维度偏好和列表式监督方面的局限性，同时显著降低了计算成本。

**AI_Comments:** 该论文的创新点在于提出了多偏好Lambda加权列表式DPO，解决了传统DPO在处理多目标和列表式偏好方面的局限性。通过引入Lambda向量和全排序偏好分布，模型能够从更丰富的人类反馈中学习，并实现对齐行为的精细控制，这是对现有对齐方法的重要改进。其低内存需求（20GB GPU）使其在计算资源有限的学术界和小型机构中具有很高的实用价值和部署潜力。这对于推动LLM在实际场景中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型(LLMs)的输出常与人类偏好不一致。现有的RLHF方法计算成本高且不稳定，而DPO虽简化了过程，但假定固定、单维偏好且仅支持二元监督，无法处理多目标或更详细的人类反馈。

**Method:** 提出多偏好Lambda加权列表式DPO (Multi-Preference Lambda-weighted Listwise DPO)。该方法通过建模全排序偏好分布而非二元比较，提供更丰富的学习信号。引入Lambda向量控制不同对齐目标的相对重要性，允许模型在推理时无需重新训练即可调整Lambda，实现可控的对齐行为。此外，还引入了学习型调度器动态采样高性能的Lambda配置以提高鲁棒性。

**Result:** 实验表明，在1B-2B规模模型上，该方法在对齐基准测试中持续优于标准DPO。它仅需20GB GPU内存进行训练，适用于计算受限环境，并能实现高效、可控、细粒度的适应性，适用于实际部署。

**Conclusion:** 多偏好Lambda加权列表式DPO通过解决现有DPO的局限性，为LLMs提供了更高效、灵活且可控的对齐方法，尤其适用于资源受限的场景，并在实际部署中表现出优越性能。

> **ai_Abstract:** 本文提出了一种名为多偏好Lambda加权列表式DPO的新方法，旨在解决大型语言模型与人类偏好不一致的问题。针对现有RLHF计算成本高和DPO仅支持二元、单维偏好的局限性，该方法通过建模全排序偏好分布和引入Lambda向量来平衡多个对齐目标（如有用性、诚实性、流畅性），从而学习更详细的人类反馈。该方法在推理时可调整Lambda以实现可控对齐，并引入学习型调度器提高鲁棒性。实验证明，该方法在小规模模型上表现优于标准DPO，且仅需20GB GPU内存，适用于资源受限环境。

> **摘要翻译:** 大型语言模型（LLMs）在广泛的语言任务中表现出强大的泛化能力，但其生成输出常常与人类偏好不符。人类反馈强化学习（RLHF）通过使用学习到的奖励函数和强化学习来优化模型以符合人类偏好，从而改善了对齐，但存在计算成本高和不稳定性问题。直接偏好优化（DPO）通过将对齐视为二元偏好对的分类任务来简化过程，在降低训练开销的同时实现了具有竞争力的性能。然而，它假设固定的、单维的偏好，并且只支持成对监督。
为了解决这些局限性，我们提出了多偏好Lambda加权列表式DPO，它允许模型从更详细的人类反馈中学习，并灵活平衡多个目标，如有用性、诚实性和流畅性。我们的方法建模全排序偏好分布而非二元比较，从而实现更具信息量的学习信号。Lambda向量控制不同对齐目标的相对重要性，允许模型在推理时无需重新训练即可在多样化的人类目标之间进行泛化，提供可控的对齐行为以用于下游使用。我们还引入了一个学习型调度器，动态采样高性能的Lambda配置以提高鲁棒性。
值得注意的是，我们的方法仅需20GB的GPU内存进行训练，使其适用于计算受限的环境，如学术实验室、教育工具或设备上的助手。在1B-2B规模模型上的实验表明，我们的方法在对齐基准测试中持续优于标准DPO，同时实现了高效、可控且细粒度的适应性，适用于实际部署。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [713] [Explainable Graph Neural Networks via Structural Externalities](https://arxiv.org/abs/2507.17848)
> *可解释图神经网络：基于结构外部性*

*Lijun Wu, Dong Hao, Zhiyi Fan* | **Category: cs.LG, cs.AI, cs.GT, econ.GN, q-fin.EC** | **Updated: 2025-07-19**

**Keywords:** 图神经网络, 可解释性, 合作博弈论, Shapley值, 结构外部性

**Comment:** 

> **TL;DR:** 提出GraphEXT框架，利用合作博弈论和结构外部性，通过量化节点对GNN预测的边际贡献来解释GNN，且在实验中表现优于现有方法。

**AI_Comments:** 本文创新性地将合作博弈论中的外部性概念引入GNN可解释性，通过关注节点间的结构交互而非仅仅节点属性，克服了现有方法的局限性。其提出的GraphEXT框架为理解GNN的决策过程提供了新的视角，对于GNN的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNNs）性能出色但“黑箱”性质使其可解释性面临挑战，现有方法未能有效捕捉节点间复杂的交互模式。

**Method:** 本文提出GraphEXT框架，该框架利用合作博弈论和社会外部性概念。GraphEXT将图节点划分为联盟，将原始图分解为独立的子图。通过将图结构作为外部性并结合外部性下的Shapley值，GraphEXT通过节点在联盟之间转换时对GNN预测的边际贡献来量化节点重要性。与传统基于Shapley值的方法不同，GraphEXT更侧重于节点之间的交互以及结构变化对GNN预测的影响。

**Result:** 在合成和真实数据集上的实验研究表明，GraphEXT在各种GNN架构下的保真度方面优于现有基线方法。

**Conclusion:** GraphEXT显著增强了GNN模型的可解释性，尤其通过关注节点交互和结构变化的影响，克服了现有方法的局限性。

> **ai_Abstract:** 本文提出GraphEXT，一个基于合作博弈论和结构外部性的GNN可解释性框架。它通过将图节点划分为联盟，并利用外部性下的Shapley值量化节点在结构变化下对GNN预测的边际贡献来解释GNN。与现有方法不同，GraphEXT更强调节点交互和结构影响。实验证明，GraphEXT在保真度方面优于现有基线，显著提升了GNN的可解释性。

> **摘要翻译:** 图神经网络（GNNs）在广泛的图相关任务中取得了卓越的性能。然而，它们的“黑箱”性质对其可解释性提出了重大挑战，并且现有方法往往未能有效捕捉网络中节点间复杂的交互模式。在这项工作中，我们提出了一种新颖的可解释性框架GraphEXT，它利用合作博弈论和社会外部性概念。GraphEXT将图节点划分为联盟，将原始图分解为独立的子图。通过将图结构作为外部性并结合外部性下的Shapley值，GraphEXT通过节点在联盟之间转换时对GNN预测的边际贡献来量化节点重要性。与主要关注节点属性的传统基于Shapley值的方法不同，我们的GraphEXT更侧重于节点之间的交互以及结构变化对GNN预测的影响。在合成和真实数据集上的实验研究表明，GraphEXT在各种GNN架构下的保真度方面优于现有基线方法，显著增强了GNN模型的可解释性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [723] [On Leveraging Unlabeled Data for Concurrent Positive-Unlabeled Classification and Robust Generation](https://arxiv.org/abs/2006.07841)
> *利用未标记数据进行并发正-未标记分类和鲁棒生成*

*Bing Yu, Ke Sun, He Wang, Zhouchen Lin, Zhanxing Zhu* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-24**

**Keywords:** 正-未标记分类, 条件生成, 未标记数据, 噪声鲁棒性, CNI-CGAN

**Comment:** Published in International Conference on Image and Graphics (ICIG),
  2025

> **TL;DR:** 本文提出一个新颖的框架，通过一个鲁棒的条件GAN辅助正-未标记分类，并利用分类器预测的标签增强生成，从而同时解决数据稀缺问题。

**AI_Comments:** 该论文的创新点在于同时解决了正-未标记分类和鲁棒生成这两个挑战性问题，并巧妙地利用两者之间的协同作用。特别是在面对数据稀缺和分布外未标记数据时，其提出的CNI-CGAN对噪声标签的鲁棒性以及利用预测标签辅助生成的设计，为有效利用大量未标记数据提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习中类标签数据稀缺是一个普遍的瓶颈，而大量的未标记数据虽可提供潜在解决方案，但很难利用。

**Method:** 提出一个新颖的训练框架，同时针对PU分类和条件生成，通过探索两者之间的相互作用，利用额外的未标记数据（尤其是分布外数据）。具体方法包括：1) 借助新型分类器噪声不变条件GAN（CNI-CGAN）提高PU分类器性能，该GAN对噪声标签具有鲁棒性；2) 利用PU分类器预测的标签辅助生成。

**Result:** 理论上证明了CNI-CGAN的最优条件，并在多样数据集上进行了广泛的实验评估。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文旨在解决机器学习中类标签数据稀缺的问题，通过同时利用正-未标记（PU）分类和条件生成，并结合额外的未标记数据。作者提出了一个新颖的训练框架，该框架通过引入一个对噪声标签鲁棒的分类器噪声不变条件GAN（CNI-CGAN）来增强PU分类器性能，并利用PU分类器预测的标签来辅助生成。该方法在理论上证明了CNI-CGAN的最优条件，并在多样数据集上进行了广泛的实验验证。

> **摘要翻译:** 类标签数据的稀缺是许多机器学习问题中普遍存在的瓶颈。尽管通常存在大量的未标记数据并提供潜在的解决方案，但利用它们极具挑战性。在本文中，我们通过同时利用正-未标记（PU）分类和条件生成以及额外的未标记数据来解决这个问题。我们提出了一个新颖的训练框架，通过探索它们之间的相互作用，在暴露于额外数据，特别是分布外未标记数据时，同时针对PU分类和条件生成：1）借助一种对噪声标签具有鲁棒性的新型分类器噪声不变条件GAN（CNI-CGAN）来提高PU分类器的性能；2）利用PU分类器预测的标签来帮助生成。在理论上，我们证明了CNI-CGAN的最优条件，并在实验上，我们对不同数据集进行了广泛的评估。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [729] [The Price equation reveals a universal force-metric-bias law of algorithmic learning and natural selection](https://arxiv.org/abs/2507.18549)
> *价格方程揭示了算法学习和自然选择的普适力-度量-偏差定律*

*Steven A. Frank* | **Category: cs.LG, q-bio.PE** | **Updated: 2025-07-24**

**Keywords:** 价格方程, 力-度量-偏差定律, 算法学习, 自然选择, 统一框架

**Comment:** 

> **TL;DR:** 价格方程揭示了一个普适的力-度量-偏差（FMB）定律，统一了多种学习算法、优化方法和自然选择。

**AI_Comments:** 这篇论文的创新点在于利用价格方程揭示了看似不相关的领域（如自然选择和机器学习）之间深层次的数学统一性。FMB定律提供了一个强大的理论框架，有助于跨学科地理解和设计算法，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管各种学习算法、优化方法和自然选择表面上存在差异，但它们共享一个共同的数学结构，作者旨在揭示并利用这一结构。

**Method:** 作者通过价格方程对变化进行简单的符号划分，揭示了一个普适的力-度量-偏差（FMB）定律：$\Delta\mathbf{\theta} = \mathbf{M}\,\mathbf{f} + \mathbf{b} + \mathbf{\xi}$。该定律将力、度量、偏差和噪声分量化，并用此框架统一了各种算法。

**Result:** FMB定律统一了自然选择、贝叶斯更新、牛顿法、随机梯度下降、随机朗之万动力学、Adam优化等大多数算法作为同一基础过程的特例。价格方程还揭示了费雪信息、Kullback-Leibler散度和达朗贝尔原理为何在学习动力学中自然产生。

**Conclusion:** FMB定律通过揭示这种共同结构，为跨学科理解、比较和设计学习算法提供了一个有原则的基础。

> **ai_Abstract:** 本文提出，通过价格方程对变化进行划分，可以揭示一个普适的力-度量-偏差（FMB）定律，该定律将自然选择、各种学习算法和优化方法统一为同一基本过程的特例。FMB定律解释了这些看似不同的系统如何共享共同的数学结构，并阐明了费雪信息等重要概念的自然起源，为理解和设计跨学科学习算法提供了统一的理论基础。

> **摘要翻译:** 尽管各种学习算法、优化方法和自然选择表面上存在差异，但它们共享一个共同的数学结构。本文展示了通过价格方程对变化进行简单的符号划分，可以揭示一个普适的力-度量-偏差（FMB）定律：$\Delta\mathbf{\theta} = \mathbf{M}\,\mathbf{f} + \mathbf{b} + \mathbf{\xi}$。其中，力 $\mathbf{f}$ 通过参数与性能之间的协方差驱动参数 $\Delta\mathbf{\theta}$ 的改进。度量 $\mathbf{M}$ 通过逆曲率重新调整运动。偏差 $\mathbf{b}$ 增加动量或改变参照系。噪声 $\mathbf{\xi}$ 促进探索。这个框架将自然选择、贝叶斯更新、牛顿法、随机梯度下降、随机朗之万动力学、Adam 优化以及大多数其他算法统一为同一基础过程的特例。价格方程还揭示了费雪信息、Kullback-Leibler 散度和达朗贝尔原理为何在学习动力学中自然产生。通过揭示这种共同结构，FMB 定律为跨学科理解、比较和设计学习算法提供了有原则的基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [730] [Task Priors: Enhancing Model Evaluation by Considering the Entire Space of Downstream Tasks](https://arxiv.org/abs/2507.09871)
> *任务先验：通过考虑下游任务的整个空间来增强模型评估*

*Niket Patel, Randall Balestriero* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 任务先验, 模型评估, 下游任务, 自监督学习, 概率空间

**Comment:** 

> **TL;DR:** 本文提出了一种新的模型评估方法，即“任务先验”，通过定义下游任务的概率空间来克服当前评估方法对固定基准的依赖，从而评估模型在所有可能任务上的表现。

**AI_Comments:** 本文提出了一种新颖且重要的模型评估范式，即“任务先验”，其创新点在于将评估范围从固定的、有限的基准扩展到所有可能的下游任务的概率空间。这直接解决了现有评估协议可能造成的“隐性瓶颈”，尤其对于自监督学习这类强调通用能力的模型至关重要。通过量化模型在整个任务空间中的平均表现和方差，该方法为模型性能提供了更鲁棒和全面的洞察，有望加速AI，特别是SSL领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 当前AI研究（特别是自监督学习SSL）的评估方法依赖于固定、手工挑选的下游基准，这被认为是一个“隐性瓶颈”。AI的宏伟目标是生产能成功解决任何可能任务的系统，而现有评估协议无法充分反映这一目标。

**Method:** 通过采用任务分布和定义“任务先验”，本文定义了一个下游任务的概率空间。在此视角下，模型性能可以在所有可能的下游任务集合上进行评估。

**Result:** 该框架首次提供了关键问题的答案，例如模型在所有可能下游任务上的平均性能（按遇到每个任务的概率加权）以及模型性能在所有下游任务上的方差（在定义的任务先验下）。

**Conclusion:** “任务先验”为评估建立了一个新标准，并有望加速自监督学习（SSL）的研究步伐，因为在SSL中，下游任务评估是研究人员可获得的唯一定性信号。

> **ai_Abstract:** 本文提出“任务先验”框架，旨在解决当前AI模型评估中依赖固定下游任务基准的局限性。通过定义一个包含任务分布和任务先验的概率空间，该方法能够评估模型在所有可能下游任务上的平均性能和性能方差，从而提供更全面、更接近AI最终目标的评估方式。这不仅为评估建立了新标准，也预期能加速自监督学习等领域的研究进展。

> **摘要翻译:** 人工智能研究，特别是自监督学习（SSL）的宏伟目标是生产能够成功解决任何可能任务的系统。相比之下，当前人工智能研究人员可用的评估方法通常依赖于一系列固定的、手工挑选的下游基准。因此，大量精力投入到设计和寻找大量的评估任务，以作为我们宏伟目标的替代。我们认为，这种僵化的评估协议在人工智能研究中造成了一个隐性瓶颈。为了弥补这一点，我们通过采用任务分布和定义“任务先验”来定义一个下游任务的概率空间。在这种观点下，可以评估模型在所有可能的下游任务集合上的性能。我们的框架首次为关键问题提供了答案，例如（i）我的模型在所有可能下游任务上的平均性能如何（按遇到每个任务的概率加权）？或（ii）在定义的“任务先验”下，我的模型在所有下游任务上的性能方差是多少？除了为评估建立新标准之外，我们相信“任务先验”将加速SSL的研究步伐——在SSL中，下游任务评估是研究人员可获得的唯一定性信号。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [735] [Learning from Hard Labels with Additional Supervision on Non-Hard-Labeled Classes](https://arxiv.org/abs/2507.18098)
> *从硬标签学习，并在非硬标签类别上进行额外监督*

*Kosuke Sugiyama, Masato Uchida* | **Category: cs.LG, 68T01, I.5** | **Updated: 2025-07-24**

**Keywords:** 硬标签学习, 额外监督, 软标签, 泛化误差, 分类

**Comment:** 32 pages, 11 figures

> **TL;DR:** 在训练数据有限的场景中，本论文提出一个理论框架，利用非硬标签类别的额外监督信息来优化软标签，从而提高分类准确率，并从理论和实验上验证了其有效性。

**AI_Comments:** 该论文的创新点在于提出了一个将硬标签和额外监督结合的理论框架，并深入分析了额外监督中真正有益的部分（非硬标签类别分布信息）。它为在数据稀缺场景下有效利用额外信息提供了理论基础和指导，对于提高分类模型性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在训练数据有限的情况下，如何利用除硬标签之外的额外监督信息来构建高精度分类模型，以及哪种额外监督本质上有益且如何提高泛化性能。

**Method:** 提出一个理论框架，将硬标签和额外监督都视为概率分布，并通过它们的仿射组合构建软标签。通过泛化误差分析，理论上描述了额外监督及其混合系数如何影响误差界的收敛速度和渐近值。

**Result:** 理论分析表明，额外监督的关键组成部分是非硬标签类别上的分布信息，而非硬标签的置信度。额外监督和混合系数在软标签的细化中发挥互补作用。实验证明，基于该理论设计的额外监督即使以简单方式使用也能提高分类准确率。

**Conclusion:** 根据所提出的理论设计额外监督可以有效提高分类准确率。

> **ai_Abstract:** 本论文针对训练数据有限场景下的分类问题，提出了一种利用硬标签和额外监督（特别是关于非硬标签类别分布的信息）来构建软标签的理论框架。研究发现，额外监督的关键在于非硬标签类别的分布信息，而非硬标签的置信度。通过泛化误差分析，论文详细阐述了额外监督及其混合系数如何协同作用以优化软标签，并影响模型的收敛速度和误差界。实验结果验证了所提理论指导下额外监督能有效提升分类精度。

> **摘要翻译:** 在由于观测成本或数据稀缺导致训练数据有限的场景中，丰富每个实例的标签信息对于构建高精度分类模型至关重要。在这种情况下，通常不仅可以获得硬标签，还可以获得“额外监督”，例如硬标签的置信度。这种设置自然引发了基本问题：哪些额外监督本质上有益？以及它们如何有助于提高泛化性能？为了解决这些问题，我们提出了一个理论框架，将硬标签和额外监督都视为概率分布，并通过它们的仿射组合构建软标签。我们的理论分析表明，额外监督的关键组成部分不是指定硬标签的置信度分数，而是非硬标签类别上的分布信息。此外，我们证明了额外监督和混合系数在软标签的细化中发挥着互补作用。直观地，在概率单纯形中，额外监督决定了代表硬标签的确定性分布应向真实标签分布调整的方向，而混合系数控制着沿该方向的步长。通过泛化误差分析，我们从理论上描述了额外监督及其混合系数如何影响误差界的收敛速度和渐近值。最后，我们通过实验证明，基于我们的理论，即使以简单的方式使用，设计额外监督也能提高分类准确率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [749] [Look the Other Way: Designing 'Positive' Molecules with Negative Data via Task Arithmetic](https://arxiv.org/abs/2507.17876)
> *反其道而行之：通过任务算术利用负面数据设计“积极”分子*

*Rıza Özçelik, Sarah de Ruiter, Francesca Grisoni* | **Category: cs.LG, physics.chem-ph, q-bio.BM** | **Updated: 2025-07-23**

**Keywords:** 分子设计, 任务算术, 负面数据, 零样本学习, 迁移学习

**Comment:** 

> **TL;DR:** 该研究提出了一种分子任务算术方法，利用丰富的负面数据学习“属性方向”，并反向生成具有期望性质的“积极”分子，在零样本和少量样本设计任务中表现出更好的多样性和成功率。

**AI_Comments:** 该论文提出了一种新颖且反直觉的方法来解决生成式分子设计中的数据稀缺问题，即通过学习“负面”数据的属性方向来生成“正面”分子。这种“反其道而行之”的思路具有创新性，并且在实际应用中展现出良好的效果，特别是在零样本和少量样本场景下，这对于药物发现和材料科学等领域具有重要意义。其数据效率和简单性是其主要优势。

<details>
  <summary>Details</summary>

**Motivation:** 具有期望性质的分子（即“积极”分子）的稀缺性是生成式分子设计的固有瓶颈。

**Method:** 提出了一种分子任务算术方法：在多样且丰富的负面示例上训练模型，以学习“属性方向”，然后反向移动模型以生成积极分子，而无需访问任何正向标记数据。

**Result:** 在20个零样本设计实验中，分子任务算术生成了比在积极分子上训练的模型更多样化和更成功的设计。此外，在双目标和少量样本设计任务中，分子任务算术能够持续增加设计的多样性，同时保持期望的设计属性。

**Conclusion:** 分子任务算术凭借其简单性、数据效率和性能，有潜力成为从头开始分子设计的实际迁移学习策略。

> **ai_Abstract:** 本论文提出了一种名为分子任务算术的新方法，旨在解决生成式分子设计中积极分子数据稀缺的问题。该方法通过在大量负面示例上训练模型来学习“属性方向”，然后反向利用这些方向来生成具有期望性质的分子，而无需任何正向标记数据。实验结果表明，在零样本和少量样本设计任务中，分子任务算术相比传统方法能生成更多样化且更成功的设计，同时保持期望的属性。该方法因其简单、高效和高性能，有望成为从头开始分子设计的标准迁移学习策略。

> **摘要翻译:** 具有期望性质的分子（即“积极”分子）的稀缺性是生成式分子设计的固有瓶颈。为了规避这一障碍，我们在此提出了分子任务算术：在多样且丰富的负面示例上训练模型以学习“属性方向”——无需访问任何正向标记数据——并反向移动模型以生成积极分子。在20个零样本设计实验中进行分析时，分子任务算术生成了比在积极分子上训练的模型更多样化和更成功的设计。此外，我们还将分子任务算术应用于双目标和少量样本设计任务。我们发现分子任务算术可以持续增加设计的 다양성，同时保持期望的设计属性。凭借其简单性、数据效率和性能，分子任务算术有潜力成为从头开始分子设计的实际迁移学习策略。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [752] [LeanKAN: A Parameter-Lean Kolmogorov-Arnold Network Layer with Improved Memory Efficiency and Convergence Behavior](https://arxiv.org/abs/2502.17844)
> *LeanKAN：一种参数精简的科尔莫哥洛夫-阿诺德网络层，具有改进的内存效率和收敛行为*

*Benjamin C. Koenig, Suyong Kim, Sili Deng* | **Category: cs.LG, cs.NE** | **Updated: 2025-07-24**

**Keywords:** Kolmogorov-Arnold Network, KAN, LeanKAN, MultKAN, 参数效率

**Comment:** 21 pages, 7 figures, and 4 tables. Updated after acceptance to
  journal

> **TL;DR:** LeanKAN 是一种新的 KAN 层，解决了 MultKAN 的缺点，如参数臃肿和超参数复杂性，提高了内存效率、收敛性并优于 MultKAN。

**AI_Comments:** LeanKAN 的创新之处在于它在保持甚至超越现有 KAN 性能的同时，显著降低了模型的复杂性和资源消耗。通过精简参数和简化超参数，它使得 KAN 更易于应用和扩展，特别是在资源受限的环境下或需要将 KAN 集成到更复杂的架构（如 KAN-ODEs）中时。这对于 KAN 的实际推广和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 最近提出的 MultKAN 层存在关键缺陷，包括在输出层适用性有限、参数臃肿、包含多余激活以及复杂的超参数。

**Method:** 本文提出了 LeanKAN，作为 MultKAN 和传统 AddKAN 层的直接模块化替代品。LeanKAN 通过在输出层具有通用适用性、显著减少给定网络结构的参数数量以及更小的超参数集来解决 MultKAN 的缺点。

**Result:** 在标准 KAN 玩具问题以及通过 KAN-ODE 学习的常微分方程和偏微分方程的演示中，LeanKAN 的稀疏参数化和紧凑结构增加了其表达能力和学习能力，在各种任务中表现优于相似甚至更大的 MultKAN。

**Conclusion:** LeanKAN 是一种有效的 KAN 层替代品，它通过精简参数和简化结构，提高了性能和效率，克服了现有 KAN 变体的局限性。

> **ai_Abstract:** 本论文介绍了 LeanKAN，一种改进的科尔莫哥洛夫-阿诺德网络（KAN）层，旨在解决现有 MultKAN 的局限性，例如参数冗余、复杂超参数和输出层适用性差。LeanKAN 作为 MultKAN 和 AddKAN 的直接替代品，显著减少了参数数量，简化了超参数，并在输出层具有通用性。实验表明，LeanKAN 的精简结构和稀疏参数化提高了表达能力和学习效率，在各种任务中性能优于 MultKAN，尤其是在 KAN-ODE 等增强型 KAN 应用中。

> **摘要翻译:** 最近提出的科尔莫哥洛夫-阿诺德网络（KAN）是多层感知器（MLP）在数据驱动建模方面的一个有前景的替代方案。虽然最初的 KAN 层只能表示加法运算符，但最近提出的 MultKAN 层结合了加法和乘法子节点，以期提高表示性能。在此，我们发现 MultKAN 层存在一些关键缺点，包括在输出层适用性有限、参数化臃肿包含多余激活以及包含复杂的超参数。为了解决这些问题，我们提出了 LeanKAN，它是 MultKAN 和传统 AddKAN 层的直接模块化替代品。LeanKAN 通过在输出层具有通用适用性、显著减少给定网络结构的参数数量以及更小的超参数集来解决 MultKAN 的这三个缺点。作为标准 AddKAN 和 MultKAN 层的一对一替换，LeanKAN 能够为传统的 KAN 学习问题以及作为其骨干的增强型 KAN 结构（例如 KAN 常微分方程（KAN-ODE）或深度算子 KAN（DeepOKAN））提供这些优势。我们在一系列演示中展示了 LeanKAN 的简洁性和效率，这些演示涵盖了标准 KAN 玩具问题以及通过 KAN-ODE 学习的常微分方程和偏微分方程，我们发现其更稀疏的参数化和紧凑的结构有助于提高其表达能力和学习能力，使其在各种任务中优于相似甚至更大的 MultKAN。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [760] [SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning](https://arxiv.org/abs/2507.14516)
> *SDSC：一种用于语义信号表示学习的结构感知度量*

*Jeyoung Lee, Hochul Kang* | **Category: cs.LG, cs.AI, cs.LO** | **Updated: 2025-07-24**

**Keywords:** 结构感知度量, 自监督学习, 时间序列, 信号表示学习, Dice相似系数

**Comment:** 

> **TL;DR:** 本文提出了信号Dice相似系数（SDSC），一种结构感知的时序信号自监督学习度量。它解决了传统距离度量（如MSE）在幅度敏感性、极性不变性及尺度无界性方面的问题，通过量化带符号幅度的交集来衡量结构一致性。实验表明，SDSC在预测和分类任务中，特别是在域内和低资源场景下，表现出与MSE相当或更优的性能。

**AI_Comments:** 这项工作通过引入结构感知度量SDSC，为时间序列自监督学习提供了一个新的视角。它解决了传统基于距离的损失函数（如MSE）在处理信号极性和尺度方面存在的局限性，提升了语义对齐和解释性。其创新之处在于将Dice相似系数思想应用于信号结构匹配，并提出了可微分的损失形式和混合损失策略。这对于提高信号表示学习的鲁棒性和泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大多数信号的自监督学习（SSL）方法采用基于距离的目标函数（如均方误差MSE），这些函数对幅度敏感、对波形极性不变且尺度无界。这些特性阻碍了语义对齐并降低了解释性。

**Method:** 提出了信号Dice相似系数（SDSC），这是一种结构感知度量，通过量化带符号幅度的交集来衡量时间信号间的结构一致性，其灵感来源于Dice相似系数（DSC）。SDSC可以转换为损失函数，方法是将其从1中减去并应用Heaviside函数的微分近似以进行梯度优化。此外，还提出了一种混合损失公式，将SDSC与MSE结合使用，以提高稳定性并在必要时保留幅度。

**Result:** 在预测和分类基准测试中，基于SDSC的预训练实现了与MSE相当或更优的性能，尤其是在域内和低资源场景下。

**Conclusion:** 信号表示中的结构保真度可以增强语义表示质量，这支持将结构感知度量视为传统基于距离方法的有效替代方案。

> **ai_Abstract:** 本文提出了一种名为信号Dice相似系数（SDSC）的新型结构感知度量，专为时间序列自监督表示学习设计。针对现有距离度量（如MSE）在语义对齐和解释性方面的不足，SDSC通过量化带符号幅度的交集来评估信号间的结构一致性。SDSC可作为损失函数用于梯度优化，并可与MSE结合形成混合损失。实验证明，在预测和分类任务中，基于SDSC的预训练在特定场景下能达到或超越MSE的性能，表明结构保真度对提升信号语义表示质量具有重要作用。

> **摘要翻译:** 我们提出了信号Dice相似系数（SDSC），这是一种用于时间序列自监督表示学习的结构感知度量函数。大多数信号的自监督学习（SSL）方法通常采用基于距离的目标函数，例如均方误差（MSE），这些函数对幅度敏感、对波形极性不变且尺度无界。这些特性阻碍了语义对齐并降低了解释性。SDSC通过量化带符号幅度的交集来解决这个问题，从而衡量时间信号之间的结构一致性，它源自Dice相似系数（DSC）。尽管SDSC被定义为一种结构感知度量，但它可以通过1减去自身并应用Heaviside函数的微分近似来用作损失函数，以进行基于梯度的优化。本文还提出了一种混合损失公式，将SDSC与MSE结合，以提高稳定性并在必要时保留幅度。在预测和分类基准测试上的实验表明，基于SDSC的预训练实现了与MSE相当或更优的性能，特别是在域内和低资源场景下。结果表明，信号表示中的结构保真度增强了语义表示质量，支持将结构感知度量视为传统基于距离方法的有效替代方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [765] [Zeroth-Order Fine-Tuning of LLMs in Random Subspaces](https://arxiv.org/abs/2410.08989)
> *随机子空间中LLMs的零阶微调*

*Ziming Yu, Pan Zhou, Sike Wang, Jia Li, Mi Tian, Hua Huang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 零阶优化, LLMs, 微调, 随机子空间, 低秩扰动

**Comment:** ICCV 2025 camera-ready version

> **TL;DR:** 提出SubZero，一种在随机子空间中使用低秩扰动的零阶优化方法，旨在高效微调LLM，相比现有零阶方法，其性能更好、收敛更快，同时减少内存消耗。

**AI_Comments:** SubZero通过解决零阶方法关键的方差问题，在内存高效的LLM微调方面取得了显著进展。低秩扰动与理论保证的结合，使其成为扩展LLM训练至更大模型的有前景方法。

<details>
  <summary>Details</summary>

**Motivation:** 微调大型语言模型（LLMs）对多种下游任务有效，但随着LLMs规模的增大，反向传播的内存需求变得 prohibitive。零阶（ZO）优化方法通过使用前向传播估计梯度，提供了一种内存高效的替代方案，但梯度估计的方差通常与模型的参数维度呈线性关系，这对LLMs来说是一个显著问题。

**Method:** 本文提出了随机子空间零阶（SubZero）优化方法，以解决LLMs高维度带来的挑战。该方法引入了针对LLMs量身定制的低秩扰动，显著减少了内存消耗，同时提高了训练性能。此外，证明了其梯度估计能紧密近似反向传播梯度，比传统ZO方法方差更低，并结合SGD确保收敛。

**Result:** 实验结果表明，与MeZO等标准ZO方法相比，SubZero在各种语言建模任务中增强了微调性能并实现了更快的收敛。

**Conclusion:** SubZero有效解决了零阶优化中LLMs高维度的挑战，提供了一种内存高效且性能优越的微调方法，并具有理论保证。

> **ai_Abstract:** 本文提出了一种名为SubZero的零阶优化新方法，用于微调大型语言模型（LLMs）。该方法通过在随机子空间中引入低秩扰动，解决了反向传播的内存限制以及传统零阶方法在高维LLM中梯度估计方差过大的问题。SubZero在理论上被证明能提供准确且低方差的梯度估计，并确保收敛。实验结果表明，与现有零阶技术相比，SubZero在LLM微调方面表现出更优的性能和更快的收敛速度。

> **摘要翻译:** 大型语言模型（LLMs）的微调已被证明对各种下游任务有效。然而，随着LLMs规模的增大，反向传播的内存需求变得越来越高昂。零阶（ZO）优化方法通过使用前向传播来估计梯度，提供了一种内存高效的替代方案，但梯度估计的方差通常与模型的参数维度呈线性关系——这对LLMs来说是一个显著问题。在本文中，我们提出了随机子空间零阶（SubZero）优化方法，以解决LLMs高维度带来的挑战。我们引入了一种专为LLMs定制的低秩扰动，显著减少了内存消耗，同时提高了训练性能。此外，我们证明了我们的梯度估计能紧密近似反向传播梯度，比传统ZO方法表现出更低的方差，并与SGD结合时确保收敛。实验结果表明，与MeZO等标准ZO方法相比，SubZero在各种语言建模任务中增强了微调性能并实现了更快的收敛。代码可在https://github.com/zimingyy/SubZero获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [769] [The Geometry of LLM Quantization: GPTQ as Babai's Nearest Plane Algorithm](https://arxiv.org/abs/2507.18553)
> *LLM量化的几何学：GPTQ作为Babai最近平面算法*

*Jiale Chen, Torsten Hoefler, Dan Alistarh* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** LLM量化, GPTQ, Babai算法, 最近向量问题, 格理论

**Comment:** 

> **TL;DR:** 本文揭示了GPTQ在特定执行条件下，数学上等同于Babai的最近平面算法，从而为GPTQ提供了几何解释和误差上限。

**AI_Comments:** 这项工作非常重要，因为它通过将GPTQ与经典的数学算法（Babai的最近平面算法）联系起来，显著提升了我们对GPTQ内部机制的理解。这种几何解释和误差上限的推导，不仅为GPTQ提供了急需的理论支撑，也为未来设计更高效、更具理论保证的量化算法指明了方向，具有很强的创新性。

<details>
  <summary>Details</summary>

**Motivation:** GPTQ作为LLM量化的标准方法，其内部机制被描述为一系列临时的代数更新，缺乏几何意义或最坏情况保证。

**Method:** 本文通过复杂的数学论证，证明当GPTQ对线性层从后向前（从最后一维到第一维）执行时，它在数学上等同于Babai的最近平面算法，该算法用于在由层输入的海森矩阵定义的格上解决经典最近向量问题（CVP）。

**Result:** 该等价性带来了两个分析结果：(i) GPTQ的误差传播步骤获得了直观的几何解释；(ii) 在无裁剪条件下，GPTQ继承了Babai算法的误差上限。

**Conclusion:** 这些结果共同将GPTQ置于坚实的理论基础之上，并为将格算法数十年的进展引入到未来数十亿参数模型的量化算法设计中打开了大门。

> **ai_Abstract:** 本研究揭示了GPTQ（一种LLM量化方法）与经典的Babai最近平面算法之间的数学等价性。通过对线性层从后向前执行的分析，论文证明了GPTQ的误差传播具有几何解释，并且在特定条件下继承了Babai算法的误差上限。这项工作为GPTQ提供了坚实的理论基础，并为未来的量化算法设计引入格算法的进步提供了可能性。

> **摘要翻译:** 将大型语言模型（LLM）的权重从16位量化到更低的位宽，是部署大规模Transformer模型到更经济的加速器上的事实方法。GPTQ作为LLM规模下一次性训练后量化的标准方法之一应运而生。然而，其内部机制被描述为一系列临时的代数更新，这模糊了其任何几何意义或最坏情况保证。在这项工作中，我们展示了，当对线性层从后向前（从最后一维到第一维）执行时，GPTQ在数学上等同于Babai的最近平面算法，该算法用于在由层输入的海森矩阵定义的格上解决经典最近向量问题（CVP）。这种等价性是基于复杂的数学论证，并具有两个分析结果：(i) GPTQ的误差传播步骤获得了直观的几何解释；(ii) 在无裁剪条件下，GPTQ继承了Babai算法的误差上限。总而言之，这些结果将GPTQ置于坚实的理论基础之上，并为将格算法数十年的进展引入到未来数十亿参数模型的量化算法设计中打开了大门。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [771] [Generalizing Adam to Manifolds for Efficiently Training Transformers](https://arxiv.org/abs/2305.16901)
> *将Adam泛化到流形以高效训练Transformer*

*Benedikt Brantner* | **Category: cs.LG, math.DG, 53Z50, 53C30, 68T07, 68W10, 90C26** | **Updated: 2025-07-24**

**Keywords:** Adam, 流形, Transformer, 优化, 全局切空间

**Comment:** 32 pages, 6 figures (some of which contain subfigures), presented at
  Enumath2023 and Enumath2025

> **TL;DR:** 本文提出了一种新的方法，利用流形的全局切空间表示来完全泛化Adam优化器到流形，无需投影步骤，并在训练带正交约束的Transformer时观察到显著的速度提升。

**AI_Comments:** 这项工作的主要创新在于利用流形的全局切空间表示来泛化Adam，避免了传统方法中复杂的投影步骤，这是一种新颖且高效的策略。其重要性体现在能够加速具有正交约束的Transformer的训练，这对于需要高精度和稳定性的模型训练具有实际价值。

<details>
  <summary>Details</summary>

**Motivation:** Adam优化器广泛用于训练神经网络，但难以解释且难以泛化到流形。尽管已有尝试，但完全泛化Adam到流形仍然难以实现。

**Method:** 本文提出了一种新方法，利用神经网络优化相关流形（如Stiefel流形、辛Stiefel流形和Grassmann流形）的特殊结构。这些流形都是齐次空间，因此允许全局切空间表示。该全局切空间表示用于执行Adam优化器中的所有步骤，从而能够在没有投影步骤的情况下将优化器完全泛化到流形。

**Result:** 所得到的算法被应用于训练Transformer，其中正交约束被强制执行到机器精度，并观察到训练过程中的显著加速。

**Conclusion:** 通过利用流形的全局切空间表示，Adam优化器可以被完全泛化到流形，无需投影步骤，并且在训练带正交约束的Transformer时实现了显著的效率提升。

> **ai_Abstract:** 本文提出了一种将Adam优化器完全泛化到流形的新方法，解决了Adam难以在流形上应用的问题。该方法利用了神经网络优化中相关流形（如Stiefel流形）的全局切空间表示，使得Adam的所有步骤都可以在此通用向量空间中执行，从而无需投影即可实现泛化。实验结果表明，将此算法应用于训练具有正交约束的Transformer时，训练速度显著加快。

> **摘要翻译:** 神经网络成功的主要原因之一是出现了一系列新的、非常成功的优化器，其中最重要的可能是Adam优化器。它被广泛用于训练神经网络，但却出了名的难以解释。由于缺乏清晰的物理直觉，Adam很难泛化到流形。虽然已经有一些尝试直接将Adam算法的部分应用于流形或寻找底层结构，但完全的泛化仍然难以实现。
  在这项工作中，提出了一种新方法，利用与神经网络优化相关的流形（如Stiefel流形、辛Stiefel流形和Grassmann流形）的特殊结构：所有这些都是齐次空间，因此允许全局切空间表示——一个共同的向量空间（李子空间），其中所有切空间都可以很容易地表示。
  这种全局切空间表示用于执行Adam优化器中的所有步骤，我们能够完全将优化器泛化到流形而无需投影步骤。然后将所得算法应用于训练一个Transformer，其中正交性约束被强制执行到机器精度，并且我们观察到训练过程中的显著加速。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [784] [GCC-Spam: Spam Detection via GAN, Contrastive Learning, and Character Similarity Networks](https://arxiv.org/abs/2507.14679)
> *GCC-Spam：基于GAN、对比学习和字符相似性网络的垃圾邮件检测*

*Zhijie Wang, Zixin Xu, Zhiyuan Pan* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 垃圾邮件检测, GAN, 对比学习, 字符相似性, 数据稀缺

**Comment:** 

> **TL;DR:** GCC-Spam是一种新颖的垃圾邮件检测框架，它利用GAN进行数据增强，对比学习提高辨别力，以及字符相似性网络对抗混淆，从而在标记数据较少的情况下实现高精度。

**AI_Comments:** 该论文提出了一种创新的多组件垃圾邮件检测方法，有效地解决了对抗性混淆和数据稀缺这两个关键挑战。字符相似性网络、对比学习和GAN的结合是一种新颖而强大的集成。

<details>
  <summary>Details</summary>

**Motivation:** 互联网上垃圾文本的指数级增长需要强大的检测机制来减轻信息泄露和社会不稳定等风险。这项工作解决了两个主要挑战：垃圾邮件发送者采用的对抗策略以及标记数据稀缺的问题。

**Method:** 本文提出了一种名为GCC-Spam的新型垃圾文本检测框架，该框架集成了三项核心创新：1. 字符相似性网络，用于捕获正字法和语音特征，以对抗字符混淆攻击并生成句子嵌入。2. 对比学习，通过优化垃圾邮件和正常文本之间潜在空间的距离来增强可区分性。3. 生成对抗网络（GAN），用于生成逼真的伪垃圾邮件样本，以缓解数据稀缺问题并提高模型鲁棒性和分类准确性。

**Result:** 在真实世界数据集上进行的广泛实验表明，GCC-Spam模型优于基线方法，以明显更少的标记样本实现了更高的检测率。

**Conclusion:** GCC-Spam是一种有效且高效的垃圾邮件检测框架，能够应对对抗性策略和数据稀缺问题，并在真实世界数据集中表现出卓越的性能。

> **ai_Abstract:** 本文介绍了GCC-Spam，一个用于鲁棒垃圾文本检测的新颖框架，解决了对抗性攻击和数据稀缺的挑战。它集成了字符相似性网络来处理混淆并生成嵌入，对比学习来提高可区分性，以及GAN来合成伪垃圾邮件以进行数据增强。实验表明，GCC-Spam超越了基线方法，以更少的标记样本实现了更高的检测率。

> **摘要翻译:** 互联网上垃圾文本的指数级增长需要强大的检测机制来减轻信息泄露和社会不稳定等风险。这项工作解决了两个主要挑战：垃圾邮件发送者采用的对抗策略以及标记数据稀缺的问题。我们提出了一种新颖的垃圾文本检测框架GCC-Spam，它集成了三项核心创新。首先，字符相似性网络捕获正字法和语音特征，以对抗字符混淆攻击，并为下游分类生成句子嵌入。其次，对比学习通过优化垃圾邮件和正常文本之间潜在空间距离来增强可区分性。第三，生成对抗网络（GAN）生成逼真的伪垃圾邮件样本，以缓解数据稀缺问题，同时提高模型鲁棒性和分类准确性。在真实世界数据集上进行的广泛实验表明，我们的模型优于基线方法，以明显更少的标记样本实现了更高的检测率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [786] [Percentile-Based Deep Reinforcement Learning and Reward Based Personalization For Delay Aware RAN Slicing in O-RAN](https://arxiv.org/abs/2507.18111)
> *百分位深度强化学习和基于奖励的个性化用于O-RAN中的时延感知RAN切片*

*Peyman Tehrani, Anas Alsoliman* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** O-RAN, RAN切片, 深度强化学习, 时延感知, 个性化

**Comment:** 

> **TL;DR:** 本文提出了一种基于百分位的深度强化学习方法（PDA-DRL）和基于奖励的个性化技术，旨在O-RAN中实现时延感知的RAN切片，同时优化资源利用和满足时延约束。

**AI_Comments:** 该论文通过结合百分位深度强化学习和创新的奖励驱动个性化方法，为O-RAN中的RAN切片提供了新颖且高效的解决方案，特别是在处理概率时延约束和多租户模型共享方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在开放无线接入网络（O-RAN）架构中，多个移动虚拟网络运营商（MVNO）竞争物理资源块（PRB），需要满足客户的概率时延上限约束，同时最小化PRB利用率。

**Method:** 首先，基于大数定律（LLN）推导奖励函数并进行实际修改。然后，提出百分位时延感知深度强化学习（PDA-DRL）解决方案。此外，为解决多MVNO模型权重共享问题，引入了一种基于奖励的个性化方法，其中每个代理根据其他代理的性能优先考虑其模型权重。

**Result:** PDA-DRL相对于为平均时延约束优化的DRL模型，将最终平均时延降低了38%。基于奖励的个性化技术超越了传统的聚合方法（如联邦平均）以及依赖流量模式和模型权重距离相似性的策略。

**Conclusion:** 该研究成功地提出并验证了PDA-DRL和基于奖励的个性化方法，有效解决了O-RAN中时延感知的RAN切片挑战，显著提升了时延性能和资源利用效率。

> **ai_Abstract:** 本文针对O-RAN架构中的RAN切片挑战，提出了百分位时延感知深度强化学习（PDA-DRL）方法。该方法通过基于大数定律的奖励函数，使多个MVNO在满足概率时延约束的同时最小化资源利用。实验结果表明，PDA-DRL将平均时延降低了38%。此外，为了实现鲁棒的个性化模型，引入了一种基于奖励的模型权重共享个性化方法，该方法在性能上优于传统聚合策略，有效解决了多MVNO环境下的模型共享问题。

> **摘要翻译:** 在本文中，我们解决了开放RAN（O-RAN）架构中无线接入网络（RAN）切片的挑战。我们的重点是一个包含多个移动虚拟网络运营商（MVNO）的网络，这些运营商竞争物理资源块（PRB），目标是满足其客户的概率时延上限约束，同时最小化PRB利用率。最初，我们基于大数定律（LLN）推导了一个奖励函数，然后进行了实际修改以适应真实世界的实验场景。然后，我们提出了我们的解决方案——基于百分位的时延感知深度强化学习（PDA-DRL），它通过将最终平均时延降低38%，证明了其优于几种基线（包括为平均时延约束优化的DRL模型）的优越性。此外，我们深入研究了多个MVNO之间模型权重共享的问题，以开发一个鲁棒的个性化模型。我们引入了一种基于奖励的个性化方法，其中每个代理根据其他代理的性能优先考虑其他代理的模型权重。这项技术超越了传统的聚合方法，例如联邦平均，以及依赖流量模式和模型权重距离相似性的策略。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [791] [Fourier Neural Operators for Non-Markovian Processes:Approximation Theorems and Experiments](https://arxiv.org/abs/2507.17887)
> *傅里叶神经算子用于非马尔可夫过程：逼近定理和实验*

*Wonjae Lee, Taeyoung Kim, Hyungbin Park* | **Category: cs.LG, cs.NA, math.NA** | **Updated: 2025-07-23**

**Keywords:** 傅里叶神经算子, 非马尔可夫过程, 随机微分方程, 分数布朗运动, 分辨率泛化

**Comment:** 

> **TL;DR:** 本文提出了一种新的傅里叶神经算子MFNO，能有效学习非马尔可夫过程，具有理论逼近保证和更好的泛化及速度。

**AI_Comments:** 该论文的创新点在于提出了MFNO，通过引入镜面填充解决了FNO处理非周期性输入的问题，并提供了严格的理论逼近保证。其重要性体现在为学习复杂随机过程提供了新的有效工具，特别是在分辨率泛化和计算效率方面超越了现有主流方法，对随机系统建模领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了学习随机系统的动态，特别是处理非马尔可夫过程和非周期性输入，并克服现有模型（如LSTMs、TCNs、DeepONet）在分辨率泛化方面的不足以及经典数值方案的计算速度慢的问题。

**Method:** 引入了镜面填充傅里叶神经算子（MFNO），通过结合镜面填充扩展了标准傅里叶神经算子（FNO），使其能够处理非周期性输入。理论分析基于Wong--Zakai型定理和各种逼近技术。

**Result:** MFNO能够以任意精度逼近路径依赖随机微分方程的解和分数布朗运动的Lipschitz变换。MFNO在经验上表现出强大的分辨率泛化能力，这是标准架构（如LSTMs、TCNs、DeepONet）中罕见的特性。MFNO的模型性能与这些基线相当或更优。MFNO提供比经典数值方案显著更快的样本路径生成速度。

**Conclusion:** MFNO是一种有效且高效的算子基神经网络，能够学习非马尔可夫过程的动态，具有强大的理论逼近能力、出色的分辨率泛化能力以及比现有方法更快的计算速度。

> **ai_Abstract:** 本文提出了一种名为镜面填充傅里叶神经算子（MFNO）的新型神经网络，用于学习随机系统的动态，特别是处理非周期性输入和非马尔可夫过程。MFNO通过理论证明可以高精度逼近路径依赖随机微分方程和分数布朗运动的解。实验结果表明，MFNO在分辨率泛化方面表现出色，性能与现有基线相当或更优，并且在样本路径生成速度上显著超越传统数值方法。

> **摘要翻译:** 本文介绍了一种基于算子的神经网络——镜面填充傅里叶神经算子（MFNO），旨在学习随机系统的动态。MFNO通过引入镜面填充扩展了标准傅里叶神经算子（FNO），使其能够处理非周期性输入。我们严格证明了MFNO能够以任意精度逼近路径依赖随机微分方程的解和分数布朗运动的Lipschitz变换。我们的理论分析建立在Wong--Zakai型定理和各种逼近技术之上。从经验上看，MFNO表现出强大的分辨率泛化能力——这是LSTMs、TCNs和DeepONet等标准架构中罕见的特性。此外，我们的模型在性能上与这些基线相当或更优，同时比经典数值方案提供显著更快的样本路径生成速度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [808] [Omni-Thinker: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards](https://arxiv.org/abs/2507.14783)
> *Omni-Thinker：通过混合奖励多任务强化学习扩展LLMs的跨领域泛化能力*

*Derek Li, Jiaming Zhou, Amirreza Kazemi, Qianyi Sun, Abbas Ghaddar, Mohammad Ali Alomrani, Liheng Ma, Yu Luo, Dong Li, Feng Wen, Jianye Hao, Mark Coates, Yingxue Zhang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 强化学习, 泛化, 混合奖励, 课程学习

**Comment:** 

> **TL;DR:** Omni-Thinker是一个RL框架，通过混合奖励和课程学习提升LLM的跨领域泛化能力，优于SFT、联合训练和模型合并。

**AI_Comments:** 这项工作通过引入Omni-Thinker框架，结合了混合奖励（规则+偏好）和课程学习策略，有效地解决了LLMs在跨领域泛化中的挑战。其创新点在于将强化学习应用于LLM的后训练，并提出了适应不同任务类型的优化方法，特别是在主观领域的应用。结果表明，课程学习在提升性能和减少遗忘方面具有显著优势，对通用LLM的未来发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的后训练方法（如监督微调SFT）在大型语言模型（LLMs）的泛化能力上表现不佳，倾向于记忆而非可迁移学习，难以在结构化推理和创意生成等广泛任务中表现出色。

**Method:** 本文引入了Omni-Thinker，一个统一的强化学习（RL）框架，旨在增强LLM在不同任务中的性能。该框架通过结合基于规则的可验证奖励和通过LLM-as-a-Judge评估的生成偏好信号来实现。Omni-Thinker能够实现跨任务类型的持续优化，并将基于RL的训练扩展到主观领域。此外，研究还探索了一种训练策略，即采用从结构化任务到开放式任务的课程式进展。

**Result:** 在四个领域进行的实验结果表明，课程学习比联合训练的性能提高了5.2%，比模型合并提高了9.1%。这些结果强调了任务感知采样和混合监督在扩展基于RL的通用LLM后训练中的重要性。

**Conclusion:** 课程学习和混合监督对于扩展基于强化学习的通用LLM的后训练至关重要，能够显著提升其跨领域泛化能力。

> **ai_Abstract:** 本文提出Omni-Thinker，一个统一的强化学习框架，旨在解决大型语言模型（LLMs）在监督微调（SFT）等后训练方法中泛化能力不足的问题。该框架结合了基于规则的奖励和LLM-as-a-Judge生成的偏好信号，以实现跨任务类型的优化，并能应用于主观领域。研究还发现，采用从结构化到开放式任务的课程学习策略能有效提升LLM的性能并减少遗忘。实验证明，该方法在跨领域泛化方面优于联合训练和模型合并，强调了任务感知采样和混合监督的重要性。

> **摘要翻译:** 通用人工智能的进步依赖于在广泛任务（从结构化推理到创意生成）中表现出色的大型语言模型（LLMs）。然而，像监督微调（SFT）这样的后训练方法在泛化方面常常遇到困难，倾向于记忆而非可迁移学习。在这项工作中，我们引入了Omni-Thinker，一个统一的强化学习（RL）框架，它通过结合基于规则的可验证奖励和通过LLM-as-a-Judge评估的生成偏好信号来增强LLM在不同任务中的性能。我们的方法能够实现跨任务类型的持续优化，并将基于RL的训练扩展到主观领域。我们进一步研究了训练策略，证明了从结构化到开放式任务的课程式进展可以提高性能并减少遗忘。在四个领域进行的实验结果表明，课程学习比联合训练的性能提高了5.2%，比模型合并提高了9.1%。这些结果强调了任务感知采样和混合监督在扩展基于RL的通用LLM后训练中的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [811] [Neural Tangent Kernels and Fisher Information Matrices for Simple ReLU Networks with Random Hidden Weights](https://arxiv.org/abs/2507.18555)
> *随机隐藏权重的简单ReLU网络的神经正切核与费雪信息矩阵*

*Jun'ichi Takeuchi, Yoshinari Takeishi, Noboru Murata, Kazushi Mimura, Ka Long Keith Ho, Hiroshi Nagaoka* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-25**

**Keywords:** 神经正切核, 费雪信息矩阵, ReLU网络, 谱分解, 近似公式

**Comment:** 

> **TL;DR:** 本文讨论了具有随机隐藏权重的两层ReLU网络的费雪信息矩阵和神经正切核，揭示了它们之间的线性变换关系，并给出了NTK的谱分解及网络函数近似公式。

**AI_Comments:** 本文对具有随机隐藏权重的简单ReLU网络的理论特性进行了深入探讨，特别是揭示了费雪信息矩阵和神经正切核之间的内在联系。其创新之处在于通过线性变换揭示了二者关系，并提供了神经正切核的谱分解和网络函数的近似公式，这对于理解神经网络的训练动态和泛化能力具有重要的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 探讨具有随机隐藏权重的两层ReLU网络的费雪信息矩阵（FIM）和神经正切核（NTK）的性质及其关系。

**Method:** 通过讨论费雪信息矩阵和神经正切核之间的线性变换关系，并展示神经正切核的谱分解及其主要特征函数的具体形式，同时推导了两层神经网络所表示函数的近似公式。

**Result:** 揭示了费雪信息矩阵和神经正切核之间的线性变换关系；给出了神经正切核的谱分解，包括具有主要特征值的特征函数的具体形式；获得了两层神经网络所表示函数的近似公式。

**Conclusion:** 本文深入分析了具有随机隐藏权重的两层ReLU网络的费雪信息矩阵和神经正切核，揭示了二者之间的线性变换关系，并提供了神经正切核的谱分解及网络函数近似公式，为理解这类网络的理论特性提供了新的视角。

> **ai_Abstract:** 本文研究了具有随机隐藏权重的两层ReLU网络的费雪信息矩阵和神经正切核（NTK）。研究揭示了FIM和NTK之间的线性变换关系，并推导了NTK的谱分解，包括其主要特征函数的具体形式。此外，论文还提出了两层神经网络所表示函数的近似公式，为理解这类网络的理论行为提供了见解。

> **摘要翻译:** 本文讨论了具有随机隐藏权重的两层ReLU网络的费雪信息矩阵和神经正切核（NTK）。我们探讨了这两个概念之间的线性变换关系，并展示了神经正切核的谱分解，其中包含主要特征值的特征函数的具体形式。我们还获得了由两层神经网络所表示函数的近似公式。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [813] [Compressed and distributed least-squares regression: convergence rates with applications to Federated Learning](https://arxiv.org/abs/2308.01358)
> *压缩分布式最小二乘回归：收敛率及其在联邦学习中的应用*

*Constantin Philippenko, Aymeric Dieuleveut* | **Category: cs.LG, math.OC, stat.ML** | **Updated: 2025-07-24**

**Keywords:** 压缩通信, 分布式学习, 联邦学习, 最小二乘回归, 收敛率

**Comment:** 

> **TL;DR:** 本文研究了压缩对分布式和联邦学习中随机梯度算法收敛率的影响，特别是在最小二乘回归中，并推广到联邦学习场景，给出了更通用的收敛率。

**AI_Comments:** 本文的创新之处在于其超越了传统的“最坏情况”分析，通过对不同无偏压缩算子的收敛率进行细致的比较，揭示了它们之间的差异。其次，研究在较弱的假设下（如预期H"older正则性）进行分析，增强了结果的普适性。此外，将结果推广到联邦学习场景，也突显了其在实际应用中的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 研究压缩对机器学习中随机梯度算法的影响，特别是其在分布式和联邦学习中的广泛应用。文章旨在揭示不同无偏压缩算子在收敛率方面的差异，超越传统最坏情况分析的局限。

**Method:** 本文聚焦于最小二乘回归（LSR），分析了一种用于最小化依赖随机场的二次函数的通用随机逼近算法。研究在随机场（特别是预期H"older正则性）和噪声协方差上设定了较弱的假设，从而能够分析包括压缩在内的各种随机化机制。研究结果随后被推广到联邦学习场景。

**Result:** 研究强调了算法引起的附加噪声协方差$\mathfrak{C}_{\mathrm{ania}}$对收敛的影响。结果表明，尽管随机场不规则，极限方差项仍以$\mathrm{Tr}(\mathfrak{C}_{\mathrm{ania}} H^{-1})/K$的比例缩放（其中$H$是优化问题的Hessian，$K$是迭代次数），这推广了香草LSR情况下的收敛率$\sigma^2 \mathrm{Tr}(H H^{-1}) / K = \sigma^2 d / K$。此外，研究分析了$\mathfrak{C}_{\mathrm{ania}}$对压缩策略的依赖性及其对收敛的影响，包括集中式和两种异构联邦学习框架。

**Conclusion:** 本文通过分析压缩策略引入的附加噪声协方差，为压缩和分布式最小二乘回归，特别是联邦学习中的随机梯度算法，提供了更通用和细致的收敛率分析。

> **ai_Abstract:** 本文深入探讨了压缩技术对分布式和联邦学习中随机梯度算法收敛率的影响。研究通过分析最小二乘回归中的通用随机逼近算法，并考虑较弱的随机场和噪声协方差假设，揭示了不同无偏压缩算子在收敛率上的差异，超越了传统的最坏情况分析。核心发现是，即使随机场不规则，极限方差项的收敛率也取决于算法引起的附加噪声协方差$\mathfrak{C}_{\mathrm{ania}}$，并推广了现有LSR的收敛率。研究进一步分析了$\mathfrak{C}_{\mathrm{ania}}$与压缩策略的关系及其对集中式和异构联邦学习框架中收敛的影响。

> **摘要翻译:** 在本文中，我们研究了压缩对机器学习中随机梯度算法的影响，该技术广泛应用于分布式和联邦学习。我们强调了几个无偏压缩算子在收敛率方面的差异，这些算子都满足相同的方差条件，从而超越了经典的“最坏情况”分析。为此，我们专注于最小二乘回归（LSR）的情况，并分析了一种依赖于随机场的最小化二次函数的通用随机逼近算法。我们对随机场（特别是预期的H"older正则性）和噪声协方差考虑了较弱的假设，这使得能够分析各种随机化机制，包括压缩。然后，我们将结果推广到联邦学习的情况。
更正式地，我们强调了算法引起的附加噪声的协方差$\mathfrak{C}_{\mathrm{ania}}$对收敛的影响。我们证明了尽管随机场不规则，极限方差项仍以$\mathrm{Tr}(\mathfrak{C}_{\mathrm{ania}} H^{-1})/K$的比例缩放（其中$H$是优化问题的Hessian，$K$是迭代次数），这推广了香草LSR情况下的收敛率$\sigma^2 \mathrm{Tr}(H H^{-1}) / K = \sigma^2 d / K$（Bach和Moulines，2013）。然后，我们分析了$\mathfrak{C}_{\mathrm{ania}}$对压缩策略的依赖性及其最终对收敛的影响，首先在集中式情况下，然后在两个异构FL框架中进行。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [816] [Diffusion Beats Autoregressive in Data-Constrained Settings](https://arxiv.org/abs/2507.15857)
> *在数据受限环境下，扩散模型优于自回归模型*

*Mihir Prabhudesai, Menging Wu, Amir Zadeh, Katerina Fragkiadaki, Deepak Pathak* | **Category: cs.LG, cs.AI, cs.CV, cs.RO** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 自回归模型, 数据受限, 隐式数据增强, 缩放定律

**Comment:** Project Webpage: https://diffusion-scaling.github.io

> **TL;DR:** 在数据稀缺但计算资源充足的条件下，扩散模型在语言任务中显著优于自回归模型，因为它们能更好地利用重复数据，表现出隐式数据增强。

**AI_Comments:** 这项研究揭示了扩散模型在数据稀缺场景下的巨大潜力，挑战了自回归模型在大型语言模型领域的长期主导地位。其创新点在于系统性地探索了数据受限环境，并提出了“隐式数据增强”的解释，为未来在特定资源约束下选择模型提供了重要指导。推导临界计算阈值的闭式表达式也具有很高的理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 自回归模型长期主导大型语言模型领域，而扩散语言模型作为一种有前景的替代方案刚刚兴起，但其相对于自回归模型的优势尚未得到充分探索。

**Method:** 本研究系统地在数据受限环境下（训练涉及对有限数据的重复遍历）研究了掩码扩散模型，并与自回归模型进行了比较。

**Result:** 当计算资源充足但数据稀缺时，扩散模型显著优于自回归模型。扩散模型能更好地利用重复数据，实现更低的验证损失和更优的下游性能。这种优势被解释为隐式数据增强，即掩码扩散使模型接触到多样化的词元排序和预测任务。研究还发现了扩散模型的新缩放定律，并推导出了扩散模型开始优于自回归模型的临界计算阈值的闭式表达式。

**Conclusion:** 当数据而非计算是瓶颈时，扩散模型为标准自回归范式提供了一个引人注目的替代方案。

> **ai_Abstract:** 本研究系统地探讨了在数据受限环境下（训练数据有限且重复使用）掩码扩散语言模型相对于自回归模型的性能。研究发现，在计算资源充足但数据稀缺的情况下，扩散模型能显著超越自回归模型，表现出更低的验证损失和更优的下游任务表现。这种优势归因于扩散模型对重复数据的更好利用和其隐式数据增强特性，即通过掩码生成暴露模型于多样化的词元排序和预测任务。此外，论文还提出了扩散模型的新缩放定律，并确定了扩散模型开始超越自回归模型的关键计算阈值。这些结果表明，当数据成为主要瓶颈时，扩散模型是自回归模型的一个强有力替代。

> **摘要翻译:** 自回归（AR）模型长期以来主导着大型语言模型的格局，推动了各种任务的进展。最近，基于扩散的语言模型已成为一种有前景的替代方案，尽管它们相对于AR模型的优势仍未得到充分探索。在本文中，我们系统地研究了数据受限环境下的掩码扩散模型——在这种环境下，训练涉及对有限数据的重复遍历——并发现当计算资源充足但数据稀缺时，它们显著优于AR模型。扩散模型能更好地利用重复数据，实现更低的验证损失和更优的下游性能。我们将这种优势解释为隐式数据增强：与AR固定的从左到右分解不同，掩码扩散使模型接触到多样化的词元排序和预测任务。我们发现了扩散模型的新缩放定律，并导出了扩散模型开始优于AR的临界计算阈值的闭式表达式。这些结果表明，当数据而非计算是瓶颈时，扩散模型为标准AR范式提供了一个引人注目的替代方案。我们的代码可在以下网址获取：https://diffusion-scaling.github.io。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [828] [Policy Disruption in Reinforcement Learning:Adversarial Attack with Large Language Models and Critical State Identification](https://arxiv.org/abs/2507.18113)
> *强化学习中的策略扰动：基于大型语言模型和关键状态识别的对抗性攻击*

*Junyong Jiang, Buwei Tian, Chenxing Xu, Songze Li, Lu Dong* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 强化学习, 对抗性攻击, 大型语言模型, 策略扰动, 关键状态识别

**Comment:** 

> **TL;DR:** 本文提出了一种新型强化学习对抗性攻击方法，利用LLM生成对抗性奖励并识别关键状态，诱导目标策略输出次优动作，且不修改环境，表现优于现有方法。

**AI_Comments:** 这篇论文的创新点在于它提出了一种不需修改环境的RL对抗性攻击方法，这显著提高了其实用性。其利用LLMs生成对抗性奖励的思路非常新颖，结合关键状态识别，能够更精准地攻击RL策略。这项工作对于理解RL系统的脆弱性以及开发更鲁棒的RL算法具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习在机器人和自动驾驶等领域取得了显著成功，但旨在误导RL系统的对抗性攻击仍然具有挑战性。现有方法通常依赖于修改环境或策略，这限制了它们的实用性。

**Method:** 本文提出一种对抗性攻击方法，其中环境中现有智能体引导目标策略输出次优动作，且不改变环境。提出一个奖励迭代优化框架，利用大型语言模型（LLMs）生成专门针对目标智能体漏洞的对抗性奖励，从而增强诱导目标智能体次优决策的有效性。此外，设计一个关键状态识别算法，以查明目标智能体最脆弱的状态，在这些状态下，受害者的次优行为会导致整体性能显著下降。

**Result:** 在不同环境中的实验结果表明，该方法优于现有方法。

**Conclusion:** 本文提出了一种新颖且实用的强化学习对抗性攻击方法，通过利用LLM和关键状态识别，能在不修改环境的情况下有效诱导RL智能体产生次优行为，并展现出优越的性能。

> **ai_Abstract:** 本文提出了一种在不修改环境的情况下对强化学习策略进行对抗性攻击的新方法。该方法通过一个奖励迭代优化框架，利用大型语言模型（LLMs）生成定制的对抗性奖励，以利用目标智能体的漏洞。此外，它还引入了一个关键状态识别算法，用于定位智能体最脆弱的状态。实验结果表明，该方法在诱导RL智能体产生次优行为方面优于现有方法。

> **摘要翻译:** 强化学习（RL）在机器人和自动驾驶等领域取得了显著成功，但旨在误导RL系统的对抗性攻击仍然具有挑战性。现有方法通常依赖于修改环境或策略，这限制了它们的实用性。本文提出了一种对抗性攻击方法，其中环境中现有智能体引导目标策略输出次优动作，且不改变环境。我们提出了一个奖励迭代优化框架，利用大型语言模型（LLMs）生成专门针对目标智能体漏洞的对抗性奖励，从而增强诱导目标智能体次优决策的有效性。此外，还设计了一个关键状态识别算法，以查明目标智能体最脆弱的状态，在这些状态下，受害者的次优行为会导致整体性能显著下降。在不同环境中的实验结果表明，我们的方法优于现有方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [830] [Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation](https://arxiv.org/abs/2507.15205)
> *用于会话情感识别的长短距离图神经网络和改进课程学习*

*Xinran Li, Xiujuan Xu, Jiaqi Qiao* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 会话情感识别, 图神经网络, 课程学习, 多模态, 特征交互

**Comment:** Accepted by the 28th European Conference on Artificial Intelligence
  (ECAI 2025)

> **TL;DR:** 本文提出了一种结合长短距离图神经网络（LSDGNN）和改进课程学习（ICL）的新型多模态方法，用于会话情感识别（ERC），并在IEMOCAP和MELD数据集上取得了优于现有基准的性能。

**AI_Comments:** 本文的创新点在于结合了长短距离图神经网络来捕获会话中不同距离的语境信息，并通过差分正则化器和双仿射模块有效融合这些特征。同时，引入改进课程学习来处理数据不平衡问题，特别是通过“加权情感转变”度量来优化学习顺序，这是一个值得关注的贡献。该方法在实际应用中对提升会话情感识别的准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 会话情感识别（ERC）是一项实用且具有挑战性的任务。

**Method:** 本文提出了一种新颖的多模态方法——长短距离图神经网络（LSDGNN）。它基于有向无环图（DAG），构建了长距离图神经网络和短距离图神经网络，分别获取远距离和近距离话语的多模态特征。为了确保长短距离特征在表示上尽可能不同，同时使两个模块之间能够相互影响，本文采用了差分正则化器并引入了双仿射模块来促进特征交互。此外，为了解决数据不平衡的挑战，本文提出了一种改进课程学习（ICL），通过计算不同情感之间的相似性来强调相似情感的转变，设计了一个“加权情感转变”度量，并开发了一个难度测量器，从而实现了一种优先学习简单样本再学习困难样本的训练过程。

**Result:** 在IEMOCAP和MELD数据集上的实验结果表明，我们的模型优于现有基准。

**Conclusion:** 本文提出的长短距离图神经网络（LSDGNN）结合改进课程学习（ICL）的方法，在会话情感识别任务中表现出色，有效解决了多模态特征融合和数据不平衡等挑战。

> **ai_Abstract:** 本文针对会话情感识别（ERC）的挑战，提出了一种新颖的多模态方法——长短距离图神经网络（LSDGNN）。该模型利用长短距离图神经网络分别捕获远近话语特征，并通过差分正则化器和双仿射模块促进特征交互。为解决数据不平衡问题，还引入了改进课程学习（ICL），通过“加权情感转变”和难度测量器优化训练过程。实验证明，该模型在IEMOCAP和MELD数据集上均超越了现有基准。

> **摘要翻译:** 会话情感识别（ERC）是一项实用且具有挑战性的任务。本文提出了一种新颖的多模态方法——长短距离图神经网络（LSDGNN）。它基于有向无环图（DAG），构建了长距离图神经网络和短距离图神经网络，分别获取远距离和近距离话语的多模态特征。为了确保长短距离特征在表示上尽可能不同，同时使两个模块之间能够相互影响，我们采用了差分正则化器并引入了双仿射模块来促进特征交互。此外，我们提出了一种改进课程学习（ICL）来解决数据不平衡的挑战。通过计算不同情感之间的相似性来强调相似情感的转变，我们设计了一个“加权情感转变”度量，并开发了一个难度测量器，从而实现了一种优先学习简单样本再学习困难样本的训练过程。在IEMOCAP和MELD数据集上的实验结果表明，我们的模型优于现有基准。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [832] [Federated Learning for Large-Scale Cloud Robotic Manipulation: Opportunities and Challenges](https://arxiv.org/abs/2507.17903)
> *联邦学习在大规模云机器人操作中的机遇与挑战*

*Obaidullah Zaland, Chanh Nguyen, Florian T. Pokorny, Monowar Bhuyan* | **Category: cs.LG** | **Updated: 2025-07-23**

**Keywords:** 联邦学习, 云机器人, 机器人操作, 分布式机器学习, 计算资源

**Comment:** Accepted for Presentation at IEEE International Conference on Machine
  Learning and Cybernetics (ICMLC) 2025

> **TL;DR:** 本文探讨了联邦学习（FL）在解决大规模云机器人操作中计算资源限制方面的潜力，并分析了其带来的机遇与挑战。

**AI_Comments:** 这篇论文的重要性在于它将新兴的联邦学习范式与当前面临计算资源限制的云机器人操作领域相结合，探讨了一个前沿且具有实际应用价值的方向。其创新点在于提出通过FL来解决大规模机器人协作中的数据隐私和计算效率问题。论文作为一篇概念性综述，清晰地阐述了机遇与挑战，为后续的研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 当前机器人操作任务受限于个体能力和速度，原因是低延迟计算资源有限。云机器人技术应运而生，通过利用云端资源的灵活性和可靠性来缓解计算需求。联邦学习作为一种新兴的分布式机器学习范式，有望为大规模云机器人操作提供一种无需共享私有数据的解决方案，从而解决现有计算限制。

**Method:** 本文首先介绍了联邦学习的基本概念及其与云机器人操作的联系。接着，展望了通过联邦学习实现高效可靠的大规模云机器人操作所面临的机遇和挑战，并指出研究人员可以在集中式或去中心化设置中设计和验证联邦学习模型。

**Result:** 本文的结果是提出了联邦学习在大规模云机器人操作中存在的机遇和挑战。

**Conclusion:** 联邦学习在分布式计算背景下的云机器人操作中具有多重优势，但也面临着一系列挑战，需要研究人员在设计和验证FL模型时加以考虑，以有效实现大规模云机器人操作。

> **ai_Abstract:** 本文探讨了联邦学习（FL）在解决大规模云机器人操作中计算资源限制方面的应用。针对传统机器人操作受限于本地计算能力的问题，云机器人技术通过利用云端资源来缓解计算压力。文章指出，FL作为一种无需共享私有数据的分布式机器学习范式，在云机器人操作场景中既带来了显著优势，也面临着一系列挑战和机遇。论文详细阐述了FL的基本概念及其与云机器人操作的联系，并展望了通过FL实现高效可靠的大规模云机器人操作的潜在方向和面临的挑战，鼓励研究人员在集中式或去中心化环境中设计和验证FL模型。

> **摘要翻译:** 联邦学习（FL）是一种新兴的分布式机器学习范式，其中模型的协同训练涉及设备的动态参与以实现广泛目标。与传统机器学习（ML）通常需要数据在本地进行训练不同，FL利用众多用户设备训练共享的全局模型，而无需共享私有数据。当前的机器人操作任务受限于机器人个体能力和速度，原因是低延迟计算资源有限。因此，云机器人概念应运而生，它允许机器人应用利用计算资源的灵活性和可靠性，有效缓解其在云边连续体中的计算需求。毫无疑问，在分布式计算背景下，正如云机器人操作场景所示，FL提供了多重优势，同时也带来了一些挑战和机遇。在本文中，我们介绍了FL的基本概念及其与云机器人操作的联系。此外，我们还展望了通过FL实现大规模高效可靠的云机器人操作所面临的机遇和挑战，研究人员可以在集中式或去中心化设置中设计和验证FL模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [855] [Beyond Internal Data: Constructing Complete Datasets for Fairness Testing](https://arxiv.org/abs/2507.18561)
> *超越内部数据：构建用于公平性测试的完整数据集*

*Varsha Ramineni, Hossein A. Rahmani, Emine Yilmaz, David Barber* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-07-24**

**Keywords:** 公平性测试, 合成数据, 数据稀缺, 人口统计数据, 偏见审计

**Comment:** 9 pages, 6 figures

> **TL;DR:** 本文提出一种利用重叠数据集构建包含人口统计信息的合成数据的方法，以克服公平性测试中真实数据稀缺的挑战，并验证其在评估公平性指标上的有效性。

**AI_Comments:** 这项工作在解决AI公平性测试中的数据稀缺和隐私挑战方面具有重要创新性。通过构建合成数据，它为行业内难以获取敏感人口统计信息的问题提供了实用的解决方案，从而支持更负责任的AI开发和部署。其重要性在于能够促进独立审计和模型无关的公平性评估，提升AI系统的透明度和可信度，对于推动AI伦理实践具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI在高风险领域的普及，公平性测试变得至关重要，但获取包含人口统计信息的完整数据面临法律、隐私、实用性以及内部历史数据集代表性不足等挑战，导致难以有效识别真实世界的偏见。

**Method:** 作者提出利用单独的重叠数据集来构建包含人口统计信息的完整合成数据。这种方法旨在准确反映受保护属性和模型特征之间的潜在关系。

**Result:** 研究验证了所构建的合成数据与真实数据具有相似的保真度。经验证明，从合成数据中获得的公平性指标与从真实数据中获得的指标保持一致。

**Conclusion:** 这项工作为克服公平性测试中真实世界数据稀缺的问题提供了一条可行的途径，能够实现独立、模型无关的公平性评估，并在真实数据有限时作为有效的替代方案。

> **ai_Abstract:** 本文针对AI公平性测试中真实数据（特别是包含人口统计信息的数据）难以获取和代表性不足的问题，提出了一种创新方法。该方法通过利用独立的重叠数据集来构建包含人口统计信息的完整合成数据，并旨在准确反映受保护属性与模型特征间的关系。研究通过与真实数据对比，验证了合成数据的保真度，并经验性地证明了基于合成数据得出的公平性指标与真实数据一致。这为在数据受限环境下进行独立、模型无关的公平性评估提供了一条可行的路径。

> **摘要翻译:** 随着人工智能在高风险领域和决策制定中的普及，测试潜在的危害和偏见变得至关重要。全球AI法规的出现反映了这种紧迫性，这些法规强调公平性和充分的测试，其中一些甚至强制要求进行独立的偏见审计。然而，获取公平性测试所需的数据仍然是一个重大挑战。特别是在工业环境中，法律和隐私问题限制了评估群体差异所需的人口统计数据的收集，并且审计师在获取数据方面面临实际和文化挑战。此外，内部历史数据集往往代表性不足，无法识别真实世界的偏见。这项工作侧重于在无法访问包含人口统计信息的完整数据集时评估分类器的公平性。我们提出利用单独的重叠数据集来构建包含人口统计信息的完整合成数据，并准确反映受保护属性和模型特征之间的潜在关系。我们通过与真实数据进行比较来验证合成数据的保真度，并经验证明了从此类合成数据中获得的公平性指标与从真实数据中获得的指标一致。因此，这项工作为克服公平性测试中真实世界数据稀缺的问题提供了一条途径，实现了独立、模型无关的公平性评估，并在真实数据有限时作为可行的替代方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [857] [Optimal Transport Regularized Divergences: Application to Adversarial Robustness](https://arxiv.org/abs/2309.03791)
> *最优传输正则化散度：在对抗鲁棒性中的应用*

*Jeremiah Birrell, Reza Ebrahimi* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-24**

**Keywords:** 最优传输, 对抗鲁棒性, 分布鲁棒优化, 深度学习, 散度

**Comment:** 34 pages, 2 figures

> **TL;DR:** 本文提出了一种新的最优传输正则化散度$D^c$，并基于此开发了$ARMOR_D$方法以增强深度学习模型的对抗鲁棒性，通过结合对抗样本传输和动态对抗重加权，在图像识别任务上取得了性能提升。

**AI_Comments:** 本文引入的$ARMOR_D$方法在对抗鲁棒性领域具有创新性，其核心在于结合了最优传输和信息散度，实现了样本的传输和动态重加权。这种“原则性的动态对抗重加权”是其关键创新点，使得方法能够更有效地生成对抗样本和提升模型鲁棒性。该方法对现有最佳表现的损失函数和OT成本进行了泛化，并通过在标准数据集上的实验验证了其有效性，为深度学习模型的鲁棒性研究提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 为了增强深度学习模型的对抗鲁棒性。

**Method:** 本文引入了一类新的最优传输正则化散度$D^c$，通过信息散度$D$与最优传输(OT)成本$C$之间的下卷积构建。在此基础上，提出了$ARMOR_D$方法，将其作为一种分布鲁棒优化(DRO)方法，通过最小化训练数据经验分布的$D^c$邻域内的最大预期损失来定义。$ARMOR_D$允许样本根据OT成本进行传输，并根据信息散度进行重加权，其关键创新在于在对抗样本传输之上增加了原则性的动态对抗重加权。

**Result:** $ARMOR_D$方法在CIFAR-10和CIFAR-100图像识别任务中，对UDR、TRADES和MART方法进行增强，实现了性能提升。具体而言，与强大的对抗攻击集成AutoAttack相比，在CIFAR-10上实现了1.9%的提升，在CIFAR-100上实现了2.1%的提升。

**Conclusion:** 本文引入了最优传输正则化散度的新类别，并提出了$ARMOR_D$方法，该方法通过结合对抗样本传输和动态对抗重加权，为提高深度学习模型的对抗鲁棒性提供了一种新颖且有效的方法，并且能够泛化现有最佳表现的损失函数和OT成本。

> **ai_Abstract:** 本文提出了一种新型最优传输正则化散度$D^c$，并基于此开发了$ARMOR_D$方法，旨在提升深度学习模型的对抗鲁棒性。$ARMOR_D$通过结合最优传输成本下的样本传输和信息散度下的动态对抗重加权，解决了分布鲁棒优化问题。该方法被证明是现有对抗训练方法的一种泛化，并在CIFAR-10和CIFAR-100数据集上，相较于AutoAttack攻击，实现了显著的性能提升。

> **摘要翻译:** 我们引入了一类新的最优传输正则化散度$D^c$，通过信息散度$D$与最优传输(OT)成本$C$之间的下卷积构建，并研究了它们在分布鲁棒优化(DRO)中的应用。具体而言，我们提出了$ARMOR_D$方法作为增强深度学习模型对抗鲁棒性的新颖方法。这些基于DRO的方法通过最小化训练数据经验分布的$D^c$邻域内的最大预期损失来定义。作为构建对抗样本的工具，我们的方法允许样本根据OT成本进行传输，并根据信息散度进行重加权；在对抗样本传输之上添加原则性的动态对抗重加权是$ARMOR_D$的一个关键创新。$ARMOR_D$可以被视为对抗训练文献中表现最佳的损失函数和OT成本的泛化；我们通过使用$ARMOR_D$增强UDR、TRADES和MART方法，并在CIFAR-10和CIFAR-100图像识别上获得改进的性能来证明这种灵活性。具体而言，使用$ARMOR_D$增强后，在CIFAR-10和CIFAR-100上对抗强大的对抗攻击集成AutoAttack分别取得了1.9%和2.1%的提升。为了促进可重现性，我们已将代码公开于https://github.com/star-ailab/ARMOR。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [858] [EarthLink: A Self-Evolving AI Agent for Climate Science](https://arxiv.org/abs/2507.17311)
> *EarthLink：一个用于气候科学的自进化AI代理*

*Zijie Guo, Jiong Wang, Xiaoyu Yue, Wangxu Wei, Zhe Jiang, Wanghan Xu, Ben Fei, Wenlong Zhang, Xinyu Gu, Lijing Cheng, Jing-Jia Luo, Chao Li, Yaqiang Wang, Tao Chen, Wanli Ouyang, Fenghua Ling, Lei Bai* | **Category: cs.LG, cs.AI, physics.ao-ph** | **Updated: 2025-07-24**

**Keywords:** AI代理, 气候科学, 地球系统研究, 自动化, 自进化

**Comment:** 

> **TL;DR:** EarthLink是一个自进化的AI代理，旨在帮助地球科学家自动化研究工作流程，并加速气候科学发现。

**AI_Comments:** EarthLink的创新之处在于其“自进化”和“交互式副驾驶”的特性，使其区别于传统静态工具。它通过自动化端到端工作流程并学习用户交互来提高效率和准确性，这对于加速气候科学发现至关重要。其透明、可审计的流程也增强了可信度，有助于科学家专注于更高层次的思考和假设生成。

<details>
  <summary>Details</summary>

**Motivation:** 现代地球科学面临数据庞大、碎片化、复杂以及分析需求日益复杂的瓶颈，阻碍了快速科学发现。

**Method:** EarthLink是一个交互式AI代理，自动化端到端研究工作流程（从规划到代码生成和多场景分析）。它能通过用户交互学习，并通过动态反馈循环持续改进其能力。

**Result:** EarthLink在气候变化的核心科学任务（如模型-观测比较和复杂现象诊断）上表现良好。多专家评估显示其分析能力与人类初级研究员的特定方面相当，并能产生科学上可靠的分析。

**Conclusion:** EarthLink是迈向高效、可信赖、协作的地球系统研究范式的重要一步，尤其在全球变化加速的时代。

> **ai_Abstract:** EarthLink是一个创新的自进化AI代理，旨在解决地球科学研究中数据复杂性和分析需求带来的瓶颈。它作为一个交互式副驾驶，自动化了从规划到分析的整个研究流程，并通过用户交互持续学习和改进。经过验证，EarthLink在气候科学任务中表现出与人类初级研究员相当的分析能力，有望推动地球系统研究进入一个更高效、可信赖和协作的新范式。

> **摘要翻译:** 现代地球科学正处于一个转折点。地球系统数据庞大、碎片化和复杂，加上日益复杂的分析需求，为快速科学发现制造了显著瓶颈。我们在此介绍EarthLink，这是第一个被设计为地球科学家交互式副驾驶的AI代理。它自动化了端到端的研究工作流程，从规划和代码生成到多场景分析。与静态诊断工具不同，EarthLink可以从用户交互中学习，通过动态反馈循环不断完善其能力。我们验证了它在多项气候变化核心科学任务上的性能，包括模型-观测比较和复杂现象诊断。在多专家评估中，EarthLink产生了科学上可靠的分析，并展示了与人类初级研究员工作流程特定方面相当的分析能力。此外，其透明、可审计的工作流程和自然语言界面使科学家能够从繁重的手动执行转向战略性监督和假设生成。EarthLink标志着在全球变化加速的时代，迈向高效、可信赖和协作的地球系统研究范式的一个关键步骤。该系统可在我们的网站 https://earthlink.intern-ai.org.cn 访问。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [876] [Maximizing Prefix-Confidence at Test-Time Efficiently Improves Mathematical Reasoning](https://arxiv.org/abs/2507.18122)
> *运行时最大化前缀置信度有效提升数学推理能力*

*Matthias Otth, Jonas Hübotter, Ido Hakimi, Andreas Krause* | **Category: cs.LG** | **Updated: 2025-07-24**

**Keywords:** 前缀置信度, 数学推理, 语言模型, 运行时, 自我提升

**Comment:** 

> **TL;DR:** 通过最大化语言模型自身的前缀置信度，无需外部验证即可在运行时有效提升其在数学推理任务上的表现。

**AI_Comments:** 这项工作创新性地利用模型自身的“前缀置信度”进行自我修正和性能提升，避免了对外部验证器或复杂奖励信号的依赖。其在数学推理任务上展现出的显著效果和计算效率优势，特别是对长度偏差的鲁棒性，为语言模型在复杂推理任务上的应用提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 近期研究表明语言模型能通过最大化自身预测置信度实现自我提升。本文旨在研究语言模型在数学推理任务中的运行时扩展，利用模型自身置信度选择最有前景的尝试。

**Method:** 本研究通过评估模型的前缀置信度来选择最有希望的推理路径并继续其生成，以提升语言模型在数学推理任务上的性能。该方法在GSM8K、MATH500、AMC23、AIME24和AIME25这五个数学推理数据集上进行了系统评估，并与多数投票法和BoN进行了比较。

**Result:** 研究发现，仅使用32个token的前缀置信度缩放就能实现显著的性能提升，并在准确性-计算权衡方面优于多数投票法。此外，前缀置信度缩放对长度偏差的敏感度低于BoN。带有前缀置信度的运行时训练虽然优于基础模型，但未超越前缀置信度缩放本身。

**Conclusion:** 在运行时最大化前缀置信度能有效提升语言模型在数学推理任务上的表现，并在准确性-计算权衡方面表现优异，同时对长度偏差具有较好的鲁棒性。

> **ai_Abstract:** 本文提出了一种在数学推理任务中提升语言模型表现的方法，即在运行时通过最大化模型自身的前缀置信度来选择并继续最有希望的推理路径。实验表明，该方法无需外部验证，仅使用少量前缀tokens即可显著提高准确性，并在计算效率和对长度偏差的鲁棒性方面优于传统方法如多数投票法。

> **摘要翻译:** 近期工作表明，语言模型可以通过最大化自身预测的置信度来实现自我提升，而无需依赖外部验证器或奖励信号。在这项工作中，我们研究了语言模型在数学推理任务上的运行时扩展，其中模型的自身置信度被用来选择最有希望的尝试。令人惊讶的是，我们发现仅通过模型的前缀置信度选择最有希望的尝试并继续其推理，就能实现显著的性能提升。我们系统地评估了前缀置信度缩放在五个数学推理数据集上的表现：小学级别的GSM8K和MATH500，以及竞赛级别的AMC23、AIME24和AIME25。我们发现，仅使用32个token的前缀置信度缩放比多数投票法能实现更好的准确性-计算权衡。此外，前缀置信度缩放似乎比BoN对长度偏差的敏感度更低。最后，我们还评估了带有前缀置信度的运行时训练，发现虽然它优于基础模型，但并未超越前缀置信度缩放本身。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [55] [A Distributed Approach for Agile Supply Chain Decision-Making Based on Network Attributes](https://arxiv.org/abs/2507.19038)
> *基于网络属性的敏捷供应链分布式决策方法*

*Mingjie Bi, Dawn M. Tilbury, Siqian Shen, Kira Barton* | **Category: cs.MA, cs.SI, cs.SY, eess.SY** | **Updated: 2025-07-25**

**Keywords:** 敏捷供应链, 分布式决策, 网络属性, 多智能体系统, 供应链中断

**Comment:** 

> **TL;DR:** 本文提出并评估了一种基于多智能体框架的分布式方法，用于在中断情况下实现敏捷供应链决策，并分析了其与网络属性和中心化方法的权衡。

**AI_Comments:** 本文的创新点在于首次将供应链性能与受中断实体的网络属性相结合进行研究，并提出了基于多智能体框架的分布式决策方法，填补了现有研究的空白。其对分布式与中心化决策在不同网络结构下的性能权衡分析，为企业在复杂多变的环境中选择合适的决策策略提供了理论支持和实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 近年来全球供应链频繁受到中断影响，企业需要高效敏捷的决策策略来应对。现有研究分析了中心化和分布式决策的权衡，但缺乏基于受中断供应链实体网络属性来理解供应链性能的研究。

**Method:** 本文从能力和网络拓扑角度刻画供应链，并研究了基于经典多智能体框架的分布式决策方法。通过一个综合案例研究评估了该分布式框架在中断情况下作为网络结构和网络内智能体属性函数的供应链性能。

**Result:** 与中心化决策方法相比，研究结果揭示了基于决策策略和网络架构的性能、计算时间和网络通信之间的权衡。

**Conclusion:** 研究成果可供实践者根据智能体能力、网络属性和期望的供应链性能来设计响应策略。

> **ai_Abstract:** 针对全球供应链频繁中断导致的企业对敏捷决策的需求，本文提出了一种基于多智能体框架的分布式决策方法。该方法从能力和网络拓扑角度刻画供应链，并通过案例研究评估了其在中断情况下作为网络结构和智能体属性函数的供应链性能。研究结果揭示了与中心化方法相比，分布式方法在性能、计算时间与网络通信方面的权衡，为实践者设计响应策略提供了依据。

> **摘要翻译:** 近年来，中断的频繁发生对全球供应链产生了负面影响。为了保持竞争力，企业通过实施高效和有效的决策策略来应对中断，努力保持敏捷性。在开发这些敏捷中断缓解方法方面，已经付出了巨大的努力，利用了中心化和分布式决策策略。尽管现有研究分析了中心化和分布式方法的权衡，但尚未发现关于基于受中断供应链实体的网络属性来理解供应链性能的相关工作。在本文中，我们从能力和网络拓扑角度刻画供应链，并研究了基于经典多智能体框架的分布式决策方法。通过一个综合案例研究评估了该分布式框架的性能，该研究调查了在中断情况下，供应链性能作为网络结构和网络内智能体属性的函数。与中心化决策方法的比较突出了基于决策策略和网络架构的性能、计算时间和网络通信之间的权衡。实践者可以利用我们研究的结果，根据智能体能力、网络属性和期望的供应链性能来设计响应策略。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [57] [Technical Implementation of Tippy: Multi-Agent Architecture and System Design for Drug Discovery Laboratory Automation](https://arxiv.org/abs/2507.17852)
> *Tippy的技术实现：药物发现实验室自动化的多智能体架构与系统设计*

*Yao Fehlis, Charles Crain, Aidan Jensen, Michael Watson, James Juhasz, Paul Mandel, Betty Liu, Shawn Mahon, Daren Wilson, Nick Lynch-Jonely, Ben Leedom, David Fuller* | **Category: cs.MA, cs.AI** | **Updated: 2025-07-18**

**Keywords:** 多智能体系统, 药物发现, 实验室自动化, 微服务, Kubernetes

**Comment:** 

> **TL;DR:** 本文详细介绍了Tippy多智能体系统在药物发现实验室自动化中的技术实现，包括其分布式微服务架构、五种专业智能体、OpenAI Agents SDK编排、Model Context Protocol工具访问、以及基于Kubernetes的生产部署策略，展示了AI智能体如何有效协调复杂的实验室工作流程。

**AI_Comments:** 该论文创新性地将多智能体系统应用于药物发现实验室自动化，提出了一个清晰且模块化的分布式微服务架构。其强调了具体的智能体分工、标准化的协议（MCP）用于工具访问，以及健壮的生产部署策略（Kubernetes, CI/CD），这对于确保系统的可扩展性、可靠性和与现有基础设施的兼容性至关重要。这为未来AI驱动的自动化实验室提供了重要的技术参考和实践经验。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在对其先前关于用于药物研究的代理AI概念框架的基础上，提供Tippy多智能体系统在药物发现实验室自动化方面的全面技术分析和实现细节。

**Method:** 本文介绍了一个分布式微服务架构，包含五个专业智能体（监督者、分子、实验室、分析、报告），这些智能体通过OpenAI Agents SDK进行协调，并通过Model Context Protocol (MCP) 访问实验室工具。系统架构还包括智能体特定的工具集成、异步通信模式和通过Git跟踪的全面配置管理。生产部署策略采用Kubernetes容器编排、Helm charts、Docker容器化和CI/CD流水线进行自动化测试和部署。此外，还集成了向量数据库用于RAG功能，并使用Envoy反向代理实现安全的外部访问。

**Result:** 该系统成功展示了专业AI智能体如何有效地协调复杂的实验室工作流程，同时保持安全性、可伸缩性、可靠性以及通过标准化协议与现有实验室基础设施的集成。

**Conclusion:** 本工作证明了专业AI智能体能够有效地协调复杂的实验室工作流程，同时确保安全性、可伸缩性、可靠性，并通过标准化协议与现有实验室基础设施无缝集成。

> **ai_Abstract:** 本文详细阐述了Tippy多智能体系统在药物发现实验室自动化中的技术实现。该系统采用分布式微服务架构，包含五种专业智能体（监督者、分子、实验室、分析、报告），通过OpenAI Agents SDK进行协调，并利用Model Context Protocol访问实验室工具。其部署策略基于Kubernetes、Helm、Docker和CI/CD，并集成了向量数据库和Envoy反向代理。该工作展示了AI智能体如何有效地协调复杂的实验室工作流程，同时确保安全性、可伸缩性、可靠性以及与现有实验室基础设施的良好集成。

> **摘要翻译:** 本文基于我们之前关于用于药物研究的代理AI概念框架，对Tippy用于药物发现实验室自动化的多智能体系统实现进行了全面的技术分析。我们提出了一个分布式微服务架构，包含五个专业智能体（监督者、分子、实验室、分析和报告），它们通过OpenAI Agents SDK进行编排协调，并通过Model Context Protocol (MCP) 访问实验室工具。系统架构涵盖了智能体特定的工具集成、异步通信模式以及通过Git跟踪的全面配置管理。我们的生产部署策略利用Kubernetes容器编排、Helm charts、Docker容器化和CI/CD流水线进行自动化测试和部署。该实现集成了向量数据库以实现RAG功能，并采用Envoy反向代理进行安全的外部访问。这项工作展示了专业AI智能体如何有效地协调复杂的实验室工作流程，同时通过标准化协议保持安全性、可伸度性、可靠性以及与现有实验室基础设施的集成。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [71] [Assemble Your Crew: Automatic Multi-agent Communication Topology Design via Autoregressive Graph Generation](https://arxiv.org/abs/2507.18224)
> *组建你的团队：通过自回归图生成实现多智能体通信拓扑的自动化设计*

*Shiyuan Li, Yixin Liu, Qingsong Wen, Chengqi Zhang, Shirui Pan* | **Category: cs.MA, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 多智能体系统, 自回归图生成, 通信拓扑设计, 大语言模型, ARG-Designer

**Comment:** 

> **TL;DR:** 本文提出ARG-Designer，一个自回归模型，用于根据自然语言任务查询自动设计多智能体系统的通信拓扑，解决了现有方法对预定义模板的依赖限制，并在多个基准测试中实现了SOTA性能。

**AI_Comments:** 该论文的创新点在于将多智能体系统（MAS）的通信拓扑设计重新定义为条件自回归图生成任务，这克服了现有方法对预定义模板和硬编码结构的依赖。ARG-Designer通过从头生成协作图，实现了高度的灵活性和可扩展性，能够根据具体任务动态调整智能体组成和通信结构，这对于复杂问题的解决至关重要。其在性能、令牌效率和可扩展性方面的提升，预示着未来MAS应用将能更好地适应多样化需求。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于大语言模型的多智能体系统（MAS）设计方法受限于模板图修改范式，依赖预定义的智能体和硬编码的交互结构，导致其对任务特定需求的适应性差。

**Method:** 本文将MAS设计重新定义为条件自回归图生成任务，联合设计系统组成和结构。提出了ARG-Designer，一个新颖的自回归模型，通过从头开始构建协作图，根据自然语言任务查询动态确定所需智能体数量、选择角色并建立最佳通信链接。

**Result:** ARG-Designer在六个不同的基准测试中不仅实现了最先进的性能，而且显著提高了令牌效率和可扩展性。

**Conclusion:** ARG-Designer通过其生成式方法，能够灵活且可扩展地创建定制化的通信拓扑，精确满足不同任务的独特需求，并克服了现有方法的局限性。

> **ai_Abstract:** 本文针对现有大语言模型多智能体系统（MAS）设计在适应性方面的局限性，提出了一种新颖的自回归模型ARG-Designer。该模型将MAS设计重构为条件自回归图生成任务，能够根据自然语言任务查询，从零开始动态地确定智能体数量、角色并构建最优通信拓扑。实验证明，ARG-Designer在多个基准测试中表现出领先的性能，并显著提升了令牌效率和可扩展性，为定制化MAS设计提供了一种灵活且高效的解决方案。

> **摘要翻译:** 基于大型语言模型（LLMs）的多智能体系统（MAS）已成为处理跨领域复杂问题的强大解决方案。MAS的有效性关键取决于其协作拓扑，这已成为自动化设计研究的焦点。然而，现有方法从根本上受限于其对预定义智能体集合和硬编码交互结构的模板图修改范式的依赖，这显著限制了它们对任务特定要求的适应性。为了解决这些限制，我们将MAS设计重新定义为条件自回归图生成任务，其中系统组成和结构被联合设计。我们提出了ARG-Designer，一个新颖的自回归模型，通过从头开始构建协作图来操作这种范式。在自然语言任务查询的条件下，ARG-Designer顺序且动态地确定所需智能体的数量，从可扩展的池中选择合适的角色，并建立它们之间最优的通信链接。这种生成式方法以灵活和可扩展的方式创建定制化的拓扑，精确地适应不同任务的独特需求。在六个不同基准上的广泛实验表明，ARG-Designer不仅实现了最先进的性能，而且享有显著更高的令牌效率和增强的可扩展性。ARG-Designer的源代码可在https://github.com/Shiy-Li/ARG-Designer获取。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [85] [Designing Value-Aligned Traffic Agents through Conflict Sensitivity](https://arxiv.org/abs/2507.18284)
> *通过冲突敏感性设计价值对齐的交通代理*

*Astrid Rakow, Joe Collenette, Maike Schwammberger, Marija Slavkovik, Gleifer Vs Alves* | **Category: cs.MA** | **Updated: 2025-07-24**

**Keywords:** 价值对齐, 交通代理, 冲突敏感性, 认知博弈论, VODDs

**Comment:** Short version of this paper has been accepted at EUMAS 2025
  https://euramas.github.io/eumas2025/

> **TL;DR:** 本文提出了一种通过采用认知博弈论中的冲突形式模型来设计与利益相关者价值观对齐的自动交通代理的方法，将重点从运行时解决道德困境转移到开发阶段预期和构建价值敏感行为。

**AI_Comments:** 本文的创新之处在于将认知博弈论中的冲突形式模型应用于自动交通代理的设计，以解决价值对齐问题。其重要性在于提供了一种在开发阶段而非运行时处理道德困境的系统方法，通过预先识别和结构化价值敏感行为，可能提高自主系统的可信度和接受度。引入VODDs的概念为在不同情境下构建符合价值的自主性提供了框架。

<details>
  <summary>Details</summary>

**Motivation:** 自动交通代理（ATAs）不仅需要安全，还需要在法律、社会和道德维度上与利益相关者的价值观保持一致。

**Method:** 本文采用认知博弈论中已有的冲突形式模型来支持此类代理的开发。研究侧重于价值冲突，并展示了冲突分析如何为设计过程的关键阶段提供信息，包括价值启发、能力规范、解释和自适应系统改进。文章还阐述并应用了“价值对齐操作设计域”（VODDs）的概念来根据上下文价值优先级构建自主性。

**Result:** 结果表明，冲突分析可以为价值启发、能力规范、解释和自适应系统改进等设计过程的关键阶段提供信息。该方法将重点从运行时解决道德困境转移到开发阶段预期和构建价值敏感行为。

**Conclusion:** 本文的方法将设计重点从运行时解决道德困境转移到在开发过程中预测和构建价值敏感行为。

> **ai_Abstract:** 本文提出了一种通过冲突敏感性设计与利益相关者价值观对齐的自动交通代理的方法。研究利用认知博弈论中的冲突形式模型，关注价值冲突，并展示了冲突分析如何指导代理设计过程中的价值启发、能力规范、解释和系统改进。通过引入价值对齐操作设计域（VODDs），该方法将重点从运行时解决道德困境转移到开发阶段对价值敏感行为的预期和结构化。

> **摘要翻译:** 自动交通代理（ATAs）不仅需要安全，还需要在法律、社会和道德维度上与利益相关者的价值观保持一致。在本文中，我们采用了一种来自认知博弈论的既定冲突形式模型来支持此类代理的开发。我们专注于价值冲突——代理面临根植于价值情境中的竞争目标的局面，并展示了冲突分析如何为设计过程的关键阶段提供信息。这包括价值启发、能力规范、解释和自适应系统改进。我们阐述并应用了价值对齐操作设计域（VODDs）的概念，以根据上下文价值优先级构建自主性。我们的方法将重点从运行时解决道德困境转移到在开发过程中预期和构建价值敏感行为。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [104] [Dynamic distributed decision-making for resilient resource reallocation in disrupted manufacturing systems](https://arxiv.org/abs/2507.19043)
> *中断制造系统中弹性资源再分配的动态分布式决策*

*Mingjie Bi, Ilya Kovalenko, Dawn M. Tilbury, Kira Barton* | **Category: cs.MA, cs.SY, eess.SY** | **Updated: 2025-07-25**

**Keywords:** 动态资源分配, 弹性制造, 多智能体系统, 重调度, 风险评估

**Comment:** 

> **TL;DR:** 提出了一种多智能体框架，用于中断制造系统中的动态重调度，该框架具有基于模型的资源智能体架构和风险评估，可减少计算量并提高吞吐量。

**AI_Comments:** 本文的创新点在于提出了基于模型的资源智能体（RA）架构以及通过聚类智能体协调策略将风险评估整合到重调度中。其重要性在于解决了因外部干扰（如疫情）导致的制造系统动态资源分配和重调度问题，提供了一种弹性的分布式解决方案。局限性在于相较于集中式方法，它在降低计算量的同时牺牲了部分吞吐量最优性。

<details>
  <summary>Details</summary>

**Motivation:** 疫情带来了意想不到的干扰，需要灵活实时的制造决策策略来应对动态环境，尤其是在资源中断发生时进行动态资源分配。现有多智能体方法很少研究智能体内部决策过程和资源不确定性。

**Method:** 引入了基于模型的资源智能体（RA）架构，实现了有效的智能体协调和动态智能体决策。基于RA架构，提出了一种通过聚类智能体协调策略纳入风险评估的重调度策略。通过基于仿真的案例研究来验证。

**Result:** 与集中式方法相比，所提出的方法在牺牲部分吞吐量最优性的情况下减少了计算量。此外，将风险评估纳入重调度决策可提高吞吐量。

**Conclusion:** 提出的多智能体框架及其风险评估策略能够有效地应对中断制造系统中的动态重调度问题，在计算效率和吞吐量之间取得平衡，并通过风险评估提高了吞吐量。

> **ai_Abstract:** 本文旨在解决中断制造系统中的动态资源分配和重调度问题。它提出了一种多智能体框架，该框架具有新颖的基于模型的资源智能体（RA）架构，用于有效的协调和动态决策。一个关键贡献是提出了一种通过聚类智能体协调策略整合风险评估的重调度策略。仿真结果表明，所提出的方法在保持合理吞吐量的同时减少了计算量，并且值得注意的是，纳入风险评估可进一步提高吞吐量。

> **摘要翻译:** COVID-19大流行给制造商带来了许多意想不到的干扰，例如市场频繁变化和人力资源有限。为了保持竞争力，需要灵活和实时的制造决策策略来应对这种高度动态的制造环境。一个重要的问题是动态资源分配以完成生产任务，尤其是在发生资源中断（例如机器故障）时。尽管已经提出了多智能体方法以灵活敏捷的方式解决该问题，但智能体内部决策过程和资源不确定性却鲜有研究。这项工作引入了一种基于模型的资源智能体（RA）架构，该架构能够实现有效的智能体协调和动态智能体决策。基于RA架构，还提出了一种通过聚类智能体协调策略纳入风险评估的重调度策略。通过基于仿真的案例研究来演示使用所提出的多智能体框架进行动态重调度。结果表明，与集中式方法相比，所提出的方法在损失部分吞吐量最优性的情况下减少了计算量。此外，案例研究表明，将风险评估纳入重调度决策可以提高吞吐量。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [153] [Heterogeneous Risk Management Using a Multi-Agent Framework for Supply Chain Disruption Response](https://arxiv.org/abs/2507.19049)
> *供应链中断响应中基于多智能体框架的异构风险管理*

*Mingjie Bi, Juan-Alberto Estrada-Garcia, Dawn M. Tilbury, Siqian Shen, Kira Barton* | **Category: cs.MA, cs.SY, eess.SY** | **Updated: 2025-07-25**

**Keywords:** 供应链中断, 异构风险管理, 多智能体系统, 风险态度, 分布式策略

**Comment:** 

> **TL;DR:** 本文提出了一种基于多智能体框架的异构风险管理机制，用于供应链中断响应，考虑了智能体的风险态度和不确定性，并通过仿真验证了其有效性。

**AI_Comments:** 本文的创新点在于提出了异构风险管理机制，并将其应用于多智能体供应链中断响应中，特别强调了考虑个体智能体的风险态度和不确定性，这对于提升供应链韧性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的供应链中断响应文献多忽略了时间动态性和个体智能体风险管理的异构性。

**Method:** 提出了一种异构风险管理机制，将不确定性和风险态度纳入智能体通信和决策策略中，以分布式方式处理随机环境中的中断。

**Result:** 通过模拟案例研究，证明了所提出方法在随机设置下的可行性和有效性，并展示了在智能体持有不同风险态度时，中断响应决策如何变化。

**Conclusion:** 该研究提出了一种有效且可行的异构风险管理机制，能够帮助企业在多智能体环境下以分布式方式应对供应链中断，并考虑了智能体的风险态度。

> **ai_Abstract:** 本文提出了一种在供应链中断响应中，基于多智能体框架的异构风险管理机制。该机制旨在解决现有研究中忽视时间动态性和个体智能体风险管理异构性的问题，通过将不确定性和风险态度融入智能体的通信和决策策略，使企业能够以分布式方式有效应对随机环境中的中断。通过模拟案例研究，验证了该方法在随机环境下的可行性和有效性，并揭示了不同风险态度对中断响应决策的影响。

> **摘要翻译:** 在高度复杂和随机的全球供应链环境中，本地企业智能体寻求分布式和动态策略以敏捷响应中断。现有文献探讨了集中式和分布式方法，但大多数工作忽略了时间动态性和个体智能体风险管理的异构性。为了弥补这一空白，本文提出了一种异构风险管理机制，将不确定性和风险态度纳入智能体通信和决策策略中。因此，这种方法使企业能够以分布式方式处理随机环境中的中断，特别是在多智能体控制和管理背景下。通过一个模拟案例研究，我们展示了所提出方法在随机设置下的可行性和有效性，以及当智能体持有各种风险态度时，中断响应决策如何变化。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [196] [Recognizing and Eliciting Weakly Single Crossing Profiles on Trees](https://arxiv.org/abs/1611.04175)
> *识别和启发树上的弱单交叉偏好剖面*

*Palash Dey* | **Category: cs.MA, cs.AI, cs.DS** | **Updated: 2025-07-24**

**Keywords:** 弱单交叉域, 偏好启发, 算法, 查询复杂度, 社会选择理论

**Comment:** Accepted in TCS journal

> **TL;DR:** 本文引入并研究了树上的弱单交叉域，设计了识别和启发该域偏好剖面的算法，并证明了查询复杂度的下界。

**AI_Comments:** 本文的创新之处在于引入了树上的弱单交叉域，这是对社会选择理论中经典单交叉域的有效推广。其重要性体现在为这一新域设计了实用的识别和启发算法，并提供了严格的理论分析，包括匹配的查询复杂度下界。特别是，它解决了先前研究中的一个开放问题，证明了特定启发算法在随机查询下的最优性，这对于理解和设计高效的偏好启发机制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文引入并研究了树上的弱单交叉域，这是对社会选择理论中已充分研究的单交叉域的推广，旨在解决在该新域中识别和启发偏好剖面的问题。

**Method:** 设计了一个多项式时间算法来识别属于该域的偏好剖面。开发了一种高效的启发算法，即使偏好只能按顺序访问且底层的单交叉树结构未知也能工作。证明了当投票者数量远大于候选人数量时，启发算法查询复杂度的匹配下界。证明了当允许随机查询时，任何算法启发单交叉剖面所需的查询数量的下界为 $\Omega(m^2\log n)$。

**Result:** 设计了识别弱单交叉域偏好剖面的多项式时间算法。开发了高效的启发算法，该算法在顺序访问偏好且未知底层树结构的情况下也能工作。证明了当投票者数量远大于候选人数量时，启发算法查询复杂度的匹配下界。证明了当允许随机查询时，启发单交叉剖面所需查询数量的 $\Omega(m^2\log n)$ 下界，解决了早期论文中的一个开放问题并证明了其偏好启发算法的最优性。

**Conclusion:** 本文成功引入并研究了树上的弱单交叉域，提供了有效的识别和启发算法，并通过严格的下界证明了这些算法的效率和最优性，特别是解决了早期工作中关于随机查询下偏好启发算法最优性的开放问题。

> **ai_Abstract:** 本文引入并研究了树上的弱单交叉偏好域，该域是现有单交叉域的推广。作者提出了一种多项式时间算法用于识别该域内的偏好剖面，并开发了一种高效的启发算法，即使在信息有限的情况下也能工作。此外，文章还为所提出的启发算法证明了查询复杂度的匹配下界，并为允许随机查询时的单交叉剖面启发证明了新的下界，从而解决了先前研究中的一个开放问题，并验证了相关算法的最优性。

> **摘要翻译:** 我们引入并研究了树上的弱单交叉域，这是社会选择理论中已充分研究的单交叉域的推广。我们设计了一个多项式时间算法来识别属于该域的偏好剖面。然后，我们为该域开发了一种高效的启发算法，即使偏好只能按顺序访问且底层的单交叉树结构未知也能工作。我们还证明了当投票者数量与候选人数量相比很大时，我们的启发算法查询复杂度的匹配下界。我们还证明了当允许随机查询时，任何算法启发单交叉剖面所需的查询数量的下界为 $\Omega(m^2\log n)$。这解决了早期论文中的一个开放问题，并证明了当允许随机查询时，它们的偏好启发算法的最优性。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [44] [Differentiable Motion Manifold Primitives for Reactive Motion Generation under Kinodynamic Constraints](https://arxiv.org/abs/2410.12193)
> *运动学动力学约束下反应式运动生成的可微分运动流形原语*

*Yonghyeon Lee* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 可微分运动流形, 反应式运动生成, 运动学动力学约束, 机器人控制, 神经网络

**Comment:** 6 pages and 9 figures

> **TL;DR:** DMMP通过学习可微分运动流形，实现高维机器人快速、满足约束的反应式运动生成。

**AI_Comments:** 该论文的创新之处在于将可微分性引入运动流形原语（DMMP），并且更重要的是，在训练过程中整合了保证约束满足的机制，这比现有方法有了显著改进。这种方法有望为复杂的机器人系统提供更鲁棒和高效的反应式运动生成。

<details>
  <summary>Details</summary>

**Motivation:** 在高维系统下，满足运动学动力学约束的实时运动生成对于实现反应式和自适应行为至关重要，但这是一个关键且具有挑战性的问题。

**Method:** 本文提出了一种两步法：首先，离线学习任务相关且满足约束的低维轨迹流形；然后，在该流形内进行快速在线搜索。他们引入了可微分运动流形原语（DMMP），这是一种新颖的神经网络架构，能够编码和生成连续时间、可微分的轨迹。DMMP利用离线轨迹优化收集的数据进行训练，并采用了一种确保约束满足的策略，这弥补了现有方法的不足。

**Result:** 在7自由度机器人手臂的动态投掷实验中，DMMP在规划速度、任务成功率和约束满足方面均优于现有方法。

**Conclusion:** DMMP有效解决了高维系统实时、受约束运动生成的挑战，并展示出优于现有方法的性能。

> **ai_Abstract:** 本文介绍了可微分运动流形原语（DMMP），这是一种新颖的神经网络架构，用于高维系统在运动学动力学约束下的实时运动生成。DMMP采用两步法：首先离线学习低维、满足约束的轨迹流形，然后进行快速在线搜索。与现有方法不同，DMMP在训练时采用了一种明确确保约束满足的策略。在7自由度机器人手臂上的实验结果表明，DMMP在规划速度、任务成功率和约束遵守方面均优于现有方法。

> **摘要翻译:** 实时运动生成——对于实现反应式和自适应行为至关重要——在高维系统下满足运动学动力学约束是一个关键但具有挑战性的问题。我们通过两步法解决这个问题：首先，离线学习任务相关、满足约束的低维轨迹流形；然后，在该流形内进行快速在线搜索。我们扩展了离散时间运动流形原语（MMP）框架，提出了可微分运动流形原语（DMMP），这是一种新颖的神经网络架构，它编码并生成连续时间、可微分的轨迹。DMMP通过轨迹优化离线收集的数据进行训练，并采用了一种确保约束满足的策略——这是现有方法所缺乏的。在7自由度机器人手臂动态投掷实验中，DMMP在规划速度、任务成功率和约束满足方面均优于现有方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [90] [Towards Multimodal Social Conversations with Robots: Using Vision-Language Models](https://arxiv.org/abs/2507.19196)
> *迈向与机器人的多模态社交对话：使用视觉-语言模型*

*Ruben Janssens, Tony Belpaeme* | **Category: cs.RO, cs.CL, cs.HC** | **Updated: 2025-07-25**

**Keywords:** 社交机器人, 多模态对话, 视觉-语言模型

**Comment:** Submitted to the workshop "Human - Foundation Models Interaction: A
  Focus On Multimodal Information" (FoMo-HRI) at IEEE RO-MAN 2025

> **TL;DR:** 本文探讨了如何利用视觉-语言模型使社交机器人能够进行多模态社交对话，以弥补当前大型语言模型在处理多模态信息方面的不足。

**AI_Comments:** 这篇论文的创新点在于明确提出并论证了视觉-语言模型在实现机器人多模态社交对话中的潜力，填补了现有大型语言模型在处理非文本社交线索方面的空白。它为未来社交机器人的发展指明了一个重要的研究方向，尽管目前仍处于概念和方向探讨阶段，未提供具体实现或实验结果。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型赋予了社交机器人进行开放域对话的能力，但它们仍缺乏利用多模态信息进行社交互动这一基本技能。

**Method:** 本文概述了机器人多模态社交对话系统的整体需求，并提出视觉-语言模型能够以足够通用的方式处理广泛的视觉信息，适用于自主社交机器人。文章还描述了如何调整这些模型以适应此设置，并讨论了现有技术挑战和评估实践。

**Result:** Not mentioned in abstract

**Conclusion:** 视觉-语言模型有望解决社交机器人多模态对话的挑战，但仍存在技术难题和评估实践需进一步探讨。

> **ai_Abstract:** 本文旨在解决当前大型语言模型赋能的社交机器人在多模态社交对话能力上的不足。作者首先指出了多模态社交系统对机器人的整体需求，接着提出视觉-语言模型（VLMs）是处理视觉信息并实现机器人多模态社交对话的有效途径。文章进一步探讨了VLMs在该场景中的适应方法、面临的技术挑战以及相关的评估实践。

> **摘要翻译:** 大型语言模型赋予了社交机器人自主进行开放域对话的能力。然而，它们仍然缺少一项基本的社交技能：利用承载社交互动信息的多种模态。以往的工作侧重于需要引用环境的任务导向型互动，或者社交互动中的特定现象，例如对话中断，而我们则概述了机器人进行社交对话的多模态系统的整体需求。我们随后论证了视觉-语言模型能够以足够通用的方式处理广泛的视觉信息，适用于自主社交机器人。我们描述了如何将它们适应这种设置，仍然存在哪些技术挑战，并简要讨论了评估实践。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [100] [An Efficient Numerical Function Optimization Framework for Constrained Nonlinear Robotic Problems](https://arxiv.org/abs/2501.17349)
> *机器人约束非线性问题的高效数值函数优化框架*

*Sait Sovukluk, Christian Ott* | **Category: cs.RO, math.OC** | **Updated: 2025-07-24**

**Keywords:** 机器人优化, 约束优化, 数值优化, 实时控制, 零空间投影

**Comment:** \c{opyright} 2025 the authors. This work has been accepted to IFAC
  for publication under a Creative Commons Licence CC-BY-NC-ND. -
  Implementation: https://github.com/ssovukluk/ENFORCpp

> **TL;DR:** 本文提出一个用于机器人约束优化问题的实时数值优化框架，结合梯度下降和零空间投影处理约束，无需解析表示，并已开源。

**AI_Comments:** 该论文的创新之处在于提出了一个无需问题解析表示、能处理黑盒约束函数且适用于实时机器人应用的数值优化框架。其结合一阶梯度方法与零空间投影进行约束优先级处理，解决了复杂机器人任务中的实际挑战。开源实现进一步提升了其对社区的价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决机器人领域中约束优化问题，特别是需要实时处理的在线轨迹和控制输入优化问题，且不要求问题的解析表示，能处理黑盒优化函数。

**Method:** 该框架结合了基于一阶梯度的线搜索算法，并通过零空间投影到约束雅可比空间实现约束优先级。

**Result:** 该工具已用C++实现并在线提供社区使用，同时提供了数值和机器人示例实现。

**Conclusion:** 论文提出了一个高效的数值函数优化框架，适用于机器人领域的实时、受约束的非线性黑盒问题，并通过开源实现验证了其有效性。

> **ai_Abstract:** 本文介绍了一个高效的数值函数优化框架，专门用于解决机器人领域的约束非线性问题。该框架以实时性为考量，适用于在线轨迹和控制输入优化，并能处理无需解析表示的黑盒约束优化函数。其核心方法是结合一阶梯度线搜索算法和通过零空间投影实现的约束优先级处理。该工具已用C++实现并开源，并提供了数值和机器人应用示例。

> **摘要翻译:** 本文提出一个数值函数优化框架，专为机器人领域的约束优化问题设计。该工具考虑到实时性，适用于在线轨迹和控制输入优化问题。所提出的框架不需要问题的任何解析表示，并且适用于约束黑盒优化函数。该方法将一阶基于梯度的线搜索算法与通过零空间投影到约束雅可比空间实现约束优先级相结合。该工具已用C++实现并在线提供社区使用，同时本文还提供了一些数值和机器人示例实现。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [106] [PinchBot: Long-Horizon Deformable Manipulation with Guided Diffusion Policy](https://arxiv.org/abs/2507.17846)
> *PinchBot：基于引导扩散策略的长周期可变形操作*

*Alison Bartsch, Arvind Car, Amir Barati Farimani* | **Category: cs.RO** | **Updated: 2025-07-23**

**Keywords:** 可变形操作, 扩散策略, 机器人陶器, 长周期任务, PinchBot

**Comment:** 

> **TL;DR:** PinchBot是一个机器人系统，利用引导扩散策略，通过捏合动作实现长周期可变形物体（如陶器）的精确操作。

**AI_Comments:** 这项工作通过将扩散策略应用于机器人可变形操作，特别是在复杂的陶器制作任务中，展示了其创新性。结合多种技术（点云嵌入、进度预测、碰撞约束）增强了系统的鲁棒性和有效性，为长周期、多模态的变形操作提供了新的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 陶器制作是一种复杂的艺术形式，需要灵巧、精确和精细的动作来将粘土块缓慢变形为有意义的3D目标形状。本文旨在创建一个机器人系统，仅通过捏合动作即可实现简单的陶器制作目标，并探索高度多模态和长周期可变形操作任务的挑战。

**Method:** 本文提出了PinchBot，一个目标条件扩散策略模型。该模型结合了预训练的3D点云嵌入、任务进度预测和碰撞约束动作投影，以实现可变形操作。

**Result:** PinchBot能够成功创建各种简单的陶器目标。

**Conclusion:** 该研究展示了PinchBot在通过捏合动作实现长周期可变形操作任务中的有效性，能够成功制作简单的陶器目标。

> **ai_Abstract:** 本文介绍了PinchBot，一个旨在通过捏合动作实现机器人陶器制作的系统。该系统利用目标条件扩散策略，并结合预训练的3D点云嵌入、任务进度预测和碰撞约束动作投影，以解决长周期可变形操作的复杂挑战。实验证明PinchBot能够成功完成多种简单的陶器目标制作任务。

> **摘要翻译:** 陶器制作是一种复杂的艺术形式，需要灵巧、精确和精细的动作才能将一块粘土缓慢地塑造成一个有意义且通常有用的3D目标形状。在这项工作中，我们旨在创建一个机器人系统，该系统仅通过捏合动作就能创建简单的陶器目标。这项捏合陶器任务使我们能够探索高度多模态和长周期可变形操作任务的挑战。为此，我们提出了PinchBot，一个目标条件扩散策略模型，该模型结合了预训练的3D点云嵌入、任务进度预测和碰撞约束动作投影，能够成功创建各种简单的陶器目标。有关实验视频和演示数据集的访问，请访问我们的项目网站：https://sites.google.com/andrew.cmu.edu/pinchbot/home。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [127] [A Step-by-step Guide on Nonlinear Model Predictive Control for Safe Mobile Robot Navigation](https://arxiv.org/abs/2507.17856)
> *非线性模型预测控制在安全移动机器人导航中的分步指南*

*Dennis Benders, Laura Ferranti, Johannes Köhler* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-23**

**Keywords:** 非线性模型预测控制, 移动机器人导航, 安全, 分步指南, 避障

**Comment:** 51 pages, 3 figures

> **TL;DR:** 本报告提供了一份关于非线性模型预测控制（NMPC）在安全移动机器人导航中应用的分步指南，旨在帮助研究人员和工程师将理论概念应用于实际。

**AI_Comments:** 本报告通过提供NMPC在移动机器人安全导航中的分步实施指南，解决了理论与实践之间的一个关键差距。其创新之处在于其高度实用的性质和对安全性的强调。该报告的“活文档”性质，鼓励社区贡献和错误修正，使其成为一个持续改进和更新的宝贵资源，这在学术出版物中是不常见的。

<details>
  <summary>Details</summary>

**Motivation:** 在充满障碍的环境中设计能安全导航的移动机器人模型预测控制（MPC）方案是一项复杂但至关重要的任务。尽管已有大量关于线性MPC和NMPC的综述，但本报告旨在专门针对NMPC在安全移动机器人导航中的应用，提供一个从理论到实践的实用且易于理解的路径，以弥合理论公式与实际机器人应用之间的差距。

**Method:** 本报告提供了一种分步方法来实施非线性模型预测控制（NMPC）方案，以满足安全要求，即确保机器人在存在干扰和测量噪声的情况下，遵守状态和输入约束并避免与障碍物碰撞。它旨在提供从理论概念到数学证明和实现的实用且易于理解的路径。

**Result:** 本报告的结果是一份关于NMPC在安全移动机器人导航中应用的实用且易于理解的指南，强调了安全性和性能保证，旨在帮助研究人员、机器人工程师和从业者将理论NMPC公式应用于现实世界的机器人应用。

**Conclusion:** 本报告为安全移动机器人导航提供了一份关于非线性模型预测控制（NMPC）的实用分步指南，旨在弥合理论与实际应用之间的差距。它强调安全性和性能保证，并作为一个可更新的文档，鼓励社区反馈以进行改进。

> **ai_Abstract:** 本报告提供了一份关于非线性模型预测控制（NMPC）在安全移动机器人导航中应用的分步指南。它旨在解决在充满障碍物环境中实现机器人安全导航的复杂性，确保机器人在存在干扰和噪声的情况下遵守约束并避免碰撞。不同于全面的综述，本报告专注于NMPC的实际实施，为研究人员和工程师提供从理论到实践的实用路径，强调安全性和性能保证。该文档是一个开放的资源，欢迎社区反馈以进行持续改进。

> **摘要翻译:** 设计一个能使移动机器人在充满障碍的环境中安全导航的模型预测控制（MPC）方案是机器人领域一项复杂但至关重要的任务。在本技术报告中，安全是指确保机器人在存在干扰和测量噪声的情况下，遵守状态和输入约束并避免与障碍物碰撞。本报告提供了一种分步方法来实施满足这些安全要求的非线性模型预测控制（NMPC）方案。许多书籍和综述文章对线性MPC（LMPC）[bemporad2007robust,kouvaritakis2016model]、NMPC[rawlings2017model,allgower2004nonlinear,mayne2014model,grune2017nonlinear,saltik2018outlook]及其在包括机器人技术[nascimento2018nonholonomic,nguyen2021model,shi2021advanced,wei2022mpc]在内的各种领域的应用提供了全面的概述。本报告不旨在复制那些详尽的综述。相反，它专门关注NMPC作为安全移动机器人导航的基础。目标是提供从理论概念到数学证明和实现的实用且易于理解的路径，强调安全性和性能保证。它面向寻求弥合理论NMPC公式与现实世界机器人应用之间差距的研究人员、机器人工程师和从业者。本报告不一定意味着会随着时间保持不变。如果有人发现所提出理论中的错误，请通过提供的电子邮件地址联系。如有必要，我们很乐意更新此文档。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [148] [OpenNav: Open-World Navigation with Multimodal Large Language Models](https://arxiv.org/abs/2507.18033)
> *OpenNav：基于多模态大型语言模型的开放世界导航*

*Mingfeng Yuan, Letian Wang, Steven L. Waslander* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 开放世界导航, 多模态大型语言模型, 机器人, 零样本导航, 价值地图

**Comment:** 

> **TL;DR:** OpenNav利用多模态大型语言模型（MLLMs）实现机器人开放世界导航，通过解释复杂语言指令并生成轨迹点，同时利用MLLMs的代码生成能力与视觉-语言感知模型交互，创建组合式2D鸟瞰图价值地图。

**AI_Comments:** 该论文的创新点在于将多模态大型语言模型（MLLMs）的代码生成能力引入机器人导航，使其能够动态地与视觉-语言感知模型交互，生成价值地图，而非仅仅依赖预定义的运动原语。这显著提升了机器人处理开放集指令和开放集对象的能力，是实现更通用、更智能机器人导航的关键一步。其在真实世界机器人上的验证也增加了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在机器人导航和规划任务中展现出潜力，但在开放世界中，将语言描述与实际机器人动作联系起来，而非仅仅调用有限的预定义运动原语，仍然是一个开放的挑战。

**Method:** 本研究旨在使机器人能够解释和分解复杂的语言指令，最终合成一系列轨迹点以完成多样化的导航任务。研究观察到多模态大型语言模型（MLLMs）在处理自由形式语言指令时表现出强大的跨模态理解和场景理解能力。更重要的是，利用MLLMs的代码生成能力，它们可以与视觉-语言感知模型交互，生成组合式2D鸟瞰图价值地图，有效整合MLLMs的语义知识与地图的空间信息，以增强机器人的空间理解。该方法通过大规模自动驾驶数据集（AVDs）在室外导航任务中验证了其零样本视觉-语言导航框架。

**Result:** 该方法在室外导航任务中展示了其执行各种自由形式自然语言导航指令的能力，同时保持了对物体检测错误和语言歧义的鲁棒性。此外，该系统在室内和室外场景的Husky机器人上进行了验证，展示了其真实世界的鲁棒性和适用性。

**Conclusion:** OpenNav成功地将多模态大型语言模型应用于开放世界机器人导航，通过结合语言理解、代码生成和视觉感知，实现了对复杂指令的鲁棒执行和对开放环境的适应性。

> **ai_Abstract:** OpenNav提出了一种利用多模态大型语言模型（MLLMs）实现开放世界机器人导航的框架。该方法旨在使机器人能够理解和分解复杂的自然语言指令，并将其转化为具体的轨迹点序列。通过利用MLLMs强大的跨模态理解和代码生成能力，系统能够与视觉-语言感知模型交互，生成整合语义与空间信息的2D鸟瞰图价值地图，从而增强机器人的空间理解。在大型自动驾驶数据集和真实机器人上的验证表明，该框架在零样本设置下，能够鲁棒地执行多样化的自然语言导航指令，并抵抗感知误差和语言歧义。

> **摘要翻译:** 预训练的大型语言模型（LLMs）展现出强大的常识推理能力，使其在机器人导航和规划任务中具有广阔前景。然而，尽管近期取得了进展，但在开放世界中，将语言描述与实际机器人动作联系起来，而非仅仅调用有限的预定义运动原语，仍然是一个开放的挑战。在这项工作中，我们旨在使机器人能够解释和分解复杂的语言指令，最终合成一系列轨迹点，以在给定开放集指令和开放集对象的情况下完成多样化的导航任务。我们观察到多模态大型语言模型（MLLMs）在处理自由形式语言指令时展现出强大的跨模态理解能力，并表现出鲁棒的场景理解。更重要的是，利用其代码生成能力，MLLMs可以与视觉-语言感知模型交互，生成组合式2D鸟瞰图价值地图，有效整合MLLMs的语义知识与地图的空间信息，以增强机器人的空间理解。为了进一步验证我们的方法，我们有效利用大规模自动驾驶数据集（AVDs）来验证我们提出的零样本视觉-语言导航框架在室外导航任务中的能力，展示了其执行各种自由形式自然语言导航指令的能力，同时保持了对物体检测错误和语言歧义的鲁棒性。此外，我们还在室内和室外场景的Husky机器人上验证了我们的系统，展示了其真实世界的鲁棒性和适用性。补充视频可在 https://trailab.github.io/OpenNav-website/ 查看。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [156] [Realtime Limb Trajectory Optimization for Humanoid Running Through Centroidal Angular Momentum Dynamics](https://arxiv.org/abs/2501.17351)
> *基于质心角动量动力学的人形机器人奔跑实时肢体轨迹优化*

*Sait Sovukluk, Robert Schuller, Johannes Englsberger, Christian Ott* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 人形机器人, 肢体轨迹优化, 实时, 角动量动力学, 奔跑

**Comment:** This paper has been accepted for publication at the IEEE
  International Conference on Robotics and Automation (ICRA), Atlanta 2025.
  Link to video: https://www.youtube.com/watch?v=czfHjwh_A0Y

> **TL;DR:** 本文提出了一种实时非线性肢体轨迹优化方法，以解决人形机器人在奔跑飞行阶段因肢体摆动不当导致的稳定性问题，并在模拟环境中验证了其有效性。

**AI_Comments:** 本文提出了一种实时非线性肢体轨迹优化方法，解决了人形机器人在高速奔跑时肢体摆动导致的稳定性挑战。其创新性在于将质心角动量动力学应用于肢体轨迹优化，以提高飞行阶段的稳定性。该研究的重要性在于为人形机器人更鲁棒、更快速的奔跑提供了解决方案，特别是在地面反作用力不可用的情况下。局限性可能在于其仅在模拟环境中进行了验证，实际机器人部署可能面临更多挑战。

<details>
  <summary>Details</summary>

**Motivation:** 人形机器人在奔跑的飞行阶段，地面反作用力不可用，肢体摆动轨迹对下一支撑相的稳定性至关重要。不当的腿部和手臂摆动会导致机器人着陆时姿态严重倾斜且不稳定，尤其是在高速高飞行时间轨迹下，系统可能无法独立于质心轨迹稳定性维持运动。

**Method:** 本文提出了一种用于人形机器人奔跑的实时非线性肢体轨迹优化问题。

**Result:** 该优化问题在两种不同的人形机器人模型上进行了测试，并通过在模拟环境中为两种机器人运行算法验证了生成的轨迹。

**Conclusion:** 所提出的实时非线性肢体轨迹优化方法能够有效生成人形机器人奔跑所需的肢体轨迹，并在模拟环境中验证了其在提高机器人稳定性方面的有效性。

> **ai_Abstract:** 本文针对人形机器人在奔跑飞行阶段肢体摆动对稳定性的关键影响，提出了一种实时非线性肢体轨迹优化方法。该方法旨在解决由于角动量守恒导致的不当肢体摆动造成的着陆姿态不稳定问题，尤其适用于高速高飞行时间奔跑。研究在两种人形机器人模型上进行了模拟测试与验证，证实了所生成轨迹的有效性。

> **摘要翻译:** 人形机器人奔跑的一个重要方面是确定肢体摆动轨迹。在飞行阶段，由于地面反作用力不可用于调节，肢体摆动轨迹对于下一支撑相的稳定性至关重要。由于角动量守恒，不当的腿部和手臂摆动会导致在下一支撑相着陆时出现高度倾斜且不可持续的身体构型。在这种情况下，机器人系统无法独立于质心轨迹的稳定性来维持运动。这个问题对于快速和高飞行时间轨迹更为明显。本文提出了一种用于人形机器人奔跑的实时非线性肢体轨迹优化问题。该优化问题在两种不同的人形机器人模型上进行了测试，并在模拟环境中通过运行算法对两种机器人生成的轨迹进行了验证。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [176] [Modular Robot and Landmark Localisation Using Relative Bearing Measurements](https://arxiv.org/abs/2507.18070)
> *模块化机器人与地标使用相对方位测量进行定位*

*Behzad Zamani, Jochen Trumpf, Chris Manzie* | **Category: cs.RO, cs.SY, eess.SP, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 模块化滤波, 机器人定位, 地标定位, 协方差交集, 非线性最小二乘

**Comment:** Submitted to RA-L

> **TL;DR:** 本文提出一种模块化非线性最小二乘滤波方法，用于独立子系统定位，并通过协方差交集算法避免信息重复计算。该方法在机器人-地标定位问题中表现出良好性能，并能通过变体实现通信带宽降低下的性能平稳下降。

**AI_Comments:** 这篇论文的创新点在于提出了一个模块化的滤波框架，它允许独立子系统在存在相互依赖的测量时也能独立更新其状态，并通过整合协方差交集算法有效地解决了信息重复计算的问题。其基于最小二乘的CI算法推导也很有趣。将该方法应用于机器人-地标定位，并证明其在通信受限条件下的性能优雅降级，这对于分布式或资源受限的机器人系统具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决由独立子系统组成的系统中，当相对测量同时依赖于多个子系统状态时，如何独立更新每个子系统的状态和误差协方差估计，并避免信息重复计算的问题。

**Method:** 本文提出一种模块化非线性最小二乘滤波方法。该方法允许每个子系统的状态和误差协方差估计独立更新，即使存在依赖多个子系统状态的相对测量。为防止信息重复计算，集成了协方差交集（CI）算法，并通过最小二乘估计对CI算法进行了替代推导。将此方法应用于机器人-地标定位问题，其中机器人姿态和地标位置的估计问题通过对固定地标的方位角测量进行耦合。

**Result:** 在随机模拟研究中，所提出的模块化方法与整体联合状态滤波器进行了基准测试，以阐明它们各自的权衡。研究还包括了所提出方法的变体，这些变体在降低通信和带宽要求的同时，实现了性能的平稳下降。

**Conclusion:** 该模块化方法在机器人-地标定位问题中表现出与整体联合状态滤波器不同的权衡，并且其变体能够在资源受限的环境下保持性能的平稳下降，具有实际应用价值。

> **ai_Abstract:** 本文提出了一种创新的模块化非线性最小二乘滤波方法，用于处理由独立子系统构成的系统定位问题。该方法通过整合协方差交集算法并基于最小二乘估计进行推导，实现了子系统状态的独立更新同时避免了信息重复计算。特别地，该方法被应用于机器人-地标定位问题，并通过模拟验证了其与传统联合状态滤波器的权衡，并展示了在降低通信带宽下性能平稳下降的变体。

> **摘要翻译:** 本文提出了一种用于由独立子系统组成的系统的模块化非线性最小二乘滤波方法。即使当相对测量同时依赖于多个子系统的状态时，每个子系统的状态和误差协方差估计也能独立更新。我们将协方差交集（CI）算法作为我们解决方案的一部分，以防止当子系统相互共享估计时信息重复计算。基于最小二乘估计的CI算法的另一种推导使得这种集成成为可能。我们将所提出的方法应用于机器人-地标定位问题。在此问题中，对相对于移动机器人SE(2)姿态测量的固定地标位置的方位角的噪声测量，将机器人姿态和地标位置的估计问题耦合起来。在随机模拟研究中，我们将所提出的模块化方法与一个整体联合状态滤波器进行基准测试，以阐明它们各自的权衡。在这项研究中，我们还包括了所提出方法的变体，这些变体在降低通信和带宽要求的同时，实现了性能的平稳下降。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [195] [Monocular Vision-Based Swarm Robot Localization Using Equilateral Triangular Formations](https://arxiv.org/abs/2507.19100)
> *基于单目视觉的等边三角形编队群机器人定位*

*Taewon Kang, Ji-Wook Kwon, Il Bae, Jin Hyo Kim* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-25**

**Keywords:** 群机器人定位, 单目视觉, 等边三角形, 机器人编队, 开放空间

**Comment:** 

> **TL;DR:** 本文提出一种基于等边三角形编队的单目视觉群机器人定位方法，旨在无需外部地标或基础设施支持的开放空间中实现高精度定位，实验证明其定位误差显著小于传统航位推算方法。

**AI_Comments:** 这项工作创新性地将等边三角形编队的几何特性与低成本单目视觉传感器结合，解决了在开放、无外部辅助定位环境下群机器人的高精度定位问题。其重要性在于提供了一种经济且高效的解决方案，特别适用于资源受限的真实世界应用，如搜索救援。该方法的优势在于其对外部环境依赖性低，且在长时间运行下表现出优越的定位精度。

<details>
  <summary>Details</summary>

**Motivation:** 移动机器人的定位对于在搜索救援等实际应用中部署机器人至关重要。本工作旨在为仅配备低成本单目视觉传感器和视觉标记的群机器人开发一个在完全开放空间中、无需地标或定位基础设施支持的准确定位系统。

**Method:** 提出一种基于等边三角形编队的定位方法。通过利用等边三角形的几何特性，使用低成本单目视觉传感器可靠且准确地获取的机器人之间的一维横向距离信息，来估计每个参与机器人的精确二维位置。

**Result:** 实验和仿真结果表明，随着行进时间的增加，所提出的方法的定位误差显著小于传统的航位推算系统（另一种适用于开放环境的低成本定位方法）。

**Conclusion:** 所提出的基于等边三角形编队的单目视觉群机器人定位方法，在开放空间中展现出优于传统航位推算方法的定位精度，尤其在长时间运行下能显著降低定位误差。

> **ai_Abstract:** 本文提出了一种基于等边三角形编队的单目视觉群机器人定位方法，旨在解决在无地标或基础设施支持的开放空间中，利用低成本单目视觉传感器实现群机器人高精度定位的问题。该方法利用等边三角形的几何特性和机器人间的一维横向距离信息来估计二维位置。实验和仿真结果表明，与传统航位推算方法相比，该方法在长时间运行下能显著降低定位误差。

> **摘要翻译:** 移动机器人的定位对于在搜索救援等实际应用中部署机器人至关重要。本工作旨在开发一种适用于仅配备低成本单目视觉传感器和视觉标记的群机器人的精确定位系统。该系统设计用于在完全开放空间中运行，无需地标或定位基础设施的支持。为此，我们提出了一种基于等边三角形编队的定位方法。通过利用等边三角形的几何特性，使用机器人之间的一维横向距离信息来估计每个参与机器人的精确二维位置，这些信息可以通过低成本单目视觉传感器可靠且准确地获取。实验和仿真结果表明，随着行进时间的增加，所提出的方法的定位误差显著小于传统的航位推算系统，后者是另一种适用于开放环境的低成本定位方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [204] [A Modular Residual Learning Framework to Enhance Model-Based Approach for Robust Locomotion](https://arxiv.org/abs/2507.18138)
> *增强基于模型方法的模块化残差学习框架，实现鲁棒运动*

*Min-Gyu Kim, Dongyun Kang, Hajun Kim, Hae-Won Park* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 模块化残差学习, 鲁棒运动, 模型基方法, 学习基方法, 四足机器人

**Comment:** 8 pages, IEEE RA-L accepted (July 2025)

> **TL;DR:** 论文提出一个结合基于模型和基于学习方法的模块化残差学习框架，通过在模型中集成残差模块来弥补模型失配，从而在不确定环境中实现更鲁棒、高效的机器人运动控制，并在实际四足机器人上得到验证。

**AI_Comments:** 这篇论文的创新点在于其模块化的残差学习框架，它巧妙地结合了传统模型方法的可靠性和学习方法的适应性。通过将残差模块嵌入到模型框架中，它有效地解决了模型失配问题，这在机器人控制中是一个普遍挑战。在实际机器人上的验证进一步证明了其在应对不确定性方面的鲁棒性和实用性，这对于机器人领域的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在模型失配时性能下降，需要结合基于模型和基于学习的优点来提高鲁棒运动控制。

**Method:** 提出一个模块化残差学习框架，将残差模块集成到基于模型的步态规划器和动力学模型中，以弥补模型失配导致的性能下降。每个残差模块选择合适的基于学习的方法，并通过在真实四足机器人上结合模型预测控制进行验证。

**Result:** 该框架在高度不确定的环境中表现出改进的控制性能，并比基线方法具有更高的学习效率。此外，它使标称控制器对参数调整更具鲁棒性。在真实四足机器人上，尽管存在模拟之外的不确定性，机器人仍能成功保持平衡并跟踪指令速度。

**Conclusion:** 提出的模块化残差学习框架通过结合基于模型和基于学习的优势，有效提升了机器人在不确定环境中的鲁棒运动控制性能和学习效率，并增强了控制器对参数调整的鲁棒性，在实际机器人上验证了其可行性。

> **ai_Abstract:** 本文提出一种新颖的模块化残差学习框架，旨在结合基于模型和基于学习方法的优势，以实现鲁棒的机器人运动控制。该框架将残差模块集成到基于模型的步态规划器和动力学模型中，有效弥补了模型失配带来的性能损失。通过模块化设计和针对性学习方法，该框架在不确定环境中显著提升了控制性能和学习效率，并增强了控制器对参数调整的鲁棒性。研究在真实四足机器人上验证了其可行性，即使面对复杂不确定性，机器人也能成功保持平衡并跟踪速度指令。

> **摘要翻译:** 本文提出了一种新颖的方法，结合了基于模型和基于学习框架的优点，以实现鲁棒运动。残差模块与基于模型框架的每个相应部分（使用启发式方法设计的足迹规划器和动力学模型）集成，以弥补模型失配导致的性能下降。通过利用模块化结构并为每个残差模块选择合适的基于学习的方法，我们的框架在高度不确定的环境中表现出改进的控制性能，同时与基线方法相比，实现了更高的学习效率。此外，我们观察到我们提出的方法不仅增强了控制性能，还提供了额外的益处，例如使标称控制器对参数调整更具鲁棒性。为了研究我们框架的可行性，我们在真实的四足机器人中展示了与模型预测控制相结合的残差模块。尽管存在超出模拟的不确定性，机器人仍成功保持平衡并跟踪指令速度。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [219] [Safe, Task-Consistent Manipulation with Operational Space Control Barrier Functions](https://arxiv.org/abs/2503.06736)
> *基于操作空间控制障碍函数的安全、任务一致性机械臂操作*

*Daniel Morton, Marco Pavone* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 操作空间控制, 控制障碍函数, 机器人安全, 实时控制, 任务一致性

**Comment:** 

> **TL;DR:** 本文提出了一种操作空间控制障碍函数（OSCBF）框架，用于在非结构化环境中对机器人机械臂进行安全、实时的控制，该框架能够处理大量安全约束，同时保持任务性能，并已在仿真和硬件中得到验证。

**AI_Comments:** 这项工作在机器人安全控制领域具有重要意义。其创新之处在于将控制障碍函数（CBF）的概念扩展到操作空间，并显式地将任务层次结构纳入CBF目标函数中，从而解决了传统CBF方法可能导致的性能下降问题。该方法的高可伸缩性（处理数百个约束）和实时控制能力是其显著优势，使其在复杂、动态的机器人操作环境中具有很强的实用性。开源代码的发布也促进了该领域的研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 在非结构化环境中对机器人机械臂进行安全的实时控制，需要在处理大量安全约束的同时不影响任务性能。传统的APF方法存在局部最小值、振荡和可伸缩性有限的问题，而MPC计算成本高昂。虽然CBF具有鲁棒性高和计算成本低的优点，但其设计必须小心，以避免显著降低机械臂的整体性能。

**Method:** 本文引入了一种操作空间控制障碍函数（OSCBF）框架，该框架集成了安全约束，同时保持了任务一致性行为。通过在CBF目标中明确考虑任务层次结构，防止了在安全极限下关节空间和操作空间任务的性能下降。

**Result:** 该方法能够扩展到数百个同时存在的约束，同时保持实时控制速率，确保在高度杂乱的环境或动态运动中也能避免碰撞、防止奇异点和限制工作空间。性能已在仿真和硬件中得到验证，并发布了开源代码。

**Conclusion:** 本文提出的OSCBF框架为机器人机械臂在复杂环境中的安全、实时控制提供了一种有效且高性能的解决方案，解决了传统方法在可伸缩性、计算成本和性能下降方面的挑战。

> **ai_Abstract:** 本文提出了一种名为操作空间控制障碍函数（OSCBF）的新框架，旨在解决在非结构化环境中机器人机械臂安全实时控制的挑战。该框架通过整合安全约束并显式考虑任务层次结构，克服了传统方法（如APF和MPC）的局限性，实现了在保持任务性能的同时处理数百个并发约束。OSCBF确保了碰撞避免、奇异点预防和工作空间限制，已在仿真和硬件中得到验证，并提供了开源实现。

> **摘要翻译:** 在非结构化环境中对机器人机械臂进行安全的实时控制，需要在处理大量安全约束的同时不影响任务性能。传统的APF方法（如人工势场）存在局部最小值、振荡和可伸缩性有限的问题，而模型预测控制（MPC）可能计算成本高昂。控制障碍函数（CBF）因其高鲁棒性和低计算成本而提供了一种有前景的替代方案，但这些安全滤波器必须精心设计，以避免显著降低机械臂的整体性能。在这项工作中，我们引入了一种操作空间控制障碍函数（OSCBF）框架，该框架集成了安全约束，同时保持了任务一致性行为。我们的方法可以扩展到数百个同时存在的约束，同时保持实时控制速率，确保即使在高度杂乱的环境或动态运动中也能避免碰撞、防止奇异点和限制工作空间。通过在CBF目标中明确考虑任务层次结构，我们在安全极限下防止了关节空间和操作空间任务的性能下降。我们在仿真和硬件中验证了性能，并在我们的项目网页上发布了开源高性能代码和媒体，https://stanfordasl.github.io/oscbf/

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [232] [Autonomous UAV Navigation for Search and Rescue Missions Using Computer Vision and Convolutional Neural Networks](https://arxiv.org/abs/2507.18160)
> *使用计算机视觉和卷积神经网络的自主无人机导航用于搜救任务*

*Luka Šiktar, Branimir Ćaran, Bojan Šekoranja, Marko Švaco* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 无人机, 搜救, 计算机视觉, 卷积神经网络, 目标跟踪

**Comment:** The paper is accepted and presented on the 34th International
  Conference on Robotics in Alpe-Adria-Danube Region, RAAD 2025, Belgrade
  Serbia

> **TL;DR:** 该论文提出了一种基于计算机视觉和卷积神经网络的无人机子系统，用于搜救任务中的人员检测、人脸识别和跟踪。

**AI_Comments:** 创新点在于结合了多种先进的CNN模型（YOLOv11, YOLOv11-pose, dlib）与ROS2框架，实现了无人机在搜救任务中的自主人员检测、识别和跟踪，并考虑了实时性和距离保持。其手动标记未知人员的功能增加了系统的灵活性。局限性在于目前仅在14名已知个体上进行了初步实验，大规模和复杂环境下的表现仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 在搜救任务中，需要高效、自主地进行人员检测、人脸识别和目标跟踪。

**Method:** 该方案整合了无人机与ROS2框架，利用YOLOv11、YOLOv11-pose和dlib库中的卷积神经网络进行人员检测、人体关键点识别和人脸识别。通过系统识别和PD控制器实现无人机自主导航，并利用YOLOv11-pose估计与目标的距离。系统支持操作员手动标记未知人员并启动跟踪。

**Result:** 在对14名已知个体的初步实验中，所提出的子系统被证明可以成功实时使用。

**Conclusion:** 该子系统能够实时用于搜救任务，未来的工作包括在大型实验无人机上实现系统以及将自主导航与GPS引导控制集成用于救援行动规划。

> **ai_Abstract:** 本文介绍了一个用于搜救任务的无人机自主导航子系统。该系统整合了无人机与ROS2框架，并利用YOLOv11、YOLOv11-pose和dlib等卷积神经网络实现人员检测、人脸识别和目标跟踪。通过系统识别和PD控制器，无人机能够自主导航并保持与目标的安全距离。实验证明该系统能实时有效跟踪已知个体，未来计划扩展至大型无人机并结合GPS导航。

> **摘要翻译:** 在本文中，我们提出了一个使用无人机（UAV）的子系统，用于搜救任务，重点关注人员检测、人脸识别和对已识别个体的跟踪。所提出的解决方案将无人机与ROS2框架集成，该框架利用多个卷积神经网络（CNN）进行搜索任务。为了实现自主无人机导航，进行了系统识别和PD控制器部署。ROS2环境利用YOLOv11和YOLOv11-pose CNN进行跟踪，以及dlib库CNN进行人脸识别。该系统检测特定个体，执行人脸识别并开始跟踪。如果该个体尚不为人知，无人机操作员可以手动定位该人员，保存其面部图像并立即启动跟踪过程。跟踪过程依赖于使用YOLOv11-pose CNN模型在人体上识别出的特定关键点。这些关键点用于跟踪特定个体并保持安全距离。为了提高跟踪精度，基于无人机IMU的测量数据进行了系统识别。识别出的系统参数用于设计PD控制器，该控制器利用YOLOv11-pose估计无人机摄像头与被识别个体之间的距离。对14名已知个体进行的初步实验表明，所提出的子系统可以成功实时使用。下一步工作包括在大型实验无人机上实现该系统以进行现场使用，并将自主导航与GPS引导控制集成，用于救援行动规划。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [252] [Compositional Coordination for Multi-Robot Teams with Large Language Models](https://arxiv.org/abs/2507.16068)
> *基于大型语言模型的多机器人团队组合式协同*

*Zhehui Huang, Guangyao Shi, Yuwei Wu, Vijay Kumar, Gaurav S. Sukhatme* | **Category: cs.RO, cs.AI, cs.LG, cs.MA** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 多机器人协同, 自然语言处理, 行为树, 代码生成

**Comment:** 9 pages, 4 figures

> **TL;DR:** 该研究提出LAN2CB框架，利用大型语言模型将自然语言任务描述直接转化为多机器人可执行代码，从而简化并通用化多机器人协同过程，减少人工投入并提高灵活性。

**AI_Comments:** 这篇论文的创新点在于将大型语言模型引入多机器人协同领域，通过自动化自然语言到代码的转换过程，极大地降低了多机器人系统开发的门槛和复杂性。其提出的LAN2CB框架，特别是行为树作为中间表示的应用，为复杂的任务解析和代码生成提供了结构化的方法。这项工作对于推动多机器人系统从专家驱动向更通用、更灵活、更易用的方向发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的多机器人协同方法依赖于任务特定且专家驱动的流程，需要人工将自然语言任务描述转换为数学公式、算法设计和可执行代码。这种方法劳动密集、对非专家不友好且对任务需求变化不灵活。

**Method:** 本文提出了LAN2CB（Language to Collective Behavior）框架，该框架利用大型语言模型（LLMs）来简化和通用化多机器人协同流程。LAN2CB通过两个核心模块将自然语言任务描述转换为多机器人系统的可执行Python代码：1) 任务分析模块，将任务描述解析为行为树；2) 代码生成模块，利用行为树和结构化知识库生成机器人控制代码。此外，研究还引入了一个自然语言任务描述数据集以支持开发和基准测试。

**Result:** 在模拟和真实环境中的实验表明，LAN2CB能够实现从自然语言进行鲁棒且灵活的多机器人协同，显著减少了人工工程投入，并支持跨不同任务类型的广泛泛化。

**Conclusion:** LAN2CB框架通过利用大型语言模型，成功地将自然语言任务描述转化为多机器人可执行代码，从而提供了一种更高效、更通用且更易于访问的多机器人协同解决方案，克服了传统方法的局限性。

> **ai_Abstract:** 本论文提出了LAN2CB框架，旨在通过利用大型语言模型（LLMs）自动化多机器人协同过程。该框架将自然语言任务描述转换为可执行的Python代码，解决了传统方法劳动密集且不灵活的问题。LAN2CB包含任务分析（将NL解析为行为树）和代码生成（基于行为树和知识库生成代码）两个模块。实验证明，LAN2CB能够实现鲁棒、灵活的多机器人协同，减少人工投入并提高泛化能力。

> **摘要翻译:** 多机器人协同传统上依赖于任务特定和专家驱动的流程，其中自然语言任务描述由领域专家手动转换为数学公式、算法设计和可执行代码。这种传统过程劳动密集、对非专家不友好，并且对任务需求的变化缺乏灵活性。在此，我们提出了LAN2CB（Language to Collective Behavior），一个利用大型语言模型（LLMs）来简化和通用化多机器人协同流程的新颖框架。LAN2CB通过两个核心模块将自然语言（NL）任务描述转换为多机器人系统的可执行Python代码：(1) 任务分析模块，将任务描述解析为行为树；(2) 代码生成模块，利用行为树和结构化知识库生成机器人控制代码。我们进一步引入了一个自然语言任务描述数据集以支持开发和基准测试。在模拟和真实环境中的实验表明，LAN2CB能够实现从自然语言进行鲁棒且灵活的多机器人协同，显著减少了人工工程投入，并支持跨不同任务类型的广泛泛化。网站：https://sites.google.com/view/lan-cb

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [264] [MoRPI-PINN: A Physics-Informed Framework for Mobile Robot Pure Inertial Navigation](https://arxiv.org/abs/2507.18206)
> *MoRPI-PINN：一种用于移动机器人纯惯性导航的物理信息框架*

*Arup Kumar Sahoo, Itzik Klein* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 物理信息神经网络, 惯性导航, 移动机器人, 导航漂移, MoRPI-PINN

**Comment:** 9 pages, 5 figures

> **TL;DR:** MoRPI-PINN是一个基于物理信息神经网络的框架，用于提高移动机器人在无卫星/摄像头环境下纯惯性导航的精度。

**AI_Comments:** 这篇论文的创新点在于将物理信息神经网络（PINN）应用于移动机器人纯惯性导航，有效地利用了物理定律来约束模型训练，从而显著提高了在无外部辅助情况下的导航精度。其轻量级特性也使其在实际应用中具有较高的部署潜力，尤其是在资源受限的边缘设备上。

<details>
  <summary>Details</summary>

**Motivation:** 移动机器人在卫星导航或摄像头不可用的情况下，准确导航是一个基本要求。仅依赖惯性传感器会导致导航漂移，因为传感器固有的噪声和误差。

**Method:** 本文提出了一种名为MoRPI-PINN的物理信息神经网络（PINN）框架，用于基于惯性的移动机器人导航。该方法通过在训练过程中嵌入物理定律和约束，旨在提供准确且鲁棒的导航解决方案。

**Result:** 通过真实世界实验，MoRPI-PINN的导航精度比其他方法提高了85%以上。

**Conclusion:** MoRPI-PINN是一种轻量级方法，即使在边缘设备上也能实现，并可用于任何典型的移动机器人应用，提供准确和鲁棒的纯惯性导航解决方案。

> **ai_Abstract:** 本文提出了MoRPI-PINN，一个基于物理信息神经网络的框架，旨在解决移动机器人在无外部定位辅助（如GPS或摄像头）时纯惯性导航的漂移问题。通过将物理定律和约束融入训练过程，MoRPI-PINN显著提高了导航精度和鲁棒性。实验结果显示，其精度比现有方法提升超过85%，且该方法轻量化，适用于边缘设备和各种移动机器人应用。

> **摘要翻译:** 移动机器人实现完全自主的一个基本要求是即使在卫星导航或摄像头不可用的情况下也能进行精确导航。在这些实际情况下，仅依赖惯性传感器会导致导航解决方案因传感器固有的噪声和误差项而发生漂移。缓解漂移的一种新兴解决方案是让机器人进行蛇形滑行运动，以增加惯性信噪比，从而实现移动机器人位置的回归。在这项工作中，我们提出了MoRPI-PINN作为一种物理信息神经网络框架，用于精确的基于惯性的移动机器人导航。通过在训练过程中嵌入物理定律和约束，MoRPI-PINN能够提供准确而鲁棒的导航解决方案。通过真实世界实验，我们展示了与其它方法相比超过85%的精度提升。MoRPI-PINN是一种轻量级方法，甚至可以在边缘设备上实现，并可用于任何典型的移动机器人应用。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [282] [Learning Gentle Grasping Using Vision, Sound, and Touch](https://arxiv.org/abs/2503.07926)
> *利用视觉、声音和触觉学习轻柔抓取*

*Ken Nakahara, Roberto Calandra* | **Category: cs.RO, cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 轻柔抓取, 多模态学习, 机器人技术, 触觉感知, 听觉反馈

**Comment:** 8 pages. Accepted by 2025 IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS)

> **TL;DR:** 该论文提出了一种利用视觉、声音和触觉信号学习轻柔抓取的方法，旨在处理易碎物品，并展示了优越的性能和显著的工程量减少。

**AI_Comments:** 这篇论文在机器人抓取领域提出了创新的多模态（视觉、声音、触觉）感知融合方法，以解决轻柔抓取易碎物品的关键挑战。将音频作为轻柔度的直接指标尤其新颖和实用。此外，该方法通过避免传感器校准和分析建模，显著减少了工程工作量，这对于机器人技术的实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在日常生活中，我们经常遇到易碎物品（如水果），它们可能因过度抓取力而受损。因此，对于这些物品，关键在于轻柔抓取——不使用最大可能的力量，而是使用必要的最小力量。

**Method:** 本文提出利用视觉、触觉和听觉信号来学习稳定且轻柔地抓取和重新抓取物体。具体而言，使用音频信号作为抓取过程中轻柔度的指标，然后从原始视觉-触觉输入训练一个端到端、动作条件的模型，该模型预测未来抓取候选的稳定性和轻柔度，从而允许选择和执行最有希望的动作。

**Result:** 在多指机械手进行的1500多次抓取试验中，实验结果表明该模型对于轻柔抓取非常有用，验证了其预测性能（比仅视觉方案高3.27%的准确率），并提供了其行为的解释。最终，真实世界实验证实，使用训练后的多模态模型进行抓取性能优于其他基线（稳定和轻柔抓取的成功率比仅视觉方案高17%）。

**Conclusion:** 该方法无需触觉传感器校准或分析力建模，大大减少了抓取易碎物品的工程量。这表明所提出的多模态方法能够有效学习轻柔抓取，并显著降低实际部署的复杂性。

> **ai_Abstract:** 本文提出了一种新颖的机器人轻柔抓取易碎物体的方法，通过整合视觉、触觉和听觉多模态感知输入实现。该研究训练了一个端到端模型，其中音频信号作为轻柔度的指示器，从而能够预测抓取的稳定性和轻柔度。实验结果表明，与仅依赖视觉的方法相比，该方法在预测准确性和真实世界抓取性能上均表现出卓越的性能，并强调了其无需传感器校准或力学建模的效率。

> **摘要翻译:** 在我们的日常生活中，我们经常遇到易碎且可能因过度抓取力而受损的物体，例如水果。对于这些物体，轻柔抓取至关重要——不是使用最大可能的力量，而是使用必要的最小力量。本文提出利用视觉、触觉和听觉信号来学习稳定且轻柔地抓取和重新抓取物体。具体而言，我们使用音频信号作为抓取过程中轻柔度的指标，然后从原始视觉-触觉输入训练一个端到端、动作条件的模型，该模型预测未来抓取候选的稳定性和轻柔度，从而允许选择和执行最有希望的动作。在多指机械手进行的1500多次抓取试验中，实验结果表明我们的模型对于轻柔抓取非常有用，验证了其预测性能（比仅视觉方案高3.27%的准确率），并提供了其行为的解释。最终，真实世界实验证实，使用训练后的多模态模型进行抓取性能优于其他基线（稳定和轻柔抓取的成功率比仅视觉方案高17%）。我们的方法无需触觉传感器校准或分析力建模，大大减少了抓取易碎物品的工程量。数据集和视频可在https://lasr.org/research/gentle-grasping获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [295] [Evaluation of facial landmark localization performance in a surgical setting](https://arxiv.org/abs/2507.18248)
> *评估面部标志点定位在手术环境中的表现*

*Ines Frajtag, Marko Švaco, Filip Šuligoj* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 面部标志点定位, 手术环境, MediaPipe, 计算机视觉, 机器人辅助

**Comment:** 

> **TL;DR:** 研究在手术环境下，MediaPipe算法在可变光照和姿态下进行面部标志点检测的性能。

**AI_Comments:** 这篇论文通过在受控手术环境中评估MediaPipe算法，为计算机视觉在医疗领域的实际应用提供了重要见解。其创新点在于模拟了手术中光照和姿态变化的复杂性。尽管指出了部分标志点检测的局限性，但其发现的性能提升对于未来将该技术整合到实际医疗程序中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有面部检测算法在医学应用中面临可变光照条件和检测位置灵活性的挑战，需要精确识别和定位患者。

**Method:** 通过一个受控实验来测试MediaPipe算法，实验中使用机械臂自动调整位置，而手术灯和模型保持固定，以模拟手术环境。

**Result:** 在手术光照下，面部标志点检测的准确性提高，显著增强了在大偏航角和俯仰角下的检测性能；但选定面部标志点的检测不精确导致标准差/离散度增加。

**Conclusion:** 该分析为MediaPipe算法在医疗程序中的潜在整合提供了讨论基础。

> **ai_Abstract:** 本研究评估了MediaPipe算法在模拟手术环境下进行面部标志点定位的性能。针对现有算法在可变光照和姿态下的挑战，实验通过机械臂调整姿态，在固定手术光照下测试了MediaPipe。结果显示，在手术光照下，算法在较大偏航角和俯仰角时检测性能显著提高，尽管部分标志点检测仍存在不精确性。研究讨论了MediaPipe在医疗程序中应用的潜力。

> **摘要翻译:** 机器人技术、计算机视觉及其应用在包括医学在内的各个领域中变得越来越广泛。许多人脸检测算法已在神经外科、眼科和整形外科中找到应用。使用这些算法的一个常见挑战是可变的光照条件和检测位置的灵活性，以识别和精确地定位患者。所提出的实验在受控环境中测试了MediaPipe算法检测面部标志点的性能，该实验使用机械臂自动调整位置，而手术灯和模型保持固定。这项研究的结果表明，在手术光照下，面部标志点检测的准确性提高，显著增强了在大偏航角和俯仰角下的检测性能。标准差/离散度的增加是由于选定面部标志点的不精确检测所致。这项分析为讨论MediaPipe算法在医疗程序中的潜在整合提供了基础。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [323] [ReSem3D: Refinable 3D Spatial Constraints via Fine-Grained Semantic Grounding for Generalizable Robotic Manipulation](https://arxiv.org/abs/2507.18262)
> *ReSem3D：通过细粒度语义接地实现可泛化机器人操作的可优化3D空间约束*

*Chenyu Su, Weiwei Shang, Chen Qian, Fei Zhang, Shuang Cong* | **Category: cs.RO, cs.AI, cs.CV, cs.HC, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 机器人操作, 3D空间约束, 语义接地, MLLMs, VFMs

**Comment:** 12 pages,9 figures

> **TL;DR:** ReSem3D是一个统一的机器人操作框架，通过结合多模态大语言模型（MLLMs）和视觉基础模型（VFMs），动态构建分层3D空间约束，以解决现有方法在语义粒度、实时规划和鲁棒性方面的限制，实现零样本条件下的泛化操作。

**AI_Comments:** ReSem3D的创新之处在于其通过结合MLLMs和VFMs实现了细粒度语义接地和分层3D空间约束的动态构建。这有效解决了现有方法在机器人操作中面临的语义粗糙、缺乏实时性和鲁棒性差等关键挑战。其在零样本条件下的泛化能力和对动态扰动的反应性是其重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在3D空间约束建模中存在三个主要限制：(1) 语义粒度粗糙；(2) 缺乏实时闭环规划；(3) 在语义多样化环境中的鲁棒性受损。

**Method:** ReSem3D是一个统一的操作框架，利用视觉基础模型（VFMs）和多模态大语言模型（MLLMs）的协同作用，实现细粒度视觉接地，并动态构建分层3D空间约束以进行实时操作。该框架由MLLMs中的分层递归推理驱动，通过与VFMs交互，从自然语言指令和RGB-D观测中分两阶段（部分级提取和区域级细化）自动构建3D空间约束。随后，这些约束被编码为关节空间中的实时优化目标，以实现对动态扰动的反应行为。

**Result:** ReSem3D在语义丰富的家庭和稀疏的化学实验室环境中进行了广泛的模拟和真实世界实验。结果表明，ReSem3D在零样本条件下执行了多样化的操作任务，表现出强大的适应性和泛化能力。

**Conclusion:** ReSem3D成功解决了现有方法在语义粒度、实时规划和鲁棒性方面的限制，通过细粒度语义接地和动态分层3D空间约束实现了可泛化、适应性强的机器人操作。

> **ai_Abstract:** ReSem3D是一个创新的机器人操作框架，旨在通过解决现有方法在语义粒度、实时规划和环境鲁棒性方面的不足来提升可泛化能力。该框架利用多模态大语言模型（MLLMs）和视觉基础模型（VFMs）的协同作用，从自然语言和视觉数据中动态构建细粒度、分层的3D空间约束。这些约束被实时优化，使机器人能够对动态扰动做出反应。实验证明，ReSem3D在零样本条件下，在多种复杂环境中展现出强大的任务执行能力、适应性和泛化性。

> **摘要翻译:** 语义驱动的3D空间约束将高级语义表示与低级动作空间对齐，促进了机器人操作中任务理解和执行的统一。多模态大语言模型（MLLMs）和视觉基础模型（VFMs）的协同推理使得跨模态3D空间约束的构建成为可能。然而，现有方法存在三个关键限制：(1) 约束建模中的语义粒度粗糙；(2) 缺乏实时闭环规划；(3) 在语义多样化环境中的鲁棒性受损。为了解决这些挑战，我们提出了ReSem3D，一个用于语义多样化环境的统一操作框架，它利用VFMs和MLLMs之间的协同作用，实现细粒度视觉接地，并动态构建分层3D空间约束以进行实时操作。具体而言，该框架由MLLMs中的分层递归推理驱动，MLLMs与VFMs交互，通过两个阶段（部分级提取和区域级细化）从自然语言指令和RGB-D观测中自动构建3D空间约束。随后，这些约束被编码为关节空间中的实时优化目标，从而实现对动态扰动的反应行为。在语义丰富的家庭和稀疏的化学实验室环境中进行了广泛的模拟和真实世界实验。结果表明，ReSem3D在零样本条件下执行了多样化的操作任务，表现出强大的适应性和泛化能力。代码和视频可在https://github.com/scy-v/ReSem3D 和 https://resem3d.github.io 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [345] [B4P: Simultaneous Grasp and Motion Planning for Object Placement via Parallelized Bidirectional Forests and Path Repair](https://arxiv.org/abs/2504.04598)
> *B4P：通过并行双向森林和路径修复实现物体放置的同步抓取和运动规划*

*Benjamin H. Leebron, Kejia Ren, Yiting Chen, Kaiyu Hang* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 抓取规划, 运动规划, 物体放置, 双向森林, 机器人

**Comment:** 

> **TL;DR:** B4P提出了一种新的同步抓取和运动规划框架，通过并行双向森林和路径修复，解决了传统机器人抓取-放置系统中抓取与运动规划解耦导致的次优问题，显著提高了在杂乱环境中的效率和鲁棒性。

**AI_Comments:** 该论文的关键创新在于提出了一个同步规划抓取和运动的框架，这直接解决了传统方法中抓取与运动规划解耦所带来的次优性问题。其利用并行双向森林的设计，不仅在理论上更优，而且在实际应用中展现出超线性加速的潜力，对于在复杂、杂乱环境中部署高自由度机器人具有重要意义。这一方法有望显著提高机器人操作的效率和成功率。

<details>
  <summary>Details</summary>

**Motivation:** 传统的机器人抓取和放置系统将抓取、放置和运动规划解耦，形成顺序优化流程，但这导致了次优性，因为抓取选择可能会限制甚至阻止机器人在杂乱环境中到达目标放置姿态的可行运动。

**Method:** 本文提出了一个基于森林的规划框架（B4P），通过并行双向森林和路径修复，同步寻找抓取配置和可行的机器人运动。该框架利用双向采样方法构建起始森林（根植于可行抓取区域）和目标森林（根植于可行放置区域），以连接有效的抓取和放置树对。

**Result:** 该框架固有的并行性实现了超线性加速，使其适用于冗余机械臂（如7自由度）在高度杂乱环境中高效工作。仿真中的大量实验表明，与多个基线相比，所提出的框架在不同场景下具有鲁棒性和效率。

**Conclusion:** B4P框架通过同步规划抓取和运动，克服了传统解耦方法的局限性，实现了在复杂环境中机器人抓取和放置任务的鲁棒、高效和可扩展解决方案。

> **ai_Abstract:** B4P提出了一种创新的基于森林的规划框架，用于同步进行机器人抓取和运动规划，以解决传统解耦方法在物体放置任务中导致的次优问题。通过构建并行双向森林来连接抓取和放置区域，该方法能够高效地在杂乱环境中为冗余机械臂找到可行的抓取和运动路径。实验结果验证了其在复杂场景下的鲁棒性和效率。

> **摘要翻译:** 机器人抓取和放置系统传统上将抓取、放置和运动规划解耦，以构建顺序优化流程，并假设各个组件能够协同工作。然而，这种分离引入了次优性，因为抓取选择可能会限制甚至禁止机器人到达目标放置姿态的可行运动，尤其是在狭窄通道的杂乱环境中。为此，我们提出了一种基于森林的规划框架，以同步寻找抓取配置和可行的机器人运动，这些运动明确满足与所选抓取配对的下游放置配置。我们提出的框架利用双向采样方法构建一个起始森林（根植于可行抓取区域）和一个目标森林（根植于可行放置区域），以促进通过随机探索的运动连接有效的抓取和放置树对的搜索。我们证明了该框架固有的并行性能够实现超线性加速，使其适用于冗余机械臂（例如7自由度）在高度杂乱环境中高效工作的应用。在仿真中的大量实验表明，与多个基线相比，所提出的框架在不同场景下具有鲁棒性和效率。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [351] [Adaptive Articulated Object Manipulation On The Fly with Foundation Model Reasoning and Part Grounding](https://arxiv.org/abs/2507.18276)
> *基于基础模型推理和部件接地的自适应铰接物体实时操作*

*Xiaojie Zhang, Yuanfei Wang, Ruihai Wu, Kunqi Xu, Yu Li, Liuyu Xiang, Hao Dong, Zhaofeng He* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 铰接物体操作, 基础模型, 部件接地, 可供性, 机器人操作

**Comment:** ICCV 2025

> **TL;DR:** AdaRPG是一个新颖的框架，利用基础模型和部件级可供性来解决铰接物体操作中的几何多样性和功能变异性挑战，并在模拟和现实世界中展示了强大的泛化能力。

**AI_Comments:** 本文的创新点在于利用基础模型进行部件提取和机制推理，从而有效解决了铰接物体操作中视觉感知和统一策略开发的关键难题。通过关注部件而非整个物体，AdaRPG提升了操作的泛化能力，为机器人处理复杂、多样化的铰接物体提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 铰接物体对机器人操作构成多样化挑战，因为其内部结构不可直接观察，机器人必须自适应探索和改进动作。现有工作在自适应铰接物体操作中实现了跨类别泛化，但仍存在两大挑战：1) 真实世界铰接物体的几何多样性使视觉感知和理解复杂化；2) 物体功能和机制的变化阻碍了统一自适应操作策略的开发。

**Method:** 本文提出了AdaRPG框架，利用基础模型提取物体部件，部件比整个物体具有更大的局部几何相似性，从而增强功能性原始技能的视觉可供性泛化。为此，构建了一个部件级可供性标注数据集来训练可供性模型。此外，AdaRPG利用基础模型中嵌入的通用知识来推理复杂机制，并基于部件可供性推断生成调用原始技能功能的高级控制代码。

**Result:** 模拟和现实世界实验表明，AdaRPG在新型铰接物体类别上具有强大的泛化能力。

**Conclusion:** AdaRPG通过利用基础模型推理和部件接地，有效地解决了铰接物体操作中的视觉感知和统一策略开发挑战，展现了对新物体的强大泛化能力。

> **ai_Abstract:** 本文提出了AdaRPG框架，旨在解决铰接物体操作中因几何多样性和功能变异性带来的挑战。AdaRPG利用基础模型提取物体部件，这些部件具有更高的局部几何相似性，从而提高视觉可供性泛化能力。通过构建部件级可供性数据集和利用基础模型进行机制推理，AdaRPG能够生成高级控制代码。实验证明，该框架在模拟和现实世界中对新型铰接物体类别展现出强大的泛化能力。

> **摘要翻译:** 铰接物体对机器人构成多样化的操作挑战。由于其内部结构无法直接观察，机器人必须自适应地探索和完善动作以生成成功的操作轨迹。尽管现有工作已尝试在自适应铰接物体操作中实现跨类别泛化，但仍存在两大主要挑战：(1) 真实世界铰接物体的几何多样性使视觉感知和理解复杂化，以及 (2) 物体功能和机制的变化阻碍了统一自适应操作策略的开发。为了解决这些挑战，我们提出了AdaRPG，一个新颖的框架，它利用基础模型来提取物体部件，这些部件比整个物体表现出更大的局部几何相似性，从而增强功能性原始技能的视觉可供性泛化。为支持这一点，我们构建了一个部件级可供性标注数据集来训练可供性模型。此外，AdaRPG利用基础模型中嵌入的通用知识来推理复杂机制，并基于部件可供性推断生成调用原始技能功能的高级控制代码。模拟和现实世界实验证明了AdaRPG在新型铰接物体类别上的强大泛化能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [393] [AF-RLIO: Adaptive Fusion of Radar-LiDAR-Inertial Information for Robust Odometry in Challenging Environments](https://arxiv.org/abs/2507.18317)
> *AF-RLIO：雷达-激光雷达-惯性信息自适应融合，用于挑战性环境中的鲁棒里程计*

*Chenglong Qian, Yang Xu, Xiufang Shi, Jiming Chen, Liang Li* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 多传感器融合, 里程计, 雷达, 激光雷达, IMU, 鲁棒导航

**Comment:** 

> **TL;DR:** AF-RLIO是一种自适应融合雷达、激光雷达、IMU和GPS的方法，旨在解决烟雾、隧道等复杂环境下机器人导航中单传感器系统性能下降的问题，通过多模块处理实现鲁棒的里程计估计。

**AI_Comments:** 该论文提出了一种创新的多传感器融合方案，特别是利用雷达数据辅助激光雷达处理动态点和环境降级，提升了系统在恶劣环境下的鲁棒性。其模块化的设计思路清晰，结合了卡尔曼滤波和因子图优化，在工程实现上具有较强的参考价值。该方法对于提升自主机器人在复杂场景下的导航能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在机器人导航中，复杂动态环境下的精确位姿估计和导航至关重要。然而，烟雾、隧道和恶劣天气等环境挑战会显著降低单一传感器系统（如激光雷达或GPS）的性能，从而损害自主机器人的整体稳定性和安全性。

**Method:** 本文提出了AF-RLIO，这是一种自适应融合方法，整合了4D毫米波雷达、激光雷达、惯性测量单元（IMU）和GPS，以利用这些传感器的互补优势，在复杂环境中进行鲁棒的里程计估计。该方法包含三个关键模块：1. 预处理模块：利用雷达数据辅助激光雷达去除动态点，并判断激光雷达的环境条件何时退化。2. 动态感知多模态里程计：选择合适的点云数据进行扫描到地图匹配，并使用迭代误差状态卡尔曼滤波器与IMU紧密耦合。3. 因子图优化模块：平衡里程计和GPS数据之间的权重，构建位姿图进行优化。

**Result:** 该方法已在数据集上进行评估，并在真实机器人环境中进行了测试，结果表明在烟雾和隧道等挑战性条件下，其有效性优于现有方法并具有显著优势。

**Conclusion:** AF-RLIO通过自适应融合雷达、激光雷达、IMU和GPS数据，在烟雾和隧道等挑战性环境中实现了鲁棒的里程计估计，有效解决了单传感器系统性能下降的问题。

> **ai_Abstract:** AF-RLIO提出了一种自适应融合雷达、激光雷达、IMU和GPS数据的方法，以解决机器人导航在烟雾、隧道等复杂环境下因单传感器性能下降导致的鲁棒性问题。该方法包含预处理、动态感知多模态里程计和因子图优化三个核心模块，通过利用雷达辅助激光雷达、紧密耦合IMU与点云数据以及优化里程计与GPS权重，实现了在挑战性环境中的高精度里程计估计，并在真实世界测试中展现出优于现有方法的性能。

> **摘要翻译:** 在机器人导航中，在复杂动态环境中保持精确的位姿估计和导航至关重要。然而，烟雾、隧道和恶劣天气等环境挑战会显著降低单一传感器系统（如激光雷达或GPS）的性能，从而损害自主机器人的整体稳定性和安全性。为了应对这些挑战，我们提出了AF-RLIO：一种自适应融合方法，它整合了4D毫米波雷达、激光雷达、惯性测量单元（IMU）和GPS，以利用这些传感器的互补优势，在复杂环境中进行鲁棒的里程计估计。我们的方法由三个关键模块组成。首先，预处理模块利用雷达数据辅助激光雷达去除动态点，并确定激光雷达的环境条件何时退化。其次，动态感知多模态里程计选择合适的点云数据进行扫描到地图匹配，并使用迭代误差状态卡尔曼滤波器与IMU紧密耦合。最后，因子图优化模块平衡里程计和GPS数据之间的权重，构建位姿图进行优化。所提出的方法已在数据集上进行评估，并在真实机器人环境中进行了测试，证明了其在烟雾和隧道等挑战性条件下相对于现有方法的有效性和优势。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [401] [Target Tracking via LiDAR-RADAR Sensor Fusion for Autonomous Racing](https://arxiv.org/abs/2505.20043)
> *用于自动驾驶赛车的激光雷达-雷达传感器融合目标跟踪*

*Marcello Cellina, Matteo Corno, Sergio Matteo Savaresi* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 目标跟踪, 传感器融合, 激光雷达, 雷达, 自动驾驶赛车

**Comment:** IEEE Conference, 6 pages

> **TL;DR:** 该研究开发了一种融合激光雷达和雷达数据的低延迟扩展卡尔曼滤波器（EKF）多目标跟踪算法，用于自动驾驶赛车在高速度下进行超车操作，并已在实验中验证其有效性。

**AI_Comments:** 该论文的创新点在于其为高速自动驾驶赛车设计了特定的传感器融合多目标跟踪算法，特别是通过EKF集成距离变化率和赛道先验知识，以及处理乱序测量的机制，这些都对提升高动态环境下目标跟踪的精度和鲁棒性至关重要。实验验证了其在极高速度下的实际应用能力，对于自动驾驶技术在赛车和未来道路车辆中的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 精确的车辆检测和动态估计是规划和执行复杂自动超车机动的关键要求，尤其是在高速多车自动驾驶赛车场景中，这将提高道路自动驾驶车辆的安全性和性能。

**Method:** 开发了一种延迟感知（Latency-Aware）的基于EKF的多目标跟踪算法，该算法融合了激光雷DAR和RADAR测量数据。该算法通过在EKF测量函数中明确集成距离变化率（Range Rate），以及在状态预测期间利用赛道的先验知识，来利用不同传感器的特性。它通过使用双状态和测量缓冲区进行重新处理，来处理乱序测量（Out-Of-Sequence Measurements），确保传感器延迟补偿且不丢失信息。

**Result:** 该算法已在PoliMOVE车队的自动赛车上实现，并通过完成多项速度高达275公里/小时的全自动超车机动实验得到了验证。

**Conclusion:** 该研究开发的激光雷达-雷达融合多目标跟踪算法能够有效支持高速自动驾驶赛车中的复杂超车操作，显著提升了自动驾驶车辆的性能和安全性。

> **ai_Abstract:** 本研究提出了一种针对高速自动驾驶赛车的多目标跟踪算法，该算法基于延迟感知的扩展卡尔曼滤波器（EKF），并融合了激光雷达和雷达传感器数据。为应对高速环境下的挑战，算法在EKF中整合了距离变化率并利用赛道先验知识，同时通过双缓冲区处理乱序测量以补偿传感器延迟。该算法已在实际赛车上实现，并成功在高达到275公里/小时的速度下完成了全自动超车操作，证明了其在提升自动驾驶性能和安全性方面的有效性。

> **摘要翻译:** 高速多车自动驾驶赛车将提高道路自动驾驶车辆的安全性和性能。从移动平台进行精确的车辆检测和动态估计是规划和执行复杂自动超车机动的关键要求。为满足这一要求，我们开发了一种延迟感知（Latency-Aware）的基于EKF的多目标跟踪算法，该算法融合了激光雷达和雷达测量数据。该算法通过在EKF测量函数中明确集成距离变化率（Range Rate），以及在状态预测期间利用赛道的先验知识，来利用不同传感器的特性。它通过使用双状态和测量缓冲区进行重新处理，来处理乱序测量（Out-Of-Sequence Measurements），确保传感器延迟补偿且不丢失信息。该算法已在PoliMOVE车队的自动赛车上实现，并通过完成多项速度高达275公里/小时的全自动超车机动实验得到了验证。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [431] [G2S-ICP SLAM: Geometry-aware Gaussian Splatting ICP SLAM](https://arxiv.org/abs/2507.18344)
> *G2S-ICP SLAM：几何感知高斯溅射ICP SLAM*

*Gyuhyeon Pak, Hae Min Cho, Euntai Kim* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 高斯溅射, ICP SLAM, 几何感知, 3D重建, 实时系统

**Comment:** 8 pages, 6 figures

> **TL;DR:** G2S-ICP SLAM是一种新的实时RGB-D SLAM系统，它使用几何感知的2D高斯盘来表示场景，并在Generalized ICP框架中实现高精度定位和重建，同时保持渲染质量。

**AI_Comments:** 这篇论文通过引入几何感知的2D高斯盘作为场景表示，有效地解决了传统3D椭球体在多视角深度解释中的不一致性问题，是其主要创新点。将这种新颖的表示与Generalized ICP框架结合，并辅以几何感知损失，使得系统在实时性、定位精度和重建完整性方面均表现出色，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D椭球体表示在深度解释上存在不一致性，因此需要一种新的表示方法来提高多视角深度解释的一致性，从而实现高保真3D重建和鲁棒的相机姿态跟踪。

**Method:** 提出G2S-ICP SLAM系统，通过将每个场景元素表示为受限于局部切平面的高斯分布（即与底层几何对齐的2D高斯盘）来建模局部表面。将这种表示嵌入到广义ICP框架中，引入各向异性协方差先验而不改变底层配准公式。此外，提出了一种几何感知损失，监督光度、深度和法线一致性。

**Result:** 该系统实现了实时操作，同时保持了视觉和几何保真度。在Replica和TUM-RGBD数据集上的广泛实验表明，G2S-ICP SLAM在定位精度、重建完整性方面优于先前的SLAM系统，同时保持了渲染质量。

**Conclusion:** G2S-ICP SLAM通过引入几何感知的2D高斯盘表示和优化的ICP框架，成功实现了高精度、实时、高保真的RGB-D SLAM，并在关键指标上超越了现有系统。

> **ai_Abstract:** G2S-ICP SLAM是一种新颖的实时RGB-D SLAM系统，它创新性地使用几何感知的2D高斯盘来表示场景元素，以实现更一致的深度解释。该系统将这种表示集成到广义ICP框架中，并引入各向异性协方差先验及几何感知损失。实验证明，G2S-ICP SLAM在定位精度和重建完整性上超越了现有系统，同时保持了渲染质量和实时性能。

> **摘要翻译:** 在本文中，我们提出了一种新颖的几何感知RGB-D高斯溅射SLAM系统，名为G2S-ICP SLAM。所提出的方法通过使用受限于局部切平面的高斯分布来表示每个场景元素，从而实时执行高保真3D重建和鲁棒的相机姿态跟踪。这有效地将局部表面建模为与底层几何对齐的2D高斯盘，与传统的基于3D椭球体且具有各向同性不确定性的表示相比，在多个视角下能够实现更一致的深度解释。为了将这种表示集成到SLAM管线中，我们通过引入各向异性协方差先验而无需改变底层配准公式，将表面对齐的高斯盘嵌入到广义ICP框架中。此外，我们提出了一种几何感知损失，用于监督光度、深度和法线一致性。我们的系统在保持视觉和几何保真度的同时实现了实时操作。在Replica和TUM-RGBD数据集上的广泛实验表明，G2S-ICP SLAM在定位精度、重建完整性方面优于先前的SLAM系统，同时保持了渲染质量。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [450] [Compliant Residual DAgger: Improving Real-World Contact-Rich Manipulation with Human Corrections](https://arxiv.org/abs/2506.16685)
> *柔顺残差DAgger：通过人工修正改进真实世界接触丰富型操作*

*Xiaomeng Xu, Yifan Hou, Zeyi Liu, Shuran Song* | **Category: cs.RO, cs.LG** | **Updated: 2025-07-24**

**Keywords:** DAgger, 接触丰富型操作, 人工修正, 柔顺控制, 机器人学习

**Comment:** 

> **TL;DR:** 本文提出了Compliant Residual DAgger (CR-DAgger)，通过柔顺干预界面和柔顺残差策略，有效利用人类修正数据，显著提升了机器人处理真实世界接触丰富型操作任务的性能。

**AI_Comments:** 本文的创新点在于提出了“柔顺干预界面”和“柔顺残差策略”，解决了在真实世界机器人操作中有效集成人类修正的难题。通过允许人类提供非中断的、柔顺的delta修正，极大地提高了数据收集的效率和质量。结合力反馈的残差策略也使得学习过程更鲁棒。这对于提升机器人处理复杂、接触密集型任务的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决真实世界接触丰富型操作中数据集聚合（DAgger）面临的关键挑战：如何收集信息丰富的人工修正数据以及如何有效地利用这些新数据更新策略。

**Method:** 引入Compliant Residual DAgger (CR-DAgger)，包含两个新颖组件：1) 柔顺干预界面，利用柔顺控制，允许人类在不中断机器人策略执行的情况下提供轻柔、准确的delta动作修正；2) 柔顺残差策略，从人类修正中学习，同时结合力反馈和力控制。

**Result:** 使用最少的修正数据，显著提高了精确接触丰富型操作任务的性能。在两个挑战性任务（翻书和皮带组装）上，基础策略成功率提高了50%以上，并且性能优于从头开始训练和微调方法。

**Conclusion:** CR-DAgger通过创新的柔顺干预界面和柔顺残差策略，有效解决了真实世界接触丰富型操作中DAgger的数据收集和策略更新问题，显著提升了机器人性能，并为实际机器人学习任务提供了实用指导。

> **ai_Abstract:** 本文提出了一种名为柔顺残差DAgger（CR-DAgger）的新方法，旨在解决真实世界接触丰富型操作中DAgger数据收集和策略更新的难题。CR-DAgger通过提供一个柔顺干预界面，使人类能在不中断机器人执行的情况下提供精准的delta动作修正，并结合一个学习人类修正并融入力反馈的柔顺残差策略。实验结果表明，该系统仅需少量修正数据就能显著提升机器人性能，在复杂任务中成功率提升超过50%，且优于现有训练方法。

> **摘要翻译:** 我们解决了真实世界接触丰富型操作中数据集聚合（DAgger）的关键挑战：如何收集信息丰富的人工修正数据以及如何有效地利用这些新数据更新策略。我们引入了柔顺残差DAgger（CR-DAgger），它包含两个新颖的组件：1）一个柔顺干预界面，该界面利用柔顺控制，允许人类在不中断正在进行的机器人策略执行的情况下提供轻柔、准确的delta动作修正；2）一个柔顺残差策略公式，该公式从人类修正中学习，同时结合力反馈和力控制。我们的系统使用最少的修正数据，显著提高了精确接触丰富型操作任务的性能，在两个具有挑战性的任务（翻书和皮带组装）上将基础策略成功率提高了50%以上，并且优于从头开始训练和微调方法。通过广泛的真实世界实验，我们为在真实世界机器人学习任务中实施有效的DAgger提供了实用指导。结果视频可在以下网址观看：https://compliant-residual-dagger.github.io/

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [473] [Residual Koopman Model Predictive Control for Enhanced Vehicle Dynamics with Small On-Track Data Input](https://arxiv.org/abs/2507.18396)
> *用于增强车辆动力学的小型在轨数据输入的残差Koopman模型预测控制*

*Yonghao Fu, Cheng Hu, Haokun Xiong, Zhangpeng Bao, Wenyuan Du, Edoardo Ghignone, Michele Magno, Lei Xie, Hongye Su* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 残差Koopman模型预测控制, 车辆轨迹跟踪, 模型预测控制, 神经网络, 小数据学习

**Comment:** 

> **TL;DR:** 提出残差Koopman模型预测控制(RKMPC)，结合线性MPC和神经网络，在少量数据下显著提升车辆轨迹跟踪性能。

**AI_Comments:** 这项研究的创新之处在于提出了一个双层控制架构，将传统LMPC的可靠性与神经网络的非线性建模能力相结合，通过残差学习的方式有效处理车辆的复杂动力学。其显著减少数据需求并提升性能的特点，对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 纯跟踪控制未能考虑车辆模型约束，影响驾驶安全。传统MPC性能依赖模型精度，但传统车辆建模在捕捉非线性动力学和保持计算效率之间存在固有的权衡，导致控制性能下降。

**Method:** 提出残差Koopman模型预测控制（RKMPC）框架。该方法采用双线性MPC架构计算控制输入：一个线性模型预测控制（LMPC）基于车辆运动学模型计算基线控制输入；一个基于神经网络的RKMPC计算补偿输入。最终控制指令通过叠加这两个分量获得，旨在保留传统机械模型的可靠性和可解释性，同时通过残差建模实现性能优化。

**Result:** 在Carsim-Matlab联合仿真平台和1:10比例F1TENTH物理赛车上验证。RKMPC仅需传统Koopman模型预测控制（KMPC）所需训练数据的20%，并提供卓越的跟踪性能。与传统LMPC相比，RKMPC将横向误差减少了11.7%-22.1%，航向误差减少了8.9%-15.8%，并将前轮转向稳定性提高了高达27.6%。

**Conclusion:** RKMPC通过结合线性MPC和神经网络进行残差建模，在减少训练数据需求的同时，显著提升了车辆轨迹跟踪的性能和稳定性，解决了传统MPC在非线性动力学建模和计算效率之间的权衡问题。

> **ai_Abstract:** 本文提出了一种残差Koopman模型预测控制（RKMPC）框架，旨在解决传统模型预测控制在车辆轨迹跟踪中面临的非线性建模与计算效率的权衡问题。RKMPC结合了基于车辆运动学模型的线性MPC和神经网络计算的补偿输入，以提供可靠且高性能的控制。实验结果表明，RKMPC在仅需少量训练数据的情况下，显著提高了车辆的轨迹跟踪精度和转向稳定性。

> **摘要翻译:** 在车辆轨迹跟踪任务中，最简单的方法是纯跟踪（Pure Pursuit, PP）控制。然而，这种单点预瞄跟踪策略未能考虑车辆模型约束，从而影响了驾驶安全。模型预测控制（MPC）作为一种广泛采用的控制方法，通过结合机械模型和物理约束来优化控制动作。然而，其控制性能关键取决于车辆建模的准确性。传统的车辆建模方法在捕捉非线性动力学和保持计算效率之间面临固有的权衡，常常导致控制性能下降。为了解决这些挑战，本文提出了残差Koopman模型预测控制（RKMPC）框架。该方法使用双线性MPC架构来计算控制输入：一个线性模型预测控制（LMPC）基于车辆运动学模型计算基线控制输入，一个基于神经网络的RKMPC计算补偿输入。最终的控制指令通过叠加这两个分量获得。这种设计保留了传统机械模型的可靠性和可解释性，同时通过残差建模实现性能优化。该方法已在Carsim-Matlab联合仿真平台和一台1:10比例的F1TENTH物理赛车上进行了验证。实验结果表明，RKMPC仅需传统Koopman模型预测控制（KMPC）所需训练数据的20%，同时提供卓越的跟踪性能。与传统LMPC相比，RKMPC将横向误差减少了11.7%-22.1%，将航向误差减少了8.9%-15.8%，并将前轮转向稳定性提高了高达27.6%。实现代码可在：https://github.com/ZJU-DDRX/Residual Koopman 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [506] [Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model](https://arxiv.org/abs/2507.06174)
> *快速双边遥操作和模仿学习：通过精确动力学模型实现无力传感器力控制*

*Koki Yamane, Yunhan Li, Masashi Konosu, Koki Inami, Junji Oaki, Sho Sakaino, Toshiaki Tsuji* | **Category: cs.RO, cs.AI, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 遥操作, 模仿学习, 无力传感器, 双边控制, 动力学模型

**Comment:** 20 pages, 9 figures, Submitted to CoRL 2025

> **TL;DR:** 通过4通道双边控制，本研究实现了低成本、无力传感器机械臂的快速遥操作和模仿学习，显著提高了力反馈和数据收集性能。

**AI_Comments:** 这篇论文的创新点在于，它解决了低成本机械臂在缺乏力传感器的情况下难以实现力反馈遥操作的问题。通过精确的动力学模型和4通道双边控制，实现了无需物理力传感器的力感知和高保真遥操作，这对于降低机器人部署成本和扩展模仿学习的应用范围具有重要意义。该方法对于需要力交互但预算有限的应用场景非常实用。

<details>
  <summary>Details</summary>

**Motivation:** 现有用于低成本机械臂的遥操作系统多采用单边控制，仅传输位置信息，缺乏力反馈，导致其难以处理快速或接触密集的任务。

**Method:** 该方法利用4通道双边控制，即使对于无力传感器的低成本机械臂也能实现力反馈。它基于精确识别的机械臂动力学，集成了非线性项补偿、速度和外力估计以及对应惯性变化的变增益。此外，通过4通道双边控制收集的数据，将力信息整合到模仿学习策略的输入和输出中。

**Result:** 该系统能够实现对无力传感器的低成本机械臂进行快速遥操作并提供力反馈。将力信息整合到模仿学习策略的输入和输出中，能提高模仿学习的性能。

**Conclusion:** 该系统在经济实惠的硬件上实现了高保真遥操作和数据收集，具有实际效果。

> **ai_Abstract:** 本文提出了一种创新的方法，通过4通道双边控制实现低成本、无力传感器机械臂的快速遥操作和模仿学习。该方法利用精确的机械臂动力学模型，整合了非线性补偿、速度与外力估计及变增益，从而在缺乏传统力传感器的情况下提供力反馈。研究还表明，将这种力信息融入模仿学习策略能显著提升性能。这些成果证明了该系统在经济型硬件上进行高保真遥操作和数据收集的实用性。

> **摘要翻译:** 近年来，模仿学习的进步使得人们对遥操作低成本机械臂以收集演示数据产生了越来越大的兴趣。然而，大多数现有系统依赖于单边控制，这种控制只传输目标位置值。虽然这种方法易于实现且适用于缓慢、非接触任务，但由于缺乏力反馈，它在快速或接触密集的任务中表现不佳。这项工作表明，即使对于无力传感器的低成本机械臂，通过利用4通道双边控制，实现带有力反馈的快速遥操作也是可行的。基于精确识别的机械臂动力学，我们的方法集成了非线性项补偿、速度和外力估计以及对应惯性变化的变增益。此外，利用通过4通道双边控制收集的数据，我们表明将力信息整合到学习策略的输入和输出中可以提高模仿学习的性能。这些结果突出了我们的系统在经济实惠的硬件上进行高保真遥操作和数据收集的实际有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [521] [Evaluating the Pre-Dressing Step: Unfolding Medical Garments Via Imitation Learning](https://arxiv.org/abs/2507.18436)
> *评估预穿戴步骤：通过模仿学习展开医用服装*

*David Blanco-Mulero, Júlia Borràs, Carme Torras* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 模仿学习, 机器人穿戴, 服装展开, 预穿戴, 操作原语

**Comment:** 6 pages, 4 figures, 2 tables. Accepted to IEEE/RSJ IROS 2025. Project
  website: https://sites.google.com/view/pre-dressing

> **TL;DR:** 本文通过模仿学习和视觉分类器，解决了机器人辅助穿戴前医用服装的展开问题，发现组合动作能有效提升展开效率。

**AI_Comments:** 本文创新性地提出了“预穿戴步骤”的概念，解决了机器人辅助穿戴领域中一个实际且常被忽视的挑战——即如何有效展开折叠的医疗服装。通过结合模仿学习来生成操作原语和视觉分类器进行状态反馈，该方法具有很强的实用性。其关于运动组合优于单一高动态运动的发现，为未来的机器人柔性物体操作提供了宝贵的经验。

<details>
  <summary>Details</summary>

**Motivation:** 在机器人辅助穿戴领域，现有工作通常假设服装已展开并可直接使用。然而，在医疗应用中，医用长袍和围裙通常以折叠状态存放，需要额外的展开步骤，这激发了本文对“预穿戴步骤”的研究。

**Method:** 本文利用模仿学习来学习三种操作原语，包括高加速和低加速运动。此外，还采用视觉分类器将服装状态分为闭合、部分打开和完全打开。

**Result:** 研究结果表明，高动态运动对于展开新拆封的服装效果不佳，而运动组合可以有效地增强打开配置。

**Conclusion:** 本文成功引入并评估了机器人辅助穿戴前的“预穿戴步骤”，即展开医用服装。通过模仿学习和视觉分类器，研究发现结合不同的操作原语能有效提高服装的展开效率，解决了机器人辅助穿戴中的一个实际挑战。

> **ai_Abstract:** 本文针对机器人辅助穿戴中医疗服装的展开问题，提出了“预穿戴步骤”。研究利用模仿学习训练三种操作原语，并结合视觉分类器来识别服装的展开状态。实证评估表明，虽然高动态运动对新拆封服装的展开效果不佳，但通过组合不同的操作原语可以有效提高服装的展开效率。

> **摘要翻译:** 机器人辅助穿戴有潜力显著帮助患者和医护人员，减轻工作负担并提高临床环境的效率。尽管机器人穿戴辅助已取得实质性进展，但以往的工作通常假设服装已经展开并准备好使用。然而，在医疗应用中，长袍和围裙通常以折叠配置存放，需要额外的展开步骤。在本文中，我们引入了预穿戴步骤，即在辅助穿戴之前展开服装的过程。我们利用模仿学习来学习三种操作原语，包括高加速和低加速运动。此外，我们采用视觉分类器将服装状态分为闭合、部分打开和完全打开。我们对所学习的操作原语及其组合进行了实证评估。我们的结果表明，高动态运动对于展开新拆封的服装效果不佳，而运动组合可以有效地增强打开配置。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [546] [Hand Gesture Recognition for Collaborative Robots Using Lightweight Deep Learning in Real-Time Robotic Systems](https://arxiv.org/abs/2507.10055)
> *用于协作机器人的轻量级深度学习实时机器人系统中的手势识别*

*Muhtadin, I Wayan Agus Darmawan, Muhammad Hilmi Rusydiansyah, I Ketut Eddy Purnama, Chastine Fatichah, Mauridhi Hery Purnomo* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 手势识别, 协作机器人, 轻量级深度学习, 实时系统, 人机交互

**Comment:** 

> **TL;DR:** 本文提出了一种基于轻量级深度学习的手势识别系统，用于实时控制协作机器人，该系统模型小巧、精度高，并已成功部署和测试。

**AI_Comments:** 该论文的创新点在于其极度轻量化的深度学习模型设计，在保证高识别精度的同时，显著降低了模型尺寸，使其非常适合边缘设备和实时机器人系统部署。这对于推动协作机器人在资源受限或需要快速响应的应用场景中的普及具有重要意义，为实现更直观、无需额外设备的未来人机协作提供了可行方案。

<details>
  <summary>Details</summary>

**Motivation:** 为了实现直观的人机协作，消除对操纵杆、平板电脑或可穿戴传感器等额外设备的依赖，使人类能够自然高效地控制协作机器人。

**Method:** 提出了一种基于轻量级深度学习的手势识别系统，该系统能够识别八种不同的手势。为了优化模型在边缘设备上的部署，研究人员利用TensorFlow Lite进行了量化和剪枝。该系统在基于ROS2的实时机器人框架内，成功地在Universal Robot UR5协作机器人上实现并测试。

**Result:** 所提出的模型仅有1,103个参数，初始尺寸为22 KB，准确率达到93.5%。经过量化和剪枝优化后，最终模型大小减小到仅7 KB。该系统已成功在Universal Robot UR5协作机器人上实现并测试。

**Conclusion:** 研究结果表明，即使是极其轻量级的模型也能为协作机器人提供准确且响应迅速的基于手势的控制，这为在受限环境中实现自然人机交互开辟了新的可能性。

> **ai_Abstract:** 本文提出了一种基于轻量级深度学习的手势识别系统，旨在通过识别八种手势，实现人类对协作机器人的自然高效控制。该模型具有极小的参数量（1,103个）和尺寸（22 KB），并达到了93.5%的准确率。通过TensorFlow Lite的量化和剪枝，模型最终尺寸进一步压缩至7 KB，成功部署并测试于Universal Robot UR5协作机器人上。研究证明，即使是超轻量级模型也能提供精确且响应迅速的手势控制，为受限环境中的人机交互开辟了新途径。

> **摘要翻译:** 直接和自然的交互对于直观的人机协作至关重要，它消除了对操纵杆、平板电脑或可穿戴传感器等额外设备的需求。在本文中，我们提出了一种基于轻量级深度学习的手势识别系统，使人类能够自然高效地控制协作机器人。该模型识别八种不同的手势，仅有1,103个参数和22 KB的紧凑尺寸，实现了93.5%的准确率。为了进一步优化模型以在边缘设备上进行实际部署，我们使用TensorFlow Lite应用了量化和剪枝，将最终模型大小减小到仅7 KB。该系统在基于ROS2的实时机器人框架内，成功地在Universal Robot UR5协作机器人上实现并测试。结果表明，即使是极其轻量级的模型也能为协作机器人提供准确且响应迅速的基于手势的控制，为受限环境中的自然人机交互开辟了新的可能性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [568] [A Novel Monte-Carlo Compressed Sensing and Dictionary Learning Method for the Efficient Path Planning of Remote Sensing Robots](https://arxiv.org/abs/2507.18462)
> *一种用于遥感机器人高效路径规划的新型蒙特卡洛压缩感知与字典学习方法*

*Alghalya Al-Hajri, Ejmen Al-Ubejdij, Aiman Erbad, Ali Safa* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 蒙特卡洛, 压缩感知, 字典学习, 路径规划, 遥感机器人

**Comment:** 

> **TL;DR:** 本文提出了一种结合蒙特卡洛优化和字典学习的压缩感知方法，用于遥感机器人高效的路径规划，显著减少了机器人行程并提高了数据重建精度。

**AI_Comments:** 本文的创新之处在于首次将压缩感知、蒙特卡洛优化和字典学习相结合，用于遥感机器人的路径规划。通过数据驱动的字典学习，显著提高了数据重建的准确性，并有效减少了机器人工作量。该方法为未来自动化环境监测提供了高效且高精度的解决方案，具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，压缩感知(CS)因其能用更少测量获取高分辨率数据的能力而备受关注。同时，无人机器人平台在遥感和环境监测中日益普及。本文旨在首次探索如何利用CS测量矩阵的结构来设计优化的机器人数据采集采样轨迹，以解决当前遥感机器人路径规划的效率问题。

**Method:** 本文提出了一种新颖的蒙特卡洛优化框架，用于生成测量矩阵，旨在最小化机器人的遍历路径长度和CS框架内的信号重建误差。该方法的核心是应用字典学习(DL)来获取数据驱动的稀疏变换，从而提高重建精度并进一步减少机器人需要采集的样本数量。

**Result:** 该方法在重建海湾地区NO2污染图的实验中表现出有效性。结果表明，与全覆盖路径相比，机器人行程可减少至不到10%；与基于DCT和多项式字典的传统CS方法相比，重建精度提高了五倍以上；与先前提出的信息路径规划(IPP)方法相比，精度提高了两倍。

**Conclusion:** 本文提出的结合蒙特卡洛压缩感知和字典学习的方法，能够显著优化遥感机器人的路径规划，在大幅减少机器人行程的同时，显著提升了环境数据重建的准确性。

> **ai_Abstract:** 本研究提出了一种结合蒙特卡洛优化和字典学习的新型压缩感知方法，旨在优化遥感机器人的路径规划。该方法通过生成优化的测量矩阵，显著减少了机器人遍历路径长度和信号重建误差。实验结果表明，该方法能将机器人行程缩短至全覆盖路径的不到10%，同时在NO2污染图重建中，与传统CS方法相比重建精度提高五倍以上，与现有信息路径规划方法相比提高两倍，展现了在高效环境数据采集方面的潜力。

> **摘要翻译:** 近年来，压缩感知（CS）作为一种使用比传统奈奎斯特采样所需更少测量来获取高分辨率感知数据的技术，引起了广泛关注。与此同时，无人机器人平台如无人机和漫游车已成为遥感和环境监测任务（包括温度、湿度和空气质量测量）日益流行的工具。在此背景下，据我们所知，本文首次研究了如何利用CS测量矩阵的结构来设计用于机器人环境数据收集的优化采样轨迹。我们提出了一种新颖的蒙特卡洛优化框架，该框架生成的测量矩阵旨在最小化机器人的遍历路径长度和CS框架内的信号重建误差。我们方法的核心是应用字典学习（DL）来获得数据驱动的稀疏变换，这提高了重建精度，同时进一步减少了机器人需要收集的样本数量。我们通过重建海湾地区NO2污染图的实验证明了我们方法的有效性。结果表明，我们的方法可以将机器人行程减少到全覆盖路径的不到10%，同时与基于DCT和多项式字典的传统CS方法相比，重建精度提高了五倍以上，与先前提出的信息路径规划（IPP）方法相比，精度提高了两倍。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [594] [Adaptive Relative Pose Estimation Framework with Dual Noise Tuning for Safe Approaching Maneuvers](https://arxiv.org/abs/2507.16214)
> *用于安全接近机动的双噪声调谐自适应相对位姿估计框架*

*Batu Candan, Simone Servadio* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 相对位姿估计, 主动碎片清除, 无迹卡尔曼滤波, 自适应滤波, 噪声调谐

**Comment:** 

> **TL;DR:** 本文提出了一个结合计算机视觉和自适应非线性滤波的完整管道，用于主动碎片清除任务中对翻滚卫星的精确鲁棒相对位姿估计，并通过双重噪声自适应策略增强了UKF的鲁棒性。

**AI_Comments:** 该论文的创新点在于其将计算机视觉与自适应非线性滤波（特别是UKF）相结合的完整管道，并引入了独特的双重噪声自适应策略。这种策略能够同时应对测量不确定性和动态模型不确定性，显著增强了系统在复杂空间环境下的鲁棒性。这对于未来主动碎片清除等高风险空间任务具有重要意义，因为它直接解决了精确导航和控制的关键挑战。

<details>
  <summary>Details</summary>

**Motivation:** 准确和鲁棒的相对位姿估计对于像欧洲空间局（ESA）的ENVISAT这样针对翻滚废弃卫星的主动碎片清除（ADR）任务至关重要。

**Method:** 该方法提出了一个集成先进计算机视觉技术（使用CNN和图像预处理检测结构标记）与自适应非线性滤波（无迹卡尔曼滤波，UKF）的完整管道。2D坐标通过相机模型转换为3D测量值，并在UKF框架中融合以估计完整的相对位姿。关键贡献在于UKF中的双重自适应策略：动态调整测量噪声协方差以补偿CNN测量不确定性，以及利用测量残差分析自适应调整过程噪声协方差以应对未建模的动态或机动。

**Result:** 所提出的自适应集成系统在高保真模拟中，使用逼真的ENVISAT模型进行了性能评估，在各种条件下（包括测量中断）将估计值与真实值进行了比较。

**Conclusion:** 这种全面的方法为鲁棒的机载相对导航提供了增强的解决方案，显著提升了ADR任务中安全近距离操作所需的能力。

> **ai_Abstract:** 本文提出了一种用于主动碎片清除（ADR）任务中精确、鲁棒相对位姿估计的自适应框架。该框架整合了计算机视觉（CNN检测结构标记）和自适应无迹卡尔曼滤波（UKF），通过将2D图像坐标转换为3D测量值并进行融合。其核心创新在于UKF中引入了双重噪声自适应策略：动态调整测量噪声协方差以应对CNN测量不确定性，以及自适应调整过程噪声协方差以处理未建模的动态。高保真模拟结果验证了该系统在各种条件下的性能，为ADR任务中的安全近距离操作提供了增强的机载相对导航解决方案。

> **摘要翻译:** 准确和鲁棒的相对位姿估计对于像欧洲空间局（ESA）的ENVISAT这样针对翻滚废弃卫星的具有挑战性的主动碎片清除（ADR）任务至关重要。这项工作提出了一个完整的管道，将先进的计算机视觉技术与自适应非线性滤波相结合，以解决这一挑战。一个通过图像预处理增强的卷积神经网络（CNN）从追踪器图像中检测结构标记（角点），其2D坐标通过相机建模转换为3D测量值。这些测量值在无迹卡尔曼滤波（UKF）框架中融合，该框架因其处理非线性相对动态的能力而被选中，以估计完整的相对位姿。主要贡献包括集成的系统架构和UKF中的双重自适应策略：测量噪声协方差的动态调谐补偿了变化的CNN测量不确定性，而利用测量残差分析的过程噪声协方差的自适应调谐则在线考虑了未建模的动态或机动。这种双重自适应增强了对测量缺陷和动态模型不确定性的鲁棒性。所提出的自适应集成系统的性能通过使用逼真的ENVISAT模型进行的高保真模拟进行了评估，在各种条件下（包括测量中断）将估计值与真实值进行了比较。这种全面的方法为鲁棒的机载相对导航提供了增强的解决方案，显著提升了ADR任务中安全近距离操作所需的能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [610] [TrafficMCTS: A Closed-Loop Traffic Flow Generation Framework with Group-Based Monte Carlo Tree Search](https://arxiv.org/abs/2308.12797)
> *TrafficMCTS：一种基于群体蒙特卡洛树搜索的闭环交通流生成框架*

*Ze Fu, Licheng Wen, Pinlong Cai, Daocheng Fu, Song Mao, Botian Shi* | **Category: cs.RO, cs.MA, cs.SY, eess.SY** | **Updated: 2025-07-25**

**Keywords:** TrafficMCTS, Monte Carlo Tree Search, Social Value Orientation, Traffic Flow Generation, Closed-Loop

**Comment:** Published in IEEE Transactions on Intelligent Transportation Systems

> **TL;DR:** TrafficMCTS是一个利用群体蒙特卡洛树搜索（MCTS）和社会价值取向（SVO）的闭环框架，用于生成多样化、类人且无碰撞的交通流，并在效率、成功率、完成时间和多样性方面优于现有方法，同时具有良好的可扩展性。

**AI_Comments:** TrafficMCTS的创新之处在于将群体蒙特卡洛树搜索（MCTS）与社会价值取向（SVO）相结合，并采用闭环架构，从而能够生成更具多样性和类人行为的交通流，克服了传统方法的局限性。其能够动态适应环境和确保无碰撞轨迹的能力，以及在效率和可扩展性方面的优势，使其在智能交通系统领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的交通流模拟方法依赖预定义的驾驶员模型、目标优化或预记录数据集，导致可扩展性、通用性和适应性受限，难以生成逼真、多样化和类人的交通模式。

**Method:** 本文引入了TrafficMCTS，一个创新框架，它结合了基于群体的蒙特卡洛树搜索（MCTS）和社会价值取向（SVO），以产生具有不同驾驶风格和协作倾向的多面交通流。该框架采用闭环架构，使车辆能够实时动态适应环境，并确保可行的无碰撞轨迹。

**Result:** 通过与最先进方法的全面比较，TrafficMCTS在计算效率、规划成功率、意图完成时间和多样性指标方面显示出优势。此外，该框架在多种场景下有效，并能诱导交通流中多样化的社会行为。TrafficMCTS还被证明能够高效模拟涉及复杂路网中众多交互车辆的多样化交通场景，捕捉类人驾驶行为的复杂动态。

**Conclusion:** TrafficMCTS框架能够高效地模拟涉及复杂路网中众多交互车辆的多样化交通场景，并捕捉类人驾驶行为的复杂动态，从而验证了其可扩展性。

> **ai_Abstract:** TrafficMCTS是一个创新的闭环交通流生成框架，它结合了群体蒙特卡洛树搜索（MCTS）和社会价值取向（SVO），旨在解决现有方法在生成逼真、多样化和类人交通模式方面的局限性。该框架使车辆能够动态适应环境并确保无碰撞轨迹。实验结果表明，TrafficMCTS在计算效率、规划成功率、意图完成时间和多样性方面优于现有方法，并能有效模拟复杂场景下的多样化社会行为和大规模交通场景，验证了其在捕捉类人驾驶行为方面的有效性和可扩展性。

> **摘要翻译:** 智能交通系统领域的交通流模拟正受到广泛关注，而生成逼真、多样化和类人的交通模式提出了必须解决的关键挑战。当前的方法通常依赖于预定义的驾驶员模型、目标优化或预记录的驾驶数据集，这限制了它们的可扩展性、通用性和适应性。在本文中，我们引入了TrafficMCTS，一个创新框架，它利用基于群体的蒙特卡洛树搜索（MCTS）和社会价值取向（SVO）的协同作用，以产生具有不同驾驶风格和协作倾向的多面交通流。我们的框架以闭环架构为基础，使车辆能够实时动态适应其环境，并确保可行的无碰撞轨迹。通过与最先进方法的全面比较，我们阐明了我们的方法在计算效率、规划成功率、意图完成时间和多样性指标方面的优势。此外，我们模拟了多种场景以说明所提出框架的有效性，并强调其在交通流中诱导多样化社会行为的能力。最后，我们通过展示TrafficMCTS能够高效模拟涉及复杂路网中众多交互车辆的多样化交通场景，捕捉类人驾驶行为的复杂动态，从而验证了其可扩展性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [617] [Experimental Comparison of Whole-Body Control Formulations for Humanoid Robots in Task Acceleration and Task Force Spaces](https://arxiv.org/abs/2507.18502)
> *人形机器人任务加速度空间和任务力空间全身控制公式的实验比较*

*Sait Sovukluk, Grazia Zambella, Tobias Egle, Christian Ott* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 全身控制, 人形机器人, 逆动力学, 无源性, 实验比较

**Comment:** This paper has been accepted for publication in 2025 IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS 2025). -
  Link to video: https://youtu.be/Nfm50ycz-FU

> **TL;DR:** 本文实验比较了人形机器人的两种全身控制方法（ID-WBC和PB-WBC）在实际条件下的鲁棒性。

**AI_Comments:** 本文的创新之处在于其对两种不同全身控制公式（ID-WBC和PB-WBC）进行了首次实验性比较，特别关注它们在非理想、真实世界条件下的鲁棒性，填补了理论预测与实际应用之间差距的研究空白。其重要性在于为人形机器人全身控制方法的选择提供了实证依据，有助于工程师在实际部署中做出更明智的决策。

<details>
  <summary>Details</summary>

**Motivation:** 尽管逆动力学全身控制（ID-WBC）和基于无源性的全身控制（PB-WBC）在理想条件下都能预测稳定性，但它们在关节摩擦、传感器噪声、未建模外部扰动和非完美接触条件下的鲁棒性尚不明确，因此需要进行实验分析和比较。

**Method:** 研究通过在人形机器人平台上进行摆动脚位置和姿态控制、有无额外配重下蹲以及跳跃等实验，对逆动力学全身控制（ID-WBC）和基于无源性的全身控制（PB-WBC）两种全身控制方法进行了分析和实验比较。

**Result:** 实验分析并比较了两种控制器，并将其观察到的性能和特性差异与控制器公式相关联，突出了每种控制器的优缺点。抽象中未详细说明具体哪种控制器在何种情况下表现更好。

**Conclusion:** 论文根据实验结果，分析并指出了逆动力学全身控制（ID-WBC）和基于无源性的全身控制（PB-WBC）两种全身控制方法在实际条件下的各自优缺点。

> **ai_Abstract:** 本文对人形机器人的两种全身控制方法——逆动力学全身控制（ID-WBC）和基于无源性的全身控制（PB-WBC）进行了实验比较。研究旨在评估这两种在任务加速度空间和任务力空间中公式化的控制器在面对关节摩擦、传感器噪声和非完美接触等实际挑战时的鲁棒性。通过在人形机器人上执行摆动脚控制、下蹲和跳跃等任务，论文分析了它们的性能差异，并指出了各自的优缺点。

> **摘要翻译:** 本文研究了人形机器人两种不同全身控制公式的实验比较：逆动力学全身控制（ID-WBC）和基于无源性的全身控制（PB-WBC）。这两种控制器根本上不同，前者在任务加速度空间中制定，后者在任务力空间中并考虑了无源性。尽管两种控制方法在闭环动力学中都能在理想条件下预测稳定性，但它们对抗关节摩擦、传感器噪声、未建模外部扰动和非完美接触条件的鲁棒性并不明显。因此，我们通过摆动脚位置和姿态控制、有无未建模额外重量的下蹲以及跳跃等实验，在人形机器人平台上分析并实验比较了这两种控制器。我们还将观察到的性能和特性差异与控制器公式联系起来，并强调了每种控制器的优缺点。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [642] [Leveraging multi-source and heterogeneous signals for fatigue detection](https://arxiv.org/abs/2507.16859)
> *利用多源异构信号进行疲劳检测*

*Luobin Cui, Yanlai Wu, Tang Ying, Weikai Li* | **Category: cs.RO, cs.AI, 62H30, I.2** | **Updated: 2025-07-24**

**Keywords:** 疲劳检测, 多源, 异构信号, 传感器受限, 泛化能力

**Comment:** 1figures,32pages

> **TL;DR:** 本文提出了一种多源异构疲劳检测框架，通过利用不同配置源域的知识，解决了现实世界中传感器受限场景下的疲劳检测问题，并证明了其在实际应用中的有效性。

**AI_Comments:** 本文的创新点在于提出了一个多源异构的疲劳检测框架，解决了现有方法在现实世界中应用受限的问题。通过利用不同来源的异构数据，该方法提高了在传感器受限场景下的适用性和泛化能力，对于安全关键领域的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 疲劳检测在航空、采矿和长途运输等安全关键应用中至关重要。然而，现有方法大多依赖高端传感器和受控环境，限制了其在现实世界中的适用性。

**Method:** 本文正式定义了一个实际但尚未充分探索的现实世界疲劳检测问题，并提出了一个异构多源疲劳检测框架，该框架自适应地利用目标域中可用的模态，同时受益于源域中存在的不同配置。

**Result:** 实验使用实际部署的传感器设置和两个公开数据集进行，结果表明该方法具有实用性、鲁棒性并改善了泛化能力。

**Conclusion:** 该方法为传感器受限场景下有效的疲劳监测铺平了道路，证明了其在现实世界应用中的潜力。

> **ai_Abstract:** 本文针对现实世界中传感器受限的疲劳检测问题，提出了一种多源异构疲劳检测框架。该框架能够利用不同传感器配置的源域知识，并自适应地利用目标域中的可用模态。实验证明了该方法在实际应用中的实用性、鲁棒性和更好的泛化能力，为实际疲劳监测提供了有效途径。

> **摘要翻译:** 疲劳检测在航空、采矿和长途运输等安全关键应用中发挥着关键作用。然而，大多数现有方法依赖于高端传感器和受控环境，限制了它们在现实世界中的适用性。本文正式定义了一个实际但尚未充分探索的现实世界疲劳检测问题，其中系统在配备适应性传感器的前提下，旨在利用来自不同仪器来源的知识，包括那些在受控环境中部署了不实用传感器的来源。为了应对这一挑战，我们提出了一种异构多源疲劳检测框架，该框架自适应地利用目标域中可用的模态，同时受益于源域中存在的不同配置。我们的实验使用实际部署的传感器设置和两个公开数据集进行，结果证明了我们方法的实用性、鲁棒性以及改进的泛化能力，为传感器受限场景下有效的疲劳监测铺平了实用道路。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [684] [Terrain-Aware Adaptation for Two-Dimensional UAV Path Planners](https://arxiv.org/abs/2507.17519)
> *考虑地形的二维无人机路径规划器适应性*

*Kostas Karakontis, Thanos Petsanis, Athanasios Ch. Kapoutsis, Pavlos Ch. Kapoutsis, Elias B. Kosmatopoulos* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 无人机, 路径规划, 三维重建, 地形感知, DARP

**Comment:** 

> **TL;DR:** 该论文提出了一种模块化算法，用于扩展现有的二维无人机路径规划器，使其能够感知地形，通过调整高度和相机方向来改善三维重建，尤其是在具有垂直特征的区域。

**AI_Comments:** 该论文的创新之处在于其模块化方法，能够将现有的二维路径规划器升级为地形感知型，从而解决当前商业软件中三维重建不完整的问题。提供开源实现也大大增加了其实用性和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 流行的商业软件中的多无人机覆盖路径规划（mCPP）算法通常将感兴趣区域仅视为二维平面，忽略了重要的三维结构特征，导致三维重建不完整，尤其是在遮挡或垂直表面周围。

**Method:** 本文提出了一种模块化算法，通过调整高度和相机方向，扩展商业二维路径规划器以实现地形感知规划。为演示其效果，该算法扩展了DARP（优化多机器人覆盖路径规划的区域划分）算法，并生成了DARP-3D。

**Result:** 在多个三维环境中的模拟结果以及使用DJI硬件的真实飞行测试表明，与基线方法相比，该方法始终能够捕获改进的三维重建，特别是在具有显著垂直特征的区域。

**Conclusion:** 通过提出一种模块化算法来使二维无人机路径规划器适应地形，本研究成功改善了三维重建的完整性，尤其是在复杂地形区域。

> **ai_Abstract:** 本文提出了一种模块化算法，旨在克服现有商业多无人机覆盖路径规划（mCPP）算法忽略三维地形特征的局限性。通过调整无人机的高度和相机方向，该算法能将传统的二维路径规划器扩展为地形感知型。论文通过将DARP算法扩展为DARP-3D来验证其有效性，并在模拟和真实飞行测试中展示，该方法在三维重建方面取得了显著改进，尤其是在垂直特征丰富的区域。

> **摘要翻译:** 多无人机覆盖路径规划（mCPP）算法在流行的商业软件中通常只将感兴趣区域视为二维平面，忽略了重要的三维结构特征。这导致三维重建不完整，尤其是在遮挡或垂直表面周围。在本文中，我们提出了一种模块化算法，可以通过调整高度和相机方向来扩展商业二维路径规划器，以促进地形感知规划。为了演示它，我们扩展了著名的DARP（优化多机器人覆盖路径规划的区域划分）算法，并生成了DARP-3D。我们在多个三维环境和使用DJI硬件的真实飞行测试中展示了模拟结果。与基线相比，我们的方法始终能够捕获改进的三维重建，特别是在具有显著垂直特征的区域。该算法的开源实现可在以下链接获取：https://github.com/konskara/TerraPlan

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [700] [Collision-free Control Barrier Functions for General Ellipsoids via Separating Hyperplane](https://arxiv.org/abs/2505.20847)
> *无碰撞控制障碍函数用于一般椭球体通过分离超平面*

*Zeming Wu, Lu Liu* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-25**

**Keywords:** 碰撞避免, 控制障碍函数, 分离超平面, 椭球体, 单层优化

**Comment:** 

> **TL;DR:** 本文提出了一种基于控制障碍函数（CBFs）和分离超平面的通用椭球体新型碰撞避免方法，该方法通过单层优化显著减少计算时间，并已通过数值仿真和实际实验验证了其有效性和实用性。

**AI_Comments:** 创新点在于将对偶锥概念与分离超平面结合到CBF框架中，实现了通用椭球体的碰撞避免，并显著优化了计算效率，仅需单层优化。这对于实时机器人和自主系统中的安全控制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种针对一般椭球体的有效且可靠的碰撞避免方法，以克服现有方法在计算效率上的限制。

**Method:** 首先，利用对偶锥概念解析推导一般椭球体的无碰撞条件。然后，通过使用分离超平面扩展受控对象的系统动力学，将这些条件整合到控制障碍函数（CBF）框架中，从而实现高效可靠的碰撞避免。该方法仅需要单层优化。

**Result:** 所提出的无碰撞CBF的有效性得到严格证明。与现有技术相比，计算时间显著减少。数值模拟和实际实验证明了所提出算法的有效性和实用性。

**Conclusion:** 本文成功提出了一种基于控制障碍函数和分离超平面的新颖且高效的通用椭球体碰撞避免方法，并通过理论证明和实验验证了其有效性和实用性。

> **ai_Abstract:** 本文介绍了一种新颖的通用椭球体碰撞避免方法，该方法结合了控制障碍函数（CBFs）和分离超平面。研究人员首先利用对偶锥概念推导了无碰撞条件，然后将其整合到CBF框架中，通过扩展系统动力学实现高效可靠的碰撞避免。该方法仅需单层优化，显著降低了计算成本。理论证明、数值模拟和实际实验均验证了其有效性和实用性。

> **摘要翻译:** 本文提出了一种基于控制障碍函数（CBFs）和分离超平面的通用椭球体新型碰撞避免方法。首先，利用对偶锥的概念，解析推导了通用椭球体的无碰撞条件。这些条件通过使用分离超平面扩展受控对象的系统动力学，被纳入CBF框架中，从而实现高效可靠的碰撞避免。所提出的无碰撞CBF的有效性得到了严格证明，确保了它们在强制执行安全约束方面的有效性。与现有技术相比，所提出的方法仅需要单层优化，显著减少了计算时间。数值模拟和实际实验证明了所提出算法的有效性和实用性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [727] [CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation](https://arxiv.org/abs/2507.17727)
> *CA-Cut: 作物对齐剪裁用于数据增强以学习更鲁棒的冠层下导航*

*Robel Mamo, Taeyeong Choi* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 数据增强, 冠层下导航, 深度学习, 作物对齐剪裁, 鲁棒性

**Comment:** Accepted for publication at the 12th European Conference on Mobile
  Robots (ECMR 2025)

> **TL;DR:** 提出CA-Cut数据增强方法，通过在作物行周围掩盖区域来提高冠层下导航模型的鲁棒性和泛化性，显著减少预测误差。

**AI_Comments:** 本文创新性地提出了CA-Cut数据增强方法，通过模拟作物行周围的遮挡，有效解决了冠层下导航中数据稀缺和复杂环境鲁棒性不足的问题。其核心在于将掩码策略与作物空间分布相结合，这比传统的随机掩码更具针对性，能够更有效地促进模型学习对遮挡鲁棒的高级特征。该方法对于农业机器人和自动驾驶等领域的数据增强具有重要借鉴意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的冠层下视觉导航深度学习模型需要大量训练数据以确保可靠性，但数据收集成本高昂。传统数据增强技术在复杂冠层环境下表现不佳，难以模拟频繁遮挡和非均匀作物间距。

**Method:** 提出一种名为Crop-Aligned Cutout (CA-Cut) 的新型数据增强方法。该方法在输入图像中掩盖随机区域，这些区域空间上分布在作物行两侧，以鼓励训练模型在细粒度信息受阻时也能捕获高层上下文特征。

**Result:** 掩码增强有效模拟遮挡，显著提高了视觉导航中语义关键点预测的鲁棒性。特别是，CA-Cut中偏向作物行的掩码分布对于提高预测精度和跨环境泛化能力至关重要，预测误差最多减少36.9%。还进行了消融研究以确定掩码数量、大小和空间分布。

**Conclusion:** CA-Cut通过模拟遮挡并偏向作物行进行掩码，显著提高了冠层下导航模型的鲁棒性、预测精度和泛化能力。

> **ai_Abstract:** 本文提出了一种名为CA-Cut（作物对齐剪裁）的新型数据增强方法，旨在提高冠层下视觉导航模型的鲁棒性。针对传统增强技术在复杂遮挡环境下表现不足的问题，CA-Cut通过在作物行周围空间性地掩盖图像区域，促使模型学习高层上下文特征。实验证明，CA-Cut能有效模拟遮挡，显著提升语义关键点预测的准确性和模型在不同环境下的泛化能力，最高可将预测误差降低36.9%。

> **摘要翻译:** 最先进的视觉冠层下导航方法采用基于深度学习的感知模型来区分可通行空间和作物行。虽然这些模型已表现出成功的性能，但它们需要大量的训练数据才能确保在实际田间部署中的可靠性。然而，数据收集成本高昂，需要大量人力进行田间采样和标注。为了解决这一挑战，模型训练期间通常采用各种数据增强技术，例如颜色抖动、高斯模糊和水平翻转，以使训练数据多样化并增强模型鲁棒性。在本文中，我们假设仅使用这些增强技术可能会导致次优性能，尤其是在频繁遮挡、碎片和作物间距不均匀的复杂冠层下环境中。相反，我们提出了一种新颖的增强方法，即作物对齐剪裁 (CA-Cut)，它在输入图像中掩盖空间上分布在作物行两侧的随机区域，以鼓励训练模型即使在细粒度信息受阻时也能捕获高层上下文特征。我们对公共玉米田数据集进行的广泛实验表明，基于掩码的增强对于模拟遮挡和显著提高视觉导航中语义关键点预测的鲁棒性是有效的。特别是，我们表明，在CA-Cut中将掩码分布偏向作物行对于提高预测精度和跨不同环境的泛化能力至关重要，预测误差最多减少36.9%。此外，我们还进行了消融研究，以确定掩码的数量、每个掩码的大小以及掩码的空间分布，从而最大限度地提高整体性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [779] [Spatio-Temporal Motion Retargeting for Quadruped Robots](https://arxiv.org/abs/2404.11557)
> *四足机器人时空运动重定向*

*Taerim Yoon, Dongho Kang, Seungmin Kim, Jin Cheng, Minsung Ahn, Stelian Coros, Sungjoon Choi* | **Category: cs.RO** | **Updated: 2025-07-24**

**Keywords:** 运动重定向, 腿式机器人, 强化学习, 模仿学习, 四足机器人

**Comment:** 20 pages, 12 figures, videos available at
  https://taerimyoon.me/Spatio-Temporal-Motion-Retargeting-for-Quadruped-Robots/

> **TL;DR:** 该研究提出了一种针对腿式机器人的运动重定向方法，能将动态动作从源头转移到形态各异的机器人上，并通过真实世界的硬件实验成功部署。

**AI_Comments:** 该论文的创新之处在于其分阶段的运动重定向方法，结合运动学和动力学层面，并通过强化学习实现精确控制。其重要性体现在能够将非专业的、嘈杂的运动源（如手持视频）转换为可部署在不同形态机器人上的复杂动作，并在真实世界硬件上进行了验证，这对于机器人模仿学习和运动生成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在将动态敏捷的运动从源动作源转移到腿式机器人上，同时解决形态差异并确保目标系统的物理可行性。

**Method:** 该方法分两阶段进行：首先在运动学层面，通过关键点轨迹生成运动学上可行的全身运动；其次在动力学层面，通过调整时间域内的运动并遵守物理约束进行细化。此过程通过强化学习促进策略训练，实现精确鲁棒的运动跟踪。

**Result:** 该方法成功将手持摄像头视频等嘈杂的运动源转换为符合目标机器人形态和物理特性的特定机器人运动。此外，还展示了地形感知运动重定向，以在箱子上执行后空翻。这些技能已成功部署到四台尺寸和物理特性不同的真实世界机器人上。

**Conclusion:** 该研究成功开发并验证了一种能够将复杂运动从多种来源（包括嘈杂的视频）转移到不同形态的腿式机器人上的运动重定向方法，并在真实硬件上实现了精确和鲁棒的运动跟踪。

> **ai_Abstract:** 本研究提出了一种用于腿式机器人的时空运动重定向方法。该方法分两阶段进行：首先在运动学层面从关键点轨迹生成全身运动，然后通过在时间域内调整并在物理约束下进行细化，在动力学层面优化运动。该过程利用强化学习进行策略训练，实现了对嘈杂运动源（如手持视频）的精确鲁棒跟踪，并成功将动作（包括地形感知的后空翻）转移到形态各异的真实四足机器人上。

> **摘要翻译:** 这项工作提出了一种针对腿式机器人的运动重定向方法，旨在将动态敏捷的运动从源动作转移到机器人上。特别是，我们通过将运动从源转移到目标来指导模仿学习过程，有效地弥合了形态差异，同时确保了目标系统的物理可行性。在第一阶段，我们专注于运动学层面的运动重定向，通过关键点轨迹生成运动学上可行的全身运动。在此之后，我们通过在时间域内调整运动并遵守物理约束，在动力学层面细化运动。这个过程通过强化学习促进策略训练，从而实现精确和鲁棒的运动跟踪。我们证明了我们的方法成功地将嘈杂的运动源（例如手持摄像头视频）转换为与目标机器人的形态和物理特性相符的机器人特定运动。此外，我们还展示了地形感知运动重定向，以在箱子上执行后空翻。我们通过硬件实验将这些技能成功部署到四台具有不同尺寸和物理特性的真实世界机器人上。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [820] [RoboCar: A Rapidly Deployable Open-Source Platform for Autonomous Driving Research](https://arxiv.org/abs/2405.03572)
> *RoboCar：一个快速部署的自动驾驶研究开源平台*

*Mehdi Testouri, Gamal Elghazaly, Raphael Frank* | **Category: cs.RO** | **Updated: 2025-07-25**

**Keywords:** 自动驾驶, 开源平台, RoboCar, 车辆研究, 模块化系统

**Comment:** 

> **TL;DR:** RoboCar是一个基于2018款起亚Soul EV的模块化、低成本开源自动驾驶研究平台，已在卢森堡市的公共道路上进行真实世界测试。

**AI_Comments:** RoboCar的创新之处在于其作为自动驾驶研究的开源、模块化和成本效益高的平台。它通过利用现有车辆并最小化修改，降低了研究门槛。其在真实世界中的测试验证了其实用性，而开源性质则极大地促进了社区协作和技术传播，对自动驾驶领域的研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了提供一个模块化、经济高效的框架，用于开发实验性自动驾驶系统，并推进自动驾驶研究。

**Method:** 该平台利用2018款起亚Soul EV，集成了一个强大的硬件和软件架构，与车辆现有系统对齐，最大限度地减少了大量修改的需求。它支持各种自动驾驶功能。

**Result:** RoboCar平台已在卢森堡市的公共道路上进行了真实世界测试，并提供了初步测试结果，展示了其在推进自动驾驶研究中的应用。

**Conclusion:** RoboCar是一个可供任何人使用的开源平台，旨在通过提供一个模块化、经济高效的框架来促进自动驾驶研究的进展。

> **ai_Abstract:** 本文介绍了RoboCar，一个基于2018款起亚Soul EV的开源自动驾驶研究平台。该平台提供了一个模块化、经济高效的硬件和软件框架，与车辆现有系统集成，支持多种自动驾驶功能，并已在真实世界中进行测试。论文详细阐述了其架构、集成挑战和初步测试结果，旨在推动自动驾驶研究，并已开源。

> **摘要翻译:** 本文介绍了RoboCar，一个由卢森堡大学开发的用于自动驾驶的开源研究平台。RoboCar利用2018款起亚Soul EV，为实验性自动驾驶系统（ADS）的开发提供了一个模块化、经济高效的框架。该平台集成了一个强大的硬件和软件架构，与车辆现有系统对齐，最大限度地减少了大量修改的需求。它支持各种自动驾驶功能，并已在卢森堡市的公共道路上进行了真实世界测试。本文概述了该平台的架构、集成挑战和初步测试结果，为其在推进自动驾驶研究中的应用提供了见解。RoboCar可在https://github.com/sntubix/robocar上获取，并以MIT开源许可证发布。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [867] [RUMI: Rummaging Using Mutual Information](https://arxiv.org/abs/2408.10450)
> *RUMI：利用互信息进行翻找*

*Sheng Zhong, Nima Fazeli, Dmitry Berenson* | **Category: cs.RO, cs.AI, I.2.9** | **Updated: 2025-07-24**

**Keywords:** 机器人翻找, 互信息, 物体姿态估计, 模型预测控制, 视觉遮挡

**Comment:** 20 pages, 20 figures, accepted by IEEE Transactions on Robotics
  (T-RO), preprint

> **TL;DR:** RUMI是一种机器人在线动作序列生成方法，用于在视觉遮挡环境中通过接触式翻找来收集已知可移动物体的姿态信息。

**AI_Comments:** 这篇论文的创新点在于提出了RUMI方法，它巧妙地利用互信息来指导机器人在视觉遮挡环境中的接触式翻找，以估计物体姿态。其贡献在于开发了一个新的信念框架、高效的信息增益计算以及鲁棒的MPC控制方案，这些对于解决机器人感知和操作中的不确定性问题至关重要。该方法在实际应用中，特别是在需要机器人与环境交互以获取信息的场景中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在视觉遮挡环境中，机器人需要一种在线生成动作序列的方法，以收集关于已知可移动物体姿态的信息，尤其是在接触丰富的翻找任务中。

**Method:** RUMI利用物体姿态分布和机器人轨迹之间的互信息进行动作规划。它从部分点云推断物体姿态分布，并实时近似其与工作空间占据的互信息。该方法开发了信息增益和可达性成本函数，并将其集成到带有随机动力学模型的模型预测控制（MPC）框架中，以闭环方式更新姿态分布。主要贡献包括新的物体姿态估计信念框架、高效的信息增益计算策略和鲁棒的基于MPC的控制方案。

**Result:** RUMI在模拟和实际任务中都表现出优于基线方法的性能。

**Conclusion:** RUMI通过其创新的信念框架、高效的信息增益计算和鲁棒的MPC控制方案，有效解决了在视觉遮挡环境中通过接触式翻找进行物体姿态估计的问题，并展现了卓越的性能。

> **ai_Abstract:** RUMI是一种新颖的机器人方法，旨在视觉遮挡环境中通过接触式翻找在线估计已知物体的姿态。它利用物体姿态与机器人轨迹间的互信息进行动作规划，结合信息增益和可达性成本函数，并在MPC框架下实时更新物体姿态分布。该方法在模拟和实际任务中均表现出优异性能。

> **摘要翻译:** 本论文提出了Rummaging Using Mutual Information (RUMI)，这是一种在线生成机器人动作序列的方法，用于在视觉遮挡环境中收集已知可移动物体姿态的信息。RUMI专注于接触丰富的翻找，利用物体姿态分布和机器人轨迹之间的互信息进行动作规划。从观察到的部分点云中，RUMI推断出兼容的物体姿态分布，并实时近似其与工作空间占据的互信息。在此基础上，我们开发了信息增益成本函数和可达性成本函数，以使物体保持在机器人的可达范围内。这些函数被集成到一个带有随机动力学模型的模型预测控制（MPC）框架中，以闭环方式更新姿态分布。主要贡献包括一个新的物体姿态估计信念框架、一个高效的信息增益计算策略以及一个鲁棒的基于MPC的控制方案。RUMI在模拟和实际任务中都表现出优于基线方法的性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [10] [WaveMamba: Wavelet-Driven Mamba Fusion for RGB-Infrared Object Detection](https://arxiv.org/abs/2507.18173)
> *WaveMamba: 小波驱动的Mamba融合用于RGB-红外目标检测*

*Haodong Zhu, Wenhao Dong, Linlin Yang, Hong Li, Yuguang Yang, Yangyang Ren, Qingcheng Zhu, Zichao Feng, Changbai Li, Shaohui Lin, Runqi Wang, Xiaoyan Luo, Baochang Zhang* | **Category: cs.CV, cs.MM** | **Updated: 2025-07-24**

**Keywords:** RGB-红外目标检测, 跨模态融合, 小波变换, Mamba, 频率特征

**Comment:** 

> **TL;DR:** WaveMamba提出了一种用于RGB-红外目标检测的跨模态融合方法，通过离散小波变换分解RGB和红外图像的频率特征，并利用基于Mamba的融合块进行有效整合。该方法显著提升了目标检测性能，在四个基准测试中平均mAP提高了4.5%。

**AI_Comments:** 创新点：将离散小波变换与基于Mamba的融合块（WMFB、LMFB）创新性地结合用于跨模态RGB-红外目标检测。针对低频（Mamba、通道交换、门控注意力）和高频（绝对最大）特征融合的特定策略也值得关注。重要性：显著的性能提升（mAP提高4.5%）证明了其在RGB和红外数据可用目标检测实际应用中的有效性和潜力。局限性：Not mentioned in abstract。

<details>
  <summary>Details</summary>

**Motivation:** 利用可见光（RGB）和红外（IR）图像的互补特性能够显著提高目标检测的性能。

**Method:** 该论文提出了WaveMamba，一种跨模态融合方法，通过离散小波变换（DWT）有效整合RGB和IR图像的独特和互补频率特征。引入了WaveMamba融合块（WMFB）以促进低频/高频子带的全面融合。WMFB内部包含低频Mamba融合块（LMFB），其基于Mamba框架，通过通道交换进行初始低频特征融合，并结合先进的门控注意力机制进行深度融合。高频特征通过“绝对最大”融合策略增强。此外，还提出了一个结合逆离散小波变换（IDWT）的改进检测头以减少信息损失。

**Result:** 该方法带来了显著的性能提升，超越了最先进的方法，并在四个基准测试中实现了平均4.5%的mAP改进。

**Conclusion:** WaveMamba是一种新颖的跨模态融合方法，通过有效整合RGB和红外图像的频率特征，显著提高了目标检测的性能，超越了现有技术水平。

> **ai_Abstract:** 本文介绍了WaveMamba，一种用于RGB-红外目标检测的新型跨模态融合框架。它利用离散小波变换将RGB和红外图像分解为频率特征，然后使用专门的WaveMamba融合块进行融合。该融合块采用基于Mamba的低频Mamba融合块进行深度低频特征整合，并采用“绝对最大”策略处理高频特征。最终结果通过一个结合逆离散小波变换的改进检测头生成。WaveMamba显著优于现有最先进的方法，在四个基准测试中平均mAP提高了4.5%。

> **摘要翻译:** 利用可见光（RGB）和红外（IR）图像的互补特性为改进目标检测提供了巨大潜力。在本文中，我们提出了WaveMamba，一种跨模态融合方法，它能有效整合由离散小波变换（DWT）分解的RGB和IR图像的独特和互补的频率特征。为了减少信息损失并产生最终的检测结果，我们还提出了一种结合逆离散小波变换（IDWT）的改进检测头。我们方法的核心是引入了WaveMamba融合块（WMFB），它促进了低频/高频子带之间的全面融合。在WMFB内部，基于Mamba框架构建的低频Mamba融合块（LMFB）首先通过通道交换执行初始低频特征融合，然后通过先进的门控注意力机制进行深度融合以增强集成。高频特征通过应用“绝对最大”融合策略得到增强。这些进步带来了显著的性能提升，我们的方法超越了最先进的方法，并在四个基准测试中实现了平均4.5%的mAP改进。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [11] [KuiSCIMA v2.0: Improved Baselines, Calibration, and Cross-Notation Generalization for Historical Chinese Music Notations in Jiang Kui's Baishidaoren Gequ](https://arxiv.org/abs/2507.18741)
> *魁SCIMA v2.0：姜夔《白石道人歌曲》中历史中文乐谱的改进基线、校准和跨符号泛化*

*Tristan Repolusk, Eduardo Veas* | **Category: cs.CV, cs.DL, cs.SD, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 光学音乐识别, 历史中文乐谱, 字符识别, 姜夔, 数据不平衡

**Comment:** International Conference on Document Analysis and Recognition. This
  preprint has not undergone any post-submission improvements or corrections.
  The Version of Record of this contribution is published in "19th
  International Conference on Document Analysis and Recognition (ICDAR 2025),
  Wuhan, China, September 16-21, 2025, Proceedings", and is available online at
  the External DOI field below

> **TL;DR:** 针对姜夔《白石道人歌曲》中的历史中文乐谱，通过改进的字符识别模型和校准技术，显著提升了OMR性能，超越了人工转录，并扩展了数据集。

**AI_Comments:** 这项工作在处理历史中文乐谱OMR的独特挑战方面取得了显著进展，特别是在数据稀缺和类别不平衡的情况下。其创新之处在于通过改进模型和校准技术，实现了超越人类转录者的性能，并扩展了数据集，为文化遗产的数字化保护提供了重要支持。

<details>
  <summary>Details</summary>

**Motivation:** 历史中文乐谱（如数字谱和律吕谱）的光学音乐识别（OMR）由于类别高度不平衡和训练数据有限而面临独特挑战。

**Method:** 开发并评估了一个针对稀疏不平衡数据的字符识别模型；通过温度标定实现模型校准；使用留一版本交叉验证确保跨历史版本的鲁棒性；扩展了KuiSCIMA数据集。

**Result:** 数字谱的字符错误率（CER）从10.4%降至7.1%；律吕谱的CER达到0.9%；模型性能优于人工转录者（人类平均CER为15.9%，最佳为7.6%）；模型校准良好，ECE低于0.0162；在五个历史版本中表现稳健；KuiSCIMA数据集扩展至包含《白石道人歌曲》的全部109首乐曲。

**Conclusion:** 本研究成果推动了历史中文音乐的数字化和可及性，促进了OMR领域的文化多样性，并将其适用性扩展到代表性不足的音乐传统。

> **ai_Abstract:** 本文针对姜夔《白石道人歌曲》中的历史中文乐谱（如数字谱和律吕谱）的光学音乐识别（OMR）所面临的类别不平衡和数据稀缺问题，提出了显著改进。研究开发并评估了一个字符识别模型，显著降低了数字谱和律吕谱的字符错误率，并超越了人类转录者的表现。通过温度标定实现了模型校准，并采用留一版本交叉验证确保了跨历史版本的鲁棒性。此外，扩展了KuiSCIMA数据集。这些进展有助于历史中文音乐的数字化和文化多样性在OMR领域的推广。

> **摘要翻译:** 历史中文乐谱（如数字谱和律吕谱）的光学音乐识别（OMR）由于类别高度不平衡和训练数据有限而面临独特挑战。本文介绍了姜夔1202年有影响力的作品集《白石道人歌曲》在OMR方面的重大进展。在这项工作中，我们开发并评估了一个针对稀疏不平衡数据的字符识别模型。我们改进了之前的基线，将数字谱的字符错误率（CER）从10.4%降低到7.1%，尽管处理的是77个高度不平衡的类别，并为律吕谱实现了0.9%的卓越CER。我们的模型表现优于人工转录者，人工平均CER为15.9%，最佳情况下为7.6%。我们采用温度标定来实现一个校准良好的模型，其预期校准误差（ECE）低于0.0162。通过留一版本交叉验证方法，我们确保了模型在五个历史版本中的鲁棒性能。此外，我们扩展了KuiSCIMA数据集，包含了《白石道人歌曲》中的全部109首乐曲，涵盖了数字谱、律吕谱和减字谱。我们的研究结果推动了历史中文音乐的数字化和可及性，促进了OMR领域的文化多样性，并将其适用性扩展到代表性不足的音乐传统。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [14] [Leveraging the Structure of Medical Data for Improved Representation Learning](https://arxiv.org/abs/2507.02987)
> *利用医疗数据结构改进表示学习*

*Andrea Agostini, Sonia Laguna, Alain Ryser, Samuel Ruiperez-Campillo, Moritz Vandenhirtz, Nicolas Deperrois, Farhad Nooralahzadeh, Michael Krauthammer, Thomas M. Sutter, Julia E. Vogt* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 医疗数据, 表示学习, 自监督学习, 胸部X光片, MIMIC-CXR

**Comment:** 

> **TL;DR:** 提出一种自监督学习框架，利用医疗数据（如配对胸部X光片）的固有结构进行表示学习，无需文本监督，在MIMIC-CXR上表现优异，为数据稀缺但结构化的领域预训练提供轻量级通用蓝图。

**AI_Comments:** 这项工作通过创新的自监督学习方法，有效解决了医疗领域数据稀缺和标注不足的问题，其利用数据固有结构（如多视图图像配对）的策略非常巧妙且具有通用性。该方法无需文本监督，降低了对昂贵标注的依赖，为领域特定预训练提供了一个轻量级且模态无关的蓝图，对推动医疗AI发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 构建通用医疗AI系统需要数据高效且领域感知的预训练策略。临床数据集（如MIMIC-CXR）图像数量有限且标注稀缺，但具有多视图成像的丰富内部结构，因此需要一种能利用这种结构的方法。

**Method:** 提出一个自监督框架，利用医疗数据集的固有结构。具体地，将配对的胸部X光片（正面和侧面视图）视为自然正样本对，学习从稀疏补丁重建每个视图，同时对齐其潜在嵌入。该方法无需文本监督。

**Result:** 在MIMIC-CXR数据集上进行评估，与有监督目标和未利用结构训练的基线相比，该方法表现出强大的性能，并生成了信息丰富的表示。

**Conclusion:** 该工作为数据结构化但稀缺的领域特定预训练提供了一个轻量级、与模态无关的蓝图。

> **ai_Abstract:** 本文提出一种自监督框架，旨在通过利用医疗数据的固有结构（如配对胸部X光片）来改进表示学习。该方法将不同视图视为正样本对，并通过从稀疏补丁重建视图并对齐潜在嵌入来学习，无需文本监督。在MIMIC-CXR数据集上的实验证明，该方法在数据稀缺但结构化的医疗领域中，比传统有监督和未利用结构的方法表现更优，为构建通用医疗AI系统提供了有效途径。

> **摘要翻译:** 构建通用医疗AI系统需要数据高效且领域感知的预训练策略。与互联网规模的语料库不同，MIMIC-CXR等临床数据集图像数量有限且标注稀缺，但通过多视图成像展现出丰富的内部结构。我们提出了一种自监督框架，利用医疗数据集的固有结构。具体来说，我们将配对的胸部X光片（即正面和侧面视图）视为自然的阳性对，学习从稀疏补丁中重建每个视图，同时对齐它们的潜在嵌入。我们的方法不需要文本监督，并能生成信息丰富的表示。在MIMIC-CXR上进行评估，我们展示了与有监督目标和未利用结构训练的基线相比的强大性能。这项工作为数据结构化但稀缺的领域特定预训练提供了一个轻量级、与模态无关的蓝图。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [16] [Exploring the interplay of label bias with subgroup size and separability: A case study in mammographic density classification](https://arxiv.org/abs/2507.17996)
> *探究标签偏差与子组大小及可分离性的相互作用：乳腺密度分类的案例研究*

*Emma A. M. Stanley, Raghav Mehta, Mélanie Roschewitz, Nils D. Forkert, Ben Glocker* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 标签偏差, 子组公平性, 医学影像AI, 深度学习, 乳腺密度分类

**Comment:** Accepted at MICCAI Workshop on Fairness of AI in Medical Imaging
  (FAIMI) 2025

> **TL;DR:** 本研究探讨了医学影像数据集中标签偏差（特别是影响特定子组的系统性错误标记）如何影响深度学习模型的学习特征和性能，发现标签偏差对特征表示有显著影响，且这种影响取决于子组的大小和可分离性，并指出验证集标签质量对子组性能评估的重要性。

**AI_Comments:** 该研究创新性地探讨了医学影像AI中标签偏差对模型学习特征和子组公平性的影响，特别是考虑了子组大小和可分离性这两个关键维度。其发现验证集标签质量对性能评估的重要性，为未来医学AI系统的开发和评估提供了宝贵的实践指导。这是对AI公平性领域的重要贡献，尤其是在数据质量难以保证的医学领域。

<details>
  <summary>Details</summary>

**Motivation:** 医学影像数据集中影响特定子组的系统性错误标记（即标签偏差）是一个关于医学AI系统公平性且未被充分研究的问题。本研究旨在调查受标签偏差影响的子组的大小和可分离性如何影响深度学习模型的学习特征和性能。

**Method:** 研究人员使用EMory BrEast imaging Dataset (EMBED) 训练了用于二元组织密度分类的深度学习模型。他们在数据集中模拟了标签偏差，影响了可分离子组（基于影像制造商）或不可分离的“伪子组”。研究还比较了使用带有干净标签或带有偏差标签的验证集来定义分类阈值时的模型性能。

**Result:** 模拟的子组标签偏差导致模型学习到的特征表示出现显著偏移。特征空间中的这些偏移取决于受标签偏差影响的子组的相对大小和可分离性。在使用带有干净标签的验证集时，受标签偏差影响的多数可分离子组的真阳性率从0.898下降到使用带有偏差标签的验证集时的0.518，这表明验证集标签质量对子组性能有显著影响。

**Conclusion:** 本研究是理解标签偏差对医学影像AI中子组公平性后果的关键贡献。

> **ai_Abstract:** 本研究探讨了医学影像数据集中特定子组的标签偏差对深度学习模型性能和特征表示的影响。通过在乳腺密度分类任务中模拟标签偏差，研究发现偏差对模型学习到的特征表示有显著影响，且这种影响取决于受影响子组的大小和可分离性。此外，研究强调了验证集标签质量对子组公平性评估的重要性，指出使用带偏差标签的验证集会导致性能指标显著下降。这项工作为理解标签偏差对医学AI公平性的影响提供了重要见解。

> **摘要翻译:** 系统性错误标记影响特定子组（即标签偏差）在医学影像数据集中是一个关于医学AI系统公平性而未被充分研究的问题。在这项工作中，我们调查了受标签偏差影响的子组的大小和可分离性如何影响深度学习模型的学习特征和性能。因此，我们使用EMory BrEast imaging Dataset (EMBED) 训练了用于二元组织密度分类的深度学习模型，其中标签偏差影响了可分离子组（基于影像制造商）或不可分离的“伪子组”。我们发现模拟的子组标签偏差导致模型学习到的特征表示出现显著偏移。重要的是，特征空间中的这些偏移取决于受标签偏差影响的子组的相对大小和可分离性。我们还观察到，根据是否使用带有干净标签的验证集来定义模型的分类阈值，子组性能存在显著差异。例如，当标签偏差影响多数可分离子组时，该子组的真阳性率从验证集具有干净标签时的0.898下降到验证集具有偏差标签时的0.518。我们的工作是对理解标签偏差对医学影像AI中子组公平性后果的关键贡献。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [19] [Elucidating the Design Space of Arbitrary-Noise-Based Diffusion Models](https://arxiv.org/abs/2507.18534)
> *阐明基于任意噪声的扩散模型的设计空间*

*Xingyu Qiu, Mengying Yang, Xinghua Ma, Dong Liang, Yuzhen Li, Fanding Li, Gongning Luo, Wei Wang, Kuanquan Wang, Shuo Li* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 任意噪声, 图像恢复, 设计空间, 计算效率

**Comment:** 21 pages, 4 figures

> **TL;DR:** EDA扩展了扩散模型的设计空间，支持任意噪声，解决了传统模型在图像恢复中高斯噪声的局限性，并在多项任务中实现了SOTA性能，且无额外计算开销。

**AI_Comments:** 该论文的创新点在于打破了传统扩散模型对固定高斯噪声的依赖，引入了“任意噪声”的概念，显著拓宽了扩散模型在图像恢复领域的应用范围和性能上限。其理论证明了噪声复杂性增加不带来额外计算开销，这一点对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的EDM模型在图像恢复中受到固定高斯噪声模式的限制，强制注入高斯噪声会损坏降级图像，过度延长图像转换距离，并增加恢复复杂性。

**Method:** 本文提出了EDA（Elucidates the Design space of Arbitrary-noise-based diffusion models），它在理论上扩展了噪声模式的自由度，同时保留了EDM的模块灵活性。该方法经过严格证明，即使增加噪声复杂性也不会在恢复过程中引入额外的计算开销。

**Result:** EDA在MRI偏置场校正（全局平滑噪声）、CT金属伪影去除（全局尖锐噪声）和自然图像阴影去除（局部边界感知噪声）三个典型任务上进行了验证。仅需5个采样步骤，EDA就超越了大多数特定任务方法，并在偏置场校正和阴影去除方面取得了最先进的性能。

**Conclusion:** EDA通过引入任意噪声模式显著改进了扩散模型在图像恢复任务中的应用，实现了卓越的性能和计算效率，且不增加计算负担。

> **ai_Abstract:** 本文提出了EDA（Elucidates the Design space of Arbitrary-noise-based diffusion models），旨在解决现有扩散模型（如EDM）在图像恢复中因固定高斯噪声模式导致的局限性。EDA理论上扩展了噪声模式的自由度，同时保持了EDM的模块灵活性，并证明了其在增加噪声复杂性时不会产生额外的计算开销。实验结果表明，EDA在MRI偏置场校正、CT金属伪影去除和自然图像阴影去除等任务中，仅用5个采样步骤就能超越多数特定任务方法，并在偏置场校正和阴影去除方面达到最先进水平。

> **摘要翻译:** EDM阐明了扩散模型的统一设计空间，但其局限于纯高斯噪声的固定噪声模式限制了图像恢复的进展。我们的研究表明，强制注入高斯噪声会破坏降级图像，过度延长图像变换距离，并增加恢复复杂性。为了解决这个问题，我们提出的EDA（阐明基于任意噪声的扩散模型的设计空间）扩展了噪声模式的自由度，同时保留了EDM原有的模块灵活性，并有严格的证明表明，增加噪声复杂性在恢复过程中不会产生额外的计算开销。EDA在三个典型任务中得到了验证：MRI偏置场校正（全局平滑噪声）、CT金属伪影去除（全局尖锐噪声）和自然图像阴影去除（局部边界感知噪声）。仅用5个采样步骤，EDA就超越了大多数特定任务方法，并在偏置场校正和阴影去除方面取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [25] [Reinforced Embodied Active Defense: Exploiting Adaptive Interaction for Robust Visual Perception in Adversarial 3D Environments](https://arxiv.org/abs/2507.18484)
> *强化具身主动防御：利用自适应交互实现对抗性3D环境中的鲁棒视觉感知*

*Xiao Yang, Lingxuan Wu, Lizhong Wang, Chengyang Ying, Hang Su, Jun Zhu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 对抗攻击, 3D环境, 视觉感知, 强化学习, 主动防御

**Comment:** arXiv admin note: text overlap with arXiv:2404.00540

> **TL;DR:** 提出Rein-EAD，一种强化学习驱动的主动防御框架，通过环境交互提高3D对抗环境下的视觉感知鲁棒性。

**AI_Comments:** Rein-EAD的创新之处在于其主动防御策略，通过强化学习与环境进行自适应交互，而非传统被动防御的预设依赖。其无需可微分环境的特性，以及对未知和自适应攻击的强大泛化能力，使其在实际部署中更具可行性和潜力，对于提高安全敏感应用中视觉感知系统的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 3D环境中的对抗性攻击对视觉感知系统（尤其是在身份验证和自动驾驶等安全敏感应用中）构成严重威胁。现有防御机制多为被动策略，依赖预定义假设，在动态3D环境中适应性受限。

**Method:** 本文引入了强化具身主动防御（Rein-EAD）框架，这是一种主动防御策略，通过自适应探索和与环境的交互来提高3D对抗环境中的感知鲁棒性。Rein-EAD采用多步目标，平衡即时预测精度与预测熵最小化，以优化跨多步时间范围的防御策略。此外，它还包含一个面向不确定性的奖励整形机制，以促进高效的策略更新，减少计算开销，并支持无需可微分环境的实际应用。

**Result:** 全面的实验验证了Rein-EAD的有效性，证明其能显著降低攻击成功率，同时在各种任务中保持标准精度。值得注意的是，Rein-EAD对未知和自适应攻击表现出强大的泛化能力。

**Conclusion:** Rein-EAD是一种有效且通用的主动防御框架，能显著提高视觉感知系统在复杂3D对抗环境中的鲁棒性，并适用于3D物体分类、人脸识别和自动驾驶等多种实际应用。

> **ai_Abstract:** Rein-EAD是一种新颖的主动防御框架，旨在解决3D对抗攻击对视觉感知系统的威胁。它通过强化学习利用自适应环境交互来增强鲁棒性，采用多步目标平衡预测精度和熵最小化，并利用不确定性奖励整形机制优化防御策略。实验证明，Rein-EAD能有效降低攻击成功率，保持准确性，并对未知攻击具有良好泛化能力，适用于多种现实世界应用，如3D物体分类、人脸识别和自动驾驶。

> **摘要翻译:** 3D环境中的对抗性攻击已成为视觉感知系统可靠性的关键威胁，尤其是在身份验证和自动驾驶等安全敏感应用中。这些攻击利用对抗性补丁和3D物体，通过利用复杂场景中的漏洞来操纵深度神经网络(DNN)的预测。现有的防御机制，如对抗训练和净化，主要采用被动策略来增强鲁棒性。然而，这些方法通常依赖于对对抗策略的预定义假设，限制了它们在动态3D设置中的适应性。为了应对这些挑战，我们引入了强化具身主动防御(Rein-EAD)，这是一种主动防御框架，它利用自适应探索和与环境的交互来提高3D对抗环境中的感知鲁棒性。通过实现一个平衡即时预测精度和预测熵最小化的多步目标，Rein-EAD在多步时间范围内优化防御策略。此外，Rein-EAD还包含一个面向不确定性的奖励整形机制，有助于高效的策略更新，从而减少计算开销并支持实际应用，而无需可微分环境。全面的实验验证了Rein-EAD的有效性，证明在保持各种任务标准准确性的同时，显著降低了攻击成功率。值得注意的是，Rein-EAD对未知和自适应攻击表现出强大的泛化能力，使其适用于包括3D物体分类、人脸识别和自动驾驶在内的实际复杂任务。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [34] [PreMix: Label-Efficient Multiple Instance Learning via Non-Contrastive Pre-training and Feature Mixing](https://arxiv.org/abs/2408.01162)
> *PreMix：通过非对比预训练和特征混合实现标签高效的多示例学习*

*Bryan Wong, Mun Yong Yi* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 多示例学习, 全玻片图像, 非对比预训练, 标签效率, 病理学

**Comment:** Under review

> **TL;DR:** PreMix是一种新的多示例学习（MIL）框架，通过非对比预训练和特征混合，解决了WSI分类中MIL聚合器预训练不足的问题，在有限标签数据下显著提升了性能。

**AI_Comments:** PreMix的创新点在于它解决了MIL领域中聚合器预训练不足的关键问题，通过引入非对比预训练和特征混合策略，有效利用了大量未标记数据，并在有限标记数据下表现出卓越性能。这对于数据标注成本高昂的医疗图像分析领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前多示例学习（MIL）方法在全玻片图像（WSI）分类中存在关键局限性，即MIL聚合器预训练不足。大多数现有方法随机初始化聚合器并从头开始训练，这使得性能对标记WSI的数量高度敏感，并忽略了临床环境中普遍存在的未标记WSI的丰富性。

**Method:** 我们提出了PreMix框架，它利用非对比预训练方法Barlow Twins，并结合Slide Mixing方法生成额外的正样本对以增强特征学习，尤其是在标记WSI数量有限的情况下。此外，通过Mixup和Manifold Mixup进行微调，进一步提高了鲁棒性，有效处理了千兆像素WSI的不同尺寸。

**Result:** 实验结果表明，将PreMix作为插件模块集成到HIPT中，在各种WSI训练尺寸和数据集上，与基线HIPT相比，F1分数平均提高了4.7%。

**Conclusion:** 这些发现强调了PreMix在标记数据有限的情况下推进WSI分类的潜力，以及其在真实世界组织病理学实践中的适用性。

> **ai_Abstract:** 本文提出了PreMix，一个针对全玻片图像（WSI）分类中多示例学习（MIL）的标签高效框架。PreMix通过结合非对比预训练（Barlow Twins）和Slide Mixing来解决MIL聚合器预训练不足的问题，尤其是在有限的标记数据条件下。此外，它利用Mixup和Manifold Mixup增强模型在处理不同尺寸WSI时的鲁棒性。实验证明，PreMix作为HIPT的插件模块，能显著提升WSI分类性能，平均F1分数提高4.7%，显示了其在临床实践中的应用潜力。

> **摘要翻译:** 多实例学习（MIL）已成为一种强大的框架，用于弱监督全玻片图像（WSI）分类，无需详细的补丁级标注即可实现玻片级预测。尽管取得了成功，但当前MIL方法的一个关键局限性在于MIL聚合器预训练的利用不足。大多数现有方法随机初始化聚合器并从头开始训练，这使得性能对标记WSI的数量高度敏感，并忽略了临床环境中普遍存在的未标记WSI的丰富性。为了解决这个问题，我们提出了PreMix，一个新颖的框架，它利用非对比预训练方法Barlow Twins，并结合Slide Mixing方法来生成额外的正样本对并增强特征学习，特别是在标记WSI数量有限的条件下。通过Mixup和Manifold Mixup进行微调进一步增强了鲁棒性，通过有效处理千兆像素WSI的不同尺寸。实验结果表明，将PreMix作为插件模块集成到HIPT中，与基线HIPT相比，在各种WSI训练尺寸和数据集上，F1平均提高了4.7%。这些发现强调了其在标记数据有限的情况下推进WSI分类的潜力及其在真实世界组织病理学实践中的适用性。代码可在https://github.com/bryanwong17/PreMix获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [38] [Towards Effective Human-in-the-Loop Assistive AI Agents](https://arxiv.org/abs/2507.18374)
> *迈向高效的人在环辅助AI智能体*

*Filippos Bellos, Yayuan Li, Cary Shu, Ruey Day, Jeffrey M. Siskind, Jason J. Corso* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 人机协作, 辅助AI, 人在环, 增强现实, 任务表现

**Comment:** 10 pages, 5 figures, 2 tables

> **TL;DR:** 本研究引入了一个评估框架、一个多模态数据集和一个配备AR的AI智能体，旨在研究和改进物理任务中的人机协作，并证明AI辅助能有效提高任务完成度。

**AI_Comments:** 本文的创新之处在于解决了人机在环AI交互在物理任务中评估的挑战。引入专门的评估框架、多模态数据集和配备AR的AI智能体是其显著贡献。其重要性在于推动了有效人机协作的发展，并在不同领域展示了任务完成度的实际提升。

<details>
  <summary>Details</summary>

**Motivation:** 在物理任务中，有效的人机协作具有巨大潜力，但由于人机交互的复杂性，评估这种协作具有挑战性。本研究的动机是开发能提供信息指导的AI智能体，以增强人类表现。

**Method:** 引入了一个评估框架和一个人机交互多模态数据集。开发了一个配备增强现实（AR）的AI智能体，用于在真实世界任务中提供交互式指导。通过人体研究进行评估。

**Result:** 分享了关于AI辅助人类表现的实证见解，并证明了AI辅助协作可以提高任务完成度。

**Conclusion:** AI辅助协作能够提高程序性任务的完成度和人类表现。

> **ai_Abstract:** 本论文旨在解决物理任务中人机协作评估的挑战，为此引入了一个评估框架和一个多模态数据集。同时，开发了一个配备增强现实（AR）的AI智能体，用于在真实世界场景中提供交互式指导。通过人体研究，本研究证明了AI辅助协作能显著提高任务完成度和人类表现。

> **摘要翻译:** 在物理任务完成方面，有效的人机协作在日常活动和专业领域都具有巨大潜力。配备信息丰富指导的AI智能体可以提高人类表现，但由于人机交互的复杂性，评估这种协作仍然具有挑战性。在这项工作中，我们引入了一个评估框架和一个多模态人机交互数据集，旨在评估AI指导如何影响程序性任务表现、错误减少和学习成果。此外，我们开发了一个配备增强现实（AR）的AI智能体，可在从烹饪到战场医疗的真实世界任务中提供交互式指导。通过人体研究，我们分享了关于AI辅助人类表现的实证见解，并证明了AI辅助协作可以提高任务完成度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [42] [Outdoor Monocular SLAM with Global Scale-Consistent 3D Gaussian Pointmaps](https://arxiv.org/abs/2507.03737)
> *户外单目SLAM与全局尺度一致的3D高斯点图*

*Chong Cheng, Sicheng Yu, Zijian Wang, Yifan Zhou, Hao Wang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D Gaussian Splatting, SLAM, Monocular, Outdoor, Scale-Consistent

**Comment:** Accepted by ICCV2025

> **TL;DR:** S3PO-GS是一种新的户外单目3DGS SLAM方法，通过自洽跟踪和基于补丁的动态建图解决了尺度漂移和几何先验缺失问题，实现了高精度跟踪和新视角合成。

**AI_Comments:** 这篇论文的创新点在于其提出了一种鲁棒的户外单目3DGS SLAM方法S3PO-GS，特别解决了现有方法在户外环境中面临的尺度漂移和几何先验缺失问题。通过引入自洽跟踪模块和基于补丁的动态建图模块，显著提升了跟踪精度和场景重建质量，使其在复杂户外场景下具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3DGS SLAM方法在户外场景中缺乏几何先验，或在相机大幅移动时存在累积误差和尺度漂移问题。

**Method:** 提出S3PO-GS方法，一种鲁棒的仅RGB户外3DGS SLAM。技术上，它建立了一个锚定在3DGS点图中的自洽跟踪模块，以避免累积尺度漂移并实现更精确和鲁棒的跟踪。此外，设计了一个基于补丁的点图动态建图模块，引入了几何先验并避免了尺度模糊性。

**Result:** S3PO-GS在Waymo、KITTI和DL3DV数据集上的实验表明，在新视角合成方面达到了最先进的结果，并在跟踪精度方面优于其他3DGS SLAM方法。

**Conclusion:** S3PO-GS成功解决了户外单目3DGS SLAM中尺度漂移和几何先验缺失的挑战，显著提高了跟踪精度和场景重建质量，特别适用于复杂的户外环境。

> **ai_Abstract:** S3PO-GS是一种新颖的、仅使用RGB图像的户外单目3DGS SLAM方法，旨在解决现有3DGS SLAM方法在户外场景中缺乏几何先验和尺度漂移的问题。该方法通过引入一个自洽跟踪模块来避免累积尺度漂移，并设计一个基于补丁的点图动态建图模块来引入几何先验并消除尺度模糊性。实验结果表明，S3PO-GS在多个户外数据集上实现了最先进的新视角合成性能和更高的跟踪精度。

> **摘要翻译:** 3D高斯泼溅（3DGS）因其高保真和实时的新视角合成性能，已成为SLAM领域流行的解决方案。然而，一些先前的3DGS SLAM方法采用可微分渲染管道进行跟踪，在户外场景中缺乏几何先验。其他方法引入了独立的跟踪模块，但它们会随着相机的大幅移动而累积误差，导致尺度漂移。为了解决这些挑战，我们提出了一种鲁棒的仅RGB户外3DGS SLAM方法：S3PO-GS。技术上，我们建立了一个锚定在3DGS点图中的自洽跟踪模块，该模块避免了累积尺度漂移，并以更少的迭代次数实现了更精确和鲁棒的跟踪。此外，我们设计了一个基于补丁的点图动态建图模块，该模块引入了几何先验，同时避免了尺度模糊性。这显著增强了跟踪精度和场景重建质量，使其特别适用于复杂的户外环境。我们在Waymo、KITTI和DL3DV数据集上的实验表明，S3PO-GS在新视角合成方面取得了最先进的结果，并在跟踪精度方面优于其他3DGS SLAM方法。项目页面：https://3dagentworld.github.io/S3PO-GS/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [48] [FedVSR: Towards Model-Agnostic Federated Learning in Video Super-Resolution](https://arxiv.org/abs/2503.13745)
> *FedVSR：迈向视频超分辨率中的模型无关联邦学习*

*Ali Mollaahmadi Dehaghi, Hossein KhademSohi, Reza Razavi, Steve Drew, Mohammad Moshirpour* | **Category: cs.CV, cs.DC** | **Updated: 2025-07-24**

**Keywords:** 视频超分辨率, 联邦学习, 模型无关, 隐私保护, 低级视觉

**Comment:** This version includes an updated abstract and introduction for
  improved clarity and context. We also added the LPIPS metric to our
  evaluation results to provide a more comprehensive assessment of perceptual
  quality

> **TL;DR:** FedVSR是首个专为视频超分辨率设计的联邦学习框架，它通过引入轻量级损失函数和损失感知聚合策略，在保护隐私的同时显著提高了超分辨率性能。

**AI_Comments:** FedVSR的创新之处在于它是首个专为VSR设计的联邦学习框架，解决了传统FL在低级视觉任务中表现不佳的问题。其引入的基于DWT的轻量级损失函数和损失感知聚合策略是关键创新点，有效提升了在保护隐私前提下的超分辨率性能，为低级视觉领域的联邦学习树立了新标杆。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在视频超分辨率（VSR）方面取得了显著进展，但通常需要集中式数据，这引发了隐私担忧。联邦学习（FL）提供了一种保护隐私的解决方案，但通用FL框架在低级视觉任务中表现不佳，导致输出模糊、质量低下。

**Method:** 本文引入了FedVSR，这是首个专为VSR设计的联邦学习框架。它具有模型无关和无状态的特点，并引入了一种基于DWT的轻量级损失函数，以在本地训练期间更好地保留高频细节。此外，一种损失感知聚合策略结合了基于DWT的损失和任务特定损失，以有效指导全局更新。

**Result:** FedVSR在多个VSR模型和数据集上的广泛实验表明，它始终优于现有FL方法，PSNR最高提高0.82 dB，SSIM最高提高0.0327，LPIPS最低降低0.0251。这些结果强调了FedVSR弥合隐私和性能之间差距的能力。

**Conclusion:** FedVSR成功弥合了视频超分辨率任务中隐私保护与性能之间的差距，为低级视觉任务中的联邦学习设定了新的基准。

> **ai_Abstract:** 本文提出了FedVSR，一个针对视频超分辨率（VSR）设计的首个模型无关、无状态联邦学习（FL）框架，旨在解决传统FL在低级视觉任务中性能不佳和集中式数据带来的隐私问题。FedVSR引入了基于DWT的轻量级损失函数以保留高频细节，并结合了损失感知聚合策略进行全局更新。实验证明，FedVSR在多项指标上显著优于现有FL方法，有效平衡了隐私保护与VSR性能。

> **摘要翻译:** 视频超分辨率旨在通过利用空间和时间信息来增强低分辨率视频。虽然深度学习取得了令人瞩目的进展，但它通常需要集中式数据，这引发了隐私担忧。联邦学习提供了一种保护隐私的解决方案，但通用FL框架在低级视觉任务中往往表现不佳，导致输出模糊、质量低下。为了解决这个问题，我们引入了FedVSR，这是首个专为VSR设计的联邦学习框架。它具有模型无关和无状态的特点，并引入了一种基于DWT的轻量级损失函数，以在本地训练期间更好地保留高频细节。此外，一种损失感知聚合策略结合了基于DWT的损失和任务特定损失，以有效指导全局更新。在多个VSR模型和数据集上的广泛实验表明，FedVSR始终优于现有FL方法，PSNR最高提高0.82 dB，SSIM最高提高0.0327，LPIPS最低降低0.0251。这些结果强调了FedVSR弥合隐私和性能之间差距的能力，为低级视觉任务中的联邦学习设定了新的基准。代码可在https://github.com/alimd94/FedVSR获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [51] [Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization](https://arxiv.org/abs/2507.15765)
> *从异质性中学习：通过分布鲁棒优化泛化动态面部表情识别*

*Feng-Qi Cui, Anyang Tong, Jinyang Huang, Jie Zhang, Dan Guo, Zhi Liu, Meng Wang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 动态面部表情识别, 异质性, 分布鲁棒优化, 注意力机制, 对比学习

**Comment:** Accepted by ACM MM'25

> **TL;DR:** 本文提出了一种名为HDF的新型框架，通过引入DAM和DSM模块，以解决动态面部表情识别（DFER）中由多源数据和个体表情变异引起的样本异质性问题，显著提高了识别准确性和鲁棒性。

**AI_Comments:** 该论文的创新点在于提出了HDF框架，并设计了DAM和DSM两个模块来专门解决DFER中的样本异质性问题。DAM通过双分支注意力设计，有效处理了时序和频率上的变异，而DSM则通过自适应优化策略平衡了损失，从而提升了模型的稳定性和判别力。这种针对异质性数据的鲁棒优化方法对于实际应用中复杂多变的面部表情数据具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有动态面部表情识别（DFER）方法在多源数据和个体表情变异导致的样本异质性下，性能会下降。为了解决这些挑战，需要一种能泛化并提高鲁棒性的方法。

**Method:** 本文提出了一个名为异质性感知分布框架（HDF）的新型框架。该框架设计了两个即插即用模块：1. 时频分布注意力模块（DAM），通过双分支注意力设计捕获时间一致性和频率鲁棒性，以提高对序列不一致性和视觉风格变化的容忍度。2. 分布感知缩放模块（DSM），基于梯度敏感性和信息瓶颈原理，动态平衡分类和对比损失，实现更稳定和有判别力的表示学习。

**Result:** 在DFEW和FERV39k两个广泛使用的数据集上进行的实验表明，HDF显著提高了识别准确性和鲁棒性。该方法在保持对多样化和不平衡场景的强大泛化能力的同时，实现了优越的加权平均召回率（WAR）和非加权平均召回率（UAR）。

**Conclusion:** HDF框架通过有效处理样本异质性，显著提高了动态面部表情识别的准确性和泛化能力，使其在面对多样化和不平衡数据时表现出更强的鲁棒性。

> **ai_Abstract:** 本文针对动态面部表情识别（DFER）中因多源数据和个体差异导致的样本异质性问题，提出了一种新型框架——异质性感知分布框架（HDF）。HDF包含两个核心模块：时频分布注意力模块（DAM），用于捕捉时序一致性和频率鲁棒性；以及分布感知缩放模块（DSM），用于动态平衡损失以优化表示学习。实验证明，HDF在识别准确性和鲁棒性方面均有显著提升，并在多样化和不平衡的数据集上展现出强大的泛化能力。

> **摘要翻译:** 动态面部表情识别（DFER）在情感计算和人机交互中发挥着关键作用。尽管现有方法取得了可比的性能，但它们不可避免地受到多源数据和个体表情变异引起的样本异质性导致的性能下降。为了应对这些挑战，我们提出了一种新颖的框架，称为异质性感知分布框架（HDF），并设计了两个即插即用模块来增强时频建模并缓解由困难样本引起的优化不平衡。具体而言，时频分布注意力模块（DAM）通过双分支注意力设计捕获时间一致性和频率鲁棒性，提高了对序列不一致性和视觉风格变化的容忍度。然后，基于梯度敏感性和信息瓶颈原理，引入了一个自适应优化模块——分布感知缩放模块（DSM），以动态平衡分类和对比损失，从而实现更稳定和有判别力的表示学习。在两个广泛使用的数据集DFEW和FERV39k上进行的广泛实验表明，HDF显著提高了识别准确性和鲁棒性。我们的方法在保持对多样化和不平衡场景的强大泛化能力的同时，实现了优越的加权平均召回率（WAR）和非加权平均召回率（UAR）。代码已在https://github.com/QIcita/HDF_DFER发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [52] [Unsupervised Domain Adaptation for 3D LiDAR Semantic Segmentation Using Contrastive Learning and Multi-Model Pseudo Labeling](https://arxiv.org/abs/2507.18176)
> *使用对比学习和多模型伪标签的3D LiDAR语义分割无监督域适应*

*Abhishek Kaushik, Norbert Haala, Uwe Soergel* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 无监督域适应, 3D LiDAR语义分割, 对比学习, 伪标签, 域偏移

**Comment:** 

> **TL;DR:** 本研究提出了一种结合对比学习预训练和多模型伪标签的两阶段框架，用于3D LiDAR语义分割的无监督域适应，有效解决了域偏移问题，无需目标域标注。

**AI_Comments:** 本论文的创新之处在于结合了对比学习和多模型集成伪标签，有效解决了3D LiDAR语义分割中的域偏移问题，尤其是在缺乏目标域标注的情况下。这种两阶段的方法提高了模型的鲁棒性和泛化能力，对自动驾驶等实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 由于域偏移（如传感器类型、地理位置）导致3D LiDAR语义分割性能下降，这对于自动驾驶系统至关重要，但手动标注目标数据成本过高。

**Method:** 本研究提出一种两阶段的无监督域适应框架。首先，在段级别使用无监督对比学习预训练骨干网络，以学习鲁棒的域不变特征。其次，引入多模型伪标签策略，利用多种最先进的架构（包括投影、体素、混合和基于圆柱的方法）的集成，通过硬投票聚合预测结果，为未标记的目标域生成高质量的伪标签。最后，使用这些伪标签对对比预训练的网络进行微调。

**Result:** 在从SemanticKITTI到未标记目标数据集（SemanticPOSS、SemanticSlamantic）的适应实验中，与直接迁移和单模型UDA方法相比，分割精度显著提高。

**Conclusion:** 结合对比预训练和精炼的集成伪标签可以有效弥合复杂的域差距，而无需目标域标注。

> **ai_Abstract:** 本研究提出了一种用于3D LiDAR语义分割的无监督域适应（UDA）两阶段框架。该框架首先通过无监督对比学习预训练网络以学习域不变特征，然后采用多模型伪标签策略，通过集成多种先进模型生成高质量的伪标签。实验证明，该方法在应对域偏移方面显著优于现有方法，无需目标域标注。

> **摘要翻译:** 由于域偏移（例如，传感器类型、地理位置）导致3D LiDAR语义分割性能下降，这对于自动驾驶系统至关重要，但手动标注目标数据成本过高。本研究通过无监督域适应（UDA）解决了这一挑战，并引入了一种新颖的两阶段框架来应对它。最初，在段级别使用无监督对比学习来预训练骨干网络，使其能够在没有标签的情况下学习鲁棒的、域不变的特征。随后，引入了一种多模型伪标签策略，该策略利用多种最先进的架构（包括投影、体素、混合和基于圆柱的方法）的集成。通过硬投票聚合这些模型的预测结果，为未标记的目标域生成高质量的、精炼的伪标签，从而减轻了单模型偏差。然后，使用这些鲁棒的伪标签对经过对比预训练的网络进行微调。在从SemanticKITTI到未标记目标数据集（SemanticPOSS、SemanticSlamantic）的适应实验中，与直接迁移和单模型UDA方法相比，分割精度显著提高。这些结果强调了结合对比预训练和精炼的集成伪标签在弥合复杂域差距方面的有效性，而无需目标域标注。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [61] [TTS-VAR: A Test-Time Scaling Framework for Visual Auto-Regressive Generation](https://arxiv.org/abs/2507.18537)
> *TTS-VAR：一种用于视觉自回归生成的测试时缩放框架*

*Zhekai Chen, Ruihang Chu, Yukang Chen, Shiwei Zhang, Yujie Wei, Yingya Zhang, Xihui Liu* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 测试时缩放, 视觉自回归, 生成模型, 多尺度生成, 计算效率

**Comment:** 10 Tables, 9 Figures

> **TL;DR:** TTS-VAR是一个用于视觉自回归模型的测试时缩放框架，通过动态批处理大小、基于聚类的多样性搜索和基于重采样的潜力选择，显著提高了生成质量。

**AI_Comments:** 该论文提出了一种创新的测试时缩放框架TTS-VAR，首次将其应用于视觉自回归模型，通过结合动态批处理、多样性搜索和潜力选择，有效提高了生成质量，对于资源受限的视觉生成场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩展视觉生成模型对于实际内容创建至关重要，但需要大量的训练和计算开销。测试时缩放因其资源效率和有前景的性能而受到日益增长的关注。

**Method:** 本文提出了TTS-VAR，这是第一个针对视觉自回归（VAR）模型的通用测试时缩放框架，将生成过程建模为路径搜索问题。为动态平衡计算效率与探索能力，该框架引入了贯穿因果生成过程的自适应递减批处理大小调度。此外，受VAR分层粗到细多尺度生成的启发，TTS-VAR整合了两个关键组件：(i) 在粗尺度上，提出基于聚类的多样性搜索，通过语义特征聚类保留结构多样性。(ii) 在细尺度上，基于重采样的潜力选择利用结合多尺度生成历史的奖励函数（潜力分数）来优先选择有前景的候选。

**Result:** 在强大的VAR模型Infinity上的实验表明，GenEval分数显著提高了8.7%（从0.69到0.75）。

**Conclusion:** 关键见解表明，早期结构特征有效影响最终质量，并且重采样效率在不同生成尺度上有所不同。

> **ai_Abstract:** 本文提出了TTS-VAR，一个用于视觉自回归（VAR）模型的首个通用测试时缩放框架。该框架将生成过程视为路径搜索问题，并通过引入自适应递减批处理大小调度来平衡计算效率和探索能力。针对VAR的分层多尺度生成特性，TTS-VAR在粗尺度上采用基于聚类的多样性搜索来保持结构多样性，在细尺度上则通过基于重采样的潜力选择来优先处理有前景的候选。实验结果显示，该方法在GenEval分数上取得了显著提升，并揭示了早期结构特征对最终质量的重要性。

> **摘要翻译:** 扩展视觉生成模型对于实际内容创建至关重要，但需要大量的训练和计算开销。或者，测试时缩放因其资源效率和有前景的性能而受到日益增长的关注。在这项工作中，我们提出了TTS-VAR，这是第一个用于视觉自回归（VAR）模型的通用测试时缩放框架，将生成过程建模为路径搜索问题。为了动态平衡计算效率和探索能力，我们首先在整个因果生成过程中引入了自适应递减批处理大小调度。此外，受VAR分层粗到细多尺度生成的启发，我们的框架集成了两个关键组件：(i) 在粗尺度上，我们观察到生成的令牌难以评估，可能导致错误地接受劣质样本或拒绝优质样本。注意到粗尺度包含足够的结构信息，我们提出了基于聚类的多样性搜索。它通过语义特征聚类保留了结构多样性，从而能够在以后选择具有更高潜力的样本。(ii) 在细尺度上，基于重采样的潜力选择使用潜力分数优先选择有前景的候选，潜力分数被定义为结合多尺度生成历史的奖励函数。在强大的VAR模型Infinity上的实验表明，GenEval分数显著提高了8.7%（从0.69到0.75）。关键见解表明，早期结构特征有效影响最终质量，并且重采样效率在不同生成尺度上有所不同。代码可在https://github.com/ali-vilab/TTS-VAR获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [70] [QR-LoRA: Efficient and Disentangled Fine-tuning via QR Decomposition for Customized Generation](https://arxiv.org/abs/2507.04599)
> *QR-LoRA：通过QR分解实现高效解耦微调以进行定制化生成*

*Jiahui Yang, Yongjia Ma, Donglin Di, Hao Li, Wei Chen, Yan Xie, Jianxun Cui, Xun Yang, Wangmeng Zuo* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** QR-LoRA, 微调, QR分解, 特征解耦, 参数高效

**Comment:** ICCV 2025, 30 pages, 26 figures

> **TL;DR:** QR-LoRA通过QR分解实现参数高效且解耦的微调，解决了传统LoRA在内容-风格融合中特征纠缠的问题，并减少了可训练参数。

**AI_Comments:** 这篇论文的创新点在于将QR分解引入LoRA微调中，通过结构化参数更新有效解决了传统LoRA在多模型融合时存在的特征纠缠问题。其利用Q矩阵的正交性实现特征解耦，并显著减少了可训练参数，是参数高效和解耦微调领域的重要进展，对于需要复杂属性融合的定制化生成任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本到图像模型中的LoRA等参数微调技术在结合多个LoRA模型进行内容-风格融合任务时，权重矩阵的非结构化修改常导致内容和风格属性之间出现不期望的特征纠缠。

**Method:** 提出QR-LoRA框架，利用QR分解进行结构化参数更新，有效分离视觉属性。其核心思想是正交Q矩阵自然地最小化不同视觉特征之间的干扰，而上三角R矩阵高效编码属性特定的变换。该方法固定Q和R矩阵，同时仅训练一个额外的任务特定ΔR矩阵。

**Result:** 实验表明QR-LoRA在内容-风格融合任务中实现了卓越的解耦，为生成模型中的参数高效、解耦微调建立了新范式。

**Conclusion:** QR-LoRA通过结构化的QR分解实现了高效且解耦的微调，显著解决了传统LoRA在多模型融合时的特征纠缠问题，并减少了可训练参数，为定制化生成提供了新的解决方案。

> **ai_Abstract:** QR-LoRA是一种新的微调框架，通过利用QR分解来解决现有LoRA在文本到图像模型中多模型融合时内容与风格特征纠缠的问题。它通过固定正交Q和上三角R矩阵，仅训练一个额外的任务特定ΔR矩阵，从而实现了参数的高效和视觉属性的有效解耦。这种方法不仅减少了可训练参数，还支持无交叉污染的多适应合并，并在内容-风格融合任务中表现出卓越的解耦性能，为生成模型中的高效解耦微调提供了新范式。

> **摘要翻译:** 现有文本到图像模型通常依赖于参数微调技术，例如低秩适应（LoRA），以定制视觉属性。然而，当结合多个LoRA模型进行内容-风格融合任务时，权重矩阵的非结构化修改常常导致内容和风格属性之间出现不期望的特征纠缠。我们提出了QR-LoRA，一个新颖的微调框架，利用QR分解进行结构化参数更新，从而有效分离视觉属性。我们的关键洞察是，正交Q矩阵自然地最小化了不同视觉特征之间的干扰，而上三角R矩阵有效地编码了属性特定的变换。我们的方法固定Q和R矩阵，同时仅训练一个额外的任务特定ΔR矩阵。这种结构化设计将可训练参数减少到传统LoRA方法的一半，并且由于ΔR矩阵之间强大的解耦特性，支持有效合并多个适应而不会发生交叉污染。实验表明，QR-LoRA在内容-风格融合任务中实现了卓越的解耦，为生成模型中的参数高效、解耦微调建立了新范式。项目页面可在：https://luna-ai-lab.github.io/QR-LoRA/ 访问。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [72] [Registration beyond Points: General Affine Subspace Alignment via Geodesic Distance on Grassmann Manifold](https://arxiv.org/abs/2507.17998)
> *超越点的配准：基于格拉斯曼流形测地距离的广义仿射子空间对齐*

*Jaeho Shin, Hyeonjae Gil, Junwoo Jang, Maani Ghaffari, Ayoung Kim* | **Category: cs.CV** | **Updated: 2025-07-25**

**Keywords:** 配准, 格拉斯曼流形, 仿射子空间, 测地距离, 成本函数

**Comment:** 

> **TL;DR:** 本文首次推导了一个可优化的格拉斯曼流形特征间关于刚体变换的成本函数，解决了现有方法在配准问题中的局限性，并实现了全局最优解，提高了计算机视觉任务的收敛性和性能。

**AI_Comments:** 本文的创新点在于首次明确推导了格拉斯曼流形上关于刚体变换的可优化成本函数，解决了长期以来阻碍其在配准问题中应用的关键瓶颈。通过直接最小化测地距离，该方法能够找到全局最优解并避免表示模糊性，这对于高维数据配准具有重要意义。其在计算机视觉任务中的表现也验证了其有效性和优越性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于仿射格拉斯曼流形的方法虽然在理论上能精确测量特征间的距离，但缺乏一个关于刚体变换的显式可优化距离函数，这限制了它们在配准问题中的应用。

**Method:** 本文首次明确推导了一个关于刚体变换（R和t）的格拉斯曼特征之间的可优化成本函数。通过严格的数学证明，展示了高维线性子空间的基础可以作为成本的显式表示。最终，提出了一种基于变换基的可优化成本函数，适用于任何仿射子空间的配准问题。该方法通过直接最小化测地距离来找到全局最优解，且对表示模糊性不敏感。

**Result:** 与基于向量参数的方法相比，本文方法能够找到全局最优解，并通过直接最小化测地距离来避免表示模糊性。所得到的成本函数及其在内点集最大化分支定界（BnB）求解器中的扩展，已被证明可以改善现有解决方案的收敛性或在各种计算机视觉任务中超越它们。

**Conclusion:** 本文成功推导并提出了一种创新的、可优化的格拉斯曼流形特征间成本函数，使得仿射子空间配准问题能够通过直接最小化测地距离实现全局最优解，显著提升了配准的性能和收敛性，克服了现有方法的局限性。

> **ai_Abstract:** 本文首次提出了一种针对格拉斯曼流形特征的可优化成本函数，用于解决仿射子空间配准问题。该方法通过数学证明，利用高维线性子空间基作为成本的显式表示，并直接最小化测地距离以实现全局最优解，有效避免了表示模糊性。实验证明，该方法在各种计算机视觉任务中显著提高了现有解决方案的收敛性并超越了其性能。

> **摘要翻译:** 仿射格拉斯曼流形因其在测量线和平面之间距离方面的理论精确性而备受青睐。尽管有此优势，现有方法只能测量接近度，而无法将距离作为刚体变换的显式函数。因此，流形上可优化的距离函数一直未得到充分发展，阻碍了其在配准问题中的应用。本文首次明确推导了两个格拉斯曼特征之间相对于刚体变换（R和t）的可优化成本函数。具体而言，我们提出了严格的数学证明，证明高维线性子空间的基础可以作为成本的显式表示。最后，我们提出了一种基于变换基的可优化成本函数，可应用于任何仿射子空间的配准问题。与基于向量参数的方法相比，我们的方法能够通过直接最小化对表示模糊性不透明的测地距离来找到全局最优解。所得到的成本函数及其在内点集最大化分支定界（BnB）求解器中的扩展，已被证明可以改善现有解决方案的收敛性或在各种计算机视觉任务中超越它们。代码可在https://github.com/joomeok/GrassmannRegistration上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [75] [Closing the Modality Gap for Mixed Modality Search](https://arxiv.org/abs/2507.19054)
> *弥合混合模态搜索的模态鸿沟*

*Binxu Li, Yuhui Zhang, Xiaohan Wang, Weixin Liang, Ludwig Schmidt, Serena Yeung-Levy* | **Category: cs.CV, cs.AI, cs.CL, cs.IR, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 混合模态搜索, 模态鸿沟, 对比学习, 视觉-语言模型, CLIP, GR-CLIP

**Comment:** Project page: https://yuhui-zh15.github.io/MixedModalitySearch/

> **TL;DR:** 现有视觉语言模型在混合模态搜索中存在模态鸿沟，导致性能不佳。本文提出GR-CLIP，一种轻量级校准方法，有效弥合模态鸿沟，显著提升混合模态搜索性能，且计算成本低。

**AI_Comments:** 本文创新性地指出了对比视觉-语言模型在混合模态搜索中存在的“模态鸿沟”问题，并提出了一个轻量级且高效的后处理校准方法GR-CLIP来解决它。其在性能上的显著提升和计算成本的大幅降低，使其在实际应用中具有重要价值，尤其是在资源受限的环境下。同时，引入MixBench这一新基准也填补了该领域的空白。

<details>
  <summary>Details</summary>

**Motivation:** 混合模态搜索是一个重要但未充分探索的实际应用。现有对比视觉-语言模型（如CLIP）在混合模态搜索任务中存在模态鸿沟，导致检索性能受限。

**Method:** 提出GR-CLIP，一种轻量级的后处理校准方法，用于消除CLIP嵌入空间中的模态鸿沟。

**Result:** 在MixBench基准测试中，GR-CLIP相对于CLIP在NDCG@10上提升高达26个百分点，超越近期视觉-语言生成嵌入模型4个百分点，同时计算量减少75倍。

**Conclusion:** GR-CLIP成功弥合了对比视觉-语言模型（如CLIP）在混合模态搜索中的模态鸿沟，显著提升了检索性能并降低了计算成本，证明了其在实际应用中的有效性和效率。

> **ai_Abstract:** 本文针对混合模态搜索中现有视觉-语言模型（如CLIP）存在的模态鸿沟问题进行了深入研究。研究发现，CLIP的图像和文本嵌入形成独立簇，导致检索性能受限。为解决此问题，论文提出了GR-CLIP，一种轻量级后处理校准方法，旨在消除嵌入空间中的模态鸿沟。在首个混合模态搜索基准MixBench上的实验表明，GR-CLIP显著提升了检索性能，并且计算效率远高于现有方法。

> **摘要翻译:** 混合模态搜索——从由图像、文本和多模态文档组成的异构语料库中检索信息——是一个重要但未充分探索的现实世界应用。在这项工作中，我们研究了对比视觉-语言模型，例如CLIP，在混合模态搜索任务上的表现。我们的分析揭示了一个关键限制：这些模型在嵌入空间中表现出明显的模态鸿沟，其中图像和文本嵌入形成不同的簇，导致模态内排序偏差和模态间融合失败。为了解决这个问题，我们提出了GR-CLIP，一种轻量级的后处理校准方法，可以消除CLIP嵌入空间中的模态鸿沟。在专门为混合模态搜索设计的第一个基准测试MixBench上进行评估，GR-CLIP相对于CLIP在NDCG@10上提升高达26个百分点，超越近期视觉-语言生成嵌入模型4个百分点，同时计算量减少75倍。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [81] [Explaining How Visual, Textual and Multimodal Encoders Share Concepts](https://arxiv.org/abs/2507.18512)
> *解释视觉、文本和多模态编码器如何共享概念*

*Clément Cornet, Romaric Besançon, Hervé Le Borgne* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 稀疏自编码器, 特征共享, 跨模态比较, 视觉编码器, 文本编码器

**Comment:** 

> **TL;DR:** 本研究提出了一种新指标和方法，用于定量比较视觉、文本和多模态编码器之间通过稀疏自编码器（SAE）提取的特征共享程度，并发现文本预训练对视觉-语言模型（VLM）中视觉特征与文本编码器共享有显著影响。

**AI_Comments:** 这项研究的创新之处在于提出了一个量化跨模态编码器特征共享的新工具，这对于理解不同模态模型如何协同工作以及多模态训练的影响至关重要。通过对大量编码器进行实证分析，揭示了文本预训练在促进视觉和文本特征共享方面的关键作用，为未来多模态模型设计提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 以往基于稀疏自编码器（SAE）特征的模型比较仅限于相同模态内的模型，缺乏跨模态编码器之间特征共享的定量比较方法。

**Method:** 提出了一种新颖的指标，用于跨SAE特征对模型进行定量比较。提出量化不同类别模型之间个体特征的“比较共享度”（Comparative Sharedness）。使用这两种新工具对21个不同类型、不同规模的编码器，以及通用和领域特定数据集进行了多项研究。

**Result:** 研究结果允许重新审视在多模态背景下训练的编码器，并量化所有这些模型共享表示或特征的程度。结果还表明，在视觉编码器中，视觉-语言模型（VLM）特有的视觉特征与文本编码器共享，突出了文本预训练的影响。

**Conclusion:** 本研究通过提出的新工具，成功量化了视觉、文本和多模态编码器之间特征的共享程度，并强调了文本预训练在促进跨模态特征共享方面的关键作用。

> **ai_Abstract:** 本论文引入了一种新颖的指标和方法，用于定量比较视觉、文本和多模态编码器之间通过稀疏自编码器（SAE）提取的特征共享程度，解决了以往研究仅限于单一模态的局限性。研究通过分析21个不同类型的编码器，发现这些模型之间存在显著的特征共享，并特别指出文本预训练对视觉-语言模型（VLM）中视觉特征与文本编码器共享具有重要影响。

> **摘要翻译:** 稀疏自编码器（SAE）已成为一种从神经网络激活中提取人类可解释特征的强大技术。以往基于SAE派生特征的模型比较仅限于相同模态内的模型。我们提出了一种新颖的指标，允许对跨SAE特征的模型进行定量比较，并用它来对视觉、文本和多模态编码器进行比较研究。我们还提出量化不同类别模型之间个体特征的“比较共享度”（Comparative Sharedness）。利用这两个新工具，我们对21个三种类型、两种显著不同大小的编码器，并考虑了通用和领域特定数据集，进行了多项研究。结果允许在多模态背景下训练的编码器光照下重新审视以前的研究，并量化所有这些模型共享某些表示或特征的程度。它们还表明，视觉编码器中VLM特有的视觉特征与文本编码器共享，突出了文本预训练的影响。代码可在https://github.com/CEA-LIST/SAEshareConcepts获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [83] [Optimizing against Infeasible Inclusions from Data for Semantic Segmentation through Morphology](https://arxiv.org/abs/2408.14672)
> *通过形态学优化语义分割中数据导致的不可行包含*

*Shamik Basu, Luc Van Gool, Christos Sakaridis* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 语义分割, 形态学, 不可行包含, 数据约束, 深度学习

**Comment:** 

> **TL;DR:** 该研究提出了一种名为InSeIn的轻量级方法，通过提取并惩罚训练数据中语义类别的不可行包含，以提高语义分割模型在不同数据集上的预测可行性和性能。

**AI_Comments:** 该论文的创新点在于引入了“不可行语义包含”的概念，并提出了一种基于形态学损失的方法来强制学习模型遵守空间语义关系。这种方法有效地弥补了纯数据驱动训练的不足，解决了模型在领域漂移下产生不合理分割的问题。其“即插即用”和“轻量级”的特性使其具有较高的实用价值和推广潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的语义分割模型通常纯粹以数据驱动的方式优化，仅最小化像素或片段的分类目标。当输入图像域与训练域不同时，这可能导致荒谬的分割结果，例如将“道路”标签分配给被标记为“天空”的片段所包含的区域，而现有数据集的真值表明这种包含是不可行的。

**Method:** 本文提出的Infeasible Semantic Inclusions (InSeIn) 方法分两步进行：首先，离线地从语义分割训练数据集中提取管理空间类别关系的显式包含约束；然后，在训练过程中引入一个可微分的形态学损失函数，惩罚违反这些约束的行为，以促进预测的可行性。InSeIn是一种轻量级的即插即用方法。

**Result:** InSeIn方法在ADE20K、Cityscapes和ACDC数据集上，对各种最先进的网络都产生了持续显著的性能改进，并有效减少了学习分割模型预测中的不可行语义包含。

**Conclusion:** InSeIn作为一种轻量级即插即用方法，通过强制执行形态学约束来最小化语义分割模型预测中的不可行包含，显著提高了模型在多个数据集上的性能，是提升预测可行性的重要一步。

> **ai_Abstract:** 本文提出了一种名为Infeasible Semantic Inclusions (InSeIn) 的新方法，旨在解决语义分割模型中因纯数据驱动优化导致的不可行分割问题。该方法通过离线提取训练数据中固有的空间类别包含约束，并在训练过程中引入一个可微分的形态学损失来惩罚违反这些约束的情况，从而强制模型预测具有可行性。InSeIn是一种轻量级、即插即用的解决方案，在多个主流数据集上显著提升了现有最先进语义分割模型的性能。

> **摘要翻译:** 最先进的语义分割模型通常以数据驱动的方式进行优化，仅最小化其训练数据上的每像素或每片段分类目标。这种纯粹的数据驱动范式常常导致荒谬的分割结果，特别是当输入图像的领域与训练期间遇到的领域发生偏移时。例如，最先进的模型可能会将“道路”标签分配给被另一个分别标记为“天空”的片段所包含的片段。然而，现有数据集的真值表明这种包含是不可行的。我们的方法，不可行语义包含（InSeIn），首先以离线、数据驱动的方式从现有语义分割训练集中提取管理空间类别关系的显式包含约束，然后强制执行一个形态学但可微分的损失，在训练期间惩罚违反这些约束的行为，以促进预测的可行性。InSeIn是一种轻量级的即插即用方法，是最小化学习分割模型预测中不可行语义包含的新一步，并在ADE20K、Cityscapes和ACDC数据集上，对各种最先进的网络都产生了持续显著的性能改进。https://github.com/SHAMIK-97/InSeIn/tree/main

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [94] [Differential-UMamba: Rethinking Tumor Segmentation Under Limited Data Scenarios](https://arxiv.org/abs/2507.18177)
> *Differential-UMamba：重新思考有限数据场景下的肿瘤分割*

*Dhruv Jain, Romain Modzelewski, Romain Hérault, Clement Chatelain, Eva Torfeh, Sebastien Thureau* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 肿瘤分割, 深度学习, 有限数据, UNet, Mamba

**Comment:** 

> **TL;DR:** Diff-UMamba是一种结合了UNet和mamba机制的新型架构，通过其噪声消除模块在数据稀缺场景下提高了肿瘤分割的准确性和鲁棒性。

**AI_Comments:** 本文在有限数据场景下对肿瘤分割进行了重新思考，其创新点在于将UNet与mamba机制结合，并引入了独特的噪声消除模块（NRM）。该模块通过信号差分策略有效解决了深度学习模型在数据稀缺时易过拟合噪声的问题，提高了模型对临床相关区域的关注。这对于医学图像分析领域，尤其是罕见疾病或隐私数据受限的应用场景，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在数据稀缺场景下，深度学习模型容易过拟合噪声和不相关模式，限制了其对未见样本的泛化能力。本文旨在解决医学图像分割中面临的这些挑战。

**Method:** 本文引入了Diff-UMamba，一种结合UNet框架和mamba机制的新型架构，用于建模长程依赖。其核心是噪声消除模块（NRM），该模块采用信号差分策略来抑制编码器中的噪声或不相关激活，从而过滤掉虚假特征并增强任务相关表示。

**Result:** Diff-UMamba在低数据设置下实现了更高的分割精度和鲁棒性。在MSD（肺和胰腺）和AIIB23等多个公共数据集上，其性能比基线方法提高了1-3%。在BraTS-21数据集上通过改变训练样本比例进行额外实验，并在内部非小细胞肺癌（NSCLC）锥形束CT（CBCT）总肿瘤体积（GTV）分割数据集上比基线提高了4-5%。

**Conclusion:** Diff-UMamba通过创新的噪声抑制机制，在数据有限的医疗图像分割任务中显著提高了模型的准确性和泛化能力。

> **ai_Abstract:** 本文提出了Diff-UMamba，一种专门针对数据稀缺场景下肿瘤分割的深度学习架构。它结合了UNet和mamba机制，并引入了一个噪声消除模块（NRM），通过信号差分策略有效抑制噪声和不相关特征，从而增强任务相关表示。实验结果表明，Diff-UMamba在多个公共和内部数据集上均能显著提高分割精度和鲁棒性，尤其是在低数据量设置下。

> **摘要翻译:** 在数据稀缺的场景下，深度学习模型常常过拟合噪声和不相关模式，这限制了它们对未见样本的泛化能力。为了解决医学图像分割中的这些挑战，我们引入了Diff-UMamba，这是一种结合了UNet框架和mamba机制的新型架构，用于建模长程依赖。Diff-UMamba的核心是一个噪声消除模块（NRM），它采用信号差分策略来抑制编码器内部的噪声或不相关激活。这鼓励模型过滤掉虚假特征并增强与任务相关的表示，从而提高其对临床有意义区域的关注。因此，该架构实现了更高的分割精度和鲁棒性，特别是在低数据设置下。Diff-UMamba在多个公共数据集上进行了评估，包括MSD（肺和胰腺）和AIIB23，在各种分割任务中均比基线方法持续提高了1-3%的性能。为了进一步评估有限数据条件下的性能，还在BraTS-21数据集上通过改变可用训练样本的比例进行了额外实验。该方法还在一个小的内部非小细胞肺癌（NSCLC）数据集上进行了验证，用于锥形束CT（CBCT）中的总肿瘤体积（GTV）分割，在该数据集上，它比基线提高了4-5%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [95] [Towards Consistent Long-Term Pose Generation](https://arxiv.org/abs/2507.18382)
> *迈向一致的长期姿态生成*

*Yayuan Li, Filippos Bellos, Jason Corso* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 姿态生成, 长期生成, 单阶段架构, 连续坐标, 相对运动预测

**Comment:** 10 pages, 5 figures, 4 tables

> **TL;DR:** 本文提出了一种新颖的单阶段架构，可以直接从图像和文本描述中在连续坐标空间生成姿态，避免了中间表示和累积误差，在长期姿态生成中表现优于现有方法。

**AI_Comments:** 本文的创新之处在于提出了一种端到端的单阶段姿态生成架构，有效解决了传统方法中中间表示导致的误差累积问题，尤其在长期姿态生成场景下展现出优越性。直接在连续坐标空间操作和统一占位符token策略是其核心亮点，有望推动长期时序生成任务的发展。

<details>
  <summary>Details</summary>

**Motivation:** 当前的姿态生成方法依赖于中间表示（如量化或自回归模型），导致在推理过程中累积误差，特别是在需要保持时间连贯性的长期姿态生成中性能下降。

**Method:** 我们提出了一种新颖的单阶段架构，可以直接从单一RGB图像和文本描述等最小上下文生成连续坐标空间中的姿态。其关键创新在于通过相对运动预测机制直接在姿态坐标上操作，消除了对中间表示或基于token的生成的需求，并通过统一的占位符token方法实现了训练和推理时行为一致的单次前向生成。

**Result:** 在Penn Action和First-Person Hand Action Benchmark (F-PHAB) 数据集上的大量实验表明，我们的方法显著优于现有的基于量化和自回归的方法，特别是在长期生成场景中。

**Conclusion:** 本文提出的单阶段架构通过直接在连续坐标空间生成姿态，并采用相对运动预测和统一占位符token方法，有效解决了传统方法在长期姿态生成中存在的误差累积和性能下降问题，实现了更优异的表现。

> **ai_Abstract:** 该论文提出了一种创新的单阶段架构，用于长期姿态生成。与依赖中间表示的现有方法不同，该模型直接从单一RGB图像和文本描述在连续坐标空间中生成姿态。通过采用相对运动预测机制和统一的占位符token方法，它避免了误差累积，并在训练和推理之间保持一致性。实验证明，该方法在长期姿态生成任务中显著优于基于量化和自回归的现有方法。

> **摘要翻译:** 当前姿态生成方法严重依赖中间表示，无论是通过带有量化的两阶段流水线还是在推理过程中累积误差的自回归模型。这种根本性限制导致性能下降，尤其是在保持时间连贯性至关重要的长期姿态生成中。我们提出了一种新颖的单阶段架构，可以直接从最小上下文（单一RGB图像和文本描述）在连续坐标空间中生成姿态，同时保持训练和推理之间的一致分布。我们的主要创新在于通过保留空间关系的相对运动预测机制和实现训练与推理行为一致的统一占位符token方法，直接在姿态坐标上操作，从而消除了对中间表示或基于token的生成的需求。通过在Penn Action和First-Person Hand Action Benchmark (F-PHAB) 数据集上进行的大量实验，我们证明了我们的方法显著优于现有的基于量化和自回归的方法，尤其是在长期生成场景中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [98] [Residual Prior-driven Frequency-aware Network for Image Fusion](https://arxiv.org/abs/2507.06735)
> *残差先验驱动的图像融合频率感知网络*

*Guan Zheng, Xue Wang, Wenhua Qian, Peng Liu, Runzhuo Ma* | **Category: cs.CV, cs.LG, cs.MM** | **Updated: 2025-07-24**

**Keywords:** 图像融合, 残差先验, 频率感知网络, 双分支, 深度学习

**Comment:** 

> **TL;DR:** 本文提出RPFNet，一个残差先验驱动的频率感知网络，用于图像融合。它通过双分支架构（残差先验模块、频域融合模块）和交叉促进模块，结合多种损失函数，有效集成判别性特征，增强细节，并促进高级视觉任务。

**AI_Comments:** RPFNet的创新点在于其独特的双分支架构，特别是引入残差先验来捕捉模态特异性差异，并通过频域处理实现高效的全局特征建模，有效规避了传统空间域建模的高计算成本。结合多种损失函数，特别是频率对比损失，进一步提升了模型在无真值情况下的表现。该方法为图像融合领域提供了一个高效且鲁实用的解决方案，对提升高级视觉任务的性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 图像融合旨在整合跨模态互补信息以生成高质量融合图像，从而提升高级视觉任务性能。然而，全局空间建模机制计算成本高昂，且缺乏真值加剧了有效捕获互补特征的难度。

**Method:** 本文提出RPFNet（残差先验驱动的频率感知网络）。RPFNet采用双分支特征提取框架：残差先验模块（RPM）从残差图中提取模态特异性差异信息，提供互补先验；频域融合模块（FDFM）通过频域卷积实现高效的全局特征建模和集成。此外，交叉促进模块（CPM）通过双向特征交互增强局部细节和全局结构的协同感知。训练过程中，引入辅助解码器和显著性结构损失以增强模型对模态特异性差异的敏感性；结合基于自适应权重的频率对比损失和SSIM损失，有效约束解空间，促进局部细节和全局特征的联合捕获，同时确保互补信息的保留。

**Result:** 广泛的实验验证了RPFNet的融合性能，它能有效整合判别性特征，增强纹理细节和显著目标，并能有效促进高级视觉任务的部署。

**Conclusion:** RPFNet通过结合残差先验和频域处理，有效解决了图像融合中全局特征建模的计算成本和真值缺失导致的互补特征捕获难题，成功整合了判别性特征并增强了细节，从而提升了高级视觉任务的性能。

> **ai_Abstract:** 本文提出了一种名为RPFNet的残差先验驱动的频率感知网络，旨在解决图像融合中全局空间建模的计算成本高昂以及缺乏真值导致难以有效捕获互补特征的问题。RPFNet采用双分支特征提取框架，包括利用残差图提取模态特异性差异信息的残差先验模块（RPM）和通过频域卷积进行高效全局特征建模的频域融合模块（FDFM）。此外，交叉促进模块（CPM）用于增强局部细节与全局结构的协同感知。在训练阶段，模型引入了辅助解码器、显著性结构损失、自适应权重频率对比损失和SSIM损失，以强化模型对差异的敏感性并约束解空间。实验结果表明，RPFNet能有效融合判别性特征，增强纹理细节和显著目标，并有助于高级视觉任务的部署。

> **摘要翻译:** 图像融合旨在整合跨模态互补信息以生成高质量融合图像，从而提升高级视觉任务性能。尽管全局空间建模机制显示出有前景的结果，但在空间域构建长程特征依赖会产生巨大的计算成本。此外，真值的缺失加剧了有效捕获互补特征的难度。为了解决这些挑战，我们提出了一种残差先验驱动的频率感知网络，命名为RPFNet。具体而言，RPFNet采用双分支特征提取框架：残差先验模块（RPM）从残差图中提取模态特异性差异信息，从而为融合提供互补先验；频域融合模块（FDFM）通过频域卷积实现高效的全局特征建模和集成。此外，交叉促进模块（CPM）通过双向特征交互增强局部细节和全局结构的协同感知。在训练过程中，我们引入辅助解码器和显著性结构损失以增强模型对模态特异性差异的敏感性。此外，结合基于自适应权重的频率对比损失和SSIM损失，有效约束解空间，促进局部细节和全局特征的联合捕获，同时确保互补信息的保留。广泛的实验验证了RPFNet的融合性能，它能有效整合判别性特征，增强纹理细节和显著目标，并能有效促进高级视觉任务的部署。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [103] [Unposed 3DGS Reconstruction with Probabilistic Procrustes Mapping](https://arxiv.org/abs/2507.18541)
> *使用概率Procrustes映射的无姿态3DGS重建*

*Chong Cheng, Zijian Wang, Sicheng Yu, Yu Hu, Nanjie Yao, Hao Wang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3DGS, 无姿态重建, 概率Procrustes映射, 点云对齐, 姿态估计

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的无姿态3DGS重建框架，通过概率Procrustes映射和联合优化，在大规模户外数据集上实现了最先进的重建效果。

**AI_Comments:** 该论文的创新点在于将概率Procrustes映射引入到无姿态3DGS重建中，有效地解决了大规模户外图像序列的姿态估计和点云对齐问题。通过子图划分、高效的全局对齐以及3DGS与姿态的联合优化，显著提升了重建的准确性和效率，特别是在处理大量未校准图像方面取得了突破，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在处理数百张户外图像的无姿态3DGS重建任务中，现有的多视角立体（MVS）模型常受限于内存并随着输入图像数量增加而精度下降。

**Method:** 该方法提出一个新颖的无姿态3DGS重建框架，将预训练的MVS先验与概率Procrustes映射策略相结合。具体而言，它将输入图像划分为子集，通过将数千万点云的映射公式化为概率Procrustes问题并求解封闭形式对齐，将子图映射到全局空间。通过概率耦合和软垃圾箱机制拒绝不确定对应，该方法在数分钟内全局对齐点云和姿态。此外，它提出了一个3DGS和相机姿态的联合优化框架，从置信度感知的锚点构建高斯，并结合3DGS可微分渲染与解析雅可比矩阵来共同优化场景和姿态。

**Result:** 在Waymo和KITTI数据集上的实验表明，该方法能够从无姿态图像序列中实现精确重建，并为无姿态3DGS重建树立了新的技术标杆。

**Conclusion:** 本文提出的框架有效解决了大规模户外图像无姿态3DGS重建的挑战，通过创新的概率Procrustes映射和联合优化策略，显著提升了重建精度和姿态估计能力，达到了行业领先水平。

> **ai_Abstract:** 本文提出了一种新颖的无姿态3DGS重建框架，旨在解决现有MVS模型在处理大量户外图像时面临的内存和精度问题。该方法将输入图像划分为子集，通过创新的概率Procrustes映射策略将子图点云高效对齐到全局空间，并采用概率耦合和软垃圾箱机制处理不确定对应。在此基础上，框架进一步联合优化3DGS的几何结构和相机姿态，通过从置信度锚点构建高斯并集成可微分渲染与解析雅可比矩阵。实验证明，该方法在Waymo和KITTI数据集上实现了卓越的无姿态图像序列重建精度，树立了新的技术标杆。

> **摘要翻译:** 3D高斯泼溅（3DGS）已成为3D表示的核心技术。其有效性在很大程度上取决于精确的相机姿态和准确的点云初始化，这些通常来源于预训练的多视角立体（MVS）模型。然而，在处理数百张户外图像的无姿态重建任务中，现有MVS模型可能会受到内存限制的困扰，并且随着输入图像数量的增加而失去精度。为了解决这一限制，我们提出了一种新颖的无姿态3DGS重建框架，该框架将预训练的MVS先验与概率Procrustes映射策略相结合。该方法将输入图像划分为子集，将子图映射到全局空间，并与3DGS联合优化几何和姿态。技术上，我们将数千万点云的映射公式化为一个概率Procrustes问题，并求解封闭形式对齐。通过采用概率耦合以及软垃圾箱机制来拒绝不确定对应关系，我们的方法能够在数分钟内对数百张图像中的点云和姿态进行全局对齐。此外，我们提出了一个3DGS和相机姿态的联合优化框架。它从置信度感知的锚点构建高斯，并将3DGS可微分渲染与解析雅可比矩阵相结合，以共同细化场景和姿态，从而实现精确重建和姿态估计。在Waymo和KITTI数据集上的实验表明，我们的方法能够从无姿态图像序列中实现精确重建，为无姿态3DGS重建树立了新的技术标杆。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [112] [Swin-TUNA : A Novel PEFT Approach for Accurate Food Image Segmentation](https://arxiv.org/abs/2507.17347)
> *Swin-TUNA：一种用于精确食物图像分割的新型PEFT方法*

*Haotian Chen, Zhiyong Xiao* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 食物图像分割, PEFT, Swin Transformer, 参数高效微调, 语义分割

**Comment:** After discussion among the authors, some parts of the paper are
  deemed inappropriate and will be revised and resubmitted

> **TL;DR:** Swin-TUNA是一种参数高效微调（PEFT）方法，通过在Swin Transformer中集成多尺度可训练适配器，以极少的参数（更新4%）实现了高性能食物图像分割，在保持高准确性的同时显著降低了计算资源需求。

**AI_Comments:** Swin-TUNA的创新性在于其将多尺度可训练适配器与Swin Transformer结合，并引入了分层特征适应机制，有效解决了大型模型在实际部署中的资源限制问题。其通过仅更新极少量参数便能达到甚至超越全参数模型的性能，对于资源受限的边缘设备和工业应用具有重要意义。该方法在参数效率和性能之间取得了出色的平衡。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于Transformer的大规模模型（如FoodSAM）在食物图像处理领域面临参数量巨大和计算资源需求高的问题，难以满足实际部署要求。

**Method:** 本文提出了Swin-TUNA，一种参数高效微调（PEFT）方法，它将多尺度可训练适配器集成到Swin Transformer架构中。其核心创新在于分层特征适应机制：设计了不同尺度的深度可分离卷积和维度映射，以处理浅层和深层网络之间的特征差异，并结合了任务无关和任务特定特征的动态平衡策略。

**Result:** Swin-TUNA在FoodSeg103和UECFoodPix Complete数据集上分别达到了50.56%和74.94%的mIoU，超越了完全参数化的FoodSAM模型，同时将参数量减少了98.7%（仅8.13M）。此外，Swin-TUNA在低数据场景下表现出更快的收敛速度和更强的泛化能力。

**Conclusion:** Swin-TUNA为组装轻量级食物图像分割提供了高效解决方案，解决了现有大规模模型在实际部署中的挑战，并在参数效率和性能之间取得了良好平衡。

> **ai_Abstract:** Swin-TUNA是一种新颖的参数高效微调（PEFT）方法，旨在解决现有大型Transformer模型在食物图像分割中参数量大、计算成本高的问题。该方法通过在Swin Transformer中集成多尺度可训练适配器，仅更新4%的参数即可实现高性能分割。Swin-TUNA的核心在于其分层特征适应机制，通过深度可分离卷积和动态平衡策略处理不同层级的特征。实验证明，Swin-TUNA在多个数据集上超越了全参数化的FoodSAM模型，同时将参数量大幅减少98.7%，并展现出更快的收敛速度和更强的泛化能力，为轻量级食物图像分割提供了高效实用的解决方案。

> **摘要翻译:** 在食物图像处理领域，高效的语义分割技术对于工业应用至关重要。然而，现有的大规模基于Transformer的模型（如FoodSAM）由于其庞大的参数量和高计算资源需求，在满足实际部署要求方面面临挑战。本文介绍了可调适配器模块（Swin-TUNA），这是一种参数高效微调（PEFT）方法，它将多尺度可训练适配器集成到Swin Transformer架构中，通过仅更新4%的参数实现了高性能食物图像分割。Swin-TUNA的核心创新在于其分层特征适应机制：它设计了不同尺度的深度可分离卷积和维度映射，以解决浅层和深层网络之间的特征差异，并结合了任务无关和任务特定特征的动态平衡策略。实验表明，该方法在FoodSeg103和UECFoodPix Complete数据集上分别达到了50.56%和74.94%的mIoU，超越了完全参数化的FoodSAM模型，同时将参数量减少了98.7%（仅8.13M）。此外，Swin-TUNA在低数据场景下表现出更快的收敛速度和更强的泛化能力，为组装轻量级食物图像提供了高效解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [126] [Degradation-Agnostic Statistical Facial Feature Transformation for Blind Face Restoration in Adverse Weather Conditions](https://arxiv.org/abs/2507.07464)
> *恶劣天气条件下盲人脸修复的降级无关统计人脸特征变换*

*Chang-Hwan Son* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 人脸修复, 恶劣天气, GAN, 统计特征变换, 降级无关

**Comment:** 

> **TL;DR:** 本文提出了一种新的基于GAN的盲人脸图像修复框架，通过统计人脸特征变换（SFFT）和降级无关特征嵌入（DAFE）模块，有效解决了恶劣天气下人脸识别图像质量下降的问题，性能优于现有SOTA方法。

**AI_Comments:** 本文提出了一种创新的GAN框架，通过引入局部统计人脸特征变换（SFFT）和降级无关特征嵌入（DAFE）模块，有效解决了恶劣天气下人脸图像修复的难题。其创新点在于显式地处理了天气引起的图像退化，并通过统计分布对齐和特征嵌入实现了对严重退化的自适应修复。这对于户外智能监控和人脸识别系统的发展具有重要意义，因为它直接提升了在复杂环境中的识别准确性。该方法在结构保真度和感知质量上的提升，表明了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 随着智能CCTV系统在户外环境中的部署增加，对在恶劣天气条件下优化的人脸识别系统的需求也随之增长。恶劣天气会显著降低图像质量，从而降低识别准确性。尽管现有的人脸图像修复（FIR）模型（基于GAN和扩散模型）已取得进展，但由于缺乏专门处理天气引起的图像退化的模块，其性能仍然有限，导致面部纹理和结构失真。

**Method:** 本文提出了一种新颖的基于GAN的盲人脸图像修复（FIR）框架，该框架集成了两个关键组件：局部统计人脸特征变换（SFFT）和降级无关特征嵌入（DAFE）。局部SFFT模块通过将低质量（LQ）面部区域的局部统计分布与高质量（HQ）对应区域的分布对齐，从而增强面部结构和颜色保真度。DAFE模块通过对齐LQ和HQ编码器表示，使修复过程适应严重的天气引起的退化，从而在恶劣天气条件下实现鲁棒的统计面部特征提取。

**Result:** 实验结果表明，所提出的降级无关SFFT模型优于现有的基于GAN和扩散模型的最新FIR方法，特别是在抑制纹理失真和准确重建面部结构方面。此外，SFFT和DAFE模块都被经验证在恶劣天气场景下的人脸修复中增强了结构保真度和感知质量。

**Conclusion:** 本文提出的降级无关统计人脸特征变换（SFFT）模型，通过结合SFFT和DAFE模块，有效解决了恶劣天气条件下人脸图像修复的挑战，显著提升了修复图像的结构保真度和感知质量，并超越了现有的先进方法。

> **ai_Abstract:** 本研究提出了一种针对恶劣天气条件下盲人脸修复的新型GAN框架，名为降级无关统计人脸特征变换（SFFT）。该框架包含两个核心模块：局部SFFT和降级无关特征嵌入（DAFE）。局部SFFT通过对齐低质量和高质量面部区域的局部统计分布来提升面部结构和颜色保真度。DAFE则通过对齐编码器表示，实现恶劣天气下鲁棒的特征提取，使修复过程能适应严重退化。实验证明，该模型在抑制纹理失真和准确重建面部结构方面，性能优于现有的GAN和扩散模型，显著提升了恶劣天气下的人脸修复质量。

> **摘要翻译:** 随着智能CCTV系统在户外环境中的日益部署，对在挑战性天气条件下优化的人脸识别系统的需求不断增长。恶劣天气会显著降低图像质量，进而降低识别准确性。尽管最近基于生成对抗网络（GANs）和扩散模型的人脸图像修复（FIR）模型已取得进展，但由于缺乏明确解决天气引起的退化的专用模块，其性能仍然有限。这导致面部纹理和结构失真。为了解决这些限制，我们提出了一种新颖的基于GAN的盲FIR框架，该框架集成了两个关键组件：局部统计人脸特征变换（SFFT）和降级无关特征嵌入（DAFE）。局部SFFT模块通过将低质量（LQ）面部区域的局部统计分布与高质量（HQ）对应区域的分布对齐，从而增强面部结构和颜色保真度。作为补充，DAFE模块通过对齐LQ和HQ编码器表示，使修复过程适应严重的天气引起的退化，从而在恶劣天气条件下实现鲁棒的统计面部特征提取。实验结果表明，所提出的降级无关SFFT模型优于现有的基于GAN和扩散模型的最新FIR方法，特别是在抑制纹理失真和准确重建面部结构方面。此外，SFFT和DAFE模块都被经验证在挑战性天气场景下的人脸修复中增强了结构保真度和感知质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [128] [GRR-CoCa: Leveraging LLM Mechanisms in Multimodal Model Architectures](https://arxiv.org/abs/2507.18009)
> *GRR-CoCa：在多模态模型架构中利用大型语言模型机制*

*Jake R. Patock, Nicole Catherine Lewis, Kevin McCoy, Christina Gomez, Canling Chen, Lorenzo Luzi* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 多模态模型, LLM机制, CoCa, 视觉-语言, 架构改进

**Comment:** 12 pages, 2 figures

> **TL;DR:** GRR-CoCa通过在CoCa模型中引入大型语言模型（LLM）的先进架构机制，显著提升了多模态任务的性能和泛化能力。

**AI_Comments:** 本文的创新点在于系统地将LLM中成熟的架构改进（如高斯误差门控线性单元、均方根归一化和旋转位置嵌入）引入到多模态模型CoCa中，这展示了一种有价值的跨模型类型知识迁移策略。论文提供了清晰的量化结果，有力地证明了这些架构选择对视觉-语言任务性能和泛化能力的实际积极影响，为未来的多模态模型设计提供了重要参考。

<details>
  <summary>Details</summary>

**Motivation:** 尽管当前最先进的多模态模型表现出色，但其架构复杂性落后于现代大型语言模型（LLMs），这限制了其进一步的性能提升。

**Method:** 本文提出了GRR-CoCa模型，通过将高斯误差门控线性单元、均方根归一化和旋转位置嵌入集成到CoCa模型的文本解码器和视觉Transformer（ViT）编码器中，对CoCa模型进行了改进。作者将GRR-CoCa与基线CoCa（具有修改后的文本解码器但保留原始ViT编码器）进行了对比，并在对比和生成任务上使用标准预训练和微调工作流程进行基准测试。

**Result:** GRR-CoCa在预训练数据集和三个不同的微调数据集上显著优于基线CoCa。预训练阶段，对比损失降低了27.25%，困惑度降低了3.71%，CoCa损失降低了7.15%。微调阶段，平均对比损失降低了13.66%，困惑度降低了5.18%，CoCa损失降低了5.55%。

**Conclusion:** GRR-CoCa的修改架构在视觉-语言领域提高了性能和泛化能力。

> **ai_Abstract:** 本文提出了GRR-CoCa，一个通过整合大型语言模型（LLM）中已被证明有效的架构机制（如高斯误差门控线性单元、均方根归一化和旋转位置嵌入）来改进现有CoCa模型的多模态架构。这些改进被应用于CoCa的文本解码器和视觉Transformer编码器。通过与基线CoCa进行严格的预训练和微调基准测试，GRR-CoCa在对比和生成任务上均表现出显著的性能提升，包括预训练阶段对比损失降低27.25%，微调阶段CoCa损失平均降低5.55%。研究结果证明，GRR-CoCa的修改架构有效提升了模型在视觉-语言任务中的性能和泛化能力。

> **摘要翻译:** 最先进（SOTA）的图像和文本生成模型是多模态模型，与大型语言模型（LLMs）有许多相似之处。尽管取得了强大的性能，但领先的基础多模态模型架构在复杂性上常常落后于当代LLMs。我们提出了GRR-CoCa，一个改进的SOTA对比字幕器（CoCa）模型，它将高斯误差门控线性单元、均方根归一化和旋转位置嵌入整合到文本解码器和视觉Transformer（ViT）编码器中。这些架构修改已被证明能提升LLMs的模型性能，但尚未在CoCa中采用。我们将GRR-CoCa与基线CoCa（一个具有相同修改文本解码器但使用CoCa原始ViT编码器的模型）进行了基准测试。我们使用标准的预训练和微调工作流程，在对比和生成任务上对模型进行了基准测试。我们的GRR-CoCa在预训练数据集和三个不同的微调数据集上显著优于基线CoCa。预训练的改进包括对比损失降低27.25%，困惑度降低3.71%，CoCa损失降低7.15%。平均微调改进包括对比损失降低13.66%，困惑度降低5.18%，CoCa损失降低5.55%。我们表明GRR-CoCa的修改架构改善了视觉-语言领域的性能和泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [132] [Scalable Frame Sampling for Video Classification: A Semi-Optimal Policy Approach with Reduced Search Space](https://arxiv.org/abs/2409.05260)
> *视频分类的可扩展帧采样：一种具有减小搜索空间的半最优策略方法*

*Junho Lee, Jeongwoo Shin, Seung Woo Ko, Seongsu Ha, Joonseok Lee* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 视频分类, 帧采样, 半最优策略, 搜索空间约简, 计算复杂度

**Comment:** 

> **TL;DR:** 该论文提出了一种新的半最优策略，通过独立估计每帧的价值来显著减少视频帧采样的搜索空间，从而在视频分类中实现高效且高性能。

**AI_Comments:** 该论文的创新点在于提出了一个新颖的视角，通过引入“半最优策略”和利用“每帧置信度”来大幅削减视频帧采样的搜索空间，从而将计算复杂度从指数级降至线性级。这对于大规模视频数据处理具有重要意义，因为它解决了现有方法在N值较大时面临的计算瓶颈，使得帧采样在实际应用中更具可扩展性和效率。其方法在保持性能的同时显著降低了计算成本，是一个实用的进步。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视频帧采样方法在选择N帧以最大化视频分类器性能时，面临着巨大的搜索空间（O(T^N)），尤其当N较大时，这导致计算复杂度很高。

**Method:** 本文提出了一种半最优策略，通过利用每帧置信度独立估计每帧的价值，将搜索空间从O(T^N)显著减少到O(T)。该策略选择置信度最高的N帧。

**Result:** 实验验证了所提出的半最优策略能够有效近似最优策略，尤其是在实际设置下。此外，在各种数据集和模型架构上的广泛实验表明，学习这种半最优策略可以确保无论N和T的大小如何，都能获得稳定且高性能的表现。

**Conclusion:** 通过引入半最优策略并利用每帧置信度，本文成功地解决了视频帧采样中巨大的搜索空间问题，实现了高效且高性能的视频分类。

> **ai_Abstract:** 本文提出了一种针对视频分类中帧采样的半最优策略，旨在解决现有方法面临的巨大搜索空间问题。通过利用每帧的独立置信度来估计其价值，该方法将搜索空间从指数级复杂度（O(T^N)）降低到线性复杂度（O(T)）。实验证明，该半最优策略能有效逼近最优策略，并在不同数据集和模型上展现出稳定的高性能，不受帧数N和总帧数T大小的影响。

> **摘要翻译:** 给定一个包含T帧的视频，帧采样任务是选择N帧（N远小于T），以最大化固定视频分类器的性能。不仅是暴力搜索，大多数现有方法都受困于其庞大的搜索空间（组合数C(T,N)），尤其当N变大时。为了解决这一挑战，我们引入了一种新的视角，将搜索空间从O(T^N)减小到O(T)。我们提出的半最优策略不是探索整个O(T^N)空间，而是基于独立估计的每帧置信度来选择最佳N帧，从而显著降低了计算复杂度。我们验证了我们的半最优策略可以有效地近似最优策略，特别是在实际设置下。此外，通过在各种数据集和模型架构上进行广泛实验，我们证明了学习我们的半最优策略可以确保无论N和T的大小如何，都能获得稳定且高性能的表现。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [143] [MatSSL: Robust Self-Supervised Representation Learning for Metallographic Image Segmentation](https://arxiv.org/abs/2507.18184)
> *MatSSL：用于金相图像分割的鲁棒自监督表示学习*

*Hoang Hai Nam Nguyen, Phan Nguyen Duc Hieu, Ho Won Lee* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 自监督学习, 金相图像分割, 门控特征融合, 小样本学习, 表示学习

**Comment:** 

> **TL;DR:** MatSSL是一种新的自监督学习架构，通过在小型未标记数据集上预训练，显著提高了金相图像分割的性能，优于现有方法。

**AI_Comments:** MatSSL的创新之处在于其采用门控特征融合的简化SSL架构，以及在小型未标记数据集上进行有效预训练的能力。这对于金相图像分析领域尤其重要，因为该领域通常难以获取大量标记数据。其在性能上的显著提升表明了其在实际应用中的巨大潜力，克服了传统监督学习和现有SSL方法的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 当前金属材料显微图像分析依赖于监督方法，需要为每个新数据集重新训练，并且在标记样本较少时表现不稳定。虽然自监督学习（SSL）利用未标记数据提供了有前景的替代方案，但大多数现有方法仍依赖于大规模数据集才能有效。MatSSL旨在克服这一局限性。

**Method:** MatSSL是一种简化的自监督学习（SSL）架构，其主干网络的每个阶段都采用门控特征融合（Gated Feature Fusion）来有效整合多级表示。该方法首先在小型、未标记数据集上进行自监督预训练，然后将模型在多个基准数据集上进行微调。

**Result:** MatSSL分割模型在MetalDAM数据集上实现了69.13%的mIoU，优于ImageNet预训练编码器实现的66.73%。与使用MicroNet预训练的模型相比，在环境阻隔涂层（EBC）基准数据集上，平均mIoU持续提高了近40%。

**Conclusion:** MatSSL通过仅使用少量未标记数据，就能有效地适应金相领域，同时保留了从自然图像大规模预训练中学习到的丰富且可转移的特征。

> **ai_Abstract:** MatSSL提出了一种新的自监督学习（SSL）架构，通过在主干网络中集成门控特征融合来有效利用多级表示。该方法旨在解决现有监督方法需要大量标记数据以及SSL方法依赖大规模数据集的局限性。MatSSL首先在小型未标记数据集上进行预训练，然后在基准数据集上进行微调，显著提升了金相图像分割的性能，例如在MetalDAM上达到69.13% mIoU，并在EBC数据集上实现了近40%的mIoU提升，证明了其在小数据量下适应金相领域的能力。

> **摘要翻译:** MatSSL是一种简化的自监督学习（SSL）架构，其主干网络的每个阶段都采用门控特征融合来有效整合多级表示。当前金属材料的显微图像分析依赖于监督方法，这需要为每个新数据集重新训练，并且在只有少量标记样本时通常表现不一致。虽然SSL通过利用未标记数据提供了一种有前景的替代方案，但大多数现有方法仍然依赖于大规模数据集才能有效。MatSSL旨在克服这一局限性。我们首先在小型、未标记数据集上进行自监督预训练，然后将模型在多个基准数据集上进行微调。由此产生的分割模型在MetalDAM上实现了69.13%的mIoU，优于ImageNet预训练编码器实现的66.73%，并且与使用MicroNet预训练的模型相比，在环境阻隔涂层基准数据集（EBC）上，平均mIoU持续提高了近40%。这表明MatSSL仅使用少量未标记数据即可有效适应金相领域，同时保留了从自然图像大规模预训练中学习到的丰富且可转移的特征。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [145] [A 3D Cross-modal Keypoint Descriptor for MR-US Matching and Registration](https://arxiv.org/abs/2507.18551)
> *一种用于MR-US匹配和配准的3D跨模态关键点描述符*

*Daniil Morozov, Reuben Dorent, Nazim Haouchine* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 跨模态配准, 关键点描述符, MRI-US, 图像配准, 深度学习

**Comment:** Under review

> **TL;DR:** 该研究提出了一种新颖的3D跨模态关键点描述符，通过合成iUS数据和对比学习，实现了鲁棒的MRI-iUS图像配准，无需手动初始化。

**AI_Comments:** 该论文的创新点在于提出了一个3D跨模态关键点描述符，并通过“合成匹配”和对比学习来克服MRI和iUS之间显著的模态差异。特别是，利用合成数据进行监督学习，以及结合概率关键点检测和动态难负样本挖掘的训练策略，是其核心贡献。该方法实现了无需手动初始化的全自动配准，并对常见的iUS伪影和视野变化具有鲁棒性，这对于临床应用具有重要意义。其可解释性也增加了方法的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 由于实时超声（iUS）与术前磁共振成像（MRI）在外观、分辨率和视野方面的严重模态特异性差异，术中iUS到MRI的配准仍然是一个未解决的问题。

**Method:** 该方法提出了一种3D跨模态关键点描述符。它采用患者特异性的“合成匹配”方法，从术前MRI生成合成iUS图像，从而实现监督对比训练以学习共享描述符空间。然后，采用概率关键点检测策略来识别解剖学上显著且模态一致的位置。训练过程中使用基于课程的triplet损失和动态难负样本挖掘，使描述符对iUS伪影（如散斑噪声和有限覆盖）具有鲁棒性，并具有旋转不变性。在推理阶段，该方法在MR和真实iUS图像中检测关键点并识别稀疏匹配，进而用于执行刚性配准。

**Result:** 该方法在ReMIND数据集上进行了评估，在11名患者中，其关键点匹配性能优于最先进的方法，平均精度达到69.8%。在图像配准方面，该方法在ReMIND2Reg基准测试中实现了2.39毫米的平均目标配准误差（TRE）。

**Conclusion:** 该研究提出了一种可解释、无需手动初始化且对iUS视野变化具有鲁棒性的新型MRI-iUS配准框架。它通过学习3D跨模态关键点描述符，有效解决了术中超声与术前MRI配准的挑战，并在实验中表现出优越或有竞争力的性能。

> **ai_Abstract:** 本研究提出了一种新颖的3D跨模态关键点描述符，用于解决术中实时超声（iUS）与术前磁共振成像（MRI）的配准难题。该方法通过从MRI合成iUS数据进行监督对比学习，构建了一个共享的描述符空间，并结合概率关键点检测策略。训练中采用特殊的损失函数以增强描述符的鲁棒性和旋转不变性。实验结果表明，该方法在关键点匹配和图像配准方面均优于或达到现有先进水平，且具有无需手动初始化、可解释和对视野变化鲁棒的优点。

> **摘要翻译:** 术中实时超声（iUS）与术前磁共振成像（MRI）的配准由于外观、分辨率和视野方面的严重模态特异性差异，仍然是一个未解决的问题。为了解决这个问题，我们提出了一种新颖的3D跨模态关键点描述符，用于MRI-iUS的匹配和配准。我们的方法采用患者特异性的“合成匹配”方法，从术前MRI生成合成iUS体数据。这使得能够进行监督对比训练，以学习共享的描述符空间。然后，采用概率关键点检测策略来识别解剖学上显著且模态一致的位置。在训练过程中，使用基于课程的triplet损失和动态难负样本挖掘来学习以下描述符：i）对iUS伪影（如散斑噪声和有限覆盖）具有鲁棒性，以及ii）具有旋转不变性。在推理时，该方法在MR和真实的iUS图像中检测关键点并识别稀疏匹配，然后用于执行刚性配准。我们的方法使用来自ReMIND数据集的3D MRI-iUS对进行评估。实验表明，我们的方法在11名患者中优于最先进的关键点匹配方法，平均精度为69.8%。对于图像配准，我们的方法在ReMIND2Reg基准测试中实现了2.39毫米的有竞争力的平均目标配准误差。与现有的iUS-MR配准方法相比，我们的框架具有可解释性，无需手动初始化，并且对iUS视野变化表现出鲁棒性。代码可在https://github.com/morozovdd/CrossKEY获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [147] [ViLU: Learning Vision-Language Uncertainties for Failure Prediction](https://arxiv.org/abs/2507.07620)
> *ViLU：学习视觉-语言不确定性以进行故障预测*

*Marc Lafon, Yannis Karmim, Julio Silva-Rodríguez, Paul Couairon, Clément Rambour, Raphaël Fournier-Sniehotta, Ismail Ben Ayed, Jose Dolz, Nicolas Thome* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 视觉-语言模型, 不确定性量化, 故障预测, 多模态表示, 后验设置

**Comment:** 

> **TL;DR:** ViLU是一个新的视觉-语言不确定性量化框架，通过整合多种文本表示和训练一个二元分类器来预测VLM的故障，并在多个数据集上表现出色。

**AI_Comments:** 创新点在于提出了一个损失无关的二元分类器作为不确定性预测器，并能有效处理后验设置。其通过整合多种文本表示来情境化不确定性估计的方法也值得关注。该研究对于提高视觉-语言模型在实际应用中的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言模型（VLMs）的可靠不确定性量化和故障预测仍然是开放的挑战。

**Method:** ViLU通过利用所有与任务相关的文本表示来情境化不确定性估计。它通过整合视觉嵌入、预测文本嵌入和图像条件文本表示（通过交叉注意力）来构建不确定性感知多模态表示。ViLU将不确定性预测器训练为一个二元分类器，使用加权二元交叉熵损失来区分正确和不正确的预测，使其与损失无关。该方法特别适用于仅有视觉和文本嵌入而无法直接访问模型的后验设置。

**Result:** 在各种数据集上的大量实验表明，该方法比最先进的故障预测方法取得了显著的进步。该方法应用于ImageNet-1k等标准分类数据集以及CC12M和LAION-400M等大规模图像-字幕数据集。消融研究强调了其架构和训练在实现有效不确定性量化方面的关键作用。

**Conclusion:** ViLU框架通过其新颖的不确定性量化方法，显著提高了视觉-语言模型的故障预测能力，尤其适用于后验设置。

> **ai_Abstract:** 本文提出了ViLU，一个针对视觉-语言模型（VLMs）的新型不确定性量化框架，旨在提高故障预测的可靠性。ViLU通过整合多种文本和视觉嵌入，构建了不确定性感知的多模态表示，并训练了一个损失无关的二元分类器来预测错误。该方法特别适用于仅有嵌入的后验场景，并在多个大型数据集上展示了优于现有技术的性能。

> **摘要翻译:** 可靠的不确定性量化（UQ）和故障预测仍然是视觉-语言模型（VLMs）面临的开放挑战。我们引入了ViLU，一个新颖的视觉-语言不确定性量化框架，它通过利用所有与任务相关的文本表示来情境化不确定性估计。ViLU通过交叉注意力整合视觉嵌入、预测文本嵌入和图像条件文本表示，构建了一个不确定性感知多模态表示。与基于损失预测的传统UQ方法不同，ViLU将不确定性预测器训练为一个二元分类器，使用加权二元交叉熵损失来区分正确和不正确的预测，使其与损失无关。特别是，我们提出的方法非常适用于后验设置，即只有视觉和文本嵌入可用而无法直接访问模型本身。在各种数据集上的大量实验表明，与最先进的故障预测方法相比，我们的方法取得了显著的进步。我们将我们的方法应用于ImageNet-1k等标准分类数据集，以及CC12M和LAION-400M等大规模图像-字幕数据集。消融研究强调了我们的架构和训练在实现有效不确定性量化方面的关键作用。我们的代码是公开的，可以在这里找到：https://github.com/ykrmm/ViLU。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [158] [HumanMaterial: Human Material Estimation from a Single Image via Progressive Training](https://arxiv.org/abs/2507.18385)
> *HumanMaterial: 基于渐进式训练的单张图像人体材质估计*

*Yu Jiang, Jiahao Xia, Jiongming Qin, Yusen Wang, Tuo Cao, Chunxia Xiao* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 人体材质估计, 逆向渲染, 渐进式训练, PBR, OpenHumanBRDF

**Comment:** 14

> **TL;DR:** 本文提出了HumanMaterial模型和OpenHumanBRDF数据集，通过渐进式训练和新型损失函数，解决了单张图像人体逆向渲染中材质估计的挑战，实现了高真实感渲染和最先进的性能。

**AI_Comments:** 本文的创新点在于构建了更全面的OpenHumanBRDF数据集，包含了以往工作中常被简化的位移和次表面散射等关键材质信息，这对于提升皮肤等复杂材质的真实感至关重要。其次，提出的HumanMaterial模型采用渐进式训练策略，有效解决了多材质估计任务中端到端模型难以平衡各材质重要性的问题，并通过引入Controlled PBR Rendering (CPR) loss进一步优化了训练过程。这些方法共同提升了单张图像人体材质估计的准确性和渲染结果的真实感，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 基于物理渲染的全身体逆向渲染在获取高质量材质以实现任意光照下的真实感渲染方面面临挑战。由于缺乏材质图约束，逆向渲染是一个不适定问题。现有工作使用简化的材质数据和渲染方程，导致渲染结果（尤其是皮肤）的真实感有限。此外，随着更多材质预测任务的增加，端到端模型难以平衡各种材质图的重要性，导致模型欠拟合。

**Method:** 本文构建了一个高质量数据集（OpenHumanBRDF），包含法线、漫反射反照率、粗糙度、镜面反照率、位移和次表面散射，以增强渲染真实感，特别是皮肤。针对多材质预测任务的挑战，设计了一个名为HumanMaterial的模型，采用渐进式训练策略，充分利用材质图的监督信息。HumanMaterial首先通过三个先验模型获得初始材质结果，然后通过一个微调模型进行优化。此外，设计了一种受控PBR渲染（CPR）损失，以在先验模型训练期间增强待优化材质的重要性。

**Result:** 在OpenHumanBRDF数据集和真实数据上的大量实验表明，所提出的方法实现了最先进的性能。

**Conclusion:** 本文通过构建高质量的OpenHumanBRDF数据集和设计具有渐进式训练策略的HumanMaterial模型，以及引入受控PBR渲染（CPR）损失，有效地解决了单张图像人体逆向渲染中材质估计的挑战，显著提升了渲染结果的真实感，并达到了当前最佳的性能。

> **ai_Abstract:** 本文针对单张图像人体逆向渲染中材质估计的真实感和多材质平衡问题，提出了两项关键贡献。首先，构建了高质量的OpenHumanBRDF数据集，包含更多细节材质如位移和次表面散射，以提升皮肤渲染真实感。其次，设计了HumanMaterial模型，采用渐进式训练策略，通过先验模型获取初始材质并由微调模型精炼，并引入受控PBR渲染（CPR）损失来平衡不同材质的重要性。实验证明，该方法在材质估计方面实现了最先进的性能，显著提高了渲染的真实感。

> **摘要翻译:** 基于物理渲染的全身体逆向渲染旨在获取高质量材质，有助于在任意光照下实现照片级真实感渲染。这项任务需要估计多个材质图，并且通常依赖于渲染结果的约束。材质图上约束的缺失使得逆向渲染成为一个不适定任务。以往的工作通过构建用于训练的材质数据集来缓解这个问题，但其简化的材质数据和渲染方程导致渲染结果的真实感有限，尤其是皮肤。为了进一步缓解这个问题，我们基于扫描的真实数据和统计材质数据构建了一个更高质量的数据集（OpenHumanBRDF）。除了法线、漫反射反照率、粗糙度、镜面反照率外，我们还生成了位移和次表面散射，以增强渲染结果的真实感，特别是对于皮肤。随着更多材质预测任务的增加，像以往工作那样使用端到端模型难以平衡各种材质图的重要性，并导致模型欠拟合。因此，我们设计了一个具有渐进式训练策略的模型（HumanMaterial），以充分利用材质图的监督信息并提高材质估计的性能。HumanMaterial首先通过三个先验模型获得初始材质结果，然后通过一个微调模型细化结果。先验模型估计不同的材质图，并且每个材质图对渲染结果的重要性不同。因此，我们设计了一种受控PBR渲染（CPR）损失，它在先验模型训练期间增强了待优化材质的重要性。在OpenHumanBRDF数据集和真实数据上的大量实验表明，我们的方法达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [168] [DAA*: Deep Angular A Star for Image-based Path Planning](https://arxiv.org/abs/2507.09305)
> *DAA*：用于基于图像的路径规划的深度角度A星算法*

*Zhiwei Xu* | **Category: cs.CV, cs.LG, eess.IV** | **Updated: 2025-07-24**

**Keywords:** 深度角度A星, 路径规划, 基于图像, 路径平滑度, 模仿学习

**Comment:** International Conference on Computer Vision (ICCV), 2025

> **TL;DR:** 本文提出了一种名为深度角度A星（DAA*）的新型学习方法，通过将路径角度自由度（PAF）融入A*算法，改善了基于图像的路径规划中的路径平滑度和相似性。

**AI_Comments:** 该论文的创新之处在于引入了路径角度自由度（PAF）并将其与A*算法结合，以自适应地提高路径平滑度，这在路径模仿学习中是一个重要但常被忽视的方面。通过联合优化路径缩短和路径平滑，DAA*提供了一种有效的方法来生成更接近参考路径且更平滑的路径。在多样化数据集上的全面评估增强了其研究贡献和方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 在从专家演示中学习路径模仿时，路径平滑度常常被忽视。本文旨在通过自适应路径平滑度来提高路径相似性。

**Method:** 引入了深度角度A星（DAA*）算法，将提出的路径角度自由度（PAF）融入A*算法中。PAF旨在通过找到其最小值和最大值之间的权衡，探索移动角度对路径节点扩展的影响，从而实现模仿学习的高适应性。DAA*通过联合优化路径缩短（对应启发式距离）和路径平滑（对应PAF）来提高路径最优性。

**Result:** DAA*在7个数据集（包括4个迷宫数据集、2个视频游戏数据集和一个包含2个场景的真实世界无人机视角数据集）上进行了全面评估，结果显示DAA*在预测路径与参考路径之间的路径相似性方面比神经A*有显著改进，并且在最短路径合理时路径长度更短，SPR提高了9.0%，ASIM提高了6.9%，PSIM提高了3.9%。此外，当与路径损失和路径概率图损失共同学习寻路时，DAA*显著优于最先进的TransPath，SPR提高了6.3%，PSIM提高了6.0%，ASIM提高了3.7%。

**Conclusion:** DAA*算法通过引入路径角度自由度（PAF），有效地解决了路径模仿学习中路径平滑度被忽视的问题，显著提高了基于图像的路径规划中的路径相似性和最优性。

> **ai_Abstract:** DAA*是一种新颖的学习方法，它通过将路径角度自由度（PAF）引入A*算法，解决了路径模仿学习中路径平滑度被忽视的问题。该方法通过联合优化路径缩短和路径平滑来提高路径最优性，实现了更高的路径相似性。在多项数据集上的评估表明，DAA*在路径相似性和路径长度方面显著优于现有方法，如神经A*和TransPath。

> **摘要翻译:** 路径平滑度在从专家演示中进行路径模仿学习时经常被忽视。在本文中，我们引入了一种新颖的学习方法，称为深度角度A星（DAA*），通过将提出的路径角度自由度（PAF）融入A*算法来提高路径相似性，实现自适应路径平滑。PAF旨在通过找到其最小值和最大值之间的权衡，探索移动角度对路径节点扩展的影响，从而实现模仿学习的高适应性。DAA*通过联合优化路径缩短和平滑来提高路径最优性，分别对应启发式距离和PAF，使其与参考路径紧密对齐。通过对包括4个迷宫数据集、2个视频游戏数据集和包含2个场景的真实世界无人机视角数据集在内的7个数据集进行全面评估，我们证明了DAA*在预测路径与参考路径之间的路径相似性方面比神经A*有显著改进，并且在最短路径合理时路径长度更短，SPR提高了9.0%，ASIM提高了6.9%，PSIM提高了3.9%。此外，当与路径损失和路径概率图损失共同学习寻路时，DAA*显著优于最先进的TransPath，SPR提高了6.3%，PSIM提高了6.0%，ASIM提高了3.7%。我们还讨论了路径最优性与搜索效率之间在适用情况下的微小权衡。我们的代码和模型权重可在https://github.com/zwxu064/DAAStar.git获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [172] [RadioDUN: A Physics-Inspired Deep Unfolding Network for Radio Map Estimation](https://arxiv.org/abs/2506.08418)
> *RadioDUN: 一种物理启发式深度展开网络用于无线电地图估计*

*Taiqin Chen, Zikun Zhou, Zheng Fang, Wenzhen Zou, Kangjun Liu, Ke Chen, Yongbing Zhang, Yaowei Wang* | **Category: cs.CV, eess.SP** | **Updated: 2025-07-24**

**Keywords:** 无线电地图估计, 深度展开网络, 稀疏信号恢复, 物理传播模型, 动态重加权

**Comment:** 

> **TL;DR:** 本文提出了RadioDUN，一种物理启发式深度展开网络，通过将无线电地图估计视为稀疏信号恢复问题并融入物理传播模型，解决了从稀疏样本构建密集无线电地图的挑战。

**AI_Comments:** 该论文的创新之处在于将深度展开网络与物理传播模型相结合，解决了传统深度学习方法难以融入物理特性的问题。通过将问题分解并引入阴影损失，RadioDUN能够更准确地建模无线电信号的复杂传播过程，在无线电地图估计领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 无线电地图对于高效资源分配和干扰缓解至关重要，但由于实际场景中测量样本有限，难以构建密集的无线电地图。现有的深度学习方法难以与无线电地图的物理特性结合。

**Method:** 将无线电地图估计视为稀疏信号恢复问题，并融入物理传播模型将其分解为多个因子优化子问题。提出RadioDUN来展开优化过程，实现自适应参数调整和先验拟合。开发动态重加权模块（DRM）以自适应地建模每个因子对无线电地图的重要性。整合与障碍物相关的因子以表达障碍物引起的信号随机衰减，并设计阴影损失作为补充监督目标。

**Result:** 实验证明，所提出的方法优于最先进的方法。

**Conclusion:** RadioDUN通过结合物理传播模型和深度展开网络，能够有效且准确地从稀疏样本中估计出密集的无线电地图，并展现出优越的性能。

> **ai_Abstract:** 本文提出RadioDUN，一种物理启发式深度展开网络，用于从稀疏样本中估计密集的无线电地图。通过将无线电地图估计问题转化为稀疏信号恢复，并结合物理传播模型将其分解为子问题，RadioDUN能够自适应地调整参数并拟合先验。它引入了动态重加权模块和阴影损失来整合无线电传播特性和障碍物效应，并在实验中表现出优于现有方法的性能。

> **摘要翻译:** 无线电地图表示区域内频谱资源的空间分布，支持高效的资源分配和干扰缓解。然而，在实际场景中可测量的样本数量有限，因此难以构建密集的无线电地图。尽管现有工作已使用深度学习从稀疏样本中估计密集的无线电地图，但它们难以与无线电地图的物理特性相结合。为解决这一挑战，我们将无线电地图估计视为稀疏信号恢复问题。进一步结合物理传播模型，将问题分解为多个因子优化子问题，从而降低了恢复复杂度。受现有压缩感知方法的启发，我们提出了无线电深度展开网络（RadioDUN），以可学习的方式展开优化过程，实现自适应参数调整和先验拟合。为了考虑无线电传播特性，我们开发了动态重加权模块（DRM）以自适应地建模每个因子对无线电地图的重要性。受物理传播模型中阴影因子的启发，我们整合了与障碍物相关的因子来表达障碍物引起的信号随机衰减。阴影损失进一步被设计用于约束因子预测并作为补充监督目标，从而增强了RadioDUN的性能。大量实验表明，所提出的方法优于最先进的方法。我们的代码将在发布后公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [179] [Multispectral Demosaicing via Dual Cameras](https://arxiv.org/abs/2503.22026)
> *通过双摄像头进行多光谱去马赛克*

*SaiKiran Tedla, Junyong Lee, Beixuan Yang, Mahmoud Afifi, Michael S. Brown* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-25**

**Keywords:** 多光谱图像, 去马赛克, 双摄像头, RGB图像, 数据集

**Comment:** https://ms-demosaic.github.io/

> **TL;DR:** 本文提出了一种利用双摄像头（RGB和多光谱）系统中的高空间保真度RGB图像来引导低保真度多光谱图像去马赛克的方法，并创建了一个新数据集，实现了最先进的精度。

**AI_Comments:** 这篇论文的创新点在于提出了利用双摄像头设置中RGB图像引导多光谱图像去马赛克的新思路，解决了多光谱图像重建的挑战。同时，构建并发布了一个大型的配对RGB-MS数据集，为该领域的研究提供了宝贵的资源，这对于推动多光谱成像技术在消费级设备中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多光谱图像在需要丰富光谱数据的应用中具有重要价值。将多光谱成像集成到多摄像头设备（如智能手机）中，可以增强光谱应用并改善RGB图像质量。多光谱数据处理中的关键一步是去马赛克。

**Method:** 论文提出了一种专为双摄像头设置（RGB和多光谱摄像头捕获相同场景）设计的多光谱图像去马赛克方法。该方法利用共同捕获的RGB图像（通常具有更高的空间保真度）来引导低保真度多光谱图像的去马赛克。此外，还引入了“双摄像头RGB-MS数据集”，这是一个包含配对的RGB和多光谱马赛克图像以及真实去马赛克输出的大型数据集，用于方法的训练和评估。

**Result:** 实验结果表明，该方法与现有技术相比，实现了最先进的精度。

**Conclusion:** 通过利用双摄像头设置中的RGB图像引导多光谱图像的去马赛克，该方法能够有效地提高多光谱图像的重建质量，并取得了优于现有技术的性能。新创建的数据集也为未来的研究提供了资源。

> **ai_Abstract:** 本文提出了一种针对双摄像头系统的多光谱图像去马赛克新方法。该方法利用高空间保真度的RGB图像来引导低保真度多光谱图像的去马赛克过程。为支持方法的训练和评估，作者还构建了一个大型的“双摄像头RGB-MS数据集”。实验证明，该方法在多光谱去马赛克方面达到了最先进的精度。

> **摘要翻译:** 多光谱（MS）图像捕获了广泛光谱波段的详细场景信息，这使其对于需要丰富光谱数据的应用具有宝贵的价值。将多光谱成像集成到多摄像头设备（如智能手机）中，有望增强光谱应用和RGB图像质量。处理多光谱数据的关键一步是去马赛克，它从摄像头捕获的马赛克多光谱图像中重建颜色信息。本文提出了一种专门为双摄像头设置设计的多光谱图像去马赛克方法，其中RGB和多光谱摄像头捕获同一场景。我们的方法利用共同捕获的RGB图像（通常具有更高的空间保真度）来引导低保真度多光谱图像的去马赛克。我们引入了“双摄像头RGB-MS数据集”——一个包含配对的RGB和多光谱马赛克图像以及真实去马赛克输出的大型集合——这使得我们的方法能够进行训练和评估。实验结果表明，与现有技术相比，我们的方法实现了最先进的精度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [181] [PF3plat: Pose-Free Feed-Forward 3D Gaussian Splatting](https://arxiv.org/abs/2410.22128)
> *PF3plat: 无姿态前馈3D高斯泼溅*

*Sunghwan Hong, Jaewoo Jung, Heeseong Shin, Jisang Han, Jiaolong Yang, Chong Luo, Seungryong Kim* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D Gaussian Splatting, Novel View Synthesis, Pose-Free, Depth Estimation, Visual Correspondence

**Comment:** Accepted by ICML'25

> **TL;DR:** PF3plat提出了一种无需相机姿态的前馈3D高斯泼溅方法，通过粗略对齐和精炼深度姿态估计，实现了无姿态图像的新颖视图合成，并在大型真实世界数据集上达到了SOTA。

**AI_Comments:** 该论文的创新点在于将3DGS扩展到无需精确相机姿态的场景，极大地拓宽了3DGS的应用范围。通过结合预训练模型进行粗略对齐和引入可学习模块进行精炼，有效解决了无姿态输入带来的训练不稳定问题。几何置信度分数的引入进一步提升了模型的鲁棒性和重建质量，使其在实际应用中更具实用性。PF3plat的性能突破了现有SOTA，对3D重建和新颖视图合成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D高斯泼溅（3DGS）方法在处理无姿态图像时，通常需要密集的图像视图、精确的相机姿态和大量的图像重叠。本文旨在提供一个实用的解决方案，以放宽这些常见假设，解决像素对齐的3DGS中因视图间3D高斯错位导致训练不稳定和收敛困难的问题。

**Method:** PF3plat通过利用预训练的单目深度估计和视觉对应模型实现3D高斯的粗略对齐。随后，引入轻量级、可学习模块来精炼粗略对齐的深度和姿态估计。此外，精炼后的估计被用于评估几何置信度分数，以衡量3D高斯中心的可靠性，并相应地调整高斯参数的预测。

**Result:** 在大型真实世界数据集上的广泛评估表明，PF3plat在所有基准测试中都达到了新的最先进水平，并通过全面的消融研究验证了其设计选择。

**Conclusion:** PF3plat成功地解决了从无姿态图像进行新颖视图合成的挑战，通过创新的对齐和精炼机制，显著提升了3D重建和视图合成的质量，并在实际应用中展现出卓越的性能和普适性。

> **ai_Abstract:** PF3plat提出了一种创新的前馈3D高斯泼溅（3DGS）框架，旨在从无姿态图像进行高效且高质量的新颖视图合成，克服了传统3DGS对密集视图、精确相机姿态和图像重叠的依赖。该方法通过利用预训练模型进行3D高斯的粗略对齐，并引入可学习模块精炼深度和姿态估计，同时结合几何置信度分数来优化高斯参数。实验证明，PF3plat在大型真实世界数据集上取得了最先进的性能。

> **摘要翻译:** 我们考虑在单次前馈中从无姿态图像进行新颖视图合成的问题。我们的框架利用了3DGS的快速、可扩展以及高质量的3D重建和视图合成能力，并在此基础上进行了扩展，提供了一个实用的解决方案，放宽了诸如密集图像视图、精确相机姿态和大量图像重叠等常见假设。我们通过识别和解决使用像素对齐3DGS所带来的独特挑战来实现这一点：不同视图之间错位的3D高斯会产生噪声或稀疏的梯度，从而破坏训练的稳定性并阻碍收敛，尤其是在不满足上述假设的情况下。为了缓解这个问题，我们采用预训练的单目深度估计和视觉对应模型来实现3D高斯的粗略对齐。然后，我们引入轻量级、可学习的模块来从粗略对齐中精炼深度和姿态估计，从而提高3D重建和新颖视图合成的质量。此外，精炼后的估计被用于估计几何置信度分数，该分数评估3D高斯中心的可靠性并相应地调整高斯参数的预测。在大型真实世界数据集上的广泛评估表明，PF3plat在所有基准测试中都设定了新的最先进水平，并得到了验证我们设计选择的全面消融研究的支持。项目页面：https://cvlab-kaist.github.io/PF3plat/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [184] [Celeb-DF++: A Large-scale Challenging Video DeepFake Benchmark for Generalizable Forensics](https://arxiv.org/abs/2507.18015)
> *Celeb-DF++: 一个用于通用取证的大规模挑战性视频深度伪造基准*

*Yuezun Li, Delong Zhu, Xinjie Cui, Siwei Lyu* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 深度伪造, 数据集, 通用取证, Celeb-DF++, 视频伪造

**Comment:** https://github.com/OUC-VAS/Celeb-DF-PP

> **TL;DR:** 引入了Celeb-DF++，这是一个大规模、多样化的视频深度伪造数据集，旨在促进通用深度伪造检测，并揭示现有检测方法的局限性。

**AI_Comments:** Celeb-DF++的创新之处在于其大规模和对伪造多样性的强调，通过整合多种生成方法和场景，显著提升了数据集的挑战性，从而更真实地反映了实际中深度伪造的多样性。这对于推动通用型深度伪造检测技术的发展至关重要，因为现有数据集的局限性在于其伪造类型单一。该工作不仅提供了新的基准，还通过评估揭示了当前检测方法的不足，为研究者指明了未来方向。

<details>
  <summary>Details</summary>

**Motivation:** AI技术快速发展导致在线深度伪造视频多样性增加，对“通用取证”（即使用单一模型检测广泛的、未见的深度伪造类型）构成紧迫挑战。现有数据集虽然规模大但伪造类型有限，不足以开发通用检测方法。

**Method:** 构建了Celeb-DF++数据集，它是Celeb-DF的扩展。该数据集包含面部交换（FS）、面部重演（FR）和说话人脸（TF）三种常见伪造场景，使用22种不同的深度伪造方法生成了大量高质量伪造视频。这些方法涵盖了架构、生成流程和目标面部区域的差异。同时，还引入了评估协议来衡量24种最新检测方法的通用性。

**Result:** 评估结果突出了现有检测方法的局限性以及新数据集的难度。

**Conclusion:** Celeb-DF++是一个大规模且具有挑战性的深度伪造视频基准，对于推动通用深度伪造取证技术的发展至关重要，并揭示了当前检测方法的不足。

> **ai_Abstract:** 本文介绍了Celeb-DF++，一个大规模、高挑战性的视频深度伪造基准数据集，旨在解决通用深度伪造检测的难题。该数据集扩展了Celeb-DF，包含了面部交换、面部重演和说话人脸三种常见场景，通过22种不同的最新深度伪造方法生成，涵盖了广泛的伪造类型。研究者还提出了评估协议，并利用24种现有检测方法进行测试，结果表明现有方法在通用性方面存在局限性，并突显了新数据集的挑战性，为未来通用深度伪造检测技术的发展提供了重要资源。

> **摘要翻译:** 人工智能技术的快速发展显著增加了在线传播的深度伪造视频的多样性，这对“通用取证”，即使用单一模型检测广泛的、未见的深度伪造类型，构成了紧迫的挑战。应对这一挑战需要不仅规模大而且伪造多样性丰富的数据集。然而，大多数现有数据集尽管规模庞大，但仅包含有限的伪造类型，使其不足以开发通用检测方法。因此，我们在早期的Celeb-DF数据集的基础上，推出了Celeb-DF++，这是一个新的大规模且具有挑战性的视频深度伪造基准，专用于通用取证挑战。Celeb-DF++涵盖了三种常见的伪造场景：换脸（FS）、面部重演（FR）和说话人脸（TF）。每种场景都包含大量高质量的伪造视频，总共使用了22种各种最新的深度伪造方法生成。这些方法在架构、生成流程和目标面部区域方面各不相同，涵盖了野外最普遍的深度伪造案例。我们还引入了评估协议，用于衡量24种最新检测方法的通用性，突出了现有检测方法的局限性以及我们新数据集的难度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [186] [TeEFusion: Blending Text Embeddings to Distill Classifier-Free Guidance](https://arxiv.org/abs/2507.18192)
> *TeEFusion：融合文本嵌入以蒸馏无分类器引导*

*Minghao Fu, Guo-Hua Wang, Xiaohao Chen, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang* | **Category: cs.CV** | **Updated: 2025-07-25**

**Keywords:** 文本到图像合成, 无分类器引导, 蒸馏, 文本嵌入, 推理加速

**Comment:** Accepted by ICCV 2025. The code is publicly available at
  https://github.com/AIDC-AI/TeEFusion

> **TL;DR:** TeEFusion通过融合文本嵌入来蒸馏无分类器引导，显著提高了文本到图像模型的推理速度，同时保持了图像质量。

**AI_Comments:** TeEFusion的创新之处在于其通过直接融合文本嵌入来“编码”引导信息，并同时蒸馏复杂的采样策略，从而在不引入额外参数的情况下大幅提高推理效率。这对于大规模部署文本到图像模型具有重要意义，因为它解决了CFG带来的计算瓶颈。该方法提供了一个通用的框架，可能适用于其他需要高效引导的生成任务。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本到图像合成方法中，无分类器引导（CFG）虽然能确保高质量生成，但其依赖两次前向传播，结合复杂的采样算法，导致推理成本过高。

**Method:** 本文提出了TeEFusion（文本嵌入融合），一种新颖高效的蒸馏方法。它通过线性操作简单地融合条件和非条件文本嵌入，将引导强度直接融入文本嵌入中，并在不增加额外参数的情况下重建所需的引导。同时，它使学生模型能够学习教师模型通过复杂采样方法产生的输出。

**Result:** 在SD3等先进模型上的广泛实验表明，TeEFusion使学生模型能够密切模仿教师模型的性能，但采样策略更简单、更高效。学生模型的推理速度比教师模型快6倍，同时图像质量保持在通过教师复杂采样方法获得的水平。

**Conclusion:** TeEFusion通过有效的蒸馏方法显著降低了文本到图像合成的推理成本，同时保持了生成质量，为高效的高质量图像生成提供了解决方案。

> **ai_Abstract:** 本文提出了TeEFusion，一种用于文本到图像合成的蒸馏方法，旨在解决无分类器引导（CFG）高昂的推理成本问题。TeEFusion通过线性融合条件和非条件文本嵌入，将CFG的引导强度直接编码到文本嵌入中，并蒸馏教师模型的复杂采样策略。实验证明，该方法使学生模型在保持图像质量的同时，推理速度比教师模型快6倍，显著提升了生成效率。

> **摘要翻译:** 文本到图像合成的最新进展在很大程度上得益于复杂的采样策略和无分类器引导（CFG）以确保高质量生成。然而，CFG对两次前向传播的依赖，特别是与复杂的采样算法结合时，会导致过高的推理成本。为了解决这个问题，我们引入了TeEFusion（文本嵌入融合），这是一种新颖高效的蒸馏方法，它直接将引导强度融入文本嵌入中，并蒸馏教师模型的复杂采样策略。通过简单地使用线性操作融合条件和非条件文本嵌入，TeEFusion在不增加额外参数的情况下重建了所需的引导，同时使学生模型能够学习教师模型通过其复杂采样方法产生的输出。在SD3等先进模型上的广泛实验表明，我们的方法使学生模型能够以更简单、更高效的采样策略密切模仿教师模型的性能。因此，学生模型的推理速度比教师模型快6倍，同时图像质量保持在通过教师复杂采样方法获得的水平。代码已在https://github.com/AIDC-AI/TeEFusion 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [187] [Synthetic Data Augmentation for Enhanced Chicken Carcass Instance Segmentation](https://arxiv.org/abs/2507.18558)
> *合成数据增强用于提升鸡胴体实例分割*

*Yihong Feng, Chaitanya Pallerla, Xiaomin Lin, Pouya Sohrabipour Sr, Philip Crandall, Wan Shou, Yu She, Dongyi Wang* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-24**

**Keywords:** 合成数据, 数据增强, 实例分割, 鸡胴体, 家禽加工

**Comment:** Submitted for journal reviewing

> **TL;DR:** 为解决鸡胴体实例分割中真实数据稀缺问题，研究提出生成逼真的合成图像，并证明合成数据显著提升了分割模型性能，减少了手动标注工作。

**AI_Comments:** 本文的创新点在于首次提出了用于鸡胴体实例分割的合成数据生成管道，并构建了专门的真实世界基准数据集，有效解决了工业应用中数据标注成本高昂和数据稀缺的痛点。其重要性体现在为家禽加工业的自动化质量控制提供了切实可行的AI解决方案，对推动工业界深度学习模型部署具有指导意义。该方法不仅提升了模型性能，还显著降低了数据准备成本，具有很强的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 家禽业需要自动化检测鸡胴体以进行质量控制、食品安全和提高效率。然而，在这些快节奏的工业环境中，开发用于实例分割等任务的稳健深度学习模型常常受到获取和标注大规模真实图像数据集所需的大量工作的阻碍。

**Method:** 1. 提出了一个生成逼真、自动标注的鸡胴体合成图像的管道。2. 引入了一个包含300张标注真实世界图像的新基准数据集。3. 使用这些数据集，研究了合成数据和自动数据标注对鸡胴体实例分割的有效性，尤其是在真实标注数据稀缺的情况下。4. 在主流实例分割模型中，评估了包含不同比例合成图像的小型真实数据集。

**Result:** 结果表明，合成数据显著提升了所有模型在鸡胴体分割方面的性能。

**Conclusion:** 这项研究强调了合成数据增强作为一种可行且有效的策略的价值，可以缓解数据稀缺问题，减少手动标注工作，并推动家禽加工业中鸡胴体稳健的AI驱动自动化检测系统的发展。

> **ai_Abstract:** 本研究针对家禽加工业中鸡胴体实例分割面临的真实标注数据稀缺问题，提出了一个生成逼真、自动标注合成图像的管道，并创建了一个新的真实世界基准数据集。通过在主流实例分割模型中评估合成数据的效果，结果表明合成数据能显著提升分割性能。这证明了合成数据增强是解决数据稀缺、减少人工标注并推进工业自动化检测系统发展的有效策略。

> **摘要翻译:** 家禽业由肉鸡生产驱动，并已发展成为世界上最大的动物蛋白产业。在屠宰场和家禽加工厂中，自动检测加工线上鸡胴体对于质量控制、食品安全和运营效率至关重要。然而，在这些快节奏的工业环境中，开发用于实例分割等任务的稳健深度学习模型常常受到获取和标注大规模真实世界图像数据集所需的大量工作的阻碍。我们提出了第一个生成逼真、自动标注的鸡胴体合成图像的管道。我们还引入了一个包含300张标注真实世界图像的新基准数据集，该数据集是专门为家禽分割研究而策划的。本研究利用这些数据集，调查了合成数据和自动数据标注在增强鸡胴体实例分割方面的功效，特别是在加工线上真实标注数据稀缺的情况下。在一个小型真实数据集上，评估了不同比例合成图像在主流实例分割模型中的表现。结果表明，合成数据显著提升了所有模型在鸡胴体分割方面的性能。这项研究强调了合成数据增强作为一种可行且有效的策略的价值，可以缓解数据稀缺问题，减少手动标注工作，并推动家禽加工业中鸡胴体稳健的AI驱动自动化检测系统的发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [188] [LOTUS: A Leaderboard for Detailed Image Captioning from Quality to Societal Bias and User Preferences](https://arxiv.org/abs/2507.19362)
> *LOTUS：一个从质量到社会偏见和用户偏好的详细图像字幕排行榜*

*Yusuke Hirota, Boyi Li, Ryo Hachiuma, Yueh-Hua Wu, Boris Ivanovic, Yuta Nakashima, Marco Pavone, Yejin Choi, Yu-Chiang Frank Wang, Chao-Han Huck Yang* | **Category: cs.CV, cs.AI, cs.CL, cs.CY, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 详细图像字幕, 排行榜, 社会偏见, 用户偏好, 大型视觉语言模型

**Comment:** Accepted to ACL 2025. Leaderboard:
  huggingface.co/spaces/nvidia/lotus-vlm-bias-leaderboard

> **TL;DR:** LOTUS是一个新的排行榜，用于评估大型视觉语言模型（LVLMs）生成的详细图像字幕，涵盖质量、风险、社会偏见和用户偏好，研究发现没有单一模型在所有标准上表现最佳。

**AI_Comments:** LOTUS的创新之处在于它首次将社会偏见和用户偏好纳入详细图像字幕的评估体系，这对于推动LVLMs的公平性和实用性具有重要意义。它不仅关注传统的质量指标，还深入探讨了模型在实际应用中可能带来的风险和用户体验，为未来LVLMs的开发和部署提供了更全面的指导。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图像字幕评估存在三大空白：缺乏标准化标准、缺乏偏见感知评估以及未考虑用户偏好。

**Method:** 本文引入了LOTUS，一个用于评估详细图像字幕的排行榜。LOTUS全面评估字幕质量（如对齐性、描述性）、风险（如幻觉）和社会偏见（如性别偏见），并通过根据不同的用户偏好定制标准来实现偏好导向的评估。

**Result:** 对近期大型视觉语言模型（LVLMs）的分析表明，没有单一模型能在所有标准上表现出色；字幕细节与偏见风险之间存在相关性；偏好导向的评估表明，最佳模型选择取决于用户优先级。

**Conclusion:** 没有单一的大型视觉语言模型能在所有详细图像字幕评估标准上表现最佳，模型选择应根据用户优先级和特定需求进行，并且需要考虑字幕细节与偏见风险之间的权衡。

> **ai_Abstract:** 本文介绍了LOTUS，一个针对大型视觉语言模型（LVLMs）生成详细图像字幕的评估排行榜。LOTUS旨在解决现有评估中标准不统一、缺乏偏见考量和用户偏好缺失的问题。该排行榜全面评估字幕的质量、潜在风险（如幻觉）和社会偏见（如性别偏见），并支持基于用户偏好的定制化评估。研究结果显示，目前没有单一LVLM能在所有评估标准上取得最佳表现，且字幕的详细程度与偏见风险之间存在相关性，模型的最佳选择取决于用户的具体优先级。

> **摘要翻译:** 大型视觉语言模型（LVLMs）已经改变了图像字幕领域，从简洁的字幕转向详细的描述。我们引入了LOTUS，一个用于评估详细字幕的排行榜，解决了现有评估中的三个主要空白：缺乏标准化标准、偏见感知评估不足以及未考虑用户偏好。LOTUS全面评估了各个方面，包括字幕质量（例如，对齐性、描述性）、风险（例如，幻觉）和社会偏见（例如，性别偏见），同时通过根据多样化的用户偏好定制标准，实现了偏好导向的评估。我们对近期LVLMs的分析表明，没有单一模型能在所有标准上表现出色，同时字幕细节与偏见风险之间存在关联。偏好导向的评估表明，最佳模型选择取决于用户优先级。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [189] [A Transfer Learning-Based Method for Water Body Segmentation in Remote Sensing Imagery: A Case Study of the Zhada Tulin Area](https://arxiv.org/abs/2507.10084)
> *一种基于迁移学习的遥感影像水体分割方法：以扎达土林地区为例*

*Haonan Chen, Xin Tong* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 迁移学习, 水体分割, 遥感影像, SegFormer, 青藏高原

**Comment:** 13 pages, 6 figures, 2 tables

> **TL;DR:** 本研究提出了一种两阶段迁移学习策略，利用SegFormer模型提高干旱高原地区遥感影像水体分割的精度，并揭示了水体的集中分布。

**AI_Comments:** 本研究的创新点在于提出了两阶段迁移学习策略，有效解决了遥感影像水体分割中领域漂移和数据稀缺的难题，显著提升了模型性能。其重要性在于为气候敏感的干旱高原地区提供了精确的水体监测技术，对于灾害风险管理、水资源规划和气候适应具有实际应用价值。特别是其定量揭示的水体集中分布特征，为水文研究提供了新见解。

<details>
  <summary>Details</summary>

**Motivation:** 青藏高原面临水安全挑战，需要先进的地球观测技术进行可持续水资源监测以应对气候变化。开发鲁棒的AI模型面临领域漂移和数据稀缺两大障碍。

**Method:** 本研究提出了一种两阶段迁移学习策略，使用SegFormer模型。模型首先在多样化的源域进行预训练，然后针对干旱的扎达土林地区进行微调。

**Result:** 实验结果显示，水体分割的交并比（IoU）从直接迁移的25.50%大幅提升至64.84%。高精度地图显示水体空间分布高度集中，超过80%的水域面积集中在不到20%的河道长度内。

**Conclusion:** 本研究展示了一种监测干旱高原地区的有效技术解决方案，并有助于推动AI驱动的地球观测在关键跨界河流源头灾害防备中的应用。高精度水体地图对理解水文过程和制定水管理及气候适应策略至关重要。

> **ai_Abstract:** 本研究针对青藏高原水安全挑战，提出一种基于SegFormer模型的两阶段迁移学习方法，用于遥感影像的水体分割。该方法有效克服了领域漂移和数据稀缺问题，将扎达土林地区水体分割的IoU从25.50%提升至64.84%。研究结果不仅提供了高精度水体地图，揭示了水体高度集中的分布特征，还为灾害风险降低、水文过程理解及水管理和气候适应策略的制定提供了关键支持，展示了AI在地球观测中的应用潜力。

> **摘要翻译:** 青藏高原被称为“亚洲水塔”，由于对气候变化高度敏感，面临严峻的水安全挑战。因此，推进地球观测以实现可持续水资源监测对于该地区建立气候韧性至关重要。本研究提出了一种利用SegFormer模型的两阶段迁移学习策略，以克服领域漂移和数据稀缺——这是开发用于气候敏感应用的鲁棒AI模型的关键障碍。在多样化的源域进行预训练后，我们的模型针对干旱的扎达土林地区进行了微调。实验结果显示性能大幅提升：水体分割的交并比（IoU）从直接迁移的25.50%飙升至64.84%。这种AI驱动的精度对于减少灾害风险至关重要，特别是在监测易发生山洪的系统方面。更重要的是，高精度地图揭示了水体高度集中的空间分布，超过80%的水域面积局限于不到20%的河道长度。这一定量发现为理解水文过程和设计有针对性的水管理和气候适应策略提供了关键证据。因此，我们的工作展示了一种监测干旱高原地区的有效技术解决方案，并有助于推动AI驱动的地球观测在关键跨界河流源头灾害防备方面的进展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [209] [EVEv2: Improved Baselines for Encoder-Free Vision-Language Models](https://arxiv.org/abs/2502.06788)
> *EVEv2: 改进的无编码器视觉-语言模型基线*

*Haiwen Diao, Xiaotong Li, Yufeng Cui, Yueze Wang, Haoge Deng, Ting Pan, Wenxuan Wang, Huchuan Lu, Xinlong Wang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 无编码器视觉-语言模型, EVEv2, 多模态系统, 仅解码器架构, 视觉推理

**Comment:** 20 pages, 10 figures, Accepted by ICCV2025 (highlight)

> **TL;DR:** EVEv2是一个新的无编码器视觉-语言模型家族，通过改进的策略和训练方法，其性能可以与主流的基于编码器的模型相媲美，具有更高的部署效率和数据效率。

**AI_Comments:** 这篇论文的创新点在于提出了EVEv2.0，一个改进的无编码器视觉-语言模型家族，其性能能够媲美甚至超越传统的基于编码器的模型，同时保持了结构简单和部署高效的优势。特别强调了通过分解和分层关联不同模态以及优化训练策略来提升性能，这对于推动统一多模态系统的发展具有重要意义。其数据效率和视觉推理能力也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有无编码器视觉-语言模型（VLMs）正迅速缩小与基于编码器的模型之间的性能差距，凸显了结构简单和部署高效的统一多模态系统的潜力。本研究旨在系统地阐明无编码器VLM的未充分研究特性，并开发出能与主流基于编码器模型竞争的有效策略。

**Method:** 系统地阐明了使用预训练视觉编码器、离散分词器和从头开始的极简视觉层的VLM之间的性能差距。开发了针对无编码器VLM的有效策略，并推出了EVEv2.0系列模型。研究中发现，正确分解和分层关联视觉和语言可以减少模态间干扰，同时设计了精心优化的训练策略来实现有效优化。通过广泛评估验证了模型性能。

**Result:** EVEv2.0的性能能够与主流的基于编码器的VLM相媲美。在统一模型中正确分解和分层关联视觉和语言能够减少模态间的干扰。精心设计的训练策略能够实现无编码器VLM的有效优化。EVEv2.0展示了卓越的数据效率和强大的视觉推理能力。

**Conclusion:** EVEv2.0代表了开发跨模态仅解码器架构的全面研究，并证明了其优越的数据效率和强大的视觉推理能力。

> **ai_Abstract:** EVEv2.0是一个新的无编码器视觉-语言模型家族，旨在缩小与基于编码器的模型之间的性能差距，同时保持结构简单和部署高效。该研究系统性地分析了无编码器VLM的特性，并提出了有效的策略，包括正确分解和分层关联视觉与语言以及精心设计的训练策略。EVEv2.0展示了与主流基于编码器模型相当的性能，并具有卓越的数据效率和强大的视觉推理能力，为开发跨模态的仅解码器架构提供了深入研究。

> **摘要翻译:** 现有的无编码器视觉-语言模型（VLM）正在迅速缩小与基于编码器的模型之间的性能差距，这突显了结构简单且部署高效的统一多模态系统的巨大潜力。我们系统地阐明了使用预训练视觉编码器、离散分词器和从头开始的极简视觉层的VLM之间的性能差距，深入挖掘了无编码器VLM未被充分研究的特性。我们为无编码器VLM开发了能够与主流基于编码器的模型相媲美的有效策略。经过深入研究，我们推出了EVEv2.0，这是一个新的、改进的无编码器VLM家族。我们表明：（i）在统一模型中正确分解和分层关联视觉和语言可以减少模态之间的干扰。（ii）精心设计的训练策略能够实现无编码器VLM的有效优化。通过广泛评估，我们的EVEv2.0代表了开发跨模态仅解码器架构的全面研究，展示了卓越的数据效率和强大的视觉推理能力。代码已在以下网址公开：https://github.com/baaivision/EVE。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [210] [Rethinking Occlusion in FER: A Semantic-Aware Perspective and Go Beyond](https://arxiv.org/abs/2507.15401)
> *重新思考FER中的遮挡：一个语义感知视角及超越*

*Huiyu Zhai, Xingxing Yang, Yalan Ye, Chenyang Li, Bin Fan, Changze Li* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 面部表情识别, 遮挡, 语义感知, 多模态, 数据集

**Comment:** 

> **TL;DR:** 本文提出了ORSANet，一个利用多模态语义指导和新损失函数来提升遮挡条件下FER性能的模型，并构建了首个遮挡导向的FER数据集。

**AI_Comments:** 本文的创新点在于其多模态语义指导（结合密集语义分割图和稀疏面部地标）来处理遮挡和固有偏差，以及定制的MCM模块实现自适应特征融合。DARELoss的引入也为区分相似表情提供了新思路。更重要的是，首次构建了面向遮挡的FER数据集Occlu-FER，为未来在该特定挑战领域的研究提供了宝贵的资源和评估基准，这对于提升FER模型在真实世界复杂环境下的鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 面部表情识别（FER）由于普遍存在的遮挡和数据集偏差而面临挑战。尤其当面部信息部分被遮挡时，现有FER模型难以提取有效的面部特征，导致分类不准确。

**Method:** 本文提出了ORSANet模型，包含三项关键贡献：1) 引入辅助多模态语义指导，包括语义分割图（作为密集语义先验）和面部地标（作为稀疏几何先验），以消除面部遮挡的歧义并学习高级语义知识，同时减轻固有噪声。2) 定制多尺度交叉交互模块（MCM），以自适应地融合不同尺度的地标特征和语义增强表示。3) 设计动态对抗排斥增强损失（DARELoss），动态调整模糊类别的裕度，进一步增强模型区分相似表情的能力。此外，还构建了首个面向遮挡的FER数据集Occlu-FER，以促进对各种真实世界遮挡条件的专门鲁棒性分析。

**Result:** 在公共基准和Occlu-FER数据集上的大量实验表明，所提出的ORSANet取得了最先进的（SOTA）识别性能。

**Conclusion:** ORSANet通过结合多模态语义指导、自适应特征融合机制和动态损失函数，显著提升了遮挡条件下的面部表情识别性能，并通过构建专门的遮挡数据集，为该领域的研究提供了新的方向和评估基准。

> **ai_Abstract:** 本文针对面部表情识别（FER）中普遍存在的遮挡和数据集偏差问题，提出了ORSANet模型。该模型引入多模态语义指导（结合语义分割图和面部地标）以获取语义增强的面部特征并减轻噪声；设计了多尺度交叉交互模块（MCM）以有效融合多模态先验；并提出了动态对抗排斥增强损失（DARELoss）以提升相似表情的区分能力。此外，研究还构建了首个遮挡导向的FER数据集Occlu-FER。实验证明，ORSANet在多个基准和Occlu-FER上均达到了最先进的识别性能。

> **摘要翻译:** 面部表情识别（FER）由于普遍存在的遮挡和数据集偏差而面临一项具有挑战性的任务。特别是当面部信息部分被遮挡时，现有FER模型难以提取有效的面部特征，导致分类不准确。针对此问题，我们提出了ORSANet，它引入了以下三个关键贡献：首先，我们引入辅助多模态语义指导，以消除面部遮挡的歧义并学习高级语义知识，这包括两方面：1) 我们引入语义分割图作为密集语义先验，以生成语义增强的面部表示；2) 我们引入面部地标作为稀疏几何先验，以减轻FER中的固有噪声，例如身份和性别偏差。其次，为了促进这两种多模态先验的有效结合，我们定制了一个多尺度交叉交互模块（MCM），以自适应地融合不同尺度的地标特征和语义增强表示。第三，我们设计了一种动态对抗排斥增强损失（DARELoss），它动态调整模糊类别的裕度，进一步增强了模型区分相似表情的能力。我们进一步构建了首个面向遮挡的FER数据集，以促进对各种真实世界遮挡条件的专门鲁棒性分析，该数据集名为Occlu-FER。在公共基准和Occlu-FER上的大量实验表明，我们提出的ORSANet取得了最先进的识别性能。代码已在https://github.com/Wenyuzhy/ORSANet-master公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [214] [VideoMind: An Omni-Modal Video Dataset with Intent Grounding for Deep-Cognitive Video Understanding](https://arxiv.org/abs/2507.18552)
> *VideoMind：一个用于深度认知视频理解的意图接地全模态视频数据集*

*Baoyao Yang, Wanyun Li, Dixin Chen, Junxiang Chen, Wenbin Yao, Haifeng Lin* | **Category: cs.CV, cs.AI, 68T45, 68T50, 68U35,, I.4.8; I.2.7; I.2.10; H.5.1** | **Updated: 2025-07-24**

**Keywords:** 视频数据集, 意图接地, 深度认知, 全模态, 链式思考

**Comment:** 7 pages; 14 figures

> **TL;DR:** VideoMind是一个包含意图表达的全模态视频数据集，旨在促进深度认知视频理解，通过链式思考方法生成深层描述，并提供基准测试以评估模型。

**AI_Comments:** VideoMind的创新之处在于其引入了“意图表达”和“深度认知表达”，并通过链式思考（COT）方法生成这些复杂的语义信息，这显著超越了现有数据集的表层描述。它为深度视频理解，特别是情感和意图识别等高级认知任务，提供了前所未有的资源和基准。该数据集的发布及其对多模态模型评估的支持，有望推动相关领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有数据集缺乏对视频内容深层认知和意图理解的支持。本研究旨在通过引入一个包含意图表达的全模态视频数据集VideoMind，以促进深度视频内容认知和增强多模态特征表示。

**Method:** VideoMind数据集包含103K视频样本（3K用于测试），每个样本配有音频和详细的文本描述。描述分为事实、抽象和意图三个层次。意图表达通过链式思考（COT）方法，利用多语言大型模型（mLLM）逐步推理生成。每份描述包含主体、地点、时间、事件、动作和意图的标注。同时，建立了包含3,000个手动验证样本的黄金标准基准，并设计了混合认知检索实验，使用多层检索指标评估深度视频理解。

**Result:** 发布了InternVideo、VAST、UMT-L等模型的评估结果。VideoMind数据集已在GitHub、HuggingFace和OpenDataLab上公开可用。

**Conclusion:** VideoMind数据集为细粒度跨模态对齐提供了一个强大的基准，并推动了需要深度视频理解的领域发展，例如情感和意图识别。

> **ai_Abstract:** VideoMind是一个新颖的全模态视频数据集，旨在解决现有数据集在深度视频内容认知和意图理解方面的不足。它包含103K个视频样本，每个样本都配有分层（事实、抽象、意图）的文本描述，特别是通过链式思考（COT）方法生成的深层意图表达。数据集还提供了用于评估深度认知视频理解的黄金标准基准和混合认知检索实验。VideoMind为细粒度跨模态对齐和需要深度视频理解的应用（如情感和意图识别）提供了重要的资源。

> **摘要翻译:** 本文介绍了VideoMind，一个以视频为中心的全模态数据集，专为深度视频内容认知和增强的多模态特征表示而设计。该数据集包含103K个视频样本（3K个预留用于测试），每个样本都配有音频和系统详细的文本描述。具体来说，每个视频及其音频都通过三个层级（事实、抽象和意图）进行描述，从表面到深度逐步深入。它包含超过2200万个单词，平均每个样本约225个单词。VideoMind与现有数据集的关键区别在于它提供了意图表达，这需要整合整个视频的上下文，并且无法直接观察。这些深度认知表达是使用链式思考（COT）方法生成的，通过逐步推理提示mLLM。每个描述都包含对主体、地点、时间、事件、动作和意图的注释，支持下游识别任务。至关重要的是，我们建立了一个包含3,000个手动验证样本的黄金标准基准，用于评估深度认知视频理解。我们设计了混合认知检索实验，通过多级检索指标进行评分，以适当评估深度视频理解。模型（例如InternVideo、VAST、UMT-L）的评估结果已发布。VideoMind可作为细粒度跨模态对齐的强大基准，并推动了需要深度视频理解的领域发展，例如情感和意图识别。该数据在GitHub、HuggingFace和OpenDataLab上公开可用，https://github.com/cdx-cindy/VideoMind。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [223] [CutS3D: Cutting Semantics in 3D for 2D Unsupervised Instance Segmentation](https://arxiv.org/abs/2411.16319)
> *CutS3D: 在3D中切割语义用于2D无监督实例分割*

*Leon Sick, Dominik Engel, Sebastian Hartwig, Pedro Hermosilla, Timo Ropinski* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 无监督实例分割, 3D语义切割, 点云, 空间重要性, 空间置信度

**Comment:** Accepted at ICCV 2025. Project Page with Code, Models & Demo:
  https://leonsick.github.io/cuts3d/

> **TL;DR:** CutS3D提出了一种新的无监督2D实例分割方法，通过在3D空间中切割语义来解决2D重叠实例分割问题，并引入空间重要性和空间置信度来提高性能，在多个基准测试中优于现有方法。

**AI_Comments:** CutS3D的创新之处在于其将3D信息引入2D无监督实例分割的策略，通过在3D空间中进行语义切割，有效地解决了2D图像中实例重叠的难题。这种跨维度的信息利用方式为无监督学习领域带来了新的思路，特别是其提出的空间重要性和空间置信度组件，进一步提升了模型的鲁棒性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的无监督2D实例分割方法通常生成伪掩码并训练类别无关检测器，但由于仅考虑语义，它们在处理2D图像空间中重叠的实例时往往会失败。

**Method:** 本文提出CutS3D方法，利用场景的点云表示在3D中切割语义掩码以获得最终的2D实例。此外，还推导了一个空间重要性函数来锐化3D实例边界的语义。为了解决掩码模糊性，通过三个空间置信度组件增强了类别无关检测器的训练，以隔离干净的学习信号。

**Result:** CutS3D方法在多个无监督实例分割和目标检测的标准基准测试中超越了竞争方法。

**Conclusion:** 通过在3D中切割语义并结合空间重要性函数和空间置信度组件，CutS3D成功解决了2D无监督实例分割中重叠实例的挑战，并取得了最先进的性能。

> **ai_Abstract:** CutS3D是一种创新的无监督2D实例分割方法，旨在克服现有方法在处理2D图像中重叠实例时的局限性。它通过利用场景的3D点云表示，在3D空间中切割语义掩码来生成2D实例。该方法还引入了空间重要性函数来细化3D边界的语义，并使用三个空间置信度组件增强类别无关检测器的训练，以解决伪掩码的模糊性。实验结果表明，CutS3D在多个标准基准测试中优于其他无监督实例分割和目标检测方法。

> **摘要翻译:** 传统上，学习分割2D图像中对象实例的算法严重依赖大量人工标注数据。直到最近，才出现了以无监督方式解决此问题的新方法。通常，这些方法首先生成伪掩码，然后训练一个类别无关的检测器。尽管此类方法达到了当前的最新技术水平，但由于仅考虑语义，它们通常无法正确分离2D图像空间中重叠的实例。为了解决这个问题，我们建议利用场景的点云表示，在3D中切割语义掩码以获得最终的2D实例。此外，我们推导了一个空间重要性函数，用于沿实例的3D边界重新锐化语义。然而，这些伪掩码仍然存在掩码模糊性。为了解决这个问题，我们进一步建议通过三个空间置信度组件来增强类别无关检测器的训练，旨在隔离干净的学习信号。凭借这些贡献，我们的方法在多个无监督实例分割和目标检测的标准基准测试中优于竞争方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [228] [Iwin Transformer: Hierarchical Vision Transformer using Interleaved Windows](https://arxiv.org/abs/2507.18405)
> *Iwin Transformer：使用交错窗口的分层视觉Transformer*

*Simin Huo, Ning Li* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** Iwin Transformer, 视觉Transformer, 交错窗口注意力, 深度可分离卷积, 分层Transformer

**Comment:** 14 pages, 10 figures, Submitted to IEEE Transactions on Pattern
  Analysis and Machine Intelligence

> **TL;DR:** 提出Iwin Transformer，一种新型分层视觉Transformer，结合交错窗口注意力和深度可分离卷积，在一个模块内实现全局信息交换，超越Swin Transformer，并在视觉任务中表现出色。

**AI_Comments:** Iwin Transformer的创新之处在于其将注意力机制和深度可分离卷积结合在一个模块中，有效地解决了Swin Transformer在全局注意力上的局限，实现了高效的全局信息交换。其无位置编码设计和直接从低分辨率到高分辨率的微调能力，使其在实际应用中更具灵活性。该研究为未来Transformer架构的设计，特别是在视频生成等领域，提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 旨在克服Swin Transformer需要两个连续块才能近似全局注意力的局限性，实现一个模块内的全局信息交换。

**Method:** 引入Iwin Transformer，一种新型的无位置编码分层视觉Transformer。它通过创新的交错窗口注意力与深度可分离卷积相结合，利用注意力连接远距离token，应用卷积连接相邻token，从而在一个模块内实现全局信息交换，并能直接从低分辨率微调到高分辨率。

**Result:** 在视觉基准测试中表现出强大的竞争力，例如在ImageNet-1K上图像分类达到87.4%的top-1准确率，并在语义分割和视频动作识别任务中表现出色。Iwin的核心组件作为独立模块，可以无缝替换类条件图像生成中的自注意力模块。

**Conclusion:** Iwin Transformer引入的概念和方法具有启发未来研究的潜力，例如视频生成中的Iwin 3D注意力。

> **ai_Abstract:** Iwin Transformer是一种新型的无位置编码分层视觉Transformer，它结合了交错窗口注意力与深度可分离卷积，在一个模块内高效地实现了全局信息交换，克服了Swin Transformer的局限。该模型可以直接从低分辨率微调到高分辨率，并在图像分类、语义分割和视频动作识别等多种视觉任务中展现出卓越的性能，其核心组件甚至可用于图像生成。

> **摘要翻译:** 我们引入了Iwin Transformer，这是一种新颖的无位置编码分层视觉Transformer，通过创新性的交错窗口注意力与深度可分离卷积的协同作用，可以直接从低分辨率微调到高分辨率。这种方法使用注意力连接远距离token，并应用卷积连接相邻token，从而在一个模块内实现全局信息交换，克服了Swin Transformer需要两个连续块才能近似全局注意力的局限性。在视觉基准测试中进行的广泛实验表明，Iwin Transformer在图像分类（ImageNet-1K上达到87.4%的top-1准确率）、语义分割和视频动作识别等任务中表现出强大的竞争力。我们还验证了Iwin中核心组件作为独立模块的有效性，它可以无缝替换类条件图像生成中的自注意力模块。Iwin Transformer引入的概念和方法有潜力启发未来的研究，例如视频生成中的Iwin 3D注意力。代码和模型可在https://github.com/cominder/Iwin-Transformer获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [230] [Quantifying and Narrowing the Unknown: Interactive Text-to-Video Retrieval via Uncertainty Minimization](https://arxiv.org/abs/2507.15504)
> *量化与缩小未知：通过不确定性最小化实现交互式文本到视频检索*

*Bingqing Zhang, Zhuo Cao, Heming Du, Yang Li, Xue Li, Jiajun Liu, Sen Wang* | **Category: cs.CV, 68T45, I.2.10; H.3.3** | **Updated: 2025-07-24**

**Keywords:** 文本到视频检索, 不确定性量化, 交互式系统, 查询细化, 召回率

**Comment:** Accepted by ICCV 2025

> **TL;DR:** UMIVR框架通过量化文本歧义、映射不确定性和帧不确定性来解决交互式文本到视频检索中的挑战，并通过生成有针对性的澄清问题来迭代细化用户查询，显著提高检索性能。

**AI_Comments:** UMIVR的创新点在于首次明确量化了文本到视频检索中的关键不确定性，并通过这些量化指标来指导交互式查询细化，而非依赖启发式方法。这种基于不确定性最小化的方法为交互式检索系统提供了一个更坚实、更具原则性的基础，有望提高用户体验和检索精度。

<details>
  <summary>Details</summary>

**Motivation:** 尽管文本到视频检索（TVR）取得了进展，但仍受多重固有不确定性（如文本查询模糊、文本-视频映射不明确、视频帧质量低）的阻碍。现有交互系统通常依赖启发式或临时策略，未能明确量化这些不确定性，限制了其有效性。

**Method:** 本文提出了UMIVR（不确定性最小化交互式文本到视频检索框架），通过无训练的原则性度量显式量化三种关键不确定性：基于语义熵的文本歧义分数（TAS）、基于Jensen-Shannon散度的映射不确定性分数（MUS）以及基于时间质量的帧采样器（TQFS）。UMIVR根据这些不确定性度量自适应生成有针对性的澄清问题，迭代细化用户查询。

**Result:** 在多个基准测试中，UMIVR的有效性得到了验证，在MSR-VTT-1k数据集上，经过10轮交互后，Recall@1显著提高到69.2%。

**Conclusion:** UMIVR通过显式量化和最小化不确定性，为交互式文本到视频检索奠定了基础，显著提高了检索性能。

> **ai_Abstract:** 本文提出UMIVR框架，旨在解决文本到视频检索中固有的不确定性问题，包括文本歧义、映射不确定性和帧不确定性。UMIVR通过引入无训练的度量（TAS、MUS、TQFS）来显式量化这些不确定性，并利用这些度量自适应生成澄清问题，以迭代细化用户查询。实验结果表明，UMIVR在多个基准测试上表现出色，显著提升了检索性能，为交互式TVR奠定了不确定性最小化的新基础。

> **摘要翻译:** 尽管最近取得了进展，但文本到视频检索（TVR）仍然受到多种固有不确定性的阻碍，例如模糊的文本查询、不明确的文本-视频映射以及低质量的视频帧。尽管交互式系统已经出现，通过澄清问题来细化用户意图以解决这些挑战，但当前方法通常依赖启发式或临时策略，没有明确量化这些不确定性，从而限制了它们的有效性。受此差距的启发，我们提出了UMIVR，一个不确定性最小化交互式文本到视频检索框架，它通过原则性的、无需训练的度量显式量化了三个关键不确定性——文本歧义、映射不确定性和帧不确定性：基于语义熵的文本歧义分数（TAS）、基于Jensen-Shannon散度的映射不确定性分数（MUS）以及基于时间质量的帧采样器（TQFS）。通过在这些不确定性度量的指导下自适应生成有针对性的澄清问题，UMIVR迭代地细化用户查询，显著降低了检索模糊性。在多个基准测试上进行的广泛实验验证了UMIVR的有效性，在MSR-VTT-1k数据集上，经过10轮交互后，Recall@1（69.2%）取得了显著增益，从而为交互式TVR奠定了不确定性最小化的基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [234] [LEAF: Latent Diffusion with Efficient Encoder Distillation for Aligned Features in Medical Image Segmentation](https://arxiv.org/abs/2507.18214)
> *LEAF：基于高效编码器蒸馏的潜在扩散模型，用于医学图像分割中的对齐特征*

*Qilin Huang, Tianyu Lin, Zhiguang Chen, Fudan Zheng* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 医学图像分割, 潜在扩散模型, 特征蒸馏, LEAF, 高效

**Comment:** Accepted at MICCAI 2025

> **TL;DR:** LEAF是一种高效的医学图像分割模型，它改进了潜在扩散模型，通过直接预测分割图和特征蒸馏来提高性能，且不增加推理开销。

**AI_Comments:** LEAF的创新点在于其针对医学图像分割任务对潜在扩散模型进行了高效的微调策略，特别是通过直接预测分割图和引入特征蒸馏来优化特征表示，同时保持了推理效率。这对于将扩散模型更广泛地应用于实际医疗场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有扩散模型在医学图像分割中直接迁移训练过程，缺乏针对性调整；常用预训练扩散模型在特征提取方面存在不足。

**Method:** 提出LEAF模型，基于潜在扩散模型。在微调过程中，将原始噪声预测模式替换为直接预测分割图，以减少分割结果方差。采用特征蒸馏方法，将卷积层隐藏状态与基于Transformer的视觉编码器特征对齐。

**Result:** 该方法在多个不同疾病类型的分割数据集上提升了原始扩散模型的性能。推理阶段不改变模型架构，不增加参数或计算量，效率高。

**Conclusion:** LEAF通过改进潜在扩散模型的微调策略和引入特征蒸馏，有效提升了医学图像分割性能，同时保持了高效率。

> **ai_Abstract:** LEAF是一种用于医学图像分割的潜在扩散模型。针对现有扩散模型在分割任务中缺乏特定调整和特征提取不足的问题，LEAF在微调阶段用直接预测分割图代替噪声预测，并引入特征蒸馏以对齐特征。实验证明，LEAF在不增加推理开销的情况下，显著提升了原始扩散模型在多种医学图像分割任务上的性能。

> **摘要翻译:** 利用扩散模型的强大能力在医学图像分割任务中取得了相当有效的结果。然而，现有方法通常直接迁移原始训练过程，没有针对分割任务进行具体调整。此外，常用的预训练扩散模型在特征提取方面仍然存在不足。基于这些考虑，我们提出了LEAF，一个基于潜在扩散模型的医学图像分割模型。在微调过程中，我们用直接预测分割图来替代原始的噪声预测模式，从而减少了分割结果的方差。我们还采用了一种特征蒸馏方法，将卷积层的隐藏状态与基于Transformer的视觉编码器的特征对齐。实验结果表明，我们的方法在多个不同疾病类型的分割数据集上提升了原始扩散模型的性能。值得注意的是，我们的方法不改变模型架构，也不增加推理阶段的参数数量或计算量，使其具有很高的效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [236] [Deep Learning-Based Age Estimation and Gender Deep Learning-Based Age Estimation and Gender Classification for Targeted Advertisement](https://arxiv.org/abs/2507.18565)
> *基于深度学习的年龄估计和性别分类用于精准广告投放*

*Muhammad Imran Zaman, Nisar Ahmed* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 深度学习, 年龄估计, 性别分类, 卷积神经网络, 精准广告

**Comment:** 6

> **TL;DR:** 本文提出一种新颖的深度学习方法，通过定制CNN同时进行面部图像的年龄和性别分类，以提升精准广告效果，实现了高精度性别分类和有竞争力的年龄估计，并指出了年轻群体年龄估计的挑战。

**AI_Comments:** 本文的创新之处在于提出了一种定制的CNN架构，能够同时进行年龄和性别分类，并通过学习共享表示来提高性能，这与现有独立处理任务的方法不同。其重要性体现在为精准广告提供了更有效的人群识别工具。论文也指出了模型在年轻群体年龄估计上的局限性，并提出了未来通过数据增强和模型优化来解决这些偏差的方向，显示了研究的深度和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过同时进行面部图像的年龄和性别分类来提高精准广告活动的有效性。现有方法通常独立处理这些任务，而本文希望通过学习共享表示来提升性能。

**Method:** 提出了一种定制的卷积神经网络（CNN）架构，该架构针对年龄和性别分类任务进行了优化，并利用面部特征中年龄和性别信息固有的相关性。模型通过学习共享表示来处理这两个任务，并在一个大型、多样化的面部图像数据集上进行训练，该数据集经过预处理以确保对光照、姿态和图像质量变化的鲁棒性。

**Result:** 实验结果表明，性别分类准确率显著提高，达到95%；年龄估计的平均绝对误差为5.77年，具有竞争力。研究还分析了不同年龄组的性能，发现准确估计年轻个体年龄存在特定挑战。

**Conclusion:** 该研究成功开发了一种基于深度学习的同时进行年龄和性别分类的方法，显著提高了性别分类准确率并提供了有竞争力的年龄估计。研究发现需要针对年轻个体年龄估计的偏差进行有针对性的数据增强和模型优化。此外，文章还探讨了不同CNN架构和超参数设置对整体性能的影响，为未来的研究提供了有价值的见解。

> **ai_Abstract:** 本文提出了一种新颖的深度学习方法，通过定制的卷积神经网络（CNN）架构，实现从面部图像同时进行年龄和性别分类，以提升精准广告效果。该模型通过学习共享表示，优于独立处理任务的现有方法。在大型多样化数据集上训练后，实验结果显示性别分类准确率达95%，年龄估计平均绝对误差为5.77年。研究还指出，年轻个体年龄估计存在挑战，需要进一步的数据增强和模型优化，并为未来研究提供了CNN架构和超参数设置的见解。

> **摘要翻译:** 本文提出了一种新颖的基于深度学习的方法，用于从面部图像中同时进行年龄和性别分类，旨在提高精准广告活动的有效性。我们提出了一种定制的卷积神经网络（CNN）架构，该架构针对这两个任务进行了优化，并利用了面部特征中年龄和性别信息固有的相关性。与现有方法通常独立处理这些任务不同，我们的模型学习共享表示，从而提高了性能。该网络在一个大型、多样化的面部图像数据集上进行训练，该数据集经过精心预处理，以确保对光照、姿态和图像质量变化的鲁棒性。我们的实验结果表明，性别分类准确率显著提高，达到95%，年龄估计的平均绝对误差为5.77年，具有竞争力。关键的是，我们分析了不同年龄组的性能，确定了准确估计年轻个体年龄的特定挑战。这项分析揭示了需要有针对性的数据增强和模型改进来解决这些偏差。此外，我们探讨了不同CNN架构和超参数设置对整体性能的影响，为未来的研究提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [238] [Verbalized Representation Learning for Interpretable Few-Shot Generalization](https://arxiv.org/abs/2411.18651)
> *可解释的少样本泛化口语化表征学习*

*Cheng-Fu Yang, Da Yin, Wenbo Hu, Nanyun Peng, Bolei Zhou, Kai-Wei Chang* | **Category: cs.CV, cs.CL, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 口语化表征学习, 少样本学习, 可解释性, 视觉-语言模型, 目标识别

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 提出口语化表征学习 (VRL)，利用视觉-语言模型自动提取人类可解释特征，显著提升少样本目标识别性能，数据量减少95%。

**AI_Comments:** VRL的创新之处在于利用VLM生成口语化且可解释的特征，这使得模型在少样本学习中不仅提高了性能，还增强了结果的可解释性，同时显著降低了数据需求。这种方法为构建更高效、更透明的AI系统提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 人类在观察少量样本后就能识别物体，这种能力源于对真实世界环境的语言理解。在低数据量设置下，开发口语化和可解释的表征可以显著提高模型泛化能力。

**Method:** 本文提出口语化表征学习 (VRL)，这是一种利用视觉-语言模型 (VLM) 自动提取用于目标识别的人类可解释特征的新方法。该方法通过VLM识别不同类别间的关键判别特征和同类别内的共享特性，以自然语言形式捕获类间差异和类内共性。这些口语化特征随后通过VLM映射为数值向量，可用于训练和推理下游分类器。

**Result:** 在相同模型规模下，VRL比现有最先进方法实现了24%的绝对改进，同时使用的数据量减少了95%，并且模型更小。此外，与人类标注属性相比，VRL学习到的特征在用于下游分类任务时表现出20%的绝对增益。

**Conclusion:** VRL通过生成可解释的口语化特征，在少样本目标识别任务中取得了显著的性能提升和数据效率优势，并且其学习到的特征优于人类标注属性。

> **ai_Abstract:** 本文提出口语化表征学习（VRL），一种新颖的少样本目标识别方法。VRL利用视觉-语言模型（VLM）自动提取人类可解释的自然语言特征，捕捉类间差异和类内共性，并将这些特征映射为数值向量。实验证明，VRL在数据量减少95%的情况下，比现有最佳方法性能提升24%，且其学习到的特征在下游任务中比人类标注属性高20%。

> **摘要翻译:** 人类在仅观察少量样本后就能识别物体，这种卓越的能力得益于其对真实世界环境固有的语言理解。开发口语化和可解释的表征可以显著提高模型在低数据设置下的泛化能力。在这项工作中，我们提出了口语化表征学习（VRL），这是一种利用少样本数据自动提取用于目标识别的人类可解释特征的新颖方法。我们的方法独特地通过利用视觉-语言模型（VLM）识别不同类别间的关键判别特征和同一类别内的共享特性，以自然语言形式捕获类间差异和类内共性。然后，这些口语化特征通过VLM映射到数值向量。由此产生的特征向量可以进一步用于训练和推理下游分类器。实验结果表明，在相同的模型规模下，VRL比现有最先进方法实现了24%的绝对改进，同时使用的数据量减少了95%，并且模型更小。此外，与人类标注属性相比，VRL学习到的特征在用于下游分类任务时表现出20%的绝对增益。代码可在：https://github.com/joeyy5588/VRL/tree/main 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [247] [High-fidelity 3D Gaussian Inpainting: preserving multi-view consistency and photorealistic details](https://arxiv.org/abs/2507.18023)
> *高保真3D高斯修复：保持多视角一致性和照片级真实细节*

*Jun Zhou, Dinghao Li, Nannan Li, Mingjie Wang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D Gaussian Inpainting, Multi-view Consistency, Photorealistic Details, 3D Gaussian Splatting, Scene Reconstruction

**Comment:** 

> **TL;DR:** 提出一种新的3D高斯修复框架，通过掩膜优化和不确定性引导优化，实现高保真和多视角一致的3D场景修复。

**AI_Comments:** 本文创新性地将3D高斯泼溅技术应用于3D场景修复，并引入了掩膜细化和不确定性引导优化机制，有效解决了3D修复中的核心难题，即多视角一致性和细节保真度，为高保真3D内容创建提供了新的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D场景修复面临挑战，因为3D结构不规则且难以保持多视角一致性。

**Method:** 提出一个新颖的3D高斯修复框架，通过利用稀疏修复视图重建完整的3D场景。该框架包含一个自动掩膜细化过程（通过高斯场景过滤和反向投影实现更准确的遮挡区域定位和逼真边界恢复）和一个区域不确定性引导优化（通过估计训练期间多视角图像中每个区域的重要性来缓解多视角不一致性并增强精细细节的保真度）。

**Result:** 在不同数据集上的综合实验表明，该方法在视觉质量和视角一致性方面均优于现有最先进的方法。

**Conclusion:** 该方法成功解决了3D高斯修复中的多视角一致性和细节保真度问题，实现了高质量的3D场景重建。

> **ai_Abstract:** 本文提出一个高保真3D高斯修复框架，旨在解决3D场景修复中多视角一致性和细节保真度的挑战。该框架通过自动掩膜细化过程精确识别遮挡区域并恢复边界，并采用不确定性引导的细粒度优化策略来缓解多视角不一致性并提升细节表现。实验证明，该方法在视觉质量和视角一致性上优于现有技术。

> **摘要翻译:** 近期多视角3D重建和新视角合成的进展，特别是通过神经辐射场（NeRF）和3D高斯泼溅（3DGS），极大地提升了3D内容创建的保真度和效率。然而，由于3D结构固有的不规则性以及保持多视角一致性的关键需求，修复3D场景仍然是一项具有挑战性的任务。在这项工作中，我们提出了一种新颖的3D高斯修复框架，通过利用稀疏修复视图重建完整的3D场景。我们的框架结合了自动掩膜细化过程和区域不确定性引导优化。具体来说，我们通过一系列操作，包括高斯场景过滤和反向投影，细化修复掩膜，从而实现更准确的遮挡区域定位和逼真的边界恢复。此外，我们的不确定性引导的细粒度优化策略，在训练期间估计多视角图像中每个区域的重要性，缓解了多视角不一致性并增强了修复结果中精细细节的保真度。在不同数据集上进行的综合实验表明，我们的方法在视觉质量和视角一致性方面均优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [251] [Accelerating Multimodal Large Language Models via Dynamic Visual-Token Exit and the Empirical Findings](https://arxiv.org/abs/2411.19628)
> *通过动态视觉-令牌退出加速多模态大型语言模型及其实证发现*

*Qiong Wu, Wenhao Lin, Yiyi Zhou, Weihao Ye, Zhanpeng Zen, Xiaoshuai Sun, Rongrong Ji* | **Category: cs.CV, cs.CL, cs.LG, cs.MM** | **Updated: 2025-07-25**

**Keywords:** 多模态大型语言模型, 视觉令牌冗余, 动态退出, 模型效率, 注意力行为

**Comment:** 

> **TL;DR:** 本文通过实证研究揭示多模态大语言模型中视觉令牌冗余问题，并提出动态视觉-令牌退出（DyVTE）方法，通过在特定层移除视觉令牌来提高模型效率和促进对模型行为的理解。

**AI_Comments:** 本文针对多模态大型语言模型中普遍存在的视觉令牌冗余问题，通过深入的实证分析揭示了其根本原因，并据此提出了一种创新性的动态退出机制。DyVTE方法不仅具有理论依据，而且通过在多个主流MLLMs上进行验证，展现了其在提高效率方面的显著效果。此外，该研究还为理解MLLMs的内部工作机制提供了宝贵的见解，具有重要的实践和理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态大型语言模型（MLLMs）中视觉令牌的过度使用导致明显的冗余和高昂的计算成本。

**Method:** 首先对MLLMs的注意力行为进行广泛实证研究，总结出三个推理阶段，并发现视觉令牌在文本令牌获得足够图像信息后停止贡献推理。基于此，提出动态视觉-令牌退出（DyVTE）方法，利用轻量级超网络感知文本令牌状态，并决定在特定层之后移除所有视觉令牌。

**Result:** 实验结果表明DyVTE有效提高了MLLMs的效率，并揭示了MLLMs的通用建模模式，有助于深入理解MLLMs。

**Conclusion:** 动态视觉-令牌退出（DyVTE）是一种有效的方法，可以减少多模态大型语言模型中的视觉冗余，显著提高模型效率，并为深入理解这些模型的内在工作机制提供了新的视角。

> **ai_Abstract:** 本文针对多模态大型语言模型（MLLMs）中视觉令牌冗余导致的计算效率低下问题，首先通过实证研究揭示了视觉令牌在文本令牌接收足够信息后便不再对推理贡献的现象。基于此发现，提出了一种名为动态视觉-令牌退出（DyVTE）的方法。DyVTE通过轻量级超网络判断并动态移除特定层后的视觉令牌，从而有效降低计算成本。实验结果表明，该方法显著提升了LLaVA、VILA等MLLMs的效率，并有助于揭示MLLMs的通用建模模式，加深了对模型行为的理解。

> **摘要翻译:** 现有的大型多模态语言模型（MLLMs）中视觉令牌的过度使用常常表现出明显的冗余，并带来高昂的计算成本。为了深入了解这个问题，我们首先对MLLMs的注意力行为进行了广泛的实证研究，并总结了MLLMs的三个主要推理阶段：(i) 令牌间的早期融合首先快速完成。(ii) 模态内建模随后发挥作用。(iii) 多模态推理恢复并持续到推理结束。特别是，我们发现当文本令牌接收到足够的图像信息时，视觉令牌将停止对推理的贡献，从而产生明显的视觉冗余。基于这些概括性的观察，我们提出了一种简单而有效的方法来提高MLLMs的效率，称为动态视觉-令牌退出（DyVTE）。DyVTE使用轻量级超网络来感知文本令牌的状态，并决定在特定层之后移除所有视觉令牌，从而解决观察到的视觉冗余问题。为了验证VTE，我们将其应用于一组MLLMs，包括LLaVA、VILA、Eagle和InternVL，并在大量基准测试中进行了广泛的实验。实验结果不仅显示了我们的VTE在提高MLLMs效率方面的有效性，而且揭示了MLLMs的通用建模模式，极大地促进了对MLLMs的深入理解。我们的代码已在https://github.com/DoubtedSteam/DyVTE 发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [257] [Towards Holistic Surgical Scene Graph](https://arxiv.org/abs/2507.15541)
> *迈向整体手术场景图*

*Jongmin Shin, Enki Cho, Ka Young Kim, Jung Yong Kim, Seong Tae Kim, Namkee Oh* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 手术场景图, 计算机辅助干预, 工具-动作-目标, 手部身份, Endoscapes-SG201

**Comment:** Accepted to MICCAI 2025

> **TL;DR:** 本研究提出了Endoscapes-SG201数据集和SSG-Com方法，以在手术场景图中整合工具-动作-目标组合和手部身份，从而提高对手术场景的理解。

**AI_Comments:** 本论文的创新之处在于提出了一个包含更丰富标注（工具-动作-目标组合和手部身份）的新数据集Endoscapes-SG201，并开发了相应的SSG-Com图基方法。这解决了现有手术场景图研究中对复杂交互和手部信息关注不足的局限性，对手术场景的更全面理解具有重要意义。提供代码和数据集也促进了社区的进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 先前的外科场景图研究未能充分探索工具-动作-目标组合和操作工具的手部身份等重要方面，尽管这些信息对手术场景理解至关重要。

**Method:** 本研究提出了Endoscapes-SG201数据集，其中包含工具-动作-目标组合和手部身份的标注。此外，还引入了SSG-Com，一种基于图的方法，旨在学习和表示这些关键元素。

**Result:** 通过在安全关键视图评估和动作三元组识别等下游任务上的实验，证明了整合这些基本场景图组件的重要性，突出了它们对手术场景理解的显著贡献。

**Conclusion:** 整合工具-动作-目标组合和手部身份等关键元素对于提高手术场景理解至关重要。

> **ai_Abstract:** 本研究旨在通过整合工具-动作-目标组合和手部身份等关键信息，提高手术场景图的全面性。为此，研究团队构建了Endoscapes-SG201数据集，并开发了SSG-Com图基方法来学习和表示这些元素。实验结果表明，这些新组件显著提升了手术场景理解在下游任务中的表现。

> **摘要翻译:** 手术场景理解对于计算机辅助干预系统至关重要，它需要对手术场景进行视觉理解，其中涉及手术工具、解剖结构及其相互作用等多种元素。为了有效表示手术场景中的复杂信息，基于图的方法已被探索用于结构化建模手术实体及其关系。先前的外科场景图研究已经证明了使用图表示手术场景的可行性。然而，手术场景的某些方面——例如工具-动作-目标的多种组合以及操作工具的手部身份——在基于图的表示中仍未得到充分探索，尽管它们很重要。为了将这些方面纳入图表示，我们提出了Endoscapes-SG201数据集，其中包含工具-动作-目标组合和手部身份的标注。我们还引入了SSG-Com，一种基于图的方法，旨在学习和表示这些关键元素。通过在下游任务（如安全关键视图评估和动作三元组识别）上的实验，我们证明了整合这些基本场景图组件的重要性，突出了它们对手术场景理解的显著贡献。代码和数据集可在https://github.com/ailab-kyunghee/SSG-Com获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [261] [Distilling Diffusion Models to Efficient 3D LiDAR Scene Completion](https://arxiv.org/abs/2412.03515)
> *将扩散模型蒸馏至高效3D激光雷达场景补全*

*Shengyuan Zhang, An Zhao, Ling Yang, Zejian Li, Chenye Meng, Haoran Xu, Tianrun Chen, AnYang Wei, Perry Pengyun GU, Lingyun Sun* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 3D LiDAR场景补全, 模型蒸馏, 采样效率, 结构损失

**Comment:** This paper is accept by ICCV'25(Oral), the model and code are
  publicly available on https: //github.com/happyw1nd/ScoreLiDAR

> **TL;DR:** 本文提出ScoreLiDAR，一种用于3D LiDAR场景补全的蒸馏方法，显著提高了扩散模型的采样速度和补全质量，使其适用于自动驾驶等实时应用。

**AI_Comments:** 该论文的创新点在于结合了扩散模型蒸馏和专门设计的结构损失，有效解决了扩散模型在3D LiDAR场景补全中效率低下的瓶颈，使其更适用于实时性要求高的自动驾驶等领域。其提出的结构损失对捕获3D场景的几何细节具有重要意义，提升了补全质量。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在3D LiDAR场景补全中表现出高补全质量和训练稳定性，但其缓慢的采样速度限制了在自动驾驶等需要高效环境感知的实际应用中的部署。

**Method:** 本文提出ScoreLiDAR，一种专为3D LiDAR场景补全模型设计的蒸馏方法，旨在显著减少采样步骤。为提高补全质量，引入了新型“结构损失”（Structural Loss），该损失包含一个约束整体结构的场景级项和一个约束关键地标点及其相对配置的点级项。

**Result:** 在SemanticKITTI数据集上，ScoreLiDAR将每帧补全时间从30.55秒加速至5.37秒（提升超过5倍），并且性能优于现有最先进的3D LiDAR场景补全模型。

**Conclusion:** ScoreLiDAR通过新颖的蒸馏方法和结构损失，成功解决了3D LiDAR场景补全中扩散模型的效率瓶颈，同时保持甚至提升了补全质量，使其更适合实际应用。

> **ai_Abstract:** 本文针对扩散模型在3D LiDAR场景补全中采样速度慢的问题，提出了一种名为ScoreLiDAR的新型蒸馏方法。该方法通过减少采样步骤显著提高效率，并引入结构损失以增强补全质量，该损失包含场景级和点级约束。实验证明，ScoreLiDAR在SemanticKITTI数据集上实现了超过5倍的速度提升，并取得了领先的性能。

> **摘要翻译:** 扩散模型因其强大的训练稳定性和高补全质量而被应用于3D激光雷达（LiDAR）场景补全。然而，缓慢的采样速度限制了基于扩散的场景补全模型的实际应用，因为自动驾驶汽车需要对周围环境进行高效感知。本文提出了一种新颖的蒸馏方法，专为3D激光雷达场景补全模型量身定制，名为ScoreLiDAR，它实现了高效且高质量的场景补全。ScoreLiDAR使蒸馏后的模型能够在蒸馏后以显著更少的步骤进行采样。为了提高补全质量，我们还引入了一种新颖的结构损失（Structural Loss），它鼓励蒸馏模型捕获3D激光雷达场景的几何结构。该损失包含一个约束整体结构的场景级项和一个约束关键地标点及其相对配置的点级项。广泛的实验表明，ScoreLiDAR在SemanticKITTI数据集上将每帧补全时间从30.55秒显著加速到5.37秒（>5倍），并实现了优于最先进的3D激光雷达场景补全模型的性能。我们的模型和代码已在https://github.com/happyw1nd/ScoreLiDAR上公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [268] [3D Test-time Adaptation via Graph Spectral Driven Point Shift](https://arxiv.org/abs/2507.18225)
> *基于图谱驱动点位移的3D测试时间适应*

*Xin Wei, Qin Yang, Yijie Fang, Mingrui Zhu, Nannan Wang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D点云, 测试时间适应, 图谱域, 领域适应, 图傅里叶变换

**Comment:** 

> **TL;DR:** 本文提出GSDTTA，一种新颖的3D点云测试时间适应方法，通过将适应过程转移到图谱域，优化低频分量，实现高效且性能优越的领域适应。

**AI_Comments:** 这项研究的创新之处在于将3D点云的测试时间适应从传统的空间域转移到图谱域。通过利用图傅里叶变换和仅优化低频分量，该方法显著提高了适应效率，并能有效捕获点云的全局结构特性，同时减少了参数量。这为3D点云处理中的领域适应提供了一个新的视角和高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的测试时间适应（TTA）方法在处理3D点云时面临挑战，因为点云结构不规则且无序。当前的3D TTA方法计算成本高昂，且可能需要额外的训练数据。

**Method:** 我们提出了图谱域测试时间适应（GSDTTA）方法。该方法将目标域点云表示为离群点感知图，并通过图傅里叶变换（GFT）将其转换到图谱域。为提高效率，适应过程仅优化最低的10%频率分量，这些分量捕获了点云的大部分能量。随后，应用逆GFT（IGFT）重建适应后的点云，实现图谱驱动的点位移。此外，该过程通过一种特征图引导的自训练策略进行增强，该策略迭代地优化谱调整和模型参数。

**Result:** 实验结果和消融研究表明，GSDTTA在基准数据集上表现出有效性，优于现有的3D点云分类TTA方法。

**Conclusion:** GSDTTA通过将3D点云的测试时间适应转移到图谱域，提供了一种高效且高性能的解决方案，有效克服了传统方法在处理不规则点云结构和计算成本上的限制。

> **ai_Abstract:** 本文提出了一种新颖的3D点云测试时间适应（TTA）方法——图谱域测试时间适应（GSDTTA），旨在解决现有3D TTA方法在处理不规则点云结构时计算成本高昂的问题。GSDTTA通过将点云表示为离群点感知图并利用图傅里叶变换将其转换到图谱域，仅优化低频分量进行高效适应。随后，通过逆傅里叶变换和特征图引导的自训练策略重建并优化点云。实验证明，GSDTTA在3D点云分类任务中优于现有TTA方法。

> **摘要翻译:** 虽然测试时间适应（TTA）方法通过在在线推理期间将预训练模型动态适应到目标域数据来有效解决领域偏移问题，但它们在3D点云中的应用受到其不规则和无序结构的阻碍。当前的3D TTA方法通常依赖于计算成本高昂的空间域优化，并且可能需要额外的训练数据。与此相反，我们提出了图谱域测试时间适应（GSDTTA），这是一种新颖的3D点云分类方法，它将适应过程转移到图谱域，通过捕获全局结构特性并使用更少的参数来实现更高效的适应。目标域中的点云被表示为离群点感知图，并通过图傅里叶变换（GFT）转换到图谱域。为了提高效率，适应过程仅通过优化最低的10%频率分量来执行，这些分量捕获了点云的大部分能量。然后应用逆GFT（IGFT）以图谱驱动点位移的方式重建适应后的点云。这个过程通过一种特征图引导的自训练策略得到增强，该策略迭代地细化谱调整和模型参数。在基准数据集上的实验结果和消融研究证明了GSDTTA的有效性，其性能优于现有的3D点云分类TTA方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [272] [MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI Agents](https://arxiv.org/abs/2507.19478)
> *MMBench-GUI：分层多平台GUI代理评估框架*

*Xuehui Wang, Zhenyu Wu, JingJing Xie, Zichen Ding, Bowen Yang, Zehao Li, Zhaoyang Liu, Qingyun Li, Xuan Dong, Zhe Chen, Weiyun Wang, Xiangyu Zhao, Jixuan Chen, Haodong Duan, Tianbao Xie, Chenyu Yang, Shiqian Su, Yue Yu, Yuan Huang, Yiqian Liu, Xiao Zhang, Yanting Zhang, Xiangyu Yue, Weijie Su, Xizhou Zhu, Wei Shen, Jifeng Dai, Wenhai Wang* | **Category: cs.CV, cs.CL** | **Updated: 2025-07-25**

**Keywords:** GUI自动化, 多平台评估, 基准测试, 效率指标, 视觉定位

**Comment:** in progress

> **TL;DR:** 论文引入了MMBench-GUI，这是一个用于评估GUI自动化代理的分层多平台基准测试框架，并提出了EQA指标。研究发现视觉定位对任务成功至关重要，且现有模型在效率方面存在显著不足，需要精确本地化、有效规划和提前停止策略。

**AI_Comments:** 该论文通过引入MMBench-GUI，首次提供了一个全面的、分层的多平台GUI代理评估框架，填补了现有评估体系的空白。其提出的EQA指标关注了以往研究中被忽视的任务效率维度。研究结果揭示了视觉定位、任务规划以及效率优化是当前GUI代理面临的关键挑战，并为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有GUI自动化代理的评估缺乏一个全面的、跨平台且关注效率的框架，导致难以全面衡量和提升代理性能。

**Method:** 本文引入了MMBench-GUI，一个分层多平台评估基准，涵盖GUI内容理解、元素定位、任务自动化和任务协作四个层面。同时，提出了一种新颖的效率-质量区域（EQA）指标，用于评估在线自动化场景下GUI代理的执行效率。

**Result:** 通过MMBench-GUI，研究发现准确的视觉定位是整体任务成功的关键决定因素，并且集成专业定位模块的模块化框架具有显著优势。此外，可靠的GUI自动化需要强大的任务规划和跨平台泛化能力，长上下文记忆、广阔的动作空间和长期推理至关重要。所有模型在任务效率方面都存在显著不足，即使任务完成也存在过多的冗余步骤。

**Conclusion:** 为了实现真正高效和可扩展的GUI自动化，精确的本地化、有效的规划和提前停止策略的整合是不可或缺的。

> **ai_Abstract:** MMBench-GUI是一个分层多平台基准测试框架，用于评估跨Windows、macOS、Linux、iOS、Android和Web平台的GUI自动化代理。它包含GUI内容理解、元素定位、任务自动化和任务协作四个评估层级，并引入了效率-质量区域（EQA）指标。通过该框架，研究强调了准确视觉定位对任务成功的关键作用，并指出现有GUI代理在任务效率上存在显著不足。论文最终提出，集成精确本地化、有效规划和提前停止策略对于实现高效和可扩展的GUI自动化至关重要。

> **摘要翻译:** 我们引入了MMBench-GUI，这是一个用于评估跨Windows、macOS、Linux、iOS、Android和Web平台GUI自动化代理的分层基准测试框架。它包含GUI内容理解、元素定位、任务自动化和任务协作四个层级，涵盖了GUI代理的基本技能。此外，我们提出了一种新颖的效率-质量区域（EQA）指标，用于评估在线自动化场景下GUI代理的执行效率。通过MMBench-GUI，我们识别出准确的视觉定位是整体任务成功的关键决定因素，并强调了集成专业定位模块的模块化框架的显著优势。此外，为了实现可靠的GUI自动化，代理需要强大的任务规划和跨平台泛化能力，其中长上下文记忆、广阔的动作空间和长期推理发挥着关键作用。更重要的是，任务效率仍然是一个严重未被充分探索的维度，所有模型都存在显著的低效率，即使任务最终完成也存在过多的冗余步骤。精确本地化、有效规划和提前停止策略的整合对于实现真正高效和可扩展的GUI自动化是不可或缺的。我们的基准测试代码、评估数据和运行环境将在https://github.com/open-compass/MMBench-GUI上公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [273] [LPTR-AFLNet: Lightweight Integrated Chinese License Plate Rectification and Recognition Network](https://arxiv.org/abs/2507.16362)
> *LPTR-AFLNet: 轻量级集成中文车牌校正与识别网络*

*Guangzhu Xu, Pengcheng Zuo, Zhi Ke, Bangjun Lei* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 中文车牌识别, 透视校正, 轻量级网络, 端到端, 实时

**Comment:** 28 pages, 33 figures

> **TL;DR:** LPTR-AFLNet是一个轻量级的端到端网络，用于校正和识别中文车牌，解决了复杂环境下的透视畸变和资源限制问题，实现了高精度和实时性能。

**AI_Comments:** LPTR-AFLNet 的创新之处在于其将车牌校正和识别集成到一个轻量级端到端网络中，特别强调了在边缘设备上的实时部署能力。利用识别输出作为弱监督信号来指导校正过程是一个巧妙的设计，它使得整个系统更加自洽和高效。此外，针对 LPRNet 的改进，如引入注意力机制和 Focal Loss，有效提升了在复杂场景下的识别精度。该研究解决了中文车牌识别中的实际挑战，并在计算效率方面取得了显著进展，具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 中文车牌识别 (CLPR) 在非受限和复杂环境下，特别是由于不同拍摄角度引起的透视畸变以及单行和双行车牌的校正问题，面临诸多挑战。考虑到边缘设备有限的计算资源，开发一个低复杂度的、端到端的集成校正和识别网络对于实现实时高效部署至关重要。

**Method:** 本文提出了一种名为 LPTR-AFLNet 的轻量级统一网络，用于中文车牌的校正和识别。该网络将透视变换校正模块 (PTR) 与优化的车牌识别网络 AFLNet 相结合。网络利用识别输出作为弱监督信号来有效指导校正过程，确保准确的透视畸变校正。为了提高识别精度，LPTR-AFLNet 对 LPRNet 进行了改进，包括引入改进的注意力模块以减少相似字符之间的混淆，并使用 Focal Loss 来解决训练期间的类别不平衡问题。

**Result:** 实验结果表明，LPTR-AFLNet 在校正透视畸变和识别双行车牌图像方面表现出色，在各种具有挑战性的场景中保持了高识别精度。此外，在中低端 GPU 平台上，该方法运行时间少于 10 毫秒。

**Conclusion:** LPTR-AFLNet 在中文车牌的校正和识别方面展现了卓越的性能和高效率，证明了其在实际应用中的实用性和广泛适用性。

> **ai_Abstract:** LPTR-AFLNet 是一种轻量级、端到端集成网络，旨在解决复杂环境下中文车牌识别中的透视畸变和资源限制问题。它结合了透视变换校正模块 (PTR) 和优化的 AFLNet 识别网络，利用识别输出作为弱监督信号指导校正。为提高识别准确性，该网络改进了 LPRNet，包括引入注意力模块和使用 Focal Loss。实验证明，LPTR-AFLNet 在校正和识别双行车牌方面表现卓越，保持高精度，并在中低端 GPU 上实现了小于 10 毫秒的实时推理速度，展现了其高效性和实用性。

> **摘要翻译:** 中文车牌识别 (CLPR) 在非受限和复杂环境下，特别由于各种拍摄角度引起的透视畸变以及单行和双行车牌的校正问题，面临诸多挑战。考虑到边缘设备有限的计算资源，开发一个低复杂度的、端到端的集成校正和识别网络对于实现实时高效部署至关重要。在这项工作中，我们提出了一个名为 LPTR-AFLNet 的轻量级统一网络，用于校正和识别中文车牌，它将透视变换校正模块 (PTR) 与优化的车牌识别网络 AFLNet 相结合。该网络利用识别输出作为弱监督信号，有效指导校正过程，确保准确的透视畸变校正。为了提高识别精度，我们对 LPRNet 引入了几项改进，包括改进的注意力模块以减少相似字符之间的混淆，以及使用 Focal Loss 来解决训练期间的类别不平衡问题。实验结果表明，LPTR-AFLNet 在校正透视畸变和识别双行车牌图像方面表现出色，在各种具有挑战性的场景中保持了高识别精度。此外，在中低端 GPU 平台上，该方法运行时间少于 10 毫秒，表明其具有实际效率和广泛适用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [278] [Facial Demorphing from a Single Morph Using a Latent Conditional GAN](https://arxiv.org/abs/2507.18566)
> *基于潜在条件GAN的单变形人脸去变形*

*Nitish Shukla, Arun Ross* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 人脸去变形, 潜在条件GAN, 人脸变形, 生物识别安全, 图像恢复

**Comment:** 

> **TL;DR:** 一种新的基于潜在条件GAN的方法能够从单个变形图像中恢复原始人脸，克服了现有方法的局限性，并对未见的变形技术表现出更好的性能。

**AI_Comments:** 该论文的创新之处在于利用潜在条件GAN在潜在空间进行去变形，从而有效解决了现有方法中“变形复制”问题以及对特定变形技术依赖的局限性。通过在合成数据上训练并在真实数据上测试，展示了其在实际应用中的鲁棒性和泛化能力，对生物识别安全领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人脸变形图像能够与多个个体生物识别关联，对生物识别系统构成威胁。现有的人脸变形检测（MAD）方法无法揭示组成图像，而人脸去变形（Demorphing）过程至关重要。然而，现有的人脸去变形方法存在变形复制问题（输出与变形图像过于相似），或者假设训练和测试变形图像由相同的变形技术生成。

**Method:** 所提出的方法通过在潜在空间中分解变形图像来克服现有问题，使其能够对由未见的变形技术和人脸风格创建的图像进行去变形。该方法在一个潜在条件GAN框架下实现，并在由合成人脸创建的变形图像上进行训练，然后使用由任意变形技术从真实人脸创建的变形图像进行测试。

**Result:** 该方法在性能上显著优于现有方法，并生成了高保真度的去变形人脸图像。

**Conclusion:** 该研究提出了一种新的基于潜在条件GAN的人脸去变形方法，有效解决了现有方法中存在的变形复制问题和对已知变形技术的依赖性，显著提高了去变形的性能和图像质量。

> **ai_Abstract:** 该论文提出了一种利用潜在条件生成对抗网络（GAN）从单个变形人脸图像中恢复原始组成人脸的方法。针对现有去变形方法存在的输出与变形图像相似（变形复制问题）以及对已知变形技术依赖的问题，该方法通过在潜在空间中分解变形图像来解决。研究在合成人脸变形图像上训练模型，并在真实人脸变形图像上进行测试，结果表明该方法显著优于现有技术，能够生成高保真度的去变形图像，并有效处理未见的变形技术和人脸风格。

> **摘要翻译:** 变形图像是通过结合两个（或更多）身份的两个（或更多）人脸图像创建的复合图像，该图像与两个（或更多）组成身份高度相似，从而使伪造的变形图像能够与多个个体进行生物识别关联。变形攻击检测（MAD）可用于检测变形图像，但无法揭示组成图像。因此，去变形——推断组成图像的过程——对于提供关于变形图像的额外证据至关重要。现有的去变形方法存在变形复制问题，即输出往往与变形图像本身非常相似，或者假设训练和测试变形图像是使用相同的变形技术生成的。所提出的方法克服了这些问题。该方法在潜在空间中分解变形图像，使其能够对由未见的变形技术和人脸风格创建的图像进行去变形。我们在由合成人脸创建的变形图像上训练我们的方法，并在使用任意变形技术从真实人脸创建的变形图像上进行测试。我们的方法在性能上显著优于现有方法，并生成了高保真度的去变形人脸图像。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [291] [DCFFSNet: Deep Connectivity Feature Fusion Separation Network for Medical Image Segmentation](https://arxiv.org/abs/2507.18407)
> *DCFFSNet：用于医学图像分割的深度连通性特征融合分离网络*

*Xun Ye, Ruixiang Tang, Mingda Zhang, Jianglong Qin* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 医学图像分割, 深度学习, 连通性, 特征融合, 解耦

**Comment:** 16 pages , 11 figures

> **TL;DR:** DCFFSNet提出了一种创新的特征空间解耦策略和深度连通性特征融合分离架构，用于医学图像分割。它解决了现有方法中特征空间耦合和特征强度量化不足的问题，并在多个数据集上取得了最先进的性能，有效解决了分割碎片化并实现了平滑的边缘过渡。

**AI_Comments:** 该论文的创新点在于提出了特征空间解耦策略，解决了现有方法中连通性特征与一般特征的耦合问题，并能量化不同特征的强度，这对于精确的医学图像分割至关重要。其引入的深度连通性特征融合分离架构，能够动态平衡多尺度特征，进一步提升了分割效果，尤其在解决分割碎片化和实现平滑边缘过渡方面表现出色，对临床应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度网络在医学图像分割中整合连通性时，通常将其强制注入为额外的特征模块，导致特征空间耦合，并且缺乏量化不同特征强度的标准化机制，从而影响边缘精度和区域一致性。

**Method:** 本文提出了DCFFSNet（深度连通性特征融合分离网络），引入了一种创新的特征空间解耦策略，用于量化连通性特征与其他特征之间的相对强度。该网络构建了一个深度连通性特征融合分离架构，以动态平衡多尺度特征表达。

**Result:** 在ISIC2018数据集上，DCFFSNet在Dice和IoU指标上分别比次优模型CMUNet高出1.3%和1.2%。在DSB2018数据集上，它比TransUNet高出0.7%（Dice）和0.9%（IoU）。在MoNuSeg数据集上，它比CSCAUNet高出0.8%（Dice）和0.9%（IoU）。结果表明DCFFSNet在所有指标上均优于现有主流方法。

**Conclusion:** DCFFSNet超越了现有主流方法，有效解决了分割碎片化问题，实现了平滑的边缘过渡，并显著增强了临床可用性。

> **ai_Abstract:** DCFFSNet是一种新型的深度学习网络，专为医学图像分割设计，旨在解决现有方法中连通性特征与其它特征耦合以及特征强度难以量化的问题。该网络通过引入创新的特征空间解耦策略和深度连通性特征融合分离架构，能够动态平衡多尺度特征表达。在ISIC2018、DSB2018和MoNuSeg等多个医学图像分割数据集上的实验结果表明，DCFFSNet在各项性能指标上均优于现有主流方法，有效避免了分割碎片化并实现了平滑的边缘过渡，显著提升了临床应用价值。

> **摘要翻译:** 医学图像分割利用拓扑连通性理论来提高边缘精度和区域一致性。然而，现有整合连通性的深度网络通常将其强制注入为额外的特征模块，导致特征空间耦合，并且缺乏量化不同特征强度的标准化机制。为了解决这些问题，我们提出了DCFFSNet（深度连通性特征融合分离网络）。它引入了一种创新的特征空间解耦策略。该策略量化了连通性特征与其他特征之间的相对强度。然后，它构建了一个深度连通性特征融合分离架构。该架构动态平衡多尺度特征表达。实验在ISIC2018、DSB2018和MoNuSeg数据集上进行。在ISIC2018上，DCFFSNet在Dice和IoU指标上分别比次优模型（CMUNet）高出1.3%和1.2%。在DSB2018上，它比TransUNet高出0.7%（Dice）和0.9%（IoU）。在MoNuSeg上，它比CSCAUNet高出0.8%（Dice）和0.9%（IoU）。结果表明DCFFSNet在所有指标上均优于现有主流方法。它有效解决了分割碎片化问题，实现了平滑的边缘过渡。这显著增强了临床可用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [294] [Faithful, Interpretable Chest X-ray Diagnosis with Anti-Aliased B-cos Networks](https://arxiv.org/abs/2507.16761)
> *使用抗锯齿 B-cos 网络进行忠实、可解释的胸部 X 射线诊断*

*Marcel Kleinmann, Shashank Agnihotri, Margret Keuper* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** B-cos 网络, 胸部 X 射线, 可解释性, 抗锯齿, 医疗诊断

**Comment:** 

> **TL;DR:** 本文引入了抗锯齿策略（FLCPooling 和 BlurPool）来改进 B-cos 网络的解释图质量，使其在保持诊断性能的同时，提供忠实且无伪影的胸部 X 射线诊断解释，适用于临床应用。

**AI_Comments:** 该论文的创新点在于解决了 B-cos 网络在医疗图像解释中存在的关键问题——解释图的锯齿伪影，这对于其在安全关键领域的实际应用至关重要。通过引入简单的抗锯齿策略，显著提升了模型的可解释性，同时保持了诊断性能，这对于推动可解释 AI 在医疗领域的落地具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在医疗成像等安全关键领域部署深度神经网络 (DNN) 需要忠实性和可解释性。B-cos 网络虽然能提供可解释的、类特异性解释，但其解释图存在严重的锯齿伪影，使其不适合临床使用。

**Method:** 通过引入抗锯齿策略，具体是使用 FLCPooling (FLC) 和 BlurPool (BP) 来显著改善解释质量。

**Result:** 在胸部 X 射线数据集上的实验表明，修改后的 $\text{B-cos}_\text{FLC}$ 和 $\text{B-cos}_\text{BP}$ 在保持强大预测性能的同时，提供了忠实且无伪影的解释，适用于多类别和多标签设置下的临床应用。

**Conclusion:** 通过引入抗锯齿策略，B-cos 网络能够为胸部 X 射线诊断提供忠实、无伪影且适用于临床应用的解释，同时保持了强大的预测性能。

> **ai_Abstract:** 本研究旨在解决 B-cos 网络在医疗图像诊断中解释图存在的锯齿伪影问题，以提高其临床适用性。通过引入 FLCPooling 和 BlurPool 等抗锯齿策略，作者改进了 B-cos 网络，使其能够在保持与现有先进 DNN 相当的诊断性能的同时，生成忠实且无伪影的类特异性解释。实验结果表明，改进后的 $\text{B-cos}_\text{FLC}$ 和 $\text{B-cos}_\text{BP}$ 模型在胸部 X 射线数据集上表现出色，为多类别和多标签设置提供了可靠的临床诊断解释。

> **摘要翻译:** 忠实性和可解释性对于在医疗成像等安全关键领域部署深度神经网络 (DNN) 至关重要。B-cos 网络通过用权重-输入对齐机制取代标准线性层，提供了一种有前景的解决方案，无需后验方法即可生成固有的可解释的、类特异性解释。尽管在诊断性能上与最先进的 DNN 保持竞争力，但标准 B-cos 模型在其解释图中存在严重的锯齿伪影，使其不适合对清晰度要求极高的临床使用。在这项工作中，我们通过引入使用 FLCPooling (FLC) 和 BlurPool (BP) 的抗锯齿策略来解决这些限制，以显著提高解释质量。我们在胸部 X 射线数据集上的实验表明，修改后的 $\text{B-cos}_\text{FLC}$ 和 $\text{B-cos}_\text{BP}$ 在保持强大预测性能的同时，提供了忠实且无伪影的解释，适用于多类别和多标签设置下的临床应用。代码可在 GitHub 仓库获取 (url: https://github.com/mkleinma/B-cos-medical-paper)。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [307] [DEFAME: Dynamic Evidence-based FAct-checking with Multimodal Experts](https://arxiv.org/abs/2412.10510)
> *DEFAME: 基于动态证据的多模态专家事实核查*

*Tobias Braun, Mark Rothermel, Marcus Rohrbach, Anna Rohrbach* | **Category: cs.CV, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 事实核查, 多模态, 证据, 零样本, MLLM

**Comment:** ICML 2025 version. 9 pages main paper, 35 pages with appendix, 18
  figures and 7 tables. Corrected two inconsistent numbers in Table 2

> **TL;DR:** DEFAME是一个模块化、零样本的多模态大语言模型（MLLM）管道，用于开放域文本-图像声明验证，通过动态选择工具和搜索深度来提取和评估文本和视觉证据，并在多个基准测试中超越现有方法，建立了新的技术水平。

**AI_Comments:** DEFAME的创新之处在于其模块化、零样本的多模态大语言模型（MLLM）管道设计，能够动态选择工具和搜索深度，并整合文本和视觉证据进行端到端的事实核查。它不仅解决了现有方法纯文本、缺乏可解释性或依赖参数知识的局限性，还在多个基准测试中取得了SOTA（State-of-the-Art）表现。引入ClaimReview2024+新基准，并在此基准上显著优于GPT-4o，进一步证明了其在避免数据泄露和处理实时信息方面的强大能力，对未来实时事实核查具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 虚假信息的泛滥对可靠和可扩展的事实核查解决方案提出了需求。

**Method:** 本文提出了DEFAME（基于动态证据的多模态专家事实核查），这是一个模块化、零样本的MLLM管道，用于开放域的文本-图像声明验证。DEFAME采用六阶段过程，动态选择工具和搜索深度来提取和评估文本和视觉证据。与以往的纯文本、缺乏可解释性或仅依赖参数知识的方法不同，DEFAME执行端到端验证，考虑声明和证据中的图像，并生成结构化的多模态报告。

**Result:** DEFAME在流行的VERITE、AVerITeC和MOCHEG基准测试中超越了所有先前的方法，确立了其作为单模态和多模态事实核查领域新技术水平的地位。此外，本文引入了一个新的多模态基准测试ClaimReview2024+，其中包含GPT-4o知识截止日期之后的声明，避免了数据泄露。在此基准上，DEFAME显著优于GPT-4o基线，显示出时间泛化能力和实时事实核查的潜力。

**Conclusion:** DEFAME在多模态事实核查方面表现出色，具有强大的时间泛化能力，并有望实现实时事实核查。

> **ai_Abstract:** DEFAME是一个创新的多模态事实核查系统，旨在应对虚假信息泛滥的问题。它采用模块化、零样本的MLLM管道，通过动态选择工具和搜索深度，对文本和图像声明进行端到端验证，并生成结构化的多模态报告。DEFAME在多个现有基准测试中超越了现有方法，成为新的技术水平。此外，论文还引入了一个新的多模态基准测试ClaimReview2024+，在此基准上DEFAME显著优于GPT-4o，展示了其强大的时间泛化能力和实时事实核查的潜力。

> **摘要翻译:** 虚假信息的泛滥对可靠和可扩展的事实核查解决方案提出了需求。我们提出了DEFAME（基于动态证据的多模态专家事实核查），这是一个模块化、零样本的多模态大语言模型（MLLM）管道，用于开放域的文本-图像声明验证。DEFAME采用六阶段过程，动态选择工具和搜索深度来提取和评估文本和视觉证据。与以往的纯文本、缺乏可解释性或仅依赖参数知识的方法不同，DEFAME执行端到端验证，考虑声明和证据中的图像，并生成结构化的多模态报告。在流行的VERITE、AVerITeC和MOCHEG基准测试上的评估表明，DEFAME超越了所有先前的方法，确立了其作为单模态和多模态事实核查领域新技术水平的地位。此外，我们引入了一个新的多模态基准测试ClaimReview2024+，其中包含GPT-4o知识截止日期之后的声明，避免了数据泄露。在此基准上，DEFAME显著优于GPT-4o基线，显示出时间泛化能力和实时事实核查的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [310] [Emotion Recognition from Skeleton Data: A Comprehensive Survey](https://arxiv.org/abs/2507.18026)
> *基于骨骼数据的情绪识别：一项全面综述*

*Haifeng Lu, Jiuyi Chen, Zhen Zhang, Ruida Liu, Runhao Zeng, Xiping Hu* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 情绪识别, 骨骼数据, 身体运动, 综述

**Comment:** 34 pages, 5 figures, 13 tables

> **TL;DR:** 本综述全面回顾了基于骨骼数据的情绪识别技术，涵盖心理模型、数据集、现有方法分类（姿态和步态），提出统一的技术分类法（Traditional, Feat2Net, FeatFusionNet, End2EndNet），并探讨了应用、挑战和未来方向。

**AI_Comments:** 这是一篇非常及时和全面的综述，对于快速发展的基于骨骼的情绪识别领域具有重要意义。它不仅系统地梳理了现有技术，还提出了创新的统一分类法，有助于研究人员理解该领域的全貌。此外，对应用前景和开放挑战的讨论也为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 通过身体动作进行情绪识别作为一种保护隐私的替代方法，正在取代依赖面部表情或生理信号的传统方法。3D骨骼获取技术和姿态估计算法的最新进展显著增强了基于全身运动进行情绪识别的可行性。

**Method:** 本综述对基于骨骼的情绪识别技术进行了全面系统的回顾。首先，介绍了情绪的心理模型以及身体运动与情绪表达之间的关系。其次，总结了公开数据集，强调了数据采集方法和情绪标注策略的差异。然后，将现有方法分为基于姿态和基于步态的方法，并从数据驱动和技术角度进行分析。特别地，提出了一种统一的分类法，包括四种主要技术范式：传统方法、Feat2Net、FeatFusionNet和End2EndNet。对每个类别中的代表性工作进行了回顾和比较，并提供了常用数据集上的基准测试结果。

**Result:** 本综述总结了公开可用的数据集，将现有方法分为基于姿态和基于步态的方法，并提出了一种涵盖四种主要技术范式的统一分类法。对每个类别中的代表性工作进行了回顾和比较，并提供了常用数据集上的基准测试结果。

**Conclusion:** 本综述探讨了情绪识别在心理健康评估（如检测抑郁症和自闭症）中的扩展应用，并讨论了该快速发展领域中存在的开放挑战和未来的研究方向。

> **ai_Abstract:** 本篇综述全面回顾了基于骨骼数据的情绪识别技术。文章首先介绍了情绪的心理学模型及其与身体运动的关系，随后总结了现有数据集的特点。接着，论文将现有方法分为姿态基和步态基两类，并提出了一种统一的技术分类法，包括传统方法、Feat2Net、FeatFusionNet和End2EndNet，对各类别代表性工作进行了比较。最后，探讨了情绪识别在心理健康领域的应用前景，并指出了未来的研究挑战与方向。

> **摘要翻译:** 通过身体动作进行情绪识别已成为一种引人注目且保护隐私的替代方案，有别于依赖面部表情或生理信号的传统方法。3D骨骼获取技术和姿态估计算法的最新进展显著增强了基于全身运动进行情绪识别的可行性。本综述对基于骨骼的情绪识别技术进行了全面系统的回顾。首先，我们介绍了情绪的心理模型，并研究了身体运动与情绪表达之间的关系。其次，我们总结了公开可用的数据集，强调了数据采集方法和情绪标注策略的差异。然后，我们将现有方法分为基于姿态和基于步态的方法，并从数据驱动和技术角度对其进行分析。特别是，我们提出了一种统一的分类法，涵盖四种主要技术范式：传统方法、Feat2Net、FeatFusionNet和End2EndNet。对每个类别中的代表性工作进行了回顾和比较，并提供了常用数据集上的基准测试结果。最后，我们探讨了情绪识别在心理健康评估中的扩展应用，例如检测抑郁症和自闭症，并讨论了该快速发展领域中存在的开放挑战和未来的研究方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [311] [DATA: Domain-And-Time Alignment for High-Quality Feature Fusion in Collaborative Perception](https://arxiv.org/abs/2507.18237)
> *DATA：协同感知中高质量特征融合的域与时间对齐*

*Chengchang Tian, Jianwei Ma, Yan Huang, Zhanye Chen, Honghao Wei, Hui Zhang, Wei Hong* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 协同感知, 特征融合, 域对齐, 时间对齐, 深度学习

**Comment:** ICCV 2025, accepted as poster. 22 pages including supplementary
  materials

> **TL;DR:** 本文提出了DATA网络，用于在协同感知中对齐特征以实现高质量融合，解决了域间隙和时间未对齐问题，实现了最先进的性能。

**AI_Comments:** 本文的创新之处在于系统地解决了协同感知中特征融合所面临的域间隙和时间未对齐两大关键挑战。通过引入CDAM和PTAM等特定模块，该方法能够有效地提升特征质量，这对于实际部署至关重要。其在严重通信延迟和姿态误差下的鲁棒性，是其在真实世界应用中显著的优势。

<details>
  <summary>Details</summary>

**Motivation:** 特征级融合在协同感知（CP）中显示出潜力，但在性能和通信带宽之间取得了平衡。然而，其有效性严重依赖于输入特征质量。高质量特征的获取面临硬件多样性和部署条件带来的域间隙，以及传输延迟带来的时间未对齐。这些挑战在整个协同网络中通过累积效应降低了特征质量。

**Method:** 本文提出了域与时间对齐（DATA）网络，旨在系统地对齐特征，同时最大化其语义表示以进行融合。具体来说，提出了一个保持一致性的域对齐模块（CDAM），通过近邻区域分层下采样和可观测性约束判别器来减少域间隙。进一步提出了一个渐进式时间对齐模块（PTAM），通过多尺度运动建模和两阶段补偿来处理传输延迟。在对齐特征的基础上，开发了一个以实例为中心的特征聚合模块（IFAM）来增强语义表示。

**Result:** 广泛的实验表明，DATA在三个典型数据集上实现了最先进的性能，并在严重的通信延迟和姿态误差下保持了鲁棒性。

**Conclusion:** DATA网络通过系统地解决域间隙和时间未对齐问题，有效提高了协同感知中特征融合的质量和鲁棒性，从而实现了卓越的性能。

> **ai_Abstract:** 本文提出了DATA网络，用于在协同感知中实现高质量的特征融合。该网络通过一致性保持域对齐模块（CDAM）解决硬件多样性和部署条件引起的域间隙，并通过渐进式时间对齐模块（PTAM）处理传输延迟引起的时间未对齐。此外，一个以实例为中心的特征聚合模块（IFAM）被用于增强语义表示。实验证明，DATA在多个数据集上达到了最先进的性能，并对通信延迟和姿态误差表现出强大的鲁棒性。

> **摘要翻译:** 特征级融合通过平衡性能和通信带宽的权衡，在协同感知（CP）中显示出潜力。然而，其有效性关键在于输入特征的质量。高质量特征的获取面临硬件多样性和部署条件带来的域间隙，以及传输延迟带来的时间未对齐。这些挑战在整个协同网络中通过累积效应降低了特征质量。在本文中，我们提出了域与时间对齐（DATA）网络，旨在系统地对齐特征，同时最大化其语义表示以进行融合。具体来说，我们提出了一个保持一致性的域对齐模块（CDAM），通过近邻区域分层下采样和可观测性约束判别器来减少域间隙。我们进一步提出了一个渐进式时间对齐模块（PTAM），通过多尺度运动建模和两阶段补偿来处理传输延迟。在对齐特征的基础上，开发了一个以实例为中心的特征聚合模块（IFAM）来增强语义表示。广泛的实验表明，DATA在三个典型数据集上实现了最先进的性能，并在严重的通信延迟和姿态误差下保持了鲁棒性。代码将在https://github.com/ChengchangTian/DATA发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [314] [PolarAnything: Diffusion-based Polarimetric Image Synthesis](https://arxiv.org/abs/2507.17268)
> *PolarAnything：基于扩散的偏振图像合成*

*Kailong Zhang, Youwei Lyu, Heng Guo, Si Li, Zhanyu Ma, Boxin Shi* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 偏振图像合成, 扩散模型, RGB到偏振, 物理渲染, 零样本学习

**Comment:** 11 pages

> **TL;DR:** 提出PolarAnything，一个基于扩散模型的框架，能够从单张RGB图像合成真实且物理精确的偏振图像，无需3D资产，解决了偏振相机可及性有限的问题。

**AI_Comments:** PolarAnything的创新点在于它利用了扩散模型的强大生成能力和零样本性能，实现了从单张RGB图像合成高保真度偏振图像，而无需复杂的3D资产。这大大降低了偏振图像获取的门槛，对于图像增强和3D重建等领域具有重要意义。其物理精确性和对下游任务的支持也增强了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 偏振图像有助于图像增强和3D重建，但偏振相机的可及性有限，阻碍了其广泛应用。现有模拟器（如Mitsuba）依赖于参数模型和大量3D资产，难以生成大规模真实感图像。

**Method:** 提出PolarAnything，一个基于扩散的生成框架，能够从单张RGB输入合成具有真实感和物理精度的偏振图像。该方法消除了对3D资产集合的依赖，并引入了一种有效的表示策略来保留偏振特性，灵感来源于预训练扩散模型的零样本性能。

**Result:** 我们的模型能够生成高质量的偏振图像，并支持偏振形状恢复等下游任务。

**Conclusion:** PolarAnything成功地从单张RGB图像合成了真实且物理精确的偏振图像，克服了现有方法的局限性，并有望促进偏振图像在更广泛应用中的使用。

> **ai_Abstract:** 本文提出了PolarAnything，一个创新的基于扩散的生成框架，旨在解决偏振相机可及性有限的问题。该模型能够仅从一张RGB图像合成高质量、真实且物理精确的偏振图像，显著优于现有方法对大量3D资产的依赖。通过引入一种有效的表示策略来保持偏振特性，PolarAnything支持如偏振形状恢复等下游任务，有望推动偏振图像在更广阔领域的应用。

> **摘要翻译:** 偏振图像有助于图像增强和3D重建任务，但偏振相机有限的可及性阻碍了其更广泛的应用。这一差距推动了合成逼真偏振图像的需求。现有的偏振模拟器Mitsuba依赖于参数化的偏振图像形成模型，并且需要覆盖形状和PBR材料的广泛3D资产，这使其无法生成大规模的逼真图像。为了解决这个问题，我们提出了PolarAnything，它能够从单张RGB输入合成兼具逼真度和物理精度的偏振图像，从而消除了对3D资产集合的依赖。借鉴预训练扩散模型的零样本性能，我们引入了一个基于扩散的生成框架，并采用了一种有效的表示策略，以保持偏振特性的保真度。实验表明，我们的模型生成了高质量的偏振图像，并支持偏振形状恢复等下游任务。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [321] [Adversarial Distribution Matching for Diffusion Distillation Towards Efficient Image and Video Synthesis](https://arxiv.org/abs/2507.18569)
> *对抗性分布匹配用于扩散蒸馏以实现高效图像和视频合成*

*Yanzuo Lu, Yuxi Ren, Xin Xia, Shanchuan Lin, Xing Wang, Xuefeng Xiao, Andy J. Ma, Xiaohua Xie, Jian-Huang Lai* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 扩散蒸馏, 对抗性学习, 模式崩溃, 图像合成, 视频合成

**Comment:** Accepted by ICCV 2025 (Highlight)

> **TL;DR:** 提出对抗性分布匹配 (ADM) 框架，通过对抗性方式进行扩散蒸馏，解决传统 DMD 的模式崩溃问题，并在图像和视频合成中实现更高效、更高性能。

**AI_Comments:** 这篇论文提出了一种新颖的对抗性蒸馏方法 ADM，有效解决了传统分布匹配蒸馏中常见的模式崩溃问题。其创新点在于引入了基于扩散的判别器和分布损失，并将其整合到统一的 DMDX 管道中，显著提升了扩散模型蒸馏的效率和性能，尤其是在一步生成方面。该方法在图像和视频合成领域具有重要意义，为生成模型的小型化和部署提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统的分布匹配蒸馏 (DMD) 方法依赖反向 KL 散度最小化，可能导致模式崩溃。

**Method:** 提出对抗性分布匹配 (ADM) 框架，利用基于扩散的判别器以对抗方式对齐真实和伪分数估计器之间的潜在预测。进一步，在一步蒸馏中，通过在潜在空间和像素空间使用混合判别器进行对抗性蒸馏来改进预训练生成器。方法引入了来自教师模型的 ODE 对的分布损失，以提供更好的初始化。将对抗性蒸馏预训练与 ADM 微调结合成统一的管道 DMDX。

**Result:** DMDX 在 SDXL 上实现比 DMD2 更优的一步性能，同时消耗更少的 GPU 时间。在 SD3-Medium、SD3.5-Large 和 CogVideoX 上应用多步 ADM 蒸馏，为高效图像和视频合成树立了新基准。

**Conclusion:** 提出的对抗性分布匹配（ADM）及其统一管道 DMDX 有效解决了传统扩散蒸馏的模式崩溃问题，并在图像和视频合成任务中取得了卓越的效率和性能提升。

> **ai_Abstract:** 本文提出了对抗性分布匹配（ADM）框架，旨在解决传统分布匹配蒸馏（DMD）中因反向 KL 散度最小化导致的模式崩溃问题。ADM 利用基于扩散的判别器以对抗方式对齐真实和伪分数估计器的潜在预测。特别地，对于一步蒸馏，ADM 引入了混合判别器并在潜在和像素空间进行对抗性蒸馏，同时采用来自教师模型的 ODE 对的分布损失进行更好的初始化。将对抗性蒸馏预训练与 ADM 微调整合为统一管道 DMDX。实验结果表明，DMDX 在 SDXL 上实现了优于 DMD2 的一步性能，且 GPU 时间消耗更少。此外，多步 ADM 蒸馏在 SD3-Medium、SD3.5-Large 和 CogVideoX 上也取得了显著进展，为高效图像和视频合成设立了新基准。

> **摘要翻译:** 标题：对抗性分布匹配用于扩散蒸馏以实现高效图像和视频合成。摘要：分布匹配蒸馏（DMD）是一种很有前景的分数蒸馏技术，可以将预训练的教师扩散模型压缩成高效的一步或多步学生生成器。然而，其对反向 Kullback-Leibler（KL）散度最小化的依赖可能在某些应用中引起模式崩溃（或模式寻求）。为了规避这一固有缺陷，我们提出了对抗性分布匹配（ADM），一个新颖的框架，它利用基于扩散的判别器以对抗方式对齐真实和伪分数估计器之间的潜在预测，以进行分数蒸馏。在极具挑战性的一步蒸馏背景下，我们通过在潜在空间和像素空间中使用混合判别器进行对抗性蒸馏，进一步改进了预训练生成器。与 DMD2 预训练中使用的均方误差不同，我们的方法结合了从教师模型收集的 ODE 对的分布损失，从而为下一阶段的分数蒸馏微调提供了更好的初始化。通过将对抗性蒸馏预训练与 ADM 微调结合成一个名为 DMDX 的统一管道，我们提出的方法在 SDXL 上实现比 DMD2 更优的一步性能，同时消耗更少的 GPU 时间。在 SD3-Medium、SD3.5-Large 和 CogVideoX 上应用多步 ADM 蒸馏的额外实验为高效图像和视频合成树立了新基准。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [336] [PARTE: Part-Guided Texturing for 3D Human Reconstruction from a Single Image](https://arxiv.org/abs/2507.17332)
> *PARTE：基于部位引导的单幅图像三维人体重建纹理化方法*

*Hyeongjin Nam, Donghwan Kim, Gyeongsik Moon, Kyoung Mu Lee* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D人体重建, 纹理化, 部位引导, 单幅图像, 纹理对齐

**Comment:** Published at ICCV 2025, 22 pages including the supplementary material

> **TL;DR:** PARTE是一种利用3D人体部位信息来解决现有3D人体重建方法中纹理错位问题的新框架，实现了最先进的重建质量。

**AI_Comments:** PARTE的创新点在于明确利用了3D人体部位信息来指导纹理重建，解决了现有方法中纹理错位这一关键限制。通过引入专门的部位分割模块和部位引导纹理化模块，该方法能够更好地保持不同人体部位纹理的独立性和结构连贯性。其结合预训练图像生成网络获取先验知识的方法，也体现了对深度学习潜力的有效利用，对于提升单幅图像3D人体重建的真实感和质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有三维人体重建方法的主要局限性在于不同人体部位之间纹理错位。大多数方法没有明确利用部位分割先验信息，导致重建纹理错位。

**Method:** 本文提出了PARTE框架，利用3D人体部位信息作为关键指导来重建3D人体纹理。该框架包含两个核心组件：1. 3D部位分割模块（PartSegmenter），用于从单幅图像中推断3D人体部位信息，它首先重建无纹理的人体表面，然后基于此预测人体部位标签。2. 部位引导纹理化模块（PartTexturer），用于将部位信息整合到纹理重建中，该模块从预训练的图像生成网络中获取关于人体部位纹理对齐的先验知识。

**Result:** 大量实验表明，PARTE框架在三维人体重建方面达到了最先进的质量。

**Conclusion:** PARTE通过引入部位引导的纹理化方法，有效解决了三维人体重建中纹理错位的问题，显著提升了重建质量。

> **ai_Abstract:** PARTE是一种创新的3D人体重建方法，旨在解决现有技术中常见的纹理错位问题。该框架通过引入3D人体部位信息作为核心指导，包含两个关键模块：PartSegmenter负责从单张图像中推断并分割出人体部位，PartTexturer则利用部位信息和预训练网络的先验知识进行纹理重建，确保纹理的准确对齐。实验证明，PARTE在3D人体重建质量上达到了最先进水平。

> **摘要翻译:** 现有三维人体重建方法的主要局限性之一是不同人体部位之间的纹理错位。每个身体部位，例如夹克或裤子，都应保持独特的纹理而不会相互融合。人体部位的结构连贯性是推断单幅图像中不可见区域人体纹理的关键线索。然而，大多数现有三维人体重建方法并未明确利用这种部位分割先验信息，导致其重建中出现纹理错位。为此，我们提出了PARTE，它利用三维人体部位信息作为关键指导来重建三维人体纹理。我们的框架包含两个核心组件。首先，为了从单幅图像中推断三维人体部位信息，我们提出了一个三维部位分割模块（PartSegmenter），该模块首先重建一个无纹理的人体表面，并基于该无纹理表面预测人体部位标签。其次，为了将部位信息整合到纹理重建中，我们引入了一个部位引导纹理化模块（PartTexturer），该模块从预训练的图像生成网络中获取关于人体部位纹理对齐的先验知识。大量实验表明，我们的框架在三维人体重建方面达到了最先进的质量。项目页面可在https://hygenie1228.github.io/PARTE/访问。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [347] [Self-Supervised Ultrasound-Video Segmentation with Feature Prediction and 3D Localised Loss](https://arxiv.org/abs/2507.18424)
> *自监督超声视频分割与特征预测和3D局部损失*

*Edward Ellis, Robert Mendel, Andrew Bulpitt, Nasim Parsa, Michael F Byrne, Sharib Ali* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 自监督学习, 超声视频分割, V-JEPA, 3D局部化损失, Vision Transformer

**Comment:** 

> **TL;DR:** 针对超声视频分割，本文首次将V-JEPA引入超声数据，并提出3D局部化辅助任务，显著提升了在有限标注数据下的分割性能。

**AI_Comments:** 本文的创新点在于首次将V-JEPA引入超声视频领域，并针对ViT在医学小数据集上的局限性，提出了一个有效的3D局部化辅助任务。这对于解决医学图像领域数据标注困难的痛点具有重要意义，尤其是在利用有限标注数据进行高精度分割方面展现了巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 超声图像数据采集和标注困难，存在低对比度、高噪声和伪影，耗时且需要专业知识。自监督学习是解决标注数据有限问题的有效方案。

**Method:** 本文首次将V-JEPA（一种基于特征预测的自监督学习框架）应用于超声视频数据。为了解决Vision Transformers (ViTs) 在小型医学数据集上表现不佳的问题（缺乏归纳偏置、空间局部性有限、缺乏分层特征学习），提出了一种新颖的3D局部化辅助任务，以在V-JEPA预训练期间改善ViT表示的局部性理解。

**Result:** 结合辅助任务的V-JEPA显著提高了各种冻结编码器配置下的分割性能。使用100%训练数据时性能提升高达3.4%，使用10%训练数据时性能提升高达8.35%。

**Conclusion:** 提出的结合3D局部化辅助任务的V-JEPA方法能有效提升超声视频分割在有限标注数据下的性能。

> **ai_Abstract:** 本文针对超声视频分割中标注数据获取困难的问题，首次将基于特征预测的自监督学习框架V-JEPA应用于超声视频数据。为弥补Vision Transformers (ViTs) 在小数据集上局部性理解不足的缺陷，提出了一种新颖的3D局部化辅助任务，以增强V-JEPA预训练期间ViT的局部性。实验结果表明，该方法显著提升了超声视频分割性能，尤其在标注数据稀缺时效果更佳。

> **摘要翻译:** 获取和标注超声图像大型数据集具有挑战性，因为超声图像对比度低、噪声高且易受伪影影响。此过程需要大量时间和临床专业知识。自监督学习（SSL）通过利用未标注数据学习有用表示，在标注数据有限时实现改进的分割性能，提供了一个有前景的解决方案。视频数据SSL的最新进展包括V-JEPA，一个完全基于特征预测的框架，避免了像素级重建或负样本。我们假设V-JEPA非常适合超声成像，因为它对嘈杂的像素级细节不敏感，同时有效利用了时间信息。据我们所知，这是首次将V-JEPA应用于超声视频数据。与其他基于补丁掩码的SSL技术（如VideoMAE）类似，V-JEPA非常适合基于ViT的模型。然而，ViT在小型医学数据集上可能表现不佳，因为缺乏归纳偏置、空间局部性有限和缺乏分层特征学习。为了提高局部性理解，我们提出了一种新颖的3D局部化辅助任务，以在V-JEPA预训练期间改善ViT表示的局部性。我们的结果表明，结合我们辅助任务的V-JEPA显著提高了各种冻结编码器配置下的分割性能，使用100%训练数据时增益高达3.4%，使用仅10%训练数据时增益高达8.35%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [349] [Personalization Toolkit: Training Free Personalization of Large Vision Language Models](https://arxiv.org/abs/2502.02452)
> *个性化工具包：大型视觉语言模型的免训练个性化*

*Soroush Seifi, Vaggelis Dorovatas, Daniel Olmeda Reino, Rahaf Aljundi* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 个性化, 大型视觉语言模型, 免训练, 检索增强生成, 视觉提示

**Comment:** 

> **TL;DR:** 本文提出了一种免训练的大型视觉语言模型个性化方法，并在新基准上取得了最先进的结果。

**AI_Comments:** 该论文的创新点在于提出了“免训练”的LVLM个性化方法，显著提升了模型的实用性和部署效率，解决了现有方法耗时且不实用的核心痛点。其结合预训练视觉基础模型、RAG和视觉提示的策略具有独创性。此外，引入新的、全面的真实世界基准对于推动个性化任务的评估和发展也具有重要意义。该方法实现了多概念的灵活个性化，对LVLM在实际应用中的广泛部署具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型视觉语言模型（LVLMs）个性化方法通常依赖耗时的测试时训练，这使得它们在实际部署中不切实际。此外，当前的个性化基准主要集中在以对象为中心、单概念的评估。

**Method:** 本文提出了一种新颖的免训练方法。该方法利用预训练的视觉基础模型提取独特特征，应用检索增强生成（RAG）技术识别视觉输入中的实例，并采用视觉提示策略来引导模型输出。

**Result:** 该方法实现了最先进的结果，超越了现有的基于训练的方法。它能够无需任何额外训练，在图像和视频上实现高效灵活的多概念个性化。

**Conclusion:** 本文提出了一种新颖且实用的免训练方法，用于大型视觉语言模型的个性化，并通过引入全面的真实世界基准，解决了现有方法的局限性，并取得了超越传统训练方法的优异性能。

> **ai_Abstract:** 本文提出了一种新颖的免训练方法，用于大型视觉语言模型（LVLMs）的个性化，旨在解决现有方法耗时且不适用于实际部署的问题。该方法利用预训练视觉基础模型提取特征，结合检索增强生成（RAG）技术识别视觉输入中的实例，并采用视觉提示策略引导模型输出。同时，论文引入了一个全面的真实世界基准来严格评估个性化任务。这种模型无关的视觉工具包能够实现图像和视频上的高效灵活多概念个性化，无需额外训练，并取得了超越现有训练方法的最新成果。

> **摘要翻译:** 大型视觉语言模型（LVLMs）的个性化涉及定制模型以识别特定用户和对象实例，并生成符合上下文的响应。现有方法通常依赖于为每个用户或对象进行耗时的测试时训练，这使得它们在实际部署中不切实际，这一限制也反映在当前的个性化基准中，这些基准侧重于以对象为中心、单概念的评估。在本文中，我们提出了一种新颖的免训练LVLM个性化方法，并引入了一个全面的真实世界基准，旨在严格评估个性化任务的各个方面。我们的方法利用预训练的视觉基础模型来提取独特特征，应用检索增强生成（RAG）技术来识别视觉输入中的实例，并采用视觉提示策略来引导模型输出。我们与模型无关的视觉工具包可以在图像和视频上实现高效灵活的多概念个性化，无需任何额外训练。我们取得了最先进的结果，超越了现有的基于训练的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [353] [DepthDark: Robust Monocular Depth Estimation for Low-Light Environments](https://arxiv.org/abs/2507.18243)
> *DepthDark：针对低光照环境的鲁棒单目深度估计*

*Longjian Zeng, Zunjie Zhu, Rongfeng Lu, Ming Lu, Bolun Zheng, Chenggang Yan, Anke Xue* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 单目深度估计, 低光照, 基础模型, 数据合成, PEFT

**Comment:** Accepted by ACM MM 2025 conference

> **TL;DR:** DepthDark提出了一种针对低光照环境的鲁棒单目深度估计基础模型，通过模拟低光照成像过程生成高质量数据集，并采用有效的PEFT策略，在夜间数据集上实现了最先进的性能。

**AI_Comments:** DepthDark的创新之处在于其双管齐下的方法：一是通过模拟低光照成像过程生成高质量的合成数据集，这有效解决了真实低光照深度数据稀缺的问题；二是通过定制化的PEFT策略，使模型能够高效适应低光照环境。这项工作对于推动自动驾驶和机器人技术在夜间或恶劣光照条件下的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前单目深度估计方法主要针对日光条件，在低光照环境下效果显著下降。缺乏专门针对低光照场景的鲁棒基础模型，这主要是由于缺少大规模、高质量的低光照配对深度数据集以及有效的参数高效微调（PEFT）策略。

**Method:** 本文提出了DepthDark模型。首先，引入了眩光模拟模块和噪声模拟模块，以准确模拟夜间成像过程，从而生成高质量的低光照配对深度数据集。其次，提出了一种有效的低光照PEFT策略，该策略利用光照引导和多尺度特征融合来增强模型在低光照环境下的能力。

**Result:** DepthDark在具有挑战性的nuScenes-Night和RobotCar-Night数据集上实现了最先进的深度估计性能。

**Conclusion:** DepthDark模型在有限的训练数据和计算资源下，在低光照环境下表现出有效的深度估计能力，验证了其在夜间数据集上的卓越性能。

> **ai_Abstract:** 本文提出了DepthDark，一个用于低光照单目深度估计的鲁棒基础模型，旨在解决现有方法在低光照环境下性能下降的问题。该模型通过引入眩光和噪声模拟模块来生成高质量的低光照配对深度数据集，并开发了一种利用光照引导和多尺度特征融合的参数高效微调（PEFT）策略。DepthDark在nuScenes-Night和RobotCar-Night数据集上取得了最先进的深度估计性能，证明了其在资源受限情况下的有效性。

> **摘要翻译:** 近年来，用于单目深度估计的基础模型受到了越来越多的关注。当前的方法主要解决典型的日光条件问题，但它们在低光照环境中的有效性显著降低。目前缺乏专门为低光照场景设计的鲁棒单目深度估计基础模型。这很大程度上源于缺乏大规模、高质量的低光照配对深度数据集以及有效的参数高效微调（PEFT）策略。为了解决这些挑战，我们提出了DepthDark，一个用于低光照单目深度估计的鲁棒基础模型。我们首先引入了一个眩光模拟模块和一个噪声模拟模块，以准确模拟夜间条件下的成像过程，从而生成高质量的低光照配对深度数据集。此外，我们提出了一种有效的低光照PEFT策略，该策略利用光照引导和多尺度特征融合来增强模型在低光照环境中的能力。我们的方法在具有挑战性的nuScenes-Night和RobotCar-Night数据集上实现了最先进的深度估计性能，验证了其在有限训练数据和计算资源下的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [362] [HybridTM: Combining Transformer and Mamba for 3D Semantic Segmentation](https://arxiv.org/abs/2507.18575)
> *混合TM：结合Transformer和Mamba进行3D语义分割*

*Xinyu Wang, Jinghua Hou, Zhe Liu, Yingying Zhu* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D语义分割, Transformer, Mamba, 混合架构, 点云

**Comment:** 7 pages, 5 figures

> **TL;DR:** 本文提出了HybridTM，首个结合Transformer和Mamba的3D语义分割混合架构，有效解决了长距离依赖和局部特征提取问题，并在多个基准测试中达到了最先进的性能。

**AI_Comments:** 这篇论文的创新点在于首次提出将Transformer和Mamba两种不同架构结合用于3D语义分割，并设计了独特的内部层混合策略，有效弥补了各自的缺点。这种混合方法为解决大规模点云中的长距离依赖和细粒度特征提取问题提供了一个有前景的方向，其在多个基准测试上取得SOTA性能也证明了其有效性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** Transformer在3D语义分割中虽有强大注意力机制，但其二次复杂度限制了对大规模点云中长距离依赖的建模。Mamba虽然处理效率高（线性复杂度），但在提取3D特征时特征表示能力不足。如何有效结合两者的优势是当前面临的挑战。

**Method:** 本文提出了HybridTM，这是首个将Transformer和Mamba集成的3D语义分割混合架构。此外，还提出了内部层混合策略（Inner Layer Hybrid Strategy），以更细粒度的方式结合注意力和Mamba，从而同时捕获长距离依赖和细粒度局部特征。

**Result:** 广泛的实验证明HybridTM在多种室内和室外数据集上具有有效性和泛化性。HybridTM在ScanNet、ScanNet200和nuScenes基准测试中取得了最先进的性能。

**Conclusion:** HybridTM通过创新性地结合Transformer和Mamba的优势，成功解决了3D语义分割中长距离依赖和细粒度特征表示的挑战，并在多个关键基准测试中取得了领先的性能。

> **ai_Abstract:** 本文提出了HybridTM，一种创新的混合架构，首次将Transformer和Mamba集成应用于3D语义分割。该方法旨在克服Transformer在处理长距离依赖时的二次复杂度和Mamba在特征表示上的不足。通过引入内部层混合策略，HybridTM能够在细粒度上结合注意力和Mamba的优势，同时捕捉长距离依赖和细粒度局部特征。实验结果表明，HybridTM在多个室内外数据集上表现出卓越的有效性和泛化能力，并在ScanNet、ScanNet200和nuScenes基准测试中达到了最先进的性能。

> **摘要翻译:** 基于Transformer的方法通过其强大的注意力机制在3D语义分割中展现出卓越的能力，但其二次复杂度限制了它们对大规模点云中长距离依赖的建模。虽然最近基于Mamba的方法提供了线性复杂度的有效处理，但在提取3D特征时它们在特征表示方面存在困难。然而，有效结合这些互补优势仍然是该领域的一个开放挑战。在本文中，我们提出了HybridTM，这是第一个将Transformer和Mamba集成用于3D语义分割的混合架构。此外，我们提出了内部层混合策略（Inner Layer Hybrid Strategy），它以更细的粒度结合了注意力和Mamba，从而能够同时捕获长距离依赖和细粒度局部特征。广泛的实验证明了我们的HybridTM在各种室内和室外数据集上的有效性和泛化性。此外，我们的HybridTM在ScanNet、ScanNet200和nuScenes基准测试中取得了最先进的性能。代码将在https://github.com/deepinact/HybridTM 提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [370] [Robust Multi-View Learning via Representation Fusion of Sample-Level Attention and Alignment of Simulated Perturbation](https://arxiv.org/abs/2503.04151)
> *鲁棒多视图学习：通过样本级注意力表示融合和模拟扰动对齐*

*Jie Xu, Na Zhao, Gang Niu, Masashi Sugiyama, Xiaofeng Zhu* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 多视图学习, 鲁棒性, 表示融合, 对比学习, 数据扰动

**Comment:** 

> **TL;DR:** 本文提出了一种名为RML的新型鲁棒多视图学习方法，通过多视图Transformer融合网络（利用样本级注意力）实现表示融合，并结合基于模拟扰动的对比学习框架对齐表示，以应对异构和不完美的多视图数据，从而学习到判别性和鲁棒性的表示。

**AI_Comments:** 本文的创新点在于结合了基于Transformer的融合网络与新颖的模拟扰动对比学习框架，显著增强了多视图学习模型对数据不完美性的鲁棒性。其自监督特性和作为即插即用模块应用于多种下游任务的潜力，凸显了其通用性和实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界中的多视图数据集往往是异构和不完美的，这导致为特定视图组合设计的多视图学习（MVL）方法缺乏应用潜力并限制了其有效性。

**Method:** 我们提出了一种名为RML的新型鲁棒多视图学习方法，它同时进行表示融合和对齐。具体来说，我们引入了一个多视图Transformer融合网络，将异构多视图数据转换为同质的词嵌入，并通过样本级注意力机制整合多个视图以获得融合表示。此外，我们提出了一个基于模拟扰动的多视图对比学习框架，动态生成噪声和不可用扰动来模拟不完美数据条件。模拟的噪声和不可用数据获得两种不同的融合表示，我们利用对比学习来对齐它们，以学习判别性和鲁棒性的表示。RML是自监督的，也可以作为正则化应用于下游任务。

**Result:** RML在多视图无监督聚类、噪声标签分类以及作为跨模态哈希检索的即插即用模块中进行了实验应用。广泛的对比实验和消融研究验证了RML的有效性。

**Conclusion:** 本文提出的RML方法通过创新的表示融合（基于样本级注意力）和对齐（基于模拟扰动对比学习）机制，成功解决了异构和不完美多视图数据带来的挑战，学习到了判别性和鲁棒性的表示。

> **ai_Abstract:** 本文提出了一种名为RML的新型鲁棒多视图学习方法，旨在解决现实世界中多视图数据异构和不完美的问题。RML包含一个多视图Transformer融合网络，该网络通过样本级注意力机制将异构视图融合为统一表示；以及一个基于模拟扰动的对比学习框架，该框架动态生成噪声数据并对齐原始与扰动数据的表示，从而学习到判别性强且鲁棒性好的特征。RML是自监督的，并可作为正则化模块应用于下游任务。实验验证了其在聚类、分类和哈希检索等任务中的有效性。

> **摘要翻译:** 近年来，多视图学习（MVL）因其融合来自多个视图的判别性信息的能力而受到广泛关注。然而，现实世界中的多视图数据集通常是异构和不完美的，这通常导致为特定视图组合设计的MVL方法缺乏应用潜力并限制了其有效性。为了解决这个问题，我们提出了一种新型的鲁棒MVL方法（即RML），该方法同时进行表示融合和对齐。具体来说，我们引入了一个简单但有效的多视图Transformer融合网络，我们将异构多视图数据转换为同质的词嵌入，然后通过样本级注意力机制整合多个视图以获得融合表示。此外，我们提出了一个基于模拟扰动的多视图对比学习框架，该框架动态生成噪声和不可用扰动，以模拟不完美数据条件。模拟的噪声和不可用数据获得两种不同的融合表示，我们利用对比学习来对齐它们，以学习判别性和鲁棒性的表示。我们的RML是自监督的，也可以作为正则化应用于下游任务。在实验中，我们将其应用于多视图无监督聚类、噪声标签分类以及作为跨模态哈希检索的即插即用模块。广泛的对比实验和消融研究验证了RML的有效性。代码可在https://github.com/SubmissionsIn/RML获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [373] [ViGText: Deepfake Image Detection with Vision-Language Model Explanations and Graph Neural Networks](https://arxiv.org/abs/2507.18031)
> *ViGText：结合视觉语言模型解释和图神经网络的深度伪造图像检测*

*Ahmad ALBarqawi, Mahmoud Nazzal, Issa Khalil, Abdallah Khreishah, NhatHai Phan* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 深度伪造检测, 视觉语言模型, 图神经网络, 泛化, 鲁棒性

**Comment:** 

> **TL;DR:** ViGText是一种新颖的深度伪造检测方法，通过结合VLLM文本解释和图神经网络，显著提升了对复杂和定制化深度伪造的泛化能力和鲁棒性。

**AI_Comments:** ViGText的创新点在于其将VLLM的文本解释与视觉数据相结合，并利用图神经网络进行深度分析，这比单纯的图像特征或字幕提供了更丰富的上下文信息，从而有效提升了对复杂和定制化深度伪造的检测能力。其在泛化能力和鲁棒性方面的显著提升，使其在应对不断演变的深度伪造技术方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度伪造技术快速发展，威胁媒体真实性；传统检测方法在面对复杂、定制化深度伪造时，泛化能力和鲁棒性不足，尤其是在对抗恶意攻击方面。

**Method:** ViGText将图像与视觉大语言模型(VLLM)文本解释集成到基于图的框架中。它将图像分割成补丁，构建图像图和文本图，并使用图神经网络(GNNs)进行整合分析以识别深度伪造。该方法通过在空间和频率域进行多级特征提取，捕捉细节。

**Result:** 在泛化评估中，平均F1分数从72.45%提升至98.32%，显示出对未见过的、微调的稳定扩散模型变体的卓越泛化能力。在鲁棒性方面，召回率比其他方法提高11.1%。面对利用其图基架构的定向攻击时，分类性能下降限制在4%以内。

**Conclusion:** ViGText通过详细的视觉和文本分析，为深度伪造检测设定了新标准，有助于确保媒体真实性和信息完整性。

> **ai_Abstract:** 本文提出ViGText，一种创新的深度伪造图像检测方法，通过将视觉大语言模型（VLLM）生成的文本解释与图像数据整合到图神经网络（GNN）框架中，克服了传统方法在泛化和鲁棒性上的不足。ViGText通过图像分块、构建图像和文本图以及多级特征提取，实现了对复杂定制化深度伪造的有效识别，并在实验中展现出显著的性能提升，尤其是在泛化能力（F1分数提升至98.32%）和鲁棒性（召回率提高11.1%）方面。

> **摘要翻译:** 深度伪造技术（可生成逼真但虚假的数字内容）的迅速兴起，威胁着媒体的真实性。传统的深度伪造检测方法在处理复杂的、定制化的深度伪造时常常力不从心，尤其是在泛化能力和对抗恶意攻击的鲁棒性方面。本文介绍了一种新颖的方法ViGText，它将图像与视觉大语言模型（VLLM）文本解释集成到基于图的框架中，以改进深度伪造检测。ViGText 的新颖之处在于它将详细解释与视觉数据相结合，与通常缺乏特异性且未能揭示细微不一致的字幕相比，它提供了更具上下文意识的分析。ViGText 系统地将图像分割成补丁，构建图像图和文本图，并利用图神经网络（GNNs）对它们进行整合分析以识别深度伪造。通过在空间和频率域使用多级特征提取，ViGText 捕获了细节，从而增强了其检测复杂深度伪造的鲁棒性和准确性。大量实验表明，ViGText 在检测用户定制的深度伪造时显著增强了泛化能力并取得了显著的性能提升。具体而言，在泛化评估中，平均 F1 分数从 72.45% 上升到 98.32%，这反映了该模型在泛化到未见过的、经过微调的稳定扩散模型变体方面的卓越能力。在鲁棒性方面，与其他深度伪造检测方法相比，ViGText 的召回率提高了 11.1%。当面临利用其基于图的架构的定向攻击时，ViGText 将分类性能下降限制在 4% 以内。ViGText 利用详细的视觉和文本分析，为深度伪造检测设定了新标准，有助于确保媒体真实性和信息完整性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [384] [ELITE: Enhanced Language-Image Toxicity Evaluation for Safety](https://arxiv.org/abs/2502.04757)
> *ELITE: 增强型语言-图像毒性评估以确保安全*

*Wonjun Lee, Doehyeon Lee, Eugene Choi, Sangyoon Yu, Ashkan Yousefpour, Haon Park, Bumsub Ham, Suhyun Kim* | **Category: cs.CV, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 视觉语言模型安全, 毒性评估, 基准测试, 多模态有害性, ELITE

**Comment:** ICML 2025. Project page at https://velpegor.github.io/ELITE/

> **TL;DR:** 现有的视觉语言模型安全基准在检测隐式有害内容和数据多样性方面存在不足。本文提出了ELITE基准和ELITE评估器，通过引入毒性评分来更准确地评估多模态有害性，并生成高质量多样化的数据集，实验证明其与人类评估更一致。

**AI_Comments:** 本文的创新点在于提出了一个结合毒性评分的增强型评估方法ELITE评估器，并基于此构建了一个高质量、多样化的安全评估基准ELITE。它解决了现有VLM安全评估中自动化方法检测不准确和数据多样性不足的关键问题，对于提升VLM的安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的视觉语言模型（VLMs）容易受到恶意提示的攻击，产生有害输出。现有的VLM安全基准主要依赖自动化评估方法，但这些方法难以检测隐式有害内容或产生不准确的评估。因此，现有基准存在有害性水平低、数据模糊和图像-文本对组合多样性有限的问题。

**Method:** 为解决现有问题，本文提出了ELITE基准，这是一个高质量的VLM安全评估基准，其核心是增强型评估方法——ELITE评估器。ELITE评估器明确引入了毒性评分，以准确评估多模态上下文中的有害性。研究者使用ELITE评估器过滤掉现有基准中模糊和低质量的图像-文本对，并生成多样化的安全和不安全图像-文本对组合。

**Result:** 实验表明，与先前的自动化方法相比，ELITE评估器与人类评估的对齐度更高，并且ELITE基准提供了增强的基准质量和多样性。

**Conclusion:** 通过引入ELITE，本文为更安全、更强大的视觉语言模型铺平了道路，为评估和减轻现实世界应用中的安全风险贡献了重要工具。

> **ai_Abstract:** 本文针对当前视觉语言模型（VLMs）易受恶意提示影响产生有害输出的问题，指出现有安全基准在隐式有害内容检测和数据多样性方面的不足。为此，研究者提出了ELITE基准和ELITE评估器。ELITE评估器通过引入毒性评分，能够更准确地评估多模态上下文中的有害性，并用于筛选和生成高质量、多样化的安全与不安全图像-文本对。实验结果表明，ELITE评估器与人类评估的对齐度优于现有自动化方法，且ELITE基准提升了评估质量和多样性，有助于推动更安全、更强大的VLM发展。

> **摘要翻译:** 当前的视觉语言模型（VLMs）仍然容易受到恶意提示的攻击，这些提示会诱导有害输出。现有的VLM安全基准主要依赖自动化评估方法，但这些方法难以检测隐式有害内容或产生不准确的评估。因此，我们发现现有基准的有害性水平较低、数据模糊且图像-文本对组合的多样性有限。为了解决这些问题，我们提出了ELITE基准，这是一个高质量的VLM安全评估基准，其核心是我们增强的评估方法——ELITE评估器。ELITE评估器明确地引入了毒性评分，以准确评估多模态上下文中的有害性，在这些上下文中，VLMs通常提供特定、令人信服但无害的图像描述。我们使用ELITE评估器从现有基准中筛选出模糊和低质量的图像-文本对，并生成多样化的安全和不安全图像-文本对组合。我们的实验表明，与先前的自动化方法相比，ELITE评估器与人类评估的对齐度更高，并且ELITE基准提供了增强的基准质量和多样性。通过引入ELITE，我们为更安全、更强大的VLM铺平了道路，为评估和减轻现实世界应用中的安全风险贡献了重要工具。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [394] [Real-Time Object Detection and Classification using YOLO for Edge FPGAs](https://arxiv.org/abs/2507.18174)
> *基于YOLO的边缘FPGA实时目标检测与分类*

*Rashed Al Amin, Roman Obermaisser* | **Category: cs.CV, cs.AR** | **Updated: 2025-07-24**

**Keywords:** YOLOv5, 目标检测, 边缘FPGA, 实时, 资源效率

**Comment:** This paper has been accepted for the 67th International Symposium on
  ELMAR 2025

> **TL;DR:** 本文提出了一种优化的YOLOv5系统，实现了在边缘FPGA上资源高效的实时目标检测和分类，并在Xilinx Kria KV260上取得了99%的分类精度，3.5W功耗和9 FPS的处理速度。

**AI_Comments:** 本文的创新点在于提出了一个针对边缘FPGA优化的YOLOv5系统，有效解决了现有YOLO模型在边缘设备上资源效率不足的问题。其重要性在于为ADAS等需要实时、低功耗目标检测的应用提供了可行方案。通过在特定硬件平台（Xilinx Kria KV260）上验证，并给出具体的功耗和帧率数据，增加了研究的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于深度学习的目标检测和分类方法（如CNNs, SSDs, YOLO）在部署到FPGA时，尽管在精度和计算速度上表现出色，但在边缘FPGA平台上实现资源效率仍面临挑战。

**Method:** 本文提出了一种基于YOLOv5的资源高效实时目标检测和分类系统，该系统针对FPGA部署进行了优化。系统在COCO和GTSRD数据集上进行训练，并在Xilinx Kria KV260 FPGA板上实现。

**Result:** 实验结果表明，该系统实现了99%的分类精度，功耗为3.5W，处理速度为9帧每秒（FPS）。

**Conclusion:** 研究结果突出了所提出的方法在实现边缘计算应用中实时、资源高效的目标检测和分类方面的有效性。

> **ai_Abstract:** 本文针对边缘FPGA平台资源效率的挑战，提出了一种优化的YOLOv5实时目标检测与分类系统。该系统在COCO和GTSRD数据集上训练，并在Xilinx Kria KV260 FPGA上实现。实验结果显示，系统达到99%的分类精度，功耗3.5W，处理速度9 FPS，证明了其在边缘计算中实现高效实时目标检测的有效性。

> **摘要翻译:** 目标检测和分类是各种应用领域中的关键任务，尤其是在开发安全可靠的高级驾驶辅助系统（ADAS）中。现有的基于深度学习的方法，如卷积神经网络（CNNs）、单发多框检测器（SSDs）和只看一次（YOLO），在部署到现场可编程门阵列（FPGAs）时，在准确性和计算速度方面表现出高性能。然而，尽管取得了这些进步，最先进的基于YOLO的目标检测和分类系统在实现适用于边缘FPGA平台的资源效率方面仍然面临挑战。为了解决这一限制，本文提出了一种基于YOLOv5的资源高效实时目标检测和分类系统，该系统针对FPGA部署进行了优化。所提出的系统在COCO和GTSRD数据集上进行训练，并在Xilinx Kria KV260 FPGA板上实现。实验结果表明，分类精度达到99%，功耗为3.5W，处理速度为9帧每秒（FPS）。这些发现突出了所提出的方法在实现边缘计算应用中实时、资源高效的目标检测和分类方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [395] [LONG3R: Long Sequence Streaming 3D Reconstruction](https://arxiv.org/abs/2507.18255)
> *LONG3R：长序列流式3D重建*

*Zhuoguang Chen, Minghui Qin, Tianyuan Yuan, Zhe Liu, Hang Zhao* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D重建, 流式处理, 长序列, 实时, 多视图

**Comment:** Accepted by ICCV 2025. Project page:
  https://zgchen33.github.io/LONG3R/

> **TL;DR:** LONG3R是一种用于长序列流式3D重建的新模型，通过循环操作和创新内存管理实现实时性能，优于现有方法。

**AI_Comments:** 该论文的创新之处在于其针对长序列实时3D重建的循环方法，特别是其记忆管理机制（记忆门控、3D时空记忆）和两阶段训练策略，有效填补了实时3D重建领域的一个关键空白。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多视图场景重建方法在处理图像流时存在局限性，要么依赖耗时的离线优化，要么受限于较短的序列，这阻碍了它们在实时场景中的应用。

**Method:** 本文提出了LONG3R模型，通过循环操作实现实时处理，并随每次新观测维护和更新内存。它采用记忆门控机制来过滤相关记忆，并将其与新观测一起输入到双源精炼解码器中进行粗到细的交互。为有效捕获长序列记忆，提出了一种3D时空记忆，它动态修剪冗余空间信息并自适应调整场景分辨率。此外，采用两阶段课程训练策略以提高长序列性能并保持训练效率。

**Result:** 实验表明，LONG3R在长序列方面优于最先进的流式方法，同时保持实时推理速度。

**Conclusion:** LONG3R模型有效解决了长序列实时3D重建的挑战，提供了一种性能优越且实用的解决方案。

> **ai_Abstract:** 本文介绍了LONG3R，一种用于长序列流式多视图3D场景重建的新模型，旨在解决现有方法在实时性或序列长度上的限制。LONG3R通过循环操作实现实时处理，并利用记忆门控机制、双源精炼解码器以及动态修剪冗余空间信息和调整分辨率的3D时空记忆来有效管理长序列数据。此外，采用两阶段课程训练策略以提高性能和训练效率。实验证明，LONG3R在长序列上优于现有流式方法，并保持实时推理速度。

> **摘要翻译:** 多视图场景重建的最新进展显著，但现有方法在处理输入图像流时面临局限性。这些方法要么依赖耗时的离线优化，要么局限于较短的序列，这阻碍了它们在实时场景中的适用性。在这项工作中，我们提出了LONG3R（长序列流式3D重建），这是一种新颖的模型，专为长序列的流式多视图3D场景重建而设计。我们的模型通过循环操作，随着每次新的观测维护和更新记忆，从而实现实时处理。我们首先采用记忆门控机制来过滤相关记忆，这些记忆与新的观测一起被输入到双源精炼解码器中，进行从粗到细的交互。为了有效捕获长序列记忆，我们提出了一种3D时空记忆，它动态修剪冗余空间信息，同时自适应地调整场景分辨率。为了提高模型在长序列上的性能，同时保持训练效率，我们采用了两阶段课程训练策略，每个阶段都针对特定的能力。实验证明，LONG3R优于最先进的流式方法，特别是对于更长的序列，同时保持实时推理速度。项目页面：https://zgchen33.github.io/LONG3R/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [403] [NLML-HPE: Head Pose Estimation with Limited Data via Manifold Learning](https://arxiv.org/abs/2507.18429)
> *NLML-HPE：通过流形学习实现有限数据下的头部姿态估计*

*Mahdi Ghafourian, Federico M. Sukno* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 头部姿态估计, 深度学习, 流形学习, 张量分解, 有限数据

**Comment:** 

> **TL;DR:** NLML-HPE 是一种新颖的深度学习方法，通过非线性流形学习在有限训练数据下进行头部姿态估计，将姿态估计视为回归问题，并解决了数据不准确和实时性能的挑战。

**AI_Comments:** 这项工作通过将头部姿态估计重新定义为回归问题并利用非线性流形学习，提供了一种处理有限训练数据的新颖方法。其创新之处在于结合了张量分解和前馈神经网络，并将姿态角度建模为连续的余弦曲线。此外，作者通过生成高质量的合成数据集来解决现有HPE数据集的标注问题，这对于提高模型性能和泛化能力具有重要意义。该方法在实时性能方面的表现也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 头部姿态估计（HPE）在人机交互和面部识别等计算机视觉应用中扮演关键角色。现有HPE数据集存在姿态标注不正确和不准确的问题，且在有限数据下难以实现实时性能。

**Method:** 本文提出了一种名为NLML-HPE的深度学习方法，用于在有限训练数据下进行头部姿态估计。该方法结合了张量分解（Tucker分解）和前馈神经网络，将头部姿态估计公式化为回归问题，将输入地标映射到姿态角度的连续表示。具体而言，该方法使用张量分解将每个欧拉角（偏航、俯仰、滚动）分解到单独的子空间，并将底层流形的每个维度建模为余弦曲线。为了解决数据挑战，作者通过旋转3D头部模型并渲染2D图像，生成了一个精确且一致的2D头部姿态数据集用于训练。

**Result:** 该方法在有限训练数据下实现了实时性能，能够准确捕捉物体从面部地标旋转的本质。一旦学习了围绕每个轴旋转的底层流形，模型在预测未见数据时速度非常快。

**Conclusion:** 通过将头部姿态估计公式化为回归问题，并利用张量分解和前馈神经网络，NLML-HPE在有限数据下实现了精确和实时的头部姿态估计，并且能够生成高质量的训练数据集。

> **ai_Abstract:** 本文提出了NLML-HPE，一种基于非线性流形学习的深度学习方法，旨在解决有限训练数据下的头部姿态估计问题。该方法将头部姿态估计视为回归任务，结合张量分解和前馈神经网络，将欧拉角分解为单独的子空间并建模为余弦曲线。为克服现有数据集标注不准确的问题，研究人员生成了一个精确的2D头部姿态数据集。NLML-HPE在有限数据下实现了实时性能，并能快速预测未见数据。

> **摘要翻译:** 头部姿态估计（HPE）在人机交互和面部识别等各种计算机视觉应用中扮演着关键角色。在本文中，我们提出了一种新颖的深度学习方法NLML-HPE，通过非线性流形学习在有限训练数据下进行头部姿态估计。该方法基于张量分解（即Tucker分解）和前馈神经网络的组合。与传统的基于分类的方法不同，我们的方法将头部姿态估计公式化为一个回归问题，将输入地标映射到姿态角度的连续表示。为此，我们的方法使用张量分解将每个欧拉角（偏航、俯仰、滚动）分解到单独的子空间，并将底层流形的每个维度建模为余弦曲线。我们解决了两个关键挑战：1. 几乎所有的HPE数据集都存在不正确和不准确的姿态标注。因此，我们通过旋转3D头部模型以固定姿态集并渲染相应的2D图像，为我们的训练集生成了一个精确且一致的2D头部姿态数据集。2. 我们的方法准确地捕捉了物体从面部地标旋转的本质，从而在有限训练数据下实现了实时性能。一旦学习了围绕每个轴旋转的底层流形，模型在预测未见数据时速度非常快。我们的训练和测试代码以及训练好的模型可在https://github.com/MahdiGhafoorian/NLML_HPE在线获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [404] [Identifying Prompted Artist Names from Generated Images](https://arxiv.org/abs/2507.18633)
> *从生成图像中识别提示的艺术家名称*

*Grace Su, Sheng-Yu Wang, Aaron Hertzmann, Eli Shechtman, Jun-Yan Zhu, Richard Zhang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 文本-图像, 艺术家识别, 基准, 负责任AI, 图像生成

**Comment:** Project page:
  https://graceduansu.github.io/IdentifyingPromptedArtists

> **TL;DR:** 本文提出了一个基准，用于从生成的图像中识别文本-图像模型中被提示的艺术家名称，旨在促进负责任的模型审查。

**AI_Comments:** 这篇论文解决了AI生成艺术中一个重要的伦理和实际问题，即如何识别图像中被引用的艺术家。通过提供一个大规模的基准数据集和系统的评估框架，它为文本-图像模型的负责任开发和内容审查提供了关键工具。对不同泛化设置的深入分析，特别是多艺术家提示的挑战性，为未来的研究指明了方向，具有重要的现实意义。

<details>
  <summary>Details</summary>

**Motivation:** 文本-图像模型被普遍且有争议地用于通过明确命名艺术家来生成图片，例如“以格雷格·鲁特科夫斯基的风格”。因此，需要一种方法来识别图像中被提示的艺术家，以实现负责任的模型审查和内容管理。

**Method:** 研究人员引入了一个用于提示艺术家识别的基准。该数据集包含195万张图像，涵盖110位艺术家，并涵盖了四种泛化设置：保留艺术家、增加提示复杂性、多艺术家提示和不同的文本-图像模型。他们评估了特征相似性基线、对比风格描述符、数据归因方法、监督分类器和少样本原型网络。

**Result:** 泛化模式各不相同：监督和少样本模型在已见艺术家和复杂提示上表现出色，而风格描述符在艺术家风格明显时表现出更好的迁移能力；多艺术家提示仍然是最具挑战性的。他们的基准揭示了巨大的提升空间。

**Conclusion:** 该基准揭示了巨大的提升空间，并提供了一个公共测试平台，以推进文本-图像模型的负责任审查。研究人员发布了数据集和基准，以促进进一步的研究。

> **ai_Abstract:** 本文提出了一个用于从生成的图像中识别文本-图像模型中被提示的艺术家名称的基准和数据集。该数据集包含195万张图像和110位艺术家，涵盖了多种泛化场景。研究人员评估了多种识别方法，发现监督和少样本模型在已知艺术家和复杂提示上表现良好，而风格描述符在风格显著时表现更佳，多艺术家提示仍是难题。该工作为文本-图像模型的负责任审查提供了公共测试平台，并鼓励进一步研究。

> **摘要翻译:** 文本-图像模型的一种常见且有争议的用途是通过明确命名艺术家来生成图片，例如“以格雷格·鲁特科夫斯基的风格”。我们引入了一个用于提示艺术家识别的基准：仅从图像预测提示中调用了哪些艺术家名称。该数据集包含195万张图像，涵盖110位艺术家，并涵盖了四种泛化设置：保留艺术家、增加提示复杂性、多艺术家提示和不同的文本-图像模型。我们评估了特征相似性基线、对比风格描述符、数据归因方法、监督分类器和少样本原型网络。泛化模式各不相同：监督和少样本模型在已见艺术家和复杂提示上表现出色，而风格描述符在艺术家风格明显时表现出更好的迁移能力；多艺术家提示仍然是最具挑战性的。我们的基准揭示了巨大的提升空间，并提供了一个公共测试平台，以推进文本-图像模型的负责任审查。我们发布了数据集和基准，以促进进一步的研究：https://graceduansu.github.io/IdentifyingPromptedArtists/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [406] [When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning](https://arxiv.org/abs/2503.07588)
> *当大型视觉-语言模型遇上大型遥感图像：从粗到细的文本引导令牌剪枝*

*Junwei Luo, Yingying Zhang, Xue Yang, Kang Wu, Qi Zhu, Lei Liang, Jingdong Chen, Yansheng Li* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大型视觉-语言模型, 遥感图像, 令牌剪枝, 文本引导, LRS-VQA

**Comment:** 18 pages, 6 figures, 18 tables

> **TL;DR:** 本文提出了一种文本引导的粗到细令牌剪枝方法，用于高效处理大型遥感图像，并构建了新的大型遥感图像视觉问答基准LRS-VQA。

**AI_Comments:** 这篇论文通过引入文本引导的令牌剪枝和动态图像金字塔，创新性地解决了大型视觉-语言模型处理巨型遥感图像的效率和信息保留难题。同时，构建新的LRS-VQA基准对推动该领域的研究和评估具有重要意义，填补了现有基准在问题多样性和图像尺寸方面的不足。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型视觉-语言模型在处理大型遥感图像时面临效率和信息丢失的挑战，因为它们使用有限网格导致信息丢失，或使用无限网格导致计算成本过高。此外，现有评估大型视觉-语言模型感知能力的基准存在问题，例如问题多样性有限和图像尺寸受限。

**Method:** 本文提出了一种结合动态图像金字塔（DIP）的文本引导令牌剪枝方法。该方法包含：(i) 一个区域焦点模块（RFM），利用文本感知区域定位能力识别关键视觉令牌；(ii) 基于DIP的从粗到细图像瓦片选择和视觉令牌剪枝策略，该策略由RFM输出引导，避免直接处理整个大型图像。此外，本文还构建了一个名为LRS-VQA的新基准，包含7,333个问答对，图像长度可达27,328像素。

**Result:** 该方法在使用相同数据的情况下，在四个数据集上优于现有高分辨率策略。与现有令牌减少方法相比，所提出的方法在高分辨率设置下表现出更高的效率。

**Conclusion:** 本文通过提出一种高效的文本引导令牌剪枝方法和构建新的LRS-VQA基准，有效解决了大型视觉-语言模型在处理大型遥感图像时的效率、信息保留以及评估基准的局限性问题。

> **ai_Abstract:** 本文针对大型视觉-语言模型处理大型遥感图像时面临的效率和信息丢失问题，提出了一种文本引导的粗到细令牌剪枝方法。该方法结合动态图像金字塔，通过区域焦点模块识别关键视觉令牌，并采用分层剪枝策略避免全图处理。此外，为解决现有基准的局限性，本文还构建了新的LRS-VQA大型遥感图像视觉问答基准。实验证明，所提方法在性能和效率上均优于现有高分辨率策略和现有令牌减少方法。

> **摘要翻译:** 现有大型遥感图像（RSI）的高效视觉-语言理解既有意义又充满挑战。当前的大型视觉-语言模型（LVLMs）通常采用有限的预定义网格来处理图像，这在处理千兆像素RSI时会导致信息丢失。相反，使用无限网格会显著增加计算成本。为了在保留图像细节的同时降低计算复杂度，我们提出了一种结合动态图像金字塔（DIP）的文本引导令牌剪枝方法。我们的方法引入了：(i) 一个区域焦点模块（RFM），它利用文本感知的区域定位能力来识别关键视觉令牌；以及 (ii) 基于DIP的从粗到细图像瓦片选择和视觉令牌剪枝策略，该策略由RFM输出引导，避免直接处理整个大型图像。此外，现有用于评估LVLM在大型RSI上感知能力的基准存在问题，例如问题多样性有限和图像尺寸受限。我们构建了一个名为LRS-VQA的新基准，它包含8个类别的7,333个问答对，图像长度可达27,328像素。我们的方法在使用相同数据的情况下，在四个数据集上优于现有高分辨率策略。此外，与现有令牌减少方法相比，我们的方法在高分辨率设置下表现出更高的效率。数据集和代码可在https://github.com/VisionXLab/LRS-VQA获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [419] [MAD-AD: Masked Diffusion for Unsupervised Brain Anomaly Detection](https://arxiv.org/abs/2502.16943)
> *MAD-AD：用于无监督脑异常检测的掩蔽扩散模型*

*Farzad Beizaee, Gregory Lodygensky, Christian Desrosiers, Jose Dolz* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-23**

**Keywords:** 无监督异常检测, 脑图像, 扩散模型, 掩蔽, 异常定位

**Comment:** 

> **TL;DR:** MAD-AD提出了一种基于掩蔽扩散模型的新方法，用于无监督脑图像异常检测，通过学习正常脑结构并在推理时识别并生成异常区域的正常对应物，从而实现卓越的异常定位性能。

**AI_Comments:** MAD-AD的创新之处在于将掩蔽机制巧妙地融入扩散模型中，以实现无监督的脑异常检测。通过训练模型识别和恢复潜在空间中的噪声图像块，它能够有效地区分正常与异常结构，并生成异常区域的正常对应物，这对于医学图像诊断具有重要意义。该方法克服了标注异常数据稀缺的挑战，是医学图像分析领域的一个重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 在缺乏标签的情况下，脑图像中的无监督异常检测对于识别损伤和病理至关重要。然而，由于脑结构的复杂性和变异性以及带标注异常数据的稀缺性，医学图像中异常的准确局部化仍然具有挑战性。

**Method:** 我们提出了一种在扩散模型中整合掩蔽的新方法，利用其生成能力来学习正常脑解剖的鲁棒表示。在训练期间，模型仅处理正常脑MRI扫描，并在潜在空间中执行前向扩散过程，向随机选择的图像块特征添加噪声。通过双重目标，模型学习识别哪些图像块是噪声并恢复其原始特征。这种策略确保模型捕获正常脑结构的复杂模式，同时将潜在异常隔离为潜在空间中的噪声。在推理时，模型识别与异常对应的噪声图像块，并通过应用反向扩散过程为这些图像块生成一个正常的对应物。

**Result:** 我们的方法超越了现有的无监督异常检测技术，在生成准确的正常对应物和局部化异常方面表现出卓越的性能。

**Conclusion:** 所提出的MAD-AD方法通过结合掩蔽扩散模型，有效解决了脑图像中无监督异常检测和精确异常定位的挑战，并取得了优于现有技术的性能。

> **ai_Abstract:** 本研究提出了一种名为MAD-AD的无监督脑异常检测新方法，该方法将掩蔽机制整合到扩散模型中。通过仅在正常脑MRI数据上训练，模型学习识别和恢复受噪声影响的图像块，从而捕获正常脑结构的复杂模式并将异常视为噪声。在推理阶段，模型能够识别异常区域并生成其正常对应物。实验结果表明，MAD-AD在生成准确的正常对应物和精确局部化异常方面，性能优于现有技术。

> **摘要翻译:** 脑图像中的无监督异常检测对于在没有标签的情况下识别损伤和病理至关重要。然而，由于脑结构的固有复杂性和变异性以及带标注异常数据的稀缺性，医学图像中异常的准确局部化仍然具有挑战性。为了解决这一挑战，我们提出了一种新颖的方法，将掩蔽整合到扩散模型中，利用其生成能力来学习正常脑解剖的鲁棒表示。在训练期间，我们的模型仅处理正常脑MRI扫描，并在潜在空间中执行前向扩散过程，该过程向随机选择的图像块特征添加噪声。遵循双重目标，模型学习识别哪些图像块是噪声并恢复其原始特征。该策略确保模型捕获正常脑结构的复杂模式，同时将潜在异常隔离为潜在空间中的噪声。在推理时，模型识别与异常对应的噪声图像块，并通过应用反向扩散过程为这些图像块生成一个正常的对应物。我们的方法超越了现有的无监督异常检测技术，在生成准确的正常对应物和局部化异常方面表现出卓越的性能。代码可在hhttps://github.com/farzad-bz/MAD-AD获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [426] [Enhancing Scene Transition Awareness in Video Generation via Post-Training](https://arxiv.org/abs/2507.18046)
> *视频生成中通过后训练增强场景转换感知*

*Hanwen Shen, Jiajie Lu, Yupeng Cao, Xiaonan Yang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 视频生成, 场景转换, 后训练, TAV数据集, 多场景视频

**Comment:** 

> **TL;DR:** 现有文生视频模型难以生成多场景视频，本文提出TAV数据集并进行后训练，以提高模型对场景转换的理解和生成能力。

**AI_Comments:** 这篇论文的创新点在于提出了专门用于提升视频生成模型场景转换感知能力的数据集（TAV）和后训练方法。这对于实现更长、更连贯、更符合用户意图的多场景视频生成具有重要意义，解决了当前文生视频模型的一个核心局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI生成视频模型在单场景短视频表现良好，但难以生成具有连贯场景转换的长视频，因为模型无法从提示中推断何时需要转换。多数开源模型在单场景数据集上训练，限制了其学习多场景生成的能力。

**Method:** 提出Transition-Aware Video (TAV) 数据集，该数据集包含经过预处理的具有多个场景转换的视频片段。在此TAV数据集上进行后训练。

**Result:** 在TAV数据集上进行后训练可以提高基于提示的场景转换理解，缩小所需场景与生成场景之间的差距，并保持图像质量。

**Conclusion:** 通过在TAV数据集上进行后训练，可以有效提升视频生成模型对场景转换的感知能力，使其能够更好地生成多场景视频。

> **ai_Abstract:** 本文旨在解决当前AI视频生成模型在生成具有连贯场景转换的多场景长视频方面的不足。研究指出，现有模型主要在单场景数据上训练，缺乏对场景转换的感知能力。为解决此问题，作者提出了“转换感知视频”（TAV）数据集，该数据集包含多场景转换的视频片段。实验结果表明，在TAV数据集上进行后训练能显著提升模型对基于提示的场景转换的理解能力，有效缩小生成场景与所需场景间的差距，并保持良好的图像质量。

> **摘要翻译:** 近期AI生成视频的进展在“文本到视频”任务上表现出色，特别是在描绘单一场景的短视频方面。然而，当前模型难以生成具有连贯场景转换的较长视频，主要是因为它们无法从提示中推断何时需要进行转换。大多数开源模型在由单一场景视频片段组成的数据集上训练，这限制了它们学习和响应需要多个场景的提示的能力。开发场景转换感知对于多场景生成至关重要，因为它允许模型通过准确检测转换来识别视频并将其分割成不同的片段。为了解决这个问题，我们提出了“转换感知视频”（TAV）数据集，该数据集由经过预处理的包含多个场景转换的视频片段组成。我们的实验表明，在TAV数据集上进行后训练可以提高基于提示的场景转换理解，缩小所需场景与生成场景之间的差距，并保持图像质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [427] [Exploiting Gaussian Agnostic Representation Learning with Diffusion Priors for Enhanced Infrared Small Target Detection](https://arxiv.org/abs/2507.18260)
> *利用高斯无关表示学习与扩散先验增强红外小目标检测*

*Junyao Li, Yahao Lu, Xingyuan Guo, Xiaoyu Xian, Tiantian Wang, Yukai Shi* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 红外小目标检测, 表示学习, 扩散模型, 数据稀缺, 高斯无关

**Comment:** Submitted to Neural Networks. We propose the Gaussian Group Squeezer,
  leveraging Gaussian sampling and compression with diffusion models for
  channel-based data augmentation

> **TL;DR:** 针对红外小目标检测（ISTD）在数据稀缺下表现脆弱的问题，本文提出高斯无关表示学习（通过高斯群压缩器进行非均匀量化）和两阶段扩散模型，以增强模型鲁棒性并提高合成样本质量，从而有效提升ISTD性能。

**AI_Comments:** 本文的创新点在于提出了高斯无关表示学习和结合两阶段扩散模型来解决红外小目标检测领域长期存在的“数据荒”问题。通过非均匀量化和高质量合成数据生成，该方法显著提升了模型在实际应用中的鲁棒性和泛化能力，对资源受限环境下的ISTD具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 目前最先进的红外小目标检测（ISTD）方法高度依赖昂贵且大量的人工标注数据进行表示学习，导致在实际场景中，特别是在高质量红外数据稀缺的情况下，表现出脆弱性，挑战了现有理论。

**Method:** 首先，研究了在不同数据稀缺情境下，主流ISTD方法的检测性能变化。其次，引入高斯无关表示学习，并具体提出高斯群压缩器（Gaussian Group Squeezer），利用高斯采样和压缩进行非均匀量化，以增强ISTD模型对各种挑战的韧性。最后，引入两阶段扩散模型进行真实世界重建，通过将量化信号与真实世界分布紧密对齐，显著提升了合成样本的质量和保真度。

**Result:** 在各种数据稀缺场景下，与最先进的检测方法进行的对比评估表明，所提出的方法是有效的。

**Conclusion:** 本文提出的利用高斯无关表示学习和扩散先验的方法，能够有效增强红外小目标检测的性能，尤其是在数据稀缺的挑战下，通过提高模型韧性和合成数据质量来提升检测效果。

> **ai_Abstract:** 针对红外小目标检测（ISTD）在数据稀缺环境下性能下降的问题，本文深入研究了主流方法在数据不足时的表现，并提出了一种新颖的解决方案。该方案包括高斯无关表示学习，其中引入了高斯群压缩器以实现非均匀量化，从而增强了模型对训练样本多样性的适应性。此外，文章还利用两阶段扩散模型进行真实世界重建，通过生成高质量的合成样本来弥补数据不足。实验结果表明，在多种数据稀缺场景下，所提出的方法相较于现有最先进技术表现出显著的优越性。

> **摘要翻译:** 红外小目标检测（ISTD）在众多实际应用中发挥着至关重要的作用。为了探索性能边界，研究人员利用大量昂贵的人工标注数据进行表示学习。然而，这种方法使得最先进的ISTD方法在实际挑战中变得高度脆弱。在本文中，我们首先研究了几种主流方法在各种稀缺性（即缺乏高质量红外数据）下的检测性能变化，这些变化挑战了关于实际ISTD的流行理论。为了解决这个问题，我们引入了高斯无关表示学习。具体来说，我们提出了高斯群压缩器，利用高斯采样和压缩进行非均匀量化。通过利用多样化的训练样本，我们增强了ISTD模型应对各种挑战的韧性。然后，我们引入了两阶段扩散模型进行真实世界重建。通过将量化信号与真实世界分布紧密对齐，我们显著提升了合成样本的质量和保真度。在各种稀缺场景下，与最先进的检测方法进行的对比评估表明了所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [432] [3D Software Synthesis Guided by Constraint-Expressive Intermediate Representation](https://arxiv.org/abs/2507.18625)
> *约束表达中间表示引导的3D软件合成*

*Shuqing Li, Anson Y. Lam, Yun Peng, Wenxuan Wang, Michael R. Lyu* | **Category: cs.CV, cs.AI, cs.MM, cs.SE** | **Updated: 2025-07-24**

**Keywords:** 3D软件合成, 中间表示, 约束满足, 领域特定语言, 用户界面

**Comment:** 

> **TL;DR:** Scenethesis 是一种新的3D软件合成方法，它使用一个约束感知的中间表示（ScenethesisLang）来处理复杂的空间和语义约束，并实现了高精度和更好的视觉评估。

**AI_Comments:** Scenethesis的创新之处在于引入了ScenethesisLang作为约束表达的中间表示，从而实现了对3D软件元素的精细控制和复杂空间约束的有效处理，这对于构建真实且可控的3D交互环境至关重要。其方法论上的分阶段合成也增强了可验证性和可修改性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的2D软件自动化生成取得了成功，但3D软件生成仍未充分探索。当前方法生成3D环境时无法修改或控制特定元素，且难以处理现实世界中固有的复杂空间和语义约束。

**Method:** 本文提出了Scenethesis，一种新颖的、对需求敏感的3D软件合成方法，它在用户规范和生成的3D软件之间保持正式的可追溯性。Scenethesis基于ScenethesisLang构建，ScenethesisLang是一种领域特定语言，作为粒度约束感知的中间表示（IR），连接自然语言需求和可执行的3D软件。它既是全面的场景描述语言，允许对3D软件元素进行精细修改，又是形式化的约束表达规范语言，能够表达复杂的空间约束。通过将3D软件合成分解为在ScenethesisLang上操作的阶段，Scenethesis实现了独立验证、有针对性的修改和系统性的约束满足。

**Result:** Scenethesis准确捕获了超过80%的用户需求，满足了超过90%的硬约束，同时处理了100多个约束。与最先进的方法相比，Scenethesis在BLIP-2视觉评估分数上实现了42.8%的改进。

**Conclusion:** Scenethesis通过引入约束表达的中间表示，有效解决了3D软件合成中复杂约束处理和精细控制的挑战，显著提升了3D软件生成的准确性和质量。

> **ai_Abstract:** 本文提出了Scenethesis，一种新颖的3D软件合成方法，旨在解决现有3D生成方法在元素控制和复杂约束处理方面的不足。Scenethesis的核心是ScenethesisLang，一个约束感知的中间表示语言，它能够将自然语言需求转化为可执行的3D软件，并支持对3D元素的精细修改及复杂空间约束的表达。实验结果表明，Scenethesis能高精度地满足用户需求和硬约束，并在视觉评估上显著优于现有技术。

> **摘要翻译:** 图形用户界面（UI）软件已经从传统的二维（2D）桌面/网络/移动界面发生了根本性的转变，转向空间三维（3D）环境。虽然现有工作在自动化2D软件生成（如HTML/CSS和移动应用界面代码合成）方面取得了显著成功，但3D软件的生成仍然未被充分探索。当前3D软件生成方法通常将3D环境作为一个整体生成，无法修改或控制软件中的特定元素。此外，这些方法难以处理现实世界中固有的复杂空间和语义约束。为了解决这些挑战，我们提出了Scenethesis，一种新颖的、对需求敏感的3D软件合成方法，它在用户规范和生成的3D软件之间保持正式的可追溯性。Scenethesis建立在ScenethesisLang之上，ScenethesisLang是一种领域特定语言，作为粒度约束感知的中间表示（IR），连接自然语言需求和可执行的3D软件。它既是全面的场景描述语言，能够对3D软件元素进行精细修改，又是形式化的约束表达规范语言，能够表达复杂的空间约束。通过将3D软件合成分解为在ScenethesisLang上操作的阶段，Scenethesis实现了独立验证、有针对性的修改和系统性的约束满足。我们的评估表明，Scenethesis准确捕获了超过80%的用户需求，满足了超过90%的硬约束，同时处理了100多个约束。此外，与最先进的方法相比，Scenethesis在BLIP-2视觉评估分数上实现了42.8%的改进。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [436] [Att-Adapter: A Robust and Precise Domain-Specific Multi-Attributes T2I Diffusion Adapter via Conditional Variational Autoencoder](https://arxiv.org/abs/2503.11937)
> *Att-Adapter：一种基于条件变分自编码器的鲁棒精确领域特定多属性T2I扩散适配器*

*Wonwoong Cho, Yan-Ying Chen, Matthew Klenk, David I. Inouye, Yanxia Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** T2I扩散模型, 属性控制, Att-Adapter, 条件变分自编码器, 多属性控制

**Comment:** ICCV'25 (Highlight), The project page is available at
  https://tri-mac.github.io/att-adapter/

> **TL;DR:** Att-Adapter通过条件变分自编码器实现对T2I扩散模型中多个连续属性的精确控制。

**AI_Comments:** Att-Adapter的创新点在于其即插即用的模块设计，以及通过解耦交叉注意力和CVAE实现多属性的精细控制和解耦，同时克服了对配对数据依赖的限制。这对于T2I生成模型在实际应用中实现更灵活和精确的条件控制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有T2I扩散模型在新的领域中，难以通过纯文本指导同时精确控制多个连续属性（如眼睛开合度、汽车宽度）。

**Method:** 提出Att-Adapter，一个即插即用模块，用于预训练扩散模型中的精细多属性控制。它从无配对、含多视觉属性的样本图像中学习一个控制适配器，利用解耦交叉注意力模块协调多领域属性与文本条件，并引入条件变分自编码器（CVAE）以缓解过拟合。

**Result:** 在两个公共数据集上的评估表明，Att-Adapter在控制连续属性方面优于所有基于LoRA的基线方法。此外，该方法实现了更宽的控制范围，并改善了多个属性之间的解耦，超越了基于StyleGAN的技术。它不需要配对合成数据进行训练，并且易于扩展到单个模型中的多个属性。

**Conclusion:** Att-Adapter提供了一种鲁棒、精确且灵活的方法，用于在文本到图像扩散模型中控制多个连续属性，且无需配对数据。

> **ai_Abstract:** 本文提出了Att-Adapter，一个即插即用的模块，旨在解决T2I扩散模型在新的领域中难以精确控制多个连续属性的问题。Att-Adapter通过学习一个控制适配器，结合解耦交叉注意力和条件变分自编码器（CVAE），实现了对预训练扩散模型的细粒度多属性控制，且无需配对训练数据。实验证明，Att-Adapter在控制连续属性方面优于LoRA和StyleGAN基线，并提供了更广的控制范围和更好的属性解耦。

> **摘要翻译:** 文本到图像（T2I）扩散模型在生成高质量图像方面取得了显著的性能。然而，在新的领域中（例如，像眼睛开合度或汽车宽度这样的数值），仅通过文本指导实现对连续属性，特别是同时控制多个属性的精确控制仍然是一个重大挑战。为了解决这个问题，我们引入了属性（Att）适配器，这是一种新颖的即插即用模块，旨在使预训练扩散模型能够进行细粒度的多属性控制。我们的方法从一组可以是非配对且包含多个视觉属性的样本图像中学习一个单一的控制适配器。Att-Adapter利用解耦的交叉注意力模块自然地协调多个领域属性与文本条件。我们进一步将条件变分自编码器（CVAE）引入Att-Adapter，以减轻过拟合，匹配视觉世界的多元性质。在两个公共数据集上的评估表明，Att-Adapter在控制连续属性方面优于所有基于LoRA的基线方法。此外，我们的方法实现了更宽的控制范围，并改善了多个属性之间的解耦，超越了基于StyleGAN的技术。值得注意的是，Att-Adapter是灵活的，训练不需要配对的合成数据，并且易于在单个模型中扩展到多个属性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [438] [Information Entropy-Based Framework for Quantifying Tortuosity in Meibomian Gland Uneven Atrophy](https://arxiv.org/abs/2507.18135)
> *基于信息熵的睑板腺不均匀萎缩弯曲度量化框架*

*Kesheng Wang, Xiaoyu Chen, Chunlei He, Fenfen Li, Xinxin Yu, Dexing Kong, Shoujun Huang, Qi Dai* | **Category: cs.CV, cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** 信息熵, 弯曲度量化, 睑板腺萎缩, 医学图像分析, 参考曲线

**Comment:** This manuscript contains 7 figures. All comments are welcome

> **TL;DR:** 本文提出了一种基于信息熵的弯曲度量化新框架，通过与参考曲线比较来评估曲线弯曲度，并成功应用于睑板腺萎缩均匀性评估，显示出在医学诊断中的临床应用潜力。

**AI_Comments:** 该研究创新性地将信息熵引入弯曲度量化，克服了传统方法依赖理想直线比较的局限性，通过与生物学合理的参考曲线比较，提供了更稳健和客观的评估。其在睑板腺萎缩评估中的应用展示了良好的临床实用性，具有推广到其他医学形态评估的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在医学图像分析中，曲线弯曲度的精确量化对于各种疾病的辅助诊断和病理评估至关重要。传统方法存在局限性，例如依赖理想化的直线比较。因此，需要一种更稳健、客观的弯曲度评估指标。

**Method:** 本文提出了一种基于信息熵的弯曲度量化框架，该框架整合了概率建模、熵理论以及曲线数据的域变换。与传统方法不同，它通过将目标曲线与指定参考曲线进行比较来评估弯曲度。首先进行数值模拟实验评估其稳定性和有效性，随后应用于量化睑板腺萎缩的空间均匀性，并分析蠕形螨阴性与阳性患者组之间的差异。

**Result:** 数值模拟实验初步评估了方法的稳定性与有效性。将该框架应用于睑板腺萎缩均匀性量化时，结果显示蠕形螨阴性组和蠕形螨阳性组在基于弯曲度的均匀性方面存在显著差异，曲线下面积为0.8768，敏感性为0.75，特异性为0.93。

**Conclusion:** 所提出的基于信息熵的弯曲度量化框架在曲线弯曲度分析中具有临床实用性，并有望成为医学诊断中定量形态评估的通用工具，尤其适用于存在生物学合理参考曲线的医学数据。

> **ai_Abstract:** 本文提出了一种新颖的基于信息熵的弯曲度量化框架，通过概率建模、熵理论和域变换，将目标曲线与参考曲线进行比较来评估弯曲度。该方法通过数值模拟验证了其稳定性和有效性。将其应用于睑板腺不均匀萎缩的量化，成功区分了蠕形螨阴性和阳性患者组，显示出良好的诊断性能（AUC 0.8768，敏感性 0.75，特异性 0.93），证明了其在医学诊断中作为通用形态评估工具的潜力。

> **摘要翻译:** 在医学图像分析领域，曲线弯曲度的精确量化在各种疾病的辅助诊断和病理评估中起着关键作用。在本研究中，我们提出了一种新颖的弯曲度量化框架，并通过评估睑板腺萎缩的均匀性来证明其有效性，作为代表性应用场景。
我们引入了一种基于信息熵的弯曲度量化框架，该框架将概率建模与熵理论相结合，并融入了曲线数据的域变换。与曲率或弧弦比等传统方法不同，这种方法通过将目标曲线与指定的参考曲线进行比较来评估目标曲线的弯曲度。因此，它更适用于医学数据中的弯曲度评估任务，因为在医学数据中可以获得生物学上合理的参考曲线，从而提供更稳健和客观的评估指标，而无需依赖理想化的直线比较。
首先，我们进行了数值模拟实验，初步评估了该方法的稳定性和有效性。随后，该框架被应用于量化睑板腺萎缩的空间均匀性，并分析了蠕形螨阴性患者组和蠕形螨阳性患者组之间这种均匀性的差异。结果表明，两组在基于弯曲度的均匀性方面存在显著差异，曲线下面积为0.8768，敏感性为0.75，特异性为0.93。这些发现突出了所提出的框架在曲线弯曲度分析中的临床实用性及其作为医学诊断中定量形态评估通用工具的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [441] [Captain Cinema: Towards Short Movie Generation](https://arxiv.org/abs/2507.18634)
> *电影船长：迈向短片电影生成*

*Junfei Xiao, Ceyuan Yang, Lvmin Zhang, Shengqu Cai, Yang Zhao, Yuwei Guo, Gordon Wetzstein, Maneesh Agrawala, Alan Yuille, Lu Jiang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 短片电影生成, 关键帧规划, 视频合成, 多模态扩散变换器, 长上下文学习

**Comment:** Under review. Project page: https://thecinema.ai

> **TL;DR:** Captain Cinema是一个短片电影生成框架，它首先根据文本描述生成关键帧以确保叙事连贯性，然后通过视频合成模型生成关键帧之间的时空动态，并引入交错训练策略以实现高效高质量的电影生成。

**AI_Comments:** 该论文提出了一种新颖的两阶段电影生成框架，通过“顶层关键帧规划”确保长程连贯性，并通过“底层视频合成”生成细节，这种分解方法是其创新点。特别值得注意的是，为长上下文视频数据引入的交错训练策略对于生成多场景长叙事作品至关重要，提高了生成效率和质量。这项工作在文本到视频生成领域具有重要意义，尤其是在自动化内容创作方面。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的动机是实现短片电影的自动化生成，解决现有方法在处理长叙事和保证视觉与叙事连贯性方面的挑战。

**Method:** Captain Cinema框架包括两个主要步骤：1. 顶层关键帧规划：根据详细的电影故事情节文本描述，生成一系列关键帧，以确保故事线和视觉（如场景和角色）的长程连贯性。2. 底层视频合成：利用支持长上下文学习的视频合成模型，以这些关键帧作为条件信号，生成它们之间的时空动态。为了支持多场景长叙事电影作品的稳定高效生成，该方法引入了一种针对长上下文视频数据专门调整的多模态扩散变换器（MM-DiT）的交错训练策略，并在一个专门策划的电影数据集上进行训练。

**Result:** 实验结果表明，Captain Cinema在自动化创建高质量、高效率、视觉连贯且叙事一致的短片电影方面表现出色。

**Conclusion:** Captain Cinema成功地提供了一个能够根据文本描述生成高质量、视觉连贯且叙事一致的短片电影的生成框架。

> **ai_Abstract:** Captain Cinema是一个创新的短片电影生成框架，它将电影生成分解为两个阶段：首先进行自上而下的关键帧规划，根据文本描述生成连贯的叙事和视觉关键帧；然后进行自下而上的视频合成，利用多模态扩散变换器（MM-DiT）和专门的交错训练策略，生成关键帧之间的时空动态。该方法旨在高效、高质量地自动化创建视觉连贯且叙事一致的短片电影。

> **摘要翻译:** 我们提出了Captain Cinema，一个用于短片电影生成的框架。给定一个详细的电影故事情节文本描述，我们的方法首先生成一系列关键帧，勾勒出整个叙事，这确保了故事情节和视觉外观（例如，场景和角色）的长程连贯性。我们将此步骤称为自上而下的关键帧规划。然后，这些关键帧作为视频合成模型的条件信号，该模型支持长上下文学习，以生成它们之间的时空动态。此步骤被称为自下而上的视频合成。为了支持多场景长叙事电影作品的稳定高效生成，我们引入了一种专门针对长上下文视频数据调整的多模态扩散变换器（MM-DiT）的交错训练策略。我们的模型在一个专门策划的电影数据集上进行训练，该数据集包含交错的数据对。我们的实验表明，Captain Cinema在高质量、高效率地自动化创建视觉连贯且叙事一致的短片电影方面表现良好。项目页面：https://thecinema.ai

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [446] [PDB-Eval: An Evaluation of Large Multimodal Models for Description and Explanation of Personalized Driving Behavior](https://arxiv.org/abs/2507.18447)
> *PDB-Eval：大型多模态模型在个性化驾驶行为描述与解释方面的评估*

*Junda Wu, Jessica Echterhoff, Kyungtae Han, Amr Abdelraouf, Rohit Gupta, Julian McAuley* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 个性化驾驶行为, 大型多模态模型, 基准, 驾驶理解, PDB-Eval

**Comment:** 

> **TL;DR:** 本文提出了PDB-Eval基准，用于评估和调整大型多模态模型，以更好地理解和解释个性化驾驶行为，显著提高了其在驾驶相关任务上的性能。

**AI_Comments:** 该论文的创新之处在于提出了一个专门针对个性化驾驶行为理解的综合基准PDB-Eval，并引入了PDB-X和PDB-QA来解决现有大型多模态模型在驾驶领域应用中的局限性。其重要性体现在通过微调显著提高了MLLMs在驾驶行为描述、解释和预测方面的能力，为未来智能驾驶辅助系统和自动驾驶技术的发展提供了更强的感知和推理基础。PDB-QA作为一种通用学习任务，在不损害模型泛化能力的前提下弥合领域差距，这一点也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 理解驾驶员行为和意图对于风险评估和事故预防至关重要，能增强安全和驾驶辅助系统的有效性。然而，现有数据集在基于外部视觉证据描述和解释一般车辆运动方面存在局限性。

**Method:** 本文引入了一个名为PDB-Eval的基准，用于详细理解个性化驾驶行为，并使大型多模态模型（MLLMs）与驾驶理解和推理对齐。PDB-Eval包含PDB-X和PDB-QA两个主要组件。PDB-X用于评估MLLMs对时间驾驶场景的理解，旨在从外部视图中找到有效的视觉证据来解释驾驶员的内部行为。PDB-QA被提出作为视觉解释问答任务，用于MLLM指令微调，以弥合领域差距而不损害MLLMs的泛化能力。

**Result:** 评估表明，对MLLMs进行细粒度描述和解释的微调可以有效弥合MLLMs与驾驶领域之间的鸿沟，使问答任务的零样本性能提高高达73.2%。在Brain4Cars的转向意图预测任务中，性能提升高达12.5%；在AIDE的所有任务中，性能持续提升高达11.0%。

**Conclusion:** 通过在PDB-Eval基准上对大型多模态模型进行微调，可以显著提高其在个性化驾驶行为理解和相关预测识别任务上的性能，有效弥合模型与驾驶领域之间的差距。

> **ai_Abstract:** 本文提出了PDB-Eval，一个专门用于评估和提升大型多模态模型（MLLMs）理解和解释个性化驾驶行为的基准。面对现有数据集在驾驶行为描述和解释方面的不足，PDB-Eval通过PDB-X（评估时间驾驶场景理解）和PDB-QA（视觉解释问答任务，用于MLLM微调）两个组件来解决。实验结果表明，在PDB-Eval上对MLLMs进行微调能显著提高其在驾驶相关问答任务上的零样本性能，并在其他驾驶行为预测和识别任务中也表现出显著提升，有效弥合了MLLMs与驾驶领域之间的差距。

> **摘要翻译:** 理解驾驶员的行为和意图对于潜在风险评估和早期事故预防至关重要。安全和驾驶辅助系统可以根据个体驾驶员的行为进行定制，显著提高其有效性。然而，现有数据集在基于外部视觉证据描述和解释一般车辆运动方面存在局限性。本文引入了一个基准，PDB-Eval，用于详细理解个性化驾驶行为，并使大型多模态模型（MLLMs）与驾驶理解和推理对齐。我们的基准由两个主要组件组成，PDB-X和PDB-QA。PDB-X可以评估MLLMs对时间驾驶场景的理解。我们的数据集旨在从外部视图中找到有效的视觉证据来解释驾驶员的内部行为。为了使MLLMs的推理能力与驾驶任务对齐，我们提出了PDB-QA作为视觉解释问答任务，用于MLLM指令微调。作为像MLLMs这样的生成模型的通用学习任务，PDB-QA可以弥合领域差距而不损害MLLMs的泛化能力。我们的评估表明，对细粒度描述和解释进行MLLMs微调可以有效弥合MLLMs与驾驶领域之间的鸿沟，这使得问答任务的零样本性能提高了高达73.2%。我们进一步评估了在Brain4Cars的意图预测和AIDE的识别任务中，在PDB-X上微调的MLLMs。我们观察到在Brain4Cars的转向意图预测任务中，性能提高了高达12.5%，并且在AIDE的所有任务中，性能持续提高了高达11.0%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [448] [Robust sensitivity control in digital pathology via tile score distribution matching](https://arxiv.org/abs/2502.20144)
> *数字病理中基于瓦片分数分布匹配的鲁棒敏感性控制*

*Arthur Pignet, John Klein, Genevieve Robin, Antoine Olivier* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 数字病理, 敏感性控制, 分布偏移, 最优传输, 多实例学习

**Comment:** Camera ready version. Accepted at MICCAI 2025

> **TL;DR:** 本文提出了一种基于最优传输和多实例学习（MIL）的新方法，用于在数字病理学中实现鲁棒的敏感性控制，即使在存在分布偏移的情况下，也只需少量校准样本即可实现可靠部署。

**AI_Comments:** 该论文为数字病理学中的一个关键实际问题提供了一个创新解决方案：确保模型在不同临床环境中保持一致的性能，特别是敏感性。通过专注于敏感性控制而非仅聚合指标（如AUC），并且仅需少量校准样本，该方法提供了一个高度实用且可部署的解决方案，这对于AI在病理学中的广泛应用具有重要意义。其结合最优传输和MIL来解决这一特定问题的贡献是新颖的。

<details>
  <summary>Details</summary>

**Motivation:** 将数字病理模型部署到各个医疗中心面临着由于分布偏移带来的挑战。尽管域泛化技术提高了模型在聚合性能（如AUC）方面的迁移能力，但临床法规通常要求控制其他指标的迁移能力，例如预设的敏感性水平。

**Method:** 本文引入了一种基于最优传输和多实例学习（MIL）的新颖方法，用于控制全玻片图像（WSI）分类模型的敏感性。

**Result:** 该方法在多个队列和任务中得到验证，只需少量校准样本即可实现鲁棒的敏感性控制。

**Conclusion:** 该方法为计算病理系统的可靠部署提供了实用的解决方案。

> **ai_Abstract:** 本文旨在解决数字病理模型在不同医疗中心部署时因分布偏移而面临的挑战，特别关注临床法规要求的敏感性控制。研究提出了一种基于最优传输和多实例学习（MIL）的新颖方法，用于实现全玻片图像分类模型的鲁棒敏感性控制。该方法在多个队列和任务中得到验证，表明它仅需少量校准样本即可实现可靠的系统部署。

> **摘要翻译:** 将数字病理模型部署到各个医疗中心面临着由于分布偏移带来的挑战。域泛化领域的最新进展在通过曲线下面积（AUC）衡量的聚合性能方面提高了模型的迁移能力。然而，临床法规通常要求控制其他指标的迁移能力，例如预设的敏感性水平。我们引入了一种基于最优传输和多实例学习（MIL）的新颖方法，用于控制全玻片图像（WSI）分类模型的敏感性。我们的方法在多个队列和任务中得到验证，只需少量校准样本即可实现鲁棒的敏感性控制，为计算病理系统的可靠部署提供了实用的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [462] [Lumina-mGPT 2.0: Stand-Alone AutoRegressive Image Modeling](https://arxiv.org/abs/2507.17801)
> *Lumina-mGPT 2.0：独立自回归图像建模*

*Yi Xin, Juncheng Yan, Qi Qin, Zhen Li, Dongyang Liu, Shicheng Li, Victor Shea-Jay Huang, Yupeng Zhou, Renrui Zhang, Le Zhuo, Tiancheng Han, Xiaoqing Sun, Siqi Luo, Mengmeng Wang, Bin Fu, Yuewen Cao, Hongsheng Li, Guangtao Zhai, Xiaohong Liu, Yu Qiao, Peng Gao* | **Category: cs.CV** | **Updated: 2025-07-23**

**Keywords:** 自回归模型, 图像生成, Lumina-mGPT 2.0, 多模态生成, 扩散模型

**Comment:** Tech Report, 23 pages, 11 figures, 7 tables

> **TL;DR:** Lumina-mGPT 2.0是一个从头开始训练的独立自回归模型，在图像生成质量上与SOTA扩散模型相当，并能处理多任务。

**AI_Comments:** Lumina-mGPT 2.0的创新在于其完全从头训练的独立自回归架构，这打破了对预训练组件的依赖，提供了更大的设计自由度。其重要性在于证明了自回归模型在高质量图像生成方面可以与扩散模型竞争，甚至在多任务处理上展现出更强的统一性。该模型在保持自回归模型固有灵活性的同时，通过高效解码策略提升了实用性，有望成为多模态生成领域的重要基础模型。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像生成方法依赖预训练组件或混合架构，限制了设计自由和许可。本文旨在通过独立自回归模型Lumina-mGPT 2.0来振兴自回归范式，实现高质量图像生成。

**Method:** Lumina-mGPT 2.0是一个独立的、仅解码器的自回归模型，完全从头开始训练。它采用统一的tokenization方案来处理多种任务，并结合了推理时缩放和推测性Jacobi采样等高效解码策略以提高质量和速度。

**Result:** Lumina-mGPT 2.0在图像生成质量上与DALL-E 3和SANA等SOTA扩散模型相当，并在标准文本到图像基准测试（如GenEval, DPG）中匹配甚至超越扩散模型。其多任务能力在Graph200K基准测试中表现出色，能够无缝处理主题驱动生成、图像编辑、可控合成和密集预测等任务。

**Conclusion:** Lumina-mGPT 2.0是一个强大、灵活的基础模型，适用于统一的多模态生成。

> **ai_Abstract:** Lumina-mGPT 2.0是一款全新的独立自回归图像生成模型，完全从头训练，旨在超越现有依赖预训练组件的方法。它在图像生成质量上与SOTA扩散模型（如DALL-E 3）持平，同时保持自回归模型的灵活性。该模型采用统一的tokenization和高效解码策略，能够处理多种任务，包括主题驱动生成、图像编辑和密集预测，并在多项基准测试中表现优异，被定位为统一多模态生成的强大基础模型。

> **摘要翻译:** 我们提出了Lumina-mGPT 2.0，一个独立的、仅解码器的自回归模型，它重新审视并振兴了自回归范式，以实现高质量图像生成及更广阔的应用。与依赖预训练组件或混合架构的现有方法不同，Lumina-mGPT 2.0完全从头开始训练，从而实现了不受限制的架构设计和许可自由。它在生成质量上与DALL-E 3和SANA等最先进的扩散模型相当，同时保留了自回归建模固有的灵活性和可组合性。我们统一的tokenization方案使模型能够在单个生成框架内无缝处理广泛的任务——包括主题驱动生成、图像编辑、可控合成和密集预测。为了进一步提高可用性，我们结合了高效的解码策略，如推理时缩放和推测性Jacobi采样，分别用于提高质量和速度。对标准文本到图像基准测试（例如GenEval、DPG）的广泛评估表明，Lumina-mGPT 2.0不仅与基于扩散的模型相匹配，在某些情况下甚至超越它们。此外，我们在Graph200K基准测试上证实了其多任务能力，原生的Lumina-mGPT 2.0表现异常出色。这些结果将Lumina-mGPT 2.0定位为用于统一多模态生成的强大、灵活的基础模型。我们已在https://github.com/Alpha-VLLM/Lumina-mGPT-2.0发布了训练细节、代码和模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [463] [Dissecting the Dental Lung Cancer Axis via Mendelian Randomization and Mediation Analysis](https://arxiv.org/abs/2507.18287)
> *通过孟德尔随机化和中介分析剖析牙齿-肺癌轴*

*Wenran Zhang, Huihuan Luo, Linda Wei, Ping Nie, Yiqun Wu, Dedong Yu* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 龋齿, 肺癌, 孟德尔随机化, 中介分析, 肺功能

**Comment:** 

> **TL;DR:** 本研究利用孟德尔随机化方法，发现龋齿与肺癌风险之间存在显著的正向因果关系，并部分通过肺功能下降介导，而牙周炎则没有发现因果效应。

**AI_Comments:** 这项研究通过孟德尔随机化方法，有效解决了观察性研究中因果关系不确定的问题，为龋齿与肺癌之间的因果联系提供了强有力的遗传学证据。其创新之处在于不仅建立了因果链，还通过中介分析揭示了肺功能下降在其中的作用机制。研究结果具有重要的公共卫生意义，提示在癌症预防中应重视口腔健康，特别是龋齿的防治。

<details>
  <summary>Details</summary>

**Motivation:** 观察性研究表明口腔疾病（牙周炎、龋齿）与肺癌之间存在关联，但因果关系尚不确定。本研究旨在探究这些口腔特征与肺癌亚型之间的因果关系，并评估肺功能在其中的中介作用。

**Method:** 本研究采用两样本孟德尔随机化 (MR) 方法，探讨牙齿特征（牙周炎、龋齿）与肺癌亚型之间的因果关系。遗传工具来源于最大规模的全基因组关联研究，包括487,823例龋齿和506,594例牙周炎病例数据，以及来自肺癌跨学科研究联盟的肺癌数据。主要分析方法是逆方差加权法；肺功能的中介作用通过Delta方法评估。

**Result:** 研究结果显示，龋齿对整体肺癌及其亚型具有显著的正向因果效应。具体而言，龋齿发病率每增加一个标准差，鳞状细胞肺癌的风险增加188.0% (OR = 2.880, 95% CI = 1.236--6.713, p = 0.014)，其中部分通过用力肺活量 (FVC) 和一秒用力呼气量 (FEV1) 的下降介导，分别占总效应的5.124%和5.890%。未发现牙周炎与肺癌之间存在因果效应。

**Conclusion:** 这些发现强调了龋齿在肺癌风险中的因果作用，并支持将口腔护理和肺功能监测整合到癌症预防策略中。

> **ai_Abstract:** 本研究利用两样本孟德尔随机化和中介分析，旨在探究口腔疾病（牙周炎、龋齿）与肺癌之间的因果关系及肺功能的中介作用。研究发现，龋齿与肺癌（特别是鳞状细胞肺癌）之间存在显著的正向因果关系，并且这种关联部分通过肺功能下降介导。具体数据显示，龋齿发病率增加一个标准差，鳞状细胞肺癌风险增加188%，其中FVC和FEV1的下降分别介导了5.124%和5.890%的总效应。然而，牙周炎与肺癌之间未发现因果关系。这些结果强调了龋齿在肺癌风险中的因果作用，并建议将口腔护理和肺功能监测纳入癌症预防策略。

> **摘要翻译:** 牙周炎和龋齿是全球影响数十亿人的常见口腔疾病。尽管观察性研究表明这些疾病与肺癌之间存在关联，但因果关系仍不确定。本研究使用两样本孟德尔随机化 (MR) 方法，探讨牙齿特征（牙周炎、龋齿）与肺癌亚型之间的因果关系，并评估肺功能的中介作用。遗传工具来源于最大规模的全基因组关联研究，包括487,823例龋齿和506,594例牙周炎病例数据，以及来自肺癌跨学科研究联盟的肺癌数据。逆方差加权法是主要的分析方法；肺功能的中介作用通过Delta方法评估。结果显示，龋齿对整体肺癌及其亚型具有显著的正向因果效应。具体而言，龋齿发病率每增加一个标准差，鳞状细胞肺癌的风险增加188.0% (OR = 2.880, 95% CI = 1.236--6.713, p = 0.014)，其中部分通过用力肺活量 (FVC) 和一秒用力呼气量 (FEV1) 的下降介导，分别占总效应的5.124%和5.890%。未发现牙周炎与肺癌之间存在因果效应。这些发现强调了龋齿在肺癌风险中的因果作用，并支持将口腔护理和肺功能监测整合到癌症预防策略中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [466] [Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning](https://arxiv.org/abs/2503.12972)
> *视觉与语言对齐：免标注多模态知识图谱构建以增强大型语言模型推理*

*Junming Liu, Siyuan Meng, Yanting Gao, Song Mao, Pinlong Cai, Guohang Yan, Yirong Chen, Zilin Bian, Ding Wang, Botian Shi* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 多模态知识图谱, 大型语言模型, 视觉-语言对齐, 免标注, 跨模态推理

**Comment:** 14 pages, 7 figures, 6 tables; Accepted to ICCV 2025

> **TL;DR:** 本文提出了VaLiK，一种无需手动标注的多模态知识图谱（MMKG）构建方法，通过将预训练的视觉-语言模型（VLMs）级联并引入跨模态相似性验证机制，有效增强了LLMs的多模态推理能力。

**AI_Comments:** 本文的创新点在于提出了VaLiK，一种无需手动标注即可构建多模态知识图谱的方法，有效解决了传统MMKG构建中语义狭窄和噪声问题。通过结合预训练VLMs和跨模态相似性验证，该方法为LLMs的多模态推理提供了更丰富、更准确的知识补充，具有重要的实践意义。其存储效率的提升也是一个亮点。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在多模态推理中面临知识不完整和幻觉问题，现有文本知识图谱（KGs）因模态隔离而无法完全解决。多模态知识图谱（MMKGs）虽有潜力，但其构建受限于手动文本标注的语义狭窄和视觉-语义实体链接中的固有噪声。

**Method:** 本文提出了Vision-align-to-Language integrated Knowledge Graph (VaLiK) 方法。该方法通过级联预训练的视觉-语言模型（VLMs）将图像特征转换为包含图像特定信息的描述，并开发了跨模态相似性验证机制来量化语义一致性，以过滤噪声。即使没有手动标注的图像描述，也能构建MMKG。

**Result:** VaLiK在保持直接实体到图像链接能力的同时，实现了显著的存储效率提升。在多模态推理任务上的实验结果表明，用VaLiK增强的LLMs优于现有最先进的模型。

**Conclusion:** VaLiK提供了一种有效且高效的免标注多模态知识图谱构建方法，显著提升了大型语言模型的多模态推理能力，并解决了传统MMKG构建中的挑战。

> **ai_Abstract:** 本文提出了一种名为VaLiK的新型多模态知识图谱（MMKG）构建方法，旨在解决大型语言模型（LLMs）在多模态推理中面临的知识不完整和幻觉问题。VaLiK通过级联预训练的视觉-语言模型（VLMs）将图像特征转化为文本描述，并引入跨模态相似性验证机制来过滤噪声，实现了无需手动标注的MMKG构建。实验证明，VaLiK不仅提高了存储效率，还显著增强了LLMs在多模态推理任务上的表现，超越了现有最先进的模型。

> **摘要翻译:** 大型语言模型（LLMs）中的多模态推理面临知识不完整和幻觉问题，而文本知识图谱（KGs）由于其模态隔离只能部分缓解这些挑战。尽管多模态知识图谱（MMKGs）有望增强跨模态理解，但其实际构建受到手动文本标注的语义狭窄和视觉-语义实体链接中固有噪声的阻碍。在本文中，我们提出了Vision-align-to-Language integrated Knowledge Graph (VaLiK)，这是一种构建MMKG的新颖方法，通过跨模态信息补充来增强LLMs的推理能力。具体来说，我们级联预训练的视觉-语言模型（VLMs）以将图像特征与文本对齐，将它们转换为封装图像特定信息的描述。此外，我们开发了一种跨模态相似性验证机制来量化语义一致性，有效地过滤掉特征对齐过程中引入的噪声。即使没有手动标注的图像描述，仅凭这些精炼的描述也足以构建MMKG。与传统MMKG构建范式相比，我们的方法在保持直接实体到图像链接能力的同时，实现了显著的存储效率提升。多模态推理任务上的实验结果表明，用VaLiK增强的LLMs优于现有最先进的模型。我们的代码已发布在https://github.com/Wings-Of-Disaster/VaLiK。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [474] [BokehDiff: Neural Lens Blur with One-Step Diffusion](https://arxiv.org/abs/2507.18060)
> *散景扩散：一步扩散的神经镜头模糊*

*Chengxuan Zhu, Qingnan Fan, Qi Zhang, Jinwei Chen, Huaqi Zhang, Chao Xu, Boxin Shi* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 镜头模糊, 扩散模型, 神经渲染, 自注意力, 散景

**Comment:** Accepted by ICCV 2025

> **TL;DR:** BokehDiff是一种新颖的镜头模糊渲染方法，利用一步扩散模型和物理启发式自注意力机制，克服了传统方法在深度估计上的限制，生成了物理准确且视觉吸引人的高质量散景效果。

**AI_Comments:** 该论文的创新点在于结合了生成扩散模型与物理启发式自注意力机制来解决镜头模糊渲染中的深度估计伪影问题。其一步推理方案和合成数据的方法也提高了效率和数据可用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法受限于深度估计的准确性，在深度不连续处会产生伪影。

**Method:** BokehDiff引入了一种新颖的镜头模糊渲染方法，利用生成扩散先验。它采用了一个物理启发式的自注意力模块，该模块与图像形成过程对齐，并结合了深度相关的模糊圈约束和自遮挡效应。该方法将扩散模型调整为一步推理方案，且不引入额外噪声。为了解决可扩展配对数据不足的问题，提出使用扩散模型合成具有透明度的真实感前景。

**Result:** 该方法实现了物理准确、视觉吸引人的结果，具有高质量和高保真度。

**Conclusion:** BokehDiff成功地克服了传统方法在深度估计上的限制，通过结合生成扩散模型和物理启发式自注意力，实现了高质量、高保真且物理准确的镜头模糊渲染。

> **ai_Abstract:** BokehDiff提出了一种基于一步扩散模型的新型神经镜头模糊渲染方法，旨在克服传统方法因深度估计不准确而产生的伪影问题。该方法结合了物理启发式自注意力模块，模拟了图像形成过程中的模糊圈和自遮挡效应。通过将扩散模型应用于单步推理，并在数据不足时合成真实感前景，BokehDiff能够生成物理准确、视觉效果好且高质量的镜头模糊效果。

> **摘要翻译:** 我们引入了BokehDiff，一种新颖的镜头模糊渲染方法，借助生成扩散先验，实现了物理准确且视觉吸引人的效果。以往的方法受限于深度估计的准确性，在深度不连续处会产生伪影。我们的方法采用了一个受物理启发的自注意力模块，该模块与图像形成过程对齐，并结合了深度相关的模糊圈约束和自遮挡效应。我们将扩散模型适应于一步推理方案，且不引入额外噪声，从而实现了高质量和高保真度的结果。为了解决可扩展配对数据不足的问题，我们提出使用扩散模型合成具有透明度的真实感前景，以平衡真实性和场景多样性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [478] [Learning to Generalize without Bias for Open-Vocabulary Action Recognition](https://arxiv.org/abs/2502.20158)
> *学习无偏泛化以实现开放词汇动作识别*

*Yating Yu, Congqi Cao, Yifan Zhang, Yanning Zhang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 开放词汇动作识别, 元学习, 静态去偏, CLIP, 泛化

**Comment:** Accepted by ICCV2025 (Highlight)

> **TL;DR:** 现有基于CLIP的视频学习器因静态偏差泛化能力受损，本文提出Open-MeDe元优化框架，通过元学习和跨批次元优化解决该问题，并在上下文内和上下文外场景中均取得SOTA表现。

**AI_Comments:** 这篇论文的创新点在于从元学习的角度解决CLIP在视频动作识别中引入的静态偏差问题，通过跨批次元优化和不依赖CLIP正则化，有效地提升了模型对新颖、上下文外动作的泛化能力，为开放词汇动作识别提供了一个新颖且有效的方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于CLIP的视频学习器在开放词汇动作识别中，因CLIP的静态偏差，容易过拟合到捷径静态特征，从而损害其泛化能力，尤其是在新颖的上下文外动作上。

**Method:** 提出Open-MeDe，一个带有静态去偏的元优化框架。它采用元学习方法，通过跨批次元优化方案，显式鼓励视频学习器快速泛化到任意后续数据，并通过虚拟评估平滑优化过程。优化过程中不使用CLIP正则化，隐式减轻了视频元学习器固有的静态偏差。此外，对优化轨迹进行自集成以获得泛化性强的最优参数。

**Result:** Open-MeDe不仅超越了为上下文内开放词汇动作识别量身定制的现有SOTA正则化方法，而且在上下文外场景中表现显著优异。

**Conclusion:** Open-MeDe通过元学习和去偏方法，成功解决了基于CLIP的视频学习器在开放词汇动作识别中的泛化能力受损问题，尤其是在面对新颖的上下文外动作时，展现出卓越的性能。

> **ai_Abstract:** 本文提出Open-MeDe，一个新颖的元优化框架，旨在解决基于CLIP的视频学习器在开放词汇动作识别中因静态偏差导致的泛化能力受损问题。Open-MeDe采用元学习方法，通过跨批次元优化和自集成策略，有效消除静态偏差并提升模型泛化能力。实验证明，Open-MeDe在上下文内和上下文外开放词汇动作识别任务上均显著优于现有SOTA方法。

> **摘要翻译:** 利用CLIP有效的视觉-文本对齐和静态泛化能力，最近的视频学习器采用CLIP初始化，并进一步进行正则化或重组，以实现在上下文中的开放词汇动作识别泛化。然而，由于CLIP的静态偏差，这些视频学习器倾向于过拟合到捷径静态特征，从而损害其泛化能力，特别是对于新颖的上下文外动作。为了解决这个问题，我们引入了Open-MeDe，一个新颖的带有静态去偏的元优化框架，用于开放词汇动作识别。从泛化的全新视角来看，Open-MeDe采用元学习方法，以经济高效的方式改进已知到开放的泛化和图像到视频的去偏。具体来说，Open-MeDe引入了一种跨批次元优化方案，通过虚拟评估明确鼓励视频学习器快速泛化到任意后续数据，从而引导更平滑的优化前景。实际上，优化过程中无需CLIP正则化隐式减轻了视频元学习器固有的静态偏差。我们进一步对优化轨迹进行自集成，以获得通用的最优参数，从而实现对上下文内和上下文外新数据的鲁棒泛化。广泛的评估表明，Open-MeDe不仅超越了为上下文内开放词汇动作识别量身定制的现有最先进的正则化方法，而且在上下文外场景中也表现显著优异。代码已在https://github.com/Mia-YatingYu/Open-MeDe 发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [482] [CRUISE: Cooperative Reconstruction and Editing in V2X Scenarios using Gaussian Splatting](https://arxiv.org/abs/2507.18473)
> *CRUISE：在V2X场景中使用高斯泼溅进行协作重建和编辑*

*Haoran Xu, Saining Zhang, Peishuo Li, Baijun Ye, Xiaoxue Chen, Huan-ang Gao, Jv Zheng, Xiaowei Song, Ziqiao Peng, Run Miao, Jinrang Jia, Yifeng Shi, Guangqi Yi, Hang Zhao, Hao Tang, Hongyang Li, Kaicheng Yu, Hao Zhao* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** V2X, 高斯泼溅, 场景重建, 数据增强, 自动驾驶

**Comment:** IROS 2025, Code: https://github.com/SainingZhang/CRUISE

> **TL;DR:** CRUISE是一个用于V2X场景的重建和合成框架，它利用分解高斯泼溅技术，高保真地重建真实世界场景，并支持灵活编辑，从而实现大规模V2X数据集增强，显著提升3D检测和跟踪性能，并能生成具有挑战性的角点案例。

**AI_Comments:** 该论文提出的CRUISE框架通过结合高斯泼溅技术，在V2X场景数据生成和增强方面展现了创新性。其分解动态交通参与者并允许编辑的能力，为自动驾驶数据增强提供了新的途径，尤其是在处理V2X复杂性和生成挑战性场景方面具有重要意义。这有助于提高自动驾驶系统在真实世界复杂情况下的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管模拟在自动驾驶任务中发挥了重要作用，但其在V2X场景中数据生成和增强的潜力尚未得到充分探索。本文旨在解决这一问题，为V2X驾驶环境引入一个全面的重建和合成框架。

**Method:** 本文提出了CRUISE框架，一个专为V2X驾驶环境设计的综合重建与合成框架。CRUISE采用分解高斯泼溅（decomposed Gaussian Splatting）技术，以高保真度重建真实世界场景，并支持灵活编辑。通过将动态交通参与者分解为可编辑的高斯表示，CRUISE能够无缝修改和增强驾驶场景。此外，该框架可从自车和基础设施视角渲染图像，从而实现用于训练和评估的大规模V2X数据集增强。

**Result:** 实验结果表明：1) CRUISE能够高保真地重建真实世界的V2X驾驶场景；2) 使用CRUISE可以提高自车、基础设施和协作视图下的3D检测性能，以及V2X-Seq基准上的协作3D跟踪性能；3) CRUISE能够有效地生成具有挑战性的角点案例。

**Conclusion:** CRUISE框架能够高保真地重建V2X驾驶场景，支持灵活编辑和大规模数据增强，从而显著提升了3D检测和跟踪的性能，并能生成有价值的挑战性场景，证明了其在自动驾驶V2X场景中的巨大潜力。

> **ai_Abstract:** CRUISE是一个为车联网（V2X）环境设计的综合重建与合成框架，旨在解决V2X场景中数据生成和增强的不足。该框架利用分解高斯泼溅技术，能够高保真地重建真实世界驾驶场景，并支持对动态交通参与者进行灵活编辑。通过从自车和基础设施视角渲染图像，CRUISE实现了大规模V2X数据集的增强。实验证明，CRUISE不仅能高保真重建场景，还能显著提升3D检测和协作3D跟踪性能，并有效生成挑战性角点案例。

> **摘要翻译:** 车联网（V2X）通信在自动驾驶中扮演着关键角色，实现了车辆与基础设施之间的协作。尽管模拟对各种自动驾驶任务做出了重大贡献，但其在V2X场景中数据生成和增强的潜力仍未得到充分探索。在本文中，我们介绍了CRUISE，一个为V2X驾驶环境设计的综合重建和合成框架。CRUISE采用分解高斯泼溅（decomposed Gaussian Splatting）技术，以高保真度重建真实世界场景，同时支持灵活编辑。通过将动态交通参与者分解为可编辑的高斯表示，CRUISE允许无缝修改和增强驾驶场景。此外，该框架可从自车和基础设施视角渲染图像，从而实现用于训练和评估的大规模V2X数据集增强。我们的实验结果表明：1) CRUISE能够高保真地重建真实世界的V2X驾驶场景；2) 使用CRUISE可以提高自车、基础设施和协作视图下的3D检测性能，以及V2X-Seq基准上的协作3D跟踪性能；3) CRUISE能够有效地生成具有挑战性的角点案例。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [491] [LMM-Det: Make Large Multimodal Models Excel in Object Detection](https://arxiv.org/abs/2507.18300)
> *LMM-Det：让大型多模态模型在目标检测中表现出色*

*Jincheng Li, Chunyu Xie, Ji Ao, Dawei Leng, Yuhui Yin* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 大型多模态模型, 目标检测, LMM-Det, 召回率, 推理优化

**Comment:** Accepted at ICCV 2025

> **TL;DR:** LMM-Det提出了一种简单有效的方法，使大型多模态模型（LMMs）能在没有专门检测模块的情况下进行目标检测，通过数据分布调整、推理优化和指令重组解决了召回率低的问题，并实验证明了其有效性。

**AI_Comments:** 这篇论文的创新点在于它挑战了LMMs必须与笨重检测器结合才能进行目标检测的传统观念，提出了一种更简洁、更通用的方法。如果LMMs真的能不依赖额外模块就实现高效的目标检测，这将大大简化多模态系统的架构，并可能为未来通用AI的发展提供新的方向。然而，抽象中没有提及具体的性能指标，这使得评估其“有效性”的程度有所保留。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型多模态模型（LMMs）在图像标注、视觉问答和视觉定位等任务中表现出色，但它们在目标检测方面的能力与专业的检测器相比存在显著差距。本研究旨在弥补这一差距，使LMMs也能擅长目标检测，而无需集成笨重的专业检测模块。

**Method:** 论文提出了LMM-Det，一种简单而有效的方法，利用大型多模态模型直接进行普通目标检测，不依赖于专门的检测模块。具体方法包括：首先，对大型多模态模型与目标检测结合时的性能（特别是召回率显著下降）进行探索性分析；其次，通过引入针对目标检测的数据分布调整和推理优化来提高召回率；最后，重新组织指令对话以增强大型多模态模型的目标检测能力。

**Result:** 广泛的实验支持了论文的论点，并展示了多功能LMM-Det的有效性。

**Conclusion:** 本文声称大型多模态模型无需任何额外的检测模块就具备目标检测能力。

> **ai_Abstract:** LMM-Det提出了一种新颖的方法，旨在提升大型多模态模型（LMMs）在目标检测任务上的性能，以弥补其与专业检测器之间的差距。该方法不依赖额外的检测模块，而是通过深入分析LMMs在目标检测中的局限性（特别是召回率低），引入了数据分布调整、推理优化以及指令对话重组等策略来增强LMMs的检测能力。实验结果证明了LMM-Det的有效性，并验证了LMMs无需专用模块即可进行目标检测的潜力。

> **摘要翻译:** 大型多模态模型（LMMs）因其在多模态理解、推理和上下文学习等方面的卓越能力，在人工智能研究和工业界引起了广泛关注。虽然LMMs在处理图像标注、视觉问答和视觉定位等任务中表现出喜人的结果，但LMMs的目标检测能力与专业检测器相比存在显著差距。为了弥补这一差距，我们摒弃了将笨重检测器与LMMs集成的传统方法，提出了一种简单而有效的方法LMM-Det，该方法利用大型多模态模型进行普通目标检测，而不依赖于专门的检测模块。具体来说，我们对大型多模态模型与目标检测结合时进行了全面的探索性分析，揭示了召回率与专业检测模型相比显著下降。为了缓解这一问题，我们提出通过引入专为目标检测量身定制的数据分布调整和推理优化来提高召回率。我们重新组织了指令对话，以增强大型多模态模型的目标检测能力。我们声称大型多模态模型无需任何额外检测模块就具备检测能力。广泛的实验支持了我们的主张，并展示了多功能LMM-Det的有效性。数据集、模型和代码可在https://github.com/360CVGroup/LMM-Det获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [498] [SV3.3B: A Sports Video Understanding Model for Action Recognition](https://arxiv.org/abs/2507.17844)
> *SV3.3B：一种用于动作识别的体育视频理解模型*

*Sai Varun Kodathala, Yashwanth Reddy Vutukoori, Rakesh Vunnam* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 体育视频理解, 动作识别, 轻量级模型, 自监督学习, SV3.3B

**Comment:** 8 pages, 6 figures, 4 tables. Submitted to AIxSET 2025

> **TL;DR:** SV3.3B是一种轻量级体育视频理解模型，结合新颖的时序运动差异采样和自监督学习，可在设备上高效部署，并显著优于现有大型模型，能生成详细的体育动作描述。

**AI_Comments:** SV3.3B的创新之处在于其轻量级设计（3.3B参数）结合时序运动差异采样和自监督学习，实现了在设备上的高效部署，这对于实时体育视频分析至关重要。其超越GPT-4o等大型模型的表现，尤其是在体育特定评估指标上的显著改进，凸显了其在专业体育分析领域的潜力。该模型解决了传统方法在捕捉细微生物力学转换方面的不足，为体育训练和表现分析提供了更精确的工具。

<details>
  <summary>Details</summary>

**Motivation:** 传统的体育视频分析受限于计算密集型模型，需要服务器端处理，且缺乏对细粒度运动的理解。现有方法难以捕捉生物力学转换的细微差别，错过了关键的动作阶段，因此需要一种能高效在设备上部署并提供详细分析的模型。

**Method:** 本文提出了SV3.3B，一个轻量级3.3B参数的视频理解模型。该模型结合了新颖的时序运动差异采样和自监督学习，以实现高效的设备端部署。它采用基于DWT-VGG16-LDA的关键帧提取机制来识别16个最具代表性的帧，然后是一个通过掩码去噪目标预训练的V-DWT-JEPA2编码器，以及一个为体育动作描述生成而微调的LLM解码器。

**Result:** SV3.3B在NSVA篮球数据集子集上进行评估，在传统文本生成指标和体育特定评估标准上均表现出色，优于包括GPT-4o变体在内的更大闭源模型，同时计算要求显著降低。该模型在生成技术详细和分析丰富的体育描述方面表现出卓越的能力，在地面真实验证指标上比GPT-4o提高了29.2%，并在信息密度、动作复杂性和测量精度等关键指标上取得了显著改进。

**Conclusion:** SV3.3B模型通过结合新颖的时序运动差异采样和自监督学习，在轻量级模型中实现了卓越的体育视频理解和动作描述生成能力，显著优于现有大型模型，并在计算效率和分析精度方面提供了实质性改进。

> **ai_Abstract:** 本文介绍了SV3.3B，一个轻量级3.3亿参数的体育视频理解模型，旨在克服现有体育视频分析中计算量大、缺乏细粒度理解的局限性。该模型结合了新颖的时序运动差异采样和自监督学习，实现了高效的设备端部署。它利用DWT-VGG16-LDA进行关键帧提取，并采用V-DWT-JEPA2编码器和LLM解码器。实验结果表明，SV3.3B在性能上超越了GPT-4o等大型模型，同时显著降低了计算需求，能够生成高度详细和分析丰富的体育动作描述。

> **摘要翻译:** 本文解决了自动化体育视频分析的挑战，该领域传统上受限于计算密集型模型，需要服务器端处理，并且缺乏对运动动作的细粒度理解。当前方法难以捕捉有意义的体育分析所需的细微生物力学转换，常常错过在几秒钟内发生的准备、执行和完成等关键阶段。为了解决这些限制，我们推出了SV3.3B，一个轻量级3.3亿参数的视频理解模型，它结合了新颖的时序运动差异采样和自监督学习，以实现高效的设备端部署。我们的方法采用基于DWT-VGG16-LDA的关键帧提取机制，智能识别体育序列中16个最具代表性的帧，然后是一个通过掩码去噪目标预训练的V-DWT-JEPA2编码器，以及一个为体育动作描述生成而微调的LLM解码器。在NSVA篮球数据集的一个子集上进行评估，SV3.3B在传统文本生成指标和体育特定评估标准上均取得了卓越的性能，优于包括GPT-4o变体在内的更大闭源模型，同时保持显著更低的计算要求。我们的模型在生成技术详细和分析丰富的体育描述方面表现出卓越的能力，在地面真实验证指标上比GPT-4o提高了29.2%，在信息密度、动作复杂性和测量精度等对全面运动分析至关重要的指标上取得了实质性改进。模型可在https://huggingface.co/sportsvision/SV3.3B获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [501] [Trigger without Trace: Towards Stealthy Backdoor Attack on Text-to-Image Diffusion Models](https://arxiv.org/abs/2503.17724)
> *无痕触发：面向文生图扩散模型的隐蔽后门攻击*

*Jie Zhang, Zhongqi Wang, Shiguang Shan, Xilin Chen* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 后门攻击, 文生图模型, 隐蔽攻击, 扩散模型, TwT

**Comment:** 

> **TL;DR:** 本文提出了一种名为“无痕触发”（TwT）的新型后门攻击方法，通过消除语义和注意力一致性，使后门样本更难被检测，并成功绕过现有防御机制。

**AI_Comments:** 本文提出了一种新颖的隐蔽后门攻击方法，其创新点在于通过主动破坏语义和注意力一致性来规避检测，这与以往的攻击方法不同。该研究揭示了当前文生图扩散模型后门防御的脆弱性，对于提升模型安全性具有重要警示意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前针对文生图扩散模型的后门攻击样本存在语义一致性和注意力一致性两种异常，这使得后门易于被防御者检测和识别。

**Method:** 本文提出了“无痕触发”（TwT）方法来明确减轻这些一致性。具体来说，利用句法结构作为后门触发器，以增强对文本变化的敏感性，从而打破语义一致性。此外，提出了一种基于核最大均值差异（KMMD）的正则化方法，以对齐后门样本和良性样本之间的交叉注意力响应分布，从而破坏注意力一致性。

**Result:** 实验表明，该方法实现了97.5%的攻击成功率，同时对防御表现出更强的抵抗力。它使平均超过98%的后门样本绕过了三种最先进的检测机制。

**Conclusion:** 本文提出的TwT方法能够实现隐蔽的后门攻击，有效绕过现有的检测机制，揭示了当前后门防御方法的脆弱性。

> **ai_Abstract:** 本文针对文生图扩散模型提出了一种名为“无痕触发”（TwT）的隐蔽后门攻击方法，旨在解决现有攻击中语义和注意力一致性导致的易检测性问题。TwT通过利用句法结构作为触发器打破语义一致性，并采用基于KMMD的正则化方法来破坏注意力一致性。实验结果显示，该方法实现了高攻击成功率（97.5%），并能有效规避现有主流检测机制（平均超过98%的样本绕过检测），揭示了当前防御策略的不足。

> **摘要翻译:** 针对文生图扩散模型的后门攻击发展迅速。然而，与良性样本相比，当前的后门样本通常表现出两个关键异常：1）语义一致性，即后门提示倾向于生成具有相似语义内容的图像，即使文本提示存在显著变化；2）注意力一致性，即触发器在交叉注意力图中引起一致的结构响应。这些一致性为防御者留下了可检测的痕迹，使得后门更容易被识别。在本文中，为了实现隐蔽的后门样本，我们提出了“无痕触发”（TwT），通过明确减轻这些一致性。具体来说，我们的方法利用句法结构作为后门触发器，以放大对文本变化的敏感性，从而有效打破语义一致性。此外，提出了一种基于核最大均值差异（KMMD）的正则化方法，以对齐后门样本和良性样本之间的交叉注意力响应分布，从而破坏注意力一致性。大量实验表明，我们的方法实现了97.5%的攻击成功率，同时表现出更强的防御抵抗力。它使平均超过98%的后门样本绕过了三种最先进的检测机制，揭示了当前后门防御方法的脆弱性。代码可在https://github.com/Robin-WZQ/TwT 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [508] [External Knowledge Injection for CLIP-Based Class-Incremental Learning](https://arxiv.org/abs/2503.08510)
> *基于CLIP的类增量学习的外部知识注入*

*Da-Wei Zhou, Kai-Wen Li, Jingyi Ning, Han-Jia Ye, Lijun Zhang, De-Chuan Zhan* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 类增量学习, CLIP, 外部知识注入, 双分支学习, GPT-4

**Comment:** Accepted to ICCV 2025. Code is available at:
  https://github.com/LAMDA-CL/ICCV25-ENGINE

> **TL;DR:** 本文提出ENGINE，一种为基于CLIP的类增量学习注入外部知识的方法，通过双分支注入调优框架（视觉分支增强数据，文本分支利用GPT-4重写描述符）和推理时的后调优知识，解决了CLIP在CIL中忽略上下文信息和特征覆盖的问题，实现了最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了一个双分支注入调优框架，有效地将外部视觉和文本知识（特别是利用GPT-4生成判别性文本描述）注入到CLIP模型中，以解决其在类增量学习中上下文信息利用不足和特征遗忘的问题。此外，结合了推理阶段的后调优知识重排序，进一步提升了性能。这种结合多模态外部知识和后处理优化的方法为CLIP在持续学习场景下的应用提供了新的思路，具有重要的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 类增量学习（CIL）中，尽管预训练的视觉-语言模型（如CLIP）提供了一个有前景的起点，但CLIP通过匹配视觉嵌入和类名进行决策，忽视了语言传递的丰富上下文信息（例如，将“猫”分解为尾巴、毛发、面部等特征）。此外，在CIL中，模型持续更新会导致这些详细特征被覆盖，因此需要外部知识进行补偿。

**Method:** 本文引入了名为ExterNal knowledGe INjEction (ENGINE) 的方法，用于基于CLIP的类增量学习。为增强数据集外部的知识迁移，作者提出了一个双分支注入调优框架，该框架从视觉和文本两种模态编码信息知识。视觉分支通过数据增强来丰富视觉特征，而文本分支则利用GPT-4重写判别性描述符。除了这种即时知识注入，还在推理阶段通过重新排序预测结果实现了后调优知识。

**Result:** 广泛的实验证明，ENGINE实现了最先进的性能。

**Conclusion:** 通过注入外部知识，模型能够更好地捕获下游任务的信息特征，即使数据不断演变。实验结果表明，ENGINE达到了最先进的性能。

> **ai_Abstract:** 本文针对基于CLIP的类增量学习（CIL）中CLIP模型忽略上下文信息和特征覆盖的问题，提出了一种名为ENGINE的外部知识注入方法。ENGINE采用双分支注入调优框架，通过视觉分支的数据增强和文本分支利用GPT-4生成判别性描述符来编码外部知识。此外，还通过推理阶段的预测结果重排序实现后调优知识。实验结果表明，ENGINE能够有效提升模型捕获信息特征的能力，并取得了当前最先进的性能。

> **摘要翻译:** 类增量学习（CIL）使学习系统能够持续适应不断演变的数据流。随着预训练的进步，利用预训练的视觉-语言模型（例如CLIP）为CIL提供了一个有前景的起点。然而，CLIP通过将视觉嵌入与类名匹配来做出决策，忽略了通过语言传达的丰富上下文信息。例如，“猫”的概念可以分解为尾巴、毛发和面部等特征进行识别。此外，由于模型不断更新，这些详细特征在CIL中会被覆盖，需要外部知识进行补偿。在本文中，我们引入了用于基于CLIP的CIL的外部知识注入（ENGINE）。为了增强数据集外部的知识转移，我们提出了一种双分支注入调优框架，该框架从视觉和文本两种模态编码信息知识。视觉分支通过数据增强来丰富视觉特征，而文本分支则利用GPT-4重写判别性描述符。除了这种即时知识注入，我们还在推理过程中通过重新排序预测结果实现了后调优知识。通过注入的知识，模型能够更好地捕获下游任务的信息特征，随着数据的发展。广泛的实验证明了ENGINE的最先进性能。代码可在以下网址获取：https://github.com/LAMDA-CL/ICCV25-ENGINE

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [522] [Adapting Large VLMs with Iterative and Manual Instructions for Generative Low-light Enhancement](https://arxiv.org/abs/2507.18064)
> *采用迭代和手动指令的自适应大型视觉语言模型用于生成式低光增强*

*Xiaoran Sun, Liyan Wang, Cong Wang, Yeying Jin, Kin-man Lam, Zhixun Su, Yang Yang, Jinshan Pan* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 低光图像增强, 视觉语言模型, 迭代指令, 语义引导, 跨模态融合

**Comment:** 

> **TL;DR:** 提出VLM-IMI框架，利用大型视觉语言模型和迭代/手动指令，通过文本描述进行语义引导的低光图像增强，优于现有方法。

**AI_Comments:** VLM-IMI的创新之处在于其将大型视觉语言模型引入低光图像增强领域，并通过迭代和手动指令引入语义指导，有效弥补了传统方法在复杂光照条件下缺乏语义信息的不足。其跨模态融合和推理阶段的指令优化策略也增强了输出的质量和细节恢复能力，为低光增强提供了新的视角和有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有低光图像增强方法忽视了正常光图像的语义指导，导致在复杂光照条件下效果受限。

**Method:** 本文提出VLM-IMI框架，该框架利用大型视觉语言模型（VLMs）和迭代及手动指令（IMIs）进行低光图像增强。VLM-IMI将所需正常光内容的文本描述作为增强线索，以实现语义引导的恢复。为有效整合跨模态先验，引入了一个指令先验融合模块，该模块动态对齐并融合图像和文本特征。在推理过程中，采用迭代和手动指令策略来优化文本指令，逐步提升视觉质量。

**Result:** VLM-IMI在各种场景下，无论是在定量指标还是感知质量方面，均优于现有最先进的方法。

**Conclusion:** VLM-IMI通过结合视觉语言模型和迭代/手动指令，有效解决了低光图像增强中语义指导缺失的问题，显著提升了图像质量和细节恢复能力。

> **ai_Abstract:** 本文提出VLM-IMI框架，利用大型视觉语言模型（VLMs）和迭代及手动指令（IMIs）解决现有低光图像增强（LLIE）方法忽视语义指导的问题。VLM-IMI通过整合正常光内容的文本描述作为增强线索，并引入指令先验融合模块来对齐和融合图像与文本特征，实现语义引导的图像恢复。在推理阶段，采用迭代和手动指令策略持续优化文本指令，从而提升图像的结构保真度、语义对齐和细节恢复。实验结果表明，VLM-IMI在定量和感知质量上均超越了当前最先进的LLIE方法。

> **摘要翻译:** 大多数现有的低光图像增强（LLIE）方法依赖于预训练模型先验、低光输入或两者兼有，而忽略了正常光图像中可用的语义指导。这种限制阻碍了它们在复杂光照条件下的有效性。在本文中，我们提出了VLM-IMI，一个新颖的框架，它利用大型视觉语言模型（VLMs）以及迭代和手动指令（IMIs）进行LLIE。VLM-IMI将所需正常光内容的文本描述作为增强线索，实现语义信息恢复。为了有效整合跨模态先验，我们引入了一个指令先验融合模块，该模块动态对齐并融合图像和文本特征，促进生成细节丰富且语义连贯的输出。在推理过程中，我们采用迭代和手动指令策略来优化文本指令，逐步提高视觉质量。这种优化增强了在极低光条件下的结构保真度、语义对齐和精细细节的恢复。在各种场景下进行的大量实验表明，VLM-IMI在定量指标和感知质量方面均优于最先进的方法。源代码可在 https://github.com/sunxiaoran01/VLM-IMI 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [524] [Q-Former Autoencoder: A Modern Framework for Medical Anomaly Detection](https://arxiv.org/abs/2507.18481)
> *Q-Former自编码器：一种现代医学异常检测框架*

*Francesco Dalmonte, Emirhan Bayar, Emre Akbas, Mariana-Iuliana Georgescu* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 医学异常检测, Q-Former, 自编码器, 视觉基础模型, 无监督学习

**Comment:** 15 pages

> **TL;DR:** 本文提出了一种名为Q-Former自编码器的新型无监督医学异常检测框架，它利用预训练的视觉基础模型作为特征提取器，并在多个基准测试中取得了最先进的结果，证明了这些模型在医学图像分析中的泛化能力。

**AI_Comments:** 该论文的创新点在于其将预训练的视觉基础模型（如DINO/DINOv2和MAE）以冻结的方式集成到自编码器框架中，用于医学异常检测。这种方法避免了从零开始训练编码器和进行特定领域微调的需要，极大地提高了模型的泛化能力和效率。Q-Former作为瓶颈的设计以及引入感知损失是其技术亮点。其重要性在于为医学图像分析领域提供了一种高效且高性能的无监督异常检测解决方案，尤其是在缺乏大量标注数据的情况下。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像中的异常检测是一项重要但具有挑战性的任务，原因在于异常的多样性以及收集全面标注数据集的实际困难。

**Method:** 本文提出了一种现代化的基于自编码器的框架——Q-Former自编码器，该框架利用DINO、DINOv2和Masked Autoencoder等最先进的预训练视觉基础模型作为冻结的特征提取器，无需领域特定微调即可获得丰富的多阶段高级表示。该方法将Q-Former架构用作瓶颈，以控制重建序列的长度并高效聚合多尺度特征，并结合了使用预训练Masked Autoencoder特征计算的感知损失，以指导重建趋向于语义上有意义的结构。

**Result:** 该框架在四个不同的医学异常检测基准测试中进行了评估，并在BraTS2021、RESC和RSNA上取得了最先进的结果。

**Conclusion:** 研究结果强调了在自然图像上预训练的视觉基础模型编码器，无需进一步微调即可有效泛化到医学图像分析任务的潜力。

> **ai_Abstract:** 本文提出了一种名为Q-Former自编码器的新型无监督医学异常检测框架。该框架创新性地利用冻结的预训练视觉基础模型（如DINO、DINOv2和MAE）作为特征提取器，避免了从头训练编码器和领域特定微调的需求。Q-Former架构被用作瓶颈，以有效聚合多尺度特征并控制重建序列长度，同时引入了基于MAE特征的感知损失以优化重建质量。该方法在BraTS2021、RESC和RSNA等四个医学异常检测基准测试中取得了最先进的性能，证明了预训练视觉模型在医学图像分析中出色的泛化能力。

> **摘要翻译:** 医学图像中的异常检测是一项重要但具有挑战性的任务，原因在于可能异常的多样性以及收集全面标注数据集的实际不可能。在这项工作中，我们提出了一种现代化的基于自编码器的框架——Q-Former自编码器，以解决无监督医学异常检测问题。该框架利用了最先进的预训练视觉基础模型，如DINO、DINOv2和Masked Autoencoder。我们没有从头开始训练编码器，而是直接利用冻结的视觉基础模型作为特征提取器，从而在不进行领域特定微调的情况下实现丰富、多阶段、高级的表示。我们建议使用Q-Former架构作为瓶颈，这使得能够控制重建序列的长度，同时有效地聚合多尺度特征。此外，我们引入了一种使用预训练Masked Autoencoder特征计算的感知损失，以指导重建趋向于语义上有意义的结构。我们的框架在四个不同的医学异常检测基准测试中进行了评估，并在BraTS2021、RESC和RSNA上取得了最先进的结果。我们的结果突出了在自然图像上预训练的视觉基础模型编码器，无需进一步微调即可有效泛化到医学图像分析任务的潜力。我们已在https://github.com/emirhanbayar/QFAE发布了代码和模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [527] [PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding](https://arxiv.org/abs/2504.13180)
> *感知语言模型：用于详细视觉理解的开放获取数据和模型*

*Jang Hyun Cho, Andrea Madotto, Effrosyni Mavroudi, Triantafyllos Afouras, Tushar Nagarajan, Muhammad Maaz, Yale Song, Tengyu Ma, Shuming Hu, Suyog Jain, Miguel Martin, Huiyu Wang, Hanoona Rasheed, Peize Sun, Po-Yao Huang, Daniel Bolya, Nikhila Ravi, Shashank Jain, Tammy Stark, Shane Moon, Babak Damavandi, Vivian Lee, Andrew Westbury, Salman Khan, Philipp Krähenbühl, Piotr Dollár, Lorenzo Torresani, Kristen Grauman, Christoph Feichtenhofer* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 视觉语言模型, 开放获取, 视频理解, 人工标注数据, 可复现性

**Comment:** Technical Report

> **TL;DR:** 本文发布了PerceptionLM的开放获取数据和模型，旨在促进透明的图像和视频理解研究，解决现有视觉语言模型封闭源代码的问题，并提供了大规模人工标注数据和评估基准。

**AI_Comments:** 这篇论文通过提供开放获取的数据和模型，以及详细的训练方法，直接解决了当前高性能视觉语言模型闭源导致科学进步受阻的关键问题。其创新之处在于构建了一个完全可复现的框架，并特别关注了视频理解中的细粒度数据空白，通过大规模人工标注数据集的发布和新评估基准的引入，为该领域的研究提供了宝贵资源，极大地促进了透明度和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 许多高性能视觉语言模型是闭源的，隐藏了它们的数据、设计和训练方法，导致科学进展难以衡量。研究社区通过蒸馏方法获取训练数据，但仍无法了解教师模型的细节和数据来源，阻碍了科学进步。

**Method:** 构建了一个完全开放和可复现的感知语言模型（PLM）框架，用于透明的图像和视频理解研究。分析了不依赖专有模型蒸馏的标准训练流程。探索了大规模合成数据以识别关键数据空白，尤其是在详细视频理解方面。发布了2.8M人工标注的细粒度视频问答对和时空定位视频字幕数据。引入了PLM-VideoBench，一个评估具有挑战性的视频理解任务的套件，重点关注对视频中“什么”、“哪里”、“何时”和“如何”进行推理的能力。通过提供数据、训练方法、代码和模型，使工作完全可复现。

**Result:** 发布了2.8M人工标注的细粒度视频问答对和时空定位视频字幕数据。引入了PLM-VideoBench，一个用于评估视频理解任务的新基准。提供了完全可复现的数据、训练方法、代码和模型。

**Conclusion:** 本文致力于构建一个完全开放和可复现的感知语言模型框架，以促进图像和视频理解领域的透明研究，并通过发布大规模人工标注数据和新的评估基准来弥补现有数据空白。

> **ai_Abstract:** 本文针对当前视觉语言模型普遍闭源且数据、设计不透明的问题，提出了一个开放且可复现的感知语言模型（PLM）框架。作者分析了不依赖蒸馏的标准训练流程，并识别出详细视频理解中的数据空白。为弥补这些空白，论文发布了2.8M人工标注的细粒度视频问答对和时空定位视频字幕，并引入了PLM-VideoBench，一个专注于视频中“什么”、“哪里”、“何时”、“如何”推理的新评估基准。所有数据、代码和模型均公开，旨在促进图像和视频理解领域的透明科学研究。

> **摘要翻译:** 视觉语言模型是计算机视觉研究不可或缺的一部分，然而许多高性能模型仍然是闭源的，模糊了它们的数据、设计和训练方法。研究社区通过使用黑盒模型的蒸馏来标注训练数据，取得了强大的基准结果，但代价是可衡量的科学进步。然而，在不了解教师模型及其数据来源的细节的情况下，科学进步仍然难以衡量。在本文中，我们研究在一个完全开放和可复现的框架中构建感知语言模型（PLM），以促进图像和视频理解的透明研究。我们分析了不依赖专有模型蒸馏的标准训练流程，并探索了大规模合成数据以识别关键数据空白，特别是在详细视频理解方面。为了弥补这些空白，我们发布了2.8M个人工标注的细粒度视频问答对和时空定位视频字幕。此外，我们引入了PLM-VideoBench，一个用于评估具有挑战性的视频理解任务的套件，重点关注对视频中“什么”、“哪里”、“何时”和“如何”进行推理的能力。我们通过提供数据、训练方法、代码和模型，使我们的工作完全可复现。https://github.com/facebookresearch/perception_models

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [535] [Improving Large Vision-Language Models' Understanding for Field Data](https://arxiv.org/abs/2507.18311)
> *提高大型视觉-语言模型对现场数据的理解*

*Xiaomei Zhang, Hanyu Zheng, Xiangyu Zhu, Jinghuan Wei, Junhong Zou, Zhen Lei, Zhaoxiang Zhang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 大型视觉-语言模型, 现场数据, 科学研究, 数据压缩, 领域感知

**Comment:** 

> **TL;DR:** FieldLVLM 框架通过结合领域感知语言生成和数据压缩多模态模型调优，显著提升了大型视觉-语言模型对科学现场数据的理解能力。

**AI_Comments:** 这项工作具有重要的创新性，它通过引入 FieldLVLM 框架，专门解决了大型视觉-语言模型在处理复杂科学现场数据时的不足。其亮点在于结合了领域知识（通过特征提取和结构化描述）和数据优化（通过数据压缩），有效地将领域特定的视觉信息转化为 LVLM 能够理解和学习的格式。这为 LVLM 在更广泛、更专业的科学领域应用奠定了基础，具有巨大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（LVLMs）在图像描述和视觉问答等任务中表现出色，但其在科学领域，特别是解释自然科学中常用的复杂现场数据方面的应用尚未得到充分探索。

**Method:** 本文引入了 FieldLVLM 框架，旨在提高大型视觉-语言模型对现场数据的理解。FieldLVLM 包含两个主要组件：领域感知语言生成策略和数据压缩多模态模型调优。领域感知语言生成策略利用专门的机器学习管道从现场数据中提取关键物理特征（如流分类、雷诺数、涡流模式），并将其转换为结构化文本描述作为数据集。数据压缩多模态模型调优则针对这些生成的数据集对 LVLM 进行微调，使用数据压缩策略减少现场输入的复杂性并保留最具信息量的值。

**Result:** 在最新提出的基准数据集上的实验结果表明，FieldLVLM 在涉及科学现场数据的任务中显著优于现有方法。

**Conclusion:** 本研究结果表明，FieldLVLM 方法为将大型视觉-语言模型应用于科学研究开辟了新的可能性，有助于弥合大型模型与领域特定发现之间的鸿沟。

> **ai_Abstract:** 该论文提出了 FieldLVLM 框架，旨在解决大型视觉-语言模型（LVLMs）在理解科学现场数据方面的不足。FieldLVLM 包含领域感知语言生成策略，用于从现场数据中提取物理特征并转换为文本描述；以及数据压缩多模态模型调优，用于高效地对 LVLM 进行微调。实验证明，FieldLVLM 在科学现场数据任务上显著优于现有方法，为 LVLM 在科学研究中的应用开辟了新途径。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）在集成视觉和文本理解的一系列任务中展现出令人印象深刻的能力，例如图像描述和视觉问答。这些模型通过与文本配对的大规模图像和视频数据集进行训练，使其能够连接视觉感知和自然语言处理。然而，它们在科学领域的应用，特别是在解释自然科学中常用的复杂现场数据方面，仍未得到充分探索。在这项工作中，我们引入了 FieldLVLM，这是一个旨在提高大型视觉-语言模型对现场数据理解的新颖框架。FieldLVLM 由两个主要组件组成：领域感知语言生成策略和数据压缩多模态模型调优。领域感知语言生成策略利用专门的机器学习管道从现场数据中提取关键物理特征，例如流分类、雷诺数和涡流模式。然后，这些信息被转换为结构化的文本描述，作为数据集。数据压缩多模态模型调优专注于使用这些生成的数据集对 LVLM 进行调优，采用数据压缩策略来降低现场输入的复杂性并仅保留最具信息量的值。这确保了与模型语言解码器的兼容性，并更有效地指导其学习。在最新提出的基准数据集上的实验结果表明，FieldLVLM 在涉及科学现场数据的任务中显著优于现有方法。我们的研究结果表明，这种方法为将大型视觉-语言模型应用于科学研究开辟了新的可能性，有助于弥合大型模型与领域特定发现之间的鸿沟。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [538] [DeGauss: Dynamic-Static Decomposition with Gaussian Splatting for Distractor-free 3D Reconstruction](https://arxiv.org/abs/2503.13176)
> *DeGauss：基于高斯泼溅的动静分解，实现无干扰三维重建*

*Rui Wang, Quentin Lohmeyer, Mirko Meboldt, Siyu Tang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D Reconstruction, Gaussian Splatting, Dynamic Scenes, Self-supervised, Distractor-free

**Comment:** Accepted by ICCV 2025

> **TL;DR:** DeGauss是一个自监督框架，通过将动态和静态元素分别建模为前景和背景高斯来解决动态场景中的无干扰3D重建问题，并在多个基准测试中表现优异。

**AI_Comments:** DeGauss的创新之处在于其解耦的动静高斯泼溅设计，能够有效地分离和重建动态与静态场景元素，这对于处理复杂真实世界数据，特别是自我中心视频中的干扰问题至关重要。其自监督特性和在多个基准上的优异表现，使其成为该领域的一个重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 从真实世界捕获中重建干净、无干扰的3D场景仍然是一个重大挑战，尤其是在高度动态和混乱的环境中，例如自我中心视频。

**Method:** 引入了DeGauss，一个简单且鲁棒的自监督框架，用于动态场景重建。它基于解耦的动静高斯泼溅设计，使用前景高斯建模动态元素，背景高斯建模静态内容，并通过概率掩码协调它们的组合，实现独立而互补的优化。

**Result:** DeGauss在NeRF-on-the-go、ADT、AEA、Hot3D和EPIC-Fields等基准测试中始终优于现有方法，为高度动态、交互丰富的环境中可泛化的无干扰3D重建建立了强大的基线。

**Conclusion:** DeGauss通过其解耦的动静高斯泼溅设计，成功解决了动态场景中无干扰3D重建的挑战，并在广泛的真实世界场景中表现出鲁棒性，超越了现有方法。

> **ai_Abstract:** DeGauss是一个创新的自监督框架，专为从真实世界动态捕获中实现无干扰3D场景重建而设计。它采用独特的动静高斯泼溅分解方法，将动态前景与静态背景分离，并通过概率掩码进行协调优化。该方法在无需复杂启发式或大量监督的情况下，在多项基准测试中显著优于现有技术，为动态交互环境中的通用3D重建设定了新标准。

> **摘要翻译:** 从真实世界捕获中重建干净、无干扰的三维场景仍然是一个重大挑战，特别是在高度动态和混乱的环境中，例如以自我为中心的视频。为了解决这个问题，我们引入了DeGauss，一个简单而鲁棒的自监督框架，用于基于解耦的动静高斯泼溅设计的动态场景重建。DeGauss使用前景高斯建模动态元素，使用背景高斯建模静态内容，并使用概率掩码协调它们的组合，从而实现独立而互补的优化。DeGauss在各种真实世界场景中都能稳健地泛化，从随意的图像集合到长时间、动态的自我中心视频，而无需依赖复杂的启发式方法或大量的监督。在包括NeRF-on-the-go、ADT、AEA、Hot3D和EPIC-Fields在内的基准测试中，实验表明DeGauss始终优于现有方法，为高度动态、交互丰富的环境中可泛化的无干扰三维重建建立了强大的基线。项目页面：https://batfacewayne.github.io/DeGauss.io/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [548] [DRWKV: Focusing on Object Edges for Low-Light Image Enhancement](https://arxiv.org/abs/2507.18594)
> *DRWKV：聚焦物体边缘的低光照图像增强*

*Xuecheng Bai, Yuxiang Wang, Boyu Hu, Qinyuan Jie, Chuanzhi Xu, Hongru Xiao, Kechen Li, Vera Chung* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 低光照图像增强, 边缘保持, Retinex, 注意力机制, 图像质量

**Comment:** 

> **TL;DR:** DRWKV是一种新型低光照图像增强模型，通过全局边缘Retinex理论、演进WKV注意力机制和双边光谱对齐器，有效保留边缘细节并提升视觉自然度，在多个基准测试中表现出色。

**AI_Comments:** 这篇论文的创新点在于其多方面的综合方法，特别是在边缘处理上的专注。通过结合全局边缘Retinex理论、独特的螺旋扫描注意力机制以及双边光谱对齐，DRWKV有效解决了低光照下边缘细节丢失的关键问题。其在保持低计算复杂度的同时实现领先性能，并提升下游任务表现，表明了该模型在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 低光照图像增强仍具挑战性，尤其是在极端光照退化下，如何保持物体边缘的连续性和精细结构细节。

**Method:** 提出DRWKV模型，包含：全局边缘Retinex (GER) 理论，用于解耦光照和边缘结构，增强边缘保真度；演进WKV注意力机制，采用螺旋扫描捕捉空间边缘连续性并建模不规则结构；双边光谱对齐器 (Bi-SAB) 和定制的MS2-Loss，共同对齐亮度和色度特征，提高视觉自然度并减少伪影。

**Result:** 在五个LLIE基准测试中，DRWKV在PSNR、SSIM和NIQE方面表现领先，同时保持低计算复杂度。此外，DRWKV增强了低光照多目标跟踪等下游任务的性能，验证了其泛化能力。

**Conclusion:** DRWKV模型通过其独特的设计（如GER理论、演进WKV注意力机制和Bi-SAB），有效解决了低光照图像增强中的边缘保持和细节恢复问题，并在性能和泛化能力上均表现出色。

> **ai_Abstract:** 本文提出DRWKV模型，旨在解决低光照图像增强中边缘和细节保持的挑战。该模型引入全局边缘Retinex理论以解耦光照和边缘，采用演进WKV注意力机制捕捉边缘连续性，并设计双边光谱对齐器和MS2-Loss以优化色彩和减少伪影。实验证明DRWKV在多项基准测试中表现优异，且计算效率高，泛化能力强，能提升下游任务性能。

> **摘要翻译:** 低光照图像增强仍然是一项具有挑战性的任务，特别是在极端光照退化下，要保持物体边缘的连续性和精细结构细节更是如此。在本文中，我们提出了一种新颖的模型——DRWKV（Detailed Receptance Weighted Key Value），它集成了我们提出的全局边缘Retinex（GER）理论，能够有效解耦光照和边缘结构，从而增强边缘保真度。其次，我们引入了演进WKV注意力机制，这是一种螺旋扫描机制，能够捕捉空间边缘连续性并更有效地建模不规则结构。第三，我们设计了双边光谱对齐器（Bi-SAB）和定制的MS2-Loss，以共同对齐亮度和色度特征，从而提高视觉自然度并减轻伪影。在五个LLIE基准测试上的大量实验表明，DRWKV在PSNR、SSIM和NIQE方面取得了领先的性能，同时保持了较低的计算复杂度。此外，DRWKV还增强了低光照多目标跟踪任务的下游性能，验证了其泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [551] [Detail++: Training-Free Detail Enhancer for Text-to-Image Diffusion Models](https://arxiv.org/abs/2507.17853)
> *Detail++: 面向文本到图像扩散模型的免训练细节增强器*

*Lifeng Chen, Jiner Wang, Zihao Pan, Beier Zhu, Xiaofeng Yang, Chi Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 文本到图像生成, 扩散模型, 细节增强, 渐进式细节注入, 免训练

**Comment:** 

> **TL;DR:** Detail++是一个免训练框架，通过渐进式细节注入策略和质心对齐损失，显著提升了文本到图像扩散模型处理复杂提示（多主体、多属性）时的细节和一致性。

**AI_Comments:** 该论文提出了一种新颖的免训练框架Detail++，通过模拟人类绘画的渐进式细节添加过程，有效解决了当前文本到图像模型在处理复杂多主体和多属性提示时的细节生成和属性绑定挑战。其创新点在于渐进式细节注入（PDI）策略和测试时的质心对齐损失，这使得模型能够在不进行额外训练的情况下显著提升生成质量和一致性，具有较高的实用价值和研究意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本到图像（T2I）生成模型在处理包含多个具有不同属性的主体的复杂提示时面临显著挑战，难以确保细节和属性绑定的一致性。

**Method:** 提出Detail++框架，采用渐进式细节注入（PDI）策略。它将复杂提示分解为一系列简化的子提示，分阶段引导生成过程。首先利用自注意力确保全局构图，然后进行精确细化。为实现属性与主体间的准确绑定，利用交叉注意力机制，并在测试时引入质心对齐损失（Centroid Alignment Loss）以减少绑定噪声并增强属性一致性。

**Result:** 在T2I-CompBench和新建的风格组合基准测试中，Detail++显著优于现有方法，尤其在涉及多个对象和复杂风格条件的情况下表现出色。

**Conclusion:** Detail++通过其免训练的渐进式细节注入策略和质心对齐损失，有效解决了文本到图像扩散模型在处理复杂提示时细节生成和属性绑定一致性的挑战，显著提升了生成质量。

> **ai_Abstract:** Detail++是一个免训练的文本到图像扩散模型细节增强框架，灵感来源于人类绘画过程。它通过将复杂提示分解为子提示并采用渐进式细节注入（PDI）策略，分阶段生成图像，首先确保全局构图，然后精确细化。为解决多主体属性绑定问题，Detail++利用交叉注意力并引入质心对齐损失。实验证明，Detail++在处理复杂提示（尤其是多对象和复杂风格）时，性能显著优于现有方法。

> **摘要翻译:** 文本到图像（T2I）生成领域的最新进展带来了令人印象深刻的视觉结果。然而，这些模型在处理复杂提示时仍面临重大挑战，特别是那些涉及多个具有不同属性的主体的情况。受人类绘画过程的启发，即首先勾勒构图然后逐步添加细节，我们提出了Detail++，一个免训练框架，它引入了一种新颖的渐进式细节注入（PDI）策略来解决这一限制。具体来说，我们将一个复杂提示分解为一系列简化的子提示，分阶段引导生成过程。这种分阶段生成利用自注意力的固有布局控制能力，首先确保全局构图，然后进行精确细化。为了实现属性与相应主体之间的精确绑定，我们利用交叉注意力机制，并在测试时进一步引入质心对齐损失（Centroid Alignment Loss），以减少绑定噪声并增强属性一致性。在T2I-CompBench和一个新建的风格组合基准测试中进行的大量实验表明，Detail++显著优于现有方法，特别是在涉及多个对象和复杂风格条件的情况下。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [556] [Vision Transformers in Precision Agriculture: A Comprehensive Survey](https://arxiv.org/abs/2504.21706)
> *农业精准化中的视觉Transformer：一项综合性调查*

*Saber Mehdipour, Seyed Abolghasem Mirroshandel, Seyed Amirhossein Tabatabaei* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 视觉Transformer, 精准农业, 植物病害检测, 计算机视觉, 综述

**Comment:** 

> **TL;DR:** 该论文全面综述了视觉Transformer（ViT）在精准农业中的应用，涵盖了其架构、与CNN的比较、面临的挑战以及未来的研究方向。

**AI_Comments:** 该论文对视觉Transformer在精准农业领域的应用进行了及时且全面的综述，这是一个快速发展的领域。其优势在于综合了现有文献，比较了ViT与CNN，并指出了关键挑战和未来方向，使其成为研究人员和从业者的宝贵资源。

<details>
  <summary>Details</summary>

**Motivation:** 检测植物病害对作物健康和产量至关重要。传统方法（人工检查、传统机器学习）在可扩展性和准确性方面存在局限性。视觉Transformer（ViT）作为一种有前景的替代方案，在处理长距离依赖和视觉任务可扩展性方面具有优势。

**Method:** 本文是一篇综述性研究，首先介绍了视觉Transformer（ViT）的基础架构及其从自然语言处理（NLP）到计算机视觉的演变。讨论了卷积神经网络（CNN）等传统模型的归纳偏置以及ViT如何减轻这些偏置。文章全面回顾了近期文献，重点关注关键方法、数据集和性能指标。研究还包括CNN和ViT的比较分析，以及对混合模型和性能增强的回顾。此外，论文探讨了数据要求、计算需求和模型可解释性等技术挑战，并提出了潜在的解决方案。最后，概述了未来研究方向。

**Result:** 作为一篇综述论文，本文没有提供新的实验结果。其“结果”是对ViT在精准农业中应用的全面回顾，包括对现有方法、数据集、性能指标的总结，以及对CNN与ViT的比较分析，并识别了技术挑战和潜在解决方案。

**Conclusion:** 视觉Transformer（ViT）有望彻底改变智能和精准农业，本研究旨在为从业者和研究人员提供对ViT如何赋能农业的更深入理解。

> **ai_Abstract:** 这篇综合性综述论文探讨了视觉Transformer（ViT）在精准农业中的应用，特别是植物病害检测，旨在解决传统方法的局限性。论文详细介绍了ViT的架构、其从自然语言处理到计算机视觉的演变，以及其在处理归纳偏置方面相对于卷积神经网络（CNN）的优势。综述涵盖了相关的方法、数据集、性能指标、混合模型和性能增强，同时还讨论了数据需求和计算量等技术挑战。论文最后概述了未来的研究方向，旨在让读者更深入地理解ViT在智能农业中的变革潜力。

> **摘要翻译:** 检测植物病害是现代农业的一个关键方面，因为它在维持作物健康和提高总产量方面发挥着关键作用。传统方法虽然仍然有价值，但通常依赖于人工检查或传统机器学习技术，两者在可扩展性和准确性方面都面临局限性。最近，视觉Transformer（ViT）作为一种有前景的替代方案出现，提供了处理长距离依赖和提高视觉任务可扩展性等优势。本综述探讨了ViT在精准农业中的应用，涵盖了一系列任务。我们首先介绍ViT的基础架构，并讨论它们从自然语言处理（NLP）到计算机视觉的转变。讨论包括卷积神经网络（CNN）等传统模型中的归纳偏置概念，以及ViT如何减轻这些偏置。我们对近期文献进行了全面回顾，重点关注关键方法、数据集和性能指标。本研究还包括CNN和ViT的比较分析，以及对混合模型和性能增强的回顾。解决了数据要求、计算需求和模型可解释性等技术挑战，并提出了潜在解决方案。最后，我们概述了未来研究方向和技术进步，这些进步可以进一步支持ViT在实际农业环境中的集成。本研究的目标是让从业者和研究人员更深入地了解ViT如何有望改变智能和精准农业。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [560] [A COCO-Formatted Instance-Level Dataset for Plasmodium Falciparum Detection in Giemsa-Stained Blood Smears](https://arxiv.org/abs/2507.18483)
> *采用COCO格式实例级数据集用于吉姆萨染色血涂片中恶性疟原虫的检测*

*Frauke Wilm, Luis Carlos Rivera Monroy, Mathias Öttl, Lukas Mürdter, Leonid Mill, Andreas Maier* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 恶性疟原虫检测, 疟疾诊断, 数据集, COCO格式, 深度学习

**Comment:** 7 pages, 4 figures, 2 tables, accepted at MICCAI 2025 Open Data

> **TL;DR:** 本文提出了一个COCO格式的恶性疟原虫检测实例级数据集，旨在解决深度学习在自动化疟疾诊断中因缺乏高质量标注数据而面临的挑战。

**AI_Comments:** 这篇论文通过创建一个高质量、COCO格式的恶性疟原虫检测数据集，解决了深度学习在自动化疟疾诊断中面临的关键数据瓶颈。其创新之处在于展示了自动化标注精修结合人工修正的有效性，为医学图像分析中大规模高质量数据集的构建提供了宝贵经验。该数据集的公开可用性将极大地促进相关领域的研究和应用发展，对发展中国家的疟疾诊断具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确检测吉姆萨染色血涂片中的恶性疟原虫对可靠的疟疾诊断至关重要，尤其是在发展中国家。然而，基于深度学习的疟疾诊断方法因缺乏详细的实例级标注数据集而受限。

**Method:** 作者提供了一个增强版的NIH疟疾公开数据集，其中包含COCO格式的详细边界框标注，以支持目标检测训练。他们通过训练Faster R-CNN模型来检测受感染和未受感染的红细胞以及白细胞，从而验证了修订后的标注。

**Result:** 在原始数据集上的交叉验证显示，受感染细胞检测的F1分数高达0.88。

**Conclusion:** 这些结果强调了标注数量和一致性的重要性，并表明自动化标注精修结合有针对性的人工校正可以产生足够高质量的训练数据，以实现稳健的检测性能。

> **ai_Abstract:** 本文提出了一个增强版的NIH疟疾数据集，该数据集以COCO格式提供了详细的实例级边界框标注，旨在解决深度学习在疟疾诊断中因缺乏高质量数据集而面临的挑战。通过训练Faster R-CNN模型验证了数据集的有效性，并在受感染细胞检测上取得了0.88的F1分数。研究结果强调了高质量标注对提升检测性能的重要性，并展示了自动化与人工修正相结合的标注方法能够生成支持稳健目标检测的训练数据。

> **摘要翻译:** 吉姆萨染色血涂片中恶性疟原虫的准确检测是可靠疟疾诊断的重要组成部分，尤其是在发展中国家。基于深度学习的目标检测方法在自动化疟疾诊断方面显示出巨大潜力，但其应用受到缺乏详细实例级标注数据集的限制。在这项工作中，我们提出了一个公开可用的NIH疟疾数据集的增强版本，其中包含COCO格式的详细边界框标注，以支持目标检测训练。我们通过训练Faster R-CNN模型来检测受感染和未受感染的红细胞以及白细胞，从而验证了修订后的标注。在原始数据集上进行的交叉验证显示，受感染细胞检测的F1分数高达0.88。这些结果强调了标注数量和一致性的重要性，并表明自动化标注精修结合有针对性的人工校正可以产生足够高质量的训练数据，以实现稳健的检测性能。更新后的标注集已通过GitHub公开提供：https://github.com/MIRA-Vision-Microscopy/malaria-thin-smear-coco。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [569] [Advances in 4D Generation: A Survey](https://arxiv.org/abs/2503.14501)
> *4D生成领域的进展：一项综述*

*Qiaowei Miao, Kehan Li, Jinsheng Quan, Zhiyuan Min, Shaojie Ma, Yichao Xu, Yi Yang, Ping Liu, Yawei Luo* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 4D生成, 综述, 动态3D资产, 生成式AI, 时空一致性

**Comment:** 

> **TL;DR:** 这篇综述系统回顾了4D生成领域，包括其表示、生成框架、基本范式及面临的挑战，旨在提供统一理解和指导未来研究。

**AI_Comments:** 这篇综述对于快速发展的4D生成领域非常有价值。它提供了急需的结构和全面的概述，帮助研究人员理解当前方法，识别空白，并关注关键挑战。其对表示、流程和范式的分类，以及对开放问题的概述，使其成为一个基础性参考。

<details>
  <summary>Details</summary>

**Motivation:** 尽管4D生成领域进展迅速，但该领域缺乏对4D表示、生成框架、基本范式以及核心技术挑战的统一理解。

**Method:** 本文通过系统深入地综述4D生成领域，首先对基础4D表示和相关技术进行分类；接着深入分析了基于条件和表示方法的代表性生成流程；随后讨论了运动和几何先验如何集成以确保时空一致性；从应用角度总结了4D生成任务；并多维度比较了四种基本范式（端到端、基于生成数据、基于隐式蒸馏、基于显式监督）；最后，强调了五个关键挑战（一致性、可控性、多样性、效率、保真度）并结合现有方法进行阐述。

**Result:** 本文分类了基础4D表示和相关技术；深入分析了代表性生成流程；讨论了运动和几何先验的集成方法；总结了动态对象/场景生成、数字人合成、可编辑4D内容和具身AI等应用任务；比较了端到端、基于生成数据、基于隐式蒸馏和基于显式监督四种基本范式；并提出了当前面临的一致性、可控性、多样性、效率和保真度五大挑战。

**Conclusion:** 通过提炼最新进展并概述开放问题，本文为4D生成领域的未来研究提供了全面且前瞻性的视角。

> **ai_Abstract:** 本综述系统回顾了新兴的4D生成领域，该领域旨在合成时间连贯的动态3D资产。为解决该领域缺乏统一理解的问题，论文对4D表示进行分类，分析了生成流程，讨论了时空一致性，总结了应用任务，并比较了四种基本范式。最后，论文强调了五个关键挑战（一致性、可控性、多样性、效率、保真度），以期指导未来的研究方向。

> **摘要翻译:** 生成式人工智能最近已从静态图像和视频合成发展到3D内容生成，最终催生了4D生成——一项在用户输入指导下合成时间连贯的动态3D资产的任务。作为新兴的研究前沿，4D生成能够实现更丰富的交互式和沉浸式体验，其应用范围从数字人到自动驾驶。尽管进展迅速，但该领域缺乏对4D表示、生成框架、基本范式以及其面临的核心技术挑战的统一理解。本综述对4D生成领域进行了系统而深入的审查。为了全面描述4D生成，我们首先对基本的4D表示进行分类，并概述了相关的4D生成技术。然后，我们对基于条件和表示方法的代表性生成流程进行了深入分析。随后，我们讨论了如何将运动和几何先验集成到4D输出中，以确保在各种控制方案下的时空一致性。从应用角度来看，本文总结了动态对象/场景生成、数字人合成、可编辑4D内容和具身AI等领域的4D生成任务。此外，我们总结并多维度比较了4D生成的四种基本范式：端到端（End-to-End）、基于生成数据（Generated-Data-Based）、基于隐式蒸馏（Implicit-Distillation-Based）和基于显式监督（Explicit-Supervision-Based）。在分析的最后，我们强调了五个关键挑战——一致性、可控性、多样性、效率和保真度——并结合现有方法对这些挑战进行了背景化。通过提炼最新进展并概述开放问题，这项工作提供了全面且前瞻性的视角，以指导4D生成领域的未来研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [570] [TextSAM-EUS: Text Prompt Learning for SAM to Accurately Segment Pancreatic Tumor in Endoscopic Ultrasound](https://arxiv.org/abs/2507.18082)
> *TextSAM-EUS：基于文本提示学习的SAM模型在内窥镜超声中准确分割胰腺肿瘤*

*Pascal Spiegler, Taha Koleilat, Arash Harirpoush, Corey S. Miller, Hassan Rivaz, Marta Kersten-Oertel, Yiming Xiao* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 胰腺肿瘤, 内窥镜超声, SAM, 文本提示学习, 医学图像分割

**Comment:** Accepted to ICCV 2025 Workshop CVAMD

> **TL;DR:** TextSAM-EUS利用文本提示学习和LoRA适配SAM，实现胰腺肿瘤在EUS图像中的准确自动分割，优于现有SOTA模型。

**AI_Comments:** 该论文的创新点在于首次将文本提示学习应用于基于SAM的医学图像分割，特别是在EUS这种具有挑战性的胰腺肿瘤分割任务中。其轻量级（仅调整0.86%参数）且无需手动几何提示即可实现高精度自动分割的能力，显著降低了对专家标注数据的依赖，提高了模型在临床应用中的实用性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 胰腺癌预后不良，依赖内窥镜超声（EUS）进行靶向活检和放疗。然而，EUS图像中的散斑噪声、低对比度和不直观的外观使得使用全监督深度学习（DL）模型进行胰腺肿瘤分割容易出错，并且高度依赖于大量由专家标注的数据集。

**Method:** TextSAM-EUS是一种新颖、轻量级的、文本驱动的Segment Anything Model（SAM）适应模型，在推理时无需手动几何提示。该方法通过BiomedCLIP文本编码器利用文本提示学习（上下文优化），并结合基于LoRA的SAM架构改编，以实现EUS中胰腺肿瘤的自动分割，仅调整了总参数的0.86%。

**Result:** 在公共胰腺内窥镜超声数据库上，TextSAM-EUS在自动提示下达到了82.69%的Dice系数和85.28%的归一化表面距离（NSD），在手动几何提示下达到了83.10%的Dice系数和85.70%的NSD，优于现有的最先进（SOTA）监督DL模型和基础模型（例如SAM及其变体）。

**Conclusion:** 作为首次将提示学习引入基于SAM的医学图像分割的尝试，TextSAM-EUS为高效、鲁棒的自动EUS分割提供了一个实用选择。

> **ai_Abstract:** TextSAM-EUS旨在解决内窥镜超声（EUS）中胰腺肿瘤分割面临的挑战，通过结合文本提示学习和LoRA对Segment Anything Model（SAM）进行轻量级适应。该模型利用BiomedCLIP文本编码器进行上下文优化，实现了无需手动几何提示的自动分割，且仅调整了0.86%的总参数。实验结果表明，TextSAM-EUS在公共数据集上表现优异，Dice系数和NSD均超越了现有SOTA监督模型和SAM变体，为EUS图像中的胰腺肿瘤提供了高效、鲁棒的自动分割方案。

> **摘要翻译:** 胰腺癌预后不良，依赖内窥镜超声（EUS）进行靶向活检和放疗。然而，EUS图像中的散斑噪声、低对比度和不直观的外观使得使用全监督深度学习（DL）模型进行胰腺肿瘤分割容易出错，并且高度依赖于大量由专家标注的数据集。为了解决这些挑战，我们提出了TextSAM-EUS，这是一种新颖、轻量级的、文本驱动的Segment Anything Model（SAM）适应模型，在推理时无需手动几何提示。我们的方法通过BiomedCLIP文本编码器利用文本提示学习（上下文优化），并结合基于LoRA的SAM架构改编，以实现EUS中胰腺肿瘤的自动分割，仅调整了总参数的0.86%。在公共胰腺内窥镜超声数据库上，TextSAM-EUS在自动提示下达到了82.69%的Dice系数和85.28%的归一化表面距离（NSD），在手动几何提示下达到了83.10%的Dice系数和85.70%的NSD，优于现有的最先进（SOTA）监督DL模型和基础模型（例如SAM及其变体）。作为首次将提示学习引入基于SAM的医学图像分割的尝试，TextSAM-EUS为高效、鲁棒的自动EUS分割提供了一个实用选择。我们的代码将在接受后公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [571] [A Multi-Dataset Benchmark for Semi-Supervised Semantic Segmentation in ECG Delineation](https://arxiv.org/abs/2507.18323)
> *心电图描绘中半监督语义分割的多数据集基准*

*Minje Park, Jeonghwa Lim, Taehyung Yu, Sunghoon Joo* | **Category: cs.CV, cs.AI, cs.LG, eess.SP** | **Updated: 2025-07-24**

**Keywords:** 心电图描绘, 半监督学习, 语义分割, 数据集基准, Transformer

**Comment:** 6 pages, 2 figures

> **TL;DR:** 本研究为心电图描绘中的半监督语义分割创建了一个多数据集基准，评估了不同算法和架构，并发现Transformer优于卷积网络，旨在推动该领域的研究。

**AI_Comments:** 这项研究通过建立一个全面的多数据集基准，解决了心电图描绘领域标注数据稀缺的关键问题。其创新点在于首次系统地评估了半监督学习方法在心电图描绘中的应用，并比较了不同神经网络架构的性能。特别地，发现Transformer在半监督设置下的优越性为未来的模型选择提供了重要指导。该基准的建立及其提出的标准化评估框架对于推动心电图描绘的半监督研究具有重要意义，有助于加速临床诊断工具的开发。

<details>
  <summary>Details</summary>

**Motivation:** 尽管深度学习在心电图描绘方面取得了进展，但由于缺乏公开可用的带注释数据集，进展受到限制。半监督学习通过利用大量未标记的心电图数据提供了一个有前景的解决方案。

**Method:** 研究团队为心电图描绘中的半监督语义分割（SemiSeg）建立了第一个系统基准。他们整合并统一了多个公共数据集，包括以前未充分利用的来源。他们采用了五种代表性的计算机视觉SemiSeg算法，并在卷积网络和Transformer两种不同架构上实现，在域内和跨域两种设置下进行评估。此外，他们提出了心电图特有的训练配置和增强策略，并引入了标准化的评估框架。

**Result:** 结果显示，在半监督心电图描绘中，Transformer的性能优于卷积网络。

**Conclusion:** 该基准有望成为推进半监督心电图描绘方法的基础，并促进该领域的进一步研究。

> **ai_Abstract:** 本研究为心电图描绘中的半监督语义分割（SemiSeg）建立了首个系统性多数据集基准。研究人员整合了多个公共心电图数据集，并评估了五种主流SemiSeg算法在卷积网络和Transformer两种架构下在域内和跨域设置中的表现。他们还提出了心电图特有的训练配置和增强策略，并引入了标准化评估框架。实验结果表明，Transformer在半监督心电图描绘任务中表现优于卷积网络。该基准旨在为未来的半监督心电图描绘方法研究奠定基础。

> **摘要翻译:** 心电图（ECG）描绘，即对有意义波形特征的分割，对临床诊断至关重要。尽管深度学习取得了最新进展，但由于公开可用的带注释数据集的稀缺，进展受到限制。半监督学习通过利用大量未标记的心电图数据提供了一个有前景的解决方案。在这项研究中，我们提出了心电图描绘中半监督语义分割（SemiSeg）的第一个系统基准。我们整理并统一了多个公共数据集，包括以前未充分利用的来源，以支持稳健和多样化的评估。我们采用了计算机视觉中的五种代表性SemiSeg算法，在两种不同的架构：卷积网络和Transformer上实现它们，并在两种不同的设置：域内和跨域中进行评估。此外，我们提出了心电图特有的训练配置和增强策略，并引入了标准化的评估框架。我们的结果表明，在半监督心电图描绘中，Transformer的性能优于卷积网络。我们预计我们的基准将作为推进半监督心电图描绘方法的基础，并将促进该领域的进一步研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [598] [One Look is Enough: A Novel Seamless Patchwise Refinement for Zero-Shot Monocular Depth Estimation Models on High-Resolution Images](https://arxiv.org/abs/2503.22351)
> *一眼即足：一种用于高清图像上零样本单目深度估计模型的新型无缝分块细化方法*

*Byeongjun Kwon, Munchurl Kim* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 零样本深度估计, 高分辨率图像, 分块细化, 深度不连续, 泛化能力

**Comment:** ICCV 2025 (camera-ready version). [Project
  page](https://kaist-viclab.github.io/One-Look-is-Enough_site)

> **TL;DR:** 本文提出了Patch Refine Once (PRO)框架，旨在解决零样本单目深度估计模型在处理高分辨率图像时遇到的深度不连续和泛化能力差的问题，通过分组块一致性训练和无偏差掩蔽实现高效和可泛化的性能。

**AI_Comments:** PRO框架，特别是其分组块一致性训练和无偏差掩蔽组件，直接解决了当前高分辨率深度估计方法在深度不连续、效率和泛化能力方面的关键局限性，具有创新性。它提高了零样本深度估计模型在真实世界高分辨率场景中的适用性，这对于实际计算机视觉应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有零样本深度估计模型在处理高分辨率图像时存在困难，因为训练和推理分辨率不匹配。全分辨率处理会导致精度下降和内存消耗巨大，而下采样则会使边缘模糊。流行的基于块的方法引入深度不连续问题且效率低下，并且由于依赖合成数据集而导致泛化能力差。

**Method:** 本文提出了Patch Refine Once (PRO)，一个高效且可泛化的基于瓦片的框架。PRO包含两个关键组件：(i) 分组块一致性训练，通过在单个反向传播步骤中联合处理四个重叠块并在其重叠区域强制执行一致性损失，提高测试时效率并缓解深度不连续问题；(ii) 无偏差掩蔽，防止深度估计模型过度拟合数据集特有的偏差，即使在合成数据上训练后也能更好地泛化到真实世界数据集。

**Result:** 在Booster、ETH3D、Middlebury 2014和NuScenes上的零样本评估表明，PRO可以无缝集成到现有深度估计模型中。

**Conclusion:** PRO框架有效地解决了现有零样本深度估计模型在处理高分辨率图像时的局限性，提供了一种高效、可泛化且可无缝集成的解决方案。

> **ai_Abstract:** 本文介绍了Patch Refine Once (PRO)，一种新颖的基于瓦片的框架，旨在解决高分辨率图像零样本单目深度估计中的挑战。PRO通过其两个核心组件：分组块一致性训练和无偏差掩蔽，克服了现有基于块方法中常见的深度不连续和泛化能力差等问题。评估结果表明，PRO可以与现有模型无缝集成并表现出有效性。

> **摘要翻译:** 零样本深度估计（DE）模型由于在大规模数据集上训练，表现出强大的泛化性能。然而，现有模型在处理高分辨率图像时面临困难，原因在于训练（分辨率较低）和推理（分辨率较高）图像分辨率存在差异。以全分辨率处理会导致深度估计精度下降并消耗大量内存，而下采样到训练分辨率则会导致估计深度图像中边缘模糊。当前流行的高分辨率深度估计方法采用基于块的方法，这在重新组合估计的深度块时引入了深度不连续问题，导致测试时效率低下。此外，为了获得细粒度的深度细节，这些方法由于真实世界稀疏的地面实况深度而依赖于合成数据集，导致泛化能力差。为了解决这些限制，我们提出了Patch Refine Once (PRO)，一个高效且可泛化的基于瓦片的框架。我们的PRO包含两个关键组件：(i) 分组块一致性训练，通过在单个反向传播步骤中联合处理四个重叠块并在其重叠区域强制执行一致性损失，从而提高测试时效率并缓解深度不连续问题；(ii) 无偏差掩蔽，防止DE模型过度拟合数据集特有的偏差，即使在合成数据上训练后也能更好地泛化到真实世界数据集。在Booster、ETH3D、Middlebury 2014和NuScenes上的零样本评估表明，我们的PRO可以无缝集成到现有深度估计模型中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [599] [FishDet-M: A Unified Large-Scale Benchmark for Robust Fish Detection and CLIP-Guided Model Selection in Diverse Aquatic Visual Domains](https://arxiv.org/abs/2507.17859)
> *FishDet-M：一个用于多样水生视觉领域中鲁棒鱼类检测和CLIP引导模型选择的统一大规模基准*

*Muayad Abujabal, Lyes Saad Saoud, Irfan Hussain* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-23**

**Keywords:** 鱼类检测, 水下图像, 基准测试, CLIP, 模型选择, 目标检测

**Comment:** 

> **TL;DR:** 提出了FishDet-M，一个大型统一鱼类检测基准，并引入CLIP模型选择框架以提高水下图像中鱼类检测的鲁棒性和自适应性。

**AI_Comments:** 本文通过构建目前最大的统一鱼类检测基准FishDet-M，显著解决了水下图像鱼类检测领域数据集碎片化和评估不一致的痛点。引入CLIP引导的模型选择框架，实现了无需集成计算的零样本自适应部署，这是重要的创新点，提高了实际应用的效率和鲁棒性。该工作为水下计算机视觉和智能海洋系统的未来研究提供了宝贵的标准化资源。

<details>
  <summary>Details</summary>

**Motivation:** 现有水下图像鱼类检测面临数据集碎片化、成像条件异构和评估协议不一致的挑战，限制了实际部署。

**Method:** 提出了FishDet-M，一个包含13个公开数据集的统一大规模鱼类检测基准，数据采用COCO风格的边界框和分割掩码标注。系统地基准测试了28种当代目标检测模型（YOLOv8-YOLOv12系列、R-CNN和DETR）。引入了基于CLIP的模型选择框架，利用视觉-语言对齐动态选择最合适的检测器。

**Result:** 结果显示不同模型在FishDet-M上的检测性能各异，以及精度和效率之间的权衡。CLIP模型选择策略在不进行集成计算的情况下实现了高性能。

**Conclusion:** FishDet-M建立了一个标准化、可复现的复杂水生场景目标检测评估平台，并支持自适应部署。

> **ai_Abstract:** 本文提出了FishDet-M，一个大规模统一的鱼类检测基准，整合了13个多样水生环境数据集，并采用COCO风格标注。研究系统评估了28种主流目标检测模型，揭示了性能与效率的权衡。为实现自适应部署，引入了基于CLIP的零样本模型选择框架，该框架通过视觉-语言对齐动态选择最佳检测器，无需集成计算即可实现高性能。FishDet-M旨在为水下计算机视觉研究提供标准化平台。

> **摘要翻译:** 水下图像中准确的鱼类检测对于生态监测、水产养殖自动化和机器人感知至关重要。然而，实际部署仍受到数据集碎片化、成像条件异构和评估协议不一致的限制。为了解决这些问题，我们提出了FishDet-M，这是最大的统一鱼类检测基准，包含13个公开可用的数据集，涵盖海洋、半咸水、遮挡和水族馆场景等多样水生环境。所有数据都使用COCO风格的边界框和分割掩码注释进行统一，从而实现一致和可扩展的跨域评估。我们系统地基准测试了28种当代目标检测模型，包括YOLOv8到YOLOv12系列、基于R-CNN的检测器和基于DETR的模型。评估使用标准指标，包括mAP、mAP@50和mAP@75，以及尺度特定分析（AP$_S$、AP$_M$、AP$_L$）和延迟、参数数量方面的推理性能分析。结果突出显示了在FishDet-M上训练的不同模型检测性能的差异，以及不同架构模型在精度和效率之间的权衡。为了支持自适应部署，我们引入了一个基于CLIP的模型选择框架，该框架利用视觉-语言对齐动态识别每个输入图像最语义合适的检测器。这种零样本选择策略无需集成计算即可实现高性能，为实时应用提供了可扩展的解决方案。FishDet-M为复杂水生场景中的目标检测评估建立了一个标准化和可复现的平台。所有数据集、预训练模型和评估工具均公开可用，以促进水下计算机视觉和智能海洋系统领域的未来研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [602] [Delving into Mapping Uncertainty for Mapless Trajectory Prediction](https://arxiv.org/abs/2507.18498)
> *深入研究无地图轨迹预测中的地图不确定性*

*Zongzheng Zhang, Xuchong Qiu, Boran Zhang, Guantian Zheng, Xunjiang Gu, Guoxuan Chi, Huan-ang Gao, Leichen Wang, Ziming Liu, Xinrun Li, Igor Gilitschenski, Hongyang Li, Hang Zhao, Hao Zhao* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 无地图轨迹预测, 地图不确定性, 运动状态, 本体感知场景门控, 自动驾驶

**Comment:** Accepted to IROS 2025, Project Page:
  https://ethan-zheng136.github.io/Dev-Unc/

> **TL;DR:** 本文通过分析智能体运动状态并提出自适应门控机制和基于协方差的地图不确定性方法，显著提高了无地图轨迹预测的性能。

**AI_Comments:** 本文的创新之处在于识别出智能体运动状态对于有效利用地图不确定性的重要性，并据此提出了自适应的本体感知场景门控机制。同时，引入与地图几何对齐的协方差不确定性表示也具有新颖性。这些贡献使得地图不确定性在无地图轨迹预测中的集成更加智能和有效，为自动驾驶领域的一个关键挑战提供了有价值的解决方案，并提高了系统的可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶正转向无地图方法，即在线生成高清地图，以减少昂贵的标注和维护成本。然而，这些在线生成的地图的可靠性存在不确定性。虽然将地图不确定性纳入轨迹预测任务可以提高性能，但现有策略对这种不确定性何时有益的特定场景的洞察力有限。

**Method:** 本文首先分析了地图不确定性对轨迹预测影响最大的驾驶场景，并确定了智能体运动状态这一关键的、以前被忽视的因素。在此基础上，提出了一种新颖的“本体感知场景门控”（Proprioceptive Scenario Gating）方法，根据自我车辆未来运动状态的预测，自适应地将地图不确定性集成到轨迹预测中。此外，还引入了一种基于协方差的地图不确定性方法，该方法与地图几何结构更好地对齐。

**Result:** 所提出的方法在真实世界的nuScenes驾驶数据集上，比最先进的无地图轨迹预测方法性能提高了高达23.6%。该方法增强了在线地图与轨迹预测之间的协同作用，提供了不确定性何时有利的可解释性，并优于以往的集成方法。

**Conclusion:** 本文通过分析运动状态并引入自适应门控机制和新的协方差地图不确定性方法，成功地提升了无地图轨迹预测的性能，使其更具可解释性，并实现了显著的性能提升。

> **ai_Abstract:** 本文旨在解决无地图自动驾驶中在线生成地图的可靠性不确定性问题，以及现有方法在利用地图不确定性进行轨迹预测时缺乏场景洞察的局限性。研究发现智能体的运动状态是影响地图不确定性效益的关键因素，并基于此提出了一种新颖的本体感知场景门控方法，根据车辆未来运动状态自适应地整合地图不确定性。同时，引入了基于协方差的地图不确定性方法以更好地匹配地图几何。实验证明，该方法显著提升了无地图轨迹预测性能，并增强了可解释性。

> **摘要翻译:** 自动驾驶的最新进展正朝着无地图方法发展，即直接从传感器数据在线生成高精度（HD）地图，从而减少昂贵的标注和维护需求。然而，这些在线生成的地图的可靠性仍然不确定。尽管将地图不确定性纳入下游轨迹预测任务已显示出性能改进的潜力，但目前的策略对这种不确定性有益的特定场景提供的洞察力有限。在这项工作中，我们首先分析了地图不确定性对轨迹预测产生最大积极影响的驾驶场景，并识别出一个关键的、以前被忽视的因素：智能体的运动状态。基于这些见解，我们提出了一种新颖的本体感知场景门控（Proprioceptive Scenario Gating），它根据自我车辆未来运动学预测自适应地将地图不确定性集成到轨迹预测中。这种轻量级、自监督的方法增强了在线地图与轨迹预测之间的协同作用，提供了不确定性何时有利的可解释性，并优于以前的集成方法。此外，我们引入了一种基于协方差的地图不确定性方法，该方法与地图几何结构更好地对齐，进一步提高了轨迹预测。广泛的消融研究证实了我们方法的有效性，使用真实世界的nuScenes驾驶数据集，无地图轨迹预测性能比最先进的方法提高了高达23.6%。我们的代码、数据和模型已在 https://github.com/Ethan-Zheng136/Map-Uncertainty-for-Trajectory-Prediction 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [607] [Beyond Low-rankness: Guaranteed Matrix Recovery via Modified Nuclear Norm](https://arxiv.org/abs/2507.18327)
> *超越低秩性：通过改进核范数实现有保证的矩阵恢复*

*Jiangjun Peng, Yisi Luo, Xiangyong Cao, Shuang Xu, Deyu Meng* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 矩阵恢复, 核范数, 改进核范数, 鲁棒PCA, 矩阵补全

**Comment:** 15 pages, 14 figures

> **TL;DR:** 本文提出一种新的改进核范数（MNN）框架，通过对变换矩阵应用核范数，同时捕获局部和全局信息，并在鲁棒PCA和矩阵补全中提供精确的理论恢复保证。

**AI_Comments:** 这项工作通过引入改进核范数（MNN）框架，在矩阵恢复领域取得了显著进展。其创新点在于通过对矩阵进行变换后应用核范数，巧妙地结合了局部和全局信息，避免了参数调优的复杂性。更重要的是，它为鲁棒PCA和矩阵补全提供了严格的理论恢复保证，填补了现有方法在此方面的空白。MNN的通用性和灵活性使其能够适应多种变换，为结构化低秩恢复提供了一个统一且强大的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的核范数（NN）在矩阵恢复问题中主要利用数据的全局低秩结构，但现有结合局部和全局信息的方法缺乏精确的理论恢复保证。

**Method:** 引入了一种新的改进核范数（MNN）框架，其中MNN族范数通过采用合适的变换并在变换后的矩阵上执行核范数来定义。

**Result:** MNN框架能够联合捕获局部信息和全局低秩性，无需权衡参数调整。在对变换的温和假设下，为鲁棒PCA和矩阵补全任务提供了精确的理论恢复保证。广泛的实验证明了方法的有效性。

**Conclusion:** MNN框架提供了一种通用且灵活的设计，能够适应各种已验证的变换，从而为结构化低秩恢复提供了一种统一且有效的方法，并在理论上提供了优于现有结合局部和全局信息方法的恢复保证。

> **ai_Abstract:** 本文提出了一种改进的核范数（MNN）框架，通过对变换后的矩阵应用核范数，旨在解决矩阵恢复问题。该框架的优势在于能够同时捕获局部和全局低秩信息，且无需额外的参数调整。更重要的是，MNN在温和假设下为鲁棒PCA和矩阵补全任务提供了精确的理论恢复保证，这是现有方法所不具备的。该方法设计通用灵活，并通过实验验证了其有效性。

> **摘要翻译:** 核范数（NN）在矩阵恢复问题中已被广泛探索，例如鲁棒主成分分析（Robust PCA）和矩阵补全，利用了数据固有的全局低秩结构。在本研究中，我们引入了一种新的改进核范数（MNN）框架，其中MNN族范数通过采用合适的变换并在变换后的矩阵上执行核范数来定义。MNN框架提供了两个主要优势：（1）它在无需权衡参数调整的情况下，联合捕获局部信息和全局低秩性；（2）在对变换的温和假设下，我们为鲁棒PCA和矩阵补全任务提供了精确的理论恢复保证——这是现有结合局部和全局信息的方法所不具备的成就。由于其通用和灵活的设计，MNN可以适应各种已验证的变换，从而为结构化低秩恢复提供了一种统一且有效的方法。广泛的实验证明了我们方法的有效性。代码和补充材料可在https://github.com/andrew-pengjj/modified_nuclear_norm获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [616] [PALADIN : Robust Neural Fingerprinting for Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.03170)
> *PALADIN：文本到图像扩散模型的鲁棒神经指纹识别*

*Murthy L, Subarna Tripathi* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 神经指纹识别, 文本到图像扩散模型, 循环纠错码, 归因准确性, 风险缓解

**Comment:** 

> **TL;DR:** 本文提出了一种新的、准确的神经指纹识别方法，用于文本到图像扩散模型，旨在解决现有技术归因准确率不足的问题，并利用了循环纠错码的概念。

**AI_Comments:** 这项工作的重要性在于它解决了当前神经指纹识别技术在实践部署中的关键障碍——即未能达到100%归因准确率。通过引入循环纠错码的概念，该方法可能为提高归因鲁棒性和准确性提供新的视角，对于打击深度伪造和恶意内容生成具有重要意义。创新点在于将编码理论的概念应用于神经网络指纹识别领域。

<details>
  <summary>Details</summary>

**Motivation:** 文本到图像生成模型（特别是开源模型）被恶意使用的风险日益严重，急需一种风险缓解策略。神经指纹识别是当前流行的归因技术，但现有方法均未能达到100%的归因准确率，导致其在实践中不可部署。

**Method:** 本文提出了一种准确的方法，通过利用编码理论中循环纠错码的概念，将神经指纹识别技术融入文本到图像扩散模型中。

**Result:** Not mentioned in abstract

**Conclusion:** 本文提出了一种准确的神经指纹识别方法，通过利用编码理论中循环纠错码的概念，旨在解决现有方法在文本到图像扩散模型归因准确性方面的不足，从而实现可部署的解决方案。

> **ai_Abstract:** 本文针对文本到图像扩散模型被恶意滥用的风险，提出了一种名为PALADIN的鲁棒神经指纹识别方法。鉴于现有神经指纹识别技术在归因准确性上未能达到100%且因此无法实际部署的局限性，作者引入了编码理论中的循环纠错码概念，以期实现对文本到图像扩散模型更准确的指纹识别，从而有效进行风险归因。

> **摘要翻译:** 文本到图像生成模型被恶意使用的风险，特别是由于此类模型的开源开发，已成为一个严重问题。作为一种风险缓解策略，利用神经指纹识别技术对生成模型进行归因正在成为一种流行技术。最近大量工作旨在解决神经指纹识别问题。人们已经广泛研究了此类模型的归因准确性与生成质量之间的权衡。然而，现有方法均未达到100%的归因准确性。任何准确率低于百分之百的模型在实践中都是不可部署的。在这项工作中，我们提出了一种准确的方法，利用编码理论文献中的循环纠错码概念，将神经指纹识别技术融入文本到图像扩散模型中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [618] [Comparison of Segmentation Methods in Remote Sensing for Land Use Land Cover](https://arxiv.org/abs/2507.18099)
> *遥感中土地利用土地覆盖分割方法的比较*

*Naman Srivastava, Joel D Joy, Yash Dixit, Swarup E, Rakshit Ramesh* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 土地利用土地覆盖, 遥感, 深度学习, 城市规划, Cartosat MX

**Comment:** 

> **TL;DR:** 本研究评估了先进的土地利用土地覆盖（LULC）测绘技术，包括基于LUT的大气校正、监督和半监督学习模型（DeeplabV3+和CPS），并通过印度海得拉巴的案例研究展示了这些技术在城市规划中的实用性，揭示了快速城市化带来的土地利用变化。

**AI_Comments:** 这篇论文的创新点在于结合了大气校正、先进的监督与半监督深度学习模型（DeeplabV3+和改进的CPS）进行LULC测绘，并特别强调了CPS模型中动态加权对伪标签可靠性的提升。其重要性在于提供了一套实用的LULC变化监测方法，对智慧城市建设和可持续发展规划具有直接指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 土地利用土地覆盖（LULC）测绘对于城市和资源规划至关重要，是发展智慧和可持续城市的核心要素。

**Method:** 该研究评估了先进的LULC测绘技术。方法包括对Cartosat多光谱（MX）传感器图像应用基于查找表（LUT）的大气校正，然后使用监督和半监督学习模型进行LULC预测。具体探索了DeeplabV3+和交叉伪监督（CPS）模型，其中CPS模型通过动态加权进行了改进，以提高训练期间伪标签的可靠性。

**Result:** 通过对印度海得拉巴的案例研究，分析了Cartosat MX图像随时间的变化，揭示了快速城市化导致显著的土地利用变化，例如城市蔓延、绿地缩小和工业区扩张。这证明了这些技术对城市规划者和政策制定者的实用性。

**Conclusion:** 该研究展示了所评估的LULC测绘技术在分析和理解城市土地利用变化方面的实用性和准确性，为城市规划者和政策制定者提供了有价值的工具。

> **ai_Abstract:** 本研究评估了先进的土地利用土地覆盖（LULC）测绘技术，旨在支持城市和资源规划。该方法结合了对Cartosat多光谱图像的基于查找表（LUT）的大气校正，以及DeeplabV3+和经过动态加权改进的交叉伪监督（CPS）等监督和半监督学习模型。通过印度海得拉巴的案例研究，研究分析了这些技术在揭示快速城市化导致的土地利用变化（如城市蔓延和绿地减少）方面的准确性和实用性，证明了其对城市规划的实际价值。

> **摘要翻译:** 土地利用土地覆盖（LULC）测绘对于城市和资源规划至关重要，是发展智慧和可持续城市的核心要素之一。本研究评估了先进的LULC测绘技术，重点关注应用于Cartosat多光谱（MX）传感器图像的基于查找表（LUT）的大气校正，随后使用监督和半监督学习模型进行LULC预测。我们探索了DeeplabV3+和交叉伪监督（CPS）模型。CPS模型通过动态加权进一步优化，从而提高了训练期间伪标签的可靠性。这种综合方法分析了LULC测绘技术在各种城市规划应用中的准确性和实用性。以印度海得拉巴为例，说明了快速城市化导致的显著土地利用变化。通过分析Cartosat MX图像随时间的变化，我们强调了城市蔓延、绿地缩小和工业区扩张等转变。这证明了这些技术对城市规划者和政策制定者的实际效用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [628] [Unsupervised Feature Disentanglement and Augmentation Network for One-class Face Anti-spoofing](https://arxiv.org/abs/2503.22929)
> *单类别人脸防伪中的无监督特征解耦与增强网络*

*Pei-Kai Huang, Jun-Xiong Chong, Ming-Tsung Hsu, Fang-Yu Hsu, Yi-Ting Lin, Kai-Heng Chien, Hao-Chiang Shao, Chiou-Ting Hsu* | **Category: cs.CV** | **Updated: 2025-07-23**

**Keywords:** 人脸防伪, 单类别FAS, 特征解耦, 特征增强, UFDANet

**Comment:** 

> **TL;DR:** UFDANet通过无监督特征解耦和增强来提高单类别人脸防伪的泛化能力，解决了现有方法中活体特征与域信息纠缠的问题。

**AI_Comments:** 该论文提出了一种创新的单类别人脸防伪方法UFDANet，其核心创新在于无监督特征解耦和两种独立的特征增强策略。通过解耦活体和域特征并分别进行增强，UFDANet有效地提升了模型对未知攻击的泛化能力，解决了传统单类别FAS的痛点。其性能达到甚至超越了部分双类别方法，显示了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 人脸防伪（FAS）技术旨在通过区分真实活体人脸和欺骗尝试来增强人脸身份验证的安全性。双类别FAS方法存在对训练攻击过拟合的风险，而单类别FAS方法虽然能很好地处理未见攻击，但对活体特征中纠缠的域信息鲁棒性较差。为了解决这些问题，本文提出UFDANet。

**Method:** 本文提出了一种无监督特征解耦与增强网络（UFDANet），这是一种单类别FAS技术，通过解耦特征增强人脸图像来提高泛化能力。UFDANet采用新颖的无监督特征解耦方法来分离活体和域特征，促进判别性特征学习。它集成了一种越分布活体特征增强方案，以合成未见欺骗类别的新活体特征，使其偏离活体类别，从而增强活体特征的代表性和判别性。此外，UFDANet还结合了域特征增强例程来合成未见域特征，从而实现更好的泛化能力。

**Result:** 大量实验表明，所提出的UFDANet优于以前的单类别FAS方法，并取得了与最先进的双类别FAS方法相当的性能。

**Conclusion:** UFDANet通过无监督特征解耦和特征增强，有效解决了单类别人脸防伪中活体特征与域信息纠缠的问题，显著提高了泛化能力，并达到了与最先进的双类别方法相当的性能。

> **ai_Abstract:** 本文提出了一种名为UFDANet的单类别人脸防伪（FAS）方法，旨在解决现有单类别FAS对活体特征中纠缠域信息鲁棒性差的问题。UFDANet通过无监督特征解耦来分离活体和域特征，并利用两种增强方案：越分布活体特征增强和域特征增强，以合成新的、未见的欺骗和域特征，从而提高活体特征的代表性、判别性以及模型的泛化能力。实验结果显示，UFDANet超越了以往的单类别FAS方法，并达到了与先进双类别FAS方法相当的性能。

> **摘要翻译:** 人脸防伪（FAS）技术旨在通过区分真实活体人脸和欺骗尝试来增强人脸身份验证的安全性。虽然双类别FAS方法存在对训练攻击过拟合的风险以实现更好的性能，但单类别FAS方法能很好地处理未见攻击，但对活体特征中纠缠的域信息鲁棒性较差。为了解决这个问题，我们提出了一种无监督特征解耦与增强网络（UFDANet），这是一种单类别FAS技术，通过解耦特征增强人脸图像来提高泛化能力。UFDANet采用新颖的无监督特征解耦方法来分离活体和域特征，促进判别性特征学习。它集成了一种越分布活体特征增强方案，以合成未见欺骗类别的新活体特征，使其偏离活体类别，从而增强活体特征的代表性和判别性。此外，UFDANet还结合了域特征增强例程来合成未见域特征，从而实现更好的泛化能力。大量实验表明，所提出的UFDANet优于以前的单类别FAS方法，并取得了与最先进的双类别FAS方法相当的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [632] [SynC: Synthetic Image Caption Dataset Refinement with One-to-many Mapping for Zero-shot Image Captioning](https://arxiv.org/abs/2507.18616)
> *SynC：用于零样本图像字幕的合成图像字幕数据集通过一对多映射进行细化*

*Si-Woo Kim, MinJu Jeon, Ye-Chan Kim, Soeun Lee, Taewhan Kim, Dong-Jin Kim* | **Category: cs.CV, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 合成数据集细化, 零样本图像字幕, 一对多映射, 语义对齐, 循环一致性

**Comment:** Accepted to ACM Multimedia 2025

> **TL;DR:** SynC通过将字幕重新分配给合成图像池中最匹配的图像来改进零样本图像字幕的合成数据集，从而显著提高性能。

**AI_Comments:** SynC的创新之处在于它不依赖于传统的过滤或重新生成，而是通过智能的“一对多”映射和循环一致性启发评分器，在现有合成图像池中重新匹配图像和字幕，有效解决了合成数据中图像不准确的问题。这对于减少手动标注成本和提升零样本图像字幕模型的训练质量具有重要意义。该方法通过充分利用已有的合成图像池，提供了一种高效且有效的数据精炼策略。

<details>
  <summary>Details</summary>

**Motivation:** 零样本图像字幕（ZIC）越来越多地利用文本到图像（T2I）模型生成的合成数据集，以减少对昂贵手动标注的需求。然而，这些T2I模型产生的图像常与对应输入字幕存在语义错位（例如，缺少对象、属性不正确），导致合成图像-字幕对噪声大，从而阻碍模型训练。现有数据集剪枝技术主要用于去除网络爬取数据中的噪声文本，但它们不适用于合成数据中字幕格式良好但图像可能不准确的独特挑战。

**Method:** 为解决现有方法的不足，本文引入了SynC，一个专门设计用于细化ZIC合成图像-字幕数据集的新颖框架。SynC不采用传统的过滤或重新生成方法，而是专注于将字幕重新分配给合成图像池中已有的、语义最对齐的图像。该方法采用一对多映射策略，首先为每个字幕检索多个相关的候选图像。然后，应用一种受循环一致性启发的对齐评分器，通过验证图像检索原始字幕的能力（通过图像到文本检索）来选择最佳图像。

**Result:** 广泛的评估表明，SynC在标准基准（MS-COCO、Flickr30k、NoCaps）上，持续显著地提高了各种ZIC模型的性能，并在多种场景中取得了最先进的结果。

**Conclusion:** SynC为整理精炼的合成数据以增强零样本图像字幕（ZIC）提供了一种有效的策略。

> **ai_Abstract:** SynC是一个新颖的框架，旨在通过解决文本到图像模型生成的合成数据中图像与字幕之间的语义不一致问题来改进零样本图像字幕。它采用独特的一对多映射策略，通过将字幕重新分配给合成图像池中最匹配的图像来细化数据集。该方法利用循环一致性启发的对齐评分器确保最佳图像选择，并在多个基准测试中显著提高了零样本图像字幕模型的性能，达到了最先进水平。

> **摘要翻译:** 零样本图像字幕（ZIC）越来越多地利用文本到图像（T2I）模型生成的合成数据集，以减少对昂贵手动标注的需求。然而，这些T2I模型产生的图像常与对应输入字幕存在语义错位（例如，缺少对象、属性不正确），导致合成图像-字幕对噪声大，从而阻碍模型训练。现有数据集剪枝技术主要用于去除网络爬取数据中的噪声文本。然而，这些方法不适用于合成数据中字幕格式良好但图像可能不准确的独特挑战。为解决这一空白，我们引入了SynC，一个专门设计用于细化ZIC合成图像-字幕数据集的新颖框架。SynC不采用传统的过滤或重新生成方法，而是专注于将字幕重新分配给合成图像池中已有的、语义最对齐的图像。我们的方法采用一对多映射策略，首先为每个字幕检索多个相关的候选图像。然后，我们应用一种受循环一致性启发的对齐评分器，通过验证图像检索原始字幕的能力（通过图像到文本检索）来选择最佳图像。广泛的评估表明，SynC在标准基准（MS-COCO、Flickr30k、NoCaps）上，持续显著地提高了各种ZIC模型的性能，并在多种场景中取得了最先进的结果。SynC为整理精炼的合成数据以增强零样本图像字幕提供了有效的策略。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [637] [Improving Bird Classification with Primary Color Additives](https://arxiv.org/abs/2507.18334)
> *使用原色添加剂改进鸟类分类*

*Ezhini Rasendiran R, Chandresh Kumar Maurya* | **Category: cs.CV, cs.AI, cs.SD, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 鸟类分类, 声谱图, 深度学习, 频率信息, 色彩化

**Comment:** 5 pages (Accepted to Interspeech 2025)

> **TL;DR:** 通过将频率信息编码为原色添加到声谱图中，显著提高了鸟类叫声分类的准确性，超越了现有模型。

**AI_Comments:** 该论文的创新点在于提出了一种新颖的特征工程方法，即利用原色添加剂将频率信息嵌入到声谱图中，从而在视觉上增强了不同鸟类叫声模式的区分度。这种将听觉信息转换为视觉编码的策略，为深度学习模型提供了更丰富的输入，有效解决了传统声谱图在处理相似叫声时遇到的混淆问题。其在BirdCLEF 2024数据集上的优异表现，证明了该方法的实用性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 鸟类物种分类是一项挑战性任务，因为存在环境噪音、重叠叫声和标签缺失。现有模型在低信噪比或多物种录音方面表现不佳，且不同物种间相似的叫声模式（motifs）会导致混淆。

**Method:** 本研究假设可以通过可视化鸟类的音高模式、速度和重复性（统称为motif）来对鸟类进行分类。将深度学习模型应用于声谱图图像，并通过使用原色添加剂将频率信息嵌入到声谱图中，以增强物种区分度。

**Result:** 所提出的方法在统计学上显著优于未进行色彩化的模型，并超越了BirdCLEF 2024的冠军，F1分数提高了7.3%，ROC-AUC提高了6.2%，CMAP提高了6.6%。

**Conclusion:** 这些结果表明，通过色彩化整合频率信息是有效的。

> **ai_Abstract:** 本研究旨在解决鸟类叫声分类中的挑战，特别是针对环境噪音和相似叫声模式导致的混淆。研究提出了一种创新方法，通过将频率信息编码为原色添加到声谱图中，以增强不同鸟类物种之间的区分度。实验结果表明，该方法在分类准确性上取得了显著提升，并在多项指标上超越了BirdCLEF 2024的冠军模型，证明了色彩化整合频率信息的有效性。

> **摘要翻译:** 我们解决了使用鸟类叫声录音对鸟类物种进行分类的问题，这是一项具有挑战性的任务，因为存在环境噪音、重叠叫声和标签缺失。现有模型在低信噪比或多物种录音方面表现不佳。我们假设可以通过可视化鸟类的音高模式、速度和重复性（统称为motif）来对鸟类进行分类。将深度学习模型应用于声谱图图像有所帮助，但不同物种间相似的motif会导致混淆。为了缓解这个问题，我们使用原色添加剂将频率信息嵌入到声谱图中。这增强了物种区分度并提高了分类准确性。我们的实验表明，所提出的方法在统计学上显著优于未进行色彩化的模型，并超越了BirdCLEF 2024的冠军，F1分数提高了7.3%，ROC-AUC提高了6.2%，CMAP提高了6.6%。这些结果表明，通过色彩化整合频率信息是有效的。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [644] [Human Scanpath Prediction in Target-Present Visual Search with Semantic-Foveal Bayesian Attention](https://arxiv.org/abs/2507.18503)
> *人类在目标存在视觉搜索中的眼动路径预测：基于语义-中央凹贝叶斯注意力*

*João Luzio, Alexandre Bernardino, Plinio Moreno* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 视觉搜索, 眼动路径预测, 贝叶斯注意力, 深度学习, 语义-中央凹

**Comment:** To be published in the 2025 IEEE International Conference on
  Development and Learning (ICDL)

> **TL;DR:** 提出SemBA-FAST模型，结合深度学习和贝叶斯注意力，在目标存在视觉搜索中准确预测人类眼动路径，超越现有方法。

**AI_Comments:** SemBA-FAST的创新之处在于其将深度目标检测与概率语义融合机制以及人工中央凹注视相结合，形成了一个动态且能顺序改进注视点预测的自上而下框架。这对于理解和模拟人类视觉注意力机制具有重要意义，尤其是在实时认知计算和机器人领域的潜在应用前景广阔。

<details>
  <summary>Details</summary>

**Motivation:** 现有生物启发计算注意力模型在眼动路径预测上取得进展，但仍有提升空间。本研究旨在评估一种新的自上而下框架SemBA-FAST在目标存在视觉搜索中预测人类视觉注意力的性能。

**Method:** 本文提出SemBA-FAST，一个自上而下的框架，用于预测目标存在视觉搜索中的人类视觉注意力。该模型将深度目标检测与概率语义融合机制相结合，动态生成注意力图，并利用预训练检测器和人工中央凹注视来更新自上而下知识并顺序改进注视点预测。

**Result:** SemBA-FAST在COCO-Search18数据集上进行了评估，其方法实现的注视序列与人类真实眼动路径高度匹配。它超越了基线和其他自上而下方法，并且在某些情况下可以与基于眼动路径的模型竞争。

**Conclusion:** 这些发现为语义-中央凹概率框架在类人注意力建模方面的能力提供了宝贵的见解，对实时认知计算和机器人技术具有重要意义。

> **ai_Abstract:** 本文提出SemBA-FAST模型，一个用于目标存在视觉搜索中预测人类眼动路径的自上而下框架。该模型结合了深度目标检测与概率语义融合机制，并利用预训练检测器和人工中央凹注视来动态生成注意力图并改进注视点预测。在COCO-Search18数据集上的评估表明，SemBA-FAST生成的注视序列与人类真实眼动路径高度匹配，且性能优于基线和其他自上而下方法，甚至能与部分基于眼动路径的模型媲美，为类人注意力建模提供了新的见解。

> **摘要翻译:** 在目标导向的视觉任务中，人类感知受自上而下和自下而上线索的引导。同时，中央凹视觉在有效引导注意力方面发挥着关键作用。现代生物启发计算注意力模型研究利用深度学习的进步，通过使用人类眼动路径数据实现了新的最先进性能。在这项工作中，我们评估了SemBA-FAST（即用于中央凹主动视觉搜索任务的基于语义的贝叶斯注意力）的性能，这是一个旨在预测目标存在视觉搜索中人类视觉注意力的自上而下框架。SemBA-FAST 将深度目标检测与概率语义融合机制相结合，动态生成注意力图，利用预训练检测器和人工中央凹注视来更新自上而下知识并顺序改进注视点预测。我们在COCO-Search18基准数据集上评估了SemBA-FAST，并将其性能与其他眼动路径预测模型进行比较。我们的方法实现的注视序列与人类真实眼动路径高度匹配。值得注意的是，它超越了基线和其他自上而下方法，并且在某些情况下可以与基于眼动路径的模型竞争。这些发现为语义-中央凹概率框架在类人注意力建模方面的能力提供了宝贵的见解，对实时认知计算和机器人技术具有重要意义。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [646] [MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection](https://arxiv.org/abs/2506.03654)
> *MambaNeXt-YOLO：一种用于实时目标检测的混合状态空间模型*

*Xiaochun Lei, Siqi Wu, Weilin Wu, Zetao Jiang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 实时目标检测, 混合状态空间模型, Mamba, YOLO, 边缘计算

**Comment:** This paper is under consideration at Image and Vision Computing

> **TL;DR:** MambaNeXt-YOLO是一种新的实时目标检测框架，结合了CNN和Mamba，以在边缘设备上实现高效的全局上下文建模和高精度。

**AI_Comments:** 该论文创新性地将线性状态空间模型Mamba引入到YOLO系列目标检测框架中，有效解决了Transformer模型在实时和边缘部署中的计算复杂性问题。通过混合CNN和Mamba的设计，MambaNeXt-YOLO在保持高精度的同时，显著提升了效率，特别是在资源受限的边缘设备上展现出强大的实用性。这为未来的高效视觉模型设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 实时目标检测在计算资源有限时面临挑战。虽然YOLO模型在速度和精度上表现良好，但Transformer模型因自注意力机制计算复杂度高，限制了其在实时和边缘部署中的实用性。因此，需要一种能够有效捕获全局上下文且计算效率高的模型。

**Method:** 本文提出MambaNeXt-YOLO，一个新颖的目标检测框架，通过三个关键贡献平衡精度和效率：1) MambaNeXt Block：一种混合设计，将CNN与Mamba集成，有效捕获局部特征和长程依赖。2) 多分支非对称融合金字塔网络（MAFPN）：一种增强的特征金字塔架构，用于改进多尺度目标检测。3) 边缘聚焦效率：优化模型以支持边缘设备部署。

**Result:** MambaNeXt-YOLO在PASCAL VOC数据集上未经任何预训练即实现了66.6%的mAP和31.9 FPS。该方法支持在NVIDIA Jetson Xavier NX和Orin NX等边缘设备上部署。

**Conclusion:** MambaNeXt-YOLO通过结合CNN和线性状态空间模型Mamba，成功解决了实时目标检测中全局上下文建模的计算效率问题，实现了在资源受限的边缘设备上的高性能部署。

> **ai_Abstract:** 本文提出了MambaNeXt-YOLO，一个结合CNN和新型线性状态空间模型Mamba的实时目标检测框架。该框架通过MambaNeXt Block有效融合局部和长程依赖特征，并利用MAFPN提升多尺度检测能力。实验结果显示，MambaNeXt-YOLO在PASCAL VOC数据集上实现了高精度和实时推理速度，并支持边缘设备部署，解决了Transformer在资源受限环境中的计算效率问题。

> **摘要翻译:** 实时目标检测是计算机视觉中一项基础但具有挑战性的任务，尤其是在计算资源有限的情况下。尽管YOLO系列模型通过平衡速度和精度设定了强大的基准，但对更丰富全局上下文建模日益增长的需求导致了基于Transformer的架构的使用。然而，Transformer由于其自注意力机制具有高计算复杂度，这限制了它们在实时和边缘部署中的实用性。为了克服这些挑战，线性状态空间模型（如Mamba）的最新发展提供了一种有前途的替代方案，通过线性复杂度实现高效的序列建模。基于这一洞察，我们提出了MambaNeXt-YOLO，一个新颖的目标检测框架，通过三个关键贡献平衡了精度和效率：(1) MambaNeXt Block：一种混合设计，将CNN与Mamba集成，有效捕获局部特征和长程依赖；(2) 多分支非对称融合金字塔网络（MAFPN）：一种增强的特征金字塔架构，改进了各种对象尺寸的多尺度目标检测；以及(3) 边缘聚焦效率：我们的方法在PASCAL VOC数据集上未经任何预训练即实现了66.6%的mAP和31.9 FPS，并支持在NVIDIA Jetson Xavier NX和Orin NX等边缘设备上部署。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [647] [Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis](https://arxiv.org/abs/2507.17860)
> *通过生成式AI图像合成促进AI皮肤病变分类器公平性评估*

*Ko Watanabe. Stanislav Frolov. Adriano Lucieri. Andreas Dengel* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 公平性评估, 生成式AI, 皮肤病变分类器, 图像合成, 偏见

**Comment:** 

> **TL;DR:** 本研究利用生成式AI合成图像来评估和改进AI皮肤病变分类器的公平性，发现该方法有前景但存在数据差异的挑战。

**AI_Comments:** 这项研究的创新之处在于利用生成式AI来解决AI公平性评估中数据代表性不足的关键挑战。通过合成数据进行公平性评估，为在难以获取真实多样化数据集的情况下提供了一种有价值的解决方案。其局限性在于指出，当评估模型的训练数据与合成图像的基础数据不一致时，公平性验证的有效性会降低，这提示了未来研究需要关注数据一致性问题。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在皮肤癌筛查中潜力巨大，但其固有的偏见可能带来风险。因此，评估和提高这些系统的公平性至关重要。公平性评估的一个关键挑战是确保评估数据集充分代表不同的个人身份信息（PII）和少数群体。

**Method:** 本研究利用最先进的生成式AI（GenAI）LightningDiT模型，通过合成图像来评估公开可用的黑色素瘤分类器的公平性。

**Result:** 结果表明，使用高度逼真的合成数据进行公平性评估是一个有前景的方向。然而，研究发现，当用于评估的黑色素瘤检测模型所训练的数据与合成图像所依据的数据不同时，验证公平性变得困难。

**Conclusion:** 尽管存在挑战，本研究提出的方法为利用合成数据衡量和增强医学影像GenAI系统中的公平性提供了一条有价值的新途径。

> **ai_Abstract:** 本研究旨在通过生成式AI（GenAI）合成图像来促进AI皮肤病变分类器的公平性评估。鉴于AI在皮肤癌筛查中的潜在偏见，研究利用LightningDiT模型生成逼真的合成数据，以评估现有黑色素瘤分类器的公平性。结果显示，合成数据在公平性评估中具有前景，但当评估模型的训练数据与合成数据的基础数据不一致时，公平性验证会面临挑战。尽管如此，该方法为医疗影像GenAI系统中的公平性衡量与提升提供了一条新途径。

> **摘要翻译:** 深度学习及其在边缘计算上的最新进展，在彻底改变黑色素瘤等皮肤癌的常规筛查方面具有巨大潜力。伴随这项技术预期效益的同时，不可预见的固有偏见也带来了潜在危险。因此，评估和提高此类系统的公平性至关重要。公平性评估的一个关键挑战是确保评估数据集充分代表不同的个人身份信息（PII）（性别、年龄和种族）和其他少数群体。在此挑战背景下，本研究利用最先进的生成式AI（GenAI）LightningDiT模型来评估公开可用的黑色素瘤分类器的公平性。结果表明，使用高度逼真的合成数据进行公平性评估是一个有前景的方向。然而，我们的发现表明，当用于评估的黑色素瘤检测模型所训练的数据与合成图像所依据的数据不同时，验证公平性变得困难。尽管如此，我们提出我们的方法为利用合成数据衡量和增强医学影像GenAI系统中的公平性提供了一条有价值的新途径。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [649] [GVCCS: A Dataset for Contrail Identification and Tracking on Visible Whole Sky Camera Sequences](https://arxiv.org/abs/2507.18330)
> *GVCCS：一个用于可见光全天空相机序列中凝结尾迹识别和跟踪的数据集*

*Gabriel Jarry, Ramon Dalmau, Philippe Very, Franck Ballerini, Stefania-Denisa Bocu* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 凝结尾迹, 数据集, 深度学习, 气候影响, 计算机视觉

**Comment:** 

> **TL;DR:** GVCCS是一个新的数据集，用于从地面可见光全天空相机序列中识别和跟踪凝结尾迹，并提供了一个统一的深度学习框架作为参考，以改进凝结尾迹监测和物理模型校准。

**AI_Comments:** GVCCS数据集的创新之处在于其提供了时间跟踪和飞行标识符，填补了现有凝结尾迹数据集的空白。这对于深入分析凝结尾迹的生命周期及其与特定航班的关联至关重要。同时，提出的统一深度学习框架为未来的凝结尾迹分析提供了强大的基准和工具，有望显著提升凝结尾迹监测和气候模型校准的准确性。

<details>
  <summary>Details</summary>

**Motivation:** 航空飞行的非二氧化碳效应（特别是凝结尾迹）对气候影响显著，可能与航空碳排放的升温效应相当。现有的物理模型在凝结尾迹形成和气候影响估计方面依赖于大气输入数据的质量和假设，且现有观测数据集缺乏时间跟踪和凝结尾迹来源归属。

**Method:** 提出了GVCCS数据集，这是一个新的开放数据集，包含使用地面可见光全天空相机记录的凝结尾迹序列。数据集中每个凝结尾迹都被单独标注并随时间跟踪，包含122个视频序列（24,228帧）和形成在相机上方的凝结尾迹的飞行标识符。作为参考，还提出了一个统一的深度学习框架，使用全景分割模型进行凝结尾迹分析，该模型在一个架构中执行语义分割、实例分割和时间跟踪。

**Result:** 提供了GVCCS数据集，其中包含高质量、时间分辨的凝结尾迹标注，以及一个用于模型评估的基准。该数据集包含122个视频序列和24,228帧，并包含飞行标识符。此外，提出了一个统一的深度学习框架作为参考。

**Conclusion:** GVCCS数据集和提出的深度学习框架支持改进凝结尾迹监测，并有助于更好地校准物理模型，从而为更准确的气候影响理解和评估奠定基础。

> **ai_Abstract:** 本文介绍了GVCCS数据集，一个用于从地面可见光全天空相机序列中识别和跟踪凝结尾迹的新型开放数据集。为解决现有凝结尾迹观测数据缺乏时间跟踪和来源归属的局限性，GVCCS提供了高质量、时间分辨的凝结尾迹标注，并包含飞行标识符。此外，论文还提出了一个统一的深度学习框架作为参考，该框架利用全景分割模型实现凝结尾迹的语义分割、实例分割和时间跟踪。该工作旨在支持改进凝结尾迹监测，促进物理模型的校准，从而更准确地理解和评估航空对气候的影响。

> **摘要翻译:** 航空对气候的影响不仅包括二氧化碳排放，还包括显著的非二氧化碳效应，尤其是凝结尾迹。这些冰云可以改变地球的辐射平衡，其升温效应可能与航空二氧化碳相当。基于物理的模型提供了凝结尾迹形成和气候影响的有用估计，但其准确性严重依赖于大气输入数据的质量以及用于表示冰粒子形成和湿度驱动持久性等复杂过程的假设。来自遥感器（如卫星和地面相机）的观测数据可用于验证和校准这些模型。然而，现有数据集未能探索凝结尾迹动力学和形成的所有方面：它们通常缺乏时间跟踪，并且不将凝结尾迹归因于其来源航班。为了解决这些限制，我们提出了地面可见光相机凝结尾迹序列（GVCCS），这是一个新的开放数据集，包含使用地面全天空相机在可见光范围内记录的凝结尾迹。每个凝结尾迹都经过单独标记和随时间跟踪，从而可以对其生命周期进行详细分析。该数据集包含122个视频序列（24,228帧），并包括在相机上方形成的凝结尾迹的航班标识符。作为参考，我们还提出了一个统一的深度学习框架，用于使用全景分割模型进行凝结尾迹分析，该模型在一个架构中执行语义分割（凝结尾迹像素识别）、实例分割（单个凝结尾迹分离）和时间跟踪。通过提供高质量、时间分辨的标注和模型评估基准，我们的工作支持改进凝结尾迹监测，并将促进物理模型的更好校准。这为更准确的气候影响理解和评估奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [657] [A New One-Shot Federated Learning Framework for Medical Imaging Classification with Feature-Guided Rectified Flow and Knowledge Distillation](https://arxiv.org/abs/2507.19045)
> *一种用于医学图像分类的单次联邦学习新框架，结合特征引导整流流和知识蒸馏*

*Yufei Ma, Hanwen Zhang, Qiya Yang, Guibo Luo, Yuesheng Zhu* | **Category: cs.CV, cs.DC** | **Updated: 2025-07-25**

**Keywords:** 单次联邦学习, 医学图像分类, 特征引导整流流, 知识蒸馏, 非独立同分布

**Comment:** Accepted at ECAI 2025

> **TL;DR:** 本文提出一种新的单次联邦学习框架，通过特征引导整流流模型加速生成并保护隐私，同时利用双层知识蒸馏处理非IID数据，在医学图像分类中表现出优越性能。

**AI_Comments:** 该论文的创新之处在于其将特征引导整流流模型与双层知识蒸馏相结合，构建了一个高效且隐私保护的单次联邦学习框架，尤其适用于对数据隐私要求极高的医疗影像领域。通过合成特征级图像而非像素级图像，显著提升了隐私安全性，同时DLKD有效解决了非IID数据下的收敛难题。该框架在仅需单轮通信的条件下取得了优于多轮联邦学习的性能，这对于资源受限或通信开销敏感的应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于生成模型的单次联邦学习方法在医疗领域面临训练效率低、潜在隐私泄露以及非独立同分布（non-IID）数据下难以收敛的挑战。

**Method:** 提出了一种改进的单次联邦学习框架。该框架包含两个核心组件：客户端的特征引导整流流模型（FG-RF），用于合成特征级图像以加速生成建模并保护隐私；以及双层知识蒸馏（DLKD）聚合方法，使全局学生模型能够同时模仿输出逻辑并对齐客户端教师模型的中间层特征，以处理非IID分布。

**Result:** 在新框架和新方法在三个非IID医学图像数据集上的实验结果表明，其性能优于多轮联邦学习方法（最高提升21.73%），并平均超越基线FedISCA 21.75%。此外，特征级合成图像显著降低了隐私泄露风险。

**Conclusion:** 该研究提出的新型单次联邦学习框架通过结合特征引导整流流和双层知识蒸馏，有效解决了医学图像分类中单次联邦学习在效率、隐私保护和非IID数据收敛方面的挑战，并取得了显著的性能提升和更好的隐私保护效果。

> **ai_Abstract:** 本文提出一种用于医学图像分类的新型单次联邦学习（OSFL）框架，旨在解决现有OSFL在医疗领域面临的训练效率、隐私泄露和非IID数据收敛难题。该框架引入了特征引导整流流模型（FG-RF）在客户端生成特征级图像以加速建模并保护隐私，并采用双层知识蒸馏（DLKD）聚合方法处理非IID数据。实验证明，该框架在医学图像数据集上显著优于多轮联邦学习和基线方法，并有效降低了隐私风险。

> **摘要翻译:** 在多中心场景中，单次联邦学习（OSFL）因其低通信开销（仅需一轮传输）而受到越来越多的关注。然而，现有的基于生成模型的OSFL方法在医疗保健领域存在训练效率低和潜在隐私泄露的问题。此外，在非独立同分布（non-IID）数据下，单轮模型聚合内实现收敛具有挑战性。为了应对这些挑战，本文提出了一种改进的OSFL框架，其中开发了一种新的特征引导整流流模型（FG-RF）和双层知识蒸馏（DLKD）聚合方法。客户端的FG-RF通过合成特征级图像而非像素级图像，加速医学图像场景中的生成建模，同时保护隐私。为了处理非IID分布，DLKD使全局学生模型能够在聚合过程中同时模仿输出逻辑并对齐客户端教师模型的中间层特征。在三个非IID医学图像数据集上的实验结果表明，我们的新框架和方法优于多轮联邦学习方法，性能提升高达21.73%，并平均超越基线FedISCA 21.75%。此外，我们的实验表明，与像素级合成图像相比，特征级合成图像显著降低了隐私泄露风险。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [658] [TextCrafter: Accurately Rendering Multiple Texts in Complex Visual Scenes](https://arxiv.org/abs/2503.23461)
> *TextCrafter：在复杂视觉场景中准确渲染多个文本*

*Nikai Du, Zhennan Chen, Zhizhou Chen, Shan Gao, Xi Chen, Zhengkai Jiang, Jian Yang, Ying Tai* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 复杂视觉文本生成, TextCrafter, 文本渲染, CVTG-2K, 图像生成

**Comment:** 

> **TL;DR:** TextCrafter 是一种新的方法，用于在复杂视觉场景中准确生成多个文本，解决了文本模糊、遗漏等问题，并提出了新的基准数据集。

**AI_Comments:** TextCrafter 的创新点在于其渐进式分解策略和令牌焦点增强机制，这有助于在复杂视觉场景中实现高保真度的文本渲染。同时，提出新的基准数据集CVTG-2K 对于推动CVTG领域的研究也具有重要意义，因为它提供了更严格的评估标准。这项工作对提升文本图像生成质量具有实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前图像生成模型在复杂视觉文本生成（CVTG）任务中，经常渲染出扭曲、模糊或缺失的视觉文本。

**Method:** 提出了TextCrafter，一种新颖的多视觉文本渲染方法。TextCrafter 采用渐进式策略来分解复杂的视觉文本，并确保文本内容与其视觉载体之间稳健对齐。此外，它还结合了令牌焦点增强机制，以在生成过程中放大视觉文本的突出性。同时，论文还提出了一个新的基准数据集CVTG-2K，用于评估CVTG任务的性能。

**Result:** TextCrafter 有效解决了CVTG任务中的文本混淆、遗漏和模糊等关键挑战。广泛的实验表明，该方法超越了现有最先进的方法。

**Conclusion:** TextCrafter 成功解决了复杂视觉文本生成中的关键挑战，并在性能上超越了现有技术，为CVTG任务提供了有效的解决方案和评估工具。

> **ai_Abstract:** 本文提出了TextCrafter，一个针对复杂视觉文本生成（CVTG）任务的新型多视觉文本渲染方法。该方法通过渐进式分解和令牌焦点增强机制，有效解决了现有模型在生成复杂场景文本时出现的扭曲、模糊和遗漏问题。为评估CVTG任务，作者还引入了新的基准数据集CVTG-2K。实验证明TextCrafter 性能优于当前最先进的方法。

> **摘要翻译:** 本文探讨了复杂视觉文本生成（CVTG）任务，该任务的重点是在视觉图像中不同区域生成复杂的文本内容。在CVTG中，图像生成模型经常渲染出扭曲、模糊或缺失的视觉文本。为了解决这些挑战，我们提出了TextCrafter，一种新颖的多视觉文本渲染方法。TextCrafter 采用渐进式策略来分解复杂的视觉文本，同时确保文本内容与其视觉载体之间稳健对齐。此外，它还结合了令牌焦点增强机制，以在生成过程中放大视觉文本的突出性。TextCrafter 有效地解决了CVTG任务中的关键挑战，例如文本混淆、遗漏和模糊。此外，我们提出了一个新的基准数据集CVTG-2K，旨在严格评估生成模型在CVTG任务上的性能。大量的实验表明，我们的方法超越了最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [666] [Datasets and Recipes for Video Temporal Grounding via Reinforcement Learning](https://arxiv.org/abs/2507.18100)
> *基于强化学习的视频时序定位数据集与方法*

*Ruizhe Chen, Zhiting Fan, Tianze Luo, Heqing Zou, Zhaopeng Feng, Guiyang Xie, Hansheng Zhang, Zhuochen Wang, Zuozhu Liu, Huaijian Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 视频时间定位, 强化学习, 监督微调, 时间定位, 数据集

**Comment:** 

> **TL;DR:** 本文提出一种结合监督微调和强化学习的两阶段训练框架，用于视频时间定位，在多个基准测试中表现优于现有模型，并发布了相关数据集和代码。

**AI_Comments:** 该论文的创新之处在于将强化学习（特别是难度控制机制）集成到视频时间定位中，这是一种解决时间感知和泛化问题的创新方法。强调高质量冷启动数据用于监督微调初始化也是一个实际的贡献。发布数据集和代码对社区非常有益，可以加速该领域的研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现有方法在大型视觉-语言模型和指令微调方面取得了进展，但它们通常存在时间感知能力有限和泛化能力差的问题。

**Method:** 本文提出一个两阶段训练框架，结合监督微调（SFT）和强化学习（RL），以提高视频时间定位模型的准确性和鲁棒性。该方法首先利用高质量的冷启动数据进行SFT初始化，然后通过难度控制的强化学习进一步增强时间定位和推理能力。

**Result:** 在多个视频时间定位基准测试上的综合实验表明，所提出的方法始终优于现有模型，特别是在具有挑战性和开放域的场景中。

**Conclusion:** 本文深入分析了训练策略和数据集构建，强调了高质量冷启动数据和难度控制强化学习的重要性。为促进进一步研究和工业应用，我们向社区发布了所有中间数据集、模型和代码。

> **ai_Abstract:** 本文针对视频时间定位（VTG）的局限性，提出了一种新颖的两阶段训练框架，该框架结合了监督微调（SFT）和难度控制的强化学习（RL）。该方法利用高质量的冷启动数据进行初始化，显著提高了VTG模型的准确性和鲁棒性，尤其是在挑战性场景中。在多个基准测试上的实验结果证实了其卓越的性能。作者还发布了数据集、模型和代码，以促进未来的研究。

> **摘要翻译:** 视频时间定位（VTG）旨在根据自然语言查询在视频中定位相关的时序片段。尽管大型视觉-语言模型（LVLMs）和指令微调取得了最新进展，但现有方法通常存在时间感知能力有限和泛化能力差的问题。在这项工作中，我们引入了一个两阶段训练框架，该框架集成了监督微调（SFT）和强化学习（RL），以提高VTG模型的准确性和鲁棒性。我们的方法首先利用高质量的精选冷启动数据进行SFT初始化，然后通过难度控制的RL进一步增强时间定位和推理能力。在多个VTG基准测试上的综合实验表明，我们的方法始终优于现有模型，特别是在具有挑战性和开放域的场景中。我们对训练策略和数据集构建进行了深入分析，强调了高质量冷启动数据和难度控制RL的重要性。为了促进进一步的研究和工业应用，我们向社区发布了所有中间数据集、模型和代码。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [674] [SIDA: Synthetic Image Driven Zero-shot Domain Adaptation](https://arxiv.org/abs/2507.18632)
> *SIDA：合成图像驱动的零样本域适应*

*Ye-Chan Kim, SeungJu Cha, Si-Woo Kim, Taewhan Kim, Dong-Jin Kim* | **Category: cs.CV, cs.AI, cs.LG, cs.MM** | **Updated: 2025-07-24**

**Keywords:** 零样本域适应, 合成图像, 图像翻译, 风格迁移, Domain Mix

**Comment:** Accepted to ACM MM 2025

> **TL;DR:** SIDA是一种新颖高效的零样本域适应方法，通过生成合成图像并利用其风格特征，引入Domain Mix和Patch Style Transfer模块，以解决现有文本驱动方法在捕获复杂真实世界变异性方面的不足并显著缩短适应时间。

**AI_Comments:** SIDA的创新之处在于其摆脱了传统零样本域适应中对文本描述的依赖，转而利用合成图像提供更丰富、更细粒度的风格线索。通过合成图像作为目标域的代理，并引入Domain Mix和Patch Style Transfer等模块，SIDA能够更好地捕捉和模拟真实世界的复杂变化，解决了文本驱动方法在处理复杂变异性方面的局限性。此外，该方法在提高适应效率方面也表现出色，显著减少了整体适应时间，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的零样本域适应方法依赖文本描述来模拟目标域风格特征，但这些方法难以捕捉复杂的真实世界变异性，并且由于其对齐过程会显著增加适应时间。

**Method:** 本文提出SIDA，一种利用合成图像的零样本域适应方法。首先，生成详细的源域图像，并应用图像翻译以反映目标域风格，然后将这些合成图像的风格特征作为目标域的代理。在此基础上，引入Domain Mix和Patch Style Transfer模块，其中Domain Mix混合多种风格以扩展域内表示，Patch Style Transfer为单个图像块分配不同风格，从而有效模拟真实世界变异。

**Result:** SIDA在多种零样本适应场景，特别是在具有挑战性的域中，展示了最先进的性能。此外，该方法通过显著减少整体适应时间，实现了高效率。

**Conclusion:** SIDA通过利用合成图像和引入Domain Mix与Patch Style Transfer模块，成功解决了零样本域适应中文本驱动方法面临的挑战，实现了更有效、更高效的域适应，并在复杂真实世界变异性建模方面取得了显著进展。

> **ai_Abstract:** SIDA是一种新颖高效的零样本域适应方法，旨在解决现有文本驱动方法在捕获复杂真实世界变异性和适应时间长的问题。该方法通过生成详细的源域图像并进行图像翻译以模拟目标域风格，将合成图像的风格特征作为目标域的代理。在此基础上，SIDA引入了Domain Mix和Patch Style Transfer模块，分别用于扩展域内表示和为图像块分配不同风格，从而有效建模真实世界变异。实验证明，SIDA在多种零样本适应场景中实现了最先进的性能，尤其是在复杂域中，并且显著缩短了适应时间，展现了其高效率。

> **摘要翻译:** 零样本域适应是一种无需利用目标域图像数据即可将模型适应目标域的方法。为了在没有目标图像的情况下实现适应，现有研究利用CLIP的嵌入空间和文本描述来模拟类似目标的风格特征。尽管零样本域适应在以往取得了进展，但我们观察到这些文本驱动的方法难以捕捉复杂的真实世界变异，并且由于其对齐过程会显著增加适应时间。我们不再依赖文本描述，而是探索利用图像数据的解决方案，这提供了多样化和更细粒度的风格线索。在这项工作中，我们提出了SIDA，一种新颖高效的利用合成图像的零样本域适应方法。为了生成合成图像，我们首先创建详细的源域图像，并应用图像翻译以反映目标域的风格。然后，我们利用这些合成图像的风格特征作为目标域的代理。基于这些特征，我们引入了Domain Mix和Patch Style Transfer模块，这些模块能够有效建模真实世界的变异。特别是，Domain Mix混合多种风格以扩展域内表示，而Patch Style Transfer将不同的风格分配给单个图像块。我们通过在各种零样本适应场景，特别是在具有挑战性的域中展示最先进的性能，证明了我们方法的有效性。此外，我们的方法通过显著减少整体适应时间，实现了高效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [676] [Diffuse and Disperse: Image Generation with Representation Regularization](https://arxiv.org/abs/2506.09027)
> *扩散与分散：表征正则化图像生成*

*Runqian Wang, Kaiming He* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 表征正则化, 分散损失, 图像生成, ImageNet

**Comment:** 

> **TL;DR:** 提出一种名为“分散损失”的即插即用正则化器，有效提升扩散生成模型性能，无需额外数据或预训练，并弥合生成建模与表征学习之间的鸿沟。

**AI_Comments:** 本文的创新点在于提出了“分散损失”（Dispersive Loss），这是一个简单而有效的即插即用正则化器，专门用于改进扩散生成模型。其重要性体现在它成功地将表征学习中的“分散”思想引入到扩散模型中，且无需复杂的正样本配对或额外的预训练/数据，大大简化了实现。这种自包含且极简的设计使其具有很高的实用价值和普适性，有助于推动生成建模和表征学习的融合。

<details>
  <summary>Details</summary>

**Motivation:** 过去十年，基于扩散的生成模型与表征学习进展相对独立，扩散模型通常依赖于基于回归的目标，且普遍缺乏显式正则化。本文旨在弥合生成建模与表征学习之间的差距，并为扩散模型提供有效正则化。

**Method:** 本文提出了一种名为“分散损失”（Dispersive Loss）的简单即插即用正则化器，用于改进基于扩散的生成模型。该损失函数鼓励内部表征在隐藏空间中分散，类似于对比自监督学习，但无需正样本对，因此不干扰回归采样过程。与表征对齐（REPA）等现有方法相比，该方法是自包含且极简的，无需预训练、额外参数或外部数据。

**Result:** 在ImageNet数据集上，对一系列模型进行了分散损失评估，结果显示其相对于广泛使用且强大的基线模型，取得了持续的性能提升。

**Conclusion:** 本文工作有望弥合生成建模与表征学习之间的差距，为扩散模型提供一种有效的正则化方法。

> **ai_Abstract:** 本文提出了一种名为“分散损失”的即插即用正则化器，旨在解决扩散生成模型缺乏显式正则化的问题，并弥合其与表征学习之间的差距。该损失函数鼓励内部表征在隐藏空间中分散，且无需正样本对，不干扰采样过程。与现有方法相比，它具有极简性，无需预训练、额外参数或外部数据。在ImageNet数据集上的实验表明，该方法能持续提升扩散模型的性能，超越现有基线。

> **摘要翻译:** 在过去十年中，基于扩散的生成模型的发展与表征学习的进展在很大程度上是相互独立的。这些扩散模型通常依赖于基于回归的目标，并且普遍缺乏显式正则化。在这项工作中，我们提出了“分散损失”（Dispersive Loss），这是一种简单的即插即用正则化器，可以有效地改进基于扩散的生成模型。我们的损失函数鼓励内部表征在隐藏空间中分散，类似于对比自监督学习，其关键区别在于它不需要正样本对，因此不会干扰用于回归的采样过程。与最近的表征对齐（REPA）方法相比，我们的方法是自包含且极简的，不需要预训练、额外的参数和外部数据。我们在ImageNet数据集上对一系列模型评估了分散损失，并报告了相对于广泛使用和强大的基线模型的持续改进。我们希望我们的工作将有助于弥合生成建模和表征学习之间的差距。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [686] [Towards Large Scale Geostatistical Methane Monitoring with Part-based Object Detection](https://arxiv.org/abs/2507.18513)
> *基于部分的目标检测在大型地统计甲烷监测中的应用*

*Adhemar de Senneville, Xavier Bou, Thibaud Ehret, Rafael Grompone, Jean Louis Bonne, Nicolas Dumelie, Thomas Lauvaux, Gabriele Facciolo* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 目标检测, 甲烷监测, 生物消化池, 遥感, 地统计学

**Comment:** 

> **TL;DR:** 本文提出了一种基于部分的目标检测方法，用于在大规模遥感图像中检测稀有生物消化池，并估计其甲烷产量，以解决大规模地统计甲烷监测的挑战。

**AI_Comments:** 该论文通过引入一种新颖的基于部分的检测方法来解决大规模遥感数据中稀有对象检测的实际挑战，这对于环境监测具有重要意义。数据集的构建考虑了稀有对象的特性，具有较高的实用价值。将计算机视觉与地统计学结合，为甲烷排放监测提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 遥感数据量巨大，但在大地理区域内检测稀有对象面临挑战，这对于评估人类活动的环境影响至关重要。本文旨在解决大规模地统计甲烷监测中生物消化池的检测问题。

**Method:** 本文提出了一种新颖的基于部分的检测方法，该方法考虑了生物消化池的关键子元素以提高初始检测精度。为此，研究人员构建了一个新的生物消化池数据集，包含少量训练和验证集以及一个大量测试集（对象稀有导致高度不平衡）。该方法被应用于新的、未见的区域以建立生物消化池清单，然后计算给定区域和时间内归因于这些基础设施的甲烷产量地统计估计。

**Result:** 本文旨在建立生物消化池的清单，并计算这些设施产生的甲烷数量的地统计估计。

**Conclusion:** 本文提出了一种通过部分目标检测方法实现大规模地统计甲烷监测的途径，通过检测生物消化池并估计其甲烷产量来解决稀有对象检测的挑战。

> **ai_Abstract:** 本文提出了一种基于部分的物体检测方法，用于解决遥感图像中大规模稀有物体（如生物消化池）检测的挑战，旨在实现大规模地统计甲烷监测。研究人员构建了一个新的生物消化池数据集，并利用所提出的方法建立生物消化池清单，进而计算其甲烷产量的地统计估计，以评估环境影响。

> **摘要翻译:** 目标检测是计算机视觉在遥感图像中的主要应用之一。尽管遥感数据的可用性不断增加，但其庞大的数据量在跨大地理区域检测稀有对象时带来了挑战。矛盾的是，这种普遍的挑战对于许多应用至关重要，例如大规模评估某些人类活动的环境影响。在本文中，我们提出通过调查法国生物消化池的甲烷生产和排放来解决这个问题。我们首先引入了一个包含生物消化池的新颖数据集，该数据集包含小型训练集和验证集，以及一个大型测试集，由于此类站点稀有，因此对无对象的观测存在高度不平衡。我们开发了一种基于部分的方法，该方法考虑了生物消化池的基本子元素以促进初始检测。为此，我们将我们的方法应用于新的、未见的区域，以建立生物消化池的清单。然后，我们计算了在给定区域和给定时间内可归因于这些基础设施的甲烷产量的地统计估计。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [688] [NSegment : Label-specific Deformations for Remote Sensing Image Segmentation](https://arxiv.org/abs/2504.19634)
> *NSegment：遥感图像分割的标签特异性变形*

*Yechan Kim, DongHo Yoon, SooYeon Kim, Moongu Jeon* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 遥感图像分割, 数据增强, 标签变形, 标注错误, 弹性变换

**Comment:** The paper is being revised substantially and will be resubmitted.

> **TL;DR:** NSegment 是一种简单有效的遥感图像分割数据增强方法，通过对分割标签进行弹性变形来缓解标注错误和数据稀缺问题，并提升模型性能。

**AI_Comments:** NSegment 的创新之处在于其独特的数据增强策略，即仅对分割标签进行弹性变形。这种方法在解决遥感图像标注不一致性和数据稀缺问题时，相比于复杂的标签选择或噪声校正机制，提供了更简单且高效的替代方案。其重要性体现在能够以较低的计算成本提升模型在噪声数据环境下的鲁棒性和性能，对遥感图像处理领域具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 遥感图像分割数据集中普遍存在标注错误，原因包括模糊的类别边界、混合像素、阴影、复杂地形特征和主观标注偏差。此外，高昂的图像采集和标注成本导致标注数据稀缺，使得训练对噪声鲁棒的模型变得复杂。现有复杂的标签选择或噪声校正机制会增加训练时间和实现复杂度。

**Method:** 本文提出了 NSegment，一种简单而有效的数据增强解决方案。与传统方法不同，NSegment 仅对分割标签应用弹性变形，并在每个训练周期中根据样本变化变形强度，以解决标注不一致性问题。

**Result:** 实验结果表明，NSegment 方法提高了各种最先进模型在遥感图像分割任务上的性能。

**Conclusion:** NSegment 是一种简单有效的数据增强方法，能够通过对标签应用特异性变形来有效缓解遥感图像分割中的标注错误和数据稀缺问题，从而提升模型性能。

> **ai_Abstract:** NSegment 是一种新颖的数据增强方法，专为解决遥感图像分割中常见的标签错误和数据稀缺问题而设计。它通过仅对分割标签应用弹性变形，并动态调整变形强度，有效提升了现有先进模型在遥感图像分割任务上的性能，同时避免了传统噪声处理方法的复杂性。

> **摘要翻译:** 遥感（RS）图像分割数据集中的标注错误通常是隐性且微妙的，原因在于模糊的类别边界、混合像素、阴影、复杂地形特征以及主观标注者偏差。此外，由于高昂的图像采集和标注成本，标注的遥感数据稀缺，这使得训练对噪声鲁棒的模型变得复杂。尽管标签选择或噪声校正等复杂机制可能解决这个问题，但它们往往会增加训练时间并增加实现复杂性。在本文中，我们提出了 NSegment——一个简单而有效的数据增强解决方案来缓解这个问题。与传统方法不同，它仅对分割标签应用弹性变形，并在每个训练周期中根据样本变化变形强度，以解决标注不一致性。实验结果表明，我们的方法提高了各种最先进模型在遥感图像分割任务上的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [689] [DiNAT-IR: Exploring Dilated Neighborhood Attention for High-Quality Image Restoration](https://arxiv.org/abs/2507.17892)
> *DiNAT-IR：探索扩张邻域注意力以实现高质量图像恢复*

*Hanzhou Liu, Binghan Li, Chengkai Liu, Mi Lu* | **Category: cs.CV** | **Updated: 2025-07-23**

**Keywords:** 图像恢复, Transformer, 扩张邻域注意力, 通道感知, 低级视觉

**Comment:** 

> **TL;DR:** 本文提出了DiNAT-IR，一个基于Transformer的图像恢复模型，通过结合扩张邻域注意力和通道感知模块，有效平衡全局上下文和局部精度，在保持计算效率的同时实现了高质量图像恢复。

**AI_Comments:** 这篇论文的创新点在于将扩张邻域注意力（DiNA）引入图像恢复领域，并针对其在低级视觉任务中全局上下文理解不足的问题，提出了一个巧妙的通道感知模块来弥补。这种结合有效平衡了Transformer的全局建模能力与局部精度的需求，同时避免了传统自注意力的高计算开销，为高分辨率图像恢复提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于Transformer的图像恢复方法（如自注意力）计算成本高，难以扩展到高分辨率图像。通道维度的自注意力（如Restormer）虽然效率高，但可能忽略对高质量图像恢复至关重要的局部伪影。因此，需要一种既能处理长距离依赖又能保持局部精度，同时控制计算成本的方法。

**Method:** 论文探索了扩张邻域注意力（DiNA），它结合了滑动窗口注意力与混合扩张因子，以平衡全局上下文和局部精度。为了解决DiNA直接应用于图像恢复时全局上下文理解受限的问题，论文引入了一个通道感知模块来补充局部注意力，从而在不牺牲像素级精度的情况下有效整合全局上下文。最终提出了DiNAT-IR，一个专为图像恢复设计的Transformer架构。

**Result:** 所提出的DiNAT-IR在多个图像恢复基准测试中取得了有竞争力的结果，为各种低级计算机视觉问题提供了高质量的解决方案。

**Conclusion:** DiNAT-IR通过结合扩张邻域注意力和通道感知模块，成功解决了传统Transformer在图像恢复中面临的效率与质量权衡问题，实现了高质量的图像恢复性能。

> **ai_Abstract:** 本文针对Transformer在图像恢复中自注意力计算成本高和现有方法（如Restormer）可能忽略局部伪影的问题，提出了DiNAT-IR模型。该模型核心在于探索和改进扩张邻域注意力（DiNA），通过引入一个通道感知模块来增强DiNA的全局上下文理解能力，同时保持像素级精度。DiNAT-IR在多个图像恢复基准测试中取得了有竞争力的结果，为低级计算机视觉任务提供了一个高效高质量的解决方案。

> **摘要翻译:** Transformer及其用于建模长距离依赖的自注意力机制已成为图像恢复任务中的主导范式。然而，自注意力的高计算成本限制了其在高分辨率图像上的可扩展性，使得效率-质量权衡成为一个关键的研究焦点。为了解决这个问题，Restormer采用了通道维度自注意力，它在通道而非空间维度上计算注意力。尽管有效，但这种方法可能会忽略对高质量图像恢复至关重要的局部伪影。为了弥补这一空白，我们受扩张邻域注意力（DiNA）在高级视觉任务中成功的启发，探索其作为一种有前途的替代方案。DiNA通过将滑动窗口注意力与混合扩张因子相结合，在不过度开销的情况下有效扩展感受野，从而平衡了全局上下文和局部精度。然而，我们的初步实验表明，将这种全局-局部设计直接应用于经典的去模糊任务会阻碍准确的视觉恢复，这主要是由于局部注意力中受限的全局上下文理解。为了解决这个问题，我们引入了一个通道感知模块来补充局部注意力，从而在不牺牲像素级精度的情况下有效整合全局上下文。所提出的DiNAT-IR，一个专门为图像恢复设计的基于Transformer的架构，在多个基准测试中取得了有竞争力的结果，为各种低级计算机视觉问题提供了高质量的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [691] [Boosting Multi-View Indoor 3D Object Detection via Adaptive 3D Volume Construction](https://arxiv.org/abs/2507.18331)
> *通过自适应三维体构建提升多视图室内三维物体检测*

*Runmin Zhang, Zhu Yu, Si-Yuan Cao, Lingyu Zhu, Guangyi Zhang, Xiaokai Bai, Hui-Liang Shen* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 多视图, 3D物体检测, 自适应体构建, 稀疏体, 室内场景

**Comment:** Accepted by ICCV2025

> **TL;DR:** SGCDet是一种新颖的多视图室内三维物体检测框架，通过自适应三维体构建和稀疏体构建策略，实现了高效且高性能的3D物体检测，且仅需3D边界框监督。

**AI_Comments:** 该论文的创新点在于提出了自适应三维体构建和稀疏体构建策略，有效解决了传统多视图3D检测中特征表示不足和计算冗余的问题。其无需地面真值场景几何的特性降低了数据标注的复杂性，具有重要的实际应用价值。在多个主流数据集上达到SOTA性能，证明了其方法的有效性和优越性。

<details>
  <summary>Details</summary>

**Motivation:** 以往的多视图3D物体检测方法将体素的感受野限制在图像的固定位置，导致特征表示能力不足且存在冗余计算。本文旨在解决这些问题。

**Method:** 本工作提出了SGCDet框架，其核心包括：1. 几何和上下文感知聚合模块：在每个图像的自适应区域内整合几何和上下文信息，并动态调整不同视图的贡献，以增强体素特征的表示能力。2. 稀疏体构建策略：自适应识别并选择高占用概率的体素进行特征细化，从而最大限度地减少自由空间中的冗余计算。该网络仅使用3D边界框进行监督，无需地面真值场景几何。

**Result:** SGCDet在ScanNet、ScanNet200和ARKitScenes数据集上取得了最先进的性能。

**Conclusion:** SGCDet通过自适应和高效的三维体构建，实现了有效的多视图室内三维物体检测，且仅需3D边界框监督，展现出卓越的性能。

> **ai_Abstract:** SGCDet是一种新型的多视图室内3D物体检测框架，通过引入几何和上下文感知聚合模块以及稀疏体构建策略，解决了传统方法中体素感受野固定和冗余计算的问题。它能够自适应地聚合信息并精炼特征，从而提高体素特征的表示能力并减少计算量。该框架仅需3D边界框监督，并在ScanNet、ScanNet200和ARKitScenes数据集上达到了最先进的性能。

> **摘要翻译:** 本工作提出了SGCDet，一种基于自适应三维体构建的新型多视图室内三维物体检测框架。与以往将体素感受野限制在图像固定位置的方法不同，我们引入了几何和上下文感知聚合模块，以整合每个图像中自适应区域内的几何和上下文信息，并动态调整不同视图的贡献，从而增强体素特征的表示能力。此外，我们提出了一种稀疏体构建策略，自适应地识别并选择具有高占用概率的体素进行特征细化，从而最大限度地减少自由空间中的冗余计算。受益于上述设计，我们的框架以自适应的方式实现了有效且高效的体构建。更好的是，我们的网络仅能通过3D边界框进行监督，消除了对地面真值场景几何的依赖。实验结果表明，SGCDet在ScanNet、ScanNet200和ARKitScenes数据集上取得了最先进的性能。源代码可在https://github.com/RM-Zhang/SGCDet获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [706] [SyncMapV2: Robust and Adaptive Unsupervised Segmentation](https://arxiv.org/abs/2506.16297)
> *SyncMapV2：鲁棒自适应无监督分割*

*Heng Zhang, Zikang Wan, Danilo Vasconcellos Vargas* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 无监督分割, 鲁棒性, 自适应, SyncMapV2, 在线学习

**Comment:** 

> **TL;DR:** SyncMapV2是一种新的无监督分割算法，在各种噪声和损坏条件下表现出最先进的鲁棒性，且无需鲁棒训练或重新初始化，可在线适应输入。

**AI_Comments:** SyncMapV2的创新之处在于其无监督、无鲁棒训练、无损失函数的设计，以及其在线适应能力，这使其在处理噪声和新输入时表现出显著优于现有SOTA方法的鲁棒性和灵活性。这代表了无监督学习领域的一个重要进展，特别是在实时、动态环境下的应用潜力巨大。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI算法在噪声增加时难以保持无监督分割的准确性，而人类视觉在这方面表现出色。传统的无监督分割方法需要对每个新输入进行重新初始化，缺乏在线适应性。

**Method:** SyncMapV2基于一种学习范式，结合了自组织动力学方程和随机网络概念。它无需鲁棒训练、监督或损失函数，并能在线适应输入。

**Result:** 在数字损坏下，SyncMapV2的mIoU下降仅为0.01%，而SOTA方法下降23.8%。在噪声（7.3% vs. 37.7%）、天气（7.5% vs. 33.8%）和模糊（7.0% vs. 29.5%）等不同类型的损坏下，性能均优于SOTA方法。在适应性测试中，性能退化接近零。

**Conclusion:** SyncMapV2是第一个实现在线适应输入，同时提供准确和鲁棒的无监督分割算法，有望促进未来鲁棒自适应智能的发展。

> **ai_Abstract:** SyncMapV2是一种创新的无监督分割算法，旨在解决现有AI在噪声环境下精度下降的问题。它无需传统训练，通过自组织动力学方程和随机网络概念，实现了在各种数字损坏（噪声、天气、模糊）下卓越的鲁棒性，mIoU下降远低于SOTA方法。更重要的是，SyncMapV2具备在线适应能力，无需对每个新输入进行重新初始化，展现出类似人类视觉的持续适应性，为未来的鲁棒自适应智能奠定了基础。

> **摘要翻译:** 人类视觉在无需明确训练的情况下擅长分割视觉线索，即使噪声严重程度增加，它仍然表现出卓越的鲁棒性。相比之下，现有的人工智能算法在类似条件下难以保持准确性。本文提出了SyncMapV2，首次解决了无监督分割的最先进鲁棒性问题。在数字损坏下，SyncMapV2的mIoU下降仅为0.01%，而现有最先进方法观察到下降23.8%。这种卓越的性能延伸到各种类型的损坏：噪声（7.3% vs. 37.7%）、天气（7.5% vs. 33.8%）和模糊（7.0% vs. 29.5%）。值得注意的是，SyncMapV2在没有任何鲁棒训练、监督或损失函数的情况下完成了这一点。它基于一种学习范式，结合了自组织动力学方程和随机网络的概念。此外，与需要为每个新输入重新初始化的传统方法不同，SyncMapV2可以在线适应，模仿人类视觉的持续适应性。因此，我们超越了准确和鲁棒的结果，提出了第一个能够在线完成所有上述操作，适应输入而不是重新初始化的算法。在适应性测试中，SyncMapV2表现出接近零的性能退化，这激励并促进了未来新一代鲁棒自适应智能的发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [708] [A Multimodal Seq2Seq Transformer for Predicting Brain Responses to Naturalistic Stimuli](https://arxiv.org/abs/2507.18104)
> *用于预测大脑对自然刺激反应的多模态Seq2Seq Transformer*

*Qianyi He, Yuan Chang Leong* | **Category: cs.CV, q-bio.NC** | **Updated: 2025-07-25**

**Keywords:** 多模态, Seq2Seq Transformer, fMRI, 脑反应, 自然刺激

**Comment:** 

> **TL;DR:** 本文针对Algonauts 2025挑战赛，提出了一种多模态Seq2Seq Transformer，用于从视觉、听觉和语言输入中自回归预测大脑对自然主义多模态电影的fMRI反应。该模型通过利用多模态序列上下文来捕捉长程时间结构，并结合共享编码器和部分受试者特定解码器来处理个体差异，在分布内和分布外数据上均表现出色。

**AI_Comments:** 该论文的创新之处在于其独特地应用了多模态Seq2Seq Transformer，专门解决了大脑对自然刺激反应的时间动态性，并通过其编码器-解码器架构考虑了个体变异性。其在分布外数据上的强大性能表明了良好的泛化能力，为脑活动预测领域提供了重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在响应Algonauts 2025挑战赛，该挑战赛要求社区开发能够预测大脑对自然主义多模态电影的整体fMRI反应的编码模型。

**Method:** 本文提出了一种序列到序列的Transformer模型，用于从视觉、听觉和语言输入中自回归地预测fMRI活动。刺激特征通过VideoMAE、HuBERT、Qwen和BridgeTower等预训练模型提取。解码器通过双重交叉注意力机制整合来自先前大脑状态和当前刺激的信息，同时关注感知信息和叙事信息。核心创新包括使用多模态上下文序列来预测大脑活动序列，以捕捉刺激和神经反应中的长程时间结构；以及结合共享编码器与部分受试者特定解码器，以利用受试者间共同的表征结构并兼顾个体差异。

**Result:** 该模型在分布内和分布外数据上均取得了强大的性能。

**Conclusion:** 该研究证明了时间感知、多模态序列建模在预测大脑活动方面的有效性。

> **ai_Abstract:** 本文针对Algonauts 2025挑战赛，提出了一种多模态序列到序列Transformer模型，用于预测大脑对自然主义多模态电影的fMRI反应。该模型从视觉、听觉和语言输入中自回归预测fMRI活动，并利用预训练模型提取特征。其核心创新在于利用多模态上下文序列来捕捉刺激和神经反应中的长程时间结构，并通过共享编码器结合部分受试者特定解码器来兼顾通用性和个体差异。实验结果表明，该模型在分布内和分布外数据上均表现出色，验证了时间感知多模态序列建模在脑活动预测中的有效性。

> **摘要翻译:** Algonauts 2025挑战赛号召社区开发编码模型，以预测大脑对自然主义多模态电影的整体fMRI反应。在此提交中，我们提出了一种序列到序列的Transformer模型，该模型从视觉、听觉和语言输入中自回归地预测fMRI活动。刺激特征是使用预训练模型提取的，包括VideoMAE、HuBERT、Qwen和BridgeTower。解码器通过双重交叉注意力机制整合来自先前大脑状态和当前刺激的信息，这些机制同时关注从刺激中提取的感知信息以及由内容高级摘要提供的叙事信息。我们方法的一个核心创新是使用多模态上下文序列来预测大脑活动序列，使模型能够捕捉刺激和神经反应中的长程时间结构。另一个创新是共享编码器与部分受试者特定解码器的结合，这利用了受试者之间共同的表征结构，同时考虑了了个体差异。我们的模型在分布内和分布外数据上都取得了强大的性能，证明了时间感知、多模态序列建模在预测大脑活动方面的有效性。代码可在https://github.com/Angelneer926/Algonauts_challenge获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [709] [Part Segmentation of Human Meshes via Multi-View Human Parsing](https://arxiv.org/abs/2507.18655)
> *通过多视角人体解析进行人体网格部件分割*

*James Dickens, Kamyar Hamad* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-22**

**Keywords:** 人体网格分割, 多视角人体解析, 点云深度学习, 语义分割, 伪真值

**Comment:** 

> **TL;DR:** 该论文提出了一种通过结合点云深度学习和多视角人体解析，实现人体网格语义分割的方法，包括伪真值标注流程和高效采样策略。

**AI_Comments:** 该论文的创新之处在于成功地将点云深度学习和人体解析这两个独立领域结合起来，以解决人体网格部件分割问题。其核心贡献在于构建了一个独特的伪真值标注流程，这对于缺乏大规模标注数据集的领域至关重要。此外，提出的内存高效采样策略和仅依赖几何信息进行分割的能力，都显著提升了方法的实用性和普适性，尤其是在处理大规模和复杂的人体网格数据时。

<details>
  <summary>Details</summary>

**Motivation:** 旨在连接大规模点云深度学习和图像人体解析这两个领域，实现大规模人体网格的逐顶点语义分割。

**Method:** 开发了一个针对Thuman2.1数据集的伪真值标注流程：网格首先对齐到标准姿态，从多个视角进行分割，然后将点级标签反向投影到原始网格上以生成逐点伪真值标注。随后，引入了一种新颖的、内存高效的采样策略，即基于空间填充曲线序列化的窗口迭代最远点采样（FPS），以有效下采样点云。接着使用PointTransformer进行纯几何分割，无需依赖纹理信息。

**Result:** 实验结果证实了所提出方法的有效性和准确性。

**Conclusion:** 所提出的方法能够有效且准确地实现人体网格的语义解析，通过纯几何分割方法弥合了点云深度学习和人体解析之间的鸿沟。

> **ai_Abstract:** 本文提出了一种通过结合点云深度学习和多视角人体解析，实现大规模人体网格逐顶点语义分割的新方法。研究开发了一个针对Thuman2.1数据集的伪真值标注流程，包括网格对齐、多视角分割和标签反向投影。为提高效率，引入了一种基于窗口迭代最远点采样和空间填充曲线序列化的新型内存高效采样策略。随后，利用PointTransformer进行纯几何分割，实现了无需纹理信息的人体网格语义解析。实验结果验证了该方法的有效性和准确性。

> **摘要翻译:** 点云深度学习的最新进展使得模型能够在仅使用无序点集的原始几何形状的情况下，在大规模点云上实现高逐部件标注精度。与此同时，人体解析领域专注于从图像中预测身体部位和衣物/配饰标签。这项工作旨在通过实现大规模人体网格的逐顶点语义分割来连接这两个领域。为此，开发了一个针对Thuman2.1数据集的伪真值标注流程：网格首先对齐到标准姿态，从多个视角进行分割，然后将得到的点级标签反向投影到原始网格上，以生成逐点伪真值标注。随后，引入了一种新颖的、内存高效的采样策略，即基于空间填充曲线序列化的窗口迭代最远点采样（FPS），以有效下采样点云。接着使用PointTransformer进行纯几何分割，从而实现人体网格的语义解析，而无需依赖纹理信息。实验结果证实了所提出方法的有效性和准确性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [718] [MC3D-AD: A Unified Geometry-aware Reconstruction Model for Multi-category 3D Anomaly Detection](https://arxiv.org/abs/2505.01969)
> *MC3D-AD：一种用于多类别三维异常检测的统一几何感知重建模型*

*Jiayi Cheng, Can Gao, Jie Zhou, Jiajun Wen, Tao Dai, Jinbao Wang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 三维异常检测, 多类别, 几何感知, 重建, 统一模型

**Comment:** 7 pages of main text, 3 pages of appendix, accepted to IJCAI 2025

> **TL;DR:** MC3D-AD提出了一种统一的几何感知重建模型，用于多类别三维异常检测，通过结合局部和全局几何信息，显著优于现有的单类别方法。

**AI_Comments:** MC3D-AD的创新之处在于其统一的多类别3D异常检测方法，解决了传统单类别训练的局限性。通过结合局部和全局几何感知重建，它能够更有效地识别不同类别的异常。该模型在泛化能力和效率方面具有重要意义，对工业产品质量控制领域有潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有三维异常检测方法通常需要为每个类别独立训练特定模型，导致成本高、效率低和泛化能力弱。

**Method:** MC3D-AD提出了一种统一模型，利用局部和全局几何感知信息重建所有类别的正常表示。具体包括：1) 自适应几何感知掩蔽注意力模块，提取几何变化信息指导掩蔽注意力。2) 局部几何感知编码器，通过改进的掩蔽注意力强化以编码组级特征。3) 全局查询解码器，利用点云位置嵌入提高解码和重建能力。

**Result:** MC3D-AD在Real3D-AD和Anomaly-ShapeNet两个公开数据集上进行了评估，在对象级AUROC方面，分别比现有最先进的单类别方法提高了3.1%和9.3%。

**Conclusion:** MC3D-AD通过其统一的几何感知重建方法，有效解决了现有三维异常检测的局限性，并在多类别场景中实现了显著优越的性能。

> **ai_Abstract:** 本文提出了MC3D-AD，一个用于多类别三维异常检测的统一几何感知重建模型。它通过整合自适应几何感知掩蔽注意力模块、局部几何感知编码器和全局查询解码器，有效利用局部和全局几何信息来重建正常表示。该模型旨在解决现有方法成本高、效率低和泛化能力弱的问题。实验结果表明，MC3D-AD在Real3D-AD和Anomaly-ShapeNet数据集上，在对象级AUROC方面分别比现有最先进的单类别方法提高了3.1%和9.3%，显示出显著的优越性。

> **摘要翻译:** 三维异常检测（AD）是控制制成品质量的一种有前景的手段。然而，现有方法通常需要为每个类别独立地精心训练一个特定任务的模型，导致成本高、效率低和泛化能力弱。因此，本文提出了一种新颖的统一模型，用于多类别三维异常检测（MC3D-AD），旨在利用局部和全局几何感知信息来重建所有类别的正常表示。首先，为了学习不同类别的鲁棒和泛化特征，我们提出了一种自适应几何感知掩蔽注意力模块，提取几何变化信息以指导掩蔽注意力。然后，我们引入了一个局部几何感知编码器，通过改进的掩蔽注意力进行强化，以编码组级特征令牌。最后，我们设计了一个全局查询解码器，利用点云位置嵌入来改善解码过程和重建能力。这为AD任务带来了局部和全局几何感知的重建特征令牌。MC3D-AD在两个公开可用的Real3D-AD和Anomaly-ShapeNet数据集上进行了评估，并显示出相对于当前最先进的单类别方法的显著优越性，在Real3D-AD和Anomaly-ShapeNet上，对象级AUROC分别提高了3.1%和9.3%。代码可在https://github.com/iCAN-SZU/MC3D-AD获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [726] [AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2507.17957)
> *AFRDA：用于域适应语义分割的注意力特征细化*

*Md. Al-Masrur Khan, Durgakant Pushp, Lantao Liu* | **Category: cs.CV** | **Updated: 2025-07-23**

**Keywords:** 无监督域适应，语义分割，特征细化，注意力机制，高频分量

**Comment:** 

> **TL;DR:** AFRDA通过自适应特征细化模块，利用语义先验和高频信息，并通过不确定性驱动的注意力机制平衡局部和全局信息，显著提升了无监督域适应语义分割的性能。

**AI_Comments:** AFRDA的创新点在于提出了AFR模块，该模块通过结合语义先验、高频信息和不确定性驱动的注意力机制，有效地平衡了局部细节和全局上下文信息，解决了无监督域适应语义分割中的一个关键挑战。其轻量级设计和在现有HRDA-based方法上的显著性能提升，表明了其良好的实用性和有效性，对该领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的无监督域适应语义分割（UDA-SS）方法在平衡细粒度局部细节与全局上下文信息方面存在困难，导致在复杂区域的分割错误。

**Method:** 本文引入了自适应特征细化（AFR）模块。AFR通过利用低分辨率逻辑的语义先验来细化高分辨率特征，并整合捕获细粒度结构和提供关键边界信息的高频分量。此外，AFR通过不确定性驱动的注意力机制自适应地平衡局部和全局信息，减少误分类。其轻量级设计允许其无缝集成到基于HRDA的UDA方法中。

**Result:** 在GTA V --> Cityscapes数据集上，将现有UDA-SS方法的mIoU提高了1.05%；在Synthia --> Cityscapes数据集上，将mIoU提高了1.04%。

**Conclusion:** AFRDA通过其自适应特征细化模块，有效解决了无监督域适应语义分割中细粒度细节和全局上下文信息平衡的挑战，显著提升了语义分割性能，并达到了最先进的水平。

> **ai_Abstract:** 本文提出了一种名为AFRDA（Attentive Feature Refinement for Domain Adaptive Semantic Segmentation）的新方法，旨在解决无监督域适应语义分割（UDA-SS）中平衡局部细节与全局上下文信息的挑战。其核心是自适应特征细化（AFR）模块，该模块通过利用语义先验细化高分辨率特征，整合高频分量以改善边界，并利用不确定性驱动的注意力机制自适应地平衡局部和全局信息。AFRDA设计轻量且易于集成到现有UDA方法中，并在多个基准测试中显著提升了UDA-SS的性能，达到了最先进的水平。

> **摘要翻译:** 在无监督域适应语义分割（UDA-SS）中，模型在标记的源域数据（例如，合成图像）上进行训练，并适应未标记的目标域（例如，真实世界图像），而无需访问目标注释。现有的UDA-SS方法常常难以平衡细粒度局部细节与全局上下文信息，导致复杂区域的分割错误。为了解决这个问题，我们引入了自适应特征细化（AFR）模块，该模块通过利用低分辨率逻辑的语义先验来细化高分辨率特征，从而提高分割精度。AFR还集成了高频分量，这些分量捕获细粒度结构并提供关键边界信息，从而改善了对象描绘。此外，AFR通过不确定性驱动的注意力机制自适应地平衡局部和全局信息，减少了误分类。其轻量级设计允许其无缝集成到基于HRDA的UDA方法中，从而实现了最先进的分割性能。我们的方法在GTA V --> Cityscapes上将现有UDA-SS方法提高了1.05%的mIoU，在Synthia --> Cityscapes上提高了1.04%的mIoU。我们框架的实现可在以下网址获取：https://github.com/Masrur02/AFRDA

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [731] [Object segmentation in the wild with foundation models: application to vision assisted neuro-prostheses for upper limbs](https://arxiv.org/abs/2507.18517)
> *野外场景下的基础模型目标分割：在视觉辅助上肢神经假肢中的应用*

*Bolutife Atoki, Jenny Benois-Pineau, Renaud Péteri, Fabien Baldacci, Aymar de Rugy* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 目标分割, 基础模型, SAM, 神经假肢, 注视点

**Comment:** 

> **TL;DR:** 本文研究了在高度杂乱的“野外”视觉场景中，使用基础模型（如SAM）进行语义目标分割的方法，并将其应用于视觉辅助上肢神经假肢。通过基于注视点生成提示来引导SAM并进行微调，实验结果显示IoU分割质量显著提升。

**AI_Comments:** 该研究的创新之处在于其将基础模型应用于极具挑战性的“野外”目标分割场景，并巧妙地结合了注视点信息来生成提示，从而有效引导了SAM模型。这种方法在无需大量特定场景微调的情况下实现了性能提升，尤其是在神经假肢等实际应用中具有重要的临床和工程意义。它展示了基础模型在泛化能力和复杂环境适应性方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 解决在高度杂乱的“野外”视觉场景中，基础模型无需针对特定图像进行微调即可执行日常物体分割的问题，特别是为了支持视觉引导上肢神经假肢的应用。

**Method:** 提出一种基于注视点生成提示的方法来引导Segment Anything Model (SAM) 在分割场景中工作，并使用自我中心视觉数据对SAM进行微调。

**Result:** 在Grasing-in-the-Wild语料库的真实世界挑战数据上，IoU分割质量指标提高了0.51点。

**Conclusion:** 该研究成功展示了通过基于注视点生成提示和微调SAM模型，可以在复杂“野外”场景中有效提升目标分割性能，并为视觉辅助上肢神经假肢提供了可行的解决方案。

> **ai_Abstract:** 本文探讨了在复杂“野外”视觉场景下，利用基础模型进行语义目标分割的应用。针对视觉辅助上肢神经假肢的需求，作者提出了一种创新方法：通过注视点生成提示来引导Segment Anything Model (SAM)，并基于自我中心视觉数据对其进行微调。实验结果表明，该方法在Grasing-in-the-Wild真实世界数据集上，目标分割的IoU质量显著提升了0.51点，证明了其在挑战性环境下的有效性和实用性。

> **摘要翻译:** 在这项工作中，我们利用基础模型解决了语义目标分割问题。我们研究了在大量不同物体上训练的基础模型，是否能在无需针对包含日常物体但高度杂乱视觉场景的特定图像进行微调的情况下执行目标分割。“野外”环境是由视觉引导上肢神经假肢的目标应用所驱动的。我们提出了一种基于注视点生成提示的方法，以在我们的分割场景中引导Segment Anything Model (SAM)，并使用自我中心视觉数据对其进行微调。我们的方法评估结果显示，在Grasing-in-the-Wild语料库的真实世界挑战数据上，IoU分割质量指标提高了0.51点，该语料库已在RoboFlow平台（https://universe.roboflow.com/iwrist/grasping-in-the-wild）上提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [732] [DSFormer: A Dual-Scale Cross-Learning Transformer for Visual Place Recognition](https://arxiv.org/abs/2507.18444)
> *DSFormer：一种用于视觉地点识别的双尺度交叉学习Transformer*

*Haiyang Jiang, Songhao Piao, Chao Gao, Lei Yu, Liguo Chen* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-24**

**Keywords:** 视觉地点识别, Transformer, 双尺度学习, 块聚类, 机器人定位

**Comment:** 

> **TL;DR:** 本文提出DSFormer，一个结合双尺度交叉学习Transformer模块和创新块聚类策略的框架，用于视觉地点识别（VPR）。该方法在各种基准数据集上实现了最先进的性能，同时提高了计算效率并减少了训练数据量。

**AI_Comments:** 该论文通过结合双尺度Transformer和创新的块聚类策略，在视觉地点识别领域取得了显著进展。其创新点在于DSFormer的双向信息传输和跨尺度学习能力，以及块聚类对数据组织和鲁棒性的优化。这些结合不仅提升了识别性能，还显著降低了训练数据需求并提高了计算效率，对移动机器人定位具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 视觉地点识别（VPR）对于移动机器人鲁棒定位至关重要，但在环境条件和视角变化下保持可靠性能面临显著挑战。

**Method:** 本文提出一个新颖的框架，该框架集成了双尺度Transformer（DSFormer）模块和创新的块聚类策略。DSFormer通过在从最后两个CNN层提取的双尺度特征之间实现双向信息传输来增强特征表示，通过自注意力捕获长距离依赖，并通过共享交叉注意力实现跨尺度学习。块聚类策略从多个不同视角重新划分SF-XL训练数据集，以优化数据组织，进一步增强对视角变化的鲁棒性。

**Result:** 该方法不仅产生了适应环境变化的鲁棒全局嵌入，而且与以前的划分方法相比，所需的训练数据量减少了约30%。在大多数基准数据集上实现了最先进的性能，超越了DELG、Patch-NetVLAD、TransVPR和R2Former等先进的重排序方法，作为使用512维全局描述符的全局检索解决方案，同时显著提高了计算效率。

**Conclusion:** 本文提出的DSFormer结合块聚类策略在视觉地点识别任务上取得了最先进的性能，有效解决了环境和视角变化带来的挑战，并提高了效率。

> **ai_Abstract:** 本文提出DSFormer，一个用于视觉地点识别（VPR）的新型框架。该框架结合了双尺度交叉学习Transformer模块和创新的块聚类策略。DSFormer通过双向信息传输增强特征表示，捕获语义和空间细节，而块聚类策略优化了训练数据组织。该方法在环境变化下表现出鲁棒性，将训练数据量减少了约30%，并在多个基准数据集上实现了最先进的性能，超越了现有方法，同时提高了计算效率。

> **摘要翻译:** 视觉地点识别（VPR）对于移动机器人鲁棒定位至关重要，但在环境条件和视角变化下保持可靠性能面临显著挑战。为了解决这个问题，我们提出了一种新颖的框架，该框架集成了双尺度Transformer（DSFormer），一个基于Transformer的交叉学习模块，以及一种创新的块聚类策略。DSFormer通过在从最后两个CNN层提取的双尺度特征之间实现双向信息传输来增强特征表示，通过自注意力捕获每个尺度内的长距离依赖关系，并通过共享交叉注意力实现跨尺度学习，从而捕获语义丰富性和空间细节。作为补充，我们的块聚类策略从多个不同视角重新划分了广泛使用的旧金山特大（SF-XL）训练数据集，优化了数据组织，以进一步增强对视角变化的鲁棒性。总而言之，这些创新不仅产生了适应环境变化的鲁棒全局嵌入，而且与以前的划分方法相比，所需的训练数据量减少了约30%。全面的实验表明，我们的方法在大多数基准数据集上实现了最先进的性能，作为使用512维全局描述符的全局检索解决方案，超越了DELG、Patch-NetVLAD、TransVPR和R2Former等先进的重排序方法，同时显著提高了计算效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [733] [ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation](https://arxiv.org/abs/2312.05407)
> *ODES：在线医学图像分割的专家指导域适应*

*Md Shazid Islam, Sayak Nag, Arindam Dutta, Miraj Ahmed, Fahim Faisal Niloy, Amit K. Roy-Chowdhury* | **Category: cs.CV** | **Updated: 2025-07-23**

**Keywords:** 域适应, 在线学习, 医学图像分割, 专家指导, 主动学习

**Comment:** 

> **TL;DR:** ODES提出了一种结合专家指导和主动学习的在线域适应方法，用于医学图像分割，以解决伪标签噪声问题，并通过图像裁剪策略提高效率。

**AI_Comments:** 该论文的创新点在于将专家指导与主动学习相结合，应用于在线医学图像分割的域适应，有效解决了伪标签噪声和在线适应效率问题。特别是提出的图像裁剪策略，为在线学习场景下的标注效率提供了新的思路，提升了方法的实用性。其重要性在于为高精度要求的医学图像分析提供了更可靠的在线域适应解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 在无监督域适应分割中，预训练网络在未标记目标数据集上预测的伪标签通常存在噪声，这在网络在线处理传入数据流时会加剧，导致分割质量低下，尤其是在对精度要求极高的医学图像分析中。

**Method:** 本文提出了ODES方法，通过主动学习从专家那里获取少量像素级标注，以增强在线流数据的域适应性能。为减少标注获取时间和提高在线适应效率，进一步提出了一种新颖的图像裁剪策略，从当前批次中选择最有用图像子集进行主动学习。

**Result:** 所提出的方法优于现有的在线适应方法，并且与离线域适应主动学习方法相比，产生了具有竞争力的结果。

**Conclusion:** 通过专家指导和主动学习，即使在没有专用训练数据的情况下，也能有效解决在线医学图像分割中域适应的伪标签噪声问题，并提高分割性能。

> **ai_Abstract:** 本文提出了一种名为ODES的在线医学图像分割域适应方法。针对无监督域适应中伪标签噪声导致在线数据流分割质量低下的问题，ODES通过主动学习引入专家少量像素级标注。为提高效率，该方法还设计了一种图像裁剪策略，以选择最有用的图像子集进行标注。实验结果表明，ODES优于现有在线适应方法，并能与离线方法媲美。

> **摘要翻译:** 无监督域适应分割通常依赖于使用预训练网络在未标记目标数据集上预测的伪标签进行自训练。然而，此类伪标签的噪声特性是网络适应源域和目标域之间分布偏移的主要瓶颈。当网络以在线方式遇到传入数据流时，这种挑战会进一步加剧，因为网络必须仅通过一轮前向和后向传播来适应传入的目标域数据流。在这种情况下，仅仅依赖不准确的伪标签会导致低质量的分割，这对于精度和准确性至关重要的医学图像分析来说是极其有害的。我们假设从专家那里获得少量像素级标注可以解决这个问题，从而即使在没有专用训练数据的情况下，也能提高在线流数据的域适应性能。我们将我们的方法命名为 ODES：在线医学图像分割的专家指导域适应，它以在线设置适应每个传入的数据批次，通过主动学习整合来自专家的反馈。通过主动学习，可以为专家标注选择每张图像中最具信息量的像素。然而，获取批次中所有图像的像素级标注通常会导致信息冗余，同时增加在线学习中的时间开销。为了减少标注获取时间并使适应过程更适合在线，我们进一步提出了一种新颖的图像裁剪策略，从当前批次中选择最有用图像子集进行主动学习。我们提出的方法优于现有的在线适应方法，并且与离线域适应主动学习方法相比，产生了具有竞争力的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [734] [Scaling RL to Long Videos](https://arxiv.org/abs/2507.07966)
> *将强化学习扩展到长视频*

*Yukang Chen, Wei Huang, Baifeng Shi, Qinghao Hu, Hanrong Ye, Ligeng Zhu, Zhijian Liu, Pavlo Molchanov, Jan Kautz, Xiaojuan Qi, Sifei Liu, Hongxu Yin, Yao Lu, Song Han* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 长视频推理, 视觉-语言模型, 强化学习, 数据集, 训练基础设施

**Comment:** Code at https://github.com/NVlabs/Long-RL and model at
  https://huggingface.co/Efficient-Large-Model/LongVILA-R1-7B

> **TL;DR:** 本文提出了一个用于长视频推理的全栈框架，结合了大规模数据集、两阶段训练流程和高效的训练基础设施，显著提升了视频问答性能和训练速度。

**AI_Comments:** 本文的创新点在于其为长视频推理提供了一个全面的全栈解决方案，从数据、训练方法到基础设施都进行了优化。特别是引入的大规模LongVideo-Reason数据集填补了长视频QA领域的空白，而MR-SP系统在效率方面的提升对于实际应用具有重要意义。该工作通过结合CoT-SFT和RL，有效提升了模型在复杂长视频内容上的推理能力，并且其开源的训练系统将极大促进相关研究。

<details>
  <summary>Details</summary>

**Motivation:** 解决视觉-语言模型（VLMs）在长视频推理中面临的独特挑战。

**Method:** 本文引入了一个全栈框架，通过强化学习将视觉-语言模型（VLMs）的推理能力扩展到长视频。该框架包含三个关键组件：1) 一个大规模数据集LongVideo-Reason，包含104K高质量长视频问答对；2) 一个两阶段训练流程，通过思维链监督微调（CoT-SFT）和强化学习（RL）扩展VLMs；3) 一个名为Multi-modal Reinforcement Sequence Parallelism (MR-SP) 的长视频RL训练基础设施，该设施整合了序列并行和基于vLLM的引擎，并利用缓存的视频嵌入进行高效的推出和预填充。

**Result:** LongVILA-R1-7B在VideoMME视频基准测试中取得了不带字幕65.0%和带字幕70.7%的准确率，并持续优于LongVILA-R1。LongVILA-R1的性能随着输入视频帧数的增加而稳步提升。MR-SP系统在长视频RL训练中实现了高达2.1倍的加速。此外，该训练系统支持在单A100节点（8个GPU）上对长达一小时的视频（例如3,600帧/约256k tokens）进行RL训练。

**Conclusion:** 本文提出的全栈框架和MR-SP系统有效解决了长视频推理的挑战，显著提升了视觉-语言模型在长视频问答任务上的性能和训练效率，并支持多模态和多种模型的RL训练。

> **ai_Abstract:** 本文提出了一个名为LongVILA的全栈框架，旨在通过强化学习提升视觉-语言模型在长视频上的推理能力。为应对长视频挑战，该框架集成了三大核心要素：大规模长视频问答数据集LongVideo-Reason；结合思维链监督微调和强化学习的两阶段训练流程；以及高效的长视频RL训练基础设施MR-SP，该系统利用序列并行和vLLM引擎优化训练效率。实验证明，LongVILA-R1-7B在视频问答任务上表现出色，并在长视频输入下保持性能提升，MR-SP系统显著加速了训练过程。该工作还开源了支持多模态和多种模型的训练系统。

> **摘要翻译:** 我们引入了一个全栈框架，利用强化学习将视觉-语言模型（VLMs）中的推理能力扩展到长视频。我们通过整合三个关键组件来解决长视频推理的独特挑战：(1) 一个大规模数据集LongVideo-Reason，包含104K高质量推理注释的长视频问答对，涵盖体育、游戏和视频博客等不同领域；(2) 一个两阶段训练流程，通过思维链监督微调（CoT-SFT）和强化学习（RL）扩展VLMs；(3) 一个用于长视频RL的训练基础设施，名为多模态强化序列并行（MR-SP），它结合了序列并行和专为长视频定制的基于vLLM的引擎，使用缓存的视频嵌入进行高效推出和预填充。在我们的实验中，LongVILA-R1-7B在视频基准测试中取得了强大的性能，在VideoMME上不带字幕和带字幕的准确率分别达到65.0%和70.7%，并在多个基准测试中持续优于LongVILA-R1。此外，LongVILA-R1显示出随着输入视频帧数增加而稳步提升的性能。值得注意的是，我们的MR-SP系统在长视频RL训练中实现了高达2.1倍的加速。此外，我们发布了可公开获取的训练系统，该系统支持在各种模态（视频、文本和音频）、各种模型（VILA和Qwen系列）甚至图像和视频生成模型上进行RL训练。在单个A100节点（8个GPU）上，它支持对长达一小时的视频（例如3,600帧/约256k token）进行RL训练。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [741] [EgoExoBench: A Benchmark for First- and Third-person View Video Understanding in MLLMs](https://arxiv.org/abs/2507.18342)
> *EgoExoBench：一个用于多模态大语言模型中第一人称和第三人称视频理解的基准*

*Yuping He, Yifei Huang, Guo Chen, Baoqi Pei, Jilan Xu, Tong Lu, Jiangmiao Pang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** EgoExoBench, 视频理解, 多模态大语言模型, 跨视角推理, 基准

**Comment:** 

> **TL;DR:** EgoExoBench是首个用于评估MLLM在第一人称和第三人称视角视频理解与推理能力的基准，发现当前SOTA模型在此方面表现不佳。

**AI_Comments:** EgoExoBench的创新之处在于它是首个专门针对MLLM在第一人称和第三人称视频理解及跨视角推理能力的基准。它揭示了当前SOTA MLLM在处理跨视角复杂任务时的局限性，特别是在语义对齐和时间推理方面，这对于具身智能和智能助手的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大语言模型（MLLMs）取得了快速进展，但它们在第一人称（自我中心）和第三人称（非自我中心）视角之间进行跨视角推理的能力尚未被探索。人类智能的本质在于能够跨这两种视角转移和整合知识，从而实现从他人学习并传达自身经验中的见解。

**Method:** 本文引入了EgoExoBench，这是首个用于自我中心-非自我中心视频理解和推理的基准。EgoExoBench基于公开可用数据集构建，包含超过7300个问答对，涵盖了语义对齐、视角关联和时间推理三个核心挑战下的十一个子任务。

**Result:** 通过评估13个最先进的MLLMs，发现尽管这些模型在单视角任务上表现出色，但它们在跨视角对齐语义、准确关联视角以及在自我-非自我语境中推断时间动态方面表现不佳。

**Conclusion:** EgoExoBench有望成为研究具身智能体和寻求类人跨视角智能的智能助手的宝贵资源。

> **ai_Abstract:** 本文提出了EgoExoBench，一个旨在评估多模态大语言模型（MLLMs）在第一人称和第三人称视角视频理解与跨视角推理能力的新基准。该基准包含11个子任务，围绕语义对齐、视角关联和时间推理三大核心挑战，构建了7300多个问答对。对13个SOTA MLLMs的评估显示，尽管它们在单视角任务上表现良好，但在跨视角语义对齐、视角关联和时间动态推理方面存在显著不足。EgoExoBench旨在推动具身智能体和智能助手在类人跨视角智能方面的研究。

> **摘要翻译:** 将第一人称（自我中心）和第三人称（非自我中心）视角的知识进行转移和整合是人类智能的内在特征，使人类能够向他人学习并传达自身经验中的见解。尽管多模态大语言模型（MLLMs）取得了快速进展，但它们执行此类跨视角推理的能力仍未被探索。为了解决这个问题，我们引入了EgoExoBench，这是首个用于自我中心-非自我中心视频理解和推理的基准。EgoExoBench基于公开可用数据集构建，包含超过7300个问答对，涵盖了语义对齐、视角关联和时间推理三个核心挑战下的十一个子任务。我们评估了13个最先进的MLLMs，发现尽管这些模型在单视角任务上表现出色，但它们在跨视角对齐语义、准确关联视角以及在自我-非自我语境中推断时间动态方面表现不佳。我们希望EgoExoBench能够成为研究具身智能体和寻求类人跨视角智能的智能助手的宝贵资源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [742] [ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars](https://arxiv.org/abs/2505.10072)
> *ToonifyGB：基于StyleGAN的高斯形变混合体用于3D风格化头部虚拟形象*

*Rui-Yang Ju, Sheng-Yen Huang, Yi-Ping Hung* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** StyleGAN, 高斯形变混合体, 3D虚拟形象, 风格化, 实时渲染

**Comment:** 

> **TL;DR:** ToonifyGB提出了一种两阶段框架，结合StyleGAN和高斯形变混合体，从单目视频生成多样化的3D风格化头部虚拟形象。

**AI_Comments:** 该论文提出了一种新颖的两阶段框架ToonifyGB，有效地结合了StyleGAN的图像风格化能力与高斯形变混合体的3D重建和动画能力。其创新点在于改进了StyleGAN以处理非固定分辨率输入，并利用生成的稳定风格化视频来学习高斯形变混合体，从而实现了高质量的3D风格化头部虚拟形象的实时渲染。这对于虚拟现实、游戏和动画等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D高斯形变混合体能实时重建可动画的头部虚拟形象，而Toonify是一种广泛使用的面部图像风格化方法。为了将Toonify扩展到使用高斯形变混合体合成多样化的风格化3D头部虚拟形象，研究人员提出了ToonifyGB。

**Method:** 本文提出了一个高效的两阶段框架ToonifyGB。第一阶段（风格化视频生成），采用改进的StyleGAN从输入视频帧生成风格化视频，解决了传统StyleGAN需要固定分辨率裁剪对齐人脸的限制，提供了更稳定的风格化视频。第二阶段（高斯形变混合体合成），方法从生成的风格化视频中学习一个风格化的中性头部模型和一组表情形变混合体。通过结合中性头部模型和表情形变混合体，ToonifyGB可以高效地渲染具有任意表情的风格化虚拟形象。

**Result:** ToonifyGB在基准数据集上使用两种代表性风格（Arcane和Pixar）验证了其有效性，能够生成高质量的动画和具有任意表情的风格化虚拟形象。

**Conclusion:** ToonifyGB成功地将StyleGAN的风格化能力与高斯形变混合体结合，实现了从单目视频高效生成多样化、高质量的3D风格化头部虚拟形象。

> **ai_Abstract:** ToonifyGB是一个两阶段框架，旨在利用StyleGAN和高斯形变混合体从单目视频生成多样化的3D风格化头部虚拟形象。第一阶段使用改进的StyleGAN生成稳定的风格化视频，克服了传统StyleGAN的裁剪限制。第二阶段从风格化视频中学习中性头部模型和表情形变混合体，从而实现高效渲染具有任意表情的风格化虚拟形象。该方法在Arcane和Pixar风格上验证了其有效性。

> **摘要翻译:** 3D高斯形变混合体的引入使得从单目视频实时重建可动画的头部虚拟形象成为可能。Toonify，一种基于StyleGAN的方法，已广泛用于面部图像风格化。为了扩展Toonify以使用高斯形变混合体合成多样化的风格化3D头部虚拟形象，我们提出了一个高效的两阶段框架ToonifyGB。在第一阶段（风格化视频生成）中，我们采用改进的StyleGAN从输入视频帧生成风格化视频，这克服了传统StyleGAN需要预处理裁剪固定分辨率对齐人脸的限制。此过程提供了更稳定的风格化视频，使高斯形变混合体能更好地捕捉视频帧的高频细节，从而促进下一阶段高质量动画的合成。在第二阶段（高斯形变混合体合成）中，我们的方法从生成的风格化视频中学习一个风格化的中性头部模型和一组表情形变混合体。通过将中性头部模型与表情形变混合体结合，ToonifyGB可以高效地渲染具有任意表情的风格化虚拟形象。我们在基准数据集上使用两种代表性风格：奥术（Arcane）和皮克斯（Pixar）验证了ToonifyGB的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [750] [Distributional Uncertainty for Out-of-Distribution Detection](https://arxiv.org/abs/2507.18106)
> *分布不确定性用于离群点检测*

*JinYoung Kim, DaeUng Jo, Kimin Yun, Jeonghyo Song, Youngjoon Yoo* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 分布不确定性, 离群点检测, 自由能后验网络, 不确定性估计, 语义分割

**Comment:** 6 pages , 3 figures , IEEE International Conference on Advanced
  Visual and Signal-Based Systems

> **TL;DR:** 本文提出了自由能后验网络，通过联合建模分布不确定性来有效检测离群点（OoD）样本，并解决了传统方法在不确定性估计上的局限性。

**AI_Comments:** 该论文的创新点在于提出了自由能后验网络，通过联合建模分布不确定性来解决传统OoD检测中不确定性估计的局限性。特别是引入基于Beta分布的密度估计器和无需采样的直接不确定性估计方法，显著提升了不确定性估计的细粒度、语义准确性和计算效率，对于不确定性感知分割具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的深度神经网络不确定性估计方法（如Monte Carlo Dropout）在离群点检测中，通常只关注模型或数据不确定性，未能与离群点检测的语义目标对齐。

**Method:** 本文提出了自由能后验网络（Free-Energy Posterior Network），这是一个新颖的框架，它利用自由能联合建模分布不确定性，并识别离群点和错误分类区域。该方法引入了两大贡献：1) 一个基于Beta分布参数化的自由能密度估计器，能够实现对模糊或未见区域的细粒度不确定性估计；2) 一个集成在后验网络中的损失函数，允许从学习到的参数直接估计不确定性，无需随机采样。通过与残差预测分支（RPL）框架结合，该方法利用Beta分布的方差来学习离群点区域。

**Result:** 该方法在Fishyscapes、RoadAnomaly和Segment-Me-If-You-Can等具有挑战性的真实世界基准测试中验证了其有效性，实现了语义上有意义且计算高效的不确定性感知分割。

**Conclusion:** 本文提出的自由能后验网络通过联合建模分布不确定性，有效解决了传统离群点检测方法在不确定性估计上的不足，提供了一种语义上更准确且计算高效的离群点识别和不确定性感知分割方案。

> **ai_Abstract:** 本文提出了一种新颖的自由能后验网络（Free-Energy Posterior Network），旨在解决现有深度学习方法在离群点（OoD）检测中不确定性估计的不足。该框架通过利用自由能联合建模分布不确定性，能够更准确地识别OoD和错误分类区域。其主要创新包括基于Beta分布的自由能密度估计器（用于细粒度不确定性估计）和集成在后验网络中的损失函数（实现直接不确定性估计而无需采样）。该方法与残差预测分支（RPL）框架结合，通过学习Beta分布的方差来识别OoD区域，最终在多个真实世界基准测试中展现出高效且语义准确的不确定性感知分割能力。

> **摘要翻译:** 从深度神经网络估计不确定性是检测离群点（OoD）样本的广泛使用方法，离群点通常表现出高预测不确定性。然而，传统的蒙特卡洛（MC）Dropout等方法往往只关注模型或数据不确定性，未能与OoD检测的语义目标对齐。为了解决这个问题，我们提出了自由能后验网络（Free-Energy Posterior Network），这是一个新颖的框架，它利用自由能联合建模分布不确定性，并识别OoD和错误分类区域。我们的方法引入了两大关键贡献：（1）一个基于Beta分布参数化的自由能密度估计器，能够实现对模糊或未见区域的细粒度不确定性估计；（2）一个集成在后验网络中的损失函数，允许从学习到的参数直接估计不确定性，无需随机采样。通过将我们的方法与残差预测分支（RPL）框架相结合，所提出的方法超越了事后能量阈值，并通过利用Beta分布的方差使网络能够学习OoD区域，从而为不确定性感知分割提供了一个语义上有意义且计算高效的解决方案。我们在包括Fishyscapes、RoadAnomaly和Segment-Me-If-You-Can在内的具有挑战性的真实世界基准测试中验证了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [751] [Structure Matters: Revisiting Boundary Refinement in Video Object Segmentation](https://arxiv.org/abs/2507.18944)
> *结构至关重要：重新审视视频目标分割中的边界细化*

*Guanyi Qin, Ziyue Wang, Daiyun Shen, Haofeng Liu, Hantao Zhou, Junde Wu, Runze Hu, Yueming Jin* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-25**

**Keywords:** 视频目标分割, 边界细化, 遮挡, 结构细化, 证据学习

**Comment:** 

> **TL;DR:** 本文提出了一种名为OASIS的新型视频目标分割方法，通过轻量级结构细化模块和证据学习来提高遮挡场景下的分割精度和速度。

**AI_Comments:** 该论文通过引入“结构细化模块”和“证据学习”来解决半监督视频目标分割中长期存在的遮挡和边界模糊问题，具有创新性。其轻量级设计和在性能与速度上的平衡，使其在实际应用中具有重要潜力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现有的基于记忆的半监督视频目标分割方法具有潜力，但在处理涉及遮挡、物体交互和高特征相似度的场景时表现不佳，且难以满足实时处理需求。

**Method:** 本文提出了一种名为OASIS的新型边界修正视频目标分割方法。该方法包含一个轻量级结构细化模块，通过融合Canny滤波器捕获的粗略边缘先验和存储的对象特征，生成对象级结构图并突出边界特征以提高分割精度。此外，引入证据学习进行不确定性估计，以进一步解决遮挡区域的挑战。

**Result:** 所提出的OASIS方法在DAVIS-17验证集上F值达到91.6（对比89.7），在YouTubeVOS 2019验证集上G值达到86.6（对比86.2），同时在DAVIS数据集上保持48 FPS的竞争性速度，展现出优越的性能和推理速度。

**Conclusion:** 本文提出的OASIS方法在具有挑战性的基准测试中展现出优于现有最先进方法的性能和竞争性的推理速度，有效解决了视频目标分割中遮挡场景的挑战。

> **ai_Abstract:** 本文针对半监督视频目标分割（SVOS）中现有方法在处理遮挡和高特征相似度场景时的不足，以及对实时性要求，提出了一种名为OASIS的新型方法。OASIS通过引入轻量级结构细化模块，结合Canny边缘先验和对象特征生成结构图并强化边界特征，以提高分割精度。此外，该方法利用证据学习进行不确定性估计，以更好地处理遮挡区域。实验结果表明，OASIS在多个挑战性基准测试中表现出卓越的性能和高效的推理速度，优于现有最先进的方法。

> **摘要翻译:** 给定一个对象掩码，半监督视频对象分割（SVOS）技术旨在跨视频帧跟踪和分割对象，是计算机视觉中的一项基本任务。尽管最近基于记忆的方法展现出潜力，但它们在处理涉及遮挡的场景时常常遇到困难，尤其是在处理对象交互和高特征相似度方面。为了解决这些问题并满足下游应用的实时处理要求，在本文中，我们提出了一种新颖的具有固有结构细化的边界修正视频对象分割方法，命名为OASIS。具体来说，我们提出了一个轻量级结构细化模块以提高分割精度。通过融合Canny滤波器捕获的粗略边缘先验和存储的对象特征，该模块可以生成对象级结构图并通过突出边界特征来细化表示。引入证据学习进行不确定性估计，以进一步解决遮挡区域的挑战。所提出的方法OASIS保持了高效的设计，然而在具有挑战性的基准测试中进行的广泛实验表明，与现有最先进的方法相比，它具有优越的性能和竞争性的推理速度，即在DAVIS-17验证集上F值达到91.6（对比89.7），在YouTubeVOS 2019验证集上G值达到86.6（对比86.2），同时在DAVIS上保持48 FPS的竞争性速度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [761] [OPEN: A Benchmark Dataset and Baseline for Older Adult Patient Engagement Recognition in Virtual Rehabilitation Learning Environments](https://arxiv.org/abs/2507.17959)
> *OPEN：一个用于虚拟康复学习环境中老年患者参与度识别的基准数据集和基线*

*Ali Abedi, Sadaf Safa, Tracey J. F. Colella, Shehroz S. Khan* | **Category: cs.CV** | **Updated: 2025-07-23**

**Keywords:** 老年患者参与度, 虚拟康复, 数据集, 参与度识别, 人工智能

**Comment:** 14 pages, 3 figures, 7 tables

> **TL;DR:** 本文介绍了OPEN数据集，这是一个用于在虚拟康复环境中识别老年患者参与度的大型数据集，并提供了基线模型。

**AI_Comments:** 该论文通过引入OPEN数据集，解决了在虚拟康复环境中老年患者参与度识别领域数据稀缺的关键问题。其创新之处在于专注于老年人群体，并提供了丰富的多模态数据（面部、手、身体关节地标及情感行为特征），同时兼顾了隐私保护。数据集的规模和提供的基线模型使其具有重要的研究价值，为未来个性化参与度建模奠定了基础。然而，论文未详细说明基线模型的具体架构和更多评估指标，这可能是未来工作的方向。

<details>
  <summary>Details</summary>

**Motivation:** 在虚拟学习中准确测量参与度，特别是在老年患者的虚拟康复环境中，是一个挑战。现有研究和数据集在老年人群体中有限，且常忽略上下文和参与度的长期性。

**Method:** 研究团队收集了11名老年患者在为期六周的每周虚拟小组学习会话（作为心脏康复的一部分）中的数据，总计超过35小时。为了保护隐私，发布的数据包括面部、手部和身体关节地标，以及从视频中提取的情感和行为特征。数据还包括二元参与状态、情感和行为标签以及上下文类型指示器。数据集提供5秒、10秒、30秒和可变长度样本版本。训练了多种机器学习和深度学习模型来演示其效用。

**Result:** OPEN数据集是同类中最大的数据集，包含超过35小时的数据。训练的模型实现了高达81%的参与度识别准确率。

**Conclusion:** OPEN数据集为老年人群的个性化参与度建模提供了可扩展的基础，并有助于更广泛的参与度识别研究。

> **ai_Abstract:** 本文介绍了OPEN数据集，这是一个为虚拟康复学习环境中老年患者参与度识别而设计的新型基准数据集。该数据集包含来自11名老年患者超过35小时的视频衍生特征和注释数据，是同类中最大的。研究者还提供了基线机器学习和深度学习模型，实现了高达81%的参与度识别准确率。OPEN旨在为老年人群的个性化参与度建模和更广泛的参与度识别研究提供支持。

> **摘要翻译:** 在虚拟学习中的参与对于参与者的满意度、表现和依从性至关重要，特别是在在线教育和虚拟康复中，互动交流起着关键作用。然而，在虚拟小组环境中准确测量参与度仍然是一个挑战。人们对使用人工智能（AI）进行大规模、真实世界、自动化参与度识别的兴趣日益增长。虽然参与度在年轻学术人群中得到了广泛研究，但针对虚拟和远程医疗学习环境中老年人的研究和数据集仍然有限。现有方法常常忽视上下文相关性和参与度在会话间的长期性。本文介绍了OPEN（老年患者参与度），一个支持AI驱动的参与度识别的新型数据集。该数据集收集自11名老年患者，他们在为期六周的每周虚拟小组学习会话中参与心脏康复，产生了超过35小时的数据，使其成为同类中最大的数据集。为了保护隐私，原始视频被保留；相反，发布的数据包括面部、手部和身体关节地标，以及从视频中提取的情感和行为特征。注释包括二元参与状态、情感和行为标签，以及上下文类型指示器，例如教师是面向小组还是个人。数据集提供5秒、10秒、30秒和可变长度样本版本。为了演示其效用，训练了多种机器学习和深度学习模型，实现了高达81%的参与度识别准确率。OPEN为老年人群的个性化参与度建模提供了可扩展的基础，并有助于更广泛的参与度识别研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [766] [FUDOKI: Discrete Flow-based Unified Understanding and Generation via Kinetic-Optimal Velocities](https://arxiv.org/abs/2505.20147)
> *FUDOKI: 基于离散流的统一理解与生成通过动能最优速度*

*Jin Wang, Yao Lai, Aoxue Li, Shifeng Zhang, Jiacheng Sun, Ning Kang, Chengyue Wu, Zhenguo Li, Ping Luo* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 离散流匹配, 多模态模型, 统一理解与生成, 动能最优速度, 非自回归

**Comment:** 37 pages, 12 figures

> **TL;DR:** FUDOKI提出了一种基于离散流匹配的统一多模态模型，超越了传统的自回归范式，在视觉理解和图像生成任务上达到了与现有最先进模型相当的性能。

**AI_Comments:** 该论文创新性地将离散流匹配引入多模态大模型领域，为克服自回归模型的固有局限性提供了一条新路径。其通过动能最优速度实现迭代细化和双向上下文集成的能力，是区别于传统方法的关键点。从预训练AR模型进行初始化的策略，有效降低了训练成本，使其具有实际可行性。FUDOKI的提出为多模态模型的未来发展奠定了重要基础，尤其是在非自回归生成和更灵活的上下文建模方面。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型多模态语言模型（MLLMs）大多依赖自回归（AR）架构，这在图像生成中的光栅扫描顺序和因果上下文建模中的推理能力方面存在固有限制，阻碍了未来的发展。

**Method:** FUDOKI是一个纯粹基于离散流匹配的统一多模态模型。它利用度量诱导的概率路径和动能最优速度，超越了以往基于掩码的损坏过程，实现了具有自我校正能力的迭代细化和更丰富的双向上下文集成。为了降低从头训练的成本，FUDOKI从预训练的基于AR的MLLMs初始化，并自适应地过渡到离散流匹配范式。

**Result:** FUDOKI在视觉理解和图像生成任务上取得了与最先进的基于自回归的MLLMs相当的性能。此外，应用测试时缩放技术可以显著提升FUDOKI的性能。

**Conclusion:** FUDOKI作为一种基于离散流匹配的统一多模态模型，展现出作为下一代统一多模态模型基础的潜力，并通过测试时缩放技术显示出未来通过强化学习进一步增强的希望。

> **ai_Abstract:** FUDOKI提出了一种基于离散流匹配的统一多模态模型，旨在克服传统自回归（AR）MLLMs在图像生成和推理方面的限制。该模型利用动能最优速度和度量诱导的概率路径，实现了迭代细化和更丰富的双向上下文集成。通过从预训练的AR-MLLMs初始化，FUDOKI在视觉理解和图像生成任务上达到了与现有最先进AR-MLLMs相当的性能，并可通过测试时缩放进一步提升，展现了其作为下一代统一多模态模型基础的巨大潜力。

> **摘要翻译:** 大型语言模型（LLMs）的快速发展催生了多模态大型语言模型（MLLMs）的出现，这些模型在单一框架内统一了视觉理解和图像生成。然而，大多数现有MLLMs依赖于自回归（AR）架构，这对其未来的发展施加了固有限制，例如图像生成中的光栅扫描顺序和因果上下文建模中受限的推理能力。在这项工作中，我们通过引入FUDOKI，一个纯粹基于离散流匹配的统一多模态模型，作为传统AR范式的替代方案，挑战了AR基方法的主导地位。通过利用度量诱导的概率路径和动能最优速度，我们的框架超越了以往基于掩码的损坏过程，实现了具有自我校正能力的迭代细化和在生成过程中更丰富的双向上下文集成。为了减轻从头开始训练的高成本，我们从预训练的基于AR的MLLMs初始化FUDOKI，并自适应地过渡到离散流匹配范式。实验结果表明，FUDOKI在视觉理解和图像生成任务上都取得了与最先进的基于AR的MLLMs相当的性能，突显了其作为下一代统一多模态模型基础的潜力。此外，我们展示了将测试时缩放技术应用于FUDOKI可以产生显著的性能增益，进一步强调了其通过强化学习未来增强的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [775] [VB-Mitigator: An Open-source Framework for Evaluating and Advancing Visual Bias Mitigation](https://arxiv.org/abs/2507.18348)
> *VB-Mitigator：一个用于评估和推进视觉偏见缓解的开源框架*

*Ioannis Sarridis, Christos Koutlis, Symeon Papadopoulos, Christos Diou* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 视觉偏见缓解, 开源框架, 计算机视觉, 公平性, 评估

**Comment:** 

> **TL;DR:** VB-Mitigator是一个开源框架，旨在通过提供统一的开发、评估和比较环境，解决计算机视觉模型中视觉偏见缓解研究中存在的碎片化实现和不一致评估实践问题，从而加速公平性计算机视觉模型的研究。

**AI_Comments:** VB-Mitigator的创新之处在于它提供了一个统一、开放且可扩展的平台，解决了视觉偏见缓解领域长期存在的碎片化问题。这对于提高研究的可重现性、公平比较不同方法以及加速该领域的进展至关重要。其重要性在于，通过标准化评估流程和提供丰富的现有方法及数据集，它能显著降低新研究的门槛，并促进更公平、更可靠的AI系统的开发。

<details>
  <summary>Details</summary>

**Motivation:** 计算机视觉模型中的偏见仍然是一个重大挑战，导致AI系统不公平、不可靠且缺乏泛化性。尽管偏见缓解研究不断深入，但碎片化的实现和不一致的评估实践阻碍了进展。不同研究中使用的不同数据集和指标使得重现性复杂化，难以公平评估和比较各种方法的有效性。

**Method:** 为了克服这些局限性，我们引入了Visual Bias Mitigator (VB-Mitigator)，这是一个开源框架，旨在简化视觉偏见缓解技术的发展、评估和比较分析。VB-Mitigator提供了一个统一的研究环境，包含12种已建立的缓解方法和7个多样化的基准数据集。VB-Mitigator的一个关键优势是其可扩展性，允许无缝集成额外的方法、数据集、指标和模型。

**Result:** VB-Mitigator旨在通过作为研究社区开发和评估其方法的基准代码库来加速面向公平性计算机视觉模型的研究。为此，我们还推荐了最佳评估实践，并提供了最先进方法之间的全面性能比较。

**Conclusion:** VB-Mitigator通过提供一个统一、可扩展的开源框架，促进了视觉偏见缓解研究的标准化和加速，并推荐了最佳评估实践，从而推动了公平性计算机视觉模型的发展。

> **ai_Abstract:** VB-Mitigator是一个开源框架，旨在解决计算机视觉模型中视觉偏见缓解研究的碎片化和评估不一致问题。它提供了一个统一的研究环境，集成了12种缓解方法和7个数据集，并具有高度可扩展性。该框架旨在通过提供一个基础代码库、推荐最佳评估实践以及进行全面的性能比较，加速公平性计算机视觉模型的研究。

> **摘要翻译:** 计算机视觉模型中的偏见仍然是一个重大挑战，常常导致不公平、不可靠和不可泛化的AI系统。尽管偏见缓解的研究已经加强，但碎片化的实现和不一致的评估实践持续阻碍着进展。不同研究中使用不同的数据集和指标使得重现性复杂化，难以公平评估和比较各种方法的有效性。为了克服这些局限性，我们引入了Visual Bias Mitigator (VB-Mitigator)，一个开源框架，旨在简化视觉偏见缓解技术的发展、评估和比较分析。VB-Mitigator提供了一个统一的研究环境，包含12种已建立的缓解方法和7个多样化的基准数据集。VB-Mitigator的一个关键优势是其可扩展性，允许无缝集成额外的方法、数据集、指标和模型。VB-Mitigator旨在通过作为研究社区开发和评估其方法的基准代码库来加速面向公平性计算机视觉模型的研究。为此，我们还推荐了最佳评估实践，并提供了最先进方法之间的全面性能比较。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [776] [GaussianFusionOcc: A Seamless Sensor Fusion Approach for 3D Occupancy Prediction Using 3D Gaussians](https://arxiv.org/abs/2507.18522)
> *GaussianFusionOcc: 一种使用3D高斯进行3D占用预测的无缝传感器融合方法*

*Tomislav Pavković, Mohammad-Ali Nikouei Mahani, Johannes Niedermayer, Johannes Betz* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 3D 占用预测, 传感器融合, 3D 高斯, 自动驾驶, 语义预测

**Comment:** 

> **TL;DR:** GaussianFusionOcc利用3D高斯和无缝传感器融合，实现更精确、高效的3D语义占用预测，超越现有SOTA模型。

**AI_Comments:** 该论文的创新点在于将3D高斯表示引入3D语义占用预测任务，这显著提升了内存效率和推理速度，解决了传统密集网格表示的局限性。同时，其提出的无缝多模态传感器融合机制，能够有效整合不同传感器数据，增强了预测的鲁棒性和准确性。这项工作对自动驾驶领域环境感知任务的实时性和资源效率具有重要意义，为未来的研究提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 3D语义占用预测是自动驾驶的关键任务，对复杂环境的精确安全解释和导航至关重要。可靠的预测依赖于有效的传感器融合，因为不同模态包含互补信息。

**Method:** GaussianFusionOcc提出了一种使用语义3D高斯和创新传感器融合机制的方法。它无缝整合来自相机、LiDAR和雷达传感器的数据，并采用模态无关的可变形注意力来提取关键特征，然后用于优化高斯属性，以更准确地表示环境。与传统依赖密集网格表示的方法不同，它使用3D高斯表示。

**Result:** 通过与各种传感器组合的广泛测试，该方法展示了其多功能性。GaussianFusionOcc通过利用多模态融合的鲁棒性和高斯表示的效率，超越了当前最先进的模型。3D高斯表示显著提高了内存效率和推理速度。

**Conclusion:** GaussianFusionOcc通过结合无缝多模态传感器融合和高效3D高斯表示，实现了卓越的3D语义占用预测，为自动驾驶提供了更精确、高效的环境理解。

> **ai_Abstract:** 本文提出GaussianFusionOcc，一种用于3D语义占用预测的新方法，它摒弃传统密集网格，转而采用语义3D高斯表示，显著提升内存效率和推理速度。该方法通过创新的无缝传感器融合机制，结合相机、LiDAR和雷达数据，并利用模态无关的可变形注意力优化高斯属性，从而实现对环境更精确的表示。实验证明，GaussianFusionOcc在性能上超越了现有最先进的模型，展现了多功能性。

> **摘要翻译:** 3D语义占用预测是自动驾驶的关键任务之一。它能够实现复杂环境中精确安全的解释和导航。可靠的预测依赖于有效的传感器融合，因为不同模态可以包含互补信息。与依赖密集网格表示的传统方法不同，我们的方法GaussianFusionOcc使用语义3D高斯以及创新的传感器融合机制。无缝集成来自相机、LiDAR和雷达传感器的数据，可以实现更精确和可扩展的占用预测，同时3D高斯表示显著提高了内存效率和推理速度。GaussianFusionOcc采用模态无关的可变形注意力从每种传感器类型中提取基本特征，然后使用这些特征来优化高斯属性，从而更准确地表示环境。与各种传感器组合的广泛测试证明了我们方法的多功能性。通过利用多模态融合的鲁棒性和高斯表示的效率，GaussianFusionOcc超越了当前最先进的模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [777] [Cloud gap-filling with deep learning for improved grassland monitoring](https://arxiv.org/abs/2403.09554)
> *基于深度学习的云间隙填充以改进草地监测*

*Iason Tsardanidis, Alkiviadis Koukos, Vasileios Sitokonstantinou, Thanassis Drivas, Charalampos Kontoes* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-24**

**Keywords:** 云间隙填充, 深度学习, 草地监测, NDVI, Sentinel-2, Sentinel-1

**Comment:** Published in Computers and Electronics in Agriculture

> **TL;DR:** 该研究提出了一种结合深度学习和多源遥感数据的方法，用于填充光学图像中的云间隙，生成连续的NDVI时间序列，从而改进草地监测和割草事件检测。

**AI_Comments:** 该论文的创新点在于结合了多源遥感数据（光学和SAR）与深度学习（CNN-RNN混合架构）来解决遥感图像中云覆盖导致的数据缺失问题。这种方法不仅生成了连续的NDVI时间序列，还通过下游任务（割草事件检测）验证了其有效性，证明了其在实际农业监测中的重要应用潜力。其优势在于利用SAR数据的全天候特性弥补了光学数据的局限性，并利用深度学习模型捕捉时空特征。

<details>
  <summary>Details</summary>

**Motivation:** 连续的光学图像时间序列对于及时监测农业土地变化（特别是草地）至关重要，但云层经常会中断这些时间序列的连续性。

**Method:** 提出了一种创新的深度学习方法，整合了无云光学（Sentinel-2）观测数据和不受天气影响的（Sentinel-1）合成孔径雷达（SAR）数据。该方法采用混合架构，结合了卷积神经网络（CNNs）和循环神经网络（RNNs），以生成连续的归一化植被指数（NDVI）时间序列。

**Result:** 该方法优于其他插值技术（线性、Akima、二次），平均绝对误差（MAE）为0.024，决定系数R^2为0.92。此外，割草事件检测的F1-score提高到84%。该方法有效减轻了由多云观测引起的突然偏移和噪声。

**Conclusion:** 该深度学习方法能够有效地填充光学图像中的云间隙，生成高质量的连续NDVI时间序列，显著改善了草地监测中的割草事件检测精度。

> **ai_Abstract:** 本研究提出一种基于深度学习的创新方法，通过融合Sentinel-2光学数据和Sentinel-1 SAR数据，实现光学图像的云间隙填充，生成连续的NDVI时间序列。该方法采用CNNs和RNNs的混合架构，有效提高了草地监测中割草事件检测的精度。在立陶宛的实验表明，该方法在MAE和R^2方面优于传统插值技术，并显著提升了割草检测的F1-score，同时有效缓解了云层引起的噪声问题。

> **摘要翻译:** 不间断的光学图像时间序列对于及时监测农业土地变化，特别是草地，至关重要。然而，这种时间序列的连续性常常被云层中断。为了应对这一挑战，我们提出了一种创新的深度学习方法，该方法整合了无云光学（Sentinel-2）观测数据和不受天气影响的（Sentinel-1）合成孔径雷达（SAR）数据。我们的方法采用了一种结合卷积神经网络（CNNs）和循环神经网络（RNNs）的混合架构，以生成连续的归一化植被指数（NDVI）时间序列，突出了NDVI在SAR和光学数据协同作用中的作用。我们通过评估所生成的NDVI时间序列对草地割草事件检测下游任务的影响，证明了观测连续性的重要性。我们在立陶宛（一个以广泛云覆盖为特征的国家）进行了研究，并将我们的方法与替代插值技术（即线性、Akima、二次）进行了比较。我们的方法优于这些技术，平均绝对误差（MAE）达到0.024，决定系数R^2为0.92。此外，我们的分析显示，使用两种广泛应用的割草检测方法，割草事件检测的性能有所改善，F1-score高达84%。我们的方法还有效减轻了源自多云观测的突然偏移和噪声，这些偏移和噪声常常被传统云掩膜遗漏，并对割草检测精度产生不利影响。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [790] [Flash-VStream: Efficient Real-Time Understanding for Long Video Streams](https://arxiv.org/abs/2506.23825)
> *Flash-VStream: 长视频流的实时高效理解*

*Haoji Zhang, Yiqin Wang, Yansong Tang, Yong Liu, Jiashi Feng, Xiaojie Jin* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 长视频理解, 视频语言模型, 实时处理, Flash Memory, 高效性

**Comment:** Accepted by ICCV 2025

> **TL;DR:** Flash-VStream提出了一种高效的视频语言模型，通过Flash Memory模块处理超长视频流并实现实时响应，显著降低推理延迟并达到SOTA性能。

**AI_Comments:** Flash-VStream的创新点在于其提出的Flash Memory模块，它巧妙地结合了低容量上下文记忆和高容量增强记忆，以解决长视频理解中固有的长上下文挑战。这种设计不仅提高了处理效率，显著降低了推理延迟，还使其能够推广到更长的视频，这对于实时应用至关重要。该方法在多项基准测试中表现出SOTA性能，证明了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型多模态语言模型在长视频理解方面面临挑战，因为其长上下文特性导致显著的计算和内存开销。大多数现有方法对长视频的处理方式与短视频相同，这对于实际应用来说效率低下，并且难以推广到更长的视频。

**Method:** 我们提出了Flash-VStream，一个高效的视频语言模型，能够处理超长视频并实时响应用户查询。我们设计了一个Flash Memory模块，其中包含一个低容量的上下文记忆用于聚合长上下文时间信息并建模信息密度分布，以及一个高容量的增强记忆，根据此分布检索详细的空间信息。

**Result:** 与现有模型相比，Flash-VStream显著降低了推理延迟。在长视频基准和综合视频基准（如EgoSchema、MLVU、LVBench、MVBench和Video-MME）上的大量实验表明，我们的方法达到了最先进的性能和卓越的效率。

**Conclusion:** Flash-VStream通过其创新的Flash Memory模块，有效解决了长视频理解中的计算和内存挑战，实现了实时高效的视频流处理，并在多项基准测试中展现出卓越的性能和效率。

> **ai_Abstract:** Flash-VStream是一个针对长视频流实时理解的高效视频语言模型。针对现有模型在处理长视频时面临的计算和内存开销问题，该模型引入了独特的Flash Memory模块，包含上下文记忆和增强记忆，以有效聚合时间信息并检索详细空间信息。实验证明，Flash-VStream在多个长视频和综合视频基准测试中显著降低了推理延迟，并取得了最先进的性能和卓越的效率。

> **摘要翻译:** 受益于大型语言模型和跨模态对齐的进步，现有的多模态大型语言模型在图像和短视频理解方面取得了显著的性能。然而，长视频的理解仍然具有挑战性，因为其长上下文特性导致显著的计算和内存开销。大多数现有工作以与短视频相同的方式处理长视频，这对于实际应用来说效率低下，并且难以推广到更长的视频。为了解决这些问题，我们提出了Flash-VStream，一个高效的视频语言模型，能够处理超长视频并实时响应用户查询。特别是，我们设计了一个Flash Memory模块，其中包含一个低容量的上下文记忆，用于聚合长上下文时间信息并建模信息密度分布，以及一个高容量的增强记忆，根据此分布检索详细的空间信息。与现有模型相比，Flash-VStream显著降低了推理延迟。在长视频基准和综合视频基准（即EgoSchema、MLVU、LVBench、MVBench和Video-MME）上的大量实验表明，我们的方法达到了最先进的性能和卓越的效率。代码可在https://github.com/IVGSZ/Flash-VStream获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [798] [T2VWorldBench: A Benchmark for Evaluating World Knowledge in Text-to-Video Generation](https://arxiv.org/abs/2507.18107)
> *T2VWorldBench：一个评估文本到视频生成中世界知识的基准*

*Yubin Chen, Xuyang Guo, Zhenmei Shi, Zhao Song, Jiahao Zhang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 文本到视频生成, 世界知识, 基准, 评估, T2VWorldBench

**Comment:** 

> **TL;DR:** 提出了T2VWorldBench，一个用于评估文本到视频模型世界知识的基准，发现当前模型在这方面存在显著不足。

**AI_Comments:** 这项工作创新性地提出了首个专门用于评估文本到视频模型世界知识的基准，填补了该领域的一个重要空白。其结合人工和自动化评估的方法提升了评估的全面性和可扩展性。研究结果明确指出了当前T2V模型的局限性，为未来开发更具常识推理和事实准确性的模型提供了明确的研究方向，具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 文本到视频（T2V）模型在生成视觉上合理的场景方面表现出色，但其利用世界知识以确保语义一致性和事实准确性的能力仍未得到充分研究。

**Method:** 提出了T2VWorldBench，一个系统性的评估框架，涵盖6个主要类别、60个子类别和1,200个提示，涉及物理、自然、活动、文化、因果关系和物体等领域。该基准结合了人工评估和使用视觉语言模型（VLMs）的自动化评估。

**Result:** 评估了10个最先进的文本到视频模型，发现大多数模型无法理解世界知识并生成真正正确的视频。

**Conclusion:** 当前文本到视频模型在利用世界知识方面存在关键差距，这为构建具有强大常识推理和事实生成能力的模型提供了宝贵的研究机会和切入点。

> **ai_Abstract:** 本文提出了T2VWorldBench，一个新颖的基准，旨在系统评估文本到视频（T2V）模型在理解和利用世界知识方面的能力。该基准包含广泛的类别和提示，并结合了人工和自动化评估方法。通过对10个先进T2V模型的评估，研究发现现有模型在生成符合世界知识的视频方面存在显著缺陷，揭示了该领域未来研究的关键方向。

> **摘要翻译:** 文本到视频（T2V）模型在生成视觉上合理的场景方面表现出色，但其利用世界知识以确保语义一致性和事实准确性的能力仍未得到充分研究。为了应对这一挑战，我们提出了T2VWorldBench，这是第一个系统性评估框架，用于评估文本到视频模型的生成世界知识的能力，涵盖物理、自然、活动、文化、因果关系和物体等六个主要类别、六十个子类别和一千二百个提示，涉及广泛的领域。为了兼顾人类偏好和可扩展评估，我们的基准结合了人工评估和使用视觉语言模型（VLMs）的自动化评估。我们评估了当前可用的十个最先进的文本到视频模型，从开源模型到商业模型，发现大多数模型无法理解世界知识并生成真正正确的视频。这些发现指出了当前文本到视频模型在利用世界知识能力方面的关键差距，为构建具有强大常识推理和事实生成能力的模型提供了宝贵的研究机会和切入点。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [803] [Bearded Dragon Activity Recognition Pipeline: An AI-Based Approach to Behavioural Monitoring](https://arxiv.org/abs/2507.17987)
> *鬃狮蜥活动识别管线：一种基于AI的行为监测方法*

*Arsen Yermukan, Pedro Machado, Feliciano Domingos, Isibor Kennedy Ihianle, Jordan J. Bird, Stefano S. K. Kaburu, Samantha J. Ward* | **Category: cs.CV** | **Updated: 2025-07-23**

**Keywords:** 鬃狮蜥, 行为监测, YOLO, 目标检测, 自动化系统

**Comment:** 

> **TL;DR:** 本文提出一个基于YOLO的自动化系统，用于实时监测鬃狮蜥的晒太阳和捕食行为，通过分析视频帧并应用规则逻辑，显著提高行为研究效率。

**AI_Comments:** 该论文提出了一种创新的、基于AI的方法来自动化动物行为监测，解决了传统方法的耗时和易错问题。其亮点在于利用YOLO模型进行实时视频分析，并构建了自定义数据集。然而，捕食行为识别的准确性受限于小目标（蟋蟀）检测的挑战，这指出了未来研究的方向，即需要更鲁棒的小目标检测技术。该系统对于大规模行为学研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统监测鬃狮蜥行为耗时且易出错。

**Method:** 本文引入一个自动化系统用于实时视频分析，使用YOLO（v5, v7, v8, v11, v12）目标检测模型识别鬃狮蜥的晒太阳和捕食行为。模型在包含鬃狮蜥、加热灯和蟋蟀的自定义公开数据集（1200张图像）上训练，其中YOLOv8s因其在准确性与速度间的平衡被选为最佳模型。系统通过提取每帧对象坐标、应用时间插值和基于规则的逻辑来分类特定行为。

**Result:** YOLOv8s被选为最佳模型，其准确性mAP@0.5:0.95为0.855。晒太阳行为检测被证明是可靠的。然而，捕食行为检测准确性较低，主要原因是蟋蟀检测效果不佳（mAP@0.5 = 0.392）。

**Conclusion:** 该自动化系统为受控环境下爬行动物行为监测提供了一个可扩展的解决方案，显著提高了研究效率和数据质量。未来的改进将集中在增强蟋蟀检测能力。

> **ai_Abstract:** 本文提出一个基于AI的自动化系统，利用YOLOv8s模型对鬃狮蜥的视频进行实时行为监测，识别晒太阳和捕食行为。该系统通过目标检测、时间插值和规则逻辑进行分类。尽管晒太阳行为检测可靠，但捕食行为检测因蟋蟀检测弱而准确性较低。该系统有望提高爬行动物行为研究的效率和数据质量。

> **摘要翻译:** 传统上对鬃狮蜥（Pogona Viticeps）行为的监测既耗时又容易出错。本项目引入了一个用于实时视频分析的自动化系统，该系统使用You Only Look Once (YOLO) 目标检测模型来识别两种关键行为：晒太阳和捕食。我们使用一个自定义的、公开可用的1200张图像数据集（包含600张鬃狮蜥、500张加热灯和100张蟋蟀）训练了五种YOLO变体（v5、v7、v8、v11、v12）。YOLOv8s因其在准确性（mAP@0.5:0.95 = 0.855）和速度之间的卓越平衡而被选为最佳模型。该系统通过提取每帧对象坐标、应用时间插值以确保连续性，并使用基于规则的逻辑来分类特定行为。晒太阳行为检测被证明是可靠的。然而，捕食行为检测的准确性较低，这主要是由于蟋蟀检测效果不佳（mAP@0.5 = 0.392）。未来的改进将侧重于通过扩展数据集或使用专门的小目标检测器来增强蟋蟀检测。这种自动化系统为在受控环境中监测爬行动物行为提供了一个可扩展的解决方案，显著提高了研究效率和数据质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [807] [Towards a Universal 3D Medical Multi-modality Generalization via Learning Personalized Invariant Representation](https://arxiv.org/abs/2411.06106)
> *通过学习个性化不变表示实现通用3D医学多模态泛化*

*Zhaorui Tan, Xi Yang, Tan Pan, Tianyi Liu, Chen Jiang, Xin Guo, Qiufeng Wang, Anh Nguyen, Yuan Qi, Kaizhu Huang, Yuan Cheng* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 医学图像, 多模态泛化, 个性化表示, 不变性学习, 跨模态

**Comment:** Accepted by ICCV25

> **TL;DR:** 该论文提出了一种两阶段方法，通过学习个性化不变表示来解决医学图像多模态泛化中的个体差异问题，显著提高了跨模态任务的泛化性和可迁移性。

**AI_Comments:** 该论文的创新点在于强调并利用了医学图像中个体生物学特征到不同模态映射的“不变性”，通过学习个性化不变表示来突破传统方法在跨模态泛化中遇到的个体差异瓶颈。这种两阶段的训练范式为未来的医学图像通用模型提供了新的思路，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 医学成像模态和个体解剖差异导致多模态任务中跨模态泛化面临挑战。现有方法通常只关注共同的解剖模式，忽略了个体差异，从而限制了其泛化性能。

**Method:** 提出了一种两阶段方法：首先，使用不变表示$\mathbb{X}_h$进行预训练以实现个性化；然后，对各种下游任务进行微调。

**Result:** 理论和实证证据表明个性化的可行性和优势，与缺乏个性化的方法相比，我们的方法在各种多模态医学任务中表现出更大的泛化性和可迁移性。广泛的实验进一步验证了我们的方法显著提高了各种泛化场景下的性能。

**Conclusion:** 通过学习个性化不变表示，可以有效增强医学多模态任务的泛化能力和可迁移性，解决个体差异带来的挑战。

> **ai_Abstract:** 本研究旨在解决医学图像多模态泛化中因模态差异和个体解剖差异导致的挑战。针对现有方法忽视个体差异的问题，论文提出了一种通过学习个性化不变表示（$\mathbb{X}_h$）来增强泛化能力的方法。该方法分为两阶段：首先进行个性化预训练，然后针对下游任务进行微调。理论和实验结果均表明，该方法能够显著提高在不同多模态医学任务中的泛化性和可迁移性。

> **摘要翻译:** 医学成像模态和个体解剖差异的变化给多模态任务中的跨模态泛化带来了挑战。现有方法通常只关注共同的解剖模式，从而忽略了个体差异，并因此限制了其泛化性能。本文强调了学习个体层面不变性，即个性化表示$\mathbb{X}_h$，在同质和异质设置下增强多模态泛化的关键作用。它揭示了个体生物学特征到不同医学模态的映射在人群中保持不变，这暗示在个性化过程中。我们提出了一种两阶段方法：使用不变表示$\mathbb{X}_h$进行预训练以实现个性化，然后对各种下游任务进行微调。我们提供了理论和经验证据，证明了个性化的可行性和优势，表明与缺乏个性化的方法相比，我们的方法在各种多模态医学任务中产生了更大的泛化性和可迁移性。广泛的实验进一步验证了我们的方法显著提高了各种泛化场景下的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [814] [Zero-Shot Skeleton-Based Action Recognition With Prototype-Guided Feature Alignment](https://arxiv.org/abs/2507.00566)
> *零样本骨骼行为识别与原型引导特征对齐*

*Kai Zhou, Shuhai Zhang, Zeng You, Jinwu Hu, Mingkui Tan, Fei Liu* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 零样本学习, 骨骼行为识别, 特征对齐, 原型引导, 对比学习

**Comment:** This paper is accepted by IEEE TIP 2025 (The journal version is
  available at https://doi.org/10.1109/TIP.2025.3586487). Code is publicly
  available at https://github.com/kaai520/PGFA

> **TL;DR:** 本文提出PGFA方法，通过端到端对比学习和原型引导对齐，显著提升了零样本骨骼行为识别的准确性，解决了特征判别不足和对齐偏差问题。

**AI_Comments:** 该论文创新性地将原型引导的思想引入零样本骨骼行为识别，并结合端到端对比学习，有效解决了现有方法中特征判别力不足和对齐偏差的难题。其提出的PGFA范式，通过理论分析和在多个数据集上的显著性能提升，证明了方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有零样本骨骼行为识别方法存在两个主要问题：1) 骨骼特征判别力不足，固定骨骼编码器无法捕获有效对齐信息；2) 测试时骨骼与未知文本特征之间的对齐偏差被忽视。

**Method:** 本文提出了一种名为PGFA的原型引导特征对齐范式。具体方法包括：1) 开发端到端跨模态对比训练框架，以改善骨骼-文本对齐，确保骨骼特征的充分判别力；2) 引入原型引导文本特征对齐策略，以减轻测试期间分布差异的不利影响。该策略得到了理论分析的支持。

**Result:** 与顶级竞争对手SMIE方法相比，PGFA在NTU-60、NTU-120和PKU-MMD数据集上分别实现了22.96%、12.53%和18.54%的绝对准确率提升。

**Conclusion:** 本文提出的PGFA方法通过解决骨骼特征判别不足和对齐偏差问题，显著提高了零样本骨骼行为识别的性能。

> **ai_Abstract:** 本文针对零样本骨骼行为识别任务中现有方法存在的骨骼特征判别不足和测试时对齐偏差问题，提出了一种名为PGFA的原型引导特征对齐范式。该方法通过构建端到端跨模态对比训练框架来增强骨骼-文本对齐，并引入原型引导文本特征对齐策略以缓解分布差异。实验结果表明，PGFA在多个知名数据集上显著优于现有SOTA方法。

> **摘要翻译:** 零样本骨骼行为识别旨在对训练期间未曾接触过的骨骼人体动作类别进行分类。由于难以从已知动作泛化到未知动作，这项任务极具挑战性。以往的研究通常采用两阶段训练：使用交叉熵损失在已知动作类别上预训练骨骼编码器，然后对预提取的骨骼和文本特征进行对齐，通过骨骼-文本对齐和语言模型的泛化能力将知识转移到未知类别。然而，它们的效率受到以下因素的阻碍：1) 骨骼特征判别力不足，因为固定的骨骼编码器无法捕获有效骨骼-文本对齐所需的必要对齐信息；2) 测试时骨骼与未知文本特征之间的对齐偏差被忽视。为此，我们提出了一种用于零样本骨骼行为识别的原型引导特征对齐范式，称之为PGFA。具体来说，我们开发了一个端到端跨模态对比训练框架，以改善骨骼-文本对齐，确保骨骼特征的充分判别力。此外，我们引入了一种原型引导文本特征对齐策略，以减轻测试期间分布差异的不利影响。我们提供了理论分析来支持我们的原型引导文本特征对齐策略，并在三个知名数据集上对我们的整体PGFA进行了实证评估。与顶级竞争对手SMIE方法相比，我们的PGFA在NTU-60、NTU-120和PKU-MMD数据集上分别实现了22.96%、12.53%和18.54%的绝对准确率提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [817] [Deformable Convolution Module with Globally Learned Relative Offsets for Fundus Vessel Segmentation](https://arxiv.org/abs/2507.18354)
> *具有全局学习相对偏移量的可变形卷积模块用于眼底血管分割*

*Lexuan Zhu, Yuxuan Li, Yuning Ren* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 可变形卷积, 眼底血管分割, 全局特征, GDCUnet, 注意力网络

**Comment:** 

> **TL;DR:** 本文提出了一种新型可变形卷积模块，通过注意力网络学习偏移量，实现特征图的全局形变，并将其应用于眼底血管分割，GDCUnet模型在公共数据集上取得了最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了一个新型的可变形卷积模块，它通过学习亚像素位移场和跨通道扭曲特征图来实现全局特征形变，并解耦了核大小与学习网络。这使得模型能更好地捕捉长距离依赖和复杂形状特征，特别适用于像眼底血管这样具有全局自相似复杂边缘的图像分割任务。其即插即用的特性也增加了模块的通用性。

<details>
  <summary>Details</summary>

**Motivation:** 可变形卷积能自适应处理复杂形状特征，但现有方法可能存在局限。本文旨在提出一种能捕获长距离全局特征的新型可变形卷积模块，并解决眼底血管分割中复杂全局自相似边缘的识别问题。

**Method:** 提出了一种即插即用的可变形卷积模块，该模块利用注意力和前馈网络学习偏移量，使可变形模式能够捕获长距离全局特征。与现有可变形卷积不同，该模块学习亚像素位移场并自适应地扭曲所有通道的特征图，而不是直接形变卷积核，这等效于核采样网格的相对形变，实现了全局特征形变以及核大小与学习网络的解耦。基于此模块，设计了用于眼底血管分割的深度学习模型GDCUnet。

**Result:** 在相同配置和统一框架下的实证评估表明，GDCUnet在公共数据集上取得了最先进的性能。进一步的消融实验证明，所提出的可变形卷积模块能更显著地学习眼底血管的复杂特征，增强了模型的表示和泛化能力。

**Conclusion:** 所提出的可变形卷积模块与传统卷积接口相似，建议将其应用于更多具有复杂全局自相似特征的机器视觉任务。

> **ai_Abstract:** 本文提出了一种新型即插即用的可变形卷积模块，通过注意力机制和前馈网络学习亚像素位移场，实现特征图的全局形变和核大小与学习网络的解耦。该模块能够捕获长距离全局特征，并被应用于眼底血管分割任务，构建了GDCUnet模型。实验结果表明，GDCUnet在公共数据集上达到了最先进的性能，且所提模块显著增强了模型对复杂特征的学习能力、表示和泛化能力。作者建议将其推广到其他具有复杂全局自相似特征的机器视觉任务中。

> **摘要翻译:** 可变形卷积通过学习偏移量来自适应地改变卷积核的形状，以处理复杂的形状特征。我们提出了一种新型的即插即用的可变形卷积模块，该模块利用注意力和前馈网络来学习偏移量，从而使可变形模式能够捕获长距离的全局特征。与现有可变形卷积相比，所提出的模块学习亚像素位移场并自适应地扭曲所有通道的特征图，而不是直接形变卷积核，这等效于核采样网格的相对形变，实现了全局特征形变以及核大小与学习网络的解耦。考虑到眼底血管具有全局自相似的复杂边缘，我们基于所提出的卷积模块设计了用于眼底血管分割的深度学习模型GDCUnet。在相同配置和统一框架下的实证评估表明，GDCUnet在公共数据集上取得了最先进的性能。进一步的消融实验证明，所提出的可变形卷积模块能更显著地学习眼底血管的复杂特征，增强了模型的表示和泛化能力。所提出的模块与传统卷积的接口相似，我们建议将其应用于更多具有复杂全局自相似特征的机器视觉任务。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [818] [IntentVCNet: Bridging Spatio-Temporal Gaps for Intention-Oriented Controllable Video Captioning](https://arxiv.org/abs/2507.18531)
> *IntentVCNet：弥合时空鸿沟以实现意图导向的可控视频字幕生成*

*Tianheng Qiu, Jingchun Gao, Jingyu Li, Huiyi Leong, Xuan Huang, Xi Wang, Xiaocheng Zhang, Kele Xu, Lan Zhang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 可控视频字幕生成, 意图导向, 时空鸿沟, 大型视觉语言模型, 盒子适配器

**Comment:** 

> **TL;DR:** 提出IntentVCNet，通过结合提示策略和盒子适配器，弥合大型视觉语言模型在意图导向的可控视频字幕生成中的时空鸿沟，实现更精细的控制。

**AI_Comments:** 该论文创新性地从提示和模型两个层面解决了大型视觉语言模型在可控视频字幕生成中面临的时空一致性难题。通过引入特定的提示策略和盒子适配器，有效提升了模型对用户意图和视频空间细节的理解与融合能力，对于推动意图导向的视觉语言任务发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型视觉语言模型（LVLMs）在处理意图导向的可控视频字幕生成时，难以在时间序列中进行细粒度的空间控制，存在显著的时空鸿沟，阻碍了实现精细的意图导向控制。

**Method:** 提出了IntentVCNet，从提示和模型两个角度统一LVLMs中的时空理解知识以弥合时空鸿沟。具体包括：1) 一种提示组合策略，使LLM能够建模用户意图提示和视频序列之间的隐含关系；2) 一个参数高效的盒子适配器，增强全局视觉上下文中的对象语义信息，使视觉token具有用户意图的先验信息。

**Result:** 实验证明，这两种策略的结合能进一步增强LVLM在视频序列中建模空间细节的能力，并促进LVLMs准确生成受控的意图导向字幕。该方法在多个开源LVLMs上取得了最先进的结果，并在IntentVC挑战中获得亚军。

**Conclusion:** 通过提出IntentVCNet及其包含的提示组合策略和盒子适配器，成功弥合了大型视觉语言模型在意图导向的可控视频字幕生成中的时空鸿沟，实现了更精细的控制和更准确的字幕生成。

> **ai_Abstract:** 本文提出了IntentVCNet，旨在解决大型视觉语言模型在意图导向的可控视频字幕生成中存在的时空鸿沟问题。通过引入提示组合策略和参数高效的盒子适配器，该网络能够统一LVLMs的时空理解能力，增强其对视频序列中空间细节的建模，从而实现更准确、更精细的意图导向字幕生成。实验证明其在多项任务中达到SOTA并获得挑战赛亚军。

> **摘要翻译:** 意图导向的可控视频字幕生成旨在根据定制的用户意图，为视频中的特定目标生成有针对性的描述。当前大型视觉语言模型（LVLMs）已获得强大的指令遵循和视觉理解能力。尽管LVLMs分别在空间和时间理解方面表现出熟练度，但它们无法直接响应指令在时间序列中执行细粒度的空间控制。这种显著的时空鸿沟使在视频中实现细粒度意图导向控制的努力变得复杂。为此，我们提出了一种新颖的IntentVCNet，它统一了LVLMs中固有的时间与空间理解知识，从提示和模型两个角度弥合时空鸿沟。具体来说，我们首先提出了一种提示组合策略，旨在使LLM能够建模表征用户意图的提示与视频序列之间的隐含关系。然后，我们提出了一种参数高效的盒子适配器，它增强了全局视觉上下文中的对象语义信息，从而使视觉token具有用户意图的先验信息。最终实验证明，这两种策略的结合可以进一步增强LVLM建模视频序列中空间细节的能力，并促进LVLM准确生成受控的意图导向字幕。我们提出的方法在几个开源LVLMs中取得了最先进的结果，并在IntentVC挑战中获得亚军。我们的代码可在https://github.com/thqiu0419/IntentVCNet 上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [819] [PLOT-TAL: Prompt Learning with Optimal Transport for Few-Shot Temporal Action Localization](https://arxiv.org/abs/2403.18915)
> *PLOT-TAL：基于最优传输的少样本时间动作定位提示学习*

*Edward Fish, Andrew Gilbert* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 少样本学习, 时间动作定位, 提示学习, 最优传输, 多提示集成

**Comment:** Accepted to ICCVWS

> **TL;DR:** 本文提出了PLOT-TAL框架，通过多提示集成和最优传输解决了少样本时间动作定位中边界不精确的问题，并在多个基准测试中取得了最先进的性能。

**AI_Comments:** 本文的创新点在于结合了提示学习和最优传输来解决少样本时间动作定位的挑战。通过多提示集成鼓励对动作子事件的专业化学习，并利用最优传输进行全局对齐，有效提升了时间边界的精确性。其无需复杂元学习的特点也增加了方法的实用性和可推广性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的少样本时间动作定位（TAL）方法通过单提示微调大型模型，往往无法产生精确的时间边界。这是因为模型从稀疏数据中学习到的动作表示缺乏判别性，从而损害了泛化能力。

**Method:** 本文提出了一种基于多提示集成的新范式，为每个动作鼓励学习一组多样化的、可学习的提示，使其专注于组合子事件。为了强制这种专业化，引入了PLOT-TAL框架，该框架利用最优传输（OT）在提示集成和视频的时间特征之间找到全局最优对齐。

**Result:** 本文方法在THUMOS'14和EPIC-Kitchens等具有挑战性的少样本基准测试中，无需复杂的元学习，建立了新的最先进（SOTA）性能。尤其在较高的IoU阈值下，性能提升显著。

**Conclusion:** 显著的性能提升，特别是在高IoU阈值下，验证了本研究的假设，并证明了学习分布式、组合表示对于精确时间定位的优越性。

> **ai_Abstract:** 本文针对少样本时间动作定位中现有方法边界不精确的问题，提出了PLOT-TAL框架。该框架引入了多提示集成的新范式，为每个动作学习一组多样化的可学习提示，并利用最优传输（OT）在提示集成与视频时间特征之间实现全局最优对齐。这种方法旨在学习分布式、组合式的动作表示，从而提升精确度。实验结果表明，PLOT-TAL在THUMOS'14和EPIC-Kitchens等基准测试中取得了新的最先进性能，尤其在高IoU阈值下表现出色。

> **摘要翻译:** **标题：** PLOT-TAL：基于最优传输的少样本时间动作定位提示学习

**摘要：** 少样本时间动作定位（TAL）方法通过单提示微调大型模型，往往无法产生精确的时间边界。这源于模型从稀疏数据中学习到的非判别性平均动作表示，损害了泛化能力。我们通过提出一种基于多提示集成的新范式来解决这个问题，其中鼓励为每个动作学习一组多样化的、可学习的提示，使其专注于组合子事件。为了强制这种专业化，我们引入了PLOT-TAL，这是一个利用最优传输（OT）在提示集成和视频时间特征之间找到全局最优对齐的框架。我们的方法在THUMOS'14和EPIC-Kitchens等具有挑战性的少样本基准测试中建立了新的最先进水平，而无需复杂的元学习。显著的性能提升，特别是在高IoU阈值下，验证了我们的假设并证明了学习分布式、组合表示对于精确时间定位的优越性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [826] [Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models](https://arxiv.org/abs/2507.11554)
> *Inversion-DPO：扩散模型的精确高效后训练*

*Zejian Li, Yize Li, Chenye Meng, Zhongni Liu, Yang Ling, Shengyuan Zhang, Guang Yang, Changyuan Yang, Zhiyuan Yang, Lingyun Sun* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** Inversion-DPO, 扩散模型, 后训练, DDIM反演, 直接偏好优化

**Comment:** Accepted by ACM MM25

> **TL;DR:** Inversion-DPO是一种新的扩散模型对齐框架，通过结合DDIM反演和DPO，避免了奖励模型，显著提高了训练的精度和效率，并在文本到图像和组合图像生成任务中表现出色。

**AI_Comments:** Inversion-DPO的创新点在于其规避奖励模型的策略，通过DDIM反演重构DPO，解决了现有对齐方法计算开销大和可能损害精度的痛点。这种方法显著提高了训练的效率和精度，使其在处理复杂生成任务时更具实用性。其在组合图像生成任务上的表现，特别是通过构建高质量数据集来增强模型能力，显示了其解决实际挑战的潜力。该研究为扩散模型的后训练提供了一个高效且高质量的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有的扩散模型对齐方法通常需要计算密集型的基础模型和奖励模型训练，这不仅计算开销大，还可能损害模型精度和训练效率。

**Method:** 我们提出了Inversion-DPO，一个通过将直接偏好优化（DPO）与DDIM反演结合，为扩散模型重构DPO，从而规避奖励模型的对齐框架。该方法利用获胜和失败样本到噪声的确定性反演来执行扩散DPO中难以处理的后验采样，从而形成一种新的后训练范式，消除了对辅助奖励模型或不准确近似的需求。论文还为此任务策划了一个包含11,140张图像的配对数据集。

**Result:** Inversion-DPO在文本到图像生成和组合图像生成任务中取得了显著的性能提升，与现有后训练方法相比表现出优势，并突出了训练后的生成模型生成高保真、组合连贯图像的能力。

**Conclusion:** Inversion-DPO为扩散模型中高效、高精度的对齐探索了一条新途径，提升了它们在复杂现实生成任务中的适用性。

> **ai_Abstract:** Inversion-DPO提出了一种创新的扩散模型后训练对齐框架，通过将直接偏好优化（DPO）与DDIM反演结合，避免了传统方法中对计算密集型奖励模型的依赖。该方法通过确定性反演实现精确高效的训练，显著提升了文本到图像和组合图像生成任务的性能，并证明了其生成高保真、组合连贯图像的能力，为扩散模型在复杂生成任务中的应用开辟了新路径。

> **摘要翻译:** 扩散模型（DMs）的最新进展得益于对齐方法，这些方法通过后训练模型使其更好地符合人类偏好。然而，这些方法通常需要计算密集型的基础模型和奖励模型训练，这不仅带来了巨大的计算开销，还可能损害模型精度和训练效率。为了解决这些限制，我们提出了Inversion-DPO，这是一种新颖的对齐框架，它通过将直接偏好优化（DPO）与DDIM反演结合，为扩散模型重构DPO，从而规避了奖励建模。我们的方法利用获胜和失败样本到噪声的确定性反演，在Diffusion-DPO中进行难以处理的后验采样，从而推导出一个新的后训练范式。这种范式消除了对辅助奖励模型或不准确近似的需求，显著提高了训练的精度和效率。我们将Inversion-DPO应用于文本到图像生成这一基础任务和组合图像生成这一挑战性任务。大量实验表明，与现有后训练方法相比，Inversion-DPO取得了显著的性能改进，并突出了训练后的生成模型生成高保真、组合连贯图像的能力。为了进行组合图像生成的后训练，我们策划了一个包含11,140张图像的配对数据集，这些图像具有复杂的结构注释和全面的分数，旨在增强生成模型的组合能力。Inversion-DPO为扩散模型中高效、高精度的对齐探索了一条新途径，提升了它们在复杂现实生成任务中的适用性。我们的代码可在https://github.com/MIGHTYEZ/Inversion-DPO获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [837] [Rectifying Magnitude Neglect in Linear Attention](https://arxiv.org/abs/2507.00698)
> *纠正线性注意力中的幅度忽略*

*Qihang Fan, Huaibo Huang, Yuang Ai, ran He* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 线性注意力, 幅度忽略, MALA, Transformer, 注意力机制

**Comment:** Accepted by ICCV2025, highlight paper

> **TL;DR:** 线性注意力虽然效率高但性能不佳，原因在于其忽略了Query的幅度信息。本文提出了幅度感知线性注意力（MALA），通过整合Query幅度来解决此问题，使其在多种任务上表现出色，并能生成更接近Softmax注意力的注意力分数分布。

**AI_Comments:** 本文针对线性注意力在实际应用中性能受限的核心问题进行了深入剖析，并提出了新颖的解决方案。其创新点在于精确识别了“Query幅度忽略”这一关键因素，并设计了Magnitude-Aware Linear Attention (MALA)来有效弥补这一缺陷。通过简单的修改，MALA不仅提升了线性注意力的性能，还使其注意力分布更接近Softmax，这对于在保持计算效率的同时提升模型表现具有重要意义。该研究对于推动高效Transformer模型的发展具有积极作用。

<details>
  <summary>Details</summary>

**Motivation:** Softmax注意力虽然全局建模能力强，但其二次复杂度限制了其在视觉任务中的应用。线性注意力虽然复杂度为线性，但相比Softmax注意力存在显著的性能下降。本文旨在分析并解决线性注意力性能下降的根本原因。

**Method:** 本文分析了线性注意力的公式，发现其完全忽略了Query的幅度信息，导致注意力分数分布无法动态适应Query的尺度变化。基于此，提出了幅度感知线性注意力（MALA），通过修改线性注意力的计算方式，充分整合Query的幅度信息，使其能生成更接近Softmax注意力且结构更均衡的注意力分数分布。

**Result:** MALA在多种任务上进行了评估，包括图像分类、目标检测、实例分割、语义分割、自然语言处理、语音识别和图像生成。MALA在所有这些任务上都取得了强劲的结果。

**Conclusion:** 本文发现线性注意力性能下降的根本原因是其忽略了Query的幅度信息。通过提出的幅度感知线性注意力（MALA），成功解决了这一问题，使得线性注意力能够在保持线性复杂度的同时，在多模态任务上实现与Softmax注意力相媲美甚至更好的性能。

> **ai_Abstract:** 本文针对线性注意力相较于Softmax注意力性能显著下降的问题进行了深入分析。研究发现，线性注意力在计算过程中完全忽略了Query的幅度信息，导致其注意力分数分布无法动态调整，并与Softmax注意力产生差异。为解决此问题，论文提出了一种新的方法——幅度感知线性注意力（MALA）。MALA通过修改线性注意力的计算方式，有效整合了Query的幅度信息，使其能够生成更接近Softmax注意力且结构更均衡的注意力分数分布。实验结果表明，MALA在图像分类、目标检测、实例分割、语义分割、自然语言处理、语音识别和图像生成等多种任务上均取得了优异的表现。

> **摘要翻译:** 作为Transformer的核心操作，Softmax注意力展现出卓越的全局建模能力。然而，其二次复杂度限制了它在视觉任务中的应用。相比之下，线性注意力与Softmax注意力形式相似，同时实现了线性复杂度，从而能够高效地进行全局信息建模。尽管如此，与标准Softmax注意力相比，线性注意力存在显著的性能下降。在本文中，我们基于线性注意力的公式，分析了导致此问题的根本原因。我们发现，与Softmax注意力不同，线性注意力完全忽略了Query的幅度信息。这导致注意力分数分布无法随着Query的缩放而动态调整。因此，尽管其结构与Softmax注意力相似，线性注意力却展现出截然不同的注意力分数分布。基于这一观察，我们提出了幅度感知线性注意力（MALA），它修改了线性注意力的计算方式，以充分整合Query的幅度。这一调整使得MALA能够生成一个与Softmax注意力非常相似且结构更均衡的注意力分数分布。我们在多项任务上评估了MALA的有效性，包括图像分类、目标检测、实例分割、语义分割、自然语言处理、语音识别和图像生成。我们的MALA在所有这些任务上都取得了强劲的结果。代码将发布在 https://github.com/qhfan/MALA

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [840] [Degradation-Consistent Learning via Bidirectional Diffusion for Low-Light Image Enhancement](https://arxiv.org/abs/2507.18144)
> *基于双向扩散的退化一致性学习用于低光图像增强*

*Jinhong He, Minglong Xue, Zhipu Liu, Mingliang Zhou, Aoxiang Ning, Palaiahnakote Shivakumara* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-24**

**Keywords:** 低光图像增强, 双向扩散, 退化一致性学习, 图像恢复

**Comment:** 10page

> **TL;DR:** 本文提出了一种名为双向扩散优化机制（BidDiff）的新型扩散模型，通过同时建模低光和正常光图像的退化过程，解决了现有单向扩散模型在低光图像增强中存在的结构不一致和像素错位问题，实现了卓越的增强效果并超越了现有技术水平。

**AI_Comments:** 该论文创新性地将双向扩散引入低光图像增强领域，解决了传统单向扩散模型难以捕捉复杂退化模式的问题。通过引入自适应特征交互块和反射感知校正模块，进一步提升了模型的性能和图像质量。其对光照衰减和噪声分布施加的隐式对称约束，是实现退化一致性学习的关键。该方法的提出对于提升低光图像处理的鲁棒性和视觉效果具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 低光图像增强旨在提高退化图像的可见性以更好地符合人类视觉感知。尽管基于扩散的方法因其强大的生成能力而表现出良好的性能，但其单向的退化建模往往难以捕捉真实世界退化模式的复杂性，导致结构不一致和像素错位。

**Method:** 我们提出了一种双向扩散优化机制，联合建模低光和正常光图像的退化过程，以实现更精确的退化参数匹配和增强生成质量。具体而言，我们在训练期间执行从低光到正常光以及从正常光到低光的双向扩散，并引入自适应特征交互块（AFI）来细化特征表示。此外，我们设计了一个反射感知校正模块（RACM）来指导去噪后的色彩恢复并抑制过曝区域。

**Result:** 在多个基准数据集上的大量实验表明，我们的方法在定量和定性评估中均优于现有最先进的方法，同时有效泛化到各种退化场景。

**Conclusion:** 本文提出的基于双向扩散的低光图像增强方法，通过双向建模退化过程并结合自适应特征交互块和反射感知校正模块，有效解决了现有方法的局限性，实现了结构一致性和高质量的图像增强，并在多样化的退化场景中展现出优异的性能和泛化能力。

> **ai_Abstract:** 本文提出了一种名为双向扩散优化机制（BidDiff）的新型低光图像增强方法，旨在解决现有扩散模型在处理复杂真实世界退化模式时出现的结构不一致和像素错位问题。BidDiff通过联合建模低光和正常光图像的双向退化过程，实现更精确的参数匹配和更高质量的图像生成。该方法引入了自适应特征交互块（AFI）来细化特征表示，并设计了反射感知校正模块（RACM）以指导色彩恢复并抑制过曝区域。实验证明，BidDiff在多个基准数据集上超越了现有最先进的方法，并具有出色的泛化能力。

> **摘要翻译:** 低光图像增强旨在提高退化图像的可见性，以更好地符合人类视觉感知。尽管基于扩散的方法因其强大的生成能力而表现出良好的性能。然而，它们的单向退化建模往往难以捕捉真实世界退化模式的复杂性，导致结构不一致和像素错位。为了解决这些挑战，我们提出了一种双向扩散优化机制，该机制联合建模低光和正常光图像的退化过程，从而实现更精确的退化参数匹配并提高生成质量。具体而言，我们在训练期间执行从低光到正常光以及从正常光到低光的双向扩散，并引入自适应特征交互块（AFI）来细化特征表示。通过利用这两个路径之间的互补性，我们的方法对光照衰减和噪声分布施加了隐式对称约束，促进了退化一致性学习并提高了模型感知光照和细节退化的能力。此外，我们设计了一个反射感知校正模块（RACM）来指导去噪后的色彩恢复并抑制过曝区域，确保内容一致性并生成符合人类视觉感知的高质量图像。在多个基准数据集上的大量实验表明，我们的方法在定量和定性评估中均优于现有最先进的方法，同时有效泛化到各种退化场景。代码位于 https://github.com/hejh8/BidDiff

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [846] [AG-VPReID.VIR: Bridging Aerial and Ground Platforms for Video-based Visible-Infrared Person Re-ID](https://arxiv.org/abs/2507.17995)
> *AG-VPReID.VIR：弥合空地平台，实现基于视频的可见光-红外行人重识别*

*Huy Nguyen, Kien Nguyen, Akila Pemasiri, Akmal Jahan, Clinton Fookes, Sridha Sridharan* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 行人重识别, 空地平台, 视频重识别, 可见光-红外, 跨模态

**Comment:** Accepted atIEEE International Joint Conference on Biometrics (IJCB)
  2025

> **TL;DR:** 引入首个空地跨模态视频行人重识别数据集AG-VPReID.VIR，并提出三流架构TCC-VPReID解决空地和跨模态重识别挑战，显著提升性能。

**AI_Comments:** 这篇论文的创新点在于首次构建了一个大规模的空地跨模态视频行人重识别数据集AG-VPReID.VIR，填补了现有数据集的空白，特别是在结合空中视角以解决地面监控局限性方面具有重要意义。同时，提出的TCC-VPReID三流架构也针对性地解决了跨平台和跨模态的复杂挑战，其多策略融合（风格鲁棒特征学习、记忆库跨视角适应、中间引导时间建模）提升了方法的鲁棒性和有效性。该工作对于推动全天候、多视角行人重识别技术的发展具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可见光与红外跨模态行人重识别数据集主要集中于地面视角，但地面红外系统存在遮挡、覆盖范围有限和易受阻碍等问题。空中视角能有效解决这些局限性，因此需要结合空地平台的数据集和方法来提升24小时监控系统的能力。

**Method:** 1. 引入AG-VPReID.VIR，首个空地跨模态视频行人重识别数据集，包含1,837个身份、4,861个轨迹（124,855帧），通过无人机和固定CCTV相机采集RGB和红外模态数据。该数据集提出了跨视角、模态差异和时间动态等独特挑战。2. 提出TCC-VPReID，一种新颖的三流架构，旨在解决跨平台和跨模态行人重识别的联合挑战。该方法通过风格鲁棒特征学习、基于记忆的跨视角适应和中间引导的时间建模来弥合空地视角和RGB-IR模态之间的域差距。

**Result:** 实验表明，与现有数据集相比，AG-VPReID.VIR数据集带来了独特的挑战。所提出的TCC-VPReID框架在多个评估协议下取得了显著的性能提升。

**Conclusion:** 本文成功构建了首个空地跨模态视频行人重识别数据集AG-VPReID.VIR，并提出了有效的TCC-VPReID三流架构来应对其特有的挑战，从而显著提升了在复杂空地和跨模态环境下的行人重识别性能，为24小时监控系统提供了关键技术支持。

> **ai_Abstract:** 本文针对现有可见光-红外行人重识别数据集缺乏空地跨模态视角的问题，首次提出了AG-VPReID.VIR数据集。该数据集整合了无人机和地面CCTV采集的RGB和红外视频数据，旨在模拟真实的24小时监控场景并引入跨视角、模态差异和时间动态等独特挑战。为有效应对这些挑战，研究者还设计了TCC-VPReID三流深度学习架构，通过多策略融合来弥合空地平台与跨模态之间的域鸿沟。实验证明，AG-VPReID.VIR数据集具有显著挑战性，而TCC-VPReID方法在其中展现了优越的性能，为未来空地融合的行人重识别研究奠定了基础。

> **摘要翻译:** 行人重识别（Re-ID）跨可见光和红外模态对于24小时监控系统至关重要，但现有数据集主要关注地面视角。虽然地面红外系统提供夜间能力，但它们存在遮挡、覆盖范围有限和易受阻碍的问题——这些问题是空中视角独特解决的。为了解决这些局限性，我们引入了AG-VPReID.VIR，这是第一个空地跨模态视频行人重识别数据集。该数据集使用无人机和固定CCTV相机在RGB和红外模态下捕捉了1,837个身份，共4,861个轨迹（124,855帧）。AG-VPReID.VIR提出了独特的挑战，包括跨视角变化、模态差异和时间动态。此外，我们提出了TCC-VPReID，一种新颖的三流架构，旨在解决跨平台和跨模态行人重识别的联合挑战。我们的方法通过风格鲁棒特征学习、基于记忆的跨视角适应和中间引导的时间建模，弥合了空地视角和RGB-IR模态之间的域差距。实验表明，与现有数据集相比，AG-VPReID.VIR提出了独特的挑战，我们的TCC-VPReID框架在多个评估协议下取得了显著的性能提升。数据集和代码可在https://github.com/agvpreid25/AG-VPReID.VIR获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [848] [Revisiting Physically Realizable Adversarial Object Attack against LiDAR-based Detection: Clarifying Problem Formulation and Experimental Protocols](https://arxiv.org/abs/2507.18457)
> *重新审视针对基于激光雷达检测的物理可实现对抗性物体攻击：澄清问题表述和实验协议*

*Luo Cheng, Hanwei Zhang, Lijun Zhang, Holger Hermanns* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 激光雷达, 对抗性攻击, 3D物体检测, 物理攻击, 鲁棒性

**Comment:** 

> **TL;DR:** 该论文提出了一个标准化框架，旨在提高针对激光雷达检测的物理可实现对抗性攻击的重现性和研究效率，并通过将模拟攻击成功转移到真实系统进行了验证。

**AI_Comments:** 这篇论文通过提出一个针对激光雷达系统的物理对抗性物体攻击的标准化框架，展现了创新性，直接解决了重现性和实际可实现性的关键问题。其对设备无关方法和开源贡献的关注，对于促进一致性研究和加速在该领域（具有重要的现实世界安全影响）的进步具有重要价值。通过将模拟攻击转移到物理系统进行验证是一个强有力的亮点。

<details>
  <summary>Details</summary>

**Motivation:** 针对基于激光雷达的3D物体检测的物理对抗性物体攻击至关重要但探索不足，并且由于设置不一致和硬件差异而导致重现性差，限制了其实际影响。现有的数字攻击缺乏物理可实现性。

**Method:** 作者提出了一个与设备无关的标准化框架，该框架抽象了物理对抗性物体攻击的关键要素，支持多种方法，并提供在模拟和现实世界环境中的基准测试协议的开源代码。

**Result:** 该框架实现了公平比较，加速了研究，并通过成功将模拟攻击转移到物理激光雷达系统进行了验证。此外，论文还深入探讨了影响攻击成功的因素。

**Conclusion:** 所提出的标准化框架提高了针对激光雷达检测的物理对抗性物体攻击的重现性和可比性，从而增进了对现实世界激光雷达感知中对抗鲁棒性的理解。

> **ai_Abstract:** 本文针对基于激光雷达的3D物体检测中物理对抗性物体攻击的挑战，特别是数字攻击缺乏物理可实现性和物理攻击重现性差的问题。论文提出了一个与设备无关的标准化框架，该框架包含开源代码和模拟及现实世界环境中的基准测试协议。此框架旨在促进公平比较和加速研究，并通过成功将模拟攻击转移到真实激光雷达系统来验证其有效性。该工作还提供了关于影响攻击成功因素的见解，从而增强了对现实世界激光雷达鲁棒性的理解。

> **摘要翻译:** 基于激光雷达的3D物体检测中的对抗鲁棒性是一个关键的研究领域，因为它在现实世界场景中有着广泛的应用。虽然许多数字攻击操纵点云或网格，但它们通常缺乏物理可实现性，限制了其实际影响。物理对抗性物体攻击仍未得到充分探索，并且由于设置不一致和硬件差异而导致重现性差。为了解决这个问题，我们提出了一个与设备无关的标准化框架，该框架抽象了物理对抗性物体攻击的关键要素，支持多种方法，并提供在模拟和现实世界环境中的基准测试协议的开源代码。我们的框架实现了公平比较，加速了研究，并通过成功将模拟攻击转移到物理激光雷达系统进行了验证。除了该框架之外，我们还深入探讨了影响攻击成功的因素，并增进了对现实世界激光雷达感知中对抗鲁棒性的理解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [856] [COT-AD: Cotton Analysis Dataset](https://arxiv.org/abs/2507.18532)
> *COT-AD：棉花分析数据集*

*Akbar Ali, Mahek Vyas, Soumyaratna Debnath, Chanda Grover Kamra, Jaidev Sanjay Khalane, Reuben Shibu Devanesan, Indra Deep Mastan, Subramanian Sankaranarayanan, Pankaj Khanna, Shanmuganathan Raman* | **Category: cs.CV, I.4.9; I.5.4; H.2.8** | **Updated: 2025-07-24**

**Keywords:** 棉花分析, 数据集, 计算机视觉, 农业, 病虫害识别

**Comment:** Dataset publicly available at:
  https://ieee-dataport.org/documents/cot-adcotton-analysis-dataset. Accepted
  to IEEE International Conference on Image Processing (ICIP) 2025

> **TL;DR:** COT-AD是一个综合性的棉花作物分析数据集，包含25,000多张图像，其中5,000张已标注，旨在通过计算机视觉技术增强棉花分析，并支持多种农业任务。

**AI_Comments:** COT-AD的创新之处在于其对棉花作物分析的全面性和专用性，有效填补了现有棉花农业数据集的关键空白。通过整合多源图像（航拍和单反）并提供详细标注，该数据集为棉花病虫害检测、植被健康监测等关键农业应用提供了宝贵的资源，有望显著加速精准农业和智能农业领域的研究与发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的棉花专用农业数据集存在关键空白，限制了通过计算机视觉技术进行棉花作物分析的能力。COT-AD旨在填补这一空白，以增强棉花作物分析。

**Method:** COT-AD包含在棉花生长周期中捕获的超过25,000张图像，其中5,000张已进行标注。数据集结合了用于田间尺度检测和分割的航拍图像，以及记录关键疾病的高分辨率单反相机图像。标注内容涵盖病虫害识别、植被和杂草分析。

**Result:** COT-AD数据集支持多种计算机视觉任务，包括分类、分割、图像恢复、图像增强、基于深度生成模型的棉花作物合成以及早期疾病管理。该数据集有助于推进数据驱动的作物管理。

**Conclusion:** COT-AD通过提供一个全面的、标注丰富的棉花分析数据集，成功填补了棉花专用农业数据集的关键空白，并为数据驱动的作物管理和计算机视觉在农业领域的应用提供了重要支持。

> **ai_Abstract:** COT-AD是一个为棉花作物分析而设计的综合性计算机视觉数据集。它包含超过25,000张在棉花生长周期中捕获的图像，其中5,000张已详细标注，涵盖了病虫害识别、植被和杂草分析。该数据集通过提供航拍图像和高分辨率单反图像，弥补了现有棉花专用农业数据集的不足。COT-AD支持分类、分割、图像恢复与增强、棉花作物合成以及早期疾病管理等多种计算机视觉任务，旨在推动数据驱动的精准农业管理。

> **摘要翻译:** 本文介绍了COT-AD，这是一个旨在通过计算机视觉增强棉花作物分析的综合数据集。它包含在棉花生长周期中捕获的25,000多张图像，其中5,000张已标注。COT-AD包括用于田间尺度检测和分割的航拍图像，以及记录关键疾病的高分辨率单反相机图像。标注内容涵盖病虫害识别、植被和杂草分析，填补了棉花专用农业数据集的关键空白。COT-AD支持分类、分割、图像恢复、增强、基于深度生成模型的棉花作物合成以及早期疾病管理等任务，从而推动数据驱动的作物管理。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [860] [PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving](https://arxiv.org/abs/2507.17596)
> *PRIX：从原始像素学习规划实现端到端自动驾驶*

*Maciej K. Wozniak, Lianhang Liu, Yixi Cai, Patric Jensfelt* | **Category: cs.CV, cs.AI, cs.LG, cs.RO** | **Updated: 2025-07-24**

**Keywords:** 自动驾驶, 端到端, 原始像素, 摄像头, PRIX

**Comment:** under review

> **TL;DR:** PRIX是一种高效的端到端自动驾驶模型，仅使用摄像头数据，无需激光雷达或BEV表示，即可从原始像素预测安全轨迹，并在基准测试中达到SOTA性能，同时更高效。

**AI_Comments:** PRIX的创新之处在于其端到端仅依赖摄像头数据的设计，避免了对昂贵激光雷达和计算密集型BEV表示的依赖，这对于大规模部署和成本敏感的自动驾驶应用具有重要意义。CaRT模块的引入也提升了视觉特征处理的鲁棒性。其在SOTA性能的同时实现高效率，预示着它在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的端到端自动驾驶模型存在模型尺寸大、依赖昂贵的激光雷达传感器和计算密集型BEV特征表示等问题，限制了其可扩展性，尤其是在仅配备摄像头的量产车辆上。

**Method:** 本文提出了PRIX（Plan from Raw Pixels），这是一种新颖且高效的端到端驾驶架构，仅使用摄像头数据进行操作，无需明确的BEV表示，也无需激光雷达。PRIX利用视觉特征提取器与生成式规划头相结合，直接从原始像素输入预测安全轨迹。其核心组件是Context-aware Recalibration Transformer (CaRT)，旨在有效增强多级视觉特征以实现更稳健的规划。

**Result:** PRIX在NavSim和nuScenes基准测试中实现了最先进的性能，与更大、多模态的扩散规划器能力相当，但在推理速度和模型尺寸方面显著更高效。

**Conclusion:** PRIX为端到端自动驾驶提供了一个实用且可扩展的解决方案，特别适用于仅配备摄像头的车辆，因为它克服了现有模型在效率和传感器依赖方面的局限性。

> **ai_Abstract:** PRIX是一种针对端到端自动驾驶的新型高效模型，旨在解决现有方法模型大、依赖激光雷达和复杂BEV表示的问题。它仅使用原始摄像头像素输入，通过视觉特征提取器和生成式规划头直接预测安全轨迹，并引入了Context-aware Recalibration Transformer (CaRT) 来增强视觉特征。实验证明，PRIX在性能上达到SOTA，并显著提高了推理速度和模型效率，使其成为量产车辆的实用解决方案。

> **摘要翻译:** 虽然端到端自动驾驶模型显示出有希望的结果，但其实际部署常因模型尺寸大、依赖昂贵的激光雷达传感器和计算密集型BEV特征表示而受阻。这限制了它们的可扩展性，特别是对于仅配备摄像头的量产车辆。为了应对这些挑战，我们提出了PRIX（Plan from Raw Pixels）。我们新颖高效的端到端驾驶架构仅使用摄像头数据运行，无需显式的BEV表示，也无需激光雷达。PRIX利用视觉特征提取器与生成式规划头相结合，直接从原始像素输入预测安全轨迹。我们架构的核心组件是上下文感知重校准变换器（CaRT），这是一个旨在有效增强多级视觉特征以实现更稳健规划的新颖模块。我们通过全面的实验证明，PRIX在NavSim和nuScenes基准测试中实现了最先进的性能，与更大、多模态的扩散规划器能力相当，同时在推理速度和模型尺寸方面显著更高效，使其成为实际部署的实用解决方案。我们的工作是开源的，代码将在https://maxiuw.github.io/prix。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [863] [MVG4D: Image Matrix-Based Multi-View and Motion Generation for 4D Content Creation from a Single Image](https://arxiv.org/abs/2507.18371)
> *MVG4D：基于图像矩阵的单图像多视角与运动生成，用于4D内容创作*

*Xiaotian Chen, DongFu Yin, Fei Richard Yu, Xuanchen Li, Xinhao Zhang* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 4D内容生成, 多视角合成, 高斯泼溅, 单图像生成, 时间一致性

**Comment:** 

> **TL;DR:** MVG4D是一种新颖的框架，通过结合多视角合成和4D高斯泼溅，从单张图像生成高保真、时间一致的动态4D内容。

**AI_Comments:** MVG4D的创新在于其提出的图像矩阵模块，它有效地从单张图像生成高质量的多视角监督信号，显著提升了4D内容的时间一致性和几何保真度。此外，将3D高斯点云与轻量级形变网络结合，有效解决了4D GS方法中常见的运动不连续和背景退化问题，为从极少输入生成沉浸式4D内容提供了新思路，对AR/VR等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管生成模型在2D到3D/4D内容创作方面取得了进展，但生成高保真且时间一致的动态4D内容仍是一个挑战，尤其是在运动不连续性和背景退化方面。

**Method:** 提出MVG4D框架，从单张静态图像生成动态4D内容。其核心是图像矩阵模块，用于合成时间连贯且空间多样化的多视角图像，为下游3D和4D重建提供丰富的监督信号。这些多视角图像用于优化3D高斯点云，并通过轻量级形变网络进一步扩展到时间域，以增强时间一致性、几何保真度和视觉真实感。

**Result:** 在Objaverse数据集上的广泛实验表明，MVG4D在CLIP-I、PSNR、FVD和时间效率方面优于现有最先进的基线。它显著减少了闪烁伪影，并锐化了跨视角和时间的结构细节，从而实现了更沉浸式的AR/VR体验。

**Conclusion:** MVG4D为从最小输入高效可控地生成4D内容开辟了新方向。

> **ai_Abstract:** MVG4D是一个创新的框架，旨在从单个静态图像生成高质量、时间一致的动态4D内容。它通过一个图像矩阵模块合成多视角图像，然后利用这些图像优化3D高斯点云，并通过一个轻量级形变网络将其扩展到时间维度，从而解决了现有4D生成方法中的时间不一致和背景退化问题。实验证明，MVG4D在性能和效率上超越了现有技术，并能生成更逼真的AR/VR内容。

> **摘要翻译:** 生成建模的进步显著增强了数字内容创作，从2D图像扩展到复杂的3D和4D场景。尽管取得了实质性进展，但生成高保真且时间一致的动态4D内容仍然是一个挑战。在本文中，我们提出了MVG4D，一个新颖的框架，通过结合多视角合成与4D高斯泼溅（4D GS），从单张静态图像生成动态4D内容。MVG4D的核心是采用图像矩阵模块，合成时间连贯且空间多样化的多视角图像，为下游3D和4D重建提供丰富的监督信号。这些多视角图像用于优化3D高斯点云，并通过轻量级形变网络进一步扩展到时间域。我们的方法有效增强了时间一致性、几何保真度和视觉真实感，解决了影响先前基于4D GS方法运动不连续和背景退化的关键挑战。在Objaverse数据集上的广泛实验表明，MVG4D在CLIP-I、PSNR、FVD和时间效率方面优于现有最先进的基线。值得注意的是，它减少了闪烁伪影，并锐化了跨视角和时间的结构细节，从而实现了更沉浸式的AR/VR体验。MVG4D为从最小输入高效可控地生成4D内容开辟了新方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [864] [Label Anything: Multi-Class Few-Shot Semantic Segmentation with Visual Prompts](https://arxiv.org/abs/2407.02075)
> *Label Anything: 多类别小样本语义分割与视觉提示*

*Pasquale De Marinis, Nicola Fanelli, Raffaele Scaringi, Emanuele Colonna, Giuseppe Fiameni, Gennaro Vessio, Giovanna Castellano* | **Category: cs.CV** | **Updated: 2025-07-25**

**Keywords:** 小样本语义分割, 视觉提示, Transformer, 多类别, 图像分割

**Comment:** ECAI 2025 - 28th European Conference on Artificial Intelligence

> **TL;DR:** “Label Anything”提出一种基于Transformer的框架，利用多种视觉提示（点、边界框、掩码）实现多类别小样本语义分割，显著减少标注工作量并达到SOTA性能。

**AI_Comments:** 这篇论文的创新点在于其多提示输入的支持，使得小样本语义分割任务更加灵活和通用，能显著减少实际应用中的标注工作量。基于Transformer的架构和通用的训练范式也增强了模型的适应性。其在多类别设置下的SOTA表现显示了该方法的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 小样本语义分割在处理新类别时需要大量标注，且传统方法存在约束。本研究旨在减少标注负担，并提供一个更灵活、更通用的框架来应对多类别、多提示的小样本语义分割任务。

**Method:** 本文引入了名为“Label Anything”的新型基于Transformer的架构，专为多提示、多路小样本语义分割设计。该方法利用点、边界框和掩码等多种视觉提示作为输入。它提出了一种新的任务公式，放宽了传统小样本分割的约束，支持多种提示类型、多类别分类，并允许在单张图像内使用多个提示。此外，设计了一种通用的训练程序，使模型能够在一个训练好的模型下无缝地在不同的N-way K-shot和提示类型配置之间操作。

**Result:** 在广泛使用的COCO-20i基准上进行的实验评估表明，“Label Anything”在现有多路小样本分割方法中取得了最先进的性能。在多类别设置下，它显著优于领先的单类别模型。

**Conclusion:** “Label Anything”通过其创新的架构和灵活的训练范式，成功解决了多类别小样本语义分割中的标注负担和通用性问题，并在主流基准上展现出卓越的性能，提供了更灵活和通用的解决方案。

> **ai_Abstract:** 本文提出了一种名为“Label Anything”的新型基于Transformer的多类别小样本语义分割框架。该框架通过整合点、边界框和掩码等多种视觉提示，显著降低了标注成本并提高了模型泛化能力。它创新性地放宽了传统小样本分割的任务约束，支持多提示、多类别输入，并设计了通用的训练流程。实验证明，“Label Anything”在COCO-20i基准上达到了最先进的性能，并在多类别设置下表现优异。

> **摘要翻译:** 小样本语义分割旨在仅使用有限的标注示例来分割先前未见类别的对象。在本文中，我们介绍了Label Anything，这是一种新颖的基于Transformer的架构，专为多提示、多路小样本语义分割而设计。我们的方法利用多种视觉提示——点、边界框和掩码——创建了一个高度灵活和通用的框架，在保持高精度的同时显著减少了标注负担。Label Anything做出了三个关键贡献：（i）我们引入了一种新的任务公式，通过支持各种类型的提示、多类别分类以及在单张图像内启用多个提示来放宽传统小样本分割的约束；（ii）我们提出了一种基于Transformer和注意力机制的新颖架构；（iii）我们设计了一种通用的训练过程，允许我们的模型在单个训练好的模型下无缝地在不同的N-way K-shot和提示类型配置之间操作。我们在广泛使用的COCO-20i基准上进行的广泛实验评估表明，Label Anything在现有多路小样本分割方法中取得了最先进的性能，同时在多类别设置下评估时显著优于领先的单类别模型。代码和训练好的模型可在https://github.com/pasqualedem/LabelAnything获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [866] [Self-Reinforcing Prototype Evolution with Dual-Knowledge Cooperation for Semi-Supervised Lifelong Person Re-Identification](https://arxiv.org/abs/2507.01884)
> *半监督终身行人重识别的自强化原型演化与双知识协作*

*Kunlun Xu, Fan Zhuo, Jiangmeng Li, Xu Zou, Jiahuan Zhou* | **Category: cs.CV** | **Updated: 2025-07-24**

**Keywords:** 终身行人重识别, 半监督学习, 原型演化, 双知识协作, 伪标签

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 针对半监督终身行人重识别（Semi-LReID）中未标记数据噪声问题，本文提出了SPRED框架，通过自强化原型演化和双知识协作生成并净化伪标签，实现了最先进的性能。

**AI_Comments:** 这篇论文的创新点在于开创性地研究了半监督终身行人重识别（Semi-LReID）问题，并提出了一个新颖的SPRED框架。其核心贡献在于引入了“自强化原型演化与双知识协作”的循环机制，有效解决了在半监督和终身学习场景下未标记数据中噪声知识的挑战。通过结合动态原型生成伪标签和新旧知识协同净化，该方法能够持续改进学习并确保知识的正向传播，这对于实际应用中数据标注成本高昂的行人重识别任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前终身行人重识别（LReID）方法主要依赖全标签数据流，但在真实世界中标签资源有限，导致大量未标记数据与少量标记样本共存的半监督LReID（Semi-LReID）问题。现有LReID方法即使结合半监督策略，也因难以处理未标记数据利用过程中产生的噪声知识，导致长期适应性能受限。

**Method:** 本文开创性地研究了Semi-LReID问题，并提出了新颖的自强化原型演化与双知识协作框架（SPRED）。其核心创新在于建立了一个自强化循环，通过动态原型引导的伪标签生成和新旧知识协同净化来增强未标记数据利用。具体而言，引入可学习的身份原型来动态捕获身份分布并生成高质量伪标签；然后，双知识协作方案整合当前模型专业化和历史模型泛化能力来提炼噪声伪标签。通过这种循环设计，逐步挖掘可靠伪标签以改进当前阶段学习并确保长期学习中的知识正向传播。

**Result:** 在已建立的Semi-LReID基准测试中，我们的SPRED方法实现了最先进的性能。

**Conclusion:** SPRED框架通过其独特的自强化原型演化和双知识协作机制，有效解决了半监督终身行人重识别中未标记数据带来的噪声挑战，并在该任务上取得了显著的性能突破，证明了其在资源受限的实际场景中的应用潜力。

> **ai_Abstract:** 本文针对资源受限下终身行人重识别（LReID）中大量未标记数据导致的半监督LReID（Semi-LReID）问题进行了开创性研究，并提出了SPRED框架。该框架通过建立动态原型引导的伪标签生成与新旧知识协同净化的自强化循环，有效处理未标记数据中的噪声知识。具体而言，SPRED利用可学习身份原型生成高质量伪标签，并通过整合当前模型专业化和历史模型泛化来提炼伪标签。实验结果表明，SPRED在Semi-LReID基准测试中达到了最先进的性能，验证了其在解决实际问题中的有效性。

> **摘要翻译:** 当前的终身行人重识别（LReID）方法主要依赖于完全标记的数据流。然而，在注释资源有限的现实世界场景中，大量未标记数据与稀缺的标记样本共存，导致半监督LReID（Semi-LReID）问题，其中LReID方法性能严重下降。现有的LReID方法，即使结合了半监督策略，也因为在利用未标记数据时难以处理出现的噪声知识，导致长期适应性能受限。在本文中，我们开创性地研究了Semi-LReID问题，引入了一个新颖的自强化原型演化与双知识协作框架（SPRED）。我们的关键创新在于在动态原型引导的伪标签生成和新旧知识协同净化之间建立了一个自强化循环，以增强未标记数据的利用。具体而言，引入了可学习的身份原型来动态捕获身份分布并生成高质量伪标签。然后，双知识协作方案整合了当前模型专业化和历史模型泛化能力，以提炼噪声伪标签。通过这种循环设计，可靠的伪标签被逐步挖掘，以改进当前阶段学习并确保长期学习中的积极知识传播。在已建立的Semi-LReID基准测试中，我们的SPRED实现了最先进的性能。我们的源代码可在https://github.com/zhoujiahuan1991/ICCV2025-SPRED获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [880] [Frequency-Dynamic Attention Modulation for Dense Prediction](https://arxiv.org/abs/2507.12006)
> *用于密集预测的频率动态注意力调制*

*Linwei Chen, Lin Gu, Ying Fu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 频率动态注意力调制, Vision Transformers, 密集预测, 频率响应, 表示崩溃

**Comment:** Accepted by ICCV 2025

> **TL;DR:** ViT中的注意力机制导致频率消失和细节丢失。本文提出频率动态注意力调制（FDAM），通过注意力反演和频率动态缩放，避免表示崩溃，显著提升了分割和检测任务的性能。

**AI_Comments:** 本文的创新点在于将电路理论中的频率响应概念引入到Vision Transformers的注意力机制中，并提出了频率动态注意力调制（FDAM）来解决ViT中固有的频率消失问题。通过注意力反演和频率动态缩放，FDAM有效地保留了高频细节，避免了表示崩溃，并在多个密集预测任务上展现了显著且一致的性能提升，尤其在遥感检测中取得了SOTA，这表明了该方法在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的Vision Transformers（ViTs）中的注意力机制使得每一层都充当低通滤波器，并且堆叠层架构存在频率消失问题，这导致关键细节和纹理的丢失。

**Method:** 本文提出了一种新颖的、受电路理论启发的频率动态注意力调制（FDAM）策略，可以轻松地插入到ViTs中。FDAM直接调制ViTs的整体频率响应，由两种技术组成：注意力反演（AttInv）和频率动态缩放（FreqScale）。AttInv通过反转注意力矩阵中的低通滤波器来生成互补的高通滤波，并动态组合两者。FreqScale用于加权不同的频率分量，以对目标响应函数进行细粒度调整。

**Result:** 通过特征相似性分析和有效秩评估，证明了该方法避免了表示崩溃。在包括SegFormer、DeiT和MaskDINO在内的各种模型上，在语义分割、目标检测和实例分割等任务中实现了持续的性能改进。此外，在遥感检测的单尺度设置中取得了最先进的结果。

**Conclusion:** 频率动态注意力调制（FDAM）通过解决ViT中因注意力机制作为低通滤波器导致的频率消失问题，有效地避免了表示崩溃，并在多种密集预测任务上显著提升了性能。

> **ai_Abstract:** 本文提出了频率动态注意力调制（FDAM），以解决Vision Transformers（ViTs）中因注意力机制作为低通滤波器导致的频率消失和细节丢失问题。FDAM通过注意力反演（AttInv）生成高通滤波并与低通滤波结合，以及频率动态缩放（FreqScale）进行细粒度频率加权，直接调制ViT的频率响应。实验表明，FDAM避免了表示崩溃，并在语义分割、目标检测和实例分割等密集预测任务上，对SegFormer、DeiT和MaskDINO等模型实现了持续的性能提升，同时在遥感检测中达到了SOTA。

> **摘要翻译:** Vision Transformers（ViTs）在计算机视觉领域取得了显著进展，在各种任务中表现出强大的性能。然而，ViTs中的注意力机制使得每一层都充当低通滤波器，并且现有Transformer中的堆叠层架构存在频率消失问题。这导致关键细节和纹理的丢失。我们提出了一种受电路理论启发的新颖策略，称为频率动态注意力调制（FDAM），它可以轻松地插入到ViTs中。FDAM直接调制ViTs的整体频率响应，由两种技术组成：注意力反演（AttInv）和频率动态缩放（FreqScale）。由于电路理论使用低通滤波器作为基本元素，我们引入了AttInv，这是一种通过反转注意力矩阵中的低通滤波器来生成互补高通滤波，并动态组合两者的方 法。我们进一步设计了FreqScale来加权不同的频率分量，以对目标响应函数进行细粒度调整。通过特征相似性分析和有效秩评估，我们证明了我们的方法避免了表示崩溃，从而在包括SegFormer、DeiT和MaskDINO在内的各种模型上实现了持续的性能改进。这些改进在语义分割、目标检测和实例分割等任务中表现明显。此外，我们将我们的方法应用于遥感检测，在单尺度设置中取得了最先进的结果。代码可在https://github.com/Linwei-Chen/FDAM获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [2] [WigglyEyes: Inferring Eye Movements from Keypress Data](https://arxiv.org/abs/2412.15669)
> *WigglyEyes：从按键数据推断眼球运动*

*Yujun Zhu, Danqing Shi, Hee-Seung Moon, Antti Oulasvirta* | **Category: cs.HC** | **Updated: 2025-07-23**

**Keywords:** 眼球运动推断, 按键数据, 扫描路径, 用户特征, 损失函数

**Comment:** 

> **TL;DR:** WigglyEyes模型仅通过按键数据推断用户眼球运动轨迹，可作为昂贵或不可行眼动追踪的替代方案。

**AI_Comments:** WigglyEyes的创新点在于它提供了一种低成本、非侵入式的眼动追踪替代方案，这在许多实际应用中具有重要意义。通过仅依赖按键数据来推断复杂的眼球运动，该模型克服了传统眼动追踪设备的局限性。其考虑个体用户特征的设计也提升了模型的普适性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 在收集真实眼动追踪数据昂贵或不可能的情况下，需要一种替代方法来推断用户在交互过程中的眼球运动。

**Method:** 该论文提出了一个WigglyEyes模型，仅基于按键日志来推断用户在输入按键时的眼球运动轨迹（scanpath）。技术核心是一个推理架构，该架构考虑了用户的个体特征，并将其推断为一个低维参数向量。此外，还提出了一种新的损失函数，用于同步推断的眼球运动与按键。

**Result:** 在触摸屏打字上的评估表明，该模型能够准确推断注视点。

**Conclusion:** 该模型能够仅通过按键数据准确推断眼球运动，为在难以获取真实眼动数据的情况下提供了一个可行的替代方案。

> **ai_Abstract:** WigglyEyes是一个创新的模型，它仅利用用户的按键数据来推断其眼球运动轨迹。该模型能够提供逐时刻的眼动扫描路径，旨在替代在真实眼动追踪数据难以获取或成本高昂的场景。其核心在于一个考虑个体用户特征的推理架构，并引入了新的损失函数以精确同步眼动与按键。在触摸屏打字上的实验验证了其眼动推断的准确性。

> **摘要翻译:** 我们提出了一个仅基于按键数据推断用户在交互过程中注视位置的模型。给定一个按键日志，它会输出一条扫描路径，逐时刻地告诉用户在输入这些按键时眼球是如何移动的。该模型可以在收集真实眼动追踪数据昂贵或不可能的情况下，作为人类数据的替代品。我们的技术洞察是一个推理架构，它考虑了用户的个体特征，这些特征被推断为一个低维参数向量。我们提出了一种新颖的损失函数，用于同步推断的眼球运动与按键。在触摸屏打字上的评估证明了准确的注视推断。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [9] [Understood: Real-Time Communication Support for Adults with ADHD Using Mixed Reality](https://arxiv.org/abs/2507.18151)
> *Understood：基于混合现实的成人多动症实时沟通支持*

*Shizhen Zhang, Shengxin Li, Quan Li* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** ADHD, 混合现实, 沟通支持, 成年人

**Comment:** Appear UIST2025

> **TL;DR:** 本文提出并评估了一个名为Understood的混合现实系统，该系统利用微软HoloLens 2为患有多动症的成年人提供实时沟通支持，通过对话总结、词语建议和话题转移检测来改善他们的沟通挑战。

**AI_Comments:** 这项研究具有创新性，因为它将混合现实技术应用于ADHD成年人的实时沟通支持，填补了现有干预措施主要针对儿童的空白。系统设计考虑了认知负荷和实际沟通障碍，通过具体功能（如实时摘要和话题检测）提供了实用的解决方案。其重要性在于为ADHD成年人提供了一种非侵入性且日常可用的工具，有望显著改善他们的社会互动质量。

<details>
  <summary>Details</summary>

**Motivation:** 患有多动症的成年人即使经过多年的社会融合，仍因执行功能障碍和情绪失调而面临沟通挑战。现有干预措施主要针对儿童，而成人缺乏能将临床策略转化为日常沟通支持的工具。

**Method:** 研究人员开发了一个名为Understood的混合现实系统，运行在微软HoloLens 2上。该系统通过形成性半结构化访谈和设计研讨会确定了沟通障碍和设计目标。Understood包含三个核心功能：实时对话摘要以减轻认知负荷、在不流畅时提供上下文相关的后续词语建议、以及话题转移检测和提醒以避免偏离主题。

**Result:** 一项受试者内用户研究和专家访谈表明，Understood系统能有效支持沟通，并具有高可用性。

**Conclusion:** Understood系统为多动症成年人提供了一种有效的实时沟通支持，可以作为治疗师介导干预的补充。

> **ai_Abstract:** 本文介绍了一个名为Understood的混合现实系统，旨在解决患有多动症的成年人在日常沟通中面临的挑战。该系统基于微软HoloLens 2，通过实时对话摘要、上下文相关词语建议和话题转移检测功能来帮助用户。研究通过用户研究和专家访谈证实了Understood在提高沟通能力和可用性方面的有效性，表明其可以作为现有治疗干预的有效补充。

> **摘要翻译:** 患有注意力缺陷多动障碍（ADHD）的成年人，即使经过多年的社会融合，也常常因执行功能障碍和情绪失调而面临沟通挑战。虽然现有干预措施主要通过结构化或侵入性方法针对儿童，但成年人缺乏能将临床策略转化为日常沟通支持的工具。为了弥补这一空白，我们推出了Understood，一个在微软HoloLens 2上实现的混合现实（MR）系统，旨在帮助患有多动症的成年人进行真实世界的沟通。通过形成性半结构化访谈和设计研讨会，我们确定了关键的沟通障碍并推导出了系统的设计目标。Understood结合了三个关键功能：(1) 实时对话摘要以减轻认知负荷，(2) 在表达不流畅时提供上下文相关的后续词语建议，以及 (3) 话题转移检测和提醒以缓解偏离主题的转换。一项受试者内用户研究和专家访谈表明，Understood能有效支持沟通，并具有高可用性，为治疗师介导的干预提供了补充。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [45] [HandProxy: Expanding the Affordances of Speech Interfaces in Immersive Environments with a Virtual Proxy Hand](https://arxiv.org/abs/2503.10029)
> *HandProxy：通过虚拟代理手扩展沉浸式环境中语音界面的可供性*

*Chen Liang, Yuxuan Liu, Martez Mott, Anhong Guo* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 语音界面, 虚拟现实, 手部交互, 沉浸式环境, 代理控制

**Comment:** Accepted in ACM IMWUT 2025

> **TL;DR:** HandProxy允许用户通过语音自然地控制虚拟手进行复杂的交互，克服了传统手部交互和语音命令的局限性。

**AI_Comments:** HandProxy的创新点在于它通过引入一个“虚拟代理手”的概念，将语音输入从简单的命令映射提升到更自然的交互描述层面，这显著扩展了语音界面在沉浸式环境中的应用范围，尤其对于那些手部交互受限的用户。该方法克服了传统语音命令的僵硬性，提供了一种更灵活、更具表现力的交互方式。

<details>
  <summary>Details</summary>

**Motivation:** 沉浸式环境中的手部交互作为主要输入方式，但受限于情境障碍、运动限制和环境约束。现有语音界面仅限于基本手势和系统控制，无法支持更丰富的表达性手部交互。

**Method:** 引入HandProxy系统，该系统不依赖预定义语音命令，而是允许用户通过语音控制虚拟代理手的移动，自然地描述预期交互，系统将语音转换为手部控制序列以实时执行。

**Result:** 一项有20名参与者的用户研究表明，HandProxy有效地在虚拟环境中实现了多样化的手部交互，任务完成率达到100%，平均每次语音命令尝试1.09次，命令执行准确率为91.8%，并支持具有不同控制和粒度级别的灵活、自然的语音输入。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** HandProxy是一个创新的系统，旨在扩展沉浸式环境中语音界面的功能，使其能够支持更丰富的表达性手部交互。针对传统手部交互的局限性以及现有语音界面只能执行基本命令的问题，HandProxy允许用户通过自然语音描述来控制虚拟代理手的移动，系统将语音实时转换为手部控制。用户研究证实了其在实现多样化虚拟手部交互方面的有效性、高任务完成率和准确性。

> **摘要翻译:** 手部交互正越来越多地被用作沉浸式环境中的主要输入方式，但由于情境障碍、运动限制和环境约束，它们并非总是可行。语音界面已被探索作为手部输入的替代方案，在研究和商业解决方案中都有应用，但它们仅限于启动基本手势和系统控制。我们引入了HandProxy，一个扩展语音界面可供性以支持表达性手部交互的系统。HandProxy不依赖于直接映射到可能交互的预定义语音命令，而是允许用户控制虚拟手作为交互代理的移动，使他们能够自然地描述预期的交互，同时系统将语音转换为一系列手部控制以进行实时执行。一项有20名参与者参与的用户研究表明，HandProxy有效地在虚拟环境中实现了多样化的手部交互，任务完成率达到100%，平均每次语音命令尝试1.09次，命令执行准确率为91.8%，同时支持具有不同控制和粒度级别的灵活、自然的语音输入。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [62] [Comparing Human and AI Performance in Visual Storytelling through Creation of Comic Strips: A Case Study](https://arxiv.org/abs/2507.18641)
> *通过创作漫画条比较人类和AI在视觉叙事中的表现：一项案例研究*

*Uğur Önal, Sanem Sariel, Metin Sezgin, Ergun Akleman* | **Category: cs.HC, cs.CY** | **Updated: 2025-05-27**

**Keywords:** 视觉叙事, 人工智能, 漫画创作, 人机比较, 案例研究

**Comment:** This paper is accepted to be presented in Digital Humanities
  Conference 2025, and it will also appear in their proceedings

> **TL;DR:** 本研究通过让AI和人类根据详细指令创作三格漫画来比较它们在视觉叙事方面的能力。结果显示AI擅长模仿艺术风格但难以创作连贯故事，而人类则善于将指令转化为有意义的视觉叙事。

**AI_Comments:** 这项研究通过一个具体的漫画创作案例，清晰地揭示了当前AI在高级创意和叙事连贯性方面的局限性，尤其是在与人类的对比中。其创新之处在于提供了一个结构化的实验框架来评估视觉叙事能力。重要性在于它强调了AI在模仿现有艺术风格方面的进步，同时也指出了其在理解和生成复杂叙事逻辑方面的不足，这对于未来AI在创意领域的应用具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 文章旨在比较人类和人工智能在视觉叙事方面的能力，特别是在创作漫画条方面的表现。

**Method:** 研究开发了详细的指令，用于重现Ernie Bushmiller的三格Nancy漫画。这些指令被提供给人类参与者（20多岁的学生，有基本艺术训练，但对该漫画无经验）和AI系统（流行的商业模型，经过训练以像艺术家一样绘画，但训练集不一定包含Bushmiller的作品）。

**Result:** 结果显示，AI系统擅长模仿专业艺术风格，但在创作连贯的视觉故事方面存在困难。相比之下，人类在将指令转化为有意义的视觉叙事方面表现出高度熟练。

**Conclusion:** 人类在将指令转化为有意义的视觉叙事方面优于AI，尽管AI在模仿艺术风格方面表现出色，但在故事连贯性上仍有不足。

> **ai_Abstract:** 本案例研究比较了人类和AI在视觉叙事中的表现，具体通过创作三格漫画。研究向人类学生和商业AI系统提供了详细指令来重现一幅经典漫画。结果表明，AI在模仿艺术风格方面表现出色，但在构建连贯视觉叙事方面存在不足，而人类则能有效将指令转化为有意义的视觉故事。

> **摘要翻译:** 本文提出了一项案例研究，比较了人类和人工智能 (AI) 在视觉叙事方面的能力。我们制定了详细的指令，以重新创作厄尼·布什米勒的三格南希漫画，并将其提供给人类和AI系统。人类参与者是20多岁的学生，他们接受过基本的艺术训练，但没有该漫画的经验或知识。使用的AI系统是流行的商业模型，它们经过训练可以像艺术家一样绘画，尽管它们的训练集不一定包含布什米勒的作品。结果表明，AI系统擅长模仿专业艺术，但在创作连贯的视觉故事方面存在困难。相比之下，人类被证明非常擅长将指令转化为有意义的视觉叙事。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [65] [ProactiveVA: Proactive Visual Analytics with LLM-Based UI Agent](https://arxiv.org/abs/2507.18165)
> *ProactiveVA：基于LLM的UI代理的主动式可视化分析*

*Yuheng Zhao, Xueli Shu, Liwen Fan, Lin Gao, Yu Zhang, Siming Chen* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 可视化分析, LLM, 主动式协助, UI代理, 智能辅助

**Comment:** 11 pages, 8 figures

> **TL;DR:** 提出ProactiveVA框架，利用LLM驱动的UI代理主动提供可视化分析帮助，解决现有系统被动响应的不足。

**AI_Comments:** 该论文创新性地提出了ProactiveVA框架，通过LLM驱动的UI代理实现了可视化分析工具的主动式智能辅助，而非传统的被动响应。这种主动性极大地提升了用户体验，尤其是在处理复杂数据时，能有效避免用户迷失。其基于形成性研究提炼设计需求并构建三阶段代理管道的方法论严谨，并在多种研究中验证了通用性和有效性，对未来智能可视化分析工具的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 可视化分析（VA）工具复杂，分析师在数据分析中容易迷失；现有的LLM辅助VA系统仅在用户明确请求时提供帮助，无法在分析师最需要时主动提供建议。

**Method:** 提出ProactiveVA框架，其中LLM驱动的UI代理监控用户交互并主动提供上下文感知协助。首先进行形成性研究，分析用户求助行为，识别用户何时、需要何种帮助以及代理如何干预。基于此，提炼出意图识别、解决方案生成、可解释性和可控性等关键设计要求。在此指导下，开发了一个包括感知、推理和行动的三阶段UI代理管道，自主感知用户需求并提供定制化建议和指导。

**Result:** 将ProactiveVA框架在两种代表性VA系统中实现，证明了其通用性。通过算法评估、案例和专家研究以及用户研究评估了框架的有效性。

**Conclusion:** ProactiveVA框架通过LLM驱动的UI代理，能够主动提供上下文感知协助，有效提升可视化分析的用户体验，并具有良好的通用性。论文还讨论了主动式VA的设计权衡和未来探索方向。

> **ai_Abstract:** 本文提出了ProactiveVA框架，旨在通过基于LLM的UI代理为可视化分析提供主动式智能辅助。针对现有LLM辅助VA系统被动响应的局限性，ProactiveVA通过监控用户交互并主动提供上下文感知建议来解决。研究通过形成性研究识别了用户求助行为和关键设计需求，并开发了一个感知、推理、行动三阶段的UI代理管道。该框架在两种VA系统中得到实现和验证，证明了其通用性和有效性。

> **摘要翻译:** 可视化分析（VA）通常应用于复杂数据，因此需要复杂的工具。尽管可视化分析赋予分析师数据分析能力，但分析师有时可能会迷失在复杂性中。这凸显了对智能辅助机制的需求。然而，即使是最新的LLM辅助VA系统也只在用户明确请求时提供帮助，这使得它们在分析师最需要时无法智能地提供建议。我们提出了一个ProactiveVA框架，其中LLM驱动的UI代理监控用户交互并主动提供上下文感知协助。为了设计有效的主动协助，我们首先进行了一项形成性研究，分析了用户交互日志中的求助行为，识别了用户何时需要主动帮助、他们需要何种帮助以及代理应如何干预。基于此分析，我们提炼出意图识别、解决方案生成、可解释性和可控性方面的关键设计要求。在这些要求的指导下，我们开发了一个三阶段UI代理管道，包括感知、推理和行动。该代理从VA交互日志中自主感知用户需求，通过系统交互式探索提供量身定制的建议和直观的指导。我们在两种代表性的VA系统中实现了该框架，证明了其通用性，并通过算法评估、案例和专家研究以及用户研究评估了其有效性。我们还讨论了主动式VA的当前设计权衡和进一步探索的领域。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [87] [On the Complexities of Testing for Compliance with Human Oversight Requirements in AI Regulation](https://arxiv.org/abs/2504.03300)
> *关于测试人工智能监管中人类监督要求合规性的复杂性*

*Markus Langer, Veronika Lazar, Kevin Baum* | **Category: cs.HC, cs.CY, K.4.1; K.5.2; J.4** | **Updated: 2025-07-24**

**Keywords:** 人工智能监管, 人类监督, 合规性测试, 社会技术治理, 欧洲人工智能法案

**Comment:** 

> **TL;DR:** 本文探讨了在人工智能监管中测试人类监督要求合规性的主要挑战，包括平衡简单与资源密集型测试方法、更新测试时机、语境依赖性以及难以操作化的标准。这些挑战反映了未来社会技术人工智能治理的更广泛问题。

**AI_Comments:** 本文在人工智能监管的实际操作层面提出了重要问题，强调了人类监督这一核心概念在合规性测试中的复杂性。其创新之处在于指出了当前测试方法（如清单式）的局限性，并呼吁更深入、更具语境敏感性的实证测试。文章将这些技术合规性挑战提升到社会技术治理的宏观层面，具有一定的理论深度和实践指导意义。其局限性可能在于，作为一篇概念性或论证性文章，它主要提出了问题，但未提供具体的解决方案或测试框架。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在强调在测试人工智能监管中人类监督要求合规性方面存在的关键挑战，特别是欧洲人工智能法案中的要求。

**Method:** 本文通过分析和论证的方式，提出了测试人工智能监管中人类监督要求合规性的主要挑战，并探讨了这些挑战如何反映了未来社会技术人工智能治理的更广泛问题。

**Result:** 结果是识别并阐述了测试人类监督要求合规性的几个核心挑战：平衡简单与资源密集型测试方法的困难、何时更新合规性测试的问题、人类监督要求的语境依赖性，以及难以操作化的标准。

**Conclusion:** 这些挑战表明，未来社会技术人工智能治理面临着从确保良好的技术产品转向确保良好的社会技术系统的更广泛挑战。

> **ai_Abstract:** 本文探讨了在人工智能监管中测试人类监督要求合规性的复杂性，重点关注了欧洲人工智能法案中的要求。文章指出，主要挑战包括在简单清单式方法与资源密集型实证测试之间取得平衡，以及应对测试更新时机、语境依赖性和难以操作化的标准。作者认为，这些挑战反映了人工智能治理从关注技术产品本身转向关注整个社会技术系统的更广泛趋势。

> **摘要翻译:** 人类监督要求是欧洲人工智能法案和人工智能治理的核心组成部分。在本文中，我们强调了测试这些要求合规性的关键挑战。一个核心难点在于平衡简单但可能无效的基于清单的方法与资源密集型且对语境敏感的对人工智能人类监督有效性的实证测试。关于何时更新合规性测试、人类监督要求的语境依赖性以及难以操作化的标准等问题，进一步使合规性测试复杂化。我们认为，这些挑战说明了未来社会技术人工智能治理中更广泛的挑战，即未来将从确保良好的技术产品转向确保良好的社会技术系统。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [121] [Recommender systems, representativeness, and online music: A psychosocial analysis of Italian listeners](https://arxiv.org/abs/2507.18169)
> *推荐系统、代表性与在线音乐：意大利听众的社会心理分析*

*Lorenzo Porcaro, Chiara Monaldi* | **Category: cs.HC, cs.CY** | **Updated: 2025-07-24**

**Keywords:** 推荐系统, 代表性危害, 在线音乐, 社会心理分析, 算法意识

**Comment:** 

> **TL;DR:** 本研究通过对意大利听众的社会心理分析，发现尽管他们熟悉在线平台，但对推荐系统缺乏批判性理解，且未完全掌握在线音乐中的代表性问题（尤其是性别差异），强调需要跨学科研究和算法意识来构建可信赖的推荐系统。

**AI_Comments:** 这篇论文的创新之处在于其采用社会心理和文化视角来分析推荐系统对音乐听众的影响，这与以往多从认知行为角度的研究形成了对比。它揭示了用户在使用推荐系统时可能存在的批判性理解不足以及对代表性问题的忽视，特别是性别差异。其重要性在于强调了在开发推荐系统时，除了技术考量外，还需要关注其社会文化影响，并提出了提升用户算法意识和数字素养的必要性，为未来可信赖推荐系统的设计提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 推荐系统广泛影响音乐收听，但关于其可能造成的代表性危害日益受到关注。现有研究多从认知行为角度探讨听众视角，很少从社会心理和文化角度进行情境化分析。本研究旨在填补这一空白。

**Method:** 研究通过访谈一组意大利音乐听众，并采用情感文本分析法分析他们的叙述。

**Result:** 研究发现，即使熟悉在线平台，听众仍可能缺乏对推荐系统的批判性理解。此外，在线音乐收听背景下的代表性问题，特别是性别差异，似乎尚未被完全理解。

**Conclusion:** 本研究强调需要进行跨学科研究来解决代表性危害，并指出算法意识和数字素养在开发可信赖推荐系统中的作用。

> **ai_Abstract:** 本研究通过对意大利音乐听众的访谈和情感文本分析，从社会心理学视角探讨了推荐系统、代表性与在线音乐的关系。结果显示，听众虽熟悉在线平台，但对推荐系统缺乏批判性理解，且对在线音乐中的代表性问题（尤其性别差异）认识不足。研究强调了跨学科研究、算法意识和数字素养对于解决代表性危害和构建可信赖推荐系统的重要性。

> **摘要翻译:** 推荐系统因其在在线平台上的广泛应用而塑造着全球的音乐收听习惯。目前，关于这些系统可能造成的代表性危害日益成为科学和公众辩论的一部分，其中音乐听众的视角通常从认知行为主义的角度进行报告和讨论，但很少从社会心理和文化的角度进行情境化分析。我们朝着这个方向前进，通过访谈一组意大利音乐听众，并运用情感文本分析法分析他们的叙述。通过这项研究，我们识别出揭示人们与收听实践之间复杂关系的共享文化图式：即使熟悉在线平台，听众可能仍然缺乏对推荐系统的批判性理解。此外，代表性问题，特别是性别差异，似乎在在线音乐收听的背景下尚未被完全掌握。本研究强调了开展跨学科研究以解决代表性危害的必要性，以及算法意识和数字素养在开发可信赖推荐系统中的作用。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [136] [Streaming, Fast and Slow: Cognitive Load-Aware Streaming for Efficient LLM Serving](https://arxiv.org/abs/2504.17999)
> *流式传输，快与慢：认知负荷感知流式传输以实现高效LLM服务*

*Chang Xiao, Brenda Yang* | **Category: cs.HC, cs.LG** | **Updated: 2025-07-23**

**Keywords:** LLM服务, 自适应流式传输, 认知负荷, 计算效率, 资源管理

**Comment:** 

> **TL;DR:** 提出了一种基于认知负荷的自适应LLM流式传输方法，以提高计算效率。

**AI_Comments:** 这篇论文提出了一种新颖且实用的方法，通过将用户侧的认知体验（认知负荷）与服务器侧的资源管理相结合，解决了LLM服务中计算资源浪费的问题。其创新点在于引入“认知负荷感知”的概念来动态调整流速，为高效的LLM服务提供了一种智能且用户友好的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型（LLM）的流式输出速度主要由计算预算决定，而忽视了人类实际阅读速度和内容相关的认知负荷，这导致计算资源利用效率低下，尤其是在高峰期会造成资源浪费和用户延迟。

**Method:** 提出了一种自适应流式传输方法，该方法根据推断的认知负荷实时动态调整LLM流式输出的速度。具体而言，它估计流式内容的认知负荷，并在复杂或信息丰富的片段中策略性地减慢流速，从而释放计算资源。该方法通过对众包用户研究数据的统计分析和模拟进行了验证。

**Result:** 研究结果表明，这种自适应方法可以有效地降低计算消耗，同时基本保持流式传输速度高于用户的正常阅读速度。

**Conclusion:** 通过考虑认知负荷来动态调整LLM流式输出速度，可以显著提高计算资源的利用效率，同时不牺牲用户体验，从而优化LLM服务。

> **ai_Abstract:** 本文提出了一种名为“流式传输，快与慢”的自适应流式传输方法，旨在解决大型语言模型（LLM）流式输出速度与人类阅读速度和认知负荷不匹配导致计算资源浪费的问题。该方法通过实时估计流式内容的认知负荷，并在复杂或信息丰富的段落中策略性地减慢流速，从而释放计算资源。通过对众包用户研究数据的统计分析和模拟表明，该方法能有效降低计算消耗，同时保持流速高于用户正常阅读速度。

> **摘要翻译:** 由大型语言模型（LLM）驱动的生成式对话界面通常以计算预算确定的速率逐个令牌地流式传输输出，而常常忽略了人类实际的阅读速度和与内容相关的认知负荷。这种不匹配经常导致计算资源的低效利用。例如，在基于云的服务中，比用户阅读速度更快的流式传输内容显得不必要，从而导致计算资源浪费并可能在高峰使用期间给其他用户带来延迟。为了解决这个问题，我们提出了一种自适应流式传输方法，该方法根据推断的认知负荷实时动态调整LLM流式输出的节奏。我们的方法估计与流式内容相关的认知负荷，并在复杂或信息丰富的片段中策略性地减慢流速，从而为其他用户释放计算资源。我们基于从众包用户研究中收集到的各种LLM生成内容的数据派生出的统计模型，进行了统计分析和模拟。我们的结果表明，这种自适应方法可以有效地降低计算消耗，同时基本保持流式传输速度高于用户的正常阅读速度。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [177] [Multimodal Behavioral Patterns Analysis with Eye-Tracking and LLM-Based Reasoning](https://arxiv.org/abs/2507.18252)
> *基于眼动追踪和大型语言模型推理的多模态行为模式分析*

*Dongyang Guo, Yasmeen Abdrabou, Enkeleda Thaqi, Enkelejda Kasneci* | **Category: cs.HC, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 眼动追踪, 大型语言模型, 多模态分析, 认知建模, 人机协作

**Comment:** 

> **TL;DR:** 本文提出了一种多模态人机协作框架，结合眼动追踪数据和大型语言模型（LLM）推理，以增强认知模式提取，并在难度预测任务中取得了显著改进。

**AI_Comments:** 该论文的创新点在于将大型语言模型（LLM）的文本推理能力与眼动追踪数据的非语言特性相结合，通过构建一个多模态人机协作框架，有效解决了传统方法在分析复杂行为模式时的局限性。其提出的多阶段管道、专家-模型协同评分和混合异常检测模块，为理解用户认知状态提供了新的视角和工具。该方法的可扩展性和可解释性使其在自适应学习、人机交互和教育分析等领域具有重要应用价值，预示着人机智能协同在行为分析方面的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 眼动追踪数据虽然能揭示认知状态，但其结构化、非语言特性使其难以分析。大型语言模型（LLM）擅长文本推理，但难以处理时间序列和数值数据。因此，需要一种方法来弥合这些差距，以更好地利用眼动追踪数据进行认知模式分析。

**Method:** 本文提出了一种多模态人机协作框架，用于从眼动追踪信号中提取认知模式。该框架包括：1) 一个多阶段管道，结合水平和垂直分割与LLM推理来发现潜在的注视模式；2) 一个专家-模型协同评分模块，整合专家判断与LLM输出，为行为解释生成信任分数；3) 一个混合异常检测模块，结合基于LSTM的时间建模与LLM驱动的语义分析。

**Result:** 在多种LLM和提示策略下的结果表明，该方法在一致性、可解释性和性能方面均有所改进，在难度预测任务中的准确率高达50%。

**Conclusion:** 该方法为认知建模提供了一种可扩展、可解释的解决方案，并在自适应学习、人机交互和教育分析等领域具有广泛的应用潜力。

> **ai_Abstract:** 本文提出了一种创新性的多模态人机协作框架，旨在克服眼动追踪数据分析的挑战以及LLM处理非文本数据的局限性。该框架整合了眼动追踪数据与LLM推理，通过多阶段管道、专家-模型协同评分模块和混合异常检测模块，有效提取用户认知模式。实验结果显示，该方法显著提升了分析的一致性、可解释性和性能，尤其在难度预测任务中表现出色，为认知建模、自适应学习和人机交互等领域提供了可扩展且可解释的解决方案。

> **摘要翻译:** 眼动追踪数据揭示了用户认知状态的宝贵见解，但由于其结构化、非语言的性质而难以分析。大型语言模型（LLM）擅长对文本进行推理，但在处理时间序列和数值数据时却表现不佳。本文提出了一种多模态人机协作框架，旨在增强从眼动追踪信号中提取认知模式的能力。该框架包括：(1) 一个多阶段管道，利用水平和垂直分割结合LLM推理来揭示潜在的注视模式；(2) 一个专家-模型协同评分模块，将专家判断与LLM输出相结合，为行为解释生成信任分数；(3) 一个混合异常检测模块，结合基于LSTM的时间建模与LLM驱动的语义分析。我们在多个LLM和提示策略下的结果显示，在一致性、可解释性和性能方面均有所改进，在难度预测任务中的准确率高达50%。这种方法为认知建模提供了一种可扩展、可解释的解决方案，并在自适应学习、人机交互和教育分析方面具有广泛的潜力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [178] [LLM-D12: A Dual-Dimensional Scale of Instrumental and Relational Dependencies on Large Language Models](https://arxiv.org/abs/2506.06874)
> *LLM-D12：一个关于大型语言模型工具性与关系性依赖的双维度量表*

*Ala Yankouskaya, Areej B. Babiker, Syeda W. F. Rizvi, Sameha Alshakhsi, Magnus Liebherr, Raian Ali* | **Category: cs.HC, cs.AI, Human-Centered Computing -- > Human computer interaction (HCI) -->
  HCI design and evaluation methods** | **Updated: 2025-07-24**

**Keywords:** LLM依赖, 工具性依赖, 关系性依赖, 心理测量学, 问卷开发

**Comment:** 

> **TL;DR:** 开发并验证了一个名为LLM-D12的12项问卷，用于衡量个体对大型语言模型的工具性和关系性依赖，并发现其具有良好的心理测量学特性。

**AI_Comments:** 这项研究创新性地提出了LLM依赖的“工具性”和“关系性”双维度概念，突破了传统行为成瘾的框架。LLM-D12量表的开发和验证为深入理解人机交互中新兴的依赖现象提供了宝贵的工具和视角，有助于未来对LLM负责任使用和潜在风险的研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有评估大型语言模型（LLM）依赖的工具稀缺，且主要基于传统行为成瘾症状，这被视为概念上的局限性，因为LLM-人类关系更为细致，需要一种全新的、独特的视角来理解和评估。

**Method:** 基于作者先前的理论工作，开发并验证了一个新的12项问卷LLM-D12，用于衡量LLM依赖。该研究从英国526名参与者中收集了数据，并使用分半样本方法对总样本的独立两半进行了探索性因子分析和验证性因子分析，以支持量表的结构。同时进行了外部验证。

**Result:** 因子分析支持了LLM-D12量表的双因子结构：工具性依赖（六项）和关系性依赖（六项）。该双因子结构表现出卓越的内部一致性和清晰的判别效度。外部验证证实了概念基础和两个子量表之间的区别。

**Conclusion:** LLM-D12量表的心理测量学特性和结构表明，对LLM的依赖不一定表示功能障碍，但可能仍然反映了在某些情境下可能出现问题的依赖水平。

> **ai_Abstract:** 本文开发并验证了一个名为LLM-D12的12项问卷，旨在弥补现有LLM依赖评估工具的不足。该量表基于理论工作，通过对526名英国参与者的数据分析，揭示了LLM依赖的双因子结构：工具性依赖和关系性依赖。研究证实了量表良好的心理测量学特性，并提出对LLM的依赖可能反映了潜在的问题性依赖水平，而非必然的功能障碍。

> **摘要翻译:** 目前人们对理解人如何与大型语言模型（LLMs）互动以及这些模型是否会引发依赖甚至成瘾行为的兴趣日益增长。评估个体对LLM依赖程度的有效工具稀缺，且主要建立在经典的行为成瘾症状之上，并适应LLM使用情境。我们认为这是一种概念上的局限性，因为LLM-人类关系更为细致，需要一种全新的、独特的视角。为了弥补这一空白，我们开发并验证了一个新的12项问卷，用于衡量LLM依赖，称为LLM-D12。该量表基于作者先前的理论工作，相应地开发了项目，并从英国的526名参与者那里收集了答复。使用分半样本方法，对总样本的独立两半进行了探索性因子分析和验证性因子分析，支持了双因子结构：工具性依赖（六项）和关系性依赖（六项）。工具性依赖反映了个体在决策和认知任务中依赖LLM支持或协作的程度。关系性依赖捕捉了将LLM视为具有社会意义、有感知力或类似伴侣实体的倾向。该双因子结构表现出卓越的内部一致性和清晰的判别效度。外部验证证实了概念基础以及两个子量表之间的区别。我们的LLM-D12量表的心理测量学特性和结构是根据新兴观点进行解释的，即对LLM的依赖不一定表示功能障碍，但可能仍然反映了在某些情境下可能出现问题的依赖水平。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [202] [Archiverse: an Approach for Immersive Cultural Heritage](https://arxiv.org/abs/2507.19376)
> *Archiverse：一种沉浸式文化遗产方法*

*Wieslaw Kopeć, Anna Jaskulska, Władysław Fuchs, Wiktor Stawski, Stanisław Knapiński, Barbara Karpowicz, Rafał Masłyk* | **Category: cs.HC, cs.CY** | **Updated: 2025-07-25**

**Keywords:** 文化遗产, 虚拟现实, 扩展现实, 沉浸式体验, 考古遗址

**Comment:** 

> **TL;DR:** 探讨使用VR和XR技术沉浸式重建和可视化文化遗产，尤其针对遗址，并指出跨学科合作和传播面临的挑战。

**AI_Comments:** 这篇论文提出了一种利用VR/XR技术进行文化遗产沉浸式体验的创新方法，特别强调了其在重建遗迹方面的潜力。论文清晰地指出了该领域面临的挑战，即跨学科合作的复杂性和虚拟环境普及的难度，这对于未来研究和实践具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 数字技术和工具改变了文化遗产的研究和数字化重建方式，需要更精确和新颖的视角来审视文化遗产，尤其是在仅存遗迹的情况下。

**Method:** 探索利用虚拟现实（VR）和扩展现实（XR）作为工具，以沉浸式和互动的方式重建和可视化历史文化遗产的遗迹，模拟其原始复杂性。

**Result:** Not mentioned in abstract

**Conclusion:** 虚拟现实和扩展现实技术在文化遗产的沉浸式重建和可视化方面具有巨大潜力，尤其对于遗址，但跨学科合作和虚拟环境的传播是其主要挑战。

> **ai_Abstract:** 这篇论文探讨了利用虚拟现实（VR）和扩展现实（（XR）技术来沉浸式地重建和可视化文化遗产，尤其针对仅存遗迹的考古遗址和建筑。文章指出，尽管这些技术能提供精确和新颖的体验视角，但其应用面临跨学科合作和虚拟环境向公众传播的挑战。

> **摘要翻译:** 数字技术和工具已经改变了我们研究文化遗产的方式以及我们对其进行数字重建的方式。激光扫描、摄影测量和各种混合现实解决方案等技术使研究人员能够更精确地从新角度审视文化物品和文物。在本次专题讨论中，我们探讨了虚拟现实（VR）和扩展现实（XR）如何作为工具，重建和可视化历史文化遗产的遗迹，并在其原始复杂性的模拟中体验它，这意味着沉浸式和互动性。以考古遗址和建筑为例的物质文化可视化在仅存废墟或考古遗迹时可能特别有用。然而，这些进步也带来了重大挑战，特别是在来自许多通常相距遥远的领域的专家之间的跨学科合作，以及虚拟沉浸式环境在专业人士和公众之间的传播方面。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [227] [Full-body WPT: wireless powering with meandered e-textiles](https://arxiv.org/abs/2506.17606)
> *全身WPT：使用蜿蜒电子纺织品进行无线供电*

*Ryo Takahashi, Takashi Sato, Wakako Yukita, Tomoyuki Yokota, Takao Someya, Yoshihiro Kawahara* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 无线电力传输, 蜿蜒纺织线圈, 可穿戴电子设备, 以身体为中心, 安全性

**Comment:** 

> **TL;DR:** 该研究提出了一种基于蜿蜒纺织线圈的全身无线电力传输（WPT）系统，该系统能将强磁场限制在皮肤表面，提高安全性和效率，并适用于可穿戴设备。

**AI_Comments:** 该研究的创新之处在于利用蜿蜒纺织线圈将磁场局限于皮肤表面，显著提高了以身体为中心的无线电力传输的安全性和效率。这对于将无线供电集成到可穿戴电子设备中至关重要，为健康监测、增强现实和人机交互等新应用提供了可能。其对用户运动的适应性是一个关键优势。

<details>
  <summary>Details</summary>

**Motivation:** 传统的感应系统会向人体深层组织发射强磁场，存在安全隐患。本研究的动机是开发一种更安全、更高效的人体周边无线电力系统，特别是为了可穿戴应用。

**Method:** 该论文提出了使用“蜿蜒纺织线圈”的“全身WPT”系统。这种线圈能够将强磁场限制在皮肤表面。系统采用“低损耗导电纱线”以实现高效率和轻量化设计。通过“仿真和实验原型”分析了其性能。

**Result:** 该系统表现出“高功率传输效率”和“对用户运动和姿势的适应性”。它提供了一个“安全高效的分布式电力网络”。

**Conclusion:** 该系统突出了以身体为中心的无线电力网络作为普适健康监测、增强现实和人机交互系统基础层的潜力。

> **ai_Abstract:** 该论文介绍了全身WPT，一种利用蜿蜒纺织线圈在人体周围构建的无线电力网络系统。与传统系统不同，该设计能将强磁场限制在皮肤表面，从而提高安全性和效率。通过使用低损耗导电纱线，它实现了节能且轻量化的设计。仿真和实验证实了其高功率传输效率和对运动的适应性，使其成为未来可穿戴健康、增强现实和人机交互系统的基础技术。

> **摘要翻译:** 我们提出了全身WPT，一种使用蜿蜒纺织线圈在人体周围进行无线电力组网的技术。与将强磁场发射到人体深层组织的传统感应系统不同，蜿蜒线圈能够将强磁场的产生限制在皮肤表面，即使扩展到人体大小也是如此。这种局部感应系统提高了身体周围无线供电的安全性和效率。此外，使用低损耗导电纱线实现了节能轻量化设计。我们通过仿真和实验原型分析了我们设计的性能，展示了高功率传输效率以及对用户运动和姿势的适应性。我们的系统利用集成到可穿戴材料中的蜿蜒纺织线圈提供了一个安全高效的分布式电力网络，突出了以身体为中心的无线电力网络作为普适健康监测、增强现实和人机交互系统基础层的潜力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [240] [Talking to...uh...um...Machines: The Impact of Disfluent Speech Agents on Partner Models and Perspective Taking](https://arxiv.org/abs/2507.18315)
> *与……呃……嗯……机器对话：不流畅语音代理对伙伴模型和视角采纳的影响*

*Rhys Jacka, Paola R. Peña, Sophie Leonard, Éva Székely, Benjamin R. Cowan* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 语音不流畅, 人机对话, 伙伴模型, 视角采纳, 自我中心交流

**Comment:** 12 pages, 3 figures, in Proceedings of the 7th ACM Conference on
  Conversational User Interfaces

> **TL;DR:** 研究发现，在人机对话中，不流畅的语音代理可能被认为更具能力，并可能增加人类的自我中心交流。

**AI_Comments:** 该研究创新性地探讨了语音不流畅在人机对话中的作用，这与传统上认为不流畅是负面因素的观点形成对比。其发现不流畅代理可能被认为更具能力，并可能影响人类的交流方式（增加自我中心交流），为未来的人机交互设计提供了新的视角。然而，文中也指出“广泛的置信区间意味着这种效果不明确”，这提示了该研究结果的局限性，可能需要进一步的研究来确认这些发现。

<details>
  <summary>Details</summary>

**Motivation:** 人类交流中语音不流畅对视角采纳和听众设计有影响，但其在人机对话（HMD）中的影响尚不清楚。

**Method:** 61名参与者在线进行了一项命名者-匹配者任务，与使用流畅或不流畅语音的代理进行互动。参与者在任务前后完成了伙伴模型问卷（PMQ）。

**Result:** 交互后评估显示，参与者认为不流畅的代理更具能力，尽管预任务评分无显著差异。但在会话灵活性或类人性评估中未观察到显著差异。研究还发现，与不流畅语音代理的互动似乎增加了自我中心交流，但效果不确定性高（置信区间宽）。

**Conclusion:** 研究讨论了不流畅性如何影响人机对话中的伙伴模型和语言产生，特别是可能增加自我中心交流。

> **ai_Abstract:** 本研究探讨了语音不流畅在人机对话中的影响。通过一项命名者-匹配者任务，参与者与流畅或不流畅的语音代理互动。结果显示，参与者认为不流畅代理更具能力，尽管对会话灵活性和类人性的感知没有显著差异。此外，研究发现与不流畅代理互动可能增加人类的自我中心交流，但该发现具有不确定性。论文讨论了不流畅性对人机对话中伙伴模型和语言产生的影响。

> **摘要翻译:** 语音不流畅在人际交流（HHC）中的视角采纳和听众设计中发挥作用，但它们在人机对话（HMD）中的影响知之甚少。在一项在线命名者-匹配者任务中，六十一名参与者与使用流畅或不流畅语音的代理进行了互动。参与者在任务前后都完成了一份伙伴模型问卷（PMQ）。交互后评估表明，尽管预任务评分没有显著差异，参与者认为不流畅的代理更具能力。然而，在会话灵活性或类人性评估中没有观察到显著差异。我们的发现还揭示了参与者与语音代理互动时自我中心和异他中心语言产生的证据。与不流畅语音代理的互动似乎增加了自我中心交流，与流畅代理相比。尽管广泛的置信区间意味着这种效果不明确。我们讨论了这一发现的潜在解释，重点关注不流畅性如何影响人机对话中的伙伴模型和语言产生。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [256] [Reality Proxy: Fluid Interactions with Real-World Objects in MR via Abstract Representations](https://arxiv.org/abs/2507.17248)
> *Reality Proxy：通过抽象表示在MR中与真实世界对象进行流畅交互*

*Xiaoan Liu, Difan Jia, Xianhao Carton Liu, Mar Gonzalez-Franco, Chen Zhu-Tian* | **Category: cs.HC, cs.AI, cs.GR, H.5.2; I.3.6** | **Updated: 2025-07-24**

**Keywords:** 混合现实, 真实世界对象交互, 抽象代理, Reality Proxy, 人工智能

**Comment:** 16 pages, 9 figures. Accepted for publication in UIST'25 (The 38th
  Annual ACM Symposium on User Interface Software and Technology), Busan,
  Republic of Korea, 28 Sep - 1 Oct 2025

> **TL;DR:** Reality Proxy通过引入真实世界对象的抽象代理，解决了在混合现实中与拥挤、遥远或部分遮挡的物理对象交互的困难，从而实现了更流畅、更丰富的交互。

**AI_Comments:** Reality Proxy通过引入抽象代理来解决MR中物理对象交互的根本问题，具有创新性。它不仅提升了基本选择，更通过AI增强的代理实现了以前难以实现的高级交互，且无需新的交互范式，这大大提升了其可用性和推广潜力。该方法提供了一个通用且强大的交互范式，对未来MR系统的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在混合现实（MR）中，当真实世界对象拥挤、遥远或部分被遮挡时，直接与它们进行交互通常很困难，这阻碍了直接的选择和操作。这些困难源于直接在物理对象上执行交互，导致输入与物理约束紧密耦合。

**Method:** 该论文通过引入“代理”（即真实世界对象的抽象表示）来解耦交互与物理约束。他们将此概念体现在Reality Proxy系统中，该系统在选择过程中将交互目标从物理对象无缝转移到其代理。Reality Proxy利用AI技术，通过语义属性和分层空间关系来丰富代理，从而实现新颖且以前繁琐的MR交互，例如浏览、基于属性的过滤、导航嵌套组和复杂的多对象选择，而无需新的手势或菜单系统。

**Result:** Reality Proxy在多种场景中展示了其多功能性，包括办公室信息检索、大规模空间导航和多无人机控制。专家评估表明该系统具有实用性和可用性。

**Conclusion:** 基于代理的抽象为未来的MR系统提供了一种强大且可泛化的交互范式。

> **ai_Abstract:** 该论文提出了一种名为Reality Proxy的混合现实（MR）系统，旨在解决与拥挤、遥远或部分遮挡的真实世界对象交互的难题。通过引入对象的抽象“代理”，该系统将交互从物理约束中解耦，从而实现更流畅、更丰富的交互。Reality Proxy利用AI为代理添加语义属性和空间关系，支持如过滤、导航和多对象选择等高级交互，且无需新的手势。系统在多种应用场景中展现了其有效性，并被专家评估认为是一种有前景的MR交互范式。

> **摘要翻译:** 在混合现实（MR）中，当真实世界对象拥挤、遥远或部分被遮挡时，直接与它们进行交互通常很困难，这阻碍了直接的选择和操作。我们观察到，这些困难源于直接在物理对象上执行交互，其中输入与它们的物理约束紧密耦合。我们的关键洞察是通过引入代理——真实世界对象的抽象表示——来解耦交互与这些约束。我们将这一概念体现在Reality Proxy中，这是一个在选择过程中将交互目标从物理对象无缝转移到其代理的系统。除了促进基本选择之外，Reality Proxy还利用AI技术通过其对应物理对象的语义属性和分层空间关系来丰富代理，从而在MR中实现新颖且以前繁琐的交互——例如浏览、基于属性的过滤、导航嵌套组和复杂的多对象选择——所有这些都不需要新的手势或菜单系统。我们展示了Reality Proxy在各种场景中的多功能性，包括办公室信息检索、大规模空间导航和多无人机控制。专家评估表明该系统具有实用性和可用性，这表明基于代理的抽象为未来的MR系统提供了一种强大且可泛化的交互范式。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [303] [PALM: PAnoramic Learning Map Integrating Learning Analytics and Curriculum Map for Scalable Insights Across Courses](https://arxiv.org/abs/2507.18393)
> *PALM：全景学习地图，整合学习分析和课程图谱，实现跨课程的可扩展洞察*

*Mahiro Ozaki, Li Chen, Shotaro Naganuma, Valdemar Švábenský, Fumiya Okubo, Atsushi Shimada* | **Category: cs.HC, cs.CY** | **Updated: 2025-07-24**

**Keywords:** 学习分析, 课程图谱, 可扩展性, 自我调节学习, 仪表盘

**Comment:** To appear in the Proceedings of the IEEE SMC 2025 conference

> **TL;DR:** PALM是一个将学习分析与课程图谱结合的仪表盘，旨在通过提供跨课程的可扩展洞察来增强学生的学习意识和自我调节能力。

**AI_Comments:** PALM的创新之处在于其将学习分析与课程图谱深度整合，解决了传统学习分析在跨课程和长期学习轨迹方面的局限性，提供了更全面的学生学习视图。其通过可视化增强学生自我调节学习和规划能力的方法具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统学习分析（LA）主要关注单个课程或学习者，缺乏考虑课程间关系和长期学习轨迹的框架，导致可扩展性挑战。

**Method:** 本研究提出了全景学习地图（PALM），一个整合学习分析和课程图谱的仪表盘。通过系统评估，在两个关键领域评估了PALM的有效性：1) 对学生学习行为意识的影响；2) 与现有系统的比较表现。

**Result:** PALM增强了学习者对学习规划和反思的意识，特别是通过可视化呈现个人学习历史和统计趋势，改善了感知行为控制。PALM在视觉吸引力和可用性方面获得了比现有系统显著更高的评价。

**Conclusion:** PALM通过提供以前无法获得的洞察，增强了自我调节学习和参与度，代表了学习分析领域超越传统方法，迈向全面和可扩展方法的重大一步。

> **ai_Abstract:** 本研究提出了全景学习地图（PALM），一个结合学习分析和课程图谱的仪表盘，旨在解决传统学习分析在跨课程洞察和长期学习轨迹方面的可扩展性限制。通过将多层教育数据整合到课程图谱中，PALM帮助学生直观理解学习记录和学业进展。系统评估显示，PALM显著提升了学生对学习规划和反思的意识，并通过可视化学习历史改善了行为控制。尽管仍需完善，PALM在视觉吸引力和可用性方面优于现有系统，为自我调节学习和参与提供了新的洞察，标志着学习分析迈向更全面和可扩展的方法。

> **摘要翻译:** 本研究提出并评估了全景学习地图（PALM），一个旨在通过整合课程级信息来解决学习分析（LA）可扩展性挑战的学习分析仪表盘。传统的学习分析研究主要集中在单个课程或学习者，并且通常缺乏一个考虑课程之间关系和长期学习轨迹的框架。为了弥补这一空白，PALM被开发出来，将多层教育数据整合到课程图谱中，使学习者能够直观地理解他们的学习记录和学业进展。我们进行了一项系统评估，以评估PALM在两个关键领域的有效性：(1) 它对学生学习行为意识的影响，以及(2) 它与现有系统的比较表现。结果表明，PALM增强了学习者对学习规划和反思的意识，特别是通过可视化呈现个人学习历史和统计趋势，从而阐明了学习行为和结果之间的联系，改善了感知行为控制。尽管PALM作为一个系统需要持续改进，但它在视觉吸引力和可用性方面获得了比现有系统显著更高的评价。通过作为一种提供以前无法获得的洞察的信息资源，PALM增强了自我调节学习和参与度，代表了学习分析领域超越传统方法，迈向全面和可扩展方法的重要一步。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [328] [Meeting Patients Where They're At: Toward the Expansion of Chaplaincy Care into Online Spiritual Care Communities](https://arxiv.org/abs/2506.11366)
> *在患者所在之处相遇：将牧师关怀扩展到在线精神关怀社区*

*Alemitu Bezabih, Shadi Nourriz, Anne-Marie Snider, Rosalie Rauenzahn, George Handzo, C. Estelle Smith* | **Category: cs.HC, cs.CY** | **Updated: 2025-07-24**

**Keywords:** 在线精神关怀, 牧师关怀, 社区支持, 混合方法研究, 关怀循环

**Comment:** 

> **TL;DR:** 这项跨学科研究探讨了将牧师精神关怀扩展到匿名、异步、基于文本的在线社区的可行性、益处和挑战，并提出了“关怀循环”模型和设计启示。

**AI_Comments:** 该论文的创新之处在于首次将专业的牧师关怀与CSCW/HCI研究相结合，填补了现有研究空白。其重要性在于为解决精神关怀的可及性问题提供了新的思路，特别是在数字时代背景下。提出的“关怀循环”模型具有理论和实践意义，为未来的在线精神关怀设计提供了框架。然而，论文也指出了技术在完全媒介精神关怀方面的局限性，这提示未来研究需深入探讨如何在保留精神关怀本质的同时，有效利用数字平台。

<details>
  <summary>Details</summary>

**Motivation:** 尽管美国对精神关怀的需求日益增长，但它往往服务不足、难以获取或被误解，且CSCW/HCI研究中几乎没有涉及专业的牧师和精神关怀提供者。本研究旨在建立对精神关怀如何（或可能不）扩展到在线空间的理解。

**Method:** 本研究采用探索性混合方法，对22名牧师进行了访谈和用户测试，围绕Reddit支持社区进行，以了解参与者对技术的看法以及他们对牧师在未来在线精神关怀社区（OSCCs）中作用的构想。数据分析采用扎根理论方法。

**Result:** 扎根理论分析强调了OSCCs的益处，包括：在患者所在之处提供服务；可及性和可扩展性；以及促进患者主动的关怀。牧师们指出，他们在OSCCs中的存在可以帮助塑造同伴互动、主持、进行团体关怀的同步聊天以及引导至外部资源。研究还发现一些精神关怀策略适用于在线空间，但也暴露了技术完全媒介精神关怀的局限性。

**Conclusion:** 基于研究结果，论文提出了一个“关怀循环”模型，连接机构化正式关怀和基于平台的社区关怀，以扩大精神关怀的可及性并提高其认知度和利用率。研究还提出了指导未来在线精神关怀工作的设计启示，并强调需要开发新的在线牧师干预措施。

> **ai_Abstract:** 本研究旨在探讨将专业的牧师精神关怀扩展到匿名、异步、基于文本的在线社区的可行性与挑战。通过对22名牧师进行访谈和用户测试，研究发现在线精神关怀社区（OSCCs）在可及性、可扩展性和促进患者主动关怀方面具有显著优势。牧师在OSCCs中的参与有助于塑造互动和引导资源。尽管部分精神关怀策略可在线进行，但技术在完全媒介精神关怀方面存在局限性。研究提出了“关怀循环”模型，旨在连接机构化和平台化关怀，并提供了未来在线精神关怀的设计启示。

> **摘要翻译:** 尽管美国对精神关怀的需求日益增长，但它往往服务不足、难以获取或被误解，而CSCW/HCI研究中几乎没有涉及专业的牧师和精神关怀提供者。这项跨学科研究旨在建立对精神关怀如何（或可能不）扩展到在线空间的初步理解——特别关注匿名、异步和基于文本的在线社区。我们对牧师（N=22）进行了一项探索性混合方法研究，包括访谈和用户测试环节，围绕Reddit支持社区进行，以了解参与者对技术的看法以及他们对牧师在未来在线精神关怀社区（OSCCs）中作用的构想。我们的扎根理论方法分析突出了OSCCs的益处，包括：在患者所在之处提供服务；可及性和可扩展性；以及促进患者主动的关怀。牧师们强调，他们在OSCCs中的存在有助于塑造同伴互动、主持、进行团体关怀的同步聊天以及引导至外部资源，同时也提出了重要的可行性问题、风险以及未来设计和研究的需求。我们使用现有的牧师技术分类法来表明某些精神关怀策略可能适用于在线空间，但我们也揭示了技术完全媒介精神关怀的局限性以及开发新的在线牧师干预措施的必要性。基于这些发现，我们提出了一个“关怀循环”模型，连接机构化正式关怀和基于平台的社区关怀，以扩大精神关怀的可及性并提高其认知度和利用率。我们还提出了设计启示，以指导未来在线精神关怀的工作。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [366] [Multisensory Integration and Sensory Substitution Across Vision, Audition, and Haptics: Answering the What, Which, and When in Study Protocols](https://arxiv.org/abs/2507.18401)
> *跨视觉、听觉和触觉的多感官整合与感官替代：研究方案中何物、何者、何时的问题解答*

*Andrew Jeyathasan, Swati Banerjee* | **Category: cs.HC, q-bio.NC** | **Updated: 2025-07-24**

**Keywords:** 多感官整合, 感官替代, 研究方案, 跨模态对应, 认知负荷

**Comment:** 

> **TL;DR:** 本文探讨了在设计有效多感官整合（MSI）研究方案时，如何考量跨模态对应、一致性、认知负荷和刺激时序等关键因素，尤其是在整合三种或更多感官模态时。

**AI_Comments:** 本文旨在填补多模态（三种或更多感官）整合研究的空白，通过系统性地审视影响MSI研究方案设计的关键因素，为未来的实验设计提供了重要的指导框架。其创新点在于强调了多模态整合的复杂性，并为研究者提供了实际的应用方法。

<details>
  <summary>Details</summary>

**Motivation:** 理解多感官整合（MSI）对于日常生活和沉浸式技术中形成连贯的感知至关重要。尽管大多数研究侧重于单模态或双模态线索，但三种或更多模态的整合仍未得到充分探索。

**Method:** 本文通过审视跨模态对应、一致性、认知负荷和刺激时序等关键因素，并探讨如何将这些因素应用于设计有效的多感官整合（MSI）研究方案。

**Result:** 本文旨在通过审视关键因素来指导设计有效的多感官整合（MSI）研究方案，这些因素包括跨模态对应、一致性、认知负荷和刺激时序，特别强调了随着模态数量增加时复杂性也随之增加的情况。

**Conclusion:** 设计有效多感官整合（MSI）研究方案需要仔细考虑跨模态对应、一致性、认知负荷和刺激时序等关键因素，尤其是在涉及三种或更多感官模态时。

> **ai_Abstract:** 本文探讨了多感官整合（MSI）的重要性，并指出当前研究在三种或更多感官模态整合方面的不足。文章详细审视了在设计有效MSI研究方案时必须考虑的关键因素，包括跨模态对应、一致性、认知负荷和刺激时序，并强调了这些因素在多模态情境下复杂性的增加，旨在为研究方案的设计提供指导。

> **摘要翻译:** 我们通过多种感官体验世界，这些感官协同工作，无论是日常生活还是沉浸式技术中，都能创造出连贯的感知。理解这种多感官整合（MSI）需要检查感官模态之间的相互作用，每种模态都具有独特的时间动态和特征。虽然大多数研究侧重于单模态或双模态线索，但三种或更多模态的整合仍未得到充分探索。MSI研究必须考虑跨模态对应、一致性、认知负荷和刺激时序等因素，这些因素随着模态数量的增加而变得日益复杂。本文审视了这些关键因素，以及如何将它们应用于设计有效的MSI研究方案。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [372] [Exploring Communication Strategies for Collaborative LLM Agents in Mathematical Problem-Solving](https://arxiv.org/abs/2507.17753)
> *探索协作式LLM智能体在数学问题解决中的沟通策略*

*Liang Zhang, Xiaoming Zhai, Jionghao Lin, Jionghao Lin, Jennifer Kleiman, Diego Zapata-Rivera, Carol Forsyth, Yang Jiang, Xiangen Hu, Arthur C. Graesser* | **Category: cs.HC, cs.AI, cs.CL, cs.CY** | **Updated: 2025-05-02**

**Keywords:** LLM智能体, 沟通策略, 数学问题解决, 协作学习, AI教育

**Comment:** 

> **TL;DR:** 本研究评估了LLM智能体在数学问题解决中的四种沟通策略，发现双智能体设置优于单智能体，其中同伴协作模式准确率最高，强调了有效沟通在AI教育中的重要性。

**AI_Comments:** 本文的创新点在于系统地评估了不同沟通策略对LLM智能体协作问题解决能力的影响，并明确指出了“同伴协作”模式的优越性。这对于未来设计更高效的AI辅助学习系统具有重要指导意义。研究结果揭示了对话行为的重要性，为多智能体系统的交互设计提供了见解。

<details>
  <summary>Details</summary>

**Motivation:** 尽管LLM智能体在AI辅助教育中日益普及，但很少有研究系统地评估不同沟通策略对智能体问题解决能力的影响。

**Method:** 研究在双智能体、基于聊天的数学问题解决环境中使用OpenAI GPT-4o模型，评估了四种沟通模式：师生互动、同伴协作、互惠式同伴教学和批判性辩论。在MATH数据集上进行评估。

**Result:** 双智能体设置优于单智能体；同伴协作模式取得了最高的准确率；陈述、确认和提示等对话行为在协作问题解决中发挥关键作用。

**Conclusion:** 多智能体框架能增强计算任务，但有效的沟通策略对于解决AI教育中的复杂问题至关重要。

> **ai_Abstract:** 本研究探讨了在AI辅助教育中，协作式大型语言模型（LLM）智能体在数学问题解决中的沟通策略。通过在双智能体、基于GPT-4o的聊天环境中评估四种沟通模式（师生互动、同伴协作、互惠式同伴教学、批判性辩论），研究发现双智能体设置显著优于单智能体，其中“同伴协作”模式表现最佳。此外，特定的对话行为（如陈述、确认、提示）对协作解决问题至关重要。研究强调了在多智能体框架中，有效的沟通策略对于应对复杂教育任务的重要性。

> **摘要翻译:** 大型语言模型（LLM）智能体在AI辅助教育中越来越多地用于支持辅导和学习。LLM智能体之间有效的沟通策略可以提高协作式问题解决的效率，并促进教育中具有成本效益的采用。然而，很少有研究系统地评估不同沟通策略对智能体问题解决能力的影响。我们的研究在双智能体、基于聊天的数学问题解决环境中，使用OpenAI GPT-4o模型，考察了四种沟通模式：师生互动、同伴协作、互惠式同伴教学和批判性辩论。在MATH数据集上进行评估，我们的结果表明，双智能体设置优于单智能体，其中同伴协作模式实现了最高的准确率。陈述、确认和提示等对话行为在协作问题解决中发挥关键作用。虽然多智能体框架增强了计算任务，但有效的沟通策略对于解决AI教育中的复杂问题至关重要。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [413] [A Custom-Built Ambient Scribe Reduces Cognitive Load and Documentation Burden for Telehealth Clinicians](https://arxiv.org/abs/2507.17754)
> *定制环境智能记录员减轻远程医疗临床医生的认知负荷和文档负担*

*Justin Morse, Kurt Gilbert, Kyle Shin, Rick Cooke, Peyton Rose, Jack Sullivan, Angelo Sisante* | **Category: cs.HC, cs.AI, cs.CL, cs.CY** | **Updated: 2025-05-02**

**Keywords:** 环境智能记录员, 远程医疗, 认知负荷, 文档负担, GPT-4o, Whisper

**Comment:** 

> **TL;DR:** 开发了一种定制的AI环境智能记录员，用于远程医疗，使用Whisper和GPT-4o生成SOAP笔记，并通过测试和实际使用证明能有效减轻临床医生的认知负荷和文档负担，并提高笔记质量和简洁性。

**AI_Comments:** 该论文展示了一个实际部署的AI解决方案，有效解决了临床医生职业倦怠和文档负担问题。其创新点在于结合了Whisper和GPT-4o进行笔记生成，并引入了LLM-as-a-judge进行质量评估，以及BART模型进行简洁性优化。实际的用户反馈数据（94%和97%的满意度）增强了其重要性。该工作为未来AI在医疗领域的应用提供了有力的实证。

<details>
  <summary>Details</summary>

**Motivation:** 临床医生职业倦怠促使人们在诊所中越来越多地采用环境医疗记录员。

**Method:** 本文介绍了一种定制的环境智能记录员应用程序，该应用程序集成到Included Health的EHR系统中。该应用程序使用Whisper进行转录，并使用带有GPT-4o的模块化上下文学习管道自动生成SOAP笔记和患者指导。此外，使用微调的BART模型对笔记进行后处理以提高简洁性。

**Result:** 在模拟就诊数据上的测试表明，该应用程序生成的笔记质量超过了专家编写的笔记，由LLM-as-a-judge确定。该应用程序已被临床实践广泛采用，Included Health有超过540名临床医生至少使用过一次。94%（n = 63）的受访临床医生报告在使用该应用程序期间认知负荷降低，97%（n = 66）报告文档负担减轻。

**Conclusion:** 这些发现突出了AI系统减轻行政负担和支持临床医生提供高效、高质量护理的潜力。

> **ai_Abstract:** 本文介绍了一个为远程医疗临床医生定制的环境智能记录员应用程序，该应用程序集成了Whisper和GPT-4o以自动生成SOAP笔记和患者指导。通过模拟测试和实际应用，该系统显著提高了笔记质量，减轻了临床医生的认知负荷和文档负担，并利用BART模型优化了笔记的简洁性，展现了AI在医疗行政支持方面的巨大潜力。

> **摘要翻译:** 临床医生职业倦怠促使人们在诊所中越来越多地采用环境医疗记录员。在这项工作中，我们介绍了一种定制的环境智能记录员应用程序，该应用程序集成到Included Health（一家提供远程医疗服务的个性化一体化医疗保健公司）的EHR系统中。该应用程序使用Whisper进行转录，并使用带有GPT-4o的模块化上下文学习管道自动生成SOAP笔记和患者指导。在模拟就诊数据上的测试表明，该应用程序生成的笔记质量超过了专家编写的笔记，由LLM-as-a-judge确定。该应用程序已被临床实践广泛采用，Included Health有超过540名临床医生至少使用过一次。94%（n = 63）的受访临床医生报告在使用该应用程序期间认知负荷降低，97%（n = 66）报告文档负担减轻。此外，我们表明使用微调的BART模型对笔记进行后处理可以提高简洁性。这些发现突出了AI系统减轻行政负担和支持临床医生提供高效、高质量护理的潜力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [420] [Towards Understanding Decision Problems As a Goal of Visualization Design](https://arxiv.org/abs/2507.18428)
> *旨在理解决策问题作为可视化设计的目的*

*Lena Cibulski, Stefan Bruckner* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 决策制定, 可视化设计, 特征化方案, 任务分析

**Comment:** 

> **TL;DR:** 本研究提出一个决策问题特征化方案，以更好地支持可视化中的决策任务。

**AI_Comments:** 这项研究的创新之处在于提供了一个结构化的方法来定义可视化设计中的决策问题，这对于开发更有效和目标明确的可视化工具至关重要。它填补了可视化研究中一个基础性的空白，即如何更精确地理解和支持决策任务。

<details>
  <summary>Details</summary>

**Motivation:** 在可视化研究中，决策制定是一个核心但未充分定义的目标。现有的任务模型虽然涉及决策过程，但往往忽略了构成决策的条件。

**Method:** 我们提出了一个特征化方案，通过数据、用户和任务上下文的关键属性来描述决策问题。

**Result:** 该方案有助于可视化研究人员更精确地指定决策支持主张，并指导适当的视觉编码和交互设计。我们通过将其应用于现有设计研究中的决策任务来证明了该方法的实用性。

**Conclusion:** 该研究突出了以决策为中心的可视化未来研究机会。

> **ai_Abstract:** 本研究旨在解决可视化研究中决策制定目标定义不足的问题，提出了一种决策问题特征化方案。该方案通过描述数据、用户和任务上下文的关键属性，帮助可视化研究人员更精确地指定决策支持主张，并指导适当的视觉编码和交互设计。研究通过将其应用于现有设计研究来证明了方法的实用性，并为未来以决策为中心的可视化研究指明了方向。

> **摘要翻译:** 决策制定是可视化研究中一个核心但未充分定义的目标。尽管现有的任务模型涉及决策过程，但它们常常忽视构成决策的条件。为了更好地支持决策制定任务，我们提出了一个特征化方案，通过数据、用户和任务上下文的关键属性来描述决策问题。该方案有助于可视化研究人员更精确地指定决策支持主张，并指导适当的视觉编码和交互。我们通过将其应用于现有设计研究中的决策任务来证明了我们方法的实用性，突出了以决策为中心的可视化未来研究机会。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [449] [Between Filters and Feeds: Investigating Douyin and WeChat's Influence on Chinese Adolescent Body Image](https://arxiv.org/abs/2507.17755)
> *滤镜与信息流之间：探究抖音和微信对中国青少年身体形象的影响*

*Jianfeng Lan, Yingjia Huang* | **Category: cs.HC, cs.CY, cs.SI** | **Updated: 2025-05-02**

**Keywords:** 社交媒体, 身体形象, 抖音, 微信, 青少年

**Comment:** 

> **TL;DR:** 本研究调查了抖音和微信对中国男性青少年身体形象的影响，发现抖音使用与身体形象显著相关，而微信则无。

**AI_Comments:** 本研究的创新点在于对比了两种不同类型的中国社交媒体平台（抖音和微信）对青少年身体形象的影响，并从“平台化”视角进行分析。其重要性在于揭示了平台特有的设计和内容模式对心理结果（如身体形象）的潜在影响，为青少年健康发展提供了新的视角和干预方向。

<details>
  <summary>Details</summary>

**Motivation:** 在数字时代，社交媒体平台在塑造青少年身体形象感知方面发挥着关键作用。本研究旨在探究抖音和微信这两种对比鲜明的中国社交媒体平台如何影响中国男性青少年的身体形象。

**Method:** 研究采用平台化视角，调查了395名年龄在10至24岁之间的男性青少年，使用多维度身体自我关系问卷-外貌量表（MBSRQ-AS）来评估自我评价和身体满意度。

**Result:** 研究结果显示，抖音使用与外貌评价和身体区域满意度显著相关，而微信使用与任何身体形象维度均无显著相关性。

**Conclusion:** 这些结果表明，抖音的算法驱动、以视频为中心的环境加剧了对理想身体标准的接触，从而在认知层面影响用户。本研究强调了在理解社交媒体对身体形象影响时考虑平台特定特征的重要性，并为解决中国男性青少年身体形象问题提供了见解。

> **ai_Abstract:** 本研究探讨了抖音和微信对中国男性青少年身体形象的影响。通过对395名10至24岁男性青少年的调查，发现抖音使用与外貌评价和身体区域满意度显著相关，而微信则无此关联。研究指出抖音的视频中心和算法驱动环境可能强化了理想身体标准，从而影响用户认知。这强调了理解社交媒体对身体形象影响时需考虑平台特性，并为解决中国青少年身体形象问题提供参考。

> **摘要翻译:** 在数字时代，社交媒体平台在塑造青少年身体形象感知方面发挥着关键作用。本研究调查了抖音和微信这两种对比鲜明的中国社交媒体平台如何影响中国男性青少年的身体形象。采用平台化视角，我们调查了395名年龄在10至24岁之间的男性青少年，使用多维度身体自我关系问卷-外貌量表（MBSRQ-AS）来评估自我评价和身体满意度。我们的研究结果显示，抖音使用与外貌评价和身体区域满意度显著相关，而微信使用与任何身体形象维度均无显著相关性。这些结果表明，抖音的算法驱动、以视频为中心的环境加剧了对理想身体标准的接触，从而在认知层面影响用户。本研究强调了在理解社交媒体对身体形象影响时考虑平台特定特征的重要性。它为关于技术设计和内容模式如何调节心理结果的更广泛讨论做出了贡献，为解决中国男性青少年身体形象问题提供了见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [455] [Effects of variation in system responsiveness on user performance in virtual environments](https://arxiv.org/abs/2507.18085)
> *系统响应性变化对虚拟环境中用户表现的影响*

*Benjamin Watson, Neff Walker, William Ribarsky, Victoria Spaulding* | **Category: cs.HC, cs.ET** | **Updated: 2025-07-24**

**Keywords:** 系统响应性, 虚拟环境, 用户表现, 标准差, 人机界面

**Comment:** 

> **TL;DR:** 研究发现，在虚拟环境中，系统响应性（SR）的标准差（SDSR）只有超过82毫秒时才会影响用户表现，并且放置任务对SR更敏感。

**AI_Comments:** 本研究的创新点在于明确区分了系统响应性的均值和标准差对用户表现的影响，并给出了SDSR影响性能的具体阈值（82毫秒）。其重要性在于为虚拟环境和交互式图形应用的设计提供了具体的指导原则，特别是关于何时需要关注响应性波动以及如何根据任务类型（如放置任务对视觉反馈的依赖性）进行优化。这有助于提升用户体验，减少不必要的系统性能优化投入。

<details>
  <summary>Details</summary>

**Motivation:** 系统响应性（SR）在虚拟环境中会随时间波动，需要用均值（MSR）和标准差（SDSR）进行统计描述。本研究旨在探讨SR的变异性如何影响用户在虚拟环境中的表现。

**Method:** 通过三项内部受试者设计研究，分别有11、12和10名参与者，考察了MSR和SDSR对抓取和放置任务表现的影响。研究中详细阐述了SR的组成部分以及实验测量和操作方法。

**Result:** 研究结果表明，只有当系统响应性标准差（SDSR）超过82毫秒时，才会影响用户表现。放置任务比抓取任务需要更频繁的视觉反馈，并且对系统响应性（SR）更为敏感。

**Conclusion:** 虚拟环境设计者无需严格控制系统响应性标准差（SDSR），并且可以根据所需的视觉反馈频率来调整SR控制策略。这些结果可用于改进各种交互式图形应用中的人机界面，包括科学可视化、训练、心理健康和娱乐。

> **ai_Abstract:** 本研究探讨了虚拟环境中系统响应性（SR）的变异性对用户表现的影响。SR通过均值（MSR）和标准差（SDSR）进行统计描述。通过三项针对抓取和放置任务的实验，研究发现SDSR仅在超过82毫秒时才会影响表现。此外，放置任务对SR更为敏感，因为它需要更频繁的视觉反馈。研究建议虚拟环境设计者无需过度关注SDSR的严格控制，并可根据视觉反馈需求调整SR策略，以优化人机交互界面。

> **摘要翻译:** 系统响应性（SR）被定义为系统响应用户控制所经过的时间。SR随时间波动，因此必须用均值（MSR）和标准差（SDSR）进行统计描述。在本文中，我们研究了虚拟环境（VEs）中的SR，概述了其组成部分以及实验测量和操作方法。然后介绍了三项关于MSR和SDSR对抓取和放置任务表现影响的研究。这些研究采用内部受试者设计，分别有11、12和10名参与者。结果显示，SDSR只有在超过82毫秒时才会影响表现。放置任务需要更频繁的视觉反馈，并且对SR更敏感。我们推断VE设计者无需严格控制SDSR，并且可能希望根据所需的视觉反馈频率来调整SR控制。这些结果可用于改进各种交互式图形应用中的人机界面，包括科学可视化、训练、心理健康和娱乐。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [468] [High-Dimensional Data Classification in Concentric Coordinates](https://arxiv.org/abs/2507.18450)
> *同心坐标中的高维数据分类*

*Alice Williams, Boris Kovalerchuk* | **Category: cs.HC, cs.LG** | **Updated: 2025-05-16**

**Keywords:** 高维数据, 同心坐标, 数据可视化, 机器学习, 平行坐标

**Comment:** 8 pages, 21 figures

> **TL;DR:** 本文提出了一种利用无损同心坐标对低维到高维数据进行可视化支持的框架，该框架是平行坐标和圆形坐标的更紧凑泛化，旨在解决现有高维数据可视化方法的局限性，并支持机器学习算法可视化和人机交互。

**AI_Comments:** 本文提出了一种新颖的同心坐标概念，作为平行坐标和圆形坐标的泛化，以解决高维数据可视化中的关键挑战，如无损性和遮挡。其创新点在于将这些坐标形式化为通用线坐标，并强调其在机器学习算法可视化和人机交互中的潜在应用。如果能提供具体的实现细节和性能评估，将进一步增强其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有解释性多维数据可视化方法在高维无损可视化方面存在局限性，面临遮挡问题且受参数化可视化计算能力的限制。

**Method:** 本文提出了一种支持低维到高维数据的框架，该框架使用无损同心坐标。同心坐标是平行坐标和圆形坐标的更紧凑泛化，属于通用线坐标可视化形式，能够直接支持机器学习算法可视化并促进人机交互。

**Result:** 摘要中未提及。

**Conclusion:** 摘要中未提及。

> **ai_Abstract:** 本文针对现有高维数据可视化方法在无损性、遮挡和计算能力方面的局限性，提出了一种基于无损同心坐标的低维到高维数据可视化框架。同心坐标是平行坐标和圆形坐标的紧凑泛化，属于通用线坐标可视化，旨在直接支持机器学习算法的可视化并增强人机交互。

> **摘要翻译:** 多维数据通过可解释方法进行可视化仍然受到高维无损可视化能力的限制，这些可视化既不会出现遮挡，也无法通过参数化可视化实现计算能力。本文提出了一种支持低维到高维数据的框架，该框架使用无损同心坐标，它们是平行坐标和圆形坐标的更紧凑泛化。这些是通用线坐标可视化的一种形式，可以直接支持机器学习算法可视化并促进人机交互。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [493] [Insights from Railway Professionals: Rethinking Railway assumptions regarding safety and autonomy](https://arxiv.org/abs/2507.17756)
> *铁路专业人士的见解：重新思考铁路关于安全和自主的假设*

*Josh Hunter, John McDermid, Simon Burton* | **Category: cs.HC, cs.AI** | **Updated: 2025-05-06**

**Keywords:** 铁路安全, 自动化, 辅助技术, 铁路专业人士, 因果模型

**Comment:** 9 pages, 3 figures, published in European Dependable Computing
  Conference 2025

> **TL;DR:** 本研究通过访谈铁路专业人士，探讨他们对安全的看法，发现他们对自动化持谨慎态度，偏好辅助技术，并强调需要为铁路开发特定的安全模型。

**AI_Comments:** 本研究通过定性访谈提供了宝贵的行业内部视角，揭示了铁路专业人士对安全和自动化的复杂看法。其创新之处在于强调了铁路系统与汽车系统的差异性，并指出需要针对铁路特性开发专属的安全评估和增强模型。这对于未来铁路自动化技术的发展具有重要指导意义，有助于避免盲目照搬其他行业的经验。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在了解铁路专业人士如何看待铁路中的安全概念，以期为未来行业内的技术发展提供信息，并弥合当代研究与实际应用之间的差距，从而有助于开发更有效的安全指标。

**Method:** 通过对司机、线路规划员和行政人员进行一系列访谈。

**Result:** 主要发现包括：对自动化持谨慎态度；偏好辅助技术；对安全有复杂的理解，整合了人为、系统和技术因素。研究还指出汽车自动化技术难以直接应用于铁路，以及需要一个铁路特定的因果模型来更好地评估和提高安全。

**Conclusion:** 本研究强调了铁路专业人士对安全的复杂理解以及对自动化的谨慎态度，并指出为铁路开发特定安全模型的重要性，以有效提升在技术发展中的安全水平。

> **ai_Abstract:** 本研究通过访谈铁路司机、线路规划员和行政人员，深入探讨了铁路专业人士对安全的认知及其与未来技术发展的关系。研究发现，专业人士对自动化持谨慎态度，更倾向于辅助技术，并认为安全是一个融合了人、系统和技术因素的复杂概念。论文强调了汽车自动化技术在铁路领域应用的局限性，并呼吁开发铁路特有的安全因果模型，以适应不断变化的技术环境，旨在促进更有效的安全指标的制定。

> **摘要翻译:** 本研究调查了铁路专业人士如何看待铁路中的安全概念，旨在为行业未来的技术发展提供信息。通过对司机、线路规划员和行政人员进行一系列访谈，研究探讨了当前的安全实践状况、自动化的潜力以及将铁路理解为一个系统之系统。主要发现强调了对自动化的谨慎态度、对辅助技术的偏好，以及对安全复杂的理解，这种理解整合了人为、系统和技术因素。研究还探讨了将汽车自动化技术转移到铁路的局限性，以及需要一个铁路特定的因果模型来更好地评估和增强不断发展的技术环境中的安全性。本研究旨在弥合当代研究与实际应用之间的差距，为开发更有效的安全指标做出贡献。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [516] [ForcePinch: Force-Responsive Spatial Interaction for Tracking Speed Control in XR](https://arxiv.org/abs/2507.18510)
> *ForcePinch：XR中用于跟踪速度控制的力响应空间交互*

*Chenyang Zhang, Tiffany S Ma, John Andrews, Eric J Gonzalez, Mar Gonzalez-Franco, Yalong Yang* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 力响应交互, 空间交互, 跟踪速度控制, XR, ForcePinch

**Comment:** 

> **TL;DR:** ForcePinch是一种新的力响应空间交互方法，通过捏合力调整指针跟踪速度，实现XR环境中快速和精确移动的平滑过渡。

**AI_Comments:** ForcePinch的创新点在于将捏合力作为调节跟踪速度的输入，模拟了物理世界中的摩擦控制，这提供了一种比传统手部运动耦合更直观和灵活的交互方式。其重要性在于为XR环境中的效率与精度平衡提供了新的解决方案，并为未来的空间交互设计提供了启发。

<details>
  <summary>Details</summary>

**Motivation:** 现有空间交互技术将跟踪速度调整与手部运动直接耦合，降低了交互灵活性；需要一种平衡效率和精度的动态跟踪速度调整方法。

**Method:** 引入ForcePinch，一种力响应空间交互方法，通过改变捏合力直观地调节指针跟踪速度。开发了一个集成了压力传感器和可定制映射功能的硬件原型。对20名参与者进行了用户研究，执行1D、2D和3D对象操作任务，并将ForcePinch与距离响应技术Go-Go和速度响应技术PRISM进行了比较。

**Result:** 用户研究结果突出了力响应方法在不同交互环境中的独特特性。

**Conclusion:** 力响应交互在XR空间交互设计中具有情境意义和多功能性，为未来的空间交互设计提供了启发。

> **ai_Abstract:** 本文提出了ForcePinch，一种基于捏合力调节XR环境中指针跟踪速度的力响应空间交互方法，旨在解决现有技术中跟踪速度与手部运动耦合导致交互灵活性降低的问题。通过开发硬件原型并进行用户研究，将ForcePinch与Go-Go和PRISM进行比较，结果表明力响应方法在不同交互情境下具有独特优势，强调了其在未来空间交互设计中的潜力和多功能性。

> **摘要翻译:** 三维环境中的空间交互需要平衡效率和精度，这要求动态调整跟踪速度。然而，现有技术通常将跟踪速度调整与手部运动直接耦合，降低了交互灵活性。受物理世界中固有的自然摩擦控制的启发，我们引入了ForcePinch，一种新颖的力响应空间交互方法，它允许用户通过改变捏合力直观地调节指针跟踪速度，并在快速和精确移动之间平滑过渡。为了实现这一概念，我们开发了一个硬件原型，该原型集成了压力传感器和可定制的映射功能，可将捏合力转换为跟踪速度调整。我们对20名参与者进行了一项用户研究，他们执行了成熟的1D、2D和3D对象操作任务，将ForcePinch与距离响应技术Go-Go和速度响应技术PRISM进行了比较。结果突出了力响应方法在不同交互环境中的独特特性。根据这些发现，我们通过四个说明性示例强调了力响应交互的情境意义和多功能性，旨在为未来的空间交互设计提供信息和启发。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [539] [BrisT1D Dataset: Young Adults with Type 1 Diabetes in the UK using Smartwatches](https://arxiv.org/abs/2507.17757)
> *BrisT1D 数据集：英国使用智能手表的年轻1型糖尿病患者*

*Sam Gordon James, Miranda Elaine Glynis Armstrong, Aisling Ann O'Kane, Harry Emerson, Zahraa S. Abdallah* | **Category: cs.HC, cs.LG** | **Updated: 2025-05-07**

**Keywords:** 1型糖尿病, 智能手表, 数据集, 数字健康, 纵向研究

**Comment:** 13 pages, 14 figures

> **TL;DR:** BrisT1D 数据集是一个新的公共数据集，包含英国24名年轻1型糖尿病患者的智能手表和血糖管理系统数据，以及访谈记录，旨在促进糖尿病管理技术和用户体验的研究。

**AI_Comments:** BrisT1D 数据集通过结合定量设备数据和定性访谈数据，提供了一个独特且全面的视角来研究智能手表在1型糖尿病管理中的实际应用和用户体验。其创新之处在于提供了原始和处理后的数据，以及访谈记录，这使得研究人员能够进行多维度分析。该数据集对于推动T1D管理技术的发展和理解数字健康工具的社会影响具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 1型糖尿病（T1D）管理技术发展迅速，但其进一步发展需要探索实际使用情况和额外的数据流。为了促进这一目标，需要更多公开的T1D管理数据集。

**Method:** BrisT1D 数据集来源于一项对24名英国年轻成年人的纵向研究，这些参与者在使用常规T1D管理的同时佩戴智能手表。数据集包含来自T1D管理系统和智能手表的设备数据（包括处理过的和原始数据），以及研究期间每月访谈和焦点小组的笔录。

**Result:** BrisT1D 数据集包含参与者使用的T1D管理系统和智能手表的设备数据，以及每月访谈和焦点小组的笔录。设备数据提供处理后的状态以方便使用和快速分析，也提供原始状态以进行深入探索。

**Conclusion:** 该数据集具有广泛的潜在应用。其定量元素可支持血糖预测、低血糖预测和闭环算法开发。定性元素可用于探索用户体验和观点，以及对智能手表在T1D管理中作用的混合方法研究。

> **ai_Abstract:** BrisT1D 数据集是一个新发布的公共数据集，旨在促进1型糖尿病（T1D）管理技术的研究和发展。该数据集来源于一项对24名英国年轻T1D患者的纵向研究，他们日常使用智能手表。它整合了来自T1D管理系统和智能手表的设备数据（包括原始和处理过的格式）以及每月访谈和焦点小组的定性记录。该数据集可用于定量分析，如血糖和低血糖预测，以及定性研究，以理解用户体验和智能手表在T1D管理中的作用。

> **摘要翻译:** 背景：1型糖尿病（T1D）的管理技术发展迅速，为未来其他慢性病的管理提供了一个有用的案例研究。这种管理技术的进一步发展需要探索其实际使用情况和额外数据流的潜力。为了促进这一点，我们将BrisT1D数据集贡献给日益增多的公共T1D管理数据集。该数据集来自一项对英国24名年轻成年人的纵向研究，他们在常规T1D管理的同时使用了智能手表。发现：BrisT1D数据集包含参与者使用的T1D管理系统和智能手表的设备数据，以及研究期间进行的每月访谈和焦点小组的笔录。设备数据以处理后的状态提供，以便于使用和更快速的分析，也以原始状态提供，以便深入探索研究中捕获的新颖见解。结论：该数据集具有一系列潜在应用。其定量元素可以支持血糖预测、低血糖预测和闭环算法开发。定性元素可以探索用户体验和观点，以及对智能手表在T1D管理中作用的更广泛的混合方法研究。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [564] [PosterMate: Audience-driven Collaborative Persona Agents for Poster Design](https://arxiv.org/abs/2507.18572)
> *PosterMate: 受众驱动的协作式角色代理用于海报设计*

*Donghoon Shin, Daniel Lee, Gary Hsieh, Gromit Yeuk-Yin Chan* | **Category: cs.HC, cs.AI, cs.CL, H.5.2; I.2.7** | **Updated: 2025-07-24**

**Keywords:** 海报设计, 协作, 角色代理, 生成式AI, 反馈系统

**Comment:** 

> **TL;DR:** PosterMate是一个海报设计助手，它利用基于营销文档构建的受众驱动的角色代理来收集反馈并促进讨论，从而帮助设计师整合修改意见。用户研究表明它能捕捉被忽视的观点并作为有效的原型工具。

**AI_Comments:** PosterMate的创新之处在于将生成式AI与协作设计相结合，通过模拟不同受众角色来提供反馈，这有效地解决了传统设计反馈中收集和协调多样化观点的难题。其基于营销文档构建角色代理的方法具有独特性，并且用户研究和在线评估的结果验证了其有效性和实用性，特别是作为原型工具的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 海报设计可以从目标受众的同步反馈中受益，但收集具有不同观点的受众并协调他们的设计修改意见具有挑战性。虽然生成式AI模型提供了模拟人类交互的机会，但尚不清楚如何将其用于设计反馈过程。

**Method:** 我们引入了PosterMate，一个海报设计助手。它通过创建基于营销文档构建的受众驱动的角色代理来促进协作。PosterMate从每个角色代理收集关于海报组件的反馈，并在主持人的帮助下激发讨论以达成结论。这些达成一致的修改可以直接整合到海报设计中。

**Result:** 通过用户研究（N=12），我们发现PosterMate有潜力捕捉被忽视的观点，同时作为一种有效的原型工具。此外，受控在线评估（N=100）显示，个体角色代理的反馈与其角色身份相符，并且讨论有效地综合了不同角色代理的观点。

**Conclusion:** PosterMate展示了捕捉被忽视观点并作为有效原型工具的潜力，其角色代理的反馈是恰当的，且讨论能有效综合不同视角。

> **ai_Abstract:** PosterMate是一个创新的海报设计助手，旨在解决获取和协调设计反馈的挑战。它利用基于营销文档构建的受众驱动的角色代理来模拟不同视角的反馈，并通过主持人引导讨论以达成共识。用户研究和在线评估证实了PosterMate在捕捉被忽视观点、作为有效原型工具以及有效整合多样化反馈方面的潜力。

> **摘要翻译:** 海报设计可以从目标受众的同步反馈中受益。然而，召集具有不同视角的受众并在设计修改上协调他们可能具有挑战性。最近的生成式人工智能模型提供了模拟类人交互的机会，但尚不清楚它们如何用于设计中的反馈过程。我们引入了PosterMate，一个海报设计助手，它通过创建基于营销文档构建的受众驱动的角色代理来促进协作。PosterMate从每个角色代理收集关于海报组件的反馈，并在主持人的帮助下激发讨论以达成结论。这些达成一致的修改可以直接整合到海报设计中。通过我们的用户研究（N=12），我们发现PosterMate有潜力捕捉被忽视的观点，同时作为一种有效的原型工具。此外，我们的受控在线评估（N=100）显示，个体角色代理的反馈与其角色身份相符，并且讨论有效地综合了不同角色代理的观点。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [587] [DHMS: A Digital Hostel Management System Integrating Campus ChatBot, Predictive Intelligence, and Real-Time Automation](https://arxiv.org/abs/2507.17759)
> *DHMS：一个集成校园聊天机器人、预测智能和实时自动化的数字宿舍管理系统*

*Riddhi Heda, Sidhant Singh, Umair Yasir, Tanmay Jaiswal, Anil Mokhade* | **Category: cs.HC** | **Updated: 2025-05-08**

**Keywords:** 数字宿舍管理, 聊天机器人, 预测智能, 自动化, 校园管理

**Comment:** 

> **TL;DR:** DHMS是一个数字宿舍管理系统，通过集成校园聊天机器人、预测智能和实时自动化，解决传统宿舍管理效率低下、沟通碎片化的问题，并在模拟测试中显示出高学生满意度和快速响应时间。

**AI_Comments:** DHMS的创新之处在于其将多项现代技术（如AI聊天机器人、预测分析、云基础设施）集成到一个统一的宿舍管理平台中，有效解决了传统管理的痛点。其在模拟测试中展现出的高学生满意度和快速响应时间是其重要性体现。然而，论文也明确指出了系统在实际大规模部署前，在集成、可扩展性、用户接受度和ERP兼容性方面仍需进一步验证，这是其当前的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的学术机构宿舍管理效率低下、延迟且沟通碎片化，无法满足数字化时代学生的需求，并给宿舍管理人员带来沉重的运营负担。

**Method:** 本文提出了DHMS（数字宿舍管理系统），一个模块化且集成的平台，旨在数字化和简化核心宿舍管理功能。DHMS利用现代网络技术、人工智能和云基础设施，通过自然语言聊天机器人自动化房间分配、申诉处理、出门条物流和沟通。它还包括用于主动维护计划的预测分析和用于反馈处理的情感分析。

**Result:** 在模拟测试中，DHMS在房间分配方面实现了92%的学生满意度，并保持了聊天机器人平均响应时间低于一秒。它还提供了预测分析和情感分析功能。

**Conclusion:** DHMS系统前景广阔，但仍需在多栋宿舍楼集成、用户接受度、负载下的可扩展性以及与ERP系统的兼容性方面进行进一步测试，才能在全校范围内部署。该工作讨论了系统架构、实施方法以及对提升用户体验、管理效率和决策过程至关重要的因素。

> **ai_Abstract:** 本文介绍了DHMS，一个数字宿舍管理系统，旨在解决传统宿舍管理中的低效率和沟通问题。该系统通过集成聊天机器人、预测智能和自动化，实现了房间分配、申诉处理等功能的数字化和自动化。模拟测试显示其在学生满意度和响应时间方面表现出色。研究还讨论了系统架构和未来部署所需的测试。

> **摘要翻译:** 学术机构的传统宿舍管理实践常常面临效率低下、延迟和沟通碎片化的问题。这些系统未能满足数字化时代学生的期望，并给宿舍工作人员带来了巨大的运营负担。本文介绍了DHMS（数字宿舍管理系统），一个模块化、集成平台，旨在数字化和简化核心宿舍管理功能。DHMS利用现代网络技术、人工智能和云基础设施，通过自然语言聊天机器人自动化房间分配、申诉处理、出门条物流和沟通。在模拟测试中，DHMS在房间分配方面实现了92%的学生满意度，并保持了聊天机器人平均响应时间低于一秒。附加功能包括用于主动维护计划的预测分析和用于反馈处理的情感分析。尽管前景广阔，该系统在全校范围内部署之前，还需要在多栋宿舍楼集成、用户接受度、负载下的可扩展性以及与ERP系统的兼容性方面进行进一步测试。这项工作讨论了系统架构、实施方法以及对提升用户体验、管理效率和决策过程至关重要的因素。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [612] [MeloKids: Multisensory VR System to Enhance Speech and Motor Coordination in Children with Hearing Loss](https://arxiv.org/abs/2507.18619)
> *MeloKids：多感官VR系统以增强听力障碍儿童的言语和运动协调能力*

*Yichen Yu, Qiaoran Wang* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 听力障碍儿童, 虚拟现实, 多感官反馈, fNIRS, 言语与运动协调

**Comment:** 

> **TL;DR:** 研究多感官VR系统如何通过整合听觉、视觉和触觉刺激来改善听力障碍儿童的语言和运动康复，并使用fNIRS评估大脑活动。

**AI_Comments:** 这项研究通过结合VR技术和多感官反馈，为听力障碍儿童的康复提供了一种创新的方法。使用fNIRS技术评估大脑皮层激活模式，增加了研究的科学严谨性，有助于理解这种干预措施的神经生理基础。其重要性在于为个性化和交互式康复系统的设计提供了潜在的证据支持。

<details>
  <summary>Details</summary>

**Motivation:** 听力障碍儿童在语言和运动发展方面面临持续挑战，因此需要探索新的技术来增强康复效果。

**Method:** 该研究探索了基于虚拟现实（VR）的多感官反馈技术，整合听觉、视觉和触觉刺激，以增强康复效果。研究使用功能性近红外光谱（fNIRS）技术，评估了儿童在不同互动模式下进行音高匹配任务时的大脑皮层激活模式。

**Result:** 研究结果旨在为设计个性化、交互式康复系统提供证据，以增强听力障碍儿童的认知参与和运动控制。

**Conclusion:** 该研究的发现旨在为开发个性化、交互式康复系统提供证据，从而改善听力障碍儿童的认知参与和运动控制。

> **ai_Abstract:** 该研究旨在解决听力障碍儿童在语言和运动发展上的挑战。通过探索一种名为MeloKids的多感官VR系统，该系统整合了听觉、视觉和触觉刺激，以期增强康复效果。研究利用fNIRS技术评估了儿童在音高匹配任务中的大脑皮层激活模式，其发现旨在为开发个性化、交互式康复系统提供依据，从而提升听力障碍儿童的认知参与和运动控制能力。

> **摘要翻译:** 听力障碍儿童在语言和运动发展方面面临持续挑战。本研究探讨了基于虚拟现实（VR）的多感官反馈技术，如何通过整合听觉、视觉和触觉刺激来增强康复效果。我们使用功能性近红外光谱（fNIRS）技术，评估了儿童在不同互动模式下进行音高匹配任务时的大脑皮层激活模式。我们的发现旨在为设计个性化、交互式康复系统提供证据，以增强听力障碍儿童的认知参与和运动控制。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [635] [Co-constructing Explanations for AI Systems using Provenance](https://arxiv.org/abs/2507.17761)
> *利用溯源共同构建AI系统解释*

*Jan-Christoph Kalo, Fina Polat, Shubha Guha, Paul Groth* | **Category: cs.HC** | **Updated: 2025-05-31**

**Keywords:** AI可解释性, 数据溯源, 共同构建, 交互式代理, 大型语言模型

**Comment:** 5 pages

> **TL;DR:** AI系统解释太复杂，我们提出一个交互式代理，利用数据溯源与用户共同构建有用的解释，并展示了原型和评估框架。

**AI_Comments:** 本文的创新点在于提出了“共同构建”解释的概念，并结合了数据溯源和交互式代理，以及利用大型语言模型进行评估，这为AI可解释性提供了一个新颖且实用的方向。其愿景有望提升AI系统解释的用户体验和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现代AI系统复杂，其输出难以理解。数据溯源虽然能帮助解释，但通常过于详细且缺乏上下文，用户难以有效理解AI系统。

**Method:** 提出一个交互式代理的愿景，该代理与用户协同工作，共同构建既对用户有用又基于数据溯源的解释。为实现此愿景，展示了一个初步原型和一个基于用户模拟及大型语言模型作为评判者的可扩展评估框架。

**Result:** 提出了一个交互式代理的初步原型，以及一个基于用户模拟和以大型语言模型作为评判方法的可扩展评估框架。

**Conclusion:** 该工作提出了一个通过共同构建解释来解决AI系统可解释性挑战的愿景，并展示了初步实现和评估方法，为AI解释提供了一个新颖方向。

> **ai_Abstract:** 本文提出了一个利用交互式代理与用户共同构建AI系统解释的愿景，旨在解决传统数据溯源解释过于详细且缺乏上下文的问题。作者展示了一个初步原型和一个基于用户模拟与大型语言模型相结合的评估框架，以验证此方法的可行性。

> **摘要翻译:** 现代人工智能系统是包含多个组件和数据源的复杂工作流程。数据溯源提供了询问和潜在解释这些系统输出的能力。然而，溯源通常过于详细且对于试图理解人工智能系统的用户来说缺乏上下文。在这项工作中，我们提出了一个交互式代理的愿景，它与用户协同工作，共同构建一个对用户有用且基于数据溯源的解释。为了阐明这一愿景，我们展示了：1) 这样一个代理的初步原型；2) 一个基于用户模拟和以大型语言模型作为评判方法的可扩展评估框架。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [660] [Evaluation of a Provenance Management Tool for Immersive Virtual Fieldwork](https://arxiv.org/abs/2507.18622)
> *沉浸式虚拟野外工作中溯源管理工具的评估*

*Armin Bernstetter, Tom Kwasnitschka, Isabella Peters* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 溯源管理, 虚拟野外工作, 可重复性, 易用性, 有用性

**Comment:** Accepted for Mensch und Computer 2025 Short Paper Track

> **TL;DR:** 本研究评估了一个用于沉浸式虚拟野外工作的溯源管理工具，发现它在可用性和有用性方面受到用户的好评，但在不同沉浸式设置下的使用模式没有显著差异。

**AI_Comments:** 这项研究的创新在于将溯源管理工具应用于沉浸式虚拟野外工作这一特定领域，并进行了用户评估。其重要性在于强调了在地球科学等领域中确保研究可重复性的需求。研究结果表明该工具具有实用性，但关于沉浸式环境对使用行为的影响仍需进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 确保研究的可重复性是良好科学实践的重要组成部分，尤其是在地球科学等领域，研究人员使用软件进行地理空间数据的交互式和沉浸式可视化，并在3D模型上进行虚拟测量。溯源信息对于支持研究工作流至关重要。

**Method:** 我们评估了一个溯源管理工具（数字实验手册，DLB），该工具允许记录与虚拟野外工具的交互并注释可视化状态。通过用户研究，调查了研究人员如何使用DLB，以及在沉浸式或非沉浸式设置中，感知到的易用性和感知到的有用性是否存在差异。

**Result:** 参与者认为DLB既有用又易于使用。虽然有迹象表明感知到的易用性存在差异（沉浸式设置中更高），但使用模式没有显示出显著的组间差异。

**Conclusion:** 溯源管理工具在虚拟野外工作中被认为是有效且易于使用的，能够支持研究的可重复性，尽管在不同沉浸式环境下的使用行为模式未显示出显著差异。

> **ai_Abstract:** 本研究评估了一个用于沉浸式虚拟野外工作的溯源管理工具（数字实验手册，DLB），旨在提高研究的可重复性。通过用户研究，发现研究人员普遍认为该工具既有用又易于使用。尽管在沉浸式环境中感知到的易用性更高，但在沉浸式与非沉浸式设置下，工具的使用模式并未显示出显著差异。

> **摘要翻译:** 确保研究的可重复性是良好科学实践不可或缺的一部分。支持这一点的一种方法是溯源：关于从数据收集到研究人员理解过程（最终形成发表结果）的研究工作流程信息。这在地球科学等学科中尤为重要，在这些学科中，研究人员使用软件进行地理空间数据的交互式和沉浸式可视化，在3D模型上进行模拟野外工作中的虚拟测量。我们评估了一个溯源管理工具，该工具允许记录与虚拟野外工具的交互并注释可视化的不同状态。用户研究调查了研究人员如何使用这种数字实验手册（DLB），以及在沉浸式或非沉浸式设置中，感知到的易用性和感知到的有用性是否存在差异。参与者认为DLB既有用又易于使用。虽然有迹象表明感知到的易用性存在差异（沉浸式设置中更高），但使用模式没有显示出显著的组间差异。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [677] [Human-AI Co-Creation: A Framework for Collaborative Design in Intelligent Systems](https://arxiv.org/abs/2507.17774)
> *人机协同创作：智能系统中协作设计的框架*

*Zhangqi Liu* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 人机协同创作, 协作设计, 智能系统, 大型语言模型, 多模态扩散模型

**Comment:** 

> **TL;DR:** 本文探讨了人机协同创作的新范式，其中AI作为积极的协作伙伴参与到设计过程的早期阶段，利用大型语言模型和多模态扩散模型作为创意代理进行迭代设计。

**AI_Comments:** 本文的创新之处在于提出了AI不仅仅是自动化工具，而是能够积极参与设计早期阶段的协作伙伴这一理念。它强调了AI在构思、视觉化和决策中的作用，并具体指出了LLMs和多模态扩散模型在这一过程中的潜力，这对于未来人机交互和创意产业的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能从后端计算工具发展为交互式、生成式协作伙伴，将其整合到早期设计过程中，需要重新思考以人为中心设计中的传统工作流程。

**Method:** 本文研究了人机协同创作的新范式，其中AI不仅用于自动化或提高效率，而是积极参与到构思、视觉概念化和决策中。具体而言，研究了GPT-4等大型语言模型和Stable Diffusion等多模态扩散模型作为创意代理，与设计师进行提案、批评和修订的迭代循环。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种人机协同创作的框架，旨在重新定义智能系统中的协作设计。随着AI从单纯的工具转变为生成式协作伙伴，研究指出需要将AI更深入地融入早期设计流程。该研究特别探讨了大型语言模型（如GPT-4）和多模态扩散模型（如Stable Diffusion）作为创意代理，如何与设计师在构思、视觉概念化和决策等环节进行迭代式的提案、批评与修订。

> **摘要翻译:** 随着人工智能（AI）不断从后端计算工具演变为交互式、生成式协作伙伴，其整合到早期设计过程中要求重新思考以人为中心设计的传统工作流程。本文探讨了人机协同创作的新兴范式，其中AI不再仅仅用于自动化或提高效率，而是积极参与到构思、视觉概念化和决策中。具体而言，我们研究了GPT-4等大型语言模型和Stable Diffusion等多模态扩散模型作为创意代理，与设计师进行提案、批评和修订的迭代循环。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [701] [Automated Brake Onset Detection in Naturalistic Driving Data](https://arxiv.org/abs/2507.17943)
> *自然驾驶数据中自动刹车起始点检测*

*Shu-Yuan Liu, Johan Engström, Gustav Markkula* | **Category: cs.HC, cs.RO** | **Updated: 2025-07-23**

**Keywords:** 自动刹车检测, 响应时间, 自然驾驶数据, 自动驾驶系统, 分段线性加速度模型

**Comment:** 

> **TL;DR:** 该研究开发了一种简单高效的算法，用于在缺乏车辆控制信号的大规模驾驶数据中自动检测刹车起始点，以评估自动驾驶系统和人类驾驶员的响应时间。

**AI_Comments:** 该论文的创新之处在于提出了一种不依赖传统车辆控制信号的自动刹车起始点检测方法，这对于处理大规模、非结构化驾驶数据（特别是ADS日志数据）具有重要意义。其方法的通用性和可配置性是亮点，使其能够广泛应用于不同类型的驾驶数据和用户。局限性在于算法的具体性能指标（R2值）和特定限制未在摘要中详细说明。

<details>
  <summary>Details</summary>

**Motivation:** 在评估自动驾驶系统（ADS）的碰撞规避场景中，响应时间测量至关重要，但现有方法（手动标注或依赖车辆控制信号）不适用于缺乏此类信号的大规模数据，尤其是在快速增长的ADS日志数据中。

**Method:** 开发了一种基于分段线性加速度模型的简单高效算法，用于自动估计刹车起始点，适用于任何包含车辆纵向时间序列数据的驾驶数据。同时提出了一种手动标注方法作为真值进行验证，并使用R2作为置信度指标来衡量算法精度，通过自然驾驶碰撞规避数据（ADS和人类）与人工标注进行对比验证。

**Result:** 该算法能够有效检测刹车起始点，并已通过人类手动标注验证。尽管存在一定局限性，但它高效、通用、适用于任何道路使用者和场景类型，且高度可配置。

**Conclusion:** 所提出的自动刹车起始点检测算法克服了现有方法在处理大规模驾驶数据时缺乏车辆控制信号的局限性，为自动驾驶系统评估提供了一种通用且高效的响应时间测量工具。

> **ai_Abstract:** 该研究提出了一种基于分段线性加速度模型的自动刹车起始点检测算法，旨在解决大规模自然驾驶数据中缺乏车辆控制信号时评估自动驾驶系统响应时间的问题。该算法高效、通用，并通过人工标注的碰撞规避数据进行了验证，克服了传统方法的局限性，可应用于各种驾驶数据和场景。

> **摘要翻译:** 响应时间测量在评估自动驾驶系统（ADS）的碰撞规避场景中扮演着关键角色，包括但不限于建立人类基准和比较ADS与人类驾驶员的响应表现。例如，测量（人类驾驶员或ADS）对冲突的响应时间需要确定刺激起始点和响应起始点。在现有研究中，响应起始点依赖于手动标注或车辆控制信号，如加速踏板和制动踏板的运动。当分析缺乏车辆控制信号的大规模数据时，这些方法不适用。这尤其适用于快速扩展的ADS日志数据，其中通过车载传感器观察周围道路使用者的行为。为了改进ADS的评估技术，并在车辆控制信号不可用时实现响应时间测量，我们开发了一种简单高效的算法，该算法基于分段线性加速度模型，用于自动估计刹车起始点，可应用于任何包含车辆纵向时间序列数据的驾驶数据。我们还提出了一种手动标注方法来识别刹车起始点，并将其用作验证的真值。R2被用作置信度指标来衡量算法的准确性，并使用ADS和人类的自然驾驶碰撞规避数据分析了其分类性能，其中我们的方法通过人类手动标注进行了验证。尽管我们的算法受到某些限制，但它高效、通用、适用于任何道路使用者和场景类型，并且高度可配置。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [719] [Same Data, Different Audiences: Using Personas to Scope a Supercomputing Job Queue Visualization](https://arxiv.org/abs/2507.17898)
> *相同数据，不同受众：使用角色来界定超级计算作业队列可视化的范围*

*Connor Scully-Allison, Kevin Menear, Kristin Potter, Andrew McNutt, Katherine E. Isaacs, Dmitry Duplyakin* | **Category: cs.HC** | **Updated: 2025-07-23**

**Keywords:** 角色, 可视化, 超级计算, 多受众, 设计研究

**Comment:** 11 Pages, 4 figures

> **TL;DR:** 开发了一个名为 Guidepost 的可视化工具，通过使用角色（personas）来支持不同用户群体对同一超算队列数据的分析，平衡了广度和特定任务支持。

**AI_Comments:** 该论文的创新之处在于将人机交互和软件工程领域的角色（personas）概念创造性地应用于可视化设计，以解决同一数据但不同受众的可视化需求。它提供了一种平衡通用实用性与特定任务支持的有效方法，对于开发多用户可视化工具具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 领域特定可视化工具通常只专注于特定用户群体的狭窄任务，这限制了它们对处理相同数据的其他用户群体的效用。本研究旨在探索如何开发能够支持多个用户群体的可视化工具，以提升整体实用性。

**Method:** 本研究通过一个设计研究，开发了名为 Guidepost 的笔记本嵌入式超算队列数据可视化工具，旨在帮助科学家评估队列等待时间、机器学习研究人员理解预测准确性，以及系统维护人员分析使用趋势。研究借鉴了人机交互和软件工程领域的人格（personas）概念，并将其应用于根据利益相关者角色的任务独特性进行分类。其模型是：所有群体共享的任务应由交互式可视化支持，而各群体独有的任务则可延迟到与笔记本嵌入式可视化设计结合的脚本编程。通过与九位专家分析师（分为“研究分析师”和“超算用户”两组）进行评估。

**Result:** 研究发现，Guidepost 可视化工具通过点选交互使用户能够成功执行共享任务，同时促进了特定案例的编程分析工作流程，从而有效服务了其三个利益相关者群体。

**Conclusion:** 通过将角色（personas）方法应用于可视化设计，可以有效地为使用相同数据的不同用户群体开发出既能支持共享任务又能兼顾特定编程分析需求的工具，从而提升可视化的整体效用。

> **ai_Abstract:** 本研究旨在解决领域特定可视化对多用户群体效用受限的问题。通过一项设计研究，开发了名为 Guidepost 的笔记本嵌入式超算队列数据可视化工具。该工具借鉴了人机交互和软件工程领域的角色（personas）概念，将任务分为共享任务（由交互式可视化支持）和独特任务（由脚本编程与嵌入式可视化结合支持）。评估结果显示，Guidepost 成功地通过点选交互支持了用户的共享任务，并促进了案例特定的编程分析流程，从而有效服务了科学家、机器学习研究人员和系统维护人员等多个利益相关者群体。

> **摘要翻译:** 领域特定可视化有时专注于为一组用户提供狭窄但重要的任务。这种专注限制了可视化对使用相同数据的其他群体的效用。虽然从其他群体引出的任务如果未明确区分可能会带来设计陷阱，但它们也提供了设计机会——开发支持多个群体的可视化。这种开发选择带来了权衡，即扩大了范围但限制了对任何一个群体更狭窄任务的支持，这在某些情况下可以增强可视化的整体效用。我们通过一项设计研究调查了这种情况，在该研究中，我们开发了 Guidepost，这是一种笔记本嵌入式超级计算机队列数据可视化工具，可帮助科学家评估超级计算机队列等待时间、机器学习研究人员理解预测准确性以及系统维护人员分析使用趋势。我们借鉴人机交互和软件工程领域现有文献中角色（personas）在可视化设计中的应用，并将其应用于根据利益相关者角色的任务独特性进行分类。在该模型下，所有群体共享的任务应由交互式可视化支持，而各群体独有的任务则可延迟到与笔记本嵌入式可视化设计结合的脚本编程。我们使用九位专家分析师评估了我们的可视化工具，他们分为两组：“研究分析师”组，在研究中使用超级计算机队列数据（代表机器学习研究人员和作业数据分析师角色），以及“超级计算机用户”组，有条件地使用此数据（代表 HPC 用户角色）。我们发现，我们的可视化工具通过使用户能够通过点选交互成功执行共享任务，同时促进了特定案例的编程分析工作流程，从而服务了我们的三个利益相关者群体。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [755] [Decoding Instructional Dialogue: Human-AI Collaborative Analysis of Teacher Use of AI Tool at Scale](https://arxiv.org/abs/2507.17985)
> *解码教学对话：大规模人机协作分析教师对AI工具的使用*

*Alex Liu, Lief Esbenshade, Shawon Sarkar, Victor Tian, Zachary Zhang, Kevin He, Min Sun* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 人机协作, 生成式AI, 教师使用AI, 定性分析, 大型语言模型

**Comment:** 

> **TL;DR:** 研究提出了一种人机协作方法，大规模分析教师如何使用生成式AI工具，发现LLM能可靠支持定性编码，并揭示了教师使用AI增强教学实践的模式。

**AI_Comments:** 这篇论文的创新之处在于提出了一种可扩展的人机协作方法，能够对大规模教育对话数据进行定性分析，这对于理解AI在教育实践中的实际应用具有重要意义。它不仅验证了大型语言模型（LLMs）在辅助定性研究方面的能力，还提供了教师使用AI的具体场景和比例，为教师培训和专业发展提供了数据支持。其方法论对于未来AI辅助的社会科学研究具有借鉴价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在教育工具中具有巨大潜力，但目前对教育工作者在实践中如何实际使用这些工具，以及如何大规模有效地研究他们与AI的互动知之甚少。

**Method:** 本文提出了一种人机协作方法，用于对来自K-12教师使用的生成式AI平台的超过14万条教育工作者-AI消息进行大规模定性分析。该方法包括一个四阶段编码流程：归纳主题发现、代码本开发、结构化标注和模型基准测试。研究开发了一个与既定教师评估框架对齐的分层代码本，以捕获教育工作者的教学目标、情境需求和教学策略。

**Result:** 研究结果表明，大型语言模型（LLMs），特别是Claude 3.5 Haiku，可以可靠地支持主题识别，在复杂场景中扩展人类识别能力，并在准确性和结构可靠性方面优于开源模型。分析还揭示了教育工作者使用AI增强教学实践（79.7%）、创建或改编内容（76.1%）、支持评估和反馈循环（46.9%）、关注学生个性化教学需求（43.3%）以及协助其他专业职责（34.2%）的实质性模式。

**Conclusion:** 本研究提供了一个可扩展、透明的AI增强定性研究模型，并为生成式AI在教育实践中不断演变的角色提供了基础性见解。它也突出了新兴的AI相关能力，这些能力对教师准备和专业发展具有直接影响。

> **ai_Abstract:** 本文提出了一种创新的人机协作方法，用于大规模分析K-12教师在生成式AI平台中与AI的互动数据（超过14万条消息）。通过四阶段编码流程和分层代码本，研究评估了大型语言模型（LLMs）在定性编码任务中的表现，并揭示了教师使用AI提升教学实践、内容创建、评估反馈、个性化教学及其他专业职责的具体模式。研究结果强调了LLMs在定性分析中的潜力，并为AI在教育中的应用及其对教师专业发展的影响提供了重要见解。

> **摘要翻译:** 将大型语言模型（LLMs）整合到教育工具中，有潜力显著影响教师规划教学、支持多样化学习者以及进行专业反思的方式。然而，关于教育工作者在实践中如何实际使用这些工具，以及如何大规模有效地研究他们与AI的互动，目前知之甚少。本文提出了一种人机协作方法，用于对来自K-12教师使用的生成式AI平台的超过14万条教育工作者-AI消息进行大规模定性分析。通过一个四阶段的编码流程，我们结合了归纳主题发现、代码本开发、结构化标注和模型基准测试，以检查教育工作者参与的模式，并评估LLMs在定性编码任务中的表现。我们开发了一个与既定教师评估框架对齐的分层代码本，捕获了教育工作者的教学目标、情境需求和教学策略。我们的研究结果表明，LLMs，特别是Claude 3.5 Haiku，可以可靠地支持主题识别，在复杂场景中扩展人类识别能力，并在准确性和结构可靠性方面优于开源模型。分析还揭示了教育工作者如何询问AI以增强教学实践（占总对话的79.7%）、创建或改编内容（76.1%）、支持评估和反馈循环（46.9%）、关注学生个性化教学需求（43.3%）以及协助其他专业职责（34.2%）的实质性模式，突出了新兴的AI相关能力，这些能力对教师准备和专业发展具有直接影响。本研究提供了一个可扩展、透明的AI增强定性研究模型，并为生成式AI在教育实践中不断演变的角色提供了基础性见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [774] [Designing Effective Human-Swarm Interaction Interfaces: Insights from a User Study on Task Performance](https://arxiv.org/abs/2504.02250)
> *设计有效的人机群交互界面：一项关于任务表现的用户研究的见解*

*Wasura D. Wattearachchi, Erandi Lakshika, Kathryn Kasmarik, Michael Barlow* | **Category: cs.HC, cs.RO** | **Updated: 2025-07-24**

**Keywords:** 人机群交互, 界面设计, 用户研究, 任务表现, 机器人群

**Comment:** 8 pages, 4 figures, 5 tables

> **TL;DR:** 本文提出了一种设计人机群交互界面的系统方法，结合理论和实证评估。通过一项用户研究，验证了所设计的平板界面在引导机器人群完成目标搜索任务方面的有效性，尽管其在不同危险类型下的表现有所差异。

**AI_Comments:** 本文的创新之处在于提出了一种系统性的人机群交互界面设计方法，并结合了理论推导与实证用户研究来验证其有效性。研究深入分析了不同危险类型对界面性能的影响，这对于未来人机群系统设计具有重要指导意义。其局限性可能在于用户研究规模相对较小，且仅限于一种特定任务类型。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在设计有效的人机群交互界面，以提高人类引导机器人群执行任务的效率和成功率。

**Method:** 研究首先从现有文献中提炼出十项设计原则，并将其应用于通过目标导向任务分析确定的关键信息维度。随后开发了一个基于平板的界面，用于目标搜索任务。最后，进行了一项包含31名参与者的用户研究，要求参与者引导机器人群在存在三种类型危险（分布式、移动和扩散）的情况下寻找目标。

**Result:** 研究结果显示，在98%的任务中，至少有一个机器人被引导接近目标，表明界面成功实现了主要任务目标。在近67%的任务中，超过50%的机器人到达了目标。在移动危险情境下表现尤为突出。此外，界面有助于最大程度地减少机器人失活，在近94%的任务中，参与者成功使超过50%的机器人保持活跃。然而，其有效性因危险类型而异，在分布式危险情境下机器人失活率最低。

**Conclusion:** 所设计的人机群交互界面在引导机器人群完成目标搜索任务方面表现出有效性，尤其是在减少机器人失活方面。然而，其在不同危险类型下的支持效果存在差异，在分布式危险情境下提供了最大的支持。

> **ai_Abstract:** 本文提出了一种结合理论和实证评估的系统性人机群交互界面设计方法。研究基于十项设计原则和目标导向任务分析，开发了一个平板界面用于机器人群目标搜索。通过一项31名参与者的用户研究，评估了界面在引导机器人群规避分布式、移动和扩散三种危险时的任务表现。结果显示，界面在引导机器人接近目标和保持机器人活跃方面表现良好，尤其是在移动危险和分布式危险场景下效果显著，但其有效性在不同危险类型间存在差异。

> **摘要翻译:** 在本文中，我们提出了一种设计人机群交互界面的系统方法，该方法结合了理论见解和实证评估。我们首先从现有文献中推导出十项设计原则，并将其应用于通过目标导向任务分析确定的关键信息维度，开发了一个用于目标搜索任务的平板界面。随后，我们进行了一项包含31名参与者的用户研究，其中人类需要引导机器人群在存在三种对机器人构成风险的危险类型（分布式、移动和扩散）的情况下寻找目标。性能根据机器人与目标的接近程度以及任务结束时失效机器人的数量进行衡量。结果表明，在98%的任务中，至少有一个机器人被引导接近目标，这表明该界面在实现任务主要目标方面取得了成功。此外，在近67%的任务中，超过50%的机器人到达了目标。此外，在移动危险中表现尤其出色。此外，该界面似乎有助于最大限度地减少机器人失效，因为在近94%的任务中，参与者成功地使超过50%的机器人保持活跃，确保了大部分集群保持运行。然而，其有效性因危险而异，在分布式危险场景中机器人失效率最低，这表明该界面在这些条件下提供了最大的支持。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [783] [People Are Highly Cooperative with Large Language Models, Especially When Communication Is Possible or Following Human Interaction](https://arxiv.org/abs/2507.18639)
> *人们与大型语言模型高度合作，尤其是在可以交流或在人际互动之后*

*Paweł Niszczota, Tomasz Grzegorczyk, Alexander Pastukhov* | **Category: cs.HC, cs.CL, cs.CY, econ.GN, q-fin.EC, I.2.7; H.5.2; H.5.3; K.4.3** | **Updated: 2025-05-10**

**Keywords:** 大型语言模型, 合作行为, 囚徒困境, 人机交互, 商业应用

**Comment:** 

> **TL;DR:** 尽管与人类对手相比合作率略低，但人们与大型语言模型表现出高度合作，尤其是在沟通或先有人际互动后。

**AI_Comments:** 这篇论文通过实证研究探讨了人机合作，特别是与LLM的合作行为，具有重要的创新性和实践意义。它挑战了人们可能不愿与机器合作的传统假设，并揭示了沟通和先前的社交互动对提升人机合作的积极影响。研究结果为LLM在商业和管理场景中的应用提供了实证支持，但同时也强调了“谨慎使用”的必要性。

<details>
  <summary>Details</summary>

**Motivation:** 探索大型语言模型（LLM）在商业环境中增强人类的潜力，特别是其对合作行为的影响，因为在商业环境中，有效的沟通、协作和利益相关者信任至关重要。

**Method:** 研究使用了囚徒困境游戏来模拟现实世界的管理和经济场景。实验1（N=100）让参与者与人类、经典机器人和LLM（GPT）进行30轮重复博弈。实验2（N=192）让参与者与人类或LLM进行一次性博弈，其中一半允许与对手交流。

**Result:** 与LLM的合作率很高，但比与人类对手低约10-15个百分点。沟通能力显著增加了与人类和LLM的合作可能性（均增加88%）。此外，在与人类进行过先前的互动后，与LLM的合作率更高，表明存在合作行为的溢出效应。

**Conclusion:** 研究结果验证了企业在具有合作成分的场景中（谨慎）使用大型语言模型的合理性。

> **ai_Abstract:** 该研究通过囚徒困境游戏探讨了人们与大型语言模型（LLM）的合作行为。结果显示，尽管与人类相比合作率略低，但人们与LLM表现出高度合作。沟通能力显著提高了与LLM和人类的合作意愿，且在与人类互动后，与LLM的合作意愿也随之提高。这表明LLM在商业合作场景中具有潜在应用价值。

> **摘要翻译:** 由大型语言模型（LLM）驱动的机器有潜力在各种任务中增强人类，这一发展对商业环境具有深远影响，因为在商业环境中，有效的沟通、协作和利益相关者信任至关重要。为了探索在这些环境中与LLM而非人类互动可能如何改变合作行为，我们使用了囚徒困境游戏——这是几个现实世界管理和经济场景的替代品。在实验1（N=100）中，参与者与人类、经典机器人和LLM（GPT，实时）进行了三十轮重复博弈。在实验2（N=192）中，参与者与人类或LLM进行了一次性博弈，其中一半被允许与对手交流，这使得LLM能够利用相对于老一代机器的关键优势。与LLM的合作率——虽然比与人类对手的互动低约10-15个百分点——但仍然很高。这一发现在实验2中尤为显著，在该实验中，自私行为的心理成本降低了。尽管允许就合作进行沟通并未弥合人机行为差距，但它同样（增加了88%）提高了与人类和LLM的合作可能性，这对于LLM来说尤其令人惊讶，因为它们的非人类性质以及人们可能不如与人类同行那样乐于与机器合作的假设。此外，在与人类进行过先前的互动后，与LLM的合作率更高，这表明合作行为存在溢出效应。我们的研究结果验证了企业在具有合作成分的场景中（谨慎）使用LLM的合理性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [792] [A Scoping Review of Functional Near-Infrared Spectroscopy (fNIRS) Applications in Game-Based Learning Environments](https://arxiv.org/abs/2411.02650)
> *游戏化学习环境中功能性近红外光谱 (fNIRS) 应用的范围界定综述*

*Shayla Sharmin, Gael Lucero-Palacios, Behdokht Kiafar, Mohammad Fahim Abrar, Mohammad Al-Ratrout, Aditya Raikwar, Roghayeh Leila Barmaki* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** fNIRS, 游戏化学习, 自适应学习, 认知状态, 范围界定综述

**Comment:** 28 pages, 3 figures

> **TL;DR:** 本综述探讨了功能性近红外光谱 (fNIRS) 在游戏化学习环境中的应用，发现fNIRS能提供认知状态的宝贵见解，但在实时自适应系统中的应用仍面临挑战，为未来脑感知学习研究提供了指导。

**AI_Comments:** 本综述突出了神经科学 (fNIRS) 与教育技术 (游戏化学习) 之间一个有前景的交叉点。其创新之处在于系统地梳理了 fNIRS 在这种特定、引人入胜的学习环境中的当前应用现状。其重要性在于，它既指出了开发脑感知自适应系统的潜力，也明确了为实现更广泛应用而需要解决的实际挑战（标准化、实时实施）。它为未来的跨学科研究提供了关键指导。

<details>
  <summary>Details</summary>

**Motivation:** 本综述旨在帮助研究人员了解功能性近红外光谱 (fNIRS) 在游戏化学习系统中研究大脑活动的应用情况，并展示通过fNIRS捕获的大脑数据如何通过监测学习者的认知状态来支持自适应学习系统的开发。选择游戏化学习系统是因为它们能使学习更具吸引力、互动性和沉浸感，这些都是自适应学习设计的关键特征。

**Method:** 本范围界定综述遵循PRISMA-ScR框架，筛选了1300篇论文，并选择了21项实证研究进行深入分析。研究被归类为情感/认知反应研究或比较研究，并根据学习平台、游戏设备、fNIRS配置、结果测量和研究设计进行了进一步分析。

**Result:** 研究结果表明，游戏化学习系统在提高参与度和投入度方面可以与传统方法一样有效。研究结果还显示，fNIRS能提供对认知状态的宝贵见解，但尚未在实时自适应系统中广泛实施。本综述指出了标准化和数据解释方面的关键挑战，并强调了fNIRS在开发脑感知互动学习环境方面的潜力。

**Conclusion:** 功能性近红外光谱 (fNIRS) 在开发脑感知、互动学习环境方面具有巨大潜力，本综述提供的见解将指导未来利用大脑数据支持自适应学习和智能系统设计的研究，尽管目前在标准化和实时实施方面仍存在挑战。

> **ai_Abstract:** 本范围界定综述调查了功能性近红外光谱 (fNIRS) 在游戏集成学习环境中的应用，旨在了解其当前用途及其对自适应学习系统的潜力。该综述遵循 PRISMA-ScR 框架，从筛选的 1300 篇论文中分析了 21 项实证研究。研究发现，游戏集成学习是有效的，fNIRS 能够提供对认知状态的宝贵见解，但其在实时自适应系统中的实现仍有限。综述指出了标准化和数据解释方面的关键挑战，同时强调了 fNIRS 在创建脑感知互动学习体验方面的巨大前景，并为未来的研究提供了指导。

> **摘要翻译:** 功能性近红外光谱 (fNIRS) 已成为研究学习过程中认知和情感过程的重要工具。我们特别关注游戏集成学习系统作为基于 fNIRS 的大脑数据分析的背景。我们选择游戏集成学习系统是因为此类系统使学习更具吸引力、互动性和沉浸感，所有这些都是自适应学习设计的关键特征。本范围界定综述的目标是帮助研究人员了解 fNIRS 迄今为止如何用于研究游戏集成学习系统中的大脑活动。我们还旨在展示通过 fNIRS 捕获的大脑数据如何通过监测学习者的认知状态来支持自适应学习系统的开发。使用 PRISMA-ScR 框架，筛选了 1300 篇论文，并选择了 21 项实证研究进行深入分析。研究被归类为情感/认知反应研究或比较研究，并根据学习平台、游戏设备、fNIRS 配置、结果测量和研究设计进行了进一步分析。研究结果表明，游戏集成学习系统在提高参与度和投入度方面可以与传统方法一样有效。研究结果还显示，fNIRS 提供了对认知状态的宝贵见解，但尚未在实时自适应系统中广泛实施。我们指出了标准化和数据解释方面的关键挑战，并强调了 fNIRS 在开发脑感知、互动学习环境方面的潜力。本综述提供了见解，以指导未来利用大脑数据支持自适应学习和智能系统设计的研究。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [797] [Evaluating judgment of spatial correlation in visual displays of scalar field distributions](https://arxiv.org/abs/2507.17997)
> *评估标量场分布可视化显示中空间相关性的判断*

*Yayan Zhao, Matthew Berger* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 空间相关性, 可视化显示, 标量场, 人类判断, 动画视图

**Comment:** 

> **TL;DR:** 本研究探讨了人类如何通过不同的可视化显示来判断二维标量场分布中的空间相关性，比较了动画和并置视图，并分析了分布特性对判断的影响。

**AI_Comments:** 该研究通过实验方法深入探讨了人类对空间相关性判断的认知过程，特别是在可视化显示领域的应用。其创新之处在于比较了不同的显示方式（动画与并置）和颜色刻度对判断的影响，并考虑了分布特性。这对于设计更有效的数据可视化工具具有重要的指导意义，有助于提升用户对复杂空间数据模式的理解和识别能力。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探讨人类在不同可视化显示中识别二维标量场分布中空间相关性的能力，特别是当需要对一组场而非单个场进行判断时。

**Method:** 研究通过实验设计比较了两种基本的标量场可视化设计：基于动画的显示和并置视图，并考察了不同颜色刻度以及分布本身（控制空间相关性水平和空间尺度的可辨别性）的影响。

**Result:** 研究结果揭示了分布特性对判断的影响，并强调了不同视觉显示方式如何影响评估空间相关性时所做判断的类型。

**Conclusion:** 研究得出结论，分布特性和视觉显示方式都会显著影响人类在评估二维标量场空间相关性时的判断。

> **ai_Abstract:** 本研究评估了人类在不同可视化显示中判断二维标量场空间相关性的能力。通过比较动画和并置视图以及不同颜色刻度，并控制空间相关性和可辨别性，实验结果表明，分布特性和视觉显示方式均会影响人类对空间相关性的判断类型。

> **摘要翻译:** 在这项工作中，我们研究了在不同形式的可视化显示中呈现的二维标量场分布中空间相关性的识别。我们研究了直接显示颜色映射标量场的简单可视化显示，即那些从分布中提取的显示，以及人类是否能在这些显示中识别出强相关的空间区域。在这种设置下，识别相关性需要对一组场而非单个场进行判断。因此，在我们的实验设计中，我们比较了两种基本的可视化设计：基于动画的显示与标量场的并置视图，以及不同的颜色刻度选择。此外，我们还研究了分布本身的影响，控制了空间相关性水平和空间尺度的可辨别性。我们研究的结果说明了这些分布特征的影响，同时也强调了不同的可视化显示如何影响在评估空间相关性时所做判断的类型。补充材料可在 https://osf.io/zn4qy 获取。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [825] [TreeReader: A Hierarchical Academic Paper Reader Powered by Language Models](https://arxiv.org/abs/2507.18945)
> *TreeReader：一种由语言模型驱动的层次化学术论文阅读器*

*Zijian Zhang, Pan Chen, Fangshi Du, Runlong Ye, Oliver Huang, Michael Liut, Alán Aspuru-Guzik* | **Category: cs.HC, cs.AI, cs.CL** | **Updated: 2025-07-25**

**Keywords:** 学术论文阅读, 语言模型, 层次化结构, 交互式探索, 摘要

**Comment:** 

> **TL;DR:** TreeReader是一个基于语言模型的交互式学术论文阅读器，它将论文分解为可按需展开的树状结构，以提高用户理解和导航复杂文献的效率。

**AI_Comments:** TreeReader的创新之处在于其将LLM的摘要能力与交互式层次结构相结合，解决了传统线性阅读和现有LLM工具在处理复杂学术文献时的痛点。这种方法有望显著提高学术文献的阅读效率和深度理解，尤其是在信息过载的时代，其对关键信息定位和验证的支持尤为重要。

<details>
  <summary>Details</summary>

**Motivation:** 传统的PDF和HTML线性格式导致认知过载，难以定位关键信息，且掩盖了论文的层次结构。现有基于大型语言模型（LLM）的聊天机器人虽然能提供摘要，但缺乏对特定部分的细致理解，可能产生不可靠信息，并丢弃文档的导航结构。

**Method:** TreeReader通过将论文分解为交互式树状结构来实现。每个部分最初由LLM生成简洁摘要，用户可以按需访问底层详细信息。此设计借鉴了对学术阅读习惯的形成性研究。文章还进行了一项用户研究以评估其影响。

**Result:** Not mentioned in abstract

**Conclusion:** TreeReader通过结合层次化摘要和交互式探索，提供了一种更集中、更高效的方式来导航和理解复杂的学术文献。

> **ai_Abstract:** TreeReader是一款新颖的语言模型增强型学术论文阅读器，旨在解决传统线性格式和现有LLM工具在论文理解和导航上的局限。它将论文内容分解为交互式树状结构，每个节点提供LLM生成的简洁摘要，并允许用户按需深入查看细节。这种设计使用户能够快速掌握核心思想、选择性探索感兴趣的部分，并对照原文验证摘要，从而提升阅读效率和理解力。

> **摘要翻译:** 高效地导航和理解学术论文对于科学进步至关重要。传统的线性格式如PDF和HTML可能导致认知过载，并模糊论文的层次结构，使得难以定位关键信息。虽然基于LLM的聊天机器人提供摘要功能，但它们往往缺乏对特定部分的细致理解，可能产生不可靠信息，并且通常会丢弃文档的导航结构。我们从一项关于学术阅读习惯的形成性研究中汲取见解，引入了TreeReader，这是一种新颖的、由语言模型增强的论文阅读器。TreeReader将论文分解为交互式树状结构，其中每个部分最初由LLM生成的简洁摘要表示，底层详细信息可按需访问。这种设计允许用户快速掌握核心思想，选择性地探索感兴趣的部分，并对照原文验证摘要。进行了一项用户研究，以评估TreeReader对阅读效率和理解力的影响。TreeReader通过将层次化摘要与交互式探索相结合，提供了一种更集中、更高效的方式来导航和理解复杂的学术文献。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [833] [Integrating Evidence into the Design of XAI and AI-based Decision Support Systems: A Means-End Framework for End-users in Construction](https://arxiv.org/abs/2412.14209)
> *将证据整合到XAI和基于AI的决策支持系统设计中：面向建筑领域终端用户的手段-目的框架*

*Peter E. D. Love, Jane Matthews, Weili Fang, Hadi Mahamivanan* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 可解释人工智能, 决策支持系统, 建筑, 基于证据的框架, 可信度

**Comment:** 74 pages, 5 figures and 3 tables

> **TL;DR:** 本文通过叙述性综述，提出了一个理论性的、基于证据的手段-目的框架，旨在解决建筑行业中AI决策支持系统缺乏支持性证据整合的问题，以增强AI生成解释的可靠性和可信度。

**AI_Comments:** 该论文的创新之处在于解决了将支持性证据整合到XAI设计中的关键空白，特别是针对建筑行业。这种对证据的关注直接解决了AI输出的可靠性和可问责性问题，这对于实际应用至关重要。所提出的手段-目的框架为增强AI解释的可信度提供了一种结构化方法，其广泛适用性也是一大优势。

<details>
  <summary>Details</summary>

**Motivation:** 在建筑行业中，尽管基于AI的决策支持系统日益普及，但对支撑AI生成输出的可靠性和问责制的证据整合关注不足。这种证据的缺失会损害解释的有效性和系统推荐的可信度，本文旨在解决这一空白。

**Method:** 本文通过叙述性综述开发并引入了一个理论性的、基于证据的手段-目的框架。

**Result:** 该框架为设计能够生成针对用户知识需求和决策背景的XAI赋能的决策支持系统提供了认知基础。它专注于评估支持AI生成解释的不同类型证据的强度、相关性和实用性。

**Conclusion:** 本文提出的框架为设计可解释的AI决策支持系统提供了认知基础，通过评估证据的强度、相关性和实用性来生成有意义的解释，从而增强AI输出的有效性和可信度。该框架虽然主要为建筑专业人士开发，但也适用于具有不同认知目标的开发者、监管者和项目经理。

> **ai_Abstract:** 本文针对建筑行业中AI决策支持系统缺乏支持性证据整合的问题，通过叙述性综述提出了一种理论性的、基于证据的手段-目的框架。该框架为设计可解释人工智能（XAI）赋能的系统提供了认知基础，通过评估证据的强度、相关性和实用性来生成有意义的解释，从而增强AI输出的有效性和可信度。该框架不仅适用于建筑专业人士，也适用于其他相关利益方。

> **摘要翻译:** 可解释人工智能旨在使AI模型的推理过程透明和可解释，尤其是在复杂的决策环境中。在建筑行业中，基于AI的决策支持系统日益普及，但对支撑AI生成输出的可靠性和问责制的证据整合关注不足。这种证据的缺失会损害解释的有效性和系统推荐的可信度。本文通过引入一个通过叙述性综述开发的理论性、基于证据的手段-目的框架来解决这一空白。该框架为设计能够生成针对用户知识需求和决策背景的有意义解释的XAI赋能的决策支持系统提供了认知基础。它专注于评估支持AI生成解释的不同类型证据的强度、相关性和实用性。虽然该框架主要针对建筑专业人士作为主要终端用户开发，但它也适用于具有不同认知目标的开发者、监管者和项目经理。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [839] ["I Would Not Be This Version of Myself Today": Elaborating on the Effects of Eudaimonic Gaming Experiences](https://arxiv.org/abs/2507.18084)
> *“我今天不会是现在的我”：阐述幸福感游戏体验的影响*

*Nisha Devasia, Georgia Kenderova, Michele Newman, Julie Kientz, Jin Ha Lee* | **Category: cs.HC** | **Updated: 2025-07-24**

**Keywords:** 幸福感游戏, 游戏体验, 积极影响, 混合方法, 个人成长

**Comment:** Accepted to CHI PLAY 2025

> **TL;DR:** 本研究调查了幸福感游戏体验对个人积极影响的感知结果，填补了现有理论模型中对“影响”元素探索不足的空白。

**AI_Comments:** 该研究通过关注幸福感游戏体验的长期影响，而非传统的享乐体验，展现了其创新性。它填补了理论模型中对“影响”元素探索不足的空白，为理解游戏对个人成长的深远作用提供了实证支持。其混合方法研究设计增加了结果的深度和广度，对游戏设计者和研究人员都具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管数字游戏研究多侧重享乐体验，但对幸福感游戏体验（通常伴随复杂情感，与个人意义和成长相关）的兴趣日益增长。理论认为此类体验有四个构成要素：动机、游戏使用、体验和影响。然而，前三个要素已得到较好探索，而“影响”及其如何促进积极个人结果的方面却未被充分探索。

**Method:** 本研究旨在调查幸福感游戏体验的感知结果，以及体验的不同组成部分如何影响这些效果。研究人员进行了一项问卷调查（n = 166），受访者回忆了有意义的游戏体验及其如何影响他们的当下生活。研究采用了混合方法来分类效果并识别其形成的重要子成分。

**Result:** 研究发现有意义的游戏体验可以带来积极的反思、学习、社交、健康和职业影响。

**Conclusion:** 本研究为有意义的游戏体验如何带来积极影响提供了实证理解，扩展了当前幸福感游戏体验的理论模型，并为研究人员和实践者如何利用这些发现促进玩家的积极结果提供了启示。

> **ai_Abstract:** 本研究旨在弥补数字游戏领域中对幸福感游戏体验“影响”要素探索不足的空白。通过对166名受访者进行混合方法调查，收集他们有意义的游戏体验及其对当前生活的影响。研究实证性地揭示了此类体验如何带来积极的反思、学习、社交、健康和职业影响，从而扩展了现有的理论模型，并为促进玩家积极成果提供了实践指导。

> **摘要翻译:** 尽管数字游戏的大部分研究都强调享乐体验，例如心流、享受和积极情感，但近年来对幸福感游戏体验的兴趣日益增加，这种体验通常伴随着复杂情感，并与个人意义和成长相关。游戏中此类体验的形成被理论化为具有四个构成要素：动机、游戏使用、体验和影响。然而，尽管前三个要素在文献中得到了相对充分的探索，但“影响”——以及它们如何影响积极的个体结果——迄今为止尚未得到充分探索。为此，在这项工作中，我们调查了幸福感游戏体验的感知结果以及体验的不同组成部分如何影响这些效果。我们进行了一项问卷调查（n = 166），受访者在其中回忆了有意义的游戏体验以及它们如何影响他们的当下生活。我们使用混合方法来分类效果并识别其形成的重要子成分。我们为有意义的游戏体验如何带来积极的反思、学习、社交、健康和职业影响提供了实证理解，扩展了当前幸福感游戏体验的理论模型，并为研究人员和实践者如何利用这些发现促进玩家的积极结果提供了启示。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='cset'></a>
## cs.ET 

### [379] [Low-power switching of memristors exhibiting fractional-order dynamics](https://arxiv.org/abs/2507.18487)
> *具有分数阶动力学特性的忆阻器低功耗开关*

*Nathan Astin, Yuriy V. Pershin* | **Category: cs.ET, cond-mat.mes-hall** | **Updated: 2025-07-24**

**Keywords:** 忆阻器, 分数阶动力学, 低功耗开关, 焦耳损耗, 神经形态计算

**Comment:** 

> **TL;DR:** 该研究提出了一个模型，用于研究具有分数阶行为的忆阻器，并通过电流脉冲进行开关操作。研究发现，最小化焦耳损耗的最佳开关策略取决于分数阶导数的阶数和功率指数，并为下一代节能神经形态计算架构奠定了基础。

**AI_Comments:** 该论文的创新之处在于将分数阶动力学引入忆阻器模型，并研究其对低功耗开关策略的影响。通过分析焦耳损耗，为忆阻器在节能神经形态计算中的应用提供了理论指导。这对于推动下一代计算架构的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在为下一代节能神经形态计算架构的进步奠定基础，这些架构能更紧密地模仿生物对应物。

**Method:** 本研究提出了一个忆阻器模型，其中状态变量的演变遵循涉及Caputo型导数的分数阶微分方程。通过研究焦耳损耗，确定了最小化损耗的最佳开关策略。

**Result:** 研究发现，最小化焦耳损耗的最佳开关策略取决于分数阶导数的阶数和运动方程中的功率指数。当分数阶导数的阶数超过功率指数的一半时，最佳方法是采用宽脉冲。反之，当不满足此条件时，通过施加零电流，然后施加最高允许幅度的窄电流脉冲来最小化焦耳损耗。这些发现还在多脉冲控制的背景下进行了探索。

**Conclusion:** 本研究为下一代节能神经形态计算架构的进步奠定了基础，这些架构能更紧密地模仿生物对应物。

> **ai_Abstract:** 本会议论文介绍了使用电流脉冲开关具有分数阶行为的忆阻器件的初步研究。该模型假设状态变量遵循分数阶微分方程，并通过焦耳损耗分析确定了最佳开关策略。研究表明，最小化损耗的关键在于分数阶导数的阶数和功率指数，并提出了两种不同的脉冲策略。这些发现对于开发节能神经形态计算架构具有重要意义。

> **摘要翻译:** 在这篇会议论文中，我们介绍了使用电流脉冲开关具有分数阶行为的忆阻器件的一些初步结果。在我们的模型中，假设状态变量的演化遵循涉及Caputo型导数的分数阶微分方程。对焦耳损耗的研究表明，最小化这些损耗的最佳开关策略取决于分数阶导数的阶数和运动方程中的功率指数。研究发现，当分数阶导数的阶数超过功率指数的一半时，最佳方法是采用宽脉冲。相反，当不满足此条件时，通过施加零电流，然后施加最高允许幅度的窄电流脉冲来最小化焦耳损耗。这些发现将在多脉冲控制的背景下进一步探讨。我们的研究为下一代更紧密模仿生物对应物的节能神经形态计算架构的进步奠定了基础。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

### [545] [Quantum Machine Learning in Precision Medicine and Drug Discovery -- A Game Changer for Tailored Treatments?](https://arxiv.org/abs/2502.18639)
> *精准医疗和药物发现中的量子机器学习——量身定制疗法的颠覆者？*

*Markus Bertl, Alan Mott, Salvatore Sinno, Bhavika Bhalgamiya* | **Category: cs.ET, cs.AI, quant-ph** | **Updated: 2025-07-24**

**Keywords:** 量子机器学习, 精准医疗, 药物发现, 形式化方法, 量子计算

**Comment:** presented at AISoLA 2024

> **TL;DR:** 量子机器学习在精准医疗和药物发现中潜力巨大，但算法错误和高成本是挑战；本文提出形式化方法能增强量子计算的可靠性和正确性，助其实现全部潜力。

**AI_Comments:** 本文创新性地将形式化方法引入量子计算在精准医疗领域的应用，旨在解决量子算法可靠性与正确性不足的痛点。这为量子机器学习的实际部署提供了更坚实的基础，特别是在对准确性要求极高的医疗健康领域。其重要性在于，它不仅强调了量子技术的前景，更提出了实现这些前景的关键路径，即通过严谨的数学验证来克服技术障碍。

<details>
  <summary>Details</summary>

**Motivation:** 医疗保健数字化面临生物系统复杂性、数据量庞大及个性化治疗需求等挑战，传统计算方法在此方面表现不足，导致诊断和治疗延迟或无效。量子计算和量子机器学习有望变革医学。

**Method:** 本文总结了量子计算在精准医疗和药物发现中的应用潜力，并提出通过数学形式化方法来增强量子算法的可靠性和正确性，以应对量子技术集成中的挑战。具体方法包括使用形式化规范语言定义算法行为、模型检查工具确保算法正确性、定理证明技术提供数学验证，以及形式化优化技术提升算法效率。

**Result:** 结果表明，形式化方法能显著提高量子计算的可靠性和正确性。在基因组数据分析中，形式化方法可以精确定义量子算法行为，确保其在所有条件下正确运行，提供数学证明以保证算法满足指定属性，并优化资源使用以提高效率和性能。

**Conclusion:** 形式化方法能显著促进量子计算充分发挥其在精准医疗中的潜力，成为该领域的颠覆者。

> **ai_Abstract:** 本文探讨了量子计算（QC）和量子机器学习（QML）在解决精准医疗和药物发现中传统计算方法局限性方面的潜力。尽管量子技术面临算法错误和高成本等挑战，但作者提出通过采用形式化方法（如形式化规范语言、模型检查和定理证明）可以显著增强量子算法的可靠性、正确性和效率。研究指出，这些数学严谨的方法在基因组数据分析等领域尤为关键，能够精确定义、验证和优化量子算法，从而帮助量子计算充分发挥其在个性化治疗和药物发现中的变革作用。

> **摘要翻译:** 医疗保健的数字化带来了诸多挑战，包括生物系统的复杂性、海量数据生成以及对个性化治疗方案的需求。传统的计算方法往往力不从心，导致诊断和治疗的延迟，有时甚至无效。量子计算（QC）和量子机器学习（QML）提供了变革性的进步，有可能彻底改变医学。本文总结了量子计算有望提供前所未有的计算能力的领域，从而实现更快、更准确的诊断、个性化治疗和增强的药物发现过程。然而，将量子技术整合到精准医疗中也带来了挑战，包括算法错误和高成本。我们展示了基于数学的技术，用于指定、开发和验证软件（形式化方法），可以增强量子计算的可靠性和正确性。通过提供严谨的数学框架，形式化方法有助于高精度地指定、开发和验证系统。在基因组数据分析中，形式化规范语言可以精确地（1）定义旨在识别与疾病相关的遗传标记的量子算法的行为和属性。模型检查工具可以系统地探索算法的所有可能状态，以（2）确保其在所有条件下都能正确运行，而定理证明技术则提供数学（3）证明，证明算法符合其指定的属性，从而确保准确性和可靠性。此外，形式化优化技术可以通过减少资源使用（例如量子比特和门操作的数量）来（4）提高量子算法的效率和性能。因此，我们认为形式化方法可以显著促进量子计算充分发挥其作为精准医疗领域颠覆者的全部潜力。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [23] [An Empirical Study on Embodied Artificial Intelligence Robot (EAIR) Software Bugs](https://arxiv.org/abs/2507.18267)
> *具身人工智能机器人 (EAIR) 软件缺陷的实证研究*

*Zeqin Liao, Zibin Zheng, Peifan Reng, Henglong Liang, Zixu Gao, Zhixiang Chen, Wei Li, Yuhong Nan* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 具身人工智能机器人, 软件缺陷, 实证研究, 缺陷分析, 缺陷映射

**Comment:** 

> **TL;DR:** 研究了885个具身人工智能机器人软件缺陷，识别了特有症状和原因，并建立了原因与模块的映射，以帮助缺陷预测、检测和修复。

**AI_Comments:** 这项研究通过对大量实际缺陷的系统分析，首次深入揭示了EAIR系统软件缺陷的特性，特别是区分了EAIR特有的症状和根本原因，并提供了实用的原因-模块映射，对于推动EAIR系统可靠性和安全性至关重要，具有重要的工程实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有对具身人工智能机器人（EAIR）系统缺陷的通用深入理解不足，这阻碍了缺陷处理实践和技术的发展。

**Method:** 对从80个EAIR系统项目中收集的885个EAIR系统缺陷进行了首次系统研究，调查了它们的症状、根本原因和模块分布。将缺陷分类为18种根本原因、15种不同症状和13个受影响模块。构建了根本原因与最常出现模块之间的映射。

**Result:** 1. 在15种识别出的症状中，有8种是EAIR系统特有的，其特点是严重的功能故障和潜在的物理危害。2. 在18种根本原因中，定义了8种EAIR特有的原因，其中大部分源于AI代理推理和决策的复杂问题。3. 构建了根本原因与最常出现模块之间的映射，以促进精确高效的缺陷预测、检测和修复。

**Conclusion:** 本研究揭示了新的有趣发现和启示，有助于未来解决或修复EAIR系统缺陷的研究。构建的映射可以帮助研究人员将诊断工作集中在最易受特定缺陷类型影响的模块上。

> **ai_Abstract:** 本文对具身人工智能机器人（EAIR）系统中的885个软件缺陷进行了首次系统性实证研究。通过分析这些缺陷的症状、根本原因和模块分布，识别出EAIR系统特有的8种症状（涉及严重功能故障和物理危害）和8种根本原因（多源于AI推理决策问题）。研究还构建了根本原因与受影响模块的映射，旨在提升EAIR缺陷的预测、检测和修复效率，为未来研究提供指导。

> **摘要翻译:** 具身人工智能机器人（EAIR）是一个新兴且快速发展的技术领域。确保其程序的正确性是成功部署的基础。然而，目前对EAIR系统缺陷的通用深入理解仍然不足，这阻碍了解决EAIR系统缺陷的实践和技术的发展。
为了弥补这一空白，我们对从80个EAIR系统项目中收集的885个EAIR系统缺陷进行了首次系统研究，以调查它们的症状、根本原因和模块分布。我们的分析付出了巨大的努力，将这些缺陷分为18种根本原因、15种不同的症状，并识别出13个受影响的模块。它揭示了几个新的有趣发现和启示，有助于阐明未来解决或修复EAIR系统缺陷的研究。首先，在识别出的15种症状中，我们的发现强调了8种EAIR系统特有的症状，其特点是严重的功能故障和潜在的物理危害。其次，在18种根本原因中，我们定义了8种EAIR特有的原因，其中大部分源于AI代理推理和决策的复杂问题。最后，为了促进精确高效的缺陷预测、检测和修复，我们构建了根本原因与它们最常出现的模块之间的映射，这使得研究人员能够将诊断工作集中在最易受特定缺陷类型影响的模块上。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [79] [YATE: The Role of Test Repair in LLM-Based Unit Test Generation](https://arxiv.org/abs/2507.18316)
> *YATE：测试修复在基于LLM的单元测试生成中的作用*

*Michael Konstantinou, Renzo Degiovanni, Jie M. Zhang, Mark Harman, Mike Papadakis* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 单元测试生成, LLM, 测试修复, 代码覆盖率, 变异测试

**Comment:** 12 pages, 4 figures

> **TL;DR:** YATE提出了一种结合规则分析和重新提示的简单技术，用于修复大型语言模型（LLM）生成的错误单元测试，显著提高了代码覆盖率和变异杀死率。

**AI_Comments:** YATE的创新之处在于它关注了LLM生成测试中的一个关键痛点：大量无效测试的产生。通过提出一种简单而有效的修复机制，它将这些“废弃”的测试转化为有价值的资源，从而提高了测试效率和质量。这对于依赖LLM进行代码生成和测试的领域具有重要意义，因为它不仅提高了测试的有效性，还可能减少对LLM的重复调用，从而优化成本。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于大型语言模型（LLM）的自动化测试生成是有效的，但它们倾向于生成大量语法和语义不正确的测试。这些不正确的测试虽然可以被检测和丢弃，但它们是“错失的机会”，因为如果修复，它们将非常有价值，能直接增加测试价值并为生成额外测试提供良好的种子。

**Method:** 我们提出了一种名为YATE的简单技术，通过结合基于规则的静态分析和重新提示来修复部分不正确的测试。

**Result:** YATE在6个开源项目上进行评估，与纯粹基于LLM的方法相比，平均能覆盖多32.06%的代码行，杀死多21.77%的变异。与HITS、SYMPROMPT、TESTSPARK和COVERUP等其他四种基于LLM的方法相比，YATE在相似的成本（LLM调用次数）下，代码行覆盖率提高了22%，分支覆盖率提高了20%，变异杀死率提高了20%。

**Conclusion:** YATE通过修复LLM生成的错误单元测试，显著提高了测试的质量和效率，使其在代码覆盖率和变异杀死方面表现优于现有LLM-based方法。

> **ai_Abstract:** 本文提出了YATE，一种修复大型语言模型（LLM）生成单元测试中错误的新技术。YATE结合了规则分析和重新提示，旨在将LLM生成的无效测试转化为有价值的测试资产。实验结果表明，YATE显著提升了测试效果，相较于纯LLM方法，代码行覆盖率和变异杀死率均有大幅提升，并且优于其他主流LLM-based测试生成工具。

> **摘要翻译:** 最近自动化测试生成的进展利用语言模型来生成单元测试。尽管有效，但语言模型倾向于生成许多在语法和语义上都不正确的测试。虽然这些不正确的测试可以很容易地被检测和丢弃，但它们构成了“错失的机会”——如果被修复，它们通常很有价值，因为它们直接增加了测试价值（它们有效地针对待测试的底层程序逻辑），并间接形成了生成额外测试的良好种子。为此，我们提出了一种简单的技术，通过结合基于规则的静态分析和重新提示来修复其中一些不正确的测试。我们在一组6个开源项目上评估了这种名为YATE的简单方法，结果表明它能有效地生成测试，平均比纯粹基于LLM的方法多覆盖32.06%的代码行，多杀死21.77%的变异。我们还将YATE与其他四种基于LLM的方法（即HITS、SYMPROMPT、TESTSPARK和COVERUP）进行了比较，结果表明它生成的测试覆盖了更多的代码。YATE在相似的成本（LLM调用次数）下，实现了22%更高的代码行覆盖率，20%更高的分支覆盖率和多杀死20%的变异。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [113] [Your ATs to Ts: MITRE ATT&CK Attack Technique to P-SSCRM Task Mapping](https://arxiv.org/abs/2507.18037)
> *您的攻击技术到任务：MITRE ATT&CK 攻击技术到 P-SSCRM 任务映射*

*Sivana Hamer, Jacob Bowen, Md Nazmul Haque, Chris Madden, Laurie Williams* | **Category: cs.SE, cs.CR** | **Updated: 2025-07-24**

**Keywords:** MITRE ATT&CK, 软件供应链风险管理, P-SSCRM, 映射, 攻击技术

**Comment:** Mapping generated from: arXiv:2503.12192

> **TL;DR:** 本文描述了MITRE ATT&CK攻击技术与P-SSCRM任务之间的映射，旨在帮助软件组织识别缓解软件供应链攻击的方法，并通过四种独立策略创建。

**AI_Comments:** 这篇论文通过建立MITRE ATT&CK与P-SSCRM任务之间的映射，提供了一个实用的工具，帮助软件组织更有效地管理软件供应链风险。其创新之处在于通过多策略方法确保映射的准确性，并间接实现了ATT&CK与其他行业标准框架的整合，提升了风险管理实践的互操作性和全面性。

<details>
  <summary>Details</summary>

**Motivation:** 帮助软件组织确定不同的P-SSCRM任务如何缓解软件供应链攻击的攻击技术。

**Method:** 通过四种独立的策略创建，以找到达成一致的映射。

**Result:** 提供了一个MITRE ATT&CK攻击技术到P-SSCRM任务的映射，同时由于P-SSCRM任务已映射到其他10个框架的任务，因此该映射也连接了MITRE ATT&CK与其他重要的政府和行业框架。

**Conclusion:** 该映射有助于软件组织理解P-SSCRM任务对MITRE ATT&CK攻击技术的缓解作用，并间接连接了MITRE ATT&CK与其他行业框架。

> **ai_Abstract:** 本文详细介绍了MITRE ATT&CK攻击技术与主动软件供应链风险管理框架(P-SSCRM)任务之间的映射。该映射旨在帮助软件组织识别和理解P-SSCRM任务如何有效缓解软件供应链攻击。该映射的创建过程采用了四种独立的策略以确保映射的准确性和共识。此外，由于P-SSCRM任务本身已与10个其他框架的任务进行了映射，因此本研究提供的映射也间接实现了MITRE ATT&CK与其他主要政府和行业框架的互联互通。

> **摘要翻译:** MITRE 对抗策略、技术和通用知识 (MITRE ATT&CK) 攻击技术到主动软件供应链风险管理框架 (P-SSCRM) 任务的映射，如本文档所述，有助于软件组织确定不同的任务如何缓解软件供应链攻击的攻击技术。该映射是通过四种独立的策略创建的，以找到达成一致的映射。由于每个 P-SSCRM 任务都映射到一个或多个来自 10 个框架的任务，因此我们提供的映射也是 MITRE ATT&CK 与其他著名的政府和行业框架之间的映射。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [134] [Understanding the Supply Chain and Risks of Large Language Model Applications](https://arxiv.org/abs/2507.18105)
> *理解大型语言模型应用的供应链与风险*

*Yujie Ma, Lili Quan, Xiaofei Xie, Qiang Hu, Jiongchi Yu, Yao Zhang, Sen Chen* | **Category: cs.SE, cs.CR** | **Updated: 2025-07-24**

**Keywords:** LLM, 供应链安全, 风险评估, 漏洞, 数据集

**Comment:** 26 pages

> **TL;DR:** 大型语言模型（LLM）应用的普及带来了复杂的供应链风险。现有风险评估多集中于模型或数据层面，忽视了供应链的整体漏洞。本文构建了首个全面的LLM供应链安全数据集，揭示了LLM应用的深层依赖和显著漏洞，并提出了实用建议。

**AI_Comments:** 本文的创新之处在于构建了首个全面的LLM供应链安全数据集，填补了现有LLM风险评估中对供应链整体漏洞关注不足的空白。其对真实世界LLM应用的深入分析揭示了生态系统中的深层依赖关系和显著漏洞，这对于推动LLM安全研究和指导行业实践具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLM）风险评估主要狭隘地集中在模型或数据层面，忽视了更广泛的供应链漏洞。尽管最近的研究已开始关注LLM供应链风险，但仍缺乏系统性研究的基准。

**Method:** 本文引入了首个用于分析和基准测试LLM供应链安全性的全面数据集。研究收集了3,859个真实世界的LLM应用，并进行了相互依赖分析，识别出109,211个模型、2,474个数据集和9,862个库。研究提取了模型微调路径、数据集重用和库依赖，以映射生态系统结构。为了评估安全性，研究从公共漏洞数据库收集了1,555个风险相关问题（50个用于应用、325个用于模型、18个用于数据集、1,229个用于库）。

**Result:** 研究发现LLM应用中存在深层嵌套的依赖关系，并在整个供应链中存在显著的漏洞。

**Conclusion:** 本文强调了对LLM供应链进行全面安全分析的必要性，并提供了实用的建议，以指导研究人员和开发人员构建更安全、更值得信赖的LLM赋能系统。

> **ai_Abstract:** 鉴于大型语言模型（LLM）应用的日益普及，理解其复杂供应链中的风险至关重要。现有风险评估的局限性在于主要关注模型或数据层面，忽视了更广泛的供应链漏洞。为弥补这一研究空白，本文构建了首个全面的LLM供应链安全数据集，该数据集涵盖了3,859个真实世界的LLM应用及其相互依赖的组件（包括模型、数据集和库），并整合了相关的风险问题。通过对该数据集的实证分析，研究揭示了LLM应用中深层嵌套的依赖关系以及整个供应链中存在的显著漏洞。文章强调了进行全面安全分析的必要性，并为研究人员和开发者提供了构建更安全、更可靠的LLM系统的实用建议。

> **摘要翻译:** 大型语言模型（LLM）的兴起导致基于LLM的系统在不同领域得到广泛部署。随着这些系统的普及，理解与其复杂供应链相关的风险变得越来越重要。基于LLM的系统并非独立存在，它们依赖于涉及预训练模型、第三方库、数据集和基础设施的相互关联的供应链。然而，大多数风险评估仅狭隘地关注模型或数据层面，忽视了更广泛的供应链漏洞。尽管最近的研究已开始解决LLM供应链风险，但仍缺乏系统性研究的基准。
为了解决这一空白，我们引入了第一个用于分析和基准测试LLM供应链安全性的综合数据集。我们收集了3,859个真实世界的LLM应用程序，并进行了相互依赖分析，识别出109,211个模型、2,474个数据集和9,862个库。我们提取了模型微调路径、数据集重用和库依赖，以映射生态系统的结构。为了评估安全性，我们从公共漏洞数据库收集了1,555个风险相关问题——50个用于应用程序、325个用于模型、18个用于数据集、1,229个用于库。
利用该数据集，我们实证分析了组件依赖关系和风险。我们的发现揭示了LLM应用程序中深层嵌套的依赖关系以及整个供应链中的显著漏洞，强调了进行全面安全分析的必要性。最后，我们提出了实用建议，以指导研究人员和开发人员构建更安全、更值得信赖的LLM赋能系统。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [135] [Gotta catch 'em all! Towards File Localisation from Issues at Large](https://arxiv.org/abs/2507.18319)
> *全都抓住！迈向大规模问题的文件定位*

*Jesse Maarleveld, Jiapan Guo, Daniel Feitosa* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 文件定位, 问题定位, 错误定位, 数据管道, 信息检索

**Comment:** 12 pages, 6 figures

> **TL;DR:** 该研究旨在解决从所有类型的问题中定位相关文件的问题，而不仅仅是错误。它提出了一个数据管道，评估了传统信息检索方法的基线性能，并发现特定于错误的启发式方法对通用问题类型表现不佳，强调了通用模型的需求。

**AI_Comments:** 这项工作具有创新性，因为它将文件定位的范围从传统的“错误”扩展到“所有问题”，这在实际开发中更具普适性。所提出的数据管道能够处理复杂的版本控制实践，为构建更全面的数据集提供了基础。研究结果揭示了现有错误定位方法的局限性，并明确指出了未来研究通用模型和可调适方法的方向，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文件定位研究主要集中在错误（bug）上，或者通过其他选择方法只考虑特定类型的问题。然而，研究目标是处理所有类型的大规模问题，不进行任何特定选择，以节省开发人员的时间。

**Method:** 本研究提供了一个用于创建问题文件定位数据集的数据管道，该管道能够处理任意的分支和合并实践。它使用传统的信息检索方法对文件定位问题进行了基线性能评估。此外，它还使用统计分析来调查错误定位社区中已知的偏差对数据集的影响。

**Result:** 结果表明，使用特定于错误的启发式方法设计的模型在通用问题类型上的表现不佳，这表明需要研究通用模型。此外，研究发现不同问题类型之间在性能上存在微小但统计学上显著的差异。最后，发现标识符的存在对大多数问题类型的性能影响很小。许多结果是依赖于项目的，这鼓励开发可以根据项目特定特征进行调整的方法。

**Conclusion:** 本研究的结论是，现有针对错误定位优化的方法不适用于更广泛的问题类型，需要开发通用的文件定位模型。同时，由于结果的项目依赖性，未来的方法应具备项目特定调整的能力。

> **ai_Abstract:** 本研究旨在扩展文件定位的范围，超越传统的错误定位，处理所有类型的问题。为此，作者提出了一个数据管道来构建通用问题文件定位数据集，并利用传统信息检索方法建立了基线性能。研究发现，针对错误优化的方法在处理通用问题时表现不佳，且性能受问题类型和标识符存在的影响。结果强调了开发通用模型以及可根据项目特性进行调整的方法的必要性。

> **摘要翻译:** 错误定位，即开发定位解决错误所需文件的方法的研究，长期以来一直致力于开发能够节省开发人员时间的方法。最近，研究人员开始考虑错误之外的问题。然而，大多数现有关于从问题中进行文件定位的研究都集中在错误上，或者使用其他选择方法来确保只有某些类型的问题被考虑为工作的重点。我们的目标是处理所有大规模问题，不进行任何特定选择。
在这项工作中，我们提供了一个用于创建问题文件定位数据集的数据管道，能够处理任意的分支和合并实践。我们使用传统的信息检索方法为文件定位问题提供了基线性能评估。最后，我们使用统计分析来调查错误定位社区中已知的偏差对我们数据集的影响。
我们的结果表明，使用特定于错误的启发式方法设计的方法在通用问题类型上表现不佳，这表明需要研究通用模型。此外，我们发现不同问题类型之间在性能上存在微小但统计学上显著的差异。最后，我们发现标识符的存在对大多数问题类型的性能影响很小。许多结果是依赖于项目的，这鼓励开发可以根据项目特定特征进行调整的方法。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [164] [Scheduzz: Constraint-based Fuzz Driver Generation with Dual Scheduling](https://arxiv.org/abs/2507.18289)
> *Scheduzz：基于约束和双重调度的模糊驱动生成*

*Yan Li, Wenzhang Yang, Yuekun Wang, Jian Gao, Shaohua Wang, Yinxing Xue, Lijun Zhang* | **Category: cs.SE, cs.CR** | **Updated: 2025-07-24**

**Keywords:** 模糊测试, LLM, 模糊驱动生成, 约束, 双重调度

**Comment:** 15 pages, 12 figures, 5 tables

> **TL;DR:** Scheduzz是一种基于LLM的模糊测试技术，通过双重调度框架生成符合库使用规范的模糊驱动，显著提高了覆盖率并发现了新漏洞，同时减少了计算开销。

**AI_Comments:** Scheduzz的创新之处在于其结合了大型语言模型（LLM）来理解库的语义和使用规范，从而生成更“合理”的模糊驱动，这解决了传统模糊测试中难以避免的无效输入问题。此外，引入的双重调度框架将模糊测试过程视为在线优化问题，高效管理资源，进一步提升了模糊测试的效率和效果。其发现大量新漏洞并获得CVE的事实证明了其在实际应用中的重要性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的库模糊测试技术在生成模糊驱动时，由于缺乏对库使用规范的理解，导致生成大量不合理的驱动，浪费计算资源且贡献的覆盖率低，并产生误报。此外，专家手动创建高质量的模糊驱动既困难又繁琐。

**Method:** 本文提出了一种新颖的自动化库模糊测试技术Scheduzz，它是一种基于LLM的库模糊测试技术。Scheduzz利用LLM理解库的合理用法并提取API组合约束。为了优化计算资源利用，它实现了一个双重调度框架，以高效管理API组合和模糊驱动。该框架将驱动生成和相应的模糊测试活动建模为在线优化问题。在调度循环中，选择多个API组合来生成模糊驱动，同时调度各种优化后的模糊驱动进行执行或暂停。

**Result:** Scheduzz在33个真实世界库中进行了评估。与基线方法相比，Scheduzz显著降低了计算开销，并在21个库中的16个库上优于UTopia。它比最先进的技术CKGFuzzer、Promptfuzz和手工项目OSS-Fuzz分别实现了1.62倍、1.50倍和1.89倍的总体覆盖率。此外，Scheduzz在这些经过充分测试的库中发现了33个以前未知的错误，其中3个已被分配CVE。

**Conclusion:** Scheduzz通过结合LLM理解库使用约束和引入双重调度机制，有效解决了现有模糊测试技术生成不合理驱动和资源浪费的问题，显著提升了模糊测试的效率、覆盖率和发现真实漏洞的能力。

> **ai_Abstract:** 本文提出了Scheduzz，一种基于LLM的自动化库模糊测试技术，旨在解决传统方法生成不合理模糊驱动和资源浪费的问题。Scheduzz利用LLM理解库用法并提取API约束，并通过双重调度框架优化模糊驱动生成和执行过程，将其建模为在线优化问题。实验结果表明，Scheduzz显著降低了计算开销，提高了代码覆盖率，并发现了33个新漏洞，其中3个获得CVE，优于现有最先进技术。

> **摘要翻译:** 模糊测试库需要专家很好地理解库的使用并制作高质量的模糊驱动，这既棘手又繁琐。因此，许多技术已被提出以自动生成模糊驱动。然而，由于缺乏对正确库使用约定的遵守，例如确保资源在打开后被关闭，它们未能生成合理的模糊驱动。更糟糕的是，现有的库模糊测试技术无条件地执行每个驱动，导致产生大量不合理的驱动，这些驱动浪费计算资源，而对覆盖率贡献甚微，并生成误报错误报告。
为了解决这些挑战，我们提出了一种新颖的自动化库模糊测试技术Scheduzz，这是一种基于LLM的库模糊测试技术。它利用LLM理解库的合理用法并提取API组合约束。为了优化计算资源利用，实施了一个双重调度框架，以高效管理API组合和模糊驱动。该框架将驱动生成和相应的模糊测试活动建模为在线优化问题。在调度循环中，选择多个API组合来生成模糊驱动，同时，各种优化后的模糊驱动被调度执行或暂停。
我们实现了Scheduzz并在33个真实世界库中进行了评估。与基线方法相比，Scheduzz显著降低了计算开销，并在21个库中的16个库上优于UTopia。它比最先进的技术CKGFuzzer、Promptfuzz和手工项目OSS-Fuzz分别实现了1.62倍、1.50倍和1.89倍的总体覆盖率。此外，Scheduzz在这些经过充分测试的库中发现了33个以前未知的错误，其中3个已被分配CVE。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [191] [FMI Meets SystemC: A Framework for Cross-Tool Virtual Prototyping](https://arxiv.org/abs/2507.18339)
> *FMI 遇见 SystemC：一个跨工具虚拟原型设计框架*

*Nils Bosbach, Meik Schmidt, Lukas Jünger, Matthias Berthold, Rainer Leupers* | **Category: cs.SE, cs.DC** | **Updated: 2025-07-24**

**Keywords:** FMI, SystemC, 虚拟原型设计, 协同仿真, 软件测试

**Comment:** PREPRINT - accepted by the 16th International Modelica and FMI
  Conference 2025

> **TL;DR:** 本文提出一个新颖的框架，通过 FMI 控制和交互基于 SystemC 的虚拟平台，从而实现对目标软件的广泛测试和验证，并加速认证过程。

**AI_Comments:** 该论文的创新之处在于解决了 SystemC 在协同仿真环境中缺乏 FMI 支持的痛点，通过构建一个新框架，有效地连接了 SystemC 虚拟平台与外部仿真工具。这对于复杂系统的早期软件开发和验证具有重要意义，尤其是在需要满足严格认证标准（如 ISO 26262）的领域。其价值在于提升了虚拟原型设计的灵活性和效率，降低了对物理硬件的依赖，从而加速了产品开发周期。

<details>
  <summary>Details</summary>

**Motivation:** 随着系统日益复杂，对全面测试和虚拟原型设计的需求不断增长。为了模拟整个系统，通常需要多个工具来覆盖不同部分，包括硬件和系统交互的环境。FMI 标准可用于连接这些工具。现代系统的控制部分通常是计算单元（如 SoC 或 MCU），执行软件并与外设交互。为了在不依赖物理硬件的情况下开发软件，常使用全系统模拟器（即虚拟平台，VP）。SystemC TLM 是 VP 开发的 IEEE 标准框架，提供模块化设计和模型交换的接口和概念。然而，SystemC 缺乏原生 FMI 支持，限制了其在更广泛的协同仿真环境中的集成。

**Method:** 本文提出了一个新颖的框架，利用 FMI 控制和交互基于 SystemC 的虚拟平台 (VP)。通过一个案例研究，展示了 SystemC 仿真中的模拟温度传感器如何通过 FMI 从外部工具获取温度值。这种方法允许未经修改的目标软件在 VP 上运行，并接收来自其他工具的真实环境输入数据（如温度、速度或加速度）。

**Result:** 该方法使得未经修改的目标软件能够在虚拟平台上运行，并接收来自其他工具的真实环境输入数据。这从而实现了广泛的软件测试和验证。通过在物理硬件可用之前使用虚拟平台准备好测试并预先测试软件，可以提前进行 ISO 26262 等认证。

**Conclusion:** 该框架通过将 FMI 与 SystemC 结合，克服了 SystemC 缺乏原生 FMI 支持的限制，实现了跨工具的虚拟原型设计和协同仿真。这使得在虚拟平台上进行广泛的软件测试和验证成为可能，并有助于加速如 ISO 26262 等认证过程。

> **ai_Abstract:** 本文提出了一个新颖的框架，将功能模型接口 (FMI) 标准与 SystemC 结合，以实现跨工具的虚拟原型设计和协同仿真。鉴于 SystemC 缺乏原生 FMI 支持，该框架允许 SystemC 虚拟平台 (VP) 通过 FMI 与外部工具进行交互，从而为在 VP 上运行的未经修改的目标软件提供真实的外部环境输入。一个案例研究展示了如何通过 FMI 从外部工具获取温度值，从而实现广泛的软件测试和验证，并加速如 ISO 26262 等认证。

> **摘要翻译:** 随着系统日益复杂，对全面测试和虚拟原型设计的需求不断增长。为了模拟整个系统，通常需要多个工具来覆盖不同部分。这些部分包括系统的硬件以及系统与之交互的环境。功能模型接口 (FMI) 协同仿真标准可用于连接这些工具。
现代系统的控制部分通常是计算单元，例如片上系统 (SoC) 或微控制器单元 (MCU)，它执行来自连接存储器的软件并与外设交互。为了在不需要访问物理硬件的情况下开发软件，通常使用全系统模拟器，即所谓的虚拟平台 (VP)。IEEE 标准化的 VP 开发框架是 SystemC TLM。SystemC 提供接口和概念，实现模块化设计和模型交换。然而，SystemC 缺乏原生 FMI 支持，这限制了其集成到更广泛的协同仿真环境中。
本文提出了一个新颖的框架，使用 FMI 控制和交互基于 SystemC 的 VP。我们展示了一个案例研究，说明 SystemC 仿真中的模拟温度传感器如何通过 FMI 从外部工具获取温度值。这种方法允许未经修改的目标软件在 VP 上运行，并接收来自其他工具的真实环境输入数据，如温度、速度或加速度值。因此，可以进行广泛的软件测试和验证。通过在物理硬件可用后立即准备好测试并使用 VP 预先测试软件，可以更早地进行 ISO 26262 等认证。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [262] [Automated Code Review Using Large Language Models with Symbolic Reasoning](https://arxiv.org/abs/2507.18476)
> *使用大语言模型与符号推理的自动化代码审查*

*Busra Icoz, Goksel Biricik* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 自动化代码审查, 大语言模型, 符号推理, 代码质量, 人工智能

**Comment:** 

> **TL;DR:** 该研究提出了一种结合大语言模型和符号推理的混合方法，以实现自动化代码审查，解决了LLM在逻辑推理方面的不足，并提高了审查的准确性和效率。

**AI_Comments:** 本文的创新之处在于提出了一种混合方法，通过结合符号推理来弥补大语言模型在逻辑推理方面的不足，从而提高了自动化代码审查的性能。这对于提升软件开发效率和代码质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 手动代码审查主观且耗时，而现有的大语言模型在理解和评估代码所需的逻辑推理能力方面存在不足。

**Method:** 本文提出了一种将符号推理技术与大型语言模型（LLMs）相结合的混合方法，旨在自动化代码审查过程。该方法在CodexGlue数据集上进行了测试，并与CodeT5、CodeBERT和GraphCodeBERT等模型进行了比较，以评估其有效性。

**Result:** 该方法提高了自动化代码审查的准确性和效率。

**Conclusion:** 结合符号推理和提示技术与大语言模型的方法能够有效提升自动化代码审查的性能。

> **ai_Abstract:** 本文提出了一种结合大语言模型（LLMs）和符号推理的混合方法，旨在解决手动代码审查的主观性和耗时性问题，以及LLMs在代码逻辑推理上的不足。研究在CodexGlue数据集上验证了该方法，并与多种现有模型进行比较，结果显示该混合方法显著提升了自动化代码审查的准确性和效率。

> **摘要翻译:** 代码审查是软件开发生命周期中的关键过程之一，对于维护代码质量至关重要。然而，手动代码审查具有主观性且耗时。鉴于其基于规则的性质，代码审查非常适合自动化。近年来，在人工智能的帮助下，人们在自动化这一过程方面做出了巨大努力。大型语言模型（LLMs）的最新发展也已成为该领域的一个有前途的工具，但这些模型通常缺乏完全理解和评估代码所需的逻辑推理能力。为了克服这一限制，本研究提出了一种混合方法，将符号推理技术与LLMs相结合，以自动化代码审查过程。我们使用CodexGlue数据集测试了我们的方法，比较了包括CodeT5、CodeBERT和GraphCodeBERT在内的多个模型，以评估将符号推理和提示技术与LLMs结合的有效性。我们的结果表明，这种方法提高了自动化代码审查的准确性和效率。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [318] [A Deep Dive into Retrieval-Augmented Generation for Code Completion: Experience on WeChat](https://arxiv.org/abs/2507.18515)
> *深入探究检索增强生成在代码补全中的应用：微信实践经验*

*Zezhou Yang, Ting Peng, Cuiyun Gao, Chaozheng Wang, Hailiang Huang, Yuetang Deng* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 代码补全, 检索增强生成, 大型语言模型, 闭源代码库, 微信

**Comment:** Accepted in ICSME 25 Industry Track

> **TL;DR:** 本文在微信工业级闭源代码库中实证研究了RAG在代码补全中的表现，发现RAG有效，尤其以基于相似性的RAG表现最佳，结合词法和语义检索效果最优，并验证了其在实际开发中的实用性。

**AI_Comments:** 本文的创新之处在于其首次在微信这样大规模的工业级闭源代码库上对RAG在代码补全中的应用进行了深入的实证研究。这弥补了现有研究主要集中在开源代码库上的空白，为RAG技术在实际生产环境中的部署和优化提供了宝贵的经验和数据支持。研究结果对于理解RAG在不同代码分布下的表现，以及如何选择和组合检索策略具有重要指导意义，对提升工业界代码补全工具的性能具有实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究已证实检索增强生成（RAG）在开源代码库和基准测试中对代码补全的有效性，但开源和闭源代码库之间潜在的分布差异带来了未被探索的独特挑战。本文旨在弥补这一空白，探究RAG方法在工业级闭源代码库（如微信）中的性能。

**Method:** 本文在微信的工业级闭源代码库上对代码补全中广泛使用的RAG方法进行了实证研究。具体而言，研究了两种主要的RAG方法：基于标识符的RAG和基于相似性的RAG，涵盖了26个参数量从0.5B到671B的开源大型语言模型。对于基于相似性的RAG，采用了词法和语义检索等不同的检索技术。研究基于1,669个内部代码仓库进行，并进行了开发者调研以验证RAG方法的实际效用。

**Result:** 1. 两种RAG方法在闭源代码库中均表现出有效性，其中基于相似性的RAG性能更优。
2. 基于相似性的RAG的有效性随更先进的检索技术而提高，其中BM25（词法检索）和GTE-Qwen（语义检索）表现出色。
3. 词法和语义检索技术的结合能产生最佳效果，展现出互补优势。
4. 通过开发者调研，验证了RAG方法在实际开发环境中的实用性。

**Conclusion:** 检索增强生成（RAG）方法在工业级闭源代码库中对代码补全任务是有效的，特别是基于相似性的RAG表现优异，并且结合词法和语义检索技术能达到最佳性能，其在实际开发中具有实用价值。

> **ai_Abstract:** 本研究深入探讨了检索增强生成（RAG）在工业级闭源代码库中应用于代码补全的性能，以弥补开源与闭源环境间RAG有效性研究的空白。通过在微信庞大的内部代码库（1,669个仓库）上对基于标识符和基于相似性的RAG方法进行实证分析，并结合词法和语义检索技术，研究发现RAG在闭源环境中同样有效，其中基于相似性的RAG表现更优，且词法与语义检索的结合能达到最佳补全效果。此外，开发者调研进一步验证了RAG在实际开发中的实用价值。

> **摘要翻译:** 代码补全作为软件工程中提升开发者生产力的关键任务，随着大型语言模型（LLMs）的快速发展取得了显著进步。近年来，检索增强生成（RAG）作为一种无需模型重新训练即可利用代码库中相关上下文来增强LLMs代码补全能力的方法，已显示出广阔前景。尽管现有研究已证明RAG在公共仓库和基准测试上的有效性，但开源和闭源代码库之间潜在的分布差异带来了仍未被探索的独特挑战。为了弥补这一差距，我们进行了一项实证研究，调查了在微信（最大的专有软件系统之一）的工业级代码库中，广泛使用的RAG方法在代码补全方面的性能。具体而言，我们广泛探索了两种主要类型的RAG方法，即基于标识符的RAG和基于相似性的RAG，涵盖了26个参数量从0.5B到671B的开源LLMs。为了进行更全面的分析，我们为基于相似性的RAG采用了不同的检索技术，包括词法检索和语义检索。基于1,669个内部仓库，我们取得了几个关键发现：（1）两种RAG方法在闭源仓库中均表现出有效性，其中基于相似性的RAG性能更优；（2）基于相似性的RAG的有效性随更先进的检索技术而提高，其中BM25（词法检索）和GTE-Qwen（语义检索）表现出色；（3）词法和语义检索技术的结合能产生最佳效果，展现出互补优势。此外，我们还进行了一项开发者调研，以验证RAG方法在真实世界开发环境中的实际效用。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [467] [SAVANT: Vulnerability Detection in Application Dependencies through Semantic-Guided Reachability Analysis](https://arxiv.org/abs/2506.17798)
> *SAVANT：通过语义引导的可达性分析检测应用程序依赖项中的漏洞*

*Wang Lingxiang, Quanzhi Fu, Wenjia Song, Gelei Deng, Yi Liu, Dan Williams, Ying Zhang* | **Category: cs.SE, cs.CR** | **Updated: 2025-07-24**

**Keywords:** 漏洞检测, 应用程序依赖, 语义分析, 大型语言模型, 软件组成分析

**Comment:** 

> **TL;DR:** SAVANT是一种利用语义预处理和大型语言模型（LLM）进行上下文分析的工具，旨在准确检测Java应用程序依赖项中的漏洞，并优于现有软件组成分析（SCA）工具。

**AI_Comments:** SAVANT的创新之处在于其结合了语义预处理和大型语言模型（LLMs）来解决传统软件组成分析（SCA）工具在理解API使用语义方面的局限性。利用LLM进行上下文分析和反射，能够更准确地判断漏洞的实际影响，从而减少误报并加速安全修复。这对于提高Java应用程序供应链安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在Java开发中，集成开源第三方库会引入已知漏洞带来的重大安全风险。现有软件组成分析（SCA）工具由于在理解API使用语义方面的局限性以及分析复杂代码库的计算挑战，难以有效检测这些库中易受攻击的API使用，导致不准确的漏洞警报，给开发团队带来负担并延迟关键安全修复。

**Method:** SAVANT利用两个见解：漏洞证明测试用例展示了漏洞如何在特定上下文中被触发，以及大型语言模型（LLMs）可以理解代码语义。SAVANT结合语义预处理和LLM驱动的上下文分析进行准确的漏洞检测。它首先将源代码分割成有意义的代码块，同时保留语义关系，然后利用基于LLM的反射来分析API使用上下文并确定实际的漏洞影响。

**Result:** 在55个真实应用程序上的评估显示，SAVANT的精确率为83.8%，召回率为73.8%，准确率为69.0%，F1分数为78.5%，优于最先进的SCA工具。

**Conclusion:** SAVANT通过结合语义预处理和LLM驱动的上下文分析，显著提高了应用程序依赖项中漏洞检测的准确性，有效解决了现有SCA工具的局限性，并提供了优于现有技术的性能。

> **ai_Abstract:** SAVANT是一种新型工具，旨在解决Java应用程序中第三方库依赖项的漏洞检测问题。针对现有软件组成分析（SCA）工具在理解API语义和处理复杂代码库方面的不足，SAVANT创新性地结合了语义预处理和大型语言模型（LLMs）驱动的上下文分析。它通过对源代码进行语义分割并利用LLM进行反射分析，以准确识别漏洞影响。实验结果表明，SAVANT在精确率、召回率、准确率和F1分数上均优于现有SCA工具，证明了其在提高漏洞检测准确性方面的有效性。

> **摘要翻译:** 在Java开发中，集成开源第三方库依赖项会引入重大安全风险，因为这些库可能包含已知漏洞。现有软件组成分析（SCA）工具由于在理解API使用语义方面的局限性以及分析复杂代码库的计算挑战，难以有效检测这些库中易受攻击的API使用，导致不准确的漏洞警报，给开发团队带来负担并延迟关键安全修复。
为了解决这些挑战，我们提出了SAVANT，它利用了两个见解：漏洞证明测试用例展示了漏洞如何在特定上下文中被触发，以及大型语言模型（LLMs）可以理解代码语义。SAVANT结合语义预处理和LLM驱动的上下文分析进行准确的漏洞检测。SAVANT首先将源代码分割成有意义的代码块，同时保留语义关系，然后利用基于LLM的反射来分析API使用上下文并确定实际的漏洞影响。我们在55个真实应用程序上的评估显示，SAVANT的精确率为83.8%，召回率为73.8%，准确率为69.0%，F1分数为78.5%，优于最先进的SCA工具。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [480] [It is Giving Major Satisfaction: Why Fairness Matters for Software Practitioners](https://arxiv.org/abs/2410.02482)
> *它带来了极大的满足感：为什么公平对软件从业者很重要*

*Emeralda Sesari, Federica Sarro, Ayushi Rastogi* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 公平感, 工作满意度, 软件从业者, 人际公平, 人口差异

**Comment:** Accepted in ACM Transactions on Software Engineering and Methodology
  (TOSEM)

> **TL;DR:** 公平感显著影响软件从业者的工作满意度，尤其是对女性、少数族裔、经验较少和有工作限制的人群影响更大。

**AI_Comments:** 这篇论文通过实证研究填补了软件工程领域公平与工作满意度关系研究的空白。其创新之处在于不仅确认了公平的普遍影响，还深入分析了不同公平维度以及特定人口群体对公平的敏感性，特别是人际公平的最大影响以及对弱势群体的更强作用，为行业提供了具象化的指导。

<details>
  <summary>Details</summary>

**Motivation:** 软件从业者常遇到职场不公，尽管公平与工作满意度的关系在其他领域已确立，但在软件专业人士中仍未充分探索。本研究旨在探讨公平感与软件从业者工作满意度之间的关系。

**Method:** 本研究对108名软件从业者进行了在线调查，随后采用序数逻辑回归分析公平感与工作满意度之间的关系，并通过调节分析考察这种关系在不同人口群体中的差异。

**Result:** 所有四种公平维度（分配公平、程序公平、人际公平和信息公平）都显著影响整体工作满意度和工作保障满意度。其中，人际公平影响最大。公平与工作满意度之间的关系对女性、少数族裔、经验较少的从业者和有工作限制的人群更强。署名公平是影响集体工作满意度的重要因素，而政策执行、高需求情况和工作时间方面的公平则影响特定人口群体。

**Conclusion:** 本研究强调了公平在软件从业者中的作用，并为组织提供了促进公平实践和针对特定人口群体的策略。

> **ai_Abstract:** 本研究调查了公平感如何影响软件从业者的工作满意度。通过对108名从业者的在线调查和序数逻辑回归分析，发现分配、程序、人际和信息公平都显著影响工作满意度，其中人际公平影响最大。研究还发现，公平对女性、少数族裔、经验较少和有工作限制的从业者影响更强，并指出署名公平、政策执行、高需求情况和工作时间等方面的公平对不同群体有特定影响。研究强调了公平的重要性，并为组织提供了提升公平实践的建议。

> **摘要翻译:** 软件从业者经常遇到职场不公，例如不平等的认可和性别偏见。尽管公平与工作满意度之间的联系已在其他领域确立，但其与软件专业人士的相关性仍未得到充分探索。本研究旨在探讨公平感如何与软件从业者的工作满意度相关联，重点关注普遍趋势和人口统计学上的具体差异。我们对108名软件从业者进行了一项在线调查，随后采用序数逻辑回归分析了软件工程背景下公平感与工作满意度之间的关系，并进行了调节分析以考察这种关系在不同人口群体中的差异。我们的研究结果表明，所有四种公平维度（即分配公平、程序公平、人际公平和信息公平）都显著影响整体工作满意度和工作保障满意度。其中，人际公平影响最大。公平与工作满意度之间的关系对女性、少数族裔、经验较少的从业者和有工作限制的人群更强。署名公平是影响集体工作满意度的重要因素，而政策执行、高需求情况和工作时间方面的公平则影响特定人口群体。本研究强调了公平在软件从业者中的作用，为组织提供了促进公平实践和针对特定人口群体的策略。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [509] [How Software Engineers Engage with AI: A Pragmatic Process Model and Decision Framework Grounded in Industry Observations](https://arxiv.org/abs/2507.17930)
> *软件工程师如何与AI协作：一个基于行业观察的实用过程模型和决策框架*

*Vahid Garousi, Zafar Jafarov* | **Category: cs.SE** | **Updated: 2025-07-23**

**Keywords:** 软件工程, 人工智能, 人机协作, 过程模型, 决策框架

**Comment:** 

> **TL;DR:** 该论文基于行业观察提出了一个实用过程模型和决策框架，旨在指导软件工程师有效使用AI工具，解决软件工程中人机协作的未充分探索领域。

**AI_Comments:** 该论文的创新之处在于直接从真实的行业观察中推导出实用模型（过程模型和决策框架），为软件工程中的人机协作提供了具体指导，这在AI工具（如Copilot）兴起的背景下至关重要。其对提示设计和决策权衡等实用方面的关注使其对从业者具有高度相关性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管AI工具有潜力改变软件工程，但软件工程师在日常任务中如何与这些工具互动，特别是在信任、改进或拒绝AI生成输出方面的决策过程，仍未得到充分探索。

**Method:** 本研究基于土耳其和阿塞拜疆三个行业环境中的从业者报告和直接观察，阐明了工程师在人工监督下如何使用AI。

**Result:** 本文提出了两项互补的贡献：一个实用的过程模型，捕捉了AI辅助软件工程的真实活动（包括提示设计、检查、回退和优化）；以及一个二维决策框架，帮助开发者权衡节省的精力与输出质量。

**Conclusion:** 这些模型为软件工程中更审慎和有效地使用AI工具提供了结构化、轻量级的指导，有助于当前关于实际人机协作的讨论。

> **ai_Abstract:** 本文探讨了软件工程师在日常任务中如何与AI工具交互这一未充分探索的领域。它提出了一个实用的AI辅助软件工程活动过程模型（例如，提示设计、优化）和一个二维决策框架，用于评估节省的精力与输出质量之间的权衡。这些基于行业观察的贡献为软件工程中有效的人机协作提供了结构化指导。

> **摘要翻译:** 人工智能（AI）通过提高生产力、效率和决策支持，有潜力改变软件工程（SE）。GitHub Copilot和ChatGPT等工具催生了“氛围编程”——一种探索性、提示驱动的开发风格。然而，软件工程师在日常任务中如何使用这些工具，特别是在决定信任、优化或拒绝AI生成输出方面，仍未得到充分探索。本文提出了两项互补的贡献。首先，一个实用的过程模型，捕捉了真实的AI辅助软件工程活动，包括提示设计、检查、回退和优化。其次，一个二维决策框架，可以帮助开发者权衡节省的精力与输出质量。我们的工作基于土耳其和阿塞拜疆三个行业环境中的从业者报告和直接观察，阐明了工程师在人工监督下如何使用AI。这些模型为软件工程中更审慎和有效地使用AI工具提供了结构化、轻量级的指导，有助于当前关于实际人机协作的讨论。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [528] [Exploring and Evaluating Interplays of BPpy with Deep Reinforcement Learning and Formal Methods](https://arxiv.org/abs/2501.15480)
> *探索和评估BPpy与深度强化学习和形式化方法之间的相互作用*

*Tom Yaacov, Gera Weiss, Adiel Ashrov, Guy Katz, Jules Zisser* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 行为编程, 深度强化学习, 形式化方法, BPpy, 系统集成

**Comment:** Accepted to the 20th International Conference on Evaluation of Novel
  Approaches to Software Engineering (ENASE 2025)

> **TL;DR:** 本文探索并评估了行为编程（BP）与人工智能（AI）和形式化方法（FM）技术的互动，旨在证明BP可以作为整合多种技术的抽象层，以实现多方面分析和丰富的开发过程，并展示了BPpy框架如何通过集成SMT求解器、模型检测和深度强化学习来扩展BP建模复杂系统的能力。

**AI_Comments:** 这篇论文的创新点在于提出了行为编程（BP）作为一种通用抽象层，能够有效地整合人工智能（AI）和形式化方法（FM）。这种整合为复杂系统建模和开发提供了一个统一的框架，有望提高开发效率和系统可靠性。其重要性在于，它为跨领域技术的协同应用提供了新的视角和实践路径，特别是在处理复杂且需要高可靠性的AI系统时具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在证明行为编程（BP）可以作为一个抽象层，整合各种人工智能（AI）和形式化方法（FM）技术，从而实现多方面的分析和丰富的开发过程。

**Method:** 本文通过具体研究BPpy框架（一个基于Python的BP实现）如何被各种形式化方法和AI工具增强以及如何增强这些工具来探索和评估BP与AI/FM技术的互动。研究评估了将BP与SMT求解器、符号和概率模型检测以及深度强化学习（DRL）等工具集成，如何扩展BP建模复杂系统的能力。

**Result:** 研究结果表明，将BP与SMT求解器、符号和概率模型检测以及深度强化学习（DRL）等工具集成，能够扩展BP建模复杂系统的能力。此外，论文还展示了开发人员如何在单一建模和开发任务中利用多种工具，并提供了定量和定性证据支持其创建统一开发框架中利用AI和FM方法的综合工具箱的愿景的可行性。

**Conclusion:** 本文的结论是，通过将行为编程（BP）与人工智能（（AI）和形式化方法（FM）技术整合，可以创建一个统一的开发框架和综合工具箱，从而有效地利用这些方法来建模和分析复杂系统。研究提供了支持这一愿景可行性的证据。

> **ai_Abstract:** 本文探讨并评估了行为编程（BP）与人工智能（AI）和形式化方法（FM）技术的相互作用。研究旨在证明BP能够作为整合多种技术的抽象层，从而实现多方面分析和高效开发。论文具体考察了BPpy框架如何通过与SMT求解器、模型检测和深度强化学习（DRL）等工具集成，来增强BP建模复杂系统的能力。研究提供了定量和定性证据，支持创建一个统一的开发框架，以利用AI和FM方法的愿景。

> **摘要翻译:** 我们探索并评估了行为编程（BP）与一系列人工智能（AI）和形式化方法（FM）技术之间的相互作用。我们的目标是证明BP可以作为一种抽象层，整合各种技术，从而实现多方面的分析和丰富的开发过程。具体来说，本文研究了BPpy框架（一个基于Python的BP实现）如何被各种形式化方法和AI工具增强，以及如何增强这些工具。我们评估了将BP与SMT求解器、符号和概率模型检测以及深度强化学习（DRL）等工具集成，如何使我们能够扩展BP建模复杂系统的能力。此外，我们还阐述了开发人员如何在单一建模和开发任务中利用多种工具。本文提供了定量和定性证据，支持我们创建一个综合工具箱的愿景的可行性，该工具箱用于在统一的开发框架中利用AI和FM方法。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [557] [Use as Directed? A Comparison of Software Tools Intended to Check Rigor and Transparency of Published Work](https://arxiv.org/abs/2507.17991)
> *依指示使用？一项旨在检查已发表工作严谨性和透明度的软件工具比较*

*Peter Eckmann, Adrian Barnett, Alexandra Bannach-Brown, Elisa Pilar Bascunan Atria, Guillaume Cabanac, Louise Delwen Owen Franzen, Małgorzata Anna Gazda, Kaitlyn Hair, James Howison, Halil Kilicoglu, Cyril Labbe, Sarah McCann, Vladislav Nachev, Martijn Roelandse, Maia Salholz-Hillel, Robert Schulz, Gerben ter Riet, Colby Vorland, Anita Bandrowski, Tracey Weissgerber* | **Category: cs.SE, cs.IR** | **Updated: 2025-07-23**

**Keywords:** 可重复性危机, 自动化工具, 严谨性, 透明度, 工具比较

**Comment:** 

> **TL;DR:** 本文比较了11种自动化工具，旨在检查已发表科学工作的严谨性和透明度，并提出了改进建议。

**AI_Comments:** 本文针对科学出版物中日益增长的可重复性危机提供了实际的解决方案。其创新之处在于对现有自动化工具进行了系统性的比较评估，这对于理解当前工具的优势和局限性至关重要。研究不仅指出了表现优异的工具或组合，更重要的是，它识别了工具开发需要改进的关键领域，为未来的工具开发指明了方向，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 科学报告中缺乏标准化和透明度导致了可重复性危机。尽管存在如ARRIVE和CONSORT等核对清单，但作者不总是遵循，同行评审也常未能发现缺失项。为解决这些问题，研究人员设计了多种自动化工具来检查不同的严谨性标准。

**Method:** 本研究对来自ScreenIT组的11种自动化工具进行了广泛比较，评估了它们在9个不同的严谨性标准下的表现。

**Result:** 研究发现，在某些标准（如开放数据检测）上，工具组合中存在一个表现远优于其他工具的“明显赢家”。而在其他情况下（如纳入和排除标准检测），工具组合的性能超越了任何单一工具的性能。研究还识别了工具开发者应重点关注的关键领域。

**Conclusion:** 研究总结了一系列见解和建议，旨在帮助严谨性和透明度检测工具的开发者和相关利益方。

> **ai_Abstract:** 本文旨在应对科学报告中的可重复性危机，通过比较11种自动化工具在9个严谨性标准上的表现。研究发现，在某些任务上存在表现出色的单一工具，而在其他任务上，工具的组合表现更优。文章还提出了针对工具开发者的改进建议，以提高这些工具的实用性，并为相关利益方提供了见解和建议，以促进严谨性和透明度检测工具的开发。

> **摘要翻译:** 可重复性危机的原因包括科学报告中缺乏标准化和透明度。ARRIVE和CONSORT等核对清单旨在提高透明度，但作者并不总是遵循，同行评审也常常未能识别缺失项。为了解决这些问题，已经设计了几种自动化工具来检查不同的严谨性标准。我们对来自ScreenIT组的11种自动化工具进行了广泛比较，涵盖了9个不同的严谨性标准。我们发现某些标准（包括开放数据检测）下，工具组合显示出明显的赢家，某个工具的表现远优于其他工具。在其他情况下（包括纳入和排除标准检测），工具组合的性能超越了任何单一工具。我们还确定了工具开发者应重点关注的关键领域，以使其工具发挥最大效用。最后，我们为严谨性和透明度检测工具的开发利益相关者提供了一系列见解和建议。本研究的代码和数据可在https://github.com/PeterEckmann1/tool-comparison获取。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [576] [On the Structure and Semantics of Identifier Names Containing Closed Syntactic Category Words](https://arxiv.org/abs/2505.18444)
> *关于包含封闭句法类别词的标识符名称的结构和语义*

*Christian D. Newman, Anthony Peruma, Eman Abdullah AlOmar, Mahie Crabbe, Syreen Banabilah, Reem S. AlSuhaibani, Michael J. Decker, Farhad Akhbardeh, Marcos Zampieri, Mohamed Wiem Mkaouer, Jonathan I. Maletic* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 标识符名称, 封闭句法类别, 语法模式, 代码理解, 命名

**Comment:** Accepted by Empirical Software Engineering (EMSE)

> **TL;DR:** 本文研究了代码标识符名称中封闭句法类别词的语言结构和语义，构建了一个新数据集CCID，并揭示了开发者如何通过命名表达程序行为。

**AI_Comments:** 本文的创新之处在于其首次聚焦于软件工程中鲜有研究的封闭句法类别词在标识符命名中的作用，并构建了专门的CCID数据集。通过结合语言学和软件工程方法，为理解代码命名背后的语言学原理提供了重要的经验基础，对程序理解、命名规范和教育具有潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 标识符名称是理解程序行为的关键线索。尽管封闭句法类别词在自然语言中扮演核心角色，但在软件工程中却鲜有研究。本文旨在填补这一空白，深入探究这些词在标识符命名中的结构和语义，以理解它们如何编码程序行为。

**Method:** 本文通过扩展语法模式概念来研究标识符名称的语言结构。具体方法包括：1. 构建了一个新的手动标注数据集——封闭类别标识符数据集（CCID），包含从30个开源系统中提取的1,275个标识符。2. 使用扎根理论启发式编码、统计分析和模式分析，分析封闭类别语法模式与程序行为之间的关系。

**Result:** 研究结果揭示了开发者在命名中用于表达概念（如控制流、数据转换、时间推理及其他行为角色）的重复结构。

**Conclusion:** 本文为理解语言资源如何在标识符名称中编码行为提供了经验基础，并为命名、程序理解和教育领域的新研究方向提供了支持。

> **ai_Abstract:** 本文深入探讨了代码标识符名称中包含封闭句法类别词（如介词、连词）的语言结构和语义。研究通过构建一个包含1275个标识符的新数据集CCID，并运用扎根理论启发式编码、统计和模式分析，揭示了开发者如何利用这些词汇在命名中表达控制流、数据转换等程序行为。这项工作为理解标识符命名中的语言编码行为提供了实证基础，并为相关研究领域开辟了新方向。

> **摘要翻译:** 标识符名称是代码的关键组成部分，是开发者理解程序行为的主要线索。本文通过扩展语法模式的概念来研究标识符名称的语言结构，这些语法模式代表了标识符短语背后的词性（PoS）序列。具体关注的是封闭句法类别词（例如，介词、连词、限定词），尽管它们在一般自然语言中扮演核心角色，但在软件工程中却鲜有研究。为了研究这些类别，本文构建并提出了封闭类别标识符数据集（CCID），这是一个新的手动标注数据集，包含从30个开源系统中提取的1,275个标识符。随后，利用扎根理论启发式编码、统计分析和模式分析，分析了封闭类别语法模式与程序行为之间的关系。结果揭示了开发者通过命名表达概念（如控制流、数据转换、时间推理及其他行为角色）的重复结构。这项工作为理解语言资源如何在标识符名称中编码行为提供了经验基础，并支持命名、程序理解和教育领域的新研究方向。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [605] [An Empirical Study of GenAI Adoption in Open-Source Game Development: Tools, Tasks, and Developer Challenges](https://arxiv.org/abs/2507.18029)
> *开源游戏开发中生成式AI采纳的实证研究：工具、任务与开发者挑战*

*Xiang Echo Chen, Wenhan Zhu, Guoshuai Albert Shi, Michael W. Godfrey* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 生成式AI, 开源, 游戏开发, 采纳, 挑战

**Comment:** 

> **TL;DR:** 现有研究对开源游戏开发中生成式AI的采纳情况了解有限。本研究通过分析GitHub议题，探讨生成式AI工具、任务和挑战，并与传统AI进行比较。

**AI_Comments:** 该论文关注了一个及时且相关的主题，即生成式AI在游戏开发中的应用。其对开源社区的关注以及对GitHub讨论的实证分析，为理解现实世界中的采纳情况和挑战提供了独特的视角，超越了理论讨论。与传统AI和非AI的比较分析是其一大亮点。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现有研究已经探讨了AI在游戏中的传统用途（如控制代理或生成程序内容），但对于生成式AI（GenAI）如何在真实世界环境中被开发者采纳，尤其是在开源社区中，缺乏实证性的理解。

**Method:** 本研究旨在通过分析GitHub上的议题讨论，探索生成式AI技术在开源游戏开发中如何被讨论、采纳和整合。研究通过比较GenAI相关议题与传统AI（TradAI）和非AI话题的议题，调查与GenAI相关的工具、任务和挑战。为实现此目标，研究构建了一个讨论AI相关话题的开源游戏仓库数据集，并对GitHub议题的分层样本应用开放式卡片分类和主题分析，对每种类型和内容进行标注，从而进行GenAI、TradAI和非AI组之间的比较分析。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究旨在填补开源游戏开发领域中生成式AI（GenAI）采纳的实证理解空白。通过分析GitHub上的议题讨论，研究探索了GenAI工具、任务和开发者面临的挑战，并将其与传统AI和非AI话题进行比较。研究构建了一个开源游戏仓库数据集，并利用开放式卡片分类和主题分析方法对GitHub议题进行标注和比较分析，以揭示GenAI对开发者工作流程和痛点的影响。

> **摘要翻译:** 生成式人工智能（GenAI）日益增长的能力已开始重塑游戏的设计和开发方式，为内容创作、游戏玩法模拟和设计构思提供了新工具。虽然先前的研究已经探讨了AI在游戏中的传统用途，例如控制代理或生成程序内容，但对于GenAI如何在真实世界环境中被开发者采纳，尤其是在开源社区中，实证理解有限。本研究旨在通过分析GitHub上的议题讨论，探索GenAI技术如何在开源游戏开发中被讨论、采纳和整合。我们通过比较GenAI相关议题与涉及传统AI（TradAI）和非AI话题的议题，调查与GenAI相关的工具、任务和挑战。我们的目标是揭示GenAI在使用模式、开发者关注点和集成实践方面与其它方法的不同之处。为实现此目标，我们构建了一个讨论AI相关话题的开源游戏仓库数据集。我们对GitHub议题的分层样本应用开放式卡片分类和主题分析，对每种类型和内容进行标注。这些标注使得GenAI、TradAI和非AI组之间的比较分析成为可能，并提供了关于GenAI如何塑造开源游戏开发者工作流程和痛点的见解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [624] [OpenCAMS: An Open-Source Connected and Automated Mobility Co-Simulation Platform for Advancing Next-Generation Intelligent Transportation Systems Research](https://arxiv.org/abs/2507.09186)
> *OpenCAMS：一个开源的互联自动化出行协同仿真平台，用于推进下一代智能交通系统研究*

*Minhaj Uddin Ahmad, Akid Abrar, Sagar Dasgupta, Mizanur Rahman* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 协同仿真, 智能交通系统, 开源, 交通模拟, V2X

**Comment:** 

> **TL;DR:** OpenCAMS是一个开源的协同仿真平台，结合SUMO、CARLA和OMNeT++，用于研究下一代智能交通系统。

**AI_Comments:** OpenCAMS的创新之处在于其将SUMO、CARLA和OMNeT++这三个在各自领域表现卓越的仿真工具进行紧密协同，从而弥补了单一仿真工具在复杂智能交通系统研究中的局限性。其时间同步的双向耦合架构保证了多领域仿真的一致性，同时保持了模块化和可扩展性，这对于未来研究的灵活性至关重要。作为一个完全开源的平台，它极大地降低了研究门槛，并促进了社区协作，对推进下一代智能交通系统研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过结合不同仿真领域的优势，支持交通安全、出行和网络安全方面的高级研究。

**Method:** OpenCAMS是一个开源、同步、可扩展的协同仿真框架，紧密耦合了SUMO（大规模微观交通建模）、CARLA（高保真3D感知、车辆动力学和控制仿真）和OMNeT++（模块化、事件驱动的网络通信，如C-V2X）。它采用时间同步、双向耦合架构，确保交通、感知和通信领域的一致仿真进展，同时保持模块化和可复现性。该平台还设计为可扩展，允许集成额外的仿真器。

**Result:** OpenCAMS成功地将SUMO、CARLA和OMNeT++三个仿真工具紧密耦合，形成了一个协同仿真平台。该平台能够模拟和渲染需要详细传感器仿真和控制逻辑的车辆子集（CARLA），协调网络范围的交通流、车辆路径和交通信号管理（SUMO），并动态映射通信节点到移动和静态实体以实现C-V2X通信（OMNeT++）。

**Conclusion:** OpenCAMS为研究社区提供了一个可访问、灵活、协作的环境，用于推进下一代智能交通系统，并且是完全开源和公开可用的。

> **ai_Abstract:** OpenCAMS是一个开源的协同仿真平台，它通过紧密耦合SUMO、CARLA和OMNeT++，为下一代智能交通系统研究提供支持。该平台结合了大规模交通建模、高保真感知与车辆动力学以及灵活的网络通信模拟能力，采用时间同步的双向耦合架构，确保仿真的一致性和可复现性。OpenCAMS旨在促进交通安全、出行和网络安全领域的高级研究，并具备良好的可扩展性，已开源供研究社区使用。

> **摘要翻译:** 我们介绍了OpenCAMS（开源互联自动化出行协同仿真平台），这是一个开源、同步且可扩展的协同仿真框架，它紧密耦合了三个一流的仿真工具：(i) SUMO，(ii) CARLA，和 (iii) OMNeT++。OpenCAMS旨在通过结合每个仿真领域的优势来支持交通安全、出行和网络安全方面的高级研究。具体来说，SUMO提供大规模微观交通建模；CARLA提供高保真3D感知、车辆动力学和控制仿真；OMNeT++则实现模块化、事件驱动的网络通信，例如蜂窝车联网 (C-V2X)。OpenCAMS采用时间同步、双向耦合架构，确保交通、感知和通信领域的一致仿真进展，同时保持模块化和可复现性。例如，CARLA可以仿真和渲染需要详细传感器仿真和控制逻辑的车辆子集；SUMO协调网络范围的交通流、车辆路径和交通信号管理；OMNeT++动态地将通信节点映射到移动实体（例如车辆）和静态实体（例如路边单元）以实现C-V2X通信。虽然这三个仿真器构成了OpenCAMS的基础核心，但该平台被设计为可扩展且面向未来，允许在不改变系统基本架构的情况下集成额外的仿真器。OpenCAMS平台是完全开源的，并通过其GitHub仓库 https://github.com/minhaj6/carla-sumo-omnetpp-cosim 公开可用，为研究社区提供了一个可访问、灵活、协作的环境，以推进下一代智能交通系统。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [653] [Factors Impacting Faculty Adoption of Project-Based Learning in Computing Education: a Survey](https://arxiv.org/abs/2507.18039)
> *影响计算机教育中教师采纳项目式学习的因素：一项调查*

*Ahmad D. Suleiman, Yiming Tang, Daqing Hou* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 项目式学习, 教师采纳, 计算机教育, 障碍, 支持

**Comment:** Accepted at IEEE Frontiers in Education (FIE) 2025. This work has
  been submitted to the IEEE for possible publication

> **TL;DR:** 尽管项目式学习（PjBL）对学生有益，但教师的采纳仍不一致。本研究通过调查发现，规划管理、项目设计和机构支持不足是主要障碍，而同伴协作、专业发展和机构激励能促进采纳。

**AI_Comments:** 本研究通过实证调查揭示了计算机教育领域教师采纳项目式学习的深层障碍与促进因素，为教育机构制定有效的支持策略提供了宝贵的见解。其混合方法研究设计增加了结果的可信度，对于推动PjBL的普及具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 项目式学习（PjBL）被认为是一种以学生为中心的教学方法，有潜力提升学生的学习动力、参与度、批判性思维、协作和问题解决能力。然而，尽管有这些益处，由于制度支持不足、时间限制、培训机会有限、项目设计或获取困难以及与课程目标对齐等挑战，教师对PjBL的采纳仍然不一致。本研究旨在探讨这些障碍，并调查促进成功采纳的策略和资源。

**Method:** 本研究采用混合方法，通过在线调查收集了80名计算机教师的数据。调查包含封闭式问题以量化障碍、促成因素和资源需求，以及开放式问题以收集定性见解。定量数据采用统计方法分析，定性回答则进行主题分析。

**Result:** 结果显示，尽管PjBL被广泛重视，但其采纳往往是选择性的，并受到规划和管理学习过程、设计合适项目以及缺乏机构支持（如时间、资金和助教）等挑战的影响。当教师能够获得同伴协作、专业发展和机构激励时，他们更有可能采纳或维持PjBL。此外，从研究、行业合作中获取项目以及向同行借用项目是新项目获取的关键促进因素。

**Conclusion:** 研究结果强调，需要系统性的支持结构来赋能教师尝试和推广项目式学习实践。

> **ai_Abstract:** 本研究调查了影响计算机教育者采纳项目式学习（PjBL）的因素。尽管PjBL对学生有显著益处，但其采纳受限于机构支持不足、时间限制和项目设计等挑战。通过对80名计算机教师的混合方法调查，研究发现规划管理、项目设计和机构支持不足是主要障碍，而同伴协作、专业发展和机构激励能显著促进PjBL的采纳。研究强调，为推广PjBL实践，系统性支持结构至关重要。

> **摘要翻译:** 本研究全文探讨了影响计算机教育工作者在软件工程和计算课程中采纳项目式学习（PjBL）的因素。PjBL作为一种以学生为中心的教学方法，被认为有潜力增强学生的学习动力、参与度、批判性思维、协作和问题解决能力。尽管有这些益处，但由于机构支持不足、时间限制、培训机会有限、设计或获取项目以及将其与课程目标对齐等挑战，教师的采纳仍然不一致。本研究探讨了这些障碍，并调查了促进成功采纳的策略和资源。本研究采用混合方法，通过一项在线调查收集了80名计算机教师的数据，该调查包括量化障碍、促成因素和资源需求的封闭式问题，以及收集定性见见的开放式问题。定量数据采用统计方法分析，而定性回答则进行主题分析。结果显示，尽管PjBL被广泛重视，但其采纳往往是选择性的，并受到规划和管理学习过程、设计合适项目以及缺乏机构支持（如时间、资金和助教）等挑战的影响。当教师能够获得同伴协作、专业发展和机构激励时，他们更有可能采纳或维持PjBL。此外，从研究、行业合作中获取项目以及向同行借用项目是新项目获取的关键促进因素。这些发现强调了需要系统性的支持结构来赋能教师尝试和推广PjBL实践。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [671] [HLSTester: Efficient Testing of Behavioral Discrepancies with LLMs for High-Level Synthesis](https://arxiv.org/abs/2504.14641)
> *HLSTester：使用大型语言模型高效测试高级综合中的行为差异*

*Kangwei Xu, Bing Li, Grace Li Zhang, Ulf Schlichtmann* | **Category: cs.SE, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 高级综合, 行为差异, 大型语言模型, 测试, FPGA

**Comment:** arXiv admin note: text overlap with arXiv:2407.03889

> **TL;DR:** HLSTester是一个LLM辅助的框架，用于高效检测高级综合（HLS）中的行为差异，通过生成HLS兼容的测试平台和优化测试输入来加速测试流程并提高通过率。

**AI_Comments:** 本文创新性地将大型语言模型（LLM）引入高级综合（HLS）的行为差异测试中，通过利用现有C/C++测试平台指导LLM生成HLS兼容的测试平台，有效缓解了LLM的幻觉问题并提高了提示质量。其结合反向切片技术识别关键变量和基于LLM的动态变异输入生成机制，显著提升了测试效率和准确性，解决了现有HLS测试方法不成熟且耗时的问题。

<details>
  <summary>Details</summary>

**Motivation:** 现有高级综合（HLS）中行为差异的测试方法不成熟且需要大量人工投入，导致原始C/C++程序与综合后电路之间存在行为差异。

**Method:** 提出HLSTester，一个LLM辅助的测试框架。通过利用原始C/C++程序的测试平台来指导LLM生成HLS兼容的测试平台，以减少LLM幻觉并提高提示质量。使用反向切片技术识别C/C++和HLS程序中的关键变量，以监控其运行时谱并深入分析差异症状。引入测试输入生成机制，结合动态变异和基于LLM的渐进推理链的洞察力来减少测试时间。采用冗余感知过滤技术跳过重复的硬件测试。

**Result:** 实验结果表明，所提出的LLM辅助测试框架显著加速了测试流程，并且与传统方法以及直接使用LLM相比，在相同的HLS程序上实现了更高的测试平台仿真通过率。

**Conclusion:** HLSTester能够高效检测HLS中的行为差异，显著加速测试流程并提高测试通过率。

> **ai_Abstract:** HLSTester是一个LLM辅助的框架，旨在高效检测高级综合（HLS）中C/C++程序与生成电路之间的行为差异。它通过利用现有C/C++测试平台指导LLM生成HLS兼容的测试平台，结合反向切片技术监控关键变量，并引入基于LLM的动态变异输入生成和冗余过滤来优化测试流程。实验证明，该框架显著提高了测试效率和仿真通过率。

> **摘要翻译:** 在高级综合（HLS）中，带有综合指令的C/C++程序用于生成FPGA实现的电路。然而，这些实现中硬件特定和平台相关的特性可能在原始C/C++程序和高级综合后的电路之间引入行为差异。现有的HLS行为差异测试方法仍不成熟，且测试流程需要大量人工投入。为了解决这一挑战，我们提出了HLSTester，一个由大型语言模型（LLM）辅助的测试框架，能够高效检测HLS中的行为差异。为了减轻LLM中的幻觉并提高提示质量，我们利用原始C/C++程序的测试平台来指导LLM生成与HLS兼容的测试平台，有效消除了某些与HLS工具不兼容的传统C/C++结构。通过对C/C++和HLS程序使用反向切片技术来确定关键变量，以监控它们的运行时谱，从而深入分析差异症状。为了缩短测试时间，引入了一种测试输入生成机制，将动态变异与基于LLM的渐进推理链的洞察力相结合。此外，通过对生成的测试输入采用冗余感知过滤技术，跳过了重复的硬件测试。实验结果表明，所提出的LLM辅助测试框架显著加速了测试流程，并且与传统方法以及直接使用LLM相比，在相同的HLS程序上实现了更高的测试平台仿真通过率。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [672] [LLMShot: Reducing snapshot testing maintenance via LLMs](https://arxiv.org/abs/2507.10062)
> *LLMShot：通过大型语言模型减少快照测试维护*

*Ergün Batuhan Kaynak, Mayasah Lami, Sahand Moslemi, Anil Koyuncu* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 快照测试, 大型语言模型, UI测试, 维护, 语义分类

**Comment:** Accepted to ICSME 2025

> **TL;DR:** LLMShot是一个利用视觉-语言模型（VLM）自动分析快照测试失败的框架，通过语义分类UI变化来减少人工维护工作，并在真实场景中表现出良好的分类性能。

**AI_Comments:** LLMShot的创新之处在于它是首个将视觉-语言模型应用于自动化语义快照测试分析的方法，有效解决了快照测试长期存在的维护难题。其重要性在于能够显著减少开发人员的人工分类工作量，并推动UI测试向更智能化的方向发展。然而，该研究也指出了当前基于提示的方法在可控视觉推理方面存在的局限性，这可能是未来研究需要关注的方向。

<details>
  <summary>Details</summary>

**Motivation:** 快照测试在现代软件开发中是UI验证的关键技术，但由于频繁的UI变化导致测试失败，需要人工检查来区分真正的回归和有意设计更改，从而产生大量的维护开销。这种人工分类过程随着应用程序的发展变得越来越繁重，因此需要自动化的分析解决方案。

**Method:** 本文介绍了LLMShot，一个利用视觉-语言模型（VLM）通过对UI变化的语义分类来自动分析快照测试失败的新颖框架。为了评估LLMShot的有效性，研究者开发了一个综合数据集，使用一个功能丰富的iOS应用程序，该程序具有可配置的功能标志，创建了产生真实快照差异的现实场景。

**Result:** 使用Gemma3模型的评估显示出强大的分类性能，其中12B变体在识别失败根本原因方面实现了超过84%的召回率，而4B模型则提供了实用的部署优势，在持续集成环境中具有可接受的性能。

**Conclusion:** LLMShot代表了首个自动化语义快照测试分析方法，为开发人员提供结构化洞察，可以显著减少人工分类工作，并推动更智能的UI测试范式。

> **ai_Abstract:** LLMShot是一个新颖的框架，旨在通过利用视觉-语言模型（VLM）对UI变化进行语义分类，从而自动化分析快照测试失败，以减少传统快照测试中由于频繁UI更新导致的大量人工维护工作。研究人员通过构建一个真实的iOS应用数据集来评估LLMShot，结果表明使用Gemma3模型实现了高效的故障原因识别（12B模型召回率超过84%），且4B模型在持续集成环境中表现良好。该研究首次实现了自动化语义快照测试分析，显著降低了开发人员的手动分类负担，并指出了当前基于提示的可控视觉推理方法的局限性。

> **摘要翻译:** 快照测试已成为现代软件开发中UI验证的关键技术，但由于频繁的UI更改导致测试失败，需要人工检查以区分真正的回归和有意设计更改，从而产生大量的维护开销。随着应用程序的发展，这种人工分类过程变得越来越繁重，因此需要自动化的分析解决方案。本文介绍了LLMShot，一个利用视觉-语言模型（VLM）通过对UI变化的语义分类来自动分析快照测试失败的新颖框架。为了评估LLMShot的有效性，我们使用一个功能丰富的iOS应用程序开发了一个综合数据集，该应用程序具有可配置的功能标志，创建了产生真实快照差异的现实场景，这些差异代表了真实的开发工作流程。我们使用Gemma3模型进行的评估显示出强大的分类性能，其中12B变体在识别失败根本原因方面实现了超过84%的召回率，而4B模型则提供了实用的部署优势，在持续集成环境中具有可接受的性能。然而，我们对选择性忽略机制的探索揭示了当前基于提示的方法在可控视觉推理方面存在显著局限性。LLMShot代表了首个自动化语义快照测试分析方法，为开发人员提供结构化洞察，可以显著减少人工分类工作，并推动更智能的UI测试范式。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [683] [OrQstrator: An AI-Powered Framework for Advanced Quantum Circuit Optimization](https://arxiv.org/abs/2507.09682)
> *OrQstrator：一个用于高级量子电路优化的AI驱动框架*

*Laura Baird, Armin Moin* | **Category: cs.SE, cs.AI, cs.ET** | **Updated: 2025-07-24**

**Keywords:** 量子电路优化, 深度强化学习, NISQ, OrQstrator, 电路编译

**Comment:** IEEE International Conference on Quantum Computing and Engineering
  (QCE) 2025 - Extended Abstract

> **TL;DR:** OrQstrator是一个AI驱动的模块化框架，利用深度强化学习和多种优化器在NISQ时代优化量子电路。

**AI_Comments:** OrQstrator的创新之处在于其模块化设计和结合深度强化学习与多种特定优化器的策略，并通过智能编排引擎进行协调。这使得它能够灵活且高效地应对NISQ时代量子电路优化的复杂挑战，尤其是在硬件感知方面。

<details>
  <summary>Details</summary>

**Motivation:** 在噪声中等规模量子（NISQ）时代，需要一个先进的框架来有效地进行量子电路优化。

**Method:** 本文提出了OrQstrator，一个由深度强化学习（DRL）驱动的模块化框架，用于量子电路优化。它包含三个互补的电路优化器：一个基于DRL的电路重写器，一个领域特定的优化器，以及一个参数化电路实例化器。这些模块由一个中央编排引擎协调，该引擎根据电路结构、硬件约束和后端感知性能特征（如门计数、深度和预期保真度）学习协调策略。该系统还利用现有最先进的NISQ分析器技术来适应后端约束。

**Result:** 该系统输出一个经过优化的电路，用于硬件感知的转译和执行。

**Conclusion:** OrQstrator通过结合深度强化学习和多种优化策略，为NISQ时代的量子电路优化提供了一个先进且模块化的解决方案，能够生成针对硬件优化的电路。

> **ai_Abstract:** OrQstrator是一个新颖的AI驱动模块化框架，旨在优化NISQ时代的量子电路。它利用深度强化学习，并集成了三种互补的优化器：一个DRL重写器、一个领域特定优化器和一个参数化实例化器。一个中央编排引擎智能地协调这些模块，根据电路结构、硬件约束和性能特征学习优化策略，最终生成用于硬件感知的转译和执行的优化电路。

> **摘要翻译:** 我们提出了一种新颖的方法OrQstrator，它是一个模块化框架，用于在噪声中等规模量子（NISQ）时代进行量子电路优化。我们的框架由深度强化学习（DRL）驱动。我们的编排引擎智能地从三个互补的电路优化器中进行选择：一个基于DRL的电路重写器，通过学习的重写序列来减少深度和门计数；一个执行高效局部门重合成和数值优化的领域特定优化器；一个参数化电路实例化器，通过在门集翻译过程中优化模板电路来改进编译。这些模块由一个中央编排引擎协调，该引擎根据电路结构、硬件约束和后端感知性能特征（如门计数、深度和预期保真度）学习协调策略。该系统输出一个经过优化的电路，用于硬件感知的转译和执行，利用现有最先进的NISQ分析器技术来适应后端约束。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [695] [An Empirical Study of Complexity, Heterogeneity, and Compliance of GitHub Actions Workflows](https://arxiv.org/abs/2507.18062)
> *GitHub Actions 工作流的复杂性、异构性和合规性实证研究*

*Edward Abrokwah, Taher A. Ghaleb* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** GitHub Actions, CI, 工作流, 复杂性, 合规性

**Comment:** Registered Report Accepted at the 41st IEEE International Conference
  on Software Maintenance and Evolution 2025 (ICSME'25)

> **TL;DR:** 本研究对GitHub Actions (GHA) 工作流的复杂性、异构性和合规性进行了实证分析，旨在了解开源项目中GHA工作流如何遵循最佳实践，并揭示需要改进的领域。

**AI_Comments:** 这项研究的重要性在于它填补了对现实世界CI工作流实践理解的空白，特别是在GitHub Actions这一主流平台上。通过大规模的实证分析，它有望为开发者和CI服务提供商提供具体、可操作的建议，以改进工作流的质量和效率。其创新之处在于结合了复杂性、异构性和合规性多个维度进行深入分析，并考虑了不同编程语言的影响。

<details>
  <summary>Details</summary>

**Motivation:** 尽管GitHub Actions (GHA) 是主流的CI服务且有官方文档和最佳实践，但目前缺乏对现实世界开源CI工作流如何遵循这些实践的实证理解。许多工作流可能过于复杂，不符合CI实践的简洁性目标。

**Method:** 本研究将调查开源软件仓库中GHA工作流的结构、复杂性、异构性和合规性。研究团队将使用来自Java、Python和C++仓库的大型GHA工作流数据集，旨在识别工作流复杂性、分析重复和异构的结构模式、评估与GHA最佳实践的合规性，并揭示不同编程语言之间CI管道设计的差异。

**Result:** 研究结果预计将揭示哪些方面严格遵循了最佳实践，以及哪些方面需要改进。

**Conclusion:** 这些研究洞察将对CI服务产生影响，凸显了CI文档中需要更清晰的指导方针和更全面的示例。

> **ai_Abstract:** 本研究对开源软件仓库中的GitHub Actions (GHA) 工作流进行了实证分析，旨在评估其复杂性、异构性及对现有最佳实践的合规性。通过分析Java、Python和C++项目中的GHA工作流大数据集，研究旨在识别常见复杂性、结构模式，并发现不同编程语言在CI管道设计上的差异。研究结果预计将为CI服务提供宝贵见解，指出需要改进的领域，并强调CI文档中提供更清晰指导和示例的重要性。

> **摘要翻译:** 持续集成（CI）已经从一种工具策略发展成为现代CI工程中的一种基本理念。它使团队能够快速、协作地开发、测试和交付软件。在CI服务中，GitHub Actions (GHA) 因其与GitHub的深度集成和庞大的可重用工作流行动生态系统而成为主导服务。尽管GHA提供了官方文档和社区支持的最佳实践，但目前对开源现实世界CI工作流如何与这些实践保持一致的实证理解似乎有限。许多工作流可能不必要地复杂，并且不符合CI实践的简洁性目标。本研究将调查开源软件仓库中GHA工作流的结构、复杂性、异构性和合规性。通过使用来自Java、Python和C++仓库的大型GHA工作流数据集，我们的目标是 (a) 识别工作流复杂性，(b) 分析重复和异构的结构模式，(c) 评估与GHA最佳实践的合规性，以及 (d) 揭示不同编程语言之间CI管道设计的差异。我们的发现预计将揭示严格遵循最佳实践的领域以及需要改进的领域。这些见解还将对CI服务产生影响，因为它们将强调CI文档中需要更清晰的指导方针和更全面的示例。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [714] [When Retriever Meets Generator: A Joint Model for Code Comment Generation](https://arxiv.org/abs/2507.12558)
> *当检索器遇到生成器：一种代码注释生成的联合模型*

*Tien P. T. Le, Anh M. T. Bui, Huy N. D. Pham, Alessio Bucaioni, Phuong T. Nguyen* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 代码注释生成, 检索增强, 联合模型, CodeT5, 对比学习

**Comment:** The paper has been peer-reviewed and accepted for publication in the
  proceedings of the 19th ACM/IEEE International Symposium on Empirical
  Software Engineering and Measurement (ESEM 2025)

> **TL;DR:** RAGSum是一个联合检索-生成模型，用于代码注释生成，通过对比预训练和复合损失函数优化，并在多个跨语言基准上显著优于现有基线。

**AI_Comments:** 该论文提出了一种新颖的联合检索-生成框架RAGSum，解决了传统检索增强方法中检索与生成独立优化导致的噪声传播问题。其创新点在于将检索和生成功能融合到单一CodeT5骨干中，并采用对比预训练和复合损失函数进行优化，同时引入轻量级自细化循环。这为代码注释自动化领域提供了一个更有效和高效的解决方案，有望提高生成注释的质量和相关性。

<details>
  <summary>Details</summary>

**Motivation:** 自动生成简洁、信息丰富的源代码注释可以减轻文档工作量并加速程序理解。然而，现有的检索增强方法通常孤立地优化检索和生成过程，导致不相关的邻居向下游传播噪声。

**Method:** 本文提出了一种名为RAGSum的新方法，旨在提高推荐的有效性和效率。RAGSum基于单个CodeT5骨干，融合了检索和生成功能。它包括一个对比预训练阶段，用于塑造代码嵌入以进行最近邻搜索；这些权重随后用于端到端训练，采用复合损失函数，该函数奖励准确的top-k检索并最小化注释生成错误。此外，还部署了一个轻量级自细化循环来完善最终输出。

**Result:** 该框架在三个跨语言基准（Java、Python、C）上进行了评估，并与三个成熟的基线进行了比较。结果表明，RAGSum在BLEU、METEOR和ROUTE-L方面显著优于基线。

**Conclusion:** 这些发现表明，紧密结合检索和生成可以提高注释自动化的上限，并激励未来的复现和定性开发者研究。

> **ai_Abstract:** RAGSum是一种新颖的联合检索-生成模型，旨在解决现有代码注释生成方法中检索和生成孤立优化导致的问题。该模型基于CodeT5骨干，通过对比预训练塑造代码嵌入，并利用复合损失函数进行端到端训练，同时引入轻量级自细化循环以优化输出。在Java、Python、C三个跨语言基准上的评估显示，RAGSum在多项指标上显著优于现有基线，证明了紧密结合检索与生成在代码注释自动化中的显著优势。

> **摘要翻译:** 自动为源代码生成简洁、信息丰富的注释可以减轻文档工作量并加速程序理解。检索增强方法首先获取带有现有注释的代码片段，然后合成新的注释，但检索和生成通常是孤立优化的，这使得不相关的邻居会向下游传播噪声。为了解决这个问题，我们提出了一种名为RAGSum的新方法，旨在提高推荐的有效性和效率。RAGSum建立在单个CodeT5骨干之上，融合了检索和生成功能。我们报告了基于CodeT5构建的统一检索-生成框架的初步结果。对比预训练阶段塑造了用于最近邻搜索的代码嵌入；这些权重随后用于端到端训练，采用复合损失函数，该函数（i）奖励准确的top-k检索；（ii）最小化注释生成错误。更重要的是，部署了一个轻量级自细化循环来完善最终输出。我们在三个跨语言基准（Java、Python、C）上评估了该框架，并将其与三个成熟的基线进行了比较。结果表明，我们的方法在BLEU、METEOR和ROUTE-L方面显著优于基线。这些发现表明，紧密结合检索和生成可以提高注释自动化的上限，并激励未来的复现和定性开发者研究。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [738] [Identifier Name Similarities: An Exploratory Study](https://arxiv.org/abs/2507.18081)
> *标识符名称相似性：一项探索性研究*

*Carol Wong, Mai Abe, Silvia De Benedictis, Marissa Halim, Anthony Peruma* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 标识符名称, 名称相似性, 代码理解, 认知负荷, 分类法

**Comment:** The 19th ACM/IEEE International Symposium on Empirical Software
  Engineering and Measurement - Emerging Results and Vision Track

> **TL;DR:** 糟糕的标识符名称会阻碍代码理解和协作。本研究探索了标识符名称相似性，提出了一种分类法来对不同形式的相似性进行分类，旨在帮助研究人员分析其影响。

**AI_Comments:** 这项研究的创新点在于提出了一个关于标识符名称相似性的分类法，为理解和量化这一问题提供了新的视角。其重要性在于，它为后续研究提供了一个基础工具，以深入探讨命名实践对软件质量和开发效率的影响。潜在的局限性可能在于其“探索性”和“初步发现”的性质，意味着还需要更多的验证和扩展。

<details>
  <summary>Details</summary>

**Motivation:** 标识符名称是程序理解的关键组成部分，但选择不当或与其他名称过于相似的名称会显著增加认知负荷，阻碍协作，并可能导致误解。

**Method:** 本研究是一项探索性研究。作者开发了一个分类法，用于对不同形式的标识符名称相似性进行分类，并提出了关于软件项目中标识符名称相似性发生情况的初步发现。

**Result:** 初步发现了软件项目中标识符名称相似性的发生情况，并开发了一个初始分类法，用于对不同形式的相似性进行分类。

**Conclusion:** 该初始分类法为研究人员提供了一个平台，用于分析和评估标识符名称相似性对代码理解、可维护性和协作的影响，并允许对该分类法进行进一步的完善和扩展。

> **ai_Abstract:** 本项探索性研究调查了软件项目中标识符名称相似性的发生情况，这种相似性可能因增加认知负荷和阻碍协作而损害程序理解。研究者开发了一个分类法，用于对不同形式的标识符名称相似性进行分类，并呈现了初步发现。该分类法旨在为未来的研究提供基础，以评估标识符名称相似性对代码理解、可维护性和开发者协作的影响。

> **摘要翻译:** 标识符名称占据了代码库的很大一部分，是有效程序理解的基石。然而，研究表明，选择不当的名称会显著增加认知负荷并阻碍协作。即使是孤立看起来可读的名称，当它们在结构或功能上与其他名称非常相似时，也可能在特定上下文中导致误解。在这项探索性研究中，我们通过开发一个对不同形式的标识符名称相似性进行分类的分类法，展示了我们关于软件项目中标识符名称相似性发生情况的初步发现。我们设想我们的初始分类法能为研究人员提供一个平台，用于分析和评估标识符名称相似性对代码理解、可维护性以及开发人员之间协作的影响，同时也允许对分类法进行进一步的完善和扩展。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [747] [SDVDiag: A Modular Platform for the Diagnosis of Connected Vehicle Functions](https://arxiv.org/abs/2507.19403)
> *SDVDiag：一个用于联网车辆功能诊断的模块化平台*

*Matthias Weiß, Falk Dettinger, Michael Weyrich* | **Category: cs.SE, cs.AI, cs.DC, B.8.2; C.2.4** | **Updated: 2025-07-25**

**Keywords:** 联网车辆诊断, 软件定义车辆, 自动化诊断, 故障排除, 模块化平台

**Comment:** 7 pages, 5 figures

> **TL;DR:** SDVDiag是一个可扩展平台，用于自动诊断联网车辆功能，通过自动化分析和动态依赖图来快速识别故障根源。

**AI_Comments:** 该论文提出了一种解决联网车辆复杂故障诊断挑战的自动化平台。其创新点在于模块化设计、运行时自适应能力、动态依赖图的构建以及结合异常监控的自动化分析流程。这对于提高联网车辆的可靠性和可用性，以及支持自动驾驶功能至关重要。该平台有望显著减少故障排除时间和成本，为未来车辆诊断系统提供了有价值的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 联网和软件定义车辆对高可靠性和可用性有严格要求，但其复杂的云/边缘架构和依赖关系使得手动诊断故障根源不可行且耗时，因此需要自动化解决方案来快速解决问题。

**Method:** 本文提出了SDVDiag，一个可扩展的自动化诊断平台。该平台能够创建从数据收集到潜在根源追踪的诊断管道，并支持通过运行时模块交换实现自适应行为。它检测并持续更新功能间的依赖关系，形成动态系统图。平台还会监控系统指标的异常，并在事件调查时捕获图快照并增强异常信息，最终通过遍历图来排名最可能的原因。

**Result:** 平台在5G测试车队环境中进行了部署和评估，结果表明它能够可靠地检测注入的故障。这表明该平台有潜力通过在早期阶段识别问题及其原因来获得新见解并减少停机时间。

**Conclusion:** SDVDiag平台能够可靠地检测联网车辆中的故障，并通过早期识别问题及其原因，有望提供新见解并减少停机时间。

> **ai_Abstract:** 本文介绍了SDVDiag，一个为联网和软件定义车辆设计的模块化、可扩展平台，旨在自动化故障诊断过程。针对传统手动分析在复杂云/边缘架构中效率低下且耗时的问题，SDVDiag通过构建从数据收集到根源追踪的自动化管道，并支持运行时模块交换实现自适应。它动态检测并更新功能间的依赖关系，形成系统图视图，并结合异常监控进行故障分析，最终通过图遍历对可能的原因进行排名。在5G测试车队环境中的评估表明，SDVDiag能可靠检测故障，有望提高诊断效率并减少车辆停机时间。

> **摘要翻译:** 联网和软件定义的车辆有望为客户提供广泛的服务和高级功能，旨在提高乘客舒适度并支持自动驾驶能力。由于联网车辆对高可靠性和可用性的要求，快速解决任何发生的故障至关重要。然而，要实现这一点，必须在具有网状依赖关系的复杂云/边缘架构中进行导航以诊断负责的根本原因。因此，手动分析变得不可行，因为它们会显著延迟故障排除。
为了解决这一挑战，本文提出了SDVDiag，一个用于联网车辆功能自动化诊断的可扩展平台。该平台能够创建涵盖从初始数据收集到潜在根本原因追踪所有步骤的管道。此外，SDVDiag通过在运行时交换模块的能力来支持自适应行为。功能之间的依赖关系被检测并持续更新，从而形成系统的动态图视图。此外，关键系统指标被监控以发现异常。每当调查事件时，都会获取图的快照并用相关异常进行增强。最后，通过遍历图并创建最可能原因的排名来执行分析。
为了评估该平台，它被部署在用于联网车辆功能的5G测试车队环境中。结果表明，可以可靠地检测注入的故障。因此，该平台通过在早期阶段识别问题及其原因，提供了获得新见解和减少停机时间的潜力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [767] [NoCode-bench: A Benchmark for Evaluating Natural Language-Driven Feature Addition](https://arxiv.org/abs/2507.18130)
> *NoCode-bench：一个评估自然语言驱动功能添加的基准*

*Le Deng, Zhonghao Jiang, Jialun Cao, Michael Pradel, Zhongxin Liu* | **Category: cs.SE** | **Updated: 2025-07-24**

**Keywords:** 自然语言处理, 无代码开发, 大语言模型, 基准测试, 特征添加

**Comment:** 

> **TL;DR:** 引入NoCode-bench，一个用于评估LLM在自然语言驱动的无代码开发中添加功能的基准；实验表明LLM在此类任务中表现不佳，成功率仅15.79%，显示其尚未准备好。

**AI_Comments:** 本文通过引入一个大规模、真实世界的基准NoCode-bench，对LLM在自然语言驱动的无代码开发中的能力进行了首次系统评估。其创新之处在于构建了结合文档更新和代码实现的验证任务集，并提供了高质量的人工验证子集。研究结果明确指出当前LLM在处理复杂代码修改任务上的局限性，特别是跨文件编辑和深层代码理解，为未来LLM在软件工程领域的进步指明了方向，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 自然语言驱动的无代码开发有望提高生产力并实现开发民主化。大语言模型（LLMs）在此范式中显示出潜力，但需要一个基准来评估它们在实际任务中的表现。

**Method:** 本文引入了NoCode-bench，这是一个旨在评估LLM在真实世界中自然语言驱动功能添加任务上的基准。它包含来自10个项目的634个任务和11.4万次代码更改。每个任务都将文档更新与相应的代码实现配对，并通过开发者编写的测试用例进行验证。一个包含114个高质量、人工验证实例的子集，NoCode-bench Verified，确保了评估的可靠性。

**Result:** 实验显示，尽管使用了大量token，但最佳LLM的任务成功率仅为15.79%。这突出了跨文件编辑、代码库理解和工具调用方面的挑战。

**Conclusion:** LLM尚未准备好进行完全由自然语言驱动的无代码开发。NoCode-bench为该领域的未来发展奠定了基础。

> **ai_Abstract:** 本文介绍了NoCode-bench，一个用于评估大型语言模型（LLMs）在自然语言驱动的无代码开发中添加新功能的基准。该基准包含634个真实世界的任务，每个任务将文档更新与相应的代码实现配对，并由开发者编写的测试用例验证。通过对LLMs的实验，发现即使是表现最好的模型也仅能达到15.79%的任务成功率，揭示了LLMs在跨文件编辑、代码库理解和工具调用等方面的不足，表明它们尚未成熟到可以完全支持自然语言驱动的无代码开发。NoCode-bench为未来的研究奠定了基础。

> **摘要翻译:** 自然语言驱动的无代码开发允许用户使用自然语言（NL）而不是编辑源代码来指定软件功能，这有望提高生产力并实现开发的民主化。大型语言模型（LLMs）在此范式中显示出潜力。在这种背景下，软件文档充当了功能性的自然语言规范。这项工作引入了NoCode-bench，这是一个旨在评估LLM在真实世界中自然语言驱动功能添加任务上的基准，它包含来自10个项目的634个任务和11.4万次代码更改。每个任务都将文档更新与相应的代码实现配对，并通过开发者编写的测试用例进行验证。一个包含114个高质量、人工验证实例的子集，NoCode-bench Verified，确保了评估的可靠性。我们的实验表明，尽管使用了大量token，但最佳LLM的任务成功率仅为15.79%，这突出了跨文件编辑、代码库理解和工具调用方面的挑战。这些发现表明LLM尚未准备好进行完全由自然语言驱动的无代码开发。NoCode-bench为该领域的未来发展奠定了基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [789] [An OpenSource CI/CD Pipeline for Variant-Rich Software-Defined Vehicles](https://arxiv.org/abs/2507.19446)
> *用于变体丰富的软件定义汽车的开源CI/CD管道*

*Matthias Weiß, Anish Navalgund, Johannes Stümpfle, Falk Dettinger, Michael Weyrich* | **Category: cs.SE, cs.DC, B.8.2; C.2.4** | **Updated: 2025-07-25**

**Keywords:** 软件定义汽车, CI/CD, OTA更新, 变体管理, 开源管道

**Comment:** 7 pages, 5 figures

> **TL;DR:** 本文提出了一个开源CI/CD管道，专门用于管理软件定义汽车（SDVs）中不断增长的软件版本和变体，通过自动化构建、测试和部署以及定制的OTA中间件，实现可靠的OTA更新和功能部署。

**AI_Comments:** 该论文的创新点在于提出了一个专门针对软件定义汽车（SDVs）的开源CI/CD管道，有效解决了SDV领域日益增长的软件版本和变体管理挑战。其重要性体现在提供了一个标准化、可移植和可扩展的解决方案，促进了SDV软件的可靠部署和OTA更新，特别是在处理异构系统和AI模型部署方面。不足之处可能在于抽象中未详细说明其开源工具的具体名称或技术栈，以及在实际大规模应用中的性能和安全性考量。

<details>
  <summary>Details</summary>

**Motivation:** 软件定义汽车（SDVs）的功能通过OTA机制持续更新，导致软件版本和变体数量不断增加，且缺乏统一的集成环境，使得互联移动解决方案的开发复杂化。为了确保异构系统间的可靠运行，需要动态编排功能并考虑硬件和软件的可变性。

**Method:** 本文提出了一个针对SDVs的开源CI/CD管道。它结合使用容器化的开源工具，自动化了构建、测试和部署阶段，创建了一个标准化、可移植和可扩展的生态系统。此外，一个定制的OTA中间件用于分发软件更新并支持车辆和后端服务的版本回滚。更新变体根据部署目标依赖和硬件配置导出。该管道还支持自动驾驶AI模型的持续开发和部署。

**Result:** 该管道在自动化代客泊车（AVP）场景中进行了评估，涉及TurtleBots和协调后端服务器。开发并部署了两个对象检测变体以匹配特定硬件要求。结果表明，实现了无缝的OTA更新、正确的变体选择以及所有目标间的成功编排。

**Conclusion:** 所提出的CI/CD管道为管理SDVs中的软件变体和OTA更新提供了一个可扩展且高效的解决方案，有助于推动未来移动技术的发展。

> **ai_Abstract:** 本文提出了一种针对软件定义汽车（SDVs）的开源CI/CD管道，旨在解决软件版本和变体管理复杂性以及统一集成环境的缺失问题。该管道通过自动化构建、测试和部署流程，并结合定制的OTA中间件，实现了软件更新的分发和回滚。它支持根据硬件配置和部署目标派生更新变体，并能持续开发和部署自动驾驶AI模型。通过自动化代客泊车场景的评估，结果证明了该管道在实现无缝OTA更新、正确变体选择和跨目标编排方面的有效性，为SDVs的软件变体管理和OTA更新提供了一个可扩展、高效的解决方案。

> **摘要翻译:** 软件定义汽车（SDVs）提供了广泛的互联功能，包括增强的驾驶行为和车队管理。这些功能通过OTA（空中下载）机制持续更新，由于车辆、云/边缘环境和相关利益方的多样性，导致软件版本和变体数量不断增加。缺乏统一的集成环境进一步使开发复杂化，因为互联移动解决方案通常是独立构建的。为了确保跨异构系统的可靠操作，考虑硬件和软件可变性的功能动态编排至关重要。本文提出了一个专为SDVs定制的开源CI/CD管道。它结合使用容器化的开源工具，自动化了构建、测试和部署阶段，创建了一个标准化、可移植和可扩展的生态系统，所有利益方均可访问。此外，一个定制的OTA中间件用于分发软件更新并支持车辆和后端服务的版本回滚。更新变体是根据部署目标依赖和硬件配置导出的。该管道还支持自动驾驶AI模型的持续开发和部署。其有效性通过一个涉及TurtleBots和协调后端服务器的自动化代客泊车（AVP）场景进行评估。开发并部署了两个对象检测变体以匹配特定硬件要求。结果表明，实现了无缝的OTA更新、正确的变体选择以及所有目标间的成功编排。总的来说，所提出的管道为管理SDVs中的软件变体和OTA更新提供了一个可扩展且高效的解决方案，有助于推动未来移动技术的发展。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [809] [SMECS: A Software Metadata Extraction and Curation Software](https://arxiv.org/abs/2507.18159)
> *SMECS：一个软件元数据提取和整理软件*

*Stephan Ferenz, Aida Jafarbigloo, Oliver Werth, Astrid Nieße* | **Category: cs.SE, cs.DL** | **Updated: 2025-07-24**

**Keywords:** 软件元数据, FAIR原则, 元数据提取, 元数据整理, SMECS

**Comment:** 

> **TL;DR:** SMECS是一个帮助研究人员从在线存储库（如GitHub）提取并整理软件元数据，以简化FAIR原则的采纳和提高元数据质量的工具。

**AI_Comments:** 该论文提出了一种实用的解决方案，通过自动化和提供用户界面来简化研究软件元数据的创建，这对于推动FAIR原则在软件领域的应用具有重要意义。其创新之处在于整合了元数据提取和用户友好的整理功能，直接解决了研究人员的痛点。

<details>
  <summary>Details</summary>

**Motivation:** 为研究软件创建高质量元数据对于遵循FAIR原则至关重要，但这一过程对研究人员来说耗时耗力。

**Method:** SMECS从GitHub等在线存储库中提取元数据，并通过一个用户友好的交互式界面呈现给研究人员进行进一步整理，并可导出为CodeMeta文件。

**Result:** 通过可用性实验评估，SMECS提供了令人满意的用户体验。

**Conclusion:** SMECS通过简化元数据创建过程，支持研究软件的FAIR化。

> **ai_Abstract:** SMECS（软件元数据提取和整理软件）旨在解决研究软件元数据创建的资源密集型问题。它能从GitHub等在线存储库提取元数据，并通过交互式界面供用户整理并导出为CodeMeta文件。可用性实验证实SMECS提供了良好的用户体验，有效简化了元数据创建，从而促进了研究软件的FAIR化。

> **摘要翻译:** 元数据在研究软件采纳FAIR原则中起着关键作用，并能实现可查找性和可重用性。然而，创建高质量的元数据对研究人员和研究软件工程师来说可能需要耗费大量资源。为了解决这一挑战，我们开发了软件元数据提取和整理软件（SMECS），它集成了从现有来源提取元数据的功能，并提供了一个用户友好的元数据整理界面。SMECS从GitHub等在线存储库中提取元数据，并通过一个交互式界面呈现给研究人员，以便进行进一步的整理并导出为CodeMeta文件。SMECS的可用性通过可用性实验进行了评估，实验证实SMECS提供了令人满意的用户体验。SMECS通过简化元数据创建过程，支持研究软件的FAIR化。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [853] [GenAI for Automotive Software Development: From Requirements to Wheels](https://arxiv.org/abs/2507.18223)
> *汽车软件开发中的生成式AI：从需求到车轮*

*Nenad Petrovic, Fengjunjie Pan, Vahid Zolfaghari, Krzysztof Lebioda, Andre Schamschurko, Alois Knoll* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 生成式AI, 汽车软件开发, 自动驾驶, ADAS, 大语言模型

**Comment:** 

> **TL;DR:** 本文提出一种由生成式AI驱动的汽车软件（尤其是自动驾驶和ADAS）自动化开发方法，涵盖从需求分析到测试场景和代码生成，旨在缩短开发周期。

**AI_Comments:** 这篇论文的创新点在于将生成式AI技术全面应用于汽车软件的自动化开发流程，涵盖从需求分析、模型构建、代码生成到测试场景创建。特别是结合了LLMs、MDE和RAG，形成了一个端到端的集成工作流，有望大幅提升开发效率并降低成本。其重要性在于为复杂且安全关键的汽车软件开发提供了新的范式，尤其是在快速迭代的自动驾驶领域。

<details>
  <summary>Details</summary>

**Motivation:** 旨在自动化汽车软件（特别是自动驾驶和高级驾驶辅助系统ADAS）的开发过程，缩短合规和再工程周期，并减少开发和测试时间。

**Method:** 本文提出一种由生成式AI赋能的汽车软件自动化开发方法。该过程从需求作为输入开始，主要生成的输出是用于仿真环境的测试场景代码以及针对连接到测试台的车辆硬件平台的ADAS功能实现。引入了利用模型驱动工程（MDE）进行需求一致性检查的额外步骤。在大语言模型（LLMs）用于需求的模型化总结（Ecore元模型、XMI模型实例和OCL约束创建）、测试场景生成、仿真代码（Python）和目标平台代码（C++）生成。此外，采用检索增强生成（RAG）从自动驾驶法规相关文档中增强测试场景生成。

**Result:** 该方法旨在缩短合规和再工程周期，以及减少ADAS相关功能的开发和测试时间。

**Conclusion:** 本文提出了一种生成式AI驱动的汽车软件自动化开发方法，特别是针对自动驾驶和ADAS功能，通过整合LLMs和RAG技术，实现了从需求到代码和测试的端到端流程，显著提高了开发效率并缩短了周期。

> **ai_Abstract:** 本文提出了一种利用生成式AI（GenAI）自动化开发汽车软件的方法，尤其针对自动驾驶和高级驾驶辅助系统（ADAS）。该方法从需求开始，通过大语言模型（LLMs）进行需求总结、测试场景生成、仿真（Python）和目标平台（C++）代码生成。同时，结合模型驱动工程（MDE）进行需求一致性检查，并采用检索增强生成（RAG）从法规文档中优化测试场景。该方法旨在显著缩短开发、测试以及合规和再工程周期。

> **摘要翻译:** 本文介绍了一种由生成式AI赋能的汽车软件自动化开发方法，重点关注自动驾驶和高级驾驶辅助系统（ADAS）功能。该过程从需求作为输入开始，主要生成的输出是用于仿真环境的测试场景代码，以及针对连接到测试台的车辆硬件平台的所需ADAS功能的实现。此外，我们引入了利用模型驱动工程（MDE）进行需求一致性检查的额外步骤。在所提出的工作流程中，大语言模型（LLM）用于需求的基于模型的总结（Ecore元模型、XMI模型实例和OCL约束创建）、测试场景生成、仿真代码（Python）和目标平台代码（C++）生成。此外，还采用检索增强生成（RAG）来增强从自动驾驶法规相关文档中生成测试场景。我们的方法旨在缩短合规和再工程周期，以及减少ADAS相关功能的开发和测试时间。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [221] [Mapping Technological Futures: Anticipatory Discourse Through Text Mining](https://arxiv.org/abs/2504.02853)
> *绘制技术未来图景：通过文本挖掘进行预期性话语分析*

*Maciej Skorski, Alina Landowska, Krzysztof Rajda* | **Category: cs.SI, cs.CL, cs.CY, cs.LG, K.4; H.3.3** | **Updated: 2025-03-25**

**Keywords:** 技术未来, 预期性话语, 文本挖掘, 关键意见领袖, 社交媒体

**Comment:** Accepted to Humanities and Social Sciences Communications. arXiv
  admin note: text overlap with arXiv:2407.17522

> **TL;DR:** 本研究通过文本挖掘分析了X平台上150万条关键意见领袖的帖子，探讨了围绕新兴技术的预期性话语，发现KOLs在塑造技术未来和影响当前社会辩论中的双重作用，并指出希望情绪占据主导。

**AI_Comments:** 本研究通过大规模社交媒体数据分析，创新性地结合了文本挖掘和情绪分析，深入探讨了KOLs在塑造技术未来预期和公共话语中的关键作用。其重要性在于揭示了社会叙事如何通过意见领袖在不确定时期被构建和传播，为理解技术与社会互动提供了新视角。

<details>
  <summary>Details</summary>

**Motivation:** 新兴技术（如人工智能）的波动性和不可预测性产生了巨大的不确定性，并在社交媒体上引发广泛讨论。本研究旨在分析围绕技术未来的预期性话语。

**Method:** 本研究分析了2021年至2023年间X平台（原Twitter）上400位关键意见领袖（KOLs）发布的150万条帖子。研究采用了先进的文本挖掘技术，包括BERTopic主题建模、情感分析、情绪分析和态度分析。

**Result:** 研究识别出100个反映预期技术驱动未来的不同主题。研究结果强调了KOLs在构建“当下未来”（对人工智能和物联网等变革性技术的乐观愿景）和影响“未来当下”（这些预测塑造当代社会和地缘政治辩论）中的双重作用。积极情绪如希望占主导地位，超过了焦虑，特别是在“机器学习、数据科学和深度学习”等主题中，而围绕“气候变化”和“战争、乌克兰和特朗普支持者”的讨论则引发了焦虑。

**Conclusion:** 通过将技术视为社会挑战的解决方案，KOLs充当了社会叙事的调解者，连接了想象中的未来和当前的现实。这些见解强调了他们在高度不确定时期引导公众对新兴技术关注的关键作用，从而增进了我们对技术媒介背景下预期性话语的理解。

> **ai_Abstract:** 本研究利用文本挖掘技术，对X平台上150万条关键意见领袖的帖子进行了分析，旨在理解新兴技术背景下的预期性话语。研究识别出100个技术未来相关主题，揭示了KOLs在塑造乐观技术愿景和影响当前社会辩论中的双重作用。结果表明，希望情绪普遍存在，尤其是在机器学习等领域，而焦虑则集中在气候变化和地缘政治等话题。研究强调KOLs在连接未来想象与现实、引导公众关注新兴技术方面发挥的关键作用。

> **摘要翻译:** 新兴技术（如人工智能）的波动性和不可预测性产生了巨大的不确定性，这在社交媒体上被广泛讨论。本研究通过分析X平台（2021年至2023年）上400位关键意见领袖（KOLs）发布的150万条帖子，探讨了围绕技术未来的预期性话语。研究采用先进的文本挖掘技术，包括BERTopic主题建模、情感、情绪和态度分析，识别出100个反映预期技术驱动未来的不同主题。我们的发现强调了KOLs在构建“当下未来”——对人工智能和物联网等变革性技术的乐观愿景——和影响“未来当下”——这些预测塑造当代社会和地缘政治辩论——中的双重作用。希望等积极情绪占据主导地位，超过了焦虑，特别是在“机器学习、数据科学和深度学习”等主题中，而围绕“气候变化”和“战争、乌克兰和特朗普支持者”的讨论则引发了焦虑。通过将技术视为社会挑战的解决方案，KOLs充当了社会叙事的调解者，连接了想象中的未来和当前的现实。这些见解强调了他们在高度不确定时期引导公众对新兴技术关注的关键作用，从而增进了我们对技术媒介背景下预期性话语的理解。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [334] [Epidemiology-informed Network for Robust Rumor Detection](https://arxiv.org/abs/2411.12949)
> *流行病学启发网络用于鲁棒谣言检测*

*Wei Jiang, Tong Chen, Xinyi Gao, Wentao Zhang, Lizhen Cui, Hongzhi Yin* | **Category: cs.SI, cs.IR** | **Updated: 2025-07-25**

**Keywords:** 谣言检测, 图神经网络, 流行病学, 大型语言模型, 鲁棒性

**Comment:** Accepted by The Web Conference 2025 (WWW2025)

> **TL;DR:** 本文提出了一种流行病学启发网络（EIN），通过整合流行病学知识并利用大型语言模型生成用户立场标签，以克服现有基于图的谣言检测模型对数据质量的敏感性，从而实现更鲁棒的谣言检测。

**AI_Comments:** 该论文的创新点在于将流行病学知识引入谣言检测领域，并巧妙地利用大型语言模型（LLMs）解决了流行病学模型所需的用户立场标注难题，显著降低了数据标注成本。这种跨领域融合和技术结合为谣言检测提供了一个新颖且鲁棒的解决方案，特别是在处理数据稀疏或噪声环境下的谣言检测问题上具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体上谣言的迅速传播对维护公众信任和信息完整性构成了重大挑战。尽管现有的图神经网络模型在谣言检测中表现优于纯文本方案，但它们对传播树深度的变化（即源信息传播能力差异）敏感。浅层传播树难以捕捉足够的级联模式，而深层传播树易受噪声用户响应影响，这限制了现有数据驱动图基谣言检测器的性能和鲁棒性。

**Method:** 本文提出了一种新颖的流行病学启发网络（EIN），该网络整合流行病学知识以增强性能并克服数据驱动方法对数据质量的敏感性。为了使流行病学理论适应谣言检测，并绕过昂贵耗时的人工标注过程，EIN利用大型语言模型（LLMs）生成用户对源信息的立场标签，从而促进学习流行病学启发表示的优化目标。

**Result:** 实验结果表明，所提出的EIN不仅在真实世界数据集上优于最先进的方法，而且在不同传播树深度下表现出增强的鲁棒性。

**Conclusion:** 通过整合流行病学知识并利用大型语言模型生成立场标签，本文提出的流行病学启发网络（EIN）显著提升了谣言检测的性能和鲁棒性，有效克服了现有图基方法对传播树深度和数据质量的敏感性。

> **ai_Abstract:** 本文提出了一种流行病学启发网络（EIN），旨在解决社交媒体谣言检测中现有图神经网络模型对数据质量和传播树深度敏感的问题。EIN通过整合流行病学知识并巧妙利用大型语言模型自动生成用户立场标签，克服了数据驱动方法的局限性。实验证明，EIN在真实数据集上表现优于现有最佳方法，并显著提升了在不同传播深度下的检测鲁棒性。

> **摘要翻译:** 社交媒体上谣言的迅速传播对维护公众信任和信息完整性构成了重大挑战。由于信息级联过程本质上是一种传播树，最近的谣言检测模型利用图神经网络额外捕获信息传播模式，从而优于纯文本解决方案。考虑到根节点主题和社***响的差异，不同的源信息自然具有不同的传播能力，导致传播树的高度不同。然而，这种变化阻碍了现有基于图的谣言检测器的数据驱动设计。对于交互有限的浅层传播树，基于图的方法不太可能捕获足够的级联模式，这使得它们处理不那么流行的新闻或早期检测需求的能力受到质疑。相反，深层传播树容易产生嘈杂的用户响应，这反过来会混淆预测。在本文中，我们提出了一种新颖的流行病学启发网络（EIN），它整合流行病学知识以通过克服数据驱动方法对数据质量的敏感性来增强性能。同时，为了使流行病学理论适应谣言检测，期望对每个用户对源信息的立场进行标注。为了绕过昂贵且耗时的人工标注过程，我们利用大型语言模型生成立场标签，从而促进学习流行病学启发表示的优化目标。我们的实验结果表明，所提出的EIN不仅在真实世界数据集上优于最先进的方法，而且在不同树深度下表现出增强的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [30] [Enhanced Velocity-Adaptive Scheme: Joint Fair Access and Age of Information Optimization in Vehicular Networks](https://arxiv.org/abs/2507.18328)
> *增强型速度自适应方案：车载网络中联合公平接入和信息年龄优化*

*Xiao Xu, Qiong Wu, Pingyi Fan, Kezhi Wang, Nan Cheng, Wen Chen, Khaled B. Letaief* | **Category: cs.NI** | **Updated: 2025-07-24**

**Keywords:** 车载网络, 公平接入, 信息年龄, 5G NR V2I, LLM

**Comment:** This paper has been submitted to IEEE TMC

> **TL;DR:** 本文提出了一种增强型速度自适应方案，通过联合优化公平接入和信息年龄（AoI），以解决5G NR V2I模式2车载网络中车辆速度差异导致的资源不公平访问和数据新鲜度问题。该方案利用随机混合系统建模AoI，并通过调整半持久调度（SPS）的选择窗口，使用基于大型语言模型（LLM）的多目标演化算法进行求解。

**AI_Comments:** 该论文的创新点在于首次将大型语言模型（LLM）应用于多目标演化算法（MOEA/D）来解决车载网络中的公平接入和信息年龄（AoI）联合优化问题。这种跨领域的方法可能为未来无线资源管理带来新的思路。同时，对车辆速度差异导致的不公平性和AoI问题的关注，以及在5G NR V2I模式2下的具体实现，使其具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在5G NR V2I模式2车载网络中，车辆速度差异导致驻留时间和通信时长不同，造成网络资源的不公平访问，可能影响驾驶安全。同时，需要确保接收数据的及时性和新鲜度（信息年龄，AoI）。模式2引入的抢占机制使得公平接入和AoI的同步优化成为必要。

**Method:** 本文提出了一个车载网络联合优化框架，定义了公平性指标，并采用随机混合系统（SHS）建模抢占机制下的信息年龄（AoI）。通过自适应调整模式2中半持久调度（SPS）的选择窗口来优化公平性和AoI。该问题使用基于大型语言模型（LLM）的多目标演化算法（MOEA/D）求解。

**Result:** 仿真结果表明，该方案在平衡公平接入和最小化信息年龄（AoI）方面是有效的。

**Conclusion:** 该研究成功地提出并验证了一种增强型速度自适应方案，能够有效解决车载网络中公平接入和信息年龄的联合优化问题，从而提升数据交付的及时性和相关性。

> **ai_Abstract:** 本文针对5G NR V2I模式2车载网络中因车辆速度差异导致的不公平资源访问和数据新鲜度（AoI）问题，提出了一种增强型速度自适应方案。该方案构建了一个联合优化框架，利用随机混合系统（SHS）建模抢占机制下的AoI，并通过自适应调整半持久调度（SPS）的选择窗口来同时优化公平性和AoI。研究采用基于大型语言模型（LLM）的多目标演化算法（MOEA/D）进行求解，仿真结果验证了该方案在平衡公平接入和最小化AoI方面的有效性。

> **摘要翻译:** 本文考虑了5G新空口（NR）车-基础设施（V2I）模式2车载网络中的公平接入问题和信息年龄（AoI）问题。具体而言，车辆遵循模式2与路边单元（RSU）通信，以获取用于驾驶辅助的准确数据。然而，车辆在相邻车道行驶时通常具有不同的速度，导致RSU驻留时间和通信持续时间不同。这导致网络资源的不公平访问，可能影响驾驶安全。为确保接收数据的新鲜度，应分析信息年龄（AoI）。模式2引入了一种新颖的抢占机制，需要同时优化公平接入和AoI，以保证及时和相关的数据交付。我们提出了一个车载网络联合优化框架，定义了公平性指标，并采用随机混合系统（SHS）建模抢占机制下的AoI。通过自适应调整模式2中半持久调度（SPS）的选择窗口，我们解决了公平性和AoI的优化问题。我们应用基于大型语言模型（LLM）的多目标演化算法（MOEA/D）来解决这个问题。仿真结果表明，我们的方案在平衡公平接入和最小化AoI方面是有效的。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [86] [Improving Wi-Fi 8 Latency with Coordinated Spatial Reuse](https://arxiv.org/abs/2507.18480)
> *采用协调空间复用技术改善Wi-Fi 8延迟*

*David Nunez, Francesc Wilhelmi, Lorenzo Galati-Giordano, Giovanni Geraci, Boris Bellalta* | **Category: cs.NI** | **Updated: 2025-07-24**

**Keywords:** Wi-Fi 8, 协调空间复用, 延迟, 频谱效率, WLAN

**Comment:** Submitted to IEEE Communications Standards Magazine

> **TL;DR:** 研究提出并评估了Wi-Fi 8网络中协调空间复用（Co-SR）的实现，以降低延迟并提高频谱效率，模拟结果显示延迟显著降低。

**AI_Comments:** 该研究通过提出并评估Co-SR在Wi-Fi 8网络中的应用，为解决新兴应用对低延迟和高吞吐量的需求提供了潜在的解决方案。其创新点在于Co-SR与Wi-Fi 8标准化工作的对齐，并利用模拟器验证了其在实际场景中的性能提升。结果显示显著的延迟降低，这对于未来Wi-Fi网络的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 满足云游戏、扩展现实（XR）和视频流服务等新兴应用对高吞吐量、低延迟和高可靠性的严格要求，并通过协调空间复用（Co-SR）优化频谱资源利用。

**Method:** 提出了一种与Wi-Fi 8标准化工作一致的Co-SR实现方案，并在Wi-Fi模拟器上进行了评估，场景为一个包含四个AP的无线局域网（WLAN）。

**Result:** 在包含四个AP的WLAN中，与分布式协调功能（DCF）相比，Co-SR使延迟降低了31%到95%。

**Conclusion:** Co-SR是一种有效改善Wi-Fi 8网络延迟和频谱效率的机制，有助于满足新兴应用的需求。

> **ai_Abstract:** 本文探讨了协调空间复用（Co-SR）在Wi-Fi 8网络中改善延迟的潜力。为满足云游戏、XR和视频流等新兴应用对低延迟的需求，研究提出了一种符合Wi-Fi 8标准化工作的Co-SR实现方案。通过Wi-Fi模拟器在包含四个AP的WLAN中进行评估，结果表明Co-SR能够将延迟显著降低31%至95%，从而有效提升网络性能和频谱效率。

> **摘要翻译:** IEEE 802.11网络不断适应，以满足云游戏、扩展现实（XR）和视频流服务等新兴应用的严格要求，这些应用需要高吞吐量、低延迟和高可靠性。为了应对这些挑战，协调空间复用（Co-SR）有望为优化频谱资源利用做出贡献。这种机制有望实现同步传输，从而提高密集环境中的频谱效率，并提升整体网络性能。在本文中，我们阐明了Co-SR在Wi-Fi 8网络中的性能。为此，我们提出了一种与正在进行的Wi-Fi 8标准化工作相符的Co-SR实现方案。评估在一个Wi-Fi模拟器上进行，这使我们能够研究所提出的Co-SR机制在相关场景中的性能。在一个由四个AP组成的无线局域网（WLAN）中获得的结果显示，与分布式协调功能（DCF）相比，Co-SR的延迟降低了31%到95%。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [198] [IEEE 802.11be Wi-Fi 7: Feature Summary and Performance Evaluation](https://arxiv.org/abs/2309.15951)
> *IEEE 802.11be Wi-Fi 7：特性总结与性能评估*

*Xiaoqian Liu, Yuhan Dong, Yiqing Li, Yousi Lin, Ming Gan* | **Category: cs.NI, eess.SP** | **Updated: 2025-07-24**

**Keywords:** Wi-Fi 7, IEEE 802.11be, 极高吞吐量, 性能评估, 低延迟

**Comment:** 

> **TL;DR:** Wi-Fi 7 (IEEE 802.11be) 旨在提供更高的吞吐量和更低的延迟，以满足4K/8K视频、VR/AR等新兴应用的需求，并通过系统级仿真验证可达30 Gbps吞吐量并降低延迟。

**AI_Comments:** 该论文及时介绍了Wi-Fi 7这一新兴标准，并着重分析了其关键特性和性能提升，特别是通过系统级仿真验证了其高吞吐量和低延迟的潜力，对于理解Wi-Fi技术的演进具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 满足4K/8K视频和VR/AR等新兴应用对更高吞吐量（数十Gbps）和低延迟的需求。

**Method:** 介绍了Wi-Fi 7的主要目标和时间线，列出了提升性能的关键技术，并通过系统级仿真验证了30 Gbps吞吐量和更低延迟的关键目标。

**Result:** 系统级仿真结果表明，通过结合新技术后，Wi-Fi 7实现了30 Gbps的吞吐量，并且延迟低于Wi-Fi 6。

**Conclusion:** Wi-Fi 7通过引入新技术，显著提升了吞吐量和降低了延迟，能够满足未来高带宽、低延迟应用的需求。

> **ai_Abstract:** 本文概述了IEEE 802.11be (Wi-Fi 7) 标准，旨在应对4K/8K视频和VR/AR等新兴应用对高吞吐量和低延迟的需求。文章介绍了Wi-Fi 7的主要目标、时间线及其关键技术，并通过系统级仿真验证了其实现高达30 Gbps吞吐量和更低延迟的能力，相较于Wi-Fi 6有显著提升。

> **摘要翻译:** 随着新兴应用对吞吐量需求的不断提高，IEEE 802.11be——极高吞吐量（EHT）标准，也被称为Wi-Fi 7，于2025年7月22日发布。它可用于满足高达数十Gbps的4K/8K视频吞吐量需求以及虚拟现实（VR）和增强现实（AR）等低延迟视频应用的需求。Wi-Fi 7不仅将Wi-Fi 6的带宽翻倍，还支持实时应用，这给Wi-Fi带来了革命性的变化。本文首先介绍了Wi-Fi 7的主要目标和时间线，然后列出了促进Wi-Fi 7性能提升的最新关键技术。最后，我们验证了Wi-Fi 7最关键的目标——潜在的最高30 Gbps吞吐量和更低的延迟。系统级仿真结果表明，通过结合新技术，Wi-Fi 7实现了30 Gbps的吞吐量，并且延迟低于Wi-Fi 6。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [253] [UAV Communications: Impact of Obstacles on Channel Characteristics](https://arxiv.org/abs/2412.17934)
> *无人机通信：障碍物对信道特性的影响*

*Kamal Shayegan* | **Category: cs.NI, eess.SP** | **Updated: 2025-07-24**

**Keywords:** 无人机, 障碍物, 信道特性, 定位, 空对地通信

**Comment:** 

> **TL;DR:** 无人机作为无线AP/基站时，高频信号易受障碍物影响。本文提出一种考虑障碍物的仿真测量方法，以优化无人机定位和提高服务质量。

**AI_Comments:** 本文的创新之处在于明确地将障碍物整合到无人机定位和信道特性分析中，这对于未来高频无人机通信至关重要。其重要性在于解决了无人机网络可靠性面临的实际挑战。局限性在于研究是基于“简单场景”的仿真。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，无人机被广泛用作无线AP和基站，但下一代无线通信将依赖更高频率，易受障碍物阻碍。因此，在考虑障碍物的情况下优化无人机定位以确保视距、提高服务质量和建立可靠连接至关重要。

**Method:** 本文提出了一种基于仿真的测量方法，用于在简单场景中表征空对地(AG)信道，并通过考虑障碍物，提出了信道表征的新视角。

**Result:** 结果对比了使用所提出的定位方法在吞吐量、数据包传输、数据包丢失和延迟方面的表现。

**Conclusion:** 考虑障碍物并将其整合到无人机定位算法中，能够有效改善空对地信道特性，从而提高通信吞吐量、数据包传输率并降低数据包丢失和延迟。

> **ai_Abstract:** 本文探讨了无人机（UAV）在作为无线接入点和基站时，高频通信易受障碍物影响的问题。为确保视距、提升服务质量并最大化覆盖范围，论文提出了一种将障碍物纳入无人机最佳定位算法的仿真测量方法，用于表征空对地信道，并比较了其在吞吐量、数据包传输、数据包丢失和延迟方面的性能。

> **摘要翻译:** 近年来，无人机（UAV）已被用作携带Wi-Fi接入点（AP）和蜂窝基站（BS）的有效平台，从而实现低成本、敏捷、灵活且具有高质量服务（QoS）的无线网络。下一代无线通信将依赖于越来越高的频率，这些频率很容易受到障碍物的阻碍。一个尚未完全解决的关键概念是在考虑障碍物的情况下将无人机定位在最佳坐标处。为了确保无人机和用户设备（UE）之间的视距（LoS），提高QoS，并建立具有最大覆盖范围的可靠无线链路，障碍物必须整合到所提出的部署算法中。本文介绍了一种基于仿真的测量方法，用于在简单场景中表征空对地（AG）信道。通过考虑障碍物，我们提出了信道表征的新视角。结果在吞吐量、数据包传输、数据包丢失和延迟方面，使用所提出的定位方法进行了比较。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [418] [ARCADE: A RAN Diagnosis Methodology in a Hybrid AI Environment for 6G Networks](https://arxiv.org/abs/2507.17861)
> *ARCADE：一种用于6G网络混合AI环境的RAN诊断方法*

*Daniel Ricardo Cunha Oliveira, Rodrigo Moreira, Flávio de Oliveira Silva* | **Category: cs.NI, cs.ET** | **Updated: 2025-07-23**

**Keywords:** 6G网络, RAN诊断, 混合AI, 异常检测, ARCADE

**Comment:** 

> **TL;DR:** ARCADE是一种用于6G网络中蜂窝接入网络异常检测和诊断的方法，它展示了混合AI架构如何增强AI在更广泛网络中的应用。

**AI_Comments:** ARCADE在6G网络背景下，通过提出一种混合AI环境下的RAN诊断方法，展示了其创新性。它解决了当前5G规范中NWDAF功能不足以覆盖所有网络段自动化的局限性，特别是在蜂窝接入网络异常检测方面。该方法的提出对于未来6G网络的自动化管理和AI的广泛应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了在6G网络中实现尚未在5G背景下充分探索的网络段的自动化，需要一种更全面的方法来利用AI，特别是在网络数据分析功能（NWDAF）之外的领域。

**Method:** 本文提出了ARCADE（自动化无线覆盖异常检测和评估），这是一种用于识别和诊断蜂窝接入网络中异常的方法。此外，它还展示了在向6G演进过程中，网络分析功能的混合架构如何增强AI在更广泛网络上下文中的应用，并以ARCADE作为这种方法的实际示例。

**Result:** 通过ARCADE，论文展示了在向6G演进过程中，网络分析功能的混合架构可以增强AI在更广泛网络上下文中的应用。

**Conclusion:** ARCADE作为一种实际方法，证明了在6G网络中采用混合AI架构可以有效提升无线接入网络（RAN）的异常诊断能力和AI的应用范围。

> **ai_Abstract:** 本文提出了ARCADE，一种在6G网络中用于识别和诊断蜂窝接入网络异常的方法。该研究旨在解决5G网络中未充分探索的网络段自动化问题，并利用AI在6G网络中的关键作用。论文通过ARCADE展示了网络分析功能的混合架构如何有效增强AI在更广泛网络环境中的应用。

> **摘要翻译:** 人工智能（AI）在6G网络的发展中扮演着关键角色。尽管当前的规范已经将网络数据分析功能（NWDAF）作为负责提供核心网络信息的网络元素，但为了实现尚未在5G背景下充分探索的网络段的自动化，将需要一种更全面的方法。在本文中，我们提出了ARCADE（自动化无线覆盖异常检测和评估），这是一种用于识别和诊断蜂窝接入网络中异常的方法。此外，我们还展示了在向6G演进过程中，网络分析功能的混合架构如何增强AI在更广泛网络上下文中的应用，并以ARCADE作为这种方法的实际示例。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [772] [Frame-Based Zero-Shot Semantic Channel Equalization for AI-Native Communications](https://arxiv.org/abs/2507.17835)
> *面向AI原生通信的基于帧的零样本语义信道均衡*

*Simone Fiorellino, Claudio Battiloro, Emilio Calvanese Strinati, Paolo Di Lorenzo* | **Category: cs.NI** | **Updated: 2025-07-23**

**Keywords:** AI原生通信, 语义信道均衡, 零样本学习, Parseval帧, 深度神经网络

**Comment:** 

> **TL;DR:** 本文提出了Parseval帧均衡器（PFE），一种零样本、基于帧的语义信道均衡器，用于对齐异构深度神经网络编码器的潜在空间，以解决AI原生通信中的语义信道噪声问题，并通过仿真验证了其有效性。

**AI_Comments:** 本文提出的PFE方法创新性地解决了AI原生通信中异构DNN编码器潜在空间失配引起的语义噪声问题，其零样本和无需再训练的特性具有重要意义。此外，结合资源动态优化策略，使得该方案在实际应用中更具鲁棒性和实用性，有望提升未来AI原生通信系统的效率和性能。

<details>
  <summary>Details</summary>

**Motivation:** 在未来的AI原生无线网络中，独立设计和训练的深度神经网络（DNN）编码器之间潜在空间的失配可能导致语义信道噪声的出现，从而阻碍相互理解并降低接收器解释传输表示的能力，最终影响整体系统性能。

**Method:** 本文提出了Parseval帧均衡器（PFE），这是一种零样本、基于帧的语义信道均衡器，它无需系统再训练即可对齐异构编码器的潜在空间。PFE能够动态进行信号压缩和扩展，从而减轻语义噪声，同时保持下游任务的性能。在此基础上，本文引入了一种动态优化策略，协调通信、计算和学习资源，以平衡多智能体语义通信场景中的能耗、端到端（E2E）延迟和任务性能。

**Result:** 广泛的仿真证实了该方法在多样化和时变网络条件下保持语义一致性并满足延迟和精度长期约束的有效性。

**Conclusion:** 本文提出的Parseval帧均衡器（PFE）及其动态优化策略能够有效解决AI原生通信中的语义信道噪声问题，通过对齐潜在空间、动态资源协调，在保证语义一致性的同时，平衡能耗、延迟和任务性能，从而显著提升未来AI原生通信系统的表现。

> **ai_Abstract:** 本文针对AI原生通信中因深度神经网络编码器潜在空间失配导致的语义信道噪声问题，提出了一种零样本、基于帧的Parseval帧均衡器（PFE）。PFE无需再训练即可对齐异构编码器，并通过动态信号压缩与扩展有效抑制语义噪声，同时保持任务性能。此外，论文还引入了一种动态优化策略，以在多智能体语义通信中平衡能耗、延迟和任务性能。仿真结果验证了该方法在复杂网络条件下保持语义一致性并满足长期约束的有效性。

> **摘要翻译:** 在未来的AI原生无线网络中，独立设计和训练的深度神经网络（DNN）编码器之间潜在空间的失配可能导致语义信道噪声的出现，从而阻碍相互理解。这损害了接收器解释传输表示的能力，从而降低了整体系统性能。为了解决这个问题，我们提出了Parseval帧均衡器（PFE），这是一种零样本、基于帧的语义信道均衡器，它无需系统再训练即可对齐异构编码器的潜在空间。PFE能够动态进行信号压缩和扩展，从而减轻语义噪声，同时保持下游任务的性能。在此基础上，我们引入了一种动态优化策略，协调通信、计算和学习资源，以平衡多智能体语义通信场景中的能耗、端到端（E2E）延迟和任务性能。广泛的仿真证实了我们方法在多样化和时变网络条件下保持语义一致性并满足延迟和精度长期约束的有效性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [815] [Talk with the Things: Integrating LLMs into IoT Networks](https://arxiv.org/abs/2507.17865)
> *与物对话：将大型语言模型集成到物联网网络中*

*Alakesh Kalita* | **Category: cs.NI** | **Updated: 2025-07-23**

**Keywords:** 大型语言模型, 物联网, 边缘计算, 检索增强生成, 智能家居

**Comment:** arXiv admin note: text overlap with arXiv:2407.20970

> **TL;DR:** 该研究提出了一个以边缘为中心的框架，将大型语言模型（LLM）集成到物联网（IoT）网络中，以实现自然语言控制、上下文感知决策和增强自动化，并在智能家居原型中进行了验证。

**AI_Comments:** 该论文通过将大型语言模型直接部署到边缘物联网设备上，提出了一种创新方法，这对于实现实时交互、保护隐私和减少对云基础设施的依赖至关重要。利用基于RAG的LLM进一步增强了其在资源受限的边缘环境中的适用性。通过智能家居原型的验证展示了其在实际中的可行性，而对权衡和挑战的讨论则为该新兴领域的未来研究和发展提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）与物联网（IoT）网络的融合为构建智能、响应迅速且用户友好的系统开辟了新机遇。本研究旨在通过集成LLM，实现物联网系统中基于自然语言的控制、上下文感知决策和增强自动化。

**Method:** 本研究提出了一个以边缘为中心的框架，将模块化、轻量级的基于检索增强生成（RAG）的LLM部署到连接物联网网关的边缘计算设备上。该框架通过本地处理用户命令和传感器数据，实现低延迟、高隐私和增强推理质量。研究通过使用LLaMA 3和Gemma 2B模型控制智能设备的智能家居原型验证了该框架。

**Result:** 实验结果突出了模型大小对模型精度和推理时间之间权衡的影响。

**Conclusion:** 该论文讨论了基于LLM的物联网系统的潜在应用以及与此类系统相关的一些关键挑战。

> **ai_Abstract:** 本文提出了一个以边缘为中心的框架，旨在将轻量级、基于检索增强生成（RAG）的大型语言模型（LLM）集成到物联网（IoT）网络中。该框架部署在边缘设备上，通过本地处理用户命令和传感器数据，实现自然语言控制和上下文感知决策，从而降低延迟、提高隐私并增强推理能力。研究通过一个智能家居原型验证了该框架，并探讨了模型大小对精度和推理时间之间权衡的影响，最后讨论了基于LLM的物联网系统的潜在应用和面临的挑战。

> **摘要翻译:** 大型语言模型（LLM）与物联网（IoT）网络的融合为构建智能、响应迅速且用户友好的系统开辟了新机遇。这项工作提出了一个以边缘为中心的框架，将LLM集成到物联网架构中，以实现基于自然语言的控制、上下文感知决策和增强自动化。所提出的模块化轻量级基于检索增强生成（RAG）的LLM部署在连接到物联网网关的边缘计算设备上，从而实现用户命令和传感器数据的本地处理，以减少延迟、提高隐私性并增强推理质量。我们通过一个使用LLaMA 3和Gemma 2B模型控制智能设备的智能家居原型验证了该框架。实验结果突出了模型精度和推理时间之间与模型大小相关的权衡。最后，我们还讨论了可以使用基于LLM的物联网系统的潜在应用，以及与此类系统相关的一些关键挑战。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [861] [Enabling Scalability in Asynchronous and Bidirectional Communication in LPWAN](https://arxiv.org/abs/2507.17905)
> *在LPWAN中实现异步和双向通信的可扩展性*

*Mahbubur Rahman* | **Category: cs.NI, cs.DC** | **Updated: 2025-07-23**

**Keywords:** LPWAN, 可扩展性, 异步通信, 双向通信, SNOW, D-OFDM, Gold码, PN序列

**Comment:** 12 pages

> **TL;DR:** 本文通过改进SNOW技术，利用基于Gold码的PN序列，实现了LPWAN中异步和双向通信的大规模可扩展性，提高了9倍的扩展性。

**AI_Comments:** 本文通过对现有LPWAN技术SNOW进行创新性改进，引入了基于Gold码的PN序列来实现大规模并发通信，有效解决了LPWAN在异步和双向通信中的可扩展性瓶颈。其在同一子载波上实现多用户并发通信的能力是关键创新点。该研究对于推动物联网和CPS等需要大量传感器和实时数据传输的应用具有重要意义，有望延长设备电池寿命并支持时间敏感型决策。

<details>
  <summary>Details</summary>

**Motivation:** LPWAN在连接广域传感器方面普遍存在，但新兴的物联网和CPS应用需要LPWAN能够实现大规模可扩展性，即众多传感器能高效、低延迟地传输数据，而这目前非常具有挑战性。

**Method:** 本文通过显著改进LPWAN技术SNOW来解决挑战。SNOW利用分布式正交频分复用（D-OFDM）子载波，使基站能够并行接收来自多个异步传感器的数据。在此基础上，本文进一步实现了SNOW的大规模可扩展性，通过允许基站解码同一子载波上大量异步传感器的并发数据，同时并行解码其他子载波。此外，还允许大量异步传感器在同一子载波上接收来自基站的不同数据，同时其他传感器也在其他子载波上并行接收数据。为此，开发了一组基于Gold码的伪随机噪声（PN）序列，这些序列在子载波内部和之间互不干扰。每个传感器使用其PN序列进行数据编码或解码，从而实现大规模并发。

**Result:** 评估结果表明，SNOW的可扩展性提高了大约9倍，同时基站的数据收集及时，传感器能效高。

**Conclusion:** 通过改进SNOW技术，利用互不干扰的Gold码PN序列，可以大幅提升LPWAN在异步和双向通信中的可扩展性，从而支持需要数万个传感器、电池寿命更长且能进行数据驱动、时间敏感决策的新兴物联网和CPS应用。

> **ai_Abstract:** 本文提出了一种改进的LPWAN技术SNOW，旨在解决现有LPWAN在大规模异步和双向通信中遇到的可扩展性挑战。通过利用D-OFDM子载波和一组互不干扰的基于Gold码的伪随机噪声（PN）序列，SNOW能够使基站并行解码同一子载波上多个传感器的并发数据，并支持基站向多个传感器在同一子载波上并行传输数据。实验结果表明，该方法将SNOW的可扩展性提高了约9倍，同时保持了数据收集的及时性和传感器的能效，为未来需要大规模传感器部署的IoT和CPS应用提供了支持。

> **摘要翻译:** LPWAN因其能够在单跳内连接大地理区域的传感器而变得无处不在。然而，在LPWAN中实现大规模可扩展性，即众多传感器能够高效、低延迟地传输数据，这对于新兴的物联网和CPS应用来说可能至关重要，但极具挑战性。在本文中，我们通过显著改进一种名为SNOW的LPWAN技术来解决上述挑战。SNOW利用分布式正交频分复用（D-OFDM）子载波，使基站能够并行接收来自多个异步传感器的数据，每个传感器使用不同的子载波。在本文中，我们通过使基站能够解码来自同一子载波上众多异步传感器的并发数据，同时并行解码其他子载波，从而在SNOW中实现了大规模可扩展性。此外，我们还使众多异步传感器能够在同一子载波上接收来自基站的不同数据，同时其他传感器也在其他子载波上并行接收数据。为此，我们开发了一组基于Gold码的伪随机噪声（PN）序列，这些序列在子载波内部和之间互不干扰。每个传感器使用其PN序列从该集合中选择用于其子载波上的数据编码或解码，从而实现大规模并发。我们的评估结果表明，我们可以在SNOW中实现大约9倍的可扩展性，同时基站的数据收集及时，传感器能效高。这可能使新兴的物联网和CPS应用成为可能，这些应用需要数万个传感器，具有更长的电池寿命，并能做出数据驱动、时间敏感的决策。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [37] [Action-List Reinforcement Learning Syndrome Decoding for Binary Linear Block Codes](https://arxiv.org/abs/2507.17893)
> *二进制线性分组码的动作列表强化学习伴随式译码*

*Milad Taghipour, Bane Vasic* | **Category: cs.IT, cs.AI, cs.LG, math.IT** | **Updated: 2025-07-23**

**Keywords:** 强化学习, 线性分组码, 伴随式译码, 马尔可夫决策过程, 动作列表译码

**Comment:** 

> **TL;DR:** 本文提出了一种基于强化学习的动作列表译码方案，通过将迭代译码映射到马尔可夫决策过程并优化状态空间，显著提高了二进制线性分组码的译码性能和效率。

**AI_Comments:** 这篇论文通过将迭代译码过程巧妙地映射到马尔可夫决策过程，并提出创新的动作列表译码方案（包括利用Deep-Q网络和自同构群），为线性分组码的译码提供了一种新的强化学习范式。其亮点在于对MDP状态空间的有效缩减以及与现有高性能译码器的结合，这有望在提高译码性能的同时控制计算复杂度，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过应用强化学习技术，提高基于翻转比特和寻找最优决策的线性分组码的译码性能。

**Method:** 1. 将迭代译码过程映射到马尔可夫决策过程（MDPs）。2. 提出多种方法减少MDP中的状态数量，包括截断MDP以学习码字周围指定半径的汉明球。3. 提出一种通用的基于强化学习的译码方案，称为“动作列表译码”，适用于任何类型的码，并基于Deep-Q网络值设计了动作列表译码器。4. 利用码的自同构群进一步提高码性能。5. 提出一种基于反馈的方法，通过在现有高性能译码器之后应用强化学习算法来利用和增强其性能。

**Result:** 1. 提出的基于Deep-Q网络的动作列表译码器显著提高了译码性能。2. 利用码的自同构群进一步提升了码性能。3. 所提出的方法有效降低了强化学习模块的复杂性。4. 在二元对称信道（BSC）上的低密度奇偶校验（LDPC）码实验结果证明了所提方法的效率。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种新颖的基于强化学习的动作列表译码方案，用于增强二进制线性分组码的译码性能。该方案将迭代译码过程建模为马尔可夫决策过程，并通过截断MDP和利用自同构群等多种策略优化了状态空间和译码效率。特别地，基于Deep-Q网络的动作列表译码器被证明能显著提升性能。此外，还引入了一种反馈机制，允许在现有高性能译码器后应用强化学习，从而有效降低了强化学习模块的复杂性。实验结果验证了该方法在LDPC码上的高效性。

> **摘要翻译:** 这篇论文探讨了强化学习技术在提高基于比特翻转和寻找最优决策的线性分组码译码性能方面的应用。我们描述了将迭代译码过程映射到马尔可夫决策过程（MDPs）的方法，并提出了不同的方法来减少MDP中的状态数量。提出了一种截断MDP来通过学习码字周围指定半径的汉明球来减少MDP中的状态数量。然后，我们提出了一种通用的基于强化学习的译码方案，适用于任何类型的码，以提高译码器的性能。我们称这种方案为动作列表译码。我们设计了一个基于Deep-Q网络值的动作列表译码器，它显著提高了性能。我们还利用码的自同构群来进一步提高码性能。此外，我们提出了一种基于反馈的方法，通过在现有译码器之后应用强化学习算法来利用和增强现有高性能译码器的性能。这些方法有效地降低了强化学习模块的复杂性。最后，我们展示了在二元对称信道（BSC）上的低密度奇偶校验（LDPC）码的实验结果，以证明所提方法的效率。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [93] [Minimax Data Sanitization with Distortion Constraint and Adversarial Inference](https://arxiv.org/abs/2507.17942)
> *具有失真约束和对抗性推理的最小最大数据净化*

*Amirarsalan Moatazedian, Yauhen Yakimenka, Rémi A. Chou, Jörg Kliewer* | **Category: cs.IT, cs.AI, math.IT** | **Updated: 2025-07-23**

**Keywords:** 数据净化, 隐私保护, 最小最大优化, 对抗性推理, 秘密共享

**Comment:** Accepted to IEEE ITW 2025

> **TL;DR:** 研究了一种隐私保护的数据共享设置，其中数据净化器在满足重构器失真约束的同时，最大化两个未经授权的对手的最小损失，并提出了一种数据驱动的最小最大优化训练方法。

**AI_Comments:** 这篇论文提出了一种新颖的数据净化框架，通过引入双对手最小最大优化来平衡数据效用和隐私保护。其创新点在于将秘密共享的理念引入到损失性数据恢复中，并考虑了对手的侧信息。这种方法为设计更鲁棒的隐私保护系统提供了理论基础和实用的训练策略。该方法可能在需要数据聚合但又需要防止未经授权个体推断的场景中具有重要应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决隐私保护数据共享中的一个挑战，即如何在允许授权重构器准确重构数据（在失真阈值内）的同时，最大化未经授权的对手从净化数据中获取信息的难度，特别是当对手拥有相关侧信息时。它旨在建模这样一种情况：单个对手无法准确重构数据，但通过协作可以实现重构。

**Method:** 将问题建模为一个受约束的数据驱动最小最大优化问题。提出了一种数据驱动的训练过程，该过程交替更新净化器、重构器和对手。此外，还分析了高斯和二元情况作为特殊场景，可以在这些场景中获得最优解，这些最优解用作评估所提出最小最大训练方法的基准。

**Result:** 提出了一个数据驱动的最小最大训练方法来解决此问题，并分析了高斯和二元情况下的理论最优解，这些最优解可作为评估所提出训练方法的基准。具体的实验结果或性能数据未在摘要中提及。

**Conclusion:** 该研究提出了一个新颖的隐私保护数据共享框架，通过最小最大优化在数据失真约束下实现对非授权方的最大化信息损失，并通过协作实现准确重构，为损失性秘密共享提供了理论基础和实用的训练方法。

> **ai_Abstract:** 本文研究了一种隐私保护的数据共享模型，其中数据净化器在满足授权重构器失真约束的同时，最大化两个拥有侧信息的非授权对手的最小损失。该模型旨在通过协作实现数据重构，类似于损失性秘密共享。作者将此问题表述为一个受约束的数据驱动最小最大优化问题，并提出了一种交替更新净化器、重构器和对手的训练程序。此外，文章还分析了高斯和二元情况下的理论最优解，作为评估所提方法的基准。

> **摘要翻译:** 我们研究了一种隐私保护的数据共享设置，其中一个净化器将私人数据转换为一个被授权重构器和两个未经授权的对手观察到的净化版本，每个对手都可以访问与私人数据相关的侧信息。重构器在失真函数下进行评估，而每个对手则使用单独的损失函数进行评估。净化器确保重构器失真保持在固定阈值以下，同时最大化两个对手的最小损失。这种双对手设置模拟了单个用户无法准确重构数据，但其组合的侧信息能够在失真阈值内进行估计的情况。净化器最大化个体损失，同时仅允许通过协作进行准确重构。这与秘密共享原则相呼应，但它是损失性而非完美恢复。我们将其构建为一个受约束的数据驱动最小最大优化问题，并提出了一种数据驱动的训练过程，该过程交替更新净化器、重构器和对手。我们还将高斯和二元情况作为特殊场景进行分析，在这些场景中可以获得最优解。这些理论最优结果是评估所提出的最小最大训练方法的基准。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [142] [On the Role of Age and Semantics of Information in Remote Estimation of Markov Sources](https://arxiv.org/abs/2507.18514)
> *马尔可夫源远程估计中信息年龄和语义的作用*

*Jiping Luo, Nikolaos Pappas* | **Category: cs.IT, cs.NI, cs.SY, eess.SY, math.IT** | **Updated: 2025-07-24**

**Keywords:** 信息年龄, 连续错误年龄, 马尔可夫源, 远程估计, 传输策略

**Comment:** Submitted for possible journal publication. A shorter version has
  been accepted as invited paper at Asilomar 2025

> **TL;DR:** 本文研究了有限状态马尔可夫链的语义感知远程估计，利用AoCE和AoI优化了传输策略，并通过一种新的算法显著提高了估计质量。

**AI_Comments:** 本文的创新点在于将信息年龄(AoI)和连续错误年龄(AoCE)相结合，共同优化马尔可夫源的远程估计性能，并提出了相应的混合传输策略和高效算法。这对于需要考虑信息时效性和误差语义的实时系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在设计一种传输策略，以在传输频率约束下优化有限状态马尔可夫链的远程估计性能。

**Method:** 采用最大后验(MAP)估计器，引入连续错误年龄(AoCE)和信息年龄(AoI)来量化误差和信息过时性。将问题建模为具有无界成本的约束马尔可夫决策过程(CMDP)，并证明了最优简单混合策略的存在。该策略基于AoCE、AoI和瞬时估计误差的阈值触发传输。开发了结构感知算法Insec-SPI来计算最优策略。

**Result:** 结果表明，结合AoI和AoCE比单独使用任一指标能显著提高估计质量。存在一种最优的简单混合策略，该策略以固定概率随机选择两种确定性切换策略。

**Conclusion:** 结合信息年龄(AoI)和连续错误年龄(AoCE)能够显著提升马尔可夫源远程估计的性能。

> **ai_Abstract:** 本文研究了有限状态马尔可夫链的语义感知远程估计问题，旨在设计一种在传输频率约束下优化估计性能的传输策略。通过引入连续错误年龄(AoCE)和信息年龄(AoI)两个指标，作者将问题建模为约束马尔可夫决策过程，并提出了一种最优简单混合策略。该研究还开发了Insec-SPI算法来计算最优策略，实验结果表明结合AoI和AoCE能显著提升估计质量。

> **摘要翻译:** 本文研究了有限状态马尔可夫链的语义感知远程估计。我们采用最大后验(MAP)估计器，旨在设计一种传输策略，以在传输频率约束下优化估计性能。我们利用两个指标，即连续错误年龄(AoCE)和信息年龄(AoI)，分别量化发射器处估计误差的重要性以及接收器处过时信息的可预测性。最优传输问题被公式化为具有无界成本的约束马尔可夫决策过程(CMDP)。我们证明了最优简单混合策略的存在，该策略以固定概率随机选择两种确定性切换策略。值得注意的是，每种切换策略仅当AoCE超过一个阈值（该阈值取决于AoI和瞬时估计误差）时才触发传输。我们进一步推导了切换策略简化为简单阈值策略的充分条件；也就是说，它对所有估计误差都采用相同的阈值。利用这些结果，我们开发了一种高效的结构感知算法Insec-SPI，该算法以降低的计算开销计算最优策略。我们的结果表明，结合AoI和AoCE比单独使用任一指标能显著提高估计质量。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [149] [Deep Learning-based Position-domain Channel Extrapolation for Cell-Free Massive MIMO](https://arxiv.org/abs/2507.17950)
> *基于深度学习的无蜂窝大规模MIMO位置域信道外推*

*Jiajia Guo, Chao-Kai Wen, Xiao Li, Shi Jin* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-23**

**Keywords:** 深度学习, 信道外推, 无蜂窝大规模MIMO, 位置域, 信道获取

**Comment:** IEEE TWC. copyright2025 IEEE. Personal use of this material is
  permitted. Permission from IEEE must be obtained for all other uses, in any
  current or future media, including reprinting/republishing this material for
  advertising or promotional purposes, creating new collective works, for
  resale or redistribution to servers or lists, or reuse of any copyrighted
  component of this work in other works

> **TL;DR:** 提出PCEnet框架，利用深度学习和用户位置信息，显著降低无蜂窝大规模MIMO系统中的信道获取开销。

**AI_Comments:** 该论文提出了一种创新的方法，将用户位置信息与深度学习相结合，以解决无蜂窝大规模MIMO系统中信道获取开销大的挑战。其核心创新在于利用用户位置作为不同信道之间的“桥梁”，实现了信道特征的有效映射和外推。此外，引入简化策略和无需位置标签的方法，提高了实用性和部署灵活性。这项工作对于提升未来无线通信系统的频谱效率和系统性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了减少信道获取开销，现有的信道外推技术已被广泛研究。本文旨在通过利用用户位置信息，解决无蜂窝大规模MIMO系统中信道获取效率低下的问题。

**Method:** 本文提出了一个名为PCEnet的基于深度学习的位置域信道外推框架，用于无蜂窝大规模MIMO系统。该框架利用用户位置作为不同信道之间的桥梁，建立信道特征之间的映射，从而利用一个已获取的信道来辅助其他信道的估计和反馈。具体而言，该方法首先利用神经网络从获得的信道中推断用户位置。估计出的位置通过中央处理单元（CPU）在基站之间共享，然后输入到神经网络中设计导频符号，并与反馈信息连接到信道重建神经网络以重建其他信道。此外，还提出了一种简化策略，仅在重建过程中使用估计位置而不修改导频设计，以降低延迟。还引入了一种无需位置标签的方法，推断相对用户位置而非绝对位置，消除了定位神经网络训练中对真实位置标签的需求。

**Result:** 仿真结果表明，所提出的PCEnet框架可将导频和反馈开销降低高达50%。

**Conclusion:** 所提出的PCEnet框架通过利用用户位置信息，有效降低了无蜂窝大规模MIMO系统中的信道获取开销，显著提高了信道获取性能。

> **ai_Abstract:** 本文提出了一种名为PCEnet的深度学习框架，用于无蜂窝大规模MIMO系统中的位置域信道外推。该框架利用用户位置作为不同信道之间的桥梁，通过神经网络从一个已获取的信道推断用户位置，并利用该位置辅助其他信道的估计和重建。PCEnet还包括简化策略和无需位置标签的方法，旨在减少信道获取开销和延迟。仿真结果显示，该方法能将导频和反馈开销降低高达50%。

> **摘要翻译:** 为了减少信道获取开销，空间域、时间域和频域信道外推技术已被广泛研究。本文提出了一种新颖的基于深度学习的位置域信道外推框架（命名为PCEnet），用于无蜂窝大规模多输入多输出（MIMO）系统。用户的精确位置信息包含重要的信道特性，可以大大提高信道获取的效率。在无蜂窝大规模MIMO中，尽管不同基站与特定用户之间的传播环境各异，且它们各自的信道是不相关的，但用户的位置在所有信道中保持不变且唯一。基于此，所提出的PCEnet框架利用位置作为信道之间的桥梁，建立不同信道特征之间的映射，从而利用一个已获取的信道来辅助其他信道的估计和反馈。具体而言，该方法首先利用神经网络（NNs）从获得的信道中推断用户位置。然后，通过中央处理单元（CPU）在基站之间共享的估计位置被馈入神经网络以设计导频符号，并与反馈信息连接到信道重建神经网络以重建其他信道，从而显著提高信道获取性能。此外，我们提出了一种简化策略，其中仅在重建过程中使用估计位置而不修改导频设计，从而降低了延迟。此外，我们引入了一种无需位置标签的方法，该方法推断相对用户位置而不是绝对位置，从而消除了定位神经网络训练中对真实位置标签的需求。仿真结果表明，所提出的PCEnet框架可将导频和反馈开销降低高达50%。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [205] [A Novel Coded Computing Approach for Distributed Multi-Task Learning](https://arxiv.org/abs/2507.18025)
> *分布式多任务学习的一种新型编码计算方法*

*Minquan Cheng, Yongkang Wang, Lingyu Zhang, Youlong Wu* | **Category: cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** 分布式多任务学习, 编码计算, 通信瓶颈, 异构数据放置, 矩阵分解

**Comment:** 17 pages, 2 figures

> **TL;DR:** 本文提出了一种新颖的编码计算方案，用于解决分布式多任务学习中的通信瓶颈问题，该方案能显著降低通信开销，并在理论上达到通信开销的下界，适用于同构和异构环境。

**AI_Comments:** 该论文提出了一种创新的编码计算方法，有效解决了大规模分布式多任务学习中的关键通信瓶颈问题。其创新之处在于将通信问题转化为矩阵分解，并设计出理论上达到最优通信下界的方案。该方案不仅在理论上严谨，而且在实践中对异构数据环境的适应性强，并具有良好的可扩展性，对于提升分布式机器学习系统的效率和性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在大规模学习场景中，分布式多任务学习（DMTL）的通信瓶颈严重限制了实际系统性能。

**Method:** 本文将DMTL系统中的通信过程表征为一个矩阵分解问题，将工作节点的数据存储约束转化为上行编码矩阵的结构特性，将数据检索需求转化为下行编码矩阵的最大距离可分离（MDS）特性。在此基础上，提出了一种新颖的编码DTML方案，旨在大幅降低异构数据放置下的DTML通信成本。

**Result:** 所提出的方案在温和条件下实现了通信开销的理论下界。这种最优性在传统的同构计算环境和各种异构场景中都成立。此外，该方案可扩展到目标函数涉及局部更新值多个线性组合的分布式线性可分离计算问题。

**Conclusion:** 本文提出的编码DMTL方案为解决分布式多任务学习中的通信瓶颈问题提供了一种最优方法，尤其是在处理异构数据放置挑战方面，并为各种分布式应用中的异构数据放置问题提供了新的解决方案。

> **ai_Abstract:** 本文旨在解决大规模分布式多任务学习（DMTL）中的通信瓶颈问题。作者将通信过程建模为矩阵分解，并将数据约束与编码矩阵特性相关联。在此基础上，提出了一种新颖的编码DMTL方案，该方案能显著降低通信开销。理论分析表明，该方案在同构和异构环境下都能达到通信开销的理论下界，并且可扩展到其他分布式线性可分离计算问题，为处理异构数据放置挑战提供了新途径。

> **摘要翻译:** 分布式多任务学习（DMTL）通过多个相关模型的协同训练有效提高了模型的泛化性能。然而，在大规模学习场景中，通信瓶颈严重限制了实际系统性能。在本文中，我们研究了采用非线性全局更新的典型DMTL系统中的通信瓶颈。该系统涉及分布式工作节点，在中央服务器的协助下，协同学习源自其局部模型参数非线性聚合的不同模型。我们首先将通信过程表征为一个矩阵分解问题。它将工作节点的数据存储约束转换为上行编码矩阵的结构特性，并将工作节点数据检索需求转换为下行编码矩阵的最大距离可分离（MDS）特性。在此基础上，我们提出了一种新颖的编码DTML方案，可以大大降低异构数据放置下的DTML通信成本。理论分析表明，所提出的方案在温和条件下实现了通信开销的理论下界。值得注意的是，这种最优性适用于传统的同构计算环境和各种异构场景。此外，我们的方案可扩展到目标函数涉及局部更新值多个线性组合的分布式线性可分离计算问题。这表明我们的方案为解决各种分布式应用中的异构数据放置挑战提供了一种新方法。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [265] [Covert Communications in MEC-Based Networked ISAC Systems Towards Low-Altitude Economy](https://arxiv.org/abs/2507.18194)
> *面向低空经济的MEC网络化ISAC系统中的隐蔽通信*

*Weihao Mao, Yang Lu, Bo Ai, Tony Q. S. Quek* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-24**

**Keywords:** 低空经济, 隐蔽通信, ISAC, MEC, 无人机

**Comment:** 

> **TL;DR:** 本文研究了面向低空经济的MEC网络化ISAC系统中的隐蔽传输设计，通过优化通信、感知和计算资源以及无人机轨迹，最小化总能耗，并提出了一种交替优化算法来解决该问题。

**AI_Comments:** 该论文在低空经济这一新兴领域，创新性地将隐蔽通信、ISAC和MEC相结合，构建了一个复杂的系统模型。通过深入分析检测错误概率和多目标优化问题，提出了有效的交替优化算法，为未来低空经济中的安全高效通信提供了理论和技术支持。其对通信、感知和计算之间权衡的揭示也具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 低空经济（LAE）是一种新兴的商业模式，它严重依赖于集成感知与通信（ISAC）、移动边缘计算（MEC）和隐蔽通信。本文旨在研究在MEC网络化ISAC系统中实现面向LAE的隐蔽传输设计。

**Method:** 本文首先推导了守卫者的检测错误概率（DEP）的闭式表达式。然后，通过优化通信、感知和计算资源以及无人机轨迹，建立了一个总能耗最小化问题，并提出了一个基于交替优化的算法来解决该问题。该算法将问题分解为资源联合优化和无人机轨迹优化两个子问题，分别通过基于逐次凸逼近的算法和基于信赖域的算法解决。

**Result:** 仿真验证了所提出算法与各种基准算法相比的有效性，并揭示了低空经济系统中通信、感知和计算之间的权衡。

**Conclusion:** 本文提出的算法在面向低空经济的MEC网络化ISAC系统中实现了有效的隐蔽通信，并揭示了通信、感知和计算资源之间的重要权衡。

> **ai_Abstract:** 本文研究了面向低空经济（LAE）的MEC网络化集成感知与通信（ISAC）系统中的隐蔽传输设计。该系统涉及MEC服务器协调多个接入点，同时处理无人机计算任务、目标定位和维持无人机隐蔽通信。研究首先推导了守卫者的检测错误概率（DEP），然后通过优化通信、感知和计算资源以及无人机轨迹，构建了一个总能耗最小化问题。为解决此问题，提出了一种基于交替优化的算法，将其分解为资源联合优化和无人机轨迹优化两个子问题，分别采用逐次凸逼近和信赖域方法求解。仿真结果验证了算法的有效性，并揭示了LAE系统中通信、感知和计算之间的权衡关系。

> **摘要翻译:** 低空经济（LAE）是一种新兴的商业模式，它严重依赖于集成感知与通信（ISAC）、移动边缘计算（MEC）和隐蔽通信。本文研究了面向低空经济的MEC网络化ISAC系统中的隐蔽传输设计，其中MEC服务器协调多个接入点同时接收来自多架无人机（UAV）的计算任务，定位感知区域中的目标，并针对多个守卫者保持无人机的隐蔽传输。我们首先推导了守卫者处检测错误概率（DEP）的闭式表达式。然后，我们通过优化通信、感知和计算资源以及无人机轨迹，建立了一个总能耗最小化问题，该问题受到MEC服务质量、DEP、雷达信噪比和无人机轨迹因果关系的约束。提出了一种基于交替优化的算法来处理所考虑的问题，该算法将其分解为两个子问题：通信、感知和计算资源的联合优化，以及无人机轨迹优化。前者通过基于逐次凸逼近的算法解决，而后者通过基于信赖域的算法解决。仿真验证了所提出算法与各种基准算法相比的有效性，并揭示了LAE系统中通信、感知和计算之间的权衡。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [331] [Hermitian hull of some GRS codes and new EAQMDS codes](https://arxiv.org/abs/2507.18361)
> *某些GRS码的Hermitian包络和新型EAQMDS码*

*Oisin Campion, Rodrigo San-José* | **Category: cs.IT, math.IT, 81P70 (Primary) 94B05 (Secondary)** | **Updated: 2025-07-24**

**Keywords:** Hermitian包络, 广义Reed-Solomon码, 量子MDS码, 纠缠辅助, 格点计数

**Comment:** 

> **TL;DR:** 本文研究了广义Reed-Solomon (GRS) 码的Hermitian包络，通过将其维数计算转化为格点计数问题，得到了维数显式公式，并利用此方法构造了新型纠缠辅助量子MDS (EAQMDS) 码。

**AI_Comments:** 本文通过将代数编码理论中的包络维数计算问题巧妙地转化为格点计数问题，为确定量子纠错码所需的纠缠资源提供了精确的数学工具。这种方法具有创新性，因为它不仅提供了理论上的显式公式，而且为构建具有新参数的纠缠辅助量子MDS码提供了灵活的途径，对于量子信息和量子通信领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 确定关联的纠缠辅助量子纠错码所需的最大纠缠对的最小数量。

**Method:** 将Hermitian包络的维数计算问题转化为格点中的计数问题，并通过解决该问题来提供维数的显式公式。

**Result:** 提供了Hermitian包络维数的显式公式；确定了关联的纠缠辅助量子纠错码所需的最大纠缠对的最小数量；获得了广泛的纠缠辅助量子MDS码以及新的参数。

**Conclusion:** 这种灵活的构造方法能够获得广泛的纠缠辅助量子MDS码以及新的参数。

> **ai_Abstract:** 本文研究了特定广义Reed-Solomon (GRS) 码的Hermitian包络，并将其维数计算问题转化为格点计数问题。通过求解该问题，文章给出了包络维数的显式公式，该公式可用于确定纠缠辅助量子纠错码所需的最大纠缠对数量。这种方法为构造新型纠缠辅助量子MDS (EAQMDS) 码及其新参数提供了灵活的途径。

> **摘要翻译:** 我们研究了特定广义Reed-Solomon码族的Hermitian包络。计算包络维数的问题被转化为格点中的计数问题。通过解决这个问题，我们为包络维数提供了显式公式，这决定了关联的纠缠辅助量子纠错码所需的最大纠缠对的最小数量。这种灵活的构造方法使得能够获得广泛的纠缠辅助量子MDS码，以及新的参数。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [386] [Private Counterfactual Retrieval](https://arxiv.org/abs/2410.13812)
> *私有反事实检索*

*Mohamed Nomeir, Pasan Dissanayake, Shreya Meel, Sanghamitra Dutta, Sennur Ulukus* | **Category: cs.IT, cs.CR, cs.LG, eess.SP, math.IT** | **Updated: 2025-07-24**

**Keywords:** 私有反事实检索, 私有信息检索, 可解释人工智能, 隐私保护, 黑盒模型

**Comment:** 

> **TL;DR:** 本文提出了基于私有信息检索（PIR）的技术，用于在提供反事实解释时保护用户隐私，并量化并减少了数据库泄露。

**AI_Comments:** 该论文的创新点在于将私有信息检索（PIR）技术应用于反事实解释的检索，从而解决了在提供透明度和可解释性时可能出现的隐私泄露问题。这对于高风险应用中黑盒模型的部署具有重要意义。文章不仅提出了保护用户隐私的方案，还量化了数据库泄露并提出了减少策略，显示了对实际应用中隐私平衡的考量。

<details>
  <summary>Details</summary>

**Motivation:** 在部署高风险应用的黑盒机器学习模型时，透明度和可解释性至关重要。提供反事实解释是满足这一要求的一种方式，但这会威胁到提供解释的机构和请求解释的用户的隐私。

**Method:** 本文提出了多种受私有信息检索（PIR）技术启发的方案，以确保用户在检索反事实解释时的隐私。提出了一种从接受点数据库中检索“精确”最近邻反事实解释的方案，为用户实现了完美的（信息论上）隐私。此外，提出了减少数据库泄露的策略，以实现更高程度的数据库隐私。这些方案还扩展以整合用户对其属性转换的偏好。方案依赖于有限域算术，并在真实数据集上进行了实证验证，以理解准确性和有限域大小之间的权衡。

**Result:** 所提出的方案在检索反事实解释时为用户实现了完美的隐私。量化了不可避免的数据库泄露，并提出了减少泄露的策略。通过实证验证，理解了准确性和有限域大小之间的权衡。数值结果支持了理论发现，并比较了所提方案的数据库泄露。

**Conclusion:** 本文提出了基于私有信息检索（PIR）的方案，用于私有反事实解释检索，在确保用户隐私的同时，量化并努力减少数据库泄露，并通过实证数据验证了其有效性。

> **ai_Abstract:** 本文提出了一种解决黑盒机器学习模型中反事实解释隐私问题的方案。该研究受到私有信息检索（PIR）技术的启发，旨在确保用户在获取反事实解释时的隐私。文中详细阐述了一种能够从数据库中检索精确最近邻反事实解释的方案，该方案为用户提供了完美的隐私保护。同时，该方案也量化了不可避免的数据库泄露，并提出了减少这种泄露的策略。此外，该方案还考虑了用户对属性转换的偏好，以提供更具操作性的解释。研究通过在真实数据集上进行实证验证，分析了准确性与有限域大小之间的权衡，并提供了数值结果来支持其理论发现。

> **摘要翻译:** 透明度和可解释性是在高风险应用中采用黑盒机器学习模型时需要考虑的两个极其重要的方面。提供反事实解释是满足这一要求的一种方式。然而，这也对提供解释的机构和请求解释的用户都构成了隐私威胁。在这项工作中，我们提出了多种受私有信息检索（PIR）技术启发的方案，这些方案在检索反事实解释时确保了用户的隐私。我们提出了一种从接受点数据库中检索“精确”最近邻反事实解释的方案，同时为用户实现了完美的（信息论上）隐私。虽然该方案为用户实现了完美的隐私，但一些数据库泄露是不可避免的，我们使用基于互信息度量对其进行了量化。此外，我们提出了减少这种泄露的策略，以实现更高程度的数据库隐私。我们将这些方案扩展以整合用户对其属性转换的偏好，以便可以接收到更具可操作性的解释。由于我们的方案依赖于有限域算术，我们通过真实数据集对我们的方案进行了实证验证，以了解准确性和有限域大小之间的权衡。最后，我们提供了数值结果来支持我们的理论发现，并比较了所提方案的数据库泄露。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [387] [AI/ML Life Cycle Management for Interoperable AI Native RAN](https://arxiv.org/abs/2507.18538)
> *互操作AI原生RAN的AI/ML生命周期管理*

*Chu-Hsiang Huang, Chao-Kai Wen, Geoffrey Ye Li* | **Category: cs.IT, cs.LG, math.IT** | **Updated: 2025-07-24**

**Keywords:** AI/ML, RAN, 生命周期管理, 3GPP, 6G

**Comment:** 8 pages, 4 figures, 2 table. This work has been submitted to the IEEE
  for possible publication

> **TL;DR:** 该论文回顾了3GPP在5G无线接入网络（RAN）中AI/ML生命周期管理（LCM）的演进，详细介绍了五块架构、监控和协作方案，并指出了开放挑战，以期实现AI原生6G。

**AI_Comments:** 本文及时且相关地回顾了3GPP为将AI/ML集成到RAN中所做的标准化努力，解决了大规模部署的关键挑战。其对LCM、互操作性的关注以及对开放挑战的识别，对于未来向6G AI原生网络的演进至关重要。强调与供应商无关的解决方案对于培育健康的生态系统尤其具有创新性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 在5G无线接入网络（RAN）中，人工智能（AI）和机器学习（ML）模型缺乏标准化的生命周期管理（LCM）框架，导致模型漂移、供应商锁定和透明度有限等挑战，从而阻碍了其大规模应用。

**Method:** 本文回顾了3GPP版本16-20中AI/ML的演进，重点关注标准化接口和功能，如网络数据分析功能（NWDAF）。它具体审查了由此产生的五块LCM架构、KPI驱动的监控机制和供应商间协作方案。

**Result:** 论文描述了五块LCM架构、KPI驱动的监控机制和供应商间协作方案。它还指出了开放挑战，包括资源高效监控、环境漂移检测、智能决策和灵活模型训练。

**Conclusion:** 本文所回顾的进展为AI原生收发器奠定了基础，这是6G的关键使能技术。

> **ai_Abstract:** 本文探讨了3GPP版本16-20中人工智能/机器学习（AI/ML）在5G无线接入网络（RAN）中集成及其生命周期管理（LCM）的演进。文章指出，缺乏统一的LCM框架会阻碍AI/ML的大规模应用，导致模型漂移和供应商锁定等问题。本文审查了已形成的五块LCM架构、基于KPI的监控机制和供应商间协作方案，并指出了在资源高效监控、智能决策等领域存在的持续挑战，这些对于开发面向6G的AI原生收发器至关重要。

> **摘要翻译:** 人工智能（AI）和机器学习（ML）模型正在迅速渗透5G无线接入网络（RAN），为波束管理、信道状态信息（CSI）反馈、定位和移动性预测提供支持。然而，如果没有标准化的生命周期管理（LCM）框架，模型漂移、供应商锁定和透明度有限等挑战阻碍了大规模采用。3GPP版本16-20逐步将AI/ML从实验性功能发展为受管理、可互操作的网络功能。从Rel-16中的网络数据分析功能（NWDAF）开始，后续版本引入了用于模型传输、执行、性能监控和闭环控制的标准化接口，最终在Rel-20中达到了双边CSI压缩工作项和供应商无关的LCM配置文件。本文回顾了由此产生的五块LCM架构、KPI驱动的监控机制和供应商间协作方案，同时指出了资源高效监控、环境漂移检测、智能决策和灵活模型训练等开放挑战。这些发展为AI原生收发器奠定了基础，作为6G的关键使能技术。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [534] [Asymptotically Minimax Regret by Bayes Mixtures](https://arxiv.org/abs/2406.17929)
> *渐近最小最大遗憾的贝叶斯混合*

*Jun'ichi Takeuchi, Andrew R. Barron* | **Category: cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** 贝叶斯混合, 最小最大遗憾, Jeffreys先验, 指数族, 随机复杂度

**Comment:** 

> **TL;DR:** 论文研究了在数据压缩、赌博和序列预测问题中，贝叶斯混合分布如何通过使用Jeffreys先验的变体或其修改版本，实现渐近最小最大遗憾，并对Rissanen随机复杂度进行了表征。

**AI_Comments:** 该论文的创新之处在于提出了对Jeffreys先验的巧妙修改，使其能够通过局部指数倾斜来适应更广泛的非指数族分布，从而在这些复杂模型中实现渐近最小最大遗憾。这项工作对于推动统计推断在数据压缩和预测等领域的理论发展和实际应用具有重要价值，尤其是在处理非标准或复杂数据结构时。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在评估在数据压缩、赌博和序列预测问题中，贝叶斯混合分布相对于最大似然估计的遗憾和预期遗憾（冗余），尤其是在不同平滑概率分布族下的性能表现。

**Method:** 论文通过评估贝叶斯混合分布与最大似然估计的遗憾来研究问题。对于一般指数族（包括非独立同分布情况），采用Jeffreys先验的变体；对于非指数族，提出了一种通过局部指数倾斜（纤维丛）来扩展分布族并实现最小最大遗憾的Jeffreys先验修改版本。此外，还展示了如何处理混合族中的完整参数单纯形。

**Result:** 研究发现，在最大似然估计位于参数空间内部的条件下，对于一般指数族，使用Jeffreys先验的变体可以实现渐近最小最大值。对于非指数族，通过修改Jeffreys先验（其测度可在给定密度族之外），也能实现最小最大遗憾。这些条件已在某些非指数族（包括曲线族、混合族和污染模型）中得到证实。此外，结果还提供了Rissanen随机复杂度的表征。

**Conclusion:** 论文表明，通过使用Jeffreys先验的变体或其修改版本，贝叶斯混合分布能够在各种平滑概率分布族下实现渐近最小最大遗憾，这对于数据压缩、赌博和序列预测等问题具有重要意义，并进一步表征了Rissanen的随机复杂度。

> **ai_Abstract:** 这篇论文探讨了在数据压缩、赌博和序列预测问题中，如何通过贝叶斯混合分布实现渐近最小最大遗憾。研究发现，对于指数族分布，使用Jeffreys先验的变体可以达到渐近最小最大值；而对于非指数族，通过对Jeffreys先验进行修改（引入局部指数倾斜），也能实现最小最大遗憾。论文还讨论了在混合族中处理完整参数单纯形的方法，并对Rissanen的随机复杂度进行了表征。

> **摘要翻译:** 我们研究了从字母表${\cal X}$中提取的序列$x^n=x_1x_2...x_n$的数据压缩、赌博和预测问题，并以遗憾和预期遗憾（冗余）的形式，针对各种平滑概率分布族进行了研究。我们在最大似然估计在参数空间内部的条件下，评估了贝叶斯混合分布与最大似然估计相比的遗憾。对于一般的指数族（包括非独立同分布情况），当使用Jeffreys先验的变体时，可以实现渐近最小最大值。有趣的是，我们还获得了一种Jeffreys先验的修改版本，其测度在给定密度族之外，以实现对非指数族类型的最小最大遗憾。这种修改通过局部指数倾斜（一种纤维丛）扩大了分布族。我们的条件已在某些非指数族中得到证实，包括曲线族和混合族（其中混合成分或其组合权重是参数化的）以及污染模型。此外，对于混合族，我们展示了如何处理完整的参数单纯形。这些结果还提供了Rissanen随机复杂度的表征。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [582] [Polarization Aware Movable Antenna](https://arxiv.org/abs/2411.06690)
> *极化感知可移动天线*

*Runxin Zhang, Yulin Shao, Yonina C. Eldar* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-24**

**Keywords:** 极化感知, 可移动天线, 信道模型, 毫米波, 无线通信

**Comment:** 

> **TL;DR:** 本文提出了一个极化感知可移动天线 (PAMA) 框架，将极化效应整合到可移动天线 (MA) 的设计和优化中，以提升无线通信性能，尤其是在高频段和单视距路径场景下。

**AI_Comments:** 该论文的创新之处在于将极化效应引入到可移动天线的设计和优化中，这突破了传统MA研究的局限性。通过引入极化感知信道模型，揭示了MA在极化匹配方面的独特优势，并证明了其在高频段和单视距场景下的潜力，对未来无线网络的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有可移动天线 (MA) 研究主要关注由不同传播路径引起的相位变化，并利用天线移动来最大化信道增益，但这种狭隘的关注限制了MA的全部潜力。

**Method:** 本文提出了一个极化感知可移动天线 (PAMA) 框架，将极化效应整合到可移动天线 (MA) 的设计和优化中。引入了一个根植于电磁理论的极化感知信道模型，揭示了MA相对于预编码等其他无线技术在优化极化匹配方面的优势。

**Result:** 研究结果表明，将极化考虑纳入可移动天线显著提高了效率、链路可靠性和数据吞吐量。PAMA能够将MA的应用范围从射频、多径丰富场景扩展到更高频段（如毫米波），即使在单视距（LOS）路径下也能发挥作用。

**Conclusion:** 将极化考虑纳入可移动天线显著提高了效率、链路可靠性和数据吞吐量，为未来更健壮和高效的无线网络铺平了道路。

> **ai_Abstract:** 本文提出了一种极化感知可移动天线（PAMA）框架，旨在克服现有可移动天线（MA）研究仅关注相位变化的局限性。通过引入基于电磁理论的极化感知信道模型，PAMA利用MA优化极化匹配的能力，从而扩展了MA的应用范围，使其在高频段（如毫米波）甚至单视距场景下也能显著提升无线通信的效率、链路可靠性和数据吞吐量。

> **摘要翻译:** 本文提出了一种极化感知可移动天线（PAMA）框架，该框架将极化效应整合到可移动天线（MA）的设计和优化中。虽然MA已被证明能有效提升无线通信性能，但现有研究主要侧重于由不同传播路径引起的相位变化，并利用天线移动来最大化信道增益。这种狭隘的关注限制了MA的全部潜力。在这项工作中，我们引入了一个根植于电磁理论的极化感知信道模型，揭示了MA相对于预编码等其他无线技术的一个决定性优势：优化极化匹配的能力。这种新理解使PAMA能够将MA的适用性从射频、多径丰富场景扩展到更高频段，例如毫米波，即使在单视距（LOS）路径下也能实现。我们的研究结果表明，将极化考虑纳入MA显著提高了效率、链路可靠性和数据吞吐量，为未来更健壮和高效的无线网络铺平了道路。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [630] [Integrated Sensing and Edge AI: Realizing Intelligent Perception in 6G](https://arxiv.org/abs/2501.06726)
> *集成感知与边缘人工智能：实现6G中的智能感知*

*Zhiyan Liu, Xu Chen, Hai Wu, Zhanwei Wang, Xianhao Chen, Dusit Niyato, Kaibin Huang* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-24**

**Keywords:** 集成感知, 边缘AI, 6G, 智能感知, 综述

**Comment:** To appear in IEEE Communications Surveys and Tutorials

> **TL;DR:** 本文全面综述了6G中的集成感知与边缘AI（ISEA），涵盖其概念、用例、技术和未来方向。

**AI_Comments:** 这篇论文对ISEA（6G的关键概念）进行了及时而全面的综述。它的优势在于对这一庞大主题进行了结构化，涵盖了技术基础、实际应用和未来挑战。其整体设计方法是创新的，强调通信、AI和感知的协同设计。它为进入该领域的研究人员提供了极好的参考。

<details>
  <summary>Details</summary>

**Motivation:** 感知应用依赖强大的AI模型，同时海量感知数据为AI模型提供燃料，这种深度融合催生了集成感知与边缘AI（ISEA）这一新的面向任务的范式，旨在实现6G中最佳感知任务性能。

**Method:** 本文对集成感知与边缘AI（ISEA）进行了全面综述。它介绍了技术基础、研究了用例、标准化和工业进展，建立了设计原则、指标、权衡和架构，并概述了相关技术，探讨了其与6G进步的相互作用，并提出了未来的研究机会。

**Result:** 综述全面概述了ISEA，包括其技术基础、通过用例展示的实际相关性、已建立的设计原则和架构、详细的技术以及其与各种6G进步的相互作用。

**Conclusion:** 论文最后提出了ISEA未来的研究机会，包括基础模型的集成、与ISAC的融合、超低延迟ISEA以及实际应用问题。

> **ai_Abstract:** 本文全面综述了6G网络中的集成感知与边缘AI（ISEA）。它强调ISEA作为一种新的面向任务的范式，由感知与AI的深度融合驱动，旨在实现最佳感知性能。该综述涵盖了技术基础、实际用例、设计原则、架构考量和关键技术。它还讨论了ISEA与其他6G进步的相互作用，并指明了未来的研究方向，包括基础模型、ISAC融合和超低延迟应用。

> **摘要翻译:** 感知和边缘人工智能（AI）被设想为第六代（6G）移动网络中两个必不可少且相互关联的功能。一方面，感知赋能的应用依赖强大的AI模型从无处不在的无线传感器中提取特征和理解语义。另一方面，海量的感知数据为持续改进边缘AI模型提供了燃料。感知和边缘AI的这种深度融合催生了一种新的面向任务的范式，称为集成感知与边缘AI（ISEA），其特点是对通信、AI计算和感知进行整体设计，以实现最佳的感知任务性能。在本文中，我们对ISEA进行了全面综述。我们首先提供了ISEA中感知、边缘AI和新通信范式的技术基础。然后，我们研究了ISEA的几个用例，以展示其实际相关性，并介绍了当前的标准化和工业进展。接下来，建立了ISEA的设计原则、指标、权衡和架构，随后全面概述了ISEA技术，包括数字空口、空中计算和先进信号处理。论文还介绍了其与各种6G进步的相互作用，例如新的物理层和网络技术。最后，我们提出了ISEA未来的研究机会，包括基础模型的集成、ISEA与集成感知和通信（ISAC）的融合、超低延迟ISEA以及实际应用问题。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [678] [Dual-Domain Exponent of Maximum Mutual Information Decoding](https://arxiv.org/abs/2501.13724)
> *最大互信息解码的双域指数*

*AmirPouya Moeini, Albert Guillén i Fàbregas* | **Category: cs.IT, math.IT, math.PR** | **Updated: 2025-07-24**

**Keywords:** 最大互信息解码, 错误指数, 双域, 联合信源信道编码, 离散无记忆信道

**Comment:** This paper is scheduled to be presented at IEEE ITW 2025, Sydney,
  Australia

> **TL;DR:** 本文推导了常数组成码的最大互信息（MMI）解码的错误指数的双域表达式，并证明其与离散无记忆信道的最大似然（ML）解码的错误指数一致。此外，该分析还扩展到联合信源信道编码，表明广义MMI解码器能够达到与最大后验（MAP）解码器相同的随机编码错误指数。

**AI_Comments:** 本文的创新之处在于提供了双域推导，将最大互信息（MMI）解码的错误指数与已知的最优解码器（最大似然和最大后验）在不同编码场景下的性能统一起来。这表明MMI解码的理论性能极限与这些最优方法相当，具有重要的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在推导和分析最大互信息（MMI）解码的错误指数，并将其与其他解码方法进行比较，证明其性能与最优解码器一致。

**Method:** 本文采用了双域推导方法来分析常数组成码的最大互信息（MMI）解码的错误指数，并将分析进一步扩展到联合信源信道编码。

**Result:** 结果表明，常数组成码的最大互信息（MMI）解码的错误指数与离散无记忆信道的最大似然解码的错误指数一致。对于联合信源信道编码，广义MMI解码器实现了与最大后验解码器相同的随机编码错误指数。

**Conclusion:** 在特定条件下和扩展后，最大互信息（MMI）解码能够实现与最大似然（ML）解码和最大后验（MAP）解码等最优解码方法相同的错误指数性能。

> **ai_Abstract:** 本文推导了常数组成码的最大互信息（MMI）解码的错误指数的双域表达式，并证明其与离散无记忆信道的最大似然（ML）解码的错误指数相同。此外，该分析还扩展到联合信源信道编码，表明广义MMI解码器能够达到与最大后验（MAP）解码器相同的随机编码错误指数。

> **摘要翻译:** 本文提供了常数组成码的最大互信息（MMI）解码错误指数的双域推导，表明其与离散无记忆信道的最大似然解码的错误指数一致。该分析进一步扩展到联合信源信道编码，证明广义MMI解码器实现了与最大后验解码器相同的随机编码错误指数。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [720] [Quantum Hypothesis Testing Lemma for Deterministic Identification over Quantum Channels](https://arxiv.org/abs/2504.20991)
> *量子信道上确定性识别的量子假设检验引理*

*Pau Colomer, Christian Deppe, Holger Boche, Andreas Winter* | **Category: cs.IT, math.IT, quant-ph** | **Updated: 2025-07-24**

**Keywords:** 量子假设检验, 确定性识别, 量子信道, 容量下限, 闵可夫斯基维数

**Comment:** 7 pages, double column

> **TL;DR:** 本文提出了一个量子假设检验引理，用于在量子信道上构建确定性识别码，从而收紧了容量下限并提供了新的见解。

**AI_Comments:** 本文的创新之处在于将经典的假设检验引理推广到量子领域，为量子信道上的确定性识别编码提供了一个理论基础和构造方法。通过引入量子态空间的填充概念和闵可夫斯基维数，该工作不仅提升了对量子信道容量的理解，还揭示了同步和非同步编码之间的关键差异，对于量子信息理论具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 作者之前的研究提出了一个用于确定性识别（DI）编码的假设检验引理，但仅限于经典信道。本次工作的动机是提供该引理的完整量子模拟，以解决量子信道上的DI编码问题。

**Method:** 本文通过提供一个量子模拟的假设检验引理来实现目标。具体方法是证明量子DI码的存在性源于修改后的输出量子态空间中的合适填充（packing），并且可以使用从这种填充派生的乘积态来构建编码。

**Result:** 结果表明，该引理能够收紧量子信道上DI的容量下限，超越了同步解码方法。特别是，这些界限现在可以仅用某个态空间的闵可夫斯基维数来表示，从而提供了理解协议性质以及同步码和非同步码之间分离的新见解。

**Conclusion:** 该量子假设检验引理为量子信道上的确定性识别提供了一个强大的工具，能够更精确地确定容量界限，并深入理解量子通信协议的特性。

> **ai_Abstract:** 本文提出了一个用于量子信道上确定性识别（DI）的量子假设检验引理，作为先前经典引理的量子模拟。该引理表明，量子DI码的存在性源于输出量子态空间中的填充，并可通过乘积态构建。这一成果不仅收紧了量子信道上DI的容量下限，还通过闵可夫斯基维数提供了对协议性质和编码类型分离的新见解。

> **摘要翻译:** 在我们的前期工作中，我们提出了“假设检验引理”，这是一个关键工具，它为具有有限输出但任意输入字母表的无记忆信道上存在良好确定性识别（DI）码建立了充分条件。在这项工作中，我们提供了该引理的完整量子模拟，这表明量子设置中DI码的存在性源于修改后的输出量子态空间中的合适填充。具体来说，我们证明了可以使用从这种填充派生的乘积态来构建这种编码。这一结果使我们能够收紧量子信道上DI的容量下限，超越了同步解码方法。特别是，我们现在可以仅用某个态空间的闵可夫斯基维数来表示这些界限，这为我们更好地理解协议的性质以及同步码和非同步码之间的分离提供了新见解。我们通过一个特定的信道示例扩展了讨论，在该示例中我们可以构建一个最优码。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [762] [RDD Function: A Tradeoff Between Rate and Distortion-in-Distortion](https://arxiv.org/abs/2507.09712)
> *RDD函数：速率与失真中失真之间的权衡*

*Lingyi Chen, Haoran Tang, Shitong Wu, Jiakun Liu, Huihui Wu, Wenyi Zhang, Hao Wu* | **Category: cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** 速率失真中失真函数, Gromov型失真, 交替镜像下降算法, 速率失真理论, 源编码

**Comment:** 

> **TL;DR:** 本文提出了一种新的速率失真中失真（RDD）函数，作为经典速率失真（RD）函数的扩展，用Gromov型失真取代了期望失真约束。由于计算复杂性高，提出了一种交替镜像下降算法来有效计算RDD函数，并通过数值结果验证了其有效性，表明其在未来场景中具有潜在应用。

**AI_Comments:** 这篇论文的创新点在于提出了RDD函数，将Gromov型失真引入速率失真理论，使其能够处理不同维度空间中的相似性度量，这在传统RD函数中是难以实现的。此外，针对高计算复杂性问题，开发了高效的交替镜像下降算法，使其理论上的创新得以实际应用。这对于未来多模态数据处理和异构数据压缩可能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在扩展经典的速率失真（RD）函数，通过引入Gromov型失真来解决在不同维度空间中定义相似性的问题，并探索其在实际源编码中的应用潜力。

**Method:** 本文提出了一种新的速率失真中失真（RDD）函数，该函数将期望失真约束替换为Gromov型失真。为了解决RDD函数计算复杂性高的问题，开发了一种采用分解、线性化和松弛技术的交替镜像下降算法。

**Result:** 数值结果表明，所开发的交替镜像下降算法在经典源和不同网格上能够有效计算RDD函数。

**Conclusion:** RDD函数作为经典RD函数的扩展，通过引入Gromov型失真，在处理不同维度空间相似性方面具有潜力，并通过所提出的算法实现了有效计算，预示其在未来场景中可能具有广泛应用。

> **ai_Abstract:** 本文引入了一种新颖的速率失真中失真（RDD）函数，它是经典速率失真（RD）函数的扩展，用Gromov型失真取代了传统的期望失真约束。这种Gromov型失真基于Gromov-Wasserstein距离，能够有效衡量不同维度空间中的相似性。尽管RDD函数具有信息论和操作性RD函数的特性，但由于其固有的高计算复杂性，作者开发了一种高效的交替镜像下降算法，通过分解、线性化和松弛技术显著降低了计算负担。数值实验验证了该算法的有效性，并指出RDD函数在未来源编码应用中的巨大潜力。

> **摘要翻译:** 在本文中，我们提出了一种名为速率失真中失真（RDD）函数的新颖函数，作为经典速率失真（RD）函数的扩展，其中期望失真约束被Gromov型失真取代。这种失真作为Gromov-Wasserstein（GW）距离的组成部分，即使在它们之间没有直接度量的情况下，也能有效地定义可能不同维度空间中的相似性。虽然RDD函数符合信息论RD函数的定义，但编码定理证实了其作为操作性RD函数的地位，从而强调了其在实际源编码中的潜在适用性。由于Gromov型失真通常具有很高的计算复杂性，RDD函数通常无法进行解析评估。因此，我们开发了一种交替镜像下降算法，通过采用分解、线性化和松弛技术显著降低了计算复杂性。在经典源和不同网格上的数值结果证明了所开发算法的有效性。通过探索RDD函数与RD函数之间的关系，我们认为RDD函数可能在未来场景中具有潜在应用。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [804] [Non-Asymptotic Achievable Rate-Distortion Region for Indirect Wyner-Ziv Source Coding](https://arxiv.org/abs/2507.17432)
> *非渐近可达率失真区域用于间接Wyner-Ziv信源编码*

*Jiahui Wei, Philippe Mary, Elsa Dupraz* | **Category: cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** Wyner-Ziv编码, 率失真, 间接设置, 有限块长, Blahut-Arimoto算法

**Comment:** 8 pages, 2 figures, 3 pages' appendix

> **TL;DR:** 本文研究了间接Wyner-Ziv信源编码问题，推导了渐近率失真函数并提供了有限块长可达区域，提出了一个Blahut-Arimoto算法进行数值评估。

**AI_Comments:** 本文通过引入潜在源S的概念，扩展了传统的Wyner-Ziv信源编码问题，使其更适用于面向目标的通信场景。提出的Blahut-Arimoto算法为间接Wyner-Ziv设置提供了一种实用的数值评估工具。其创新性在于将语义信息（S）纳入编码框架，并提供了有限块长下的理论和算法支持。

<details>
  <summary>Details</summary>

**Motivation:** 研究间接Wyner-Ziv信源编码问题，其中编码器和解码器均未观测到的潜在源S需要在解码器重建。这在面向目标的通信中日益重要，其中S可以表示从X获得的语义信息。

**Method:** 推导了渐近状态下的间接Wyner-Ziv率失真函数，并提供了有限块长下的可达区域。提出了一种针对间接Wyner-Ziv设置的Blahut-Arimoto算法。

**Result:** 提出的算法用于对S作为分类标签时可达的间接率失真区域进行数值评估。

**Conclusion:** 本文推导了间接Wyner-Ziv信源编码的率失真函数和有限块长可达区域，并通过提出的Blahut-Arimoto算法进行了数值验证，证明了其在处理潜在语义信息方面的可行性。

> **ai_Abstract:** 本文研究了间接Wyner-Ziv信源编码问题，其中一个未观测到的潜在源S需要被重建，这在面向目标的通信中具有重要意义。文章推导了渐近和有限块长下的间接Wyner-Ziv率失真函数及可达区域，并提出了一种定制的Blahut-Arimoto算法。该算法被用于数值评估当S作为分类标签时的可达率失真区域。

> **摘要翻译:** 在Wyner-Ziv信源编码问题中，源X需要被编码，而解码器可以访问辅助信息Y。本文研究了间接设置，其中编码器和解码器均未观测到的潜在源S也必须在解码器处重建。这种场景在面向目标的通信背景下日益相关，其中S可以表示从X获得的语义信息。本文推导了渐近状态下的间接Wyner-Ziv率失真函数，并提供了有限块长下的可达区域。此外，还提出了一种专为间接Wyner-Ziv设置量身定制的Blahut-Arimoto算法。然后，当S被视为分类标签时，该算法被用于对可达的间接率失真区域进行数值评估。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [212] [Designing High-Performance and Thermally Feasible Multi-Chiplet Architectures enabled by Non-bendable Glass Interposer](https://arxiv.org/abs/2507.18040)
> *基于不可弯曲玻璃中介层的高性能和热可行多芯片架构设计*

*Harsh Sharma, Janardhan Rao Doppa, Umit Y. Ogras, Partha Pratim Pande* | **Category: cs.AR** | **Updated: 2025-07-24**

**Keywords:** 多芯片架构, 玻璃中介层, 翘曲, 协同优化, 性能功耗比

**Comment:** Paper accepted at ACM Transactions on Embedded Computing Systems. To
  be presented in Taiwan, Sept. 2025

> **TL;DR:** 本文提出了一种热、翘曲和性能感知的协同设计框架，用于基于玻璃中介层的多芯片架构，以在实现高性能和低功耗的同时解决翘曲问题。

**AI_Comments:** 这项研究通过引入一个协同设计框架来解决玻璃中介层多芯片系统中关键的翘曲问题，展现了其创新性。它不仅关注性能和功耗，还将结构可靠性纳入设计考量，这对于未来大型、高性能集成电路的可靠性至关重要。其在性能提升和功耗降低方面的显著成果，预示了玻璃中介层在高性能计算领域，特别是AI硬件加速方面的巨大潜力。该方法提供了一个全面的解决方案，超越了单一维度的优化。

<details>
  <summary>Details</summary>

**Motivation:** 基于玻璃中介层的多芯片架构虽然在电气性能、总线宽度和互连范围方面具有优势，但随着系统尺寸的增加，封装变形（翘曲）成为一个关键挑战，导致严重的机械应力和可靠性问题。传统封装技术无法有效管理大型系统中的翘曲，因此需要新的方法来缓解翘曲引起的弯曲，同时保持可扩展的性能。

**Method:** 本文提出了一种热、翘曲和性能感知的协同设计框架，该框架采用架构和封装协同优化。该框架将表面和嵌入式芯片分解，以平衡相互冲突的设计目标，确保在性能、功耗和结构可靠性之间实现最佳权衡。

**Result:** 通过该设计框架优化的多芯片架构，在执行深度神经网络工作负载时，与传统2.5D系统相比，性能提升高达64.7%，功耗降低40%，且制造成本更低。

**Conclusion:** 本文提出的协同设计框架能够有效解决基于玻璃中介层的多芯片系统中翘曲导致的可靠性问题，同时显著提升性能并降低功耗和成本，为高性能计算提供了新的解决方案。

> **ai_Abstract:** 本文针对玻璃中介层多芯片架构中日益严重的翘曲问题，提出了一种热、翘曲和性能感知的协同设计框架。该框架通过架构与封装的协同优化，平衡性能、功耗和结构可靠性，有效缓解了大尺寸系统中的翘曲挑战。实验结果表明，该框架优化的多芯片架构在深度神经网络工作负载下，性能提升高达64.7%，功耗降低40%，并降低了制造成本。

> **摘要翻译:** 基于玻璃中介层的多芯片架构提供了卓越的电气性能，由于串扰减少而实现了更高的总线宽度，并且在再分布层中的电容低于当前的硅中介层系统。这些优势带来了更低的每比特能耗、更高的通信频率和更长的互连范围。然而，在基于玻璃中介层的系统中，随着系统尺寸的增加，封装变形（翘曲）成为一个关键挑战，导致严重的机械应力和可靠性问题。超出一定尺寸后，传统封装技术无法有效管理翘曲，因此需要新的方法来缓解翘曲引起的弯曲，同时为基于玻璃中介层的多芯片系统提供可扩展的性能。为了解决这些相互交织的挑战，我们提出了一种热、翘曲和性能感知的协同设计框架，该框架采用架构和封装协同优化。所提出的框架将表面和嵌入式芯片分解，以平衡相互冲突的设计目标，确保在性能、功耗和结构可靠性之间实现最佳权衡。我们的实验表明，通过我们设计框架优化的多芯片架构，与传统的2.5D系统相比，在执行深度神经网络工作负载时，实现了高达64.7%的性能提升和40%的功耗降低，且制造成本更低。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [275] [Sandwich: Separating Prefill-Decode Compilation for Efficient CPU LLM Serving](https://arxiv.org/abs/2507.18454)
> *Sandwich：分离预填充-解码编译以实现高效的CPU LLM服务*

*Juntao Zhao, Jiuru Li, Chuan Wu* | **Category: cs.AR, cs.AI, cs.DC, cs.PL** | **Updated: 2025-05-19**

**Keywords:** CPU LLM服务, 预填充-解码分离, 硬件优化, GEMM核, 吞吐量

**Comment:** 

> **TL;DR:** Sandwich是一种针对CPU LLM服务的引擎，通过分别优化预填充和解码阶段来提高吞吐量并降低延迟，其生成的GEMM核表现优异且调优成本低。

**AI_Comments:** Sandwich的创新在于认识到并解决了LLM推理预填充和解码阶段工作负载差异导致的低效问题。通过针对性地分离和优化这两个阶段，它显著提升了CPU LLM服务的性能和资源效率，使其成为GPU服务的一个更具竞争力的替代方案。其GEMM核的性能和低调优成本也显示了强大的工程实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的CPU LLM服务方案忽略了LLM推理中预填充和解码阶段的工作负载差异，采用静态模型分区和供应商库，导致次优性能。

**Method:** 本文提出了Sandwich，一个以硬件为中心的CPU LLM服务引擎，它为预填充和解码阶段使用不同的执行计划并分别进行优化。

**Result:** Sandwich实现了平均2.01倍的吞吐量提升；单序列服务中，90%的首次生成时间（TTFT）和每输出令牌时间（TPOT）延迟令人满意，且需求降低高达3.40倍；在连续批处理服务中，Goodput显著提升。Sandwich生成的GEMM核优于代表性供应商核和其他动态形状解决方案，性能可与静态编译器媲美，而核调优成本降低了三个数量级。

**Conclusion:** Sandwich通过分离和优化LLM推理的预填充和解码阶段，显著提升了CPU上LLM服务的效率和性能，其生成的GEMM核在性能和调优成本方面均表现出色。

> **ai_Abstract:** Sandwich是一种新型的CPU LLM服务引擎，旨在解决现有CPU方案未区分预填充和解码阶段的低效问题。它通过为这两个阶段设计并分别优化执行计划来提高效率。实验结果表明，Sandwich在吞吐量、延迟和资源需求方面均显著优于现有基线，并且其生成的GEMM核在性能上可与静态编译器媲美，同时大幅降低了调优成本。

> **摘要翻译:** 利用CPU来服务大型语言模型（LLMs）是GPU服务的一种资源友好的替代方案。现有的基于CPU的解决方案忽略了LLM推理的预填充和解码阶段之间的工作负载差异，应用静态的每NUMA（非统一内存访问）节点模型分区并利用供应商库进行操作级别执行，这是次优的。我们提出了Sandwich，一个以硬件为中心的基于CPU的LLM服务引擎，它为预填充和解码阶段使用不同的执行计划并分别进行优化。我们在五个CPU平台（包括带有AVX-2和AVX-512的x86以及带有NEON的ARM）上，对Sandwich在不同基准和数据集上进行了评估。Sandwich实现了平均2.01倍的吞吐量提升，90%的首次生成时间（TTFT）和每输出令牌时间（TPOT）延迟令人满意，单序列服务中的需求降低高达3.40倍，以及在连续批处理服务中Goodput的显著提升。Sandwich生成的GEMM核优于代表性供应商核和其他动态形状解决方案，实现了与静态编译器相当的性能，而核调优成本降低了三个数量级。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [494] [DiP: A Scalable, Energy-Efficient Systolic Array for Matrix Multiplication Acceleration](https://arxiv.org/abs/2412.09709)
> *DiP：一种可扩展、高能效的矩阵乘法加速脉动阵列*

*Ahmed J. Abdelmaksoud, Shady Agwa, Themis Prodromakis* | **Category: cs.AR, cs.DC** | **Updated: 2025-07-24**

**Keywords:** 脉动阵列, 矩阵乘法, DiP, Transformer, 能效

**Comment:** 

> **TL;DR:** DiP是一种新型脉动阵列架构，通过消除FIFO同步并采用新数据流，显著提升矩阵乘法加速的吞吐量和能效，尤其适用于Transformer工作负载。

**AI_Comments:** 这项工作在脉动阵列设计领域具有重要创新。通过提出DiP数据流并成功消除传统的FIFO同步机制，该论文有效解决了现有脉动阵列在吞吐量和能效上的瓶颈。其创新点在于对数据流和架构的重新思考，不仅节省了硬件资源，还显著提升了计算单元的利用率。这对于加速Transformer等日益增长的AI模型具有重要意义，展现了在专用硬件设计方面提升AI计算效率的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** Transformers模型因其卓越的准确性在自然语言处理（NLP）领域受到广泛关注，但其数据密集性对现有计算架构提出了显著的性能需求。现有的脉动阵列架构（如Google TPUs采用的）虽然能效高，但由于通过FIFO缓冲区进行输入输出同步，面临吞吐量和能耗损失。

**Method:** 本文提出了一种名为Diagonal-Input and Permutated weight stationary (DiP) 的新型可扩展脉动阵列架构，用于矩阵乘法加速。该架构通过创新的数据流设计，消除了现有权值固定脉动阵列所需的同步FIFO。研究人员开发了针对权值固定和DiP架构的分析模型，涵盖延迟、吞吐量、PEs完全利用时间(TFPU)和FIFO开销。此外，还使用22nm商用技术进行了全面的硬件设计空间探索。

**Result:** DiP架构通过消除FIFO，实现了面积、功耗和能耗的节省。它最大化了计算资源利用率，比传统权值固定架构的吞吐量提高了高达50%。在能效/面积方面，DiP的可扩展性优势达到了2.02倍的提升。在Transformer工作负载上，DiP优于类TPU架构，能耗改善高达1.81倍，延迟改善高达1.49倍。在64x64尺寸、4096个PEs的配置下，DiP实现了8.192 TOPS的峰值吞吐量和9.548 TOPS/W的能效。

**Conclusion:** DiP架构通过创新的数据流和消除FIFO，显著提升了脉动阵列的吞吐量和能效，特别是在处理Transformer模型所需的矩阵乘法时，展现出优于现有先进架构的性能和能耗优势。

> **ai_Abstract:** 本文提出了一种名为DiP（Diagonal-Input and Permutated weight stationary）的新型可扩展脉动阵列架构，旨在加速矩阵乘法，尤其针对Transformer等数据密集型模型。DiP通过消除传统脉动阵列中用于输入输出同步的FIFO缓冲区，显著降低了面积、功耗和能耗。该架构采用创新的数据流，最大化计算资源利用率，相比传统权值固定架构，吞吐量提升高达50%。实验结果表明，DiP在能效/面积上提升2.02倍，在Transformer工作负载上比类TPU架构能效提升1.81倍，延迟提升1.49倍，且在特定规模下实现了高吞吐量和能效。

> **摘要翻译:** Transformers模型因其卓越的准确性在自然语言处理（NLP）应用领域受到越来越多的关注。然而，这些数据密集型模型对现有计算架构提出了显著的性能要求。脉动阵列架构，如谷歌TPU等商用AI计算平台所采用的，提供了能源效率高的数据重用，但由于通过先进先出（FIFO）缓冲区进行输入输出同步，面临吞吐量和能源损失。本文提出了一种新型可扩展脉动阵列架构，其特点是采用对角输入和置换权重固定（DiP）数据流，用于矩阵乘法加速。所提出的架构消除了现有最先进的权重固定脉动阵阵列所需的同步FIFO。除了通过消除这些FIFO实现的面积、功耗和能源节省外，DiP架构最大化了计算资源利用率，比传统权重固定架构的吞吐量提高了高达50%。本文为权重固定和DiP架构开发了分析模型，包括延迟、吞吐量、PEs完全利用时间（TFPU）和FIFO开销。使用22nm商用技术进行的全面硬件设计空间探索表明了DiP的可扩展性优势，在每面积能效方面实现了高达2.02倍的提升。此外，DiP在来自广泛使用模型的Transformer工作负载上优于类TPU架构，能效改善高达1.81倍，延迟改善高达1.49倍。在64x64尺寸、4096个PEs的配置下，DiP实现了8.192 TOPS的峰值吞吐量和9.548 TOPS/W的能效。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [504] [PRACtical: Subarray-Level Counter Update and Bank-Level Recovery Isolation for Efficient PRAC Rowhammer Mitigation](https://arxiv.org/abs/2507.18581)
> *PRACtical：子阵级计数器更新和存储体级恢复隔离，实现高效PRAC Rowhammer缓解*

*Ravan Nazaraliyev, Saber Ganjisaffar, Nurlan Nazaraliyev, Nael Abu-Ghazaleh* | **Category: cs.AR, cs.ET** | **Updated: 2025-07-24**

**Keywords:** Rowhammer, DRAM, PRAC, 性能优化, 缓解

**Comment:** 

> **TL;DR:** PRACtical通过优化计数器更新和实现存储体级恢复隔离，显著提升了DDR5 PRAC+ABO Rowhammer缓解方案的性能和能效。

**AI_Comments:** 本文提出的PRACtical方法在Rowhammer缓解领域具有重要创新。其核心贡献在于两点：一是通过集中式增量电路实现子阵级计数器更新的性能优化，允许操作重叠；二是通过引入DRAM驻留寄存器实现存储体级的恢复隔离，有效避免了传统方法中整个内存通道停顿的问题。这些改进显著提升了DRAM的性能和能效，同时维护了Rowhammer保护，对实际系统应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着DRAM密度增加，Rowhammer问题日益严重。DDR5的PRAC+ABO机制虽然能缓解此威胁，但存在性能开销：计数器更新增加延迟，且恢复刷新会暂停整个内存通道，即使只有部分存储体受攻击。

**Method:** 提出PRACtical。首先，通过引入集中式增量电路减少计数器更新延迟，并允许计数器更新与同一DRAM芯片中其他子阵的后续行激活重叠。其次，通过DRAM驻留寄存器识别受攻击的存储体，实现存储体级别的恢复隔离，仅暂停受影响的存储体而非整个通道。

**Result:** PRACtical使性能平均提升8%（最高达20%），能耗降低19%，并能将激进性能攻击造成的性能下降限制在6%以内，同时保持Rowhammer保护。

**Conclusion:** PRACtical在保持Rowhammer保护的同时，显著提升了现有PRAC+ABO缓解方案的性能和能效。

> **ai_Abstract:** PRACtical是一种性能优化的Rowhammer缓解方法，旨在解决DDR5标准中PRAC+ABO机制的性能开销。它通过引入集中式增量电路来减少计数器更新延迟并允许操作重叠，并通过实现存储体级别的恢复隔离来避免整个内存通道的停顿。该方法在保持Rowhammer保护的同时，显著提升了性能和能效。

> **摘要翻译:** 随着DRAM密度的增加，Rowhammer问题变得更加严重，这是因为电荷泄漏加剧，导致诱发位翻转所需的激活次数减少。DDR5标准通过DRAM内部的每行激活计数器（PRAC）和警报退避（ABO）信号来触发缓解措施，以应对此威胁。然而，PRAC在预充电阶段增加计数器会带来性能开销，并且恢复刷新会暂停整个内存通道，即使只有一个存储体受到攻击。
我们提出了PRACtical，这是一种性能优化的PRAC+ABO方法，它保持了相同的安全保障。首先，我们通过引入一个集中式增量电路来减少计数器更新延迟，从而使计数器更新能够与同一DRAM芯片中其他子阵的后续行激活重叠。其次，我们通过实现存储体级别的粒度来增强$RFM_{ab}$缓解：不再暂停整个通道，而只暂停受影响的存储体。这是通过一个识别受攻击存储体的DRAM驻留寄存器实现的。
PRACtical的性能比现有技术平均提升8%（最高达20%），能耗降低19%，并将激进性能攻击造成的性能下降限制在6%以下，同时保持了Rowhammer保护。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [540] [GNN-ACLP: Graph Neural Networks Based Analog Circuit Link Prediction](https://arxiv.org/abs/2504.10240)
> *GNN-ACLP：基于图神经网络的模拟电路链路预测*

*Guanyuan Pan, Tiansheng Zhou, Bingtao Ma, Yaqi Wang, Jianxiang Zhao, Zhi Li, Yugui Lin, Pietro Lio, Shuai Wang* | **Category: cs.AR, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 图神经网络, 模拟电路, 链路预测, 网表转换, SpiceNetlist

**Comment:** Code and data will be made available on request to the corresponding
  author. V4 Update: Add Future Work; Improve Typesetting

> **TL;DR:** GNN-ACLP是一种基于图神经网络的模拟电路链路预测方法，通过引入SEAL框架、Netlist Babel Fish工具和SpiceNetlist数据集，解决了现有方法在拓扑模式利用、数据稀缺和格式兼容性方面的挑战，显著提高了预测精度和泛化能力。

**AI_Comments:** 这篇论文的创新点在于结合了图神经网络与模拟电路链路预测问题，并针对现有挑战提出了多方面的解决方案。SEAL框架的引入提升了预测精度，而Netlist Babel Fish工具利用LLM和RAG解决网表格式兼容性问题，这在电路设计自动化领域是一个新颖且实用的结合。此外，构建新的大规模数据集也为后续研究提供了宝贵的资源。该研究对于推动模拟电路设计自动化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在模拟电路设计自动化中，从不完整的网表中识别缺失的元件连接（电路链路预测）至关重要。然而，现有方法面临三大挑战：1) 未能充分利用电路图中的拓扑模式，导致预测精度降低；2) 由于注释复杂性导致数据稀缺，影响模型泛化能力；3) 对各种网表格式的适应性有限。

**Method:** 本文提出GNN-ACLP，一种基于图神经网络（GNNs）的方法，通过三项创新解决现有挑战：1) 引入SEAL（从子图、嵌入和属性中学习进行链路预测）框架，实现端口级精度；2) 提出Netlist Babel Fish，一个利用检索增强生成（RAG）和大型语言模型（LLM）的网表格式转换工具，以提高网表格式兼容性；3) 构建SpiceNetlist，一个包含775个带注释电路的综合数据集。

**Result:** 实验结果显示，在数据集内评估中，GNN-ACLP在SpiceNetlist上精度提高了16.08%，在Image2Net上提高了11.38%，在Masala-CHAI上提高了16.01%，均优于基线。在跨数据集评估中，精度保持在92.05%至99.07%，展现出强大的特征迁移能力。

**Conclusion:** GNN-ACLP通过创新的框架、工具和数据集构建，显著提升了模拟电路链路预测的精度和泛化能力，有效解决了现有方法在拓扑模式利用不足、数据稀缺和网表格式兼容性方面的关键挑战。

> **ai_Abstract:** GNN-ACLP是一种基于图神经网络的模拟电路链路预测方法，旨在解决现有方法在拓扑模式利用、数据稀缺和网表格式兼容性方面的不足。该方法通过引入SEAL框架实现端口级精度，提出Netlist Babel Fish工具提升格式兼容性，并构建了大规模SpiceNetlist数据集。实验证明GNN-ACLP显著提高了预测精度，并在跨数据集评估中展现出优异的泛化能力。

> **摘要翻译:** 电路链路预测，即从不完整的网表中识别缺失的元件连接，在模拟电路设计自动化中至关重要。然而，现有方法面临三个主要挑战：1）电路图中拓扑模式利用不足，降低了预测精度；2）由于注释的复杂性导致数据稀缺，阻碍了模型的泛化；3）对各种网表格式的适应性有限。我们提出了GNN-ACLP，一种基于图神经网络（GNNs）的方法，其具有三项创新来解决这些挑战。首先，我们引入了SEAL（从子图、嵌入和属性中学习进行链路预测）框架，并在电路链路预测中实现了端口级精度。其次，我们提出了Netlist Babel Fish，一个利用检索增强生成（RAG）和大型语言模型（LLM）的网表格式转换工具，以提高网表格式的兼容性。最后，我们构建了SpiceNetlist，一个包含10种不同元件类别、775个带注释电路的综合数据集。实验表明，与基线相比，在数据集内评估中，SpiceNetlist上的精度提高了16.08%，Image2Net上提高了11.38%，Masala-CHAI上提高了16.01%，同时在跨数据集评估中精度保持在92.05%至99.07%，展现出强大的特征迁移能力。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [588] [The New LLM Bottleneck: A Systems Perspective on Latent Attention and Mixture-of-Experts](https://arxiv.org/abs/2507.15465)
> *新的LLM瓶颈：潜注意力与专家混合的系统视角*

*Sungmin Yun, Seonyong Park, Hwayong Nam, Younjoo Lee, Gunjun Lee, Kwanhee Kyung, Sangpyo Kim, Nam Sung Kim, Jongmin Kim, Hyungyo Kim, Juhwan Cho, Seungmin Baek, Jung Ho Ahn* | **Category: cs.AR, cs.AI** | **Updated: 2025-07-23**

**Keywords:** LLM瓶颈, 潜注意力, 专家混合, 系统设计, 算术强度

**Comment:** 15 pages, 11 figures

> **TL;DR:** 本文认为，多头潜注意力（MLA）和专家混合（MoE）等新型Transformer架构改变了传统注意力瓶颈的性质，降低了对专用注意力硬件的需求，并将挑战转移到设计均衡的系统。

**AI_Comments:** 本文提出了对LLM性能瓶颈的全新视角，指出随着MLA和MoE等架构的兴起，传统的注意力内存瓶颈已不再是主要挑战。其创新之处在于将重点从单一组件的优化转移到整个系统层面的平衡设计，这对于未来大规模AI模型的硬件和系统协同设计具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统Transformer模型中多头注意力（MHA）的内存瓶颈长期以来推动了专用硬件的研究。然而，本文认为，多头潜注意力（MLA）和专家混合（MoE）等近期架构转变挑战了专用注意力硬件的前提，因此需要重新审视LLM的瓶颈。

**Method:** 本文通过两项关键观察来论证其观点：一是多头潜注意力（MLA）的算术强度比MHA高出两个数量级，使其接近计算密集型，适合现代加速器；二是专家混合（MoE）通过批处理可以将算术强度调整至与密集层匹配，从而创建更平衡的计算配置文件。

**Result:** 研究发现，多头潜注意力（MLA）的算术强度显著提高，使其接近计算密集型，适合通用GPU。同时，专家混合（MoE）的算术强度可以通过批处理进行调整，以匹配密集层，从而实现更平衡的计算负载。

**Conclusion:** 结论是，对专用注意力硬件的需求正在减少。下一代Transformer的核心挑战不再是加速单一的内存密集型层，而是需要设计具有足够计算能力、内存容量、内存带宽和高带宽互连的均衡系统，以管理大规模模型的多样化需求。

> **ai_Abstract:** 本文探讨了大型语言模型（LLM）中新的计算瓶颈。研究指出，传统Transformer模型中多头注意力（MHA）的内存瓶颈已因多头潜注意力（MLA）和专家混合（MoE）等新型架构而发生改变。MLA的算术强度显著提高，使其更适合通用GPU，而MoE可以通过批处理实现计算平衡。这些发现表明，专用注意力硬件的需求正在减少，未来LLM的优化重点应转向设计具备均衡计算、内存和互连能力的整体系统。

> **摘要翻译:** 传统Transformer模型中的计算工作负载截然二分。多头注意力（MHA）是内存密集型的，算术强度低，而前馈层是计算密集型的。这种二分法长期以来推动了对专用硬件的研究，以缓解MHA瓶颈。
本文认为，近期架构转变，即多头潜注意力（MLA）和专家混合（MoE），挑战了专用注意力硬件的前提。我们提出了两个关键观察。首先，MLA的算术强度比MHA高出两个数量级以上，使其接近计算密集型，非常适合现代加速器如GPU。其次，通过将MoE专家分布在一组加速器上，可以通过批处理调整其算术强度，以匹配密集层，从而创建更平衡的计算配置文件。
这些发现揭示了对专用注意力硬件需求的减少。下一代Transformer的核心挑战不再是加速单一的内存密集型层。相反，重点必须转移到设计具有足够计算、内存容量、内存带宽和高带宽互连的均衡系统，以管理大规模模型的多样化需求。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [615] [RailX: A Flexible, Scalable, and Low-Cost Network Architecture for Hyper-Scale LLM Training Systems](https://arxiv.org/abs/2507.18889)
> *RailX：一种面向超大规模LLM训练系统的灵活、可扩展、低成本网络架构*

*Yinxiao Feng, Tiancheng Chen, Yuchen Wei, Siyuan Shen, Shiju Wang, Wei Li, Kaisheng Ma, Torsten Hoefler* | **Category: cs.AR, cs.DC, cs.NI** | **Updated: 2025-07-25**

**Keywords:** RailX, 超大规模LLM训练, 网络架构, 电路交换, 哈密顿分解

**Comment:** 25 pages, 21 figures, 6 tables

> **TL;DR:** RailX提出了一种基于节点内直连和节点间电路交换的可重构网络架构，旨在为超大规模LLM训练提供灵活、可扩展且低成本的解决方案。

**AI_Comments:** RailX的创新之处在于其结合了节点内直连和节点间电路交换的混合架构，并通过2D物理组织和哈密顿分解理论实现了前所未有的可扩展性和成本效益。它解决了超大规模AI训练中网络瓶颈的核心问题，特别是其在成本上的显著优势对未来大型模型训练基础设施的建设具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有互连网络架构（如树形拓扑和直接拓扑）在可扩展性、成本效益、双向带宽和灵活性方面无法满足日益增长的超大规模AI工作负载需求。

**Method:** 本文提出了RailX，一种基于节点内直连和节点间电路交换的可重构网络架构。它将节点和光交换机进行物理2D组织，并通过基于哈密顿分解理论的新型互连方法，将独立的基于轨道的环组织成全连接拓扑，同时优化环内集合通信和全连接通信。

**Result:** RailX能够互连超过10万个芯片，具有超高带宽，直径仅为2~4个节点间跳数。RailX的每注入/All-Reduce带宽成本低于Fat-Tree的10%，每双向/All-to-All带宽成本低于Fat-Tree的50%。具体而言，互连20万个芯片（1.8TB带宽）仅需约13亿美元。RailX还可应用于ML-as-a-service（MLaaS）场景，灵活映射不同形状、规模和并行策略的训练工作负载，并能应对故障。

**Conclusion:** RailX作为一种灵活、可扩展且低成本的网络架构，为超大规模LLM训练系统提供了高性能的互连解决方案，显著降低了成本并增强了灵活性和故障处理能力。

> **ai_Abstract:** 本文提出RailX，一种为超大规模LLM训练系统设计的新型可重构网络架构。针对传统网络在可扩展性、成本和带宽上的局限，RailX通过节点内直连、节点间电路交换和2D物理组织实现高扩展性。其基于哈密顿分解的互连方法优化了集体通信和全连接通信。实验结果表明，RailX能以极低的成本互连大量芯片，提供高带宽，并在MLaaS场景中展现出灵活性和故障容忍能力。

> **摘要翻译:** 日益增长的AI工作负载需要超大规模基础设施；然而，传统的互连网络架构既不具备足够的扩展性，也不够成本效益。树形拓扑，如Rail-optimized网络，成本极其昂贵，而直接拓扑，如Torus，则双向带宽和灵活性不足。在本文中，我们提出了RailX，一种基于节点内直连和节点间电路交换的可重构网络架构。节点和光交换机进行物理2D组织，比现有集中式电路交换网络实现了更好的可扩展性。我们提出了一种基于哈密顿分解理论的新型互连方法，将独立的基于轨道的环组织成全连接拓扑，同时优化环内集合通信和全连接通信。超过10万个具有超高带宽的芯片可以通过一个扁平的交换层互连，并且直径仅为2~4个节点间跳数。RailX的每注入/All-Reduce带宽成本低于Fat-Tree的10%，每双向/All-to-All带宽成本低于Fat-Tree的50%。具体而言，互连20万个芯片（1.8TB带宽）仅需约13亿美元。RailX还可用于ML-as-a-service（MLaaS）场景，其中可以灵活映射具有各种形状、规模和并行策略的单个或多个训练工作负载，并且可以规避故障。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [770] [Clo-HDnn: A 4.66 TFLOPS/W and 3.78 TOPS/W Continual On-Device Learning Accelerator with Energy-efficient Hyperdimensional Computing via Progressive Search](https://arxiv.org/abs/2507.17953)
> *Clo-HDnn：一种通过渐进式搜索实现能效超维计算的4.66 TFLOPS/W和3.78 TOPS/W持续在设备学习加速器*

*Chang Eun Song, Weihong Xu, Keming Fan, Soumil Jain, Gopabandhu Hota, Haichao Yang, Leo Liu, Kerem Akarvardar, Meng-Fan Chang, Carlos H. Diaz, Gert Cauwenberghs, Tajana Rosing, Mingu Kang* | **Category: cs.AR, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 持续学习, 片上学习, 超维计算, 能效, 加速器

**Comment:** Published in 2025 Symposium on VLSI Technology and Circuits (VLSI
  Technology and Circuits), Kyoto, Japan, 2025

> **TL;DR:** Clo-HDnn是一种能效高的片上持续学习加速器，通过超维计算和渐进式搜索实现高能效。

**AI_Comments:** 该论文通过将超维计算与特定的架构和算法优化相结合，为片上持续学习提出了一种创新方法。所展示的高能效（高达7.77倍的提升）是一个重要的贡献，解决了边缘人工智能面临的关键挑战。无梯度持续学习和用于降低复杂性的渐进式搜索是显著的创新点。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是为新兴的持续学习（CL）任务设计一种片上学习（ODL）加速器。

**Method:** Clo-HDnn集成了超维计算（HDC）、低成本Kronecker HD编码器和权重聚类特征提取（WCFE）。它采用无梯度持续学习，支持双模式操作，并通过渐进式搜索来降低复杂性。

**Result:** Clo-HDnn实现了4.66 TFLOPS/W（特征提取）和3.78 TOPS/W（分类器）的能效，将复杂性降低了高达61%，并且与现有最先进的片上学习加速器相比，能效分别提高了7.77倍和4.85倍。

**Conclusion:** Clo-HDnn通过优化超维计算，有效解决了持续在设备学习的能效和复杂性挑战。

> **ai_Abstract:** Clo-HDnn是一种针对持续学习的片上加速器。它利用超维计算，并结合了Kronecker HD编码器、WCFE、无梯度持续学习、双模式操作和渐进式搜索等优化技术，实现了高能效（4.66 TFLOPS/W和3.78 TOPS/W）和降低的复杂性，性能优于现有最先进的加速器。

> **摘要翻译:** Clo-HDnn是一种为新兴的持续学习（CL）任务设计的片上学习（ODL）加速器。Clo-HDnn集成了超维计算（HDC）以及低成本的Kronecker HD编码器和权重聚类特征提取（WCFE），以优化准确性和效率。Clo-HDnn采用无梯度持续学习，以类超向量的形式高效更新和存储学习到的知识。其双模式操作能够针对更简单的数据集绕过昂贵的特征提取，而渐进式搜索通过仅编码和比较部分查询超向量，将复杂性降低了高达61%。Clo-HDnn实现了4.66 TFLOPS/W（特征提取）和3.78 TOPS/W（分类器）的能效，与现有最先进的片上学习加速器相比，能效分别提高了7.77倍和4.85倍。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [226] [Caching Techniques for Reducing the Communication Cost of Federated Learning in IoT Environments](https://arxiv.org/abs/2507.17772)
> *物联网环境中联邦学习通信成本降低的缓存技术*

*Ahmad Alhonainy, Praveen Rao* | **Category: cs.DC, cs.AI, cs.CV, cs.LG** | **Updated: 2025-07-19**

**Keywords:** 联邦学习, 物联网, 缓存技术, 通信成本, 边缘计算

**Comment:** Journal

> **TL;DR:** 本文提出了FIFO、LRU和基于优先级的缓存策略，以减少联邦学习在物联网环境中的通信成本，同时保持模型精度。

**AI_Comments:** 该论文通过引入缓存机制，为联邦学习在资源受限的物联网环境中部署提供了实用的解决方案。其创新点在于将传统缓存策略应用于联邦学习的模型更新传输，有效地权衡了通信效率与模型精度。这对于推动联邦学习在边缘计算和IoT应用中的实际落地具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习在分布式设备间协同训练模型时，通信成本是主要瓶颈，尤其是在资源受限的环境中。

**Method:** 本文引入了FIFO、LRU和优先级缓存策略，通过选择性地转发重要的模型更新来减少不必要的传输。

**Result:** 在CIFAR-10和医疗数据集上的实验表明，通信量减少，同时准确性损失最小。结果证实，智能缓存提高了可伸缩性、内存效率，并支持边缘物联网网络中可靠的联邦学习。

**Conclusion:** 智能缓存技术能够有效降低联邦学习在物联网环境中的通信成本，同时保持模型精度，使其适用于智能城市、医疗保健等延迟敏感的应用。

> **ai_Abstract:** 本文提出了一系列缓存策略（FIFO、LRU、优先级）来解决联邦学习在物联网环境中面临的通信成本瓶颈。通过选择性地传输关键模型更新，这些策略旨在减少带宽消耗，同时保持模型性能。实验结果证明，该方法在降低通信量的同时，对模型准确性的影响极小，从而提升了联邦学习在资源受限边缘设备上的可扩展性和部署可行性。

> **摘要翻译:** 联邦学习（FL）允许多个分布式设备在不集中数据的情况下共同训练一个共享模型，但通信成本仍然是一个主要瓶颈，尤其是在资源受限的环境中。本文介绍了缓存策略——FIFO、LRU和基于优先级的——以减少不必要的模型更新传输。通过选择性地转发重要更新，我们的方法降低了带宽使用，同时保持了模型精度。在CIFAR-10和医疗数据集上的实验表明，通信量减少，同时准确性损失最小。结果证实，智能缓存提高了可伸缩性、内存效率，并支持边缘物联网网络中可靠的联邦学习，使其在智能城市、医疗保健和其他延迟敏感应用中具有实际部署价值。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [340] [Incentivised Orchestrated Training Architecture (IOTA): A Technical Primer for Release](https://arxiv.org/abs/2507.17766)
> *激励式协调训练架构 (IOTA)：发布技术入门*

*Felix Quinque, Alan Aboudib, Szymon Fonau, Rodrigo Lopez Portillo Alcocer, Brian McCrindle, Steffen Cruz* | **Category: cs.DC, cs.LG** | **Updated: 2025-07-16**

**Keywords:** 去中心化训练, 大型语言模型, 激励机制, 协作训练,  Bittensor

**Comment:** 

> **TL;DR:** IOTA 是一种新的去中心化大型语言模型训练架构，通过将矿工转化为协作单元，解决了传统去中心化训练中模型本地适应和“赢者通吃”奖励的问题，实现了任意规模扩展并公平奖励贡献者。

**AI_Comments:** IOTA的创新之处在于其将去中心化训练中的竞争者转化为协作单元，并通过多项技术突破解决了现有痛点。数据和管道并行SWARM架构、激活压缩、Butterfly All-Reduce以及CLASP机制共同构建了一个高度可扩展、高效且公平的分布式训练系统。这对于推动大型模型在资源受限环境下的协同训练具有重要意义，尤其是在区块链和去中心化AI领域。

<details>
  <summary>Details</summary>

**Motivation:** Bittensor 的 Subnet 9 (SN9) 证明了去中心化预训练的可行性，但存在核心问题：每个矿工必须在本地适应整个模型，以及“赢者通吃”的奖励机制鼓励模型囤积。

**Method:** 本文引入了激励式协调训练架构 (IOTA)，通过将SN9中先前孤立的竞争者转变为一个协作单元来解决这些限制。IOTA的关键初步结果包括：(1) 数据和管道并行SWARM架构：协调器将模型层分发给异构矿工并在它们之间传输激活，使模型大小能随参与者数量扩展；(2) 粒度化、连续激励：验证者衡量每个矿工的贡献并按比例分配代币排放；(3) 激活压缩：使用模型瓶颈将激活的通信带宽减少高达128倍，大大提高训练速度；(4) Butterfly All-Reduce：矿工以O(1)带宽平均不相交的参数切片，提供线性可扩展性、冗余和内置的串通检测；(5) CLASP (通过路径采样进行贡献损失评估)：一种公平归因方案，根据边际效用按比例分配贡献，并检测漏洞。

**Result:** IOTA实现了将先前孤立的竞争者转化为单一协作单元，能够任意扩展并公平奖励每个贡献者。具体成果包括：模型大小能够随参与者数量扩展，而非受限于单台机器的VRAM；验证者能按比例分配代币奖励；激活通信带宽减少高达128倍，大大提高了训练速度；实现了线性可扩展性、冗余和内置串通检测的参数平均；以及公平的贡献归因和漏洞检测。

**Conclusion:** IOTA通过引入协作式训练架构，成功解决了去中心化大型语言模型预训练中模型本地适应性限制和不公平奖励机制的问题，实现了高效、可扩展且公平的分布式训练。

> **ai_Abstract:** 本文提出了激励式协调训练架构 (IOTA)，旨在解决当前去中心化大型语言模型 (LLM) 预训练中的两大挑战：矿工需本地适应完整模型和“赢者通吃”的奖励机制。IOTA 将独立的贡献者转变为一个协作单元，通过数据和管道并行SWARM架构实现模型规模随参与者数量扩展，而非受限于单机VRAM。它引入了粒度化、连续激励机制以公平分配奖励，利用激活压缩技术显著提升训练速度，并通过Butterfly All-Reduce实现高效且具有冗余的参数平均。此外，CLASP机制确保了贡献的公平归因和漏洞检测。IOTA为可扩展、高效且公平的去中心化LLM训练提供了一个新范式。

> **摘要翻译:** 2024年8月，Bittensor的子网9（SN9）证明了一个由激励的、无需许可的参与者组成的分布式网络可以各自预训练从7亿到140亿参数不等的大型语言模型（LLMs），同时超越了既定基线。虽然这项工作验证了基于区块链的去中心化预训练是可行的，但它存在核心问题：(i) 每个矿工都必须在本地适应整个模型，以及 (ii) “赢者通吃”的奖励机制鼓励模型囤积。
本文介绍了IOTA（激励式协调训练架构），这是一种通过将SN9中先前孤立的竞争者转变为一个可以任意扩展同时仍公平奖励每个贡献者的单一协作单元来解决这些限制的架构。
关键初步成果包括：(1) 数据和管道并行SWARM架构——协调器将模型层分发给异构矿工并在它们之间传输激活，使模型大小能随参与者数量扩展，而不是受限于单台机器的显存；(2) 粒度化、连续激励——验证者衡量每个矿工的贡献并按比例分配代币排放；(3) 激活压缩——我们使用模型瓶颈将激活的通信带宽减少高达128倍，大大提高了训练速度；(4) Butterfly All-Reduce——矿工以O(1)带宽平均不相交的参数切片，提供线性可扩展性、冗余和内置的串通检测；(5) CLASP（通过路径采样进行贡献损失评估）——一种公平归因方案，即使贡献在管道中相互依赖，也能根据矿工的边际效用按比例分配信用并检测漏洞。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [380] [MultiKernelBench: A Multi-Platform Benchmark for Kernel Generation](https://arxiv.org/abs/2507.17773)
> *MultiKernelBench：一个多平台核函数生成基准测试*

*Zhongzhen Wen, Yinghui Zhang, Zhong Li, Zhongxin Liu, Linna Xie, Tian Zhang* | **Category: cs.DC, cs.LG, cs.PF, cs.SE** | **Updated: 2025-07-20**

**Keywords:** 深度学习核函数生成, 大型语言模型, 基准测试, 多平台, MultiKernelBench

**Comment:** 

> **TL;DR:** MultiKernelBench是一个用于评估基于LLM的深度学习核函数生成的综合性多平台基准测试，旨在解决现有基准测试的局限性，并揭示了LLM在不同硬件平台上的生成能力和泛化挑战。

**AI_Comments:** MultiKernelBench的创新之处在于其作为首个综合性、多平台基准测试，显著扩展了对LLM在DL核函数生成领域评估的广度和深度。其模块化设计确保了未来的可扩展性，而提出的类别感知提示方法则为提升生成质量提供了实用策略。该工作对于推动LLM在高性能计算领域的应用具有重要意义，并为后续研究提供了宝贵的评估工具和洞察。

<details>
  <summary>Details</summary>

**Motivation:** 现有的用于评估大型语言模型（LLMs）在深度学习（DL）核函数自动生成方面表现的基准测试存在局限性，包括硬件支持有限、核函数分类粒度粗糙以及任务覆盖不平衡。

**Method:** 本文引入了MultiKernelBench，这是首个针对基于LLM的DL核函数生成的综合性多平台基准测试。它涵盖14个明确定义的核函数类别的285项任务，并支持Nvidia GPU、华为NPU和Google TPU三种主要硬件平台。为实现未来的可扩展性，设计了一个模块化的后端抽象层。此外，还提出了一种简单有效的类别感知一次性提示方法，通过提供类别内示例来提高生成质量。

**Result:** 通过对七个最先进的LLM进行系统评估，研究揭示了任务难度的显著差异、对训练暴露较少的平台泛化能力差的问题，以及目标提示策略的有效性。

**Conclusion:** 研究结果表明，在基于LLM的深度学习核函数生成领域，存在任务难度差异大、模型泛化能力不足的问题，但通过有针对性的提示策略可以有效提升生成质量。

> **ai_Abstract:** 本文介绍了MultiKernelBench，一个针对基于大型语言模型（LLM）的深度学习核函数生成的综合性多平台基准测试。它旨在解决现有基准测试硬件支持有限、分类粗糙和任务覆盖不平衡的缺点。MultiKernelBench涵盖285项任务，分为14个核函数类别，并支持Nvidia GPU、华为NPU和Google TPU。该基准测试采用模块化设计以实现可扩展性，并提出了一种类别感知的一次性提示方法来提高生成质量。对七个SOTA LLM的评估揭示了任务难度差异、泛化能力弱以及提示策略的有效性。

> **摘要翻译:** 使用大型语言模型（LLMs）自动生成深度学习（DL）核函数已成为一种有前景的方法，可减少编写高性能操作符实现所需的人工工作和特定硬件专业知识。然而，现有用于评估此领域LLM的基准测试存在硬件支持有限、核函数分类粒度粗糙以及任务覆盖不平衡的问题。为了解决这些局限性，我们引入了MultiKernelBench，这是首个针对基于LLM的DL核函数生成的综合性、多平台基准测试。MultiKernelBench涵盖14个明确定义的核函数类别的285项任务，并支持三种主要硬件平台：Nvidia GPU、华为NPU和Google TPU。为了实现未来的可扩展性，我们设计了一个模块化的后端抽象层，将平台特定逻辑与核心基准测试基础设施解耦，从而方便地集成新的硬件平台。我们进一步提出了一种简单而有效的类别感知一次性提示方法，通过提供类别内示例来提高生成质量。通过对七个最先进的LLM进行系统评估，我们揭示了任务难度的显著差异、对训练暴露较少的平台泛化能力差的问题，以及目标提示策略的有效性。MultiKernelBench已在https://github.com/wzzll123/MultiKernelBench 公开可用。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [396] [PolyServe: Efficient Multi-SLO Serving at Scale](https://arxiv.org/abs/2507.17769)
> *PolyServe：大规模高效多SLO服务*

*Kan Zhu, Haiyang Shi, Le Xu, Jiaxin Shan, Arvind Krishnamurthy, Baris Kasikci, Liguang Xie* | **Category: cs.DC, cs.LG** | **Updated: 2025-07-17**

**Keywords:** LLM服务, 多SLO调度, 延迟敏感, 吞吐量优化, 尾部延迟

**Comment:** 

> **TL;DR:** PolyServe 是一种新颖的多SLO调度策略，旨在解决大规模LLM服务中多样化延迟要求带来的挑战，通过分组、智能路由和资源共享，在保持高SLO达成的同时最大化吞吐量。

**AI_Comments:** PolyServe 的创新之处在于其对多SLO请求的细粒度处理，超越了传统的LS/BE分类。其通过创建负载梯度以促进自动扩缩，以及允许宽松SLO请求共享资源以提高利用率的方法，是其设计亮点。此外，对尾部延迟的精确控制也提升了用户体验。该方法在LLM大规模部署中具有重要意义，能够显著提升服务效率和用户满意度。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）应用的兴起导致了对多样化令牌生成延迟要求的出现。简单地将工作负载分类为延迟敏感（LS）或尽力而为（BE）会忽略延迟敏感类别中的细微差别，并导致次优的用户体验和调度机会。现有系统主要关注处理整体请求速率的自动扩缩，而SLO的多样性需要更细粒度的自动扩缩。此外，不同延迟敏感SLO的请求不能容忍长时间延迟，尾部延迟必须得到控制。

**Method:** PolyServe 是一种新颖的大规模多SLO调度策略，旨在保持高SLO达成率并最大化吞吐量。它首先根据每个令牌的延迟要求将请求分组到多个桶中，然后将每个桶调度到服务器集群的子集。PolyServe 将请求路由到负载最高但仍能达成SLO的服务器，以创建有利于自动扩缩的负载梯度。为了提高利用率，当宽松SLO请求的服务器饱和时，PolyServe 允许它们共享更严格SLO的实例。PolyServe 利用分析数据指导调度决策，并通过请求等待时间感知调度、动态分块和连续分块预填充预测来管理尾部延迟。

**Result:** PolyServe 与现有策略相比，实现了1.23倍的良好吞吐量增益，达到最佳良好吞吐量的92.5%。

**Conclusion:** PolyServe 有效解决了大规模LLM服务中多SLO请求的调度挑战，显著提高了吞吐量和SLO达成率。

> **ai_Abstract:** PolyServe 是一种针对大规模LLM服务提出的创新性多SLO调度策略。它通过根据每令牌延迟要求对请求进行分组，并智能地将它们路由到负载最高但仍能满足SLO的服务器来创建负载梯度，从而促进自动扩缩。为提高资源利用率，PolyServe 允许宽松SLO的请求在自身服务器饱和时共享更严格SLO的实例。该系统利用分析数据，并通过请求等待时间感知调度、动态分块和连续分块预填充预测来有效管理尾部延迟。实验结果表明，PolyServe 实现了1.23倍的良好吞吐量增益，接近最优性能的92.5%。

> **摘要翻译:** 大型语言模型（LLM）的进步导致了LLM驱动应用程序的激增。这些应用程序具有多样化的令牌生成延迟要求。因此，简单地将工作负载分类为延迟敏感（LS）或尽力而为（BE）会忽略延迟敏感类别中的细微差别，并导致次优的用户体验和调度机会。然而，高效地服务具有多个SLO要求的请求带来了重大挑战。首先，批处理中的所有请求同时生成新令牌，这可能使其与不同的SLO要求不匹配。此外，尽管现有系统专注于自动扩缩以处理各种整体请求速率，但SLO的多样性需要这些SLO层之间进行细粒度的自动扩缩。最后，与LS/BE场景不同（其中BE请求可以随时中止以确保LS请求的SLO达成），具有不同延迟敏感SLO的请求不能容忍长时间延迟，并且必须控制尾部延迟。
为了应对这些挑战，我们提出了PolyServe，一种新颖的大规模多SLO调度策略，旨在保持高SLO达成率并最大化吞吐量。PolyServe 首先根据每个令牌的延迟要求将请求分组到多个桶中，然后将每个桶调度到服务器集群的子集。PolyServe 将请求路由到负载最高但仍能达成SLO的服务器，以创建有利于自动扩缩的负载梯度。为了提高利用率，当宽松SLO请求的服务器饱和时，PolyServe 允许它们共享更严格SLO的实例。PolyServe 利用分析数据指导调度决策，并通过请求等待时间感知调度、动态分块和连续分块预填充预测来管理尾部延迟。PolyServe 与现有策略相比，实现了1.23倍的良好吞吐量增益，达到最佳良好吞吐量的92.5%。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [423] [CUTHERMO: Understanding GPU Memory Inefficiencies with Heat Map Profiling](https://arxiv.org/abs/2507.18729)
> *CUTHERMO：通过热图分析理解GPU内存低效率*

*Yanbo Zhao, Jinku Cui, Zecheng Li, Shuyin Jiao, Xu Liu, Jiajia Li* | **Category: cs.DC, cs.PF** | **Updated: 2025-07-24**

**Keywords:** GPU内存分析, 热图分析, 性能优化, cuThermo, 内存低效率

**Comment:** 

> **TL;DR:** cuThermo是一个轻量级GPU内存分析工具，通过热图识别运行时内存低效率并提供优化指导，实现了显著的性能提升。

**AI_Comments:** cuThermo的创新之处在于其无需修改源代码即可进行细粒度GPU内存分析的能力，这大大降低了使用门槛。通过热图可视化内存访问模式并提供优化指导，使得开发者能够更直观地理解和解决GPU内存瓶颈。高达721.79%的性能提升证明了其在实际应用中的巨大潜力。该工具对于提升GPU应用程序的性能和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** GPU在高性能计算和机器学习中不可或缺，但其内存子系统的有效利用面临挑战，因为缺乏全面的运行时和细粒度内存分析支持，导致难以理解内存瓶颈。

**Method:** 本文引入了cuThermo，一个轻量级且实用的GPU内存分析工具。它无需修改硬件、操作系统或应用程序源代码，即可在GPU二进制文件上运行。cuThermo通过基于不同访问的warp计数生成热图，在运行时识别字扇区级别的数据共享导致的内存低效率，并提供性能调优指导。

**Result:** 通过对六个应用程序的实验，cuThermo识别出五种可在不同GPU架构上移植的内存访问模式。通过在两个GPU上评估优化效果，cuThermo实现了高达721.79%的性能提升。

**Conclusion:** cuThermo是一个有效的GPU内存分析工具，能够识别内存低效率并提供优化指导，从而显著提高GPU应用程序的性能。

> **ai_Abstract:** 本文提出了cuThermo，一个轻量级且实用的GPU内存分析工具，旨在解决当前GPU架构中运行时和细粒度内存分析支持的不足。cuThermo无需修改源代码即可在GPU二进制文件上运行，并通过热图（基于不同的访问warp计数）识别字扇区级别的内存低效率，从而提供优化指导。实验表明，该工具能够识别跨GPU架构可移植的内存访问模式，并在优化后实现显著的性能提升，最高可达721.79%。

> **摘要翻译:** GPU已成为高性能计算、机器学习和许多其他领域不可或缺的一部分。有效利用GPU上的内存子系统对于通过大规模并行化最大化计算能力至关重要。分析内存访问模式已被证明是理解应用程序中内存瓶颈的有效方法。然而，GPU架构上缺乏全面的运行时和细粒度内存分析支持。在这项工作中，我们引入了cuThermo，一个用于GPU内存分析的轻量级实用分析工具。它在GPU二进制文件上运行，无需修改硬件、操作系统或应用程序源代码。对于CUDA应用程序，cuThermo通过基于不同的访问warp计数的“热图”在运行时识别内存低效率，以表示字扇区级别的数据共享，并在性能调优迭代中提供优化指导。通过我们对六个应用程序的实验，我们识别出五种可在不同GPU架构上移植的内存访问模式。通过在两个GPU上评估优化，cuThermo实现了高达721.79%的性能提升。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [458] [PPipe: Efficient Video Analytics Serving on Heterogeneous GPU Clusters via Pool-Based Pipeline Parallelism](https://arxiv.org/abs/2507.18748)
> *PPipe：基于池化流水线并行在异构GPU集群上提供高效视频分析服务*

*Z. Jonny Kong, Qiang Xu, Y. Charlie Hu* | **Category: cs.DC** | **Updated: 2025-07-24**

**Keywords:** 异构GPU集群, 流水线并行, 视频分析, 模型推理, 资源利用

**Comment:** 

> **TL;DR:** 本文提出了PPipe系统，通过基于池化的流水线并行，在异构GPU集群上高效提供视频分析服务，从而提高了GPU利用率和吞吐量。

**AI_Comments:** 该论文的创新之处在于将流水线并行技术应用于异构GPU集群上的延迟敏感型推理服务，特别是通过识别和利用低端GPU未被充分利用的能力。这种方法有效地解决了视频分析服务中高效利用多样化硬件资源的挑战，在GPU利用率和吞吐量方面提供了显著的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 随着GPU的快速发展，异构GPU集群在云端和本地数据中心变得普遍。本研究旨在将通常用于训练的流水线并行技术，有效应用于异构GPU集群上的延迟敏感型模型推理（如视频分析），并利用低端GPU被忽视的能力，因为许多模型层在低端和高端GPU上具有可比的推理延迟。

**Method:** 本文提出了一个名为PPipe的新型推理服务系统，该系统采用基于池化的流水线并行。PPipe包含一个基于MILP（混合整数线性规划）的控制平面和一个执行基于资源预留的自适应批处理的数据平面，以利用模型层多样性和GPU架构多样性之间的协同作用。

**Result:** 在多种工作负载（18个CNN模型）上的评估表明，PPipe实现了41.1% - 65.5%的低端GPU更高利用率，同时保持了高端GPU的高利用率，与各种基线相比，服务吞吐量提高了32.2% - 75.1%。

**Conclusion:** PPipe系统通过有效地利用异构GPU集群，显著提高了低端GPU的利用率和整体服务吞吐量，证明了基于池化流水线并行在视频分析服务中的有效性。

> **ai_Abstract:** 本文提出了PPipe，一个专为异构GPU集群上延迟敏感型视频分析设计的推理服务系统。PPipe利用基于池化的流水线并行技术，通过发现并利用许多模型层在不同等级GPU上具有相似推理延迟的特性，有效利用了低端GPU的潜力。该系统包含一个基于MILP的控制平面和基于资源预留自适应批处理的数据平面。实验结果表明，与现有基线相比，PPipe在保持高端GPU高利用率的同时，显著提高了低端GPU的利用率（41.1%-65.5%）和整体服务吞吐量（32.2%-75.1%）。

> **摘要翻译:** 随着GPU的快速创新，公共云和本地数据中心中的异构GPU集群变得越来越普遍。在本文中，我们展示了流水线并行，一种在面向吞吐量的深度学习模型训练中得到充分研究的技术，如何能有效地用于在异构GPU集群上提供延迟敏感的模型推理，例如在视频分析系统中。我们的工作利用了模型层多样性与GPU架构多样性之间的协同作用，这使得许多层在低端和高端GPU上运行时具有可比的推理延迟。我们探讨了如何利用流水线并行来利用低端GPU的这种被忽视的能力，并提出了一个新颖的推理服务系统PPipe，该系统通过基于MILP的控制平面和执行基于资源预留的自适应批处理的数据平面来采用基于池的流水线并行。在不同工作负载（18个CNN模型）上的评估结果表明，与各种基线相比，PPipe在保持高端GPU高利用率的同时，实现了41.1% - 65.5%的低端GPU更高利用率，从而实现了32.2% - 75.1%的更高服务吞吐量。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [500] [Deadline-Aware Joint Task Scheduling and Offloading in Mobile Edge Computing Systems](https://arxiv.org/abs/2507.18864)
> *移动边缘计算系统中截止日期感知的联合任务调度与卸载*

*Ngoc Hung Nguyen, Van-Dinh Nguyen, Anh Tuan Nguyen, Nguyen Van Thieu, Hoang Nam Nguyen, Symeon Chatzinotas* | **Category: cs.DC, cs.CC, C.2.4; I.2.8** | **Updated: 2025-07-25**

**Keywords:** 移动边缘计算, 任务调度, 任务卸载, 截止日期, 服务质量

**Comment:** 14 pages, 13 figures. Accepted for publication in IEEE Internet of
  Things Journal (JIOT)

> **TL;DR:** 本文提出了一种在移动边缘计算系统中，用于截止日期敏感任务的联合调度和卸载算法。该算法旨在优化任务顺序，并支持用户基于服务器信息进行卸载决策，以实现低复杂度和高服务效率。

**AI_Comments:** 该论文解决了移动边缘计算中一个关键且复杂的挑战——如何在满足严格截止日期的同时，优化任务调度和卸载。其创新之处在于提出了一个最优的离线调度算法以及一个高效的在线方法，并且证明了其低复杂度，这对于实际系统部署非常重要。该研究通过数值结果验证了算法的有效性，为提升MEC系统的QoS提供了有价值的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 为了提升用户体验，移动边缘计算（MEC）和云系统对严格的交互式服务质量（QoS）需求不断增加，这要求计算密集型任务必须满足特定的截止日期或实现极低延迟。现有研究主要关注减少未按时完成的任务数量，但其主要挑战在于总搜索时间和调度效率。

**Method:** 本文提出了一种最优作业调度算法，用于确定给定任务集的最优任务顺序。此外，用户可以根据服务器提供的信息做出明智的卸载决策。针对随机到达任务的不确定性，本文进一步开发了一种具有快速中断检测的在线方法。

**Result:** 所提出的最优作业调度算法具有线性对数时间复杂度O(nlogn)，其中n是任务数量，表现出低复杂性。在线方法实现了快速接受时间，时间复杂度为O(n)。大量的数值结果表明，该算法在服务比率和调度成本方面是有效的。

**Conclusion:** 本文提出的算法在移动边缘计算系统中实现了截止日期感知的联合任务调度和卸载，展现了其最优性、低复杂性和在服务比率与调度成本方面的有效性。

> **ai_Abstract:** 本论文针对移动边缘计算（MEC）和云系统中计算密集型任务的截止日期和低延迟要求，提出了一种截止日期感知的联合任务调度与卸载算法。该算法包括一个最优作业调度部分，旨在确定任务的最佳执行顺序，并允许用户根据服务器信息进行智能卸载决策。为了应对动态任务到达的挑战，论文还开发了一个具有快速中断检测的在线调度方法。研究结果表明，所提出的算法具有O(n log n)和O(n)的低时间复杂度，并在服务比率和调度成本方面表现出显著的有效性。

> **摘要翻译:** 在移动边缘计算（MEC）和云系统中，为了改善用户体验，对严格的交互式服务质量（QoS）的需求日益增强。因此，这些系统中计算密集型任务的处理需要遵守特定的截止日期或实现极低的延迟。为了优化任务调度性能，现有研究主要集中于减少未达到截止日期的延迟作业数量。然而，这些方法的主要挑战在于总搜索时间和调度效率。在本文中，我们提出了一种最优作业调度算法，旨在为给定任务集确定最优任务顺序。此外，用户可以根据服务器提供的信息做出明智的任务卸载决策。本文提供了性能分析的详细信息，以展示其最优性和线性对数时间O(nlogn)的低复杂性，其中n是任务数量。为了解决随机到达任务的不确定性，我们进一步开发了一种具有快速中断检测的在线方法，该方法以O(n)的时间复杂度实现了快速接受时间。提供了大量的数值结果，以证明所提出的算法在服务比率和调度成本方面的有效性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [531] [GPUnion: Autonomous GPU Sharing on Campus](https://arxiv.org/abs/2507.18928)
> *GPUnion：校园自主GPU共享*

*Yufang Li, Yuanbo Zhang, Hanlong Liao, Guoming Tang, Deke Guo* | **Category: cs.DC, C.2.4; C.2.1** | **Updated: 2025-07-25**

**Keywords:** GPU共享, 校园资源, 自主, 容器化, 资源管理

**Comment:** 7 pages, 3 figures, 1 table. Submitted to the ACM Workshop on Hot
  Topics in Networks (HOTNETS) 2025

> **TL;DR:** GPUnion是一个为解决校园GPU资源不平衡问题而设计的平台，它通过允许自愿和自主的GPU共享，提高了资源利用率和访问，同时无需集中式控制。

**AI_Comments:** 该论文通过优先考虑提供者自主权，为资源共享提供了一种创新方法，这在学术环境中至关重要。利用容器化、检查点和迁移功能解决了动态资源环境中的关键挑战。它对去中心化的关注挑战了传统的集中式模型，使其与校园规模的资源管理高度相关。

<details>
  <summary>Details</summary>

**Motivation:** 校园内GPU资源存在显著失衡，一些实验室的服务器利用率不足，而另一些实验室则缺乏进行AI研究所需的计算资源。现有的GPU共享平台通常依赖于集中式监督和持久分配模型，这与学术资源所有权的自愿和自主性质相冲突。

**Method:** GPUnion引入了三个核心机制：i) 基于容器的任务调度和执行，ii) 资源提供者优先的架构，以及iii) 具有自动检查点和迁移功能的弹性执行。GPUnion还支持自定义数据存储，并集成了非root执行和镜像认证，以改进容器化的隔离性和安全性。

**Result:** 案例研究表明，GPU利用率提高了30%以上，交互式会话增加了40%，在提供者离开期间，94%的工作负载迁移成功。

**Conclusion:** GPUnion证明了提供者自主权和平台可靠性可以共存，挑战了传统的集中式范式，并使校园网络内的计算资源访问民主化。

> **ai_Abstract:** GPUnion是一个为解决校园GPU资源不平衡问题而设计的自主GPU共享平台。它通过容器化任务调度、提供者优先架构和弹性执行（支持自动检查点和迁移）实现自愿参与和提供者自主权。该平台还增强了安全性和隔离性。案例研究显示，GPUnion显著提高了GPU利用率、交互会话数量，并成功迁移了工作负载，证明了自主性与平台可靠性可以并存，从而推动了校园计算资源的民主化。

> **摘要翻译:** 校园内GPU资源存在显著失衡，一些实验室的服务器利用率不足，而另一些实验室则缺乏进行AI研究所需的计算资源。GPU共享可以缓解这种差异，而现有平台通常依赖于集中式监督和持久分配模型，这与学术资源所有权的自愿和自主性质相冲突。我们提出了GPUnion，一个校园规模的GPU共享平台，它支持自愿参与，同时保留了提供者的完全自主权。GPUnion整合了三个核心机制：i) 基于容器的任务调度和执行，ii) 资源提供者优先的架构，以及iii) 具有自动检查点和迁移功能的弹性执行。GPUnion还支持自定义数据存储，并集成了非root执行和镜像认证，以改进容器化的隔离性和安全性。跨多个校园场景的案例研究表明，GPU利用率提高了30%以上，交互式会话增加了40%，在提供者离开期间，94%的工作负载迁移成功。GPUnion证明了提供者自主权和平台可靠性可以共存，挑战了传统的集中式范式，并使校园网络内的计算资源访问民主化。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [573] [The Case for Time-Shared Computing Resources](https://arxiv.org/abs/2507.19287)
> *分时计算资源的案例*

*Pierre Jacquet, Adrien Luxey-Bitri* | **Category: cs.DC** | **Updated: 2025-07-25**

**Keywords:** 分时计算, 资源共享, 环境影响, 能源效率, 云计算

**Comment:** Post-proceedings paper presented at LIMITS 2025: 11th Workshop on
  Computing within Limits, 2025-06-26/27, Online

> **TL;DR:** ICT的环保影响日益增长，本文倡导通过改进租户间的资源共享（即分时计算）来减少物理资源消耗，以实现能源效率提升和集群规模缩小，尽管可能牺牲性能。

**AI_Comments:** 本文提出了一种应对ICT环境影响的重要且具有前瞻性的解决方案，即重新审视和推广分时计算的概念。其创新之处在于将分时提升到更高的抽象层次，并明确指出性能权衡是实现资源高效利用的关键。在当前资源日益紧张的背景下，这种“用更少资源做更多事”的理念具有重要意义。然而，如何平衡性能下降与用户体验，以及如何克服现有技术和商业模式的惯性，将是未来面临的主要挑战。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于信息和通信技术（ICT）日益增长的环境影响以及其固有的资源限制，未来数据中心可能需要在更严格的限制下管理服务。当前云计算环境中租户通常不共享计算资源，导致资源浪费，因此需要一种新的方法来应对资源稀缺性。

**Method:** 本文倡导通过改进租户之间的资源共享来管理更少的物理资源，这是一种超越传统硬件级分时的更高抽象范式。该方法涉及在“性能降低”的条件下“用更少的资源做事”。文章回顾了现有技术，识别了挑战和机遇，提出了分时计算的解释，并概述了关键研究方向。

**Result:** 增强基础设施的共享化可以减少集群规模（通过整合）并提高能源效率，这些收益与可接受的性能权衡相关。这被认为是一种比取消服务更具社会可接受性的情况。

**Conclusion:** 面对ICT日益增长的环境影响和资源限制，通过改进租户间的资源共享，即使以性能降低为代价，也能有效减少物理资源消耗，降低集群规模，提高能源效率，这是一种可行且可能更具社会可接受性的解决方案。

> **ai_Abstract:** 本文探讨了信息和通信技术（ICT）日益增长的环境影响及其对有限资源的需求。研究发现，即使在云平台等环境中，租户通常也不共享计算资源。为应对此问题，论文提出了一种新的范式，倡导通过改进租户间的资源共享来管理更少的物理资源，这超越了传统的硬件级分时。尽管这种方法可能导致性能降低，但它能有效减少集群规模并提高能源效率。文章回顾了现有技术，识别了挑战和机遇，并提出了分时计算的解释和未来研究方向，认为这是一种比取消服务更可接受的资源管理方式。

> **摘要翻译:** 信息和通信技术（ICT）对环境的影响持续增长，这主要受到使用量增加、回弹效应和新兴需求的推动。然而，尽管其服务本质上是虚拟的，但该行业仍受其物质性的固有限制，无法依赖无限的资源池。因此，未来主机设施中可能需要在更严格的限制下管理各种支持的服务。与普遍假设相反，我们发现租户通常不共享计算资源，即使在通常被认为是共享化的环境中，例如云平台。出于性能、安全性、可预测性以及可能更重要的是计算资源成本下降的原因，分时已被逐步淘汰。本文倡导通过改进租户之间的资源共享来管理更少的物理资源。这代表了一种范式转变，超越了硬件层面的传统分时，达到了更高的抽象层次。这种方法需要在“性能降低”的条件下“用更少的资源做事”。尽管如此，增强基础设施的共享化可以减少集群规模（通过整合）并提高能源效率，其收益与可接受的性能权衡相关，这是一种可能比取消服务更具社会可接受性的情况。我们回顾了现有技术，识别了挑战和机遇，提出了分时计算的解释，并概述了关键研究方向。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [831] [Fully Energy-Efficient Randomized Backoff: Slow Feedback Loops Yield Fast Contention Resolution](https://arxiv.org/abs/2302.07751)
> *全能量高效随机退避：慢反馈循环产生快速争用解决*

*Michael A. Bender, Jeremy T. Fineman, Seth Gilbert, John Kuszmaul, Maxwell Young* | **Category: cs.DC** | **Updated: 2025-07-25**

**Keywords:** 争用解决, 能量效率, 随机退避, 反馈循环, 对抗性噪声

**Comment:** 

> **TL;DR:** 本文提出一种新的争用解决算法，在对抗性噪声下，以高概率实现恒定吞吐量和每包对数多项式次信道访问，证明了无需短反馈循环即可实现高效通信。

**AI_Comments:** 这篇论文的创新点在于打破了传统争用解决算法对“短反馈循环”的依赖，证明了在保持恒定吞吐量和对对抗性噪声鲁棒性的前提下，可以大幅减少信道访问次数，从而实现更高的能量效率。这对于无线通信和物联网等资源受限环境下的设备设计具有重要意义，可能为未来的协议设计提供新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统争用解决算法为实现恒定吞吐量需要短反馈循环，但频繁的监听和发送消耗大量能量。本文旨在探究实现恒定吞吐量是否必须依赖短反馈循环，以及对抗性噪声（干扰）如何影响长反馈循环和能量效率，即在减少信道访问（提高能效）的同时，是否必须牺牲恒定吞吐量或对噪声的鲁棒性。

**Method:** 论文提出了一种新的争用解决算法。该算法在存在N个数据包和J个干扰槽的对抗性输入环境下运行。它通过设计一种机制来减少信道访问，同时保持高性能。

**Result:** 提出的算法在N个数据包和J个干扰槽的存在下，以高概率实现了恒定吞量，并且每个数据包的信道访问次数为polylog(N+J)。这表明无需牺牲性能即可实现能量效率。

**Conclusion:** 本文证明，在争用解决问题中，无需牺牲恒定吞吐量或对噪声的鲁棒性，即可实现能量高效（减少信道访问次数）的通信。通过设计的算法，即使在慢反馈循环和对抗性噪声下，也能获得高效的争用解决。

> **ai_Abstract:** 本文研究了共享信道争用解决中的能量效率问题，特别是是否需要短反馈循环才能实现恒定吞吐量以及对抗性噪声的影响。针对传统算法对短反馈循环的依赖，作者提出了一种新的随机退避算法。该算法在存在N个数据包和J个对抗性干扰槽的情况下，以高概率实现了恒定吞吐量，并且每个数据包仅需要polylog(N+J)次信道访问。这表明，无需牺牲吞吐量或对噪声的鲁棒性，即可通过慢反馈循环实现高效且能量节约的争用解决。

> **摘要翻译:** 争用解决旨在协调对共享信道的访问。时间以时隙为单位进行，数据包可以在任何时隙传输。如果该时隙没有其他数据包传输，则数据包成功发送。如果两个或更多数据包在同一时隙发送，则这些传输均不成功。在时隙期间监听会提供三元反馈，指示该时隙是(0)静默、(1)成功传输还是(2+)噪声。没有其他反馈可用。数据包随时间（对抗性地）注入系统。数据包一旦成功发送即离开系统。目标是在优化吞吐量（大致是成功时隙的比例）的同时发送所有数据包。
大多数具有恒定吞吐量的现有算法需要短反馈循环，即数据包在时隙t+1的发送概率完全由其在时隙t的内部状态和时隙t的信道反馈决定。一个悬而未决的问题是这些短反馈循环是否必要；也就是说，为了实现恒定吞吐量，监听和更新必须多久发生一次？这个问题涉及能量效率，因为监听和发送都会消耗大量能量。信道也可能遭受对抗性噪声（“干扰”），这会导致任何监听者听到噪声，即使没有数据包发送。干扰如何影响我们对长反馈循环/能量效率的目标？
连接这些问题，我们问：争用解决算法为了减少信道访问必须牺牲什么？我们必须放弃恒定吞吐量或对噪声的鲁棒性吗？在这里，我们表明我们无需妥协任何东西。假设有N个数据包和J个干扰时隙，其中输入由自适应对抗者决定。我们给出了一个算法，该算法以N+J的高概率具有恒定吞吐量和每个数据包polylog(N+J)次信道访问。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [878] [Urban Green Governance: IoT-Driven Management and Enhancement of Urban Green Spaces in Campobasso](https://arxiv.org/abs/2507.12106)
> *城市绿色治理：物联网驱动的坎波巴索城市绿地管理与提升*

*Antonio Salis, Gabriele Troina, Gianluca Boanelli, Marco Ottaviano, Paola Fortini, Soraya Versace* | **Category: cs.DC, cs.CY** | **Updated: 2025-07-25**

**Keywords:** 城市绿色治理, 物联网, 智能管理, 城市绿地, 坎波巴索

**Comment:** 18 pages, 6 Figures

> **TL;DR:** 该项目展示了如何通过整合物联网系统和数据驱动平台，实现对坎波巴索城市绿地的实时监测和优化管理，从而提升城市生态系统和居民生活质量。

**AI_Comments:** 该论文展示了一个将物联网技术应用于城市绿地管理的实际案例，其创新点在于结合了实时监测、数据分析、机器学习预测和决策支持系统，形成了一个全面的智能管理平台。这对于提升城市可持续发展和居民福祉具有重要意义，尤其是在资源优化和环境监测方面提供了宝贵的实践经验。

<details>
  <summary>Details</summary>

**Motivation:** 高效设计和管理公共绿地对促进城市人口的健康和福祉至关重要，这些绿地是城市生态系统的“绿色之肺”，通过提供生态系统服务来提升生活质量。

**Method:** 该项目整合了物联网系统和数据驱动的治理平台，通过决策支持系统（DSS）实时监测树木和绿地的健康状况。它还收集和分析来自多种来源的数据，包括天气条件、空气质量、土壤湿度和污染水平。利用Tree Talker传感器和土壤湿度/水势监测系统，结合基于机器学习算法的预测模型，优化公共公园的灌溉，并提供定制警报。

**Result:** 一个基于云计算的平台支持绿地管理者、技术专家和操作人员进行全面的实时决策。该系统能够智能控制和管理城市绿地，优化公共公园的灌溉，并当监测参数（如土壤温度、湿度或水势）超出预设阈值时激活定制警报。

**Conclusion:** 该案例证明了数字化、物联网传感器融合和技术创新如何支持可持续的城市治理，促进环境韧性并改善公民的生活质量。

> **ai_Abstract:** 该论文介绍了坎波巴索市的“智慧绿色城市”项目，这是一个由物联网驱动的城市绿地管理和增强的创新模型。该项目通过整合物联网传感器和数据驱动平台，实现对绿地健康状况的实时监测，并收集天气、空气质量、土壤湿度等多样化数据。利用机器学习预测模型，该系统能够优化灌溉，并提供定制警报。这展示了数字化和技术创新在支持可持续城市治理、提升环境韧性及改善居民生活质量方面的潜力。

> **摘要翻译:** 高效设计和管理公共绿地是促进城市人口健康和福祉的关键因素，这一点得到了世界卫生组织、联合国环境规划署和欧洲环境署的强调。这些区域是城市生态系统的“绿色之肺”，通过提供生态系统服务在提升生活质量方面发挥着至关重要的作用。在此背景下，由意大利企业部（MIMIT）资助的坎波巴索市“智慧绿色城市”用例，通过采用先进的集成和可互操作的新兴技术系统，成为可持续管理城市绿地的创新模式。该项目整合了物联网系统和数据驱动的治理平台，通过决策支持系统（DSS）实现对树木和绿地健康状况的实时监测。它还促进了来自不同来源的数据收集和分析，包括天气条件、空气质量、土壤湿度、污染水平。由此产生的基于云计算的平台支持绿地管理者、技术专家和操作人员进行全面的实时决策。它利用Tree Talker传感器，并与土壤湿度和水势监测系统集成，实现城市绿地的智能控制和管理。通过基于机器学习算法的预测模型和物联网传感器提供的实时数据，可以优化公共公园的灌溉，提供何时以及施用多少水的建议。当监测参数（如土壤温度、湿度或水势）超出预定义阈值时，还会激活定制警报层以警告用户。该用例展示了数字化、物联网传感器融合和技术创新如何支持可持续的城市治理，促进环境韧性并改善公民的生活质量。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [13] [Demystifying AI in Criminal Justice](https://arxiv.org/abs/2507.19305)
> *揭秘人工智能在刑事司法中的应用*

*Richard Berk* | **Category: cs.CY, stat.AP** | **Updated: 2025-07-25**

**Keywords:** 人工智能, 刑事司法, 综述, 法律学者, 困惑

**Comment:** 25 pages. No figures or tables

> **TL;DR:** 一篇旨在为非技术背景的刑事司法从业者和法律学者澄清人工智能在刑事司法中应用的入门性综述。

**AI_Comments:** 这篇论文通过提供一个非技术性的入门指南，解决了刑事司法领域对人工智能的普遍困惑，其重要性在于降低了理解门槛，促进了跨学科交流。

<details>
  <summary>Details</summary>

**Motivation:** 刑事司法从业人员和法律学者对人工智能在刑事司法中的应用普遍存在困惑。

**Method:** 本文是一篇教学性综述，旨在为统计学或计算机科学背景较少的读者提供补充材料，并鼓励他们深入研究感兴趣的主题。

**Result:** Not mentioned in abstract

**Conclusion:** 本文旨在补充更专业的技术处理，并鼓励读者深入研究感兴趣的主题，以消除对人工智能在刑事司法中应用的困惑。

> **ai_Abstract:** 本文旨在为缺乏统计学或计算机科学背景的刑事司法从业者和法律学者提供一份教学性综述，以澄清人工智能在刑事司法中的应用，并鼓励他们进一步探索相关主题。

> **摘要翻译:** 刑事司法从业人员和法律学者对人工智能在刑事司法中的应用普遍存在困惑。这篇教学性综述是为那些几乎没有统计学或计算机科学背景的读者撰写的。它无意取代更专业的技术处理。它旨在补充这些技术处理，并鼓励读者更深入地研究他们感兴趣的话题。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [107] [How Instructional Sequence and Personalized Support Impact Diagnostic Strategy Learning](https://arxiv.org/abs/2507.17760)
> *教学序列和个性化支持如何影响诊断策略学习*

*Fatma Betül Güreş, Tanya Nazaretsky, Bahar Radmehr, Martina Rau, Tanja Käser* | **Category: cs.CY, cs.AI, cs.HC, K.3.1** | **Updated: 2025-05-08**

**Keywords:** 教学序列, 个性化支持, 诊断策略学习, 情景式学习, 知识迁移

**Comment:** Submitted to AIED 2025 main track

> **TL;DR:** 本研究探讨了在情景式学习中，诊断策略教学在问题解决之前（I-PS）或之后（PS-I）对学习和迁移的影响，发现PS-I在迁移任务中表现显著更好。

**AI_Comments:** 这项研究的创新之处在于其对情景式学习中教学序列的深入探讨，特别是在问题解决前后提供诊断策略教学的效果比较。其重要性在于为教育者提供了优化诊断推理教学策略的实证依据，强调了先实践后理论的教学模式在提升知识迁移方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在各种教育领域中，支持学生发展有效的诊断推理是一个关键挑战。新手常受认知偏差（如过早下结论和过度依赖启发式）困扰。情景式学习（SBL）虽能通过提供真实案例和迭代练习解决这些问题，但最佳的教学和问题解决活动序列仍不明确。

**Method:** 本研究采用组间设计，在一个名为PharmaSim的在线SBL环境中进行，该环境模拟药剂师学徒的真实客户互动，以检验个性化支持如何融入不同的教学序列，以及在问题解决之前（I-PS）或之后（PS-I）提供明确的诊断策略教学是否能改善学习及其迁移。

**Result:** 结果表明，两种教学类型都有益，但PS-I（问题解决后教学）在迁移任务中导致显著更高的表现。

**Conclusion:** 在情景式学习环境中，先进行问题解决再提供明确的诊断策略教学，比先教学再解决问题，更能有效提升学习的迁移效果。

> **ai_Abstract:** 本研究探讨了在情景式学习（SBL）环境中，教学序列（在问题解决前或后提供诊断策略教学）和个性化支持对学生诊断策略学习和迁移的影响。研究发现，尽管两种教学方式都有益，但在问题解决之后再进行明确的诊断策略教学（PS-I）能显著提高学习者在迁移任务中的表现。

> **摘要翻译:** 支持学生发展有效的诊断推理是各种教育领域中的一个关键挑战。新手常受认知偏差（如过早下结论和过度依赖启发式）困扰。情景式学习（SBL）可以通过提供真实的案例经验和迭代练习来解决这些挑战，但教学和问题解决活动的最佳序列仍不明确。本研究探讨了如何将个性化支持融入不同的教学序列，以及在问题解决之前（I-PS）或之后（PS-I）提供明确的诊断策略教学是否能改善学习及其迁移。我们采用组间设计，在一个名为PharmaSim的在线SBL环境中进行，该环境模拟药剂师学徒的真实客户互动。结果表明，虽然两种教学类型都有益，但PS-I在迁移任务中导致显著更高的表现。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [244] [Extracting Insights from Large-Scale Telematics Data for ITS Applications: Lessons and Recommendations](https://arxiv.org/abs/2507.13936)
> *从大规模远程信息处理数据中提取见解用于ITS应用：经验与建议*

*Gibran Ali, Neal Feierabend, Prarthana Doshi, Calvin Winkowski, Michael Fontaine* | **Category: cs.CY** | **Updated: 2025-07-25**

**Keywords:** 远程信息处理数据, 智能交通系统, 大数据处理, 交通规划

**Comment:** Accepted for 2025 IEEE International Conference on Intelligent
  Transportation Systems (ITSC 2025)

> **TL;DR:** 该研究针对大规模、非标准化远程信息处理数据，构建了数据处理管道、开放数据存储库和可视化工具，并总结了挑战和建议，以帮助交通专业人士更好地利用数据。

**AI_Comments:** 这篇论文的创新之处在于它直接解决了大规模、异构远程信息处理数据实际应用中的痛点，即数据量巨大且缺乏标准化。通过构建一个端到端的数据处理和分析框架，并提炼出实际操作中的经验教训和建议，该研究为ITS领域利用新兴的远程信息处理数据提供了宝贵的实践指导和工具。其贡献不仅在于技术实现，更在于其对行业痛点的深刻理解和实用性解决方案的提供。

<details>
  <summary>Details</summary>

**Motivation:** 尽管远程信息处理数据规模庞大且在交通测量、分类、规划和控制方面提供了新的机遇，但其巨大的数据量和制造商之间缺乏标准化，需要更清晰地理解数据和改进数据处理方法以提取可操作的见解。

**Method:** 该研究通过四个主要目标来解决上述需求：1. 构建了一个数据处理管道，用于高效分析2021年8月至2022年8月在弗吉尼亚州收集的14亿英里（1.2亿次行程）远程信息处理数据。2. 创建了一个行程和路段级别的开放数据存储库。3. 设计了交互式可视化工具，用于从数据中提取有关出行行为和道路速度剖面的见解。4. 总结了处理数据时面临的主要挑战，并提供了克服这些挑战的建议。

**Result:** 结果是构建了一个高效的数据处理管道、一个开放数据存储库、交互式可视化工具，并总结了处理大规模远程信息处理数据的主要挑战和克服这些挑战的建议。

**Conclusion:** 这项工作将帮助数据收集制造商和数据使用交通专业人士更好地理解利用远程信息处理数据的可能性和需要避免的主要陷阱。

> **ai_Abstract:** 本文旨在解决大规模、非标准化远程信息处理数据在交通应用中面临的挑战。研究构建了一个高效的数据处理管道，用于分析弗吉尼亚州收集的14亿英里远程信息处理数据，并创建了开放数据存储库和交互式可视化工具。此外，文章总结了数据处理过程中的主要挑战并提供了解决方案，旨在帮助制造商和交通专业人士更好地利用此类数据并避免潜在问题。

> **摘要翻译:** 目前，美国90%以上的新车都在收集和传输远程信息处理数据。其他发达国家也出现了类似的趋势。交通规划者此前曾以各种形式利用远程信息处理数据，但其目前的规模为交通测量、分类、规划和控制提供了重要的S新机遇。尽管存在这些机遇，但庞大的数据量和制造商之间缺乏标准化，需要更清晰地理解数据和改进数据处理方法以提取可操作的见解。
本文通过四个主要目标迈出了解决这些需求的一步。首先，构建了一个数据处理管道，用于高效分析2021年8月至2022年8月在弗吉尼亚州收集的14亿英里（1.2亿次行程）远程信息处理数据。其次，创建了一个行程和路段级别的开放数据存储库。第三，设计了交互式可视化工具，用于从这些数据中提取有关出行行为和道路速度剖面的见解。最后，总结了处理这些数据时面临的主要挑战，并提供了克服这些挑战的建议。这项工作将帮助数据收集制造商和数据使用交通专业人士更好地理解可能性和需要避免的主要陷阱。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [287] [The Impact of Pseudo-Science in Financial Loans Risk Prediction](https://arxiv.org/abs/2507.16182)
> *金融贷款风险预测中伪科学的影响*

*Bruno Scarone, Ricardo Baeza-Yates* | **Category: cs.CY, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 伪科学, 金融风险预测, 幸存者偏差, 机器学习, 社会成本

**Comment:** 

> **TL;DR:** 本研究探讨了在金融贷款风险预测中，伪科学假设和幸存者偏差对机器学习模型的影响，发现社会最优模型可能不会导致显著的准确性损失，且模型随时间表现出的“改进”实际上可能加剧了不公平性和幸存者偏差。

**AI_Comments:** 该论文揭示了在机器学习应用于金融风险预测时，伪科学假设和幸存者偏差可能带来的深远社会影响。其创新之处在于不仅关注模型准确性，更引入了社会成本的考量，并指出“改进”的假象可能掩盖了更深层的不公平性。这对于负责任的AI开发和部署具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究伪科学假设在金融贷款风险预测中对人们行为预测的社会影响，并探讨幸存者偏差在此应用中的影响。

**Method:** 通过分析模型的准确性和社会成本来评估模型，并针对常用学习方法和数据集验证了结果。研究了训练模型时幸存者偏差导致的动态变化。

**Result:** 社会最优模型在下游任务中可能不会导致显著的准确性损失。受幸存者偏差影响的模型在训练时会出现准确性略微下降，而召回率和精确度随时间提高的自然动态，这种“改进”实际上是模型不公平性和幸存者偏差加剧的错觉。

**Conclusion:** 在金融贷款风险预测中，伪科学假设和幸存者偏差会扭曲模型表现，导致系统看起来在改进，但实际上却变得更不公平。选择社会最优模型可以在不显著牺牲准确性的情况下减轻这些负面影响。

> **ai_Abstract:** 本研究探讨了在金融贷款风险预测中，伪科学假设和幸存者偏差对机器学习模型的影响。研究发现，在不显著牺牲准确性的前提下，存在社会最优模型。此外，模型在训练过程中可能表现出虚假的性能提升，即准确率略有下降但召回率和精确率上升，这实则加剧了模型的不公平性和幸存者偏差。

> **摘要翻译:** 我们研究了伪科学假设在金融借贷风险预测中对人们行为预测的社会影响，这是机器学习在金融借贷风险预测中一个直接的应用。这个用例也体现了幸存者偏差在贷款回报预测中的影响。我们从准确性和社会成本两方面分析了这些模型，结果表明，对于这个下游任务，社会最优模型可能不会导致显著的准确性损失。我们的结果已针对常用的学习方法和数据集进行了验证。我们的发现还表明，在训练受幸存者偏差影响的模型时，存在一种自然的动态：准确性略微下降，而召回率和精确度随时间提高。这些结果构成了一种错觉，导致观察者认为系统正在变得更好，而事实上模型正遭受着越来越严重的不公平性和幸存者偏差。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [595] [A Concept for Efficient Scalability of Automated Driving Allowing for Technical, Legal, Cultural, and Ethical Differences](https://arxiv.org/abs/2507.18326)
> *自动驾驶高效可扩展性的概念：兼顾技术、法律、文化和伦理差异*

*Lars Ullrich, Michael Buchholz, Jonathan Petit, Klaus Dietmayer, Knut Graichen* | **Category: cs.CY, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 自动驾驶, 可扩展性, 微调, 社会政治方面, 迁移学习

**Comment:** Accepted to be published at 2025 28th IEEE International Conference
  on Intelligent Transportation Systems (ITSC), Gold Coast, Australia, November
  18-21, 2025

> **TL;DR:** 本文提出了一种两阶段微调概念，旨在实现自动驾驶系统在技术、法律、文化和伦理差异下的高效可扩展性。

**AI_Comments:** 本文通过将社会政治因素（法律、文化、伦理）明确融入自动驾驶可扩展性的技术微调过程，提供了一种创新方法。这种全面的视角对于全球实际部署至关重要，超越了纯粹的技术挑战。带有国家特定奖励模型的两阶段微调尤为新颖，解决了当前自动驾驶研究中的一个显著空白。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶（AD）的高效可扩展性是降低成本、提高安全性、节约资源和最大化影响的关键。然而，现有研究主要关注特定车辆和环境，而广泛部署需要跨各种配置和环境的可扩展性，尤其是考虑到车辆类型、传感器、执行器以及交通法规、法律要求、文化动态和伦理范式等方面的差异。

**Method:** 本文提出了一个两阶段微调过程。第一阶段，通过一个国家特定的奖励模型对特定环境进行微调，该模型作为技术适应和社会政治要求之间的接口。第二阶段，车辆特定的迁移学习促进系统适应并管理设计决策的验证。

**Result:** 该概念提供了一个数据驱动的过程，该过程整合了技术和社会政治方面，从而实现了跨技术、法律、文化和伦理差异的有效可扩展性。

**Conclusion:** 本文提出的数据驱动的两阶段微调概念，通过整合技术和社会政治方面，有效地解决了自动驾驶通用能力的可扩展适应性挑战，以应对全球范围内的多样化差异。

> **ai_Abstract:** 本文介绍了一种新颖的两阶段微调概念，旨在实现自动驾驶系统的高效可扩展性。该研究认识到广泛的自动驾驶部署需要超越特定车辆和上下文的适应性，因此提出的数据驱动过程整合了技术和社会政治方面的考量。第一阶段通过国家特定的奖励模型将能力微调到特定环境，而第二阶段则利用车辆特定的迁移学习进行系统适应和验证，最终实现跨越不同技术、法律、文化和伦理环境的有效可扩展性。

> **摘要翻译:** 自动驾驶（AD）的高效可扩展性是降低成本、提高安全性、节约资源和最大化影响的关键。然而，现有研究侧重于特定的车辆和环境，而广泛部署需要跨各种配置和环境的可扩展性。车辆类型、传感器、执行器，以及交通法规、法律要求、文化动态甚至伦理范式的差异，都要求数据驱动开发的能力具有高度灵活性。在本文中，我们解决了将通用能力可扩展地适应到所需系统和环境的挑战。我们的概念遵循两阶段微调过程。在第一阶段，通过一个国家特定的奖励模型对特定环境进行微调，该模型作为技术适应和社会政治要求之间的接口。在第二阶段，车辆特定的迁移学习促进系统适应并管理设计决策的验证。总而言之，我们的概念提供了一个数据驱动的过程，该过程整合了技术和社会政治方面，从而实现了跨技术、法律、文化和伦理差异的有效可扩展性。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [702] [Weaving the Future: Generative AI and the Reimagining of Fashion Design](https://arxiv.org/abs/2507.17758)
> *编织未来：生成式AI与时尚设计的重塑*

*Pierre-Marie Chauvin, Angèle Merlin, Xavier Fresquet, Hugo Caselles-Dupré, Benjamin Simmenauer, Mathieu de Fayet* | **Category: cs.CY, cs.HC** | **Updated: 2025-05-07**

**Keywords:** 生成式AI, 时尚设计, 创意流程, 人机协同, 算法设计

**Comment:** 

> **TL;DR:** 本文探讨了生成式AI在时尚设计中的整合，分析其对创意流程、伦理、美学和劳工的影响，并强调人机协同、创新潜力及算法设计的挑战。

**AI_Comments:** 这篇论文创新性地探讨了生成式AI在时尚设计领域的具体应用，并全面考虑了其多方面的影响，包括技术、伦理、美学和环境方面。其重要性在于为时尚界拥抱AI提供了理论框架和潜在挑战的预警。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探讨生成式AI如何整合到时尚设计过程中，以及它如何重塑创意工作流程。

**Method:** 本文基于2025年1月“Tisser le futur”研讨会的见解，探讨了AI如何重塑从构思到原型制作的创意工作流程，并审视了其伦理、美学和劳工影响。

**Result:** 研究结果强调了人机之间的协同创造动态、美学创新的潜力，以及算法设计带来的环境和文化挑战。

**Conclusion:** 本文探讨了生成式AI对时尚设计过程的全面影响，揭示了其在提升创意和效率方面的潜力，同时也强调了需要解决的伦理、美学、劳工、环境和文化挑战。

> **ai_Abstract:** 本文探讨了生成式AI在时尚设计领域的应用，分析了其如何改变从构思到原型制作的创意流程。文章深入审视了AI整合所带来的伦理、美学和劳工影响，并指出了人机协同的潜力、美学创新的可能性以及算法设计面临的环境和文化挑战。

> **摘要翻译:** 本文探讨了生成式AI在时尚设计过程中的整合。本文借鉴了2025年1月“Tisser le futur”研讨会的见解，调查了AI如何重塑从构思到原型制作的创意工作流程，同时审视了其伦理、美学和劳工影响。本文强调了人机之间的协同创造动态、美学创新的潜力，以及算法设计的环境和文化挑战。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [711] [Towards reliable use of artificial intelligence to classify otitis media using otoscopic images: Addressing bias and improving data quality](https://arxiv.org/abs/2507.18842)
> *耳镜图像人工智能分类中耳炎的可靠应用：解决偏差和提高数据质量*

*Yixi Xu, Al-Rahim Habib, Graeme Crossland, Hemi Patel, Chris Perry, Kris Bock, Tony Lian, William B. Weeks, Rahul Dodhia, Juan Lavista Ferres, Narinder Pal Singh* | **Category: cs.CY** | **Updated: 2025-07-24**

**Keywords:** 中耳炎, 人工智能, 数据偏差, 耳镜图像, 泛化性

**Comment:** 

> **TL;DR:** AI诊断中耳炎因数据偏差和伪影而不可靠，需改进数据质量以提高泛化性。

**AI_Comments:** 该研究创新性地通过反事实实验深入探究了AI模型在医疗图像诊断中对非临床特征的依赖性，揭示了数据集质量和偏差对模型可靠性和泛化性的严重影响。其重要性在于，为未来开发更稳健、更值得信赖的医疗AI诊断系统提供了关键指导，强调了数据策展和标准化协议的重要性，而非仅仅追求高内部性能。

<details>
  <summary>Details</summary>

**Motivation:** 耳病是全球听力损失的重要原因，中耳炎是儿童可预防的主要病因。人工智能（AI）有望通过耳镜图像分析实现早期诊断，但数据集偏差和不一致性限制了模型的泛化性和可靠性。

**Method:** 本回顾性研究系统评估了三个公共耳镜图像数据集（智利、美国俄亥俄州、土耳其），采用定量和定性方法。进行了两次反事实实验：(1) 遮蔽临床相关特征以评估模型对非临床伪影的依赖性；(2) 评估色调、饱和度和亮度对诊断结果的影响。

**Result:** 定量分析显示智利和美国俄亥俄州数据集存在显著偏差。反事实实验I发现，模型内部性能高（AUC > 0.90）但外部泛化性差，原因是数据集特有的伪影。土耳其数据集偏差较少，更依赖临床有意义的特征。反事实实验II识别出智利和美国俄亥俄州数据集中的常见伪影。在智利数据集中，用临床不相关特征训练的逻辑回归模型实现了高内部（AUC = 0.89）和外部（美国俄亥俄州：AUC = 0.87）性能。定性分析发现所有数据集都存在冗余，美国俄亥俄州数据集存在与临床结果相关的风格偏差。

**Conclusion:** 数据集偏差严重损害了基于AI的耳镜诊断模型的可靠性和泛化性。通过标准化成像协议、纳入多样化数据集和改进标记方法来解决这些偏差对于开发稳健的AI解决方案、提高高质量医疗保健的可及性和增强诊断准确性至关重要。

> **ai_Abstract:** 本研究系统评估了用于中耳炎AI诊断的耳镜图像数据集，发现现有数据集存在显著偏差和伪影，导致模型泛化性差。通过反事实实验揭示，模型可能依赖非临床特征。研究强调，为了开发可靠的AI诊断工具，必须通过标准化成像、多样化数据和改进标注来解决这些数据质量问题。

> **摘要翻译:** 耳病是全球听力损失的重要原因，其中复发性中耳炎是儿童可预防的主要病因，影响其发育。人工智能（AI）有望通过耳镜图像分析实现早期诊断，但数据集偏差和不一致性限制了模型的泛化性和可靠性。这项回顾性研究系统地评估了三个公共耳镜图像数据集（智利；美国俄亥俄州；土耳其），采用了定量和定性方法。进行了两次反事实实验：(1) 遮蔽临床相关特征以评估模型对非临床伪影的依赖性，以及 (2) 评估色调、饱和度和亮度对诊断结果的影响。定量分析显示智利和美国俄亥俄州数据集存在显著偏差。反事实实验I发现，由于数据集特有的伪影，模型内部性能高（AUC > 0.90）但外部泛化性差。土耳其数据集偏差较少，随着遮蔽增加，AUC从0.86降至0.65，表明其更依赖临床有意义的特征。反事实实验II识别出智利和美国俄亥俄州数据集中的常见伪影。一个在智利数据集中利用临床不相关特征训练的逻辑回归模型实现了高内部（AUC = 0.89）和外部（美国俄亥俄州：AUC = 0.87）性能。定性分析发现所有数据集都存在冗余，美国俄亥俄州数据集中存在与临床结果相关的风格偏差。总而言之，数据集偏差严重损害了基于AI的耳镜诊断模型的可靠性和泛化性。通过标准化成像协议、纳入多样化数据集和改进标记方法来解决这些偏差对于开发稳健的AI解决方案、提高高质量医疗保健的可及性和增强诊断准确性至关重要。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [759] [Adaptive Learning Systems: Personalized Curriculum Design Using LLM-Powered Analytics](https://arxiv.org/abs/2507.18949)
> *自适应学习系统：使用大型语言模型驱动的分析进行个性化课程设计*

*Yongjie Li, Ruilin Nong, Jianan Liu, Lucas Evans* | **Category: cs.CY, cs.CL** | **Updated: 2025-07-25**

**Keywords:** 自适应学习系统, 大型语言模型, 个性化课程设计, 教育技术, 机器学习

**Comment:** 

> **TL;DR:** 本文介绍了一个利用大型语言模型（LLM）驱动的分析框架，用于个性化课程设计，旨在通过适应性学习提高学生参与度和知识保留。

**AI_Comments:** 该论文的创新之处在于利用LLM的强大分析能力，实现了真正意义上的自适应和个性化学习路径，通过实时数据分析动态调整学习内容。其重要性在于有望将传统的静态教育模式转变为以学生为中心、高度定制化的学习体验，从而显著提升学习效果和学生参与度。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）正在通过实现针对个体学生需求的个性化学习体验来彻底改变教育领域，因此需要一个利用LLM分析的自适应学习系统框架。

**Method:** 本文引入了一个自适应学习系统框架，该框架利用LLM驱动的分析进行个性化课程设计。该方法使用先进的机器学习来分析实时数据，使系统能够调整学习路径并推荐符合每个学习者进度的资源。通过持续评估学生，该框架增强了教学策略，确保所呈现的材料具有相关性和吸引力。

**Result:** 实验结果表明，使用定制课程时，学习者的参与度和知识保留率均有显著提高。在不同教育环境中进行的评估表明，该框架具有灵活性，并对学习成果产生了积极影响。

**Conclusion:** 该框架有可能将传统的教育实践重塑为更具适应性和以学生为中心的模型。

> **ai_Abstract:** 本文提出了一个利用大型语言模型（LLM）驱动的分析框架，用于自适应学习系统中的个性化课程设计。该框架利用先进的机器学习技术实时分析学生数据，以动态调整学习路径、推荐资源并优化教学策略。实验结果表明，该方法显著提高了学习者的参与度和知识保留率，并展现了其在不同教育环境中的灵活性和积极影响，有望推动教育模式向更个性化和以学生为中心的方向发展。

> **摘要翻译:** 大型语言模型（LLM）通过实现针对个体学生需求的个性化学习体验，正在彻底改变教育领域。在本文中，我们介绍了一个自适应学习系统框架，该框架利用LLM驱动的分析进行个性化课程设计。这种创新方法使用先进的机器学习来分析实时数据，使系统能够调整学习路径并推荐符合每个学习者进度的资源。通过持续评估学生，我们的框架增强了教学策略，确保所呈现的材料具有相关性和吸引力。实验结果表明，使用定制课程时，学习者的参与度和知识保留率均有显著提高。在不同教育环境中进行的评估表明，该框架具有灵活性，并对学习成果产生了积极影响，有可能将传统的教育实践重塑为更具适应性和以学生为中心的模型。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [801] [Computing, Complexity and Degrowth : Systemic Considerations for Digital De-escalation](https://arxiv.org/abs/2507.19070)
> *计算、复杂性与去增长：数字降级的系统性考量*

*Valentin Girard, Maud Rio, Romain Couillet* | **Category: cs.CY** | **Updated: 2025-07-25**

**Keywords:** 数字去增长, 复杂性, 数字降级, 棘轮效应, 自下而上

**Comment:** 

> **TL;DR:** 该研究探讨了数字技术与复杂性之间的联系，旨在克服数字去增长的系统性障碍。文章识别了三种复杂性，并提出自下而上的简化策略以应对棘轮效应，促进数字去增长。

**AI_Comments:** 该论文创新性地将“复杂性”概念引入数字去增长领域，并识别了不同类型的复杂性对数字降级的影响。其提出棘轮效应并强调自下而上的简化策略具有重要的实践指导意义。这为理解数字社会中的不可逆性提供了新的视角，并为实现更可持续的数字未来开辟了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有数字去增长研究主要批判数字扩张或提出替代实践，但分析数字技术与复杂性之间的联系对于克服阻碍数字降级的系统性障碍至关重要。

**Method:** 文章梳理了文献中观察到的计算与复杂性之间的不同类型联系：数字技术固有的基础设施复杂性、由其引起的社会政治复杂性以及受数字化阻碍的本体论复杂性。通过探索这些联系，论文旨在找出减少基础设施和社会政治复杂性的方法，并摆脱还原论范式，以支持数字去增长。提出克服障碍的策略。

**Result:** 研究表明，复杂性会诱发棘轮效应（即技术在社会发展中的不可逆性），使得个人难以处理去增长的努力。

**Conclusion:** 为了克服这些障碍，提出了策略，表明自下而上的简化方法更有可能使不同利益相关者（包括用户）产生替代方案。这种数字转变需要开发使个人摆脱对数字习惯和基础设施依恋的方法和技术工具。

> **ai_Abstract:** 本文探讨了数字技术与复杂性之间的关键联系，以促进数字去增长。文章识别了数字技术中固有的基础设施复杂性、其引起的社会政治复杂性以及受数字化阻碍的本体论复杂性。研究发现，复杂性会导致棘轮效应，使去增长努力变得困难。为此，论文提出自下而上的简化策略，并强调开发帮助个体摆脱数字依赖的工具和方法，从而为数字降级和替代方案的出现提供支持。

> **摘要翻译:** 对数字去增长的研究主要批判数字扩张或提出替代数字实践。然而，分析数字技术与复杂性之间的联系对于克服阻碍数字降级的系统性障碍至关重要。本文介绍了文献中观察到的复杂性与计算之间不同类型的联系：数字技术固有的基础设施复杂性、由其引起的社会政治复杂性，以及最后，受数字化阻碍的本体论复杂性（个体与环境相关的各种方式）。本文探讨了这些联系，以找出减少基础设施和社会政治复杂性的方法，并摆脱还原论范式，以支持数字去增长。其发展表明，复杂性会诱发棘轮效应（即技术在社会发展中的不可逆性），使得个人难以处理去增长的努力。因此，提出了克服这些障碍的策略，表明自下而上的简化方法更有可能使不同利益相关者（包括用户）产生替代方案。这种数字转变假设需要开发能够使个人摆脱对数字习惯和基础设施依恋的方法和技术工具，这开辟了一个重要的研究领域。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [843] [A Protocol to Address Ecological Redirection for Digital Practices in Organizations](https://arxiv.org/abs/2507.19078)
> *解决组织中数字实践生态重定向的协议*

*Valentin Girard, Antoine Martin, Maud Rio, Romain Couillet* | **Category: cs.CY** | **Updated: 2025-07-25**

**Keywords:** 生态重定向, 数字实践, 可持续性, 组织, 协议

**Comment:** 

> **TL;DR:** 本论文提出了一种协议，旨在帮助组织对数字实践进行生态重定向，通过映射依恋、提升知识和技能，并最终操作化数字实践的关闭/转型，以应对数字化社会的可持续性问题。

**AI_Comments:** 该论文的创新之处在于提出了一个具体的、可操作的协议，以解决组织数字实践的生态重定向问题，填补了现有研究中方法论缺失的空白。其重要性在于，它不仅关注技术手段，更强调通过仲裁和放弃来促进可持续性，这对于推动社会走向更可持续的数字化未来具有指导意义。该协议通过实证研究进行验证，增强了其潜在的实用性和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 数字化社会引发了对其可持续性及其产生的社会技术影响的质疑。生态重定向旨在将可持续性作为方向而非技术手段来实现，但目前尚未有具体的实施方法。因此，本论文旨在提出一个协议来支持组织中的利益相关者进行数字实践的生态重定向。

**Method:** 该协议基于多学科调查，首先映射对数字工具的依恋。然后，它旨在提高利益相关者的知识和技能，以准备关于仲裁和放弃的辩论。最后，协议旨在操作化目标数字实践的关闭或转型。该协议将在不同背景下进行真实条件测试，并通过一项实证研究来衡量其流畅性、有效性和社会技术障碍。

**Result:** 本文提出了一项实证研究，旨在衡量协议的流畅性（参与者执行协议的轻松程度）、协议在重定向目标方面的有效性，以及重定向过程中的社会技术障碍。

**Conclusion:** 本论文的结论是，该协议有助于组织更好地理解生态重定向的相关障碍及其变革性目标，从而帮助它们制定大规模和激进的政策，以实现理想和可持续的社会。

> **ai_Abstract:** 本论文提出了一种针对组织数字实践的生态重定向协议。鉴于数字化社会的可持续性问题和现有方法学的缺失，该协议旨在通过多学科调查映射数字工具依恋，提升利益相关者知识和技能以促进关于数字实践取舍的辩论，并最终操作化特定数字实践的关闭或转型。该协议将通过实证研究评估其流畅性、有效性和潜在的社会技术障碍，旨在帮助组织更好地理解和实施可持续的数字转型。

> **摘要翻译:** 社会数字化引发了对其可持续性及其产生的社会技术影响的质疑。应用于组织的生态重定向是一个旨在将可持续性作为方向而非技术手段来实现的研究领域。论文调查了对某些数字使用和技术的仲裁和放弃。然而，生态重定向尚未解决其在组织中实施的具体方法。因此，本论文提出了一种协议，旨在支持利益相关者对其数字实践进行生态重定向。该协议基于通过多学科调查映射对数字工具的依恋。然后，它提出增加利益相关者的知识和技能，以准备关于放弃仲裁的辩论，并最终操作化目标数字实践的关闭/转型。该协议将在不同背景下进行真实条件测试。论文提出了一项实证研究，旨在衡量：1) 参与者执行协议的流畅性，2) 协议在重定向目标方面的有效性，3) 重定向过程中的社会技术障碍。论文总结了该协议对组织潜在的好处，即更好地理解与其生态重定向相关的障碍以及此类协议的变革目标。这将帮助它们制定大规模和激进的政策，以实现理想和可持续的社会。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [24] [Select2Drive: Pragmatic Communications for Real-Time Collaborative Autonomous Driving](https://arxiv.org/abs/2501.12040)
> *Select2Drive：实时协作式自动驾驶的实用通信*

*Jiahao Huang, Jianhang Zhu, Rongpeng Li, Zhifeng Zhao, Honggang Zhang* | **Category: cs.CE** | **Updated: 2025-07-24**

**Keywords:** 协作式自动驾驶, 实用通信, 分布式预测感知, 资源优化, V2X

**Comment:** 

> **TL;DR:** Select2Drive是一个为自动驾驶设计的框架，它通过分布式预测感知和基于兴趣区域的实用通信，优化了有限的计算和通信资源，提升了感知、决策和驾驶性能。

**AI_Comments:** 该论文的创新点在于结合了分布式预测感知和基于兴趣区域的实用通信，以解决协作式自动驾驶中资源受限和延迟累积的问题。通过关注“少即是多”的原则，它有效地优化了通信负载，并提升了决策质量。其在实际数据集上的验证增加了研究的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动驾驶系统面临计算和通信资源有限的问题，并且协作感知和决策中的累积延迟是一个挑战。

**Method:** 本文提出了Select2Drive框架，旨在优化有限的计算和通信资源利用。该框架通过引入分布式预测感知来减轻感知和决策中的累积延迟，并将高维语义特征预测简化为计算成本高效、运动感知的重建。此外，Select2Drive利用基于兴趣区域的实用通信（PragComm）优先处理关键区域的通信，从而提高通信效率和决策效率。

**Result:** 在V2Xverse和DAIR-V2X数据集上的实证评估表明，Select2Drive在有限带宽下（姿态误差条件下）的离线感知任务中分别实现了2.60%和1.99%的改进。此外，它在闭环驾驶分数和路线完成率方面分别提供了至多8.35%和2.65%的增强，特别是在交通密集和高速动态的场景中。

**Conclusion:** Select2Drive通过优化资源利用和通信策略，显著提升了协作式自动驾驶的感知、决策和整体驾驶性能，特别是在资源受限和复杂场景下表现突出。

> **ai_Abstract:** 本文提出了Select2Drive框架，旨在优化协作式自动驾驶中有限的计算和通信资源利用。该框架通过引入分布式预测感知来减轻感知和决策中的累积延迟，并通过将高维语义特征预测简化为运动感知的重建。此外，Select2Drive利用基于兴趣区域的实用通信，优先传输关键区域数据，从而提升通信和决策效率。实验结果表明，Select2Drive在感知准确性、闭环驾驶分数和路线完成率方面均有显著提升，尤其适用于资源受限和复杂交通场景。

> **摘要翻译:** 车联网通信辅助的自动驾驶近年来取得了显著进展，其中实用通信（PragComm）作为一种有前景的范式，用于车辆和其他代理之间的实时协作。同时，广泛的研究探索了端到端驾驶框架中协作感知和决策之间的相互作用。在这项工作中，我们重新审视了协作驾驶问题，并提出了Select2Drive框架，以优化有限的计算和通信资源的利用。特别是，为了减轻感知和决策中的累积延迟，Select2Drive通过制定主动预测范式引入了分布式预测感知，并将高维语义特征预测简化为计算成本高效、运动感知的重建。鉴于“少即是多”的原则，即过度扩展的感知视野可能会混淆决策模块而不是对其有所贡献，Select2Drive利用基于兴趣区域的实用通信来优先处理关键区域的通信，从而提高通信效率和决策效率。在V2Xverse和真实世界DAIR-V2X上的实证评估表明，Select2Drive在有限带宽下（姿态误差条件下）的离线感知任务中分别实现了2.60%和1.99%的改进。此外，它在闭环驾驶分数和路线完成率方面分别提供了至多8.35%和2.65%的增强，特别是在交通密集和高速动态的场景中。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [66] [Agentar-DeepFinance-100K: A Large-Scale Financial Dataset via Systematic Chain-of-Thought Synthesis Optimization](https://arxiv.org/abs/2507.12901)
> *Agentar-DeepFinance-100K：通过系统化思维链合成优化构建的大规模金融数据集*

*Xiaoke Zhao, Zhaowen Zhou, Lin Chen, Lihong Wang, Zhiyi Huang, Kaiyuan Zheng, Yanjun Zheng, Xiyang Du, Longfei Liao, Jiawei Liu, Xiang Qi, Bo Zhang, Peng Zhang, Wei Wang, Zhe Li* | **Category: cs.CE** | **Updated: 2025-07-24**

**Keywords:** 金融数据集, 思维链, 大语言模型, 金融推理, Agentar-DeepFinance-100K

**Comment:** 

> **TL;DR:** Agentar-DeepFinance-100K是一个大规模金融推理数据集，它通过多视角知识提取和自我修正重写优化了思维链合成，并分析了影响思维链有效性的因素，显著提升了金融基准测试的表现。

**AI_Comments:** 该论文通过提出Agentar-DeepFinance-100K数据集，创新性地解决了现有思维链（CoT）合成在金融领域深度不足的问题。其引入的多视角知识提取（MKE）和自我修正重写（SCR）管道，以及对CoT有效性因素的系统性分析（CoT Cube），为构建高质量的金融推理数据提供了宝贵的框架。该数据集的发布有望显著推动金融领域大型语言模型的应用和研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型在金融领域应用潜力巨大，但现有的思维链（CoT）合成方法存在CoT采样深度不足的问题，且尚未充分探索如何构建设计良好的金融推理知识空间。

**Method:** 本文提出了Agentar-DeepFinance-100K数据集，其特点是系统化的CoT合成优化。首先引入了一个全面的CoT合成管道，包括多视角知识提取（MKE）和自我修正重写（SCR），以生成详尽且深入的金融推理轨迹。其次，进行了名为“CoT Cube”的系统性研究，分析了影响CoT有效性的关键因素（如必要性、长度和合成器），为高质量金融CoT的构建提供了有价值的见解。

**Result:** 在Agentar-DeepFinance-100K数据集上训练的模型在金融基准测试中取得了显著改进。

**Conclusion:** Agentar-DeepFinance-100K数据集及其系统化思维链合成优化方法，为金融推理模型的研究提供了高质量的数据和有价值的见解，并显著提升了模型在金融任务上的表现。

> **ai_Abstract:** 本文介绍了Agentar-DeepFinance-100K，一个通过系统化思维链（CoT）合成优化构建的大规模金融推理数据集。该数据集通过多视角知识提取（MKE）和自我修正重写（SCR）管道生成深入的金融推理轨迹，并对CoT的有效性因素进行了“CoT Cube”研究。实验证明，基于此数据集训练的模型在金融基准测试中表现出显著提升。

> **摘要翻译:** 大型语言模型（LLMs）最近的进展展示了卓越的通用推理能力，在金融领域具有巨大的应用潜力，该领域需要稳健可靠的推理。事实证明，从先进的通用推理模型中提炼高质量的思维链（CoT）原理为金融推理模型提供了一条有前景且高效的途径。然而，现有的CoT合成方法存在CoT采样深度不足的问题，如何构建一个设计良好的金融推理知识空间仍未被探索。在本文中，我们提出了Agentar-DeepFinance-100K，一个以系统化CoT合成优化为特征的大规模金融推理数据集。我们首先引入了一个全面的CoT合成管道，包括多视角知识提取（MKE）和自我修正重写（SCR），以生成详尽且深入的金融推理轨迹。此外，还进行了一项名为CoT Cube的系统性调查，分析了影响CoT有效性的关键因素，例如必要性、长度和合成器，为高质量金融CoT的构建提供了有价值的见解。实验表明，在我们的Agentar-DeepFinance-100K上训练的模型在金融基准测试中取得了显著改进。我们公开发布Agentar-DeepFinance-100K，希望能够推动金融推理模型的研究。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [768] [Digital Twin Technologies in Predictive Maintenance: Enabling Transferability via Sim-to-Real and Real-to-Sim Transfer](https://arxiv.org/abs/2507.18449)
> *预测性维护中的数字孪生技术：通过虚实和实虚转换实现可迁移性*

*Sizhe Ma, Katherine A. Flanigan, Mario Bergés* | **Category: cs.CE, cs.AI, cs.CY, cs.LG** | **Updated: 2025-05-15**

**Keywords:** 数字孪生, 预测性维护, 虚实转换, 实虚转换, 现实差距分析

**Comment:** Accepted and presented at 2024 ASCE International Conference on
  Computing in Civil Engineering (i3CE 2024)

> **TL;DR:** 本文研究了在数字孪生框架中集成“现实差距分析（RGA）”模块，以实现模拟和真实世界操作之间的双向知识迁移，从而解决可迁移性挑战。

**AI_Comments:** 这篇论文的创新点在于提出了“现实差距分析（RGA）”模块的概念，并将其集成到数字孪生框架中，以系统性地解决虚实和实虚知识迁移中的“现实差距”问题。这对于数字孪生在预测性维护等工业应用中的推广和标准化具有重要意义，因为它直接解决了模型在真实世界中应用时的准确性和适应性问题。该方法不仅考虑了单向的知识转移，还强调了双向反馈的重要性，这对于实现数字孪生的全面生命周期管理至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 尽管数字孪生技术已从概念走向现实，但由于缺乏标准化框架，其从学术界到工业界的过渡复杂。现有数字孪生研究主要关注资产迁移，而模拟与真实操作之间的知识迁移（虚实转换和实虚转换）对于数字孪生中的全面生命周期管理至关重要。其中一个关键挑战是校准“现实差距”。

**Method:** 本研究通过将单个“现实差距分析（RGA）”模块集成到现有数字孪生框架中，并利用数据管道将其与历史存储库和仿真模型连接，来管理虚实和实虚转换。通过卡内基梅隆大学一座人行天桥的案例研究，展示了该方法与现有框架不同集成水平的性能。

**Result:** 通过完全实施RGA模块和完整的数据管道，该方法能够在不影响效率的情况下，实现模拟和真实世界操作之间的双向知识迁移。

**Conclusion:** 通过集成RGA模块和建立完整的数据管道，可以有效弥合数字孪生中的“现实差距”，实现模拟与真实世界之间的知识双向高效迁移，从而增强数字孪生的可迁移性。

> **ai_Abstract:** 本文探讨了在数字孪生（DT）中实现可迁移性的关键挑战，特别是模拟与真实世界操作之间的知识转移（虚实转换和实虚转换）。为解决模拟预测与实际结果之间的“现实差距”，研究提出并验证了将单个“现实差距分析（RGA）”模块集成到现有DT框架中的方法。通过数据管道连接RGA模块与历史数据和仿真模型，案例研究表明，该方法能够高效地实现模拟与真实世界之间的双向知识迁移。

> **摘要翻译:** 物联网（IoT）和人工智能的进步促使数字孪生（DTs）从概念性想法演变为更可实现的现实。然而，由于缺乏标准化框架，从学术界向工业界的过渡是复杂的。本文基于作者先前建立的支持标准化数字孪生开发的功能和信息要求，重点关注一个关键方面：可迁移性。虽然现有数字孪生研究主要集中于资产迁移，但“虚实转换”（sim-to-real transfer）和“实虚转换”（real-to-sim transfer）——即在模拟和真实世界操作之间转移知识——对于数字孪生中的全面生命周期管理至关重要。在此过程中，一个关键挑战是校准“现实差距”，即模拟预测与实际结果之间的差异。我们的研究调查了将单个现实差距分析（RGA）模块集成到现有数字孪生框架中，以有效管理虚实转换和实虚转换的影响。这种集成通过数据管道实现，这些数据管道将RGA模块与数字孪生框架的现有组件（包括历史存储库和仿真模型）连接起来。卡内基梅隆大学一座人行天桥的案例研究展示了我们方法与现有框架不同集成水平的性能。通过RGA模块的全面实施和完整的数据管道，我们的方法能够在不影响效率的情况下，实现模拟和真实世界操作之间的双向知识转移。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='csfl'></a>
## cs.FL 

### [115] [Time for Quiescence: Modelling quiescent behaviour in testing via time-outs in timed automata](https://arxiv.org/abs/2507.18205)
> *静止时间：通过定时自动机中的超时建模测试中的静止行为*

*Laura Brandán Briones, Marcus Gerhold, Petra van den Bos, Mariëlle Stoelinga* | **Category: cs.FL** | **Updated: 2025-07-24**

**Keywords:** 基于模型的测试, 静止行为, 定时自动机, 超时, 标签迁移系统

**Comment:** 

> **TL;DR:** 本文提出一种提升算子，通过引入单个时钟和超时机制，在不增加定时自动机复杂性的情况下，为基于模型的测试中的静止行为建模提供形式化基础，并证明了其与现有测试一致性理论的等价性。

**AI_Comments:** 这篇论文通过引入一个巧妙的“提升算子”，有效地解决了基于模型测试中处理静止行为的实际挑战，同时避免了使用复杂定时自动机的开销。其创新之处在于将工业界常用的超时机制形式化，并证明了其与现有测试理论的兼容性和等价性，这对于弥合理论与实践之间的鸿沟具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在实践中，基于模型的测试（MBT）使用简单的模型（如LTS）来派生测试套件。然而，为了处理静止（即可观察输出的缺失），需要设置一个超时来判断静止。虽然存在定时MBT，但它通常依赖于定时自动机（TA）的全部功能，这可能过于复杂。因此，需要一种更简单有效的方法来形式化地处理测试中的静止行为。

**Method:** 本文提出了一种“提升算子”$\chi^{\scriptstyle M}\!$，它在不增加定时自动机（TA）开销的情况下，为LTS添加了时间。给定一个LTS，$\chi^{\scriptstyle M}\!$引入了一个单一的时钟，用于用户选择的时间边界$M>0$来声明静止。在定时自动机中，该时钟用于建模输出应在时钟达到值$M$之前发生，而静止恰好在时间$M$发生。这种方法为工业实践中选择超时来判断静止提供了形式化基础。

**Result:** 1. 当且仅当实现其提升版本在定时$\mathbf{tioco_M}$下一致时，实现才在$\mathbf{ioco}$下一致。
2. 在标准$\mathbf{ioco}$测试生成算法之前或之后应用$\chi^{\scriptstyle M}\!$会产生相同的测试集。
3. 提升的TA测试套件和原始LTS测试套件对每个实现都提供相同的判断。

**Conclusion:** 本文通过引入一个简单的提升算子，为基于模型的测试中通过超时处理静止行为提供了形式化基础，并证明了其与现有测试一致性理论的等价性，从而为工业实践提供了理论支持。

> **ai_Abstract:** 本文针对基于模型的测试（MBT）中处理静止行为的挑战，提出了一种名为$\chi^{\scriptstyle M}\!$的提升算子。该算子通过为带标签的迁移系统（LTS）引入一个单一时钟和用户定义的超时$M$，在不增加定时自动机（TA）复杂性的前提下，形式化地建模了测试中的静止行为。研究证明，该方法与现有的测试一致性理论（如$\mathbf{ioco}$）具有等价性，并且在测试生成和判断方面保持一致性，为工业实践中通过超时判断静止提供了坚实的理论基础。

> **摘要翻译:** 基于模型的测试（MBT）从被测系统的行为规范中派生测试套件。在实践中，工程师倾向于使用简单的模型，例如带标签的迁移系统（LTS）。然而，为了在实践中处理静止——即可观察输出的缺失——需要设置一个超时来判断静止。定时MBT虽然存在，但它通常依赖于定时自动机（TA）的全部功能。
我们提出了一种提升算子$\chi^{\scriptstyle M}\!$，它在不增加TA开销的情况下添加了时间：给定一个LTS，$\chi^{\scriptstyle M}\!$引入了一个单一的时钟，用于用户选择的时间边界$M>0$来声明静止。在定时自动机中，该时钟用于建模输出应在时钟达到值$M$之前发生，而静止恰好在时间$M$发生。通过这种方式，我们为工业实践中选择超时来判断静止提供了形式化基础。我们的贡献有三方面：（1）当且仅当实现其提升版本在定时$\mathbf{tioco_M}$下一致时，实现才在$\mathbf{ioco}$下一致；（2）在标准$\mathbf{ioco}$测试生成算法之前或之后应用$\chi^{\scriptstyle M}\!$会产生相同的测试集；（3）提升的TA测试套件和原始LTS测试套件对每个实现都提供相同的判断。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [157] [The complexity of reachability problems in strongly connected finite automata](https://arxiv.org/abs/2504.13784)
> *强连通有限自动机中可达性问题的复杂性*

*Stefan Kiefer, Andrew Ryzhikov* | **Category: cs.FL** | **Updated: 2025-07-23**

**Keywords:** 有限自动机, 可达性问题, 计算复杂度, NL完全, 强连通

**Comment:** To appear in MFCS 2025

> **TL;DR:** 本文从计算复杂度的角度探讨了强连通有限自动机中可达性问题的存在性，并提出了一种通用技术，证明了几个NL完全问题在强连通情况下仍然是NL完全的。

**AI_Comments:** 本文的创新之处在于提出了一种通用技术，证明了在强连通这种特殊且在应用中常见的有限自动机条件下，一些重要的可达性问题（对应于矩阵的消亡性和遍历性）仍然保持其原有的NL完全计算复杂度。这对于理解这些问题的内在复杂性及其在受限条件下的行为具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 有限自动机中的若干可达性问题（如NFA的完备性和全DFA的同步性）对应于非负矩阵集合的基本性质。特别是，上述两种性质分别对应于矩阵的消亡性和遍历性。强连通的情况在应用中频繁出现，并且通常比一般情况具有更好的性质，因此需要从计算复杂度的角度来研究其存在性。

**Method:** 开发了一种通用技术，用于证明几个NL完全问题在强连通情况下仍然是NL完全的。

**Result:** 研究表明，即使承诺是强连通的，判断二元全DFA是否同步仍然是NL完全的；在相同承诺下，判断具有非常有限非确定性的二元无歧义NFA的完备性也是NL完全的。

**Conclusion:** 在强连通有限自动机中，某些与矩阵消亡性和遍历性相关的NL完全可达性问题，即使在特定限制条件下，其计算复杂度仍然保持NL完全。

> **ai_Abstract:** 本文从计算复杂度的角度研究了强连通有限自动机中的可达性问题，这些问题与非负矩阵的消亡性和遍历性相关。研究提出了一种通用技术，证明了在强连通情况下，多个NL完全问题（如二元全DFA的同步性和二元无歧义NFA的完备性）的计算复杂度仍然保持NL完全。

> **摘要翻译:** 有限自动机中的若干可达性问题，例如NFA的完备性和全DFA的同步性，对应于非负矩阵集合的基本性质。特别是，上述两种性质分别对应于矩阵的消亡性（mortality）和遍历性（ergodicity），它们询问是否存在输入矩阵的乘积分别等于零矩阵和一列仅包含严格正项的矩阵。当输入自动机是强连通的（即对应的非负矩阵集合是不可约的）情况，在应用中频繁出现，并且通常比一般情况具有更好的性质。在本文中，我们从计算复杂度的角度探讨了此类性质的存在性，并开发了一种通用技术，以表明几个NL完全问题在强连通情况下仍然是NL完全的。特别是，我们证明了即使承诺是强连通的，判断二元全DFA是否同步仍然是NL完全的，并且在相同承诺下，判断具有非常有限非确定性的二元无歧义NFA的完备性也是NL完全的。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [199] [Chance and Mass Interpretations of Probabilities in Markov Decision Processes (Extended Version)](https://arxiv.org/abs/2506.10377)
> *马尔可夫决策过程（扩展版）中概率的几率和质量解释*

*Yun Chen Tsai, Kittiphon Phalakarn, S. Akshay, Ichiro Hasuo* | **Category: cs.FL** | **Updated: 2025-07-24**

**Keywords:** 马尔可夫决策过程, 概率解释, 统一语义, 可达性问题, 几率-质量分类器

**Comment:** To appear at CONCUR'25

> **TL;DR:** 本文提出了一个统一的语义框架，整合了马尔可夫决策过程（MDPs）中概率的两种现有解释（状态转换器和分布转换器）以及两种新解释，并研究了新语义下的可达性问题。

**AI_Comments:** 本文的创新之处在于提出了一个统一的语义框架，能够整合并扩展马尔可夫决策过程（MDPs）中概率的不同解释方式。通过引入“几率和质量解释”以及“几率-质量（CM）分类器”，该工作为理解和分析MDPs提供了更全面和系统化的视角。此外，对新语义下可达性问题的研究及其算法贡献，也为MDPs的实际应用和验证提供了有价值的工具。

<details>
  <summary>Details</summary>

**Motivation:** 传统的马尔可夫决策过程（MDPs）在验证中通常被视为状态转换器，概率定义在状态序列上，调度器进行随机选择。然而，另一种视图（特别适合建模动态系统）将MDPs定义为分布转换器。本文旨在提供一个统一的语义框架来整合这两种现有视图以及引入两种新的视图，以更好地理解MDPs中概率的不同解释。

**Method:** 本文通过识别MDP中随机性的不同来源（调度器、配置和转换）并提供不同的概率解释方式（称为几率解释和质量解释），自然地推导出了MDP的四种语义。这些语义通过一种称为几率-质量（CM）分类器的数学构造系统地统一起来。此外，本文还研究了其中两种新语义下的可达性问题，并提供了两种算法来解决它们。

**Result:** 通过识别随机性来源和解释方式，自然地产生了MDP的四种语义。这些语义通过几率-质量（CM）分类器得到了系统性的统一。对于两种新的语义，可达性问题被证明是困难的，并提供了相应的解决算法。

**Conclusion:** 本文成功地提出了一个统一的语义框架，能够容纳马尔可夫决策过程（MDPs）中概率的现有和新的解释。通过几率-质量（CM）分类器，这些不同的语义得到了系统性的整合，并且对新语义下的可达性问题进行了深入研究，提供了硬度证明和解决方案。

> **ai_Abstract:** 本文提出了一个统一的语义框架，旨在整合马尔可夫决策过程（MDPs）中概率的不同解释。通过识别随机性来源（调度器、配置、转换）和两种解释方式（几率和质量），该框架自然地导出了四种MDP语义，并通过几率-质量（CM）分类器进行了系统性统一。此外，论文还研究了其中两种新语义下的可达性问题，证明了其复杂性并提出了相应的解决算法。

> **摘要翻译:** 马尔可夫决策过程（MDPs）是在不确定性下进行决策的流行模型。验证中MDP的传统观点将其视为状态转换器，其中概率定义在状态序列上，调度器进行随机选择。另一种观点，特别适合建模动态系统，将MDPs定义为分布转换器，调度器分配概率质量。我们的主要贡献是一个统一的语义框架，该框架容纳了这两种观点以及两种新的观点。MDP的这四种语义通过识别MDP中随机性的不同来源（即调度器、配置和转换）并提供不同的概率解释方式（称为几率和质量解释）自然产生。这些语义通过一种称为几率-质量（CM）分类器的数学构造系统地统一起来。作为另一个主要贡献，我们研究了两种新语义中的每一种的可达性问题，证明了它们的难度并提供了两种解决它们的算法。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [99] [Rapid Modeling Architecture for Lightweight Simulator to Accelerate and Improve Decision Making for Industrial Systems](https://arxiv.org/abs/2507.17990)
> *工业系统轻量级仿真器的快速建模架构，以加速和改进决策*

*Takumi Kato, Zhi Li Hu* | **Category: eess.SY, cs.MA, cs.RO, cs.SY** | **Updated: 2025-07-23**

**Keywords:** 快速建模架构, 轻量级仿真器, 工业系统, 决策支持, 建模时间减少

**Comment:** 8 pages, 13 figures. Manuscript accepted at the 2025 IEEE 21st
  International Conference on Automation Science and Engineering (CASE 2025)

> **TL;DR:** 提出了一种快速建模架构（RMA），用于轻量级工业仿真器，可显著缩短建模时间（减少78.3%），从而加速和改进工业系统设计中的决策。

**AI_Comments:** 这篇论文的创新点在于提出了快速建模架构（RMA），有效解决了工业系统早期设计阶段仿真建模效率低下的痛点。通过显著缩短建模时间，RMA使得仿真工具能更好地支持快速迭代和优化决策，对于提高工业系统设计的敏捷性和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在工业系统（如配送中心和制造工厂）的早期设计阶段，决策者信息有限，导致设计精度不足且后期难以纠正。尽管仿真器能有效发现问题，但传统仿真器建模耗时过长，无法满足快速决策的需求。

**Method:** 论文提出了一种快速建模架构（RMA），用于构建轻量级工业仿真器。该架构旨在减轻建模负担，同时保留必要细节，以加速和改进决策。研究人员基于RMA原型化了一个仿真器，并将其应用于实际工厂布局设计问题，并与现有仿真器进行了建模时间比较。

**Result:** 与传统仿真器相比，基于RMA的仿真器在建模时间上实现了78.3%的显著减少。

**Conclusion:** 快速建模架构（RMA）能有效降低工业仿真器的建模时间，从而显著加速和改进工业系统设计中的决策过程。

> **ai_Abstract:** 本文提出了一种名为快速建模架构（RMA）的新方法，旨在解决传统工业仿真器建模时间过长的问题。RMA能够为轻量级工业仿真器在保留关键细节的同时减轻建模负担，从而加速和改进工业系统设计中的决策。通过原型化并应用于实际工厂布局设计问题，RMA仿真器与传统仿真器相比，建模时间减少了78.3%。

> **摘要翻译:** 设计工业系统，例如建造、改进和自动化配送中心和制造工厂，涉及在早期阶段信息有限情况下的关键决策。信息不足导致系统设计精度较低，这些问题通常难以在后期解决。使用仿真器对设计系统进行建模并及早发现问题是有效的。然而，传统仿真器所需的建模时间过长，无法实现快速模型创建以满足决策需求。在本文中，我们提出了一种用于轻量级工业仿真器的快速建模架构（RMA），它在保持必要细节的同时减轻了建模负担，以加速和改进决策。我们基于RMA原型化了一个仿真器，并将其应用于实际工厂布局设计问题。我们还将我们的仿真器与现有仿真器的建模时间进行了比较，结果显示，与传统仿真器相比，我们的仿真器建模时间减少了78.3%。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [206] [Safe Reinforcement Learning-based Automatic Generation Control](https://arxiv.org/abs/2507.17868)
> *基于安全强化学习的自动发电控制*

*Amr S. Mohamed, Emily Nguyen, Deepa Kundur* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-23**

**Keywords:** 安全强化学习, 自动发电控制, 控制障碍函数, 电力系统

**Comment:** 5 pages, conference: IEEE Power and Energy Systems General Meeting
  2025

> **TL;DR:** 本文提出了一种基于控制障碍函数的框架，用于在自动发电控制中实现强化学习智能体的安全学习和部署，以解决机器学习在电力系统控制中缺乏安全保证的问题。

**AI_Comments:** 本文的创新之处在于将控制障碍函数引入强化学习，以解决机器学习在电力系统等关键应用中安全性不足的问题。这对于促进强化学习在需要高可靠性领域的实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在电力系统中，对先进控制和决策算法的需求日益增长，以提高系统的可靠性、弹性和稳定性。然而，应用机器学习技术进行控制决策时，其安全性是一个关键问题，因为这些方法通常缺乏安全保证。

**Method:** 本文提出了一种基于控制障碍函数（Control Barrier Functions）的框架，旨在促进强化学习智能体在电力系统控制应用（特别是自动发电控制）中的安全学习和部署。

**Result:** 本文开发了必要的安全障碍和强化学习框架，以在自动发电控制中建立对强化学习作为安全选项的信任。

**Conclusion:** 本文为未来详细的验证和应用研究奠定了基础，表明强化学习可以作为自动发电控制的安全选项。

> **ai_Abstract:** 本文针对电力系统控制中机器学习方法缺乏安全保证的问题，提出了一种基于控制障碍函数的框架。该框架旨在实现强化学习智能体在自动发电控制中的安全学习与部署，从而在关键电力应用中建立对强化学习作为安全选项的信任，并为未来的深入研究奠定基础。

> **摘要翻译:** 在对实施先进控制和决策算法的需求日益增长，以增强电力系统的可靠性、弹性和稳定性之际，采用机器学习技术的安全性问题成为一个关键关注点。尽管这些方法可以用于得出更优的控制决策，但它们往往缺乏安全保证。本文提出了一种基于控制障碍函数（control barrier functions）的框架，旨在促进强化学习智能体在电力系统控制应用（特别是自动发电控制）中的安全学习和部署。我们开发了必要的安全障碍和强化学习框架，以在自动发电控制中建立对强化学习作为安全选项的信任——这为未来详细的验证和应用研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [235] [A software framework for stochastic model predictive control of nonlinear continuous-time systems (GRAMPC-S)](https://arxiv.org/abs/2407.09261)
> *非线性连续时间系统随机模型预测控制的软件框架 (GRAMPC-S)*

*Daniel Landgraf, Andreas Völz, Knut Graichen* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 随机模型预测控制, 非线性系统, 不确定性传播, 高斯过程回归, 开源

**Comment:** This preprint has not undergone peer review or any post-submission
  improvements or corrections. The Version of Record of this article is
  published in Optimization and Engineering, and is available online at
  https://doi.org/10.1007/s11081-025-10006-z

> **TL;DR:** GRAMPC-S是一个开源的随机MPC框架，用于控制具有机会约束的非线性不确定系统，并能在毫秒级采样时间下实际应用。

**AI_Comments:** 该论文提出GRAMPC-S，一个开源的随机模型预测控制框架，其创新点在于结合了多种不确定性传播方法和高斯过程回归来处理不确定性，并将随机问题转化为确定性问题求解。其重要性在于，它使得随机MPC在非线性不确定系统控制中实现毫秒级采样时间的实际应用成为可能，具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 提供一个用于非线性不确定系统随机模型预测控制的开源框架，以应对实际应用中不确定性的挑战。

**Method:** 该框架采用多种不确定性传播方法来预测系统状态的随机矩，并利用高斯过程回归处理系统动力学的未知部分。它将随机MPC公式重构为确定性公式，并通过GRAMPC求解。

**Result:** 实验评估表明，GRAMPC-S可以用于实际控制非线性不确定系统，且采样时间在毫秒范围内。

**Conclusion:** GRAMPC-S是一个实用的框架，可用于在毫秒级采样时间下控制非线性不确定系统。

> **ai_Abstract:** 本文介绍了GRAMPC-S，一个针对具有机会约束的非线性不确定系统的开源随机模型预测控制框架。它整合了多种不确定性传播方法和高斯过程回归，将随机MPC问题转化为确定性问题并由GRAMPC求解。通过广泛的实验验证，GRAMPC-S被证明能在毫秒级采样时间下有效地应用于实际的非线性不确定系统控制。

> **摘要翻译:** 本文提出了用于具有机会约束的非线性不确定系统的开源随机模型预测控制框架 GRAMPC-S。它提供了几种不确定性传播方法来预测系统状态的随机矩，并且可以使用高斯过程回归考虑系统动力学的未知部分。这些方法用于将随机MPC公式重新表述为确定性公式，然后通过 GRAMPC 求解。所提出的框架的性能通过来自广泛技术领域的示例进行了评估。实验评估表明，GRAMPC-S 可以在毫秒级采样时间下用于非线性不确定系统控制的实际应用。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [241] [Trusted Data Fusion, Multi-Agent Autonomy, Autonomous Vehicles](https://arxiv.org/abs/2507.17875)
> *信任数据融合、多智能体自主性、自动驾驶汽车*

*R. Spencer Hallyburton, Miroslav Pajic* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-23**

**Keywords:** 信任框架, 多智能体系统, 传感器融合, 隐马尔可夫模型, 无人机

**Comment:** 

> **TL;DR:** 本文提出了一种基于信任的框架，利用隐马尔可夫模型（HMM）在分布式多智能体网络中进行可靠的传感器融合，以应对网络安全攻击，并在案例研究中展示了其在情报、监视和侦察（ISR）性能方面的提升以及恶意行为者检测能力。

**AI_Comments:** 该论文的创新点在于提出了一个基于隐马尔可夫模型（HMM）的信任框架，用于分布式多智能体网络中的可靠传感器融合，有效解决了去中心化网络面临的网络物理攻击问题。通过优先处理可信数据源，增强了系统在对抗环境下的鲁棒性和准确性。此外，利用虚幻引擎模拟器构建新型数据集进行评估，为研究提供了实际且可控的测试环境，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 多智能体无人机（UAV）特设网络在情报、监视和侦察（ISR）任务中共享实时数据，但由于其分散性，面临安全挑战，易受网络物理攻击。本研究旨在解决这些安全漏洞，确保分布式多智能体网络中的传感器融合可信。

**Method:** 本文引入了一个基于信任的框架，用于分布式多智能体网络中的可靠传感器融合。该框架利用隐马尔可夫模型（HMM）来分散地估计智能体及其提供信息的信任度。为了评估在系统/任务感知攻击下的可靠传感器融合，研究人员构建了一个基于虚幻引擎模拟器的新型多智能体空中数据集。

**Result:** 通过案例研究，该框架展示了改进的情报、监视和侦察（ISR）性能，并能够在对抗环境中检测恶意行为者。

**Conclusion:** 该研究提出的基于信任的框架通过隐马尔可夫模型实现可靠的传感器融合，有效提升了多智能体网络在对抗环境中的ISR性能和对恶意行为者的检测能力，从而增强了系统的弹性和准确性。

> **ai_Abstract:** 本文针对分布式多智能体无人机网络在ISR任务中面临的网络安全威胁，提出了一种基于信任的传感器融合框架。该框架利用隐马尔可夫模型（HMM）分散评估智能体及其数据的可信度，并优先融合来自可靠源的数据，以增强系统在对抗环境中的弹性和准确性。研究还构建了一个基于虚幻引擎的新型数据集进行评估，并通过案例研究验证了其在提升ISR性能和检测恶意行为者方面的有效性。

> **摘要翻译:** 多智能体协作增强了情报、监视和侦察（ISR）任务中的态势感知。无人机（UAV）特设网络允许实时数据共享，但由于其分散性，面临安全挑战，使其容易受到网络物理攻击。本文引入了一个基于信任的框架，用于分布式多智能体网络中可靠的传感器融合，利用基于隐马尔可夫模型（HMM）的方法，以分散方式估计智能体及其提供信息的信任度。信任感知的数据融合优先融合来自可靠来源的数据，从而增强了对抗环境中的弹性和准确性。为了评估在系统/任务感知攻击下的可靠传感器融合，我们提出了一个基于虚幻引擎模拟器构建的新型多智能体空中数据集。我们通过案例研究证明了改进的ISR性能以及在对抗环境中检测恶意行为者的能力。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [276] [Quantitative Damping Calculation and Compensation Method for Global Stability Improvement of Inverter-Based Systems](https://arxiv.org/abs/2507.18001)
> *基于逆变器系统的全局稳定性改进的定量阻尼计算与补偿方法*

*Yang Li, Zenghui Zheng, Xiangyang Wu, Jiayong Li, Wei Wang, Qiang Zeng, Zhikang Shuai* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 阻尼计算, 稳定性, 逆变器系统, 阻尼补偿, 小信号稳定性

**Comment:** 

> **TL;DR:** 本文提出了一种定量阻尼计算和补偿方法，以有效提高基于逆变器系统的全局稳定性。

**AI_Comments:** 本文的创新点在于提出了定量阻尼计算方法，明确了所需的阻尼补偿量和位置，并结合特殊的AD控制策略提高了阻尼效率，为解决逆变器系统稳定性问题提供了实用的解决方案。其重要性在于解决了现有研究中未明确的精确阻尼补偿量问题。

<details>
  <summary>Details</summary>

**Motivation:** 多逆变器系统中小信号稳定性问题引起的宽带振荡对系统安全运行构成严重威胁。研究表明系统不稳定是由于缺乏正阻尼，但目前尚未明确确保系统全局稳定性所需的精确阻尼补偿量。

**Method:** 首先，基于系统节点导纳模型，提出了一种定量阻尼计算算法，可以给出足够的稳定性改进所需的阻尼补偿量和补偿位置。然后，提出了一种带有输出电流前馈控制策略的特定AD，使AD呈准纯电阻性，有效提高系统阻尼效率。最后，通过一个包含三个逆变器的测试系统进行案例研究。

**Result:** 案例研究表明，所提出的方法为有效提高基于逆变器系统的全局稳定性提供了一个有前景的解决方案。仿真和实验验证了所提出的方法。

**Conclusion:** 提出的定量阻尼计算和补偿方法能够有效增强基于逆变器系统的全局稳定性。

> **ai_Abstract:** 本文针对多逆变器系统中的小信号稳定性问题，提出了一种定量阻尼计算和补偿方法。该方法首先基于节点导纳模型计算所需的阻尼补偿量和位置，然后提出一种带有输出电流前馈控制的准纯电阻性AD策略以提高阻尼效率。通过三逆变器系统案例研究，验证了该方法能有效提升基于逆变器系统的全局稳定性。

> **摘要翻译:** 小信号稳定性问题引起的宽带振荡对多逆变器系统的安全运行构成重大威胁，吸引了广泛的研究关注。研究表明系统不稳定是由于缺乏正阻尼，但尚未明确指定确保系统全局稳定性所需的精确阻尼补偿量。本文提出了一种可行的定量阻尼计算和补偿解决方案，以增强基于逆变器系统的全局稳定性。首先，基于系统节点导纳模型，提出了一种定量阻尼计算算法，该算法可以建议所需的阻尼补偿以及补偿位置，以充分改善稳定性。然后，我们提出了一种带有输出电流前馈控制策略的特定AD，该策略使AD呈准纯电阻性，并能有效提高系统阻尼效率。最后，以一个包含三个逆变器的测试系统作为案例研究，表明所提出的方法为有效提高基于逆变器系统的全局稳定性提供了一个有前景的解决方案。仿真和实验验证了所提出的方法。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [298] [Integrating and Comparing Radiality Constraints for Optimized Distribution System Reconfiguration](https://arxiv.org/abs/2411.11596)
> *整合并比较用于优化配电系统重构的辐射状约束*

*Pablo Cortes, Alejandra Tabares, Fredy Franco, Astrid Xiomara Rodríguez, David Álvarez-Martínez* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-23**

**Keywords:** 配电系统重构, 辐射状约束, 计算效率, 功率损耗, 优化

**Comment:** 

> **TL;DR:** 本文比较了不同辐射状约束公式在配电系统重构问题中的计算效率，发现选择的约束对计算性能有显著影响。

**AI_Comments:** 本文的创新点在于系统性地比较了多种辐射状约束公式的计算效率，填补了该领域在实践应用指导上的空白。其重要性在于为工程师和研究人员提供了选择最优约束以提高重构算法效率的依据，对于实际配电网络的运行优化具有直接的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 配电系统重构是一个关键的优化问题，旨在通过改变系统拓扑来最小化功率损耗。该问题通常建模为混合整数非线性规划，对于大型网络需要高计算资源，并且需要专门的辐射状约束来保持配电网络的树状结构。

**Method:** 本文对专业文献中提出的不同辐射状约束公式进行了全面的分析，整合并比较了它们相关的计算负担。通过使用一致的硬件和软件设置，在几个知名测试案例中评估了这些约束的性能。

**Result:** 研究结果表明，根据所选的辐射状约束集，计算效率存在显著差异。

**Conclusion:** 这些发现为优化实际配电网络中的重构策略提供了宝贵的见解。

> **ai_Abstract:** 本文针对配电系统重构这一关键优化问题，深入分析并比较了不同辐射状约束公式的计算效率。研究发现，在一致的软硬件环境下，不同约束集的选择对计算性能有显著影响，这为实际配电网络中重构策略的优化提供了重要指导。

> **摘要翻译:** 电力配电系统的重构是一个关键的优化问题，旨在通过操作互连开关改变系统拓扑来最小化功率损耗。这个问题通常被建模为混合整数非线性规划，对于大规模网络需要高计算资源，并且需要专门的辐射状约束来保持配电网络的树状结构。本文提出了一项全面的分析，整合并比较了专业文献中为配电系统重构提出的不同辐射状约束公式所带来的计算负担。通过使用一致的硬件和软件设置，我们评估了这些约束在几个知名测试案例中的性能。我们的研究结果揭示了根据所选辐射状约束集，计算效率存在显著差异，为优化实际配电网络中的重构策略提供了宝贵的见解。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [317] [Carbon Emission Flow Tracing: Fast Algorithm and California Grid Study](https://arxiv.org/abs/2507.18077)
> *碳排放流追踪：快速算法与加州电网研究*

*Yuqing Shen, Yuanyuan Shi, Daniel Kirschen, Yize Chen* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 碳排放追踪, 电网, 最优潮流, 加州电网, 空间排放分析

**Comment:** In Submission, 16 pages, 11 figures, code available at
  https://github.com/yuqing5/Carbon-Tracker-California

> **TL;DR:** 本文提出了一种新颖高效的算法，用于量化电网中节点平均和边际碳排放率，并通过加州电网案例研究验证了其有效性。

**AI_Comments:** 该论文的创新之处在于提出了一种基于图论的计算高效算法，能够精确追踪电网中碳排放的流动，并量化其对不同节点和用户的具体影响。其重要性体现在为电网脱碳提供了关键的分析工具，使系统运营商和政策制定者能够更精细地理解排放的空间和时间分布，从而制定更有效的减排策略。开源其算法和研究数据也极大地促进了未来在电网排放、规划和能源政策领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 随着清洁能源转型，电力系统脱碳成为焦点。尽管系统运营商公开系统级碳排放信息，但发电机排放如何在电网中传输并影响特定位置的电力用户仍不清楚。本研究旨在解决这一问题。

**Method:** 本文提出了一种新颖且计算高效的方法，用于精确量化节点平均和边际碳排放率，适用于交流和直流最优潮流问题。该方法利用基于图的拓扑排序和有向循环去除技术，应用于由发电调度和最优潮流解决方案形成的有向图。通过模拟8,870总线的加州电网并使用实际CAISO数据和CATS模型进行验证。

**Result:** 该算法有效识别了每个发电机对每个节点的贡献，捕捉了排放如何在不同系统条件下空间分布。通过模拟加州电网，该方法准确估计了潮流条件、发电组合和全系统排放，并为加州每个县提供了精细的时空排放分析。研究揭示了现实世界中的位置和时间排放模式。

**Conclusion:** 本文提出的算法和加州研究为未来电网排放、规划、运营和能源政策研究奠定了基础，提供了量化电网中碳排放流动的有效工具。

> **ai_Abstract:** 本文提出了一种新颖且计算高效的算法，用于精确量化电网中节点平均和边际碳排放率。该方法利用图论技术分析发电调度和最优潮流解决方案形成的图，以追踪碳排放流。通过对8,870总线的加州电网进行模拟，并结合实际CAISO数据，验证了该算法在识别发电机贡献、估计潮流条件和提供精细时空排放分析方面的有效性，为电网脱碳和能源政策提供了重要工具。

> **摘要翻译:** 电力系统脱碳是清洁能源转型的焦点。虽然系统运营商和公用事业公司越来越多地公布系统级碳排放信息，但发电机排放如何在电网中传输以及如何影响特定位置的电力用户仍不清楚。本文提出了一种新颖且计算高效的方法，用于精确量化节点平均和边际碳排放率，适用于交流和直流最优潮流问题。该方法利用基于图的拓扑排序和有向循环去除技术，应用于由发电调度和最优潮流解决方案形成的有向图。我们提出的算法有效地识别了每个发电机对每个节点的贡献，捕捉了排放如何在不同系统条件下空间分布。为了验证其有效性并揭示现实世界中的位置和时间排放模式，我们使用实际CAISO数据和CATS模型模拟了8,870总线的真实加州电网。根据从CAISO公共数据获得或估计的节点负荷和可再生发电量的一年小时数据，我们的方法准确估计了潮流条件、发电组合和全系统排放，并为加州每个县提供了精细的时空排放分析。我们的算法和加州研究均已开源，为未来电网排放、规划、运营和能源政策研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [354] [Integrated Learning and Optimization for Congestion Management and Profit Maximization in Real-Time Electricity Market](https://arxiv.org/abs/2412.18003)
> *实时电力市场中拥堵管理与利润最大化的集成学习与优化*

*Imran Pervez, Ricardo Pinto Lima, Omar Knio* | **Category: eess.SY, cs.AI, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 集成学习与优化, 实时电力市场, 经济调度, 直流最优潮流, 线路拥堵

**Comment:** 

> **TL;DR:** 开发了一种集成学习与优化（ILO）方法，用于实时电力市场中的经济调度和最优潮流问题，以有效管理拥堵和最大化经济效益。

**AI_Comments:** 该论文的创新点在于提出了集成学习与优化（ILO）框架，将学习和优化过程紧密结合，以实时适应电力市场中的不确定性（如负载和PTDF）。与传统的顺序学习方法相比，ILO直接针对经济运行目标进行优化，而非仅仅追求预测准确性，这对于实际电力市场运营具有重要意义。该方法有效解决了电力市场中的事后惩罚和线路拥堵问题，为提高电力系统经济效益提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过解决经济调度（ED）和直流最优潮流（DCOPF）问题，改善电力系统的经济运行，并解决电力市场中的事后惩罚和线路拥堵问题。

**Method:** 提出了新颖的集成学习与优化（ILO）方法。该方法将负载作为经济调度（ED）中的未知参数，并将负载和功率传输分布因子（PTDF）矩阵作为直流最优潮流（DCOPF）中的未知参数进行优化。ILO方法通过捕捉实时电力市场和线路拥堵行为来训练后悔函数，进而训练未知负载和PTDF矩阵，以实现减少事后惩罚和线路拥堵的目标。该方法与传统的顺序学习与优化（SLO）方法进行了比较。

**Result:** 实验证明，与顺序学习与优化（SLO）方法相比，所提出的集成学习与优化（ILO）方法在最小化电力市场中的事后惩罚和最小化线路拥堵方面表现出优越性，从而显著改善了经济运行。

**Conclusion:** 集成学习与优化（ILO）方法能够有效解决实时电力市场中的事后惩罚和线路拥堵问题，显著提升电力系统的经济运行效率。

> **ai_Abstract:** 该论文提出了一种新颖的集成学习与优化（ILO）方法，用于解决实时电力市场中的经济调度（ED）和直流最优潮流（DCOPF）问题。该方法将未知负载和功率传输分布因子（PTDF）作为优化参数，并通过训练后悔函数来捕捉市场和线路拥堵行为，旨在最小化事后惩罚和线路拥堵。实验结果表明，与传统的顺序学习与优化（SLO）相比，ILO在改善电力系统经济运行方面表现出显著的优越性。

> **摘要翻译:** 我们开发了新颖的集成学习与优化（ILO）方法，以解决经济调度（ED）和直流最优潮流（DCOPF）问题，从而实现更好的经济运行。经济调度的优化问题将负荷作为未知参数，而直流最优潮流则将负荷和功率传输分布因子（PTDF）矩阵作为未知参数。PTDF 表示由于两个区域之间的有功功率传输而引起的输电线路上有功功率的增量变化。这些值代表了输电线路上功率流的线性化近似。我们开发了新颖的 ILO 公式，利用 ED 和 DCOPF 优化公式来解决电力市场中的事后惩罚和线路拥堵问题。我们提出的方法捕捉了实时电力市场和线路拥堵行为，以训练后悔函数，最终训练不同母线上的未知负荷和线路 PTDF 矩阵，以实现上述事后目标。所提出的方法与顺序学习与优化（SLO）进行了比较，后者训练负荷和 PTDF 预测以提高准确性而非经济运行。我们的实验证明了 ILO 在最小化电力市场中的事后惩罚和最小化线路拥堵方面的优越性，从而显著改善了经济运行。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [360] [Towards Microgrid Resilience Enhancement via Mobile Power Sources and Repair Crews: A Multi-Agent Reinforcement Learning Approach](https://arxiv.org/abs/2507.18095)
> *迈向通过移动电源和抢修队增强微电网弹性：一种多智能体强化学习方法*

*Yi Wang, Dawei Qiu, Fei Teng, Goran Strbac* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 微电网弹性, 移动电源, 抢修队, 多智能体强化学习, 去中心化

**Comment:** 

> **TL;DR:** 本文提出了一种去中心化的分层多智能体强化学习方法，用于在通信受损时协调移动电源和抢修队，以增强微电网弹性。

**AI_Comments:** 本文的创新点在于提出了一个去中心化的分层多智能体强化学习方法，解决了传统集中式调度在通信受损情况下的局限性。这对于提高微电网在极端事件下的韧性具有重要意义。通过结合电力与交通网络的调度决策，并引入嵌入式函数增强学习性能，该研究为未来微电网的弹性运行提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究在集中式框架下解决移动电源和抢修队的协调调度问题，并假设通信网络在事件后仍能完全运行。然而，越来越多的证据表明，某些极端事件会损坏或降级通信基础设施，使得集中式决策变得不切实际，因此需要一个去中心化的解决方案。

**Method:** 本文提出了一个去中心化的框架来解决移动电源和抢修队的弹性驱动调度问题。为解决此问题，提出了一种分层多智能体强化学习方法，该方法包含一个两级框架：高级动作用于在电力和交通网络之间切换决策，低级动作通过混合策略构建，用于计算电力网络中的连续调度决策和交通网络中的离散路由决策。该方法还使用一个封装系统动态的嵌入式函数来增强学习稳定性和可扩展性。

**Result:** 基于IEEE 33节点和69节点电力网络的案例研究验证了所提出方法在负荷恢复方面的有效性。

**Conclusion:** 提出的去中心化分层多智能体强化学习方法能够有效协调移动电源和抢修队，在通信基础设施受损的情况下增强微电网弹性，并通过负荷恢复展示了其有效性。

> **ai_Abstract:** 本文针对极端事件导致通信基础设施受损时，现有集中式协调移动电源（MPS）和抢修队（RC）调度方法失效的问题，提出了一个去中心化的弹性驱动调度框架。为解决此问题，研究提出了一种分层多智能体强化学习方法，该方法包含一个两级决策机制：高级决策用于切换电力与交通网络，低级决策通过混合策略实现连续调度和离散路由。此外，该方法通过嵌入式函数封装系统动态，以提高学习的稳定性和可扩展性。通过IEEE 33节点和69节点电力网络的案例研究，验证了该方法在负荷恢复和增强微电网弹性方面的有效性。

> **摘要翻译:** 移动电源（MPS）因其在处理复杂的电力-交通耦合系统方面的灵活性和移动性，已逐渐部署到微电网中，作为与抢修队（RC）协调以增强弹性的关键资源。然而，以往的工作以集中式方式解决了MPS和RC的协调调度问题，并假设事件发生后通信网络仍能完全运行。然而，越来越多的证据表明，某些极端事件会损坏或降级通信基础设施，这使得集中式决策变得不切实际。为了弥补这一空白，本文在一个去中心化框架中阐述了MPS和RC的弹性驱动调度问题。为解决此问题，本文提出了一种具有两级框架的分层多智能体强化学习方法，其中高级动作用于在电力和交通网络之间切换决策，通过混合策略构建的低级动作分别用于计算电力和交通网络中的连续调度和离散路由决策。所提出的方法还使用一个封装系统动态的嵌入式函数来增强学习稳定性和可扩展性。基于IEEE 33节点和69节点电力网络的案例研究验证了所提出方法在负荷恢复方面的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [363] [GREAT: Grassmannian REcursive Algorithm for Tracking & Online System Identification](https://arxiv.org/abs/2412.09052)
> *GREAT: 格拉斯曼递归跟踪与在线系统辨识算法*

*András Sasfi, Alberto Padoan, Ivan Markovsky, Florian Dörfler* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-07-25**

**Keywords:** 格拉斯曼流形, 在线系统辨识, 时变子空间, 递归算法, 数据驱动控制

**Comment:** Submitted to IEEE Transactions on Automatic Control

> **TL;DR:** 本文提出了一种名为GREAT的在线算法，利用格拉斯曼流形优化来识别时变子空间，并提供了理论收敛保证和不确定性量化。

**AI_Comments:** 这篇论文的创新点在于将格拉斯曼流形优化应用于在线时变子空间识别，并为非参数子空间模型提供了严格的理论收敛保证和不确定性量化，这对于数据驱动控制领域的线性时变系统分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统参数系统模型难以对线性时变系统提供严格保证。近年来，非参数子空间模型在数据驱动控制中受到关注，因其能够为线性时变系统提供严格保证。

**Method:** 所提出的方法利用格拉斯曼流形上的优化，形成了格拉斯曼递归跟踪算法（GREAT）。该算法将子空间视为格拉斯曼流形上的点，并根据在线数据，通过在包含最新数据窗口的成本函数上执行格拉斯曼梯度下降来在线更新子空间估计。

**Result:** 在对在线数据的信噪比和子空间变化率做出适当假设的情况下，该算法被证明具有指数收敛速度，并提供了估计值与真实子空间距离的上限，从而量化了不确定性。算法的适用性通过数值例子得到验证。

**Conclusion:** GREAT算法为在线识别时变子空间提供了一种有效且具有理论保证的方法，解决了线性时变系统建模的难题，对数据驱动控制领域具有重要意义。

> **ai_Abstract:** 本文提出了一种名为GREAT的在线算法，用于识别由线性动力系统定义的时变子空间。该方法利用格拉斯曼流形上的优化，将子空间视为流形上的点，并通过在线数据进行格拉斯曼梯度下降更新。研究证明了在特定条件下算法的指数收敛性，并量化了估计的不确定性。该算法通过数值例子验证了其在数据驱动控制中识别时变线性系统方面的适用性，解决了传统参数模型难以提供严格保证的问题。

> **摘要翻译:** 本文介绍了一种用于识别由线性动力系统定义的时变子空间的在线方法。通过非参数子空间模型表示线性系统的方法最近在数据驱动控制领域引起了极大的兴趣。这种系统表示使我们能够为线性时变系统提供严格的保证，这对于参数系统模型来说很难获得。所提出的方法利用格拉斯曼流形上的优化，从而形成了格拉斯曼递归跟踪算法（GREAT）。我们将子空间视为格拉斯曼流形上的点，并通过在流形上执行优化，根据在线数据调整估计。在每个时间步，从当前子空间获得一个受有界误差影响的单一测量值。子空间估计通过在包含最近数据窗口的成本函数上进行格拉斯曼梯度下降在线更新。在对在线数据的信噪比和子空间变化率做出适当假设的情况下，我们为所得算法建立了理论保证。更具体地说，我们证明了指数收敛速度，并以估计值与真实子空间距离的上限形式提供了不确定性量化。通过数值例子证明了所提出算法的适用性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [397] [Adaptive Self-Improvement for Smarter Energy Systems using Agentic Policy Search](https://arxiv.org/abs/2501.19340)
> *使用代理策略搜索实现智能能源系统的自适应自我改进*

*Alexander Sommer, Peter Bazan, Behnam Babaeian, Jonathan Fellerer, Warren B. Powell, Reinhard German* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-25**

**Keywords:** 代理策略搜索, 大型语言模型, 能源系统, 策略优化, 自我改进

**Comment:** 

> **TL;DR:** Agentic Policy Search (APS) 利用大型语言模型 (LLM) 自动生成和改进能源系统控制策略，实现了显著的经济效益并接近最优解。

**AI_Comments:** 该研究通过将大型语言模型应用于能源系统控制，提出了一种新颖的代理策略搜索框架，其创新性在于利用LLM的生成和推理能力实现策略的自动化设计和自我改进。这不仅简化了传统手动设计策略的复杂性，还显著提高了系统对动态环境的适应性。其重要性体现在实现了接近最优的经济效益，并兼顾了策略的可解释性，为智能能源管理提供了一个有前景且可推广的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的能源系统控制策略通常是手动设计，开发复杂且耗时，难以适应快速变化的环境。大型语言模型 (LLM) 结合了丰富的上下文知识和生成可执行代码的能力，为解决这一问题提供了新的范式。

**Method:** 本文提出了代理策略搜索 (Agentic Policy Search, APS) 框架，这是一个分层优化框架。在该框架中，LLM 作为自主代理，负责提出完整的控制逻辑，将其转化为可执行代码，并通过直接的系统反馈进行迭代改进。

**Result:** 将APS应用于一个包含光伏、电池、需求和动态电价的住宅能源系统。在仅七个模拟日内，该方法相对于无电池参考场景（-10.70 欧元）产生了高达 6.20 欧元的净利润，几乎与完美信息线性规划的全局最优解匹配。

**Conclusion:** APS 通过结合 LLM 驱动的策略搜索与生成人类可解释的控制逻辑，有效地弥合了能源管理中的适应性和可追溯性之间的鸿沟，并为其他领域的代理优化提供了一个可转移的框架。

> **ai_Abstract:** 本文提出了一种名为代理策略搜索 (APS) 的新型分层优化框架，利用大型语言模型 (LLM) 作为自主代理，自动生成、转化并迭代改进能源系统的控制逻辑。该方法在一个住宅能源系统模拟中取得了显著的经济效益，在短时间内接近了全局最优解，并提供了可解释的控制逻辑，从而提升了能源管理的适应性和可追溯性。

> **摘要翻译:** 控制能源系统通常涉及手动设计的决策策略，这些策略的开发过程复杂且耗时。这一过程需要多个领域专家之间的跨学科协作，导致对快速变化的环境适应缓慢且不灵活。大型语言模型（LLMs）通过将广泛的上下文知识与生成结构化、可执行代码的能力相结合，提供了一种有前景的范式转变。
我们提出了代理策略搜索（APS）——一种新颖的层次优化框架，其中LLMs充当自主代理，提出完整的控制逻辑，将其翻译成可执行代码，并通过直接的系统反馈进行迭代改进。我们将APS应用于一个具有光伏、电池、需求和动态电价的住宅能源系统。在仅仅七个模拟天内，该方法相比无电池参考情景（-10.70 欧元）产生了高达6.20欧元的净利润，几乎与完全知情的线性规划的全局最优解相匹配。通过将LLM驱动的策略搜索与人类可解释的控制逻辑的生成相结合，APS有效地弥合了能源管理中的适应性和可追溯性之间的鸿沟——同时还为其他领域的代理优化提供了一个可转移的框架。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [402] [Regional Frequency-Constrained Planning for the Optimal Sizing of Power Systems via Enhanced Input Convex Neural Networks](https://arxiv.org/abs/2507.18102)
> *基于增强型输入凸神经网络的电力系统最优规模区域频率约束规划*

*Yi Wang, Goran Strbac* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 区域频率, 电力系统规划, 输入凸神经网络, 遗传算法, 最优规模

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的电力系统最优规模规划模型，该模型通过增强型输入凸神经网络考虑了区域频率安全和区域间振荡，并使用自适应遗传算法进行求解。

**AI_Comments:** 该论文的创新之处在于明确解决了现有电力系统规划中区域频率差异这一关键空白。通过使用增强型输入凸神经网络来提取复杂的区域频率约束，并结合自适应遗传算法解决多阶段问题，展示了其稳健的方法论。这项工作对于开发具有高可再生能源渗透率的更具弹性且更具成本效益的电力系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 电力系统中可再生能源的大量渗透导致系统惯量水平降低，并增加了对频率响应服务的需求。现有研究大多只考虑统一频率安全，忽略了区域频率的空间差异。

**Method:** 本文提出了一种新的电力系统最优规模规划模型，以捕捉区域频率安全和区域间频率振荡。具体通过增强型输入凸神经网络（ICNN）提取区域频率约束，并嵌入到优化中，其中采用原则性权重初始化策略解决传统ICNN的梯度消失问题。同时，开发了带有稀疏性计算和局部搜索的自适应遗传算法，将规划模型分为两个阶段并迭代求解。

**Result:** 在三个不同的电力系统上进行了案例研究，验证了所提出的频率约束规划模型在确保区域系统安全和获得实际投资决策方面的有效性。

**Conclusion:** 所提出的模型有效解决了电力系统规划中的区域频率安全问题，从而实现了安全且实际的投资决策。

> **ai_Abstract:** 本文针对现有电力系统规划模型忽略区域频率空间差异的问题，提出了一种新型最优规模规划模型，以捕捉区域频率安全和区域间振荡。该模型利用增强型输入凸神经网络（ICNN）提取区域频率约束，并通过新的权重初始化策略提升ICNN的拟合能力。同时，采用自适应遗传算法将规划模型分解为两阶段并有效求解。案例研究验证了该模型在确保区域系统安全和支持实际投资决策方面的有效性。

> **摘要翻译:** 电力系统中可再生能源的大量渗透导致系统惯量水平降低，并增加了对频率响应服务的需求。目前已有大量研究开发了用于电力系统安全的频率约束模型。然而，大多数现有文献只考虑统一的频率安全，而忽略了不同区域的频率空间差异。为了弥补这一空白，本文提出了一种新颖的电力系统最优规模规划模型，该模型捕捉了区域频率安全和区域间频率振荡。具体来说，区域频率约束首先通过增强型输入凸神经网络（ICNN）提取，然后嵌入到原始的频率安全优化中，其中采用了原则性的权重初始化策略来处理传统ICCNN中非负权重的梯度消失问题并增强其拟合能力。开发了一种带有稀疏性计算和局部搜索的自适应遗传算法，将规划模型分为两个阶段并有效地迭代求解。在三个不同的电力系统上进行了案例研究，验证了所提出的频率约束规划模型在确保区域系统安全和获得实际投资决策方面的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [430] [Modal-based prediction of power system frequency response and frequency nadir](https://arxiv.org/abs/2502.02735)
> *基于模态的电力系统频率响应和频率最低点预测*

*Francisco Zelaya-Arrazabal, Sebastian Martinez-Lizana, Héctor Pulgar-Painemal* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-25**

**Keywords:** 模态分析, 频率响应, 频率最低点, 电力系统, 动态响应

**Comment:** 

> **TL;DR:** 本文提出一种基于模态分析的新方法，用于预测电力系统频率响应和频率最低点，相比传统方法能更准确地捕捉系统动态，并在多个系统上验证了其有效性。

**AI_Comments:** 这篇论文提出了一种创新性的电力系统频率响应预测方法，通过引入模态分析，显著提升了对系统动态的捕捉能力，克服了传统ASF模型的局限性。其优势在于提高了预测的鲁棒性和准确性，对电力系统稳定运行的分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统基于平均系统频率（ASF）模型的方法对系统动态表示过于简化，无法捕捉真实的系统动态，因此需要一种更详细、更准确的分析方法。

**Method:** 本文提出一种基于模态分析的新方法。通过分解完整的系统动态响应，该方法识别出基于频率行为参与度的主要模态，并推导出频率轨迹的闭式表达式。

**Result:** 该方法能够捕捉真实的系统动态，避免了过度简化的表示。主要模态对系统参数的敏感度较低，从而能够在不同运行条件下实现鲁棒和准确的估计。该方法在两个基准系统和萨尔瓦多输电规划网络上进行了测试，展示了其可扩展性、精确性和适应性。

**Conclusion:** 该方法代表了一种从观察简化的平均系统频率响应转向更关注系统动态的详细分析的转变。

> **ai_Abstract:** 本文提出了一种新颖的基于模态分析的方法，用于预测电力系统的频率响应和频率最低点。该方法通过分解系统动态响应并识别主导模态，推导出频率轨迹的闭式表达式，从而能够捕捉真实的系统动态，避免了传统方法的过度简化。实验结果表明，该方法在不同运行条件下具有鲁棒性、准确性、可扩展性、精确性和适应性，为电力系统频率分析提供了一种更详细的动态视角。

> **摘要翻译:** 本文介绍了一种基于模态分析预测系统频率响应（SFR）和频率最低点的新方法。通过分解完整的系统动态响应，该方法根据模态在频率行为中的参与度识别出主导模态，并推导出了频率轨迹的闭式表达式。与基于平均系统频率（ASF）模型的传统方法不同，该方法能够捕捉真实的系统动态，避免了过度简化的表示。主导模态对系统参数表现出较低的敏感性，从而能够在不同的运行条件下实现鲁棒和准确的估计。所提出的方法在两个基准系统以及萨尔瓦多输电规划网络上进行了测试，证明了其可扩展性、精确性和适应性。该方法论代表了从观察简化的平均系统频率响应到更侧重于系统动态的详细分析的转变。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [433] [Two-Stage TSO-DSO Services Provision Framework for Electric Vehicle Coordination](https://arxiv.org/abs/2507.18110)
> *电动汽车协调的两阶段TSO-DSO服务提供框架*

*Yi Wang, Dawei Qiu, Fei Teng, Goran Strbac* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 电动汽车, 频率响应, 电压支持, 两阶段框架, 强化学习

**Comment:** 

> **TL;DR:** 提出一种两阶段框架，通过分散式强化学习协调电动汽车为输电系统提供频率服务并为配电系统提供电压支持。

**AI_Comments:** 该论文的创新点在于提出了一个协调TSO和DSO需求的两阶段框架，解决了电动汽车在提供电网服务时可能引发的电压问题。其引入的分散式运行范式和通信高效的强化学习算法，对于处理大规模电动汽车的复杂性具有重要意义，提升了实际应用的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 随着可再生能源渗透率的提高，电力系统惯性降低，对频率响应服务需求增加。电动汽车具备车网互动能力，可为输电系统运营商（TSO）提供频率服务。然而，电动汽车在支持TSO频率时可能对配电系统运营商（DSO）造成电压安全问题，因此需要协调TSO频率和DSO电压。

**Method:** 本文提出一个多电动汽车的两阶段服务提供框架。第一阶段，电动汽车参与日前TSO-DSO交互以安排频率储备。第二阶段，电动汽车在配电网络中进行实时调度，以提供储备并支持DSO电压。考虑到电动汽车数量庞大和环境复杂性，第二阶段引入了分散式运行范式，并提出一种通信高效的强化学习（RL）算法，以在不影响策略性能的情况下减少大规模多智能体RL训练期间的通信开销。

**Result:** 在6节点输电和33节点配电网络以及69节点配电网络上进行了案例研究，评估了所提方法在使电动汽车能够提供频率服务和电压支持方面的有效性和可扩展性。

**Conclusion:** 该方法能够有效且可扩展地使电动汽车提供频率服务和电压支持，协调了TSO频率响应需求和DSO电压安全问题。

> **ai_Abstract:** 本文提出了一种两阶段服务提供框架，旨在协调电动汽车为输电系统（TSO）提供频率服务和为配电系统（DSO）提供电压支持。第一阶段涉及电动汽车的日前频率储备调度，而第二阶段则在配电网络中进行实时调度，以提供储备并维持电压。为应对大规模电动汽车的复杂性，该框架在第二阶段采用分散式运行范式，并引入了一种通信高效的强化学习算法。案例研究验证了该方法在频率服务和电压支持方面的有效性和可扩展性。

> **摘要翻译:** 电力系统中的可再生能源渗透率持续走高，导致系统惯性降低，并对频率响应服务提出了更高的要求。电动汽车（EVs）凭借其车网互动（V2G）能力，可以为输电系统运营商（TSOs）提供经济高效的频率服务。然而，电动汽车本身连接到配电网络，在支持TSO频率时可能给配电系统运营商（DSOs）带来电压安全问题。为了协调TSO频率和DSO电压，本文提出了一种多电动汽车的两阶段服务提供框架。在第一阶段，电动汽车参与日前TSO-DSO交互，以制定频率储备计划；在第二阶段，电动汽车在配电网络中进行实时调度行为，以提供储备，同时支持DSO电压。考虑到电动汽车数量可能庞大且环境复杂，第二阶段引入了分散式运行范式进行实时电动汽车调度，并提出了一种通信高效的强化学习（RL）算法，以在不影响策略性能的情况下减少大规模多智能体RL训练期间的通信开销。在6节点输电和33节点配电网络以及69节点配电网络上进行了案例研究，以评估所提方法在使电动汽车能够提供频率服务和电压支持方面的有效性和可扩展性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [460] [Integration of a Graph-Based Path Planner and Mixed-Integer MPC for Robot Navigation in Cluttered Environments](https://arxiv.org/abs/2504.13372)
> *机器人杂乱环境导航中基于图的路径规划器与混合整数MPC的集成*

*Joshua A. Robbins, Stephen J. Harnett, Andrew F. Thompson, Sean Brennan, Herschel C. Pangborn* | **Category: eess.SY, cs.RO, cs.SY** | **Updated: 2025-07-25**

**Keywords:** 机器人导航, 路径规划, 混合整数MPC, 中轴图, 重规划

**Comment:** 

> **TL;DR:** 本文提出一种多层规划与控制框架，结合基于中轴图的全局路径规划器和混合整数模型预测控制（MPC），实现机器人在部分已知杂乱环境中的高效导航与重规划。

**AI_Comments:** 该研究创新性地结合了基于图的全局规划与局部MPC，实现了在不确定环境中的高效路径重规划，解决了传统方法在复杂环境中适应性不足的问题。其通过检测不可行性来触发重规划的机制，提高了系统的响应速度和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 自动移动机器人在不确定环境中导航时，需要具备更新路径规划的能力。

**Method:** 本文提出一种使用多层规划与控制框架的重规划策略。具体方法包括：使用基于中轴图的规划器定义基于已知障碍物的全局路径；通过混合整数模型预测控制（MPC）方法检测局部环境中的终端约束是否不可行；利用不可行性检测触发通过删除中轴图边来实现高效的全局重规划。

**Result:** 所提出的重规划策略已通过实验得到验证。

**Conclusion:** 所提出的多层重规划策略在实验中表现出有效性，能够使机器人在部分已知杂乱环境中实现高效导航和路径更新。

> **ai_Abstract:** 本文提出一种针对自动机器人在部分已知杂乱环境中导航的重规划策略。该策略采用多层规划与控制框架，结合基于中轴图的全局路径规划器和混合整数模型预测控制（MPC）。MPC负责检测局部环境的约束不可行性，并触发高效的全局重规划，通过删除中轴图的边来实现。该重规划策略已通过实验验证。

> **摘要翻译:** 自动移动机器人在不确定环境中导航时，更新路径规划的能力是一项必要的能力。本文提出了一种使用多层规划与控制框架的重规划策略，适用于机器人环境部分已知的情况。一个基于中轴图的规划器根据已知障碍物定义全局路径规划，图中每条边对应一个独特的走廊。一种混合整数模型预测控制（MPC）方法检测源自全局规划的终端约束是否不可行，同时受限于局部环境的非凸描述。不可行性检测用于通过删除中轴图边来触发高效的全局重规划。所提出的重规划策略通过实验得到了验证。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [469] [Data-Driven Model Order Reduction for Continuous- and Discrete-Time Nonlinear Systems](https://arxiv.org/abs/2507.18131)
> *连续和离散时间非线性系统的数据驱动模型降阶*

*Behrad Samari, Henrik Sandberg, Karl H. Johansson, Abolfazl Lavaei* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 数据驱动, 模型降阶, 非线性系统, 仿真函数, 半定规划

**Comment:** 

> **TL;DR:** 本文提出了一种数据驱动框架，用于构建未知数学模型的连续和离散时间非线性系统的降阶模型（ROMs）。通过利用两组输入-状态轨迹数据，构建了系统的闭环表示，并利用仿真函数（SFs）建立了原始系统与数据驱动ROMs输出轨迹之间的相似性关系。该方法通过半定规划同时构建ROMs和SFs，并保证了正确性，可用于控制器合成。

**AI_Comments:** 本文的创新之处在于提出了一个纯数据驱动的方法来构建非线性系统的降阶模型，尤其是在系统数学模型未知的情况下，这在实际应用中具有重要意义。通过引入仿真函数和半定规划，为ROMs的构建和验证提供了严格的理论基础和正确性保证。该方法能够将ROMs应用于控制器合成，进一步拓展了其实用价值。其局限性可能在于数据收集的要求以及半定规划的计算复杂性对于超高维系统可能带来的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 模型降阶对于复杂系统的控制器设计至关重要，但构建有效的降阶模型（ROMs）面临挑战，特别是对于高度非线性的动态系统。当实际系统模型不可用时（现实世界应用中常见情况），这些挑战尤为突出。

**Method:** 本文提出了一种数据驱动框架，用于构建具有未知数学模型的连续和离散时间非线性动态系统的降阶模型（ROMs）。该方法利用从系统收集的两组输入-状态轨迹数据，首先构建系统的基于数据的闭环表示。然后，利用仿真函数（SFs）的概念，建立原始系统输出轨迹与其数据驱动ROMs输出轨迹之间的相似性关系，从而形式化地表征它们的接近程度。为实现此目的，本文提出了数据依赖的半定规划作为充分条件，以同时构建ROMs和SFs，并提供正确性保证。此外，本文还展示了所获得的数据驱动ROMs可用于合成控制器，确保未知系统满足高级逻辑属性，通过先为数据驱动ROMs设计控制器，然后通过接口函数将结果转换回原始系统。

**Result:** 本文证明了所获得的数据驱动ROMs可用于合成控制器，确保未知系统满足高级逻辑属性。通过四个涉及未知动态和高度非线性项的基准案例研究，评估了数据驱动发现的有效性。

**Conclusion:** 本文提出的数据驱动框架能够有效地为具有未知数学模型的连续和离散时间非线性系统构建降阶模型，并可用于控制器合成，确保系统满足高级逻辑属性，在处理高度非线性系统时表现出良好的有效性。

> **ai_Abstract:** 本文提出了一种新颖的数据驱动框架，用于为数学模型未知的连续和离散时间非线性系统构建有效的降阶模型（ROMs）。该方法利用两组输入-状态轨迹数据构建系统闭环表示，并通过仿真函数（SFs）量化原始系统与ROMs输出轨迹之间的相似性。通过解决数据依赖的半定规划问题，该框架能够同时构建ROMs和SFs，并提供正确性保证。此外，研究展示了这些数据驱动ROMs可用于设计控制器，以确保未知系统满足高层逻辑属性，并通过基准案例研究验证了其在处理高度非线性系统方面的有效性。

> **摘要翻译:** 模型降阶通过推导保持基本系统特性的低维模型来简化高维动力系统。这些技术对于复杂系统的控制器设计至关重要，同时显著降低了计算成本。然而，构建有效的降阶模型（ROMs）带来了相当大的挑战，特别是对于以高度非线性项为特征的动力系统。当实际系统模型不可用时，这些挑战进一步加剧，这种情况在现实世界应用中经常遇到。在这项工作中，我们提出了一个数据驱动框架，用于构建具有未知数学模型的连续和离散时间非线性动态系统的ROMs。通过利用从系统收集的两组数据，即两个输入-状态轨迹，我们首先构建了一个基于数据的系统闭环表示。然后，我们利用仿真函数（SFs）的概念，在原始系统与其数据驱动ROMs的输出轨迹之间建立相似性关系，从而能够对其接近程度进行形式化表征。为了实现这一点，我们提出了数据依赖的半定规划作为充分条件，以同时构建ROMs和SFs，同时提供正确性保证。我们证明了所获得的数据驱动ROMs可用于合成控制器，确保未知系统满足高级逻辑属性。这是通过首先为数据驱动ROMs设计控制器，然后通过接口函数将结果转换回原始系统来实现的。我们通过四个涉及未知动态和高度非线性项的基准案例研究，评估了我们数据驱动发现的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [490] [A User-centric Game for Balancing V2G Benefits with Battery Degradation of Electric Vehicles](https://arxiv.org/abs/2505.11027)
> *电动汽车V2G收益与电池退化平衡的用户中心博弈*

*Arghya Mallick, Georgios Pantazis, Peyman Mohajerin Esfahani, Sergio Grammatico* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-25**

**Keywords:** V2G, 电池退化, 用户中心, 电动汽车, 权衡

**Comment:** 

> **TL;DR:** 提出了一种新的用户中心V2G框架，平衡电动汽车V2G收益和电池健康退化。

**AI_Comments:** 该论文的创新点在于提出了一个用户中心的V2G框架，允许用户根据自身偏好平衡经济收益和电池退化，这对于推广V2G技术和保护用户资产具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决电动汽车用户在V2G应用中面临的财务收益与电池健康退化之间的权衡问题。

**Method:** 提出了一种新颖的用户中心车网互动（V2G）框架。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种创新的用户中心V2G框架，旨在帮助电动汽车用户根据其个人偏好，智能地权衡参与V2G所获得的经济收益与可能导致的电池健康损耗。

> **摘要翻译:** 我们提出了一种新颖的用户中心车网互动（V2G）框架，该框架使电动汽车（EV）用户能够根据个人偏好信号，平衡V2G带来的经济效益与电池健康退化之间的权衡。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [503] [Data-Driven Incremental GAS Certificate of Nonlinear Homogeneous Networks: A Formal Modular Approach](https://arxiv.org/abs/2507.18141)
> *数据驱动的非线性齐次网络增量GAS认证：一种形式化模块化方法*

*Mahdieh Zaker, David Angeli, Abolfazl Lavaei* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 数据驱动, 增量全局渐近稳定性, 齐次网络, 组合式方法, 样本复杂度

**Comment:** 

> **TL;DR:** 本文提出了一种数据驱动的组合方法，用于验证具有未知动力学的互连齐次网络的增量全局渐近稳定性（delta-GAS），解决了现有方法样本复杂度呈指数增长的问题。

**AI_Comments:** 本文的主要创新在于提出了一个数据驱动的组合式方法，显著解决了现有整体式方法在处理大规模网络时样本复杂度呈指数增长的问题。通过将样本复杂度从指数级降低到线性级，极大地提高了该方法在实际复杂系统中的可行性和应用潜力。这种模块化方法对于分析和验证大型未知非线性网络具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有文献中的整体式方法在子系统数量增加时，样本复杂度呈指数增长，使其不适用于实际应用，因此需要一种更高效的验证方法。

**Method:** 本文提出了一种组合式数据驱动方法来验证互连齐次网络的增量全局渐近稳定性（delta-GAS）。该方法利用子系统的增量输入到状态稳定性（delta-ISS）概念，并将其Lyapunov条件重新构建为鲁棒优化程序（ROP）。由于存在未知子系统动力学，通过收集每个未知子系统轨迹的数据，开发了一个场景优化程序（SOP）来解决ROP，并为每个子系统构建delta-ISS Lyapunov函数。然后，利用小增益组合条件，基于数据驱动的delta-ISS Lyapunov函数，为未知互连网络构建增量Lyapunov函数，并提供正确性保证。

**Result:** 本文的数据驱动组合方法使样本复杂度与子系统粒度对齐，所需数据量随子系统数量线性增加。与现有整体式方法相比，后者样本复杂度呈指数增长。通过将该方法应用于包含10000个子系统的未知非线性齐次网络，证明了互连网络是delta-GAS的，并具有正确性保证。

**Conclusion:** 本文提出的数据驱动组合方法能够有效且高效地验证具有未知动力学的互连齐次网络的增量全局渐近稳定性，显著降低了样本复杂度，使其在实际应用中具有可行性。

> **ai_Abstract:** 本文提出了一种新颖的数据驱动组合方法，用于验证具有未知动力学的互连齐次网络的增量全局渐近稳定性（delta-GAS）。该方法将delta-ISS Lyapunov条件重构为鲁棒优化问题，并通过场景优化解决，为每个子系统构建delta-ISS Lyapunov函数。随后，利用小增益条件，基于这些数据驱动的Lyapunov函数构建整个网络的增量Lyapunov函数。与现有整体式方法相比，该方法将样本复杂度从指数级降低到线性级，显著提高了在大规模网络中的实用性，并通过一个包含10000个子系统的网络实例验证了其有效性。

> **摘要翻译:** 这项工作侧重于一种组合式数据驱动方法，用于验证具有未知数学动力学的度数为一的互连齐次网络的增量全局渐近稳定性（delta-GAS）。我们提出的方法利用了子系统的增量输入到状态稳定性（delta-ISS）概念，该概念通过delta-ISS Lyapunov函数来表征。为了实现我们的数据驱动方案，我们首先将delta-ISS Lyapunov条件重新构建为一个鲁棒优化程序（ROP）。然而，由于ROP约束中存在未知子系统动力学，我们通过从每个未知子系统的轨迹中收集数据，开发了一个场景优化程序（SOP）。我们解决SOP并为每个具有未知动力学的子系统构建一个delta-ISS Lyapunov函数。然后，我们利用小增益组合条件，基于其数据驱动的单个子系统的delta-ISS Lyapunov函数，促进为具有未知动力学的未知互连网络构建一个增量Lyapunov函数，同时提供正确性保证。我们证明了我们的数据驱动组合方法使样本复杂度与子系统粒度对齐，导致所需数据量随子系统数量线性增加。相比之下，现有文献中的整体式方法在子系统数量增加时，样本复杂度呈指数增长，使其不适用于实际应用。为了验证我们组合式数据驱动方法的有效性，我们将其应用于一个度数为一的未知非线性齐次网络，该网络包含10000个子系统。通过从每个未知子系统收集数据，我们证明了互连网络是delta-GAS的，并具有正确性保证。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [520] [Quasi Steady-State Frequency](https://arxiv.org/abs/2505.21461)
> *准稳态频率*

*Joan Gutierrez-Florensa, Alvaro Ortega, Lukas Sigrist, Federico Milano* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-25**

**Keywords:** 准稳态频率, 频率估计, 电力系统, 暂态条件, 功率电子

**Comment:** 

> **TL;DR:** 本文引入了准稳态（QSS）频率的新概念，旨在弥补电力系统频率估计中稳态和瞬时频率之间的空白，特别适用于高功率电子渗透的系统。

**AI_Comments:** 这篇论文通过引入准稳态频率的概念，提供了一种新颖且实用的方法来解决电力系统（特别是高功率电子渗透系统）中频率估计的挑战。其创新之处在于弥补了传统稳态和瞬时频率之间的空白，并借鉴了流体动力学的概念来定义其有效范围，这是一种跨学科的创新应用。

<details>
  <summary>Details</summary>

**Motivation:** 电力系统，特别是高功率电子渗透的系统，精确的频率估计对于控制、监测和保护至关重要。

**Method:** 本文引入了准稳态（QSS）频率的新概念，它弥补了稳态频率和瞬时频率之间的空白。QSS频率在任何稳态条件下（包括不平衡和非正弦）均与交流电压的基波频率一致，并能在暂态条件下捕捉时变基波频率。论文还提出了一个借鉴流体动力学的度量，即环量的时变导数，来定义QSS频率的有效范围。

**Result:** 通过分析示例和基于IEEE 39总线系统全功能EMT模型的案例研究，分别说明了QSS频率的特性及其在暂态条件下的行为。

**Conclusion:** QSS频率能够准确估计电力系统在稳态和暂态条件下的频率，特别适用于高功率电子渗透的系统。

> **ai_Abstract:** 本文提出了一种新颖的准稳态（QSS）频率概念，旨在弥合电力系统中稳态频率与瞬时频率之间的差距。QSS频率能够准确反映稳态（包括不平衡和非正弦）和暂态条件下的基波频率。为定义其有效性范围，论文引入了流体动力学中的环量时变导数作为度量。通过分析示例和IEEE 39总线系统的EMT模型案例研究，验证了QSS频率的特性和暂态行为，强调了其在电力系统，尤其是在高功率电子集成系统中的重要性。

> **摘要翻译:** 准确的频率估计对于电力系统的控制、监测和保护至关重要，特别是对于高功率电子渗透的系统。本文引入了准稳态（QSS）频率的新概念，作为一种弥补稳态频率和瞬时频率之间空白的量。QSS频率在任何稳态条件下，包括不平衡和非正弦，都与交流电压的基波频率一致，并能够捕捉暂态条件下的时变基波频率。论文还提出了一个借鉴流体动力学的度量，即环量的时变导数，来定义QSS频率的有效范围。分析示例以及基于IEEE 39总线系统全功能EMT模型的案例研究分别用于说明QSS频率的特性及其在暂态条件下的行为。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [537] [An Explainable Equity-Aware P2P Energy Trading Framework for Socio-Economically Diverse Microgrid](https://arxiv.org/abs/2507.18738)
> *一个可解释的公平感知P2P能源交易框架，适用于社会经济多元化微电网*

*Abhijan Theja, Mayukha Pal* | **Category: eess.SY, cs.GT, cs.LG, cs.SY** | **Updated: 2025-07-24**

**Keywords:** P2P能源交易, 微电网, 公平性, 强化学习, 可解释AI

**Comment:** 

> **TL;DR:** 该文提出了一个结合多目标优化、合作博弈和强化学习的P2P能源交易框架，旨在解决社会经济多元化微电网中的公平分配问题，并利用可解释AI提升透明度，实现可持续和公平的能源社区。

**AI_Comments:** 该论文的创新之处在于将多目标优化、合作博弈论与强化学习和可解释AI相结合，以解决社会经济多元化微电网中的公平能源分配问题。特别是引入RL来动态调整公平权重，并利用XAI增强透明度，是其突出亮点。它提供了一个实际可行的路径，以实现更公平、更可持续的能源社区，对于推动智能电网和社区能源管理的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在社区微电网中，公平和动态的能源分配是一个关键挑战，尤其是在服务社会经济多元化参与者时。静态优化和成本分摊方法往往无法适应不断演变的不公平性，导致参与者不满和不可持续的合作。

**Method:** 本文提出了一个新颖的框架，该框架集成了多目标混合整数线性规划（MILP）、合作博弈论和由强化学习（RL）驱动的动态公平调整机制。核心是一个基于公平导向福利最大化（EqWM）原则的双层优化模型，该模型纳入罗尔斯公平原则，优先考虑最弱势参与者的福利。引入了一个近端策略优化（PPO）代理，根据观察到的成本和可再生能源获取方面的不公平性，动态调整优化目标中的社会经济权重。为了确保透明度，使用可解释AI（XAI）来解释源自加权Shapley值的利益分配。

**Result:** 该框架在六个真实场景中进行了验证，显示峰值需求降低高达72.6%，并获得显著的合作收益。自适应RL机制随着时间的推移进一步降低了基尼系数。

**Conclusion:** 该框架提供了一条通向真正可持续和公平能源社区的途径，通过动态调整和可解释性解决了能源分配中的公平性挑战。

> **ai_Abstract:** 本文提出了一个创新的P2P能源交易框架，旨在解决社会经济多元化微电网中的公平能源分配挑战。该框架结合了多目标MILP、合作博弈论和基于强化学习的动态公平调整机制，其核心是优先考虑弱势群体的公平导向福利最大化双层优化模型。通过PPO代理动态调整权重并利用XAI解释利益分配，该框架在真实场景中实现了显著的峰值需求削减和合作收益，并有效降低了基尼系数，为构建可持续和公平的能源社区提供了解决方案。

> **摘要翻译:** 社区微电网中公平和动态的能源分配仍然是一个关键挑战，尤其是在服务社会经济多元化参与者时。静态优化和成本分摊方法往往无法适应不断演变的不公平性，导致参与者不满和不可持续的合作。本文提出了一个新颖的框架，该框架集成了多目标混合整数线性规划（MILP）、合作博弈论和由强化学习（RL）驱动的动态公平调整机制。该框架的核心是基于公平导向福利最大化（EqWM）原则的双层优化模型，该模型纳入罗尔斯公平原则，优先考虑最弱势参与者的福利。我们引入了一个近端策略优化（PPO）代理，根据观察到的成本和可再生能源获取方面的不公平性，动态调整优化目标中的社会经济权重。这种由RL驱动的反馈循环使系统能够学习和适应，持续努力实现更公平的状态。为了确保透明度，可解释AI（XAI）被用于解释源自加权Shapley值的利益分配。该框架在六个真实场景中进行了验证，显示峰值需求降低高达72.6%，并获得显著的合作收益。自适应RL机制随着时间的推移进一步降低了基尼系数，展示了一条通向真正可持续和公平能源社区的途径。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [541] [Unit Commitment Framework for Nuclear Reactors with Reactivity Decline](https://arxiv.org/abs/2507.18150)
> *考虑反应性衰减的核反应堆机组组合框架*

*Shiny Choudhury, Michael Davidson, George Tynan* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 核反应堆, 机组组合, 反应性衰减, 氙中毒, 燃料循环

**Comment:** 11 pages, preliminary version, comments welcome

> **TL;DR:** 本文提出了一种物理信息驱动的元启发式建模方法，将燃料循环动力学与机组组合（UC）框架相结合，以实现核反应堆的灵活调度，并揭示灵活运行可以减缓反应性衰减并延长燃料循环。

**AI_Comments:** 这项工作的创新之处在于将核反应堆的复杂物理行为（如燃料循环动力学、反应性衰减和氙中毒）直接整合到标准的机组组合调度框架中。这使得核反应堆的调度能够反映其真实的物理限制和操作灵活性，而不仅仅是将其视为僵化的基荷电源。其重要性在于，通过揭示灵活操作可以延长燃料循环和减缓反应性衰减，为核电在未来能源系统中的灵活集成提供了新的视角和工具，有助于提升核电的经济性和运行效率。

<details>
  <summary>Details</summary>

**Motivation:** 核反应堆通常被视为不灵活的基荷发电机，具有固定的停机时间和严格的爬坡限制。然而，反应堆的运行灵活性与其燃料循环阶段和相关的反应性裕度密切相关。氙中毒是功率机动性的一个关键物理限制，可能导致停机时间延长和随后的功率爬坡受阻。因此，需要一个能够考虑这些物理约束的调度框架。

**Method:** 本文引入了一种物理信息驱动的元启发式建模方法，将燃料循环动力学直接嵌入到机组组合（UC）框架中。该框架跟踪反应性裕度，动态激活与氙相关的约束，并根据堆芯条件内生地实施再燃料停机。通过捕获循环内反应性演化和氙中毒的条件性发生，该公式允许进行反映监管限制和物理行为的依赖于运行的核电调度。

**Result:** 当应用于在不同运行模式（从基荷到部分负荷）下运行的代表性反应堆机队时，该框架揭示了灵活运行可以减缓反应性衰减并延长燃料循环。结果表明，考虑燃料循环的灵活性建模对于核反应堆的精确调度至关重要，并为将核电集成到能源系统模型中提供了可行的途径。

**Conclusion:** 本文提出的框架通过捕获循环内反应性演化和氙中毒的条件性发生，允许进行反映监管限制和物理行为的依赖于运行的核电调度。这种方法对于核反应堆的精确调度至关重要，并为将核电集成到能源系统模型中提供了可行的途径。

> **ai_Abstract:** 本文提出了一种新的机组组合（UC）框架，用于核反应堆的调度，以解决其传统上被认为不灵活的问题。该框架通过整合物理信息，特别是燃料循环动力学、反应性裕度跟踪和氙中毒相关约束的动态激活，实现了更精细的建模。它能够根据堆芯条件内生地管理再燃料停机。研究结果表明，这种考虑燃料循环的灵活操作方法能够减缓反应性衰减并延长燃料循环寿命，这对于核反应堆的准确调度和将其有效整合到更广泛的能源系统模型中至关重要。

> **摘要翻译:** 核反应堆通常被建模为不灵活的基荷发电机，具有固定的停机时间和严格的爬坡限制。然而，在实践中，反应堆的运行灵活性与其燃料循环阶段和相关的反应性裕度密切相关。功率机动性的一个关键物理约束是氙中毒，它是由功率下降后中子吸收氙浓度增加引起的。这会由于堆芯反应性受抑制而延迟甚至阻止随后的功率爬坡。此外，如果反应堆在低反应性期间停机，由于这些氙瞬变，重启时间可能会显著变化，导致更长的停机时间。这项工作引入了一种物理信息驱动的元启发式建模方法，将燃料循环动力学直接嵌入到机组组合（UC）框架中。该框架跟踪反应性裕度，动态激活与氙相关的约束，并根据堆芯条件内生地实施再燃料停机。通过捕获循环内反应性演化和氙中毒的条件性发生，该公式允许进行反映监管限制和物理行为的依赖于运行的核电调度。当应用于在不同运行模式（从基荷到部分负荷）下运行的代表性反应堆机队时——从基荷到部分负荷——该框架揭示了灵活运行可以减缓反应性衰减并延长燃料循环。结果表明，考虑燃料循环的灵活性建模对于核反应堆的精确调度至关重要，并为将核电集成到能源系统模型中提供了可行的途径。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [550] [The Sustainability of the Leo Orbit Capacity via Risk-Driven Active Debris Removal](https://arxiv.org/abs/2507.16101)
> *通过风险驱动的主动碎片清除实现近地轨道容量的可持续性*

*Yacob Medhin, Simone Servadio* | **Category: eess.SY, cs.SY, physics.space-ph** | **Updated: 2025-07-25**

**Keywords:** 空间碎片, 近地轨道, 主动碎片清除, 风险评估, FMM

**Comment:** 20 pages, 10 figures

> **TL;DR:** 近地轨道（LEO）空间碎片日益增多，威胁轨道可持续性。本研究开发并验证了过滤修正MITRI（FMM）风险指数，用于优先识别高危碎片。通过MOCAT-MC模拟框架，结果表明FMM在识别高风险目标方面表现优异，但性能受清除节奏影响，且物理质量项对于风险评估至关重要。本研究提供了一个开源工具，有助于优化主动碎片清除目标选择，确保LEO长期可行性。

**AI_Comments:** 本研究的创新之处在于提出了FMM这一增强型风险指数，并通过MOCAT-MC模拟框架进行了严格验证，为LEO空间碎片清除提供了更精准的风险评估工具。其重要性在于直接应对了日益严峻的空间碎片威胁，通过优化ADR目标选择，有助于保障LEO轨道的长期可持续性。此外，提供开源工具也体现了研究的实用价值。尽管FMM表现优异，但其性能受清除节奏影响的发现提示了未来研究中需进一步权衡和优化操作策略。

<details>
  <summary>Details</summary>

**Motivation:** 近地轨道（LEO）中日益增长的空间碎片危及轨道的长期可持续性，因此需要对主动碎片清除（ADR）任务进行高效的风险评估。

**Method:** 本研究开发并验证了过滤修正MITRI（FMM），这是一种增强的风险指数，旨在改进高关键性碎片的优先级排序。研究利用MOCAT-MC模拟框架进行了全面的性能评估和敏感性分析，以探究FMM公式的稳健性。

**Result:** 结果表明，FMM在年度清除行动中能更有效地识别高风险目标，但不同风险模型之间存在细微的性能权衡，这取决于操作清除的节奏。分析还证实，基于物理的质量项对于实际风险评估是不可或缺的。

**Conclusion:** 本研究通过提供一个经过验证的开源工具和对风险动态的关键见解，增强了我们选择最佳主动碎片清除目标并确保LEO操作长期可行性的能力。

> **ai_Abstract:** 本研究针对近地轨道（LEO）空间碎片日益增多对轨道可持续性造成的威胁，提出了一种名为过滤修正MITRI（FMM）的增强型风险指数，旨在优化主动碎片清除（ADR）任务中高危碎片的识别和优先级排序。通过MOCAT-MC模拟框架进行性能评估和敏感性分析，研究发现FMM在识别高风险目标方面表现优异，但其性能受清除节奏影响，且物理质量项对风险评估至关重要。本研究不仅提供了一个经验证的开源工具，还为理解风险动态提供了关键见解，从而提升了选择最佳ADR目标和确保LEO长期运行可行性的能力。

> **摘要翻译:** 近地轨道（LEO）中日益增长的空间碎片危及轨道的长期可持续性，需要对主动碎片清除（ADR）任务进行高效的风险评估。本研究开发并验证了过滤修正MITRI（FMM），这是一种增强的风险指数，旨在改进高关键性碎片的优先级排序。利用MOCAT-MC模拟框架，我们进行了全面的性能评估和敏感性分析，以探究FMM公式的稳健性。结果表明，FMM在年度清除行动中能更有效地识别高风险目标，但不同风险模型之间存在细微的性能权衡，这取决于操作清除的节奏。分析还证实，基于物理的质量项对于实际风险评估是不可或缺的。本研究通过提供一个经过验证的开源工具和对风险动态的关键见解，增强了我们选择最佳ADR目标并确保LEO操作长期可行性的能力。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [577] [Stability Constrained Voltage Control in Distribution Grids with Arbitrary Communication Infrastructure](https://arxiv.org/abs/2507.18158)
> *配电网中任意通信基础设施下的稳定性约束电压控制*

*Zhenyi Yuan, Jie Feng, Yuanyuan Shi, Jorge Cortés* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 电压控制, 配电网, 稳定性约束, 通信基础设施, 输入凸神经网络

**Comment:** 

> **TL;DR:** 本文提出了一个统一框架，设计基于学习的无功功率控制器，用于配电网电压调节，确保系统稳定性，并允许利用任意通信基础设施，通过ICNN和监督学习实现，仿真证明了其有效性。

**AI_Comments:** 该论文的创新之处在于提出了一个统一的框架，突破了传统稳定控制器对分散式结构的限制，允许控制器利用任意通信基础设施，从而能够整合更全面的信息，实现更优的控制性能。通过引入ICNN并结合监督学习，提供了一种实用的控制器设计方法。其重要性在于为未来智能电网中分布式控制器的设计提供了新的思路，特别是在考虑通信能力对控制系统性能提升方面的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法中，可证明稳定的控制器仅限于分散式结构，限制了其利用非本地信息的能力，导致控制器设计约束过于保守。

**Method:** 提出了一个统一的设计框架，使控制器能够利用物理电网之上的任意通信基础设施，以纳入超出本地总线的信息。设计并构建了基于输入凸神经网络（ICNN）的控制器，使其在任意通信场景下满足稳定性约束，并使用监督学习进行训练。

**Result:** 在加州大学圣地亚哥分校（UCSD）微电网测试平台上的仿真结果表明了该框架的有效性，并突出了通信在改善控制性能方面的作用。

**Conclusion:** 该统一设计框架及其基于ICNN的控制器能够有效地在配电网中实现稳定性约束的电压控制，且通信能力显著提升了控制性能。

> **ai_Abstract:** 这篇论文提出了一种用于配电网电压调节的基于学习的无功功率控制器设计框架，克服了现有稳定控制器仅限于分散式的问题。新框架允许控制器利用任意通信基础设施获取更广泛的信息，从而放宽了设计约束。研究人员构建了基于输入凸神经网络（ICNN）的控制器，并通过监督学习进行训练，确保其在各种通信场景下的稳定性。仿真结果验证了该框架的有效性，并强调了通信在提升控制性能中的关键作用。

> **摘要翻译:** 我们考虑设计基于学习的无功功率控制器的问题，该控制器在配电网中执行电压调节，同时确保闭环系统的稳定性。与现有方法不同，现有方法中可证明稳定的控制器仅限于分散式，我们提出了一个统一的设计框架，该框架使控制器能够利用物理电网之上的任意通信基础设施。这使得控制器能够纳入超出其本地总线的信息，将现有方法作为特例涵盖，并导致对控制器设计的约束不那么保守。然后，我们提供了一个设计程序，用于构建基于输入凸神经网络（ICNN）的控制器，这些控制器在任意通信场景下通过设计满足识别的稳定性约束，并使用监督学习训练这些控制器。在加州大学圣地亚哥分校（UCSD）微电网测试平台上的仿真结果说明了该框架的有效性，并突出了通信在改善控制性能方面的作用。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [579] [Approximating CCCV charging using SOC-dependent tapered charging power constraints in long-term microgrid planning](https://arxiv.org/abs/2507.18853)
> *在长期微电网规划中使用基于荷电状态的锥形充电功率约束近似CCCV充电*

*Hassan Zahid Butt, Xingpeng Li* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-25**

**Keywords:** CCCV充电, 锥形充电功率, 微电网规划, 电池储能系统, 荷电状态

**Comment:** 

> **TL;DR:** 本文提出了一种可处理且可扩展的方法，通过使用基于荷电状态的锥形充电功率约束来近似电池储能系统的CCCV充电行为，以提高效率、减少热应力并准确规划电池尺寸。

**AI_Comments:** 这项研究的创新之处在于提出了一种在微电网规划中模拟CCCV充电的实用方法，克服了传统恒功率模型和大型系统CCCV实施的局限性。其重要性在于能够更准确地规划BESS尺寸，提高系统可靠性和效率，从而避免电池容量不足和潜在的运行问题。该方法的可处理性和可扩展性使其在实际应用中具有较高的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的长期微电网规划模型假设电池储能系统（BESS）恒功率充电，忽略了由于内阻升高导致充电末期发生的效率损失。尽管在电池单元层面可以使用恒流恒压（CCCV）充电来缓解，但这在大型系统中的电池组层面不切实际。然而，电池管理系统和逆变器控制可以通过在高荷电状态（SOC）水平下逐渐降低充电功率来模拟这种效果，从而在充电速度和提高效率、减少热应力之间进行权衡。在规划模型中忽略这种行为可能导致电池尺寸不足和潜在的可靠性问题。

**Method:** 本文提出了一种可处理且可扩展的方法，通过使用基于荷电状态的锥形充电功率（TCP）约束来近似CCCV行为。通过MATLAB的概念验证演示了锥形充电的能量传输和效率优势。该方法被整合到长期规划框架中，并在合成负载和太阳能配置文件下进行了评估。

**Result:** 结果表明，在需要快速充电的动态操作条件下，锥形充电显著影响BESS的尺寸、成本和可靠性。

**Conclusion:** 这些发现强调锥形充电是准确捕捉长期微电网规划中BESS性能的关键建模因素。

> **ai_Abstract:** 本文提出了一种在长期微电网规划中近似恒流恒压（CCCV）充电行为的新方法，即使用基于荷电状态（SOC）的锥形充电功率（TCP）约束。传统模型忽略了充电末期的效率损失，导致电池尺寸规划不准确。通过MATLAB概念验证，研究展示了锥形充电在能量传输和效率上的优势，并将其整合到长期规划框架中进行评估。结果表明，锥形充电对电池储能系统（BESS）的尺寸、成本和可靠性有显著影响，特别是在需要快速充电的动态条件下，强调了其作为微电网规划中BESS性能关键建模因素的重要性。

> **摘要翻译:** 传统长期微电网规划模型假设电池储能系统（BESS）恒功率充电，忽略了由于内阻升高导致充电末期发生的效率损失。尽管在电池单元层面可以使用恒流恒压（CCCV）充电来缓解，但这在大型系统中的电池组层面不切实际。然而，电池管理系统和逆变器控制可以通过在高荷电状态（SOC）水平下逐渐降低充电功率来模拟这种效果，从而在充电速度和提高效率、减少热应力之间进行权衡。在规划模型中忽略这种行为可能导致电池尺寸不足和潜在的可靠性问题。本文提出了一种可处理且可扩展的方法，通过使用基于荷电状态的锥形充电功率（TCP）约束来近似CCCV行为。通过MATLAB的概念验证演示了锥形充电的能量传输和效率优势。该方法被整合到长期规划框架中，并在合成负载和太阳能配置文件下进行了评估。结果表明，在需要快速充电的动态操作条件下，锥形充电显著影响BESS的尺寸、成本和可靠性。这些发现强调锥形充电是准确捕捉长期微电网规划中BESS性能的关键建模因素。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [614] [Optimal Integration Of Heat-Pump And Solar Thermal Energy In The Pre-heating Loop Of Wood And Gas Boiler Based District Heating System](https://arxiv.org/abs/2507.18204)
> *燃木和燃气锅炉区域供热系统中热泵和太阳能热能预热回路的优化集成*

*Hamza Mettali, Rousset François, Eric Bideaux, Clausse Marc* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-07-24**

**Keywords:** 区域供热, 太阳能热能, 热泵, MILP, 燃木锅炉

**Comment:** 

> **TL;DR:** 本研究优化了区域供热系统中热泵和太阳能热能与燃木/燃气锅炉的集成，通过MILP模型考虑技术经济和环境因素，并分析了不同碳税和排放情景下的影响。

**AI_Comments:** 这篇论文的创新点在于使用MILP模型对区域供热系统中的热泵、太阳能热能、燃木和燃气锅炉的集成进行多目标优化，同时考虑了技术经济和环境（CO2）因素，并引入了温度离散化以提高模型收敛性。其重要性在于为区域供热系统在脱碳背景下如何选择和集成不同的可再生能源提供了量化分析和决策支持。论文揭示了不同能源集成策略（如太阳能与生物质能）在成本、效率和碳排放方面的权衡，以及碳税对系统设计的影响，具有重要的实际指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 区域能源网络中热生产的脱碳需要整合可再生能源，特别是太阳能热能（带或不带热泵）。然而，系统性能高度依赖于外部温度和设定点温度，因此需要优化系统设计以平衡技术经济和环境因素。

**Method:** 开发了一个混合整数线性规划（MILP）模型，该模型包含温度离散化以实现问题线性化，并捕获热发生器的关键动态特性。该模型通过消散6%的过剩太阳能热量，将MIP间隙从26小时内的19%减少到12小时内的10%，从而提高了收敛性。

**Result:** 多情景分析显示，在不同碳税和CO2排放情景下：太阳能集成面积可达11,932平方米，但燃气依赖性增加50%，热储能（TES）损失增加49%。引入燃木锅炉可降低对太阳能的依赖，覆盖45%的热量需求，降低平准化热成本（LCOH），但限制了可再生能源的渗透。较高的碳税促进了太阳能的采用，但面临存储效率低下的问题，而生物质能提高了成本效率和系统稳定性。

**Conclusion:** 优化区域供热系统中热泵与太阳能热能的集成，需权衡技术经济与环境效益。太阳能集成可减少碳排放但可能增加燃气依赖和储能损失；而生物质能（燃木锅炉）虽能降低成本和提高系统稳定性，但可能限制可再生能源渗透率。碳税水平对可再生能源的采用有显著影响，但需解决存储效率问题。

> **ai_Abstract:** 本研究旨在优化基于燃木和燃气锅炉的区域供热系统中热泵和太阳能热能的集成，以实现热生产的脱碳。通过开发一个考虑技术经济和环境因素的混合整数线性规划（MILP）模型，研究分析了在不同碳税和CO2排放情景下，太阳能和生物质能（燃木）集成的影响。结果表明，太阳能集成虽然可观，但可能增加燃气依赖和储能损失；而燃木锅炉可降低成本并提高系统稳定性，但可能限制可再生能源渗透。研究强调了在设计此类系统时，需要在不同可再生能源技术之间以及成本、环境效益和系统稳定性之间进行权衡。

> **摘要翻译:** 区域能源网络中热生产的脱碳需要整合可再生能源。除了基于生物质的解决方案外，太阳能热能（带或不带热泵）也提供了重要的机会。然而，系统性能高度依赖于外部和设定点温度。本研究旨在通过考虑技术经济和环境（CO2）因素的多标准方法来优化系统设计。开发了一个混合整数线性规划（MILP）模型，该模型包含温度离散化以实现问题线性化，并捕获热发生器的关键动态特性。该模型通过消散6%的过剩太阳能热量，将26小时内的19%的MIP间隙减少到12小时内的10%，从而提高了收敛性。在两种碳税水平和不同CO2排放情况下的多情景分析显示，太阳能集成面积可达11,932平方米，但燃气依赖性增加了50%，热储能（TES）损失增加了49%。引入燃木锅炉降低了对太阳能的依赖，覆盖了45%的热量，降低了平准化热成本（LCOH），但限制了可再生能源的渗透。较高的碳税促进了太阳能的采用，但面临存储效率低下的问题，而生物质能提高了成本效率和系统稳定性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [621] [Enhancing Robustness of Control Barrier Function: A Reciprocal Resistance-based Approach](https://arxiv.org/abs/2507.18888)
> *控制障碍函数鲁棒性增强：一种基于互易电阻的方法*

*Xinming Wang, Zongyi Guo, Jianguo Guo, Jun Yang, Yunda Yan* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-25**

**Keywords:** 控制障碍函数, 鲁棒性, 互易电阻, 扰动抑制, 安全控制

**Comment:** 7 pages, 5 figures, No presented at any conference

> **TL;DR:** 开发了一种基于互易电阻的控制障碍函数（RRCBF）来增强受扰非线性系统的鲁棒性，无需明确的扰动界限，并通过引入扰动观测器进一步提升性能。

**AI_Comments:** 本文的创新点在于引入了“互易电阻”的概念来增强控制障碍函数的鲁棒性，特别是在扰动界限未知的情况下。通过生成“缓冲区”和结合扰动观测器，有效解决了现有CBF在实际应用中面临的鲁棒性挑战，对于安全关键系统的控制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统控制障碍函数在受扰动系统中的鲁棒性不足，尤其是在扰动界限未知的情况下，需要一种无需明确扰动界限即可增强鲁棒性的方法。

**Method:** 本文开发了一种新的互易电阻基控制障碍函数（RRCBF），通过将一个类似互易电阻的项整合到传统的归零障碍函数框架中，建立了互易电阻基障碍函数（RRBF），并证明了其相关安全集的前向不变性和对有界扰动的鲁棒性。RRBF固有地在安全集边界附近生成缓冲区。该概念被扩展到高阶RRCBFs。此外，为应对复杂时变扰动，还引入了基于扰动观测器的RRCBF（DO-RRCBF），利用扰动估计来增强安全保证和恢复标称控制性能。

**Result:** 所提出的RRCBF增强了受扰仿射非线性系统的控制障碍函数鲁棒性，无需明确的扰动界限。RRBF能够生成缓冲区并有效抑制不确定性和外部扰动，并证明了其安全集的前向不变性及对有界扰动的鲁棒性。DO-RRCBF能够缓解复杂时变扰动下的保守性，并增强安全保证和恢复标称控制性能。通过二阶线性系统和自适应巡航控制场景的仿真研究，验证了所提出框架在展示前向不变性和高相对度系统鲁棒性方面的有效性。

**Conclusion:** 通过引入互易电阻项和结合扰动观测器，本文提出的RRCBF框架显著提升了控制障碍函数在存在未知扰动下的鲁棒性和性能，并通过仿真验证了其有效性。

> **ai_Abstract:** 本文提出了一种新的基于互易电阻的控制障碍函数（RRCBF），用于增强受扰仿射非线性系统的鲁棒性，无需已知扰动界限。该方法通过引入互易电阻状项，构建了能够生成缓冲区并保证安全集前向不变性的互易电阻基障碍函数（RRBF）。为进一步应对复杂时变扰动，还引入了结合扰动观测器的DO-RRCBF。仿真研究验证了该框架在安全性和性能恢复方面的有效性。

> **摘要翻译:** 本研究开发了一种新的基于互易电阻的控制障碍函数（RRCBF），旨在增强受扰仿射非线性系统的控制障碍函数鲁棒性，而无需明确了解扰动界限。通过将一个类似互易电阻的项整合到传统的归零障碍函数框架中，我们正式建立了基于互易电阻的障碍函数（RRBF）的概念，并严格证明了其相关安全集的前向不变性及其对有界扰动的鲁棒性。RRBF固有地在安全集边界附近生成一个缓冲区，有效主导不确定性和外部扰动的影响。这一基础概念被扩展以制定RRCBFs，包括其高阶变体。为了缓解复杂、时变扰动下的保守性，我们进一步引入了基于扰动观测器的RRCBF（DO-RRCBF），它利用扰动估计来增强安全保证并恢复标称控制性能。所提出框架的有效性通过两项仿真研究得到验证：一个二阶线性系统展示了相平面中的前向不变性，以及一个自适应巡航控制场景展示了高相对度系统中的鲁棒性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [663] [GMM-Based Time-Varying Coverage Control](https://arxiv.org/abs/2507.18938)
> *基于GMM的时变覆盖控制*

*Behzad Zamani, James Kennedy, Airlie Chapman, Peter Dower, Chris Manzie, Simon Crase* | **Category: eess.SY, cs.RO, cs.SY** | **Updated: 2025-07-25**

**Keywords:** 时变覆盖控制, 高斯混合模型, 分布式控制, 多车机器人, 羽流监测

**Comment:** Submitted to CDC 2025

> **TL;DR:** 开发了一种基于高斯混合模型（GMM）的时变覆盖控制器，能够有效处理密度函数的时间演化，适用于多车机器人应用，并通过无人机群监测化学羽流进行了验证。

**AI_Comments:** 该论文的创新点在于提出了一种基于高斯混合模型（GMM）的有效方法来处理时变覆盖控制中密度函数的时间演化，这在以往工作中常被忽略或简化。其提出的控制器不仅能最小化覆盖成本，还具备计算高效和分布式特性，使其在多车机器人应用中具有重要意义。通过无人机群监测化学羽流的实验验证，进一步突出了其实用性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 在涉及时变密度函数的覆盖控制问题中，覆盖控制律依赖于密度函数时间演化的空间积分，而这一部分常常被忽略、用上限取代或通过数值近似计算。

**Method:** 提出了一种针对时变密度函数特殊情况的覆盖控制方法，该密度函数被建模为通过已知速度的时变源演化的高斯混合模型（GMMs）。通过施加这种结构，获得了能够完全整合密度函数时间演化的有效时变覆盖控制器。

**Result:** 证明了在该控制律下产生的轨迹能最小化整体覆盖成本。在仿真中，与经典时变覆盖控制器进行了性能比较。该控制律计算高效且分布式，非常适合涉及时变覆盖控制问题的多车机器人应用。在无人机群监测羽流的实验中，展示了由该控制器引导的无人机能够以分布式方式跟踪模拟的时变化学羽流。

**Conclusion:** 所提出的基于GMM的时变覆盖控制律能够有效且分布式地处理时变密度函数的覆盖控制问题，并通过最小化覆盖成本和在多车机器人应用中的成功验证，证明了其优越性。

> **ai_Abstract:** 本文提出了一种基于高斯混合模型（GMM）的时变覆盖控制方法，专门处理密度函数随时间演化的问题。该方法通过将时变密度函数建模为由已知速度源演化的GMMs，构建了一个能完全整合密度函数时间演化的高效控制器。研究表明，该控制律能最小化覆盖成本，且具有计算高效和分布式的特点，非常适用于多车机器人系统。通过无人机群在模拟化学羽流监测中的实验验证，证明了其在实际应用中的有效性。

> **摘要翻译:** 在涉及时变密度函数的覆盖控制问题中，覆盖控制律依赖于密度函数时间演化的空间积分。后者常常被忽略，被上限取代，或被计算为所涉及空间积分的数值近似值。在本文中，我们考虑了时变密度函数的一种特殊情况，即将其建模为高斯混合模型（GMMs），并通过一组时变源（具有已知相应速度）随时间演化。通过施加这种结构，我们获得了一个高效的时变覆盖控制器，该控制器完全整合了密度函数的时间演化。我们证明了在该控制律下产生的轨迹能够最小化整体覆盖成本。我们阐明了所提出控制器的结构，并将其与经典的瞬态覆盖控制器进行了比较，在仿真中对覆盖性能进行了基准测试。此外，我们强调了所提出控制律的计算效率和分布式特性使其非常适合涉及时变覆盖控制问题的多车辆机器人应用。我们将我们的方法应用于使用无人机群进行羽流监测。在一次实验现场试验中，我们展示了由所提出的控制器引导的无人机能够以分布式方式跟踪模拟的时变化学羽流。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [697] [Maneuvering-based Dynamic Thrust Allocation for Fully-Actuated Vessels](https://arxiv.org/abs/2507.18309)
> *基于机动的全驱动船舶动态推力分配*

*Emir Cem Gezer, Roger Skjetne* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 推力分配, 全驱动船舶, 控制李雅普诺夫函数, 控制障碍函数, 船舶操纵

**Comment:** 

> **TL;DR:** 本文提出了一种使用操纵问题解决全驱动船舶推力分配的新方法，结合了控制李雅普诺夫函数和控制障碍函数，旨在提供简单、有效且平滑动态的推力参考信号。

**AI_Comments:** 这篇论文的创新点在于将船舶操纵问题与推力分配相结合，并引入了控制李雅普诺夫函数和控制障碍函数来解决动态跟踪、速率限制和饱和问题。这种方法旨在提高推力分配的实际应用效果，使其更平滑、更有效。

<details>
  <summary>Details</summary>

**Motivation:** 针对全驱动船舶的推力分配问题，提出一种新的、更有效且简单的解决方案。

**Method:** 该方法利用船舶操纵问题来解决推力分配。它使用控制李雅普诺夫函数创建非线性参考滤波器，以确保对最佳推力分配解决方案的动态跟踪，并对输出推力参考进行速率限制。此外，它还利用控制障碍函数来确保推力饱和限制得到遵守。

**Result:** 抽象中未明确提及实验结果，但该方法旨在实现简单性、有效性以及平滑动态的推力参考信号。

**Conclusion:** 本文提出了一种新的、简单且有效的推力分配方法，通过结合控制李雅普诺夫函数和控制障碍函数，实现了对最佳推力分配解决方案的动态跟踪和对推力饱和限制的遵守，并能生成平滑动态的推力参考信号。

> **ai_Abstract:** 本文提出了一种基于船舶操纵问题的动态推力分配新方法，专为全驱动船舶设计。该方法结合了控制李雅普诺夫函数用于动态跟踪最佳推力分配解并进行速率限制，以及控制障碍函数以确保推力饱和限制。其目标是实现推力分配的简单性、有效性及平滑动态的推力参考信号。

> **摘要翻译:** 本文介绍了一种解决推力分配问题的新方法，该方法利用海事领域中全驱动船舶的操纵问题。该方法使用控制李雅普诺夫函数来为推进器力创建非线性参考滤波器。该滤波器确保了对最佳推力分配解决方案的动态跟踪，并对输出推进器参考进行了速率限制。它进一步使用控制障碍函数来确保推进器力饱和限制得到遵守。该方法旨在为船舶推力分配的实施提供简单性、有效性以及平滑和动态的推进器参考信号。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [705] [Research on Sectionalizing Switches Placement Problem of Distribution System Automation Based on Multi-Objective Optimization Analysis](https://arxiv.org/abs/2507.19029)
> *基于多目标优化分析的配电系统自动化分段开关选址问题研究*

*Selma Cheshmeh Khavar, Arya Abdollahi* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-25**

**Keywords:** 分段开关选址, 配电系统自动化, 多目标优化, 遗传算法, 可靠性

**Comment:** 

> **TL;DR:** 本研究提出了一种基于改进多目标遗传算法的方法，用于优化配电系统自动化分段开关的选址，旨在提高可靠性并降低运营成本，并在实际馈线上验证了其可行性。

**AI_Comments:** 该论文解决了配电系统中的一个重要实际问题，即自动化设备（分段开关）的优化布局，这对于提高电网的运行效率和可靠性具有直接意义。其方法创新在于将可靠性提升和运营成本最小化纳入多目标优化框架，并利用改进的非支配排序遗传算法进行求解，这是一种处理此类复杂问题的有效方法。

<details>
  <summary>Details</summary>

**Motivation:** 配电系统优化面临的主要问题是实现高配电可靠性并同时最小化运营成本。从可靠性和经济性角度来看，确定配电系统网络中自动化设备的最佳数量和位置是至关重要的问题。

**Method:** 本文构建了一个多目标模型，其中首要目标是最小化运营成本下的自动化设备最佳选址，次要目标是提高可靠性指标。为解决这一多目标混合整数非线性规划问题，开发并提出了一种改进的非支配排序遗传算法。

**Result:** 所提出的算法在Tabriz配电网络的两个配电馈线（包括带分布式发电单元的Azar变电站的第三馈线以及构成双馈线的ElGoli变电站的第一和第三馈线）上进行了应用，并验证了其可行性。

**Conclusion:** 提出的算法在解决配电系统自动化设备选址问题，兼顾提高可靠性和降低运营成本方面具有可行性。

> **ai_Abstract:** 本文研究了配电系统自动化中分段开关的优化选址问题，旨在同时提高配电可靠性并最小化运营成本。为此，提出了一种多目标模型，并采用改进的非支配排序遗传算法来解决该多目标混合整数非线性规划问题。算法的可行性通过在Tabriz配电网络的实际馈线上的应用得到了验证。

> **摘要翻译:** 实现高配电可靠性并同时最小化运营成本是配电系统优化的主要问题。从可靠性和经济性角度来看，确定配电系统网络中自动化设备的最佳数量和位置是一个基本问题。为解决这些问题，本文建立了一个多目标模型，其中首要目标是实现自动化设备的最佳选址以最小化运营成本，同时次要目标考虑了可靠性指标的改善。因此，开发并提出了一种改进的非支配排序遗传算法来解决这个多目标混合整数非线性规划问题。通过将其应用于Tabriz配电网络的两个配电馈线（包括带分布式发电单元的Azar变电站的第三馈线以及构成双馈线的ElGoli变电站的第一和第三馈线），验证了所提算法的可行性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [737] [Toward Sustainable Vertical Farming: Impacts of Environmental Factors and Energy Mix on Performance and Costs](https://arxiv.org/abs/2507.18419)
> *走向可持续垂直农业：环境因素和能源结构对性能和成本的影响*

*Francesco Ceccanti, Aldo Bischi, Umberto Desideri, Andrea Baccioli* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 垂直农业, 能源消耗, 环境因素, 可持续性, PPFD

**Comment:** 

> **TL;DR:** 本研究分析了垂直农业的性能和成本，发现光合光子通量密度（PPFD）是作物生长和能耗的主导因素。研究提出了最具成本效益的配置（24C, 250 PPFD, 1400 ppm CO2, 带保温层），并强调垂直农业的可持续性依赖于近乎脱碳的能源系统。

**AI_Comments:** 这篇论文通过广泛的情景模拟，深入分析了垂直农业中环境因素和能源结构对性能和成本的影响，具有重要的实践指导意义。其创新之处在于量化了PPFD在作物生长和能耗中的主导作用，并提出了在不同气候下均适用的成本效益配置。论文强调了脱碳能源系统对垂直农业可持续性的关键作用，为未来垂直农业的发展提供了重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 垂直农业在提供稳定、高质量、无虫害蔬菜生产方面日益受到关注，并能与能源系统和城市发展协同。为提高能源效率和降低成本，制定标准化设计和操作指南至关重要。

**Method:** 本研究通过评估162种情景，分析了垂直农业系统的生产性能和能耗，以评估其效率、可持续性和经济可行性。这些情景结合了三个温度、光合光子通量密度（PPFD）和二氧化碳浓度水平，并考虑了挪威、中国和迪拜三个不同气候区，以及两种保温层厚度。

**Result:** 由于HVACD系统，保温层和外部气候对作物产量影响不显著。PPFD是作物生长的主要影响因素（相关性：0.85），其次是CO2（0.36）和室内温度（0.22）。PPFD也是总能耗的主要驱动因素（相关性：0.73），因为它影响照明和HVACD负荷。最低的比能耗（SEC）与最低的作物产量（55 kg/m2）同时出现。生菜的平准化成本（LCoL）分析表明，最具成本效益的配置是24C、250 PPFD、1400 ppm CO2，并带有保温层，这在所有气候下都保持一致。

**Conclusion:** 最终，只有接近脱碳的能源系统才能支持垂直农业，而不会与进口生菜相比增加二氧化碳排放。

> **ai_Abstract:** 本研究分析了垂直农业系统的性能和能耗，评估其效率、可持续性和经济可行性。通过在不同环境因素（温度、PPFD、CO2浓度、保温层）和气候区（挪威、中国、迪拜）下模拟162种情景，发现PPFD是作物生长和总能耗的主导因素。研究确定了最具成本效益的生菜生产配置（24C, 250 PPFD, 1400 ppm CO2, 带保温层），并强调只有采用近乎脱碳的能源系统，垂直农业才能实现可持续发展，避免增加碳排放。

> **摘要翻译:** 垂直农业因其能够确保稳定、高质量、无虫害的蔬菜生产，同时支持与能源系统和城市发展的协同作用而日益受到关注。因此，标准化的设计和操作指南对于提高能源效率和降低成本至关重要。本研究分析了垂直农业系统的生产性能和能耗，评估其效率、可持续性和经济可行性。通过结合三个温度、光合光子通子密度（PPFD）和二氧化碳浓度水平，在挪威、中国和迪拜三个不同的气候区（这些地区在社会环境方面也存在差异）评估了总共162种情景。每个情景中还测试了两种保温层厚度。结果表明，由于供暖、通风、空调和除湿（HVACD）系统，保温层和外部气候均未显著影响作物生产力。PPFD被证明是作物生长的主要因素（相关性：0.85），其次是CO2（0.36）和室内温度（0.22）。PPFD也成为总能耗的主要驱动因素（相关性：0.73），因为它影响照明和HVACD负荷。值得注意的是，最低的比能耗（SEC）与最低的作物生产力（55 kg/m2）同时出现。生菜的平准化成本（LCoL）平衡了生产力和能源使用，确定最具成本效益的设置为24C、250 PPFD、1400 ppm CO2，并带有保温层，这在所有气候下都保持一致。最终，只有接近脱碳的能源系统才能支持垂直农业，而不会与进口生菜相比增加二氧化碳排放。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [753] [Radio Map Assisted Routing and Predictive Resource Allocation over Dynamic Low Altitude Networks](https://arxiv.org/abs/2507.19111)
> *基于无线电地图辅助的动态低空网络路由与预测资源分配*

*Bowen Li, Junting Chen* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-25**

**Keywords:** 动态低空网络, 无人机, 路由, 资源分配, 时空图

**Comment:** 

> **TL;DR:** 本文提出了一种动态时空图模型和跨层优化框架，用于解决动态低空网络中无人机继电器的数据路由和预测资源分配问题，并在单商品和多商品传输任务中取得了显著性能提升。

**AI_Comments:** 本文的创新点在于提出了动态时空图模型和跨层优化框架，有效地将复杂的路由和资源分配问题转化为更易于解决的瓶颈路径规划问题。通过利用问题结构的单调性特性，实现了全局最优解的有效获取，这对于实际应用中的性能保障至关重要。此外，对单商品和多商品场景的全面分析以及显著的性能提升（高达30 dB和100倍）突显了其重要性。该研究为未来低空网络的高效数据传输和资源管理提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 由于动态低空网络中时变拓扑和需要控制对地面系统的干扰，优化数据路由和资源分配具有挑战性。传统的方案依赖于统一和精细时间划分的时间扩展图，不适用于干扰感知应用。

**Method:** 本文开发了一种动态时空图模型，采用跨层优化框架，将联合路由和预测资源分配问题转换为联合瓶颈路径规划和资源分配问题。通过显式确定性界限处理信道不确定性，并利用问题结构的单调性特性，有效达到预测资源分配子问题的全局最优解。该方法扩展到多商品传输任务，通过时频分配，并开发了一种二分搜索算法，利用可行集族的单调性找到最优解。

**Result:** 仿真验证了单商品算法在延迟敏感和大数据传输方面，比经典基于图的方法有超过30 dB的性能增益，接近全局最优。同时，多商品方法在密集服务场景中实现了100倍的改进，并通过数据分段实现了额外的20 dB性能增益。

**Conclusion:** 本文提出的动态时空图模型和优化框架能有效解决动态低空网络中的路由和预测资源分配问题，并在单商品和多商品场景中展现出显著的性能提升。

> **ai_Abstract:** 本文提出了一种针对动态低空网络中无人机中继的路由和预测资源分配的跨层优化框架。该框架基于动态时空图模型，将问题转化为联合瓶颈路径规划和资源分配。通过引入确定性界限处理信道不确定性，并利用问题结构的单调性实现全局最优解。研究进一步扩展到多商品传输，并开发了二分搜索算法。仿真结果表明，该方法在单商品传输中比传统方法有超过30 dB的性能提升，在多商品密集服务场景中实现了100倍改进和额外的20 dB增益。

> **摘要翻译:** 动态低空网络通过无人机（UAV）中继器实现高效可靠数据传输，这些中继器通常按预定轨迹运行，具有巨大潜力。然而，由于时变拓扑和需要控制对地面系统的干扰，优化数据路由和资源分配具有挑战性。传统方案依赖于具有统一和精细时间划分的时间扩展图，这使得它们不适用于干扰感知应用。本文开发了一种动态时空图模型，采用跨层优化框架，将联合路由和预测资源分配问题转换为联合瓶颈路径规划和资源分配问题。我们开发了显式确定性界限来处理信道不确定性，并证明了问题结构中的单调性特性，使我们能够有效地达到预测资源分配子问题的全局最优解。然后，通过时频分配将此方法扩展到多商品传输任务，并开发了一种二分搜索算法，通过利用可行集族的单调性找到最优解。仿真验证了单商品算法在延迟敏感和大数据传输方面，比经典基于图的方法有超过30 dB的性能增益，接近全局最优。同时，多商品方法在密集服务场景中实现了100倍的改进，并通过数据分段实现了额外的20 dB性能增益。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [781] [A Robust Predictive Control Method for Pump Scheduling in Water Distribution Networks](https://arxiv.org/abs/2507.18492)
> *一种用于供水网络水泵调度的鲁棒预测控制方法*

*Mirhan Ürkmez, Carsten Kallesøe, Jan Dimon Bendtsen, Eric C. Kerrigan, John Leth* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 鲁棒预测控制, 水泵调度, 供水网络, 不确定性, 优化

**Comment:** 

> **TL;DR:** 本文提出了一种鲁棒模型预测控制（RMPC）方法，用于优化和可靠地调度供水网络中的水泵，以应对不确定性并降低运营成本。

**AI_Comments:** 该论文的创新之处在于提出了一种鲁棒模型预测控制方法，有效应对了供水网络水泵调度中的不确定性。其重要性体现在通过考虑不确定性，提高了调度的可靠性，并成功将计算复杂度从高阶降低到更实际的$\\mathcal{O}(N^3)$，使其在实际应用中更具可行性。

<details>
  <summary>Details</summary>

**Motivation:** 供水公司旨在降低供水网络（WDNs）中主要由水泵驱动的高昂电费。然而，由于模型不确定性和用水需求预测误差，水泵调度具有挑战性。

**Method:** 本文提出了一种鲁棒模型预测控制（RMPC）方法，用于水泵调度。该方法扩展了之前针对其模型量身定制的有效鲁棒控制方法。它使用一个具有有界加性扰动的线性模型来表示水箱水位演变，不确定性界限来自WDN模拟和需求数据。在每个时间步，优化一个与过去扰动相关的泵调度策略，以在预测范围内满足系统约束。该优化问题最初需要$\\mathcal{O}(N^6)$的计算量，通过重新表述为稀疏形式，将其减少到$\\mathcal{O}(N^3)$。

**Result:** 该方法在丹麦中型城镇兰德斯的供水网络模型上进行评估，在满足约束方面优于标称和约束紧缩模型预测控制（MPC）方法，并提供了可比的经济效益。

**Conclusion:** 所提出的鲁棒预测控制方法能够有效应对供水网络水泵调度中的不确定性，并在满足系统约束和经济效益方面表现出色，优于传统MPC方法。

> **ai_Abstract:** 本文提出了一种鲁棒模型预测控制（RMPC）方法，用于解决供水网络中水泵调度面临的模型不确定性和需求预测误差挑战。该方法采用线性模型和有界扰动来表示水位变化，并优化与过去扰动相关的调度策略，以在预测范围内满足系统约束。通过将优化问题重新表述为稀疏形式，计算复杂度从$\\mathcal{O}(N^6)$显著降低到$\\mathcal{O}(N^3)$。在实际网络模型上的评估显示，该RMPC方法在满足约束方面优于现有MPC方法，同时保持了可比的经济效益。

> **摘要翻译:** 供水公司旨在降低供水网络（WDNs）中主要由水泵驱动的高昂电费。然而，由于模型不确定性和用水需求预测误差，水泵调度具有挑战性。本文提出了一种鲁棒模型预测控制（RMPC）方法，用于优化和可靠地调度水泵，该方法扩展了之前针对我们模型量身定制的有效鲁棒控制方法。一个具有有界加性扰动的线性模型用于表示水箱水位演变，不确定性界限来自WDN模拟和需求数据。在每个时间步，优化一个与过去扰动相关的泵调度策略，以在预测范围内满足系统约束。然后以滚动时域方式应用所得策略。优化问题最初被表述为每次迭代需要$\\mathcal{O}(N^6)$的计算量，通过重新表述为稀疏形式，将其减少到$\\mathcal{O}(N^3)$。在代表丹麦中型城镇兰德斯供水网络的模型上进行评估时，该方法在满足约束方面优于标称和约束紧缩模型预测控制（MPC）方法，并提供了可比的经济效益。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [795] [Truncated Gaussian Noise Estimation in State-Space Models](https://arxiv.org/abs/2507.19244)
> *状态空间模型中的截断高斯噪声估计*

*Rodrigo A. González, Angel L. Cedeño, Koen Tiels, Tom Oomen* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-25**

**Keywords:** 截断高斯噪声, 状态空间模型, 参数估计, 最大似然, 期望最大化

**Comment:** 6 pages,2 figures

> **TL;DR:** 本文提出了一种结合最大似然和EM算法，用于估计状态空间模型中截断高斯噪声参数的方法，以解决传统高斯噪声假设在有界噪声下不准确的问题。

**AI_Comments:** 该论文的创新点在于将传统的高斯噪声假设推广到截断高斯噪声，解决了在噪声具有有界特性时传统方法的局限性。通过引入最大似然和EM算法，提供了一种实用的参数估计方法，对于提升状态空间模型在实际应用中的准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在状态空间系统识别中，传统的高斯噪声假设在噪声服从有界分布时可能导致不准确。本文旨在将高斯噪声假设推广到可能截断的密度。

**Method:** 本文提出了一种基于最大似然原理结合期望最大化（EM）算法的数据驱动方法，用于估计状态空间模型中截断高斯噪声的参数。

**Result:** 所提出的方法通过一个仿真示例验证了其有效性。

**Conclusion:** 成功引入并验证了一种估计状态空间模型中截断高斯噪声参数的方法，解决了传统高斯噪声假设的局限性。

> **ai_Abstract:** 本文针对状态空间系统识别中传统高斯噪声假设在噪声有界时可能导致不准确的问题，提出了一种估计截断高斯噪声参数的新方法。该数据驱动方法结合了最大似然原理和期望最大化算法，并通过仿真示例验证了其有效性，旨在将高斯噪声假设推广到更普遍的截断密度。

> **摘要翻译:** 在贝叶斯状态估计中，为了过程优化、状态监测、故障检测和控制，人们在将约束纳入状态估计方面付出了巨大努力。然而，在状态空间系统识别领域，普遍的做法是在高斯噪声假设下构建模型，当噪声遵循有界分布时，这可能导致不准确。为了将高斯噪声假设推广到可能截断的密度，本文介绍了一种估计服从截断高斯噪声的状态空间模型中噪声参数的方法。我们提出的数据驱动方法植根于最大似然原理与期望最大化算法相结合。所提出方法的有效性通过一个仿真示例得到了支持。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [824] [Global Observer Design for a Class of Linear Observed Systems on Groups](https://arxiv.org/abs/2507.18493)
> *群上一类线性观测系统的全局观测器设计*

*Changwu Liu, Yuan Shen* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 群上系统, 全局观测器, 状态估计, 李群, 卡尔曼观测器

**Comment:** 16 pages, 1 figure

> **TL;DR:** 本文提出了一种统一的观测器框架，通过将李群上的双不变系统限制在其正规子群上，将原系统沉浸到线性时变系统中，并结合卡尔曼型观测器和优化方法，实现了群值状态的全局指数稳定观测。

**AI_Comments:** 本文的创新点在于提出了一个统一的观测器框架，并利用系统沉浸和优化方法解决了群上非欧几里得状态空间观测的拓扑难题，实现了全局指数稳定性。其将理论应用于导航问题，显示出潜在的实际价值。然而，全局最优解的寻找是实现GES的关键，这可能在实际应用中引入计算复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 线性观测系统在群上编码了各种实际状态估计问题的几何结构，这表明对其进行观测器设计具有重要的实际应用价值。

**Method:** 本文通过将李群上的双不变系统限制在其正规子群上，提出了一种统一的观测器框架。这种结构特性使得原始系统能够沉浸到线性时变系统中。然后，通过为沉浸系统设计一个类卡尔曼观测器，并通过优化重建群值状态来构建观测器。

**Result:** 在满足秩条件且找到重构优化的一个全局最优解时，实现了全局指数稳定性（GES）。当同时估计输入偏差时，保证了半全局稳定性。该理论应用于双帧系统的GES观测器设计，能够建模一系列导航问题。提供了两个非平凡的例子来说明实现细节。

**Conclusion:** 本文成功设计了一类群上线性观测系统的全局观测器，通过新颖的系统沉浸和优化方法，解决了非欧几里得状态空间的拓扑难题，并实现了全局指数稳定性，对导航等实际问题具有重要意义。

> **ai_Abstract:** 本文提出了一种针对群上一类线性观测系统的统一观测器框架。通过将李群上的双不变系统限制到其正规子群，实现了原始系统到线性时变系统的沉浸。在此基础上，通过结合类卡尔曼观测器和优化方法重构群值状态，设计了观测器。研究表明，在特定条件下可实现全局指数稳定性，并在联合估计输入偏差时保证半全局稳定性。该方法适用于导航等实际应用，并提供了实例验证。

> **摘要翻译:** 群上的线性观测系统编码了各种实际状态估计问题的几何结构。本文提出了一种统一的观测器框架，通过将李群上的双不变系统限制在其正规子群上，用于一类线性观测系统。这种结构特性有力地使得原始系统沉浸到线性时变系统中。利用这种沉浸，通过首先为沉浸系统设计一个类卡尔曼观测器，然后通过优化重建群值状态来构建观测器。在满足秩条件的情况下，只要找到重构优化的一个全局最优解，就可以实现全局指数稳定性（GES），这反映了非欧几里得状态空间固有的拓扑困难。当同时估计输入偏差时，可以保证半全局稳定性。该理论应用于双帧系统的GES观测器设计，该系统能够建模一系列导航问题。提供了两个非平凡的例子来说明实现细节。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [836] [Cell-based VSC Analysis Methodology: From Graph Laplacian to Converter Degrees of Freedom](https://arxiv.org/abs/2507.19260)
> *电池单元式VSC分析方法：从图拉普拉斯到变流器自由度*

*Daniele Falchi, Eduardo Prieto-Araujo, Oriol Gomis-Bellmunt* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-25**

**Keywords:** 变流器自由度, 图拉普拉斯, 电池单元式VSC, 模块化多电平变流器, 变量变换

**Comment:** 

> **TL;DR:** 本文提出了一种基于图拉普拉斯谱分析的通用方法，用于确定多种电池单元式电压源变流器（VSC）拓扑的变量变换矩阵，以评估其自由度。

**AI_Comments:** 该论文提出了一种新颖的、基于图论的方法来分析变流器的自由度，这对于理解和控制复杂的电力电子系统具有重要意义。通过将图拉普拉斯谱分析应用于变流器拓扑，它提供了一种系统性的方法来确定独立变量，类似于经典的Clarke变换，这可能为未来的变流器设计和控制策略提供新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 电力电子变流器在电力系统中被广泛使用，需要对其自由度（DOFs）进行评估以建立正确的操作和控制。现有方法需要类似Clarke变换的通用方法来揭示不同变流器拓扑的独立变量集。

**Method:** 提出了一种通用方法来确定针对多种电池单元式电压源变流器（VSC）配置的变量变换矩阵，这些配置与完全二部图和多部图相关。该方法基于图拉普拉斯谱分析，用于揭示变流器连接点的结构正态模式。此外，还引入了基于自由度的瞬时功率模式公式以进行完整表征。

**Result:** 该方法能够确定多种电池单元式VSC拓扑（包括模块化多电平变流器MMC）的变量变换矩阵，并揭示了变流器连接点的结构正态模式。

**Conclusion:** 该论文提出了一种通用的、基于图拉普拉斯谱分析的方法，有效地确定了电池单元式VSC拓扑的自由度，并为瞬时功率模式提供了表征，为变流器的操作和控制提供了基础。

> **ai_Abstract:** 本文提出了一种通用的分析方法，旨在确定电池单元式电压源变流器（VSC）拓扑（如模块化多电平变流器MMC）的自由度（DOFs）。该方法利用图拉普拉斯谱分析来识别变流器连接点的结构正态模式，并推导出相应的变量变换矩阵，从而揭示了多种与完全二部图和多部图相关的变流器配置的独立变量集。此外，文章还引入了基于自由度的瞬时功率模式公式，以实现对变流器的完整电气特性表征。

> **摘要翻译:** 电力电子变流器在电力系统中被大量使用，以互连多个异构电气层。此外，其固有的多功能性，即利用变流器网络拓扑的灵活性，被广泛用于根据特定应用容纳一定数量的终端和端口。在这方面，电力应用中可以遇到多种变流器布置。此外，为了正确建立操作和控制，需要针对每种变流器拓扑评估所谓的自由度（DOFs）。在这方面，类似于众所周知的Clarke变换（其清楚地揭示了星形拓扑系统的自由度），可以实现进一步的类似变换来描绘表征特定变流器结构的独立变量集。针对电池单元式电压源变流器（VSC）拓扑类别，包括模块化多电平变流器（MMC）；本文提出了一种通用方法，用于确定与完全二部图和多部图相关的多种变流器布置的变量变换矩阵。该方法基于图拉普拉斯谱分析，它揭示了变流器连接点的结构正态模式。此外，为了完整表征，还引入了基于自由度的瞬时功率模式公式。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [869] [Design and optimization of a novel leaf-shape antenna for RF energy transfer](https://arxiv.org/abs/2507.18630)
> *叶形天线在射频能量传输中的设计与优化*

*Junbin Zhong, Mingtong Chen, Zhengbao Yang* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-24**

**Keywords:** 叶形天线, 射频能量传输, 仿生设计, 915 MHz, 阻抗匹配

**Comment:** 

> **TL;DR:** 该研究设计并优化了一种受自然叶片启发的新型叶形天线，用于915 MHz频段的射频能量传输，并在200厘米距离内有效供电。

**AI_Comments:** 该论文提出了一种新颖的仿生叶形天线设计，其创新点在于将自然结构应用于射频能量捕获，并取得了在特定频段和距离下的良好性能。未来的工作方向，如穿透混凝土测试和自主对准系统，表明了该技术在实际应用中的潜力和挑战。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种受生物启发的叶形天线，通过阻抗匹配优化其在915 MHz频段的性能，并评估其捕获射频能量的效率，以改善射频能量传输。

**Method:** 设计过程包括选择合适的叶片形状，使用AutoCAD和HFSS软件进行天线建模，并制造PCB原型。通过仿真和物理测试优化天线性能。

**Result:** 天线在915 MHz频率下S11参数达到接近-20 dB，表明能量捕获有效。实验结果显示天线能够在最远200厘米的距离为设备供电，充电时间反映了其效率。

**Conclusion:** 该研究得出结论，所提出的天线的仿生设计改善了射频能量传输。

> **ai_Abstract:** 本研究设计并优化了一种受自然叶片启发的射频能量传输新型叶形天线。研究目标是开发仿生天线，优化其在915 MHz频段的性能并评估其效率。通过AutoCAD和HFSS建模及PCB原型制造，并通过仿真和物理测试进行优化。结果显示，天线在915 MHz下S11参数接近-20 dB，并能在200厘米距离内为设备供电。研究认为该仿生设计有效改善了射频能量传输。

> **摘要翻译:** 本研究介绍了受自然叶片结构启发的射频能量传输新型叶形天线的设计与优化。本研究的目标是开发一种仿生天线，通过阻抗匹配优化其在915 MHz频段的性能，并评估其捕获射频能量的效率。设计过程包括选择合适的叶片形状，使用AutoCAD和HFSS软件对天线进行建模，并制作印刷电路板（PCB）原型。通过仿真和物理测试优化天线性能，在915 MHz频率下S11参数达到接近-20 dB，表明能量捕获有效。实验结果表明，该天线能够在最远200厘米的距离为设备供电，充电时间反映了其效率。研究得出结论，所提出的天线的仿生设计改善了射频能量传输。未来的工作应侧重于测试天线穿透混凝土的能力以及开发用于自主对准的反馈系统。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [54] [SA-WiSense: A Blind-Spot-Free Respiration Sensing Framework for Single-Antenna Wi-Fi Devices](https://arxiv.org/abs/2507.17623)
> *SA-WiSense：一种适用于单天线Wi-Fi设备的无盲点呼吸感知框架*

*Guangteng Liu, Xiayue Liu, Zhixiang Xu, Yufeng Yuan, Hui Zhao, Yuxuan Liu, Yufei Jiang* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** Wi-Fi感知, 呼吸监测, 盲点, 单天线, 相位偏移

**Comment:** 12pages, 10figures

> **TL;DR:** SA-WiSense提出一种适用于单天线Wi-Fi设备的无盲点呼吸感知框架，通过跨子载波CSI比率（CSCR）消除随机相位偏移，并利用遗传算法（GA）优化子载波选择，实现了高精度的呼吸监测。

**AI_Comments:** 这篇论文的创新点在于提出了CSCR方法来直接消除随机相位偏移，以及利用遗传算法优化子载波选择，从而在单天线Wi-Fi设备上实现了无盲点的呼吸监测。其成本效益高且适用于物联网设备的特性使其具有重要的实际应用价值。该研究为低成本、高精度的非接触式生命体征监测提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 当前非接触式Wi-Fi呼吸监测面临由随机相位偏移引起的盲点问题，这会破坏呼吸信号的互补性。现有解决方案通常需要多天线设备，成本较高且不适用于物联网（IoT）中普遍存在的单天线设备。

**Method:** 该论文提出了SA-WiSense框架，主要包含两部分：1. 跨子载波信道状态信息比（CSCR）方法，利用子载波之间CSI的比值来消除随机相位偏移，从而实现无盲点感知。2. 基于遗传算法的子载波选择（GASS）方法，通过优化CSCR的感知信噪比（SSNR）来选择最佳子载波，并使用遗传算法求解。该框架使用商品化的ESP32微控制器进行实验验证。

**Result:** 所提出的方法在最远8.0米的距离上实现了91.2%的呼吸监测检测率，并且比现有的单天线方法更加准确。

**Conclusion:** SA-WiSense框架通过创新的CSCR和GASS方法，成功解决了单天线Wi-Fi呼吸监测中的盲点问题和随机相位偏移，显著提高了监测精度，并为物联网应用提供了经济高效的解决方案。

> **ai_Abstract:** SA-WiSense是一种用于单天线Wi-Fi设备的无盲点呼吸感知框架，旨在解决Wi-Fi呼吸监测中由随机相位偏移引起的盲点问题。该框架通过引入跨子载波信道状态信息比（CSCR）来消除相位偏移，并利用基于遗传算法的子载波选择（GASS）来优化感知性能。SA-WiSense具有成本效益，适用于物联网设备。实验结果表明，该方法在8米距离内能达到91.2%的呼吸监测检测率，优于现有单天线方案。

> **摘要翻译:** Wi-Fi感知为非接触式人体呼吸监测提供了一种有前景的技术。然而，一个关键挑战是随机相位偏移引起的盲点问题，它会破坏呼吸信号的互补性。为了解决这一挑战，我们提出了一种单天线Wi-Fi感知（SA-WiSense）框架，以提高人体呼吸监测的准确性，并使其对随机相位偏移具有鲁棒性。所提出的SA-WiSense框架具有成本效益，因为它只使用单个天线，而不是像以前的工作那样使用多个天线。因此，所提出的框架适用于物联网（IoT），其中大多数传感器都配备了单个天线。一方面，我们提出了一种基于跨子载波信道状态信息（CSI）比率（CSCR）的盲点缓解方法，用于物联网，其中利用子载波之间两个CSI值的比率来缓解随机相位偏移。我们证明，通过所提出的CSCR方法可以消除随机相位偏移，从而恢复信号固有的互补性，实现无盲点感知。另一方面，我们提出了一种基于遗传算法（GA）的子载波选择（GASS）方法，通过根据子载波之间CSCR的感知信噪比（SSNR）来制定优化问题。GA被用于解决所制定的优化问题。我们使用商品化的ESP32微控制器构建了一个实验测试。所提出的工作经验证在最远8.0米的距离上实现了91.2%的呼吸监测检测率，比现有单天线方法准确得多。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [150] [Prime and Co-prime Integer Matrices](https://arxiv.org/abs/2505.00862)
> *素数和互素整数矩阵*

*Xiang-Gen Xia, Guangpu Guo* | **Category: eess.SP, cs.DM, cs.IT, math.IT** | **Updated: 2025-07-23**

**Keywords:** 整数矩阵, 素数矩阵, 互素矩阵, 多维互素感知, 中国剩余定理

**Comment:** 

> **TL;DR:** 本文研究并刻画了素数和互素整数矩阵，提供了一种构建互素整数矩阵族的方法，有潜在应用。

**AI_Comments:** 这项研究通过对特定整数矩阵的刻画，为潜在的应用领域（如多维互素感知和多维中国剩余定理）提供了一种实用的构建方法，显示了理论研究与实际应用结合的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究素数和互素整数矩阵的性质，并探索其在多维互素感知和多维中国剩余定理等领域的潜在应用。

**Method:** 本文调查了素数和互素整数矩阵及其性质，并刻画了所有同时也是素数整数矩阵的成对互素整数矩阵。

**Result:** 本文提供了一种构建成对互素整数矩阵族的简单方法。

**Conclusion:** 通过刻画同时是素数整数矩阵的成对互素整数矩阵，本文为多维互素感知和多维中国剩余定理等领域提供了构建相关矩阵的简单方法。

> **ai_Abstract:** 本文深入探讨了素数和互素整数矩阵的特性，并成功地刻画了同时满足素数和成对互素条件的整数矩阵。这项工作提供了一种简便的途径来构建成对互素整数矩阵族，这对于多维互素感知和多维中国剩余定理等领域可能具有重要的应用价值。

> **摘要翻译:** 本文研究了素数和互素整数矩阵及其性质。它刻画了所有同时也是素数整数矩阵的成对互素整数矩阵。这提供了一种构建成对互素整数矩阵族的简单方法，可能在多维互素感知和多维中国剩余定理中具有应用。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [279] [Real-time rail vehicle localisation using spatially resolved magnetic field measurements](https://arxiv.org/abs/2507.19327)
> *基于空间分辨磁场测量的实时轨道车辆定位*

*Niklas Dieckow, Katharina Ostaszewski, Philip Heinisch, Henriette Struckmann, Hendrik Ranocha* | **Category: eess.SP, cs.SY, eess.SY** | **Updated: 2025-07-25**

**Keywords:** 轨道车辆定位, 磁场测量, 粒子滤波, 序列对齐, 实时定位

**Comment:** 

> **TL;DR:** 本文提出了两种基于磁场测量和预录磁图的实时轨道车辆定位方法（粒子滤波和序列对齐），并结合了混合方法，展示了其在安全关键型应用中的实时能力和高精度。

**AI_Comments:** 该论文引入了利用磁场进行轨道车辆定位的新颖方法，为GNSS可能不可靠的环境提供了替代或补充解决方案。混合方法的提出是一种务实的策略，它结合了两种方法的优势（冷启动性能与跟踪精度）。此外，在消费级硬件上实现实时运行的能力也具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 为安全关键型轨道应用提供准确、鲁棒的实时轨道车辆定位，以克服现有系统的局限性。

**Method:** 本文提出了两种互补的实时轨道车辆定位方法：
1. 基于粒子滤波：通过磁相似性进行重加权，采用重尾非高斯核以增强稳定性。
2. 基于无状态序列对齐：将实时磁信号转换到空间域，并使用相似性度量与磁图匹配。
此外，还提出了一种混合方法：先进行基于对齐的初始化，然后进行粒子滤波跟踪。

**Result:** 1. 粒子滤波：在21.6公里路段上实现了亚5米精度，但在低速和冷启动时性能下降。
2. 对齐方法：在冷启动场景表现出色，92%的测试中定位精度在30米以内（使用前三匹配则为100%）。
3. 运行时分析证实了在消费级硬件上的实时能力。

**Conclusion:** 该系统提供了准确、鲁棒的定位，适用于安全关键型轨道应用。

> **ai_Abstract:** 本文介绍了两种利用磁场测量和预录磁图的实时轨道车辆定位方法：一种是采用非高斯核的粒子滤波器，另一种是无状态序列对齐技术。研究还提出了一种结合两种方法的混合策略以提升性能。实验结果表明，粒子滤波器能达到亚5米精度，但在冷启动时表现不佳，而对齐方法则在冷启动场景中表现优异（92%的测试中定位在30米内）。该系统验证了其实时能力，并能为安全关键型轨道应用提供准确且鲁棒的定位。

> **摘要翻译:** 这项工作提出了两种基于磁场测量和预先记录的磁图的互补实时轨道车辆定位方法。第一种方法使用通过磁相似性重新加权的粒子滤波器，采用重尾非高斯核以增强稳定性。第二种是无状态序列对齐技术，它将实时磁信号转换到空间域，并使用相似性度量将其与磁图匹配。使用运营列车数据进行的实验表明，粒子滤波器在21.6公里范围内实现了轨道选择性、亚5米精度，尽管其性能在低速和冷启动时会下降。精度测试受到基于GNSS的参考系统的限制。相比之下，基于对齐的方法在冷启动场景中表现出色，在92%的测试中定位在30米以内（使用前三匹配则为100%）。一种混合方法结合了两种方法——基于对齐的初始化，然后是粒子滤波器跟踪。运行时分析证实了在消费级硬件上的实时能力。该系统提供了准确、鲁棒的定位，适用于安全关键型轨道应用。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [283] [Time and Frequency Synchronization for Multiuser OTFS in Uplink](https://arxiv.org/abs/2507.17966)
> *上行链路多用户OTFS系统中的时间和频率同步*

*Mohsen Bayat, Sanoopkumar P. S., Arman Farhang* | **Category: eess.SP** | **Updated: 2025-07-23**

**Keywords:** OTFS, 时间同步, 频率同步, 多用户系统, 高移动性

**Comment:** 

> **TL;DR:** 本文提出并详细阐述了上行链路多用户OTFS系统在高速移动场景下的时间和频率同步技术，包括两种TO估计方法和一种CFO估计方法。

**AI_Comments:** 该论文的创新点在于为高移动性多用户OTFS系统设计了具体的、实用的时间和频率同步方案。通过引入带循环前缀的导频（SU-PCP和MU-PCP）和创新的相关性及滤波器组方法来解决时间偏移估计，并通过将多维CFO估计问题降维来提高计算效率。特别是，通过寻找相关函数中的第一个主要峰值而不是最高峰值来提高TO估计精度，以及应用CPF-BEM处理信道时变性，都体现了方法的精细化和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在高移动场景下，准确估计和校正时间偏移（TOs）和载波频率偏移（CFOs）对于上行链路多用户OTFS（MU-OTFS）系统至关重要。TO估计对于定位用户导频至关重要，而CFO估计则能提高信道估计精度。

**Method:** 本文提出了两种时间偏移（TO）估计技术和一种载波频率偏移（CFO）估计技术：
1.  **TO估计（方法一）：** 针对现有MU-OTFS多用户导频结构，用带循环前缀（PCP）的实际导频（称为单用户启发式PCP或SU-PCP）替换脉冲导频（IMP）。该结构使用不同的Zadoff-Chu（ZC）序列，通过接收端相关性实现导频分离，并基于此提出了一种相关性TO估计技术。
2.  **TO估计（方法二）：** 提出了一种频谱效率高且实用的导频模式（MU-PCP），其中每个用户在时延-多普勒平面上的共享导频区域内传输PCP。接收端利用滤波器组分离不同用户信号并估计其TOs。此外，推导了一个数学阈值范围，通过寻找相关函数中的第一个主要峰值而非仅依赖最高峰值来提高TO估计精度。
3.  **CFO估计：** 在定位用户接收到的导频信号后，将多维最大似然（ML）搜索问题分解为多个一维搜索问题。该技术应用第一类切比雪夫多项式基展开模型（CPF-BEM），以有效处理信道随时间的变化，从而获得所有用户的CFO估计。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对高速移动场景下的上行链路多用户OTFS系统，提出了一系列时间和频率同步技术。研究重点在于精确估计和校正时间偏移（TOs）和载波频率偏移（CFOs）。在TO估计方面，论文提出了两种方法：一是将现有导频结构中的脉冲导频替换为单用户启发式PCP（SU-PCP），利用Zadoff-Chu序列和相关性进行估计；二是设计了一种频谱高效的MU-PCP导频模式，结合滤波器组和数学阈值来精确分离和估计不同用户的TO。在CFO估计方面，提出了一种通过将多维最大似然搜索问题转化为多个一维搜索问题，并利用第一类切比雪夫多项式基展开模型（CPF-BEM）来处理信道时变性的方法。

> **摘要翻译:** 在本文中，我们提出了上行链路多用户正交时频空（OTFS）系统在高速移动场景下的时间和频率同步技术。这项工作侧重于准确估计和校正时间偏移（TOs）和载波频率偏移（CFOs）。具体而言，TO估计对于在时延-时间平面上定位用户导频至关重要，而CFO估计则能提高信道估计精度。首先，我们针对MU-OTFS中现有的多用户导频结构提出了一种TO估计技术。我们将该导频结构中的脉冲导频（IMP）替换为一种更实用的带循环前缀（PCP）的导频，称为单用户启发式PCP（SU-PCP）。该结构采用不同的Zadoff-Chu（ZC）序列，通过接收端的相关性实现导频分离。因此，我们引入了一种使用该导频结构的基于相关性的上行链路MU-OTFS的TO估计技术。其次，提出了一种频谱效率高且实用的导频模式，其中每个用户在时延-多普勒平面上的共享导频区域内传输PCP，称为MU-PCP。在接收端，第二种TO估计技术利用滤波器组分离不同用户的信号并准确估计其TOs。然后，我们推导了一个数学阈值范围，通过寻找相关函数中的第一个主要峰值而非仅依赖最高峰值来提高TO估计精度。在使用所提出的TO估计技术之一定位接收到的用户导频信号后，我们提出的CFO估计技术将多维最大似然（ML）搜索问题简化为多个一维搜索问题。在该技术中，我们应用第一类切比雪夫多项式基展开模型（CPF-BEM）来有效处理信道的时间变化，从而获得所有用户的CFO估计。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [325] [Metasurface-based Fluid Antennas: from Electromagnetics to Communications Model](https://arxiv.org/abs/2507.17982)
> *基于超表面的流体天线：从电磁学到通信模型*

*Pablo Ramírez-Espinosa, Cleofás Segura-Gómez, Ángel Palomares-Caballero, F. Javier López-Martínez, David Morales-Jiménez* | **Category: eess.SP** | **Updated: 2025-07-23**

**Keywords:** 流体天线系统, 超表面, 动态超表面天线, 分析模型, 空间分集

**Comment:** 

> **TL;DR:** 本文提出了一种基于超表面的流体天线系统（FAS）的完整分析模型，利用动态超表面天线（DMA）实现，并通过电路理论重写了信号模型，解决了现有可重构天线分析建模的挑战，并验证了其性能可与理想FAS媲美。

**AI_Comments:** 本文的创新点在于为基于超表面的流体天线系统提供了一个完整的分析模型，解决了以往电子可重构天线难以进行理论建模的难题。这使得研究人员能够从理论层面深入理解这类系统，并进行系统设计，而无需完全依赖耗时的全波仿真或测量。其重要性在于为未来FAS的开发和优化奠定了理论基础，有助于推动空间分集技术的实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 电子可重构天线在分析建模方面面临挑战，通常需要全波仿真或测量进行表征，这严重限制了提取对系统设计有用的理论见解。鉴于这些困难以及对流体天线系统（FAS）日益增长的兴趣，本文旨在提出一个完整的分析模型。

**Method:** 本文提出了一种基于超表面的流体天线系统（FAS）的完整分析模型，具体通过动态超表面天线（DMA）实现FAS概念。研究利用电路理论，根据导纳矩阵重写了传统的FAS信号模型，考虑了超表面固有的电磁效应。

**Result:** 所提出的模型通过全波仿真进行了验证，显示出良好的一致性。研究进一步说明了如何将该模型应用于标准性能分析，并提供了关键指标的闭合形式表达式，包括得到的信号协方差矩阵。结果证实，实际的基于DMA的FAS可以实现与理想位置灵活天线相似的性能。

**Conclusion:** 本文提出的基于超表面的流体天线系统（FAS）的分析模型，特别是通过动态超表面天线（DMA）实现的，能够有效解决可重构天线建模的挑战，并证明了其在实际应用中能够达到与理想FAS相当的性能。

> **ai_Abstract:** 本文针对电子可重构天线在分析建模方面的挑战，提出了一种基于超表面（特别是动态超表面天线，DMA）的流体天线系统（FAS）的完整分析模型。该模型利用电路理论，通过导纳矩阵重写了FAS的信号模型，并考虑了超表面的电磁效应。模型经全波仿真验证，结果表明实际的DMA-based FAS能够达到与理想位置灵活天线相当的性能，为FAS的理论洞察和系统设计提供了新的途径。

> **摘要翻译:** 流体天线系统（FAS）作为一种有效而简单的空间分集利用手段，已成为无线通信领域的热门话题。由于物理移动辐射单元的限制，电子可重构天线正作为FAS的实际实现方式出现，因为改变辐射方向图在功能上等同于物理移动设备。然而，电子可重构天线在分析建模方面带来了挑战，通常需要全波仿真或测量进行表征；这严重限制了提取对系统设计有用的理论见解。受这些困难以及对FAS日益增长的兴趣的驱使，本文提出了一个完整的基于超表面的FAS实现体的分析模型。具体来说，我们提倡通过动态超表面天线（DMA）来实现FAS概念，该天线迄今已被提议作为多输入多输出（MIMO）系统中的阵列替代品。我们利用电路理论，根据导纳矩阵重写了FAS的传统信号模型，考虑了超表面固有的电磁效应。该模型通过全波仿真进行了验证，显示出良好的一致性。我们进一步说明了如何将该模型应用于标准性能分析，并提供了关键指标的闭合形式表达式，包括得到的信号协方差矩阵。结果证实，实际的基于DMA的FAS可以实现与理想位置灵活天线相似的性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [367] [Multiple Active STAR-RIS-Assisted Secure Integrated Sensing and Communication via Cooperative Beamforming](https://arxiv.org/abs/2507.18035)
> *多活动STAR-RIS辅助的安全集成感知与通信通过协作波束成形*

*Hyeonho Noh, Hyeonsu Lyu, Hyun Jong Yang* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 集成感知与通信, STAR-RIS, 安全通信, 协作波束成形, 交替优化

**Comment:** 

> **TL;DR:** 本文研究了多活动STAR-RIS辅助的安全集成感知与通信网络中的协作波束成形，通过联合优化最大化通信和速率，同时满足感知与安全约束。

**AI_Comments:** 本文的创新点在于将多个活动STAR-RIS引入到安全ISAC网络中，并提出了一种有效的交替优化框架来解决复杂的非凸联合优化问题。通过考虑感知、安全和功率等多重约束，该研究为未来ISAC系统的设计提供了有价值的见解。其方法结合了KKT条件、SCA和SDP，显示出解决复杂无线通信优化问题的强大能力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在探索由多个有源同步传输和反射可重构智能表面（STAR-RIS）赋能的集成感知与通信（ISAC）网络，以在基站向多用户提供下行通信并同时询问感知目标时，最大化总通信和速率，同时满足严格的感知信噪比、保密信息泄露上限以及硬件和总功率约束。

**Method:** 联合优化基站发射波束成形器和每个活动STAR-RIS的反射/传输系数。针对由此产生的高度非凸问题，提出了一种高效的交替优化（AO）框架。首先，将原始公式重新表述为等效但更易处理的形式并划分为子问题。基站波束成形器通过KKT条件以闭式更新，而STAR-RIS的反射和传输向量通过逐次凸逼近（SCA）进行细化，生成一个半定规划问题，然后通过半定松弛求解。

**Result:** 综合仿真表明，所提出的算法在严格满足规定的感知和安全约束的同时，相对于无源RIS和单个STAR-RIS基线，提供了显著的和速率增益。

**Conclusion:** 本文提出的基于交替优化的算法能够有效优化多活动STAR-RIS辅助的安全ISAC系统，并在满足感知和安全要求的同时显著提升通信和速率。

> **ai_Abstract:** 本文研究了多活动STAR-RIS辅助的安全集成感知与通信（ISAC）网络。通过联合优化基站波束成形器和STAR-RISs的反射/传输系数，旨在最大化通信和速率，同时满足严格的感知SINR、信息泄露限制以及功率约束。针对所形成的高度非凸优化问题，提出了一种基于交替优化（AO）的解决方案，其中基站波束成形器通过KKT条件更新，STAR-RIS系数通过逐次凸逼近和半定松弛求解。仿真结果验证了该算法在提高和速率方面优于现有基线，并能有效满足感知和安全要求。

> **摘要翻译:** 本文探讨了一种由多个活动同步传输和反射可重构智能表面（STAR-RIS）赋能的集成感知与通信（ISAC）网络。基站（BS）向多个用户提供下行通信，同时询问一个感知目标。我们联合优化基站发射波束成形器以及每个活动STAR-RIS的反射/传输系数，以最大化总通信和速率，同时满足（i）严格的感知信噪比（SINR）要求，（ii）保密信息泄露的上限，以及（iii）基站和STAR-RISs的独立硬件和总功率约束。由此产生的高度非凸程序通过高效的交替优化（AO）框架进行解决。首先，将原始公式重新表述为等效但更易处理的表示形式，并划分为子问题。基站波束成形器通过Karush-Kuhn-Tucker（KKT）条件以闭式更新，而STAR-RIS反射和传输向量通过逐次凸逼近（SCA）进行细化，从而产生一个半定规划，然后通过半定松弛求解。综合仿真表明，所提出的算法相对于无源RIS和单个STAR-RIS基线，提供了显著的和速率增益，同时严格满足了规定的感知和安全约束。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [409] [Geometrical portrait of Multipath error propagation in GNSS Direct Position Estimation](https://arxiv.org/abs/2507.18096)
> *GNSS直接定位中多径误差传播的几何表征*

*Jihong Huang, Rong Yang, Wei Gao, Xingqun Zhan, Zheng Yao* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 直接定位, 多径误差, 几何分析, 卫星圆形多径偏差模型, 卫星选择

**Comment:** 

> **TL;DR:** 本文通过几何分析，研究了GNSS直接定位（DPE）中多径误差的传播特性，提出了卫星圆形多径偏差（SCMB）模型，并验证了多径对定位偏差的影响，为DPE卫星选择提供了几何参考。

**AI_Comments:** 这篇论文通过引入几何分析和SCMB模型，填补了GNSS直接定位（DPE）中多径误差理论表征的空白，具有创新性。其发现对于城市环境中DPE系统的性能优化，特别是在卫星选择方面，提供了重要的实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 尽管直接定位（DPE）能显著增强GNSS接收机在城市环境中的鲁棒性，但目前仍缺乏关于DPE理论中多径误差的理论表征。研究旨在通过几何分析填补这一空白，理解多径误差如何导致估计偏差。

**Method:** 该研究通过几何分析扩展了DPE噪声方差的理论框架，重点在于量化偏心偏差（相对于方位角和仰角）引起的CAF和PVT解的偏差，从而实现多径误差的几何表示。引入了卫星圆形多径偏差（SCMB）模型，整合了来自多个卫星通道的CAF和PVT误差。通过蒙特卡洛模拟和城市峡谷测试验证了多径几何表征的正确性。

**Result:** 研究发现，最大PVT偏差取决于不同卫星通道中观察到的最大多径误差。此外，PVT偏差随卫星仰角的增加而增大，这受CAF多径偏差投影的影响。

**Conclusion:** 论文为从几何角度选择DPE卫星提供了参考，强调了选择高低仰角平衡组合以实现最佳卫星几何配置的重要性。

> **ai_Abstract:** 本文针对GNSS直接定位（DPE）中多径误差缺乏理论表征的问题，通过几何分析方法，量化了多径对交叉模糊函数（CAF）和位置、速度、时间（PVT）解的影响，并提出了卫星圆形多径偏差（SCMB）模型。研究发现PVT偏差受最大多径误差和卫星仰角影响，且随仰角增大而增大。研究结果为优化DPE卫星选择提供了几何指导，建议选择高低仰角平衡的卫星组合。

> **摘要翻译:** 直接定位（DPE）是一种直接从GNSS信号的交叉模糊函数（CAF）中估计位置、速度和时间（PVT）信息的方法，显著增强了接收机在城市环境中的鲁棒性。然而，在DPE理论背景下，多径误差的理论表征仍然缺乏。几何观测突出了多径和热噪声引起的DPE误差的独特特征，分别表现为估计偏差和方差。本文在通过几何分析扩展DPE噪声方差理论框架的基础上，通过量化偏心偏差（相对于方位角和仰角）引起的CAF和PVT解的偏差，重点关注多径误差的几何表示。引入了卫星圆形多径偏差（SCMB）模型，整合了来自多个卫星通道的CAF和PVT误差。通过讨论各种多径条件，确定了最大或最小PVT偏差的边界。通过蒙特卡洛模拟和城市峡谷测试证实了多径几何表征的正确性。研究结果表明，最大PVT偏差取决于在各种卫星通道中观察到的最大多径误差。此外，PVT偏差随卫星仰角的增加而增大，这受CAF多径偏差投影的影响。这为从几何角度选择DPE卫星提供了参考，强调了选择高低仰角平衡组合以实现最佳卫星几何配置的重要性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [439] [Envelope Control Enabled Probabilistic Shaping for Peak Power Constrained IM DD Systems](https://arxiv.org/abs/2507.18149)
> *包络控制赋能的峰值功率受限IM-DD系统概率成形*

*Dongdong Zou, Wei Wang, Jiawen Yao, Zhongxing Tian, Zeyu Feng, Huan Huang, Fan Li, Gordon Ning Liu, Gangxiang Shen, Yi Cai* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 概率成形, IM-DD系统, 峰值功率受限, 记忆效应, 包络控制

**Comment:** 

> **TL;DR:** 针对峰值功率受限IM-DD系统中概率成形的有效应用问题，本文提出了一种新的间接概率成形方案，通过信号包络控制和动态选择映射来减轻存储器效应，并在接收端使用改进的M-BCJR算法的涡轮均衡器。实验证明，该方案在56GBaud PAM8系统中实现了1dB的接收灵敏度提升。

**AI_Comments:** 这篇论文通过包络控制和新颖的映射/均衡方案解决了记忆效应问题，为在具有挑战性的IM-DD系统中应用概率成形引入了一种创新方法。所展示的性能提升以及与现有架构的兼容性突出了其实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 概率成形（PS）在强度调制和直接检测（IM-DD）系统中受到了广泛关注。然而，由于独特的系统模型和固有限制，PS技术在IM-DD系统中的有效应用仍然是一个开放性问题，尤其是在具有记忆效应的系统中。

**Method:** 提出了一种新颖的间接概率成形（PS）方案，专为峰值功率受限（PPC）IM-DD系统设计。该方法通过策略性地控制信号包络来减轻记忆效应引起的损伤。在发射端，采用动态选择映射（DSLM）机制，使当前符号不仅由当前比特模式决定，还由指定记忆长度内的先前生成符号决定。在接收端，提出了一种带有改进M-BCJR算法的涡轮均衡器来实现由DSLM引起的模糊比特的恢复。

**Result:** 在56GBaud PAM8系统中的实验验证表明，所提出的方案在2km单模光纤传输中实现了1dB的接收灵敏度提升。此外，该方案还被证明与典型的概率幅度成形架构兼容，实现了简单且细粒度的速率自适应能力。

**Conclusion:** 这项工作为PS技术在具有记忆效应的峰值功率受限IM-DD系统中的应用开辟了新视野。

> **ai_Abstract:** 本文解决了概率成形（PS）在具有记忆效应的峰值功率受限（PPC）强度调制和直接检测（IM-DD）系统中应用的挑战。提出了一种新颖的间接PS方案，通过控制信号包络来减轻记忆效应引起的损伤。该方案在发射端引入了动态选择映射（DSLM），并在接收端使用了带有改进M-BCJR算法的涡轮均衡器。在56GBaud PAM8系统中的实验结果表明，该方案实现了1dB的接收灵敏度提升，并与概率幅度成形兼容以实现速率自适应。

> **摘要翻译:** 概率成形（PS）在强度调制和直接检测（IM-DD）系统中受到了广泛关注。然而，由于独特的系统模型和固有限制，PS技术在IM-DD系统中的有效应用仍然是一个开放性问题，尤其是在具有记忆效应的系统中。本文提出了一种专门针对峰值功率受限（PPC）IM-DD系统的新型间接PS方案。其核心思想在于策略性地控制信号包络，以减轻记忆效应引起的损伤，例如非线性、过冲、峰均功率比增强等。所提出的方案在发射端引入了动态选择映射（DSLM）机制，实现了非典型的比特到符号映射，其中当前符号不仅由当前比特模式决定，还由指定记忆长度内的先前生成符号决定。在接收端，提出了一种带有改进M-BCJR算法的涡轮均衡器，以实现由DSLM引起的模糊比特的恢复。在56GBaud PAM8系统中的实验验证表明，所提出的方案在2km单模光纤传输中实现了1dB的接收灵敏度提升。此外，所提出的方案还被证明与典型的概率幅度成形架构兼容，实现了简单且细粒度的速率自适应能力。据我们所知，这项工作为PS技术在具有记忆效应的峰值功率受限IM-DD系统中的应用开辟了新视野。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [475] [ICWLM: A Multi-Task Wireless Large Model via In-Context Learning](https://arxiv.org/abs/2507.18167)
> *ICWLM：一种基于上下文学习的多任务无线大模型*

*Yuxuan Wen, Xiaoming Chen, Maojun Zhang, Zhaoyang Zhang* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 无线大模型, 上下文学习, 多任务学习, 物理层, 泛化能力

**Comment:** 

> **TL;DR:** ICWLM是一个无线原生基础模型，通过上下文学习实现多任务物理层问题的联合解决，克服了现有深度学习方法的局限性，并展示了强大的泛化能力。

**AI_Comments:** ICWLM的创新之处在于它是首个“无线原生”的基础模型，直接针对无线数据进行训练，而非适配LLMs。其核心贡献是引入上下文学习（ICL）来解决无线通信中数据稀缺和模型泛化的问题，显著减少了对大量再训练的需求。此外，DWA算法的应用确保了多任务学习的稳定性和效率。这项工作为构建统一、自适应的未来无线AI模型提供了新的思路，有望简化部署和提升资源管理智能化水平，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的无线通信技术（如mMIMO和mmWave）导致网络复杂性和计算需求显著增加。现有的深度学习方法在改善物理层性能方面通常是任务特定的，并且面临数据稀缺和泛化能力差的挑战。

**Method:** 本文提出了一种新颖的上下文无线大模型（ICWLM），这是一种无线原生基础模型，旨在同时进行物理层多任务学习。ICWLM直接从零开始在大规模混合无线数据集上进行训练，而不是将无线数据适配到预训练的LLMs。它联合解决了多用户预编码（和速率最大化和最大最小SINR）和信道预测等多个经典物理层问题。ICWLM的关键创新在于利用上下文学习（ICL），使其能够以最少的示范对适应不同的系统配置和信道条件，无需大量再训练。此外，采用动态权重平均（DWA）算法来动态平衡多任务训练期间的各个任务损失。

**Result:** 广泛的仿真结果表明，ICWLM与任务特定方法相比，实现了有竞争力的性能，同时对未见的系统配置表现出卓越的泛化能力。

**Conclusion:** 这项工作为未来无线网络开发统一和自适应的AI模型提供了一个有前景的范式，可能减少部署复杂性并增强智能资源管理。

> **ai_Abstract:** 本文提出了ICWLM，一个无线原生的大模型，旨在通过上下文学习（ICL）解决物理层的多任务问题。针对现有深度学习方法在无线通信中面临的任务特异性、数据稀缺和泛化能力差的挑战，ICWLM直接在大规模混合无线数据集上训练，并能联合解决多用户预编码和信道预测等问题。通过结合ICL和动态权重平均（DWA）算法，ICWLM在适应不同系统配置和信道条件时表现出卓越的泛化能力，且无需大量再训练。仿真结果显示，ICWLM在性能上与任务特定方法相当，并为未来无线网络提供了一个统一且自适应的AI模型范式。

> **摘要翻译:** 无线通信技术的快速发展，特别是大规模多输入多输出（mMIMO）和毫米波（mmWave），带来了显著的网络复杂性和计算需求。为提高物理层性能，研究人员付出了大量努力，借助于深度学习（DL）方法，然而这些方法通常是任务特定的，并且难以应对数据稀缺和泛化问题。为了解决这些挑战，我们提出了一种新颖的上下文无线大模型（ICWLM），这是一种无线原生基础模型，旨在同时进行物理层多任务学习。与将无线数据适配到预训练的大型语言模型（LLMs）的传统方法不同，ICWLM直接从零开始在大规模混合无线数据集上进行训练。它联合解决了多个经典的物理层问题，包括多用户预编码（和速率最大化和最大最小SINR）和信道预测。ICWLM的一个关键创新是其利用上下文学习（ICL），使模型能够以最少的示范对适应不同的系统配置和信道条件，从而无需大量的再训练。此外，我们采用动态权重平均（DWA）算法来动态平衡多任务训练期间的各个任务损失，确保在不同目标下高效稳定的学习。广泛的仿真结果表明，ICWLM与任务特定方法相比，实现了有竞争力的性能，同时对未见的系统配置表现出卓越的泛化能力。这项工作为未来无线网络开发统一和自适应的AI模型提供了一个有前景的范式，可能减少部署复杂性并增强智能资源管理。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [486] [GNSS Jammer and Spoofer Mitigation via Multi-Antenna Processing](https://arxiv.org/abs/2507.18166)
> *通过多天线处理缓解GNSS干扰器和欺骗器*

*Jonas Elmiger, Gian Marti, Christoph Studer* | **Category: eess.SP, cs.IT, math.IT** | **Updated: 2025-07-24**

**Keywords:** GNSS, 干扰器, 欺骗器, 多天线, 缓解

**Comment:** 

> **TL;DR:** 本文提出了一种名为SCHIEBER的新颖多天线GNSS接收机方法，无需预知接收机位置或攻击类型，即可有效缓解GNSS干扰和欺骗攻击。

**AI_Comments:** SCHIEBER方法的创新性在于它能同时应对干扰和欺骗攻击，且无需预知接收机位置或攻击类型，这大大增强了其在实际应用中的灵活性和鲁棒性。特别是针对欺骗攻击，通过结合DoA和伪距一致性测试，提供了一种新颖且对位置不变的检测机制，这对于提高GNSS系统的安全性具有重要意义。该研究对于未来GNSS抗干扰和抗欺骗技术的发展具有积极的推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 现代定位依赖于全球导航卫星系统（GNSS）的无线电信号，但其接收功率低，容易受到干扰攻击（恶意发射机发出强干扰以破坏信号捕获）和欺骗攻击（恶意发射机通过传输伪造GNSS信号来模仿合法卫星），因此需要一种能有效缓解这些威胁的方法。

**Method:** 本文提出了一种名为SCHIEBER的新颖多天线GNSS接收机方法。该方法无需预知接收机位置或攻击类型：对于干扰器，在信号捕获期间使用一种新开发的自适应空间滤波技术进行缓解；对于欺骗器，在信号捕获后，通过比较所捕获信号的方向（DoA）和伪距估计值来测试其一致性，从而识别并拒绝欺骗信号，该测试对未知的接收机位置具有不变性。

**Result:** 研究人员通过对GPS L1 C/A系统在欺骗和干扰攻击下的广泛仿真，证明了所提出方法的有效性。

**Conclusion:** 所提出的SCHIEBER方法能够有效缓解GNSS干扰和欺骗攻击，且无需预知接收机位置或攻击类型。

> **ai_Abstract:** 本文提出了一种名为SCHIEBER的多天线GNSS接收机方法，旨在解决GNSS系统易受干扰和欺骗攻击的问题。该方法无需预先了解接收机位置或攻击类型。它通过在信号捕获阶段利用自适应空间滤波技术来缓解干扰，并在信号捕获后通过比较信号的到达方向和伪距估计值来检测并拒绝欺骗信号，此检测方法对接收机位置未知的情况具有鲁棒性。通过对GPS L1 C/A系统的广泛仿真，验证了该方法的有效性。

> **摘要翻译:** 现代定位依赖于全球导航卫星系统（GNSS）的无线电信号。这些信号的接收功率较低，使其容易受到干扰攻击，即恶意发射机发出强干扰以破坏信号捕获。此外，GNSS还容易受到欺骗攻击，即恶意发射机通过传输虚假GNSS信号来模仿合法卫星。我们提出了一种名为SCHIEBER的新颖方法，适用于多天线GNSS接收机，该方法无需预知接收机位置或攻击类型即可缓解干扰器和欺骗器：干扰器在信号捕获期间通过最近开发的自适应空间滤波技术进行缓解。欺骗器在信号捕获后通过一种新颖的方法进行识别和拒绝，该方法通过比较所捕获信号的到达方向（DoA）和伪距估计值来测试其一致性，该测试对于未知的接收机位置具有不变性。我们通过对GPS L1 C/A系统在欺骗和干扰攻击下的广泛仿真，证明了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [511] [Quantized Signal Recovery with Interference via Parametrized Look-Up Tables](https://arxiv.org/abs/2507.18370)
> *通过参数化查找表恢复带干扰的量化信号*

*Morriel Kasher, Michael Tinston, Predrag Spasojevic* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 参数化查找表, 量化信号恢复, 干扰消除, 低分辨率ADC, 实时恢复

**Comment:** 13 pages, 18 figures

> **TL;DR:** 本文提出了一种利用参数化查找表（LUTs）对低分辨率模数转换器进行高效全数字后校正的方法，通过评估分析估计器并提出近似方法，实现了对期望信号的高精度实时恢复，并显著优于传统线性滤波技术。

**AI_Comments:** 本文的创新之处在于将参数化模型融入查找表（LUTs），以优化低分辨率模数转换器的信号恢复性能，特别是在存在干扰的情况下。其重要性体现在为全数字后校正提供了一种高效且鲁棒的解决方案，显著优于传统方法，并在实际应用中具有潜力。该方法对非线性量化器和时变干扰源的鲁棒性是其一大亮点。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决低分辨率模数转换器（ADCs）的后校正问题，并提高其在存在噪声和干扰情况下的性能，本文旨在通过参数化查找表（LUTs）实现高效的全数字信号恢复。

**Method:** 本文通过将参数化模型整合到查找表（LUTs）中，以优化其性能。研究评估了三种用于参数化LUT的分析估计器，并提出了几种近似方法以提高相位偏移键控（PSK）输入信号和线性调频（LFM）干扰信号估计问题的可处理性。该方法旨在实时恢复期望输入信号的瞬时值。

**Result:** 模拟结果验证了所提出的估计器能够高精度地实时恢复期望输入信号的瞬时值，包括消除由高功率带外干扰导致的前端饱和引起的谐波失真。与传统线性滤波技术相比，该估计器实现了显著的性能增益，并且对输入参数、非线性量化器和时变干扰源的变化具有鲁棒性。对于一个3比特量化音调输入，使用固定的12抽头模型，均方误差（MSE）改善了>10 dB，无杂散动态范围（SFDR）改善了>20 dBc。

**Conclusion:** 本文提出的基于参数化查找表（LUTs）的估计器能够有效地恢复低分辨率量化信号，并在存在干扰的情况下表现出高精度和鲁棒性，显著优于传统线性滤波技术。

> **ai_Abstract:** 本文提出了一种通过参数化查找表（LUTs）对低分辨率模数转换器进行高效全数字后校正的方法。该方法整合了信号、噪声和干扰的参数模型，并评估了三种分析估计器，同时提出了提高估计可处理性的近似方法。模拟结果表明，该估计器能高精度实时恢复期望信号，消除谐波失真，并比传统线性滤波技术有显著增益，对输入参数、非线性量化器和时变干扰源具有鲁棒性，在特定条件下，MSE和SFDR有显著改善。

> **摘要翻译:** 通过使用查找表（LUTs），可以实现低分辨率模数转换器的高效全数字后校正。通过为期望的输入信号、噪声水平和干扰信号整合一个参数化模型，可以优化LUT的性能。我们评估了三种与参数化LUTs集成的分析估计器，特别是应用于低分辨率、非线性或宽带量化器。我们还提出了几种近似方法，以提高相位偏移键控输入信号和线性调频干扰信号估计问题的可处理性。模拟结果验证了我们的估计器能够高精度地实时恢复所需输入信号的瞬时值。这包括消除由于高功率带外干扰导致前端饱和而混叠到所需信号带宽内的谐波失真。我们的估计器被证明比传统的线性滤波技术取得了显著的增益，同时对输入参数、非线性量化器和时变干扰源的变化也具有鲁棒性。对于一个量化为3比特并使用固定12抽头模型估计的音调输入，我们在均方误差上实现了>10 dB的改善，在无杂散动态范围上实现了>20 dBc的改善。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [547] [A Foundation Model for Massive MIMO Precoding with an Adaptive per-User Rate-Power Tradeoff](https://arxiv.org/abs/2507.18587)
> *一种用于大规模MIMO预编码的基础模型，具有自适应的用户速率-功率权衡*

*Jérôme Emery, Ali Hasanzadeh Karkan, Jean-François Frigon, François Leduc-Primeau* | **Category: eess.SP, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大规模MIMO, 预编码, 基础模型, 深度学习, 数据增强

**Comment:** 6 pages, 3 figures. Accepted to the IEEE International Symposium on
  Personal, Indoor and Mobile Radio Communications (PIMRC) 2025

> **TL;DR:** 提出了一种基于Transformer的大规模MIMO预编码基础模型，可在动态调整用户速率需求的同时最小化能耗，并通过数据增强克服数据稀缺问题。

**AI_Comments:** 本文提出了一种创新的基于Transformer的基础模型，用于大规模MIMO预编码，有效解决了深度学习模型在实际部署中面临的数据稀缺和训练复杂性问题。其通过数据增强方法提升模型适应性，并在性能与复杂度之间取得了良好平衡，有望推动深度学习在无线通信领域的实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习（DL）已成为大规模多输入多输出（mMIMO）系统中预编码的一种解决方案，但其模型训练需要高质量的本地数据集，而这通常难以收集。

**Method:** 提出了一种基于Transformer的大规模MIMO预编码基础模型，旨在最小化发射机能耗并自适应每用户速率需求。为解决数据稀缺环境下的模型适应性问题，引入了一种数据增强方法，通过计算预训练特征提取器输出之间的余弦相似度来寻找与目标分布相似的训练样本。

**Result:** 在相同能耗下，所提出的基础模型在零样本部署时显著优于零迫（ZF）算法，并且以8倍的复杂度降低接近加权最小均方误差（WMMSE）的性能。

**Conclusion:** 该工作通过解决数据可用性和训练复杂性挑战，使得基于深度学习的解决方案得以实际应用。此外，动态配置每用户速率需求的能力可被更高层级的资源分配和调度算法利用，以更好地控制能效、频谱效率和公平性。

> **ai_Abstract:** 本文针对大规模MIMO预编码中深度学习模型训练所需高质量本地数据集难以获取的问题，提出了一种基于Transformer的基础模型。该模型旨在最小化发射机能耗并自适应每用户速率需求，并通过引入数据增强方法来应对数据稀缺环境下的模型适应性挑战。实验结果表明，该模型在零样本部署时性能显著优于零迫算法，且能以更低的复杂度接近加权最小均方误差的性能。这项工作为深度学习在实际通信系统中的应用提供了可行性。

> **摘要翻译:** 深度学习（DL）已成为大规模多输入多输出（mMIMO）系统中预编码的一种解决方案，因为它能够学习传播环境的特征。然而，训练这样的模型需要部署现场高质量的本地数据集，而这通常难以收集。我们提出了一种基于Transformer的大规模MIMO预编码基础模型，旨在最小化发射机的能耗，同时动态适应每用户的速率需求。在相同能耗下，所提出的基础模型的零样本部署显著优于零迫（ZF）算法，并且以8倍的复杂度降低接近加权最小均方误差（WMMSE）的性能。为了解决数据稀缺环境下的模型适应性问题，我们引入了一种数据增强方法，通过计算预训练特征提取器输出之间的余弦相似度来寻找与目标分布相似的训练样本。我们的工作通过解决数据可用性和训练复杂性的挑战，使得基于深度学习的解决方案得以实际应用。此外，动态配置每用户速率需求的能力可以被更高级别的资源分配和调度算法利用，以更好地控制能效、频谱效率和公平性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [619] [Multi-frame Detection via Graph Neural Networks: A Link Prediction Approach](https://arxiv.org/abs/2410.13436)
> *基于图神经网络的多帧检测：一种链接预测方法*

*Zhihao Lin, Chang Gao, Junkun Yan, Qingfu Zhang, Bo Chen, Hongwei Liu* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 多帧检测, 图神经网络, 链接预测, 弱目标检测, 虚警抑制

**Comment:** 

> **TL;DR:** 本文提出一种基于图神经网络（GNNs）的链接预测方法，将多帧检测问题重新定义为图中的链接预测任务，以解决现有算法的性能损失和信息利用不足问题。该方法统一了目标轨迹搜索和检测过程，有效提升了弱目标检测性能并抑制了虚警。

**AI_Comments:** 该论文的创新点在于将多帧检测问题巧妙地重新构建为图神经网络中的链接预测任务，而非传统的节点分类。这种方法有效地统一了轨迹搜索和轨迹检测这两个通常分离的步骤，并通过GNNs深度整合了多维特征，从而有望在弱目标检测领域提供更鲁棒、高效的解决方案。该方法的提出对于提升雷达、声呐等领域的弱目标探测能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的高效多帧检测算法通常基于三个顺序步骤（绘图提取、轨迹搜索和轨迹检测），但这可能导致显著的检测性能损失且未能充分利用跨帧的可用回波信息。此外，现有应用于多帧检测的图神经网络算法主要基于节点分类任务，无法直接输出目标轨迹。

**Method:** 本文将多帧检测问题重新定义为图中的链接预测任务。首先，对超过低阈值的多帧观测进行粗略关联，以构建观测关联图。其次，设计了一个基于图神经网络的多特征链接预测网络，该网络集成了回波结构、多普勒信息和绘图的时空耦合等多维信息。通过利用链接预测原理，将轨迹搜索和轨迹检测过程统一为一个步骤。

**Result:** 实验结果表明，与传统的单帧和多帧检测算法相比，所提出的算法在抑制虚警的同时，提高了弱目标的检测性能。此外，可解释性分析表明，所设计的网络有效整合了所利用的特征，从而能够准确关联目标和虚警。

**Conclusion:** 本文提出的基于图神经网络的链接预测方法有效解决了传统多帧检测算法的局限性，通过统一轨迹搜索和检测过程并整合多维信息，显著提升了弱目标检测性能并抑制了虚警。

> **ai_Abstract:** 本文提出了一种新颖的多帧检测算法，将该问题重新定义为基于图神经网络（GNNs）的链接预测任务。该方法首先构建观测关联图，然后设计了一个多特征链接预测网络，整合了回波结构、多普勒信息和时空耦合等多种维度信息。通过将轨迹搜索和轨迹检测统一为一个步骤，该算法在弱目标检测和虚警抑制方面表现出优于传统单帧和多帧检测算法的性能。

> **摘要翻译:** 多帧检测算法可以有效利用连续回波之间的相关性，以提高弱目标的检测性能。现有的高效多帧检测算法通常基于三个顺序步骤：通过相对较低的初级阈值进行绘图提取、轨迹搜索和轨迹检测。然而，这些三阶段处理算法可能会导致显著的检测性能损失，并且未能充分利用跨帧的可用回波信息。至于将图神经网络应用于多帧检测，现有算法主要基于节点分类任务，无法直接输出目标轨迹。在本文中，我们将多帧检测问题重新定义为图中的链接预测任务。首先，我们对超过低阈值的多帧观测进行粗略关联，以构建观测关联图。随后，设计了一个基于图神经网络的多特征链接预测网络，该网络集成了回波结构、多普勒信息和绘图的时空耦合等多维信息。通过利用链接预测原理，我们将轨迹搜索和轨迹检测过程统一为一个步骤，以减少性能损失并直接输出目标轨迹。实验结果表明，与传统的单帧和多帧检测算法相比，所提出的算法在抑制虚警的同时，提高了弱目标的检测性能。此外，可解释性分析表明，所设计的网络有效整合了所利用的特征，从而能够准确关联目标和虚警。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [640] [Variational Bayesian Inference for Multiple Extended Targets or Unresolved Group Targets Tracking](https://arxiv.org/abs/2407.15226)
> *变分贝叶斯推理用于多扩展目标或未分辨群目标跟踪*

*Yuanhao Cheng, Yunhe Cao, Tat-Soon Yeo, Yulin Zhang, Fu Jie* | **Category: eess.SP, cs.SY, eess.SY** | **Updated: 2025-07-25**

**Keywords:** 变分贝贝斯推理, 扩展目标跟踪, 群目标跟踪, 随机矩阵模型, 数据关联

**Comment:** 21 pages, 14 figures, 4 tables

> **TL;DR:** 该论文提出了一种基于变分贝叶斯推理的方法，用于在杂波环境中跟踪多扩展目标或未分辨群目标，并通过两种轻量化方案降低了计算复杂度。

**AI_Comments:** 这篇论文的创新点在于将变分贝叶斯推理应用于多扩展目标或未分辨群目标跟踪，并结合随机矩阵模型和概率数据关联处理复杂环境下的不确定性。其提出的两种轻量化方案也增强了方法的实用性。在杂波环境下实现高精度和高适应性的目标跟踪是一个重要且具有挑战性的问题。

<details>
  <summary>Details</summary>

**Motivation:** 在杂波环境中跟踪多扩展目标或未分辨群目标是一个挑战，尤其是在测量源不确定性较高的情况下。

**Method:** 该方法首先基于随机矩阵模型（RMM）将目标联合状态建模为Gamma Gaussian Inverse Wishart (GGIW) 分布。然后，考虑杂波引起的测量源不确定性，采用概率数据关联的思想，将联合关联事件描述为联合先验分布中的未知参数。接着，利用变分贝叶斯推理（VBI）近似求解非解析后验分布。为提高实用性，还提出了两种轻量化方案：一种是基于聚类修剪联合关联事件，另一种是通过边缘关联概率简化变分后验。

**Result:** 通过仿真和真实数据实验证明了所提出方法的有效性。结果显示，该方法在准确性和适应性方面优于当前最先进的方法。

**Conclusion:** 所提出的基于变分贝叶斯推理的多扩展目标或未分辨群目标跟踪方法在杂波环境中表现出优越的准确性和适应性，并且通过轻量化方案提高了实用性。

> **ai_Abstract:** 本文提出了一种创新的变分贝叶斯推理（VBI）方法，用于在杂波环境中跟踪多扩展目标或未分辨群目标。该方法利用随机矩阵模型和GGIW分布对目标状态进行建模，并通过概率数据关联处理测量源不确定性。为解决非解析后验分布，采用了VBI。此外，为提高实用性，论文还提出了两种计算复杂度较低的轻量化方案。仿真和真实数据显示，该方法在准确性和适应性上均优于现有先进方法。

> **摘要翻译:** 本文提出了一种在杂波环境下跟踪多扩展目标或不可分辨群目标的方法。首先，基于随机矩阵模型（RMM），将目标的联合状态建模为Gamma Gaussian Inverse Wishart (GGIW) 分布。考虑到杂波引起的测量源不确定性，我们采用了概率数据关联的思想，并将联合关联事件描述为联合先验分布中的一个未知参数。然后，采用变分贝叶斯推理（VBI）来近似求解非解析的后验分布。此外，为确保所提方法的实用性，我们进一步提供了两种潜在的轻量化方案以降低其计算复杂度。其中一种基于聚类，有效修剪了联合关联事件。另一种是通过边缘关联概率简化变分后验。最后，通过仿真和真实数据实验证明了所提方法的有效性，并且我们展示了所提方法在准确性和适应性方面优于当前最先进的方法。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [661] [Learning Wideband User Scheduling and Hybrid Precoding with Graph Neural Networks](https://arxiv.org/abs/2503.04233)
> *基于图神经网络的宽带用户调度和混合预编码学习*

*Shengjie Liu, Chenyang Yang, Shengqian Han* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 图神经网络, 用户调度, 混合预编码, 宽带多天线系统, 资源分配

**Comment:** 

> **TL;DR:** 宽带多天线系统中的用户调度和混合预编码联合学习面临挑战。本文提出了一种基于图神经网络（GNN）的两级联模块架构来解决此问题，并针对GNN的同参数同决策（SPSD）特性进行了改进。仿真结果表明该架构性能良好且具有泛化能力。

**AI_Comments:** 本文通过将图神经网络（GNNs）应用于宽带用户调度和混合预编码的联合优化这一具有挑战性的问题，做出了重要贡献。其关键创新在于识别并有效缓解了GNN在无线资源分配中存在的“同参数同决策”（SPSD）特性。所提出的改进（调度器使用一系列GNNs，预编码器采用新颖的注意力机制）展现了对GNN在此背景下局限性的深刻理解。该方法在不同系统规模下的强大泛化能力是一个主要优势，突显了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 宽带多天线系统中的用户调度和混合预编码由于资源块上大量的用户组合以及资源块之间共享模拟预编码器等挑战，从未被联合学习过。

**Method:** 通过将联合优化问题重新表述为等效的函数优化问题，本文提出了一种基于图神经网络（GNN）的架构，该架构由两个级联模块组成。针对发现的无线策略的同参数同决策（SPSD）特性，开发了一系列GNNs来增强调度器模块，并基于SPSD特性分析设计了一种新颖的注意力机制用于预编码器模块中的信息聚合。

**Result:** 仿真结果表明，所提出的架构在短推理时间和低训练复杂度下实现了令人满意的频谱效率，并且可以泛化到用户、资源块以及基站和用户天线的数量。

**Conclusion:** 所提出的GNN架构有效地实现了宽带多天线系统中的用户调度和混合预编码的联合学习，克服了现有挑战，并展示了在不同系统规模下的出色性能和泛化能力。

> **ai_Abstract:** 本文旨在解决宽带多天线系统中用户调度和混合预编码联合学习的难题，该难题源于用户组合的庞大性及资源块间模拟预编码器的共享。研究人员提出了一种基于图神经网络（GNN）的架构，包含两个级联模块以联合学习这些策略。文章发现并解决了GNN在处理相似用户信道时存在的“同参数同决策”（SPSD）特性，通过为调度器模块开发一系列GNNs，并为预编码器模块设计了一种新颖的注意力机制。仿真结果验证了该架构能实现令人满意的频谱效率、短推理时间、低训练复杂度，并对用户、资源块和天线数量具有良好的泛化能力。

> **摘要翻译:** 宽带多天线系统中的用户调度和混合预编码从未被联合学习过，这是由于资源块（RBs）上大量的用户组合以及RBs之间共享模拟预编码器所带来的挑战。在本文中，我们致力于使用图神经网络（GNNs）联合学习调度和预编码策略，GNNs由于其在问题规模上的泛化潜力，已成为优化资源分配的强大工具。通过将联合优化问题重新表述为调度和预编码策略的等效函数优化问题，我们提出了一种基于GNN的架构，该架构由两个级联模块组成，用于学习这两种策略。我们发现无线策略在集合上定义时具有同参数同决策（SPSD）特性，这表明当用户信道相似时，GNN无法很好地学习最优调度策略。这促使我们开发一系列GNNs来增强调度器模块。此外，通过分析SPSD特性，我们发现GNN中的线性聚合器何时会阻碍规模泛化。基于这一观察，我们为预编码器模块中的信息聚合设计了一种新颖的注意力机制。仿真结果表明，所提出的架构在短推理时间和低训练复杂度下实现了令人满意的频谱效率，并且可以泛化到基站和用户的数量、资源块和天线数量。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [703] [Evaluating the Scalability of Binary and Ternary CNN Workloads on RRAM-based Compute-in-Memory Accelerators](https://arxiv.org/abs/2505.07490)
> *评估基于RRAM的存内计算加速器上二值和三值CNN工作负载的可扩展性*

*José Cubero-Cascante, Rebecca Pelke, Noah Flohr, Arunkumar Vaidyanathan, Rainer Leupers, Jan Moritz Joseph* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** RRAM, 存内计算, CNN, ADC, 寄生效应

**Comment:** PREPRINT - Presented at the 2025 IEEE Computer Society Annual
  Symposium on VLSI (ISVLSI 2025)

> **TL;DR:** 本文引入了新的模拟方法来评估RRAM-based CIM加速器上二值和三值CNN的性能，发现三值CNN对寄生效应和低ADC分辨率更具弹性，但能效降低了40%。

**AI_Comments:** 该论文通过引入创新的模拟方法，深入分析了RRAM-based CIM加速器在处理二值和三值CNN工作负载时面临的关键挑战，即线寄生效应和ADC分辨率限制。其贡献在于提供了精确的建模工具和对不同CNN类型性能权衡的量化分析，这对于指导未来节能型深度学习硬件的设计至关重要。研究揭示了三值CNN在鲁棒性上的优势和能效上的劣势，为设计者提供了宝贵的取舍信息。

<details>
  <summary>Details</summary>

**Motivation:** 卷积神经网络（CNN）日益增长的计算需求需要节能的加速策略。基于电阻式随机存取存储器（RRAM）的存内计算（CIM）架构通过减少数据移动和实现低功耗原位计算提供了一种有前景的解决方案。然而，其效率受限于外围电路，特别是模数转换器（ADC）的高成本。

**Method:** 本文引入了新的模拟方法来建模电阻线寄生效应和有限ADC分辨率对RRAM交叉阵列的影响。寄生效应模型采用向量化算法，计算交叉阵列输出电流的误差低于0.15%。此外，提出了一种可变步长ADC和校准方法，显著降低了ADC分辨率要求。这些精度模型与基于统计的能量模型相结合，并用于对二值和三值CNN进行比较分析。

**Result:** 实验结果表明，三值CNN对线寄生效应和较低的ADC分辨率表现出更大的弹性，但能效降低了40%。

**Conclusion:** 这些发现为优化基于RRAM的CIM加速器以实现节能深度学习提供了有价值的见解。

> **ai_Abstract:** 本文针对RRAM-based存内计算（CIM）加速器中CNN计算的能效问题，特别是外围电路（如ADC）成本高昂的挑战，提出了一系列新型模拟方法。这些方法包括一个高精度的电阻线寄生效应模型以及一种可变步长ADC和校准策略，旨在降低ADC分辨率需求。研究将这些模型与能量模型结合，对二值和三值CNN进行了比较分析，发现三值CNN虽然对寄生效应和低ADC分辨率更具鲁棒性，但能效却降低了40%。研究结果为优化RRAM-based CIM加速器提供了重要指导。

> **摘要翻译:** 卷积神经网络（CNN）日益增长的计算需求需要节能的加速策略。基于电阻式随机存取存储器（RRAM）的存内计算（CIM）架构通过减少数据移动和实现低功耗原位计算提供了一种有前景的解决方案。然而，其效率受限于外围电路，特别是模数转换器（ADC）的高成本。通常采用大型交叉阵列和低ADC分辨率来缓解这一问题，但这可能会损害精度。本文引入了新的模拟方法来建模电阻线寄生效应和有限ADC分辨率对RRAM交叉阵列的影响。我们的寄生效应模型采用向量化算法，计算交叉阵列输出电流的误差低于0.15%，与SPICE相比。此外，我们提出了一种可变步长ADC和校准方法，显著降低了ADC分辨率要求。这些精度模型与基于统计的能量模型相结合。使用我们的框架，我们对二值和三值CNN进行了比较分析。实验结果表明，三值CNN对线寄生效应和较低的ADC分辨率表现出更大的弹性，但能效降低了40%。这些发现为优化基于RRAM的CIM加速器以实现节能深度学习提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [745] [Theoretical Analysis for the CommSense Measurement System](https://arxiv.org/abs/2506.07685)
> *CommSense测量系统的理论分析*

*Sandip Jana, Amit Kumar Mishra, Mohammed Zafar Ali Khan* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** CommSense, 6G, 集成感知与通信, PCA, SVM, OFDM

**Comment:** 

> **TL;DR:** 本文对一种将基于PCA的检测器嵌入标准OFDM接收器的CommSense框架进行了深入分析，旨在实现6G网络中快速、准确、鲁棒的无设备散射体感知。

**AI_Comments:** 本文的创新点在于提出了将PCA与SVM结合应用于CommSense框架，实现了在6G网络背景下快速、准确且鲁棒的无设备散射体感知。通过降维和优化检测器选择，解决了传统方法中推理时间长和对参数估计误差敏感的问题。这对于未来6G中通信与感知的深度融合具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 未来的6G网络旨在融合通信与感知，利用OFDM波形实现高吞吐量数据传输和环境感知。现有方法在实时、无设备检测被动散射体方面存在挑战，本研究旨在通过CommSense框架解决此问题。

**Method:** 本研究对CommSense框架进行了彻底分析，该框架将轻量级、基于PCA的检测器嵌入标准OFDM接收器中，以实现实时、无设备的被动散射体检测。研究基于现实的三链路Rician信道模型，比较了四种检测器：全维度似然比检验（Full LRT）、基于PCA的LRT、以及带有线性和RBF核的PCA-SVM。

**Result:** 通过将N维CSI投影到P（远小于N）个主成分子空间，推理时间比全LRT减少了一个数量级，同时实现了最佳错误率（经验错误与Bhattacharyya错误界限紧密对齐，当P约等于10时，ROC曲线下面积（AUC）约等于1）。仿真结果表明，基于LRT的技术容易受到参数估计误差的影响，而SVM则对此具有弹性。

**Conclusion:** 研究结果表明，基于PCA的检测与轻量级SVM相结合，可以提供快速、准确、鲁棒的散射体感知，为6G及未来网络中的集成感知与通信（ISAC）铺平了道路。

> **ai_Abstract:** 本文对用于6G网络集成感知与通信（ISAC）的CommSense测量系统进行了理论分析。该系统将基于PCA的轻量级检测器嵌入标准OFDM接收器，以实现实时、无设备的被动散射体检测。研究比较了多种检测器在Rician信道模型下的性能，发现基于PCA的方法能显著减少推理时间并保持高检测精度。特别是，结合PCA的SVM表现出对参数估计误差的鲁棒性，证明了其在未来6G ISAC应用中的潜力。

> **摘要翻译:** 未来的6G网络设想模糊通信与感知的界限，利用无处不在的OFDM波形进行高吞吐量数据传输和环境感知。在这项工作中，我们对基于通信的感知（CommSense）框架进行了彻底分析，该框架将轻量级、基于PCA的检测器嵌入到标准OFDM接收器中；从而无需任何额外的发射器即可实现实时、无设备的被动散射体（例如无人机、车辆等）检测。从现实的三链路Rician信道模型（直接Tx到Rx，级联Tx到散射体，以及散射体到Rx）开始，我们比较了四种检测器：全维度似然比检验（Full LRT）、基于PCA的LRT、以及带有线性和RBF核的PCA-SVM。通过将N维CSI投影到P（远小于N）个主成分子空间，推理时间比全LRT减少了一个数量级，同时实现了最佳错误率，即经验错误与Bhattacharyya错误界限紧密对齐，并且当P约等于10时，ROC曲线下面积（AUC）约等于1。从仿真结果我们已经表明，基于LRT的技术容易受到参数估计误差的影响，而SVM则对此具有弹性。我们的结果表明，当基于PCA的检测与轻量级SVMs结合时，可以提供快速、准确、鲁棒的散射体感知，为6G及未来网络中的集成感知与通信（ISAC）铺平了道路。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [787] [Masked Autoencoders that Feel the Heart: Unveiling Simplicity Bias for ECG Analyses](https://arxiv.org/abs/2506.22495)
> *感知心脏的掩码自编码器：揭示心电图分析中的简单性偏差*

*He-Yang Xu, Hongxiang Gao, Yuwen Li, Xiu-Shen Wei, Chengyu Liu* | **Category: eess.SP, cs.AI, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 心电图分析, 简单性偏差, 自监督学习, 掩码自编码器, 时频特征

**Comment:** there are factual errors

> **TL;DR:** 本文揭示了心电图（ECG）分析中监督模型存在的简单性偏差（Simplicity Bias, SB），该偏差导致模型忽略细微但关键的临床信息。作者提出了一种基于自监督学习（SSL）的新方法，通过时频感知滤波器和多粒度原型重建来缓解SB，并在大规模ECG数据集上取得了最先进的性能。

**AI_Comments:** 这篇论文通过深入探讨心电图（ECG）分析中的“简单性偏差”问题，揭示了传统监督学习模型在处理复杂、动态医学信号时的局限性。其创新点在于将自监督学习（SSL）引入ECG领域，并提出了具体的技术方案，如时频感知滤波器和多粒度原型重建，以有效捕获ECG信号的细微变化。此外，构建大规模多中心ECG数据集对于推动该领域的研究具有重要意义。该工作不仅在理论上分析了偏差，还在实践中提供了解决方案，并取得了SOTA性能，对临床诊断和ECG智能分析具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 监督式心电图（ECG）模型倾向于过拟合主导和重复模式，从而忽略细微但临床关键的线索，这种现象被称为简单性偏差（Simplicity Bias, SB），即模型偏爱易于学习的信号而非细微但信息丰富的信号。本文旨在实证证明SB在ECG分析中的存在及其对诊断性能的负面影响，并发现自监督学习（SSL）可以缓解这一问题，从而提供解决偏差的有希望的方向。

**Method:** 本文提出了一种遵循自监督学习（SSL）范式的新方法，包含两个关键组件：1）时频感知滤波器（Temporal-Frequency aware Filters），用于捕获反映ECG信号动态特性的时频特征；2）在此基础上，多粒度原型重建（Multi-Grained Prototype Reconstruction），用于跨双域进行粗粒度和细粒度表示学习，以进一步缓解简单性偏差（SB）。为推动ECG分析中的SSL，研究者还整理了一个包含来自300多个临床中心的153万份记录的大规模多中心ECG数据集。

**Result:** 在六个ECG数据集上的三个下游任务的实验表明，本文提出的方法能有效减少简单性偏差（SB），并取得了最先进的性能。

**Conclusion:** 本文提出的基于自监督学习的方法能够有效减少ECG分析中的简单性偏差，并在多项任务上实现了最先进的诊断性能。

> **ai_Abstract:** 本文研究了心电图（ECG）分析中监督模型存在的简单性偏差（Simplicity Bias, SB），该偏差导致模型忽略细微但临床关键的信号。研究发现自监督学习（SSL）可以有效缓解SB。基于此，作者提出了一种新颖的SSL方法，包含时频感知滤波器和多粒度原型重建，旨在捕获ECG的动态特性并进行多粒度表示学习，从而进一步减轻SB。为支持ECG的SSL研究，还构建了一个大规模多中心ECG数据集。实验证明，该方法能有效降低SB，并在多个下游任务上达到了最先进的性能。

> **摘要翻译:** 心电图（ECG）的诊断价值在于其动态特性，涵盖了从节律波动到随时间域和频率域演变的细微波形变形。然而，监督式ECG模型倾向于过拟合主导和重复模式，从而忽略细微但临床关键的线索，这种现象被称为简单性偏差（Simplicity Bias, SB），即模型偏爱易于学习的信号而非细微但信息丰富的信号。在这项工作中，我们首先实证证明了SB在ECG分析中的存在及其对诊断性能的负面影响，同时发现自监督学习（SSL）可以缓解这一问题，为解决该偏差提供了有希望的方向。遵循SSL范式，我们提出了一种新方法，包含两个关键组件：1）时频感知滤波器，用于捕获反映ECG信号动态特性的时频特征；2）在此基础上，多粒度原型重建，用于跨双域进行粗粒度和细粒度表示学习，进一步缓解SB。为了推动ECG分析中的SSL，我们整理了一个包含来自300多个临床中心的153万份记录的大规模多中心ECG数据集。在六个ECG数据集上的三个下游任务的实验表明，我们的方法能有效减少SB并取得了最先进的性能。代码和数据集将公开发布。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [829] [EEG Foundation Models: A Critical Review of Current Progress and Future Directions](https://arxiv.org/abs/2507.11783)
> *脑电图基础模型：当前进展和未来方向的批判性综述*

*Gayal Kuruppu, Neeraj Wagh, Yogatheesan Varatharajah* | **Category: eess.SP, cs.AI, cs.LG, q-bio.NC** | **Updated: 2025-07-23**

**Keywords:** 脑电图基础模型, 自监督学习, Transformer, 批判性综述, 脑电图特征提取

**Comment:** 20 pages, 5 figures, 3 tables (main + supplement)

> **TL;DR:** 本文对早期脑电图基础模型（EEG-FMs）进行了批判性综述，发现多数采用基于Transformer的序列建模和掩码序列重建，但模型评估异质且有限，难以评估实际效用。未来需要标准化评估、更强的扩展效应以及与领域专家合作以提高实际应用价值。

**AI_Comments:** 这篇综述文章的重要性在于及时梳理了新兴的脑电图基础模型领域，指出了当前研究的共性和局限性。它不仅总结了现有方法，更重要的是明确了未来研究的方向，例如标准化评估、扩展性验证以及与领域应用的结合，这对于推动该领域的健康发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 监督式脑电图编码器难以学习鲁棒的脑电图模式且过度依赖昂贵的信号标注，促使研究转向通用自监督脑电图编码器（即脑电图基础模型）。然而，早期脑电图基础模型的实际应用准备情况和长期研究进展的准则尚不明确，因此需要系统全面的综述来理解当前技术水平并确定未来方向。

**Method:** 本研究回顾了10个早期的脑电图基础模型，并对其方法论、实证发现和突出研究空白进行了批判性综合。

**Result:** 研究发现，大多数脑电图基础模型采用基于Transformer骨干和掩码序列重建进行自监督的序列建模方案。然而，模型评估仍然异质且大部分受限，这使得评估其开箱即用的实用性变得困难。

**Conclusion:** 未来工作除了采用标准化和真实的评估外，还应展示更实质性的扩展效应，并在脑电图表示学习流程中做出有原则且值得信赖的选择。与领域专家合作开发基准、软件工具、技术方法和应用可能进一步提高脑电图基础模型的转化实用性和实际应用。

> **ai_Abstract:** 本文对早期脑电图基础模型（EEG-FMs）的当前进展进行了批判性综述，旨在解决监督式编码器学习鲁棒模式和依赖标注的局限性。研究回顾了10个EEG-FMs，发现它们普遍采用基于Transformer的序列建模和掩码序列重建，但评估方法不一致且有限。作者强调未来需要标准化评估、展示更大的扩展效应，并在模型选择上更加严谨，同时建议与领域专家合作以促进EEG-FMs的实际应用。

> **摘要翻译:** 通过脑电图（EEG）记录的电脑活动模式对科学和临床研究具有巨大价值。监督式脑电图编码器无法学习鲁棒的脑电图模式以及它们对昂贵信号标注的过度依赖，促使研究转向通用自监督脑电图编码器，即脑电图基础模型（EEG-FMs），以实现鲁棒和可扩展的脑电图特征提取。然而，早期脑电图基础模型的实际应用准备情况以及长期研究进展的准则尚不明确。因此，有必要对第一代脑电图基础模型进行系统而全面的综述，以了解当前的技术水平并确定未来脑电图基础模型的关键方向。为此，本研究综述了10个早期的脑电图基础模型，并对其方法论、实证发现和突出研究空白进行了批判性综合。我们发现大多数脑电图基础模型采用基于Transformer骨干和掩码序列重建进行自监督的序列建模方案。然而，模型评估仍然异质且大部分受限，这使得评估其开箱即用的实用性变得困难。除了采用标准化和真实的评估外，未来的工作还应展示更实质性的扩展效应，并在脑电图表示学习流程中做出有原则且值得信赖的选择。我们相信，与领域专家合作开发基准、软件工具、技术方法和应用可能进一步提高脑电图基础模型的转化实用性和实际应用。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [877] [Phase-optimised linearly-constrained minimum-variance beamformers](https://arxiv.org/abs/2507.14937)
> *相位优化线性约束最小方差波束形成器*

*Hugh L Kennedy* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 波束形成器, 线性约束最小方差, 群延迟, 噪声功率, 处理延迟

**Comment:** Fixed a few minor things spotted since the initial upload

> **TL;DR:** 提出了一种确定线性约束最小方差（LCMV）波束形成器最佳群延迟的新方法，并探讨了两种优化延迟的选择：最小化噪声功率或最小化处理延迟，通过VHF通信和UHF双基地雷达应用进行了验证。

**AI_Comments:** 这项研究的创新之处在于识别并利用了LCMV波束形成器中未被探索的群延迟设计自由度。通过提供两种优化策略（最小化噪声或延迟），该方法为实际应用提供了灵活性和潜在的性能提升。其重要性在于为波束形成器的设计提供了新的维度，可能在通信和雷达系统中实现更优的信号处理。

<details>
  <summary>Details</summary>

**Motivation:** 探索线性约束最小方差（LCMV）波束形成器中一个未被探索的设计自由度，即最佳群延迟的确定。

**Method:** 提出了一种确定最佳群延迟的新程序。推荐了两种选择最佳延迟的方法：一是最小化噪声功率的解；二是最小化处理延迟的解。

**Result:** 通过模拟甚高频（VHF）通信和超高频（UHF）双基地雷达应用，探索了这种设计自由度的潜力。

**Conclusion:** 通过探索最佳群延迟，可以优化线性约束最小方差（LCMV）波束形成器的性能，以最小化噪声功率或处理延迟。

> **ai_Abstract:** 本文提出了一种优化线性约束最小方差（LCMV）波束形成器的新方法，通过确定最佳群延迟来提高性能。该方法提供了两种优化选择：最小化噪声功率或最小化处理延迟。研究通过模拟VHF通信和UHF双基地雷达应用验证了这一新设计自由度的潜力。

> **摘要翻译:** 本文提出了一种确定线性约束最小方差（LCMV）波束形成器最佳群延迟的新程序。推荐了两种选择最佳延迟的方法：第一种是使噪声功率最小化的解决方案；第二种是使处理延迟最小化的解决方案。通过模拟甚高频（VHF）通信和超高频（UHF）双基地雷达应用，探索了这种迄今为止未被探索的设计自由度的潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [4] [MLRU++: Multiscale Lightweight Residual UNETR++ with Attention for Efficient 3D Medical Image Segmentation](https://arxiv.org/abs/2507.16122)
> *MLRU++：用于高效3D医学图像分割的多尺度轻量级残差UNETR++与注意力机制*

*Nand Kumar Yadav, Rodrigue Rizk, William CW Chen, KC Santosh* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-25**

**Keywords:** 医学图像分割, 3D分割, UNETR++, 注意力机制, 轻量级网络

**Comment:** 

> **TL;DR:** MLRU++是一种新的轻量级CNN-Transformer混合架构，通过引入LCBAM和M2B模块，在保持高分割精度的同时显著提高了3D医学图像分割的计算效率。

**AI_Comments:** MLRU++的创新性在于其轻量级设计和对效率的关注，通过LCBAM和M2B模块在CNN-Transformer混合架构中实现了性能与计算成本的平衡。这对于资源受限的医疗应用尤其重要。其在多个数据集上验证的卓越性能和效率提升，使其成为3D医学图像分割领域的一个重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 由于解剖变异性和体数据的高计算需求，准确高效的医学图像分割至关重要但极具挑战性。现有混合CNN-Transformer架构虽然性能先进但复杂性高。

**Method:** 本文提出了MLRU++，一种多尺度轻量级残差UNETR++架构，旨在平衡分割精度和计算效率。它引入了两项关键创新：轻量级通道和瓶颈注意力模块（LCBAM），以最小开销增强上下文特征编码；以及解码器中的多尺度瓶颈块（M2B），通过多分辨率特征聚合捕获细粒度细节。

**Result:** 在Synapse、BTCV、ACDC和Decathlon Lung四个公开基准数据集上进行实验。MLRU++取得了最先进的性能，Synapse的平均Dice分数达到87.57%，ACDC为93.00%，Lung为81.12%。与现有领先模型相比，MLRU++在Synapse和ACDC上的Dice分数分别提高了5.38%和2.12%，同时显著减少了参数数量和计算成本。消融研究证实了LCBAM和M2B的有效性。

**Conclusion:** MLRU++为3D医学图像分割任务提供了一个实用且高性能的解决方案。

> **ai_Abstract:** 本文提出了MLRU++，一种创新的多尺度轻量级残差UNETR++架构，专为高效3D医学图像分割设计。该模型通过引入轻量级通道和瓶颈注意力模块（LCBAM）和多尺度瓶颈块（M2B）来优化上下文特征编码和细粒度细节捕获，从而在保持高分割精度的同时显著降低计算复杂性。实验结果表明，MLRU++在多个基准数据集上实现了最先进的性能，并在Dice分数上有所提升，同时显著减少了参数和计算成本，为3D医学图像分割提供了一个实用且高性能的解决方案。

> **摘要翻译:** 准确高效的医学图像分割至关重要但极具挑战性，这归因于解剖变异性和体数据的高计算需求。最近的混合CNN-Transformer架构取得了最先进的结果，但增加了显著的复杂性。在本文中，我们提出了MLRU++，一种多尺度轻量级残差UNETR++架构，旨在平衡分割精度和计算效率。它引入了两项关键创新：轻量级通道和瓶颈注意力模块（LCBAM），以最小开销增强上下文特征编码；以及解码器中的多尺度瓶颈块（M2B），通过多分辨率特征聚合捕获细粒度细节。在四个公开基准数据集（Synapse、BTCV、ACDC和Decathlon Lung）上进行的实验表明，MLRU++取得了最先进的性能，Synapse的平均Dice分数达到87.57%，ACDC为93.00%，Lung为81.12%。与现有领先模型相比，MLRU++在Synapse和ACDC上的Dice分数分别提高了5.38%和2.12%，同时显著减少了参数数量和计算成本。评估LCBAM和M2B的消融研究进一步证实了所提出架构组件的有效性。结果表明，MLRU++为3D医学图像分割任务提供了一个实用且高性能的解决方案。源代码可在以下地址获取：https://github.com/1027865/MLRUPP

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [56] [EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Control](https://arxiv.org/abs/2507.15292)
> *EndoControlMag：基于周期性参考重置和分层组织感知双掩模控制的鲁棒内窥镜血管运动放大*

*An Wang, Rulin Zhou, Mengya Xu, Yiru Ye, Longfei Gou, Yiting Chang, Hao Chen, Chwee Ming Lim, Jiankun Wang, Hongliang Ren* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 血管运动放大, 内窥镜手术, 周期性参考重置, 分层组织感知, 双掩模控制

**Comment:** 

> **TL;DR:** EndoControlMag是一个无需训练的、基于拉格朗日的框架，用于内窥镜手术中血管运动放大，通过周期性参考重置和分层组织感知双掩模控制，在复杂场景下实现了高精度和鲁棒性。

**AI_Comments:** EndoControlMag的创新之处在于其无需训练的Lagrangian框架，以及为内窥镜环境量身定制的两个核心模块：周期性参考重置有效解决了传统运动放大中常见的误差累积问题，而分层组织感知双掩模控制则通过自适应软化策略，在复杂多变的手术场景中实现了对血管运动的精准且鲁棒的放大，考虑了组织特性。其结合预训练跟踪模型和双模式软化策略，显著提升了在遮挡、器械干扰等挑战下的性能，对于提高内窥镜手术的精度和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在内窥镜手术中，可视化微弱的血管运动对于手术精度和决策至关重要，但由于手术场景的复杂性和动态性，这仍然是一个挑战。

**Method:** 本文提出了EndoControlMag，一个无需训练、基于拉格朗日的框架，采用掩模条件血管运动放大。它包含两个关键模块：1) 周期性参考重置（PRR）方案，将视频分割成短的重叠片段，动态更新参考帧以防止误差累积并保持时间连贯性；2) 分层组织感知放大（HTM）框架，采用双模式掩模膨胀。HTM首先使用预训练的视觉跟踪模型跟踪血管核心，然后对周围组织应用两种自适应软化策略之一：基于运动的软化（根据观察到的组织位移调制放大强度）或基于距离的指数衰减（模拟生物力学衰减）。

**Result:** 在EndoVMM24数据集上进行的定量指标、视觉评估和专家外科医生评估表明，EndoControlMag在放大精度和视觉质量方面显著优于现有方法，并在具有挑战性的手术条件下（包括遮挡、器械干扰、视图变化和血管变形）保持了鲁棒性。

**Conclusion:** EndoControlMag通过其创新的周期性参考重置和分层组织感知双掩模控制框架，解决了内窥镜手术中血管运动放大的挑战，显著提高了手术精度和视觉质量。

> **ai_Abstract:** EndoControlMag是一个为内窥镜手术设计的无需训练的血管运动放大框架。它通过周期性参考重置（PRR）解决误差累积问题，并采用分层组织感知放大（HTM），利用预训练跟踪模型定位血管核心，并对周围组织应用基于运动或距离的双模式软化策略。该方法在多种复杂内窥镜场景下，在放大精度、视觉质量和鲁棒性方面均显著优于现有方法。

> **摘要翻译:** 内窥镜手术中微弱血管运动的可视化对于手术精度和决策至关重要，但由于手术场景的复杂性和动态性，这仍然是一个挑战。为了解决这个问题，我们引入了EndoControlMag，一个无需训练、基于拉格朗日的框架，该框架采用掩模条件血管运动放大，专为内窥镜环境量身定制。我们的方法具有两个关键模块：一个周期性参考重置（PRR）方案，它将视频分成短的重叠片段，并动态更新参考帧以防止误差累积，同时保持时间连贯性；以及一个分层组织感知放大（HTM）框架，该框架具有双模式掩模膨胀。HTM首先使用预训练的视觉跟踪模型跟踪血管核心，即使在遮挡和视角变化的情况下也能保持准确的定位。然后，它对周围组织应用两种自适应软化策略之一：基于运动的软化，根据观察到的组织位移按比例调节放大强度；或基于距离的指数衰减，模拟生物力学力的衰减。这种双模式方法适应了不同的手术场景——基于运动的软化在复杂的组织变形中表现出色，而基于距离的软化在不可靠的光流条件下提供稳定性。我们在EndoVMM24数据集上评估了EndoControlMag，该数据集涵盖四种不同类型的手术和各种挑战性场景，包括遮挡、器械干扰、视角变化和血管变形。定量指标、视觉评估和专家外科医生评估表明，EndoControlMag在放大精度和视觉质量方面显著优于现有方法，同时在具有挑战性的手术条件下保持了鲁棒性。代码、数据集和视频结果可在https://szupc.github.io/EndoControlMag/获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [60] [Improving Multislice Electron Ptychography with a Generative Prior](https://arxiv.org/abs/2507.17800)
> *多层电子叠层衍射成像与生成式先验的改进*

*Christian K. Belardi, Chia-Hao Lee, Yingheng Wang, Justin Lovelace, Kilian Q. Weinberger, David A. Muller, Carla P. Gomes* | **Category: eess.IV, cond-mat.mtrl-sci, cs.CV, physics.optics** | **Updated: 2025-07-25**

**Keywords:** 多层电子叠层衍射成像, 扩散模型, 生成式先验, 图像重建, SSIM

**Comment:** 16 pages, 10 figures, 5 tables

> **TL;DR:** 开发了一种名为 MEP-Diffusion 的扩散模型，作为生成式先验，显著提高了多层电子叠层衍射成像的重建质量。

**AI_Comments:** 这篇论文通过引入生成式先验（扩散模型）来解决传统迭代算法在多层电子叠层衍射成像中的局限性，其创新点在于将深度学习模型与传统物理逆问题求解相结合。90.50% 的 SSIM 提升是一个非常显著的成果，表明该方法在提高图像质量方面具有巨大潜力。这种混合方法为高分辨率晶体结构成像提供了一个新的、高效的途径，有望加速材料科学和纳米技术领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多层电子叠层衍射成像算法迭代耗时且因其病态性质产生次优解。

**Method:** 开发了 MEP-Diffusion，一个专门为 MEP 训练的扩散模型，基于大型晶体结构数据库。它通过 Diffusion Posterior Sampling (DPS) 作为生成式先验集成到现有迭代求解器中，形成混合方法。

**Result:** 这种混合方法显著提高了重建 3D 体积的质量，SSIM 相较现有方法提升了 90.50%。

**Conclusion:** 将扩散模型作为生成式先验集成到多层电子叠层衍射成像中，可以显著提高图像重建质量。

> **ai_Abstract:** 本文针对多层电子叠层衍射成像（MEP）中现有迭代算法耗时且重建质量次优的问题，提出了一种名为 MEP-Diffusion 的新型扩散模型。该模型在一个大型晶体结构数据库上训练，并通过扩散后验采样（DPS）作为生成式先验集成到现有重建方法中。实验结果表明，这种混合方法显著提升了重建三维图像的质量，SSIM 相比现有方法提高了 90.50%。

> **摘要翻译:** 多层电子叠层衍射成像（MEP）是一种逆成像技术，可以通过计算从衍射图样中重建原子晶体结构的最高分辨率图像。现有的算法通常迭代地解决这个逆问题，但由于其病态性质，既耗时又产生次优解。我们开发了 MEP-Diffusion，一个专门为 MEP 训练的扩散模型，该模型在一个大型晶体结构数据库上进行训练，旨在增强现有的迭代求解器。MEP-Diffusion 可以通过扩散后验采样（DPS）轻松地作为生成式先验集成到现有的重建方法中。我们发现这种混合方法极大地提高了重建三维图像的质量，相较于现有方法，SSIM 提高了 90.50%。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [116] [Benchmarking of Deep Learning Methods for Generic MRI Multi-Organ Abdominal Segmentation](https://arxiv.org/abs/2507.17971)
> *用于通用MRI多器官腹部分割的深度学习方法基准测试*

*Deepa Krishnaswamy, Cosmin Ciausu, Steve Pieper, Ron Kikinis, Benjamin Billot, Andrey Fedorov* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-25**

**Keywords:** MRI分割, 深度学习, 基准测试, 腹部, 多器官分割

**Comment:** 

> **TL;DR:** 本文对现有MRI腹部多器官分割深度学习模型进行了基准测试，并引入了一个基于CT分割数据训练的新模型ABDSynth，发现MRSegmentator表现最佳，而ABDSynth在数据有限时是一个可行替代方案。

**AI_Comments:** 本文对MRI腹部多器官分割领域的三种主流深度学习模型进行了全面的基准测试，为研究人员和临床医生选择合适的工具提供了宝贵参考。其创新点在于引入了ABDSynth模型，探索了利用CT数据训练MRI分割模型的可能性，这在一定程度上缓解了MRI数据标注困难的痛点，尽管其性能略逊于MRI数据训练的模型，但为未来无需大量标注数据的医学图像分割研究提供了新的思路。评估使用了多个未见数据集，增强了结果的可靠性和泛化性。

<details>
  <summary>Details</summary>

**Motivation:** 虽然深度学习在CT腹部分割方面取得了进展，但MRI分割由于固有的信号变异性和高昂的训练数据标注成本而更具挑战性，现有方法受限于有限的MRI序列训练集，可能限制了其泛化能力。因此，需要对MRI腹部分割工具的现状进行全面评估。

**Method:** 本文对三种最先进的开源模型（MRSegmentator、MRISegmentator-Abdomen和TotalSegmentator MRI）进行了全面基准测试。此外，还引入并评估了ABDSynth，一个纯粹基于广泛可用的CT分割数据训练的SynthSeg模型（不使用真实MRI图像）。评估利用了三个公共数据集（训练时未被任何评估方法使用），涵盖了主要制造商、五种MRI序列以及各种受试者条件、体素分辨率和视野，以评估准确性和泛化能力。

**Result:** 结果显示，MRSegmentator取得了最佳性能，并且泛化能力最强。相比之下，ABDSynth的结果略逊一筹，但其对训练数据的要求较低，使其在标注预算有限的情况下成为一个替代方案。

**Conclusion:** MRSegmentator是目前MRI腹部多器官分割的最佳选择，而ABDSynth为数据标注资源有限的研究提供了有前景的替代方案，未来的研究应关注提高ABDSynth的准确性或探索其他无需大量MRI标注数据的方法。

> **ai_Abstract:** 本研究对当前三种先进的MRI腹部多器官深度学习分割模型（MRSegmentator、MRISegmentator-Abdomen和TotalSegmentator MRI）进行了全面的基准测试，以应对MRI分割中数据标注困难和泛化性差的挑战。同时，提出并评估了ABDSynth模型，该模型仅利用CT分割数据进行训练，无需真实的MRI图像。实验结果表明，MRSegmentator表现最佳且泛化能力最强。尽管ABDSynth的准确性略低，但其对训练数据要求低的特点使其在标注资源有限的情况下具有实用价值。

> **摘要翻译:** 深度学习的最新进展使得腹部计算机断层扫描（CT）分割的自动化工具变得强大。与此同时，磁共振成像（MRI）的分割由于固有的信号变异性和标注训练数据集所需增加的工作量而更具挑战性。因此，现有方法是在有限的MRI序列集上训练的，这可能会限制它们的泛化能力。为了描述MRI腹部分割工具的现状，我们在此对三种最先进的开源模型进行了全面基准测试：MRSegmentator、MRISegmentator-Abdomen和TotalSegmentator MRI。由于这些模型是使用劳动密集型的手动标注周期进行训练的，我们还引入并评估了ABDSynth，一个纯粹基于广泛可用的CT分割数据（无真实图像）训练的SynthSeg模型。更普遍地，我们通过利用三个公共数据集（在训练期间未被任何评估方法看到）来评估准确性和泛化能力，这些数据集涵盖了所有主要制造商、五种MRI序列以及各种受试者条件、体素分辨率和视野。我们的结果表明，MRSegmentator实现了最佳性能并且泛化能力最强。相比之下，ABDSynth的结果略不准确，但其对训练数据的宽松要求使其在标注预算有限时成为一个替代方案。评估代码和数据集可在 https://github.com/deepakri201/AbdoBench 获取，用于未来的基准测试，同时还提供了ABDSynth的推理代码和权重。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [119] [AI Workflow, External Validation, and Development in Eye Disease Diagnosis](https://arxiv.org/abs/2409.15087)
> *眼病诊断中的AI工作流程、外部验证与发展*

*Qingyu Chen, Tiarnan D L Keenan, Elvira Agron, Alexis Allot, Emily Guan, Bryant Duong, Amr Elsawy, Benjamin Hou, Cancan Xue, Sanjeeb Bhandari, Geoffrey Broadhead, Chantal Cousineau-Krieger, Ellen Davis, William G Gensheimer, David Grasic, Seema Gupta, Luis Haddock, Eleni Konstantinou, Tania Lamba, Michele Maiberger, Dimosthenis Mantopoulos, Mitul C Mehta, Ayman G Nahri, Mutaz AL-Nawaflh, Arnold Oshinsky, Brittany E Powell, Boonkit Purt, Soo Shin, Hillary Stiefel, Alisa T Thavikulwat, Keith James Wroblewski, Tham Yih Chung, Chui Ming Gemmy Cheung, Ching-Yu Cheng, Emily Y Chew, Michelle R. Hribar, Michael F. Chiang, Zhiyong Lu* | **Category: eess.IV, cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** AI辅助诊断, 年龄相关性黄斑变性, 外部验证, 持续学习, 临床工作流程

**Comment:** Published in JAMA Network Open,
  doi:10.1001/jamanetworkopen.2025.17204

> **TL;DR:** AI辅助诊断显著提升了眼科医生对AMD的诊断准确性和效率，并通过持续学习在不同数据集上表现出强大的鲁棒性。

**AI_Comments:** 本文的创新之处在于其对AI辅助诊断在真实临床工作流程中的外部验证，并强调了持续学习对模型性能提升和鲁棒性的重要性。通过对比有无AI辅助的诊断表现，以及在多样化数据集上的系统评估，该研究提供了AI在医疗领域实际应用价值的有力证据，解决了AI“下游问责制”的关键问题。

<details>
  <summary>Details</summary>

**Motivation:** 及时诊断疾病面临挑战，原因在于疾病负担日益增加以及临床医生数量有限。AI在诊断准确性方面显示出前景，但由于在临床工作流程和多样化人群中缺乏充分验证，面临实际应用问题。本研究旨在解决医疗AI下游问责制方面的空白。

**Method:** 本研究针对年龄相关性黄斑变性（AMD）诊断和严重程度分类，设计并实施了AI辅助诊断工作流程。研究比较了24名来自12个机构的临床医生在有无AI辅助下的诊断性能，使用了从“年龄相关性眼病研究（AREDS）”中抽样的真实患者数据。此外，通过整合约40,000张额外医学图像（AREDS2数据集），展示了现有AI模型的持续增强。改进后的模型随后使用AREDS、AREDS2测试集以及来自新加坡的外部测试集进行了系统评估。

**Result:** AI辅助显著提高了24名临床医生中23名的诊断准确性和分类能力，平均F1-score从37.71（手动）提高到45.52（手动+AI），增长了20%（P值<0.0001），在某些情况下提升超过50%。在效率方面，AI辅助减少了19名被追踪临床医生中17名的诊断时间，时间节省高达40%。此外，一个配备持续学习功能的模型在三个独立数据集上表现出强大的性能，准确性提高了29%，在新加坡人群中F1-score从42提高到54。

**Conclusion:** AI辅助诊断能够显著提高临床医生的诊断准确性和效率，并且通过持续学习和外部验证，AI模型能够展现出强大的泛化能力和持续改进潜力，从而解决医疗AI在实际应用中的验证和问责问题。

> **ai_Abstract:** 本研究旨在解决医疗AI在临床应用中缺乏充分验证的问题，通过对年龄相关性黄斑变性（AMD）诊断案例进行研究。研究设计并实施了AI辅助诊断工作流程，并与无AI辅助情况进行对比。结果显示，AI辅助显著提升了临床医生的诊断准确性和效率。此外，通过整合大规模新数据并进行持续学习，AI模型在多个独立数据集上表现出强大的泛化能力和性能提升。这强调了AI在眼病诊断中提升临床效果和效率的潜力，并为AI的外部验证和持续开发提供了实证。

> **摘要翻译:** 及时诊断疾病面临挑战，原因在于疾病负担日益增加以及临床医生数量有限。人工智能在诊断准确性方面显示出前景，但由于在临床工作流程和多样化人群中缺乏充分验证，面临实际应用问题。本研究通过一个关于年龄相关性黄斑变性（AMD）诊断和严重程度分类的案例研究，解决了医疗AI下游问责制方面的空白。我们设计并实施了一个AI辅助的AMD诊断工作流程，比较了来自12个机构的24名临床医生在有无AI辅助下使用从年龄相关性眼病研究（AREDS）中抽样的真实患者数据的诊断性能。此外，我们通过整合大约40,000张额外医学图像（命名为AREDS2数据集），展示了现有AI模型的持续增强。然后，使用AREDS和AREDS2测试集以及来自新加坡的外部测试集对改进后的模型进行了系统评估。AI辅助显著提高了24名临床医生中23名的诊断准确性和分类能力，平均F1-score从37.71（手动）提高到45.52（手动+AI），增长了20%（P值<0001），在某些情况下提升超过50%。在效率方面，AI辅助减少了19名被追踪临床医生中17名的诊断时间，时间节省高达40%。此外，一个配备持续学习功能的模型在三个独立数据集上表现出强大的性能，准确性提高了29%，在新加坡人群中F1-score从42提高到54。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [163] [Parameter-Efficient Fine-Tuning of 3D DDPM for MRI Image Generation Using Tensor Networks](https://arxiv.org/abs/2507.18112)
> *使用张量网络对3D DDPM进行参数高效微调以生成MRI图像*

*Binghua Li, Ziqing Chang, Tong Liang, Chao Li, Toshihisa Tanaka, Shigeki Aoki, Qibin Zhao, Zhe Sun* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 参数高效微调, 3D DDPM, MRI图像生成, 张量网络, TenVOO

**Comment:** 

> **TL;DR:** 本文提出TenVOO，一种基于张量网络的参数高效微调方法，用于3D DDPM在MRI图像生成中的应用，显著减少参数量并达到最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了TenVOO方法，首次将张量网络引入到3D DDPM的参数高效微调中，有效解决了3D卷积参数量大的问题。其在保持高性能的同时显著减少了可训练参数，这对于资源受限的环境或需要快速部署的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前针对三维（3D）U-Net型去噪扩散概率模型（DDPMs）在磁共振成像（MRI）图像生成中的参数高效微调（PEFT）研究，特别是3D卷积操作的参数高效表示方面，仍然非常有限。

**Method:** 本文提出Tensor Volumetric Operator (TenVOO)，一种新颖的PEFT方法，专门设计用于微调具有3D卷积骨干的DDPMs。TenVOO利用张量网络建模，用低维张量表示3D卷积核，从而在微调过程中以少量参数有效捕获复杂的空间依赖性。

**Result:** TenVOO在三个脑部MRI数据集（ADNI、PPMI和BraTS2021）上进行了评估，其在多尺度结构相似性指数（MS-SSIM）方面达到了最先进的性能，优于现有方法，并且仅需要原始模型0.3%的可训练参数。

**Conclusion:** TenVOO通过利用张量网络实现了3D DDPM在MRI图像生成中的参数高效微调，显著减少了参数量，同时保持或提升了图像生成质量，有效解决了3D卷积操作参数高效表示的挑战。

> **ai_Abstract:** 本文提出TenVOO，一种新颖的参数高效微调（PEFT）方法，专为具有3D卷积骨干的去噪扩散概率模型（DDPMs）设计，以解决MRI图像生成中3D卷积操作参数高效表示的挑战。TenVOO利用张量网络将3D卷积核表示为低维张量，从而在微调过程中以极少的参数（仅为原始模型的0.3%）有效捕获复杂的空间依赖性。在ADNI、PPMI和BraTS2021等脑部MRI数据集上的评估表明，TenVOO在MS-SSIM方面取得了最先进的性能。

> **摘要翻译:** 我们解决了磁共振成像（MRI）图像生成中三维（3D）U-Net型去噪扩散概率模型（DDPMs）的参数高效微调（PEFT）挑战。尽管其具有实际意义，但关于3D卷积操作的参数高效表示研究仍然有限。为了弥补这一差距，我们提出了张量体积算子（TenVOO），一种专门为微调具有3D卷积骨干的DDPMs设计的新型PEFT方法。TenVOO利用张量网络建模，用低维张量表示3D卷积核，在微调过程中以少量参数有效捕获复杂的空间依赖性。我们在三个下游脑部MRI数据集——ADNI、PPMI和BraTS2021上评估了TenVOO，通过微调一个在英国生物样本库59,830张T1加权脑部MRI扫描上预训练的DDPM。我们的结果表明，TenVOO在多尺度结构相似性指数（MS-SSIM）方面达到了最先进的性能，在捕获空间依赖性方面优于现有方法，同时仅需要原始模型0.3%的可训练参数。我们的代码可在https://github.com/xiaovhua/tenvoo获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [248] [U-Net Based Healthy 3D Brain Tissue Inpainting](https://arxiv.org/abs/2507.18126)
> *基于U-Net的健康3D脑组织修复*

*Juexin Zhang, Ying Weng, Ke Chen* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** U-Net, 脑组织修复, 3D图像合成, 数据增强, BraTS

**Comment:** Accepted by the International Brain Tumor Segmentation (BraTS)
  challenge organized at MICCAI 2024 conference. Included 7 pages, 2 figures

> **TL;DR:** 该论文提出了一种基于U-Net的健康3D脑组织修复方法，通过数据增强训练，在BraTS-Local-Inpainting挑战赛中取得了第一名，并在SSIM、PSNR和MSE指标上表现出色。

**AI_Comments:** 该论文的创新点在于将U-Net架构与精心设计的数据增强策略相结合，用于3D脑组织修复任务。其在BraTS-Local-Inpainting挑战赛中获得第一名，充分证明了方法的有效性和优越性。低标准差的评估结果也表明了模型的高稳定性和泛化能力，这对于医学图像处理应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在从掩蔽的输入图像中合成健康的3D脑组织，特别是针对“ASNR-MICCAI BraTS局部组织修复合成”任务。

**Method:** 本研究采用了一种基于U-Net的架构，并实施了全面的数据增强策略，通过在训练期间随机掩蔽健康图像来增强模型的泛化能力和鲁棒性。模型在BraTS-Local-Inpainting数据集上进行训练。

**Result:** 在BraTS-Local-Inpainting验证集上，模型实现了SSIM分数为0.841（标准差0.103），PSNR分数为23.257（标准差4.213），MSE分数为0.007（标准差0.007）。该方法在挑战赛中获得了第一名。

**Conclusion:** 该模型在恢复健康脑组织方面表现出卓越的性能，评估指标结果一致且可靠，表明其在各种输入场景下的可靠性和一致性。

> **ai_Abstract:** 本文提出了一种新颖的基于U-Net的健康3D脑组织修复方法，旨在从掩蔽的MRI图像中重建缺失区域。该方法结合了U-Net架构和全面的数据增强策略，以提高模型的泛化能力和鲁棒性。模型在BraTS-Local-Inpainting数据集上训练，并在验证集上取得了卓越的性能，SSIM、PSNR和MSE指标表现出色，且标准差较低，证明了其高可靠性和一致性。该方法在相关挑战赛中荣获第一名。

> **摘要翻译:** 本文介绍了一种从掩蔽输入图像中合成健康3D脑组织的新颖方法，特别关注“ASNR-MICCAI BraTS局部组织修复合成”任务。我们提出的方法采用基于U-Net的架构，旨在有效重建脑部MRI扫描中缺失或损坏的区域。为了增强模型的泛化能力和鲁棒性，我们实施了全面的数据增强策略，其中包括在训练期间随机掩蔽健康图像。我们的模型在BraTS-Local-Inpainting数据集上进行训练，并在恢复健康脑组织方面表现出卓越的性能。所采用的评估指标，包括结构相似性指数（SSIM）、峰值信噪比（PSNR）和均方误差（MSE），持续产生令人印象深刻的结果。在BraTS-Local-Inpainting验证集上，我们的模型实现了0.841的SSIM分数、23.257的PSNR分数和0.007的MSE分数。值得注意的是，这些评估指标显示出相对较低的标准差，即SSIM分数为0.103，PSNR分数为4.213，MSE分数为0.007，这表明我们的模型在各种输入场景下具有可靠性和一致性。我们的方法还在挑战赛中获得了第一名。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [290] [Deep Learning for Glioblastoma Morpho-pathological Features Identification: A BraTS-Pathology Challenge Solution](https://arxiv.org/abs/2507.18133)
> *深度学习在胶质母细胞瘤形态病理特征识别中的应用：一项BraTS-病理挑战赛解决方案*

*Juexin Zhang, Ying Weng, Ke Chen* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 胶质母细胞瘤, 深度学习, BraTS-Path, 图像识别, 形态病理特征

**Comment:** Accepted by the International Brain Tumor Segmentation (BraTS)
  challenge organized at MICCAI 2024 conference

> **TL;DR:** 该论文介绍了BraTS-Path 2024挑战赛中用于胶质母细胞瘤形态病理特征识别的深度学习解决方案。模型表现不佳，但在挑战赛中获得第二名。

**AI_Comments:** 该论文展示了一个深度学习解决方案在医学图像挑战赛中的应用。尽管模型的整体性能指标（如准确率、F1分数）较低，但其在特异性上表现出色，并且在竞争激烈的挑战赛中取得了第二名的成绩，这表明即使是表现不佳的模型，在特定条件下也可能具有实用价值或潜力。这可能归因于其对阴性样本的卓越识别能力。然而，较低的MCC值也提示模型预测能力仍有提升空间。研究结果也反映了医学图像分析，尤其是在处理高异质性疾病如胶质母细胞瘤时，所面临的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 胶质母细胞瘤是一种高度侵袭性的脑肿瘤，具有多样化的分子和病理特征，其异质性给诊断带来了挑战。准确诊断和评估异质性对于选择正确治疗和改善患者预后至关重要。传统方法依赖于组织样本中特定特征的识别，而深度学习为改善胶质母细胞瘤诊断提供了一种有前景的方法。

**Method:** 作者在BraTS-Path Challenge 2024中，利用预训练模型并在BraTS-Path训练数据集上进行微调。

**Result:** 模型在BraTS-Path验证集上表现不佳，准确率、召回率和F1-score均为0.392229。特异性达到0.898704。Matthews相关系数（MCC）为0.255267。该解决方案在测试阶段获得了第二名。

**Conclusion:** 该深度学习模型在胶质母细胞瘤形态病理特征识别方面表现有限，但在BraTS-Path挑战赛中取得了第二名的成绩，显示了在特定评估标准下的潜力。

> **ai_Abstract:** 本论文介绍了作者在BraTS-Path 2024挑战赛中针对胶质母细胞瘤形态病理特征识别提出的深度学习解决方案。该方法利用预训练模型并在挑战赛数据集上进行微调。尽管模型在验证集上的准确率、召回率和F1分数较低（均为0.392229），但特异性较高（0.898704），MCC为0.255267。最终，该解决方案在挑战赛测试阶段获得了第二名。

> **摘要翻译:** 胶质母细胞瘤是一种具有多样化分子和病理特征的高度侵袭性脑肿瘤，其异质性给诊断带来了挑战。准确诊断和评估这种异质性对于选择正确的治疗方案和改善患者预后至关重要。传统方法依赖于识别组织样本中的特定特征，但深度学习为改善胶质母细胞瘤诊断提供了一种有前景的方法。在本文中，我们介绍了我们参加BraTS-Path 2024挑战赛的方法。我们利用一个预训练模型，并在BraTS-Path训练数据集上对其进行微调。我们的模型在具有挑战性的BraTS-Path验证集上表现不佳，正如Synapse在线平台严格评估的那样。该模型实现了0.392229的准确率、0.392229的召回率和0.392229的F1分数，表明在目标条件下正确识别实例的能力一致。值得注意的是，我们的模型表现出0.898704的完美特异性，显示出正确分类阴性病例的卓越能力。此外，计算出的Matthews相关系数（MCC）为0.255267，表示预测值和实际值之间的有限正相关性，并突出了我们模型的整体预测能力。我们的解决方案还在测试阶段获得了第二名。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [335] [Tackling Hallucination from Conditional Models for Medical Image Reconstruction with DynamicDPS](https://arxiv.org/abs/2503.01075)
> *使用 DynamicDPS 解决条件模型在医学图像重建中的幻影问题*

*Seunghoi Kim, Henry F. J. Tregidgo, Matteo Figini, Chen Jin, Sarang Joshi, Daniel C. Alexander* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 医学图像重建, 幻影, 扩散模型, DynamicDPS, 图像质量转换

**Comment:** 

> **TL;DR:** DynamicDPS 是一种基于扩散模型的方法，通过结合条件和无条件扩散模型，并优化采样过程，有效减少了医学图像重建中的幻影（虚假结构），显著提升了图像质量和下游任务性能，同时大幅提高了效率。

**AI_Comments:** DynamicDPS 的创新点在于将条件和无条件扩散模型相结合来解决医学图像重建中的幻影问题，并引入了优化采样过程的策略（跳过早期阶段和自适应步长），极大地提升了效率。其模型无关和无需微调的特性使其具有很高的普适性和应用价值，在保证图像质量的同时，显著降低了计算成本，对临床应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 幻影（Hallucinations）是医学图像重建中关键的挑战，尤其对于数据驱动的条件模型而言，它们是地面真实中不存在的虚假结构。这些幻影的存在会严重影响医学图像的准确性和可靠性。

**Method:** 本文提出了 DynamicDPS，一个基于扩散的框架，它整合了条件和无条件扩散模型来增强低质量医学图像并系统地减少幻影。该方法首先使用条件模型生成初始重建，然后通过自适应的基于扩散的逆问题求解器对其进行细化。DynamicDPS 通过为每个样本选择最佳起始时间点来跳过逆向过程的早期阶段，并应用 Wolfe 线搜索来确定自适应步长，从而提高效率和图像保真度。它利用扩散先验和数据一致性来有效减少任何条件模型输出中的幻影。

**Result:** 在低场 MRI 增强的图像质量转换中验证了其有效性。对合成和真实 MR 扫描的广泛评估（包括用于组织体积估计的下游任务）表明，DynamicDPS 减少了幻影，使关键组织的相对体积估计提高了 15% 以上，同时仅使用了基线扩散模型所需采样步骤的 5%。

**Conclusion:** DynamicDPS 作为一种模型无关且无需微调的方法，为医学成像中的幻影减少提供了一种鲁棒的解决方案。

> **ai_Abstract:** 本文提出 DynamicDPS，一个创新性的扩散模型框架，旨在解决医学图像重建中条件模型产生的幻影问题。该方法结合了条件和无条件扩散模型，通过生成初始重建后，利用自适应逆问题求解器进行优化，并引入了跳过早期逆向过程和自适应步长的策略，显著提升了效率和图像保真度。实验证明，DynamicDPS 不仅有效减少了幻影，还在下游任务（如组织体积估计）中实现了超过 15% 的性能提升，且仅需极少的采样步骤。作为一种模型无关且无需微调的方案，DynamicDPS 为医学图像重建提供了一个高效且鲁棒的幻影消除工具。

> **摘要翻译:** 幻影是地面真实中不存在的虚假结构，在医学图像重建中构成了严峻的挑战，特别是对于数据驱动的条件模型。我们假设将无条件扩散模型与数据一致性相结合，并在多样化数据集上进行训练，可以减少这些幻影。在此基础上，我们提出了 DynamicDPS，一个基于扩散的框架，它整合了条件和无条件扩散模型，以增强低质量医学图像，同时系统地减少幻影。我们的方法首先使用条件模型生成初始重建，然后通过自适应的基于扩散的逆问题求解器对其进行细化。DynamicDPS 通过为每个样本选择最佳起始时间点来跳过逆向过程的早期阶段，并应用 Wolfe 线搜索来确定自适应步长，从而提高效率和图像保真度。利用扩散先验和数据一致性，我们的方法有效地减少了任何条件模型输出中的幻影。我们在低场 MRI 增强的图像质量转换中验证了其有效性。对合成和真实 MR 扫描的广泛评估，包括用于组织体积估计的下游任务，表明 DynamicDPS 减少了幻影，使关键组织的相对体积估计提高了 15% 以上，同时仅使用了基线扩散模型所需采样步骤的 5%。作为一种模型无关且无需微调的方法，DynamicDPS 为医学成像中的幻影减少提供了一种鲁棒的解决方案。代码将在发布后公开提供。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [358] [X-ray2CTPA: Leveraging Diffusion Models to Enhance Pulmonary Embolism Classification](https://arxiv.org/abs/2406.16109)
> *X-ray2CTPA：利用扩散模型增强肺栓塞分类*

*Noa Cahan, Eyal Klang, Galit Aviram, Yiftach Barash, Eli Konen, Raja Giryes, Hayit Greenspan* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 跨模态翻译, 肺栓塞分类, X射线, CTPA

**Comment:** preprint, project code: https://github.com/NoaCahan/X-ray2CTPA

> **TL;DR:** 该研究提出一种基于扩散模型的方法，将低分辨率X射线图像转换为高分辨率CTPA图像，以提高肺栓塞分类的准确性，从而提供更经济便捷的诊断工具。

**AI_Comments:** 这项工作通过引入基于扩散模型的跨模态翻译，将低成本、低辐射的X射线图像转换为高信息量的CTPA图像，为肺栓塞诊断提供了创新的解决方案。其核心创新在于利用生成式AI弥合了不同模态医学图像之间的差距，同时解决了实际应用中的成本和可及性问题。该方法的普适性也预示着其在其他医学图像转换和诊断领域的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 胸部X射线（CXR）成像能力有限，而CT扫描（特别是CTPA）虽然提供更详细的三维数据，但成本高、辐射暴露大且可及性差。本研究旨在探索将低对比度分辨率的2D X射线输入转换为高对比度和空间分辨率的3D CTPA扫描，以解决这些局限性。

**Method:** 本文提出了一种新颖的基于扩散模型的方法，用于实现从2D低对比度分辨率X射线到3D高对比度和空间分辨率CTPA扫描的跨模态翻译。模型性能通过定量指标和放射科医生的定性反馈进行评估。

**Result:** 生成的3D图像被用于分类框架中，并在使用初始CXR输入的PE（肺栓塞）分类任务中显示出AUC的提高。该方法具有普适性，能够执行其他医学成像中的跨模态翻译。

**Conclusion:** 该方法可能为更易于获取且成本效益更高的先进诊断工具铺平道路。

> **ai_Abstract:** 本文提出了一种名为X-ray2CTPA的新型扩散模型方法，旨在将低对比度分辨率的2D胸部X射线图像转换为高对比度和空间分辨率的3D CT肺血管造影（CTPA）图像。该方法旨在解决CT扫描成本高、辐射大和可及性差的问题，同时弥补X射线成像能力有限的不足。通过将合成的3D图像用于肺栓塞分类任务，该研究展示了AUC的显著提高。此方法具有普适性，有望促进更便捷、经济的先进诊断工具的发展。

> **摘要翻译:** 胸部X射线或胸部放射（CXR）通常用于医疗诊断，与计算机断层扫描（CT）相比，其成像能力通常有限，而CT扫描提供更详细和准确的三维数据，特别是像CT肺血管造影（CTPA）这样的增强扫描。然而，CT扫描成本更高，辐射暴露更大，并且不如CXR易于获取。在这项工作中，我们探索了从2D低对比度分辨率X射线输入到3D高对比度和空间分辨率CTPA扫描的跨模态翻译。受生成式AI最新进展的推动，我们引入了一种新颖的基于扩散模型的方法来完成这项任务。我们使用定量指标和放射科医生的定性反馈来评估模型性能，确保生成图像的诊断相关性。此外，我们将合成的3D图像应用于分类框架中，并显示在使用初始CXR输入的PE分类任务中AUC有所提高。所提出的方法具有普适性，能够执行医学成像中的其他跨模态翻译。它可能为更易于获取且成本效益更高的先进诊断工具铺平道路。该项目的代码可在：https://github.com/NoaCahan/X-ray2CTPA 获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [371] [L-FUSION: Laplacian Fetal Ultrasound Segmentation & Uncertainty Estimation](https://arxiv.org/abs/2503.05245)
> *L-FUSION：拉普拉斯胎儿超声分割与不确定性估计*

*Johanna P. Müller, Robert Wright, Thomas G. Day, Lorenzo Venturini, Samuel F. Budd, Hadrien Reynaud, Joseph V. Hajnal, Reza Razavi, Bernhard Kainz* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 胎儿超声分割, 不确定性估计, 深度学习, 图像分析, 产前诊断

**Comment:** Accepted at MICCAI ASMUS 2025

> **TL;DR:** L-FUSION是一个新的框架，通过整合不确定性量化和基础模型，显著提高了胎儿超声图像的分割精度和异常检测能力，并提供可靠的不确定性估计，无需手动疾病标记。

**AI_Comments:** L-FUSION的创新之处在于其将不确定性量化（包括偶然性和认知不确定性）与胎儿超声分割相结合，并利用了基础模型。这不仅提高了分割精度，更重要的是，它提供了诊断反馈中的不确定性信息，这对于临床决策至关重要。此外，它消除了对手动疾病标记的需求，提高了效率和可扩展性。该方法对于产前诊断领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 产前超声（US）的准确分析对于早期发现发育异常至关重要，但操作员依赖性和技术限制（如内在伪影、设置错误）会使图像解释和诊断不确定性评估复杂化。

**Method:** L-FUSION（带有集成基础模型的拉普拉斯胎儿超声分割）是一个框架，通过无监督、规范学习和大规模基础模型整合不确定性量化，以实现正常和病理扫描中胎儿结构的鲁棒分割。它利用随机分割网络的偶然性逻辑分布和带有快速Hessian估计的拉普拉斯近似，仅从分割头估计认知不确定性。结合集成的Dropout组件，L-FUSION能够通过增强的不确定性图和分割反事实来可靠地区分病变与正常胎儿解剖结构。

**Result:** L-FUSION在多个数据集上的评估显示，它实现了卓越的分割精度和一致的不确定性量化，能够可靠地量化异常以提供即时诊断反馈，并提高了认知和偶然不确定性的解释，消除了手动疾病标记的需要。

**Conclusion:** L-FUSION支持现场决策，并为临床环境中推进胎儿超声分析提供了一个可扩展的解决方案。

> **ai_Abstract:** L-FUSION是一个用于胎儿超声图像分割和不确定性估计的框架，旨在解决现有技术在图像解释和不确定性评估方面的挑战。它通过整合无监督学习、大规模基础模型、随机分割网络的偶然性逻辑分布和拉普拉斯近似来量化不确定性，从而实现对正常和病理扫描中胎儿结构的鲁棒分割。该方法提供了可靠的异常量化和增强的不确定性图，能够区分病变与正常解剖结构，并消除了手动疾病标记的需求。L-FUSION在多数据集上的评估表明，其在分割精度和不确定性量化方面表现优异，为临床决策提供了可扩展且可靠的支持。

> **摘要翻译:** 产前超声（US）的准确分析对于早期发现发育异常至关重要。然而，操作员依赖性和技术限制（例如内在伪影和效应、设置错误）会使图像解释和诊断不确定性的评估复杂化。我们提出了L-FUSION（带有集成基础模型的拉普拉斯胎儿超声分割），这是一个通过无监督、规范学习和大规模基础模型整合不确定性量化，用于正常和病理扫描中胎儿结构鲁棒分割的框架。我们建议利用随机分割网络的偶然性逻辑分布和带有快速Hessian估计的拉普拉斯近似，仅从分割头估计认知不确定性。这使我们能够实现可靠的异常量化，以提供即时诊断反馈。结合集成的Dropout组件，L-FUSION能够通过增强的不确定性图和超声成像中的分割反事实，可靠地区分病变与正常胎儿解剖结构。它改善了认知和偶然不确定性的解释，并消除了手动疾病标记的需要。在多个数据集上的评估显示，L-FUSION实现了卓越的分割精度和一致的不确定性量化，支持现场决策，并为临床环境中推进胎儿超声分析提供了一个可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [378] [SR-NeRV: Improving Embedding Efficiency of Neural Video Representation via Super-Resolution](https://arxiv.org/abs/2505.00046)
> *SR-NeRV：通过超分辨率提高神经视频表示的嵌入效率*

*Taiga Hayami, Kakeru Koizumi, Hiroshi Watanabe* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 隐式神经表示, 视频压缩, 超分辨率, 高频细节, 神经视频表示

**Comment:** 

> **TL;DR:** SR-NeRV通过整合超分辨率网络，在保持模型大小的同时，显著提高了神经视频表示中高频细节的重建质量。

**AI_Comments:** 该论文创新性地将超分辨率网络引入到隐式神经表示的视频压缩框架中，有效解决了高频细节重建的难题。其重要性在于在保持模型紧凑性的前提下，显著提升了视频压缩的视觉质量，这对于实际应用具有重要意义。这种将不同任务模块化并结合的思路值得借鉴。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于隐式神经表示（INR）的视频压缩方法在严格的模型尺寸限制下难以重建高频细节，而高频细节在实际压缩场景中至关重要。研究观察到高频分量在帧间的时间冗余度较低。

**Method:** 提出了一种基于INR的视频表示框架，该框架集成了通用超分辨率（SR）网络。通过将精细细节的重建工作卸载到预训练的SR网络上，提高了视觉保真度。

**Result:** 实验结果表明，所提出的方法在重建质量方面优于传统的基于INR的基线方法，同时保持了相当的模型尺寸。

**Conclusion:** 通过引入超分辨率网络，SR-NeRV有效解决了INR基线方法在重建高频细节上的不足，实现了更好的视觉保真度，且模型尺寸具有竞争力。

> **ai_Abstract:** 本文提出了SR-NeRV，一个基于隐式神经表示（INR）的视频表示框架，旨在解决现有INR方法在模型尺寸受限下重建高频细节的不足。通过将通用超分辨率（SR）网络集成到框架中，并将高频细节的重建任务交由预训练的SR网络处理，SR-NeRV显著提升了视觉保真度。实验证明，SR-NeRV在重建质量上超越了传统的INR基线方法，同时维持了可比的模型尺寸。

> **摘要翻译:** 隐式神经表示（INRs）因其在各种领域建模复杂信号的能力而受到广泛关注。最近，基于INR的框架在神经视频压缩中通过将视频内容嵌入到紧凑的神经网络中显示出前景。然而，这些方法在严格的模型尺寸限制下常常难以重建高频细节，这在实际压缩场景中至关重要。为了解决这一限制，我们提出了一种基于INR的视频表示框架，该框架集成了通用超分辨率（SR）网络。这种设计的动机是观察到高频分量在帧间往往表现出较低的时间冗余。通过将精细细节的重建工作卸载到在自然图像上预训练的专用SR网络，所提出的方法提高了视觉保真度。实验结果表明，所提出的方法在重建质量方面优于传统的基于INR的基线方法，同时保持了相当的模型尺寸。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [385] [BiECVC: Gated Diversification of Bidirectional Contexts for Learned Video Compression](https://arxiv.org/abs/2505.09193)
> *BiECVC: 门控双向上下文多样化学习视频压缩*

*Wei Jiang, Junru Li, Kai Zhang, Li Zhang* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 学习视频压缩, 双向上下文, 上下文门控, 非局部相关性, 比特率降低

**Comment:** Accepted to ACMMM 2025

> **TL;DR:** BiECVC是一种新的学习双向视频压缩框架，通过多样化上下文建模和自适应上下文门控，首次在所有标准测试数据集上超越VTM 13.2 RA。

**AI_Comments:** 这篇论文通过引入多样化的上下文建模和自适应门控机制，有效解决了学习双向视频压缩中的关键挑战。其创新性在于将非局部相关性纳入BVC，并借鉴语言模型中的数据依赖衰减概念来动态过滤上下文，这在视频压缩领域是新颖的。BiECVC超越VTM 13.2 RA的成果，表明了学习视频压缩在性能上已达到工业级标准，对未来视频编解码器发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的学习双向视频压缩（BVC）方法在性能上落后于前向预测方法，主要原因是难以提取多样且准确的上下文（主要利用时间运动，忽略跨帧的非局部相关性），且缺乏动态抑制由快速运动或遮挡引起的有害上下文的适应性。

**Method:** 本文提出了BiECVC框架，旨在解决现有BVC的上下文提取和适应性问题。BiECVC结合了多样化的局部和非局部上下文建模以及自适应上下文门控。具体方法包括：1) 局部上下文增强：重用较低层的高质量特征并通过解码运动向量对齐；2) 非局部依赖建模：采用线性注意力机制；3) 双向上下文门控：受自回归语言模型中的数据依赖衰减启发，根据条件编码结果动态过滤上下文信息。

**Result:** BiECVC取得了最先进的性能，与VTM 13.2相比，在随机访问（RA）配置下，帧内周期分别为32和64时，比特率分别降低了13.4%和15.7%。据作者所知，BiECVC是第一个在所有标准测试数据集上超越VTM 13.2 RA的学习视频编解码器。

**Conclusion:** BiECVC通过引入多样化上下文建模和自适应上下文门控，显著提升了学习双向视频压缩的性能，首次在所有标准测试数据集上超越了VTM 13.2 RA。

> **ai_Abstract:** 本文提出了BiECVC，一个用于学习双向视频压缩（BVC）的新框架，旨在解决现有BVC在上下文提取多样性和准确性方面的不足以及对有害上下文的适应性问题。BiECVC通过结合多样化的局部和非局部上下文建模（包括特征重用与运动向量对齐、线性注意力机制）和创新的双向上下文门控（动态过滤上下文），显著提升了性能。实验证明，BiECVC在随机访问配置下，比特率相比VTM 13.2有显著降低，并且是首个在所有标准测试数据集上超越VTM 13.2 RA的学习视频编解码器，标志着BVC领域的重要突破。

> **摘要翻译:** 近年来，基于前向预测的学习视频压缩（LVC）方法取得了令人瞩目的成果，甚至在低延迟B（LDB）配置下超越了VVC参考软件VTM。相比之下，学习双向视频压缩（BVC）仍未得到充分探索，并且仍然落后于其仅前向的对应方法。这种性能差距主要归因于提取多样化和准确上下文的能力有限：大多数现有BVC主要利用时间运动，而忽略了跨帧的非局部相关性。此外，它们缺乏动态抑制由快速运动或遮挡引起的有害上下文的适应性。为了解决这些挑战，我们提出了BiECVC，一个BVC框架，它结合了多样化的局部和非局部上下文建模以及自适应上下文门控。为了增强局部上下文，BiECVC重用较低层的高质量特征，并使用解码运动向量对其进行对齐，而无需引入额外的运动开销。为了有效地建模非局部依赖关系，我们采用了线性注意力机制，平衡了性能和复杂性。为了进一步减轻不准确上下文预测的影响，我们引入了双向上下文门控，其灵感来自于近期自回归语言模型中的数据依赖衰减，以根据条件编码结果动态过滤上下文信息。大量的实验表明，BiECVC取得了最先进的性能，与VTM 13.2相比，在随机访问（RA）配置下，帧内周期分别为32和64时，比特率分别降低了13.4%和15.7%。据我们所知，BiECVC是第一个在所有标准测试数据集上超越VTM 13.2 RA的学习视频编解码器。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [392] [Dynamic mapping from static labels: remote sensing dynamic sample generation with temporal-spectral embedding](https://arxiv.org/abs/2506.02574)
> *从静态标签到动态制图：基于时空嵌入的遥感动态样本生成*

*Shuai Yuan, Shuang Chen, Tianwu Lin, Jincheng Yuan, Geng Tian, Yang Xu, Jie Wang, Peng Gong* | **Category: eess.IV, cs.CV, cs.MM** | **Updated: 2025-07-24**

**Keywords:** 动态样本生成, 遥感, 时空嵌入, 变分自编码器, 异常检测

**Comment:** 

> **TL;DR:** 提出TasGen方法，通过时空嵌入从单日期静态标签生成遥感动态训练样本，以解决静态样本过时和手动更新困难的问题。

**AI_Comments:** 该论文提出了一种新颖的方法，通过自动化流程生成遥感动态样本，有效解决了传统静态样本过时和手动更新效率低下的问题。其创新点在于结合了时空解耦与联合嵌入，并通过HTS-VAE模型捕捉陆表动态的复杂性。此外，提出的异常解释方法增加了模型的可解释性，有助于理解地表变化的具体原因。该方法对于需要持续更新地理信息的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 遥感地理制图需要及时且有代表性的样本，但快速的陆表变化导致静态样本在数月内过时，手动更新样本劳动密集且不可持续。

**Method:** 本文提出了TasGen，一种两阶段的时空感知自动样本生成方法。第一阶段，引入分层时空变分自编码器（HTS-VAE），通过解耦和联合嵌入时空信息来学习正常样本的低维潜在模式，实现鲁棒的异常检测。第二阶段，一个在稳定样本上训练的分类器对跨时间的变化点进行重新标记，以生成动态样本。此外，还提出了基于Gibbs采样的异常解释方法，将变化归因于特定的时空维度。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究提出TasGen，一种两阶段的时空感知自动样本生成方法，旨在解决遥感地理制图中静态样本快速过时和手动更新困难的问题。TasGen通过引入分层时空变分自编码器（HTS-VAE）在第一阶段学习正常样本的时空嵌入模式，从而实现异常检测。第二阶段则利用分类器对变化点进行重新标记，以生成动态训练样本。此外，该方法还包括一个异常解释机制，能够识别导致变化的具体时空维度。

> **摘要翻译:** 准确的遥感地理制图需要及时且有代表性的样本。然而，快速的陆表变化常常使静态样本在数月内过时，使得手动更新样本变得劳动密集且不可持续。为了解决这一挑战，我们提出了TasGen，一种两阶段时空感知自动样本生成方法，用于从单日期静态标签生成动态训练样本，无需人工干预。陆表动态通常表现为时空序列中的异常。这些异常是多变量但统一的：时间、光谱或联合异常源于不同的机制，不能简单地耦合，因为这可能会掩盖变化的本质。然而，任何陆表状态都对应着一个连贯的时空特征，如果将这两个维度分开建模，则会丢失。为了有效地捕捉这些动态，TasGen首先解耦时间和光谱特征以分离它们各自的贡献，然后将它们耦合以建模它们的协同作用。在第一阶段，我们引入了一种分层时空变分自编码器（HTS-VAE），具有双维度嵌入，通过首先解耦然后联合嵌入时间和光谱信息，学习正常样本的低维潜在模式。这种时空嵌入通过识别与学习到的联合模式的偏差来实现鲁棒的异常检测。在第二阶段，一个在稳定样本上训练的分类器对跨时间的变化点进行重新标记，以生成动态样本。为了不仅检测而且解释地表动态，我们进一步提出了一种基于吉布斯采样的异常解释方法，该方法将变化归因于特定的光谱-时间维度。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [400] [crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023](https://arxiv.org/abs/2506.12006)
> *crossMoDA挑战：2021年至2023年前庭神经鞘瘤和耳蜗分割跨模态域适应技术演进*

*Navodini Wijethilake, Reuben Dorent, Marina Ivory, Aaron Kujawa, Stefan Cornelissen, Patrick Langenhuizen, Mohamed Okasha, Anna Oviedova, Hexin Dong, Bogyeong Kang, Guillaume Sallé, Luyi Han, Ziyuan Zhao, Han Liu, Yubo Fan, Tao Yang, Shahad Hardan, Hussain Alasmawi, Santosh Sanjeev, Yuzhou Zhuang, Satoshi Kondo, Maria Baldeon Calisto, Shaikh Muhammad Uzair Noman, Cancan Chen, Ipek Oguz, Rongguo Zhang, Mina Rezaei, Susana K. Lai-Yuen, Satoshi Kasai, Yunzhi Huang, Chih-Cheng Hung, Mohammad Yaqub, Lisheng Wang, Benoit M. Dawant, Cuntai Guan, Ritse Mann, Vincent Jaouen, Tae-Eui Kam, Li Zhang, Jonathan Shapey, Tom Vercauteren* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 跨模态域适应, 医学图像分割, 前庭神经鞘瘤, 耳蜗, crossMoDA挑战

**Comment:** 

> **TL;DR:** crossMoDA挑战系列报告了2022和2023年的结果，并回顾了其在跨模态域适应中用于前庭神经鞘瘤和耳蜗分割的演变，发现数据集扩大和异质性增加能减少异常值，但耳蜗分割因复杂性增加而下降，表明需要更具挑战性的任务。

**AI_Comments:** 这篇论文通过分析crossMoDA挑战赛的演变，清晰地展示了医学图像领域跨模态域适应技术在真实世界数据复杂性增加时的表现。其创新之处在于挑战赛本身的设计，逐步引入多机构、异构数据和更精细的亚分割任务，这反映了临床需求和技术发展的方向。论文强调了数据异质性对模型鲁棒性的重要性，并指出了在复杂任务下（如肿瘤亚分割）性能可能下降的局限性。这为未来挑战设计和研究方向提供了宝贵的见解，即需要寻找更能推动技术突破的“更具挑战性的跨模态任务”。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是推动无监督跨模态分割技术的发展，特别是在医学图像领域，通过crossMoDA挑战系列为前庭神经鞘瘤（VS）和耳蜗在T2 MRI扫描上的自动化分割提供一个有意义的基准，以实现更具成本效益的VS管理。

**Method:** 本文报告了2022年和2023年crossMoDA挑战赛的结果，并对多年来的挑战进展进行了回顾性分析。挑战赛本身从2021年的单机构数据和基本分割，演变为2022年的多机构数据和Koos分级，到2023年则包含了异构常规数据和肿瘤内部及外部成分的亚分割。

**Result:** 观察结果显示，随着数据集的扩大，异常值的数量减少，尽管扫描协议的多样性同时增加。2023年挑战赛的获胜方法减少了2021年和2022年测试数据上的异常值，证明了数据异质性的增加可以提高分割性能。然而，2023年耳蜗的Dice得分有所下降，这可能是由于肿瘤亚注释的复杂性增加影响了整体分割性能。

**Conclusion:** 尽管在临床可接受的前庭神经鞘瘤分割方面仍需取得进展，但性能趋于平稳表明，未来可能需要更具挑战性的跨模态任务来更好地进行基准测试。

> **ai_Abstract:** crossMoDA挑战系列旨在推动医学图像中无监督跨模态域适应分割技术的发展，特别针对前庭神经鞘瘤和耳蜗在T2 MRI上的分割。本文回顾并报告了2022年和2023年挑战赛的进展与结果。研究发现，随着数据集的扩大和异质性的增加，分割性能的异常值有所减少，2023年的优胜方法也验证了异质性数据对性能提升的积极作用。然而，由于新增的复杂性，耳蜗分割的性能在2023年有所下降。论文指出，尽管仍需努力实现临床可接受的VS分割，但当前性能的平台期预示着未来需要更具挑战性的跨模态任务以促进进一步研究。

> **摘要翻译:** cross-Modality Domain Adaptation (crossMoDA) 挑战系列于2021年与国际医学图像计算和计算机辅助干预大会 (MICCAI) 共同发起，专注于无监督跨模态分割，即从对比增强T1 (ceT1) 学习并转移到T2 MRI。这项任务是领域偏移的一个极端例子，被选作一个有意义且具有说明性的基准。从临床应用的角度来看，其目标是在T2扫描上实现前庭神经鞘瘤 (VS) 和耳蜗的自动化分割，以实现更具成本效益的VS管理。随着时间的推移，挑战目标不断演变以增强其临床相关性。挑战从2021年使用单机构数据和基本分割，到2022年纳入多机构数据和Koos分级，到2023年则包含了异构常规数据以及肿瘤内部和外部成分的亚分割。在这项工作中，我们报告了2022年和2023年挑战赛的结果，并对挑战多年来的进展进行了回顾性分析。连续挑战贡献的观察结果表明，随着数据集的扩大，异常值的数量减少。这一点值得注意，因为数据集的扫描协议多样性同时增加。2023年挑战赛的获胜方法减少了2021年和2022年测试数据上的异常值，证明了数据异质性的增加如何能够提高即使在同质数据上的分割性能。然而，2023年耳蜗的Dice得分有所下降，这可能是由于肿瘤亚注释增加了复杂性，从而影响了整体分割性能。尽管在临床可接受的前庭神经鞘瘤分割方面仍需取得进展，但性能趋于平稳表明，未来更具挑战性的跨模态任务可能更适合作为基准。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [445] [Estimating Sensitivity Maps for X-Nuclei Magnetic Resonance Spectroscopic Imaging](https://arxiv.org/abs/2507.18850)
> *X核磁共振波谱成像灵敏度图估计*

*Nicholas Dwork, Jeremy W. Gordon, Shuyu Tang, Peder E. Z. Larson* | **Category: eess.IV, physics.med-ph, q-bio.QM** | **Updated: 2025-07-24**

**Keywords:** 灵敏度图, X核磁共振, 波谱成像, L2最优方法, 超极化MRI

**Comment:** 

> **TL;DR:** 一种新的L2最优方法，通过从测量中提取更多信息，提高了X核磁共振波谱成像中灵敏度图的估计准确性和信噪比，优于RefPeak方法。

**AI_Comments:** 该论文提出了一种创新的L2最优方法，通过利用多源信息（如光谱分箱、时间点、频率）来提高X核磁共振波谱成像中灵敏度图的估计精度，解决了X核信号可能不显著的挑战。相较于传统方法，其在准确性和信噪比方面的提升具有重要意义，尤其对于超极化MRI等新兴技术有潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在估计X核磁共振波谱成像中的线圈灵敏度图，特别是在X核在视野中可能不显著存在的情况下。

**Method:** 提出了一种名为L2最优方法的新方法，通过解决一个最小二乘问题来估计线圈灵敏度。该方法从光谱的多个分箱、动态成像的多个时间点或利用频谱激励时的多个频率中获取多个灵敏度估计。该方法与常用的RefPeak方法进行了比较，后者使用最高能量的光谱分箱来估计灵敏度图。

**Result:** L2最优方法在数值模型成像中产生了更准确的灵敏度图，并且在使用超极化丙酮酸作为对比剂的超极化MRI脑部、胰腺和心脏成像中显示出更高的信噪比。

**Conclusion:** L2最优方法通过从测量中提取更多信息，能够更好地估计灵敏度。

> **ai_Abstract:** 本研究提出了一种名为L2最优方法的新方法，用于估计X核磁共振波谱成像中的线圈灵敏度图，尤其适用于X核在视野中不显著的情况。该方法通过解决最小二乘问题，并从光谱、动态成像或频谱激励的多个来源获取灵敏度估计。与常用的RefPeak方法相比，L2最优方法在数值模型成像中表现出更高的准确性，并在超极化MRI的活体成像中提高了信噪比，因为它能从测量中提取更多信息。

> **摘要翻译:** 本研究旨在估计X核磁共振波谱成像（X-nuclei Magnetic Resonance Spectroscopic Imaging）中的灵敏度图，特别是在X核在整个视野中可能不显著存在的情况下。我们提出通过解决一个最小二乘问题来估计线圈的灵敏度，其中每一行对应于给定体素灵敏度的单个估计。多个估计来自光谱的多个分箱、动态成像的多个时间点，或利用频谱激励时的多个频率。本手稿中提出的方法，称为L2最优方法，与常用的RefPeak方法进行了比较，后者使用具有最高能量的光谱分箱来估计灵敏度图。L2最优方法在数值模型成像时产生了更准确的灵敏度图，并且在超极化MRI中使用超极化丙酮酸作为对比剂对大脑、胰腺和心脏进行成像时，显示出更高的信噪比。L2最优方法能够通过从测量中提取更多信息，更好地估计灵敏度。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [481] [RealisVSR: Detail-enhanced Diffusion for Real-World 4K Video Super-Resolution](https://arxiv.org/abs/2507.19138)
> *RealisVSR：面向真实世界4K视频超分辨率的细节增强扩散模型*

*Weisong Zhao, Jingkai Zhou, Xiangyu Zhu, Weihua Chen, Xiao-Yu Zhang, Zhen Lei, Fan Wang* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-25**

**Keywords:** 视频超分辨率, 扩散模型, 细节增强, 4K, RealisVSR

**Comment:** 

> **TL;DR:** RealisVSR提出了一种细节增强的视频扩散模型，通过引入新的架构、损失函数和4K基准数据集，解决了现有视频超分辨率模型在时序一致性、高频细节恢复和4K评估方面的挑战。

**AI_Comments:** RealisVSR的创新之处在于其对真实世界4K视频超分辨率的全面解决方案，不仅在模型架构（CPC）和损失函数（HR-Loss）上进行了优化以提升细节恢复和时序一致性，更重要的是，它填补了4K VSR评估基准的空白，推出了RealisVideo-4K数据集。这对于推动VSR领域向更高分辨率和更真实场景发展具有重要意义。模型在减少训练数据量方面的优势也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 尽管扩散模型在视频超分辨率（VSR）方面取得了进展，但仍存在三大挑战：1) 基础模型中时序动态建模不一致；2) 复杂真实世界退化下高频细节恢复能力有限；3) 当前方法主要依赖细节不足的720P数据集，导致细节增强和4K超分辨率评估不足。

**Method:** 本文提出了RealisVSR，一个高频细节增强的视频扩散模型，包含三项核心创新：1) 结合Wan2.1视频扩散的“一致性保留ControlNet (CPC)”架构，用于建模平滑和复杂运动并抑制伪影；2) 结合小波分解和HOG特征约束的“高频校正扩散损失 (HR-Loss)”，用于纹理恢复；3) “RealisVideo-4K”，首个包含1,000个高清视频-文本对的公开4K VSR基准。

**Result:** RealisVSR利用Wan2.1的先进时空引导，仅需现有方法5-25%的训练数据量。在多个VSR基准（REDS, SPMCS, UDM10, YouTube-HQ, VideoLQ, RealisVideo-720P）上的大量实验证明了其优越性，尤其在超高分辨率场景中表现出色。

**Conclusion:** RealisVSR成功解决了视频超分辨率领域中时序一致性、高频细节恢复和4K评估的难题，并通过创新的模型架构、损失函数和新型4K基准数据集，显著提升了真实世界4K视频的超分辨率性能。

> **ai_Abstract:** 本文提出RealisVSR，一个高频细节增强的视频扩散模型，旨在解决现有视频超分辨率（VSR）方法在时序动态建模、高频细节恢复以及4K分辨率评估方面的不足。RealisVSR引入了三项核心创新：一致性保留ControlNet (CPC) 架构、高频校正扩散损失 (HR-Loss) 和首个公开的4K VSR基准数据集RealisVideo-4K。实验证明，RealisVSR在各种VSR基准上，尤其是在超高分辨率场景中，表现出卓越的性能，并且显著减少了训练数据需求。

> **摘要翻译:** 视频超分辨率（VSR）通过扩散模型取得了显著进展，有效解决了基于GAN的方法固有的过平滑问题。尽管最近取得了进展，VSR领域仍存在三个关键挑战：1) 基础模型中时序动态建模不一致；2) 复杂真实世界退化下高频细节恢复能力有限；3) 细节增强和4K超分辨率评估不足，因为当前方法主要依赖细节不足的720P数据集。为了解决这些挑战，我们提出了RealisVSR，一个高频细节增强的视频扩散模型，具有三项核心创新：1) 结合Wan2.1视频扩散的“一致性保留ControlNet (CPC)”架构，用于建模平滑和复杂运动并抑制伪影；2) 结合小波分解和HOG特征约束的“高频校正扩散损失 (HR-Loss)”，用于纹理恢复；3) “RealisVideo-4K”，首个包含1,000个高清视频-文本对的公开4K VSR基准。利用Wan2.1的先进时空引导，我们的方法与现有方法相比，仅需5-25%的训练数据量。在VSR基准（REDS、SPMCS、UDM10、YouTube-HQ、VideoLQ、RealisVideo-720P）上的大量实验证明了我们的优越性，尤其在超高分辨率场景中。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [502] [Towards Robust Foundation Models for Digital Pathology](https://arxiv.org/abs/2507.17845)
> *迈向数字病理学的鲁棒基础模型*

*Jonah Kömen, Edwin D. de Jong, Julius Hense, Hannah Marienwald, Jonas Dippel, Philip Naumann, Eric Marcus, Lukas Ruff, Maximilian Alber, Jonas Teuwen, Frederick Klauschen, Klaus-Robert Müller* | **Category: eess.IV, cs.AI, cs.CV, cs.LG, q-bio.QM** | **Updated: 2025-07-22**

**Keywords:** 数字病理学, 基础模型, 鲁棒性, 临床部署, PathoROB

**Comment:** 

> **TL;DR:** 生物医学基础模型（FMs）易受非生物技术特征影响，带来临床部署风险。本研究首次系统性调查病理学FM鲁棒性，引入PathoROB基准进行量化，发现现有FM普遍存在鲁棒性缺陷并导致诊断错误。研究强调鲁棒性评估对FM临床应用至关重要，未来FM开发需将鲁棒性作为核心设计原则。

**AI_Comments:** 该论文首次系统性地调查了数字病理学中基础模型对非生物技术特征的鲁棒性，这是一项重要的贡献。其创新之处在于引入了PathoROB基准和新颖的鲁棒性度量指标，为评估和改进这些模型提供了急需的工具。研究发现现有FM普遍存在鲁棒性缺陷并可能导致严重临床错误，这突出了AI在医疗领域安全部署的关键挑战。该工作强调将鲁棒性作为未来FM开发的核心设计原则，对于推动负责任的医疗AI发展具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 生物医学基础模型（FMs）虽在医疗领域迅速发展，但易受非生物技术特征（如手术技术、实验室程序和扫描仪硬件差异）影响，这给其临床部署带来了风险。本研究旨在首次系统性调查病理学FM的鲁棒性，并提出解决方案以缓解这些问题，确保其安全有效的临床应用。

**Method:** 本研究首次系统性调查了病理学基础模型（FM）对非生物特征的鲁棒性。工作内容包括：(i) 引入量化FM鲁棒性的新度量方法；(ii) 展示有限鲁棒性带来的后果；(iii) 提出了一个FM鲁棒化框架以缓解问题。具体地，开发了PathoROB，一个鲁棒性基准，包含鲁棒性指数等三个新颖指标，并使用了来自34个医疗中心的28个生物类别的四个数据集进行评估。

**Result:** 实验结果显示，所有20个被评估的FM都存在鲁棒性缺陷，且它们之间存在显著差异。非鲁棒的FM表示会导致重大的诊断下游错误和临床失误，阻碍安全临床应用。使用更鲁棒的FM和事后鲁棒化方法显著降低（但尚未完全消除）了此类错误的风险。

**Conclusion:** 鲁棒性评估对于病理学基础模型（FM）在临床应用前的验证至关重要。未来的FM开发必须将鲁棒性作为核心设计原则。PathoROB为生物医学领域的鲁棒性评估提供了蓝图，指导FM改进，以实现更鲁棒、更具代表性、更具临床可部署性且优先考虑生物信息而非技术伪影的AI系统。

> **ai_Abstract:** 该论文首次系统性地研究了数字病理学基础模型（FMs）对非生物技术特征的鲁棒性。作者开发了PathoROB基准，包含新颖的鲁棒性指标和多中心数据集，用于评估和量化FM的鲁棒性。研究发现，当前FMs普遍存在鲁棒性缺陷，这些缺陷可能导致严重的诊断错误。通过使用更鲁棒的模型和事后鲁棒化方法，可以显著降低错误风险。研究强调，鲁棒性评估对于病理学FM的临床部署至关重要，并呼吁将鲁棒性作为未来FM设计和开发的核心原则。

> **摘要翻译:** 生物医学基础模型 (FMs) 正在迅速改变人工智能赋能的医疗保健研究，并进入临床验证阶段。然而，它们容易学习非生物技术特征——包括手术/内窥镜技术、实验室程序和扫描仪硬件的变化——这给临床部署带来了风险。我们首次系统地调查了病理学 FM 对非生物特征的鲁棒性。我们的工作 (i) 引入了量化 FM 鲁棒性的措施，(ii) 展示了有限鲁棒性的后果，以及 (iii) 提出了一个 FM 鲁棒性框架以缓解这些问题。具体来说，我们开发了 PathoROB，一个鲁棒性基准，包含三个新颖的指标（包括鲁棒性指数）和涵盖来自 34 个医疗中心的 28 个生物学类别的四个数据集。我们的实验揭示了所有 20 个评估的 FM 都存在鲁棒性缺陷，并且它们之间存在显著的鲁棒性差异。我们发现不鲁棒的 FM 表示可能导致重大的诊断下游错误和临床失误，从而阻碍安全的临床应用。使用更鲁棒的 FM 和事后鲁棒化显著降低了（但尚未完全消除）此类错误的风险。这项工作确立了在临床应用前对病理学 FM 进行鲁棒性评估的必要性，并表明未来的 FM 开发必须将鲁棒性作为核心设计原则。PathoROB 为评估生物医学领域的鲁棒性提供了蓝图，指导 FM 改进工作，以实现更鲁棒、更具代表性、更具临床可部署性的 AI 系统，这些系统优先考虑生物信息而非技术伪影。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [513] [Hierarchical Diffusion Framework for Pseudo-Healthy Brain MRI Inpainting with Enhanced 3D Consistency](https://arxiv.org/abs/2507.17911)
> *用于增强3D一致性的伪健康脑部MRI图像修复的分层扩散框架*

*Dou Hoon Kwark, Shirui Luo, Xiyue Zhu, Yudu Li, Zhi-Pei Liang, Volodymyr Kindratenko* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-23**

**Keywords:** 分层扩散, 脑部MRI, 图像修复, 3D一致性, 伪健康

**Comment:** 11 pages, 2 figures

> **TL;DR:** 该论文提出了一种分层扩散框架，通过结合两个垂直的2D阶段来处理伪健康脑部MRI图像修复，解决了现有方法在3D一致性和数据效率方面的局限性，并实现了卓越的性能。

**AI_Comments:** 该论文的创新点在于其独特的分层2D扩散框架，它巧妙地解决了医学图像修复中3D一致性和数据效率之间的矛盾。通过结合轴向和冠状视图的优势，该方法能够在不牺牲细节保真度的情况下，有效减少对大量3D训练数据的依赖，这对于数据获取困难的医疗领域具有重要意义。其性能超越现有基线，表明了该方法在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 伪健康图像修复是分析病理脑部MRI扫描的重要预处理步骤。大多数当前方法倾向于使用切片式2D模型，尽管其平面内保真度高，但切片间的独立性导致了体积不连续性。完全3D模型可以缓解此问题，但其高模型容量需要大量的训练数据才能实现可靠、高保真度的合成，这在医疗环境中通常不切实际。

**Method:** 本研究提出了一种分层扩散框架，通过用两个垂直的粗到细2D阶段取代直接的3D建模。首先，轴向扩散模型生成粗略、全局一致的修复；然后，冠状扩散模型细化解剖细节。通过结合垂直空间视图和自适应重采样，该方法平衡了数据效率和体积一致性。

**Result:** 实验表明，该方法在真实性和体积一致性方面均优于最先进的基线方法。

**Conclusion:** 本方法在数据效率和体积一致性之间取得了平衡，并在伪健康图像修复方面表现出色，使其成为一个有前景的解决方案。

> **ai_Abstract:** 本论文提出了一种新颖的分层扩散框架，用于伪健康脑部MRI图像修复，旨在解决现有2D方法缺乏3D一致性以及3D方法对大量训练数据需求过高的问题。该框架采用两个垂直的2D扩散阶段：首先通过轴向模型进行粗略的全局修复，随后通过冠状模型进行精细的解剖细节完善。通过这种设计，该方法在数据效率和体积一致性之间取得了平衡，并在实验中证明其在真实性和体积一致性上均优于现有先进技术，为医学图像处理提供了一个有前景的解决方案。

> **摘要翻译:** 伪健康图像修复是分析病理脑部MRI扫描的重要预处理步骤。大多数当前的修复方法倾向于使用切片式2D模型，因为它们具有较高的平面内保真度，但切片间的独立性会导致体积不连续性。完全3D模型可以缓解这个问题，但其高模型容量需要大量的训练数据才能实现可靠、高保真度的合成——这在医疗环境中通常不切实际。我们通过用两个垂直的粗到细2D阶段取代直接的3D建模，用分层扩散框架解决了这些限制。轴向扩散模型首先产生粗略的、全局一致的修复；然后冠状扩散模型细化解剖细节。通过结合垂直空间视图和自适应重采样，我们的方法平衡了数据效率和体积一致性。我们的实验表明，我们的方法在真实性和体积一致性方面均优于最先进的基线，使其成为伪健康图像修复的一个有前景的解决方案。代码可在https://github.com/dou0000/3dMRI-Consistent-Inpaint 获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [517] [RegScore: Scoring Systems for Regression Tasks](https://arxiv.org/abs/2507.19155)
> *RegScore：回归任务的评分系统*

*Michal K. Grzeszczyk, Tomasz Szczepański, Pawel Renc, Siyeop Yoon, Jerome Charton, Tomasz Trzciński, Arkadiusz Sitek* | **Category: eess.IV** | **Updated: 2025-07-25**

**Keywords:** 评分系统, 回归任务, 可解释性, 稀疏性, 双模态学习

**Comment:** Accepted for the 28th International Conference on Medical Image
  Computing and Computer Assisted Intervention (MICCAI) 2025

> **TL;DR:** RegScore是一种新型的、稀疏的、可解释的回归任务评分系统，通过放宽系数限制和结合多模态数据（如医学图像）提高了预测性能，并在临床环境中提供了透明和可信的决策支持。

**AI_Comments:** RegScore的创新之处在于其将传统评分系统的透明性与现代机器学习（束搜索、k-稀疏岭回归）和深度学习（TIP transformer、多模态数据融合）相结合，专门应用于回归任务。这解决了传统评分系统在回归场景中表现不佳的问题，并提供了可解释的预测，这在医疗等关键领域至关重要。其个性化评分和多模态整合是亮点，提升了模型的实用性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的评分系统主要用于分类任务，且受限于整数系数，不适用于回归任务。本研究旨在为回归任务开发一种透明、可解释且性能优越的评分系统。

**Method:** 本研究引入了RegScore，一种专为回归任务设计的稀疏、可解释评分系统。它利用束搜索（beam search）和k-稀疏岭回归（k-sparse ridge regression）来放宽传统评分系统对整数系数的限制，从而提高预测性能。此外，RegScore还扩展到双模态深度学习，通过整合表格数据和医学图像。它利用TIP（Tabular Image Pretraining）transformer的分类token生成个性化线性回归参数和个性化RegScore，实现个体化评分。

**Result:** RegScore及其个性化双模态扩展在估计平均肺动脉压的实验中，结合表格数据和心脏MRI图像，表现出与最先进的黑盒模型相当或更优的性能。

**Conclusion:** RegScore为临床环境中的回归任务提供了一种透明且可解释的方法，有助于做出更明智和可信的决策。它通过放宽传统评分系统的限制并整合多模态数据，实现了卓越的预测性能。

> **ai_Abstract:** RegScore是一种新型的、稀疏且可解释的回归任务评分系统，旨在克服传统评分系统在回归任务中的局限性。它通过束搜索和k-稀疏岭回归放宽了对整数系数的限制，并扩展到结合表格数据和医学图像的双模态深度学习，利用TIP transformer实现个性化评分。实验证明，RegScore在预测性能上可与SOTA黑盒模型媲美或超越，为临床决策提供了透明和可信赖的工具。

> **摘要翻译:** 评分系统因其固有的简单性和透明性而被广泛应用于医疗领域，特别是在涉及表格数据的分类任务中。在这项工作中，我们引入了RegScore，一种新颖的、稀疏的、可解释的评分系统，专门为回归任务设计。与受限于整数值系数的传统评分系统不同，RegScore利用束搜索和k-稀疏岭回归来放宽这些限制，从而提高预测性能。我们将RegScore扩展到双模态深度学习，通过将表格数据与医学图像相结合。我们利用TIP（表格图像预训练）transformer的分类token生成个性化线性回归参数和个性化RegScore，从而实现个性化评分。我们通过使用表格数据估计平均肺动脉压来证明RegScore的有效性，并通过结合心脏MRI图像进一步细化这些估计。实验结果表明，RegScore及其个性化双模态扩展的性能与最先进的黑盒模型相当或更优。我们的方法为临床环境中的回归任务提供了一种透明和可解释的方法，促进了更明智和可信的决策。我们提供了代码，网址为https://github.com/SanoScience/RegScore。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [553] [Extreme Cardiac MRI Analysis under Respiratory Motion: Results of the CMRxMotion Challenge](https://arxiv.org/abs/2507.19165)
> *呼吸运动下极端心脏MRI分析：CMRxMotion挑战赛的结果*

*Kang Wang, Chen Qin, Zhang Shi, Haoran Wang, Xiwen Zhang, Chen Chen, Cheng Ouyang, Chengliang Dai, Yuanhan Mo, Chenchen Dai, Xutong Kuang, Ruizhe Li, Xin Chen, Xiuzheng Yue, Song Tian, Alejandro Mora-Rubio, Kumaradevan Punithakumar, Shizhan Gong, Qi Dou, Sina Amirrajab, Yasmina Al Khalil, Cian M. Scannell, Lexiaozi Fan, Huili Yang, Xiaowu Sun, Rob van der Geest, Tewodros Weldebirhan Arega, Fabrice Meriaudeau, Caner Özer, Amin Ranem, John Kalkhof, İlkay Öksüz, Anirban Mukhopadhyay, Abdul Qayyum, Moona Mazher, Steven A Niederer, Carles Garcia-Cabrera, Eric Arazo, Michal K. Grzeszczyk, Szymon Płotka, Wanqin Ma, Xiaomeng Li, Rongjun Ge, Yongqing Kou, Xinrong Chen, He Wang, Chengyan Wang, Wenjia Bai, Shuo Wang* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-25**

**Keywords:** 心脏MRI, 呼吸运动, 深度学习, 图像伪影, CMRxMotion挑战赛

**Comment:** 

> **TL;DR:** CMRxMotion挑战赛旨在推动研究深度学习模型在呼吸运动伪影下心脏MRI分析的鲁棒性，发布了数据集并评估了22种算法在图像质量评估和心肌分割任务上的表现。

**AI_Comments:** 这项研究通过组织一个专门的挑战赛并发布高质量的、包含受控运动伪影的数据集，创新性地解决了深度学习在临床心脏MRI应用中的一个关键限制——呼吸运动伪影。其重要性在于为社区提供了一个标准化的基准和资源，以开发和评估更鲁棒的深度学习模型，直接提升了心脏MRI分析的临床实用性。对运动伪影对生物标志物影响的分析也具有重要的临床意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型在自动心脏磁共振（CMR）分析中表现出色，但其有效性高度依赖高质量、无伪影的图像。在临床实践中，CMR采集常因呼吸运动而受损，但深度学习模型对此类伪影的鲁棒性仍是一个未充分探索的问题。

**Method:** 组织了MICCAI CMRxMotion挑战赛，策划并公开发布了一个包含40名健康志愿者320个CMR电影序列的数据集，这些志愿者执行了特定的呼吸方案以诱导受控范围的运动伪影。挑战赛包含两个任务：1) 自动图像质量评估，根据运动严重程度对图像进行分类；2) 在存在运动伪影的情况下进行鲁棒的心肌分割。共提交了22种算法并进行了评估。

**Result:** 共提交了22种算法，并在两个指定任务上进行了评估。本文介绍了挑战设计和数据集的全面概述，报告了表现最佳方法的评估结果，并进一步调查了运动伪影对五种临床相关生物标志物的影响。

**Conclusion:** CMRxMotion挑战赛成功促进了深度学习模型在呼吸运动伪影下心脏MRI分析鲁棒性的研究，并提供了宝贵的数据集和基准，揭示了运动伪影对临床生物标志物的影响。

> **ai_Abstract:** 该论文介绍了MICCAI CMRxMotion挑战赛，旨在解决深度学习模型在呼吸运动伪影下的心脏MRI分析中鲁棒性不足的问题。挑战赛构建了一个包含320个CMR电影序列的公开数据集，并设置了图像质量评估和心肌分割两项任务。共22种算法参与评估，论文报告了顶级方法的表现，并分析了运动伪影对临床生物标志物的影响，所有资源均已公开。

> **摘要翻译:** 深度学习模型在自动化心脏磁共振（CMR）分析中取得了最先进的性能。然而，这些模型的功效高度依赖于高质量、无伪影图像的可用性。在临床实践中，CMR采集经常因呼吸运动而退化，但深度学习模型对此类伪影的鲁棒性仍然是一个未充分探索的问题。为了促进该领域的研究，我们组织了MICCAI CMRxMotion挑战赛。我们策划并公开发布了一个包含40名健康志愿者320个CMR电影序列的数据集，这些志愿者执行了特定的呼吸方案以诱导受控范围的运动伪影。挑战赛包括两个任务：1）自动图像质量评估，根据运动严重程度对图像进行分类；2）在存在运动伪影的情况下进行鲁棒的心肌分割。总共有22种算法被提交并在两个指定任务上进行了评估。本文全面概述了挑战赛的设计和数据集，报告了表现最佳方法的评估结果，并进一步调查了运动伪影对五种临床相关生物标志物的影响。所有资源和代码均可在https://github.com/CMRxMotion 公开获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [554] [Integrating Feature Selection and Machine Learning for Nitrogen Assessment in Grapevine Leaves using In-Field Hyperspectral Imaging](https://arxiv.org/abs/2507.17869)
> *利用田间高光谱成像技术整合特征选择与机器学习评估葡萄叶片氮含量*

*Atif Bilal Asad, Achyut Paudel, Safal Kshetri, Chenchen Kang, Salik Ram Khanal, Nataliya Shcherbatyuk, Pierre Davadant, R. Paul Schreiner, Santosh Kalauni, Manoj Karkee, Markus Keller* | **Category: eess.IV, cs.CV, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 高光谱成像, 氮, 葡萄, 特征选择, 机器学习

**Comment:** 

> **TL;DR:** 本研究利用田间高光谱成像、特征选择和机器学习技术预测葡萄叶片和冠层氮含量，识别出鲁棒的光谱区域，预测R方分别为0.49（冠层）和0.57（叶片）。

**AI_Comments:** 该论文创新性地将田间高光谱成像与先进的特征选择和机器学习技术结合，用于葡萄园的精准氮管理。识别出对氮预测具有鲁棒性的光谱区域尤为重要。尽管R方值中等，但其田间应用和针对单株植物的关注代表了精准农业实践的重大进展。

<details>
  <summary>Details</summary>

**Motivation:** 氮是葡萄园中最重要的营养物质之一，其土壤含量具有高度时空变异性。因此，需要准确估计葡萄叶片氮浓度并进行个体化施肥管理，以最佳地满足植物需求。

**Method:** 该研究使用田间高光谱图像（400-1000nm），采集自不同葡萄园、两个生长季和两个生长阶段的四种葡萄品种。经过图像处理后，采用两种特征选择方法识别最佳光谱波段集，并使用梯度提升（Gradient Boosting）和XGBoost两种机器学习模型进行氮浓度预测模型的训练和测试。

**Result:** 特征选择方法识别出的光谱区域在不同方法和数据集类型（叶片级和冠层级）中均表现出一致性，尤其是在500-525nm、650-690nm、750-800nm和900-950nm等关键区域，表明这些区域对预测氮含量具有鲁棒性。机器学习模型在冠层级数据上实现了0.49的R方，在叶片级数据上实现了0.57的R方。

**Conclusion:** 该研究证明了利用田间高光谱成像结合特征选择和机器学习技术监测葡萄园氮状况的潜力。

> **ai_Abstract:** 本研究利用田间高光谱成像技术，结合特征选择和机器学习方法（梯度提升和XGBoost），开发了预测葡萄叶片和冠层氮浓度的模型。研究识别出对氮含量预测具有鲁棒性的关键光谱区域，并在叶片级数据上实现了0.57的R方，在冠层级数据上实现了0.49的R方。该研究证明了整合特征选择和机器学习技术在葡萄园氮状态监测方面的潜力。

> **摘要翻译:** 氮（N）是葡萄园中最重要的营养物质之一，影响植物生长以及随后的葡萄酒和果汁等产品。由于土壤氮具有高度空间和时间变异性，因此需要准确估计葡萄叶片的氮浓度，并在单株植物水平上管理施肥，以最佳地满足植物需求。在本研究中，我们使用了在田间采集的四种不同葡萄品种的高光谱图像，波长范围为400至1000纳米，这些图像来自不同的葡萄园，并在两个生长季节的两个不同生长阶段收集，以开发用于预测叶片级和冠层级氮浓度的模型。图像处理后，采用了两种特征选择方法来识别对叶片氮浓度有响应的最佳光谱波段集。选定的光谱波段用于训练和测试两种不同的机器学习（ML）模型，即梯度提升（Gradient Boosting）和XGBoost，用于预测氮浓度。叶片级和冠层级数据集选定波段的比较表明，特征选择方法识别出的大多数光谱区域在两种方法和数据集类型（叶片级和冠层级数据集）中均表现出一致性，特别是在关键区域：500-525nm、650-690nm、750-800nm和900-950nm。这些发现表明这些光谱区域在预测氮含量方面的鲁棒性。氮预测结果表明，尽管在每个分析级别使用了不同的选定光谱波段集，但机器学习模型在冠层级数据上实现了0.49的R方，在叶片级数据上实现了0.57的R方。该研究证明了利用田间高光谱成像以及在集成特征选择和机器学习技术中使用光谱数据来监测葡萄园氮状态的潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [555] [Direct Dual-Energy CT Material Decomposition using Model-based Denoising Diffusion Model](https://arxiv.org/abs/2507.18012)
> *基于模型去噪扩散模型的直接双能CT物质分解*

*Hang Xu, Alexandre Bousse, Alessandro Perelli* | **Category: eess.IV, cs.CV, physics.med-ph, 92C55, 94A08, I.4.5; J.3** | **Updated: 2025-07-24**

**Keywords:** 双能CT, 物质分解, 去噪扩散模型, 深度学习, 投影域分解

**Comment:** 13 pages, 10 figures, 2 tables

> **TL;DR:** 本文提出了一种名为DEcomp-MoD的深度学习方法，用于直接从双能CT投影数据进行定量物质分解，该方法优于现有技术。

**AI_Comments:** 该论文的创新点在于将DECT光谱模型知识与去噪扩散模型相结合，实现了从投影数据到物质图像的直接转换，有效避免了传统图像域分解方法中射束硬化效应带来的问题。这种端到端的方法提高了物质分解的准确性，并展示了其在临床应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有方法在图像域进行物质分解作为后处理步骤，但这未能考虑射束硬化效应，导致次优结果。

**Method:** 本文提出了一种名为Dual-Energy Decomposition Model-based Diffusion (DEcomp-MoD) 的深度学习方法。该算法将光谱DECT模型的知识融入深度学习训练损失中，并结合了物质图像域中基于分数的去噪扩散学习先验。推理优化损失直接以正弦图作为输入，并通过基于模型的条件扩散模型转换为物质图像，从而保证结果的一致性。

**Result:** DEcomp-MoD方法在低剂量AAPM数据集的合成DECT正弦图上进行了定量和定性评估，结果表明其性能优于最先进的无监督基于分数模型和有监督深度学习网络。

**Conclusion:** DEcomp-MoD在物质分解方面表现出卓越的性能，并具有用于临床诊断的潜力。

> **ai_Abstract:** 本文提出了一种名为DEcomp-MoD的深度学习方法，用于解决传统双能CT物质分解方法在图像域处理导致次优结果的问题。DEcomp-MoD直接将DECT投影数据转换为物质图像，通过将光谱DECT模型知识融入训练损失并结合基于分数的去噪扩散先验来实现。该方法直接处理正弦图输入，并通过条件扩散模型确保结果一致性。实验结果表明，DEcomp-MoD在合成DECT数据集上优于现有的无监督和有监督深度学习方法，显示出在临床诊断中的应用潜力。

> **摘要翻译:** 双能X射线计算机断层扫描（DECT）是一种先进技术，利用X射线线性衰减与能量的依赖性，无需手动分割即可在临床图像中自动分解物质。然而，大多数方法在重建后将物质分解作为图像域中的后处理步骤，但此过程未考虑射束硬化效应，导致结果次优。在这项工作中，我们提出了一种名为双能分解基于模型扩散（DEcomp-MoD）的深度学习方法，用于定量物质分解，它直接将DECT投影数据转换为物质图像。该算法基于将光谱DECT模型的知识整合到深度学习训练损失中，并结合物质图像域中基于分数的去噪扩散学习先验。重要的是，推理优化损失直接将正弦图作为输入，并通过基于模型的条件扩散模型转换为物质图像，从而保证结果的一致性。我们使用低剂量AAPM数据集的合成DECT正弦图对所提出的DEcomp-MoD方法进行了定量和定性评估。最后，我们表明DEcomp-MoD优于最先进的无监督基于分数模型和有监督深度学习网络，并具有部署用于临床诊断的潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [559] [TCM-Tongue: A Standardized Tongue Image Dataset with Pathological Annotations for AI-Assisted TCM Diagnosis](https://arxiv.org/abs/2507.18288)
> *TCM-Tongue：一个用于AI辅助中医诊断的带病理标注的标准化舌象数据集*

*Xuebo Jin, Longfei Gao, Anshuo Tong, Zhengyang Chen, Jianlei Kong, Ning Sun, Huijun Ma, Qiang Wang, Yuting Bai, Tingli Su* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 中医, 舌诊, 数据集, AI辅助诊断, 病理标注

**Comment:** 16 pages, 11 figures, 2 Tables

> **TL;DR:** 本文提出了TCM-Tongue数据集，一个包含6719张标准化舌象图片并带有20种病理症状标注的数据集，旨在解决AI在中医舌诊中数据不足的问题，并已用多种深度学习模型进行了基准测试。

**AI_Comments:** 本文的主要创新在于构建了首个大规模、标准化且带有详细病理标注的舌象数据集TCM-Tongue，有效弥补了AI在中医舌诊领域的数据空白。该数据集的标准化采集和专业医生验证确保了数据质量，并通过多种深度学习模型的基准测试验证了其在AI开发中的实用性。这对于推动中医诊断的客观化和智能化具有重要意义，有望加速AI在中医领域的应用与发展。

<details>
  <summary>Details</summary>

**Motivation:** 传统中医舌诊面临主观解释和成像协议不一致导致的标准化挑战，且缺乏大规模、带标注的数据集阻碍了人工智能在中医诊断领域的发展。

**Method:** 本文提出了TCM-Tongue数据集，这是首个用于AI驱动中医舌诊的专业数据集。该数据集包含6719张在标准化条件下捕获的高质量图像，并标注了20种病理症状类别（平均每张图像有2.54个临床验证的标签，均由执业中医师验证）。该数据集支持多种标注格式（COCO、TXT、XML），并通过九种深度学习模型（YOLOv5/v7/v8变体、SSD和MobileNetV2）进行了基准测试，以展示其对AI开发的实用性。

**Result:** 成功构建了TCM-Tongue数据集，包含6719张高品质、标准化采集并经中医师验证的带20种病理症状标注的舌象图像。数据集支持COCO、TXT、XML等多种标注格式。通过使用YOLOv5/v7/v8变体、SSD和MobileNetV2等九种深度学习模型进行基准测试，验证了该数据集对AI开发的实用性。

**Conclusion:** TCM-Tongue数据集为推进中医领域可靠的计算工具提供了关键基础，弥补了阻碍该领域进展的数据短缺，并通过标准化、高质量的诊断数据促进了AI在研究和临床实践中的整合。

> **ai_Abstract:** 为解决中医舌诊中AI发展面临的标准化挑战和数据短缺问题，本文提出了TCM-Tongue数据集，这是首个用于AI辅助中医舌诊的标准化数据集。该数据集包含6719张高品质舌象图片，并标注了20种病理症状，支持多种标注格式。通过使用九种深度学习模型进行基准测试，验证了其对AI开发的实用性。该数据集为中医计算工具的发展奠定了基础，促进了AI在中医研究和临床实践中的整合。

> **摘要翻译:** 传统中医（TCM）舌诊虽然具有临床价值，但由于主观解释和不一致的成像协议而面临标准化挑战，加上缺乏大规模、带标注的数据集阻碍了人工智能的发展。为了弥补这一空白，我们提出了第一个用于AI驱动中医舌诊的专业数据集，该数据集包含6719张在标准化条件下捕获的高质量图像，并标注了20种病理症状类别（平均每张图像有2.54个临床验证的标签，均由执业中医师验证）。该数据集支持多种标注格式（COCO、TXT、XML），具有广泛的可用性，并已使用九种深度学习模型（YOLOv5/v7/v8变体、SSD和MobileNetV2）进行了基准测试，以展示其对AI开发的实用性。这一资源为推进中医领域可靠的计算工具提供了关键基础，弥补了阻碍该领域进展的数据短缺，并通过标准化、高质量的诊断数据促进了AI在研究和临床实践中的整合。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [590] [Enhancing Diabetic Retinopathy Classification Accuracy through Dual Attention Mechanism in Deep Learning](https://arxiv.org/abs/2507.19199)
> *深度学习中通过双重注意力机制提高糖尿病视网膜病变分类准确性*

*Abdul Hannan, Zahid Mahmood, Rizwan Qureshi, Hazrat Ali* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-25**

**Keywords:** 糖尿病视网膜病变, 深度学习, 注意力机制, 数据不平衡, 分类

**Comment:** submitted to Computer Methods in Biomechanics and Biomedical
  Engineering: Imaging & Visualization

> **TL;DR:** 本文提出一种结合全局和类别注意力块的深度学习模型，以解决糖尿病视网膜病变分类中数据不平衡问题，并在公开数据集上达到了有竞争力的性能。

**AI_Comments:** 本文的创新点在于引入双重注意力机制（GAB和CAB）来有效解决糖尿病视网膜病变分类中常见的数据不平衡问题，这对于提高模型的泛化能力至关重要。其重要性在于能够辅助眼科医生制定个性化治疗方案，具有较高的临床应用价值。同时，研究还关注了模型参数量，指出MobileNetV3-small在保持竞争性性能的同时具有较小的模型规模，这对于实际部署具有优势。

<details>
  <summary>Details</summary>

**Motivation:** 自动分类糖尿病视网膜病变对个性化治疗至关重要，但数据集中数据分布不平衡是深度学习模型泛化能力的瓶颈。

**Method:** 提出一种基于注意力机制的深度学习模型，将全局注意力块（GAB）和类别注意力块（CAB）结合到模型中，并使用MobileNetV3-small、Efficientnet-b0和DenseNet-169作为骨干网络。

**Result:** 在APTOS数据集上，DenseNet-169达到83.20%的平均准确率，MobileNetV3-small为82%，EfficientNet-b0为80%。在EYEPACS数据集上，EfficientNet-b0达到80%的平均准确率，DenseNet-169为75.43%，MobileNetV3-small为76.68%。实验还获得了82.0%的F1-score，82.1%的精确度，83.0%的敏感度，95.5%的特异性和88.2%的Kappa分数。MobileNetV3-small在APTOS和EYEPACS数据集上的参数量分别为160万和90万，相对较少。

**Conclusion:** 所提出的方法在糖尿病视网膜病变分类方面取得了与最新研究相当的有竞争力的性能。

> **ai_Abstract:** 本文针对糖尿病视网膜病变（DR）自动分类中数据不平衡导致的深度学习模型泛化能力受限问题，提出了一种基于双重注意力机制的深度学习模型。该模型结合了全局注意力块（GAB）和类别注意力块（CAB），并以MobileNetV3-small、Efficientnet-b0和DenseNet-169作为骨干网络。在APTOS和EYEPACS两个公开数据集上的实验结果表明，所提出的方法在准确率、F1-score等多个指标上均表现出色，且MobileNetV3-small模型参数量较少，达到了与现有研究相当的竞争力。

> **摘要翻译:** 糖尿病视网膜病变（DR）的自动分类可以帮助眼科医生制定个性化治疗方案，使其成为临床实践的关键组成部分。然而，数据集中不平衡的数据分布成为用于DR分类的深度学习模型泛化能力的瓶颈。在这项工作中，我们将全局注意力块（GAB）和类别注意力块（CAB）结合到深度学习模型中，从而有效克服了DR分类中数据分布不平衡的问题。我们提出的方法基于一种注意力机制的深度学习模型，该模型采用MobileNetV3-small、Efficientnet-b0和DenseNet-169三个预训练网络作为骨干架构。我们在两个公开可用的DR视网膜眼底图像数据集上评估了所提出的方法。实验结果表明，在APTOS数据集上，DenseNet-169的平均准确率为83.20%，其次是MobileNetV3-small和EfficientNet-b0，分别达到82%和80%的准确率。在EYEPACS数据集上，EfficientNet-b0的平均准确率为80%，而DenseNet-169和MobileNetV3-small分别达到75.43%和76.68%的准确率。此外，我们还计算了实验的F1-score为82.0%，精确度为82.1%，敏感度为83.0%，特异性为95.5%，Kappa分数为88.2%。此外，在我们的工作中，MobileNetV3-small在APTOS数据集上的参数量为160万，在EYEPACS数据集上的参数量为90万，这与其他方法相比相对较少。所提出的方法取得了与最近报道的DR分类工作相当的有竞争力的性能。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [625] [SAM2-Aug: Prior knowledge-based Augmentation for Target Volume Auto-Segmentation in Adaptive Radiation Therapy Using Segment Anything Model 2](https://arxiv.org/abs/2507.19282)
> *SAM2-Aug：基于先验知识的增强，用于自适应放射治疗中目标体积的自动分割，使用Segment Anything Model 2*

*Guoping Xu, Yan Dai, Hengrui Zhao, Ying Zhang, Jie Deng, Weiguo Lu, You Zhang* | **Category: eess.IV, cs.CV, physics.med-ph** | **Updated: 2025-07-25**

**Keywords:** SAM2-Aug, 肿瘤分割, 自适应放射治疗, 先验知识, 图像增强

**Comment:** 26 pages, 10 figures

> **TL;DR:** SAM2-Aug通过结合先验图像和增强提示多样性，显著提高了SAM2在自适应放射治疗中肿瘤分割的准确性和泛化能力，并在多个数据集上表现优异。

**AI_Comments:** 该论文的创新点在于针对SAM2在医疗图像分割中精度不足的问题，提出了基于先验知识的增强策略，特别是结合了医疗图像的特有属性（如先验MR图像和注释）和提示工程（如随机边界框扩展和掩膜操作）。这使得SAM2能够更好地适应复杂的医学影像分割任务，克服了其在通用场景下可能存在的局限性。其重要性在于为ART提供了一个更准确、高效的肿瘤分割工具，有助于提高治疗质量并减少人工干预。模型的泛化能力强，能在不同肿瘤类型和成像序列上保持优异性能，这在临床应用中具有显著价值。

<details>
  <summary>Details</summary>

**Motivation:** 自适应放射治疗（ART）中精确的肿瘤分割至关重要，但目前的方法耗时且依赖用户。Segment Anything Model 2（SAM2）在提示驱动分割方面有潜力，但在肿瘤精度上存在不足。本研究旨在通过基于先验知识的增强策略来提升SAM2在ART中的表现。

**Method:** 提出了两种策略来改进SAM2：1) 使用先验MR图像和注释作为上下文输入；2) 通过随机边界框扩展和掩膜侵蚀/膨胀来提高提示的鲁棒性。由此产生的模型SAM2-Aug在One-Seq-Liver数据集上进行微调和测试，并在Mix-Seq-Abdomen和Mix-Seq-Brain数据集上未经再训练进行了评估。

**Result:** SAM2-Aug在所有数据集上均优于卷积、基于Transformer和提示驱动模型，Dice分数分别为0.86（肝脏）、0.89（腹部）和0.90（大脑）。它在肿瘤类型和成像序列上表现出强大的泛化能力，并在边界敏感指标上性能提升。

**Conclusion:** 结合先验图像和增强提示多样性显著提高了分割精度和泛化能力。SAM2-Aug为ART中的肿瘤分割提供了一个鲁棒、高效的解决方案。

> **ai_Abstract:** 本研究提出了SAM2-Aug模型，旨在通过引入先验知识和增强提示多样性来改进Segment Anything Model 2（SAM2）在自适应放射治疗（ART）中肿瘤自动分割的准确性和泛化能力。SAM2-Aug利用先验MR图像和注释作为上下文输入，并通过随机边界框扩展和掩膜操作提高提示鲁棒性。实验结果显示，SAM2-Aug在多个肿瘤数据集上均优于现有模型，并展示了强大的跨肿瘤类型和成像序列的泛化能力，为ART中的肿瘤分割提供了一个高效且鲁棒的解决方案。

> **摘要翻译:** 目的：精确的肿瘤分割对于自适应放射治疗（ART）至关重要，但仍耗时且依赖用户。Segment Anything Model 2（SAM2）在基于提示的分割方面显示出前景，但在肿瘤精度方面存在不足。我们提出了基于先验知识的增强策略，以增强SAM2在ART中的应用。
方法：引入了两种策略来改进SAM2：(1) 使用先验MR图像和注释作为上下文输入；(2) 通过随机边界框扩展和掩膜侵蚀/膨胀来提高提示的鲁棒性。由此产生的模型SAM2-Aug在One-Seq-Liver数据集（31名肝癌患者的115张MRI）上进行了微调和测试，并在Mix-Seq-Abdomen（88张MRI，28名患者）和Mix-Seq-Brain（86张MRI，37名患者）上未经再训练进行了评估。
结果：SAM2-Aug在所有数据集上均优于卷积、基于Transformer和提示驱动模型，Dice分数分别为0.86（肝脏）、0.89（腹部）和0.90（大脑）。它在肿瘤类型和成像序列上表现出强大的泛化能力，并在边界敏感指标上性能有所改善。
结论：结合先验图像和增强提示多样性显著提高了分割精度和泛化能力。SAM2-Aug为ART中的肿瘤分割提供了一个鲁棒、高效的解决方案。代码和模型将在https://github.com/apple1986/SAM2-Aug发布。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [639] [UniSegDiff: Boosting Unified Lesion Segmentation via a Staged Diffusion Model](https://arxiv.org/abs/2507.18362)
> *UniSegDiff：通过分阶段扩散模型提升统一病灶分割*

*Yilong Hu, Shijie Chang, Lihe Zhang, Feng Tian, Weibing Sun, Huchuan Lu* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 扩散模型, 病灶分割, 统一分割, 分阶段训练, 医学图像

**Comment:** MICCAI2025

> **TL;DR:** UniSegDiff通过分阶段扩散模型解决了现有扩散模型在统一病灶分割中的效率和性能问题，并显著优于现有SOTA方法。

**AI_Comments:** UniSegDiff的创新点在于其分阶段训练和推理策略，有效解决了扩散模型在医学图像分割中注意力分布不均的问题，提高了训练效率和分割性能。其统一处理多模态和多器官病灶分割的能力也极具价值，为临床应用提供了更通用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 扩散概率模型在医学图像分割中潜力巨大，但现有训练和推理策略导致不同时间步的注意力分布不均，训练时间长且解决方案次优，尤其在统一病灶分割方面。

**Method:** 提出UniSegDiff，一个新颖的扩散模型框架，用于统一地解决多模态和多器官的病灶分割问题。该框架引入了分阶段的训练和推理方法，动态调整不同阶段的预测目标，强制模型在所有时间步保持高注意力，并通过预训练特征提取网络实现统一病灶分割。

**Result:** 在六个不同器官、多种成像模态上的综合实验结果表明，UniSegDiff显著优于之前的最先进（SOTA）方法。

**Conclusion:** UniSegDiff通过其独特的分阶段训练和推理策略，有效解决了扩散模型在统一病灶分割中的挑战，并取得了卓越的性能，使其成为该领域一个有前景的解决方案。

> **ai_Abstract:** 本文提出了UniSegDiff，一个新颖的分阶段扩散模型框架，用于统一的多模态多器官病灶分割。针对现有扩散模型训练效率低、性能次优的问题，UniSegDiff通过引入分阶段训练和推理策略，动态调整预测目标，确保模型在所有时间步都保持高注意力，并通过预训练特征提取网络实现统一分割。实验证明UniSegDiff在六个器官和多种模态上的性能显著优于现有SOTA方法。

> **摘要翻译:** 扩散概率模型（DPM）在各种生成任务中表现出卓越的性能。扩散模型固有的随机性有助于解决医学图像和标签边缘模糊等问题，使扩散概率模型（DPM）成为病灶分割的一种有前景的方法。然而，我们发现当前扩散模型的训练和推理策略导致不同时间步的注意力分布不均，从而导致训练时间更长和次优的解决方案。为此，我们提出了UniSegDiff，一个新颖的扩散模型框架，旨在以统一的方式解决多模态和多器官的病灶分割问题。该框架引入了一种分阶段的训练和推理方法，动态调整不同阶段的预测目标，强制模型在所有时间步保持高度关注，并通过预训练分割的特征提取网络实现统一病灶分割。我们在六个不同器官的各种成像模态上评估了性能。综合实验结果表明，UniSegDiff显著优于以前的最先进（SOTA）方法。代码可在https://github.com/HUYILONG-Z/UniSegDiff获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [669] [A multi-dynamic low-rank deep image prior (ML-DIP) for real-time 3D cardiovascular MRI](https://arxiv.org/abs/2507.19404)
> *一种用于实时三维心血管MRI的多动态低秩深度图像先验 (ML-DIP)*

*Chong Chen, Marc Vornehm, Preethi Chandrasekaran, Muhammad A. Sultan, Syed M. Arshad, Yingmin Liu, Yuchi Han, Rizwan Ahmad* | **Category: eess.IV** | **Updated: 2025-07-25**

**Keywords:** 三维实时心血管MRI, 深度图像先验, 欠采样重建, 低秩, 心脏运动

**Comment:** 

> **TL;DR:** 本文提出了一种名为ML-DIP的框架，用于从高度欠采样数据重建高质量三维实时电影心血管磁共振（CMR），无需完全采样的训练数据。该方法在体模、健康受试者和室性早搏（PVC）患者中表现出色，能有效恢复心脏运动和不规则心跳。

**AI_Comments:** 该论文的关键创新在于其ML-DIP框架，能够从欠采样数据重建图像，而无需依赖完全采样的训练数据，这克服了许多深度学习方法在数据依赖性上的限制。其逐次扫描优化的特性也增强了方法的灵活性和适用性。这项工作的重要性在于实现了高加速因子（超过1000）的高质量三维实时CMR，对于动态心血管评估，尤其是在运动或心律失常等具有挑战性的临床条件下，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种从高度欠采样数据重建三维实时电影心血管磁共振（CMR）的框架，且无需完全采样的训练数据。

**Method:** 本研究开发了一种多动态低秩深度图像先验（ML-DIP）框架，该框架使用独立的神经网络对空间图像内容和时间形变场进行建模。这些网络针对每次扫描进行优化，直接从欠采样的k空间数据重建动态图像序列。ML-DIP在具有模拟室性早搏（PVCs）的三维电影数字体模、十名健康受试者（包括两名在休息和运动期间均进行扫描的受试者）以及五名PVC患者中进行了评估。体模结果使用峰值信噪比（PSNR）和结构相似性指数度量（SSIM）进行评估。体内性能通过比较左心室功能量化（与二维实时电影相比）和图像质量（与二维实时电影和基于分箱的5D-Cine相比）进行评估。

**Result:** 在体模研究中，ML-DIP在最短两分钟的扫描时间内实现了PSNR > 29 dB和SSIM > 0.90，同时恢复了心脏运动、呼吸运动和PVC事件。在健康受试者中，ML-DIP获得了与二维电影相当的功能测量结果，并且图像质量高于5D-Cine，包括在高心率和整体运动的运动期间。在PVC患者中，ML-DIP保留了逐搏变异性并重建了不规则心跳，而5D-Cine由于分箱显示了运动伪影和信息丢失。

**Conclusion:** ML-DIP通过从未采样数据中学习低秩空间和时间表示，无需依赖外部完全采样训练数据集，实现了加速因子超过1000的高质量三维实时CMR。

> **ai_Abstract:** 本文介绍了一种名为多动态低秩深度图像先验（ML-DIP）的新型框架，用于从高度欠采样的k空间数据重建高质量的三维实时电影心血管磁共振（CMR）图像。该框架利用独立的神经网络对空间内容和时间形变进行建模，并针对每次扫描进行优化，无需外部训练数据。在体模、健康受试者和室性早搏（PVC）患者上的评估表明，ML-DIP能够实现卓越的图像质量和功能测量，尤其是在高心率、整体运动和不规则心跳等挑战性场景下，其性能优于现有方法如5D-Cine。该方法显著加速了高保真三维实时CMR的实现。

> **摘要翻译:** 目的：开发一种从高度欠采样数据重建三维实时电影心血管磁共振（CMR）的框架，无需完全采样的训练数据。
方法：我们开发了一种多动态低秩深度图像先验（ML-DIP）框架，该框架使用独立的神经网络对空间图像内容和时间形变场进行建模。这些网络针对每次扫描进行优化，直接从欠采样的k空间数据重建动态图像序列。ML-DIP在以下对象上进行了评估：(i) 具有模拟室性早搏（PVCs）的三维电影数字体模，(ii) 十名健康受试者（包括两名在休息和运动期间均进行扫描的受试者），以及(iii) 五名PVC患者。体模结果使用峰值信噪比（PSNR）和结构相似性指数度量（SSIM）进行评估。体内性能通过比较左心室功能量化（与二维实时电影相比）和图像质量（与二维实时电影和基于分箱的5D-Cine相比）进行评估。
结果：在体模研究中，ML-DIP在最短两分钟的扫描时间内实现了PSNR > 29 dB和SSIM > 0.90，同时恢复了心脏运动、呼吸运动和PVC事件。在健康受试者中，ML-DIP获得了与二维电影相当的功能测量结果，并且图像质量高于5D-Cine，包括在高心率和整体运动的运动期间。在PVC患者中，ML-DIP保留了逐搏变异性并重建了不规则心跳，而5D-Cine由于分箱显示了运动伪影和信息丢失。
结论：ML-DIP通过从未采样数据中学习低秩空间和时间表示，无需依赖外部完全采样训练数据集，实现了加速因子超过1000的高质量三维实时CMR。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [681] [DiagR1: A Vision-Language Model Trained via Reinforcement Learning for Digestive Pathology Diagnosis](https://arxiv.org/abs/2507.18433)
> *DiagR1: 一种通过强化学习训练的消化病理诊断视觉语言模型*

*Minxi Ouyang, Lianghui Zhu, Yaqing Bao, Qiang Huang, Jingli Ouyang, Tian Guan, Xitong Ling, Jiawen Li, Song Duan, Wenbin Dai, Li Zheng, Xuemei Zhang, Yonghong He* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 消化病理, 视觉语言模型, 强化学习, 诊断, GRPO

**Comment:** 

> **TL;DR:** DiagR1是一个视觉语言模型，通过强化学习训练，提高了消化病理诊断的准确性和临床实用性，解决了现有模型数据质量和推理透明度问题。

**AI_Comments:** 这篇论文的创新点在于结合了强化学习（GRPO）来优化视觉语言模型在病理诊断中的推理质量和输出结构，并提出了一种提示论证策略来解决数据噪声和幻觉问题。构建大规模高质量数据集也是其重要贡献。该研究显著提高了自动化病理诊断的准确性和临床实用性，对于提升医疗效率和诊断可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前多模态模型在胃肠道病理分析中受限于数据质量和推理透明度：公共数据集中普遍存在的噪声和不完整标注导致模型产生事实幻觉，且缺乏明确的中间推理链使得输出难以审计，临床实践中信任度低。

**Method:** 构建了一个包含显微描述和诊断结论的大规模胃肠道病理数据集；提出了一种提示论证策略，结合病变分类和解剖部位信息，引导模型更好地捕获图像特定特征并保持语义一致性；采用结合监督微调和群相对策略优化（GRPO）的后训练流程，以提高推理质量和输出结构。

**Result:** 在真实世界病理报告生成任务中，该方法在生成质量、结构完整性和临床相关性方面显著优于现有SOTA开源和专有基线。与现有解决方案相比，临床相关性提高18.7%，结构完整性提高32.4%，诊断错误减少41.2%，显示出卓越的准确性和临床实用性。

**Conclusion:** DiagR1模型在消化病理诊断中表现出卓越的准确性和临床实用性，有效解决了现有模型的局限性。

> **ai_Abstract:** DiagR1是一个创新的视觉语言模型，专为消化病理诊断设计。该模型通过构建高质量的大规模数据集、引入提示论证策略以增强图像特征捕获和语义一致性，并结合监督微调与强化学习（GRPO）进行后训练，有效解决了现有模型在数据质量、推理透明度和诊断准确性方面的局限。实验证明，DiagR1在病理报告生成任务中显著提升了生成质量、结构完整性和临床相关性，大幅减少了诊断错误，展现出优越的性能和临床实用价值。

> **摘要翻译:** 多模态大模型在自动化病理图像分析方面展现出巨大潜力。然而，当前用于胃肠道病理的多模态模型受到数据质量和推理透明度的双重限制：公共数据集中普遍存在的噪声和不完整标注使得视觉语言模型在生成诊断文本时容易产生事实幻觉，而缺乏明确的中间推理链使得输出难以审计，从而在临床实践中信任度较低。为了解决这些问题，我们构建了一个包含显微描述和诊断结论的大规模胃肠道病理数据集，并提出了一种提示论证策略，该策略结合了病变分类和解剖部位信息。这种设计引导模型更好地捕获图像特定特征并在生成中保持语义一致性。此外，我们采用了一种结合监督微调和群相对策略优化（GRPO）的后训练流程，以提高推理质量和输出结构。在真实世界病理报告生成任务上的实验结果表明，我们的方法在生成质量、结构完整性和临床相关性方面显著优于最先进的开源和专有基线。我们的解决方案在临床相关性方面比最先进的模型高出18.7%，结构完整性提高32.4%，诊断错误减少41.2%，与现有解决方案相比，显示出卓越的准确性和临床实用性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [793] [Framework of a multiscale data-driven DT of the musculoskeletal system](https://arxiv.org/abs/2506.11821)
> *多尺度数据驱动的肌肉骨骼系统数字孪生框架*

*Martina Paccini, Simone Cammarasana, Giuseppe Patanè* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-25**

**Keywords:** 肌肉骨骼系统, 数字孪生, 多尺度数据, 生物力学, 个性化医疗

**Comment:** 

> **TL;DR:** 本文提出了一个多尺度数据驱动的肌肉骨骼数字孪生（MS-DT）框架，旨在通过整合多种生物力学数据和计算模型，为肌肉骨骼疾病提供个性化诊断和治疗工具。

**AI_Comments:** 该论文提出了一种创新的多尺度数据驱动数字孪生框架，将多种异构生物力学数据整合到统一模型中，从而实现了肌肉骨骼系统的患者特定高保真建模。其重要性在于为肌肉骨骼疾病的个性化诊断、治疗和康复提供了强大的工具，有望显著提升临床实践的精确性和效率。实时可视化和交互式平台的设计也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 肌肉骨骼疾病（MSDs）是全球残疾的主要原因，需要先进的诊断和治疗工具进行个性化评估和治疗。有效管理MSDs涉及异构数据源的交互，使得数字孪生（DT）范式成为一个有价值的选择。

**Method:** 本文引入了肌肉骨骼数字孪生（MS-DT），这是一个新颖的框架，它将多尺度生物力学数据与计算建模相结合，以创建肌肉骨骼系统的详细、患者特定表示。通过结合运动捕捉、超声成像、肌电图和医学成像，MS-DT能够分析脊柱运动学、姿势和肌肉功能。一个交互式可视化平台为临床医生和研究人员提供了直观的界面，用于探索生物力学参数和跟踪患者特定变化。

**Result:** 结果表明，MS-DT在提取精确的运动学和动态组织特征方面是有效的，为监测脊柱生物力学和康复提供了一个全面的工具。该框架提供了高保真建模和实时可视化，以改善患者特定的诊断和干预计划。

**Conclusion:** 该肌肉骨骼数字孪生（MS-DT）框架通过整合多尺度生物力学数据和计算模型，为肌肉骨骼疾病的个性化诊断、干预规划和康复监测提供了高保真建模和实时可视化能力，有效应对了异构数据源的挑战。

> **ai_Abstract:** 本文提出了一种名为肌肉骨骼数字孪生（MS-DT）的新型框架，旨在为肌肉骨骼疾病提供个性化的诊断和治疗工具。该框架通过整合多尺度生物力学数据（如运动捕捉、超声、肌电图、医学成像）和计算建模，创建了患者特定的肌肉骨骼系统数字表示。MS-DT能够分析脊柱运动学、姿势和肌肉功能，并提供交互式可视化平台。研究结果表明，MS-DT能有效提取精确的运动学和动态组织特征，为脊柱生物力学监测和康复提供高保真建模和实时可视化，从而改进患者诊断和干预规划。

> **摘要翻译:** 肌肉骨骼疾病（MSDs）是全球残疾的主要原因，需要先进的诊断和治疗工具进行个性化评估和治疗。MSDs的有效管理涉及异构数据源的交互，使得数字孪生（DT）范式成为一个有价值的选择。本文介绍了肌肉骨骼数字孪生（MS-DT），这是一个新颖的框架，它将多尺度生物力学数据与计算建模相结合，以创建肌肉骨骼系统的详细、患者特定表示。通过结合运动捕捉、超声成像、肌电图和医学成像，MS-DT能够分析脊柱运动学、姿势和肌肉功能。一个交互式可视化平台为临床医生和研究人员提供了直观的界面，用于探索生物力学参数和跟踪患者特定变化。结果表明，MS-DT在提取精确的运动学和动态组织特征方面是有效的，为监测脊柱生物力学和康复提供了一个全面的工具。该框架提供了高保真建模和实时可视化，以改善患者特定的诊断和干预计划。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [834] [A Study of Anatomical Priors for Deep Learning-Based Segmentation of Pheochromocytoma in Abdominal CT](https://arxiv.org/abs/2507.15193)
> *腹部CT中基于深度学习的嗜铬细胞瘤分割的解剖学先验知识研究*

*Tanjin Taher Toma, Tejas Sudharshan Mathai, Bikash Santra, Pritam Mukherjee, Jianfei Liu, Wesley Jong, Darwish Alabyad, Vivek Batheja, Abhishek Jha, Mayank Patel, Darko Pucar, Jayadira del Rivero, Karel Pacak, Ronald M. Summers* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 嗜铬细胞瘤, 分割, 深度学习, 解剖学先验知识, CT

**Comment:** 

> **TL;DR:** 本研究系统评估了用于深度学习嗜铬细胞瘤分割的解剖学先验知识，发现肿瘤+肾脏+主动脉（TKA）注释策略显著提高了分割精度和肿瘤负荷量化能力。

**AI_Comments:** 该研究的创新之处在于系统地评估了各种器官特异性解剖学先验知识对嗜铬细胞瘤分割的影响，并成功识别出TKA作为一种最优的先验配置。其重要性在于，通过提高嗜铬细胞瘤的分割精度，为临床诊断、治疗计划和潜在的遗传推断提供了更准确、有价值的工具，且该方法具有良好的鲁棒性和泛化能力。文中未提及明确的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 腹部CT扫描中嗜铬细胞瘤（PCC）的精确分割对于肿瘤负荷评估、预后和治疗计划至关重要，并有助于推断遗传簇，减少对昂贵检测的依赖。

**Method:** 本研究采用nnU-Net框架，系统评估了十一种注释策略，引入了一套基于器官特异性解剖学先验知识的新型多类别方案，这些先验知识来源于肾上腺肿瘤周围常见的邻近器官（如肝脏、脾脏、肾脏、主动脉、肾上腺和胰腺）。研究在NIH临床中心的105次增强CT扫描数据上进行了训练和测试，使用Dice相似系数（DSC）、归一化表面距离（NSD）和实例F1分数衡量性能。

**Result:** 在所有策略中，肿瘤+肾脏+主动脉（TKA）注释实现了最高的分割精度，在DSC（p = 0.0097）、NSD（p = 0.0110）和F1分数（在IoU阈值为0.5时提高了25.84%）方面显著优于先前使用的肿瘤+身体（TB）注释。TKA模型还显示出卓越的肿瘤负荷量化能力（R^2 = 0.968），并在所有遗传亚型中实现了强大的分割。在五折交叉验证中，TKA在所有IoU阈值（0.1至0.5）下均持续优于TB。

**Conclusion:** 将相关的解剖学背景纳入深度学习模型对于实现精确的嗜铬细胞瘤分割具有重要价值，为支持嗜铬细胞瘤患者的临床评估和纵向疾病监测提供了有价值的工具。

> **ai_Abstract:** 本研究探讨了利用解剖学先验知识改进腹部CT扫描中嗜铬细胞瘤（PCC）的深度学习分割。研究采用nnU-Net框架，评估了十一种注释策略，包括基于邻近器官的新型多类别方案。结果显示，肿瘤+肾脏+主动脉（TKA）注释策略显著优于现有方法（肿瘤+身体），在PCC分割精度、肿瘤负荷量化和对遗传亚型的泛化能力方面均表现更优。这些发现强调了在医学图像分割中纳入特定解剖学背景的重要性。

> **摘要翻译:** 腹部CT扫描中嗜铬细胞瘤（PCC）的精确分割对于肿瘤负荷评估、预后和治疗计划至关重要。它还有助于推断遗传簇，减少对昂贵检测的依赖。本研究系统地评估了解剖学先验知识，以确定能改进基于深度学习的PCC分割的配置。我们采用nnU-Net框架评估了十一种注释策略，用于嗜铬细胞瘤的精确3D分割，引入了一套基于器官特异性解剖学先验知识的新型多类别方案。这些先验知识来源于肾上腺肿瘤周围常见的邻近器官（例如肝脏、脾脏、肾脏、主动脉、肾上腺和胰腺），并与先前工作中使用的广泛身体区域先验知识进行了比较。该框架在NIH临床中心91名患者的105次增强CT扫描数据上进行了训练和测试。性能通过Dice相似系数（DSC）、归一化表面距离（NSD）和实例F1分数进行衡量。在所有策略中，肿瘤+肾脏+主动脉（TKA）注释实现了最高的分割精度，在70-30的训练-测试划分中，其在DSC（p = 0.0097）、NSD（p = 0.0110）和F1分数（在IoU阈值为0.5时提高了25.84%）方面显著优于先前使用的肿瘤+身体（TB）注释。TKA模型还在肿瘤负荷量化方面表现出卓越性能（R^2 = 0.968），并在所有遗传亚型中实现了强大的分割。在五折交叉验证中，TKA在所有IoU阈值（0.1至0.5）下始终优于TB，这增强了其鲁棒性和泛化能力。这些发现强调了将相关解剖学背景纳入深度学习模型以实现精确PCC分割的价值，为支持PCC患者的临床评估和纵向疾病监测提供了有价值的工具。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [84] [Segmentation-free Goodness of Pronunciation](https://arxiv.org/abs/2507.16838)
> *免切分发音质量评估*

*Xinwei Cao, Zijian Fan, Torbjørn Svendsen, Giampiero Salvi* | **Category: eess.AS, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 发音错误检测, 发音质量评估, 免切分, CTC, 音素评估

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 该论文提出了一种新的免切分发音质量评估（GOP）方法，名为GOP-AF，其利用CTC模型实现了音素级别发音评估的最新技术水平。

**AI_Comments:** 该论文的创新之处在于成功移除了音素级别发音评估中对预切分的传统依赖，这极大地提高了评估的准确性并拓宽了现代CTC模型在计算机辅助语言学习（CALL）系统中的应用。GOP-AF方法的理论严谨性、对数值稳定性的考虑以及归一化处理都体现了其设计的全面性和实用性。这对于MDD领域是一个重要的进步，因为它使得发音评估系统能够更好地利用当前最先进的深度学习声学模型。

<details>
  <summary>Details</summary>

**Motivation:** 现有的发音错误检测和诊断（MDD）系统，特别是音素级别的发音评估，通常需要将语音预先切分为音素单元。这种预切分限制了方法的准确性，并且阻碍了现代基于CTC的声学模型在评估中的应用。

**Method:** 本研究首先提出了自对齐发音质量评估（GOP-SA），它允许在MDD中使用经过CTC训练的ASR模型。接着，定义了一种更通用的免对齐方法，即GOP-AF，该方法考虑了目标音素的所有可能对齐。论文详细阐述了GOP-AF的理论基础、解决潜在数值问题的实现方法以及使其适用于具有不同时间峰度声学模型的适当归一化方法。

**Result:** 研究在CMU Kids和Speechocean762数据集上进行了广泛的实验，比较了不同方法的定义，评估了GOP-AF对声学模型峰度和目标音素周围上下文量的依赖性。结果表明，从所提出的方法中提取的特征向量在Speechocean762数据集上的音素级别发音评估中取得了最先进的结果。

**Conclusion:** 本研究提出的免切分发音质量评估方法，特别是GOP-AF，在音素级别发音评估中取得了最先进的性能，解决了传统方法对预切分的依赖，并使得现代基于CTC的声学模型能够被有效利用。

> **ai_Abstract:** 本文旨在解决当前发音错误检测与诊断（MDD）系统中音素级别发音评估对预切分的依赖性问题。作者提出了两种新颖的免切分发音质量评估（GOP）方法：自对齐GOP（GOP-SA）和更通用的免对齐GOP（GOP-AF）。GOP-SA允许使用CTC训练的ASR模型进行MDD，而GOP-AF则考虑了目标音素的所有可能对齐，并提供了理论阐述、数值问题解决方案和适当的归一化。在CMU Kids和Speechocean762数据集上的大量实验结果表明，所提出的方法，特别是GOP-AF，在音素级别发音评估方面取得了最先进的性能。

> **摘要翻译:** 发音错误检测与诊断（MDD）是现代计算机辅助语言学习（CALL）系统的重要组成部分。在MDD中，音素级别的发音评估是帮助第二语言学习者提高发音的关键。然而，大多数系统都基于某种形式的发音质量评估（GOP），这需要将语音预先切分为音素单元。这限制了这些方法的准确性以及使用现代基于CTC的声学模型进行评估的可能性。在本研究中，我们首先提出了自对齐GOP（GOP-SA），它使得经过CTC训练的ASR模型能够用于MDD。接下来，我们定义了一种更通用的免对齐方法，该方法考虑了目标音素的所有可能对齐（GOP-AF）。我们对GOP-AF的定义进行了理论阐述，提供了一种解决潜在数值问题的实现方法，以及适当的归一化处理，这使得该方法适用于具有不同时间峰度声学模型。我们在CMU Kids和Speechocean762数据集上提供了广泛的实验结果，比较了我们方法的不同定义，估计了GOP-AF对声学模型峰度和目标音素周围上下文量的依赖性。最后，我们将我们的方法与Speechocean762数据的最新研究进行了比较，结果表明，从所提出的方法中提取的特征向量在音素级别发音评估中取得了最先进的成果。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [162] [ASR-Guided Speaker-Role Diarization and Diarization-Guided ASR Decoding](https://arxiv.org/abs/2507.17765)
> *ASR引导的说话人角色日志化与日志化引导的ASR解码*

*Arindam Ghosh, Mark Fuhs, Bongjun Kim, Anurag Chowdhury, Monika Woszczyna* | **Category: eess.AS, cs.AI, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 说话人角色日志化, ASR, 日志化, 联合建模, 上下文预测器

**Comment:** Work in progress

> **TL;DR:** 本文将联合自动语音识别（ASR）和说话人日志化（SD）框架扩展到说话人角色日志化（RD），通过简化训练、使用独立的任务特定预测器，并利用RD信息来改善ASR解码，特别是在减少小词删除错误方面。

**AI_Comments:** 本文的创新之处在于将传统的说话人日志化（SD）扩展到更具实际应用价值的说话人角色日志化（RD），并将其与ASR深度融合。特别是，它解决了词预测和角色预测所需的上下文差异问题，通过引入独立的预测器来优化性能。此外，利用RD信息反向指导ASR解码，有效减少了小词删除错误，展示了跨任务信息流的潜力。这对于提升复杂对话场景中语音识别系统的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 从应用角度来看，说话人角色日志化（RD），例如区分医生与病人、主持人与嘉宾等，通常比传统的仅分配通用标签（如speaker-1、speaker-2）的说话人日志化（SD）更有用。本文旨在将现有的联合自动语音识别（ASR）+SD框架扩展到RD。

**Method:** 本文将现有的联合ASR+SD框架扩展到RD，并提出三项关键贡献：1) 通过强制对齐和交叉熵损失简化训练，取代RNNT损失；2) 表明词预测和角色预测需要不同量的预测器上下文，因此采用独立的任务特定预测器，而非现有共享预测器模型；3) 提出一种利用RD后验活动来影响ASR解码并减少小词删除错误的方法。

**Result:** 成功减少了ASR解码中的小词删除错误。

**Conclusion:** 本文成功将联合ASR+SD框架扩展到说话人角色日志化（RD），通过优化训练方法和引入任务特定预测器，并利用RD信息反向指导ASR解码，有效提高了ASR的准确性，尤其是在减少小词删除错误方面。

> **ai_Abstract:** 本文将联合自动语音识别（ASR）和说话人日志化（SD）框架扩展到更具应用价值的说话人角色日志化（RD）。作者提出了三项主要改进：一是通过强制对齐和交叉熵损失简化了训练过程；二是针对词预测和角色预测对上下文需求的不同，设计了独立的任务特定预测器，而非沿用共享预测器模型；三是提出了一种利用RD后验活动来指导ASR解码，从而有效减少小词删除错误的方法。这项工作为提高多方对话场景下语音识别的实用性和准确性提供了新思路。

> **摘要翻译:** 从应用角度来看，说话人角色日志化（RD），例如区分医生与病人、主持人与嘉宾等，通常比传统的仅分配通用标签（如speaker-1、speaker-2）的说话人日志化（SD）更有用。在联合自动语音识别（ASR）+SD（谁说了什么？）的背景下，最近的端到端模型采用一个辅助的SD传感器，与ASR传感器同步，以预测每个词的说话人。本文将此框架扩展到RD，并有三项关键贡献：1) 我们通过强制对齐和交叉熵损失而不是RNNT损失来简化训练；2) 我们表明词预测和角色预测需要不同量的预测器上下文，从而导致独立的任务特定预测器，这与现有共享预测器模型不同；3) 我们提出了一种利用RD后验活动来影响ASR解码并减少小词删除错误的方法。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [476] [A Concept-based approach to Voice Disorder Detection](https://arxiv.org/abs/2507.17799)
> *基于概念的声音障碍检测方法*

*Davide Ghia, Gabriele Ciravegna, Alkis Koudounas, Marco Fantini, Erika Crosetti, Giovanni Succo, Tania Cerquitelli* | **Category: eess.AS, cs.LG, cs.SD** | **Updated: 2025-07-23**

**Keywords:** 声音障碍检测, 可解释人工智能, 概念模型, 深度学习, 临床可信度

**Comment:** 

> **TL;DR:** 本文研究了一种基于可解释人工智能（XAI）的概念模型，用于声音障碍检测，旨在提高诊断的透明度和可信度，同时保持与传统深度学习相当的性能。

**AI_Comments:** 这篇论文的创新点在于将可解释人工智能（XAI）应用于声音障碍检测，特别关注概念模型以解决深度学习模型在临床应用中的“黑箱”问题。这种方法对于需要高透明度和可信度的医疗诊断领域至关重要，有望推动AI在医疗领域的实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 声音障碍影响大量人群，自动化、非侵入性诊断技术对医疗保健至关重要。尽管深度神经网络（DNNs）能有效诊断，但其决策过程不透明，限制了在临床环境中的可信度。

**Method:** 本文研究了一种基于可解释人工智能（XAI）的替代方法，旨在提高DNNs的可解释性。具体来说，重点关注概念模型，如概念瓶颈模型（CBM）和概念嵌入模型（CEM）。

**Result:** 这些概念模型在提供更透明和可解释的决策框架的同时，能够实现与传统深度学习方法相当的性能。

**Conclusion:** 基于概念的可解释人工智能模型（如CBM和CEM）为声音障碍检测提供了一种有前景的解决方案，它在保持高性能的同时，显著提高了模型的透明度和临床可信度。

> **ai_Abstract:** 本文提出了一种基于可解释人工智能（XAI）的概念方法，用于声音障碍的自动化检测。针对传统深度神经网络在临床应用中透明度不足的问题，研究了概念瓶颈模型（CBM）和概念嵌入模型（CEM）。结果表明，这些概念模型在提供更可解释决策框架的同时，能够达到与传统深度学习方法相媲美的性能，从而提高了诊断系统的临床可信度。

> **摘要翻译:** 声音障碍影响着相当一部分人口，使用自动化、非侵入性技术进行诊断将代表医疗保健领域的一项重大进步，改善患者的生活质量。最近的研究表明，人工智能模型，特别是深度神经网络（DNN），可以有效解决这项任务。然而，由于其复杂性，这些模型的决策过程通常不透明，限制了它们在临床环境中的可信度。本文研究了一种基于可解释人工智能（XAI）的替代方法，XAI是一个旨在通过提供不同形式的解释来提高DNN可解释性的领域。具体而言，这项工作侧重于基于概念的模型，如概念瓶颈模型（CBM）和概念嵌入模型（CEM），以及它们如何能够实现与传统深度学习方法相当的性能，同时提供更透明和可解释的决策框架。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [488] [Integrating IP Broadcasting with Audio Tags: Workflow and Challenges](https://arxiv.org/abs/2407.15423)
> *将IP广播与音频标签集成：工作流程与挑战*

*Rhys Burchett-Vass, Arshdeep Singh, Gabriel Bibbó, Mark D. Plumbley* | **Category: eess.AS, cs.AI, cs.MM, cs.SD** | **Updated: 2025-07-25**

**Keywords:** IP广播, 音频标签, 微服务, 工作流程, 延迟

**Comment:** Accepted for publication in 2025 AES International Conference on
  Artificial Intelligence and Machine Learning for Audio

> **TL;DR:** 本文探讨了将音频标签模型容器化为微服务，以集成到IP广播工作流程中，并讨论了相关挑战，特别是延迟问题。

**AI_Comments:** 本文的创新之处在于将音频标签功能封装为微服务，使其能够灵活地集成到现代IP广播生态系统中，这对于提高内容制作的自动化和效率具有重要意义。论文也务实地指出了集成过程中面临的关键挑战——延迟问题，这对于实时广播应用至关重要，体现了研究的实用性和前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** 广播行业已采用IP技术，彻底改变了内容制作方式，带来了更大的灵活性。音频标签在内容制作中具有多种用途（如添加音效、识别不需要的声音事件），但需要一种模块化、可访问且灵活的方式将其无缝集成到各种规模的广播工作流程中。

**Method:** 将音频标签模型容器化为一个微服务，即一个小型独立的代码模块，可以集成到多种不同的网络设置中。

**Result:** 描述了将音频标签模型容器化为微服务的过程，旨在开发一个模块化、可访问且灵活的工具，能够无缝部署到各种规模的广播工作流程中。讨论了所选音频标签模型的延迟及其对最终产品有用性的影响。

**Conclusion:** 本文描述了将音频标签模型集成到IP广播工作流程中的方法，并强调了延迟作为其有用性的一个关键挑战。

> **ai_Abstract:** 该论文详细阐述了将音频标签模型容器化为微服务，以实现其与IP广播工作流程的集成。这种方法旨在创建一个模块化、易于访问且灵活的工具，能够适应从小到大的各种制作规模，并探讨了在实际应用中，音频标签模型的延迟对最终产品有效性的影响及相关挑战。

> **摘要翻译:** 广播行业已经采用了IP技术，彻底改变了新闻采集到现场音乐活动等现场和预录内容的制作。IP广播允许以易于配置的方式传输音频和视频信号，符合现代网络技术。这种向IP工作流程的转变带来了更大的灵活性，不仅在信号路由方面，还在使用标准网络开发技术集成工具方面。其中一种可能的工具是实时音频标签，它在内容制作中具有多种用途。这些用途可能包括为自动字幕添加音效或识别场景中不需要的声音事件。在本文中，我们描述了将音频标签模型容器化为微服务的过程，微服务是一个小型独立的模块化代码，可以集成到多种不同的网络设置中。目标是开发一个模块化、可访问且灵活的工具，能够无缝部署到各种规模的广播工作流程中，从小型制作到大型公司。讨论了所选音频标签模型的延迟及其对最终产品有用性的影响所带来的挑战。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [530] [Self-Supervised Frameworks for Speaker Verification via Bootstrapped Positive Sampling](https://arxiv.org/abs/2501.17772)
> *通过自举正样本采样的说话人识别自监督框架*

*Theo Lepage, Reda Dehak* | **Category: eess.AS, cs.LG, cs.SD** | **Updated: 2025-07-24**

**Keywords:** 自监督学习, 说话人识别, 正样本采样, 信道信息, 表示学习

**Comment:** accepted for publication in IEEE TASLP

> **TL;DR:** 本文提出自监督正样本采样（SSPS），一种用于说话人识别（SV）的自监督学习新方法。SSPS通过在表示空间中选择正样本，有效降低了表示中录音源信息的编码，显著提升了SV性能，并降低了类内方差，增强了鲁棒性。

**AI_Comments:** 本文创新性地提出SSPS，通过在表示空间而非原始音频域进行正样本采样，有效解决了自监督说话人识别中表示编码过多信道信息的核心问题。这种方法不仅提升了性能，还在简化训练框架的同时提高了鲁棒性，对推动自监督学习在SV领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自监督学习（SSL）框架在说话人识别（SV）中，其正样本采样策略导致学习到的表示中编码了过多的录音源信息，即使通过大量数据增强也难以缩小与监督系统的性能差距，这是其根本性限制。

**Method:** 本文引入了自监督正样本采样（SSPS），这是一种自举技术，用于在SV的SSL框架中采样合适且多样化的正样本。SSPS在表示空间中采样接近锚点的正样本，假设这些伪正样本属于同一说话人身份但对应不同的录音条件。

**Result:** SSPS在应用于SimCLR、SwAV、VICReg和DINO等主要SSL框架时，在VoxCeleb基准上持续显示出SV性能的提升。使用SSPS，SimCLR和DINO在VoxCeleb1-O上分别达到2.57%和2.53%的等错误率（EER）。SimCLR的EER相对降低了58%，以更简单的训练框架获得了与DINO相当的性能。此外，SSPS降低了说话人表示中的类内方差并减少了信道信息，同时在没有数据增强的情况下表现出更强的鲁棒性。

**Conclusion:** SSPS通过改进自监督学习中的正样本采样策略，有效解决了说话人识别中表示编码过多信道信息的问题，显著提升了SV性能，降低了类内方差，并增强了表示的鲁棒性，即使在没有数据增强的情况下也能保持良好性能。

> **ai_Abstract:** 本文提出了自监督正样本采样（SSPS），一种用于说话人识别（SV）自监督学习的新型自举采样策略。针对现有SSL框架中正样本因共享信道特性而导致表示中编码过多录音源信息的问题，SSPS在表示空间中寻找接近锚点的伪正样本，这些样本被假定为同一说话人但来自不同录音条件。实验表明，SSPS在主流SSL框架上显著提升了SV性能，例如使SimCLR和DINO在VoxCeleb1-O上达到低EER，并使SimCLR的EER相对降低58%。SSPS还能降低类内方差、减少信道信息，并在无数据增强下增强鲁棒性。

> **摘要翻译:** 自监督学习（SSL）的最新发展在说话人识别（SV）方面展现出巨大潜力，但缩小与监督系统之间的性能差距仍然是一个持续的挑战。SSL框架依赖于锚点-正样本对，这些对由同一音频片段的不同部分构建。因此，即使经过大量数据增强，正样本也具有与其对应锚点相似的信道特性。因此，这种正样本采样策略是一个根本性限制，因为它在学习到的表示中编码了过多的录音源信息。本文引入了自监督正样本采样（SSPS），这是一种自举技术，用于在SV的SSL框架中采样合适且多样化的正样本。SSPS在表示空间中采样接近其锚点的正样本，假设这些伪正样本属于同一说话人身份但对应不同的录音条件。该方法在应用于SimCLR、SwAV、VICReg和DINO等主要SSL框架时，在VoxCeleb基准上持续显示出SV性能的提升。使用SSPS，SimCLR和DINO在VoxCeleb1-O上分别达到2.57%和2.53%的等错误率（EER）。SimCLR的EER相对降低了58%，以更简单的训练框架获得了与DINO相当的性能。此外，SSPS降低了说话人表示中的类内方差并减少了信道信息，同时在没有数据增强的情况下表现出更强的鲁棒性。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [567] [Incremental Averaging Method to Improve Graph-Based Time-Difference-of-Arrival Estimation](https://arxiv.org/abs/2507.07087)
> *增量平均法改进基于图的时间差到达估计*

*Klaus Brümann, Kouei Yamaoka, Nobutaka Ono, Simon Doclo* | **Category: eess.AS, eess.SP** | **Updated: 2025-07-25**

**Keywords:** TDOA估计, 增量平均, GCC-PHAT, 最小生成树, 声源定位

**Comment:** This paper was accepted for presentation at the IEEE Workshop on
  Applications of Signal Processing to Audio and Acoustics (WASPAA) 2025

> **TL;DR:** 提出一种增量平均法来计算GCC-PHAT函数的交叉功率谱密度，以提高基于图的TDOA和声源定位在噪声和混响环境下的精度。

**AI_Comments:** 该论文的创新点在于提出了增量平均法来整合多个交叉功率谱密度，从而在GCC-PHAT框架下增强TDOA估计的鲁棒性。这种方法有效解决了噪声和混响对定位精度的负面影响，对于实际声源定位应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于TDOA的语音源定位方法常受背景噪声和混响影响，导致估计精度下降。尽管MST方法提高了鲁棒性，但仍需进一步减少噪声和混响对TDOA估计精度的影响。

**Method:** 本文提出一种增量平均法来计算最小生成树（MST）的广义互相关相位变换（GCC-PHAT）函数，该方法通过对多个交叉功率谱密度（CPSDs）进行平均实现。在每一步中，通过考虑前一步中通过其他麦克风间接计算的CPSDs来增加平均的CPSDs数量。

**Result:** 在有噪声和混响的实验室环境中，针对不同声源和麦克风配置以及三种混响条件进行的实验结果表明，与依赖单个CPSDs的参考麦克风和基于MST的方法以及基于转向响应功率的声源定位方法相比，所提出的考虑多个CPSDs的方法提高了TDOA估计和声源位置估计的精度。

**Conclusion:** 提出的增量平均法通过整合多个交叉功率谱密度，显著提高了在噪声和混响环境下基于TDOA的声源定位精度。

> **ai_Abstract:** 本文提出一种增量平均法，旨在提升基于图的TDOA（时间差到达）估计在噪声和混响环境下的精度。该方法通过对最小生成树（MST）的广义互相关相位变换（GCC-PHAT）函数进行多交叉功率谱密度（CPSD）的增量平均计算，其中逐步纳入间接计算的CPSD。实验结果表明，与现有基于单CPSD的参考和MST方法以及转向响应功率方法相比，所提方法显著提高了TDOA和声源定位的准确性。

> **摘要翻译:** 基于时间差到达（TDOA）的语音源定位估计常受到背景噪声和混响的不利影响。估计麦克风对之间TDOA的常用方法是最大化具有相位变换（GCC-PHAT）函数的广义互相关。由于不同麦克风对之间的TDOA满足一致性关系，通常只使用一小部分麦克风对进行声源位置估计。虽然麦克风对的集合通常基于参考麦克风确定，但最近提出了一种更鲁棒的方法，通过计算GCC-PHAT函数可靠性信号图的最小生成树（MST）来确定麦克风对的集合。为了减少噪声和混响对TDOA估计精度的影响，本文提出了一种增量方法，通过对多个交叉功率谱密度（CPSDs）进行平均来计算MST的GCC-PHAT函数。在该方法的每一步中，通过考虑前一步中通过其他麦克风间接计算的CPSDs来增加平均的CPSDs数量。使用在有噪声和混响的实验室中通过空间分布的麦克风阵列记录的信号，评估了所提出方法在TDOA估计误差和2D声源位置估计误差方面的性能。针对不同声源和麦克风配置以及三种混响条件的实验结果表明，与依赖单个CPSDs的参考麦克风和基于MST的方法以及基于转向响应功率的声源定位方法相比，所提出的考虑多个CPSDs的方法提高了TDOA估计和声源位置估计的精度。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [608] [P.808 Multilingual Speech Enhancement Testing: Approach and Results of URGENT 2025 Challenge](https://arxiv.org/abs/2507.11306)
> *P.808 多语言语音增强测试：URGENT 2025 挑战赛的方法与结果*

*Marvin Sach, Yihui Fu, Kohei Saijo, Wangyou Zhang, Samuele Cornell, Robin Scheibler, Chenda Li, Anurag Kumar, Wei Wang, Yanmin Qian, Shinji Watanabe, Tim Fingscheidt* | **Category: eess.AS** | **Updated: 2025-07-25**

**Keywords:** 语音增强, 主观评估, 多语言, P.808, URGENT 挑战赛

**Comment:** 5 pages, 2 figures

> **TL;DR:** 该论文介绍了 P.808 众包主观听力测试方法，并提出了一种本地化文本和音频组件的流程，用于多语言语音增强评估。此外，它还分析了 URGENT 挑战赛的结果，并指出对于生成式语音增强方法，主观和客观无参考指标应辅以客观语音保真度指标以检测幻觉。

**AI_Comments:** 该论文的创新点在于其提出了 P.808 主观测试方法在多语言环境下的本地化流程，这对于评估全球范围内的语音增强系统至关重要。同时，它对生成式 AI 在语音增强领域带来的挑战进行了深入分析，特别是指出了在检测“幻觉”方面现有评估方法的局限性，并提出了结合语音保真度指标的必要性，这对于未来语音增强质量评估具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在语音增强 (SE) 系统的语音质量评估中，主观听力测试被认为是黄金标准，尤其是在大量新的生成式或混合方法出现后，这些方法暴露出一些客观指标的问题。Interspeech 2025 URGENT 语音增强挑战赛引入了多语言测试方面，促使研究者探讨多语言测试程序。

**Method:** 本文回顾了 ITU-T P.808 众包主观听力测试方法。主要贡献是提出了一种本地化 Naderi 和 Cutler 的众包主观绝对类别评级 (ACR) 听力测试中涉及文本到语音 (TTS) 的文本和音频组件的过程。此外，还分析了 URGENT 挑战赛的结果，以探讨在生成式 AI 时代 P.808 ACR 主观测试作为黄金标准的可靠性。

**Result:** 分析 URGENT 挑战赛的结果显示，对于生成式语音增强 (SE) 方法，主观 (ACR MOS) 和客观 (DNSMOS, NISQA) 无参考指标似乎需要辅以客观语音保真度指标，才能可靠地检测幻觉。

**Conclusion:** 对于生成式语音增强方法，为了可靠地检测幻觉，主观和客观无参考指标应与客观语音保真度指标结合使用。作者将很快发布用于根据 ITU-T P.808 进行新的多语言语音增强主观评估的本地化脚本和方法。

> **ai_Abstract:** 本文探讨了多语言语音增强系统的主观质量评估，特别是针对新兴的生成式 AI 方法。它回顾了 ITU-T P.808 众包主观听力测试方法，并提出了一种本地化该方法中文本和音频组件的新流程，以支持多语言评估。通过分析 URGENT 2025 挑战赛的结果，论文发现对于生成式语音增强，除了传统的主观和客观无参考指标外，还需要结合客观语音保真度指标来有效检测幻觉。作者表示将发布相关的本地化工具。

> **摘要翻译:** 在语音增强 (SE) 系统的语音质量评估中，主观听力测试迄今为止仍被认为是黄金标准。考虑到大量新的生成式或混合方法涌入该领域，暴露出一些客观指标的问题，这一点应该更加真实。Interspeech 2025 URGENT 语音增强挑战赛等工作也涉及非英语数据集，为测试程序增加了多语言方面。本文简要回顾了 ITU-T P.808 众包主观听力测试方法。第一个新颖的贡献是我们提出的本地化 Naderi 和 Cutler 的众包主观绝对类别评级 (ACR) 听力测试（涉及文本到语音 (TTS)）的文本和音频组件的过程。此外，我们对 URGENT 挑战赛的结果进行了令人惊讶的分析和深入见解，探讨了在生成式 AI 时代 (P.808) ACR 主观测试作为黄金标准的可靠性。特别是，对于生成式 SE 方法，主观 (ACR MOS) 和客观 (DNSMOS, NISQA) 无参考指标似乎应辅以客观语音保真度指标，以可靠地检测幻觉。最后，我们将很快发布我们的本地化脚本和方法，以便于根据 ITU-T P.808 轻松部署新的多语言语音增强主观评估。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [631] [FD-Bench: A Full-Duplex Benchmarking Pipeline Designed for Full Duplex Spoken Dialogue Systems](https://arxiv.org/abs/2507.19040)
> *FD-Bench：一个为全双工语音对话系统设计的全双工基准测试流程*

*Yizhou Peng, Yi-Wen Chao, Dianwen Ng, Yukun Ma, Chongjia Ni, Bin Ma, Eng Siong Chng* | **Category: eess.AS, cs.CL** | **Updated: 2025-07-25**

**Keywords:** 全双工语音对话系统, 基准测试, 用户打断, FD-Bench, 性能评估

**Comment:** Accepted to Interspeech 2025. 5 pages

> **TL;DR:** FD-Bench是一个为全双工语音对话系统（FDSDS）设计的全面基准测试流程，用于评估其在用户打断和复杂场景下的性能，并发现现有模型仍面临挑战。

**AI_Comments:** FD-Bench的创新在于提供了一个专门为全双工语音对话系统设计的全面基准测试流程，填补了现有基准缺乏全双工场景指标的空白。其利用LLMs、TTS和ASR构建模拟环境，并通过多样化指标评估系统性能，对于推动FDSDS的发展具有重要意义。研究结果揭示了当前FDSDS在处理用户打断和复杂环境下的局限性，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的语音对话系统依赖于轮流对话，而全双工语音对话系统（FDSDS）通过允许实时用户打断和回溯，实现了更自然的人机交互。然而，现有基准测试缺乏针对全双工场景的指标，例如评估模型在用户打断期间的性能。

**Method:** 本文提出了一个利用大型语言模型（LLMs）、文本转语音（TTS）和自动语音识别（ASR）的全面全双工基准测试流程FD-Bench。它通过多样化的新指标评估FDSDS处理用户打断、管理延迟以及在挑战性场景中保持鲁棒性的能力。该基准测试应用于三个开源FDSDS（Moshi、Freeze-omni和VITA-1.5），使用了超过40小时生成的语音，包括293个模拟对话和1,200次打断。

**Result:** 结果显示，所有模型在频繁干扰和嘈杂条件下，例如未能响应用户打断，仍然面临挑战。

**Conclusion:** 现有全双工语音对话系统在处理用户打断和应对复杂场景方面仍有待改进，FD-Bench为评估这些系统的性能提供了一个全面的工具。

> **ai_Abstract:** FD-Bench是一个为全双工语音对话系统（FDSDS）设计的全面基准测试流程，旨在解决现有基准测试缺乏全双工场景指标的问题。该流程利用LLMs、TTS和ASR，评估FDSDS处理用户打断、延迟管理和鲁棒性。通过对Moshi、Freeze-omni和VITA-1.5等开源FDSDS的测试，发现现有模型在频繁打断和噪声环境下仍面临挑战，如未能响应用户打断。

> **摘要翻译:** 全双工语音对话系统（FDSDS）通过允许实时用户打断和回溯，与依赖轮流对话的传统SDS相比，实现了更自然的人机交互。然而，现有基准测试缺乏针对全双工场景的指标，例如评估模型在用户打断期间的性能。在本文中，我们提出了一个利用大型语言模型（LLMs）、文本转语音（TTS）和自动语音识别（ASR）的全面全双工基准测试流程FD-Bench，以解决这一空白。它通过多样化的新指标评估FDSDS处理用户打断、管理延迟以及在挑战性场景中保持鲁棒性的能力。我们将我们的基准测试应用于三个开源FDSDS（Moshi、Freeze-omni和VITA-1.5），使用了超过40小时生成的语音，包括293个模拟对话和1,200次打断。结果显示，所有模型在频繁干扰和嘈杂条件下，例如未能响应用户打断，仍然面临挑战。演示、数据和代码将发布。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [673] [Assessment of Personality Dimensions Across Situations Using Conversational Speech](https://arxiv.org/abs/2507.19137)
> *使用对话语音评估跨情境的人格维度*

*Alice Zhang, Skanda Muralidhar, Daniel Gatica-Perez, Mathew Magimai-Doss* | **Category: eess.AS, cs.AI, cs.SD** | **Updated: 2025-07-25**

**Keywords:** 对话语音, 人格感知, 自动人格感知, 情境化人格, 声学特征

**Comment:** 

> **TL;DR:** 本研究表明，通过对话语音感知的人格特质在不同情境下显著不同，且特定声学特征在不同情境中对不同人格维度（如神经质）的预测能力更强；手工提取的特征优于说话人嵌入。

**AI_Comments:** 本研究的创新之处在于其对情境化人格感知的关注，挑战了以往APP研究中将人格视为静态特质的普遍假设。通过对比中立和压力情境，并发现不同声学特征对特定人格维度的预测效力，为构建更智能、更具情境感知能力的辅助技术提供了重要见解。此外，手工特征优于说话人嵌入的发现也为后续研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 以往的自动人格感知（APP）研究将人格视为与语境无关的静态特质。然而，心理学研究表明，感知到的人格会因语境和情境而异。鉴于用户偏好与自身人格相符的辅助技术，因此需要研究如何更准确地感知情境化的人格。

**Method:** 本研究调查了对话语音与感知人格之间的关系，参与者在两种工作情境（中立访谈和压力客户互动）中进行互动，并分析了其语音特征。

**Result:** 1) 感知人格在不同互动中存在显著差异；2) 在中立互动中，响度、声级和频谱通量特征能指示感知到的外向性、宜人性、责任心和开放性，而在压力情境中，神经质与这些特征相关；3) 手工制作的声学特征和非语言特征在感知人格推断方面优于说话人嵌入；4) 压力互动更能预测神经质，这与现有的心理学研究一致。

**Conclusion:** 通过对话语音感知的人格特质确实会因情境而异，且特定声学特征在不同情境中对不同人格维度的预测能力有所不同。特别是在压力情境下，神经质的预测更为准确，且手工提取的声学和非语言特征在感知人格推断上表现优异。

> **ai_Abstract:** 本研究旨在解决自动人格感知（APP）中人格特质被视为静态的问题，探究对话语音在不同情境下（中立访谈和压力互动）与感知人格的关系。研究发现，感知人格会随情境显著变化，且特定声学特征（如响度、声级、频谱通量）在不同情境下对不同人格维度（如在中立情境中的外向性、宜人性、责任心、开放性，以及在压力情境中的神经质）具有指示作用。值得注意的是，手工提取的声学和非语言特征在人格推断方面优于说话人嵌入，并且压力互动能更有效地预测神经质。

> **摘要翻译:** 以往的研究表明，用户更喜欢与自己个性相符的辅助技术。这激发了人们对自动人格感知（APP）的兴趣，旨在预测个体感知到的人格特质。以前的APP研究将人格视为静态特质，与语境无关。然而，正如心理学研究所示，感知到的人格会因语境和情境而异。在本研究中，我们调查了参与者在两种工作情境（中立访谈和压力客户互动）中对话语音与感知人格之间的关系。我们的主要发现是：1) 感知人格在不同互动中存在显著差异；2) 响度、声级和频谱通量特征在中立互动中指示感知到的外向性、宜人性、责任心和开放性，而神经质在压力情境中与这些特征相关；3) 手工制作的声学特征和非语言特征在感知人格推断方面优于说话人嵌入；4) 压力互动更能预测神经质，这与现有心理学研究一致。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [715] [Should Top-Down Clustering Affect Boundaries in Unsupervised Word Discovery?](https://arxiv.org/abs/2507.19204)
> *自下而上聚类是否应该影响无监督词汇发现中的边界？*

*Simon Malan, Benjamin van Niekerk, Herman Kamper* | **Category: eess.AS, cs.CL, cs.SD** | **Updated: 2025-07-25**

**Keywords:** 无监督词汇发现, 语音分割, 自下而上, 自上而下, 聚类

**Comment:** 5 figures, 5 tables

> **TL;DR:** 在无监督词汇发现中，自下而上和自上而下两种方法在性能上相当，但自下而上方法速度更快。自上而下影响有时有益，但通常简单自下而上方法表现同样好。聚类是两者的限制因素。

**AI_Comments:** 该论文通过实验证明了在无监督词汇发现中，简单的自下而上方法在性能上可以与更复杂的自上而下方法相媲美，并且在效率上具有显著优势，这对于实际应用具有重要意义。同时，指出了当前方法的共同瓶颈——聚类步骤，为未来的研究方向提供了明确的指导，即关注聚类技术和表示学习的改进。

<details>
  <summary>Details</summary>

**Motivation:** 研究无监督语音分割成词单元并聚类以创建词典的问题。先前工作分为自下而上和自上而下两种框架。自上而下方法将聚类词的信息纳入边界选择，但尚不清楚这种信息是否必要以改进分割。

**Method:** 论文比较了两种类似的方法：一种是简单的自下而上策略，它使用相邻自监督特征之间的不相似性预测词边界，然后聚类；另一种是自上而下的系统，它是ES-KMeans动态规划方法的更新版本，迭代使用K-means更新边界。

**Result:** 在五种语言的ZeroSpeech基准测试中，两种方法都取得了可比的最新成果。自下而上系统速度快近五倍。详细分析表明，ES-KMeans的自上而下影响有时有益（取决于候选边界等因素），但在许多情况下，简单的自下而上方法表现同样好。

**Conclusion:** 自下而上方法在无监督词汇发现中与自上而下方法表现相当且速度更快。聚类步骤是两种方法的限制因素。因此，建议未来的工作应关注改进聚类技术和学习更具区分度的类词表示。

> **ai_Abstract:** 本研究探讨了无监督语音中词汇发现的边界确定问题，比较了自下而上和自上而下两种策略。研究发现，虽然自上而下的聚类信息有时能改善边界选择，但在多数情况下，简单的自下而上方法（基于特征不相似性分割后聚类）表现同样出色，且速度快近五倍。论文指出，聚类步骤是当前方法的共同限制，并建议未来研究应侧重于改进聚类技术和学习更具区分度的词表示。

> **摘要翻译:** 我们研究了将未标记语音分割成类词单元并进行聚类以创建词典的问题。先前的工作可以分为两个框架。自下而上方法首先确定边界，然后将固定分割的词聚类形成词典。相反，自上而下方法将聚类词的信息纳入边界选择。然而，尚不清楚自上而下的信息是否是改进分割所必需的。为了探究这一点，我们考察了两种类似的方法，它们的不同之处在于自上而下的聚类是否影响边界选择。我们简单的自下而上策略使用相邻自监督特征之间的不相似性预测词边界，然后将所得片段聚类以构建词典。我们的自上而下系统是ES-KMeans动态规划方法的更新版本，它迭代地使用K-means来更新其边界。在五种语言的ZeroSpeech基准测试中，两种方法都取得了可比的最新成果，其中自下而上系统速度快近五倍。通过详细分析，我们表明ES-KMeans的自上而下影响可能是有益的（取决于候选边界等因素），但在许多情况下，简单的自下而上方法表现同样好。对于这两种方法，我们都表明聚类步骤是一个限制因素。因此，我们建议未来的工作应侧重于改进聚类技术和学习更具区分度的类词表示。项目代码库：https://github.com/s-malan/prom-seg-clus。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [757] [Comparison of Knowledge Distillation Methods for Low-complexity Multi-microphone Speech Enhancement using the FT-JNF Architecture](https://arxiv.org/abs/2507.19208)
> *低复杂度多麦克风语音增强中基于FT-JNF架构的知识蒸馏方法比较*

*Robert Metzger, Mattes Ohlenbusch, Christian Rollwage, Simon Doclo* | **Category: eess.AS** | **Updated: 2025-07-25**

**Keywords:** 知识蒸馏, 语音增强, FT-JNF, 模型压缩, 多麦克风

**Comment:** Accepted at the ITG Conference on Speech Communication 2025 in Berlin

> **TL;DR:** 本研究比较了FT-JNF架构下，多种知识蒸馏方法在降低多麦克风语音增强模型复杂度同时保持性能方面的效果。

**AI_Comments:** 该研究的创新点在于将知识蒸馏技术应用于FT-JNF架构的多麦克风语音增强，有效解决了模型复杂度和部署受限的问题。其重要性在于为资源受限设备上的高性能语音增强提供了可行的解决方案。论文明确展示了KD在压缩模型尺寸方面的显著效果，且性能损失极小，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度神经网络多麦克风语音增强算法复杂度高，难以在资源受限设备上部署；直接减少参数通常会导致性能下降。知识蒸馏是解决此问题的一种有前景的方法。

**Method:** 研究人员在频率-时间联合非线性滤波器（FT-JNF）架构上，评估了五种知识蒸馏方法。这些方法通过直接输出匹配、中间层自相似性以及融合多层损失来训练小型（学生）模型，使其从大型预训练（教师）模型中学习。实验在一个模拟数据集上进行，使用了五麦克风紧凑阵列。

**Result:** 与不使用知识蒸馏的训练相比，三种知识蒸馏方法显著提高了学生模型的性能。学生模型仅使用教师模型25%的参数，在0 dB信噪比下能达到可比的PESQ分数。模型大小可减少高达96%，而PESQ分数仅有微小下降。

**Conclusion:** 知识蒸馏是有效降低FT-JNF架构下多麦克风语音增强模型复杂度的同时保持性能的关键方法。

> **ai_Abstract:** 本论文探讨了在FT-JNF架构下，利用知识蒸馏（KD）技术解决多麦克风语音增强模型在资源受限设备上部署的挑战。研究评估了多种KD方法，旨在从大型教师模型中训练出小型学生模型，同时保持性能。实验结果表明，部分KD方法能显著提升学生模型性能，并实现了高达96%的模型尺寸缩减，而性能（PESQ分数）仅有微小损失，证明了KD在低复杂度语音增强中的有效性。

> **摘要翻译:** 近年来，使用深度神经网络（DNNs）的多麦克风语音增强取得了显著进展。然而，许多提出的基于DNN的语音增强算法无法在硬件资源有限的设备上实现。仅仅通过减少参数来降低此类系统的复杂度通常会导致性能变差。知识蒸馏（KD）是一种有前景的方法，可以在减小DNN模型大小的同时保持性能。在本文中，我们考虑了最近提出的频率-时间联合非线性滤波器（FT-JNF）架构，并研究了几种KD方法，以从大型预训练（教师）模型中训练出更小（学生）模型。通过直接输出匹配、中间层的自相似性以及融合多层损失，评估了五种KD方法。在使用了五麦克风紧凑阵列的模拟数据集上的实验结果表明，与不使用KD的训练相比，三种KD方法显著提高了学生模型的性能。一个只包含教师模型25%参数的学生模型在0 dB信噪比下达到了可比的PESQ分数。此外，模型大小可以减少高达96%，而PESQ分数仅有微小下降。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [799] [Binaural Target Speaker Extraction using HRTFs and a Complex-Valued Neural Network](https://arxiv.org/abs/2507.19369)
> *双耳目标说话人提取：基于HRTF和复值神经网络*

*Yoav Ellinson, Sharon Gannot* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-25**

**Keywords:** 双耳说话人提取, HRTF, 复值神经网络, 说话人分离, 语音处理

**Comment:** 

> **TL;DR:** 该研究提出了一种利用HRTF和复值神经网络进行双耳目标说话人提取的新方法，无需说话人嵌入，在无回响和轻度回响环境下表现出色。

**AI_Comments:** 这篇论文的创新点在于提出了一个无需说话人嵌入的双耳目标说话人提取方法，增强了泛化能力。其核心创新在于采用了直接处理复值STFT的复值神经网络，这与传统方法不同，可能为声学信号处理带来新的视角和性能提升。在保留双耳线索和处理回响方面的表现也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 旨在模仿人类在多说话人同时存在时选择性关注单个说话人的能力。

**Method:** 提出一种新的双耳目标说话人提取方法，利用听者的头部相关传输函数（HRTF）来隔离目标说话人。该方法不依赖于说话人嵌入，因此具有说话人独立性。采用一个完全复值神经网络，直接作用于混合音频信号的复值短时傅里叶变换（STFT）。

**Result:** 在无回响、无噪声场景中，表现出色的提取性能，同时有效保留了目标信号的双耳线索。在轻度回响条件下，改进版本依然稳健，保持了语音清晰度，保留了声源方向性，并同时减少了回响。

**Conclusion:** 该方法能够有效地从混合音频中提取目标说话人，并在不同声学条件下保持鲁棒性，同时保留重要的空间听觉信息。

> **ai_Abstract:** 本文提出了一种新颖的双耳目标说话人提取方法，旨在模仿人类的听觉选择能力。该方法利用HRTF并采用一个直接处理复值STFT的复值神经网络，实现了说话人独立性及跨语言泛化。实验结果表明，该方法在无回响和轻度回响环境下均表现出色，能有效提取目标说话人并保留双耳线索和声源方向性，同时具备降混响能力。

> **摘要翻译:** 在这项工作中，我们旨在模仿人类在多个说话人同时存在的情况下，选择性地关注单个说话人的能力。我们提出了一种新颖的双耳目标说话人提取方法，该方法利用听者的头部相关传输函数（HRTF）来隔离所需说话人。值得注意的是，我们的方法不依赖于说话人嵌入，这使其具有说话人独立性，并能在不同语言的多个语音数据集上实现强大的泛化能力。
我们采用一个完全复值神经网络，直接作用于混合音频信号的复值短时傅里叶变换（STFT）。这与使用频谱图或将STFT的实部和虚部作为单独实值输入进行处理的传统方法有所不同。
我们首先在无回响、无噪声的场景中评估了该方法，结果表明它具有出色的提取性能，同时有效保留了目标信号的双耳线索。然后，我们在轻度回响条件下测试了一个改进变体。该版本在回响环境中保持稳健，保持了语音清晰度，保留了声源方向性，并同时减少了回响。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [20] [A Survey of Event Causality Identification: Taxonomy, Challenges, Assessment, and Prospects](https://arxiv.org/abs/2411.10371)
> *事件因果关系识别综述：分类、挑战、评估与展望*

*Qing Cheng, Zefan Zeng, Xingchen Hu, Yuehang Si, Zhong Liu* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 事件因果关系识别, 自然语言处理, 综述, 深度学习, 大型语言模型

**Comment:** 

> **TL;DR:** 该综述系统地调查了事件因果关系识别（ECI）的基本概念、模型、挑战和未来方向。

**AI_Comments:** 这是一篇全面的综述性论文，对事件因果关系识别（ECI）领域进行了系统性的梳理。其创新之处在于提供了详细的分类法，并对现有模型进行了批判性评估和定量分析。这对于研究人员理解该领域的现状、挑战和未来发展方向具有重要指导意义，尤其是在LLMs背景下对零样本ECI的关注，体现了其前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** 事件因果关系识别（ECI）已成为自然语言处理（NLP）中的一项重要任务，旨在自动检测文本中事件之间的因果关系。

**Method:** 该综述系统地调查了基本概念和模型，发展了一个系统的分类法，并批判性地评估了各种模型。它将ECI模型分为句子级（SECI）和文档级（DECI），并回顾了各种方法，包括基于特征模式匹配、机器学习分类器、深度语义编码、基于提示的微调、因果知识预训练、数据增强策略、事件图推理等。还特别关注了多语言、跨语言和零样本ECI的最新进展。

**Result:** 该综述分析了每种方法的优缺点和未解决的挑战。对四个基准数据集进行了广泛的定量评估，以严格评估各种ECI模型的性能。

**Conclusion:** 讨论了未来的研究方向，并强调了进一步推进该领域的机会。

> **ai_Abstract:** 本综述全面审视了自然语言处理中的事件因果关系识别（ECI）任务。文章定义了ECI的核心概念和问题，并提出了一个系统分类框架，将ECI模型划分为句子级和文档级。它详细回顾了各种识别方法，包括传统方法、深度学习方法以及基于LLM的最新进展，并分析了它们的优缺点及面临的挑战。此外，综述还对主流ECI模型在基准数据集上的性能进行了定量评估，并展望了未来的研究方向。

> **摘要翻译:** 事件因果关系识别（ECI）已成为自然语言处理（NLP）中的一项重要任务，专注于自动检测文本中事件之间的因果关系。这项全面的综述系统地调查了基本概念和模型，发展了一个系统的分类法并批判性地评估了各种模型。我们首先定义了核心概念，形式化了ECI问题，并概述了标准评估协议。我们的分类框架将ECI模型分为两个主要任务：句子级事件因果关系识别（SECI）和文档级事件因果关系识别（DECI）。对于SECI，我们回顾了采用特征模式匹配、机器学习分类器、深度语义编码、基于提示的微调和因果知识预训练以及数据增强策略的模型。对于DECI，我们专注于利用深度语义编码、事件图推理和基于提示的微调的方法。特别关注了多语言和跨语言ECI以及利用大型语言模型（LLMs）的零样本ECI的最新进展。我们分析了每种方法的优缺点和未解决的挑战。对四个基准数据集进行了广泛的定量评估，以严格评估各种ECI模型的性能。最后，我们讨论了未来的研究方向，并强调了进一步推进该领域的机会。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [21] [MedicalBERT: enhancing biomedical natural language processing using pretrained BERT-based model](https://arxiv.org/abs/2507.08013)
> *MedicalBERT：使用预训练BERT模型增强生物医学自然语言处理*

*K. Sahit Reddy, N. Ragavenderan, Vasanth K., Ganesh N. Naik, Vishalakshi Prabhu, Nagaraja G. S* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-25**

**Keywords:** MedicalBERT, 生物医学自然语言处理, 预训练模型, BERT, 迁移学习

**Comment:** 

> **TL;DR:** MedicalBERT是一个针对生物医学领域优化的预训练BERT模型，通过在大型生物医学数据集上训练并使用领域特定词汇，在多项生物医学NLP任务中超越了现有的BERT基模型和通用BERT模型。

**AI_Comments:** MedicalBERT的创新点在于其针对生物医学领域的深度优化，通过在大规模生物医学语料库上进行预训练并引入领域特定词汇，有效解决了现有通用模型在处理专业生物医学文本时的局限性。其重要性体现在为生物医学NLP任务提供了更高效、更准确的工具，尤其是在命名实体识别和关系提取等关键任务上表现出色。这对于加速生物医学研究和临床应用具有重要意义。该研究也进一步验证了迁移学习在特定领域NLP任务中的强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的预训练语言模型（如BERT、RoBERTa、T5、GPT）在理解复杂文本方面表现出色，但生物医学文献的领域特定术语对这些模型构成了挑战。Word2Vec和Bi-LSTM无法完全解决这些问题，而GPT和T5虽然能捕捉上下文，但在需要双向理解的任务中表现不足。因此，需要一个能更好处理生物医学领域特定术语和任务的模型。

**Method:** 本研究提出了MedicalBERT，这是一个在大型生物医学数据集上训练的预训练BERT模型，并配备了领域特定词汇，以增强对生物医学术语的理解。MedicalBERT模型进一步优化和微调，以解决各种任务，包括命名实体识别、关系提取、问答、句子相似性和文档分类。使用F1分数、准确性和Pearson相关系数等性能指标来展示模型效率，并与其他基于BERT的模型（如BioBERT、SciBERT和ClinicalBERT）进行比较。

**Result:** MedicalBERT在大多数基准测试中优于BioBERT、SciBERT和ClinicalBERT等模型，并且在所有评估任务中，平均比通用BERT模型高出5.67%。

**Conclusion:** 本研究强调了利用预训练BERT模型进行医学NLP任务的潜力，证明了迁移学习技术在捕获领域特定信息方面的有效性。

> **ai_Abstract:** 本文提出了MedicalBERT，一个专门为生物医学领域设计的预训练BERT模型。该模型通过在大型生物医学数据集上训练并整合领域特定词汇来增强对生物医学术语的理解。MedicalBERT针对命名实体识别、关系提取、问答、句子相似性和文档分类等多项任务进行了优化和微调。实验结果表明，MedicalBERT在多数基准测试中优于BioBERT、SciBERT和ClinicalBERT等现有BERT基模型，并且在所有评估任务上平均比通用BERT模型性能提升5.67%，证明了预训练BERT模型和迁移学习在医学NLP任务中的有效性。

> **摘要翻译:** 自然语言处理（NLP）的最新进展得益于BERT、RoBERTa、T5和GPT等预训练语言模型。这些模型在理解复杂文本方面表现出色，但生物医学文献及其领域特定术语带来了挑战，这是Word2Vec和双向长短期记忆（Bi-LSTM）等模型无法完全解决的。GPT和T5尽管能捕捉上下文，但在需要双向理解的任务中表现不足，这与BERT不同。为了解决这个问题，我们提出了MedicalBERT，一个在大型生物医学数据集上训练并配备领域特定词汇的预训练BERT模型，它增强了对生物医学术语的理解。MedicalBERT模型进一步优化和微调，以解决各种任务，包括命名实体识别、关系提取、问答、句子相似性和文档分类。我们采用F1分数、准确性和Pearson相关系数等性能指标来展示我们模型的效率，并与BioBERT、SciBERT和ClinicalBERT等其他基于BERT的模型进行比较。MedicalBERT在大多数基准测试中优于这些模型，并且在所有评估任务中，平均比通用BERT模型高出5.67%。这项工作还强调了利用预训练BERT模型进行医学NLP任务的潜力，证明了迁移学习技术在捕获领域特定信息方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [27] [A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation](https://arxiv.org/abs/2507.18973)
> *一个工具箱，而非一把锤子——Multi-TAG：通过多工具聚合扩展数学推理能力*

*Bohan Yao, Vikas Yadav* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-25**

**Keywords:** Multi-TAG, 大型语言模型, 数学推理, 工具聚合, 免微调

**Comment:** 21 pages, 3 figures

> **TL;DR:** Multi-TAG是一个免微调、仅推理的框架，通过同时调用和聚合多个工具来显著提升大型语言模型在复杂数学推理任务上的表现。

**AI_Comments:** Multi-TAG的创新之处在于其“多工具聚合”范式，而非传统的单工具调用，这使其能更好地处理复杂的多步骤数学推理。其“免微调、仅推理”的特性极大地提高了框架的普适性和易用性，尤其对于大型或闭源模型而言，这是一个重要的优势。该研究为LLM在更复杂、更精确的推理任务中的应用开辟了新路径。

<details>
  <summary>Details</summary>

**Motivation:** 现有的工具增强型大型语言模型在处理需要多步骤精确推理的复杂数学问题时表现不佳，因为它们通常在每个推理步骤只选择和调用单一工具。

**Method:** 本文提出了Multi-TAG（Multi-Tool AGgregation-based）框架。它引导大型语言模型在每个推理步骤中并发调用多个工具，然后聚合这些多样化的输出以验证和完善推理过程，从而提高解决方案的鲁棒性和准确性。Multi-TAG是一个免微调、仅推理的框架，适用于任何大型语言模型骨干。

**Result:** Multi-TAG在MATH500、AIME、AMC和OlympiadBench这四个具有挑战性的基准测试中进行了评估。在开源和闭源的大型语言模型骨干上，Multi-TAG始终显著优于最先进的基线方法，平均性能提升了6.0%至7.5%。

**Conclusion:** Multi-TAG通过其多工具聚合方法，有效解决了大型语言模型在复杂数学推理中单工具调用的局限性，显著提升了其在该领域的性能和适用性。

> **ai_Abstract:** 本文提出了Multi-TAG框架，旨在解决现有工具增强型大型语言模型在复杂数学推理中单工具调用所面临的挑战。Multi-TAG通过引导LLM在每个推理步骤中并发调用多个工具，并聚合其输出以验证和完善推理，从而提升解决方案的鲁棒性和准确性。作为一个免微调、仅推理的框架，Multi-TAG适用于各种LLM。实验证明，Multi-TAG在多个复杂数学基准测试中显著优于现有SOTA方法，平均性能提升6.0%至7.5%。

> **摘要翻译:** 通过外部工具增强大型语言模型（LLMs）是开发高性能数学推理系统的一个有前景的方向。先前的工具增强方法通常会微调LLM，使其在每个推理步骤中选择并调用单个工具，并在GSM8K等简单数学推理基准测试中显示出有希望的结果。然而，这些方法在需要多步骤精确推理的更复杂数学问题上表现不佳。为了解决这一限制，我们提出了Multi-TAG，一个基于多工具聚合（Multi-Tool AGgregation）的框架。Multi-TAG不依赖于单一工具，而是引导LLM在每个推理步骤中并发调用多个工具。然后，它聚合这些多样化的输出，以验证和完善推理过程，从而增强解决方案的鲁棒性和准确性。值得注意的是，Multi-TAG是一个免微调、仅推理的框架，使其可以轻松应用于任何LLM骨干，包括计算成本高昂难以微调的大型开源模型和无法使用自定义配方进行微调的专有前沿模型。我们在四个具有挑战性的基准测试上评估了Multi-TAG：MATH500、AIME、AMC和OlympiadBench。在开源和闭源LLM骨干上，Multi-TAG始终显著且大幅优于最先进的基线方法，平均比最先进的基线方法提高了6.0%到7.5%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [28] [Multilingual LLMs Are Not Multilingual Thinkers: Evidence from Hindi Analogy Evaluation](https://arxiv.org/abs/2507.13238)
> *多语言大型语言模型并非多语言思考者：来自印地语类比评估的证据*

*Ashray Gupta, Rohan Joseph, Sunny Rai* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 多语言LLM, 印地语, 类比推理, HATS, 语言泛化

**Comment:** 

> **TL;DR:** 本研究引入了新的印地语类比测试集（HATS），发现多语言大型语言模型在印地语类比推理方面表现不佳，且英语提示效果最好，揭示了多语言LLM在非英语语言中推理能力的局限性。

**AI_Comments:** 本论文的创新之处在于构建了一个专门的印地语类比测试集（HATS），这对于评估多语言LLM在非英语语言中的推理能力至关重要。研究发现多语言LLM在印地语类比推理中仍依赖英语提示获得最佳表现，这揭示了当前模型在跨语言泛化方面存在的局限性，具有重要的指导意义。提出的基于基础的思维链方法也为提升模型性能提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在英语推理能力方面已被广泛评估，但其在印度语言中的能力研究不足，这限制了我们对这些模型能否跨语言泛化的理解。本研究旨在填补这一空白。

**Method:** 研究引入了一个新的印地语类比测试集（HATS），包含405个来自印度政府考试的多项选择题。研究使用不同的提示策略对最先进的多语言大型语言模型进行了基准测试，并引入了一种利用类比推理认知理论的基于基础的思维链（Chain of Thought）方法。

**Result:** 实验表明，无论采用何种提示策略，模型在使用英语提示时表现最佳。研究引入的基于基础的思维链方法提高了模型在印地语类比问题上的性能。

**Conclusion:** 本研究的测试集解决了评估大型语言模型在印地语推理能力方面关键资源缺乏的问题，揭示了多语言LLM在非英语语言中推理能力的局限性。

> **ai_Abstract:** 本研究旨在弥补多语言大型语言模型在印度语言（特别是印地语）推理能力评估方面的空白。为此，研究引入了一个新的印地语类比测试集（HATS），包含405个多项选择题。通过对最先进的多语言LLM进行基准测试，并引入一种基于认知理论的思维链方法，研究发现该方法能提升模型在印地语类比问题上的表现。然而，实验结果显示，无论采用何种提示策略，模型在使用英语提示时表现最佳，这表明当前多语言LLM在非英语语言中的推理能力仍有待提高。HATS的推出为评估LLM在印地语中的推理能力提供了重要的资源。

> **摘要翻译:** 类比测试模型推断概念之间隐含关系的能力，使其成为评估推理能力的关键基准。虽然大型语言模型（LLM）在英语推理方面得到了广泛评估，但它们在印度语言中的能力仍未得到充分研究，这限制了我们对这些模型能否跨语言泛化的理解。为了弥补这一空白，我们引入了一个新的印地语类比测试集（HATS），包含405个来自印度政府考试的多项选择题。我们使用各种提示策略对最先进的多语言大型语言模型进行了基准测试，并引入了一种利用类比推理认知理论的基于基础的思维链方法。这种方法提高了模型在印地语类比问题上的性能。我们的实验表明，无论采用何种提示策略，模型在使用英语提示时表现最佳。我们的测试集解决了评估LLM在印地语推理能力方面关键资源缺乏的问题。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [31] [GrAInS: Gradient-based Attribution for Inference-Time Steering of LLMs and VLMs](https://arxiv.org/abs/2507.18043)
> *GrAInS：基于梯度的LLM和VLM推理时操纵归因*

*Duy Nguyen, Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal* | **Category: cs.CL, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 推理时操纵, 大型语言模型, 视觉语言模型, 梯度归因, 模型控制

**Comment:** 21 pages. Code: https://github.com/duykhuongnguyen/GrAInS

> **TL;DR:** GrAInS是一种新的推理时操纵方法，通过使用基于梯度的归因来识别关键令牌，并构建方向性操纵向量，从而实现对LLM和VLM行为的精细、可解释控制，无需微调，并显著优于现有基线。

**AI_Comments:** GrAInS的创新之处在于其将基于梯度的归因（特别是集成梯度）应用于推理时操纵，以识别对模型输出有关键影响的单个令牌。这种方法实现了比现有固定向量方法更精细、更具解释性的控制。其在多模态设置下的有效性也值得关注，解决了视觉和文本输入贡献不均的问题。该方法提供了一种轻量级且高效的模型行为调整方案，避免了昂贵的微调过程，对于快速迭代和部署AI模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的推理时操纵方法依赖于固定的全局干预向量，忽视了单个输入令牌的因果影响，并且未能利用模型logits中信息丰富的梯度，尤其是在视觉和文本输入贡献不均匀的多模态设置中。

**Method:** GrAInS使用通过集成梯度进行的对比式、基于梯度的归因，以识别对偏好和非偏好输出贡献最大的前k个最有影响力的令牌（包括正向和负向归因）。然后，这些令牌被用于构建捕获从不良行为到理想行为语义转变的方向性操纵向量。在推理过程中，GrAInS根据令牌级别的归因信号调整Transformer层的隐藏激活，并对激活进行归一化以保持表示尺度。

**Result:** GrAInS在TruthfulQA上使Llama-3.1-8B的准确率提高了13.22%；使用LLaVA-1.6-7B将MMHal-Bench上的幻觉率从0.624降低到0.514；将SPA-VL上的对齐胜率提高了8.11%，同时保持了模型的流畅性和通用能力。

**Conclusion:** GrAInS提供了一种无需重新训练或辅助监督的、细粒度、可解释和模块化的模型行为控制方法，并在经验上持续优于微调和现有操纵基线。

> **ai_Abstract:** GrAInS是一种新颖的推理时操纵方法，旨在解决现有方法在LLM和VLM中存在的局限性，如依赖固定全局向量和忽视令牌因果影响。该方法通过基于梯度的归因识别关键令牌，并构建方向性操纵向量，以实现对模型行为的细粒度、可解释控制。GrAInS在语言和视觉-语言任务中均表现出色，经验结果表明其在准确性、幻觉率降低和对齐方面显著优于传统微调和现有操纵基线，且无需模型重训练。

> **摘要翻译:** 推理时操纵方法通过在测试时修改内部激活而不更新模型权重，为微调大型语言模型（LLM）和视觉语言模型（VLM）提供了一种轻量级的替代方案。然而，大多数现有方法依赖于固定的全局干预向量，忽视了单个输入令牌的因果影响，并且未能利用模型logits中信息丰富的梯度，尤其是在视觉和文本输入贡献不均匀的多模态设置中。为了解决这些限制，我们引入了GrAInS，这是一种推理时操纵方法，适用于仅语言模型和视觉语言模型及任务。GrAInS通过集成梯度使用对比的、基于梯度的归因来识别前k个最有影响力的令牌，这些令牌根据其对偏好与非偏好输出的贡献进行正向和负向归因。然后，这些令牌被用于构建方向性操纵向量，以捕捉从不良行为到理想行为的语义转变。在推理过程中，GrAInS根据令牌级别的归因信号调整Transformer层的隐藏激活，并对激活进行归一化以保持表示尺度。这使得对模型行为的控制更加细粒度、可解释和模块化，无需重新训练或辅助监督。经验上，GrAInS始终优于微调和现有操纵基线：它在使用Llama-3.1-8B的TruthfulQA上实现了13.22%的准确率提升，使用LLaVA-1.6-7B将MMHal-Bench上的幻觉率从0.624降低到0.514，并将SPA-VL上的对齐胜率提高了8.11%，同时保持了模型的流畅性和通用能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [35] [Causally Testing Gender Bias in LLMs: A Case Study on Occupational Bias](https://arxiv.org/abs/2212.10678)
> *因果性测试大型语言模型中的性别偏见：一项关于职业偏见的案例研究*

*Yuen Chen, Vethavikashini Chithrra Raghuram, Justus Mattern, Rada Mihalcea, Zhijing Jin* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 性别偏见, 大型语言模型, 因果测试, 职业偏见, OccuGender

**Comment:** 

> **TL;DR:** 本文提出了一种测量生成式语言模型偏见的因果公式，并基于此设计了基准OccuGender来测试大型语言模型中的职业性别偏见。结果显示模型存在显著偏见，并探讨了偏见缓解策略。

**AI_Comments:** 该论文的创新点在于提出了一个因果框架来量化LLM中的偏见，并创建了一个具体的基准OccuGender来测试职业性别偏见，这对于理解和缓解LLM中的社会偏见具有重要意义。其方法论严谨，结果具有实践指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）生成的文本已显示出对不同人群存在各种有害的、类人的偏见，这促使了旨在理解和衡量此类影响的研究。

**Method:** 本文引入了一种用于生成式语言模型偏见测量的因果公式，并基于此理论基础，列出了一系列设计稳健偏见基准的期望。随后，提出了一个名为OccuGender的基准，并附带偏见测量程序，以调查职业性别偏见。研究测试了包括Llama、Mistral及其指令调优版本在内的多个最先进的开源LLMs。

**Result:** 测试结果表明，这些模型表现出显著的职业性别偏见。

**Conclusion:** 论文讨论了偏见缓解的提示策略，并扩展了因果公式以说明该框架的通用性。

> **ai_Abstract:** 该研究提出了一种衡量生成式语言模型偏见的因果公式，并基于此构建了一个名为OccuGender的基准，用于检测大型语言模型中的职业性别偏见。通过对Llama和Mistral等主流LLM的测试，发现它们普遍存在显著的职业性别偏见。论文还探讨了偏见缓解的提示策略，并论证了该因果框架的通用性。

> **摘要翻译:** 大型语言模型（LLMs）生成的文本已显示出对不同人群存在各种有害的、类人的偏见。这些发现促使了旨在理解和衡量此类影响的研究。本文引入了一种用于生成式语言模型偏见测量的因果公式。基于这一理论基础，我们列出了一系列设计稳健偏见基准的期望。随后，我们提出了一个名为OccuGender的基准，并附带偏见测量程序，以调查职业性别偏见。我们测试了包括Llama、Mistral及其指令调优版本在内的多个最先进的开源LLMs在OccuGender上的表现。结果显示这些模型表现出显著的职业性别偏见。最后，我们讨论了偏见缓解的提示策略，并扩展了我们的因果公式以说明该框架的通用性。我们的代码和数据可在https://github.com/chenyuen0103/gender-bias 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [49] [Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters](https://arxiv.org/abs/2507.13618)
> *Seed-X：构建强大的7B参数多语言翻译大型语言模型*

*Shanbo Cheng, Yu Bao, Qian Cao, Luyang Huang, Liyan Kang, Zhicheng Liu, Yu Lu, Wenhao Zhu, Jingwen Chen, Zhichao Huang, Tao Li, Yifu Li, Huiying Lin, Sitong Liu, Ningxin Peng, Shuaijie She, Lu Xu, Nuo Xu, Sen Yang, Runsheng Yu, Yiming Yu, Liehao Zou, Hang Li, Lu Lu, Yuxuan Wang, Yonghui Wu* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-25**

**Keywords:** 多语言翻译, 大型语言模型, Seed-X, 思维链, 强化学习

**Comment:** 

> **TL;DR:** Seed-X是一个7B参数的开源多语言翻译LLM，通过多样化数据预训练、思维链微调和强化学习，在28种语言上实现了与领先闭源模型相当的性能，并优于更大的开源模型。

**AI_Comments:** Seed-X的创新之处在于以相对较小的7B参数规模实现了与顶尖闭源模型相媲美的多语言翻译性能，并通过结合CoT和RL来提高泛化能力。其开源性质对于推动多语言翻译研究和应用具有重要意义，提供了一个高效且高质量的基线模型。

<details>
  <summary>Details</summary>

**Motivation:** 多语言翻译对于大型语言模型（LLMs）来说是一项具有挑战性的任务，因为它们难以处理复杂的语言模式和自动化翻译中出现的生硬翻译。

**Method:** Seed-X的基础模型在包含28种语言的单语和双语内容的多元高质量数据集上进行预训练。指令模型通过思维链（CoT）推理进行微调以进行翻译，并通过强化学习（RL）进一步增强，以在不同的语言对之间实现更好的泛化。

**Result:** Seed-X在28种语言上实现了与领先的闭源模型（包括Gemini-2.5和GPT-4o）相当的性能，并且在自动评估指标和人工评估中都显著优于更大的开源模型。

**Conclusion:** Seed-X成功地将7B参数的LLM的翻译能力推向了极限，并在多语言翻译方面取得了与顶尖闭源模型相媲美的性能，同时开源了模型参数以促进翻译研究和应用。

> **ai_Abstract:** 本文介绍了Seed-X，一个7B参数的开源多语言翻译大型语言模型系列。该模型通过在包含28种语言的多元高质量数据集上进行预训练，并结合思维链（CoT）推理微调和强化学习（RL）增强，显著提升了翻译能力。Seed-X在性能上与Gemini-2.5和GPT-4o等领先的闭源模型相当，并超越了更大的开源模型，其参数已公开，旨在推动翻译研究。

> **摘要翻译:** 多语言翻译对于大型语言模型（LLMs）来说是一项具有挑战性的任务，因为它们难以处理复杂的语言模式和自动化翻译中出现的生硬翻译。在本文中，我们介绍了Seed-X，一个包含指令模型和推理模型的开源LLM家族，它以7B的参数规模将翻译能力推向了极限。基础模型在包含28种语言的单语和双语内容的多元高质量数据集上进行预训练，充分利用了多语言数据的潜力。指令模型通过思维链（CoT）推理进行微调以进行翻译，并通过强化学习（RL）进一步增强，以在不同的语言对之间实现更好的泛化。Seed-X在28种语言上实现了与领先的闭源模型（包括Gemini-2.5和GPT-4o）相当的性能，并且在自动评估指标和人工评估中都显著优于更大的开源模型。我们通过优化过程分享了最佳实践，并公开了参数以促进翻译研究和应用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [53] [Privacy-Preserving Synthetic Review Generation with Diverse Writing Styles Using LLMs](https://arxiv.org/abs/2507.18055)
> *使用大型语言模型生成具有多样化写作风格的隐私保护合成评论*

*Tevin Atwal, Chan Nam Tieu, Yefeng Yuan, Zhan Shi, Yuhong Liu, Liang Cheng* | **Category: cs.CL, cs.CR, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 合成数据, 隐私保护, 大型语言模型, 数据多样性, 提示工程

**Comment:** 

> **TL;DR:** 本研究评估并改进了LLM生成合成数据的多样性和隐私保护能力。

**AI_Comments:** 该论文的创新之处在于其提出了评估合成数据多样性和隐私的综合指标体系，并针对LLM生成合成数据的不足，提出了一种有效的基于提示的改进方法。这对于推动安全、高质量合成数据在实际应用中的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）生成的合成数据在数据驱动应用中带来了机遇，但其多样性和隐私风险尚未得到充分探索。现有LLM在生成多样化且保护隐私的合成数据方面存在显著局限性。

**Method:** 本文提出了一套全面的指标，用于定量评估LLM生成合成数据集的多样性（语言表达、情感、用户视角）和隐私（再识别风险、风格异常值）。基于评估结果，提出了一种基于提示的方法，以增强合成评论的多样性，同时保护评论者隐私。

**Result:** 实验结果表明，LLMs在生成多样化和隐私保护合成数据方面的能力存在显著局限性。

**Conclusion:** 通过提出的基于提示的方法，可以有效增强合成评论的多样性，同时保护评论者隐私，从而克服LLM在生成此类数据方面的现有局限性。

> **ai_Abstract:** 本研究关注LLM生成合成数据的多样性和隐私问题，提出了一套全面的评估指标来量化这些方面。实验发现当前LLM在这方面存在局限性。为解决此问题，研究提出了一种基于提示的方法，旨在提高合成评论的多样性并保护用户隐私。

> **摘要翻译:** 大型语言模型（LLMs）生成的合成数据日益增长的使用为数据驱动应用带来了机遇和挑战。虽然合成数据为真实世界数据提供了成本效益高、可扩展的替代方案，以促进模型训练，但其多样性和隐私风险仍未得到充分探索。本文专注于基于文本的合成数据，提出了一套全面的指标，用于定量评估由几种最先进的LLMs生成的合成数据集的多样性（即语言表达、情感和用户视角）和隐私（即再识别风险和风格异常值）。实验结果揭示了LLMs在生成多样化和隐私保护合成数据方面的能力存在显著局限性。在评估结果的指导下，提出了一种基于提示的方法，以增强合成评论的多样性，同时保护评论者隐私。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [68] [Arg-LLaDA: Argument Summarization via Large Language Diffusion Models and Sufficiency-Aware Refinement](https://arxiv.org/abs/2507.19081)
> *Arg-LLaDA：通过大型语言扩散模型和充分性感知细化进行论点摘要*

*Hao Li, Yizheng Sun, Viktor Schlegel, Kailai Yang, Riza Batista-Navarro, Goran Nenadic* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 论点摘要, 大型语言模型, 扩散模型, 迭代生成, 充分性感知

**Comment:** Preprint

> **TL;DR:** Arg-LLaDA是一个新的大型语言扩散框架，通过迭代细化和充分性检查来改进论点摘要生成，超越了现有SOTA方法。

**AI_Comments:** Arg-LLaDA的创新之处在于其迭代的扩散框架，结合了充分性感知机制，解决了论点摘要生成中长期存在的忠实度和连贯性问题。这种迭代细化方法在处理复杂、多视角辩论的摘要生成方面具有重要意义，超越了传统单次生成模型的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的论点摘要生成方法主要依赖单次生成，对事实纠正或结构细化的支持有限，导致生成阶段探索不足。

**Method:** 引入Arg-LLaDA，一个新颖的大型语言扩散框架，通过充分性引导的重新掩码和再生来迭代改进摘要。该方法结合灵活的掩码控制器和充分性检查模块，以识别和修改不支持、冗余或不完整的文本段。

**Result:** 在两个基准数据集上的实证结果表明，Arg-LLaDA在10个自动评估指标中的7个上超越了最先进的基线。此外，人工评估显示在核心维度（覆盖范围、忠实性和简洁性）上都有显著改进。

**Conclusion:** Arg-LLaDA的迭代、充分性感知生成策略被证明是有效的，能够生成更忠实、简洁和连贯的论点摘要。

> **ai_Abstract:** 本文提出了Arg-LLaDA，一个基于大型语言扩散模型的论点摘要新框架。该框架通过迭代的充分性引导重新掩码和再生机制，解决了现有单次生成方法在事实纠正和结构细化方面的不足。Arg-LLaDA结合了掩码控制器和充分性检查模块，以提高摘要的忠实性、简洁性和连贯性。实验结果和人工评估均表明，Arg-LLaDA在多个指标上显著优于现有SOTA方法，验证了其迭代生成策略的有效性。

> **摘要翻译:** 论点摘要旨在生成复杂、多视角辩论的简洁、结构化表示。尽管最近的工作在论证组件的识别和聚类方面取得了进展，但生成阶段仍未得到充分探索。现有方法通常依赖单次生成，对事实纠正或结构细化的支持有限。为了解决这一差距，我们引入了Arg-LLaDA，一个新颖的大型语言扩散框架，通过充分性引导的重新掩码和再生来迭代改进摘要。我们的方法结合了灵活的掩码控制器和充分性检查模块，以识别和修改不支持、冗余或不完整的文本段，从而产生更忠实、简洁和连贯的输出。在两个基准数据集上的实证结果表明，Arg-LLaDA在10个自动评估指标中的7个上超越了最先进的基线。此外，人工评估显示在核心维度（覆盖范围、忠实性和简洁性）上都有显著改进，验证了我们迭代的、充分性感知生成策略的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [73] [Synthetic Data Generation for Phrase Break Prediction with Large Language Model](https://arxiv.org/abs/2507.18044)
> *基于大型语言模型的短语停顿预测合成数据生成*

*Hoyeon Lee, Sejung Son, Ye-Eun Kang, Jong-Hwan Kim* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 短语停顿预测, 合成数据生成, 大型语言模型, 语音技术, 数据标注

**Comment:** Accepted at Interspeech 2025

> **TL;DR:** 本文提出利用大型语言模型（LLM）生成合成数据，以解决短语停顿预测中对大量人工标注的依赖问题，并证明其在多语言环境下的有效性。

**AI_Comments:** 该论文的创新之处在于将大型语言模型应用于语音领域的合成数据生成，特别是在短语停顿预测任务中。这对于解决传统方法中数据标注成本高、获取困难的问题具有重要意义。其贡献在于证明了LLM在生成高质量、可替代人工标注的合成数据方面的潜力，为未来语音技术的发展提供了新的思路，尤其是在资源受限的语言或领域。

<details>
  <summary>Details</summary>

**Motivation:** 当前的短语停顿预测方法严重依赖大量人工标注数据，导致高昂的成本和精力消耗。此外，语音领域固有的变异性使得获取高质量、一致的数据更加复杂。受大型语言模型在自然语言处理领域解决数据挑战的成功启发，本文旨在利用LLM克服这些挑战。

**Method:** 本文探索利用大型语言模型（LLM）生成合成短语停顿标注数据。通过与传统标注方法进行比较，并在多种语言中评估其有效性，以解决人工标注和语音相关任务的数据挑战。

**Result:** 研究结果表明，基于LLM的合成数据生成有效缓解了短语停顿预测中的数据挑战。

**Conclusion:** 本文的结论是，基于大型语言模型的合成数据生成可以有效解决短语停顿预测中的数据挑战，并突出了LLM作为语音领域可行解决方案的潜力。

> **ai_Abstract:** 本文提出了一种利用大型语言模型（LLM）生成合成数据的方法，以解决短语停顿预测中对大量人工标注的依赖问题。通过与传统标注方法进行比较并在多种语言中评估，研究发现LLM生成的合成数据能有效缓解数据获取的挑战，并展现了LLM在语音领域应用的潜力。

> **摘要翻译:** 当前短语停顿预测方法解决了文本到语音系统中的关键韵律方面，但严重依赖于来自音频或文本的大量人工标注，这带来了显著的人力投入和成本。语音领域固有的由语音因素驱动的变异性进一步使获取一致、高质量的数据复杂化。最近，大型语言模型（LLM）在通过生成定制的合成数据同时减少人工标注需求方面，在解决自然语言处理中的数据挑战方面取得了成功。受此启发，我们探索利用LLM生成合成短语停顿标注，通过与传统标注进行比较并在多种语言中评估其有效性，解决了人工标注和语音相关任务的挑战。我们的研究结果表明，基于LLM的合成数据生成有效缓解了短语停顿预测中的数据挑战，并突出了LLM作为语音领域可行解决方案的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [77] [Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models](https://arxiv.org/abs/2507.14241)
> *Promptomatix：一个大型语言模型的自动提示优化框架*

*Rithesh Murthy, Ming Zhu, Liangwei Yang, Jielin Qiu, Juntao Tan, Shelby Heinecke, Caiming Xiong, Silvio Savarese, Huan Wang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 提示优化, 大型语言模型, 自动化框架, 提示工程, Promptomatix

**Comment:** 

> **TL;DR:** Promptomatix是一个自动提示优化框架，可将自然语言任务描述转换为高质量提示，无需手动调优，且性能优于现有库。

**AI_Comments:** 该论文提出了一种创新的自动提示优化框架Promptomatix，解决了当前LLM提示工程中手动、低效和非专家难以操作的问题。其亮点在于无需人工干预和领域知识即可生成高质量提示，并且通过模块化设计和成本感知优化实现了可伸缩性和效率，对推动LLM的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型（LLMs）的提示工程是手动、不一致且非专家难以操作的，限制了LLMs的最佳表现。

**Method:** Promptomatix通过分析用户意图、生成合成训练数据、选择提示策略并使用成本感知目标优化提示来工作。它支持基于元提示的轻量级优化器和DSPy驱动的编译器，并采用模块化设计。

**Result:** Promptomatix在5个任务类别中表现出与现有库相当或或更优的性能，同时减少了提示长度和计算开销，使提示优化更具可伸缩性和效率。

**Conclusion:** Promptomatix提供了一个自动化、高效且可扩展的提示优化解决方案，使非专家也能生成高质量提示，从而提升LLMs的性能。

> **ai_Abstract:** Promptomatix是一个新颖的自动提示优化框架，旨在解决大型语言模型（LLMs）手动提示工程的痛点。它通过分析用户意图、生成合成数据和智能选择优化策略，将自然语言任务描述转化为高质量提示。该框架支持多种优化器，并采用模块化设计。实验证明，Promptomatix在性能上优于或媲美现有方法，且能有效降低提示复杂度和计算成本，实现了提示优化的自动化、高效和可扩展性。

> **摘要翻译:** 大型语言模型（LLMs）在精心设计的提示下表现最佳，然而提示工程仍然是手动的、不一致的，并且非专业人士难以接触。我们引入了Promptomatix，一个自动提示优化框架，它将自然语言任务描述转换为高质量提示，无需手动调优或领域专业知识。Promptomatix支持轻量级的基于元提示的优化器和DSPy驱动的编译器，其模块化设计使其未来可扩展到更高级的框架。该系统分析用户意图，生成合成训练数据，选择提示策略，并使用成本感知目标优化提示。在五类任务中进行评估，Promptomatix与现有库相比，实现了竞争性或更优的性能，同时减少了提示长度和计算开销，使提示优化具有可伸缩性和效率。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [96] [A New Pair of GloVes](https://arxiv.org/abs/2507.18103)
> *一副新GloVe模型*

*Riley Carlson, John Bauer, Christopher D. Manning* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** GloVe, 词嵌入, 自然语言处理, NER, 语言演变

**Comment:** 

> **TL;DR:** 该报告介绍了2024年更新的GloVe词向量模型，这些模型在更现代的数据集上训练，并针对文化和语言演变进行了优化，在最新命名实体识别（NER）任务上表现出改进。

**AI_Comments:** 该论文解决了词嵌入模型随时间推移而过时的问题，并通过更新数据和提供详细文档来改进现有模型，这对于确保NLP应用的持续有效性至关重要。其创新点在于对“时间依赖”数据的性能提升，这在快速变化的语言环境中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 2014年的原始GloVe模型已被广泛使用，但语言和世界不断演变，现有模型需要更新以适应当前用法。此外，2014年的模型缺乏详细的数据版本和预处理文档，新模型旨在纠正这一不足。

**Method:** 作者使用维基百科（Wikipedia）、Gigaword和Dolma数据集的一个子集训练了两组新的词嵌入模型。通过词汇比较、直接测试和命名实体识别（NER）任务进行评估。

**Result:** 2024年的GloVe向量包含了新的文化和语言相关词汇；在类比和相似性等结构化任务上表现相当；在最近的、时间依赖的NER数据集（如非西方新闻专线数据）上表现出改进的性能。

**Conclusion:** 2024年的新GloVe模型成功地整合了现代词汇，保持了在结构化任务上的性能，并显著提升了在当代、时间敏感的命名实体识别任务上的表现，同时提供了详细的文档。

> **ai_Abstract:** 本报告介绍了2024年更新的GloVe词向量模型。鉴于语言和世界的演变以及2014年原始模型文档的不足，研究人员使用维基百科、Gigaword和Dolma的子集训练了新模型。评估结果显示，新模型不仅包含了新的文化和语言相关词汇，在结构化任务上与旧模型性能相当，还在处理近期、时间敏感的命名实体识别任务（特别是针对非西方新闻专线数据）时展现出显著的性能提升。

> **摘要翻译:** 本报告记录、描述并评估了新的2024年英语GloVe（词表示全局向量）模型。尽管2014年构建的原始GloVe模型已被广泛使用并被证明有用，但语言和世界仍在不断演变，我们认为当前的使用可以从更新的模型中受益。此外，2014年的模型没有仔细记录所使用的确切数据版本和预处理方式，我们通过记录这些新模型纠正了这一点。我们使用维基百科、Gigaword和Dolma的一个子集训练了两组词嵌入。通过词汇比较、直接测试和NER任务的评估表明，2024年的向量包含了新的文化和语言相关词汇，在类比和相似性等结构化任务上表现相当，并在最近的、时间依赖的NER数据集（如非西方新闻专线数据）上表现出改进的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [105] [3LM: Bridging Arabic, STEM, and Code through Benchmarking](https://arxiv.org/abs/2507.15850)
> *3LM：通过基准测试连接阿拉伯语、STEM 和代码*

*Basma El Amel Boussaha, Leen AlQadi, Mugariya Farooq, Shaikha Alsuwaidi, Giulia Campesan, Ahmed Alzubaidi, Mohammed Alyafeai, Hakim Hacid* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 阿拉伯语LLM, 基准测试, STEM, 代码, 3LM

**Comment:** 

> **TL;DR:** 3LM是一个新的阿拉伯语LLM基准套件，涵盖STEM和代码领域，旨在弥补现有阿拉伯语基准的空白。

**AI_Comments:** 本文的创新之处在于填补了阿拉伯语LLM在STEM和代码领域基准测试的显著空白。通过创建特定领域的、高质量的基准，它为阿拉伯语LLM在这些日益重要的应用领域的发展和评估提供了关键工具，具有重要的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管阿拉伯语是世界上使用最广泛的语言之一，但针对阿拉伯语的大型语言模型（LLM）的开发和评估工作相对有限。现有的阿拉伯语基准主要集中在语言、文化或宗教内容，在STEM和代码等领域存在显著空白，而这些领域对于现实世界的LLM应用越来越重要。

**Method:** 该研究提出了3LM，一个包含三个专门为阿拉伯语设计的基准套件。第一个是来自阿拉伯语教科书和教育工作表的STEM相关问答对；第二个是使用相同来源合成生成的STEM问题；第三个基准侧重于代码生成，通过人工循环过程和多轮审查，精心翻译了两个广泛使用的代码基准。

**Result:** 发布了3LM，一个包含三个阿拉伯语基准的套件：一个自然来源的STEM问答对基准，一个合成生成的STEM问题基准，以及一个通过翻译和人工审核构建的代码生成基准。

**Conclusion:** 通过公开这些基准，旨在支持阿拉伯语LLM在STEM和代码等重要但代表性不足领域的研究发展。

> **ai_Abstract:** 本研究介绍了3LM，一个专为阿拉伯语大型语言模型（LLM）设计的综合基准套件，旨在弥补现有阿拉伯语基准在STEM和代码领域的空白。该套件包含三个基准：一个基于阿拉伯语教材的自然STEM问答对集，一个合成生成的STEM问题集，以及一个通过人工翻译和多轮审查构建的代码生成基准。通过公开这些基准，研究旨在推动阿拉伯语LLM在这些关键但未充分探索领域的研发。

> **摘要翻译:** 阿拉伯语是世界上使用最广泛的语言之一，然而，针对阿拉伯语的大型语言模型（LLM）的开发和评估工作仍然相对有限。大多数现有的阿拉伯语基准侧重于语言、文化或宗教内容，在STEM和代码等领域留下了显著空白，而这些领域对于现实世界的LLM应用越来越重要。为了帮助弥补这一差距，我们提出了3LM，一个专为阿拉伯语设计的三个基准套件。第一个是一组STEM相关的问答对，自然来源于阿拉伯语教科书和教育工作表。第二个包含合成生成的STEM问题，使用相同的来源创建。第三个基准侧重于代码生成，通过对两个广泛使用的代码基准进行仔细翻译构建，并结合了人工循环过程和多轮审查，以确保高质量和忠实的翻译。我们公开了所有这三个基准，以支持阿拉伯语LLM在这些重要但代表性不足领域的研究增长。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [110] [Debating Truth: Debate-driven Claim Verification with Multiple Large Language Model Agents](https://arxiv.org/abs/2507.19090)
> *辩论真相：多大型语言模型代理驱动的辩论式事实核查*

*Haorui He, Yupeng Li, Dacheng Wen, Reynold Cheng, Francis C. M. Lau* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 事实核查, 大型语言模型, 辩论式学习, 多智能体系统, 数字素养

**Comment:** 

> **TL;DR:** DebateCV是一个新的基于多LLM代理的辩论式事实核查框架，通过模拟辩论过程并结合合成数据后训练，在不同证据质量下优于现有方法。

**AI_Comments:** 该论文的创新点在于首次将辩论驱动的方法引入事实核查领域，并利用多LLM代理模拟真实世界的辩论过程。通过引入合成数据后训练策略，有效解决了现实世界中辩论式事实核查数据稀缺的问题，提升了模型在复杂场景下的性能，对于提升数字素养具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有单LLM事实核查方法难以处理涉及多方面证据的复杂事实核查，受现实世界事实核查实践启发，需要一种更有效的方法。

**Method:** 提出DebateCV框架，首次采用多LLM代理的辩论驱动方法进行事实核查。框架中，两个“辩论者”对声明持相反立场进行多轮论证，一个“主持人”评估论证并给出裁决。为提高主持人性能，引入了新的后训练策略，利用零样本DebateCV生成的合成辩论数据，解决了现实世界辩论驱动事实核查数据稀缺的问题。

**Result:** 实验结果表明，我们的方法在不同证据质量下优于现有事实核查方法。

**Conclusion:** DebateCV框架通过模拟辩论过程和利用合成数据进行后训练，显著提升了复杂事实核查的性能，为数字素养的提升提供了有效工具。

> **ai_Abstract:** 本文提出了DebateCV，一个创新的多LLM代理辩论式事实核查框架，旨在解决现有单LLM方法在处理复杂多证据声明时的不足。DebateCV模拟真实辩论过程，由两名LLM辩论者对声明进行多轮论证，一名LLM主持人裁决。为应对数据稀缺，引入了基于零样本DebateCV生成合成数据的后训练策略。实验证明，DebateCV在不同证据质量下均优于现有事实核查方法。

> **摘要翻译:** 事实核查对于提升数字素养至关重要。然而，最先进的单一大型语言模型（LLM）方法难以处理涉及多方面证据的复杂事实核查。受现实世界事实核查实践的启发，我们提出了 DebateCV，这是第一个采用多LLM代理的辩论驱动方法的事实核查框架。在我们的框架中，两名“辩论者”对一个声明采取对立立场并进行多轮论证，而一名“主持人”评估论证并给出带理由的裁决。为了进一步提高“主持人”的性能，我们引入了一种新颖的后训练策略，该策略利用零样本 DebateCV 生成的合成辩论数据，有效解决了现实世界辩论驱动事实核查数据稀缺的问题。实验结果表明，我们的方法在不同证据质量下优于现有事实核查方法。我们的代码和数据集已公开可用，网址为 https://anonymous.4open.science/r/DebateCV-6781。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [122] [TELEVAL: A Dynamic Benchmark Designed for Spoken Language Models in Chinese Interactive Scenarios](https://arxiv.org/abs/2507.18061)
> *TELEVAL：一个为中文交互场景下语音语言模型设计的动态基准*

*Zehan Li, Hongjie Chen, Yuxin Zhang, Jing Zhou, Xuening Wang, Hang Lv, Mengjie Du, Yaodong Song, Jie Lian, Jian Kang, Jie Li, Yongxiang Li, Zhongjiang He, Xuelong Li* | **Category: cs.CL, cs.AI, cs.SD, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 语音语言模型, 动态基准, 中文交互, 对话代理, 用户体验

**Comment:** 

> **TL;DR:** 现有语音语言模型评估基准与真实用户交互不符。本文提出TELEVAL，一个针对中文交互场景下语音语言模型的动态基准，评估模型在自然对话中的表现，实验表明现有模型仍需改进。

**AI_Comments:** TELEVAL的创新之处在于其以用户为中心的设计理念，并特别强调了对隐式语义和副语言的评估，这弥补了现有SLM基准的不足。它直接关注模型在真实对话场景中的表现，对于推动更自然、更具交互性的SLM发展具有重要意义。该基准的提出有望引导研究方向，促使模型更好地理解和响应人类复杂的语音交互。

<details>
  <summary>Details</summary>

**Motivation:** 现有语音语言模型（SLMs）评估基准主要关注其执行复杂任务的能力，但往往未能与用户在真实对话场景中的自然交互方式对齐，未能有效反映真实用户体验。

**Method:** 论文提出了TELEVAL，一个专门为评估SLMs在真实中文交互场景中作为对话代理有效性而设计的动态基准。TELEVAL定义了三个评估维度：显式语义、副语言和隐式语义、以及系统能力。它采用与真实世界使用一致的对话格式，并分别评估文本和音频输出。TELEVAL特别关注模型从用户语音中提取隐式线索并无需额外指令即可适当响应的能力。

**Result:** 实验表明，尽管现有SLMs取得了进展，但在自然对话任务中仍有相当大的改进空间。

**Conclusion:** TELEVAL可以作为一个以用户为中心的评估框架，直接反映用户体验，并有助于开发更强大的面向对话的语音语言模型。

> **ai_Abstract:** 本文提出了TELEVAL，一个为中文交互场景下语音语言模型（SLMs）设计的动态评估基准。现有基准未能充分反映真实用户交互。TELEVAL通过定义显式语义、副语言和隐式语义、以及系统能力三个维度，以对话形式评估SLMs的文本和音频输出，并特别关注模型提取隐式线索的能力。实验结果显示，当前SLMs在自然对话任务上仍有显著提升空间。TELEVAL旨在提供一个以用户为中心的评估框架，以促进更优秀的对话型SLMs的发展。

> **摘要翻译:** 语音语言模型（SLMs）近年来取得了快速进展，同时涌现出许多用于评估其性能的基准。然而，大多数现有基准主要侧重于评估SLMs是否能执行与大型语言模型（LLMs）所处理的复杂任务相媲美的任务，往往未能与用户在真实世界对话场景中的自然交互方式对齐。在本文中，我们提出了TELEVAL，一个专门设计用于评估SLMs在真实中文交互场景中作为对话代理有效性的动态基准。TELEVAL定义了三个评估维度：显式语义、副语言和隐式语义，以及系统能力。它采用与真实世界使用一致的对话格式，并分别评估文本和音频输出。TELEVAL特别关注模型从用户语音中提取隐式线索并无需额外指令即可适当响应的能力。我们的实验表明，尽管最近取得了进展，现有SLMs在自然对话任务中仍有相当大的改进空间。我们希望TELEVAL能够作为一个以用户为中心的评估框架，直接反映用户体验，并有助于开发更强大的面向对话的SLMs。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [133] [Re:Form -- Reducing Human Priors in Scalable Formal Software Verification with RL in LLMs: A Preliminary Study on Dafny](https://arxiv.org/abs/2507.16331)
> *Re:Form -- 通过LLM中的强化学习减少可扩展形式化软件验证中的人类先验：对Dafny的初步研究*

*Chuanhao Yan, Fengdi Che, Xuhan Huang, Xu Xu, Xin Li, Yizhi Li, Xingwei Qu, Jingzhe Shi, Zhuangzhuang He, Chenghua Lin, Yaodong Yang, Binhang Yuan, Hang Zhao, Yu Qiao, Bowen Zhou, Jie Fu* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 形式化验证, 强化学习, 大型语言模型, Dafny, 人类先验

**Comment:** 

> **TL;DR:** 本研究探索了一种使用形式化语言（如Dafny）和强化学习来减少大型语言模型在可扩展形式化软件验证中对人类先验依赖的方法，并展示了在生成可验证代码和泛化能力方面的显著改进。

**AI_Comments:** 该研究的创新点在于将强化学习与形式化语言（Dafny）结合，以减少大型语言模型在软件验证中对昂贵人类先验的依赖。通过引入自动化数据整理和形式化验证器反馈，它展示了即使小型模型也能生成高质量的可验证代码，并在泛化能力上超越现有模型。这对于推动大规模、可靠的软件验证具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于非正式语言的大型语言模型（LLM）在软件验证过程中面临可靠性和可扩展性挑战，其生成的程序难以验证。此外，在监督复杂编程任务时，提供人类标注的思维链和先验变得不可接受地耗时。

**Method:** 本研究系统地探索了使用形式化语言Dafny作为主要环境来减少人类先验的方法。主要依赖于引入一个自动化和可扩展的数据整理流程，以及与形式化语言验证器反馈相结合的精心设计的强化学习（RL）。引入了DafnyComp，一个带有自动形式化规范的组合式形式化程序基准。

**Result:** 通过监督微调（SFT）阶段，即使是小型模型（例如0.5B）也能生成语法正确且可验证的Dafny代码，超越了专有模型。带有正则化的强化学习进一步提高了性能，实现了对领域外任务更强的泛化能力，并在具有挑战性的DafnyComp基准测试中超越了所有强基线。

**Conclusion:** 通过将LLMs与形式化系统结合，并利用自动化数据整理和强化学习，可以显著减少对人类先验的依赖，从而实现大规模、可靠的形式化软件验证。

> **ai_Abstract:** 本研究提出了一种名为“Re:Form”的方法，旨在通过在大型语言模型（LLM）中结合强化学习（RL）和形式化语言（Dafny）来减少软件验证中对人类先验的依赖。针对现有LLM在非正式语言环境下验证不可靠且难以扩展的问题，以及人类先验提供成本高昂的挑战，研究引入了自动化数据整理管道和与形式化验证器集成的RL设计。他们构建了DafnyComp基准测试，并证明了即使小型模型也能生成可验证的Dafny代码，并通过RL实现更好的泛化能力，超越了现有基线和专有模型，为大规模可靠的形式化软件验证提供了可行路径。

> **摘要翻译:** 现有基于非正式语言（例如人类语言）的、通过强化学习（RL）训练的大型语言模型（LLM）面临一个重大挑战：它们提供关键训练信号的验证过程既不可靠也无法扩展。事实上，目前流行的大型专有模型几乎无法生成可验证的程序。一个有前景但尚未充分探索的替代方案是基于形式化语言的推理。将LLM根植于严谨的形式化系统中，让生成模型在形式化语言空间（例如Dafny）中运行，能够对其推理过程和结果进行自动且数学上可证明的验证。这种能力对于实现大规模、可靠的形式化软件验证至关重要。通常的做法是使用人类标注的思维链和其他人类先验来诱导LLM的推理和编码能力。不幸的是，为监督复杂的编程任务提供此类先验变得耗时且难以接受。在这项工作中，我们系统地探索了如何通过形式化语言Dafny作为我们初步研究的主要环境来减少人类先验。我们的管道主要依赖于引入一个自动化且可扩展的数据整理管道，以及与形式化语言验证器反馈相结合的精心设计的强化学习。我们引入了DafnyComp，一个用于规范推理的组合式形式化程序基准，其规范是自动形式化的。我们的监督微调（SFT）阶段使即使是小型模型（例如0.5B）也能生成语法正确且可验证的Dafny代码，超越了专有模型。带有正则化的强化学习进一步提高了性能，实现了对领域外任务更强的泛化能力，并在具有挑战性的DafnyComp基准测试中超越了所有强基线。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [137] [Specification Self-Correction: Mitigating In-Context Reward Hacking Through Test-Time Refinement](https://arxiv.org/abs/2507.18742)
> *规范自校正：通过测试时优化缓解上下文奖励黑客攻击*

*Víctor Gallego* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 奖励黑客攻击, 语言模型, 规范自校正, 测试时优化, 模型对齐

**Comment:** Accepted to SCALR Workshop @ COLM 2025

> **TL;DR:** 语言模型容易受到上下文奖励黑客攻击，即利用有缺陷的指令获得高分而非实现真实意图。本文提出了规范自校正（SSC），一个测试时框架，使语言模型能够识别并纠正其自身指导规范中的缺陷，从而显著降低这种漏洞。

**AI_Comments:** 该论文的创新之处在于其“规范自校正”机制，它允许语言模型在测试时动态地识别并修正其自身的指导规范，而非仅仅修正输出，且无需重新训练。这直接解决了奖励黑客攻击这一关键对齐问题，使其在实际应用中具有高度实用性。其在显著降低漏洞方面的有效性是其主要优势。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型（LMs）容易受到上下文奖励黑客攻击，即它们利用有缺陷或错误的文字规范或评分标准中的漏洞，在不满足用户真实意图的情况下获得高分。

**Method:** 规范自校正（SSC）是一种新颖的测试时框架。它采用多步推理过程：模型首先根据可能受污染的规范生成响应，然后批判其输出，接着修改规范本身以消除可利用的漏洞，最后使用这种自校正的规范生成一个更健壮的响应。此过程在推理时发生，无需修改模型权重。

**Result:** 在涉及创意写作和代理编码任务的多个语言模型实验中，虽然模型最初在50-70%的情况下会利用有缺陷的规范进行作弊，但SSC过程将这种漏洞降低了90%以上。此方法无需修改权重，并导致模型行为更稳健地对齐。

**Conclusion:** 规范自校正（SSC）是一个有效的测试时框架，通过使语言模型能够识别并纠正其自身指导规范中的缺陷，从而缓解了上下文奖励黑客攻击，并导致模型行为更稳健地对齐。

> **ai_Abstract:** 本文提出了规范自校正（SSC），这是一种新颖的测试时框架，旨在缓解语言模型中的上下文奖励黑客攻击问题。SSC通过多步推理过程使语言模型能够识别并修正其自身指导规范中的缺陷：首先生成基于潜在缺陷规范的响应，然后批判该输出，接着修订规范以消除漏洞，最后基于修正后的规范生成一个更鲁棒的响应。实验表明，SSC将模型利用缺陷规范进行作弊的漏洞降低了90%以上，实现了更稳健的模型对齐，且无需修改模型权重。

> **摘要翻译:** 语言模型（LMs）容易受到上下文奖励黑客攻击，即它们利用有缺陷或错误的文字规范或评分标准中的漏洞，在不满足用户真实意图的情况下获得高分。我们引入了规范自校正（SSC），这是一种新颖的测试时框架，它使语言模型能够识别并纠正其自身指导规范中的缺陷。SSC采用多步推理过程，模型首先根据可能受污染的规范生成响应，然后批判其输出，接着修改规范本身以消除可利用的漏洞。最后，使用这种自校正的规范生成一个更健壮的响应。在涉及创意写作和代理编码任务的多个语言模型实验中，我们证明，尽管模型最初在50-70%的情况下会利用有缺陷的规范进行作弊，但SSC过程将这种漏洞降低了90%以上。这种动态修复发生在推理时，不需要修改权重，并导致模型行为更稳健地对齐。代码位于 https://github.com/vicgalle/specification-self-correction 。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [144] [GLiNER2: An Efficient Multi-Task Information Extraction System with Schema-Driven Interface](https://arxiv.org/abs/2507.18546)
> *GLiNER2：一种高效的多任务信息抽取系统，具有模式驱动接口*

*Urchade Zaratiana, Gil Pasternak, Oliver Boyd, George Hurn-Maloney, Ash Lewis* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 信息抽取, 多任务, Transformer, 模式驱动, GLiNER2

**Comment:** 

> **TL;DR:** GLiNER2是一个高效的、统一的多任务信息抽取系统，它在保持CPU效率和紧凑性的同时，通过模式驱动接口支持命名实体识别、文本分类和分层结构数据抽取，并在实验中展现出与LLM相当的竞争力及更高的部署可访问性。

**AI_Comments:** GLiNER2的创新之处在于其将多种信息抽取任务统一到一个高效模型中，并通过模式驱动接口提供灵活的多任务组合能力。与依赖大型语言模型的方案相比，其CPU效率和部署可访问性的显著提升，使其在实际应用中更具吸引力，尤其是在资源受限的环境下。

<details>
  <summary>Details</summary>

**Motivation:** 信息抽取（IE）是许多自然语言处理（NLP）应用的基础，但现有解决方案通常需要针对不同任务的专门模型，或者依赖于计算成本高昂的大型语言模型（LLM）。

**Method:** 我们提出了GLiNER2，一个统一的框架，它增强了原始GLiNER架构，以在一个高效模型中支持命名实体识别、文本分类和分层结构数据抽取。GLiNER2基于预训练的Transformer编码器架构构建，保持了CPU效率和紧凑的尺寸，同时通过直观的模式驱动接口引入了多任务组合。

**Result:** 我们的实验表明，GLiNER2在抽取和分类任务上表现出有竞争力的性能，并且与基于LLM的替代方案相比，在部署可访问性方面有显著改进。

**Conclusion:** GLiNER2提供了一个高效、统一且易于部署的信息抽取解决方案，在性能上与大型语言模型相当，解决了现有方案的效率和可访问性问题。

> **ai_Abstract:** GLiNER2是一个统一且高效的信息抽取框架，它扩展了GLiNER架构，在一个模型中支持命名实体识别、文本分类和分层结构数据抽取。该系统基于预训练的Transformer编码器，具有CPU效率高和模型尺寸紧凑的特点，并通过模式驱动接口实现多任务处理。实验证明，GLiNER2在性能上具有竞争力，并且相比基于大型语言模型的方案，显著提升了部署的可访问性。该项目已作为开源库发布。

> **摘要翻译:** 信息抽取（IE）是许多自然语言处理（NLP）应用的基础，但现有解决方案通常需要针对不同任务的专门模型，或者依赖于计算成本高昂的大型语言模型。我们提出了GLiNER2，一个统一的框架，它增强了原始GLiNER架构，以在一个高效模型中支持命名实体识别、文本分类和分层结构数据抽取。GLiNER2基于预训练的Transformer编码器架构构建，保持了CPU效率和紧凑的尺寸，同时通过直观的模式驱动接口引入了多任务组合。我们的实验表明，GLiNER2在抽取和分类任务上表现出有竞争力的性能，并且与基于LLM的替代方案相比，在部署可访问性方面有显著改进。我们将GLiNER2作为开源的pip可安装库发布，并提供预训练模型和文档，网址为https://github.com/fastino-ai/GLiNER2。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [152] [Objectifying the Subjective: Cognitive Biases in Topic Interpretations](https://arxiv.org/abs/2507.19117)
> *客观化主观：主题解释中的认知偏差*

*Swapnil Hingmire, Ze Shi Li, Shiyu, Zeng, Ahmed Musa Awon, Luiz Franciscatto Guerra, Neil Ernst* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 主题解释, 认知偏差, 用户研究, 锚定和调整, 主题质量

**Comment:** Accepted for publication at the Transactions of ACL (TACL) (pre-MIT
  Press publication version)

> **TL;DR:** 用户在解释主题时会受到锚定和调整等认知偏差的影响，而非仅基于概率，这表明需要建立考虑偏差的用户模型。

**AI_Comments:** 该论文的创新之处在于将主题评估的焦点从纯粹的统计度量转向人类认知过程。通过揭示认知偏差（如锚定和调整）在主题解释中的作用，它指出了当前主题建模和评估中的一个关键空白。这种理解对于设计更以用户为中心和更有效的主题探索工具至关重要。其局限性可能在于特定用户研究结果的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 当前最先进的主题质量评估方法（如连贯性和词语入侵）未能衡量主题在多大程度上促进了语料库的探索。为了设计基于任务和用户群体、更符合实际的评估指标，本研究旨在理解用户如何解释主题。

**Method:** 我们进行了用户研究，以了解用户如何解释主题。我们提出了主题质量的构建，并要求用户在主题上下文中对其进行评估，并提供评估背后的理由。我们使用反思性主题分析从用户提供的理由中识别主题解释的主题。

**Result:** 用户在解释主题时，依赖于可用性和代表性启发式而非概率。我们提出了一种基于锚定和调整启发式的主题解释理论：用户锚定在显着词汇上，并通过语义调整来得出解释。

**Conclusion:** 主题解释可以被视为生态理性用户在不确定性下做出的判断，因此需要建立考虑认知偏差的用户模型和评估框架。

> **ai_Abstract:** 本论文研究了用户如何解释主题，发现当前的主题评估指标未能充分考虑语料库探索的便利性。通过用户研究和主题分析，作者发现用户在解释主题时依赖于可用性、代表性以及特别是锚定和调整等认知启发式（即锚定于显著词汇并进行语义调整），而非纯粹的概率。论文得出结论，主题解释是在不确定性下做出的判断，因此需要开发考虑认知偏差的用户模型和评估框架。

> **摘要翻译:** 主题的解释对其下游应用至关重要。当前最先进的主题质量评估指标，如连贯性和词语入侵，未能衡量主题在多大程度上促进语料库的探索。为了设计基于任务和用户群体的评估指标，我们进行了用户研究，以了解用户如何解释主题。我们提出了主题质量的构建，并要求用户在主题上下文中对其进行评估，并提供评估背后的理由。我们使用反思性主题分析从理由中识别主题解释的主题。用户根据可用性和代表性启发式而不是概率来解释主题。我们提出了一种基于锚定和调整启发式的主题解释理论：用户锚定在显着词汇上，并进行语义调整以得出解释。主题解释可以被视为生态理性用户在不确定性下做出判断，因此需要认知偏差感知的用户模型和评估框架。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [154] [Technical Report of TeleChat2, TeleChat2.5 and T1](https://arxiv.org/abs/2507.18013)
> *TeleChat2、TeleChat2.5 和 T1 的技术报告*

*Zihan Wang, Xinzhang Liu, Yitong Yao, Chao Wang, Yu Zhao, Zhihao Yang, Wenmin Deng, Kaipeng Jia, Jiaxin Peng, Yuyao Huang, Sishi Xiong, Zhuo Jiang, Kaidong Yu, Xiaohui Hu, Fubei Yao, Ruiyu Fang, Zhuoru Jiang, Ruiting Song, Qiyi Xie, Rui Xue, Xuewei He, Yanlei Xue, Zhu Yuan, Zhaoxi Zhang, Zilu Huang, Shiquan Wang, Xin Wang, Hanming Wu, Mingyuan Wang, Xufeng Zhan, Yuhan Sun, Zhaohu Xing, Yuhao Jiang, Bingkai Yang, Shuangyong Song, Yongxiang Li, Zhongjiang He, Xuelong Li* | **Category: cs.CL, I.2.7** | **Updated: 2025-07-25**

**Keywords:** TeleChat, 大型语言模型, 训练策略, 性能提升, 推理

**Comment:** 32 pages, 5 figures

> **TL;DR:** 本文介绍了TeleChat系列的新模型TeleChat2、TeleChat2.5和T1，它们通过改进训练策略在性能上实现了显著提升，尤其在推理、代码生成和数学任务上表现出色，并已公开发布。

**AI_Comments:** 这篇论文通过“最小化模型架构变化，最大化训练策略优化”的路径，展示了在现有模型基础上通过精细化训练也能取得突破性进展，甚至超越一些知名专有模型，这对于资源有限的研究者具有重要启发意义。模型的公开发布也促进了社区的发展。

<details>
  <summary>Details</summary>

**Motivation:** 提升TeleChat模型的性能，以更好地支持复杂的推理、代码生成和数学任务，并提供最先进的语言模型供开发者和研究人员使用。

**Method:** 该系列模型在模型架构变化最小的情况下，主要通过增强预训练和后训练阶段的训练策略来实现性能提升。TeleChat2在10万亿高质量多样化tokens上进行预训练，并结合监督微调（SFT）和直接偏好优化（DPO）。TeleChat2.5和T1在此基础上，通过引入领域特定数据集的持续预训练并结合强化学习（RL）来进一步提升性能。T1专门用于复杂推理，支持长链式思考（CoT），而TeleChat2.5则优先考虑推理速度。旗舰模型T1和TeleChat2.5是115B参数的密集Transformer架构。

**Result:** 新系列模型（TeleChat2、TeleChat2.5和T1）比其前身TeleChat实现了显著的性能提升。T1在数学和编码方面显示出实质性改进。T1-115B在推理和通用任务性能上显著优于原始TeleChat，并且超越了OpenAI的o1-mini和GPT-4o等专有模型。TeleChat2.5在速度方面表现出色。

**Conclusion:** TeleChat2、TeleChat2.5和T1系列模型通过增强训练策略，在复杂推理、代码生成和数学任务上实现了显著的性能提升，达到了最先进水平，并且已公开发布，以赋能开发者和研究人员。

> **ai_Abstract:** 本技术报告介绍了TeleChat模型的最新系列：TeleChat2、TeleChat2.5和T1。这些新模型在模型架构变化不大的前提下，通过优化预训练和后训练策略，实现了显著的性能提升。TeleChat2在海量高质量数据上进行预训练并结合SFT和DPO。TeleChat2.5和T1在此基础上，通过持续预训练领域特定数据集和强化学习，进一步提升了代码生成和数学推理能力。其中，T1擅长复杂推理，TeleChat2.5则注重推理速度。这些115B参数的密集Transformer模型在推理和通用任务上表现卓越，T1-115B甚至超越了某些专有模型。所有模型，包括35B和115B参数的版本，均已公开发布，旨在赋能开发者和研究人员。

> **摘要翻译:** 我们推出了TeleChat模型的最新系列：TeleChat2、TeleChat2.5和T1，与前身TeleChat相比，它们提供了显著的升级。尽管模型架构变化最小，但新系列通过增强预训练和后训练阶段的训练策略实现了实质性的性能提升。该系列始于TeleChat2，它在10万亿高质量多样化tokens上进行预训练。随后通过监督微调（SFT）和直接偏好优化（DPO）进一步增强其能力。TeleChat2.5和T1通过结合领域特定数据集的持续预训练和强化学习（RL）来扩展流水线，以提高代码生成和数学推理任务的性能。T1变体专为复杂推理而设计，支持长链式思考（CoT）推理，并在数学和编码方面表现出实质性改进。相比之下，TeleChat2.5优先考虑速度，提供快速推理。T1和TeleChat2.5这两款旗舰模型都是具有115B参数的密集Transformer架构，与原始TeleChat相比，在推理和通用任务性能上展现出显著进步。值得注意的是，T1-115B甚至超越了OpenAI的o1-mini和GPT-4o等专有模型。我们公开发布TeleChat2、TeleChat2.5和T1，包括35B和115B参数的后训练版本，旨在为开发者和研究人员提供最先进的语言模型，以适应各种应用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [161] [BlockDialect: Block-wise Fine-grained Mixed Format Quantization for Energy-Efficient LLM Inference](https://arxiv.org/abs/2501.01144)
> *BlockDialect：用于节能型LLM推理的块级细粒度混合格式量化*

*Wonsuk Jang, Thierry Tambe* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** LLM量化, 混合格式量化, 细粒度量化, BlockDialect, DialectFP4

**Comment:** ICML 2025

> **TL;DR:** 本文提出BlockDialect，一种块级细粒度混合格式量化技术，通过为LLM推理分配最优数字格式并引入DialectFP4，显著提高量化精度和能效，以应对大型语言模型日益增长的内存和计算挑战。

**AI_Comments:** 该论文的创新点在于提出了“块级细粒度混合格式”量化，并通过引入“格式本”和“DialectFP4”来解决现有量化方法难以捕捉细微数据分布的问题。这种方法不仅提升了量化精度，还通过兼容低精度整数算术确保了能效，为LLM在资源受限环境下的部署提供了新的思路。其关注数据表示而非简单缩放的策略具有重要的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的尺寸不断增长，导致内存使用和计算成本面临巨大挑战。尽管量化是一种解决方案，但现有方法难以捕捉细微的块数据分布。

**Method:** 本文提出BlockDialect，一种块级细粒度混合格式技术，它从格式本中为每个块分配最优数字格式以实现更好的数据表示。此外，引入DialectFP4，一个包含FP4变体（类似于方言）的格式本，以适应不同的数据分布。为高效利用，提出两阶段方法进行在线DialectFP4激活量化。DialectFP4通过选择可表示的值作为与低精度整数算术兼容的缩放整数来确保能效。

**Result:** 与MXFP4格式相比，BlockDialect在LLaMA3-8B（LLaMA2-7B）模型上实现了10.78%（7.48%）的精度提升，同时每数据位使用率更低。即使在量化全路径矩阵乘法时，其精度也仅比全精度低5.45%（2.69%）。

**Conclusion:** 本文专注于如何表示而非如何缩放，为节能型LLM推理提供了一条有前景的路径。

> **ai_Abstract:** 本文提出了BlockDialect，一种针对大型语言模型（LLMs）推理的块级细粒度混合格式量化技术，旨在解决LLM内存和计算成本问题。该方法通过从预定义的格式本中为每个数据块选择最优的数字格式来更好地表示数据，并引入了DialectFP4以适应不同的数据分布，同时确保与低精度整数算术的兼容性以实现能效。实验结果表明，BlockDialect在LLaMA模型上相较于现有量化方法显著提高了精度，并在保持接近全精度性能的同时降低了位使用量，为节能型LLM推理提供了有效途径。

> **摘要翻译:** 大型语言模型（LLMs）尺寸的快速增长给内存使用和计算成本带来了巨大挑战。量化权重和激活可以解决这些问题，其中硬件支持的细粒度缩放作为一种有前景的解决方案，可以缓解异常值问题。然而，现有方法难以捕捉细微的块数据分布。我们提出了BlockDialect，一种块级细粒度混合格式技术，它从格式本中为每个块分配最优数字格式，以实现更好的数据表示。此外，我们引入了DialectFP4，一个包含FP4变体（类似于方言）的格式本，以适应不同的数据分布。为了高效利用这一点，我们提出了一种用于在线DialectFP4激活量化的两阶段方法。重要的是，DialectFP4通过选择可表示的值作为与低精度整数算术兼容的缩放整数来确保能效。与MXFP4格式相比，BlockDialect在LLaMA3-8B（LLaMA2-7B）模型上实现了10.78%（7.48%）的精度提升，同时每数据位使用率更低，并且即使在量化全路径矩阵乘法时，其精度也仅比全精度低5.45%（2.69%）。我们的工作专注于如何表示而非如何缩放，为节能型LLM推理提供了一条有前景的路径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [167] [LLM Alignment as Retriever Optimization: An Information Retrieval Perspective](https://arxiv.org/abs/2502.03699)
> *大型语言模型对齐作为检索器优化：一个信息检索视角*

*Bowen Jin, Jinsung Yoon, Zhen Qin, Ziqi Wang, Wei Xiong, Yu Meng, Jiawei Han, Sercan O. Arik* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-07-23**

**Keywords:** LLM对齐, 信息检索, 直接优化, LarPO, 检索器优化

**Comment:** 26 pages

> **TL;DR:** 本文提出LarPO，一种将LLM对齐视为信息检索中的检索器优化的新方法，通过直接优化显著提高了对齐质量。

**AI_Comments:** 这项工作通过将LLM对齐问题与成熟的信息检索原理相结合，提供了一个新颖且有前景的视角。其创新之处在于提出LarPO，一种直接优化方法，旨在简化复杂的RL对齐流程。将LLM生成和奖励模型映射到IR的检索器-重排序器范式，为理解和改进LLM行为提供了新的框架。实验结果的显著提升表明该方法具有重要潜力，可能为未来的LLM对齐研究开辟更高效、更易于实施的路径。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于强化学习的LLM对齐方法过于复杂，而直接优化方法提供了更简单的替代方案。为了确保LLM的行为正确、可信和道德，解决错误信息、幻觉、偏见和滥用等挑战，有效的LLM对齐至关重要。

**Method:** 本文提出了一种新颖的直接优化方法，将LLM生成和奖励模型映射到信息检索（IR）的检索器-重排序器范式。在此基础上，提出了LLM对齐作为检索器偏好优化（LarPO），这是一种新的对齐方法，旨在增强整体对齐质量。

**Result:** LarPO在AlpacaEval2上平均提高了38.9%，在MixEval-Hard上平均提高了13.7%。

**Conclusion:** 本工作通过整合信息检索基础，为推进LLM对齐开辟了新途径，为未来的研究提供了有前景的方向。

> **ai_Abstract:** 本研究提出了一种名为LarPO的新型大型语言模型（LLM）对齐方法，该方法将LLM对齐问题视为信息检索（IR）中的检索器优化。针对现有强化学习对齐方法的复杂性，LarPO采用直接优化方式，将LLM生成和奖励模型映射到IR的检索器-重排序器范式。实验结果表明，LarPO在AlpacaEval2和MixEval-Hard上分别取得了38.9%和13.7%的平均性能提升，为LLM对齐研究提供了结合IR基础的新方向。

> **摘要翻译:** 大型语言模型（LLM）凭借其在推理、编码和沟通方面的能力，彻底改变了人工智能，推动了各行各业的创新。它们的真正潜力取决于有效的对齐，以确保正确、可信和道德的行为，解决诸如错误信息、幻觉、偏见和滥用等挑战。虽然现有的基于强化学习（RL）的对齐方法以其复杂性而闻名，但直接优化方法提供了一种更简单的替代方案。在这项工作中，我们借鉴已建立的信息检索（IR）原则，引入了一种新颖的LLM对齐直接优化方法。我们提出了一个系统的框架，将LLM对齐与IR方法论相结合，将LLM生成和奖励模型映射到IR的检索器-重排序器范式。在此基础上，我们提出了LLM对齐作为检索器偏好优化（LarPO），这是一种新的对齐方法，可以提高整体对齐质量。广泛的实验验证了LarPO的有效性，在AlpacaEval2和MixEval-Hard上分别平均提高了38.9%和13.7%。我们的工作通过整合IR基础，为推进LLM对齐开辟了新途径，为未来的研究提供了有前景的方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [193] [An Empirical Investigation of Gender Stereotype Representation in Large Language Models: The Italian Case](https://arxiv.org/abs/2507.19156)
> *大型语言模型中性别刻板印象表示的实证研究：以意大利语为例*

*Gioele Giachino, Marco Rondina, Antonio Vetrò, Riccardo Coppola, Juan Carlos De Martin* | **Category: cs.CL, cs.AI, cs.CY, cs.HC** | **Updated: 2025-07-25**

**Keywords:** 大型语言模型, 性别刻板印象, 偏见, 意大利语, ChatGPT, Gemini

**Comment:** 16 pages, European Conference on Machine Learning and Principles and
  Practice of Knowledge Discovery in Databases (ECML PKDD 2025) - 5th Workshop
  on Bias and Fairness in AI (BIAS25)

> **TL;DR:** 本研究调查了大型语言模型（LLMs）在意大利语中如何根据无性别提示生成有偏见的输出，发现它们会延续性别刻板印象，例如将“她”与“助理”而非“经理”关联。

**AI_Comments:** 这项研究通过聚焦意大利语这一语法性别丰富的语言，提供了一个独特的视角来审视大型语言模型中的性别刻板印象，这与大多数关注英语的研究不同。其发现的偏见程度令人担忧，特别是将女性代词几乎完全与较低层级职业关联，突出了LLMs在多语言和文化背景下偏见传播的严重性。该研究对于理解AI伦理和开发去偏见策略具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的广泛应用引发了对其传播刻板印象和生成偏见内容的担忧。本研究旨在探讨LLMs如何根据无性别提示生成响应，从而导致偏见输出，特别关注性别和职业偏见。

**Method:** 本研究采用结构化实验方法，使用涉及三种不同职业组合（具有层级关系）的提示。研究使用语法性别差异显著的意大利语，以揭示当前LLMs在非英语语言中生成客观文本的潜在局限性。研究检查了两个流行的基于LLM的聊天机器人：OpenAI ChatGPT (gpt-4o-mini) 和 Google Gemini (gemini-1.5-flash)，通过API收集了3600个响应。

**Result:** 结果表明，LLMs生成的内容会延续刻板印象。例如，Gemini将100%（ChatGPT为97%）的“她”代词与“助理”而非“经理”关联。

**Conclusion:** AI生成文本中存在的偏见可能在工作场所或招聘选择等许多领域产生重大影响，引发对其使用的伦理担忧。理解这些风险对于制定缓解策略和确保基于AI的系统不加剧社会不平等、反而促进更公平的结果至关重要。

> **ai_Abstract:** 本研究实证调查了大型语言模型（LLMs）在处理意大利语无性别提示时如何表现出性别和职业偏见。通过对OpenAI ChatGPT和Google Gemini进行实验，并收集3600个响应，研究发现LLMs生成的内容显著延续了刻板印象，例如将女性代词与低层级职业（如助理）而非高层级职业（如经理）关联。这表明LLMs可能加剧社会不平等，并强调了开发缓解策略以确保AI系统促进公平结果的重要性。

> **摘要翻译:** 大型语言模型（LLMs）在各种领域中日益广泛的使用引发了人们对其轻易传播刻板印象并导致生成有偏见内容的担忧。本研究侧重于性别和职业偏见，探讨了LLMs如何根据无性别提示塑造响应，从而导致有偏见的输出。本分析采用结构化实验方法，给出涉及三种不同职业组合的提示，这些组合也具有层级关系。本研究使用意大利语，一种具有广泛语法性别差异的语言，以突出当前LLMs在非英语语言中生成客观文本的潜在局限性。研究检查了两个流行的基于LLM的聊天机器人，即OpenAI ChatGPT (gpt-4o-mini) 和 Google Gemini (gemini-1.5-flash)。通过API，我们收集了3600个响应。结果突出显示了LLMs生成的内容如何延续刻板印象。例如，Gemini将100%（ChatGPT为97%）的“她”代词与“助理”而非“经理”关联。AI生成文本中存在的偏见可能在许多领域产生重大影响，例如在工作场所或招聘选择中，引发对其使用的伦理担忧。理解这些风险对于制定缓解策略和确保基于AI的系统不加剧社会不平等，而是促进更公平的结果至关重要。未来的研究方向包括将研究扩展到其他聊天机器人或语言，完善提示工程方法或进一步利用更大的实验基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [200] [The Role of Orthographic Consistency in Multilingual Embedding Models for Text Classification in Arabic-Script Languages](https://arxiv.org/abs/2507.18762)
> *正字法一致性在阿拉伯文字语言文本分类多语言嵌入模型中的作用*

*Abdulhady Abas Abdullah, Amir H. Gandomi, Tarik A Rashid, Seyedali Mirjalili, Laith Abualigah, Milena Živković, Hadi Veisi* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 阿拉伯文字语言, 文本分类, 多语言模型, RoBERTa, 脚本感知预训练

**Comment:** 

> **TL;DR:** 针对阿拉伯文字语言，通用多语言模型表现不佳。本文引入AS-RoBERTa系列模型，通过语言特定预训练，在文本分类任务上显著优于mBERT和XLM-RoBERTa，强调脚本感知专业化的价值。

**AI_Comments:** 这项研究创新性地提出了针对阿拉伯文字语言的AS-RoBERTa模型，通过强调语言特定和脚本聚焦的预训练，有效解决了通用多语言模型在该类语言上的性能瓶颈。其重要性在于为低资源或特定脚本语言的NLP模型开发提供了新的方向，证明了定制化预训练的有效性。局限性可能在于其结论主要基于阿拉伯文字语言，对于其他共享脚本但语言差异大的语系是否同样适用，有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有多语言模型（如mBERT和XLM-RoBERTa）在共享脚本但正字法规范和文化背景不同的语言（特别是阿拉伯文字语言如库尔德索拉尼语、阿拉伯语、波斯语和乌尔都语）上表现不佳。

**Method:** 引入Arabic Script RoBERTa (AS-RoBERTa) 系列模型，包含四个RoBERTa基模型，每个模型都在其特定语言的大型语料库上进行预训练。通过专注于语言特定的脚本特征和统计数据进行预训练，以捕捉通用模型忽略的模式。

**Result:** AS-RoBERTa变体在分类任务上比mBERT和XLM-RoBERTa高出2到5个百分点。消融研究证实，以脚本为中心的预训练是取得这些收益的关键。误差分析显示共享脚本特征和领域特定内容如何影响性能。

**Conclusion:** 脚本感知专业化对于使用阿拉伯文字的语言具有重要价值，并支持进一步开展基于脚本和语言特异性的预训练策略研究。

> **ai_Abstract:** 本文针对mBERT和XLM-RoBERTa等多语言模型在阿拉伯文字语言中表现不佳的问题，提出了Arabic Script RoBERTa (AS-RoBERTa) 系列模型。AS-RoBERTa通过在语言特定的语料库上进行脚本特征和统计数据的预训练，能够捕捉到通用模型忽略的模式。实验结果表明，AS-RoBERTa在文本分类任务上显著优于现有通用模型，且消融研究证实脚本聚焦预训练是关键。研究强调了脚本感知专业化对于处理阿拉伯文字语言的重要性。

> **摘要翻译:** 在自然语言处理中，mBERT和XLM-RoBERTa等多语言模型有望实现广泛覆盖，但它们在共享脚本但正字法规范和文化背景不同的语言上常常表现不佳。这个问题在阿拉伯文字语言中尤为突出，例如库尔德索拉尼语、阿拉伯语、波斯语和乌尔都语。我们引入了阿拉伯文字RoBERTa (AS-RoBERTa) 系列：四个基于RoBERTa的模型，每个模型都在针对其特定语言的大型语料库上进行了预训练。通过将预训练重点放在语言特定的脚本特征和统计数据上，我们的模型能够捕捉到通用模型所忽略的模式。在分类任务上进行微调时，AS-RoBERTa变体比mBERT和XLM-RoBERTa高出2到5个百分点。一项消融研究证实，以脚本为中心的预训练是这些收益的核心。使用混淆矩阵进行的误差分析显示了共享脚本特征和领域特定内容如何影响性能。我们的结果强调了脚本感知专业化对于使用阿拉伯文字的语言的价值，并支持进一步开展基于脚本和语言特异性的预训练策略研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [213] [GOAT-SLM: A Spoken Language Model with Paralinguistic and Speaker Characteristic Awareness](https://arxiv.org/abs/2507.18119)
> *GOAT-SLM：一种具有副语言和说话者特征意识的口语模型*

*Hongjie Chen, Zehan Li, Yaodong Song, Wenming Deng, Yitong Yao, Yuxin Zhang, Hang Lv, Xuechao Zhu, Jian Kang, Jie Lian, Jie Li, Chao Wang, Shuangyong Song, Yongxiang Li, Zhongjiang He, Xuelong Li* | **Category: cs.CL, cs.AI, cs.SD, eess.AS** | **Updated: 2025-07-25**

**Keywords:** 口语模型, 副语言, 说话者特征, 双模态, 分阶段训练

**Comment:** 

> **TL;DR:** GOAT-SLM是一种新型口语模型，通过双模态头架构和分阶段训练，超越文本语义，整合副语言和说话者特征，在语义和非语义任务上表现出色，尤其在情感、方言和年龄敏感交互方面优于现有模型。

**AI_Comments:** 这项工作在口语模型领域具有重要创新性，它超越了传统上仅关注语言内容的方法，将副语言和说话者特征纳入建模，这对于实现更自然、更具情境感的人机交互至关重要。其双模态头架构和分阶段训练策略为处理语音中复杂的多维度信息提供了有效途径。GOAT-SLM的提出为未来开发更具社会意识和人类感知能力的AI系统奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有端到端口语模型（SLMs）主要将语音视为语言内容的载体，忽略了人类语音中丰富的副语言和说话者特征线索，如方言、年龄、情感和非语音发声。

**Method:** 引入了GOAT-SLM，它采用了一种双模态头架构，将语言建模与声学实现解耦，以实现强大的语言理解和富有表现力、适应性的语音生成。此外，还提出了一种模块化、分阶段的训练策略，利用大规模语音-文本语料库逐步对齐语言、副语言和说话者特征信息。

**Result:** 在多维度评估基准TELEVAL上的实验结果表明，GOAT-SLM在语义和非语义任务上均实现了良好平衡的性能，并且在处理情感、方言变异和年龄敏感交互方面优于现有开源模型。

**Conclusion:** 这项工作强调了超越语言内容进行建模的重要性，并推动了更自然、适应性强、具有社会意识的口语系统发展。

> **ai_Abstract:** GOAT-SLM是一种新型口语模型，旨在解决现有模型忽视语音中副语言和说话者特征的问题。它采用双模态头架构将语言建模与声学实现解耦，并通过模块化、分阶段的训练策略整合多源信息。实验证明，GOAT-SLM在语义和非语义任务上表现均衡，并在情感、方言和年龄敏感交互方面优于现有模型，推动了更自然、适应性强的口语系统发展。

> **摘要翻译:** GOAT-SLM：一种具有副语言和说话者特征意识的口语模型

端到端口语模型（SLMs）的最新进展显著提高了AI系统进行自然口语交互的能力。然而，大多数现有模型仅将语音视为语言内容的载体，常常忽略了人类语音中嵌入的丰富副语言和说话者特征线索，例如方言、年龄、情感和非语音发声。在这项工作中，我们引入了GOAT-SLM，这是一种新型的具有副语言和说话者特征意识的口语模型，旨在将口语建模扩展到文本语义之外。GOAT-SLM采用双模态头架构，将语言建模与声学实现解耦，从而实现强大的语言理解，同时支持富有表现力和适应性的语音生成。为了提高模型效率和通用性，我们提出了一种模块化、分阶段的训练策略，利用大规模语音-文本语料库逐步对齐语言、副语言和说话者特征信息。在多维度评估基准TELEVAL上的实验结果表明，GOAT-SLM在语义和非语义任务上均实现了良好平衡的性能，并且在处理情感、方言变异和年龄敏感交互方面优于现有开源模型。这项工作强调了超越语言内容进行建模的重要性，并推动了更自然、适应性强、具有社会意识的口语系统发展。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [243] [Can Small-Scale Data Poisoning Exacerbate Dialect-Linked Biases in Large Language Models?](https://arxiv.org/abs/2507.19195)
> *小规模数据投毒会加剧大型语言模型中与方言相关的偏见吗？*

*Chaymaa Abbas, Mariette Awad, Razane Tajeddine* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 数据投毒, 方言偏见, 大型语言模型, 非洲裔美国人白话英语, 毒性

**Comment:** 

> **TL;DR:** 小规模数据投毒会显著增加大型语言模型中针对非洲裔美国人白话英语（AAVE）输入的毒性，而对标准美式英语（SAE）的影响较小，尤其是在大型模型中。

**AI_Comments:** 这篇论文探讨了数据投毒与方言偏见这一关键且未被充分探索的交叉点，揭示了看似微小的攻击如何加剧大型语言模型中既有的社会不平等。利用GPT-4o作为审计器是一种有趣的方法学选择。研究结果强调了开发更健壮、更具社会责任感的AI实践的紧迫性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在促进包容性和平衡响应方面不断改进，但这些系统仍然容易编码和放大社会偏见。本研究旨在探讨方言变异（特别是非洲裔美国人白话英语（AAVE）与标准美式英语（SAE））如何与数据投毒相互作用，从而影响输出的毒性。

**Method:** 研究使用了小型和中型LLaMA模型，并采用GPT-4o作为公平性审计器来评估差异。

**Result:** 即使是极少量的投毒数据，也会显著增加AAVE输入的毒性，而对SAE的影响相对较小。更大的模型表现出更显著的放大效应。GPT-4o识别出与AAVE输入不成比例地相关的有害刻板印象模式，包括攻击性、犯罪性和智力低下等。

**Conclusion:** 数据投毒和方言偏见具有复合影响，这强调了在开发过程中需要进行方言感知评估、有针对性的去偏干预以及对社会负责的训练协议。

> **ai_Abstract:** 本研究探讨了小规模数据投毒如何加剧大型语言模型中与方言相关的偏见，特别关注非洲裔美国人白话英语（AAVE）与标准美式英语（SAE）之间的差异。研究发现，即使是极少量的投毒数据，也会显著增加LLaMA模型中AAVE输入的毒性，且在更大模型中效果更明显。通过GPT-4o作为公平性审计器，揭示了与AAVE输入不成比例地相关的有害刻板印象。这些发现强调了数据投毒和方言偏见的复合影响，并呼吁在LLM开发中进行方言感知评估和有针对性的去偏干预。

> **摘要翻译:** 尽管大型语言模型（LLMs）在促进包容性和平衡响应方面不断改进，但这些系统仍然容易编码和放大社会偏见。本研究探讨了方言变异，特别是非洲裔美国人白话英语（AAVE）与标准美式英语（SAE），如何与数据投毒相互作用，从而影响输出的毒性。我们使用小型和中型LLaMA模型，结果表明即使是极少量的投毒数据，也会显著增加AAVE输入的毒性，而对SAE的影响相对较小。更大的模型表现出更显著的放大效应，这表明随着模型规模的增大，易感性会提高。为了进一步评估这些差异，我们聘请了GPT-4o作为公平性审计器，它识别出与AAVE输入不成比例地相关的有害刻板印象模式，包括攻击性、犯罪性和智力低下。这些发现强调了数据投毒和方言偏见的复合影响，并强调了在开发过程中进行方言感知评估、有针对性的去偏干预以及对社会负责的训练协议的必要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [245] [How do language models learn facts? Dynamics, curricula and hallucinations](https://arxiv.org/abs/2503.21676)
> *语言模型如何学习事实？动力学、课程与幻觉*

*Nicolas Zucchet, Jörg Bornschein, Stephanie Chan, Andrew Lampinen, Razvan Pascanu, Soham De* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 语言模型, 知识获取, 学习动态, 幻觉, 数据分布

**Comment:** Accepted at the 2nd Conference on Language Modeling (2025)

> **TL;DR:** 本文研究了语言模型学习事实的动态过程，发现学习分为三个阶段，训练数据分布会影响学习，并且幻觉与知识同时出现，微调新知识会损害现有记忆。

**AI_Comments:** 这项研究通过揭示语言模型学习事实的三个阶段及其机制，特别是性能平台期与注意力电路形成的关系，提供了对LLM内部知识获取过程的宝贵洞察。强调数据分布对学习动态和幻觉产生的影响，对于指导未来模型训练和减轻幻觉问题具有重要意义。同时，指出了微调整合新知识可能破坏现有记忆的挑战，为增量学习和知识编辑研究提供了新的方向。其创新性在于深入分析了学习动态的微观机制，并提出了数据调度策略的潜在应用。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在预训练期间积累了大量知识，但控制这种知识获取的动态机制尚不清楚。

**Method:** 本文通过一个合成事实回忆任务来研究语言模型的学习动态。

**Result:** 1. 语言模型以三个阶段学习，在获得精确事实知识之前会经历一个性能平台期，此平台期与支持回忆的基于注意力的电路形成同时发生。2. 训练数据分布显著影响学习动态，不平衡的分布导致更短的平台期。3. 幻觉与知识同时出现，并且通过微调将新知识整合到模型中具有挑战性，因为它会迅速破坏其现有的参数记忆。

**Conclusion:** 研究结果强调了数据分布在知识获取中的重要性，并提出了加速神经网络训练的新型数据调度策略。

> **ai_Abstract:** 本文通过合成事实回忆任务，深入探究了大型语言模型学习事实的动态过程。研究发现，模型的知识获取分为三个阶段，并存在一个与注意力机制形成相关的性能平台期。同时，训练数据分布对学习动态有显著影响，不平衡数据可缩短平台期。此外，研究揭示幻觉与知识同步产生，且通过微调整合新知识容易损害模型既有记忆。这些发现强调了数据分布在知识获取中的关键作用，并为优化神经网络训练提出了新的数据调度策略。

> **摘要翻译:** 大型语言模型在预训练期间积累了大量的知识，但控制这种获取的动态过程仍然知之甚少。这项工作研究了语言模型在合成事实回忆任务上的学习动态，揭示了三个关键发现：首先，语言模型分三个阶段学习，在获取精确的事实知识之前表现出性能平台期。从机制上讲，这个平台期与支持回忆的基于注意力的电路的形成同时发生。其次，训练数据分布显著影响学习动态，因为不平衡的分布导致更短的平台期。最后，幻觉与知识同时出现，并且通过微调将新知识整合到模型中具有挑战性，因为它会迅速破坏其现有的参数记忆。我们的结果强调了数据分布在知识获取中的重要性，并提出了加速神经网络训练的新型数据调度策略。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [254] [ExpliCa: Evaluating Explicit Causal Reasoning in Large Language Models](https://arxiv.org/abs/2502.15487)
> *ExpliCa: 评估大型语言模型中的显式因果推理*

*Martina Miliani, Serena Auriemma, Alessandro Bondielli, Emmanuele Chersoni, Lucia Passaro, Irene Sucameli, Alessandro Lenci* | **Category: cs.CL, cs.AI, 68T50, 68T07, I.2.7** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 因果推理, 数据集, ExpliCa, 时间关系

**Comment:** Accepted for publication in Findings of ACL 2025

> **TL;DR:** 本文介绍了ExpliCa数据集，用于评估大型语言模型在显式因果推理方面的能力。研究发现，即使是顶级模型也难以达到高准确率，并且容易混淆因果关系与时间关系，性能也受语言顺序影响。

**AI_Comments:** ExpliCa数据集的创新之处在于其整合了因果和时间关系，并考虑了语言顺序，这对于深入理解LLM的推理机制至关重要。研究揭示了当前LLM在显式因果推理方面的局限性，特别是混淆时间与因果关系的问题，这为未来的模型改进提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）越来越多地应用于需要解释和推理准确性的任务中。因此，需要一个专门的数据集来评估LLM在显式因果推理方面的能力。

**Method:** 本文引入了一个名为ExpliCa的新数据集，用于评估LLM的显式因果推理能力。ExpliCa独特地整合了不同语言顺序呈现的因果和时间关系，并明确通过语言连接词表达。该数据集通过众包的人类可接受性评分进行了丰富。研究通过提示和基于困惑度的指标测试了LLM，并评估了七个商业和开源LLM。

**Result:** 研究发现，即使是顶级模型也很难达到0.80的准确率。有趣的是，模型倾向于将时间关系与因果关系混淆，并且它们的性能也受到事件语言顺序的强烈影响。最后，基于困惑度的分数和提示性能受模型大小的影响不同。

**Conclusion:** 大型语言模型在显式因果推理方面仍存在显著挑战，尤其是在区分因果和时间关系以及处理不同语言顺序方面。

> **ai_Abstract:** 本文介绍了ExpliCa数据集，旨在评估大型语言模型在显式因果推理方面的表现。该数据集结合了不同语言顺序的因果和时间关系，并包含人类评分。研究测试了多款LLM，发现即使是先进模型也难以达到高准确率，且易混淆因果与时间关系，性能受语言顺序显著影响。此外，模型大小对困惑度与提示性能的影响各异。

> **摘要翻译:** 大型语言模型（LLMs）越来越多地应用于需要解释和推理准确性的任务中。在本文中，我们介绍了ExpliCa，这是一个用于评估LLMs显式因果推理能力的新数据集。ExpliCa独特地整合了以不同语言顺序呈现并通过语言连接词明确表达的因果和时间关系。该数据集通过众包的人类可接受性评分得到了丰富。我们通过提示和基于困惑度的指标在ExpliCa上测试了LLMs。我们评估了七个商业和开源LLMs，结果显示即使是顶级模型也很难达到0.80的准确率。有趣的是，模型倾向于将时间关系与因果关系混淆，并且它们的性能也受到事件语言顺序的强烈影响。最后，基于困惑度的分数和提示性能受模型大小的影响不同。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [259] [ylmmcl at Multilingual Text Detoxification 2025: Lexicon-Guided Detoxification and Classifier-Gated Rewriting](https://arxiv.org/abs/2507.18769)
> *ylmmcl 在 2025 年多语言文本去毒化：词典引导的去毒化和分类器门控重写*

*Nicole Lai-Lopez, Lusha Wang, Su Yuan, Liza Zhang* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 多语言文本去毒化, 词典引导, 分类器门控, 序列到序列模型, PAN-2025

**Comment:** 16 pages, 5 figures, 3 tables,

> **TL;DR:** ylmmcl 团队提出了一个多语言文本去毒化方案，结合词典引导标记、微调的序列到序列模型和分类器门控机制，在 PAN-2025 竞赛中表现优异。

**AI_Comments:** 本文的创新点在于结合了词典引导的显式毒性词汇标注与分类器门控机制，为多语言文本去毒化提供了一个鲁棒且精确的解决方案。与传统的无监督或单语言方法相比，这种集成方法有望提高去毒化的精度和跨语言泛化能力，尤其是在处理多语言文本时具有重要意义。尽管在 SIM 上存在权衡，但其在去毒化强度上的持续改进表明了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 针对现有的无监督或单语言去毒化管道的不足，作者旨在通过利用多语言毒性词汇表进行精确的毒性词汇标注，以实现更高精度和跨语言泛化能力的文本去毒化。

**Method:** 提出了一种鲁棒的多语言文本去毒化管道，该管道集成了词典引导的标记（通过 multilingual_toxic_lexicon）、一个微调的序列到序列模型（s-nlp/mt0-xl-detox-orpo）以及一个迭代的基于分类器的门控机制。

**Result:** 最终模型获得了最高的 STA (0.922)，开发和测试集上的有毒输入平均官方 J 分为 0.612。xCOMET 分数分别为 0.793 (开发集) 和 0.787 (测试集)。性能优于多种语言的基线和回译方法，并在高资源环境下（英语、俄语、法语）表现出强大的泛化能力。

**Conclusion:** 该模型在去毒化强度方面表现出持续改进，尽管在 SIM 方面存在一些权衡。在 PAN-2025 竞赛中，ylmmcl 团队以 0.612 的分数获得了第九名。

> **ai_Abstract:** 本文介绍了 ylmmcl 团队在 PAN-2025 多语言文本去毒化任务中的解决方案。该方案是一个集成了词典引导标记、微调的序列到序列模型和迭代分类器门控机制的管道。它通过利用多语言毒性词汇表进行精确标注，克服了现有无监督或单语言方法的局限。实验结果表明，该模型在 STA、J 分和 xCOMET 等指标上表现出色，优于基线方法，并在高资源语言中展现出良好的泛化能力，最终在竞赛中获得第九名。

> **摘要翻译:** 在本文中，我们介绍了 ylmmcl 团队在 PAN-2025 竞赛中多语言文本去毒化任务的解决方案：一个鲁棒的多语言文本去毒化管道，它集成了词典引导的标记、一个微调的序列到序列模型 (s-nlp/mt0-xl-detox-orpo) 和一个迭代的基于分类器的门控机制。我们的方法通过利用 multilingual_toxic_lexicon 进行显式毒性词汇标注，从而以更高的精度和跨语言泛化能力指导去毒化，这与之前的无监督或单语言管道不同。我们的最终模型从之前的尝试中获得了最高的 STA (0.922)，并且在开发和测试集上的有毒输入平均官方 J 分为 0.612。它还获得了 0.793 (开发集) 和 0.787 (测试集) 的 xCOMET 分数。这种性能优于多种语言的基线和回译方法，并在高资源环境下（英语、俄语、法语）表现出强大的泛化能力。尽管在 SIM 方面存在一些权衡，但该模型在去毒化强度方面表现出持续改进。在竞赛中，我们团队以 0.612 的分数获得了第九名。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [285] [How Much Do Large Language Model Cheat on Evaluation? Benchmarking Overestimation under the One-Time-Pad-Based Framework](https://arxiv.org/abs/2507.19219)
> *大型语言模型在评估中作弊了多少？基于一次性密码本框架的过高估计基准测试*

*Zi Liang, Liantong Yu, Shiyu Zhang, Qingqing Ye, Haibo Hu* | **Category: cs.CL, cs.CR** | **Updated: 2025-07-25**

**Keywords:** 大型语言模型, 评估, 过高估计, 动态基准, 一次性密码本

**Comment:** Source code: https://github.com/liangzid/ArxivRoll/ Website:
  https://arxivroll.moreoverai.com/

> **TL;DR:** 大型语言模型（LLMs）评估存在过高估计问题。本文提出了ArxivRoll，一个基于一次性密码本的动态评估框架，用于生成新的测试用例并量化污染，以提供更公平、可重复的评估。

**AI_Comments:** 这篇论文提出了一种新颖的、基于密码学“一次性密码本”思想的动态评估框架ArxivRoll，以解决LLM评估中普遍存在的“作弊”或过高估计问题。其创新点在于通过定期生成新且私有的测试集（SCP）和量化污染的指标（Rugged Scores），有效提高了评估的公平性、透明度和时效性，对推动LLM的公正评估具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）评估中存在日益增长的过高估计问题，这源于公共基准的污染或不平衡的模型训练，导致不真实的评估结果，从而影响LLMs之间的公平比较和对其实际能力的评估。现有方法无法同时确保可重复性、透明度和高效率，且未能对当前LLMs中过高估计的程度进行量化。

**Method:** 本文提出了ArxivRoll动态评估框架，该框架灵感来源于密码学中的一次性密码本加密。ArxivRoll包含两个核心组件：i) SCP（Sequencing, Cloze, and Prediction），一个用于自动化生成私有测试用例的工具；ii) Rugged Scores (RS)，用于衡量公共基准污染和训练偏差的比例。利用SCP，ArxivRoll每六个月使用ArXiv上的最新文章构建新的基准，并将其用于LLM性能的一次性评估。

**Result:** 广泛的实验证明了所构建基准的高质量，并且提供了对当前LLMs的系统性评估。

**Conclusion:** ArxivRoll框架通过提供高质量、动态且系统化的基准测试，有效解决了大型语言模型评估中的过高估计问题，从而实现更公平、透明和高效的性能评估。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）评估中因数据污染或训练偏差导致的过高估计问题，提出了一种名为ArxivRoll的动态评估框架。该框架受一次性密码本启发，包含自动化私有测试用例生成器SCP和衡量污染与偏差的Rugged Scores。ArxivRoll利用ArXiv最新文章每半年生成新基准进行一次性评估，旨在提供更公平、可重复、透明且高效的LLM性能评估，并已通过实验验证其基准质量和系统评估能力。

> **摘要翻译:** 大型语言模型（LLMs）评估中的过高估计问题日益受到关注。由于公共基准的污染或不平衡的模型训练，LLMs在公共基准上可能会获得不真实的评估结果，无论是故意的还是无意的，这导致LLMs之间不公平的比较，并损害了它们实际能力的评估。现有基准试图通过永久保密测试用例、通过人工评估减轻污染或反复收集和构建新样本来解决这些问题。然而，这些方法无法同时确保可重复性、透明度和高效率。此外，当前LLMs中过高估计的程度仍未被量化。为了解决这些问题，我们提出了ArxivRoll，一个受密码学中一次性密码本加密启发的动态评估框架。ArxivRoll包含两个关键组件：i) SCP（Sequencing, Cloze, and Prediction），一个用于私有测试用例的自动化生成器；ii) Rugged Scores（RS），衡量公共基准污染和训练偏差比例的指标。利用SCP，ArxivRoll每六个月使用ArXiv上的最新文章构建新的基准，并将其用于LLM性能的一次性评估。广泛的实验证明了我们基准的高质量，并且我们提供了对当前LLMs的系统性评估。源代码可在https://github.com/liangzid/ArxivRoll/获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [286] [Evaluation of LLM Vulnerabilities to Being Misused for Personalized Disinformation Generation](https://arxiv.org/abs/2412.13666)
> *评估大型语言模型被滥用于生成个性化虚假信息的脆弱性*

*Aneta Zugecova, Dominik Macko, Ivan Srba, Robert Moro, Jakub Kopal, Katarina Marcincinova, Matus Mesarcik* | **Category: cs.CL, cs.AI, cs.CY** | **Updated: 2025-07-25**

**Keywords:** 大型语言模型, 虚假信息, 个性化, 脆弱性, 安全过滤器

**Comment:** ACL 2025 main

> **TL;DR:** 本研究评估了大型语言模型（LLMs）生成个性化虚假信息的脆弱性，发现现有安全过滤器不足，且个性化反而会降低安全过滤器激活，相当于一种越狱行为，急需开发者解决。

**AI_Comments:** 这篇论文揭示了一个关键且令人担忧的漏洞：个性化，通常是为了提升用户体验而设计的功能，却可能被利用来绕过安全措施，从而导致更有效的虚假信息生成。这一发现对于LLM的安全性和防护具有重要意义，提醒开发者在追求个性化能力的同时，必须高度重视其潜在的滥用风险。

<details>
  <summary>Details</summary>

**Motivation:** 近期大型语言模型（LLMs）生成高质量内容的能力引发了对其被滥用的担忧。以往研究表明LLMs可用于生成虚假新闻和个性化内容，但个性化与虚假信息结合的危险组合尚未得到全面研究。这种组合应触发LLMs的集成安全过滤器，但目前情况不明。

**Method:** 本研究通过评估近期开放和封闭的大型语言模型生成个性化英文虚假新闻文章的意愿和脆弱性来填补空白。此外，研究还探讨了LLMs是否能可靠地元评估个性化质量，以及个性化是否影响生成文本的可检测性。

**Result:** 结果表明需要更强大的安全过滤器和免责声明，因为大多数被评估的LLMs中这些功能并未正常运行。此外，研究发现个性化实际上降低了安全过滤器激活，从而有效地起到了越狱的作用。

**Conclusion:** 个性化降低安全过滤器激活的这种行为必须得到大型语言模型开发者和服务提供商的紧急解决。

> **ai_Abstract:** 本研究评估了大型语言模型（LLMs）生成个性化虚假信息的脆弱性。研究发现，尽管LLMs能生成高质量内容，但其安全过滤器在面对个性化虚假信息时表现不足。更令人担忧的是，个性化行为反而会降低安全过滤器激活，相当于一种“越狱”手段，使得LLMs更容易生成有害内容。这凸显了LLM开发者和提供商急需加强安全措施和免责声明以应对此严重漏洞。

> **摘要翻译:** 近期大型语言模型（LLMs）生成高质量内容且人类无法区分其与人类撰写文本的能力，引发了对其滥用的诸多担忧。以往研究表明，LLMs可以有效地被滥用于生成遵循预定叙事的虚假新闻文章。它们生成个性化（在各个方面）内容的能力也得到了评估，并且大多被认为可用。然而，LLMs的个性化和虚假信息生成能力的结合尚未得到全面研究。这种危险的组合应该触发LLMs的集成安全过滤器，如果存在的话。本研究通过评估近期开放和封闭LLMs的脆弱性，以及它们生成个性化英文虚假新闻文章的意愿来填补这一空白。我们进一步探讨了LLMs是否能可靠地元评估个性化质量，以及个性化是否影响生成文本的可检测性。我们的结果表明需要更强大的安全过滤器和免责声明，因为在大多数被评估的LLMs中，这些功能并未正常运行。此外，我们的研究揭示，个性化实际上降低了安全过滤器激活；因此有效地起到了越狱的作用。这种行为必须得到LLM开发者和服务提供商的紧急解决。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [316] [Comparison of pipeline, sequence-to-sequence, and GPT models for end-to-end relation extraction: experiments with the rare disease use-case](https://arxiv.org/abs/2311.13729)
> *管道、序列到序列和GPT模型在端到端关系抽取中的比较：以罕见病用例进行实验*

*Shashank Gupta, Xuguang Ai, Ramakanth Kavuluru* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 端到端关系抽取, 管道模型, 序列到序列模型, GPT模型, 罕见病, 生物医学NLP

**Comment:** An updated version of this paper has appeared in the proceedings of
  NLDB 2025 with a different title. The corresonding DOI is in the metadata
  provided below

> **TL;DR:** 在端到端关系抽取（E2ERE）中，研究表明传统的管道模型在有训练数据时表现最佳，优于序列到序列模型和更大的GPT模型，尤其是在罕见病数据集上。

**AI_Comments:** 这项研究通过在罕见病这一复杂且重要的生物医学用例上进行端到端关系抽取模型的比较，提供了宝贵的实践指导。其创新点在于首次将E2ERE应用于RareDis数据集，并对不同范式（包括GPT模型）进行了严格的对比和错误分析。研究结果挑战了大型生成模型在有监督E2ERE任务上的普遍优势认知，强调了传统管道模型在性能、成本和碳足迹方面的实用性。这对于资源有限的生物医学NLP应用具有重要意义。局限性在于，研究也指出需要更创新的方法来结合不同模型的优点，以进一步提升E2ERE的性能。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在比较三种主流的端到端关系抽取（E2ERE）范式在生物医学领域（特别是罕见病）中的表现，以评估它们在处理复杂数据集时的有效性。

**Method:** 作者评估了三种E2ERE方法：NER → RE 管道、联合序列到序列模型和生成式预训练Transformer (GPT) 模型。实验使用了RareDis信息抽取数据集，并在一组化学-蛋白质相互作用数据集上进行了验证。研究中使用了可比较的最新模型和最佳实践，并进行了错误分析。

**Result:** 研究发现，管道模型仍然是表现最好的，序列到序列模型紧随其后。GPT模型（参数量是前者的八倍）的表现甚至不如序列到序列模型，并且比管道模型低超过10个F1点。部分匹配和不连续实体导致了许多NER错误，从而降低了整体E2E性能。

**Conclusion:** 当有训练数据可用时，为E2ERE训练和定制的传统模型比生成式语言模型（更适合零样本设置）表现更好。需要更创新的方法来结合小型编解码管道模型和大型GPT模型的优点以改进E2ERE。目前，设计良好的管道模型在E2ERE中以更低的成本和碳足迹提供了显著的性能提升。

> **ai_Abstract:** 这篇论文比较了三种主流的端到端关系抽取（E2ERE）范式：NER → RE 管道、联合序列到序列模型和生成式GPT模型，特别是在处理罕见病领域的复杂生物医学文本时。研究发现，在有训练数据的情况下，传统的管道模型表现最优，其次是序列到序列模型，而参数量更大的GPT模型表现最差。论文强调，尽管生成式模型在零样本场景下有优势，但对于有训练数据的E2ERE任务，定制化的传统模型更有效，且成本和碳足迹更低。

> **摘要翻译:** 端到端关系抽取（E2ERE）是生物医学领域自然语言处理（NLP）的一项重要且实际的应用。在本文中，我们旨在比较E2ERE的三种主流范式，使用一个专注于罕见病的复杂数据集，该数据集涉及不连续和嵌套实体。我们使用RareDis信息抽取数据集来评估三种竞争性方法（用于E2ERE）：NER → RE 管道、联合序列到序列模型和生成式预训练Transformer (GPT) 模型。我们为每种方法使用可比较的最新模型和最佳实践，并进行错误分析以评估它们的失效模式。我们的研究结果表明，管道模型仍然是最好的，而序列到序列模型紧随其后；参数量是其八倍的GPT模型甚至比序列到序列模型更差，并且比管道模型低超过10个F1点。部分匹配和不连续实体导致了许多NER错误，从而降低了整体E2E性能。我们还在第二个用于化学-蛋白质相互作用的E2ERE数据集上验证了这些发现。尽管基于生成式语言模型的方法更适合零样本设置，但当有训练数据可用时，我们的结果表明，使用为E2ERE训练和定制的更传统模型会更好。需要更创新的方法来结合小型编解码管道模型和大型GPT模型的优点，以改进E2ERE。截至目前，我们认为设计良好的管道模型以更低的成本和碳足迹为E2ERE提供了显著的性能提升。我们的贡献也是首次对RareDis数据集进行E2ERE。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [319] [Evaluating Code-Mixing in LLMs Across 18 Languages](https://arxiv.org/abs/2507.18791)
> *评估大型语言模型在18种语言中的语码混用能力*

*Yilun Yang, Yekun Chai* | **Category: cs.CL** | **Updated: 2025-07-24**

**Keywords:** 语码混用, 大型语言模型, 多语言评估, 数据生成, GPT-4

**Comment:** 

> **TL;DR:** 本文全面评估了大型语言模型在18种语言语码混用数据上的表现，发现其性能不佳，并提出了一种新的语码混用文本生成方法。

**AI_Comments:** 本文通过对18种语言的语码混用能力进行全面评估，填补了现有LLM评估基准的空白，并提出了一种新颖的语码混用数据生成方法，具有重要的创新性。该研究揭示了LLMs在处理跨语系语码混用时的局限性，对未来多语言LLM的训练和发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的语码混用基准测试（如LinCE和GLUECoS）在语言配对和任务上存在局限性，未能充分评估大型语言模型（LLMs）的语码混用能力。尽管语码混用对多语言用户很重要，但在此背景下对LLMs的研究仍然有限。此外，当前的语码混用数据生成方法不完善。

**Method:** 本文对大型语言模型在来自七个语系的18种语言的语码混用数据上的表现进行了全面评估。此外，提出了一种结合词语替换和GPT-4提示来生成合成语码混用文本的新方法。

**Result:** 分析显示，大型语言模型在涉及多个语系的语码混用数据集上表现持续不佳。

**Conclusion:** 研究表明，可以通过增加训练数据量、扩大模型规模和改进少样本学习来提升大型语言模型在语码混用任务上的性能。

> **ai_Abstract:** 本研究全面评估了大型语言模型（LLMs）在七个语系的18种语言语码混用数据上的性能，发现LLMs在此类数据集上表现持续不佳。为解决现有语码混用基准和数据生成方法的不足，本文提出了一种结合词语替换和GPT-4提示的新型合成语码混用文本生成方法。研究结果强调了通过增加训练数据量、扩大模型规模和改进少样本学习来提升LLMs语码混用能力的重要性。

> **摘要翻译:** 语码混用，即在对话中切换语言的做法，给传统自然语言处理带来了独特的挑战。现有的基准测试，如LinCE和GLUECoS，受限于狭窄的语言配对和任务，未能充分评估大型语言模型（LLMs）的语码混用能力。尽管语码混用对多语言用户具有重要意义，但在此背景下对LLMs的研究仍然有限。此外，当前生成语码混用数据的方法尚不完善。在本文中，我们对LLMs在来自七个语系的18种语言的语码混用数据上的表现进行了全面评估。我们还提出了一种通过结合词语替换和GPT-4提示来生成合成语码混用文本的新方法。我们的分析揭示了LLMs在涉及多个语系的语码混用数据集上持续存在的性能不足。我们建议，训练数据量、模型规模和少样本学习的改进可以提高它们的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [327] [Jailbreaking Large Language Diffusion Models: Revealing Hidden Safety Flaws in Diffusion-Based Text Generation](https://arxiv.org/abs/2507.19227)
> *攻破大型语言扩散模型：揭示基于扩散的文本生成中的隐藏安全缺陷*

*Yuanhe Zhang, Fangzhou Xie, Zhenhong Zhou, Zherui Li, Hao Chen, Kun Wang, Yufei Guo* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 大型语言扩散模型, 越狱, 安全漏洞, 并行解码越狱, 有害内容生成

**Comment:** 

> **TL;DR:** 该研究揭示了大型语言扩散模型（LLDMs）的安全漏洞，并提出了一个名为PAD的新型越狱方法，该方法在实验中实现了97%的攻击成功率，并发现LLDMs生成有害内容的速度是自回归LLMs的两倍。

**AI_Comments:** 这篇论文的创新点在于首次系统性地揭示了大型语言扩散模型（LLDMs）的安全漏洞，并提出了一种针对扩散架构的有效越狱方法PAD。其重要性在于，在LLDMs日益普及的背景下，揭示其潜在的有害内容生成风险对于未来安全部署和开发至关重要。研究发现LLDMs生成有害内容的速度更快，这一发现对行业具有警示作用，提醒开发者和用户需要更加关注这类模型的安全防护。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言扩散模型（LLDMs）虽然在推理速度和数学推理任务上表现出色，但其精确和快速的生成能力加剧了有害内容生成的担忧。现有针对大型语言模型（LLMs）的越狱方法对LLDMs效果有限，未能暴露其安全漏洞。目前尚不清楚LLDMs是否具备安全鲁棒性，以及现有攻击是否与扩散架构不兼容，因此需要深入研究以揭示其漏洞。

**Method:** 为了解决LLDMs的安全漏洞问题，研究首先揭示了LLDMs对越狱攻击的脆弱性，并指出攻击失败源于其根本的架构差异。研究提出了一个名为“并行解码越狱”（PArallel Decoding jailbreak, PAD）的方法，专门针对基于扩散的语言模型。PAD引入了“多点注意力攻击”（Multi-Point Attention Attack），该方法受LLMs中肯定回复模式的启发，引导并行生成过程产生有害输出。

**Result:** 在对四种LLDMs进行的实验评估中，PAD实现了97%的越狱攻击成功率，揭示了显著的安全漏洞。此外，与同等大小的自回归LLMs相比，LLDMs生成有害内容的速度提高了2倍，这显著突出了不受控制滥用的风险。

**Conclusion:** 通过全面的分析，本研究对LLDM架构进行了深入探讨，为基于扩散的语言模型的安全部署提供了关键见解，并揭示了LLDMs在有害内容生成方面的显著安全漏洞和更高的风险。

> **ai_Abstract:** 本研究揭示了大型语言扩散模型（LLDMs）存在的安全漏洞，指出现有越狱方法对LLDMs无效的原因在于其架构差异。为此，论文提出了一种名为“并行解码越狱”（PAD）的新型越狱方法，该方法通过“多点注意力攻击”引导LLDMs生成有害内容。实验结果表明，PAD对LLDMs的越狱成功率高达97%，并且发现LLDMs生成有害内容的速度比同等大小的自回归LLMs快两倍，这凸显了LLDMs在安全部署方面面临的重大风险。

> **摘要翻译:** 大型语言扩散模型（LLDMs）表现出与大型语言模型（LLMs）相当的性能，同时在推理速度和数学推理任务方面具有独特的优势。LLDMs精确而快速的生成能力加剧了有害内容生成的担忧，而现有为LLMs设计的越狱方法对LLDMs的有效性有限，未能暴露其安全漏洞。成功的防御并不能明确解决有害内容生成的问题，因为目前尚不清楚LLDMs是否具备安全鲁棒性，或者现有攻击是否与基于扩散的架构不兼容。为了解决这个问题，我们首先揭示了LLDMs越狱的脆弱性，并证明LLDMs中攻击失败源于根本的架构差异。我们为基于扩散的语言模型提出了一种并行解码越狱（PAD）方法。PAD引入了多点注意力攻击，它通过LLM中肯定响应模式的启发，引导并行生成过程产生有害输出。对四种LLDMs的实验评估表明，PAD实现了97%的越狱攻击成功率，揭示了显著的安全漏洞。此外，与同等大小的自回归LLM相比，LLDMs有害内容生成速度提高了2倍，显著突出了不受控制滥用的风险。通过全面分析，我们对LLDM架构进行了调查，为基于扩散的语言模型的安全部署提供了关键见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [329] [Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning](https://arxiv.org/abs/2507.16802)
> *Agentar-Fin-R1：通过领域专业知识、训练效率和高级推理增强金融智能*

*Yanjun Zheng, Xiyang Du, Longfei Liao, Xiaoke Zhao, Zhaowen Zhou, Jingze Song, Bo Zhang, Jiawei Liu, Xiang Qi, Zhe Li, Zhiqiang Zhang, Wei Wang, Peng Zhang* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 金融大语言模型, Agentar-Fin-R1, 可信度, 金融智能, Finova基准

**Comment:** 

> **TL;DR:** Agentar-Fin-R1是一个基于Qwen3的金融大语言模型系列（8B和32B参数），通过整合高质量金融任务标签系统、多层可信度保证框架和优化训练流程，显著提升了金融应用中的推理、可靠性和领域专业化能力，并在多个金融和通用推理基准测试中达到了最先进的性能，同时提出了Finova评估基准以评估实际部署能力。

**AI_Comments:** 该论文的创新点在于提出了Agentar-Fin-R1系列金融大语言模型，并结合了系统化的金融任务标签、多层可信度保证框架和优化的训练策略，以解决现有LLMs在金融领域面临的特定挑战。其重要性体现在模型在金融和通用推理任务上均达到了SOTA性能，并引入了专为评估金融智能体而设计的Finova基准，这对于推动金融AI的实际部署和可信度至关重要。论文强调了可信度、领域专业知识和训练效率，这些都是高风险金融应用中的关键因素。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型在金融应用中，当面临需要复杂推理能力、严格可信度标准以及高效适应特定领域需求时，经常表现出局限性。

**Method:** 引入了基于Qwen3基础模型构建的Agentar-Fin-R1系列金融大语言模型（8B和32B参数）。优化方法整合了高质量、系统化的金融任务标签系统和全面的多层可信度保证框架，包括高质量可信知识工程、多智能体可信数据合成和严格的数据验证治理。通过标签引导的自动化难度感知优化、两阶段训练流程和动态归因系统，实现了训练效率的显著提升。模型在Fineva、FinEval和FinanceIQ等主流金融基准以及MATH-500和GPQA-diamond等通用推理数据集上进行了全面评估。还提出了Finova评估基准，专注于智能体级别的金融推理和合规性验证。

**Result:** Agentar-Fin-R1不仅在金融任务上取得了最先进的性能，而且展现出卓越的通用推理能力。

**Conclusion:** Agentar-Fin-R1被证实是高风险金融应用中一个值得信赖且有效的解决方案。

> **ai_Abstract:** Agentar-Fin-R1是针对金融领域开发的大语言模型系列，旨在解决现有LLMs在金融应用中面临的复杂推理、可信度和领域适应性挑战。该系列模型基于Qwen3构建，通过结合高质量金融任务标签系统、多层可信度保证框架（包括知识工程、数据合成和验证）以及优化的两阶段训练流程，显著提升了训练效率、推理能力和可靠性。模型在主流金融及通用推理基准测试中表现出色，达到了最先进水平。此外，研究还引入了Finova评估基准，专门用于评估智能体级金融推理和合规性验证，进一步验证了Agentar-Fin-R1作为高风险金融应用中可信赖解决方案的有效性。

> **摘要翻译:** 大语言模型（LLMs）在金融应用中展现出巨大的潜力；然而，现有模型在面对需要复杂推理能力、严格可信度标准以及高效适应特定领域需求的场景时，经常表现出局限性。我们引入了Agentar-Fin-R1系列金融大语言模型（8B和32B参数），其基于Qwen3基础模型专门设计，旨在增强金融应用的推理能力、可靠性和领域专业化。我们的优化方法整合了高质量、系统化的金融任务标签系统与全面的多层可信度保证框架。该框架涵盖高质量可信知识工程、多智能体可信数据合成和严格的数据验证治理。通过标签引导的自动化难度感知优化、两阶段训练流程和动态归因系统，我们实现了训练效率的显著提升。我们的模型在包括Fineva、FinEval和FinanceIQ在内的主流金融基准以及MATH-500和GPQA-diamond等通用推理数据集上进行了全面评估。为了全面评估实际部署能力，我们创新性地提出了Finova评估基准，该基准专注于智能体级别的金融推理和合规性验证。实验结果表明，Agentar-Fin-R1不仅在金融任务上取得了最先进的性能，而且展现出卓越的通用推理能力，验证了其作为高风险金融应用中值得信赖解决方案的有效性。Finova基准可在https://github.com/antgroup/Finova获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [332] [HIVMedQA: Benchmarking large language models for HIV medical decision support](https://arxiv.org/abs/2507.18143)
> *HIVMedQA：基准测试大型语言模型在艾滋病医疗决策支持中的应用*

*Gonzalo Cardenal-Antolin, Jacques Fellay, Bashkim Jaha, Roger Kouyos, Niko Beerenwinkel, Diane Duroux* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-25**

**Keywords:** 大型语言模型, 艾滋病, 基准测试, 医疗决策支持, HIVMedQA

**Comment:** 

> **TL;DR:** 本研究引入了HIVMedQA基准，评估了大型语言模型在艾滋病医疗问答中的能力，发现Gemini 2.5 Pro表现最佳，但模型仍面临复杂问题和认知偏差的挑战。

**AI_Comments:** 这项研究的创新之处在于其引入了HIVMedQA，这是一个专门为评估LLMs在艾滋病护理中表现而设计的基准测试，填补了该领域研究的空白。其重要性在于对当前LLM在复杂医疗场景下的能力进行了全面且深入的评估，并揭示了LLM在医学推理、理解复杂问题以及避免认知偏见方面的局限性。这些发现对于指导未来LLM在医疗领域的开发和安全部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）正成为支持临床医生日常决策的重要工具。艾滋病管理因其复杂性（包括多样的治疗方案、合并症和依从性挑战）而成为一个引人注目的应用案例。然而，将LLMs整合到临床实践中引发了对其准确性、潜在危害和临床医生接受度的担忧。尽管前景广阔，但AI在艾滋病护理中的应用仍未得到充分探索，且LLM基准测试研究稀缺。本研究旨在评估LLMs在艾滋病管理中的现有能力，突出其优缺点。

**Method:** 本研究引入了HIVMedQA，这是一个旨在评估艾滋病护理中开放式医疗问题回答能力的基准测试。数据集包含与传染病医生合作开发的精选、临床相关问题。我们评估了七个通用型和三个医学专业型LLM，并应用了提示工程来提高性能。我们的评估框架结合了词汇相似性方法和“LLM作为评判者”的方法，并进行了扩展以更好地反映临床相关性。我们从问题理解、推理、知识回忆、偏见、潜在危害和事实准确性等关键维度评估了性能。

**Result:** 结果显示，Gemini 2.5 Pro在大多数维度上始终优于其他模型。值得注意的是，排名前三的模型中有两个是专有模型。随着问题复杂性的增加，模型性能下降。医学微调模型并非总是优于通用模型，并且更大的模型大小并非性能的可靠预测指标。推理和理解比事实回忆更具挑战性，并且观察到了近期效应和现状偏见等认知偏差。

**Conclusion:** 这些发现强调了需要有针对性的开发和评估，以确保LLM安全有效地整合到临床护理中。

> **ai_Abstract:** 本研究旨在评估大型语言模型（LLMs）在艾滋病医疗决策支持中的能力，以应对艾滋病管理复杂性及当前LLM基准测试的稀缺性。为此，研究团队构建了HIVMedQA，一个包含临床相关问题的基准测试数据集，并评估了七个通用型和三个医学专业型LLMs。评估采用词汇相似性和“LLM作为评判者”的方法，涵盖问题理解、推理、知识回忆、偏见、潜在危害和事实准确性等维度。结果显示，Gemini 2.5 Pro表现最佳，但LLMs在处理复杂问题和推理方面仍有不足，且存在认知偏差。研究强调，需针对性开发和评估以确保LLM安全有效地应用于临床护理。

> **摘要翻译:** 大型语言模型（LLMs）正成为支持临床医生日常决策的重要工具。艾滋病管理因其复杂性，包括多样的治疗方案、合并症和依从性挑战，而成为一个引人注目的用例。然而，将LLMs整合到临床实践中引发了对其准确性、潜在危害和临床医生接受度的担忧。尽管前景广阔，但AI在艾滋病护理中的应用仍未得到充分探索，且LLM基准测试研究稀缺。本研究旨在评估LLMs在艾滋病管理中的现有能力，突出其优缺点。我们引入了HIVMedQA，这是一个旨在评估艾滋病护理中开放式医疗问题回答能力的基准测试。数据集包含与传染病医生合作开发的精选、临床相关问题。我们评估了七个通用型和三个医学专业型LLM，并应用了提示工程来提高性能。我们的评估框架结合了词汇相似性方法和“LLM作为评判者”的方法，并进行了扩展以更好地反映临床相关性。我们从问题理解、推理、知识回忆、偏见、潜在危害和事实准确性等关键维度评估了性能。结果显示，Gemini 2.5 Pro在大多数维度上始终优于其他模型。值得注意的是，排名前三的模型中有两个是专有模型。随着问题复杂性的增加，模型性能下降。医学微调模型并非总是优于通用模型，并且更大的模型大小并非性能的可靠预测指标。推理和理解比事实回忆更具挑战性，并且观察到了近期效应和现状偏见等认知偏差。这些发现强调了需要有针对性的开发和评估，以确保LLM安全有效地整合到临床护理中。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [333] [GIIFT: Graph-guided Inductive Image-free Multimodal Machine Translation](https://arxiv.org/abs/2507.18562)
> *GIIFT：图引导归纳式无图像多模态机器翻译*

*Jiafeng Xiong, Yuting Zhao* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 多模态机器翻译, 图神经网络, 无图像推理, 归纳泛化, 场景图

**Comment:** 

> **TL;DR:** GIIFT是一个新的两阶段图引导框架，用于多模态机器翻译，它通过学习跨模态知识，实现了在推理时无需图像也能达到最先进的性能。

**AI_Comments:** GIIFT的创新点在于其“无图像推理”能力，这极大地拓展了多模态机器翻译的实际应用范围，克服了传统MMT对图像输入的依赖。通过引入图结构和归纳泛化能力，它有效地弥补了模态间隙，并提高了模型的通用性，具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有MMT方法在利用模态间隙方面面临挑战，因为它们强制执行严格的视觉-语言对齐，并且仅限于在其训练的多模态域内进行推理。

**Method:** 本文提出了GIIFT，一个两阶段的图引导归纳式无图像多模态机器翻译（MMT）框架。该方法通过构建新颖的多模态场景图来保留和整合模态特定信息，并使用一个跨模态图注意力网络适配器在统一的融合空间中学习多模态知识，从而能够归纳泛化到更广泛的无图像翻译领域。

**Result:** 在Multi30K数据集的英译法和英译德任务上，GIIFT超越了现有方法并达到了最先进的水平，即使在推理时没有图像。在WMT基准测试中，相对于无图像翻译基线有显著改进。

**Conclusion:** GIIFT在归纳式无图像推理方面表现出强大的能力。

> **ai_Abstract:** 本文提出了GIIFT，一个图引导归纳式无图像多模态机器翻译框架，旨在解决现有MMT方法在模态间隙和推理域限制上的挑战。GIIFT通过构建多模态场景图和使用跨模态图注意力网络适配器，在统一空间中学习多模态知识，并能归纳泛化到无图像翻译。实验证明，GIIFT在Multi30K和WMT数据集上均超越现有方法，实现了无图像推理下的SOTA性能。

> **摘要翻译:** 多模态机器翻译（MMT）已证明视觉信息在机器翻译中的显著帮助。然而，现有的MMT方法在利用模态间隙方面面临挑战，因为它们强制执行严格的视觉-语言对齐，并且局限于在其训练的多模态域内进行推理。在这项工作中，我们构建了新颖的多模态场景图，以保留和整合模态特定信息，并引入GIIFT，一个两阶段的图引导归纳式无图像MMT框架，该框架使用跨模态图注意力网络适配器在统一的融合空间中学习多模态知识，并将其归纳泛化到更广泛的无图像翻译领域。在Multi30K数据集的英译法和英译德任务上的实验结果表明，我们的GIIFT超越了现有方法并达到了最先进的水平，即使在推理时没有图像。WMT基准测试的结果显示，相对于无图像翻译基线有显著改进，这证明了GIIFT在归纳式无图像推理方面的强大能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [346] [Identity-related Speech Suppression in Generative AI Content Moderation](https://arxiv.org/abs/2409.13725)
> *生成式AI内容审核中的身份相关言论压制*

*Grace Proebsting, Oghenefejiro Isaacs Anigboro, Charlie M. Crawford, Danaé Metaxa, Sorelle A. Friedler* | **Category: cs.CL, cs.CY, cs.HC** | **Updated: 2025-07-24**

**Keywords:** 身份相关言论, 生成式AI, 内容审核, 言论压制, 偏见

**Comment:** ACM Conference on Equity and Access in Algorithms, Mechanisms, and
  Optimization, 2025

> **TL;DR:** 本文研究发现，生成式AI内容审核系统更容易错误地压制与特定身份群体相关的言论，且压制原因因身份而异，这可能限制了身份相关内容的创作。

**AI_Comments:** 本文揭示了生成式AI内容审核系统中存在的偏见问题，特别是对边缘化身份群体言论的错误压制，具有重要的社会和技术意义。其创新之处在于定义了言论压制衡量标准并构建了专门的基准数据集。研究结果对AI伦理和负责任的AI开发提供了重要警示。

<details>
  <summary>Details</summary>

**Motivation:** 自动化内容审核系统长期以来错误地标记和移除边缘化身份群体的内容。随着生成式AI系统越来越多地用于创意和表达性文本生成，这些系统沿用了此类过滤器，导致适当的文本被压制。本研究旨在探讨这些技术将允许谁的故事被讲述，又将压制谁的故事。

**Method:** 本文定义并引入了言论压制（speech suppression）的衡量标准，重点关注被内容审核API错误过滤的与不同身份群体相关的言论。研究使用了传统的短篇用户生成数据集和更长的生成式AI专用数据（包括本文引入的两个新数据集），为九个身份群体的言论压制测量创建了一个基准。研究测试了一个传统和四个生成式AI内容审核服务。

**Result:** 研究发现，身份相关的言论比其他言论更容易被错误地压制。错误标记行为的原因因身份而异，基于刻板印象和文本关联，例如，与残疾相关的内容更容易因自残或健康原因被标记，而非基督教内容则更容易被标记为暴力或仇恨。

**Conclusion:** 随着生成式AI系统越来越多地用于创意工作，我们呼吁进一步关注这可能如何影响身份相关内容的创作。

> **ai_Abstract:** 本研究探讨了生成式AI内容审核中存在的身份相关言论压制问题。作者定义了言论压制衡量标准，并利用新旧数据集构建了一个基准，测试了多个内容审核服务。结果表明，与身份相关的言论更容易被错误地压制，且压制原因与刻板印象相关。论文呼吁业界关注生成式AI对身份相关内容创作的潜在负面影响。

> **摘要翻译:** 自动化内容审核系统长期以来一直被用于识别和过滤在线不良用户生成内容。但这些系统在错误标记和移除边缘化身份群体内容方面有历史记录。生成式AI系统现在使用此类过滤器来阻止不良生成内容被创建或展示给用户。虽然许多关注点放在确保此类系统不会产生不良结果上，但对于确保生成适当文本的关注却少得多。从教室到好莱坞，随着生成式AI越来越多地用于创意或表达性文本生成，这些技术将允许谁的故事被讲述，又将压制谁的故事？
在本文中，我们定义并引入了言论压制（speech suppression）的衡量标准，重点关注一系列内容审核API错误过滤的与不同身份群体相关的言论。通过使用内容审核中传统的短篇用户生成数据集以及更长的生成式AI专用数据（包括我们在这项工作中引入的两个数据集），我们为九个身份群体的言论压制测量创建了一个基准。在测试的一个传统和四个生成式AI自动化内容审核服务中，我们发现身份相关的言论比其他言论更容易被错误地压制。我们发现错误标记行为的原因因身份而异，基于刻板印象和文本关联，例如，与残疾相关的内容更容易因自残或健康原因被标记，而非基督教内容则更容易被标记为暴力或仇恨。随着生成式AI系统越来越多地用于创意工作，我们敦促进一步关注这可能如何影响身份相关内容的创作。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [356] [Spike No More: Stabilizing the Pre-training of Large Language Models](https://arxiv.org/abs/2312.16903)
> *不再出现尖峰：稳定大型语言模型的预训练*

*Sho Takase, Shun Kiyono, Sosuke Kobayashi, Jun Suzuki* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-25**

**Keywords:** 损失尖峰, 大型语言模型, 预训练, 梯度范数, 稳定性

**Comment:** COLM 2025

> **TL;DR:** 大型语言模型预训练中常出现损失尖峰，本文通过分析发现“小子层”和“大跳跃连接”是稳定预训练、防止尖峰的关键条件。

**AI_Comments:** 本文针对大型语言模型预训练中的一个关键实际问题——损失尖峰，提供了深入的理论分析和实证验证。其创新之处在于将损失尖峰归因于梯度范数增长，并从模型架构层面（小尺寸子层、大跳跃连接）提出了具体的解决方案。这对于优化LLM训练效率和稳定性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型预训练过程中经常出现损失尖峰，这些尖峰会降低模型性能，有时甚至会毁掉整个预训练过程。鉴于预训练需要巨大的计算预算，因此有必要避免此类尖峰。

**Method:** 本文基于损失尖峰是由梯度范数突然增长引起的假设，通过分析子层雅可比矩阵的谱范数，探索了保持梯度范数较小的因素。研究人员还进行了各种实验，以经验性地验证其理论分析。

**Result:** 研究发现，稳定预训练过程需要两个条件：小尺寸子层和大的跳跃连接。实验结果表明，满足这些条件的方法能有效防止预训练期间的损失尖峰。

**Conclusion:** 通过确保使用小尺寸子层和大的跳跃连接，可以有效防止大型语言模型预训练中的损失尖峰，从而稳定预训练过程。

> **ai_Abstract:** 大型语言模型预训练中常见的损失尖峰会严重影响模型性能并耗费大量计算资源。本文假设尖峰源于梯度范数的突然增长，并通过分析子层雅可比矩阵的谱范数，提出稳定预训练需要“小尺寸子层”和“大跳跃连接”这两个条件。实验验证了满足这些条件的方法能有效防止损失尖峰。

> **摘要翻译:** 大型语言模型预训练过程中经常出现损失尖峰。这些尖峰会降低大型语言模型的性能，有时甚至会毁掉整个预训练过程。鉴于预训练需要巨大的计算预算，我们应该避免此类尖峰。基于损失尖峰是由梯度范数突然增长引起的假设，我们通过分析子层雅可比矩阵的谱范数，探索了保持梯度范数较小的因素。我们的发现表明，稳定预训练过程需要两个条件：小尺寸子层和大的跳跃连接。我们进行了各种实验以经验性地验证我们的理论分析。实验结果表明，满足这些条件的方法能有效防止预训练期间的损失尖峰。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [369] [Identifying Fine-grained Forms of Populism in Political Discourse: A Case Study on Donald Trump's Presidential Campaigns](https://arxiv.org/abs/2507.19303)
> *识别政治话语中民粹主义的细粒度形式：以唐纳德·特朗普总统竞选为例*

*Ilias Chalkidis, Stephanie Brandl, Paris Aslanidis* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 大型语言模型, 民粹主义, 政治话语, RoBERTa, 特朗普

**Comment:** Pre-print

> **TL;DR:** 本研究探讨大型语言模型（LLMs）识别细粒度民粹主义的能力。通过创建新数据集并评估多种LLMs，发现LLMs在检测民粹主义话语方面存在局限性，而微调的RoBERTa分类器表现更优。研究还应用于分析特朗普和欧洲政治家的演讲。

**AI_Comments:** 本文的创新之处在于其专注于LLMs在细致社会科学概念（如民粹主义）识别方面的应用，并为此创建了专门的新数据集。研究不仅揭示了当前LLMs在处理此类复杂任务时的局限性，也证明了通过特定任务微调（如RoBERTa）可以显著提升性能。此外，对特朗普和欧洲政治家演讲的案例研究，为政治话语分析提供了实际应用价值，并探讨了模型的跨语境泛化能力，这对于实际部署具有重要意义。局限性可能在于数据集的规模和多样性，以及LLMs在无微调情况下的性能差距。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在指令遵循任务中表现出色，但它们对细致的社会科学概念（如民粹主义）的理解尚未得到充分探索。本研究旨在探究LLMs是否能够识别和分类民粹主义的细粒度形式。

**Method:** 本研究构建并发布了专门用于捕捉民粹主义话语的新数据集。研究评估了多种预训练（大型）语言模型（包括开源和专有模型），并采用了多种提示范式。此外，还使用了微调的RoBERTa分类器进行比较。最后，将表现最佳的模型应用于分析唐纳德·特朗普的竞选演讲，并对欧洲政治家的竞选演讲进行基准测试，以评估模型的泛化能力。

**Result:** 分析显示，LLMs在检测民粹主义话语方面存在显著的性能差异和局限性。微调的RoBERTa分类器在未经微调的情况下，其性能远超所有新一代指令调优的LLMs。研究成功从特朗普的竞选演讲中提取了关于其民粹主义修辞策略的宝贵见解。在跨语境迁移性评估中，指令调优的LLMs在域外数据上表现出更强的鲁棒性。

**Conclusion:** 本研究探讨了大型语言模型在识别政治话语中细粒度民粹主义方面的能力和局限性。结果表明，尽管LLMs在处理此类复杂概念时面临挑战，但经过特定任务微调的模型（如RoBERTa）可以取得优异性能。同时，指令调优的LLMs在跨域泛化方面展现出潜力，为政治话语分析提供了新的工具和见解。

> **ai_Abstract:** 本研究旨在评估大型语言模型（LLMs）识别政治话语中细粒度民粹主义的能力。通过构建新数据集并测试多种LLMs，发现LLMs在检测民粹主义方面存在局限性，而微调的RoBERTa模型表现更佳。研究将最佳模型应用于分析唐纳德·特朗普的竞选演讲，揭示其民粹主义修辞策略，并进一步通过分析欧洲政治家演讲评估模型的跨语境泛化能力，发现指令调优的LLMs在域外数据上更具鲁棒性。

> **摘要翻译:** 大型语言模型（LLMs）在一系列指令遵循任务中展现出卓越的能力，然而它们对细致的社会科学概念的掌握仍未得到充分探索。本文探讨LLMs是否能够识别和分类民粹主义的细粒度形式，这是一个在学术和媒体辩论中都复杂且有争议的概念。为此，我们策划并发布了专门设计用于捕捉民粹主义话语的新颖数据集。我们评估了一系列预训练（大型）语言模型，包括开源和专有模型，并采用了多种提示范式。我们的分析揭示了性能上的显著差异，突显了LLMs在检测民粹主义话语方面的局限性。我们发现，一个经过微调的RoBERTa分类器在未经微调的情况下，其性能远远优于所有新一代指令调优的LLMs。此外，我们将表现最佳的模型应用于分析唐纳德·特朗普的竞选演讲，从中提取了关于其战略性使用民粹主义修辞的宝贵见解。最后，我们通过对欧洲政治家的竞选演讲进行基准测试来评估这些模型的泛化能力，为政治话语分析中的跨语境可迁移性提供了一个视角。在这种情况下，我们发现指令调优的LLMs在域外数据上表现出更强的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [374] [Sticking to the Mean: Detecting Sticky Tokens in Text Embedding Models](https://arxiv.org/abs/2507.18171)
> *趋于均值：检测文本嵌入模型中的“粘性”词元*

*Kexin Chen, Dongxia Wang, Yi Liu, Haonan Zhang, Wenhai Wang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 粘性词元, 文本嵌入, Transformer, 分词, 模型鲁棒性

**Comment:** ACL 2025 main

> **TL;DR:** 文本嵌入模型中存在“粘性词元”，它们会扭曲嵌入距离并降低下游任务性能。本文定义了这些词元，提出了STD检测方法，发现了大量粘性词元，并分析了其来源和对性能的影响，强调需要改进分词策略。

**AI_Comments:** 这项研究揭示了文本嵌入模型中一个之前未被充分认识到的重要问题——“粘性词元”。其创新之处在于首次系统地定义并提出了一种高效的检测方法（STD），并量化了其对下游任务的负面影响。这对于提高文本嵌入模型的可靠性和鲁棒性具有重要意义，尤其是在关注模型内部机制和分词策略的背景下。研究结果对未来的模型设计和分词优化提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Transformer文本嵌入模型广泛使用，但“粘性词元”会损害嵌入的可靠性，扭曲句子的相似性，并降低下游性能。因此，需要系统地调查这些异常词元。

**Method:** 本文系统地调查了异常词元，正式定义了它们，并引入了一种基于句子和词元过滤的高效检测方法，即粘性词元检测器（STD）。将STD应用于14个模型家族的40个检查点。

**Result:** 共发现了868个粘性词元。这些词元通常来源于词汇表中的特殊或未使用的条目，以及多语言语料库中的碎片化子词。它们的出现与模型大小或词汇量没有严格关联。粘性词元导致下游任务（如聚类和检索）的性能显著下降，最高达50%。通过注意力层分析，发现粘性词元在模型内部表示中占据主导地位。

**Conclusion:** 研究结果表明，未来的文本嵌入应用需要更好的分词策略和模型设计，以减轻粘性词元的影响。

> **ai_Abstract:** 本文研究了文本嵌入模型中的“粘性词元”，这些词元会扭曲嵌入空间并损害下游任务性能。研究者定义了粘性词元，并提出了高效的粘性词元检测器（STD），在多个模型中发现了大量此类词元。分析揭示了其来源（特殊或碎片化子词），并证实了它们对聚类和检索任务的显著负面影响。结果强调了改进分词策略和模型设计的必要性。

> **摘要翻译:** 尽管基于Transformer的文本嵌入模型在NLP任务中广泛使用，但令人惊讶的“粘性词元”可能会损害嵌入的可靠性。当这些词元被重复插入到句子中时，它们会使句子相似度趋向于某个特定值，从而扰乱嵌入距离的正常分布并降低下游性能。在本文中，我们系统地调查了此类异常词元，正式定义了它们，并引入了一种基于句子和词元过滤的高效检测方法，即粘性词元检测器（STD）。将STD应用于14个模型家族的40个检查点，我们共发现了868个粘性词元。我们的分析表明，这些词元通常来源于词汇表中的特殊或未使用的条目，以及多语言语料库中的碎片化子词。值得注意的是，它们的存在与模型大小或词汇量没有严格关联。我们进一步评估了粘性词元如何影响下游任务，如聚类和检索，观察到性能显著下降，最高达50%。通过注意力层分析，我们发现粘性词元在模型内部表示中占据主导地位，这引发了对分词鲁棒性的担忧。我们的研究结果表明，未来的文本嵌入应用需要更好的分词策略和模型设计，以减轻粘性词元的影响。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [375] [CueBuddy: helping non-native English speakers navigate English-centric STEM education](https://arxiv.org/abs/2507.18827)
> *CueBuddy：帮助非英语母语者适应以英语为中心的STEM教育*

*Pranav Gupta* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** STEM教育, 非英语母语者, 词汇提示, 多语言词汇表, 关键词识别

**Comment:** 

> **TL;DR:** CueBuddy通过实时词汇提示和多语言词汇表查询，帮助非英语母语的STEM学生理解英语专业术语。

**AI_Comments:** CueBuddy提供了一种新颖且实用的方法来解决非英语母语学生在英语STEM教育中遇到的语言障碍，尤其是在技术术语理解方面。其创新点在于结合了关键词识别和多语言词汇表查询，实现了非侵入式的实时辅助，避免了传统实时翻译的成本和技术内容处理难题。这种方法对于提高全球范围内非英语母语学生的STEM学习效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 全球各地的STEM学生，特别是来自全球南方的学生，尽管在科学先决条件方面与英语流利的同伴水平相当，却因为英语熟练度不足而落后。他们能轻松理解日常英语，但英语中的关键术语仍然具有挑战性。大多数情况下，这些学生在低资源语言环境中完成了大部分课程的先决条件。虽然实时语音翻译到低资源语言是一个有前景的研究领域，但大规模的语音翻译模型可能过于昂贵，并且在处理技术内容时往往表现不佳。

**Method:** 本文描述了CueBuddy系统，旨在通过实时技术关键词识别和实时多语言词汇表查询，提供“词汇提示”，帮助学生跟上复杂的英语专业术语，同时不干扰他们对讲座的注意力。

**Result:** 本文描述了CueBuddy系统，该系统通过提供实时的“词汇提示”，帮助非英语母语的STEM学生理解复杂的英语专业术语，而不会干扰他们对讲座的注意力。

**Conclusion:** 本文介绍了CueBuddy系统，旨在通过提供实时“词汇提示”来帮助非英语母语的STEM学生克服英语专业术语上的障碍。论文还讨论了该方法的局限性和未来的扩展方向。

> **ai_Abstract:** CueBuddy是一个旨在帮助非英语母语的STEM学生克服英语专业术语障碍的系统。针对现有实时语音翻译成本高且难以处理技术内容的局限性，CueBuddy通过实时识别讲座中的技术关键词并提供多语言词汇表查询，为学生提供即时“词汇提示”，使他们能够在不分散注意力的情况下理解复杂的英语术语。论文还讨论了该方法的局限性及未来的发展方向。

> **摘要翻译:** 全球各地的STEM学生，特别是来自全球南方的学生，尽管在科学先决条件方面与英语流利的同伴水平相当，却因为英语流利度不足而落后。虽然他们中的许多人能够轻松理解日常英语，但英语中的关键术语仍然具有挑战性。在大多数情况下，这些学生是在低资源语言环境中完成了大部分课程的先决条件。实时语音翻译到低资源语言是一个有前景的研究领域，然而，语音翻译模型大规模应用时可能过于昂贵，并且在处理技术内容时常常表现不佳。在本文中，我们描述了CueBuddy，它旨在通过实时技术关键词识别和实时多语言词汇表查询来提供“词汇提示”，从而帮助学生跟上复杂的英语专业术语，而不会干扰他们对讲座的注意力。我们还描述了我们方法的局限性和未来的扩展。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [376] [A Fisher's exact test justification of the TF-IDF term-weighting scheme](https://arxiv.org/abs/2507.15742)
> *TF-IDF词项加权方案的费舍尔精确检验合理性*

*Paul Sheridan, Zeyad Ahmed, Aitazaz A. Farooque* | **Category: cs.CL, cs.IR, math.ST, stat.TH** | **Updated: 2025-07-24**

**Keywords:** TF-IDF, 费舍尔精确检验, 词项加权, 统计显著性, 信息检索

**Comment:** 23 pages, 4 tables, accepted in The American Statistician 2025

> **TL;DR:** 本文通过将TF-IDF与费舍尔精确检验的p值联系起来，为TF-IDF词项加权方案提供了统计学上的合理性解释。

**AI_Comments:** 该论文为TF-IDF提供了一个新颖的统计学基础，使其超越了纯粹的启发式方法。这种与费舍尔精确检验的联系具有创新性，并提供了坚实的理论支持，这对于其在文本分析中的持续使用和发展至关重要。它弥合了经验成功与理论理解之间的鸿沟。

<details>
  <summary>Details</summary>

**Motivation:** 尽管TF-IDF在信息检索中广泛应用，但其缺乏坚实的理论基础。本文旨在从统计显著性检验的角度为其提供理论依据。

**Method:** 研究表明，在温和条件下，TF-ICF（一种TF-IDF变体）与单尾费舍尔精确检验p值的负对数密切相关。在理想化假设下，TF-IDF也与该负对数p值相关，并证明在无限大文档集合的极限情况下，该量收敛于TF-IDF。

**Result:** TF-ICF与单尾费舍尔精确检验p值的负对数密切相关。在特定理想化假设下，TF-IDF与该负对数p值存在联系。在文档集合无限大的极限情况下，该量收敛于TF-IDF。

**Conclusion:** 本文通过费舍尔精确检验为TF-IDF提供了统计学上的合理性，为统计学家解释了该词项加权方案长期有效的原因。

> **ai_Abstract:** 本文为广泛使用的TF-IDF词项加权方案提供了统计学上的合理性。研究表明，一种常见的TF-IDF变体TF-ICF与单尾费舍尔精确检验p值的负对数密切相关。该研究进一步在理想化条件下建立了TF-IDF与此p值之间的联系，并证明在大型文档集合中存在收敛性，从而为统计学界提供了TF-IDF有效性的理论基础。

> **摘要翻译:** 词频-逆文档频率，简称TF-IDF，可以说是信息检索史上最著名的数学表达式。TF-IDF及其众多变体被构想为一种简单的启发式方法，用于量化给定词项的出现频率在众多文档中集中于任何一个给定文档的程度，并在各种文本分析应用中作为词项加权方案被常规使用。越来越多的学术研究致力于将TF-IDF置于坚实的理论基础之上。本文在此传统之上，通过展示如何从显著性检验的角度理解这个著名表达式，从而向统计学界证明了TF-IDF使用的合理性。我们表明，在温和的正则性条件下，常见的TF-IDF变体TF-ICF与单尾费舍尔精确统计显著性检验的p值的负对数密切相关。作为推论，我们在某些理想化假设下建立了TF-IDF与上述负对数变换p值之间的联系。我们进一步证明，作为一种极限情况，当文档集合无限大时，这个量会收敛于TF-IDF。TF-IDF的费舍尔精确检验合理性为在职统计学家提供了一个现成的解释，阐明了该词项加权方案长期以来行之有效的原因。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [388] [OPeRA: A Dataset of Observation, Persona, Rationale, and Action for Evaluating LLMs on Human Online Shopping Behavior Simulation](https://arxiv.org/abs/2506.05606)
> *OPeRA：一个用于评估LLM在人类在线购物行为模拟中表现的观察、角色、理由和行动数据集*

*Ziyi Wang, Yuxuan Lu, Wenbo Li, Amirali Amini, Bo Sun, Yakov Bart, Weimin Lyu, Jiri Gesi, Tian Wang, Jing Huang, Yu Su, Upol Ehsan, Malihe Alikhani, Toby Jia-Jun Li, Lydia Chilton, Dakuo Wang* | **Category: cs.CL, cs.HC** | **Updated: 2025-07-24**

**Keywords:** LLMs, 在线购物, 数据集, 行为模拟, 数字孪生

**Comment:** 

> **TL;DR:** 引入OPeRA数据集，用于评估LLM模拟人类在线购物行为的能力，填补高质量公开数据集的空白。

**AI_Comments:** OPERA数据集的创新之处在于它是首个全面整合用户角色、浏览器观察、细粒度网络行为和即时理由的公开数据集，为LLM在模拟人类复杂行为方面的评估提供了急需的基准。这对于推动LLM成为个性化数字孪生代理的研究具有重要意义，填补了现有数据集的空白。

<details>
  <summary>Details</summary>

**Motivation:** 评估大型语言模型（LLMs）模仿真实用户行为的能力仍是一个开放的挑战，主要是因为缺乏捕捉可观察行为和内部推理的高质量、公开数据集。

**Method:** 引入了一个名为OPERA的新型数据集，该数据集从真实人类参与者的在线购物会话中收集了观察、角色、理由和行动。通过开发在线问卷和自定义浏览器插件来高保真地收集此数据集。

**Result:** 利用OPERA，建立了第一个基准，用于评估当前LLM在给定角色和<观察、行动、理由>历史的情况下，预测特定用户下一步行动和理由的能力。

**Conclusion:** 该数据集为未来旨在作为人类个性化数字孪生的LLM代理研究奠定了基础。

> **ai_Abstract:** 本文介绍了OPERA数据集，这是一个用于评估大型语言模型（LLMs）模拟人类在线购物行为能力的新型数据集。OPERA包含从真实用户收集的观察、角色、理由和行动数据，旨在解决当前缺乏高质量公开数据集来评估LLMs模拟真实用户行为的挑战。该数据集全面捕捉了用户角色、浏览器观察、细粒度网络行为和即时理由，并首次建立了一个基准，用于评估LLMs预测用户下一步行动和理由的能力，为未来开发个性化数字孪生LLM代理奠定了基础。

> **摘要翻译:** 大型语言模型（LLMs）能否准确模拟特定用户的下一个网络行为？尽管LLMs在生成“可信”人类行为方面已显示出有前景的能力，但评估它们模仿真实用户行为的能力仍然是一个开放的挑战，这主要是由于缺乏高质量、公开可用的数据集，这些数据集既能捕捉实际人类用户的可观察行为，又能捕捉其内部推理。为了解决这一差距，我们引入了OPERA，这是一个从真实人类参与者在线购物会话中收集的观察、角色、理由和行动的新型数据集。OPERA是第一个全面捕捉用户角色、浏览器观察、细粒度网络行为和自我报告的即时理由的公共数据集。我们开发了在线问卷和自定义浏览器插件来高保真地收集此数据集。利用OPERA，我们建立了第一个基准，用于评估当前LLMs在给定角色和<观察、行动、理由>历史的情况下，预测特定用户下一步行动和理由的能力。该数据集为未来旨在作为人类个性化数字孪生的LLM代理研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [391] [How Important is Domain Specificity in Language Models and Instruction Finetuning for Biomedical Relation Extraction?](https://arxiv.org/abs/2402.13470)
> *领域特异性在生物医学关系抽取中的语言模型和指令微调中有多重要？*

*Aviv Brokman, Ramakanth Kavuluru* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 语言模型, 指令微调, 生物医学自然语言处理, 关系抽取, 领域特异性

**Comment:** A version of this paper has appeared in the proceedings of NLDB 2025
  with a slightly different title. The corresponding DOI is also listed below
  in the metadata

> **TL;DR:** 通用语言模型在生物医学关系抽取中表现优于生物医学领域模型；然而，生物医学指令微调即使数据量少得多，也与通用指令微调效果相似，表明应侧重于对通用语言模型进行大规模生物医学指令微调。

**AI_Comments:** 这篇论文提供了一个令人惊讶且反直觉的发现：通用领域语言模型在生物医学关系抽取中可能优于领域特定模型，这挑战了“越专业化的预训练越好”的普遍假设。这对自然语言处理研究中的资源分配具有重要指导意义，表明微调通用模型可能更高效。关于生物医学指令微调在指令数量较少的情况下仍能保持效率的发现也极具价值。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于训练领域特定模型和指令微调所需的大量精力，本研究旨在探究它们在生物医学关系抽取这一关键任务中是否带来性能提升。

**Method:** 本研究通过回答两个问题来探究：(1) 在生物医学语料库上训练的语言模型是否优于在通用领域语料库上训练的模型？(2) 在生物医学数据集上进行指令微调的模型是否优于在混合数据集上微调的模型或仅预训练的模型？研究使用了现有语言模型，并在四个数据集上进行了测试。

**Result:** 令人惊讶的是，通用领域模型通常优于生物医学领域模型。然而，生物医学指令微调尽管指令数量少得多，但其性能提升程度与通用指令微调相似。

**Conclusion:** 研究发现，将研究精力集中在对通用语言模型进行更大规模的生物医学指令微调上，可能比构建领域特定的生物医学语言模型更富有成效。

> **ai_Abstract:** 本文研究了领域特异性在生物医学关系抽取中语言模型和指令微调的重要性。与普遍假设相反，研究发现通用领域语言模型通常优于在生物医学语料库上训练的模型。然而，生物医学指令微调被证明是有效的，尽管指令数量少得多，但其性能提升与通用指令微调相似。研究结果表明，将重点放在对通用语言模型进行大规模生物医学指令微调上，可能比开发新的领域特定语言模型更有益。

> **摘要翻译:** 在通用自然语言处理领域开发的前沿技术，经常随后被应用于高价值、数据丰富的生物医学领域。过去几年，生成式语言模型（LMs）、指令微调和少样本学习已成为自然语言处理研究的焦点。因此，在生物医学语料库上预训练的生成式语言模型大量涌现，生物医学指令微调也得到了尝试，所有这些都希望领域特异性能够提高下游任务的性能。鉴于训练此类模型需要付出不小的努力，我们调查了它们在生物医学自然语言处理关键任务——关系抽取中，是否以及有哪些益处。具体来说，我们解决了两个问题：(1) 在生物医学语料库上训练的语言模型是否优于在通用领域语料库上训练的模型？(2) 在生物医学数据集上进行指令微调的模型是否优于在混合数据集上微调的模型或仅预训练的模型？我们使用现有语言模型，并在四个数据集上进行了测试，以解决这些问题。令人惊讶的结果是，通用领域模型通常优于生物医学领域模型。然而，生物医学指令微调尽管指令数量少得多，但其性能提升程度与通用指令微调相似。我们的研究结果表明，将研究精力集中在对通用语言模型进行更大规模的生物医学指令微调上，可能比构建领域特定的生物医学语言模型更富有成效。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [398] [FinDPO: Financial Sentiment Analysis for Algorithmic Trading through Preference Optimization of LLMs](https://arxiv.org/abs/2507.18417)
> *FinDPO：通过LLM偏好优化实现量化交易的金融情感分析*

*Giorgos Iacovides, Wuyang Zhou, Danilo Mandic* | **Category: cs.CL, cs.LG, q-fin.ST, q-fin.TR** | **Updated: 2025-07-24**

**Keywords:** 金融情感分析, 大型语言模型, 偏好优化, 量化交易, FinDPO

**Comment:** 

> **TL;DR:** FinDPO是一个利用直接偏好优化（DPO）技术为金融情感分析设计的LLM框架，它克服了传统监督微调（SFT）模型的泛化性问题，并在情感分类和量化交易模拟中表现出最先进的性能和显著的盈利能力。

**AI_Comments:** FinDPO的创新之处在于首次将直接偏好优化（DPO）应用于金融领域的大型语言模型，有效地解决了传统监督微调模型在金融文本数据中泛化能力差的问题。其引入的“logit-to-score”转换机制是另一个亮点，它使得LLM的离散情感预测能够更平滑、更实际地融入量化交易策略，并最终在模拟中展示了在现实交易成本下依然可观的盈利能力和风险调整表现，这对于金融AI的实际应用具有重要的指导意义和潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前用于金融情感分析的监督微调（SFT）大型语言模型（LLM）存在对训练数据记忆化和泛化能力不足的问题，这在需要适应未见事件和金融领域特定细微语言的金融领域是一个严重的限制。

**Method:** 本文提出了FinDPO，这是首个基于直接偏好优化（DPO）进行后训练人类偏好对齐的金融领域LLM框架。该框架还通过一种新颖的“logit-to-score”转换方法，将离散的情感预测转化为连续的、可排序的情感分数（概率），从而将微调后的因果LLM整合到实际的投资组合策略中。

**Result:** FinDPO在标准情感分类基准测试中实现了最先进的性能，平均比现有监督微调模型高出11%。模拟结果表明，即使在5个基点的实际交易成本下，FinDPO作为首个基于情感的方法，每年仍能保持67%的显著正回报和2.0的夏普比率所表明的强大风险调整性能。

**Conclusion:** FinDPO是第一个基于情感分析的方法，即使在现实交易成本下，也能在量化交易中保持显著的正回报和强大的风险调整性能。

> **ai_Abstract:** FinDPO是一个针对金融情感分析的新型LLM框架，它通过直接偏好优化（DPO）克服了传统监督微调（SFT）模型在泛化性方面的局限。该模型在情感分类基准测试中取得了最先进的性能，并引入了独特的“logit-to-score”转换机制，将离散的情感预测转化为连续分数，使其能够有效整合到量化交易策略中。模拟结果显示，即使在考虑实际交易成本的情况下，FinDPO也能实现显著的正回报和优秀的风险调整表现。

> **摘要翻译:** 在线金融相关文本数据中表达的观点对交易决策和市场走势产生着越来越深远的影响。这一趋势突显了情感分析作为量化此类观点性质和强度的工具的关键作用。随着生成式AI（GenAI）的快速发展，监督微调（SFT）大型语言模型（LLMs）已成为金融情感分析的事实标准。然而，SFT范式可能导致训练数据记忆化，并且通常无法泛化到未见样本。这在金融领域是一个关键的限制，因为模型必须适应以前未观察到的事件和金融领域细致入微的特定语言。为此，我们引入了FinDPO，这是第一个基于通过直接偏好优化（DPO）进行后训练人类偏好对齐的金融领域特定LLM框架。所提出的FinDPO在标准情感分类基准上取得了最先进的性能，平均优于现有监督微调模型11%。独特的是，FinDPO框架通过一种新颖的“logit-to-score”转换，将离散的情感预测转化为连续的、可排序的情感分数（概率），从而将微调后的因果LLM整合到实际的投资组合策略中。通过这种方式，模拟表明，FinDPO是第一个即使在5个基点（bps）的实际交易成本下，也能保持每年67%的显著正回报和2.0的夏普比率所表明的强大风险调整性能的基于情感的方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [411] [AutoPCR: Automated Phenotype Concept Recognition by Prompting](https://arxiv.org/abs/2507.19315)
> *AutoPCR：基于提示的自动化表型概念识别*

*Yicheng Tao, Yuanhao Huang, Jie Liu* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 表型概念识别, 提示工程, 大型语言模型, 生物医学文本挖掘, 泛化能力

**Comment:** 

> **TL;DR:** AutoPCR是一种基于提示的表型概念识别方法，无需本体特定训练，在多个基准数据集上超越现有SOTA方法，并具有良好的泛化能力。

**AI_Comments:** AutoPCR的创新之处在于其无需本体特定训练，并通过结合多种策略（规则、神经标记、SapBERT和LLM提示）实现概念识别，显著提高了方法的通用性和对新本体的泛化能力。其在生物医学文本挖掘领域的应用潜力巨大，尤其是在处理不断变化的术语和多样化文本类型方面。

<details>
  <summary>Details</summary>

**Motivation:** 现有表型概念识别方法通常需要本体特定训练，并且难以泛化到不同文本类型和不断发展的生物医学术语。

**Method:** AutoPCR通过三个阶段进行概念识别：使用基于规则和神经标记策略的混合方法进行实体提取；通过SapBERT进行候选检索；以及通过提示大型语言模型进行实体链接。

**Result:** 在四个基准数据集上的实验表明，AutoPCR在提及级别和文档级别评估中均实现了最佳的平均和最稳健的性能，超越了现有最先进的方法。进一步的消融和迁移研究证明了其归纳能力和对新本体的泛化性。

**Conclusion:** AutoPCR作为一种无需本体特定训练的表型概念识别方法，在性能和泛化能力上均表现出色，为生物医学文本挖掘提供了更鲁棒和通用的解决方案。

> **ai_Abstract:** AutoPCR是一种创新的基于提示的表型概念识别方法，旨在解决现有方法对本体特定训练的依赖和泛化能力不足的问题。它采用三阶段处理流程，结合了规则、神经标记、SapBERT和大型语言模型提示。实验证明，AutoPCR在多个基准测试中表现优异，超越了当前最先进的技术，并展现出强大的归纳和泛化能力，尤其对新本体具有良好的适用性。

> **摘要翻译:** 表型概念识别（CR）是生物医学文本挖掘中的一项基础任务，能够支持临床诊断和知识图谱构建等应用。然而，现有方法通常需要本体特定的训练，并且难以泛化到多样化的文本类型和不断发展的生物医学术语。我们提出了AutoPCR，一种基于提示的表型概念识别方法，它不需要本体特定的训练。AutoPCR分三个阶段执行概念识别：使用基于规则和神经标记策略的混合方法进行实体提取，通过SapBERT进行候选检索，以及通过提示大型语言模型进行实体链接。在四个基准数据集上的实验表明，AutoPCR在提及级别和文档级别评估中均实现了最佳的平均和最稳健的性能，超越了现有最先进的方法。进一步的消融和迁移研究证明了其归纳能力和对新本体的泛化性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [415] [SCOPE: Stochastic and Counterbiased Option Placement for Evaluating Large Language Models](https://arxiv.org/abs/2507.18182)
> *SCOPE：用于评估大型语言模型的随机和反偏置选项放置*

*Wonjun Jeong, Dongseok Kim, Taegkeun Whangbo* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 评估, 偏置, 多项选择, SCOPE

**Comment:** 34 pages, 1 figure

> **TL;DR:** SCOPE是一种新的评估框架，通过估计和抵消LLM在多项选择任务中利用选项位置或标签偏置的能力，从而提供更公平、可靠的模型评估。

**AI_Comments:** SCOPE的创新之处在于其数据集无关的方法来估计和抵消LLM在多项选择任务中的位置偏置，以及其通过重新分配答案槽位和阻止语义相似干扰项邻近放置来提高评估公平性的机制。这对于更准确地衡量LLM的真实理解能力而非其利用偏置的能力至关重要，为LLM评估设定了新的标准。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在多项选择任务中可能通过利用选项位置或标签中的固有偏置来获得虚高分数，而非真正理解。本研究的动机是测量和减轻这种选择偏置，以提高LLM评估的公平性和可靠性。

**Method:** 本研究引入了SCOPE评估框架，它通过重复调用缺乏语义内容的空提示来估计每个模型的独特位置偏置分布。然后，SCOPE根据逆偏置分布重新分配答案槽位，从而均衡随机选择正确答案的概率（幸运率）。此外，它还防止语义相似的干扰项被放置在答案附近，从而阻止基于表面邻近线索的“险胜”猜测。

**Result:** 在多项基准实验中，SCOPE在稳定性能改进方面始终优于现有去偏置方法，并对正确选项显示出更清晰的置信度分布。

**Conclusion:** SCOPE框架为增强大型语言模型评估的公平性和可靠性提供了一个新标准。

> **ai_Abstract:** 本研究提出SCOPE，一个用于评估大型语言模型的框架，旨在解决LLM在多项选择任务中因利用选项偏置而导致分数虚高的问题。SCOPE通过估计模型的位置偏置分布并重新分配答案槽位来抵消这种偏置，同时避免语义相似干扰项的邻近放置。实验结果表明，SCOPE在性能提升和置信度分布方面优于现有去偏置方法，为LLM评估提供了更公平可靠的新标准。

> **摘要翻译:** 大型语言模型（LLMs）在多项选择任务中可能通过利用选项位置或标签中的固有偏置来获得虚高分数，而非真正理解。本研究引入了SCOPE，一个旨在以独立于数据集的方式测量和减轻这种选择偏置的评估框架。通过重复调用缺乏语义内容的空提示，SCOPE估计每个模型独特的位置偏置分布。然后，它根据逆偏置分布重新分配答案槽位，从而均衡随机选择正确答案的概率（幸运率）。此外，它还防止语义相似的干扰项被放置在答案附近，从而阻止基于表面邻近线索的“险胜”猜测。在多项基准实验中，SCOPE在稳定性能改进方面始终优于现有去偏置方法，并对正确选项显示出更清晰的置信度分布。因此，该框架为增强LLM评估的公平性和可靠性提供了一个新标准。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [424] [MultiSocial: Multilingual Benchmark of Machine-Generated Text Detection of Social-Media Texts](https://arxiv.org/abs/2406.12549)
> *MultiSocial：社交媒体文本机器生成文本检测的多语言基准*

*Dominik Macko, Jakub Kopal, Robert Moro, Ivan Srba* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-25**

**Keywords:** 机器生成文本检测, 多语言, 社交媒体, 基准数据集, LLMs

**Comment:** ACL 2025 main

> **TL;DR:** MultiSocial提出了首个多语言、多平台的社交媒体机器生成文本检测基准数据集，并发现微调检测器在社交媒体文本上表现良好，且训练时的平台选择很重要。

**AI_Comments:** MultiSocial的创新之处在于其构建了首个多语言、多平台的社交媒体机器生成文本检测基准数据集，填补了该领域的一个重要空白。这对于推进社交媒体环境中机器生成内容（如虚假信息、垃圾信息）的检测技术具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 目前机器生成文本检测研究主要集中在英语和长文本上，而社交媒体文本通常更短、语言非正式，且缺乏针对此类文本的多语言基准数据集来评估现有检测方法。

**Method:** 提出了首个多语言（22种语言）和多平台（5个社交媒体平台）的社交媒体机器生成文本检测数据集MultiSocial。该数据集包含472,097条文本，其中约5.8万条是人类编写的，其余由7个多语言LLM生成。作者使用该基准比较了现有检测方法在零样本和微调形式下的表现。

**Result:** 微调后的检测器在社交媒体文本上进行训练没有问题，并且训练时的平台选择很重要。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究提出了MultiSocial，一个涵盖22种语言和5个社交媒体平台的机器生成文本检测基准数据集，旨在解决现有研究主要集中在英语长文本的局限性。该数据集包含近50万条文本，其中包含人类编写和由7个多语言LLM生成的文本。通过使用该基准，研究发现微调后的检测器能够很好地适应社交媒体文本，并且训练时选择的平台对检测性能有影响。

> **摘要翻译:** 最近的大型语言模型（LLMs）能够生成高质量的多语言文本，人类难以区分其与真实的人类编写文本。然而，机器生成文本检测的研究主要集中在英语和较长的文本上，例如新闻文章、科学论文或学生论文。社交媒体文本通常更短，并且常常具有非正式语言、语法错误或独特的语言项（例如表情符号、标签）。在研究现有方法检测此类文本的能力方面存在空白，这也体现在缺乏现有的多语言基准数据集。为了填补这一空白，我们提出了首个用于社交媒体领域机器生成文本检测的多语言（22种语言）和多平台（5个社交媒体平台）数据集，名为MultiSocial。它包含472,097条文本，其中约5.8万条是人类编写的，大约相同数量的文本由7个多语言LLMs生成。我们使用该基准来比较现有检测方法在零样本和微调形式下的表现。我们的结果表明，微调后的检测器在社交媒体文本上进行训练没有问题，并且训练时的平台选择很重要。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [428] [PrismRAG: Boosting RAG Factuality with Distractor Resilience and Strategized Reasoning](https://arxiv.org/abs/2507.18857)
> *PrismRAG：通过干扰项韧性和策略化推理提升RAG事实性*

*Mohammad Kachuee, Teja Gollapudi, Minseok Kim, Yin Huang, Kai Sun, Xiao Yang, Jiaqi Wang, Nirav Shah, Yue Liu, Aaron Colak, Anuj Kumar, Wen-tau Yih, Xin Luna Dong* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 检索增强生成, 事实性, 微调, 干扰项韧性, 策略化推理

**Comment:** 

> **TL;DR:** PrismRAG是一个高效的微调框架，通过干扰项感知QA和推理习惯训练，显著提升了RAG的事实性和鲁棒性。

**AI_Comments:** PrismRAG的创新点在于其独特的微调框架，特别是结合了“干扰项感知QA对”训练和“推理中心习惯”的灌输，这直接针对了RAG模型在复杂和不完美检索上下文中的核心弱点。这种方法不仅提升了模型的事实性，还减少了对复杂人工指令的依赖，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 检索增强生成（RAG）在检索到的上下文包含混淆的半相关段落时，或需要深度上下文理解和推理才能回答问题时，往往表现不佳。

**Method:** PrismRAG是一个高效的微调框架，它通过两种方式训练模型：(i) 使用混合了黄金证据和微妙干扰项的干扰项感知QA对来训练模型；(ii) 灌输以推理为中心习惯，使大型语言模型无需大量人工指令即可进行规划、合理化和综合。

**Result:** 在12个开放式RAG QA基准测试中，PrismRAG将平均事实性提高了5.4%，优于现有最先进的解决方案。

**Conclusion:** PrismRAG通过其创新的微调框架，有效解决了RAG在处理干扰项和需要深度推理时的不足，显著提升了RAG系统的事实性和性能。

> **ai_Abstract:** 本文提出了PrismRAG，一个高效的微调框架，旨在解决检索增强生成（RAG）在处理干扰项和需要深度推理时的事实性问题。PrismRAG通过干扰项感知QA对训练和灌输推理中心习惯来提升大型语言模型的能力。实验结果表明，PrismRAG在多个RAG QA基准测试中将平均事实性提高了5.4%，优于现有SOTA方法。

> **摘要翻译:** 检索增强生成（RAG）在检索到的上下文包含混淆的半相关段落时，或者回答问题需要深度上下文理解和推理时，往往表现不佳。我们提出了一个高效的微调框架，称为PrismRAG，它（i）使用混合了黄金证据和微妙干扰段落的干扰项感知QA对来训练模型，以及（ii）灌输以推理为中心的习惯，使大型语言模型无需依赖大量人工设计的指令即可进行规划、合理化和综合。在跨越不同应用领域和场景的12个开放式RAG QA基准测试中进行评估，PrismRAG将平均事实性提高了5.4%，超越了现有最先进的解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [447] [Smooth Reading: Bridging the Gap of Recurrent LLM to Self-Attention LLM on Long-Context Tasks](https://arxiv.org/abs/2507.19353)
> *流畅阅读：弥合循环式大型语言模型与自注意力大型语言模型在长上下文任务上的鸿沟*

*Kai Liu, Zhan Su, Peijie Dong, Fengran Mo, Jianfei Gao, ShaoTing Zhang, Kai Chen* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-25**

**Keywords:** 循环式大型语言模型, 自注意力大型语言模型, 长上下文任务, 流畅阅读, 分块推理

**Comment:** 

> **TL;DR:** 本文提出“流畅阅读”方法，通过分块推理和迭代总结，显著提升循环式大型语言模型在长上下文任务上的表现，使其性能媲美自注意力大型语言模型，同时保持高效性。

**AI_Comments:** 本文提出的“流畅阅读”方法具有创新性，它从人类阅读策略中汲取灵感，以一种新颖的方式解决了循环式大型语言模型在处理长上下文时的内存瓶颈问题。其重要性在于，它成功地使循环式大型语言模型在长上下文任务上首次实现了与自注意力大型语言模型相媲美的性能，同时保持了显著的效率优势（训练速度快3倍，推理速度快2倍）。这为未来在需要高效处理长上下文的应用中，重新聚焦和发展循环式大型语言模型提供了新的可能性和方向。

<details>
  <summary>Details</summary>

**Motivation:** 循环式大型语言模型（Recurrent LLMs）虽然计算效率高，但由于固定大小的内存限制，在长上下文任务上表现不佳，无法与自注意力大型语言模型（Self-Attention LLMs）匹敌。以往研究主要通过架构创新提升内存容量，但未能完全弥合性能差距。作者认为，一次性处理整个上下文不适合循环式大型语言模型。

**Method:** 本文提出“流畅阅读”（Smooth Reading），一种受人类阅读策略启发的分块推理方法。该方法将上下文分块处理，并迭代总结上下文信息，从而降低内存需求，使其更兼容循环式大型语言模型。

**Result:** 实验结果表明，“流畅阅读”方法显著缩小了循环式大型语言模型与自注意力大型语言模型在长上下文任务上的性能差距，同时保留了循环式大型语言模型的效率优势。具体而言，在LongBench上，Recurrent LLM SWA-3B-4k 的性能从比Self-Attention LLMs低5.68%提升到高3.61%。此外，该方法在64k上下文时，训练速度快3倍，推理速度快2倍，保持了高效率。

**Conclusion:** 据作者所知，这是首次通过循环式大型语言模型在长上下文任务上达到与自注意力大型语言模型相媲美性能的工作，同时保持了其效率优势。

> **ai_Abstract:** 循环式大型语言模型（Recurrent LLMs）因其高效性而备受关注，但在长上下文任务上由于内存限制而性能不足。本文提出“流畅阅读”（Smooth Reading）方法，受人类阅读启发，通过分块推理和迭代总结上下文信息，有效降低内存需求。实验证明，该方法显著弥合了循环式大型语言模型与自注意力大型语言模型（Self-Attention LLMs）在长上下文任务上的性能差距，使SWA-3B-4k 在LongBench上的表现反超后者，同时保持了循环式大型语言模型在训练和推理上的高效率。

> **摘要翻译:** 最近，具有线性计算复杂度的循环式大型语言模型（Recurrent LLMs）重新成为自注意力大型语言模型（Self-Attention LLMs）的有效替代品，后者具有二次复杂度。然而，循环式大型语言模型由于其有限的固定大小内存，在长上下文任务上通常表现不佳。以往的研究主要集中于通过架构创新增强循环式大型语言模型的内存容量，但这些方法尚未使循环式大型语言模型在长上下文任务上达到自注意力大型语言模型的性能。我们认为，这一限制源于一次性处理整个上下文不适合循环式大型语言模型。在本文中，我们提出了“流畅阅读”（Smooth Reading），一种受人类阅读策略启发的分块推理方法。“流畅阅读”以分块方式处理上下文并迭代总结上下文信息，从而降低内存需求，使该方法更兼容循环式大型语言模型。我们的实验结果表明，该方法显著缩小了循环式大型语言模型和自注意力大型语言模型在长上下文任务上的性能差距，同时保留了循环式大型语言模型的效率优势。我们的“流畅阅读”使SWA-3B-4k（一个循环式大型语言模型）在LongBench上的表现从比自注意力大型语言模型低5.68%提升到高3.61%。此外，我们的方法保持了高效率，与自注意力大型语言模型相比，在64k上下文时训练速度快3倍，推理速度快2倍。据我们所知，这是首次通过循环式大型语言模型在长上下文任务上实现与自注意力大型语言模型可比性能的工作。我们希望我们的方法能启发该领域的未来研究。为了促进进一步的进展，我们将发布代码和数据集。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [451] [Safeguarding RAG Pipelines with GMTP: A Gradient-based Masked Token Probability Method for Poisoned Document Detection](https://arxiv.org/abs/2507.18202)
> *使用GMTP保护RAG管道：一种用于中毒文档检测的基于梯度的掩码令牌概率方法*

*San Kim, Jonghwi Kim, Yejin Jeon, Gary Geunbae Lee* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** RAG, 中毒文档检测, GMTP, 梯度, 掩码语言模型

**Comment:** 18 pages, accepted to ACL Findings 2025

> **TL;DR:** GMTP是一种新的防御方法，通过检查检索器相似性函数的梯度并利用掩码语言模型检测低概率的注入令牌，以检测和过滤RAG管道中的中毒文档。

**AI_Comments:** GMTP的创新点在于结合了梯度信息和掩码语言模型来检测RAG中的中毒文档，这种方法利用了注入令牌的异常概率分布。其重要性在于解决了RAG系统面临的实际安全威胁，有助于提高LLMs在外部知识来源下的可靠性和安全性。该方法在实际应用中具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 检索增强生成（RAG）依赖外部知识来增强大型语言模型（LLMs），但这引入了安全风险，攻击者可以注入中毒文档以引导生成有害或误导性的输出。

**Method:** 本文提出了一种名为梯度掩码令牌概率（GMTP）的新型防御方法。GMTP通过检查检索器相似性函数的梯度来识别高影响令牌，然后掩盖这些关键令牌，并通过掩码语言模型（MLM）检查它们的概率。由于注入的令牌通常表现出明显低的掩码令牌概率，因此GMTP可以轻松检测恶意文档。

**Result:** 实验表明，GMTP能够消除超过90%的中毒内容，同时保留相关文档，从而在各种数据集和对抗性设置下保持稳健的检索和生成性能。

**Conclusion:** GMTP是一种有效的防御机制，能够显著减少RAG管道中中毒文档的影响，同时保持系统性能。

> **ai_Abstract:** 本文提出了一种名为GMTP（梯度掩码令牌概率）的新型防御方法，旨在保护检索增强生成（RAG）管道免受中毒文档的攻击。GMTP通过分析检索器相似性函数的梯度来识别关键令牌，并利用掩码语言模型（MLM）检测注入的低概率恶意令牌。实验证明，GMTP能有效过滤超过90%的中毒内容，同时保持RAG系统的性能和相关性。

> **摘要翻译:** 检索增强生成（RAG）通过提供外部知识来增强大型语言模型（LLMs），以实现准确和最新的响应。然而，这种对外部来源的依赖暴露出安全风险，攻击者可以将中毒文档注入知识库，以引导生成过程产生有害或误导性的输出。在本文中，我们提出了基于梯度的掩码令牌概率（GMTP），这是一种检测和过滤对抗性制作文档的新型防御方法。具体来说，GMTP通过检查检索器相似性函数的梯度来识别高影响令牌。然后，这些关键令牌被掩盖，并通过掩码语言模型（MLM）检查它们的概率。由于注入的令牌通常表现出明显低的掩码令牌概率，这使得GMTP能够轻松检测恶意文档并实现高精度过滤。实验表明，GMTP能够消除超过90%的中毒内容，同时保留相关文档，从而在各种数据集和对抗性设置下保持稳健的检索和生成性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [452] [SpeechIQ: Speech Intelligence Quotient Across Cognitive Levels in Voice Understanding Large Language Models](https://arxiv.org/abs/2507.19361)
> *SpeechIQ：语音理解大型语言模型中跨认知水平的语音智商*

*Zhen Wan, Chao-Han Huck Yang, Yahan Yu, Jinchuan Tian, Sheng Li, Ke Hu, Zhehuai Chen, Shinji Watanabe, Fei Cheng, Chenhui Chu, Sadao Kurohashi* | **Category: cs.CL, cs.AI, cs.SC, cs.SD, eess.AS** | **Updated: 2025-07-25**

**Keywords:** 语音理解, 大型语言模型, 认知评估, SpeechIQ, 布鲁姆分类法

**Comment:** Our Speech-IQ leaderboard will be hosted at
  huggingface.co/spaces/nvidia/Speech-IQ-leaderboard. ACL 2025 main

> **TL;DR:** SpeechIQ引入了一种基于人类认知的新型评估管道，用于衡量语音理解大型语言模型（LLM Voice）的语音理解能力，超越了传统的指标，并在三个认知层面（记忆、理解、应用）进行评估，可用于量化能力、统一比较、识别错误和检测幻觉。

**AI_Comments:** 本文的创新之处在于将人类认知理论（布鲁姆分类法）引入到语音理解LLM的评估中，提出了一个多维度的评估框架SIQ，超越了单一的性能指标。这种方法不仅能更全面地评估模型的“理解”能力，还能发现现有基准的缺陷和模型的幻觉问题，对未来的多模态AI研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有语音理解评估指标（如词错误率WER）无法全面评估语音理解大型语言模型（LLM Voice）的语音理解能力。本文旨在引入一种受人类认知启发的新型评估方法，以更全面地衡量和评估LLM Voice的语音理解能力。

**Method:** 本文引入了语音智商（Speech-based Intelligence Quotient, SIQ）作为一种受人类认知启发的评估管道。SIQ基于布鲁姆分类法，在三个认知水平上评估LLM Voice：1) 记忆（使用WER衡量逐字准确性）；2) 理解（衡量LLM解释的相似性）；3) 应用（通过问答准确性模拟下游任务）。

**Result:** SIQ不仅能量化语音理解能力，还能在级联方法（如ASR LLM）和端到端模型之间提供统一的比较，识别现有基准中的标注错误，并检测LLM Voice中的幻觉。

**Conclusion:** SpeechIQ框架是首个将认知原理与面向语音的基准结合起来的智能测试，同时揭示了多模态训练中被忽视的挑战。

> **ai_Abstract:** 本文提出了SpeechIQ，一种基于人类认知启发的新型评估方法，用于衡量语音理解大型语言模型（LLM Voice）的语音理解能力。它超越了传统的词错误率（WER），在记忆、理解和应用三个认知层面进行评估。SpeechIQ不仅能够量化语音理解能力，还能统一比较不同模型，识别标注错误，并检测模型幻觉，为多模态训练中的挑战提供了新的视角。

> **摘要翻译:** 我们引入了基于语音的智商（SIQ）作为一种受人类认知启发的语音理解大型语言模型（LLM Voice）评估管道，旨在评估其语音理解能力。SIQ超越了流行的语音理解指标，如词错误率（WER），它根据布鲁姆分类法，在三个认知水平上检查LLM Voice：(1) 记忆（即逐字准确性的WER）；(2) 理解（即LLM解释的相似性）；以及(3) 应用（即模拟下游任务的问答准确性）。我们证明SIQ不仅量化了语音理解能力，还提供了级联方法（例如ASR LLM）和端到端模型之间的统一比较，识别了现有基准中的标注错误，并检测了LLM Voice中的幻觉。我们的框架代表了一种首创的智能测试，它将认知原理与面向语音的基准结合起来，同时揭示了多模态训练中被忽视的挑战。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [454] [Long-Form Answers to Visual Questions from Blind and Low Vision People](https://arxiv.org/abs/2408.06303)
> *针对盲人和低视力人群视觉问题的长篇回答*

*Mina Huh, Fangyuan Xu, Yi-Hao Peng, Chongyan Chen, Hansika Murugu, Danna Gurari, Eunsol Choi, Amy Pavel* | **Category: cs.CL, cs.CV** | **Updated: 2025-07-25**

**Keywords:** 长篇视觉问答, 盲人和低视力, 数据集, 幻觉, VizWiz-LF

**Comment:** COLM 2024 Oral Spotlight

> **TL;DR:** 提出了VizWiz-LF数据集，用于盲人和低视力人群的视觉问题长篇回答(LFVQA)，发现生成式答案存在幻觉问题，并研究了模型拒绝回答的能力。

**AI_Comments:** 这篇论文的创新点在于首次为盲人和低视力人群的视觉问题构建了长篇回答数据集，并深入分析了长篇回答的结构和内容。其重要性在于揭示了当前视觉语言模型在生成长篇回答时存在的严重幻觉问题，特别是对于无法回答的问题。这为未来模型开发指明了方向，即需要提升模型识别并拒绝回答不确定或无法回答问题的能力，从而提高辅助技术的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 视觉语言模型可以生成长篇视觉问题回答(LFVQA)，但缺乏针对盲人和低视力(BLV)用户提出的视觉问题的长篇答案数据集，且需要评估这些答案的质量和存在的问题（如幻觉）。

**Method:** 1. 贡献了VizWiz-LF数据集，包含4.2k长篇答案，来自人工专家和六个VQA模型。2. 开发并标注了LFVQA句子功能角色，证明长篇答案包含额外信息。3. 对长篇答案进行了自动和人工评估（与BLV和视力正常者）。4. 评估VQA模型在不同提示策略下拒绝回答无法回答问题（如模糊或不相关图像）的能力。

**Result:** 1. VizWiz-LF数据集包含4.2k长篇答案，覆盖600个视觉问题。2. 长篇答案包含超越问题答案的信息，如解释和建议。3. 盲人和低视力人群认为人工和生成的长篇答案都合理。4. 生成的答案常出现不正确的视觉细节幻觉，尤其对于无法回答的视觉问题。5. 评估了VQA模型在不同提示策略下拒绝回答无法回答问题的能力以减少幻觉。

**Conclusion:** 针对盲人和低视力人群的视觉问题长篇回答具有潜力，但模型生成的答案容易产生幻觉，尤其是在图像无法回答的情况下。研究模型拒绝回答的能力是减少幻觉的关键方向。

> **ai_Abstract:** 本文针对盲人和低视力人群的视觉问题，推出了首个长篇答案数据集VizWiz-LF，并对长篇视觉问题回答（LFVQA）进行了深入分析和评估。研究发现，LFVQA不仅包含直接答案，还包括解释和建议。尽管生成式答案在BLV用户看来具有合理性，但普遍存在幻觉问题，尤其是在图像不清晰或不相关时。为解决此问题，论文探讨了VQA模型在不同提示策略下拒绝回答无法回答问题的能力。

> **摘要翻译:** 视觉语言模型现在能够针对图像问题生成长篇回答——即长篇视觉问题回答（LFVQA）。我们贡献了VizWiz-LF数据集，其中包含盲人和低视力（BLV）用户提出的视觉问题的长篇答案。VizWiz-LF包含4.2k个长篇答案，对应600个视觉问题，这些答案由人类专家描述者和六个VQA模型收集而来。我们开发并标注了LFVQA句子功能角色，并证明长篇答案包含超出问题答案的信息，例如解释和建议。我们还与盲人和低视力人群以及视力正常人群进行了自动和人工评估，以评估长篇答案。盲人和低视力人群认为人工编写和生成的长篇答案都具有合理性，但生成的答案经常会幻觉出不正确的视觉细节，特别是对于无法回答的视觉问题（例如，模糊或不相关的图像）。为了减少幻觉，我们评估了VQA模型在多种提示策略下拒绝回答无法回答问题的能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [464] [MindFlow+: A Self-Evolving Agent for E-Commerce Customer Service](https://arxiv.org/abs/2507.18884)
> *MindFlow+：一种用于电商客服的自进化智能体*

*Ming Gong, Xucheng Huang, Ziheng Xu, Vijayan K. Asari* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 电商客服, 对话智能体, 大型语言模型, 强化学习, 工具使用

**Comment:** 

> **TL;DR:** MindFlow+是一个结合LLM、模仿学习和离线RL的自进化对话智能体，通过工具增强演示和奖励条件数据建模，在电商客服对话中表现优于基线。

**AI_Comments:** MindFlow+的创新之处在于其结合LLMs、模仿学习和离线RL，并引入了工具增强演示和奖励条件数据建模这两种数据中心机制，特别是在电商客服这一复杂领域。AI贡献率作为新指标也很有意义，能更好地量化AI在对话中的作用。

<details>
  <summary>Details</summary>

**Motivation:** 传统基于意图的系统难以处理动态、多轮的电商客服对话，高质量对话对于电商客服至关重要。

**Method:** 提出MindFlow+，一个自进化的对话智能体，它通过结合大型语言模型（LLMs）、模仿学习和离线强化学习（RL）来学习领域特定行为。MindFlow+引入了两种数据中心机制：工具增强演示构建（暴露模型于知识增强和代理式交互以有效使用工具）和奖励条件数据建模（使用奖励信号使响应与任务特定目标对齐）。引入AI贡献率作为衡量AI在对话中参与度的新颖指标。

**Result:** 在真实电商对话中的实验表明，MindFlow+在上下文相关性、灵活性和任务准确性方面优于强大的基线。

**Conclusion:** 结合LLMs工具推理和奖励引导学习，可以构建领域专业化、上下文感知的对话系统。

> **ai_Abstract:** 本文提出了MindFlow+，一个用于电商客服的自进化对话智能体，旨在解决传统意图系统在动态多轮交互中的不足。MindFlow+结合了大型语言模型、模仿学习和离线强化学习，并通过工具增强演示和奖励条件数据建模两种数据中心机制来优化学习过程。作者还引入了AI贡献率来衡量AI在对话中的参与度。实验结果显示，MindFlow+在上下文相关性、灵活性和任务准确性方面均优于现有基线，证明了其在构建领域专业化、上下文感知对话系统方面的潜力。

> **摘要翻译:** 高质量对话对于电商客服至关重要，然而传统的基于意图的系统难以处理动态、多轮的交互。我们提出了MindFlow+，一个自进化的对话智能体，它通过结合大型语言模型（LLMs）与模仿学习和离线强化学习（RL）来学习领域特定行为。MindFlow+引入了两种以数据为中心的机制来指导学习：工具增强演示构建，它使模型接触到知识增强和代理式（ReAct风格）交互，以实现有效的工具使用；以及奖励条件数据建模，它使用奖励信号使响应与任务特定目标对齐。为了评估模型在响应生成中的作用，我们引入了AI贡献率，一个量化AI在对话中参与度的新颖指标。在真实世界电商对话中的实验表明，MindFlow+在上下文相关性、灵活性和任务准确性方面优于强大的基线。这些结果证明了结合LLMs工具推理和奖励引导学习来构建领域专业化、上下文感知的对话系统的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [471] [Not All Features Deserve Attention: Graph-Guided Dependency Learning for Tabular Data Generation with Language Models](https://arxiv.org/abs/2507.18504)
> *并非所有特征都值得关注：基于图引导的依赖学习用于语言模型的表格数据生成*

*Zheyu Zhang, Shuo Yang, Bardh Prenkaj, Gjergji Kasneci* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 表格数据生成, 语言模型, 图神经网络, 依赖学习, 自注意力机制

**Comment:** 

> **TL;DR:** 大型语言模型在表格数据生成中因过度关注不重要特征而效率低下，GraDe通过图引导的依赖学习解决了这个问题。

**AI_Comments:** 该论文的创新点在于将外部知识（稀疏依赖图）显式地引入到LLM的自注意力机制中，解决了LLM在处理表格数据时注意力分散的问题。其重要性在于提供了一种有效且微创的方法来提升LLM在结构化数据生成任务上的性能，特别是对于复杂数据集。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在表格数据生成方面潜力巨大，但其自注意力机制会平等地关注所有特征对，导致对关键关系的注意力稀释，特别是在复杂依赖或语义模糊的数据集中，因为表格数据固有的稀疏特征级依赖与LLMs的机制不匹配。

**Method:** 本文提出了GraDe（Graph-Guided Dependency Learning），一种将稀疏依赖图显式集成到LLMs注意力机制中的新方法。GraDe采用一个轻量级动态图学习模块，由外部提取的功能依赖引导，优先处理关键特征交互并抑制不相关交互。

**Result:** 在多种真实世界数据集上的实验表明，GraDe在复杂数据集上比现有基于LLM的方法性能提高高达12%，并在合成数据质量方面与最先进方法具有竞争力。

**Conclusion:** GraDe是一种微创且有效的解决方案，为使用LLMs进行结构感知的表格数据建模提供了实用方法。

> **ai_Abstract:** 本文提出了GraDe，一种新颖的方法，旨在解决大型语言模型在表格数据生成中自注意力机制对不重要特征过度关注的问题。GraDe通过将外部提取的功能依赖图集成到LLMs的注意力机制中，优先处理关键特征交互，从而提高了模型在复杂数据集上的性能，并在合成数据质量方面达到SOTA水平，为LLMs进行结构感知表格数据建模提供了实用且有效的方案。

> **摘要翻译:** 大型语言模型（LLM）通过对文本化的特征-值对进行建模，在表格数据生成方面展现出强大潜力。然而，表格数据固有地表现出稀疏的特征级依赖关系，其中许多特征交互在结构上并不重要。这造成了一个根本性的不匹配，因为LLM的自注意力机制不可避免地将焦点分散到所有对上，稀释了对关键关系的注意力，特别是在具有复杂依赖或语义模糊特征的数据集中。为了解决这一限制，我们提出了GraDe（图引导的依赖学习），这是一种新颖的方法，它将稀疏依赖图明确地整合到LLM的注意力机制中。GraDe采用一个轻量级的动态图学习模块，由外部提取的功能依赖引导，优先处理关键特征交互，同时抑制不相关的交互。我们在各种真实世界数据集上的实验表明，GraDe在复杂数据集上比现有基于LLM的方法性能提高高达12%，同时在合成数据质量方面取得了与最先进方法相当的结果。我们的方法侵入性小但有效，为使用LLM进行结构感知的表格数据建模提供了一个实用的解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [483] [Enhancing Speech Emotion Recognition Leveraging Aligning Timestamps of ASR Transcripts and Speaker Diarization](https://arxiv.org/abs/2507.19356)
> *利用ASR转录和说话人分离的时间戳对齐增强语音情感识别*

*Hsuan-Yu Wang, Pei-Ying Lee, Berlin Chen* | **Category: cs.CL, I.2.7; I.5.1** | **Updated: 2025-07-25**

**Keywords:** 语音情感识别, 时间戳对齐, ASR, 说话人分离, 多模态融合

**Comment:** 6 pages, 3 figures, to appear in the Proceedings of the 2025
  International Conference on Asian Language Processing (IALP)

> **TL;DR:** 该研究通过对齐ASR转录和说话人分离的时间戳，显著提高了多模态语音情感识别的准确性，解决了模态间错位的问题。

**AI_Comments:** 该论文的创新点在于明确提出并解决了ASR转录和说话人分离输出之间时间戳错位对多模态情感识别性能的影响。通过引入一个系统性的时间对齐流程，并结合先进的文本（RoBERTa）和音频（Wav2Vec）嵌入以及门控交叉注意力融合机制，有效提升了情感识别的准确性。其重要性在于为未来鲁棒的多模态情感分析系统奠定了基础，特别是在需要精确时间同步的对话场景中。

<details>
  <summary>Details</summary>

**Motivation:** 在对话情境中，自动语音识别（ASR）转录和说话人分离（SD）输出之间的错位经常降低多模态情感识别系统的可靠性。

**Method:** 研究引入了一个对齐流程，利用预训练的ASR和说话人分离模型，系统地同步时间戳以生成准确标记的说话人片段。其多模态方法结合了RoBERTa提取的文本嵌入和Wav2Vec的音频嵌入，并通过门控机制增强的交叉注意力融合。

**Result:** 在IEMOCAP基准数据集上的实验评估表明，精确的时间戳对齐显著提高了语音情感识别（SER）的准确性，优于缺乏同步的基线方法。

**Conclusion:** 结果强调了时间对齐的至关重要性，证明了其在提高整体情感识别准确性方面的有效性，并为鲁棒的多模态情感分析奠定了基础。

> **ai_Abstract:** 本论文旨在通过对齐自动语音识别（ASR）转录和说话人分离（SD）的时间戳，解决多模态语音情感识别（SER）中模态间错位导致可靠性下降的问题。研究团队开发了一个利用预训练ASR和SD模型的时间戳对齐流程，并构建了一个结合RoBERTa文本嵌入和Wav2Vec音频嵌入，并通过门控机制增强交叉注意力融合的多模态系统。实验结果表明，精确的时间戳对齐显著提升了SER准确性，优于未同步的基线方法，证实了时间对齐在增强情感识别精度中的关键作用。

> **摘要翻译:** 本文研究了将基于时间戳的自动语音识别（ASR）转录与说话人分离（SD）输出之间的对齐整合对语音情感识别（SER）准确性的影响。这两种模态之间的错位常常降低多模态情感识别系统的可靠性，尤其是在对话情境中。为了解决这个问题，我们引入了一个对齐流程，利用预训练的ASR和说话人分离模型，系统地同步时间戳以生成准确标记的说话人片段。我们的多模态方法结合了通过RoBERTa提取的文本嵌入和来自Wav2Vec的音频嵌入，利用通过门控机制增强的交叉注意力融合。在IEMOCAP基准数据集上的实验评估表明，精确的时间戳对齐提高了SER准确性，优于缺乏同步的基线方法。结果突出了时间对齐的至关重要性，证明了其在提高整体情感识别准确性方面的有效性，并为鲁棒的多模态情感分析提供了基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [484] [Advancing biomolecular understanding and design following human instructions](https://arxiv.org/abs/2410.07919)
> *遵循人类指令推进生物分子理解与设计*

*Xiang Zhuang, Keyan Ding, Tianwen Lyu, Yinuo Jiang, Xiaotong Li, Zhuoyi Xiang, Zeyuan Wang, Ming Qin, Kehua Feng, Jike Wang, Qiang Zhang, Huajun Chen* | **Category: cs.CL, q-bio.BM** | **Updated: 2025-07-25**

**Keywords:** 生物分子设计, 大型语言模型, 自然语言处理, 药物发现, 酶工程

**Comment:** 

> **TL;DR:** InstructBioMol是一个大型语言模型，旨在通过整合自然语言、分子和蛋白质，弥合AI计算能力与人类直观目标之间的差距，从而实现根据人类指令理解和设计生物分子，在药物发现和酶工程等领域展现出巨大潜力。

**AI_Comments:** InstructBioMol的创新之处在于其构建了一个能够全面对齐自然语言、分子和蛋白质的统一框架，有效弥合了AI计算能力与人类直观意图之间的鸿沟。这对于推动生物分子设计从纯粹的计算驱动转向更直观、更符合人类需求的交互方式具有重要意义。其在药物分子生成和酶设计方面的量化改进，也证明了其在实际应用中的巨大潜力。未来的工作可以进一步探索其在更复杂生物系统中的应用以及与实验验证的结合。

<details>
  <summary>Details</summary>

**Motivation:** 尽管人工智能在生物分子研究中取得了显著进展，但在将AI的计算能力与研究人员的直观目标（特别是使用自然语言）相结合方面存在关键空白。现有的大型语言模型在生物分子研究中的应用仍处于初期，面临专业知识、多模态数据整合和语义对齐等挑战。

**Method:** 提出了InstructBioMol，一个大型语言模型，通过对自然语言、分子和蛋白质进行全面的“任意到任意”对齐，旨在弥合自然语言与生物分子之间的鸿沟。该模型能够整合多模态生物分子作为输入，并允许研究人员以自然语言表达设计目标，从而提供满足精确生物需求的生物分子输出。

**Result:** InstructBioMol能够理解并根据人类指令设计生物分子。具体表现为：在结合亲和力方面，生成的药物分子有10%的改进；在酶设计方面，实现了70.4的酶-底物对预测分数。

**Conclusion:** InstructBioMol模型能够有效理解和设计遵循人类指令的生物分子，展现出改变现实世界生物分子研究的巨大潜力。

> **ai_Abstract:** 本研究提出InstructBioMol，一个大型语言模型，旨在解决人工智能在生物分子研究中与人类直观目标之间的差距。该模型通过对自然语言、分子和蛋白质进行全面的“任意到任意”对齐，实现了多模态生物分子输入和自然语言指令输出生物分子的能力。实验证明，InstructBioMol能有效理解并遵循人类指令设计生物分子，例如生成结合亲和力提高10%的药物分子和预测分数达70.4的酶，显示出其在药物发现和酶工程等领域的巨大应用潜力。

> **摘要翻译:** 理解和设计生物分子，如蛋白质和小分子，是推进药物发现、合成生物学和酶工程的核心。人工智能的最新突破彻底改变了生物分子研究，在生物分子预测和设计方面取得了显著的准确性。然而，人工智能的计算能力与研究人员的直观目标之间仍然存在关键差距，特别是在使用自然语言将复杂任务与人类意图联系起来方面。大型语言模型已显示出解释人类意图的潜力，但由于专业知识要求、多模态数据整合以及自然语言与生物分子之间的语义对齐等挑战，它们在生物分子研究中的应用仍处于萌芽阶段。为了解决这些限制，我们提出了InstructBioMol，一个旨在通过对自然语言、分子和蛋白质进行全面的任意到任意对齐来弥合自然语言与生物分子之间鸿沟的大型语言模型。该模型可以将多模态生物分子作为输入，并使研究人员能够以自然语言阐明设计目标，从而提供满足精确生物需求的生物分子输出。实验结果表明，InstructBioMol能够根据人类指令理解和设计生物分子。特别是，它能够生成结合亲和力提高10%的药物分子，并设计出酶-底物对预测分数达到70.4的酶。这突显了其改变现实世界生物分子研究的潜力。代码可在https://github.com/HICAI-ZJU/InstructBioMol获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [492] [NUTMEG: Separating Signal From Noise in Annotator Disagreement](https://arxiv.org/abs/2507.18890)
> *NUTMEG：从标注者分歧中分离信号与噪声*

*Jonathan Ivey, Susan Gauch, David Jurgens* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 标注者分歧, 信号噪声分离, 贝叶斯模型, 众包, NLP数据质量

**Comment:** 

> **TL;DR:** NUTMEG是一个新的贝叶斯模型，它通过考虑标注者背景来区分人工标注数据中的噪声和系统性分歧，从而提高下游模型的性能。

**AI_Comments:** NUTMEG的创新之处在于其贝叶斯模型能够有效分离标注者分歧中的“信号”和“噪声”，这对于提高众包数据质量至关重要。该方法通过考虑标注者背景信息，更精细地处理了标注一致性问题，超越了传统聚合方法。其重要性在于能够提升基于人工标注数据的NLP模型的性能，尤其是在处理复杂、主观性强的任务时。潜在的局限性可能在于收集和利用标注者背景信息的成本和可行性，以及模型在非常规或极度稀疏的分歧模式下的表现。

<details>
  <summary>Details</summary>

**Motivation:** NLP模型依赖人工标注数据，但众包数据常导致标注冲突。传统方法将分歧视为错误，而近期研究认为分歧可能是真正的信号。目前少有模型能有效区分标注者分歧中的信号与噪声。

**Method:** 本文引入了NUTMEG，一个新型贝叶斯模型。该模型整合了标注者背景信息，以去除人工标注训练数据中的噪声标注，同时保留系统性分歧。

**Result:** 在合成数据上，NUTMEG在从系统性分歧标注中恢复真实值方面比传统聚合方法更有效。模型性能受子群体规模、分歧率和垃圾信息率的影响。使用NUTMEG聚合数据训练的下游模型显著优于传统聚合方法训练的模型。

**Conclusion:** 在训练人工标注数据时，考虑标注者能力和系统性分歧都至关重要。

> **ai_Abstract:** 本文提出了NUTMEG，一个贝叶斯模型，旨在解决人工标注数据中存在的标注者分歧问题。与传统将分歧视为错误的方法不同，NUTMEG通过整合标注者背景信息，能够区分并去除噪声标注，同时保留有意义的系统性分歧。实验证明，NUTMEG在从含有系统性分歧的数据中恢复真实值方面优于传统聚合方法，并且使用NUTMEG处理后的数据训练的下游模型表现出显著的性能提升。这强调了在处理人工标注数据时，同时考虑标注者能力和系统性分歧的重要性。

> **摘要翻译:** NLP模型通常依赖人工标注数据进行训练和评估。许多方法通过大量技能、背景和动机各异的标注者进行众包，导致标注冲突。传统上，这些冲突通过聚合方法解决，这些方法假设分歧是错误。近期工作认为，对于许多任务，标注者可能存在真正的分歧，并且这种变异应被视为信号而非噪声。然而，很少有模型能分离标注者分歧中的信号和噪声。在这项工作中，我们引入了NUTMEG，一个新型贝叶斯模型，它整合了标注者背景信息，以从人工标注的训练数据中去除噪声标注，同时保留系统性分歧。通过使用合成数据，我们表明NUTMEG在从具有系统性分歧的标注中恢复真实值方面比传统聚合方法更有效。我们进一步分析了子群体规模、分歧率和垃圾信息率的差异如何影响我们模型的性能。最后，我们证明了在NUTMEG聚合数据上训练的下游模型显著优于在传统聚合方法数据上训练的模型。我们的结果强调了在训练人工标注数据时，同时考虑标注者能力和系统性分歧的重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [495] [DocTER: Evaluating Document-based Knowledge Editing](https://arxiv.org/abs/2308.09954)
> *DocTER：评估基于文档的知识编辑*

*Suhang Wu, Ante Wang, Minlong Peng, Yujie Lin, Wenbo Li, Mingming Sun, Jinsong Su* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 知识编辑, 文档, DocTER, 评估基准, 神经网络

**Comment:** Information processing & management

> **TL;DR:** 引入DocTER基准，评估基于文档的知识编辑，发现其比基于三元组的编辑更具挑战性，并分析影响因素。

**AI_Comments:** 本文创新性地提出了基于文档的知识编辑范式，并构建了首个相关评估基准DocTER，填补了该领域的空白。其“提取-然后-编辑”管道为现有方法适应新范式提供了思路。研究结果揭示了基于文档编辑的挑战性，并深入分析了影响性能的多个关键因素，为未来研究指明了方向，具有重要的实践和理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 知识编辑旨在纠正神经网络中过时或不准确的知识。早期研究使用手动标注的事实三元组，而本文旨在探索使用易于获取的文档进行知识编辑。

**Method:** 建立了首个名为DocTER的评估基准，该基准包含用于编辑的反事实知识文档。引入了四维评估体系：编辑成功率、局部性、推理和跨语言迁移。为适应基于文档的任务，开发了“提取-然后-编辑”管道，先从文档中提取三元组再应用现有方法。

**Result:** 实验表明，使用文档进行知识编辑比使用三元组更具挑战性。即使是表现最佳的上下文编辑方法，在编辑成功率方面仍比使用黄金三元组低10个百分点，在推理和跨语言测试集上也有类似表现。论文还分析了影响任务性能的关键因素，包括提取三元组的质量、编辑知识在文档中的频率和位置、推理增强方法以及跨语言知识编辑在不同方向上的性能差异。

**Conclusion:** 基于文档的知识编辑比基于三元组的编辑更具挑战性，需要进一步研究。对影响性能因素的分析为未来研究提供了有价值的见解。

> **ai_Abstract:** 本文探索了基于文档的神经网络知识编辑，并为此建立了首个评估基准DocTER。该基准包含反事实知识文档，并引入了四维评估体系。研究开发了“提取-然后-编辑”管道以适应现有方法。实验结果表明，基于文档的编辑比基于三元组的编辑更具挑战性，即使是最佳方法也存在显著差距。论文还深入分析了影响性能的关键因素，为未来研究提供了方向。

> **摘要翻译:** 知识编辑旨在纠正神经网络中过时或不准确的知识。在本文中，我们探索使用易于获取的文档进行知识编辑，而不是早期研究中使用的手动标注的事实三元组。为了推动该领域的发展，我们建立了首个评估基准DocTER，其特点是包含用于编辑的反事实知识文档。我们引入了一个全面的四视角评估：编辑成功率、局部性、推理和跨语言迁移。为了使传统的基于三元组的知识编辑方法适应这项任务，我们开发了一个“提取-然后-编辑”管道，在应用现有方法之前从文档中提取三元组。对流行的知识编辑方法的实验表明，使用文档进行编辑比使用三元组提出了更大的挑战。在基于文档的场景中，即使是表现最佳的上下文编辑方法，在编辑成功率方面仍比使用黄金三元组低10个百分点。这一观察结果在推理和跨语言测试集中也成立。我们进一步分析了影响任务性能的关键因素，包括提取三元组的质量、编辑知识在文档中的频率和位置、各种增强推理的方法，以及跨语言知识编辑在不同方向上的性能差异，这为未来的研究提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [512] [AQuilt: Weaving Logic and Self-Inspection into Low-Cost, High-Relevance Data Synthesis for Specialist LLMs](https://arxiv.org/abs/2507.18584)
> *AQuilt：将逻辑和自检融入低成本、高相关性数据合成，用于专业领域大型语言模型*

*Xiaopeng Ke, Hexuan Deng, Xuebo Liu, Jun Rao, Zhenxi Song, Jun Yu, Min Zhang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 数据合成, 专业LLMs, 指令微调, 逻辑推理, 自检

**Comment:** 32 pages, 4 figures

> **TL;DR:** AQuilt是一种低成本、高相关性的数据合成框架，通过结合逻辑和自检，为专业领域LLMs生成指令微调数据，性能可与DeepSeek-V3媲美，但成本显著降低。

**AI_Comments:** AQuilt的创新之处在于其将逻辑和自检机制融入数据合成过程，显著提高了数据的质量和模型性能，同时大幅降低了成本。这对于在资源有限的情况下开发和部署专业领域LLMs具有重要意义，有助于推动LLMs在垂直领域的应用和普及。其低成本高效率的特点使其具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在通用领域表现出色，但在专业领域往往表现不佳。现有数据合成方法虽然有前景，但要么计算成本高昂，要么性能受限，并且在不同任务间的泛化能力不足。

**Method:** 本文提出了AQuilt框架，用于从无标签数据为任何专业领域构建指令微调数据，其核心组成包括回答（Answer）、问题（Question）、无标签数据（Unlabeled data）、检查（Inspection）、逻辑（Logic）和任务类型（Task type）。通过整合逻辑和自检机制，AQuilt鼓励推理过程和自我检查，以提升模型性能。此外，可定制的任务指令能够生成针对任何任务的高质量数据。作者构建了一个包含703k示例的数据集来训练一个强大的数据合成模型。

**Result:** 实验结果表明，AQuilt的性能与DeepSeek-V3相当，但生产成本仅为DeepSeek-V3的17%。进一步分析显示，AQuilt生成的数据对下游任务表现出更高的相关性。

**Conclusion:** AQuilt通过整合逻辑和自检机制，提供了一种低成本、高相关性的数据合成方法，有效解决了专业领域LLMs数据匮乏和现有方法局限性的问题，显著提升了模型性能并降低了成本。

> **ai_Abstract:** AQuilt是一个创新的框架，旨在为专业领域的大型语言模型（LLMs）解决数据合成的挑战。它通过整合逻辑推理和自检机制，从无标签数据高效生成高质量、高相关性的指令微调数据。实验证明，AQuilt在性能上与DeepSeek-V3相当，但成本仅为其17%，并且其生成的数据对下游任务表现出更高的相关性。该研究为专业LLMs的数据扩充提供了经济高效且高性能的解决方案。

> **摘要翻译:** 尽管大型语言模型（LLMs）在通用领域表现出色，但在专业领域往往表现不佳。现有方法通常依赖数据合成方法，通过使用无标签数据捕捉领域特定特征并取得有希望的结果。然而，这些方法要么计算成本高昂，要么性能受限，同时在不同任务间的泛化能力不足。为解决这些挑战，我们提出了AQuilt，一个用于从相应无标签数据为任何专业领域构建指令微调数据的框架，其组成包括回答（Answer）、问题（Question）、无标签数据（Unlabeled data）、检查（Inspection）、逻辑（Logic）和任务类型（Task type）。通过整合逻辑和自检，我们鼓励推理过程和自我检查以提升模型性能。此外，可定制的任务指令能够为任何任务生成高质量数据。因此，我们构建了一个包含703k示例的数据集来训练一个强大的数据合成模型。实验表明，AQuilt的性能与DeepSeek-V3相当，但生产成本仅为后者的17%。进一步分析表明，我们生成的数据对下游任务具有更高的相关性。源代码、模型和脚本可在https://github.com/Krueske/AQuilt获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [514] [A Comprehensive Evaluation of Semantic Relation Knowledge of Pretrained Language Models and Humans](https://arxiv.org/abs/2412.01131)
> *预训练语言模型与人类语义关系知识的综合评估*

*Zhihan Cao, Hiroaki Yamada, Simone Teufel, Takenobu Tokunaga* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 语义关系, 预训练语言模型, 知识评估, 人机比较, 知识差距

**Comment:** 

> **TL;DR:** 本文对预训练语言模型（PLMs）的语义关系知识进行了全面评估，涵盖了超纲词、下纲词、整体词、部分词、反义词和同义词五种关系，并与人类表现进行了比较。结果显示，PLMs在所有语义关系上与人类存在显著知识差距，且因果语言模型不一定优于掩码语言模型，反义词是模型表现较好的特例。

**AI_Comments:** 本文通过引入更全面的语义关系类型和评估指标，并首次将PLMs与人类表现进行直接比较，显著推进了对PLMs语义知识理解的评估。其创新点在于评估范围的扩展和人机对比的引入，揭示了PLMs在语义知识方面与人类的差距，为未来模型改进提供了明确方向。研究指出了因果语言模型并非总优于掩码语言模型，以及反义词是模型表现较好的特例，这些发现对模型选择和特定任务优化具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究对预训练语言模型（PLMs）的语义关系知识评估不全面，通常只关注上位词关系，且未将PLMs的表现与人类在相同任务上的表现进行比较，导致对模型语义关系知识的理解不完整。

**Method:** 本研究提出了一个全面的评估框架，涵盖了超纲词之外的五种语义关系：下纲词、整体词、部分词、反义词和同义词。采用了五个指标（其中两个是新引入的）：完备性、完整性、对称性、原型性和可区分性，以公平地比较人类和模型在相同任务上的表现。实验涉及六个预训练语言模型（四个掩码语言模型和两个因果语言模型）。

**Result:** 实验结果表明，人类和模型在所有语义关系上都存在显著的知识差距。通常，尽管因果语言模型被广泛使用，但它们并不总是比掩码语言模型表现得更好。反义词是一种例外关系，所有模型在该关系上表现都相当不错。

**Conclusion:** 预训练语言模型在语义关系知识方面与人类存在显著差距，尤其是在超纲词之外的关系上。不同类型的预训练语言模型在语义理解能力上表现各异，且因果语言模型并非在所有情况下都优于掩码语言模型，但模型在反义词关系上表现相对较好。

> **ai_Abstract:** 本文针对预训练语言模型（PLMs）在语义关系知识评估方面的不足，提出了一个全面的评估框架。该框架不仅扩展了评估的语义关系类型（包括下位词、整体词、部分词、反义词和同义词），还引入了新的评估指标，并首次将PLMs与人类在相同任务上的表现进行比较。实验结果表明，PLMs在语义关系理解上与人类存在显著差距，且不同PLM架构（掩码与因果）在性能上表现出复杂性，其中反义词是模型表现较好的特例。

> **摘要翻译:** 最近，许多工作都关注预训练语言模型（PLMs）究竟学习了语言的哪些方面以及它们是如何学习的这一谜团。这类研究的一个方向是调查PLMs关于语义关系的知识。然而，语义关系的许多方面仍未被探索。通常，只考虑了一种关系，即上位词关系。此外，之前的工作没有测量人类在与PLMs执行相同任务时的表现。这意味着目前对这些模型语义关系知识的程度只有不完整的认识。为了弥补这一空白，我们引入了一个全面的评估框架，涵盖了上位词之外的五种关系，即下位词、整体词、部分词、反义词和同义词。我们使用五个指标（其中两个是新引入的）来评估语义关系知识最近未处理的方面，即完备性、完整性、对称性、原型性和可区分性。利用这些指标，我们可以公平地比较人类和模型在相同任务上的表现。我们的大量实验涉及六个PLMs，包括四个掩码语言模型和两个因果语言模型。结果揭示了人类和模型在所有语义关系上都存在显著的知识差距。总的来说，因果语言模型尽管被广泛使用，但并不总是比掩码语言模型表现得更好。反义词是所有模型表现都相当不错的例外关系。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [519] [Data Augmentation for Spoken Grammatical Error Correction](https://arxiv.org/abs/2507.19374)
> *口语语法纠错的数据增强*

*Penny Karanasou, Mengjie Qian, Stefano Bannò, Mark J. F. Gales, Kate M. Knill* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-25**

**Keywords:** 口语语法纠错, 数据增强, 音频-文本对, 语法错误, 不流利性

**Comment:** This work has been accepted by ISCA SLaTE 2025

> **TL;DR:** 针对口语语法纠错(SGEC)的数据资源不足问题，本文提出了一种全自动方法来生成带语法错误和不流利性的音频-文本对，并设计了评估指标，以增强SGEC数据集。

**AI_Comments:** 本文的创新点在于提出了一个全自动的数据增强方法来解决口语语法纠错领域的数据稀缺问题，并设计了评估指标来衡量生成数据的质量。这对于推动SGEC研究具有重要意义，尤其是在缺乏高质量标注语音数据的背景下。其方法考虑了文本和声学特征的保持以及对语言评估分数的影响，显示出实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的语法纠错(GEC)有强大的基准数据集，但口语语法纠错(SGEC)的高质量标注口语数据集仍然资源不足。

**Method:** 提出了一种全自动方法来生成带有语法错误和不流利性的音频-文本对。此外，还提出了一系列客观指标，用于评估生成的数据并选择更适合SGEC的数据集。目标是生成一个增强数据集，该数据集在提供新型错误的同时，保持原始数据的文本和声学特征，并且不改变第二语言(L2)学习者的语言评估分数。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对口语语法纠错（SGEC）领域高质量标注数据集稀缺的问题，提出了一种全自动的数据增强方法。该方法能生成包含语法错误和不流利性的音频-文本对，并引入客观指标来评估和选择生成的数据。研究旨在创建一个既能保留原始数据特征，又能引入新错误类型，且不影响语言评估分数的增强数据集。该增强数据在书面GEC和SGEC任务上进行了评估，实验基于S&I语料库。

> **摘要翻译:** 尽管语法纠错（GEC）存在强大的基准数据集，但口语语法纠错（SGEC）的高质量标注口语数据集仍然资源不足。在本文中，我们提出了一种全自动方法来生成带有语法错误和不流利性的音频-文本对。此外，我们提出了一系列客观指标，可用于评估生成的数据并选择更适合SGEC的数据集。目标是生成一个增强数据集，该数据集在提供新型错误的同时，保持原始数据的文本和声学特征。这个增强数据集应该增强和丰富原始语料库，同时不改变第二语言（L2）学习者的语言评估分数。我们评估了增强语料库在书面GEC（文本部分）和SGEC（音频-文本对）中的使用。我们的实验是在S&I语料库上进行的，这是第一个公开可用的带有语法错误标注的语音数据集。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [523] [Locate-and-Focus: Enhancing Terminology Translation in Speech Language Models](https://arxiv.org/abs/2507.18263)
> *定位与聚焦：增强语音语言模型中的术语翻译*

*Suhang Wu, Jialong Tang, Chengyi Yang, Pei Zhang, Baosong Yang, Junhui Li, Junfeng Yao, Min Zhang, Jinsong Su* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 语音翻译, 术语翻译, 定位与聚焦, 语音语言模型

**Comment:** Accepted at ACL 2025

> **TL;DR:** 提出了一种“定位与聚焦”方法，通过定位语音中的术语并关联多模态知识，提高了语音翻译中术语的准确性。

**AI_Comments:** 这篇论文提出了一种创新的两阶段方法来解决语音翻译中术语翻译的痛点。其亮点在于通过“定位”来减少噪声干扰，并通过“聚焦”来充分利用多模态翻译知识，这对于提升专业领域语音翻译的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管直接语音翻译（ST）日益受到关注，但准确翻译话语中的术语仍是一大挑战。现有方法常受无关噪声干扰，且未能充分利用翻译知识。

**Method:** 本文提出了一种新颖的“定位与聚焦”方法用于术语翻译。该方法首先有效定位话语中包含术语的语音片段以构建翻译知识，从而最小化无关信息。随后，它从音频和文本两种模态将翻译知识与话语及假设关联起来，使语音翻译模型在翻译过程中能更好地聚焦于翻译知识。

**Result:** 实验结果表明，该方法能有效定位话语中的术语并提高术语翻译的成功率，同时保持了稳健的通用翻译性能。

**Conclusion:** 该研究提出并验证了“定位与聚焦”方法在语音翻译中提升术语翻译准确性的有效性，同时不损害整体翻译性能。

> **ai_Abstract:** 本文提出了一种新颖的“定位与聚焦”方法，旨在解决语音翻译中术语翻译不准确的问题。该方法通过首先定位话语中包含术语的语音片段来构建精炼的翻译知识，并将其与多模态信息关联，使语音翻译模型能更有效地聚焦于关键术语。实验结果表明，该方法显著提高了术语翻译的成功率，并保持了良好的整体翻译性能。

> **摘要翻译:** 直接语音翻译（ST）如今受到越来越多的关注，然而，话语中术语的准确翻译仍然是一个巨大的挑战。在这方面，当前的研究主要集中于将各种翻译知识融入ST模型。然而，这些方法往往难以应对无关噪声的干扰，并且不能充分利用翻译知识。为了解决这些问题，本文提出了一种新颖的“定位与聚焦”术语翻译方法。它首先有效定位话语中包含术语的语音片段以构建翻译知识，从而最大限度地减少ST模型的无关信息。随后，它从音频和文本两种模态将翻译知识与话语及假设关联起来，使ST模型在翻译过程中能更好地聚焦于翻译知识。在各种数据集上的实验结果表明，我们的方法能有效定位话语中的术语并提高术语翻译的成功率，同时保持了稳健的通用翻译性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [536] [REPRO-Bench: Can Agentic AI Systems Assess the Reproducibility of Social Science Research?](https://arxiv.org/abs/2507.18901)
> *REPRO-Bench：智能体AI系统能否评估社会科学研究的可重复性？*

*Chuxuan Hu, Liyun Zhang, Yeji Lim, Aum Wadhwani, Austin Peters, Daniel Kang* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 可重复性评估, 智能体AI系统, 社会科学, REPRO-Bench, REPRO-Agent

**Comment:** Accepted to ACL 2025 Findings

> **TL;DR:** 引入REPRO-Bench基准评估智能体AI系统在社会科学研究可重复性评估中的能力，发现现有系统表现不佳，但开发的新智能体REPRO-Agent显著提升了准确率。

**AI_Comments:** 本文的创新点在于提出了一个更全面、更贴近真实世界的社会科学研究可重复性评估基准REPRO-Bench，并首次系统性地探索了智能体AI系统在此领域的应用潜力。其重要性体现在为AI在科学研究严谨性保障方面提供了新的研究方向和挑战。尽管现有智能体表现不佳，但REPRO-Agent的开发证明了改进的可能性，也突显了当前AI技术在处理复杂、多模态科学评估任务上的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 手动评估社会科学论文的可重复性成本高昂。现有研究复现基准存在局限性，例如只关注代码和数据复现，过度简化真实场景，缺乏数据格式和编程语言多样性。本研究旨在评估智能体AI系统自动化此过程的能力，并解决现有基准的问题。

**Method:** 引入了REPRO-Bench，一个包含112个任务实例的集合，每个实例代表一篇带有公开复现报告的社会科学论文。智能体被要求根据原始论文PDF和复现包评估论文的可重复性。REPRO-Bench提供与真实世界评估复杂性相当的端到端评估任务。研究评估了三个代表性AI智能体，并基于实证分析开发了REPRO-Agent。

**Result:** 在REPRO-Bench上，表现最佳的现有AI智能体准确率仅为21.4%。开发的REPRO-Agent将现有智能体所达到的最高准确率提高了71%。

**Conclusion:** 需要开发更先进的AI智能体来自动化真实世界中的可重复性评估。

> **ai_Abstract:** 本研究提出了REPRO-Bench，一个用于评估智能体AI系统在社会科学论文可重复性评估能力的基准。该基准包含112个真实世界的任务实例，旨在解决现有基准的局限性。初步评估显示，现有智能体表现不佳（最高准确率21.4%）。为此，研究开发了REPRO-Agent，显著提升了评估准确率，并强调了未来开发更先进AI智能体自动化可重复性评估的必要性。

> **摘要翻译:** 评估社会科学论文的可重复性对于促进研究过程的严谨性至关重要，但手动评估成本高昂。随着智能体AI系统（即AI智能体）的最新进展，我们旨在评估其自动化这一过程的能力。然而，现有用于复现研究论文的基准（1）仅关注使用提供的代码和数据复现结果，而不评估其与论文的一致性；（2）过度简化了真实世界场景；（3）缺乏数据格式和编程语言的必要多样性。为了解决这些问题，我们引入了REPRO-Bench，这是一个包含112个任务实例的集合，每个实例代表一篇带有公开复现报告的社会科学论文。智能体被要求根据原始论文PDF和相应的复现包评估论文的可重复性。REPRO-Bench的特点是针对社会科学论文可重复性进行端到端评估任务，其复杂性与真实世界评估相当。我们在REPRO-Bench上评估了三个代表性AI智能体，其中表现最佳的智能体准确率仅为21.4%。基于我们的实证分析，我们开发了REPRO-Agent，它将现有智能体所达到的最高准确率提高了71%。我们得出结论，应开发更先进的AI智能体来自动化真实世界中的可重复性评估。REPRO-Bench已公开在https://github.com/uiuc-kang-lab/REPRO-Bench。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [544] [LLMs are Also Effective Embedding Models: An In-depth Overview](https://arxiv.org/abs/2412.12591)
> *LLMs也是有效的嵌入模型：深度综述*

*Chongyang Tao, Tao Shen, Shen Gao, Junshuo Zhang, Zhen Li, Kai Hua, Wenpeng Hu, Zhengwei Tao, Shuai Ma* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 大型语言模型, 嵌入模型, 直接提示, 数据中心调优, 综述

**Comment:** 38 pages

> **TL;DR:** 本综述深入探讨了大型语言模型（LLMs）如何从传统编码器模型转变为有效的嵌入模型，并详细介绍了两种主要策略（直接提示和数据中心调优）、高级方法、影响因素以及当前面临的挑战。

**AI_Comments:** 这篇综述非常及时且重要，因为它系统地梳理了LLMs作为嵌入模型这一新兴且快速发展的领域。其创新之处在于首次全面概述了从LLMs生成高质量嵌入的两种主要范式（直接提示和数据中心调优），并详细探讨了各种高级应用场景和影响因素。这对于理解LLMs在NLP领域的最新进展，特别是其作为通用表征工具的潜力至关重要。同时，文章也坦诚地指出了当前面临的挑战和局限性，为未来的研究指明了方向，具有很高的实践指导意义和理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）在自然语言处理领域取得突破性进展，其作为嵌入模型的有效性日益受到关注，这标志着从传统编码器模型向解码器模型转变的范式。本综述旨在深入探讨这一转变，系统地概述LLMs作为嵌入模型的方法、挑战和未来方向，为研究人员和实践者提供宝贵资源。

**Method:** 本综述首先回顾了LLM时代之前的基本嵌入技术，然后详细介绍了两种主要策略来从LLM中派生嵌入：1) 直接提示（讨论提示设计和基本原理）；2) 数据中心调优（涵盖模型架构、训练目标、数据构建等方面）。此外，还涵盖了从长文本、多语言、代码、跨模态数据以及推理感知和领域特定场景中生成嵌入的高级方法，并讨论了影响嵌入模型选择的因素（性能/效率、密集/稀疏嵌入、池化策略、缩放定律）。

**Result:** 综述系统地梳理了LLMs作为嵌入模型的发展历程、核心策略、高级应用场景、影响因素，并指出了当前面临的限制和挑战，例如跨任务嵌入质量、效率与准确性之间的权衡、低资源、长上下文、数据偏差和鲁棒性等问题。

**Conclusion:** 本综述通过综合当前进展，突出关键挑战，并为未来旨在提高LLMs作为嵌入模型有效性和效率的工作提供了一个全面的框架，从而成为研究人员和实践者的宝贵资源。

> **ai_Abstract:** 本综述深入探讨了大型语言模型（LLMs）作为嵌入模型的兴起及其有效性，标志着从传统编码器模型向解码器LLMs的范式转变。文章详细审视了从LLMs生成嵌入的两种主要策略：直接提示和数据中心调优，并扩展到处理长文本、多语言、代码和跨模态数据等高级场景。此外，综述还讨论了影响嵌入模型选择的因素，如性能、效率和池化策略，并指出了当前面临的挑战，包括跨任务质量、效率与准确性权衡、低资源和数据偏差等。该综述旨在为研究人员和实践者提供一个全面框架，以促进LLMs在嵌入领域的未来研究和应用。

> **摘要翻译:** 大型语言模型（LLMs）通过在各种任务中取得最先进的性能，彻底改变了自然语言处理。最近，它们作为嵌入模型的有效性受到了关注，标志着从传统的仅编码器模型（如ELMo和BERT）向仅解码器、大规模LLMs（如GPT、LLaMA和Mistral）的范式转变。本综述对这一转变进行了深入概述，首先介绍了LLM时代之前的基本技术，然后通过两种主要策略从LLM中派生嵌入的基于LLM的嵌入模型。1）直接提示：我们主要讨论了提示设计和推导出有竞争力嵌入的潜在原理。2）以数据为中心的调优：我们涵盖了影响嵌入模型调优的广泛方面，包括模型架构、训练目标、数据构建等。在此基础上，我们还涵盖了从更长文本、多语言、代码、跨模态数据以及推理感知和其他领域特定场景中生成嵌入的高级方法。此外，我们讨论了影响嵌入模型选择的因素，例如性能/效率比较、密集与稀疏嵌入、池化策略和缩放定律。最后，本综述强调了将LLMs用于嵌入的局限性和挑战，包括跨任务嵌入质量、效率与准确性之间的权衡、低资源、长上下文、数据偏差、鲁棒性等。本综述通过综合当前进展、突出关键挑战并为未来旨在提高LLMs作为嵌入模型有效性和效率的工作提供一个全面的框架，从而成为研究人员和实践者的宝贵资源。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [552] [VeriMinder: Mitigating Analytical Vulnerabilities in NL2SQL](https://arxiv.org/abs/2507.17896)
> *VeriMinder：缓解NL2SQL中的分析漏洞*

*Shubham Mohole, Sainyam Galhotra* | **Category: cs.CL, cs.AI, cs.DB** | **Updated: 2025-07-23**

**Keywords:** NL2SQL, 分析漏洞, 认知偏差, VeriMinder, 大型语言模型

**Comment:** 

> **TL;DR:** VeriMinder是一个交互式系统，旨在帮助NLIDB用户识别并缓解分析问题中的认知偏差，通过引入上下文语义映射、Hard-to-Vary原则和优化的LLM驱动提示生成来实现。

**AI_Comments:** VeriMinder通过专注于解决NL2SQL中长期被忽视的认知偏差问题，展现了其创新性。它不仅提出了理论框架（如Hard-to-Vary原则），还结合了前沿的LLM技术来生成高质量提示，这为提高数据分析的可靠性提供了一个实用且有效的解决方案。其开源性质进一步提升了其重要性和潜在影响力。

<details>
  <summary>Details</summary>

**Motivation:** 自然语言数据库接口（NLIDBs）普及了数据分析，但对于缺乏统计分析背景的用户来说，如何提出无偏见的分析问题是一个紧迫的挑战。尽管文本到SQL生成精度研究很多，但解决分析问题中的认知偏差仍未得到充分探索。

**Method:** 本文提出了VeriMinder，一个用于检测和缓解分析漏洞的交互式系统。其方法包含三个关键创新点：1）一个针对特定分析背景下偏见的上下文语义映射框架；2）一个操作化“难以改变原则”（Hard-to-Vary principle）并指导用户进行系统数据分析的分析框架；3）一个优化的、由大型语言模型（LLM）驱动的系统，该系统通过多候选、批评反馈和自我反思的结构化过程生成高质量、任务特定的提示。

**Result:** 用户测试证实了VeriMinder的优点。在直接用户体验评估中，82.5%的参与者表示系统积极影响了分析质量。在对比评估中，VeriMinder在分析的具体性、全面性和准确性指标上，比替代方法至少高出20%。

**Conclusion:** VeriMinder系统作为一款网络应用，旨在帮助用户在数据分析过程中避免“错误问题”的漏洞。其代码库和提示已作为MIT许可的开源软件提供，以促进社区内的进一步研究和应用。

> **ai_Abstract:** VeriMinder是一个创新的交互式系统，旨在解决自然语言数据库接口（NLIDBs）中用户提问可能存在的认知偏差和分析漏洞。该系统通过引入上下文语义映射框架、操作化Hard-to-Vary原则的分析框架以及优化的LLM驱动提示生成机制，帮助用户构建无偏见的分析问题。用户测试表明，VeriMinder显著提升了分析质量，并在具体性、全面性和准确性方面优于现有方法，其开源实现有助于推动相关研究和应用。

> **摘要翻译:** 使用自然语言接口与数据库交互（NLIDBs）的应用系统使数据分析变得大众化。这种积极的发展也带来了一个紧迫的挑战，即帮助那些可能没有统计分析背景的用户，在使用这些系统时，能够提出无偏见的分析问题。尽管大量研究集中在文本到SQL的生成精度上，但解决分析问题中的认知偏差仍未得到充分探索。我们提出了VeriMinder，https://veriminder.ai，一个用于检测和缓解此类分析漏洞的交互式系统。我们的方法引入了三个关键创新点：(1) 一个针对特定分析上下文相关偏见的上下文语义映射框架；(2) 一个操作化“难以改变原则”并指导用户进行系统数据分析的分析框架；(3) 一个优化的、由大型语言模型（LLM）驱动的系统，该系统通过包含多个候选、批评反馈和自我反思的结构化过程生成高质量、任务特定的提示。用户测试证实了我们方法的优点。在直接用户体验评估中，82.5%的参与者表示对分析质量产生了积极影响。在对比评估中，VeriMinder的得分显著高于替代方法，在分析的具体性、全面性和准确性指标上至少好20%。我们的系统，作为一个网络应用程序实现，旨在帮助用户在数据分析过程中避免“错误问题”的漏洞。VeriMinder的代码库和提示，https://reproducibility.link/veriminder，作为MIT许可的开源软件提供，以促进社区内的进一步研究和采纳。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [561] [Detection of Adverse Drug Events in Dutch clinical free text documents using Transformer Models: benchmark study](https://arxiv.org/abs/2507.19396)
> *使用Transformer模型检测荷兰语临床自由文本中的不良药物事件：基准研究*

*Rachel M. Murphy, Nishant Mishra, Nicolette F. de Keizer, Dave A. Dongelmans, Kitty J. Jager, Ameen Abu-Hanna, Joanna E. Klopotowska, Iacer Calixto* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 不良药物事件, Transformer模型, 临床文本, 自然语言处理, 基准研究

**Comment:** 30 Pages, 5 Figures (Main Paper), 19 Pages, 2 Figures(Supplements).
  Rachel M. Murphy and Nishant Mishra are shared first authors. Joanna E.
  Klopotowska and Iacer Calixto are shared last authors

> **TL;DR:** 本研究为使用Transformer模型在荷兰语临床自由文本中检测不良药物事件设定了基准，发现MedRoBERTa.nl模型表现最佳。

**AI_Comments:** 本研究通过对多种Transformer模型在荷兰语临床自由文本中进行不良药物事件检测的系统性基准测试，填补了该领域的一个空白。其创新之处在于使用了真实世界的临床数据和多样的评估场景（包括内部和外部验证），并强调了针对ADE检测任务选择合适性能指标的重要性。这为未来在临床文本挖掘中应用语言模型提供了宝贵的实践指导和性能参照。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在为使用多种Transformer模型在荷兰语临床自由文本中检测不良药物事件（ADE）建立一个基准，并强调使用适合ADE检测任务和未来临床用途的性能指标的重要性。

**Method:** 研究训练了一个Bi-LSTM模型和四个基于Transformer的荷兰语或多语言编码模型（BERTje, RobBERT, MedRoBERTa.nl, NuNER），用于命名实体识别（NER）和关系分类（RC）任务。数据集包括102份经过详细标注的荷兰语ICU临床进展记录以及来自一家学术医院ICU和两家非学术医院内科病房的匿名化临床自由文本。模型通过内部评估（使用金标准和预测实体）和外部验证（文档级别ADE检测）进行评估，报告了微观和宏观平均F1分数。

**Result:** 尽管模型在ADE关系分类任务上的差异很小，但MedRoBERTa.nl是表现最佳的模型，使用金标准时宏观平均F1分数为0.63，使用预测实体时为0.62。在外部验证中，MedRoBERTa.nl模型也表现最佳，使用预测实体时召回率在0.67到0.74之间，这意味着67%到74%的含有ADE的出院信被检测到。

**Conclusion:** 本基准研究提出了一种稳健且具有临床意义的方法，用于评估语言模型在临床自由文本中进行ADE检测。研究强调了使用适合临床自由文本中ADE检测任务和未来临床应用的适当性能指标的必要性。

> **ai_Abstract:** 本研究旨在为使用Transformer模型在荷兰语临床自由文本中检测不良药物事件（ADE）建立基准。研究训练了Bi-LSTM和四种Transformer模型（BERTje, RobBERT, MedRoBERTa.nl, NuNER）进行命名实体识别和关系分类，使用了ICU进展记录和出院信等荷兰语临床文本数据。评估方法包括内部和外部验证，并报告了F1分数和召回率。结果显示MedRoBERTa.nl模型表现最佳，其在外部验证中对含有ADE的出院信的检测召回率达到67%-74%。本研究为ADE检测的语言模型评估提供了稳健方法，并强调了使用适当性能指标的重要性。

> **摘要翻译:** 本研究使用多种Transformer模型、临床场景和适合目的的性能指标，为荷兰语临床自由文本中不良药物事件（ADE）的检测设定了一个基准。我们训练了一个双向长短期记忆（Bi-LSTM）模型和四个基于Transformer的荷兰语和/或多语言编码模型（BERTje、RobBERT、MedRoBERTa.nl和NuNER），用于命名实体识别（NER）和关系分类（RC）任务，使用了102份经过丰富标注的荷兰语ICU临床进展记录。重复使用了来自一家学术医院重症监护室（ICU）患者的匿名化自由文本临床进展记录，以及来自两家非学术医院内科病房患者的出院信。我们使用金标准（两步任务）和预测实体（端到端任务）对我们的ADE RC模型进行了内部评估。此外，所有模型都在文档级别对ADE检测进行了外部验证。考虑到数据集中ADE的不平衡性，我们报告了微观和宏观平均F1分数。尽管模型在ADE RC任务上的差异很小，但MedRoBERTa.nl是表现最佳的模型，使用金标准时宏观平均F1分数为0.63，使用预测实体时为0.62。MedRoBERTa.nl模型在我们的外部验证中也表现最佳，使用预测实体时召回率在0.67到0.74之间，这意味着67%到74%的含有ADE的出院信被检测到。我们的基准研究提出了一种稳健且具有临床意义的方法，用于评估语言模型在临床自由文本文档中进行ADE检测。我们的研究强调了使用适合临床自由文本文档中ADE检测任务和未来预期临床用途的适当性能指标的必要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [563] [Quantifying the Uniqueness and Divisiveness of Presidential Discourse](https://arxiv.org/abs/2401.01405)
> *量化总统言论的独特性和分裂性*

*Karen Zhou, Alexander A. Meitus, Milo Chase, Grace Wang, Anne Mykland, William Howell, Chenhao Tan* | **Category: cs.CL, cs.AI, cs.CY, cs.SI** | **Updated: 2025-07-23**

**Keywords:** 总统言论,独特性,分裂性,大型语言模型,唐纳德·特朗普

**Comment:** Published in PNAS Nexus:
  https://academic.oup.com/pnasnexus/article/3/10/pgae431/7814873

> **TL;DR:** 本研究量化了美国总统言论的独特性和分裂性，发现唐纳德·特朗普的言论模式明显不同于近期所有主要政党总统候选人，尤其体现在其分裂性和对抗性语言的使用上。

**AI_Comments:** 本文的创新之处在于提出了基于大型语言模型的新颖独特性度量标准和针对分裂性言论的新词汇，为量化政治话语提供了新工具。其重要性在于揭示了特定政治人物（如唐纳德·特朗普）在言论模式上的显著偏离，为理解现代政治沟通的演变提供了实证支持。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探究美国总统的言论是否存在可辨别的差异，如果存在，具体体现在哪些方面，以及这些差异是否局限于单一的交流媒介。

**Method:** 本文引入了一种基于大型语言模型的新颖独特性度量标准，开发了一种针对分裂性言论的新词汇，并提出了一个评估总统如何独特地谈论其政治对手的框架。将这些工具应用于各种总统演讲语料库。

**Result:** 研究发现大量证据表明唐纳德·特朗普的言论模式与近期所有主要政党总统候选人的言论模式存在显著差异。特朗普比他的共和党同僚更具独特性，后者的独特性值更接近民主党人。造成这些差异的原因是特朗普使用了分裂性和对抗性语言，尤其是在针对其政治对手时。这些差异在各种测量策略中都成立，出现在竞选活动和官方总统演讲中，并且似乎并非总统沟通世俗变化的产物。

**Conclusion:** 唐纳德·特朗普的言论模式在独特性和分裂性方面显著不同于其他近期美国总统，这主要归因于其对抗性语言的使用，且这种差异在不同场合和测量方法下均保持一致。

> **ai_Abstract:** 本研究通过引入基于大型语言模型的新颖独特性度量标准和分裂性言论词汇，分析了美国总统言论的差异。研究发现唐纳德·特朗普的言论模式与近期其他主要政党总统候选人显著不同，其独特性高于共和党同僚，且这种差异主要源于其对政治对手使用的分裂性和对抗性语言。这些发现适用于不同沟通场合和测量策略。

> **摘要翻译:** 美国总统的言论是否明显不同？如果不同，体现在哪些方面？这些差异是否仅限于单一的传播媒介？为了调查这些问题，本文引入了一种基于大型语言模型的新颖独特性度量标准，开发了一种针对分裂性言论的新词汇，并提出了一个评估总统如何独特地谈论其政治对手的框架。将这些工具应用于各种总统演讲语料库，我们发现大量证据表明唐纳德·特朗普的言论模式与近期所有主要政党总统候选人的言论模式存在显著差异。特朗普比他的共和党同僚更具独特性，后者的独特性值更接近民主党人。造成这些差异的原因是特朗普使用了分裂性和对抗性语言，尤其是在针对其政治对手时。这些差异在各种测量策略中都成立，出现在竞选活动和官方总统演讲中，并且似乎并非总统沟通世俗变化的产物。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [572] [SLoW: Select Low-frequency Words! Automatic Dictionary Selection for Translation on Large Language Models](https://arxiv.org/abs/2507.18902)
> *SLoW：选择低频词！大型语言模型翻译的自动词典选择*

*Hongyuan Lu, Zixuan Li, Zefan Zhang, Wai Lam* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 自动词典选择, 大型语言模型, 低频词, 机器翻译, Token效率

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）的语言支持有限，字典提示法虽能增强翻译但成本高昂。本文提出自动词典选择（ADS）任务，并提出SLoW方法，通过选择低频词典来节省token并提升翻译性能，且无需访问训练数据。

**AI_Comments:** 本文提出的SLoW方法极具创新性，它通过引入“自动词典选择”（ADS）这一新任务，有效解决了大型语言模型多语言翻译中效率与成本的矛盾。其核心优势在于无需依赖通常难以获取的训练数据进行频率估计，仅通过选择低频词典就能显著提升翻译性能并节省token，这对于LLMs的实际应用具有重要意义。SLoW的通用性和在不微调LLMs的情况下实现性能提升的能力，使其成为一个非常实用的解决方案。尽管抽象中未提及具体局限性，但未来工作可能会探索其在更广泛或特定领域语言上的表现。

<details>
  <summary>Details</summary>

**Motivation:** 全球有7000多种语言，但现有大型语言模型（LLMs）仅支持数百种语言。尽管基于词典的提示方法可以增强LLMs的翻译能力，但大多数方法使用所有可用词典，导致高昂的token消耗。因此，需要一种能在token消耗和翻译性能之间取得平衡的灵活方法。

**Method:** 本文提出了一种名为“自动词典选择”（ADS）的新任务，旨在自动选择用于增强翻译的词典。为此，我们提出了一种新颖有效的方法，称为SLoW（Select Low-frequency Words!），它选择频率较低的词典。SLoW的独特优势在于：1. 无需访问训练数据进行频率估计（通常不可用）。2. 继承了基于词典方法的优势，即无需对LLMs进行额外微调。

**Result:** 在FLORES的100种语言上的实验结果表明，SLoW超越了强大的基线方法，并能显著节省token使用量。对于许多语言，其翻译性能甚至超越了使用完整词典的基线。一个令人震惊的事实是，无需使用实际训练数据（通常无法获取）进行频率估计，使用公共资源获得的估计频率在改善ChatGPT、Llama和DeepSeek的翻译方面仍然明显有效。

**Conclusion:** SLoW方法通过选择低频词典，在不访问训练数据的情况下，有效地实现了大型语言模型翻译中的自动词典选择，显著节省了token并提升了性能，甚至在某些情况下超越了使用完整词典的效果。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）在多语言翻译中语言支持有限且字典提示法成本高的问题，提出了一项名为“自动词典选择”（ADS）的新任务。研究引入了SLoW（Select Low-frequency Words!）方法，该方法通过选择低频词典来优化翻译。SLoW的创新之处在于其无需访问训练数据即可进行频率估计，并能有效节省token消耗。实验结果表明，SLoW在100种语言上不仅超越了现有基线，还在许多情况下实现了比使用完整词典更好的翻译性能，同时显著降低了成本。

> **摘要翻译:** 世界上有7000多种语言，而当前的大型语言模型（LLMs）仅支持数百种语言。基于词典的提示方法可以增强它们的翻译能力，但大多数方法使用所有可用的词典，这可能会非常昂贵。相反，在token消耗和翻译性能之间取得平衡将更加灵活。本文提出了一项新颖的任务，称为自动词典选择（ADS）。该任务的目标是自动选择使用哪个词典来增强翻译。我们提出了一种新颖有效的方法，我们称之为SLoW（Select Low-frequency Words!），它选择那些频率较低的词典。我们的方法具有独特的优势。首先，无需访问训练数据进行频率估计（这通常是不可用的）。其次，它继承了基于词典方法的优势，即无需对LLMs进行额外的微调。FLORES上100种语言的实验结果表明，SLoW超越了强大的基线，并且可以明显节省token使用量，许多语言甚至超越了完整词典基线的翻译性能。一个令人震惊的事实是，无需使用实际训练数据（通常无法获取）进行频率估计，使用公共资源获得的估计频率在改善ChatGPT、Llama和DeepSeek的翻译方面仍然明显有效。代码和数据将在发布后提供。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [575] [T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation](https://arxiv.org/abs/2501.12612)
> *T2ISafety：评估图像生成中公平性、毒性和隐私的基准*

*Lijun Li, Zhelun Shi, Xuhao Hu, Bowen Dong, Yiran Qin, Xihui Liu, Lu Sheng, Jing Shao* | **Category: cs.CL, cs.CR** | **Updated: 2025-07-25**

**Keywords:** T2ISafety, 图像生成, 安全性, 公平性, 毒性, 隐私

**Comment:** Accepted at CVPR 2025

> **TL;DR:** T2ISafety 是一个评估文生图模型在毒性、公平性和隐私方面安全性的新基准，它包含详细的任务层次结构、大规模数据集和改进的评估器，揭示了现有模型在这些方面存在的问题。

**AI_Comments:** T2ISafety的创新之处在于其构建了一个全面且分层的安全评估框架，涵盖了毒性、公平性和隐私这三个关键但常被忽视的维度。其大规模手动标注数据集和能够识别GPT等模型未检测到的风险的评估器，显著提升了T2I模型安全评估的深度和广度。这项工作的重要性在于为文生图模型的负责任开发提供了急需的工具和见解，揭示了即使是先进模型也存在的持续安全漏洞。

<details>
  <summary>Details</summary>

**Motivation:** 尽管文生图模型取得了快速进展，但它们在生成有害、偏见或私人内容方面存在显著的安全隐患。当前对文生图模型安全性的评估仍处于早期阶段，许多关键风险尚未被充分探索。

**Method:** 研究人员引入了T2ISafety基准，用于评估文生图模型在毒性、公平性和隐私三个关键领域的安全性。他们构建了一个包含12个任务和44个类别的详细层次结构，并收集了70K个相应的提示。基于此分类法和提示集，他们构建了一个包含68K张手动标注图像的大规模文生图数据集，并训练了一个能够检测先前工作中未识别的关键风险的评估器。

**Result:** 对12个主流扩散模型在T2ISafety上进行评估后，发现了一些问题，包括持续存在的种族公平性问题、生成有害内容的倾向，以及模型间隐私保护的显著差异，即使使用了概念擦除等防御方法。

**Conclusion:** T2ISafety基准揭示了当前文生图模型在公平性、毒性和隐私保护方面存在的显著安全问题，表明即使是先进的模型也未能有效解决这些风险。

> **ai_Abstract:** 本文介绍了T2ISafety，一个用于评估文生图模型安全性的新基准，涵盖毒性、公平性和隐私三个关键领域。该基准包含一个详细的任务和类别层次结构，一个包含70K提示和68K手动标注图像的大规模数据集，以及一个能检测现有模型未能识别风险的评估器。通过对12个扩散模型的评估，研究揭示了模型在种族公平性、毒性生成和隐私保护方面存在的普遍问题。

> **摘要翻译:** 文生图（T2I）模型取得了快速发展，能够根据文本提示在各个领域生成高质量图像。然而，这些模型存在显著的安全隐患，包括生成有害、偏见或私人内容的风险。当前对T2I安全性评估的研究仍处于早期阶段。尽管已经做出了一些努力来评估特定安全维度的模型，但许多关键风险仍未被探索。为了弥补这一空白，我们引入了T2ISafety，这是一个评估T2I模型在三个关键领域：毒性、公平性和偏见方面的安全基准。我们基于这三个领域构建了一个包含12个任务和44个类别的详细层次结构，并精心收集了70K个相应的提示。基于此分类法和提示集，我们构建了一个包含68K张手动标注图像的大规模T2I数据集，并训练了一个能够检测先前工作未能识别的关键风险的评估器，包括甚至像GPT这样超大型专有模型都无法正确检测的风险。我们评估了12个主流扩散模型在T2ISafety上的表现，并揭示了几个问题，包括持续存在的种族公平性问题、生成有害内容的倾向，以及即使使用了概念擦除等防御方法，模型间隐私保护也存在显著差异。数据和评估器已在https://github.com/adwardlee/t2i_safety发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [603] [Towards Domain Specification of Embedding Models in Medicine](https://arxiv.org/abs/2507.19407)
> *医学嵌入模型领域规范化研究*

*Mohammad Khodadad, Ali Shiraee, Mahdi Astaraki, Hamidreza Mahyar* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 医学文本嵌入, 领域规范化, 基准测试, MEDTE, 自监督学习

**Comment:** 

> **TL;DR:** 本文提出了一种名为MEDTE的新型医学文本嵌入模型，并创建了一个包含51个任务的综合基准测试套件，以解决现有医学嵌入模型在数据多样性和评估通用性方面的不足，结果显示其性能优于现有SOTA模型。

**AI_Comments:** 本文的创新之处在于提出了一个专门针对医学领域的文本嵌入模型MEDTE，并构建了一个前所未有的、包含51个任务的综合医学基准测试套件，这对于推动医学文本处理和评估标准具有重要意义。通过解决现有模型在数据多样性和评估通用性上的局限性，该研究为未来的医疗保健应用奠定了更坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有医学文本嵌入模型存在两个主要缺陷：一是大多模型训练数据狭窄且方法过时，无法捕捉医学术语和语义的多样性；二是现有评估基准不充分，无法在真实世界的医学任务中泛化。

**Method:** 本文利用MEDTE模型，该模型通过跨多个数据源的自监督对比学习，在多样化的医学语料库上进行了广泛微调，以提供鲁棒的医学文本嵌入。同时，本文提出了一个包含51个任务的综合基准测试套件，涵盖分类、聚类、配对分类和检索，该套件基于MTEB但针对医学文本的细微差别进行了定制。

**Result:** 本文的组合方法不仅建立了一个鲁棒的评估框架，而且产生的嵌入模型在不同任务中始终优于现有的最先进替代方案。

**Conclusion:** 通过提出MEDTE模型和定制的医学基准测试套件，本文有效解决了当前医学文本嵌入模型在数据多样性和评估通用性方面的不足，并显著提升了模型性能。

> **ai_Abstract:** 本文旨在解决当前医学文本嵌入模型在数据多样性和评估通用性方面的不足。作者提出了MEDTE，一个通过自监督对比学习在多样化医学语料库上微调的通用文本嵌入（GTE）模型，以生成鲁棒的医学文本嵌入。此外，本文还构建了一个包含51个任务的综合医学基准测试套件，该套件针对医学文本的特点进行了定制。实验结果表明，该方法不仅提供了一个强大的评估框架，而且其生成的嵌入在多种任务中持续优于现有最先进的模型。

> **摘要翻译:** 医学文本嵌入模型是广泛医疗保健应用的基础，包括临床决策支持、生物医学信息检索和医学问答，然而它们仍受到两个关键缺陷的阻碍。首先，大多数模型是在狭窄的医学和生物数据切片上训练的，除了方法学上不新颖外，这使得它们不适合捕捉实践中遇到的术语和语义的多样性。其次，现有评估往往不足：即使是广泛使用的基准测试也无法在真实世界医学任务的整个范围内进行泛化。
为了解决这些差距，我们利用MEDTE，一个通过跨多个数据源的自监督对比学习，在多样化医学语料库上广泛微调的GTE模型，以提供鲁棒的医学文本嵌入。
除了这个模型，我们还提出了一个包含51个任务的综合基准测试套件，涵盖分类、聚类、配对分类和检索，该套件基于大规模文本嵌入基准（MTEB）但针对医学文本的细微差别进行了定制。我们的结果表明，这种组合方法不仅建立了一个鲁棒的评估框架，而且产生的嵌入模型在不同任务中始终优于现有的最先进替代方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [604] [An Efficient Sparse Fine-Tuning with Low Quantization Error via Neural Network Pruning](https://arxiv.org/abs/2502.11439)
> *通过神经网络剪枝实现低量化误差的高效稀疏微调*

*Cen-Jhih Li, Aditya Bhaskara* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 稀疏微调, 神经网络剪枝, 内存效率, 大型语言模型, 参数高效微调

**Comment:** 

> **TL;DR:** 本文提出了一种基于神经网络剪枝的新型稀疏微调（SpFT）框架，通过识别重要神经元来限制微调权重，从而在保持SOTA精度的同时，将SpFT的内存效率提高20-50%。

**AI_Comments:** 这项工作通过将神经网络剪枝的思想引入稀疏微调，提供了一种新颖且高效的微调策略。其创新点在于利用神经元重要性进行选择性微调，有效降低了计算资源需求，对于资源受限的用户而言具有重要意义。在保持精度的前提下显著提升内存效率是其主要亮点。

<details>
  <summary>Details</summary>

**Motivation:** 针对计算预算有限的用户，开发内存和计算效率高的微调方法对于将基础模型（如大型语言模型）适应下游任务至关重要。现有的稀疏微调（SpFT）和低秩适应（LoRA）框架已广泛应用，但仍有改进空间。

**Method:** 本文开发了一种新的稀疏微调（SpFT）框架，其灵感来源于神经网络剪枝。具体而言，该方法首先利用网络剪枝中的特征重要性度量（特别是结构化剪枝方法）来识别“重要”神经元/节点，然后通过将权重限制在涉及这些神经元的范围内进行微调。

**Result:** 在常见的语言任务上进行的实验表明，该方法将SpFT的内存效率提高了20-50%，同时与LoRA变体等最先进方法的精度相匹配。

**Conclusion:** 本文提出了一种基于神经网络剪枝的高效稀疏微调方法，该方法在显著提升内存效率的同时，保持了与现有最先进方法相当的精度，使得基础模型的微调更加经济可行。

> **ai_Abstract:** 本文提出了一种基于神经网络剪枝的新型稀疏微调（SpFT）框架，旨在解决基础模型微调的内存和计算效率问题。该方法通过识别模型中的“重要”神经元并仅对相关权重进行微调，显著提高了SpFT的内存效率（20-50%），同时在语言任务上保持了与LoRA等先进方法相同的精度。

> **摘要翻译:** 微调是使基础模型（如大型语言模型）适应下游任务的重要一步。为了让计算预算有限的用户更容易进行这一步骤，开发内存和计算效率高的微调方法至关重要。稀疏微调（SpFT）和低秩适应（LoRA）是解决此问题并已在实践中广泛采用的两种框架。在这项工作中，我们开发了一种新的SpFT框架，其灵感来源于神经网络剪枝。从高层次来看，我们首先利用网络剪枝中的特征重要性度量（具体来说，我们使用结构化剪枝方法）来识别“重要”神经元/节点，然后通过将权重限制在涉及这些神经元的范围内进行微调。在常见的语言任务上进行的实验表明，我们的方法将SpFT的内存效率提高了20-50%，同时与LoRA变体等最先进方法的精度相匹配。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [613] [Large language models provide unsafe answers to patient-posed medical questions](https://arxiv.org/abs/2507.18905)
> *大型语言模型对患者提出的医疗问题提供不安全的答案*

*Rachel L. Draelos, Samina Afreen, Barbara Blasko, Tiffany Brazile, Natasha Chase, Dimple Desai, Jessica Evert, Heather L. Gardner, Lauren Herrmann, Aswathy Vaikom House, Stephanie Kass, Marianne Kavan, Kirshma Khemani, Amanda Koire, Lauren M. McDonald, Zahraa Rabeeah, Amy Shah* | **Category: cs.CL, cs.HC** | **Updated: 2025-07-25**

**Keywords:** 大型语言模型, 患者安全, 医疗建议, 聊天机器人, 红队测试

**Comment:** 20 pages

> **TL;DR:** 研究发现，大型语言模型（LLMs）对患者提出的医疗问题提供的答案存在不安全性和问题性，可能导致严重的患者伤害。

**AI_Comments:** 这项研究的重要性在于其首次由医生主导的红队测试，直接评估了LLM在医疗建议方面的患者安全性。它提供了量化证据，揭示了当前LLM在提供医疗信息时存在的严重缺陷和潜在危害，特别是高比例的问题性及不安全回复。这对于提醒公众和开发者关注LLM在医疗领域的应用风险，并推动未来AI医疗工具的安全性改进具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 数百万患者已定期使用大型语言模型（LLM）聊天机器人获取医疗建议，这引发了患者安全担忧。

**Method:** 本研究是一项由医生主导的红队测试研究，比较了四种公开可用的聊天机器人（Anthropic的Claude、Google的Gemini、OpenAI的GPT-4o和Meta的Llama3-70B）在一个新数据集HealthAdvice上的安全性。研究使用了一个能够进行定量和定性分析的评估框架，评估了针对222个患者提出的、寻求建议的初级保健医学问题（涵盖内科、妇科和儿科）的888个聊天机器人回复。

**Result:** 研究发现聊天机器人之间存在统计学上的显著差异。问题性回复的比例从21.6%（Claude）到43.2%（Llama）不等，不安全回复的比例从5%（Claude）到13%（GPT-4o、Llama）不等。定性结果显示，聊天机器人的回复有可能导致严重的患者伤害。

**Conclusion:** 本研究表明，数百万患者可能正在从公开可用的聊天机器人那里获得不安全的医疗建议，需要进一步的工作来提高这些强大工具的临床安全性。

> **ai_Abstract:** 本研究是一项由医生主导的红队测试，旨在评估大型语言模型（LLM）聊天机器人对患者提出的医疗问题的安全性。研究比较了Claude、Gemini、GPT-4o和Llama3-70B在HealthAdvice数据集上的表现，共评估了222个问题和888个回复。结果显示，各聊天机器人之间存在显著差异，问题性回复率介于21.6%至43.2%之间，不安全回复率介于5%至13%之间。研究指出，这些不安全的回复可能对患者造成严重伤害，并强调需要改进LLM在医疗领域的临床安全性。

> **摘要翻译:** 数百万患者已定期使用大型语言模型（LLM）聊天机器人获取医疗建议，这引发了患者安全担忧。这项由医生主导的红队测试研究，比较了四种公开可用的聊天机器人——Anthropic的Claude、Google的Gemini、OpenAI的GPT-4o和Meta的Llama3-70B——在一个新数据集HealthAdvice上的安全性，并使用了一个能够进行定量和定性分析的评估框架。总共评估了222个患者提出的、寻求建议的初级保健医学问题（涵盖内科、妇科和儿科）的888个聊天机器人回复。我们发现聊天机器人之间存在统计学上的显著差异。问题性回复的比例从21.6%（Claude）到43.2%（Llama）不等，不安全回复的比例从5%（Claude）到13%（GPT-4o、Llama）不等。定性结果显示，聊天机器人的回复有可能导致严重的患者伤害。这项研究表明，数百万患者可能正在从公开可用的聊天机器人那里获得不安全的医疗建议，需要进一步的工作来提高这些强大工具的临床安全性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [634] [Can LLMs Predict Citation Intent? An Experimental Analysis of In-context Learning and Fine-tuning on Open LLMs](https://arxiv.org/abs/2502.14561)
> *LLMs能预测引用意图吗？开放LLM的上下文学习和微调的实验分析*

*Paris Koloveas, Serafeim Chatzopoulos, Thanasis Vergoulis, Christos Tryfonopoulos* | **Category: cs.CL, cs.DL** | **Updated: 2025-07-25**

**Keywords:** 大型语言模型, 引用意图预测, 上下文学习, 微调, 开放LLM

**Comment:** Accepted for publication on TPDL 2025

> **TL;DR:** 研究表明，开放式LLM通过上下文学习和微调能够有效预测引用意图，甚至优于传统方法，且提供了评估框架。

**AI_Comments:** 本文的创新之处在于证明了通用开放式LLM，而非特定领域模型，也能高效地进行引用意图预测，且仅需少量任务特定数据。这对于LLM在学术信息处理领域的应用具有重要意义。同时，研究提供了详细的实验分析，并开源了评估框架和模型，促进了该领域未来的研究。

<details>
  <summary>Details</summary>

**Motivation:** 传统引用意图预测依赖特定领域预训练模型，本研究旨在探索通用开放式LLM通过上下文学习和微调来适应此任务的能力，并验证其有效性。

**Method:** 研究通过零样本、单样本、少样本和多样本提示，评估了五种开放LLM家族中的十二种模型变体，以识别最佳模型和提示参数。随后，对表现最佳的模型进行微调，并在SciCite和ACL-ARC数据集上进行评估。

**Result:** 通过上下文学习实验确定了表现最佳的模型和提示参数。对模型进行微调后，在SciCite数据集上F1分数相对基线提高了8%，在ACL-ARC数据集上提高了4.3%。

**Conclusion:** 开放式LLM能够通过上下文学习和微调有效预测引用意图，为模型选择和提示工程提供了有价值的见解。

> **ai_Abstract:** 本文探讨了开放式大型语言模型（LLM）通过上下文学习和微调预测引用意图的能力。研究评估了多种开放LLM模型及其提示策略，并发现通用LLM仅需少量特定任务数据即可有效执行此任务。通过微调，最佳模型在SciCite和ACL-ARC数据集上的F1分数显著提高，证明了任务特定适应的重要性。研究结果为模型选择和提示工程提供了指导，并公开了评估框架和模型。

> **摘要翻译:** 这项工作研究了开放式大型语言模型（LLM）通过上下文学习和微调预测引用意图的能力。与依赖SciBERT等特定领域预训练模型的传统方法不同，我们证明了通用LLM可以通过最少的特定任务数据适应这项任务。我们使用零样本、单样本、少样本和多样本提示，评估了五个主要开放LLM家族中的十二种模型变体。我们的实验研究通过大量的上下文学习实验确定了表现最佳的模型和提示参数。然后，我们通过微调该模型展示了特定任务适应的显著影响，与指令微调基线相比，在SciCite数据集上实现了8%的F1分数相对提高，在ACL-ARC数据集上实现了4.3%的提高。这些发现为模型选择和提示工程提供了有价值的见解。此外，我们公开了我们的端到端评估框架和模型，以供未来使用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [645] [TokenSmith: Streamlining Data Editing, Search, and Inspection for Large-Scale Language Model Training and Interpretability](https://arxiv.org/abs/2507.19419)
> *TokenSmith：简化大规模语言模型训练和可解释性的数据编辑、搜索和检查*

*Mohammad Aflah Khan, Ameya Godbole, Johnny Tian-Zheng Wei, Ryan Wang, James Flemings, Krishna Gummadi, Willie Neiswanger, Robin Jia* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** TokenSmith, 数据编辑, 语言模型训练, 可解释性, 数据集工具

**Comment:** 

> **TL;DR:** TokenSmith是一个开源库，用于交互式编辑、检查和分析大型语言模型预训练数据集，旨在简化数据调试、验证和实验，并民主化生产级数据集工具的访问。

**AI_Comments:** TokenSmith的创新在于提供了一个统一且易于使用的平台，用于大型语言模型预训练数据的交互式管理。它通过简化数据调试和实验，降低了研究人员访问生产级工具的门槛，从而有望加速LLM的开发和可解释性研究。

<details>
  <summary>Details</summary>

**Motivation:** 理解预训练过程中训练数据与模型行为之间的关系至关重要，但现有工作流程使这一过程繁琐、分散且研究人员难以访问。

**Method:** TokenSmith是一个开源库，支持对Megatron风格预训练框架（如GPT-NeoX、Megatron和NVIDIA NeMo）中使用的数据集进行交互式编辑、检查和分析。它提供搜索、查看、摄取、导出、检查和采样数据等操作，通过简单的用户界面和模块化后端实现。它还支持结构化编辑预训练数据，无需更改训练代码。

**Result:** TokenSmith简化了数据集的调试、验证和实验。它作为现有大型语言模型预训练工作流程的即插即用补充，使生产级数据集工具的访问民主化。

**Conclusion:** TokenSmith提供了一个急需的解决方案，通过简化数据编辑、搜索和检查过程，帮助研究人员更好地理解训练数据和大型语言模型行为之间的关系。

> **ai_Abstract:** TokenSmith是一个开源库，旨在解决大型语言模型预训练中数据与模型行为关系理解的挑战。它提供了一个用户友好的界面和模块化后端，支持对Megatron风格数据集进行广泛操作，包括编辑、搜索、查看和采样。TokenSmith允许结构化编辑数据而无需修改训练代码，从而简化了数据集的调试、验证和实验，并使生产级数据集工具更易于访问。

> **摘要翻译:** 理解预训练过程中训练数据与模型行为之间的关系至关重要，但现有工作流程使这一过程繁琐、分散且研究人员难以访问。我们提出了TokenSmith，一个用于交互式编辑、检查和分析Megatron风格预训练框架（如GPT-NeoX、Megatron和NVIDIA NeMo）中使用的数据集的开源库。TokenSmith支持广泛的操作，包括搜索、查看、摄取、导出、检查和采样数据，所有这些都可以通过简单的用户界面和模块化后端访问。它还支持对预训练数据进行结构化编辑，而无需更改训练代码，从而简化了数据集的调试、验证和实验。TokenSmith被设计为现有大型语言模型预训练工作流程的即插即用补充，从而使生产级数据集工具的访问民主化。TokenSmith托管在GitHub上，并附有文档和教程。演示视频也可在YouTube上观看。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [648] [Evaluating the Performance of AI Text Detectors, Few-Shot and Chain-of-Thought Prompting Using DeepSeek Generated Text](https://arxiv.org/abs/2507.17944)
> *评估AI文本检测器、少样本和思维链提示在使用DeepSeek生成文本时的性能*

*Hulayyil Alshammari, Praveen Rao* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-23**

**Keywords:** AI文本检测器, DeepSeek, 对抗性攻击, 少样本提示, 思维链推理

**Comment:** 

> **TL;DR:** 本文评估了AI文本检测器对DeepSeek生成文本的检测性能，发现对抗性攻击（尤其是人性化）会显著降低准确性，而DeepSeek通过少样本和思维链提示在文本分类方面表现良好。

**AI_Comments:** 这项研究填补了现有AI文本检测研究中关于DeepSeek的空白，并深入探讨了对抗性攻击（特别是人性化改写）对检测器性能的实际影响。此外，它还探索了利用LLM自身进行文本分类的潜力，为未来的检测方法提供了新的视角。研究结果强调了开发更鲁棒的AI文本检测器的必要性，尤其是在面对复杂的人性化攻击时。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLMs）的快速发展引发了对写作完整性的担忧，促使AI检测技术应运而生。然而，现有研究主要关注ChatGPT等主流LLMs，对DeepSeek这一新发布的LLM的检测性能存在明显空白。此外，对抗性攻击（如改写和人性化）会抑制检测器检测机器生成文本的能力，需要进一步评估。

**Method:** 本研究调查了六种常见的AI检测工具（AI Text Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, GPTZero）对DeepSeek生成文本的识别能力。研究收集了49对人类撰写的问答对，并使用DeepSeek-v3生成了对应的AI文本样本。然后，应用了标准改写和人性化改写等对抗性技术，额外增加了196个样本以挑战检测器鲁棒性。此外，研究还将DeepSeek本身视为一个检测器，通过少样本提示和思维链推理（CoT）来分类AI和人类撰写的文本。

**Result:** QuillBot和Copyleaks在原始和改写的DeepSeek文本上表现接近完美。其他检测器，特别是AI Text Classifier和GPT-2，表现出不一致的结果。最有效的攻击是“人性化”，它将Copyleaks的准确率降低到71%，QuillBot降低到58%，GPTZero降低到52%。少样本和CoT提示显示出高准确性，最佳的五样本结果仅将49个样本中的一个误分类（AI召回率96%，人类召回率100%）。

**Conclusion:** 人性化攻击显著降低了现有AI文本检测工具的准确性，凸显了其对抗性弱点。同时，利用DeepSeek通过少样本和思维链提示进行文本分类展示了高效性能，为未来的AI文本检测方法提供了新的方向。

> **ai_Abstract:** 本文评估了六种AI文本检测工具对DeepSeek生成文本的识别性能，并研究了标准和人性化改写等对抗性攻击对其准确性的影响。研究还探讨了DeepSeek本身通过少样本和思维链提示进行文本分类的能力。结果显示，QuillBot和Copyleaks对原始和改写DeepSeek文本表现良好，但“人性化”攻击显著降低了所有检测器的准确性。同时，DeepSeek结合少样本和思维链提示在区分AI和人类文本方面表现出高效率。

> **摘要翻译:** 大型语言模型（LLM）迅速改变了书面材料的创作方式。LLM引发了关于写作完整性的问题，从而推动了人工智能（AI）检测技术的诞生。对抗性攻击，例如标准和人性化改写，会抑制检测器检测机器生成文本的能力。以往的研究主要集中在ChatGPT和其他知名LLM上，并且显示出检测器之间准确性差异很大。然而，关于最近发布的LLM DeepSeek的文献存在明显空白。因此，在这项工作中，我们调查了六种普遍可用的AI检测工具——AI Text Classifier、Content Detector AI、Copyleaks、QuillBot、GPT-2和GPTZero——是否能持续识别由DeepSeek生成的文本。这些检测器暴露于上述对抗性攻击。我们还将DeepSeek本身视为一个检测器，通过执行少样本提示和思维链推理（CoT）来分类AI和人类撰写的文本。我们收集了49对LLM时代前的人工撰写问答对，并使用DeepSeek-v3生成了匹配的回复，从而产生了49个AI生成样本。然后，我们应用了改写和人性化等对抗性技术，额外增加了196个样本。这些样本用于挑战检测器的鲁棒性并评估对准确性的影响。虽然QuillBot和Copyleaks在原始和改写的DeepSeek文本上表现接近完美，但其他检测器——特别是AI Text Classifier和GPT-2——表现出不一致的结果。最有效的攻击是人性化，将Copyleaks的准确率降低到71%，QuillBot降低到58%，GPTZero降低到52%。少样本和CoT提示显示出高准确性，最佳的五样本结果仅将49个样本中的一个误分类（AI召回率96%，人类召回率100%）。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [650] [SALM-Duplex: Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model](https://arxiv.org/abs/2505.15670)
> *SALM-Duplex：高效直接的语音到语音语言模型双工建模*

*Ke Hu, Ehsan Hosseini-Asl, Chen Chen, Edresson Casanova, Subhankar Ghosh, Piotr Żelasko, Zhehuai Chen, Jason Li, Jagadeesh Balam, Boris Ginsburg* | **Category: cs.CL, cs.SD, eess.AS** | **Updated: 2025-07-25**

**Keywords:** 双工语音到语音, 语言模型, 实时交互, 用户打断, 无语音预训练

**Comment:** Accepted to Interspeech 2025

> **TL;DR:** 提出SALM-Duplex，一种新型双工语音到语音（S2S）模型，可实现连续用户输入和实时交互，无需语音预训练，降低比特率，并提升推理、轮流和打断能力。该模型是首个公开提供训练和推理代码的双工S2S模型。

**AI_Comments:** SALM-Duplex的创新之处在于其直接建模同步用户和代理流的双工S2S架构，以及通过预训练流编码器实现无需语音预训练的突破。这显著降低了数据门槛，并简化了与大型语言模型的整合。其在实时交互能力上的提升和比特率的降低具有重要实用价值。作为首个开源的双工S2S模型，它对整个社区的进步和复现性做出了重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 当前的语音语言模型受限于回合制交互，缺乏实时适应性，例如用户打断功能，这限制了人机交互的直观性。

**Method:** 提出SALM-Duplex，一种新颖的双工语音到语音（S2S）架构。该架构通过通道融合实现连续用户输入和编解码器代理输出，直接建模同步的用户和代理流。它利用预训练的流编码器处理用户输入，从而无需进行语音预训练。此外，采用独立的代理和用户建模架构，便于编解码器微调以获得更好的代理语音，并将比特率减半至0.6 kbps。

**Result:** 1. SALM-Duplex在推理、轮流和打断能力方面优于先前的双工模型。
2. 该模型无需语音预训练，显著减少了所需的语音数据量。
3. 简化了从任何大型语言模型（LLM）构建双工S2S模型的过程。
4. 比特率相比先前工作减半至0.6 kbps。
5. 是第一个公开提供训练和推理代码的双工S2S模型，促进了复现性。

**Conclusion:** SALM-Duplex显著提升了语音到语音语言模型的实时交互能力和效率，通过创新的架构设计减少了数据需求并简化了开发流程，是该领域的重要进展。

> **ai_Abstract:** SALM-Duplex是一种创新的双工语音到语音（S2S）语言模型，旨在解决现有S2S模型在实时交互（如用户打断）方面的局限性。该模型采用独特的架构，直接建模同步的用户和代理流，并利用预训练的流编码器，从而无需语音预训练，显著降低了对语音数据的需求。通过独立的代理和用户建模，SALM-Duplex实现了更优的代理语音和更低的比特率（0.6 kbps）。实验证明，该模型在推理、轮流和打断能力上超越了现有双工模型，并简化了基于LLM构建双工S2S模型的过程。此外，它是首个提供开源代码的双工S2S模型，有利于研究复现。

> **摘要翻译:** 口语对话是一种直观的人机交互形式，但当前的语音语言模型通常仍受限于回合制交流，缺乏实时适应性，例如用户打断。我们提出了一种新颖的双工语音到语音（S2S）架构，其特点是连续用户输入和编解码器代理输出，并通过通道融合直接建模同步的用户和代理流。使用预训练的流式编码器进行用户输入，使得首个无需语音预训练的双工S2S模型成为可能。代理和用户建模的独立架构有助于编解码器微调，以获得更好的代理语音，并且与以前的工作相比，比特率减半（0.6 kbps）。实验结果表明，所提出的模型在推理、轮流和打断能力方面优于以前的双工模型。该模型所需的语音数据量显著减少，因为跳过了语音预训练，这显著简化了从任何大型语言模型构建双工S2S模型的过程。最后，它是第一个公开提供训练和推理代码的双工S2S模型，以促进可复现性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [656] [A Systematic Review of Key Retrieval-Augmented Generation (RAG) Systems: Progress, Gaps, and Future Directions](https://arxiv.org/abs/2507.18910)
> *检索增强生成（RAG）系统综述：进展、差距与未来方向*

*Agada Joseph Oche, Ademola Glory Folashade, Tirthankar Ghosal, Arpan Biswas* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 检索增强生成, RAG, 大型语言模型, 系统综述, 自然语言处理

**Comment:** 33 pages, 2 figures

> **TL;DR:** 本文对检索增强生成（RAG）系统进行了全面的系统综述，追溯其发展，分析核心技术组件、企业部署挑战、性能评估，并指出当前挑战和未来方向。

**AI_Comments:** 本文作为一篇系统综述，全面梳理了RAG的进展、挑战和未来方向，对理解RAG领域具有重要价值。其创新性在于对核心组件、企业部署和新兴解决方案的系统性分析，为研究人员和实践者提供了清晰的路线图。该综述的重要性在于其能够帮助读者快速把握RAG的全貌，识别现有差距，并为未来的研究提供启示。

<details>
  <summary>Details</summary>

**Motivation:** RAG结合大型语言模型（LLMs）与信息检索系统，旨在提高事实基础、准确性和上下文相关性，并解决参数模型中幻觉和知识过时的问题。

**Method:** 本文对RAG进行了全面的系统综述，追溯其演变，详细检查核心技术组件（检索机制、序列到序列生成模型、融合策略），进行逐年分析以突出里程碑和研究趋势，探讨企业系统中的部署挑战，并对RAG实现进行比较评估，基准测试检索准确性、生成流畅性、延迟和计算效率，最后批判性评估了持续存在的挑战。

**Result:** 综述分析了RAG的关键里程碑和研究趋势，探讨了其在企业系统部署中的实际挑战（专有数据检索、安全性、可伸缩性），并对RAG实现的性能（检索准确性、生成流畅性、延迟、计算效率）进行了基准测试。同时，评估了检索质量、隐私问题和集成开销等持续挑战。

**Conclusion:** RAG的未来发展将包括混合检索方法、隐私保护技术、优化的融合策略和代理RAG架构，这些创新将导向更可靠、高效和上下文感知的知识密集型自然语言处理系统。

> **ai_Abstract:** 本文对检索增强生成（RAG）系统进行了全面的系统综述。文章追溯了RAG从早期发展到最新应用的演变，强调其通过结合大型语言模型和信息检索来解决LLM幻觉和知识过时问题的动机。综述详细分析了RAG的核心技术组件、关键发展里程碑、在企业部署中的挑战（如数据检索、安全、可伸缩性），并比较评估了其性能指标（准确性、流畅性、延迟、效率）。文章还批判性地评估了RAG面临的持续挑战，并指出了未来的发展方向，包括混合检索、隐私保护和代理RAG架构，旨在推动更可靠、高效的知识密集型NLP系统。

> **摘要翻译:** 检索增强生成（RAG）代表了自然语言处理（NLP）领域的一项重大进展，它将大型语言模型（LLM）与信息检索系统相结合，以增强事实基础、准确性和上下文相关性。本文对RAG进行了全面的系统综述，追溯了其从开放域问答的早期发展到跨多样化应用的最新先进实现。综述首先概述了RAG背后的动机，特别是其减轻参数模型中幻觉和过时知识的能力。核心技术组件——检索机制、序列到序列生成模型和融合策略——得到了详细审查。逐年分析突出了关键里程碑和研究趋势，提供了对RAG快速增长的深入见解。本文进一步探讨了RAG在企业系统中的部署，解决了与专有数据检索、安全性和可伸缩性相关的实际挑战。对RAG实现进行了比较评估，对检索准确性、生成流畅性、延迟和计算效率进行了基准测试。对检索质量、隐私问题和集成开销等持续挑战进行了批判性评估。最后，综述强调了新兴解决方案，包括混合检索方法、隐私保护技术、优化的融合策略和代理RAG架构。这些创新预示着未来将出现更可靠、高效和上下文感知的知识密集型NLP系统。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [664] [Palm: A Culturally Inclusive and Linguistically Diverse Dataset for Arabic LLMs](https://arxiv.org/abs/2503.00151)
> *Palm：一个面向阿拉伯语大型语言模型的文化包容性与语言多样性数据集*

*Fakhraddin Alwajih, Abdellah El Mekki, Samar Mohamed Magdy, Abdelrahim A. Elmadany, Omer Nacar, El Moatez Billah Nagoudi, Reem Abdel-Salam, Hanin Atwany, Youssef Nafea, Abdulfattah Mohammed Yahya, Rahaf Alhamouri, Hamzah A. Alsayadi, Hiba Zayed, Sara Shatnawi, Serry Sibaee, Yasir Ech-Chammakhy, Walid Al-Dhabyani, Marwa Mohamed Ali, Imen Jarraya, Ahmed Oumar El-Shangiti, Aisha Alraeesi, Mohammed Anwar Al-Ghrawi, Abdulrahman S. Al-Batati, Elgizouli Mohamed, Noha Taha Elgindi, Muhammed Saeed, Houdaifa Atou, Issam Ait Yahia, Abdelhak Bouayad, Mohammed Machrouh, Amal Makouar, Dania Alkawi, Mukhtar Mohamed, Safaa Taher Abdelfadil, Amine Ziad Ounnoughene, Rouabhia Anfel, Rwaa Assi, Ahmed Sorkatti, Mohamedou Cheikh Tourad, Anis Koubaa, Ismail Berrada, Mustafa Jarrar, Shady Shehata, Muhammad Abdul-Mageed* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 阿拉伯语LLM, 数据集, 文化包容性, 方言多样性, 大型语言模型

**Comment:** More information about our dataset is available at our project page:
  https://github.com/UBC-NLP/palm

> **TL;DR:** 本文介绍了Palm，一个为期一年、社区驱动的阿拉伯语大型语言模型（LLM）数据集，涵盖22个阿拉伯国家，包含现代标准阿拉伯语和方言阿拉伯语，揭示了LLM在文化和方言能力方面的局限性。

**AI_Comments:** 该论文通过解决LLM开发中的一个关键空白——文化和语言包容性（特别是针对非英语语言），做出了重大贡献。由来自阿拉伯世界的研究人员共同推动的社区驱动方法极具创新性，确保了真正的代表性。该数据集对现代标准阿拉伯语和多样化方言的关注对于实际应用尤为重要。研究结果突出了当前LLM的关键局限性，强调了对更具文化细微性和方言意识的训练数据和模型架构的需求。其公开可用性极大地增强了其影响力和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）日益融入日常生活，确保其文化敏感性和包容性至关重要，尤其是在阿拉伯语LLM领域。

**Method:** 本文介绍了名为“Palm”的数据集，这是一个为期一年、社区驱动的项目，覆盖了所有22个阿拉伯国家。该数据集包含现代标准阿拉伯语（MSA）和阿拉伯方言（DA）的指令（输入、响应对），涵盖20个不同主题，由一个由44名研究人员组成的团队构建。该数据集被用于评估几种前沿LLM的文化和方言能力。

**Result:** 使用Palm数据集进行的评估揭示了前沿LLM的显著局限性。闭源LLM虽然通常表现强劲，但并非没有缺陷；较小的开源模型面临更大的挑战。此外，数据集中或模型性能中，某些国家（例如埃及、阿联酋）的代表性似乎比其他国家（例如伊拉克、毛里塔尼亚、也门）更好。

**Conclusion:** Palm数据集是评估和揭示大型语言模型在阿拉伯语语境下文化和方言能力及局限性的宝贵资源，强调了开发更具包容性的数据和模型的必要性。标注指南、代码和数据均已公开，以供复现。

> **ai_Abstract:** 本文介绍了“Palm”，一个面向阿拉伯语大型语言模型（LLM）的文化包容性与语言多样性数据集。该数据集由来自22个阿拉伯国家的44名研究人员历时一年开发，包含现代标准阿拉伯语（MSA）和多种阿拉伯方言（DA）的输入-响应对，涵盖20个主题。Palm数据集用于评估前沿LLM，揭示了它们在文化和方言理解方面的局限性，指出闭源模型存在缺陷，开源模型挑战更大，且部分国家代表性不足。数据集、指南和代码均已公开，以供复现。

> **摘要翻译:** 随着大型语言模型（LLM）日益融入日常生活，确保其文化敏感性和包容性至关重要。我们推出了我们的数据集，这是一个为期一年、社区驱动的项目，覆盖了所有22个阿拉伯国家。该数据集包含现代标准阿拉伯语（MSA）和阿拉伯方言（DA）的指令（输入、响应对），涵盖了20个不同主题。由来自阿拉伯世界的44名研究人员（均为本文作者）组成的团队构建，我们的数据集提供了广泛、包容的视角。我们使用我们的数据集评估了几种前沿LLM的文化和方言能力，揭示了显著的局限性。例如，尽管闭源LLM通常表现强劲，但它们并非没有缺陷，而较小的开源模型面临更大的挑战。此外，某些国家（例如埃及、阿联酋）的代表性似乎比其他国家（例如伊拉克、毛里塔尼亚、也门）更好。我们的标注指南、代码和数据均公开可用，以供复现。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [668] [VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks](https://arxiv.org/abs/2407.19795)
> *VolDoGer：LLM辅助的视觉-语言任务域泛化数据集*

*Juhwan Choi, Junehyoung Kwon, JungMin Yun, Seunguk Yu, YoungBin Kim* | **Category: cs.CL, cs.AI, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 域泛化, 视觉-语言任务, LLM, 数据集, VolDoGer

**Comment:** ICCV 2025 Workshop on Curated Data for Efficient Learning (CDEL)

> **TL;DR:** 提出VolDoGer数据集，用于视觉-语言任务的域泛化研究，通过LLM辅助标注构建。

**AI_Comments:** 这篇论文通过引入VolDoGer数据集，解决了视觉-语言任务域泛化研究中关键的数据集缺失问题。其创新之处在于将LLM辅助标注技术应用于视觉-语言领域，显著减轻了数据标注的负担，为未来该领域的研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型在未见域数据上的域泛化能力至关重要，但视觉-语言任务的域泛化研究受限于缺乏所需数据集。

**Method:** 提出VolDoGer（Vision-Language Dataset for Domain Generalization），一个专门用于域泛化的数据集，涵盖图像描述、视觉问答和视觉蕴含三项视觉-语言任务。该数据集通过将LLM（大型语言模型）辅助数据标注技术扩展到视觉-语言任务来构建，以减轻人工标注的负担。

**Result:** 通过VolDoGer数据集评估了从微调模型到最近的多模态大型语言模型等各种模型的域泛化能力。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了VolDoGer数据集，旨在解决视觉-语言任务中域泛化研究因缺乏专用数据集而受限的问题。VolDoGer是一个专门用于域泛化的视觉-语言数据集，涵盖图像描述、视觉问答和视觉蕴含任务。该数据集利用LLM辅助数据标注技术构建，以降低人工标注成本。研究人员利用VolDoGer评估了多种模型的域泛化能力。

> **摘要翻译:** 域泛化是深度学习模型的一个关键方面，因为它决定了模型在未见领域数据上表现良好的能力。然而，针对视觉-语言任务的深度学习模型域泛化研究仍然有限，这主要是由于缺乏所需的数据集。为了解决这些挑战，我们提出了VolDoGer：一个用于域泛化的视觉-语言数据集，它专门设计用于解决图像描述、视觉问答和视觉蕴含这三项视觉-语言任务。我们通过将基于LLM的数据标注技术扩展到视觉-语言任务来构建VolDoGer，从而减轻了招募人类标注者的负担。我们通过VolDoGer评估了各种模型的域泛化能力，包括从微调模型到最近的多模态大型语言模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [675] [TRPrompt: Bootstrapping Query-Aware Prompt Optimization from Textual Rewards](https://arxiv.org/abs/2507.18618)
> *TRPrompt: 从文本奖励引导查询感知提示优化*

*Andreea Nica, Ivan Zakazov, Nicolas Mario Baldwin, Saibo Geng, Robert West* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 提示优化, 文本奖励, 大型语言模型, 查询感知, 提示模型

**Comment:** 

> **TL;DR:** TRPrompt通过将文本反馈直接整合到提示模型训练中，统一了现有的提示优化方法，无需预先收集数据集，并在数学推理任务上取得了最先进的查询感知提示效果。

**AI_Comments:** TRPrompt的创新之处在于其成功地将文本反馈直接融入到提示模型的训练过程中，从而统一了两种主流的提示优化范式。这种方法避免了传统方法对大量预设数据集的依赖，并通过迭代反馈机制实现了模型的自我改进，显著提升了大型语言模型在复杂推理任务（特别是数学问题）上的性能和提示质量。

<details>
  <summary>Details</summary>

**Motivation:** 现有的提示优化方法要么依赖启发式文本反馈（无需训练），要么依赖数值奖励训练专门的提示模型。本文旨在统一这两种方法，通过直接将文本反馈整合到提示模型训练中，从而无需预先收集数据集，并能迭代改进。

**Method:** TRPrompt（文本奖励提示框架）通过将文本反馈直接整合到提示模型的训练中，统一了现有基于文本反馈和数值奖励的提示优化方法。该框架无需预先收集数据集，并能通过对生成提示的反馈进行迭代改进。它利用大型语言模型内化“良好”提示概念的能力，通过文本奖励提供高分辨率信号来训练提示模型。

**Result:** TRPrompt训练的提示模型能够为挑战性数学数据集（如GSMHard和MATH）中的问题生成最先进的查询特定提示。

**Conclusion:** TRPrompt成功地将文本反馈整合到提示模型的训练中，有效统一了不同的提示优化方法，并在生成查询特定提示方面展现出卓越的性能，特别是在复杂的数学推理任务中达到了最先进水平。

> **ai_Abstract:** TRPrompt是一个新颖的框架，它通过将文本反馈直接整合到提示模型的训练中，统一了现有基于文本反馈和数值奖励的提示优化方法。该框架无需预先收集数据集，并通过迭代反馈不断改进。TRPrompt利用大型语言模型对“良好”提示的内在理解，能够生成最先进的查询特定提示，并在GSMHard和MATH等挑战性数学数据集上展现出卓越的性能。

> **摘要翻译:** 提示优化无需更新目标模型的参数即可提高大型语言模型（LLM）的推理能力。在基于启发式的“一步一步思考”方法之后，该领域已发展出两个主要方向：一类方法使用文本反馈以训练无关的方式从通用LLM中引出改进的提示，而另一类研究则依赖数值奖励来训练一个特殊的提示模型，专门为目标模型提供最优提示。在本文中，我们引入了文本奖励提示框架（TRPrompt），通过将文本反馈直接整合到提示模型的训练中，统一了这些方法。我们的框架不需要预先收集数据集，并且通过对生成的提示的反馈进行迭代改进。当与LLM内化“良好”提示概念的能力相结合时，文本奖励提供的高分辨率信号使我们能够训练一个提示模型，为来自挑战性数学数据集GSMHard和MATH的问题生成最先进的查询特定提示。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [679] [CLEAR: Error Analysis via LLM-as-a-Judge Made Easy](https://arxiv.org/abs/2507.18392)
> *CLEAR：基于LLM作为评判者的错误分析变得简单*

*Asaf Yehudai, Lilach Eden, Yotam Perlitz, Roy Bar-Haim, Michal Shmueli-Scheuer* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** LLM评估, 错误分析, LLM-as-a-Judge, CLEAR, 交互式工具

**Comment:** 

> **TL;DR:** CLEAR是一个开源交互式工具包，用于通过LLM作为评判者进行错误分析，它能生成逐实例反馈，识别系统级错误，并提供可视化仪表板。

**AI_Comments:** CLEAR的创新之处在于它将LLM作为评判者的能力从简单的评分扩展到细致的错误分析，填补了现有评估方法的空白。其开源和交互式仪表板的设计，极大降低了LLM错误分析的门槛，对于LLM的开发和改进具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前LLM评估范式通常只提供单一分数或排名，无法解释模型表现好坏的具体原因。为了弥补这一差距，本文引入CLEAR，旨在提供可操作的错误分析，揭示模型性能背后的具体原因。

**Method:** CLEAR是一个交互式、开源的LLM错误分析工具包。它首先生成逐实例的文本反馈，然后创建一套系统级错误问题，并量化每个已识别问题的普遍性。此外，它还提供一个交互式仪表板，支持通过聚合可视化进行全面错误分析，应用交互式过滤器来隔离特定问题或分数范围，并深入到单个实例以揭示特定的行为模式。

**Result:** 通过RAG和数学基准测试的CLEAR分析，以及用户案例研究，证明了CLEAR的实用性。

**Conclusion:** CLEAR通过LLM作为评判者，提供了一种简单、有效且可解释的错误分析方法，填补了现有LLM评估范式中缺乏具体原因分析的空白，对于理解和改进LLM性能至关重要。

> **ai_Abstract:** 本文介绍了CLEAR，一个开源的交互式工具包，旨在解决当前LLM评估中缺乏具体错误原因分析的问题。CLEAR利用LLM作为评判者，生成逐实例的文本反馈，识别系统级错误，并量化其普遍性。它还提供一个交互式仪表板，支持聚合可视化、过滤器和实例钻取，以实现全面的错误分析。该工具在RAG和数学基准测试以及用户案例研究中展示了其有效性。

> **摘要翻译:** 大型语言模型（LLM）的评估越来越依赖于其他LLM作为评判者。然而，当前的评估范式通常只产生一个单一的分数或排名，回答的是哪个模型更好，而不是为什么更好。尽管这些高层分数对于基准测试至关重要，但它们掩盖了模型性能背后具体的、可操作的原因。为了弥补这一差距，我们引入了CLEAR，一个用于基于LLM的错误分析的交互式开源软件包。CLEAR首先生成逐实例的文本反馈，然后创建一套系统级错误问题，并量化每个已识别问题的普遍性。我们的软件包还为用户提供了一个交互式仪表板，允许通过聚合可视化进行全面的错误分析，应用交互式过滤器来隔离特定问题或分数范围，并深入到展示特定行为模式的单个实例。我们展示了CLEAR在RAG和数学基准测试中的分析，并通过用户案例研究展示了其效用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [687] [GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning](https://arxiv.org/abs/2507.19457)
> *GEPA：反思性提示演化可超越强化学习*

*Lakshya A Agrawal, Shangyin Tan, Dilara Soylu, Noah Ziems, Rishi Khare, Krista Opsahl-Ong, Arnav Singhvi, Herumb Shandilya, Michael J Ryan, Meng Jiang, Christopher Potts, Koushik Sen, Alexandros G. Dimakis, Ion Stoica, Dan Klein, Matei Zaharia, Omar Khattab* | **Category: cs.CL, cs.AI, cs.LG, cs.SE, I.2.7; I.2.6; I.2.4; I.2.8** | **Updated: 2025-07-25**

**Keywords:** LLM, 提示优化, 反思学习, 强化学习, GEPA

**Comment:** 

> **TL;DR:** GEPA是一种利用自然语言反思的提示优化器，它在LLM任务中比强化学习方法更高效且性能更好，所需试运行次数显著减少。

**AI_Comments:** GEPA的创新之处在于其利用了LLM自身强大的自然语言理解和生成能力进行自我反思和学习，而非依赖外部稀疏奖励信号。这是一种更“自然”且高效的优化范式，避免了强化学习中常见的样本效率问题。其重要性在于为LLM的微调和适应提供了新的、更有效率的途径，尤其是在数据或计算资源有限的场景下。该方法可能为未来的LLM自适应学习和自我改进开辟新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）通过强化学习（RL）方法（如GRPO）适应下游任务时，通常需要数千次试运行才能学习新任务。作者认为，语言的可解释性可以为LLMs提供比基于稀疏标量奖励的策略梯度更丰富的学习介质。

**Method:** 本文提出了GEPA（Genetic-Pareto），一个提示优化器，它彻底结合了自然语言反思，通过试错学习高级规则。GEPA对包含一个或多个LLM提示的AI系统进行系统级轨迹采样（例如，推理、工具调用和工具输出），并用自然语言对其进行反思，以诊断问题、提出并测试提示更新，并结合来自其自身尝试的帕累托前沿的互补经验。

**Result:** GEPA通常能将少量试运行转化为巨大的质量提升。在四项任务中，GEPA平均比GRPO高出10%，最高达20%，同时使用的试运行次数减少了35倍。GEPA还在两个LLM上比领先的提示优化器MIPROv2高出10%以上，并作为代码优化的推理时搜索策略显示出有希望的结果。

**Conclusion:** GEPA通过利用自然语言反思进行提示演化，能够显著超越传统的强化学习方法在LLM任务上的表现，尤其是在效率方面，大大减少了所需的试运行次数，证明了语言作为学习介质的有效性。

> **ai_Abstract:** 本文提出了一种名为GEPA（Genetic-Pareto）的提示优化器，旨在解决大型语言模型（LLMs）通过强化学习（RL）适应任务时效率低下的问题。GEPA利用LLM对自身试错过程的自然语言反思来学习和优化提示，从而避免了传统RL方法对大量试运行的需求。实验结果表明，GEPA在多项任务上显著优于GRPO等RL方法，性能提升高达20%，同时所需的试运行次数减少了35倍。此外，GEPA在与现有领先的提示优化器MIPROv2的比较中也表现出色，并在代码优化等领域展现出应用潜力。

> **摘要翻译:** 大型语言模型（LLMs）正越来越多地通过强化学习（RL）方法（如组相对策略优化（GRPO））适应下游任务，而这些方法通常需要数千次试运行才能学习新任务。我们认为，语言的可解释性通常可以为LLMs提供比从稀疏标量奖励中导出的策略梯度更丰富的学习介质。为了验证这一点，我们引入了GEPA（Genetic-Pareto），一个提示优化器，它彻底结合了自然语言反思，通过试错学习高级规则。给定任何包含一个或多个LLM提示的AI系统，GEPA会采样系统级轨迹（例如，推理、工具调用和工具输出），并用自然语言对其进行反思，以诊断问题、提出并测试提示更新，并结合来自其自身尝试的帕累托前沿的互补经验。由于GEPA的设计，它通常只需少量试运行就能带来巨大的质量提升。在四项任务中，GEPA平均比GRPO高出10%，最高达20%，同时使用的试运行次数减少了35倍。GEPA还在两个LLM上比领先的提示优化器MIPROv2高出10%以上，并作为代码优化的推理时搜索策略显示出有希望的结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [692] [Acoustically Precise Hesitation Tagging Is Essential for End-to-End Verbatim Transcription Systems](https://arxiv.org/abs/2506.04076)
> *声学精确的犹豫标记对于端到端逐字转录系统至关重要*

*Jhen-Ke Lin, Hao-Chien Lu, Chung-Chun Wang, Hong-Yun Lin, Berlin Chen* | **Category: cs.CL, cs.SD, eess.AS** | **Updated: 2025-07-25**

**Keywords:** ASR, 犹豫标记, 逐字转录, Whisper, LoRA

**Comment:** accepted to the ISCA SLaTE-2025 Workshop

> **TL;DR:** 声学精确的犹豫标记显著提高了逐字转录系统的ASR准确性。

**AI_Comments:** 该论文的创新之处在于明确展示了声学精确的犹豫标记对于提高逐字ASR系统准确性的重要性，特别是在L2语音转录方面。它利用了先进的Whisper模型和Gemini 2.0 Flash进行精确的填充词推理，并结合LoRA进行高效微调，为处理语音不流畅性提供了有效的解决方案。这对于需要高精度逐字转录的下游应用（如口语评估）具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动口语评估中的逐字转录需要准确捕捉不流畅之处（如犹豫），这对于错误分析和反馈等下游任务至关重要。然而，许多ASR系统会丢弃或泛化犹豫，从而丢失重要的声学细节。

**Method:** 本研究使用低秩适应（LoRA）在Speak & Improve 2025语料库上对Whisper模型进行微调，且不依赖外部音频训练数据。研究比较了三种标注方案：去除犹豫（Pure）、通用标记（Rich）以及由Gemini 2.0 Flash从现有音频-文本对中推断出的声学精确填充词（Extra）。

**Result:** 挑战系统在“Pure”方案下实现了6.47%的词错误率（WER），在“Extra”方案下实现了5.81%的词错误率。挑战后的实验表明，使用“Extra”方案微调Whisper Large V3 Turbo模型取得了5.5%的词错误率，比“Pure”方案（6.2%的词错误率）相对提高了11.3%。

**Conclusion:** 明确、真实的填充停顿标记显著提高了ASR系统在逐字L2语音转录中的准确性。

> **ai_Abstract:** 本研究旨在提高自动口语评估中逐字转录系统对语音不流畅性的捕捉能力。通过使用低秩适应（LoRA）在Speak & Improve 2025语料库上微调Whisper模型，并比较了三种犹豫标注方案（Pure、Rich、Extra），研究发现由Gemini 2.0 Flash推断出的声学精确填充词（Extra方案）显著提高了ASR准确性。实验结果显示，采用“Extra”方案微调Whisper Large V3 Turbo模型，词错误率达到5.5%，相较于去除犹豫的“Pure”方案（6.2%），相对提升了11.3%。这证明了明确且真实的填充停顿标记对于逐字L2语音转录至关重要。

> **摘要翻译:** 自动口语评估的逐字转录要求准确捕捉不流畅之处，这对于错误分析和反馈等下游任务至关重要。然而，许多ASR系统会丢弃或泛化犹豫，从而丢失重要的声学细节。我们使用低秩适应（LoRA）在Speak & Improve 2025语料库上对Whisper模型进行微调，且不依赖外部音频训练数据。我们比较了三种标注方案：去除犹豫（Pure）、通用标记（Rich）以及由Gemini 2.0 Flash从现有音频-文本对中推断出的声学精确填充词（Extra）。我们的挑战系统在“Pure”方案下实现了6.47%的词错误率（WER），在“Extra”方案下实现了5.81%的词错误率。挑战后的实验表明，使用“Extra”方案微调Whisper Large V3 Turbo模型取得了5.5%的词错误率，比“Pure”方案（6.2%的词错误率）相对提高了11.3%。这表明明确、真实的填充停顿标记显著提高了ASR系统在逐字L2语音转录中的准确性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [694] [Ensemble Debiasing Across Class and Sample Levels for Fairer Prompting Accuracy](https://arxiv.org/abs/2503.05157)
> *跨类别和样本级别的集成去偏以实现更公平的提示准确性*

*Ruixi Lin, Ziqiao Wang, Yang You* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 集成去偏, 类别不平衡, 语言模型, 提示准确性, 样本级别校正

**Comment:** Published as a conference paper at COLM 2025

> **TL;DR:** 本文提出了一种基于Heaviside步函数集成去偏方法，用于解决语言模型在文本分类中存在的类别准确性不平衡问题，通过在类别和样本级别进行校正，实现了最先进的整体准确性提升和平衡的类别准确性。

**AI_Comments:** 该论文的创新点在于提出了一个新颖的、基于Heaviside步函数的集成去偏方法，并强调了在类别和样本两个层面进行校正的重要性。特别是样本级别的校正被证明是提升弱势类别的关键，这为未来解决语言模型中的公平性问题提供了新的视角。其在Llama-2模型上的有效性也展示了该方法的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型在文本分类任务中存在严重的类别准确性不平衡问题，即整体准确性提升是以牺牲弱势类别的准确性为代价。研究的动机在于通过提升弱势类别的准确性来改善整体准确性，而不是仅仅加强强势类别。

**Method:** 提出了一种基于Heaviside步函数的集成去偏方法，该方法能够在类别和样本级别灵活地校正上下文学习到的类别概率。

**Result:** 在七个文本分类基准上使用Llama-2-13B进行评估，结果显示该方法在实现平衡类别准确性的同时，获得了最先进的整体准确性提升。分析表明，样本级别的校正对于提升弱势类别是必要的。此外，该方法对更大的模型Llama-2-70B也带来了显著的性能提升，尤其是在生物医学领域的任务上。

**Conclusion:** 集成去偏方法在类别和样本两个层面上的校正对于解决语言模型中的类别准确性不平衡问题至关重要，并且能够有效提升弱势类别的性能，从而实现更公平和更准确的提示。

> **ai_Abstract:** 本文提出了一种新颖的基于Heaviside步函数的集成去偏方法，旨在解决大型语言模型在文本分类中存在的类别准确性不平衡问题。该方法通过在类别和样本两个层面灵活地校正上下文学习到的概率，有效提升了弱势类别的准确性，从而在保持或提升整体准确性的同时，实现了更平衡的类别表现。实验结果表明，该方法在多个基准测试上取得了最先进的性能，并强调了样本级别校正对于提升弱势类别的关键作用。

> **摘要翻译:** 语言模型是强大的少样本学习器，在文本分类任务中实现了良好的整体准确性，但这掩盖了其结果存在严重的类别准确性不平衡问题。我们认为，追求整体准确性不应通过强化强势类别来实现，而应通过提升弱势类别来实现。为了解决这种不平衡，我们提出了一种基于Heaviside步函数的集成去偏方法，该方法能够在类别和样本级别灵活地校正上下文学习到的类别概率。使用Llama-2-13B在七个文本分类基准上进行的评估表明，我们的方法在实现平衡类别准确性的同时，获得了最先进的整体准确性提升。更重要的是，我们对所产生的概率校正方案进行了分析，表明样本级别的校正对于提升弱势类别是必要的。由于有效校正了弱势类别，我们的方法也为更大的模型变体Llama-2-70B带来了显著的性能提升，尤其是在生物医学领域任务上，这进一步证明了在两个级别进行集成去偏的必要性。我们的源代码可在https://github.com/NUS-HPC-AI-Lab/DCS获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [698] [Mining Contextualized Visual Associations from Images for Creativity Understanding](https://arxiv.org/abs/2507.18915)
> *从图像中挖掘情境化视觉关联以理解创造力*

*Ananya Sahu, Amith Ananthram, Kathleen McKeown* | **Category: cs.CL, cs.CV** | **Updated: 2025-07-25**

**Keywords:** 视觉关联, 创意理解, 图像描述, 视觉-语言模型, 数据集

**Comment:** 

> **TL;DR:** 本文提出了一种从图像中挖掘情境化视觉关联的方法，并利用这些关联生成高质量的创意描述，显著提升了视觉编码器在创意领域的表现。

**AI_Comments:** 这项工作具有重要的创新性，它解决了现有视觉-语言模型在处理非字面化、创意性视觉描述时的不足。通过引入“情境化视觉关联”的概念并开发自动挖掘方法，极大地扩展了模型的理解能力。所生成的大规模创意描述数据集及其对零样本检索性能的提升，为未来在艺术、文学等创意领域的人工智能应用奠定了基础。其开源性质也将极大促进相关研究的进展。

<details>
  <summary>Details</summary>

**Motivation:** 理解他人的创意产出需要共享的关联语言，但现有视觉-语言模型（如CLIP）依赖的网络抓取数据集通常包含简短、字面化的替代文本，缺乏情境化的视觉关联。

**Method:** 引入了一种方法，用于从图像中挖掘显著视觉元素的情境化关联，该方法可扩展到任何未标注数据集。利用挖掘到的关联，生成不同抽象程度的高质量创意描述。

**Result:** 生产了一个新的视觉关联数据集和MSCOCO图像的170万创意描述。人类评估证实这些描述在保持视觉基础的同时，抽象程度显著增加。此外，在该数据集上对视觉编码器进行微调，在诗歌和隐喻可视化这两个创意领域的零样本图像-文本检索方面取得了显著改进。

**Conclusion:** 本文提出的方法能够有效挖掘图像中的情境化视觉关联，并生成高质量的创意描述，这不仅有助于提升对人类创造力的理解，也显著改善了视觉-语言模型在创意领域的表现。研究成果已开源。

> **ai_Abstract:** 本文提出了一种新颖的方法，旨在从图像中自动挖掘情境化的视觉关联，以克服现有视觉-语言模型在理解创意描述方面的局限性。该方法能够生成不同抽象程度的创意图像描述，并通过构建大规模数据集（包含170万个MSCOCO创意描述）进行了验证。实验结果和人工评估表明，生成的描述既保持视觉基础又具备更高的抽象性。此外，利用该数据集对视觉编码器进行微调，显著提升了模型在诗歌和隐喻可视化等创意领域的图像-文本检索性能。所有研究成果均已开源。

> **摘要翻译:** 理解另一个人的创意产出需要共享的关联语言。然而，在训练视觉-语言模型（如CLIP）时，我们依赖于网络抓取的数据集，这些数据集包含简短、主要是字面意义的替代文本。在这项工作中，我们引入了一种方法，用于从图像中挖掘显著视觉元素的情境化关联，该方法可以扩展到任何未标注的数据集。给定一幅图像，我们可以利用这些挖掘到的关联生成不同抽象程度的高质量创意描述。通过我们的方法，我们生成了一个新的视觉关联数据集和MSCOCO图像的177万创意描述。人类评估证实这些描述在保持视觉基础的同时，展现出可识别的、不断增加的抽象程度。此外，在该数据集上对视觉编码器进行微调，在诗歌和隐喻可视化这两个创意领域的零样本图像-文本检索方面取得了有意义的改进。我们发布了我们的数据集、生成代码和模型，供更广泛的社区使用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [722] [AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular Data](https://arxiv.org/abs/2507.18442)
> *AraTable：基准测试LLM对阿拉伯语表格数据的推理和理解能力*

*Rana Alshaikh, Israa Alghanmi, Shelan Jeawak* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** AraTable, LLM, 阿拉伯语, 表格数据, 基准测试

**Comment:** 

> **TL;DR:** AraTable是一个新的基准数据集，用于评估大型语言模型（LLM）对阿拉伯语表格数据的推理和理解能力。研究发现LLM在简单任务上表现尚可，但在复杂推理和事实核查方面仍面临挑战，并提出了一个自动化评估框架。

**AI_Comments:** 这项研究通过创建首个针对阿拉伯语表格数据的综合基准AraTable，填补了LLM评估领域的一个重要空白。其创新之处在于结合LLM生成和人工验证的混合数据构建方法，以及提出的自动化评估框架，后者在效率和准确性方面具有显著潜力。论文揭示了LLM在处理复杂跨语言表格推理任务时的局限性，为未来研究指明了方向，对于推动阿拉伯语NLP和跨语言LLM的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在处理结构化数据，特别是表格数据方面的性能有限。尽管英语表格数据有大量基准，但阿拉伯语由于公共资源稀缺和语言特性，在这方面仍代表性不足。

**Method:** 提出了AraTable，一个综合性基准，用于评估LLM在阿拉伯语表格数据上的推理和理解能力。AraTable包含直接问答、事实核查和复杂推理等多种评估任务。数据生成采用混合管道，即LLM生成初始内容，再由人工专家进行过滤和验证。此外，还提出了一个使用自反思机制的全自动化评估框架。

**Result:** 初步分析表明，LLM在直接问答等简单表格任务上表现尚可，但在需要更深层次推理和事实核查的任务上仍然面临显著的认知挑战。提出的自动化评估框架其性能与人工判断几乎相同。

**Conclusion:** LLM在复杂表格推理任务上仍有很大的改进空间。这项研究提供了一个有价值的、可公开获取的资源和评估框架，有助于加速处理和分析阿拉伯语结构化数据的基础模型的发展。

> **ai_Abstract:** 本文介绍了AraTable，一个专为评估大型语言模型（LLM）在阿拉伯语表格数据上推理和理解能力的新型基准。鉴于LLM在结构化数据处理上的局限性以及阿拉伯语资源的匮乏，AraTable通过结合LLM生成和人工验证的混合管道构建了高质量数据集，涵盖了直接问答、事实核查和复杂推理等任务。初步结果显示，LLM在简单任务上表现尚可，但在复杂推理和事实核查方面仍面临挑战。研究还提出了一个性能接近人工判断的自动化评估框架。AraTable旨在成为推动阿拉伯语结构化数据处理模型发展的重要公共资源。

> **摘要翻译:** 大型语言模型（LLM）的认知和推理能力推动了自然语言处理的显著进步。然而，它们在解释结构化数据，特别是表格格式数据方面的性能仍然有限。尽管英语表格数据的基准广泛可用，但阿拉伯语由于公共资源的有限性和其独特的语言特征，在这方面仍然代表性不足。为了弥补这一空白，我们提出了AraTable，一个新颖而全面的基准，旨在评估LLM应用于阿拉伯语表格数据时的推理和理解能力。AraTable包含各种评估任务，如直接问答、事实核查和复杂推理，涉及广泛的阿拉伯语表格来源。我们的方法遵循混合管道，其中初始内容由LLM生成，随后由人类专家过滤和验证，以确保高数据集质量。使用AraTable的初步分析表明，尽管LLM在直接问答等简单表格任务上表现尚可，但当任务需要更深层次的推理和事实核查时，它们仍然面临显著的认知挑战。这表明未来在改进复杂表格推理任务性能方面存在巨大机会。我们还提出了一个使用自反思机制的全自动化评估框架，其性能与人工判断几乎相同。这项研究提供了一个有价值的、可公开获取的资源和评估框架，有助于加速处理和分析阿拉伯语结构化数据的基础模型的发展。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [724] [Relation Extraction with Instance-Adapted Predicate Descriptions](https://arxiv.org/abs/2503.17799)
> *实例自适应谓词描述的关系抽取*

*Yuhang Jiang, Ramakanth Kavuluru* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 关系抽取, 双编码器, 谓词描述, 实例自适应, 对比学习

**Comment:** This paper has been accepted to appear in the proceedings of AMIA
  2025

> **TL;DR:** 本文提出了一种新颖的双编码器架构，用于关系抽取任务，通过实例特定的谓词表示，在多个数据集上实现了1%到2%的F1分数提升。

**AI_Comments:** 该论文的创新点在于提出了实例自适应的谓词描述方法，通过引入第二个编码器来动态生成与输入实例相关的谓词表示，而非使用固定的线性层。这种方法提高了关系抽取的准确性，尤其是在小型编码器模型上的表现，为下游应用提供了更精确的信息抽取能力。其简洁而优雅的公式设计也值得称赞。

<details>
  <summary>Details</summary>

**Motivation:** 关系抽取（RE）是信息抽取中的一项标准任务，在知识发现和问答等下游应用中扮演重要角色。尽管解码器专用的大型语言模型在生成任务中表现出色，但较小的编码器模型仍然是RE的首选架构。本文旨在改进这些小型模型的微调方法。

**Method:** 本文重新审视了使用小型编码器模型进行关系抽取的方法，提出了一种新颖的双编码器架构，并结合了对比损失和交叉熵损失。与以往使用固定线性层表示谓词的方法不同，该方法使用第二个编码器通过将实体跨度信息注入其中，计算实例特定的谓词表示。

**Result:** 在两个生物医学RE数据集和两个通用领域数据集上进行了实验。与最先进的方法相比，该方法在F1分数上实现了1%到2%的提升。消融研究证明了所提出架构中各种组件的重要性。

**Conclusion:** 本文提出了一种有效且优雅的关系抽取方法，通过实例自适应的谓词描述，显著提升了小型编码器模型在多个数据集上的性能。

> **ai_Abstract:** 本文提出了一种用于关系抽取的新型双编码器架构，旨在改进小型编码器模型的微调。该方法通过第二个编码器计算实例特定的谓词表示，将真实实体跨度信息融入其中，并结合对比损失和交叉熵损失进行训练。实验结果表明，该方法在生物医学和通用领域的关系抽取数据集上，比现有最佳方法实现了1%到2%的F1分数提升。

> **摘要翻译:** 关系抽取（RE）是一项标准的信息抽取任务，在知识发现和问答等下游应用中发挥着重要作用。尽管仅解码器的大型语言模型在生成任务中表现出色，但较小的编码器模型仍然是关系抽取任务的首选架构。在本文中，我们重新审视了使用新颖的双编码器架构对这些较小型模型进行微调的方法，并结合了对比损失和交叉熵损失。与以往采用固定线性层表示谓词的方法不同，我们的方法使用第二个编码器，通过将真实实体跨度信息注入其中，计算实例特定的谓词表示。我们在两个生物医学关系抽取数据集和两个通用领域数据集上进行了实验。我们的方法以简单而优雅的公式，比最先进的方法实现了1%到2%的F1分数提升。消融研究证明了所提出的架构中各种组件的重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [725] [JCAPT: A Joint Modeling Approach for CAPT](https://arxiv.org/abs/2506.19315)
> *JCAPT：一种用于CAPT的联合建模方法*

*Tzu-Hsuan Yang, Yue-Yang He, Berlin Chen* | **Category: cs.CL, cs.AI, eess.AS** | **Updated: 2025-07-25**

**Keywords:** 计算机辅助发音训练, 联合建模, Mamba, 发音评估, 错误检测

**Comment:** Accepted to the ISCA SLaTE-2025 Workshop

> **TL;DR:** JCAPT利用Mamba、音韵特征和思考令牌策略，联合建模发音评估和错误检测，在CAPT任务上表现优于现有方法。

**AI_Comments:** 这项研究的创新之处在于首次将音韵归因、基于SSM的建模（Mamba）和提示策略结合应用于计算机辅助发音训练（CAPT）领域，为APA和MDD任务提供了统一且更具解释性的解决方案。其在MDD任务上的显著提升表明了联合建模和引入新架构（Mamba）的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 自动发音评估（APA）和发音错误检测与诊断（MDD）是第二语言学习中计算机辅助发音训练（CAPT）系统的关键任务。以往研究表明，对这两项任务进行联合建模可以带来相互益处，因此需要一个统一的框架来提升这些任务的性能和可解释性。

**Method:** 本文提出了一个名为JCAPT的统一框架，该框架利用Mamba（一种选择性状态空间模型SSM），并整合了音韵特征和“思考令牌”策略，旨在联合增强自动发音评估（APA）和发音错误检测与诊断（MDD）中的可解释性和细粒度时间推理能力。这是首次将音韵归因、基于SSM的建模和提示技术结合应用于CAPT领域。

**Result:** 在speechocean762基准数据集上进行的一系列实验表明，JCAPT模型持续优于现有方法，尤其是在发音错误检测与诊断（MDD）任务上表现突出。

**Conclusion:** JCAPT通过结合Mamba、音韵特征和思考令牌策略，成功地为计算机辅助发音训练（CAPT）中的发音评估和错误检测提供了统一且更优的解决方案，尤其在MDD任务上取得了显著改进。

> **ai_Abstract:** 本文提出了JCAPT，一个用于计算机辅助发音训练（CAPT）的联合建模框架。该框架利用选择性状态空间模型Mamba，并结合音韵特征和思考令牌策略，以提升自动发音评估（APA）和发音错误检测与诊断（MDD）的可解释性和时间推理能力。实验结果显示，JCAPT在speechocean762基准上表现优于现有方法，尤其在MDD任务上效果显著。

> **摘要翻译:** 有效的发音反馈在第二语言（L2）学习中至关重要，计算机辅助发音训练（CAPT）系统通常包含两个关键任务：自动发音评估（APA）和发音错误检测与诊断（MDD）。最近的研究表明，对这两项任务进行联合建模可以带来相互益处。我们的统一框架利用Mamba，这是一种选择性状态空间模型（SSM），同时整合了音韵特征和思考令牌策略，以共同增强APA和MDD中的可解释性和细粒度时间推理能力。据我们所知，这是首次将音韵归因、基于SSM的建模和提示技术结合应用于CAPT领域的研究。在speechocean762基准数据集上进行的一系列实验表明，我们的模型持续优于现有方法，特别是在MDD任务上。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [728] [Conversations Gone Awry, But Then? Evaluating Conversational Forecasting Models](https://arxiv.org/abs/2507.19470)
> *对话走偏了，但之后呢？评估对话预测模型*

*Son Quoc Tran, Tushaar Gangavarapu, Nicholas Chernogor, Jonathan P. Chang, Cristian Danescu-Niculescu-Mizil* | **Category: cs.CL, cs.HC** | **Updated: 2025-07-25**

**Keywords:** 对话预测, 对话走偏, 评估框架, 基准, 语言模型

**Comment:** Code and data available as part of ConvoKit:
  https://convokit.cornell.edu

> **TL;DR:** 本文提出了首个统一的对话偏离预测（CGA）任务评估框架和新的指标，以实现模型间的直接比较并评估其预测修正能力。

**AI_Comments:** 本文的创新之处在于提出了一个统一的评估框架和基准，解决了CGA任务中模型比较缺乏标准的问题。引入的“预测修正能力”指标尤其重要，因为它反映了模型在动态对话情境中的适应性和鲁棒性，这对于实际应用中的对话系统至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 赋予自动化系统预测对话走向的能力，以协助人际互动。现有的对话偏离预测（CGA）任务缺乏统一的评估框架。

**Method:** 重新审视了对话偏离（CGA）任务，引入了首个统一的评估框架，创建了一个基准，以实现不同架构之间的直接和可靠比较。此外，还引入了一个新的指标，用于衡量模型随着对话进展修正预测的能力。

**Result:** 该框架能够对当前CGA模型的进展提供最新概览，并考虑到语言模型的最新发展。

**Conclusion:** 通过引入统一的评估框架和新颖的修正能力指标，本工作为对话偏离预测模型提供了一个更可靠和全面的评估方法。

> **ai_Abstract:** 本文针对“对话走偏”（CGA）预测任务，提出了首个统一的评估框架和基准，旨在促进不同模型架构之间的直接和可靠比较。此外，该工作还引入了一个新的指标，用于衡量模型在对话进行过程中修正其预测的能力，从而为CGA模型的评估提供了更全面和标准化的方法。

> **摘要翻译:** 我们经常依靠直觉来预测对话的方向。赋予自动化系统类似的预见能力可以帮助它们辅助人际互动。最近开发具有这种预测能力的模型的工作主要集中在“对话走偏”（Conversations Gone Awry, CGA）任务上：预测正在进行的对话是否会偏离轨道。在这项工作中，我们重新审视了这项任务，并引入了第一个统一的评估框架，创建了一个基准，从而能够对不同架构进行直接和可靠的比较。这使我们能够结合语言模型的最新进展，对CGA模型的当前进展提供最新概述。我们的框架还引入了一个新颖的指标，用于衡量模型随着对话进展修正其预测的能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [736] [Uncovering Cross-Linguistic Disparities in LLMs using Sparse Autoencoders](https://arxiv.org/abs/2507.18918)
> *使用稀疏自编码器揭示大型语言模型中的跨语言差异*

*Richmond Sin Jing Xuan, Jalil Huseynov, Yang Zhang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-25**

**Keywords:** 大型语言模型, 跨语言差异, 稀疏自编码器, 激活模式, 低秩适应

**Comment:** 

> **TL;DR:** 本文使用稀疏自编码器揭示了多语言大型语言模型中资源匮乏语言的激活模式差异，并通过激活感知微调提升了性能。

**AI_Comments:** 本文创新性地使用稀疏自编码器揭示了多语言LLM中不同语言（特别是中低资源语言）激活模式的内在差异，为理解LLM的跨语言能力提供了新的视角。通过激活感知微调的策略，有效地提升了模型对低资源语言的处理能力，为未来多语言LLM的优化提供了有价值的方向。其局限性可能在于，所观察到的基准测试性能提升虽然一致但“适度”，这表明激活对齐虽是关键因素，但可能还需要结合其他方法才能实现更显著的性能飞跃。

<details>
  <summary>Details</summary>

**Motivation:** 多语言大型语言模型（LLMs）在通用基准测试中，中低资源语言的表现不佳，逊色于高资源语言，研究旨在探究其原因并提出改进方案。

**Method:** 研究分析了Gemma-2-2B模型在26个残差层和10种语言（包括中文、俄语、西班牙语、意大利语、印尼语、加泰罗尼亚语、马拉地语、马拉雅拉姆语、印地语以及英语作为参考）中的激活模式。使用稀疏自编码器（SAEs）揭示激活模式差异。为了解决这些差异，通过低秩适应（LoRA）进行激活感知微调。

**Result:** 中低资源语言在早期层接收到的激活度低26.27%，在更深层保持19.89%的持续差距。通过激活感知微调，马拉雅拉姆语和印地语等语言的激活度显著提升，分别达到87.69%和86.32%，同时英语的激活度保持在91%左右。微调后，基准测试结果显示出适度但一致的性能提升。

**Conclusion:** 激活对齐是提升多语言大型语言模型性能的关键因素。

> **ai_Abstract:** 本文研究了多语言大型语言模型在处理中低资源语言时表现不佳的问题。通过分析Gemma-2-2B模型在不同语言中的激活模式，发现中低资源语言存在显著的激活度差异。为解决此问题，研究团队采用稀疏自编码器揭示这些差异，并利用低秩适应（LoRA）进行激活感知微调，成功提升了中低资源语言的激活水平，并带来了基准测试性能的稳定改善。研究强调激活对齐是提升多语言LLM性能的关键。

> **摘要翻译:** 多语言大型语言模型（LLMs）表现出强大的跨语言泛化能力，但在ARC-Challenge、MMLU和HellaSwag等常见基准测试中，中低资源语言的表现不佳。我们分析了Gemma-2-2B模型在所有26个残差层和10种语言（包括中文（zh）、俄语（ru）、西班牙语（es）、意大利语（it），以及中低资源语言如印尼语（id）、加泰罗尼亚语（ca）、马拉地语（mr）、马拉雅拉姆语（ml）和印地语（hi），以英语（en）作为参考）中的激活模式。使用稀疏自编码器（SAEs），我们揭示了激活模式中系统性的差异。中低资源语言在早期层接收到的激活度低达26.27%，在更深层仍存在19.89%的持续差距。为了解决这个问题，我们通过低秩适应（LoRA）应用激活感知微调，使得激活度显著提升，例如马拉雅拉姆语提升87.69%，印地语提升86.32%，同时英语的激活度保持在91%左右。微调后，基准测试结果显示出适度但一致的改进，突出表明激活对齐是增强多语言大型语言模型性能的关键因素。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [739] [Are LLM Belief Updates Consistent with Bayes' Theorem?](https://arxiv.org/abs/2507.17951)
> *LLM的信念更新与贝叶斯定理一致吗？*

*Sohaib Imran, Ihor Kendiukhov, Matthew Broerman, Aditya Thomas, Riccardo Campanella, Rob Lamb, Peter M. Atkinson* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 大型语言模型, 贝叶斯定理, 信念更新, 一致性, 贝叶斯一致性系数

**Comment:** Accepted at the ICML 2025 Workshop on Assessing World Models

> **TL;DR:** 研究发现，更大、能力更强的预训练语言模型在信念更新上与贝叶斯定理更一致。

**AI_Comments:** 这项研究通过引入贝叶斯一致性系数（BCC）量化了LLM信念更新的贝叶斯一致性，提供了一种新颖的评估LLM推理能力的方法。其发现大型模型更符合贝叶斯定理，揭示了模型规模与理性推理能力之间的潜在联系，对LLM的未来发展和治理具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 探讨更大、能力更强的语言模型在面对上下文证据时，其对命题的“信念”更新是否更符合贝叶斯定理。

**Method:** 提出了一个贝叶斯一致性系数（BCC）指标，并生成了用于测量BCC的数据集。测量了来自五个模型家族的多个仅预训练语言模型的BCC，并与模型参数数量、训练数据量以及常见基准测试得分进行比较。

**Result:** 结果表明，更大、能力更强的预训练语言模型分配的置信度与贝叶斯定理更一致，这支持了研究假设。

**Conclusion:** 这些结果对于我们理解和管理大型语言模型具有重要意义。

> **ai_Abstract:** 本文研究了大型语言模型（LLM）的信念更新是否与贝叶斯定理一致。作者提出了贝叶斯一致性系数（BCC）指标并构建数据集进行测量。研究发现，参数更多、能力更强的预训练LLM在信念更新上与贝叶斯定理的符合度更高，这对于理解和管理LLM具有重要意义。

> **摘要翻译:** 大型且能力更强的语言模型在提供上下文证据时，是否学会了更一致地根据贝叶斯定理更新其对命题的“信念”？为了验证这一点，我们制定了一个贝叶斯一致性系数（BCC）指标，并生成了一个用于测量BCC的数据集。我们测量了来自五个模型家族的多个仅预训练语言模型的BCC，并将其与模型参数数量、训练数据量以及常见基准测试得分进行比较。我们的结果为以下假设提供了证据：更大、能力更强的预训练语言模型分配的置信度与贝叶斯定理更一致。这些结果对我们理解和治理大型语言模型具有重要意义。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [744] [The Moral Gap of Large Language Models](https://arxiv.org/abs/2507.18523)
> *大型语言模型的道德鸿沟*

*Maciej Skorski, Alina Landowska* | **Category: cs.CL, cs.CY, cs.HC, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 道德推理, 微调, 提示工程, 性能差距

**Comment:** preprint

> **TL;DR:** 大型语言模型在道德推理方面存在显著差距，任务特定微调优于提示工程。

**AI_Comments:** 该论文揭示了大型语言模型在复杂道德推理方面的局限性，强调了领域特定微调的重要性。其创新在于首次对LLM在道德推理任务上的表现进行了全面比较。这对于开发更符合伦理的AI系统具有重要意义，提示未来研究应更多关注特定任务的深度优化而非通用模型的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 道德基础检测对于分析社会话语和开发符合伦理的AI系统至关重要。尽管大型语言模型在各种任务中表现出色，但它们在专门的道德推理方面的性能尚不明确。

**Method:** 本研究首次使用ROC、PR和DET曲线分析，对最先进的LLM和在Twitter和Reddit数据集上进行微调的Transformer模型进行了全面比较。

**Result:** 结果揭示了显著的性能差距，尽管进行了提示工程，LLM仍表现出高假阴性率和对道德内容的系统性漏检。

**Conclusion:** 这些发现表明，对于道德推理应用，任务特定微调仍然优于提示。

> **ai_Abstract:** 本研究旨在评估大型语言模型（LLM）在道德推理任务上的表现，并将其与经过微调的Transformer模型进行比较。研究发现，尽管LLM在其他任务中表现优秀，但在道德内容检测方面存在显著的性能差距，即使通过提示工程也未能弥补。结果表明，任务特定的微调在道德推理应用中仍优于单纯的提示工程。

> **摘要翻译:** 道德基础检测对于分析社会话语和开发符合伦理的AI系统至关重要。尽管大型语言模型在各种任务中表现出色，但它们在专门的道德推理方面的性能尚不明确。
本研究首次使用ROC、PR和DET曲线分析，对最先进的LLM和在Twitter和Reddit数据集上进行微调的Transformer模型进行了全面比较。
结果揭示了显著的性能差距，尽管进行了提示工程，LLM仍表现出高假阴性率和对道德内容的系统性漏检。这些发现表明，对于道德推理应用，任务特定微调仍然优于提示。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [748] [Kill two birds with one stone: generalized and robust AI-generated text detection via dynamic perturbations](https://arxiv.org/abs/2504.21019)
> *一石二鸟：基于动态扰动的通用且鲁棒的AI生成文本检测*

*Yinghan Zhou, Juan Wen, Wanli Peng, Yiming Xue, Ziwei Zhang, Zhengxian Wu* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-25**

**Keywords:** AI生成文本检测, 泛化性, 鲁棒性, 动态扰动, 强化学习

**Comment:** Accepted by NAACL 2025 main conference

> **TL;DR:** 本文提出了一种名为DP-Net的新型AI生成文本检测方法，通过引入动态扰动，同时解决了AI生成文本检测中的泛化性和鲁棒性挑战，并在实验中表现出优异的性能。

**AI_Comments:** 本文的创新点在于提出了一个统一的框架（DP-Net），通过动态扰动和强化学习，同时解决了AI生成文本检测领域中普遍存在的泛化性和鲁棒性挑战，实现了“一石二鸟”的效果。这种将鲁棒性视为领域偏移并利用强化学习引入扰动的思路具有独特性和启发性，对于提升AIGT检测器的实用性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型的日益普及引发了对AI生成文本（AIGT）滥用的担忧。因此，建立一种具有高泛化性和鲁棒性的AIGT检测方法变得越来越重要。然而，现有方法要么侧重于模型泛化，要么侧重于鲁棒性，缺乏同时解决泛化和鲁棒性挑战的统一机制。

**Method:** 本文认为鲁棒性可以视为一种特定形式的领域偏移，并经验性地揭示了AIGT检测任务中模型泛化的内在机制。在此基础上，提出了一种名为DP-Net的新型AIGT检测方法，该方法通过带有精心设计的奖励和动作的强化学习引入动态扰动。

**Result:** 实验结果表明，所提出的DP-Net在三种跨领域场景下的泛化能力显著优于一些最先进的AIGT检测方法。同时，DP-Net在两种文本对抗性攻击下也达到了最佳鲁棒性。

**Conclusion:** DP-Net通过引入动态扰动，成功地同时解决了AI生成文本检测中的泛化性和鲁棒性挑战，并取得了显著的性能提升。

> **ai_Abstract:** 针对AI生成文本检测中泛化性和鲁棒性难以同时解决的问题，本文提出了一种名为DP-Net的新型方法。该方法将鲁棒性视为领域偏移的一种形式，并通过强化学习引入动态扰动。实验证明，DP-Net在跨领域泛化和对抗性攻击鲁棒性方面均显著优于现有SOTA方法。

> **摘要翻译:** 大型语言模型的日益普及引发了对AI生成文本（AIGT）潜在滥用的担忧。建立一种具有高泛化性和鲁棒性的AIGT检测方法变得越来越重要。然而，现有方法要么侧重于模型泛化，要么侧重于鲁棒性。同时解决泛化和鲁棒性挑战的统一机制探索较少。在本文中，我们认为鲁棒性可以视为一种特定形式的领域偏移，并经验性地揭示了AIGT检测任务中模型泛化的内在机制。然后，我们提出了一种新型AIGT检测方法（DP-Net），该方法通过带有精心设计的奖励和动作的强化学习引入动态扰动。实验结果表明，所提出的DP-Net在三种跨领域场景下的泛化能力显著优于一些最先进的AIGT检测方法。同时，DP-Net在两种文本对抗性攻击下也达到了最佳鲁棒性。代码已公开在https://github.com/CAU-ISS-Lab/AIGT-Detection-Evade-Detection/tree/main/DP-Net。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [754] [Mechanistic Indicators of Understanding in Large Language Models](https://arxiv.org/abs/2507.08017)
> *大型语言模型理解的机制指标*

*Pierre Beckmann, Matthieu Queloz* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 机制可解释性, 大型语言模型, 机器理解, 概念理解, 原则性理解

**Comment:** 32 pages

> **TL;DR:** 本文综合了机制可解释性(MI)的最新发现，提出了一个新颖的理论框架来思考机器理解，并提出了理解的三层概念，但强调LLM的理解与人类理解仍有本质区别。

**AI_Comments:** 本文通过综合机制可解释性的最新研究，为理解大型语言模型的能力提供了一个新颖且结构化的理论框架。其创新之处在于提出了三层理解的概念，这有助于更细致地分析和评估LLMs的认知能力。论文也明确指出了LLMs理解与人类理解的根本差异，这对于避免过度拟人化LLMs的能力具有重要意义，并为未来研究指明了方向，即不再纠结于“是否理解”，而是深入探索“如何理解”。

<details>
  <summary>Details</summary>

**Motivation:** 挑战大型语言模型(LLMs)仅依赖表面统计的观点，并深入探讨LLMs的内部工作机制和理解能力。

**Method:** 本文综合了机制可解释性(MI)的最新发现，并将其整合到一个新颖的理论框架中，提出了理解的三层概念：概念理解、世界状态理解和原则性理解。

**Result:** LLMs发展出功能上类似于人类理解的内部结构，表现为“看到联系”。提出了三层理解：概念理解（形成特征并学习联系）、世界状态理解（学习事实联系并动态跟踪变化）和原则性理解（发现连接事实的“回路”）。然而，“并行机制”现象表明这些理解形式与人类理解仍有根本区别。

**Conclusion:** 关于LLMs是否理解的争论应超越简单的“是”或“否”的二元问题，转而深入研究其独特的工作方式，并构建更适合它们的理解概念。

> **ai_Abstract:** 本文综合了机制可解释性(MI)在揭示大型语言模型(LLMs)内部运作方面的最新发现，挑战了LLMs仅依赖表面统计的观点。作者提出了一个新颖的理论框架，将LLMs的理解能力概念化为发展出类似于“看到联系”的内部结构。文章进一步提出了理解的三层概念：概念理解、世界状态理解和原则性理解。尽管如此，论文也指出，由于“并行机制”的存在，LLMs的理解形式与人类理解仍有显著差异。最终，论文呼吁将对LLMs理解的讨论从简单的二元判断转向深入探究其独特的思维方式并构建更恰当的理解概念。

> **摘要翻译:** 机制可解释性（MI）是探索大型语言模型（LLM）内部工作原理的领域，其最新发现挑战了这些模型仅依赖表面统计的观点。我们对这些发现进行了易于理解的综合，这既是对MI的介绍，又将这些发现整合到一个关于机器理解的新颖理论框架中。我们认为，LLM发展出功能上类似于“看到联系”这种理解方式的内部结构。为了深化这一观点，我们提出了一个三层理解概念。首先，当模型在潜在空间中形成作为方向的“特征”，学习事物多样表现形式之间的联系时，概念理解便出现了。其次，当模型学习特征之间偶然的事实联系并动态跟踪世界变化时，世界状态理解便出现了。第三，当模型不再依赖于一系列记忆的事实，而是发现连接这些事实的“回路”时，原则性理解便出现了。然而，“并行机制”现象表明，这些理解形式与人类理解仍有根本区别。我们得出结论，关于LLM是否理解的辩论应该超越“是”或“否”的问题，转而研究它们奇特的心智是如何运作的，并形成适合它们的概念。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [763] [Restoring Rhythm: Punctuation Restoration Using Transformer Models for Bangla, a Low-Resource Language](https://arxiv.org/abs/2507.18448)
> *恢复韵律：使用Transformer模型对低资源语言孟加拉语进行标点符号恢复*

*Md Obyedullahil Mamun, Md Adyelullahil Mamun, Arif Ahmad, Md. Imran Hossain Emu* | **Category: cs.CL, cs.AI, cs.LG, I.2; I.7** | **Updated: 2025-07-24**

**Keywords:** 标点符号恢复, 孟加拉语, Transformer模型, 低资源语言, 数据增强

**Comment:** 

> **TL;DR:** 本研究使用Transformer模型（XLM-RoBERTa-large）对低资源语言孟加拉语的标点符号进行自动恢复，取得了高准确率，并为该领域提供了基线和资源。

**AI_Comments:** 该论文的创新点在于将Transformer模型应用于低资源语言孟加拉语的标点恢复，并通过数据增强有效解决了资源稀缺问题。其重要性体现在为孟加拉语NLP领域建立了强大的基线，并为未来的研究提供了公开资源。模型的泛化能力在嘈杂的ASR场景中表现出色，具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 标点符号恢复能提高文本可读性，对自动语音识别（ASR）的后处理任务至关重要，特别是对于孟加拉语等低资源语言。

**Method:** 本研究探索了基于Transformer的模型，特别是XLM-RoBERTa-large，来自动恢复孟加拉语无标点文本中的标点符号。研究重点是预测句号、逗号、问号和感叹号四种标点符号。为了解决标注资源稀缺的问题，研究构建了一个大型多样的训练语料库并应用了数据增强技术。

**Result:** 最佳模型在数据增强因子alpha = 0.20%的情况下训练，在新闻测试集上达到了97.1%的准确率，在参考集上达到91.2%，在ASR集上达到90.2%。结果表明模型对参考和ASR文本具有很强的泛化能力。

**Conclusion:** 这项工作为孟加拉语标点符号恢复建立了一个强大的基线，并贡献了公开可用的数据集和代码以支持低资源NLP领域的未来研究。

> **ai_Abstract:** 本研究旨在通过使用Transformer模型（特别是XLM-RoBERTa-large）来自动恢复孟加拉语文本中的标点符号，以提高文本可读性和支持ASR后处理。针对低资源语言的挑战，作者构建了大型训练语料库并应用了数据增强技术。实验结果显示，模型在新闻、参考和ASR测试集上均取得了高准确率（97.1%、91.2%、90.2%），证明了其在真实世界场景中的有效性。该工作为孟加拉语标点符号恢复提供了强大的基线，并贡献了宝贵的公开数据集和代码。

> **摘要翻译:** 标点符号恢复提高了文本的可读性，对于自动语音识别（ASR）的后处理任务至关重要，特别是对于孟加拉语等低资源语言。在这项研究中，我们探索了基于Transformer的模型，特别是XLM-RoBERTa-large，在无标点孟加拉语文本中自动恢复标点符号的应用。我们专注于预测四种标点符号：句号、逗号、问号和感叹号，涵盖不同的文本领域。为了解决标注资源稀缺的问题，我们构建了一个大型且多样化的训练语料库，并应用了数据增强技术。我们表现最佳的模型，在增强因子alpha = 0.20%的情况下进行训练，在新闻测试集上实现了97.1%的准确率，在参考集上实现了91.2%，在ASR集上实现了90.2%。结果表明该模型对参考和ASR转录文本具有很强的泛化能力，证明了该模型在真实世界、嘈杂场景中的有效性。这项工作为孟加拉语标点符号恢复建立了一个强大的基线，并提供了公开可用的数据集和代码以支持低资源NLP领域的未来研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [773] [RADLADS: Rapid Attention Distillation to Linear Attention Decoders at Scale](https://arxiv.org/abs/2505.03005)
> *RADLADS：大规模快速注意力蒸馏到线性注意力解码器*

*Daniel Goldstein, Eric Alcaide, Janna Lu, Eugene Cheah* | **Category: cs.CL, cs.AI, cs.LG, I.2.7** | **Updated: 2025-07-25**

**Keywords:** 注意力蒸馏, 线性注意力, Transformer, 大语言模型, 模型转换

**Comment:** 

> **TL;DR:** 提出RADLADS协议，能快速且低成本地将softmax注意力Transformer转换为高性能线性注意力解码器模型。

**AI_Comments:** 这项工作具有显著的创新性，因为它提供了一种极为高效且经济的方法来优化现有的大型Transformer模型，使其在推理时具有线性注意力模型的优势，而无需从头开始训练。其低成本和高效率的转换过程，对于推动大型语言模型在资源受限环境下的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在将计算成本高的softmax注意力Transformer模型高效地转换为计算效率更高的线性注意力解码器模型，同时保持性能。

**Method:** 提出RADLADS协议，用于将softmax注意力Transformer快速转换为线性注意力解码器模型。该协议只需3.5亿至7亿个token进行转换，不到原始教师模型训练token数的0.005%。同时引入了两种新的RWKV变体架构，并成功将流行的Qwen2.5开源模型（7B、32B和72B）进行了转换。

**Result:** 转换一个72B的线性注意力模型成本低于2000美元。推理质量接近原始Transformer模型。这些模型在标准基准测试中，对于其规模的线性注意力模型，实现了最先进的下游性能。所有模型（除72B模型外）均在HuggingFace上以Apache 2.0许可证发布。

**Conclusion:** RADLADS协议能够以极低的成本和极少的计算量，将现有的大规模softmax注意力Transformer模型高效转换为高性能的线性注意力解码器模型，为部署更高效的大语言模型提供了新途径。

> **ai_Abstract:** RADLADS提出了一种名为“大规模快速注意力蒸馏到线性注意力解码器”的协议，旨在高效地将大型softmax注意力Transformer模型转换为线性注意力解码器模型。该方法仅需极少量（0.005%）的token和极低的成本（72B模型低于2000美元），就能将现有模型（如Qwen2.5）转换为性能接近原始Transformer的线性注意力模型，并在同等规模的线性注意力模型中达到最先进水平。研究还引入了两种新的RWKV变体架构，并开源了相关模型和代码。

> **摘要翻译:** 我们提出了大规模快速注意力蒸馏到线性注意力解码器（RADLADS），这是一种将softmax注意力Transformer快速转换为线性注意力解码器模型的协议，同时提出了两种新的RWKV变体架构，以及从流行的Qwen2.5开源模型（7B、32B和72B）转换而来的模型。我们的转换过程仅需3.5亿至7亿个token，不到用于训练原始教师模型的token总数的0.005%。以当前价格计算，将我们的72B模型转换为线性注意力模型的成本不到2000美元，但在推理时的质量仍接近原始Transformer。这些模型在其规模的线性注意力模型标准基准测试中，实现了最先进的下游性能。我们将在HuggingFace上发布所有模型，采用Apache 2.0许可证，但72B模型也受Qwen许可证协议的约束。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [778] [A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1](https://arxiv.org/abs/2507.08621)
> *基于LLM的论证分类的综合研究：从LLAMA到GPT-4o再到Deepseek-R1*

*Marcin Pietroń, Rafał Olszowski, Jakub Gomułka, Filip Gampel, Andrzej Tomski* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 论证分类, 大型语言模型, GPT-4o, Deepseek-R1, 思维链

**Comment:** 

> **TL;DR:** 对LLM在公开论证分类数据集上的表现进行了全面研究，发现GPT-4o表现最佳，Deepseek-R1在推理增强模型中占优，但两者仍有错误。

**AI_Comments:** 这项研究首次对LLM在公共论证分类数据集上的表现进行了全面的比较分析，填补了该领域的空白。其创新之处在于不仅比较了不同LLM的性能，还特别关注了结合推理能力（如思维链）的模型，并深入探讨了它们的错误模式以及提示算法和数据集的局限性，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）显著提升了论证挖掘的效率，但目前在公开可用的论证分类数据库中，关于这些模型操作的研究和结果仍然缺乏。

**Method:** 本文对包括GPT、Llama和DeepSeek等多种LLM进行了研究，并测试了结合思维链（Chain-of-Thoughts）算法的推理增强变体。研究使用了Args.me和UKP等多样化数据集进行论证分类基准测试。

**Result:** ChatGPT-4o在论证分类基准测试中表现最佳。在结合推理能力的模型中，Deepseek-R1表现出优越性。然而，尽管表现优异，GPT-4o和Deepseek-R1仍然会犯错，并且论文讨论了所有模型中最常见的错误。

**Conclusion:** LLM在论证分类中表现出色，特别是GPT-4o和Deepseek-R1，但它们并非完美无缺。这项工作还揭示了已知提示算法在论证分析中的一些弱点，并指出了改进方向，同时深入分析了现有论证数据集的不足。

> **ai_Abstract:** 这项研究全面评估了多种大型语言模型（LLMs），包括GPT、Llama和DeepSeek系列及其推理增强变体，在Args.me和UKP等公开论证分类数据集上的表现。研究发现ChatGPT-4o在基准测试中表现最佳，而Deepseek-R1在结合推理能力的模型中表现突出。尽管LLMs表现出强大的能力，但它们仍存在错误，论文讨论了常见错误并指出了现有提示算法的局限性及其改进方向，同时深入分析了现有论证数据集的不足。

> **摘要翻译:** 论证挖掘（AM）是一个跨学科研究领域，整合了逻辑学、哲学、语言学、修辞学、法律、心理学和计算机科学的见解。它涉及自动识别和提取论证组成部分，如前提和主张，以及检测它们之间的关系，如支持、攻击或中立。最近，该领域取得了显著进展，特别是随着大型语言模型（LLM）的出现，与传统方法和其他深度学习模型相比，LLM提升了分析和提取论证语义的效率。尽管有许多基准测试用于测试和验证LLM的质量，但这些模型在公开可用的论证分类数据库中的操作研究和结果仍然缺乏。本文对精选的LLM进行了研究，使用了Args.me和UKP等多样化数据集。测试的模型包括GPT、Llama和DeepSeek的不同版本，以及结合了思维链算法的推理增强变体。结果表明，ChatGPT-4o在论证分类基准测试中表现优于其他模型。在结合推理能力的模型中，Deepseek-R1显示出其优越性。然而，尽管它们表现优异，GPT-4o和Deepseek-R1仍然会犯错。论文讨论了所有模型中最常见的错误。据我们所知，这项工作是首次使用LLM和提示算法对上述数据集进行的更广泛的分析。这项工作还显示了已知提示算法在论证分析中的一些弱点，同时指出了改进方向。这项工作的附加价值在于深入分析了可用的论证数据集并揭示了它们的缺点。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [780] [Natural Language Processing for Tigrinya: Current State and Future Directions](https://arxiv.org/abs/2507.17974)
> *提格雷尼亚语自然语言处理：现状与未来方向*

*Fitsum Gaim, Jong C. Park* | **Category: cs.CL, cs.AI, I.2.7** | **Updated: 2025-07-25**

**Keywords:** 提格雷尼亚语, 自然语言处理, 综述, 低资源语言, 形态复杂性

**Comment:** 

> **TL;DR:** 对提格雷尼亚语NLP研究进行了全面综述，分析了现状、挑战和未来方向。

**AI_Comments:** 这篇综述论文对于提格雷尼亚语NLP领域具有重要意义，它不仅系统梳理了该语言NLP研究的现状和发展轨迹，还明确指出了面临的挑战和未来的研究方向。其创新之处在于提供了全面的文献回顾和资源分析，并为该领域的未来发展提供了清晰的路线图。特别是强调了形态复杂性和资源稀缺性是主要障碍，并提出了针对性的解决方案，如形态感知建模和社区驱动的资源开发，这对于低资源语言的NLP研究具有普遍的借鉴意义。

<details>
  <summary>Details</summary>

**Motivation:** 提格雷尼亚语尽管有数百万人使用，但在自然语言处理（NLP）研究中严重不足。这项工作旨在对提格雷尼亚语的NLP研究进行全面调查，以了解其现状和发展轨迹。

**Method:** 本研究对2011年至2025年间超过40项提格雷尼亚语NLP研究进行了全面综述和系统分析。回顾了计算资源、模型和应用在形态处理、机器翻译、语音识别和问答等十个不同下游任务中的现状。

**Result:** 分析揭示了提格雷尼亚语NLP研究从基础的、基于规则的系统向现代神经网络架构发展的清晰轨迹，并且进展始终由资源创建的里程碑推动。研究确定了源于提格雷尼亚语形态复杂性和资源稀缺性的关键挑战。

**Conclusion:** 这项工作既可以作为提格雷尼亚语NLP研究人员的全面参考，也可以作为推动该领域未来发展的路线图。

> **ai_Abstract:** 本论文对提格雷尼亚语的自然语言处理（NLP）研究进行了全面综述，涵盖了2011年至2025年间的40多项研究。研究系统分析了该语言在计算资源、模型和应用方面的现状，涉及形态处理、机器翻译等十个下游任务。分析表明，提格雷尼亚语NLP已从规则系统发展到神经网络架构，且资源创建是推动进展的关键。论文识别了形态复杂性和资源稀缺性等挑战，并提出了形态感知建模、跨语言迁移和社区资源开发等未来研究方向，旨在为该领域提供参考和发展路线图。

> **摘要翻译:** 尽管有数百万人使用，提格雷尼亚语在自然语言处理（NLP）研究中仍然严重不足。这项工作对提格雷尼亚语的NLP研究进行了全面调查，分析了2011年至2025年间跨越十多年的40多项研究。我们系统地回顾了计算资源、模型和应用在十个不同的下游任务中的现状，包括形态处理、机器翻译、语音识别和问答。我们的分析揭示了从基础的、基于规则的系统到现代神经网络架构的清晰轨迹，进展始终由资源创建的里程碑推动。我们指出了源于提格雷尼亚语形态复杂性和资源稀缺性的关键挑战，同时强调了有前景的研究方向，包括形态感知建模、跨语言迁移和以社区为中心的资源开发。这项工作既可以作为研究人员的全面参考，也可以作为推动提格雷尼亚语NLP的路线图。调查研究和资源的精选元数据已公开可用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [782] [LLaVA-NeuMT: Selective Layer-Neuron Modulation for Efficient Multilingual Multimodal Translation](https://arxiv.org/abs/2507.18940)
> *LLaVA-NeuMT：高效多语言多模态翻译的选择性层-神经元调制*

*Jingxuan Wei, Caijun Jia, Qi Chen, Yujun Cai, Linzhuang Sun, Xiangxiang Zhang, Gaowei Wu, Bihui Yu* | **Category: cs.CL, cs.MM** | **Updated: 2025-07-25**

**Keywords:** 多模态机器翻译, 多语言翻译, 层-神经元调制, 跨语言适应, 效率

**Comment:** 

> **TL;DR:** LLaVA-NeuMT提出了一种新颖的多模态多语言翻译框架，通过选择性层和神经元调制来解决跨语言干扰和参数共享效率低下的问题，仅微调40%参数即可超越全量微调并实现SOTA性能。

**AI_Comments:** LLaVA-NeuMT的创新点在于其独特的层选择和神经元级别适应机制，这使得模型能够高效地处理多语言多模态翻译中的跨语言干扰问题。其仅微调40%参数即可超越全量微调的SOTA结果，凸显了其在效率和性能上的显著优势，为未来的多模态多语言翻译研究提供了有价值的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态机器翻译（MMT）方法在双语环境中表现良好，但将其扩展到多语言翻译时面临挑战，主要原因在于跨语言干扰和无效的参数共享策略。

**Method:** 本文提出了LLaVA-NeuMT框架，通过明确建模语言特异性和语言无关表示来缓解多语言干扰。该方法包含一个层选择机制，用于识别不同语言对最信息丰富的层；以及一个神经元级别的适应策略，动态选择语言特异性和无关的神经元，以提高翻译质量并减少冗余。

**Result:** 在M3-Multi30K和M3-AmbigCaps数据集上进行了广泛实验，结果表明LLaVA-NeuMT在仅微调40%模型参数的情况下，超越了全量微调方法，并在两个数据集上均取得了SOTA（State-of-the-Art）结果。

**Conclusion:** LLaVA-NeuMT为多模态多语言适应提供了一个高效且可扩展的跨语言适应解决方案，其分析进一步揭示了所选层和神经元在多模态多语言适应中的重要性。

> **ai_Abstract:** LLaVA-NeuMT是一个新颖的多模态多语言翻译框架，旨在通过明确建模语言特异性和语言无关表示来解决现有MMT方法在多语言扩展中面临的跨语言干扰和参数共享效率低下问题。它通过层选择机制和神经元级别适应策略，动态识别和利用最信息丰富的层和神经元。实验证明，LLaVA-NeuMT仅微调40%参数即可超越全量微调，并在M3-Multi30K和M3-AmbigCaps数据集上实现SOTA性能，为多模态翻译中的跨语言适应提供了高效且可扩展的解决方案。

> **摘要翻译:** 多模态机器翻译（MMT）通过整合视觉上下文来提高翻译质量，有助于解决文本歧义。尽管现有的MMT方法在双语设置中表现良好，但由于跨语言干扰和无效的参数共享策略，将其扩展到多语言翻译仍然具有挑战性。为了解决这个问题，我们提出了LLaVA-NeuMT，这是一种新颖的多模态多语言翻译框架，它明确地建模语言特异性表示和语言无关表示，以减轻多语言干扰。我们的方法包括一个层选择机制，用于识别不同语言对最信息丰富的层；以及一个神经元级别的适应策略，动态选择语言特异性和无关的神经元，以提高翻译质量同时减少冗余。我们在M3-Multi30K和M3-AmbigCaps数据集上进行了广泛的实验，结果表明LLaVA-NeuMT在仅微调40%模型参数的情况下，超越了全量微调方法，并最终在两个数据集上均取得了SOTA结果。我们的分析进一步提供了关于在多模态多语言适应中选择的层和神经元重要性的见解，为多模态翻译中的跨语言适应提供了一种高效且可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [794] [Plan for Speed: Dilated Scheduling for Masked Diffusion Language Models](https://arxiv.org/abs/2506.19037)
> *速度规划：掩码扩散语言模型的扩张调度*

*Omer Luxembourg, Haim Permuter, Eliya Nachmani* | **Category: cs.CL, cs.AI, cs.IT, cs.LG, cs.NE, math.IT** | **Updated: 2025-07-24**

**Keywords:** 掩码扩散语言模型, 扩张调度, 非自回归生成, 文本生成, 推理速度

**Comment:** 

> **TL;DR:** 本文提出了扩张去掩码调度器（DUS），一种无需规划模型的方法，通过将序列位置划分为非相邻的扩张组并并行去掩码，以提高掩码扩散语言模型（MDLMs）的生成速度和质量，解决了现有采样器效率低下的问题。

**AI_Comments:** 本文提出了一种新颖的调度策略DUS，有效解决了MDLMs在并行去掩码时效率低下的核心问题。其创新点在于采用了“扩张”分组并行去掩码，并明确权衡速度与质量，这对于提升非自回归生成模型的实用性具有重要意义。该方法无需修改底层模型，易于部署，且在多个领域展现出优越性，揭示了MDLMs的真实性能潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有掩码扩散语言模型（MDLMs）的采样器在并行去掩码多个位置时忽略了相互作用，导致其行为退化为缓慢的、自回归式的，未能充分发挥MDLMs快速、非自回归文本生成的潜力。

**Method:** 本文提出了扩张去掩码调度器（DUS），这是一种仅用于推理、无需规划模型的方法。DUS通过将序列位置划分为非相邻的扩张组，并并行地对它们进行去掩码，从而最小化每个去噪步骤中联合熵增益的上限。该方法明确权衡了网络调用次数与生成质量。

**Result:** DUS恢复了传统并行去掩码策略下损失的大部分性能。在数学（GSM8K, MATH500）、代码（HumanEval, MBPP）和常识基准（BBH, MMLU-Pro）测试中，DUS的表现优于基于置信度的规划器，且无需修改底层的去噪器。它揭示了MDLMs真正的速度-质量边界。

**Conclusion:** DUS显著提高了掩码扩散语言模型的推理效率，在不修改底层模型的情况下，实现了速度和质量的更好平衡，展现了MDLMs在各种任务中的真正潜力。

> **ai_Abstract:** 本文针对掩码扩散语言模型（MDLMs）现有采样器在并行去掩码时效率低下、行为自回归的问题，提出了扩张去掩码调度器（DUS）。DUS是一种无需规划模型的推理方法，通过将序列位置划分为非相邻的扩张组并并行去掩码，以最小化联合熵增益。实验结果表明，DUS在不修改底层模型的情况下，显著提升了MDLMs在多种基准测试上的性能，并实现了更好的速度-质量平衡。

> **摘要翻译:** 掩码扩散语言模型（MDLMs）有望实现快速、非自回归的文本生成，然而，现有基于模型置信度选择去掩码标记的采样器，在并行去掩码多个位置时忽略了相互作用，并有效地退化为缓慢的自回归行为。我们提出了扩张去掩码调度器（DUS），这是一种仅用于推理、无需规划模型的方法，它将序列位置划分为非相邻的扩张组，并并行去掩码，以最小化每个去噪步骤中联合熵增益的上限。通过明确权衡网络调用次数与生成质量，DUS恢复了传统并行去掩码策略下损失的大部分性能。在数学（GSM8K, MATH500）、代码（HumanEval, MBPP）和常识基准（BBH, MMLU-Pro）测试中，DUS的表现优于基于置信度的规划器，且无需修改底层的去噪器，并揭示了MDLMs真正的速度-质量边界。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [796] [Distilling the Implicit Multi-Branch Structure in LLMs' Reasoning via Reinforcement Learning](https://arxiv.org/abs/2505.16142)
> *通过强化学习蒸馏大型语言模型推理中隐含的多分支结构*

*Shicheng Xu, Liang Pang, Yunchang Zhu, Jia Gu, Zihao Wei, Jingcheng Deng, Feiyang Pan, Huawei Shen, Xueqi Cheng* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 强化学习, 知识蒸馏, 大型语言模型, 推理, 多分支结构

**Comment:** 15 pages

> **TL;DR:** 本文提出RLKD，一个基于强化学习的蒸馏框架，旨在帮助小型LLM学习教师模型隐含的多分支推理结构，而非仅仅模仿固定的输出路径，从而超越传统的SFT-RL方法。

**AI_Comments:** 这篇论文的创新点在于提出了一个能够捕捉LLM内在多分支推理结构的蒸馏方法，而非仅仅模仿表面输出。通过引入GSRM和强化学习，它有效地解决了SFT在蒸馏复杂推理能力方面的局限性。其重要性在于为小型LLM的推理能力提升提供了一条更有效、更深入的路径，尤其是在数据量有限的情况下仍能取得优异表现，这对于资源受限的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的通过监督微调（SFT）从教师模型蒸馏推理路径的方法，未能有效捕获教师模型潜在的真实推理中复杂的元推理和解决问题的交织结构（即隐含的多分支结构）。SFT将这种丰富的结构扁平化为令牌预测序列，阻碍了有效蒸馏，因此需要一种新的方法来解决这一限制。

**Method:** 本文提出了RLKD（Reinforcement Learning-based Distillation），一个基于强化学习的蒸馏框架，并引入了一种新颖的生成结构奖励模型（GSRM）。GSRM将推理路径转换为多个元推理-解决步骤，并计算奖励以衡量学生和教师推理之间的结构对齐。RLKD将此奖励与强化学习相结合，使学生LLM能够内化教师隐含的多分支推理结构。

**Result:** 实验表明，即使在仅0.1%数据量的RL-only训练下，RLKD也超越了标准的SFT-RL管道，释放了比基于SFT蒸馏更大的学生推理潜力。

**Conclusion:** 通过引入RLKD框架和生成结构奖励模型（GSRM），本研究成功地将教师模型隐含的多分支推理结构蒸馏到学生LLM中，显著提高了学生模型的推理能力，并超越了传统的SFT方法。

> **ai_Abstract:** 本文提出了一种名为RLKD的强化学习蒸馏框架，旨在解决传统监督微调（SFT）在蒸馏大型语言模型（LLM）推理能力时无法捕获其隐含多分支结构的问题。RLKD引入了一个生成结构奖励模型（GSRM），该模型将推理路径转化为元推理-解决步骤，并计算奖励以衡量学生与教师推理的结构对齐。通过将GSRM奖励与强化学习结合，RLKD使学生LLM能够内化教师的真实多分支推理结构，而非简单模仿输出路径。实验证明，RLKD即使在数据量极少的情况下，也能显著提升学生LLM的推理潜力，超越了标准的SFT-RL方法。

> **摘要翻译:** 通过监督微调（SFT）从教师模型向学生模型蒸馏推理路径，为提高小型大型语言模型（LLM）的推理能力提供了一条捷径。然而，教师模型生成的推理路径往往只反映了其底层真实推理的表面痕迹。认知神经科学的见解表明，真实推理涉及元推理（从多个候选问题中选择合适的子问题）和解决问题（处理子问题）之间复杂的交织。这意味着真实推理具有隐含的多分支结构。监督微调将这种丰富的结构扁平化为教师推理路径中扁平的令牌预测序列，从而阻碍了将这种结构有效蒸馏给学生。为了解决这一限制，我们提出了RLKD，一个基于强化学习（RL）的蒸馏框架，由一个新颖的生成结构奖励模型（GSRM）指导。我们的GSRM将推理路径转换为多个元推理-解决步骤，并计算奖励以衡量学生和教师推理之间的结构对齐。RLKD将此奖励与RL结合，使学生LLM能够内化教师隐含的多分支推理结构，而不仅仅是模仿固定的输出路径。实验表明，即使在RL-only制度下，仅用0.1%的数据进行训练，RLKD也超越了标准的SFT-RL管道，释放了比基于SFT的蒸馏更大的学生推理潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [805] [Generation of Synthetic Clinical Text: A Systematic Review](https://arxiv.org/abs/2507.18451)
> *生成合成临床文本：一项系统综述*

*Basel Alshaikhdeeb, Ahmed Abdelmonem Hemedan, Soumyabrata Ghosh, Irina Balaur, Venkata Satagopam* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 合成临床文本, 系统综述, 自然语言处理, 隐私保护, Transformer

**Comment:** 

> **TL;DR:** 对生成合成临床文本的现有方法、目的和评估方法进行了系统综述，发现其在解决NLP数据稀疏和隐私问题方面很有前景，但隐私仍是挑战。

**AI_Comments:** 这项系统综述全面梳理了合成临床文本生成领域的现状，突出了其在解决NLP数据挑战方面的潜力，并指出了隐私保护这一关键限制。该研究对于理解当前技术趋势（如Transformer的应用）和未来研究方向具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决临床自然语言处理（NLP）中数据稀疏性和隐私问题。

**Method:** 通过对PubMed、ScienceDirect、Web of Science、Scopus、IEEE、Google Scholar和arXiv等数据库进行系统检索，识别了94篇相关文章，并对生成目的、技术和评估方法进行了定量分析。

**Result:** 自2018年以来，合成医学文本生成受到广泛关注，主要目的包括文本增强、辅助写作、语料库构建、隐私保护、标注和实用性。Transformer架构（尤其是GPTs）是主流技术。评估主要关注相似性、隐私、结构和实用性，其中实用性最常用。合成文本在下游NLP任务中表现出中等程度的替代真实文档的可能性，作为增强和补充真实文档，有助于提高准确性和克服稀疏/欠采样问题。

**Conclusion:** 生成合成医学文本是解决临床NLP中数据稀疏性和隐私问题的巨大资产，能够加速工作流程和管道开发。然而，隐私仍然是主要问题，需要更多人工评估来检查敏感信息。

> **ai_Abstract:** 本文对生成合成临床文本进行了系统综述，旨在解决临床NLP中的数据稀疏和隐私问题。研究分析了生成目的、技术和评估方法，发现自2018年以来，Transformer模型（尤其是GPTs）被广泛用于文本增强、隐私保护等目的。尽管合成文本在NLP任务中显示出作为真实文档补充的潜力，并有助于提高准确性，但隐私保护仍是其主要挑战，需要进一步的人工评估。

> **摘要翻译:** 生成临床合成文本是解决常见临床自然语言处理（NLP）问题（如稀疏性和隐私）的有效方案。本文旨在通过对生成合成医学自由文本进行系统综述，对以下三个研究问题进行定量分析：(i) 生成目的，(ii) 技术，以及 (iii) 评估方法。我们在PubMed、ScienceDirect、Web of Science、Scopus、IEEE、Google Scholar和arXiv数据库中检索了与生成合成医学非结构化自由文本相关的出版物。在收集的1,398篇文章中，我们确定了94篇相关文章。自2018年以来，合成医学文本的生成受到了广泛关注，其主要目的是文本增强、辅助写作、语料库构建、隐私保护、标注和实用性。Transformer架构是生成文本的主要流行技术，尤其是GPTs。另一方面，评估主要有四个方面，包括相似性、隐私、结构和实用性，其中实用性是评估生成的合成医学文本最常用的方法。尽管生成的合成医学文本在不同的下游NLP任务中表现出作为真实医学文档的中等可能性，但它已被证明是作为真实文档的增强和补充，在提高准确性和克服稀疏/欠采样问题方面具有巨大价值。然而，隐私仍然是生成合成医学文本背后的一大问题，需要更多的人工评估来检查是否存在任何敏感信息。尽管如此，生成合成医学文本的进步将大大加速工作流程和管道的采用，从而省去耗时的数据传输法律程序。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [821] [DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning System for Multi-Turn Clinical Dialogue](https://arxiv.org/abs/2505.19630)
> *DoctorAgent-RL：一个用于多轮临床对话的多智能体协作强化学习系统*

*Yichun Feng, Jiawei Wang, Lu Zhou, Zhen Lei, Yixue Li* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 多智能体强化学习, 临床对话, LLMs, 医疗咨询, 诊断性能

**Comment:** 

> **TL;DR:** 本文提出了DoctorAgent-RL，一个基于强化学习的多智能体系统，用于多轮临床对话。它通过医生智能体优化提问策略来动态收集信息，在多轮推理能力和诊断性能方面优于现有模型，具有重要的实际应用价值。

**AI_Comments:** 本文的创新之处在于利用多智能体强化学习框架来模拟动态临床咨询，突破了静态监督学习的局限性。MTMedDialog数据集的构建也是一个重要贡献。该方法能够使LLM自主发展临床推理逻辑，是其核心优势，在提高医疗诊断准确性和效率方面具有重要的实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在生物医学问答领域表现出色，但在实际临床咨询中仍面临挑战。单轮咨询系统导致诊断模糊，而传统的多轮对话模型受限于静态监督学习，缺乏灵活性，无法智能提取关键临床信息。

**Method:** 我们提出了DoctorAgent-RL，一个基于强化学习（RL）的多智能体协作框架，将医疗咨询建模为不确定性下的动态决策过程。医生智能体通过与患者智能体的多轮交互，在RL框架内持续优化其提问策略，并根据咨询评估器的综合奖励动态调整其信息收集路径。这种RL微调机制使LLM能够自主开发符合临床推理逻辑的交互策略。此外，我们构建了MTMedDialog，这是第一个能够模拟患者交互的英语多轮医疗咨询数据集。

**Result:** 实验表明，DoctorAgent-RL在多轮推理能力和最终诊断性能方面均优于现有模型。

**Conclusion:** 这种方法通过在时间紧张的环境中降低误诊风险、解放临床医生处理复杂病例，并开创优化医疗资源分配和缓解劳动力短缺的策略，展现出巨大的实用价值。

> **ai_Abstract:** 本文提出了DoctorAgent-RL，一个用于多轮临床对话的多智能体协作强化学习系统。该系统旨在解决现有LLM在实际临床咨询中面临的局限性以及传统多轮模型的不足。它将医疗咨询建模为动态决策过程，医生智能体通过与患者智能体的RL驱动交互来优化提问策略，并由咨询评估器指导，从而使LLM能够自主发展符合临床推理的交互策略。作者还构建了首个模拟患者交互的英语多轮医疗咨询数据集MTMedDialog。实验证明，DoctorAgent-RL显著提升了多轮推理能力和诊断准确性，在降低误诊、优化医疗资源方面具有重要的实际应用价值。

> **摘要翻译:** 大型语言模型（LLM）在生物医学问答领域展现出卓越的能力，但其在实际临床咨询中的应用仍面临核心挑战。单轮咨询系统要求患者一次性描述所有症状，导致诊断模糊不清。传统的多轮对话模型受限于静态监督学习，缺乏灵活性，无法智能地提取关键临床信息。为了解决这些局限性，我们提出了
DoctorAgent-RL，一个基于强化学习（RL）的多智能体协作框架，将医疗咨询建模为不确定性下的动态决策过程。医生智能体在RL框架内，通过与患者智能体的多轮交互，持续优化其提问策略，并根据来自咨询评估器的综合奖励动态调整其信息收集路径。这种RL微调机制使LLM能够自主开发符合临床推理逻辑的交互策略，而不是肤浅地模仿现有对话数据中的模式。值得注意的是，我们构建了MTMedDialog，这是第一个能够模拟患者交互的英语多轮医疗咨询数据集。实验表明，
DoctorAgent-RL在多轮推理能力和最终诊断性能方面均优于现有模型。这种方法通过在时间紧张的环境中降低误诊风险、解放临床医生处理复杂病例，并开创优化医疗资源分配和缓解劳动力短缺的策略，展现出巨大的实用价值。代码和数据可在https://github.com/JarvisUSTC/DoctorAgent-RL获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [823] [Legal Document Summarization: Enhancing Judicial Efficiency through Automation Detection](https://arxiv.org/abs/2507.18952)
> *法律文件摘要：通过自动化检测提升司法效率*

*Yongjie Li, Ruilin Nong, Jianan Liu, Lucas Evans* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 法律文件摘要, 司法效率, 自动化, 自然语言处理, 机器学习

**Comment:** 

> **TL;DR:** 本文提出了一种利用先进自然语言处理和机器学习技术自动生成法律文件摘要的方法，旨在提升司法效率，减轻法律专业人员的负担，并减少信息遗漏。

**AI_Comments:** 该论文的创新之处在于将先进的NLP和机器学习技术应用于法律文件摘要，直接解决了司法领域效率低下的痛点。其重要性在于提供了一种可行的自动化解决方案，有望显著优化法律专业人员的工作流程，提高审判效率并降低人为错误。该研究为法律科技领域的发展提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 通过自动化关键信息检测来提升司法效率，减轻法律专业人员的负担，并减少遗漏重要信息的可能性。

**Method:** 该方法利用最先进的自然语言处理技术，从大量法律文本中识别并提取必要数据。通过采用先进的机器学习算法，该框架识别司法文件中的潜在模式，以创建精确的摘要。

**Result:** 实验结果表明，该方法能够生成高质量的摘要，同时保持原始内容的完整性并显著缩短处理时间。在操作效率方面有显著提升，使法律从业者能够将精力集中在关键的分析和决策活动上。

**Conclusion:** 本研究强调了有前景的技术驱动策略，这些策略可以显著改变法律部门的工作流程动态，并强调了自动化在完善司法流程中的作用。

> **ai_Abstract:** 本研究提出了一种通过自动化检测提升司法效率的法律文件摘要方法。该方法结合了先进的自然语言处理和机器学习算法，能够从冗长的法律文本中识别并提取关键信息，生成高质量的摘要。实验证明，该方法显著提高了操作效率，减轻了法律专业人员的负担，并有助于减少错误，从而使法律从业者能更专注于核心分析和决策工作。

> **摘要翻译:** 法律文件摘要代表着通过自动化关键信息检测来提高司法效率的重大进步。我们的方法利用最先进的自然语言处理技术，从大量法律文本中细致地识别和提取基本数据，从而促进更高效的审查过程。通过采用先进的机器学习算法，该框架识别司法文件中的潜在模式，以创建封装关键元素的精确摘要。这种自动化减轻了法律专业人员的负担，同时降低了因忽视重要信息而导致错误的 L可能性。通过对实际法律数据集进行的全面实验，我们证明了我们的方法在生成高质量摘要的同时，能够保持原始内容的完整性并显著提高处理时间。结果显示操作效率显著提高，使法律从业者能够将精力集中在关键的分析和决策活动上，而不是手动审查。本研究强调了有前景的技术驱动策略，这些策略可以显著改变法律部门的工作流程动态，强调了自动化在完善司法流程中的作用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [844] [Toward Structured Knowledge Reasoning: Contrastive Retrieval-Augmented Generation on Experience](https://arxiv.org/abs/2506.00842)
> *迈向结构化知识推理：基于经验的对比检索增强生成*

*Jiawei Gu, Ziting Xian, Yuanzhen Xie, Ye Liu, Enjie Liu, Ruichao Zhong, Mochi Gao, Yunzhi Tan, Bo Hu, Zang Li* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 结构化知识推理, 对比检索增强生成, 大型语言模型, 上下文学习, 经验记忆

**Comment:** ACL 2025 Findings

> **TL;DR:** CoRE框架通过对比上下文学习和经验记忆，显著提升了大型语言模型在结构化数据（如Text-to-SQL和TableQA）上的表现。

**AI_Comments:** CoRE的创新之处在于其通过“经验记忆”和“对比上下文学习”来模拟人类的知识迁移能力，以解决LLMs在结构化数据上的固有缺陷。MCTS用于生成经验记忆，显著扩大了训练数据并增强了多样性，这是一种新颖且高效的数据增强策略。其“训练无关且持续”的特性使其具有很高的实用价值和可扩展性，有望推动LLMs在结构化知识推理领域取得重大进展。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在处理表格和数据库等结构化数据时表现不佳，原因在于预训练中接触不足以及文本到结构的转换机制僵化。为了弥合这种认知差距，模拟人类的知识迁移能力，本研究提出了新的框架。

**Method:** 引入了名为CoRE（Contrastive Retrieval-Augmented Generation on Experience）的框架。CoRE通过构建经验记忆表示，并利用对比上下文学习（In-Context Learning, ICL）来增强泛化能力，从而模拟人类的知识迁移。此外，采用蒙特卡洛树搜索（MCTS）生成经验记忆，将训练数据量扩大8-9倍，以增加多样性和领域覆盖。

**Result:** CoRE在Text-to-SQL和TableQA任务上显著提高了性能，平均增益分别为3.44%和4.24%，在挑战性任务上最高可达17.2%。MCTS生成的经验记忆将训练数据量扩大了8-9倍，增强了多样性和领域覆盖。

**Conclusion:** CoRE框架通过训练无关和持续的方法，有效地提升了大型语言模型在结构化知识处理方面的专业能力，使其能够更好地推理结构化数据。

> **ai_Abstract:** 本研究提出CoRE（Contrastive Retrieval-Augmented Generation on Experience）框架，旨在解决大型语言模型在结构化数据处理上的不足。CoRE通过构建经验记忆和利用对比上下文学习来模拟人类知识迁移，从而增强LLMs在表格和数据库等结构化数据上的推理能力。实验结果显示，CoRE在Text-to-SQL和TableQA任务上取得了显著的性能提升，并通过MCTS生成的经验记忆扩大了训练数据，提高了数据多样性和领域覆盖，为LLMs处理结构化知识提供了训练无关且持续有效的方法。

> **摘要翻译:** 大型语言模型（LLMs）在纯文本任务上表现出色，但在表格和数据库等结构化数据上表现不佳。潜在的挑战源于它们在预训练期间的曝光不足以及僵化的文本到结构转换机制。与人类能够无缝地将所学模式应用于不同数据模态不同，LLMs难以推断表格格式中嵌入的隐式关系，尤其是在缺乏明确结构指导的情况下。为了弥合这种认知差距，我们引入了基于经验的对比检索增强生成（CoRE）框架，该框架构建经验记忆表示并通过对比上下文学习（ICL）增强泛化能力，以模拟人类的知识迁移。在Text-to-SQL和TableQA上的实验表明，CoRE显著提高了性能，平均增益分别为3.44%和4.24%，在挑战性任务上最高可达17.2%。我们通过蒙特卡洛树搜索（MCTS）生成的经验记忆将训练数据扩展了8-9倍，增强了多样性和领域覆盖。这种无需训练且持续的方法推动LLMs走向结构化知识专业化。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [851] [A Survey of Deep Learning for Geometry Problem Solving](https://arxiv.org/abs/2507.11936)
> *深度学习在几何问题求解中的综述*

*Jianzhe Ma, Wenxuan Wang, Qin Jin* | **Category: cs.CL, cs.AI, cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 深度学习, 几何问题求解, 综述, 数学推理, 多模态大型语言模型

**Comment:** Work in progress

> **TL;DR:** 该论文综述了深度学习在几何问题求解中的应用，涵盖了相关任务、深度学习方法、评估指标以及未来的挑战和方向。

**AI_Comments:** 这是一篇及时且重要的综述性论文，因为它系统地整理了深度学习在几何问题求解这一复杂领域中的进展。其创新之处在于提供了结构化的内容，包括任务、方法、评估和未来方向，并额外提供了一个持续更新的GitHub论文列表，这对于研究人员来说是一个宝贵的资源。该工作对于推动人工智能在数学推理能力，特别是几何推理方面的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 几何问题求解是数学推理的关键领域，广泛应用于教育、人工智能的数学能力评估和多模态能力评估。近年来，深度学习技术，特别是多模态大型语言模型的快速发展，引发了广泛的研究热潮，因此需要一份全面的综述。

**Method:** 本文对深度学习在几何问题求解中的应用进行了全面综述，具体包括：(i) 几何问题求解中相关任务的全面总结；(ii) 相关深度学习方法的彻底回顾；(iii) 评估指标和方法的详细分析；(iv) 对当前挑战和未来方向的批判性讨论。

**Result:** 该综述提供了一个关于深度学习在几何问题求解方面的全面且实用的参考，旨在促进该领域的进一步发展。

**Conclusion:** 本综述旨在为深度学习在几何问题求解领域提供一个全面实用的参考，以促进该领域的进一步发展。

> **ai_Abstract:** 本研究综述了深度学习在几何问题求解领域的应用。文章详细总结了相关任务，深入回顾了深度学习方法，分析了评估指标，并讨论了当前挑战与未来方向。该综述旨在为该领域提供全面实用的参考，以促进其进一步发展。

> **摘要翻译:** 几何问题求解是数学推理的一个关键领域，广泛涉及教育、人工智能数学能力评估和多模态能力评估等许多重要领域。近年来，深度学习技术的快速发展，特别是多模态大型语言模型的兴起，引发了广泛的研究热潮。本文综述了深度学习在几何问题求解中的应用，包括 (i) 对几何问题求解中相关任务的全面总结；(ii) 对相关深度学习方法的彻底回顾；(iii) 对评估指标和方法的详细分析；以及 (iv) 对当前挑战和未来方向的批判性讨论。我们的目标是为深度学习在几何问题求解中提供一个全面实用的参考，以促进该领域的进一步发展。我们创建了一个在GitHub上持续更新的论文列表：https://github.com/majianz/dl4gps。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [862] [A Similarity Measure for Comparing Conversational Dynamics](https://arxiv.org/abs/2507.18956)
> *比较会话动态的相似性度量*

*Sang Min Jung, Kaixiang Zhang, Cristian Danescu-Niculescu-Mizil* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 会话动态, 相似性度量, 交互模式, 会话分析, 情境权力

**Comment:** Code and demos available in ConvoKit (https://convokit.cornell.edu/)

> **TL;DR:** 本文提出了一种新的相似性度量方法，用于量化和比较会话的整体交互动态，并验证了其在分析大型在线社区会话中的实用性。

**AI_Comments:** 这项工作通过引入一种量化会话动态的相似性度量，填补了现有方法在自动化比较会话整体模式方面的空白。其创新之处在于关注会话的“形状”而非单个回复，并提供了一个实用的工具来分析复杂的交互数据，这对于会话分析和评估会话代理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的方法未能稳健地自动化比较会话的整体交互动态，而这种能力对于提升会话数据分析和更全面地评估会话代理至关重要。

**Method:** 作者提出了一种新的相似性度量方法来比较会话动态，并设计了一个验证框架来测试该度量在捕获会话动态差异方面的鲁棒性及其对会话主题的敏感性。

**Result:** 该度量被用于分析大型在线社区的会话动态，为情境权力在会话中的作用带来了新的见解。

**Conclusion:** 该研究成功引入了一种新的会话动态相似性度量，并展示了其在分析真实世界会话数据中的实用性，为理解复杂交互模式提供了工具。

> **ai_Abstract:** 本文提出了一种新的相似性度量方法，旨在量化和比较会话的整体交互动态，以解决现有方法无法稳健自动化比较会话模式的问题。研究人员设计了一个验证框架来评估该度量的鲁棒性和主题敏感性，并将其应用于分析大型在线社区的会话，从而揭示了情境权力在会话中的作用。

> **摘要翻译:** 标题：比较会话动态的相似性度量
摘要：会话的质量超越了每个单独回复的质量，而是通过这些回复如何组合成交互模式，从而赋予会话独特的整体“形状”而显现。然而，目前还没有一个稳健的自动化方法能够根据会话的整体交互动态来比较它们。这样的方法可以增强会话数据的分析，并帮助更全面地评估会话代理。在这项工作中，我们引入了一种用于比较会话动态的相似性度量。我们设计了一个验证框架，用于测试该度量在捕获会话动态差异方面的鲁棒性，并评估其对会话主题的敏感性。最后，为了说明该度量的实用性，我们用它来分析一个大型在线社区中的会话动态，为情境权力在会话中的作用带来了新的见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [868] [NeuralDB: Scaling Knowledge Editing in LLMs to 100,000 Facts with Neural KV Database](https://arxiv.org/abs/2507.18028)
> *神经网络数据库：利用神经键值数据库将LLM中的知识编辑扩展到100,000个事实*

*Weizhi Fei, Hao Shi, Jing Xu, Jingchen Peng, Jiazheng Li, Jingzhao Zhang, Bo Bai, Wei Han, Zhenyuan Chen, Xueyan Niu* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 知识编辑, 大型语言模型, 键值数据库, NeuralDB, 模型更新

**Comment:** 

> **TL;DR:** NeuralDB是一个新的知识编辑框架，它使用神经KV数据库将LLM中的知识编辑扩展到100,000个事实，同时保持模型的一般能力和编辑效果。

**AI_Comments:** 本文的创新点在于将知识编辑建模为神经KV数据库查询，并引入了门控检索模块，有效解决了大规模知识编辑中模型通用能力受损的问题。其将编辑规模扩展到100,000个事实，比现有工作提高了50倍，显示出显著的实用价值和扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大规模知识编辑（Locate-and-Edit）方法在扩展到数千个编辑时，可能会损害大型语言模型（LLM）的通用能力，甚至导致遗忘已编辑的事实。

**Method:** 本文将现有线性Locate-and-Edit方法建模为查询键值（KV）数据库。在此基础上，提出了NeuralDB，一个将编辑事实显式表示为神经KV数据库的编辑框架。该框架配备了一个非线性门控检索模块，该模块仅在推理涉及已编辑事实时才操作，从而有效保留了LLM的通用能力。

**Result:** 在ZsRE和CounterFacts数据集上，对10,000个事实的编辑实验（使用GPT2-XL, GPT-J (6B) 和Llama-3 (8B)）表明，NeuralDB在编辑效果、泛化性、特异性、流畅性和一致性方面表现出色，并保留了六个代表性文本理解和生成任务的整体性能。进一步的实验表明，NeuralDB在扩展到100,000个事实（比现有工作多50倍）时仍能保持有效性。

**Conclusion:** NeuralDB通过引入神经KV数据库和门控检索模块，解决了大规模知识编辑中通用能力受损和遗忘的问题，实现了高效且可扩展的LLM知识编辑。

> **ai_Abstract:** 本文提出了NeuralDB，一个用于大型语言模型知识编辑的新框架。它通过将编辑事实表示为带有非线性门控检索模块的神经键值数据库，解决了现有大规模编辑方法可能损害模型通用能力和导致遗忘的问题。实验证明，NeuralDB在编辑效率、泛化性、特异性、流畅性和一致性上表现优异，并能将知识编辑扩展到100,000个事实，同时保持LLM的整体性能。

> **摘要翻译:** 高效编辑存储在大型语言模型（LLM）中的知识，无需大规模训练即可实现模型更新。一种可能的解决方案是定位编辑（Locate-and-Edit，L&E），它允许同时修改大量事实。然而，这种编辑可能会损害LLM的通用能力，甚至在扩展到数千次编辑时导致遗忘已编辑的事实。在本文中，我们将现有线性L&E方法建模为查询键值（KV）数据库。从这个角度出发，我们提出了NeuralDB，一个将编辑事实显式表示为神经KV数据库的编辑框架，该数据库配备了一个非线性门控检索模块。特别是，我们的门控模块只在推理涉及已编辑事实时才操作，从而有效保留了LLM的通用能力。在ZsRE和CounterFacts数据集上，使用GPT2-XL、GPT-J (6B) 和Llama-3 (8B) 进行了涉及10,000个事实编辑的综合实验。结果表明，NeuralDB不仅在编辑效果、泛化性、特异性、流畅性和一致性方面表现出色，而且在六个代表性文本理解和生成任务中保持了整体性能。进一步的实验表明，即使扩展到100,000个事实（比现有工作多50倍），NeuralDB仍能保持其有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [872] [References Matter: Investigating the Impact of Reference Set Variation on Summarization Evaluation](https://arxiv.org/abs/2506.14335)
> *参考文献很重要：探究参考集变异对摘要评估的影响*

*Silvia Casola, Yang Janet Liu, Siyao Peng, Oliver Kraus, Albert Gatt, Barbara Plank* | **Category: cs.CL** | **Updated: 2025-07-25**

**Keywords:** 摘要评估, 参考集变异, 度量指标, ROUGE, LLM评估

**Comment:** 

> **TL;DR:** 摘要评估中，参考集的选择对常用度量指标（尤其是基于n-gram的指标如ROUGE）的稳定性有显著影响，可能导致模型排名不可靠，建议在评估中纳入参考集变异。

**AI_Comments:** 本文揭示了当前摘要评估方法中一个关键但常被忽视的问题：参考集选择对评估结果的显著影响。其创新之处在于系统地量化了这种不稳定性，并特别指出了对ROUGE等广泛使用指标的潜在危害。这项研究对于提高LLM时代摘要评估的可靠性和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人类语言生成具有丰富的多样性，但在摘要评估中常被忽视。虽然多参考摘要已知能提高与人类判断的相关性，但参考集对基于参考的度量指标的影响尚未被系统地研究。

**Method:** 本研究考察了广泛使用的基于参考的度量指标对参考集选择的敏感性，分析了三个不同的多参考摘要数据集：SummEval、GUMSum和DUC2004。此外，还收集了LLM输出在不同体裁数据上的人类判断，并检查其与度量指标的相关性。

**Result:** 许多流行的度量指标表现出显著的不稳定性。这种不稳定性对于ROUGE等基于n-gram的指标尤其令人担忧，因为模型排名会因参考集的不同而变化，从而损害模型比较的可靠性。对于不同体裁数据上的LLM输出，人类判断与度量指标之间发现相关性很弱甚至没有相关性。

**Conclusion:** 建议在摘要评估中纳入参考集变异，以增强一致性以及与人类判断的相关性，尤其是在评估大型语言模型（LLMs）时。

> **ai_Abstract:** 本研究系统地探究了参考集变异对摘要评估中常用参考指标（如ROUGE）的影响。通过分析SummEval、GUMSum和DUC2004等数据集，发现许多指标存在显著不稳定性，尤其在n-gram基指标中，模型排名会随参考集变化而不可靠。此外，对LLM输出的人类判断与指标相关性较低。研究强调了在摘要评估中纳入参考集变异的重要性，以提高评估的一致性和与人类判断的相关性，尤其针对大型语言模型。

> **摘要翻译:** 人类语言生成表现出显著的丰富性和变异性，反映了多样的交流风格和意图。然而，这种变异在摘要评估中常常被忽视。虽然已知拥有多个参考摘要可以提高与人类判断的相关性，但参考集对基于参考的度量指标的影响尚未被系统地研究。这项工作考察了广泛使用的基于参考的度量指标与参考集选择相关的敏感性，分析了三个不同的多参考摘要数据集：SummEval、GUMSum和DUC2004。我们证明了许多流行的度量指标表现出显著的不稳定性。这种不稳定性对于ROUGE等基于n-gram的指标尤其令人担忧，因为模型排名会因参考集的不同而变化，从而损害模型比较的可靠性。我们还收集了LLM输出在不同体裁数据上的人类判断，并检查其与度量指标的相关性，以补充现有关于新闻摘要以外的发现，结果发现相关性很弱甚至没有。总而言之，我们建议在摘要评估中纳入参考集变异，以增强一致性以及与人类判断的相关性，尤其是在评估大型语言模型时。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [18] [A Truly Subcubic Combinatorial Algorithm for Induced 4-Cycle Detection](https://arxiv.org/abs/2507.18845)
> *诱导4-环检测的一个真正的次立方组合算法*

*Amir Abboud, Shyan Akmal, Nick Fischer* | **Category: cs.DS, cs.DM** | **Updated: 2025-07-24**

**Keywords:** 诱导4-环, 组合算法, 次立方, 图分解, 确定性算法

**Comment:** 

> **TL;DR:** 首次提出了一个运行时间为O(n^2.84)的真正次立方组合算法，用于检测图中的诱导4-环，解决了诱导4-环检测是否是三角形难的问题。

**AI_Comments:** 本文的创新之处在于提出了第一个真正的次立方组合算法，解决了诱导4-环检测的长期开放问题，并将其与三角形检测区分开来。其方法上的创新在于采用了图分解技术，这在子图检测领域是新颖的应用。虽然速度不如非组合算法，但作为组合算法，它带来了确定性等其他重要优势。

<details>
  <summary>Details</summary>

**Motivation:** 先前工作将诱导4-环检测是否是三角形难的问题确定为完成最低级别分类的唯一剩余情况，并称之为“好奇”的案例。本文旨在提供对这一问题的否定性解决。

**Method:** 本文提出了一种新的组合算法，其运行时间为O(n^2.84)。该算法不同于以往的子图检测技术，创新性地采用了图分解这一新颖的方法，而图分解此前主要用于更全局的问题或削减次多项式因子。

**Result:** 本文提出了第一个真正的次立方组合算法来检测图中的诱导4-环，运行时间为O(n^2.84)。这一结果成功地将诱导4-环检测任务与三角形检测任务（在BMM假设下组合上需要n^{3-o(1)}时间）分离。此外，该算法是第一个非平凡的确定性算法。

**Conclusion:** 本文的结果可以看作是对诱导4-环检测是否是三角形难这一问题的否定性解决，成功地将诱导4-环检测与三角形检测的任务区分开来。

> **ai_Abstract:** 本文提出了首个真正的次立方组合算法，用于在O(n^2.84)时间内检测图中的诱导4-环。这一成果解决了诱导4-环检测是否是三角形难的问题，并成功将其与三角形检测任务分离。该算法创新性地采用了图分解技术，并提供了第一个非平凡的确定性诱导4-环检测方法。

> **摘要翻译:** 我们提出了第一个真正的次立方组合算法，用于检测图中的诱导4-环。在n节点图上的运行时间为O(n^2.84)，从而将诱导4-环检测的任务与三角形检测的任务分离开来，后者在流行的BMM假设下组合上需要n^{3-o(1)}时间。
大量工作致力于表征诱导H-检测的精确时间复杂度，相对于各种大小的团检测的复杂度。先前的工作将诱导4-环检测是否是三角形难的问题确定为完成最低级别分类的唯一剩余情况，并称之为“好奇”的案例[Dalirrooyfard, Vassilevska W., FOCS 2022]。我们的结果可以看作是对这个问题的否定性解决。
我们的算法偏离了大量子图检测算法中的现有技术，采用了迄今为止仅限于更全局问题（如在流问题中使用扩展器分解）或削减次多项式因子（如在图正则引理中的应用）的图分解这一流行主题。虽然我们的算法比基于多项式恒等式检验的（非组合）最先进的O(n^ω)时间算法[Vassilevska W., Wang, Williams, Yu, SODA 2014]慢，但组合上的进步通常会带来其他好处。特别是，我们给出了第一个非平凡的确定性算法，用于检测诱导4-环。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [74] [String Consensus Problems with Swaps and Substitutions](https://arxiv.org/abs/2507.19139)
> *字符串一致性问题，带有交换和替换*

*Estéban Gabory, Laurent Bulteau, Gabriele Fici, Hilde Verbeek* | **Category: cs.DS, cs.CC** | **Updated: 2025-07-25**

**Keywords:** 字符串一致性, 最近字符串, 交换, 替换, FPT, 多项式时间

**Comment:** Full version of the work presented at SPIRE 2025

> **TL;DR:** 本文研究了带有交换和替换操作的广义字符串一致性问题，证明了其在参数$d$下是FPT，并为最小化距离和的变体提出了多项式时间算法。

**AI_Comments:** 本文通过引入交换操作扩展了经典的字符串一致性问题，并成功地为两个重要变体提供了有效的算法（FPT和多项式时间），这对于处理更复杂的字符串相似性度量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有最近字符串问题只考虑替换操作，本文旨在通过引入相邻字符的交换操作来推广该问题，以更全面地解决字符串一致性问题。

**Method:** 对于允许替换和相邻字符交换的广义最近字符串问题，证明了其对于参数$d$是FPT (Fixed-Parameter Tractable)。对于目标是最小化输出字符串与所有输入字符串之间距离之和的变体，提出了一个多项式时间算法。

**Result:** 证明了广义最近字符串问题（允许交换和替换）对于参数$d$是FPT。为最小化距离和的变体提供了一个多项式时间算法。

**Conclusion:** 成功地为带有交换和替换操作的广义字符串一致性问题及其变体提供了计算复杂性分析和有效的算法。

> **ai_Abstract:** 本文研究了广义字符串一致性问题，其中在传统的替换操作之外，还允许相邻字符的交换，且每次操作成本为单位一。尽管此广义问题已知是NP难的，但本文证明了它对于参数$d$是固定参数可解（FPT）的。此外，针对旨在最小化输出字符串与所有输入字符串之间距离之和的变体，本文提出了一种多项式时间算法。

> **摘要翻译:** 字符串一致性问题旨在找到一个字符串，该字符串相对于给定输入字符串集最小化某个给定距离。具体来说，在“最近字符串”问题中，我们给定一组等长字符串和一个半径$d$。目标是找到一个新的字符串，该字符串与每个输入字符串的差异最多为$d$次替换。我们研究了该问题的一个推广，其中除了替换之外，还允许相邻字符的交换，每次操作都会产生单位成本。Amir 等人证明，即使只允许交换，这个广义问题也是NP难的。在本文中，我们证明了它对于参数$d$是FPT。此外，我们研究了一个变体，其目标是最小化输出字符串与所有输入字符串之间的距离之和。对于这个版本，我们提出了一个多项式时间算法。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [91] [Learning Safe Strategies for Value Maximizing Buyers in Uniform Price Auctions](https://arxiv.org/abs/2406.03674)
> *学习统一价格拍卖中价值最大化买家的安全策略*

*Negin Golrezaei, Sourav Sahoo* | **Category: cs.DS, cs.GT, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 统一价格拍卖, 安全策略, 投资回报率, 次线性遗憾, 学习算法

**Comment:** 84 pages, 5 figures. Appeared at ICML 2025

> **TL;DR:** 本文研究了重复统一价格多单位拍卖中价值最大化买家的竞标问题，引入了“安全竞标策略”概念，并设计了一种实现次线性遗憾的多项式时间学习算法，同时评估了其鲁棒性。

**AI_Comments:** 本文的创新点在于提出了“安全竞标策略”这一概念，它在严格的RoI约束下提供了鲁棒性。其多项式时间学习算法在理论上实现了次线性遗憾，并在实践中表现良好，这对于实际应用具有重要意义。该研究为对抗性环境下的拍卖竞标提供了新的视角和有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 买家在重复统一价格多单位拍卖中，目标是在T轮内最大化其累积价值，同时在战略（或对抗性）环境中遵守每轮投资回报率（RoI）约束。

**Method:** 引入了“安全竞标策略”的概念，即无论竞争对手出价如何都能满足RoI约束的策略。证明了这些策略满足温和的无过度出价条件，仅依赖于投标者的估价曲线，并且投标者可以无损地关注有限子集。设计了一种多项式时间学习算法，在完全信息和强盗设置下，相对于事后最优安全策略实现了次线性遗憾。定义了丰富度比率$\alpha$来评估安全策略对更丰富类别的事后最优策略的鲁棒性。

**Result:** 安全策略满足温和的无过度出价条件，仅依赖于估价曲线，且可聚焦于有限子集。设计的学习算法在完全信息和强盗设置下，相对于事后最优安全策略实现了次线性遗憾。算法对更强的基准实现了$\alpha$-近似次线性遗憾。在半合成拍卖数据上的模拟显示，经验丰富度比率显著优于理论最坏情况界限。

**Conclusion:** 本文提出了满足RoI约束的安全竞标策略和相应的学习算法，该算法在理论和实践中均表现良好，并且可以扩展到更复杂的买家和竞争对手模型。

> **ai_Abstract:** 本文研究了重复统一价格多单位拍卖中价值最大化买家的竞标问题，目标是在遵守每轮投资回报率（RoI）约束的同时最大化累积价值。作者引入了“安全竞标策略”的概念，并证明了其特性。论文设计了一种多项式时间学习算法，该算法在完全信息和强盗设置下，相对于事后最优安全策略实现了次线性遗憾，并且对更广泛的最优策略也实现了$\alpha$-近似次线性遗憾。实验结果表明，经验丰富度比率优于理论最坏情况界限，且所提策略和算法具有良好的可扩展性。

> **摘要翻译:** 我们从价值最大化买家的角度研究重复统一价格多单位拍卖中的竞标问题。买家旨在在T轮内最大化其累积价值，同时在战略（或对抗性）环境中遵守每轮投资回报率（RoI）约束。使用m统一竞标格式，买家提交m个出价-数量对（bi，qi）以需求qi单位，出价bi，实际中m远小于M，其中M表示买家的最大需求。
我们引入了安全竞标策略的概念，即无论竞争对手出价如何都能满足RoI约束的策略。尽管要求严格，我们表明这些策略满足温和的无过度出价条件，仅依赖于投标者的估价曲线，并且投标者可以无损地关注有限子集。尽管子集大小为O(Mm)，我们设计了一种多项式时间学习算法，在完全信息和强盗设置下，相对于事后最优安全策略实现了次线性遗憾。
我们评估了安全策略对更丰富类别的事后最优策略的鲁棒性。我们定义丰富度比率$\alpha \in (0,1]$为最优安全策略的价值与更丰富类别最优策略的价值的最小比率，并构建了显示$\alpha$紧密性的困难实例。我们的算法对这些更强的基准实现了$\alpha$-近似次线性遗憾。在半合成拍卖数据上的模拟显示，经验丰富度比率显著优于理论最坏情况界限。所提出的安全策略和学习算法自然地扩展到更细致的买家和竞争对手模型。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [130] [Budget and Profit Approximations for Spanning Tree Interdiction](https://arxiv.org/abs/2507.19178)
> *生成树拦截的预算与利润近似*

*Rafail Ostrovsky, Yuval Rabani, Yoav Siman Tov* | **Category: cs.DS** | **Updated: 2025-07-25**

**Keywords:** 最小生成树拦截, 近似算法, 预算最小化, 利润最大化, 超模函数

**Comment:** Presented at the APPROX 2025 conference

> **TL;DR:** 本文为最小生成树拦截的预算最小化和利润最大化版本提供了多项式时间对数近似保证，并提出了一种基于图论松弛和批处理贪婪算法的解决方案。

**AI_Comments:** 本文的创新之处在于为最小生成树拦截的预算和利润问题提供了新的多项式时间对数近似保证，填补了现有O(1)近似方法不适用的空白。通过将问题转化为最小化线性函数受超模覆盖约束，并利用图论松弛和批处理贪婪算法，为解决这类NP-hard问题提供了有效途径。其重要性在于为网络设计、资源分配等领域中涉及最小生成树优化的问题提供了理论和算法支持。

<details>
  <summary>Details</summary>

**Motivation:** 现有针对类似目标（最大化树的总成本而非增加量）的O(1)近似保证不适用于成本增加，且同样的技术不适用于预算版本。因此，研究在任何增加量下最小化最小生成树成本的问题，旨在为预算和利润问题提供近似保证。

**Method:** 研究了在任何增加量下最小化最小生成树成本的问题，并证明其是多项式时间可解的。利用这种解决方案，提出了NP-hard拦截问题的图论松弛。利用最小生成树权重增益的超模性质，设计并分析了一种基于批处理贪婪的算法。

**Result:** 为最小生成树拦截的预算最小化和利润最大化版本提供了多项式时间对数近似保证。证明了最小化最小生成树增加任何量成本的版本是多项式时间可解的，并给出了高效算法。

**Conclusion:** 本文为最小生成树拦截的预算最小化和利润最大化问题提供了多项式时间对数近似保证，并通过图论松弛和批处理贪婪算法有效解决了相关NP-hard问题。

> **ai_Abstract:** 本文研究了最小生成树拦截问题，该问题旨在通过移除图边来增加最小生成树的权重。针对预算最小化和利润最大化两种版本，论文提供了多项式时间对数近似保证。与现有方法不适用于成本增加和预算版本的情况不同，本文通过研究最小化任意增加量最小生成树成本的可解性（并提供了高效算法），启发了一种图论松弛方法。利用最小生成树权重增益的超模性质，设计并分析了一种基于批处理贪婪的算法来解决预算问题。

> **摘要翻译:** 我们为最小生成树拦截的预算最小化和利润最大化版本提供了多项式时间对数近似保证。在该问题中，目标是移除无向图的一些边（带边权重和边成本），以增加最小生成树的权重。在预算最小化版本中，目标是最小化移除边的总成本，同时实现最小生成树权重所需的增加量Δ。在同一框架内的另一个目标是在预算约束下最大化拦截利润，即最小生成树权重的增加量。对于类似目标（最大化树的总成本，而不是增加量）存在已知的多项式时间O(1)近似保证。然而，该保证似乎不适用于成本增加。此外，同样的技术似乎不适用于预算版本。
我们的近似保证是通过研究最小化任意增加量最小生成树成本的问题而得到的。我们表明，与预算和利润问题相反，此版本的拦截问题是多项式时间可解的，并且我们给出了解决它的高效算法。该解决方案启发了NP-hard拦截问题的图论松弛。最小生成树权重增益作为移除边集合的函数是超模的。因此，预算问题是最小化线性函数受超模覆盖约束的一个实例。我们使用图论松弛来设计和分析一种基于批处理贪婪的算法。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [194] [Query Efficient Structured Matrix Learning](https://arxiv.org/abs/2507.19290)
> *查询高效的结构化矩阵学习*

*Noah Amsel, Pratyush Avi, Tyler Chen, Feyza Duman Keles, Chinmay Hegde, Cameron Musco, Christopher Musco, David Persson* | **Category: cs.DS, cs.LG, cs.NA, math.NA** | **Updated: 2025-07-25**

**Keywords:** 结构化矩阵学习, 查询效率, 矩阵向量积, 复杂度分析, 覆盖数

**Comment:** 

> **TL;DR:** 本文研究了从矩阵向量积查询中学习未知矩阵的结构化近似问题，并展示在矩阵向量积模型下，查询复杂度可以达到近乎二次方的提升，即从$O(\log|\mathcal{F}|)$降至$\tilde{O}(\sqrt{\log|\mathcal{F}|})$，并证明了该界限的紧性。

**AI_Comments:** 本文的创新之处在于，它挑战了传统矩阵草图方法在矩阵向量积查询模型下的查询效率极限，并取得了突破性的进展。通过引入新的理论分析方法，特别是利用覆盖数论证，作者证明了在matvec模型下，学习结构化矩阵近似的查询复杂度可以实现显著的二次方改进。这一发现对于需要高效处理大型结构化数据的科学计算和机器学习领域具有重要意义，可能为未来算法设计提供新的视角。其结果的紧性证明进一步增强了研究的理论贡献。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在解决从矩阵向量积查询中学习未知矩阵的结构化近似问题。这个问题在科学计算和机器学习算法中至关重要，应用于结构化矩阵的快速乘法和求逆、构建一阶优化的预处理器以及作为微分算子学习的模型。现有工作主要关注特定结构化矩阵家族的查询复杂度上下限，而本文旨在更普遍地理解从一般矩阵家族中学习近似的查询复杂度。

**Method:** 本文研究了在给定矩阵向量积（matvec）查询（$x \rightarrow Ax$和$x \rightarrow A^Tx$）的情况下，学习未知矩阵$A$的结构化近似问题。研究侧重于从任意有限大小的矩阵家族$\mathcal{F}$中寻找$A$的近最优近似。通过覆盖数论证，将结果扩展到无限家族，并以线性矩阵家族为例。

**Result:** 论文的主要结果表明，在matvec模型中，学习任何有限大小的矩阵家族$\mathcal{F}$的近最优近似的查询复杂度可以从标准矩阵草图方法的$O(\log|\mathcal{F}|)$显著提升至$\tilde{O}(\sqrt{\log|\mathcal{F}|})$，实现了近乎二次方的改进。此外，该论文证明了此界限在对数对数因子内是紧的。对于维度为$q$的线性矩阵家族，可以实现$\tilde{O}(\sqrt{q})$的查询复杂度，优于现有草图技术和向量-矩阵-向量查询的$O(q)$界限。

**Conclusion:** 本文在矩阵向量积模型下，显著提升了从一般矩阵家族中学习结构化近似的查询效率，将复杂度从对数级别降低到平方根对数级别，并证明了该界限的紧性，这为科学计算和机器学习中的相关应用提供了更高效的理论基础。

> **ai_Abstract:** 本文研究了在矩阵向量积（matvec）查询条件下，从一般矩阵家族中学习未知矩阵结构化近似的查询效率问题。相较于现有方法在向量-矩阵-向量查询模型下或矩阵草图技术中达到$O(\log|\mathcal{F}|)$或$O(q)$的复杂度，本研究发现，在matvec模型下，学习有限矩阵家族$\mathcal{F}$的近最优近似的查询复杂度可以显著降低至$\tilde{O}(\sqrt{\log|\mathcal{F}|})$，对于维度为$q$的线性矩阵家族，则为$\tilde{O}(\sqrt{q})$。这些结果实现了查询复杂度的近乎二次方改进，并被证明是紧的，为相关应用提供了更高的效率。

> **摘要翻译:** 我们研究了在给定矩阵向量积（matvec）查询（形式为$x \rightarrow Ax$和$x \rightarrow A^Tx$）的情况下，学习未知矩阵$A$的结构化近似（低秩、稀疏、带状等）的问题。这个问题对于科学计算和机器学习中的算法至关重要，应用于结构化矩阵的快速乘法和求逆、构建一阶优化的预处理器，并作为微分算子学习的模型。先前的工作主要集中于获取学习在应用中常见特定结构化矩阵家族的查询复杂度上下限。\n我们开始更普遍地研究这个问题，旨在理解从一般矩阵家族中学习近似的查询复杂度。我们的主要结果集中于从任何有限大小的矩阵家族$\mathcal{F}$中找到$A$的近最优近似。矩阵草图的标准结果表明，在这种设置下，$O(\log|\mathcal{F}|)$次matvec查询就足够了。对于形式为$x,y\rightarrow x^TAy$的向量-矩阵-向量查询，这个界限也可以达到，并且是最佳的，这类查询在秩-1矩阵感知的工作中得到了广泛研究。\n令人惊讶的是，我们发现，在matvec模型中，查询复杂度可以实现近乎二次方的改进，达到$\tilde{O}(\sqrt{\log|\mathcal{F}|})$。此外，我们证明了这个界限在对数对数因子内是紧的。通过覆盖数论证，我们的结果扩展到经过充分研究的无限家族。例如，我们确定可以以$\tilde{O}(\sqrt{q})$次matvec查询学习维度为$q$的任何“线性矩阵家族”的近最优近似，这比通过草图技术和向量-矩阵-向量查询可实现的$O(q)$界限有所改进。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [266] [Edge-weighted Matching in the Dark](https://arxiv.org/abs/2507.19366)
> *黑暗中的边加权匹配*

*Zhiyi Huang, Enze Sun, Xiaowei Wu, Jiahao Zhao* | **Category: cs.DS** | **Updated: 2025-07-25**

**Keywords:** 无感知二分匹配, 二次排序, 竞争比, 在线算法, 二次规划

**Comment:** 

> **TL;DR:** 提出了一种0.659竞争比的二次排序算法，用于解决无感知二分匹配问题，打破了现有界限并改进了最佳竞争比。

**AI_Comments:** 这篇论文通过引入“二次排序”这一新颖算法，在无感知二分匹配问题上取得了显著突破，不仅解决了长期存在的开放问题，还提升了竞争比，超越了此前依赖分布的最佳算法。其创新点在于将二次形式引入算法的定义和分析中，并通过二次规划进行优化，为在线匹配算法的设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决Tang、Wu和Zhang (JACM 2023)提出的开放问题，并突破$1-\frac{1}{e}$的障碍，同时改善现有Query-Commit Matching算法的竞争比。

**Method:** 提出了一种名为“二次排序”（Quadratic Ranking）的新型算法，它是经典排序算法的变体。该算法通过两个函数进行参数化，并利用这两个函数的二次形式来定义和分析算法中的关键表达式。研究表明，这些二次形式是满足一组自然属性的唯一选择，并且可以通过二次规划求解器来优化这两个函数的选择。

**Result:** 提出了一种0.659竞争比的二次排序算法，用于无感知二分匹配问题。这个结果打破了$1-\frac{1}{e}$的障碍，并且其竞争比优于Chen等人（SODA 2025）提出的现有最佳0.641竞争比（针对Query-Commit Matching的依赖分布算法）。

**Conclusion:** 该研究通过引入二次排序算法，成功解决了无感知二分匹配问题中的一个开放性问题，并显著提高了算法的竞争比，为该领域树立了新的基准。

> **ai_Abstract:** 这篇论文介绍了一种0.659竞争比的二次排序算法，专为无感知二分匹配问题设计。该算法成功突破了$1-\frac{1}{e}$的竞争比障碍，并超越了现有依赖分布算法的最佳性能（0.641）。二次排序算法是经典排序算法的创新变体，其核心在于利用参数化的两个函数的二次形式进行定义与分析，并通过二次规划实现优化。

> **摘要翻译:** 我们提出了一种用于无感知二分匹配问题（Query-Commit Matching的无分布版本）的0.659竞争比二次排序算法。这一结果打破了$1-\frac{1}{e}$的障碍，解决了Tang、Wu和Zhang（JACM 2023）提出的一个开放性问题。此外，这种无分布算法的竞争比改进了Chen、Huang、Li和Tang（SODA 2025）提出的Query-Commit Matching的最佳现有0.641竞争比（该算法是依赖分布的）。二次排序是经典排序算法的一种新颖变体。我们用两个函数对算法进行参数化，并让算法定义和分析中的两个关键表达式成为这两个函数的二次形式。我们表明，二次形式是满足一组自然属性的唯一选择。此外，它们允许我们使用强大的二次规划求解器来优化这两个函数的选择。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [422] [Minmax-Regret $k$-Sink Location on a Dynamic Tree Network with Uniform Capacities](https://arxiv.org/abs/1806.03814)
> *具有均匀容量的动态树网络上的最小最大遗憾 $k$ 汇点选址*

*Mordecai J. Golin, Sai Sandeep* | **Category: cs.DS** | **Updated: 2025-07-24**

**Keywords:** 最小最大遗憾, $k$ 汇点选址, 动态树网络, 均匀容量, 鲁棒优化

**Comment:** 

> **TL;DR:** 本文解决了具有均匀容量的动态树网络上最小最大遗憾 $k$ 汇点选址问题，为一般 $k$ 值提供了多项式时间解。

**AI_Comments:** 本文的主要创新在于将具有均匀容量的动态树网络上最小最大遗憾 $k$ 汇点选址问题的解决方案从 $k=1$ 推广到了一般 $k$ 值，这是鲁棒优化和网络流问题领域的一个重要理论进展。尽管所提出的算法复杂度较高，但它为之前无解的问题提供了第一个多项式时间解决方案，具有显著的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 疏散问题中，确定 $k$ 个汇点以最小化疏散时间至关重要。传统的 $k$ 汇点选址问题在一般图上是NP难的，但在树上可解。为了应对流量值的不确定性，引入了最小最大遗憾的概念，旨在找到在所有可能场景下，实际疏散时间与该场景下最小疏散时间之间差异最小的汇点布局。此前，对于具有均匀容量的动态树网络上的最小最大遗憾 $k$ 汇点选址问题，只有 $k=1$ 的情况有已知的多项式时间解，而对于一般 $k$ 值，该问题尚未解决。

**Method:** 本文提出了一种算法，为具有均匀容量的动态树网络上的最小最大遗憾 $k$ 汇点选址问题（对于一般 $k$ 值）提供了多项式时间解。抽象中未详细说明具体算法步骤。

**Result:** 本文为具有均匀容量的动态树网络上的最小最大遗憾 $k$ 汇点选址问题提供了多项式时间解，其时间复杂度为 $O\Bigl( \max(k^2 \log^2 k,\log ^2n)\, k^4 n^2 \log^5 n\Bigr)$。

**Conclusion:** 本文成功地解决了具有均匀容量的动态树网络上最小最大遗憾 $k$ 汇点选址问题在一般 $k$ 值下的多项式时间可解性，填补了该领域的一个空白。

> **ai_Abstract:** 本文研究了具有均匀容量的动态树网络上的最小最大遗憾 $k$ 汇点选址问题。动态流网络中，流量以特定容量通过边，当流入速度超过流出速度时会发生拥堵。疏散问题旨在将所有流量疏散到 $k$ 个汇点，以最小化疏散时间。最小最大遗憾概念源于鲁棒优化，旨在找到一个汇点布局，使其在所有可能的流量场景下，实际疏散时间与该场景下最佳疏散时间之间的差异最小。此前，该问题在动态树网络上仅对 $k=1$ 有多项式时间解。本文为一般 $k$ 值提供了该问题的多项式时间解，其时间复杂度为 $O\Bigl( \max(k^2 \log^2 k,\log ^2n)\, k^4 n^2 \log^5 n\Bigr)$。

> **摘要翻译:** 一个具有均匀容量 $c$ 的动态流网络 $G$ 是一个图，其中在单个时间单位内最多有 $c$ 单位的流可以进入一条边。如果流进入顶点的速度快于其离开的速度，就会发生拥堵。疏散问题是指假设所有流是汇合的，即所有流通过特定顶点后必须遵循相同的出口边，将所有流疏散到汇点。$k$ 汇点选址问题是放置 $k$ 个汇点，以最小化此疏散时间。尽管 $k$ 汇点选址问题在一般图上是NP难的，但在树上可以在 $\tilde O(k^2 n)$ 时间内解决。
最小最大遗憾的概念源于鲁棒优化。对于每个源点，提供了一系列可能的流值，并且任何在此范围内的流值场景都可能发生。目标是找到一个汇点布局，该布局在所有可能场景下，最小化疏散到这些汇点的时间与该场景下最小疏散时间之间的差异。
具有均匀容量的动态路径网络上的最小最大遗憾 $k$ 汇点选址问题在 $n$ 和 $k$ 上是多项式可解的。类似地，树上的最小最大遗憾 $k$ 中心问题在 $n$ 和 $k$ 上也是多项式可解的。在这项工作之前，对于具有均匀容量的动态树网络上的最小最大遗憾 $k$ 汇点选址问题，只有 $k=1$ 的情况才有已知的多项式时间解。本文解决了这个问题，对于一般 $k$ 值，其时间复杂度为
$$O\Bigl( \max(k^2 \log^2 k,\log ^2n)\, k^4 n^2 \log^5 n\Bigr)$$

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [207] [Generating real-time detailed ground visualisations from sparse aerial point clouds](https://arxiv.org/abs/2507.18664)
> *从稀疏航空点云生成实时详细地面可视化*

*Aidan Murray, Eddie Waite, Caleb Ross, Scarlet Mitchell, Alexander Bradley, Joanna Jamrozy, Kenny Mitchell* | **Category: cs.GR, cs.CV, I.3.2; I.4.10** | **Updated: 2025-07-24**

**Keywords:** 实时可视化, 航空点云, 3D内容生成, 地面可视化, 自动化

**Comment:** CVMP Short Paper. 1 page, 3 figures, CVMP 2022: The 19th ACM SIGGRAPH
  European Conference on Visual Media Production, London. This work was
  supported by the European Union's Horizon 2020 research and innovation
  programme under Grant 101017779

> **TL;DR:** 该论文提出了一种从稀疏航空点云自动生成高质量、实时详细地面可视化内容的方法，解决了传统手动创建3D内容成本高昂且准确性不足的问题。

**AI_Comments:** 该论文的创新之处在于其自动化处理流程，能够将稀疏的航空扫描数据转化为高质量、实时的详细地面可视化内容。这对于降低大规模户外3D内容制作的成本和提高还原真实世界的准确性具有重要意义。其在训练、模拟和视频游戏等领域的应用潜力，也凸显了该方法的实用价值和广阔前景。

<details>
  <summary>Details</summary>

**Motivation:** 构建逼真且视觉质量足以在步行或驾车时观察的大规模户外3D内容，通常需要由大量熟练的艺术家团队完成，这导致成本高昂且难以精确还原真实世界的地貌多样性。

**Method:** 作者提出了一种方法，定义了一个过程，能够自动放大真实世界的扫描数据，并实时渲染成动画3D形式，以便高质量地进行近距离探索。

**Result:** 该方法能够生成高质量、可用于近距离探索的实时动画3D内容，适用于训练、模拟、视频游戏和可视化应用，解决了传统手动制作成本高昂和准确性不足的问题。

**Conclusion:** 该论文提出了一种自动化的方法，能够从稀疏航空点云生成实时详细的地面可视化内容，为训练、模拟、视频游戏和可视化等应用提供了一种成本效益高且准确性强的解决方案。

> **ai_Abstract:** 本文提出了一种从稀疏航空点云自动生成高质量实时地面可视化内容的方法。该方法旨在解决传统手动创建大规模户外3D内容所面临的成本高昂和准确性不足的问题，通过自动放大真实世界的扫描数据并进行实时3D渲染，为训练、模拟、视频游戏和可视化等应用提供了一种高效且逼真的解决方案。

> **摘要翻译:** 构建逼真且视觉质量足以在步行或驾车时近距离观察的大规模户外3D内容，通常需要由大量擅长建模、纹理、材质着色和照明的艺术家团队完成，这通常会导致成本高昂，并且在还原真实世界地貌的多样性方面准确性降低。在我们提出的方法中，我们定义了一个过程，可以自动放大真实世界的扫描数据，并实时渲染成动画3D形式，以便高质量地进行近距离探索，适用于训练、模拟、视频游戏和可视化应用。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [231] [GeoAvatar: Adaptive Geometrical Gaussian Splatting for 3D Head Avatar](https://arxiv.org/abs/2507.18155)
> *GeoAvatar: 用于三维头部化身的自适应几何高斯泼溅*

*SeungJun Moon, Hah Min Lew, Seungeun Lee, Ji-Su Kang, Gyeong-Moon Park* | **Category: cs.GR, cs.CV, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 3D头部化身, 高斯泼溅, 自适应几何, 口腔动画, 身份保留

**Comment:** ICCV 2025, Project page: https://hahminlew.github.io/geoavatar/

> **TL;DR:** GeoAvatar 提出了一种自适应几何高斯泼溅框架，通过自适应预分配和分区域变形策略，解决了3D头部化身生成中身份保留与动画效果平衡的挑战，并发布了新的动态人脸数据集。

**AI_Comments:** GeoAvatar的创新点在于其自适应几何高斯泼溅框架，特别是自适应预分配阶段（APS）和针对口腔的精细化变形策略，这有效地解决了现有方法在高斯适应面部几何偏差上的不足。此外，发布新的DynamicFace数据集也对该领域的研究具有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 尽管3D头部化身生成取得了进展，但在身份保留（重建）与新姿态和表情（动画）之间取得平衡仍然是一个挑战。现有方法难以使高斯适应面部区域变化的几何偏差，导致质量不佳。

**Method:** GeoAvatar 提出了一种自适应几何高斯泼溅框架。它利用无监督的自适应预分配阶段（APS），将高斯分割为刚性和柔性两部分，用于自适应偏移正则化。基于口腔解剖学和动力学，引入了新颖的口腔结构和分区域变形策略，以增强口腔的动画保真度。此外，还提出了一个正则化损失，用于高斯和3DMM面部之间的精确绑定。研究团队还发布了DynamicFace，一个包含高度表达面部动作的视频数据集。

**Result:** 广泛的实验表明，GeoAvatar 在重建和新颖动画场景中，与现有最先进方法相比，表现出优越性。

**Conclusion:** GeoAvatar通过自适应几何高斯泼溅框架，有效解决了3D头部化身生成中身份保留与动画效果的平衡问题，并在重建和动画方面超越了现有技术。

> **ai_Abstract:** GeoAvatar 提出了一种自适应几何高斯泼溅框架，旨在解决3D头部化身生成中身份保留与动画效果之间的平衡问题。该方法通过自适应预分配阶段（APS）将高斯分为刚性和柔性集，并引入了基于口腔解剖学和动态的分区域变形策略，以增强口腔动画保真度。此外，还设计了正则化损失以实现高斯与3DMM面部的精确绑定。论文还发布了新的动态面部数据集DynamicFace。实验证明，GeoAvatar 在重建和动画方面优于现有SOTA方法。

> **摘要翻译:** 尽管三维头部化身生成取得了最新进展，但在身份保留（即重建）与新姿态和表情（即动画）之间取得平衡仍然是一个挑战。现有方法难以使高斯适应面部区域变化的几何偏差，导致次优的质量。为了解决这个问题，我们提出了GeoAvatar，一个自适应几何高斯泼溅框架。GeoAvatar 利用自适应预分配阶段（APS），这是一种无监督方法，将高斯分割为刚性和柔性两部分，用于自适应偏移正则化。然后，基于口腔解剖学和动力学，我们引入了一种新颖的口腔结构和分区域变形策略，以增强口腔的动画保真度。最后，我们提出了一个正则化损失，用于高斯和3DMM面部之间的精确绑定。此外，我们发布了DynamicFace，一个包含高度表达面部动作的视频数据集。广泛的实验表明，GeoAvatar 在重建和新颖动画场景中，与现有最先进方法相比，表现出优越性。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [270] [Procedural city modeling](https://arxiv.org/abs/2507.18899)
> *程序化城市建模*

*Thomas Lechner, Ben Watson, Uri Wilensky, Martin Felsen* | **Category: cs.GR** | **Updated: 2025-07-25**

**Keywords:** 程序化城市建模, 智能体模拟, 土地利用, 建筑分布, 城市发展

**Comment:** 

> **TL;DR:** 提出一种基于土地利用和建筑分布的程序化城市生成方法，通过智能体模拟实现从乡村到大都市的逼真演变。

**AI_Comments:** 这篇论文的创新点在于其将城市建模的重点从道路网络转移到土地利用和建筑分布，并引入了基于智能体模拟的自下而上生成范式。这种方法不仅能够生成视觉上更具说服力的城市，而且通过简单的规则涌现复杂行为的理念，为城市建模带来了更高的灵活性和可扩展性，使其能够模拟城市发展过程中的动态性和社会文化因素。

<details>
  <summary>Details</summary>

**Motivation:** 现有城市建模方法主要关注道路网络，无法生成逼真且可信的城市，且难以捕捉城市发展行为。本研究旨在生成具有发展行为、在不同发展阶段都具说服力的、自自动化的人工城市。

**Method:** 提出一种程序化城市生成方法，侧重于土地利用和建筑分布，而非仅填充道路网络。采用基于智能体的模拟，通过设定简单的行为规则，使智能体在模拟环境中相互作用，从而涌现出复杂的城市行为。模型旨在仅需地形描述作为输入，并允许高低层参数调整以支持艺术创作。

**Result:** 能够生成逼真且可信的人工城市，这些城市能够捕捉发展行为，并在从乡村到大都市的任何发展阶段都显得引人注目。模型是自自动化的，仅需地形描述作为输入。

**Conclusion:** 通过基于智能体的简单规则集，可以生成复杂的城市行为，并使模型在结构类型以及描述社会和文化影响方面具有可扩展性，从而实现逼真且可信的程序化城市建模。

> **ai_Abstract:** 这篇论文提出了一种新的程序化城市建模方法，旨在通过捕捉城市发展行为来生成逼真且可信的虚拟城市。与以往主要关注道路网络的方法不同，本文方法侧重于土地利用和建筑分布，并利用基于智能体的模拟，通过简单的规则集实现复杂行为的涌现。该模型高度自动化，仅需地形输入，并支持艺术定制，期望能够模拟从乡村到大都市的城市演变，并具有在结构和社会文化影响方面的可扩展性。

> **摘要翻译:** 我们提出了一种程序化生成熟悉而复杂的人造物：城市的方法。我们并非试图复制现有城市，而是通过捕捉发展行为来生成令人信服且合理的虚拟城市。此外，我们的成果旨在自我构建，使其在从乡村到大都市的任何过渡点都应显得引人注目。我们的方法主要侧重于土地利用和建筑分布来创建真实的城市环境，而之前城市建模的尝试主要集中于填充道路网络。最后，我们希望我们的模型能够实现自我自动化，以至于唯一必要的输入是地形描述，但也可以指定其他高层和低层参数以支持艺术贡献。借助基于智能体的模拟，我们正在生成一个智能体和行为系统，它们通过对模拟环境的影响相互作用。我们的理念是，随着每个智能体遵循一套简单的行为规则，更复杂的行为将倾向于从智能体之间及其不同规则集之间的互动中涌现出来。通过将我们的模型限制为每类智能体的一组简单规则，我们希望使我们的模型不仅在所产生的结构类型方面可扩展，而且在描述所有城市中普遍存在的社会和文化影响方面也可扩展。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [313] [Tiny is not small enough: High-quality, low-resource facial animation models through hybrid knowledge distillation](https://arxiv.org/abs/2507.18352)
> *小还不够小：通过混合知识蒸馏实现高质量、低资源的面部动画模型*

*Zhen Han, Mattias Teye, Derek Yadgaroff, Judith Bütepage* | **Category: cs.GR, cs.LG, cs.MM, cs.SD, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 面部动画, 知识蒸馏, 低资源, 设备上推理, 实时

**Comment:** Accepted to ACM Transactions on Graphics 2025 (SIGGRAPH journal
  track)

> **TL;DR:** 通过混合知识蒸馏和伪标签训练小型学生模型，本文实现了高质量、低资源的面部动画，使其能够在设备上实时运行。

**AI_Comments:** 本文的创新点在于将混合知识蒸馏与伪标签技术相结合，成功地将大型高性能模型的知识迁移到极小的学生模型中，从而实现了在资源受限设备上的实时面部动画。其重要性体现在突破了传统高质量面部动画模型对计算资源和存储空间的高要求，为游戏开发和数字角色应用提供了新的可能性。其局限性可能在于伪标签的质量对最终模型性能的影响，以及模型在更复杂、多样化场景下的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 高质量、鲁棒的语音驱动3D面部动画模型需要大量多样化数据集，但现有模型通常过大，只能在专用机器上进行离线推理。本文旨在实现设备上的实时面部动画模型。

**Method:** 本文通过使用混合知识蒸馏与伪标签来克服大型数据集的缺乏。利用一个高性能的教师模型，在大规模音频数据集上训练非常小的学生模型。学生模型仅包含卷积层和全连接层，无需注意力上下文或循环更新。

**Result:** 实验表明，该方法可以将内存占用减少到3.4 MB，所需的未来音频上下文减少到81 ms，同时保持高质量的动画效果。

**Conclusion:** 这为设备上推理铺平了道路，是迈向逼真、模型驱动的数字角色的重要一步。

> **ai_Abstract:** 本文提出了一种通过混合知识蒸馏和伪标签训练小型学生模型的方法，以实现在资源受限设备上进行高质量、实时语音驱动的3D面部动画。针对现有模型体积过大、仅限于离线推理的问题，研究团队利用高性能教师模型在大规模音频数据集上训练仅包含卷积和全连接层的轻量级学生模型。实验结果显示，该方法显著降低了模型的内存占用和音频上下文需求，同时保持了动画质量，为设备上推理和创建逼真数字角色奠定了基础。

> **摘要翻译:** 高质量、鲁棒的语音驱动3D面部动画机器学习模型需要大量多样化的高质量音频-动画对数据集。为了克服这种数据集的缺乏，最近的工作引入了大型预训练语音编码器，这些编码器对输入音频的变化具有鲁棒性，因此使面部动画模型能够泛化到不同的说话人、音频质量和语言。然而，由此产生的面部动画模型过大，只能在专用机器上进行离线推理。在这项工作中，我们在游戏开发的背景下探索设备上的实时面部动画模型。我们通过使用混合知识蒸馏与伪标签来克服大型数据集的缺乏。给定一个大型音频数据集，我们采用一个高性能的教师模型来训练非常小的学生模型。与预训练的语音编码器不同，我们的学生模型只包含卷积层和全连接层，无需注意力上下文或循环更新。在我们的实验中，我们证明可以将内存占用减少到3.4 MB，所需的未来音频上下文减少到81 ms，同时保持高质量的动画。这为设备上推理铺平了道路，是迈向逼真、模型驱动的数字角色的重要一步。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [326] [TiVy: Time Series Visual Summary for Scalable Visualization](https://arxiv.org/abs/2507.18972)
> *TiVy：可伸缩可视化的时间序列视觉摘要*

*Gromit Yeuk-Yin Chan, Luis Gustavo Nonato, Themis Palpanas, Cláudio T. Silva, Juliana Freire* | **Category: cs.GR, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 时间序列, 可视化, 可伸缩性, 序列模式, 动态时间规整

**Comment:** to be published in TVCG (IEEE VIS 2025)

> **TL;DR:** TiVy通过使用序列模式总结时间序列，解决了多时间序列可视化中可伸缩性和视觉清晰度的问题，实现了更快、更清晰的数据展示。

**AI_Comments:** TiVy的创新之处在于其独特地结合了动态时间规整（DTW）和序列模式来总结时间序列，并能提取时间对齐的变长子序列，这显著优于传统聚类方法。其在速度上的1000倍提升和对视觉清晰度的改善，使其成为处理大规模时间序列数据可视化领域的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有时间序列可视化方法在处理长时间跨度或大量时间序列时，存在可伸缩性差和视觉混乱（如过多小倍数或线条重叠）的问题，难以清晰地展示数据并从中获取洞察。

**Method:** TiVy是一种新算法，它首先使用动态时间规整（DTW）基于子序列的视觉相似性将时间序列转换为一组符号序列；然后，根据频繁的序列模式构建相似子序列的非交并分组，生成时间序列的视觉摘要。与传统聚类不同，TiVy提取的是时间上对齐的变长相似子序列。此外，TiVy还提供了一个交互式可视化界面，能够实时渲染大规模时间序列。

**Result:** TiVy算法能够提取清晰准确的时间序列模式，提供无杂乱的叠加可视化效果，并实现了比直接DTW聚类快1000倍的显著加速。它还被证明能有效探索海量时间序列数据中的隐藏结构。

**Conclusion:** TiVy通过其创新的序列模式总结方法，有效解决了大规模时间序列可视化中的可伸缩性和视觉清晰度挑战，提供了一种高效、准确的数据探索工具。

> **ai_Abstract:** 本文提出了TiVy，一种解决多时间序列可视化中可伸缩性和视觉清晰度问题的算法。现有方法在处理长时间序列时常导致视觉混乱。TiVy利用动态时间规整（DTW）和序列模式，将时间序列转换为符号序列并进行分组，生成清晰的视觉摘要。该方法能提取时间对齐的变长相似子序列，并提供实时交互式可视化。实验证明，TiVy能提取准确模式，相较于传统DTW聚类速度提升1000倍，有效揭示大规模时间序列中的隐藏结构。

> **摘要翻译:** 可视化多个时间序列在可伸缩性和视觉清晰度之间存在根本性的权衡。时间序列捕捉了许多大规模真实世界过程的行为，从股票市场趋势到城市活动。用户通常通过将它们可视化为折线图，并列或叠加多个时间序列来比较它们并识别趋势和模式，从而获得洞察。然而，现有表示在可伸缩性方面存在困难：当覆盖长时间跨度时，会导致过多的小倍数或重叠线造成视觉混乱。我们提出了TiVy，一种使用序列模式总结时间序列的新算法。它使用动态时间规整（DTW）将序列转换为一组基于子序列视觉相似性的符号序列，然后根据频繁的序列模式构建相似子序列的非交并分组。分组结果是时间序列的视觉摘要，提供了更少的重复小倍数和无杂乱的叠加。与常见的聚类技术不同，TiVy提取时间上对齐的相似子序列（长度可变）。我们还提出了一种交互式时间序列可视化，可以实时渲染大规模时间序列。我们的实验评估表明，我们的算法（1）在可视化时间序列数据时提取清晰准确的模式，（2）与直接的DTW聚类相比，实现了显著的加速（1000倍）。我们还在两种使用场景中展示了我们方法探索海量时间序列数据中隐藏结构的效率。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [382] [Motion Synthesis with Sparse and Flexible Keyjoint Control](https://arxiv.org/abs/2503.15557)
> *稀疏柔性关键点控制的运动合成*

*Inwoo Hwang, Jinseok Bae, Donggeun Lim, Young Min Kim* | **Category: cs.GR, cs.CV, cs.RO** | **Updated: 2025-07-25**

**Keywords:** 运动合成, 关键点控制, 扩散模型, 角色动画, 柔性控制

**Comment:** Accepted to ICCV 2025. Project Page: http://inwoohwang.me/SFControl

> **TL;DR:** 提出了一种基于稀疏柔性关键点信号的分解扩散运动合成框架，解决了传统动画制作中密集控制的限制，实现了更直观、灵活的角色动画生成。

**AI_Comments:** 本文提出了一种新颖的分解式扩散模型，通过引入稀疏和时间无关的关键点控制，显著提升了角色运动合成的实用性和灵活性。其创新点在于将复杂的全身运动分解为关键点运动和全身运动两个阶段，并通过低维关键点实现对多种控制信号的适应，有效降低了动画制作的复杂性。该方法对于动画师来说，提供了更直观和高效的动画生成工具，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 创建富有表现力的角色动画劳动密集，需要动画师在空间和时间上进行复杂的精细调整。现有的可控运动生成方法通常依赖于预定义的密集时空规范（例如，带有精确每帧时间信息的密集骨盆轨迹），这限制了动画师的实用性。

**Method:** 提出了一种实用的可控运动合成框架，该框架尊重稀疏和柔性关键点信号。该方法采用分解式扩散运动合成框架，首先从稀疏输入控制信号合成关键点运动，然后基于完成的关键点轨迹合成全身运动。引入了时间无关的控制公式，消除了对帧特定时间注释的需求，增强了控制灵活性。

**Result:** 通过在不同数据集和场景上的综合实验，证明了稀疏柔性关键点控制的有效性。

**Conclusion:** 稀疏柔性关键点控制在生成可控角色动画方面是有效的，并且比传统方法更具实用性和灵活性。

> **ai_Abstract:** 本文提出了一种名为“稀疏柔性关键点控制”的运动合成框架，旨在解决传统角色动画制作中因密集时空规范导致的劳动密集和实用性受限问题。该框架采用分解式扩散模型，首先从稀疏输入信号合成关键点运动，然后基于这些关键点轨迹生成全身运动。其创新之处在于利用低维关键点实现对多种控制信号的适应性，并引入时间无关的控制公式，显著提升了控制的灵活性和直观性。实验证明了该方法在生成可控、自然角色动画方面的有效性。

> **摘要翻译:** 创建富有表现力的角色动画劳动密集，需要动画师在空间和时间上进行复杂的精细调整。现有的可控运动生成方法通常依赖于预定义的密集时空规范（例如，带有精确每帧时间信息的密集骨盆轨迹），这限制了动画师的实用性。为了在不同场景中处理高级意图和直观控制，我们提出了一种实用的可控运动合成框架，该框架尊重稀疏和柔性关键点信号。我们的方法采用分解式扩散运动合成框架，首先从稀疏输入控制信号合成关键点运动，然后基于完成的关键点轨迹合成全身运动。低维关键点运动可以轻松适应各种控制信号类型，例如用于多样化目标驱动运动合成的末端执行器位置，或将功能约束纳入关键点子集。此外，我们引入了时间无关的控制公式，消除了对帧特定时间注释的需求并增强了控制灵活性。然后，共享的第二阶段可以从密集的关键点运动中合成自然全身运动，精确满足任务要求。我们通过在不同数据集和场景上的综合实验证明了稀疏柔性关键点控制的有效性。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [405] [Advancing Multimodal LLMs by Large-Scale 3D Visual Instruction Dataset Generation](https://arxiv.org/abs/2507.08513)
> *通过大规模3D视觉指令数据集生成推进多模态LLMs*

*Liu He, Xiao Zeng, Yizhi Song, Albert Y. C. Chen, Lu Xia, Shashwat Verma, Sankalp Dayal, Min Sun, Cheng-Hao Kuo, Daniel Aliaga* | **Category: cs.GR, cs.CV** | **Updated: 2025-07-23**

**Keywords:** 多模态大语言模型, 3D视觉指令数据集, 相机-物体关系, 数据合成, Ultimate3D

**Comment:** 

> **TL;DR:** 本文提出一个合成生成流水线，用于创建大规模3D视觉指令数据集，以解决多模态大语言模型在捕获相机-物体关系方面的不足，并展示了其在相机-物体关系识别任务上的显著性能提升。

**AI_Comments:** 本文的创新点在于提出了一个合成生成流水线，能够高效地创建大规模且具有精确相机-物体关系标注的3D视觉指令数据集，从而有效解决了现有MLLMs训练数据多样性不足的问题。通过结合3D资产、先进的图像生成技术和LLM的文本生成能力，该方法为提升MLLMs对复杂视觉关系的理解能力提供了一个非常有前景的方向。其结果表明，专门构造的数据集对于提升模型在特定复杂任务上的性能至关重要，对未来MLLM的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态大语言模型（MLLMs）在准确捕获相机-物体关系（特别是物体方向、相机视角和相机镜头）方面存在困难，原因是它们在训练图像中缺乏多样化的相机-物体关系和相应的文本描述。

**Method:** 作者提出了一个合成生成流水线来创建大规模3D视觉指令数据集。该框架以3D资产作为输入，并使用渲染和基于扩散的图像生成模型来创建保留精确相机-物体关系的照片级真实图像。此外，还使用大语言模型（LLMs）生成文本提示，以指导视觉指令微调和控制图像生成。

**Result:** 创建了Ultimate3D数据集，包含24万个带有精确相机-物体标注的VQAs及其相应的基准。在所提出的数据集上进行微调的MLLMs在相机-物体关系识别任务上，比商业模型平均精度提高了33.4%。

**Conclusion:** 所提出的代码、数据集和基准将有助于多模态大语言模型的广泛应用。

> **ai_Abstract:** 本文提出了一种创新的合成生成流水线，旨在解决多模态大语言模型（MLLMs）在理解复杂相机-物体关系方面的不足。该流水线利用3D资产、渲染技术和扩散模型生成具有精确相机-物体关系的光真实图像，并结合大语言模型生成指导性文本提示。通过此方法，研究人员构建了大规模的Ultimate3D数据集（包含24万个VQA样本），并展示了在该数据集上微调的MLLMs在相机-物体关系识别任务上比商业模型有显著的性能提升，平均准确率提高了33.4%。该工作为推进MLLMs在复杂视觉理解方面的应用奠定了基础。

> **摘要翻译:** 多模态大语言模型（MLLMs）在准确捕获相机-物体关系方面存在困难，特别是物体方向、相机视角和相机镜头。这源于现有MLLMs在训练图像中缺乏多样化的相机-物体关系和相应的文本描述。为了解决这个问题，我们提出了一种合成生成流水线来创建大规模3D视觉指令数据集。我们的框架以3D资产作为输入，并使用渲染和基于扩散的图像生成模型来创建保留精确相机-物体关系的照片级真实图像。此外，大语言模型（LLMs）被用于生成文本提示，以指导视觉指令微调和控制图像生成。我们创建了Ultimate3D，一个包含24万个带有精确相机-物体标注的VQAs数据集，以及相应的基准。在我们的数据集上进行微调的MLLMs表现优于商业模型，在相机-物体关系识别任务上平均准确率提高了33.4%。我们的代码、数据集和基准将有助于多模态大语言模型的广泛应用。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [597] [PS-GS: Gaussian Splatting for Multi-View Photometric Stereo](https://arxiv.org/abs/2507.18231)
> *PS-GS：多视角光度立体高斯泼溅*

*Yixiao Chen, Bin Liang, Hanzhi Guo, Yongqing Cheng, Jiayi Zhao, Dongdong Weng* | **Category: cs.GR, cs.CV** | **Updated: 2025-07-24**

**Keywords:** 高斯泼溅, 多视角光度立体, 逆向渲染, 3D重建, 光照估计

**Comment:** 

> **TL;DR:** PS-GS通过结合高斯泼溅和多视角光度立体，高效地联合估计物体的几何、材质和光照，从而实现更准确的3D重建。

**AI_Comments:** PS-GS创新性地将高斯泼溅这一高效的3D表示方法与多视角光度立体相结合，有效解决了传统逆向渲染中几何、材质和光照联合估计的难题。通过引入多光源信息和特定的正则化策略，显著提高了重建的准确性和效率，并为后续的应用如新视图合成和重照明提供了高质量的3D资产。

<details>
  <summary>Details</summary>

**Motivation:** 将逆向渲染与多视角光度立体（MVPS）结合可以比依赖固定环境光照的逆向渲染方法获得更准确的3D重建，但高效的逆向渲染与MVPS结合仍然具有挑战性。

**Method:** 本文提出了PS-GS方法，它首先重建一个标准的2D高斯泼溅模型作为初始几何。基于该初始化模型，通过包含光照计算多层感知器的完整渲染方程进行延迟逆向渲染。在整个优化过程中，通过未校准的光度立体估计法线来正则化渲染的法线图。还提出了用于单向光的2D高斯光线追踪以细化入射光照。这些正则化以及多视角和多光源图像的使用缓解了逆向渲染的病态问题。

**Result:** 实验证明，在合成和真实数据集上，PS-GS方法在重建精度和计算效率方面均优于现有工作。优化后重建的对象可用于新颖视图合成、重新照明以及材质和形状编辑。

**Conclusion:** PS-GS成功地将高斯泼溅与多视角光度立体相结合，实现了高效且准确的联合几何、材质和光照估计，有效解决了逆向渲染的病态问题，并为后续应用提供了高质量的3D重建。

> **ai_Abstract:** PS-GS是一种结合高斯泼溅和多视角光度立体的新方法，旨在高效准确地联合估计物体的几何、材质和光照。该方法利用2D高斯泼溅模型进行几何初始化，并通过包含光照计算MLP的完整渲染方程进行逆向渲染。通过未校准光度立体法线和2D高斯光线追踪进行正则化，有效缓解了逆向渲染的病态问题。实验证明，PS-GS在重建精度和计算效率上均优于现有方法，并支持新视图合成、重照明及材质/形状编辑。

> **摘要翻译:** 将逆向渲染与多视角光度立体（MVPS）结合可以比依赖固定环境光照的逆向渲染方法获得更准确的3D重建。然而，高效的逆向渲染与MVPS结合仍然具有挑战性。为了弥补这一空白，我们引入了多视角光度立体高斯泼溅（PS-GS），它能高效地联合估计由不同方向光源（多光源）照明的物体的几何、材质和光照。我们的方法首先重建一个标准的2D高斯泼溅模型作为初始几何。基于该初始化模型，通过包含光照计算多层感知器的完整渲染方程进行延迟逆向渲染。在整个优化过程中，我们通过未校准的光度立体估计法线来正则化渲染的法线图。我们还提出了用于单向光的2D高斯光线追踪以细化入射光照。这些正则化以及多视角和多光源图像的使用缓解了逆向渲染的病态问题。优化后，重建的对象可用于新颖视图合成、重新照明以及材质和形状编辑。在合成和真实数据集上的实验表明，我们的方法在重建精度和计算效率方面均优于现有工作。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [812] [Zero-Shot Dynamic Concept Personalization with Grid-Based LoRA](https://arxiv.org/abs/2507.17963)
> *基于网格LoRA的零样本动态概念个性化*

*Rameen Abdal, Or Patashnik, Ekaterina Deyneka, Hao Chen, Aliaksandr Siarohin, Sergey Tulyakov, Daniel Cohen-Or, Kfir Aberman* | **Category: cs.GR, cs.CV, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 零样本, 动态概念个性化, Grid-LoRA, 文本到视频生成, 视频网格

**Comment:** Project Page and Video :
  https://snap-research.github.io/zero-shot-dynamic-concepts/

> **TL;DR:** 本文提出了一种零样本框架，用于文本到视频模型中的动态概念个性化，通过训练轻量级Grid-LoRA适配器在结构化视频网格中实现编辑和合成，并在推理时使用Grid Fill模块生成连贯且保持身份的输出，无需测试时优化。

**AI_Comments:** 本文的创新点在于提出了一个完全零样本的动态概念个性化框架，通过引入Grid-LoRA和Grid Fill模块，有效解决了现有方法需要实例级微调的扩展性问题。其在无需测试时优化的前提下，实现对未见概念的泛化能力，是文本到视频生成领域的一个重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的动态概念个性化方法需要对每个实例进行微调，这限制了其可扩展性。

**Method:** 本文引入了一个完全零样本的框架，用于文本到视频模型中的动态概念个性化。该方法利用结构化的2x2视频网格来空间组织输入和输出对，从而能够训练轻量级的Grid-LoRA适配器，用于在这些网格内进行编辑和合成。在推理时，一个专用的Grid Fill模块完成部分观察到的布局，生成时间连贯且身份保持的输出。

**Result:** 一旦训练完成，整个系统只需一次前向传播即可运行，能够泛化到以前未见的动态概念，无需任何测试时优化。大量的实验证明了在各种主题和编辑场景中，该方法都能获得高质量和一致的结果，甚至超越了训练过的概念。

**Conclusion:** 本文提出的零样本框架通过使用Grid-LoRA和Grid Fill模块，成功实现了文本到视频模型中动态概念的个性化，克服了现有方法的扩展性限制，并展现了高质量的泛化能力。

> **ai_Abstract:** 本文提出了一种零样本框架，用于在文本到视频模型中实现动态概念个性化，以解决现有方法可扩展性差的问题。该方法利用结构化的2x2视频网格训练轻量级Grid-LoRA适配器进行编辑和合成，并在推理时通过Grid Fill模块生成时间连贯且身份保持的输出。该系统无需测试时优化，仅需一次前向传播即可泛化到新概念，并在广泛的实验中展示了高质量和一致性。

> **摘要翻译:** 最近文本到视频生成技术的进展使得从文本和图像提示生成高质量内容成为可能。虽然捕获特定主体外观和运动的动态概念个性化（从单个视频中实现）现在是可行的，但大多数现有方法需要对每个实例进行微调，这限制了可扩展性。我们引入了一个完全零样本的框架，用于文本到视频模型中的动态概念个性化。我们的方法利用结构化的2x2视频网格，以空间方式组织输入和输出对，从而能够训练轻量级的Grid-LoRA适配器，用于在这些网格内进行编辑和合成。在推理时，一个专用的Grid Fill模块完成部分观察到的布局，生成时间连贯且身份保持的输出。一旦训练完成，整个系统只需一次前向传播即可运行，能够泛化到以前未见的动态概念，无需任何测试时优化。大量的实验证明了在各种主题和编辑场景中，该方法都能获得高质量和一致的结果，甚至超越了训练过的概念。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [160] [An Investigation of Prompt Variations for Zero-shot LLM-based Rankers](https://arxiv.org/abs/2406.14117)
> *零样本大型语言模型排序器提示变体研究*

*Shuoqi Sun, Shengyao Zhuang, Shuai Wang, Guido Zuccon* | **Category: cs.IR, cs.CL** | **Updated: 2025-07-25**

**Keywords:** 零样本, LLM, 排序器, 提示变体, 排序算法

**Comment:** Accepted for publication at the 47th European Conference on
  Information Retrieval (ECIR 2025)

> **TL;DR:** 本研究系统地探究了零样本大型语言模型（LLM）排序器中提示词组件和措辞对效果的影响，发现提示词的选择有时比排序算法本身对排序效果影响更大。

**AI_Comments:** 这项研究创新性地揭示了在零样本LLM排序中，提示词设计的重要性可能被低估，其对性能的影响有时甚至超过了核心的排序算法。这对于未来LLM在信息检索领域的应用和研究具有重要指导意义，强调了精细化提示工程的价值。

<details>
  <summary>Details</summary>

**Motivation:** 目前尚不清楚零样本大型语言模型（LLM）排序器性能差异是源于底层的排序算法，还是由于提示词选择等次要因素。这种不确定性可能会阻碍未来的研究。

**Method:** 通过大规模实验和分析。

**Result:** 研究发现，排序算法、LLM骨干模型以及提示词组件和措辞都会影响零样本LLM排序器的性能。更重要的是，提示词的选择有时对排序效果的影响甚至超过了实际的排序算法，并且在考虑提示词变体时，不同排序方法之间的差异变得更加模糊。

**Conclusion:** 提示词组件和措辞的选择对零样本LLM排序器的有效性具有显著影响，有时其影响力甚至超过了实际的排序算法，这表明在评估和设计此类系统时，提示词设计至关重要。

> **ai_Abstract:** 本研究系统地调查了零样本大型语言模型（LLM）排序器中提示词组件和措辞对性能的影响。通过大规模实验，研究发现排序算法和LLM骨干模型都会影响排序效果，但提示词的选择和措辞的影响更为显著，有时甚至超过了排序算法本身，这表明提示词设计在零样本LLM排序中扮演着关键角色。

> **摘要翻译:** 我们系统地理解了提示词中特定组件和措辞对基于零样本大型语言模型（LLM）的排序器有效性的影响。最近提出了几种基于LLM的零样本排序方法。在许多方面，这些方法有所不同，包括（1）它们实现的排序算法，例如点对点（pointwise）与列表式（listwise），（2）使用的骨干LLM，例如GPT3.5与FLAN-T5，（3）提示词中使用的组件和措辞，例如是否使用角色定义（角色扮演）以及表达此意图的实际词语。目前尚不清楚性能差异是由于底层的排序算法，还是由于更好的提示词选择等虚假因素。这种混淆可能会阻碍未来的研究。通过我们的大规模实验和分析，我们发现排序算法确实导致了零样本LLM排序方法之间的差异。然而，LLM骨干模型也同样如此——但更重要的是，提示词组件和措辞的选择会影响排序。事实上，在我们的实验中，我们发现，有时这些后者元素对排序器有效性的影响比实际的排序算法更大，并且在考虑提示词变体时，排序方法之间的差异变得更加模糊。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [201] [Negative Sampling in Recommendation: A Survey and Future Directions](https://arxiv.org/abs/2409.07237)
> *推荐系统中的负采样：一项综述与未来方向*

*Haokai Ma, Ruobing Xie, Lei Meng, Fuli Feng, Xiaoyu Du, Xingwu Sun, Zhanhui Kang, Xiangxu Meng* | **Category: cs.IR** | **Updated: 2025-07-25**

**Keywords:** 负采样, 推荐系统, 综述, 用户反馈, 未来方向

**Comment:** 39 pages, 10 figures; Under review

> **TL;DR:** 本综述审视了推荐系统中的负采样策略，对其进行分类，并探讨了未来的研究方向，强调了其在解决推荐系统挑战方面的重要性。

**AI_Comments:** 这项综述对于全面审视推荐系统中一个常被忽视但至关重要的方面具有重要价值。它为负采样技术提供了结构化的理解，并明确指出了未来的研究机会，这对研究人员和实践者都非常有益。

<details>
  <summary>Details</summary>

**Motivation:** 推荐系统面临信息茧房、交互稀疏性等挑战，传统推荐算法常忽略负反馈。负采样作为一种揭示用户行为中真实负面信息的关键方法，对于理解用户偏好和改进推荐系统至关重要。

**Method:** 本综述首先讨论了现有用户反馈、负采样的关键作用及推荐系统中的优化目标，并分析了阻碍其进展的挑战。接着，它对现有负采样策略进行了广泛的文献回顾，并将其分为五类。最后，详细阐述了在不同推荐系统场景中定制负采样策略的见解，并概述了未来的研究方向。

**Result:** 本综述将现有负采样策略分为五大类，提供了针对不同推荐系统场景的定制负采样策略的深入见解，并概述了未来可能的研究方向。

**Conclusion:** 负采样是改进推荐系统、解决其固有挑战不可或缺的步骤。本综述全面回顾了当前的负采样策略，并指明了未来的研究方向。

> **ai_Abstract:** 本综述探讨了负采样在推荐系统（RS）中的关键作用，该系统传统上忽视了负反馈。论文指出，负采样对于解决RS中的信息茧房和稀疏性等挑战、理解用户偏好至关重要。本研究回顾了现有的负采样策略，将其分为五类，并提供了在各种RS场景中应用这些策略的见解，最后概述了未来的研究方向。

> **摘要翻译:** 推荐系统（RS）旨在从海量用户行为中捕捉个性化偏好，使其在信息爆炸时代变得举足轻重。然而，RS固有的“信息茧房”、交互稀疏性、冷启动问题和反馈循环使得用户只能与有限数量的物品进行交互。传统的推荐算法通常侧重于正向历史行为，却忽视了负反馈在理解用户偏好中的重要作用。作为一个有前景但容易被忽视的领域，负采样擅长揭示用户行为中固有的真实负面信息，正成为RS中不可避免的程序。在本综述中，我们首先讨论了现有用户反馈、负采样的关键作用以及RS中的优化目标，并深入分析了持续阻碍其进展的挑战。然后，我们对RS中现有的负采样策略进行了广泛的文献回顾，并根据其不同的技术将其分为五类。最后，我们详细阐述了在不同RS场景中定制负采样策略的见解，并概述了社区可能参与并受益的未来研究方向。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [250] [Interact2Vec -- An efficient neural network-based model for simultaneously learning users and items embeddings in recommender systems](https://arxiv.org/abs/2506.22648)
> *Interact2Vec——一种用于推荐系统中同时学习用户和物品嵌入的高效神经网络模型*

*Pedro R. Pires, Tiago A. Almeida* | **Category: cs.IR, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 推荐系统, 嵌入学习, 神经网络, 隐式反馈, Interact2Vec

**Comment:** Published in Applied Soft Computing (ASOC), 49 pages, 14 figures

> **TL;DR:** Interact2Vec是一种高效的神经网络模型，它利用隐式反馈同时学习用户和物品的低维嵌入，解决了推荐系统中数据稀疏和维度过高的问题，并在计算资源有限的情况下表现出色。

**AI_Comments:** 该论文提出了一种创新的神经网络模型Interact2Vec，其亮点在于仅依赖隐式反馈就能同时学习用户和物品的嵌入，并显著提升了训练效率。借鉴NLP领域的优化策略是其创新之处。在解决数据稀疏性和高维度问题的同时，其在资源受限环境下的高效性使其具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 推荐系统面临数据维度高和稀疏性问题。现有许多基于神经网络的嵌入学习方法架构复杂或依赖内容数据，而内容数据并非总能获取。

**Method:** 本文提出了Interact2Vec，一个新颖的神经网络模型，它仅需隐式反馈即可同时学习用户和物品的分布式嵌入。该模型采用了自然语言处理模型中常用的先进策略来优化训练过程并提升最终嵌入的质量。

**Result:** 在外部质量实验（Top-N排名问题）中，Interact2Vec在30%的数据集中取得了第二或第三的最好结果，与其他推荐算法相比具有竞争力。与其它基于嵌入的模型相比，其平均训练时间减少了274%，效率显著。内部质量分析也显示了令人满意的结果。

**Conclusion:** Interact2Vec能够取得有前景的结果，特别是在外部任务上，并且在计算资源稀缺的场景下，它是一个优秀的嵌入生成模型，能够高效地同时学习物品和用户的嵌入。

> **ai_Abstract:** Interact2Vec是一种新型的神经网络模型，专为推荐系统设计，旨在解决数据高维度和稀疏性问题。该模型仅利用隐式反馈，高效地同时学习用户和物品的低维嵌入，并借鉴了自然语言处理领域的优化策略。实验结果表明，Interact2Vec在Top-N推荐任务中表现出竞争力，并且在训练效率上显著优于其他基于嵌入的模型，特别适合计算资源有限的环境。

> **摘要翻译:** 在过去的十年中，推荐系统的人气激增。尽管取得了显著进展，但它们仍面临着诸如数据维度高和稀疏性等挑战性问题。将用户和物品表示为通过神经网络学习的低维嵌入已成为一种主流解决方案。然而，尽管最近的研究显示出有前景的结果，但许多方法依赖于复杂的架构或需要内容数据，而这些数据并非总是可用。本文提出了Interact2Vec，一种新颖的神经网络模型，它仅需隐式反馈即可同时学习用户和物品的分布式嵌入。该模型采用了自然语言处理模型中常用的先进策略来优化训练阶段并增强最终嵌入。针对模型的外部和内部质量进行了两种类型的实验。在前一种实验中，我们在Top-N排名问题中对Interact2Vec嵌入生成的推荐进行了基准测试，并将其与六种其他推荐算法进行了比较。该模型在30%的数据集中取得了第二或第三的最好结果，与其他推荐器具有竞争力，并且被证明非常高效，与其它基于嵌入的模型相比，平均训练时间减少了274%。随后，我们通过相似性表分析了嵌入的内部质量。我们的发现表明，Interact2Vec可以取得有前景的结果，特别是在外部任务上，并且在计算资源稀缺的场景下，它是一个优秀的嵌入生成模型，能够高效地同时学习物品和用户的嵌入。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [470] [DR.EHR: Dense Retrieval for Electronic Health Record with Knowledge Injection and Synthetic Data](https://arxiv.org/abs/2507.18583)
> *DR.EHR：结合知识注入和合成数据的电子健康记录密集检索*

*Zhengyun Zhao, Huaiyuan Ying, Yue Zhong, Sheng Yu* | **Category: cs.IR, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 电子健康记录, 密集检索, 知识注入, 合成数据, 语义鸿沟

**Comment:** Model and code released upon acceptance

> **TL;DR:** 提出DR.EHR，一种用于电子健康记录（EHR）检索的密集检索模型，通过知识注入和合成数据生成解决语义鸿沟问题，并在基准测试中取得SOTA表现。

**AI_Comments:** DR.EHR的创新之处在于其结合了知识注入和合成数据生成，有效解决了EHR领域特有的医学知识不足和训练数据稀缺问题。两阶段训练流程设计精巧，使其在专业领域检索任务中表现出色，对于临床应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 电子健康记录（EHR）在临床实践中至关重要，但其检索面临语义鸿沟挑战。现有密集检索模型（通用领域和生物医学领域）因医学知识不足或训练语料不匹配而表现不佳。

**Method:** 提出DR.EHR系列密集检索模型，专为EHR检索定制。采用两阶段训练流程：第一阶段从生物医学知识图谱中提取医学实体并注入知识；第二阶段利用大型语言模型生成多样化训练数据。使用MIMIC-IV出院总结进行训练，并训练了1.1亿和70亿参数的两个变体。

**Result:** 在CliniQ基准测试中，DR.EHR模型显著优于所有现有密集检索器，达到最先进水平。详细分析证实其在各种匹配和查询类型，特别是复杂语义匹配（如含义和缩写）上的优越性。消融研究验证了每个管道组件的有效性。在EHR QA数据集上的补充实验表明模型在自然语言问题（包括多实体复杂问题）上的泛化能力。

**Conclusion:** 该工作显著推进了EHR检索，为临床应用提供了强大的解决方案。

> **ai_Abstract:** DR.EHR是一种新型的密集检索模型，专为解决电子健康记录（EHR）检索中的语义鸿沟问题而设计。该模型采用两阶段训练方法：首先从生物医学知识图谱中注入医学知识，然后利用大型语言模型生成大规模合成训练数据。DR.EHR在CliniQ基准测试中超越了现有所有密集检索器，实现了最先进的性能，并在复杂的语义匹配和自然语言问答任务中展现出强大的泛化能力和优越性。

> **摘要翻译:** 电子健康记录（EHR）在临床实践中至关重要，但其检索仍然是一个挑战，主要原因在于语义鸿沟问题。密集检索的最新进展提供了有前景的解决方案，但现有模型，无论是通用领域还是生物医学领域，都因医学知识不足或训练语料不匹配而表现不佳。本文介绍了DR.EHR，一系列专门为EHR检索定制的密集检索模型。我们提出了一个两阶段训练流程，利用MIMIC-IV出院总结来解决对大量医学知识和大规模训练数据的需求。第一阶段涉及医学实体提取和来自生物医学知识图谱的知识注入，而第二阶段则采用大型语言模型生成多样化的训练数据。我们训练了DR.EHR的两个变体，分别有1.1亿和70亿参数。在CliniQ基准测试中评估，我们的模型显著优于所有现有密集检索器，取得了最先进的成果。详细分析证实了我们的模型在各种匹配和查询类型上的优越性，特别是在具有挑战性的语义匹配（如含义和缩写）方面。消融研究验证了每个管道组件的有效性，EHR QA数据集上的补充实验证明了模型在自然语言问题（包括带有多个实体的复杂问题）上的泛化能力。这项工作显著推进了EHR检索，为临床应用提供了强大的解决方案。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [505] [CityHood: An Explainable Travel Recommender System for Cities and Neighborhoods](https://arxiv.org/abs/2507.18778)
> *CityHood：一个针对城市和社区的可解释旅行推荐系统*

*Gustavo H Santos, Myriam Delgado, Thiago H Silva* | **Category: cs.IR, cs.SI** | **Updated: 2025-07-24**

**Keywords:** 旅行推荐系统, 可解释性, 兴趣建模, 多尺度分析, LIME

**Comment:** Accepted at ASONAM'25

> **TL;DR:** CityHood是一个交互式、可解释的旅行推荐系统，它利用大规模谷歌地点评论和多维度指标，在城市和社区层面为用户提供个性化推荐，并通过LIME和自然语言解释提供透明的推荐理由。

**AI_Comments:** CityHood的创新之处在于其将多尺度分析（城市和社区层面）、丰富的用户兴趣建模（结合多元指标）以及关键的可解释性（LIME和自然语言解释）整合到一个面向用户的旅行推荐系统中。这不仅提升了推荐的准确性和个性化，更重要的是增强了用户的信任度和理解，解决了传统推荐系统“黑箱”问题，具有重要的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在弥合基于位置的推荐系统中的空白，通过结合兴趣建模、多尺度分析和可解释性来提供用户友好的系统。

**Method:** CityHood系统通过利用大规模谷歌地点评论，并结合地理、社会人口、政治和文化指标来建模用户兴趣。它在城市（核心统计区 - CBSA）和社区（邮政编码）层面提供个性化推荐，并采用可解释技术（LIME）和自然语言解释来支持推荐理由。用户可以通过可视化界面探索推荐并检查每个建议背后的推理。

**Result:** 演示展示了空间相似性、文化契合度和兴趣理解如何被用于使旅行推荐变得透明和吸引人。

**Conclusion:** 这项工作通过在一个面向用户的系统中结合兴趣建模、多尺度分析和可解释性，弥补了基于位置的推荐领域的空白。

> **ai_Abstract:** CityHood是一个创新的交互式旅行推荐系统，它能够根据用户的兴趣，在城市和社区两个层面提供个性化且可解释的推荐。该系统通过整合大规模谷歌地点评论以及地理、社会人口、政治和文化等多元指标来理解用户兴趣。它利用LIME技术和自然语言解释，确保推荐过程的透明度，并允许用户通过直观的界面深入了解推荐背后的逻辑。这项工作通过整合兴趣建模、多尺度分析和可解释性，有效填补了现有位置推荐系统中的不足。

> **摘要翻译:** 我们提出了CityHood，一个交互式、可解释的推荐系统，它根据用户的兴趣区域推荐城市和社区。该系统利用大规模谷歌地点评论，并结合地理、社会人口、政治和文化指标来建模用户兴趣。它在城市（核心统计区 - CBSA）和社区（邮政编码）层面提供个性化推荐，并由可解释技术（LIME）和自然语言解释支持。用户可以根据他们陈述的偏好探索推荐，并通过可视化界面检查每个建议背后的推理。该演示说明了空间相似性、文化契合度和兴趣理解如何被用于使旅行推荐变得透明和吸引人。这项工作通过在一个面向用户的系统中结合一种兴趣建模、多尺度分析和可解释性，弥补了基于位置的推荐领域的空白。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [542] [Semantic IDs for Music Recommendation](https://arxiv.org/abs/2507.18800)
> *音乐推荐的语义ID*

*M. Jeffrey Mei, Florian Henkel, Samuel E. Sandberg, Oliver Bembom, Andreas F. Ehmann* | **Category: cs.IR, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 音乐推荐, 语义ID, 推荐系统, 共享嵌入, 模型大小

**Comment:** RecSys 2025 Industry Track

> **TL;DR:** 使用共享的基于内容的特征（语义ID）改进音乐推荐系统的准确性、多样性并减小模型大小。

**AI_Comments:** 该论文的创新点在于提出了“语义ID”的概念，通过共享内容特征来替代传统的独立项目嵌入，解决了推荐系统模型参数量过大的问题。这不仅降低了模型的存储和计算成本，还提升了推荐的准确性和多样性，并通过实际的在线A/B测试验证了其在生产环境中的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 训练推荐系统通常需要为每个项目学习独特的嵌入，这会占用模型大部分可训练参数，导致模型笨重。

**Method:** 使用共享的基于内容的特征（“语义ID”）来代替为每个项目学习独特的嵌入。

**Result:** 在两个音乐推荐数据集上，包括一个音乐流媒体服务的在线A/B测试中，显示了使用语义ID在提高推荐准确性和多样性、同时减小模型大小方面的益处。

**Conclusion:** 使用语义ID是一种有效的方法，可以使推荐系统更轻量级，并提高性能。

> **ai_Abstract:** 本文提出使用共享的基于内容的特征（“语义ID”）来优化音乐推荐系统。与为每个项目学习独特嵌入的传统方法相比，语义ID能显著减少模型参数量和内存占用，从而实现更轻量级的模型，并允许增加模型复杂性。实验结果表明，该方法在提高推荐准确性和多样性、同时减小模型大小方面具有显著优势，并通过在线A/B测试得到了验证。

> **摘要翻译:** 训练用于下一项推荐的推荐系统通常需要为每个项目学习独特的嵌入，这可能会占用模型大部分可训练参数。共享嵌入，例如使用内容信息，可以减少内存中需要存储的不同嵌入的数量。这使得模型更轻量级；相应地，由于内存中需要存储的嵌入更少，模型复杂性可以增加。我们展示了在两个音乐推荐数据集上，包括一个音乐流媒体服务的在线A/B测试中，使用共享的基于内容的特征（“语义ID”）在提高推荐准确性和多样性、同时减小模型大小方面的益处。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [578] [A Comprehensive Review of AI-based Intelligent Tutoring Systems: Applications and Challenges](https://arxiv.org/abs/2507.18882)
> *基于人工智能的智能辅导系统综合综述：应用与挑战*

*Meriem Zerkouk, Miloud Mihoubi, Belkacem Chikhaoui* | **Category: cs.IR, cs.AI, cs.ET** | **Updated: 2025-07-25**

**Keywords:** 智能辅导系统, 人工智能, 系统综述, 教育技术, 应用挑战

**Comment:** Journal of Computers in Education ( 2025 )

> **TL;DR:** 本文对基于人工智能的智能辅导系统（ITS）进行了全面综述，分析了其在实际教育环境中的运作、应用挑战及评估，并提出了未来研究建议。

**AI_Comments:** 这是一篇重要的综述性论文，因为它系统地审视了AI在教育领域应用的关键技术——智能辅导系统。其创新之处在于通过系统文献综述方法，不仅总结了现有应用，更深入剖析了其有效性的复杂性及面临的挑战，尤其是指出了研究方法论上的不足，为未来研究提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于人工智能的智能辅导系统（ITS）具有改变教学的巨大潜力，但其有效性结果不一，因此需要对ITS在实际教育环境中的运作方式以及应用和评估中存在的挑战进行全面理解。

**Method:** 本文采用系统文献综述方法，分析了2010年至2025年间发表的众多合格研究，涵盖了教学策略、自然语言处理、自适应学习、学生建模以及ITS的特定领域应用等领域。

**Result:** 研究结果揭示了ITS有效性的复杂性，突出了其进步与持续存在的挑战。研究还指出，实验设计和数据分析需要更高的科学严谨性。

**Conclusion:** 基于研究发现，本文提出了未来研究的建议和实际应用启示。

> **ai_Abstract:** 本文对基于人工智能的智能辅导系统（ITS）进行了全面系统的文献综述，旨在理解其在真实教育环境中的运作情况，并识别其应用和评估中面临的挑战。研究分析了2010-2025年间的相关文献，涵盖了教学策略、NLP、自适应学习等多个方面。结果显示ITS的有效性复杂多样，既有进展也存在挑战，并强调了实验设计和数据分析需更严谨。文章最后提出了未来研究方向和实践建议。

> **摘要翻译:** 基于人工智能的智能辅导系统（ITS）在改变教学和学习方面具有巨大潜力。随着ITS的设计、开发和整合到教育环境中的努力持续进行，关于其有效性的结果喜忧参半。本文提供了一项全面综述，以理解ITS在实际教育环境中的运作方式，并识别其应用和评估中相关的挑战。我们采用系统文献综述方法，分析了2010年至2025年间发表的众多合格研究，检查了教学策略、自然语言处理、自适应学习、学生建模以及ITS的特定领域应用等领域。结果揭示了ITS有效性的复杂性，突出了其进步与持续存在的挑战。该研究还指出，实验设计和数据分析需要更高的科学严谨性。基于这些发现，本文提出了未来研究的建议和实际应用启示。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [620] [Agent0: Leveraging LLM Agents to Discover Multi-value Features from Text for Enhanced Recommendations](https://arxiv.org/abs/2507.18993)
> *Agent0：利用LLM代理从文本中发现多值特征以增强推荐*

*Blaž Škrlj, Benoît Guilleminot, Andraž Tori* | **Category: cs.IR, cs.LG** | **Updated: 2025-07-25**

**Keywords:** LLM代理, 特征工程, 推荐系统, 信息提取, 自动化特征发现

**Comment:** Agent4IR, KDD '25

> **TL;DR:** Agent0是一个基于LLM代理的系统，用于自动化从非结构化文本中提取信息和构建特征，以增强推荐系统。

**AI_Comments:** Agent0创新性地将LLM代理应用于推荐系统的特征工程，特别是自动化多值特征的发现，这在传统上是一个耗时且昂贵的环节。其引入的动态反馈循环和自动提示工程调优方法，为LLM在数据中心任务中的应用提供了新的范式，具有重要的实践意义。该研究解决了推荐系统开发中的核心挑战之一，即有效且经济地获取高质量特征。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）及其代理框架在自动化信息提取方面取得了显著进展，但其在数据中心研究中的应用仍未充分利用。分类特征对大规模推荐系统至关重要，但获取成本高昂。当前推荐系统开发中最具挑战性的阶段之一是自动化特征发现。

**Method:** 本文提出了Agent0，一个由LLM驱动的、基于代理的系统，旨在自动化从原始非结构化文本中进行信息提取和特征构建。Agent0协调一组相互作用的LLM代理，以自动识别对后续任务（如模型或AutoML管道）最有价值的文本方面。Agent0还提供了一种自动化的提示工程调优方法，该方法利用来自预言机的动态反馈循环。

**Result:** 研究结果表明，这种闭环方法对于自动化特征发现既实用又有效。

**Conclusion:** Agent0系统通过利用LLM代理，成功实现了从文本中自动化发现和构建多值特征，有效解决了推荐系统开发中特征发现的挑战。

> **ai_Abstract:** Agent0是一个基于LLM代理的系统，旨在自动化从非结构化文本中提取信息并构建多值特征，以提升推荐系统性能。该系统通过协调LLM代理识别文本中的关键方面，并利用动态反馈循环进行自动提示工程调优。研究表明，这种闭环方法在自动化特征发现方面实用且有效，解决了推荐系统开发中的一个主要挑战。

> **摘要翻译:** 大型语言模型（LLMs）及其相关的基于代理的框架显著推动了自动化信息提取，这是现代推荐系统的一个关键组成部分。虽然这些多任务框架广泛应用于代码生成，但它们在以数据为中心的研究中的应用仍未充分挖掘。本文提出了Agent0，一个由LLM驱动的、基于代理的系统，旨在自动化从原始非结构化文本中进行信息提取和特征构建。分类特征对于大规模推荐系统至关重要，但通常获取成本高昂。Agent0协调一组相互作用的LLM代理，以自动识别对后续任务（如模型或AutoML管道）最有价值的文本方面。除了其特征工程能力之外，Agent0还提供了一种自动化的提示工程调优方法，该方法利用来自预言机的动态反馈循环。我们的研究结果表明，这种闭环方法对于自动化特征发现既实用又有效，而特征发现被认为是当前推荐系统开发中最具挑战性的阶段之一。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [662] [SelfRACG: Enabling LLMs to Self-Express and Retrieve for Code Generation](https://arxiv.org/abs/2507.19033)
> *SelfRACG：使大型语言模型能够自表达和检索以进行代码生成*

*Qian Dong, Jia Chen, Qingyao Ai, Hongning Wang, Haitao Li, Yi Wu, Yao Hu, Yiqun Liu, Shaoping Ma* | **Category: cs.IR** | **Updated: 2025-07-25**

**Keywords:** SelfRACG, 代码生成, LLM, 检索增强, 信息需求

**Comment:** Tsinghua&Xiaohongshu

> **TL;DR:** SelfRACG是一种新的代码生成范式，它使LLM能够自表达其信息需求，从而更好地检索外部知识并提高代码生成性能。

**AI_Comments:** SelfRACG的创新之处在于将LLM的信息需求表达能力融入检索过程，解决了传统RACG中外部检索模块无法准确捕捉LLM内部需求的问题。这使得检索到的知识与LLM的生成意图更加契合，从而显著提升了代码生成质量。该方法为未来RACG的研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有的检索增强代码生成（RACG）方法在使用外部检索模块时，即使是连续的代码片段，内容也常因逻辑进展而发散，导致内容鸿沟。这种鸿沟削弱了当前RACG方法的性能，因为基于内容匹配的外部检索模块无法推断LLM生成下一个代码片段所需的特定信息。

**Method:** 我们提出了SelfRACG，这是一种使大型语言模型（LLM）能够自表达其信息需求以增强RACG的新范式。具体来说，SelfRACG包含一个信息需求表达模块和一种两阶段信息需求引导的训练策略，这鼓励LLM表达其信息需求。

**Result:** 大量实验表明，SelfRACG能够检索与LLM自身信息需求更一致的外部知识，从而比普通RACG获得更优越的生成性能。

**Conclusion:** SelfRACG通过使LLM自表达信息需求，有效解决了现有RACG方法中的内容鸿沟问题，显著提高了代码生成性能。

> **ai_Abstract:** 本文提出了一种名为SelfRACG的新型检索增强代码生成（RACG）范式，旨在解决现有RACG方法中因内容鸿沟导致的问题。传统方法依赖外部检索模块，但无法准确推断LLM在生成代码时所需的信息。SelfRACG通过引入信息需求表达模块和两阶段训练策略，使LLM能够主动表达其信息需求，从而检索到更匹配的外部知识。实验证明，SelfRACG在代码生成性能上优于传统的RACG方法。

> **摘要翻译:** 现有检索增强代码生成（RACG）方法通常使用外部检索模块来获取语义相似的代码片段，用于生成后续片段。然而，即使是连续的代码片段，内容也常因逻辑进展而发散，导致内容鸿沟。这种鸿沟削弱了当前RACG方法的性能，因为基于内容匹配的外部检索模块无法推断LLM生成下一个代码片段所需的特定信息需求。因此，我们提出了SelfRACG，这是一种新颖的范式，使大型语言模型（LLM）能够自表达其信息需求以增强RACG。具体来说，SelfRACG包含一个信息需求表达模块和一种两阶段信息需求引导的训练策略，这鼓励LLM表达其信息需求。大量实验表明，SelfRACG能够检索与LLM自身信息需求更一致的外部知识，从而比普通RACG获得更优越的生成性能。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [690] [VERIRAG: Healthcare Claim Verification via Statistical Audit in Retrieval-Augmented Generation](https://arxiv.org/abs/2507.17948)
> *VERIRAG：通过检索增强生成中的统计审计进行医疗索赔验证*

*Shubham Mohole, Hongjun Choi, Shusen Liu, Christine Klymko, Shashank Kushwaha, Derek Shi, Wesam Sakla, Sainyam Galhotra, Ruben Glatt* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 检索增强生成, 医疗索赔验证, 统计审计, 证据质量, 科学严谨性

**Comment:** 

> **TL;DR:** VERIRAG是一个解决检索增强生成（RAG）系统无法评估证据科学质量问题的框架。它引入了Veritable清单、Hard-to-Vary（HV）分数和动态接受阈值，以根据证据质量和主张的非凡程度来验证医疗索赔。在四个数据集上，VERIRAG的表现优于所有基线，F1分数提高了10到14个点。

**AI_Comments:** VERIRAG的创新之处在于它为RAG系统引入了对证据科学质量的评估机制，解决了现有系统“方法论盲点”的关键问题。通过结合多维度评估（Veritable）、量化证据强度（HV Score）和动态调整验证标准（Dynamic Acceptance Threshold），该框架显著提升了RAG在医疗索赔验证中的可靠性和准确性。这项工作对于提高临床决策支持系统的信任度和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的检索增强生成（RAG）系统在临床决策支持中日益普及，但它们无法评估所检索证据的科学质量，将缺乏科学严谨性甚至被撤回的论文与严谨的研究等同对待。为了解决这一挑战，本研究旨在开发一个能够验证医疗索赔并评估证据质量的框架。

**Method:** 本研究提出了VERIRAG框架，它包含三个主要组成部分：(i) Veritable，一个11点清单，用于评估每个来源的方法学严谨性，包括数据完整性和统计有效性；(ii) Hard-to-Vary（HV）分数，一个定量聚合器，根据证据的质量和多样性对其进行加权；以及(iii) 动态接受阈值，根据主张的非凡程度校准所需的证据。

**Result:** VERIRAG方法在四个数据集（包括撤回、冲突、综合和已确定的科学语料库）上始终优于所有基线。它实现了0.53到0.65的绝对F1分数，与每个相应数据集中次优方法相比，F1分数提高了10到14个点。

**Conclusion:** VERIRAG框架通过引入评估证据科学质量和主张非凡程度的机制，成功解决了检索增强生成（RAG）系统在医疗索赔验证中缺乏科学严谨性评估的问题，并在多个数据集上显著优于现有方法。

> **ai_Abstract:** 本研究提出了VERIRAG框架，旨在解决检索增强生成（RAG）系统在临床决策中无法评估证据科学质量的问题。VERIRAG通过引入Veritable（一个评估方法学严谨性的11点清单）、Hard-to-Vary（HV）分数（一个根据质量和多样性加权证据的聚合器）以及动态接受阈值（根据主张的非凡程度校准所需证据）来实现医疗索赔的验证。在包含撤回、冲突、综合和已确定的科学语料库的四个数据集上，VERIRAG的表现始终优于所有基线，F1分数绝对值达到0.53至0.65，比次优方法提高了10到14个点，证明了其在验证医疗索赔方面的有效性。

> **摘要翻译:** 检索增强生成（RAG）系统在临床决策支持中日益普及，但它们在方法论上存在盲点——它们检索证据却无法验证其科学质量。一篇声称“异干扰素治疗后抗氧化蛋白减少”的论文和一项严谨的多实验室复制研究将被同等对待，即使前者缺乏科学严谨性甚至已被撤回。为了应对这一挑战，我们引入了VERIRAG，一个具有三项显著贡献的框架：(i) Veritable，一个11点清单，用于评估每个来源的方法学严谨性，包括数据完整性和统计有效性；(ii) Hard-to-Vary（HV）分数，一个定量聚合器，根据证据的质量和多样性对其进行加权；以及(iii) 动态接受阈值，根据主张的非凡程度校准所需的证据。在四个数据集——包括撤回、冲突、综合和已确定的科学语料库——中，VERIRAG方法始终优于所有基线，实现了0.53到0.65的绝对F1分数，与每个相应数据集中次优方法相比，提高了10到14个点。我们将发布重现我们结果所需的所有材料。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [704] [PBiLoss: Popularity-Aware Regularization to Improve Fairness in Graph-Based Recommender Systems](https://arxiv.org/abs/2507.19067)
> *PBiLoss：面向流行度的正则化以改善基于图的推荐系统中的公平性*

*Mohammad Naeimi, Mostafa Haghir Chehreghani* | **Category: cs.IR, cs.AI, cs.NE** | **Updated: 2025-07-25**

**Keywords:** 流行度偏差, 公平性, 图推荐系统, 正则化, PBiLoss

**Comment:** 

> **TL;DR:** PBiLoss是一种新颖的正则化损失函数，通过惩罚模型对流行商品的偏好来减少基于图的推荐系统中的流行度偏差，从而显著提高公平性，同时保持或提高推荐准确性。

**AI_Comments:** PBiLoss的创新性在于将流行度偏差的缓解直接嵌入到损失函数中，通过正则化和新颖的采样策略，提供了一种模型无关的公平性提升方案。其重要性在于解决了推荐系统长期面临的流行度偏差问题，提升了内容的公平曝光和多样性，同时避免了对推荐准确性的负面影响。该方法的可扩展性和实用性使其在实际应用中具有广阔前景。

<details>
  <summary>Details</summary>

**Motivation:** 基于图神经网络的推荐系统易受流行度偏差的影响，即过度推荐流行商品，导致内容多样性降低和公平性受损。

**Method:** 本文提出了PBiLoss，一种基于正则化的损失函数，旨在明确对抗基于图的推荐模型中的流行度偏差。PBiLoss通过惩罚模型对流行商品的倾向来增强传统训练目标，从而鼓励推荐不太流行但可能更个性化的内容。该方法引入了两种采样策略：流行正样本（PopPos）和流行负样本（PopNeg），分别调节训练期间正负流行商品的贡献。此外，还探索了两种区分流行商品的方法：一种基于固定流行度阈值，另一种不设任何阈值，使方法灵活适应。PBiLoss是模型无关的，可无缝集成到LightGCN等最先进的基于图的框架中。

**Result:** 在多个真实世界数据集上的综合实验表明，PBiLoss显著提高了公平性，表现为用户流行度排名相关性（PRU）和商品流行度排名相关性（PRI）的降低，同时保持甚至提升了标准的推荐准确性和排名指标。

**Conclusion:** 这些结果强调了将公平性目标直接嵌入优化过程的有效性，为现代推荐系统中平衡准确性和公平内容曝光提供了一个实用且可扩展的解决方案。

> **ai_Abstract:** PBiLoss是一种新颖的正则化损失函数，旨在解决基于图的推荐系统中的流行度偏差问题。该方法通过惩罚模型对流行商品的偏好，并引入PopPos和PopNeg两种采样策略来调节流行商品在训练中的贡献，从而鼓励推荐多样化的内容。PBiLoss具有模型无关性，可灵活集成到现有框架中。实验证明，PBiLoss在提高公平性的同时，能够保持或提升推荐准确性和排名指标，为平衡推荐系统中的准确性和公平性提供了一个实用且可扩展的解决方案。

> **摘要翻译:** 推荐系统，特别是那些基于图神经网络（GNNs）的系统，在捕获用户-商品交互模式方面取得了显著成功。然而，它们仍然容易受到流行度偏差的影响——即过度推荐流行商品的倾向——导致内容多样性降低和公平性受损。在本文中，我们提出了PBiLoss，一种新颖的基于正则化的损失函数，旨在明确对抗基于图的推荐模型中的流行度偏差。PBiLoss通过惩罚模型对流行商品的倾向来增强传统训练目标，从而鼓励推荐不太流行但可能更个性化的内容。我们引入了两种采样策略：流行正样本（PopPos）和流行负样本（PopNeg），分别调节训练期间正负流行商品的贡献。我们进一步探索了两种区分流行商品的方法：一种基于固定流行度阈值，另一种不设任何阈值，使方法灵活适应。我们提出的方法是模型无关的，可以无缝集成到LightGCN及其变体等最先进的基于图的框架中。在多个真实世界数据集上的综合实验表明，PBiLoss显著提高了公平性，表现为用户流行度排名相关性（PRU）和商品流行度排名相关性（PRI）的降低，同时保持甚至提升了标准的推荐准确性和排名指标。这些结果强调了将公平性目标直接嵌入优化过程的有效性，为现代推荐系统中平衡准确性和公平内容曝光提供了一个实用且可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [717] [Neural Machine Unranking](https://arxiv.org/abs/2408.05330)
> *神经机器去排序*

*Jingrui Hou, Axel Finke, Georgina Cosma* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 神经机器去排序, 机器遗忘, 对比学习, 信息检索, 数据隐私

**Comment:** 

> **TL;DR:** 本文提出了神经信息检索中的机器遗忘问题，即神经机器去排序（NuMuR）任务，并提出了一种名为对比与一致性损失（CoCoL）的双目标框架，以有效实现数据遗忘，同时保持保留数据的性能。

**AI_Comments:** 该论文的创新点在于首次明确提出了神经信息检索领域的机器遗忘问题，即神经机器去排序（NuMuR），并针对该领域特有的挑战（非标准化分数和纠缠数据）提出了定制化的解决方案CoCoL框架。其重要性在于响应了日益增长的数据隐私合规性需求，为神经IR系统中的选择性信息删除提供了有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 神经信息检索（IR）系统中对数据隐私合规性和选择性信息删除的需求日益增长，这促使了神经机器去排序（NuMuR）问题的提出。

**Method:** 本文提出了对比与一致性损失（CoCoL）这一双目标框架来解决现有方法在神经机器去排序（NuMuR）任务中的局限性。CoCoL包含两个部分：1) 对比损失，旨在降低遗忘集上的相关性分数，同时保持纠缠样本的性能；2) 一致性损失，用于保留保留集上的准确性。

**Result:** 在MS MARCO和TREC CAR数据集上，通过四种不同的神经IR模型进行的广泛实验表明，CoCoL在实现显著遗忘的同时，最大限度地减少了保留性能和泛化性能的损失。

**Conclusion:** CoCoL方法比现有技术能更有效、更可控地实现数据删除。

> **ai_Abstract:** 本文针对神经信息检索（IR）中的机器遗忘问题，提出了神经机器去排序（NuMuR）这一新任务。鉴于现有遗忘方法在处理神经排序器输出和纠缠数据场景时的不足，作者提出了一种名为对比与一致性损失（CoCoL）的双目标框架。CoCoL通过结合对比损失（降低遗忘集分数并保持纠缠样本性能）和一致性损失（保持保留集准确性）来解决这些挑战。实验结果表明，CoCoL在实现有效遗忘的同时，能最小化对保留数据和泛化性能的影响，从而实现了比现有技术更有效和可控的数据删除。

> **摘要翻译:** 我们解决了神经信息检索（IR）中的机器遗忘问题，引入了一项名为神经机器去排序（NuMuR）的新任务。这个问题的提出是由于神经IR系统中对数据隐私合规性和选择性信息删除的需求日益增长。现有的任务或模型无关的遗忘方法，主要为分类任务设计，对于NuMuR来说是次优的，原因在于两个核心挑战：（1）神经排序器输出的是未归一化的相关性分数而不是概率分布，这限制了传统师生蒸馏框架的有效性；（2）纠缠数据场景，即查询和文档同时出现在遗忘集和保留集中，可能会降低现有方法的保留性能。为了解决这些问题，我们提出了一种双目标框架：对比与一致性损失（CoCoL）。CoCoL包括：（1）对比损失，用于降低遗忘集上的相关性分数，同时保持纠缠样本的性能，以及（2）一致性损失，用于保持保留集上的准确性。在MS MARCO和TREC CAR数据集上，通过四种不同的神经IR模型进行的广泛实验表明，CoCoL在实现显著遗忘的同时，最大限度地减少了保留性能和泛化性能的损失。我们的方法比现有技术能更有效、更可控地实现数据删除。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [746] [Distilling a Small Utility-Based Passage Selector to Enhance Retrieval-Augmented Generation](https://arxiv.org/abs/2507.19102)
> *蒸馏小型基于效用的段落选择器以增强检索增强生成*

*Hengran Zhang, Keping Bi, Jiafeng Guo, Jiaming Zhang, Shuaiqiang Wang, Dawei Yin, Xueqi Cheng* | **Category: cs.IR, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 检索增强生成, 效用判断, 模型蒸馏, 段落选择, 计算成本

**Comment:** 9 pages, 5 figures

> **TL;DR:** 本文提出了一种将大型语言模型（LLMs）的效用判断能力蒸馏到小型模型中的方法，以降低计算成本并提高检索增强生成（RAG）的答案质量，特别是在处理复杂查询时。

**AI_Comments:** 本文的创新点在于将大型语言模型的效用判断能力蒸馏到小型模型，有效解决了RAG中LLM判断成本高昂的痛点。这种基于效用选择而非传统相关性排序的方法，为复杂查询提供了更灵活、更高效的解决方案，对RAG的实际应用具有重要意义。通过发布数据集标注，也促进了该领域的后续研究。

<details>
  <summary>Details</summary>

**Motivation:** 在检索增强生成（RAG）中，尽管基于效用的检索能带来益处，但使用大型语言模型（LLMs）进行效用判断的计算成本高昂，限制了可评估的段落数量，这对于需要大量信息的复杂查询来说是个问题。

**Method:** 提出了一种将LLM的效用判断能力蒸馏到小型、高效模型的方法。该方法侧重于基于效用的选择而非排序，通过动态选择与特定查询相关的有用段落，无需固定阈值。学生模型通过滑动窗口方法学习教师LLM的伪答案生成和效用判断。使用Qwen3-32B作为教师模型，蒸馏出RankQwen1.7B和UtilityQwen1.7B。

**Result:** 实验表明，基于效用的选择为RAG提供了一种灵活且成本效益高的方法，显著降低了计算成本，同时提高了答案质量。对于复杂问题，基于效用的选择在增强答案生成性能方面比相关性排序更有效。

**Conclusion:** 本文提出的蒸馏方法能够将大型语言模型的效用判断能力转移到小型模型中，为检索增强生成（RAG）提供了一种成本效益高且灵活的解决方案，显著提高了复杂问题的答案生成质量。

> **ai_Abstract:** 本研究提出了一种创新方法，将大型语言模型（LLMs）的效用判断能力蒸馏到小型、高效的模型中，以优化检索增强生成（RAG）系统。针对LLMs进行效用判断的高计算成本问题，研究引入了基于效用而非相关性的动态段落选择机制。通过训练学生模型学习教师LLMs的判断能力，实验证明该方法显著降低了RAG的计算开销，并提高了复杂查询的答案质量。研究成果包括蒸馏出的RankQwen1.7B和UtilityQwen1.7B模型，并强调了基于效用选择在提升答案生成性能方面的优越性。

> **摘要翻译:** 检索增强生成（RAG）通过整合检索到的信息来增强大型语言模型（LLMs）。标准的检索过程优先考虑相关性，侧重于查询和段落之间的话题一致性。相比之下，在RAG中，重点已转向效用，即考虑段落对于生成准确答案的有用性。尽管经验证据表明基于效用的检索在RAG中具有优势，但使用LLMs进行效用判断的高计算成本限制了可评估的段落数量。这种限制对于需要大量信息的复杂查询来说是个问题。为了解决这个问题，我们提出了一种将LLMs的效用判断能力蒸馏到更小、更高效模型中的方法。我们的方法侧重于基于效用的选择而非排序，从而能够根据特定查询动态选择段落，而无需固定的阈值。我们训练学生模型，利用滑动窗口方法，动态选择有用段落，从教师LLMs学习伪答案生成和效用判断。我们的实验表明，基于效用的选择为RAG提供了一种灵活且成本效益高的解决方案，显著降低了计算成本，同时提高了答案质量。我们展示了使用Qwen3-32B作为教师模型进行相关性排序和基于效用选择的蒸馏结果，分别蒸馏到RankQwen1.7B和UtilityQwen1.7B。我们的研究结果表明，对于复杂问题，基于效用的选择在增强答案生成性能方面比相关性排序更有效。我们将发布MS MARCO数据集的相关性排序和基于效用选择的标注，以支持该领域的进一步研究。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [788] [Towards LLM-Enhanced Group Recommender Systems](https://arxiv.org/abs/2507.19283)
> *迈向LLM增强的群组推荐系统*

*Sebastian Lubos, Alexander Felfernig, Thi Ngoc Trang Tran, Viet-Man Le, Damian Garber, Manuel Henrich, Reinhard Willfort, Jeremias Fuchs* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-25**

**Keywords:** 群组推荐系统, 大型语言模型, 决策支持, 群组动态, 推荐系统

**Comment:** 

> **TL;DR:** 本文分析了大型语言模型（LLMs）如何支持群组推荐系统，以提高决策支持质量和适用性，解决群组推荐中存在的复杂性。

**AI_Comments:** 本文探讨了将大型语言模型（LLMs）应用于群组推荐系统这一新兴且具有挑战性的领域。其创新点在于尝试利用LLMs处理群组推荐中特有的复杂性，如群组动态理解和多层次解释生成。此研究对于提升群组决策支持的智能化水平具有重要意义，但也可能面临LLMs在处理特定领域知识和确保推荐公平性方面的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 群组推荐系统相较于单用户推荐系统引入了额外的复杂性，包括理解群组动态、定义有效的决策过程、确保推荐适用于所有成员以及提供群组和个人层面的解释。本文的动机是探索大型语言模型（LLMs）如何支持这些方面，从而提高群组推荐系统的整体决策支持质量和适用性。

**Method:** 本文分析了大型语言模型（LLMs）如何支持群组推荐系统的各个方面，以提高其决策支持质量和适用性。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在群组推荐系统中的应用潜力。群组推荐系统面临多重挑战，如理解群组动态、决策过程、个体适应性及解释生成。研究旨在分析LLMs如何有效应对这些复杂性，进而提升群组推荐的决策支持能力和实际应用价值。

> **摘要翻译:** 与单用户推荐系统不同，群组推荐系统旨在为群组生成和解释推荐。这种面向群组的设置引入了额外的复杂性，因为必须解决在个人环境中不存在的几个因素。这些因素包括理解群组动态（例如，群组内的社会依赖）、定义有效的决策过程、确保推荐适用于所有群组成员，以及提供群组层面的解释和对个人用户的解释。在本文中，我们分析了大型语言模型（LLMs）如何支持这些方面，并帮助提高群组推荐系统的整体决策支持质量和适用性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [822] [Fashion-AlterEval: A Dataset for Improved Evaluation of Conversational Recommendation Systems with Alternative Relevant Items](https://arxiv.org/abs/2507.18017)
> *Fashion-AlterEval：一个用于改进会话推荐系统评估的替代相关物品数据集*

*Maria Vlachou* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 会话推荐系统, 用户模拟器, 数据集, 评估, 替代物品

**Comment:** arXiv admin note: substantial text overlap with arXiv:2401.05783

> **TL;DR:** 现有会话推荐系统（CRS）的用户模拟器存在单目标物品和无限耐心的问题。本文提出了Fashion-AlterEval数据集和两个新的元用户模拟器，通过考虑替代物品和用户耐心变化来改进CRS评估，实验表明这显著影响了现有模型的评估结果，并揭示了现有评估方法低估了系统的有效性。

**AI_Comments:** 该论文通过引入更真实的用户模拟，解决了会话推荐系统（CRS）评估中的一个关键局限性。其创新之处在于考虑了替代相关物品和动态的用户耐心，这超越了简单化的单目标、无限耐心的用户模型。这项工作很重要，因为它提供了一个更准确的评估框架，可能促进开发更稳健、以用户为中心的CRS模型。它强调了现有评估方法可能低估了CRS的真实能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的会话推荐系统（CRS）用户模拟器在离线评估中存在局限性，主要体现在它们只关注单一目标物品以及在大量轮次中表现出无限的耐心。

**Method:** 提出Fashion-AlterEval数据集，通过在现有时尚CRS数据集中添加新的标注，包含人类对替代物品的判断。基于此数据集，提出了两个新颖的元用户模拟器，这些模拟器不仅允许模拟用户表达对替代物品的偏好，还能改变主意和耐心程度。

**Result:** 在Shoes和Fashion IQ数据集以及三个CRS模型上的实验表明，模拟器使用替代物品的知识对现有CRS模型的评估有显著影响。具体来说，现有单一目标评估低估了系统的有效性；当模拟用户被允许考虑替代相关物品时，系统能更快地响应以满足用户需求。

**Conclusion:** 通过引入对替代物品的考虑和更真实的用户行为模拟（如改变主意和耐心程度），可以更准确地评估会话推荐系统，揭示现有评估方法所低估的系统有效性，并促使系统更快地满足用户需求。

> **ai_Abstract:** 本文提出了Fashion-AlterEval数据集和两个新颖的元用户模拟器，旨在解决现有会话推荐系统（CRS）用户模拟器在单一目标物品和无限耐心方面的局限性。Fashion-AlterEval数据集通过在现有时尚CRS数据集中添加标注，包含了人类对替代物品的判断。实验表明，使用这些新的模拟器和替代物品的知识对现有CRS模型的评估有显著影响，揭示了现有单一目标评估低估了系统的有效性，并且当用户被允许考虑替代相关物品时，系统能更快地满足用户需求。

> **摘要翻译:** 在会话推荐系统（CRS）中，用户在每一轮都会对推荐的物品提供反馈，从而使CRS的推荐得到改进。由于需要大量数据，用户模拟器被用于训练和评估。此类用户模拟器根据对单一目标物品的了解来评价当前检索到的物品。然而，在离线设置中使用模拟器进行系统评估受到对单一目标物品的关注以及在大量轮次中其无限耐心的限制。为了克服现有模拟器的这些局限性，我们提出了Fashion-AlterEval，这是一个新的数据集，通过在常见的时尚CRS数据集中添加新的标注，包含了人类对一系列替代物品的判断。因此，我们提出了两个新颖的元用户模拟器，它们利用收集到的判断，不仅允许模拟用户表达他们对其原始目标物品的替代品的偏好，而且还允许他们改变主意和耐心程度。在我们使用Shoes和Fashion IQ作为原始数据集以及三个CRS模型进行的实验中，我们发现模拟器使用替代物品的知识对现有CRS模型的评估可以产生相当大的影响，特别是现有单一目标评估低估了它们的有效性，并且当模拟用户被允许考虑替代相关物品时，系统可以迅速响应以更快地满足用户。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [850] [Neural Corrective Machine Unranking](https://arxiv.org/abs/2411.08562)
> *神经纠正机器去排序*

*Jingrui Hou, Axel Finke, Georgina Cosma* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 机器遗忘, 信息检索, 神经IR, 纠正性去排序, 蒸馏

**Comment:** submitted to Information Sciences

> **TL;DR:** 提出了一种名为CuRD的教师-学生框架，用于在神经信息检索系统中进行纠正性去排序，旨在有效遗忘特定数据并纠正替代文档的排名，同时保持模型性能。

**AI_Comments:** 本文的创新点在于提出了“纠正性去排序”的概念，通过引入替代文档来解决传统机器遗忘在信息检索中可能导致的排名完整性问题和遗忘行为暴露问题。CuRD框架的教师-学生蒸馏方法设计精巧，实现了遗忘、纠正和性能保持的多目标平衡，对于神经IR系统的隐私保护和数据管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的机器遗忘方法应用于神经信息检索系统时，可能损害检索效果或暴露遗忘行为。

**Method:** 提出纠正性去排序，通过整合替代文档来保持排名完整性。设计了一种新颖的教师-学生框架——纠正性去排序蒸馏（CuRD），该框架通过调整模型使遗忘样本的相关性得分模仿低排名样本，并通过微调替代样本的相关性得分来匹配被遗忘样本，同时保持对非遗忘样本的性能。在MS MARCO和TREC CAR数据集上，使用BERTcat、BERTdot、ColBERT、PARADE四种模型进行评估。

**Result:** CuRD在遗忘和纠正方面优于七种最先进的基线方法，同时保持了模型的保留和泛化能力，遗忘集大小介于训练数据集的1%至20%之间。

**Conclusion:** CuRD框架有效解决了神经信息检索中的机器去排序问题，实现了高效的遗忘和纠正，并维持了模型性能。

> **ai_Abstract:** 本文针对神经信息检索（IR）系统中机器遗忘可能损害性能或暴露遗忘行为的问题，提出了“纠正性去排序”概念，并引入了新颖的教师-学生框架CuRD。CuRD通过调整模型使遗忘样本的相关性得分模仿低排名样本，微调替代样本以匹配被遗忘样本的得分，同时保持非遗忘样本的性能。实验证明，CuRD在四种神经IR模型和两个数据集上，在遗忘和纠正方面均优于现有基线，并有效保持了模型性能。

> **摘要翻译:** 神经信息检索（IR）系统中的机器遗忘要求在删除特定数据的同时保持模型性能。将现有机器遗忘方法应用于IR可能会损害检索效率，或由于从呈现给用户的检索结果中删除特定项目而无意中暴露遗忘行为。我们形式化了纠正性去排序，它通过整合替代文档来保持排名完整性，从而扩展了（神经）IR语境下的机器遗忘，并为此任务提出了一种新颖的教师-学生框架——纠正性去排序蒸馏（CuRD）。CuRD (1) 通过调整（训练好的）神经IR模型来促进遗忘，使其对要遗忘样本的输出相关性得分模仿低排名、不可检索样本的得分；(2) 通过微调替代样本的相关性得分使其与相应要遗忘样本的得分紧密匹配来启用纠正；(3) 旨在保持对非遗忘目标样本的性能。我们在MS MARCO和TREC CAR数据集上，使用四种神经IR模型（BERTcat、BERTdot、ColBERT、PARADE）评估了CuRD。对训练数据集中1%至20%的遗忘集大小进行的实验表明，CuRD在遗忘和纠正方面优于七种最先进的基线方法，同时保持了模型的保留和泛化能力。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [870] [Let It Go? Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization](https://arxiv.org/abs/2507.19473)
> *放手吧？不尽然：通过基于内容的初始化解决序列推荐中的物品冷启动问题*

*Anton Pembek, Artem Fatkulin, Anton Klenitskiy, Alexey Vasilev* | **Category: cs.IR, cs.AI, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 物品冷启动, 序列推荐, 内容基初始化, 可训练增量, 嵌入适应

**Comment:** 

> **TL;DR:** 该论文提出了一种通过在冻结内容嵌入中引入一个小的可训练增量来解决序列推荐中物品冷启动问题的新方法。

**AI_Comments:** 这项工作的创新之处在于，它提出了一种巧妙且有效的方法来调整预训练的内容嵌入。它避免了完全冻结或完全微调的二元选择，而是引入了“小的可训练增量”这一中间地带。这种细致的方法对于平衡模型的适应性和表示的稳定性至关重要，尤其对于冷启动物品。该方法看起来实用且具有普适性。

<details>
  <summary>Details</summary>

**Motivation:** 许多序列推荐系统存在物品冷启动问题，即互动较少或没有互动的新物品无法被模型有效利用。尽管基于内容的方法常用于此，但直接使用冻结的内容嵌入会导致次优性能，而过度微调则会损害冷启动物品的性能，因为物品表示可能偏离其原始结构。

**Method:** 作者提出了一种新方法，即在冻结的内容嵌入中引入一个小的可训练增量（delta）。这使得物品表示能够在适应推荐任务的同时，不偏离其原始语义结构太远。

**Result:** 该方法在多个数据集和模态上（包括带有文本描述的电子商务数据集和带有基于音频表示的音乐数据集）均显示出持续的改进。

**Conclusion:** 该论文提出的方法通过允许物品表示在适应任务的同时保持其原始语义结构，有效地解决了序列推荐中的物品冷启动问题，并在不同数据集上取得了持续的性能提升。

> **ai_Abstract:** 本论文旨在解决序列推荐系统中的物品冷启动问题。研究指出，基于内容的初始化虽常用，但完全冻结内容嵌入会导致次优性能，而过度微调则会损害冷启动物品。为此，论文提出了一种新颖方法：在冻结的内容嵌入中引入一个小的可训练增量。这种方法使得物品表示能够在适应推荐任务的同时，保持其原始语义结构，并在多个数据集和模态上展示了持续的性能改进。

> **摘要翻译:** 许多序列推荐系统都面临冷启动问题，即由于缺乏训练好的嵌入，互动较少或没有互动的物品无法被模型有效利用。利用物品元数据的内容基方法在这种情况下常被使用。一种可能的方法是使用从文本描述等内容特征派生出的嵌入作为模型嵌入的初始化。然而，直接使用冻结的内容嵌入往往会导致次优性能，因为它们可能无法完全适应推荐任务。另一方面，对这些嵌入进行微调会降低冷启动物品的性能，因为物品表示在训练后可能会偏离其原始结构。我们提出了一种新颖的方法来解决这一局限性。我们不是完全冻结内容嵌入或对其进行广泛微调，而是在冻结嵌入中引入一个小的可训练的增量，使模型能够调整物品表示，同时又不让它们偏离其原始语义结构太远。这种方法在多个数据集和模态上表现出持续的改进，包括带有文本描述的电子商务数据集和带有基于音频表示的音乐数据集。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [873] [Injecting External Knowledge into the Reasoning Process Enhances Retrieval-Augmented Generation](https://arxiv.org/abs/2507.19333)
> *将外部知识注入推理过程增强检索增强生成*

*Minghao Tang, Shiyu Ni, Jiafeng Guo, Keping Bi* | **Category: cs.IR, cs.CL** | **Updated: 2025-07-25**

**Keywords:** 检索增强生成, 大型语言模型, 噪声段落, 鲁棒性, 推理过程

**Comment:** 

> **TL;DR:** 通过将检索到的段落明确地整合到大型语言模型的推理过程中，Passage Injection 方法显著提高了检索增强生成（RAG）的性能和对噪声的鲁棒性。

**AI_Comments:** 该论文的创新点在于将检索到的段落显式地融入到大型语言模型的“推理过程”中，而非仅仅作为上下文。这种方法巧妙地利用了LLMs固有的推理和自我反思能力来识别和抵制噪声信息，从而显著提高了RAG系统的鲁棒性和可靠性。针对噪声段落的关注及其解决方案在实际应用中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 检索增强生成（RAG）的有效性常因存在噪声（即低质量）检索段落而受到损害。提高大型语言模型（LLMs）对这种噪声的鲁棒性对于提升RAG系统的可靠性至关重要。

**Method:** 本文提出了一种名为“Passage Injection”的简单而有效的方法，它将检索到的段落明确地整合到大型语言模型的推理过程中，旨在增强模型识别和抵制噪声段落的能力。该方法在通用RAG设置下使用BM25作为检索器进行了验证。

**Result:** 在四个推理增强型大型语言模型和四个事实问答数据集上的实验表明，Passage Injection显著提高了整体RAG性能。对两种噪声检索设置（随机噪声和反事实噪声）的进一步分析显示，Passage Injection持续提高了鲁棒性。对照实验证实，Passage Injection也能有效利用有益的段落。

**Conclusion:** 研究结果表明，将段落整合到大型语言模型的推理过程中是构建更鲁棒的RAG系统的一个有前景的方向。

> **ai_Abstract:** 检索增强生成（RAG）系统常受噪声检索段落影响。为解决此问题，本文提出Passage Injection方法，该方法将检索到的段落显式地融入大型语言模型（LLMs）的推理过程，以增强模型识别和抵抗噪声的能力。实验结果显示，Passage Injection显著提升了RAG的整体性能，并在存在随机噪声和反事实噪声的情况下持续提高了系统的鲁棒性，同时也能有效利用有用信息。这表明将段落整合到LLMs的推理过程是构建更稳健RAG系统的一个有前景的方向。

> **摘要翻译:** 检索增强生成（RAG）已被广泛采用，用于通过外部知识增强大型语言模型（LLMs）以处理知识密集型任务。然而，其有效性常因存在噪声（即低质量）检索段落而受到损害。增强LLMs对这种噪声的鲁棒性对于提高RAG系统的可靠性至关重要。最近的进展使LLMs具备了强大的推理和自我反思能力，使其能够识别并纠正其推理过程中的错误。受此能力的启发，我们提出了Passage Injection——一种简单而有效的方法，它明确地将检索到的段落整合到LLMs的推理过程中，旨在增强模型识别和抵制噪声段落的能力。我们在通用RAG设置下使用BM25作为检索器验证了Passage Injection。在四个推理增强型LLMs和四个事实问答数据集上的实验表明，Passage Injection显著提高了整体RAG性能。对两种噪声检索设置——随机噪声（模型获得不相关段落）和反事实噪声（模型获得误导性段落）——的进一步分析显示，Passage Injection持续提高了鲁棒性。对照实验证实，Passage Injection也能有效利用有益的段落。这些发现表明，将段落整合到LLMs的推理过程中是构建更鲁棒的RAG系统的一个有前景的方向。代码可在[此处](https://github.com/mh-tang/Passage-Injection)找到。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [338] [Neuromorphic Computing: A Theoretical Framework for Time, Space, and Energy Scaling](https://arxiv.org/abs/2507.17886)
> *神经形态计算：时间、空间和能量扩展的理论框架*

*James B Aimone* | **Category: cs.NE, cs.AR, cs.DC** | **Updated: 2025-07-23**

**Keywords:** 神经形态计算, 能量扩展, 时间空间扩展, 稀疏算法, 迭代优化

**Comment:** True pre-print; to be submitted at future date

> **TL;DR:** 神经形态计算在时间空间扩展上与传统系统相当，但在能量扩展上不同，更适合稀疏和迭代算法。

**AI_Comments:** 这篇论文通过提供一个理论框架来阐明神经形态计算的计算价值，这是非常有价值的。它清晰地指出了神经形态计算在能量效率方面的独特优势以及其最适合的算法类型，有助于指导未来神经形态硬件和软件的开发方向。

<details>
  <summary>Details</summary>

**Motivation:** 神经形态计算被视为传统冯诺依曼架构的低功耗替代品，但其计算价值难以精确定义。

**Method:** 本文解释了神经形态计算如何被视为通用和可编程的，并展示了其在时间、空间和能量方面的扩展性，并与传统系统进行了比较。

**Result:** 神经形态计算的时间和空间扩展与理论上的无限处理器传统系统相当，但能量扩展显著不同。传统系统的能量与绝对算法工作量成比例，而神经形态系统的能量与算法状态的导数成比例。神经形态计算特别适用于可扩展和稀疏算法（如迭代优化和大规模采样），而传统多核系统（如GPU）则针对密集数值应用进行了优化。

**Conclusion:** 神经形态计算具有独特的特性，使其非常适合特定类型的算法，与传统的冯诺依曼架构相比，提供了不同的计算价值主张。

> **ai_Abstract:** 本文提出了一个理论框架，探讨了神经形态计算（NMC）的时间、空间和能量扩展。研究指出，NMC 在时间空间扩展方面与传统系统相似，但在能量扩展上表现出根本性差异，其能量消耗与算法状态的导数相关。因此，NMC 被证明更适合处理可扩展和稀疏的算法，如迭代优化和大规模采样，而与传统为密集数值应用优化的多核系统形成互补。

> **摘要翻译:** 神经形态计算 (NMC) 越来越被视为传统冯诺依曼架构（如中央处理器 (CPU) 和图形处理器 (GPU)）的低功耗替代方案，然而其计算价值主张一直难以精确定义。在此，我们解释了尽管 NMC 与传统存储程序架构有很大不同，但应将其视为通用且可编程的。我们表明，NMC 的时间空间扩展与理论上无限处理器传统系统相当，但能量扩展显著不同。具体而言，传统系统的能量与绝对算法工作量成比例，而神经形态系统的能量与算法状态的导数成比例。NMC 架构的独特特性使其非常适合与传统多核系统（如已针对密集数值应用（例如线性代数）进行优化的 GPU）不同类别的算法。相比之下，NMC 的独特特性使其非常适合可扩展和稀疏算法，其活动与目标函数成比例，例如迭代优化和大规模采样（例如蒙特卡洛）。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [444] [Explicit Sign-Magnitude Encoders Enable Power-Efficient Multipliers](https://arxiv.org/abs/2507.18179)
> *显式符号-幅度编码器实现高能效乘法器*

*Felix Arnold, Maxence Bouvier, Ryan Amaudruz, Renzo Andri, Lukas Cavigelli* | **Category: cs.NE, cs.AR, cs.PF** | **Updated: 2025-07-24**

**Keywords:** 能效, 乘法器, 符号-幅度编码, AI工作负载, 开关活动量

**Comment:** Accepted and presented at the 34th International Workshop on Logic &
  Synthesis June 2025

> **TL;DR:** 通过将定点乘法器分解为符号-幅度编码器和乘法模块，并分别优化，本方法显著降低了AI工作负载中常见输入值的功耗，最高可达33%的开关活动量减少。

**AI_Comments:** 本文提出了一种新颖且实用的方法来优化定点乘法器的功耗，尤其针对AI应用场景。其创新点在于将乘法器分解并利用符号-幅度编码的固有优势，同时通过独立优化和考虑兼容性来确保实际应用的可行性。在不牺牲逻辑等效性的前提下实现显著的功耗降低，这一点非常重要。进一步的优化空间也通过设计空间探索被证明，显示了该方法的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在最大化定点乘法器单元的能效，尤其针对AI工作负载中常见的围绕零点分布的输入值，以实现显著的功耗节省。

**Method:** 该方法通过将定点乘法器分解为子组件：首先，一个编码器块将操作数从补码转换为符号-幅度表示；然后，一个乘法器模块执行计算并将结果输出为原始格式。为确保计算格式不变，这两个组件被单独综合和优化。此外，还采用了基于开关活动驱动的设计空间探索的综合优化方法。

**Result:** 在标准偏差为3.0的正常分布输入流下，4位乘法器设计在综合后仿真显示，与不分解的综合相比，开关活动量降低了12.9%。在放宽合规性并略微缩小输入范围（-7到+7）的情况下，开关活动量减少可达33%。此外，基于开关活动驱动的设计空间探索的综合优化方法可进一步提高5-10%的能效。

**Conclusion:** 该方法通过使用显式符号-幅度编码器和分解优化，在保持逻辑等效性的前提下，显著提高了定点乘法器的能效，特别是在AI工作负载中常见的输入条件下。结合开关活动驱动的优化方法，能效还能进一步提升，确保了在生产就绪系统中的兼容性。

> **ai_Abstract:** 本研究提出了一种提高定点乘法器能效的新方法。通过将乘法器分解为补码到符号-幅度编码器和乘法模块，并对二者进行独立综合和优化，该方法能有效利用符号-幅度编码的低功耗特性。实验结果表明，在AI工作负载常见的输入条件下，该方法可使开关活动量显著降低，最高达33%，同时保持电路的逻辑等效性，确保了在实际系统中的兼容性。此外，结合开关活动驱动的综合优化可进一步提升能效。

> **摘要翻译:** 这项工作提出了一种通过将定点乘法器单元分解为子组件来最大化其能效的方法。首先，一个编码器块将操作数从补码转换为符号-幅度表示，然后一个乘法器模块执行计算并将结果以原始格式输出。这使得乘法运算能够利用符号-幅度编码的能效优势。为了确保计算格式不被改变，这两个组件被单独综合和优化。我们的方法对AI工作负载中常见的围绕零点居中的输入值带来了显著的功耗节省。在标准偏差为3.0的正常分布输入流的实际输入条件下，4位乘法器设计的综合后仿真显示，与不分解的综合相比，开关活动量降低了高达12.9%。这些收益是在确保符合任何生产就绪系统要求的前提下实现的，因为整体电路保持逻辑等效。在解除合规性限制并略微缩小输入范围（-7到+7）的情况下，开关活动量减少可达33%。此外，我们证明了基于开关活动驱动的设计空间探索的综合优化方法，与功耗无关的方法相比，可以在能效方面进一步提高5-10%。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [584] [Game-Theoretic Gradient Control for Robust Neural Network Training](https://arxiv.org/abs/2507.19143)
> *鲁棒神经网络训练的博弈论梯度控制*

*Maria Zaitseva, Ivan Tomilov, Natalia Gusarova* | **Category: cs.NE, cs.LG, 68T07, I.2.6** | **Updated: 2025-07-25**

**Keywords:** 神经网络, 鲁棒性, 梯度dropout, 博弈论, 噪声

**Comment:** 19 pages, 6 figures

> **TL;DR:** 本文通过引入“梯度dropout”和目标变量噪声，在博弈论框架下提升前馈神经网络的噪声鲁棒性，实验结果显示在特定条件下效果显著。

**AI_Comments:** 本文的创新之处在于将反向传播过程视为多智能体博弈，并在此框架下提出“梯度dropout”以增强神经网络的鲁棒性，同时结合了目标变量噪声。这种将博弈论引入神经网络训练的方法为理解和改进神经网络的复杂行为提供了新的理论视角。其重要性在于提供了一种可能更有效且不改变网络架构的正则化手段。然而，方法的有效性高度依赖于数据集和超参数的自适应调整，这可能增加了实际应用的复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 前馈神经网络(FFNNs)易受输入噪声影响，导致预测性能下降。现有正则化方法常改变网络结构或忽略神经元交互。

**Method:** 将反向传播解释为多智能体博弈，提出“梯度dropout”选择性地使隐藏层神经元梯度归零（概率1-p），同时保持前向传播活跃。此外，还对目标变量施加白噪声或稳定分布噪声。整个方法构建在组合博弈论框架内。

**Result:** 在十个不同表格数据集上进行实验，结果显示影响各异：鲁棒性和准确性可能提高或降低，取决于数据集和超参数。值得注意的是，在回归任务中，梯度dropout (p=0.9)结合稳定分布目标噪声显著提高了输入噪声鲁棒性，表现为更平坦的MSE曲线和更稳定的SMAPE值。

**Conclusion:** 该方法具有潜力，强调了自适应参数调整的关键作用，并为在博弈论框架内将神经网络分析为展现涌现行为的复杂自适应系统开辟了新途径。

> **ai_Abstract:** 本研究提出了一种基于博弈论的梯度控制方法，旨在提升前馈神经网络的噪声鲁棒性。通过引入“梯度dropout”在反向传播中选择性地使梯度归零，并结合对目标变量施加噪声，该方法在组合博弈论框架下运作。实验结果表明，在回归任务中，特定参数设置下的梯度dropout与稳定分布目标噪声结合能显著提高输入噪声鲁棒性，为神经网络的鲁棒性训练提供了新的视角。

> **摘要翻译:** 前馈神经网络（FFNNs）容易受到输入噪声的影响，从而降低预测性能。现有的正则化方法，如dropout，通常会改变网络架构或忽视神经元之间的交互。本研究旨在通过修改反向传播（将其解释为多智能体博弈）并探索受控的目标变量噪声来增强FFNN的噪声鲁棒性。我们的“梯度dropout”在反向传播过程中以1-p的概率选择性地使隐藏层神经元梯度归零，同时保持前向传播活跃。这被构建在组合博弈论的框架内。此外，目标变量受到白噪声或稳定分布的扰动。在十个不同的表格数据集上进行的实验显示出不同的影响：鲁棒性和准确性可能提高或降低，这取决于数据集和超参数。值得注意的是，在回归任务中，梯度dropout（p = 0.9）结合稳定分布目标噪声显著提高了输入噪声鲁棒性，表现为更平坦的MSE曲线和更稳定的SMAPE值。这些结果突出了该方法的潜力，强调了自适应参数调整的关键作用，并为在博弈论框架内将神经网络分析为展现涌现行为的复杂自适应系统开辟了新途径。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [710] [Enhancing Generalization of Spiking Neural Networks Through Temporal Regularization](https://arxiv.org/abs/2506.19256)
> *通过时间正则化增强脉冲神经网络的泛化能力*

*Boxuan Zhang, Zhen Xu, Kuan Tao* | **Category: cs.NE, cs.AI** | **Updated: 2025-07-25**

**Keywords:** 脉冲神经网络, 时间正则化, 泛化能力, 过拟合, Fisher信息

**Comment:** Code is available at https://anonymous.4open.science/r/TRT-7FBFUYT4E

> **TL;DR:** 本文提出了一种时间正则化训练（TRT）方法，通过在早期时间步施加更强的约束来解决脉冲神经网络（SNNs）的过拟合问题，显著提高了其泛化能力。

**AI_Comments:** 本文提出了一种新颖的时间正则化训练（TRT）方法，有效解决了脉冲神经网络（SNNs）在小规模数据集上训练时普遍存在的过拟合问题，并显著提升了其泛化能力。其创新之处在于引入了时间依赖的正则化机制，并从理论上通过Fisher信息分析解释了其有效性，揭示了时间信息集中（TIC）现象，为SNNs的训练提供了新的视角和方法。这项工作对于推动SNNs在实际应用中的部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 直接训练的脉冲神经网络（SNNs）由于神经形态数据集规模有限和梯度不匹配问题，存在严重的过拟合问题，这从根本上限制了它们的泛化性能。

**Method:** 本文提出了一种时间正则化训练（TRT）方法，通过引入时间依赖的正则化机制，在早期时间步施加更强的约束。通过消融研究、损失景观可视化和学习曲线分析来验证其有效性，并基于Fisher信息分析建立了理论解释。

**Result:** TRT能够有效缓解过拟合，使训练损失景观平坦化，从而增强泛化能力。在CIFAR10/100、ImageNet100、DVS-CIFAR10和N-Caltech101等数据集上，TRT的表现优于其他最先进的方法。研究还揭示了时间信息集中（TIC）现象，即Fisher信息在早期时间步逐步集中。

**Conclusion:** TRT中实现的时间衰减正则化机制有效地引导网络在早期信息丰富的时步学习鲁棒特征，从而显著提高了模型的泛化能力。

> **ai_Abstract:** 本文针对脉冲神经网络（SNNs）在有限神经形态数据集上训练时出现的过拟合和泛化能力受限问题，提出了一种时间正则化训练（TRT）方法。该方法通过引入时间依赖的正则化机制，在早期时间步施加更强的约束。实验结果表明，TRT能有效缓解过拟合，平坦化损失景观，从而显著提升SNNs的泛化性能。通过Fisher信息分析，研究还揭示了时间信息集中（TIC）现象，并从理论上解释了TRT如何引导网络在早期时间步学习鲁棒特征。

> **摘要翻译:** 脉冲神经网络（SNNs）因其事件驱动和低功耗特性而受到广泛关注，使其特别适用于处理基于事件的神经形态数据。最近的研究表明，由于神经形态数据集的规模有限和梯度不匹配问题，直接训练的SNNs存在严重的过拟合问题，这从根本上限制了它们的泛化性能。在本文中，我们提出了一种时间正则化训练（TRT）方法，通过引入时间依赖的正则化机制，在早期时间步施加更强的约束。我们将TRT的性能与CIFAR10/100、ImageNet100、DVS-CIFAR10和N-Caltech101等数据集上的其他最先进方法进行了比较。为了验证TRT的有效性，我们进行了消融研究和分析，包括损失景观可视化和学习曲线分析，结果表明TRT可以有效缓解过拟合并使训练损失景观平坦化，从而增强泛化能力。此外，我们基于Fisher信息分析的结果，建立了TRT时间正则化机制的理论解释。我们通过跟踪TRT训练过程中Fisher信息来分析SNNs内部的时间信息动态，揭示了时间信息集中（TIC）现象，即Fisher信息在早期时间步逐步集中。TRT中实现的时间衰减正则化机制有效地引导网络在早期信息丰富的时步学习鲁棒特征，从而显著提高了模型的泛化能力。代码可在https://anonymous.4open.science/r/TRT-7FBFUYT4E获取。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [39] [A Simple and Robust Weak Galerkin Method for the Brinkman Equations on Non-Convex Polytopal Meshes](https://arxiv.org/abs/2507.18896)
> *一种用于非凸多面体网格上 Brinkman 方程的简单鲁棒弱 Galerkin 方法*

*Chunmei Wang, Shangyou Zhang* | **Category: math.NA, cs.NA, 65N30, 65N15, 65N12, 65N20** | **Updated: 2025-07-25**

**Keywords:** 弱 Galerkin, Brinkman 方程, 无稳定项, 多面体网格, 流体流动

**Comment:** 32 pages, 9 tables, 9 figures. arXiv admin note: text overlap with
  arXiv:2507.05953

> **TL;DR:** 本文提出了一种新颖的无稳定项弱 Galerkin 有限元方法，用于求解 Brinkman 方程。该方法能够统一处理 Stokes 和 Darcy 流动，适用于非凸多面体网格，并具有鲁棒性和精度。

**AI_Comments:** 该论文的创新之处在于开发了一种“无稳定项”的弱 Galerkin 方法来处理复杂的 Brinkman 方程，并成功地统一了 Stokes 和 Darcy 流动的处理方式。此外，该方法适用于非凸多面体网格，这相对于传统方法在处理混合流动状态和复杂几何形状时的局限性，提供了一个显著的改进。

<details>
  <summary>Details</summary>

**Motivation:** 标准有限元方法在处理 Brinkman 方程中 Stokes 和 Darcy 混合流动时，由于单元空间不兼容，难以保持稳定性和精度。因此，需要开发一种统一的数值方案来解决这一挑战。

**Method:** 本文提出了一种新颖的无稳定项弱 Galerkin (WG) 有限元方法。该方法支持由凸和非凸多面体单元组成的通用有限元划分，并采用气泡函数作为关键分析组件以实现稳定性和收敛性。

**Result:** 所提出的 WG 方法在一个统一的框架内展示了解决 Stokes 和 Darcy 主导流动的强大能力。为 WG 有限元解严格推导了最优阶误差估计。数值实验验证了该方法在求解 Brinkman 方程时的鲁棒性、可靠性、灵活性和准确性。

**Conclusion:** 本文成功开发了一种简单、鲁棒且精确的无稳定项弱 Galerkin 方法，用于求解 Brinkman 方程，能够有效地处理复杂的流体流动状态和网格类型。

> **ai_Abstract:** 本文提出了一种新颖的无稳定项弱 Galerkin (WG) 有限元方法，旨在解决 Brinkman 方程在异质多孔介质中 Stokes 和 Darcy 混合流动的模拟难题。针对传统有限元方法在不同流动状态下兼容性差的问题，该 WG 方法提供了一个统一、稳定且精确的数值框架。它支持包含非凸单元的通用多面体网格，并利用气泡函数增强稳定性和收敛性。研究严格推导了最优阶误差估计，并通过数值实验验证了该方法在求解 Brinkman 方程时的鲁棒性、可靠性、灵活性和准确性。

> **摘要翻译:** 本文提出了一种新颖的无稳定项弱 Galerkin (WG) 有限元方法，用于求解 Brinkman 方程，无需传统稳定技术。Brinkman 模型在数学上融合了 Stokes 和 Darcy 方程的特征，描述了多物理场环境中的流体流动，特别是在以空间变渗透率为特征的非均质多孔介质中。在这种情况下，流动行为在某些区域可能主要由 Darcy 动力学控制，而在其他区域则由 Stokes 动力学控制。在这种背景下，一个核心困难源于标准有限元空间的不兼容性：对 Stokes 方程稳定的单元通常对 Darcy 流动表现不佳，反之亦然。本研究解决的主要挑战是开发一种统一的数值方案，以在两种流动状态下保持稳定性和准确性。为此，所提出的 WG 方法展示了通过统一框架解决 Stokes 和 Darcy 主导流动的强大能力。该方法支持由凸和非凸多面体单元组成的通用有限元划分，并采用气泡函数作为关键分析组件以实现稳定性和收敛性。为 WG 有限元解严格推导了最优阶误差估计。此外，还进行了一系列数值实验，以验证理论发现，说明了该方法在求解 Brinkman 方程时的鲁棒性、可靠性、灵活性和准确性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [82] [Fourier Spectral Methods for Block Copolymer Systems on Sphere](https://arxiv.org/abs/2507.18968)
> *球面上嵌段共聚物体系的傅里叶谱方法*

*Wangbo Luo, Yanxiang Zhao* | **Category: math.NA, cs.NA, math-ph, math.MP** | **Updated: 2025-07-25**

**Keywords:** 傅里叶谱方法, 嵌段共聚物, Ohta-Kawasaki 模型, 球面, 自组装图案

**Comment:** 36 pages, 8 figures

> **TL;DR:** 本文提出了一种傅里叶谱方法，用于模拟球面上Ohta-Kawasaki (OK) 和 Nakazawa-Ohta (NO) 模型的动力学和图案形成，并揭示了多种自组装图案，验证了OK模型的有效性。

**AI_Comments:** 该论文的创新之处在于将傅里叶谱方法应用于球面上块状共聚物系统的模拟，特别是结合了DFS和BDF2方案，实现了高效且能量稳定的计算。其重要性在于不仅成功模拟了复杂的自组装图案，并发现其与生物膜图案的相似性，还定量验证了OK模型中的三分之二定律，为理解共聚物系统中的图案形成提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 研究球面上Ohta-Kawasaki (OK) 和 Nakazawa-Ohta (NO) 模型的粗化动力学和平衡图案形成。

**Method:** 采用双傅里叶球面 (DFS) 方法进行空间离散化，并使用二阶后向微分公式 (BDF2) 方案进行时间演化，从而得到一个高效且能量稳定的方案来模拟单位球面上的OK和NO模型。

**Result:** 数值实验揭示了多种自组装图案，包括二元系统中的单气泡组装以及三元系统中的双气泡和混合气泡组装。这些图案与实验中的生物膜图案非常相似。研究还探索了排斥强度与组装中气泡数量之间的关系，并证实了OK模型中的三分之二定律。

**Conclusion:** OK模型在实际应用中（如模拟生物膜图案）表现出有效性，并且该研究提供了自组装图案如何依赖共聚物系统中系统参数的定量证据。

> **ai_Abstract:** 本文提出了一种基于傅里叶谱方法的新型高效能量稳定方案，用于模拟球面上Ohta-Kawasaki (OK) 和 Nakazawa-Ohta (NO) 模型的粗化动力学和平衡图案形成。该方法结合了双傅里叶球面 (DFS) 空间离散化和二阶后向微分公式 (BDF2) 时间演化。数值实验成功模拟了多种自组装图案，包括单气泡、双气泡和混合气泡结构，这些图案与实验生物膜图案高度相似。研究还定量证实了OK模型中的三分之二定律，揭示了系统参数对自组装图案的影响。

> **摘要翻译:** 我们在球形域上引入了Ohta-Kawasaki (OK) 和 Nakazawa-Ohta (NO) 模型的谱方法，研究了它们的粗化动力学和平衡图案形成。我们采用双傅里叶球面 (DFS) 方法进行空间离散化，并使用二阶后向微分公式 (BDF2) 方案进行时间演化，从而得到一个高效且能量稳定的方案来模拟单位球面上的OK和NO模型。我们的数值实验揭示了各种自组装图案，例如二元系统中的单气泡组装以及三元系统中的双气泡和混合气泡组装。这些图案与实验中的生物膜图案非常相似，证明了OK模型在实际应用中的有效性。此外，我们的研究还探讨了排斥强度与组装中气泡数量之间的关系，证实了OK模型中的三分之二定律。这为自组装图案如何依赖共聚物系统中系统参数提供了定量证据。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [124] [Weighted least squares subdivision schemes for noisy data on triangular meshes](https://arxiv.org/abs/2507.18976)
> *用于三角网格上噪声数据的加权最小二乘细分方案*

*Costanza Conti, Sergio López-Ureña, Dionisio F. Yáñez* | **Category: math.NA, cs.NA** | **Updated: 2025-07-25**

**Keywords:** 加权最小二乘, 细分方案, 噪声数据, 三角网格, 去噪

**Comment:** 

> **TL;DR:** 本文提出了一种新的线性细分方案，用于处理三角网格上的噪声数据，并证明了其去噪能力和在多分辨率上下文中的适用性。

**AI_Comments:** 该论文提出了一种创新的、几何依赖的加权最小二乘细分方案，用于处理三角网格上的噪声数据。其核心贡献在于证明了方案的去噪能力和在多分辨率背景下的实用性，这为处理复杂几何数据提供了一个有前景的工具。方案的“几何依赖”特性可能导致非均匀性，这在某些应用中可能需要额外的考虑。与现有局部线性回归方法的性能相似性表明了其有效性，而其细分性质则扩展了其应用范围。

<details>
  <summary>Details</summary>

**Motivation:** 为了细化三角网格上给定的噪声数据。

**Method:** 本文提出并分析了一种新的线性细分方案家族。细分规则包括局部拟合和评估一个加权最小二乘近似的一次多项式。这些规则适用于任何类型的三角网格，包括有限网格或包含奇异顶点的网格，并且是几何依赖的，可能导致非均匀方案。

**Result:** 对于这些新的细分方案，能够证明其再现性、近似阶数、去噪能力，并且对于某些特殊类型的网格，还能证明其收敛性。数值实验表明，它们的性能与先进的局部线性回归方法相似。

**Conclusion:** 这些细分方案的细分性质使其适用于多分辨率上下文以及处理噪声几何数据。

> **ai_Abstract:** 本文介绍了一种针对三角网格上噪声数据的新型线性细分方案。该方案通过局部拟合加权最小二乘一次多项式来细化数据，适用于各种三角网格类型，包括包含奇异顶点的网格。研究证明了该方案的再现性、近似阶数、去噪能力和收敛性。数值实验表明，其性能与先进的局部线性回归方法相当，并且由于其细分特性，特别适用于多分辨率分析和处理噪声几何数据。

> **摘要翻译:** 本文提出并分析了一种新的线性细分方案家族，用于细化三角网格上给定的噪声数据。细分规则包括局部拟合和评估一个加权最小二乘近似的一次多项式。这类规则适用于任何类型的三角网格，包括有限网格或包含奇异顶点的网格，并且是几何依赖的，这可能导致非均匀方案。对于这些新的细分方案，我们能够证明其再现性、近似阶数、去噪能力，并且对于某些特殊类型的网格，还能证明其收敛性。几项数值实验表明，它们的性能与先进的局部线性回归方法相似，但其细分性质使其适用于多分辨率上下文以及处理噪声几何数据，如示例所示。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [166] [Barenblatt solutions for the time-fractional porous medium equation: approach via integral equations](https://arxiv.org/abs/2507.19217)
> *时间分数阶多孔介质方程的Barenblatt解：积分方程方法*

*Josefa Caballero, Hanna Okrasińska-Płociniczak, Łukasz Płociniczak, Kishin Sadarangani* | **Category: math.NA, cs.NA, math.AP** | **Updated: 2025-07-25**

**Keywords:** Barenblatt解, 时间分数阶多孔介质方程, 积分方程, 数值方案, Caputo导数

**Comment:** 

> **TL;DR:** 本文通过积分方程方法研究了时间分数阶多孔介质方程的Barenblatt解，并证明了其存在性和基本性质，同时提出了收敛的数值方案进行计算和验证。

**AI_Comments:** 该论文的创新之处在于其采用积分方程方法来严格处理时间分数阶多孔介质方程的Barenblatt解，并首次明确证明了其多种基本性质。同时，提出的收敛数值方案弥补了理论与实践之间的空白，对于实际应用具有重要意义。通过结合理论证明和数值验证，该研究提供了对时间分数阶多孔介质方程解的全面而深入的理解。

<details>
  <summary>Details</summary>

**Motivation:** 探索时间分数阶多孔介质方程的Barenblatt解，并理解其特性，同时开发有效的数值方法来计算这些解，以弥合理论与实践之间的鸿沟。

**Method:** 采用积分方程方法严格证明了Barenblatt解的存在性，并建立了其基本性质。此外，引入了一系列收敛的数值方案来计算这些Barenblatt解。

**Result:** 严格证明了Barenblatt解的存在性，并建立了其包括上下界估计、质量守恒、正则性和单调性在内的若干基本性质。提出的数值方法被证明是收敛的，并通过各种示例验证了其有效性。

**Conclusion:** 本文通过积分方程方法成功探索并建立了时间分数阶多孔介质方程Barenblatt解的理论框架，并开发了有效的数值计算方法，从而增强了对这些解的理解和适用性。

> **ai_Abstract:** 本文研究了具有Caputo型时间导数的时间分数阶多孔介质方程的Barenblatt解。研究采用积分方程方法，严格证明了这些解的存在性及其上下界估计、质量守恒、正则性、单调性等基本性质。此外，文中还提出并验证了一系列收敛的数值方案，旨在高效计算这些Barenblatt解，并通过实例进一步增强了理论框架的理解和实际应用。

> **摘要翻译:** 本文探讨了时间分数阶多孔介质方程的Barenblatt解，该方程以Caputo型时间导数表征。我们采用积分方程方法，严格证明了这些解的存在性，并建立了若干基本性质，包括上下界估计、质量守恒、正则性和单调性。为了弥合理论与实践之间的差距，我们引入了一系列收敛的数值方案，专门用于计算Barenblatt解，确保了可靠和高效的近似。理论框架通过各种示例得到丰富，这些示例阐明了概念并验证了所提出数值方法的有效性，从而增强了我们结果的理解和适用性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [208] [Plug and Play Splitting Techniques for Poisson Image Restoration](https://arxiv.org/abs/2507.19378)
> *即插即用分裂技术用于泊松图像恢复*

*Alessandro Benfenati* | **Category: math.NA, cs.NA** | **Updated: 2025-07-25**

**Keywords:** 即插即用, 泊松图像恢复, 分裂技术, ADMM, 图像去噪

**Comment:** 

> **TL;DR:** 针对泊松图像恢复，本文提出了一种新的即插即用（PnP）分裂方法PnPSplit+，解决了现有PnP在泊松数据上收敛性问题，并提供了去模糊步骤的闭式解，在强噪声和模糊条件下表现出色。

**AI_Comments:** 该论文的创新点在于将PIDSplit+的思想引入PnP框架以解决泊松图像恢复中的特定挑战，特别是通过ADMM实现去模糊步骤的闭式解，从而提高了计算效率。其重要性在于扩展了PnP方法的适用范围，使其能够更有效地处理泊松噪声数据，这在低光成像等领域具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有即插即用（PnP）方法在高斯数据图像恢复中效果显著，但其理论不能直接扩展到泊松情况，原因是保真函数（Kullback-Leibler泛函）的梯度非Lipschitz，或其近端算子没有闭式解，导致内部子问题需要迭代求解。

**Method:** 本文将PIDSplit+算法的思想扩展到即插即用（PnP）方案中，利用交替方向乘子法（ADMM）为去模糊步骤提供了闭式解，从而无需迭代求解器。通过使用严格非膨胀去噪器确保了方法的收敛性。

**Result:** 所提出的PnPSplit+方法在不同的泊松图像恢复问题上进行了测试，即使在高噪声水平和严重模糊条件下也显示出显著的性能。

**Conclusion:** PnPSplit+方法通过提供去模糊步骤的闭式解和确保收敛性，有效解决了泊松图像恢复中即插即用（PnP）方法的挑战，并在高噪声和严重模糊条件下展现出卓越的图像恢复性能。

> **ai_Abstract:** 本文提出了一种名为PnPSplit+的即插即用（PnP）分裂技术，用于解决泊松图像恢复问题。针对现有PnP方法在泊松数据上因保真函数特性和缺乏闭式解而导致的理论和计算挑战，PnPSplit+通过扩展PIDSplit+算法并利用交替方向乘子法（ADMM），实现了去模糊步骤的闭式解，避免了迭代求解。该方法通过使用严格非膨胀去噪器保证了收敛性，并在高噪声和严重模糊条件下展现出卓越的图像恢复性能。

> **摘要翻译:** 即插即用（PnP）方法在高斯数据图像恢复问题框架中取得了显著成果。然而，由于保真函数（Kullback-Leibler泛函）的梯度非Lipschitz，或该项的近端算子缺乏闭式解，导致需要为内部子问题采用迭代求解器，因此高斯情况下的现有理论无法扩展到泊松情况。在这项工作中，我们将PIDSplit+算法的思想扩展到PnP方案中，利用交替方向乘子法（ADMM）：这使得去模糊步骤能够提供闭式解，无需迭代求解器。通过使用严格非膨胀去噪器确保了方法的收敛性。所提出的方法，即PnPSplit+，在不同的泊松图像恢复问题上进行了测试，即使在高噪声水平和严重模糊条件下也显示出显著的性能。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [267] [A non-iterative domain decomposition time integrator for linear wave equations](https://arxiv.org/abs/2507.19379)
> *线性波动方程的非迭代域分解时间积分器*

*Tim Buchholz, Marlis Hochbruck* | **Category: math.NA, cs.NA, 65M12, 35L20, 65M55 (Primary) 65N30, 35L05 (Secondary)** | **Updated: 2025-07-25**

**Keywords:** 域分解, 波动方程, 非迭代, 时间积分器, Crank-Nicolson

**Comment:** 24 pages, 5 figures

> **TL;DR:** 本文提出并分析了一种针对线性声波方程的非迭代域分解积分器，该方法结合了隐式Crank-Nicolson步和局部预测步，实现了空间并行，允许更大的时间步长并保持高精度，理论分析和数值实验均证实了其有效性。

**AI_Comments:** 本文的创新点在于将为抛物线问题设计的域分解方法成功地应用于线性波动方程，并实现了非迭代的时间积分。这种方法能够显著提高计算效率，允许更大的时间步长，同时保持高精度和并行化能力，对于大规模波动方程的数值模拟具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决线性声波方程的数值求解问题，特别是实现空间并行化并允许比显式方案更大的时间步长，同时保持高精度，本文提出了一种非迭代的域分解时间积分器。

**Method:** 该方法的核心思想是将空间子域上的隐式Crank-Nicolson步与子域界面上的局部预测步相结合。它将为抛物线问题设计的方法（如Blum, Lisky和Rannacher (1992)或Dawson和Dupont (1992)）应用于波动方程的全离散设置，并使用带质量集总（mass lumping）的线性有限元。该方法是非迭代的，可以在时间上顺序推进，无需在每个时间步进行迭代。

**Result:** 与显式方案相比，该方法允许显著更大的时间步长并保持高精度。理论证明，在依赖于子域重叠宽度的CFL型条件下，该方法在时间上达到二阶精度，并实现$	ext{O}(h + 	au^2)$的全局收敛。数值实验证实了理论结果。

**Conclusion:** 数值实验证实了本文提出的非迭代域分解时间积分器的理论结果。

> **ai_Abstract:** 本文提出了一种用于线性声波方程的非迭代域分解时间积分器。该方法通过在空间子域上使用隐式Crank-Nicolson步并在子域界面上结合局部预测步，实现了空间并行化，并且无需在每个时间步进行迭代。该方法是对现有抛物线问题方法的改编，适用于波动方程的全离散设置，并采用线性有限元与质量集总。研究表明，该方法相比显式方案能使用更大的时间步长并保持高精度，理论上实现了时间二阶精度和全局$	ext{O}(h + 	au^2)$收敛，这些结果已通过数值实验得到验证。

> **摘要翻译:** 我们提出并分析了一种用于线性声波方程的非迭代域分解积分器。其核心思想是将空间子域上的隐式Crank-Nicolson步与子域界面上的局部预测步相结合。这使得在时间上顺序推进的同时能够实现空间并行化，并且在每个时间步不需要迭代。该方法类似于Blum、Lisky和Rannacher（1992）或Dawson和Dupont（1992）为抛物线问题设计的方法。我们的方法将其应用于波动方程的全离散设置，使用带有质量集总（mass lumping）的线性有限元。与显式方案相比，我们的方法允许显著更大的时间步长并保持高精度。我们证明了在依赖于子域重叠宽度的CFL型条件下，所得方法在时间上达到二阶精度，并实现$	ext{O}(h + 	au^2)$的全局收敛。最后，我们通过数值实验证实了理论结果。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [299] [Convergence of Discrete Exterior Calculus for the Hodge-Dirac Operator](https://arxiv.org/abs/2507.19405)
> *霍奇-狄拉克算子的离散外微分收敛性*

*Radovan Dabetić, Ralf Hiptmair* | **Category: math.NA, cs.NA** | **Updated: 2025-07-25**

**Keywords:** 离散外微分, 霍奇-狄拉克算子, 收敛性, 离散化

**Comment:** 

> **TL;DR:** 该论文利用现有技术，为霍奇-狄拉克算子在离散外微分框架下的离散化提供了一个简短的收敛性证明。

**AI_Comments:** 该论文的创新之处在于提供了一个简短的收敛性证明，这可能简化了霍奇-狄拉克算子在离散外微分框架下离散化的理论分析。其重要性在于为相关数值方法提供了更坚实的数学基础，尽管具体贡献的深度有赖于对所引用工作的理解。

<details>
  <summary>Details</summary>

**Motivation:** 提供霍奇-狄拉克算子在离散外微分 (DEC) 框架下离散化的收敛性证明。

**Method:** 使用[Johnny Guzm\'an 和 Pratyush Potu, A Framework for Analysis of DEC Approximations to Hodge-Laplacian Problems using Generalized Whitney Forms, arXiv:2505.08934, 2025]中建立的技术。

**Result:** 提供了一个霍奇-狄拉克算子在离散外微分 (DEC) 框架下离散化的收敛性简短证明。

**Conclusion:** 论文成功地提供了一个霍奇-狄拉克算子在离散外微分框架下离散化收敛性的简短证明。

> **ai_Abstract:** 本论文提供了一个关于霍奇-狄拉克算子在离散外微分 (DEC) 框架中离散化收敛性的简短证明，该证明是基于[Johnny Guzm\'an 和 Pratyush Potu]的工作中建立的技术。

> **摘要翻译:** 本文利用[Johnny Guzm\'an 和 Pratyush Potu, A Framework for Analysis of DEC Approximations to Hodge-Laplacian Problems using Generalized Whitney Forms, arXiv:2505.08934, 2025]中建立的技术，为离散外微分 (DEC) 框架下霍奇-狄拉克算子离散化的收敛性提供了一个简短证明。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [489] [Superfast direct inversion of the nonuniform discrete Fourier transform via hierarchically semi-separable least squares](https://arxiv.org/abs/2404.13223)
> *通过分层半可分离最小二乘法实现非均匀离散傅里叶变换的超快速直接反演*

*Heather Wilber, Ethan N. Epperly, Alex H. Barnett* | **Category: math.NA, cs.NA, 65T50, 65F55, 65F20** | **Updated: 2025-07-24**

**Keywords:** 非均匀离散傅里叶变换, 直接反演, 分层半可分离, 最小二乘, 低秩结构

**Comment:** 30 pages, 8 figures

> **TL;DR:** 引入了一种超快速直接求解器，用于反演非均匀离散傅里叶变换矩阵，该方法利用矩阵的层次低秩结构，实现了接近线性的计算复杂度，尤其适用于大型问题。

**AI_Comments:** 这篇论文的创新点在于提出了一种超快速直接求解器，用于处理非均匀离散傅里叶变换的求逆问题。其核心贡献在于揭示并利用了相关矩阵的分层低秩结构，从而实现了接近线性的计算复杂度，显著优于现有方法，特别是在处理大规模问题时，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决涉及非均匀离散傅里叶变换矩阵的超定线性系统，特别是需要一种快速直接求解器来处理这些具有挑战性的问题。

**Method:** 将非均匀离散傅里叶变换矩阵转换为具有分层低秩结构的柯西型形式，解释其秩结构，并开发了一种基于该分析的快速秩结构分层近似方法以及分层最小二乘求解器。

**Result:** 该方法是一种直接反演非均匀离散变换的方法，其复杂度通常接近于问题的自由度，并在基准测试中表现出色，特别适用于具有多个右侧项的大型问题。

**Conclusion:** 该研究成功开发了一种超快速直接求解器，能够高效处理非均匀离载傅里叶变换的求逆问题，尤其在大规模应用中表现突出。

> **ai_Abstract:** 本文介绍了一种用于求解涉及非均匀离散傅里叶变换矩阵的超定线性系统的直接求解器。该方法利用了矩阵可转换为具有分层低秩结构的柯西型形式的特性，并开发了一种快速秩结构分层近似方法和分层最小二乘求解器。实验结果表明，该求解器能够以接近线性的复杂度反演非均匀离散变换，尤其适用于处理具有多个右侧项的大型问题。

> **摘要翻译:** 引入了一种用于求解涉及非均匀离散傅里叶变换矩阵的超定线性系统的直接求解器。此类矩阵可以转换为具有分层低秩结构的柯西型形式。解释了该矩阵的秩结构，并表明相关子矩阵的秩仅随矩阵列数的对数增长。基于此分析，开发了一种快速秩结构分层近似方法，以及用于这些及相关系统的分层最小二乘求解器。该结果是一种直接反演非均匀离散变换的方法，其复杂度通常接近于问题的自由度。该求解器在反演一维II型（或正向）变换的设置中，针对一系列条件数和问题规模（高达4 x 10^6 x 2 x 10^6）与各种迭代和直接求解器进行了基准测试。这些实验表明，该方法特别适用于具有多个右侧项的大型问题。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [525] [Spectral alignment of kernel matrices and applications](https://arxiv.org/abs/2409.04263)
> *核矩阵的谱对齐及其应用*

*Tizan Wenzel, Armin Iske* | **Category: math.NA, cs.NA** | **Updated: 2025-07-25**

**Keywords:** 核矩阵, 谱对齐, 稳定性估计, Ingham型定理, 有限光滑核

**Comment:** 

> **TL;DR:** 本文通过改进多元Ingham型定理，获得了核矩阵的新的精细稳定性估计，并探讨了不同平滑度核的瑞利商之间的关系，以及对特征向量的影响。

**AI_Comments:** 这项研究通过引入改进的多元Ingham型定理，为核矩阵的稳定性分析提供了新的理论基础，特别是在处理有限光滑核方面具有创新性。它对于理解核方法中算法的收敛性和稳定性具有重要意义，并可能在基于核的近似领域有广泛应用。

<details>
  <summary>Details</summary>

**Motivation:** 核矩阵是基于核的近似中的关键量，其稳定性及算法收敛性等重要性质可通过核矩阵进行分析。

**Method:** 本文改进了一个多元Ingham型定理，并将其应用于获得核矩阵的稳定性估计。研究重点放在有限光滑核（如Matérn或Wendland核），但结果也适用于范数等效核。

**Result:** 获得了核矩阵的新的精细稳定性估计。特别地，得到了不同平滑度核的核矩阵瑞利商相互关联的结果。

**Conclusion:** 对这些核矩阵的特征向量得出了结论。

> **ai_Abstract:** 本文通过改进多元Ingham型定理，为核矩阵，特别是有限光滑核（如Matérn和Wendland核）的稳定性提供了新颖且精细的估计。研究揭示了不同平滑度核的瑞利商之间的关系，并探讨了这些核矩阵特征向量的相关结论。

> **摘要翻译:** 核矩阵是基于核的近似中的关键量，其稳定性及算法收敛性等重要性质可通过核矩阵进行分析。
在这项工作中，我们改进了一个多元Ingham型定理，然后利用它来获得核矩阵的新的精细稳定性估计。为此，我们专注于有限光滑核的情况，例如Matérn或Wendland核族，同时注意到这些结果也扩展到范数等效核。我们特别获得了将不同平滑度核的核矩阵的瑞利商相互关联的结果。最后，我们评论了这些核矩阵特征向量的结论。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [566] [Local Characteristic Decomposition of Equilibrium Variables for Hyperbolic Systems of Balance Laws](https://arxiv.org/abs/2412.19791)
> *守恒律双曲系统平衡变量的局部特征分解*

*Shaoshuai Chu, Alexander Kurganov, Mingye Na, Bao Shan Wang, Ruixiao Xin* | **Category: math.NA, cs.NA** | **Updated: 2025-07-25**

**Keywords:** 守恒律双曲系统, 高阶数值方法, 局部特征分解, 平衡变量, 平衡格式

**Comment:** 

> **TL;DR:** 本文提出了一种新的平衡变量局部特征分解（LCD）方法，用于构建非振荡且保持稳态的守恒律双曲系统高阶数值方法。

**AI_Comments:** 本文的创新点在于引入了一种针对平衡变量的局部特征分解方法，这同时解决了高阶数值方法中的振荡和稳态保持两大关键问题。这对于开发更鲁棒、更精确的守恒律双曲系统高阶数值格式具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 高阶数值方法在处理守恒律双曲系统时面临两大挑战：一是重构（插值）可能产生振荡，除非应用于局部特征变量；二是需要设计能够精确保持物理相关稳态的平衡（WB）格式。

**Method:** 为了实现非振荡重构并保持稳态，本文引入了一种新的平衡变量局部特征分解（LCD）。该技术被应用于在WB A-WENO框架中实现的五阶Ai-WENO-Z插值方法。

**Result:** 所开发的技术在多种数值示例上展示了其性能。

**Conclusion:** 通过引入平衡变量的局部特征分解，本文成功开发了对守恒律双曲系统既非振荡又能保持稳态的高阶数值方法。

> **ai_Abstract:** 本文针对守恒律双曲系统高阶数值方法中存在的振荡问题和稳态保持需求，提出了一种新颖的平衡变量局部特征分解（LCD）方法。该方法旨在实现非振荡重构并确保格式的平衡性。所提出的技术被应用于五阶Ai-WENO-Z插值，并在数值示例中验证了其有效性。

> **摘要翻译:** 本文关注守恒律双曲系统的高阶数值方法。这类方法通常基于对计算出的离散量进行高阶分段多项式重构（插值）。然而，除非通过局部特征分解（LCD）将重构（插值）过程应用于局部特征变量，否则此类重构（插值）可能会产生振荡。设计精确稳定的高阶格式的另一个挑战是需要在通量、源项和非守恒积项之间保持微妙的平衡：一个好的格式应该在能够精确保持某些（物理相关）稳态的意义上是平衡的（WB）。确保重构（插值）保持这些稳态的方法之一是将其应用于平衡变量，这些变量在稳态下应保持恒定。为了实现这一目标并保持重构（插值）的非振荡性，我们引入了一种新的平衡变量的LCD。我们将所开发的技术应用于在[S. Chu, A. Kurganov, and R. Xin, Beijing J. of Pure and Appl. Math., to appear]中最新引入的WB A-WENO框架内实现的五阶Ai-WENO-Z插值，并在各种数值示例上展示了其性能。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [609] [A posteriori error control for a finite volume scheme for a cross-diffusion model of ion transport](https://arxiv.org/abs/2502.08306)
> *离子输运交叉扩散模型的有限体积格式的后验误差控制*

*Arne Berrens, Jan Giesselmann* | **Category: math.NA, cs.NA, 65M15, 35K65, 35K51, 65M08, 35K40** | **Updated: 2025-07-25**

**Keywords:** 后验误差估计, 交叉扩散模型, 有限体积格式, 离子输运, 稳定性框架

**Comment:** 27 pages, 2 tables

> **TL;DR:** 本文首次为离子输运交叉扩散系统推导了可靠的后验误差估计，并数值验证了其误差估计器与真实误差同阶。

**AI_Comments:** 本文的创新点在于首次为交叉扩散系统提供了后验误差估计，填补了该领域的一个重要空白。这对于离子输运等复杂模型的数值模拟精度控制具有重要意义。所提出的稳定性框架独立于数值格式，具有一定的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 针对模拟离子通过纳米孔传输的交叉扩散系统，目前缺乏可靠的后验误差估计，本文旨在填补这一空白，首次为交叉扩散系统提供后验误差估计。

**Method:** 论文为中心元有限体积格式推导了可靠的后验误差估计，为此，他们建立了一个独立于数值格式的稳定性框架，并引入了合适的（协调的）数值解重构。该稳定性框架依赖于与系统弱唯一性结果中相同的简化假设。当存在电场力时，还假设溶剂浓度有统一的下界。

**Result:** 成功为交叉扩散系统推导了第一个后验误差估计。此外，还推导了近似扩散方程的有限体积格式的点式后验误差估计。数值实验表明，误差估计器与真实误差具有相同的阶。

**Conclusion:** 本文成功为离子输运交叉扩散模型的有限体积格式提供了可靠的后验误差估计，并通过数值实验验证了其有效性，表明所提出的误差估计器能够准确反映真实误差的量级。

> **ai_Abstract:** 本研究首次为模拟离子通过纳米孔传输的交叉扩散系统，推导了中心元有限体积格式的可靠后验误差估计。通过建立独立于数值格式的稳定性框架和引入合适的数值解重构，解决了交叉扩散系统缺乏后验误差估计的问题。研究还推导了扩散方程的有限体积格式的点式后验误差估计。数值实验验证了所提误差估计器的有效性，显示其与真实误差具有相同的收敛阶。

> **摘要翻译:** 我们为模拟离子通过纳米孔传输的交叉扩散系统的中心元有限体积格式，推导了一个可靠的后验误差估计。为此，我们推导了一个独立于数值格式的稳定性框架，并引入了一个合适的（协调的）数值解重构。该稳定性框架依赖于与该系统弱唯一性结果中相同的简化假设。此外，当存在电场力时，我们假设溶剂浓度有统一的下界。这是交叉扩散系统的第一个后验误差估计。在此过程中，我们为近似扩散方程的有限体积格式推导了一个点式后验误差估计。我们进行了数值实验，结果表明误差估计器与真实误差具有相同的阶。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [651] [Linearized Localized Orthogonal Decomposition for Quasilinear Nonmonotone Elliptic PDE](https://arxiv.org/abs/2502.13831)
> *拟线性非单调椭圆偏微分方程的线性化局部正交分解*

*Maher Khrais, Barbara Verfürth* | **Category: math.NA, cs.NA, 65N30, 65N15, 35J60, 65J15, 65N12** | **Updated: 2025-07-25**

**Keywords:** 局部正交分解, 拟线性椭圆问题, 多尺度方法, 非单调, 线性化

**Comment:** 

> **TL;DR:** 提出并分析了一种基于局部正交分解的、用于求解具有多尺度系数的拟线性非单调椭圆问题的新多尺度方法，该方法无需强结构假设，并提供了严格的适定性分析和收敛性估计。

**AI_Comments:** 该论文的创新之处在于将局部正交分解（LOD）的思想应用于拟线性非单调椭圆问题，并克服了传统多尺度方法对周期性或尺度分离等强结构假设的依赖。它通过引入线性化技术，扩展了LOD方法的适用范围，并提供了严格的数学分析和数值验证，这对于处理复杂介质中的偏微分方程具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决具有空间多尺度系数的拟线性非单调椭圆问题，并提出一种不依赖周期性或尺度分离等结构假设的方法。

**Method:** 提出了一种受局部正交分解（LOD）启发的数值方法。该方法通过在小的局部子域上求解线性细尺度问题来构建多尺度空间，并考虑了两种不同的线性化技术。

**Result:** 对两种线性化技术进行了严格的适定性分析和$H^1$-半范数下的收敛性估计。理论和数值比较讨论了不同线性化点策略的性能。数值实验证实了理论发现并展示了方法的适用性。

**Conclusion:** 该方法在解决具有多尺度系数的拟线性非单调椭圆问题上具有良好的理论基础和实际适用性，并且不依赖于强结构假设。

> **ai_Abstract:** 本文提出并分析了一种新的多尺度方法，用于解决具有空间多尺度系数的拟线性非单调椭圆问题。该方法受到局部正交分解（LOD）的启发，其优势在于不要求周期性或尺度分离等结构假设，仅需对系数进行最小的正则性假设。通过在小局部子域上求解线性细尺度问题来构建多尺度空间，并探讨了两种不同的线性化技术。研究提供了严格的适定性分析和在$H^1$-半范数下的收敛性估计，并通过理论和数值实验验证了方法的性能和适用性。

> **摘要翻译:** 本文提出并分析了一种针对一类具有空间多尺度系数的拟线性非单调椭圆问题的多尺度方法。该数值方法受局部正交分解（LOD）的启发，因此我们不需要周期性或尺度分离等结构假设，而只需要对系数有最小的正则性假设。为了构建多尺度空间，我们在小的局部子域上求解线性细尺度问题，为此我们考虑了两种不同的线性化技术。对于这两种技术，我们都给出了严格的适定性分析和$H^1$-半范数下的收敛性估计。我们从理论和数值上比较并讨论了我们针对不同线性化点的策略的性能。数值实验强调了理论发现并说明了该方法的适用性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [693] [AFIRE: Accurate and Fast Image Reconstruction Algorithm for Geometric-inconsistent Multispectral CT](https://arxiv.org/abs/2505.24793)
> *AFIRE：用于几何不一致多光谱CT的精确快速图像重建算法*

*Yu Gao, Chong Chen* | **Category: math.NA, cs.NA, physics.med-ph, 65J15, 65R32, 65J22, 68U10** | **Updated: 2025-07-25**

**Keywords:** 多光谱CT, 图像重建, 几何不一致, 简化牛顿法, AFIRE

**Comment:** 39 pages, 16 figures, 1 table

> **TL;DR:** 提出AFIRE算法，用于解决几何不一致多光谱CT的精确快速图像重建问题，该算法基于简化牛顿法，表现出高精度和高效率。

**AI_Comments:** 该论文通过深入分析非线性映射的导数结构，巧妙地将简化牛顿法应用于多光谱CT图像重建，尤其是在几何不一致的挑战性场景下。其创新点在于对问题数学结构的深刻理解，并转化为高效的算法。算法在精度和效率上的显著提升，以及收敛性理论的建立，使其具有重要的理论和实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 当不同X射线能量谱下的扫描几何形状不一致或不匹配时，非线性多光谱CT的精确快速图像重建具有挑战性。

**Method:** 提出了AFIRE（精确快速图像重建）算法，利用简化牛顿法。该算法基于对相关非线性映射的导数算子（梯度）的洞察，即在特殊点（如零点）可表示为由X射线变换（投影矩阵）组成的对角算子（矩阵）与一个非常小规模矩阵的复合（块乘法）。

**Result:** 在适当条件下，建立了算法的收敛性理论。数值实验验证了该算法在完全几何不一致双能CT中，无论有无噪声投影数据，都能准确有效地重建基图像。该算法在精度和效率方面显著优于一些现有最先进方法。

**Conclusion:** AFIRE算法能够解决几何不一致多光谱CT的精确快速图像重建问题，并在精度和效率上表现出色，同时具有灵活性和可扩展性。

> **ai_Abstract:** 本论文提出了一种名为AFIRE的算法，旨在解决非线性多光谱CT中由于扫描几何不一致导致的精确快速图像重建难题。该算法基于对非线性映射导数算子的新发现，并利用简化牛顿法。研究不仅建立了算法的收敛性理论，还通过数值实验证明了其在几何不一致双能CT中重建图像的准确性和高效性，性能优于现有方法，并展现了良好的灵活性和可扩展性。

> **摘要翻译:** 对于非线性多光谱计算机断层扫描（CT），当不同X射线能量谱下的扫描几何形状不一致或不匹配时，精确快速的图像重建具有挑战性。受此启发，我们提出了一种精确快速图像重建（AFIRE）算法，以解决轻度全扫描情况下的此类问题。从连续（或离散）设置中，我们发现所涉及的非线性映射在某些特殊点（例如零点）的导数算子（梯度）可以表示为由X射线变换（投影矩阵）组成的对角算子（矩阵）与一个非常小规模矩阵的复合（块乘法）。基于这些见解，AFIRE算法通过利用简化牛顿法被提出。在适当的条件下，我们建立了所提出算法的收敛性理论。此外，还进行了数值实验，以验证所提出的算法能够在完全几何不一致的双能CT中，使用无噪声和有噪声的投影数据，准确有效地重建基图像。特别是，所提出的算法在精度和效率方面显著优于一些最先进的方法。最后，还展示了所提出算法的灵活性和可扩展性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [740] [IMEX-RB: a self-adaptive implicit-explicit time integration scheme exploiting the reduced basis method](https://arxiv.org/abs/2506.16470)
> *IMEX-RB：一种利用降阶基方法自适应隐式-显式时间积分方案*

*Micol Bassanini, Simone Deparis, Francesco Sala, Riccardo Tenderini* | **Category: math.NA, cs.NA, 65M12** | **Updated: 2025-07-25**

**Keywords:** 自适应时间积分, 隐式-显式方案, 降阶基方法, 常微分方程, 数值稳定性

**Comment:** 20 pages, 7 figures

> **TL;DR:** IMEX-RB是一种自适应隐式-显式（IMEX）时间积分方案，它通过动态构建降阶子空间并在全阶显式步骤中使用，实现了对常微分方程组的高精度和计算效率，且无需参数化或离线-在线分离。

**AI_Comments:** IMEX-RB的创新之处在于其自适应性和对传统降阶基方法限制的规避，即无需PDE参数化和离线-在线分离。通过动态构建降阶子空间，它提高了方法的灵活性和适用性。该方法在数值模拟中具有重要意义，尤其是在需要高效且高精度求解大规模ODE系统时。

<details>
  <summary>Details</summary>

**Motivation:** 为了数值积分由偏微分方程空间离散化产生的常微分方程组，需要一种新的自适应隐式-显式（IMEX）时间积分方案，以克服传统降阶基方法的限制并提高效率。

**Method:** 本文提出了一种名为IMEX-RB的自适应隐式-显式（IMEX）时间积分方案。该方法在每个时间步将高保真问题投影到一个低维子空间并隐式积分其动力学，然后将结果作为全阶显式步骤的初始猜测。与传统降阶基方法不同，IMEX-RB无需底层PDE的参数化，也无需离线-在线分离，因为降阶子空间是利用高保真解历史动态构建的。文章展示了IMEX-RB的一阶公式，并分析了其收敛性和稳定性。

**Result:** IMEX-RB在适当的超参数条件下是无条件稳定的。数值实验表明，IMEX-RB的性能优于传统的后向欧拉等时间积分方案，在适当调整其主要超参数（即降阶基大小和稳定性容差）的情况下，能够提供高精度解。此外，当时间步长超过前向欧拉稳定性阈值时，IMEX-RB在计算上比后向欧拉更具优势。

**Conclusion:** IMEX-RB是一种有效且高效的自适应隐式-显式时间积分方案，能够为常微分方程组提供高精度解，并在计算上优于传统方法，同时避免了传统降阶基方法的某些限制。

> **ai_Abstract:** 本文提出了一种名为IMEX-RB的自适应隐式-显式（IMEX）时间积分方案，用于数值求解由偏微分方程空间离散化产生的常微分方程组。该方法结合了降阶基（RB）方法，在每个时间步动态构建低维子空间进行隐式积分，并将其结果作为全阶显式步骤的初始猜测。与传统RB方法不同，IMEX-RB无需PDE参数化或离线-在线分离。研究展示了其一阶公式、收敛性和无条件稳定性。数值实验表明，IMEX-RB在提供高精度解方面优于传统方法如后向欧拉，并且在特定时间步长范围内具有计算优势。

> **摘要翻译:** 在这项工作中，我们引入了一种名为IMEX-RB的自适应隐式-显式（IMEX）时间积分方案，用于数值积分由有限差分法对偏微分方程（PDEs）进行空间离散化所产生的常微分方程（ODEs）系统。该方法利用降阶基（RB）方法，在每个时间步将高保真问题投影到一个合适的低维子空间并隐式积分其动力学。遵循IMEX范式，所得解随后作为全阶显式步骤中的一个“有根据的猜测”。值得注意的是，与规范的RB方法相比，IMEX-RB既不需要底层PDE的参数化，也不具有离线-在线分离，因为降阶子空间是动态构建的，利用了高保真解历史。我们提出了IMEX-RB的一阶公式，展示并证明了其收敛性和稳定性特性。特别是，在方法超参数的适当条件下，IMEX-RB是无条件稳定的。理论分析通过在二维和三维代表性模型问题上进行的数值实验得到了证实。结果表明，我们的方法可以优于传统的像后向欧拉这样的时间积分方案。事实上，IMEX-RB提供了高保真度的精确解，前提是其主要超参数——即降阶基大小和稳定性容差——经过适当调整。此外，对于超过前向欧拉稳定性阈值的一系列时间步长，IMEX-RB比后向欧拉实现了计算增益。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [758] [A conservative invariant-domain preserving projection technique for hyperbolic systems under adaptive mesh refinement](https://arxiv.org/abs/2507.18717)
> *双曲系统自适应网格细化下的一种守恒不变域保持投影技术*

*Jake Harmon, Martin Kronbichler, Matthias Maier, Eric Tovar* | **Category: math.NA, cs.NA, 65M60, 65M12, 35L50, 35L65, 76M10** | **Updated: 2025-07-24**

**Keywords:** 不变域保持, 投影技术, 双曲系统, 自适应网格细化, 守恒

**Comment:** 

> **TL;DR:** 本文提出了一种严格、守恒的不变域保持（IDP）投影技术，用于双曲系统的自适应网格细化，能够证明其保持物理性质，并提高了精度和效率，同时避免了特设校正。

**AI_Comments:** 该研究的创新点在于提出了一个严格的、可证明的IDP投影技术，用于自适应网格细化下的双曲系统，解决了传统方法可能需要特设校正来保持物理不变量的问题。其重要性体现在为需要保持物理性质的复杂系统模拟提供了更可靠、高效的数值工具。

<details>
  <summary>Details</summary>

**Motivation:** 在双曲系统数值模拟中，保持物理性质至关重要，而现有方法可能需要特设校正来维持物理不变量。

**Method:** 提出了一种严格的、守恒的不变域保持（IDP）投影技术，用于分层离散化，在解空间之间映射时强制保持在物理隐含的凸集中。该方案与合适的细化指示器结合，为双曲系统提供了可证明的IDP自适应数值方法。文中提供了特性证明和在高性能有限元代码中的详细构造。

**Result:** 通过对一系列计算上具有挑战性的基准问题的研究，证明了该方案在增强精度和效率方面的特性，并完全避免了为保持物理不变量而进行的特设校正。

**Conclusion:** 该提出的IDP投影技术能够为双曲系统提供一种可证明的、保持物理性质的自适应数值方法，且具有更高的精度和效率，同时避免了特设校正。

> **ai_Abstract:** 本文提出了一种针对双曲系统自适应网格细化的严格、守恒的不变域保持（IDP）投影技术。该技术通过在解空间映射时强制保持在物理隐含的凸集中，确保了物理性质的守恒。与合适的细化指示器结合，该方法为双曲系统提供了可证明的IDP自适应数值解法。实验结果表明，该方案在避免特设校正的同时，显著提高了计算精度和效率。

> **摘要翻译:** 我们提出了一种严格的、守恒的不变域保持（IDP）投影技术，用于分层离散化，在解空间之间映射时强制保持在物理隐含的凸集中。当与合适的细化指示器结合时，所提出的方案能够为物理性质保持至关重要的双曲系统提供一种可证明的IDP自适应数值方法。除了这些特性的证明，我们还在高性能有限元代码的背景下提供了该方法的详细构造。为了说明我们提出的方案，我们研究了一系列计算上具有挑战性的基准问题，展示了增强的精度和效率特性，同时完全避免了为保持物理不变量而进行的特设校正。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [800] [Symmetry-reduced model reduction of shift-equivariant systems via operator inference](https://arxiv.org/abs/2507.18780)
> *通过算子推断对移位等变系统进行对称性降阶模型约简*

*Yu Shuai, Clarence W. Rowley* | **Category: math.NA, cs.NA, math.OC, physics.comp-ph, 35B06 (Primary), 65D15 (Primary), 68W25 (Primary), 35Q35
  (Secondary), 47A58 (Secondary), G.1.2; G.1.6; I.2.6; J.2** | **Updated: 2025-07-24**

**Keywords:** 移位等变系统, 降阶模型, 算子推断, 行进解, 数值稳定性

**Comment:** 30 pages, 7 figures. Orally presented at the SIAM Conference on
  Applications of Dynamical Systems (SIAM DS25). Submitted to Advances in
  Computational Mathematics (ACOM)

> **TL;DR:** 本文提出了一种新的数据驱动的降阶模型方法，用于处理具有移位等变性的偏微分方程。该方法通过在行进参考系中表示解，并额外估计行进速度，从而更好地捕捉行进解并提高数值稳定性。

**AI_Comments:** 该论文的创新点在于将移位等变系统的特性（行进解）与数据驱动的算子推断方法相结合。通过引入行进参考系和速度估计，作者有效地解决了标准算子推断在处理这类系统时可能遇到的局限性。其重要性在于为分析和模拟具有行进波或模式的复杂系统提供了一种更精确、更稳定的降阶建模工具。在应用方面，这对于涉及流体动力学、化学反应扩散等领域中的行进波现象具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有算子推断方法可以直接从数据中近似降阶模型，但对于具有移位等变性的系统（通常存在行进解），其可能无法充分捕捉解的行进特性。本研究的动机是开发一种改进的算子推断方法，不仅能近似解的空间冻结剖面，还能估计其行进速度，以更好地处理移位等变系统。

**Method:** 该方法考虑了具有移位等变性的偏微分方程的数据驱动降阶模型。核心思想是在一个行进参考系中表示解，这样可以用相对较少的基础函数来描述。在此基础上，对现有的算子推断方法添加了额外的项，以确保降阶模型不仅近似解的空间冻结剖面，还能估计作为该剖面函数的行进速度。

**Result:** 该方法在Kuramoto-Sivashinsky方程上的验证结果表明，该方法能够稳健地捕捉行进解，并且比标准算子推断方法表现出更高的数值稳定性。

**Conclusion:** 通过在行进参考系中表示解并额外估计行进速度，所提出的对称性降阶模型约简方法能够有效且稳健地处理具有移位等变性的偏微分方程，并显著提高了数值稳定性。

> **ai_Abstract:** 本研究提出了一种针对具有移位等变性的偏微分方程的数据驱动降阶模型新方法。该方法的核心在于在行进参考系中表示解，并对传统的算子推断方法进行扩展，使其能够同时近似解的空间剖面并估计其行进速度。通过在Kuramoto-Sivashinsky方程上的验证，结果显示该方法能够稳健地捕捉行进解，并显著提升了数值稳定性。

> **摘要翻译:** 我们考虑了具有移位等变性的偏微分方程的数据驱动降阶模型。移位等变系统通常存在行进解，我们方法的主要思想是在一个行进参考系中表示解，在该参考系中，解可以用相对较少的基础函数来描述。现有的算子推断方法允许直接从数据中近似降阶模型，而无需了解全阶动力学。我们的方法增加了额外的项，以确保降阶模型不仅近似解的空间冻结剖面，还能估计作为该剖面函数的行进速度。我们使用Kuramoto-Sivashinsky方程验证了我们的方法，该方程是一个一维偏微分方程，表现出行进解和时空混沌。结果表明，我们的方法能够稳健地捕捉行进解，并且比标准算子推断方法表现出更高的数值稳定性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [835] [Fourth-Order Compact FDMs for Steady and Time-Dependent Nonlinear Convection-Diffusion Equations](https://arxiv.org/abs/2507.18799)
> *稳态和瞬态非线性对流-扩散方程的四阶紧致有限差分法*

*Qiwei Feng, Catalin Trenchea* | **Category: math.NA, cs.NA** | **Updated: 2025-07-24**

**Keywords:** 有限差分法, 对流-扩散方程, 非线性方程, 四阶, 紧致格式

**Comment:** 22 pages and 6 figures

> **TL;DR:** 本文提出并验证了求解稳态和瞬态非线性对流-扩散方程的四阶紧致有限差分方法，这些方法通过迭代线性化和减少污染效应，实现了高精度和高效性，尤其在与间断伽辽金方法比较时显示出显著优势。

**AI_Comments:** 本文为解决复杂的非线性对流-扩散问题提供了一种鲁棒且高精度的方法。其创新之处在于将迭代线性化与高阶紧致FDM相结合，并进行特定修改以减少污染效应。所展示的优越性能，特别是在与DG方法进行比较时，凸显了其在对精度要求严格的数值模拟中的实际重要性。可扩展到三维和更一般方程的特性进一步拓宽了其适用性。

<details>
  <summary>Details</summary>

**Motivation:** 为了准确高效地求解具有Dirichlet边界条件的稳态和瞬态非线性对流-扩散方程，这些方程因其非线性和对高阶精度的需求而具有挑战性。

**Method:** 对于稳态非线性方程，采用迭代方法将其转化为线性形式，并推导了在均匀笛卡尔网格上的四阶紧致9点有限差分法（FDM），同时修改FDM以减少污染效应。对于瞬态非线性方程，采用Crank-Nicolson (CN)、BDF3、BDF4时间步进方法离散时间域，并应用类似的迭代方法将非线性方程重写为相同的线性对流-扩散方程，然后提出了二阶到四阶的紧致9点FDM，同样减少了污染效应。

**Result:** 稳态FDM的线性系统在网格尺寸足够小时能生成M-矩阵。所有FDM在网格尺寸足够小时都满足离散最大值原理。通过对具有可变和时变扩散系数以及挑战性非线性项的例子验证了方法在$l_2$和$l_{\infty}$范数下的精度和期望收敛率。与第三阶BDF3方法和间断伽辽金（DG）方法比较，本文提出的二阶CN方法以及BDF3方案在粗时间步长下能产生更小的误差，特别是当应用相同的BDF3方案时，误差仅为DG方法所得误差的1.6%。

**Conclusion:** 本文提出的四阶紧致有限差分方法能够高精度、高效率地求解稳态和瞬态非线性对流-扩散方程，数值结果表明其性能优于现有方法（如DG方法），并且可以很容易地扩展到三维空间域和更一般的非线性对流-扩散-反应方程。

> **ai_Abstract:** 本文提出并讨论了求解稳态和瞬态非线性对流-扩散方程的四阶紧致有限差分方法。通过迭代方法将非线性方程转化为线性形式，并结合改进的9点FDM，有效降低了污染效应。所提出的方法在理论上满足离散最大值原理，并通过数值实验验证了其在不同条件下的高精度和期望收敛率，尤其在与DG方法比较时，显示出显著的误差优势。这些方法易于推广到三维和更复杂的方程。

> **摘要翻译:** 本文讨论了具有Dirichlet边界条件的稳态和瞬态非线性对流-扩散（平流-扩散）方程。对于稳态非线性方程，我们使用迭代方法将其重构为线性形式，并推导出了在均匀笛卡尔网格上求解该重构方程的四阶紧致9点有限差分法（FDM）。为了提高精度，我们修改了FDM以减少污染效应。在网格尺寸$h$足够小的情况下，FDM的线性系统生成一个M-矩阵。对于瞬态非线性方程，我们使用Crank-Nicolson (CN)、BDF3、BDF4时间步进方法离散时间域，并应用类似的迭代方法将非线性方程重写为相同的线性对流-扩散方程。然后，我们提出了在均匀笛卡尔网格上具有减少污染效应的二阶到四阶紧致9点FDM。我们证明了所有FDM在$h$足够小时都满足离散最大值原理。提供了几个具有可变和时变扩散系数以及挑战性非线性项（不限于Burgers方程）的例子，以验证在空间和时间上的$l_2$和$l_{\infty}$范数下的精度和期望收敛率。我们还将我们的二阶CN方法与三阶BDF3方法和间断伽辽金（DG）方法进行了比较，数值结果表明我们的FDM在粗时间步长下能产生小误差。特别是，如果应用相同的BDF3方案，我们的误差是DG方法所得误差的1.6%。所提出的方法可以很容易地扩展到三维空间域和更一般的非线性对流-扩散-反应方程。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [854] [A stabilized Two-Step Formulation of Maxwell's Equations in the time-domain](https://arxiv.org/abs/2507.18235)
> *时域麦克斯韦方程组的稳定两步公式*

*Leon Herles, Mario Mally, Jörg Ostrowski, Sebastian Schöps, Melina Merkel* | **Category: math.NA, cs.CE, cs.NA** | **Updated: 2025-07-24**

**Keywords:** 麦克斯韦方程组, 时域, 低频不稳定性, 稳定化, 伽辽金离散化

**Comment:** 6 pages, 9 figures

> **TL;DR:** 本文提出了一种稳定的时域两步麦克斯韦方程组公式，有效解决了低频数值不稳定性问题，并适用于非线性、温度相关材料的模拟。

**AI_Comments:** 这项工作在解决时域电磁场模拟中的低频不稳定性方面具有重要意义。引入广义树余树规范以确保在静态极限下的鲁棒性是一个关键的创新点。该方法对非线性、温度相关材料的适用性也增强了其实用价值和应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 模拟跨宽频率范围的电磁场时，由于低频数值不稳定性，会面临挑战。

**Method:** 本工作将麦克斯韦方程组的稳定两步公式扩展到时域。在空间上采用伽辽金离散化，时间上应用两种定制的时间离散方案，分别针对两步求解过程中的一阶和二阶时间偏微分方程。为解决低频不稳定性，引入了广义树余树规范（generalized tree-cotree gauge）以消除旋度-旋度算子的奇异性。

**Result:** 在学术和应用导向的3D问题上的数值结果证实了该方法的稳定性、准确性，以及对非线性、温度相关材料的适用性。

**Conclusion:** 该方法成功解决了时域电磁场模拟中的低频不稳定性问题，并对复杂材料具有良好的适用性，为电磁场模拟提供了稳定的解决方案。

> **ai_Abstract:** 本文提出了一种时域麦克斯韦方程组的稳定两步公式，旨在解决电磁场模拟中常见的低频数值不稳定性问题。该方法结合了伽辽金空间离散化和针对不同阶偏微分方程的定制时间离散方案，并通过引入广义树余树规范有效消除了旋度-旋度算子的奇异性。数值实验证明，该方法在3D问题上具有良好的稳定性、准确性，并能成功应用于非线性、温度相关的材料。

> **摘要翻译:** 模拟跨宽频率范围的电磁场由于低频时的数值不稳定性而具有挑战性。这项工作将麦克斯韦方程组的稳定两步公式扩展到时域。在空间上使用伽辽金离散化，我们应用了两种不同的时间离散方案，这些方案是为此处使用的两步求解过程中的一阶和二阶时间偏微分方程量身定制的。为了解决低频不稳定性，我们引入了一种广义树余树规范，该规范消除了旋度-旋度算子的奇异性，即使在静态极限下也能确保鲁棒性。在学术和应用导向的3D问题上的数值结果证实了该方法的稳定性、准确性以及对非线性、温度相关材料的适用性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [879] [Neural Correction Operator: A Reliable and Fast Approach for Electrical Impedance Tomography](https://arxiv.org/abs/2507.18875)
> *神经网络校正算子：一种可靠快速的电阻抗断层成像方法*

*Amit Bhat, Ke Chen, Chunmei Wang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-25**

**Keywords:** 电阻抗断层成像, 神经校正算子, 病态问题, 深度学习, 逆问题

**Comment:** 

> **TL;DR:** 针对电阻抗断层成像（EIT）中神经网络直接算子学习的不可靠性，本研究提出了一种神经校正算子框架，结合L-BFGS优化进行初始估计和深度学习模型进行校正，显著提高了重建质量、鲁棒性并大幅提升了计算速度，为解决严重病态逆问题提供了通用范式。

**AI_Comments:** 该论文的创新之处在于将传统的迭代优化（L-BFGS）与深度学习相结合，以解决电阻抗断层成像（EIT）的严重病态性问题。这种混合方法通过先获取初始估计再进行深度学习校正，有效提升了重建的可靠性和速度，为其他类似的病态逆问题提供了一个通用的解决范式。

<details>
  <summary>Details</summary>

**Motivation:** 电阻抗断层成像（EIT）是一种非侵入式医学成像方法，但其严重的病态性使得神经网络直接算子学习变得不可靠。

**Method:** 提出了神经校正算子框架，将逆映射学习为两个算子的组合：一个使用L-BFGS优化并限制迭代次数以从测量数据获取初始估计的重建算子；一个使用深度学习模型（如卷积神经网络架构和条件扩散模型）实现的校正算子，用于从初始猜测中重建真实介质。通过与L-BFGS方法以及直接学习逆映射的神经算子和条件扩散模型进行比较评估。

**Result:** 与迭代方法和相同架构的直接神经算子学习方法相比，该方法实现了显著更好的重建质量。所提出的框架还对测量噪声表现出鲁棒性，同时与传统方法相比，计算速度大幅提升。

**Conclusion:** 神经校正算子为解决严重病态的逆问题中的神经算子学习提供了一个通用范式。

> **ai_Abstract:** 本文针对电阻抗断层成像（EIT）中因严重病态性导致的神经网络直接算子学习不可靠的问题，提出了一种神经校正算子框架。该框架将逆映射分解为两个阶段：首先使用L-BFGS优化获得初始重建，然后利用深度学习模型（如CNN或条件扩散模型）对初始估计进行校正。数值实验表明，与传统迭代方法和直接神经算子学习方法相比，该方法显著提高了重建质量，同时对测量噪声具有鲁棒性并大幅提升了计算速度。该框架为解决严重病态逆问题中的神经算子学习提供了一种通用且有效的方法。

> **摘要翻译:** 电阻抗断层成像（EIT）是一种非侵入式医学成像方法，通过边界电压-电流测量重建电导率介质，但其严重的病态性使得神经网络直接算子学习变得不可靠。我们提出了神经校正算子框架，该框架将逆映射学习为两个算子的组合：一个使用L-BFGS优化并限制迭代次数从测量数据获取初始估计的重建算子，以及一个使用深度学习模型实现的校正算子，用于从初始猜测中重建真实介质。我们探索了卷积神经网络架构和条件扩散模型作为校正算子的替代选择。我们通过与L-BFGS方法以及直接学习逆映射的神经算子和条件扩散模型在多个基准数据集上进行比较，评估了神经校正算子。我们的数值实验表明，与迭代方法和相同架构的直接神经算子学习方法相比，我们的方法实现了显著更好的重建质量。所提出的框架还对测量噪声表现出鲁棒性，同时与传统方法相比，计算速度大幅提升。神经校正算子为解决严重病态的逆问题中的神经算子学习提供了一个通用范式。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [123] [HH-Codec: High Compression High-fidelity Discrete Neural Codec for Spoken Language Modeling](https://arxiv.org/abs/2507.18897)
> *HH-Codec：高压缩高保真离散神经编解码器，用于口语建模*

*Rongkun Xue, Yazhe Niu, Shuai Hu, Zixin Yin, Yongqiang Yao, Jing Yang* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-07-25**

**Keywords:** 离散神经编解码器, 语音标记化, 高压缩, 高保真, 口语建模

**Comment:** 

> **TL;DR:** HH-Codec是一种新的神经编解码器，通过单量化器推理实现对24 kHz音频的极端压缩（24 tokens/s）和0.3 kbps的超低带宽，同时保持最先进的语音重建高保真度。

**AI_Comments:** 该论文的创新点在于提出了HH-Codec，它通过单量化器推理、精心设计的VQ空间和非对称编解码器架构，有效解决了大规模语音系统中的高计算成本和带宽问题。其在实现极高压缩比（0.3 kbps）的同时保持了高保真语音重建的SOTA性能，这对于资源受限或需要高效传输的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在大规模语音到语音系统中，多量化器并行流的复杂性和高时间维度编解码器的计算成本构成了重大挑战。

**Method:** 本文介绍了HH-Codec，一种神经编解码器，通过单量化器推理实现24 kHz音频每秒24个token的极端压缩。该方法涉及为口语建模精心设计的向量量化（VQ）空间，以优化压缩效率并最小化信息损失。在此基础上，提出了一个非对称编码器-解码器架构（Audio-VQ-Mel-Audio），利用双重监督和渐进式训练来增强重建稳定性和保真度。

**Result:** HH-Codec在语音重建方面取得了最先进的性能，带宽超低（0.3 kbps），并实现了24 kHz音频每秒24个token的极端压缩。研究进一步评估了其在码本利用和生成模型适应性方面的有效性，并通过广泛的消融实验验证了每个模块的必要性。

**Conclusion:** HH-Codec通过其创新的设计（包括单量化器推理、优化的VQ空间和非对称架构），成功解决了传统语音编解码器在大规模系统中的挑战，实现了卓越的高压缩和高保真语音重建性能，并被证明在实际应用中有效。

> **ai_Abstract:** HH-Codec是一种新型的离散神经编解码器，旨在解决大规模语音系统中的复杂性和计算成本挑战。它通过独特的单量化器推理、为口语建模优化的向量量化空间以及非对称编码器-解码器架构，实现了对24 kHz音频的极端压缩（24 tokens/s）和0.3 kbps的超低带宽，同时在语音重建方面达到了最先进的高保真性能。该研究还通过消融实验验证了其模块的有效性。

> **摘要翻译:** 离散语音标记化是语音编解码器中的一个基本组成部分。然而，在大规模语音到语音系统中，来自多个量化器的并行流的复杂性以及高时间维度编解码器的计算成本带来了重大挑战。在本文中，我们介绍了HH-Codec，这是一种神经编解码器，它在24 kHz音频下实现了每秒24个token的极端压缩，同时依赖于单量化器推理。我们的方法涉及为口语建模精心设计的向量量化空间，优化压缩效率，同时最大限度地减少信息损失。在此基础上，我们提出了一种非对称编码器-解码器架构（Audio-VQ-Mel-Audio），该架构利用双重监督和渐进式训练来增强重建的稳定性和保真度。HH-Codec以0.3 kbps的超低带宽在语音重建方面取得了最先进的性能。我们进一步评估了其在码本利用和生成模型适应性方面的有效性，并通过广泛的消融实验验证了每个模块的必要性。HH-Codec可在https://github.com/opendilab/HH-Codec上获取。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [185] [MLLM-based Speech Recognition: When and How is Multimodality Beneficial?](https://arxiv.org/abs/2507.19037)
> *基于MLLM的语音识别：多模态何时以及如何有益？*

*Yiwen Guan, Viet Anh Trinh, Vivek Voleti, Jacob Whitehill* | **Category: cs.SD, cs.CL, cs.MM, eess.AS** | **Updated: 2025-07-25**

**Keywords:** 多模态大型语言模型, 自动语音识别, 噪声环境, 模态融合, Mamba

**Comment:** 

> **TL;DR:** 本文研究了在嘈杂环境下，多模态输入如何以及何时能提高基于MLLM的自动语音识别（ASR）准确性，发现多模态通常有益，其效果取决于噪声水平、模态同步性、视觉表征质量以及输入顺序和权重。

**AI_Comments:** 这篇论文探讨了多模态在语音识别中的应用，特别关注了其在噪声环境下的效益，具有重要的实践意义。其创新之处在于系统性地分析了不同模态、噪声水平、模型架构以及输入策略对ASR性能的影响。特别是对同步与非同步模态效益差异的揭示，以及对视觉编码器质量重要性的强调，为未来多模态ASR系统的设计提供了明确的方向。此外，对Mamba模型表现的验证也增加了其研究的广度。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型（MLLMs）为语音、文本、图像等模态的统一建模开辟了新的可能性。本文旨在探究在何种条件下以及采用何种模型架构，多模态输入能够提高嘈杂环境下的自动语音识别（ASR）准确性。

**Method:** 通过在合成数据和真实世界数据上进行实验。

**Result:** 1. 利用更多模态通常能提高ASR准确性，因为每种模态都提供互补信息，但改进程度取决于听觉噪声的量。2. 同步模态（如唇部动作）在高噪声水平下更有用，而非同步模态（如图像上下文）在中等噪声水平下最有用。3. 更高质量的视觉表征持续提高ASR准确性，这凸显了开发更强大视觉编码器的重要性。4. Mamba在多模态效益方面表现出与Transformers相似的趋势。5. 模态的输入顺序以及它们在损失函数中的权重可以显著影响准确性。

**Conclusion:** 这些发现既提供了实用的见解，也有助于加深我们对挑战性条件下多模态语音识别的理解。

> **ai_Abstract:** 本文探讨了在嘈杂环境下，基于多模态大型语言模型（MLLMs）的语音识别中，多模态输入的效益。研究通过实验发现，增加模态通常能提高ASR准确性，但其效果受噪声水平、模态同步性（如唇部动作在高噪声下更有效，图像上下文在中等噪声下更有效）、视觉表征质量、以及模态输入顺序和损失权重的影响。研究还指出Mamba模型在多模态效益上与Transformers表现相似。这些发现为多模态语音识别提供了实用指导和深入理解。

> **摘要翻译:** 多模态大型语言模型（MLLMs）的最新进展为语音、文本、图像和其他模态的统一建模开辟了新的可能性。本文在我们先前工作的基础上，研究了在何种条件和模型架构下，多个输入模态可以提高嘈杂环境下的自动语音识别（ASR）准确性。通过在合成数据和真实世界数据上的实验，我们发现：(1) 利用更多模态通常能提高ASR准确性，因为每种模态都提供互补信息，但改进程度取决于听觉噪声的量。(2) 同步模态（例如唇部动作）在高噪声水平下更有用，而非同步模态（例如图像上下文）在中等噪声水平下最有用。(3) 更高质量的视觉表征持续提高ASR准确性，这凸显了开发更强大视觉编码器的重要性。(4) Mamba在多模态效益方面表现出与Transformers相似的趋势。(5) 模态的输入顺序以及它们在损失函数中的权重可以显著影响准确性。这些发现既提供了实用的见解，也有助于加深我们对挑战性条件下多模态语音识别的理解。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [249] [From Continuous to Discrete: Cross-Domain Collaborative General Speech Enhancement via Hierarchical Language Models](https://arxiv.org/abs/2507.19062)
> *从连续到离散：基于分层语言模型的跨域协作通用语音增强*

*Zhaoxi Mu, Rilin Chen, Andong Li, Meng Yu, Xinyu Yang, Dong Yu* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-25**

**Keywords:** 通用语音增强, 分层语言模型, 跨域协作, 复合失真, 连续到离散

**Comment:** ACMMM 2025

> **TL;DR:** OmniGSE是一个新的通用语音增强框架，通过两阶段架构（连续特征增强和离散令牌生成）和分层语言模型，有效处理多种语音失真，并在复合失真场景下表现出色。

**AI_Comments:** 该论文的创新点在于提出了一个能够同时处理多种复杂语音失真的通用语音增强框架OmniGSE，解决了现有方法仅关注单一失真的局限性。其两阶段的“从连续到离散”处理范式，结合判别式和生成式方法的优点，以及引入分层语言模型来建模不同级别的声学特征，都为通用语音增强领域提供了新的思路和强大的解决方案。特别是在复合失真场景下的优异表现，凸显了其在实际应用中的重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有语音增强方法通常只专注于优化单一类型的失真，难以有效处理现实世界中语音信号同时存在的多种失真（如背景噪声、混响、带宽限制、信号削波和网络丢包）。

**Method:** OmniGSE采用两阶段架构，结合了判别式和生成式方法的优点，实现跨域协作优化。第一阶段使用轻量级通道分离的NAC-RoFormer增强连续特征。第二阶段通过语言模型生成离散令牌以重建高质量语音，其中设计了由RootLM和多个BranchLM组成的分层语言模型结构，RootLM建模跨码本层的通用声学特征，BranchLMs捕捉不同码本级别之间的渐进关系。

**Result:** 实验结果表明，OmniGSE在多个基准测试中超越了现有模型，尤其在涉及复合失真的场景中表现突出。

**Conclusion:** OmniGSE框架在现实世界的应用中具有鲁棒和多功能的语音增强潜力，能够有效处理多种复杂的语音失真。

> **ai_Abstract:** OmniGSE是一种新颖的通用语音增强框架，旨在解决现实世界中语音信号面临的多种复合失真问题。它采用两阶段跨域协作优化架构，首先使用NAC-RoFormer增强连续特征，然后通过独特的分层语言模型（RootLM和BranchLMs）生成离散令牌重建高质量语音。实验证明，OmniGSE在处理复合失真方面优于现有模型，展现了其在实际应用中的强大潜力和多功能性。

> **摘要翻译:** 本文介绍了一种名为OmniGSE的新型通用语音增强（GSE）框架，旨在减轻语音信号在现实世界场景中遇到的各种失真。这些失真包括背景噪声、混响、带宽限制、信号削波和网络丢包。现有方法通常侧重于优化单一类型的失真，在复杂场景中难以有效处理多种失真同时存在的情况。OmniGSE通过两阶段架构整合判别式和生成式方法的优点，弥补了这一差距，从而实现跨域协作优化。在第一阶段，使用轻量级通道分离的NAC-RoFormer增强连续特征。在第二阶段，通过语言模型生成离散令牌以重建高质量语音。具体来说，我们设计了一种由RootLM和多个BranchLM组成的分层语言模型结构。RootLM建模跨码本层的通用声学特征，而BranchLM则明确捕捉不同码本级别之间的渐进关系。实验结果表明，OmniGSE在多个基准测试中超越了现有模型，尤其在涉及复合失真的场景中表现出色。这些发现强调了该框架在现实世界应用中实现鲁棒和多功能语音增强的潜力。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [305] [Latent Granular Resynthesis using Neural Audio Codecs](https://arxiv.org/abs/2507.19202)
> *使用神经音频编解码器的潜在颗粒重合成*

*Nao Tokui, Tom Baker* | **Category: cs.SD, cs.LG, eess.AS, eess.SP** | **Updated: 2025-07-25**

**Keywords:** 潜在颗粒重合成, 神经音频编解码器, 颗粒合成, 音频重合成, 音色转移

**Comment:** Accepted at ISMIR 2025 Late Breaking Demos

> **TL;DR:** 本文介绍了一种使用神经音频编解码器在潜在向量级别进行颗粒重合成的新技术，通过创建“颗粒码本”并匹配潜在颗粒来将目标音频的音色与源音频的音色混合，同时保持目标音频的时间结构。

**AI_Comments:** 这项研究的创新之处在于将颗粒合成的概念提升到潜在向量层面，并结合神经音频编解码器，从而在无需模型训练的情况下实现高质量的音频重合成。其重要性在于解决了传统拼接合成的固有问题，即不连续性，并提供了一个灵活且高效的创意音频工具。该方法能够同时保留目标音频的时间结构并融入源音频的音色特征，这在音频内容创作和转换方面具有巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是开发一种新颖的创意音频重合成技术，该技术能够避免传统拼接合成中常见的听觉不连续性，并能处理多样化的音频材料，且无需模型训练。

**Method:** 该方法通过将源音频语料库编码成潜在向量片段来创建“颗粒码本”。然后，将目标音频信号的每个潜在颗粒与码本中最接近的对应物进行匹配。最后，将得到的混合序列解码以生成音频。

**Result:** 该技术无需模型训练，适用于多样化的音频材料，并且通过编解码器在解码过程中的隐式插值，自然地避免了传统拼接合成中典型的不连续性。生成的音频保留了目标的时间结构，同时采用了源的音色特征。

**Conclusion:** 本文提出了一种新颖的潜在颗粒重合成技术，利用神经音频编解码器在潜在向量级别进行操作，成功实现了创意音频重合成，并解决了传统拼接合成的局限性，提供了高质量的音频输出。

> **ai_Abstract:** 本文提出了一种名为“潜在颗粒重合成”的创新音频处理技术。该方法利用神经音频编解码器，将源音频编码为潜在向量的“颗粒码本”。在重合成时，它将目标音频的潜在颗粒与码本中的最接近项进行匹配，然后解码生成的混合序列。这种方法能够将源音频的音色特征融入目标音频的时间结构中，且无需模型训练，适用于多种音频类型，并有效避免了传统拼接合成中常见的听觉不连续性。

> **摘要翻译:** 我们引入了一种新颖的创意音频重合成技术，该技术通过在潜在向量级别重新设计颗粒合成的概念来操作。我们的方法通过将源音频语料库编码成潜在向量片段来创建一个“颗粒码本”，然后将目标音频信号的每个潜在颗粒与其在码本中最接近的对应物进行匹配。由此产生的混合序列被解码以生成音频，该音频保留了目标的时间结构，同时采用了源的音色特性。这项技术不需要模型训练，适用于多样化的音频材料，并且通过编解码器在解码过程中的隐式插值，自然地避免了传统拼接合成中典型的不连续性。我们在 https://github.com/naotokui/latentgranular/ 提供了补充材料，以及一个概念验证实现，允许用户在 https://huggingface.co/spaces/naotokui/latentgranular 尝试自己的声音。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [350] [Benchmarking Cross-Domain Audio-Visual Deception Detection](https://arxiv.org/abs/2405.06995)
> *跨领域视听欺骗检测基准测试*

*Xiaobao Guo, Zitong Yu, Nithish Muthuchamy Selvaraj, Bingquan Shen, Adams Wai-Kin Kong, Alex C. Kot* | **Category: cs.SD, cs.CV, cs.MM, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 欺骗检测, 跨领域, 视听, 泛化, 基准测试

**Comment:** 15 pages

> **TL;DR:** 论文提出了首个跨领域视听欺骗检测基准，评估现有方法的泛化能力，并引入了MM-IDGM算法和Attention-Mixer融合方法以提升性能。

**AI_Comments:** 本文的创新点在于构建了首个跨领域视听欺骗检测基准，填补了现有研究在模型泛化能力评估上的空白。同时，提出的MM-IDGM算法和Attention-Mixer融合方法为提升跨领域欺骗检测性能提供了新的思路。该基准对于推动未来视听欺骗检测在真实世界场景中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动化欺骗检测对评估真实性至关重要，但现有视听欺骗检测方法在不同场景下的泛化能力尚未得到充分探索。

**Method:** 论文建立了首个跨领域视听欺骗检测基准，使用广泛采用的音视频特征和不同架构进行基准测试，比较了单域到单域和多域到单域的泛化性能。研究了三种域采样策略（域同时、域交替、域逐域），并提出了通过最大化模态编码器之间梯度内积的MM-IDGM算法以及Attention-Mixer融合方法来增强泛化性能。

**Result:** 论文提出了MM-IDGM算法以增强泛化性能，并通过Attention-Mixer融合方法提高了性能。

**Conclusion:** 论文提出的新跨领域基准将促进未来在视听欺骗检测领域的研究。

> **ai_Abstract:** 本文针对现有视听欺骗检测方法在不同场景下泛化能力不足的问题，首次提出了一个跨领域视听欺骗检测基准。该基准用于评估现有方法的泛化性能，并比较了单域到单域及多域到单域的泛化表现。研究还探讨了多源域数据训练的三种域采样策略，并提出了MM-IDGM算法和Attention-Mixer融合方法以提升模型的泛化能力和整体性能。

> **摘要翻译:** 自动化欺骗检测对于协助人类准确评估真实性和识别欺骗行为至关重要。传统的接触式技术，如测谎仪，依赖生理信号来确定个体陈述的真实性。然而，自动化欺骗检测的最新进展表明，从音频和视频模态导出的多模态特征在公开数据集上可能优于人类观察者。尽管取得了这些积极的发现，但现有视听欺骗检测方法在不同场景下的泛化能力在很大程度上仍未被探索。为了弥补这一空白，我们提出了第一个跨领域视听欺骗检测基准，使我们能够评估这些方法在现实世界场景中的泛化能力。我们使用广泛采用的音频和视觉特征以及不同的架构进行基准测试，比较了单域到单域和多域到单域的泛化性能。为了进一步利用来自多个源域的数据进行训练的影响，我们研究了三种域采样策略，包括域同时、域交替和域逐域，用于多域到单域泛化评估。我们还提出了一种通过最大化模态编码器之间梯度内积来增强泛化性能的算法，名为“MM-IDGM”。此外，我们提出了Attention-Mixer融合方法以提高性能，我们相信这个新的跨领域基准将促进未来在视听欺骗检测领域的研究。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [361] [Face2VoiceSync: Lightweight Face-Voice Consistency for Text-Driven Talking Face Generation](https://arxiv.org/abs/2507.19225)
> *Face2VoiceSync：轻量级文本驱动会说话的人脸生成中的人脸-语音一致性*

*Fang Kang, Yin Cao, Haoyu Chen* | **Category: cs.SD, cs.CV, cs.MM, eess.AS** | **Updated: 2025-07-25**

**Keywords:** 文本驱动人脸生成, 语音-人脸一致性, 轻量级模型, 副语言特征, Face2VoiceSync

**Comment:** 

> **TL;DR:** Face2VoiceSync 提出了一种新的框架，用于从人脸图像和文本生成会说话的人脸动画及其对应的语音。它解决了现有方法对固定驱动语音的依赖问题，实现了语音与人脸的对齐、语音多样性控制、高效训练，并在单一GPU上达到了视觉和音频的最新性能。

**AI_Comments:** 本文的创新点在于将文本驱动的会说话人脸生成任务扩展到同时生成人脸动画和匹配语音，解决了现有语音驱动方法中人脸-语音不匹配的限制。其轻量级 VAE 设计显著降低了训练参数，提高了效率，使其能够在单张 GPU 上运行并达到最先进的性能，这对于实际应用具有重要意义。新提出的评估指标也有助于更全面地评估生成结果的质量。

<details>
  <summary>Details</summary>

**Motivation:** 现有语音驱动的会说话人脸生成方法依赖于固定的驱动语音，这限制了其进一步的应用，例如导致人脸与语音不匹配的问题。因此，本文旨在解决一个更具挑战性的任务：给定人脸图像和文本，生成会说话的人脸动画及其对应的语音。

**Method:** 本文提出了一个名为 Face2VoiceSync 的新颖框架，包含以下几个贡献：1) 语音-人脸对齐：确保生成的语音与面部外观匹配；2) 多样性与操控：使生成的语音能够控制副语言特征空间；3) 高效训练：使用轻量级 VAE 连接视觉和音频大型预训练模型，训练参数显著少于现有方法；4) 新的评估指标：公平评估多样性和身份一致性。

**Result:** 实验结果表明，Face2VoiceSync 在单一 40GB GPU 上实现了视觉和音频方面的最先进性能。

**Conclusion:** Face2VoiceSync 成功地解决了文本驱动的会说话人脸生成中的人脸-语音一致性问题，通过其创新的框架和轻量级设计，在视觉和音频质量上都达到了顶尖水平，并且效率高。

> **ai_Abstract:** Face2VoiceSync 提出了一种解决文本驱动会说话人脸生成中人脸-语音不匹配问题的新框架。该方法通过引入语音-人脸对齐、语音多样性控制、基于轻量级 VAE 的高效训练以及新的评估指标，实现了从人脸图像和文本生成高质量、一致的会说话人脸动画和对应语音。实验证明其在视觉和音频性能上均达到SOTA，且计算效率高。

> **摘要翻译:** 最近在语音驱动的会说话人脸生成方面的研究取得了可喜的成果，但它们对固定驱动语音的依赖限制了进一步的应用（例如，人脸-语音不匹配）。因此，我们将任务扩展到一个更具挑战性的设置：给定一张人脸图像和要说的文本，生成会说话的人脸动画及其对应的语音。相应地，我们提出了一个新颖的框架 Face2VoiceSync，具有几项新颖的贡献：1) 语音-人脸对齐：确保生成的语音与面部外观匹配；2) 多样性与操控：使生成的语音能够控制副语言特征空间；3) 高效训练：使用轻量级 VAE 连接视觉和音频大型预训练模型，训练参数显著少于现有方法；4) 新的评估指标：公平评估多样性和身份一致性。实验表明 Face2VoiceSync 在单一 40GB GPU 上实现了视觉和音频方面的最先进性能。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [416] [The Eloquence team submission for task 1 of MLC-SLM challenge](https://arxiv.org/abs/2507.19308)
> *Eloquence团队在MLC-SLM挑战任务1中的提交*

*Lorenzo Concina, Jordi Luque, Alessio Brutti, Marco Matassoni, Yuchen Zhang* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-25**

**Keywords:** 多语言语音识别, 对话语音模型, MLC-SLM挑战, 自动语音识别, 对比学习

**Comment:** Technical Report for MLC-SLM Challenge of Interspeech2025

> **TL;DR:** 本文介绍了Eloquence团队为MLC-SLM挑战任务1所做的研究和实验，该任务旨在通过开发语音语言模型架构来推进多语言对话语音识别。论文探讨了三种多语言ASR方法，包括评估基线模型、利用SLAM-ASR框架以及研究对比学习和扩展对话上下文的作用。

**AI_Comments:** 本文作为MLC-SLM挑战的提交，重点在于其对多语言对话语音识别领域的技术探索和方法论贡献。它通过评估现有基线、利用特定框架和引入对比学习等多种策略，展示了团队在解决复杂多语言ASR问题上的努力。虽然摘要中未提及具体结果，但所提出的研究方向和方法对于推进该领域的发展具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在推进多语言对话语音识别，通过开发语音语言模型架构来应对真实世界对话数据在构建鲁棒语音对话系统中的日益增长的重要性。

**Method:** 本文探讨了三种多语言ASR方法：
1. 评估官方基线模型，通过使用不同的基础模型训练线性投影器和qformer投影器来理解其优缺点。
2. 利用SLAM-ASR框架训练自定义的多语言线性投影器。
3. 研究对比学习和扩展对话上下文在增强识别鲁棒性方面的作用。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了Eloquence团队针对多语言对话语音语言模型（MLC-SLM）挑战任务1的研究和实验。该研究旨在通过开发语音语言模型架构，提升多语言对话语音识别能力，并应对真实世界对话数据在构建鲁棒语音对话系统中的重要性。文中详细探讨了三种多语言自动语音识别（ASR）方法：评估官方基线模型的性能，利用SLAM-ASR框架训练自定义的多语言线性投影器，以及探究对比学习和扩展对话上下文对识别鲁棒性的影响。

> **摘要翻译:** 在本文中，我们介绍了Eloquence团队为多语言对话语音语言模型（MLC-SLM）挑战和研讨会任务1所进行的研究和实验，该任务侧重于通过开发语音语言模型架构来推进多语言对话语音识别。鉴于真实世界对话数据对于构建鲁棒语音对话系统的日益增长的相关性，我们探索了三种多语言ASR方法。首先，我们通过使用不同的基础模型训练两个投影器（线性投影器和qformer），对官方基线进行了评估，以更好地理解其优点和局限性。其次，我们利用SLAM-ASR框架训练了一个自定义的多语言线性投影器。最后，我们研究了对比学习和扩展对话上下文在增强识别鲁棒性方面的作用。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [515] [LENS-DF: Deepfake Detection and Temporal Localization for Long-Form Noisy Speech](https://arxiv.org/abs/2507.16220)
> *LENS-DF：用于长篇嘈杂语音的深度伪造检测和时间定位*

*Xuechen Liu, Wanying Ge, Xin Wang, Junichi Yamagishi* | **Category: cs.SD, cs.CR, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 音频深度伪造检测, 时间定位, 嘈杂语音, 长时长语音, 自监督学习

**Comment:** Accepted by IEEE International Joint Conference on Biometrics (IJCB)
  2025, Osaka, Japan

> **TL;DR:** LENS-DF 是一个用于在复杂和真实条件下训练和评估音频深度伪造检测和时间定位的新方法，其生成的数据训练的模型表现优于传统方法。

**AI_Comments:** LENS-DF的创新之处在于其综合性的“配方”，特别是能够可控地生成具有复杂真实特征（如长时长、噪声、多说话人）的音频数据，这直接解决了现有深度伪造检测方法在真实世界应用中面临的挑战。其重要性体现在提升了音频深度伪造检测和定位的鲁棒性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有音频深度伪造检测方法在复杂和真实的音频条件下（如长时长、嘈杂、多说话人）表现不佳，因此需要一个能有效应对这些挑战的训练和评估框架。

**Method:** 本文提出了LENS-DF，一个用于训练和评估音频深度伪造检测和时间定位的综合方案。它能生成具有长时长、嘈杂和多说话人等可控特性的音频。检测和定位协议使用基于自监督学习前端和简单后端构建的模型。

**Result:** 使用LENS-DF生成数据训练的模型始终优于通过传统方法训练的模型，证明了LENS-DF在鲁棒音频深度伪造检测和定位方面的有效性和实用性。

**Conclusion:** LENS-DF为在复杂真实条件下进行音频深度伪造检测和时间定位提供了一个有效且实用的解决方案，能够显著提升模型的性能。

> **ai_Abstract:** LENS-DF是一种新颖的音频深度伪造检测和时间定位方法，专为应对长时长、嘈杂和多说话人等复杂现实音频条件而设计。它包含一个可控的音频生成模块和相应的检测协议。实验结果表明，与传统方法相比，使用LENS-DF生成数据训练的模型在性能上表现更优，验证了其在鲁棒音频深度伪造检测和定位中的有效性。

> **摘要翻译:** 本研究引入了LENS-DF，一种新颖且全面的方法，用于在复杂和真实的音频条件下训练和评估音频深度伪造检测和时间定位。该方法的生成部分以可控方式从输入数据集中输出具有几个关键特征的音频，例如更长的持续时间、嘈杂条件以及包含多个说话人。相应的检测和定位协议使用模型。我们基于自监督学习前端和简单后端进行了实验。结果表明，使用LENS-DF生成数据训练的模型始终优于通过传统方法训练的模型，证明了LENS-DF在鲁棒音频深度伪造检测和定位方面的有效性和实用性。我们还对引入的变体进行了消融研究，调查它们对该领域现实挑战的影响和相关性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [600] [Bob's Confetti: Phonetic Memorization Attacks in Music and Video Generation](https://arxiv.org/abs/2507.17937)
> *鲍勃的五彩纸屑：音乐和视频生成中的语音记忆攻击*

*Jaechul Roh, Zachary Novack, Yuefeng Peng, Niloofar Mireshghallah, Taylor Berg-Kirkpatrick, Amir Houmansadr* | **Category: cs.SD, cs.AI, cs.CL, eess.AS** | **Updated: 2025-07-23**

**Keywords:** 语音记忆攻击, 音乐生成, 视频生成, 对抗性语音提示, 多模态生成

**Comment:** 

> **TL;DR:** 研究发现，歌词到歌曲（LS2）和文本到视频模型容易受到语音记忆攻击，即使歌词语义改变，模型也能重新生成训练数据中相似的音视频内容。

**AI_Comments:** 这项研究通过引入“对抗性语音提示”和揭示“语音到视觉反刍”现象，创新性地指出了当前多模态生成模型在训练数据记忆方面的深层漏洞。其重要性在于，它不仅验证了音频生成模型的记忆风险，更拓展到文本到视频模型，揭示了跨模态的潜在安全隐患。这为未来生成式AI的伦理、法律和技术发展提供了重要的警示和研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 歌词到歌曲（LS2）生成模型对训练数据记忆的脆弱性尚未得到充分探索，这引发了对版权、安全和内容来源的担忧。

**Method:** 引入了一种名为对抗性语音提示（Adversarial PhoneTic Prompting, APT）的新型攻击，通过同音替换（例如，将“mom's spaghetti”改为“Bob's confetti”）在语义上改变歌词，但保留其声学结构。使用CLAP、AudioJudge和CoverID等音频域指标评估了LS2模型的记忆化程度。此外，还研究了语音改变的歌词对文本到视频模型视觉记忆的影响。

**Result:** LS2模型（如SUNO和YuE）即使在歌词语义扭曲的情况下，也能重新生成与已知训练内容惊人相似的输出，并在音频域指标上获得高相似度。这种脆弱性存在于多种语言和流派中。更令人惊讶的是，仅语音改变的歌词就能触发文本到视频模型（如Veo 3）的视觉记忆，重建原始音乐视频中的视觉元素（包括角色外观和场景构成），尽管提示中没有视觉线索。作者将此现象称为“语音到视觉反刍”。

**Conclusion:** 这些发现揭示了转录条件下的多模态生成系统中存在一个关键漏洞：仅通过语音提示就可以解锁记忆化的视听内容，这引发了对现代生成系统中版权、安全和内容来源的紧迫问题。

> **ai_Abstract:** 该研究揭示了歌词到歌曲（LS2）和文本到视频生成模型中存在的语音记忆攻击漏洞。通过一种名为对抗性语音提示（APT）的新方法，即使歌词语义被同音替换改变，模型也能重新生成与训练数据高度相似的音频和视频内容。研究发现，这种漏洞在多语言、多流派中普遍存在，并且仅语音修改的歌词就能触发文本到视频模型的视觉记忆。这些发现对生成式AI的版权、安全和内容来源提出了严峻挑战。

> **摘要翻译:** 歌词到歌曲（LS2）生成模型承诺从文本端到端合成音乐，但它们对训练数据记忆的脆弱性仍未得到充分探索。我们引入了对抗性语音提示（APT），这是一种新颖的攻击，其中歌词在语义上被改变，同时通过同音替换（例如，Eminem著名的“mom's spaghetti”→“Bob's confetti”）保留其声学结构。尽管存在这些扭曲，我们发现了一种强大的亚词汇记忆形式：SUNO和YuE等模型重新生成的输出与已知的训练内容惊人地相似，在CLAP、AudioJudge和CoverID等音频域指标上实现了高相似度。这种脆弱性跨多种语言和流派持续存在。更令人惊讶的是，我们发现仅语音改变的歌词就可以触发文本到视频模型的视觉记忆。当用《Lose Yourself》中经过语音修改的歌词进行提示时，Veo 3重建了原始音乐视频中的视觉元素——包括角色外观和场景构成——尽管提示中没有视觉线索。我们将这种现象称为语音到视觉反刍。总而言之，这些发现揭示了转录条件下的多模态生成系统中存在一个关键漏洞：仅语音提示就可以解锁记忆化的视听内容，这引发了关于现代生成系统中版权、安全和内容来源的紧迫问题。示例生成可在我们的演示页面（jrohsc.github.io/music_attack/）上查看。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [841] [SCORE-SET: A dataset of GuitarPro files for Music Phrase Generation and Sequence Learning](https://arxiv.org/abs/2507.18723)
> *SCORE-SET：一个用于音乐短语生成和序列学习的GuitarPro文件数据集*

*Vishakh Begari* | **Category: cs.SD, cs.LG, eess.AS** | **Updated: 2025-07-24**

**Keywords:** GuitarPro, 数据集, 音乐生成, 序列学习, 吉他演奏

**Comment:** 6 pages, 6 figures

> **TL;DR:** SCORE-SET是一个包含Guitar Pro制表文件的数据集，专为吉他音乐生成、序列建模和性能感知学习任务设计，它包含了真实的吉他演奏表现细节。

**AI_Comments:** 该论文的创新点在于构建了一个专门针对吉他演奏细节（如弯音、滑音等）的Guitar Pro数据集，填补了现有数据集在表现力方面的空白。这对于开发更真实、更具表现力的吉他音乐生成和学习模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数据集可能无法充分支持吉他音乐生成、序列建模和性能感知学习任务，特别是缺乏包含吉他演奏细微表现的数据。

**Method:** 该数据集通过将MAESTRO和GiantMIDI中的MIDI音符转换为节奏吉他音轨而构建。这些音轨进一步处理，以包含吉他演奏中典型的各种表现设置，如弯音、滑音、颤音和掌闷，以更好地反映真实吉他演奏的细微差别。

**Result:** 提供了一个名为SCORE-SET的精选Guitar Pro制表文件（.gp5格式）数据集，该数据集专为吉他音乐生成、序列建模和性能感知学习任务而定制，并包含了多种吉他演奏的表现设置。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** SCORE-SET是一个新颖的Guitar Pro文件数据集，它将MAESTRO和GiantMIDI的MIDI数据转换为节奏吉他音轨，并加入了多种真实的吉他演奏表现技巧，旨在支持吉他音乐生成、序列建模和性能感知学习等高级任务。

> **摘要翻译:** 提供了一个精选的Guitar Pro制表文件（.gp5格式）数据集，专为涉及吉他音乐生成、序列建模和性能感知学习的任务而定制。该数据集源自MAESTRO和GiantMIDI中的MIDI音符，这些音符已被改编成节奏吉他音轨。这些音轨经过进一步处理，以包含吉他演奏中典型的各种表现设置，如弯音、滑音、颤音和掌闷，从而更好地反映真实吉他演奏的细微差别。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [847] [Information and motor constraints shape melodic diversity across cultures](https://arxiv.org/abs/2408.12635)
> *信息和运动限制塑造了跨文化的旋律多样性*

*John M McBride, Nahie Kim, Yuri Nishikawa, Mekhmed Saadakeev, Marcus T Pearce, Tsvi Tlusty* | **Category: cs.SD, cs.IT, eess.AS, math.IT, physics.soc-ph** | **Updated: 2025-07-24**

**Keywords:** 旋律多样性, 信息限制, 运动限制, 文化演化, 音乐传播

**Comment:** 

> **TL;DR:** 本研究发现，信息限制而非仅仅运动限制，在塑造跨文化旋律多样性中扮演了关键角色，通过对民谣和艺术音乐的分析，揭示了信息率的权衡以及中间旋律复杂度的普遍性。

**AI_Comments:** 这项研究通过引入“信息限制”的概念，为理解跨文化旋律的普遍特征提供了一个新的视角，超越了传统的“运动限制”解释。其创新之处在于量化了信息率的决定因素，并提出了一个无参数模型来预测旋律特征。这项工作对于音乐学、认知科学和文化演化领域都具有重要意义，揭示了文化传播在塑造艺术形式中的深层机制。

<details>
  <summary>Details</summary>

**Motivation:** 运动限制假说无法解释旋律中所有常见的特征，例如重复、歌曲长度和音阶大小。因此，本研究旨在探究信息限制在塑造这些旋律特征中的作用。

**Method:** 研究测量了来自多个大洲的62个民间旋律语料库和来自欧洲（包括土耳其）的39个艺术音乐语料库中的信息率决定因素。此外，研究还使用了一个无参数模型，利用标度运动、旋律长度和信息率的信息限制来预测经验音阶度分布。

**Result:** 研究发现，在所有社会中，存在多种权衡作用，这些权衡都限制了信息率。相比之下，艺术音乐显示出更长、更复杂的旋律，并且复杂性随时间增加，这表明艺术音乐和民间音乐存在不同的文化演化选择压力。无参数模型成功预测了经验音阶度分布。

**Conclusion:** 研究结果提供了强有力的证据，表明音乐文化传播过程中的信息限制限制了音阶中的音符数量，并暗示了中间旋律复杂度的趋势反映了旋律文化演化中的一个基本限制。

> **ai_Abstract:** 本研究探讨了信息限制在塑造跨文化旋律多样性中的作用，以补充或超越现有运动限制假说的解释。通过分析大量民间和艺术音乐语料库，研究发现信息率存在多种权衡，并且艺术音乐的复杂性更高。一个无参数模型成功地预测了音阶度分布，从而证明了信息限制在文化传播中限制音阶音符数量，并指出中等旋律复杂度是旋律文化演化的一个基本约束。

> **摘要翻译:** 可能的旋律数量巨大得难以估量，然而尽管旋律变异的潜力几乎无限，但来自不同社会的旋律却惊人地相似。运动限制假说解释了某些相似性，例如音阶运动和轮廓形状，但未能解释其他主要的共同特征，例如重复、歌曲长度和音阶大小。在此，我们研究了信息限制在塑造这些旋律特征中的作用。我们测量了跨越多个大洲的62个民间旋律语料库中的信息率决定因素，发现所有这些都作用于限制跨社会的信息率的多种权衡。相比之下，来自欧洲（包括土耳其）的39个艺术音乐语料库显示出更长、更复杂的旋律，并且复杂性随时间增加，这表明艺术音乐和民间音乐中存在不同的文化演化选择压力，这可能归因于书面与口头传播的使用。我们的无参数模型利用音阶运动、旋律长度以及最重要的是信息率的信息限制来预测经验音阶度分布。这些结果提供了强有力的证据，表明音乐文化传播过程中的信息限制限制了音阶中的音符数量，并暗示了中间旋律复杂度的趋势反映了旋律文化演化中的一个基本限制。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [6] [Multi-Year Maintenance Planning for Large-Scale Infrastructure Systems: A Novel Network Deep Q-Learning Approach](https://arxiv.org/abs/2507.18732)
> *大规模基础设施系统多年维护规划：一种新颖的网络深度Q学习方法*

*Amir Fard, Arnold X. -X. Yuan* | **Category: math.OC, cs.AI, cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 深度强化学习, 基础设施资产管理, 多年规划, 可扩展性, 预算约束

**Comment:** 

> **TL;DR:** 该研究提出一种基于深度强化学习的新框架，用于优化大规模基础设施网络的资产维护策略，解决传统方法的扩展性和计算复杂性问题。

**AI_Comments:** 该研究的创新之处在于将深度强化学习应用于大规模基础设施维护，特别是通过分解马尔可夫决策过程和整合预算约束，显著提高了可扩展性和效率。这有望彻底改变大型基础设施网络的管理方式。

<details>
  <summary>Details</summary>

**Motivation:** 传统的维护和修复规划方法在处理预算受限的数千个资产组成的大规模网络时，面临可扩展性和计算挑战。

**Method:** 本文提出一种新颖的深度强化学习（DRL）框架来优化资产管理策略。该框架通过将网络级马尔可夫决策过程（MDP）分解为单独的资产级MDP，并使用统一的神经网络架构，从而降低计算复杂性，提高学习效率和可扩展性。同时，通过预算分配机制直接纳入年度预算限制。

**Result:** 在对一个包含68,800个路段的大型路面网络进行的案例研究中，所提出的DRL框架在效率和网络性能方面均表现出优于渐进式线性规划和遗传算法等传统方法的显著改进。

**Conclusion:** 该深度强化学习框架为基础设施资产管理提供了一种卓越的方法，并展示了强化学习在复杂、大规模环境中的更广泛应用潜力。

> **ai_Abstract:** 本文提出了一种新颖的深度强化学习（DRL）框架，用于大规模基础设施系统的多年维护规划。该框架通过将网络级问题分解为资产级马尔可夫决策过程并结合统一的神经网络架构，以及整合预算约束，解决了传统方法面临的可扩展性和计算复杂性挑战。通过对一个大型路面网络的案例研究，该方法在效率和网络性能方面均显著优于传统优化技术。

> **摘要翻译:** 基础设施资产管理对于维持道路网络、桥梁和公用事业网络等公共基础设施的性能至关重要。传统的维护和修复规划方法经常面临可扩展性和计算挑战，特别是对于预算受限的数千个资产组成的大规模网络。本文提出了一种新颖的深度强化学习（DRL）框架，用于优化大型基础设施网络的资产管理策略。通过将网络级马尔可夫决策过程（MDP）分解为单独的资产级MDP，同时使用统一的神经网络架构，所提出的框架降低了计算复杂性，提高了学习效率，并增强了可扩展性。该框架通过预算分配机制直接纳入年度预算限制，确保维护计划既优化又经济高效。通过对一个包含68,800个路段的大型路面网络进行案例研究，所提出的DRL框架在效率和网络性能方面均表现出优于渐进式线性规划和遗传算法等传统方法的显著改进。这一进展有助于基础设施资产管理以及强化学习在复杂、大规模环境中的更广泛应用。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [46] [Sparse optimal control for infinite-dimensional linear systems with applications to graphon control](https://arxiv.org/abs/2507.18030)
> *无限维线性系统的稀疏最优控制及其在图论控制中的应用*

*Takuya Ikeda, Masaaki Nagahara* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 稀疏最优控制, 无限维系统, 图论, 网络系统, L1优化

**Comment:** 16 pages

> **TL;DR:** 本文研究了无限维线性系统的稀疏最优控制及其在大型网络系统（通过图论表示）中的应用，旨在解决资源限制和网络结构未知的问题。

**AI_Comments:** 本文的创新点在于将稀疏最优控制应用于无限维线性系统，并巧妙地利用图论（graphons）来处理大规模网络系统中网络结构难以精确获取的问题，这对于降低计算复杂度和处理现实世界的复杂网络系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型网络系统通常在资源受限下运行，且难以精确获取节点间的网络结构。

**Method:** 本文研究了无限维线性系统的稀疏最优控制，并将其应用于网络结构由图论函数（graphon）表示的系统。具体方法包括：推导稀疏最优控制可通过L1优化问题获得的充分条件；引入一类非凸最优控制问题，其最优解与稀疏最优控制一致；证明大型有限维网络系统的稀疏最优控制可通过相应的极限图论系统近似。

**Result:** 本文取得了双重贡献：(i) 推导了一个充分条件，在此条件下稀疏最优控制可通过求解相应的L1优化问题获得；并引入了一类非凸最优控制问题，若其存在最优解，则最优解始终与稀疏最优控制一致。(ii) 证明了在底层图在切割范数拓扑中接近极限图论的条件下，大型有限维网络系统的稀疏最优控制可由相应的极限图论系统近似。通过数值示例验证了所提方法的有效性。

**Conclusion:** 本文提出并分析了无限维线性系统的稀疏最优控制方法，并将其应用于通过图论表示的大型网络系统，有效解决了资源约束和网络结构难以精确获取的问题。

> **ai_Abstract:** 本文针对大型网络系统面临的资源限制和网络结构未知问题，研究了无限维线性系统的稀疏最优控制及其在通过图论表示的网络系统中的应用。主要贡献包括：推导了稀疏最优控制可通过L1优化问题获得的充分条件，并提出了一类能产生稀疏最优解的非凸问题；同时，证明了大型有限维网络系统的稀疏最优控制可由极限图论系统近似。数值示例验证了该方法的有效性。

> **摘要翻译:** 大型网络系统通常在资源受限下运行，且难以精确获取节点间的网络结构。为解决这些问题，本文研究了无限维线性系统的稀疏最优控制及其在网络系统中的应用，其中网络结构由一个称为图论（graphon）的极限函数表示，该函数捕捉了整体连接模式。本文的贡献是双重的：(i) 为了降低计算复杂度，我们推导了一个充分条件，在此条件下稀疏最优控制可以通过求解其相应的L1优化问题获得。此外，我们引入了一类非凸最优控制问题，只要这些非凸问题存在最优解，其最优解总是与稀疏最优控制一致。(ii) 我们证明了，在底层图在切割范数拓扑中接近极限图论的条件下，大型有限维网络系统的稀疏最优控制可以由相应的极限图论系统近似。通过数值示例说明了所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [102] [Partial-State DADS Control for Matched Unmodeled Dynamics](https://arxiv.org/abs/2507.18609)
> *局部状态DADS控制用于匹配的未建模动力学*

*Iasson Karafyllis, Miroslav Krstic* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** DADS控制, 动态不确定性, 鲁棒调节, 局部状态反馈, 无限维系统

**Comment:** 28 pages. arXiv admin note: text overlap with arXiv:2311.07938,
  arXiv:2402.17222, arXiv:2410.16691

> **TL;DR:** 本文将DADS控制扩展到具有匹配动态不确定性且干扰和未知参数无界的时间不变系统，实现鲁棒调节，即使在无限维情况下也有效。

**AI_Comments:** 这项工作扩展了DADS控制的应用范围，解决了在存在未知边界干扰和参数的动态不确定性系统中的鲁棒控制问题，特别是其能够处理无限维系统，这在实际工程应用中具有重要意义。绕过小增益条件的能力也是一个显著的优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有控制方法难以应对时间不变系统中的动态不确定性，特别是当干扰和未知参数的边界未知时，这相当于未测量动态不确定性状态的局部状态自适应反馈问题。

**Method:** 本文将死区自适应干扰抑制（DADS）控制方法扩展到满足匹配条件且干扰和未知参数无界的时不变系统。此外，论文还详细分析了当未测量状态为无限维（由反应-扩散偏微分方程描述，扩散系数和反应项未知）时的控制系统。

**Result:** DADS控制器能够绕过小增益条件，即使互连强度无已知界限也能实现系统的鲁棒调节。无论干扰和未知参数的大小如何，都不会出现增益和状态漂移。即使在无限维情况下，DADS控制器也能被设计并保证植物状态的鲁棒调节。

**Conclusion:** DADS控制是一种有效且鲁棒的控制策略，适用于处理具有匹配动态不确定性且干扰和未知参数无界的时不变系统，包括那些具有无限维未测量状态的复杂系统。

> **ai_Abstract:** 本文将死区自适应干扰抑制（DADS）控制扩展到具有匹配动态不确定性且干扰和未知参数无界的时间不变系统。研究表明，DADS控制器能够绕过小增益条件，实现鲁棒调节，且不产生增益和状态漂移，即使互连强度无已知界限。论文还详细分析了当未测量状态为无限维（由反应-扩散偏微分方程描述）时的应用，并证明DADS控制器即使在此复杂情况下也能保证植物状态的鲁棒调节。

> **摘要翻译:** 我们将死区自适应干扰抑制（DADS）控制扩展到具有满足匹配条件且已知干扰和未知参数无界的时间不变系统。这个问题等同于局部状态自适应反馈，其中建模动态不确定性的状态是未测量的。我们表明，DADS控制器可以绕过小增益条件，即使互连强度没有已知界限，也能实现系统的鲁棒调节。此外，无论干扰和未知参数的大小如何，都不会出现增益和状态漂移。最后，本文提供了对一个控制系统的详细分析，其中未测量状态（或动态不确定性）是无限维的，并由一个反应-扩散偏微分方程描述，其中扩散系数和反应项是未知的。结果表明，即使在无限维情况下，DADS控制器也能被设计并保证植物状态的鲁棒调节。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [138] [Nonconvex Optimization Framework for Group-Sparse Feedback Linear-Quadratic Optimal Control I: Penalty Approach](https://arxiv.org/abs/2507.18114)
> *非凸优化框架用于组稀疏反馈线性二次最优控制 I: 罚函数方法*

*Lechen Feng, Xun Li, Yuan-Hua Ni* | **Category: math.OC, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 非凸优化, 组稀疏, 反馈控制, 线性二次问题, PALM算法

**Comment:** 

> **TL;DR:** 本文提出了一个统一的非凸优化框架，用于设计组稀疏反馈控制器，并开发了一种保证收敛的罚函数算法。

**AI_Comments:** 本文的创新之处在于提出了一个统一的非凸优化框架，直接处理组稀疏反馈控制器的设计，避免了传统凸松弛或限制性结构假设的弊端。提出的PALM算法及其收敛性分析为实际应用提供了理论保障，填补了大规模系统控制领域的一个重要空白。

<details>
  <summary>Details</summary>

**Motivation:** 针对大规模系统中可伸伸缩和结构感知控制的需求，本文旨在解决经典LQ问题的两个重要扩展：具有固定通信拓扑的分布式LQ问题（DFT-LQ）和稀疏反馈LQ问题（SF-LQ）。现有方法依赖凸松弛或仅限于块对角结构，存在局限性。

**Method:** 本文提出了一个统一的非凸优化框架，直接将控制器综合表述为带有组$\ell_0$-范数正则化的有限维非凸优化问题，以捕获通用稀疏模式。进一步，提出了一种基于罚函数的近端交替线性化最小化（PALM）算法，并提供了严格的收敛性分析。

**Result:** 本文建立了DFT-LQ和SF-LQ问题之间的联系，表明两者都可以在其统一框架内解决。所提出的PALM算法在温和假设下提供了严格的收敛性分析，克服了目标函数缺乏强制性的问题。该方法支持所有子问题的有效求解器，并保证全局收敛到临界点。

**Conclusion:** 本文通过直接设计具有理论保证的组稀疏反馈增益，而无需诉诸凸替代或限制性结构假设，填补了现有文献中的一个关键空白。

> **ai_Abstract:** 本文提出了一个统一的非凸优化框架，用于设计无限时域线性二次（LQ）问题中的组稀疏反馈控制器。该框架通过直接将控制器综合表述为带有组$\ell_0$-范数正则化的非凸优化问题，解决了分布式LQ和稀疏反馈LQ问题，并克服了现有方法在处理通用稀疏模式时的局限性。文章提出了一种基于罚函数的PALM算法，并提供了严格的收敛性分析，保证了全局收敛到临界点，从而实现了具有理论保证的组稀疏反馈增益的直接设计。

> **摘要翻译:** 本文为无限时域线性二次（LQ）问题中组稀疏反馈控制器的设计开发了一个统一的非凸优化框架。我们解决了经典LQ问题的两个突出扩展：具有固定通信拓扑的分布式LQ问题（DFT-LQ）和稀疏反馈LQ问题（SF-LQ），两者都源于大规模系统中对可伸缩和结构感知控制的需求。与依赖凸松弛或仅限于块对角结构的现有方法不同，我们直接将控制器综合表述为带有组$\ell_0$-范数正则化的有限维非凸优化问题，以捕获通用稀疏模式。我们建立了DFT-LQ和SF-LQ问题之间的联系，表明两者都可以在我们的统一框架内解决。此外，我们提出了一种基于罚函数的近端交替线性化最小化（PALM）算法，并在温和假设下提供了严格的收敛性分析，克服了目标函数缺乏强制性的问题。所提出的方法支持所有子问题的有效求解器，并保证全局收敛到临界点。我们的结果通过直接设计具有理论保证的组稀疏反馈增益，而无需诉诸凸替代或限制性结构假设，填补了现有文献中的一个关键空白。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [237] [Optimal Control of Hybrid Systems via Measure Relaxations](https://arxiv.org/abs/2507.19210)
> *混合系统测度松弛最优控制*

*Etienne Buehrle, Ömer Şahin Taş, Christoph Stiller* | **Category: math.OC, cs.SY, eess.SY, 90C22, 93C10, 28A99** | **Updated: 2025-07-25**

**Keywords:** 最优控制, 混合系统, 凸松弛, 占据测度, 轨迹优化

**Comment:** 7 pages, 6 figures, accepted at CDC 2025

> **TL;DR:** 该论文提出了一种基于凸集图框架和占据测度的混合系统轨迹优化新方法，通过凸松弛将问题转化为可高效求解的凸优化问题。与非凸方法相比，其计算的成本下界接近非凸解，并且与混合整数公式相比，运行时速度显著提升，扩展性更好。

**AI_Comments:** 该论文的创新点在于将凸集图框架与基于占据测度的凸松弛相结合，用于混合系统的最优控制。其重要性在于显著提高了混合系统轨迹优化的可扩展性和运行时效率，克服了传统NP-难混合整数公式的局限性，同时仍能提供接近非凸解的优质结果。一个局限性是它继承了半定规划的某些限制。提供开源实现是一个积极的方面。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是为分段多项式系统（尤其是混合系统）提供一种高效的轨迹优化方法，以克服NP-难的混合整数公式在处理大量离散模式时所面临的计算挑战和不切实际性。

**Method:** 本文提出了一种基于凸集图（graphs of convex sets）框架的分段多项式系统轨迹优化方法。该方法通过基于占据测度（occupation measures）的最优控制凸松弛来实例化该框架，从而得到一个类似于离散最短路径线性规划的凸优化问题，该问题可以有效地求解到全局最优。该方法被用于在时序逻辑规范下规划轨迹，并将其计算的成本下界与固定模式序列的非凸优化方法进行比较。

**Result:** 尽管该方法继承了半定规划的局限性，但与NP-难的混合整数公式相比，它在处理大量离散模式时具有更好的可扩展性。数值实验表明，该方法计算的成本下界通常接近非凸解，并且与通常难以处理的混合整数公式相比，运行时速度显著加快。

**Conclusion:** 该论文的结论是，所提出的基于测度松弛的混合系统最优控制方法，通过结合凸集图框架，提供了一种高效且可扩展的轨迹优化方案。它在计算成本上接近非凸方法，并在运行时效率上显著优于传统的混合整数公式。

> **ai_Abstract:** 该论文提出了一种基于凸集图框架和占据测度的混合系统轨迹优化新方法。通过将最优控制问题凸松弛化，将其转化为一个可高效求解到全局最优的凸优化问题。尽管该方法继承了半定规划的局限性，但与NP-难的混合整数公式相比，它在处理大量离散模式时具有更好的可扩展性。数值实验表明，该方法计算的成本下界通常接近非凸解，且运行时速度显著优于混合整数公式。

> **摘要翻译:** 我们提出了一种基于最近提出的凸集图框架的分段多项式系统轨迹优化方法。我们利用基于占据测度的最优控制凸松弛来实例化该框架，从而得到一个类似于离散最短路径线性规划的凸优化问题，该问题可以有效地求解到全局最优。虽然这种方法继承了半定规划的局限性，但与NP-难的混合整数公式相比，其对大量离散模式的可扩展性有所提高。我们用此方法在时序逻辑规范下规划轨迹，并将计算出的成本下界与固定模式序列的非凸优化方法进行比较。在我们的数值实验中，我们发现这个下界通常接近非凸解，而与通常难以处理的混合整数公式相比，运行时速度显著加快。我们的实现代码可在 https://github.com/ebuehrle/hpoc 获取。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [364] [Orthogonal Constrained Minimization with Tensor $\ell_{2,p}$ Regularization for HSI Denoising and Destriping](https://arxiv.org/abs/2407.03605)
> *基于张量$\\ell_{2,p}$正则化的正交约束最小化高光谱图像去噪和去条纹*

*Xiaoxia Liu, Shijie Yu, Jian Lu, Xiaojun Chen* | **Category: math.OC, cs.CV, 68U10, 90C26, 15A18, 65F22** | **Updated: 2025-07-24**

**Keywords:** 高光谱图像去噪, 张量$\\ell_{2,p}$正则化, 低秩张量, 正交约束, 近端块坐标下降

**Comment:** 

> **TL;DR:** 提出一种新的多尺度低秩张量正则化$\\ell_{2,p}$（MLTL2p）方法，用于高光谱图像去噪和去条纹，并在实验中表现出优越性。

**AI_Comments:** 该论文提出了一种创新的MLTL2p方法，结合了多尺度低秩张量正则化和非凸$\\ell_{2,p}$范数，有效处理了高光谱图像的混合噪声问题。其通过正交约束最小化框架和收敛性保证的迭代算法，在理论和实践上都具有重要意义。特别是在与深度学习方法比较中展现出优越性，突显了其在传统优化方法中的竞争力。

<details>
  <summary>Details</summary>

**Motivation:** 高光谱图像（HSIs）经常受到高斯噪声、死线和条纹等混合噪声的污染，需要有效的去噪和去条纹方法。

**Method:** 提出MLTL2p方法，包含正交约束最小化模型和迭代算法。模型基于稀疏性增强的多尺度低秩张量正则化和张量$\\ell_{2,p}$范数（p∈(0,1)）。多尺度低秩正则化利用全局和局部光谱相关性以及空间非局部自相似先验。低秩约束基于独立高阶奇异值分解及其核心张量上的稀疏性增强。张量$\\ell_{2,p}$范数从矩阵$\\ell_{2,p}$范数扩展而来。采用近端块坐标下降算法解决非凸非光滑最小化问题，并证明算法生成的序列的任何累积点都收敛到一阶稳定点。

**Result:** 提出的MLTL2p方法在均值峰值信噪比等指标以及视觉质量方面优于包括基于深度学习方法在内的最先进方法，并在模拟和真实高光谱数据集上进行了验证。

**Conclusion:** 提出的MLTL2p方法能够有效地进行高光谱图像去噪和去条纹，并在性能上超越了现有先进方法。

> **ai_Abstract:** 本文提出了一种名为MLTL2p的新型多尺度低秩张量正则化$\\ell_{2,p}$方法，用于高光谱图像的去噪和去条纹。该方法结合了稀疏性增强的多尺度低秩张量正则化和张量$\\ell_{2,p}$范数，并采用近端块坐标下降算法求解其非凸非光滑正交约束最小化模型。实验结果表明，MLTL2p方法在性能上优于现有的先进方法，包括基于深度学习的方法，提升了高光谱图像的去噪和去条纹效果。

> **摘要翻译:** 高光谱图像（HSIs）经常受到高斯噪声、死线、条纹等混合噪声的污染。本文提出了一种用于高光谱图像去噪和去条纹的多尺度低秩张量正则化$\\ell_{2,p}$ (MLTL2p) 方法，该方法包含一个正交约束最小化模型和一个具有收敛性保证的迭代算法。所提出的MLTL2p方法的模型建立在一种新的稀疏性增强多尺度低秩张量正则化和张量$\\ell_{2,p}$范数（其中\\(p\\in (0,1)\\)）的基础上。用于高光谱图像去噪的多尺度低秩正则化利用了高光谱图像的全局和局部光谱相关性以及空间非局部自相似先验。相应的低秩约束是基于独立高阶奇异值分解及其核心张量上的稀疏性增强来制定的，以促进更强的低秩性。用于高光谱图像去条纹的张量$\\ell_{2,p}$范数是从矩阵$\\ell_{2,p}$范数扩展而来的。在MLTL2p方法中，提出了一种近端块坐标下降算法来解决由此产生的具有正交约束的非凸非光滑最小化问题。我们证明了该算法生成的序列的任何累积点都收敛到一阶稳定点，该稳定点通过子平稳性、对称性和正交约束的可行性三个等式来定义。在数值实验中，我们将所提出的方法与包括基于深度学习方法在内的最先进方法进行了比较，并在模拟和真实高光谱数据集上测试了这些方法。我们提出的MLTL2p方法在均值峰值信噪比等指标以及视觉质量方面表现出优越性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [580] [Modeling Nonlinear Control Systems via Koopman Control Family: Universal Forms and Subspace Invariance Proximity](https://arxiv.org/abs/2307.15368)
> *通过 Koopman 控制族建模非线性控制系统：通用形式和子空间不变性邻近*

*Masih Haseli, Jorge Cortés* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** Koopman控制族, 非线性控制系统, 子空间不变性, 数据驱动建模, 通用形式

**Comment:** 19 pages

> **TL;DR:** 本文介绍了Koopman控制族（KCF），这是一个用于建模非线性控制系统的数学框架，旨在为基于Koopman的方法在具有输入的系统中提供坚实的理论基础，并建立了通用形式和近似方法。

**AI_Comments:** 本文通过将Koopman算子理论扩展到带输入的通用非线性系统，为控制系统领域的Koopman算子理论提供了重要的理论进展。Koopman控制族（KCF）的引入和子空间不变性邻近的概念具有创新性，为各种现有模型提供了一个统一的框架，并为非不变情况提供了近似方法。其在数据驱动建模中的自然适用性突显了其实际重要性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为在具有输入的系统中使用基于Koopman的方法提供坚实的理论基础，特别是针对一般的（不一定是控制仿射的）离散时间非线性控制系统。

**Method:** 本文引入了Koopman控制族（KCF）数学框架，并证明KCF概念可以在函数空间上捕捉非线性控制系统的行为。通过采用KCF下子空间不变性的广义概念，为有限维模型建立了一个通用形式。在子空间不不变的情况下，提出了一种近似模型的方法，并使用不变性邻近的概念来表征模型的准确性。文章最后讨论了该框架如何自然地适用于控制系统的数据驱动建模。

**Result:** Koopman控制族（KCF）能够捕捉非线性控制系统在函数空间上的行为。基于KCF下子空间不变性的概念，建立了有限维模型的通用形式，该形式涵盖了常用的线性、双线性和线性切换模型。对于子空间不不变的情况，提出了一种使用不变性邻近概念来表征模型准确性的近似方法。

**Conclusion:** 所提出的Koopman控制族（KCF）框架为建模一般的非线性控制系统提供了坚实的理论基础，建立了有限维模型的通用形式，并且自然地适用于数据驱动建模。

> **ai_Abstract:** 本文引入了Koopman控制族（KCF）作为建模一般离散时间非线性控制系统的数学框架。它为基于Koopman的带输入方法提供了理论基础，并证明KCF能够捕捉函数空间上的系统行为。作者利用KCF下的子空间不变性，为有限维模型建立了通用形式，涵盖了常见的线性、双线性和切换模型。对于非不变子空间，提出了一种近似方法，其精度由不变性邻近来表征。该框架在数据驱动建模中的适用性也得到了讨论。

> **摘要翻译:** 本文介绍了Koopman控制族（KCF），这是一个用于建模一般（不一定是控制仿射的）离散时间非线性控制系统的数学框架，旨在为在具有输入的系统中使用基于Koopman的方法提供坚实的理论基础。我们证明了KCF的概念在（可能是无限维的）函数空间上捕捉了非线性控制系统的行为。通过采用KCF下子空间不变性的广义概念，我们为有限维模型建立了一个通用形式，该形式涵盖了常用的线性、双线性和线性切换模型作为特定实例。在子空间在KCF下不不变的情况下，我们提出了一种以通用形式近似模型的方法，并使用不变性邻近的概念来表征模型的准确性。最后，我们讨论了所提出的框架如何自然地适用于控制系统的数据驱动建模。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [655] [Designing efficient interventions for pre-disease states using control theory](https://arxiv.org/abs/2507.18269)
> *使用控制理论设计高效的疾病前状态干预措施*

*Makito Oku* | **Category: math.OC** | **Updated: 2025-07-24**

**Keywords:** 疾病前状态, 控制理论, 马尔可夫链稀疏控制, 疾病预防, 早期干预

**Comment:** 24 pages, 14 figures, 1 table, submitted to NOLTA

> **TL;DR:** 提出了一种基于控制理论的马尔可夫链稀疏控制（MCSC）方法，用于疾病前状态的治疗干预，并通过仿真和真实数据进行了验证。

**AI_Comments:** 这篇论文的创新点在于将控制理论引入疾病前状态的治疗干预，特别是提出了马尔可夫链稀疏控制（MCSC）方法。它填补了现有理论在疾病前治疗数学框架方面的空白。其重要性在于为早期疾病干预提供了新的数学工具和视角，有望在延长健康寿命方面发挥作用。

<details>
  <summary>Details</summary>

**Motivation:** 在老龄化社会中，延长健康预期寿命至关重要，这需要预防疾病在疾病前状态发生。尽管已发展出用于疾病前检测的理论，但疾病前治疗的数学框架尚未完善。

**Method:** 提出了一种名为马尔可夫链稀疏控制（MCSC）的基于控制理论的方法，用于疾病前治疗。该方法将马尔可夫链上概率分布的时间演化描述为离散时间线性系统，并通过设计稀疏控制器来识别少数干预候选状态。

**Result:** MCSC 的有效性通过数值模拟和真实数据分析得到了验证。

**Conclusion:** 该研究成功开发了一种基于控制理论的马尔可夫链稀疏控制（MCSC）方法，为疾病前状态的治疗干预提供了新的数学框架，并证明了其有效性。

> **ai_Abstract:** 本文提出了一种创新的基于控制理论的马尔可夫链稀疏控制（MCSC）方法，旨在解决疾病前状态治疗缺乏数学框架的问题。MCSC 将马尔可夫链上的概率分布演化建模为离散时间线性系统，并通过稀疏控制器识别关键干预点。数值模拟和真实数据分析验证了该方法的有效性，为在老龄化社会中延长健康寿命提供了潜在的干预策略。

> **摘要翻译:** 为了延长老龄化社会中的健康预期寿命，在疾病前状态预防各种疾病至关重要。尽管已经发展了用于疾病前检测的动态网络生物标志物理论，但疾病前治疗的数学框架尚未完善。本文提出了一种基于控制理论的疾病前治疗方法，命名为马尔可夫链稀疏控制（MCSC），其中马尔可夫链上概率分布的时间演化被描述为离散时间线性系统。通过设计稀疏控制器，可以识别出少数几个候选干预状态。MCSC 的有效性通过数值模拟和真实数据分析得到了验证。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='mathst'></a>
## math.ST 

### [12] [Zeroth-order log-concave sampling](https://arxiv.org/abs/2507.18021)
> *零阶对数凹采样*

*Yunbum Kook* | **Category: math.ST, cs.DS, cs.LG, math.FA, math.PR, stat.TH** | **Updated: 2025-07-24**

**Keywords:** 零阶采样, 对数凹分布, 查询复杂度, Rényi散度, 凸体

**Comment:** 30 pages

> **TL;DR:** 本文研究了对数凹采样的零阶查询复杂度，提出了一种改进的近端采样器变体和一种退火方案，以实现具有匹配Rényi阶数的查询复杂度，并为通用对数凹分布提供了扩展。

**AI_Comments:** 该论文在对数凹采样的零阶查询复杂度方面取得了重要进展，特别是在Rényi散度下的分析。其创新点在于提出了改进的近端采样器和新的退火方案，并提供了严格的查询复杂度界限。通过引入超收缩性等数学工具，该研究为理解和优化高维采样算法提供了坚实的理论基础。其结果对于需要从复杂分布中进行高效采样的领域（如机器学习、统计物理）具有潜在的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 本文研究了对数凹采样的零阶查询复杂度，特别是使用成员预言机对凸体进行均匀采样。其动机在于改进和理解零阶查询设置下对数凹采样的效率，并提供在不同Rényi散度下的统一和改进的暖启动生成复杂性。

**Method:** 本文提出了近端采样器的一个简单变体，以实现特定的查询复杂度。此外，引入了一种简单的退火方案来生成q-Rényi散度中的暖启动。为了在退火方案中传递Rényi暖度，研究建立了同时热流下的超收缩性，并将其转化为对数Sobolev不等式下近端采样器的改进混合保证。

**Result:** 所提出的采样器在q-Rényi散度中实现了ε-接近的采样输出，查询复杂度为$\\widetilde{O}(qM_{q}^{q/(q-1)}d^{2}\\\lVert\\operatorname{cov}\\pi\\rVert\\log\\frac{1}{\\varepsilon})$。退火方案使用$\\widetilde{O}(qd^{2}R^{3/2}\\\lVert\\operatorname{cov}\\pi\\rVert^{1/4})$查询生成q-Rényi散度中的暖启动，该结果介于总变差和Rényi无穷大散度中暖启动生成的已知复杂度之间。这些结果自然地扩展到通过评估预言机可访问的通用对数凹分布，但会产生额外的二次查询。

**Conclusion:** 本文为零阶对数凹采样提供了新的查询复杂度结果和方法，包括一个新的近端采样器变体和一个退火方案。通过建立超收缩性和改进混合保证，这些方法在理论上得到了支持，并且可以推广到更广泛的对数凹分布。

> **ai_Abstract:** 本文研究了对数凹采样的零阶查询复杂度，特别是从凸体中进行均匀采样。作者提出了一个改进的近端采样器变体，其在q-Rényi散度下实现了高效的采样，并给出了具体的查询复杂度。此外，论文还引入了一种新颖的退火方案，用于生成暖启动，并证明了其在不同Rényi散度下的复杂度优于或统一了现有结果。通过建立超收缩性和改进混合保证，该研究为零阶对数凹采样的理论和实践提供了重要进展，并将其结果推广到更广泛的对数凹分布。

> **摘要翻译:** 我们研究了对数凹采样的零阶查询复杂度，特别是使用成员预言机对凸体进行均匀采样。我们提出了近端采样器的一个简单变体，它实现了查询复杂度，并且在初始暖度和输出保证之间具有匹配的Rényi阶数。具体来说，对于任何$\varepsilon>0$和$q\geq2$，该采样器在$\pi_{0}$处初始化，输出的样本其分布在q-Rényi散度中与$\mathbb{R}^{d}$中凸体上的均匀分布$\pi$相距$\varepsilon$，使用的成员查询次数为$\widetilde{O}(qM_{q}^{q/(q-1)}d^{2}\\\lVert\\operatorname{cov}\\pi\\rVert\\log\\frac{1}{\\varepsilon})$，其中$M_{q}=\\\lVert\\text{d}\\pi_{0}/\\text{d}\\pi\\rVert_{L^{q}(\\pi})$。我们进一步引入了一个简单的退火方案，该方案使用$\widetilde{O}(qd^{2}R^{3/2}\\\lVert\\operatorname{cov}\\pi\\rVert^{1/4})$查询生成q-Rényi散度中的暖启动（即$M_{q}=O(1)$），其中$R^{2}=\\mathbb{E}_{\\pi}[|\\cdot|^{2}]$。这插值了总变差和Rényi无穷大散度中暖启动生成的已知复杂度。为了在退火方案中传递Rényi暖度，我们在同时热流下建立了超收缩性，并将其转化为对数Sobolev不等式下近端采样器的改进混合保证。这些结果自然地扩展到通过评估预言机可访问的通用对数凹分布，但会产生额外的二次查询。

</details>

[⬆️ 返回分类顶部](#mathst) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [17] [Robust Non-adaptive Group Testing under Errors in Group Membership Specifications](https://arxiv.org/abs/2409.05345)
> *组测试中群组成员规范错误下的鲁棒非自适应组测试*

*Shuvayan Banerjee, Radhendushka Srivastava, James Saunderson, Ajit Rajwade* | **Category: stat.ML, cs.IT, cs.LG, math.IT** | **Updated: 2025-07-24**

**Keywords:** 组测试, 鲁棒性, Lasso, 去偏, 成员错误

**Comment:** 

> **TL;DR:** 本文提出了一种名为DRLT的新型组测试方法，用于在群组成员规范存在错误的情况下，鲁棒地识别有缺陷的样本和错误指定的组，并提供理论保证和数值验证。

**AI_Comments:** 该论文的创新点在于解决了组测试领域一个重要的实际问题：群组成员规范中的错误。通过将Lasso去偏技术与专门的假设检验相结合，DRLT方法不仅提高了缺陷样本识别的鲁棒性，还能够识别出错误指定的组，这在实际应用中具有重要意义。该工作扩展了统计估计器偏差缓解的理论，并提供了实证和理论支持，对于提高组测试在复杂环境下的可靠性具有积极作用。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有的组测试方法都假设群组成员是准确指定的，然而在实际应用中，由于资源限制或人为错误，这种假设可能不成立。当技术人员无意中混合了不正确的样本子集时，就会发生此类错误，导致现有方法失效。因此，需要一种能够处理群组成员规范错误的鲁棒组测试方法。

**Method:** 本文开发了一种名为“去偏鲁棒Lasso测试方法”（DRLT）的新型组测试方法。DRLT基于一种去偏或减少Lasso（一种流行的稀疏回归技术）估计中固有偏差的方法。该方法还提供了估计器产生的重建误差的理论上限。DRLT结合了两个精心设计的假设检验，分别用于：(i) 在群组成员规范存在错误的情况下识别有缺陷的样本；(ii) 识别具有错误成员规范的组。DRLT方法扩展了统计估计器（如LASSO）的偏差缓解文献，以处理由于群组成员规范错误等因素导致某些测量值包含异常值的重要情况。

**Result:** 数值结果表明，所提出的DRLT方法在识别有缺陷样本和错误指定组方面，优于多种基线方法和鲁棒回归技术。此外，本文还提供了估计器产生的重建误差的理论上限。

**Conclusion:** DRLT方法成功地解决了组测试中群组成员规范错误的问题，通过去偏Lasso估计和专门设计的假设检验，实现了对有缺陷样本和错误指定组的鲁棒识别。这扩展了统计估计器偏差缓解的应用范围，提高了组测试在实际应用中的可靠性。

> **ai_Abstract:** 本文提出了一种名为去偏鲁棒Lasso测试方法（DRLT）的新型组测试方法，旨在解决现有组测试（GT）方法中普遍存在的群组成员规范准确性假设在实际应用中可能不成立的问题。DRLT通过去偏Lasso估计并结合两个专门设计的假设检验，能够鲁棒地识别有缺陷的样本以及具有错误成员规范的组。研究提供了DRLT重建误差的理论上限，并通过数值结果证明，DRLT在处理群组成员规范错误方面，优于现有的基线和鲁棒回归技术。

> **摘要翻译:** 给定p个样本，每个样本可能有缺陷或无缺陷，组测试（GT）旨在通过对n个（n < p）“组”进行测试来确定它们的缺陷状态，其中一个组是通过混合p个样本的子集形成的。假设有缺陷样本的数量与p相比非常小，GT算法即使在少量组的情况下也能很好地恢复所有p个样本的状态。然而，大多数现有方法都假设群组成员资格被准确指定。由于各种资源限制，这个假设在所有应用中可能并非总是成立。例如，当技术人员在实验室准备组时，无意中混合了与指定不符的不正确样本子集时，就可能发生此类错误。我们开发了一种新的GT方法，即去偏鲁棒Lasso测试方法（DRLT），该方法可以处理此类群组成员资格规范错误。所提出的DRLT方法基于一种去偏或减少Lasso（一种流行且有效的稀疏回归技术）产生的估计中固有偏差的方法。我们还提供了我们的估计器产生的重建误差的理论上限。然后，我们的方法结合了两个精心设计的假设检验，分别用于（i）在群组成员资格规范存在错误的情况下识别有缺陷的样本，以及（ii）识别具有错误成员资格规范的组。DRLT方法扩展了统计估计器（如LASSO）的偏差缓解文献，以处理由于群组成员资格规范错误等因素导致某些测量值包含异常值的重要情况。我们提供了数值结果，表明我们的方法在识别有缺陷样本以及错误指定组方面优于几种基线和鲁棒回归技术。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [180] [A Two-armed Bandit Framework for A/B Testing](https://arxiv.org/abs/2507.18118)
> *A/B测试的双臂赌博机框架*

*Jinjuan Wang, Qianglin Wen, Yu Zhang, Xiaodong Yan, Chengchun Shi* | **Category: stat.ML, cs.LG, stat.AP** | **Updated: 2025-07-24**

**Keywords:** A/B测试, 双臂赌博机, 双重稳健估计, 置换检验, 统计功效

**Comment:** 

> **TL;DR:** 本文提出了一个双臂赌博机框架，旨在通过结合双重稳健估计和置换检验来提高A/B测试的功效，并在理论、数值实验和实际数据中展示出优于现有方法的性能。

**AI_Comments:** 本文的创新点在于将双臂赌博机框架引入A/B测试，并结合双重稳健估计和置换检验，旨在提高A/B测试的统计功效。其重要性在于为A/B测试提供了一种更强大、更有效的方法，有望在实际应用中提升决策质量。

<details>
  <summary>Details</summary>

**Motivation:** A/B测试在现代科技公司中广泛用于策略评估和产品部署，但现有方法的功效可能不足，因此需要改进方法来提高A/B测试的功效。

**Method:** 提出的程序包含三个主要步骤：(i) 采用双重稳健估计生成伪结果；(ii) 利用双臂赌博机框架构建检验统计量；(iii) 应用基于置换的方法计算p值。

**Result:** 通过渐近理论、数值实验和来自一家网约车公司的真实世界数据，证明了所提出方法的有效性，并显示其性能优于现有方法。

**Conclusion:** 本文提出的双臂赌博机框架能够有效提高A/B测试的功效，并在多种验证方式中表现出优于现有方法的性能。

> **ai_Abstract:** 本文针对A/B测试中现有方法功效不足的问题，提出了一个基于双臂赌博机的新框架。该框架结合了双重稳健估计、双臂赌博机构建检验统计量以及基于置换的p值计算方法。通过理论分析、数值模拟和真实数据验证，证明了该方法能够有效提高A/B测试的功效，并优于现有方法。

> **摘要翻译:** A/B测试在现代科技公司中被广泛用于策略评估和产品部署，旨在比较新开发策略与标准对照下的结果。文献中开发的各种因果推断和强化学习方法都适用于A/B测试。本文引入了一个双臂赌博机框架，旨在提高现有方法的功效。所提出的程序包含三个主要步骤：(i) 采用双重稳健估计生成伪结果；(ii) 利用双臂赌博机框架构建检验统计量；(iii) 应用基于置换的方法计算p值。我们通过渐近理论、数值实验和来自一家网约车公司的真实世界数据证明了所提出方法的有效性，并显示其性能优于现有方法。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [182] [Fixing the Pitfalls of Probabilistic Time-Series Forecasting Evaluation by Kernel Quadrature](https://arxiv.org/abs/2503.06079)
> *通过核求积修复概率时间序列预测评估的缺陷*

*Masaki Adachi, Masahiro Fujisawa, Michael A Osborne* | **Category: stat.ML, cs.LG, 62C10, 62F15** | **Updated: 2025-07-24**

**Keywords:** 概率时间序列预测, CRPS, 评估指标, 核求积, 估计偏差

**Comment:** 11 pages, 6 figures

> **TL;DR:** 本文提出了一种核求积方法，用于解决概率时间序列预测中连续排序概率分数（CRPS）估计器的偏差问题，并证明其性能优于现有方法。

**AI_Comments:** 本文解决了概率时间序列预测评估中的一个关键问题，即常用CRPS估计器的偏差。通过引入核求积方法，提供了一种理论上更优、实践中表现更好的解决方案，对于提升时间序列预测模型的评估质量具有重要意义。其创新之处在于将核求积应用于CRPS的无偏估计，并考虑了计算的可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 概率时间序列预测模型的评估指标（如CRPS）涉及难以处理的积分，其常用估计器（如GluonTS中的分位数估计器和概率加权矩近似）存在固有的估计偏差，导致近似粗糙，并在CRPS值接近时导致预测模型性能排名不准确。

**Method:** 本文引入了一种核求积方法，该方法利用无偏的CRPS估计器，并采用立体求积构造实现可扩展计算。

**Result:** 在经验上，我们提出的方法始终优于两种广泛使用的CRPS估计器。

**Conclusion:** 本文提出的核求积方法能够有效解决现有CRPS估计器的偏差问题，为概率时间序列预测评估提供了更准确和可靠的手段。

> **ai_Abstract:** 本文针对概率时间序列预测评估中CRPS估计器的固有偏差问题，提出了一种基于核求积的新方法。研究发现，现有的分位数估计器和概率加权矩近似都存在偏差，导致模型性能排名不准确。新方法利用无偏CRPS估计器和立体求积构造，实现了可扩展的计算，并在实验中证明其性能优于两种广泛使用的CRPS估计器，从而提高了评估的准确性和可靠性。

> **摘要翻译:** 尽管概率时间序列预测模型具有重要意义，但它们的评估指标通常涉及难以处理的积分。最广泛使用的指标——连续排序概率分数（CRPS）——是一个严格的适当评分函数；然而，它的计算需要近似。我们发现流行的CRPS估计器——特别是广泛使用的GluonTS库中实现的分位数估计器和概率加权矩近似——都表现出固有的估计偏差。这些偏差导致粗糙的近似，当CRPS值接近时，导致预测模型性能的排名不正确。为了解决这个问题，我们引入了一种核求积方法，该方法利用无偏的CRPS估计器，并采用立体求积构造实现可扩展计算。从经验上看，我们的方法始终优于两种广泛使用的CRPS估计器。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [203] [Tuning Sequential Monte Carlo Samplers via Greedy Incremental Divergence Minimization](https://arxiv.org/abs/2503.15704)
> *通过贪婪增量散度最小化调整序贯蒙特卡洛采样器*

*Kyurae Kim, Zuheng Xu, Jacob R. Gardner, Trevor Campbell* | **Category: stat.ML, cs.LG, stat.CO** | **Updated: 2025-07-23**

**Keywords:** 序贯蒙特卡洛采样, 马尔可夫核调整, Kullback-Leibler散度, 贪婪增量, Langevin Monte Carlo

**Comment:** Accepted to ICML'25; v4: fixed typos

> **TL;DR:** 提出了一种通过最小化增量KL散度来调整SMC采样器中马尔可夫核的新框架，成本远低于基于梯度的传统方法。

**AI_Comments:** 这篇论文提出了一种创新的、计算效率更高的方法来调整SMC采样器，解决了现有梯度优化方法成本高昂的痛点。其核心创新在于利用增量KL散度最小化，并提供了一种无需梯度的步长调整算法，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 序贯蒙特卡洛（SMC）采样器的性能高度依赖于马尔可夫核的调整。对于使用未调整马尔可夫核的SMC采样器，标准调整目标不再适用。现有的基于随机梯度的端到端优化方法通常会产生过高的训练成本。

**Method:** 提出了一种通用的自适应框架，通过最小化提议路径和目标路径之间的增量Kullback-Leibler（KL）散度来调整SMC采样器中的马尔可夫核。对于步长调整，提供了一种无需梯度和调整的算法，适用于Langevin Monte Carlo（LMC）等核。还为SMC采样器中使用的动能LMC提供了量身定制的调整方案。

**Result:** 实现能够以几个普通SMC运行的成本获得完整的调整参数时间表，这只是基于梯度方法成本的一小部分。

**Conclusion:** 论文提出了一个高效的框架来调整SMC采样器中的马尔可夫核，显著降低了计算成本，尤其是在步长调整方面。

> **ai_Abstract:** 本文提出了一种调整序贯蒙特卡洛 (SMC) 采样器中马尔可夫核的新方法，旨在解决现有方法（如基于梯度优化）成本过高的问题。该方法通过最小化提议路径与目标路径之间的增量Kullback-Leibler (KL) 散度来实现自适应调整。特别地，对于步长调整，提出了一种无需梯度和调整的通用算法，并展示了其在Langevin Monte Carlo (LMC) 核中的应用。实验结果表明，该方法能够以显著低于传统梯度方法的计算成本获得高效的参数调整。

> **摘要翻译:** 序贯蒙特卡洛 (SMC) 采样器的性能在很大程度上取决于路径提议中使用的马尔可夫核的调整。对于使用未调整马尔可夫核的SMC采样器，标准的调整目标，例如Metropolis-Hastings接受率或预期平方跳跃距离，不再适用。虽然已经探索了基于随机梯度的端到端优化来调整SMC采样器，但它们通常会产生过高的训练成本，即使仅用于调整核步长。在这项工作中，我们提出了一种通用的自适应框架，通过最小化提议路径和目标路径之间的增量Kullback-Leibler (KL) 散度来调整SMC采样器中的马尔可夫核。对于步长调整，我们提供了一种无需梯度和调整的算法，通常适用于Langevin Monte Carlo (LMC) 等核。我们通过为SMC采样器中使用的动能LMC提供量身定制的方案，进一步证明了我们方法的实用性。我们的实现能够以几个普通SMC运行的成本获得完整的调整参数时间表，这只是基于梯度方法成本的一小部分。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [315] [Choosing Public Datasets for Private Machine Learning via Gradient Subspace Distance](https://arxiv.org/abs/2303.01256)
> *通过梯度子空间距离选择用于隐私机器学习的公共数据集*

*Xin Gu, Gautam Kamath, Zhiwei Steven Wu* | **Category: stat.ML, cs.CR, cs.CV, cs.DS, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 差分隐私, 公共数据集, 梯度子空间距离, 机器学习, 过量风险

**Comment:** Accepted to SaTML 2025

> **TL;DR:** 该研究提出了一种通过测量公共和私有数据梯度之间的低维子空间距离来选择公共数据集的算法，以优化差分隐私机器学习的性能，并通过理论和实证证明了其有效性。

**AI_Comments:** 该论文提出了一种新颖且实用的方法，解决了差分隐私机器学习中如何有效利用公共数据进行噪声抑制的关键挑战。通过引入梯度子空间距离这一可量化的指标，为公共数据集的选择提供了一个清晰的指导原则，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 在差分隐私机器学习中，利用公共数据可以减少噪声，但如何选择最适合特定隐私任务的公共数据集尚不明确。

**Method:** 提出了一种算法，通过测量公共和私有样本梯度之间的低维子空间距离来选择公共数据集。

**Result:** 理论分析表明，过量风险与该子空间距离成比例。该距离易于计算且对设置修改具有鲁棒性。实证评估表明，训练模型的准确性与该距离单调相关。

**Conclusion:** 通过测量公共和私有样本梯度之间的低维子空间距离，可以有效地选择公共数据集，从而提高差分隐私机器学习模型的准确性并降低过量风险。

> **ai_Abstract:** 本研究针对差分隐私机器学习中公共数据集的选择问题，提出了一种基于梯度子空间距离的算法。该算法通过计算公共和私有数据梯度之间的低维子空间距离来选择最合适的公共数据集，以降低模型训练中的噪声并提高准确性。理论分析证明了过量风险与该距离的相关性，且该距离易于计算。实证结果也验证了模型准确性与该距离的单调关系。

> **摘要翻译:** 差分隐私随机梯度下降通过在每次迭代中注入噪声来使模型训练私有化，其中噪声幅度随模型参数的数量而增加。最近的工作表明，我们可以通过利用公共数据进行隐私机器学习来减少噪声，方法是将梯度投影到由公共数据规定的子空间上。然而，给定一组公共数据集，事先不清楚哪一个可能最适合隐私任务。我们提出了一种算法，通过测量公共和私有样本梯度之间的低维子空间距离来选择公共数据集。我们提供了理论分析，证明过量风险与该子空间距离成比例。该距离易于计算且对设置修改具有鲁棒性。实证评估表明，训练模型的准确性与该距离单调相关。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [355] [On Reconstructing Training Data From Bayesian Posteriors and Trained Models](https://arxiv.org/abs/2507.18372)
> *从贝叶斯后验和训练模型中重建训练数据*

*George Wynne* | **Category: stat.ML, cs.LG, math.ST, stat.TH** | **Updated: 2025-07-24**

**Keywords:** 训练数据重建, 贝叶斯后验, 分数匹配, 机器学习隐私, 数据漏洞

**Comment:** 

> **TL;DR:** 该论文提出了一个数学框架和分数匹配方法，用于从公开的模型参数中重建训练数据，解决了机器学习中的数据隐私漏洞。

**AI_Comments:** 该论文通过为训练数据重建攻击建立数学框架和提出新的分数匹配方法（尤其是在贝叶斯模型中的首次应用），在机器学习隐私领域具有重要创新性。它不仅明确了问题的本质，还为未来防御此类攻击提供了理论基础和潜在工具。

<details>
  <summary>Details</summary>

**Motivation:** 现代机器学习方法存在一个主要漏洞：当模型及其训练参数被公开时，攻击者可以通过训练数据重建攻击来尝试重建训练数据的信息。

**Method:** 该论文提出了三个主要贡献：建立一个表达该问题的数学框架；通过最大均值差异等价性来表征易受攻击的训练数据特征；并概述了一个分数匹配框架，用于在贝叶斯和非贝叶斯模型中重建数据，其中后者是文献中的首次提出。

**Result:** 该研究建立了表达训练数据重建问题的数学框架，通过最大均值差异等价性表征了训练数据中易受攻击的特征，并提出了一个用于贝叶斯和非贝叶斯模型的数据重建分数匹配框架。

**Conclusion:** 该论文成功地为从贝叶斯后验和训练模型中重建训练数据的问题建立了数学和方法论基础，并通过引入分数匹配框架（尤其是在贝叶斯模型中的首次应用）为解决机器学习数据隐私漏洞提供了新的工具。

> **ai_Abstract:** 本论文探讨了现代机器学习中训练数据隐私泄露的漏洞，即当模型参数公开时，攻击者可能重建原始训练数据。为此，作者提出了一个形式化的数学框架来描述此问题，并通过最大均值差异等价性识别了数据中易受攻击的特征。此外，论文还首次提出了一个分数匹配框架，用于在贝叶斯和非贝叶斯模型中进行数据重建，为解决这一隐私挑战提供了新的方法。

> **摘要翻译:** 公开模型规范及其训练参数意味着攻击者可以通过训练数据重建攻击来尝试重建训练数据信息，这是现代机器学习方法的一个主要漏洞。本文提出了三个主要贡献：建立一个表达该问题的数学框架；通过最大均值差异等价性来表征易受攻击的训练数据特征；并概述了一个分数匹配框架，用于在贝叶斯和非贝叶斯模型中重建数据，其中后者是文献中的首次提出。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [435] [DriftMoE: A Mixture of Experts Approach to Handle Concept Drifts](https://arxiv.org/abs/2507.18464)
> *DriftMoE：一种处理概念漂移的专家混合方法*

*Miguel Aspis, Sebastián A. Cajas Ordónez, Andrés L. Suárez-Cetrulo, Ricardo Simón Carbajo* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 概念漂移, 专家混合, 数据流, 在线学习, 自适应集成

**Comment:** Accepted at the SYNDAiTE@ECMLPKDD 2025 workshop

> **TL;DR:** DriftMoE是一种在线专家混合模型，通过协同训练框架处理概念漂移，利用神经网络路由器和Hoeffding树专家实现专业化，并取得了有竞争力的结果。

**AI_Comments:** DriftMoE的创新之处在于其新颖的协同训练框架以及神经网络路由器与增量式Hoeffding树专家之间的共生学习循环，这使得有效的专家专业化和对概念漂移的适应成为可能。这解决了从非平稳数据中学习的一个关键挑战。其竞争性的性能和开源代码的提供增强了其重要性和潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 现有自适应集成方法在处理非平稳数据流时，由于粗粒度适应机制或简单投票方案，未能充分利用专业知识，缺乏资源效率和即时适应性。

**Method:** DriftMoE是一种在线专家混合（MoE）架构，采用新颖的协同训练框架。它包含一个紧凑的神经网络路由器，与一组增量式Hoeffding树专家共同训练。核心创新在于一个共生学习循环：路由器选择最合适的专家进行预测，相关专家根据真实标签增量更新，路由器使用多热正确性掩码优化参数以强化每个准确的专家。这为路由器提供了清晰的训练信号并加速了专家专业化。

**Result:** DriftMoE在九个最先进的数据流学习基准（包括突变、渐变和真实世界漂移）上进行了评估。结果表明，DriftMoE与最先进的流学习自适应集成方法相比，取得了有竞争力的结果。

**Conclusion:** DriftMoE为概念漂移适应提供了一种原则性且高效的方法。

> **ai_Abstract:** 本文介绍了DriftMoE，一种在线专家混合（MoE）架构，旨在处理非平稳数据流中的概念漂移。它通过新颖的协同训练框架解决了现有自适应集成方法的局限性。DriftMoE由一个神经网络路由器和增量式Hoeffding树专家组成，并通过一个共生学习循环连接，该循环促进了专家专业化并提供了清晰的训练信号。在各种数据流基准上的评估表明，DriftMoE与最先进的方法相比取得了有竞争力的性能，为概念漂移适应提供了一种高效且原则性的解决方案。

> **摘要翻译:** 从受概念漂移影响的非平稳数据流中学习，需要模型能够即时适应并保持资源效率。现有的自适应集成方法通常依赖于粗粒度的适应机制或简单的投票方案，未能最佳地利用专业知识。本文介绍了DriftMoE，一种在线专家混合（MoE）架构，通过新颖的协同训练框架解决了这些局限性。DriftMoE的特点是，一个紧凑的神经网络路由器与一组增量式Hoeffding树专家共同训练。其关键创新在于一个共生学习循环，该循环使得专家专业化成为可能：路由器选择最合适的专家进行预测，相关专家根据真实标签增量更新，路由器使用多热正确性掩码细化其参数，以强化每个准确的专家。这种反馈循环为路由器提供了清晰的训练信号，同时加速了专家专业化。我们在九个最先进的数据流学习基准上评估了DriftMoE的性能，这些基准涵盖了突变、渐变和真实世界的漂移，并测试了两种不同的配置：一种是专家专注于数据状态（多类别变体），另一种是他们专注于单类别专业化（基于任务的变体）。我们的结果表明，DriftMoE与最先进的流学习自适应集成方法取得了有竞争力的结果，为概念漂移适应提供了一种原则性且高效的方法。所有代码、数据管道和可复现脚本均可在我们的公共GitHub仓库中获取：https://github.com/miguel-ceadar/drift-moe。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [507] [Euclidean Distance Deflation Under High-Dimensional Heteroskedastic Noise](https://arxiv.org/abs/2507.18520)
> *欧几里得距离在高维异方差噪声下的校正*

*Keyi Li, Yuval Kluger, Boris Landa* | **Category: stat.ML, cs.LG, math.ST, stat.TH, 62R07, 62G** | **Updated: 2025-07-24**

**Keywords:** 欧几里得距离, 异方差噪声, 距离校正, 噪声估计, 高维数据

**Comment:** 

> **TL;DR:** 提出一种无超参数方法，在高维异方差噪声下准确估计噪声并校正欧几里得距离，具有理论保证和实验验证。

**AI_Comments:** 这项工作提出了一种重要且创新的方法来解决高维数据中普遍存在的异方差噪声对欧几里得距离计算的扭曲问题。其创新之处在于提出了一种无超参数的联合估计噪声和校正距离的原则性方法，并在不假设先验知识的情况下提供了严格的理论保证。该方法在实际应用中（如单细胞RNA测序数据分析）表现出良好的性能，有望显著提高依赖距离度量的机器学习和数据分析算法的鲁棒性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 在许多机器学习和数据分析算法中，成对欧几里得距离计算是基础步骤，但真实世界应用中，距离常被异方差噪声（一种噪声大小随观测值变化的非均匀损坏）扭曲，导致底层数据几何结构失真。

**Method:** 开发了一种原则性的、无超参数的方法，可以联合估计每个观测值的噪声大小并校正成对欧几里得距离。该方法在高维设置下进行，不假设干净数据结构或噪声分布的先验知识。提供了理论保证，建立了噪声大小和距离估计误差的概率界限，这些界限在特征维度和数据集大小增加时以多项式速率收敛到零。

**Result:** 在合成数据集上的实验表明，该方法在具有挑战性的情况下能准确估计距离，显著提高了后续基于距离计算的鲁棒性。在单细胞RNA测序数据上的应用表明，该方法产生的噪声大小估计与已建立的原型模型一致，实现了准确的最近邻识别。

**Conclusion:** 即使噪声水平变化很大，在高维设置下，无需先验知识，也能可靠地估计每观测值的噪声大小并校正成对欧几里得距离。

> **ai_Abstract:** 本文提出了一种在高维异方差噪声下校正欧几里得距离的新方法。该方法无需先验知识和超参数，能够联合估计每个观测值的噪声大小并准确校正成对距离。研究提供了理论保证，证明了其估计误差的收敛性，并通过合成数据和单细胞RNA测序数据的实验验证了其在提高距离计算鲁棒性和实现准确最近邻识别方面的有效性。

> **摘要翻译:** 成对欧几里得距离计算是许多机器学习和数据分析算法中的基本步骤。然而，在实际应用中，这些距离经常被异方差噪声所扭曲——这是一种普遍存在的非均匀损坏形式，其特征是数据观测值之间的噪声大小可变。这种噪声以一种非平凡的方式膨胀了计算出的距离，导致对底层数据几何结构的错误表示。在这项工作中，我们解决了在高维异方差噪声下，估计每个观测值的噪声大小和校正成对欧几里得距离的任务。也许令人惊讶的是，我们发现，在一般高维设置下，并且不假设干净数据结构或噪声分布的先验知识，这两个任务都可以可靠地执行，即使噪声水平变化很大。具体来说，我们开发了一种原则性的、无超参数的方法，可以联合估计噪声大小并校正距离。我们为我们的方法提供了理论保证，建立了噪声大小和距离估计误差的概率界限。这些以归一化 $\ell_1$ 范数衡量的界限，随着特征维度和数据集大小的增加，以多项式速率收敛到零。在合成数据集上的实验表明，我们的方法在具有挑战性的情况下能准确估计距离，显著提高了后续基于距离计算的鲁棒性。值得注意的是，当应用于单细胞RNA测序数据时，我们的方法产生的噪声大小估计与已建立的原型模型一致，从而实现了对许多下游分析至关重要的准确最近邻识别。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [680] [Sliding Window Informative Canonical Correlation Analysis](https://arxiv.org/abs/2507.17921)
> *滑动窗口信息典范相关分析*

*Arvind Prasadan* | **Category: stat.ML, cs.LG, eess.IV, math.ST, stat.CO, stat.ME, stat.TH, 62H20, 62H25 (Primary) 62J10, 62L10 (Secondary)** | **Updated: 2025-07-23**

**Keywords:** 典范相关分析, 流式数据, 滑动窗口, 主成分分析, 高维数据

**Comment:** 22 pages, submitted

> **TL;DR:** 提出一种新的在线流数据CCA扩展方法SWICCA，结合流式PCA和滑动窗口实现实时CCA，适用于高维数据。

**AI_Comments:** 该论文的创新之处在于将经典的典范相关分析（CCA）扩展到在线流数据处理场景，解决了传统CCA在处理实时、高维数据时的局限性。其结合流式PCA和滑动窗口的策略具有实用价值，使得CCA能应用于更广泛的动态数据分析任务。

<details>
  <summary>Details</summary>

**Motivation:** 将传统的典范相关分析（CCA）扩展到在线、流式数据设置。

**Method:** 提出滑动窗口信息典范相关分析（SWICCA）。该方法使用流式主成分分析（PCA）算法作为后端，并结合少量样本的滑动窗口来实时估计CCA分量。

**Result:** 通过数值模拟表征了其性能，提供了理论性能保证，并提供了一个真实数据示例来证明其适用于极高维度和可扩展性。

**Conclusion:** SWICCA方法适用于极高维度，并且具有良好的可扩展性。

> **ai_Abstract:** 本文提出了一种名为滑动窗口信息典范相关分析（SWICCA）的新型方法，旨在将传统的典范相关分析（CCA）应用于在线流数据。SWICCA利用流式主成分分析（PCA）作为基础，并结合滑动窗口技术实现CCA分量的实时估计。研究通过数值模拟验证了其性能，提供了理论保证，并通过真实数据实例展示了该方法在处理极高维度数据时的适用性和可扩展性。

> **摘要翻译:** 典范相关分析（CCA）是一种用于在两个数据集中寻找相关特征集的技术。在本文中，我们提出了一种将CCA扩展到在线、流式数据设置的新颖方法：滑动窗口信息典范相关分析（SWICCA）。我们的方法使用流式主成分分析（PCA）算法作为后端，并结合少量样本的滑动窗口来实时估计CCA分量。我们阐述并描述了我们的算法，提供了数值模拟来表征其性能，并提供了理论性能保证。SWICCA方法适用于极高维度且具有可扩展性，我们提供了一个真实数据示例来证明这种能力。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [63] [Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift](https://arxiv.org/abs/2302.10160)
> *协变量偏移下核岭回归的伪标签方法*

*Kaizheng Wang* | **Category: stat.ME, cs.LG, math.ST, stat.ML, stat.TH, 62J07, 62G05** | **Updated: 2025-07-24**

**Keywords:** 核岭回归, 协变量偏移, 伪标签, 模型选择, 非渐近分析

**Comment:** 45 pages, 2 figures

> **TL;DR:** 本文提出并分析了一种在协变量偏移下对核岭回归使用伪标签进行模型选择的方法，并证明其达到最优误差率。

**AI_Comments:** 这篇论文的创新点在于将伪标签技术应用于协变量偏移下的核岭回归模型选择，并提供了严格的非渐近理论保证。其重要性在于，在数据分布不一致的现实场景中，提供了一种有效利用有限有标签数据和大量无标签数据进行回归学习的解决方案。研究结果表明伪标签在模型选择中的有效性，且不会牺牲性能，这对于实际应用具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在协变量偏移下，目标分布上的无标签数据和特征分布可能不同的有标签数据，如何学习一个在目标分布上具有小均方误差的回归函数。

**Method:** 将有标签数据分成两个子集，分别进行核岭回归以获得一组候选模型和一个插补模型。使用插补模型填充缺失标签，然后选择最佳候选模型。

**Result:** 所提出的估计器能够有效适应目标分布的结构和协变量偏移，并通过有效样本量的概念量化了这种适应性。该估计器在多对数因子内达到了最小最大最优误差率，并且使用伪标签进行模型选择不会显著阻碍性能。

**Conclusion:** 在协变量偏移下的核岭回归中，使用伪标签进行模型选择是一种有效且性能不受显著影响的方法，其估计器能够达到理论最优的误差率。

> **ai_Abstract:** 本文针对协变量偏移下的核岭回归问题，提出了一种新颖的伪标签方法。该方法将有标签数据分为两部分，分别训练出候选模型和插补模型，并利用插补模型生成伪标签以选择最优候选模型。理论分析表明，该估计器能有效适应目标分布和协变量偏移，达到近乎最优的误差率，并且伪标签的使用对性能无显著负面影响。

> **摘要翻译:** 我们开发并分析了一种在协变量偏移下进行核岭回归的原则性方法。目标是基于目标分布的无标签数据和可能具有不同特征分布的有标签数据，学习一个在目标分布上具有小均方误差的回归函数。我们建议将有标签数据分成两个子集，并分别对它们进行核岭回归，以获得一组候选模型和一个插补模型。我们使用后者来填充缺失的标签，然后相应地选择最佳候选模型。我们的非渐近超额风险界限表明，我们的估计器能有效地适应目标分布的结构和协变量偏移。这种适应性通过一种有效样本量的概念来量化，该概念反映了有标签源数据对目标回归任务的价值。我们的估计器在多对数因子内达到了最小最大最优误差率，并且我们发现使用伪标签进行模型选择不会显著阻碍性能。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [67] [CatchPhrase: EXPrompt-Guided Encoder Adaptation for Audio-to-Image Generation](https://arxiv.org/abs/2507.18750)
> *CatchPhrase：EXPrompt引导的编码器适应性音频到图像生成*

*Hyunwoo Oh, SeungJu Cha, Kwanyoung Lee, Si-Woo Kim, Dong-Jin Kim* | **Category: cs.MM, cs.SD, eess.AS** | **Updated: 2025-07-24**

**Keywords:** 音频到图像生成, 语义错位, 跨模态生成, 大型语言模型, 音频字幕模型

**Comment:** 

> **TL;DR:** CatchPhrase是一个新的音频到图像生成框架，通过利用大型语言模型和音频字幕模型生成的语义提示来解决音频输入和生成图像之间的语义错位问题。

**AI_Comments:** CatchPhrase的创新之处在于其EXPrompt引导的编码器适应方法，特别是利用LLMs和ACMs生成和选择语义丰富的提示，以解决音频到图像生成中的复杂语义错位问题。这种方法有效提升了跨模态生成的准确性和质量，对于多模态内容生成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态编码器在跨模态生成方面取得了进展，但同音异义词和听觉错觉引起的歧义仍然阻碍了准确的对齐。本文旨在解决音频输入和生成图像之间的语义错位问题。

**Method:** CatchPhrase通过以下步骤解决问题：1. EXPrompt Mining：利用大型语言模型（LLMs）和音频字幕模型（ACMs）从弱类别标签生成丰富的跨模态语义提示。2. EXPrompt Selector：应用多模态过滤和检索，为每个音频样本选择语义对齐最佳的提示，以解决类别级和实例级错位。3. 训练轻量级映射网络：使预训练的文本到图像生成模型适应音频输入。

**Result:** 在多个音频分类数据集上进行的广泛实验表明，CatchPhrase改进了音频到图像的对齐，并通过减轻语义错位持续增强了生成质量。

**Conclusion:** CatchPhrase通过其创新的EXPrompt引导编码器适应方法，成功解决了音频到图像生成中的语义错位问题，显著提升了生成质量和对齐度。

> **ai_Abstract:** CatchPhrase是一个新颖的音频到图像生成框架，旨在解决音频输入和生成图像之间的语义错位问题。它通过“EXPrompt Mining”利用LLMs和ACMs生成丰富的跨模态语义提示，并通过“EXPrompt Selector”选择最佳提示来解决类别级和实例级错位。随后，一个轻量级映射网络被训练以使预训练的文本到图像模型适应音频输入。实验证明，该方法有效提高了音频到图像的对齐和生成质量。

> **摘要翻译:** 我们提出了CatchPhrase，一个新颖的音频到图像生成框架，旨在减轻音频输入和生成图像之间的语义错位。尽管多模态编码器的最新进展使得跨模态生成取得了进展，但源于同音异义词和听觉错觉的歧义继续阻碍着准确的对齐。为了解决这个问题，CatchPhrase通过利用大型语言模型（LLMs）和音频字幕模型（ACMs），从弱类别标签生成丰富的跨模态语义提示（EXPrompt Mining）。为了解决类别级和实例级错位，我们应用多模态过滤和检索，为每个音频样本选择语义对齐最佳的提示（EXPrompt Selector）。然后训练一个轻量级映射网络，以使预训练的文本到图像生成模型适应音频输入。在多个音频分类数据集上进行的广泛实验表明，CatchPhrase改进了音频到图像的对齐，并通过减轻语义错位持续增强了生成质量。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [69] [Scalable Parameter Design for Superconducting Quantum Circuits with Graph Neural Networks](https://arxiv.org/abs/2411.16354)
> *基于图神经网络的超导量子电路可扩展参数设计*

*Hao Ai, Yu-xi Liu* | **Category: quant-ph, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 超导量子电路, 参数设计, 图神经网络, 可扩展性, 量子串扰

**Comment:** 

> **TL;DR:** 提出了一种基于图神经网络（GNNs）的超导量子电路参数设计算法，通过“三阶梯扩展”机制显著提高了大规模量子芯片的设计效率和错误缓解能力。

**AI_Comments:** 该论文的创新点在于首次将图神经网络引入超导量子芯片的参数设计，并提出了一种新颖的“三阶梯扩展”机制，有效解决了大规模量子系统模拟的挑战。其重要性体现在显著提升了量子芯片设计的效率和可扩展性，为未来大规模量子计算机的构建提供了关键技术支持。

<details>
  <summary>Details</summary>

**Motivation:** 随着大规模超导量子计算芯片的设计和制造，模拟量子系统的复杂性对计算机辅助设计（CAD）构成了巨大挑战，尤其对于大型芯片。

**Method:** 该算法依赖于“三阶梯扩展”机制，包含两个神经网络模型：一个在小规模电路上进行监督训练的评估器（用于中等规模电路），以及一个在中等规模电路上进行无监督训练的设计器（用于大规模电路）。同时考虑了单量子比特和双量子比特门的频率（对应节点和边的参数）。

**Result:** 数值结果表明，训练有素的设计器在效率、有效性和可扩展性方面具有显著优势。例如，对于约870个量子比特的大规模超导量子电路，该GNNs算法将错误率降低到现有最先进算法的51%，并且时间从90分钟缩短到27秒。

**Conclusion:** 提出了一种性能更好、可扩展性更强的超导量子芯片参数设计算法，首次展示了将GNNs应用于超导量子芯片的优势。

> **ai_Abstract:** 该论文提出了一种利用图神经网络（GNNs）进行超导量子电路参数设计的可扩展算法，旨在解决大规模量子芯片计算机辅助设计的复杂性问题。该算法采用“三阶梯扩展”机制，包括一个用于中等规模电路的评估器和一个用于大规模电路的设计器，并同时考虑单量子比特和双量子比特门的频率。实验证明，该方法在大规模电路设计中显著提高了效率、有效性和可扩展性，例如，在870个量子比特的电路上，将错误率降低到现有方法的51%，并将设计时间从90分钟缩短到27秒，首次展示了GNNs在超导量子芯片设计中的应用优势。

> **摘要翻译:** 为了证明量子计算的优越性，人们正在设计和制造越来越大规模的超导量子计算芯片。然而，模拟量子系统的复杂性对量子芯片的计算机辅助设计构成了重大挑战，特别是对于大规模芯片。我们在此利用图神经网络（GNNs）的可扩展性，提出了一种用于大规模超导量子电路的参数设计算法。该算法依赖于所谓的“三阶梯扩展”机制，该机制包括两个神经网络模型：一个在小规模电路上进行监督训练的评估器，用于应用于中等规模电路；以及一个在中等规模电路上进行无监督训练的设计器，用于应用于大规模电路。我们展示了我们的算法在缓解量子串扰错误方面的应用。同时考虑了单量子比特和双量子比特门的频率（对应于节点和边的参数）。数值结果表明，训练有素的设计器在效率、有效性和可扩展性方面取得了显著优势。例如，对于包含约870个量子比特的大规模超导量子电路，我们的基于GNNs的算法实现了最先进算法产生的错误的51%，并将时间从90分钟减少到27秒。总而言之，我们提出了一种性能更好、可扩展性更强的超导量子芯片参数设计算法，该算法初步展示了将GNNs应用于超导量子芯片的优势。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [284] [Hybrid Reward-Driven Reinforcement Learning for Efficient Quantum Circuit Synthesis](https://arxiv.org/abs/2507.16641)
> *混合奖励驱动的强化学习用于高效量子电路合成*

*Sara Giordano, Kornikar Sen, Miguel A. Martin-Delgado* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 量子电路合成, 强化学习, Q-learning, 混合奖励, 量子优化

**Comment:** 13 pages, 4 figures, color figures

> **TL;DR:** 该研究引入了一种基于混合奖励机制的强化学习框架，利用表格Q-learning和离散量子态空间，高效合成最小深度和优化门数的量子电路，以应对量子电路合成的挑战。

**AI_Comments:** 该论文的创新之处在于其将强化学习应用于量子电路合成，特别是通过离散化量子态空间和引入独特的混合奖励机制来应对量子态空间指数增长的挑战。这种方法能够高效地探索复杂的量子态空间并合成接近最优的量子电路，对于资源受限的NISQ设备和未来的容错量子计算都具有重要意义。其鲁棒性和生成最小深度电路的能力是其突出优点。

<details>
  <summary>Details</summary>

**Motivation:** 在NISQ时代和未来的容错量子计算中，高效合成能够从固定初始态生成指定目标量子态的量子电路是一个核心挑战。

**Method:** 该方法采用基于动作序列的表格Q-learning，在离散的量子态空间中操作，以有效管理空间维度的指数增长。它引入了一种混合奖励机制，结合了指导智能体朝向目标态的静态领域知识奖励，以及惩罚门拥塞和重复访问等低效电路结构的动态惩罚。通过利用稀疏矩阵表示和态空间离散化，该方法实现了高维环境的可伸缩导航，同时最小化了计算开销。

**Result:** 在多达七个量子比特的图态制备任务中，该算法始终能发现最小深度和优化门数的电路。将该框架扩展到任意量子态的通用门集时，它仍然能生成最小深度的电路，这突显了算法的鲁棒性和适应性。

**Conclusion:** 研究结果证实，这种强化学习驱动的方法能高效探索复杂的量子态空间并合成接近最优的量子电路，为量子电路优化提供了资源高效的基础。

> **ai_Abstract:** 该论文提出了一种基于强化学习的量子电路合成框架，旨在从固定初始态生成特定目标量子态。该框架采用表格Q-learning，并在离散量子态空间中操作以应对维度爆炸问题。其核心创新在于引入了一种混合奖励机制，结合了静态领域知识奖励和动态惩罚，以鼓励高效的电路结构。通过稀疏矩阵和离散化，该方法实现了高维环境下的可伸缩性。实验证明，该算法能在图态制备和通用门集任务中发现最小深度和优化门数的电路，显示出其高效性、鲁棒性和适应性，为量子电路优化提供了资源高效的解决方案。

> **摘要翻译:** 本研究引入了一种强化学习（RL）框架，用于高效合成从固定初始态生成指定目标量子态的量子电路，解决了NISQ时代和未来容错量子计算中的一个核心挑战。该方法利用基于动作序列的表格Q-learning，在离散的量子态空间中操作，以有效管理空间维度的指数增长。该框架引入了一种混合奖励机制，结合了指导智能体朝向目标态的静态、领域知识奖励，以及惩罚门拥塞和重复访问等低效电路结构的可定制动态惩罚。通过利用稀疏矩阵表示和态空间离散化，该方法实现了高维环境的可伸缩导航，同时最大程度地减少了计算开销。在多达七个量子比特的图态制备任务上进行基准测试，我们证明该算法始终能发现最小深度和优化门数的电路。此外，将该框架扩展到任意量子态的通用门集时，它仍然能生成最小深度的电路，这突显了算法的鲁棒性和适应性。结果证实，这种强化学习驱动的方法能高效探索复杂的量子态空间并合成接近最优的量子电路，为量子电路优化提供了资源高效的基础。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [341] [Early State Exclusion in 7-Qubit Spin Chains](https://arxiv.org/abs/2507.18767)
> *7量子比特自旋链中的早期态排除*

*Mia Gabriella Escobar, Valentin Garcia, Anastasiia Minenkova* | **Category: quant-ph, cs.NA, math.NA, 15A29, 81P45, 47B36, 33C45** | **Updated: 2025-07-24**

**Keywords:** 早期态排除, 量子自旋链, Jacobi矩阵, 量子比特

**Comment:** 11 pages, 8 figures

> **TL;DR:** 本文解决了奇数N≥7时，含/不含早期态排除的量子自旋链哈密顿量Jacobi矩阵的存在性问题，并给出了7x7矩阵的无限族。

**AI_Comments:** 这项研究解决了量子自旋链哈密顿量在奇数N值下存在性的一个长期存在的开放问题，为理解量子自旋链的物理性质提供了重要的理论基础。其创新点在于为7量子比特系统构建了具体的Jacobi矩阵族。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究已证明当N为偶数且N≥4时，含或不含早期态排除（ESE）的N×N Jacobi矩阵（代表量子自旋链的哈密顿量）存在。然而，对于奇数N≥7的情况，其存在性仍是一个未解决的问题。

**Method:** 作者考虑了一个经历最近邻相互作用并受环境效应影响的量子比特链，并提出了无限族7x7 Jacobi矩阵，这些矩阵包含或不包含早期态排除。

**Result:** 提出了无限族7x7 Jacobi矩阵，这些矩阵代表了含或不含早期态排除的量子自旋链的哈密顿量。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文解决了奇数N≥7时，含或不含早期态排除（ESE）的量子自旋链哈密顿量Jacobi矩阵存在性的开放问题。研究通过考虑一个受环境效应影响的7量子比特链，成功提出了无限族7x7 Jacobi矩阵，这些矩阵代表了含或不含ESE的哈密顿量。

> **摘要翻译:** 抽象：对于任何偶数N≥4，已证明存在代表含或不含早期态排除（ESE）的量子自旋链哈密顿量的N×N Jacobi矩阵的无限族。然而，对于奇数N≥7的情况，它们的存在性仍然是一个未解决的问题。在第三节中，我们考虑了一个经历最近邻相互作用并受环境效应影响的量子比特链，并提出了无限族7×7 Jacobi矩阵，这些矩阵含或不含ESE。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [425] [Translating Between the Common Haar Random State Model and the Unitary Model](https://arxiv.org/abs/2503.11634)
> *通用哈尔随机态模型与酉模型之间的转换*

*Eli Goldin, Mark Zhandry* | **Category: quant-ph, cs.CR** | **Updated: 2025-07-23**

**Keywords:** 通用哈尔随机态模型, 酉模型, 黑盒分离, 量子密码学, 分离证明

**Comment:** 39 pages

> **TL;DR:** 本文证明了通用哈尔随机态（CHRS）模型下的分离可以在特定条件下提升为酉分离，从而为量子原语提供了简单、模块化且无错误的分离证明。

**AI_Comments:** 本文解决了量子密码学中一个关键问题，即如何将不完整的CHRS模型分离提升为完整的酉模型分离。其创新之处在于提出了通用的提升条件，这使得证明过程更加简洁、模块化且不易出错。这项工作对于确保量子密码原语的安全性边界具有重要意义，因为它纠正了现有研究中的错误并扩展了已知的酉分离。

<details>
  <summary>Details</summary>

**Motivation:** 黑盒分离是密码学的基础，但通用哈尔随机态（CHRS）模型下的量子密码学原语分离被认为是不完整的。最近的一些工作试图将这些分离提升到完整的酉分离，但发现其中存在显著错误。因此，本文旨在提供一种可靠的方法来将CHRS分离通用地提升为酉分离。

**Method:** 本文证明了CHRS分离可以通用提升的普适条件。

**Result:** 本文提供了简单、模块化且无错误的量子原语完整酉分离证明。这些技术不仅简化了现有分离的证明，还发现了以前只在CHRS模型中已知的新分离。

**Conclusion:** 通过证明CHRS分离可以通用提升的条件，本文成功地提供了可靠的、完整的量子原语酉分离证明，并扩展了已知分离的范围。

> **ai_Abstract:** 本文研究了量子密码学中黑盒分离的转换问题，特别是从通用哈尔随机态（CHRS）模型到完整的酉模型。鉴于现有提升结果中存在的错误，作者提出了通用条件，证明了CHRS分离可以可靠地提升为酉分离。这不仅简化了现有分离的证明，还发现了以前仅在CHRS模型中已知的新分离，从而为量子密码学提供了更稳健的分离证明。

> **摘要翻译:** 黑盒分离是密码学的基石，它揭示了各种目标的障碍。最近的一系列工作探索了量子密码原语的黑盒分离。具体来说，在通用哈尔随机态（CHRS）模型中已知许多分离，尽管该模型不被认为是完全分离，而是一个起点。最近的一些工作试图将这些分离提升到酉分离，这被认为是完全分离。不幸的是，我们发现在一些提升结果中存在显著错误。
我们证明了CHRS分离可以在何种通用条件下被提升，从而为各种量子原语提供了简单、模块化且无错误的完整酉分离证明。我们的技术使得现有分离的证明更加简单，并且发现了以前只在CHRS模型中已知的新分离。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [591] [Hybrid quantum-classical algorithm for near-optimal planning in POMDPs](https://arxiv.org/abs/2507.18606)
> *混合量子-经典算法用于部分可观测马尔可夫决策过程中的近最优规划*

*Gilberto Cunha, Alexandra Ramôa, André Sequeira, Michael de Oliveira, Luís Barbosa* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 量子强化学习, 部分可观测马尔可夫决策过程, 混合算法, 贝叶斯网络, 计算加速

**Comment:** 

> **TL;DR:** 本文提出了一种混合量子-经典算法QBRL，利用量子增强的信念更新，在部分可观测环境中实现了亚二次方的近最优规划加速。

**AI_Comments:** 本文的创新之处在于将量子计算方法引入部分可观测环境下的强化学习，提出了QBRL算法，并通过量子增强的信念更新实现了计算加速。其严谨的无预言机时间复杂度分析比传统黑盒假设更具实际意义。然而，文中也指出量子优势的大小会因部署设置而异，这提示了该技术在实际应用中可能面临的挑战和需要进一步研究的领域。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习（RL）在部分可观测环境（如POMDPs）中的决策制定面临计算挑战，而现有量子加速推理的成果为解决这一问题提供了可能。

**Method:** 本文引入了量子贝叶斯强化学习（QBRL），这是一种混合量子-经典前瞻算法，用于部分可观测环境中的基于模型的强化学习。该方法利用量子拒绝采样结合幅度放大来加速稀疏贝叶斯网络上的推理，从而实现量子增强的信念更新。研究中进行了在容错量子设备假设下的严格、无预言机的时间复杂度分析，并进行了数值实验将QBRL与经典算法进行基准测试。

**Result:** 研究表明，对于其动态形成稀疏贝叶斯网络的环境，通过量子增强的信念更新，可以实现亚二次方（sub-quadratically）更快的基于视野的近最优规划。数值实验揭示了量子计算优势如何转化为决策性能，并强调了该优势的大小在不同部署设置中可能显著不同。

**Conclusion:** 本文提出的QBRL算法能够为部分可观测环境中的近最优规划提供显著的计算加速，尽管实际优势的大小取决于具体的部署设置。

> **ai_Abstract:** 本文介绍了量子贝叶斯强化学习（QBRL），一种混合量子-经典算法，用于部分可观测马尔可夫决策过程（POMDPs）中的近最优规划。QBRL利用量子拒绝采样和幅度放大加速贝叶斯网络推理，从而实现量子增强的信念更新。研究表明，在动态为稀疏贝叶斯网络的环境中，QBRL能以亚二次方速度实现近最优规划。通过严谨的时间复杂度分析和数值实验，本文探讨了量子计算优势对决策性能的影响及其在不同部署设置下的变异性。

> **摘要翻译:** 强化学习（RL）为部分可观测环境中的决策提供了原则性框架，这些环境可以建模为马尔可夫决策过程并通过动态决策贝叶斯网络紧凑表示。最近的进展表明，结合幅度放大的量子拒绝采样可以加速稀疏贝叶斯网络上的推理，从而在估计接受概率方面实现计算加速。在此结果的基础上，我们引入了量子贝叶斯强化学习（QBRL），这是一种用于部分可观测环境中基于模型的RL的混合量子-经典前瞻算法。我们对量子设备在容错假设下进行了严格的、无预言机的时间复杂度分析。与假设黑盒预言机的标准处理方法不同，我们明确指定了推理过程，这使得我们的界限能更准确地反映真实的计算成本。我们表明，对于其动态形成稀疏贝叶斯网络的环境，通过量子增强的信念更新，可以实现亚二次方更快的基于视野的近最优规划。此外，我们通过数值实验将QBRL与其经典对应算法在简单但具有启发性的决策任务上进行了基准测试。我们的结果详细分析了量子计算优势如何转化为决策性能，强调了优势的大小在不同部署设置中可能显著不同。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [593] [Non-Variational Quantum Random Access Optimization with Alternating Operator Ansatz](https://arxiv.org/abs/2502.04277)
> *采用交替算子变分法的非变分量子随机存取优化*

*Zichang He, Rudy Raymond, Ruslan Shaydulin, Marco Pistoia* | **Category: quant-ph, cs.ET** | **Updated: 2025-07-24**

**Keywords:** 量子优化, QRAO, QAOA, 非变分, MaxCut

**Comment:** 9 pages, 8+1 figures, accepted by Scientific Reports

> **TL;DR:** 该论文提出了一种基于量子交替算子变分法（QAOA）的非变分量子随机存取优化（QRAO）方法，用于解决MaxCut问题。研究表明，使用与实例无关的固定参数也能达到良好性能，从而避免了变分参数优化的需要。

**AI_Comments:** 本文通过为QRAO提出一种非变分方法，解决了变分量子算法的一个关键限制（即需要针对特定实例进行参数调整）。固定参数能够产生良好性能的发现意义重大，因为它极大地简化了量子优化在近期和早期容错量子计算机上的实现和可扩展性。这项工作有助于使量子优化更加实用。

<details>
  <summary>Details</summary>

**Motivation:** 近期量子计算机在处理工业规模优化问题时面临规模和量子纠错开销的限制。量子随机存取优化（QRAO）旨在减少空间需求，但目前的实现均采用变分算法，这些算法需要训练特定于实例的参数，导致难以扩展。

**Method:** 本文提出并基准测试了一种基于量子交替算子变分法（QAOA）的非变分QRAO方法，应用于MaxCut问题。研究中评估了不同的设计选择，包括各种混合器、初始状态以及QRAO特有的QAOA成本算子实现。

**Result:** 研究表明，与实例无关的“固定”参数能够实现良好的性能，从而消除了变分参数优化的需要。此外，研究确定了一种在实践中表现良好的策略。

**Conclusion:** 本研究的结果为在早期容错量子计算机上实际执行量子随机存取优化（QRAO）铺平了道路。

> **ai_Abstract:** 本文提出了一种非变分量子随机存取优化（QRAO）方法，该方法利用量子交替算子变分法（QAOA）来解决MaxCut问题。与以往需要针对特定实例调整参数的变分QRAO实现不同，本方法证明了固定且与实例无关的参数也能实现优异性能，从而解决了可扩展性挑战。该研究还探索了混合器和初始状态等多种设计元素，并识别出一种有效的实用策略，这为QRAO在未来容错量子计算机上的可行性奠定了基础。

> **摘要翻译:** 解决困难的优化问题是量子计算机最有前景的应用领域之一，因为此类问题在工业中无处不在，并且存在广泛适用的量子加速。然而，近期量子计算机处理工业规模优化问题的能力受到其规模和量子纠错开销的限制。量子随机存取优化（QRAO）已被提出以减少量子优化所需的空间。然而，迄今为止，QRAO仅通过变分算法实现，这些算法需要训练特定于实例的变分参数，使其难以扩展。我们提出并基准测试了一种基于量子交替算子变分法（QAOA）的非变分QRAO方法，用于MaxCut问题。我们表明，与实例无关的“固定”参数可以实现良好的性能，从而消除了变分参数优化的需要。此外，我们评估了不同的设计选择，例如各种混合器、初始状态以及QAOA成本算子的QRAO特定实现，并确定了一种在实践中表现良好的策略。我们的结果为在早期容错量子计算机上实际执行QRAO铺平了道路。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [641] [Is Circuit Depth Accurate for Comparing Quantum Circuit Runtimes?](https://arxiv.org/abs/2505.16908)
> *量子电路深度在比较量子电路运行时是否准确？*

*Matthew Tremba, Paul Hovland, Ji Liu* | **Category: quant-ph, cs.ET** | **Updated: 2025-07-24**

**Keywords:** 量子电路深度, 运行时, 门感知深度, 量子硬件, 电路编译

**Comment:** 8 pages, 6 figures

> **TL;DR:** 量子电路深度在比较运行时不准确，本文提出了一种新的度量标准——门感知深度，它通过考虑不同门的执行时间来更准确地预测量子电路的运行时。

**AI_Comments:** 这篇论文的创新点在于提出了“门感知深度”这一新颖的度量标准，有效地解决了传统电路深度在评估量子电路运行时方面的局限性。通过考虑不同门的实际执行时间，该方法为量子电路的编译优化和性能评估提供了更准确、更实用的工具。其重要性体现在它能帮助开发者更好地理解和优化量子程序的实际运行性能，尤其是在当前量子硬件门执行时间不一的背景下。该方法在保持便携性的同时显著提升了预测准确性，具有很强的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管量子电路深度常用于近似电路运行时，但它忽略了当前硬件实现中不同门具有不同执行时间的普遍特性，这可能导致运行时比较的差异。因此，研究人员调查了电路深度在比较相同电路的不同编译版本的运行时方面的准确性。

**Method:** 研究人员评估了传统深度和多量子位深度在预测运行时相对差异和识别最短运行时编译版本方面的准确性。由于发现电路深度不准确，他们引入了一种新的度量标准——门感知深度，该标准使用架构的平均门执行时间来加权门对运行时的贡献。这种方法允许在不完全了解所有门时间的情况下捕获门类型间的差异，同时保持跨相同架构设备的便携性。

**Result:** 电路深度对于预测运行时差异和识别最短运行时版本均不准确。与传统深度和多量子位深度相比，门感知深度在任务（1）中将预测的平均相对误差分别降低了68倍和18倍，在任务（2）中将正确识别的平均数量分别提高了20和43个百分点。此外，论文还提供了适用于当前IBM Eagle和Heron架构的门感知深度权重配置。

**Conclusion:** 电路深度不是比较量子电路运行时的准确指标。门感知深度通过考虑不同门的执行时间，能够显著提高运行时预测的准确性，并更有效地识别最短运行时的电路版本，从而为量子电路编译和性能评估提供了更可靠的工具。

> **ai_Abstract:** 本研究发现，常用的量子电路深度在比较不同编译版本的电路运行时方面并不准确，因为它忽略了不同量子门执行时间不同的事实。为了解决这一问题，论文提出了一种名为“门感知深度”的新度量标准。该标准通过考虑平均门执行时间来加权门的贡献，从而在不需要精确门时间的情况下提高运行时预测的准确性和跨设备的可移植性。实验结果表明，门感知深度在预测运行时差异和识别最短运行时版本方面，相比传统和多量子位深度，表现出显著的准确性提升，并提供了针对IBM Eagle和Heron架构的权重配置。

> **摘要翻译:** 尽管量子电路深度通常用于近似电路运行时，但它忽略了当前硬件实现的一个普遍特征：不同门的执行时间不同。认识到潜在的差异，我们研究了深度在比较同一电路编译版本之间运行时方面的准确性。特别是，我们评估了传统深度和多量子位深度在（1）预测运行时相对差异和（2）识别运行时最短的编译电路版本方面的准确性。我们发现电路深度对于这两个任务都不准确，因此引入了一种新的度量标准——门感知深度，它使用架构的平均门执行时间来加权门对运行时的贡献。使用平均门时间使门感知深度能够在不需要精确了解所有门时间的情况下捕获按门类型变化的差异，从而提高准确性，同时保持跨相同架构设备的便携性。与传统深度和多量子位深度相比，门感知深度在任务（1）中将预测的平均相对误差分别降低了68倍和18倍，在任务（2）中将正确识别的平均数量分别提高了20和43个百分点。最后，我们提供了适用于当前IBM Eagle和Heron架构的门感知深度权重配置。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [721] [Quantum Machine Learning Playground](https://arxiv.org/abs/2507.17931)
> *量子机器学习游乐场*

*Pascal Debus, Sebastian Issel, Kilian Tscharke* | **Category: quant-ph, cs.GR, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 量子机器学习, 可视化, 交互式工具, 教育, 量子计算

**Comment:** Accepted to IEEE Computer Graphics and Applications. Final version:
  https://doi.org/10.1109/MCG.2024.3456288

> **TL;DR:** 本文介绍了一个交互式可视化工具，旨在降低量子机器学习（QML）的入门门槛，并鼓励该领域的进一步创新。

**AI_Comments:** 该论文提出并实现了一个开创性的量子机器学习可视化工具，填补了该领域的一个重要空白。其创新之处在于将经典机器学习的可视化成功经验引入QML，有望显著降低QML的学习曲线，对该领域的教育和普及具有重要意义。作为一个“游乐场”，它提供了一个直观的探索环境，对于初学者和研究人员都具有实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 受经典机器学习可视化工具（如TensorFlow Playground）成功的启发，本文旨在弥补量子机器学习领域可视化资源的空白。

**Method:** 本文涵盖了量子计算和经典机器学习中相关可视化隐喻的全面概述，开发了算法可视化概念，并设计了一个具体的交互式Web应用程序实现。通过结合针对数据重上传通用量子分类器（一种代表性QML模型）的常见可视化隐喻，实现了该工具。

**Result:** 开发了一个伴随的交互式应用程序，作为量子机器学习游乐场的第一版，用于学习和探索QML模型。

**Conclusion:** 该工具旨在降低量子计算的入门门槛，并鼓励该领域的进一步创新。

> **ai_Abstract:** 本文介绍了一个创新的交互式可视化工具——量子机器学习游乐场，旨在揭示量子机器学习（QML）算法的奥秘。受经典机器学习可视化工具的启发，该工作旨在弥补QML可视化资源的不足。文章详细介绍了相关可视化隐喻、算法可视化概念的开发以及作为交互式Web应用程序的具体实现设计。通过结合数据重上传通用量子分类器的可视化隐喻，该工具旨在降低量子计算的入门门槛，并促进该领域的创新。

> **摘要翻译:** 本文介绍了一个创新的交互式可视化工具，旨在揭示量子机器学习（QML）算法的奥秘。我们的工作受到经典机器学习可视化工具（如TensorFlow Playground）成功的启发，旨在弥补专门针对QML领域的可视化资源空白。本文包括对量子计算和经典机器学习中相关可视化隐喻的全面概述、算法可视化概念的开发以及作为交互式Web应用程序的具体实现设计。通过结合针对所谓数据重上传通用量子分类器（作为代表性QML模型）的常见可视化隐喻，本文旨在降低量子计算的入门门槛，并鼓励该领域的进一步创新。随附的交互式应用程序是量子机器学习游乐场的第一版提案，用于学习和探索QML模型。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matmtrl-sci'></a>
## cond-mat.mtrl-sci 

### [97] [Performance in solving the Hermitian and pseudo-Hermitian Bethe-Salpeter equation with the Yambo code](https://arxiv.org/abs/2504.10096)
> *使用Yambo代码求解厄米和伪厄米Bethe-Salpeter方程的性能*

*Petru Milev, Blanca Mellado-Pinto, Muralidhar Nalabothula, Ali Esquembre Kucukalic, Fernando Alvarruiz, Enrique Ramos, Alejandro Molina-Sanchez, Ludger Wirtz, Jose E. Roman, Davide Sangalli* | **Category: cond-mat.mtrl-sci, cs.DC, 81-04, A.0** | **Updated: 2025-07-24**

**Keywords:** Bethe-Salpeter方程, Yambo代码, 特征值问题, 性能分析, 密集矩阵

**Comment:** Submitted to SciPost Physics Codebases

> **TL;DR:** 本文分析了使用Yambo代码结合不同库（ScaLAPACK/ELPA/SLEPc）求解厄米和伪厄米Bethe-Salpeter方程的性能，结果表明可以处理10^5量级的密集BSE矩阵。

**AI_Comments:** 这项工作通过优化Yambo代码与高性能线性代数库的接口，显著提升了求解大规模Bethe-Salpeter方程的能力，这对于凝聚态物理领域的大规模模拟具有重要意义。特别是处理10^5量级密集矩阵的突破，扩大了BSE在实际计算中的应用范围。

<details>
  <summary>Details</summary>

**Motivation:** 解决凝聚态物理中Bethe-Salpeter方程（BSE）产生的结构化特征值问题，并分析不同策略的性能。

**Method:** 使用Yambo代码构建BSE矩阵；通过将Yambo与ScaLAPACK和ELPA库接口实现直接对角化，与SLEPc库接口实现迭代方法；考虑厄米和伪厄米形式，处理三种不同大小的密集矩阵；在CPU和GPU集群上分析了时间消耗和内存利用率；提供了实现细节，特别是伪厄米情况。

**Result:** 结果表明，现在可以处理10$^5$量级的密集BSE矩阵。

**Conclusion:** 求解BSE方程，特别是处理大规模密集矩阵的性能得到了显著提升，使其在实际应用中变得可行。

> **ai_Abstract:** 本文研究了使用Yambo代码求解凝聚态物理中Bethe-Salpeter方程的结构化特征值问题的性能。作者比较了两种策略：基于ScaLAPACK/ELPA的直接对角化和基于SLEPc的迭代方法，并考虑了厄米和伪厄米形式。通过在CPU和GPU集群上分析时间与内存利用率，证明了处理高达10^5量级的密集BSE矩阵已成为可能。

> **摘要翻译:** 我们分析了在凝聚态物理中求解源自Bethe-Salpeter方程（BSE）的结构化特征值问题的两种策略的性能。BSE矩阵使用Yambo代码构建，两种策略通过将Yambo与用于直接对角化的ScaLAPACK和ELPA库，以及用于迭代方法的SLEPc库进行接口实现。我们考虑了厄米（Tamm-Dancoff近似）和伪厄米形式，处理了三种不同大小的密集矩阵。文中还提供了实现的描述，包括伪厄米情况的详细信息。在CPU和GPU集群上分析了时间消耗和内存利用率。我们的结果表明，现在处理10$^5$量级的密集BSE矩阵是可行的。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phim'></a>
## astro-ph.IM 

### [111] [Recommendations to overcome language barriers in the Vera C. Rubin Observatory Research Ecosystem](https://arxiv.org/abs/2507.18682)
> *克服维拉·C·鲁宾天文台研究生态系统中语言障碍的建议*

*José Antonio Alonso Pavón, Andrés Alejandro Plazas Malagón* | **Category: astro-ph.IM, cs.CY, physics.soc-ph** | **Updated: 2025-07-24**

**Keywords:** 语言障碍, 多语言, 科学交流, 鲁宾天文台, 学术写作

**Comment:** 19 pages, accepted for publication at the Bulletin of the American
  Astronomical Society (peer review requested), Vol. 57, Issue 1

> **TL;DR:** 本报告提出了五项建议，旨在减少维拉·C·鲁宾天文台研究生态系统中的语言障碍，以促进将英语作为第二语言的研究人员的更广泛参与。

**AI_Comments:** 该论文的创新之处在于其全面且多维度的语言障碍解决方案，不仅关注语言技能提升，更强调构建支持性生态系统，并前瞻性地纳入了AI工具的伦理使用。其重要性在于，它为国际大型科研项目如何促进语言公平、提升全球科研合作效率提供了具体且可操作的指导，有望引领科学交流的民主化进程。

<details>
  <summary>Details</summary>

**Motivation:** 认识到科学领域中英语的语言霸权限制了研究人员的参与和生产力，本报告旨在提供一套全面的建议来减少语言障碍，促进将英语作为第二语言的研究人员的更广泛包容。

**Method:** 本报告提出了五项核心建议：多语言演示格式、学术写作培训、虚拟写作中心、语言支持计划和写作静修。这些建议基于教学理论和实证证据，强调协作式、社会嵌入式的科学写作方法。还鼓励道德地使用人工智能工具进行翻译和写作辅助。

**Result:** 通过实施这些建议，旨在将语言从障碍转变为资源，将多语言能力视为全球研究合作中的一项资产。预计这将使生态系统能够引领科学交流的民主化，并培养更公平、多语言的研究文化。

**Conclusion:** 本报告倡导采用可适应的、社区驱动的策略，这些策略可以在鲁宾研究生态系统多样化的机构和学科背景中发展，而不是提供一刀切的解决方案。

> **ai_Abstract:** 本报告针对维拉·C·鲁宾天文台研究生态系统中的语言障碍，提出了五项综合性建议，旨在提升非英语母语研究人员的参与度。报告指出英语霸权限制了科学交流，因此提议采用多语言演示、学术写作培训、设立虚拟写作中心、提供语言支持项目及组织写作静修。这些建议根植于教学理论与实证，并强调协作与社会嵌入式方法，同时鼓励伦理地使用AI工具。目标是将语言从障碍转变为资源，视多语言为资产，以促进科学交流的民主化和构建更公平、多语言的研究文化。

> **摘要翻译:** 本报告提出了一套全面的五项建议，旨在减少维拉·C·鲁宾天文台研究生态系统中的语言障碍，促进将英语作为第二语言的研究人员的更广泛包容。认识到科学领域中英语的语言霸权限制了参与和生产力，该文件提出了多语言演示格式、学术写作培训、虚拟写作中心、语言支持计划和写作静修。每项建议都以教学理论和实证证据为基础，强调协作式、社会嵌入式的科学写作方法。所提出的学术写作培训整合了建构主义和社会文化视角，强调语体意识、修辞能力和反思实践。虚拟写作中心将作为永久性基础设施，提供个性化辅导和同行评审支持，而语言支持计划则通过研讨会、咨询和语言工具的使用来解决持续的需求。写作静修提供沉浸式环境，用于集中工作和指导。这些建议还鼓励道德地使用人工智能工具进行翻译和写作辅助，在培养语言能力的同时培养数字素养。总的来说，这些举措旨在将语言从障碍转变为资源，将多语言能力视为全球研究合作中的一项资产。该文件没有提供一刀切的解决方案，而是倡导可适应的、社区驱动的策略，这些策略可以在鲁宾研究生态系统多样化的机构和学科背景中发展。通过实施这些实践，该生态系统可以引领科学交流的民主化，并培养更公平、多语言的研究文化。

</details>

[⬆️ 返回分类顶部](#astro-phim) | [⬆️ 返回总目录](#toc)

---

<a id='csgt'></a>
## cs.GT 

### [118] [Online Housing Market](https://arxiv.org/abs/2501.15916)
> *在线房屋市场*

*Julien Lesca* | **Category: cs.GT, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 在线房屋市场, 机制设计, 串行独裁, 顶部交易循环, 不可能性结果

**Comment:** 

> **TL;DR:** 这篇论文研究了在线房屋市场问题，扩展了串行独裁和顶部交易循环机制。研究表明，在在线环境中同时实现所有理想属性是不可能的，并提出了实现部分属性的变体。

**AI_Comments:** 这篇论文通过将在线市场的动态性引入经典问题，解决了机制设计中的一个重要挑战。其不可能性结果是一个关键贡献，揭示了根本性的局限性。这项工作对于理解设计高效和公平的在线分配机制中的权衡至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 将经典的房屋市场问题扩展到代理人动态进出的在线场景，并试图保留帕累托效率、个体理性、策略稳健性等理想属性，同时防止代理人策略性地延迟到达或提前离开。

**Method:** 作者将串行独裁机制和盖尔的顶部交易循环机制扩展到在线场景。然后，分析在在线环境中同时实现帕累托效率、个体理性、策略稳健性以及防止策略性时间选择等属性的可能性。

**Result:** 在线环境中同时实现所有这些理想属性是不可能的。论文提出了几种变体，每种变体都能实现这些属性的不同子集。

**Conclusion:** 在线房屋市场中，同时实现帕累托效率、个体理性、策略稳健性以及防止策略性时间选择是不可能的。论文提出了实现部分属性的替代方案。

> **ai_Abstract:** 这篇论文研究了在线房屋市场问题，其中代理人动态地进入和退出市场。作者将串行独裁和顶部交易循环等经典机制应用于这种在线环境，旨在保留帕累托效率、个体理性、策略稳健性等理想属性，并阻止代理人进行策略性时间操作。研究结果表明，在在线环境中同时实现所有这些期望属性是不可能的。因此，论文提出了几种能够实现这些属性不同子集的变体机制。

> **摘要翻译:** 本文研究了著名的房屋市场问题的一个在线变体，其中每个代理人拥有一套房屋，并根据其偏好寻求将其交换为另一套房屋。在这种在线设置中，代理人可以随时到达和离开，这意味着并非所有代理人都同时出现在房屋市场上。我将众所周知的串行独裁机制和盖尔的顶部交易循环机制扩展到这种在线场景，旨在保留其理想属性，如帕累托效率、个体理性以及策略稳健性。这些扩展也试图阻止代理人策略性地延迟到达或提前离开。我证明了在在线环境中同时实现所有这些属性是不可能的，并且我提出了几种实现这些属性不同子集的变体。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

<a id='hep-ph'></a>
## hep-ph 

### [140] [Variational inference for pile-up removal at hadron colliders with diffusion models](https://arxiv.org/abs/2410.22074)
> *强子对撞机中基于扩散模型的堆积去除变分推断*

*Malte Algren, Tobias Golling, Christopher Pollard, John Andrew Raine* | **Category: hep-ph, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 堆积去除, 变分推断, 扩散模型, 粒子物理, 硬散射喷注

**Comment:** 19 pages, 13 figures

> **TL;DR:** 本文提出了一种名为 vipr 的新方法，利用扩散模型和变分推断在强子对撞机中进行堆积去除，通过生成模型预测硬散射粒子喷注成分，并在各种堆积场景下表现出色。

**AI_Comments:** 本文的创新之处在于首次将扩散模型和变分推断应用于强子对撞机中的堆积去除问题，并采用生成模型来估计硬散射喷注成分的完整后验分布。这为解决探测器效率不完美下的堆积问题提供了新的视角和更鲁棒的解决方案，对高能物理数据分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在强子对撞机中，准确识别和去除来自非目标碰撞（堆积）的粒子是挑战。现有方法在探测器效率不完美时可能性能受限。本文旨在提出一种更有效的方法来估计硬散射喷注成分，以克服这些限制。

**Method:** 本文提出了一种名为 vipr 的新方法，利用基于扩散模型的变分推断进行 pp 相互作用的堆积去除。该方法训练一个生成模型来预测去除堆积后的硬散射粒子喷注成分，而不是使用分类方法来识别粒子来源。这种方法能够估计硬散射喷注成分的完整后验分布。

**Result:** vipr 在模拟的 $t\bar{t}$ 事件喷注样本（叠加堆积污染）中进行了性能评估。结果显示，vipr 在预测硬散射喷注子结构方面优于 softdrop，并且在各种堆积场景下与 puppiml 具有可比的性能。

**Conclusion:** vipr 方法能够估计硬散射喷注成分的完整后验分布，这在堆积去除领域是一个新颖的探索。与现有方法相比，vipr 具有明显的优势，尤其是在探测器效率不完美的情况下。

> **ai_Abstract:** 本文介绍了一种名为 vipr 的新颖堆积去除方法，该方法将变分推断与扩散模型相结合，应用于强子对撞机中的 pp 相互作用。与传统分类方法不同，vipr 训练一个生成模型来预测去除堆积后的硬散射粒子喷注成分，从而能够估计完整的后验分布。实验结果表明，在模拟的 $t\bar{t}$ 事件中，vipr 在堆积去除性能上优于 softdrop，并与 puppiml 相当，尤其在探测器效率不完美时显示出优势。

> **摘要翻译:** 在本文中，我们提出了一种使用基于扩散模型的变分推断进行 pp 相互作用堆积去除的新方法，称为 vipr。该方法不使用分类方法来识别哪些粒子来自初级碰撞，而是训练一个生成模型来预测去除堆积后的硬散射粒子喷注成分。这导致对硬散射喷注成分的完整后验分布进行估计，这在堆积去除的背景下尚未被探索，与现有方法相比具有明显优势，尤其是在探测器效率不完美的情况下。我们在模拟的 $t\bar{t}$ 事件喷注样本中评估了 vipr 的性能，该样本叠加了堆积污染。vipr 在预测硬散射喷注子结构方面优于 softdrop，并在各种堆积场景下与 puppiml 具有可比的性能。

</details>

[⬆️ 返回分类顶部](#hep-ph) | [⬆️ 返回总目录](#toc)

---

<a id='csdl'></a>
## cs.DL 

### [159] [New source, new possibilities: An exploratory study of Bluesky posts referencing scholarly articles](https://arxiv.org/abs/2507.18840)
> *新来源，新可能性：一项关于Bluesky上引用学术文章的探索性研究*

*Er-Te Zheng, Xiaorui Jiang, Zhichao Fang, Mike Thelwall* | **Category: cs.DL, cs.CY** | **Updated: 2025-07-24**

**Keywords:** Bluesky, 科学传播, 替代计量学, 社交媒体, 学术文章

**Comment:** 30 pages, 8 figures

> **TL;DR:** 随着学者从X平台迁移，本研究首次大规模分析了Bluesky上学术文章的传播情况，发现它是一个新兴的科学传播平台和替代计量学（altmetrics）的潜在来源，其帖子表现出更高的文本原创性，预示着更深入的学术互动。

**AI_Comments:** 本研究具有创新性，因为它首次对Bluesky作为科学传播平台进行了大规模分析。它揭示了Bluesky在替代计量学方面的潜力，并指出其独特的文本原创性可能促进比X平台更深入的学术互动。这项研究对于理解学术社交媒体格局的演变具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于学者从X平台迁移，Bluesky被提议作为潜在替代方案。本研究旨在评估其在科学传播方面的可行性和相关性，并探索其作为社交媒体指标新来源的潜力。

**Method:** 我们收集并分析了2024年2月至2025年4月期间87,470条引用了72,898篇学术文章的Bluesky帖子，并整合了来自OpenAlex数据库的元数据。我们检查了时间趋势、学科覆盖范围、语言使用、文本特征和用户参与度。

**Result:** 从2024年11月起，Bluesky上的学术活动急剧增加，这与学术界普遍从X平台转移的趋势相吻合。帖子主要集中在社会科学、环境科学和医学领域，并且主要以英文书写。与X平台类似，点赞和转发远多于回复和引用。然而，Bluesky帖子表现出比X平台更高的文本原创性，这表明了更强的解释性参与。

**Conclusion:** 这些发现突显了Bluesky作为科学传播的可信平台和替代计量学（altmetrics）有前景来源的新兴作用。该平台不仅可能促进研究成果的早期可见性，还可能在不断发展的社交媒体环境中促进更有意义的学术对话。

> **ai_Abstract:** 本研究首次大规模分析了社交媒体平台Bluesky上学术文章的传播情况，以评估其作为科学传播平台和替代计量学新来源的潜力。研究收集并分析了2024年2月至2025年4月期间近9万条引用学术文章的Bluesky帖子，发现其学术活动显著增长，主要集中在社会、环境和医学领域，且英文帖子为主。尽管点赞和转发仍是主要互动形式，但Bluesky帖子展现出更高的文本原创性，表明更深入的学术参与。研究结果表明，Bluesky正成为科学传播的可信平台和有前景的替代计量学来源，有望促进研究成果的早期可见性和更有意义的学术对话。

> **摘要翻译:** 随着学者从X平台迁移，社交媒体平台Bluesky被提议作为潜在替代方案。为了评估其在科学传播方面的可行性和相关性，本研究首次大规模分析了Bluesky上学术文章的传播情况，探索其作为社交媒体指标新来源的潜力。我们收集并分析了2024年2月至2025年4月期间87,470条引用了72,898篇学术文章的Bluesky帖子，并整合了来自OpenAlex数据库的元数据。我们检查了时间趋势、学科覆盖范围、语言使用、文本特征和用户参与度。从2024年11月起，Bluesky上的学术活动急剧增加，这与学术界普遍从X平台转移的趋势相吻合。帖子主要集中在社会科学、环境科学和医学领域，并且主要以英文书写。与X平台类似，点赞和转发远多于回复和引用。然而，Bluesky帖子表现出比X平台更高的文本原创性，这表明了更强的解释性参与。这些发现突显了Bluesky作为科学传播的可信平台和替代计量学（altmetrics）有前景来源的新兴作用。该平台不仅可能促进研究成果的早期可见性，还可能在不断发展的社交媒体环境中促进更有意义的学术对话。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

<a id='physicsmed-ph'></a>
## physics.med-ph 

### [165] [Design and fabrication of ultrasound linear array transducer used in ultrasound endoscope](https://arxiv.org/abs/2507.18628)
> *用于超声内窥镜的超声线性阵列换能器的设计与制造*

*Yuan Zhang, Mingtong Chen, Zhengbao Yang* | **Category: physics.med-ph, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 超声内窥镜, 线性阵列换能器, 超声成像平台, 微创应用, 压电复合材料

**Comment:** 

> **TL;DR:** 成功构建了超声成像平台并设计制造了用于微创内窥镜应用的超声线性阵列探头。

**AI_Comments:** 这篇论文展示了在超声内窥镜技术方面的一个重要进展，通过集成TI EVMs构建了功能强大的超声成像平台，并成功设计制造了小型化、高性能的线性阵列探头。其创新点在于将现成的评估模块与定制的微型探头相结合，为微创医疗诊断提供了潜在的工具。

<details>
  <summary>Details</summary>

**Motivation:** 建立一个功能性系统，用于获取和处理超声信号，特别是针对微创内窥镜应用。

**Method:** 基于德州仪器(TI)评估模块(EVMs)设计和开发了超声成像平台，该平台支持32通道高压信号传输和回波接收，并集成了TGC和CWD路径。同时，设计并制造了一个64单元、5MHz中心频率的相控阵线性超声内窥镜探头，并完成了其匹配层、背衬层、2-2压电复合材料和电极的制造和组装。

**Result:** 成功构建了超声成像平台，该平台能够传输和接收超声信号，并支持多种阵列探头成像。同时，设计并制造了一个微型化且性能优化的64单元、5MHz中心频率的相控阵线性超声内窥镜探头。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文详细介绍了用于微创内窥镜应用的超声成像平台和新型超声内窥镜探头的设计与制造。该平台基于TI EVMs，支持32通道信号处理和多种阵列探头成像。同时，成功设计并制造了一个小型化、高性能的64单元、5MHz相控阵线性超声内窥镜探头，并完成了其关键组件的组装。

> **摘要翻译:** 本报告详细介绍了超声成像平台的成功构建以及新型超声内窥镜探头的设计与制造。该项目的主要目标是建立一个功能性系统，用于获取和处理超声信号，专门针对微创内窥镜应用。超声成像平台主要基于德州仪器(TI)评估模块(EVMs)设计和开发。它能够传输32通道高压信号并接收回波信号，具有片上信号放大和采集功能。此外，该平台集成了完整的时变增益控制(TGC)成像路径和连续波多普勒(CWD)路径。结合主机计算机软件，它支持线性阵列、凸阵列和相控阵探头的成像。同时，设计了一个64单元、5MHz中心频率的相控阵线性超声内窥镜探头，旨在实现小型化和最佳成像性能。其匹配层、背衬层、2-2压电复合材料和电极的制造和组装已完成。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

### [242] [Time-resolved dynamic CBCT reconstruction using prior-model-free spatiotemporal Gaussian representation (PMF-STGR)](https://arxiv.org/abs/2503.22139)
> *使用无先验模型时空高斯表示（PMF-STGR）的时间分辨动态CBCT重建*

*Jiacheng Xie, Hua-Chieh Shao, You Zhang* | **Category: physics.med-ph, cs.LG, eess.IV** | **Updated: 2025-07-24**

**Keywords:** 动态CBCT, 高斯表示, 无先验模型, 运动补偿, 时间分辨

**Comment:** 25 pages, 5 figures

> **TL;DR:** PMF-STGR是一种新的动态CBCT重建方法，它利用3D高斯表示，无需先验模型，能更快、更准确地重建图像和运动。

**AI_Comments:** PMF-STGR的创新之处在于其采用无先验模型的3D高斯表示，实现了“一次性”训练，大大简化了动态CBCT重建流程，并避免了传统方法如相位排序或分箱的复杂性。其在效率和准确性上的显著提升，特别是重建时间减少50%和更好的运动精度，对于临床应用具有重要意义，有望加速动态CBCT在运动管理和放疗中的普及。该方法展现了强大的实用价值和临床转化潜力。

<details>
  <summary>Details</summary>

**Motivation:** 时间分辨CBCT成像对于表征规律和不规律运动、患者设置以及运动适应性放疗具有高度需求，但现有方法可能效率不高或需要复杂的先验模型。

**Method:** PMF-STGR框架基于3D高斯表示，包含三个主要组件：1) 一组密集的3D高斯用于重建动态序列的参考帧CBCT；2) 另一组3D高斯用于捕获三级、从粗到精的运动基底分量（MBCs）来建模扫描内运动；3) 基于CNN的运动编码器用于求解MBC的特定于投影的时间系数。通过这些时间系数，学习到的MBCs组合成形变矢量场，将参考CBCT变形为特定于投影的时间分辨CBCT，从而捕获动态运动。该方法支持“一次性”训练，无需任何先验解剖或运动模型。

**Result:** PMF-STGR在XCAT体模模拟和真实患者扫描中进行了评估。结果显示，PMF-STGR优于现有的基于INR的方法PMF-STINR。与PMF-STINR相比，PMF-STGR重建时间减少了50%，同时重建的图像模糊度更低，运动精度更高。评估指标包括图像相对误差、结构相似性指数测量、肿瘤质心误差和地标定位误差。

**Conclusion:** PMF-STGR通过提高效率和准确性，增强了动态CBCT成像在潜在临床转化中的适用性。

> **ai_Abstract:** 该论文提出了一种名为PMF-STGR的无先验模型时空高斯表示框架，用于时间分辨动态CBCT重建。该方法利用3D高斯表示来重建参考CBCT并建模扫描内运动，并通过CNN编码器求解时间系数。PMF-STGR无需先验模型，通过“一次性”训练即可实现。实验证明，PMF-STGR比现有方法PMF-STINR更快（重建时间减少50%）且更准确，能够生成更少模糊的图像和更高的运动精度，从而显著提升了动态CBCT在临床应用中的潜力。

> **摘要翻译:** 时间分辨CBCT成像，即重建反映扫描内运动的动态CBCT序列（每个X射线投影一个CBCT，无需相位排序或分箱），对于规律和不规律运动的表征、患者设置和运动适应性放射治疗具有高度需求。我们将患者解剖结构和相关运动场表示为3D高斯，开发了一种基于高斯表示的框架（PMF-STGR），用于快速准确的动态CBCT重建。PMF-STGR包含三个主要组件：一组密集的3D高斯，用于重建动态序列的参考帧CBCT；另一组3D高斯，用于捕获三级、从粗到精的运动基底分量（MBCs）以建模扫描内运动；以及一个基于CNN的运动编码器，用于求解MBC的特定于投影的时间系数。通过时间系数缩放，学习到的MBCs将组合成形变矢量场，将参考CBCT变形为特定于投影的时间分辨CBCT，以捕获动态运动。由于3D高斯的强大表示能力，PMF-STGR可以在“一次性”训练方式下从标准3D CBCT扫描重建动态CBCT，而无需使用任何先验解剖或运动模型。我们使用XCAT体模模拟和真实患者扫描评估了PMF-STGR。评估动态CBCT和运动准确性的指标包括图像相对误差、结构相似性指数测量、肿瘤质心误差和地标定位误差。PMF-STGR显示出优于最先进的基于INR的方法PMF-STINR的明显优势。与PMF-STINR相比，PMF-STGR重建时间减少了50%，同时重建的图像模糊度更低，运动精度更高。通过提高效率和准确性，PMF-STGR增强了动态CBCT成像在潜在临床转化中的适用性。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

### [477] [Diffusion-Assisted Frequency Attention Model for Whole-body Low-field MRI Reconstruction](https://arxiv.org/abs/2507.17764)
> *扩散辅助频率注意力模型用于全身低场MRI重建*

*Xin Xie, Yu Guan, Zhuoxu Cui, Dong Liang, Qiegen Liu* | **Category: physics.med-ph, cs.CV** | **Updated: 2025-07-09**

**Keywords:** 扩散模型, 频率注意力, 低场MRI, 图像重建, 低信噪比

**Comment:** 29 pages,7 figures

> **TL;DR:** DFAM结合扩散模型和频率注意力，显著提升低信噪比条件下低场MRI重建性能，优于现有方法，对资源受限环境有前景。

**AI_Comments:** DFAM的创新之处在于将扩散模型的强大生成能力与频率域注意力机制相结合，有效解决了低场MRI在低信噪比条件下的重建难题。其在资源受限环境中的应用潜力尤其重要，有望为欠发达地区提供更可及的MRI诊断。

<details>
  <summary>Details</summary>

**Motivation:** 在低信噪比条件下，低场MRI重建性能有待提高，尤其是在资源受限或欠发达的临床环境中，需要一种有效的解决方案。

**Method:** DFAM（扩散辅助频率注意力模型）通过整合扩散模型的生成能力和频域注意力的表示能力来实现。

**Result:** 实验结果表明，DFAM持续优于传统的重建算法和近期基于学习的方法。

**Conclusion:** DFAM作为一种有前景的解决方案，能够推动低场MRI重建的发展，特别适用于资源受限或欠发达的临床环境。

> **ai_Abstract:** 本研究提出了一种名为DFAM（扩散辅助频率注意力模型）的新方法，通过结合扩散模型的生成能力和频域注意力的表示能力，显著提升了低信噪比条件下的低场MRI重建性能。实验证明，DFAM在性能上超越了传统的重建算法和最新的学习型方法，预示着其在推动低场MRI重建，尤其是在资源受限的临床环境中，具有巨大潜力。

> **摘要翻译:** 通过将扩散模型的生成优势与频域注意力的表示能力相结合，DFAM在低信噪比条件下有效提升了重建性能。实验结果表明，DFAM持续优于传统的重建算法和近期基于学习的方法。这些发现突出了DFAM作为一种有前景的解决方案，能够推动低场MRI重建的发展，特别是在资源受限或欠发达的临床环境中。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cslo'></a>
## cs.LO 

### [215] [On Automating Proofs of Multiplier Adder Trees using the RTL Books](https://arxiv.org/abs/2507.19010)
> *关于使用RTL书籍自动化乘法器加法树证明的研究*

*Mayank Manjrekar* | **Category: cs.LO, cs.SC** | **Updated: 2025-07-25**

**Keywords:** 形式验证, ACL2, 乘法器, 硬件设计, 自动化证明

**Comment:** In Proceedings ACL2 2025, arXiv:2507.18567

> **TL;DR:** 提出一个名为ctv-cp的子句处理器，用于自动化Arm公司算术硬件设计的ACL2证明开发，特别针对整数乘法器模块。

**AI_Comments:** 这项工作通过引入一个自动化子句处理器ctv-cp，显著提高了Arm公司在算术硬件形式验证方面的效率，特别是在处理复杂的整数乘法器模块时。其创新点在于将新的处理器集成到现有验证框架中，自动化了通常耗时耗力的ACL2证明开发。

<details>
  <summary>Details</summary>

**Motivation:** 自动化Arm公司用于形式验证算术硬件设计的ACL2证明开发，特别是针对整数乘法器模块的证明。

**Method:** 提出了一个实验性的、经过验证的子句处理器ctv-cp，该处理器适用于Arm公司用于形式验证算术硬件设计的框架。

**Result:** 大大自动化了整数乘法器模块的ACL2证明开发工作，这些模块存在于从浮点除法到矩阵乘法等各种设计中。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了一个实验性且经过验证的子句处理器ctv-cp，该处理器被集成到Arm公司用于算术硬件形式验证的现有框架中。通过使用ctv-cp，可以大幅自动化针对整数乘法器模块的ACL2证明开发过程，这些模块广泛应用于从浮点除法到矩阵乘法等多种设计中。

> **摘要翻译:** 我们提出了一个实验性的、经过验证的子句处理器ctv-cp，它符合Arm公司用于算术硬件设计形式验证的框架。这在很大程度上自动化了整数乘法器模块的ACL2证明开发工作，这些模块存在于从浮点除法到矩阵乘法等各种设计中。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [389] [Proceedings 19th International Workshop on the ACL2 Theorem Prover and Its Applications](https://arxiv.org/abs/2507.18567)
> *第19届ACL2定理证明器及其应用国际研讨会论文集*

*Ruben Gamboa, Panagiotis Manolios* | **Category: cs.LO, cs.AI** | **Updated: 2025-07-24**

**Keywords:** ACL2, 定理证明器, 自动化推理, 研讨会, Boyer-Moore

**Comment:** 

> **TL;DR:** ACL2研讨会是ACL2定理证明系统用户展示相关研究的主要技术论坛。ACL2是一个工业级自动化推理系统，是Boyer-Moore定理证明器家族的最新成员。

**AI_Comments:** 这份文件是研讨会论文集，而非一篇具体的研究论文。它强调了ACL2定理证明系统作为工业级自动化推理工具的重要性及其在学术界的认可（荣获ACM软件系统奖）。创新性或局限性不适用于描述研讨会论文集本身。

<details>
  <summary>Details</summary>

**Motivation:** ACL2研讨会系列是ACL2定理证明系统用户展示与ACL2定理证明器及其应用相关研究的主要技术论坛。

**Method:** Not mentioned in abstract

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本篇论文集是第19届ACL2国际研讨会的成果，该研讨会是ACL2定理证明系统用户展示相关研究的主要技术论坛。ACL2是Boyer-Moore定理证明器家族中最新的工业级自动化推理系统，其开发者曾于2005年获得ACM软件系统奖。

> **摘要翻译:** ACL2研讨会系列是ACL2定理证明系统用户展示与ACL2定理证明器及其应用相关研究的主要技术论坛。ACL2是一个工业级自动化推理系统，是Boyer-Moore定理证明器家族的最新成员。Boyer、Kaufmann和Moore因其在ACL2和Boyer-Moore家族其他定理证明器方面的工作而荣获2005年ACM软件系统奖。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [465] [Learning Concepts Definable in First-Order Logic with Counting](https://arxiv.org/abs/1909.03820)
> *学习可在带计数的一阶逻辑中定义的概唸*

*Steffen van Bergerem* | **Category: cs.LO, cs.AI, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 一阶逻辑, 计数逻辑, 次线性时间学习, 关系结构, PAC学习

**Comment:** 

> **TL;DR:** 该研究将一阶逻辑分类器的次线性时间学习泛化到带计数的一阶逻辑 (FOCN)，并证明了结构度数限制对于实现次线性学习算法至关重要。

**AI_Comments:** 这篇论文通过将高效学习算法扩展到更具表达力的逻辑框架（FOCN，其包含计数能力），做出了重要贡献。这是将数值方面整合到逻辑学习中的关键一步。论文发现度数限制对于次线性时间学习至关重要，为逻辑概念学习的复杂性提供了重要的理论见解。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在将现有的一阶逻辑分类器次线性时间学习结果推广到更具表达力的逻辑，例如带计数的一阶逻辑 (FOCN)，从而将机器学习的数值方面纳入学习框架。此外，研究还旨在探究实现高效学习所需条件，特别是结构度数的限制。

**Method:** 本研究通过将现有的一阶逻辑分类器学习结果泛化到带计数的一阶逻辑 (FOCN) 来实现其目标。具体地，研究证明了在多对数度数结构类上 FOCN 中可定义的分类器可以被一致地在次线性时间内学习，并将此结果扩展到了不可知PAC学习，针对度数至多为 $(\log \log n)^c$ 的结构类。此外，研究还通过证明在无界度数结构上无法实现次线性时间学习，即使对于普通一阶逻辑中可定义的分类器，从而强调了度数限制的重要性。

**Result:** 研究证明了在多对数度数结构类上，带计数的一阶逻辑 (FOCN) 中可定义的分类器可以被一致地在次线性时间内学习。此外，该结果被扩展到了不可知可能近似正确 (PAC) 学习，适用于度数至多为 $(\log \log n)^c$ 的结构类。更重要的是，研究表明结构度数的限制对于获得次线性时间学习算法至关重要：对于无界度数的结构，即使是普通一阶逻辑中可定义的分类器，也无法在次线性时间内学习。

**Conclusion:** 本研究成功地将次线性时间学习扩展到带计数的一阶逻辑 (FOCN)，证明了在特定度数限制下其可行性。研究还强调了有界度数对于高效学习的关键作用，并指出了当不满足此条件时学习的根本局限性。

> **ai_Abstract:** 本研究在Grohe和Turán引入的逻辑框架下，探讨了关系背景结构上的布尔分类问题。在已知一阶逻辑分类器在多对数度数结构上可次线性时间学习的基础上，本研究将该结果推广到带计数的一阶逻辑 (FOCN)。我们证明了在多对数度数结构类上，FOCN中可定义的分类器可以被一致地在次线性时间内学习，并将其扩展到不可知PAC学习。此外，研究强调了度数限制对于获得次线性时间学习算法的重要性，指出对于无界度数结构，即使是普通一阶逻辑中可定义的分类器，也无法在次线性时间内学习。

> **摘要翻译:** 我们研究了Grohe和Turán（TOCS 2004）引入的逻辑框架中，关系背景结构上的布尔分类问题。已知（Grohe和Ritzert，LICS 2017）在多对数度数结构上可定义的一阶逻辑分类器可以在次线性时间内学习，其中结构的度数和运行时间以结构的大小衡量。我们将这些结果推广到带计数的一阶逻辑FOCN，该逻辑由Kuske和Schweikardt（LICS 2017）引入，作为一种概括各种其他计数逻辑的表达性逻辑。具体来说，我们证明了在多对数度数结构类上FOCN中可定义的分类器可以被一致地在次线性时间内学习。这可以看作是朝着将学习框架扩展到包含机器学习的数值方面迈出的第一步。我们将结果扩展到不可知可能近似正确（PAC）学习，适用于度数至多为 $(\log \log n)^c$ 的结构类，其中c为某个常数。此外，我们表明度数限制对于获得次线性时间学习算法至关重要。也就是说，我们证明，对于无界度数的结构，即使是普通一阶逻辑中可定义的分类器，也无法在次线性时间内学习。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [589] [Approximate SMT Counting Beyond Discrete Domains](https://arxiv.org/abs/2507.18612)
> *近似SMT计数超越离散域*

*Arijit Shaw, Kuldeep S. Meel* | **Category: cs.LO, cs.AI** | **Updated: 2025-07-24**

**Keywords:** SMT, 模型计数, 混合公式, 近似计数, pact

**Comment:** To be published in the proceedings of Design Automation Conference
  (DAC) 2025

> **TL;DR:** 本文介绍了pact，一种用于混合SMT公式的近似SMT模型计数器，它使用基于哈希的方法，并在基准测试中取得了显著的性能提升。

**AI_Comments:** 本文的创新之处在于将近似SMT模型计数扩展到混合公式，解决了现有方法仅限于离散变量的局限性。其提出的pact方法利用哈希技术和对数次求解器调用，在性能上取得了显著突破，极大地提升了处理复杂SMT计数问题的能力。理论保证的提供也增加了其可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有SMT模型计数方法（如位爆炸）仅限于离散变量，难以对混合SMT公式中投影到离散域的解进行计数。因此，需要扩展SMT功能以实现模型计数，特别是对于混合SMT公式。

**Method:** 本文提出了pact，一个用于混合SMT公式的SMT模型计数器。它利用基于哈希的近似模型计数来估计解，并提供理论保证。pact相对于投影变量进行对数次SMT求解器调用，并利用优化的哈希函数。

**Result:** pact在大量基准测试中比基线方法实现了显著的性能提升。在14,202个实例中，pact成功完成了603个实例，而基线方法只能完成13个实例。

**Conclusion:** pact有效地将近似SMT模型计数扩展到混合公式，显著提升了处理此类问题的能力。

> **ai_Abstract:** 本文介绍了一种名为pact的SMT模型计数器，旨在解决现有方法在混合SMT公式中对离散域解计数受限的问题。pact采用基于哈希的近似模型计数方法，并提供理论保证，通过对数次SMT求解器调用显著提升了性能。实验结果表明，pact在处理大量实例时远优于基线方法。

> **摘要翻译:** 可满足性模理论（SMT）求解器推动了自动化推理的发展，解决了离散和连续域中的复杂公式。命题模型计数方面的最新进展促使将SMT能力扩展到模型计数，特别是对于混合SMT公式。现有方法，如位爆炸，仅限于离散变量，这凸显了在混合公式中将解投影到离散域进行计数的挑战。
我们引入了pact，一个用于混合公式的SMT模型计数器，它使用基于哈希的近似模型计数来估计具有理论保证的解。pact相对于投影变量进行对数次SMT求解器调用，利用优化的哈希函数。pact在大量基准测试中比基线方法取得了显著的性能改进。特别是，在14,202个实例中，pact成功完成了603个实例，而基线方法只能完成13个实例。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [756] [muRelBench: MicroBenchmarks for Zonotope Domains](https://arxiv.org/abs/2404.16243)
> *muRelBench: 仿射域的微基准测试*

*Kenny Ballou, Elena Sherman* | **Category: cs.LO, cs.SE** | **Updated: 2025-07-23**

**Keywords:** 微基准测试, 抽象域, 数值抽象域, 弱关系, muRelBench

**Comment:** SRP accepted at SEET 2025

> **TL;DR:** muRelBench 是一个用于弱关系抽象域及其操作的微基准测试框架，旨在帮助研究人员快速评估和验证数值抽象域算法的性能改进和正确性。

**AI_Comments:** muRelBench 提供了一个创新性的工具，通过合成基准测试来评估抽象域算法，这对于数值抽象域的研究具有重要意义。它能够帮助研究人员在早期阶段快速验证算法的性能和正确性，从而降低了后续密集实验的成本和风险。其可扩展性和正确性检查机制是其主要亮点。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在提供一个可扩展的微基准测试框架，使研究人员能够实验性地评估数值抽象域的算法，如闭包、最小上界和遗忘操作，从而在进行更密集的实验之前，快速原型化和验证性能改进。此外，它还提供机制来检查合成基准测试中的正确性。

**Method:** 本文提出了一个名为 muRelBench 的框架，用于弱关系抽象域及其操作的合成基准测试。该框架支持对数值抽象域算法进行实验性评估，并提供检查基准测试正确性的机制。

**Result:** 该框架使研究人员能够实验性地评估数值抽象域的提议算法（如闭包、最小上界和遗忘），并能快速原型化和验证性能改进。此外，它还提供了检查合成基准测试中正确性属性的机制。

**Conclusion:** muRelBench 框架为弱关系抽象域的算法评估提供了一个有效的工具，帮助研究人员在数值抽象域的性能改进和正确性验证方面进行快速迭代和实验。

> **ai_Abstract:** muRelBench 是一个为弱关系抽象域及其操作设计的合成微基准测试框架。它旨在帮助研究人员实验性地评估数值抽象域的算法，如闭包、最小上界和遗忘，从而加速性能改进的原型验证。该框架还包含确保合成基准测试正确性的机制。

> **摘要翻译:** 我们提出了 \texttt{muRelBench}，一个用于弱关系抽象域及其操作的合成基准测试框架。这个可扩展的微基准测试框架使研究人员能够实验性地评估数值抽象域的提议算法，例如闭包、最小上界和遗忘，使他们能够在考虑更密集的实验之前，快速原型化和验证性能改进。此外，该框架提供了检查每个基准测试的正确性属性的机制，以确保合成基准测试的正确性。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

<a id='statap'></a>
## stat.AP 

### [224] [Active Learning For Repairable Hardware Systems With Partial Coverage](https://arxiv.org/abs/2503.16315)
> *可修复硬件系统局部覆盖下的主动学习*

*Michael Potter, Beyza Kalkanlı, Deniz Erdoğmuş, Michael Everett* | **Category: stat.AP, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 主动学习, 可修复硬件系统, 可靠性推断, 采集函数, 局部覆盖

**Comment:** Submitted to IEEE Access - Reliability Society

> **TL;DR:** 针对可修复硬件系统可靠性模型参数推断中主动学习（AL）应用不足的问题，本文提出了一种新的松弛混合整数半定规划（MISDP）AL采集函数，该函数在部分测试覆盖场景下，在6000种实验配置中表现优于现有方法。

**AI_Comments:** 该论文解决了硬件可靠性领域一个重要的实际问题，即在有限资源下如何有效推断可修复硬件系统的可靠性。其创新之处在于将主动学习方法应用于这一特定领域，并针对硬件系统固有的复杂性（如老化和部分测试）设计了专门的采集函数。实验设计严谨，通过大规模的模拟验证，增强了研究成果的可靠性和普适性，为未来在实际工程中的应用提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 从现场数据推断可修复硬件系统的可靠性特征具有挑战性，尤其是在预算固定和维护周期最少的情况下。现有的主动学习（AL）方法在机器学习任务中表现出潜力，但在可修复硬件系统的可靠性模型参数推断方面仍未得到充分探索。这需要专门的AL采集函数（AFs）来考虑硬件老化以及系统由多个子系统组成，且可能只进行部分测试的事实。

**Method:** 本文提出了一种松弛混合整数半定规划（MISDP）主动学习采集函数（AF），该函数结合了诊断覆盖率（DC）、费雪信息矩阵（FIMs）和诊断测试预算。此外，研究人员设计了基于经验的模拟实验，重点关注两种诊断测试场景：1）具有重叠子系统覆盖的硬件系统部分测试，以及2）一个诊断测试完全包含另一个子系统覆盖的部分测试。该方法与文献中最广泛使用的AL AF（熵）以及其他几种为可靠性模型参数推断量身定制的直观AL AFs进行了评估。

**Result:** 所提出的AF在6000种实验配置中，在绝对总预期事件误差（ATEER）和均方误差（MSE）曲线的曲线下面积（AUC）方面，平均表现优于其他替代AFs。通过Friedman假设检验，在0.05的alpha水平上计算得出统计显著性。

**Conclusion:** 本文提出的松弛混合整数半定规划（MISDP）主动学习采集函数（AF）在可修复硬件系统可靠性模型参数推断中表现出优越性，特别是在存在部分诊断覆盖的复杂测试场景下，有效解决了现有方法的局限性。

> **ai_Abstract:** 该研究旨在解决在预算和维护周期受限下，从现场数据推断可修复硬件系统可靠性特征的挑战。针对主动学习（AL）在此领域应用不足的问题，论文提出了一种新的松弛混合整数半定规划（MISDP）AL采集函数，该函数考虑了诊断覆盖率、费雪信息矩阵和测试预算，并能处理硬件老化及部分子系统测试的情况。通过对两种部分测试场景的模拟实验，结果表明，在6000种实验配置中，所提出的AF在可靠性参数推断的准确性方面（以ATEER和MSE的AUC衡量）显著优于现有的熵基和其他直观AL AFs。

> **摘要翻译:** 从现场数据推断可靠性特征的最佳诊断测试和硬件系统实例具有挑战性，尤其是在预算固定和维护周期最少的情况下。主动学习（AL）在有限数据和预算限制下的参数推断方面已在机器学习/深度学习任务中显示出前景。然而，对于可修复硬件系统，用于可靠性模型参数推断的AL仍未得到充分探索。它需要专门的AL采集函数（AFs），以考虑硬件老化以及硬件系统由多个子系统组成，在给定诊断测试中可能只进行部分测试的事实。为了解决这些挑战，我们提出了一种松弛混合整数半定规划（MISDP）AL AF，该函数结合了诊断覆盖率（DC）、费雪信息矩阵（FIMs）和诊断测试预算。此外，我们设计了基于经验的模拟实验，重点关注两种诊断测试场景：1）具有重叠子系统覆盖的硬件系统部分测试，以及2）一个诊断测试完全包含另一个子系统覆盖的部分测试。我们评估了我们提出的方法与文献中最广泛使用的AL AF（熵）以及其他几种为可靠性模型参数推断量身定制的直观AL AFs。我们提出的AF在6000种实验配置中，在绝对总预期事件误差（ATEER）和均方误差（MSE）曲线的曲线下面积（AUC）方面，平均表现最佳，并且通过Friedman假设检验在0.05的alpha水平上计算出统计显著性。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [263] [Learning Individual Reproductive Behavior from Aggregate Fertility Rates via Neural Posterior Estimation](https://arxiv.org/abs/2506.22607)
> *通过神经后验估计从汇总生育率中学习个体生殖行为*

*Daniel Ciganda, Ignacio Campón, Iñaki Permanyer, Jakob H Macke* | **Category: stat.AP, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 生育率, 神经后验估计, 个体行为, 微观模拟, 贝叶斯框架

**Comment:** 

> **TL;DR:** 该研究引入了一个贝叶斯框架，利用神经后验估计从汇总的年龄别生育率中学习个体层面的生殖行为参数，并能预测个体结果。

**AI_Comments:** 该论文的创新之处在于其无似然贝叶斯框架，能够从宏观汇总数据中推断微观个体行为，有效弥合了人口学研究中的微观-宏观鸿沟。其能够生成完整的合成生命史并显著减少数据需求，对人口学建模和预测具有重要意义。该方法在处理无法直接观测个体行为但有大量汇总数据的领域具有广泛应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 年龄别生育率（ASFRs）虽然提供了生殖变化的广泛记录，但其汇总性质掩盖了驱动生育趋势的个体层面行为机制。为了弥合这种微观-宏观差距，研究旨在从汇总数据中推断个体行为。

**Method:** 引入了一个无似然贝叶斯框架，该框架将一个人口学可解释的个体层面生殖过程模拟模型与序贯神经后验估计（SNPE）相结合。利用ASFRs来恢复核心行为参数。

**Result:** 该框架成功恢复了控制当代生育的核心行为参数，包括家庭规模偏好、生育时机和避孕失败。该框架的有效性在四个生育制度不同的国家队列中得到验证。模型仅基于汇总数据估计，成功预测了样本外个体层面的结果分布，包括首次性行为年龄、期望家庭规模和生育间隔。

**Conclusion:** 该框架能够生成完整的合成生命史，显著减少了构建微观模拟模型的数据需求，并实现了行为明确的人口预测。

> **ai_Abstract:** 本研究提出了一个创新的无似然贝叶斯框架，通过结合个体层面的生殖模拟模型和序贯神经后验估计（SNPE），从汇总的年龄别生育率（ASFRs）中学习个体生殖行为。该框架成功恢复了关键行为参数，并在多个国家得到验证，还能预测样本外的个体结果。这项工作降低了微观模拟模型的数据要求，并为行为明确的人口预测提供了可能。

> **摘要翻译:** 年龄别生育率（ASFRs）提供了最广泛的生殖变化记录，但其汇总性质掩盖了驱动生育趋势的个体层面行为机制。为了弥合这种微观-宏观差距，我们引入了一个无似然贝叶斯框架，该框架将一个人口学可解释的个体层面生殖过程模拟模型与序贯神经后验估计（SNPE）相结合。我们证明，该框架仅使用ASFRs就能成功恢复控制当代生育的核心行为参数，包括家庭规模偏好、生育时机和避孕失败。该框架的有效性在四个生育制度不同的国家的队列中得到了验证。最引人注目的是，该模型仅基于汇总数据进行估计，成功预测了样本外个体层面的结果分布，包括首次性行为年龄、期望家庭规模和生育间隔。因为我们的框架能够生成完整的合成生命史，它显著减少了构建微观模拟模型的数据需求，并实现了行为明确的人口预测。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [344] [A Simulated Reconstruction and Reidentification Attack on the 2010 U.S. Census: Full Technical Report](https://arxiv.org/abs/2312.11283)
> *针对2010年美国人口普查的模拟重建和再识别攻击：完整技术报告*

*John M. Abowd, Tamara Adams, Robert Ashmead, David Darais, Sourya Dey, Simson L. Garfinkel, Nathan Goldschlag, Daniel Kifer, Philip Leclerc, Ethan Lew, Scott Moore, Rolando A. Rodríguez, Ramy N. Tadros, Lars Vilhuber* | **Category: stat.AP, cs.CR, econ.EM** | **Updated: 2025-07-23**

**Keywords:** 重建攻击, 再识别, 人口普查, 隐私保护, 数据披露

**Comment:** Replaces "The 2010 Census Confidentiality Protections Failed, Here's
  How and Why'' with the published version, which has a new title. Harvard Data
  Science Review (2025)

> **TL;DR:** 本报告揭示了2010年美国人口普查的表格数据并非如预期般安全，通过重建攻击可高度精确地再识别个人信息，但2020年的新框架能有效防御此类攻击，同时现有替代方案存在不足。

**AI_Comments:** 这篇论文揭示了传统统计数据披露方法中一个关键但被忽视的漏洞，即聚合数据并非绝对安全。其创新之处在于通过实际重建攻击证明了2010年美国人口普查表格数据的脆弱性，并量化了潜在的隐私泄露风险。这对于统计机构重新评估其数据发布策略具有重要意义，并为2020年人口普查采用更先进的差分隐私等技术提供了强有力的支持依据。论文的发现强调了在数据共享和隐私保护之间寻求平衡的挑战性。

<details>
  <summary>Details</summary>

**Motivation:** 挑战统计机构关于表格数据比微数据泄露风险更低的假设，特别是针对2010年美国人口普查数据，证明聚合数据并非固有地比底层微数据更不易披露。

**Method:** 研究人员仅使用2010年美国人口普查发布的180个表格集中的34个，重建了五个人口统计变量（普查区、性别、年龄、种族和民族）的微观数据，并进行了再识别研究。

**Result:** 1. 在70%的普查区（9700万人）中，所有记录均被完美重建。2. 对于340万易受攻击者（种族和民族与普查区内多数人不同者），在完美重建的普查区内，种族和民族的实际普查回应推断准确率达到95%。3. 2020年美国人口普查更强大的披露限制框架能够防御基于重建的攻击。4. 2020年人口普查披露规避系统的现有替代方案要么无法保护机密性，要么会过度降低统计数据的实用性，无法满足重新划分选区的主要法定用途。

**Conclusion:** 2010年美国人口普查的表格数据并非固有地比其底层微数据更不易披露，存在严重的重建和再识别风险。2020年人口普查的披露限制框架已得到改进以应对此类攻击，而其他替代方案则存在实用性或隐私保护的权衡问题。

> **ai_Abstract:** 本技术报告揭示了2010年美国人口普查的表格数据并非如统计机构所假设的那样比微数据更不易披露。研究人员仅使用部分公开的表格数据，成功重建了70%普查区（9700万人）的微观数据，并能以95%的准确率再识别340万易受攻击者的敏感信息。论文进一步指出，2020年美国人口普查采用的更鲁棒的披露限制框架能够有效防御此类重建攻击，同时强调了现有替代方案在隐私保护和数据实用性之间的权衡问题。

> **摘要翻译:** 统计机构通常使用与保护公开微数据中个人记录不同的策略来保护表格数据的机密性。聚合被认为是使生成统计数据固有地比微数据更不易泄露。2010年美国人口普查对其表格和微数据出版物使用了不同的披露限制规则。我们表明，这些表格数据固有地比其底层微数据更不易泄露的假设是错误的。2010年人口普查发布了超过1500亿条统计数据，分为180个表格集，几乎所有都处于最详细的地理层面——单个普查区。仅使用34个已发布的表格集，我们重建了五个变量（普查区、性别、年龄、种族和民族）的微数据。仅使用已发布的数据，攻击者使用我们的方法可以验证，所有普查区中70%（9700万人）的所有记录都被完美重建。我们通过再识别研究证实，在完美重建准确性的普查区内，攻击者可以以95%的准确率正确推断340万易受攻击者（种族和民族与普查区内多数人不同的唯一个体）的实际普查种族和民族回应。接下来，我们表明2020年美国人口普查使用的更强大的披露限制框架能够防御基于重建的攻击。最后，我们表明2020年人口普查披露规避系统的现有替代方案要么无法保护机密性，要么会过度降低统计数据的实用性，无法满足主要法定用途：根据1965年投票权法案重新划分全国所有立法和投票区的边界。这是完整的技术报告。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [271] [Hierarchical Dimensionless Learning (Hi-π): A physics-data hybrid-driven approach for discovering dimensionless parameter combinations](https://arxiv.org/abs/2507.18332)
> *分层无量纲学习 (Hi-π): 一种物理-数据混合驱动的无量纲参数组合发现方法*

*Mingkun Xia, Haitao Lin, Weiwei Zhang* | **Category: physics.flu-dyn, cs.LG, physics.data-an** | **Updated: 2025-07-24**

**Keywords:** 无量纲学习, 量纲分析, 符号回归, 物理-数据混合, 流体力学

**Comment:** 

> **TL;DR:** Hi-π是一种结合物理和数据的混合方法，用于自动发现高维系统中关键的无量纲参数组合，解决了传统量纲分析的冗余问题。

**AI_Comments:** 这篇论文通过引入Hi-π方法，有效地解决了传统量纲分析在高维系统中的局限性，即冗余参数问题。其创新点在于结合了物理驱动的量纲分析和数据驱动的符号回归，实现了无量纲参数的自动发现和优化。该方法在多个流体力学经典案例中的成功应用，证明了其在揭示复杂物理系统内在规律方面的强大潜力，具有重要的理论和实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的量纲分析在应用于高维系统时会产生冗余的无量纲参数，这使得建立具有物理意义的描述变得困难。

**Method:** 本文引入了分层无量纲学习（Hi-π），这是一种物理-数据混合驱动的方法，它结合了量纲分析和符号回归，以自动发现关键的无量纲参数组合。

**Result:** 在瑞利-贝纳对流中，该方法准确提取了瑞利数和普朗特数，验证了其在多尺度数据上的统一表示优势。在圆形管道黏性流中，该方法自动发现了雷诺数和相对粗糙度这两个最佳无量纲参数，实现了精度和复杂性之间的平衡。在亚音速流动的可压缩性校正中，该方法有效地提取了经典的可压缩性校正公式，同时展示了其通过最佳参数变换发现分层结构表达式的能力。

**Conclusion:** Hi-π方法能够有效地从高维物理系统中自动发现关键的无量纲参数组合和分层结构表达式，解决了传统量纲分析的冗余问题，并提供了物理意义上的描述。

> **ai_Abstract:** 本文提出了分层无量纲学习（Hi-π），这是一种创新的物理-数据混合驱动方法，旨在解决传统量纲分析在高维系统中的冗余参数问题。Hi-π结合了量纲分析和符号回归，能够自动发现关键的无量纲参数组合。通过在瑞利-贝纳对流、圆形管道黏性流和亚音速流可压缩性校正等经典流体力学案例中的应用，Hi-π成功提取了具有物理意义的无量纲参数和分层表达式，展示了其在降低复杂性、揭示物理规律方面的有效性和优越性。

> **摘要翻译:** 量纲分析提供了一个普适的框架，用于降低物理复杂性并揭示内在规律。然而，其应用于高维系统时仍然会产生冗余的无量纲参数，这使得建立具有物理意义的描述变得具有挑战性。在此，我们引入了分层无量纲学习（Hi-π），这是一种物理-数据混合驱动的方法，它结合了量纲分析和符号回归，以自动发现关键的无量纲参数组合。我们将此方法应用于流体力学各个研究领域的经典示例。对于瑞利-贝纳对流，该方法准确地提取了两个内在的无量纲参数：瑞利数和普朗特数，验证了其在多尺度数据上的统一表示优势。对于圆形管道中的黏性流，该方法自动发现了两个最佳无量纲参数：雷诺数和相对粗糙度，实现了精度和复杂性之间的平衡。对于亚音速流中的可压缩性校正，该方法有效地提取了经典的可压缩性校正公式，同时展示了其通过最佳参数变换发现分层结构表达式的能力。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

### [810] [On zero-order consistency residue and background pressure for the conservative SPH fluid dynamics](https://arxiv.org/abs/2507.18210)
> *关于守恒型SPH流体动力学中的零阶一致性残余和背景压力*

*Feng Wang, Xiangyu Hu* | **Category: physics.flu-dyn, cs.CE, physics.comp-ph** | **Updated: 2025-07-24**

**Keywords:** SPH, 零阶一致性, 数值阻尼, 背景压力, 核梯度校正

**Comment:** 50 pages and 27 figures and 6 tables

> **TL;DR:** 本文深入分析了守恒型SPH方法中零阶一致性问题导致的数值阻尼现象，揭示了其与背景压力的关联，并通过理论分析和数值实验验证了现有修正方法的局限性，强调了在高背景压力场景下修正方案的必要性。

**AI_Comments:** 本文对SPH方法中一个长期存在的关键问题——零阶一致性残余及其导致的数值阻尼进行了深入而系统的分析。其创新之处在于明确揭示了残余与背景压力的关联，并指出现有修正方法的根本性局限。这对于SPH方法的精确性和稳定性具有重要意义，尤其是在高背景压力和复杂几何流动的模拟中，为未来更鲁棒的SPH模型开发提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 守恒型光滑粒子流体动力学（SPH）方法中的零阶一致性问题会导致流体在长通道中（无论是层流还是湍流）以及重力驱动的自由表面流中出现显著的数值阻尼和过度的数值耗散。本文旨在深入分析这种阻尼的原因，揭示其与零阶梯度一致性残余的共同根源，并探讨背景压力对其的不利影响。

**Method:** 本文首先对压力驱动通道流中的阻尼原因进行了彻底分析，并将其与重力驱动自由表面流中过度的数值耗散问题联系起来。通过理论分析和数值实验，聚焦于关键敏感因素进行研究。具体测试了重力驱动自由表面流中水深和输入动压对残余诱导的非物理能量耗散的影响，以及压力驱动通道流中通道长度、分辨率和出口压力对速度损失的影响。此外，引入了最先进的逆核梯度校正技术，并在两种典型流体中进行了测试。

**Result:** 研究发现，零阶一致性问题，即使通过粒子正则化方案（如输运速度公式）进行缓解，仍会显著阻尼长通道中的流动。零阶梯度一致性残余是两种典型流体场景中非物理数值阻尼的共同根源。背景压力对这两种场景下的残余有不利影响。最先进的逆核梯度校正技术被证明在减少残余效应方面是有效的，但其校正能力存在根本性限制。FDA喷嘴的测试也表明了残余在复杂几何形状中的影响。

**Conclusion:** 零阶梯度一致性残余是导致守恒型SPH方法中非物理数值阻尼的关键因素，且背景压力会加剧其不利影响。尽管逆核梯度校正技术能有效减少残余效应，但其修正能力存在根本限制。因此，在不可避免存在高背景压力的场景中，校正方案是必不可少的。

> **ai_Abstract:** 本文深入探讨了守恒型SPH方法中零阶一致性问题导致的数值阻尼和能量耗散。研究揭示了零阶梯度一致性残余是压力驱动通道流和重力驱动自由表面流中非物理阻尼的共同根源，并分析了背景压力对其的负面影响。通过理论分析和数值实验，论文评估了现有修正技术（如逆核梯度校正）的有效性及其局限性，强调了在高背景压力复杂几何场景中，开发更有效修正方案的必要性。

> **摘要翻译:** 作为保守型光滑粒子流体动力学（SPH）方法的主要挑战之一，零阶一致性问题，尽管被认为可以通过粒子正则化方案（如输运速度公式）来缓解，但在层流和湍流模拟中都会显著阻尼长通道中的流动。基于这一发现，本文不仅彻底分析了这种压力驱动通道流中的阻尼原因，而且将这个问题与重力驱动自由表面流中过度的数值耗散联系起来。揭示了两种典型流动场景中非物理数值阻尼的共同根源——零阶梯度一致性残余。揭示并讨论了背景压力对这两种场景中残余的不利影响。为了全面理解残余的行为并减轻其潜在的不利影响，我们进行了理论分析和数值实验，重点关注关键敏感因素。为了研究重力驱动自由表面流中残余引起的非物理能量耗散，测试了无粘性驻波情况下的水深和输入动压。为了研究压力驱动通道流中的速度损失，我们检查了通道长度、分辨率和出口压力的影响。将最先进的逆核梯度校正技术引入到两种典型流中，并证明其在减少残余效应方面是有效的，但我们发现其校正能力从根本上是有限的。最后，测试了FDA喷嘴这一工程基准，以证明残余在复杂几何形状中的影响，强调了在不可避免存在高背景压力的场景中校正方案的必要性。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='q-finpm'></a>
## q-fin.PM 

### [277] [HARLF: Hierarchical Reinforcement Learning and Lightweight LLM-Driven Sentiment Integration for Financial Portfolio Optimization](https://arxiv.org/abs/2507.18560)
> *HARLF：用于金融投资组合优化的分层强化学习与轻量级LLM驱动情感整合*

*Benjamin Coriat, Eric Benhamou* | **Category: q-fin.PM, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 金融投资组合优化, 分层强化学习, 大型语言模型, 情感分析, 深度强化学习

**Comment:** 

> **TL;DR:** 论文提出HARLF，一个结合分层强化学习和轻量级LLM情感分析的金融投资组合优化框架，在回测中表现优异。

**AI_Comments:** 这篇论文的创新点在于将分层强化学习与轻量级LLM驱动的情感分析相结合，用于金融投资组合优化，实现了跨模态数据的高效整合。其三层架构设计有助于提高决策的稳定性和可扩展性。实际的回测结果表明了该方法的有效性和超越基准的性能，对金融科技领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统市场指标可能不足以捕捉金融市场的复杂性，需要整合金融新闻中的情感信号以提高投资组合优化效果。

**Method:** 本文提出HARLF，一个三层架构的框架：底层RL代理处理混合数据，元代理聚合其决策，超级代理根据市场数据和情感分析合并决策。该框架将轻量级大型语言模型（LLM）与深度强化学习（DRL）相结合，以整合情感信号和传统市场指标。

**Result:** 在2000-2017年训练后，并在2018-2024年的数据上进行评估，该框架实现了26%的年化收益率和1.2的夏普比率，表现优于等权重和S&P 500基准。

**Conclusion:** 该分层强化学习框架结合LLM情感分析，能够有效优化金融投资组合，并在实际数据中表现出卓越的性能和稳定性。

> **ai_Abstract:** 本文介绍了一种名为HARLF的金融投资组合优化框架，该框架创新性地结合了分层深度强化学习和轻量级大型语言模型，用于整合市场指标和金融新闻情感信号。其三层架构通过不同层级的RL代理处理并聚合决策。在2018-2024年的回测中，HARLF实现了26%的年化收益率和1.2的夏普比率，显著优于基准，展示了其在金融市场中的有效性和稳定性。

> **摘要翻译:** 本文提出了一种新颖的投资组合优化分层框架，将轻量级大型语言模型（LLM）与深度强化学习（DRL）相结合，以整合金融新闻中的情感信号和传统市场指标。我们的三层架构采用基础RL代理处理混合数据，元代理聚合其决策，以及一个超级代理根据市场数据和情感分析合并决策。在2000-2017年训练后，并在2018-2024年的数据上进行评估，该框架实现了26%的年化收益率和1.2的夏普比率，优于等权重和S&P 500基准。主要贡献包括可扩展的跨模态整合、增强稳定性的分层RL结构以及开源可复现性。

</details>

[⬆️ 返回分类顶部](#q-finpm) | [⬆️ 返回总目录](#toc)

---

<a id='q-bioqm'></a>
## q-bio.QM 

### [289] [Comparison of Optimised Geometric Deep Learning Architectures, over Varying Toxicological Assay Data Environments](https://arxiv.org/abs/2507.17775)
> *优化几何深度学习架构在不同毒理学分析数据环境下的比较*

*Alexander D. Kalian, Lennart Otte, Jaewook Lee, Emilio Benfenati, Jean-Lou C. M. Dorne, Claire Potter, Olivia J. Osborne, Miao Guo, Christer Hogstrand* | **Category: q-bio.QM, cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 几何深度学习, 图神经网络, 毒理学分析, 化学信息学, 贝叶斯优化

**Comment:** 

> **TL;DR:** 本研究比较了不同图神经网络（GNN）架构在不同数据量毒理学分析数据集上的性能，发现GINs在数据丰富环境下表现更优，而GATs在数据稀疏环境下表现更优。

**AI_Comments:** 本研究通过对不同GNN架构在不同数据丰度毒理学数据集上的系统比较，填补了现有研究的空白。其创新之处在于明确指出了GINs适用于数据丰富环境，而GATs适用于数据稀疏环境，为化学信息学领域中选择合适的GNN模型提供了重要的实践指导。此外，对超参数空间和优化状态的分析也深入揭示了不同GNN算法的内在特性。

<details>
  <summary>Details</summary>

**Motivation:** 在人工智能驱动的化学信息学中，几何深度学习是一种新兴技术，但不同图神经网络（GNN）架构在该领域的独特影响尚未得到充分探索。

**Method:** 本研究将图卷积网络（GCNs）、图注意力网络（GATs）和图同构网络（GINs）应用于7个不同数据量和终点的毒理学分析数据集，进行分析激活的二分类。对分子图进行预处理，强制类平衡，并对所有数据集进行5折分层后，对每个GNN在每个分析数据集上进行了贝叶斯优化（共21次）。

**Result:** 优化后的GNNs的曲线下面积（AUC）得分范围为0.728-0.849。在7个数据量最丰富的毒理学分析中，GINs始终优于GCNs和GATs。然而，GATs在剩余2个数据最稀疏的分析中表现显著优于其他模型。对探索的高维超参数空间以及优化后的超参数状态的后续分析发现，GCNs和GATs彼此达到了更接近的优化状态，与GINs相比，这进一步表明了GINs作为GNN算法的独特性。

**Conclusion:** 研究结果表明，GINs是数据丰富环境下的更优架构，而GATs是数据稀疏环境下的更优架构。

> **ai_Abstract:** 本研究比较了三种图神经网络（GNNs），即GCNs、GATs和GINs，在7个不同数据量毒理学分析数据集上的性能，以进行二分类。通过贝叶斯优化，发现GINs在数据丰富的毒理学分析中表现最佳，而GATs在数据稀疏的分析中表现突出。研究结果揭示了不同GNN架构对数据环境的适应性差异，并指出GINs具有独特的算法特性。

> **摘要翻译:** 几何深度学习是人工智能（AI）驱动的化学信息学中一种新兴技术，然而，不同图神经网络（GNN）架构在该领域的独特影响尚未得到充分探索。本研究比较了图卷积网络（GCNs）、图注意力网络（GATs）和图同构网络（GINs）的性能，这些模型应用于7个不同数据量和终点的毒理学分析数据集，以执行分析激活的二分类。在对分子图进行预处理、强制类平衡以及对所有数据集进行5折分层之后，对每个GNN应用于每个分析数据集进行了贝叶斯优化（共进行了21次独特的贝叶斯优化）。优化后的GNNs在所有折叠中平均的曲线下面积（AUC）得分范围为0.728-0.849，自然地在特定分析和GNNs之间有所不同。在7个数据量最丰富的毒理学分析中，GINs被发现始终优于GCNs和GATs。然而，GATs在剩余2个数据最稀疏的分析中表现显著优于其他模型。这表明GINs是数据丰富环境下的更优架构，而GATs是数据稀疏环境下的更优架构。随后对探索的高维超参数空间以及优化后的超参数状态的分析发现，GCNs和GATs彼此达到了可测量的更接近的优化状态，与GINs相比，这进一步表明了GINs作为GNN算法的独特性。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

### [440] [CM-UNet: A Self-Supervised Learning-Based Model for Coronary Artery Segmentation in X-Ray Angiography](https://arxiv.org/abs/2507.17779)
> *CM-UNet：一种基于自监督学习的X射线血管造影冠状动脉分割模型*

*Camille Challier, Xiaowu Sun, Thabo Mahendiran, Ortal Senouf, Bernard De Bruyne, Denise Auberson, Olivier Müller, Stephane Fournier, Pascal Frossard, Emmanuel Abbé, Dorina Thanou* | **Category: q-bio.QM, cs.LG, I.2; I.4; I.5; J.3** | **Updated: 2025-07-22**

**Keywords:** 自监督学习, 冠状动脉分割, X射线血管造影, CM-UNet, 迁移学习

**Comment:** IEEE EMBC 2025, 7 pages, 6 figures

> **TL;DR:** CM-UNet利用自监督学习和迁移学习，仅用少量标注数据即可实现X射线血管造影中冠状动脉的准确分割，显著优于无预训练模型。

**AI_Comments:** 该研究的创新点在于首次将自监督学习应用于X射线血管造影的冠状动脉分割，并有效解决了标注数据稀缺的难题。其重要性体现在能够显著减少人工标注工作量，提高诊断效率和准确性，对临床实践具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 冠状动脉的准确分割在临床实践中仍是挑战，阻碍了冠心病的有效诊断和管理。缺乏大型标注数据集限制了自动化工具的开发。

**Method:** 提出CM-UNet模型，该模型利用未标注数据集进行自监督预训练，然后在有限的标注数据上进行迁移学习和微调。

**Result:** 仅用18张标注图像微调CM-UNet，Dice分数下降15.2%，而无预训练的基线模型下降46.5%。这表明自监督学习能提升分割性能并减少对大型数据集的依赖。

**Conclusion:** 自监督学习在改善X射线血管造影的冠状动脉分割方面至关重要，能提升诊断准确性，改进临床工作流程，减轻放射科医生工作量，并加速疾病检测。

> **ai_Abstract:** CM-UNet是一种基于自监督学习的模型，旨在解决X射线血管造影中冠状动脉分割对大量标注数据依赖的问题。该模型通过在未标注数据上进行自监督预训练，并在少量标注数据上进行迁移学习，显著提高了分割精度，同时大幅减少了对标注数据的需求，为临床诊断提供了更高效、准确的工具。

> **摘要翻译:** 冠状动脉的精确分割在临床实践中仍然是一个重大挑战，阻碍了有效诊断和管理冠状动脉疾病的能力。用于模型训练的大型标注数据集的缺乏加剧了这一问题，限制了可辅助放射科医生的自动化工具的开发。为了解决这个问题，我们引入了CM-UNet，它利用未标注数据集上的自监督预训练和有限标注数据上的迁移学习，从而能够在最大限度地减少大量手动标注需求的同时实现准确的疾病检测。仅用18张而不是500张标注图像对CM-UNet进行微调，Dice分数下降了15.2%，而未经预训练的基线模型下降了46.5%。这表明自监督学习可以提高分割性能并减少对大型数据集的依赖。这是首批强调自监督学习在改善X射线血管造影冠状动脉分割方面重要性的研究之一，对提高临床实践中的诊断准确性具有潜在影响。通过提高X射线血管造影图像的分割精度，所提出的方法旨在改善临床工作流程，减轻放射科医生的工作量，并加速疾病检测，最终有助于改善患者预后。源代码可在https://github.com/CamilleChallier/Contrastive-Masked-UNet 公开获取。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

### [802] [A PBN-RL-XAI Framework for Discovering a "Hit-and-Run" Therapeutic Strategy in Melanoma](https://arxiv.org/abs/2507.10136)
> *用于发现黑色素瘤中“一击即走”治疗策略的PBN-RL-XAI框架*

*Zhonglin Liu* | **Category: q-bio.QM, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 黑色素瘤, 免疫疗法耐药, 概率布尔网络, 强化学习, 一击即走策略

**Comment:** 9 pages, 5 figures. Submitted to the IEEE International Conference on
  Bioinformatics and Biomedicine (BIBM) 2025. Code is available at
  https://github.com/Liu-Zhonglin/pbn-melanoma-project

> **TL;DR:** 本研究开发了一个PBN-RL-XAI框架，用于发现黑色素瘤中克服抗PD-1免疫疗法耐药性的“一击即走”治疗策略，发现短期抑制LOXL2蛋白是有效的。

**AI_Comments:** 这项研究的创新之处在于结合了PBN、RL和XAI来解决复杂的生物系统中的治疗耐药问题。特别是“一击即走”的治疗策略概念非常新颖且具有临床潜力，它提出了一种通过短暂干预来重置生物网络，从而克服耐药性的可能性。该计算框架有望用于发现其他复杂疾病中的非显而易见的干预方案。

<details>
  <summary>Details</summary>

**Motivation:** 转移性黑色素瘤对PD-1抗体免疫疗法存在先天性耐药，且其潜在的分子网络机制尚不明确，这仍是一个主要的临床挑战。

**Method:** 研究首先利用患者肿瘤活检的转录组数据构建了一个动态概率布尔网络（PBN）模型，以阐明调控治疗反应的逻辑。随后，采用强化学习（RL）智能体系统性地发现最佳的多步骤治疗干预措施。最后，利用可解释人工智能（XAI）机制性地解释了智能体的控制策略。

**Result:** 分析揭示，精确计时的四步暂时性抑制赖氨酰氧化酶样2蛋白（LOXL2）是最有效的策略。可解释性分析表明，这种“一击即走”的干预足以消除驱动耐药性的分子特征，使网络无需持续干预即可自我纠正。

**Conclusion:** 本研究提出了一种新颖的、时间依赖的治疗假设，以克服免疫疗法耐药性，并提供了一个强大的计算框架，用于识别复杂生物系统中不明显的干预方案。

> **ai_Abstract:** 本研究针对转移性黑色素瘤对PD-1免疫疗法耐药的临床挑战，开发了一个集概率布尔网络（PBN）、强化学习（RL）和可解释人工智能（XAI）于一体的计算框架。该框架通过构建分子网络模型，并利用RL智能体探索治疗干预策略，最终结合XAI解释其决策。研究发现，精确地短期（四步）抑制LOXL2蛋白能有效消除耐药分子特征，实现“一击即走”的治疗效果，无需持续干预。这为克服免疫疗法耐药性提供了一种新颖的时间依赖性治疗假设和强大的计算工具。

> **摘要翻译:** 转移性黑色素瘤对PD-1抗体免疫疗法存在先天性耐药，且其潜在的分子网络机制尚不明确，这仍是一个主要的临床挑战。为了解决这个问题，我们利用患者肿瘤活检的转录组数据构建了一个动态概率布尔网络模型，以阐明调控治疗反应的逻辑。随后，我们采用强化学习智能体系统性地发现最佳的多步骤治疗干预措施，并利用可解释人工智能机制性地解释了智能体的控制策略。分析揭示，精确计时的四步暂时性抑制赖氨酰氧化酶样2蛋白（LOXL2）是最有效的策略。我们的可解释性分析表明，这种“一击即走”的干预足以消除驱动耐药性的分子特征，使网络无需持续干预即可自我纠正。本研究提出了一种新颖的、时间依赖的治疗假设，以克服免疫疗法耐药性，并提供了一个强大的计算框架，用于识别复杂生物系统中不明显的干预方案。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

<a id='q-fincp'></a>
## q-fin.CP 

### [308] [Alternative Loss Function in Evaluation of Transformer Models](https://arxiv.org/abs/2507.16548)
> *评估Transformer模型中的替代损失函数*

*Jakub Michańków, Paweł Sakowski, Robert Ślepaczuk* | **Category: q-fin.CP, cs.LG, q-fin.TR** | **Updated: 2025-07-24**

**Keywords:** 损失函数, Transformer, LSTM, 量化金融, MADL

**Comment:** 12 pages, fixed grammar, typos and minor error in tables

> **TL;DR:** 本研究通过在股票和加密货币资产上进行实证实验，发现使用平均绝对方向损失（MADL）函数时，Transformer模型在预测生成方面表现显著优于LSTM模型，尤其适用于量化金融中的算法投资策略。

**AI_Comments:** 该论文的创新之处在于将平均绝对方向损失（MADL）函数应用于Transformer模型，并在量化金融领域进行了实证验证。研究结果清晰地展示了Transformer模型在使用MADL时相比LSTM模型的优越性，这对于设计更有效的算法投资策略具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在机器学习模型，尤其是应用于量化金融问题时，选择一个合适的损失函数对于训练、验证、估计和超参数调整至关重要。

**Method:** 本研究通过对股票和加密货币资产进行实证实验，应用了平均绝对方向损失（MADL）函数，并比较了Transformer和LSTM模型在使用MADL函数时的结果。

**Result:** 实证结果表明，在几乎所有情况下，Transformer模型的结果都显著优于LSTM模型。

**Conclusion:** 在量化金融领域，对于优化预测生成模型而言，应用平均绝对方向损失（MADL）函数时，Transformer模型表现出比LSTM模型更优越的性能。

> **ai_Abstract:** 本研究探讨了在量化金融中评估机器学习模型时替代损失函数的重要性。通过在股票和加密货币资产上进行实证实验，论文应用了平均绝对方向损失（MADL）函数，并将其与Transformer和LSTM模型结合使用。研究结果表明，在使用MADL函数时，Transformer模型在预测生成方面表现出显著优于LSTM模型的性能，强调了在算法投资策略中选择合适损失函数和模型架构的关键作用。

> **摘要翻译:** 机器学习模型的适当设计和架构，尤其是在其应用于量化金融问题时，至关重要。这个过程中最重要的方面是为训练、验证、估计目的和超参数调优选择一个合适的损失函数。因此，在本研究中，通过对股票和加密货币资产的实证实验，我们应用了平均绝对方向损失（MADL）函数，该函数更适合优化用于算法投资策略的预测生成模型。MADL函数的结果在Transformer和LSTM模型之间进行了比较，我们发现几乎在所有情况下，Transformer模型的结果都显著优于LSTM模型。

</details>

[⬆️ 返回分类顶部](#q-fincp) | [⬆️ 返回总目录](#toc)

---

### [434] [Advancing Financial Engineering with Foundation Models: Progress, Applications, and Challenges](https://arxiv.org/abs/2507.18577)
> *利用基础模型推进金融工程：进展、应用与挑战*

*Liyuan Chen, Shuoling Liu, Jiangpeng Yan, Xiaoyu Wang, Henglin Liu, Chuang Li, Kecheng Jiao, Jixuan Ying, Yang Veronica Liu, Qiang Yang, Xiu Li* | **Category: q-fin.CP, cs.AI, cs.LG** | **Updated: 2025-07-07**

**Keywords:** 金融工程, 基础模型, 金融基础模型, 综述, 人工智能

**Comment:** Under Review

> **TL;DR:** 本综述全面概述了金融基础模型（FFMs）在金融工程中的进展、应用和挑战，并提出了其分类和未来研究方向。

**AI_Comments:** 这篇综述论文的重要性在于它系统地梳理了金融领域专用基础模型（FFMs）的现状，弥补了通用基础模型在金融领域应用时的局限性。其提出的三类FFM分类法（FinLFMs, FinTSFMs, FinVLFMs）具有创新性，为该领域的研究提供了清晰的框架。同时，论文不仅总结了进展，还明确指出了数据稀缺、算法可扩展性和基础设施等关键挑战，为未来的研究指明了方向，具有很强的实用指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管GPT-4和Gemini等通用基础模型在金融任务中表现出色，但金融应用的独特领域要求（如多模态推理、监管合规性、数据隐私）限制了它们。这些挑战促使了专门为金融设计的金融基础模型（FFMs）的出现。本综述旨在全面概述FFMs。

**Method:** 本综述全面概述了FFMs，并提出了一个涵盖三种关键模态的分类法：金融语言基础模型（FinLFMs）、金融时间序列基础模型（FinTSFMs）和金融视觉语言基础模型（FinVLFMs）。论文审查了它们的架构、训练方法、数据集和实际应用，并指出了关键挑战和未来研究机会。

**Result:** 提出了FFMs的三种关键模态分类法：金融语言基础模型（FinLFMs）、金融时间序列基础模型（FinTSFMs）和金融视觉语言基础模型（FinVLFMs）。识别了数据可用性、算法可扩展性和基础设施限制方面的关键挑战。

**Conclusion:** 本综述旨在作为理解FFMs的全面参考，并为未来创新提供实用路线图。

> **ai_Abstract:** 基础模型（FMs）正在推动金融工程发展，但通用FMs在金融领域面临独特挑战，催生了金融基础模型（FFMs）。本综述全面概述了FFMs，提出了涵盖金融语言、时间序列和视觉语言三种模态的分类法，并审查了其架构、训练、数据集和应用。文章还指出了数据可用性、算法可扩展性和基础设施等关键挑战，并展望了未来研究方向，旨在为理解FFMs和未来创新提供参考。

> **摘要翻译:** 基础模型（FMs）——具有强大泛化能力的大规模预训练模型——的出现为金融工程开辟了新领域。尽管GPT-4和Gemini等通用FMs在从财务报告摘要到情感感知预测等任务中表现出良好的性能，但许多金融应用仍受限于独特领域要求，如多模态推理、监管合规性和数据隐私。这些挑战促使了金融基础模型（FFMs）的出现——一类专门为金融设计的模型。本综述全面概述了FFMs，并提出了一个涵盖三种关键模态的分类法：金融语言基础模型（FinLFMs）、金融时间序列基础模型（FinTSFMs）和金融视觉语言基础模型（FinVLFMs）。我们回顾了它们的架构、训练方法、数据集和实际应用。此外，我们还指出了数据可用性、算法可扩展性和基础设施限制方面的关键挑战，并提供了对未来研究机会的见解。我们希望本综述既能作为理解FFMs的全面参考，也能作为未来创新的实用路线图。FFM相关出版物和资源的最新集合将维护在我们的网站https://github.com/FinFM/Awesome-FinFMs上。

</details>

[⬆️ 返回分类顶部](#q-fincp) | [⬆️ 返回总目录](#toc)

---

<a id='cscc'></a>
## cs.CC 

### [312] [Downward self-reducibility in the total function polynomial hierarchy](https://arxiv.org/abs/2507.19108)
> *全函数多项式层级中的向下自归约性*

*Karthik Gajulapalli, Surendra Ghentiyala, Zeyong Li, Sidhant Saraogi* | **Category: cs.CC, cs.DS** | **Updated: 2025-07-25**

**Keywords:** 向下自归约性, 全函数多项式层级, 复杂性类, 搜索问题, TFNP

**Comment:** 

> **TL;DR:** 本文研究了全函数多项式层级（TFPH）中向下自归约问题，并证明了即使对于更强大的归约，也存在类似TFNP中观察到的复杂性类坍缩现象。

**AI_Comments:** 本文在计算复杂性理论领域做出了重要贡献，将向下自归约性的研究从决策问题和TFNP扩展到更广阔的全函数多项式层级。其创新之处在于证明了即使在允许更强大归约的情况下，复杂性类坍缩现象依然存在，揭示了向下自归约性对计算复杂性类结构的深远影响。这项工作对于理解搜索问题的内在难度及其与各种复杂性类之间的关系具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究（Harsha, Mitropolsky和Rosen [ITCS, 2023]）开始研究搜索问题中的向下自归约性，并表明TFNP中向下自归约问题若有唯一解则在PLS或UEOPL中。本文旨在证明这是一种更普遍的现象，适用于全函数多项式层级中更难的搜索问题。

**Method:** 本文通过证明全函数多项式层级（TFΣiP）中的任何问题，如果允许访问Σi-1P预言机的随机向下自归约，则必须位于PLSΣi-1P中。如果问题具有本质上唯一的解，则它位于UEOPLΣi-1P中。

**Result:** 任何TFΣiP中的问题，若允许访问Σi-1P预言机的随机向下自归约，则在PLSΣi-1P中。若问题具有本质上唯一的解，则在UEOPLΣi-1P中。作为应用，Range Avoidance和Linear Ordering Principle问题被证明都在UEOPLNP中。

**Conclusion:** 本文证明了向下自归约性导致的复杂性类坍缩现象在全函数多项式层级中普遍存在，即使在允许更强大归约的情况下也成立，并为特定问题提供了新的复杂性上界。

> **ai_Abstract:** 本文研究了全函数多项式层级（TFPH）中的向下自归约问题，扩展了先前关于搜索问题中向下自归约性的研究。研究发现，即使在TFPH中更高级别的复杂性类，向下自归约性也会导致复杂性类坍缩。具体而言，TFΣiP中的问题若允许随机向下自归约并访问Σi-1P预言机，则分别位于PLSΣi-1P或UEOPLΣi-1P（对于本质上唯一解的问题）。这些发现为Range Avoidance和Linear Ordering Principle等问题提供了新的复杂性上界。

> **摘要翻译:** 一个问题P如果存在一个高效的算法，允许只对P的严格更小实例进行查询，则被认为是向下自归约的。向下自归约性在判定问题的情况下得到了很好的研究，并且众所周知，任何向下自归约问题都必须位于PSPACE中。Harsha、Mitropolsky和Rosen [ITCS, 2023] 开始研究搜索问题中的向下自归约。他们展示了以下有趣的坍缩现象：如果一个问题在TFNP中并且也是向下自归约的，那么它必须在PLS中。此外，如果问题承认唯一解，那么它必须在UEOPL中。
我们证明这仅仅是更普遍现象的冰山一角，这种现象甚至适用于全函数多项式层级（TFΣiP）中更难的搜索问题。事实上，即使我们允许我们的向下自归约更强大，这种坍缩仍然会发生。
我们证明任何在TFΣiP中的问题，如果允许访问Σi-1P预言机的随机向下自归约，则必须在PLSΣi-1P中。如果问题具有本质上唯一的解，那么它位于UEOPLΣi-1P中。
作为我们框架的一个（众多）应用，我们为Range Avoidance和Linear Ordering Principle问题获得了新的上界，并证明它们都在UEOPLNP中。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

### [499] [Certificate-Sensitive Subset Sum: Realizing Instance Complexity](https://arxiv.org/abs/2507.15511)
> *证书敏感子集和：实现实例复杂度*

*Jesus Salas* | **Category: cs.CC, cs.DS, F.1.3; F.2.2** | **Updated: 2025-07-25**

**Keywords:** 子集和, 证书敏感, 实例复杂性, NP完全问题, 算法

**Comment:** 14 pages + appendix. Companion to arXiv:2503.20162 ("Beyond
  Worst-Case Subset Sum: An Adaptive, Structure-Aware Solver with Sub-2^{n/2}
  Enumeration"

> **TL;DR:** 首次提出一种确定性的、证书敏感的子集和算法IC-SubsetSum，其运行时间与输入实例的复杂性（U）成比例，并在最坏情况下优于经典算法，为NP完全问题引入了新的范式。

**AI_Comments:** 这篇论文的创新点在于提出了第一个运行时能够自适应输入结构（通过实例复杂性证书U）的确定性NP完全问题算法。其在最坏情况下优于经典算法的表现，以及对现有细粒度归约的重新审视，都显示了其理论和实践的重要性，为理解和解决NP完全问题提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发一种确定性的、运行时能根据输入结构自适应的NP完全问题（子集和）算法，以克服现有经典方法在所有实例上表现不佳的局限性。

**Method:** 提出IC-SubsetSum算法，通过枚举所有不同的子集和（由U表示的信息论最小证明），在确定性时间$O(U \cdot n^2)$和空间$O(U \cdot n)$内解决子集和问题。还提出了一个随机变体，其预期运行时间为$O(U \cdot n)$。

**Result:** IC-SubsetSum算法的复杂性直接受证书大小U控制。其确定性版本在时间上为$O(U \cdot n^2)$，空间为$O(U \cdot n)$；随机版本预期运行时间为$O(U \cdot n)$。最坏情况下的运行时间保证为$O^*(2^{n/2 - \varepsilon})$，首次严格优于所有实例上的经典方法。研究还表明，依赖经典$2^{n/2}$难度的细粒度归约仅适用于U最大化的无碰撞实例。

**Conclusion:** IC-SubsetSum算法通过结构性地重新定义了子集和问题的难度障碍，并为NP完全问题引入了一种新的证书敏感算法范式。

> **ai_Abstract:** 这篇论文介绍了一种名为IC-SubsetSum的确定性、证书敏感算法，用于解决子集和问题。该算法的运行时间$O(U \cdot n^2)$和空间$O(U \cdot n)$（随机变体为$O(U \cdot n)$）直接取决于实例复杂性证书U的大小，U代表不同子集和的数量。IC-SubsetSum在最坏情况下能以$O^*(2^{n/2 - \varepsilon})$的运行时间严格优于所有实例上的经典方法，并为NP完全问题提供了一种新的结构敏感算法范式。

> **摘要翻译:** 我们提出了据我们所知第一个针对经典NP完全问题的确定性、证书敏感算法，其运行时被证明能适应每个输入的结构。对于一个子集和实例$(S, t)$，令$\Sigma(S)$表示不同子集和的集合，并定义$U = |\Sigma(S)|$。这个集合作为信息论上最小的证据，即实例复杂性（IC）证书。
我们的求解器IC-SubsetSum以确定性时间$O(U \cdot n^2)$和空间$O(U \cdot n)$枚举$\Sigma(S)$的每个元素。一个随机变体实现了预期运行时间$O(U \cdot n)$。因此，算法的复杂性直接由证书大小决定，并且这种结构敏感的性能与最坏情况下$O^*(2^{n/2 - \varepsilon})$（其中$\varepsilon > 0$为常数）的运行时间相结合，这是第一个在每个实例上都严格优于经典方法的结果。
我们重新审视了依赖于子集和经典$2^{n/2}$难度的细粒度归约，并表明这些论证仅适用于U最大化的无碰撞实例。IC-SubsetSum从结构上重新定义了这一障碍，并为NP完全问题引入了一种新的证书敏感算法范式。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

<a id='mathlo'></a>
## math.LO 

### [352] [Axiomatizing Rumsfeld Ignorance](https://arxiv.org/abs/2507.17776)
> *伦斯斐尔德无知的公理化*

*Jie Fan* | **Category: math.LO, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 伦斯斐尔德无知, 公理化, 无知, 可达关系, 双框架类

**Comment:** This is an almost-final version

> **TL;DR:** 解决了伦斯斐尔德无知与无知在逻辑上可定义性导致的问题，通过假设不同的可达关系，并提供了新的公理化。

**AI_Comments:** 本文的创新之处在于通过区分两种无知形式中隐含知识算子的可达关系，巧妙地解决了逻辑上的可定义性问题，从而使公理化工作更具非平凡性。这对于理解和形式化不同层次的无知概念具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** Kit Fine 的研究中，伦斯斐尔德无知可由无知定义，这使得一些现有结果和公理化问题变得微不足道，因为隐含知识算子的可达关系相同。

**Method:** 假设无知和伦斯斐尔德无知中包含的隐含知识算子的两个可达关系是不同的，其中一个可达关系是另一个的任意子集，从而避免了可定义性问题并保留了大部分现有有效性。

**Result:** 主要结果是对各种适当的双框架类进行了公理化。

**Conclusion:** 将提出的框架应用于分析 Fine 的结果。

> **ai_Abstract:** 本文旨在解决 Kit Fine 提出的伦斯斐尔德无知与普通无知之间存在的可定义性问题，该问题导致了公理化工作的简单化。作者通过假设两种无知形式中隐含知识算子的可达关系不同（其中一个为另一个的子集），成功避免了此问题并保留了原有有效性。主要贡献是为各种双框架类提供了新的公理化，并将其应用于分析 Fine 的原始发现。

> **摘要翻译:** 在最近的一篇论文中，Kit Fine 提出了关于（一阶）无知、二阶无知和伦斯斐尔德无知逻辑性质的一些显著结果。然而，伦斯斐尔德无知可以用无知来定义，这使得一些现有结果和公理化问题变得微不足道。一个主要原因是无知和伦斯斐尔德无知这些打包算子中包含的隐含知识算子的可达关系是相同的。在这项工作中，我们假设这两个可达关系是不同的，其中一个可达关系是另一个的任意子集。这将避免可定义性问题并保留大部分先前的有效性。主要结果是对各种适当的双框架类进行了公理化。最后，我们将我们的框架应用于分析 Fine 的结果。

</details>

[⬆️ 返回分类顶部](#mathlo) | [⬆️ 返回总目录](#toc)

---

<a id='mathco'></a>
## math.CO 

### [368] [Cycle-factors of regular graphs via entropy](https://arxiv.org/abs/2507.19417)
> *正则图的循环因子通过熵*

*Micha Christoph, Nemanja Draganić, António Girão, Eoin Hurley, Lukas Michel, Alp Müyesser* | **Category: math.CO, cs.DM, cs.DS, math.PR** | **Updated: 2025-07-25**

**Keywords:** 正则图, 循环因子, 熵, 随机算法, 图论

**Comment:** Conference version accepted to FOCS 2025. An expanded version with
  open problems will follow

> **TL;DR:** 本文将随机排列中循环数量的经典结果推广到有向d-正则图，证明其随机循环因子平均有$\\mathcal{O}((n\\log d)/d)$个循环，并提供了相关算法。

**AI_Comments:** 本文的创新之处在于将经典结果推广到更广泛的图类型，并利用熵理论这一强大的工具来解决图论中的组合问题。其结果不仅改进了理论界限，还提供了实际的算法，显示出理论与应用结合的价值。

<details>
  <summary>Details</summary>

**Motivation:** 推广随机排列中循环数量的经典结果到d-正则图；改进现有界限；解决Magnant和Martin的猜想以及Vishnoi等人研究的问题。

**Method:** 使用熵的语言；利用正则二分图中完美匹配数量的上下界非常接近这一事实。

**Result:** 证明了n个顶点的有向d-正则图的随机循环因子平均有$\\mathcal{O}((n\\log d)/d)$个循环。这个结果在常数因子上是紧密的，并改进了之前Vishnoi提出的$\\mathcal{O}(n/\\sqrt{\\log d})$的最佳界限。提供了随机多项式时间算法，用于找到这样的循环因子，并且如果图是连通的，还可以找到长度为$(1+\\mathcal{O}((\\log d)/d)) \\cdot n$的旅行。

**Conclusion:** 本文的结果在Magnant和Martin的一个猜想以及Vishnoi、Feige、Ravi和Singh研究的一个问题上取得了进展。

> **ai_Abstract:** 本文将随机排列中循环数量的经典结果推广到有向d-正则图，证明其随机循环因子平均有$\\mathcal{O}((n\\log d)/d)$个循环，显著改进了现有界限。研究还提出了用于查找此类循环因子和近似旅行的随机多项式时间算法，从而在相关猜想和问题上取得了进展。证明方法利用了熵理论和正则二分图中完美匹配的性质。

> **摘要翻译:** 随机排列的经典结果是，n个元素的随机排列平均有大约$\\log n$个循环。我们将这一事实推广到所有n个顶点的有向d-正则图，通过证明此类图的随机循环因子平均有$\\mathcal{O}((n\\log d)/d)$个循环。这个结果在常数因子上是紧密的，并且改进了之前Vishnoi提出的$\\mathcal{O}(n/\\sqrt{\\log d})$的最佳界限。我们的结果还产生了随机多项式时间算法，用于找到这样的循环因子，并且如果图是连通的，还可以找到长度为$(1+\\mathcal{O}((\\log d)/d)) \\cdot n$的旅行。这在Magnant和Martin的一个猜想以及Vishnoi、Feige、Ravi和Singh研究的一个问题上取得了进展。我们的证明使用熵的语言来利用正则二分图中完美匹配数量的上下界非常接近的事实。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

### [459] [Kernelization for list $H$-coloring for graphs with small vertex cover](https://arxiv.org/abs/2507.12005)
> *针对小顶点覆盖图的列表H着色问题的核化*

*Marta Piecyk, Astrid Pieterse, Paweł Rzążewski, Magnus Wahlström* | **Category: math.CO, cs.DS** | **Updated: 2025-07-25**

**Keywords:** 列表H着色, 核化, 顶点覆盖, 图不变量, 参数化复杂性

**Comment:** 

> **TL;DR:** 该论文引入了新的图不变量 $c^*(H)$ 和 $d^*(H)$，为列表H着色问题（以顶点覆盖数为参数）提供了紧致的核化界限，改进了现有结果。

**AI_Comments:** 该论文通过对列表H着色问题的核化界限进行精细分析，对参数化复杂性理论做出了重要贡献。引入新的图不变量 $c^*(H)$ 和 $d^*(H)$ 具有创新性，为问题复杂性提供了更精确的刻画。这些结果改进了现有界限，并揭示了图结构（通过H）与核化限制之间复杂的内在关系。关于 $d^*(H)$ 普遍紧致性的猜想为未来的研究开辟了道路。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究列表H着色问题（以图的顶点覆盖数为参数）的核化性质。它扩展了Jansen和Pieterse的先前工作，旨在为非完全图H找到更紧致、更通用的核化界限，从而更好地理解该问题的计算复杂性。

**Method:** 作者定义了两个新的整数图不变量 $c^*(H)$ 和 $d^*(H)$。他们利用这些不变量来推导列表H着色问题的核化上下界。此外，通过多项式方法证明了某些图类别上的紧致性，并利用多项式层级崩溃的假设来证明下界。

**Result:** 列表H着色问题具有一个 $\mathcal{O}(k^{c^*(H)})$ 顶点的核。除非多项式层级崩溃，否则对于任何 $\varepsilon > 0$，它不接受大小为 $\mathcal{O}(k^{d^*(H)-\varepsilon})$ 的核。如果 $c^*(H) > d^*(H)$，则存在一个 $\mathcal{O}(k^{c^*(H)-\varepsilon})$ 顶点的核，其中 $\varepsilon \geq 2^{1-c^*(H)}$。对于某些图类别，包括环的幂图和 $\Delta(H) \leq c^*(H)$ 的图，边界 $d^*(H)$ 是紧的。

**Conclusion:** 本文为列表H着色问题（以顶点覆盖数为参数）建立了接近紧致的核化界限。通过引入新的图不变量 $c^*(H)$ 和 $d^*(H)$，该研究改进了现有结果，并为问题复杂性提供了更精确的刻画。作者推测所提出的紧致性在一般情况下也成立。

> **ai_Abstract:** 本文研究了以顶点覆盖数 $k$ 为参数的列表H着色问题的核化性质。在现有工作的基础上，作者引入了两个新的图不变量 $c^*(H)$ 和 $d^*(H)$，为核大小建立了接近紧致的上下界。具体来说，他们证明了核的大小上限为 $\mathcal{O}(k^{c^*(H)})$ 个顶点，下限为 $\mathcal{O}(k^{d^*(H)-\varepsilon})$，并在 $c^*(H) > d^*(H)$ 时给出了更精确的上限。他们还证明了 $d^*(H)$ 对于特定图类的紧致性，并推测其普遍适用性。

> **摘要翻译:** 对于一个固定的图 $H$，在列表 $H$-着色问题中，给定一个图 $G$ 以及对于 $G$ 中每个顶点 $v$ 的列表 $L(v) \subseteq V(H)$，我们需要确定是否存在一个从 $(G,L)$ 到 $H$ 的列表同态 $\varphi$，即一个保持边的映射 $\varphi: V(G)\to V(H)$，且满足对于 $G$ 中每个顶点 $v$，都有 $\varphi(v)\in L(v)$。注意，如果 $H$ 是一个包含 $q$ 个顶点的完全图，则此问题等同于列表 $q$-着色。我们研究了列表 $H$-着色问题关于图 $G$ 的顶点覆盖数参数化的核化性质：给定一个实例 $(G,L)$ 和一个大小为 $k$ 的 $G$ 的顶点覆盖，我们能否将 $(G,L)$ 约化为一个等价的列表 $H$-着色实例 $(G',L')$，其中 $G'$ 的大小由 $k$ 的低次多项式 $p(k)$ 限制？这个问题之前由 Jansen 和 Pieterse [Algorithmica 2019] 研究过，他们提供了一个上限，对于列表 $q$-着色而言（即当 $H$ 是一个完全图时），该上限被证明是最优的。这个结果是核化通过有界度多项式方法的最早应用之一。我们定义了两个新的整数图不变量 $c^*(H)$ 和 $d^*(H)$，其中 $d^*(H) \leq c^*(H) \leq d^*(H)+1$，并证明对于每个图 $H$，列表 $H$-着色 -- 具有一个包含 $\mathcal{O}(k^{c^*(H)})$ 个顶点的核， -- 除非多项式层级崩溃，否则对于任何 $\varepsilon > 0$，不接受大小为 $\mathcal{O}(k^{d^*(H)-\varepsilon})$ 的核。 -- 此外，如果 $c^*(H) > d^*(H)$，则存在一个包含 $\mathcal{O}(k^{c^*(H)-\varepsilon})$ 个顶点的核，其中 $\varepsilon \geq 2^{1-c^*(H)}$。 此外，我们还表明，对于某些类别的图，包括环的幂图以及 $\Delta(H) \leq c^*(H)$ 的图（特别是包括团），使用多项式方法证明了 $d^*(H)$ 边界是紧的。我们推测这在一般情况下也成立。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [408] [An advanced AI driven database system](https://arxiv.org/abs/2507.17778)
> *一个先进的AI驱动的数据库系统*

*M. Tedeschi, S. Rizwan, C. Shringi, V. Devram Chandgir, S. Belich* | **Category: cs.DB, cs.AI, cs.SE, 68P20, H.2.4; I.2.7** | **Updated: 2025-07-22**

**Keywords:** AI数据库, 自然语言处理, 大型语言模型, 数据管理, 模式推理

**Comment:** 10 pages, 5 figures, appears in EDULEARN25 Conference Proceedings

> **TL;DR:** 本文提出一个AI驱动的数据库系统，通过自然语言处理和大型语言模型，简化数据管理，自动化任务，降低技术门槛和人为错误。

**AI_Comments:** 该论文的创新之处在于将AI、NLP和LLM深度集成到数据库系统中，以自动化数据管理任务（如模式和查询生成）并简化用户交互。其重要性在于解决了当前数据库系统在复杂性和可用性方面的痛点，特别是降低了非技术用户的门槛。然而，摘要中未提及具体的实现细节、性能评估或实际应用案例，这些可能是进一步研究或未来工作需要关注的方面。

<details>
  <summary>Details</summary>

**Motivation:** 当前的数据库系统存在复杂性和可用性问题，特别是对于缺乏技术专业知识或不熟悉查询语言（如SQL）的用户。

**Method:** 该系统是一个由AI支持的新型数据库系统，通过基于自然语言处理（NLP）的直观界面、自动创建结构化查询和半结构化数据格式（如YAML, JSON, API文档）来改进数据管理。它通过集成大型语言模型（LLMs）和先进机器学习算法来自动化数据建模、模式创建、查询理解和性能优化等基本任务。该AI数据库采用生成式模式推理和格式选择来构建其模式模型和执行格式。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出一个AI驱动的数据库系统，旨在解决当前数据库系统在复杂性和可用性方面的问题，特别是针对非技术用户。该系统利用自然语言处理（NLP）提供直观界面，并自动化结构化查询和半结构化数据格式的创建。通过集成大型语言模型（LLMs）和先进机器学习算法，该系统旨在自动化数据建模、模式创建和性能优化等核心任务，从而降低对技术技能的需求并减少人为错误，其核心在于生成式模式推理和格式选择。

> **摘要翻译:** 当代数据库系统虽然有效，但在复杂性和可用性方面存在严重问题，特别是对于缺乏技术专业知识但又不熟悉SQL等查询语言的个人。本文提出了一种由人工智能（AI）支持的新型数据库系统，旨在通过基于自然语言处理（NLP）的直观界面以及自动创建结构化查询和半结构化数据格式（如YAML、JSON和API文档）来改进数据管理。该系统旨在通过集成大型语言模型（LLMs）和先进的机器学习算法来增强数据库的潜力。这种集成旨在实现数据建模、模式创建、查询理解和性能优化等基本任务的自动化。本文提出的系统旨在缓解当前数据库技术的主要问题，旨在减少对技术技能、手动性能调优的需求以及人为错误的潜在可能性。该AI数据库采用生成式模式推理和格式选择来构建其模式模型和执行格式。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [699] [Big Data Energy Systems: A Survey of Practices and Associated Challenges](https://arxiv.org/abs/2507.19154)
> *大数据能源系统：实践与相关挑战综述*

*Lunodzo J. Mwinuka, Massimo Cafaro, Lucas Pereira, Hugo Morais* | **Category: cs.DB, cs.DC** | **Updated: 2025-07-25**

**Keywords:** 能源系统, 大数据管理, 综述, 数据空间, 区块链

**Comment:** 

> **TL;DR:** 该综述论文探讨了能源系统大数据管理的研究趋势，包括实践、机遇、挑战，并提供了对新兴技术的见解和实用建议，以应对传统和高级数据管理方案的瓶颈。

**AI_Comments:** 该论文作为一篇综述，系统梳理了能源系统大数据管理的现状、挑战与未来方向，特别关注了新兴技术的应用，对于该领域的研究人员和实践者具有较高的参考价值。其创新性在于对数据监管需求和多种新兴技术的整合分析，并提供实践性建议。

<details>
  <summary>Details</summary>

**Motivation:** 能源系统产生海量数据，传统及现有高级数据管理方法在可扩展性、可访问性、存储、检索和分析效率方面存在瓶颈，限制了其有效性，因此需要对大数据管理实践和挑战进行全面综述。

**Method:** 本研究是一篇综述论文，通过探索能源系统大数据管理的研究趋势，特别是考察现有存储和数据集成解决方案的局限性，并分析新兴技术在能源领域的应用。

**Result:** 论文探讨了能源系统大数据管理的研究趋势，强调了实践、机遇和挑战。它还利用选定的参考架构突出了数据监管要求，并深入探讨了数据空间、各种数据管理架构、点对点数据管理和区块链等新兴技术，并提供了实现增强数据共享和监管合规的实用建议。

**Conclusion:** 该综述论文深入探讨了当前能源系统数据存储和集成解决方案的局限性，并分析了新兴技术如何应用于该领域，为实现增强数据共享和监管合规提供了新见解和实用建议。

> **ai_Abstract:** 本综述论文旨在解决能源系统大数据管理面临的挑战。文章分析了传统及现有高级数据管理方案（如NoSQL和云平台）的局限性，并探讨了能源系统大数据管理的研究趋势、实践、机遇与挑战。论文还关注数据监管要求，并深入探讨了数据空间、点对点数据管理和区块链等新兴技术在能源领域的应用，最终为提升数据共享和监管合规性提供了实用建议。

> **摘要翻译:** 能源系统在极短的时间间隔内产生大量数据，给高效数据管理带来了挑战。传统数据管理方法常常难以应对可伸缩性和可访问性问题，限制了其有效性。为了解决这些问题，已经采用了更先进的解决方案，例如NoSQL数据库和基于云的平台。然而，即使这些先进的解决方案也可能遇到瓶颈，这会影响数据存储、检索和分析的效率。本综述论文探讨了能源系统大数据管理的研究趋势，重点介绍了实践、机遇和挑战。此外，还使用选定的参考架构突出了数据监管要求。本综述特别探讨了当前存储和数据集成解决方案的局限性，并考察了新技术如何应用于能源领域。论文提供了关于新兴技术的新颖见解，包括数据空间、各种数据管理架构、点对点数据管理和区块链，同时提供了实现增强数据共享和监管合规的实用建议。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

<a id='mathap'></a>
## math.AP 

### [453] [Reconstruction in the Calderón problem on a fixed partition from finite and partial boundary data](https://arxiv.org/abs/2507.19410)
> *基于有限和部分边界数据在固定分区上Calderón问题的重建*

*Henrik Garde* | **Category: math.AP, cs.NA, math.NA, 35R30, 35Q60, 35R05, 47H05,** | **Updated: 2025-07-25**

**Keywords:** Calderón问题, 电阻抗断层扫描, 电导率重建, 分段常数, 有限边界数据

**Comment:** 4 pages, 1 figure

> **TL;DR:** 本文修改了作者之前的一种重建方法，用于在已知分区和有限/部分边界数据情况下，重建Calderón问题中的分段常数电导率，且无需电导率的上下界。

**AI_Comments:** 该论文的创新之处在于通过修改现有方法，显著放宽了Calderón问题中电导率重建的假设条件。特别是，在分区已知的前提下，移除了对分层假设、局部Neumann-to-Dirichlet映射以及电导率上下界的需求，这使得该方法在实际应用中更具鲁棒性和普适性。它在数据有限和部分的情况下仍能有效工作，对电阻抗断层扫描等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 作者之前的重建方法（Comm. PDE, 45(9):1118--1133, 2020）需要分层假设和局部Neumann-to-Dirichlet映射，因为分段常数分区也被假定为未知。本文的动机是修改该方法，使其在分区已知的情况下，仅需有限和部分边界测量，并适用于一般的分段常数电导率，且无需对未知电导率的上下界进行假设。

**Method:** 本文修改了作者之前的一种重建方法。具体地，当分段常数分区已知时，该方法被调整以处理一般的分段常数电导率，并仅使用有限数量的部分边界测量。此外，新方法不再需要对未知电导率的下限/上限进行假设。

**Result:** 修改后的方法在分区已知的情况下，能够重建一般的分段常数电导率，且仅需有限数量的部分边界测量。与之前的方法相比，不再需要分层假设、局部Neumann-to-Dirichlet映射，也无需对未知电导率施加下限/上限。

**Conclusion:** 本文成功地修改了Calderón问题中的电导率重建方法，使其在分区已知时，能够更广泛地应用于分段常数电导率的重建，并显著减少了对数据和电导率性质的假设要求。

> **ai_Abstract:** 本文基于作者之前的Calderón问题（电阻抗断层扫描）中分段常数电导率重建方法进行了改进。当分段常数分区已知时，原方法所需的层状假设和局部Neumann-to-Dirichlet映射被移除。新方法仅需有限和部分边界数据即可重建一般的分段常数电导率，且无需对未知电导率设置上下界，从而简化了重建过程并拓宽了适用性。

> **摘要翻译:** 这篇短文修改了作者之前的一种重建方法（Comm. PDE, 45(9):1118--1133, 2020），用于重建Calderón问题（电阻抗断层扫描）中的分段常数电导率。在之前那篇论文中，由于分段常数分区也被假定为未知，因此需要分层假设和局部Neumann-to-Dirichlet映射。本文展示了在分区已知的情况下如何修改该方法，以适用于一般的分段常数电导率，并且仅需要有限数量的部分边界测量。此外，无需未知电导率的下限/上限。

</details>

[⬆️ 返回分类顶部](#mathap) | [⬆️ 返回总目录](#toc)

---

<a id='csdm'></a>
## cs.DM 

### [456] [In Reverie Together: Ten Years of Mathematical Discovery with a Machine Collaborator](https://arxiv.org/abs/2507.17780)
> *共同沉思：与机器合作者进行数学发现的十年*

*Randy Davila, Boris Brimkov, Ryan Pepper* | **Category: cs.DM, cs.AI, math.CO** | **Updated: 2025-07-23**

**Keywords:** 图论, 开放猜想, 机器协作, 数学发现, TxGraffiti

**Comment:** 

> **TL;DR:** 本文介绍了由自动猜想系统TxGraffiti生成的四个图论开放猜想，它们简洁、基于自然图不变量，并通过数百个图进行了经验验证。这些猜想至今未被解决，作者旨在通过它们激发人类数学家和AI系统参与其中，并反思机器在数学创造过程中的作用。

**AI_Comments:** 这篇论文的创新之处在于展示了AI系统（TxGraffiti）在数学发现，特别是生成开放性猜想方面的能力，这超越了传统上AI在解决已知问题上的应用。其重要性在于强调了人机协作在科学研究中的潜力，并提出了关于机器在创造性思维中角色的深刻哲学问题。它挑战了我们对“发现”和“创造”的传统认知，为未来AI辅助的科学研究开辟了新的视角。论文通过具体的、未解决的数学问题来例证其观点，增加了其说服力。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是展示机器在数学发现中的创造性贡献，通过提出由自动化猜想系统TxGraffiti生成的四个未解决的图论猜想，激发人类数学家和AI系统对这些问题的参与，并促使人们反思机器在数学思想创造过程中有意义的参与。

**Method:** 本文的方法是展示由自动化猜想系统TxGraffiti生成的四个图论开放猜想。这些猜想是基于符号模式识别和数学家定义的启发式方法，并通过多年的人机对话进行完善。它们通过经验验证了数百个图。

**Result:** 本文的结果是提出了四个由TxGraffiti系统生成的开放图论猜想。这些猜想简洁、基于自然图不变量，并已通过数百个图进行经验验证，但至今仍未被证明或找到反例。它们被视为数学挑战和创造性表达。

**Conclusion:** 本文的结论是，机器不仅可以生成具有挑战性的数学猜想，还可以通过其参与启发人类的思考和好奇心，并为数学发现提供原始材料。这促使人们反思机器在数学创造性思维过程中有意义的参与。

> **ai_Abstract:** 本文介绍了自动化猜想系统TxGraffiti在图论领域生成的四个开放性猜想。这些猜想简洁、基于图不变量，并已通过大量图进行经验验证，但至今仍未被解决。作者旨在通过这些“人机协作产物”，激发数学界对这些问题的兴趣，并引发对机器在数学发现和创造过程中所扮演角色的深入思考。

> **摘要翻译:** 我们提出了由自动化猜想系统\texttt{TxGraffiti}生成的四个图论开放猜想。每个猜想都简洁、基于自然图不变量，并通过数百个图进行了经验验证。尽管付出了大量的努力，这些陈述仍然悬而未决——既无法证明也找不到反例。它们不仅是数学挑战，也是创造性的表达——它们诞生于符号模式识别和数学家定义的启发式方法，通过多年的人机对话得以完善，现在作为协作成果回馈给社区。这些猜想不仅邀请形式证明，也邀请人们反思机器如何唤起惊奇、激发好奇心，并为发现提供原始材料。通过突出这些问题，我们旨在激励人类数学家和AI系统参与其中——不仅是为了解决它们，更是为了反思当机器有意义地参与数学思想的创造性过程时，这意味着什么。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

<a id='econgn'></a>
## econ.GN 

### [487] [From Individual Learning to Market Equilibrium: Correcting Structural and Parametric Biases in RL Simulations of Economic Models](https://arxiv.org/abs/2507.18229)
> *从个体学习到市场均衡：纠正经济模型强化学习模拟中的结构性和参数性偏差*

*Zeqiang Zhang, Ruxin Chen* | **Category: econ.GN, cs.AI, q-fin.EC** | **Updated: 2025-07-24**

**Keywords:** 强化学习, 经济模型, 市场均衡, 平均场强化学习, 结构性偏差

**Comment:** 

> **TL;DR:** 本文提出一种校准的平均场强化学习框架，以纠正RL在经济模型中模拟学习代理时出现的结构性和参数性偏差，使其行为与竞争均衡对齐。

**AI_Comments:** 这篇论文的创新点在于它识别并解决了强化学习在经济建模中应用时存在的深层理论和实践问题。通过引入“校准的平均场强化学习”框架，它巧妙地弥合了微观学习行为与宏观经济均衡之间的鸿沟，使得RL能够更准确地模拟经济代理人的行为，而非导致非预期的操纵性策略。这对于计算经济学和社会科学领域具有重要意义，因为它提供了一个更可靠的工具来分析复杂经济系统中的动态学习过程。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习应用于经济建模时，存在基本冲突：RL代理倾向于操纵环境而非作为市场价格接受者（结构性偏差），以及经济贴现与RL处理跨期成本之间的不匹配（参数性偏差）。传统RL模拟导致非均衡、买方垄断策略。

**Method:** 提出一个校准的平均场强化学习（Mean-Field Reinforcement Learning）框架。该框架将一个代表性代理嵌入固定的宏观经济场中，并调整成本函数以反映经济机会成本。采用迭代算法使其收敛到一个自洽的不动点。

**Result:** 所提出的迭代算法收敛到一个自洽的不动点，其中代理的策略与竞争均衡对齐。

**Conclusion:** 该方法为计算社会科学领域中经济系统学习代理的建模提供了一种可操作且理论上合理的方法。

> **ai_Abstract:** 本文探讨了将强化学习应用于经济模型时出现的结构性（RL代理成为操纵者而非接受者）和参数性（贴现不匹配）偏差。通过在一个搜索匹配模型中展示这些问题，研究者提出了一种校准的平均场强化学习框架。该框架通过将代理嵌入固定宏观经济场并调整成本函数，使迭代算法收敛到代理策略与竞争均衡对齐的不动点，从而提供了一种稳健的经济系统学习代理建模方法。

> **摘要翻译:** 强化学习（RL）在经济建模中的应用揭示了均衡理论假设与学习代理涌现行为之间存在根本性冲突。虽然经典的经济模型假设原子化代理作为总市场条件的“接受者”行事，但朴素的单代理RL模拟却激励代理成为其环境的“操纵者”。本文首先在一个凹生产的搜索匹配模型中展示了这种差异，表明标准RL代理学习到的是非均衡的、买方垄断的策略。此外，我们还识别出一种由经济贴现与RL对跨期成本处理不匹配所引起的参数性偏差。为了解决这两个问题，我们提出了一种校准的平均场强化学习框架，该框架将一个代表性代理嵌入固定的宏观经济场中，并调整成本函数以反映经济机会成本。我们的迭代算法收敛到一个自洽的不动点，其中代理的策略与竞争均衡对齐。这种方法为计算社会科学更广阔领域内的经济系统中的学习代理建模提供了一种可操作且理论上合理的方法。

</details>

[⬆️ 返回分类顶部](#econgn) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phhe'></a>
## astro-ph.HE 

### [518] [On the Energy Distribution of the Galactic Center Excess' Sources](https://arxiv.org/abs/2507.17804)
> *银河系中心过量辐射源的能量分布研究*

*Florian List, Yujin Park, Nicholas L. Rodd, Eve Schoen, Florian Wolf* | **Category: astro-ph.HE, astro-ph.CO, astro-ph.IM, cs.LG, hep-ph** | **Updated: 2025-07-23**

**Keywords:** 银河系中心过量辐射, 点源, 神经网络, 光谱信息, 暗物质

**Comment:** 7+20 pages, 2+20 figures, comments welcome

> **TL;DR:** 研究表明，银河系中心过量辐射（GCE）的来源如果是由点源组成，则需要远超预期的海量暗淡点源，或者它本质上是弥散的，这与暗物质预测一致。

**AI_Comments:** 这篇论文的创新之处在于首次将光谱信息引入到银河系中心过量辐射（GCE）的点源分析中，克服了以往研究仅限于空间分析的局限性。通过引入能量信息，研究揭示了GCE如果由点源组成，则其数量将远超预期，且单个源非常暗淡，这为GCE的起源（无论是弥散性还是暗物质）提供了更强的证据。其重要性在于为理解GCE的性质提供了更精细的约束，并可能有助于区分暗物质信号与天体物理背景。

<details>
  <summary>Details</summary>

**Motivation:** 银河系中心过量辐射（GCE）的性质是一个未解之谜，之前的分析仅限于空间结构，忽略了光谱信息，无法区分GCE是暗物质湮灭还是暗淡点源。本研究旨在克服这些技术限制，利用光谱信息进一步探究GCE的来源。

**Method:** 采用了一种神经网络辅助的基于模拟的推理方法，结合了空间和光谱数据来分析GCE的点源解释。

**Result:** 结合能量信息后，推定的点源变得显著更暗。如果GCE是由点源引起，预测银河系中心有大约10^5个源，或90%置信度下超过35,000个源，这远高于早期分析的数百个源。在最佳拟合背景模型下，该过量辐射本质上与暗物质预测的泊松发射一致。

**Conclusion:** GCE的性质要么是真正的弥散性，要么由数量异常庞大的暗淡点源组成，这与暗物质的预测相符。

> **ai_Abstract:** 本研究利用神经网络辅助的模拟推理方法，首次将空间和光谱数据结合起来分析银河系中心过量辐射（GCE）。结果显示，如果GCE由点源组成，则需要数量庞大且非常暗淡的源（远超先前估计的数万个），或者GCE本质上是弥散的，这与暗物质的预测一致。这挑战了GCE由少量亮源组成的传统观点，并为理解其起源提供了新的视角。

> **摘要翻译:** 银河系中心过量辐射（GCE）仍然是费米伽马射线空间望远镜发现的标志性谜团之一。尽管它可能预示着湮灭暗物质的发现，但与这一结论相悖的是，有分析表明其辐射的空间结构似乎与一组暗淡点源更一致。技术限制使得先前的分析纯粹在空间上研究点源假设。所有可能有助于将GCE与复杂且不确定的天体物理辐射区分开来的光谱信息都被丢弃了。我们证明，一种神经网络辅助的基于模拟的推理方法可以克服这些限制，从而利用空间和光谱数据来验证GCE的点源解释。这种增补是深刻的：能量信息使得推定的点源显著变暗，这表明GCE本质上是真正的弥散性，或者由数量异常庞大的源组成。定量地，对于我们最佳拟合的背景模型，该过量辐射本质上与暗物质预测的泊松发射一致。如果该过量辐射是由点源引起，我们的中位数预测是在银河系中心有大约10^5个源，或者在90%置信度下超过35,000个源，这两者都显著大于早期GCE点源分析所倾向的数百个源。

</details>

[⬆️ 返回分类顶部](#astro-phhe) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matstr-el'></a>
## cond-mat.str-el 

### [549] [Deep Variational Free Energy Calculation of Hydrogen Hugoniot](https://arxiv.org/abs/2507.18540)
> *氢Hugoniot的深度变分自由能计算*

*Zihang Li, Hao Xie, Xinyang Dong, Lei Wang* | **Category: cond-mat.str-el, cs.LG, physics.comp-ph** | **Updated: 2025-07-24**

**Keywords:** 深度变分自由能, 氢Hugoniot, 状态方程, 温稠密物质, 深度生成模型

**Comment:** 7+17 pages, 5+14 figures, for source code and raw data, see
  https://github.com/fermiflow/Hugoniot

> **TL;DR:** 本文开发了一种深度变分自由能框架，用于计算温稠密区域氢的状态方程，并旨在解决氘Hugoniot曲线上现有理论与实验的差异。

**AI_Comments:** 本文创新性地将深度生成模型引入到复杂物理系统（如温稠密物质）的自由能计算中，通过结合多种神经网络结构来处理核和电子的复杂相互作用，为高精度计算材料状态方程提供了新途径。其重要性在于能够为极端条件下的物质行为提供理论预测和验证，有助于解决实验与理论之间的长期争议。

<details>
  <summary>Details</summary>

**Motivation:** 计算温稠密区域氢的状态方程；解决氘Hugoniot曲线上现有理论和实验结果的差异。

**Method:** 开发了一个深度变分自由能框架。该方法通过三个深度生成模型参数化有限温度下氢核和电子的变分密度矩阵：一个表示经典核玻尔兹曼分布的归一化流模型；一个模拟激发态电子分布的自回归Transformer；一个构建Hartree-Fock轨道中电子回流坐标的置换等变流模型。通过联合优化这三个神经网络以最小化变分自由能。

**Result:** 获得了致密氢的状态方程和相关热力学性质。计算结果与氘Hugoniot曲线上其他理论和实验结果进行了比较。计算结果为温稠密区域的氘提供了有价值的基准。

**Conclusion:** 所计算的结果为温稠密区域的氘提供了有价值的基准，并有助于解决现有差异。

> **ai_Abstract:** 本文提出了一种深度变分自由能框架，用于计算温稠密区域氢的状态方程和热力学性质。该框架结合了归一化流、自回归Transformer和置换等变流三种深度生成模型，共同优化以最小化变分自由能。研究结果与氘Hugoniot曲线上的现有数据进行了比较，并为温稠密区域的氘提供了新的基准，有助于解决现有理论与实验之间的差异。

> **摘要翻译:** 我们开发了一个深度变分自由能框架来计算温稠密物质区域中氢的状态方程。该方法利用三个深度生成模型在有限温度下参数化氢核和电子的变分密度矩阵：一个表示经典核玻尔兹曼分布的归一化流模型，一个模拟激发态电子分布的自回归Transformer，以及一个构建Hartree-Fock轨道中电子回流坐标的置换等变流模型。通过联合优化这三个神经网络以最小化变分自由能，我们获得了致密氢的状态方程和相关热力学性质。我们将我们的结果与氘Hugoniot曲线上的其他理论和实验结果进行比较，旨在解决现有差异。计算结果为温稠密区域的氘提供了有价值的基准。

</details>

[⬆️ 返回分类顶部](#cond-matstr-el) | [⬆️ 返回总目录](#toc)

---

<a id='physicsoptics'></a>
## physics.optics 

### [583] [Modular and Automated Workflow for Streamlined Raman Signal Analysis](https://arxiv.org/abs/2507.17917)
> *模块化和自动化工作流程，用于简化拉曼信号分析*

*Mykyta Kizilov, Vsevolod Cheburkanov, Joseph Harrington, Vladislav V. Yakovlev* | **Category: physics.optics, eess.SP, physics.chem-ph** | **Updated: 2025-07-23**

**Keywords:** 拉曼光谱, 信号分析, 预处理, Voigt峰拟合, 自动化

**Comment:** Preprint. Submitted to Journal of Raman Spectroscopy

> **TL;DR:** 本文提出了一种模块化和自动化的拉曼光谱数据处理工作流程，包括预处理和Voigt峰拟合，并在合成和真实数据上验证了其有效性，代码已开源。

**AI_Comments:** 该论文的创新点在于提供了一个模块化和自动化的拉曼信号分析工作流程，解决了传统拉曼光谱分析中预处理的复杂性。开源代码的提供也极大地提高了其可用性和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 拉曼光谱是材料表征的强大工具，但其信号分析需要细致的预处理来识别和处理噪声、基线漂移和随机尖峰。

**Method:** 本文提出了一种生成和预处理拉曼光谱的综合方法，并描述了将Voigt峰拟合到光谱以确定峰参数的方法。

**Result:** 这些方法的有效性通过合成和真实的拉曼光谱得到了验证，相关代码已在开源GitHub仓库中提供。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了一种用于拉曼信号分析的模块化自动化工作流程。该方法解决了拉曼光谱中噪声、基线漂移和尖峰等预处理挑战，并提供了生成和预处理光谱的综合方法，以及使用Voigt峰拟合来确定峰参数。其有效性已通过合成和真实拉曼光谱得到验证，并提供了开源代码。

> **摘要翻译:** 拉曼光谱是材料表征的强大工具。然而，为了识别和处理噪声、基线漂移和随机尖峰，需要仔细的预处理。本文提出了一种生成和预处理拉曼光谱的综合方法。此外，我们描述了将Voigt峰拟合到光谱以确定峰参数的方法。这些方法的有效性通过合成和真实的拉曼光谱得到了验证，代码已在开源GitHub仓库中提供。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

<a id='statot'></a>
## stat.OT 

### [586] [Machine Learning Solutions Integrated in an IoT Healthcare Platform for Heart Failure Risk Stratification](https://arxiv.org/abs/2505.09619)
> *集成到物联网医疗平台中的机器学习解决方案，用于心力衰竭风险分层*

*Aiman Faiz, Anna Maria De Roberto, Claudio Pascarelli, Gianvito Mitrano, Gianluca Fimiani, Marina Garofano, Genoveffa Tortora, Mariangela Lazoi, Claudio Passino, Alessia Bramanti* | **Category: stat.OT, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 机器学习, 心力衰竭, 风险分层, 集成学习, 物联网医疗

**Comment:** 

> **TL;DR:** 该论文提出了一种基于机器学习的集成学习模型，用于识别心力衰竭风险患者，该模型在真实数据集上表现出高灵敏度和可接受的准确性，并优于基线模型，可作为医疗专业人员的决策支持工具。

**AI_Comments:** 该论文的创新之处在于其采用的改进堆叠集成学习方法，结合了特定领域的临床和超声心动图特征，以提高心力衰竭风险分层的准确性和灵敏度。其将机器学习模型集成到物联网医疗平台的愿景，体现了对实际应用和远程医疗的关注，这在慢性病管理中具有重要意义。高灵敏度（95%）的实现是其一大亮点，确保了高风险患者的有效识别，对于早期干预至关重要。尽管准确性（84%）可能不是最高，但作者对其在特定应用场景下的合理性进行了充分解释，体现了对实际需求和临床优先级的理解。该研究为心力衰竭的智能监测和管理提供了有益的探索。

<details>
  <summary>Details</summary>

**Motivation:** 慢性心力衰竭（HF）的管理在现代医疗保健中面临重大挑战，需要持续监测、早期发现病情恶化以及个性化治疗策略。本研究旨在开发一种预测模型，以识别具有心力衰竭风险的患者。

**Method:** 本研究提出了一种基于机器学习技术的预测模型，具体采用了一种改进的堆叠（stacking）集成学习方法。该模型包含两个专门模型，分别利用临床和超声心动图特征，然后通过一个元模型（meta-model）来结合这两个模型的预测结果。

**Result:** 该模型在真实数据集上进行了评估，结果表明其在心力衰竭风险患者的分层方面表现良好。具体而言，模型获得了95%的高灵敏度，确保几乎所有高风险患者都被识别出来。准确性为84%，这在某些机器学习环境中可能被认为是中等水平，但考虑到识别心力衰竭风险患者的优先性（以便他们参与远程监测项目），这是可以接受的。初步发现还表明，基于机器学习的风险分层模型可以作为有价值的决策支持工具，辅助早期干预和个性化患者管理。与三个基线模型进行对比，本研究的预测模型表现优于这些未对特征进行分组的基线模型。

**Conclusion:** 本研究提出的基于机器学习的预测模型在心力衰竭风险分层方面表现出色，特别是在识别高风险患者方面具有高灵敏度。它可作为医疗专业人员的宝贵决策支持工具，辅助早期干预和个性化患者管理。初步结果表明该模型优于传统的基线方法。

> **ai_Abstract:** 该论文介绍了一种集成到物联网（IoT）医疗平台中的机器学习解决方案，旨在对心力衰竭（HF）患者进行风险分层。研究开发了一个基于改进堆叠技术的集成学习预测模型，该模型结合了利用临床和超声心动图特征的两个专门模型的预测结果。在真实数据集上的评估显示，该模型在风险分层方面表现良好，具有95%的高灵敏度和84%的准确性。尽管准确性在某些上下文中可能适中，但考虑到识别高风险患者以进行远程监测的优先性，该性能被认为是可接受的。研究结果强调了该模型作为医疗专业人员的宝贵决策支持工具的潜力，能够辅助早期干预和个性化患者管理。与基线模型相比，该预测模型表现出优越的性能。

> **摘要翻译:** 慢性心力衰竭（HF）的管理在现代医疗保健中面临重大挑战，需要持续监测、早期发现病情恶化以及个性化治疗策略。本文提出了一种基于机器学习（ML）技术的预测模型，用于识别心力衰竭风险患者。该模型采用集成学习方法，是一种改进的堆叠技术，它使用两个专门模型，分别利用临床和超声心动图特征，然后通过一个元模型来结合这两个模型的预测结果。我们首先在一个真实数据集上评估了该模型，结果表明它在心力衰竭风险患者的分层方面表现良好。具体而言，我们获得了95%的高灵敏度，确保几乎所有高风险患者都被识别出来。至于准确性，我们获得了84%，这在某些机器学习环境中可能被认为是中等水平。然而，考虑到我们优先识别心力衰竭风险患者（因为他们将被邀请参与PrediHealth研究项目的远程监测计划，本论文的一些作者正在参与该项目），这是可以接受的。初步发现还表明，基于机器学习的风险分层模型不仅可以在PrediHealth项目中，而且可以为医疗专业人员提供有价值的决策支持工具，辅助早期干预和个性化患者管理。为了更好地理解我们预测模型的价值和潜力，我们还将其结果与使用三个基线模型获得的结果进行了对比。初步结果表明，我们的预测模型优于这些简单地考虑特征（即未将其分为临床和超声心动图特征）的基线模型。

</details>

[⬆️ 返回分类顶部](#statot) | [⬆️ 返回总目录](#toc)

---

<a id='physicsacc-ph'></a>
## physics.acc-ph 

### [596] [A Supervised Machine Learning Framework for Multipactor Breakdown Prediction in High-Power Radio Frequency Devices and Accelerator Components: A Case Study in Planar Geometry](https://arxiv.org/abs/2507.17881)
> *高功率射频设备和加速器组件中多重击穿预测的监督机器学习框架：以平面几何为例*

*Asif Iqbal, John Verboncoeur, Peng Zhang* | **Category: physics.acc-ph, cs.LG, physics.app-ph, physics.plasm-ph** | **Updated: 2025-07-23**

**Keywords:** 多重击穿, 机器学习, 射频设备, 加速器组件, 击穿预测

**Comment:** 

> **TL;DR:** 本研究首次应用监督机器学习预测高功率射频设备和加速器组件中的多重击穿现象，并评估了不同模型性能。

**AI_Comments:** 本研究首次将监督机器学习应用于多重击穿预测，具有创新性。它解决了高功率射频设备设计中一个计算密集型的关键挑战。研究也揭示了现有方法的局限性，即在某些材料上性能下降，这强调了未来需要更广泛、更具代表性的数据集覆盖。

<details>
  <summary>Details</summary>

**Motivation:** 多重击穿是一种非线性电子雪崩现象，会严重损害高功率射频设备和加速器系统的性能。准确预测多重击穿敏感性是关键但计算密集型的挑战。

**Method:** 本研究首次将监督机器学习（包括随机森林、Extra Trees、XGBoost和多层感知器MLPs）应用于预测双表面平面几何中的多重击穿敏感性。使用一个跨越六种不同次级电子产额（SEY）材料剖面的模拟数据集来训练模型，以预测时间平均电子增长率。性能通过交并比（IoU）、结构相似性指数（SSIM）和皮尔逊相关系数进行评估。MLPs在贝叶斯超参数优化过程中结合IoU和SSIM的标量化目标函数进行训练，并采用5折交叉验证。

**Result:** 树模型在跨不相交材料域的泛化能力上始终优于MLP。使用结合IoU和SSIM的标量化目标函数训练的MLP模型优于使用单一目标损失函数训练的模型。主成分分析揭示某些材料的性能下降源于不相交的特征空间分布。

**Conclusion:** 本研究展示了基于机器学习的多重击穿预测的潜力和局限性，并为先进射频和加速器系统设计中加速、数据驱动的建模奠定了基础。

> **ai_Abstract:** 本研究首次探索了监督机器学习在预测高功率射频设备和加速器组件中多重击穿现象的应用。研究人员利用模拟数据集训练了多种回归模型（如随机森林、XGBoost、MLPs），以预测时间平均电子增长率。结果表明，树模型在泛化能力上表现更优，而结合多目标优化训练的MLPs性能更佳。研究强调了数据集覆盖范围的重要性，并为未来数据驱动的射频系统设计奠定了基础，同时指出了ML方法的潜力和局限性。

> **摘要翻译:** 多重击穿是一种非线性电子雪崩现象，可以严重损害高功率射频（RF）设备和加速器系统的性能。在不同材料和操作条件下准确预测多重击穿敏感性仍然是加速器组件设计和射频工程中一个关键但计算密集型的挑战。本研究首次将监督机器学习（ML）应用于预测双表面平面几何中的多重击穿敏感性。使用一个跨越六种不同次级电子产额（SEY）材料剖面的模拟数据集来训练回归模型——包括随机森林（RF）、Extra Trees（ET）、极端梯度提升（XGBoost）和漏斗结构多层感知器（MLPs）——以预测时间平均电子增长率${\delta}_{avg}$。性能通过交并比（IoU）、结构相似性指数（SSIM）和皮尔逊相关系数进行评估。树模型在跨不相交材料域的泛化能力上始终优于MLP。使用在贝叶斯超参数优化过程中结合IoU和SSIM的标量化目标函数训练的MLP模型，其性能优于使用单一目标损失函数训练的模型，并采用5折交叉验证。主成分分析揭示某些材料的性能下降源于不相交的特征空间分布，这强调了需要更广泛的数据集覆盖。本研究展示了基于机器学习的多重击穿预测的潜力和局限性，并为先进射频和加速器系统设计中加速、数据驱动的建模奠定了基础。

</details>

[⬆️ 返回分类顶部](#physicsacc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cscg'></a>
## cs.CG 

### [633] [Explainable Mapper: Charting LLM Embedding Spaces Using Perturbation-Based Explanation and Verification Agents](https://arxiv.org/abs/2507.18607)
> *可解释的映射器：使用基于扰动的解释和验证代理绘制大型语言模型嵌入空间*

*Xinyuan Yan, Rita Sevastjanova, Sinie van der Ben, Mennatallah El-Assady, Bei Wang* | **Category: cs.CG, cs.LG** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型嵌入, 映射器图, 可解释性, 扰动技术, 代理

**Comment:** 

> **TL;DR:** 介绍了一个半自动框架，使用基于LLM的扰动代理来探索和解释大型语言模型嵌入空间的拓扑结构。

**AI_Comments:** 该论文的创新点在于提出了一个半自动化的框架，利用LLM代理和扰动技术来解释和探索高维LLM嵌入空间，显著降低了人工分析的成本和复杂性。其重要性在于提供了一种可扩展的方法来理解LLM内部表征的语言属性，对于LLM的可解释性研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 手动探索LLM嵌入空间以揭示编码的语言属性需要大量人工，且LLM产生的高维嵌入捕获复杂的语义和句法关系，理解其底层结构很重要。

**Method:** 引入一个半自动注释LLM嵌入属性的框架。定义了映射图（mapper graph）中可探索元素的分类法（节点、边、路径、组件、轨迹）。通过两种可定制的基于LLM的代理执行注释，这些代理采用扰动技术进行可扩展和自动化分析，帮助探索、解释和验证解释的鲁棒性。该框架在一个可视化分析工作区中实例化。

**Result:** 通过案例研究证明了其有效性。复制了先前关于BERT架构各层嵌入属性的研究结果，并对拓扑邻域的语言属性提供了进一步的观察。

**Conclusion:** 该框架能够半自动化地探索和解释LLM嵌入空间的语言属性，提高了分析效率和可扩展性。

> **ai_Abstract:** 本文提出了一个名为“可解释的映射器”的半自动化框架，旨在解决手动探索大型语言模型（LLM）高维嵌入空间拓扑结构效率低下的问题。该框架利用映射器图总结嵌入空间结构，并定义了可探索元素的分类法。核心在于引入了两种基于LLM的可定制代理，它们通过扰动技术进行可扩展的自动化分析，以探索、解释和验证映射器元素的语言特性。通过在可视化分析工作区中的实例化和案例研究，该框架被证明能够有效复制现有发现并提供新的观察，从而促进对LLM嵌入空间深层语言属性的理解。

> **摘要翻译:** 大型语言模型（LLM）产生高维嵌入，捕获词语、句子和概念之间丰富的语义和句法关系。通过映射器图（mapper graph）研究LLM嵌入空间的拓扑结构，使我们能够理解其底层结构。具体来说，映射器图总结了嵌入空间的拓扑结构，其中每个节点代表一个拓扑邻域（包含一组嵌入），如果它们的相应邻域重叠，则连接两个节点。然而，手动探索这些嵌入空间以揭示编码的语言属性需要大量人工。为了解决这个挑战，我们引入了一个用于半自动注释这些嵌入属性的框架。为了组织探索过程，我们首先定义了映射器图中可探索元素的分类法，例如节点、边、路径、组件和轨迹。这些元素的注释通过两种可定制的基于LLM的代理执行，这些代理采用扰动技术进行可扩展和自动化分析。这些代理有助于探索和解释映射器元素的特征，并验证所生成解释的鲁棒性。我们将该框架实例化在一个可视化分析工作区中，并通过案例研究证明了其有效性。特别是，我们复制了先前关于BERT架构各层嵌入属性的研究结果，并对拓扑邻域的语言属性提供了进一步的观察。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

<a id='physicsins-det'></a>
## physics.ins-det 

### [636] [A 55-nm SRAM Chip Scanning Errors Every 125 ns for Event-Wise Soft Error Measurement](https://arxiv.org/abs/2504.08305)
> *用于事件级软错误测量的每125纳秒扫描错误的55纳米SRAM芯片*

*Yuibi Gomi, Akira Sato, Waleed Madany, Kenichi Okada, Satoshi Adachi, Masatoshi Itoh, Masanori Hashimoto* | **Category: physics.ins-det, cs.AR** | **Updated: 2025-07-24**

**Keywords:** SRAM芯片, 软错误测量, 事件级, 时间同步, 空间同步

**Comment:** 4 pages, 9 figures, accepted for publication in IEEE Solid-State
  Circuits Letters (SSCL)

> **TL;DR:** 开发了一种55纳米SRAM芯片系统，能够以125纳秒的频率扫描错误，并结合粒子探测器进行事件级软错误测量，解决了传统方法无法区分的误分类问题，并通过质子辐照实验验证了其同步和空间精度。

**AI_Comments:** 该论文的创新点在于开发了一种能够进行高速（125纳秒）错误扫描的55纳米SRAM芯片，并将其集成到一个完整的事件级软错误测量系统中。该系统通过精确的时间和空间同步，解决了传统软错误测量中存在的分类模糊问题，特别是对伪MCUs和远距离MCUs的区分能力，这对于深入理解和分析辐射引起的软错误机制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法无法区分伪MCUs和远距离MCUs等软错误误分类，需要一种新的系统来精确识别SBUs和MCUs并进行事件级软错误测量。

**Method:** 开发了一种55纳米CMOS SRAM芯片，每125纳秒扫描所有数据并通过SPI接口输出带时间戳的软错误数据。该系统结合了开发的芯片和粒子探测器。通过确定亚纳秒分辨率的复位偏移实现事件构建，并成功同步SRAM芯片和粒子探测器之间的时间戳，考虑了辐射引起的PLL扰动，空间同步保持在几十微米以内。

**Result:** 该系统实现了事件级软错误测量，并能精确识别SBUs和MCUs，解决了传统方法无法区分的伪MCUs和远距离MCUs等误分类问题。在东北大学RARiS进行的80-MeV质子辐照实验验证了系统运行。SRAM芯片和粒子探测器之间的时间戳成功同步，空间同步保持在几十微米以内。

**Conclusion:** 开发的55纳米SRAM芯片系统能够进行高精度的事件级软错误测量，并通过精确的时间和空间同步解决了传统软错误分类的局限性。

> **ai_Abstract:** 本研究开发了一种55纳米CMOS SRAM芯片及其配套系统，旨在实现高精度的事件级软错误测量。该芯片每125纳秒扫描数据并输出带时间戳的错误信息。结合粒子探测器，该系统能够精确识别单比特翻转（SBUs）和多比特翻转（MCUs），有效解决传统方法中存在的伪MCUs和远距离MCUs等分类错误。系统在80-MeV质子辐照实验中验证了其功能，并成功实现了SRAM芯片与探测器之间的时间和空间同步，精度分别达到亚纳秒和几十微米。

> **摘要翻译:** 我们开发了一种55纳米CMOS SRAM芯片，该芯片每125纳秒扫描所有数据，并通过FIFO经由SPI接口输出带时间戳的软错误数据。所提出的系统，由开发的芯片和粒子探测器组成，能够实现事件级软错误测量和SBUs和MCUs的精确识别，从而解决了传统方法无法区分的伪MCUs和远距离MCUs等误分类问题。在东北大学RARiS进行的80-MeV质子辐照实验验证了系统运行。SRAM芯片和粒子探测器之间的时间戳成功同步，考虑了辐射引起的PLL扰动。通过确定亚纳秒分辨率的复位偏移实现了事件构建，空间同步保持在几十微米以内。

</details>

[⬆️ 返回分类顶部](#physicsins-det) | [⬆️ 返回总目录](#toc)

---

<a id='q-bionc'></a>
## q-bio.NC 

### [638] [Multimodal Recurrent Ensembles for Predicting Brain Responses to Naturalistic Movies (Algonauts 2025)](https://arxiv.org/abs/2507.17897)
> *多模态循环集成模型预测大脑对自然电影的反应（Algonauts 2025）*

*Semih Eren, Deniz Kucukahmetler, Nico Scherf* | **Category: q-bio.NC, cs.CV, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 多模态, 循环集成, 大脑反应, fMRI, 自然电影

**Comment:** 8 pages, 2 figures, 1 table. Invited report, CCN 2025 Algonauts
  Project session (3rd-place team). Code:
  https://github.com/erensemih/Algonauts2025_ModalityRNN

> **TL;DR:** 该研究提出了一种多模态循环集成模型，用于预测大脑对自然电影的皮层反应，在Algonauts 2025挑战赛中排名第三，并在单个脑区表现最佳。

**AI_Comments:** 该论文提出了一种有效且可扩展的多模态循环集成模型，在脑响应预测领域取得了显著成果。其创新点在于结合了多模态信息（视觉、听觉、语言）以及分层循环网络设计，并引入了课程学习和模型集成策略来优化性能。在Algonauts 2025挑战赛中取得的第三名和最高的单脑区预测精度证明了其方法的有效性。此外，该方法被确立为一个简单、可扩展的基线，对未来多模态脑编码基准研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确预测大脑对自然刺激（如电影）的皮层反应，需要能够随时间整合视觉、听觉和语义信息的模型。

**Method:** 研究提出了一种分层多模态循环集成模型，将预训练的视频、音频和语言嵌入映射到fMRI时间序列。该模型包含特定模态的双向RNN编码时间动态，其隐藏状态被融合并传递到第二个循环层，轻量级的受试者特定头部输出1000个皮层区域的反应。训练采用复合MSE-相关损失和逐步从早期感觉区域向晚期关联区域转移重点的课程学习策略。平均100个模型变体以提高鲁棒性。

**Result:** 该系统在Algonauts 2025挑战赛排行榜上排名第三，整体皮尔逊相关系数r=0.2094，并在所有参与者中实现了最高的单脑区峰值分数（平均r=0.63），尤其是在最具挑战性的受试者（受试者5）上表现出显著提升。

**Conclusion:** 该方法为未来的多模态脑编码基准建立了一个简单、可扩展的基线。

> **ai_Abstract:** 本研究提出一种分层多模态循环集成模型，用于预测大脑对自然电影的皮层反应。该模型整合了视频、音频和语言嵌入，并使用双向RNN捕获时间动态，通过两层循环网络和受试者特定头部输出fMRI反应。模型采用复合损失和课程学习进行训练，并通过集成策略增强鲁棒性。在Algonauts 2025挑战赛中，该模型表现出色，排名第三，并取得了最高的单脑区预测精度，为未来的多模态脑编码研究提供了有效且可扩展的基线。

> **摘要翻译:** 准确预测大脑对自然刺激的分布式皮层反应需要模型能够随时间整合视觉、听觉和语义信息。我们提出了一种分层多模态循环集成模型，将预训练的视频、音频和语言嵌入映射到四名受试者在观看Algonauts 2025挑战赛提供的近80小时电影时记录的fMRI时间序列。特定模态的双向RNN编码时间动态；它们的隐藏状态被融合并传递到第二个循环层，轻量级的受试者特定头部输出1000个皮层区域的反应。训练依赖于复合MSE-相关损失和逐步将重点从早期感觉区域转移到晚期关联区域的课程学习策略。平均100个模型变体进一步提高了鲁棒性。由此产生的系统在竞赛排行榜上排名第三，整体皮尔逊相关系数r = 0.2094，并在所有参与者中实现了最高的单脑区峰值分数（平均r = 0.63），尤其是在最具挑战性的受试者（受试者5）上获得了显著提升。该方法为未来的多模态脑编码基准建立了一个简单、可扩展的基线。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

<a id='physicscomp-ph'></a>
## physics.comp-ph 

### [849] [Machine Learning Workflow for Analysis of High-Dimensional Order Parameter Space: A Case Study of Polymer Crystallization from Molecular Dynamics Simulations](https://arxiv.org/abs/2507.17980)
> *机器学习工作流用于高维序参数空间分析：聚合物分子动力学模拟结晶的案例研究*

*Elyar Tourani, Brian J. Edwards, Bamin Khomami* | **Category: physics.comp-ph, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 聚合物结晶, 分子动力学模拟, 机器学习, 序参数, 结晶度指数

**Comment:** 30 pages, 8 figures, 1 table

> **TL;DR:** 本文提出了一种集成机器学习工作流，利用高维特征向量、降维嵌入和无监督聚类来准确量化聚合物结晶度，并发现仅需三个序参数即可高效计算结晶指数，且在大型模拟中表现出色。

**AI_Comments:** 这项研究的创新之处在于其整合了多种机器学习技术，从高维原子特征中自动学习并识别出最小且高效的序参数集来量化聚合物结晶度。它克服了传统方法对单一序参数和预设截止点的依赖，提供了更鲁棒和数据驱动的解决方案。其能够实现实时计算结晶度，并洞察结晶过程中熵和对称性作用的演变，对于大规模分子模拟和材料科学领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 目前聚合物结晶路径的识别依赖于基于单一序参数预设截止点的方法，但这容易受截止点敏感性和系统偏差的影响。

**Method:** 本研究提出一种集成机器学习工作流，利用原子分子动力学数据量化聚合物结晶度。首先，每个原子由结合几何、热力学和对称性描述符的高维特征向量表示。接着，采用低维嵌入揭示原子环境中的潜在结构指纹，并使用无监督聚类高精度识别晶态和非晶态原子。然后，利用监督学习技术识别捕获这些标签的最小序参数集。

**Result:** 实验证明，仅使用三个序参数就足以重现结晶标签。基于这些序参数，结晶度指数（C-index）被定义为逻辑回归模型预测结晶度的概率，其在整个过程中保持双峰分布，分类性能（AUC）超过0.98。此外，一个在少量快照上训练的模型就能实现高效的实时结晶度计算。研究还显示，最优C-index拟合在结晶不同阶段演变，支持了熵在早期成核中占主导地位而对称性在后期变得更重要的假设。

**Conclusion:** 该工作流为序参数选择提供了一种数据驱动的策略，并提供了一个监测大规模聚合物模拟中结构转变的指标。

> **ai_Abstract:** 本文提出了一种创新的机器学习工作流，旨在克服传统方法中单一序参数定义聚合物结晶度的局限性和偏差。该工作流通过将原子表示为高维特征向量，并结合低维嵌入和无监督聚类来准确识别晶态和非晶态原子。在此基础上，利用监督学习技术识别出仅需三个序参数即可高效量化结晶度的最小集合。研究定义了结晶度指数（C-index）作为逻辑回归模型的结晶概率，实现了高分类性能（AUC>0.98），并支持实时计算。该方法为聚合物结晶的序参数选择和结构转变监测提供了一种数据驱动且高效的策略。

> **摘要翻译:** 目前，聚合物结晶路径的识别是利用基于分子模拟数据，在单一序参数（OP）上预设一个截止点来定义成核或结晶区域的。除了对截止点的敏感性外，每个序参数都引入了其自身的系统偏差。在这项研究中，提出了一种集成的机器学习工作流，用于使用原子分子动力学数据准确量化聚合物系统中的结晶度。每个原子由一个结合了几何、热力学类和基于对称性的描述符的高维特征向量表示。采用低维嵌入来揭示原子环境中的潜在结构指纹。随后，对嵌入进行无监督聚类，以高精度识别晶态和非晶态原子。在生成多维数据的高质量标签后，我们使用监督学习技术来识别能够完全捕获此标签的最小序参数集。进行了各种测试以减少特征集，结果表明仅使用三个序参数就足以重新创建结晶标签。基于这些观察到的序参数，结晶度指数（C-index）被定义为逻辑回归模型预测结晶度的概率，其在整个过程中保持双峰分布，分类性能（AUC）超过0.98（AUC）。值得注意的是，在一个或几个快照上训练的模型能够实现高效的实时结晶度计算。最后，我们展示了最优C-index拟合在结晶的各个阶段如何演变，支持了熵在早期成核中占主导地位，而对称性在后期获得相关性的假设。该工作流为序参数选择提供了一种数据驱动的策略，并提供了一个监测大规模聚合物模拟中结构转变的指标。

</details>

[⬆️ 返回分类顶部](#physicscomp-ph) | [⬆️ 返回总目录](#toc)

