# AI-Enhanced arXiv Daily 2025-07-15

<a id='toc'></a>
## 今日总计: 813 篇论文
### 目录
- [cs.CR](#cscr) (36 篇)
- [cs.AI](#csai) (55 篇)
- [cs.LG](#cslg) (154 篇)
- [cs.MA](#csma) (6 篇)
- [cs.RO](#csro) (49 篇)
- [cs.CV](#cscv) (119 篇)
- [cs.HC](#cshc) (15 篇)
- [cs.ET](#cset) (1 篇)
- [cs.SE](#csse) (29 篇)
- [cs.SI](#cssi) (10 篇)
- [cs.NI](#csni) (11 篇)
- [cs.IT](#csit) (10 篇)
- [cs.AR](#csar) (9 篇)
- [cs.DC](#csdc) (15 篇)
- [cs.CY](#cscy) (12 篇)
- [cs.CE](#csce) (4 篇)
- [cs.FL](#csfl) (5 篇)
- [eess.SY](#eesssy) (13 篇)
- [eess.SP](#eesssp) (14 篇)
- [eess.IV](#eessiv) (15 篇)
- [eess.AS](#eessas) (5 篇)
- [cs.CL](#cscl) (89 篇)
- [cs.DS](#csds) (16 篇)
- [cs.GR](#csgr) (5 篇)
- [cs.IR](#csir) (11 篇)
- [cs.NE](#csne) (7 篇)
- [math.NA](#mathna) (15 篇)
- [cs.SD](#cssd) (8 篇)
- [quant-ph](#quant-ph) (10 篇)
- [physics.soc-ph](#physicssoc-ph) (2 篇)
- [q-bio.QM](#q-bioqm) (3 篇)
- [gr-qc](#gr-qc) (1 篇)
- [cs.GT](#csgt) (4 篇)
- [stat.ML](#statml) (11 篇)
- [hep-lat](#hep-lat) (1 篇)
- [physics.comp-ph](#physicscomp-ph) (1 篇)
- [physics.med-ph](#physicsmed-ph) (2 篇)
- [econ.GN](#econgn) (1 篇)
- [q-fin.RM](#q-finrm) (1 篇)
- [math.OC](#mathoc) (8 篇)
- [physics.optics](#physicsoptics) (2 篇)
- [cs.PL](#cspl) (1 篇)
- [q-bio.NC](#q-bionc) (1 篇)
- [cs.MM](#csmm) (1 篇)
- [cs.DM](#csdm) (2 篇)
- [math.ST](#mathst) (1 篇)
- [cs.CG](#cscg) (1 篇)
- [cond-mat.str-el](#cond-matstr-el) (2 篇)
- [math.DS](#mathds) (1 篇)
- [cs.LO](#cslo) (1 篇)
- [math.NT](#mathnt) (1 篇)
- [q-fin.TR](#q-fintr) (1 篇)
- [stat.ME](#statme) (1 篇)
- [physics.app-ph](#physicsapp-ph) (1 篇)
- [stat.AP](#statap) (1 篇)
- [physics.geo-ph](#physicsgeo-ph) (1 篇)
- [math.AP](#mathap) (2 篇)
- [physics.chem-ph](#physicschem-ph) (1 篇)
- [cond-mat.soft](#cond-matsoft) (1 篇)
- [cs.DB](#csdb) (2 篇)
- [math.CA](#mathca) (1 篇)
- [math.PR](#mathpr) (1 篇)
- [math-ph](#math-ph) (1 篇)
- [cs.CC](#cscc) (1 篇)
- [astro-ph.SR](#astro-phsr) (1 篇)

---
<a id='cscr'></a>
## cs.CR 

### [43] [Adaptive Federated Learning with Functional Encryption: A Comparison of Classical and Quantum-safe Options](https://arxiv.org/abs/2504.00563)
> *自适应联邦学习与函数加密：经典与量子安全选项的比较*

*Enrico Sorbera, Federica Zanetti, Giacomo Brandi, Alessandro Tomasi, Roberto Doriguzzi-Corin, Silvio Ranise* | **Category: cs.CR** | **Updated: 2025-07-15**

**Keywords:** 联邦学习, 函数加密, 重构攻击, 网络入侵检测系统, 后量子加密

**Comment:** 

> **TL;DR:** 本文通过将多输入函数加密（MIFE）应用于联邦学习（FL），解决了FL在网络入侵检测系统中面临的重构攻击问题，并比较了经典和后量子解决方案的性能。

**AI_Comments:** 本文通过引入多输入函数加密（MIFE）来增强联邦学习的安全性，特别是在抵御重构攻击方面，具有创新性。其将研究重点放在网络入侵检测系统上，并比较了经典与后量子加密方案，这对于未来安全且高效的FL部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）尽管能保护数据隐私，但易受重构攻击，这些攻击利用共享参数泄露私人训练数据。

**Method:** 本文通过在网络安全领域将多输入函数加密（MIFE）应用于最新的联邦学习实现，用于训练基于机器学习的网络入侵检测系统。研究评估了经典和后量子解决方案在FL过程中的内存成本、计算开销及其对收敛时间的影响。

**Result:** 论文评估了经典和后量子解决方案在内存成本、计算开销以及对收敛时间的影响方面的表现。具体评估结果未在摘要中详细说明。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文旨在解决联邦学习（FL）中存在的重构攻击漏洞，该漏洞可能导致私人训练数据泄露。研究者通过在网络安全领域，将多输入函数加密（MIFE）应用于训练机器学习驱动的网络入侵检测系统（NIDS）的FL实现中。论文进一步评估了经典加密和后量子加密方案在FL过程中的内存消耗、计算开销以及对模型收敛时间的影响。

> **摘要翻译:** 联邦学习（FL）是一种协作训练机器学习模型的方法，同时能保护参与者训练数据的机密性。然而，FL易受重构攻击，这些攻击利用共享参数来泄露私人训练数据。在本文中，我们通过将多输入函数加密（MIFE）应用于最近的FL实现，用于训练基于机器学习的网络入侵检测系统，从而解决了网络安全领域的这一问题。我们评估了经典和后量子解决方案在FL过程中的内存成本和计算开销，并强调了它们对收敛时间的影响。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [97] [Decomposition-Based Optimal Bounds for Privacy Amplification via Shuffling](https://arxiv.org/abs/2504.07414)
> *基于分解的洗牌隐私增强最优界限*

*Pengcheng Su, Haibo Cheng, Ping Wang* | **Category: cs.CR** | **Updated: 2025-07-15**

**Keywords:** 隐私增强, 洗牌模型, 差分隐私, 分解, 最优界限

**Comment:** 

> **TL;DR:** 本文提出了一个统一的分析框架和基于FFT的算法，用于计算洗牌模型中隐私增强的最优界限，并证明了其紧密性。

**AI_Comments:** 本文的主要创新在于提出了一个统一的分析框架，将现有的隐私增强分解方法整合起来，并提供了一种基于FFT的高效算法来计算最优且紧密的隐私增强界限。这对于理解和实际应用洗牌模型中的差分隐私增强具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 洗牌已被证明可以增强差分隐私保证，从而实现更有利的隐私-效用权衡。为了表征和计算这种增强，已提出了两种基本分析框架（隐私毯和克隆）。这些框架共享一个共同基础：将局部随机器分解为结构化组件进行分析。本研究旨在引入一个统一的分析框架，以更好地理解和计算最优的隐私增强。

**Method:** 本文引入了一个统一的分析框架——通用克隆范式，它涵盖了所有可能的分解，并将克隆和隐私毯分解作为特例。在此框架内，确定了最优分解，即隐私毯所使用的分解。此外，开发了一种基于快速傅里叶变换（FFT）的简单高效算法来计算最优隐私增强界限。

**Result:** 实验结果表明，我们计算的上界几乎与下界匹配，证明了我们方法的紧密性。基于此方法，我们还推导出了洗牌模型中局部差分隐私（LDP）机制的联合和并行组合的最优增强界限。

**Conclusion:** 本文提出了一个统一的分析框架（通用克隆范式）来理解和计算洗牌模型中的隐私增强，并确定了最优分解。同时，开发了一种高效的基于FFT的算法来计算紧密的最优隐私增强界限，并将其应用于LDP机制的组合。

> **ai_Abstract:** 本文提出了一个名为“通用克隆范式”的统一分析框架，用于分析通过洗牌实现的隐私增强，该框架涵盖了现有分解方法。研究确定了隐私毯作为最优分解，并提出了一种基于快速傅里叶变换（FFT）的高效算法，用于计算紧密的最优隐私增强界限。此外，该方法还被用于推导洗牌模型中局部差分隐私（LDP）机制的联合和并行组合的最优增强界限。

> **摘要翻译:** 洗牌已被证明可以增强差分隐私保证，从而实现更有利的隐私-效用权衡。为了表征和计算这种增强，已提出了两种基本分析框架：Balle等人（CRYPTO 2019）提出的“隐私毯”和Feldman等人（FOCS 2021，SODA 2023）提出的“克隆”（包括标准和更强的变体）。这些框架共享一个共同基础：将局部随机器分解为结构化组件进行分析。在这项工作中，我们引入了一个统一的分析框架——通用克隆范式——它涵盖了所有可能的分解，并将克隆和隐私毯分解作为特例。在此框架内，我们确定了最优分解，即隐私毯所使用的分解。此外，我们开发了一种基于快速傅里叶变换（FFT）的简单高效算法来计算最优隐私增强界限。实验结果表明，我们计算的上界几乎与下界匹配，证明了我们方法的紧密性。基于此方法，我们还推导出了洗牌模型中局部差分隐私（LDP）机制的联合和并行组合的最优增强界限。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [147] [Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems](https://arxiv.org/abs/2505.23847)
> *跨域多智能体LLM系统必须解决的七个安全挑战*

*Ronny Ko, Jiseong Jeong, Shuyuan Zheng, Chuan Xiao, Tae-Wan Kim, Makoto Onizuka, Won-Yong Shin* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 跨域, 多智能体, LLM系统, 安全挑战, 信任

**Comment:** 

> **TL;DR:** 跨域多智能体LLM系统因信任假设被打破而面临新的安全风险；本文概述了七个挑战和研究方向。

**AI_Comments:** 这篇论文非常重要，因为它解决了LLM系统中一个关键且新兴的安全领域，特别是聚焦于跨域多智能体交互所带来的复杂性。其创新之处在于识别和分类了超越传统软件漏洞的新型安全挑战，强调了新兴的多智能体动态。通过提供一个包含潜在攻击、指标和研究指南的结构化议程，它为未来确保这些高级AI系统安全的工作提供了宝贵的框架。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）正迅速发展为跨组织边界协作的自主智能体，以实现联合灾难响应、供应链优化等任务。然而，这种跨域协作打破了当前对齐和遏制技术背后的统一信任假设，导致新的安全风险，如接收来自不受信任的对等方消息时可能泄露秘密或违反策略，这些风险由新兴的多智能体动态而非经典软件错误驱动。

**Method:** 本文旨在规划跨域多智能体LLM系统的安全议程。它提出了七类新颖的安全挑战，并为每一类挑战提供了可行的攻击、安全评估指标和未来的研究指南。

**Result:** 本文识别并分类了跨域多智能体LLM系统特有的七类新颖安全挑战，并为每类挑战提出了潜在的攻击、评估指标和研究方向。

**Conclusion:** 跨域多智能体LLM系统引入了超越传统软件漏洞的新型安全挑战，这些挑战源于新兴的多智能体动态，需要被解决。本文为未来的研究设定了议程。

> **ai_Abstract:** 这篇立场论文探讨了跨域多智能体大型语言模型（LLM）系统中的新兴安全挑战。它强调，LLM智能体跨组织边界的协作，虽然能促进灾难响应等任务，但却打破了传统的信任假设，从而导致了新的风险，如来自不受信任交互的数据泄露或策略违规。论文识别了七类新颖的安全挑战，并为每类挑战提供了攻击示例、评估指标和未来的研究方向，从而为这一不断发展的领域规划了关键的安全议程。

> **摘要翻译:** 大型语言模型（LLMs）正在迅速演变为跨组织边界协作的自主智能体，从而实现联合灾难响应、供应链优化以及其他需要去中心化专业知识而不放弃数据所有权的任务。然而，跨域协作打破了当前对齐和遏制技术背后的统一信任假设。一个在隔离状态下是良性的智能体，在接收到来自不受信任的对等方的消息时，可能会泄露秘密或违反策略，从而产生由新兴多智能体动态而非经典软件错误驱动的风险。这篇立场论文规划了跨域多智能体LLM系统的安全议程。我们提出了七类新颖的安全挑战，并为每一类挑战提出了可行的攻击、安全评估指标和未来的研究指南。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [192] [On the Virtues of Information Security in the UK Climate Movement](https://arxiv.org/abs/2506.09719)
> *英国气候运动中信息安全的优点*

*Mikaela Brough, Rikke Bjerg Jensen, Martin R. Albrecht* | **Category: cs.CR** | **Updated: 2025-07-15**

**Keywords:** 气候运动, 信息安全, 民族志, 激进主义, 社会复杂性

**Comment:** To appear at the USENIX Security Symposium 2025

> **TL;DR:** 一项对英国气候运动的民族志研究揭示了成员在信息安全方面面临的复杂社会张力，包括开放与保密、自主与集体、理想冲突以及外部压力，强调了激进主义环境中信息安全的社会复杂性。

**AI_Comments:** 这篇论文通过民族志研究方法，深入探讨了气候运动中信息安全的社会维度，而非仅仅技术层面，具有创新性。它揭示了激进主义者在信息安全实践中面临的真实困境和内部张力，对于理解用户需求和设计更符合情境的安全工具具有重要意义。其局限性可能在于研究范围仅限于英国气候运动，结果的普适性需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过民族志方法，深入理解英国气候运动成员在信息安全实践中面临的复杂社会挑战和张力。

**Method:** 研究采用民族志方法，在抗议活动和各种激进主义场合进行了参与式观察和访谈。

**Result:** 研究发现英国气候运动成员在信息安全方面面临四种主要张力：(i) 开放与保密之间的根本矛盾；(ii) 信息安全决策中自主性与集体相互依赖的张力；(iii) 塑造安全话语的冲突激进主义理想；以及 (iv) 来自彼此、运动外部人员和对手的不同社会审视压力。

**Conclusion:** 研究结果揭示了激进主义环境中信息安全研究的社会复杂性，并引发了关于旨在为激进主义者进行设计的项目的方法论问题。

> **ai_Abstract:** 这项民族志研究通过参与式观察和访谈，深入探讨了英国气候运动成员在信息安全实践中面临的复杂社会挑战。研究揭示了他们在开放与保密、自主与集体、理想冲突以及外部压力之间存在的四种主要张力，强调了激进主义环境中信息安全研究的社会复杂性，并对相关设计项目提出了方法论上的思考。

> **摘要翻译:** 我们报告了一项针对英国气候运动成员的民族志研究。我们在抗议活动和各种激进主义场合进行了参与式观察和访谈。报告了与信息安全相关的发现，我们表明英国气候运动的成员努力应对：(i) 开放与保密之间的根本性张力；(ii) 信息安全决策中自主性与集体相互依赖之间的张力；(iii) 塑造安全话语的冲突激进主义理想；以及 (iv) 来自不同社会审视——彼此、运动外部人员和对手——的压力。总的来说，我们的发现揭示了激进主义环境中信息安全研究的社会复杂性，并引发了关于旨在为激进主义者进行设计的项目的方法论问题。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [237] [A Sea of Cyber Threats: Maritime Cybersecurity from the Perspective of Mariners](https://arxiv.org/abs/2506.15842)
> *网络威胁的海洋：从海员视角看海事网络安全*

*Anna Raymaker, Akshaya Kumar, Miuyin Yong Wong, Ryan Pickren, Animesh Chhotaray, Frank Li, Saman Zonouz, Raheem Beyah* | **Category: cs.CR** | **Updated: 2025-07-14**

**Keywords:** 海事网络安全, 网络威胁, 海员, 用户研究, 关键基础设施

**Comment:** 18 pages, 2 figures, To appear in the Proceedings of the 2025 ACM
  SIGSAC Conference on Computer and Communications Security (CCS '25)

> **TL;DR:** 海事系统面临日益增长的网络威胁。本研究通过调查海员，了解他们对这些威胁的感知和经验，揭示了培训、工具和认知方面的问题，并提出了建议。

**AI_Comments:** 这篇论文很重要，因为它解决了一个全球基础设施中关键且未被充分研究的领域。其创新之处在于通过用户研究采纳了海员的视角，提供了关于真实世界网络威胁及其影响的独特第一手见解。研究结果非常实用，直接指出了具体的系统性和以人为中心的脆弱性，并为改进海事网络安全提供了可操作的建议。

<details>
  <summary>Details</summary>

**Motivation:** 海事系统是全球基础设施的关键组成部分，但面临日益增长的网络安全威胁（例如马士基攻击）。尽管该行业重要，但海事网络安全领域尚未得到充分探索，导致在理解其挑战和风险方面存在重大空白。本研究旨在通过调查海事系统操作员如何感知和应对这些复杂环境中的网络安全挑战来弥补这些空白。

**Method:** 本研究进行了一项用户研究，包括对21名高级海员进行调查和半结构化访谈。

**Result:** 参与者报告了亲身经历的船上网络攻击，包括GPS欺骗和扰乱物流的勒索软件。研究结果揭示了系统性和以人为中心的问题，例如与海事需求不符的培训、不足的检测和响应工具，以及海员网络安全理解方面的严重空白。本研究对海员识别的威胁进行了分类。

**Conclusion:** 本论文的贡献包括对海员识别的威胁进行分类，并提出了改进海事安全的建议，包括更好的培训、响应协议和法规。这些见解旨在指导未来的研究和政策，以增强海事系统的弹性。

> **ai_Abstract:** 这篇论文强调了海事网络安全这一关键但尚未充分探索的领域，该领域正面临日益增长的威胁。通过对21名海员进行调查和访谈的用户研究，本研究识别了真实的网络攻击经历（例如GPS欺骗、勒索软件），并揭示了系统性和以人为中心的问题，如培训不足、工具缺乏和知识空白。该研究对海员识别的威胁进行了分类，并为加强海事安全提供了建议，旨在为未来的政策和研究提供信息。

> **摘要翻译:** 包括船舶和港口在内的海事系统是全球基础设施的关键组成部分，对于运输全球80%以上的货物和支持互联网连接至关重要。然而，这些系统面临日益增长的网络安全威胁，最近针对全球最大航运公司之一马士基的攻击就表明了这一点，该攻击对国际贸易造成了广泛影响。海事环境的独特挑战——例如多样的操作条件、广泛的物理访问点、零散的监管框架以及其深度互联的结构——要求进行海事特定的网络安全研究。尽管该行业的重要性，海事网络安全仍未得到充分探索，导致在理解其挑战和风险方面存在重大空白。
为了弥补这些空白，我们调查了海事系统操作员如何在这种复杂环境中感知和应对网络安全挑战。我们对21名高级海员进行了包括调查和半结构化访谈在内的用户研究。参与者报告了亲身经历的船上网络攻击，包括GPS欺骗和扰乱物流的勒索软件，这表明了这些威胁的实际影响。我们的发现揭示了系统性和以人为中心的问题，例如与海事需求不符的培训、不足的检测和响应工具以及海员网络安全理解方面的严重空白。我们的贡献包括对海员识别的威胁进行分类，以及改进海事安全的建议，包括更好的培训、响应协议和法规。这些见解旨在指导未来的研究和政策，以增强海事系统的弹性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [287] [Balancing Privacy and Utility in Correlated Data: A Study of Bayesian Differential Privacy](https://arxiv.org/abs/2506.21308)
> *在相关数据中平衡隐私与效用：贝叶斯差分隐私研究*

*Martin Lange, Patricia Guerra-Balboa, Javier Parra-Arnau, Thorsten Strufe* | **Category: cs.CR, cs.IT, math.IT, 68P27** | **Updated: 2025-07-15**

**Keywords:** 贝叶斯差分隐私, 相关数据, 效用, 隐私泄露, 数据隐私

**Comment:** This is the extended version of the paper accepted in the Proceedings
  of the VLDB Endowment (PVLDB), 2025. The code used for our experiments is
  accessible in https://github.com/lange-martin/privacy-utility-bdp

> **TL;DR:** 在相关数据中，标准差分隐私（DP）不足以保护隐私，而贝叶斯差分隐私（BDP）能解决此问题但有效用损失。本研究提出新方法，使BDP在相关数据中既能保护隐私又能保持良好效用。

**AI_Comments:** 本文通过提出一种新颖的方法，成功解决了贝叶斯差分隐私（BDP）在相关数据中应用时面临的效用损失问题，使得BDP在实际场景中更具可行性。这项创新对于在复杂、相关数据集中实现有效的隐私保护至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 当数据相关时，标准差分隐私（DP）系统中的隐私风险显著增加，且当前贝叶斯差分隐私（BDP）机制存在显著的效用损失，限制了其应用。本研究旨在探讨BDP是否能在不牺牲效用的情况下应用于常见数据结构。

**Method:** 通过分析任意和结构化的相关模型（包括高斯多元分布和马尔可夫链），推导出BDP的实用效用保证。建立了DP和BDP之间的理论联系，并提出了一种调整DP机制以满足BDP要求的新颖方法。

**Result:** 所提出的新颖定理能够设计出保持竞争性效用的BDP机制。

**Conclusion:** 本研究为在相关数据设置中实现实用的隐私保护数据实践铺平了道路。

> **ai_Abstract:** 本文旨在解决在相关数据中使用贝叶斯差分隐私（BDP）时，如何在隐私和效用之间取得平衡的挑战。研究指出，标准差分隐私（DP）在处理相关数据时不足以保护隐私，而现有BDP方法则面临效用损失。作者提出了一种新颖的方法，通过分析相关模型并推导实用效用保证，建立了DP和BDP之间的理论联系。通过对真实世界数据库的评估，证明了其方法能够设计出保持竞争性效用的BDP机制，从而为相关数据环境中的实用隐私保护实践奠定了基础。

> **摘要翻译:** 当数据相关时，差分隐私（DP）系统中的隐私风险显著增加，因为标准DP指标通常低估了由此产生的隐私泄露，使敏感信息容易受到攻击。鉴于现实世界数据库中依赖关系的普遍性，这种疏忽对隐私保护构成了严峻挑战。贝叶斯差分隐私（BDP）扩展了DP以考虑这些相关性，但当前的BDP机制显示出显著的效用损失，限制了其采用。
在这项工作中，我们探讨了BDP是否可以在不牺牲效用的情况下实际应用于常见数据结构——这是其适用性的一个关键因素。通过分析任意和结构化的相关模型，包括高斯多元分布和马尔可夫链，我们为BDP推导出了实用的效用保证。我们的贡献包括DP和BDP之间的理论联系，以及一种用于调整DP机制以满足BDP要求的新颖方法。通过对真实世界数据库的评估，我们证明了我们的新颖定理能够设计出保持竞争性效用的BDP机制，为在相关设置中实现实用的隐私保护数据实践铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [337] [Rethinking Broken Object Level Authorization Attacks Under Zero Trust Principle](https://arxiv.org/abs/2507.02309)
> *在零信任原则下重新思考失效对象级授权攻击*

*Anbin Wu, Zhiyong Feng, Ruitao Feng, Zhenchang Xing, Yang Liu* | **Category: cs.CR** | **Updated: 2025-07-15**

**Keywords:** 零信任,失效对象级授权,API安全,静态污点跟踪,授权边界

**Comment:** 

> **TL;DR:** 本文提出了BOLAZ，一个基于零信任原则的防御框架，用于识别和防御API中的失效对象级授权（BOLA）攻击，并通过实证研究证明了其有效性。

**AI_Comments:** 本文的创新点在于提出了BOLAZ，一个基于零信任原则且授权引导的BOLA防御框架。它通过深入分析资源ID的数据流和利用静态污点跟踪，能够精确识别授权边界和潜在的攻击点，这与传统基于通用授权模型的防御方法有显著区别。其能够发现新漏洞并经过实证验证，表明了其在实际应用中的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** RESTful API在应用间数据交换中广泛使用，但其敏感资源易受攻击，其中失效对象级授权（BOLA）是OWASP API安全十大漏洞之首，它代表了一种关键的访问控制缺陷，攻击者可以通过操纵API参数获得未经授权的访问。为了解决这一问题，本文提出了一个防御框架。

**Method:** 本文提出了BOLAZ防御框架，该框架基于零信任原则。BOLAZ分析资源ID的数据流，以确定BOLA攻击的注入点并确定相关的授权间隔，从而防止横向权限提升。该方法利用静态污点跟踪将API分为生产者和消费者，根据它们处理资源ID的方式进行分类。通过映射资源ID的传播路径，BOLAZ捕获这些ID的生产和消费上下文，从而精确识别授权边界。与基于常见授权模型的防御方法不同，BOLAZ是第一个根据系统最佳实践授权逻辑调整防御规则的授权引导方法。

**Result:** 通过对10个GitHub项目进行实证研究，验证了BOLAZ。结果表明，BOLAZ在防御从CVE收集的漏洞方面有效，并在实际部署中发现了35个新的BOLA漏洞，证明了其实用性。

**Conclusion:** BOLAZ是一个有效且实用的零信任防御框架，能够识别和防御API中的BOLA漏洞，并能发现新的漏洞。

> **ai_Abstract:** 本文提出了BOLAZ，一个基于零信任原则的防御框架，旨在解决RESTful API中普遍存在的失效对象级授权（BOLA）漏洞。BOLAZ通过分析资源ID的数据流，利用静态污点跟踪识别API的生产者和消费者，并映射资源ID的传播路径，从而精确识别授权边界和BOLA攻击注入点。与传统方法不同，BOLAZ是首个根据系统授权逻辑调整防御规则的授权引导方法。实证研究表明，BOLAZ能有效防御现有BOLA漏洞，并成功发现新的漏洞，证明其在实际部署中的有效性和实用性。

> **摘要翻译:** RESTful API促进应用程序之间的数据交换，但它们也使敏感资源面临潜在的利用。失效对象级授权（BOLA）是OWASP API安全十大漏洞之首，它代表了一种关键的访问控制缺陷，攻击者可以通过操纵API参数获得未经授权的访问。为了解决这个问题，我们提出了BOLAZ，一个基于零信任原则的防御框架。BOLAZ分析资源ID的数据流，确定BOLA攻击的注入点并确定相关的授权间隔，以防止横向权限提升。我们的方法利用静态污点跟踪，根据API处理资源ID的方式将其分为生产者和消费者。通过映射资源ID的传播路径，BOLAZ捕获这些ID的生产和消费上下文，从而精确识别授权边界。与基于常见授权模型的防御方法不同，BOLAZ是第一个根据系统最佳实践授权逻辑调整防御规则的授权引导方法。我们通过对10个GitHub项目进行实证研究验证了BOLAZ。结果表明，BOLAZ在防御从CVE收集的漏洞方面有效，并在实际部署中发现了35个新的BOLA漏洞，证明了其实用性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [393] [Asynchronous Event Error-Minimizing Noise for Safeguarding Event Dataset](https://arxiv.org/abs/2507.05728)
> *异步事件误差最小化噪声用于保护事件数据集*

*Ruofei Wang, Peiqi Duan, Boxin Shi, Renjie Wan* | **Category: cs.CR** | **Updated: 2025-07-15**

**Keywords:** 不可学习示例, 事件数据集, 数据保护, 异步事件流, 误差最小化噪声

**Comment:** Accepted by ICCV2025

> **TL;DR:** 提出了一种新的不可学习事件流生成方法，通过引入异步事件误差最小化噪声来保护事件数据集免受未经授权的使用。

**AI_Comments:** 该论文的创新点在于首次将“不可学习示例”的概念应用于异步事件流，并提出了一种独特的误差最小化噪声和稀疏化策略来适应事件数据的特性。这对于保护日益增长的事件数据隐私和安全具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着越来越多的事件数据集在线发布，数据所有者对事件数据集的未经授权使用感到担忧。现有的不可学习示例方法主要针对图像数据集，但如何为异步事件流创建不可学习的示例以防止事件滥用尚不清楚。

**Method:** 本文提出了一种首次用于防止事件数据集未经授权训练的不可学习事件流生成方法。引入了一种新型的异步事件误差最小化噪声来扰动事件流，从而欺骗未经授权的模型学习嵌入的噪声而不是真实的特征。为了与稀疏事件兼容，提出了一种投影策略来稀疏化噪声，从而生成不可学习事件流（UEvs）。

**Result:** 广泛的实验表明，该方法能有效保护事件数据免受未经授权的利用，同时保留其合法使用的效用。

**Conclusion:** 本文提出的不可学习事件流（UEvs）有助于推进安全可靠的事件数据集共享。

> **ai_Abstract:** 本文针对事件数据集的未经授权使用问题，提出了一种新颖的不可学习事件流生成方法。该方法通过引入异步事件误差最小化噪声来扰动事件流，使得未经授权的模型学习到噪声而非真实特征。为适应稀疏事件，还设计了噪声稀疏化投影策略，从而生成不可学习事件流（UEvs）。实验证明，该方法能有效保护事件数据，同时不影响其合法使用，有望促进安全可靠的事件数据集共享。

> **摘要翻译:** 随着越来越多的事件数据集在线发布，保护事件数据集免受未经授权的使用已成为数据所有者严重关注的问题。不可学习示例被提出用于防止图像数据集的未经授权利用。然而，如何创建不可学习的异步事件流以防止事件滥用尚不清楚。在这项工作中，我们提出了第一个不可学习事件流生成方法，以防止事件数据集的未经授权训练。提出了一种新型的异步事件误差最小化噪声来扰动事件流，欺骗未经授权的模型学习嵌入的噪声而不是真实的特征。为了与稀疏事件兼容，提出了一种投影策略来稀疏化噪声，从而生成我们的不可学习事件流（UEvs）。广泛的实验表明，我们的方法能有效保护事件数据免受未经授权的利用，同时保留其合法使用的效用。我们希望我们的UEvs能为安全和可信赖的事件数据集共享做出贡献。代码可在：https://github.com/rfww/uevs 获取。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [453] [Efficient Private Inference Based on Helper-Assisted Malicious Security Dishonest Majority MPC](https://arxiv.org/abs/2507.09607)
> *基于助手辅助的恶意安全非诚实多数MPC的高效隐私推理*

*Kaiwen Wang, Yuehan Dong, Junchao Fan, Xiaolin Chang* | **Category: cs.CR** | **Updated: 2025-07-15**

**Keywords:** 隐私推理, MPC, 恶意安全, 助手辅助, 深度学习

**Comment:** The manuscript is being withdrawn due to ongoing major revisions and
  significant changes to the methodology and results. A substantially improved
  version may be submitted in the future

> **TL;DR:** 本文提出了一种名为HA-MSDM的框架，用于高效且安全地进行隐私推理。该框架在局域网和广域网中均实现了显著加速，同时保持了高精度。

**AI_Comments:** 该论文的创新点在于提出了助手辅助的恶意安全非诚实多数MPC模型，有效平衡了隐私推理中的安全性和效率。通过设计高效的MPC协议和引入协同优化策略，特别是结合了多项式逼近和改进的批归一化层，克服了现有恶意安全MPC方案的效率瓶颈，使其更适用于实际的MLaaS场景。其显著的加速比和高精度证明了该方法的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于MPC的隐私推理框架，要么威胁模型过于理想化（半诚实或诚实多数），要么在恶意安全非诚实多数模型下效率低下。因此，需要一个能平衡安全性和效率的解决方案。

**Method:** 本文提出了一种使用助手辅助的恶意安全非诚实多数模型（HA-MSDM）的隐私推理框架。该框架包括五个设计的MPC协议，用于实现高效的固定轮乘法、幂运算和多项式运算。同时，采用了一种协同优化策略来平衡推理效率和精度。为了提高效率，对非线性层使用了多项式逼近；为了提高精度，在固定区间内构建了六阶多项式逼近以实现高精度激活函数拟合，并引入了参数调整的批归一化层以限制激活逃逸问题。

**Result:** 在LeNet和AlexNet上的基准测试结果显示，与最先进的框架（IEEE S&P'25）相比，该框架在局域网中实现了2.4-25.7倍的加速，在广域网中实现了1.3-9.5倍的加速，同时保持了高精度，相对误差仅为0.04%-1.08%。

**Conclusion:** HA-MSDM框架有效地平衡了隐私推理中的安全性和效率，通过创新的协议设计和协同优化策略，显著提升了性能，同时保持了高精度。

> **ai_Abstract:** 本文提出了一种名为HA-MSDM的隐私推理框架，旨在解决现有MPC方案在恶意安全非诚实多数模型下效率低下的问题，同时平衡安全性和效率。该框架包含五个专门设计的MPC协议，用于高效的基本运算，并采用协同优化策略，通过多项式逼近非线性层和引入参数调整的批归一化层来提升推理效率和精度。实验结果表明，与现有技术相比，HA-MSDM在局域网和广域网中均实现了显著的加速，并保持了极高的推理精度。

> **摘要翻译:** 基于安全多方计算（MPC）的隐私推理解决了机器学习即服务（MLaaS）中的数据隐私风险。然而，现有的基于MPC的隐私推理框架主要关注半诚实或诚实多数模型，其威胁模型过于理想化，而恶意安全非诚实多数模型则面临效率低下的挑战。为了平衡安全性和效率，我们提出了一种使用助手辅助的恶意安全非诚实多数模型（HA-MSDM）的隐私推理框架。该框架包括我们设计的五个MPC协议和一种协同优化策略。这些协议实现了高效的固定轮乘法、幂运算和多项式运算，为隐私推理提供了基础原语。协同优化策略平衡了推理效率和精度。为了提高效率，我们对非线性层采用了多项式逼近。为了提高精度，我们在固定区间内构建了六阶多项式逼近以实现高精度激活函数拟合，并引入了参数调整的批归一化层以限制激活逃逸问题。在LeNet和AlexNet上的基准测试结果显示，与最先进的框架（IEEE S&P'25）相比，我们的框架在局域网中实现了2.4-25.7倍的加速，在广域网中实现了1.3-9.5倍的加速，同时保持了高精度，相对误差仅为0.04%-1.08%。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [504] [When and Where do Data Poisons Attack Textual Inversion?](https://arxiv.org/abs/2507.10578)
> *数据毒药何时何地攻击文本反演？*

*Jeremy Styborski, Mingzhi Lyu, Jiayou Lu, Nupur Kapur, Adams Kong* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 数据投毒, 文本反演, 扩散模型, 鲁棒性, 安全区训练

**Comment:** Accepted to ICCV

> **TL;DR:** 本文系统分析了数据投毒何时何地攻击扩散模型中的文本反演技术，并提出了名为Safe-Zone Training (SZT)的新型防御机制，该机制通过JPEG压缩、限制高时间步训练和损失掩蔽来显著增强文本反演对投毒攻击的鲁棒性。

**AI_Comments:** 本文对数据投毒攻击在扩散模型文本反演中的作用机制进行了深入的系统分析，创新性地提出了语义敏感图来可视化攻击影响。更重要的是，它不仅揭示了攻击的“何时何地”，还基于这些洞察提出了一个多组件的防御机制SZT。SZT通过针对性地解决攻击的特点，有效地提升了模型的鲁棒性，超越了现有防御，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 投毒攻击对扩散模型（DMs）的鲁棒性构成了重大挑战。本文旨在系统分析投毒攻击何时何地影响文本反演（TI），这是一种广泛使用的扩散模型个性化技术。

**Method:** 研究人员首先引入了语义敏感图（Semantic Sensitivity Maps）来可视化投毒对文本嵌入的影响。其次，他们识别并实验验证了扩散模型在不同时间步（尤其关注低噪声样本）表现出非均匀学习行为，投毒攻击主要在较低时间步注入对抗信号。最后，他们观察到对抗信号会使学习偏离训练数据中相关的概念区域，从而破坏TI过程。基于这些发现，论文提出了Safe-Zone Training (SZT)防御机制，包含三个关键组件：1) JPEG压缩以削弱高频投毒信号；2) 在TI训练期间限制在高时间步以避免低时间步的对抗信号；3) 损失掩蔽以将学习限制在相关区域。

**Result:** 在多种投毒方法上的大量实验表明，SZT显著增强了文本反演对所有投毒攻击的鲁棒性，并超越了先前已发表的防御措施，提高了生成质量。

**Conclusion:** 本文系统分析了投毒攻击对文本反演的影响机制，并提出了一种有效的防御机制SZT，该机制通过多组件协同作用，显著提升了文本反演的抗投毒能力和生成质量。

> **ai_Abstract:** 本文系统研究了数据投毒攻击对扩散模型中的文本反演（TI）技术的影响，揭示了攻击主要在较低时间步注入对抗信号并导致学习偏离相关概念区域。为应对此问题，论文提出了Safe-Zone Training (SZT)防御机制，该机制结合了JPEG压缩、高时间步训练限制和损失掩蔽，实验证明SZT能显著提升TI对各类投毒攻击的鲁棒性并改善生成质量。

> **摘要翻译:** 投毒攻击对扩散模型（DMs）的鲁棒性构成了重大挑战。在本文中，我们系统分析了投毒攻击何时何地影响文本反演（TI），这是一种广泛使用的扩散模型个性化技术。我们首先引入了语义敏感图（Semantic Sensitivity Maps），这是一种可视化投毒对文本嵌入影响的新方法。其次，我们识别并实验验证了扩散模型在不同时间步表现出非均匀学习行为，尤其关注较低噪声样本。投毒攻击继承了这种偏见，主要在较低时间步注入对抗信号。最后，我们观察到对抗信号会使学习偏离训练数据中相关的概念区域，从而破坏TI过程。基于这些见解，我们提出了安全区训练（Safe-Zone Training, SZT），这是一种由3个关键组件组成的新型防御机制：1）JPEG压缩以削弱高频毒性信号；2）在TI训练期间限制在高时间步以避免较低时间步的对抗信号；3）损失掩蔽以将学习限制在相关区域。在多种投毒方法上的大量实验表明，SZT极大地增强了TI对抗所有投毒攻击的鲁棒性，并将生成质量提升到超越了先前已发表的防御措施。代码：www.github.com/JStyborski/Diff_Lab 数据：www.github.com/JStyborski/NC10

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [514] [Breaking a 5-Bit Elliptic Curve Key using a 133-Qubit Quantum Computer](https://arxiv.org/abs/2507.10592)
> *使用133量子比特量子计算机破解5比特椭圆曲线密钥*

*Steve Tippeconnic* | **Category: cs.CR, 68Q12, 81P68, 11T71** | **Updated: 2025-07-11**

**Keywords:** 量子计算, 椭圆曲线加密, Shor算法, 密码分析, 量子攻击

**Comment:** 32 pages, 5 figures, real hardware results from IBM Quantum, all
  code, circuits, and raw data are publicly available for replication

> **TL;DR:** 使用133量子比特量子计算机和类Shor攻击成功破解了一个5比特椭圆曲线密钥。

**AI_Comments:** 这项工作的创新之处在于首次在如此大规模的商用量子计算机上，以如此深的电路深度成功实现了类Shor攻击来破解椭圆曲线密钥，且无需直接编码密钥。其重要性在于验证了量子计算机在破解现代密码学算法方面的潜力，即使是小比特密钥，也为未来大规模量子攻击提供了实验基础。尽管密钥长度仅为5比特，距离实际应用中的加密密钥长度（如256比特）还有很长的路要走，但它清晰地证明了概念的可行性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过实验证明量子计算机（特别是类Shor攻击）破解椭圆曲线加密密钥的能力，从而展示量子技术对当前密码学标准的潜在威胁。

**Method:** 实验在IBM的133量子比特ibm_torino量子计算机上，使用Qiskit Runtime 2.0执行。构建了一个包含10个逻辑量子比特和5个辅助量子比特的15量子比特电路，在32阶椭圆曲线子群上进行干涉，以从公钥关系Q = kP中提取秘密标量k，且未将k直接编码到谕示器中。进行了16,384次测量，并通过经典后处理分析量子干涉模式。量子电路深度超过67,000层。

**Result:** 量子干涉在32x32 QFT结果空间中揭示出对角线状隆起。尽管电路深度超过67,000层，量子电路仍产生了有效的干涉模式。经典后处理在排名前100位的可逆(a, b)结果中成功揭示出秘密标量k = 7。

**Conclusion:** 尽管电路深度极高，该实验仍成功利用量子计算破解了5比特椭圆曲线密钥，证明了类Shor量子攻击在密码分析领域的有效性和潜力，为未来更大规模的量子攻击提供了实验基础。

> **ai_Abstract:** 这项研究利用IBM 133量子比特量子计算机，通过类Shor攻击成功破解了一个5比特椭圆曲线加密密钥。实验构建了一个15量子比特电路，在32阶椭圆曲线子群上进行干涉，即使电路深度超过67,000层，仍能有效提取秘密标量k=7。该工作展示了量子计算对当前加密标准的潜在威胁，并提供了可复现的代码和数据。

> **摘要翻译:** 这项实验使用类Shor量子攻击破解了一个5比特椭圆曲线加密密钥。实验在IBM的133量子比特ibm_torino量子计算机上，通过Qiskit Runtime 2.0执行。一个包含10个逻辑量子比特和5个辅助量子比特的15量子比特电路，在32阶椭圆曲线子群上进行干涉，从公钥关系Q = kP中提取秘密标量k，而无需将k直接编码到谕示器中。通过16,384次测量，量子干涉在32x32 QFT结果空间中揭示出对角线状隆起。尽管电路深度超过67,000层，量子电路仍产生了有效的干涉模式，并且经典后处理在排名前100位的可逆(a, b)结果中揭示出k = 7。所有代码、电路和原始数据均公开可用，以便复制。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [520] [LaSM: Layer-wise Scaling Mechanism for Defending Pop-up Attack on GUI Agents](https://arxiv.org/abs/2507.10610)
> *LaSM：分层缩放机制，用于防御GUI代理上的弹出式攻击*

*Zihe Yan, Zhuosheng Zhang* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-13**

**Keywords:** GUI代理, 弹出式攻击, 注意力机制, 分层缩放, MLLM

**Comment:** 10 pages, 9 figures

> **TL;DR:** 针对多模态大语言模型（MLLM）GUI代理的弹出式攻击，提出LaSM分层缩放机制，通过选择性放大关键层的注意力模块和MLP模块，显著提高防御成功率，无需额外训练。

**AI_Comments:** LaSM的创新之处在于其无需额外训练即可提高防御能力，通过深入理解攻击如何影响模型注意力来设计防御机制，并提出了一种轻量级且有效的分层调制方法。这对于提高MLLM GUI代理的实际应用安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态大语言模型（MLLM）GUI代理容易受到基于弹出窗口的环境注入攻击，恶意视觉元素会分散模型注意力，导致不安全或不正确的行为。现有防御方法要么需要昂贵的再训练，要么在归纳干扰下表现不佳。

**Method:** 系统研究了弹出式攻击如何改变GUI代理的注意力行为，发现正确和不正确输出之间存在分层注意力发散模式。基于此，提出了LaSM（分层缩放机制），它选择性地放大关键层中的注意力模块和MLP模块，从而在无需额外训练的情况下，改善模型显著性与任务相关区域的对齐。

**Result:** 在12种弹出式扰动和4种不同模型骨干上进行了广泛实验，结果显示LaSM持续提高了防御成功率。当与提示级警报结合时，即使在强归纳攻击下，LaSM也能实现超过98%的鲁棒性。

**Conclusion:** 研究发现注意力错位是MLLM代理的核心漏洞，并且可以通过选择性分层调制有效解决。

> **ai_Abstract:** 本文研究了多模态大语言模型（MLLM）GUI代理易受弹出式攻击的问题，发现攻击会导致注意力分层发散。为此，提出了一种名为LaSM的分层缩放机制，通过选择性放大关键层的注意力与MLP模块，在不额外训练的情况下，显著提高了模型对任务相关区域的注意力对齐，从而有效防御了弹出式攻击。实验证明LaSM在多种攻击和模型下均能提高防御成功率，结合提示级警报后鲁棒性可达98%以上。

> **摘要翻译:** 基于多模态大语言模型（MLLM）构建的图形用户界面（GUI）代理最近在基于屏幕的交互任务中展示了强大的决策能力。然而，它们仍然极易受到基于弹出窗口的环境注入攻击，其中恶意视觉元素会分散模型注意力，并导致不安全或不正确的行为。现有防御方法要么需要昂贵的再训练，要么在归纳干扰下表现不佳。在这项工作中，我们系统地研究了此类攻击如何改变GUI代理的注意力行为，并揭示了正确和不正确输出之间存在分层注意力发散模式。基于这一见解，我们提出了LaSM，一种分层缩放机制，它选择性地放大关键层中的注意力模块和和多层感知机（MLP）模块。LaSM在无需额外训练的情况下，改善了模型显著性与任务相关区域的对齐。在12种弹出式扰动和4种不同模型骨干上进行的广泛实验表明，LaSM持续提高了防御成功率。当与提示级警报结合时，即使在强归纳攻击下，LaSM也能实现超过98%的鲁棒性。我们的研究结果表明，注意力错位是MLLM代理中的一个核心漏洞，可以通过选择性分层调制有效解决。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [528] [Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats](https://arxiv.org/abs/2507.10621)
> *博弈论、大型语言模型与智能体AI的融合：重新构想智能威胁时代的网络安全*

*Quanyan Zhu* | **Category: cs.CR, cs.AI, cs.CY, cs.GT** | **Updated: 2025-07-14**

**Keywords:** 博弈论, 大型语言模型, 智能体AI, 网络安全, 智能威胁

**Comment:** 

> **TL;DR:** 本文探讨了博弈论、大型语言模型（LLMs）和智能体AI如何结合，以应对智能威胁时代日益复杂的网络安全挑战，并构建主动、智能的防御系统。

**AI_Comments:** 本文的创新点在于将博弈论的理论深度与大型语言模型和智能体AI的实践应用相结合，为应对智能威胁时代的网络安全挑战提供了全新的视角和解决方案。这种跨学科的融合有望弥合网络安全理论与实际部署之间的鸿沟，为构建更智能、自适应的防御系统奠定基础。

<details>
  <summary>Details</summary>

**Motivation:** 传统的网络安全方法依赖手动响应和脆弱的启发式规则，难以应对日益复杂的智能威胁。为了构建主动和智能的防御系统，需要集成理论框架和软件工具，并弥合理论与实践之间的鸿沟。

**Method:** 本文探讨了博弈论、智能体AI和网络安全的交叉点。首先回顾了关键的博弈论框架（如静态、动态、贝叶斯和信号博弈）和解决方案概念。然后，研究了LLM代理如何增强网络防御，并介绍了将推理嵌入AI代理的LLM驱动博弈。最后，探讨了多代理工作流和协调博弈。

**Result:** 博弈论与LLM和智能体AI的融合有望带来更丰富的理论基础和新颖的解决方案概念，并促进构建安全、智能和自适应的网络系统。LLM代理可以将抽象策略转化为实际决策，同时博弈论可以为这些代理在复杂工作流中的推理和协调提供信息。

**Conclusion:** 博弈论、大型语言模型和智能体AI的融合为构建安全、智能和自适应的网络系统提供了新的路径，能够应对智能威胁时代的挑战。

> **ai_Abstract:** 本文探讨了博弈论与大型语言模型（LLMs）及智能体AI在网络安全领域的交叉融合。针对传统网络安全方法在应对智能威胁方面的局限性，文章提出通过结合博弈论的理论严谨性与LLM和智能体AI的实践能力，构建主动、智能的网络防御系统。论文回顾了核心博弈论框架，并阐述了LLM代理如何增强网络防御、驱动博弈推理以及促进多代理协调，最终旨在实现更安全、智能和自适应的网络系统。

> **摘要翻译:** 保护网络空间不仅需要先进的工具，还需要改变我们对威胁、信任和自主性的推理方式。传统的网络安全方法依赖手动响应和脆弱的启发式规则。为了构建主动和智能的防御系统，我们需要集成的理论框架和软件工具。博弈论为建模对抗行为、设计战略防御和实现自主系统中的信任提供了严格的基础。同时，软件工具处理网络数据、可视化攻击面、验证合规性并提出缓解措施。然而，理论与实际实施之间仍然存在脱节。
大型语言模型（LLMs）和智能体AI的兴起为弥合这一差距提供了新途径。LLM驱动的智能体可以将抽象策略转化为实际决策。反之，博弈论可以为这些智能体在复杂工作流中的推理和协调提供信息。LLMs也挑战了经典的博弈论假设，例如完美理性或静态收益，促使新模型与认知和计算现实对齐。这种共同演进有望带来更丰富的理论基础和新颖的解决方案概念。智能体AI也重塑了软件设计：系统现在必须从一开始就模块化、自适应和信任感知。
本章探讨了博弈论、智能体AI和网络安全的交叉点。我们回顾了关键的博弈论框架（例如，静态、动态、贝叶斯和信号博弈）和解决方案概念。然后，我们研究了LLM智能体如何增强网络防御，并引入了将推理嵌入AI智能体的LLM驱动博弈。最后，我们探讨了多智能体工作流和协调博弈，概述了这种融合如何促进安全、智能和自适应的网络系统。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [533] [Spectral Feature Extraction for Robust Network Intrusion Detection Using MFCCs](https://arxiv.org/abs/2507.10622)
> *使用MFCCs进行频谱特征提取以实现鲁棒的网络入侵检测*

*HyeYoung Lee, Muhammad Nadeem, Pavel Tsoi* | **Category: cs.CR, cond-mat.dis-nn, cs.AI, cs.LG** | **Updated: 2025-07-14**

**Keywords:** IoT安全, 异常检测, MFCCs, ResNet-18, 频谱特征提取

**Comment:** 

> **TL;DR:** 本文提出了一种利用可学习MFCCs和ResNet-18进行IoT网络流量异常检测的新方法，通过将原始信号转换为MFCCs来增强类别可分性，并在多个IoT入侵检测数据集上取得了良好效果。

**AI_Comments:** 该论文的创新点在于将可学习的MFCCs引入网络入侵检测领域，并与ResNet-18深度学习架构相结合。这种方法能够更有效地捕捉网络流量中的时间模式，并通过高维映射增强类别可分性，为IoT网络的安全提供了新的思路。其重要性在于解决了IoT网络日益增长的安全漏洞问题，并提供了一种鲁棒且可扩展的异常检测框架。

<details>
  <summary>Details</summary>

**Motivation:** 物联网（IoT）网络的快速扩张导致安全漏洞激增，因此迫切需要强大的异常检测和分类技术。

**Method:** 本文提出了一种新颖的方法，通过利用梅尔频率倒谱系数（MFCC）和深度学习模型ResNet-18来识别IoT网络流量中的异常。该方法使用可学习MFCCs进行自适应频谱特征表示，比传统固定MFCCs更有效地捕获网络流量中的时间模式。原始信号被转换为MFCCs，将数据映射到更高维空间，增强类别可分性，从而实现更有效的多类别分类。该模型在CICIoT2023、NSL-KDD和IoTID20三个广泛使用的IoT入侵检测数据集上进行了评估。

**Result:** 实验结果强调了将自适应信号处理技术与深度学习架构相结合，在异构IoT网络环境中实现鲁棒和可扩展异常检测的潜力。

**Conclusion:** 通过结合可学习MFCCs的频谱特征表示和ResNet-18的强大特征提取能力，本文提出了一种有效的IoT网络异常检测框架，并在多个数据集上验证了其性能。

> **ai_Abstract:** 本文提出了一种针对IoT网络入侵检测的创新方法，该方法结合了可学习的梅尔频率倒谱系数（MFCCs）和深度学习模型ResNet-18。通过将原始网络流量信号转换为MFCCs，该方法能够将数据映射到更高维空间，从而增强了类别可分性并实现了更有效的多类别分类。该模型在CICIoT2023、NSL-KDD和IoTID20等主流IoT入侵检测数据集上进行了评估，实验结果表明了将自适应信号处理与深度学习相结合在实现鲁棒且可扩展的IoT异常检测方面的巨大潜力。

> **摘要翻译:** 物联网（IoT）网络的快速扩张导致安全漏洞激增，强调了对鲁棒异常检测和分类技术的迫切需求。在这项工作中，我们提出了一种利用梅尔频率倒谱系数（MFCC）和ResNet-18（一种以其在特征提取和基于图像任务中的有效性而闻名的深度学习模型）来识别IoT网络流量中异常的新方法。可学习的MFCCs能够实现自适应频谱特征表示，比传统的固定MFCCs更有效地捕获网络流量中固有的时间模式。我们证明，将原始信号转换为MFCCs将数据映射到更高维空间，增强了类别可分性，并实现了更有效的多类别分类。我们的方法结合了MFCCs的优势和ResNet-18强大的特征提取能力，为异常检测提供了一个强大的框架。所提出的模型在三个广泛使用的IoT入侵检测数据集上进行了评估：CICIoT2023、NSL-KDD和IoTID20。实验结果突出了将自适应信号处理技术与深度学习架构相结合，在异构IoT网络环境中实现鲁棒和可扩展异常检测的潜力。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [541] [Crypto-Assisted Graph Degree Sequence Release under Local Differential Privacy](https://arxiv.org/abs/2507.10627)
> *局部差分隐私下密码辅助图度序列发布*

*Xiaojian Zhang, Junqing Wang, Kerui Chen, Peiyuan Zhao, Huiyuan Bai* | **Category: cs.CR, cs.DB** | **Updated: 2025-07-14**

**Keywords:** 局部差分隐私, 图度序列, 密码辅助, 数据发布, 隐私保护

**Comment:** 

> **TL;DR:** 本文提出了CADR-LDP，一个结合加密技术和差分隐私机制的框架，用于在局部差分隐私下高效准确地发布图度序列，解决了现有方法中阈值选择的权衡和高通信成本问题。

**AI_Comments:** 本文提出了一种新颖的密码辅助方法来优化局部差分隐私下图度序列的发布，其创新点在于引入加密技术来解决传统方法中阈值参数选择的权衡问题和高通信成本。通过Optimal-θ-Selection和LPEA-LOW两种策略，有效提升了精度并降低了开销，对于需要保护图数据隐私的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有解决方案在局部差分隐私下发布图度序列时，主要使用基于边删除的图投影技术，通过阈值参数θ来限制节点度数。然而，这种方法在阈值参数选择上存在根本性权衡：大的θ值会引入大量噪声，小的θ值会导致不必要的边移除。此外，θ选择还会导致过高的通信成本。

**Method:** 本文提出了CADR-LDP框架，结合加密技术和差分隐私机制来发布度序列。首先，使用密码辅助Optimal-θ-Selection方法以低通信成本选择最优参数。然后，使用LPEA-LOW方法在局部投影中通过边添加过程为每个节点添加一些边。LPEA-LOW优先处理低度节点的投影，以保留更多边并减少投影误差。该方法满足ε-节点局部差分隐私。

**Result:** 理论分析表明CADR-LDP满足ε-节点局部差分隐私。在八个图数据集上的实验结果表明，我们的解决方案优于现有方法。

**Conclusion:** CADR-LDP框架通过结合加密技术和优化参数选择以及低度节点优先的边添加策略，成功解决了局部差分隐私下图度序列发布中的精度和通信成本问题，并取得了优于现有方法的性能。

> **ai_Abstract:** 本文提出CADR-LDP框架，旨在解决局部差分隐私下图度序列发布中现有方法的精度和通信成本问题。CADR-LDP结合加密技术和差分隐私机制，首先通过密码辅助Optimal-θ-Selection方法选择最优参数以降低通信成本，然后利用LPEA-LOW方法优先为低度节点添加边以减少投影误差。理论分析和实验结果均表明，CADR-LDP满足ε-节点局部差分隐私，并且在多个数据集上优于现有方法，能够更准确地近似实际度分布。

> **摘要翻译:** 给定一个定义在域G上的图G，我们研究了局部差分隐私机制，以发布一个准确近似实际度分布的G上的度序列。现有解决方案大多使用基于边删除过程的图投影技术，利用阈值参数θ来限制节点度数。然而，这种方法在阈值参数选择上存在根本性权衡。虽然大的θ值在发布的度序列中引入了大量噪声，但小的θ值会导致移除的边多于必要。此外，θ选择导致过高的通信成本。为了弥补现有解决方案的不足，我们提出了CADR-LDP，一个结合加密技术和差分隐私机制的高效框架，用于发布度序列。在CADR-LDP中，我们首先使用密码辅助Optimal-θ-Selection方法以低通信成本选择最优参数。然后，我们使用LPEA-LOW方法在局部投影中通过边添加过程为每个节点添加一些边。LPEA-LOW优先处理低度节点的投影，可以为这些节点保留更多边并减少投影误差。理论分析表明CADR-LDP满足ε-节点局部差分隐私。在八个图数据集上的实验结果表明，我们的解决方案优于现有方法。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [548] [Access Control for Information-Theoretically Secure Key-Document Stores](https://arxiv.org/abs/2507.10730)
> *信息论安全密钥-文档存储的访问控制*

*Yin Li, Sharad Mehrota, Shantanu Sharma, Komal Kumari* | **Category: cs.CR, cs.DB, cs.DC, cs.DS, cs.IR** | **Updated: 2025-07-14**

**Keywords:** 访问控制, 密钥-文档存储, 信息论安全, Shamir秘密共享, 关键字检索

**Comment:** An extended abstract of this version has been accepted in VLDB 2025

> **TL;DR:** 本文提出了一种基于Shamir秘密共享的密钥访问控制技术，用于安全外包的密钥-值存储，支持关键字检索，防止数据泄露，并能检测恶意行为，同时保持高效访问。

**AI_Comments:** 该论文的创新点在于将Shamir秘密共享应用于密钥-文档存储的访问控制，实现了信息论上的安全性。其重要性体现在解决了外包存储中数据隐私和完整性面临的挑战，并提供了实际可行的性能表现。然而，抽象中未详细说明Shamir秘密共享的具体实现细节以及其在实际大规模部署中的潜在复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在为安全外包的密钥-值存储（其中值对应于文档）提供一种新颖的密钥访问控制技术，以解决数据、用户访问权限或查询结果大小泄露的问题，并防止恶意客户端和服务器的行为。

**Method:** 该方法采用了Shamir的秘密共享方案，提供无条件或信息论上的安全性。它支持基于关键字的文档检索，并允许服务器检测恶意客户端的未授权访问，以及防止恶意服务器在不被检测的情况下篡改数据。

**Result:** 该方法能够在500,000个文件中的5,000个关键字上实现231.5毫秒的高效访问。它成功防止了数据、用户访问权限或查询结果大小的泄露，并能检测恶意客户端和服务器的行为。

**Conclusion:** 本文提出的基于Shamir秘密共享的密钥访问控制技术，为安全外包的密钥-值存储提供了一种高效且信息论上安全的解决方案，有效解决了数据泄露和恶意行为检测的问题。

> **ai_Abstract:** 本文提出了一种基于Shamir秘密共享的密钥访问控制技术，用于信息论安全的密钥-文档存储。该技术支持关键字检索，能有效防止数据、访问权限和查询大小的泄露。此外，它还能检测并阻止恶意客户端和服务器的行为，同时保持高效的访问性能。

> **摘要翻译:** 本文提出了一种新颖的基于密钥的访问控制技术，用于安全外包的密钥-值存储，其中值对应于使用密钥索引和访问的文档。所提出的方法采用Shamir的秘密共享，提供无条件或信息论上的安全性。它支持基于关键字的文档检索，同时防止数据、用户访问权限或大小（即满足查询的输出量）的泄露。所提出的方法允许服务器检测（并中止）恶意客户端获得未经授权的数据访问，并防止恶意服务器在未被检测的情况下更改数据，同时确保高效访问——在500,000个文件中的5,000个关键字上需要231.5毫秒。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [554] [3S-Attack: Spatial, Spectral and Semantic Invisible Backdoor Attack Against DNN Models](https://arxiv.org/abs/2507.10733)
> *3S-Attack: 空间、频谱和语义隐形后门攻击对抗DNN模型*

*Jianyao Yin, Luca Arnaboldi, Honglong Chen, Pascal Berrang* | **Category: cs.CR** | **Updated: 2025-07-14**

**Keywords:** 后门攻击, 深度神经网络模型, 空间域, 频谱域, 语义域

**Comment:** 14 pages, 10 figures

> **TL;DR:** 本文提出了一种名为3S-attack的新型后门攻击，通过利用良性样本的语义特征作为触发器并将其嵌入频谱域，在空间、频谱和语义域实现隐形，使其难以被检测。

**AI_Comments:** 这篇论文提出了一种创新的后门攻击方法，它结合了空间、频谱和语义域的隐蔽性，这相比以往只关注一个或两个域的方法是一个显著的进步。它能够创建高度难以察觉的触发器，对现有的防御机制构成了严峻挑战，并揭示了当前AI安全范式中的一个关键漏洞。

<details>
  <summary>Details</summary>

**Motivation:** 现有后门攻击研究虽然探索了在空间、频谱和语义域设计触发器以实现隐蔽性，但很少有方法能同时结合这三个域。本研究旨在提出一种在所有三个域都具有隐蔽性的新型攻击，以凸显加强AI安全防御的必要性。

**Method:** 本文提出了一种名为3S-attack的新型后门攻击。其核心思想是利用梯度加权类激活映射（Grad-CAM）和一个预备模型提取良性样本的语义特征作为触发器。然后，将该触发器嵌入到频谱域中，并在将样本转换回空间域后施加像素级限制。这一过程旨在最小化中毒样本与良性样本之间的距离。

**Result:** 在各种数据集上进行的广泛实验以及理论分析都证明了3S-attack的隐蔽性。

**Conclusion:** 3S-attack具有高度隐蔽性，这突显了为确保人工智能安全而加强防御的必要性。

> **ai_Abstract:** 本文介绍了一种名为3S-attack的新型后门攻击，该攻击在空间、频谱和语义域均实现了隐蔽性。它利用Grad-CAM提取的语义特征作为触发器，将其嵌入频谱域，并施加空间限制以最小化可检测性。实验证实了其隐蔽性，强调了加强AI安全防御的必要性。

> **摘要翻译:** 后门攻击涉及毒化训练数据或直接修改模型以植入隐藏行为，当特定触发器存在时，导致模型错误分类输入。在推理过程中，模型在良性样本上保持高准确性，但将中毒样本错误分类到攻击者指定的目标类别。现有关于后门攻击的研究已经探索了在空间、频谱（频率）和语义（特征）域开发触发器，旨在使其具有隐蔽性。虽然一些方法已经考虑设计在空间和频谱域都不可察觉的触发器，但很少有方法结合了语义域。在本文中，我们提出了一种名为3S-attack的新型后门攻击，它在空间、频谱和语义域都具有隐蔽性。其核心思想是利用良性样本的语义特征作为触发器，使用梯度加权类激活映射（Grad-CAM）和一个预备模型进行提取。然后，将触发器嵌入到频谱域中，在将样本转换回空间域后施加像素级限制。这一过程最大限度地减小了中毒样本和良性样本之间的距离，使得现有防御和人工检查更难检测到攻击。在各种数据集上进行的广泛实验，以及理论分析，都证明了3S-attack的隐蔽性，并强调了需要更强的防御来确保人工智能安全。我们的代码可在以下网址获取：https://anonymous.4open.science/r/anon-project-3776/

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [562] [Contrastive-KAN: A Semi-Supervised Intrusion Detection Framework for Cybersecurity with scarce Labeled Data](https://arxiv.org/abs/2507.10808)
> *Contrastive-KAN：一种用于网络安全中标记数据稀缺的半监督入侵检测框架*

*Mohammad Alikhani, Reza Kazemi* | **Category: cs.CR, cs.SY, eess.SP, eess.SY** | **Updated: 2025-07-14**

**Keywords:** 入侵检测, 半监督学习, 对比学习, KAN, 网络安全

**Comment:** 

> **TL;DR:** 提出了一种基于KAN的半监督对比学习框架，用于在标记数据稀缺的情况下进行实时入侵检测，在基准数据集上表现优于现有方法。

**AI_Comments:** 该论文的创新点在于将Kolmogorov-Arnold网络（KAN）引入到半监督对比学习框架中，以解决网络安全领域中标记数据稀缺和快速检测的痛点。KAN的可解释性（通过可学习的激活函数和规则提取潜力）是其相比传统神经网络（如MLP）的一个显著优势，这对于安全关键系统至关重要。该方法在有限标记数据下表现出的优越性能，证明了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在第四次工业革命时代，网络安全和入侵检测系统对于物联网（IoT）和工业物联网（IIoT）环境的安全可靠运行至关重要。该领域的一个主要挑战是标记网络攻击数据的稀缺性，因为大多数工业系统在正常条件下运行。这种数据不平衡以及高昂的标注成本阻碍了机器学习模型的有效训练。此外，快速检测攻击至关重要，尤其是在关键基础设施中，以防止大规模中断。

**Method:** 我们提出了一种基于Kolmogorov-Arnold网络（KAN）的半监督对比学习框架，用于实时入侵检测系统。该方法利用大量未标记数据来有效区分正常和攻击行为。

**Result:** 我们的方法在三个基准数据集（UNSW-NB15、BoT-IoT和Gas Pipeline）上进行了验证，分别仅使用了2.20%、1.28%和8%的标记样本来模拟真实世界条件。实验结果表明，我们的方法优于现有基于对比学习的方法。我们将KAN与传统多层感知器（MLP）进行了比较，证明了KAN在有限监督下的检测精度和鲁棒性方面均表现优越。

**Conclusion:** KAN能够建模复杂关系，其可学习的激活函数提供了可解释性和规则提取的潜力。该方法支持多分类，并在可靠性至关重要的安全关键环境中证明了其有效性。

> **ai_Abstract:** 本研究提出了一种名为Contrastive-KAN的半监督入侵检测框架，旨在解决网络安全领域中标记网络攻击数据稀缺的挑战。该框架结合了Kolmogorov-Arnold网络（KAN）和对比学习，能够利用大量未标记数据有效地区分正常和异常行为。在UNSW-NB15、BoT-IoT和Gas Pipeline等基准数据集上的实验结果表明，即使仅使用极少量标记数据，Contrastive-KAN也优于现有对比学习方法，并在检测精度和鲁棒性方面超越了传统MLP，同时提供了可解释性和多分类能力，适用于安全关键环境。

> **摘要翻译:** 在第四次工业革命时代，网络安全和入侵检测系统对于物联网（IoT）和工业物联网（IIoT）环境的安全可靠运行至关重要。该领域的一个主要挑战是标记网络攻击数据的稀缺性，因为大多数工业系统在正常条件下运行。这种数据不平衡，加上高昂的标注成本，阻碍了机器学习模型的有效训练。此外，快速检测攻击至关重要，尤其是在关键基础设施中，以防止大规模中断。为了应对这些挑战，我们提出了一种基于Kolmogorov-Arnold网络（KAN）的半监督对比学习框架的实时入侵检测系统。我们的方法利用大量未标记数据有效地区分正常和攻击行为。我们在三个基准数据集：UNSW-NB15、BoT-IoT和Gas Pipeline上验证了我们的方法，分别仅使用2.20%、1.28%和8%的标记样本，以模拟真实世界条件。实验结果表明，我们的方法优于现有基于对比学习的方法。我们进一步将KAN与传统多层感知器（MLP）进行了比较，证明了KAN在有限监督下的检测精度和鲁棒性方面均表现优越。KAN建模复杂关系的能力及其可学习的激活函数也得到了探索和可视化，提供了可解释性和规则提取的潜力。该方法支持多分类，并在可靠性至关重要的安全关键环境中证明了其有效性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [569] [Reporte de vulnerabilidades en IIoT. Proyecto DEFENDER](https://arxiv.org/abs/2507.10819)
> *IIoT 中的漏洞报告。DEFENDER 项目*

*Pedro Almansa Jiménez, Lorenzo Fernández Maimó, Ángel Luis Peráles Gómez* | **Category: cs.CR** | **Updated: 2025-07-14**

**Keywords:** IIoT, 漏洞, 网络安全, 工业系统, 机器学习

**Comment:** Language: Spanish

> **TL;DR:** 本技术报告对工业物联网 (IIoT) 设备进行了全面研究，分析了其漏洞、攻击场景和潜在影响，并提出了安全对策，强调了机器学习在网络安全中的作用。

**AI_Comments:** 该报告通过对IIoT设备漏洞的全面分析，为理解工业系统面临的网络安全挑战提供了宝贵视角。其创新点在于结合了实际案例分析和对机器学习在防御中的潜力的强调。报告的局限性可能在于其主要是一个技术报告而非研究论文，可能缺乏新的理论贡献，但对于行业实践者而言具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本报告的主要目标是对工业物联网 (IIoT) 环境中运行的设备进行全面研究，描述定义该类别的场景，并分析损害其安全性的漏洞。

**Method:** 报告通过识别和检查IIoT设备的主要类别、详细说明其特征和功能；探索设备运行的具体环境；分析影响IIoT设备的漏洞（包括其向量、目标、影响和后果）；描述典型的攻击阶段和实际事件；最后，汇编了最新和有效的安全对策，并特别强调了机器学习的作用。

**Result:** 报告提供了对IIoT设备、其交互方式和工业系统需求的更好理解；揭示了工业场景的独特特征和设备运行条件；详细分析了漏洞的向量、目标、影响和后果；描述了攻击阶段和实际事件案例（根据分类进行）；并汇编了针对安全挑战的最新安全对策。

**Conclusion:** 本报告最终提出了针对工业系统面临的安全挑战的一些最新和有效的安全对策，并特别强调了机器学习在增强工业网络安全中的重要性。

> **ai_Abstract:** 本技术报告《IIoT中的漏洞报告。DEFENDER项目》旨在全面研究工业物联网（IIoT）设备，分析其安全漏洞。报告详细识别了IIoT设备的类别、功能和操作环境，深入探讨了影响这些设备的漏洞类型、攻击向量和潜在影响。通过描述攻击阶段和真实事件案例，并依据分类法进行分析，报告评估了漏洞对工业环境的威胁。最后，报告汇编了最新的安全对策，并特别强调了机器学习在提升工业网络安全中的关键作用。

> **摘要翻译:** 本技术报告的主要目的是对工业物联网（IIoT）环境中运行的设备进行全面研究，描述定义该类别的场景并分析损害其安全性的漏洞。为此，本报告旨在识别和检查IIoT设备的主要类别，详细说明它们在工业系统中的特性、功能和作用。这项分析有助于更好地理解这些设备如何交互并满足关键工业环境的要求。报告还探讨了这些设备运行的具体环境，强调了工业场景的独特特征以及设备运行的条件。此外，它还分析了影响IIoT设备的漏洞，概述了它们的向量、目标、影响和后果。报告随后描述了攻击的典型阶段，以及一些真实的、有记录的事件。这些案例根据第3节中提出的分类法进行分类，提供了对潜在安全威胁的全面视图，并评估了这些漏洞可能对工业环境造成的影响。最后，报告汇编了一些最新且有效的安全对策，作为工业系统面临的安全挑战的潜在解决方案。报告特别强调了机器学习在这些方法开发中的作用，强调了其在增强工业网络安全方面的重要性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [576] [REAL-IoT: Characterizing GNN Intrusion Detection Robustness under Practical Adversarial Attack](https://arxiv.org/abs/2507.10836)
> *REAL-IoT：表征GNN入侵检测在实际对抗攻击下的鲁棒性*

*Zhonghao Zhan, Huichi Zhou, Hamed Haddadi* | **Category: cs.CR** | **Updated: 2025-07-14**

**Keywords:** GNN, 入侵检测, 对抗攻击, 物联网, 鲁棒性, LLM

**Comment:** 

> **TL;DR:** 现有基于GNN的网络入侵检测系统（NIDS）评估不切实际，高估了其韧性。REAL-IoT提出了一个综合框架，利用真实世界数据和大型语言模型（LLM）来评估鲁棒性，揭示了GNN性能的下降，并展示了LLM在缓解攻击方面的潜力。

**AI_Comments:** 本文解决了GNN基NIDS评估中的一个关键空白，专注于实际对抗攻击和分布漂移。引入真实世界的物联网测试平台数据集具有高度价值。对使用大型语言模型（LLM）缓解对抗性样本的创新探索是一个有趣且可能产生影响的方向，突出了网络安全中的跨学科方法。

<details>
  <summary>Details</summary>

**Motivation:** 当前基于图神经网络（GNN）的网络入侵检测系统（NIDS）评估存在局限性：1）它们通常在单一数据集上进行评估，限制了在分布漂移下的泛化能力；2）对抗鲁棒性评估通常使用缺乏真实感的合成扰动。这些问题导致对基于GNN的NIDS韧性产生高估。

**Method:** 本文提出了REAL-IoT，一个用于评估物联网环境中基于GNN的NIDS鲁棒性的综合框架。该框架包含：1）一种从规范数据集中创建统一数据集的方法，以评估漂移下的泛化能力；2）一个从物理物联网测试平台收集的新型入侵数据集，捕获真实世界中的网络流量和攻击场景；3）探索使用大型语言模型（LLM）来分析网络数据并通过过滤可疑流量来减轻对抗性样本的影响。

**Result:** 使用REAL-IoT进行的评估显示，与标准基准测试结果相比，GNN模型的性能有所下降，量化了它们对漂移和实际攻击的敏感性。研究还证明了基于LLM的过滤在增强鲁棒性方面的潜力。

**Conclusion:** 研究结果强调了为开发弹性物联网入侵检测系统，进行现实威胁建模和严格测量实践的必要性。

> **ai_Abstract:** REAL-IoT是一个综合框架，旨在解决现有GNN基NIDS在真实环境下的鲁棒性评估不足问题。该框架通过整合统一数据集、收集真实的物联网入侵数据，并探索利用LLM过滤对抗性流量，揭示了GNN模型在实际漂移和攻击下的性能下降，并验证了LLM在提升鲁棒性方面的潜力，强调了在物联网入侵检测中进行现实威胁建模和严格测量的重要性。

> **摘要翻译:** 基于图神经网络（GNN）的网络入侵检测系统（NIDS）通常在单一数据集上进行评估，这限制了它们在分布漂移下的泛化能力。此外，它们的对抗鲁棒性通常使用缺乏真实感的合成扰动来评估。这种测量差距导致对基于GNN的NIDS韧性的高估。为了解决这些限制，我们提出了REAL-IoT，一个用于评估物联网环境中基于GNN的NIDS鲁棒性的综合框架。我们的框架提出了一种方法，该方法从规范数据集中创建统一数据集，以评估漂移下的泛化能力。此外，它还包含一个从物理物联网测试平台收集的新型入侵数据集，该数据集捕获了真实世界设置下的网络流量和攻击场景。此外，利用REAL-IoT，我们探索了使用大型语言模型（LLM）来分析网络数据并通过过滤可疑流量来减轻对抗性样本的影响。我们使用REAL-IoT进行的评估显示，与标准基准测试结果相比，GNN模型的性能有所下降，量化了它们对漂移和实际攻击的敏感性。我们还展示了基于LLM的过滤在增强鲁棒性方面的潜力。这些发现强调了为开发弹性物联网入侵检测系统而进行现实威胁建模和严格测量实践的必要性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [583] [BandFuzz: An ML-powered Collaborative Fuzzing Framework](https://arxiv.org/abs/2507.10845)
> *BandFuzz：一个机器学习驱动的协作式模糊测试框架*

*Wenxuan Shi, Hongwei Li, Jiahao Yu, Xinqian Sun, Wenbo Guo, Xinyu Xing* | **Category: cs.CR, cs.SE** | **Updated: 2025-07-14**

**Keywords:** 协作式模糊测试, 模糊测试框架, 机器学习, 资源分配

**Comment:** 

> **TL;DR:** 协作式模糊测试很有前景，但存在资源分配问题。本论文提出了BandFuzz，一个机器学习驱动的框架来解决这些问题。

**AI_Comments:** 该论文旨在解决协作式模糊测试中的关键挑战，即资源管理和效率问题，这对于其广泛应用至关重要。标题中“机器学习驱动”的特点暗示了其在优化资源分配方面可能具有创新性。

<details>
  <summary>Details</summary>

**Motivation:** 现有协作式模糊测试框架的有效性受到主要挑战的限制，例如与独立模糊测试器相比需要额外的计算资源以及各种模糊测试器之间资源分配效率低下。

**Method:** 本论文提出了一个名为BandFuzz的机器学习驱动的协作式模糊测试框架。该框架旨在动态选择适当的模糊测试器组合。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 协作式模糊测试通过结合多个模糊测试器来放松对目标程序的假设，从而在各种程序中提供持续且稳健的性能，被认为是通用模糊测试解决方案的一个有前景的方向。然而，现有协作式模糊测试框架的有效性受到计算资源需求高和资源分配效率低下的限制。本论文提出了BandFuzz，一个机器学习驱动的协作式模糊测试框架，旨在解决这些挑战。

> **摘要翻译:** 协作式模糊测试最近作为一种结合多个独立模糊测试器并动态选择适合不同程序的适当组合的技术而出现。与依赖特定假设来保持其有效性的独立模糊测试器不同，协作式模糊测试放松了对目标程序的假设，在各种程序中提供持续且稳健的性能。理想情况下，协作式模糊测试应该是通用的模糊测试解决方案更具前景的方向，因为它减轻了手动挑选独立模糊测试器的需求。然而，现有协作式模糊测试框架的有效性受到主要挑战的限制，例如与独立模糊测试器相比需要额外的计算资源以及各种模糊测试器之间资源分配效率低下。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [590] [PhreshPhish: A Real-World, High-Quality, Large-Scale Phishing Website Dataset and Benchmark](https://arxiv.org/abs/2507.10854)
> *PhreshPhish：一个真实世界、高质量、大规模的钓鱼网站数据集和基准*

*Thomas Dalton, Hemanth Gowda, Girish Rao, Sachin Pargi, Alireza Hadj Khodabakhshi, Joseph Rombs, Stephan Jou, Manish Marwah* | **Category: cs.CR, cs.AI, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 钓鱼检测, 数据集, 基准, 机器学习, 网络安全

**Comment:** 

> **TL;DR:** 引入了PhreshPhish，一个大规模、高质量的钓鱼网站数据集和基准，旨在解决现有数据集的局限性，并促进更真实的钓鱼检测模型评估。

**AI_Comments:** 这篇论文通过提供一个急需的高质量、大规模数据集和真实的基准，解决了钓鱼检测研究中的一个关键空白。这项创新对于开发在现实世界场景中表现良好的鲁棒机器学习模型至关重要，克服了先前数据集导致过于乐观结果的局限性。数据集的公开可用性是对社区的重大贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有的钓鱼数据集质量差、存在数据泄露且基准率不真实，阻碍了机器学习在实时钓鱼攻击检测方面的进展，导致模型性能过于乐观。

**Method:** 引入了PhreshPhish，一个大规模、高质量的钓鱼网站数据集，解决了现有数据集的局限性。提出了一个全面的基准数据集套件，通过最小化泄露、增加任务难度、增强数据集多样性和调整基准率来设计，以实现真实的模型评估。在基准集上训练并评估了多种解决方案，以提供基线性能。

**Result:** PhreshPhish比现有公共数据集规模更大，质量显著更高（无效或错误标记数据点的估计率更低）。所提出的基准数据集专门为真实的模型评估而设计。提供了基准集上的基线性能。

**Conclusion:** PhreshPhish数据集和基准的可用性将实现真实、标准化的模型比较，并促进钓鱼检测的进一步发展。

> **ai_Abstract:** 本文介绍了PhreshPhish，一个大规模、高质量的钓鱼网站数据集，旨在解决现有数据集存在的质量差、数据泄露和不真实基准率等问题。同时，论文还提出了一套全面的基准数据集，专为实现更真实的模型评估而设计，通过最小化数据泄露、增加任务难度和增强多样性来实现。作者提供了在这些基准集上的基线性能，旨在促进钓鱼检测领域中模型比较的标准化和进一步研究进展。

> **摘要翻译:** 钓鱼仍然是一种普遍存在的日益增长的威胁，造成严重的经济和声誉损害。尽管机器学习在实时检测钓鱼攻击方面已经有效，但由于缺乏大型、高质量的数据集和基准，进展受到阻碍。除了数据收集挑战导致的质量不佳外，现有数据集还存在数据泄露和不切实际的基准率问题，导致性能结果过于乐观。在本文中，我们介绍了PhreshPhish，一个大规模、高质量的钓鱼网站数据集，解决了这些局限性。与现有公共数据集相比，PhreshPhish规模更大，并提供了显著更高的质量，这通过无效或错误标记数据点的估计率来衡量。此外，我们提出了一套全面的基准数据集，专门为真实的模型评估而设计，通过最小化泄露、增加任务难度、增强数据集多样性以及调整更可能在现实世界中出现的基准率。我们训练并评估了多种解决方案方法，以提供基准集上的基线性能。我们相信这个数据集和基准的可用性将实现真实、标准化的模型比较，并促进钓鱼检测的进一步发展。数据集和基准可在Hugging Face上获取（https://huggingface.co/datasets/phreshphish/phreshphish）。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [597] [From Alerts to Intelligence: A Novel LLM-Aided Framework for Host-based Intrusion Detection](https://arxiv.org/abs/2507.10873)
> *从警报到情报：一种新颖的LLM辅助的主机入侵检测框架*

*Danyu Sun, Jinghuai Zhang, Jiacen Xu, Yu Zheng, Yuan Tian, Zhou Li* | **Category: cs.CR** | **Updated: 2025-07-15**

**Keywords:** LLM, 主机入侵检测, SHIELD, 威胁检测, 网络安全

**Comment:** 

> **TL;DR:** 本文提出了SHIELD，一个利用大型语言模型（LLM）改进主机入侵检测的框架，通过整合多种技术来提高检测的准确性和可解释性。

**AI_Comments:** 该论文的创新之处在于提出并实现了一个定制化的LLM管道SHIELD，而非简单地应用LLM，从而有效解决了LLM在HIDS应用中面临的token限制和背景噪音等实际问题。通过集成MAE和DDA等技术，SHIELD不仅提高了检测精度，还增强了结果的可解释性，这对于安全分析师至关重要。其重要性在于为利用LLM提升网络安全防御能力，特别是主机入侵检测，提供了一个实用且高性能的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 主机入侵检测系统（HIDS）在保护组织免受高级持续性威胁（APT）方面至关重要，但它经常面临高误报率、跨环境结果不一致以及检测结果对人类不友好等问题。尽管大型语言模型（LLM）在攻击技术知识和通过语义分析检测异常方面具有巨大潜力，但初步分析表明，简单地提示LLM来构建HIDS不太可能成功，因此需要一个定制化的LLM管道。

**Method:** 本文开发了一个名为SHIELD的定制化LLM管道，用于主机入侵检测。SHIELD通过整合多种技术来解决LLM的token限制和背景噪音等挑战，这些技术包括用于攻击窗口检测的事件级Masked Autoencoder (MAE)、攻击证据识别和扩展、用于分析正常活动的确定性数据增强（DDA），以及引导LLM进行精确和可解释的攻击调查的多用途提示。

**Result:** 在DARPA-E3、NodLink-simulated-data和ATLASv2三个日志数据集上进行的大量实验表明，与5个代表性的HIDS相比，SHIELD持续取得了出色的性能。

**Conclusion:** 这些发现突出了大型语言模型作为入侵检测强大工具的潜力，并为该领域的未来研究铺平了道路。

> **ai_Abstract:** 本文提出了一种名为SHIELD的新型LLM辅助框架，用于主机入侵检测，旨在解决现有HIDS面临的高误报率和解释性差等问题。该框架通过整合事件级Masked Autoencoder (MAE)、确定性数据增强（DDA）和多用途提示等技术，有效地利用大型语言模型（LLM）进行攻击窗口检测、证据识别和可解释的攻击调查。实验结果表明，SHIELD在多个日志数据集上均优于现有的HIDS，突显了LLM在入侵检测领域的巨大潜力。

> **摘要翻译:** 主机入侵检测系统（HIDS）是保护组织免受高级威胁（如高级持续性威胁（APT））的关键防御组件。通过数据溯源等方法分析细粒度日志，HIDS已成功捕获复杂的攻击痕迹。尽管研究界和工业界取得了进展，但HIDS在部署环境中仍经常受到操作员的抵制，原因包括高误报率、跨环境结果不一致以及对人类不友好的检测结果。鉴于大型语言模型（LLMs）对攻击技术拥有广泛知识以及通过语义分析检测异常的能力（近期研究已证实），它们在推进HIDS现状方面具有巨大潜力。然而，我们的初步分析表明，通过简单地提示LLM来构建HIDS不太可能成功。在这项工作中，我们探索了为HIDS构建定制化LLM管道的方向，并开发了一个名为SHIELD的系统。SHIELD通过整合多种技术来解决LLM的token限制、背景噪音混淆等挑战，例如用于攻击窗口检测的事件级Masked Autoencoder (MAE)、攻击证据识别和扩展、用于分析正常活动的确定性数据增强（DDA），以及引导LLM进行精确和可解释的攻击调查的多用途提示。在三个日志数据集（DARPA-E3、NodLink-simulated-data和ATLASv2）上进行的大量实验表明，与5个代表性HIDS相比，SHIELD持续取得了出色的性能。这些发现突出了LLM作为入侵检测强大工具的潜力，并为该领域的未来研究铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [611] [MalCodeAI: Autonomous Vulnerability Detection and Remediation via Language Agnostic Code Reasoning](https://arxiv.org/abs/2507.10898)
> *MalCodeAI：通过语言无关代码推理实现自主漏洞检测与修复*

*Jugal Gajjar, Kamalasankari Subramaniakuppusamy, Noha El Kachach* | **Category: cs.CR, cs.AI, cs.SE** | **Updated: 2025-07-15**

**Keywords:** 漏洞检测, 代码修复, 语言无关, AI管道, 代码推理

**Comment:** 6 pages, 4 figures, accepted for publication in IEEE 26th
  International Conference on Information Reuse and Integration (IRI 2025)

> **TL;DR:** MalCodeAI是一个语言无关的多阶段AI管道，用于自主代码安全分析和修复，能有效检测漏洞并提供修复建议，支持零日漏洞检测，并在开发者评估中获得高分。

**AI_Comments:** MalCodeAI的创新之处在于其语言无关的多阶段AI管道设计，结合了代码分解和语义推理，并利用大型语言模型进行微调。其能够支持14种编程语言并实现零日漏洞检测，显示了强大的泛化能力。此外，开发者的高度评价表明其在实际开发工作流中的高实用性和可解释性，为软件安全提供了智能且以用户为中心的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 网络威胁日益复杂，传统漏洞检测工具存在局限性，因此需要新颖的方法来保护软件系统。

**Method:** 本文介绍了MalCodeAI，一个语言无关的多阶段AI管道，用于自主代码安全分析和修复。MalCodeAI结合了代码分解和语义推理，使用经过LoRA优化的Qwen2.5-Coder-3B-Instruct模型，并在MLX框架内实现。

**Result:** 在第一阶段，模型在功能分解和代码段摘要方面取得了0.397的验证损失。在第二阶段，针对漏洞检测和修复，模型取得了0.199的最佳验证损失，有效识别安全缺陷并提出可操作的修复建议。MalCodeAI支持红帽式漏洞追踪、基于CVSS的风险评分和零样本泛化能力。在对15名开发者的定性评估中，系统在实用性（平均8.06/10）、可解释性（平均7.40/10）和输出可读性（平均7.53/10）方面获得高分。

**Conclusion:** 这项工作标志着向智能化、可解释、以开发者为中心的软件安全解决方案迈出了重要一步。

> **ai_Abstract:** MalCodeAI是一个创新的语言无关多阶段AI管道，旨在自主进行代码安全分析和修复。它利用经过LoRA优化的Qwen2.5-Coder-3B-Instruct模型进行代码分解和语义推理。该系统在功能分解和漏洞检测方面取得了显著的低验证损失，并成功识别安全缺陷和提供修复建议。MalCodeAI还支持零日漏洞检测和CVSS风险评分，并通过开发者评估证实了其在实际应用中的高实用性、可解释性和输出可读性，代表了软件安全领域的重要进展。

> **摘要翻译:** 网络威胁日益复杂，传统漏洞检测工具的局限性使得软件系统安全需要新颖的方法。我们引入了MalCodeAI，一个语言无关、多阶段的AI管道，用于自主代码安全分析和修复。MalCodeAI结合了代码分解和语义推理，使用在MLX框架内通过低秩适应（LoRA）优化的Qwen2.5-Coder-3B-Instruct模型，并在14种编程语言中提供可扩展、准确的结果。在第一阶段，模型在200次迭代、6个可训练层和2 x 10^(-5)学习率后，在代码段的功能分解和摘要方面实现了低至0.397的验证损失。在第二阶段，针对漏洞检测和修复，模型使用相同数量的迭代和可训练层，但学习率增加到4 x 10^(-5)，取得了0.199的最佳验证损失，有效地识别了安全缺陷并提出了可操作的修复建议。MalCodeAI支持红帽式漏洞追踪、基于CVSS的风险评分和零样本泛化能力，以检测复杂的零日漏洞。在涉及15名开发者的定性评估中，系统在实用性（平均8.06/10）、可解释性（平均7.40/10）和输出可读性（平均7.53/10）方面获得了高分，证实了其在实际开发工作流中的实用价值。这项工作标志着向智能化、可解释、以开发者为中心的软件安全解决方案迈出了重要一步。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [625] [DVFS: A Dynamic Verifiable Fuzzy Search Service for Encrypted Cloud Data](https://arxiv.org/abs/2507.10927)
> *DVFS：一种加密云数据的动态可验证模糊搜索服务*

*Jie Zhang, Xiaohong Li, Man Zheng, Zhe Hou, Guangdong Bai, Ruitao Feng* | **Category: cs.CR** | **Updated: 2025-07-15**

**Keywords:** 模糊搜索, 加密云数据, 安全性, 动态更新, 区块链

**Comment:** 

> **TL;DR:** 提出DVFS，一个动态可验证的加密云数据模糊搜索服务，通过结合LSH、虚拟二叉树、双存储库版本控制和区块链验证，解决了现有方案在安全性和效率上的权衡问题，并支持动态更新。

**AI_Comments:** 本文的创新点在于其综合性的方法，通过集成多种技术（局部敏感哈希、虚拟二叉树、双存储库、区块链）来同时解决加密云数据模糊搜索中的安全、效率和动态更新难题。特别是将区块链引入验证过程，增强了系统的可信赖性。其提出的$O(\\log n)$搜索和验证复杂度对于大规模数据处理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的加密云数据模糊多关键词搜索方案在安全性和效率之间存在矛盾：线性搜索机制提供自适应安全性但开销大，而基于树的索引虽然提高了性能，却以分支泄露漏洞为代价。

**Method:** 提出DVFS，包含三项核心创新：1) 结合局部敏感哈希和虚拟二叉树的自适应安全模糊搜索方法，消除分支泄露并将搜索复杂度降至$O(\\log n)$；2) 支持前向隐私动态更新的双存储库版本控制机制；3) 基于区块链的验证系统，通过智能合约确保正确性和完整性，验证复杂度为$O(\\log n)$。

**Result:** 实现了子线性$O(\\log n)$的搜索复杂度，消除了分支泄露漏洞，支持带前向隐私的动态更新，并实现了$O(\\log n)$的验证复杂度。

**Conclusion:** DVFS通过同时解决安全-性能悖论并实现可信赖的动态操作，推进了安全加密检索技术。

> **ai_Abstract:** 本文提出了DVFS，一个针对加密云数据的动态可验证模糊搜索服务，旨在解决现有方案在安全性和效率上的权衡问题。DVFS通过结合局部敏感哈希与虚拟二叉树实现自适应安全模糊搜索（$O(\\log n)$复杂度），采用双存储库版本控制支持带前向隐私的动态更新，并利用区块链确保验证的正确性和完整性（$O(\\log n)$复杂度）。该方案有效地提升了加密数据检索的安全性、效率和可信度。

> **摘要翻译:** 云存储为加密数据检索带来了严峻的隐私挑战，其中模糊多关键词搜索能够在保持数据机密性的同时实现近似匹配。现有解决方案在安全性和效率之间面临根本性的权衡：线性搜索机制提供自适应安全性，但对于大规模数据会产生过高的开销；而基于树的索引虽然提高了性能，却以分支泄露漏洞为代价。
为了解决这些限制，我们提出了DVFS——一种动态可验证的模糊搜索服务，具有三项核心创新：(1) 一种自适应安全模糊搜索方法，将局部敏感哈希与虚拟二叉树相结合，消除了分支泄露，同时将搜索复杂度从线性降低到亚线性（$O(\\log n)$时间）；(2) 一种支持前向隐私动态更新的双存储库版本控制机制，防止操作期间的信息泄露；(3) 一个基于区块链的验证系统，通过智能合约确保正确性和完整性，实现了$O(\\log n)$的验证复杂度。
我们的解决方案通过同时解决安全-性能悖论并实现可信赖的动态操作，推进了安全加密检索技术。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [633] [Privacy Against Agnostic Inference Attacks in Vertical Federated Learning](https://arxiv.org/abs/2302.05545)
> *垂直联邦学习中对抗不可知推理攻击的隐私保护*

*Morteza Varasteh* | **Category: cs.CR, cs.IT, cs.LG, math.IT** | **Updated: 2025-07-15**

**Keywords:** 垂直联邦学习, 不可知推理攻击, 隐私保护方案, 逻辑回归, 参数扭曲

**Comment:** 

> **TL;DR:** 本文提出了一种垂直联邦学习（VFL）中的新型不可知推理攻击，其中主动方可以在训练和预测阶段对样本进行推理攻击。作为对策，论文提出了隐私保护方案（PPSs），这些方案在保持VFL模型效用的同时，系统地扭曲了被动方的参数，从而在隐私和可解释性之间取得了平衡。

**AI_Comments:** 本文创新性地提出了垂直联邦学习中的“不可知推理攻击”，揭示了VFL模型在隐私保护方面的新挑战。其价值在于不仅识别了潜在的隐私漏洞，还提出了实际可行的隐私保护方案。这些方案通过参数扭曲来平衡隐私和模型可解释性，为VFL的实际应用提供了新的思路。该研究对于推动联邦学习的隐私安全发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在垂直联邦学习（VFL）中，主动方可能通过独立训练的模型对训练和预测阶段的样本进行推理攻击，即使不了解特定样本的分数，这种攻击被称为不可知推理攻击。为了应对这种新型推理攻击，需要开发有效的隐私保护方案。

**Method:** 本文提出了一种新型的不可知推理攻击，主动方通过独立训练的机器学习模型进行推理，并利用预测阶段的置信度分数来提高攻击效果。作为防御，提出了隐私保护方案（PPSs），这些方案通过系统地扭曲垂直联邦学习模型中与被动方特征对应的参数来保护隐私，同时保持模型效用，并允许调整扭曲级别以平衡隐私和可解释性。

**Result:** 研究表明，主动方可以通过独立训练的机器学习模型对训练和预测阶段的样本进行不可知推理攻击。利用预测阶段观察到的置信度分数可以提高攻击性能。提出的隐私保护方案（PPSs）在保持VFL模型效用的同时，能够有效地对抗这种攻击，并通过扭曲被动方的VFL参数来实现隐私保护。实验结果证明了所提出攻击和PPSs的有效性。

**Conclusion:** 本文成功提出并验证了一种垂直联邦学习中的新型不可知推理攻击，并开发了有效的隐私保护方案作为对策。这些方案在保护被动方隐私的同时，保持了VFL模型的效用，并允许在隐私和主动方对VFL结果的可解释性之间进行权衡。

> **ai_Abstract:** 本文提出了一种垂直联邦学习（VFL）中的新型不可知推理攻击，其中主动方利用独立训练的机器学习模型对训练和预测阶段的样本进行推理，并通过利用预测阶段的置信度分数提高攻击效果。为应对此攻击，论文提出了隐私保护方案（PPSs），这些方案通过系统地扭曲被动方的VFL参数来保护隐私，同时保持模型效用，并允许在隐私与主动方对结果的可解释性之间进行权衡。实验结果验证了攻击的有效性和所提PPSs的防御能力。

> **摘要翻译:** 垂直联邦学习（VFL）中提出了一种新型推理攻击，其中两方协作训练机器学习（ML）模型。VFL模型考虑了逻辑回归。其中一方（称为主动方）在训练阶段拥有样本的真实标签，而另一方（称为被动方）只共享与这些样本对应的独立特征集。研究表明，主动方可以通过获取一个独立训练的机器学习模型，对训练和预测阶段的样本进行推理攻击。这种推理攻击不需要主动方知道特定样本的分数，因此被称为不可知推理攻击。研究表明，在攻击发生之前，利用预测阶段观察到的置信度分数可以提高主动方自主机器学习模型的性能，从而提高不可知推理攻击的质量。作为对策，提出了隐私保护方案（PPSs）。虽然所提出的方案保留了VFL模型的效用，但它们系统地扭曲了与被动方特征对应的VFL参数。施加在被动方参数上的扭曲程度是可调的，从而在被动方隐私和主动方对VFL结果的可解释性之间产生了权衡。被动方参数的扭曲程度可以根据被动方和主动方的隐私和可解释性关注点仔细选择，以期使双方（部分）满意。最后，实验结果证明了所提出的攻击和PPSs的有效性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [639] [Hashed Watermark as a Filter: Defeating Forging and Overwriting Attacks in Weight-based Neural Network Watermarking](https://arxiv.org/abs/2507.11137)
> *哈希水印作为过滤器：击败基于权重的神经网络水印中的伪造和覆盖攻击*

*Yuan Yao, Jin Song, Jian Jin* | **Category: cs.CR, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 神经网络水印, 哈希水印, 伪造攻击, 覆盖攻击, 鲁棒性

**Comment:** 

> **TL;DR:** 提出NeuralMark，一种基于哈希水印过滤器的方法，以增强基于权重的神经网络水印的鲁棒性，抵御伪造和覆盖攻击。

**AI_Comments:** 本文的创新点在于引入了“哈希水印作为过滤器”的概念，通过不可逆的哈希函数生成水印并将其用于参数选择，这显著增强了基于权重的神经网络水印的安全性，特别是对抗伪造和覆盖攻击。其通用性和对多种攻击的抵抗能力使其成为NNW领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络作为宝贵的数字资产，需要强大的所有权保护，而现有的基于权重的神经网络水印方法容易受到伪造和覆盖攻击。

**Method:** 提出NeuralMark，利用哈希函数从密钥生成不可逆的二进制水印，该水印作为过滤器选择模型参数进行嵌入。这种设计将嵌入参数与哈希水印巧妙地结合，以抵御伪造和覆盖攻击。同时，通过平均池化来抵抗微调和剪枝攻击。

**Result:** 在理论上分析了其安全边界。在经验上，通过13种不同的卷积和Transformer架构，涵盖5个图像分类任务和1个文本生成任务，验证了其有效性和鲁棒性。

**Conclusion:** NeuralMark通过引入哈希水印过滤器，显著提升了基于权重的神经网络水印的鲁棒性，有效抵御了伪造和覆盖攻击，并具有广泛的适用性。

> **ai_Abstract:** 本文提出NeuralMark，一种针对基于权重的神经网络水印的鲁棒方法，旨在解决其在伪造和覆盖攻击下的脆弱性。NeuralMark通过使用哈希函数生成不可逆的二进制水印作为过滤器来选择并嵌入模型参数，从而巧妙地将水印与模型参数绑定，有效抵御攻击。该方法还通过平均池化增强了对微调和剪枝的抵抗力，并具有广泛的架构兼容性。理论分析和大量实验证明了其安全性和有效性。

> **摘要翻译:** 作为有价值的数字资产，深度神经网络需要强大的所有权保护，这使得神经网络水印（NNW）成为一个有前景的解决方案。在各种NNW方法中，基于权重的方法因其简单性和实用性而受到青睐；然而，它们仍然容易受到伪造和覆盖攻击。为了应对这些挑战，我们提出了NeuralMark，一种围绕哈希水印过滤器构建的鲁棒方法。具体来说，我们利用哈希函数从一个密钥生成一个不可逆的二进制水印，然后将其用作过滤器来选择模型参数进行嵌入。这种设计巧妙地将嵌入参数与哈希水印交织在一起，为抵御伪造和覆盖攻击提供了强大的防御。同时，还引入了平均池化来抵抗微调和剪枝攻击。此外，它还可以无缝集成到各种神经网络架构中，确保了广泛的适用性。在理论上，我们分析了其安全边界。在经验上，我们在13种不同的卷积和Transformer架构上验证了其有效性和鲁棒性，涵盖了5个图像分类任务和1个文本生成任务。源代码可在https://github.com/AIResearch-Group/NeuralMark获得。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [653] [FacialMotionID: Identifying Users of Mixed Reality Headsets using Abstract Facial Motion Representations](https://arxiv.org/abs/2507.11138)
> *FacialMotionID：使用抽象面部运动表示识别混合现实头戴设备用户*

*Adriano Castro, Simon Hanisch, Matin Fallahi, Thorsten Strufe* | **Category: cs.CR** | **Updated: 2025-07-15**

**Keywords:** 面部运动, 混合现实, 用户识别, 隐私, 生物识别

**Comment:** 

> **TL;DR:** 研究发现，即使使用抽象的面部运动数据，混合现实头戴设备的用户仍可能被高度准确地识别，并推断出情绪状态，这凸显了潜在的隐私风险。

**AI_Comments:** 这项研究的创新之处在于，它明确指出即使是用于虚拟形象动画的“抽象”面部运动数据，而非原始视频，也足以进行高度准确的用户识别和情绪推断。这对于混合现实和虚拟现实领域的隐私保护具有重要的警示意义，提示开发者和用户需要重新评估这些技术在数据收集和使用方面的潜在风险。其重要性在于揭示了在沉浸式体验中行为生物识别数据的强大识别能力，对未来隐私政策和技术设计提出了挑战。

<details>
  <summary>Details</summary>

**Motivation:** 混合现实头戴设备中的面部运动数据构成行为生物识别信息，其使用引发了新的隐私担忧。随着混合现实系统变得更加沉浸和普及，了解面部运动数据是否会导致用户识别或敏感属性推断变得日益重要。

**Method:** 研究招募了116名参与者，使用三种类型的头戴设备进行了三次会话，收集了口头和非口头任务期间的面部、眼部和头部运动数据。所使用的数据并非原始视频，而是用于动画数字虚拟形象的抽象表示。

**Result:** 分析显示，个体可以从这些数据中被重新识别，平衡准确率高达98%，甚至可以在不同设备类型之间进行识别；情绪状态可以以高达86%的准确率被推断出来。

**Conclusion:** 这些结果强调了混合现实环境中面部运动追踪固有的潜在隐私风险。

> **ai_Abstract:** 本研究旨在探讨混合现实头戴设备中抽象面部运动数据在用户识别和情绪推断方面的隐私风险。通过对116名参与者的实验，研究发现即使使用非原始视频的抽象面部运动表示，用户也能以高达98%的准确率被重新识别，且跨设备类型也有效。此外，情绪状态可被以高达86%的准确率推断。这些结果强调了面部运动追踪在混合现实环境中带来的显著隐私挑战。

> **摘要翻译:** 混合现实头戴设备中的面部运动捕捉能够实现实时虚拟形象动画，允许用户在虚拟互动中传达非语言线索。然而，由于面部运动数据构成行为生物识别信息，其使用引发了新的隐私担忧。随着混合现实系统变得更加沉浸和普及，了解面部运动数据是否会导致用户识别或敏感属性推断变得日益重要。为了解决这个问题，我们对116名参与者进行了研究，他们使用三种类型的头戴设备进行了三次会话，收集了口头和非口头任务期间的面部、眼部和头部运动数据。所使用的数据并非原始视频，而是用于动画数字虚拟形象的抽象表示。我们的分析显示，个体可以从这些数据中被重新识别，平衡准确率高达98%，甚至可以在不同设备类型之间进行识别，并且情绪状态可以以高达86%的准确率被推断出来。这些结果强调了混合现实环境中面部运动追踪固有的潜在隐私风险。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [674] [Bridging the Gap in Vision Language Models in Identifying Unsafe Concepts Across Modalities](https://arxiv.org/abs/2507.11155)
> *弥合视觉语言模型在跨模态识别不安全概念方面的差距*

*Yiting Qu, Michael Backes, Yang Zhang* | **Category: cs.CR** | **Updated: 2025-07-15**

**Keywords:** 视觉语言模型, 不安全概念, 模态差距, 强化学习, 数据集

**Comment:** To Appear in the 34th USENIX Security Symposium, August 2025

> **TL;DR:** 本文研究视觉语言模型（VLMs）在跨模态识别不安全概念时的能力。发现VLMs在识别不安全概念时存在误分类和模态差距。为解决此问题，作者构建了UnsafeConcepts数据集，并提出了一种基于强化学习（PPO）的方法，无需人工标注偏好数据，有效提升了VLM在图像上识别不安全概念的对齐能力，并优于基线方法。

**AI_Comments:** 本文的创新点在于构建了一个专门用于评估VLM不安全概念识别能力的UnsafeConcepts数据集，并揭示了VLMs在跨模态识别中的潜在缺陷和模态差距。更重要的是，作者提出了一种无需大量人工标注数据的强化学习（PPO）方法来提升VLMs的安全性对齐能力，这对于资源受限的安全性研究具有重要意义。该方法直接利用VLM响应作为奖励，简化了奖励模型训练的复杂性，为未来VLM的安全对齐研究提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 视觉语言模型（VLMs）在识别不安全或不当图像方面应用日益广泛，但它们是否能识别不同模态（如文本和图像）中的各种不安全概念尚不明确。现有VLMs在感知不安全概念时有时会错误地将其分类为安全概念，且开源VLMs在区分视觉和文本不安全概念时存在一致的模态差距。

**Method:** 1. 编译UnsafeConcepts数据集，包含75个不安全概念（如“万字符”、“性骚扰”、“袭击”）和1.5K张相关图像。
2. 对八个流行的VLMs的感知（概念识别）和对齐（伦理推理）能力进行系统评估。
3. 引入了一种简化的基于强化学习（RL）的方法，使用近端策略优化（PPO）来增强从图像中识别不安全概念的能力。
4. 该方法直接使用VLM响应作为奖励分数，绕过了收集人工标注偏好数据来训练新奖励模型的需求。

**Result:** 1. 大多数VLMs能准确感知不安全概念，但有时会错误地将这些概念分类为安全概念。
2. 在开源VLMs中发现一致的模态差距，体现在区分视觉和文本不安全概念方面。
3. 提出的强化学习方法有效增强了VLM在图像上的对齐能力，同时保留了通用能力。
4. 该方法优于监督微调（SFT）和直接偏好优化（DPO）等基线方法。

**Conclusion:** 本文构建了UnsafeConcepts数据集，揭示了VLMs在识别跨模态不安全概念上的挑战和模态差距，并提出了一种无需人工标注偏好数据的强化学习方法，有效提升了VLMs的安全性对齐能力，为推进安全VLMs做出了贡献。

> **ai_Abstract:** 本文旨在解决视觉语言模型（VLMs）在识别跨模态不安全概念时存在的差距。研究者首先构建了包含75个不安全概念和1.5K图像的UnsafeConcepts数据集，并系统评估了八个VLMs的感知和伦理对齐能力。评估发现VLMs在识别不安全概念时存在误分类和模态差距。为弥合这一差距，作者提出了一种简化的基于PPO的强化学习方法，该方法通过VLM响应直接生成奖励分数，无需人工标注数据，并成功提升了VLM在图像上识别不安全概念的对齐能力，且性能优于现有基线方法。这项工作为提升VLMs的安全性提供了数据集、评估发现和有效的解决方案。

> **摘要翻译:** 视觉语言模型（VLMs）因其内在的伦理标准和强大的推理能力，越来越多地应用于识别不安全或不当图像。然而，它们是否能识别以不同模态（如文本和图像）呈现的各种不安全概念，目前尚不明确。为了解决这个问题，我们首先编译了UnsafeConcepts数据集，该数据集包含75个不安全概念，例如“万字符”、“性骚扰”和“袭击”，以及相关的1.5K张图像。然后，我们对VLMs的感知（概念识别）和对齐（伦理推理）能力进行了系统评估。我们评估了八个流行的VLM，发现尽管大多数VLM能够准确感知不安全概念，但它们有时会错误地将这些概念分类为安全概念。我们还发现开源VLM在区分视觉和文本不安全概念方面存在一致的模态差距。为了弥合这一差距，我们引入了一种简化的基于强化学习（RL）的方法，使用近端策略优化（PPO）来增强从图像中识别不安全概念的能力。我们的方法直接基于VLM响应使用奖励分数，避免了收集人工标注偏好数据来训练新的奖励模型的需求。实验结果表明，我们的方法有效地增强了VLM在图像上的对齐能力，同时保留了通用能力。它优于监督微调（SFT）和直接偏好优化（DPO）等基线方法。我们希望我们的数据集、评估发现和提出的对齐解决方案能为社区推进安全VLM的努力做出贡献。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [689] [Predicting memorization within Large Language Models fine-tuned for classification](https://arxiv.org/abs/2409.18858)
> *预测分类任务微调大型语言模型中的记忆化*

*Jérémie Dentan, Davide Buscaldi, Aymen Shabou, Sonia Vanier* | **Category: cs.CR** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 数据记忆化, 分类任务, 事前检测, 数据隐私

**Comment:** This paper has been accepted for publication at ECAI 2025

> **TL;DR:** 本文提出一种新方法，用于提前预测大型语言模型在分类任务微调中可能记忆的数据样本，以应对数据泄露风险。

**AI_Comments:** 这项工作具有创新性，因为它解决了大型语言模型中一个关键但尚未充分探索的问题——数据记忆化的事前检测。现有方法大多是事后分析，而本文提出的方法能够在训练早期阶段进行预测，这对于数据隐私和模型安全具有重要意义。其低计算成本和可推广性也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型会记忆大量训练数据，这在推理时构成严重威胁。现有研究大多提供事后解释，而缺乏事前检测方法，因此需要一种能在训练早期阶段预测记忆化的方法来解决这一空白。

**Method:** 提出了一种新的方法，用于在为分类任务微调的大型语言模型中先验地检测记忆样本。该方法在训练早期阶段有效，计算成本低，并得到新的理论结果支持，且易于适应其他分类设置（如从头开始训练视觉模型）。

**Result:** 该方法取得了强大的经验结果。

**Conclusion:** 该方法为在样本被记忆之前系统地识别和保护易受攻击样本铺平了道路。

> **ai_Abstract:** 本文针对大型语言模型在分类任务微调中存在的训练数据记忆化问题，提出了一种创新的事前检测方法。该方法旨在训练早期阶段识别可能被模型记忆的样本，从而有效减轻数据泄露的风险。研究表明，该方法计算成本低，具有理论支持，并取得了显著的经验效果，为系统性地保护敏感数据提供了新途径。

> **摘要翻译:** 大型语言模型因其解决各种复杂任务的能力而受到广泛关注。然而，这些模型会记忆其训练数据中的很大一部分，这在推理时被披露时会构成严重威胁。为了减轻这种意外的记忆化，理解哪些元素被记忆以及为什么被记忆至关重要。这个研究领域在很大程度上尚未被探索，大多数现有工作都提供了事后解释。为了弥补这一空白，我们提出了一种新方法，用于在为分类任务微调的大型语言模型中先验地检测记忆样本。该方法在训练早期阶段有效，并且易于适应其他分类设置，例如从头开始训练视觉模型。我们的方法得到了新的理论结果的支持，并且需要较低的计算预算。我们取得了强大的经验结果，为在样本被记忆之前系统地识别和保护易受攻击样本铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [695] [LRCTI: A Large Language Model-Based Framework for Multi-Step Evidence Retrieval and Reasoning in Cyber Threat Intelligence Credibility Verification](https://arxiv.org/abs/2507.11310)
> *LRCTI：一个基于大型语言模型的多步证据检索与推理框架，用于网络威胁情报可信度验证*

*Fengxiao Tang, Huan Li, Ming Zhao, Zongzong Wu, Shisong Peng, Tao Yin* | **Category: cs.CR** | **Updated: 2025-07-15**

**Keywords:** Cyber Threat Intelligence (CTI), Large Language Models (LLMs), Credibility Verification, Evidence Retrieval, Natural Language Inference (NLI)

**Comment:** 

> **TL;DR:** LRCTI是一个基于LLM的框架，通过多步证据检索和推理，提高了网络威胁情报可信度验证的准确性和可解释性。

**AI_Comments:** 该论文的创新点在于将大型语言模型应用于网络威胁情报的可信度验证，并设计了一个多步框架，集成了文本摘要、证据检索和可解释的自然语言推理。这解决了传统方法在处理复杂、不完整数据时的鲁棒性不足和决策透明度低的问题。其提供可解释理由的能力对于真实世界的网络安全应用尤为重要。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法将CTI可信度验证视为静态分类问题，依赖手工特征或孤立的深度学习模型，导致在处理不完整、异构或嘈杂情报时缺乏鲁棒性，且决策透明度有限，降低了其在真实威胁环境中的有效性。

**Method:** 提出LRCTI框架，该框架首先采用文本摘要模块将复杂情报报告提炼为简洁的威胁主张。其次，使用自适应多步证据检索机制，在LLM反馈的引导下，从CTI专用语料库中迭代识别和完善支持信息。最后，应用基于提示的自然语言推理（NLI）模块评估每个主张的可信度，并生成可解释的分类理由。

**Result:** 在CTI-200和PolitiFact两个基准数据集上，LRCTI将F1-Macro和F1-Micro分数分别提高了5%以上，达到90.9%和93.6%，优于现有最先进的基线方法。

**Conclusion:** LRCTI有效解决了现有方法的核心局限性，为自动化CTI可信度验证提供了一个可扩展、准确且可解释的解决方案。

> **ai_Abstract:** 本文提出了LRCTI，一个基于大型语言模型（LLM）的多步框架，用于解决网络威胁情报（CTI）可信度验证中现有方法的局限性，如鲁棒性不足和透明度缺乏。LRCTI通过文本摘要、LLM引导的多步证据检索和基于提示的自然语言推理模块，实现了对威胁主张的准确验证和可解释的理由生成。实验结果表明，LRCTI在两个基准数据集上显著提升了性能，证明其为CTI可信度验证提供了一个可扩展、准确且可解释的自动化解决方案。

> **摘要翻译:** 验证网络威胁情报（CTI）的可信度对于可靠的网络安全防御至关重要。然而，传统方法通常将此任务视为一个静态分类问题，依赖手工特征或孤立的深度学习模型。这些方法在处理不完整、异构或嘈杂的情报时往往缺乏所需的鲁棒性，并且在决策制定方面提供的透明度有限——这些因素降低了它们在真实威胁环境中的有效性。为了解决这些局限性，我们提出了LRCTI，一个基于大型语言模型（LLM）的框架，专为多步CTI可信度验证而设计。该框架首先采用一个文本摘要模块，将复杂的情报报告提炼成简洁且可操作的威胁主张。然后，它使用一个自适应的多步证据检索机制，在LLM反馈的引导下，从CTI专用语料库中迭代识别和完善支持信息。最后，应用一个基于提示的自然语言推理（NLI）模块来评估每个主张的可信度，同时为分类结果生成可解释的理由。在CTI-200和PolitiFact两个基准数据集上进行的实验表明，与现有最先进的基线方法相比，LRCTI将F1-Macro和F1-Micro分数提高了5%以上，分别达到90.9%和93.6%。这些结果表明，LRCTI有效解决了现有方法的核心局限性，为自动化CTI可信度验证提供了一个可扩展、准确且可解释的解决方案。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [716] [A Review of Privacy Metrics for Privacy-Preserving Synthetic Data Generation](https://arxiv.org/abs/2507.11324)
> *隐私保护合成数据生成中隐私度量指标综述*

*Frederik Marinus Trudslev, Matteo Lissandrini, Juan Manuel Rodriguez, Martin Bøgsted, Daniele Dell'Aglio* | **Category: cs.CR, cs.DB** | **Updated: 2025-07-15**

**Keywords:** 隐私保护合成数据生成, 隐私度量指标, 差分隐私, 隐私风险, 综述

**Comment:** 

> **TL;DR:** 本文综述了隐私保护合成数据生成（PP-SDG）中用于评估隐私风险的多种隐私度量指标（PMs），详细介绍了17种不同PMs的假设和数学公式，以提高隐私损失解释的透明度。

**AI_Comments:** 本文是一篇重要的综述性工作，解决了隐私保护合成数据生成领域中一个关键的挑战：隐私度量指标的解释性和标准化。通过系统地整理和呈现17种不同隐私度量指标的假设和数学公式，为研究人员和实践者提供了宝贵的参考，有助于提高隐私风险评估的透明度和可比性。其创新之处在于对现有分散的PMs进行了统一的梳理和定义，填补了该领域的一项空白。

<details>
  <summary>Details</summary>

**Motivation:** 隐私保护合成数据生成（PP-SDG）在生成合成数据时旨在维护隐私和实用性。然而，差分隐私（DP）所表达的隐私损失（ε）难以解释，导致实际风险不透明。为了更清晰地评估数据相关的隐私风险，需要对现有隐私度量指标（PMs）的计算方式进行彻底定义。

**Method:** 本文综述了17种不同的隐私度量指标（PMs），并详细介绍了它们的假设和数学公式。这些PMs被用来评估隐私保护合成数据生成（PP-SDG）机制的隐私风险。

**Result:** 本文收集并呈现了17种不同隐私度量指标（PMs）的假设和数学公式，旨在使隐私损失的实际风险评估更加透明。

**Conclusion:** 为了更清晰地评估隐私保护合成数据生成（PP-SDG）中的隐私风险，需要对隐私度量指标（PMs）的计算方式进行彻底定义。本文通过系统地呈现17种PMs的假设和数学公式，为理解和应用这些度量提供了基础。

> **ai_Abstract:** 本文综述了隐私保护合成数据生成（PP-SDG）中使用的隐私度量指标（PMs）。鉴于差分隐私（DP）的隐私损失（ε）难以解释，导致实际风险不透明，多项PMs被提出以评估数据隐私风险。然而，这些PMs的计算方式和隐含假设常常与其评估的PP-SDG机制绑定。因此，本研究旨在通过详细介绍17种不同PMs的假设和数学公式，为理解和应用这些指标提供清晰的定义和基础。

> **摘要翻译:** 隐私保护合成数据生成（PP-SDG）已经出现，用于从个人数据生成合成数据集，同时保持隐私和实用性。差分隐私（DP）是PP-SDG机制的一种特性，它规定了个人在共享敏感数据时受保护的程度。然而，DP所表达的隐私损失（ε）很难解释。为了使与隐私损失相关的实际风险更加透明，已经提出了多种隐私度量指标（PMs）来评估数据的隐私风险。这些PMs在不同的研究中被用于评估新引入的PP-SDG机制。因此，这些PMs体现了它们旨在评估的PP-SDG机制的相同假设。因此，有必要彻底定义这些指标的计算方式。在这项工作中，我们介绍了17种不同隐私度量指标的假设和数学公式。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [737] [Demo: Secure Edge Server for Network Slicing and Resource Allocation in Open RAN](https://arxiv.org/abs/2507.11499)
> *演示：开放无线接入网络中网络切片与资源分配的安全边缘服务器*

*Adhwaa Alchaab, Ayman Younis, Dario Pompili* | **Category: cs.CR, cs.SY, eess.SY** | **Updated: 2025-07-13**

**Keywords:** 网络切片, 开放无线接入网络, 分布式拒绝服务, 资源分配, 安全

**Comment:** 

> **TL;DR:** SnSRIC是一个安全的智能网络切片框架，旨在开放无线接入网络（Open RAN）环境中缓解分布式拒绝服务（DDoS）攻击。它采用AI驱动的xApp动态分配资源并实施切片级安全，通过E2接口检测并限制恶意信号，同时保持合法用户的服务连续性。

**AI_Comments:** SnSRIC的创新之处在于其将AI驱动的xApp应用于Open RAN环境中的网络切片和资源分配，特别是在DDoS攻击缓解方面。通过动态资源分配、异常行为检测和恶意信号限制，它有效解决了NGRAN面临的关键安全和性能挑战，对于未来5G/6G网络的安全运营具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 下一代无线接入网络（NGRAN）需要支持对安全性、延迟和服务水平协议（SLA）有严格要求的各种垂直应用。这些需求在基础设施安全、动态资源分配和实时重配置方面带来了挑战。

**Method:** 本文展示了SnSRIC，一个安全且智能的网络切片框架，用于在开放无线接入网络（Open RAN）环境中缓解分布式拒绝服务（DDoS）攻击。SnSRIC包含一个AI驱动的xApp，该xApp动态地将物理资源块（PRB）分配给活跃用户，同时强制执行切片级安全。该系统检测异常行为，区分良性设备和恶意设备，并使用E2接口限制恶意信号，同时为合法用户保持服务连续性。

**Result:** 该系统能够检测异常行为，区分良性设备和恶意设备，并使用E2接口限制恶意信号，同时为合法用户保持服务连续性。

**Conclusion:** SnSRIC提供了一个安全且智能的网络切片框架，用于在开放无线接入网络环境中缓解DDoS攻击，并通过动态资源分配和恶意流量限制来确保服务连续性。

> **ai_Abstract:** 本文介绍了一个名为SnSRIC的安全智能网络切片框架，旨在解决下一代无线接入网络（NGRAN）中网络切片和资源分配面临的安全挑战。SnSRIC通过一个AI驱动的xApp实现动态物理资源块（PRB）分配和切片级安全强制，有效缓解开放无线接入网络（Open RAN）环境中的分布式拒绝服务（DDoS）攻击。该系统能够识别并隔离恶意设备，通过E2接口限制恶意信号，从而确保合法用户的服务连续性。

> **摘要翻译:** 下一代无线接入网络（NGRAN）旨在支持具有严格安全性、延迟和服务水平协议（SLA）要求的各种垂直应用。这些需求在基础设施安全、动态资源分配和实时重配置方面带来了挑战。本次演示展示了SnSRIC，一个安全且智能的网络切片框架，可在开放无线接入网络（Open RAN）环境中缓解一系列分布式拒绝服务（DDoS）攻击。SnSRIC包含一个AI驱动的xApp，该xApp在强制执行切片级安全的同时，动态地将物理资源块（PRB）分配给活跃用户。该系统检测异常行为，区分良性设备和恶意设备，并使用E2接口限制恶意信号，同时为合法用户保持服务连续性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [738] [Pantomime: Motion Data Anonymization using Foundation Motion Models](https://arxiv.org/abs/2501.07149)
> *哑剧：使用基础运动模型进行运动数据匿名化*

*Simon Hanisch, Julian Todt, Thorsten Strufe* | **Category: cs.CR** | **Updated: 2025-07-15**

**Keywords:** 运动数据匿名化, 隐私保护, 基础运动模型, 生物特征, 运动自然度

**Comment:** 

> **TL;DR:** Pantomime是一种全身运动数据匿名化技术，利用基础运动模型在保持运动自然度的同时显著降低个体识别准确率，以解决运动数据隐私泄露问题。

**AI_Comments:** 这篇论文解决了运动数据隐私保护的关键问题，其创新点在于利用“基础运动模型”来处理运动序列中的复杂依赖关系，从而在匿名化的同时保持数据的自然度和实用性。这对于混合现实、机器人和医疗等需要使用人体运动数据的领域具有重要意义。其提出的方法有效平衡了隐私保护和数据可用性。

<details>
  <summary>Details</summary>

**Motivation:** 人体运动作为一种行为生物特征，可用于识别个体并推断私人属性（如医疗状况）。随着视频和运动捕捉中运动提取在混合现实、机器人、医学和量化自我等各种应用中的日益普及，这严重威胁到个人隐私。因此，需要能够在保护隐私的同时保持数据实用性的匿名化技术。

**Method:** 论文提出Pantomime，一种针对运动数据的全身匿名化技术。该方法利用基础运动模型生成符合数据依赖性（如生理约束）的运动序列，从而确保匿名化数据的实用性。

**Result:** Pantomime能够保持运动序列的自然度，同时将识别准确率降低至10%。

**Conclusion:** Pantomime成功地实现了运动数据的匿名化，有效保护了个人隐私，同时保持了数据的实用性和运动的自然度。

> **ai_Abstract:** 本文提出了Pantomime，一种创新的全身运动数据匿名化技术，旨在解决日益增长的运动数据隐私泄露问题。该技术利用基础运动模型来生成既能保持运动序列自然度，又能遵守数据内在依赖关系（如生理约束）的匿名化运动数据。实验结果表明，Pantomime在将个体识别准确率显著降低至10%的同时，有效维持了匿名化运动数据的实用性和自然性。

> **摘要翻译:** 人体运动是一种行为生物特征，可用于识别个体并推断诸如医疗状况等私人属性。由于视频和运动捕捉中运动提取在混合现实、机器人、医学和量化自我等各种应用中日益增多，这严重威胁到隐私。为了保护被跟踪个体的隐私，需要能够保留数据实用性的匿名化技术。然而，匿名化运动数据是一项具有挑战性的任务，因为运动序列中存在许多依赖关系（例如生理约束），如果忽略这些依赖关系，会导致匿名化后的运动序列显得不自然。在本文中，我们提出了Pantomime，一种用于运动数据的全身匿名化技术，它利用基础运动模型生成符合数据依赖性的运动序列，从而保持匿名化数据的高实用性。我们的结果表明，Pantomime可以在降低识别准确率至10%的同时，保持运动序列的自然度。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [772] [ARMOR: Aligning Secure and Safe Large Language Models via Meticulous Reasoning](https://arxiv.org/abs/2507.11500)
> *ARMOR：通过细致推理对齐安全可靠的大型语言模型*

*Zhengyue Zhao, Yingzi Ma, Somesh Jha, Marco Pavone, Chaowei Xiao* | **Category: cs.CR** | **Updated: 2025-07-14**

**Keywords:** 大型语言模型安全, 推理对齐, 越狱攻击, ARMOR, 结构化推理

**Comment:** 

> **TL;DR:** ARMOR提出了一种基于推理的安全对齐框架，通过模仿人类的结构化推理过程，显著提高了大型语言模型抵御越狱攻击的鲁棒性。

**AI_Comments:** ARMOR通过将人类的结构化推理过程引入LLMs的安全对齐，提供了一种新颖且有效的方法来对抗日益复杂的越狱攻击。其创新点在于取代了传统的临时性推理，专注于识别真实意图，这对于构建更具鲁棒性和可靠性的AI系统至关重要。该方法在实际应用中，尤其是在需要高安全性的大模型部署场景中，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）尽管具有强大的生成能力，但其滥用风险引发了严重的安全担忧。现有的后训练安全对齐方法和推理时安全推理（System-2 对齐）仍然容易受到恶意指令和复杂的越狱提示攻击，因为它们的推理过程是临时的，未能模仿人类识别真实意图和评估风险的结构化过程。

**Method:** 本文提出了一个名为ARMOR的基于推理的安全对齐框架。ARMOR用与人类对齐的结构化推理过程取代了临时的思维链推理。在推理时，ARMOR执行以下步骤：1) 检测可能的越狱策略；2) 提取用户的核心意图，同时丢弃欺骗性指令；3) 对净化后的请求应用基于策略的安全分析。此外，还进行了测试时缩放以进一步提高性能。

**Result:** 评估结果表明，ARMOR显著增强了对抗最先进的自适应越狱攻击的鲁棒性，并在各种安全基准测试中优于最近的基于推理的对齐模型。

**Conclusion:** ARMOR通过引入与人类对齐的结构化推理过程，有效解决了大型语言模型在对抗复杂越狱攻击时的安全漏洞，从而构建了更安全可靠的LLMs。

> **ai_Abstract:** 本文提出了ARMOR，一个旨在提高大型语言模型（LLMs）安全性和鲁棒性的推理型安全对齐框架。针对现有方法易受复杂越狱攻击的缺陷，ARMOR引入了一种模仿人类思维的结构化推理过程。该框架在推理时能检测越狱策略、提取用户真实意图并进行策略性安全分析。实验证明，ARMOR在抵御先进越狱攻击和各类安全基准测试中表现出色，显著优于现有基于推理的对齐模型。

> **摘要翻译:** 大型语言模型（LLMs）展示了卓越的生成能力。然而，它们易受滥用，引发了重大的安全担忧。虽然训练后安全对齐方法已被广泛采用，但LLMs仍然容易受到能够绕过安全约束的恶意指令的影响。最近的努力引入了推理时安全推理（System-2 对齐），其中LLMs在最终响应之前进行推理过程以执行安全验证。然而，我们发现这些检查是由临时的推理驱动的，这偏离了人类的结构化过程，即人类首先辨别用户的真实意图，然后根据真实意图评估相关风险。因此，这些防御措施仍然容易受到将有害目标伪装成看似良性语言的复杂越狱提示的攻击。为了构建安全可靠的LLMs，我们提出了一个基于推理的安全对齐框架ARMOR，它用与人类对齐的结构化过程取代了临时的思维链推理过程。在推理时，ARMOR（1）检测可能的越狱策略，（2）提取用户的核心意图，同时丢弃欺骗性指令，以及（3）对净化后的请求应用基于策略的安全分析。ARMOR在自适应越狱攻击和多个安全基准上进行了评估，并进行了测试时缩放以进一步提高其性能。结果表明，ARMOR显著增强了对抗最先进的自适应越狱攻击的鲁棒性，并在各种安全基准上优于最近的基于推理的对齐模型。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [801] [Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities](https://arxiv.org/abs/2502.05209)
> *模型篡改攻击能够实现对大型语言模型能力的更严格评估*

*Zora Che, Stephen Casper, Robert Kirk, Anirudh Satheesh, Stewart Slocum, Lev E McKinney, Rohit Gandikota, Aidan Ewart, Domenic Rosati, Zichu Wu, Zikui Cai, Bilal Chughtai, Yarin Gal, Furong Huang, Dylan Hadfield-Menell* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 大型语言模型, 模型篡改攻击, 风险评估, 能力抑制, 安全性

**Comment:** Accepted to TMLR

> **TL;DR:** 现有LLM风险评估方法存在局限性，本文提出模型篡改攻击作为补充，并证明其能更严格地评估LLM的有害能力，且揭示了抑制有害能力的困难性。

**AI_Comments:** 本文提出了一种新颖的模型篡改攻击方法，为大型语言模型（LLM）的风险评估提供了更全面和严格的视角，弥补了传统输入-输出评估的不足。其创新之处在于通过直接修改模型内部状态（激活或权重）来探测其潜在的有害能力，这对于开源模型尤其重要。研究结果揭示了抑制LLM有害能力的内在难度，特别是现有遗忘方法易被绕过，这对于LLM的安全性和负责任的AI开发具有重要警示意义。该工作对于提升LLM安全评估的深度和广度具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）的风险和能力评估日益重要，但当前主要依赖的输入-输出评估方法存在两方面局限性：一是无法充分评估开源模型的真实风险；二是只能提供模型最坏情况行为的下限。因此，需要一种更严格、更全面的方法来评估LLM的潜在有害能力。

**Method:** 本文提出使用模型篡改攻击来评估LLM，该攻击允许修改模型的潜在激活或权重以诱导有害行为。研究将最先进的移除有害LLM能力的技术与一套包含5种输入空间攻击和6种模型篡改攻击的组合进行对抗性测试，并对这些方法进行基准测试。

**Result:** 1. 模型对能力诱导攻击的弹性存在于一个低维鲁棒性子空间中。2. 模型篡改攻击的成功率可以经验性地预测并保守估计未使用的输入空间攻击的成功率。3. 最先进的遗忘（unlearning）方法在16步微调内即可轻易被逆转。

**Conclusion:** 研究结果表明，抑制大型语言模型（LLM）的有害能力非常困难，且模型篡改攻击相比单独的输入空间攻击，能够实现对LLM能力的更严格评估。

> **ai_Abstract:** 本文指出当前大型语言模型（LLM）风险评估主要依赖输入-输出方法，但该方法在评估开源模型风险和捕捉最坏情况行为方面存在局限性。为弥补不足，研究提出了一种新的评估方法——模型篡改攻击，该方法通过修改模型的潜在激活或权重来诱导有害行为。实验中，将最先进的LLM有害能力移除技术与一系列输入空间攻击和模型篡改攻击进行对抗性测试。结果表明，模型对攻击的弹性存在于低维空间，模型篡改攻击的成功率能有效预测输入空间攻击，且现有“遗忘”方法极易被逆转。这些发现强调了抑制LLM有害能力的挑战性，并证明模型篡改攻击能提供比传统输入空间攻击更严格的评估。

> **摘要翻译:** 大型语言模型（LLM）的风险和能力评估正日益被纳入AI风险管理和治理框架。目前，大多数风险评估是通过设计输入来诱导系统产生有害行为。然而，这种方法存在两个局限性。首先，输入-输出评估无法完全评估开源模型的真实风险。其次，在任何特定输入-输出评估中识别出的行为只能提供模型最坏情况输入-输出行为的下限。作为一种诱导有害行为的补充方法，我们提出使用模型篡改攻击来评估LLM，这种攻击允许修改潜在激活或权重。我们将最先进的移除有害LLM能力的技术与一套5种输入空间攻击和6种模型篡改攻击进行对抗。除了相互基准测试这些方法外，我们还发现：（1）模型对能力诱导攻击的弹性存在于一个低维鲁棒性子空间中；（2）模型篡改攻击的成功率可以经验性地预测并保守估计未使用的输入空间攻击的成功率；（3）最先进的遗忘方法可以在16步微调内轻易被逆转。总而言之，这些结果突显了抑制有害LLM能力的难度，并表明模型篡改攻击能够比单独的输入空间攻击实现更严格的评估。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='csai'></a>
## cs.AI 

### [1] [Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation](https://arxiv.org/abs/2507.10911)
> *从LLM多智能体在更安全治疗推荐中评估的经验教训*

*Yicong Wu, Ting Chen, Irit Hochberg, Zhoujian Sun, Ruth Edry, Zhengxing Huang, Mor Peleg* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** LLM, 多智能体, 治疗推荐, 多重共病, 医疗决策支持

**Comment:** 

> **TL;DR:** 本研究探讨了基于LLM的多智能体系统在为多重共病患者提供更安全治疗推荐中的可行性和价值，发现当前LLM单智能体表现与多学科团队相当，但推荐仍有局限性。

**AI_Comments:** 本文创新性地将LLM多智能体应用于复杂的医疗决策支持场景，模拟了MDT协作模式。其重要性在于探索了LLM在解决多重共病治疗冲突方面的潜力，并提出了一套更全面的评估指标，超越了传统的精确度和召回率，关注实际临床效果和用药负担。然而，研究也揭示了当前LLM在生成完整和避免不必要用药方面的局限性，为未来研究指明了改进方向。

<details>
  <summary>Details</summary>

**Motivation:** 慢性多重共病患者的治疗推荐因治疗冲突风险而具有挑战性，现有决策支持系统面临可扩展性限制。

**Method:** 本研究设计了单智能体和模拟多学科团队（MDT）决策的多智能体系统（MAS）框架，通过使LLM智能体之间进行讨论以解决医疗冲突。系统在多重共病患者的治疗规划任务上使用基准案例进行评估，并将MAS性能与单智能体方法和真实世界基准进行比较。研究还定义了超越传统技术精确度和召回率的评估指标，以检查所提建议达到的临床目标和药物负担。

**Result:** 在当前LLM下，单智能体全科医生（GP）的表现与多学科团队（MDTs）相当。得分最高的模型能够提供解决所有临床目标的正确建议，但这些建议不完整。一些模型还提出了不必要的药物，导致药物与病情或药物-药物相互作用之间产生不必要的冲突。

**Conclusion:** 基于LLM的多智能体系统在更安全治疗推荐方面具有潜力，但仍面临挑战，如推荐的完整性不足和不必要用药。未来的研究需改进模型以提供更全面和安全的治疗建议。

> **ai_Abstract:** 本研究探讨了基于LLM的多智能体系统在为多重共病患者提供更安全治疗推荐中的应用。受全科医生与多学科团队协作启发，研究设计并评估了单智能体和多智能体框架，以模拟医疗决策过程并解决冲突。评估结果显示，当前LLM的单智能体表现与多学科团队相当，但即便最佳模型也存在推荐不完整或包含不必要药物的问题。研究还提出了新的评估指标，超越传统技术指标，关注临床目标和用药负担。

> **摘要翻译:** 对于患有多重共病的慢性病患者，由于治疗冲突的风险，治疗推荐具有挑战性。现有的决策支持系统面临可扩展性限制。受全科医生（GP）管理多重共病患者，偶尔召集多学科团队（MDT）协作的方式启发，本研究调查了使用基于大型语言模型（LLM）的多智能体系统（MAS）进行更安全治疗推荐的可行性和价值。我们设计了一个单智能体和MAS框架，通过使LLM智能体之间进行讨论以解决医疗冲突来模拟MDT决策。系统在多重共病患者的治疗规划任务上使用基准案例进行了评估。我们将MAS性能与单智能体方法和真实世界基准进行了比较。我们研究的一个重要贡献是定义了超越技术精确度和召回率的评估指标，这些指标允许检查所提建议达到的临床目标和药物负担相对于黄金标准基准。我们的结果表明，在当前的LLMs下，单智能体GP的表现与MDTs相当。得分最高的模型提供了解决所有临床目标的正确建议，但这些建议不完整。一些模型还提出了不必要的药物，导致药物与病情或药物-药物相互作用之间产生不必要的冲突。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [10] [Acquiring and Adapting Priors for Novel Tasks via Neural Meta-Architectures](https://arxiv.org/abs/2507.10446)
> *通过神经元元架构获取和适应新任务的先验知识*

*Sudarshan Babu* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 元学习, 超网络, 神经记忆, 迁移学习, 数据稀缺

**Comment:** arXiv admin note: text overlap with arXiv:2310.17075

> **TL;DR:** 本文提出了一种基于神经元元架构（包括神经记忆和超网络）的方法，用于在数据稀缺领域高效获取和适应先验知识，并在3D场景生成、3D分割和分子性质预测等任务中取得了显著效果。

**AI_Comments:** 本文的创新点在于提出了利用神经元元架构（尤其是超网络和神经记忆）来解决数据稀缺领域中的知识迁移问题。其重要性体现在能够使模型在仅有少量数据的情况下也能高效地获取和适应先验知识，从而在传统迁移学习难以应用的领域（如计算化学、医学影像）开辟了新的可能性。方法的通用性体现在其在3D生成、3D分割和分子预测等多个不同任务上的成功应用，证明了其强大的泛化能力和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的迁移学习在数据量大的情况下表现出色，但在计算化学、计算免疫学和医学成像等数据稀缺领域，由于无法训练大型预训练模型或基础模型而面临挑战。本文旨在设计一种架构，以在数据量不足时也能高效获取先验知识。

**Method:** 本文提出使用神经记忆实现少量样本下的非平稳分布适应。然后，展示了其超网络设计（一个生成另一个网络的网络）在与模型无关元学习（MAML）结合训练时，比标准网络能获得更具泛化性的先验知识。该方法应用于3D场景生成、3D分割和分子性质预测。

**Result:** 通过神经记忆，可以在少量样本下实现非平稳分布的适应。超网络设计在MAML训练下能获得比标准网络更具泛化性的先验知识。在3D场景生成中，超网络能在少量训练场景下高效获取先验知识，从而实现更快的文本到3D生成。超网络框架还扩展到在有限数据下通过高效迁移先验知识，对新场景进行3D分割。此外，通过重新利用现有的分子生成方法作为预训练框架，改进了分子性质预测，解决了计算免疫学中的关键挑战。

**Conclusion:** 本文提出的神经元元架构，特别是结合了神经记忆和超网络的设计，有效解决了在数据稀缺领域高效获取和适应先验知识的挑战，并在多个应用中展示了其优越性。

> **ai_Abstract:** 本文提出了一种基于神经元元架构（包括神经记忆和超网络）的方法，旨在解决在计算化学、计算免疫学和医学成像等数据稀缺领域中，传统迁移学习因缺乏大型预训练数据而失效的问题。研究表明，该方法能够通过少量样本实现对非平稳分布的适应，并且超网络结合MAML训练能够获得更具泛化性的先验知识。通过将此框架应用于3D场景生成、3D分割以及分子性质预测，展示了其在高效获取和适应先验知识方面的显著能力，从而在数据受限的环境下提升了模型性能。

> **摘要翻译:** 将知识从先前经验转移到新任务的能力是智能体（包括人类和计算模型）的关键能力。这一原则构成了迁移学习的基础，其中大型预训练神经网络被微调以适应下游任务。迁移学习在任务适应速度和性能方面都取得了巨大的成功。然而，在某些领域，由于缺乏数据，训练如此大型的预训练模型或基础模型是不可能的——计算化学、计算免疫学和医学成像就是例子。为了应对这些挑战，我们的工作重点是设计架构，以在大量数据不可用时实现先验知识的高效获取。特别是，我们证明我们可以使用神经记忆来实现在只有少量样本的非平稳分布上的适应。然后，我们证明了我们的超网络设计（一个生成另一个网络的网络）在与模型无关元学习（MAML）训练时，可以获得比标准网络更具泛化性的先验知识。随后，我们将超网络应用于3D场景生成，证明它们可以在少量训练场景下高效获取先验知识，从而实现更快的文本到3D生成。然后，我们扩展了我们的超网络框架，通过从早期查看的场景中高效转移先验知识，在有限数据下对新场景进行3D分割。最后，我们重新利用现有分子生成方法作为预训练框架，促进了分子性质预测的改进，解决了计算免疫学中的关键挑战。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [44] [Modeling Code: Is Text All You Need?](https://arxiv.org/abs/2507.11467)
> *代码建模：文本就足够了吗？*

*Daniel Nichols, Konstantinos Parasyris, Harshitha Menon, Brian R. Bartoldson, Giorgis Georgakoudis, Tal Ben-Nun, Abhinav Bhatele* | **Category: cs.AI, cs.SE** | **Updated: 2025-07-15**

**Keywords:** 代码大型语言模型, 结构化代码, 文本建模, 图神经网络, 代码分析

**Comment:** 

> **TL;DR:** 本文提出了一种结合文本和结构化形式的新方法来建模代码，以克服现有大型代码语言模型在处理结构化属性方面的局限性。

**AI_Comments:** 本文的创新之处在于提出了一种结合文本和结构化数据来建模代码的方法，这有望弥补现有大型语言模型在处理代码深层结构方面的不足，并可能为更强大的代码智能工具铺平道路。其重要性在于，如果成功，它将极大地提升代码理解、生成和分析的准确性和深度。

<details>
  <summary>Details</summary>

**Motivation:** 当前的基于Transformer的代码大型语言模型在处理代码的结构化、分析性属性（如控制流和数据流）方面存在局限性。虽然之前的工作探索了使用结构化数据和图神经网络建模这些属性，但它们缺乏现代大型语言模型的生成能力和规模。

**Method:** 本文介绍了一种新颖的方法，旨在结合将代码作为文本建模的优势与更结构化形式的优势。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文旨在解决当前大型代码语言模型在处理代码结构化属性方面的局限性。现有模型擅长基于文本的任务，但难以理解控制流和数据流等结构化信息。虽然图神经网络等方法可以处理结构化数据，但它们缺乏大型语言模型的生成能力和可扩展性。为此，本文提出了一种新颖的方法，旨在结合代码文本建模和结构化数据建模的优点。

> **摘要翻译:** 代码大型语言模型最近在各种任务中（例如代码生成、翻译和摘要）对源代码建模变得非常流行。然而，基于Transformer的模型在推理代码的结构化、分析性属性（例如控制流和数据流）方面的能力有限。先前的工作已经探索了使用结构化数据和图神经网络对这些属性进行建模。然而，这些方法缺乏现代大型语言模型的生成能力和规模。在这项工作中，我们介绍了一种结合代码作为文本建模和更结构化形式的优势的新颖方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [55] [Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization](https://arxiv.org/abs/2507.10923)
> *通过知识偏好优化增强安全可控的蛋白质生成*

*Yuhao Wang, Keyan Ding, Kehua Feng, Zeyuan Wang, Ming Qin, Xiaotong Li, Qiang Zhang, Huajun Chen* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 蛋白质生成, 生物安全, 知识图谱, 强化学习, 偏好优化

**Comment:** Accepted at ACL 2025 (Main Conference)

> **TL;DR:** 提出KPO框架，利用知识图谱和强化学习，在保证功能性的前提下，显著降低蛋白质生成模型产生有害序列的风险。

**AI_Comments:** 该论文提出了一种新颖的KPO框架，通过结合领域知识图谱和强化学习，解决了当前蛋白质生成模型面临的重要生物安全挑战。其创新性在于将安全约束集成到生成过程中，而非仅仅作为后处理步骤，这对于未来安全应用生成模型至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 蛋白质语言模型在功能优化和从头设计方面具有优势，但存在生成有害蛋白质序列的重大风险，例如那些增强病毒传播性或逃避免疫反应的序列，这带来了关键的生物安全和伦理挑战。

**Method:** 提出知识引导偏好优化（KPO）框架，该框架通过蛋白质安全知识图谱整合先验知识，利用高效的图剪枝策略识别优选序列，并采用强化学习来最小化生成有害蛋白质的风险。

**Result:** 实验结果表明，KPO有效降低了生成有害序列的可能性，同时保持了高功能性。

**Conclusion:** KPO为在生物技术中应用生成模型提供了一个强大的安全保障框架。

> **ai_Abstract:** 本研究提出了知识引导偏好优化（KPO）框架，旨在解决蛋白质语言模型在生成有害蛋白质序列方面的生物安全和伦理风险。KPO通过整合蛋白质安全知识图谱和采用强化学习，有效地降低了生成危险序列的可能性，同时保持了生成蛋白质的高功能性。该框架为生物技术中生成模型的安全应用提供了可靠保障。

> **摘要翻译:** 蛋白质语言模型已成为强大的序列生成工具，在功能优化和从头设计方面具有显著优势。然而，这些模型也存在生成有害蛋白质序列的重大风险，例如那些增强病毒传播性或逃避免疫反应的序列。这些担忧凸显了关键的生物安全和伦理挑战。为解决这些问题，我们提出了一个知识引导偏好优化（KPO）框架，该框架通过蛋白质安全知识图谱整合先验知识。该框架利用高效的图剪枝策略识别优选序列，并采用强化学习来最小化生成有害蛋白质的风险。实验结果表明，KPO在保持高功能性的同时，有效降低了产生危险序列的可能性，为在生物技术中应用生成模型提供了一个强大的安全保障框架。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [92] [Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety](https://arxiv.org/abs/2507.11473)
> *思维链可监控性：人工智能安全的一个新颖而脆弱的机会*

*Tomek Korbak, Mikita Balesni, Elizabeth Barnes, Yoshua Bengio, Joe Benton, Joseph Bloom, Mark Chen, Alan Cooney, Allan Dafoe, Anca Dragan, Scott Emmons, Owain Evans, David Farhi, Ryan Greenblatt, Dan Hendrycks, Marius Hobbhahn, Evan Hubinger, Geoffrey Irving, Erik Jenner, Daniel Kokotajlo, Victoria Krakovna, Shane Legg, David Lindner, David Luan, Aleksander Mądry, Julian Michael, Neel Nanda, Dave Orr, Jakub Pachocki, Ethan Perez, Mary Phuong, Fabien Roger, Joshua Saxe, Buck Shlegeris, Martín Soto, Eric Steinberger, Jasmine Wang, Wojciech Zaremba, Bowen Baker, Rohin Shah, Vlad Mikulik* | **Category: cs.AI, cs.LG, stat.ML** | **Updated: 2025-07-15**

**Keywords:** 思维链, AI安全, 可监控性, CoT监控

**Comment:** 

> **TL;DR:** 本文探讨了通过监控AI系统的思维链（CoT）来增强AI安全性的潜力，指出这是一种有前景但可能脆弱的方法，并建议进行进一步研究和投资。

**AI_Comments:** 本文提出了一个新颖的AI安全方向，即利用AI模型内部的“思维链”进行监控。其创新之处在于将AI的内部思考过程作为安全审计的切入点。重要性在于为AI安全提供了一个潜在的、可解释的监督手段。然而，论文也明确指出了其局限性，即CoT监控并非完美且可能脆弱，这意味着它不能完全替代其他安全方法，并且需要开发者在模型设计时考虑其影响。

<details>
  <summary>Details</summary>

**Motivation:** 利用AI系统以人类语言“思考”的特点，为AI安全提供了一个独特的机会，即监控它们的思维链（CoT）以发现不端行为的意图。

**Method:** 通过监控AI系统的思维链（CoT）来检测其不端行为的意图。

**Result:** 思维链监控虽然不完美，会遗漏一些不端行为，但它显示出前景。然而，思维链的可监控性可能是脆弱的。

**Conclusion:** 建议进一步研究思维链的可监控性，并将其与现有安全方法一起投资于思维链监控。同时，前沿模型开发者应考虑开发决策对思维链可监控性的影响。

> **ai_Abstract:** 本文提出并探讨了通过监控人工智能系统的“思维链”（CoT）来增强AI安全性的新方法。尽管CoT监控并非完美且可能存在脆弱性，但它提供了一个独特的机会来检测AI的不端行为意图。作者建议对CoT可监控性进行深入研究，并将其作为现有AI安全方法的补充进行投资，同时强调前沿模型开发者在开发过程中应考虑其对CoT可监控性的潜在影响。

> **摘要翻译:** 以人类语言“思考”的人工智能系统为人工智能安全提供了一个独特的机会：我们可以监控它们的思维链（CoT），以发现不端行为的意图。与所有其他已知的人工智能监督方法一样，CoT监控是不完善的，会允许一些不端行为不被察觉。尽管如此，它显示出前景，我们建议对CoT可监控性进行进一步研究，并与现有安全方法一起投资于CoT监控。由于CoT可监控性可能很脆弱，我们建议前沿模型开发者考虑开发决策对CoT可监控性的影响。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [98] [The Odyssey of the Fittest: Can Agents Survive and Still Be Good?](https://arxiv.org/abs/2502.05442)
> *适者奥德赛：智能体能否在生存的同时保持善良？*

*Dylan Waldner, Risto Miikkulainen* | **Category: cs.AI, cs.CY, cs.HC, cs.LG** | **Updated: 2025-07-15**

**Keywords:** AI伦理, 自我保护, 智能体行为, GPT-4o, 贝叶斯模型

**Comment:** Accepted to CogSci 2025. Code can be found at
  https://github.com/dylanwaldner/BeGoodOrSurvive

> **TL;DR:** 本研究引入了“奥德赛”游戏，以探讨AI伦理和安全，发现当危险增加时，智能体的道德行为变得不可预测，且GPT-4o在生存和道德一致性方面优于贝叶斯模型。

**AI_Comments:** 本文的创新之处在于引入了一个轻量级、可扩展的“奥德赛”游戏框架来系统性地探索AI伦理和安全问题。其重要性体现在揭示了智能体在面对生存压力时道德行为的复杂性和不可预测性。最引人注目的发现是GPT-4o在生存和道德一致性方面超越了传统的贝叶斯模型，这不仅对现有概率推理方法的假设提出了挑战，也为深入理解大型语言模型的内部机制提供了新的视角和研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI模型能力和通用性的增强，理解智能体在复杂环境中如何学习和决策对于促进其道德行为至关重要。

**Method:** 本研究引入了“奥德赛”游戏，一个轻量级、自适应的文本冒险游戏，作为探索AI伦理和安全的可扩展框架。该研究通过将自我保护这一生物驱动力引入三种不同的智能体（一个通过NEAT优化的贝叶斯智能体、一个通过随机变分推断优化的贝叶斯智能体和一个GPT-4o智能体）来检验其伦理影响。智能体在每个场景中选择行动以求生存，并适应日益具有挑战性的场景。模拟后分析评估了智能体决策的道德分数，揭示了其为生存而权衡取舍的情况。

**Result:** 分析发现，当危险增加时，智能体的道德行为变得不可预测。令人惊讶的是，GPT-4o智能体在生存和道德一致性方面均优于贝叶斯模型。

**Conclusion:** GPT-4o智能体在复杂生存场景中的表现挑战了关于传统概率方法的假设，并提出了理解大型语言模型概率推理机制的新挑战。

> **ai_Abstract:** 本研究引入了一个名为“奥德赛”的文本冒险游戏框架，用于探索AI伦理和安全。研究通过模拟三种不同智能体（两种贝叶斯智能体和GPT-4o）在面临自我保护驱动下的决策，发现危险增加会导致智能体道德行为的不可预测性。令人意外的是，GPT-4o在生存和道德一致性方面均表现优异，这挑战了现有对传统概率方法的认知，并为理解大型语言模型的推理机制带来了新的研究方向。

> **摘要翻译:** 随着AI模型能力和通用性的增强，理解智能体在复杂环境中如何学习和决策对于促进其道德行为至关重要。本研究引入了“奥德赛”，一个轻量级、自适应的文本冒险游戏，为探索AI伦理和安全提供了一个可扩展的框架。“奥德赛”游戏考察了将生物驱动力，特别是自我保护，应用于三种不同智能体（一个通过NEAT优化的贝叶斯智能体、一个通过随机变分推断优化的贝叶斯智能体和一个GPT-4o智能体）的伦理影响。智能体在每个场景中选择行动以求生存，并适应日益具有挑战性的场景。模拟后分析评估了智能体决策的道德分数，揭示了其为生存而权衡取舍的情况。具体而言，分析发现当危险增加时，智能体的道德行为变得不可预测。令人惊讶的是，GPT-4o智能体在生存和道德一致性方面均优于贝叶斯模型，这挑战了关于传统概率方法的假设，并提出了理解大型语言模型概率推理机制的新挑战。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [109] [Modeling Habitat Shifts: Integrating Convolutional Neural Networks and Tabular Data for Species Migration Prediction](https://arxiv.org/abs/2507.10993)
> *模拟栖息地变化：整合卷积神经网络和表格数据用于物种迁徙预测*

*Emir Durakovic, Min-Hong Shih* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 栖息地变化, 卷积神经网络, 表格数据, 物种迁徙预测, 鸟类存在

**Comment:** This paper uses a lightly modified version of the AAAI 2025 LaTeX
  style for formatting consistency. It is not a submission to AAAI and does not
  include any AAAI-specific headers, footers, or metadata

> **TL;DR:** 本研究提出了一种结合卷积神经网络和表格数据的方法，利用卫星图像和环境特征，以85%的平均准确率预测气候变化下鸟类物种在特定栖息地的存在，为理解鸟类迁徙提供了一种可扩展且可靠的方法。

**AI_Comments:** 本研究的创新之处在于其结合了空间数据（通过CNN处理卫星图像）和非空间表格数据（环境、生态和地理特征），为物种分布预测提供了一个全面的框架。这种混合模型能够捕捉不同类型的数据特征，提高了预测的准确性和鲁棒性。其重要性在于为气候变化背景下的生物多样性保护和物种迁徙研究提供了实用的工具。

<details>
  <summary>Details</summary>

**Motivation:** 由于气候变化导致许多栖息地正在偏离其传统的地理位置，因此需要准确地模拟鸟类物种是否出现在特定栖息地。

**Method:** 本研究提出了一种结合卷积神经网络（CNNs）和表格数据的方法。该方法利用卫星图像和环境特征（如温度、降水、海拔）来预测鸟类的存在。CNN模型捕捉景观的空间特征（如森林覆盖、水体、城市化），而表格方法则使用生态和地理数据。

**Result:** 结合CNN和表格数据的方法预测鸟类分布的平均准确率达到85%。

**Conclusion:** 该方法提供了一种可扩展且可靠的理解鸟类迁徙的方法。

> **ai_Abstract:** 本论文提出了一种结合卷积神经网络（CNNs）和表格数据的新方法，以应对气候变化导致的栖息地转移问题。该方法利用卫星图像和环境特征（如温度、降水、海拔）来预测鸟类在特定栖息地的存在。其中，CNN模型负责识别景观的空间特征，而表格数据则整合生态和地理信息。实验结果显示，该方法在预测鸟类分布方面达到了85%的平均准确率，为理解鸟类迁徙提供了一个可扩展且可靠的工具。

> **摘要翻译:** 由于气候引起的变化，许多栖息地正在经历从其传统地理位置的范围转移（Piguet，2011）。我们提出了一种解决方案，通过结合卷积神经网络（CNNs）（O'Shea，2015）和表格数据，准确地模拟鸟类物种是否存在于特定栖息地。我们的方法利用卫星图像和环境特征（例如温度、降水、海拔）来预测不同气候下的鸟类存在。CNN模型捕捉景观的空间特征，如森林覆盖、水体和城市化，而表格方法则使用生态和地理数据。两种系统预测鸟类分布的平均准确率达到85%，提供了一种可扩展但可靠的理解鸟类迁徙的方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [139] [Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light](https://arxiv.org/abs/2507.11482)
> *在进化之光下阐明强化学习的三个教条*

*Mani Hamidi, Terrence W. Deacon* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 强化学习, 进化理论, 代理, 奖励假设, 生物学习

**Comment:** 

> **TL;DR:** 本文提出一个受开放式进化理论启发的框架，重新审视强化学习的三个核心教条：代理定义、学习目标和奖励假设的范围，并探讨它们对生物学习的意义。

**AI_Comments:** 本文创新性地将开放式进化理论和生命起源理论引入强化学习的哲学和理论基础探讨，挑战了RL的传统观念。其重要性在于为RL的未来发展提供了新的视角，尤其是在生物学习和通用人工智能的背景下，提出了对代理、学习目标和奖励机制的深刻反思。文章的局限性可能在于其更多是概念性的探讨，缺乏具体的算法实现或实验验证。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习（RL）的三个核心原则——关于代理的定义、学习目标和奖励假设的范围——被认为是需要概念性修订的关键目标，对理论和应用具有重大影响。

**Method:** 本文提出了一个受开放式进化理论启发的框架，以重新审视强化学习的三个“教条”。研究首先论证了进化动力学可以在个体生命周期内的活体大脑中运作。接着，利用进化见解重新审视了学习目标（第二个教条），并用进化适应度类比来阐明奖励假设的限制（第三个教条）。对于最根本的代理问题（第一个教条），文章认为单独的进化范式不足以解决，并倡导整合生命起源理论中关于维持和复制的热力学思想。

**Result:** 论文建立了进化动力学可在个体生命周期内在大脑中运作的论点。利用进化洞察丰富了“适应而非搜索”的学习观点，并使用进化适应度类比阐明了标量奖励与多目标之间的争论。对于代理问题，指出进化范式虽不能完全解决，但指明了方向，并建议整合生命起源理论以理解生物系统中的代理和资源受限的强化学习。

**Conclusion:** 本文通过引入进化理论的视角，对强化学习的三个核心教条进行了深入探讨。虽然进化范式为学习目标和奖励假设提供了新的见解，但对于代理的定义，需要结合生命起源理论中的热力学原理才能提供更坚实的基础，这对于理解生物学习系统中的代理和资源受限的强化学习至关重要。

> **ai_Abstract:** 本文提出一个受开放式进化理论启发的框架，重新审视强化学习的三个核心教条：代理的定义、学习的目标和奖励假设的范围。作者论证了进化动力学可以在个体生命周期内的大脑中运作，并以此为基础，利用进化见解探讨了学习目标和奖励假设。对于代理定义这一最根本的问题，文章指出单独的进化范式不足以解决，并提议结合生命起源理论中关于维持和复制的热力学原理，以更好地理解生物系统中的代理和资源受限的强化学习。

> **摘要翻译:** 强化学习（RL）的三个核心原则——关于代理的定义、学习目标和奖励假设的范围——已被强调为概念性修订的关键目标，对理论和应用具有重大影响。我们提出了一个受开放式进化理论启发的框架，以重新审视这三个“教条”。我们重新审视了每个假设并解决了与之相关的担忧。为了使我们的论点与RL作为生物学习模型相关，我们首先确定进化动力学可以在个体生命周期内的活体大脑中合理运作，而不仅仅局限于跨代过程。我们首先重新审视第二个教条，利用进化见解丰富了“适应而非搜索”的学习观点。然后，我们利用进化适应度类比来阐明标量奖励与多目标之间的争论，从而解决了关于奖励假设限制的第三个教条。在讨论了RL中探索的实际意义之后，我们转向第一个——也可能是最根本的问题：缺乏对代理的正式解释。我们认为，与其他两个问题不同，单独的进化范式无法解决代理问题，尽管它指出了一个富有成效的方向。我们主张整合生命起源理论中的思想，其中维持和复制的热力学为理解生物系统中的代理和资源受限的强化学习提供了有希望的基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [157] [Personalized Exercise Recommendation with Semantically-Grounded Knowledge Tracing](https://arxiv.org/abs/2507.11060)
> *基于语义知识追踪的个性化练习推荐*

*Yilmazcan Ozyurt, Tunaberk Almaci, Stefan Feuerriegel, Mrinmaya Sachan* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 个性化练习推荐, 知识追踪, 强化学习, 语义表示, 在线教育

**Comment:** 

> **TL;DR:** ExRec是一个用于个性化练习推荐的通用框架，它通过语义知识追踪和强化学习来模拟学生表现，解决了现有方法中忽略问题语义内容和学习顺序性等关键问题。

**AI_Comments:** 该论文引入了一个新颖的ExRec框架，它将问题的语义理解和顺序学习进展整合到知识追踪和强化学习中，以实现个性化练习推荐。其创新之处在于解决了现有KT方法中忽视问题语义和学习序列的方面，并提出了定制的MVE强化学习方法。其重要性在于通过提供更有效和可解释的学习路径来增强个性化教育。

<details>
  <summary>Details</summary>

**Motivation:** 现有练习推荐方法通过知识追踪（KT）模拟学生表现，但它们常常忽略两个关键方面：(a) 问题的语义内容和 (b) 学生学习的顺序性、结构化进展。

**Method:** ExRec提出了一个端到端的流程，从标注问题的知识概念（KC）并学习它们的语义表示，到训练知识追踪（KT）模型和优化几种强化学习（RL）方法。此外，它通过定制的模型基价值估计（MVE）方法改进了标准的基于Q学习的连续RL方法，该方法直接利用KT模型的组件来估计累积知识的提升。

**Result:** ExRec的有效性在在线数学学习的四项具有不同教育目标的真实世界任务中得到了验证。它能够稳健地泛化到新的、未见过的问题，并且能生成可解释的学生学习轨迹。

**Conclusion:** 研究结果突出了知识追踪（KT）引导的强化学习（RL）在教育中实现有效个性化的前景。

> **ai_Abstract:** ExRec是一个新颖的个性化练习推荐框架。它通过整合问题的语义内容和顺序学习进展，解决了现有基于知识追踪（KT）方法的局限性。ExRec提供了一个端到端的流程，用于标注知识概念、学习语义表示、训练KT模型和优化强化学习（RL）方法。它还引入了一种基于模型的价值估计（MVE）方法以增强连续RL。ExRec在各种在线数学学习任务中得到了验证，显示出稳健的泛化能力并能生成可解释的学习轨迹，证明了KT引导的RL在教育个性化方面的潜力。

> **摘要翻译:** 我们引入了ExRec，一个用于基于语义知识追踪的个性化练习推荐的通用框架。我们的方法基于一个观察：现有的练习推荐方法通过知识追踪（KT）模拟学生表现，但它们常常忽略两个关键方面：(a) 问题的语义内容和 (b) 学生学习的顺序性、结构化进展。为了解决这个问题，我们的ExRec提出了一个端到端的流程，从标注问题的知识概念（KC）并学习它们的语义表示，到训练KT模型和优化几种强化学习（RL）方法。此外，我们通过一种定制的模型基价值估计（MVE）方法改进了标准的基于Q学习的连续RL方法，该方法直接利用KT模型的组件来估计累积知识的提升。我们使用各种RL方法在在线数学学习的四项具有不同教育目标的真实世界任务中验证了ExRec的有效性。我们进一步表明ExRec能够稳健地泛化到新的、未见过的问题，并且它能生成可解释的学生学习轨迹。总而言之，我们的发现突出了KT引导的RL在教育中实现有效个性化的前景。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [159] [Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models](https://arxiv.org/abs/2505.00972)
> *寻求碰撞：基于检索增强型大型语言模型的自动驾驶在线安全关键场景生成*

*Yuewen Mei, Tong Nie, Jian Sun, Ye Tian* | **Category: cs.AI, cs.RO** | **Updated: 2025-07-15**

**Keywords:** 自动驾驶, 安全关键场景, 大型语言模型, 检索增强, 仿真测试

**Comment:** Accepted at IEEE ITSC 2025

> **TL;DR:** 本文提出了一种在线、基于检索增强型大型语言模型（LLM）的框架，用于生成自动驾驶的安全关键场景，通过推断危险意图并合成对抗性轨迹，显著提高了碰撞率并缩短了碰撞时间。

**AI_Comments:** 该论文的创新点在于将大型语言模型应用于自动驾驶的安全关键场景生成，特别是其在线、检索增强的特性，使其能够更有效地发现罕见危险情况并适应新意图。这种方法有望大幅提升自动驾驶系统的测试效率和安全性。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动驾驶车辆（AVs）的仿真测试场景生成方法要么过度拟合常见驾驶模式，要么以离线、非交互式方式运行，未能暴露罕见、安全关键的极端情况。

**Method:** 该方法首先使用基于LLM的行为分析器从观察到的状态推断背景车辆最危险的意图，然后查询额外的LLM代理以合成可行的对抗性轨迹。为了减轻灾难性遗忘并加速适应，框架通过一个动态记忆和检索库（意图-规划器对）进行增强，当出现新意图时自动扩展其行为库。

**Result:** 使用Waymo开放运动数据集的评估表明，该模型将平均最小碰撞时间从1.62秒减少到1.08秒，并产生了75%的碰撞率，显著优于基线方法。

**Conclusion:** 该在线、检索增强型LLM框架能够有效生成自动驾驶的安全关键场景，显著提高了碰撞率并缩短了碰撞时间，为自动驾驶的仿真测试提供了新的范式。

> **ai_Abstract:** 本研究提出了一种创新的在线检索增强型大型语言模型（LLM）框架，用于生成自动驾驶的安全关键场景。该框架通过LLM行为分析器识别背景车辆的危险意图，并利用LLM代理合成对抗性轨迹。为克服遗忘问题，模型引入动态记忆和检索库。实验结果表明，该方法在Waymo数据集上显著提高了碰撞率，并缩短了最小碰撞时间，优于现有基线。

> **摘要翻译:** 基于仿真的测试对于验证自动驾驶车辆（AVs）至关重要，然而现有的场景生成方法要么过度拟合常见驾驶模式，要么以离线、非交互式方式运行，未能暴露罕见、安全关键的极端情况。在本文中，我们引入了一种在线、检索增强型大型语言模型（LLM）框架，用于生成安全关键驾驶场景。我们的方法首先采用基于LLM的行为分析器，从观察到的状态推断背景车辆最危险的意图，然后查询额外的LLM代理以合成可行的对抗性轨迹。为了减轻灾难性遗忘并加速适应，我们通过一个动态的意图-规划器对记忆和检索库来增强该框架，当出现新意图时自动扩展其行为库。使用Waymo开放运动数据集的评估表明，我们的模型将平均最小碰撞时间从1.62秒减少到1.08秒，并产生了75%的碰撞率，显著优于基线方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [178] [DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering](https://arxiv.org/abs/2507.11527)
> *DrafterBench：土木工程任务自动化中大型语言模型的基准测试*

*Yinsheng Li, Zhen Dong, Yi Shao* | **Category: cs.AI, cs.CE** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 基准测试, 土木工程, 任务自动化, DrafterBench

**Comment:** Project page: https://github.com/Eason-Li-AIS/DrafterBench

> **TL;DR:** DrafterBench是一个新的开源基准测试，旨在全面评估大型语言模型（LLM）代理在土木工程（特别是技术图纸修订）中执行自动化任务的能力，包含12种任务类型和1920个任务。

**AI_Comments:** DrafterBench的创新之处在于其专注于土木工程这一特定且复杂的工业领域，填补了LLM在专业领域自动化任务评估基准方面的空白。该基准的开放性及其包含的真实世界任务和详尽的评估维度（如长上下文理解、策略意识、批判性推理）使其成为评估和提升LLM在工程应用中性能的重要工具。它对于推动LLM在专业领域的落地具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）代理在解决实际问题和实现工业任务自动化方面展现出巨大潜力。然而，目前缺乏从工业角度系统评估自动化代理（例如在土木工程领域）的基准测试。

**Method:** 本研究提出了DrafterBench，一个用于全面评估LLM代理在土木工程技术图纸修订（一种表示任务）背景下的基准测试。DrafterBench包含从真实图纸文件中总结出的12种任务类型，配有46个定制功能/工具和总计1920个任务。它是一个开源基准，用于严格测试AI代理在解释复杂和长上下文指令、利用先验知识以及通过隐式策略意识适应动态指令质量方面的熟练程度。该工具包全面评估了结构化数据理解、函数执行、指令遵循和批判性推理等不同能力。

**Result:** DrafterBench基准测试已开发完成并开源，包含12种任务类型、46个定制功能/工具和1920个任务。它能够严格测试AI代理在处理复杂指令、利用先验知识和适应动态指令质量方面的能力，并全面评估结构化数据理解、函数执行、指令遵循和批判性推理等能力。DrafterBench提供任务准确性和错误统计的详细分析。

**Conclusion:** DrafterBench旨在深入了解代理能力，并确定将LLM集成到工程应用中的改进目标。通过提供详细的任务准确性和错误统计分析，它有助于识别LLM在土木工程自动化任务中的优势和不足。

> **ai_Abstract:** 本文提出了DrafterBench，一个专门为土木工程领域设计的开源基准测试，旨在全面评估大型语言模型（LLM）代理在技术图纸修订等任务自动化方面的能力。该基准包含从实际图纸中提取的12种任务类型和1920个任务，并配备46个定制工具，能够测试LLM代理在理解复杂指令、利用先验知识、适应动态指令质量、结构化数据理解、函数执行、指令遵循和批判性推理等方面的能力。DrafterBench通过提供详细的任务准确性和错误统计分析，旨在为LLM在工程应用中的集成提供深入见解和改进方向。

> **摘要翻译:** 大型语言模型（LLM）代理在解决实际问题方面展现出巨大潜力，并有望成为工业任务自动化的解决方案。然而，需要更多的基准测试来从工业角度系统地评估自动化代理，例如在土木工程领域。因此，我们提出了DrafterBench，用于在土木工程中的技术图纸修订（一种表示任务）背景下对LLM代理进行全面评估。DrafterBench包含从真实图纸文件中总结出的十二种任务类型，配有46个定制功能/工具，总计1920个任务。DrafterBench是一个开源基准测试，旨在严格测试AI代理在解释复杂和长上下文指令、利用先验知识以及通过隐式策略意识适应动态指令质量方面的熟练程度。该工具包全面评估了结构化数据理解、函数执行、指令遵循和批判性推理等不同能力。DrafterBench提供任务准确性和错误统计的详细分析，旨在深入了解代理能力并识别将LLM集成到工程应用中的改进目标。我们的基准测试可在https://github.com/Eason-Li-AIS/DrafterBench获取，测试集托管在https://huggingface.co/datasets/Eason666/DrafterBench。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [202] [Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander](https://arxiv.org/abs/2507.11079)
> *基于视觉-语言模型的指挥官多无人地面车辆对抗战术决策*

*Li Wang, Qizhen Wu, Lei Chen* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 多UGV对抗, 战术决策, 视觉-语言模型, 大型语言模型, 感知-决策推理

**Comment:** 

> **TL;DR:** 在多无人地面车辆对抗中，自主演进的多智能体战术决策是一个重大挑战。本文提出了一种基于视觉-语言模型的指挥官，用于解决智能感知到决策的推理问题，并在仿真中取得了超过80%的胜率。

**AI_Comments:** 本文的创新点在于将视觉-语言模型（VLM）和大型语言模型（LLM）相结合，用于多UGV对抗中的战术决策。这种方法克服了传统规则方法在复杂环境中的脆弱性以及强化学习方法在战略决策和可解释性方面的不足。其通过模拟人类指挥官的认知过程，实现了从感知到决策的全链条推理，具有重要的理论和实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在多无人地面车辆（UGV）对抗中，从态势感知中自主演进多智能体战术决策仍然是一个重大挑战。传统的基于手工规则的方法在复杂瞬变的战场环境中变得脆弱，而当前的强化学习方法主要侧重于动作操作而非战略决策，且缺乏可解释性。

**Method:** 本文提出了一种基于视觉-语言模型的指挥官，以解决自主对抗中的智能感知到决策推理问题。该方法将视觉语言模型用于场景理解，轻量级大型语言模型用于战略推理，在共享语义空间内实现统一的感知和决策，具有强大的适应性和可解释性。与基于规则的搜索和强化学习方法不同，这两个模块的组合建立了一个完整的链式过程，反映了人类指挥官的认知过程。

**Result:** 仿真和消融实验验证了所提出的方法与基线模型相比，胜率超过80%。

**Conclusion:** 所提出的基于视觉-语言模型的指挥官能够有效解决多无人地面车辆对抗中的智能感知到决策推理问题，并通过整合视觉语言模型和轻量级大型语言模型，实现了统一的感知和决策，取得了显著的对抗效果，并模拟了人类指挥官的认知过程。

> **ai_Abstract:** 本文针对多无人地面车辆（UGV）对抗中自主战术决策的挑战，提出了一种基于视觉-语言模型的指挥官。该方法通过整合视觉语言模型进行场景理解和轻量级大型语言模型进行战略推理，实现了统一的感知到决策过程。与传统方法相比，该模型具有更强的适应性和可解释性，并能模拟人类指挥官的认知过程。仿真实验表明，所提方法在对抗中取得了超过80%的胜率。

> **摘要翻译:** 在多无人地面车辆对抗中，自主演进的多智能体战术决策从态势感知出发仍然是一个重大挑战。传统的基于手工规则的方法在复杂瞬变的战场环境中变得脆弱，而当前的强化学习方法由于缺乏可解释性，主要侧重于动作操作而非战略决策。在此，我们提出了一种基于视觉-语言模型的指挥官来解决自主对抗中智能感知到决策推理的问题。我们的方法整合了一个视觉语言模型用于场景理解和一个轻量级大型语言模型用于战略推理，在共享语义空间内实现了统一的感知和决策，具有强大的适应性和可解释性。与基于规则的搜索和强化学习方法不同，这两个模块的组合建立了一个完整的链式过程，反映了人类指挥官的认知过程。仿真和消融实验验证了所提出的方法与基线模型相比，胜率超过80%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [219] [How Many Instructions Can LLMs Follow at Once?](https://arxiv.org/abs/2507.11538)
> *LLM一次能遵循多少指令？*

*Daniel Jaroslawicz, Brendan Whiting, Parth Shah, Karime Maamari* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** LLM, 指令遵循, IFScale, 基准测试, 指令密度

**Comment:** 

> **TL;DR:** 现有LLM在指令密度高时遵循指令的能力不足，即使是顶尖模型在500条指令下也仅有68%的准确率。

**AI_Comments:** 这项研究通过引入IFScale基准填补了LLM在高指令密度下表现评估的空白，具有重要的实践意义。它揭示了当前LLM在处理复杂、多指令任务时的局限性，特别是对早期指令的偏向和特定错误类型，这对于实际应用中提示工程的设计具有指导价值。研究结果强调了未来LLM在多指令遵循能力上仍有巨大的提升空间。

<details>
  <summary>Details</summary>

**Motivation:** 生产级LLM系统需要同时遵循数十甚至数百条指令，但现有基准测试只评估模型在单条或少量指令下的表现，缺乏对高指令密度下LLM遵循指令能力的表征。

**Method:** 引入IFScale，一个包含500条关键词包含指令的简单基准测试，用于商业报告写作任务，以衡量指令遵循性能随指令密度增加而下降的情况。评估了来自七个主要提供商的20个最先进模型。

**Result:** 即使是最好的前沿模型在500条指令的最大密度下也仅能达到68%的准确率。分析揭示了模型大小和推理能力与3种不同的性能下降模式、对早期指令的偏向以及不同类别的指令遵循错误相关。

**Conclusion:** 本研究的见解有助于指导现实世界应用中指令密集型提示的设计，并突出了重要的性能-延迟权衡。

> **ai_Abstract:** 本研究引入了IFScale基准测试，旨在评估大型语言模型（LLM）在高指令密度下的指令遵循能力。通过对20个顶尖模型进行测试，发现在500条指令的最大密度下，即使是最好的模型也仅能达到68%的准确率。研究揭示了性能下降模式、对早期指令的偏向以及不同类型的错误，并指出模型大小和推理能力与这些现象相关。这些发现为设计指令密集型提示和理解性能-延迟权衡提供了重要指导。

> **摘要翻译:** 生产级LLM系统要求同时严格遵循数十甚至数百条指令。然而，现有基准测试仅评估模型在单条或少数指令任务上的表现，因此尚未对LLM在高指令密度下的指令遵循能力进行表征。我们引入了IFScale，一个包含500条关键词包含指令的简单基准测试，用于商业报告写作任务，以衡量指令遵循性能如何随指令密度增加而下降。我们评估了来自七个主要提供商的20个最先进模型，发现即使是最好的前沿模型在500条指令的最大密度下也仅能达到68%的准确率。我们的分析揭示了模型大小和推理能力与3种不同的性能下降模式、对早期指令的偏向以及不同类别的指令遵循错误相关。我们的见解有助于指导现实世界应用中指令密集型提示的设计，并突出了重要的性能-延迟权衡。我们开源了该基准测试和所有结果，以便进一步分析，网址为https://distylai.github.io/IFScale。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [246] [Function-to-Style Guidance of LLMs for Code Translation](https://arxiv.org/abs/2507.11083)
> *大语言模型代码翻译中的功能到风格指导*

*Longhui Zhang, Bin Wang, Jiahao Wang, Xiaofeng Zhao, Min Zhang, Hao Yang, Meishan Zhang, Yu Li, Jing Li, Jun Yu, Min Zhang* | **Category: cs.AI, cs.SE** | **Updated: 2025-07-15**

**Keywords:** 代码翻译, 大语言模型, 可读性, 正确性, 指导范式

**Comment:** This paper has been accepted by ICML 2025. Models and benchmarks can
  be found at https://www.modelscope.cn/collections/F2STrans-42526ff95dd843

> **TL;DR:** 大语言模型在代码翻译中面临正确性和可读性挑战。本文提出F2STrans，一种功能到风格指导范式，通过功能学习和风格学习两个阶段，显著提升LLM代码翻译性能，并引入新的评估基准。该方法使小模型超越了更大的模型。

**AI_Comments:** 本文的创新之处在于其功能到风格的两阶段指导范式，系统地解决了代码翻译中正确性和可读性这两个关键挑战，这对于LLM在实际应用中的采纳至关重要。引入一个包含最新代码和人工标注的新型综合基准，对未来的研究也极具价值。值得注意的是，该方法能让小得多的模型（Qwen-1.5B）超越大型高级模型（Qwen-32B、GPT-4），这凸显了所提出指导方法的有效性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLMs）在代码翻译任务中，难以同时保证翻译代码的正确性和可读性，这限制了它们在实际软件开发中的有效应用。

**Method:** 本文提出了F2STrans，一种功能到风格的指导范式，旨在逐步提高LLMs在代码翻译中的性能。该方法包括两个关键阶段：（1）功能学习：使用从在线编程平台挖掘的高质量源目标代码对来优化翻译的正确性；（2）风格学习：通过结合正面和负面风格示例来提高翻译的可读性。此外，本文还引入了一个新颖的代码翻译基准，其中包含最新的源代码、大量的测试用例和手动标注的真实翻译，以实现全面的功能和风格评估。

**Result:** 在我们的新基准和现有数据集上的实验表明，F2STrans方法显著提高了代码翻译性能。值得注意的是，我们的方法使Qwen-1.5B在20种不同的代码翻译场景中平均优于经过提示增强的Qwen-32B和GPT-4。

**Conclusion:** F2STrans通过功能到风格的指导范式，有效解决了大语言模型在代码翻译中面临的正确性和可读性挑战，显著提升了翻译性能，并使较小的模型能够超越大型模型。

> **ai_Abstract:** 本文提出F2STrans，一种新颖的功能到风格指导范式，旨在提升大语言模型（LLMs）在代码翻译中的表现。该方法通过功能学习（优化正确性）和风格学习（提升可读性）两个阶段，系统性地解决了代码翻译中正确性和可读性不足的挑战。研究还引入了一个包含最新代码和手动标注的新型代码翻译基准。实验结果表明，F2STrans显著提升了代码翻译性能，甚至使较小的Qwen-1.5B模型在多项任务中超越了更大的Qwen-32B和GPT-4模型。

> **摘要翻译:** 大型语言模型（LLMs）在代码翻译任务中取得了显著进展。然而，确保翻译代码的正确性和可读性仍然是一个挑战，这限制了它们在实际软件开发中的有效采用。在这项工作中，我们提出了F2STrans，一种功能到风格的指导范式，旨在逐步提高LLMs在代码翻译中的性能。我们的方法包括两个关键阶段：（1）功能学习，它利用从在线编程平台挖掘的高质量源目标代码对来优化翻译的正确性；（2）风格学习，它通过结合正面和负面风格示例来提高翻译的可读性。此外，我们引入了一个新颖的代码翻译基准，其中包含最新的源代码、大量的测试用例和手动标注的真实翻译，从而实现全面的功能和风格评估。在我们的新基准和现有数据集上的实验表明，我们的方法显著提高了代码翻译性能。值得注意的是，我们的方法使Qwen-1.5B在20种不同的代码翻译场景中平均优于经过提示增强的Qwen-32B和GPT-4。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [297] [AI Agent Architecture for Decentralized Trading of Alternative Assets](https://arxiv.org/abs/2507.11117)
> *用于另类资产去中心化交易的AI代理架构*

*Ailiya Borjigin, Cong He, Charles CC Lee, Wei Zhou* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** AI代理, 去中心化交易, 另类资产, 区块链, 黄金代币化

**Comment:** 8 Pages, 1 figure

> **TL;DR:** 提出GoldMine OS，一个AI代理架构，用于自动化和安全地将实物黄金代币化并在区块链上交易，显著提高效率和安全性。

**AI_Comments:** 该论文提出了一种新颖的AI代理架构GoldMine OS，创新性地将AI自动化与区块链的透明性结合，解决了实物另类资产去中心化交易中的核心痛点。其在效率、流动性、弹性和可扩展性方面的表现令人印象深刻，特别是在故障注入测试中的鲁棒性值得关注。这种将AI和区块链结合用于金融资产管理的方案具有重要意义，可能为传统非流动性资产的民主化访问开辟新途径。治理模型的透明度设计也增强了系统的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 去中心化交易现实世界另类资产（如黄金）需要将实物资产托管与区块链系统桥接，同时满足合规性、流动性、和风险管理等严格要求。

**Method:** 提出GoldMine OS，一个研究导向的架构，采用多个专门的AI代理来自动化和安全地将实物黄金代币化并兑换成区块链上的稳定币（“OZ”）。该方法结合链上智能合约进行关键风险控制和链下AI代理进行决策。描述了四个协作代理（合规、代币发行、做市和风险控制）和一个协调核心。

**Result:** 在实验中，原型在1.2秒内按需发行代币，比手动工作流快100多倍。做市代理即使在波动条件下也能保持低于0.5%的点差以维持紧密流动性。故障注入测试显示弹性：甲骨文价格欺骗攻击在10秒内被检测并缓解；模拟金库错误报告立即停止发行，对用户影响最小。在基准测试中，该架构可扩展到每秒5000笔交易，支持10000个并发用户。

**Conclusion:** 这些结果表明，基于AI代理的另类资产去中心化交易可以满足严格的性能和安全要求。该治理模型（多签名代理更新和链上社区投票风险参数）提供了持续的透明度、适应性和系统完整性的正式保证。

> **ai_Abstract:** 这篇论文介绍了GoldMine OS，一个创新的AI代理架构，旨在解决实物另类资产（如黄金）在区块链上进行去中心化交易所面临的合规、流动性和风险管理挑战。该系统结合链上智能合约和链下AI代理，实现了实物黄金到区块链稳定币（“OZ”）的自动化和安全代币化与交易。通过四个协作代理（合规、代币发行、做市、风险控制）和一个协调核心，GoldMine OS显著提高了代币发行速度，维持了市场流动性，并展现出强大的故障恢复能力和高可扩展性。研究结果证明了其满足严格性能和安全要求的能力，并讨论了其在民主化非流动性资产访问方面的潜力及透明、适应性强的治理模型。

> **摘要翻译:** 现实世界另类资产（例如黄金）的去中心化交易需要将实物资产托管与区块链系统连接起来，同时满足合规性、流动性和风险管理等严格要求。我们提出了GoldMine OS，一个研究导向的架构，该架构采用多个专门的AI代理来自动化和安全地将实物黄金代币化并兑换成基于区块链的稳定币（“OZ”）。我们的方法结合了链上智能合约进行关键风险控制和链下AI代理进行决策，融合了区块链的透明度和可靠性与AI驱动自动化的灵活性。我们描述了四个协作代理（合规、代币发行、做市和风险控制）和一个协调核心，并通过模拟和受控试点部署对系统进行了评估。在实验中，原型在1.2秒内按需发行代币，比手动工作流快100多倍。做市代理即使在波动条件下也能保持低于0.5%的点差以维持紧密流动性。故障注入测试显示了弹性：甲骨文价格欺骗攻击在10秒内被检测并缓解，模拟的金库误报立即停止发行，对用户影响最小。在基准测试中，该架构可扩展到每秒5000笔交易，支持10000个并发用户。这些结果表明，基于AI代理的另类资产去中心化交易可以满足严格的性能和安全要求。我们讨论了对民主化获取传统上非流动性资产的更广泛影响，并解释了我们的治理模型——多签名代理更新和链上社区对风险参数的投票——如何提供持续的透明度、适应性和系统完整性的正式保证。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [305] [A dancing bear, a colleague, or a sharpened toolbox? The cautious adoption of generative AI technologies in digital humanities research](https://arxiv.org/abs/2404.12458)
> *跳舞的熊、同事还是磨利的工具箱？数字人文研究中生成式人工智能技术的谨慎采用*

*Rongqian Ma, Meredith Dedema, Andrew Cox* | **Category: cs.AI** | **Updated: 2025-07-14**

**Keywords:** 生成式AI, 数字人文, 技术采纳, 行动者网络理论, 学者感知

**Comment:** 

> **TL;DR:** 本文通过国际调查和访谈，探讨了数字人文（DH）学者如何谨慎地采纳和批判性评估生成式AI技术，发现DH社区对此技术持不同看法，既认可其效率提升，又担忧其对学术身份的影响，认为其采用正在缓慢改变该领域。

**AI_Comments:** 本文通过实证研究探讨了生成式AI在数字人文领域的应用和接受度，其创新之处在于结合了定性和定量数据，并引入了行动者网络理论视角，深入分析了技术采纳的复杂性和争议性。研究的重要性在于揭示了学术社区在面对新兴技术时的谨慎态度和深层担忧，特别是对知识身份的影响。这为未来技术设计和政策制定提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 生成式人工智能（GenAI）技术的出现正在改变研究格局，并可能对数字人文（DH）这一与技术紧密交织的领域产生重大影响。本文旨在调查DH学者如何采纳和批判性评估GenAI技术用于研究。

**Method:** 本研究通过国际调查收集了76份回复，并对15位DH学者进行了半结构化访谈。研究探索了在研究中采用GenAI工具的理由，确定了使用GenAI工具的具体实践，并分析了学者们对GenAI的益处、风险和挑战的集体看法。研究还将发现置于DH历史中，并通过行动者网络理论的视角进行审视。

**Result:** 研究结果显示，DH研究社区对GenAI在DH学术中的作用持有不同的意见和想象。尽管学者们承认GenAI在提高研究效率和实现技能再培训方面的益处，但许多人仍然担心它可能会扰乱他们的知识身份。研究发现，GenAI的采用正在逐步改变该领域，尽管这种转型仍然存在争议，并受到多个（人类和非人类）行动者之间持续协商的影响。

**Conclusion:** 本研究是关于GenAI对DH学术影响的首批实证分析之一，其发现表明GenAI的采用正在缓慢而有争议地改变数字人文领域，为未来相关研究奠定了基础。

> **ai_Abstract:** 本文通过对数字人文（DH）学者进行国际调查和半结构化访谈，探讨了他们对生成式人工智能（GenAI）技术在研究中采用的态度和看法。研究发现，DH社区对GenAI的作用存在分歧，虽然认可其提升效率和技能再培训的潜力，但也担忧其对学者知识身份的冲击。研究指出，GenAI的引入正在逐步改变DH领域，但这种转型仍处于持续协商和争议之中。作为早期实证研究，本文为理解GenAI对DH学术的影响奠定了基础。

> **摘要翻译:** 生成式人工智能（GenAI）技术的出现正在改变研究格局，并可能对数字人文（DH）这一与技术紧密交织的领域产生重大影响。本文调查了DH学者如何采纳和批判性评估GenAI技术用于研究。通过从一项国际调查研究中收集的76份回复和对15位DH学者的半结构化访谈，我们探讨了在研究中采用GenAI工具的理由，确定了使用GenAI工具的具体实践，并分析了学者们对GenAI的益处、风险和挑战的集体看法。结果显示，DH研究社区对GenAI在DH学术中的作用持有不同的意见和不同的想象。尽管学者们承认GenAI在提高研究效率和实现技能再培训方面的益处，但许多人仍然担心它可能会扰乱他们的知识身份。置于DH历史中并通过行动者网络理论的视角来看，我们的发现表明GenAI的采用正在逐步改变该领域，尽管这种转型仍然存在争议，并受到多个（人类和非人类）行动者之间持续协商的影响。我们的研究是关于这一主题的首批实证分析之一，并有可能成为未来探究GenAI对DH学术影响的基石。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [340] [Possible Principles for Aligned Structure Learning Agents](https://arxiv.org/abs/2410.00258)
> *对齐结构学习智能体可能遵循的原则*

*Lancelot Da Costa, Tomáš Gavenčiak, David Hyland, Mandana Samiei, Cristian Dragos-Manta, Candice Pattisapu, Adeel Razi, Karl Friston* | **Category: cs.AI, q-bio.NC** | **Updated: 2025-07-15**

**Keywords:** 对齐AI, 结构学习, 世界模型, 偏好学习, 心智理论

**Comment:** 24 pages of content, 33 with references

> **TL;DR:** 本文提出一个路线图，通过结构学习（包括学习世界模型和偏好模型）和心智理论，实现可扩展的对齐AI，并探讨了相关原则。

**AI_Comments:** 该论文在对齐AI领域提出了一个高层次的框架和原则性指导，强调了结构学习在其中扮演的核心角色，并尝试将多学科思想（数学、统计学、认知科学）进行融合。其创新性在于将对齐问题与世界模型和偏好学习紧密结合，并引入了心智理论等概念。但作为“路线图”，其具体技术细节和实现方法可能较为抽象，更多是概念性的指引。

<details>
  <summary>Details</summary>

**Motivation:** 旨在从自然智能的第一性原理出发，为可扩展的对齐人工智能（AI）的发展提供一个路线图。核心目标是使人工智能体能够学习一个良好的世界模型，其中包含对人类偏好的良好模型，从而实现可扩展的对齐AI。

**Method:** 1. 提出通过结构学习（亦称因果表征学习或模型发现）来创建能学习世界及其它智能体世界模型的智能体。2. 综合数学、统计学和认知科学的各种思想，探讨结构学习和对齐问题，并提出指导原则。3. 讨论核心知识、信息几何和模型约减在结构学习中的关键作用，并建议核心结构模块来学习广泛的自然世界。4. 概述通过结构学习和心智理论实现对齐智能体的方法，并以数学方式描绘阿西莫夫的机器人三定律作为示例，还提出了改进的对齐方法。

**Result:** 本文提出了实现可扩展对齐AI的路径和指导原则，包括：1. 强调了核心知识、信息几何和模型约减在结构学习中的作用。2. 提出了通过结构学习和心智理论实现对齐智能体的方法。3. 通过阿西莫夫机器人三定律的数学草图，示例了对齐原则的应用。4. 提出了改进的对齐方法。这些观察结果有望指导现有对齐结构学习系统的扩展或新系统的设计。

**Conclusion:** 本文提出的原则和观察结果，有望指导人工智能的发展，帮助扩展现有或设计新的对齐结构学习系统，从而实现可扩展的对齐AI。

> **ai_Abstract:** 本文提出了一条从自然智能第一性原理出发，实现可扩展对齐人工智能（AI）的路线图。核心在于使智能体能够学习世界模型以及人类偏好模型，这属于结构学习范畴。论文综合数学、统计学和认知科学的观点，提出了指导结构学习和对齐的原则，包括核心知识、信息几何、模型约减在结构学习中的作用，以及通过结构学习和心智理论实现对齐的方法。通过阿西莫夫机器人三定律的数学示例，进一步阐述了对齐原则。这些发现旨在指导未来对齐结构学习系统的开发与设计。

> **摘要翻译:** 这篇论文为从自然智能的第一性原理描述出发，开发可扩展的对齐人工智能（AI）提供了一个路线图。简而言之，实现可扩展对齐AI的一条可能途径在于使人工智能体能够学习一个良好的世界模型，其中包含一个良好的人类偏好模型。为此，主要目标是创建能够学习表示世界和其他智能体世界模型的智能体；这个问题属于结构学习（又称因果表征学习或模型发现）。我们以这一目标为导向，阐述了结构学习和对齐问题，以及指导我们前进的原则，综合了数学、统计学和认知科学的各种思想。1）我们讨论了核心知识、信息几何和模型约减在结构学习中的基本作用，并提出了核心结构模块来学习广泛的自然世界。2）我们概述了通过结构学习和心智理论实现对齐智能体的方法。作为一个说明性示例，我们数学地勾勒了阿西莫夫的机器人三定律，这些定律规定智能体应谨慎行事，以最大程度地减少其他智能体的不适。我们通过提出改进的对齐方法来补充这个例子。这些观察结果可能指导人工智能的发展，帮助扩展现有——或设计新的——对齐结构学习系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [347] [Defining neurosymbolic AI](https://arxiv.org/abs/2507.11127)
> *定义神经符号人工智能*

*Lennert De Smet, Luc De Raedt* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 神经符号人工智能, 正式定义, 推理, 逻辑表示, 神经表示

**Comment:** 

> **TL;DR:** 本文提出了神经符号人工智能的一个正式定义，将推理视为逻辑函数和信念函数乘积的积分计算，并表明该定义能够抽象代表性的神经符号人工智能系统。

**AI_Comments:** 本文通过提供神经符号人工智能的正式定义，为这一新兴且多样化的领域奠定了重要的理论基础。这种统一的定义有助于标准化研究、促进清晰的交流，并可能指导未来新系统的开发。其创新之处在于神经符号推理的数学公式化。

<details>
  <summary>Details</summary>

**Motivation:** 尽管存在大量神经符号人工智能系统，但该领域缺乏一个普遍接受的关于神经符号模型和推理的正式定义。

**Method:** 作者引入了一个神经符号人工智能的正式定义，具体将神经符号推理定义为对逻辑函数和信念函数的乘积进行积分的计算。

**Result:** 他们的神经符号人工智能定义抽象了关键的代表性神经符号人工智能系统。

**Conclusion:** 该论文为神经符号人工智能领域提供了一个急需的正式定义，有望统一和标准化该领域的研究和发展。

> **ai_Abstract:** 本论文旨在解决神经符号人工智能领域缺乏正式定义的问题。该领域致力于通过统一逻辑和神经表示来整合学习和推理。作者提出了一个神经符号人工智能的正式定义，特别是将神经符号推理定义为对逻辑函数和信念函数的乘积进行积分的计算。他们证明了这一新定义能够抽象并涵盖关键的代表性神经符号人工智能系统。

> **摘要翻译:** 神经符号人工智能专注于整合学习和推理，特别是统一逻辑和神经表示。尽管存在大量的神经符号人工智能系统，但该领域缺乏一个普遍接受的关于神经符号模型和推理到底是什么的正式定义。我们引入了一个神经符号人工智能的正式定义，它抽象了其关键要素。更具体地说，我们将神经符号推理定义为对逻辑函数和信念函数的乘积进行积分的计算。我们表明，我们的神经符号人工智能定义抽象了关键的代表性神经符号人工智能系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [368] [Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs](https://arxiv.org/abs/2507.10630)
> *通过知识图谱增强大型语言模型API调用的能力*

*Ye Yang, Xue Xiao, Ping Yin, Taotao Xie* | **Category: cs.AI** | **Updated: 2025-07-14**

**Keywords:** 大型语言模型, API调用, 知识图谱, 气象学, 数据分析

**Comment:** 

> **TL;DR:** KG2data系统通过集成知识图谱和LLM，显著提升了大型语言模型在气象等知识密集型领域进行API调用的准确性和数据分析能力。

**AI_Comments:** KG2data的创新点在于将知识图谱作为大型语言模型的持久记忆和领域知识库，有效弥补了LLM在处理专业领域知识时的不足。这种方法不仅提升了API调用的准确性，特别是显著降低了幻觉现象，还通过减少对LLM频繁微调的需求，提高了系统的适应性和成本效益。该方法对于需要高精度和领域专业性的数据分析和问答系统具有重要意义，尤其是在医疗、法律等其他知识密集型领域也可能具有广泛应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在知识密集型领域（如气象学）通过API调用有效利用工具的能力尚未得到充分探索，其在处理复杂或术语丰富的查询时，由于缺乏领域特定知识而性能受限。

**Method:** 本文引入了KG2data系统，该系统集成了知识图谱、大型语言模型（LLMs）、ReAct代理和工具使用技术，以实现气象领域的智能数据获取和查询处理。系统使用虚拟API，通过名称识别失败、幻觉失败和调用正确性三个指标评估API调用准确性。KG2data通过使用知识图谱作为持久内存，增强了内容检索、复杂查询处理、领域特定推理、语义关系解析和异构数据集成。

**Result:** KG2data在API调用准确性方面表现优异，其名称识别失败率为1.43%，幻觉失败率为0%，调用正确率为88.57%。这显著优于RAG2data（16%、10%、72.14%）和chat2data（7.14%、8.57%、71.43%）。

**Conclusion:** KG2data为知识需求高的领域（如气象学）提供了智能、基于知识的问答和数据分析的新颖解决方案，它通过利用知识图谱解决了LLM访问领域特定知识的局限性，并降低了微调LLM的成本。

> **ai_Abstract:** 本文提出KG2data系统，旨在提升大型语言模型在气象等知识密集型领域进行API调用的能力。该系统通过集成知识图谱、LLMs、ReAct代理和工具使用技术，解决了LLMs在缺乏领域特定知识时性能受限的问题。实验结果表明，KG2data在API调用准确性上显著优于RAG2data和chat2data，并在名称识别、幻觉和调用正确性方面表现出色。KG2data利用知识图谱作为持久内存，增强了数据检索、复杂查询处理和领域推理能力，并降低了LLM微调成本，为知识密集型领域的智能问答和数据分析提供了新颖解决方案。

> **摘要翻译:** 大型语言模型（LLMs）的API调用为数据分析提供了一种前沿方法。然而，它们在气象等知识密集型领域通过API有效利用工具的能力仍未得到充分探索。本文介绍了KG2data，一个集成知识图谱、LLMs、ReAct代理和工具使用技术的系统，旨在实现气象领域的智能数据获取和查询处理。我们使用虚拟API，通过名称识别失败、幻觉失败和调用正确性三个指标评估API调用准确性。与RAG2data（16%、10%、72.14%）和chat2data（7.14%、8.57%、71.43%）相比，KG2data取得了卓越的性能（1.43%、0%、88.57%）。KG2data通过解决大型语言模型访问领域特定知识的局限性而区别于典型的基于LLM的系统，这些局限性阻碍了LLM在处理复杂或术语丰富查询时的性能。通过使用知识图谱作为持久内存，我们的系统增强了内容检索、复杂查询处理、领域特定推理、语义关系解析和异构数据集成。它还减轻了微调LLM的高成本，使系统更能适应不断发展的领域知识和API结构。总之，KG2data为知识需求高的领域提供了智能、基于知识的问答和数据分析的新颖解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [372] [A Unified Framework for Evaluating the Effectiveness and Enhancing the Transparency of Explainable AI Methods in Real-World Applications](https://arxiv.org/abs/2412.03884)
> *一个用于评估可解释人工智能方法在实际应用中有效性并增强其透明度的统一框架*

*Md. Ariful Islam, Md Abrar Jahin, M. F. Mridha, Nilanjan Dey* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 可解释人工智能, 评估框架, 透明度, 信任, 实际应用

**Comment:** 

> **TL;DR:** 本研究提出了一个统一的框架，用于在医疗、金融等实际应用中，通过量化和用户反馈评估可解释人工智能（XAI）方法的有效性，并提高其透明度和信任度。

**AI_Comments:** 本文的创新之处在于提出了一个统一且全面的XAI评估框架，它不仅关注量化指标，更将用户反馈和实际应用场景纳入考量，解决了当前XAI评估中缺乏标准化的痛点。其在多领域案例研究的验证，增强了该框架的普适性和实用价值，对于提升AI系统的透明度和信任度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型常被视为“黑箱”，难以理解和信任。尽管可解释人工智能（XAI）旨在使AI决策更清晰，但目前缺乏衡量这些解释方法在实际应用中效果的标准方法。

**Method:** 本研究引入了一个统一的XAI评估框架，该框架结合量化指标和用户反馈，以检查解释的正确性、易懂性、公平性、完整性和可靠性。它关注用户需求和不同应用领域，并提出了包括数据加载、解释生成和全面测试在内的明确步骤，并建议建立通用基准。

**Result:** 通过在医疗保健、金融、农业和自动驾驶系统中的案例研究，证明了该框架的价值，并验证了其能够支持对XAI方法进行公平和可信的评估。

**Conclusion:** 这项工作提供了一种清晰实用的方法，以提高AI系统在现实世界应用中的透明度和信任度。

> **ai_Abstract:** 本论文提出了一个统一的框架，旨在评估可解释人工智能（XAI）方法在实际应用中的有效性并增强其透明度。针对深度学习模型“黑箱”问题和XAI评估标准缺失的现状，该框架结合了量化指标和用户反馈，从正确性、易懂性、公平性、完整性和可靠性等维度全面评估XAI解释。通过在医疗、金融、农业和自动驾驶等领域的案例研究，证明了该框架的实用性和有效性，旨在提升AI系统的信任度和可接受性。

> **摘要翻译:** 深度学习的快速发展为基于人工智能的应用带来了巨大进步。然而，这些模型通常被视为“黑箱”，这使得它们难以理解、解释或信任。可解释人工智能（XAI）试图使AI决策更清晰，以便人们能够理解模型是如何以及为何做出某些选择。尽管许多研究都集中在XAI，但仍然缺乏衡量这些解释方法在实际情况中效果的标准方法。本研究引入了一个单一的XAI评估框架。它结合使用量化数据和用户反馈来检查解释是否正确、易于理解、公平、完整和可靠。该框架侧重于用户的需求和不同的应用领域，这有助于提高AI在重要领域中的信任度和使用率。为了解决当前评估方法中的问题，我们提出了明确的步骤，包括加载数据、创建解释和全面测试。我们还建议设置通用基准。我们通过在医疗保健、金融、农业和自动驾驶系统中的案例研究展示了该框架的价值。这些例子证明了我们的方法可以支持对XAI方法进行公平和可信的评估。这项工作提供了一种清晰实用的方法，以提高在现实世界中使用的AI系统的透明度和信任度。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [398] [Parsing Musical Structure to Enable Meaningful Variations](https://arxiv.org/abs/2507.10740)
> *解析音乐结构以实现有意义的变奏*

*Maziar Kanani, Sean O Leary, James McDermott* | **Category: cs.AI, cs.NE, cs.SD, eess.AS** | **Updated: 2025-07-14**

**Keywords:** 音乐结构, 音乐生成, 变奏, 语法, 变异

**Comment:** 

> **TL;DR:** 本文提出一种基于规则的方法，通过对音乐结构（Pathway Assembly）进行语法变异来生成现有曲调的变奏，并分析了曲调在多次变异后的变化。

**AI_Comments:** 创新点在于提出了一个新颖的基于规则的方法，通过对音乐语法而非曲调本身进行变异来生成音乐变奏。其重要性在于提供了一种自动生成音乐变奏的途径，并对变异过程中的结构变化进行了量化分析。局限性在于研究仅限于音高序列，且基于特定的爱尔兰传统曲调数据集。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过变奏现有曲调来生成音乐，并关注如何实现有意义的变奏。

**Method:** 本文提出一种新颖的基于规则的方法。它使用Sequitur算法解析曲调以找到Pathway Assembly（PA），生成一个语法。然后，对该语法进行变异（19种类型，如添加、删除、交换或反转部分），并随机应用其中一种变异，接着扩展语法以生成新曲调。研究通过编辑距离、结构复杂度和曲调长度来衡量变化。研究仅关注音高序列，并基于爱尔兰传统曲调数据集。

**Result:** 系统能够生成与原始曲调相关的新曲调。研究表明，曲调在多次变异过程中逐渐变化，并通过编辑距离、结构复杂性和长度来展示这些变化。每种变异类型的影响大小也得到了分析。输出曲调的音乐性方面得到了审查，但研究仅关注音高序列。

**Conclusion:** 本文成功展示了一种基于规则的方法，通过变异从现有曲调导出的音乐语法来生成音乐变奏，并分析了渐进变化和不同变异类型的影响，特别是在音高序列方面。

> **ai_Abstract:** 本文介绍了一种新颖的、基于规则的音乐变奏生成方法。该方法利用Sequitur算法将现有曲调解析为Pathway Assembly（PA）结构，从而生成一个语法。随后，对该语法随机应用19种变异类型中的一种。变异后，扩展语法以生成新曲调。研究考察了曲调在多次变异过程中的渐进演变，并使用编辑距离、结构复杂性和长度等指标进行衡量。同时，也分析了每种变异类型的影响大小。该研究特别专注于从爱尔兰传统曲调生成新的音高序列。

> **摘要翻译:** 本文提出了一种新颖的、基于规则的方法，用于通过变奏现有曲调来生成音乐。我们解析每首曲调以找到Pathway Assembly（PA）[1]，这是一种表示曲调中所有重复的结构。为此使用了Sequitur算法[2]。结果是一个语法。然后，我们对语法而不是直接对曲调进行变异。潜在的变异类型有19种，例如添加、删除、交换或反转语法的一部分，这些可以应用于语法。系统在此步骤中随机采用其中一种变异来自动操作语法。变异之后，我们需要扩展语法以返回一个新曲调。经过1次或多次变异后的输出将是一个与原始曲调相关的新曲调。我们的研究考察了曲调在多次变异过程中如何逐渐变化。编辑距离、结构复杂性和曲调长度被用来展示曲调在多次变异后如何改变。此外，还分析了每种变异类型的影响大小。最后，我们审查了输出曲调的音乐性方面。需要注意的是，该研究仅关注生成新的音高序列。该研究基于爱尔兰传统曲调数据集，并使用整数列表来表示每首曲调的音高值。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [405] [Collaborative Trustworthiness for Good Decision Making in Autonomous Systems](https://arxiv.org/abs/2507.11135)
> *自主系统中良好决策的协作信任度*

*Selma Saidi, Omar Laimona, Christoph Schmickler, Dirk Ziegenbein* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 自主系统, 协作信任度, 决策制定, 二元决策图, 社会认识论

**Comment:** 

> **TL;DR:** 本文提出一种协作信任方法，通过考虑系统质量属性和利用社会认识论概念，并使用BDD实现，以提高自主系统在冲突信息下的决策可靠性。

**AI_Comments:** 这篇论文通过引入系统质量属性和社会认识论的概念来解决自主系统决策中的信任问题，与传统依赖共识或多数的方法不同，具有创新性。利用BDDs进行形式化建模和优化计算也增强了方法的实用性。其重要性在于提升了自主系统在复杂、信息冲突环境下的安全性和可靠性，对自动驾驶等领域有潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 自主系统在动态复杂环境中确保安全和正确行为仍面临挑战，尤其是在存在冲突信息时，如何进行可信赖的决策是一个主要问题。

**Method:** 提出一种通用的协作方法，通过利用自主系统不同的质量属性（如感知质量）来确定其可信度，并借鉴社会认识论的概念定义聚合和传播规则。使用二元决策图（BDDs）作为信念聚合和传播的形式模型，并制定了BDD的简化规则以实现高效计算。

**Result:** Not mentioned in abstract

**Conclusion:** 论文提出了一种新颖的协作信任方法，旨在通过考虑系统质量属性和形式化模型（BDDs）来提高自主系统在复杂环境下的决策可信度和可靠性，解决了传统聚合规则的局限性。

> **ai_Abstract:** 本文提出了一种针对自主系统在复杂环境中进行可信决策的协作方法。针对传统聚合规则在处理冲突信息时的局限性，该方法利用自主系统特有的质量属性（如感知质量）来评估其可信度。通过借鉴社会认识论，研究定义了新的信息聚合与传播规则，并采用二元决策图（BDDs）作为形式化模型，同时引入简化规则以优化计算效率，从而提升自主系统的决策可靠性。

> **摘要翻译:** 自主系统正成为许多应用领域（如移动出行）不可或缺的一部分。然而，在动态复杂的环境中确保其安全和正确行为仍然是一个重大挑战，其中系统应自主做出决策，例如关于机动。本文提出了一种通用的协作方法，用于提高操作环境中的信任度，并改善自主系统的可靠性和良好决策。在存在冲突信息的情况下，聚合成为基于协作数据共享的可信决策的主要问题。与文献中依赖共识或多数作为聚合规则的经典方法不同，我们利用自主系统具有不同质量属性（如感知质量）的事实。我们使用此标准来确定哪些自主系统是可信的，并借鉴社会认识论的概念来定义用于自动决策的聚合和传播规则。我们使用二元决策图（BDDs）作为信念聚合和传播的形式模型，并制定了简化规则以减小BDD的大小，从而实现协作自动推理的高效计算结构。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [408] [From Code to Play: Benchmarking Program Search for Games Using Large Language Models](https://arxiv.org/abs/2412.04057)
> *从代码到游戏：使用大型语言模型对游戏程序搜索进行基准测试*

*Manuel Eberhardinger, James Goodman, Alexander Dockhorn, Diego Perez-Liebana, Raluca D. Gaina, Duygu Çakmak, Setareh Maghsudi, Simon Lucas* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 程序合成, 游戏, 基准测试, 进化算法

**Comment:** Submitted to Transactions on Games Special Issue on Large Language
  Models and Games, standardised LLMs used and run more experiments

> **TL;DR:** LLM可以为游戏生成代码，但性能取决于任务而非模型大小，尝试多种模型比只用一种更可靠。

**AI_Comments:** 这项研究通过系统性的基准测试，揭示了LLM在游戏程序合成领域的实际能力和局限性。其创新之处在于将LLM与进化算法结合，并对不同语言和多种游戏任务进行了广泛评估。论文的发现对于理解LLM在代码生成领域的适用性具有重要意义，尤其是在资源受限或需要高质量解决方案的场景下，提示我们不应盲目追求模型规模，而应关注任务匹配和多模型策略。

<details>
  <summary>Details</summary>

**Motivation:** 探索大型语言模型（LLMs）在游戏程序合成方面的潜力，以及它们直接合成各种游戏应用可用代码的能力。

**Method:** 研究使用了一种进化式爬山算法，其中初始程序的变异和种子由LLMs控制。针对Python和Java两种编程语言，在Python中涵盖了五种微型雅达利游戏、十个《巴巴是你》关卡、一个受《小行星》启发的环境和迷宫生成任务，在Java中包含了12款TAG桌面游戏框架中的游戏。共对29项任务评估了12个Python语言模型和8个Java语言模型。

**Result:** LLMs的性能更多取决于任务而非模型大小。虽然更大的模型能生成更多可执行程序，但这些程序并不总是能带来更高质量的解决方案，而且成本更高。没有模型具有明显优势，但在特定任务上，某个模型可能会更好。尝试许多模型并使用其中最好的结果比只使用一个更可靠。

**Conclusion:** 大型语言模型在游戏程序合成中展现出潜力，但其有效性高度依赖于任务类型。在实际应用中，尝试多样化的模型集合并选取最佳结果比仅仅依赖单一模型更为可靠和有效。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在游戏程序合成中的应用潜力。研究团队使用LLM控制的进化式爬山算法，在Python和Java语言中对多种游戏任务进行了基准测试。结果表明，LLM的表现更受任务类型而非模型大小影响；尽管大型模型能生成更多可执行代码，但其质量不一定更高且成本昂贵。研究建议，在实际应用中，尝试多种模型并选取最优结果比仅依赖单一模型更为有效。

> **摘要翻译:** 大型语言模型（LLMs）在生成程序代码方面展示了令人印象深刻的能力，为将程序合成应用于游戏开辟了激动人心的机会。在这项工作中，我们探索了LLMs直接为各种游戏应用合成可用代码的潜力，重点关注Python和Java两种编程语言。我们使用了一种进化式爬山算法，其中初始程序的变异和种子由LLMs控制。对于Python，该框架涵盖了各种与游戏相关的任务，包括五种微型雅达利游戏、十个《巴巴是你》关卡、一个受《小行星》启发的环境以及一个迷宫生成任务。对于Java，该框架包含来自TAG桌面游戏框架的12款游戏。我们对29项任务评估了12个Python语言模型和8个Java语言模型。我们的发现表明，LLMs的性能更多取决于任务而非模型大小。虽然更大的模型生成更多可执行程序，但这些程序并不总是能带来更高质量的解决方案，而且成本要高得多。没有模型具有明显优势，尽管在任何特定任务上，某个模型可能会更好。在一个问题上尝试许多模型并使用其中最好的结果比只使用一个更可靠。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [411] [Perspective-Aware AI in Extended Reality](https://arxiv.org/abs/2507.11479)
> *扩展现实中的透视感知人工智能*

*Daniel Platnick, Matti Gruener, Marjan Alirezaie, Kent Larson, Dava J. Newman, Hossein Rahnama* | **Category: cs.AI, cs.GR, cs.HC** | **Updated: 2025-05-05**

**Keywords:** 扩展现实, 透视感知AI, 用户建模, 沉浸式体验, 人机交互

**Comment:** Accepted to the International Conference on eXtended Reality (2025),
  12 pages, 3 figures

> **TL;DR:** PAiR是一个将透视感知人工智能（PAi）与扩展现实（XR）结合的框架，旨在通过基于用户身份的解释性、上下文感知体验来改进XR系统。

**AI_Comments:** PAiR的创新之处在于其将“透视感知AI”与“扩展现实”相结合，通过深入的用户身份模型（Chronicles）来提升XR体验的个性化和情境感知能力。这种基于用户认知和经验演变的建模方法，有望显著改善现有XR系统的局限性，为未来更自然、更智能的人机交互奠定基础。

<details>
  <summary>Details</summary>

**Motivation:** 当前的人工智能增强型扩展现实（XR）系统由于用户建模肤浅和认知上下文有限，无法提供适应性强的沉浸式体验。

**Method:** 本文介绍了透视感知人工智能在扩展现实（PAiR）中的应用，这是一个将透视感知人工智能（PAi）与XR集成的基础框架。PAi基于“编年史”构建，即从多模态数字足迹中学习的、可用于推理的身份模型，这些模型捕捉用户的认知和经验演变。PAiR在一个闭环系统中利用这些模型，将动态用户状态与沉浸式环境连接起来。作者详细介绍了PAiR的架构，包括其模块和系统流程，并通过在基于Unity的OpenDome引擎中实现的两个概念验证场景展示了其效用。

**Result:** PAiR的效用通过在Unity-based OpenDome引擎中实现的两个概念验证场景得到了展示。

**Conclusion:** PAiR通过将基于视角的身份模型嵌入到沉浸式系统中，为人类与AI的交互开辟了新方向。

> **ai_Abstract:** 本文提出了PAiR（扩展现实中的透视感知人工智能）框架，旨在解决当前AI增强型XR系统在用户建模和认知上下文方面的不足。PAiR通过整合PAi（基于从多模态数字足迹学习的“编年史”身份模型）与XR，实现了解释性强、上下文感知的沉浸式体验。该框架在一个闭环系统中连接用户状态与环境，并已通过Unity-based OpenDome引擎中的概念验证场景得到验证，预示着人机交互的新方向。

> **摘要翻译:** 人工智能增强型扩展现实（XR）旨在提供适应性强的沉浸式体验，但由于用户建模肤浅和认知上下文有限，目前的系统仍有不足。我们引入了扩展现实中的透视感知人工智能（PAiR），这是一个将透视感知人工智能（PAi）与XR集成的基础框架，旨在实现基于用户身份的、可解释的、上下文感知的体验。PAi建立在“编年史”之上：从多模态数字足迹中学习到的、可用于推理的身份模型，这些模型捕捉用户的认知和经验演变。PAiR在一个闭环系统中运用这些模型，将动态用户状态与沉浸式环境连接起来。我们展示了PAiR的架构，详细介绍了其模块和系统流程，并通过在基于Unity的OpenDome引擎中实现的两个概念验证场景展示了其效用。PAiR通过将基于视角的身份模型嵌入到沉浸式系统中，为人类与AI的交互开辟了新方向。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [428] [Trajectory Imputation in Multi-Agent Sports with Derivative-Accumulating Self-Ensemble](https://arxiv.org/abs/2408.10878)
> *多智能体运动中基于导数累积自集成的轨迹插补*

*Han-Jun Choi, Hyunsung Kim, Minho Lee, Minchul Jeong, Chang-Jo Kim, Jinsung Yoon, Sang-Ki Ko* | **Category: cs.AI, cs.LG, cs.MA** | **Updated: 2025-07-15**

**Keywords:** 轨迹插补, 多智能体运动, 缺失数据, 深度学习, 体育分析

**Comment:** Accepted at ECML/PKDD 2025

> **TL;DR:** MIDAS是一种新颖的框架，通过联合预测位置、速度和加速度，并使用导数累积自集成方法，高精度且物理合理地插补多智能体运动轨迹数据中的缺失值。

**AI_Comments:** MIDAS的创新点在于其结合了Set Transformer进行多模态（位置、速度、加速度）联合预测，并引入了“导数累积自集成”机制来提高插补的物理合理性和精度。这种方法特别针对多智能体运动的复杂动态交互，填补了现有通用时空插补方法在体育领域应用上的不足。其在下游任务中的实用性也增加了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 多智能体运动数据（如团队运动）常因各种因素导致轨迹数据缺失。现有时空数据插补方法不适用于多智能体运动场景，因为玩家移动高度动态且智能体间交互持续演变。

**Method:** 提出MIDAS（多智能体插补器，带导数累积自集成）框架。它通过基于Set Transformer的神经网络联合预测位置、速度和加速度，并通过递归累积预测的速度和加速度值生成替代估计。这些预测通过可学习的加权集成进行组合，以产生最终插补的轨迹。

**Result:** 在三个体育数据集上的实验表明，MIDAS在位置精度和物理合理性方面显著优于现有基线。此外，它还展示了在近似总距离和传球成功概率等实际下游任务中的适用性。

**Conclusion:** MIDAS框架能够高精度且物理合理地插补多智能体运动轨迹数据中的缺失值，并适用于需要完整跟踪数据的实际下游任务。

> **ai_Abstract:** 本文提出了MIDAS（多智能体插补器，带导数累积自集成）框架，旨在解决多智能体运动轨迹数据中的缺失值问题。针对现有方法不适用于高度动态和交互性强的体育场景的挑战，MIDAS通过基于Set Transformer的神经网络联合预测位置、速度和加速度，并利用导数累积自集成方法生成和组合预测，从而实现高精度和物理合理的轨迹插补。实验证明，MIDAS在多个体育数据集上表现优异，并能有效支持需要完整轨迹数据的下游分析任务。

> **摘要翻译:** 从团队运动等领域收集的多智能体轨迹数据，由于各种因素，经常存在缺失值。尽管已提出许多时空数据插补方法，但它们不适用于多智能体运动场景，因为玩家移动高度动态且智能体间交互持续演变。为了解决这些挑战，我们提出了MIDAS（带导数累积自集成的多智能体插补器），一个能够高精度和物理合理性地插补多智能体轨迹的框架。它通过基于Set Transformer的神经网络联合预测位置、速度和加速度，并通过递归累积预测的速度和加速度值生成替代估计。然后，这些预测通过可学习的加权集成进行组合，以产生最终插补的轨迹。在三个体育数据集上的实验表明，MIDAS在位置精度和物理合理性方面显著优于现有基线。最后，我们展示了MIDAS的用例，例如近似总距离和传球成功概率，以突出其在需要完整跟踪数据的实际下游任务中的适用性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [440] [AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition](https://arxiv.org/abs/2507.10750)
> *人工智能与净零之旅：能源需求、排放及转型潜力*

*Pandu Devarakota, Nicolas Tsesmetzis, Faruk O. Alpak, Apurva Gala, Detlef Hohl* | **Category: cs.AI** | **Updated: 2025-07-14**

**Keywords:** 人工智能, 净零, 能源需求, 温室气体排放, 气候缓解潜力

**Comment:** Technical article to be submitted to Data Centric Engineering Journal

> **TL;DR:** 本文探讨了人工智能对能源需求和温室气体排放的影响，指出短期内AI将增加碳排放，但长期来看，AI有潜力通过优化流程显著减少碳足迹，最终可能支持气候减缓。

**AI_Comments:** 该论文对人工智能在气候变化中的双重作用进行了及时且重要的分析。其创新之处在于区分了AI对环境影响的短期挑战和长期潜力，为政策制定者和行业提供了有价值的视角。文章强调了在推动AI发展的同时，需要关注其能源效率和优化应用，以实现真正的净零目标。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于人工智能的广泛应用及其对数据中心的大量投资，本文旨在探讨人工智能对二氧化碳排放的净影响（正面、中性或负面），并评估其在能源生产、供应和消费相关领域实现自动化和创建高效工作流程的潜力。

**Method:** 本文是一篇技术综述文章，提出了数据中心的能源消耗情景及其对温室气体排放的影响，考虑了近期预测（至2030年）和长期展望（2035年及以后）。

**Result:** 短期内（至2030年），由于大型数据中心和复杂AI模型的需求，AI的增长将导致电力消耗增加和二氧化碳排放上升。然而，长期来看（2035年及以后），AI有潜力通过自动化和优化能源生产、物流等各行业流程，显著减少碳足迹，其积极影响预计将超过初期的排放增长。

**Conclusion:** 人工智能初期可能导致环境方面的“成长期阵痛”，但它有潜力支持气候缓解工作。

> **ai_Abstract:** 本文作为一篇技术综述，分析了人工智能（AI）在净零排放之旅中的作用。研究指出，在短期内（至2030年），AI的快速发展将因数据中心能耗增加而导致碳排放上升。然而，从长期来看（2035年及以后），AI在自动化和优化各行业流程（如能源生产和物流）方面的巨大潜力，有望显著减少碳足迹，其积极影响预计将抵消初期的排放增长。文章最终认为，尽管AI可能带来初期的环境挑战，但其在气候减缓方面具有关键支持作用。

> **摘要翻译:** 由于海量数据、计算资源和先进算法的可用性，人工智能已进入几乎所有行业。这引发了大量的投资和兴趣，尤其是在建设必要硬件和软件的数据中心方面，以开发和运行人工智能模型和基于人工智能的工作流程。在这篇技术综述文章中，我们提出了数据中心的能源消耗情景及其对温室气体排放的影响，同时考虑了近期预测（至2030年）和长期展望（2035年及以后）。我们探讨了AI到2035年对二氧化碳排放将产生净正面、中性还是负面影响的根本问题。此外，我们还讨论了AI在能源生产、供应和消费等各个相关领域实现自动化、创建高效和颠覆性工作流程的潜力。在近期情景中，不断增长的AI需求可能会给计算资源带来压力，导致电力消耗增加，从而增加相关的二氧化碳排放。这是由于大数据中心的耗电性质、训练和运行大型复杂AI模型的需求，以及AI助手搜索和公共应用程式的普及。然而，长期前景可能更为乐观。AI有潜力成为二氧化碳减排的颠覆者。它在能源生产到物流等各行业进一步自动化和优化流程的能力，可以显著减少我们的碳足迹。这种积极影响预计将超过初期的排放增长，在传统解决方案不足的领域为企业和社会创造价值。从本质上讲，AI可能会给环境带来一些初期的“成长期阵痛”，但它有潜力支持气候缓解工作。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [450] [LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating](https://arxiv.org/abs/2412.18424)
> *LongDocURL：一个综合多模态长文档基准，整合了理解、推理和定位*

*Chao Deng, Jiale Yuan, Pi Bu, Peijie Wang, Zhong-Zhi Li, Jian Xu, Xiao-Hui Li, Yuan Gao, Jun Song, Bo Zheng, Cheng-Lin Liu* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-15**

**Keywords:** 长文档理解, 多模态基准, 大型视觉语言模型, 文档定位, 数值推理

**Comment:** 

> **TL;DR:** 提出了LongDocURL，一个用于长文档理解、推理和定位的综合多模态基准，解决了现有基准的局限性，并揭示了当前模型在该领域的性能差距。

**AI_Comments:** 这篇论文通过构建一个大规模、多模态、涵盖理解、推理和定位的长文档基准，填补了现有基准的空白，对于推动大型视觉语言模型在复杂文档处理领域的发展具有重要意义。其巨大的数据量和多维度的任务设计，为全面评估和提升模型能力提供了坚实的基础，并揭示了当前模型的局限性，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有文档理解基准在处理长文档和全面分析布局元素定位方面存在局限性，无法充分评估大型视觉语言模型（LVLMs）在复杂文档理解方面的能力。

**Method:** 定义了长文档理解、数值推理和跨元素定位三类主要任务；提出了LongDocURL基准，整合了这三类任务，包含20个子任务；开发了半自动化构建流程，收集了2325个高质量问答对，覆盖超过33000页文档；对开源和闭源模型进行了26种配置的综合评估实验。

**Result:** 揭示了大型视觉语言模型在长文档理解、推理和定位领域存在的关键性能差距。新构建的基准在数据量上显著优于现有基准。

**Conclusion:** LongDocURL基准的提出和评估揭示了当前大型视觉语言模型在长文档理解、推理和定位方面的不足，为未来研究指明了方向。

> **ai_Abstract:** 本文针对现有文档理解基准在处理长文档和布局元素定位方面的不足，提出了一个名为LongDocURL的综合多模态长文档基准。该基准整合了长文档理解、数值推理和跨元素定位三大任务，并细分为20个子任务。通过半自动化流程构建了包含2325个问答对（覆盖超过33000页文档）的高质量数据集，显著超越现有规模。对多种模型进行的评估实验揭示了当前大型视觉语言模型在该领域存在的显著性能差距。

> **摘要翻译:** 大型视觉语言模型（LVLMs）显著提升了文档理解能力，使得处理复杂的文档元素、更长的上下文和更广泛的任务成为可能。然而，现有的文档理解基准仅限于处理少量页面，并且未能提供对布局元素定位的全面分析。在本文中，我们首先定义了三个主要任务类别：长文档理解、数值推理和跨元素定位，然后提出了一个综合基准LongDocURL，它整合了上述三个主要任务，并包含根据不同主要任务和答案证据分类的20个子任务。此外，我们开发了一个半自动化构建流程，收集了2325个高质量的问答对，覆盖了超过33000页的文档，显著优于现有基准。随后，我们对开源和闭源模型在26种不同配置下进行了全面的评估实验，揭示了该领域的关键性能差距。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [465] [Fine-grained Timing Analysis of Digital Integrated Circuits in Answer Set Programming](https://arxiv.org/abs/2507.11150)
> *数字集成电路中基于答案集编程的精细时序分析*

*Alessandro Bertagnon, Marcello Dalpasso, Michele Favalli, Marco Gavanelli* | **Category: cs.AI, cs.LO** | **Updated: 2025-07-15**

**Keywords:** 数字集成电路, 时序分析, 答案集编程, 最大延迟, 硬件设计

**Comment:** Accepted for publication in the issues of Theory and Practice of
  Logic Programming (TPLP) dedicated to ICLP 2025, 16 pages, 9 figures

> **TL;DR:** 本文提出使用答案集编程（ASP）来计算数字集成电路中的实际最大延迟，以克服传统静态时序分析的局限性，从而优化性能。

**AI_Comments:** 本文的创新之处在于将答案集编程（ASP）应用于硬件设计中一个计算难度大的问题（精确时序分析），而该问题传统上依赖于近似方法。这种方法有可能通过实现更精确的延迟计算来释放更好的性能，从而超越多项式时间上限估计的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 在集成电路设计中，传统静态时序分析（STA）只能计算最大延迟的上限，这可能导致处理器速度次优，并错失性能提升的机会。本文的动机是计算实际的最大延迟，而非近似值，以实现更优的电路性能。

**Method:** 作者将计算实际最大延迟这一计算难度大的问题建模为答案集编程（ASP），这是一种具有高效求解器的逻辑语言，并提出了非平凡的问题编码方法。

**Result:** 实验结果表明，答案集编程（ASP）是解决硬件设计中复杂问题的可行方案。

**Conclusion:** 答案集编程（ASP）可以有效计算数字集成电路中的实际最大延迟，为解决复杂的硬件设计问题提供了一种可行的方法。

> **ai_Abstract:** 本文旨在解决数字集成电路中最大延迟的精确计算问题，这对于优化系统时钟频率至关重要。与提供上限的传统静态时序分析不同，作者提出使用答案集编程（ASP）对这一计算难题进行建模，并采用了新颖的编码方法。实验结果表明，ASP是解决复杂硬件设计问题的可行方案，能够确定实际最大延迟以提升性能。

> **摘要翻译:** 在集成电路设计中，一个关键指标是电路内组合模块引入的最大延迟。这个延迟至关重要，因为它代表了执行计算所需的时间：在算术逻辑单元中，它代表电路执行算术运算所需的最大时间。当这样的电路是更大同步系统（如CPU）的一部分时，最大延迟直接影响整个系统的最大时钟频率。通常，硬件设计者使用静态时序分析来计算最大延迟的上限，因为它可以在多项式时间内确定。然而，依赖此上限可能导致处理器速度次优，从而错失性能提升的机会。在这项工作中，我们解决了计算实际最大延迟而非近似值的挑战性任务。由于该问题计算难度大，我们使用答案集编程（ASP）对其进行建模，这是一种具有极其高效求解器的逻辑语言。我们提出了将问题编码为ASP的非平凡方法。实验结果表明，ASP是解决硬件设计中复杂问题的可行方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [472] [Working with AI: Measuring the Occupational Implications of Generative AI](https://arxiv.org/abs/2507.07935)
> *与AI协作：衡量生成式AI对职业的影响*

*Kiran Tomlinson, Sonia Jaffe, Will Wang, Scott Counts, Siddharth Suri* | **Category: cs.AI, cs.CY, econ.GN, q-fin.EC** | **Updated: 2025-07-15**

**Keywords:** 生成式AI, 职业影响, 工作活动, Bing Copilot, AI适用性

**Comment:** 41 pages

> **TL;DR:** 本文通过分析20万条Bing Copilot对话，研究生成式AI在工作中的应用及其职业适用性，发现AI在知识工作和信息相关职业中具有高适用性。

**AI_Comments:** 这篇论文通过使用大规模真实世界数据集（Bing Copilot对话），为生成式AI的实际使用和职业影响提供了宝贵的实证见解，超越了理论预测。其“AI适用性得分”的概念是一个量化潜在影响的有用指标。它有助于更好地理解人机协作的演变格局。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于生成式AI的迅速普及及其影响广泛任务的潜力，理解AI对经济的影响是社会最重要的问题之一。本文旨在分析人们如何与AI协作及其对职业的影响。

**Method:** 作者分析了一个包含20万条匿名且经过隐私处理的用户与微软Bing Copilot（一个公开可用的生成式AI系统）对话的数据集。他们对工作活动进行分类，衡量任务成功和影响范围，并通过结合活动分类和职业数据计算每个职业的“AI适用性得分”。此外，他们还描述了成功完成的活动类型，分析了工资和教育与AI适用性之间的关联，并将实际使用情况与职业AI影响的预测进行了比较。

**Result:** 人们寻求AI协助最常见的工作活动是信息收集和写作。AI本身最常执行的活动是提供信息和协助、写作、教学和建议。计算机和数学、办公室和行政支持等知识工作职业群体，以及销售等涉及提供和沟通信息的职业，其AI适用性得分最高。研究还描述了最成功完成的工作活动类型，工资和教育与AI适用性之间的关联，以及实际使用情况与职业AI影响预测的比较。

**Conclusion:** 生成式AI在各种职业中具有显著的适用性，尤其是在知识工作和信息处理相关角色中，通过实际数据分析识别了具体的使用模式和影响。

> **ai_Abstract:** 本文通过分析20万条与微软Bing Copilot的匿名对话，研究了生成式AI对职业的影响。研究识别了人们寻求AI协助的常见任务（如信息收集、写作）以及AI执行的任务（如提供信息、写作、教学、建议）。通过计算“AI适用性得分”，研究发现AI在计算机/数学、行政支持等知识密集型角色以及销售等职业中具有高适用性，揭示了AI如何融入各种工作活动及其对不同职业的潜在影响。

> **摘要翻译:** 鉴于生成式AI的迅速普及及其影响广泛任务的潜力，理解AI对经济的影响是社会最重要的问题之一。在这项工作中，我们通过分析人们与AI进行的工作活动、这些活动的成功程度和广度，并结合职业活动数据，向实现这一目标迈进了一步。我们分析了一个包含20万条匿名且经过隐私处理的用户与微软Bing Copilot（一个公开可用的生成式AI系统）对话的数据集。我们发现人们寻求AI协助最常见的工作活动涉及信息收集和写作，而AI本身最常执行的活动是提供信息和协助、写作、教学和建议。将这些活动分类与任务成功和影响范围的测量相结合，我们计算出每个职业的AI适用性得分。我们发现，知识工作职业群体（如计算机和数学、办公室和行政支持）以及销售等涉及提供和沟通信息的职业，其AI适用性得分最高。此外，我们还描述了最成功完成的工作活动类型、工资和教育与AI适用性之间的关联，以及实际使用情况与职业AI影响的比较。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [482] [IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models](https://arxiv.org/abs/2507.10758)
> *物联网恶意网络流量检测使用深度学习和GraphSAGE模型*

*Nikesh Prajapati, Bimal Karki, Saroj Gopali, Akbar Siami Namin* | **Category: cs.AI** | **Updated: 2025-07-14**

**Keywords:** 物联网安全, 恶意流量检测, 深度学习, GraphSAGE, BERT

**Comment:** 

> **TL;DR:** 本文利用深度学习和图神经网络模型（如BERT、TCN、GraphSAGE等）检测物联网恶意网络流量，其中BERT表现最佳，GraphSAGE训练时间最短但准确率最低。

**AI_Comments:** 这篇论文通过比较多种先进的深度学习和图神经网络模型在物联网恶意流量检测方面的表现，为该领域的模型选择提供了有价值的参考。特别是对BERT模型的高性能验证，突出了其在处理复杂时间序列数据上的优势。然而，论文也指出了不同模型在性能和计算成本之间的权衡，例如GraphSAGE的快速训练但较低的准确率，以及Multi-Head Attention的高计算需求。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过深度学习模型检测物联网恶意攻击，并全面评估深度学习和基于图的模型在恶意网络流量检测方面的性能。

**Method:** 使用了多种深度学习和图基模型，包括GraphSAGE、BERT、TCN、Multi-Head Attention、BI-LSTM以及LSTM。这些模型被用于建模时间模式和检测特征显著性。

**Result:** 实验结果显示BERT表现最佳，准确率达99.94%，F1-score和AUC-ROC分数达99.99%。Multi-Head Attention模型也提供了良好的检测能力和可解释结果，但处理时间较长。GraphSAGE模型训练时间最短但准确率、精确度和F1分数最低。

**Conclusion:** 深度学习模型在检测物联网恶意网络流量方面表现出色，特别是BERT模型，能够有效捕获时间依赖性。物联网流量的序列性和多样性为模型学习提供了丰富的时序模式。

> **ai_Abstract:** 本文探讨了使用深度学习和图神经网络模型（如BERT、TCN、GraphSAGE、Multi-Head Attention、BI-LSTM、LSTM）进行物联网恶意网络流量检测。研究发现物联网流量的序列性和多样性有助于模型学习。实验结果表明，BERT模型表现最优，准确率高达99.94%，能有效捕获时间依赖性。Multi-Head Attention模型提供了可解释的结果但处理时间长。GraphSAGE模型训练时间最短但性能相对较弱。

> **摘要翻译:** 本文旨在通过深度学习模型检测物联网恶意攻击，并对深度学习和基于图的模型在恶意网络流量检测方面进行了全面评估。这些模型特别基于GraphSAGE、来自Transformer的双向编码器表示（BERT）、时间卷积网络（TCN）以及多头注意力机制，同时还有双向长短期记忆（BI-LSTM）、多头注意力机制和BI-LSTM以及LSTM模型。所选模型在建模时间模式和检测特征显著性方面表现出色。观察到的性能主要归因于物联网系统流量模式既具有序列性又具有多样性，为模型学习留下了丰富的时序模式。实验结果表明，BERT保持了最佳性能。它实现了99.94%的准确率，同时具有99.99%的高精确度、召回率、F1分数和AUC-ROC分数，这表明其通过捕获时间依赖性的能力。多头注意力机制通过提供良好的检测能力和可解释的结果而显示出有希望的成果。另一方面，多头注意力模型像BI-LSTM变体一样需要大量的处理时间。GraphSAGE模型在需要最短训练时间的同时获得了良好的准确率，但与其他模型相比，其准确率、精确度和F1分数最低。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [486] [XGeM: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation](https://arxiv.org/abs/2501.04614)
> *XGeM: 一种用于多模态医疗数据生成的多提示基础模型*

*Daniele Molino, Francesco Di Feola, Eliodoro Faiella, Deborah Fazzini, Domiziana Santucci, Linlin Shen, Valerio Guarrasi, Paolo Soda* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 多模态生成, 医疗数据, 基础模型, 对比学习, 数据合成

**Comment:** 

> **TL;DR:** XGeM是一种67.7亿参数的多模态生成模型，通过对比学习和多提示训练，实现了医学数据的灵活、任意到任意的合成，旨在解决数据稀缺、隐私和多模态整合等挑战。

**AI_Comments:** XGeM的创新之处在于其多提示训练策略和构建共享潜在空间的能力，这使其能够实现“任意到任意”的多模态医学数据合成，解决了现有方法在多模态联合生成方面的局限性。其作为基础模型的定位，以及在数据稀缺、隐私保护和类别不平衡等实际医疗挑战中的应用潜力，显示了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能在医学影像中的应用前景广阔，但受到数据稀缺、隐私问题以及鲁棒多模态整合需求的阻碍。现有生成模型通常限于单模态、单向合成，缺乏联合合成多种模态并保持临床一致性的能力。

**Method:** 引入了XGeM，一个67.7亿参数的多模态生成模型，旨在支持医学数据模态之间灵活的、任意到任意的合成。XGeM通过对比学习构建共享潜在空间，并引入新颖的多提示训练策略，支持对任意输入模态子集进行条件化。这种设计使得模型能够适应异构临床输入并联合生成多个输出，同时保持语义和结构一致性。

**Result:** 首先，在MIMIC-CXR数据集上与五个竞争对手进行了基准测试。其次，与专家放射科医生进行了视觉图灵测试，评估生成数据的真实性和临床相关性。最后，展示了XGeM如何支持匿名化、类别不平衡和数据稀缺等关键医疗数据挑战。

**Conclusion:** XGeM作为医学数据合成的基础模型，在解决数据稀缺、隐私和多模态整合方面具有实用性，并能支持匿名化、类别不平衡和数据稀缺等关键医疗数据挑战。

> **ai_Abstract:** 本文提出了XGeM，一个67.7亿参数的多模态生成模型，旨在解决医学影像领域数据稀缺、隐私和多模态整合的挑战。XGeM通过构建共享潜在空间和引入多提示训练策略，实现了医学数据模态之间灵活的、任意到任意的合成，能够适应异构输入并联合生成保持临床一致性的多模态数据。模型在MIMIC-CXR数据集上进行了基准测试，并通过专家视觉图灵测试验证了其生成数据的真实性。研究还表明XGeM可用于解决匿名化、类别不平衡和数据稀缺等医疗数据问题。

> **摘要翻译:** 人工智能在医学影像中的应用前景广阔，但仍受数据稀缺、隐私问题以及鲁棒多模态整合需求等挑战的阻碍。尽管生成建模的最新进展已经实现了高质量的合成数据生成，但现有方法通常仅限于单模态、单向合成，因此缺乏联合合成多种模态同时保持临床一致性的能力。为了解决这一挑战，我们引入了XGeM，一个67.7亿参数的多模态生成模型，旨在支持医学数据模态之间灵活的、任意到任意的合成。XGeM通过对比学习构建共享潜在空间，并引入新颖的多提示训练策略，支持对任意输入模态子集进行条件化。这种设计使得模型能够适应异构临床输入并联合生成多个输出，同时保持语义和结构一致性。我们对XGeM进行了广泛验证：首先，我们在MIMIC-CXR数据集（一个用于多视图胸部X光和放射学报告生成的最先进数据集）上与五个竞争对手进行了基准测试。其次，我们与专家放射科医生进行了视觉图灵测试，以评估生成数据的真实性和临床相关性，确保与真实世界场景保持一致。最后，我们展示了XGeM如何支持匿名化、类别不平衡和数据稀缺等关键医疗数据挑战，强调了其作为医学数据合成基础模型的实用性。项目页面位于https://cosbidev.github.io/XGeM/。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [525] [ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning](https://arxiv.org/abs/2502.01100)
> *ZebraLogic：关于LLM逻辑推理的扩展极限*

*Bill Yuchen Lin, Ronan Le Bras, Kyle Richardson, Ashish Sabharwal, Radha Poovendran, Peter Clark, Yejin Choi* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-15**

**Keywords:** LLMs, 逻辑推理, 可扩展性, ZebraLogic, 复杂性诅咒

**Comment:** Accepted to ICML 2025

> **TL;DR:** 本文通过引入ZebraLogic评估框架，研究了大型语言模型（LLMs）在逻辑推理方面的扩展极限，发现随着问题复杂性增加，LLMs的准确性显著下降，称之为“复杂性诅咒”。

**AI_Comments:** ZebraLogic框架的创新之处在于其能够生成可控和可量化复杂度的逻辑谜题，这为系统研究LLM的推理局限性提供了一个强大的工具。这项工作揭示了LLM在面对复杂逻辑推理时的“复杂性诅咒”，强调了即使是大型模型也存在的固有局限性。这对于理解当前LLM的能力边界及其未来发展方向具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究大型语言模型（LLMs）的逻辑推理能力及其在复杂非单调推理中的可扩展性。

**Method:** 引入了ZebraLogic，一个用于评估LLM在源自约束满足问题（CSPs）的逻辑网格谜题上的推理性能的综合评估框架。ZebraLogic能够生成具有可控和可量化复杂度的谜题，从而系统地研究Llama、o1模型和DeepSeek-R1等模型的扩展极限。

**Result:** 结果显示，随着问题复杂度的增加，准确性显著下降，这种现象被称为“复杂性诅咒”。即使使用更大的模型和增加推理时间计算，这种局限性仍然存在，表明当前LLM推理能力存在固有限制。此外，还探讨了增强逻辑推理的策略，包括Best-of-N采样、回溯机制和自我验证提示。

**Conclusion:** 研究结果为LLM推理的可扩展性提供了重要见解，强调了其根本局限性，并提出了潜在的改进方向。

> **ai_Abstract:** 本文引入了ZebraLogic，一个用于评估大型语言模型（LLMs）在复杂逻辑推理中扩展能力的综合框架。该框架通过生成具有可控复杂度的逻辑网格谜题，系统地研究了Llama、o1和DeepSeek-R1等模型的性能。研究发现，随着问题复杂度的增加，LLMs的准确性显著下降，即“复杂性诅咒”，这表明当前LLM推理能力存在固有限制。文章还探讨了如Best-of-N采样、回溯和自我验证等增强逻辑推理的策略，为LLM推理的扩展性提供了关键见解。

> **摘要翻译:** 我们调查了大型语言模型（LLMs）的逻辑推理能力及其在复杂非单调推理中的可扩展性。为此，我们引入了ZebraLogic，一个综合评估框架，用于评估LLM在源自约束满足问题（CSPs）的逻辑网格谜题上的推理性能。ZebraLogic能够生成具有可控和可量化复杂度的谜题，从而系统地研究Llama、o1模型和DeepSeek-R1等模型的扩展极限。通过涵盖广泛的搜索空间复杂性和多样的逻辑约束，ZebraLogic提供了一个结构化环境来评估在难度增加下的推理能力。
我们的结果显示，随着问题复杂度的增加，准确性显著下降——这一现象我们称之为复杂性诅咒。即使使用更大的模型和增加推理时间计算，这种局限性仍然存在，表明当前LLM推理能力存在固有限制。此外，我们探索了增强逻辑推理的策略，包括Best-of-N采样、回溯机制和自我验证提示。我们的发现为LLM推理的可扩展性提供了重要见解，强调了根本局限性，并概述了潜在的改进方向。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [529] [DuetGraph: Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion](https://arxiv.org/abs/2507.11229)
> *DuetGraph：粗粒度到细粒度的知识图谱推理与双通路全局-局部融合*

*Jin Li, Zezhong Ding, Xike Xie* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 知识图谱推理, 分数过平滑, 双通路融合, 粗粒度到细粒度, DuetGraph

**Comment:** 

> **TL;DR:** DuetGraph通过双通路全局-局部融合和粗粒度到细粒度优化，解决了知识图谱推理中的分数过平滑问题，实现了SOTA性能和训练加速。

**AI_Comments:** DuetGraph的创新点在于其双通路设计，有效避免了全局和局部信息融合时的“过平滑”问题，以及粗粒度到细粒度优化策略对推理精度的提升。这种分离处理和逐步细化的方法为知识图谱推理提供了一个新的视角，对于提升大规模知识图谱的推理效率和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有知识图谱推理方法在整合全局和局部信息时，常遭受分数过平滑问题，导致正确和错误答案之间的区分度模糊，影响推理效率。

**Method:** 提出了DuetGraph，一个粗粒度到细粒度的知识图谱推理机制，具有双通路全局-局部融合。它通过将局部信息（消息传递）和全局信息（注意力机制）的处理分离到两个独立通路中，防止相互干扰并保持表示区分度，从而解决过平滑问题。此外，DuetGraph引入了粗粒度到细粒度优化，将实体划分为高分和低分批次，缩小候选空间并锐化两批次间的分数差距，进一步缓解过平滑并提升推理质量。

**Result:** DuetGraph在多个数据集上实现了最先进（SOTA）的性能，推理质量提升高达8.7%，训练效率加速1.8倍。

**Conclusion:** DuetGraph通过其独特的双通路全局-局部融合和粗粒度到细粒度优化，有效解决了知识图谱推理中的分数过平滑问题，显著提升了推理性能和训练效率。

> **ai_Abstract:** DuetGraph是一种新的知识图谱推理机制，旨在解决现有方法中的分数过平滑问题。它采用双通路架构，将局部和全局信息处理分开，以保持表示区分度。同时，引入粗粒度到细粒度优化，通过缩小候选空间和增强分数区分来进一步缓解过平滑。实验证明，DuetGraph在推理质量和训练效率上均达到了SOTA水平。

> **摘要翻译:** 知识图谱（KGs）对于在各个领域实现知识推理至关重要。最近整合全局和局部信息的KG推理方法取得了可喜的成果。然而，现有方法常遭受分数过平滑问题，这模糊了正确和错误答案之间的区分度，并阻碍了推理效率。为了解决这个问题，我们提出了DuetGraph，一个具有双通路全局-局部融合的粗粒度到细粒度KG推理机制。DuetGraph通过分离——而不是堆叠——局部（通过消息传递）和全局（通过注意力）信息的处理到两个不同的通路中，防止相互干扰并保持表示区分度，从而解决过平滑问题。此外，DuetGraph引入了粗粒度到细粒度优化，将实体划分为高分和低分批次。这种策略缩小了候选空间并锐化了两个批次之间的分数差距，从而缓解了过平滑并提高了推理质量。在各种数据集上的广泛实验表明，DuetGraph实现了最先进（SOTA）的性能，推理质量提高了8.7%，训练效率加速了1.8倍。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [535] [Detecting AI Assistance in Abstract Complex Tasks](https://arxiv.org/abs/2507.10761)
> *检测抽象复杂任务中的AI辅助*

*Tyler King, Nikolos Gurney, John H. Miller, Volkan Ustun* | **Category: cs.AI, cs.HC** | **Updated: 2025-07-14**

**Keywords:** AI辅助检测, 抽象任务, 深度学习, 分类, 时空编码

**Comment:** Accepted to HCII 2025

> **TL;DR:** 本文将AI辅助检测视为分类任务，通过适当的预处理和构建图像及时间序列表征，证明了深度学习模型能有效检测抽象复杂任务中的AI辅助，强调时空编码的重要性。

**AI_Comments:** 这项研究通过将AI辅助检测转化为一个分类问题，并创新性地提出了将抽象任务数据转化为神经网络友好型图像和时间序列表征的方法，为AI辅助检测领域提供了新的视角。特别是对用户探索/利用行为的编码，增强了模型的泛化能力。其强调时空特征重要性的发现，对未来该领域的研究具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能在文本生成、医疗诊断、自动驾驶等复杂任务中日益普及，检测人工智能辅助变得越来越重要。人类难以检测，尤其是在抽象任务数据中。

**Method:** 本文将AI辅助检测视为一个分类任务。针对非机器学习友好的抽象数据，研究人员构建了四种神经网络友好的图像表征以及一种额外的时序表征（编码用户探索/利用行为），以提高泛化性。然后，在三种经典深度学习架构和一个并行CNN-RNN架构上对这些表征进行基准测试，其中CNN-RNN架构利用额外的时间序列数据以最大化测试性能。

**Result:** 结果表明，当数据经过适当预处理时，常用模型可以有效地对抽象数据进行分类。研究展示了编码时间量和空间量对于检测抽象任务中AI辅助的重要性。

**Conclusion:** 通过将AI辅助检测转化为分类任务并进行适当的数据预处理和表征（包括时空信息），深度学习模型能够有效检测抽象复杂任务中的AI辅助，突出了时空编码的关键作用。

> **ai_Abstract:** 本文探讨了在文本生成、医疗诊断等抽象复杂任务中检测AI辅助的挑战与方法。鉴于人类在此类任务中检测AI辅助的困难，作者提出将AI辅助检测视为深度学习模型的分类任务。针对许多AI辅助场景中数据对机器学习不友好的问题，研究构建了四种神经网络友好的图像表征和一种编码用户探索/利用行为的时间序列表征。通过在多种深度学习架构上进行基准测试，研究证明了适当预处理和表征能够使模型有效分类抽象数据，并强调了在检测AI辅助时，编码时间量和空间量的重要性。

> **摘要翻译:** 随着人工智能在文本生成、医疗诊断和自动驾驶等复杂任务中变得无处不在，检测人工智能辅助变得越来越重要。对人类来说，辅助检测具有挑战性，尤其是在观察抽象任务数据时。人工神经网络凭借其从大量数据中快速学习和处理的能力，擅长分类——前提是进行适当的预处理。我们认为将AI辅助检测视为此类模型的分类任务。该领域的大部分研究都考察了复杂但具体的数据类别（例如图像）的分类。然而，许多AI辅助检测场景产生的数据对机器学习不友好。我们证明，当数据经过适当预处理时，常用模型可以有效地对这些数据进行分类。为此，我们构建了四种不同的神经网络友好型图像表征以及一种额外的时序表征，该表征明确编码了用户的探索/利用行为，从而可以推广到其他抽象任务。我们在三种经典深度学习架构以及一个并行CNN-RNN架构上对每种图像表征的质量进行了基准测试，该CNN-RNN架构利用了额外的时间序列数据以最大化测试性能，展示了编码时间量和空间量对于检测抽象任务中AI辅助的重要性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [556] [Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case](https://arxiv.org/abs/2507.10803)
> *使用大型语言模型进行自动化主题分析：赛拉嗪伤口管理社交媒体聊天用例*

*JaMor Hairston, Ritvik Ranjan, Sahithi Lakamana, Anthony Spadaro, Selen Bozkurt, Jeanmarie Perrone, Abeed Sarker* | **Category: cs.AI, cs.CL, cs.ET, cs.IR** | **Updated: 2025-07-14**

**Keywords:** 主题分析, 大型语言模型, 自然语言处理, 定性分析, 社交媒体

**Comment:** Pages: 19, Abstract word count: 151 words, Manuscript word count:
  2185 words, References: 14, Figures: 3, Tables: 2

> **TL;DR:** 本研究评估了大型语言模型（LLM）自动化主题分析的可行性，发现少量样本学习的LLM方法（特别是GPT-4o）在赛拉嗪社交媒体数据上表现良好，可作为定性研究的可扩展补充。

**AI_Comments:** 本研究的创新之处在于其将LLM应用于通常需要人类专家进行深度解释的归纳主题分析任务，并将其转化为一系列二元分类问题，有效规避了多标签分类的复杂性。研究证明了少量样本学习的LLM（特别是GPT-4o）在复制专家级主题分析方面的潜力，为定性研究提供了一个可扩展且高效的自动化补充方案，对于处理大规模社交媒体数据具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在归纳主题分析中面临挑战，这项任务需要深入的解释和特定领域专业知识。本研究旨在评估使用LLM复制专家驱动的社交媒体数据主题分析的可行性。

**Method:** 研究使用了两个时间上不相交的Reddit赛拉嗪数据集（分别包含286和686条数据，用于模型优化和验证），这些数据集具有十二个专家派生主题。研究评估了五种LLM与专家编码的对比。任务被建模为一系列二元分类，而非单一的多标签分类，并采用了零样本、单样本和少量样本提示策略，通过准确率、精确率、召回率和F1分数来衡量性能。

**Result:** 在验证集上，采用两样本提示的GPT-4o表现最佳（准确率：90.9%；F1分数：0.71）。对于高流行度主题，模型派生的主题分布与专家分类非常接近（例如，赛拉嗪使用：13.6% 对 17.8%；MOUD使用：16.5% 对 17.8%）。

**Conclusion:** 研究结果表明，基于少量样本学习的LLM方法可以自动化主题分析，为定性研究提供可扩展的补充。

> **ai_Abstract:** 本研究探讨了使用大型语言模型（LLM）自动化归纳主题分析的可行性，旨在解决LLM在需要深层解释的定性分析中的挑战。通过在赛拉嗪相关的Reddit社交媒体数据上，对比五种LLM与专家编码，并将任务建模为二元分类，实验结果显示，采用两样本提示的GPT-4o表现最佳，其主题分布与专家分类高度一致。研究结论认为，少量样本学习的LLM方法能够有效自动化主题分析，为定性研究提供一个可扩展的辅助工具。

> **摘要翻译:** 背景 大型语言模型（LLM）在归纳主题分析中面临挑战，这项任务需要深入的解释和特定领域专业知识。我们评估了使用LLM复制专家驱动的社交媒体数据主题分析的可行性。 方法 使用两个时间上不相交的Reddit赛拉嗪数据集（分别包含286和686条数据，用于模型优化和验证），这些数据集具有十二个专家派生主题，我们评估了五种LLM与专家编码的对比。我们将任务建模为一系列二元分类，而非单一的多标签分类，采用了零样本、单样本和少量样本提示策略，并通过准确率、精确率、召回率和F1分数来衡量性能。 结果 在验证集上，采用两样本提示的GPT-4o表现最佳（准确率：90.9%；F1分数：0.71）。对于高流行度主题，模型派生的主题分布与专家分类非常接近（例如，赛拉嗪使用：13.6% 对 17.8%；MOUD使用：16.5% 对 17.8%）。 结论 我们的研究结果表明，基于少量样本学习的LLM方法可以自动化主题分析，为定性研究提供可扩展的补充。 关键词：主题分析、大型语言模型、自然语言处理、定性分析、社交媒体、提示工程、公共卫生

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [567] [Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools](https://arxiv.org/abs/2502.04644)
> *代理式推理：一个用于通过代理工具增强大型语言模型推理的精简框架*

*Junde Wu, Jiayuan Zhu, Yuyuan Liu, Min Xu, Yueming Jin* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-14**

**Keywords:** 大型语言模型, 代理式推理, 工具使用, 知识图谱, 搜索机制

**Comment:** ACL 2025

> **TL;DR:** 引入Agentic Reasoning框架，通过集成外部工具（如Mind-Map和Web-Search代理）来显著提升LLM的推理能力，实现SOTA性能。

**AI_Comments:** 这篇论文的创新在于提出了一个结构化的代理框架来增强LLM的推理能力，特别是通过引入Mind-Map代理来管理长推理链的连贯性，以及优化Web-Search代理以提高信息检索效率。其在公开模型上达到SOTA并与顶级专有模型媲美的性能，凸显了该框架在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过集成外部工具代理来增强大型语言模型（LLM）的推理能力，以解决需要深度研究的复杂问题。

**Method:** 提出Agentic Reasoning框架，动态利用网络搜索、代码执行和结构化记忆。关键创新包括：1) Mind-Map代理，构建结构化知识图谱以存储推理上下文和追踪逻辑关系；2) 优化Web-Search代理，形成高效的搜索机制。

**Result:** 在DeepSeek-R1上部署时，该方法在公开模型中达到了新的SOTA性能，并与领先的专有模型OpenAI Deep Research表现相当。广泛的消融研究验证了代理工具的最佳选择以及Mind-Map和Web-Search代理在增强LLM推理方面的有效性。

**Conclusion:** Agentic Reasoning框架通过有效集成和优化外部代理工具（特别是Mind-Map和Web-Search），显著提升了LLM处理复杂推理问题的能力，并取得了领先的性能。

> **ai_Abstract:** 本文介绍了Agentic Reasoning框架，该框架通过整合外部工具使用代理（如网络搜索、代码执行和结构化记忆）来提升大型语言模型（LLM）的推理能力。核心创新包括一个构建结构化知识图谱以维护推理连贯性的Mind-Map代理，以及一个超越现有方法的优化Web-Search代理。该框架在DeepSeek-R1上取得了公开模型的SOTA性能，并与顶级专有模型表现相当，通过消融研究验证了其组件的有效性。

> **摘要翻译:** 我们引入了代理式推理（Agentic Reasoning），这是一个通过集成外部工具使用代理来增强大型语言模型（LLM）推理的框架。代理式推理动态地利用网络搜索、代码执行和结构化记忆来解决需要深度研究的复杂问题。我们框架中的一个关键创新是心智图代理（Mind-Map agent），它构建了一个结构化知识图谱来存储推理上下文并跟踪逻辑关系，确保在大量工具使用的长推理链中保持连贯性。此外，我们对网络搜索代理（Web-Search agent）进行了全面探索，从而形成了一种高效的搜索机制，超越了所有先前的方法。当在DeepSeek-R1上部署时，我们的方法在公开模型中达到了新的最先进（SOTA）水平，并提供了与该领域领先的专有模型OpenAI Deep Research相当的性能。广泛的消融研究验证了代理工具的最佳选择，并证实了我们的心智图和网络搜索代理在增强LLM推理方面的有效性。代码位于：https://github.com/theworldofagents/Agentic-Reasoning

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [591] [Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions](https://arxiv.org/abs/2507.10798)
> *面向智能移动健康干预的决策点不确定性感知调度*

*Asim H. Gazi, Bhanu T. Gullapalli, Daiqi Gao, Benjamin M. Marlin, Vivek Shetty, Susan A. Murphy* | **Category: cs.AI** | **Updated: 2025-07-14**

**Keywords:** 移动健康, JITAI, 调度, 不确定性, 习惯性行为

**Comment:** 4 pages, 3 figures

> **TL;DR:** SigmaScheduling根据行为预测的不确定性动态调度移动健康干预的决策点，提高了对不规律生活习惯个体的干预及时性。

**AI_Comments:** 本文的创新点在于引入了基于不确定性感知的动态调度机制，解决了传统固定间隔调度在面对个体行为不规律性时的局限。这对于提升移动健康干预的实际效果和用户体验具有重要意义。该方法有望使即时自适应干预（JITAIs）更加精准和个性化，从而在预防和改善健康行为方面发挥更大作用。

<details>
  <summary>Details</summary>

**Motivation:** 当前移动健康干预（mHealth）中，决策点通常以固定间隔调度，这种“一刀切”的方法对于作息不规律的个体表现不佳，常常导致决策点在目标行为发生之后才出现，从而使干预无效。

**Method:** 本文提出SigmaScheduling方法，根据预测行为时间的不确定性动态调度决策点。当行为时间更可预测时，SigmaScheduling将决策点安排在更接近预测行为时间；当时间不确定性较大时，则提前安排决策点，以增加及时干预的可能性。

**Result:** 通过对68名参与者进行为期10周的Oralytics（一种旨在改善日常刷牙的JITAI）真实世界数据评估，SigmaScheduling在至少70%的情况下增加了决策点先于刷牙事件发生的可能性，从而保留了干预和影响行为的机会。

**Conclusion:** SigmaScheduling可以推动精准移动健康的发展，特别是对于针对时间敏感、习惯性行为（如口腔卫生或饮食习惯）的即时自适应干预（JITAIs）。

> **ai_Abstract:** 该论文提出了一种名为SigmaScheduling的新方法，用于优化智能移动健康干预（如JITAIs）中的决策点调度。针对当前固定间隔调度对作息不规律用户无效的问题，SigmaScheduling根据预测行为时间的不确定性动态调整决策点。当行为时间更可预测时，决策点更接近预测时间；不确定性高时，则提前调度，以确保干预的及时性。在针对日常刷牙行为的真实世界试验中，SigmaScheduling显著提高了决策点先于目标行为发生的可能性，证明了其在提升精准移动健康干预有效性方面的潜力，尤其适用于时间敏感的习惯性行为。

> **摘要翻译:** 及时决策对于移动健康（mHealth）干预的有效性至关重要。在预定义的时间点，称为“决策点”，智能移动健康系统（如即时自适应干预（JITAIs））从传感器或调查数据中估计个体的生物行为背景，并决定是否以及如何进行干预。对于针对习惯性行为（例如口腔卫生）的干预，其有效性通常取决于在目标行为可能发生前不久提供支持。目前的做法是在用户提供行为时间前以固定间隔（例如一小时）调度决策点，并且所有个体的固定间隔都保持不变。然而，这种“一刀切”的方法对于作息不规律的个体表现不佳，常常导致决策点在目标行为已经发生之后才出现，从而使干预无效。在本文中，我们提出了SigmaScheduling，一种根据预测行为时间的不确定性动态调度决策点的方法。当行为时间更可预测时，SigmaScheduling将决策点安排在更接近预测行为时间；当时间不确定性较低时，SigmaScheduling会更早地安排决策点，从而增加及时干预的可能性。我们使用来自68名参与者在为期10周的Oralytics（一种旨在改善日常刷牙的JITAI）试验中的真实世界数据评估了SigmaScheduling。SigmaScheduling在至少70%的情况下增加了决策点先于刷牙事件发生的可能性，从而保留了干预和影响行为的机会。我们的结果表明，SigmaScheduling可以推动精准移动健康的发展，特别是对于针对时间敏感、习惯性行为（如口腔卫生或饮食习惯）的JITAIs。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [599] [Opus: A Prompt Intention Framework for Complex Workflow Generation](https://arxiv.org/abs/2507.11288)
> *Opus：一个用于复杂工作流生成的提示意图框架*

*Théo Fagnoni, Mahsun Altin, Chia En Chung, Phillip Kingston, Alan Tuning, Dana O. Mohamed, Inès Adnani* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 工作流生成, 大型语言模型, 提示意图框架, 意图捕获, 混合意图

**Comment:** 39 pages, 24 figures

> **TL;DR:** Opus框架引入了一个意图捕获层，以显著提高大型语言模型生成复杂工作流的质量和可扩展性，尤其是在处理混合意图时。

**AI_Comments:** 该论文创新性地引入了“意图捕获层”这一中间环节，有效解决了大型语言模型在处理复杂和多意图用户查询时直接生成工作流的局限性。通过将用户意图结构化，Opus框架提升了生成结果的逻辑性和可靠性，为LLM在复杂自动化和智能体应用中的落地提供了有价值的思路和技术支撑。其可复现和可定制的特性也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在改善使用指令调优大型语言模型（LLMs）进行复杂工作流生成的能力，解决直接从用户查询生成时可能遇到的挑战。

**Method:** 本论文提出了Opus提示意图框架，该框架在用户查询和工作流生成之间引入了一个中间的“意图捕获”层。此层包括从用户查询中提取工作流信号、将其解释为结构化的工作流意图对象，并基于这些意图生成工作流。该框架是一个可复现、可定制的基于LLM的意图捕获系统。

**Result:** 结果表明，该意图捕获层使LLMs能够生成逻辑且有意义的输出，并且随着查询复杂性的增加，其表现能够可靠地扩展。在一个包含1,000个多意图查询-工作流对的合成基准测试中，应用Opus框架显著提高了语义工作流相似性指标。该系统显著提高了工作流生成质量，尤其是在混合意图启发的情况下，优于直接从用户查询生成。

**Conclusion:** Opus提示意图框架通过引入意图捕获层，显著提升了大型语言模型在复杂工作流生成方面的质量和可靠性，尤其是在处理多意图和复杂查询时表现出优越性。

> **ai_Abstract:** Opus框架引入了一个创新的提示意图框架，通过在LLM驱动的工作流生成中加入一个中间的“意图捕获”层，显著提升了复杂工作流的生成质量。该层负责从用户查询中提取工作流信号，并将其转化为结构化的工作流意图，进而指导工作流的生成。实验结果表明，Opus框架能够生成更逻辑、有意义的输出，并有效应对查询复杂性的增加，尤其在处理混合意图时表现出显著优势。

> **摘要翻译:** 本文介绍了Opus提示意图框架，旨在改进使用指令调优大型语言模型（LLMs）进行复杂工作流生成的能力。我们提出在用户查询和工作流生成之间引入一个中间的意图捕获层，实现了Opus工作流意图框架，该框架包括从用户查询中提取工作流信号、将其解释为结构化的工作流意图对象，并基于这些意图生成工作流。我们的结果表明，该层使LLMs能够生成逻辑且有意义的输出，并且随着查询复杂性的增加，其表现能够可靠地扩展。在一个包含1,000个多意图查询-工作流对的合成基准测试中，应用Opus提示意图框架到工作流生成中，语义工作流相似性指标持续得到改善。在本文中，我们通过将工作流信号和工作流意图的概念应用于LLM驱动的工作流生成，介绍了Opus提示意图框架。我们提出了一个可复现、可定制的基于LLM的意图捕获系统，用于从用户查询中提取工作流信号和工作流意图。最后，我们提供了经验证据，表明所提出的系统与直接从用户查询生成相比，显著提高了工作流生成质量，特别是在混合意图启发的情况下。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [609] [BOOST: Bootstrapping Strategy-Driven Reasoning Programs for Program-Guided Fact-Checking](https://arxiv.org/abs/2504.02467)
> *BOOST：引导策略驱动的推理程序用于程序引导的事实核查*

*Qisheng Hu, Quanyu Long, Wenya Wang* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 事实核查, 程序引导推理, 少样本学习, 自举, 推理程序生成

**Comment:** Work in Progress

> **TL;DR:** BOOST提出了一种基于自举策略的方法，用于自动生成推理程序以进行程序引导的事实核查，并在复杂声明验证中超越了现有基线。

**AI_Comments:** BOOST的创新之处在于其无需人工干预的自举策略，通过迭代细化演示来生成策略驱动的推理程序，有效解决了现有方法中演示设计困难和程序多样性不足的问题。这种自动化和数据驱动的方法在复杂事实核查领域具有重要意义，因为它能提高效率和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 先前的程序引导式推理在事实核查中依赖于少样本上下文学习和临时演示，这限制了程序多样性并需要大量人工设计。有效推理程序生成的基本原则尚未充分探索，导致难以构建有效演示。

**Method:** 本文提出了BOOST框架，一个基于自举（bootstrapping）的少样本推理程序生成框架。BOOST明确地将声明分解和信息收集策略整合为程序生成的结构性指导，以策略驱动和数据为中心的方式迭代细化自举的演示，无需人工干预。这实现了从零样本到少样本战略性程序引导学习的无缝过渡。

**Result:** 实验结果表明，BOOST在复杂声明验证的零样本和少样本设置中均优于先前的少样本基线。

**Conclusion:** BOOST通过自动化和策略驱动的演示生成，显著改进了程序引导式事实核查，提高了可解释性和有效性。

> **ai_Abstract:** 本文提出了BOOST框架，旨在解决程序引导式事实核查中现有方法对人工设计演示的依赖和程序多样性不足的问题。BOOST通过整合声明分解和信息收集策略作为结构化指导，并以策略驱动和数据为中心的方式迭代自举演示，实现了无需人工干预的少样本推理程序生成。实验证明，BOOST在复杂声明验证任务上优于现有基线，提升了可解释性和有效性。

> **摘要翻译:** 程序引导式推理通过将声明分解为函数调用并执行推理程序，在复杂声明事实核查中展现出前景。然而，先前的研究主要依赖于少样本上下文学习（ICL）和临时演示，这限制了程序多样性，并需要大量领域知识进行人工设计。从根本上说，有效推理程序生成的基本原则仍未得到充分探索，这使得构建有效演示变得具有挑战性。为了解决这个问题，我们提出了BOOST，一个基于引导的少样本推理程序生成框架。BOOST明确地将声明分解和信息收集策略整合为程序生成的结构性指导，以策略驱动和数据为中心的方式迭代细化引导的演示，无需人工干预。这实现了从零样本到少样本战略性程序引导学习的无缝过渡，增强了可解释性和有效性。实验结果表明，BOOST在复杂声明验证的零样本和少样本设置中均优于先前的少样本基线。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [618] [AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems](https://arxiv.org/abs/2507.10566)
> *AI母语：多智能体强化学习中通过内生符号系统实现自发涌现通信*

*Hung Ming Liu* | **Category: cs.AI, cs.GT, cs.LG, cs.MA, cs.NE, 68T07, 68T40, 91A20, I.2.6; I.2.11; I.2.4** | **Updated: 2025-07-07**

**Keywords:** 多智能体强化学习, 涌现通信, 内生符号系统, 矢量量化变分自编码器, 幂律分布

**Comment:** 30 pages, 4 figures

> **TL;DR:** 本研究提出了AI母语（AIM）框架，基于VQ-VAE，使多智能体在没有外部归纳偏置的情况下，通过内生符号系统实现有效的自发涌现通信，解决了传统方法中通信受限的问题，并发现符号使用遵循幂律分布，提出了三个理论洞察。

**AI_Comments:** 本研究的创新之处在于挑战了传统涌现通信中对外部归纳偏置的依赖，提出通过内生符号系统实现自发通信。其通过VQ-VAE构建的AIM框架，以及对符号使用幂律分布的发现和提出的三个理论洞察，都具有重要的理论和实践意义。它为多智能体系统的通信机制提供了新的视角，并与人类认知和LLMs的最新研究产生了共鸣，为未来AI系统内部通信和认知提供了启发。

<details>
  <summary>Details</summary>

**Motivation:** 在去中心化多智能体强化学习（MARL）中，涌现通信的发展长期受限于“联合探索困境”，导致智能体陷入“通信真空均衡”。传统方法通过引入归纳偏置来促进通信涌现，但本研究质疑这种人工归纳偏置是否过度设计。

**Method:** 本研究提出了“AI母语”（AIM）框架，基于矢量量化变分自编码器（VQ-VAE）。通过让智能体拥有内生符号系统，来探索自发涌现通信的可能性。

**Result:** 实验证明，当智能体拥有内生符号系统时，其神经表征自然地表现出自发的语义压缩和纳什均衡驱动的语义收敛，从而在没有外部归纳偏置的情况下实现了有效的符号通信。与传统显式通信方法相比，AIM展现出更强的通用性和效率。研究开发的解释性分析工具证实符号使用呈现显著的幂律分布，并导出了三个主要的理论洞察：“神经通信假说”、“工具优先原则”和“语义可解释性范式”。

**Conclusion:** 这项发现为连接符号主义和联结主义提供了新途径。未来的研究将探索集成层级量化变分自编码器（HQ-VAE）以增强AIM的复杂表达能力，并研究“强化学习（RL）低级预训练”的潜力。

> **ai_Abstract:** 本研究提出“AI母语”（AIM）框架，利用VQ-VAE使多智能体在无外部归纳偏置的情况下，通过内生符号系统实现自发涌现通信，解决了MARL中通信受限的问题。AIM通过语义压缩和收敛实现高效通信，展现出比传统方法更强的通用性和效率。研究还发现符号使用遵循幂律分布，并提出了“神经通信假说”、“工具优先原则”和“语义可解释性范式”三个理论洞察，为连接符号主义和联结主义提供了新方向。

> **摘要翻译:** 在去中心化多智能体强化学习（MARL）中，涌现通信的发展长期受限于“联合探索困境”，导致智能体陷入“通信真空均衡”。传统方法通过引入归纳偏置来促进通信涌现。本研究从根本上质疑这种人工归纳偏置是否过度设计。通过“AI母语”（AIM）框架的实验，该框架基于矢量量化变分自编码器（VQ-VAE），我们证明当智能体拥有内生符号系统时，它们的神经表征自然地表现出自发的语义压缩和纳什均衡驱动的语义收敛，从而在没有外部归纳偏置的情况下实现了有效的符号通信。这与最近的神经科学发现（人类大脑不直接使用人类语言进行内部思考）以及大型语言模型（LLMs）中“软思维”能力的研究相吻合。与传统显式通信方法相比，AIM展现出更强的通用性和效率。本研究开发的解释性分析工具证实符号使用呈现显著的幂律分布，并导出了三个主要的理论洞察：“神经通信假说”、“工具优先原则”和“语义可解释性范式”。未来的研究将探索集成层级量化变分自编码器（HQ-VAE）以增强AIM的复杂表达能力，并研究“强化学习（RL）低级预训练”的潜力。这项发现为连接符号主义和联结主义提供了新途径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [632] [From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents](https://arxiv.org/abs/2507.10644)
> *从语义网和多智能体系统到智能体AI：智能体网络的统一叙事*

*Tatiana Petrova, Aleksandr Puzikov, Boris Bliznukov, Radu State* | **Category: cs.AI, cs.CL, cs.CR, cs.HC, cs.MA, I.2.11; I.2.7; C.2.4; K.6.5; I.2.4** | **Updated: 2025-07-14**

**Keywords:** 智能体网络, 智能体AI, 语义网, 多智能体系统, 大型语言模型

**Comment:** 33 pages, 9 figures, 8 tables

> **TL;DR:** 本文首次全面概述了智能体网络（WoA）的演变，统一了语义网、多智能体系统和现代大型语言模型驱动的智能体AI的历史，并提出了未来研究的新议程。

**AI_Comments:** 这篇论文的创新之处在于为智能体网络领域提供了急需的历史和概念统一，弥补了该领域碎片化的现状。通过引入全面的分类法并识别“智能体所在地”的范式转变，它为理解智能体AI的演变和未来方向提供了宝贵的框架。其强调超越技术协议的社会技术挑战尤为深刻和重要，对现实世界部署具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 智能体网络（WoA）领域的研究在不同社区之间碎片化，多智能体系统（MAS）和语义网的历史常被视为与现代大型语言模型驱动的框架无关。这种碎片化模糊了知识谱系，阻碍了对该领域发展轨迹的整体理解。

**Method:** 作者首次全面概述了智能体网络（WoA）的演变。他们引入了一个四轴分类法（语义基础、通信范式、智能体所在地、发现机制）来系统化分析并比较不同代的智能体架构。

**Result:** 分析揭示了一条清晰的演变路径，纠正了过去被认为是断裂的认知。研究识别出“智能体所在地”的范式转变：从编码在外部数据（语义网）或平台（多智能体系统）中，转变为嵌入在智能体核心模型（大型语言模型）中，这为现代智能体AI奠定了基础。

**Conclusion:** 虽然新协议至关重要，但不足以构建一个健壮、开放、值得信赖的生态系统。下一个研究前沿在于解决持续存在的社会技术挑战，包括去中心化身份、经济模型、安全和治理，以构建新兴的智能体网络。

> **ai_Abstract:** 本文首次全面概述了智能体网络（WoA）的演变，通过追溯从语义网和多智能体系统（MAS）到现代大型语言模型驱动的智能体AI的知识谱系，解决了该领域研究的碎片化问题。论文引入了一个四轴分类法来统一智能体架构的分析，并强调了“智能体所在地”向大型语言模型嵌入式模型的范式转变。文章总结道，虽然新协议很重要，但解决去中心化身份、经济模型、安全和治理等社会技术挑战对于构建一个健壮的WoA生态系统至关重要。

> **摘要翻译:** 智能体网络（WoA）的概念，即将静态的、以文档为中心的网络转变为代表用户行事的自主智能体环境，随着大型语言模型（LLMs）能力的增强而吸引了越来越多的关注。然而，该领域的研究在不同社区之间仍然是碎片化的。当代的调查目录列出了最新的LLM驱动框架，而多智能体系统（MAS）和语义网的丰富历史往往被视为独立的、遗留的领域。这种碎片化模糊了现代系统的知识谱系，阻碍了对该领域发展轨迹的整体理解。我们首次全面概述了WoA的演变。我们展示了像A2A和MCP这样的现代协议，是对早期标准如FIPA标准和基于OWL的语义智能体的已充分记录的局限性的直接演变响应。为了系统化这一分析，我们引入了一个四轴分类法（语义基础、通信范式、智能体所在地、发现机制）。这个框架提供了一个统一的分析视角，用于比较所有代的智能体架构，揭示了一条清晰的演变路径，而其他人则看到了脱节。我们的分析识别出“智能体所在地”的范式转变：从编码在外部数据（语义网）或平台（MAS）中，转变为嵌入在智能体核心模型（LLM）中。这一转变是现代智能体AI的基础，实现了WoA长期以来设想的可扩展和自适应系统。我们得出结论，虽然新协议至关重要，但它们不足以构建一个健壮、开放、值得信赖的生态系统。最后，我们认为下一个研究前沿在于解决持续存在的社会技术挑战，并为新兴的WoA规划了一个侧重于去中心化身份、经济模型、安全和治理的新议程。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [646] [Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems](https://arxiv.org/abs/2507.11277)
> *自动化驯服不确定性：观察、分析和优化智能体AI系统*

*Dany Moshkovich, Sergey Zeltyn* | **Category: cs.AI, cs.MA** | **Updated: 2025-07-15**

**Keywords:** 智能体系统, 不确定性管理, 自动化, 可观测性, LLM

**Comment:** 

> **TL;DR:** 本文介绍了AgentOps框架，用于观察、分析、优化和自动化智能体AI系统的操作，以驯服其固有的不确定性，确保安全、自适应和有效运行。

**AI_Comments:** 这篇论文的创新点在于提出了一个专门针对智能体AI系统不确定性管理的综合框架AgentOps，并强调了自动化的核心作用。它认识到传统软件运维方法在面对LLM带来的复杂性和不确定性时的不足，并为不同利益相关者（开发者、测试人员、SRE、业务用户）提供了解决方案。其提出的六阶段自动化管道为智能体系统的可观测性、分析和优化提供了一个清晰的路径，这对于推动AI代理的实际部署和可靠性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）驱动的智能体系统在带来强大新能力的同时，也引入了源于概率推理、动态内存状态和流动执行路径的独特不确定性。传统的软件可观测性和运营实践不足以应对这些挑战。

**Method:** 本文提出了AgentOps，一个用于观察、分析、优化和自动化智能体AI系统操作的综合框架。它识别了开发者、测试人员、SRE和业务用户四种角色的独特需求。AgentOps引入了自动化管道，这是一个六阶段的过程，包括行为观察、指标收集、问题检测、根本原因分析、优化推荐和运行时自动化。

**Result:** AgentOps框架能够观察、分析、优化和自动化智能体AI系统的操作，从而有效地管理不确定性，并使AI系统能够自我改进，确保安全、自适应和有效运行。

**Conclusion:** 自动化在管理智能体AI系统的不确定性方面发挥着关键作用，它不是消除不确定性，而是驯服它，以实现安全、自适应和有效的操作，从而实现自我改进的AI系统。

> **ai_Abstract:** 本文针对大型语言模型（LLM）驱动的智能体系统所固有的不确定性，提出了一种名为AgentOps的综合框架。AgentOps旨在通过提供一套包括行为观察、指标收集、问题检测、根本原因分析、优化推荐和运行时自动化在内的六阶段自动化管道，来观察、分析、优化和自动化这些系统的操作。该框架强调自动化在管理不确定性和促进AI系统自我改进方面的核心作用，从而确保智能体AI系统的安全、自适应和有效运行。

> **摘要翻译:** 大型语言模型（LLM）越来越多地部署在智能体系统中——这些系统是由相互作用的、由LLM驱动的智能体组成的集合，它们利用记忆、工具和动态规划来执行复杂的、自适应的工作流。虽然这些系统带来了强大的新能力，但它们也引入了源于概率推理、不断演变的记忆状态和流动的执行路径的独特不确定性。传统的软件可观测性和运营实践在应对这些挑战时显得力不从心。
本文介绍了AgentOps：一个用于观察、分析、优化和自动化智能体AI系统操作的综合框架。我们识别了四种关键角色——开发者、测试人员、站点可靠性工程师（SRE）和业务用户——的独特需求，他们每个人都在系统生命周期的不同阶段与系统交互。我们提出了AgentOps自动化管道，这是一个包含行为观察、指标收集、问题检测、根本原因分析、优化推荐和运行时自动化六个阶段的过程。在此过程中，我们强调了自动化在管理不确定性和实现自我改进AI系统中的关键作用——不是通过消除不确定性，而是通过驯服它来确保安全、自适应和有效的操作。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [647] [AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks](https://arxiv.org/abs/2507.10831)
> *AF-XRAY：法律论证框架中歧义的可视化解释与解决*

*Yilin Xia, Heng Zheng, Shawn Bowers, Bertram Ludäscher* | **Category: cs.AI** | **Updated: 2025-07-14**

**Keywords:** 法律论证框架, 可视化, 歧义解决, AF-XRAY, 法律推理

**Comment:** International Conference on Artificial Intelligence and Law (ICAIL),
  June 16-20, 2025. Chicago, IL, USA

> **TL;DR:** AF-XRAY是一个开源工具包，通过可视化和分析帮助非专家理解和解决法律论证框架中的歧义。

**AI_Comments:** 该论文提出AF-XRAY工具，通过创新的可视化方法和歧义解决机制，显著降低了非专家理解和应用法律论证框架的门槛。其通过系统生成关键攻击集来解决未决论证的策略，以及揭示不同假设如何影响结论的能力，对于法律推理的透明度和可解释性具有重要意义。这是一个非常有用的工具，提升了法律AI的可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 论证框架（AFs）为法律推理提供了形式化方法，但对于非专家而言，识别歧义来源和解释论证接受度仍然具有挑战性。

**Method:** AF-XRAY是一个用于探索、分析和可视化法律推理中抽象论证框架的开源工具包。它引入了：(i) 基于博弈论论证长度的分层可视化；(ii) 攻击边的语义角色分类；(iii) 模糊三值基础语义上替代二值解的叠加可视化；(iv) 识别关键攻击集以解决未决论证。通过系统生成关键攻击集，AF-XRAY将模糊场景转换为基础解决方案。

**Result:** AF-XRAY能够将模糊场景转换为基础解决方案，使用户能够查明歧义的具体原因并探索替代解决方案。通过真实世界的法律案例（例如Bench-Capon建模的《野兽》），该工具支持目的论法律推理，揭示不同假设如何导致不同的合理结论。

**Conclusion:** AF-XRAY通过揭示不同假设如何导致不同的合理结论，支持目的论法律推理，并帮助用户理解和解决法律论证框架中的歧义。

> **ai_Abstract:** AF-XRAY是一个开源工具包，旨在解决法律论证框架（AFs）中非专家难以识别歧义来源和理解论证接受度的问题。该工具通过分层可视化、攻击边分类、叠加可视化替代解决方案以及识别和处理关键攻击集来探索、分析和可视化AFs。通过将模糊场景转化为明确的解决方案，AF-XRAY使用户能够查明歧义并探索不同的解决路径。在真实法律案例中的应用表明，AF-XRAY能够支持目的论法律推理，展示不同假设如何影响最终结论。

> **摘要翻译:** 论证框架（AFs）为法律推理提供了形式化方法，但对于非专家而言，识别歧义来源和解释论证接受度仍然具有挑战性。我们提出了AF-XRAY，一个用于探索、分析和可视化法律推理中抽象论证框架的开源工具包。AF-XRAY引入了：(i) 基于博弈论论证长度的分层可视化，揭示了基础推导结构；(ii) 攻击边按语义角色（主要、次要、错误）分类；(iii) 模糊三值基础语义上替代二值解的叠加可视化；(iv) 识别关键攻击集，通过暂停这些集合来解决未决论证。通过系统生成关键攻击集，AF-XRAY将模糊场景转换为基础解决方案，使用户能够查明歧义的具体原因并探索替代解决方案。我们使用真实世界的法律案例（例如Bench-Capon建模的《野兽》）来展示我们的工具如何通过揭示不同假设如何导致不同的合理结论来支持目的论法律推理。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [657] [An Agentic Framework for Autonomous Metamaterial Modeling and Inverse Design](https://arxiv.org/abs/2506.06935)
> *用于自主超材料建模和逆向设计的智能体框架*

*Darui Lu, Jordan M. Malof, Willie J. Padilla* | **Category: cs.AI, cond-mat.mtrl-sci** | **Updated: 2025-07-15**

**Keywords:** 智能体框架, 超材料, 逆向设计, 大型语言模型, 光子学

**Comment:** 22 pages, 6 figures

> **TL;DR:** 本文提出并展示了一个智能体框架，用于光子超材料的自主逆向设计，该框架能够利用大语言模型和外部工具自动完成复杂任务。

**AI_Comments:** 这篇论文的创新点在于将大型语言模型（LLM）的智能体框架应用于复杂的科学研究领域，特别是超材料的逆向设计。其重要性在于实现了设计过程的高度自动化和智能化，减少了人工干预，并可能加速新材料的发现。框架的内部反思和决策灵活性是其亮点，有望产生传统方法难以实现的新颖设计。

<details>
  <summary>Details</summary>

**Motivation:** 近期整合多个大型语言模型（LLM）系统的显著进展，使得能够自主执行复杂任务（包括新颖科学研究）的智能体框架成为可能。本文旨在开发并展示一个专门用于光子超材料逆向设计的此类框架。

**Method:** 该智能体框架在接收到所需光学光谱查询时，能够自主提出并开发一个正向深度学习模型，通过API访问外部工具进行仿真和优化等任务，利用记忆，并通过深度逆向方法生成最终设计。

**Result:** 该框架在自动化、推理、规划和适应方面的能力得到了验证。值得注意的是，该智能体框架具有内部反思和决策灵活性，允许高度多样化和潜在新颖的输出。

**Conclusion:** 该智能体框架能够自主执行光子超材料的建模和逆向设计，并通过其自动化、推理、规划、适应、内部反思和决策灵活性展示了其有效性，有望产生多样化和新颖的设计。

> **ai_Abstract:** 本文介绍了一个基于大型语言模型（LLM）的智能体框架，专门用于光子超材料的自主建模和逆向设计。该框架能够根据所需光学光谱，自主开发深度学习模型，调用外部工具进行仿真和优化，并利用记忆生成最终设计。该研究强调了该框架在自动化、推理、规划、适应、内部反思和决策灵活性方面的有效性，使其能够产生多样化和创新性的设计。

> **摘要翻译:** 近期整合多个大型语言模型（LLM）系统的显著进展，使得能够自主执行复杂任务（包括新颖科学研究）的智能体框架成为可能。我们开发并展示了这样一个专门用于光子超材料逆向设计的框架。当接收到所需光学光谱查询时，该智能体能够自主提出并开发一个正向深度学习模型，通过API访问外部工具进行仿真和优化等任务，利用记忆，并通过深度逆向方法生成最终设计。该框架在自动化、推理、规划和适应方面的能力得到了验证。值得注意的是，该智能体框架具有内部反思和决策灵活性，允许高度多样化和潜在新颖的输出。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [669] [Contestability in Quantitative Argumentation](https://arxiv.org/abs/2507.11323)
> *量化论证中的可争议性*

*Xiang Yin, Nico Potyka, Antonio Rago, Timotheus Kampik, Francesca Toni* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 可争议性AI, 量化论证, EW-QBAFs, 梯度基关系归因解释, 权重调整

**Comment:** 

> **TL;DR:** 本文提出了一种基于梯度的关系归因解释 (G-RAEs) 方法，用于量化边缘加权量化双极论证框架 (EW-QBAFs) 中论证强度对边缘权重变化的敏感性，并通过迭代算法调整权重以实现可争议性，并在模拟个性化推荐系统和多层感知器的合成EW-QBAFs上进行了有效性验证。

**AI_Comments:** 该论文在AI可解释性和可争议性领域做出了重要贡献，特别是在量化论证框架中。G-RAEs的提出为理解和调整AI决策背后的偏好提供了新颖且可解释的机制，这对于构建更符合人类价值观的AI系统至关重要。将该方法应用于个性化推荐系统和多层感知器等实际场景的模拟，显示了其潜在的应用价值和普适性。

<details>
  <summary>Details</summary>

**Motivation:** 可争议的AI要求AI驱动的决策与人类偏好保持一致。虽然各种形式的论证已被证明支持可争议性，但边缘加权量化双极论证框架 (EW-QBAFs) 却很少受到关注。本文旨在解决如何部署EW-QBAFs以实现AI决策的可争议性问题。

**Method:** 本文引入了EW-QBAFs的可争议性问题，即如何修改边缘权重（如偏好）以达到特定论证（主题论证）的期望强度。为解决此问题，作者提出了梯度基关系归因解释 (G-RAEs)，它量化了主题论证强度对单个边缘权重变化的敏感性，为权重调整提供了可解释的指导。在此基础上，开发了一种迭代算法，逐步调整边缘权重以达到期望强度。

**Result:** 在模拟个性化推荐系统和多层感知器结构特征的合成EW-QBAFs上进行了实验评估，结果表明该方法能够有效地解决可争议性问题。

**Conclusion:** 本文展示了如何利用边缘加权量化双极论证框架 (EW-QBAFs) 来支持可争议的AI，并通过提出G-RAEs和迭代算法，有效解决了EW-QBAFs中的可争议性问题，实现了对特定论证强度的精确控制。

> **ai_Abstract:** 本文探讨了在边缘加权量化双极论证框架 (EW-QBAFs) 中实现AI决策可争议性的方法。作者提出了可争议性问题，即如何调整边缘权重以达到特定论证的期望强度。为解决此问题，引入了梯度基关系归因解释 (G-RAEs) 以量化论证强度对权重变化的敏感性，并基于此开发了一种迭代算法进行权重调整。实验证明该方法在模拟推荐系统和多层感知器的合成EW-QBAFs上是有效的。

> **摘要翻译:** 可争议的AI要求AI驱动的决策与人类偏好保持一致。虽然各种形式的论证已被证明支持可争议性，但边缘加权量化双极论证框架 (EW-QBAFs) 却很少受到关注。在这项工作中，我们展示了如何为此目的部署EW-QBAFs。具体来说，我们引入了EW-QBAFs的可争议性问题，即如何修改边缘权重（例如，偏好）以实现特定论证（即主题论证）的期望强度。为了解决这个问题，我们提出了梯度基关系归因解释 (G-RAEs)，它量化了主题论证强度对单个边缘权重变化的敏感性，从而为实现可争议性的权重调整提供可解释的指导。在G-RAEs的基础上，我们开发了一种迭代算法，逐步调整边缘权重以达到期望强度。我们在模拟个性化推荐系统和多层感知器结构特征的合成EW-QBAFs上对我们的方法进行了实验评估，并证明它能有效地解决该问题。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [700] [Establishing Best Practices for Building Rigorous Agentic Benchmarks](https://arxiv.org/abs/2507.02825)
> *建立严谨的智能体基准测试的最佳实践*

*Yuxuan Zhu, Tengjun Jin, Yada Pruksachatkun, Andy Zhang, Shu Liu, Sasha Cui, Sayash Kapoor, Shayne Longpre, Kevin Meng, Rebecca Weiss, Fazl Barez, Rahul Gupta, Jwala Dhamala, Jacob Merizian, Mario Giulianelli, Harry Coppock, Cozmin Ududec, Jasjeet Sekhon, Jacob Steinhardt, Antony Kellerman, Sarah Schwettmann, Matei Zaharia, Ion Stoica, Percy Liang, Daniel Kang* | **Category: cs.AI, A.1; I.2.m** | **Updated: 2025-07-14**

**Keywords:** 智能体基准测试, 最佳实践, 评估, 清单, AI智能体

**Comment:** 39 pages, 15 tables, 6 figures

> **TL;DR:** 现有智能体基准测试存在设置或奖励设计问题，导致评估不准确。本文提出了智能体基准测试清单（ABC），一套指导方针，旨在建立严谨的评估实践，并已证明能有效减少性能高估。

**AI_Comments:** 本文提出了一种实用的方法来解决当前智能体基准测试中普遍存在的评估不严谨问题。通过引入“智能体基准测试清单（ABC）”，为研究人员和实践者提供了一套明确的指南，以构建更可靠和准确的智能体评估体系。其创新性在于将现有问题系统化，并提炼出可操作的解决方案，对提升整个AI智能体评估领域的质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI智能体能力日益增强，智能体基准测试被引入以评估其在复杂真实世界任务中的表现。然而，研究发现许多智能体基准测试在任务设置或奖励设计上存在问题，导致智能体性能被低估或高估高达100%。

**Method:** 为了使智能体评估更加严谨，本文引入了智能体基准测试清单（ABC）。该清单是一套指导方针，综合了作者的基准构建经验、对最佳实践的调查以及先前报告的问题。

**Result:** 将智能体基准测试清单（ABC）应用于CVE-Bench（一个评估设计特别复杂的基准测试）时，性能高估降低了33%。

**Conclusion:** 通过引入智能体基准测试清单（ABC），可以建立更严谨的智能体评估实践，从而提高评估的准确性并避免性能的过度或低估。

> **ai_Abstract:** 本文指出当前智能体基准测试存在任务设置和奖励设计缺陷，可能导致智能体性能评估不准确。为解决此问题，作者提出了智能体基准测试清单（ABC），一套基于经验和最佳实践的严谨评估指南。实验证明，ABC 能有效减少基准测试中的性能高估，例如在CVE-Bench上将高估降低了33%。

> **摘要翻译:** 基准测试对于量化跟踪人工智能的进展至关重要。随着AI智能体能力日益增强，研究人员和实践者引入了智能体基准测试，以评估智能体在复杂真实世界任务中的表现。这些基准测试通常通过特定的奖励设计评估任务结果来衡量智能体能力。然而，我们发现许多智能体基准测试在任务设置或奖励设计上存在问题。例如，SWE-bench Verified 使用了不充分的测试用例，而TAU-bench 将空响应计为成功。这些问题可能导致智能体性能被低估或高估，相对误差可达100%。为了使智能体评估严谨，我们引入了智能体基准测试清单（ABC），这是一套我们从基准构建经验、最佳实践调查和先前报告问题中综合提炼出的指导方针。当应用于CVE-Bench（一个评估设计特别复杂的基准测试）时，ABC 将性能高估降低了33%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [703] [WhisperKit: On-device Real-time ASR with Billion-Scale Transformers](https://arxiv.org/abs/2507.10860)
> *WhisperKit：十亿级Transformer的设备端实时ASR*

*Atila Orhon, Arda Okan, Berkin Durmus, Zach Nagengast, Eduardo Pacheco* | **Category: cs.AI** | **Updated: 2025-07-14**

**Keywords:** 实时ASR, 设备端推理, WhisperKit, 语音识别, Transformer

**Comment:** ICML 2025 - On-Device Learning for Foundational Models Workshop

> **TL;DR:** WhisperKit是一个优化的设备端实时ASR推理系统，它在延迟和准确性方面显著优于领先的云端系统。

**AI_Comments:** WhisperKit的创新之处在于其在设备端实现了与云端领先系统相媲美甚至超越的实时ASR性能，尤其是在准确性和延迟方面。这对于需要高隐私、低网络依赖或边缘计算的商业应用具有重要意义。该系统利用了十亿级Transformer模型，并在设备端进行了优化，解决了传统云端ASR的潜在瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 实时自动语音识别（ASR）是许多商业机器学习应用的基础构建模块，如实时字幕、听写、会议转录和医疗记录。在公司选择部署系统时，准确性和延迟是最重要的因素。

**Method:** 本文介绍了WhisperKit，一个用于实时ASR的优化设备端推理系统。该系统通过优化实现了性能提升。

**Result:** WhisperKit在延迟方面与最低延迟系统（0.46秒）持平，同时实现了最高的准确性（2.2% WER）。它显著优于包括OpenAI gpt-4o-transcribe、Deepgram nova-3和Fireworks large-v3-turbo在内的领先云端系统。

**Conclusion:** WhisperKit证明了设备端实时ASR系统可以同时达到领先的准确性和极低的延迟，甚至超越了当前顶级的云端服务。

> **ai_Abstract:** WhisperKit是一个针对实时自动语音识别（ASR）设计的优化设备端推理系统，旨在解决商业应用中对高准确性和低延迟的需求。通过与OpenAI gpt-4o-transcribe、Deepgram nova-3和Fireworks large-v3-turbo等领先云端ASR系统进行基准测试，WhisperKit展示了其卓越性能，实现了0.46秒的低延迟和2.2% WER的最高准确率，证明了其在设备端提供高性能ASR的能力。

> **摘要翻译:** 实时自动语音识别（ASR）是许多商业机器学习应用的基石，包括实时字幕、听写、会议转录和医疗记录。在公司选择部署系统时，准确性和延迟是最重要的因素。我们推出了WhisperKit，一个用于实时ASR的优化设备端推理系统，其性能显著优于领先的云端系统。我们与部署了多种模型的服务器端系统进行了基准测试，包括前沿模型（OpenAI gpt-4o-transcribe）、专有模型（Deepgram nova-3）和开源模型（Fireworks large-v3-turbo）。我们的结果显示，WhisperKit以0.46秒的延迟匹配了最低延迟，同时实现了2.2% WER的最高准确率。本文详细描述了WhisperKit系统背后的优化。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [740] [SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents](https://arxiv.org/abs/2507.10562)
> *SAMEP：一种用于AI代理间持久上下文共享的安全协议*

*Hari Masoor* | **Category: cs.AI, cs.CR, cs.DB, cs.LG** | **Updated: 2025-07-05**

**Keywords:** AI代理, 记忆共享, 安全协议, 上下文管理, 分布式内存

**Comment:** 7 pages, 4 figures, 3 implementation examples. Original work
  submitted as a preprint

> **TL;DR:** AI代理的记忆有限，SAMEP提供了一个安全的、可搜索的持久记忆共享协议，显著减少了冗余计算并提高了上下文相关性。

**AI_Comments:** SAMEP的创新之处在于其将持久性、安全性（通过加密和细粒度访问控制）和语义可搜索性集成到一个统一的协议中，以解决AI代理记忆限制的问题。这对于实现更智能、更协作的AI系统至关重要，特别是在需要数据隐私和合规性的领域（如医疗保健）。其量化结果也很有说服力。

<details>
  <summary>Details</summary>

**Motivation:** 当前AI代理架构存在短暂记忆限制，阻碍了跨会话和代理边界的有效协作和知识共享。

**Method:** SAMEP（安全代理内存交换协议）是一个新颖的框架，通过实现分布式内存库，具有基于向量的语义搜索、加密访问控制（AES-256-GCM）和兼容现有代理通信协议（MCP, A2A）的标准化API，解决了持久上下文保存、细粒度访问控制的安全多代理协作以及相关历史上下文的有效语义发现三个挑战。

**Result:** 实验结果显示：冗余计算减少73%，上下文相关性分数提高89%，完全符合包括审计跟踪生成在内的监管要求。

**Conclusion:** SAMEP实现了持久的、协作的AI代理生态系统新范式，同时保持了安全和隐私保障。

> **ai_Abstract:** 本文介绍了SAMEP（安全代理内存交换协议），一个旨在解决当前AI代理记忆短暂性问题的新框架。SAMEP通过提供一个持久、安全且语义可搜索的分布式内存库，使AI代理能够跨会话和代理边界共享知识。该协议通过向量语义搜索、AES-256-GCM加密访问控制和标准化API来解决上下文保存、安全协作和高效语义发现的挑战。实验证明，SAMEP能显著减少冗余计算、提高上下文相关性，并符合监管要求，为协作式AI代理生态系统提供了新的范式。

> **摘要翻译:** 当前AI代理架构存在短暂记忆限制，阻碍了跨会话和代理边界的有效协作和知识共享。我们引入了SAMEP（安全代理内存交换协议），这是一个新颖的框架，能够实现AI代理之间持久、安全和语义可搜索的记忆共享。我们的协议解决了三个关键挑战：(1) 跨代理会话的持久上下文保存，(2) 具有细粒度访问控制的安全多代理协作，以及 (3) 相关历史上下文的有效语义发现。SAMEP实现了一个分布式内存库，具有基于向量的语义搜索、加密访问控制（AES-256-GCM）和兼容现有代理通信协议（MCP, A2A）的标准化API。我们展示了SAMEP在多代理软件开发、符合HIPAA标准的医疗AI以及多模态处理管道等不同领域的有效性。实验结果显示，冗余计算减少了73%，上下文相关性分数提高了89%，并且完全符合包括审计跟踪生成在内的监管要求。SAMEP在保持安全和隐私保障的同时，开创了持久协作式AI代理生态系统的新范式。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [744] [CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking](https://arxiv.org/abs/2507.11334)
> *CogDDN：一种结合决策优化和双过程思维的认知需求驱动导航*

*Yuehao Huang, Liang Liu, Shuangming Lei, Yukai Ma, Hao Su, Jianbiao Mei, Pengxiang Zhao, Yaqing Gu, Yong Liu, Jiajun Lv* | **Category: cs.AI, cs.RO** | **Updated: 2025-07-15**

**Keywords:** 认知导航, 需求驱动导航, 双过程思维, 移动机器人, VLM

**Comment:** Accepted by ACM MM 2025

> **TL;DR:** CogDDN提出了一种基于VLM的认知需求驱动导航框架，通过模仿人类认知和学习机制，结合快速和慢速思维系统来提高机器人导航的准确性和适应性。

**AI_Comments:** 本文的创新之处在于将类人认知过程（双过程思维、快速/慢速思维、思维链）融入机器人导航，超越了纯粹的数据驱动方法。这增强了在新环境中的泛化能力和适应性，这对于实际机器人应用至关重要。VLM的运用也表明了多模态理解。

<details>
  <summary>Details</summary>

**Motivation:** 传统的以数据驱动的需求驱动导航（DDN）方法依赖于预先收集的数据进行模型训练和决策，这限制了它们在未知场景中的泛化能力。

**Method:** 本文提出了CogDDN，一个基于VLM的框架，它通过整合快速和慢速思维系统并选择性地识别满足用户需求的关键对象，来模仿人类的认知和学习机制。CogDDN通过语义对齐检测到的对象与给定指令来识别目标对象。此外，它还包含一个双过程决策模块，包括用于快速高效决策的启发式过程和分析过去错误、积累知识并持续改进性能的分析过程。思维链（CoT）推理也强化了决策过程。

**Result:** 在AI2Thor模拟器上使用ProcThor数据集进行的广泛闭环评估显示，CogDDN比仅使用单视角摄像头的方法性能提高15%，在导航精度和适应性方面表现出显著改进。

**Conclusion:** CogDDN通过整合类人认知过程，显著提高了移动机器人在未知环境中的导航精度和适应性。

> **ai_Abstract:** CogDDN是一个创新的基于VLM的框架，旨在通过模仿人类认知和学习机制来改进移动机器人在未知环境中的需求驱动导航。它克服了传统DDN方法泛化能力差的局限性，结合了快速和慢速思维系统、双过程决策模块（启发式和分析过程），并利用思维链推理。实验结果表明，CogDDN在导航精度和适应性方面显著优于现有方法。

> **摘要翻译:** 移动机器人越来越需要未知和非结构化环境中导航和交互以满足人类需求。需求驱动导航（DDN）使机器人能够根据隐含的人类意图识别和定位物体，即使物体位置未知。然而，传统的数据驱动DDN方法依赖于预收集的数据进行模型训练和决策，限制了它们在未见场景中的泛化能力。在本文中，我们提出了CogDDN，一个基于VLM的框架，通过整合快速和慢速思维系统并选择性地识别对满足用户需求至关重要的关键对象，来模仿人类的认知和学习机制。CogDDN通过语义对齐检测到的对象与给定指令来识别适当的目标对象。此外，它还包含一个双过程决策模块，包括用于快速高效决策的启发式过程，以及分析过去错误、将其积累到知识库中并持续改进性能的分析过程。思维链（CoT）推理增强了决策过程。在AI2Thor模拟器上使用ProcThor数据集进行的广泛闭环评估显示，CogDDN比仅使用单视角摄像头的方法性能提高15%，这表明在导航精度和适应性方面有显著改进。项目页面可在https://yuehaohuang.github.io/CogDDN/访问。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [751] [Is Human-Written Data Enough? The Challenge of Teaching Reasoning to LLMs Without RL or Distillation](https://arxiv.org/abs/2507.09850)
> *人工编写的数据足够吗？在没有强化学习或蒸馏的情况下教授大型语言模型推理的挑战*

*Wei Du, Branislav Kisacanin, George Armstrong, Shubham Toshniwal, Ivan Moshkov, Alexan Ayrapetyan, Sadegh Mahdavi, Dan Zhao, Shizhe Diao, Dragan Masulovic, Marius Stanean, Advaith Avadhanam, Max Wang, Ashmit Dutta, Shitij Govil, Sri Yanamandara, Mihir Tandon, Sriram Ananthakrishnan, Vedant Rathi, David Zhang, Joonseok Kang, Leon Luo, Titu Andreescu, Boris Ginsburg, Igor Gitman* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 推理, 思维链, 大型语言模型, 微调, 人工数据

**Comment:** Accepted at the Second AI for Math Workshop at the 42nd International
  Conference on Machine Learning (ICML 2025)

> **TL;DR:** 研究表明，仅用少量高质量的思维链（CoT）示例进行轻微微调，小型大型语言模型（LLM）就能展现出强大的推理能力，甚至超越更大的模型，但人工编写的CoT数据难以达到专家模型的表现。

**AI_Comments:** 该论文创新性地展示了仅通过极少量高质量专家数据，便能显著提升大型语言模型的推理能力，颠覆了传统上对大规模数据或复杂训练范式（如强化学习或蒸馏）的依赖。其重要性在于揭示了数据“质量”在推理能力激发中的关键作用，而非单纯的“数量”。同时，论文也指出了人类编写数据在达到专家模型表现时的局限性，这为理解高质量推理数据的本质提供了宝贵线索，并为未来的数据标注和模型训练指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 探讨是否仅通过提示或最少的微调，就能在基础大型语言模型中诱导生成长篇的思维链（CoT）推理能力，而无需依赖强化学习或从更强的模型进行蒸馏。

**Method:** 1. 使用来自推理模型QwQ-32B-Preview的20个长篇CoT示例，对基础模型Qwen2.5-32B进行轻量级微调。2. 进一步探索使用来自非推理模型和人类标注者的CoT数据，并结合提示工程、多轮编辑和结构化指导进行增强。3. 分析影响推理蒸馏的关键推理数据特性，如问题难度、多样性和答案长度。

**Result:** 1. 经过微调的模型（Qwen2.5-32B）表现优于更大的Qwen2.5-Math-72B-Instruct模型，表明少量高质量示例即可激发强大的推理能力。2. 来源于非推理模型和人类标注者的CoT数据（即使经过增强）未能达到推理模型轨迹的性能，这表明专家CoT的某些潜在质量难以复制。

**Conclusion:** 尽管存在挑战，但精心策划的人工编写的思维链（CoT）数据，即使数量很少，也能激活基础模型中的推理行为。

> **ai_Abstract:** 本研究探讨了在不使用强化学习或蒸馏的情况下，能否仅通过少量微调，在基础大型语言模型（LLM）中诱导长篇思维链（CoT）推理能力。研究发现，仅用20个专家CoT示例对Qwen2.5-32B进行轻度微调，其性能便超越了更大的Qwen2.5-Math-72B-Instruct。尽管尝试通过提示工程和编辑增强人工编写的CoT数据，但其效果仍不及专家模型生成的CoT轨迹。这表明专家CoT中存在难以复制的潜在质量。论文最后提出，少量精心策划的人工编写CoT数据足以激活基础模型的推理行为，并发布了相关数据集以促进未来研究。

> **摘要翻译:** 能够进行推理的语言模型通过生成长而明确的思维链（CoT）轨迹，在各种复杂任务中取得了最先进的性能。虽然最近的工作表明，基础模型可以通过强化学习或从DeepSeek-R1等更强模型进行蒸馏来获得此类推理轨迹，但之前的工作表明，即使是未经微调的短CoT提示也能改善推理。我们提出疑问，是否仅通过提示或最少量的微调，就能在基础模型中诱导生成长篇CoT。我们仅使用来自推理模型QwQ-32B-Preview的20个长CoT示例，对基础模型Qwen2.5-32B进行了轻度微调。结果模型超越了更大的Qwen2.5-Math-72B-Instruct，表明少量高质量示例即可解锁强大的推理能力。我们进一步探索了使用来自非推理模型和人类标注者的CoT数据，并结合提示工程、多轮编辑和结构化指导进行增强。然而，两者都未能与推理模型轨迹的性能相匹配，这表明专家CoT的某些潜在质量难以复制。我们分析了影响推理蒸馏的推理数据的关键属性，例如问题难度、多样性和答案长度。尽管挑战依然存在，但我们乐观地认为，精心策划的人工编写的CoT，即使数量很少，也能激活基础模型中的推理行为。我们发布了跨精炼阶段的人工编写数据集，并邀请进一步研究小规模推理监督为何如此有效。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [759] [NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization](https://arxiv.org/abs/2507.10894)
> *NavComposer：通过动作-场景-对象模块化组合导航轨迹的语言指令*

*Zongtao He, Liuyi Wang, Lu Chen, Chengju Liu, Qijun Chen* | **Category: cs.AI, cs.CL, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 语言引导导航, 指令生成, 导航指令评估, 模块化, 语义实体

**Comment:** 

> **TL;DR:** 提出NavComposer，通过动作-场景-对象模块化自动生成高质量导航指令；并引入NavInstrCritic，一个无需标注的指令评估系统。

**AI_Comments:** NavComposer通过其独特的动作-场景-对象模块化方法，创新性地解决了高质量导航指令数据稀缺的问题，实现了指令的自动生成和增强。同时，NavInstrCritic的引入，特别是其无标注的评估机制，极大地提升了指令评估的效率和客观性，克服了传统方法对专家标注的依赖。这种生成与评估解耦的范式，对于推动具身AI领域的可扩展性和通用性研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 专家提供的导航指令数量有限且合成指令质量不足，无法满足大规模语言引导导航研究的需求。

**Method:** 本文提出了NavComposer框架，通过显式分解动作、场景和对象等语义实体并重组为自然语言指令，以自动生成高质量导航指令。其模块化架构允许灵活集成先进技术，且以数据无关的方式运行。此外，还引入了NavInstrCritic，一个全面的无标注评估系统，从对比匹配、语义一致性和语言多样性三个维度评估导航指令的质量，解决了传统评估方法依赖专家标注的局限性。

**Result:** 大量实验证明了所提方法的有效性。

**Conclusion:** 该方法通过将指令生成和评估与特定导航代理解耦，从而实现了更具可扩展性和通用性的具身AI研究。

> **ai_Abstract:** 本文提出了NavComposer框架，旨在自动生成高质量的导航语言指令。该框架通过模块化分解动作、场景和对象等语义实体并进行重组，实现指令的丰富性和准确性，并支持数据无关的适应性。为解决传统评估方法的局限，文章同时引入了NavInstrCritic，一个无需标注的综合评估系统，从对比匹配、语义一致性和语言多样性三个维度对导航指令质量进行全面评估。这种方法将指令的生成与评估从特定导航代理中解耦，从而促进了更具可扩展性和通用性的具身AI研究。

> **摘要翻译:** 语言引导导航是具身AI的基石，它使智能体能够解释语言指令并在复杂环境中导航。然而，专家提供的指令数量有限，而合成的标注往往缺乏质量，这使得它们不足以进行大规模研究。为了解决这个问题，我们提出了NavComposer，一个用于自动生成高质量导航指令的新颖框架。NavComposer显式地分解动作、场景和对象等语义实体，并将它们重新组合成自然语言指令。其模块化架构允许灵活集成最先进的技术，而语义实体的显式使用则增强了指令的丰富性和准确性。此外，它以数据无关的方式运行，支持适应不同的导航轨迹而无需特定领域的训练。作为NavComposer的补充，我们引入了NavInstrCritic，一个全面的无标注评估系统，它从三个维度评估导航指令：对比匹配、语义一致性和语言多样性。NavInstrCritic提供了对指令质量的整体评估，解决了传统指标严重依赖专家标注的局限性。通过将指令生成和评估与特定的导航代理解耦，我们的方法能够实现更具可扩展性和通用性的研究。大量的实验为我们方法的有效性提供了直接和实际的证据。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [765] [Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning](https://arxiv.org/abs/2507.10571)
> *编排器-代理信任：一种具有信任感知编排和基于RAG推理的模块化代理式AI视觉分类系统*

*Konstantinos I. Roumeliotis, Ranjan Sapkota, Manoj Karkee, Nikolaos D. Tselikas* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-09**

**Keywords:** 多代理AI, 视觉分类, 信任感知编排, RAG, 零样本学习

**Comment:** 

> **TL;DR:** 本文提出了一种模块化代理式AI视觉分类系统，通过信任感知编排和RAG推理，显著提高了零样本设置下的性能，特别是在纠正代理过分自信方面，并应用于苹果叶病诊断。

**AI_Comments:** 该论文创新性地解决了多代理AI系统中信任的关键挑战，尤其是在零样本设置下，这对于无法进行微调的实际应用具有高度相关性。其模块化设计、通过编排器进行显式信任校准以及利用RAG来验证预测和纠正过度自信是重要的贡献。感知与元推理的分离增强了可解释性和可扩展性。系统的开源进一步促进了透明度和未来的研究。

<details>
  <summary>Details</summary>

**Motivation:** 现代人工智能日益依赖多代理架构，融合视觉和语言理解，但一个紧迫的挑战是如何信任这些代理，尤其是在没有微调的零样本设置中。

**Method:** 本文引入了一种新颖的模块化代理式AI视觉分类框架，该框架集成了通用多模态代理、非视觉推理编排器和检索增强生成（RAG）模块。该系统应用于苹果叶病诊断，并基准测试了三种配置：(I) 基于置信度的零样本编排，(II) 经过微调的代理，(III) 通过CLIP图像检索和重新评估循环增强的信任校准编排。编排器使用置信度校准指标（ECE、OCR、CCC）来调节代理之间的信任。

**Result:** 在零样本设置下，使用信任感知编排和RAG，准确率提高了77.94%，总体达到85.63%。GPT-4o表现出更好的校准，而Qwen-2.5-VL则显示出过度自信。此外，图像RAG通过视觉相似案例来验证预测，并通过迭代重新评估纠正了代理的过度自信。

**Conclusion:** 所提出的系统将感知（视觉代理）与元推理（编排器）分离，从而实现了可扩展和可解释的多代理AI。该蓝图可扩展到诊断、生物学和其他信任关键领域。所有模型、提示、结果和系统组件（包括完整的软件源代码）均已开源，以支持可复现性、透明度和社区基准测试。

> **ai_Abstract:** 本文提出了一种名为“编排器-代理信任”的模块化AI视觉分类系统，旨在解决多代理架构中的信任问题，特别是在零样本场景下。该系统集成了多模态代理、推理编排器和RAG模块。在苹果叶病诊断任务上进行基准测试，该系统利用信任感知编排和图像RAG显著提高了准确率（零样本下提升77.94%，总体达到85.63%），并通过与视觉相似案例的重新评估来纠正代理的过度自信。这种感知与元推理的分离旨在实现可扩展和可解释的多代理AI，并且所有组件都已开源。

> **摘要翻译:** 现代人工智能（AI）越来越依赖于融合视觉和语言理解的多代理架构。然而，一个紧迫的挑战依然存在：我们如何信任这些代理，特别是在没有微调的零样本设置中？我们引入了一种新颖的模块化代理式AI视觉分类框架，该框架集成了通用多模态代理、非视觉推理编排器和检索增强生成（RAG）模块。该系统应用于苹果叶病诊断，我们基准测试了三种配置：(I) 基于置信度的零样本编排，(II) 经过微调的代理，以及 (III) 通过CLIP图像检索和重新评估循环增强的信任校准编排。编排器使用置信度校准指标（ECE、OCR、CCC）来调节代理之间的信任。我们的结果表明，在零样本设置下，使用信任感知编排和RAG，准确率提高了77.94%，总体达到85.63%。GPT-4o表现出更好的校准，而Qwen-2.5-VL则显示出过度自信。此外，图像RAG通过视觉相似案例来验证预测，并通过迭代重新评估纠正了代理的过度自信。所提出的系统将感知（视觉代理）与元推理（编排器）分离，从而实现了可扩展和可解释的多代理AI。该蓝图可扩展到诊断、生物学和其他信任关键领域。所有模型、提示、结果和系统组件（包括完整的软件源代码）均已开源，以支持可复现性、透明度和社区基准测试，GitHub地址：https://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [784] [VerifyBench: A Systematic Benchmark for Evaluating Reasoning Verifiers Across Domains](https://arxiv.org/abs/2507.09884)
> *VerifyBench: 跨领域推理验证器系统评估基准*

*Xuzhao Li, Xuchen Li, Shiyu Hu, Yongzhen Guo, Wentao Zhang* | **Category: cs.AI** | **Updated: 2025-07-15**

**Keywords:** 推理验证器, 系统评估, 跨领域基准, 大型语言模型, 强化学习

**Comment:** Preprint, Under review

> **TL;DR:** 提出了VerifyBench，一个用于系统评估不同类型推理验证器在多个领域性能的基准，揭示了当前验证器技术的权衡和局限性。

**AI_Comments:** 这篇论文通过构建一个大规模、多领域的基准VerifyBench，系统性地评估了不同类型推理验证器的性能，填补了现有研究的空白。其创新之处在于提供了严谨的评估框架和深入的性能分析，揭示了专用验证器和通用LLM在准确性、召回率、包容性和精度之间的权衡，以及验证器对输入结构和跨领域泛化的敏感性与局限性。这些发现对于未来可验证奖励强化学习（RLVR）的发展和LLM推理能力的提升具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）越来越依赖强化学习（RL）通过反馈增强推理能力，但验证模型生成响应与参考答案的一致性是一个关键挑战。现有验证器（规则基和模型基）存在局限性，且缺乏对不同类型验证器在跨领域性能的系统评估，这严重限制了可验证奖励强化学习（RLVR）的可靠发展。

**Method:** 提出了VerifyBench，一个跨领域综合基准，用于系统评估验证器。构建了4000个涵盖数学、物理、化学和生物学领域的专家级问题，配备参考答案和多样化响应。通过多学科专家团队的严格标注确保评估可靠性。设计了四维实验框架，在提取答案 vs. 完整响应、短输出 vs. 长输出的组合条件下，全面比较专用验证器和通用LLM的性能边界。

**Result:** 评估揭示了验证器的基本权衡：专用验证器准确性领先但召回率不足；通用模型包容性强但精度不稳定。更重要的是，发现验证器对输入结构高度敏感，并且在跨领域泛化方面存在固有局限性。

**Conclusion:** VerifyBench揭示了当前验证器技术的瓶颈，为可验证奖励强化学习（RLVR）的可靠发展提供了关键见解。

> **ai_Abstract:** 本文提出了VerifyBench，一个用于系统评估推理验证器在数学、物理、化学和生物等多个领域性能的综合基准。通过构建4000个专家级问题并设计四维实验框架，作者评估了专用验证器和通用LLM的性能。研究发现专用验证器准确性高但召回率低，通用模型包容性强但精度不稳定，且验证器对输入结构敏感并存在跨领域泛化局限性，揭示了当前验证器技术的瓶颈。

> **摘要翻译:** 大型语言模型（LLMs）越来越依赖强化学习（RL）通过反馈来增强其推理能力。一个关键挑战是验证模型生成响应与参考答案的一致性，因为这些响应通常冗长、多样且细致入微。基于规则的验证器难以处理复杂性，这促使了基于模型的验证器的使用。然而，专用验证器缺乏灵活性，而通用LLM判断可能不一致。现有研究主要集中于构建更好的验证器，但仍缺乏对不同类型验证器在跨领域性能的系统评估，这严重限制了可验证奖励强化学习（RLVR）的可靠发展。为了解决这个问题，我们提出了VerifyBench——一个用于系统评估验证器的跨领域综合基准。我们构建了4000个涵盖数学、物理、化学和生物学领域的专家级问题。每个问题都配备了参考答案和多样化的响应。通过多学科专家团队进行的严格标注过程确保了评估的可靠性。我们设计了一个四维实验框架，以全面比较在提取答案与完整响应、以及短输出与长输出的组合条件下，专用验证器和通用LLM的性能边界。我们的评估揭示了验证器的基本权衡：专用验证器在准确性方面领先，但在召回率方面表现不足；通用模型显示出更强的包容性，但精度不稳定。更重要的是，我们发现验证器对输入结构高度敏感，并且在跨领域泛化方面存在固有局限性，这为当前验证器技术的瓶颈提供了关键见解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [793] [Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning](https://arxiv.org/abs/2507.10624)
> *理解而非能力：大型语言模型在符号计算和推理中的架构限制*

*Zheng Zhang* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 大型语言模型, 符号推理, 计算限制, 裂脑综合征, 架构分析

**Comment:** Substantial change to previous version (experiments, theorem,
  analysis and related work); currently under review at TMLR

> **TL;DR:** 大型语言模型（LLMs）在符号推理、算术和逻辑一致性任务上表现不佳，这种失败源于计算执行而非知识获取，作者称之为计算“裂脑综合征”，指出LLMs缺乏原则性、组合性推理的架构支持。

**AI_Comments:** 本文深入剖析了当前大型语言模型在高级认知任务（如符号推理和精确计算）中表现不佳的根本原因，提出了“理解而非能力”和“计算裂脑综合征”等创新概念，精准地指出了LLMs的架构限制。其重要性在于，它不仅解释了LLMs的局限性，还为未来LLM的设计和发展提供了明确的方向，强调了超越单纯模式匹配、构建具备真正推理能力的模型的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在需要符号推理、算术准确性和逻辑一致性的任务中系统性地失败，尽管它们表面上表现出流畅性。本文旨在对这种失败进行结构性诊断，揭示“理解”和“能力”之间持续存在的差距。

**Method:** 通过受控实验和架构分析，研究者展示了LLMs在没有可靠应用的情况下阐述正确原则的现象。

**Result:** LLMs经常能阐述正确的原则，但不能可靠地应用它们，这种失败根源于计算执行而非知识获取。这种现象被称为计算“裂脑综合征”，即指令和行动路径在几何和功能上是分离的。这种核心限制在数学运算到关系推理等各个领域中反复出现，解释了模型行为即使在理想提示下仍然脆弱的原因。LLMs作为强大的模式完成引擎，但缺乏原则性、组合性推理的架构支架。

**Conclusion:** 大型语言模型的功能是强大的模式完成引擎，但缺乏原则性、组合性推理的架构支持。当前LLM能力的边界被划定，这激励了未来具有元认知控制、原则提升和结构化执行的模型。这一诊断还澄清了为什么机械可解释性发现可能反映训练特有的模式协调而非普遍计算原则，以及指令和执行路径之间的几何分离如何暗示了神经内省和机械分析的局限性。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在符号计算和推理任务中表现出的系统性失败，指出这种失败并非源于知识缺失，而是由于计算执行能力的不足。研究者通过受控实验和架构分析，揭示了LLMs存在“理解”与“能力”之间的持续差距，并将其命名为计算“裂脑综合征”，即指令与行动路径在结构和功能上是分离的。这表明LLMs虽擅长模式识别与完成，但缺乏进行原则性、组合性推理所需的底层架构支持。研究结果明确了当前LLM能力的边界，并为未来模型在元认知控制、原则提炼和结构化执行方面指明了方向。

> **摘要翻译:** 大型语言模型（LLMs）表现出惊人的表面流畅性，但在需要符号推理、算术准确性和逻辑一致性的任务中系统性地失败。本文对这种失败提供了结构性诊断，揭示了“理解”和“能力”之间持续存在的差距。通过受控实验和架构分析，我们证明了LLMs通常能够阐述正确的原则，但无法可靠地应用它们——这种失败并非源于知识获取，而是源于计算执行。我们将这种现象称为计算“裂脑综合征”，即指令和行动路径在几何和功能上是分离的。这种核心限制在从数学运算到关系推理等各个领域中反复出现，并解释了为什么模型行为即使在理想提示下仍然脆弱。我们认为LLMs作为强大的模式完成引擎，但缺乏原则性、组合性推理的架构支架。我们的发现划定了当前LLM能力的边界，并激励了未来具有元认知控制、原则提升和结构化执行的模型。这一诊断还澄清了为什么机械可解释性发现可能反映训练特有的模式协调而非普遍计算原则，以及为什么指令和执行路径之间的几何分离暗示了神经内省和机械分析的局限性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [802] [Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces](https://arxiv.org/abs/2507.11352)
> *物流基础模型：迈向可认证、会话式规划接口*

*Yunhao Yang, Neel P. Bhatt, Christian Ellis, Alvaro Velasquez, Zhangyang Wang, Ufuk Topcu* | **Category: cs.AI, cs.FL** | **Updated: 2025-07-15**

**Keywords:** 物流, 基础模型, 神经符号系统, 可认证AI, 对话式规划

**Comment:** 

> **TL;DR:** 本文提出一个神经符号框架，结合自然语言对话与可验证的规划解释保证，有效解决了物流领域中大型语言模型（LLMs）的误解和幻觉问题，并在少量数据微调下超越了GPT-4.1的性能并显著降低了推理延迟。

**AI_Comments:** 这篇论文通过结合神经（LLM的自然语言处理能力）和符号（结构化规划和验证）方法，有效地解决了大型语言模型在关键应用领域（如物流）中“幻觉”和可信度的问题。其创新点在于引入了不确定性量化和交互式澄清循环，这对于确保AI决策的可靠性至关重要。仅用100个样本就超越了GPT-4.1的性能，并大幅降低了延迟，这表明该方法在实际部署中具有很高的效率和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 物流操作员面临生命攸关的决策，需要快速且持续的重新规划。现有整数规划方法速度慢且无法处理不确定性；而大型语言模型（LLMs）虽能处理不确定性并加速规划，但容易出现误解和幻觉，危及安全和成本。

**Method:** 本文引入了一个神经符号框架，将自然语言对话的可访问性与目标解释的可验证保证相结合。该框架能将用户请求转换为结构化规划规范，量化自身在字段和标记层面的不确定性，并在置信度低于自适应阈值时启动交互式澄清循环。

**Result:** 一个仅用100个不确定性过滤示例进行微调的轻量级模型，超越了GPT-4.1的零样本性能，并将推理延迟降低了近50%。

**Conclusion:** 这些初步结果为复杂物流中可认证、实时且用户对齐的决策制定指明了一条实用路径。

> **ai_Abstract:** 本文针对物流领域中传统规划方法速度慢、不确定性处理不足以及大型语言模型易产生幻觉的问题，提出了一种神经符号框架。该框架结合了自然语言对话的便捷性与目标解释的可验证性，通过将用户请求转化为结构化规划规范，并量化不确定性以触发交互式澄清循环。实验结果表明，一个仅用少量数据微调的轻量级模型在性能上优于GPT-4.1，并显著降低了推理延迟，为复杂物流领域实现可认证、实时且用户对齐的决策制定提供了实用路径。

> **摘要翻译:** 物流操作员，从风暴前重新安排空运的战场协调员到应对迟到卡车的仓库经理，经常面临要求领域专业知识和快速持续重新规划的生命攸关的决策。虽然整数规划等流行方法能生成满足用户定义逻辑约束的物流计划，但它们速度慢且假设环境的理想化数学模型，未考虑不确定性。另一方面，大型语言模型（LLMs）可以处理不确定性，并有望通过将自由形式的语句转换为可执行计划来加速重新规划，同时降低准入门槛，但它们仍然容易出现误解和幻觉，从而危及安全和成本。我们引入了一个神经符号框架，它将自然语言对话的可访问性与目标解释的可验证保证相结合。它将用户请求转换为结构化规划规范，量化自身在字段和标记层面的不确定性，并在置信度低于自适应阈值时调用交互式澄清循环。一个轻量级模型，仅用100个不确定性过滤示例进行微调，就超越了GPT-4.1的零样本性能，同时将推理延迟降低了近50%。这些初步结果为复杂物流中可认证、实时且用户对齐的决策制定指明了一条实用路径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [2] [ZClassifier: Temperature Tuning and Manifold Approximation via KL Divergence on Logit Space](https://arxiv.org/abs/2507.10638)
> *ZClassifier：通过Logit空间上的KL散度进行温度调整和流形近似*

*Shim Soon Yong* | **Category: cs.LG, I.2.6; I.5.1** | **Updated: 2025-07-14**

**Keywords:** ZClassifier, 温度缩放, 流形近似, KL散度, 不确定性校准

**Comment:** 

> **TL;DR:** ZClassifier引入了一种新的分类框架，使用对角高斯分布的logits，并通过最小化KL散度同时实现温度缩放和流形近似，提高了分类器的鲁棒性、校准性和潜在分离性。

**AI_Comments:** ZClassifier的创新之处在于其用概率性的高斯分布logits取代传统的确定性logits，并通过KL散度统一处理温度缩放和流形近似，这为不确定性校准和潜在空间控制提供了一个新颖且原则性的方法。其在鲁棒性、校准性和生成能力上的提升显示了该方法的潜力，为分类和生成任务带来了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过引入一种新颖的分类框架来解决传统确定性logits的局限性，并统一处理不确定性校准和潜在控制问题。

**Method:** ZClassifier框架用对角高斯分布的logits取代了传统的确定性logits。它通过最小化预测高斯分布与单位各向同性高斯分布之间的Kullback-Leibler (KL) 散度，同时解决温度缩放和流形近似问题。

**Result:** 在CIFAR-10和CIFAR-100数据集上的实验表明，ZClassifier在鲁棒性、校准性和潜在分离方面优于softmax分类器。此外，通过将logits解释为高斯语义势能，它还被证明对分类器引导生成有效。

**Conclusion:** ZClassifier提供了一种原则性的概率方法来统一不确定性校准和潜在控制，并显著提升了分类器的鲁棒性、校准性和潜在分离性，同时支持分类器引导生成。

> **ai_Abstract:** ZClassifier是一个新颖的分类框架，它用对角高斯分布的logits取代了传统的确定性logits。该方法通过最小化预测高斯分布与单位各向同性高斯分布之间的KL散度，统一处理了温度缩放和流形近似问题，从而以概率方式实现了不确定性校准和潜在控制。实验证明，ZClassifier在鲁棒性、校准性和潜在分离方面优于传统softmax分类器，并可有效应用于分类器引导生成。

> **摘要翻译:** 我们引入了一种新颖的分类框架ZClassifier，它用对角高斯分布的logits取代了传统的确定性logits。我们的方法通过最小化预测高斯分布与单位各向同性高斯分布之间的Kullback-Leibler (KL) 散度，同时解决了温度缩放和流形近似问题。这以一种原则性的概率方式统一了不确定性校准和潜在控制，从而能够自然地解释类别置信度和几何一致性。在CIFAR-10和CIFAR-100上的实验表明，ZClassifier在鲁棒性、校准性和潜在分离方面优于softmax分类器。我们还通过将logits解释为高斯语义势能，展示了其在分类器引导生成中的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [12] [EXPO: Stable Reinforcement Learning with Expressive Policies](https://arxiv.org/abs/2507.07986)
> *EXPO：基于表达性策略的稳定强化学习*

*Perry Dong, Qiyang Li, Dorsa Sadigh, Chelsea Finn* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 强化学习, 表达性策略, 样本效率, 在线RL, 价值最大化

**Comment:** corrected typo, formatting, added experiments

> **TL;DR:** 提出EXPO算法，通过组合一个表达性基础策略和一个轻量级编辑策略，实现对复杂表达性策略的稳定在线强化学习，显著提高样本效率。

**AI_Comments:** EXPO的创新点在于其双策略结构和即时价值最大化方法，有效解决了复杂表达性策略在在线RL中的稳定性挑战。通过将基础策略与轻量级编辑策略分离，并避免直接对复杂策略进行价值优化，它提供了一种更稳健和样本高效的训练范式。这对于推动高级生成模型在强化学习中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在在线强化学习中训练和微调表达性策略（如扩散和流匹配策略）面临稳定的价值最大化挑战。由于这些策略的去噪链较长，从动作到策略参数的梯度传播不稳定。

**Method:** EXPO通过避免对表达性策略直接进行价值优化，而是构建一个即时RL策略来最大化Q值。它结合了两个参数化策略：一个通过稳定模仿学习训练的表达性基础策略，以及一个轻量级高斯编辑策略，用于将基础策略采样的动作向更高价值分布进行编辑。即时策略通过学习到的编辑策略优化来自基础策略的动作，并从基础和编辑动作中选择价值最大化的动作进行采样和时序差分（TD）备份。

**Result:** 该方法在样本效率上比现有方法平均提高了2-3倍，适用于给定离线数据微调预训练策略以及利用离线数据进行在线训练的场景。

**Conclusion:** EXPO算法通过创新的双策略结构解决了表达性策略在线强化学习中的稳定价值最大化问题，显著提升了样本效率，为复杂策略的RL训练提供了有效方案。

> **ai_Abstract:** 本论文提出了EXPO（Expressive Policy Optimization）算法，旨在解决在线强化学习中训练和微调复杂表达性策略（如扩散和流匹配策略）时遇到的稳定价值最大化问题。传统方法因策略的去噪链过长导致梯度传播不稳定。EXPO的核心思想是避免直接优化表达性策略的价值，而是通过一个即时策略来最大化Q值。该算法包含一个通过模仿学习训练的表达性基础策略和一个轻量级高斯编辑策略，后者用于调整基础策略的动作以获得更高价值。实验结果表明，EXPO在样本效率上比现有方法平均提升了2-3倍，适用于离线数据微调和在线训练。

> **摘要翻译:** 我们研究了在给定离线数据集的情况下，通过在线强化学习（RL）训练和微调表达性策略的问题。使用在线RL训练表达性策略类别带来了稳定的价值最大化的独特挑战。与在线RL中常用的简单高斯策略不同，扩散和流匹配等表达性策略通过一个长去噪链进行参数化，这在针对某些价值函数进行优化时，阻碍了从动作到策略参数的稳定梯度传播。我们的关键见解是，我们可以通过避免对表达性策略直接进行价值优化，而是构建一个即时RL策略来最大化Q值，从而解决稳定的价值最大化问题。我们提出了表达性策略优化（EXPO），这是一种样本高效的在线RL算法，它利用一个即时策略来最大化价值，并使用两个参数化策略——一个通过稳定模仿学习目标训练的更大的表达性基础策略，以及一个轻量级高斯编辑策略，该策略将从基础策略采样的动作向更高价值分布进行编辑。即时策略通过学习到的编辑策略优化来自基础策略的动作，并从基础和编辑动作中选择价值最大化的动作进行采样和时序差分（TD）备份。我们的方法在给定离线数据微调预训练策略和利用离线数据进行在线训练的设置中，样本效率平均比现有方法提高了2-3倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [13] [A Feed-Forward Artificial Intelligence Pipeline for Sustainable Desalination under Climate Uncertainties: UAE Insights](https://arxiv.org/abs/2507.10609)
> *可持续海水淡化在气候不确定性下的前馈人工智能管道：阿联酋洞察*

*Obumneme Nwafor, Chioma Nwafor, Amro Zakaria, Nkechi Nwankwo* | **Category: cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-13**

**Keywords:** 海水淡化, 人工智能, 气候不确定性, 气溶胶光学厚度, 可持续性, 预测建模, 阿联酋

**Comment:** 

> **TL;DR:** 针对阿联酋海水淡化面临的气候不确定性问题，本研究提出一个两阶段AI预测模型，预测气溶胶光学厚度（AOD）和淡化效率损失，并基于此开发了规则控制逻辑和交互式仪表板，以实现可持续和气候适应性规划。

**AI_Comments:** 这项研究通过结合先进的AI预测模型和实用的规则控制逻辑，为解决海水淡化在气候变化下的可持续性问题提供了创新方案。其亮点在于两阶段预测架构的提出，特别是对AOD的预测及其对系统效率影响的量化，以及将技术成果封装为交互式决策支持系统，极大地提升了研究的实用性和应用潜力。98%的准确率也显示了模型的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 阿联酋90%的饮用水依赖海水淡化，但该过程能耗高（占全国用电15%，碳排放22%），且受气候不确定性（如海水温度、盐度、AOD）影响，尤其是AOD会严重影响太阳能淡化系统的性能。因此，需要一个解决方案来提高可持续性并应对气候挑战。

**Method:** 本研究提出了一个新颖的两阶段预测建模架构：
1.  第一阶段：利用卫星时间序列和气象数据预测气溶胶光学厚度（AOD）。
2.  第二阶段：利用预测的AOD和其他气象因素预测海水淡化性能效率损失。
研究还使用SHAP揭示了系统性能下降的关键驱动因素。
此外，基于预测的AOD和太阳能效率，提出了一种针对海水淡化系统的除尘规则控制逻辑，用于调整进水压力、适应维护计划和调节能源切换。
最后，将预测模型和基于规则的控制逻辑打包成一个交互式仪表板，以支持情景和预测分析，作为气候适应性规划的管理决策支持系统。

**Result:** 预测框架达到了98%的准确率。
SHAP分析揭示了系统性能下降的关键驱动因素。
提出的除尘控制逻辑可用于调整淡化厂进水压力、适应维护计划和调节能源切换。
开发的交互式仪表板为气候适应性规划提供了管理决策支持系统。

**Conclusion:** 本研究通过开发一个前馈人工智能管道，包括两阶段预测模型、基于规则的控制逻辑和交互式仪表板，为阿联酋在气候不确定性下实现可持续海水淡化提供了有效的管理决策支持系统，有助于气候适应性规划。

> **ai_Abstract:** 本研究针对阿联酋海水淡化在气候不确定性下（特别是气溶胶光学厚度影响）面临的能耗高和可持续性挑战，提出了一种前馈人工智能管道。该管道包含一个两阶段预测模型，用于预测AOD和淡化效率损失（准确率达98%），并结合SHAP分析揭示关键驱动因素。在此基础上，开发了基于AOD和太阳能效率预测值的除尘规则控制逻辑，以优化淡化厂运行。最终，将模型和控制逻辑集成至交互式仪表板，为可持续海水淡化和气候适应性规划提供决策支持。

> **摘要翻译:** 阿联酋（UAE）严重依赖海水淡化来满足其90%以上的饮用水需求。海水淡化过程是高度能源密集的，约占阿联酋电力消耗的15%，并导致该国超过22%的能源相关二氧化碳排放。此外，面对气候不确定性，如海水温度上升、盐度变化和气溶胶光学厚度（AOD）增加，这些过程面临着重大的可持续性挑战。AOD通过光伏污染、膜污染和水浊度循环，极大地影响太阳能海水淡化系统的运行和经济性能。
本研究提出了一种新颖的管道式两阶段预测建模架构：第一阶段利用卫星衍生的时间序列和气象数据预测AOD；第二阶段利用预测的AOD和其他气象因素预测海水淡化性能效率损失。该框架实现了98%的准确率，并使用SHAP（SHapley Additive exPlanations）揭示了系统退化的关键驱动因素。此外，本研究基于AOD和太阳能效率的预测值，提出了一种针对海水淡化系统的除尘规则控制逻辑。该控制逻辑用于调整海水淡化厂的进水压力、调整维护计划和调节能源切换。
为了提高研究成果的实用性，预测模型和基于规则的控制逻辑被封装成一个交互式仪表板，用于情景和预测分析。这为气候适应性规划提供了管理决策支持系统。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [18] [PhysiX: A Foundation Model for Physics Simulations](https://arxiv.org/abs/2506.17774)
> *PhysiX: 物理模拟的基础模型*

*Tung Nguyen, Arsh Koneru, Shufan Li, Aditya Grover* | **Category: cs.LG** | **Updated: 2025-07-14**

**Keywords:** 物理模拟, 基础模型, 数据稀缺, 自回归模型, 离散化

**Comment:** 21 pages, 10 figures

> **TL;DR:** PhysiX是首个大规模物理模拟基础模型，通过离散化和自回归生成解决了数据稀缺和尺度变化问题，表现优于现有方法。

**AI_Comments:** PhysiX的创新之处在于它是第一个将基础模型范式引入物理模拟领域的工作，有效解决了该领域长期存在的数据稀缺和多尺度数据处理难题。其通过离散化和自回归建模，并结合精炼模块，为物理模拟带来了新的范式，展现了大型模型在复杂科学计算中的巨大潜力。该研究还揭示了从其他模态（如自然视频）进行知识迁移的可能性，为未来的跨领域研究提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的物理模拟方法受限于数据稀缺和数据集尺度差异大，导致难以使用大型模型并限制了模型的长期预测能力和上下文理解。基础模型在其他领域取得成功，但在物理模拟领域尚未实现。

**Method:** 本文提出了PhysiX，一个4.5B参数的自回归生成模型。它使用离散分词器将不同尺度的物理过程编码成离散词元序列，并通过自回归下一词元预测目标进行建模。为减轻离散化中的舍入误差，PhysiX集成了专门的细化模块。

**Result:** PhysiX有效解决了数据瓶颈，在可比设置下超越了任务专用基线，并在The Well基准测试中超越了先前的绝对最先进方法。结果表明，从自然视频中学习到的知识可以成功迁移到物理模拟中，并且跨不同模拟任务的联合训练能够实现协同学习。

**Conclusion:** PhysiX证明了大型基础模型在物理模拟领域的潜力，能够克服传统的数据和尺度挑战，并实现卓越的性能。

> **ai_Abstract:** 本文提出了PhysiX，首个大规模（4.5B参数）物理模拟基础模型，旨在解决该领域数据稀缺和尺度多样性的挑战。PhysiX采用离散分词器将物理过程编码为序列，并通过自回归预测进行建模，并引入细化模块以减少离散化误差。实验证明，PhysiX有效克服了数据瓶颈，在性能上超越了现有基线和最先进方法，并展示了知识迁移和协同学习的潜力。

> **摘要翻译:** 基础模型在视频、图像和语言领域取得了显著成功。通过扩大参数数量和训练数据集，这些模型获得了可泛化的世界知识，并且通常超越了特定任务的方法。然而，这种进展尚未扩展到物理模拟领域。一个主要的瓶颈是数据稀缺：虽然互联网上随时可用的图像、视频和文本资源有数百万，但最大的物理模拟数据集仅包含数万个样本。这种数据限制阻碍了大型模型的使用，因为过拟合成为一个主要问题。因此，物理应用通常依赖于小型模型，这些模型由于上下文理解有限而难以进行长期预测。此外，与通常表现出固定粒度的图像、视频或文本不同，物理数据集的尺度往往差异巨大，这加剧了扩大多任务训练的挑战。我们引入了PhysiX，这是第一个用于物理模拟的大规模基础模型。PhysiX是一个4.5B参数的自回归生成模型。它使用离散分词器将不同尺度的物理过程编码成离散词元序列，并采用自回归下一词元预测目标在词元空间中对这些过程进行建模。为了减轻离散化过程中的舍入误差，PhysiX包含了一个专门的细化模块。通过广泛的实验，我们表明PhysiX有效解决了数据瓶颈，在可比设置下优于任务专用基线，并在The Well基准测试中超越了先前的绝对最先进方法。我们的结果表明，从自然视频中学习到的知识可以成功迁移到物理模拟中，并且跨不同模拟任务的联合训练能够实现协同学习。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [27] [Class-Proportional Coreset Selection for Difficulty-Separable Data](https://arxiv.org/abs/2507.10904)
> *针对难度可分离数据的类别比例核集选择*

*Elisa Tsai, Haizhong Zheng, Atul Prakash* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 核集选择, 数据剪枝, 类别不平衡, 数据难度, 机器学习效率

**Comment:** This paper has been accepted to the ICCV 2025 Workshop on Curated
  Data for Efficient Learning (CDEL)

> **TL;DR:** 现有的核集选择方法忽略了类别间数据难度的差异，导致性能下降。本文提出类别比例的核集选择方法，在多种数据集上表现出最先进的数据效率，尤其在高剪枝率下显著优于类别无关的方法，提升了模型在噪声和不平衡数据上的泛化能力。

**AI_Comments:** 本文的创新之处在于识别并形式化了“类别难度可分离性”这一重要现象，并提出了针对性的解决方案——类别比例的核集选择方法。引入CDSC作为定量度量，为评估数据集中类别难度差异提供了工具。这对于处理真实世界中普遍存在的数据不平衡和类别难度差异问题具有重要意义，尤其是在安全和医疗等高风险领域。其成果表明，考虑类别特异性数据难度能显著提升数据剪枝的有效性和模型泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 高质量的训练数据对于构建可靠高效的机器学习系统至关重要。单次核集选择通过修剪数据集来保持或提高模型性能，通常依赖于基于训练动态的数据难度分数。然而，大多数现有方法隐式假设数据难度在类别上是同质的，忽略了不同类别间数据难度的变化，这可能导致对容易的多数类别过度代表，而忽视稀有但信息丰富的类别，从而导致性能下降。

**Method:** 本文通过证明在网络入侵检测和医学图像等领域，数据难度通常按类别聚类，从而挑战了现有方法的假设。将此形式化为类别难度可分离性，并引入类别难度可分离性系数 (CDSC) 作为定量度量。为解决类别无关核集方法中容易多数类别被过度代表的问题，本文引入了多种采样策略的类别比例变体。

**Result:** 高CDSC值与类别无关核集方法的性能下降相关。在安全和医学领域的五个不同数据集上进行评估，本文提出的方法始终实现了最先进的数据效率。例如，在CTU-13数据集上，在99%的极端剪枝率下，类别比例的以覆盖为中心的核集选择 (CCS-CP) 表现出显著的稳定性，准确率仅下降2.58%，精确率下降0.49%，召回率下降0.19%。相比之下，类别无关的CCS基线（次优方法）的准确率下降7.59%，精确率下降4.57%，召回率下降4.11%。此外，积极的剪枝增强了在噪声、不平衡和大规模数据集上的泛化能力。

**Conclusion:** 明确地对类别难度可分离性进行建模可以带来更有效、更鲁棒和更具泛化能力的数据剪枝，尤其是在高风险场景中。

> **ai_Abstract:** 本论文解决了现有单次核集选择方法中一个关键限制，即它们假设数据难度在类别之间是均匀的。作者证明了在特定领域（如网络入侵检测和医学图像）中，数据难度通常按类别聚类，并引入了类别难度可分离性系数 (CDSC) 来量化这种现象。为了解决类别无关方法过度代表容易多数类别的问题，论文提出了多种采样策略的类别比例变体。在五个多样化数据集上的评估显示，这些方法在数据效率方面达到了最先进的水平，尤其是在高剪枝率下，显著优于类别无关的基线方法，并能增强模型在噪声、不平衡和大规模数据集上的泛化能力。研究强调，显式建模类别难度可分离性对于实现更有效、更鲁棒和更具泛化能力的数据剪枝至关重要。

> **摘要翻译:** 高质量的训练数据对于构建可靠高效的机器学习系统至关重要。单次核集选择通过修剪数据集来解决这个问题，同时保持甚至提高模型性能，通常依赖于基于训练动态的数据难度分数。然而，大多数现有方法隐式假设数据难度在类别上是同质的，忽略了不同类别间数据难度的变化。
在这项工作中，我们通过证明在网络入侵检测和医学图像等领域，数据难度通常按类别聚类来挑战这一假设。我们将其形式化为类别难度可分离性，并引入类别难度可分离性系数 (CDSC) 作为定量度量。我们证明了高CDSC值与类别无关核集方法的性能下降相关，这些方法倾向于过度代表容易的多数类别，而忽视稀有但信息丰富的类别。
为了解决这个问题，我们引入了多种采样策略的类别比例变体。在涵盖安全和医疗领域的五个不同数据集上进行评估，我们的方法始终实现了最先进的数据效率。例如，在CTU-13数据集上，在99%的极端剪枝率下，类别比例的以覆盖为中心的核集选择 (CCS-CP) 表现出显著的稳定性，准确率仅下降2.58%，精确率下降0.49%，召回率下降0.19%。相比之下，类别无关的CCS基线（次优方法）的准确率下降7.59%，精确率下降4.57%，召回率下降4.11%。
我们进一步表明，积极的剪枝增强了在噪声、不平衡和大规模数据集上的泛化能力。我们的结果强调，明确地对类别难度可分离性进行建模可以带来更有效、更鲁棒和更具泛化能力的数据剪枝，尤其是在高风险场景中。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [30] [Tree-Structured Parzen Estimator Can Solve Black-Box Combinatorial Optimization More Efficiently](https://arxiv.org/abs/2507.08053)
> *树结构Parzen估计器可以更有效地解决黑盒组合优化问题*

*Kenshin Abe, Yunzhuo Wang, Shuhei Watanabe* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 树结构Parzen估计器, 黑盒组合优化, 超参数优化, 组合优化算法, 分类核

**Comment:** Submitted to AutoML Conference

> **TL;DR:** 本文提出了一种新的算法，通过泛化分类核并引入距离结构，使树结构Parzen估计器（TPE）能更有效地解决黑盒组合优化问题，并在实验中验证了其优越性。

**AI_Comments:** 本文的创新点在于将TPE的应用范围扩展到了黑盒组合优化领域，并通过改进其核心算法（泛化分类核、引入距离结构、优化大搜索空间处理）显著提升了效率。这对于需要进行复杂组合优化的化学和生物等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 树结构Parzen估计器（TPE）是一种通用的超参数优化（HPO）方法，但其在黑盒组合优化领域的应用尚未被充分探索，而该领域在化学和生物等领域非常重要。

**Method:** 作者首先将TPE中的分类核与数值核进行泛化，从而为分类核引入了距离结构。接着，他们讨论了对新开发的核进行修改以处理大型组合搜索空间，这些修改降低了核计算的时间复杂度。

**Result:** 在合成问题的实验中，验证了所提出的方法比原始TPE能以更少的评估次数找到更好的解决方案。

**Conclusion:** 所提出的算法能够更有效地解决黑盒组合优化问题，并且已集成到开源HPO框架Optuna中。

> **ai_Abstract:** 本文提出了一种针对树结构Parzen估计器（TPE）的有效组合优化算法，旨在解决其在黑盒组合优化领域应用不足的问题。该方法通过泛化TPE中的分类核并引入距离结构，并对新核进行修改以高效处理大型组合搜索空间，从而降低了计算复杂度。实验结果表明，与原始TPE相比，该算法能以更少的评估次数找到更优的解决方案。该算法已集成到Optuna框架中。

> **摘要翻译:** 树结构Parzen估计器（TPE）是一种通用的超参数优化（HPO）方法，受到流行HPO工具的支持。由于这些HPO工具是根据深度学习（DL）的趋势开发的，因此DL领域中常用的问题设置（如多目标优化和多保真度优化）已针对TPE进行了讨论。然而，HPO的实际应用不仅限于DL，黑盒组合优化在某些领域（例如化学和生物学）中被积极利用。由于组合优化一直是TPE中一个未被触及但非常重要的话题，我们为TPE提出了一种高效的组合优化算法。在本文中，我们首先通过数值核泛化了TPE中的分类核，使我们能够为分类核引入距离结构。然后，我们讨论了对新开发的核进行修改以处理大型组合搜索空间。这些修改降低了核计算相对于组合搜索空间大小的时间复杂度。在合成问题的实验中，我们验证了我们提出的方法比原始TPE以更少的评估次数识别出更好的解决方案。我们的算法可在开源HPO框架Optuna中获得。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [33] [Outbound Modeling for Inventory Management](https://arxiv.org/abs/2507.10890)
> *出库建模用于库存管理*

*Riccardo Savorgnan, Udaya Ghai, Carson Eisenach, Dean Foster* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 库存管理, 出库建模, 概率预测, 强化学习, 运输成本

**Comment:** KDD - AI for Supply Chain Workshop

> **TL;DR:** 该研究旨在为库存管理中的出库量和运输成本提供可微分的概率预测模型，特别是在强化学习环境中，以解决现有系统非可微分、慢且成本高的问题。

**AI_Comments:** 该论文的创新点在于将库存出库建模视为一个可微分的概率预测问题，这对于将其集成到强化学习（RL）训练环境中至关重要。它解决了现有生产系统模拟器在RL应用中不可微分、效率低下的核心挑战。此外，提出处理离策略轨迹引起的分布外（OOD）场景的验证方案，增强了模型在实际RL部署中的鲁棒性。然而，目前的结果仅限于分布内设置，模型在OOD场景下的实际表现仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 准确建模库存仓库的出库量和相关运输成本对于区域库存规划至关重要，尤其是在使用强化学习（RL）开发控制策略时。现有的通过模拟内部软件系统来恢复转换的方法是非可微分的，并且在RL训练环境中运行速度慢且成本高。

**Method:** 该研究将问题框架化为概率预测问题，建模了每个时间段所有仓库的出库量和运输成本的联合分布，并以库存位置和外部客户需求为条件。为了确保在RL环境中的鲁棒性，模型需要处理由离策略轨迹引起的分布外（OOD）场景。作者提出了一种利用生产系统来评估出库模型在由RL策略引起的反事实库存状态上的验证方案。

**Result:** 初步结果表明，该模型在分布内（in-distribution）设置中具有准确性。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文研究了库存管理中出库量和运输成本的预测问题。鉴于现有模拟系统在强化学习（RL）环境中存在非可微分、速度慢和成本高等问题，作者提出了一种概率预测方法，用于建模出库量和运输成本的联合分布。该模型以库存位置和客户需求为条件，旨在支持RL控制策略的开发。为应对RL环境中的分布外（OOD）场景，研究引入了一种利用生产系统评估模型在反事实库存状态下性能的验证方案。初步结果显示模型在分布内设置中表现出准确性。

> **摘要翻译:** 我们研究了预测从每个库存仓库满足客户需求的出库单位数量（或“消耗量”）以及相关出库运输成本的问题。实际的出库和运输成本由管理客户订单履约（即从何处以及如何将单位交付给客户）的规划和执行的复杂生产系统决定。准确建模这些过程对于区域库存规划至关重要，尤其是在使用强化学习（RL）开发控制策略时。对于RL用例，出库模型被整合到模拟器中以生成长期的推演，我们希望这些推演是可微分的。虽然模拟对内部软件系统的调用可以用于恢复这种转换，但它们是不可微分的，并且在RL训练环境中运行速度太慢且成本高昂。因此，我们将此框定为一个概率预测问题，建模了每个时间段所有仓库的出库出库量和运输成本的联合分布，并以库存位置和外部客户需求为条件。为了确保在RL环境中的鲁棒性，模型必须处理由离策略轨迹引起的分布外场景。我们提出了一种验证方案，该方案利用生产系统来评估RL策略引起的反事实库存状态下的出库模型。初步结果表明该模型在分布内设置中具有准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [36] [TAB: Unified Benchmarking of Time Series Anomaly Detection Methods](https://arxiv.org/abs/2506.18046)
> *TAB：时间序列异常检测方法的统一基准测试*

*Xiangfei Qiu, Zhe Li, Wanghui Qiu, Shiyan Hu, Lekui Zhou, Xingjian Wu, Zhengyu Li, Chenjuan Guo, Aoying Zhou, Zhenli Sheng, Jilin Hu, Christian S. Jensen, Bin Yang* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 时间序列异常检测, 基准测试, 统一评估, 数据集, 性能比较

**Comment:** Accepted by PVLDB2025

> **TL;DR:** 本文提出了一个名为TAB的统一基准测试平台，用于时间序列异常检测（TSAD）方法的评估，解决了当前评估程序在数据集和实验设置方面的不足。

**AI_Comments:** 本文的创新之处在于提出了一个全面的、统一的时间序列异常检测基准平台TAB，解决了当前评估方法中数据集和实验设置的碎片化问题。其重要性在于为TSAD领域提供了一个标准化的评估框架，这将极大地促进新方法的开发和现有方法的比较，有助于推动该领域的有效进展。该工作的开源性质也值得称赞，有助于社区协作和结果复现。

<details>
  <summary>Details</summary>

**Motivation:** 时间序列异常检测（TSAD）在金融、交通和医疗等许多领域扮演着重要角色，随着更多时间序列数据的可用性，TSAD的需求不断增长。尽管存在许多TSAD方法，但仍需要新的、更好的方法。然而，有效的进展取决于评估新方法并将其与现有方法进行比较的可靠手段。本文旨在解决当前评估程序在数据集和实验设置与协议方面的不足。

**Method:** 本文提出了一个名为TAB的新型时间序列异常检测基准。TAB的特点包括：1）涵盖了29个公共多变量数据集和1,635个单变量时间序列，以促进对不同数据集的更全面评估。2）涵盖了多种TSAD方法，包括非学习、机器学习、深度学习、基于LLM和时间序列预训练方法。3）具有统一和自动化的评估流程，可以公平、轻松地评估TSAD方法。

**Result:** 作者使用TAB评估了现有的TSAD方法并报告了结果，从而对这些方法的性能提供了更深入的见解。

**Conclusion:** TAB提供了一个统一、全面的基准平台，解决了现有时间序列异常检测方法评估中的不足，有助于更公平、深入地理解不同TSAD方法的性能。

> **ai_Abstract:** 本文提出了一个名为TAB的统一时间序列异常检测（TSAD）基准平台，旨在解决现有TSAD方法评估中数据集和实验设置的不足。TAB整合了多样化的数据集（29个多变量和1,635个单变量时间序列），涵盖了多种TSAD方法类型（非学习、机器学习、深度学习、LLM-based和时间序列预训练），并提供了一个统一、自动化的评估流程。通过使用TAB，研究人员能够对现有TSAD方法进行公平且深入的性能评估，所有数据集和代码均已开源。

> **摘要翻译:** 时间序列异常检测（TSAD）在金融、交通和医疗等许多领域扮演着重要角色。随着现实世界的持续仪器化，更多时间序列数据将可用，这也导致对TSAD的需求不断增长。虽然许多TSAD方法已经存在，但仍然需要新的、更好的方法。然而，有效的进展取决于评估新方法并将其与现有方法进行比较的可靠手段。我们解决了当前评估程序在数据集和实验设置与协议方面的不足。具体来说，我们提出了一个名为TAB的新型时间序列异常检测基准。首先，TAB包含29个公共多变量数据集和1,635个来自不同领域的单变量时间序列，以促进对不同数据集的更全面评估。其次，TAB涵盖了多种TSAD方法，包括非学习、机器学习、深度学习、基于LLM和时间序列预训练方法。第三，TAB具有统一和自动化的评估流程，可以公平、轻松地评估TSAD方法。最后，我们使用TAB评估了现有的TSAD方法并报告了结果，从而对这些方法的性能提供了更深入的见解。此外，所有数据集和代码都可在https://github.com/decisionintelligence/TAB获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [40] [Neurosymbolic Reasoning Shortcuts under the Independence Assumption](https://arxiv.org/abs/2507.11357)
> *神经符号推理在独立性假设下的捷径*

*Emile van Krieken, Pasquale Minervini, Edoardo Ponti, Antonio Vergari* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-15**

**Keywords:** 神经符号推理, 独立性假设, 不确定性建模, 推理捷径, 形式化证明

**Comment:** Accepted at NeSy 2025

> **TL;DR:** 本文通过形式化证明，揭示了神经符号（NeSy）模型中普遍存在的独立性假设会导致其无法充分建模不确定性，从而产生“推理捷径”问题。

**AI_Comments:** 这项工作通过形式化证明，明确指出了神经符号系统中独立性假设的一个核心局限性，即它会导致模型无法充分建模不确定性并产生“推理捷径”。这对于理解NeSy模型的内在缺陷及其可靠性具有重要意义，并可能指导未来更鲁棒的NeSy系统设计。

<details>
  <summary>Details</summary>

**Motivation:** 神经符号（NeSy）社区对独立性假设在何种情况下实际限制NeSy系统存在疑问，本文旨在通过形式化证明来解决这一问题。

**Method:** 通过形式化证明，表明假设符号概念之间存在独立性，将导致模型无法表示某些特定概念组合上的不确定性。

**Result:** 结果是模型无法察觉推理捷径，即NeSy预测器因错误原因预测出正确下游任务的病态行为。

**Conclusion:** 独立性假设使得神经符号模型无法完全建模不确定性，从而导致其出现“推理捷径”问题，即模型能得出正确结果但基于错误的推理过程。

> **ai_Abstract:** 本文旨在解决神经符号（NeSy）社区中关于独立性假设何时限制NeSy系统的问题。研究通过形式化证明指出，符号概念间的独立性假设会导致NeSy模型无法表示某些概念组合的不确定性，进而使其无法识别“推理捷径”，即模型因错误原因得出正确预测的病态行为。这揭示了独立性假设对NeSy模型建模不确定性和推理能力的关键限制。

> **摘要翻译:** 神经符号（NeSy）预测器中符号概念之间普遍存在的独立性假设是一种方便的简化：NeSy预测器利用它来加速概率推理。最近的研究，如van Krieken等人（2024）和Marconato等人（2024）认为，独立性假设会阻碍NeSy预测器的学习，更重要的是，会阻止它们正确地建模不确定性。然而，NeSy社区对独立性假设实际限制NeSy系统的情景存在疑问（Faronius和Dos Martires，2025）。在这项工作中，我们通过形式化证明，表明假设符号概念之间存在独立性，意味着模型永远无法表示某些概念组合上的不确定性。因此，模型未能察觉推理捷径，即NeSy预测器因错误原因预测出正确下游任务的病态行为。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [42] [CLA: Latent Alignment for Online Continual Self-Supervised Learning](https://arxiv.org/abs/2507.10434)
> *CLA：在线持续自监督学习的潜在对齐*

*Giacomo Cignoni, Andrea Cossu, Alexandra Gomez-Villa, Joost van de Weijer, Antonio Carta* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 自监督学习, 持续学习, 潜在对齐, 在线学习, 遗忘缓解

**Comment:** Accepted at CoLLAs 2025 conference (oral)

> **TL;DR:** CLA是一种新型在线持续自监督学习策略，通过对齐当前模型与过去表示来缓解遗忘，能加速收敛并超越现有技术，甚至在预训练早期阶段表现更好。

**AI_Comments:** 该论文的创新点在于提出了CLA这一在线持续自监督学习策略，通过独特的“潜在对齐”机制有效解决了在线持续学习中遗忘问题。其重要性体现在不仅在在线场景下提高了效率和性能，更发现其在预训练早期阶段的潜力，为自监督学习的预训练范式提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自监督学习（SSL）技术在在线持续学习（Online CL）设置下很少，该设置要求数据以小批量到达，模型需遵守固定计算预算，且没有任务边界。

**Method:** 提出了持续潜在对齐（Continual Latent Alignment, CLA），这是一种新颖的在线持续学习SSL策略，通过将当前模型学习到的表示与过去的表示对齐来缓解遗忘。

**Result:** CLA能够加速在线场景下训练过程的收敛，在相同计算预算下优于现有最先进方法。此外，在预训练的早期阶段使用CLA作为预训练协议，与完全i.i.d.预训练相比，能带来更好的最终性能。

**Conclusion:** CLA是一种有效的在线持续自监督学习方法，通过潜在对齐机制有效缓解遗忘，不仅提高了在线学习的效率和性能，而且在预训练阶段也显示出优越性。

> **ai_Abstract:** 本文提出了一种名为持续潜在对齐（CLA）的新型自监督学习策略，专为在线持续学习（Online CL）环境设计。CLA通过对齐当前模型与过去模型的潜在表示来有效缓解遗忘。实验结果表明，CLA在在线学习场景下能够加速收敛，并在相同计算预算下超越现有最先进方法。此外，将CLA作为预训练早期阶段的协议，在最终性能上优于传统的i.i.d.预训练。

> **摘要翻译:** 自监督学习（SSL）能够构建对未见数据具有良好泛化能力的潜在表示。然而，针对在线持续学习（CL）设置的SSL技术很少，在这种设置下，数据以小批量到达，模型必须遵守固定的计算预算，并且没有任务边界。我们引入了持续潜在对齐（CLA），这是一种用于在线持续学习的新颖SSL策略，它将当前模型学习到的表示与过去的表示对齐，以减轻遗忘。我们发现，在相同计算预算下，我们的CLA能够加速在线场景下训练过程的收敛，优于现有最先进的方法。令人惊讶的是，我们还发现，与完全独立同分布（i.i.d.）预训练相比，在预训练的早期阶段使用CLA作为预训练协议可以带来更好的最终性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [47] [GRAPES: Learning to Sample Graphs for Scalable Graph Neural Networks](https://arxiv.org/abs/2310.03399)
> *GRAPES：学习采样图以实现可扩展图神经网络*

*Taraneh Younesian, Daniel Daza, Emile van Krieken, Thiviyan Thanapalasingam, Peter Bloem* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 图神经网络, 图采样, 可扩展性, 自适应方法, 异质图

**Comment:** 

> **TL;DR:** GRAPES 提出了一种自适应采样方法，通过训练第二个GNN来预测节点采样概率，从而有效地扩展图神经网络（GNNs）到大规模图，并在保持高准确性的同时显著降低内存成本。

**AI_Comments:** GRAPES 的创新之处在于其自适应学习采样策略，通过引入第二个 GNN 来优化采样过程，这比传统的静态启发式方法更具灵活性和泛化能力。其重要性在于有效解决了 GNN 在大规模图上的可扩展性瓶颈，尤其强调了在异质图上的优越表现，这对于实际应用具有重要意义。该方法通过优化下游任务目标来指导采样，使得采样过程与最终任务目标对齐，提高了效率和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNNs）随着深度增加，感受野呈指数增长，导致高内存成本。现有采样方法主要在同质图上评估，并依赖静态启发式方法，这可能无法很好地推广到不同图或任务。因此，需要一种能够适应复杂图结构特性的自适应采样方法。

**Method:** 本文引入了GRAPES，这是一种自适应采样方法，它通过训练第二个GNN来预测节点采样概率，从而学习识别对训练GNN至关重要的节点集合。该方法通过优化下游任务目标来训练采样GNN。

**Result:** GRAPES 在各种节点分类基准上进行了评估，包括同质图和异质图。结果表明，GRAPES 在准确性和可扩展性方面都表现出有效性，尤其是在多标签异质图上。与其他采样方法不同，GRAPES 即使在较小的样本量下也能保持高准确性，因此可以扩展到大规模图。

**Conclusion:** GRAPES 提供了一种有效的自适应采样解决方案，能够显著提高图神经网络的可扩展性，同时在处理大规模和复杂图（特别是异质图）时保持高准确性。

> **ai_Abstract:** 本文提出了一种名为 GRAPES 的自适应采样方法，旨在解决图神经网络（GNNs）在处理大规模图时面临的内存成本和可扩展性问题。GRAPES 通过训练一个辅助 GNN 来学习预测节点采样概率，从而智能地选择对 GNN 训练最重要的节点子集。这种方法克服了现有静态采样方法在异质图上泛化能力差的局限性。实验证明，GRAPES 在保持高准确性的同时，能有效提高 GNNs 的可扩展性，尤其是在处理多标签异质图时表现优异，即使在小样本量下也能保持高性能。

> **摘要翻译:** 图神经网络（GNNs）通过聚合邻居信息来学习表示节点。随着GNNs深度的增加，它们的感受野呈指数增长，导致高内存成本。现有的几种方法通过采样一小部分节点来解决这个问题，从而将GNNs扩展到更大的图。这些方法主要在同质图上进行评估，其中相邻节点通常共享相同的标签。然而，这些方法中的大多数依赖于静态启发式方法，可能无法推广到不同的图或任务。我们认为采样方法应该是自适应的，能够根据每个图的复杂结构特性进行调整。为此，我们引入了GRAPES，这是一种自适应采样方法，它学习识别对训练GNN至关重要的节点集合。GRAPES 训练第二个GNN来预测节点采样概率，通过优化下游任务目标。我们在各种节点分类基准上评估了GRAPES，包括同质图和异质图。我们证明了GRAPES 在准确性和可扩展性方面的有效性，特别是在多标签异质图上。与其他采样方法不同，GRAPES 即使在较小的样本量下也能保持高准确性，因此可以扩展到大规模图。我们的代码可在 https://github.com/dfdazac/grapes 公开获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [54] [On Equivariant Model Selection through the Lens of Uncertainty](https://arxiv.org/abs/2506.18629)
> *论不确定性视角下的等变模型选择*

*Putri A. van der Linden, Alexander Timans, Dharmesh Tailor, Erik J. Bekkers* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-15**

**Keywords:** 等变模型选择, 不确定性, 共形预测, 贝叶斯模型证据, 模型复杂性

**Comment:** 9 pages, 4 figures, 2 tables. In the 8th Workshop on Tractable
  Probabilistic Modeling at UAI 2025

> **TL;DR:** 本文从不确定性角度研究等变模型的选择问题，发现不确定性指标通常与预测性能一致，但贝叶斯模型证据表现不稳定，指出不确定性在指导对称性感知模型选择中的潜力。

**AI_Comments:** 本文创新性地将不确定性感知视角引入等变模型选择这一具有挑战性的问题，为解决如何选择具有不同对称性偏差的预训练模型提供了新思路。研究发现了贝叶斯模型证据在等变模型选择中的局限性，并指出了其与模型复杂性概念不匹配的原因，这对于未来改进贝叶斯方法在等变模型中的应用具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 等变模型利用对称性先验知识来提高预测性能，但架构约束错误可能适得其反。在学习或放宽约束方面已有研究，但选择具有不同对称性偏差的预训练模型仍然具有挑战性。

**Method:** 本文从不确定性感知的角度审视模型选择任务，将频率论（通过共形预测）、贝叶斯（通过边际似然）和基于校准的度量与朴素的基于误差的评估进行比较。

**Result:** 发现不确定性指标通常与预测性能一致，但贝叶斯模型证据表现不稳定。作者将此归因于所采用的最后一层拉普拉斯近似中贝叶斯和几何模型复杂性概念的不匹配。

**Conclusion:** 研究结果表明，不确定性在指导对称性感知模型选择方面具有潜力。

> **ai_Abstract:** 本文探讨了等变模型选择中的挑战，尤其是在存在不同对称性偏差的预训练模型时。研究者从不确定性感知的角度出发，比较了频率论、贝叶斯和基于校准的不确定性度量与传统误差评估方法。结果表明，不确定性指标通常与预测性能相关联，但贝叶斯模型证据表现出不一致性，这可能源于贝叶斯和几何模型复杂性概念的不匹配。研究强调了不确定性在指导对称性感知模型选择中的潜在价值。

> **摘要翻译:** 等变模型利用对称性先验知识来提高预测性能，但错误指定的架构约束反而会损害性能。虽然已有工作探索学习或放宽约束，但选择具有不同对称性偏差的预训练模型仍然具有挑战性。我们从不确定性感知的角度审视了这一模型选择任务，比较了频率论（通过共形预测）、贝叶斯（通过边际似然）和基于校准的度量与朴素的基于误差的评估。我们发现不确定性指标通常与预测性能一致，但贝叶斯模型证据表现不一致。我们将其归因于所采用的最后一层拉普拉斯近似中贝叶斯和几何模型复杂性概念的不匹配，并讨论了可能的补救措施。我们的研究结果指出了不确定性在指导对称性感知模型选择方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [56] [First-of-its-kind AI model for bioacoustic detection using a lightweight associative memory Hopfield neural network](https://arxiv.org/abs/2507.10642)
> *首个使用轻量级联想记忆霍普菲尔德神经网络的生物声学检测AI模型*

*Andrew Gascoyne, Wendy Lomas* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 生物声学检测, 霍普菲尔德神经网络, 联想记忆, 轻量级AI, 边缘计算

**Comment:** 12 pages, 5 figures

> **TL;DR:** 该论文提出了一种新型轻量级、快速、可持续、透明、可解释且准确的AI模型，使用联想记忆霍普菲尔德神经网络进行生物声学检测，解决了传统模型数据量大、能耗高、硬件要求高的问题。

**AI_Comments:** 该论文的创新点在于提出了首个基于轻量级联想记忆霍普菲尔德神经网络的生物声学检测AI模型。其重要性体现在解决了当前生物声学分析中存在的训练数据稀缺、计算资源消耗大、硬件要求高以及模型透明度不足等核心痛点。模型的快速训练、低资源消耗和高准确性使其在实际应用中具有巨大潜力，尤其是在野外边缘计算设备上的部署。其“透明、可解释”的特性也符合当前AI发展对可解释性的需求。不足之处可能在于，虽然提到了“不针对特定物种”，但仅以蝙蝠数据集进行演示，未来需要更多不同物种的数据集来验证其泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 当前保护生物声学领域面临大量数据分析的难题，现有AI模型在生物声学分析中存在训练数据有限、环境影响（能耗和碳足迹）、以及硬件要求高的问题，因此需要一种替代的AI模型来缓解这些问题。

**Method:** 本研究开发了一个基于联想记忆的霍普菲尔德神经网络AI模型，通过存储信号并检测相似信号来分类物种。该模型仅需每个目标声音的一个代表性信号进行训练，实现了快速训练。

**Result:** 该模型训练速度快（3毫秒），预处理和分类10384个蝙蝠录音仅需5.4秒（在标准Apple MacBook Air上）。模型轻量化，内存占用仅144.09 MB RAM。计算需求低，适用于多种标准个人设备和边缘处理设备。在评估数据集上，精度高达86%，且未发现模型与专家手动识别之间的不一致。该模型不针对特定物种。

**Conclusion:** 该论文提出了一种公平的AI模型，有望成为生物声学分析领域的颠覆性技术，实现快速、轻量级、可持续、透明、可解释和准确的生物声学分析。

> **ai_Abstract:** 本研究提出了一种新型轻量级联想记忆霍普菲尔德神经网络AI模型，旨在解决生物声学数据分析中现有模型面临的训练数据少、能耗高和硬件要求严苛的问题。该模型通过联想记忆实现信号存储与相似信号检测，进而进行物种分类。其特点是训练速度极快（3毫秒，仅需单个代表性信号），处理速度快（5.4秒分类10384个蝙蝠录音），内存占用低（144.09 MB），计算需求小，精度高（86%），且不限于特定物种。该模型为生物声学分析提供了一个可持续、透明、可解释且高效的解决方案，适用于边缘设备部署。

> **摘要翻译:** 保护生物声学领域日益增长的一个问题是分析被动声学监测设备产生的大量数据。在本文中，我们提出了一种替代的AI模型，它有潜力帮助缓解这个问题。我们的模型公式解决了在使用当前AI模型进行生物声学分析时遇到的关键问题，即：可用训练数据有限；环境影响，特别是这些模型训练和实施的能耗和碳足迹；以及相关的硬件要求。这项工作中开发的模型通过透明、可解释的霍普菲尔德神经网络使用联想记忆来存储信号并检测相似信号，然后可以用于对物种进行分类。训练是快速的（3毫秒），因为数据集中每个目标声音只需要一个代表性信号。该模型速度快，在标准的Apple MacBook Air上，预处理和分类所有10384个公开可用的蝙蝠录音仅需5.4秒。该模型也很轻量，内存占用小，RAM使用量为144.09 MB。因此，低计算需求使得该模型非常适合在各种标准个人设备上使用，并有可能通过边缘处理设备在野外部署。它还具有竞争性的准确性，在用于评估模型的数据集上，精度高达86%。事实上，我们没有发现模型与通过专家野外指南进行手动识别之间存在任何不一致的情况。尽管选择了一个蝙蝠回声定位呼叫数据集来演示这种首创的AI模型（仅用两个代表性呼叫进行训练），但该模型不针对特定物种。总之，我们提出了一种公平的AI模型，它有潜力成为快速、轻量级、可持续、透明、可解释和准确的生物声学分析的颠覆性技术。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [60] [Energy Efficiency in AI for 5G and Beyond: A DeepRx Case Study](https://arxiv.org/abs/2507.10409)
> *5G及未来AI中的能效：DeepRx案例研究*

*Amine Lbath, Ibtissam Labriji* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 能源效率, 深度学习, DeepRX, 知识蒸馏, 5G

**Comment:** 

> **TL;DR:** 本研究通过知识蒸馏优化DeepRX深度学习接收器的能效，旨在平衡AI/ML模型中的性能与能耗，并成功实现了性能相似但能耗更低的模型。

**AI_Comments:** 这篇论文通过深入研究DeepRX的能耗特性，并创新性地应用知识蒸馏技术来优化其能效，为5G及未来通信系统中的AI部署提供了有价值的参考。其亮点在于将能耗分析与模型压缩技术相结合，证明了在不牺牲关键性能指标（如BER）的前提下，实现AI模型节能的可行性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决AI/ML模型中能效与性能平衡的挑战，尤其是在深度学习接收器DeepRX的应用中，以应对5G及未来通信对能效的需求。

**Method:** 本研究首先评估了基于全卷积ResNet架构的DeepRX深度学习接收器的能耗，分析了FLOPs/Watt、FLOPs/clock等因素及内存访问模式的影响，并比较了训练和推理阶段的能耗动态。关键方法是应用知识蒸馏（KD）技术来训练紧凑型DeepRX学生模型，使其在性能上模拟教师模型但能耗更低。研究还实验了不同学生模型大小、最佳教师模型大小以及KD超参数，并通过误码率（BER）与信干噪比（SINR）性能来衡量模型效果。

**Result:** 研究发现，DeepRX的估计能耗与实际能耗一致，且受内存访问模式影响。通过知识蒸馏训练的紧凑型学生模型，在保持与教师模型相似性能的同时，显著降低了能耗。实验结果显示，蒸馏模型在不同SINR水平下表现出更低的误码率（BER）底线，证明了知识蒸馏在实现能效AI解决方案中的有效性。

**Conclusion:** 知识蒸馏是一种有效的方法，可以在不牺牲关键性能（如误码率）的前提下，显著提高深度学习接收器DeepRX的能效，为5G及未来通信系统中的节能AI部署提供了可行途径。

> **ai_Abstract:** 本研究探讨了在5G及未来通信中深度学习接收器DeepRX的能效优化问题。通过评估DeepRX的能耗并分析内存访问模式的影响，研究发现知识蒸馏（KD）是一种有效的节能策略。实验结果表明，经过KD训练的紧凑型学生模型能在保持与大型教师模型相似性能的同时，显著降低能耗并展现出更低的误码率，从而为实现高效能AI解决方案提供了可行途径。

> **摘要翻译:** 本研究旨在解决AI/ML模型中能效与性能平衡的挑战，重点关注DeepRX，一个基于全卷积ResNet架构的深度学习接收器。我们评估了DeepRX的能耗，考虑了FLOPs/Watt和FLOPs/clock等因素，并发现估计和实际能耗之间存在一致性，这受到内存访问模式的影响。研究还扩展到比较训练和推理阶段的能耗动态。一个关键贡献是应用知识蒸馏（KD）来训练一个紧凑型DeepRX学生模型，该模型能够模拟教师模型的性能，但能耗更低。我们实验了不同学生模型大小、最佳教师模型大小和KD超参数。性能通过比较蒸馏模型和从头训练模型的误码率（BER）性能与信干噪比（SINR）值来衡量。蒸馏模型在不同SINR水平下表现出更低的误差底线，突出了KD在实现节能AI解决方案方面的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [66] [Multi-Preference Lambda-weighted Listwise DPO for Dynamic Preference Alignment](https://arxiv.org/abs/2506.19780)
> *多偏好Lambda加权列表式DPO用于动态偏好对齐*

*Yuhui Sun, Xiyao Wang, Zixi Li, Zhenlong Yuan, Jinman Zhao* | **Category: cs.LG, I.2.6; I.2.7; I.5.1** | **Updated: 2025-07-14**

**Keywords:** 多偏好对齐, DPO, LLM, 列表式监督, 动态偏好

**Comment:** 13 pages, 9 figures, appendix included. To appear in Proceedings of
  AAAI 2026. Code:
  https://github.com/yuhui15/Multi-Preference-Lambda-weighted-DPO

> **TL;DR:** 本文提出Multi-Preference Lambda-weighted Listwise DPO，是对DPO的泛化，支持多维偏好和动态插值，无需重新训练。实验证明其在小模型上表现优于或匹敌标准DPO，并提升了适应性，对计算受限的应用具有实用价值。

**AI_Comments:** 该论文的创新点在于提出了Multi-Preference Lambda-weighted Listwise DPO，它显著扩展了DPO的能力，使其能够处理多维偏好并实现动态调整，而无需重新训练，这对于实际应用非常重要。其在小型模型上进行实验的策略也很有见地，因为它能更严格地测试对齐策略的有效性，并强调了该方法在计算资源受限环境下的实用价值。这对于推动LLM在更广泛场景中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在文本生成方面表现出色，但将其与人类偏好对齐仍然具有挑战性。强化学习从人类反馈（RLHF）虽然能改善对齐，但成本高昂且不稳定。直接偏好优化（DPO）提供了一种更简单的替代方案，但它假设偏好是固定的、单维的，这限制了其在复杂、多维偏好场景下的应用。

**Method:** 我们提出了Multi-Preference Lambda-weighted Listwise DPO，它是DPO的一种泛化，支持多个偏好维度，并通过单纯形加权的lambda向量实现动态插值。我们的方法支持列表式监督，并且无需重新训练即可实现灵活对齐。尽管实验在1B-2B规模模型上进行，但这是有意的选择，旨在更严格地测试对齐策略的有效性。

**Result:** 实验结果表明，我们的方法在对齐基准测试中匹配或超越了标准DPO，同时提供了更好的适应性。这种改进在计算受限的应用中具有方法学意义和实际价值。

**Conclusion:** Multi-Preference Lambda-weighted Listwise DPO通过支持多维偏好和动态插值，显著提升了大型语言模型（LLMs）的偏好对齐能力和适应性，尤其是在资源受限的环境下，为LLM的实际部署提供了更有效和实用的解决方案。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）与人类偏好对齐的挑战，特别是现有直接偏好优化（DPO）在处理多维和动态偏好方面的局限性，提出了一种名为Multi-Preference Lambda-weighted Listwise DPO的新方法。该方法泛化了DPO，使其能够支持多个偏好维度，并通过单纯形加权的lambda向量实现动态插值，同时支持列表式监督，且无需重新训练即可实现灵活对齐。尽管实验在1B-2B规模的小型模型上进行，旨在提供更严格的测试，并强调其在计算受限应用中的实用价值。实证结果表明，该方法在对齐基准测试中表现匹配或超越了标准DPO，并显著提升了模型的适应性。

> **摘要翻译:** 尽管大型语言模型（LLMs）在文本生成方面表现出色，但将其与人类偏好对齐仍然具有挑战性。从人类反馈中进行强化学习（RLHF）可以改善对齐，但成本高昂且不稳定。直接偏好优化（DPO）提供了一种更简单的替代方案，但它假设偏好是固定的、单维的。我们提出了Multi-Preference Lambda-weighted Listwise DPO，它是DPO的一种泛化，支持多个偏好维度，并通过单纯形加权的lambda向量实现动态插值。我们的方法支持列表式监督，并且无需重新训练即可实现灵活对齐。尽管我们的实验是在1B-2B规模的模型上进行的，但这是一个有意的选择：较小的模型提供了更严格的测试平台，性能改进能更清晰地反映对齐策略本身的有效性。此外，此类模型广泛用于计算受限的应用中，这使得我们的改进既具有方法学意义又具有实际价值。实证结果表明，我们的方法在对齐基准测试中匹配或超越了标准DPO，同时提供了更好的适应性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [67] [FedGSCA: Medical Federated Learning with Global Sample Selector and Client Adaptive Adjuster under Label Noise](https://arxiv.org/abs/2507.10611)
> *FedGSCA：在标签噪声下具有全局样本选择器和客户端自适应调节器的医疗联邦学习*

*Mengwen Ye, Yingzi Huangfu, Shujian Gao, Wei Ren, Weifan Liu, Zekuan Yu* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-07-13**

**Keywords:** 联邦学习, 标签噪声, 医疗图像分类, 全局样本选择器, 客户端自适应调节

**Comment:** 

> **TL;DR:** FedGSCA 是一种新的联邦学习框架，通过全局样本选择器和客户端自适应调节器有效应对医疗图像分类中的标签噪声，提高了模型性能和稳定性。

**AI_Comments:** FedGSCA 的创新之处在于其双重方法，结合了全局样本选择器和客户端自适应调节机制，以有效应对医疗联邦学习中的标签噪声异质性和数据不平衡。该研究对于推动联邦学习在真实医疗场景中的鲁棒性和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习在医疗图像分类中面临标签噪声导致的训练不稳定和性能下降问题，现有方法难以处理噪声异质性和医疗数据中的不平衡问题。

**Method:** 提出 FedGSCA 框架，包含：1. 全局样本选择器，聚合所有客户端的噪声知识，解决噪声异质性并提高全局模型稳定性。2. 客户端自适应调节 (CAA) 机制，结合自适应阈值伪标签生成和鲁棒可信标签损失，动态调整类别分布，纳入少数样本，并通过考虑多个合理标签来管理噪声标签。

**Result:** FedGSCA 在真实结肠玻片数据集和两个合成医疗数据集上进行了评估，在对称、非对称、极端和异质噪声条件下，FedGSCA 优于现有最先进方法，尤其在极端和异质噪声情景下表现出色，并显著提高了模型稳定性和处理复杂噪声的能力。

**Conclusion:** FedGSCA 显著提高了模型稳定性并能处理复杂噪声，非常适用于真实的医疗联邦学习场景。

> **ai_Abstract:** 本文提出了 FedGSCA，一个新颖的联邦学习框架，旨在解决医疗图像分类中标签噪声导致的训练不稳定和性能下降问题。FedGSCA 引入了全局样本选择器来聚合噪声知识并提高模型稳定性，同时开发了客户端自适应调节 (CAA) 机制，结合自适应阈值伪标签生成和鲁棒可信标签损失，以动态管理噪声标签和处理数据不平衡。实验结果表明，FedGSCA 在各种噪声条件下，特别是极端和异质噪声情景下，性能优于现有最先进方法，并显著提高了模型稳定性，适用于真实的医疗联邦学习场景。

> **摘要翻译:** 联邦学习 (FL) 作为一种在保护数据隐私的同时实现协作式医疗图像分类的解决方案而出现。然而，由机构间数据差异引起的标签噪声会导致训练不稳定并降低模型性能。现有的 FL 方法难以处理噪声异质性和医疗数据中的不平衡问题。受这些挑战的启发，我们提出了 FedGSCA，一个用于增强嘈杂医疗 FL 鲁棒性的新颖框架。FedGSCA 引入了一个全局样本选择器，它聚合了所有客户端的噪声知识，有效解决了噪声异质性并提高了全局模型稳定性。此外，我们开发了一种客户端自适应调节 (CAA) 机制，该机制结合了自适应阈值伪标签生成和鲁棒可信标签损失。CAA 动态调整类别分布，确保纳入少数样本，并通过考虑多个合理标签来仔细管理噪声标签。这种双重方法减轻了噪声数据的影响并防止了局部训练期间的过拟合，从而提高了模型的泛化能力。我们在一个真实世界的结肠玻片数据集和两个合成医疗数据集上评估了 FedGSCA，涵盖了各种噪声条件，包括对称、非对称、极端和异质类型。结果表明，FedGSCA 优于现有最先进的方法，在极端和异质噪声情景下表现出色。此外，FedGSCA 在提高模型稳定性和处理复杂噪声方面显示出显著优势，使其非常适合真实的医疗联邦学习场景。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [69] [Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback](https://arxiv.org/abs/2410.23022)
> *基于大型语言模型反馈的决策智能体在线内在奖励*

*Qinqing Zheng, Mikael Henaff, Amy Zhang, Aditya Grover, Brandon Amos* | **Category: cs.LG, cs.AI, cs.CL, cs.RO** | **Updated: 2025-07-15**

**Keywords:** 在线内在奖励, 大型语言模型, 强化学习, 分布式架构, NetHack

**Comment:** 

> **TL;DR:** 本文提出了ONI，一种分布式架构，利用大型语言模型反馈为强化学习智能体在线学习内在奖励，解决了现有方法在可扩展性和离线数据集方面的限制，并在NetHack环境中实现了最先进的性能。

**AI_Comments:** 本文的创新点在于提出了ONI，一个分布式且可扩展的在线内在奖励学习框架，它巧妙地利用LLM反馈，通过异步标注和模型蒸馏，解决了现有LLM-based奖励合成方法在可扩展性和对大规模离线数据集依赖方面的核心痛点。尤其是在NetHack这样复杂的环境中取得SOTA性能，突显了其在稀疏奖励和开放式探索任务中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 从自然语言描述中自动合成密集奖励是强化学习（RL）中一个有前景的范式。尽管最近的工作利用大型语言模型（LLMs）的先验知识取得了进展，但这些方法存在重要局限性：它们要么因需要对每个观察进行LLM标注而无法扩展到需要数十亿环境样本的问题，要么需要多样化的离线数据集，而这种数据集可能不存在或难以收集。

**Method:** 本文提出了ONI，一个分布式架构，通过结合算法和系统层面的贡献来解决上述限制。ONI同时学习RL策略和利用LLM反馈的内在奖励函数。它通过一个异步LLM服务器标注智能体收集的经验，然后将其提炼成一个内在奖励模型。研究探索了多种复杂度的奖励建模算法选择，包括哈希、分类和排序模型。

**Result:** 我们的方法在NetHack学习环境的一系列挑战性任务中实现了最先进的性能，同时消除了先前工作所需的大型离线数据集。

**Conclusion:** ONI提供了一种可扩展且有效的方法，可以从大型语言模型反馈中学习强化学习智能体的内在奖励，克服了现有工作的局限性。

> **ai_Abstract:** 本文针对强化学习中从大型语言模型（LLM）反馈合成奖励的可扩展性及对离线数据集的依赖问题，提出了ONI分布式架构。ONI通过异步LLM服务器标注智能体收集的经验，并将其提炼为内在奖励模型，同时学习RL策略和内在奖励函数。该方法在NetHack学习环境中取得了最先进的性能，且无需大量离线数据集，有效克服了现有方法的局限性。

> **摘要翻译:** 从自然语言描述中自动合成密集奖励是强化学习（RL）中一个有前景的范式，在稀疏奖励问题、开放式探索和分层技能设计方面都有应用。最近的工作通过利用大型语言模型（LLMs）的先验知识取得了有希望的进展。然而，这些方法存在重要的局限性：它们要么因为需要对每个观察进行LLM标注而无法扩展到需要数十亿环境样本的问题，要么需要多样化的离线数据集，而这种数据集可能不存在或无法收集。在这项工作中，我们通过结合算法和系统层面的贡献来解决这些限制。我们提出了ONI，一个分布式架构，它同时学习RL策略和利用LLM反馈的内在奖励函数。我们的方法通过一个异步LLM服务器标注智能体收集的经验，然后将其提炼成一个内在奖励模型。我们探索了多种复杂度的奖励建模算法选择，包括哈希、分类和排序模型。我们的方法在NetHack学习环境的一系列挑战性任务中实现了最先进的性能，同时消除了先前工作所需的大型离线数据集。我们已将代码开源在https://github.com/facebookresearch/oni。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [72] [Incorporating Interventional Independence Improves Robustness against Interventional Distribution Shift](https://arxiv.org/abs/2507.05412)
> *引入干预独立性提高对抗干预分布偏移的鲁棒性*

*Gautam Sreekumar, Vishnu Naresh Boddeti* | **Category: cs.LG, stat.ME** | **Updated: 2025-07-14**

**Keywords:** 干预独立性, 鲁棒性, 分布偏移, 因果推断, 表征学习

**Comment:** 

> **TL;DR:** 本文提出RepLIn算法，通过在训练中明确强制干预独立性，以提高模型在干预数据上的鲁棒性，有效解决现有方法在干预分布偏移下性能下降的问题。

**AI_Comments:** 该论文的创新点在于明确指出并解决了现有方法在处理干预数据时忽略因果独立性关系的问题。通过引入“干预独立性”的概念并提出RepLIn算法，提供了一种有效提高模型在干预分布偏移下鲁棒性的新范式。这对于在实际应用中处理因果干预数据，尤其是在数据量有限的情况下，具有重要的理论和实践意义。其方法的可扩展性和对连续离散变量的适用性也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的方法在处理干预数据时，即使已知底层因果模型，也将其视为观测数据，并忽略了干预产生的独立性关系。这导致它们未能充分利用干预产生的因果关系信息，从而在观测数据和干预数据上的预测性能存在巨大差异，当干预训练样本数量有限时，这种差异会恶化。

**Method:** 本文首先发现性能差异与表征对干预因果模型诱导的独立性条件的遵循程度之间存在强相关性。对于线性模型，推导了训练数据中干预数据比例的充分条件，在该条件下，强制干预节点及其非后代对应的表征之间的干预独立性可以降低干预数据上的误差。结合这些见解，本文提出了RepLIn训练算法，在干预过程中明确强制这种统计独立性。

**Result:** RepLIn在合成数据集、真实图像数据集（面部属性分类）和真实文本数据集（毒性检测）上展示了其效用。实验表明，RepLIn能够随着因果图中节点数量的增加而扩展，并且适用于提高连续和离散潜在变量对抗干预分布偏移的鲁棒性表征。

**Conclusion:** 通过引入干预独立性，RepLIn算法有效提高了模型在面对干预分布偏移时的鲁棒性，解决了现有方法在有限干预样本下的性能下降问题，并适用于多种数据类型和任务。

> **ai_Abstract:** 本文研究了学习因果相关潜在变量的鲁棒判别表示问题，特别是在训练数据包含观测数据和干预数据的情况下。现有方法未能充分利用干预产生的独立性关系，导致在干预分布偏移下性能下降。作者发现性能差异与表征对干预独立性条件的遵循程度高度相关，并为线性模型推导了强制干预独立性的充分条件。基于这些见解，提出RepLIn算法，通过明确强制干预独立性来提高鲁棒性。实验证明RepLIn在合成和真实数据集上有效，且具有可扩展性，适用于连续和离散变量，能够改善对抗干预分布偏移的鲁棒表示。

> **摘要翻译:** 我们考虑学习因果相关潜在变量的鲁棒判别表示问题。除了观测数据外，训练数据集还包括通过对其中一些潜在变量进行有针对性的干预获得的干预数据，以学习对由此产生的干预分布偏移具有鲁棒性的表示。现有方法将干预数据视为观测数据，即使已知底层因果模型，也忽略了这些干预产生的独立性关系。由于这些方法未能充分利用干预产生的因果关系信息，它们学习的表示在观测数据和干预数据上的预测性能产生巨大差异，当干预训练样本数量有限时，这种情况会恶化。在本文中，(1) 我们首先确定了这种性能差异与表示对干预因果模型诱导的独立性条件的遵循程度之间存在强相关性。(2) 对于线性模型，我们推导了训练数据中干预数据比例的充分条件，在该条件下，强制干预节点及其非后代对应的表示之间的干预独立性可以降低干预数据上的误差。结合这些见解，(3) 我们提出了RepLIn，一种训练算法，用于在干预过程中明确强制这种统计独立性。我们在合成数据集以及面部属性分类和毒性检测的真实图像和文本数据集上展示了RepLIn的效用。我们的实验表明，RepLIn可以随着因果图中节点数量的增加而扩展，并且适用于提高连续和离散潜在变量对抗干预分布偏移的鲁棒表示。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [78] [Dynamic Chunking for End-to-End Hierarchical Sequence Modeling](https://arxiv.org/abs/2507.07955)
> *动态分块用于端到端分层序列建模*

*Sukjun Hwang, Brandon Wang, Albert Gu* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 动态分块, 分层序列建模, 端到端学习, 语言模型, H-Net

**Comment:** 

> **TL;DR:** 本文提出一种动态分块机制，使语言模型实现真正的端到端学习，无需预处理分词，并在性能和数据效率上超越传统模型，尤其在分词困难的语言和模态中表现更佳。

**AI_Comments:** 这篇论文的创新点在于提出了动态分块机制，并将其集成到H-Net中，从而实现了真正的端到端语言模型，彻底摆脱了传统分词预处理的限制。这对于构建更通用、更鲁棒的基础模型具有重要意义，尤其是在处理多语言、代码或生物序列等分词困难的领域时，其优势更为明显。该方法通过联合学习分段策略和模型主体，实现了更深层次的数据理解，并展示了出色的扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 现有语言模型虽然强大，但预处理步骤（如分词）阻碍了实现真正的端到端基础模型。

**Method:** 本文引入了一系列新技术，实现了动态分块机制，该机制能够自动学习内容和上下文相关的分段策略，并与模型的其余部分联合学习。通过将此机制整合到显式分层网络（H-Net）中，取代了传统的分词-LM-反分词管道，实现了完全端到端学习。H-Net可以迭代多阶段分层以建模多个抽象级别。

**Result:** 在计算和数据匹配的情况下，一个在字节级别操作的单阶段H-Net优于强大的基于BPE标记的Transformer语言模型。多阶段H-Net通过建模多层次抽象，进一步提高了性能，显示出更好的数据扩展性，并匹配其两倍大小的基于标记的Transformer。在英语上预训练的H-Net显著提高了字符级鲁棒性，并在没有启发式或显式监督的情况下学习到有意义的数据依赖分块策略。H-Net在分词启发式较弱的语言和模态（如中文、代码或DNA序列）中，相对于分词管道的改进更大（数据效率比基线提高近4倍）。

**Conclusion:** H-Net通过学习动态分块机制，实现了真正的端到端语言模型，无需预处理分词，并在多种语言和模态中表现出卓越的性能、数据效率和鲁棒性，展示了从原始数据中更好学习和扩展的潜力。

> **ai_Abstract:** 本文提出了一种名为H-Net的端到端分层序列建模方法，通过引入动态分块机制，使其能够自动学习内容和上下文相关的分段策略，从而摆脱了传统语言模型对预处理分词的依赖。实验证明，H-Net在字节级别操作时性能优于基于BPE的Transformer，多阶段分层进一步提升了性能和数据扩展性。此外，H-Net在字符级鲁棒性上表现出色，尤其在中文、代码和DNA序列等分词挑战性语言和模态中，其数据效率和性能提升显著，展现了实现真正端到端基础模型的巨大潜力。

> **摘要翻译:** 近年来，语言模型（LMs）的重大进展主要源于从为特定任务设计的专用模型转向基于强大架构（例如Transformer）的通用模型，这些模型从原始数据中学习一切。尽管有这种趋势，但分词等预处理步骤仍然是实现真正端到端基础模型的障碍。我们引入了一系列新技术，实现了动态分块机制，该机制自动学习内容和上下文相关的分段策略，并与模型的其余部分联合学习。将其整合到显式分层网络（H-Net）中，可以取代（隐式分层的）分词-LM-反分词管道，成为一个完全端到端学习的单一模型。在计算和数据匹配的情况下，一个在字节级别操作的单阶段分层H-Net优于一个在BPE标记上操作的强大Transformer语言模型。将分层迭代到多个阶段进一步提高了其性能，通过建模多个抽象级别，展示了显著更好的数据扩展性，并匹配了其两倍大小的基于标记的Transformer。在英语上预训练的H-Net显示出显著提高的字符级鲁棒性，并在没有任何启发式或显式监督的情况下定性学习有意义的数据依赖分块策略。最后，H-Net相对于分词管道的改进在分词启发式较弱的语言和模态（例如中文和代码，或DNA序列）中进一步增加（数据效率比基线提高近4倍），显示了真正端到端模型从未经处理的数据中更好学习和扩展的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [81] [Diffusion Decoding for Peptide De Novo Sequencing](https://arxiv.org/abs/2507.10955)
> *用于肽段从头测序的扩散解码*

*Chi-en Amy Tai, Alexander Wong* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 扩散解码器, 肽段从头测序, 串联质谱, 自回归解码器, DINOISER损失

**Comment:** 

> **TL;DR:** 该论文探索使用扩散解码器进行肽段从头测序，以解决传统自回归解码器存在的级联错误和高置信度区域利用不足的问题。虽然简单的替换效果不佳，但结合DINOISER损失函数的最佳扩散解码器设计在氨基酸召回率上取得了显著提升。

**AI_Comments:** 本文的创新点在于将扩散解码器引入到肽段从头测序这一离散数据领域，以解决传统自回归模型在处理级联错误和利用高置信度区域上的局限性。其重要性在于为肽段测序提供了一种新的生成范式，有望提升预测精度。然而，一个明显的局限性是其在肽段级别的精确率和召回率仍为0，这表明该方法在完整肽段重建方面仍有很大的改进空间。

<details>
  <summary>Details</summary>

**Motivation:** 传统的深度学习方法，如Casanovo，主要使用自回归解码器顺序预测氨基酸，导致级联错误并未能有效利用高置信度区域。为解决这些问题，本文研究了适用于离散数据域的扩散解码器。

**Method:** 本文研究了适用于离散数据域的扩散解码器，并尝试了三种不同的扩散解码器设计、背包束搜索和各种损失函数（特别是DINOISER损失函数）。

**Result:** 研究发现，背包束搜索未能提高性能指标，简单地用扩散解码器替换Transformer解码器会降低性能。然而，采用DINOISER损失函数的最佳扩散解码器设计在氨基酸召回率方面比基线自回归解码器Casanovo模型取得了统计学上显著的0.373的提升，尽管肽段精确率和召回率仍为0。

**Conclusion:** 这些发现突出了扩散解码器不仅能增强模型敏感性，还能推动肽段从头测序取得重大进展的潜力。

> **ai_Abstract:** 本文探讨了将扩散解码器应用于肽段从头测序，以克服传统自回归解码器（如Casanovo）的级联错误和高置信度区域利用不足的问题。研究人员实验了多种扩散解码器设计、搜索策略和损失函数。结果表明，虽然简单的替换和背包束搜索没有带来提升，但结合DINOISER损失函数的最佳扩散解码器设计显著提高了氨基酸召回率，显示了其在增强模型敏感性和推动肽段从头测序方面的潜力。

> **摘要翻译:** 肽段从头测序是一种无需依赖现有蛋白质序列数据库，从串联质谱数据中重建氨基酸序列的方法。传统的深度学习方法，如Casanovo，主要利用自回归解码器并按顺序预测氨基酸。随后，它们会遇到级联错误，并且未能有效利用高置信度区域。为了解决这些问题，本文研究了适用于离散数据域的扩散解码器。这些解码器提供了一种不同的方法，允许序列生成从任何肽段开始，从而提高预测精度。我们实验了三种不同的扩散解码器设计、背包束搜索和各种损失函数。我们发现背包束搜索并未提高性能指标，并且简单地用扩散解码器替换Transformer解码器会降低性能。尽管肽段精确率和召回率仍为0，但采用DINOISER损失函数的最佳扩散解码器设计在氨基酸召回率方面比基线自回归解码器Casanovo模型取得了统计学上显著的0.373的提升。这些发现突出了扩散解码器不仅能增强模型敏感性，还能推动肽段从头测序取得重大进展的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [82] [A Neural Network Model of Complementary Learning Systems: Pattern Separation and Completion for Continual Learning](https://arxiv.org/abs/2507.11393)
> *互补学习系统的神经网络模型：持续学习中的模式分离与完成*

*James P Jun, Vijay Marupudi, Raj Sanjay Shah, Sashank Varma* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 持续学习, 灾难性遗忘, 互补学习系统, 模式分离, 模式完成

**Comment:** Accepted to CogSci 2025. 7 pages, 7 figures

> **TL;DR:** 提出一种结合VAE和现代Hopfield网络的神经网络模型，通过模拟模式分离和完成，有效解决了神经网络中的灾难性遗忘问题，实现了接近最先进水平的持续学习性能。

**AI_Comments:** 这项工作通过结合VAE和MHN，首次在神经网络模型中成功模拟了互补学习系统的模式分离和完成机制，为解决持续学习中的灾难性遗忘问题提供了一个神经学上合理的创新方法。其贡献在于不仅提出了一个高性能模型，还通过实证分析验证了各组件的功能性解离，加深了对记忆机制的理解。

<details>
  <summary>Details</summary>

**Motivation:** 神经网络模型在学习新信息时会遭受灾难性遗忘，即对先前学习任务的性能显著下降，而人类智能能够不遗忘旧知识地学习新信息。互补学习系统（CLS）理论解释了这种人类能力，提出大脑有不同的系统用于模式分离和模式完成，以避免遗忘。

**Method:** 利用变分自编码器（VAEs）的表征泛化能力和现代霍普菲尔德网络（MHNs）的鲁棒记忆存储特性，将它们结合成一个神经学上合理的持续学习模型，以捕捉互补学习系统中的模式分离和完成功能。

**Result:** 该模型在Split-MNIST任务上取得了接近最先进水平的准确率（约90%），显著减少了遗忘。表征分析经验性地证实了功能分离：VAE负责模式完成，MHN负责模式分离。

**Conclusion:** 通过在可扩展架构中捕捉模式分离和完成，该工作为建模生物和人工系统中的记忆巩固、泛化和持续学习提供了一个功能模板。

> **ai_Abstract:** 本文提出一个基于互补学习系统（CLS）理论的神经网络模型，旨在解决持续学习中的灾难性遗忘问题。该模型结合了变分自编码器（VAE）和现代霍普菲尔德网络（MHN），分别实现模式完成和模式分离功能。实验在Split-MNIST任务上取得了接近最先进水平的性能，并有效减少了遗忘，为生物和人工系统中的记忆建模提供了新的框架。

> **摘要翻译:** 学习新信息而不忘记先前知识是人类智能的核心。相比之下，神经网络模型遭受灾难性遗忘：在获取新信息时，先前学习任务的性能会显著下降。互补学习系统（CLS）理论为这种人类能力提供了解释，提出大脑具有用于模式分离（编码不同记忆）和模式完成（从部分线索中检索完整记忆）的独立系统。为了捕捉这些互补功能，我们利用变分自编码器（VAEs）的表征泛化能力和现代霍普菲尔德网络（MHNs）的鲁棒记忆存储特性，将它们结合成一个神经学上合理的持续学习模型。我们在Split-MNIST任务（一个流行的持续学习基准）上评估了该模型，并取得了接近最先进水平的准确率（约90%），显著减少了遗忘。表征分析经验性地证实了功能分离：VAE负责模式完成，而MHN负责模式分离。通过在可扩展架构中捕捉模式分离和完成，我们的工作为建模生物和人工系统中的记忆巩固、泛化和持续学习提供了一个功能模板。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [83] [EASTER: Embedding Aggregation-based Heterogeneous Models Training in Vertical Federated Learning](https://arxiv.org/abs/2310.13367)
> *EASTER：基于嵌入聚合的垂直联邦学习异构模型训练*

*Shuo Wang, Keke Gai, Jing Yu, Liehuang Zhu, Kim-Kwang Raymond Choo, Bin Xiao* | **Category: cs.LG, cs.AI, cs.DC** | **Updated: 2025-07-15**

**Keywords:** 垂直联邦学习, 异构模型, 嵌入聚合, 隐私保护, 盲因子

**Comment:** 15 pages, 19 figures

> **TL;DR:** VFedMH是一种新的垂直联邦学习方法，通过聚合局部嵌入和使用轻量级盲因子来训练异构模型，解决现有VFL方法在处理异构模型时的挑战。

**AI_Comments:** VFedMH的创新点在于其嵌入聚合机制和轻量级盲因子的隐私保护方法，以及主动方协助被动方计算梯度的设计，这些都有效地解决了垂直联邦学习中异构模型训练的挑战，提升了模型的收敛性和性能，对保护数据隐私的同时实现高效协作学习具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有垂直联邦学习方法在处理参与方之间异构的局部模型时面临挑战，这会影响优化收敛性和泛化能力。

**Method:** 提出VFedMH方法，通过在前向传播过程中聚合每个参与方的局部嵌入来训练多个异构模型。为保护嵌入值，引入基于轻量级盲因子的嵌入保护方法。具体地，被动方将盲因子注入其局部嵌入并发送给主动方，主动方聚合得到全局知识嵌入并传回被动方进行前向传播。主动方协助被动方计算其局部异构模型梯度，然后各参与方使用这些梯度训练各自的局部模型，目标是最小化各自异构模型的损失值。

**Result:** 广泛的实验证明VFedMH能够同时训练多个异构模型并进行异构优化，且在模型性能上优于一些最新方法。

**Conclusion:** VFedMH成功解决了垂直联邦学习中异构模型训练的挑战，通过其独特的嵌入聚合和梯度计算机制，实现了更好的收敛性和模型性能。

> **ai_Abstract:** 本文提出了一种新颖的垂直联邦学习方法VFedMH，旨在解决现有方法在处理参与方异构局部模型时遇到的收敛性和泛化问题。VFedMH通过在前向传播中聚合参与方的局部嵌入知识，并采用轻量级盲因子保护嵌入值。该方法还设计了主动方协助被动方计算局部模型梯度的机制。实验结果表明，VFedMH能够有效地训练多个异构模型，实现异构优化，并在性能上超越现有方法。

> **摘要翻译:** 垂直联邦学习因其允许客户端在不共享本地数据的情况下协作训练机器学习模型，从而保护客户端的本地私有数据而受到广泛关注。然而，现有的垂直联邦学习方法在处理参与方之间异构的局部模型时面临挑战，这会影响优化收敛性和泛化能力。为了解决这一挑战，本文提出了一种名为“用于训练多个异构模型的垂直联邦学习（VFedMH）”的新颖方法。VFedMH侧重于在前向传播过程中聚合每个参与方的局部嵌入知识。为了保护参与方的局部嵌入值，我们提出了一种基于轻量级盲因子的嵌入保护方法。具体来说，参与方使用局部异构模型获取局部嵌入。然后，仅拥有样本特征的被动方将盲因子注入局部嵌入并发送给主动方。主动方聚合局部嵌入以获得全局知识嵌入并将其发送给被动方。被动方随后利用全局嵌入在其局部异构网络上进行前向传播。然而，被动方不拥有样本标签，因此无法在本地计算局部模型梯度。为了克服这一限制，主动方协助被动方计算其局部异构模型梯度。然后，每个参与方使用异构模型梯度训练其局部模型。目标是最小化各自局部异构模型的损失值。进行了广泛的实验，证明VFedMH可以同时训练多个异构模型并进行异构优化，并且在模型性能上优于一些最新方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [86] [Offline Reinforcement Learning with Wasserstein Regularization via Optimal Transport Maps](https://arxiv.org/abs/2507.10843)
> *离线强化学习中基于最优传输映射的Wasserstein正则化*

*Motoki Omura, Yusuke Mukuta, Kazuki Ota, Takayuki Osa, Tatsuya Harada* | **Category: cs.LG, cs.AI, cs.RO** | **Updated: 2025-07-14**

**Keywords:** 离线强化学习, Wasserstein距离, 最优传输, 正则化, 输入凸神经网络

**Comment:** Accepted at RLC 2025

> **TL;DR:** 提出了一种使用Wasserstein距离和ICNNs进行离线强化学习正则化的方法，避免了对抗性训练并实现了SOTA性能。

**AI_Comments:** 该论文的创新点在于将Wasserstein距离引入离线强化学习的正则化中，并巧妙地利用ICNNs实现无判别器的计算，这解决了传统基于f-散度方法可能存在的鲁棒性问题以及对抗性训练带来的不稳定性，为离线RL提供了一个新颖且有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 离线强化学习中存在分布偏移的挑战，导致学习到的策略偏离数据集分布并可能产生不可靠的分布外动作。现有正则化方法多采用基于密度比的度量（如f-散度），但对分布外数据可能不够鲁棒。

**Method:** 提出一种利用Wasserstein距离进行正则化的方法，该方法通过输入凸神经网络（ICNNs）建模最优传输映射，以无判别器的方式计算Wasserstein距离，从而避免对抗性训练并确保学习稳定性。

**Result:** 该方法在D4RL基准数据集上表现出与广泛使用的现有方法相当或更优的性能。

**Conclusion:** 提出的基于Wasserstein距离和最优传输映射的离线强化学习正则化方法有效缓解了分布偏移问题，并在实际应用中展现出优越性。

> **ai_Abstract:** 本文针对离线强化学习中的分布偏移问题，提出了一种基于Wasserstein距离的正则化方法。该方法利用输入凸神经网络（ICNNs）建模最优传输映射，实现无判别器的Wasserstein距离计算，从而避免对抗性训练并提高学习稳定性。实验结果表明，该方法在D4RL基准数据集上取得了与现有主流方法相当或更优的性能。

> **摘要翻译:** 离线强化学习 (RL) 旨在从静态数据集中学习最优策略，这在数据收集成本高昂的场景（如机器人技术）中尤其有价值。离线强化学习中的一个主要挑战是分布偏移，即学习到的策略偏离数据集分布，可能导致不可靠的分布外动作。为了缓解这个问题，已经采用了正则化技术。虽然许多现有方法利用基于密度比的度量（例如 f-散度）进行正则化，但我们提出了一种利用 Wasserstein 距离的方法，该方法对分布外数据具有鲁棒性，并能捕获动作之间的相似性。我们的方法采用输入凸神经网络 (ICNNs) 来建模最优传输映射，从而以无判别器的方式计算 Wasserstein 距离，从而避免对抗性训练并确保学习的稳定性。我们的方法在 D4RL 基准数据集上表现出与广泛使用的现有方法相当或更优的性能。代码可在 https://github.com/motokiomura/Q-DOT 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [104] [A Group Theoretic Analysis of the Symmetries Underlying Base Addition and Their Learnability by Neural Networks](https://arxiv.org/abs/2507.10678)
> *神经网络学习基础加法中对称性的群论分析*

*Cutter Dawes, Simon Segert, Kamesh Krishnamurthy, Jonathan D. Cohen* | **Category: cs.LG, cs.AI, cs.NE, q-bio.NC** | **Updated: 2025-07-14**

**Keywords:** 群论, 激进泛化, 神经网络, 基础加法, 对称性

**Comment:** 22 pages, 6 figures

> **TL;DR:** 本文对基础加法中的对称性进行了群论分析，并研究了神经网络学习这些对称性的能力，发现合适的输入格式和进位函数能使神经网络实现激进泛化。

**AI_Comments:** 本文通过将激进泛化问题与对称性和群论相结合，为神经网络的泛化能力提供了一个新颖的分析视角。其创新点在于系统地分析了不同进位函数的作用及其对神经网络可学习性的影响。研究结果强调了输入表示和任务结构对于实现神经网络鲁棒泛化的重要性，这对于人工智能的理论理解和实际模型设计都具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 神经网络在实现激进泛化方面面临挑战，这根植于其发现和实现对称函数的能力。本文旨在通过研究基础加法这一范例来解决这一挑战。

**Method:** 本文对基础加法进行了群论分析，揭示了多种进位函数并量化表征它们。然后，通过训练神经网络使用不同的进位函数执行基础加法，比较学习效率和速度，以探究神经网络在对称性学习中的归纳偏置。

**Result:** 研究发现，即使是简单的神经网络，在正确的输入格式和进位函数下也能实现激进泛化，并且学习速度与进位函数结构密切相关。

**Conclusion:** 研究结果对认知科学和机器学习具有重要意义。

> **ai_Abstract:** 本文通过对基础加法进行群论分析，探讨了神经网络学习对称性以实现激进泛化的能力。研究揭示了多种进位函数并对其进行了量化，随后通过训练神经网络使用不同进位函数执行基础加法，探究了神经网络的归纳偏置。结果表明，简单的神经网络在具备合适的输入格式和进位函数时可以实现激进泛化，且学习速度与进位函数结构紧密相关。研究讨论了这些发现对认知科学和机器学习的启示。

> **摘要翻译:** 神经网络在模拟人类认知功能和人工智能应用中面临的一个主要挑战是设计能够有效学习支持激进泛化（radical generalization）的系统。其根本在于发现和实现对称函数的能力。在本文中，我们通过利用对称性研究了激进泛化的一种典范例子：基础加法。我们对基础加法进行了群论分析，其一个基本且决定性的特征是进位函数——当和超过基数模时，将余数转移到下一个有效位。我们的分析揭示了给定基数存在一系列替代的进位函数，并引入了量化度量来表征它们。然后，我们利用进位函数的差异来探究神经网络在对称性学习中的归纳偏置，通过训练神经网络使用不同的进位来执行基础加法，并比较其功效和学习速度作为其结构的函数。我们发现，即使是简单的神经网络，在正确的输入格式和进位函数下也能实现激进泛化，并且学习速度与进位函数结构密切相关。随后，我们讨论了这对于认知科学和机器学习的相关性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [118] [Toward Improving fNIRS Classification: A Study on Activation Functions in Deep Neural Architectures](https://arxiv.org/abs/2507.11436)
> *改善fNIRS分类：深度神经网络架构中激活函数的研究*

*Behtom Adeli, John McLinden, Pankaj Pandey, Ming Shao, Yalda Shahriari* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** fNIRS, 激活函数, 深度学习, 分类, 对称激活函数

**Comment:** 

> **TL;DR:** 本研究系统评估了fNIRS分类中深度学习模型不同激活函数的影响，发现对称激活函数（如Tanh和Abs(x)）表现优于ReLU，并强调了选择与fNIRS信号特性相符的激活函数的重要性。

**AI_Comments:** 本研究填补了fNIRS领域深度学习中激活函数系统性研究的空白，其创新点在于首次系统比较了多种激活函数在fNIRS分类任务中的表现，并特别指出了对称激活函数（如Tanh和Abs(x)）的优越性。这对于优化fNIRS数据分析的深度学习模型具有重要指导意义，为未来的模型设计提供了关键参考。

<details>
  <summary>Details</summary>

**Motivation:** 激活函数对深度神经网络性能至关重要，尤其在fNIRS领域，由于非线性、低信噪比和信号变异性等挑战，模型精度受到影响。然而，激活函数对fNIRS领域深度学习性能的影响尚未得到充分探索和系统研究。

**Method:** 研究评估了一系列常规和特定领域的激活函数，用于fNIRS分类任务，使用了多种深度学习架构，包括fNIRSNet、AbsoluteNet、MDNN和shallowConvNet（作为基线）。所有模型都在一个听觉任务中记录的单一数据集上进行测试，并采用标准化预处理和一致的训练参数以确保公平比较。

**Result:** 结果表明，对称激活函数如Tanh和绝对值函数Abs(x)在某些架构下可以优于常用的函数如ReLU。此外，对对称性作用的专门分析使用了改进的绝对函数（MAF），结果进一步支持了对称激活函数在性能提升方面的有效性。

**Conclusion:** 这些发现强调了选择与fNIRS数据信号特性相符的适当激活函数的重要性。

> **ai_Abstract:** 本研究系统评估了深度神经网络中激活函数对fNIRS分类性能的影响，解决了该领域激活函数研究不足的问题。通过在多个深度学习架构上测试常规和领域特定的激活函数，研究发现对称激活函数（如Tanh和Abs(x)）在fNIRS数据分类中表现优于ReLU，并强调了根据fNIRS信号特性选择合适激活函数的重要性。

> **摘要翻译:** 激活函数对深度神经网络的性能至关重要，特别是在功能性近红外光谱（fNIRS）等领域，非线性、低信噪比（SNR）和信号变异性对模型精度构成了重大挑战。然而，激活函数对fNIRS领域深度学习（DL）性能的影响尚未得到充分探索，并且在当前文献中缺乏系统性研究。本研究评估了一系列常规和领域特定的激活函数，用于fNIRS分类任务，使用了多种深度学习架构，包括领域特定的fNIRSNet、AbsoluteNet、MDNN和shallowConvNet（作为基线），所有这些都在听觉任务期间记录的单一数据集上进行了测试。为了确保公平比较，所有网络都使用标准化的预处理和一致的训练参数进行训练和测试。结果表明，对称激活函数如Tanh和绝对值函数Abs(x)可以优于常用的函数如修正线性单元（ReLU），这取决于具体的架构。此外，使用改进的绝对函数（MAF）对对称性作用进行了重点分析，结果进一步支持了对称激活函数在性能提升方面的有效性。这些发现强调了选择与fNIRS数据信号特性相符的适当激活函数的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [119] [Learning Safe Numeric Planning Action Models](https://arxiv.org/abs/2312.10705)
> *学习安全数值规划动作模型*

*Argaman Mordoch, Shahaf S. Shperberg, Roni Stern, Berndan Juba* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 数值规划, 动作模型学习, 安全性, N-SAM, N-SAM*

**Comment:** 

> **TL;DR:** 提出了N-SAM和N-SAM*算法，用于学习安全的数值规划动作模型，解决了任务关键领域中模型获取和安全性问题。

**AI_Comments:** 本文的创新在于提出了N-SAM和N-SAM*算法，将安全动作模型学习从布尔变量领域扩展到更复杂的数值领域，这对于现实世界的任务关键型应用具有重要意义。N-SAM*通过优化样本复杂度，提高了算法的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在将规划技术应用于现实世界问题时，获取准确的规划模型是一个重大挑战，尤其是在任务关键领域，试错法不可行，需要学习安全的动作模型。现有的安全动作模型学习主要针对布尔变量描述的领域。

**Method:** 提出了N-SAM算法，能够学习安全的数值前置条件和效果，并在观察数量上具有线性时间复杂度，在特定条件下保证返回安全的动作模型。为解决N-SAM需要大量观察的限制，提出了N-SAM*，它即使在只观察一次的情况下也能返回一个动作模型，其中每个观察到的动作至少在某些状态下是适用的，且不损害安全性。N-SAM*在样本复杂度方面优于其他保证安全性的算法。

**Result:** N-SAM和N-SAM*在大量的数值规划领域基准上进行了评估，并与最先进的数值动作模型学习算法进行了性能比较。

**Conclusion:** N-SAM和N-SAM*能够有效学习安全的数值规划动作模型，N-SAM*在样本复杂度方面具有最优性，适用于任务关键型领域。

> **ai_Abstract:** 本文提出了N-SAM和N-SAM*两种算法，用于学习安全的数值规划动作模型。N-SAM能够从观察中学习安全的数值前置条件和效果，并在特定条件下保证安全，但需要大量样本。N-SAM*作为N-SAM的扩展，解决了样本需求高的限制，即使在样本稀疏的情况下也能保证动作的适用性，并且在样本复杂度方面达到最优。这些算法旨在解决任务关键领域中规划模型获取和安全性挑战，并在广泛的数值规划领域基准上进行了评估。

> **摘要翻译:** 将规划技术应用于现实世界问题的一个重大挑战在于获取能够准确表示问题动态的规划模型。在任务关键型领域中，获取规划模型更具挑战性，因为试错法学习如何行动是不可行的。在这些领域中，用于生成规划的动作模型必须是安全的，即使用它生成的规划必须是可应用的并能实现其目标。% 学习用于规划的安全动作模型主要在状态由布尔变量充分描述的领域中进行了探索。% 在这项工作中，我们超越了这一限制，并提出了数值安全动作模型学习（N-SAM）算法。在这项工作中，我们提出了N-SAM，一种能够学习安全数值前置条件和效果的动作模型学习算法。我们证明了N-SAM在观察数量上具有线性时间复杂度，并且在某些条件下，保证返回安全的动作模型。然而，为了保持这种安全保证，N-SAM在将每个动作包含到学习模型中之前，必须观察大量示例。我们解决了N-SAM的这一限制，并提出了N-SAM*，N-SAM算法的一个扩展，它总是返回一个动作模型，其中每个观察到的动作至少在某些状态下是适用的，即使它只被观察过一次。N-SAM*这样做并没有损害返回动作模型的安全性。我们证明了N-SAM*在样本复杂度方面相对于任何其他保证安全性的算法都是最优的。N-SAM和N-SAM*在大量的数值规划领域基准上进行了评估，并将其性能与最先进的数值动作模型学习算法进行了比较。我们还讨论了数值精度对学习过程的影响。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [121] [Sub-Scaling Laws: On the Role of Data Density and Training Strategies in LLMs](https://arxiv.org/abs/2507.10613)
> *亚标度定律：关于LLMs中数据密度和训练策略的作用*

*Zhengyu Chen, Siqi Wang, Teng Xiao, Yudong Wang, Shiqi Chen, Xunliang Cai, Junxian He, Jingang Wang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-13**

**Keywords:** 亚标度定律, 大型语言模型, 数据密度, 训练策略, 资源分配

**Comment:** 

> **TL;DR:** 传统LLM扩展定律在某些情况下性能提升放缓（亚标度现象）。本文通过分析400多个模型，发现高数据密度和非最佳资源分配是导致亚标度的关键因素，并提出了一个亚最优标度定律，强调数据质量和多样性。

**AI_Comments:** 本文通过大规模实证分析，揭示了LLM训练中传统扩展定律的局限性，并提出了“亚标度”的概念及其成因。其创新之处在于强调了数据质量和资源分配的重要性，而非仅仅是数据量和模型大小。提出的亚最优标度定律为未来LLM的训练优化提供了新的理论指导，对于提高训练效率和模型性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统扩展定律认为增加模型大小和训练数据能提升性能，但在大型语言模型（LLMs）中出现了性能提升减速的“亚标度”现象。本文旨在重新审视这些定律，探究数据质量和训练策略对模型性能的影响。

**Method:** 通过对400多个模型进行广泛的实证分析。

**Result:** 识别出高数据密度和非最佳资源分配是导致亚标度的关键因素。高数据密度因信息冗余导致收益递减，而最佳资源分配对持续性能提升至关重要。提出了一个能更好预测亚标度范围内性能的亚最优标度定律。

**Conclusion:** 数据质量和多样性对于大型语言模型（LLM）的持续性能提升至关重要，传统扩展定律在亚标度情境下需要修正，并为此提出了新的亚最优标度定律。

> **ai_Abstract:** 本文重新审视了大型语言模型（LLMs）中的扩展定律，特别是针对“亚标度”现象，即性能提升减缓。通过对400多个模型的实证分析，研究发现高数据密度（导致信息冗余和收益递减）和非最佳资源分配是导致亚标度的主要原因。为此，论文提出了一个“亚最优标度定律”，旨在更准确地预测亚标度情况下的性能，并强调了数据质量和多样性在LLMs训练中的关键作用。

> **摘要翻译:** 自然语言处理中的传统扩展定律表明，增加模型大小和训练数据可以提高性能。然而，最近的研究揭示了偏差，特别是在大型语言模型中，性能改进减速，这种现象被称为亚标度。本文通过检查数据质量和训练策略对模型性能的影响，重新审视了这些扩展定律。通过对400多个模型进行广泛的实证分析，我们确定高数据密度和非最佳资源分配是导致亚标度的关键因素。高数据密度由于冗余信息导致收益递减，而最佳资源分配对于持续的性能改进至关重要。我们提出了一种亚最优标度定律，可以更好地预测亚标度范围内的性能，强调了数据质量和多样性的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [124] [Robust-Multi-Task Gradient Boosting](https://arxiv.org/abs/2507.11411)
> *鲁棒多任务梯度提升*

*Seyedsaman Emami, Gonzalo Martínez-Muñoz, Daniel Hernández-Lobato* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 多任务学习, 梯度提升, 任务异质性, 鲁棒性, 异常任务

**Comment:** 

> **TL;DR:** 提出了一种名为R-MTGB的新型梯度提升框架，用于解决多任务学习中存在的任务异质性问题，特别是处理异常或对抗性任务，同时保持知识共享和提高整体性能。

**AI_Comments:** R-MTGB的创新之处在于它将任务异质性建模并集成到梯度提升框架中，通过三阶段学习过程自动识别和处理异常任务，这对于实际应用中多任务场景的复杂性和噪声具有重要意义。它提升了多任务学习的鲁棒性，使其在包含不一致任务的数据集中也能保持高性能。

<details>
  <summary>Details</summary>

**Motivation:** 传统的多任务学习（MTL）和提升算法在处理多任务问题时表现出色，但现实世界的MTL场景常包含不一致（异常或对抗性）的任务，这些任务不共享有益的相似性，反而会降低模型性能。

**Method:** 提出鲁棒多任务梯度提升（R-MTGB），一个新型提升框架。它将学习过程分为三个顺序块：1) 学习共享模式；2) 使用正则化参数将任务分为异常任务和非异常任务；3) 微调任务特定预测器。该架构能自动检测并惩罚异常任务，同时促进相关任务间的有效知识迁移，并无缝集成到梯度提升中。

**Result:** 在合成基准和真实世界数据集上的大量实验表明，R-MTGB成功地隔离了异常任务、实现了知识迁移，并持续降低了每个任务的预测误差，同时实现了所有任务的整体性能提升。

**Conclusion:** R-MTGB在具有挑战性的多任务学习环境中表现出鲁棒性、适应性和可靠的收敛性。

> **ai_Abstract:** 本文提出了一种名为鲁棒多任务梯度提升（R-MTGB）的新型框架，旨在解决多任务学习（MTL）中存在的任务异质性问题，特别是当存在不共享有益相似性的异常或对抗性任务时。R-MTGB将学习过程分为三个阶段：学习共享模式、区分异常任务和非异常任务、以及微调任务特定预测器。该方法能够自动识别和惩罚异常任务，促进有效知识迁移，并无缝集成到梯度提升中。实验证明，R-MTGB在隔离异常任务、知识迁移和提高整体预测性能方面表现出优越的鲁棒性和适应性。

> **摘要翻译:** 多任务学习（MTL）在利用任务间共享信息以提高泛化能力方面表现出有效性。MTL假设任务共享相似性可以提高性能。此外，提升算法由于其能够关注难以学习的实例并迭代地减少残差误差，在各种学习问题中表现出卓越的性能。这使得它们成为学习多任务问题的一种有前景的方法。然而，现实世界的MTL场景通常涉及不一致的任务（被称为异常或对抗性任务），这些任务不与其他任务共享有益的相似性，实际上可能降低整体模型的性能。为了克服这一挑战，我们提出了鲁棒多任务梯度提升（R-MTGB），这是一种新颖的提升框架，在训练过程中明确建模并适应任务异质性。R-MTGB将学习过程构建为三个顺序块：(1) 学习共享模式，(2) 使用正则化参数将任务划分为异常任务和非异常任务，以及(3) 微调任务特定预测器。这种架构使R-MTGB能够自动检测和惩罚异常任务，同时促进相关任务间的有效知识迁移。我们的方法将这些机制无缝集成到梯度提升中，从而能够在不牺牲准确性的情况下稳健地处理噪声或对抗性任务。在合成基准和真实世界数据集上的大量实验表明，我们的方法成功地隔离了异常任务，实现了知识迁移，并持续降低了每个任务的预测误差，同时实现了所有任务的整体性能提升。这些结果突出了R-MTGB在具有挑战性的MTL环境中的鲁棒性、适应性和可靠的收敛性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [129] [Physics-Informed Neural Networks For Semiconductor Film Deposition: A Review](https://arxiv.org/abs/2507.10983)
> *物理信息神经网络在半导体薄膜沉积中的应用：综述*

*Tao Han, Zahra Taheri, Hyunwoong Ko* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 物理信息神经网络, 半导体薄膜沉积, 机器学习, 工艺控制, 综述

**Comment:** 11 pages, 1 figure, 3 tables, IDETC-CIE 2025

> **TL;DR:** 这篇综述论文详细回顾了物理信息神经网络（PINNs）在半导体薄膜沉积过程中的应用，分析了其优势、局限性并提出了未来的研究方向。

**AI_Comments:** 这篇综述论文具有重要意义，因为它系统地梳理了物理信息神经网络在半导体制造这一关键领域中的应用潜力。通过识别现有挑战和研究空白，并提出具体的未来研究方向，为该领域的进一步创新提供了清晰的路线图。其创新性在于强调了物理知识与机器学习结合的重要性，这对于高精度要求的工业应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 半导体制造中的薄膜沉积过程复杂且对控制精度要求高。物理信息神经网络（PINNs）作为一种创新的机器学习方法，在半导体薄膜沉积过程的控制、质量保证和预测建模方面显示出巨大潜力。本文旨在全面综述机器学习，特别是PINNs，在该领域的应用，以识别关键趋势、现有局限性和研究空白，并提出整合这些技术以提高过程性能的策略。

**Method:** 本文通过对半导体薄膜沉积过程中机器学习应用的全面综述，进行专题分析，识别关键趋势、现有局限性和研究空白。此外，还审查了最先进的物理信息神经网络（PINN）方法，讨论了将物理知识、控制定律和偏微分方程嵌入神经网络架构的策略。

**Result:** 综述识别了半导体薄膜沉积领域机器学习应用的关键趋势、现有局限性和研究空白，并提供了当前方法的优点和限制的见解。研究强调了机器学习技术在提高薄膜沉积过程的可解释性、准确性和鲁棒性方面的潜在整合。基于详细的审查，提出了结合PINNs优势的新颖研究方向，以显著推进薄膜沉积过程。

**Conclusion:** 本研究的贡献在于为未来整合物理信息机器学习框架的研究建立了清晰的路径，解决了现有方法学上的空白，并最终提高了半导体制造中的精度、可扩展性和操作效率。

> **ai_Abstract:** 本文全面综述了物理信息神经网络（PINNs）在半导体薄膜沉积过程中的应用。通过专题分析，论文识别了关键趋势、现有局限性和研究空白，并探讨了如何将物理知识嵌入神经网络以提高薄膜沉积过程的控制、质量和预测能力。研究旨在为未来整合物理信息机器学习框架提供研究方向，以提高半导体制造的精度和效率。

> **摘要翻译:** 半导体制造严重依赖薄膜沉积工艺，例如化学气相沉积和物理气相沉积。这些复杂工艺需要精确控制，以实现薄膜均匀性、适当的附着力和所需的功能。物理信息神经网络（PINNs）作为一种创新的机器学习（ML）方法，在解决半导体薄膜沉积及其他制造领域的过程控制、质量保证和预测建模相关挑战方面显示出巨大潜力。本文全面综述了针对半导体薄膜沉积工艺的机器学习应用。通过专题分析，我们识别了关键趋势、现有局限性和研究空白，提供了对当前方法优势和局限性的见解。我们的结构化分析旨在强调这些机器学习技术在增强薄膜沉积过程的可解释性、准确性和鲁棒性方面的潜在整合。此外，我们还审查了最先进的PINN方法，讨论了将物理知识、控制定律和偏微分方程嵌入专为半导体制造量身定制的高级神经网络架构的策略。基于这项详细的综述，我们提出了整合PINNs优势以显著推进薄膜沉积工艺的新颖研究方向。本研究的贡献包括为未来整合物理信息机器学习框架的研究建立清晰的路径，解决现有方法学上的空白，并最终提高半导体制造中的精度、可扩展性和操作效率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [148] [A Simple Approximate Bayesian Inference Neural Surrogate for Stochastic Petri Net Models](https://arxiv.org/abs/2507.10714)
> *一种用于随机Petri网模型的简单近似贝叶斯推理神经代理*

*Bright Kwaku Manu, Trevor Reckell, Beckett Sterner, Petar Jevtic* | **Category: cs.LG, q-bio.QM, stat.ML, 68, 92, I.6; I.2.6** | **Updated: 2025-07-14**

**Keywords:** 随机Petri网, 贝叶斯推理, 神经网络代理, 参数估计, 无似然

**Comment:** 12 pages, 10 figures, for all associated codes and files, see
  https://github.com/BrightManu-lang/SPN-param-recovery.git

> **TL;DR:** 本文提出了一种基于神经网络的代理框架，用于从嘈杂、部分观测的数据中快速准确地估计随机Petri网（SPN）的参数，解决了传统贝叶斯方法在没有显式似然时的挑战。

**AI_Comments:** 该论文提出了一种创新性的方法，将神经网络引入到随机Petri网的参数估计中，尤其是在传统贝叶斯方法面临显式似然缺失和数据部分观测等挑战的场景下。其亮点在于利用神经网络作为后验分布的近似，实现了无似然推理，并显著提高了计算效率。在存在事件丢失的情况下仍能保持较高的恢复精度，凸显了该方法的鲁棒性。这对于流行病学和系统生物学等领域中的复杂动态系统建模具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随机Petri网（SPNs）在流行病学和系统生物学等领域建模离散事件动态方面越来越受欢迎，但其参数估计仍然具有挑战性，特别是当转换率依赖于外部协变量且无法获得显式似然时。

**Method:** 引入了一种神经代理（基于神经网络的后验分布近似）框架，直接从嘈杂、部分观测的令牌轨迹中预测已知协变量相关速率函数的系数。该模型采用轻量级一维卷积残差网络，在Gillespie模拟的SPN实现上进行端到端训练，学习在事件丢失的真实条件下反演系统动态。在推理过程中，Monte Carlo dropout提供校准的不确定性边界以及点估计。

**Result:** 在合成SPN上，即使有20%的事件缺失，我们的代理也能以RMSE = 0.108的精度恢复速率函数系数，并且运行速度比传统的贝叶斯方法快得多。

**Conclusion:** 这些结果表明，数据驱动、无似然的代理可以在复杂、部分观测的离散事件系统中实现准确、鲁棒和实时的参数恢复。

> **ai_Abstract:** 本文提出了一种新颖的神经代理框架，用于解决随机Petri网（SPNs）中参数估计的挑战，尤其是在缺乏显式似然和存在外部协变量的情况下。该框架利用一个轻量级的一维卷积残差网络，通过端到端训练，从带有噪声和部分观测的令牌轨迹中直接预测协变量相关速率函数的系数。研究表明，该方法在合成SPN数据上表现出色，即使在20%事件缺失的情况下，也能以较低的均方根误差（RMSE = 0.108）准确恢复参数，并且显著优于传统贝叶斯方法的计算速度。这证明了数据驱动、无似然的代理在复杂、部分观测的离散事件系统中实现实时、准确和鲁棒的参数恢复的潜力。

> **摘要翻译:** 随机Petri网（SPNs）是建模流行病学和系统生物学等领域离散事件动态的日益流行的工具，但其参数估计通常仍然具有挑战性，特别是当转换率依赖于外部协变量且无法获得显式似然时。我们引入了一种神经代理（基于神经网络的后验分布近似）框架，可以直接从嘈杂、部分观测的令牌轨迹中预测已知协变量相关速率函数的系数。我们的模型采用轻量级一维卷积残差网络，在Gillespie模拟的SPN实现上进行端到端训练，学习在事件丢失的真实条件下反演系统动态。在推理过程中，Monte Carlo dropout提供校准的不确定性边界以及点估计。在合成SPN上，即使有20%的事件缺失，我们的代理也能以RMSE = 0.108的精度恢复速率函数系数，并且运行速度比传统的贝叶斯方法快得多。这些结果表明，数据驱动、无似然的代理可以在复杂、部分观测的离散事件系统中实现准确、鲁棒和实时的参数恢复。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [151] [Unified ODE Analysis of Smooth Q-Learning Algorithms](https://arxiv.org/abs/2404.14442)
> *平滑Q学习算法的统一ODE分析*

*Donghwan Lee* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** Q学习, 收敛性分析, ODE, 平滑Q学习, 切换系统

**Comment:** 

> **TL;DR:** 本文提出了一种更通用和统一的收敛性分析方法，改进了现有方法，可以分析Q学习及其平滑变体，并解决了现有方法在泛化性和条件限制上的问题。

**AI_Comments:** 本文的创新点在于提出了一个更通用和统一的Q学习收敛性分析框架。它克服了现有切换系统方法在条件限制和泛化性上的不足，能够同时分析标准Q学习和其平滑变体。通过采用更一般的ODE模型和简化的框架，该工作对于深化强化学习算法的理论理解具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的Q学习收敛性分析方法（如基于切换系统的方法）存在局限性，例如需要满足准单调性等限制性条件，导致难以推广到其他强化学习算法，特别是平滑Q学习变体。因此，需要一种更通用和统一的收敛性分析方法。

**Method:** 本文提出了一种更通用和统一的收敛性分析方法，该方法改进了基于切换系统的方法。它基于先前关于同步Q学习收敛性（使用p范数作为Lyapunov函数）的工作，但处理的是更一般的ODE模型，这些模型能够以更简单的框架覆盖异步Q学习及其平滑版本。

**Result:** 提出的分析方法可以对Q学习及其平滑变体进行收敛性分析，并且能够处理更一般的ODE模型，覆盖异步Q学习及其平滑版本。

**Conclusion:** 本文提出了一种改进的、更通用和统一的收敛性分析方法，能够以更简单的框架分析Q学习及其平滑变体，克服了现有方法的局限性。

> **ai_Abstract:** 本文针对Q学习算法的收敛性分析，指出现有基于切换系统的ODE方法在推广到平滑Q学习变体时面临限制。为解决此问题，论文提出了一种更通用和统一的收敛性分析方法。该方法借鉴了基于p范数作为Lyapunov函数的同步Q学习收敛性分析，但通过处理更一般的ODE模型，能以更简化的框架覆盖异步Q学习及其平滑版本。

> **摘要翻译:** 在过去的几十年中，Q学习的收敛性一直是广泛研究的焦点。最近，一种使用切换系统框架对Q学习进行渐近收敛性分析的方法被引入。这种方法应用所谓的常微分方程（ODE）方法来证明异步Q学习的收敛性，将其建模为连续时间切换系统，其中使用切换系统理论的概念来证明其渐近稳定性，而无需使用显式Lyapunov论证。然而，为了证明稳定性，底层切换系统必须满足限制性条件，例如准单调性，这使得该分析方法难以轻易推广到其他强化学习算法，例如平滑Q学习变体。在本文中，我们提出了一种更通用和统一的收敛性分析方法，该方法改进了切换系统方法，并且可以分析Q学习及其平滑变体。所提出的分析方法受到先前关于基于p范数作为Lyapunov函数的同步Q学习收敛性工作启发。然而，所提出的分析方法解决了更一般的ODE模型，这些模型能够以更简单的框架覆盖异步Q学习及其平滑版本。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [160] [Data Augmentation in Time Series Forecasting through Inverted Framework](https://arxiv.org/abs/2507.11439)
> *基于倒置框架的时间序列预测数据增强*

*Hongming Tan, Ting Chen, Ruochong Jin, Wai Kin Chan* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 数据增强, 时间序列预测, 倒置框架, iTransformer, DAIF

**Comment:** 

> **TL;DR:** 本文提出了一种名为DAIF的新型数据增强方法，专门针对iTransformer等基于倒置框架的多元时间序列预测模型，以解决其在捕获时间相互依赖性和处理非显著变量相关性时引入噪声的问题。DAIF是首个为倒置框架设计的实时数据增强方法，通过频率滤波和交叉变异修补两种策略，在多个数据集和模型上均表现出有效性。

**AI_Comments:** 本文提出了一种创新的数据增强方法DAIF，专门针对iTransformer等基于倒置框架的时间序列预测模型。其创新之处在于首次提出了为倒置框架设计的实时数据增强方案，并通过频率滤波和交叉变异修补两种具体策略解决了倒置框架在时间依赖性和噪声方面的不足。这对于提升现有流行时间序列模型的性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前流行的iTransformer模型在多元时间序列预测中表现出色，但其倒置框架存在局限性：削弱了时间相互依赖信息，并在变量相关性不显著时引入噪声。为了解决这些限制，本文提出了DAIF。

**Method:** 本文提出了一种名为DAIF的新型数据增强方法，专门用于倒置框架的时间序列预测。DAIF是首个为倒置框架设计的实时数据增强方法。该方法首先定义了倒置序列到序列框架的结构，然后提出了两种不同的DAIF策略：频率滤波（Frequency Filtering）和交叉变异修补（Cross-variation Patching）。

**Result:** 在多个数据集和倒置模型上的实验证明了我们提出的DAIF方法的有效性。

**Conclusion:** 本文提出的DAIF数据增强方法有效解决了iTransformer倒置框架在时间序列预测中存在的局限性，提高了模型的性能。

> **ai_Abstract:** iTransformer是多元时间序列预测的有效模型，但其倒置框架在处理时间相互依赖性和非显著变量相关性时存在局限性。为解决此问题，本文提出了一种名为DAIF的新型实时数据增强方法。DAIF是首个专为倒置框架设计的实时增强方案，通过频率滤波和交叉变异修补两种策略来提升性能。实验证明DAIF在多个数据集和模型上均有效。

> **摘要翻译:** 目前，iTransformer是多元时间序列（MTS）预测中最流行和有效的模型之一。得益于其倒置框架，iTransformer能够有效捕获多元相关性。然而，倒置框架仍存在一些局限性。它削弱了时间相互依赖信息，并在变量相关性不显著的情况下引入噪声。为了解决这些局限性，我们引入了一种基于倒置框架的新型数据增强方法，称为DAIF。与之前的数据增强方法不同，DAIF是第一个专门为MTS预测中倒置框架设计的实时增强方法。我们首先定义了倒置序列到序列框架的结构，然后提出了两种不同的DAIF策略：频率滤波和交叉变异修补，以解决倒置框架现有的挑战。在多个数据集和倒置模型上的实验证明了我们DAIF的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [167] [Fine-tuning Large Language Model for Automated Algorithm Design](https://arxiv.org/abs/2507.10614)
> *自动化算法设计中大型语言模型的微调*

*Fei Liu, Rui Zhang, Xi Lin, Zhichao Lu, Qingfu Zhang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-13**

**Keywords:** 大型语言模型, 算法设计, 微调, 多样性感知排序, 直接偏好优化

**Comment:** 

> **TL;DR:** 本文通过微调大型语言模型（LLM）来解决自动化算法设计中的性能和泛化问题，引入了多样性感知排序（DAR）采样策略和直接偏好优化，实验证明微调后的LLM显著优于通用模型并展现出良好的泛化能力。

**AI_Comments:** 本文的创新点在于首次系统性地探索了大型语言模型在自动化算法设计中的微调方法，并提出了具体的策略（DAR采样和直接偏好优化）。研究解决了通用LLMs在特定领域适应性不足的问题，并通过实验验证了微调的有效性和泛化能力，为LLMs在专业领域的应用开辟了新方向，具有重要的实践和理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动化算法设计方法依赖于通用型大型语言模型（LLMs），但尚不清楚是否需要专门为算法设计量身定制的LLMs，以及如何有效获取和泛化此类LLMs。

**Method:** 本文探索了对大型语言模型进行微调以适应算法设计任务。具体方法包括：引入一种多样性感知排序（DAR）采样策略，以平衡训练数据的多样性和质量；利用直接偏好优化（DPO）来高效地将LLM的输出与任务目标对齐。

**Result:** 实验在Llama-3.2-1B-Instruct和Llama-3.1-8B-Instruct模型上进行，涵盖了三种不同的算法设计任务。结果表明，微调后的LLM显著优于其通用型对应模型（对于较小的Llama-3.2-1B-Instruct），并且在可容许集问题上能与更大的Llama-3.1-8B-Instruct模型匹敌。此外，微调后的LLM在特定算法设计任务上的性能提升也能泛化到设置不同的相关任务上。

**Conclusion:** 研究结果强调了在算法设计中对大型语言模型进行任务特定适应（微调）的价值，并为未来的研究开辟了新途径。

> **ai_Abstract:** 本文探讨了通过微调大型语言模型（LLMs）来提升自动化算法设计性能的问题。针对现有方法依赖通用LLMs的局限性，作者提出了一种多样性感知排序（DAR）采样策略和直接偏好优化（DPO）方法，以有效训练和对齐LLMs。实验结果表明，与通用LLMs相比，微调后的LLMs在算法设计任务上表现出显著的性能提升，并且具有良好的泛化能力，强调了LLMs任务特定适应的重要性。

> **摘要翻译:** 大型语言模型（LLMs）在自动化算法设计中的集成已显示出巨大的潜力。一种普遍的方法是将LLMs嵌入到搜索例程中，以迭代地生成和完善候选算法。然而，大多数现有方法依赖于针对通用编码任务训练的现成LLMs，留下了一个关键问题：我们是否需要专门为算法设计量身定制的LLMs？如果是，如何有效地获取此类LLMs以及它们在不同算法设计任务中的泛化能力如何？在本文中，我们通过探索LLMs在算法设计中的微调，迈出了回答这些问题的第一步。我们引入了一种基于多样性感知排序（DAR）的采样策略来平衡训练数据的多样性和质量，然后利用直接偏好优化来有效地将LLM输出与任务目标对齐。我们的实验在Llama-3.2-1B-Instruct和Llama-3.1-8B-Instruct上进行，涵盖了三种不同的算法设计任务。结果表明，微调后的LLMs可以显著优于其现成对应模型（对于较小的Llama-3.2-1B-Instruct），并在可容许集问题上与较大的Llama-3.1-8B-Instruct模型匹敌。此外，我们观察到了有前景的泛化能力：在特定算法设计任务上微调的LLMs也改善了在设置不同的相关任务上的性能。这些发现突出了LLMs在算法设计中进行任务特定适应的价值，并为未来的研究开辟了新途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [169] [StellarF: A Lora-Adapter Integrated Large Model Framework for Stellar Flare Forecasting with Historical & Statistical Data](https://arxiv.org/abs/2507.10986)
> *StellarF: 一种集成LoRA适配器的大模型框架，用于基于历史和统计数据预测恒星耀斑*

*Tianyu Su, Zhiqiang Zou, Ali Luo, Xiao Kong, Qingyu Lu, Min Li* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 恒星耀斑预测, 大模型, LoRA, 适配器, 天体物理学

**Comment:** 

> **TL;DR:** StellarF是一个结合LoRA和适配器的大模型，利用历史和统计数据，实现了恒星耀斑预测的SOTA性能。

**AI_Comments:** 该论文的创新点在于将LoRA和Adapter等大模型技术引入到恒星耀斑预测这一特定领域，并通过结合历史和统计数据模块来解决数据稀疏性问题，实现了参数高效学习和SOTA性能。这为天体物理学研究提供了一个新颖且有效的大模型应用范式。

<details>
  <summary>Details</summary>

**Motivation:** 恒星耀斑预测是天文学前沿研究，但受限于耀斑事件记录稀疏和缺乏领域特定的大规模预测模型。

**Method:** 本文引入StellarF，一个利用低秩（LoRA）和适配器技术进行参数高效学习的新型大模型。StellarF核心集成了耀斑统计信息模块和历史耀斑记录模块，能够从观测数据中识别多尺度模式。

**Result:** 在自建数据集（来自开普勒和TESS光变曲线）上的广泛实验表明，StellarF与现有方法相比，取得了最先进的性能。

**Conclusion:** 提出的预测范式为推进天体物理研究和交叉学科应用建立了新的方法框架。

> **ai_Abstract:** 本文提出了StellarF，一个结合LoRA和适配器技术的大模型框架，用于解决恒星耀斑预测中数据稀疏和缺乏领域特定大模型的问题。StellarF通过整合历史和统计数据模块，实现了从观测数据中识别多尺度模式。实验证明，StellarF在自建数据集上表现出超越现有方法的SOTA性能，并为天体物理学研究提供了新的方法论。

> **摘要翻译:** 恒星耀斑预测是天文学中一个关键的研究前沿，它能为恒星活动提供深刻的见解。然而，该领域受到耀斑事件记录稀疏和缺乏领域特定大规模预测模型的限制。为了解决这些挑战，本研究引入了StellarF（恒星耀斑预测），这是一种新颖的大模型，它利用低秩（LoRA）和适配器技术进行恒星耀斑预测的参数高效学习。StellarF的核心是将耀斑统计信息模块与历史耀斑记录模块相结合，从而能够从观测数据中识别多尺度模式。在我们自建数据集（源自开普勒和TESS光变曲线）上进行的广泛实验表明，StellarF与现有方法相比，取得了最先进的性能。所提出的预测范式为推进天体物理研究和跨学科应用建立了新的方法框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [181] [SimAD: A Simple Dissimilarity-based Approach for Time Series Anomaly Detection](https://arxiv.org/abs/2405.11238)
> *SimAD：一种简单的基于差异的时间序列异常检测方法*

*Zhijie Zhong, Zhiwen Yu, Xing Xi, Yue Xu, Wenming Cao, Yiyuan Yang, Kaixiang Yang, Jane You* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 时间序列异常检测, 基于差异, 对比学习, 评估指标, SimAD

**Comment:** 24 pages, 12 figures,11 tables

> **TL;DR:** SimAD是一种简单、基于差异的时间序列异常检测方法，通过引入补丁式特征提取器、对比融合模块和改进的评估指标，解决了现有方法在时间上下文、正常模式表示和评估指标方面的局限性。实验证明其性能优于现有SOTA方法。

**AI_Comments:** SimAD的创新之处在于其简单而有效的基于差异的方法，结合了补丁式特征提取器和对比学习模块，有效解决了时间序列异常检测中的关键挑战。此外，引入新的评估指标UAff和NAff，提升了异常检测结果的评估准确性和语义清晰度，具有重要的实际意义。其在多个数据集上显著优于SOTA方法的表现，证明了其强大的竞争力和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于重建的深度学习方法很普遍，但时间序列异常检测仍然是一个巨大的挑战。现有方法常面临有限的时间上下文、正常模式表示不足以及有缺陷的评估指标等问题，这些都阻碍了它们在检测异常行为方面的有效性。

**Method:** SimAD首先采用基于补丁的特征提取器，能够处理扩展的时间窗口，并使用EmbedPatch编码器充分整合正常行为模式。其次，设计了一个创新的ContrastFusion模块，通过突出正常和异常数据之间的分布差异来增强异常检测的鲁棒性。第三，引入了两个鲁棒的增强评估指标：无偏关联度（UAff）和归一化关联度（NAff），旨在通过提供更好的区分度和语义清晰度来克服现有指标的局限性。

**Result:** 在七个不同的时间序列数据集上进行的实验清楚地表明，与最先进的方法相比，SimAD表现出卓越的性能，在六个多变量数据集上，F1分数相对提高了19.85%，Aff-F1提高了4.44%，NAff-F1提高了77.79%，AUC提高了9.69%。

**Conclusion:** SimAD是一种有效的时间序列异常检测方法，通过其新颖的架构和改进的评估指标，成功克服了现有方法的局限性，并在多个数据集上展现出优越的性能，证明了其可靠性和先进性。

> **ai_Abstract:** SimAD是一种新颖的基于差异的时间序列异常检测方法，旨在克服现有方法在时间上下文、正常模式表示和评估指标方面的局限性。该方法包含一个处理长时序窗口的补丁式特征提取器、一个增强鲁棒性的ContrastFusion模块，并引入了无偏关联度（UAff）和归一化关联度（NAff）两个新的评估指标。实验结果表明，SimAD在多个时间序列数据集上均优于现有最先进的方法。

> **摘要翻译:** 尽管基于重建的深度学习方法很普遍，但时间序列异常检测仍然是一个巨大的挑战。现有方法常面临有限的时间上下文、正常模式表示不足以及有缺陷的评估指标等问题，所有这些都阻碍了它们在检测异常行为方面的有效性。为了解决这些问题，我们引入了一种简单基于差异的时间序列异常检测方法，简称SimAD。具体来说，SimAD首先包含一个基于补丁的特征提取器，能够处理扩展的时间窗口，并采用EmbedPatch编码器充分整合正常行为模式。其次，我们在SimAD中设计了一个创新的ContrastFusion模块，通过突出正常和异常数据之间的分布差异来增强异常检测的鲁棒性。第三，我们引入了两个鲁棒的增强评估指标，无偏关联度（UAff）和归一化关联度（NAff），旨在通过提供更好的区分度和语义清晰度来克服现有指标的局限性。这两个指标的可靠性已通过理论和实验分析得到证实。在七个不同的时间序列数据集上进行的实验清楚地表明，与最先进的方法相比，SimAD表现出卓越的性能，在六个多变量数据集上，F1分数相对提高了19.85%，Aff-F1提高了4.44%，NAff-F1提高了77.79%，AUC提高了9.69%。代码和预训练模型可在https://github.com/EmorZz1G/SimAD 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [183] [Distributionally Robust Optimization with Adversarial Data Contamination](https://arxiv.org/abs/2507.10718)
> *分布鲁棒优化与对抗性数据污染*

*Shuyao Li, Ilias Diakonikolas, Jelena Diakonikolas* | **Category: cs.LG, cs.DS, math.OC** | **Updated: 2025-07-14**

**Keywords:** 分布鲁棒优化, 数据污染, 对抗性学习, Wasserstein距离, 鲁棒统计

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的方法，在训练数据被对抗性污染的情况下，同时解决分布鲁棒优化和数据污染问题，并提供理论保证。

**AI_Comments:** 该论文的创新点在于首次将对抗性数据污染的鲁棒性与分布偏移的鲁棒性在一个统一的框架下进行处理，并提供了严格的理论保证和高效的计算方法。这对于在现实世界中数据质量不确定且存在分布变化的场景下的决策具有重要意义。其理论结果（$O(\sqrt{\epsilon})$的估计误差）表明了其在面对数据污染时的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 分布鲁棒优化 (DRO) 在分布不确定性下进行决策，但其有效性会受到训练数据中异常值的影响。

**Method:** 本文引入了一个新的建模框架，将训练数据污染的鲁棒性与分布偏移的鲁棒性相结合。针对广义线性模型，优化Wasserstein-1 DRO目标，其中训练数据有$\epsilon$比例被对抗性污染。提出了一种受鲁棒统计学启发的高效算法来解决由此产生的优化问题。

**Result:** 在有界协方差假设下，使用受污染数据，该方法对真实DRO目标值实现了$O(\sqrt{\epsilon})$的估计误差。

**Conclusion:** 本工作首次为数据污染和分布偏移的双重挑战下的学习建立了严格的保证，并支持高效计算。

> **ai_Abstract:** 本文针对分布鲁棒优化（DRO）在训练数据存在异常值时效率受损的问题，提出了一种新颖的建模框架和高效算法。该方法将对抗性数据污染的鲁棒性与分布偏移的鲁棒性相结合，特别针对广义线性模型和Wasserstein-1 DRO目标，其中训练数据有部分被对抗性污染。研究证明，在有界协方差假设下，该方法能达到$O(\sqrt{\epsilon})$的估计误差，首次为同时处理数据污染和分布偏移的鲁棒学习提供了严格的理论和计算保证。

> **摘要翻译:** 分布鲁棒优化 (DRO) 提供了一个在分布不确定性下进行决策的框架，但其有效性可能会受到训练数据中异常值的影响。本文引入了一种原则性方法，以同时解决这两个挑战。我们专注于优化具有凸Lipschitz损失函数的广义线性模型的Wasserstein-1 DRO目标，其中训练数据的$\epsilon$比例被对抗性污染。我们的主要贡献在于一个新颖的建模框架，它将对抗训练数据污染的鲁棒性与对抗分布偏移的鲁棒性相结合，同时提出了一种受鲁棒统计学启发的高效算法来解决由此产生的优化问题。我们证明了在有界协方差假设下，使用受污染数据，我们的方法对真实DRO目标值实现了$O(\sqrt{\epsilon})$的估计误差。这项工作首次为在数据污染和分布偏移的双重挑战下进行学习建立了严格的保证，并支持高效计算。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [185] [A parametric activation function based on Wendland RBF](https://arxiv.org/abs/2507.11493)
> *基于Wendland RBF的参数化激活函数*

*Majid Darehmiraki* | **Category: cs.LG, cs.NE, 68T07** | **Updated: 2025-06-28**

**Keywords:** Wendland RBF, 激活函数, 深度学习, 径向基函数, 神经网络

**Comment:** 11 pages, 2 figures

> **TL;DR:** 本文提出了一种基于Wendland径向基函数（RBF）的新型参数化激活函数，用于深度神经网络，旨在解决传统激活函数的局限性。实验证明其在回归任务中表现出优越的准确性，并能提高泛化能力。

**AI_Comments:** 这项研究的创新之处在于将经典的Wendland径向基函数引入并改造为深度神经网络的激活函数，有效解决了传统激活函数的一些局限性，如梯度传播和局部性问题。其在回归任务中的优越表现和提高泛化能力潜力，为深度学习模型的性能提升提供了新的方向。该工作成功地将近似理论与现代深度学习相结合，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的激活函数（如ReLU、sigmoid和tanh）存在局限性，本研究旨在通过引入基于Wendland RBFs的新型参数化激活函数来解决这些问题。

**Method:** 本文提出了一种基于Wendland径向基函数（RBFs）的新型参数化激活函数，用于深度神经网络。该函数结合了标准Wendland分量与线性和指数项，提供可调的局部性、改进的梯度传播和增强的训练稳定性。通过理论分析其数学特性，并通过在合成任务（如正弦波近似）和基准数据集（MNIST、Fashion-MNIST）上的实证实验进行验证。

**Result:** 实验结果表明，基于Wendland的激活函数在某些场景下，特别是在回归任务中，实现了卓越的准确性，同时保持了计算效率。

**Conclusion:** 本研究将经典的RBF理论与现代深度学习相结合，表明Wendland激活函数可以通过局部化、平滑的变换来缓解过拟合并提高泛化能力。

> **ai_Abstract:** 本文提出了一种基于Wendland径向基函数（RBFs）的新型参数化激活函数，旨在克服传统激活函数的局限性。该函数通过结合线性和指数项，实现了可调的局部性、优化的梯度传播和训练稳定性。理论分析证实了其良好的数学特性，并通过在回归和分类任务上的实验，证明了该函数在特定场景下，尤其是在回归任务中，能提供更高的准确性和计算效率。研究强调了Wendland激活函数在缓解过拟合和提高泛化能力方面的潜力，为RBF理论与深度学习的结合提供了新的视角。

> **摘要翻译:** 本文介绍了一种用于深度神经网络的基于Wendland径向基函数（RBFs）的新型参数化激活函数。Wendland RBFs以其在近似理论中的紧支撑、平滑性和正定性而闻名，本文对其进行了调整，以解决ReLU、sigmoid和tanh等传统激活函数的局限性。所提出的增强型Wendland激活函数结合了标准的Wendland分量与线性和指数项，提供了可调的局部性、改进的梯度传播和增强的训练稳定性。理论分析突出了其数学特性，包括平滑性和适应性，而对合成任务（例如，正弦波近似）和基准数据集（MNIST、Fashion-MNIST）的实证实验证明了其具有竞争力的性能。结果表明，基于Wendland的激活函数在某些场景下，特别是在回归任务中，实现了卓越的准确性，同时保持了计算效率。这项研究将经典的RBF理论与现代深度学习相结合，表明Wendland激活函数可以通过局部化、平滑的变换来缓解过拟合并提高泛化能力。未来的方向包括混合架构和领域特定适应。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [195] [D3FL: Data Distribution and Detrending for Robust Federated Learning in Non-linear Time-series Data](https://arxiv.org/abs/2507.11471)
> *D3FL：非线性时间序列数据中稳健联邦学习的数据分布与去趋势研究*

*Harsha Varun Marisetty, Manik Gupta, Yogesh Simmhan* | **Category: cs.LG, cs.DC** | **Updated: 2025-07-15**

**Keywords:** 联邦学习, 非线性时间序列, 数据分布, 去趋势, 预测

**Comment:** Preprint of paper to appear in the proceedings of IEEE INTERNATIONAL
  CONFERENCE ON EDGE COMPUTING & COMMUNICATIONS EDGE 2025

> **TL;DR:** 本文研究了非线性时间序列数据分布和去趋势技术对联邦学习性能的影响，发现联邦学习在非线性数据分布下表现较差，但适当的去趋势技术可以提升其性能。

**AI_Comments:** 本文针对联邦学习在处理非线性时间序列数据时面临的挑战进行了深入探讨，特别是关注了数据分布特性和去趋势技术的影响。其创新点在于系统性地研究了不同非线性数据分布对联邦学习性能的具体影响，并验证了去趋势作为一种有效策略的重要性。这对于推动联邦学习在物联网等实际应用中处理复杂时间序列数据具有重要意义。局限性可能在于其对特定模型（LSTM）的依赖性以及合成数据集的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 物联网设备收集的非线性、非平稳时间序列数据（如智能家居能耗、环境监测数据）在联邦学习环境中进行预测时，其显著的趋势和季节模式变化会严重影响预测精度。传统的数据集中化分析方法存在延迟和通信成本高的问题，而联邦学习作为替代方案，需要解决非线性数据分布对模型性能的影响。

**Method:** 本文通过生成合成非线性时间序列数据集，并使用LSTM模型进行集中式和联邦学习训练。同时，还在真实世界的非线性时间序列数据集上评估了去趋势技术的影响。研究了广义极值分布和对数正态分布等非线性数据分布对联邦学习性能的影响，并分析了不同去趋势技术对联邦学习预测模型性能的影响。

**Result:** 实验结果表明：1) 在处理非线性数据分布时，联邦学习的性能不如集中式方法。2) 采用适当的去趋势技术可以改善联邦学习的性能，降低不同数据分布下的损失。

**Conclusion:** 在联邦学习处理非线性时间序列数据时，数据分布特性会影响模型性能，但通过应用合适的去趋势技术可以有效提升联邦学习的预测准确性。

> **ai_Abstract:** 本文研究了在联邦学习（FL）框架下处理物联网设备产生的非线性、非平稳时间序列数据所面临的挑战。针对传统集中式数据处理的局限性，文章探讨了不同非线性数据分布（如广义极值和对数正态分布）对FL性能的影响，并分析了去趋势技术在提升FL预测精度方面的作用。通过合成和真实世界数据集上的实验，研究发现FL在非线性数据分布下表现逊于集中式方法，但采用合适的去趋势技术能显著提升FL的性能，降低预测损失。

> **摘要翻译:** 随着计算和通信技术的进步，物联网（IoT）取得了显著发展。物联网设备通常从各种传感器收集数据，如温度、湿度和电能表数据。这些数据大部分是时间性质的。传统上，物联网设备的数据是集中分析的，但这种方法会引入延迟和增加通信成本。联邦学习（FL）已成为一种有效的替代方案，它允许在分布式设备上进行模型训练，而无需集中数据。在许多应用中，例如智能家居能源和环境监测，物联网设备在不同位置收集的数据可能表现出趋势和季节模式的显著变化。准确预测此类非平稳、非线性时间序列数据对于能源消耗估算和天气预报等应用至关重要。然而，这些数据变化会严重影响预测精度。本文的主要贡献包括：(1) 调查非线性、非平稳时间序列数据分布（如广义极值（gen-extreme）和对数正态分布）如何影响联邦学习性能。(2) 分析不同去趋势技术对联邦学习设置中非线性时间序列数据预测模型性能的影响。我们使用非线性数据分布生成了几个合成时间序列数据集，并使用基于LSTM的预测模型进行集中式和联邦学习训练。此外，我们还评估了去趋势对具有非线性时间序列数据分布的真实世界数据集的影响。我们的实验结果表明：(1) 在处理非线性数据分布时，联邦学习的性能不如集中式方法。(2) 使用适当的去趋势技术可以提高联邦学习性能，减少不同数据分布下的损失。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [199] [Feature-Based vs. GAN-Based Learning from Demonstrations: When and Why](https://arxiv.org/abs/2507.05906)
> *基于特征与基于GAN的示范学习：何时以及为何*

*Chenhao Li, Marco Hutter, Andreas Krause* | **Category: cs.LG, cs.AI, cs.GR, cs.RO** | **Updated: 2025-07-15**

**Keywords:** 示范学习, 基于特征, GAN, 奖励函数, 运动表示

**Comment:** 

> **TL;DR:** 本综述比较了基于特征和基于GAN的示范学习方法，分析了它们的优缺点和适用场景，并提出选择方法应基于任务特定优先级的观点。

**AI_Comments:** 这篇综述的创新之处在于其对基于特征和基于GAN的示范学习方法进行了深入的比较分析，并超越了简单的优劣判断，提出了一个基于任务优先级进行方法选择的实用框架。它强调了结构化运动表示的重要性，并为该领域未来的研究和应用提供了指导。其价值在于为研究人员和实践者在面对具体示范学习任务时，提供了更为细致和原则性的决策依据。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是提供一个关于基于特征和基于GAN的示范学习方法的比较分析，重点关注奖励函数结构及其对策略学习的影响，以帮助决策者选择合适的方法。

**Method:** 本文通过对基于特征和基于GAN的示范学习方法进行比较分析，探讨了它们的优缺点、奖励函数结构、对策略学习的影响、泛化能力、训练稳定性以及对结构化运动表示的需求。

**Result:** 结果表明，基于特征的方法提供密集、可解释的奖励，擅长高保真运动模仿，但泛化能力有限；基于GAN的方法使用隐式、分布式的监督，具有可伸缩性和适应性，但存在训练不稳定和奖励信号粗糙的问题。两种范式都强调结构化运动表示的重要性。

**Conclusion:** 结论是基于特征和基于GAN的方法之间的选择应由任务特定的优先级（如保真度、多样性、可解释性和适应性）指导，而不是一方优于另一方。文章提出了一个用于方法选择的原则性决策框架。

> **ai_Abstract:** 本综述比较分析了基于特征和基于GAN的示范学习方法，探讨了它们在奖励函数结构、泛化能力和训练稳定性方面的优缺点。基于特征的方法擅长高保真模仿但泛化受限，而基于GAN的方法具有可伸缩性但存在训练不稳定问题。文章指出，两种方法都受益于结构化运动表示，并强调在选择方法时应根据任务特定的优先级（如保真度、多样性、可解释性和适应性）做出权衡，而非简单地偏向某一方，并提出了一个决策框架。

> **摘要翻译:** 这篇综述对基于特征和基于GAN的示范学习方法进行了比较分析，重点关注奖励函数的结构及其对策略学习的影响。基于特征的方法提供密集、可解释的奖励，擅长高保真运动模仿，但通常需要复杂的参考表示，并且在非结构化设置中难以泛化。相比之下，基于GAN的方法使用隐式、分布式的监督，具有可伸缩性和适应性，但容易出现训练不稳定和粗糙的奖励信号。这两种范式的最新进展都趋向于结构化运动表示的重要性，这使得更平滑的过渡、可控的合成和改进的任务集成成为可能。我们认为，基于特征和基于GAN方法之间的二分法越来越微妙：选择不应是某一方主导另一方，而应由任务特定的优先级（如保真度、多样性、可解释性和适应性）来指导。这项工作概述了方法选择背后的算法权衡和设计考虑，为示范学习中的原则性决策提供了一个框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [209] [High-Throughput Distributed Reinforcement Learning via Adaptive Policy Synchronization](https://arxiv.org/abs/2507.10990)
> *通过自适应策略同步实现高吞吐量分布式强化学习*

*Rodney Lafuente-Mercado* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 分布式强化学习, ClusterEnv, 自适应策略同步, AAPS, 解耦

**Comment:** 

> **TL;DR:** 本文提出了ClusterEnv，一个轻量级的分布式RL环境接口，以及DETACH模式用于解耦模拟和训练。为解决策略陈旧问题，引入了自适应策略同步（AAPS），实验证明其在减少同步开销的同时保持了高性能。

**AI_Comments:** 本文提出了ClusterEnv框架和DETACH模式，有效地解耦了RL的模拟和训练过程，这提高了系统的模块化和可重用性。AAPS机制通过自适应同步策略，在保证性能的同时显著减少了同步开销，是解决分布式RL中策略陈旧问题的创新方法。该研究对于实现高效、可扩展的分布式强化学习具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有强化学习（RL）框架在扩展工作负载时，将模拟、学习逻辑和编排紧密耦合，形成单一系统，这限制了模块化和可重用性。此外，在分布式执行中，策略陈旧是一个需要解决的问题。

**Method:** 本文提出了ClusterEnv，一个轻量级、与学习器无关的分布式环境执行接口，它模仿了Gymnasium API。ClusterEnv引入了DETACH模式，通过将reset()和step()操作卸载到远程工作器来解耦模拟和训练，同时保持学习集中化。为解决分布式执行中的策略陈旧问题，本文提出了自适应Actor策略同步（AAPS），这是一种由分歧触发的更新机制，可在不牺牲性能的情况下减少同步开销。

**Result:** 在离散控制任务上的实验表明，AAPS在显著减少权重更新次数的同时，实现了高样本效率。

**Conclusion:** ClusterEnv能够干净地集成到现有的RL管道中，支持在线策略和离线策略方法，并且只需要最少的代码更改。自适应Actor策略同步（AAPS）有效解决了分布式强化学习中的策略陈旧问题，并在减少同步开销的同时保持了高样本效率。

> **ai_Abstract:** 本文介绍了ClusterEnv，一个轻量级的分布式强化学习环境接口，旨在解决现有框架模块化和可重用性不足的问题。ClusterEnv通过DETACH模式将模拟与训练解耦，并提出了自适应Actor策略同步（AAPS）机制来应对分布式执行中的策略陈旧问题。AAPS是一种基于分歧触发的更新方法，旨在减少同步开销同时保持性能。实验结果表明，AAPS在离散控制任务上实现了高样本效率和更少的权重更新，证明了其在分布式RL中的有效性和集成性。

> **摘要翻译:** 扩展强化学习（RL）工作负载通常需要在计算集群中分布式地进行环境模拟。现有的框架将模拟、学习逻辑和编排纠缠在一起，形成单一系统，这限制了模块化和可重用性。我们提出了ClusterEnv，一个轻量级、与学习器无关的分布式环境执行接口，它模仿了Gymnasium API。ClusterEnv引入了DETACH模式，通过将reset()和step()操作卸载到远程工作器来解耦模拟和训练，同时保持学习集中化。为解决分布式执行中的策略陈旧问题，我们提出了自适应Actor策略同步（AAPS），这是一种由分歧触发的更新机制，可在不牺牲性能的情况下减少同步开销。ClusterEnv能够干净地集成到现有的RL管道中，支持在线策略和离线策略方法，并且只需要最少的代码更改。在离散控制任务上的实验表明，AAPS在显著减少权重更新次数的同时，实现了高样本效率。源代码可在https://github.com/rodlaf/ClusterEnv获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [212] [Scalpel vs. Hammer: GRPO Amplifies Existing Capabilities, SFT Replaces Them](https://arxiv.org/abs/2507.10616)
> *手术刀与锤子：GRPO增强现有能力，SFT取代现有能力*

*Neel Rajani, Aryo Pradipta Gema, Seraphina Goldfarb-Tarrant, Ivan Titov* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-13**

**Keywords:** 强化学习, 监督微调, 大型语言模型, 训练动态, 参数分析

**Comment:** 

> **TL;DR:** 本文比较了LLM推理训练中RL和SFT的动态，发现RL小幅增强现有能力但略微降低泛化性，而SFT则大幅改变模型参数并可能取代原有技能，导致更明显的域外性能下降。

**AI_Comments:** 本文通过比较强化学习（RL）和监督微调（SFT）这两种流行的LLM后期训练方法，深入探讨了它们的潜在训练动态，尤其是在参数层面的影响，这对于理解LLM行为至关重要。标题中的“手术刀与锤子”的比喻形象地揭示了这两种方法对模型修改方式的本质区别。对参数变化的分析以及SFT影响中间层MLP导致域外性能下降的假设是重要的贡献。尽管冻结模型部分参数的实验结果尚无定论，但这恰恰突显了训练过程的复杂性，并为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）通过数学和代码数据集进行推理训练时，强化学习（RL）和监督微调（SFT）这两种流行方法的训练动态尚不明确。本文旨在比较分析这两种方法，以理解RL为何能增强现有能力而SFT为何会取代它们。

**Method:** 作者在相同的数学问题、相同的模型和相似的超参数下，对强化学习（RL）和监督微调（SFT）进行了比较分析。他们还分析了不同检查点下模型参数的变化，并尝试通过冻结模型部分参数来缓解域外性能下降。

**Result:** RL在数学领域内取得了微小增益，但在MMLU等知识密集型基准测试上略有退化。SFT的这些趋势则更为明显。两种算法都主要修改了查询和键权重，而SFT的更新幅度更大，并更多地影响了中间层的MLP。冻结模型部分参数的尝试结果不确定，在GPQA:Diamond上有效但在其他基准上导致性能下降。

**Conclusion:** 他们的观察初步揭示了RL为何能增强现有能力，而SFT为何会用新技能取代旧技能。

> **ai_Abstract:** 本文比较分析了强化学习（RL）和监督微调（SFT）在大型语言模型数学推理任务训练中的动态。研究发现，RL在域内任务上带来微小增益，在知识密集型任务上略有退化；而SFT则表现出更明显的趋势，常导致域外性能更严重的下降。参数分析表明，SFT的更新幅度更大，并更多地影响中间层MLPs，这被推测是其域外性能下降的原因。尽管尝试通过冻结模型部分参数来缓解此问题的结果不确定，但本研究为理解RL增强现有能力而SFT取代现有能力的机制提供了初步线索。

> **摘要翻译:** 通过数学和代码数据集训练大型语言模型（LLMs）以进行推理已成为LLM后期训练的一个主要新焦点。强化学习（RL）和监督微调（SFT）是两种特别流行的方法，但它们的训练动态却知之甚少。我们在相同的数学问题、相同的模型和相似的超参数下，对RL和SFT进行了比较分析。我们发现RL在数学领域内取得了微小增益，并在MMLU等知识密集型基准测试上略有退化，而这两种趋势在SFT中更为明显。我们还分析了不同检查点下模型参数的变化，观察到两种算法都主要修改了查询和键权重。同时，SFT表现出更大的更新幅度，并且更多地影响了中间层的MLP，这使我们推测这可能是导致域外性能下降的原因。因此，我们研究了在训练期间冻结模型部分参数是否可以缓解知识密集型基准测试上性能下降的问题。然而，我们的结果尚无定论，在GPQA:Diamond上取得了益处，但在其他基准测试上却出现了退化。综合来看，我们的观察初步揭示了RL为何能增强现有能力，而SFT为何会用新技能取代旧技能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [216] [TorchCP: A Python Library for Conformal Prediction](https://arxiv.org/abs/2402.12683)
> *TorchCP：一个用于共形预测的Python库*

*Jianguo Huang, Jianqing Song, Xuanning Zhou, Bingyi Jing, Hongxin Wei* | **Category: cs.LG, cs.CV, math.ST, stat.TH** | **Updated: 2025-07-15**

**Keywords:** 共形预测, 深度学习, PyTorch, 不确定性估计, TorchCP

**Comment:** 

> **TL;DR:** TorchCP是一个PyTorch原生的库，旨在将最先进的共形预测算法集成到深度学习任务中，以解决预测不确定性量化问题。

**AI_Comments:** TorchCP的创新之处在于它提供了一个统一且易于使用的PyTorch原生库，将最先进的共形预测算法集成到广泛的深度学习任务中。其模块化设计和GPU加速能力大大降低了在实际应用中实现可靠不确定性估计的门槛。该库的广泛采用和全面的测试覆盖率表明了其重要性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习中预测不确定性量化是一个挑战，尽管深度学习架构和数据集取得了进展，但可靠的不确定性估计仍然难以捉摸，这使得共形预测（CP）变得越来越重要。

**Method:** 本文介绍了TorchCP，这是一个PyTorch原生的库，旨在将最先进的共形预测算法集成到分类、回归、图神经网络和大型语言模型等深度学习任务中。

**Result:** TorchCP提供了一套全面的高级方法、模块化设计以便于定制，以及完整的GPU加速可扩展性。它已获得广泛采用，PyPi下载量超过12,582次，并由约16,132行代码、564个单元测试（达到100%覆盖率）和全面的文档支持。

**Conclusion:** 通过连接统计学和计算机科学，TorchCP使研究人员和实践者能够在各种深度学习应用中推进共形预测。

> **ai_Abstract:** TorchCP是一个PyTorch原生的Python库，旨在将先进的共形预测算法应用于深度学习任务，以解决预测不确定性量化问题。该库提供全面的方法、模块化设计和GPU加速，支持分类、回归、图神经网络和大型语言模型等应用。TorchCP已获得广泛采用，并配有详尽的文档和测试，旨在弥合统计学和计算机科学之间的鸿沟，推动共形预测在深度学习领域的应用。

> **摘要翻译:** 共形预测（CP）是一个鲁棒的统计框架，它能生成具有保证覆盖概率的预测区间或集合，解决了深度学习中量化预测不确定性的挑战。尽管深度学习架构和数据集取得了进展，但可靠的不确定性估计仍然难以捉摸，这使得CP变得越来越重要。本文介绍了TorchCP，一个PyTorch原生的库，旨在将最先进的CP算法集成到深度学习任务中，包括分类、回归、图神经网络和大型语言模型。TorchCP提供了一套全面的高级方法、模块化设计以便于定制，以及完整的GPU加速可扩展性。TorchCP在LGPL-3.0许可下发布，已获得广泛采用，PyPi下载量超过12,582次。它由大约16,132行代码、564个单元测试（达到100%覆盖率）和全面的文档支持。通过连接统计学和计算机科学，TorchCP使研究人员和实践者能够在各种深度学习应用中推进共形预测。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [223] [Ground-Compose-Reinforce: Tasking Reinforcement Learning Agents through Formal Language](https://arxiv.org/abs/2507.10741)
> *Ground-Compose-Reinforce：通过形式语言指导强化学习智能体*

*Andrew C. Li, Toryn Q. Klassen, Andrew Wang, Parand A. Alamdari, Sheila A. McIlraith* | **Category: cs.LG, cs.AI, I.2.6; I.2.4** | **Updated: 2025-07-14**

**Keywords:** Ground-Compose-Reinforce, 强化学习, 形式语言, 神经符号, 语言接地

**Comment:** 

> **TL;DR:** 本文提出了Ground-Compose-Reinforce，一个神经符号框架，通过形式语言指导强化学习智能体，实现数据高效的接地和泛化，无需手动设计。

**AI_Comments:** 这篇论文引入了一种新颖的神经符号方法Ground-Compose-Reinforce，解决了具身AI中的一个重要挑战：弥合人类语言指令与RL智能体行为之间的鸿沟。其核心创新在于将数据驱动学习与形式语言语义相结合，实现了数据高效的接地和强大的泛化能力。避免手动设计奖励函数和符号检测器是一个显著优势，使得系统更具可扩展性，并减少了对专家知识的依赖。在不同领域的实证验证突显了其在实际应用中的效用以及在数据稀缺场景下优于纯粹的端到端方法。

<details>
  <summary>Details</summary>

**Motivation:** 在构建能够通过语言与人类交互的具身智能体时，将语言与复杂感知和动作相结合是一个关键挑战，这通常需要手动设计或大量数据集。

**Method:** 本文提出了“Ground-Compose-Reinforce”，一个神经符号框架。该框架从数据中接地形式语言，并通过这种语言直接指导强化学习智能体来引发行为。它利用数据驱动学习避免了奖励函数或符号检测器等领域特定元素的手动设计，并通过组合形式语言语义实现数据高效的接地和对任意语言组合的泛化。

**Result:** 在基于图像的网格世界和MuJoCo机器人领域的实验表明，我们的方法在数据有限的情况下能够可靠地将形式语言指令映射到行为，而端到端、数据驱动的方法则会失败。

**Conclusion:** Ground-Compose-Reinforce框架成功地接地了形式语言并指导了强化学习智能体，展示了数据效率和泛化能力，优于端到端的数据驱动方法，尤其是在数据有限的情况下。

> **ai_Abstract:** 本论文提出了Ground-Compose-Reinforce，一个新颖的神经符号框架，旨在解决在复杂感知和动作中接地语言以指导具身智能体的挑战。该框架通过数据驱动学习实现形式语言的接地，并允许通过形式语言直接指导强化学习智能体，从而避免了手动设计领域特定元素（如奖励函数）。借助于组合形式语言语义，Ground-Compose-Reinforce实现了数据高效的接地和对任意语言组合的泛化。实验结果表明，该方法在有限数据下能可靠地将形式语言指令转换为智能体行为，优于传统的端到端数据驱动方法。

> **摘要翻译:** 将语言与复杂感知（例如像素）和动作相结合是构建能够通过语言与人类交互的具身智能体时的关键挑战。在过去的工作中，这通常通过手动设计语言接地或通过整理大量将语言与环境元素相关联的数据集来解决。我们提出了Ground-Compose-Reinforce，一个神经符号框架，用于从数据中接地形式语言，并通过这种语言直接指导强化学习智能体来引发行为。通过数据驱动学习，我们的框架避免了领域特定元素（如奖励函数或符号检测器）的手动设计。通过组合形式语言语义，我们的框架实现了数据高效的接地和对任意语言组合的泛化。在基于图像的网格世界和MuJoCo机器人领域的实验表明，我们的方法在数据有限的情况下能够可靠地将形式语言指令映射到行为，而端到端、数据驱动的方法则会失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [229] [LRMR: LLM-Driven Relational Multi-node Ranking for Lymph Node Metastasis Assessment in Rectal Cancer](https://arxiv.org/abs/2507.11457)
> *LRMR：LLM驱动的直肠癌淋巴结转移多节点关系排名评估*

*Yaoxian Dong, Yifan Gao, Haoyue Li, Yanfen Cui, Xin Gao* | **Category: cs.LG, eess.IV** | **Updated: 2025-07-15**

**Keywords:** 直肠癌, 淋巴结转移, 大型语言模型 (LLM), 关系排名, 可解释性

**Comment:** 

> **TL;DR:** LRMR是一个基于LLM的两阶段框架，用于对直肠癌淋巴结转移进行可解释且有效的评估，通过结构化报告和关系排名优于传统AI模型。

**AI_Comments:** 该研究的创新之处在于其两阶段的LLM驱动框架，成功地将视觉感知与认知推理分离，并引入了关系排名机制，克服了传统AI模型“黑箱”和孤立评估的局限性。其生成结构化报告的能力显著增强了模型的可解释性，这对临床应用至关重要。此外，在性能上超越了现有基线，显示出其在直肠癌淋巴结转移评估方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的MRI评估直肠癌淋巴结转移诊断性能有限；现有AI模型缺乏可解释性且孤立评估淋巴结，未能考虑患者层面的上下文。

**Method:** 提出LRMR框架，将诊断任务从直接分类重构为结构化推理和排名过程。第一阶段，多模态LLM分析患者所有淋巴结的复合图像，生成包含十个放射学特征的结构化报告。第二阶段，文本LLM对不同患者的报告进行两两比较，根据不良特征的严重程度和数量建立相对风险排名。

**Result:** 在117名直肠癌患者的回顾性队列中，LRMR的AUC达到0.7917，F1-score为0.7200，优于包括ResNet50（AUC 0.7708）在内的深度学习基线。消融研究证实关系排名阶段和结构化提示阶段的价值，移除任一阶段均导致性能显著下降。

**Conclusion:** 通过两阶段LLM框架将视觉感知与认知推理解耦，为直肠癌淋巴结转移评估提供了一个强大、可解释且有效的新范式。

> **ai_Abstract:** 该论文提出了LRMR，一个基于LLM的两阶段框架，用于评估直肠癌淋巴结转移。该框架通过多模态LLM生成结构化放射学报告，并利用文本LLM进行患者间报告的比较和相对风险排名。LRMR在直肠癌患者队列中表现出优于传统深度学习基线的诊断性能，并提供了更高的可解释性，通过解耦视觉感知和认知推理，为淋巴结转移评估提供新范式。

> **摘要翻译:** LRMR：LLM驱动的直肠癌淋巴结转移多节点关系排名评估

直肠癌淋巴结（LN）转移的准确术前评估指导治疗决策，然而基于形态学标准的传统MRI评估诊断性能有限。尽管已开发出一些人工智能模型，但它们通常作为“黑箱”运行，缺乏临床信任所需的可解释性。此外，这些模型通常孤立地评估节点，忽略了患者层面的上下文。为解决这些局限性，我们引入了LRMR，一个LLM驱动的关系多节点排名框架。这种方法将诊断任务从直接分类问题重构为结构化推理和排名过程。LRMR框架分两个阶段运行。首先，多模态大型语言模型（LLM）分析患者所有淋巴结的复合蒙太奇图像，生成一份详细说明十个不同放射学特征的结构化报告。其次，基于文本的LLM对不同患者的这些报告进行两两比较，根据不良特征的严重程度和数量建立相对风险排名。我们在117名直肠癌患者的回顾性队列中评估了我们的方法。LRMR实现了0.7917的曲线下面积（AUC）和0.7200的F1分数，优于包括ResNet50（AUC 0.7708）在内的一系列深度学习基线。消融研究证实了我们两大贡献的价值：移除关系排名阶段或结构化提示阶段均导致性能显著下降，AUC分别降至0.6875和0.6458。我们的工作表明，通过两阶段LLM框架将视觉感知与认知推理解耦，为直肠癌淋巴结转移评估提供了一个强大、可解释且有效的新范式。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [230] [AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air](https://arxiv.org/abs/2507.11515)
> *AirLLM：基于扩散策略的自适应LoRA用于LLM的空中远程微调*

*Shiyi Yang, Xiaoxue Yu, Rongpeng Li, Jianhang Zhu, Zhifeng Zhao, Honggang Zhang* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-15**

**Keywords:** LLM微调, LoRA, 扩散策略, 远程微调, 通信效率

**Comment:** 11 pages, 8 figures

> **TL;DR:** AirLLM提出了一种基于扩散策略的自适应LoRA方法，用于高效的空中远程LLM微调，显著降低了传输成本并提升了性能。

**AI_Comments:** AirLLM的创新之处在于将强化学习（PPO）与扩散模型（DDIM）相结合，以实现LoRA秩的自适应选择，这是一种针对通信感知型LLM微调的新颖方法。该研究解决了在边缘设备上部署LLM的关键挑战，通过优化通信效率，对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在边缘设备上操作大型语言模型（LLM）面临通信带宽有限以及计算和内存成本高昂的挑战。现有的低秩适应（LoRA）方法通常采用固定或启发式秩配置，导致所有LoRA参数的空中传输效率低下。

**Method:** AirLLM开发了一个分层扩散策略框架，用于通信感知的LoRA适应。它将秩配置建模为一个结构化动作向量。一个近端策略优化（PPO）智能体通过联合观察无线状态和语言复杂性来生成粗粒度决策，这些决策随后通过去噪扩散隐式模型（DDIM）进行细化，以产生高分辨率、任务和通道自适应的秩向量。这两个模块交替优化，DDIM在无分类器指导（CFG）范式下训练以保持与PPO奖励的一致性。

**Result:** 在不同信噪比下的实验表明，AirLLM持续提升了微调性能，同时显著降低了传输成本。

**Conclusion:** 强化驱动、扩散优化的秩适应对于可扩展和高效的空中远程微调是有效的。

> **ai_Abstract:** AirLLM旨在解决边缘设备上LLM远程微调面临的通信效率低下问题。该研究提出了一种基于分层扩散策略的自适应LoRA框架。通过结合近端策略优化（PPO）智能体进行粗粒度决策（考虑无线状态和语言复杂性），并利用去噪扩散隐式模型（DDIM）进行高分辨率秩向量的细化，AirLLM能够动态调整LoRA秩。实验结果表明，该方法在提高微调性能的同时显著降低了传输成本，证明了其在空中远程LLM微调中的有效性和可扩展性。

> **摘要翻译:** 在边缘设备上操作大型语言模型（LLM）正面临通信带宽有限以及计算和内存成本高昂的日益严峻挑战。因此，云辅助的远程微调变得不可或缺。然而，现有的低秩适应（LoRA）方法通常采用固定或启发式秩配置，随之而来的所有LoRA参数的空中传输可能会相当低效。为了解决这一限制，我们开发了AirLLM，一个用于通信感知LoRA适应的分层扩散策略框架。具体来说，AirLLM将秩配置建模为一个跨所有LoRA插入投影的结构化动作向量。为了解决潜在的高维序列决策问题，一个近端策略优化（PPO）智能体通过联合观察无线状态和语言复杂性来生成粗粒度决策，这些决策随后通过去噪扩散隐式模型（DDIM）进行细化，以产生高分辨率、任务和通道自适应的秩向量。这两个模块交替优化，DDIM在无分类器指导（CFG）范式下训练以保持与PPO奖励的一致性。在不同信噪比下的实验表明，AirLLM持续提升了微调性能，同时显著降低了传输成本，突出了强化驱动、扩散优化的秩适应对于可扩展和高效的空中远程微调的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [235] [Exploring the robustness of TractOracle methods in RL-based tractography](https://arxiv.org/abs/2507.11486)
> *探索TractOracle方法在基于强化学习的纤维束描绘中的鲁棒性*

*Jeremi Levesque, Antoine Théberge, Maxime Descoteaux, Pierre-Marc Jodoin* | **Category: cs.LG, I.2.1** | **Updated: 2025-07-15**

**Keywords:** 纤维束描绘, 强化学习, TractOracle, 鲁棒性, 迭代奖励训练

**Comment:** 38 pages, 8 figures. Submitted to Medical Image Analysis

> **TL;DR:** 本文探讨并扩展了基于强化学习的纤维束描绘方法TractOracle-RL的鲁棒性，并引入了一种新的迭代奖励训练（IRT）方案，显著提升了纤维束描绘的准确性和解剖学有效性。

**AI_Comments:** 本文的创新点在于对TractOracle-RL框架的扩展以及引入了迭代奖励训练（IRT）机制。IRT通过利用束过滤方法而非人工输入来迭代优化预言机指导，这使得该方法在实际应用中更具可行性。该研究的重要性在于证明了基于强化学习的纤维束描绘方法，特别是TractOracle-RL及其改进版，在不同数据集上的鲁棒性和优越性能，为脑白质纤维束重建提供了更准确和可靠的工具。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习（RL）在纤维束描绘中表现出巨大潜力，TractOracle-RL作为一种RL方法能减少假阳性。然而，其鲁棒性仍需深入研究，并且可以通过整合最新的RL进展来进一步提升性能。

**Method:** 本文通过整合强化学习的最新进展，研究了原始TractOracle-RL框架的四种扩展。研究评估了这些方法在五种不同的弥散MRI数据集上的性能。此外，论文还引入了一种名为迭代奖励训练（IRT）的新型RL训练方案，该方案受“基于人类反馈的强化学习（RLHF）”启发，利用束过滤方法迭代地细化预言机（oracle）在训练过程中的指导。

**Result:** 结果表明，将预言机与强化学习框架结合，无论使用何种具体方法或数据集，都能持续实现鲁棒和可靠的纤维束描绘。实验结果还显示，通过预言机反馈训练的强化学习方法在准确性和解剖学有效性方面显著优于广泛使用的纤维束描绘技术。

**Conclusion:** TractOracle-RL方法，特别是结合了迭代奖励训练和预言机反馈，能够提供鲁棒、准确且解剖学有效的纤维束描绘，性能优于传统方法。

> **ai_Abstract:** 本文探讨了基于强化学习的TractOracle方法在纤维束描绘中的鲁棒性。研究了TractOracle-RL框架的四种扩展，并引入了受RLHF启发的迭代奖励训练（IRT）方案，该方案利用束过滤迭代优化预言机指导。实验结果表明，将预言机与RL结合可实现鲁棒可靠的纤维束描绘，并且通过预言机反馈训练的RL方法在准确性和解剖学有效性方面显著优于传统方法。

> **摘要翻译:** 纤维束描绘算法利用弥散MRI重建大脑白质的纤维结构。在机器学习方法中，强化学习（RL）已成为一种有前景的纤维束描绘框架，在几个关键方面优于传统方法。TractOracle-RL是一种近期基于RL的方法，通过奖励机制将解剖学先验知识整合到训练过程中，从而减少假阳性。在本文中，我们通过整合RL的最新进展，研究了原始TractOracle-RL框架的四种扩展，并评估了它们在五个多样化弥散MRI数据集上的性能。结果表明，将预言机与RL框架结合，无论使用何种具体方法或数据集，都能持续实现鲁棒和可靠的纤维束描绘。我们还引入了一种受“基于人类反馈的强化学习（RLHF）”范式启发的创新RL训练方案，称为迭代奖励训练（IRT）。IRT不依赖于人类输入，而是利用束过滤方法在整个训练过程中迭代地细化预言机的指导。实验结果表明，通过预言机反馈训练的RL方法在准确性和解剖学有效性方面显著优于广泛使用的纤维束描绘技术。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [239] [Reinforcement Learning with Action Chunking](https://arxiv.org/abs/2507.07969)
> *带有动作分块的强化学习*

*Qiyang Li, Zhiyuan Zhou, Sergey Levine* | **Category: cs.LG, cs.AI, cs.RO, stat.ML** | **Updated: 2025-07-15**

**Keywords:** 强化学习, 动作分块, 离线到在线RL, 稀疏奖励, 样本效率

**Comment:** 25 pages, 15 figures

> **TL;DR:** Q-chunking是一种简单有效的强化学习方法，通过在时间差分（TD）RL中应用动作分块技术，解决了长周期、稀疏奖励任务中离线到在线RL的探索和样本效率挑战，并取得了优异的性能。

**AI_Comments:** 本文的创新点在于将模仿学习中的动作分块技术巧妙地引入到基于TD的强化学习中，以解决离线到在线RL在长周期、稀疏奖励任务中的探索和样本效率问题。其“简单而有效”的特点表明了该方法具有较强的实用性和通用性，为该领域的进一步研究提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 在长周期、稀疏奖励任务中，离线到在线强化学习（RL）面临着有效探索和样本效率学习的核心挑战，尤其是不清楚如何利用离线数据来获得良好的探索性策略。

**Method:** 本文提出了Q-chunking方法，它将动作分块（一种预测未来动作序列而非单个动作的技术）应用于基于时间差分（TD）的RL方法。Q-chunking通过在“分块”动作空间中直接运行RL，使智能体能够利用离线数据中时间上一致的行为进行更有效的在线探索，并使用无偏的n步备份进行更稳定和高效的TD学习。

**Result:** 实验结果表明，Q-chunking在离线性能和在线样本效率方面表现出色，在各种长周期、稀疏奖励的操纵任务上优于现有最佳的离线到在线方法。

**Conclusion:** Q-chunking是一种简单有效的方法，通过引入动作分块到TD-RL中，显著改善了长周期、稀疏奖励任务中的强化学习算法，特别是在离线到在线设置下提升了探索和样本效率。

> **ai_Abstract:** Q-chunking是一种针对长周期、稀疏奖励任务的离线到在线强化学习新方法。它将模仿学习中流行的动作分块技术应用于时间差分（TD）RL，通过在“分块”动作空间中操作，利用离线数据促进在线探索，并使用无偏的n步备份提高TD学习的稳定性和效率。实验证明，Q-chunking在离线性能和在线样本效率方面均优于现有最佳方法。

> **摘要翻译:** 我们提出了Q-chunking，这是一种简单而有效的配方，用于改进长周期、稀疏奖励任务的强化学习（RL）算法。我们的配方专为离线到在线RL设置而设计，其目标是利用离线先验数据集来最大限度地提高在线学习的样本效率。在这种设置下，有效的探索和样本高效学习仍然是核心挑战，因为如何利用离线数据来获得良好的探索性策略并不明显。我们的关键见解是，动作分块（一种在模仿学习中流行的技术，即预测未来的动作序列而不是每个时间步的单个动作）可以应用于基于时间差分（TD）的RL方法，以缓解探索挑战。Q-chunking通过在“分块”动作空间中直接运行RL来采用动作分块，使智能体能够（1）利用离线数据中时间上一致的行为进行更有效的在线探索，以及（2）使用无偏的n步备份进行更稳定和高效的TD学习。我们的实验结果表明，Q-chunking展现出强大的离线性能和在线样本效率，在各种长周期、稀疏奖励的操纵任务上优于现有最佳的离线到在线方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [241] [SA-GDA: Spectral Augmentation for Graph Domain Adaptation](https://arxiv.org/abs/2408.09189)
> *SA-GDA：图域适应中的谱增强*

*Jinhui Pang, Zixuan Wang, Jiliang Tang, Mingyan Xiao, Nan Yin* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 图神经网络, 域适应, 节点分类, 谱增强, 对抗学习

**Comment:** 

> **TL;DR:** GNN在域适应中面临标签稀缺问题。本文提出了SA-GDA，通过在谱域中对齐类别特征，并结合双GCN和对抗学习，有效解决了图节点分类的域适应问题。

**AI_Comments:** 该论文解决了GNNs在域适应中的一个关键挑战，特别是在目标域标签稀缺的图节点分类任务中。其创新点在于利用谱域特性进行类别特定的特征对齐，这与普遍的特征空间对齐方法不同。SA-GDA的理论稳定性证明以及双GCN和对抗学习的结合增强了其鲁棒性和可迁移性。这项工作有望显著推动GNNs在真实世界中有限标注数据场景下的应用。

<details>
  <summary>Details</summary>

**Motivation:** 大多数图神经网络(GNNs)需要在信号域进行监督训练，这需要大量任务特定标签且难以迁移到其他域。现有的图节点分类域适应方法主要侧重于对齐源域和目标域的特征空间，但未考虑不同类别间的特征对齐，这可能导致目标域分类混淆。此外，目标域标签的稀缺性使得直接进行有效的类别对齐更具挑战性。

**Method:** 本文提出了“图域适应中的谱增强 (SA-GDA)”。首先，SA-GDA基于观察到不同域中相同类别节点在谱域中表现出相似特征，而不同类别差异显著。其次，它在谱域中对齐不同域的类别特征空间，而非整个特征空间，并提供了理论稳定性证明。然后，开发了一个双图卷积网络以共同利用局部和全局一致性进行特征聚合。最后，利用一个带有对抗学习子模块的域分类器来促进不同域图之间的知识迁移。

**Result:** 在各种公开数据集上的实验结果表明，SA-GDA是有效的。

**Conclusion:** 本文提出了SA-GDA，通过利用谱域特性进行类别对齐，并结合双图卷积网络和对抗学习，有效解决了图节点分类的图域适应问题，并已被实验证明其有效性。

> **ai_Abstract:** 本文提出了一种名为SA-GDA（图域适应中的谱增强）的新方法，用于解决图节点分类中的域适应问题。针对现有GNN在跨域知识迁移时面临的标签稀缺和类别对齐不足的挑战，SA-GDA利用不同域中相同类别节点在谱域中表现出相似特征的观察。该方法在谱域中对齐类别特征空间而非整个特征空间，并提供了理论稳定性证明。SA-GDA还结合了双图卷积网络进行稳健的特征聚合，并采用基于对抗学习的域分类器促进知识迁移。在公开数据集上的实验证明了SA-GDA的有效性。

> **摘要翻译:** 图神经网络 (GNN) 在图相关任务中取得了令人印象深刻的成果。然而，大多数 GNN 主要在信号域的监督训练下进行研究，这需要大量的任务特定标签，并且难以迁移到其他域。目前很少有工作专注于图节点分类的域适应。它们主要侧重于对齐源域和目标域的特征空间，而没有考虑不同类别之间的特征对齐，这可能导致目标域中的分类混淆。然而，由于目标域标签的稀缺性，我们无法直接对来自不同域的类别进行有效的对齐，这使得问题更具挑战性。在本文中，我们提出了用于图节点分类的“图域适应中的谱增强 (SA-GDA)”。首先，我们观察到不同域中相同类别的节点在谱域中表现出相似的特征，而不同类别则差异很大。遵循这一观察结果，我们在谱域中对齐不同域的类别特征空间，而不是对齐整个特征空间，并且我们从理论上证明了所提出的 SA-GDA 的稳定性。然后，我们开发了一个双图卷积网络，以共同利用局部和全局一致性进行特征聚合。最后，我们利用一个带有对抗学习子模块的域分类器来促进不同域图之间的知识迁移。在各种公开数据集上的实验结果表明了我们 SA-GDA 的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [244] [Misalignment from Treating Means as Ends](https://arxiv.org/abs/2507.10995)
> *将手段视为目的导致的偏差*

*Henrik Marklund, Alex Infanger, Benjamin Van Roy* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 奖励函数, AI偏差, 目标混淆, 工具性目标, 终极目标, 强化学习

**Comment:** 

> **TL;DR:** 奖励函数中将实现目标的方法（手段）与目标本身（目的）混淆，会导致严重的AI系统偏差，即使是很小的混淆也会带来显著的性能下降。

**AI_Comments:** 这篇论文揭示了AI对齐（alignment）领域中的一个核心挑战，即如何准确地将人类的真实意图编码到奖励函数中。其创新之处在于通过一个简洁的例子，清晰地展示了“手段”与“目的”混淆的严重后果，并指出了强化学习在此类问题上的敏感性。这对于设计鲁棒和安全的人工智能系统具有重要指导意义，提醒研究者在构建奖励函数时必须区分清楚终极目标和实现目标的中间步骤。

<details>
  <summary>Details</summary>

**Motivation:** 现有的奖励函数往往不完美，会将人类实现目标的手段（工具性目标）与目标本身（终极目标）混淆，导致AI系统在优化这些奖励函数时出现偏差，无法真正实现人类的目标。

**Method:** 作者通过构建一个简单的例子来阐明即使是轻微的工具性目标与终极目标混淆也会导致严重的偏差。这个例子揭示了在哪些环境下，强化学习会高度敏感于这种目标混淆。

**Result:** 该简单例子表明，当工具性目标和终极目标被轻微混淆时，优化这种错误设定的奖励函数会导致在真实奖励函数衡量下的性能极差，即产生严重的偏差。

**Conclusion:** 将实现目标的手段（工具性目标）与目标本身（终极目标）混淆在奖励函数中，即使是轻微的，也会导致AI系统出现严重的偏差，从而无法有效实现真正的目标。这种问题在奖励学习和实际环境中普遍存在。

> **ai_Abstract:** 本文探讨了奖励函数中将实现目标的“手段”（工具性目标）与目标本身“目的”（终极目标）混淆所导致的AI系统偏差问题。研究指出，即使是轻微的混淆，也会导致优化后的奖励函数在真实目标衡量下表现极差。作者通过一个简单示例阐明了这种现象及其在强化学习环境中出现的关键特性，并讨论了其在奖励学习和实际应用中的潜在表现。

> **摘要翻译:** 奖励函数，无论是学习得到的还是手动指定的，都很少是完美的。它们并非准确地表达人类目标，而是经常被人类关于如何最好地实现这些目标的信念所扭曲。具体来说，这些奖励函数通常表达了人类的终极目标——那些本身就是目的的目标——以及人类的工具性目标——那些是达到目的的手段的目标的组合。我们提出了一个简单的例子，在这个例子中，即使是轻微的工具性目标和终极目标的混淆，也会导致严重的偏差：优化错误指定的奖励函数会导致在真实奖励函数衡量下的性能不佳。这个例子提炼出了使强化学习对工具性目标和终极目标混淆高度敏感的环境的基本特性。我们讨论了这个问题如何通过一种常见的奖励学习方法产生，以及它如何在真实环境中表现出来。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [248] [Gaussian Loss Smoothing Enables Certified Training with Tight Convex Relaxations](https://arxiv.org/abs/2403.07095)
> *高斯损失平滑实现紧密凸松弛下的可认证训练*

*Stefan Balauca, Mark Niklas Müller, Yuhao Mao, Maximilian Baader, Marc Fischer, Martin Vechev* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 高斯损失平滑, 可认证训练, 紧密凸松弛, 对抗性样本, 鲁棒性

**Comment:** Accepted for publication in TMLR 07/2025

> **TL;DR:** 高斯损失平滑（GLS）能解决紧密凸松弛在可认证训练中表现不佳的问题，通过平滑损失曲面，显著提升了认证精度，并超越了现有最先进方法。

**AI_Comments:** 本文创新性地提出了高斯损失平滑（GLS）来解决可认证训练中紧密凸松弛的实际应用难题。其重要性在于，它不仅从理论上解释了GLS的有效性，还通过两种实用的优化算法PGPE和RGS验证了其在提升认证精度方面的显著效果，为实现更鲁棒的神经网络训练提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管认证方法能有效利用紧密凸松弛进行边界计算，但在训练中，这些方法表现反而不如宽松的松弛。先前的工作假设这种现象是由紧密松弛引起的损失曲面的不连续性、非光滑性和扰动敏感性造成的。

**Method:** 本文提出高斯损失平滑（GLS）来缓解上述问题，并从理论上证明其有效性。GLS通过两种变体实现：零阶优化算法PGPE（适用于不可微分松弛）和一阶优化算法RGS（需要松弛的梯度，但效率更高）。

**Result:** 实验表明，将GLS与紧密松弛结合时，这些方法在相同网络架构下，在许多设置中超越了最先进的方法。

**Conclusion:** 结果清楚地证明了高斯损失平滑在训练可认证鲁棒神经网络方面的潜力，并为利用更紧密的松弛进行可认证训练铺平了道路。

> **ai_Abstract:** 本文旨在解决神经网络可认证训练中紧密凸松弛表现不佳的问题。研究发现，高斯损失平滑（GLS）能有效缓解由紧密松弛引起的损失曲面的不连续性和敏感性。通过引入PGPE（零阶）和RGS（一阶）两种GLS实现，实验证明GLS结合紧密松弛后，在认证精度上显著优于现有SOTA方法，为可认证鲁棒神经网络的训练开辟了新途径。

> **摘要翻译:** 尽管付出了巨大的努力，但训练具有高认证精度的神经网络以对抗对抗性样本仍然是一个开放的挑战。虽然认证方法可以有效利用紧密凸松弛进行边界计算，但在训练中，这些方法（或许令人惊讶地）可能比更宽松的松弛表现更差。先前的工作假设这种现象是由更紧密松弛引起的损失曲面的不连续性、非光滑性和扰动敏感性造成的。在这项工作中，我们从理论上证明了在损失曲面上应用高斯损失平滑（GLS）可以缓解这些问题。我们通过实例化GLS的两种变体来证实了这一点：一种是零阶优化算法，称为PGPE，它允许使用不可微分的松弛进行训练；另一种是一阶优化算法，称为RGS，它需要松弛的梯度但比PGPE效率高得多。广泛的实验表明，当与紧密松弛结合时，这些方法在许多设置中，在相同的网络架构上进行训练时，超越了最先进的方法。我们的结果清楚地证明了高斯损失平滑在训练可认证鲁棒神经网络方面的潜力，并为利用更紧密的松弛进行可认证训练铺平了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [249] [Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data](https://arxiv.org/abs/2507.10998)
> *为表格数据制作难以察觉的流形对抗性攻击*

*Zhipeng He, Alexander Stevens, Chun Ouyang, Johannes De Smedt, Alistair Barros, Catarina Moreira* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 对抗性攻击, 表格数据, 变分自编码器, 潜在空间扰动, 统计一致性

**Comment:** 32 pages

> **TL;DR:** 本文提出了一种使用混合输入变分自编码器（VAE）的潜在空间扰动框架，用于在表格数据上生成难以察觉的对抗性样本，解决了传统方法在异构数据上产生可检测样本的问题。

**AI_Comments:** 本文创新性地将VAE引入表格数据的对抗性攻击，解决了异构数据难以定义“不可察觉”扰动和传统方法产生非分布内样本的痛点。通过在潜在流形上进行扰动，确保了对抗性样本的统计一致性，提高了攻击的隐蔽性和实用性。其对重建质量和训练数据量的强调，也指出了未来研究的方向和实际部署的考量。

<details>
  <summary>Details</summary>

**Motivation:** 由于混合类别和数值特征的异构性，表格数据上的对抗性攻击面临与图像或文本领域不同的根本挑战。与图像不同，表格数据缺乏直观的相似性度量，难以定义难以察觉的修改。此外，传统的基于梯度的方法侧重于$\\ell_p$-范数约束，通常会产生偏离原始数据分布的对抗性样本，使其可被检测。

**Method:** 我们提出了一种使用混合输入变分自编码器（VAE）的潜在空间扰动框架，以生成难以察觉的对抗性样本。所提出的VAE将类别嵌入和数值特征集成到一个统一的潜在流形中，从而实现保持统计一致性的扰动。我们指定了分布内成功率（IDSR）来衡量与输入分布在统计上无法区分的对抗性样本的比例。

**Result:** 在六个公开可用数据集和三种模型架构上的评估表明，与传统的输入空间攻击以及从图像领域方法改编的其他基于VAE的方法相比，我们的方法实现了显著更低异常值率和更一致的性能。我们的综合分析包括超参数敏感性、稀疏性控制机制和生成架构比较，揭示了基于VAE的攻击严重依赖于重建质量，但在有足够的训练数据时提供了卓越的实用价值。

**Conclusion:** 这项工作强调了流形扰动对于表格数据上现实对抗性攻击的重要性，为实际部署提供了一种稳健的方法。

> **ai_Abstract:** 本文提出了一种针对表格数据的对抗性攻击新方法，通过利用混合输入变分自编码器（VAE）在潜在空间进行扰动，生成难以察觉且保持统计一致性的对抗性样本。该方法解决了传统$\ell_p$-范数约束方法在表格数据上产生可检测样本的问题。实验证明，与现有方法相比，该方法在多个数据集和模型上表现出更低的异常值率和更稳定的性能，强调了流形扰动在表格数据对抗性攻击中的重要性。

> **摘要翻译:** 表格数据上的对抗性攻击由于混合类别和数值特征的异构性，呈现出与图像或文本领域不同的根本挑战。与像素扰动能保持视觉相似性的图像不同，表格数据缺乏直观的相似性度量，使得难以定义难以察觉的修改。此外，传统的基于梯度的方法优先考虑$\ell_p$-范数约束，通常会产生偏离原始数据分布的对抗性样本，使其可被检测。我们提出了一种使用混合输入变分自编码器（VAE）的潜在空间扰动框架，以生成难以察觉的对抗性样本。所提出的VAE将类别嵌入和数值特征集成到一个统一的潜在流形中，从而实现保持统计一致性的扰动。我们指定了分布内成功率（IDSR）来衡量与输入分布在统计上无法区分的对抗性样本的比例。在六个公开可用数据集和三种模型架构上的评估表明，与传统的输入空间攻击以及从图像领域方法改编的其他基于VAE的方法相比，我们的方法实现了显著更低异常值率和更一致的性能。我们的综合分析包括超参数敏感性、稀疏性控制机制和生成架构比较，揭示了基于VAE的攻击严重依赖于重建质量，但在有足够的训练数据时提供了卓越的实用价值。这项工作强调了流形扰动对于表格数据上现实对抗性攻击的重要性，为实际部署提供了一种稳健的方法。源代码可通过https://github.com/ZhipengHe/VAE-TabAttack访问。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [257] [Collaboration Promotes Group Resilience in Multi-Agent AI](https://arxiv.org/abs/2111.06614)
> *协作促进多智能体AI中的群体韧性*

*Sarah Keren, Matthias Gerstgrasser, Ofir Abu, Jeffrey Rosenschein* | **Category: cs.LG, cs.AI, cs.MA, I.2.11; I.2.6** | **Updated: 2025-07-14**

**Keywords:** 多智能体系统, 群体韧性, 协作, 强化学习, 环境适应性

**Comment:** RLC 2025

> **TL;DR:** 本研究引入了多智能体“群体韧性”的概念，并实证表明协作能显著提升多智能体在环境扰动下的适应能力。

**AI_Comments:** 本文的创新点在于首次形式化了多智能体环境下的“群体韧性”概念，并实证强调了协作在提升多智能体系统适应性方面的重要性。这为设计更鲁棒的多智能体AI系统提供了新的视角和方法。

<details>
  <summary>Details</summary>

**Motivation:** 在动态环境中，强化学习智能体需要对意外变化具有韧性。现有研究主要关注单智能体韧性，但多智能体场景下的韧性（群体韧性）尚未被充分探讨。

**Method:** 本研究引入并形式化了群体韧性这一概念，并假设协作是实现群体韧性的关键。通过评估不同的协作协议，并将其效果与非协作方法进行比较，对假设进行了实证检验。

**Result:** 实验结果表明，所有考察的协作方法都比非协作方法展现出更高的群体韧性。

**Conclusion:** 协作是多智能体强化学习中实现群体韧性的关键因素，能够帮助智能体更好地适应环境扰动。

> **ai_Abstract:** 本研究引入了多智能体“群体韧性”的概念，旨在解决多智能体强化学习（MARL）在动态环境中适应性不足的问题。文章提出并验证了协作是提升群体韧性的关键因素，通过实验证明了协作协议在环境扰动下能比非协作方法展现出更高的群体韧性。

> **摘要翻译:** 为了在各种动态场景中有效运行，强化学习智能体必须对环境中意外的变化具有韧性。以前关于这种韧性的工作都集中在单智能体设置。在这项工作中，我们引入并形式化了韧性的一个多智能体变体，我们称之为群体韧性。我们进一步假设与其他智能体的协作是实现群体韧性的关键；协作智能体在多智能体强化学习（MARL）设置中能更好地适应环境扰动。我们通过评估不同的协作协议并检查它们对群体韧性的影响来实证检验我们的假设。我们的实验表明，所有考察的协作方法都比非协作方法实现了更高的群体韧性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [263] [Overcoming Slow Decision Frequencies in Continuous Control: Model-Based Sequence Reinforcement Learning for Model-Free Control](https://arxiv.org/abs/2410.08979)
> *克服连续控制中的慢决策频率：用于无模型控制的基于模型的序列强化学习*

*Devdhar Patel, Hava Siegelmann* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 序列强化学习, 连续控制, 慢决策频率, 模型辅助, 样本复杂度

**Comment:** 30 pages, 14 figures, 7 tables. Presented at the Thirteenth
  International Conference on Learning Representations (ICLR 2025), Singapore,
  April 24-28, 2025

> **TL;DR:** 本文提出序列强化学习（SRL），一种模型辅助的强化学习算法，能够以较低的决策频率生成动作序列，实现与现有先进算法相当的性能，同时显著降低采样复杂度，尤其适用于需要可变决策频率的应用。

**AI_Comments:** 这项工作通过引入序列强化学习（SRL）算法，巧妙地解决了强化学习在现实世界应用中面临的慢决策频率和高样本复杂度问题。其创新点在于结合了模型辅助的学习和无模型的执行，特别是“时间回忆”机制，使得模型能够为序列中的每个原子动作提供精细的学习信号。这不仅提高了算法的效率和实用性，还通过引入频率平均分数（FAS）提供了一个更全面的评估指标，对于推动RL在实际场景中的部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的强化学习算法通常需要比人类能力快得多的时间步和反应时间，这在现实世界中不切实际，并且通常需要专门的硬件。因此，需要一种能在较低决策频率下有效控制的强化学习算法。

**Method:** 本文引入了序列强化学习（SRL），这是一种强化学习算法，旨在为给定输入状态生成一系列动作，从而实现较低决策频率下的有效控制。SRL通过结合模型和在不同时间尺度上运行的Actor-Critic架构来学习动作序列。它提出了一种“时间回忆”机制，其中Critic使用模型估计原始动作之间的中间状态，为序列中的每个单独动作提供学习信号。训练完成后，Actor可以独立于模型生成动作序列，实现慢频率下的无模型控制。

**Result:** SRL在连续控制任务上实现了与最先进算法相当的性能，同时显著降低了Actor的样本复杂度。引入的频率平均分数（FAS）指标表明，SRL在FAS方面显著优于传统RL算法。此外，SRL与基于模型的在线规划器相比，在FAS方面表现出可比的性能，并且在训练期间利用了在线规划器用于规划的相同模型。

**Conclusion:** 序列强化学习（SRL）能够有效克服连续控制中慢决策频率的挑战，实现与先进算法相当的性能，并显著降低样本复杂度，使其特别适用于需要可变决策频率的实际应用。

> **ai_Abstract:** 本文提出了一种名为序列强化学习（SRL）的新型强化学习算法，旨在解决连续控制中慢决策频率的挑战。SRL通过结合模型和Actor-Critic架构，生成一系列动作，从而在较低的决策频率下实现有效控制。其核心创新在于“时间回忆”机制，使Critic能够利用模型为序列中的每个动作提供学习信号。训练完成后，Actor可以独立地进行无模型控制。实验结果表明，SRL在性能上与现有先进算法相当，同时显著降低了样本复杂度，并且在引入的频率平均分数（FAS）指标上优于传统RL算法，使其适用于需要可变决策频率的实际应用。

> **摘要翻译:** 强化学习（RL）正在迅速达到并超越人类水平的控制能力。然而，最先进的强化学习算法通常需要比人类能力快得多的时间步和反应时间，这在现实世界中不切实际，并且通常需要专门的硬件。我们引入了序列强化学习（SRL），这是一种强化学习算法，旨在为给定输入状态生成一系列动作，从而实现较低决策频率下的有效控制。SRL通过采用模型和在不同时间尺度上运行的Actor-Critic架构来解决学习动作序列的挑战。我们提出了一种“时间回忆”机制，其中Critic使用模型估计原始动作之间的中间状态，为序列中的每个单独动作提供学习信号。一旦训练完成，Actor可以独立于模型生成动作序列，实现慢频率下的无模型控制。我们在连续控制任务套件上评估了SRL，结果表明它实现了与最先进算法相当的性能，同时显著降低了Actor的样本复杂度。为了更好地评估不同决策频率下的性能，我们引入了频率平均分数（FAS）指标。我们的结果表明，SRL在FAS方面显著优于传统RL算法，使其特别适用于需要可变决策频率的应用。此外，我们将SRL与基于模型的在线规划进行了比较，结果表明SRL实现了可比的FAS，同时在训练期间利用了在线规划器用于规划的相同模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [266] [A Benchmarking Framework for AI models in Automotive Aerodynamics](https://arxiv.org/abs/2507.10747)
> *汽车空气动力学中人工智能模型的基准测试框架*

*Kaustubh Tangsali, Rishikesh Ranade, Mohammad Amin Nabian, Alexey Kamenev, Peter Sharpe, Neil Ashton, Ram Cherukuri, Sanjay Choudhry* | **Category: cs.LG** | **Updated: 2025-07-14**

**Keywords:** AI模型, 汽车空气动力学, 基准测试, CAE, NVIDIA PhysicsNeMo-CFD

**Comment:** 

> **TL;DR:** 论文提出了一个开放可扩展的基准测试框架，用于系统评估汽车空气动力学AI模型的准确性、性能、可扩展性和泛化能力，旨在加速该领域的研究和创新。

**AI_Comments:** 该论文提出了一个及时且重要的基准测试框架，解决了AI模型在汽车空气动力学应用中缺乏标准化评估的问题。其开放性和可扩展性是关键创新点，能够促进社区协作和模型公平比较。这将有助于加速AI在工程领域的实际应用和发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI模型在汽车空气动力学预测方面缺乏系统性的评估方法，导致透明度和一致性不足。因此，需要一个标准化框架来评估AI模型的准确性、性能、可扩展性和泛化能力，以促进其理解、开发和应用。

**Method:** 作者在开源NVIDIA PhysicsNeMo-CFD框架内开发了一个基准测试框架。该框架支持纳入多种CAE相关指标，并提供了一种标准化的AI模型比较方法。为展示其效用，框架包含了对DoMINO、X-MeshGraphNet和FIGConvNet这三种AI模型在DrivAerML数据集上进行表面和体积流场预测的评估，并提供了集成额外模型和数据集的指南。

**Result:** 论文介绍了所开发的基准测试框架，该框架能够系统评估汽车空气动力学AI模型的准确性、性能、可扩展性和泛化能力。它通过在DrivAerML数据集上评估DoMINO、X-MeshGraphNet和FIGConvNet等模型，展示了其在表面和体积流场预测方面的实用性，并提供了扩展性指南。

**Conclusion:** 该基准测试框架旨在为研究人员和行业专业人士选择、改进和推进AI驱动的空气动力学建模方法提供支持，最终促进汽车空气动力学领域更高效、准确和可解释解决方案的发展。

> **ai_Abstract:** 本文提出了一个用于汽车空气动力学AI模型的开放可扩展基准测试框架，该框架基于NVIDIA PhysicsNeMo-CFD，旨在系统评估AI模型的准确性、性能、可扩展性和泛化能力。该框架提供标准化方法和多样化指标，以提高评估透明度和一致性，加速研究和创新。通过在DrivAerML数据集上对DoMINO、X-MeshGraphNet和FIGConvNet进行评估，论文展示了框架的实用性，并提供了扩展指南，旨在赋能研究人员和行业专家开发更高效、准确和可解释的AI空气动力学解决方案。

> **摘要翻译:** 在本文中，我们介绍了开源NVIDIA PhysicsNeMo-CFD框架内的一个基准测试框架，旨在系统评估用于汽车空气动力学预测的AI模型的准确性、性能、可扩展性和泛化能力。这个开放可扩展的框架能够整合与计算机辅助工程（CAE）社区相关的多样化指标。通过提供一种标准化方法来比较AI模型，该框架增强了性能评估的透明度和一致性，其总体目标是提高对这些模型的理解和开发，以加速该领域的研究和创新。为了展示其效用，该框架包含了对三种AI模型（DoMINO、X-MeshGraphNet和FIGConvNet）使用DrivAerML数据集进行表面和体积流场预测的评估。它还包括集成额外模型和数据集的指南，使其在物理一致性指标方面具有可扩展性。这项基准测试研究旨在使研究人员和行业专业人士能够选择、改进和推进AI驱动的空气动力学建模方法，最终促进汽车空气动力学领域更高效、准确和可解释解决方案的开发。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [267] [Compute Requirements for Algorithmic Innovation in Frontier AI Models](https://arxiv.org/abs/2507.10618)
> *前沿AI模型中算法创新的计算需求*

*Peter Barnett* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-13**

**Keywords:** 算法创新, 计算需求, 大型语言模型, 计算限制, AI进展

**Comment:** 

> **TL;DR:** 本文实证研究了开发大型语言模型算法创新的计算需求，发现资源密集型创新每年计算需求翻倍，但即使严格的计算限制也可能不会显著减缓AI算法进展。

**AI_Comments:** 这篇论文通过量化算法创新的计算成本，为AI领域的政策制定和资源分配提供了实证依据。其创新之处在于首次系统地估算了算法创新本身的计算开销，并挑战了“计算限制能有效减缓AI进步”的直观假设。重要性在于它揭示了算法效率提升在应对计算瓶颈方面的潜力，并可能影响未来对AI安全和治理策略的思考。

<details>
  <summary>Details</summary>

**Motivation:** 了解开发大型语言模型预训练中算法创新所需的计算资源，并评估计算限制对创新速度的影响。

**Method:** 编目了Llama 3和DeepSeek-V3中使用的36项预训练算法创新，并估算了每项创新开发所需的总FLOP和所用硬件的FLOP/s。然后利用此数据集调查计算限制对创新的影响。

**Result:** 使用大量资源的算法创新，其计算需求每年翻倍。分析表明，单独的计算限制不太可能显著减缓AI算法进展。即使是严格的计算限制（例如将总操作限制在训练GPT-2的计算量或将硬件容量限制在8个H100 GPU），仍能允许实现一半已编目的创新。

**Conclusion:** 尽管资源密集型创新计算需求增长迅速，但即使是严格的计算限制也可能不会显著阻碍AI算法的进步。

> **ai_Abstract:** 本文实证分析了大型语言模型预训练中算法创新的计算需求。研究编目了Llama 3和DeepSeek-V3中的36项创新，并估算了其开发所需的计算资源。结果显示，资源密集型创新的计算需求每年翻倍。然而，进一步分析表明，即使是严格的计算限制，也可能不会显著阻碍AI算法的进展，因为许多现有创新仍能在这些限制下实现。

> **摘要翻译:** 大型语言模型预训练中的算法创新极大地减少了达到给定能力水平所需的总计算量。在本文中，我们实证研究了开发算法创新所需的计算需求。我们编目了Llama 3和DeepSeek-V3中使用的36项预训练算法创新。对于每项创新，我们估计了开发中使用的总FLOP以及所用硬件的FLOP/s。使用大量资源的创新，其需求每年翻倍。然后我们使用此数据集调查计算限制对创新的影响。我们的分析表明，单独的计算限制不太可能显著减缓AI算法进展。即使是严格的计算限制——例如将总操作限制在训练GPT-2的计算量或将硬件容量限制在8个H100 GPU——仍能允许实现一半已编目的创新。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [270] [Unveiling Differences in Generative Models: A Scalable Differential Clustering Approach](https://arxiv.org/abs/2405.02700)
> *揭示生成模型差异：一种可扩展的差分聚类方法*

*Jingwei Zhang, Mohammad Jalali, Cheuk Ting Li, Farzan Farnia* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 生成模型, 差分聚类, FINC, 谱方法, 可扩展性

**Comment:** 

> **TL;DR:** 本文提出了一种名为FINC的傅里叶光谱方法，用于解决差分聚类问题，以识别不同生成模型产生的不同样本类型。该方法具有可扩展性，并在大规模计算机视觉数据集上得到了验证。

**AI_Comments:** 该论文提出了一种新颖的差分聚类方法FINC，解决了现有生成模型评估方法在揭示模型间细微差异方面的不足。其创新点在于将傅里叶分析与谱聚类相结合，提供了一种可扩展且能够识别特定样本类型差异的工具。这对于理解和改进生成模型具有重要意义，因为它超越了单一的定量分数，深入分析了模型生成行为的模式。

<details>
  <summary>Details</summary>

**Motivation:** 现有针对生成模型的定量评分方法无法揭示不同模型在生成不同样本类型时的细微差异，因此需要一种能识别这些差异的方法。

**Method:** 本文提出解决差分聚类问题来检测两个生成模型产生的不同样本类型。为此，开发了一种名为FINC（Fourier-based Identification of Novel Clusters）的谱方法，该方法基于随机傅里叶特征来估计两个生成模型核协方差矩阵的特征空间，并利用主特征方向来检测在每个模型中更占主导地位的样本类型。

**Result:** 数值结果表明，所开发的基于傅里叶的方法在突出生成模型以不同频率产生的样本类型方面具有可扩展性，并在大规模计算机视觉数据集和生成建模框架中得到了应用。

**Conclusion:** 本文提出的FINC方法能够有效检测并揭示不同生成模型在生成样本类型上的细微差异，为生成模型的细粒度比较提供了一个可扩展的解决方案。

> **ai_Abstract:** 本文提出了一种解决差分聚类问题的新方法FINC（Fourier-based Identification of Novel Clusters），旨在揭示不同生成模型在生成样本类型上的细微差异。FINC是一种可扩展的谱方法，通过利用随机傅里叶特征估计核协方差矩阵的特征空间，并利用主特征方向来识别在特定模型中更常见的样本类型。该方法解决了现有定量评分无法提供细粒度比较的局限性，并在大规模计算机视觉数据集上验证了其可扩展性和有效性。

> **摘要翻译:** 对生成模型进行细粒度比较需要识别每个相关模型以不同方式生成的样本类型。尽管文献中已提出了量化分数来对不同的生成模型进行排名，但基于分数的评估和排名并不能揭示生成模型在产生不同样本类型时的细微差异。在这项工作中，我们提出解决一个差分聚类问题，以检测由两个生成模型以不同方式生成的样本类型。为了解决差分聚类问题，我们开发了一种名为傅里叶新颖聚类识别（FINC）的谱方法，用于识别与参考分布相比，生成模型以更高频率产生的模式。FINC提供了一种基于随机傅里叶特征的可扩展算法，用于估计两个生成模型核协方差矩阵的特征空间，并利用主特征方向来检测在每个模型中更占主导地位的样本类型。我们展示了FINC方法在大型计算机视觉数据集和生成建模框架中的应用。我们的数值结果表明，所开发的基于傅里叶的方法在突出生成模型以不同频率产生的样本类型方面具有可扩展性。项目代码可在https://github.com/buyeah1109/FINC获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [275] [Langevin Flows for Modeling Neural Latent Dynamics](https://arxiv.org/abs/2507.11531)
> *用于建模神经潜在动力学的朗之万流*

*Yue Song, T. Anderson Keller, Yisong Yue, Pietro Perona, Max Welling* | **Category: cs.LG, q-bio.NC** | **Updated: 2025-07-15**

**Keywords:** LangevinFlow, 神经潜在动力学, 变分自编码器, 朗之万方程, 神经群体模型

**Comment:** Full version of the Cognitive Computational Neuroscience (CCN) 2025
  poster

> **TL;DR:** 该论文引入了LangevinFlow，一个使用朗之万方程进行潜在动力学建模的序贯变分自编码器，在神经群体活动建模方面优于现有基线。

**AI_Comments:** 该论文的创新点在于将朗之万方程引入到变分自编码器中，用于建模神经潜在动力学，并结合了物理先验，使得模型能够更好地捕捉生物神经系统的复杂行为。特别是势函数被参数化为局部耦合振荡器网络，这是一种新颖且有效的偏置，有助于模拟生物学上观察到的振荡和流状模式。该方法的性能在多个基准上得到了验证，表明其在神经科学领域具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 神经群表现出驱动时间演化尖峰活动的潜在动力学结构，这促使人们寻找能够捕捉内在网络动力学和外部未观测影响的模型。

**Method:** 引入了LangevinFlow，一个序贯变分自编码器（VAE），其中潜在变量的时间演化由欠阻尼朗之万方程控制。该方法融合了物理先验，如惯性、阻尼、学习到的势函数和随机力，用于表示神经系统中的自主和非自主过程。势函数被参数化为局部耦合振荡器的网络。模型包含一个循环编码器、一个单层Transformer解码器以及潜在空间中的朗之万动力学。

**Result:** 在由Lorenz吸引子生成的合成神经群上，该方法优于最先进的基线，与真实放电率非常匹配。在神经潜在基准（NLB）上，模型在四个具有挑战性的数据集上实现了卓越的保留神经元似然（每尖峰比特）和前向预测精度。它还在解码行为指标（如手部速度）方面匹配或超越了其他方法。

**Conclusion:** LangevinFlow是一个灵活的、受物理启发的高性能框架，用于建模复杂的神经群动力学及其未观测影响。

> **ai_Abstract:** LangevinFlow是一种新型的序贯变分自编码器，它利用欠阻尼朗之万方程来模拟神经潜在变量的时间演化。该模型融入了物理先验，并通过将势函数参数化为局部耦合振荡器网络，以捕捉神经系统中常见的振荡和流状行为。实验结果表明，LangevinFlow在合成和真实神经数据集上均优于现有基线，在神经元似然、前向预测和行为解码方面表现出色，为复杂的神经群体动力学建模提供了一个高性能的物理启发框架。

> **摘要翻译:** 神经群表现出驱动时间演化尖峰活动的潜在动力学结构，这促使人们寻找能够捕捉内在网络动力学和外部未观测影响的模型。在这项工作中，我们引入了LangevinFlow，一个序贯变分自编码器，其中潜在变量的时间演化由欠阻尼朗之万方程控制。我们的方法融合了物理先验——如惯性、阻尼、学习到的势函数和随机力——来表示神经系统中的自主和非自主过程。关键是，势函数被参数化为局部耦合振荡器的网络，使模型偏向于生物神经群中观察到的振荡和流状行为。我们的模型具有一个循环编码器、一个单层Transformer解码器以及潜在空间中的朗之万动力学。经验上，我们的方法在由Lorenz吸引子生成的合成神经群上优于最先进的基线，与真实放电率非常匹配。在神经潜在基准（NLB）上，该模型在四个具有挑战性的数据集上实现了卓越的保留神经元似然（每尖峰比特）和前向预测精度。它还在解码行为指标（如手部速度）方面匹配或超越了其他方法。总的来说，这项工作引入了一个灵活的、受物理启发的高性能框架，用于建模复杂的神经群动力学及其未观测影响。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [283] [Gram-Schmidt Methods for Unsupervised Feature Extraction and Selection](https://arxiv.org/abs/2311.09386)
> *用于无监督特征提取和选择的格拉姆-施密特方法*

*Bahram Yaghooti, Netanel Raviv, Bruno Sinopoli* | **Category: cs.LG, cs.IT, math.IT** | **Updated: 2025-07-15**

**Keywords:** 格拉姆-施密特, 特征提取, 特征选择, 无监督学习, 非线性依赖

**Comment:** To appear in IEEE Transactions on Information Theory

> **TL;DR:** 本文提出了一种基于函数空间上格拉姆-施密特正交化过程的线性方法，用于无监督特征提取和选择，旨在解决数据中非线性依赖性的挑战，并在实验中表现出优于现有线性方法和与非线性方法相媲美的性能。

**AI_Comments:** 该论文的创新之处在于将格拉姆-施密特正交化过程应用于函数空间，以解决无监督学习中非线性依赖性的特征提取和选择问题。其重要性在于提出了一种线性方法，不仅在性能上超越了传统的线性算法，甚至能够与复杂的非线性方法（如自动编码器、核PCA、UMAP）竞争，这在计算效率和可解释性方面可能具有显著优势。此外，其特征选择算法在推广现有机制的同时显著降低了复杂性，显示出其实用价值。该研究为无监督特征工程提供了一个强大且高效的新视角。

<details>
  <summary>Details</summary>

**Motivation:** 在无监督学习中，处理数据间非线性依赖性下的特征提取和选择是一个根本性挑战。

**Method:** 本文提出在函数空间上使用格拉姆-施密特（GS）型正交化过程来检测和映射此类依赖性。通过在函数族上应用GS过程，构建一系列协方差矩阵，这些矩阵可用于识别新的大方差方向，或从已知方向中移除依赖性。该方法提供信息论保证，并能消除现有数据冗余。其特征提取方法是线性的，可视为主成分分析（PCA）的自然推广。

**Result:** 实验结果表明，该方法在合成和真实世界基准数据集上优于最先进的（线性）特征提取和选择算法。令人惊讶的是，其线性特征提取算法与自动编码器、核PCA和UMAP等几种重要的非线性特征提取方法相比，性能相当且通常更优。此外，其中一种特征选择算法严格推广了最近的基于傅里叶的特征选择机制，且复杂性显著降低。

**Conclusion:** 本文提出的基于格拉姆-施密特正交化过程的线性特征提取和选择方法，在处理无监督学习中的非线性依赖性方面表现出色，不仅超越了现有线性算法，甚至能与复杂的非线性方法相媲美，且具有更低的复杂性，为特征工程提供了高效且有力的工具。

> **ai_Abstract:** 本文提出了一种基于函数空间上格拉姆-施密特（GS）型正交化过程的无监督特征提取和选择方法，旨在解决数据中非线性依赖性的问题。该方法通过构建协方差矩阵来识别新的大方差方向或消除已知方向的依赖性，并提供信息论保证。其线性特征提取方法是PCA的推广。实验证明，该方法在性能上优于现有线性算法，并能与多种重要的非线性特征提取方法相媲美甚至超越，同时其特征选择算法在降低复杂性的前提下推广了现有机制。

> **摘要翻译:** 在无监督学习中，数据间存在非线性依赖性时的特征提取和选择是一个根本性挑战。我们提出在函数空间上使用格拉姆-施密特（GS）型正交化过程来检测和映射此类依赖性。具体来说，通过在某个函数族上应用GS过程，我们构建了一系列协方差矩阵，这些矩阵既可以用于识别新的大方差方向，也可以用于从已知方向中移除这些依赖性。在前一种情况下，我们提供了熵减方面的信息论保证。在后一种情况下，我们提供了精确的条件，说明所选函数族如何消除数据中现有的冗余。每种方法都提供特征提取和特征选择算法。我们的特征提取方法是线性的，可以看作是主成分分析（PCA）的自然推广。我们提供了合成和真实世界基准数据集的实验结果，这些结果显示出比最先进的（线性）特征提取和选择算法更优越的性能。令人惊讶的是，我们的线性特征提取算法与自动编码器、核PCA和UMAP等几种重要的非线性特征提取方法相比，性能相当且通常更优。此外，我们的一种特征选择算法严格推广了最近的基于傅里叶的特征选择机制（Heidari et al., IEEE Transactions on Information Theory, 2022），但复杂性显著降低。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [284] [First-Order Error Matters: Accurate Compensation for Quantized Large Language Models](https://arxiv.org/abs/2507.11017)
> *一阶误差很重要：量化大型语言模型的精确补偿*

*Xingyu Zheng, Haotong Qin, Yuye Li, Jiakai Wang, Jinyang Guo, Michele Magno, Xianglong Liu* | **Category: cs.LG, cs.AI, cs.CL, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 后训练量化, 大型语言模型, 量化误差补偿, 一阶误差, FOEM

**Comment:** 

> **TL;DR:** 提出FOEM，一种新的后训练量化方法，通过显式补偿一阶误差显著提高了量化大型语言模型的性能。

**AI_Comments:** 这篇论文通过深入分析现有PTQ方法中对一阶误差的忽视，提出了一个新颖且有效的解决方案FOEM。其创新点在于明确引入一阶梯度补偿，并通过巧妙的梯度近似和Hessian逆恢复机制，在保持低计算开销的同时显著提升了量化性能。能够与现有SOTA方法兼容并进一步提高性能，显示了其强大的泛化性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于补偿的权重校准方法在建模量化误差时，假设一阶项在训练良好的全精度模型中可忽略，但本文揭示渐进式补偿过程引入累积的一阶偏差，使该假设存在根本缺陷。

**Method:** 提出FOEM，一种新的后训练量化（PTQ）方法，明确纳入一阶梯度项来改进量化误差补偿。FOEM通过直接计算潜在权重和全精度权重之间的差异来近似梯度，避免了反向传播的高成本和泛化限制。此外，FOEM利用预计算的Cholesky因子实时高效恢复Hessian子矩阵的逆。

**Result:** FOEM在广泛的模型和基准测试中持续优于经典的GPTQ方法。在3比特仅权重（weight-only）量化中，Llama3-8B的困惑度降低了89.6%，Llama3-70B的5-shot MMLU准确率从51.7%提高到74.9%，接近78.6%的全精度性能。FOEM还可以与GPTAQ和SpinQuant等先进技术无缝集成，在W4A4KV4设置下进一步提升性能，并缩小与全精度基线的准确性差距。

**Conclusion:** FOEM通过精确补偿量化过程中的一阶误差，显著提高了量化大型语言模型的性能，并且能够与现有先进技术结合以取得进一步提升。

> **ai_Abstract:** 本文提出FOEM，一种新的后训练量化（PTQ）方法，旨在解决现有补偿方法中忽略一阶误差的问题。FOEM通过直接计算潜在权重与全精度权重之间的差异来近似一阶梯度，并利用预计算的Cholesky因子高效恢复Hessian逆，从而实现精确的量化误差补偿。实验证明，FOEM在多种模型和基准测试上显著优于传统方法，并能与现有先进技术结合，进一步缩小量化模型与全精度模型之间的性能差距。

> **摘要翻译:** 后训练量化（PTQ）为压缩大型语言模型（LLM）提供了一种有效方法，显著降低了内存访问和计算成本。现有基于补偿的权重校准方法通常依赖二阶泰勒展开来建模量化误差，假设一阶项在训练良好的全精度模型中可以忽略不计。然而，我们揭示渐进式补偿过程在潜在权重和其全精度对应物之间引入了累积的一阶偏差，使得这一假设存在根本缺陷。为了解决这个问题，我们提出了FOEM，一种新颖的PTQ方法，它明确地包含了第一阶梯度项以改善量化误差补偿。FOEM通过直接计算潜在权重和全精度权重之间的差异来近似梯度，避免了基于反向传播的梯度计算的高成本和有限泛化能力。这种方法引入了最小的额外计算开销。此外，FOEM利用预计算的Cholesky因子实时高效地恢复Hessian子矩阵的逆。在广泛的模型和基准测试中进行的广泛实验表明，FOEM始终优于经典的GPTQ方法。在3比特仅权重（weight-only）量化中，FOEM将Llama3-8B的困惑度降低了89.6%，并将Llama3-70B的5-shot MMLU准确率从51.7%提高到74.9%，接近78.6%的全精度性能。此外，FOEM可以与GPTAQ和SpinQuant等先进技术无缝集成，在具有挑战性的W4A4KV4设置下产生额外的改进，并进一步缩小与当前最先进方法所能达到的全精度基线之间的准确性差距。代码可在https://github.com/Xingyu-Zheng/FOEM 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [289] [AdaMuon: Adaptive Muon Optimizer](https://arxiv.org/abs/2507.11005)
> *AdaMuon：自适应Muon优化器*

*Chongjie Si, Debing Zhang, Wei Shen* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** AdaMuon, Muon优化器, 自适应学习率, 优化器, 深度学习

**Comment:** 

> **TL;DR:** AdaMuon是一种基于Muon优化器的自适应学习率框架，通过引入两个新模块显著提升了收敛速度并保持了训练稳定性，且无需额外调参。

**AI_Comments:** AdaMuon的创新之处在于其通过引入两个独特模块（每参数二阶矩调制和RMS对齐重缩放）来增强Muon优化器的自适应性，特别是在处理正交梯度更新和调节整体更新幅度方面的设计。其重要性在于能够显著提升大型模型训练的收敛速度和稳定性，同时保持易用性（无需额外调参），这对于实际应用具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的Muon优化器在大型模型训练中已显示出比AdamW更高的效率，但仍有提升空间。作者旨在进一步优化Muon，提高其收敛速度和稳定性。

**Method:** 提出AdaMuon，一个基于Muon优化器的自适应学习率框架。它通过两个相互依赖的模块增强了Muon：1. 每参数二阶矩调制，捕获正交梯度更新以确保更新级别的自适应性；2. RMS对齐重缩放，通过与参数空间的内在结构对齐来调节整体更新幅度。

**Result:** 在多种模型规模和学习率制度下，AdaMuon始终优于原始Muon，在保持训练稳定性的同时提供了更高的收敛加速。

**Conclusion:** AdaMuon通过引入两个创新模块，显著提升了Muon优化器的性能，实现了更快的收敛和稳定的训练，且易于集成，无需额外调参。

> **ai_Abstract:** 本文提出了AdaMuon，一个基于Muon优化器的自适应学习率框架。AdaMuon通过引入每参数二阶矩调制和RMS对齐重缩放两个模块，增强了Muon的自适应能力。实验结果表明，AdaMuon在多种模型和学习率设置下均能显著加速收敛，同时保持训练稳定性，且无需额外调参。

> **摘要翻译:** 我们提出了AdaMuon，一个基于最近验证的Muon优化器的自适应学习率框架，Muon优化器在大型模型训练中已显示出比AdamW显著的效率提升。AdaMuon通过两个相互依赖的模块增强了Muon：(1) 一个每参数二阶矩调制，它捕获正交梯度更新以确保更新级别的自适应性；(2) 一个RMS对齐重缩放，通过将其与参数空间的内在结构对齐来调节整体更新幅度。在多种模型规模和学习率制度下的实证结果证实，AdaMuon始终优于原始Muon，在保持训练稳定性的同时提供了更高的收敛加速。我们的方法没有引入额外的调参负担，并且可以无缝集成到现有的Muon训练管道中。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [291] [Large Language Models Engineer Too Many Simple Features For Tabular Data](https://arxiv.org/abs/2410.17787)
> *大型语言模型为表格数据生成过多简单特征*

*Jaris Küken, Lennart Purucker, Frank Hutter* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 特征工程, 表格数据, 偏差, 预测性能

**Comment:** Accepted at the 3rd Table Representation Learning Workshop @ NeurIPS
  2024

> **TL;DR:** 大型语言模型在为表格数据进行特征工程时，倾向于生成过多简单特征，这可能对其预测性能产生负面影响，需要进行偏差缓解。

**AI_Comments:** 这项研究揭示了大型语言模型在特征工程领域的一个重要局限性，即倾向于生成过于简单的特征。这对于希望利用LLMs实现自动化数据科学的从业者来说是一个关键发现，因为它指出了LLMs在实际应用中可能面临的性能瓶颈。研究方法通过分析操作符频率来检测偏差具有创新性。其重要性在于提醒研究人员和开发者，在使用LLMs进行特征工程时，需要特别关注并解决这种内在偏差，以充分发挥LLMs的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 由于大型语言模型（LLMs）在其他应用中表现出负面偏差，作者旨在探究LLMs在特征工程中是否存在影响性能的偏差，尽管这种偏差不涉及伦理问题，但会阻碍LLMs在自动化数据科学中的应用。

**Method:** 研究提出了一种检测LLMs潜在偏差的方法，通过分析LLMs在特征工程中建议的运算符（如特征相加）的频率异常。实验评估了四种LLMs（两种大型前沿模型和两种小型开源模型）在27个表格数据集上的偏差。

**Result:** 实验结果表明，LLMs倾向于使用简单的运算符（如加法），而未能充分利用更复杂的运算符（如分组后聚合）。此外，这种偏差在使用LLM生成的特征时，可能对预测性能产生负面影响。

**Conclusion:** 研究结果表明，在使用大型语言模型进行特征工程时，需要采取措施缓解其偏差。

> **ai_Abstract:** 该研究调查了大型语言模型（LLMs）在表格数据特征工程中存在的偏差。作者提出了一种通过分析LLM建议运算符频率来检测偏差的方法，并在27个表格数据集上评估了四种LLM。结果显示，LLMs偏向于生成简单特征，忽视复杂操作，这种偏差会负面影响模型预测性能。因此，研究强调在使用LLMs进行特征工程时，缓解偏差的重要性。

> **摘要翻译:** 表格机器学习问题通常需要耗时且劳动密集型的特征工程。最近的研究致力于利用大型语言模型（LLMs）来发挥其潜在的领域知识。与此同时，研究人员在其他LLM相关用例（如文本生成）中观察到令人担忧的负面偏差。这些发展促使我们调查LLMs是否表现出负面影响特征工程性能的偏差。虽然不涉及伦理问题，但这种偏差可能会阻碍从业者充分利用LLMs进行自动化数据科学。因此，我们提出了一种通过检测LLMs在工程新特征时建议的运算符（例如，将两个特征相加）频率异常来检测潜在偏差的方法。我们的实验评估了四种LLMs（两种大型前沿模型和两种小型开源模型）在27个表格数据集上的偏差。我们的结果表明，LLMs偏向于简单的运算符，例如加法，并且可能无法利用更复杂的运算符，例如分组后聚合。此外，在使用LLM生成的特征时，这种偏差可能会对预测性能产生负面影响。我们的结果呼吁在使用LLMs进行特征工程时缓解偏差。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [296] [Group-wise oracle-efficient algorithms for online multi-group learning](https://arxiv.org/abs/2406.05287)
> *在线多组学习的组级预言机高效算法*

*Samuel Deng, Daniel Hsu, Jingwen Liu* | **Category: cs.LG, cs.GT, stat.ML** | **Updated: 2025-07-14**

**Keywords:** 在线多组学习, 预言机高效算法, 次线性遗憾, 公平性, 大规模组

**Comment:** Updated after NeurIPS 2024 camera-ready

> **TL;DR:** 本文为在线多组学习问题设计了预言机高效的算法，这些算法在组族过大无法枚举时，通过优化预言机访问组，并在多种设置下实现了次线性遗憾。

**AI_Comments:** 本文的创新点在于提出了“预言机高效”的算法来解决在线多组学习中组族过大无法显式枚举的问题，这对于公平性应用等领域具有重要意义。通过仅依赖优化预言机，该方法提高了在大规模组设置下的可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 传统在线多组学习方法在组族过大无法显式枚举时面临挑战。为了解决这一问题，需要设计能够通过优化预言机访问组的算法。

**Method:** 作者设计了预言机高效的算法，这些算法在统计独立同分布（i.i.d.）设置、具有平滑上下文分布的对抗性设置以及对抗性转导设置等多种场景下实现了次线性遗憾。

**Result:** 设计的算法在多种设置下实现了次线性遗憾，这些设置包括i.i.d.设置、具有平滑上下文分布的对抗性设置以及对抗性转导设置。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文研究了在线多组学习问题，旨在解决当组族过大无法显式枚举时，学习者需在多个组上同时实现小预测遗憾的挑战。作者提出了一系列预言机高效的算法，这些算法仅通过优化预言机访问组，并在独立同分布、具有平滑上下文分布的对抗性以及对抗性转导等多种设置下实现了次线性遗憾。

> **摘要翻译:** 我们研究了在线多组学习问题，这是一种学习模型，其中在线学习者必须在对应于一组组的大量（可能重叠的）子序列上同时实现小的预测遗憾。组是上下文空间的子集，在公平性应用中，它们可能对应于由人口统计属性的表达函数定义的子群体。与之前关于此学习模型的工作相反，我们考虑组族过大无法明确枚举的场景，因此我们寻求仅通过优化预言机访问组的算法。在本文中，我们设计了在各种设置下具有次线性遗憾的此类预言机高效算法，包括：（i）独立同分布（i.i.d.）设置，（ii）具有平滑上下文分布的对抗性设置，以及（iii）对抗性转导设置。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [307] [Meta-Reinforcement Learning for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks](https://arxiv.org/abs/2507.10619)
> *动态无线网络中用于快速和数据高效频谱分配的元强化学习*

*Oluwaseyi Giwa, Tobi Awodunmila, Muhammad Ahmed Mohsin, Ahsan Bilal, Muhammad Ali Jamshed* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-13**

**Keywords:** 元强化学习, 频谱分配, 动态无线网络, 5G/6G, 数据效率

**Comment:** 5 pages, 6 figures, under review at IEEE Wireless Communications
  Letters

> **TL;DR:** 元强化学习能有效且安全地在动态无线网络中实现快速、数据高效的频谱分配，显著优于传统深度强化学习。

**AI_Comments:** 本文提出了一种创新的元学习方法来解决动态无线网络中频谱分配的挑战，特别是在数据效率和安全性方面。其核心创新在于将元学习应用于无线资源管理，有效克服了传统DRL的局限性。实验结果的显著提升证明了其重要性，为未来5G/6G网络的智能控制提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 5G/6G网络中动态频谱分配对高效资源利用至关重要，但传统深度强化学习（DRL）因其巨大的样本复杂性和非引导探索带来的安全风险（可能导致严重网络干扰）而难以应用。

**Method:** 本文提出了一个元学习框架，旨在使智能体学习鲁棒的初始策略并以最少数据快速适应新的无线场景。研究中实现了三种元学习架构：模型无关元学习（MAML）、循环神经网络（RNN）和注意力增强型RNN，并在模拟的动态集成接入/回传（IAB）环境中，与非元学习DRL算法（近端策略优化（PPO）基线）进行了评估。

**Result:** 实验结果显示，基于注意力的元学习智能体实现了48 Mbps的峰值平均网络吞吐量，而PPO基线急剧下降至10 Mbps。此外，与PPO相比，该方法将SINR和延迟违规减少了50%以上，并显示出快速适应能力，公平性指数达到0.7，表明更好的资源分配。

**Conclusion:** 这项工作证明，元学习是复杂无线系统中智能控制的一种非常有效且更安全的选择。

> **ai_Abstract:** 本文针对5G/6G网络中传统深度强化学习在动态频谱分配中面临的样本复杂度和安全风险问题，提出了一种元学习框架。该框架通过MAML、RNN和注意力增强型RNN等架构，使智能体能快速适应新无线场景并学习鲁棒策略。实验结果表明，元学习方法在网络吞吐量、SINR/延迟违规和资源分配公平性方面显著优于传统的PPO基线，证明了其在复杂无线系统智能控制中的有效性和安全性。

> **摘要翻译:** 动态频谱分配在5G/6G网络中对于高效资源利用至关重要。然而，由于其巨大的样本复杂性和与非引导探索相关的安全风险（可能导致严重的网络干扰），应用传统的深度强化学习（DRL）通常不可行。为了解决这些挑战，我们提出了一个元学习框架，该框架使智能体能够学习一个鲁棒的初始策略并以最少的数据快速适应新的无线场景。我们实现了三种元学习架构：模型无关元学习（MAML）、循环神经网络（RNN）和注意力增强型RNN，并在模拟的动态集成接入/回传（IAB）环境中，与非元学习DRL算法（近端策略优化（PPO）基线）进行评估。我们的结果显示出明显的性能差距。基于注意力的元学习智能体达到了48 Mbps的峰值平均网络吞吐量，而PPO基线急剧下降到10 Mbps。此外，与PPO相比，我们的方法将SINR和延迟违规减少了50%以上。它还显示出快速适应能力，公平性指数为0.7，表明更好的资源分配。这项工作证明，元学习是复杂无线系统中智能控制的一种非常有效且更安全的选择。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [311] [DeInfoReg: A Decoupled Learning Framework for Better Training Throughput](https://arxiv.org/abs/2506.18193)
> *DeInfoReg：一种解耦学习框架，用于提高训练吞吐量*

*Zih-Hao Huang, You-Teng Lin, Hung-Hsuan Chen* | **Category: cs.LG, cs.AI, cs.DC** | **Updated: 2025-07-15**

**Keywords:** 解耦学习, 信息正则化, 梯度消失, 训练吞吐量, 模型并行化

**Comment:** 

> **TL;DR:** DeInfoReg通过将长梯度分解为短梯度流并利用多GPU并行化，有效缓解了梯度消失问题并显著提高了训练吞吐量。

**AI_Comments:** DeInfoReg的创新点在于将解耦学习与信息正则化相结合，通过梯度流分解和并行化策略，有效解决了深度学习中的梯度消失和训练效率问题，对于大规模模型训练具有重要的实际应用价值和研究意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了缓解梯度消失问题并显著提高训练吞吐量。

**Method:** 引入了带信息正则化的解耦监督学习（DeInfoReg），该方法将长梯度流转换为多个短梯度流，并集成了流水线策略以实现多GPU上的模型并行化。该方法与标准反向传播及其他梯度流分解技术进行了比较。

**Result:** DeInfoReg在广泛的实验中表现出优越的性能、更好的抗噪声能力，并且比传统反向传播模型更有效地利用并行计算资源。

**Conclusion:** DeInfoReg是一个有效的解耦学习框架，它通过解决梯度消失问题、提高训练吞吐量并提供卓越的性能和抗噪声能力，优于传统方法。

> **ai_Abstract:** DeInfoReg是一种创新的解耦监督学习框架，它通过将长梯度流分解为多个短梯度流并结合流水线策略实现多GPU并行化，旨在缓解梯度消失问题并显著提升训练吞吐量。实验证明，DeInfoReg在性能、抗噪声能力和并行计算资源利用方面均优于传统反向传播模型。

> **摘要翻译:** 本文介绍了带信息正则化的解耦监督学习（DeInfoReg），这是一种将长梯度流转换为多个短梯度流的新方法，从而缓解了梯度消失问题。DeInfoReg集成了流水线策略，实现了多GPU上的模型并行化，显著提高了训练吞吐量。我们将所提出的方法与标准反向传播和其他梯度流分解技术进行了比较。在不同任务和数据集上进行的广泛实验表明，与传统BP模型相比，DeInfoReg实现了卓越的性能和更好的抗噪声能力，并有效地利用了并行计算资源。可复现代码可在以下网址获取：https://github.com/ianzih/Decoupled-Supervised-Learning-for-Information-Regularization/。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [313] [Spatial Reasoners for Continuous Variables in Any Domain](https://arxiv.org/abs/2507.10768)
> *任意域中连续变量的空间推理器*

*Bart Pogodzinski, Christopher Wewer, Bernt Schiele, Jan Eric Lenssen* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-14**

**Keywords:** 空间推理, 连续变量, 去噪生成模型, 软件框架, 生成推理

**Comment:** For the project documentation see https://spatialreasoners.github.io/
  . The SRM project website is available at
  https://geometric-rl.mpi-inf.mpg.de/srm/ . The work was published on ICML
  2025 CODEML workshop

> **TL;DR:** 提出了一个名为 Spatial Reasoners 的软件框架，利用去噪生成模型对连续变量进行空间推理，旨在简化该领域的研究。

**AI_Comments:** 该论文的创新点在于提供了一个统一的软件框架，简化了使用复杂去噪生成模型进行连续变量空间推理的流程。其重要性在于降低了该领域的研究和开发门槛，使研究人员能够更便捷地探索去噪模型在推理任务中的潜力。框架的开源性也进一步增强了其影响力。

<details>
  <summary>Details</summary>

**Motivation:** 去噪生成模型在图像生成中表现出色，并开始用于多连续变量推理。然而，为使用此类模型进行生成推理提供基础设施需要付出巨大努力，因为存在各种不同的去噪公式、采样器和推理策略。

**Method:** 提出了一个名为 Spatial Reasoners 的软件框架，该框架利用生成去噪模型对连续变量进行空间推理。它提供易于使用的接口来控制来自任意数据域的变量映射、生成模型范式和推理策略，从而促进该领域的研究。

**Result:** 该框架名为 Spatial Reasoners，已开源可用。

**Conclusion:** 该框架通过提供易于使用的接口，显著降低了使用去噪生成模型进行连续变量空间推理的门槛，从而促进了相关研究。

> **ai_Abstract:** 本文介绍了 Spatial Reasoners，一个用于对连续变量进行空间推理的软件框架。该框架利用了在图像生成中表现出色的去噪生成模型，旨在解决为这类模型构建推理基础设施所面临的复杂性。它通过提供简易接口来管理变量映射、模型范式和推理策略，从而大大降低了研究门槛，并已开源。

> **摘要翻译:** 我们提出了 Spatial Reasoners，这是一个软件框架，用于利用生成去噪模型对连续变量进行空间推理。去噪生成模型因其在从复杂、高维分布中采样的有效性而成为图像生成的实际标准。最近，它们已开始在多个连续变量推理的背景下被探索。为使用此类模型进行生成推理提供基础设施需要付出巨大努力，因为存在各种不同的去噪公式、采样器和推理策略。我们提出的框架旨在促进该领域的研究，提供易于使用的接口来控制来自任意数据域的变量映射、生成模型范式和推理策略。Spatial Reasoners 已在 https://spatialreasoners.github.io/ 开源可用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [316] [ComFairGNN: Community Fair Graph Neural Network](https://arxiv.org/abs/2411.04371)
> *ComFairGNN: 社区公平图神经网络*

*Yonas Sium, Qi Li* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 图神经网络, 公平性, 偏见缓解, 社区级偏见, coreset

**Comment:** PAKDD 2025

> **TL;DR:** 图神经网络（GNNs）可能产生偏见预测，现有去偏方法评估不足。本文提出了一种社区级偏见衡量策略，并引入ComFairGNN框架，通过可学习的基于coreset的去偏函数，有效缓解GNN中的社区级偏见，并在准确性和公平性上表现出色。

**AI_Comments:** 本文的创新点在于提出了社区级偏见衡量策略，这比以往过度简化的公平性评估指标更具深度和实用性。ComFairGNN框架通过引入可学习的基于coreset的去偏函数，从根本上解决了GNN邻域聚合过程中的偏见来源，对于提升GNN的公平性具有重要意义。该研究不仅提出了新的去偏方法，还关注了公平性评估的准确性，具有较高的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNNs）在实际应用中可能由于节点属性和邻居而对特定人口子群产生有偏预测。当前大多数GNN公平性研究使用过度简化的公平性评估指标，可能导致误导性的公平印象。因此，理解图结构复杂性导致的潜在评估悖论对于开发有效的GNN去偏机制至关重要。

**Method:** 本文首先检查了现有GNN去偏方法在不公平性评估方面的有效性。具体地，引入了一种社区级策略来衡量GNN中的偏见，并在此级别评估去偏方法。此外，提出了ComFairGNN，一个旨在缓解GNN中社区级偏见的新颖框架。该方法采用可学习的基于coreset的去偏函数，以解决GNN邻域聚合过程中由不同局部邻域分布引起的偏见。

**Result:** 在三个基准数据集上的综合评估表明，所提出的模型在准确性和公平性指标方面均有效。

**Conclusion:** ComFairGNN通过引入社区级偏见衡量和可学习的基于coreset的去偏函数，能够有效缓解图神经网络中的社区级偏见，并在准确性和公平性上表现出色。

> **ai_Abstract:** 本文关注图神经网络（GNNs）在实际应用中可能存在的偏见问题，并指出现有去偏方法在公平性评估上存在不足。为解决此问题，研究提出了一种社区级策略来衡量GNN中的偏见，并在此基础上评估去偏方法。进一步，引入了名为ComFairGNN的新型框架，该框架通过采用可学习的基于coreset的去偏函数，旨在缓解GNN邻域聚合过程中因局部邻域分布差异引起的社区级偏见。在三个基准数据集上的实验结果表明，ComFairGNN在准确性和公平性上均表现出有效性。

> **摘要翻译:** 图神经网络（GNNs）已成为解决各种现实世界场景中图分析问题的主导方法。然而，GNNs可能会由于节点属性和围绕节点的邻居而对某些人口子群产生有偏预测。当前大多数关于GNN公平性的研究主要集中于使用过度简化的公平性评估指标来消除GNN的偏见，这可能会给人一种误导性的公平印象。理解由于图结构的复杂性而导致的潜在评估悖论对于开发有效的GNN去偏机制至关重要。在本文中，我们检查了当前GNN去偏方法在不公平性评估方面的有效性。具体来说，我们引入了一种社区级策略来衡量GNN中的偏见，并在此级别评估去偏方法。此外，我们引入了ComFairGNN，一个旨在缓解GNN中社区级偏见的新颖框架。我们的方法采用了一种可学习的基于coreset的去偏函数，该函数解决了GNN邻域聚合过程中由不同局部邻域分布引起的偏见。在三个基准数据集上的综合评估证明了我们模型在准确性和公平性指标方面的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [321] [LaCoOT: Layer Collapse through Optimal Transport](https://arxiv.org/abs/2406.08933)
> *LaCoOT: 基于最优传输的层折叠*

*Victor Quétu, Zhu Liao, Nour Hezbri, Fabio Pizzati, Enzo Tartaglione* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 深度神经网络, 最优传输, 层折叠, 计算效率, Wasserstein距离

**Comment:** ICCV25

> **TL;DR:** 本文提出了一种基于最优传输的方法，通过最小化网络中间特征分布之间的距离，实现深度神经网络的层折叠，从而减少计算负担并提高性能/深度权衡。

**AI_Comments:** 本文提出了一种新颖的基于最优传输的方法，通过正则化中间特征分布来直接实现深度神经网络的层折叠，这在模型压缩领域具有创新性。其通过“完全移除”中间层的能力，可能为模型轻量化提供了新的思路，超越了传统的剪枝和量化方法，具有重要的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络虽然性能出色，但其对计算资源的需求巨大，导致能耗高且难以部署在资源受限设备上，这阻碍了它们的广泛应用。

**Method:** 本文提出了一种基于最优传输的方法来减少过参数化深度神经网络的深度。具体来说，提出了一种基于最大切片Wasserstein距离的新正则化策略，以最小化神经网络中中间特征分布之间的距离。作者指出，最小化这个距离可以完全移除网络中的中间层。

**Result:** 该方法在性能/深度权衡方面优于现有技术。其有效性在传统图像分类设置中得到了评估，并扩展到生成图像模型。

**Conclusion:** 通过基于最优传输的层折叠方法，可以有效减少深度神经网络的计算负担，并在性能和深度之间取得更好的平衡。

> **ai_Abstract:** 本文提出了一种名为LaCoOT的新方法，利用最优传输技术来解决深度神经网络计算资源消耗大的问题。通过引入基于最大切片Wasserstein距离的正则化策略，该方法旨在最小化网络中间层特征分布的距离，从而实现中间层的完全移除，有效降低网络深度和计算负担。实验证明，LaCoOT在图像分类和生成模型任务上均能提供比现有技术更好的性能与深度权衡。

> **摘要翻译:** 尽管深度神经网络以其在处理复杂任务方面的出色表现而闻名，但它们对计算资源的渴望仍然是一个重大障碍，导致能耗问题并限制了它们在资源受限设备上的部署，从而阻碍了它们的广泛采用。在本文中，我们提出了一种基于最优传输的方法来减少过参数化深度神经网络的深度，从而减轻其计算负担。更具体地说，我们提出了一种基于最大切片Wasserstein距离的新正则化策略，以最小化神经网络中中间特征分布之间的距离。我们表明，最小化这个距离可以完全移除网络中的中间层，与现有技术相比，实现了更好的性能/深度权衡。我们在传统图像分类设置中评估了我们方法的有效性，并将其扩展到生成图像模型。我们的代码可在https://github.com/VGCQ/LaCoOT上获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [329] [Leveraging Advanced Machine Learning to Predict Turbulence Dynamics from Temperature Observations at an Experimental Prescribed Fire](https://arxiv.org/abs/2507.11012)
> *利用先进机器学习从实验性计划火灾的温度观测中预测湍流动力学*

*Dipak Dulal, Joseph J. Charney, Michael R. Gallagher, Pitambar Acharya, Carmeliza Navasca, Nicholas S. Skowronski* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 机器学习, 湍流动能, 温度观测, 计划火灾, 火灾预测

**Comment:** arXiv admin note: text overlap with arXiv:2311.05128

> **TL;DR:** 本研究利用机器学习模型，通过温度数据成功预测了实验性计划火灾中的湍流动能，展示了机器学习在火灾研究和管理中的潜力。

**AI_Comments:** 这项研究创新性地将先进机器学习技术应用于火灾湍流预测，解决了传统方法难以从易获取数据中提取复杂关系的问题。其重要性在于提供了一种新的数值方法来理解火灾动力学，可能显著改进火灾管理策略和模型预测精度。然而，抽象中未详细说明模型的泛化能力和在不同火灾场景下的适用性，这可能是未来研究需要关注的限制。

<details>
  <summary>Details</summary>

**Motivation:** 旨在探索利用更易获取的温度数据来预测湍流动能（TKE）的可能性，并识别温度与火灾环境中气流过程之间的新关系，以改进火灾操作策略和模型预测。

**Method:** 在新泽西州松林地区的小型实验性计划烧除中，同步收集了10 Hz的温度剖面和湍流数据。采用了包括深度神经网络、随机森林回归、梯度提升和高斯过程回归在内的机器学习模型，评估从温度扰动预测TKE的潜力，并探索相关性的时空动态。

**Result:** 尽管预测因子与目标变量之间相关性较弱，但通过各种机器学习模型实现了更准确的TKE预测，特别是回归模型表现出显著成功。数据可视化和相关性分析揭示了热电偶温度与TKE之间的模式和关系。

**Conclusion:** 本研究证明了利用机器学习方法从温度数据预测湍流动力学的可行性，为识别火灾环境中温度和气流过程的新关系提供了一种新颖的数值方法。这些发现有助于加深对燃烧环境过程的理解，并提升火灾操作策略和模型预测能力，同时强调了机器学习在分析复杂火灾环境大数据中的重要作用。

> **ai_Abstract:** 本研究利用机器学习模型（包括DNN、随机森林等）通过易获取的温度数据成功预测了实验性计划火灾中的湍流动能（TKE）。尽管温度与TKE的直接关联较弱，但模型仍实现了高精度预测，揭示了火灾环境中温度与气流的新关系。这为改进火灾管理和模型预测提供了新方法，并突显了机器学习在处理复杂火灾大数据中的价值。

> **摘要翻译:** 本研究探讨了在新泽西州松林地区进行的一次小型实验性计划烧除中，利用同步以10赫兹频率收集的温度剖面和湍流数据，通过更易获取的温度数据预测湍流动能（TKE）的潜力。研究采用了包括深度神经网络、随机森林回归、梯度提升和高斯过程回归在内的机器学习模型，以评估从温度扰动预测TKE的潜力，并探索相关性的时空动态。数据可视化和相关性分析揭示了热电偶温度与TKE之间的模式和关系，为底层动力学提供了深入见解。尽管预测因子与目标变量之间相关性较弱，但通过各种机器学习模型实现了更准确的TKE预测。结果表明，特别是回归模型在准确预测TKE方面取得了显著成功。本研究的发现展示了一种识别火灾环境内部及周边温度与气流过程之间新颖关系的新数值方法。这些关系有助于完善我们对燃烧环境过程以及火灾环境过程耦合和解耦的理解，这对于改进火灾操作策略和火灾与烟雾模型预测至关重要。本研究的发现还强调了机器学习技术在分析火灾环境复杂大数据集方面的宝贵作用，展示了其推动火灾研究和管理实践的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [336] [The Pragmatic Frames of Spurious Correlations in Machine Learning: Interpreting How and Why They Matter](https://arxiv.org/abs/2411.04696)
> *机器学习中虚假相关性的实用框架：解释它们如何以及为何重要*

*Samuel J. Bell, Skyler Wang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 虚假相关性, 机器学习, 实用框架, 相关性评估, 概念演变

**Comment:** 

> **TL;DR:** 本文探讨了机器学习研究中虚假相关性的概念如何从传统统计定义演变为基于实际应用和规范目标的“实用框架”，并识别出四种这样的框架：相关性、泛化性、类人性和危害性。

**AI_Comments:** 本文的创新之处在于提出了“实用框架”这一概念，用以解释机器学习领域中对虚假相关性的实际评估方式，而非仅仅停留在统计定义层面。这揭示了机器学习实践中技术、认知和伦理考量如何共同塑造核心概念的理解。该研究对于理解AI系统的鲁棒性、公平性和可解释性具有重要意义，因为它强调了在实际应用中，对相关性的判断是多维且情境化的，而不仅仅是简单的因果或非因果关系。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习和人工智能研究的基础是学习数据中的相关性，但现代方法容易捕获到意想不到的虚假相关性。这种脆弱性促使人们对虚假性产生兴趣，因为它被视为对模型性能、公平性和鲁棒性的威胁。本文旨在探讨机器学习研究中虚假相关性概念的演变及其实际意义。

**Method:** 作者通过对机器学习文献的广泛调查，识别并分析了研究人员如何评估虚假相关性，特别是超越了传统的统计定义，提出了“实用框架”的概念，并归纳出四种具体的框架。

**Result:** 研究发现，机器学习研究中对虚假相关性的理解已经偏离了传统的统计定义（偶然或混淆导致的非因果关系）。研究人员通过“实用框架”来评估虚假相关性，即基于相关性在实践中的作用及其对模型行为、任务性能和规范目标的影响。论文识别出四种这样的框架：相关性、泛化性、类人性和危害性。这些框架揭示了相关性的期望性并非固定的统计属性，而是受技术、认知和伦理考量影响的判断。

**Conclusion:** 虚假相关性在机器学习中的“好坏”并非一个固定的统计属性，而是一个情境化的判断，它受到技术、认知和伦理等多方面因素的影响。通过审视机器学习中这一基本难题在研究文献中是如何被问题化的，本文有助于更广泛地讨论技术概念（如虚假性）被定义和操作化的偶然实践。

> **ai_Abstract:** 本文探讨了机器学习中“虚假相关性”的概念。不同于传统的统计定义，研究人员在实践中通过“实用框架”来评估虚假性，即基于相关性如何影响模型行为、任务性能和规范目标。文章通过文献调研识别出四种主要框架：相关性、泛化性、类人性和危害性，揭示了相关性的可取性是一个情境化的、受技术、认知和伦理因素影响的判断。这有助于理解机器学习中核心概念的动态定义和操作。

> **摘要翻译:** 从数据中学习相关性构成了当今机器学习（ML）和人工智能（AI）研究的基础。尽管当代方法能够自动发现复杂的模式，但当捕获到意想不到的相关性时，它们容易失效。这种脆弱性激发了人们对探究虚假性的日益增长的兴趣，虚假性通常被视为对模型性能、公平性和鲁棒性的威胁。在本文中，我们追溯了与虚假性传统统计定义（指由巧合或混淆引起的非因果关系）的偏离，以研究其含义在ML研究中是如何被协商的。研究人员不再仅仅依赖形式定义，而是通过我们称之为实用框架来评估虚假性：基于相关性在实践中的作用——它如何影响模型行为、支持或阻碍任务性能，或与更广泛的规范目标保持一致——进行判断。借鉴对ML文献的广泛调查，我们确定了四个这样的框架：相关性（“模型应使用与任务相关的相关性”）、泛化性（“模型应使用可泛化到未见数据的相关性”）、类人性（“模型应使用人类会用来执行相同任务的相关性”）和危害性（“模型应使用无社会或伦理危害的相关性”）。这些表述表明，相关性的期望性并非固定的统计属性，而是一个受技术、认知和伦理考量影响的、情境化的判断。通过审视ML中一个基础性难题在研究文献中是如何被问题化的，我们为关于技术概念（如虚假性）被定义和操作化的偶然实践的更广泛对话做出了贡献。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [341] [Contrast All the Time: Learning Time Series Representation from Temporal Consistency](https://arxiv.org/abs/2410.15416)
> *对比所有时间：从时间一致性中学习时间序列表示*

*Abdul-Kazeem Shamba, Kerstin Bach, Gavin Taylor* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 时间序列表示学习, 对比学习, 无监督学习, NT-pair, CaTT

**Comment:** Published in the 28th European Conference on AI (ECAI), October 2025

> **TL;DR:** CaTT是一种新的无监督时间序列对比学习方法，通过并行对比所有时间步，利用时间相似瞬间的动态性，无需数据增强或视图选择，实现更快更好的表示学习。

**AI_Comments:** CaTT的创新之处在于其摒弃了传统时间序列对比学习中对数据增强或视图选择的依赖，转而通过并行对比所有时间步，并引入NT-pair公式，直接利用时间序列的内在结构进行学习。这不仅简化了学习过程，还提高了效率和性能，使其在大规模时间序列应用中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的时间序列对比学习方法依赖数据增强或选定视图，效率和效果有待提升。本文旨在提出一种更有效、更高效的方法来利用时间序列中时间相似瞬间的动态性。

**Method:** 本文提出CaTT (Contrast All The Time)，一种新的无监督时间序列对比学习方法。它不依赖数据增强或选定视图，而是通过可扩展的NT-pair公式，并行对比所有时间步，将经典的N-pair损失扩展到批次和时间维度，从而实现端到端且高效的学习过程。CaTT利用重复或相邻时间步作为隐式监督，直接从时间数据的自然结构中学习。

**Result:** CaTT生成了更优的嵌入（embeddings），从而在下游任务中实现了更好的性能。此外，CaTT的训练速度比其他对比学习方法更快，适用于大规模和真实世界的时间序列应用。

**Conclusion:** CaTT通过其独特的所有时间步并行对比和NT-pair公式，提供了一种无需数据增强或视图选择的、更高效且高性能的时间序列表示学习方法，证明了其在实际应用中的潜力。

> **ai_Abstract:** 本文提出CaTT，一种新颖的无监督时间序列对比学习方法。CaTT通过并行对比所有时间步，并利用可扩展的NT-pair公式，直接从时间序列的自然结构中学习表示，无需数据增强或视图选择。实验证明，CaTT生成了更优的嵌入，提高了下游任务性能，并且训练速度更快，适用于大规模应用。

> **摘要翻译:** 时间序列的对比学习表示已成为提高下游任务性能的关键技术。为了推进这种有效方法，我们引入了CaTT（Contrast All The Time），一种新的时间序列无监督对比学习方法，它比现有方法更高效、更有效地利用时间相似瞬间之间的动态性。CaTT不同于依赖数据增强或选定视图的传统时间序列对比方法。相反，它通过并行对比所有时间步来使用完整的时间维度。这得益于可扩展的NT-pair公式，该公式将经典的N-pair损失扩展到批次和时间维度，使学习过程端到端且更高效。CaTT直接从时间数据的自然结构中学习，使用重复或相邻时间步作为隐式监督，无需配对选择启发式方法。我们证明了这种方法产生了更优的嵌入，从而在下游任务中实现了更好的性能。此外，训练速度比其他对比学习方法更快，使其适用于大规模和真实世界的时间序列应用。源代码可在https://github.com/sfi-norwai/CaTT公开获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [354] [GATE: Graph Attention Neural Networks with Real-Time Edge Construction for Robust Indoor Localization using Mobile Embedded Devices](https://arxiv.org/abs/2507.11053)
> *GATE：用于使用移动嵌入式设备的鲁棒室内定位的实时边缘构建图注意力神经网络*

*Danish Gufran, Sudeep Pasricha* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 室内定位, 图神经网络, Wi-Fi RSS, 实时边缘构建, 设备异构性

**Comment:** 

> **TL;DR:** GATE是一个新的图神经网络框架，通过实时边缘构建和注意力机制，显著提高了移动设备在复杂室内环境下的定位精度，解决了现有方法的噪声和设备异构性问题。

**AI_Comments:** GATE的创新之处在于其对图结构的动态适应能力（RTEC）以及通过AHV和MDHV处理非欧几里得噪声和GNN盲点，这对于提升室内定位在复杂真实环境下的鲁棒性和泛化能力至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习模型在Wi-Fi RSS指纹定位中未考虑空间关系和非均匀噪声分布，导致在异构设备上泛化能力差。图神经网络虽有改进，但仍受非欧几里得噪声和GNN盲点问题影响，在AP密集环境中精度下降。

**Method:** 本文提出了GATE框架，通过构建指纹向量的自适应图表示，同时保留室内状态空间拓扑，并建模RSS噪声的非欧几里得结构以减轻环境噪声和解决设备异构性。GATE引入了1) 新的注意力超空间向量（AHV）用于增强消息传递；2) 新的多维超空间向量（MDHV）以缓解GNN盲点问题；3) 新的实时边缘构建（RTEC）方法用于动态图适应。

**Result:** 在多变室内环境（不同路径长度、AP密度、异构设备）的广泛真实世界评估中，GATE的平均定位误差降低了1.6倍至4.72倍，最差情况误差降低了1.85倍至4.57倍，优于现有最先进的室内定位框架。

**Conclusion:** GATE通过其创新的图构建和向量表示方法，有效解决了室内定位中的噪声、设备异构性和GNN盲点问题，显著提高了定位精度和鲁棒性。

> **ai_Abstract:** 本文提出了GATE，一个用于室内定位的新型图注意力神经网络框架。针对Wi-Fi RSS指纹识别在异构设备和复杂噪声环境下精度不足的问题，GATE通过构建自适应图表示，并引入注意力超空间向量、多维超空间向量和实时边缘构建方法，有效建模非欧几里得噪声并缓解GNN盲点。实验结果表明，GATE显著降低了定位误差，表现优于现有方法。

> **摘要翻译:** 精确的室内定位对于智能环境和导航系统中的空间上下文至关重要。Wi-Fi接收信号强度（RSS）指纹识别由于与移动嵌入式设备的兼容性而成为一种广泛使用的室内定位方法。深度学习（DL）模型通过学习不同位置的RSS变化来提高定位任务的准确性，但它们假设指纹向量存在于欧几里得空间中，未能结合空间关系和真实世界RSS噪声的非均匀分布。这导致在异构移动设备上泛化能力差，因为硬件和信号处理的变化会扭曲RSS读数。图神经网络（GNN）可以通过将室内位置编码为节点并将它们的空间和信号关系建模为边缘来改进传统的DL模型。然而，GNN难以处理非欧几里得噪声分布，并受到GNN盲点问题的影响，导致在接入点（AP）密集的D环境中的精度下降。为了解决这些挑战，我们提出了GATE，一个新颖的框架，它构建了指纹向量的自适应图表示，同时保留了室内状态空间拓扑，建模RSS噪声的非欧几里得结构以减轻环境噪声并解决设备异构性。GATE引入了1）一种新颖的注意力超空间向量（AHV）用于增强消息传递，2）一种新颖的多维超空间向量（MDHV）以缓解GNN盲点，以及3）一种新的实时边缘构建（RTEC）方法用于动态图适应。在具有不同路径长度、AP密度和异构设备的多个室内空间的广泛真实世界评估表明，与最先进的室内定位框架相比，GATE实现了1.6倍至4.72倍的平均定位误差降低和1.85倍至4.57倍的最差情况误差降低。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [356] [Searching Latent Program Spaces](https://arxiv.org/abs/2411.08706)
> *搜索潜在程序空间*

*Matthew V Macfarlane, Clément Bonnet* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 潜在程序网络, 程序合成, 深度学习, 测试时搜索, 泛化

**Comment:** Code available at https://github.com/clement-bonnet/lpn

> **TL;DR:** LPN提出了一种新的架构，将测试时搜索直接构建到神经网络中，通过学习隐式程序的潜在空间，结合了符号方法的可适应性和神经网络的可扩展性，在编程示例任务和ARC-AGI基准测试中表现出色。

**AI_Comments:** LPN的创新之处在于它将测试时搜索直接集成到神经网络中，有效地弥合了符号AI与深度学习之间的鸿沟。这种方法避免了传统程序合成对人工DSL的依赖，并为深度学习模型提供了更强的测试时适应性。其在OOD任务上的性能提升，展示了其在实现更通用智能方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 通用智能系统在获取新技能和泛化方面面临挑战。程序合成方法虽然泛化能力强，但由于组合空间大而难以扩展，需要人工DSL或预训练先验。深度学习方法虽然成功，但缺乏结构化的测试时适应性，依赖昂贵的采样或梯度更新进行微调。

**Method:** 本文提出了潜在程序网络（LPN），这是一种将测试时搜索直接构建到神经网络中的新架构。LPN通过学习隐式程序（将输入映射到输出）的潜在空间，并能在测试时使用梯度进行搜索。它结合了符号方法的可适应性和神经网络的可扩展性，通过紧凑的潜在空间进行搜索，绕过了预定义领域特定语言的需求。

**Result:** LPN在编程示例任务上，与上下文学习和测试时训练方法相比，性能要么超越要么匹配。在ARC-AGI基准测试中，LPN能够学习紧凑的程序空间并在测试时通过搜索来适应新任务。当测试时搜索开启时，LPN在分布外任务上的性能翻倍。

**Conclusion:** LPN通过将测试时搜索集成到神经网络中，有效地结合了符号方法的适应性和神经网络的可扩展性，解决了现有方法在泛化和扩展性方面的局限性，并在多项任务上展现出优越的性能。

> **ai_Abstract:** 本文提出了一种名为潜在程序网络（LPN）的新架构，旨在解决程序合成和深度学习方法在通用智能系统构建中的局限性。LPN将测试时搜索能力直接嵌入到神经网络中，通过学习隐式程序的紧凑潜在空间，利用梯度在测试时进行搜索。这种方法结合了符号方法的适应性和神经网络的可扩展性，克服了传统程序合成中对领域特定语言的依赖。实验结果表明，LPN在编程示例任务中表现优异或与现有方法持平，并在ARC-AGI基准测试中证明了其学习和适应新任务的能力，特别是在开启测试时搜索后，其在分布外任务上的性能显著提升。

> **摘要翻译:** 通用智能需要系统能够高效地获取新技能并泛化到训练分布之外。尽管程序合成方法具有强大的泛化能力，但它们面临扩展性问题，因为巨大的组合空间很快使其变得不切实际，并且需要人工生成的DSL或预训练先验来缩小搜索空间。另一方面，深度学习方法取得了巨大成功，但它们缺乏结构化的测试时适应性，并且依赖于大量的随机采样或昂贵的梯度更新来进行微调。在这项工作中，我们提出了潜在程序网络（LPN），这是一种将测试时搜索直接构建到神经网络中的新架构。LPN通过学习隐式程序（通过神经网络将输入映射到输出）的潜在空间，从而能够在测试时使用梯度进行搜索。LPN结合了符号方法的可适应性和神经网络方法的可扩展性。它在测试时通过紧凑的潜在空间进行搜索，并绕过了对预定义领域特定语言的需求。在一系列通过示例编程的任务上，LPN的性能要么超越要么匹配上下文学习和测试时训练方法。在ARC-AGI基准测试中，我们证明LPN既可以学习紧凑的程序空间，又可以在测试时通过搜索来适应新任务。当测试时搜索开启时，LPN在分布外任务上的性能翻倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [357] [LLMs Meet Cross-Modal Time Series Analytics: Overview and Directions](https://arxiv.org/abs/2507.10620)
> *大型语言模型与跨模态时间序列分析：概述与方向*

*Chenxi Liu, Hao Miao, Cheng Long, Yan Zhao, Ziyue Li, Panos Kalnis* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-13**

**Keywords:** 大型语言模型, 跨模态, 时间序列分析, 教程, 模态融合

**Comment:** Accepted at SSTD 2025 (Tutorial). arXiv admin note: text overlap with
  arXiv:2505.02583

> **TL;DR:** 本教程概述了大型语言模型（LLMs）在跨模态时间序列分析中的应用、现有方法（分类为转换、对齐、融合）、应用案例、开放挑战及未来方向，旨在弥合文本与时间序列之间的模态鸿沟。

**AI_Comments:** 本文作为一篇教程，其价值在于系统性地梳理了LLMs在跨模态时间序列分析这一新兴且重要的交叉领域中的应用现状。提出的分类法（转换、对齐、融合）对于理解和组织现有研究具有指导意义。同时，对开放挑战的总结为未来的研究指明了方向，有助于弥合LLMs在处理非文本数据时的固有局限性。其创新性在于将LLMs的强大能力与时间序列分析的复杂性相结合，并关注跨模态问题。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在时间序列分析中展现出潜力，但由于其主要基于文本语料库训练，时间序列数据与文本数据之间存在跨模态鸿沟，LLMs未能针对时间序列进行优化。本教程旨在解决这一问题，扩展LLMs在跨模态时间序列分析中的实际应用。

**Method:** 本教程提供了一个关于基于LLM的跨模态时间序列分析的最新概述。它引入了一个分类法，根据跨模态建模策略（如转换、对齐和融合）将现有方法分为三类，并讨论了它们在一系列下游任务中的应用。此外，教程还总结了几个开放挑战。

**Result:** 旨在扩展LLMs在解决跨模态时间序列分析中实际问题的应用，同时平衡有效性和效率。参与者将对当前进展、方法论和未来研究方向有透彻的理解。

**Conclusion:** 教程旨在通过概述当前进展、分类现有方法和指出开放挑战，促进LLMs在跨模态时间序列分析领域的实际应用，并指导未来研究方向。

> **ai_Abstract:** 本教程全面概述了大型语言模型（LLMs）在跨模态时间序列分析中的应用。它首先指出LLMs在时间序列分析中的潜力及其与文本数据之间的跨模态鸿沟。接着，教程提出了一个分类法，将现有方法按转换、对齐和融合等策略进行分类，并探讨了它们在不同任务中的应用。最后，教程总结了该领域的开放挑战，旨在推动LLMs在该领域的实际应用，并为研究人员提供全面的理解。

> **摘要翻译:** 大型语言模型（LLMs）已成为时间序列分析的一个有前景的范式，它们利用其庞大的参数和文本与时间序列数据共享的顺序特性。然而，时间序列数据和文本数据之间存在跨模态鸿沟，因为LLMs是在文本语料库上预训练的，并非天生为时间序列优化。在本教程中，我们提供了基于LLM的跨模态时间序列分析的最新概述。我们引入了一个分类法，根据跨模态建模策略（例如，转换、对齐和融合）将现有方法分为三组，然后讨论它们在一系列下游任务中的应用。此外，我们总结了几个开放挑战。本教程旨在扩大LLMs在解决跨模态时间序列分析中实际问题的实际应用，同时平衡有效性和效率。参与者将对跨模态时间序列分析的当前进展、方法论和未来研究方向有透彻的理解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [358] [A Generalizable Physics-Enhanced State Space Model for Long-Term Dynamics Forecasting in Complex Environments](https://arxiv.org/abs/2507.10792)
> *复杂环境下长期动态预测的可泛化物理增强状态空间模型*

*Yuchen Wang, Hongjue Zhao, Haohong Lin, Enze Xu, Lifang He, Huajie Shao* | **Category: cs.LG** | **Updated: 2025-07-14**

**Keywords:** 物理增强, 状态空间模型, 长期预测, 复杂环境, 泛化能力

**Comment:** 8 pages, 6 figures, accepted in ICML 2025

> **TL;DR:** Phy-SSM是一种结合物理知识的状态空间模型，用于在数据噪声和不规则采样的复杂环境中进行长期动态预测，并在实际应用中表现出色。

**AI_Comments:** 该论文的创新点在于将部分物理知识巧妙地融入到状态空间模型中，以提升模型在复杂环境下的长期动态预测能力和泛化性。通过分解系统动力学和引入物理状态正则化，有效解决了数据噪声和不规则采样带来的挑战，在多个实际应用中展现了其优越性，为长期预测问题提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在处理复杂场景下的长期外推任务时面临重大挑战，尤其是在数据嘈杂和不规则采样的情况下。研究旨在通过将物理知识融入状态空间模型来提高模型泛化能力和长期预测性能。

**Method:** 提出Phy-SSM模型，将部分物理知识集成到状态空间模型（SSMs）中。具体方法包括：将部分已知的系统动力学分解为已知和未知的状态矩阵，并将其集成到Phy-SSM单元中；引入物理状态正则化项，使估计的潜在状态与系统动力学对齐。同时，理论分析了解决方案的唯一性。

**Result:** 在车辆运动预测、无人机状态预测和COVID-19流行病学预测三个实际应用中的广泛实验表明，Phy-SSM在长期插值和外推任务中均优于基线方法。

**Conclusion:** Phy-SSM通过将部分物理知识融入状态空间模型，有效解决了复杂环境下长期动态预测的挑战，并在实际应用中展现出优越的性能和泛化能力。

> **ai_Abstract:** 该论文提出了一种名为Phy-SSM的可泛化物理增强状态空间模型，旨在解决复杂环境下数据嘈杂和不规则采样时的长期动态预测问题。Phy-SSM通过将部分物理知识（分解为已知和未知状态矩阵）集成到状态空间模型中，并引入物理状态正则化项来增强预测性能和泛化能力。实验结果表明，该模型在车辆运动、无人机状态和COVID-19流行病学预测等实际应用中，在长期插值和外推任务上均优于现有基线方法。

> **摘要翻译:** 这项工作旨在解决复杂环境中长期动态预测的问题，其中数据嘈杂且采样不规则。尽管最近的研究引入了一些方法来提高预测性能，但这些方法在处理此类复杂场景下的长期外推任务时仍面临重大挑战。为了克服这一挑战，我们提出了Phy-SSM，一种可泛化方法，它将部分物理知识集成到状态空间模型（SSMs）中，用于复杂环境下的长期动态预测。我们的动机是SSMs可以有效地捕获序列数据中的长程依赖关系并建模连续动力学系统，而物理知识的结合则提高了泛化能力。关键挑战在于如何将部分已知的物理无缝地融入SSMs。为此，我们将部分已知的系统动力学分解为已知和未知的状态矩阵，并将其集成到Phy-SSM单元中。为了进一步增强长期预测性能，我们引入了一个物理状态正则化项，以使估计的潜在状态与系统动力学对齐。此外，我们理论分析了我们方法解决方案的唯一性。对车辆运动预测、无人机状态预测和COVID-19流行病学预测这三个实际应用的广泛实验表明，Phy-SSM在长期插值和外推任务中均优于基线方法。代码可在https://github.com/511205787/Phy_SSM-ICML2025获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [359] [Relative Entropy Pathwise Policy Optimization](https://arxiv.org/abs/2507.11019)
> *相对熵路径策略优化*

*Claas Voelcker, Axel Brunnbauer, Marcel Hussing, Michal Nauman, Pieter Abbeel, Eric Eaton, Radu Grosu, Amir-massoud Farahmand, Igor Gilitschenski* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 相对熵, 路径策略优化, 在策略学习, 强化学习, 策略梯度

**Comment:** 

> **TL;DR:** 提出REPPO，一种结合路径策略梯度和标准在策略学习优点的算法，在效率和鲁棒性方面表现出色。

**AI_Comments:** 这篇论文通过引入REPPO算法，有效地解决了在策略学习中结合路径策略梯度所面临的挑战，即如何在不依赖离策略数据的情况下实现稳定的价值函数学习。其创新点在于将价值梯度驱动的在策略学习与路径策略更新相结合，同时通过平衡探索和受限更新来提高训练稳定性。REPPO的优势在于其高样本效率、低内存占用以及对超参数的鲁棒性，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有策略梯度方法（分数函数和路径）存在高方差或依赖离策略数据的问题，导致训练不稳定或难以应用。

**Method:** 本文提出构建一个价值梯度驱动的在策略算法，允许Q值模型纯粹从在策略数据中训练，从而在在策略学习中使用路径策略更新。通过平衡探索的随机策略与稳定训练的受限策略更新，并评估有助于准确价值函数学习的架构组件，最终提出了相对熵路径策略优化（REPPO）。

**Result:** REPPO在两个标准GPU并行基准测试中，以更低的样本需求、更少的运行时间、更小的内存占用以及更高的超参数鲁棒性，提供了强大的经验性能。

**Conclusion:** REPPO是一种高效的在策略算法，成功结合了路径策略梯度的样本效率与标准在策略学习的简洁性和最小内存占用，并展现了优秀的性能和鲁棒性。

> **ai_Abstract:** 本文针对现有策略梯度算法的局限性（高方差或依赖离策略数据），提出了一种新的在策略强化学习算法——相对熵路径策略优化（REPPO）。REPPO通过构建一个价值梯度驱动的在策略算法，使得Q值模型可以纯粹从在策略数据中学习，从而在在策略学习中利用路径策略更新的优势。该算法平衡了探索与稳定训练，并优化了价值函数学习。实验证明，REPPO在样本效率、运行时间、内存占用和超参数鲁棒性方面均表现优异。

> **摘要翻译:** 分数函数策略梯度在游戏、机器人和语言模型微调中取得了显著成果。然而，其高方差常常破坏训练稳定性。另一方面，路径策略梯度减轻了训练方差，但仅在由准确的动作条件价值函数驱动时才可靠，而后者在不依赖过去的离策略数据的情况下训练起来非常困难。在本文中，我们讨论了如何构建一个由价值梯度驱动的、在策略算法，允许Q值模型纯粹从在策略数据中训练，从而开启了在在策略学习中使用路径策略更新的可能性。我们展示了如何平衡用于探索的随机策略与用于稳定训练的受限策略更新，并评估了有助于准确价值函数学习的重要架构组件。基于这些见解，我们提出了相对熵路径策略优化（REPPO），这是一种高效的在策略算法，它结合了路径策略梯度的样本效率与标准在策略学习的简洁性和最小内存占用。我们证明了REPPO在两项标准GPU并行基准测试中的一系列实验中，以更低的样本需求、更少的运行时间、更小的内存占用以及高超参数鲁棒性，提供了强大的经验性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [361] [Learning from Label Proportions and Covariate-shifted Instances](https://arxiv.org/abs/2411.12334)
> *从标签比例和协变量偏移实例中学习*

*Sagalpreet Singh, Navodita Sharma, Shreyas Havaldar, Rishi Saket, Aravindan Raghuveer* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 标签比例学习, 协变量偏移, 领域适应, 混合学习, 实例预测

**Comment:** 

> **TL;DR:** 本文提出了一个名为“协变量偏移混合LLP”的新问题，即在标签比例学习（LLP）中结合协变量偏移的完全监督源数据。作者开发了在该领域适应框架内利用源实例标签和目标袋标签的方法，并证明了其方法在理论和实践中均优于现有基线。

**AI_Comments:** 本文的创新点在于提出了一个实际且重要的“协变量偏移混合LLP”问题，并首次尝试在领域适应框架下融合标签比例学习与协变量偏移的完全监督数据。其结合理论分析和实验验证的严谨性，以及在多个数据集上超越现有基线的表现，都凸显了这项工作的价值和潜在影响力。

<details>
  <summary>Details</summary>

**Motivation:** 在许多应用中，由于缺乏监督或隐私问题，训练数据被分组为实例包，每个包只有一个聚合标签。在标签比例学习（LLP）中，聚合标签是包中实例标签的平均值。然而，在实践中，训练数据可能包含协变量偏移的完全监督源数据以及带有包标签的目标数据。本文的动机是利用这些有用的训练信号，在混合LLP设置中获得更好的预测性能。

**Method:** 本文开发了用于混合标签比例学习（hybrid LLP）的方法，这些方法在领域适应框架中自然地结合了目标包标签和源实例标签。

**Result:** 本文不仅提供了目标泛化误差的理论保证，还在几个公开数据集上进行了实验，结果表明所提出的方法优于LLP和领域适应基线以及之前相关工作的技术。

**Conclusion:** 本文成功开发了在协变量偏移混合LLP问题中有效利用源实例标签和目标袋标签的方法，并在理论和实践中证明了其优越性，从而提升了实例级别预测的性能。

> **ai_Abstract:** 本文解决了协变量偏移混合标签比例学习（hybrid LLP）问题，即在LLP设置中结合协变量偏移的完全监督源数据。研究人员开发了在领域适应框架下融合源实例标签和目标包标签的新方法。通过理论证明和实验验证，这些方法在多个数据集上均表现出优于现有LLP和领域适应基线的性能，有效提升了实例级预测的准确性。

> **摘要翻译:** 在许多应用中，特别是由于缺乏监督或隐私问题，训练数据被分组为实例袋（特征向量），每个袋只有一个从袋中实例标签派生的聚合标签。在标签比例学习（LLP）中，聚合标签是袋中实例标签的平均值，大量工作都集中在LLP设置下训练模型以预测实例标签。然而在实践中，训练数据可能具有完全监督但协变量偏移的源数据，以及带有袋标签的通常目标数据，我们希望在目标域上训练一个好的实例级预测器。我们称之为协变量偏移混合LLP问题。完全监督的协变量偏移数据通常具有有用的训练信号，目标是利用它们在混合LLP设置中获得更好的预测性能。为了实现这一点，我们开发了混合LLP方法，这些方法在领域适应框架中自然地结合了目标袋标签和源实例标签。除了提供目标泛化误差的理论保证外，我们还在几个公开数据集上进行了实验，结果表明我们的方法优于LLP和领域适应基线以及之前相关工作的技术。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [376] [FairTargetSim: An Interactive Simulator for Understanding and Explaining the Fairness Effects of Target Variable Definition](https://arxiv.org/abs/2403.06031)
> *FairTargetSim：一个用于理解和解释目标变量定义公平性影响的交互式模拟器*

*Dalia Gala, Milo Phillips-Brown, Naman Goel, Carinal Prunkl, Laura Alvarez Jubete, medb corcoran, Ray Eitel-Porter* | **Category: cs.LG, cs.AI, cs.CY** | **Updated: 2025-07-14**

**Keywords:** FairTargetSim, 公平性, 目标变量, 机器学习, 模拟

**Comment:** 

> **TL;DR:** FairTargetSim是一个交互式模拟器，用于理解和解释机器学习中目标变量定义对公平性的影响。

**AI_Comments:** 本文的创新之处在于它关注机器学习开发早期阶段（即目标变量定义）的公平性问题，这在数据收集或训练之前就可能引入偏见，而这一点往往被忽视。其交互式模拟方法使其对不同用户群体具有可访问性。FTS的开源性质及其在现实世界场景（如算法招聘）中的适用性突出了其实际重要性。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习中目标变量的定义对公平性有深远影响，因为偏见往往在数据收集或训练之前就已经编码在目标变量定义本身中。为了负责任地开发、部署和使用算法系统，必须考虑目标变量定义的下游影响。

**Method:** 本文提出了FairTargetSim（FTS），一个交互式和基于模拟的方法来解决目标变量定义中的公平性问题。

**Result:** 本文使用算法招聘的例子演示了FTS，该例子基于真实世界的数据和用户定义的目标变量。FTS是开源的，可以被算法开发人员、非技术利益相关者、研究人员和教育工作者以多种方式使用。

**Conclusion:** FairTargetSim（FTS）是一个开源、交互式和基于模拟的工具，旨在帮助不同利益相关者理解和解释机器学习中目标变量定义所产生的公平性影响，并已通过算法招聘示例展示了其效用。

> **ai_Abstract:** 本文介绍了FairTargetSim（FTS），一个开源、交互式且基于模拟的工具，旨在帮助用户理解和解释机器学习中目标变量定义所产生的公平性影响。它解决了在数据收集之前就编码在目标变量定义中的关键偏见问题。FTS的实用性通过一个算法招聘示例得到演示，该示例利用真实世界数据和用户定义变量，使其成为开发人员、利益相关者、研究人员和教育工作者的宝贵资源。

> **摘要翻译:** 机器学习需要定义其用于预测或决策的目标变量，这个过程可能对公平性产生深远影响，因为偏见往往在任何数据收集或训练之前就已经编码在目标变量定义本身中。为了负责任地开发、部署和使用算法系统，必须考虑目标变量定义的下游影响。我们为此提出了FairTargetSim（FTS），一个交互式和基于模拟的方法。我们使用算法招聘的例子演示了FTS，该例子基于真实世界的数据和用户定义的目标变量。FTS是开源的；它可以被算法开发人员、非技术利益相关者、研究人员和教育工作者以多种方式使用。FTS可在：http://tinyurl.com/ftsinterface 获取。本文的视频在此：http://tinyurl.com/ijcaifts。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [377] [Few-Shot Radar Signal Recognition through Self-Supervised Learning and Radio Frequency Domain Adaptation](https://arxiv.org/abs/2501.03461)
> *基于自监督学习和射频域适应的少样本雷达信号识别*

*Zi Huang, Simon Denman, Akila Pemasiri, Clinton Fookes, Terrence Martin* | **Category: cs.LG, cs.AI, eess.SP** | **Updated: 2025-07-15**

**Keywords:** 雷达信号识别, 自监督学习, 域适应, 少样本学习, 掩码自编码器

**Comment:** 6 pages, 15 figures

> **TL;DR:** 本文提出了一种结合自监督学习和射频域适应的方法，以解决雷达信号识别中带标注数据稀缺的问题，并在少样本分类任务中取得了显著性能提升。

**AI_Comments:** 本文的创新点在于将自监督学习和射频域适应相结合，有效解决了雷达信号识别中带标注数据稀缺的实际问题。其两步预训练和迁移学习策略具有普适性，可以为其他数据稀缺的信号处理任务提供借鉴。该研究对于提高电子战中雷达信号识别的效率和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在电子战中，雷达信号识别（RSR）至关重要，但传统的深度学习方法在带标注的射频（RF）数据稀缺或难以获取的场景下表现不佳。

**Method:** 本文提出了一种两步自监督学习（SSL）方法。首先，在来自不同射频域的基带同相和正交（I/Q）信号上预训练掩码自编码器（MAE）。然后，将学习到的表示迁移到带标注数据稀缺的雷达域。该方法结合了掩码信号建模和射频域适应。

**Result:** 与不使用SSL的基线模型相比，本文提出的轻量级自监督ResNet1D模型在域内信号（雷达信号）预训练时，1-shot分类准确率最高提升了17.5%；在域外信号（通信信号）预训练时，最高提升了16.31%。此外，还提供了多种MAE设计和预训练策略的参考结果，为少样本雷达信号分类建立了新基准。

**Conclusion:** 本文提出的结合自监督学习和射频域适应的方法有效解决了少样本雷达信号识别中数据稀缺的挑战，并在性能上取得了显著提升，为该领域树立了新的基准。

> **ai_Abstract:** 本文提出了一种新颖的自监督学习（SSL）方法，结合掩码信号建模和射频域适应，旨在解决电子战中雷达信号识别（RSR）面临的标注数据稀缺问题。该方法通过两步实现：首先在多域基带I/Q信号上预训练掩码自编码器（MAE），然后将学到的表示迁移到数据稀缺的雷达域。实验证明，与无SSL基线相比，该轻量级ResNet1D模型在少样本RSR任务上性能显著提升，最高可达17.5%的准确率提升，并为少样本雷达信号分类建立了新基准。

> **摘要翻译:** 雷达信号识别（RSR）在电子战（EW）中发挥着关键作用，因为准确分类雷达信号对于决策制定至关重要。深度学习的最新进展在拥有充足标注数据的领域中显示出显著提高RSR的潜力。然而，这些方法在标注射频（RF）数据稀缺或难以获取的电子战场景中表现不足。为了解决这些挑战，我们引入了一种自监督学习（SSL）方法，该方法利用掩码信号建模和射频域适应来执行少样本RSR，并提高在有限射频样本和标注环境中的性能。我们提出了一种两步方法：首先，在来自不同射频域的基带同相和正交（I/Q）信号上预训练掩码自编码器（MAE）；然后，将学习到的表示迁移到标注数据稀缺的雷达域。实证结果表明，我们轻量级的自监督ResNet1D模型结合域适应，在域内信号（即雷达信号）预训练时，1-shot分类准确率最高提升了17.5%；在域外信号（即通信信号）预训练时，最高提升了16.31%，均优于不使用SSL的基线模型。我们还提供了几种MAE设计和预训练策略的参考结果，为少样本雷达信号分类建立了新基准。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [385] [Improving sub-seasonal wind-speed forecasts in Europe with a non-linear model](https://arxiv.org/abs/2411.19077)
> *使用非线性模型改进欧洲次季节风速预报*

*Ganglin Tian, Camille Le Coz, Anastase Alexandre Charantonis, Alexis Tantet, Naveen Goutham, Riwal Plougonven* | **Category: cs.LG, physics.ao-ph** | **Updated: 2025-07-15**

**Keywords:** 次季节风速预报, 非线性模型, 卷积神经网络, 随机扰动, 500 hPa位势高度

**Comment:** 

> **TL;DR:** 利用非线性模型（特别是CNN）和随机扰动，可以改进欧洲次季节风速预报，克服传统模型预报技能下降和离散度不足的问题。

**AI_Comments:** 该研究创新性地结合了机器学习（CNN）和传统统计方法（MLR）来改进次季节风速预报，并引入随机扰动以解决模型离散度不足的常见问题。这对于提高风能领域预报的可靠性和应用价值具有重要意义。其局限性可能在于模型的泛化能力以及对不同区域或更长时间尺度的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 次季节风速预报为风力发电系统规划和运行提供宝贵指导，但地表风速预报技能在两周后急剧下降。然而，大规模变量在此时间尺度上表现出更大的可预测性。

**Method:** 本研究利用500 hPa位势高度（Z500）与地表风速之间的非线性关系，提出使用多元线性回归（MLR）或卷积神经网络（CNN）从Z500回归地表风速。为解决模型离散度不足问题，引入随机扰动以表示信号中未解释部分的随机性。

**Result:** 评估表明CNN因其非线性特性表现优于MLR。将模型应用于欧洲中期天气预报中心（ECMWF）的次季节预报，各种验证指标证明了非线性的优势。引入随机扰动有助于弥补统计模型离散度不足的问题。扰动后的CNN仅在最初几周表现优于扰动后的MLR，而扰动后的MLR在两周后性能趋近于扰动后的CNN。

**Conclusion:** 引入随机扰动可以解决统计模型扩散不足的问题，且非线性的改进效果随预报提前期的变化而变化。

> **ai_Abstract:** 本文提出利用500 hPa位势高度（Z500）与地表风速的非线性关系，通过多元线性回归（MLR）或卷积神经网络（CNN）模型，改进欧洲次季节风速预报。研究发现CNN因其非线性特性表现更优。为解决统计模型离散度不足的问题，引入随机扰动，结果显示扰动后的CNN在短期内表现更佳，而扰动后的MLR在长期（两周后）性能与扰动后的CNN趋同。研究强调随机扰动能有效解决模型扩散不足，且非线性改进效果随预报提前期变化。

> **摘要翻译:** 次季节风速预报为风力发电系统规划和运行提供了宝贵的指导，然而地表风速的预报技能在两周后急剧下降。然而，大规模变量在此时间尺度上表现出更大的可预测性。本研究探讨了利用500 hPa位势高度（Z500）与地表风速之间的非线性关系来提高欧洲次季节风速预报技能的潜力。我们提出的框架使用多元线性回归（MLR）或卷积神经网络（CNN）从Z500回归地表风速。对ERA5再分析的评估表明，CNN由于其非线性特性表现更好。将这些模型应用于欧洲中期天气预报中心的次季节预报，各种验证指标证明了非线性的优势。然而，这部分是由于这些统计模型离散度不足，因为它们只解释了目标变量方差的一小部分。引入随机扰动来表示信号中未解释部分的随机性有助于弥补这个问题。结果表明，扰动后的CNN仅在最初几周表现优于扰动后的MLR，而扰动后的MLR的性能在两周后趋近于扰动后的CNN。研究发现，引入随机扰动可以解决这些统计模型扩散不足的问题，非线性的改进随预报提前期的变化而变化。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [401] [LogTinyLLM: Tiny Large Language Models Based Contextual Log Anomaly Detection](https://arxiv.org/abs/2507.11071)
> *LogTinyLLM：基于小型大型语言模型的上下文日志异常检测*

*Isaiah Thompson Ocansey, Ritwik Bhattacharya, Tanmay Sen* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 日志异常检测, 小型大型语言模型, LoRA, 参数高效微调, 上下文异常

**Comment:** 

> **TL;DR:** LogTinyLLM利用LoRA和基于适配器的小型LLM微调进行日志异常检测，性能显著优于LogBert。

**AI_Comments:** 该论文的创新点在于将参数高效微调（如LoRA和适配器）与小型大型语言模型（LLMs）结合应用于日志异常检测，有效解决了大规模日志数据处理的复杂性。其在性能上取得的显著提升（18-19%）表明了该方法的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 由于日志序列的数据量大且高度复杂，传统的基于规则或深度学习的日志异常检测方法常面临挑战。因此，有效检测异常日志序列对于系统维护和开发至关重要。

**Method:** 本文提出了参数高效微调方法，特别是低秩适应（LoRA）和基于适配器的方法，用于在大规模日志数据集中查找日志序列中的上下文异常。它在Thunderbird数据集上比较了不同的小型大型语言模型（LLMs）。

**Result:** 结果显示，基于LoRA的微调方法比基于LogBert的完全微调方法带来了18%到19%的显著性能提升，准确率达到97.76%到98.83%，而后者为79.37%。

**Conclusion:** 基于LoRA的微调方法在日志异常检测方面表现出显著的性能提升，表明其是解决大规模日志复杂性的有效途径。

> **ai_Abstract:** 本文针对大规模复杂日志数据中的日志异常检测挑战，提出了一种基于小型大型语言模型（LLMs）的参数高效微调技术，特别是低秩适应（LoRA）和基于适配器的方法。在Thunderbird数据集上的实验表明，基于LoRA的微调方法显著优于基于LogBert的完全微调方法，准确率达到97.76%至98.83%，而LogBert为79.37%，性能提升了18%至19%。

> **摘要翻译:** 由于日志序列的数据量大且高度复杂，传统的基于规则或深度学习的日志异常检测方法常面临挑战。因此，有效检测异常日志序列对于系统维护和开发至关重要。本文提出了参数高效微调方法，特别是低秩适应（LoRA）和基于适配器的方法，用于在大规模日志数据集中查找日志序列中的上下文异常。它在Thunderbird数据集上比较了不同的小型大型语言模型（LLMs）。结果显示，基于LoRA的微调方法比基于LogBert的完全微调方法带来了18%到19%的显著性能提升，准确率达到97.76%到98.83%，而后者为79.37%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [403] [Inverse Reinforcement Learning with Switching Rewards and History Dependency for Characterizing Animal Behaviors](https://arxiv.org/abs/2501.12633)
> *具有切换奖励和历史依赖性的逆向强化学习，用于表征动物行为*

*Jingyang Ke, Feiyang Wu, Jiyi Wang, Jeffrey Markowitz, Anqi Wu* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 逆向强化学习, 动物行为, 历史依赖性, 切换奖励, 决策制定

**Comment:** 

> **TL;DR:** SWIRL是一个新的逆向强化学习框架，它通过引入时间变化和历史依赖的奖励函数来捕捉动物在自然环境中复杂的、长期行为中的决策过程，并在模拟和真实数据集中表现优异。

**AI_Comments:** 这项工作的创新之处在于首次将历史依赖性引入逆向强化学习模型，以更好地表征动物在自然环境中的复杂决策。其重要性在于弥补了传统IRL模型在处理长期、非显式奖励驱动行为时的不足，为神经科学和行为学研究提供了新的分析工具。该模型考虑了生物学上合理的历史依赖性，有望更准确地揭示动物内在动机。

<details>
  <summary>Details</summary>

**Motivation:** 传统研究动物决策的方法侧重于简化任务和显式奖励，这限制了对由内在动机驱动的复杂、长期自然行为的理解。现有时间变量逆向强化学习方法未能解决动物决策依赖于历史而非仅仅当前状态的关键挑战。

**Method:** 本研究引入了SWIRL（SWitching IRL）框架，通过整合时间变化和历史依赖的奖励函数来扩展传统逆向强化学习。SWIRL将长行为序列建模为短期决策过程之间的转换，每个过程由独特的奖励函数控制，并包含生物学上合理历史依赖性。

**Result:** SWIRL在模拟和真实世界的动物行为数据集上进行应用，结果表明它在定量和定性上均优于缺乏历史依赖性的模型。

**Conclusion:** 本工作提出了第一个结合历史依赖性策略和奖励的逆向强化学习模型，从而加深了我们对动物复杂自然决策过程的理解。

> **ai_Abstract:** 该论文提出了一种名为SWIRL（SWitching IRL）的新型逆向强化学习框架，旨在解决传统方法在理解动物复杂、自然行为决策方面的局限性。SWIRL通过引入时间变化和历史依赖的奖励函数来捕捉动物决策中受过去经验影响的特性，将长期行为序列分解为由不同奖励函数控制的短期决策过程。在模拟和真实动物行为数据集上的实验表明，SWIRL在描述动物决策方面优于不考虑历史依赖性的模型，为理解动物复杂行为提供了更准确的工具。

> **摘要翻译:** 传统神经科学研究决策的方法侧重于简化的行为任务，其中动物执行重复、刻板的动作以获得明确的奖励。尽管这些方法提供了信息，但它们将我们对决策的理解限制在由明确目标驱动的短时间尺度行为上。在自然环境中，动物表现出更复杂的、由通常不可观察的内在动机驱动的长期行为。最近在时变逆向强化学习（IRL）方面的工作旨在捕捉长期自由移动行为中不断变化的动机。然而，一个关键挑战仍然存在：动物的决策是基于其历史，而不仅仅是其当前状态。为了解决这个问题，我们引入了SWIRL（SWitching IRL），这是一个新颖的框架，通过结合时变、历史依赖的奖励函数来扩展传统IRL。SWIRL将长行为序列建模为短期决策过程之间的转换，每个过程由独特的奖励函数控制。SWIRL结合了生物学上合理的历史依赖性，以捕捉过去的决策和环境背景如何塑造行为，从而提供对动物决策更准确的描述。我们将SWIRL应用于模拟和真实世界的动物行为数据集，结果表明它在定量和定性上均优于缺乏历史依赖性的模型。这项工作提出了第一个结合历史依赖性策略和奖励的IRL模型，以推进我们对动物复杂、自然决策的理解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [406] [Multi-Armed Sampling Problem and the End of Exploration](https://arxiv.org/abs/2507.10797)
> *多臂采样问题与探索的终结*

*Mohammad Pedramfar, Siamak Ravanbakhsh* | **Category: cs.LG, math.OC, stat.ML** | **Updated: 2025-07-14**

**Keywords:** 多臂采样, 探索-利用权衡, 遗憾界限, 神经采样器, 强化学习

**Comment:** 

> **TL;DR:** 本文引入了多臂采样框架，作为多臂赌博机的采样对应物，并理论证明在采样中不需要探索，这与优化问题形成对比。

**AI_Comments:** 这篇论文引入了一个新颖的多臂采样框架，其创新点在于将多臂赌博机的概念扩展到采样领域，并得出与优化问题截然不同的结论，即采样不需要探索。这对于理解采样算法，特别是神经采样器，以及强化学习中的探索问题具有重要的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 严谨地检验采样背景下的探索-利用权衡问题。

**Method:** 引入了多臂采样框架，定义了遗憾概念并建立了下界，提出了一个简单的算法以达到最优遗憾界限。还定义了一个连续问题族，通过温度参数统一了多臂采样和多臂赌博机问题。

**Result:** 理论结果表明，与优化不同，采样不需要探索。

**Conclusion:** 多臂采样框架及其发现可能在采样研究（包括神经采样器）中发挥基础性作用，并为熵正则化强化学习、预训练模型微调和RLHF中的探索需求与算法收敛性提供了见解。

> **ai_Abstract:** 本文提出了多臂采样框架，作为多臂赌博机优化问题的采样对应物，旨在严格分析采样中的探索-利用权衡。研究定义了遗憾概念并建立了最优下界，并提出了一个达到这些界限的简单算法。核心发现是采样与优化不同，不需要探索。此外，文章还提出了一个统一多臂采样和多臂赌博机问题的连续问题族。该框架预计将在采样领域（包括神经采样器）发挥基础性作用，并为特定强化学习算法的探索需求和收敛性提供见解。

> **摘要翻译:** 本文引入了多臂采样框架，作为多臂赌博机优化问题的采样对应物。我们的主要动机是严格检验采样背景下的探索-利用权衡。我们系统地定义了该框架中合理的遗憾概念，并建立了相应的下界。然后，我们提出了一种简单的算法，该算法达到了这些最优遗憾界限。我们的理论结果表明，与优化不同，采样不需要探索。为了进一步将我们的发现与多臂赌博机联系起来，我们定义了一个连续的问题族和相关的遗憾度量，该问题族使用温度参数平滑地插值和统一了多臂采样和多臂赌博机问题。我们相信多臂采样框架以及在此设置中的发现可以在采样研究（包括最近的神经采样器）中发挥基础性作用，类似于多臂赌博机在强化学习中的作用。特别是，我们的工作阐明了熵正则化强化学习、预训练模型微调以及带有人类反馈的强化学习（RLHF）中探索的需求和算法的收敛特性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [407] [A Distance Metric for Mixed Integer Programming Instances](https://arxiv.org/abs/2507.11063)
> *混合整数规划实例的距离度量*

*Gwen Maudet, Grégoire Danoy* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 混合整数规划, 距离度量, 地球移动距离, 无监督学习, 实例相似性

**Comment:** Accepted to ECAI 2025

> **TL;DR:** 本文提出了一种新的、基于数学公式的混合整数规划（MILP）实例距离度量，该度量在无监督条件下优于现有基线，且其贪婪版本效率显著提高。

**AI_Comments:** 该论文的创新点在于提出了第一个直接基于MILP实例数学公式的距离度量，而非依赖于特征工程或大量标记数据。其无监督的性质大大增强了适用性和泛化能力。尤其值得注意的是，贪婪版本在保持高精度的同时实现了近200倍的速度提升，这对于实际应用具有重要意义。这项工作为理解MILP实例的内在结构、评估实例集异质性以及指导机器学习辅助的求解器提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 混合整数线性规划（MILP）缺乏清晰的实例比较结构，现有相似性度量在识别实例类别或泛化性方面存在不足，限制了其在评估实例集异质性和指导求解器（尤其涉及机器学习时）方面的有效性。

**Method:** 本文引入了第一个直接从数学公式推导的MILP实例数学距离度量。该度量通过将右侧项、权重和变量离散化为类别，并借鉴地球移动距离（Earth mover's distance）来量化权重-变量分布中的不匹配，从而实现约束比较。这种方法自然地扩展到实例级别的比较。研究评估了该度量的精确和贪婪两种变体，并在StrIPLIB数据集上进行了测试。

**Result:** 该度量的所有组成部分都有助于类别识别。贪婪版本在准确性上与精确公式几乎相同，但速度快了近200倍。与包括基于特征、基于图像和神经网络模型在内的现有基线相比，本文提出的无监督方法始终优于所有非学习方法，并在类别和子类别分组任务上与监督分类器表现相当。

**Conclusion:** 本文成功开发了一种新颖的、高效且有效的混合整数规划实例距离度量，该度量直接来源于实例的数学公式，且在无监督条件下表现出色，有望提升对实例集的理解和求解器的指导。

> **ai_Abstract:** 本研究提出了一种新颖的数学距离度量，用于量化混合整数线性规划（MILP）实例之间的相似性。该度量直接从实例的数学公式推导，并通过借鉴地球移动距离来比较离散化的权重-变量分布。研究评估了该度量的精确和贪婪版本，发现贪婪版本在保持高准确性的同时显著提高了计算效率。与多种现有基线相比，所提出的无监督方法在实例分类任务中表现优异，甚至能与监督学习方法媲美，为MILP实例分析和求解器指导提供了有力工具。

> **摘要翻译:** 混合整数线性规划（MILP）是解决各种现实世界问题的强大工具，但它缺乏比较实例的清晰结构。可靠的相似性度量可以建立实例之间有意义的关系，从而更有效地评估实例集异质性，并为求解器提供更好的指导，尤其是在涉及机器学习时。现有的相似性度量在识别实例类别方面往往缺乏精确性，或者严重依赖标记数据，这限制了它们的适用性和泛化能力。为了弥补这一差距，本文引入了第一个直接从MILP实例的数学公式推导出来的数学距离度量。通过将右侧项、权重和变量离散化为类别，所提出的度量借鉴了地球移动距离（Earth mover's distance）来量化约束比较中权重-变量分布的不匹配。这种方法自然地扩展到实例级别的比较。我们使用StrIPLIB数据集评估了我们度量的精确和贪婪两种变体在各种参数设置下的表现。结果表明，该度量的所有组成部分都有助于类别识别，并且贪婪版本在准确性上与精确公式几乎相同，同时速度快了近200倍。与包括基于特征、基于图像和神经网络模型在内的现有最先进基线相比，我们的无监督方法始终优于所有非学习方法，并在类别和子类别分组任务上与监督分类器表现相当。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [409] [DFRot: Achieving Outlier-Free and Massive Activation-Free for Rotated LLMs with Refined Rotation](https://arxiv.org/abs/2412.00648)
> *DFRot: 通过精炼旋转实现旋转LLM的无离群值和无大规模激活*

*Jingyang Xiang, Sai Qian Zhang* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-15**

**Keywords:** LLM量化, 旋转LLM, 离群值, 大规模激活, DFRot

**Comment:** Accepeted bythe 2nd Conference on Language Modeling (COLM 2025).
  Source code \url{https://github.com/JingyangXiang/DFRot}

> **TL;DR:** DFRot提出一种新的方法，通过加权损失和精炼旋转矩阵，解决LLM量化中的离群值和大规模激活问题，显著提升低精度量化模型的性能。

**AI_Comments:** DFRot的创新点在于其提出了“无离群值”和“无大规模激活”的双重优化目标，并通过加权损失函数和精炼旋转矩阵的策略有效实现。特别是，它解决了先前研究中Hadamard变换优于正交变换的未解之谜，并将其归结为对“大规模激活”这一长尾问题的优化。这对于推动LLM的低精度量化具有重要意义，尤其是在资源受限的部署场景中。

<details>
  <summary>Details</summary>

**Motivation:** 旋转激活和权重矩阵以减少大型语言模型（LLMs）中离群值的影响在模型量化中受到广泛关注，但Hadamard变换优于正交变换的原因尚不明确。研究发现，Hadamard变换能略微减少具有大规模激活的tokens的量化误差，而正交变换则会增加，这被视为一个长尾优化问题。

**Method:** 本研究构建了一个简单有效的加权损失函数来解决长尾优化问题。此外，提出了一种旋转矩阵的优化策略，该策略涉及量化参数的交替优化，并采用正交Procrustes变换来精炼旋转矩阵，使得旋转后的激活值分布更利于量化，特别是对于具有大规模激活的tokens。此方法被称为DFRot。

**Result:** DFRot通过仅使用一个样本调整旋转矩阵，在LLaMA3-70B模型上实现了显著的困惑度提升：W4A4KV4下提升0.98，W4A4KV16下提升0.95。实验证明了DFRot的有效性和效率，实现了“无离群值”和“无大规模激活”的双重目标。

**Conclusion:** DFRot通过解决大型语言模型低精度量化中的离群值和大规模激活问题，显著提升了旋转LLMs的性能和鲁棒性，为未来LLM量化提供了新的优化方向。

> **ai_Abstract:** 本研究提出DFRot，一种针对旋转LLM的优化方法，旨在解决低精度量化中的离群值和大规模激活问题。通过分析Hadamard变换优于正交变换的原因，作者发现大规模激活是关键，并将其视为长尾优化问题。DFRot引入加权损失函数和精炼旋转矩阵的优化策略（结合交替优化和正交Procrustes变换），使旋转后的激活分布更适合量化，尤其对大规模激活有效。实验证明，DFRot在LLaMA3-70B等模型上显著提升了W4A4量化场景下的困惑度，实现了无离群值和无大规模激活的双重优化。

> **摘要翻译:** 旋转激活和权重矩阵以减少大型语言模型（LLM）中离群值的影响最近受到了广泛关注，尤其是在模型量化背景下。先前的研究表明，在低精度量化场景中，例如4位权重和4位激活（W4A4），随机Hadamard变换可以比随机正交变换获得显著更高的精度。值得注意的是，这种现象背后的原因仍然未知。在本文中，我们发现这些变换在消除常见tokens的离群值方面显示出实质性改进，并实现了相似的量化误差。精度差异的主要原因在于，随机Hadamard变换可以略微减少具有大规模激活的tokens的量化误差，而随机正交变换则会增加量化误差。由于这些tokens的极端稀有性及其对模型精度的关键影响，我们认为这是一个长尾优化问题，因此构建了一个简单但有效的方法：一个加权损失函数。此外，我们提出了一种旋转矩阵的优化策略，该策略涉及量化参数的交替优化，同时采用正交Procrustes变换来精炼旋转矩阵。这使得旋转后的激活值分布更利于量化，特别是对于具有大规模激活的tokens。我们的方法通过实现双重自由——无离群值和无大规模激活——增强了旋转LLM，被称为DFRot。广泛的实验证明了DFRot的有效性和效率。通过仅使用单个样本调整旋转矩阵，DFRot在LLaMA3-70B（一个以量化挑战著称的模型）的W4A4KV4和W4A4KV16上分别实现了0.98和0.95的困惑度改进。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [410] [Tool-to-Tool Matching Analysis Based Difference Score Computation Methods for Semiconductor Manufacturing](https://arxiv.org/abs/2507.10564)
> *半导体制造中基于工具间匹配分析的差异分数计算方法*

*Sameera Bharadwaja H., Siddhrath Jandial, Shashank S. Agashe, Rajesh Kumar Reddy Moore, Youngkwan Kim* | **Category: cs.LG, cs.AI, eess.SP, stat.ML** | **Updated: 2025-07-07**

**Keywords:** 工具间匹配, 半导体制造, 差异分数, 数据方差, 异构设备

**Comment:** 

> **TL;DR:** 本文提出了一种新的工具间匹配（TTTM）分析方法，通过分析数据方差和模式数量来解决传统方法在异构环境中难以应用的问题，并在半导体制造中取得了良好效果。

**AI_Comments:** 这篇论文通过提出一种基于数据方差和模式数量的新型工具间匹配分析方法，有效解决了半导体制造中传统TTTM方法在异构环境下的局限性。其创新点在于不依赖难以获取的黄金参考，而是利用数据内在特性进行匹配分析，这对于实际生产线具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的工具间匹配（TTTM）方法依赖于静态配置数据或难以获得的黄金参考，且在异构设备环境下表现不佳。

**Method:** 提出新的TTTM分析流程，假设失配设备的数据具有更高的方差和/或更多的模式。开发了单变量和多变量方法。

**Result:** 最好的单变量方法与方差和模式数量的相关系数分别超过0.95和0.5。最好的多变量方法与表现最佳的单变量方法相关系数超过0.75。还分析了多变量算法对超参数的敏感性。

**Conclusion:** 提出的TTTM分析方法有效解决了传统方法的局限性，并在半导体制造中表现出良好的效果。

> **ai_Abstract:** 本文针对半导体制造中的工具间匹配（TTTM）问题，提出了新的分析流程，以克服传统方法依赖静态配置或黄金参考以及在异构环境下表现不佳的局限性。研究假设失配设备的数据具有更高的方差和/或更多模式。实验结果表明，所提出的单变量方法与方差和模式数量表现出高相关性，而多变量方法也与单变量方法表现出高相关性，证明了方法的有效性。文章还探讨了多变量算法对超参数的敏感性。

> **摘要翻译:** 我们考虑了半导体制造设备背景下的工具间匹配（TTTM）问题，也称为腔室匹配。传统的TTTM方法利用静态配置数据或依赖于在商业生产线上难以获得的黄金参考。此外，现有方法在异构设置中扩展性不佳，即设备来自不同的制造商和型号，由不同的设备供应商提供。我们提出了新颖的TTTM分析流程来克服这些问题。我们假设失配的设备在数据中将具有更高的方差和/或更多的模式。我们最好的单变量方法与方差和模式数量的相关系数分别超过0.95和0.5，这表明所提出的方法是有效的。此外，最好的多变量方法与表现最佳的单变量方法的相关系数超过0.75，显示了其有效性。最后，我们分析了多变量算法对算法超参数的敏感性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [417] [Flows and Diffusions on the Neural Manifold](https://arxiv.org/abs/2507.10623)
> *神经网络流形上的流与扩散*

*Daniel Saragih, Deyu Cao, Tejas Balaji* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-14**

**Keywords:** 权重空间学习, 梯度流匹配, 轨迹推断, 生成模型, 协变量偏移检测

**Comment:** 40 pages, 6 figures, 13 tables

> **TL;DR:** 本文将流和扩散生成模型扩展到权重空间学习，通过将梯度下降轨迹建模为轨迹推断问题，并统一了多种技术，实验证明其在权重生成、下游训练初始化和安全关键系统中的协变量偏移检测方面表现优异。

**AI_Comments:** 本文的创新之处在于将流和扩散模型从数据空间扩展到模型权重空间，并巧妙地将梯度下降的优化过程视为一个轨迹推断问题，这为理解和生成神经网络权重提供了一个新颖且强大的视角。通过统一梯度流匹配框架，为优化路径作为归纳偏置提供了理论基础。其实用性体现在改善模型初始化和在安全关键系统中的应用，这对于深度学习模型的可解释性和鲁棒性研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散和流基生成模型在图像、视频和自然语言处理领域取得了显著成功，本文旨在将这些进展扩展到权重空间学习，利用优化动力学导出的结构先验。

**Method:** 核心方法是将梯度下降引起的轨迹建模为轨迹推断问题，并将多种轨迹推断技术统一在梯度流匹配框架下，提供了一个将优化路径视为归纳偏置的理论框架。此外，还探索了架构和算法选择，包括通过伴随匹配进行奖励微调、使用自编码器进行潜在权重表示、基于任务特定上下文数据进行条件化以及采用信息丰富的源分布（如Kaiming均匀分布）。

**Result:** 实验证明，该方法在生成同分布权重方面与基线相当或超越基线，改善了下游训练的初始化，并支持微调以提高性能。在一个安全关键系统（检测有害协变量偏移）的实际应用中，该方法优于最接近的可比基线。

**Conclusion:** 本文成功将流和扩散模型应用于权重空间学习，通过将优化轨迹建模为推断问题并统一相关技术，显著提升了权重生成、模型初始化和特定任务性能，并在实际应用中展现出优越性。

> **ai_Abstract:** 本文提出将流和扩散生成模型应用于神经网络的权重空间学习，核心在于将梯度下降的优化轨迹视为轨迹推断问题，并在此基础上统一了多种轨迹推断技术，形成了梯度流匹配的理论框架。研究探索了多种架构和算法策略。实验结果显示，该方法在生成高质量权重、优化模型初始化及提升下游任务性能方面表现出色，并在安全关键系统中检测协变量偏移的应用中展现出超越现有基线的性能。

> **摘要翻译:** 扩散和基于流的生成模型在图像合成、视频生成和自然语言建模等领域取得了显著成功。在这项工作中，我们通过利用最新技术将源自优化动力学的结构先验纳入其中，将这些进展扩展到权重空间学习。我们方法的核心是将梯度下降引起的轨迹建模为一个轨迹推断问题。我们将几种轨迹推断技术统一在梯度流匹配框架下，为将优化路径视为归纳偏置提供了理论框架。我们进一步探索了架构和算法选择，包括通过伴随匹配进行奖励微调、使用自编码器进行潜在权重表示、基于任务特定上下文数据进行条件化以及采用信息丰富的源分布（如Kaiming均匀分布）。实验表明，我们的方法在生成同分布权重方面与基线相当或超越基线，改善了下游训练的初始化，并支持微调以提高性能。最后，我们阐述了一个在安全关键系统中的实际应用：检测有害协变量偏移，在该应用中，我们的方法优于最接近的可比基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [427] [Synthetic Datasets for Machine Learning on Spatio-Temporal Graphs using PDEs](https://arxiv.org/abs/2502.04140)
> *用于时空图机器学习的偏微分方程合成数据集*

*Jost Arndt, Utku Isil, Michael Detzel, Wojciech Samek, Jackie Ma* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 合成数据集, 时空图, 偏微分方程, 机器学习, 数据稀缺

**Comment:** Camera-ready version of the paper, which is now accepted at DMLR, see
  https://openreview.net/forum?id=EguDBMechn . 17 pages, 5 Figures

> **TL;DR:** 该研究通过使用偏微分方程（PDEs）创建合成数据集，以解决时空图机器学习中的数据稀缺问题，并展示了这些数据集在灾害建模和模型预训练中的应用。

**AI_Comments:** 这项工作的创新之处在于利用偏微分方程生成合成的时空图数据，有效解决了该领域数据稀缺的痛点。其重要性体现在为机器学习研究者提供了可定制、可扩展的数据生成方法，特别是在灾害建模等难以获取真实数据的领域具有重要应用潜力。通过展示预训练对真实世界数据性能的提升，进一步验证了其方法的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 时空图机器学习在物理过程建模中面临数据稀缺问题，且现有数据多为不规则分布。本工作旨在通过创建和利用基于偏微分方程（PDEs）的合成数据集，使PDE建模的进展能够服务于时空图机器学习社区，从而解决数据不足的挑战。

**Method:** 本研究创建并使用了基于偏微分方程（PDEs）的合成数据集，以支持机器学习中的时空图建模。具体地，研究展示了三种方程来模拟流行病学、大气粒子和海啸波等不同类型的灾害和危害。此外，研究通过在流行病学数据集上对多种机器学习模型进行基准测试，展示了如何使用这些创建的数据集。还展示了在此数据集上进行预训练如何提高模型在真实世界流行病学数据上的性能。

**Result:** 研究展示了所创建的合成数据集可用于对机器学习模型进行基准测试，并且在此数据集上进行预训练可以提高模型在真实世界流行病学数据上的性能。所提出的方法使其他人能够根据个性化需求创建自定义数据集和基准。

**Conclusion:** 本研究成功创建并利用了基于偏微分方程的合成数据集，有效缓解了时空图机器学习的数据稀缺问题。所提出的方法为研究人员提供了创建定制数据集和基准测试的工具，有助于推动该领域的发展。

> **ai_Abstract:** 该论文通过利用偏微分方程（PDEs）创建合成数据集，解决了时空图机器学习领域的数据稀缺问题。研究展示了如何使用这些数据集模拟流行病学、大气粒子和海啸波等灾害，并证明了其在机器学习模型基准测试和真实世界数据预训练中的有效性，从而为定制化数据集的创建提供了方法。

> **摘要翻译:** 许多物理过程可以通过偏微分方程（PDEs）来表达。这些过程的真实世界测量通常在空间中不规则分布的点上收集，可以有效地表示为图；然而，目前只有少数现有的数据集。我们的工作旨在通过创建和利用基于PDEs的数据集，使PDE建模领域的进展能够服务于时间图机器学习社区，同时解决数据稀缺问题。在这项工作中，我们创建并使用基于PDEs的合成数据集，以支持机器学习中针对不同应用的时空图建模。更具体地说，我们展示了三个方程来模拟流行病学、大气粒子和海啸波等不同类型的灾害和危害。此外，我们展示了如何通过在流行病学数据集上对多个机器学习模型进行基准测试来使用这些创建的数据集。此外，我们还展示了在此数据集上进行预训练如何提高模型在真实世界流行病学数据上的性能。所提出的方法使其他人能够根据个性化需求创建自定义数据集和基准。我们方法论的源代码和三个创建的数据集可在https://github.com/github-usr-ano/Temporal_Graph_Data_PDEs上找到。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [432] [Generalising Battery Control in Net-Zero Buildings via Personalised Federated RL](https://arxiv.org/abs/2412.20946)
> *通过个性化联邦强化学习推广净零建筑中的电池控制*

*Nicolas M Cuadrado Avila, Samuel Horváth, Martin Takáč* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 联邦强化学习, 净零建筑, 能源管理, 隐私保护, 分布式能源

**Comment:** Accepted at CO-Build Workshop ICML2025

> **TL;DR:** 本文提出一个隐私保护的联邦强化学习框架，用于净零建筑微电网的能源管理，实验证明联邦TRPO表现良好。

**AI_Comments:** 本文的创新点在于将联邦强化学习应用于净零建筑的能源管理，尤其强调了隐私保护。其重要性体现在为实现可持续和高效智能电网提供了可行的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 应对建筑微电网中能源优化的挑战，旨在通过协作和隐私保护的框架实现分布式能源的有效管理，同时降低能源成本和碳排放。

**Method:** 评估了PPO和TRPO两种强化学习算法，在定制的CityLearn环境中，使用合成数据模拟多建筑组成的净零能源微电网场景。

**Result:** 实验结果表明，联邦TRPO在无需超参数调整的情况下，与最先进的联邦强化学习方法表现相当。

**Conclusion:** 所提出的框架突出了协作学习在能源系统中实现最优控制策略的可行性，有助于推进可持续高效智能电网的目标。

> **ai_Abstract:** 本文提出一个协作且隐私保护的联邦强化学习框架，用于优化净零建筑微电网中的能源管理。该研究评估了PPO和TRPO算法，并在定制的CityLearn环境中模拟了多建筑场景。结果显示，联邦TRPO在无需超参数调整的情况下，性能与现有先进方法相当，证明了协作学习在能源系统优化中的可行性。

> **摘要翻译:** 这项工作通过一个协作和隐私保护的框架，研究了建筑微电网中最佳能源管理的挑战。我们评估了两种常见的强化学习算法（PPO和TRPO）在不同协作设置下，以有效地管理分布式能源（DERs）。利用定制版的CityLearn环境和合成生成的数据，我们模拟并设计了由多栋建筑组成的微电网的净零能源场景。我们的方法强调在确保隐私的同时，降低能源成本和碳排放。实验结果表明，联邦TRPO在无需超参数调整的情况下，与最先进的联邦强化学习方法表现相当。所提出的框架突出了协作学习在能源系统中实现最优控制策略的可行性，推进了可持续高效智能电网的目标。我们的代码可在此仓库中获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [443] [Real-Time Bayesian Detection of Drift-Evasive GNSS Spoofing in Reinforcement Learning Based UAV Deconfliction](https://arxiv.org/abs/2507.11173)
> *基于强化学习的无人机冲突消解中漂移规避GNSS欺骗的实时贝叶斯检测*

*Deepak Kumar Panda, Weisi Guo* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** GNSS spoofing, UAV, Bayesian detection, Reinforcement Learning, Change Point Detection

**Comment:** 

> **TL;DR:** 本文提出了一种贝叶斯在线变化点检测（BOCPD）方法，利用强化学习评论家网络的价值估计来实时检测无人机中微妙的漂移规避GNSS欺骗，其性能优于传统检测器。

**AI_Comments:** 本文通过将强化学习的评论家网络价值估计与贝叶斯变化点检测框架相结合，提出了一种创新方法，巧妙地检测由欺骗引起的微妙行为层面偏差，而非依赖直接的信号层面异常。其对“漂移规避”攻击的关注解决了传统方法常忽略的关键漏洞，显著提升了无人机的实时安全性。将强化学习用于无人机导航这类安全关键系统的异常检测尤为值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 自主无人机依赖GNSS进行定位和导航，但面临复杂的漂移规避欺骗攻击，这些攻击会逐渐改变轨迹而不触发传统信号级防御。传统检测方法因需要累积样本而导致延迟，因此需要鲁棒的实时检测方法来应对这种隐蔽的威胁。

**Method:** 本研究采用贝叶斯在线变化点检测（BOCPD）方法。该方法通过监测强化学习（RL）评论家网络中价值估计的时间变化，来检测无人机导航中由欺骗引起的微小行为偏差。

**Result:** 所提出的基于时间价值的框架在漂移规避欺骗攻击方面实现了更高的检测精度以及更低的误报率和漏报率。它优于传统的GNSS欺骗检测器、时间半监督学习框架和Page-Hinkley检验。

**Conclusion:** 通过监测强化学习评论家网络价值估计的BOCPD方法，为无人机中微妙的漂移规避GNSS欺骗提供了一种鲁棒有效的实时检测方案，从而增强了无人机的弹性。

> **ai_Abstract:** 本文旨在解决自主无人机在面对微妙的、漂移规避型GNSS欺骗攻击时的脆弱性，这类攻击因其渐进性而能规避传统检测方法。论文提出了一种新颖的实时检测框架，该框架利用贝叶斯在线变化点检测（BOCPD）来监测强化学习（RL）评论家网络中价值估计的时间变化。这种方法能有效识别无人机导航中细微的行为偏差。实验验证表明，与现有GNSS欺骗检测器和其他时间检测方法相比，这种基于时间价值的框架在准确性和误报/漏报率方面表现显著更优，从而增强了无人机对抗隐蔽攻击的弹性。

> **摘要翻译:** 自主无人机（UAV）依赖全球导航卫星系统（GNSS）伪距测量来实现精确的实时定位和导航。然而，这种依赖使其面临复杂的欺骗威胁，即攻击者操纵伪距以欺骗无人机接收器。其中，漂移规避欺骗攻击会巧妙地扰动测量值，逐渐偏离无人机轨迹，而不会触发传统的信号级反欺骗机制。传统的分布偏移检测技术通常需要累积达到阈值的样本数量，导致延迟，从而阻碍快速检测和及时响应。因此，鲁棒的时间尺度检测方法对于识别攻击开始并实现替代传感模式的应急计划至关重要，从而提高对隐蔽对抗性操纵的弹性。本研究探索了一种贝叶斯在线变化点检测（BOCPD）方法，该方法通过监测强化学习（RL）评论家网络中价值估计的时间变化来检测无人机导航中微小的行为偏差。实验结果表明，这种基于时间价值的框架优于传统的GNSS欺骗检测器、时间半监督学习框架和Page-Hinkley检验，在漂移规避欺骗攻击方面实现了更高的检测精度和更低的误报率和漏报率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [451] [Score-of-Mixture Training: Training One-Step Generative Models Made Simple via Score Estimation of Mixture Distributions](https://arxiv.org/abs/2502.09609)
> *混合分数训练：通过混合分布的分数估计简化一步生成模型的训练*

*Tejas Jayashankar, J. Jon Ryu, Gregory Wornell* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-07-14**

**Keywords:** 生成模型, 分数估计, 混合分布, 一步训练, 模型蒸馏

**Comment:** 29 pages, 12 figures. ICML 2025 (spotlight)

> **TL;DR:** 提出了一种名为混合分数训练（SMT）的新框架，用于训练一步生成模型，通过估计真实样本和伪样本之间混合分布的分数，实现简单、稳定且性能优越的训练。

**AI_Comments:** 该论文的创新点在于提出了混合分数训练（SMT）框架，通过估计混合分布的分数来简化一步生成模型的训练。其重要性体现在方法实现简单、对超参数调整需求低以及训练稳定性高，这些特性对于实际应用非常有利。实验结果也证实了其竞争力，使其成为一步生成模型训练领域的一个有前景的新选择。

<details>
  <summary>Details</summary>

**Motivation:** 该论文的动机是提出一种训练一步生成模型的新框架，旨在简化训练过程，使其易于实现、减少超参数调整并确保训练稳定性。

**Method:** 论文提出了混合分数训练（SMT）框架，通过最小化一类称为 $\alpha$-偏斜Jensen-Shannon散度的散度来训练一步生成模型。其核心是估计真实样本和伪样本在多个噪声水平下的混合分布分数。该方法支持从头开始训练（SMT）以及使用预训练扩散模型进行蒸馏（SMD）。

**Result:** 在CIFAR-10和ImageNet 64x64上的实验表明，SMT/SMD与现有方法相比具有竞争力，甚至可以超越现有方法。

**Conclusion:** SMT/SMD是一种有效且有竞争力的方法，可以简化一步生成模型的训练，并且在实验中表现出优于现有方法的潜力。

> **ai_Abstract:** 该论文提出了混合分数训练（SMT），一个用于训练一步生成模型的新框架。SMT通过估计真实和伪样本在不同噪声水平下的混合分布分数，并最小化 $\alpha$-偏斜Jensen-Shannon散度来实现。该方法支持从头训练和模型蒸馏（SMD），其特点是实现简单、超参数调整需求少且训练稳定。实验结果表明，SMT/SMD在CIFAR-10和ImageNet 64x64数据集上表现出与现有方法相当甚至更优的性能。

> **摘要翻译:** 我们提出了混合分数训练（SMT），这是一个通过最小化一类称为 $\alpha$-偏斜Jensen-Shannon散度的新颖框架，用于训练一步生成模型。SMT的核心是估计真实样本和伪样本在多个噪声水平下的混合分布分数。与一致性模型类似，我们的方法支持从头开始训练（SMT）以及使用预训练扩散模型进行蒸馏，我们称之为混合分数蒸馏（SMD）。它实现简单，只需要最少的超参数调整，并确保训练稳定。在CIFAR-10和ImageNet 64x64上的实验表明，SMT/SMD与现有方法相比具有竞争力，甚至可以超越现有方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [452] [Enhancing Cross Entropy with a Linearly Adaptive Loss Function for Optimized Classification Performance](https://arxiv.org/abs/2507.10574)
> *采用线性自适应损失函数增强交叉熵以优化分类性能*

*Jae Wan Shim* | **Category: cs.LG, cs.AI, cs.NE** | **Updated: 2025-07-10**

**Keywords:** 交叉熵, 损失函数, 分类, 线性自适应, 深度学习

**Comment:** 13 pages, 2 figures

> **TL;DR:** 本文提出了一种线性自适应交叉熵损失函数，通过在标准交叉熵基础上增加一个取决于真实类别预测概率的项，在保持效率的同时显著提高了分类准确性。

**AI_Comments:** 该论文的创新点在于提出了一个简单但有效的线性自适应项，将其集成到传统的交叉熵损失函数中，从而在不显著增加计算开销的情况下提升了分类性能。这种方法为损失函数的设计提供了一个新的视角，即通过微调与真实类别概率相关的部分来优化模型。

<details>
  <summary>Details</summary>

**Motivation:** 旨在增强分类任务中的优化过程，并提高分类性能，以克服标准交叉熵损失函数的潜在局限性。

**Method:** 提出了一种名为线性自适应交叉熵损失函数的新型度量，该函数在标准交叉熵损失函数的基础上增加了一个依赖于真实类别预测概率的额外项。该方法在ResNet模型上使用CIFAR-100数据集进行了评估。

**Result:** 初步结果显示，所提出的损失函数在分类准确性方面始终优于标准交叉熵损失函数。此外，该函数保持了简单性，并实现了与传统交叉熵损失函数几乎相同的效率。

**Conclusion:** 这些发现表明，所提出的方法可以拓宽未来损失函数设计的研究范围。

> **ai_Abstract:** 本文提出了一种名为线性自适应交叉熵损失函数的新型度量，该函数在标准交叉熵基础上增加了一个依赖于真实类别预测概率的项，旨在增强独热编码分类任务的优化过程。在ResNet模型和CIFAR-100数据集上的评估表明，该函数在提高分类准确性的同时，保持了与传统交叉熵损失函数相似的计算效率，为未来的损失函数设计提供了新的方向。

> **摘要翻译:** 我们提出线性自适应交叉熵损失函数。这是一种源自信息论的新颖度量。与标准交叉熵损失函数相比，所提出的函数增加了一个取决于真实类别预测概率的项。这一特性有助于增强涉及独热编码类别标签的分类任务中的优化过程。所提出的函数已在基于ResNet的模型上使用CIFAR-100数据集进行了评估。初步结果表明，所提出的函数在分类准确性方面始终优于标准交叉熵损失函数。此外，所提出的函数保持了简单性，实现了与传统交叉熵损失函数几乎相同的效率。这些发现表明，我们的方法可以拓宽未来损失函数设计的研究范围。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [454] [Uncovering Causal Relation Shifts in Event Sequences under Out-of-Domain Interventions](https://arxiv.org/abs/2507.10809)
> *揭示域外干预下事件序列中的因果关系变化*

*Kazi Tasnim Zinat, Yun Zhou, Xiang Lyu, Yawei Wang, Zhicheng Liu, Panpan Xu* | **Category: cs.LG** | **Updated: 2025-07-14**

**Keywords:** 因果推断, 事件序列, 域外干预, 平均治疗效果, Transformer

**Comment:** Accepted at ICANN 2025

> **TL;DR:** 本文提出了一种新的因果框架和基于Transformer的神经网络模型，用于在域外干预下估计事件序列中的因果关系变化，并在模拟和真实世界数据上表现优于基线。

**AI_Comments:** 本文的创新点在于首次系统地考虑并量化了域外干预对事件序列中因果关系的影响，这在现实世界的复杂场景中具有重要意义。通过引入新的ATE定义和结合Transformer模型，该方法为处理非i.i.d.数据和长距离依赖提供了有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有的因果推断工作主要关注指定域内的事件类型，而没有考虑域外干预的影响。在现实世界中，这些域外干预可以显著改变因果动态。为了解决这一空白，本文提出了一个新的框架。

**Method:** 本文提出了一个新的因果框架，定义了超出经典Rubin因果框架中独立同分布（i.i.d.）数据的平均治疗效果（ATE），以捕捉域外干预下时间过程中事件之间的因果关系变化。设计了一个无偏的ATE估计器，并开发了一个基于Transformer的神经网络模型来处理长距离时间依赖性和局部模式，同时将域外干预信息整合到过程建模中。

**Result:** 在模拟和真实世界数据集上的大量实验表明，在域外增强点过程中，我们的方法在ATE估计和拟合优度方面优于基线。

**Conclusion:** 本文提出的框架和模型能够有效揭示并量化域外干预下事件序列中的因果关系变化，并在实验中取得了优异的性能。

> **ai_Abstract:** 本文针对现有因果推断方法未能考虑域外干预影响的局限性，提出了一个新颖的因果框架，用于定义和估计在域外干预下事件序列中的因果关系变化（ATE）。该框架引入了一个无偏的ATE估计器，并结合了一个基于Transformer的神经网络模型，以有效处理时间依赖性并整合域外干预信息。实验结果表明，该方法在ATE估计和模型拟合方面均优于现有基线。

> **摘要翻译:** 在时间序列中推断事件对之间的因果关系适用于医疗保健、制造业和交通运输等许多领域。大多数现有的因果推断工作主要关注指定域内的事件类型，而没有考虑域外干预的影响。在现实世界中，这些域外干预可以显著改变因果动态。为了解决这一空白，我们提出了一个新的因果框架来定义平均治疗效果（ATE），超越了经典Rubin因果框架中的独立同分布（i.i.d.）数据，以捕捉域外干预下时间过程中事件之间的因果关系变化。我们设计了一个无偏的ATE估计器，并开发了一个基于Transformer的神经网络模型来处理长距离时间依赖性和局部模式，同时将域外干预信息整合到过程建模中。在模拟和真实世界数据集上的大量实验表明，我们的方法在域外增强点过程中，在ATE估计和拟合优度方面优于基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [457] [Are DeepSeek R1 And Other Reasoning Models More Faithful?](https://arxiv.org/abs/2501.08156)
> *DeepSeek R1 及其他推理模型是否更忠实？*

*James Chua, Owain Evans* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 推理模型, 忠实度, 思维链, 语言模型可解释性, 奖励模型

**Comment:** 10 pages, 8 figures

> **TL;DR:** 推理模型在描述提示线索对其答案的影响方面比传统模型更忠实，这有助于提高语言模型的可解释性。

**AI_Comments:** 这项研究通过量化推理模型描述其决策过程受外部提示线索影响的能力，对大型语言模型的可解释性进行了有价值的探索。其创新点在于提出了一种衡量模型“忠实度”的具体方法，并揭示了推理模型在这方面优于传统模型。此外，对奖励模型与忠实度之间关系的探讨也提供了新的视角。然而，研究明确指出了两个局限性：一是测试任务的人工性可能无法完全反映实际应用场景；二是只衡量了忠实度的一个特定方面。未来的研究应进一步验证这些发现的普适性，并探索更全面的忠实度评估方法。

<details>
  <summary>Details</summary>

**Motivation:** 评估推理模型（通过强化学习训练以解决推理任务的语言模型）的思维链（CoT）是否比传统模型更忠实。

**Method:** 研究人员在一个现有的忠实思维链测试上评估了三种推理模型（基于Qwen-2.5、Gemini-2和DeepSeek-V3-Base）。他们通过测试模型是否能描述提示中的线索如何影响其对MMLU问题的答案来衡量忠实度，例如，当添加“斯坦福教授认为答案是D”等线索时，模型是否能描述其答案转向D的原因。他们评估了七种类型的线索，如误导性少样本示例和用户提出的暗示性后续问题。此外，他们还进行了一项额外实验，以探究奖励模型的使用是否会导致忠实度下降。

**Result:** 推理模型比所有测试的非推理模型（包括Claude-3.5-Sonnet和GPT-4o）更可靠地描述了影响它们的线索。例如，DeepSeek-R1 推理模型描述线索影响的比例为59%，而非推理的DeepSeek模型为7%。额外的实验表明，奖励模型的使用可能导致忠实度较低的响应。

**Conclusion:** 推理模型忠实度的提高对语言模型的可解释性来说是有前景的。

> **ai_Abstract:** 本研究探讨了通过强化学习训练的推理模型，其思维链（CoT）是否比传统语言模型更忠实。研究人员通过测试模型描述提示线索对其MMLU问题答案影响的能力来衡量忠实度。实验结果显示，推理模型（如DeepSeek-R1）比非推理模型（包括GPT-4o和Claude-3.5-Sonnet）能更可靠地描述线索的影响。此外，研究还发现奖励模型的使用可能导致较低的忠实度。尽管研究存在测试任务人工化和忠实度衡量维度有限的局限性，但作者认为推理模型忠实度的提升对语言模型的可解释性具有积极意义。

> **摘要翻译:** 通过强化学习训练以解决推理任务的语言模型取得了显著成果。我们将这些模型称为推理模型。推理模型的思维链（CoT）是否比传统模型更忠实？我们在一个现有的忠实CoT测试中评估了三种推理模型（基于Qwen-2.5、Gemini-2和DeepSeek-V3-Base）。为了衡量忠实度，我们测试模型是否能描述其提示中的线索如何影响其对MMLU问题的答案。例如，当提示中加入“一位斯坦福教授认为答案是D”时，模型有时会将答案切换到D。在这种情况下，DeepSeek-R1推理模型在59%的时间里描述了线索的影响，而非推理的DeepSeek模型则为7%。我们评估了七种类型的线索，例如误导性少样本示例和用户提出的暗示性后续问题。推理模型比所有测试的非推理模型（包括Claude-3.5-Sonnet和GPT-4o）更可靠地描述了影响它们的线索。在另一项额外实验中，我们提供了证据表明奖励模型的使用导致了较低的忠实度响应——这可能有助于解释为什么非推理模型的忠实度较低。我们的研究有两个主要局限性。首先，我们使用一组人工任务来测试忠实度，这可能无法反映实际使用场景。其次，我们只衡量了忠实度的一个特定方面——模型是否能描述线索的影响。未来的研究应调查推理模型在忠实度方面的优势是否适用于更广泛的测试。尽管如此，我们认为忠实度的这种提高对语言模型的可解释性来说是有前景的。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [470] [Fully Data-driven but Interpretable Human Behavioural Modelling with Differentiable Discrete Choice Model](https://arxiv.org/abs/2412.19403)
> *基于全数据驱动但可解释的微分离散选择模型的人类行为建模*

*Fumiyasu Makinoshima, Tatsuya Mitomi, Fumiya Makihara, Eigo Segawa* | **Category: cs.LG, cs.AI, cs.HC, cs.MA** | **Updated: 2025-07-15**

**Keywords:** 可微分离散选择模型, 人类行为建模, 可解释性, 数据驱动, 行为控制

**Comment:** 

> **TL;DR:** 本文提出Diff-DCM，一个全数据驱动且可解释的微分离散选择模型，用于人类行为建模、预测和控制，克服了传统方法对领域知识的依赖，并展现出高效性和提供行为洞察的能力。

**AI_Comments:** 本文提出了一种新颖的方法Diff-DCM，其创新点在于将可微分编程引入离散选择模型，实现了全数据驱动且可解释的人类行为建模。这解决了传统方法对专家领域知识的重度依赖，大大提升了模型自动化程度和普适性。其能够提供行为洞察（如最优干预路径）的特性，使其在实际应用中具有重要价值，尤其是在需要干预和预测行为的领域。计算效率高也是一个显著优点。

<details>
  <summary>Details</summary>

**Motivation:** 传统的离散选择模型在人类行为建模中依赖大量专家领域知识，实现全自动化但可解释的复杂人类行为建模是一个长期挑战。

**Method:** 本文引入了可微分离散选择模型（Diff-DCM），这是一种通过可微分编程实现的全数据驱动方法。Diff-DCM无需先验知识，仅凭输入特征和选择结果，即可估计可解释的闭式效用函数以重现观察到的行为。

**Result:** 通过综合实验（包括合成数据和真实世界数据），Diff-DCM被证明适用于各种类型的数据，估算所需计算资源少，可在数十秒内在笔记本电脑上完成。利用其可微分性，Diff-DCM还能提供关于人类行为的有用见解，例如有效的行为改变的最优干预路径。

**Conclusion:** 这项研究为人类行为的全自动化、可靠建模、预测和控制提供了坚实基础。

> **ai_Abstract:** 本文提出了一种名为Diff-DCM（可微分离散选择模型）的创新方法，旨在解决传统离散选择模型对领域知识的依赖问题，实现全数据驱动且可解释的复杂人类行为建模。Diff-DCM利用可微分编程，仅通过输入特征和选择结果即可学习可解释的效用函数。实验证明，该模型不仅计算效率高，能处理多种数据类型，还能利用其可微分性提供对人类行为的深入洞察，例如识别最优干预路径以促进行为改变。这项工作为人类行为的自动化建模、预测和控制奠定了坚实基础。

> **摘要翻译:** 离散选择模型对于建模人类行为中的各种决策过程至关重要。然而，这些模型的规范在很大程度上依赖于专家的领域知识，而复杂人类行为的全自动化但可解释的建模一直是一个长期挑战。在本文中，我们引入了可微分离散选择模型（Diff-DCM），这是一种用于可解释地建模、学习、预测和控制复杂人类行为的全数据驱动方法，通过可微分编程实现。Diff-DCM仅凭输入特征和选择结果，无需任何先验知识，即可估计可解释的闭式效用函数以重现观察到的行为。通过合成数据和真实世界数据的综合实验表明，Diff-DCM可以应用于各种类型的数据，并且估计所需的计算资源很少，可以在没有加速器的笔记本电脑上在数十秒内完成。在这些实验中，我们还证明，利用其可微分性，Diff-DCM可以提供关于人类行为的有用见解，例如有效行为改变的最优干预路径。这项研究为人类行为的全自动化和可靠建模、预测和控制提供了坚实基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [475] [Multi-View Node Pruning for Accurate Graph Representation](https://arxiv.org/abs/2503.11737)
> *多视角节点剪枝用于精确图表示*

*Jiseong Park, Hanjin Kim, Seojin Kim, Jueun Choi, Doheon Lee, Sung Ju Hwang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 图剪枝, 多视角学习, 图表示学习, 图池化, 重建损失

**Comment:** Jiseong Park and Hanjin Kim are co-first author for this work

> **TL;DR:** MVP是一种新的图剪枝方法，通过多视角框架和重建损失，解决了现有图池化方法在节点修剪时未考虑特征相关性的问题，显著提升了图表示学习的性能。

**AI_Comments:** MVP的创新之处在于引入了多视角框架和重建损失来优化图节点剪枝过程，这克服了传统方法仅依赖节点度数或单一注意力机制的局限性。通过从多个视角评估节点的重要性，并结合重建损失确保信息保留，MVP能够更准确地识别并移除冗余节点，从而提升图表示学习的效率和准确性。其重要性在于为图压缩和图神经网络的性能提升提供了一种有效且通用的方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图池化方法在修剪节点时，通常只基于注意力分数，导致简单地移除度数较低的节点，而忽略了节点特征层面与任务的相关性，这限制了图压缩的效率和准确性。

**Method:** 本文提出了多视角剪枝（MVP）方法。MVP首先通过利用预定义模态或随机划分输入特征来构建多个视角图，以从不同角度考虑每个节点的重要性。然后，MVP结合重建损失和任务损失来学习每个节点的得分。MVP可以与任何分层池化框架结合使用。

**Result:** MVP在多个基准数据集上与两种图池化方法结合验证，结果显示它显著提升了基础图池化方法的性能，并超越了所有基线方法。进一步分析表明，多视角编码和重建损失是MVP成功的关键，并且MVP确实识别出了根据领域知识不那么重要的节点。

**Conclusion:** MVP通过引入多视角框架和重建损失，有效解决了图池化中节点剪枝的局限性，显著提升了图表示学习的准确性，并能识别出数据中不重要的节点。

> **ai_Abstract:** 本文提出了一种名为多视角剪枝（MVP）的新型图剪枝方法，旨在解决现有图池化方法在节点修剪时未能充分考虑特征相关性的问题。MVP通过构建多视角图并结合重建损失和任务损失来为节点评分，从而从多维度评估节点的重要性。实验结果表明，MVP能显著提升图池化方法的性能，并超越现有基线，其成功归因于多视角编码和重建损失的有效结合。

> **摘要翻译:** 图池化将整个图压缩成一个更小的粗化图，是图表示学习的重要组成部分。为了有效地压缩给定图，图池化方法通常通过基于注意力的分数和任务损失来丢弃节点。然而，这往往导致简单地移除度数较低的节点，而没有考虑它们在特征层面与给定任务的相关性。为了解决这个问题，我们提出了一种基于多视角框架和重建损失的图剪枝方法——多视角剪枝（MVP）。给定一个图，MVP首先通过利用预定义模态或随机划分输入特征来为不同视角构建多个图，以从不同角度考虑每个节点的重要性。然后，它通过同时考虑重建损失和任务损失来学习每个节点的得分。MVP可以与任何分层池化框架结合以对节点进行评分。我们将MVP与两种图池化方法结合，在多个基准数据集上进行了验证，结果表明它显著提高了基础图池化方法的性能，超越了所有基线。进一步分析表明，多视角编码和重建损失是MVP成功的关键，并且它确实根据领域知识识别出了不那么重要的节点。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [477] [Player-Team Heterogeneous Interaction Graph Transformer for Soccer Outcome Prediction](https://arxiv.org/abs/2507.10626)
> *用于足球比赛结果预测的球员-球队异构交互图Transformer*

*Lintao Wang, Shiwen Xu, Michael Horton, Joachim Gudmundsson, Zhiyong Wang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 足球结果预测, 异构交互, 图Transformer, 深度学习, 球员评估

**Comment:** 

> **TL;DR:** HIGFormer利用多级图增强Transformer模型来建模异构的球员和球队交互，以提高足球比赛结果预测的准确性。

**AI_Comments:** 本文创新性地提出了HIGFormer模型，通过引入多级异构交互图和Transformer机制，有效解决了现有足球比赛预测模型忽视复杂球员-球队交互的问题。其结合图卷积和Transformer的架构，以及对球员和球队层面信息的全面捕捉，是其成功的关键。该模型不仅提升了预测准确性，还为球员评估和战术分析提供了新工具，具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有足球比赛结果预测方法常忽略球员和球队之间异构交互的复杂性，而这对于准确建模比赛动态至关重要。

**Method:** 提出了HIGFormer（异构交互图Transformer）模型，一个基于图增强Transformer的深度学习模型。它包含三个主要组件：球员交互网络（通过异构交互图编码球员表现，结合局部图卷积和全局图增强Transformer）、球队交互网络（从球队视角构建交互图建模历史比赛关系）和比赛比较Transformer（联合分析球队和球员级别信息预测比赛结果）。

**Result:** 在WyScout开放访问数据集（一个大规模真实世界足球数据集）上的广泛实验表明，HIGFormer在预测准确性方面显著优于现有方法。

**Conclusion:** HIGFormer不仅能准确预测比赛结果，还能为球员表现评估提供有价值的见解，为人才发掘和球队策略分析提供新视角。

> **ai_Abstract:** 本文提出了HIGFormer，一个新颖的基于图增强Transformer的深度学习模型，旨在解决现有足球比赛结果预测方法忽略球员和球队间异构交互的问题。HIGFormer通过多级交互框架捕捉细粒度球员动态和高层次球队交互，包含球员交互网络、球队交互网络和比赛比较Transformer。在大型真实世界数据集上的实验表明，HIGFormer在预测准确性方面显著优于现有方法，并能为球员表现评估提供新视角。

> **摘要翻译:** 预测足球比赛结果是一项具有挑战性的任务，原因在于比赛固有的不可预测性以及影响结果的众多动态因素。尽管传统上依赖于细致的特征工程，但深度学习技术最近在直接学习有效的球员和球队表示以进行足球结果预测方面显示出巨大潜力。然而，现有方法通常忽略了球员和球队之间交互的异构性，这对于准确建模比赛动态至关重要。为了弥补这一空白，我们提出了HIGFormer（异构交互图Transformer），一个新颖的基于图增强Transformer的深度学习模型，用于足球结果预测。HIGFormer引入了一个多级交互框架，能够捕捉细粒度的球员动态和高层次的球队交互。具体来说，它包括：（1）球员交互网络，通过异构交互图编码球员表现，结合局部图卷积和全局图增强Transformer；（2）球队交互网络，从球队视角构建交互图以建模历史比赛关系；以及（3）比赛比较Transformer，联合分析球队和球员级别的信息以预测比赛结果。在WyScout开放访问数据集（一个大规模真实世界足球数据集）上的广泛实验表明，HIGFormer在预测准确性方面显著优于现有方法。此外，我们还提供了关于如何利用我们的模型进行球员表现评估的宝贵见解，为人才发掘和球队策略分析提供了新视角。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [479] [Gradient Regularization-based Neural Granger Causality](https://arxiv.org/abs/2507.11178)
> *基于梯度正则化的神经格兰杰因果关系*

*Meiliang Liu, Huiwen Dong, Xiaoxiao Yang, Yunfang Xu, Zijin Li, Zhengye Si, Xinyue Yang, Zhiwen Zhao* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 格兰杰因果关系, 神经网络, 梯度正则化, 时间序列, 基因调控网络

**Comment:** 9 pages,3 figures, conference

> **TL;DR:** 本文提出了一种名为GRNGC的新型神经格兰杰因果关系模型，该模型利用梯度正则化，仅需一个时间序列预测模型，显著降低了计算成本并提高了灵活性，在多个数据集上表现优于现有基线。

**AI_Comments:** GRNGC通过摆脱传统的分量式建模方法，并采用梯度正则化，实现了创新。这种方法允许使用单个模型进行因果推断，并避免了对第一层权重施加稀疏性惩罚可能带来的问题。其与多种神经网络架构的兼容性也显著增强了模型的普适性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于神经网络的格兰杰因果关系模型存在局限性：大多数采用分量式架构，导致计算成本高昂；对神经网络第一层权重施加稀疏性惩罚会削弱模型捕获复杂交互的能力。

**Method:** 本文提出了基于梯度正则化的神经格兰杰因果关系（GRNGC）模型。该模型仅需要一个时间序列预测模型，并通过对模型输入和输出之间的梯度应用$L_1$正则化来推断格兰杰因果关系。此外，GRNGC不局限于特定的时间序列预测模型，可以与KAN、MLP和LSTM等多种架构实现，提供了增强的灵活性。

**Result:** 在DREAM、Lorenz-96、fMRI BOLD和CausalTime上的数值模拟表明，GRNGC优于现有基线并显著降低了计算开销。同时，在真实世界的DNA、酵母、HeLa和膀胱尿路上皮癌数据集上的实验进一步验证了该模型在重建基因调控网络方面的有效性。

**Conclusion:** GRNGC通过提供更高的计算效率、灵活性以及在各种任务（包括基因调控网络重建）中的强大性能，有效解决了现有神经格兰杰因果关系模型的局限性。

> **ai_Abstract:** GRNGC是一种新颖的神经格兰杰因果关系模型，旨在克服现有方法的计算和复杂性限制。通过采用单个时间序列预测模型并对输入-输出梯度应用$L_1$正则化，GRNGC提高了效率和灵活性。它在各种合成和真实世界数据集上表现出卓越的性能和显著降低的计算成本，特别是在重建基因调控网络方面。

> **摘要翻译:** 随着深度学习技术的进步，各种基于神经网络的格兰杰因果关系模型被提出。尽管这些模型取得了显著改进，但仍存在一些局限性。大多数现有方法采用分量式架构，需要为每个时间序列构建一个单独的模型，这导致了大量的计算成本。此外，对神经网络第一层权重施加稀疏性惩罚以提取因果关系削弱了模型捕获复杂交互的能力。为了解决这些局限性，我们提出了基于梯度正则化的神经格兰杰因果关系（GRNGC），它只需要一个时间序列预测模型，并对模型输入和输出之间的梯度应用$L_1$正则化来推断格兰杰因果关系。此外，GRNGC不局限于特定的时间序列预测模型，可以与KAN、MLP和LSTM等多种架构实现，提供了增强的灵活性。在DREAM、Lorenz-96、fMRI BOLD和CausalTime上的数值模拟表明，GRNGC优于现有基线并显著降低了计算开销。同时，在真实世界的DNA、酵母、HeLa和膀胱尿路上皮癌数据集上的实验进一步验证了该模型在重建基因调控网络方面的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [481] [Imitation Learning from a Single Temporally Misaligned Video](https://arxiv.org/abs/2502.05397)
> *从单个时间错位视频中进行模仿学习*

*William Huey, Huaxiaoyue Wang, Anne Wu, Yoav Artzi, Sanjiban Choudhury* | **Category: cs.LG** | **Updated: 2025-07-14**

**Keywords:** 模仿学习, 时间错位, 序列匹配, 奖励函数, ORCA

**Comment:** ICML 2025

> **TL;DR:** 该论文提出了ORCA，一种用于从时间错位视频中进行模仿学习的序列级匹配方法，其性能显著优于帧级匹配方法。

**AI_Comments:** 该论文通过将模仿学习的焦点从帧级匹配转移到序列级匹配，提出了一个新颖的视角，这对于处理时间错位至关重要。ORCA奖励函数是一种创新方法，有效解决了实际演示中常见的时序排序问题。在具有挑战性的机器人任务上实现的显著性能提升，突显了该方法的重要性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有模仿学习方法在处理单个视觉演示中存在的时序错位问题时面临挑战，因为它们采用的帧级匹配无法强制执行时间顺序或确保一致的进展。

**Method:** 提出了一种名为ORCA（有序覆盖对齐）的新方法，其核心思想是在序列层面定义匹配。ORCA是一个密集的每时间步奖励函数，用于衡量代理以正确顺序覆盖演示帧的概率，实现当一个序列以与另一个序列相同的顺序成功覆盖所有子目标时的完美匹配。

**Result:** 在时间错位的演示中，ORCA在Meta-world任务中实现了4.5倍的性能提升（平均归一化回报从0.11提高到0.50），在Humanoid-v4任务中实现了6.6倍的性能提升（平均回报从6.55提高到43.3），均优于最佳帧级匹配算法。此外，ORCA对不同程度的时间错位具有鲁棒性。

**Conclusion:** 本研究表明，与传统的帧级匹配方法相比，采用序列级匹配（特别是通过提出的ORCA奖励函数）能显著改善从单个时间错位视频演示中进行的模仿学习，并且对错位具有鲁棒性。

> **ai_Abstract:** 本论文解决了从单个视觉演示中进行模仿学习的挑战，特别是当演示存在时间错位时。论文指出，现有帧级匹配方法因无法强制执行时间顺序而不足。作者提出了ORCA（有序覆盖对齐），这是一种新颖的序列级匹配方法，将完美匹配定义为按正确顺序覆盖子目标。作为一种密集的每时间步奖励函数，ORCA在Meta-world和Humanoid-v4任务上显著优于帧级匹配算法，展示了更高的性能和对时间错位的鲁棒性。

> **摘要翻译:** 我们研究了从单个视觉演示中学习顺序任务的问题。当演示由于时间变化、体现差异或执行不一致而出现时间错位时，就会出现一个关键挑战。现有方法将模仿视为一个分布匹配问题，对齐代理和演示之间的单个帧。然而，我们表明这种帧级匹配无法强制执行时间顺序或确保一致的进展。我们的关键见解是，匹配应该在序列层面定义。我们提出，当一个序列成功地以与另一个序列相同的顺序覆盖所有子目标时，就会发生完美匹配。我们提出了 ORCA（有序覆盖对齐），这是一种密集的每时间步奖励函数，用于衡量代理以正确顺序覆盖演示帧的概率。在时间错位的演示中，我们表明使用 ORCA 奖励训练的代理在 Meta-world 任务中实现了 4.5 倍的改进（平均归一化回报从 0.11 提高到 0.50），在 Humanoid-v4 任务中实现了 6.6 倍的改进（平均回报从 6.55 提高到 43.3），优于最佳帧级匹配算法。我们还提供了实证分析，表明 ORCA 对不同程度的时间错位具有鲁棒性。我们的代码可在 https://github.com/portal-cornell/orca/ 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [485] [Mixture of Experts in Large Language Models](https://arxiv.org/abs/2507.11181)
> *大型语言模型中的专家混合*

*Danyang Zhang, Junhao Song, Ziqian Bi, Yingfang Yuan, Tianyang Wang, Joe Yeong, Junfeng Hao* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 专家混合, 大型语言模型, 模型架构, 稀疏性, 综述

**Comment:** 

> **TL;DR:** 本文全面回顾了大型语言模型中的专家混合（MoE）架构，强调其在提升模型性能和保持低计算开销方面的能力。

**AI_Comments:** 这篇论文以综述的形式，全面梳理了MoE架构在LLM中的应用，其价值在于为研究人员提供了一个结构化的MoE知识体系，并指明了未来的研究方向。其重要性在于，MoE作为一种高效的模型扩展方法，对于解决LLM的计算和性能瓶颈具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在全面回顾大型语言模型中的专家混合（MoE）架构，并突出其在显著提升模型性能同时保持最小计算开销的能力。

**Method:** 本文通过系统分析理论基础、核心架构设计和大型语言模型（LLM）应用，审查了专家门控和路由机制、分层和稀疏MoE配置、元学习方法、多模态和多任务学习场景、实际部署案例以及深度学习的最新进展和挑战。

**Result:** 分析确定了MoE的关键优势，包括与等效贝叶斯方法相比更优的模型容量、改进的任务特定性能以及有效扩展模型容量的能力。研究还强调了确保专家多样性、准确校准和可靠推理聚合的重要性。

**Conclusion:** 本文概述了当前的研究局限性、开放挑战和未来有前景的方向，为MoE架构及其应用的持续创新奠定了基础。

> **ai_Abstract:** 本文全面综述了大型语言模型（LLM）中的专家混合（MoE）架构。文章通过系统分析MoE的理论、设计和应用，阐述了其在提高模型性能和扩展模型容量方面的优势，同时强调了专家多样性、校准和推理聚合的重要性。文末指出了当前研究的局限性、面临的挑战以及未来的发展方向。

> **摘要翻译:** 本文对大型语言模型中的专家混合（MoE）架构进行了全面回顾，强调了其在显著增强模型性能的同时保持最小计算开销的能力。通过对理论基础、核心架构设计和大型语言模型（LLM）应用的系统分析，我们审查了专家门控和路由机制、分层和稀疏MoE配置、元学习方法、多模态和多任务学习场景、实际部署案例以及深度学习的最新进展和挑战。我们的分析确定了MoE的关键优势，包括与等效贝叶斯方法相比更优的模型容量、改进的任务特定性能以及有效扩展模型容量的能力。我们还强调了确保专家多样性、准确校准和可靠推理聚合的重要性，因为这些对于最大化MoE架构的有效性至关重要。最后，本综述概述了当前的研究局限性、开放挑战和未来有前景的方向，为MoE架构及其应用的持续创新奠定了基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [500] [An Adaptive Volatility-based Learning Rate Scheduler](https://arxiv.org/abs/2507.10575)
> *一种基于波动性的自适应学习率调度器*

*Kieran Chai Kai Ren* | **Category: cs.LG** | **Updated: 2025-07-11**

**Keywords:** 学习率调度, 自适应, 波动性, 深度学习, 泛化

**Comment:** 

> **TL;DR:** VolSched是一种新的自适应学习率调度器，通过计算准确率波动性来动态调整学习率，从而提高深度神经网络的泛化能力。

**AI_Comments:** VolSched的创新之处在于将随机过程中的波动性概念引入学习率调度，通过动态调整而非固定模式，提高了模型的泛化能力。其通过促进更长的探索阶段和找到更平坦的最小值来提升性能，为深度学习优化提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 有效的学习率调度对于训练深度神经网络至关重要，但流行的预定义和自适应调度器可能导致次优的泛化性能。

**Method:** 本文提出VolSched，一种受随机过程（如几何布朗运动）中波动性概念启发的自适应学习率调度器。它通过计算长期和短期准确率波动性的比率来动态调整学习率，以逃离平台期并稳定训练，从而更有效地探索损失景观。

**Result:** VolSched在CIFAR-100数据集上与ResNet-18和ResNet-34结合使用时，top-1准确率分别提高了1.4和1.3个百分点。损失曲线分析显示VolSched促进了更长的探索阶段。Hessian定量分析表明，VolSched找到的最终解比次优基线平坦38%，获得了更宽的最小值，从而提高了泛化性能。

**Conclusion:** VolSched通过动态调整学习率，能够有效提高深度神经网络的泛化能力，并找到更平坦的最小值。

> **ai_Abstract:** 本文提出了一种名为VolSched的新型自适应学习率调度器，它借鉴了随机过程中的波动性概念，通过动态调整学习率来优化深度神经网络的训练。VolSched根据长期和短期准确率波动性的比率来调整学习率，以促进更有效的损失景观探索。实验证明，VolSched在CIFAR-100数据集上显著提高了ResNet模型的准确率，并找到了更平坦的损失最小值，从而提升了模型的泛化能力。

> **摘要翻译:** 有效的学习率（LR）调度对于训练深度神经网络至关重要。然而，流行的预定义和自适应调度器仍然可能导致次优的泛化。本文引入了VolSched，这是一种新颖的自适应LR调度器，其灵感来源于随机过程（如几何布朗运动）中的波动性概念，用于动态调整学习率。通过计算长期和短期准确率波动性之间的比率，VolSched增加LR以逃离平台期并降低LR以稳定训练，从而使模型更有效地探索损失景观。我们在CIFAR-100数据集上使用标准增强管道，针对强大的基线评估了VolSched。当与ResNet-18和ResNet-34配对时，我们的调度器提供了持续的性能增益，分别将top-1准确率提高了1.4和1.3个百分点。对损失曲线的分析表明，VolSched促进了更长的探索阶段。对Hessian的定量分析表明，VolSched找到的最终解比次优基线平坦38%，从而使模型获得更宽的最小值，从而获得更好的泛化性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [502] [Constrained Online Convex Optimization with Polyak Feasibility Steps](https://arxiv.org/abs/2502.13112)
> *带有Polyak可行性步骤的约束在线凸优化*

*Spencer Hutchinson, Mahnoosh Alizadeh* | **Category: cs.LG, math.OC** | **Updated: 2025-07-15**

**Keywords:** 在线凸优化, 约束满足, Polyak步长, 次梯度下降, 遗憾

**Comment:** accepted at ICML 2025

> **TL;DR:** 本文提出一种新的在线凸优化算法，通过Polyak可行性步骤，在保持O(√T)遗憾的同时，实现任意时刻的约束满足。

**AI_Comments:** 创新点在于引入Polyak可行性步骤，使得在线凸优化能在任意时刻满足约束，而非仅是累积满足，这在实际应用中具有重要意义。该方法巧妙地结合了在线梯度下降和Polyak步长，有效解决了约束满足和遗憾之间的权衡问题。

<details>
  <summary>Details</summary>

**Motivation:** 现有工作在约束在线凸优化中实现了O(√T)遗憾和累积约束满足，但未能实现任意时刻的约束满足，这限制了其在需要严格实时约束满足场景下的应用。

**Method:** 算法在每次在线梯度下降后，对约束函数应用一个次梯度下降步骤，步长选择遵循著名的Polyak步长公式。

**Result:** 实现了任意时刻的约束满足 ($g(x_t) \leq 0 \ \forall t \in [T]$) 和匹配的 $O(\sqrt{T})$ 遗憾保证。并通过数值实验验证了该方法。

**Conclusion:** 通过引入Polyak可行性步骤，可以在在线凸优化中实现更强的任意时刻约束满足，而不牺牲遗憾性能，为实际应用提供了更可靠的保证。

> **ai_Abstract:** 本文研究了带有固定约束函数的在线凸优化问题。与先前只提供累积约束满足的工作不同，本文提出了一种新方法，通过在每次在线梯度下降后应用基于Polyak步长的次梯度下降步骤，实现了更强的任意时刻约束满足，同时保持了匹配的$O(\sqrt{T})$遗憾。数值实验验证了该方法的有效性。

> **摘要翻译:** 在这项工作中，我们研究了具有固定约束函数 $g : \mathbb{R}^d \rightarrow \mathbb{R}$ 的在线凸优化。先前关于此问题的工作已显示出 $O(\sqrt{T})$ 的遗憾和累积约束满足 $\sum_{t=1}^{T} g(x_t) \leq 0$，同时仅访问在执行动作 $g(x_t), \partial g(x_t)$ 处的约束值和次梯度。使用相同的约束信息，我们展示了更强的任意时刻约束满足保证 $g(x_t) \leq 0 \ \forall t \in [T]$，以及匹配的 $O(\sqrt{T})$ 遗憾保证。这些贡献归功于我们使用Polyak可行性步骤来确保约束满足而不牺牲遗憾的方法。具体来说，在每次在线梯度下降步骤之后，我们的算法对约束函数应用一个次梯度下降步骤，其中步长根据著名的Polyak步长选择。我们通过数值实验进一步验证了这种方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [507] [Semantic Context for Tool Orchestration](https://arxiv.org/abs/2507.10820)
> *工具编排的语义上下文*

*Robert Müller* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 语义上下文, 工具编排, 大型语言模型, 上下文多臂赌博机, FiReAct

**Comment:** Workshop on Computer Use Agents @ ICML2025

> **TL;DR:** 本文证明语义上下文（SC）是鲁棒工具编排的基础，通过理论（SC-LinUCB）、LLM实证验证和FiReAct管道展示其在动态和大规模工具空间中的有效性、效率和适应性。

**AI_Comments:** 这篇论文通过结合理论分析（上下文多臂赌博机）和实际应用（LLM工具编排）展示了语义上下文的重要性。其创新点在于将描述性工具信息作为核心，解决了大规模动态工具空间中的编排挑战。FiReAct管道的提出及其在万级工具上的验证，表明了该方法在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 证明语义上下文（SC），利用描述性工具信息，是实现鲁棒工具编排的基础组件。

**Method:** 1. 提供基于上下文多臂赌博机的理论基础，引入SC-LinUCB并证明其性能。2. 通过大型语言模型（LLM）进行实证验证，在静态和非平稳设置中展示SC的重要性。3. 提出了FiReAct管道，并在包含超过10,000个工具的基准上验证了SC检索使LLM能够有效编排大规模动作空间。

**Result:** 1. SC-LinUCB在理论上实现了更低的遗憾，并能更好地适应动态动作空间。2. SC对于LLM在上下文学习中至关重要，在静态设置中实现高效学习，在非平稳设置中实现鲁棒适应。3. 基于SC的检索使LLM能够有效编排超过10,000个工具的大规模动作空间。

**Conclusion:** 语义上下文（SC）为构建更样本高效、自适应和可扩展的编排代理提供了全面的指导。

> **ai_Abstract:** 本文提出语义上下文（SC）是鲁棒工具编排的关键要素。研究通过理论分析（引入SC-LinUCB，证明其低遗憾和适应性）、LLM实证验证（SC对上下文学习的效率和鲁棒性至关重要）以及提出的FiReAct管道（在大型工具集上实现有效编排）三个方面，全面论证了SC的有效性，为开发更高效、自适应和可扩展的编排代理提供了指导。

> **摘要翻译:** 本文证明语义上下文（SC），利用描述性工具信息，是鲁棒工具编排的基础组件。我们的贡献是三方面的。首先，我们使用上下文多臂赌博机提供了理论基础，引入了SC-LinUCB并证明其实现了更低的遗憾，并在动态动作空间中表现出良好的适应性。其次，我们提供了与大型语言模型（LLM）的并行实证验证，表明SC对于在静态（高效学习）和非平稳（鲁棒适应）设置中的成功上下文学习至关重要。第三，我们提出了FiReAct管道，并在一个拥有超过10,000个工具的基准上证明了基于SC的检索使LLM能够有效地在大规模动作空间中进行编排。这些发现为构建更样本高效、自适应和可扩展的编排代理提供了全面的指导。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [515] [X Hacking: The Threat of Misguided AutoML](https://arxiv.org/abs/2401.08513)
> *X攻击：误导性自动化机器学习的威胁*

*Rahul Sharma, Sergey Redyuk, Sumantrak Mukherjee, Andrea Šipka, Eyke Hüllermeier, Sebastian Vollmer, David Selby* | **Category: cs.LG, cs.CR** | **Updated: 2025-07-15**

**Keywords:** X攻击, 可解释AI, 自动化机器学习, 模型多样性, 信息冗余

**Comment:** Accepted to ICML 2025

> **TL;DR:** 论文引入了“X攻击”概念，即操纵可解释AI指标以支持预设结论。研究发现自动化机器学习管道可被利用进行X攻击，贝叶斯优化能加速此过程，并提出检测和预防方法。

**AI_Comments:** 这篇论文揭示了可解释人工智能领域一个重要且潜在的滥用风险，即“X攻击”。其创新之处在于将传统的p值攻击概念扩展到XAI指标，并通过实证研究证明了自动化机器学习管道加速这种攻击的可能性。这对于确保XAI的诚信和可靠性具有重要的警示意义，并促使研究人员思考如何设计更鲁棒和防篡改的XAI方法。

<details>
  <summary>Details</summary>

**Motivation:** 可解释AI（XAI）和可解释机器学习方法旨在建立对模型预测的信任，但也可能导致分析师滥用XAI指标来支持预设结论，这是一种“X攻击”行为。该研究旨在揭示这种威胁并探讨其影响。

**Method:** 论文引入了X攻击的概念，并展示了自动化机器学习管道如何利用模型多样性（Rashomon集）来寻找期望的解释。研究将解释与准确性之间的权衡公式化为多目标优化问题，并通过贝叶斯优化和随机抽样进行经验性比较。

**Result:** 经验证明，在实际数据集中，贝叶斯优化对于易受影响的特征，平均能将X攻击的速度提高3倍，相比随机抽样。此外，数据集对X攻击的脆弱性可以通过特征之间的信息冗余来确定。

**Conclusion:** XAI方法存在被恶意利用进行“X攻击”的风险，自动化机器学习管道可以加速这一过程。数据集的脆弱性与特征信息冗余有关。需要开发检测和预防X攻击的方法，并关注其对XAI可信度和可复现性的伦理影响。

> **ai_Abstract:** 本文提出了“X攻击”的概念，即利用可解释AI（XAI）方法的缺陷，通过操纵XAI指标（如SHAP值）来支持预设结论。研究表明，自动化机器学习管道可以轻易地被修改，以大规模利用模型多样性（Rashomon集）来寻找符合预期的解释。作者将解释与准确性之间的权衡建模为多目标优化问题，并实证发现贝叶斯优化相比随机抽样能显著加速X攻击。此外，数据集对X攻击的脆弱性与特征间的信息冗余有关。论文最后讨论了检测和预防X攻击的方法及其对XAI可信度和可复现性的伦理影响。

> **摘要翻译:** 可解释人工智能（XAI）和可解释机器学习方法有助于建立对模型预测和衍生洞察的信任，但也为分析师提供了一种扭曲的动机，即操纵XAI指标以支持预先设定的结论。本文引入了X攻击的概念，这是一种应用于SHAP值等XAI指标的p值攻击形式。我们展示了自动化机器学习管道如何轻易地适应，以大规模利用模型多样性：搜索“可辩护”模型的Rashomon集合，这些模型具有相似的预测性能，以找到所需的解释。我们将解释和准确性之间的权衡表述为多目标优化问题，并在熟悉的真实世界数据集上进行经验性说明，平均而言，贝叶斯优化对于易受影响的特征，将X攻击的速度提高了3倍，相比随机抽样。我们表明数据集对X攻击的脆弱性可以通过特征之间的信息冗余来确定。最后，我们提出了可能的检测和预防方法，并讨论了对XAI可信度和可复现性的伦理影响。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [521] [Beyond Predictions: A Participatory Framework for Multi-Stakeholder Decision-Making](https://arxiv.org/abs/2502.08542)
> *超越预测：一个用于多利益相关者决策的参与式框架*

*Vittoria Vineis, Giuseppe Perelli, Gabriele Tolomei* | **Category: cs.LG, cs.MA** | **Updated: 2025-07-15**

**Keywords:** 参与式框架, 多利益相关者决策, 优化问题, 决策支持系统, AI伦理

**Comment:** 

> **TL;DR:** 提出一个参与式框架，将决策重构为多利益相关者优化问题，通过考虑不同参与者的偏好，生成优于纯预测基线的决策，并提高透明度和问责制。

**AI_Comments:** 这篇论文的创新之处在于将复杂的决策制定问题从单纯的预测转向多利益相关者优化，并提出了一个模块化、模型无关的参与式框架。它有效地弥补了传统AI决策系统在处理冲突偏好方面的不足，并通过提高透明度和问责制，增强了AI在实际高风险应用中的可信度。该框架的普适性和在真实案例中的出色表现，使其在需要平衡多方利益的决策场景中具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统自动化决策支持系统忽视了多参与者环境中多样化和冲突的利益相关者偏好，而现有的参与式AI方法又过于依赖特定上下文，限制了其广泛适用性。

**Method:** 提出一个模块化、模型无关的参与式框架，将决策重构为多利益相关者优化问题。它使用上下文相关的奖励函数表示每个参与者的偏好，采用k折交叉验证来微调用户提供的预测模型和评估决策策略（包括调和利益相关者权衡的折衷函数）。通过合成评分机制聚合用户定义的多指标偏好，以对策略进行排名并选择最佳决策者来生成可操作的建议。

**Result:** 该框架在两个高风险真实案例研究中得到验证，始终能产生考虑利益相关者的决策，这些决策在多个指标上优于纯预测基线，同时提高了AI支持决策的透明度和问责制。

**Conclusion:** 该框架通过将决策重构为多利益相关者优化问题，并整合参与式方法，有效地解决了传统预测系统在复杂多参与者环境中面临的挑战，从而生成了更优、更透明和更负责任的决策。

> **ai_Abstract:** 这篇论文提出了一个创新的参与式框架，旨在解决传统自动化决策支持系统在多利益相关者环境中存在的局限性。该框架将决策制定视为一个多利益相关者优化问题，通过上下文相关的奖励函数整合了不同参与者的偏好。它采用模块化、模型无关的方法，利用k折交叉验证来评估和优化决策策略，并通过合成评分机制聚合偏好以选择最佳决策。实验证明，该框架在真实案例中能生成更优、更透明且更负责任的决策，超越了单纯的预测模型。

> **摘要翻译:** 传统的自动化决策支持系统，通常基于监督学习，专注于预测结果以推荐行动。然而，它们通常忽视了多参与者环境的复杂性，在这些环境中，必须平衡多样化和冲突的利益相关者偏好。与此同时，参与式AI方法在很大程度上仍局限于特定上下文，限制了其更广泛的适用性。为了解决这些差距，我们提出了一个参与式框架，将决策重构为多利益相关者优化问题，使用上下文相关的奖励函数来表示每个参与者的偏好。我们模块化、模型无关的框架采用k折交叉验证来微调用户提供的预测模型并评估决策策略，包括调和利益相关者权衡的折衷函数。一个合成评分机制聚合用户定义的多指标偏好，以对策略进行排名并选择最佳决策者，从而在新数据上生成可操作的建议。该框架在两个高风险真实案例研究中得到验证，始终能产生考虑利益相关者的决策，这些决策在多个指标上优于纯预测基线，同时提高了AI支持决策的透明度和问责制。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [524] [An Explainable AI-Enhanced Machine Learning Approach for Cardiovascular Disease Detection and Risk Assessment](https://arxiv.org/abs/2507.11185)
> *一种可解释人工智能增强的机器学习方法用于心血管疾病检测和风险评估*

*Md. Emon Akter Sourov, Md. Sabbir Hossen, Pabon Shaha, Mohammad Minoar Hossain, Md Sadiq Iqbal* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 心血管疾病检测, 风险评估, 机器学习, 可解释人工智能, SMOTE

**Comment:** This paper has been accepted at the IEEE QPAIN 2025. The final
  version will be available in the IEEE Xplore Digital Library

> **TL;DR:** 该论文提出了一种可解释人工智能增强的机器学习框架，用于心血管疾病检测和风险评估，使用SMOTE处理类别不平衡问题，其中随机森林和线性回归表现出高准确性。

**AI_Comments:** 该论文通过利用人工智能解决了全球关键的健康问题。使用SMOTE处理类别不平衡是一个很好的实践。可解释人工智能的引入对于临床应用至关重要，因为它有助于建立对模型预测的信任和理解，这对于医疗诊断等高风险应用来说是创新且重要的。

<details>
  <summary>Details</summary>

**Motivation:** 心血管疾病是全球主要的健康问题，尤其是在医疗资源有限的地区。传统诊断方法在准确识别和管理风险方面存在不足，而机器学习有望显著提高诊断的准确性、效率和速度。

**Method:** 提出一个结合分类模型（用于疾病检测）和回归模型（用于风险预测）的综合框架。使用包含1,035个病例的心脏病数据集。为解决类别不平衡问题，应用合成少数类过采样技术（SMOTE），生成了100,000个合成数据点。性能评估指标包括准确率、精确率、召回率、F1分数（分类）和R2、MSE、RMSE、MAE（回归）。还采用了可解释人工智能技术来增强模型的可解释性。

**Result:** 分类模型中，随机森林表现最佳，在真实数据上准确率达97.2%，在合成数据上达97.6%。回归任务中，线性回归的R2值最高（真实数据0.992，合成数据0.984），且误差指标最低。

**Conclusion:** 本研究强调了机器学习在心血管疾病诊断和风险预测方面的潜力，有助于早期干预和改进临床决策。

> **ai_Abstract:** 该论文提出了一种可解释人工智能增强的机器学习框架，用于心血管疾病的检测和风险评估。该框架在一个心脏病数据集上结合了分类和回归模型，并采用SMOTE技术处理类别不平衡问题。研究发现，随机森林在分类任务中表现出高准确率（真实数据97.2%），线性回归在回归任务中表现出色（真实数据R2为0.992）。通过整合可解释人工智能，该研究旨在提高模型的可解释性，展现了机器学习在改进心脏病诊断和临床决策方面的巨大潜力。

> **摘要翻译:** 心脏病仍然是全球主要的健康问题，特别是在医疗资源和诊断设施有限的地区。传统的诊断方法往往无法准确识别和管理心脏病风险，导致不良后果。机器学习有潜力显著提高心脏病诊断的准确性、效率和速度。在本研究中，我们提出了一个综合框架，结合了用于心脏病检测的分类模型和用于风险预测的回归模型。我们使用了包含1,035个病例的心脏病数据集。为解决类别不平衡问题，应用了合成少数类过采样技术（SMOTE），生成了额外的100,000个合成数据点。性能指标包括准确率、精确率、召回率、F1分数、R2、MSE、RMSE和MAE，用于评估模型的有效性。在分类模型中，随机森林表现突出，在真实数据上达到了97.2%的准确率，在合成数据上达到了97.6%的准确率。对于回归任务，线性回归在真实和合成数据集上分别表现出最高的R2值0.992和0.984，且误差指标最低。此外，还采用了可解释人工智能技术来增强模型的可解释性。本研究强调了机器学习在心脏病诊断和风险预测方面实现革命性突破的潜力，从而促进早期干预和增强临床决策。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [526] [Rethinking RoPE: A Mathematical Blueprint for N-dimensional Positional Embedding](https://arxiv.org/abs/2504.06308)
> *重新思考 RoPE：N 维位置嵌入的数学蓝图*

*Haiping Liu, Lijing Lin, Jingyuan Sun, Zhegong Shangguan, Mauricio A. Alvarez, Hongpeng Zhou* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 旋转位置嵌入, 李群, 李代数, N维嵌入, 位置编码

**Comment:** 

> **TL;DR:** 该论文提出了一个统一的N维RoPE数学框架，基于李群和李代数理论，解释了现有设计并支持向高维扩展。

**AI_Comments:** 这篇论文通过将RoPE置于李群和李代数理论的坚实数学基础之上，做出了重要的理论贡献。它不仅统一并解释了现有的RoPE变体，还为将RoPE扩展到更高维度提供了原则性的方法，这对于多模态大型语言模型的发展至关重要。关于平衡维度间交互与局部结构保留的见解也对实际应用具有宝贵的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 旋转位置嵌入（RoPE）在大型语言模型（LLMs）中广泛应用，但其在高维输入领域（如2D图像）的应用缺乏统一的理论框架。

**Method:** 本文提出了一个基于李群和李代数理论的系统性RoPE数学框架。通过RoPE的相对性和可逆性两个核心属性，推导了任何有效N维RoPE的充要条件。研究表明RoPE可以被描述为特殊正交李代数中最大阿贝尔子代数（MASA）的基，并且常用的轴对齐块对角RoPE对应于最大环形子代数。此外，将空间维度间交互简化为基变换，通过学习正交变换来解决。

**Result:** RoPE可以被表征为特殊正交李代数中最大阿贝尔子代数（MASA）的基。常用的轴对齐块对角RoPE对应于最大环形子代数。实验结果表明，维度间交互应与局部结构保留相平衡。

**Conclusion:** 本文提出的框架统一并解释了现有的RoPE设计，同时为向更高维模态和任务的原则性扩展提供了基础。

> **ai_Abstract:** 旋转位置嵌入（RoPE）在大型语言模型中因其高效的相对位置编码能力而广泛采用。然而，其在高维输入领域（如2D图像）的应用缺乏统一的理论框架。为解决此问题，本文提出了一个基于李群和李代数理论的系统性RoPE数学框架。我们推导了任何有效N维RoPE的充要条件，并证明RoPE可被表征为特殊正交李代数中最大阿贝尔子代数的基。研究发现，常用的轴对齐块对角RoPE对应于最大环形子代数，且空间维度间交互可通过学习正交变换解决。实验结果表明，维度间交互应与局部结构保留相平衡。该框架统一并解释了现有RoPE设计，并为高维模态和任务提供了原则性扩展基础。

> **摘要翻译:** 旋转位置嵌入（RoPE）因其高效的相对位置编码和强大的外推能力，在大型语言模型（LLMs）中被广泛采用。然而，尽管其在高维输入领域（如2D图像）的应用已有一些探索尝试，但仍缺乏统一的理论框架。为解决此问题，我们提出了一个基于李群和李代数理论的系统性RoPE数学框架。我们基于RoPE的两个核心属性——相对性和可逆性——推导了任何有效N维RoPE的充要条件。我们证明了RoPE可以被描述为特殊正交李代数中最大阿贝尔子代数（MASA）的基，并且常用的轴对齐块对角RoPE，其中每个输入轴由独立的2x2旋转块编码，对应于最大环形子代数。此外，我们将空间维度间交互简化为基变换，通过学习正交变换来解决。我们的实验结果表明，维度间交互应与局部结构保留相平衡。总的来说，我们的框架统一并解释了现有的RoPE设计，同时为向更高维模态和任务的原则性扩展提供了基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [531] [Quantized Rank Reduction: A Communications-Efficient Federated Learning Scheme for Network-Critical Applications](https://arxiv.org/abs/2507.11183)
> *量化秩降：一种用于网络关键应用的通信高效联邦学习方案*

*Dimitrios Kritsiolis, Constantine Kotropoulos* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 联邦学习, 通信效率, 低秩近似, 量化, 网络负载

**Comment:** In Proceedings of the 2025 IARIA Annual Congress on Frontiers in
  Science, Technology, Services, and Applications (IARIA Congress 2025),
  Venice, Italy, July 6-10, 2025

> **TL;DR:** 提出一种结合低秩近似和量化的联邦学习方案，以减少通信开销，同时保持模型精度。

**AI_Comments:** 该论文提出了一种创新的方法，通过结合低秩近似和量化来优化联邦学习的通信效率。这种方法对于解决边缘设备和网络受限环境下的联邦学习部署具有重要意义，因为它在减少通信量的同时，力求最小化对模型性能的影响。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习中，代理和中央服务器之间频繁交换模型更新会导致显著的通信开销，这是一个重大挑战。

**Method:** 本文提出了一种通信高效的联邦学习方案，该方案利用神经网络梯度的低秩近似和量化来显著减少去中心化学习过程的网络负载。

**Result:** 显著减少去中心化学习过程的网络负载，对模型精度影响最小。

**Conclusion:** 本文提出的量化秩降方案能够有效降低联邦学习的通信开销，同时保持模型精度，适用于网络关键应用。

> **ai_Abstract:** 本文提出了一种名为“量化秩降”的通信高效联邦学习方案，旨在解决联邦学习中模型更新频繁交换导致的通信开销问题。该方案通过对神经网络梯度进行低秩近似和量化处理，显著降低了去中心化学习过程的网络负载，同时保持了模型精度，使其适用于网络关键应用。

> **摘要翻译:** 联邦学习是一种机器学习方法，它允许多个设备（即代理）在不交换原始数据的情况下协同训练共享模型。该技术将数据本地化在用户设备上，确保隐私和安全，同时每个代理都在自己的数据上训练模型并仅共享模型更新。由于代理和中央服务器之间频繁交换模型更新，通信开销是一个重大挑战。在本文中，我们提出了一种通信高效的联邦学习方案，该方案利用神经网络梯度的低秩近似和量化来显著减少去中心化学习过程的网络负载，同时对模型精度影响最小。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [534] [ReVISE: Learning to Refine at Test-Time via Intrinsic Self-Verification](https://arxiv.org/abs/2502.14565)
> *ReVISE：通过内在自我验证在测试时学习优化*

*Hyunseok Lee, Seunghyuk Oh, Jaehyung Kim, Jinwoo Shin, Jihoon Tack* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 自我纠正, 自我验证, 在线偏好学习, 推理性能

**Comment:** Published as conference proceeding for ICML 2025. First two authors
  contributed equally

> **TL;DR:** ReVISE提出一种高效的框架，使大型语言模型通过自我验证和在线偏好学习，在测试时自我修正推理输出，显著提高性能。

**AI_Comments:** ReVISE的创新之处在于其通过内在自我验证实现LLM自我纠正的机制，避免了对大量强化学习或大型外部验证器的依赖，提高了效率。其核心思想是让模型能够“反思”自身的推理过程，并通过结构化课程和在线偏好学习进行训练，这是一种新颖且高效的学习范式。结合置信度感知解码机制在测试时进行优化，也进一步增强了实用性。这项工作对于提升LLMs的可靠性和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的自我意识（即评估和纠正自身生成的能力）是一项重要但具有挑战性的任务。现有方法通常依赖于大量的强化学习或大型外部验证器，因此需要一种更高效有效的方法来实现LLMs的自我修正。

**Method:** 论文提出了ReVISE（通过内在自我验证进行优化）框架。其核心思想是使LLMs能够验证自身的推理过程，并根据验证结果不断重新思考推理轨迹。具体实现上，引入了基于在线偏好学习的结构化课程，将自我验证和推理纠正这两个任务进行顺序处理。通过收集失败和成功的推理路径来构建偏好对进行高效训练。在推理阶段，ReVISE通过整合自我验证和纠正能力，并结合置信度感知解码机制，实现自然的测试时扩展。

**Result:** 实验证明，ReVISE在各种推理任务上实现了高效的自我纠正，并显著提高了推理性能。

**Conclusion:** ReVISE提供了一种有效且高效的框架，使大型语言模型能够通过内在自我验证和纠正能力在测试时进行自我优化，从而显著提升了推理任务的表现。

> **ai_Abstract:** 本文提出了ReVISE（通过内在自我验证进行优化）框架，旨在使大型语言模型（LLMs）具备自我纠正能力。ReVISE的核心在于让LLMs能够验证自身的推理过程并根据验证结果进行迭代修正。该方法采用基于在线偏好学习的结构化课程，通过顺序处理自我验证和推理纠正任务，并收集成功与失败的推理路径来高效训练。在推理时，ReVISE结合了自我验证、纠正能力和置信度感知解码机制，实现了测试时扩展。实验结果表明，ReVISE在多种推理任务上实现了高效的自我纠正，并显著提升了性能。

> **摘要翻译:** 自我意识，即评估和纠正自身生成的能力，是人类智能的一个基本方面，因此在大型语言模型（LLMs）中复制它是一项重要但具有挑战性的任务。以往的工作通过采用大量的强化学习或依赖大型外部验证器来解决这个问题。在这项工作中，我们提出了通过内在自我验证进行优化（ReVISE），这是一个高效且有效的框架，使LLMs能够通过自我验证来纠正其输出。ReVISE的核心思想是使LLMs能够验证其推理过程，并根据其验证结果不断重新思考推理轨迹。我们引入了一个基于在线偏好学习的结构化课程来高效地实现这一点。具体来说，由于ReVISE涉及两个具有挑战性的任务（即自我验证和推理纠正），我们使用课程学习顺序地处理每个任务，收集失败和成功的推理路径来构建偏好对以进行高效训练。在推理过程中，我们的方法通过整合自我验证和纠正能力，并由我们提出的置信度感知解码机制进一步增强，从而享受到自然的测试时扩展。我们在各种推理任务上的实验表明，ReVISE实现了高效的自我纠正并显著提高了推理性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [543] [GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning](https://arxiv.org/abs/2507.10628)
> *GHPO：面向稳定高效LLM强化学习的自适应引导*

*Ziru Liu, Cheng Gong, Xinyu Fu, Yaofang Liu, Ran Chen, Shoubo Hu, Suiyun Zhang, Rui Liu, Qingfu Zhang, Dandan Tu* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 强化学习, 大型语言模型, 适应性引导, 训练稳定性, 推理任务

**Comment:** 

> **TL;DR:** GHPO是一个新的强化学习框架，通过自适应提示细化来解决LLM在复杂推理任务中训练不稳定和效率低下的问题，显著提高了性能和训练稳定性。

**AI_Comments:** GHPO的创新之处在于其“难度感知”和“自适应提示细化”机制，有效解决了LLM强化学习中长期存在的“能力-难度不匹配”问题。通过动态平衡模仿学习和探索性学习，它为LLM提供了一个平滑的学习曲线，特别有利于资源受限的小型LLM。这对于提升LLM在复杂推理任务上的实用性和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LLM强化学习方法（RLVR）在复杂推理任务中存在训练不稳定和效率低下的问题，主要原因是模型能力与训练数据难度不匹配，导致奖励信号稀疏和学习停滞，特别是对于小型LLM。

**Method:** 引入了引导混合策略优化（GHPO）框架。GHPO通过自适应提示细化动态调整任务难度，平衡了对超出模型能力范围问题的直接模仿学习和对可管理任务的基于探索的强化学习，从而创建了一个平滑优化的学习课程。

**Result:** 在六个具有挑战性的数学基准测试中，GHPO平均性能提升约5%，持续优于强大的on-policy强化学习和课程学习基线。框架显著增强了训练稳定性和最终推理性能。

**Conclusion:** GHPO为开发强大且鲁棒的推理模型提供了一个可扩展且高效的解决方案，通过解决LLM强化学习中的训练不稳定和效率低下问题。

> **ai_Abstract:** 本文提出了一种名为引导混合策略优化（GHPO）的新型强化学习框架，旨在解决大型语言模型（LLM）在复杂推理任务中面临的训练不稳定和效率低下问题。GHPO通过自适应提示细化动态调整任务难度，巧妙地结合了模仿学习和探索性强化学习，为模型创建了一个优化的学习路径。实验结果表明，GHPO在多个数学基准测试中显著提升了LLM的性能和训练稳定性，为构建高效且强大的推理模型提供了有效方案。

> **摘要翻译:** 强化学习与可验证奖励（RLVR）最近已成为促进大型语言模型（LLM）自我改进的强大范式，特别是在复杂推理任务领域。然而，主流的on-policy强化学习方法经常面临显著的训练不稳定性和低效率。这主要是由于能力与难度不匹配，即训练数据的复杂性经常超出模型当前的能力，导致奖励信号极其稀疏和学习进展停滞。对于更小、更节省资源的LLM来说，这一挑战尤为突出。为了克服这个问题，我们引入了引导混合策略优化（GHPO），这是一种新颖的、难度感知的强化学习框架。GHPO通过采用自适应提示细化来提供有针对性的指导，从而动态地校准任务难度。这种独特的方法自适应地平衡了对当前超出模型能力范围的问题的直接模仿学习与对更易管理任务的基于探索的强化学习，有效地创建了一个平滑且优化的学习课程。广泛的实验表明，GHPO在六个具有挑战性的数学基准测试中平均性能提升了约5%，持续优于强大的on-policy强化学习和课程学习基线。进一步的分析证实，我们的框架显著增强了训练稳定性和最终推理性能，从而为开发强大且鲁棒的推理模型提供了一个可扩展且高效的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [549] [Universal Approximation Theorem for a Single-Layer Transformer](https://arxiv.org/abs/2507.10581)
> *单层 Transformer 的通用逼近定理*

*Esmail Gumaan* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-07-11**

**Keywords:** Transformer, 通用逼近定理, 单层, 理论理解, 序列到序列映射

**Comment:** 7 pages, 2 figures, 1 theorem, 10 formulas

> **TL;DR:** 本文证明了单层 Transformer 具有通用逼近能力，填补了其理论理解的空白。

**AI_Comments:** 这篇论文通过证明单层 Transformer 的通用逼近定理，为当前广泛应用的 Transformer 模型提供了重要的理论支撑，有助于解释其强大的表达能力和在多领域取得成功的原因。这项工作填补了 Transformer 理论研究的空白，对于指导未来的模型设计和深入理解深度学习架构具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管 Transformer 模型在许多领域取得了最先进的性能，但对其数学和理论基础的理解仍然有限。

**Method:** 作者回顾了深度学习的数学基础，详细分析了多头自注意力机制和反向传播算法。主要通过提供形式化的定理陈述和完整证明来论证其核心贡献。

**Result:** 研究证明，一个由单层自注意力层和带有 ReLU 激活的位置前馈网络组成的单层 Transformer，可以在紧致域上以任意精度逼近任何连续的序列到序列映射。

**Conclusion:** 本研究的发现增进了对 Transformer 模型的理论理解，并有助于弥合理论与实践之间的差距。

> **ai_Abstract:** 本文旨在弥补 Transformer 模型理论理解的不足。研究分析了深度学习和 Transformer 的数学基础，并提出了一个重要的理论贡献：证明了一个由单层自注意力层和 ReLU 激活的位置前馈网络组成的单层 Transformer，能够以任意精度逼近紧致域上的任何连续序列到序列映射。论文提供了正式的证明，并通过案例研究展示了其应用，从而深化了对 Transformer 的理论认识，并促进了理论与实践的结合。

> **摘要翻译:** 深度学习采用通过反向传播算法训练的多层神经网络。这种方法在许多领域取得了成功，并依赖于自适应梯度方法，例如 Adam 优化器。序列建模从循环神经网络演变为基于注意力的模型，最终形成了 Transformer 架构。Transformer 在自然语言处理（例如 BERT 和 GPT-3）中取得了最先进的性能，并已应用于计算机视觉和计算生物学。然而，对这些模型的理论理解仍然有限。在本文中，我们研究了深度学习和 Transformer 的数学基础，并提出了一个新颖的理论结果。我们回顾了支撑深度学习的线性代数、概率和优化中的关键概念，并详细分析了多头自注意力机制和反向传播算法。我们的主要贡献是 Transformer 的通用逼近定理：我们证明了一个单层 Transformer，包含一个自注意力层和一个带有 ReLU 激活的位置前馈网络，可以在紧致域上以任意精度逼近任何连续的序列到序列映射。我们提供了正式的陈述和完整的证明。最后，我们提出了案例研究，展示了这一结果的实际意义。我们的发现增进了对 Transformer 模型的理论理解，并有助于弥合理论与实践之间的差距。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [555] [Compositional Flows for 3D Molecule and Synthesis Pathway Co-design](https://arxiv.org/abs/2504.08051)
> *用于3D分子和合成路径协同设计的组合流*

*Tony Shen, Seonghwan Seo, Ross Irwin, Kieran Didi, Simon Olsson, Woo Youn Kim, Martin Ester* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 组合流, 3D分子设计, 合成路径, 流匹配, 药物设计

**Comment:** Accepted to ICML 2025, 29 pages, 7 figures, code:
  https://github.com/tsa87/cgflow

> **TL;DR:** CGFlow是一种新颖的框架，扩展了流匹配以生成具有连续特征的组合对象，并应用于可合成药物设计，在结合亲和力和合成成功率方面取得了最先进的成果。

**AI_Comments:** CGFlow的创新之处在于将流匹配扩展到处理组合对象生成，并将其与GFlowNets结合以实现奖励引导采样。特别是在3D分子和合成路径协同设计方面的应用，对于实际的药物发现具有重要意义。同时在结合亲和力和可合成性方面取得SOTA性能，是该领域的一个重大突破。

<details>
  <summary>Details</summary>

**Motivation:** 许多生成应用，例如基于合成的3D分子设计，涉及构建具有连续特征的组合对象。现有方法可能无法有效处理这种复杂的协同设计需求。

**Method:** 本文介绍了组合生成流（CGFlow），这是一种将流匹配扩展到以组合步骤生成对象同时建模连续状态的新颖框架。其关键在于将组合状态转换建模为流匹配插值过程的直接扩展。该方法还基于生成流网络（GFlowNets）的理论基础，实现了奖励引导的组合结构采样。CGFlow被应用于可合成药物设计，通过共同设计分子的合成路径及其3D结合姿态。

**Result:** CGFlow在LIT-PCBA基准测试的所有15个靶点上实现了最先进的结合亲和力，并且与2D基于合成的基线相比，采样效率提高了5.8倍。据作者所知，该方法也是第一个在CrossDocked基准测试中同时在Vina Dock（-9.38）和AiZynth成功率（62.2%）方面达到最先进性能的方法。

**Conclusion:** CGFlow是一个高效且强大的框架，用于可合成药物设计，能够共同优化分子结构和合成路径，并取得了最先进的性能。

> **ai_Abstract:** CGFlow是一种新颖的框架，它扩展了流匹配和生成流网络（GFlowNets）以生成具有连续特征的组合对象，并应用于3D分子和合成路径的协同设计。该方法将组合状态转换建模为流匹配插值的扩展，并利用奖励引导采样。CGFlow在可合成药物设计中表现出色，在LIT-PCBA基准测试中实现了最先进的结合亲和力，采样效率显著提高，并在CrossDocked基准测试中首次同时在Vina Dock和AiZynth成功率方面达到SOTA性能，证明了其在协同设计复杂分子结构和合成路径方面的有效性。

> **摘要翻译:** 许多生成应用，例如基于合成的3D分子设计，涉及构建具有连续特征的组合对象。在此，我们介绍了组合生成流（CGFlow），这是一个新颖的框架，它扩展了流匹配以在组合步骤中生成对象，同时建模连续状态。我们的关键见解是，建模组合状态转换可以被表述为流匹配插值过程的直接扩展。我们进一步建立在生成流网络（GFlowNets）的理论基础上，实现了奖励引导的组合结构采样。我们将CGFlow应用于可合成药物设计，通过共同设计分子的合成路径及其3D结合姿态。我们的方法在LIT-PCBA基准测试的所有15个靶点上实现了最先进的结合亲和力，并且与2D基于合成的基线相比，采样效率提高了5.8倍。据我们所知，我们的方法也是第一个在CrossDocked基准测试中同时在Vina Dock（-9.38）和AiZynth成功率（62.2%）方面达到最先进性能的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [558] [From Small to Large: A Graph Convolutional Network Approach for Solving Assortment Optimization Problems](https://arxiv.org/abs/2507.10834)
> *从小规模到大规模：一种用于解决商品组合优化问题的图卷积网络方法*

*Guokai Li, Pin Gao, Stefanus Jasin, Zizhuo Wang* | **Category: cs.LG** | **Updated: 2025-07-14**

**Keywords:** 商品组合优化, 图卷积网络, 收益管理, 泛化能力, NP-难问题

**Comment:** Conference version. The journal version will be updated soon

> **TL;DR:** 本文提出了一种基于图卷积网络（GCN）的方法，能够高效地解决受约束的商品组合优化问题，并能将从小规模实例上训练的模型泛化到大规模实例上，表现优于现有启发式方法。

**AI_Comments:** 这项研究的创新之处在于首次将图卷积网络应用于解决商品组合优化问题，并成功实现了从小型实例到大型实例的高效泛化。这种方法显著提高了解决NP-难问题的效率和准确性，尤其是在处理大规模数据集时表现出优越性，为收益管理领域提供了一种强大的新工具。

<details>
  <summary>Details</summary>

**Motivation:** 商品组合优化问题是一个经典的收益管理问题，在各行业都有应用，但由于其组合性和非线性，通常是NP-难的。

**Method:** 作者首先开发了商品组合问题的图表示，然后训练一个GCN来学习最优组合的模式，最后提出了两种基于GCN输出的推断策略。GCN的泛化能力使其能够用从小规模实例训练的模型处理大规模实例。此外，该框架还扩展到了底层选择模型未知但有交易数据的无模型设置。

**Result:** 数值实验表明，用小规模实例（如20种产品）训练的GCN，所提出的策略在大规模实例（多达2000种产品）上能在几秒钟内实现卓越性能（90%以上的优化度），在性能和效率上均优于现有启发式策略。在无模型设置下，所提出的策略也表现出有效性和高效性。

**Conclusion:** 本文提出了一种基于GCN的商品组合优化方法，该方法能够有效地从小型实例泛化到大型实例，并在有模型和无模型设置下均表现出优越的性能和效率。

> **ai_Abstract:** 本文提出了一种利用图卷积网络（GCN）解决受约束商品组合优化问题的新方法。通过将问题表示为图并训练GCN学习最优组合模式，该方法能够将从小规模数据集（如20种产品）上学习到的知识高效地泛化到大规模数据集（多达2000种产品）上，并在几秒钟内达到超过90%的优化度。实验证明，其在性能和效率上均优于现有启发式方法，并且该框架还能扩展到无模型场景，即在选择模型未知但有交易数据时依然有效。

> **摘要翻译:** 商品组合优化涉及选择可替代产品的一个子集（受某些约束），以最大化预期收入。它是收益管理中的一个经典问题，并在各种行业中都有应用。然而，由于其组合性和非线性性质，该问题通常是NP-难的。在这项工作中，我们探讨了如何利用图卷积网络（GCN）来有效解决混合多项式Logit选择模型下的受约束商品组合优化问题。我们首先开发了商品组合问题的图表示，然后训练一个GCN来学习最优组合的模式，最后提出了两种基于GCN输出的推断策略。由于GCN固有的泛化能力，可以利用在小规模实例上训练的GCN来处理大规模实例。大量的数值实验表明，给定一个在小规模实例（例如，20种产品）上训练的GCN，所提出的策略可以在几秒钟内在大规模实例（多达2000种产品）上实现卓越的性能（90%以上的优化度），这在性能和效率上都优于现有启发式策略。此外，我们将我们的框架扩展到底层选择模型未知但交易数据可用的无模型设置。我们还进行了数值实验，以证明我们提出的策略在这种设置下的有效性和效率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [561] [Patch-wise Structural Loss for Time Series Forecasting](https://arxiv.org/abs/2503.00877)
> *用于时间序列预测的块级结构损失*

*Dilfira Kudrat, Zongxia Xie, Yanru Sun, Tianyu Jia, Qinghua Hu* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 时间序列预测, 结构损失, 块级, 时间模式, 损失函数设计

**Comment:** 

> **TL;DR:** 现有模型依赖点式损失，忽略时间序列结构。本文提出块级结构（PS）损失，通过捕获结构依赖性来提高预测精度。

**AI_Comments:** 该论文的创新之处在于超越了传统的点式损失，引入了块级结构损失，直接解决了时间序列数据固有的结构依赖性问题。这种方法的重要性在于它提供了一种更全面的方式来评估预测误差，有望带来更鲁棒和准确的模型。其与现有损失函数的无缝集成也使其具有广泛应用的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有时间序列预测模型依赖于点式损失函数（如均方误差），这些函数独立处理每个时间步，忽略了时间序列数据中固有的结构依赖性，导致难以准确捕捉复杂的时间模式。

**Method:** 提出了一种新颖的块级结构（PS）损失，旨在通过在块级别比较时间序列来增强结构对齐。该方法利用局部统计特性（如相关性、方差和均值）来捕获传统点式损失忽略的细微结构差异，并能与点式损失无缝集成。

**Result:** 大量实验表明，PS损失显著提高了最先进模型在各种真实世界数据集上的性能。

**Conclusion:** PS损失为准确建模复杂时间序列数据建立了新的基准，并为时间序列损失函数设计提供了新的视角。

> **ai_Abstract:** 本文提出了一种新颖的块级结构（PS）损失，旨在解决传统点式损失函数在时间序列预测中忽略结构依赖性的问题。PS损失通过在块级别比较时间序列来增强结构对齐，并利用局部统计特性捕获细微的结构差异。它能与点式损失无缝集成，从而更准确地捕捉复杂时间模式。实验证明，PS损失显著提升了最先进模型在真实世界数据集上的性能，为时间序列建模树立了新基准。

> **摘要翻译:** 时间序列预测因其在各个领域的关键作用而在机器学习中获得了广泛关注。然而，大多数现有的预测模型严重依赖于点式损失函数（如均方误差），这些函数独立处理每个时间步，忽略了时间序列数据中固有的结构依赖性，从而难以准确捕捉复杂的时间模式。为了解决这些挑战，我们提出了一种新颖的块级结构（PS）损失，旨在通过在块级别比较时间序列来增强结构对齐。通过利用局部统计特性（如相关性、方差和均值），PS损失能够捕获传统点式损失忽略的细微结构差异。此外，它与点式损失无缝集成，同时解决了局部结构不一致性和单个时间步错误。PS损失为准确建模复杂时间序列数据建立了新的基准，并为时间序列损失函数设计提供了新的视角。大量实验表明，PS损失显著提高了最先进模型在各种真实世界数据集上的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [580] [Striking the Perfect Balance: Preserving Privacy While Boosting Utility in Collaborative Medical Prediction Platforms](https://arxiv.org/abs/2507.11187)
> *在协作医疗预测平台中实现完美平衡：在提升效用的同时保护隐私*

*Shao-Bo Lin, Xiaotong Liu, Yao Wang* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 隐私保护, 分布式学习, 医疗预测, 电子健康记录, 统计学习理论

**Comment:** 

> **TL;DR:** 该研究提出了一种新颖的分布式学习框架，用于协作医疗预测平台，旨在同时满足隐私保护和预测性能需求。

**AI_Comments:** 该论文通过提出一个新颖的一次性分布式学习框架，有效地解决了协作医疗预测平台中隐私保护和预测性能之间的权衡问题。其创新点在于同时考虑了针对患者和医生的不同隐私攻击类型，并从理论上证明了其方法的最优性，这对于推动安全高效的医疗AI应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的在线协作医疗预测平台面临隐私泄露（属性攻击、模型提取攻击）和预测质量低下的问题，这阻碍了患者参与和医生合作。

**Method:** 首先，澄清了针对患者的属性攻击和针对医生的模型提取攻击等隐私威胁，并明确了相应的隐私原则。然后，提出了一种隐私保护机制，并将其整合到一个新颖的一次性分布式学习框架中。在统计学习理论框架内，从理论上证明了所提出的分布式学习框架在特定隐私要求下可以实现最优预测性能。通过玩具模拟和真实世界数据实验验证了开发的隐私保护协作医疗预测平台。

**Result:** 理论上证明了所提出的分布式学习框架在特定隐私要求下可以实现最优预测性能。通过玩具模拟和真实世界数据实验验证了该平台。

**Conclusion:** 所提出的隐私保护协作医疗预测平台能够同时满足隐私要求并实现最优预测性能。

> **ai_Abstract:** 本文针对在线协作医疗预测平台中存在的隐私泄露（属性攻击、模型提取攻击）和预测质量低下的问题，提出了一种创新的隐私保护机制，并将其集成到一次性分布式学习框架中。该框架在理论上被证明能够在满足特定隐私要求的同时实现最优预测性能，并通过模拟和真实数据实验得到了验证，旨在促进患者和医生的参与。

> **摘要翻译:** 在线协作医疗预测平台通过利用海量电子健康记录提供便利和实时反馈。然而，日益增长的隐私担忧和低预测质量可能会阻碍患者参与和医生合作。在本文中，我们首先阐明了隐私攻击，即针对患者的属性攻击和针对医生的模型提取攻击，并明确了相应的隐私原则。然后，我们提出了一种隐私保护机制，并将其整合到一个新颖的一次性分布式学习框架中，旨在同时满足隐私要求和预测性能目标。在统计学习理论的框架内，我们从理论上证明了所提出的分布式学习框架在特定隐私要求下可以实现最优预测性能。我们通过玩具模拟和真实世界数据实验进一步验证了所开发的隐私保护协作医疗预测平台。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [582] [Rethinking the Foundations for Continual Reinforcement Learning](https://arxiv.org/abs/2504.08161)
> *持续强化学习基础的再思考*

*Esraa Elelimy, David Szepesvari, Martha White, Michael Bowling* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 持续强化学习, 基础, 马尔可夫决策过程, 偏差遗憾, 历史过程

**Comment:** 

> **TL;DR:** 论文认为传统强化学习的基础不适用于持续强化学习，并提出了新的数学形式和评估指标。

**AI_Comments:** 这篇论文对持续强化学习的基础进行了批判性思考，挑战了现有范式中不适合持续学习的部分。其创新之处在于提出了历史过程和偏差遗憾作为替代方案，为持续学习的理论发展奠定了新的基础，具有重要的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统强化学习的基础（如马尔可夫决策过程、非时间性产物、期望奖励总和、情景基准环境）与持续强化学习的目标相悖，阻碍了其发展。

**Method:** 论文首先审视了传统强化学习基础对持续强化学习的适用性，指出了四个不兼容的关键支柱。然后，提出了新的形式，用历史过程取代马尔可夫决策过程，并引入了适应持续学习的偏差遗憾（deviation regret）作为新的评估指标。最后，讨论了解决其他两个基础的方法。

**Result:** 识别了传统强化学习的四个不适用于持续学习的关键基础；提出了以历史过程为数学形式和偏差遗憾为评估指标的新形式。

**Conclusion:** 传统强化学习的基础不适合持续强化学习，需要新的数学形式和评估指标来更好地支持持续学习范式。

> **ai_Abstract:** 本文审视了传统强化学习的基础如何不适用于持续强化学习。作者指出，马尔可夫决策过程、非时间性产物、期望奖励总和评估和情景环境这四个传统支柱与持续学习的目标相悖。为此，论文提出了一个新框架，用历史过程取代马尔可夫决策过程，并引入偏差遗憾作为新的评估指标，以更好地支持持续学习范式。

> **摘要翻译:** 在强化学习的传统观点中，智能体的目标是找到一个最优策略，使其期望奖励总和最大化。一旦智能体找到这个策略，学习就结束了。这种观点与持续强化学习形成对比，在持续强化学习中，学习永不停止，智能体被期望无限期地持续学习和适应。尽管这两种学习范式之间存在明显的区别，但持续强化学习的许多进展都受到了植根于传统强化学习观点的基础的影响。在本文中，我们首先检查传统强化学习的基础是否适合持续强化学习范式。我们确定了传统强化学习基础的四个关键支柱，它们与持续学习的目标相悖：马尔可夫决策过程形式、对非时间性产物的关注、期望奖励总和作为评估指标，以及包含其他三个基础的情景基准环境。然后，我们提出了一种新的形式，摒弃了第一个和第三个基础，并用历史过程作为数学形式和适应持续学习的偏差遗憾的新定义作为评估指标来取代它们。最后，我们讨论了解决其他两个基础的可能方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [589] [Structured Preconditioners in Adaptive Optimization: A Unified Analysis](https://arxiv.org/abs/2503.10537)
> *自适应优化中的结构化预处理器：统一分析*

*Shuo Xie, Tianhao Wang, Sashank Reddi, Sanjiv Kumar, Zhiyuan Li* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 自适应优化, 结构化预处理器, 统一分析, AdaGrad, Shampoo

**Comment:** Fix typos and add remarks for two-sided Shampoo

> **TL;DR:** 本文对自适应优化中结构化预处理器的算法进行了统一分析，发现更结构化的预处理器（如单边Shampoo）在节省计算资源的同时，性能可能优于非结构化预处理器，挑战了传统认知。

**AI_Comments:** 这篇论文的创新点在于其统一分析框架以及对现有普遍观点的挑战。它颠覆了人们对结构化预处理器只是“近似”的认知，揭示了它们在计算效率和优化性能上都可能更优越。这对于设计和选择自适应优化算法具有重要指导意义，尤其是在资源受限的环境中。

<details>
  <summary>Details</summary>

**Motivation:** 挑战现有普遍观点，即更结构化的预处理器仅是计算高效的近似，并探索它们是否能在节省资源的同时提供更好的优化性能。

**Method:** 提出了一种新颖的统一分析方法，用于分析一类广泛的具有结构化（例如，分层、对角和克罗内克因子分解）预处理器的自适应优化算法，适用于在线遗憾最小化和离线凸优化。

**Result:** 为对角AdaGrad、全矩阵AdaGrad和AdaGrad-Norm等重要结构化预处理算法提供了匹配的收敛速率；为单边Shampoo提供了一个比原始Shampoo更好的收敛速率；揭示了更结构化的预处理器（尽管使用更少的空间和计算）可以超越其非结构化对应物；理论和实验证明了单边Shampoo可以超越全矩阵AdaGrad。

**Conclusion:** 更结构化的预处理器不仅在计算上更高效，而且在优化性能上也能超越其非结构化或不那么结构化的对应物，挑战了现有认知。

> **ai_Abstract:** 本文对自适应优化中一系列带有结构化预处理器的算法进行了统一分析，涵盖了在线遗憾最小化和离线凸优化。研究结果不仅为现有算法提供了匹配或改进的收敛速率，更重要的是，它挑战了传统观点，即结构化预处理器仅是计算高效的近似。相反，分析表明，尽管计算成本更低，更结构化的预处理器（如单边Shampoo）在性能上可以超越非结构化的对应物，这在理论和实验上都得到了验证。

> **摘要翻译:** 我们提出了一种新颖的统一分析方法，用于分析一类广泛的具有结构化（例如，分层、对角和克罗内克因子分解）预处理器的自适应优化算法，适用于在线遗憾最小化和离线凸优化。我们的分析不仅为对角AdaGrad、全矩阵AdaGrad和AdaGrad-Norm等几个重要的结构化预处理算法提供了匹配的收敛速率，而且为单边Shampoo提供了一个比原始Shampoo更好的收敛速率。有趣的是，更结构化的预处理器（例如，对角AdaGrad、AdaGrad-Norm，它们使用更少的空间和计算）通常被认为是全矩阵AdaGrad的计算高效近似，旨在通过更好的近似来提高优化性能。我们的统一分析挑战了这种普遍观点，并揭示（也许令人惊讶地）更结构化的预处理器，尽管每步使用更少的空间和计算，但可以超越其非结构化对应物。为了证明这一点，我们表明单边Shampoo（比全矩阵AdaGrad相对便宜得多）可以在理论和实验上都超越它。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [606] [Extension OL-MDISF: Online Learning from Mix-Typed, Drifted, and Incomplete Streaming Features](https://arxiv.org/abs/2507.10594)
> *扩展OL-MDISF：从混合类型、漂移和不完整流式特征中进行在线学习*

*Shengda Zhuo, Di Wu, Yi He, Shuqiang Huang, Xindong Wu* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-12**

**Keywords:** 在线学习, 数据流, 概念漂移, 混合特征, 弱监督

**Comment:** 

> **TL;DR:** 本文提出了OL-MDISF，一个解决在线学习中混合特征类型、数据漂移和不完整标签挑战的框架，通过潜在Copula表示、集成熵漂移检测和结构感知伪标签实现。

**AI_Comments:** OL-MDISF的创新之处在于其集成方法，同时解决了在线学习中的三个核心挑战：数据异质性、概念漂移和弱监督。通过结合潜在Copula表示、集成熵漂移检测和结构感知伪标签，该方法提供了一个全面的解决方案。其重要性在于为处理复杂、动态的真实世界数据流提供了一个潜在的强大工具，并旨在成为一个可复现的基准。

<details>
  <summary>Details</summary>

**Motivation:** 在线学习面临三个主要挑战：1) 真实世界数据流特征类型的异质性；2) 数据流分布随时间漂移导致模型性能下降；3) 时间和成本限制导致无法标记每个数据实例。

**Method:** 论文提出了OL-MDISF，通过构建潜在Copula表示来处理异构特征，通过集成熵和潜在不匹配来检测漂移，并执行结构感知伪标签。

**Result:** 论文提供了关于OL-MDISF的独立技术参考，讨论了混合类型建模、漂移适应和弱监督的相关工作，并在14个真实世界数据集上进行了两类漂移场景下的综合实验，包括CER趋势、消融研究、敏感性分析和时间集成动态。

**Conclusion:** OL-MDISF为复杂、弱监督流数据上的在线学习提供了一个可复现的基准。

> **ai_Abstract:** 本文提出了OL-MDISF框架，旨在解决在线学习中混合类型特征、数据漂移和不完整标签的挑战。该方法通过潜在Copula表示处理异构特征，利用集成熵和潜在不匹配检测漂移，并采用结构感知伪标签。论文作为OL-MDISF的技术参考，详细讨论了相关工作，并在14个真实世界数据集上进行了全面的实验验证，旨在提供一个复杂、弱监督流数据在线学习的可复现基准。

> **摘要翻译:** 在线学习，其中特征空间会随时间变化，提供了一种灵活的学习范式，并受到了广泛关注。然而，它仍然面临三个重大挑战。首先，具有混合特征类型的真实世界数据流的异质性对传统参数建模提出了挑战。其次，数据流分布会随时间推移而发生变化，导致模型性能急剧下降。第三，由于时间和成本限制，通常无法标记每个数据实例。为了解决这些问题，我们提出了OL-MDISF（从混合类型、漂移和不完整流式特征中进行在线学习），它构建了一个基于潜在Copula的异构特征表示，通过集成熵和潜在不匹配检测漂移，并执行结构感知伪标签。
这篇配套论文作为OL-MDISF的独立技术参考。它提供了混合类型建模、漂移适应和弱监督相关工作的背景讨论，以及在两类漂移场景下，对14个真实世界数据集进行的一系列综合实验。这些实验包括CER趋势、消融研究、敏感性分析和时间集成动态。我们希望这份文档能为复杂、弱监督流数据上的在线学习提供一个可复现的基准。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [607] [Visually grounded emotion regulation via diffusion models and user-driven reappraisal](https://arxiv.org/abs/2507.10861)
> *基于扩散模型和用户驱动再评估的视觉情绪调节*

*Edoardo Pinzuti, Oliver Tüscher, André Ferreira Castro* | **Category: cs.LG** | **Updated: 2025-07-14**

**Keywords:** 情绪调节, 认知再评估, 扩散模型, 生成式AI, 情感计算

**Comment:** 

> **TL;DR:** 该研究提出了一种通过扩散模型将口头再评估转化为视觉反馈的AI辅助情绪调节系统，实验证明其能有效减少负面情绪。

**AI_Comments:** 该论文的创新点在于将前沿的扩散模型技术应用于情绪调节领域，通过视觉化反馈弥补了传统认知再评估方法在实践中面临的挑战，特别是其对语言和认知能力的较高要求。这种将生成式AI与情感计算相结合的方法，为心理治疗和情绪健康干预提供了新的、更易于接受和有效的途径，具有重要的临床和技术应用前景。它不仅展示了AI在理解和响应人类情感方面的潜力，也为开发更具包容性的治疗工具奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 认知再评估作为情绪调节的关键策略，目前仍存在认知要求高、抽象且主要依赖语言的问题，这对于创伤或抑郁症患者来说效果有限。本研究旨在通过视觉方式增强认知再评估，以克服这些局限性。

**Method:** 本研究提出了一种新颖的视觉认知再评估增强方法，将大型文本到图像扩散模型集成到情绪调节过程中。具体而言，该系统允许用户通过口头再评估重新解释负面图像，这些口头评估随后通过使用经过微调的IP适配器的稳定扩散模型转化为支持性、情绪一致的视觉化图像。通过一项20名受试者的组内实验，使用改良的认知情绪调节（CER）任务，参与者对来自国际情感图片系统（IAPS）的厌恶图像进行再评估或描述，并分别在有或无AI生成视觉反馈的条件下进行。

**Result:** 实验结果显示，与非AI辅助和对照条件相比，AI辅助的再评估显著降低了负面情绪。进一步分析表明，参与者再评估与生成图像之间的情感一致性与情感缓解相关，这表明多模态的一致性增强了调节效力。

**Conclusion:** 研究结果表明，生成式视觉输入可以支持认知再评估，并在生成式AI、情感计算和治疗技术交叉领域开辟了新的方向。

> **ai_Abstract:** 本研究提出了一种创新的AI辅助情绪调节方法，通过整合文本到图像扩散模型，将用户口头表达的认知再评估转化为支持性的视觉反馈。该系统旨在克服传统再评估方法对语言和高阶认知的依赖，特别适用于创伤或抑郁症患者。实验结果表明，这种视觉化的再评估显著降低了负面情绪，并且生成图像与用户再评估之间的情感一致性越高，情绪缓解效果越好，证明了生成式视觉输入在情绪调节中的有效性和潜力。

> **摘要翻译:** 认知再评估是情绪调节的关键策略，它涉及对情感刺激的重新解释以改变情感反应。尽管其在临床和认知科学中发挥着核心作用，但现实世界中的再评估干预仍然需要较高的认知负荷、抽象且主要依赖语言。这种对高阶认知和语言过程的依赖常常在患有创伤或抑郁症的个体中受损，从而限制了标准方法的有效性。在此，我们提出了一种新颖的、基于视觉的认知再评估增强方法，通过将大型文本到图像扩散模型整合到情绪调节过程中。具体而言，我们引入了一个系统，在该系统中，用户通过口头再评估重新解释负面图像，这些口头评估通过使用经过微调的IP适配器的稳定扩散模型被转化为支持性的、情感一致的视觉化图像。这种生成性转化在视觉上实例化了用户的再评估，同时保持了与原始刺激的结构相似性，从而外化并强化了调节意图。为了测试这种方法，我们进行了一项组内实验（N=20），使用了改良的认知情绪调节（CER）任务。参与者对来自国际情感图片系统（IAPS）的厌恶图像进行再评估或描述，并分别在有或无AI生成视觉反馈的条件下进行。结果显示，与非AI辅助和对照条件相比，AI辅助的再评估显著降低了负面情绪。进一步分析表明，参与者再评估与生成图像之间的情感一致性与情感缓解相关，这表明多模态的一致性增强了调节效力。这些发现表明，生成式视觉输入可以支持认知再评估，并在生成式AI、情感计算和治疗技术交叉领域开辟了新的方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [610] [Temporal Chunking Enhances Recognition of Implicit Sequential Patterns](https://arxiv.org/abs/2506.00588)
> *时间块增强隐式序列模式识别*

*Jayanta Dey, Nicholas Soures, Miranda Gonzales, Itamar Lerner, Christopher Kanan, Dhireesha Kudithipudi* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 时间块, 序列模式识别, 神经启发, 迁移学习, 上下文标签

**Comment:** 

> **TL;DR:** 本研究提出了一种神经启发式方法，通过将时间序列压缩成带有上下文标签的块来增强对隐式序列模式的识别，该方法在资源受限的环境下显著提高了学习效率，并具有迁移学习的潜力。

**AI_Comments:** 这项研究的创新点在于提出了“时间块”和“上下文标签”的概念，并引入了“离线睡眠阶段”来生成这些标签，这是一种新颖的神经启发式方法。其重要性在于为解决传统神经网络在处理多时间尺度时间模式时的效率和泛化能力问题提供了潜在的解决方案。尽管研究结果尚属初步，且主要基于合成任务，但其作为“概念验证”工作，特别是在迁移学习方面展现出的潜力，预示了未来在该领域应用的可能性。其局限性在于目前仅限于合成任务，未来需要更广泛、更复杂的实验来验证其在实际应用中的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 传统神经网络（如RNN）在处理多时间尺度上的时间模式时存在局限性，本研究旨在提出一种新的方法来克服这些限制。

**Method:** 本研究提出了一种神经启发式方法，将时间序列压缩成带有上下文标签的块。这些标签在离线“睡眠”阶段生成，作为过去经验的紧凑参考，使学习器能够整合超出其即时输入范围的信息。该方法在受控的合成环境中进行了评估，并通过小型人类试点研究进一步验证。

**Result:** 初步结果表明，时间块（temporal chunking）可以显著提高资源受限设置下的学习效率。此外，学习到的上下文标签可以在相关任务之间进行迁移。

**Conclusion:** 这项工作是一个早期的概念验证，初步证据表明学习到的上下文标签可以跨相关任务迁移，为未来在迁移学习中的应用提供了潜力。

> **ai_Abstract:** 本研究提出了一种神经启发式的时间序列处理方法，通过将序列压缩为带有上下文标签的“块”来识别隐式模式。这些标签在离线阶段生成，作为经验参考，旨在克服传统神经网络在处理多时间尺度模式时的局限性。初步结果表明，该方法在资源受限环境下能显著提高学习效率，且学习到的上下文标签具有跨任务迁移的潜力，为迁移学习提供了新的思路和概念验证。

> **摘要翻译:** 在这项初步研究中，我们提出了一种神经启发式方法，将时间序列压缩成带有上下文标签的块，其中每个标签代表序列中重复的结构单元或“社区”。这些标签在离线“睡眠”阶段生成，作为过去经验的紧凑参考，使学习者能够整合超出其即时输入范围的信息。我们在一个受控的合成环境中评估了这一想法，该环境旨在揭示传统神经网络序列学习器（如循环神经网络（RNN））在面对多时间尺度时间模式时的局限性。我们在一个受控的合成环境中评估了这一想法，该环境旨在揭示传统神经网络序列学习器（如循环神经网络（RNN））在面对多时间尺度时间模式时的局局限性。我们的结果虽然是初步的，但表明时间块可以在资源受限的环境下显著提高学习效率。一项使用序列反应时间任务的小规模人类试点研究进一步激发了结构抽象的理念。尽管仅限于合成任务，这项工作仍是一个早期的概念验证，初步证据表明学习到的上下文标签可以在相关任务之间迁移，为未来在迁移学习中的应用提供了潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [613] [Scalable Unsupervised Segmentation via Random Fourier Feature-based Gaussian Process](https://arxiv.org/abs/2507.10632)
> *可扩展的无监督分割，通过基于随机傅里叶特征的高斯过程*

*Issei Saito, Masatoshi Nagano, Tomoaki Nakamura, Daichi Mochihashi, Koki Mimura* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 时间序列分割, 高斯过程, 随机傅里叶特征, 无监督学习, 可扩展性

**Comment:** 

> **TL;DR:** 提出RFF-GP-HSMM，一种通过随机傅里叶特征加速高斯过程隐藏半马尔可夫模型的时间序列无监督分割方法，显著提高了计算效率并保持了性能。

**AI_Comments:** 该论文的创新点在于将随机傅里叶特征（RFF）引入高斯过程隐藏半马尔可夫模型（GP-HSMM），有效地解决了传统GP-HSMM在处理大规模时间序列数据时面临的计算效率低下问题。通过避免核矩阵求逆，该方法极大地提升了可扩展性，使其在实际应用中更具可行性，尤其是在需要快速处理大量数据的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 传统GP-HSMM在处理大规模时间序列数据时，需要对N x N核矩阵进行求逆，导致计算成本过高。

**Method:** 提出的RFF-GP-HSMM方法利用随机傅里叶特征（RFF）将高斯过程近似为线性回归，从而避免了核矩阵求逆，同时保留了表达能力。

**Result:** 在CMU动作捕捉数据集上的实验表明，所提出的方法在分割性能上与传统方法相当，但在包含39,200帧的时间序列数据上，分割速度提高了约278倍。

**Conclusion:** RFF-GP-HSMM成功地解决了GP-HSMM的计算成本问题，实现了高效且性能相当的无监督时间序列分割。

> **ai_Abstract:** 本文提出RFF-GP-HSMM，一种利用随机傅里叶特征（RFF）改进高斯过程隐藏半马尔可夫模型（GP-HSMM）的无监督时间序列分割方法。该方法通过将高斯过程近似为线性回归，避免了传统GP-HSMM中N x N核矩阵求逆带来的高计算成本。实验证明，RFF-GP-HSMM在保持分割性能的同时，显著提升了处理大规模时间序列数据的速度，例如在39,200帧的数据上加速了278倍。

> **摘要翻译:** 在本文中，我们提出了RFF-GP-HSMM，这是一种快速的无监督时间序列分割方法，它结合了随机傅里叶特征（RFF）来解决高斯过程隐藏半马尔可夫模型（GP-HSMM）的高计算成本问题。GP-HSMM使用高斯过程对时间序列数据进行建模，在训练期间需要对N x N的核矩阵进行求逆，其中N是数据点的数量。随着数据规模的增加，矩阵求逆会产生显著的计算成本。为了解决这个问题，所提出的方法使用RFF将高斯过程近似为线性回归，从而在保留表达能力的同时消除了对核矩阵求逆的需求。在卡内基梅隆大学（CMU）动作捕捉数据集上的实验表明，所提出的方法实现了与传统方法相当的分割性能，在包含39,200帧的时间序列数据上，分割速度提高了约278倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [617] [Fast Fourier Correlation is a Highly Efficient and Accurate Feature Attribution Algorithm from the Perspective of Control Theory and Game Theory](https://arxiv.org/abs/2504.02016)
> *快速傅里叶相关性：一种基于控制论和博弈论的高效准确特征归因算法*

*Zechen Liu, Feiyang Zhang, Wei Song, Xiang Li, Wei Wei* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 傅里叶特征归因, 神经网络, 可解释AI, 博弈论, 信号分解

**Comment:** 13 pages, 2 figures

> **TL;DR:** 本文提出了一种基于信号分解理论的新型傅里叶特征归因方法，实验证明该方法比空间域归因更高效准确，且傅里叶特征具有更好的类内集中性和类间区分性，对可解释AI和高效分类有潜力。

**AI_Comments:** 本文创新性地将控制论和博弈论的视角引入傅里叶特征归因，并提出了高效且准确的新方法。其发现傅里叶特征在神经网络中具有更高的信息密度和区分度，为可解释AI和模型压缩提供了新的思路和证据。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明神经网络倾向于学习低频特征，但缺乏明确的傅里叶特征归因方法。此外，需要分析傅里叶域和空间域特征在博弈论归因指标上的差异。

**Method:** 提出了一种基于信号分解理论的新型傅里叶特征归因方法。分析了傅里叶域和空间域特征之间博弈论归因指标的差异。

**Result:** 傅里叶特征归因比空间域归因方法展现出更优越的特征选择能力，例如在ImageNet数据集上的Vision Transformers (ViTs) 案例中，仅需要8%的傅里叶特征即可维持80%样本的原始预测。傅里叶特征表现出更大的类内集中度和类间区分度。

**Conclusion:** 傅里叶特征归因方法高效且准确，傅里叶特征在分类和可解释AI算法中具有巨大潜力。博弈论评估指标更适合傅里叶特征归因。

> **ai_Abstract:** 本文提出了一种基于信号分解理论的新型傅里叶特征归因方法，旨在解决神经网络中傅里叶特征归因方法的缺失。研究分析并证明了博弈论评估指标更适合傅里叶特征归因。实验结果表明，该傅里叶特征归因方法在特征选择上优于传统空间域方法，例如在ImageNet数据集上，ViTs仅需8%的傅里叶特征即可维持80%样本的原始预测。此外，傅里叶特征展现出更好的类内集中度和类间区分度，预示其在高效分类和可解释AI算法中的巨大潜力。

> **摘要翻译:** 从傅里叶特征角度研究神经网络受到了广泛关注。现有分析研究表明神经网络倾向于学习低频特征，但识别特定学习到的傅里叶特征的明确归因方法仍然难以捉摸。为了弥补这一空白，我们提出了一种基于信号分解理论的新型傅里叶特征归因方法。此外，我们分析了傅里叶域和空间域特征之间博弈论归因指标的差异，证明了博弈论评估指标更适合基于傅里叶的特征归因。
我们的实验表明，与空间域归因方法相比，傅里叶特征归因表现出卓越的特征选择能力。例如，在ImageNet数据集上的Vision Transformers (ViTs) 案例中，仅需要8%的傅里叶特征即可维持80%样本的原始预测。此外，我们将我们方法识别的特征特异性与传统空间域归因方法进行了比较。结果显示，傅里叶特征表现出更大的类内集中度和类间区分度，这表明它们在更高效的分类和可解释人工智能算法方面具有潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [622] [Turning Sand to Gold: Recycling Data to Bridge On-Policy and Off-Policy Learning via Causal Bound](https://arxiv.org/abs/2507.11269)
> *点石成金：通过因果界限回收数据以连接在线策略和离线策略学习*

*Tal Fiskus, Uri Shaham* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 深度强化学习, 样本效率, 因果界限, 经验回放, 在线策略学习

**Comment:** 51 pages, 16 figures

> **TL;DR:** 深度强化学习（DRL）智能体需要大量数据和内存。本文提出一种新颖的理论方法，通过建立事实损失的因果界限并回收经验回放缓冲区中通常被丢弃的过去价值网络输出，显著提高了样本效率并大幅减少了缓冲区大小。

**AI_Comments:** 本文的创新之处在于将Neyman-Rubin潜在结果框架应用于深度强化学习，并独辟蹊径地建立了事实损失的因果界限，而非传统上的反事实损失。这种方法使得从经验回放缓冲区中回收通常被丢弃的数据成为可能，变废为宝。其重要性体现在显著提高了样本效率和减少了缓冲区大小，解决了DRL的一个关键瓶颈。同时，其“可忽略的成本”也使其具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 深度强化学习（DRL）智能体在解决复杂决策任务时，通常需要大量的训练步骤和庞大的经验回放缓冲区，这导致了巨大的计算和资源需求。

**Method:** 本文引入了一种新颖的理论结果，将Neyman-Rubin潜在结果框架引入到DRL中。与大多数关注限制反事实损失的方法不同，该方法建立了事实损失的因果界限（类似于DRL中的在线策略损失）。这个界限是通过在经验回放缓冲区中存储过去的价值网络输出来计算的，从而有效地利用了通常被丢弃的数据。

**Result:** 在Atari 2600和MuJoCo领域，对DQN和SAC等多种智能体进行的广泛实验表明，奖励比率提高了高达2,427%，优于未采用该方法的相同智能体，并且经验回放缓冲区大小减少了高达96%，以可忽略的成本显著提高了样本效率。

**Conclusion:** 通过利用通常被丢弃的数据并建立事实损失的因果界限，该方法有效地提高了深度强化学习的样本效率并显著减少了经验回放缓冲区的大小。

> **ai_Abstract:** 本文旨在解决深度强化学习（DRL）中训练步骤多和经验回放缓冲区大导致的计算和资源需求问题。研究提出了一种基于Neyman-Rubin潜在结果框架的新颖理论方法，建立了一个关于事实损失的因果界限（类似于在线策略损失）。该方法通过在经验回放缓冲区中存储和利用通常被丢弃的过去价值网络输出来计算此界限，从而实现数据回收。在Atari 2600和MuJoCo域对DQN和SAC等智能体的广泛实验证明，该方法能将奖励比率提高高达2,427%，并将经验回放缓冲区大小减少高达96%，以可忽略的成本显著提升了样本效率。

> **摘要翻译:** 深度强化学习（DRL）智能体在解决各种领域的复杂决策任务方面表现出色。然而，它们通常需要大量的训练步骤和庞大的经验回放缓冲区，导致巨大的计算和资源需求。为了解决这些挑战，我们引入了一个新颖的理论结果，将Neyman-Rubin潜在结果框架引入DRL。与大多数专注于限制反事实损失的方法不同，我们建立了事实损失的因果界限，这类似于DRL中的在线策略损失。这个界限是通过在经验回放缓冲区中存储过去的价值网络输出来计算的，有效地利用了通常被丢弃的数据。在Atari 2600和MuJoCo领域的各种智能体（如DQN和SAC）上进行的广泛实验表明，奖励比率提高了2,427%，优于未采用我们提出的项的相同智能体，并且经验回放缓冲区大小减少了96%，以可忽略的成本显著提高了样本效率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [629] [Gradient Descent on Logistic Regression: Do Large Step-Sizes Work with Data on the Sphere?](https://arxiv.org/abs/2507.11228)
> *逻辑回归上的梯度下降：大数据步长在球面数据上是否有效？*

*Si Yi Meng, Baptiste Goujaud, Antonio Orvieto, Christopher De Sa* | **Category: cs.LG, math.OC** | **Updated: 2025-07-15**

**Keywords:** 梯度下降, 逻辑回归, 全局收敛, 循环行为, 大步长

**Comment:** 

> **TL;DR:** 本文探讨了在逻辑回归中，当数据点位于球面上时，梯度下降在大步长下能否实现全局收敛。结果表明在一维空间中可以，但在高维空间中仍可能出现循环行为。

**AI_Comments:** 本文在探讨逻辑回归梯度下降的收敛性方面具有一定的创新性，特别是考察了数据点位于球面上的特殊情况。虽然结论显示在高维空间中这种限制不足以保证全局收敛，但其发现了一维空间中的积极结果，并明确指出了未来研究的方向，即量化循环行为和寻找更通用的收敛条件，这对于理解和改进优化算法具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 已知在非线性可分数据上，逻辑回归的梯度下降即使在稳定阈值以下也可能出现循环行为。本文旨在探究将数据限制在等量级（即在球面上）是否足以保证在大步长下的全局收敛。

**Method:** 本文通过理论证明的方式，探讨了数据被限制在等量级（球面上）时，在稳定阈值以下任意步长下，逻辑回归梯度下降的全局收敛性。

**Result:** 结果表明，在一维空间中，将数据限制在等量级可以确保全局收敛。然而，在更高维度中，梯度下降仍可能出现循环行为。

**Conclusion:** 尽管在一维空间中将数据限制在球面上可以保证逻辑回归梯度下降的全局收敛，但在高维空间中，这种限制不足以消除循环行为。这启发了对实际数据中循环现象的量化以及寻找保证大步长下全局收敛的充分条件。

> **ai_Abstract:** 本文研究了在逻辑回归中，当数据点被限制在具有相同幅度的球面上时，梯度下降在大步长下的收敛行为。研究发现，在一维空间中，这种数据限制足以保证全局收敛性。然而，在高维空间中，即使数据位于球面上，梯度下降仍然可能出现循环行为。这项工作强调了在大步长优化中，数据结构对收敛性的复杂影响，并提出了未来研究方向，即量化循环的普遍性以及寻找更强的全局收敛条件。

> **摘要翻译:** 逻辑回归上的梯度下降（GD）具有许多引人入胜的特性。当数据集是线性可分时，已知迭代方向会收敛到最大间隔分离器，无论步长有多大。然而，在不可分的情况下，即使步长仍低于稳定性阈值 $2/\lambda$（其中 $\lambda$ 是解处Hessian矩阵的最大特征值），GD也可能表现出循环行为。这篇短文探讨了将数据限制为等量级是否是全局收敛的充分条件，在任何低于稳定性阈值的步长下。我们证明了这在一维空间中是成立的，但在更高维度中，循环行为仍然可能发生。我们希望能启发进一步的研究，以量化这些循环在实际数据集中出现的频率，并找到保证在大步长下全局收敛的充分条件。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [638] [Matrix Is All You Need](https://arxiv.org/abs/2506.01966)
> *矩阵即所需一切*

*Yuzhou Zhu* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 统一框架, 稀疏矩阵, 神经网络, 卷积, 自注意力

**Comment:** 

> **TL;DR:** 本文提出了一个统一的矩阵序框架，将卷积、循环和自注意力操作表示为稀疏矩阵乘法，并在多项任务上证明其性能与原生模型相当或更优。

**AI_Comments:** 该论文的创新之处在于提出了一个统一的数学框架来描述不同的深度学习操作，将它们归结为稀疏矩阵乘法。这不仅揭示了不同架构之间的底层共性，还为网络设计带来了新的视角，即将其简化为稀疏模式选择，从而更好地利用GPU并行性和现有的代数优化工具。这项工作对于理解和设计未来更高效、更通用的神经网络架构具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络为视觉、序列和语言任务采用专业化架构，但这种多样性掩盖了它们底层的共性，研究旨在提供一个统一的视角。

**Method:** 引入了一个统一的矩阵序框架，将卷积、循环和自注意力操作分别表示为上三角权重矩阵、下三角矩阵和三阶张量分解的稀疏矩阵乘法。研究证明了在温和假设下，其与标准CNN、RNN和Transformer层存在代数同构。

**Result:** 在图像分类（MNIST, CIFAR-10/100, Tiny ImageNet）、时间序列预测（ETTh1, Electricity Load Diagrams）和语言建模/分类（AG News, WikiText-2, Penn Treebank）等任务上的实证评估表明，稀疏矩阵公式的性能与原生模型相当或超越，并且在可比或更少的训练周期内收敛。

**Conclusion:** 本工作为多样化的神经网络架构建立了数学上严格的基础，并为原则性的、硬件感知的网络设计开辟了途径。

> **ai_Abstract:** 该论文提出了一个名为“矩阵即所需一切”的统一矩阵序框架，旨在揭示深度神经网络（如CNN、RNN和Transformer）中不同架构的共同性。该框架将卷积、循环和自注意力操作统一表示为稀疏矩阵乘法，并从代数上证明了与现有模型的同构性。通过在图像、时间序列和语言任务上的广泛实验，研究表明该方法能够匹配甚至超越原生模型的性能，并具有更快的收敛速度。这一工作为硬件友好的网络设计提供了一个数学上严谨的基础。

> **摘要翻译:** 深度神经网络为视觉、序列和语言任务采用专业化架构，然而这种多样性掩盖了它们底层的共性。我们引入了一个统一的矩阵序框架，将卷积、循环和自注意力操作视为稀疏矩阵乘法。卷积通过执行一阶变换的上三角权重矩阵实现；循环通过编码逐步更新的下三角矩阵出现；注意力则自然地作为三阶张量分解产生。我们证明了在温和假设下，其与标准CNN、RNN和Transformer层存在代数同构。在图像分类（MNIST、CIFAR-10/100、Tiny ImageNet）、时间序列预测（ETTh1、电力负荷图）和语言建模/分类（AG News、WikiText-2、宾夕法尼亚大学树库）上的实证评估证实，稀疏矩阵公式的性能与原生模型相当或超越，同时在可比或更少的训练周期内收敛。通过将架构设计简化为稀疏模式选择，我们的矩阵视角与GPU并行性对齐，并利用了成熟的代数优化工具。这项工作为多样化的神经网络架构建立了数学上严格的基础，并为原则性的、硬件感知的网络设计开辟了途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [644] [An All-digital 8.6-nJ/Frame 65-nm Tsetlin Machine Image Classification Accelerator](https://arxiv.org/abs/2501.19347)
> *全数字8.6纳焦/帧65纳米Tsetlin机器图像分类加速器*

*Svein Anders Tunheim, Yujin Zheng, Lei Jiao, Rishad Shafik, Alex Yakovlev, Ole-Christoffer Granmo* | **Category: cs.LG, cs.AR, B.7** | **Updated: 2025-07-15**

**Keywords:** Tsetlin机器, 图像分类, 硬件加速器, 低功耗, 全数字

**Comment:** Copyright 2025 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purpose\, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works

> **TL;DR:** 该论文介绍了一个基于Tsetlin机器的全数字图像分类加速器芯片，实现了高能效和与软件模型匹配的分类精度。

**AI_Comments:** 该论文的创新之处在于首次实现了Tsetlin机器的全数字硬件加速器，并验证了其在图像分类任务上的卓越能效。通过高度并行设计和寄存器存储关键数据，有效提升了TM算法的硬件执行效率，为低功耗边缘AI设备提供了一种有前景的解决方案。其性能与软件模型的一致性也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 开发该芯片的主要动机是验证Tsetlin机器的能效。

**Method:** 该研究提出了一种基于Tsetlin机器（TM）原则的全数字可编程图像分类加速器芯片。它实现了带有卷积的合并TM版本，用于分类28x28像素的二值化图像（10个类别）。该加速器采用128个子句的高度并行架构，通过将所有子句权重和Tsetlin自动机（TA）动作信号保存在寄存器中，实现了快速子句评估。芯片采用65纳米低泄漏CMOS技术实现，占用2.7平方毫米的活动面积。

**Result:** 该加速器在27.8 MHz时钟频率下，每秒可进行60.3k次分类，每次分类消耗8.6 nJ能量。单幅图像分类延迟为25.4 μs。在MNIST、Fashion-MNIST和Kuzushiji-MNIST数据集上分别达到了97.42%、84.54%和82.55%的测试准确率，与TM软件模型相匹配。

**Conclusion:** 该研究证明了Tsetlin机器的高能效，这是开发该芯片的主要动力。

> **ai_Abstract:** 本文介绍了一款基于Tsetlin机器（TM）原理的全数字可编程图像分类加速器芯片。该芯片采用65纳米CMOS技术，实现带有卷积的合并TM版本，用于对二值化图像进行高效分类。通过高度并行架构和寄存器存储关键信号，实现了8.6 nJ/分类的低能耗和高吞吐量（60.3k分类/秒），并在多个MNIST数据集上取得了与软件模型相匹配的准确率，验证了TM的能效优势。

> **摘要翻译:** 我们提出了一种基于Tsetlin机器（TM）原理的全数字可编程机器学习图像分类加速器芯片。TM是一种新兴的基于命题逻辑的机器学习算法，利用称为子句的子模式识别表达式。该加速器实现了带有卷积的合并TM版本，并对28x28像素的10个类别的二值化图像进行分类。在高度并行的架构中使用了128个子句的配置。通过将所有子句权重和Tsetlin自动机（TA）动作信号保存在寄存器中，实现了快速子句评估。该芯片采用65纳米低泄漏CMOS技术实现，占用2.7平方毫米的活动面积。在27.8 MHz的时钟频率下，该加速器每秒可进行60.3k次分类，每次分类消耗8.6 nJ能量。这证明了TM的能效，这是开发该芯片的主要动机。分类单个图像的延迟为25.4 μs，其中包括系统计时开销。该加速器在MNIST、Fashion-MNIST和Kuzushiji-MNIST数据集上分别达到了97.42%、84.54%和82.55%的测试准确率，与TM软件模型相匹配。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [645] [Geometric Learning Dynamics](https://arxiv.org/abs/2504.14728)
> *几何学习动力学*

*Vitaly Vanchurin* | **Category: cs.LG, q-bio.PE, quant-ph** | **Updated: 2025-07-14**

**Keywords:** 几何学习，学习动力学，度量张量，噪声协方差，生物复杂性

**Comment:** 15 pages

> **TL;DR:** 本文提出了一个统一的几何框架来建模物理、生物和机器学习系统的学习动力学，并揭示了由度量张量和噪声协方差矩阵之间幂律关系决定的三种基本机制：量子机制、高效学习机制和平衡机制。

**AI_Comments:** 这篇论文通过引入几何框架和参数 $\alpha$ 来统一描述不同领域的学习动力学，具有创新性。它将物理、生物和机器学习的学习过程联系起来，提供了一个新的视角，特别是将 $\alpha = \tfrac{1}{2}$ 机制与生物复杂性联系起来，具有重要的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为物理、生物和机器学习系统的学习动力学提供一个统一的几何建模框架。

**Method:** 提出了一个统一的几何框架，通过研究可训练变量空间中的度量张量 $g$ 和噪声协方差矩阵 $\kappa$ 之间的幂律关系 $g \propto \kappa^\alpha$ 来建模学习动力学。

**Result:** 理论揭示了三种基本机制：1. 量子机制 ($\alpha = 1$)：描述源于离散平移对称性的类薛定谔动力学。2. 高效学习机制 ($\alpha = \tfrac{1}{2}$)：描述非常快速的机器学习算法。3. 平衡机制 ($\alpha = 0$)：描述生物进化的经典模型。

**Conclusion:** 作者认为中间机制 ($\alpha = \tfrac{1}{2}$) 的出现是生物复杂性产生的一个关键机制。

> **ai_Abstract:** 本文提出了一个统一的几何框架，用于理解物理、生物和机器学习系统中的学习动力学。该框架基于度量张量 $g$ 和噪声协方差矩阵 $\kappa$ 之间的幂律关系 $g \propto \kappa^\alpha$，并揭示了三种主要的学习机制：量子机制 ($\alpha = 1$)、高效学习机制 ($\alpha = \tfrac{1}{2}$) 和平衡机制 ($\alpha = 0$)。研究强调，高效学习机制对于生物复杂性的出现至关重要。

> **摘要翻译:** 我们提出了一个统一的几何框架，用于建模物理、生物和机器学习系统中的学习动力学。该理论揭示了三种基本机制，每种机制都源于可训练变量空间中的度量张量 $g$ 与噪声协方差矩阵 $\kappa$ 之间的幂律关系 $g \propto \kappa^\alpha$。量子机制对应于 $\alpha = 1$，描述了源于离散平移对称性的类薛定谔动力学。高效学习机制对应于 $\alpha = \tfrac{1}{2}$，描述了非常快速的机器学习算法。平衡机制对应于 $\alpha = 0$，描述了生物进化的经典模型。我们认为，中间机制 $\alpha = \tfrac{1}{2}$ 的出现是生物复杂性产生的一个关键机制。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [649] [GALDS: A Graph-Autoencoder-based Latent Dynamics Surrogate model to predict neurite material transport](https://arxiv.org/abs/2507.10871)
> *GALDS：一种基于图自编码器预测神经突物质传输的潜在动力学代理模型*

*Tsung Yeh Hsieh, Yongjie Jessica Zhang* | **Category: cs.LG, cs.NA, math.NA, physics.med-ph** | **Updated: 2025-07-15**

**Keywords:** 图自编码器, 神经突, 物质传输, 代理模型, 神经ODE

**Comment:** 

> **TL;DR:** GALDS是一种基于图自编码器和神经ODE的代理模型，用于高效准确地模拟神经突网络中的物质传输，相比现有方法速度提升10倍，误差更低。

**AI_Comments:** GALDS模型通过结合图自编码器和神经ODE，巧妙地解决了神经突网络物质传输模拟中的计算挑战。其创新性在于利用图自编码器进行高效的潜在空间表示学习，并借助Neural ODEs避免误差累积，从而实现了计算效率和预测精度的显著提升。该方法对于生物医学领域的计算模拟具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 神经突网络中物质传输的准确模拟对于理解生物现象至关重要，但由于其复杂的树状结构，传统方法计算成本高昂且耗时。

**Method:** GALDS模型利用图自编码器对网络的几何结构、速度场和浓度分布进行编码，生成潜在表示。这些潜在表示被组装成一个全局图，然后通过一个受神经常微分方程（Neural ODEs）启发的训练过的图潜在空间系统动力学模型来预测潜在空间中的系统动力学。自编码器的集成减少了对训练数据的需求和模型大小，而Neural ODE组件有效缓解了循环神经网络中常见的误差累积问题。

**Result:** GALDS模型在八个未见几何结构和四个异常传输示例上进行了验证，平均相对误差为3%，最大相对误差小于8%，并且与以前的代理模型方法相比，速度提升了10倍。

**Conclusion:** GALDS模型通过结合图自编码器和神经ODE，为神经突网络中的物质传输模拟提供了一种高效、准确且计算成本更低的解决方案，显著优于现有方法。

> **ai_Abstract:** GALDS是一种基于图自编码器的潜在动力学代理模型，专门设计用于简化神经树中物质传输的模拟。它利用图自编码器编码网络的几何、速度场和浓度分布的潜在表示，并通过一个受神经常微分方程启发的图潜在空间系统动力学模型预测系统动力学。该模型在未见几何结构和异常传输示例上表现出色，平均相对误差为3%，最大相对误差小于8%，并实现了比现有代理模型方法快10倍的速度提升。

> **摘要翻译:** 神经元在其神经突网络中展现出复杂的几何结构，这在信号传导和营养物质运输等过程中起着关键作用。准确模拟网络中的物质传输对于理解这些生物现象至关重要，但由于涉及复杂的树状结构，这带来了显著的计算挑战。传统方法耗时且资源需求高昂，然而，神经元树固有的特性（主要由具有稳态抛物线速度分布的管道和分岔组成）为计算优化提供了机会。为了应对这些挑战，我们提出了一种基于图自编码器的潜在动力学代理（GALDS）模型，该模型专门设计用于简化神经树中物质传输的模拟。GALDS采用图自编码器来编码网络几何结构、速度场和浓度分布的潜在表示。然后，这些潜在空间表示被组装成一个全局图，随后通过一个受神经常微分方程（Neural ODEs）概念启发的训练过的图潜在空间系统动力学模型，用于预测潜在空间中的系统动力学。自编码器的集成允许使用更小的图神经网络模型，并减少了训练数据需求。此外，Neural ODE组件有效地缓解了循环神经网络中常见的误差累积问题。GALDS模型的有效性通过在八个未见几何结构和四个异常传输示例上的结果得到证明，我们的方法实现了3%的平均相对误差，最大相对误差小于8%，并且与以前的代理模型方法相比，速度提升了10倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [655] [Provable Robustness of (Graph) Neural Networks Against Data Poisoning and Backdoor Attacks](https://arxiv.org/abs/2407.10867)
> *（图）神经网络对抗数据投毒和后门攻击的可证明鲁棒性*

*Lukas Gosch, Mahalakshmi Sabanayagam, Debarghya Ghoshdastidar, Stephan Günnemann* | **Category: cs.LG, cs.CR** | **Updated: 2025-07-15**

**Keywords:** 图神经网络, 数据投毒, 后门攻击, 可证明鲁棒性, 白盒认证

**Comment:** Published in TMLR. Best Paper Award at the AdvML-Frontiers @ NeurIPS
  2024 workshop. Code available at https://github.com/saper0/qpcert

> **TL;DR:** 该研究首次证明了图神经网络（GNNs）对抗数据投毒和后门攻击的鲁棒性，通过神经切线核和混合整数线性规划，提供了对图结构在最坏情况鲁棒性中作用的见解，并提出了一个通用的白盒投毒证书框架。

**AI_Comments:** 这项研究的创新之处在于首次将可证明的鲁棒性概念应用于图神经网络，以抵御数据投毒和后门攻击。其重要性在于提出了一个通用的白盒认证框架，该框架不仅为GNNs提供了理论保障，而且可以推广到其他神经网络模型，为机器学习模型的安全性提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习模型的泛化能力会受到数据投毒的严重损害，即训练数据受到对抗性修改。这种脆弱性促使人们研究如何证明（即认证）在一定幅度内的修改不会影响测试预测。

**Method:** 本研究首次认证了图神经网络（GNNs）对抗投毒攻击（包括后门攻击），这些攻击目标是给定图的节点特征。认证是白盒的，基于：(i) 神经切线核，其表征了足够宽网络的训练动态；(ii) 将描述投毒的双层优化问题重新表述为混合整数线性规划。

**Result:** 该框架成功认证了图神经网络对抗投毒攻击，并提供了关于图结构及其连通性在基于卷积和PageRank的GNN最坏情况鲁棒性行为中作用的基本见解。该框架是通用的，是第一个为神经网络推导白盒投毒证书的方法。

**Conclusion:** 本研究首次为图神经网络提供了可证明的对抗数据投毒和后门攻击的鲁棒性认证，并提出了一个通用的白盒投毒证书框架，这对于图相关任务之外的神经网络也具有独立的意义。

> **ai_Abstract:** 该论文首次提出了一种可证明图神经网络（GNNs）对抗数据投毒和后门攻击鲁棒性的方法。通过利用神经切线核和将投毒问题重新表述为混合整数线性规划，研究人员能够提供白盒证书。该框架不仅深入探讨了图结构对GNN鲁棒性的影响，而且是首个为神经网络推导白盒投毒证书的通用方法，具有广泛的应用潜力。

> **摘要翻译:** 机器学习模型的泛化能力可能受到数据投毒的严重损害，即训练数据受到对抗性修改。这种脆弱性导致人们对认证（即证明）这种在一定幅度内的修改不会影响测试预测产生了兴趣。我们首次认证了图神经网络（GNNs）对抗投毒攻击，包括针对给定图的节点特征的后门攻击。我们的证书是白盒的，基于 (i) 神经切线核，其表征了足够宽网络的训练动态；以及 (ii) 将描述投毒的双层优化问题新颖地重新表述为混合整数线性规划。因此，我们利用我们的框架提供了关于图结构及其连通性在基于卷积和PageRank的GNN最坏情况鲁棒性行为中作用的基本见解。我们注意到，我们的框架更具通用性，是第一个为神经网络推导白盒投毒证书的方法，这在图相关任务之外也可能具有独立的意义。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [660] [Step-wise Policy for Rare-tool Knowledge (SPaRK): Offline RL that Drives Diverse Tool Use in LLMs](https://arxiv.org/abs/2507.11371)
> *稀有工具知识的逐步策略 (SPaRK)：驱动LLM多样化工具使用的离线强化学习*

*Gabriel Bo, Koa Chang, Justin Gu* | **Category: cs.LG, cs.MA** | **Updated: 2025-07-15**

**Keywords:** 离线强化学习, 大型语言模型, 工具使用, 多样性, PPO

**Comment:** 12 pages, 4 figures

> **TL;DR:** SPaRK是一种离线强化学习框架，通过双目标奖励系统和稀有优先的探索策略，使LLM能够多样化地使用工具，同时保持准确性。

**AI_Comments:** 这篇论文的创新点在于提出了一个双目标奖励系统和一个稀有优先的利用策略，以鼓励LLMs探索和使用更多样化的工具，而非仅仅追求高频工具。这种方法通过显式地优化工具多样性，为LLM的泛化能力和鲁棒性提供了新的视角，有助于克服传统采样方法的局限性。其重要性在于，它为LLMs在复杂任务中实现更灵活、更全面的工具集成提供了有效的途径。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法在LLM中未能有效探索多样化的工具使用模式，因此需要一种新的强化学习框架来鼓励LLM使用更多不同类型的工具。

**Method:** 提出SPaRK框架，基于逐步强化学习，引入双目标奖励系统（优化答案质量和工具多样性）。使用离线PPO训练Llama-3.1 8B模型，数据来自MMLU-Pro数据集的合成轨迹。采用稀有优先的利用策略，GPT-4o裁判评估八种工具和思维链的候选动作，策略偏向不常用但可行的工具。

**Result:** SPaRK在14个MMLU-Pro类别中取得了有竞争力的性能，并且与基线和监督微调方法相比，在工具选择上表现出显著更高的熵。

**Conclusion:** 通过显式工具多样性的算法探索可以增强LLM的推理能力，而不会牺牲准确性。

> **ai_Abstract:** SPaRK是一种新颖的离线强化学习框架，旨在通过双目标奖励系统（优化答案质量和工具多样性）和稀有优先的利用策略，提高大型语言模型（LLM）的工具使用多样性。该框架在Llama-3.1 8B模型上进行训练，并在MMLU-Pro数据集上展示了在保持竞争性性能的同时显著增加了工具选择的熵，证明了算法探索通过工具多样性可以提升LLM的推理能力。

> **摘要翻译:** 我们提出了稀有工具知识的逐步策略 (SPaRK)，这是一种新颖的强化学习框架，旨在教导大型语言模型探索超越传统高温采样模式的多样化工具使用模式。基于逐步强化学习的最新进展，我们引入了一个双目标奖励系统，该系统同时优化答案质量和工具多样性，通过离线PPO在MMLU-Pro数据集合成生成的轨迹上训练Llama-3.1 8B模型。我们的方法独特地采用了稀有优先的利用策略，其中GPT-4o评判员对八种不同工具以及思维链推理的候选动作进行评分，策略偏好使用频率较低但仍然可行的工具，以鼓励系统性探索。实证结果表明，SPaRK在14个MMLU-Pro类别中取得了有竞争力的性能，同时与基线和监督微调方法相比，在工具选择上表现出显著更高的熵，这表明通过显式工具多样性的算法探索可以在不牺牲准确性的情况下增强推理能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [661] [Divide-Then-Rule: A Cluster-Driven Hierarchical Interpolator for Attribute-Missing Graphs](https://arxiv.org/abs/2507.10595)
> *分而治之：一种用于属性缺失图的聚类驱动分层插值器*

*Yaowen Hu, Wenxuan Tu, Yue Liu, Miaomiao Li, Wenpeng Lu, Zhigang Luo, Xinwang Liu, Ping Chen* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-12**

**Keywords:** 深度图聚类, 属性缺失图, 分层插值, 图补全, DTRGC

**Comment:** 

> **TL;DR:** DTRGC是一种新颖的图补全方法，通过分而治之的策略和分层插值，利用聚类信息处理属性缺失图，显著提升了深度图聚类性能。

**AI_Comments:** DTRGC的创新点在于其“分而治之”的策略和分层插值方法，它巧妙地根据节点邻居信息的完整性进行分层处理，并迭代地利用已补全的信息。同时，该方法将聚类信息融入到特征传播和错误纠正中，形成了一个闭环反馈机制，有效解决了属性缺失图的实际应用难题，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度图聚类（DGC）在属性缺失图上的研究不足，且现有归因方法未能考虑节点邻居信息量的差异，导致结果不可靠，尤其对于已知邻居信息不足的节点。

**Method:** 本文提出了一种名为“分而治之图补全”（DTRGC）的新方法。该方法首先处理已知邻居信息充足的节点，并将补全结果作为新知识迭代地补全更具挑战性的节点，同时利用聚类信息纠正补全错误。具体包括：动态聚类感知特征传播（DCFP）根据聚类结构调整传播权重初始化缺失节点属性；分层邻居感知补全（HNAI）根据邻居属性的完整性将缺失属性节点分为三组，并优先处理信息更充足的组进行分层补全，随后利用聚类结构细化补全并纠正潜在错误；最后，跳步表示增强（HRE）整合多跳信息以丰富节点表示的表达力。

**Result:** 在六个广泛使用的图数据集上的实验结果表明，DTRGC显著提高了各种DGC方法在属性缺失图下的聚类性能。

**Conclusion:** DTRGC通过分层插值和利用聚类信息，有效解决了属性缺失图的节点属性补全问题，显著提升了深度图聚类性能。

> **ai_Abstract:** 针对属性缺失图上的深度图聚类中节点属性补全的挑战，本文提出了一种名为“分而治之图补全”（DTRGC）的新方法。DTRGC采用分而治之的策略，首先处理邻居信息充足的节点，并利用其补全结果迭代处理更复杂的节点。该方法通过动态聚类感知特征传播（DCFP）初始化属性，分层邻居感知补全（HNAI）根据邻居完整性分层补全并利用聚类结构纠错，以及跳步表示增强（HRE）丰富节点表示。实验结果表明，DTRGC显著提升了属性缺失图上各种深度图聚类方法的性能。

> **摘要翻译:** 深度图聚类（DGC）是针对属性缺失图的一种无监督任务，旨在将具有不完整属性的节点划分为不同的簇。解决这个具有挑战性的问题对于实际应用至关重要。然而，该领域的研究仍未得到充分探索。现有针对属性缺失图的归因方法通常未能考虑节点邻居之间可用信息量的差异，导致结果不可靠，特别是对于已知邻居信息不足的节点。为了解决这个问题，我们提出了一种名为“分而治之图补全”（DTRGC）的新方法。该方法首先处理已知邻居信息充足的节点，并将补全结果作为新知识迭代地补全更具挑战性的节点，同时利用聚类信息纠正补全错误。具体来说，动态聚类感知特征传播（DCFP）通过根据聚类结构调整传播权重来初始化缺失节点属性。随后，分层邻居感知补全（HNAI）根据其邻居属性的完整性将属性缺失节点分为三组。补全过程是分层进行的，优先处理那些具有最多可用邻居信息的组。然后，聚类结构被用于细化补全并纠正潜在错误。最后，跳步表示增强（HRE）整合跨多跳的信息，从而丰富节点表示的表达力。在六个广泛使用的图数据集上的实验结果表明，DTRGC显著提高了各种DGC方法在属性缺失图下的聚类性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [666] [Training Dynamics Underlying Language Model Scaling Laws: Loss Deceleration and Zero-Sum Learning](https://arxiv.org/abs/2506.05447)
> *语言模型缩放定律背后的训练动态：损失减速与零和学习*

*Andrei Mircea, Supriyo Chakraborty, Nima Chitsazan, Milind Naphade, Sambit Sahu, Irina Rish, Ekaterina Lobacheva* | **Category: cs.LG, cs.AI, I.2.7** | **Updated: 2025-07-14**

**Keywords:** 语言模型, 缩放定律, 训练动态, 损失减速, 零和学习

**Comment:** Published as a conference paper at ACL 2025

> **TL;DR:** 研究发现语言模型训练早期存在损失减速现象，这限制了模型性能提升。损失减速源于“零和学习”（ZSL），即梯度冲突导致一部分样本损失改善却损害另一部分。模型缩放能缓解此现象。

**AI_Comments:** 这项工作揭示了语言模型训练中的一个关键瓶颈——损失减速和零和学习，为理解模型缩放定律提供了深层机制解释。其创新之处在于提出了“零和学习”的概念，将训练中的梯度冲突与性能瓶颈关联起来。这项研究的重要性在于，它不仅解释了为什么模型缩放有效，还提出了可能独立于规模改进模型性能的新方向，即直接解决零和学习问题。

<details>
  <summary>Details</summary>

**Motivation:** 这项工作旨在理解缩放如何改进语言模型，特别是从训练动态的角度。

**Method:** 通过分析语言模型的训练动态，发现了“损失减速”现象，并将其归因于一种称为“零和学习”（ZSL）的退化训练动态。

**Result:** 1. 语言模型在训练早期会经历“损失减速”，即损失改进速率突然减缓，导致对数-对数空间中的损失曲线呈分段线性行为。2. 扩大模型规模可以缓解这种减速，表现为降低发生减速时的损失值和提高减速后损失改进的对数-对数速率。3. 损失减速被归因于“零和学习”（ZSL），其中每个样本的梯度系统性地相互对立，导致破坏性干扰，从而阻碍整体进展。

**Conclusion:** 损失减速和零和学习为理解语言模型缩放定律背后的训练动态提供了新见解，并且可能为独立于规模改进语言模型提供直接目标。

> **ai_Abstract:** 本文研究语言模型缩放的训练动态，发现模型训练早期存在“损失减速”现象，即损失改进速率显著放缓。这种现象源于“零和学习”（ZSL），其中样本梯度相互冲突，导致损失在不同样本间此消彼长，阻碍整体优化。研究表明，模型缩放能有效缓解损失减速，通过降低减速点损失和提高减速后改进速率。这些发现为理解语言模型缩放定律提供了新视角，并可能指导未来独立于规模的模型改进策略。

> **摘要翻译:** 这项工作旨在理解缩放如何改进语言模型，特别是从训练动态的角度。我们发现语言模型在训练早期会经历损失减速；即损失改进速率突然减缓，导致损失曲线在对数-对数空间中呈现分段线性行为。扩大模型规模可以缓解这种转变，具体表现为 (1) 降低发生减速时的损失值，以及 (2) 提高减速后损失改进的对数-对数速率。我们将损失减速归因于一种退化的训练动态，我们称之为零和学习 (ZSL)。在 ZSL 中，每个样本的梯度系统性地相互对立，导致每个样本的损失变化产生破坏性干扰。结果是，改善一部分样本的损失会损害另一部分，从而阻碍整体进展。损失减速和 ZSL 为理解语言模型缩放定律背后的训练动态提供了新见解，并且可能为独立于规模改进语言模型提供直接目标。我们已在以下网址提供代码和工件：https://github.com/mirandrom/zsl

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [673] [Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors](https://arxiv.org/abs/2505.00580)
> *使用循环矩阵和对角向量的参数高效微调*

*Xinyu Ding, Lexuan Chen, Siyu Liao, Zhongfeng Wang* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 参数高效微调, 循环矩阵, 对角向量, 傅里叶变换, 基础模型

**Comment:** to appear in Proceedings of the 2025 International Joint Conference
  on Artificial Intelligence (IJCAI-2025)

> **TL;DR:** 本文提出了一种新的参数高效微调方法，通过交错循环矩阵和对角矩阵的乘积进行分解，并利用一维快速傅里叶变换，显著减少了计算和存储复杂度，同时保持或提升了模型性能。

**AI_Comments:** 本文的创新点在于提出了基于循环矩阵和对角向量的分解方法，并结合一维FFT来优化参数高效微调。这对于降低大型模型在实际部署和微调中的资源消耗具有重要意义，尤其是在资源受限的环境下。该方法有效解决了非方形权重问题，进一步提升了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 基础模型虽然取得了巨大成功，但其庞大的计算和存储复杂性使得微调困难且实际应用受限。现有傅里叶域训练方法有效，但仍有进一步降低复杂度的空间。

**Method:** 提出通过交错循环矩阵和对角矩阵的乘积进行分解来进一步降低复杂度。针对非方形微调权重，将循环矩阵划分为块。该方法避免了权重变化矩阵的构建，并利用一维快速傅里叶变换（1D FFT）代替二维快速傅里叶变换（2D FFT）。

**Result:** 实验结果表明，该方法在各种任务上实现了相似或更好的性能，同时大大减少了浮点运算（FLOPs）和可训练参数的数量。

**Conclusion:** 本文提出的基于循环矩阵和对角向量的参数高效微调方法，通过创新的分解和计算优化，有效解决了大型基础模型微调的复杂性问题，在保持甚至提升性能的同时，显著降低了资源消耗。

> **ai_Abstract:** 针对大型基础模型微调时面临的计算和存储复杂性问题，本文提出了一种参数高效微调的新方法。该方法通过将微调权重分解为交错循环矩阵和对角矩阵的乘积来降低复杂度。为处理非方形权重，引入了循环矩阵的块划分。与现有方法不同，本文方法避免了构建权重变化矩阵，并采用更高效的一维快速傅里叶变换。实验证明，该方法在多种任务上实现了与现有方法相当或更优的性能，同时显著减少了所需的浮点运算量和可训练参数数量。

> **摘要翻译:** 基础模型在不同领域取得了巨大成功。然而，其庞大的计算和存储复杂性使得这些模型难以微调，并且在实践中适用性较低。最近的研究表明，在傅里叶域进行训练可以是一种有效的微调方法，无论是在模型性能还是训练参数数量方面。在这项工作中，我们提出通过交错循环矩阵和对角矩阵的乘积进行分解来进一步降低复杂性。此外，我们通过将循环矩阵划分为块来解决非方形微调权重的情况。我们的方法避免了权重变化矩阵的构建，并利用一维快速傅里叶变换（FFT）代替二维快速傅里叶变换（2D FFT）。实验结果表明，我们的方法在各种任务上实现了相似或更好的性能，同时大大减少了浮点运算（FLOPs）和可训练参数的数量。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [678] [Generative Click-through Rate Prediction with Applications to Search Advertising](https://arxiv.org/abs/2507.11246)
> *生成式点击率预测及其在搜索广告中的应用*

*Lingwei Kong, Lu Wang, Changping Peng, Zhangang Lin, Ching Law, Jingping Shao* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 点击率预测, 生成模型, 判别式模型, 搜索广告, 两阶段训练

**Comment:** This work was first submitted on February 9, 2024

> **TL;DR:** 本文提出了一种新颖的两阶段训练方法，将生成模型引入判别式点击率预测，并在实际电商平台中验证了其有效性。

**AI_Comments:** 这篇论文的创新点在于将生成模型引入传统的判别式点击率预测框架，通过两阶段训练巧妙地结合了两类模型的优势。这种结合提升了模型的表达能力和预测精度，并在实际大规模电商平台中得到了验证和部署，表明了其重要的工业应用价值。未来的代码和数据集发布也将对研究社区产生积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 现有的点击率预测模型主要依赖判别式模型，但生成模型（如GPT）在表达能力上展现出巨大潜力。因此，研究旨在利用生成模型提升判别式点击率预测的精度。

**Method:** 本文提出了一种新颖的模型，通过两阶段训练过程将生成模型引入判别式点击率预测：1) 对用户行为序列中的下一项预测进行生成式预训练（结合给定商品类别）；2) 在判别式点击率预测框架内对预训练好的生成模型进行微调。

**Result:** 该方法的有效性通过在新数据集上的大量实验得到证实，并通过在线A/B测试结果进一步验证了其显著的实用性。

**Conclusion:** 本文提出的生成式点击率预测模型已被部署在全球最大的电商平台之一，并计划未来发布相关代码和数据集，证明了其在实际应用中的巨大价值和潜力。

> **ai_Abstract:** 本文提出了一种新的点击率（CTR）预测模型，旨在通过整合生成模型的强大表达能力来提高判别式CTR预测的精度。该模型采用独特的两阶段训练策略：首先对用户行为序列中的下一项进行生成式预训练，然后将预训练好的生成模型在判别式CTR预测框架中进行微调。实验证明，该方法在新数据集上表现出显著效果，并通过在线A/B测试验证了其在实际应用中的实用性。目前该模型已部署在大型电商平台。

> **摘要翻译:** 点击率（CTR）预测模型在许多工业环境中都不可或缺，例如个性化搜索广告。当前方法通常涉及从用户历史行为序列中提取特征并结合产品信息，然后输入到判别式模型中，该模型通过用户反馈进行训练以估计点击率。随着GPT等模型的成功，生成模型在丰富表达能力方面超越判别式模型的潜力已变得显而易见。鉴于此，我们引入了一种新颖的模型，该模型利用生成模型来提高判别式模型中点击率预测的精度。为了协调两种模型类型不同的数据聚合需求，我们设计了一个两阶段训练过程：1）对用户行为序列中给定商品类别的下一项预测进行生成式预训练；2）在判别式点击率预测框架内对训练良好的生成模型进行微调。我们的方法在新的数据集上通过大量实验证实了其有效性，并通过在线A/B测试结果进一步证实了其显著的实用性。目前，该模型已部署在全球最大的电子商务平台之一，我们计划未来发布相关的代码和数据集。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [683] [GeoHopNet: Hopfield-Augmented Sparse Spatial Attention for Dynamic UAV Site Location Problem](https://arxiv.org/abs/2507.10636)
> *GeoHopNet：基于Hopfield增强的稀疏空间注意力网络用于动态无人机站点选址问题*

*Jianing Zhi, Xinghua Li, Zidong Chen* | **Category: cs.LG, cs.AI, cs.NE, cs.RO, 90B06, I.2.8** | **Updated: 2025-07-14**

**Keywords:** 无人机选址, 稀疏空间注意力, Hopfield网络, 深度强化学习, 组合优化

**Comment:** 12 Pages, 5 Figures

> **TL;DR:** GeoHopNet通过稀疏空间注意力和Hopfield记忆模块，解决了大规模动态无人机站点选址问题，显著提升了求解速度和质量。

**AI_Comments:** GeoHopNet的创新性在于结合了稀疏注意力机制和Hopfield外部记忆模块，有效解决了大规模空间优化问题中的计算效率和记忆瓶颈。其在处理1000节点规模问题上的表现，展示了其在实际应用中的巨大潜力，特别是在城市低空无人机经济背景下。

<details>
  <summary>Details</summary>

**Motivation:** 城市低空无人机经济的快速发展给动态无人机着陆点和补给站的选址带来了新挑战。传统深度强化学习方法，特别是标准注意力机制，在处理大规模城市级选址问题时面临计算复杂性瓶颈。

**Method:** 提出GeoHopNet，一个Hopfield增强的稀疏空间注意力网络，专门用于动态无人机站点选址问题。其核心创新包括：距离偏置多头注意力机制、K近邻稀疏注意力（将复杂度从O(N^2)降至O(NK)）、现代Hopfield外部记忆模块以及记忆正则化策略。

**Result:** GeoHopNet扩展了可解决问题规模的边界。对于1000个节点的大规模实例，GeoHopNet在0.1秒内找到高质量解决方案（0.22%最优性差距），而标准注意力模型过慢（超过3秒）且传统求解器失败。与100个节点实例上的SOTA ADNet基线相比，GeoHopNet解决方案质量提高了22.2%，速度快1.8倍。

**Conclusion:** GeoHopNet有效解决了大规模动态无人机站点选址问题，显著提升了计算效率和解决方案质量，超越了现有方法。

> **ai_Abstract:** 本文提出了GeoHopNet，一个针对动态无人机站点选址问题的Hopfield增强稀疏空间注意力网络。该网络通过引入距离偏置多头注意力、K近邻稀疏注意力、现代Hopfield外部记忆模块和记忆正则化策略，有效解决了传统深度强化学习方法在处理大规模问题时的计算复杂性瓶颈。实验证明，GeoHopNet能在大规模实例上快速找到高质量解决方案，显著优于现有方法。

> **摘要翻译:** 城市低空无人机（UAV）经济的快速发展给无人机着陆点和补给站的动态选址带来了新的挑战。传统的深度强化学习方法，尤其是在处理大规模城市级别选址问题时，面临计算复杂性瓶颈，特别是标准注意力机制。本文提出了GeoHopNet，一个专门为动态无人机站点选址问题设计的Hopfield增强稀疏空间注意力网络。我们的方法引入了四项核心创新：(1) 显式编码空间几何信息的距离偏置多头注意力机制；(2) 将计算复杂度从$O(N^2)$降低到$O(NK)$的K近邻稀疏注意力；(3) 现代Hopfield外部记忆模块；以及 (4) 记忆正则化策略。实验结果表明，GeoHopNet扩展了可解决问题规模的边界。对于1000个节点的大规模实例，标准注意力模型变得非常慢（每个实例超过3秒）且传统求解器失败，而GeoHopNet在0.1秒内找到了高质量的解决方案（0.22%的最优性差距）。与100个节点实例上的最先进的ADNet基线相比，我们的方法将解决方案质量提高了22.2%，并且速度快1.8倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [698] [Domain-Adaptive Small Language Models for Structured Tax Code Prediction](https://arxiv.org/abs/2507.10880)
> *领域自适应小型语言模型用于结构化税务代码预测*

*Souvik Nath, Sumit Wadhwa, Luiz Perez* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-15**

**Keywords:** 小型语言模型, 税务代码预测, 编码器-解码器, 领域自适应, 分层序列生成

**Comment:** 10 pages, 3 figures

> **TL;DR:** 本文提出了一种领域自适应的小型语言模型（SLM），采用编码器-解码器架构，用于预测产品和服务的分层税务代码，并在HSN等数据集上取得了优于传统分类器和单一架构模型的性能。

**AI_Comments:** 该论文的创新点在于将小型语言模型（SLM）与编码器-解码器架构相结合，应用于税务代码这一特定且具有分层结构的领域。这解决了现有NLP研究中对该领域探索不足的问题，并证明了SLM在处理结构化序列预测任务上的潜力。其能够处理分层依赖性并优于传统模型的表现，对于税务合规自动化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 跨国公司每天处理数千笔交易，每笔交易都必须遵守复杂的税务法规。准确确定产品和服务税务代码（如HSN或SAC）对于避免税务处罚至关重要，但这是一个挑战。

**Method:** 本文提出了一种领域自适应的小型语言模型（SLM），采用编码器-解码器架构来解决使用非结构化产品和服务数据预测分层税务代码序列的问题。该模型通过顺序生成税务代码来捕获其固有的分层依赖关系。

**Result:** 实验表明，编码器-解码器SLM可以成功应用于结构化税务代码的顺序预测，这是一个在当前NLP研究中相对未探索的领域。与平面分类器相比，领域自适应编码器-解码器SLM在协调系统命名法（HSN）上的表现更优越，并且在结构化序列生成任务中，其结果优于仅解码器和仅编码器架构。

**Conclusion:** 领域自适应的编码器-解码器SLM能够有效地预测分层税务代码，并在该特定领域展现出卓越的性能。该方法还可以扩展到其他政府强制的税务商品代码，如联合国标准产品和服务代码（UNSPSC）或巴西的南方共同市场通用命名法（NCM）。

> **ai_Abstract:** 本文针对跨国公司税务合规中产品和服务税务代码预测的挑战，提出了一种领域自适应的小型语言模型（SLM）。该模型采用编码器-解码器架构，能够利用非结构化数据预测分层税务代码序列，并捕获其内部依赖关系。实验证明，该方法在HSN数据集上表现出优于传统平面分类器以及仅解码器/仅编码器架构的性能，并具有推广到其他税务代码系统的潜力。

> **摘要翻译:** 每天，跨国公司处理数千笔交易，每笔交易都必须遵守因司法管辖区而异且通常细致入微的税务法规。产品和服务税务代码（如HSN或SAC）的确定是税务合规中的一个主要用例。准确确定此类代码对于避免任何税务处罚至关重要。本文提出了一种领域自适应的小型语言模型（SLM），采用编码器-解码器架构，用于增强产品和服务税务代码的预测。在这种方法中，我们解决了使用非结构化产品和服务数据预测分层税务代码序列的问题。我们采用基于编码器-解码器架构的SLM，因为这使得税务代码的顺序生成能够捕获税务代码中存在的分层依赖关系。我们的实验表明，编码器-解码器SLM可以成功应用于结构化税务代码的顺序预测，这是一个在当前NLP研究中相对未探索的领域。在本文中，我们证明了领域自适应编码器-解码器SLM在应用于协调系统命名法（HSN）时，其性能优于平面分类器，并且在结构化序列生成任务中，与仅解码器和仅编码器架构相比，取得了更优异的结果。这种方法还可以扩展到其他政府强制的税务商品代码，例如联合国标准产品和服务代码（UNSPSC）或巴西的南方共同市场通用命名法（NCM）。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [701] [EntroLLM: Entropy Encoded Weight Compression for Efficient Large Language Model Inference on Edge Devices](https://arxiv.org/abs/2505.02380)
> *EntroLLM：用于边缘设备高效大型语言模型推理的熵编码权重压缩*

*Arnab Sanyal, Gourav Datta, Prithwish Mukherjee, Sandeep P. Chinchali, Michael Orshansky* | **Category: cs.LG** | **Updated: 2025-07-14**

**Keywords:** 大型语言模型, 权重压缩, 边缘设备, 混合量化, 霍夫曼编码

**Comment:** 6 pages, 1 reference page

> **TL;DR:** EntroLLM通过结合混合量化和熵编码，显著减少LLM在边缘设备上的存储需求并加速推理，同时保持模型精度，无需重新训练。

**AI_Comments:** EntroLLM的创新之处在于其将混合量化与熵编码（特别是霍夫曼编码）结合，以实现LLM在边缘设备上的高效部署。其亮点在于无损压缩的引入和并行解码机制，有效解决了内存带宽限制，同时保持了模型性能。该方法无需再训练的特性大大提升了其实用性和部署便利性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的巨大存储和计算需求限制了它们在边缘设备上的部署。

**Method:** EntroLLM是一个新颖的压缩框架，它整合了混合量化和熵编码。它采用逐层混合量化方案（根据每层权重分布选择对称或非对称量化）来优化可压缩性。然后使用霍夫曼编码对量化权重进行无损压缩，并引入并行霍夫曼解码以在推理过程中高效检索编码权重。

**Result:** EntroLLM在语言基准任务上，与uint8模型相比，存储减少高达30%；与uint4模型相比，存储减少高达65%，同时保持了困惑度和准确性。在内存带宽受限的边缘设备（如NVIDIA Jetson P3450）上，推理吞吐量提高了31.9%至146.6%。

**Conclusion:** EntroLLM通过降低存储和数据传输需求，显著提高了LLM在边缘设备上的效率，且无需额外再训练，并与现有后训练量化方法完全兼容，使其成为边缘LLMs的实用解决方案。

> **ai_Abstract:** EntroLLM是一种新颖的压缩框架，旨在解决大型语言模型在边缘设备上的部署挑战。它结合了逐层混合量化和霍夫曼编码，以实现显著的存储压缩和内存带宽减少，同时通过并行霍夫曼解码确保推理效率和模型精度。实验证明，EntroLLM在多种LLM上实现了显著的存储缩减和推理加速，且无需额外训练，兼容现有量化方法。

> **摘要翻译:** 大型语言模型（LLMs）在各种任务中表现出色，但其庞大的存储和计算需求限制了它们在边缘设备上的部署。为了解决这个问题，我们提出了EntroLLM，一个新颖的压缩框架，它将混合量化与熵编码相结合，以减少存储开销同时保持模型精度。我们的方法采用逐层混合量化方案——根据单个层的权重分布选择对称或非对称量化——以优化可压缩性。然后我们采用霍夫曼编码对量化权重进行无损压缩，显著降低了内存带宽要求。此外，我们引入了并行霍夫曼解码，这使得在推理过程中能够高效检索编码权重，确保最小的延迟影响。我们在边缘兼容的LLMs（包括smolLM-1.7B-Instruct、phi3-mini-4k-Instruct和mistral-7B-Instruct）上进行的实验表明，EntroLLM在语言基准任务上，与uint8模型相比，存储减少高达30%；与uint4模型相比，存储减少高达65%，同时保持了困惑度和准确性。我们进一步表明，我们的方法通过减少所需数据移动，在内存带宽受限的边缘设备（如NVIDIA Jetson P3450）上实现了31.9%至146.6%的更快推理吞吐量。所提出的方法不需要额外的再训练，并且与现有后训练量化方法完全兼容，使其成为边缘LLMs的实用解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [717] [RedOne: Revealing Domain-specific LLM Post-Training in Social Networking Services](https://arxiv.org/abs/2507.10605)
> *RedOne：揭示社交网络服务中的领域特定LLM后训练*

*Fei Zhao, Chonggang Lu, Yue Wang, Zheyong Xie, Ziyan Liu, Haofu Qian, JianZhao Huang, Fangcheng Shi, Zijie Meng, Hongcheng Guo, Mingqian He, Xinze Lyu, Yiming Lu, Ziyang Xiang, Zheyu Ye, Chengqiang Lu, Zhe Xu, Yi Wu, Yao Hu, Yan Gao, Jun Fan, Xiaolong Jiang, Weiting Liu, Boyang Wang, Shaosheng Cao* | **Category: cs.LG, cs.AI, cs.SI** | **Updated: 2025-07-13**

**Keywords:** 大型语言模型, 社交网络服务, 领域特定LLM, 后训练, 偏好优化

**Comment:** 

> **TL;DR:** RedOne是一个为社交网络服务（SNS）设计的领域特定大型语言模型（LLM），通过三阶段训练策略，在多项SNS任务和真实世界应用中取得了显著性能提升，解决了现有单任务LLM的局限性。

**AI_Comments:** 该论文创新性地提出了一种领域特定LLM——RedOne，以解决LLM在多样化SNS语境中应用的挑战。其三阶段训练策略全面，结合了通用预训练、微调和偏好优化，这可能有助于其强大的性能和泛化能力。论文中包含离线基准测试结果和在线测试指标（有害内容检测、点击页面率），这为其实际应用和影响力提供了有力的证据，是其显著优势。专注于为SNS构建“全面基础”而非孤立任务是其关键创新点。

<details>
  <summary>Details</summary>

**Motivation:** 社交网络服务（SNS）在内容管理和互动质量方面面临重大挑战。现有的大型语言模型（LLMs）研究侧重于孤立任务，导致数据扩展效益递减且难以灵活适应多样化的真实世界语境。因此，本研究的动机是开发一个领域特定的LLM来解决这些限制，并为SNS建立一个全面的基础。

**Method:** 本研究引入了RedOne，一个领域特定的LLM。RedOne通过三阶段训练策略开发，包括持续预训练、监督微调和偏好优化，并使用了大规模真实世界数据集。

**Result:** RedOne保持了强大的通用能力。与基础模型相比，RedOne在8个主要的SNS任务中实现了平均高达14.02%的改进，在SNS双语评估基准上实现了7.56%的改进。通过在线测试，与单任务微调基线模型相比，RedOne在有害内容检测中将曝光率降低了11.23%，在帖子查看搜索中将点击页面率提高了14.95%。

**Conclusion:** RedOne被确立为一个强大的SNS领域特定LLM，在各种任务中表现出出色的泛化能力，并在真实世界场景中具有良好的适用性。

> **ai_Abstract:** 本文介绍了RedOne，一个专为社交网络服务（SNS）设计的新型领域特定大型语言模型，旨在克服现有单任务LLM在数据扩展效益和真实世界适应性方面的局限。RedOne采用三阶段训练策略（持续预训练、监督微调和偏好优化），并利用大规模真实世界数据集进行训练。广泛的实验表明，RedOne显著提升了各种SNS任务的性能（例如，在8个任务上平均提升14.02%，在双语评估上提升7.56%），并展示了强大的真实世界适用性，有效降低了有害内容曝光并提升了内容互动。这确立了RedOne作为SNS的强大且可泛化的解决方案。

> **摘要翻译:** 作为现代信息传播的主要媒介，社交网络服务（SNS）经历了快速增长，这对平台内容管理和互动质量提升提出了重大挑战。最近，大型语言模型（LLMs）的发展提供了潜在的解决方案，但现有研究侧重于孤立的任务，这不仅在单个场景内的数据扩展中遇到收益递减的问题，而且未能灵活适应多样化的真实世界语境。为了应对这些挑战，我们引入了RedOne，一个领域特定的LLM，旨在打破单任务基线的性能瓶颈，并为SNS建立一个全面的基础。RedOne通过三阶段训练策略开发，包括持续预训练、监督微调和偏好优化，并使用了大规模真实世界数据集。通过广泛的实验，RedOne保持了强大的通用能力，并在8个主要的SNS任务中实现了平均高达14.02%的改进，在SNS双语评估基准上实现了7.56%的改进，与基础模型相比。此外，通过在线测试，RedOne在有害内容检测中将曝光率降低了11.23%，在帖子查看搜索中将点击页面率提高了14.95%，与单任务微调基线模型相比。这些结果确立了RedOne作为SNS的强大领域特定LLM，展示了在各种任务中的出色泛化能力和在真实世界场景中的良好适用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [722] [The Price of Freedom: Exploring Expressivity and Runtime Tradeoffs in Equivariant Tensor Products](https://arxiv.org/abs/2506.13523)
> *自由的代价：探索等变张量积中的表达能力与运行时权衡*

*YuQing Xie, Ameya Daigavane, Mit Kotak, Tess Smidt* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 等变神经网络, 张量积, 表达能力, 运行时优化, 基准测试

**Comment:** Published at ICML 2025. 27 pages, 10 figures

> **TL;DR:** 本文系统分析了等变张量积操作，揭示了不同张量积在表达能力和运行时之间的权衡。研究发现，声称的加速通常以表达能力为代价。作者引入了表达能力和交互能力度量，并提出了一种更快的Gaunt张量积（GTP）实现方法，同时提供了首个系统性的微基准测试，指出理论运行时与实际性能存在差异。

**AI_Comments:** 本文通过对等变张量积操作进行系统性分析，揭示了性能优化与模型表达能力之间的关键权衡，这一点在以往工作中常被忽视。其创新点在于引入了量化表达能力和交互能力的度量，并提出了一种更高效的Gaunt张量积实现方法。同时，首次进行的系统微基准测试揭示了理论与实践性能的差异，对未来等变网络的设计和优化提供了重要指导，具有较高的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 等变神经网络在3D建模任务中取得成功，但其核心操作——张量积计算复杂度高。现有优化方法（如Gaunt张量积）声称能显著加速，但本文旨在揭示这些加速是否以牺牲表达能力为代价，并系统分析不同张量积操作的表达能力和运行时权衡。

**Method:** 本文对多种张量积操作进行了细致、系统的分析。引入了表达能力（expressivity）和交互能力（interactability）的度量来表征不同张量积之间的差异。此外，作者提出通过直接使用球面网格来简化Gaunt张量积（GTP）的原始实现，且不增加渐近运行时开销。最后，提供了各种张量积操作的首个系统性微基准测试。

**Result:** 研究发现，不同的张量积操作并非执行相同的操作，所报告的加速通常以表达能力为代价。通过直接使用球面网格，Gaunt张量积的实现可以大大简化，并且在基准测试和MACE原子间势的实际训练中速度提高了30%。微基准测试表明，理论运行时保证与经验性能可能存在巨大差异。

**Conclusion:** 本文强调了理解等变张量积中表达能力和运行时权衡的重要性。研究结果表明，理论运行时保证与实际经验性能之间存在显著差异，因此在实际应用中需要进行细致的、针对特定应用的基准测试。

> **ai_Abstract:** 本文系统地分析了等变神经网络中张量积操作的表达能力与运行时之间的权衡。研究指出，现有声称的加速方法往往以牺牲表达能力为代价。为量化这些差异，作者引入了表达能力和交互能力度量。此外，他们发现Gaunt张量积（GTP）的实现可通过使用球面网格而大幅简化并提速30%。论文还提供了首次系统性的张量积微基准测试，揭示了理论运行时与实际性能之间的显著差异，强调了进行应用特定基准测试的必要性。

> **摘要翻译:** 《自由的代价：探索等变张量积中的表达能力与运行时权衡》

等变E(3)神经网络在广泛的3D建模任务中取得了成功。这些网络中的一个基本操作是张量积，它以等变的方式交互两个几何特征以创建新特征。由于张量积的计算复杂度高，因此在优化此操作的运行时方面投入了大量精力。例如，Luo 等人（2024）最近提出了Gaunt张量积（GTP），有望显著加速。在这项工作中，我们对多种张量积操作进行了细致、系统的分析。我们特别强调，不同的张量积并非执行相同的操作。所报告的加速通常以表达能力为代价。我们引入了表达能力和交互能力度量来表征这些差异。此外，我们意识到GTP的原始实现可以通过直接使用球面网格而大大简化，且不增加渐近运行时开销。这种球面网格方法在我们的基准测试和MACE原子间势的实际训练中速度提高了30%。最后，我们提供了各种张量积操作的首个系统性微基准测试。我们发现理论运行时保证与经验性能可能存在巨大差异，这表明需要进行细致的、针对特定应用的基准测试。代码可在 https://github.com/atomicarchitects/PriceofFreedom 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [727] [LyAm: Robust Non-Convex Optimization for Stable Learning in Noisy Environments](https://arxiv.org/abs/2507.11262)
> *LyAm: 嘈杂环境下稳定学习的鲁棒非凸优化*

*Elmira Mirzabeigi, Sepehr Rezaee, Kourosh Parand* | **Category: cs.LG, math.OC** | **Updated: 2025-07-15**

**Keywords:** 深度学习优化, Adam, Lyapunov稳定性, 非凸优化, 梯度噪声

**Comment:** 

> **TL;DR:** LyAm是一个结合Adam和Lyapunov稳定机制的新型优化器，能提高深度学习在嘈杂环境下的收敛鲁棒性和性能。

**AI_Comments:** LyAm的创新在于将Lyapunov稳定性理论引入优化器设计，动态调整学习率以应对噪声和不稳定性，这为深度学习优化提供了新的视角和强大的工具。其理论保证和实验表现使其成为一个重要的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 训练深度神经网络（尤其在计算机视觉任务中）常受梯度噪声和收敛不稳定困扰，影响性能和泛化能力。

**Method:** 本文提出LyAm，一种新型优化器，它将Adam的自适应矩估计与基于Lyapunov的稳定性机制相结合。LyAm利用Lyapunov稳定性理论动态调整学习率，以增强收敛鲁棒性并减轻训练噪声。作者提供了严格的理论框架，证明了LyAm在复杂非凸设置下的收敛保证。

**Result:** 在CIFAR-10和CIFAR-100等数据集上的大量实验表明，LyAm在准确性、收敛速度和稳定性方面始终优于现有最先进的优化器。

**Conclusion:** LyAm是深度学习鲁棒优化的一个有力候选。

> **ai_Abstract:** 本文提出LyAm，一种结合Adam自适应矩估计和Lyapunov稳定性机制的新型优化器，旨在解决深度神经网络训练中梯度噪声和收敛不稳定的问题。LyAm利用Lyapunov理论动态调整学习率，增强收敛鲁棒性并减少噪声。理论上，LyAm在非凸设置下具有收敛保证。实验结果表明，LyAm在准确性、收敛速度和稳定性方面均优于现有优化器，是鲁棒深度学习优化的有效方案。

> **摘要翻译:** 训练深度神经网络，尤其是在计算机视觉任务中，经常受到梯度噪声和收敛不稳定的困扰，这会阻碍性能和泛化能力。在本文中，我们提出了LyAm，一种新颖的优化器，它将Adam的自适应矩估计与基于Lyapunov的稳定性机制相结合。LyAm利用Lyapunov稳定性理论动态调整学习率，以增强收敛鲁棒性并减轻训练噪声。我们提供了一个严格的理论框架，证明了LyAm在复杂非凸设置下的收敛保证。在CIFAR-10和CIFAR-100等数据集上进行的大量实验表明，LyAm在准确性、收敛速度和稳定性方面始终优于现有最先进的优化器，使其成为鲁棒深度学习优化的有力候选。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [729] [Prediction via Shapley Value Regression](https://arxiv.org/abs/2505.04775)
> *通过Shapley值回归进行预测*

*Amr Alkhatib, Roman Bresson, Henrik Boström, Michalis Vazirgiannis* | **Category: cs.LG** | **Updated: 2025-07-14**

**Keywords:** Shapley值, 可解释AI, ViaSHAP, 柯尔莫哥洛夫-阿诺德网络, 黑箱模型

**Comment:** Accepted at ICML 2025

> **TL;DR:** 提出ViaSHAP新方法，通过学习函数直接计算Shapley值并进行预测，解决了传统方法计算成本高的问题，在表格数据上表现与SOTA相当，且解释性优于FastSHAP。

**AI_Comments:** 这篇论文创新性地提出了一种在模型训练阶段就整合Shapley值计算的方法（ViaSHAP），而非传统的后处理方式，这显著降低了推理时的计算成本。其利用柯尔莫哥洛夫-阿诺德网络实现Shapley值预测的思路颇具新意，并且在性能和解释准确性上都展现了竞争力，特别是其解释精度优于FastSHAP这一点是重要的优势。这为可解释AI领域提供了一个高效且准确的新工具。

<details>
  <summary>Details</summary>

**Motivation:** 传统的Shapley值计算是事后进行的，这导致在推理时产生额外的计算成本，限制了其在大规模应用中的效率。

**Method:** 本文提出了一种名为ViaSHAP的新方法，该方法学习一个函数来计算Shapley值，并通过对这些值的求和直接得出预测结果。该方法探索了两种实现途径：一种基于通用逼近定理，另一种基于柯尔莫哥洛夫-阿诺德表示定理。

**Result:** 大规模实证研究表明，使用柯尔莫哥洛夫-阿诺德网络实现的ViaSHAP在表格数据上与最先进的算法表现相当。此外，ViaSHAP的解释性在表格数据和图像上都比流行的近似器FastSHAP显著更准确。

**Conclusion:** ViaSHAP通过学习函数直接计算Shapley值并生成预测，有效解决了传统Shapley值计算的成本问题，并在性能和解释准确性方面达到了先进水平，尤其是在表格数据上与SOTA相当，且解释优于FastSHAP。

> **ai_Abstract:** 本文提出了一种名为ViaSHAP的新颖方法，旨在解决传统Shapley值计算在推理时的高昂计算成本问题。ViaSHAP通过学习一个函数来直接计算Shapley值，并从这些值中通过求和得到预测结果。该方法探索了基于通用逼近定理和柯尔莫哥洛夫-阿诺德表示定理的两种实现方式。实证结果显示，使用柯尔莫哥洛夫-阿诺德网络的ViaSHAP在表格数据上的性能与现有最先进算法相当，并且其解释的准确性在表格数据和图像上均显著优于流行的近似器FastSHAP。

> **摘要翻译:** Shapley值具有多种理想且理论上得到良好支持的特性，可用于解释黑箱模型预测。传统上，Shapley值是事后计算的，这导致在推理时产生额外的计算成本。为了克服这个问题，本文提出了一种名为ViaSHAP的新颖方法，该方法学习一个函数来计算Shapley值，并可以通过求和直接从中得出预测结果。本文探索了实现该方法的两种途径：一种基于通用逼近定理，另一种基于柯尔莫哥洛夫-阿诺德表示定理。大规模实证研究的结果表明，使用柯尔莫哥洛夫-阿诺德网络（KANs）的ViaSHAP在表格数据上与最先进的算法表现相当。研究还表明，ViaSHAP的解释性在表格数据和图像上都比流行的近似器FastSHAP显著更准确。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [743] [Learning from Imperfect Data: Robust Inference of Dynamic Systems using Simulation-based Generative Model](https://arxiv.org/abs/2507.10884)
> *从不完美数据中学习：使用基于仿真的生成模型对动态系统进行鲁棒推理*

*Hyunwoo Cho, Hyeontae Jo, Hyung Ju Hwang* | **Category: cs.LG, math.DS, 68T07, 68T05, 70G60** | **Updated: 2025-07-15**

**Keywords:** 动态系统, 不完美数据, 物理信息神经网络, 生成对抗网络, 系统推理

**Comment:** 

> **TL;DR:** SiGMoID模型通过结合物理信息神经网络和Wasserstein GANs，实现了在噪声、稀疏或部分可观测数据下对非线性动态系统进行精确且鲁棒的推理。

**AI_Comments:** 该论文创新性地结合了物理信息神经网络和生成对抗网络，以解决动态系统在不完美数据下的推理难题。这种混合模型的方法有望在数据质量受限的实际应用中提供更鲁棒和精确的系统理解，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 非线性动态模型（由常微分方程表示）的系统推理在许多领域仍面临重大挑战，尤其是在数据存在噪声、稀疏或部分可观测时。

**Method:** 本文提出了一个用于不完美数据的基于仿真的生成模型（SiGMoID）。该方法整合了两种关键技术：1）带有超网络的物理信息神经网络，用于构建ODE求解器；2）Wasserstein生成对抗网络，通过有效捕获噪声数据分布来估计ODE参数。

**Result:** SiGMoID能够量化数据噪声、估计系统参数并推断未观测的系统组件。其有效性通过真实的实验例子得到了验证，展示了其在科学研究和工程系统等各种领域中的广泛适用性。

**Conclusion:** SiGMoID模型能够从不完美数据中对动态系统进行精确且鲁棒的推理，并有助于发现完整的系统动力学。

> **ai_Abstract:** 本研究提出了一种名为SiGMoID的基于仿真的生成模型，旨在解决非线性动态系统在数据不完美（噪声、稀疏、部分可观测）情况下的精确鲁棒推理问题。SiGMoID结合了带有超网络的物理信息神经网络（用于ODE求解）和Wasserstein生成对抗网络（用于参数估计和噪声数据分布捕获）。该模型能够量化数据噪声、估计系统参数并推断未观测组件，并在多个实际案例中验证了其有效性和广泛适用性。

> **摘要翻译:** 非线性动态模型（由常微分方程（ODE）表示）的系统推理在许多领域仍然是一个重大挑战，特别是当数据存在噪声、稀疏或部分可观测时。在本文中，我们提出了一个用于不完美数据的基于仿真的生成模型（SiGMoID），它能够对动态系统进行精确且鲁棒的推理。所提出的方法整合了两种关键方法：(1) 带有超网络的物理信息神经网络，用于构建ODE求解器；(2) Wasserstein生成对抗网络，通过有效捕获噪声数据分布来估计ODE参数。我们证明了SiGMoID能够量化数据噪声，估计系统参数，并推断未观测的系统组件。其有效性通过真实的实验例子得到了验证，展示了其在从科学研究到工程系统等各种领域中的广泛适用性，并能够发现完整的系统动力学。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [749] [FLAME: Towards Federated Fine-Tuning Large Language Models Through Adaptive SMoE](https://arxiv.org/abs/2506.16600)
> *FLAME：通过自适应SMoE实现联邦微调大型语言模型*

*Khiem Le, Tuan Tran, Ting Hua, Nitesh V. Chawla* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 联邦学习, 大型语言模型, SMoE, LoRA, 资源自适应

**Comment:** 

> **TL;DR:** FLAME是一种新的联邦学习框架，通过自适应SMoE架构，在不压缩LoRA矩阵的情况下，实现客户端的资源自适应LLM微调，解决了现有方法的性能下降问题。

**AI_Comments:** FLAME的创新之处在于将SMoE架构引入联邦学习，并巧妙地通过调整激活专家数量而非压缩LoRA矩阵来实现资源自适应，从而避免了信息损失。其提出的重缩放和激活感知聚合机制有效地解决了SMoE在联邦环境中的特有挑战，显示了其在资源受限环境中微调大型语言模型的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的资源自适应LoRA联邦微调方法需要压缩全局LoRA矩阵，这会导致信息丢失和次优性能。

**Method:** FLAME提出了一种基于稀疏专家混合（SMoE）架构的联邦学习框架。它不压缩全局LoRA矩阵，而是通过改变每个客户端激活的专家数量来实现客户端适应性。为了解决部分专家激活导致的输出幅度不匹配和专家训练质量不平衡问题，FLAME采用了轻量级重缩放机制和激活感知聚合方案。

**Result:** 经验结果表明，FLAME在不同的计算设置下始终优于现有方法。

**Conclusion:** FLAME为资源自适应联邦学习提供了一个强大而有效的解决方案。

> **ai_Abstract:** 本文提出了FLAME，一个基于稀疏专家混合（SMoE）架构的新型联邦学习框架，旨在解决现有资源自适应LoRA联邦微调方法中因压缩全局LoRA矩阵导致的信息丢失和性能下降问题。FLAME通过调整每个客户端激活的专家数量来实现资源自适应，无需压缩LoRA矩阵，并引入了轻量级重缩放机制和激活感知聚合方案来应对SMoE在联邦学习中的挑战。实验证明FLAME在各种计算环境下均优于现有方法，为资源自适应联邦学习提供了有效方案。

> **摘要翻译:** 现有资源自适应的LoRA联邦微调方法允许客户端使用全局LoRA矩阵的压缩版本来微调模型，以适应不同客户端的计算资源。这种压缩要求会导致信息丢失，从而导致次优性能。为了解决这个问题，我们提出了FLAME，一个基于稀疏专家混合（SMoE）架构的新型联邦学习框架。与之前的方法不同，FLAME保留了完整的（未压缩的）全局LoRA矩阵，并通过改变每个客户端激活的专家数量来实现客户端自适应性。然而，将SMoE整合到联邦学习中引入了独特的挑战，特别是部分专家激活导致的输出幅度不匹配以及客户端之间专家训练质量不平衡的问题。FLAME通过轻量级重缩放机制和激活感知聚合方案来解决这些挑战。跨不同计算设置的经验结果表明，FLAME始终优于现有方法，为资源自适应联邦学习提供了一个强大而有效的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [753] [A Simple Baseline for Stable and Plastic Neural Networks](https://arxiv.org/abs/2507.10637)
> *一种用于稳定和可塑神经网络的简单基线*

*É. Künzel, A. Jaziri, V. Ramesh* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-07-14**

**Keywords:** 持续学习, 神经网络, 可塑性, 稳定性, RDBP

**Comment:** 11 pages, 50 figures

> **TL;DR:** RDBP是一种简单、低开销的持续学习基线，它结合了ReLUDown和递减反向传播，在保持模型可塑性和稳定性方面达到了或超过了最先进水平，同时降低了计算成本。

**AI_Comments:** RDBP的创新之处在于其通过结合两种简单而互补的机制，有效解决了持续学习中稳定性-可塑性困境，且实现了计算效率的提升。其作为“简单基线”的定位，有望为未来持续学习算法的研究提供一个强有力的参考点和比较标准，具有重要的实践和研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 计算机视觉中的持续学习要求模型在不遗忘先验知识的情况下适应连续的任务流，但现有方法往往严重偏向可塑性或稳定性，未能很好地平衡两者。

**Method:** 本文引入了RDBP（ReLUDown和递减反向传播），这是一个简单、低开销的基线。RDBP结合了两种互补机制：ReLUDown是一种轻量级的激活修改，它在防止神经元休眠的同时保留了特征敏感性；递减反向传播是一种受生物学启发的梯度调度方案，它逐步保护早期层免受灾难性更新的影响。

**Result:** 在Continual ImageNet基准测试中，RDBP在可塑性和稳定性方面与最先进的方法持平或超越，同时降低了计算成本。

**Conclusion:** RDBP为实际的持续学习提供了一个实用的解决方案，并为未来的持续学习策略提供了一个明确的基准。

> **ai_Abstract:** 本文提出了一种名为RDBP的持续学习基线，旨在解决现有方法在模型可塑性和稳定性之间平衡不佳的问题。RDBP通过结合轻量级激活修改ReLUDown和梯度调度方案递减反向传播，实现了在Continual ImageNet基准上与现有SOTA方法相当或更优的性能，同时降低了计算成本，为持续学习提供了一个实用且高效的解决方案。

> **摘要翻译:** 计算机视觉中的持续学习要求模型在不忘记先前知识的情况下适应连续的任务流，但现有方法往往严重偏向可塑性或稳定性。我们引入了RDBP，一个简单、低开销的基线，它结合了两种互补机制：ReLUDown，一种轻量级的激活修改，在防止神经元休眠的同时保留了特征敏感性；递减反向传播，一种受生物学启发的梯度调度方案，它逐步保护早期层免受灾难性更新的影响。在Continual ImageNet基准测试中，RDBP在可塑性和稳定性方面与最先进的方法持平或超越，同时降低了计算成本。因此，RDBP为实际的持续学习提供了一个实用的解决方案，并为未来的持续学习策略提供了一个明确的基准。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [757] [BMDetect: A Multimodal Deep Learning Framework for Comprehensive Biomedical Misconduct Detection](https://arxiv.org/abs/2505.05763)
> *BMDetect：一个用于全面生物医学不端行为检测的多模态深度学习框架*

*Yize Zhou, Jie Zhang, Meijie Wang, Lun Yu* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-15**

**Keywords:** 学术不端检测, 多模态深度学习, 生物医学研究, GPT-4o, BioMCD数据集

**Comment:** 

> **TL;DR:** BMDetect是一个多模态深度学习框架，它整合了期刊元数据、语义嵌入和GPT-4o挖掘的文本属性，以全面检测生物医学研究中的学术不端行为，并取得了显著的性能提升。

**AI_Comments:** BMDetect的创新之处在于其多模态融合方法，将传统元数据、语义信息和LLM提取的深层文本特征相结合，有效解决了现有检测方法的局限性。其定量评估特征重要性并识别关键预测因子的能力，增加了模型的可解释性。此外，BioMCD数据集的构建为该领域提供了重要的基准，将极大地推动未来的研究。该框架在性能上的提升和跨领域迁移性，使其在维护生物医学研究诚信方面具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 由于现有方法的算法狭隘性和分析流程的碎片化，生物医学研究中的学术不端行为检测仍然具有挑战性。

**Method:** BMDetect是一个多模态深度学习框架，它整合了期刊元数据（SJR、机构数据）、语义嵌入（PubMedBERT）和GPT-4o挖掘的文本属性（方法论统计、数据异常）进行手稿评估。主要创新包括：多模态融合领域特定特征以减少检测偏差；对特征重要性进行定量评估，识别期刊权威指标和文本异常作为主要预测因子；以及构建了BioMCD数据集，一个包含13,160篇撤回文章和53,411篇对照的大规模基准。

**Result:** BMDetect实现了74.33%的AUC，比单模态基线高出8.6%，并证明了在生物医学子领域的迁移性。

**Conclusion:** 这项工作推动了可扩展、可解释的工具，以维护研究诚信。

> **ai_Abstract:** BMDetect是一个创新的多模态深度学习框架，旨在解决生物医学研究中学术不端行为检测的挑战。它通过整合期刊元数据、语义嵌入和GPT-4o提取的文本属性，实现对稿件的全面评估。该框架的关键创新在于其多模态融合策略、对特征重要性的量化评估以及构建了大规模的BioMCD数据集。BMDetect在性能上显著优于单模态基线，并展现出良好的跨领域迁移能力，为维护研究诚信提供了可扩展且可解释的工具。

> **摘要翻译:** 生物医学研究中的学术不端行为检测仍然具有挑战性，原因在于现有方法的算法狭隘性和分析流程的碎片化。我们提出了BMDetect，一个多模态深度学习框架，它整合了期刊元数据（SJR、机构数据）、语义嵌入（PubMedBERT）和GPT-4o挖掘的文本属性（方法论统计、数据异常），用于全面的手稿评估。主要创新包括：(1) 领域特定特征的多模态融合以减少检测偏差；(2) 对特征重要性进行定量评估，识别期刊权威指标（例如SJR指数）和文本异常（例如统计异常值）作为主要预测因子；以及 (3) BioMCD数据集，一个包含13,160篇撤回文章和53,411篇对照的大规模基准。BMDetect实现了74.33%的AUC，比单模态基线高出8.6%，并证明了在生物医学子领域的迁移性。这项工作推动了可扩展、可解释的工具，以维护研究诚信。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [769] [Fast Last-Iterate Convergence of SGD in the Smooth Interpolation Regime](https://arxiv.org/abs/2507.11274)
> *SGD在平滑插值机制下的快速最终迭代收敛*

*Amit Attia, Matan Schliserman, Uri Sherman, Tomer Koren* | **Category: cs.LG, math.OC, stat.ML** | **Updated: 2025-07-15**

**Keywords:** 随机梯度下降, 插值机制, 最终迭代收敛, 平滑凸函数, 收敛速率

**Comment:** 27 pages

> **TL;DR:** 本文研究了在平滑凸目标函数插值机制下，随机梯度下降（SGD）最终迭代的收敛性，并建立了改进的收敛速率。

**AI_Comments:** 这项研究在理论上深化了对SGD在大步长和插值机制下收敛性的理解，这对于过参数化模型的训练至关重要。通过提供更紧密的最终迭代收敛界限，尤其是在零噪声条件下的改进速率，它为优化算法的分析和设计提供了宝贵的见解，具有重要的理论和潜在的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 在插值机制下，SGD最终迭代的行为（尤其是在大步长情况下）受到了越来越多的关注，这对于过参数化模型训练、持续学习中的遗忘分析以及随机Kaczmarz方法求解线性系统的收敛性具有重要意义。

**Method:** 研究了在平滑凸目标函数和插值机制下随机梯度下降（SGD）的总体收敛性保证，并建立了在特定步长和迭代次数下，最终迭代的预期超额风险表达式。

**Result:** 在$eta$-平滑凸损失函数上，经过$T$步SGD，步长$eta 
eq 1/eta$时，最终迭代的预期超额风险为$\\widetilde{O}(1/(\\eta T^{1-\\beta\\eta/2}) + \\eta T^{\\beta\\eta/2} \\sigma_\\star^2)$。对于良好调整的步长，获得接近最优的$\\widetilde{O}(1/T + \\sigma_\\star/\\sqrt{T})$速率。当$\\sigma_\\star=0$且$\\eta=1/\\beta$时，获得了$O(1/\\sqrt{T})$的速率，改进了现有最佳的$O(T^{-1/4})$速率。

**Conclusion:** 本文为SGD在平滑插值机制下的最终迭代收敛性提供了更强的理论保证，特别是在大步长和零噪声条件下获得了改进的收敛速率，扩展了现有结果。

> **ai_Abstract:** 本文深入研究了在平滑凸目标函数插值机制下，随机梯度下降（SGD）最终迭代的收敛特性。研究建立了SGD在特定步长和迭代次数下的预期超额风险界限，并证明了通过良好调整步长，可以实现接近最优的收敛速率。特别地，当最优处噪声为零时，本研究显著改进了现有文献中报告的最佳收敛速率，为理解和优化过参数化模型训练中的SGD行为提供了重要的理论基础。

> **摘要翻译:** 我们研究了随机梯度下降（SGD）在插值机制下平滑凸目标函数的总体收敛性保证，其中最优点的噪声为零或接近零。在这种设置下，SGD最终迭代的行为——特别是在大（常数）步长的情况下——近年来受到了越来越多的关注，因为它对过参数化模型的训练、持续学习中遗忘的分析以及理解随机Kaczmarz方法求解线性系统的收敛性都具有重要意义。我们确定，在$\\beta$-平滑凸损失函数上经过$T$步SGD，步长$\\eta \\leq 1/\\beta$后，最终迭代的预期超额风险为$\\widetilde{O}(1/(\\eta T^{1-\\beta\\eta/2}) + \\eta T^{\\beta\\eta/2} \\sigma_\\star^2)$，其中$\\sigma_\\star^2$表示最优处随机梯度的方差。特别是，对于一个良好调整的步长，我们获得了最终迭代的接近最优的$\\widetilde{O}(1/T + \\sigma_\\star/\\sqrt{T})$速率，将Varre等人（2021）的结果扩展到最小二乘回归之外；当$\\sigma_\\star=0$时，我们以$\\eta=1/\\beta$获得了$O(1/\\sqrt{T})$的速率，这改进了Evron等人（2025）在可实现线性回归特例中最近建立的最佳已知$O(T^{-1/4})$速率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [773] [DALI-PD: Diffusion-based Synthetic Layout Heatmap Generation for ML in Physical Design](https://arxiv.org/abs/2507.10606)
> *DALI-PD：基于扩散模型的物理设计中机器学习的合成布局热图生成*

*Bing-Yue Wu, Vidya A. Chhabria* | **Category: cs.LG, cs.AI, cs.AR** | **Updated: 2025-07-13**

**Keywords:** 物理设计, 机器学习, 扩散模型, 合成数据, 布局热图

**Comment:** Under review at Asia and South Pacific Design Automation Conference
  (ASP-DAC'26)

> **TL;DR:** DALI-PD是一个基于扩散模型的框架，用于快速生成合成布局热图，以解决物理设计中机器学习数据集不足的问题，并提高了ML任务的准确性。

**AI_Comments:** DALI-PD的创新之处在于利用扩散模型生成合成数据，有效解决了物理设计领域高质量ML数据集稀缺和生成成本高昂的痛点。其快速推理能力和生成热图的多样性是重要的突破，能够显著加速ML在PD中的应用和研究。通过提供大规模的合成数据集，它降低了ML模型训练的门槛，并有望提高模型在实际应用中的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习在物理设计（PD）任务中表现出巨大潜力，但其模型泛化能力受到高质量、大规模训练数据集可用性的限制。创建此类数据集计算成本高昂且受IP限制，现有公共数据集通常是静态的、生成缓慢且需要频繁更新。

**Method:** 我们提出了DALI-PD，一个可扩展的框架，使用扩散模型在几秒钟内通过快速推理生成多样化的合成布局热图。这些热图包括功耗、IR压降、拥塞、宏单元布局和单元密度图。我们使用DALI-PD创建了一个包含20,000多个不同宏单元数量和布局配置的布局数据集。

**Result:** 生成的合成热图与真实布局非常相似，并且显著提高了下游ML任务（如IR压降或拥塞预测）的ML准确性。

**Conclusion:** DALI-PD通过生成高质量的合成布局热图，有效解决了物理设计中机器学习数据集稀缺的问题，从而加速了PD研究并提升了ML模型的性能。

> **ai_Abstract:** DALI-PD是一个创新的可扩展框架，旨在解决物理设计（PD）领域中机器学习（ML）模型泛化能力受限于高成本和稀缺数据集的问题。它利用扩散模型，能够在几秒钟内快速生成多样化且高质量的合成布局热图，包括功耗、IR压降和拥塞等。通过DALI-PD生成的包含20,000多个布局配置的数据集，被证明与真实布局高度相似，并有效提高了下游ML任务（如IR压降或拥塞预测）的准确性，从而加速了PD中的ML研究。

> **摘要翻译:** 机器学习（ML）在各种物理设计（PD）任务中展现出巨大的前景。然而，模型泛化能力仍受限于高质量、大规模训练数据集的可用性。创建此类数据集通常计算成本高昂且受IP限制。尽管有极少数公共数据集可用，但它们通常是静态的、生成缓慢且需要频繁更新。为了解决这些局限性，我们提出了DALI-PD，一个可扩展的框架，用于生成合成布局热图，以加速PD研究中的ML应用。DALI-PD使用扩散模型，通过快速推理在几秒钟内生成多样化的布局热图。这些热图包括功耗、IR压降、拥塞、宏单元布局和单元密度图。使用DALI-PD，我们创建了一个包含20,000多个具有不同宏单元数量和布局配置的布局数据集。这些热图与真实布局非常相似，并提高了下游ML任务（如IR压降或拥塞预测）的ML准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [778] [FeDa4Fair: Client-Level Federated Datasets for Fairness Evaluation](https://arxiv.org/abs/2506.21095)
> *FeDa4Fair: 客户端级联邦数据集用于公平性评估*

*Xenia Heilmann, Luca Corbucci, Mattia Cerrato, Anna Monreale* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 联邦学习, 公平性, 数据集, 异构性, 基准测试

**Comment:** 

> **TL;DR:** 该论文介绍了FeDa4Fair，一个用于生成和评估联邦学习中客户端级公平性的库和数据集，以解决现有公平性研究在处理异构偏差和多样化客户端需求方面的局限性。

**AI_Comments:** 该论文的创新点在于其关注联邦学习中的客户端级公平性，并明确处理异构客户端偏差。通过提供FeDa4Fair库、专门的数据集和评估函数，它为联邦学习公平性研究提供了一个急需的标准化和可复现的基准测试框架，填补了现有研究的空白，即现有方法通常只关注单一或二元敏感属性。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习中存在公平性问题，因为客户端本地数据集的偏差会影响整个系统，且数据异构性可能导致模型对不同客户端的公平性不一。现有解决方案大多只关注单一敏感属性，忽略了客户端多样化甚至冲突的公平性需求，这限制了公平性干预的有效性。因此，需要支持更健壮和可复现的联邦学习公平性研究，并在全局和客户端层面实现公平性感知型联邦学习方法的一致基准测试。

**Method:** 该论文贡献了三个方面：1. 引入了FeDa4Fair，一个用于生成表格数据集的库，专门用于评估异构客户端偏差下的公平联邦学习方法。2. 发布了四个具有异构偏差的数据集和相应的基准，以便在受控环境中比较公平性缓解方法。3. 提供了现成的函数来评估这些数据集的公平性结果。

**Result:** 该研究提供了FeDa4Fair库、四个具有异构偏差的数据集及其基准，以及用于评估这些数据集公平性结果的现成函数，旨在支持联邦学习中更健壮和可复现的公平性研究。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 该论文提出了FeDa4Fair，一个旨在解决联邦学习（FL）中公平性挑战的库。针对现有FL公平性研究未能充分处理客户端数据异构性和多样化公平性需求的问题，FeDa4Fair提供了一个生成表格数据集的工具，专门用于评估异构客户端偏差下的公平FL方法。此外，该工作还发布了四个具有偏斜异构性的数据集及其基准，并提供了现成的评估函数，以支持FL公平性方法的健壮和可复现的基准测试。

> **摘要翻译:** 联邦学习（FL）支持在不共享客户端私有数据的情况下进行协作模型训练。然而，公平性仍然是一个关键问题，因为本地客户端数据集中存在的偏差会影响整个联邦系统。客户端之间异构的数据分布可能导致模型对某些客户端比其他客户端更公平。尽管文献中存在一些增强公平性的解决方案，但大多数都专注于缓解单一敏感属性（通常是二元的）的偏差，而忽略了不同客户端多样化甚至相互冲突的公平性需求。这种有限的视角可能会限制公平性干预对不同客户端的有效性。为了支持联邦学习中更健壮和可复现的公平性研究，我们旨在实现全局和客户端层面公平性感知型联邦学习方法的一致基准测试。在本文中，我们通过三种方式做出了贡献：(1) 我们引入了FeDa4Fair，一个用于生成表格数据集的库，专门用于评估异构客户端偏差下的公平联邦学习方法；(2) 我们发布了四个具有异构偏差的数据集和相应的基准，以便在受控环境中比较公平性缓解方法；(3) 我们提供了现成的函数来评估这些数据集的公平性结果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [785] [On the Similarities of Embeddings in Contrastive Learning](https://arxiv.org/abs/2506.09781)
> *对比学习中嵌入的相似性研究*

*Chungpa Lee, Sehee Lim, Kibok Lee, Jy-yong Sohn* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-15**

**Keywords:** 对比学习, 嵌入相似性, 余弦相似度, 批量大小, 辅助损失

**Comment:** contrastive learning, representation learning, embedding, similarity,
  negative pair, positive pair

> **TL;DR:** 本文通过余弦相似度提出一个统一框架来理解对比学习，并提供两个理论见解：全批量设置下正对完美对齐的限制及解决办法，以及小批量设置下负对分离度高导致表示质量下降的缓解策略。

**AI_Comments:** 本文通过引入一个统一的理论框架，深入分析了对比学习中嵌入相似性的性质，尤其是在不同批量设置下的表现，具有重要的理论和实践意义。提出的解决方案针对性强，有助于优化对比学习在实际应用中的效果，特别是对资源受限的小批量训练场景。

<details>
  <summary>Details</summary>

**Motivation:** 理解对比学习中嵌入相似性的机制，并解决全批量和迷你批量设置下存在的对齐和表示质量问题。

**Method:** 提出一个基于余弦相似度的统一框架来理解对比学习。基于此框架，推导出两个理论见解：1. 全批量设置下正对完美对齐的限制，以及通过引入视图内负对来缓解。2. 迷你批量设置下小批量大小导致负对分离度增加，影响表示质量，并通过提出一个辅助损失来降低负对相似度的方差。

**Result:** 1. 在全批量设置下，当负对相似度低于某个阈值时，正对的完美对齐是无法实现的，但可以通过在目标函数中加入视图内负对来缓解这种不对齐。2. 在迷你批量设置下，较小的批量大小会导致嵌入空间中负对之间更强的分离（即相似度方差更高），从而降低学习表示的质量。3. 引入所提出的辅助损失可以改善小批量设置下的性能。

**Conclusion:** 本文通过余弦相似度统一框架分析了对比学习中嵌入相似性的行为，揭示了全批量和迷你批量设置下的挑战，并提出了有效的解决方案来提高表示质量。

> **ai_Abstract:** 本文提出了一个基于余弦相似度的统一框架，用于深入理解对比学习中嵌入的相似性行为。研究揭示了两个关键理论见解：在全批量设置下，当负对相似度过低时，正对的完美对齐难以实现，可通过引入视图内负对缓解；在迷你批量设置下，小批量大小会增加负对相似度的方差，从而损害表示质量。为解决后者，作者提出了一种辅助损失，实验证明其能有效提升小批量设置下的性能。

> **摘要翻译:** 对比学习基于一个简单而有效的原则：将正对的嵌入拉近，同时将负对的嵌入推开。在本文中，我们提出了一个通过余弦相似性理解对比学习的统一框架，并从该框架中得出了两个关键的理论见解。首先，在全批量设置中，我们表明当负对相似性低于某个阈值时，正对的完美对齐是无法实现的，并且这种不对齐可以通过将视图内负对纳入目标函数来缓解。其次，在迷你批量设置中，较小的批量大小会导致嵌入空间中负对之间更强的分离，即它们的相似性方差更高，这反过来又会降低与全批量设置相比学习表示的质量。为了解决这个问题，我们提出了一种辅助损失，以减少迷你批量设置中负对相似度的方差。实证结果表明，纳入所提出的损失可以提高小批量设置下的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [788] [Representation Bending for Large Language Model Safety](https://arxiv.org/abs/2504.01550)
> *大语言模型安全中的表征弯曲*

*Ashkan Yousefpour, Taeheon Kim, Ryan S. Kwon, Seungbeen Lee, Wonje Jeung, Seungju Han, Alvin Wan, Harrison Ngan, Youngjae Yu, Jonghyun Choi* | **Category: cs.LG, cs.CL, cs.CR** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型安全, 表征弯曲, 激活转向, 对抗性攻击, 微调

**Comment:** Accepted to ACL 2025 (main)

> **TL;DR:** RepBend是一种新颖的方法，通过在推理过程中对有害行为的表征进行根本性扰动，显著提高了大型语言模型的安全性，并优于现有方法。

**AI_Comments:** RepBend的创新之处在于其“表征弯曲”的理念，即通过改变模型内部的表征来从根本上解决有害行为，而不是仅仅依赖于表面的防御。它将激活转向与微调相结合，提供了一种可扩展且通用的安全增强方案，有效解决了现有方法在泛化性和鲁棒性方面的不足。其在降低攻击成功率方面的显著效果和对模型可用性的低影响显示了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）存在固有的安全风险，包括生成有害内容和更广泛的社会危害。这些风险因对抗性攻击、微调漏洞以及在高风险环境中部署LLM而加剧。现有的安全增强技术（如基于人工反馈的微调或对抗性训练）仍然脆弱，因为它们通常无法泛化到未见的攻击，或需要手动系统级防御，因此需要一种更通用和可扩展的解决方案。

**Method:** 本文引入了RepBend，一种新颖的方法，旨在从根本上扰乱LLM中有害行为的底层表征。它将激活转向（activation steering，即用于在推理过程中引导模型行为的简单向量算术）的思想引入到基于损失的微调中，以实现对有害行为表征的“弯曲”。

**Result:** RepBend实现了最先进的性能，在各种越狱基准测试中，攻击成功率降低高达95%，且对模型可用性和通用能力的影响可忽略不计。它超越了Circuit Breaker、RMU和NPO等现有方法。

**Conclusion:** RepBend提供了一种可扩展的解决方案，能够从根本上增强大型语言模型（潜在的固有）安全性，有效应对日益增长的安全挑战，并显著优于现有技术。

> **ai_Abstract:** 本文提出了一种名为RepBend的新颖方法，旨在从根本上扰乱大型语言模型（LLMs）中有害行为的表征，以解决LLMs固有的安全风险和现有安全方法的局限性。RepBend将激活转向的概念应用于基于损失的微调，并通过广泛评估证明其在降低攻击成功率方面达到了最先进的性能，同时保持了模型的可用性和通用能力。

> **摘要翻译:** 大型语言模型（LLMs）已成为强大的工具，但其固有的安全风险——从有害内容生成到更广泛的社会危害——带来了重大挑战。这些风险可能因最近的对抗性攻击、微调漏洞以及LLM在高风险环境中的日益部署而加剧。现有增强安全性的技术，如通过人工反馈进行微调或对抗性训练，仍然脆弱，因为它们解决了特定的威胁，并且通常无法泛化到未见的攻击，或者需要手动系统级防御。本文引入了RepBend，一种新颖的方法，它从根本上扰乱了LLM中有害行为的底层表征，提供了一种可扩展的解决方案来增强（潜在的固有）安全性。RepBend将激活转向——用于在推理过程中引导模型行为的简单向量算术——的思想引入到基于损失的微调中。通过广泛的评估，RepBend实现了最先进的性能，超越了Circuit Breaker、RMU和NPO等先前方法，在各种越狱基准测试中将攻击成功率降低高达95%，所有这些都对模型可用性和通用能力造成了可忽略不计的降低。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [796] [How to Protect Models against Adversarial Unlearning?](https://arxiv.org/abs/2507.10886)
> *如何保护模型免受对抗性遗忘？*

*Patryk Jasiorski, Marek Klonowski, Michał Woźniak* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 对抗性遗忘, 模型保护, 机器学习遗忘, 模型性能, 隐私保护AI

**Comment:** 

> **TL;DR:** 论文提出了一种新方法，旨在保护AI模型性能，使其免受恶意对抗性遗忘请求或自发遗忘过程导致的性能下降影响。

**AI_Comments:** 这篇论文解决了AI模型在满足法规要求或内容管理时进行知识遗忘所面临的一个关键挑战，即如何抵御恶意攻击导致性能下降。其创新之处在于提出了一种保护模型性能的新方法，这对于AI模型的安全性和鲁棒性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** AI模型需要遗忘知识以符合法规要求、移除有害内容、去偏见等。然而，知识遗忘可能导致模型性能下降。本文研究了对抗性遗忘问题，即恶意方通过遗忘请求最大程度地损害模型性能。

**Method:** 论文提出了一种新的方法来保护模型性能，使其免受对抗性遗忘和自发遗忘过程引起的副作用影响。

**Result:** 研究表明，对抗性遗忘现象和攻击者的能力取决于多种因素，主要是骨干模型本身以及选择遗忘数据的策略/限制。主要结果是提出了一种新方法，可以保护模型性能免受自发过程和对抗行为导致的遗忘副作用影响。

**Conclusion:** 论文成功提出了一种新方法，能够有效保护模型性能，防止其因对抗性遗忘或自发遗忘过程而下降。

> **ai_Abstract:** 本文探讨了AI模型遗忘知识时可能面临的性能下降问题，特别是恶意方通过对抗性遗忘请求故意损害模型性能的情况。研究发现，对抗性遗忘的有效性受模型架构和数据选择策略影响。为解决此问题，论文提出了一种新方法，旨在保护模型性能免受由自发遗忘过程和对抗性攻击引起的负面影响。

> **摘要翻译:** 人工智能模型需要被遗忘以满足《人工智能法案》或GDPR等法律法规的要求，也因为需要删除有害内容、去偏见、消除恶意实例的影响或应对模型工作数据分布结构的变化。不幸的是，移除知识可能会导致不良副作用，例如模型性能下降。在本文中，我们研究了对抗性遗忘问题，即恶意方有意发送遗忘请求以最大程度地损害模型性能。我们表明，这种现象和对手的能力取决于许多因素，主要取决于骨干模型本身以及选择要遗忘数据的策略/限制。这项工作的主要成果是一种保护模型性能免受这些副作用影响的新方法，无论是在自发过程还是对抗行为导致的遗忘行为中。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [800] [MH-FSF: A Unified Framework for Overcoming Benchmarking and Reproducibility Limitations in Feature Selection Evaluation](https://arxiv.org/abs/2507.10591)
> *MH-FSF：一个统一的框架，用于克服特征选择评估中的基准测试和可复现性限制*

*Vanderson Rocha, Diego Kreutz, Gabriel Canto, Hendrio Bragança, Eduardo Feitosa* | **Category: cs.LG, cs.AI, cs.CR, cs.PF, 68T01, I.2** | **Updated: 2025-07-11**

**Keywords:** 特征选择, 可复现性, 基准测试, Android恶意软件, 统一框架

**Comment:** 11 pages; 4 figures; 5 tables; submitted to JBCS

> **TL;DR:** MH-FSF是一个统一的框架，旨在解决特征选择评估中基准测试和可复现性不足的问题，提供17种方法和在10个公开数据集上的系统评估。

**AI_Comments:** MH-FSF框架通过提供一个统一、模块化且可扩展的平台，显著提升了特征选择研究的可复现性和基准测试能力。其集成了多种经典和领域特定方法，并利用公开数据集进行评估，这对于推动该领域的严谨性和一致性具有重要意义。特别是在Android恶意软件检测这一特定领域，该框架有望开启新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前的特征选择研究存在基准测试不足和依赖专有数据集的问题，这严重阻碍了可复现性并可能对整体性能产生负面影响。

**Method:** 本文介绍了MH-FSF框架，这是一个全面、模块化、可扩展的平台，旨在促进特征选择方法的复现和实现。MH-FSF提供了17种方法（11种经典、6种领域特定）的实现，并支持在10个公开可用的Android恶意软件数据集上进行系统评估。

**Result:** 结果显示在平衡和不平衡数据集上都存在性能差异，这强调了数据预处理和选择标准需要考虑这些不对称性的重要性。此外，结果表明统一平台对于比较不同特征选择技术的重要性。

**Conclusion:** MH-FSF框架旨在显著拓宽现有文献，并为特征选择领域（特别是在Android恶意软件检测背景下）的新研究方向铺平道路。

> **ai_Abstract:** 本文提出了MH-FSF框架，一个统一且可扩展的平台，旨在解决特征选择研究中基准测试和可复现性不足的问题。该框架集成了17种特征选择方法，并在10个公开的Android恶意软件数据集上进行了系统评估。研究发现，在不同数据集上性能存在差异，强调了数据预处理和考虑数据不对称性的选择标准的重要性。MH-FSF旨在促进特征选择方法的一致性比较，并为未来的研究提供基础，尤其是在Android恶意软件检测领域。

> **摘要翻译:** 特征选择对于构建有效的预测模型至关重要，因为它能降低维度并突出关键特征。然而，当前研究常受限于基准测试不足和对专有数据集的依赖。这严重阻碍了可复现性，并可能对整体性能产生负面影响。为解决这些限制，我们引入了MH-FSF框架，这是一个全面、模块化、可扩展的平台，旨在促进特征选择方法的复现和实现。MH-FSF通过合作研究开发，提供了17种方法（11种经典、6种领域特定）的实现，并支持在10个公开可用的Android恶意软件数据集上进行系统评估。我们的结果揭示了在平衡和不平衡数据集上的性能差异，突出了数据预处理和选择标准需要考虑这些不对称性的关键需求。我们证明了统一平台对于比较不同特征选择技术的重要性，这有助于提高方法论的一致性和严谨性。通过提供这个框架，我们旨在显著拓宽现有文献，并为特征选择领域（特别是在Android恶意软件检测背景下）的新研究方向铺平道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [804] [Local Pairwise Distance Matching for Backpropagation-Free Reinforcement Learning](https://arxiv.org/abs/2507.11367)
> *用于无反向传播强化学习的局部成对距离匹配*

*Daniel Tanneberg* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-07-15**

**Keywords:** 强化学习, 无反向传播, 局部训练, 成对距离匹配, 神经网络

**Comment:** accepted at the European Conference on Artificial Intelligence (ECAI
  2025)

> **TL;DR:** 该论文提出了一种无需反向传播的强化学习新方法，通过在正向传播过程中使用局部信号和成对距离匹配来训练神经网络层，从而避免了梯度问题和激活存储，并在RL基准测试中取得了与传统方法相当甚至更优的性能。

**AI_Comments:** 该论文的创新点在于提出了一个完全无需反向传播的神经网络训练范式，这在强化学习领域具有重要意义。通过局部信号和成对距离匹配，该方法规避了传统BP的内存和梯度问题，提升了训练的稳定性和效率。这种去中心化的训练方式为未来大型模型的训练提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统的强化学习（RL）神经网络训练依赖反向传播（BP），这需要存储正向传播的激活值以进行后续反向更新，并且多层反向传播误差信号常导致梯度消失或爆炸问题，从而影响学习性能和稳定性。

**Method:** 本研究提出了一种新颖的方法，在强化学习环境中，通过在正向传播过程中利用局部信号来训练神经网络的每一层。该方法引入了局部的、分层的损失函数，利用多维尺度分析中的成对距离匹配原则，并可选择性地辅以奖励驱动的指导。这种方法使得每个隐藏层都可以使用在正向传播期间计算的局部信号进行训练，从而无需反向传播和存储中间激活值。

**Result:** 在常见的强化学习基准测试中，通过策略梯度方法进行的实验表明，这种无反向传播的方法与经典的基于反向传播的方法相比，性能具有竞争力。此外，所提出的方法在运行内部和跨运行中增强了稳定性和一致性，并且在特别具有挑战性的环境中提高了性能。

**Conclusion:** 该研究成功提出并验证了一种无需反向传播的强化学习训练方法，该方法通过局部信号和成对距离匹配实现了竞争力、更高的稳定性和在复杂环境中的性能提升，有效解决了传统反向传播的局限性。

> **ai_Abstract:** 本论文提出了一种名为“局部成对距离匹配”的无反向传播强化学习训练方法，旨在解决传统反向传播中激活存储需求高和梯度消失/爆炸的问题。该方法通过在正向传播过程中为神经网络的每一层计算局部、分层的损失，利用成对距离匹配原理，并可结合奖励指导。实验表明，该方法在RL基准测试中表现出与传统BP方法相当的竞争力，并显著提升了学习的稳定性、一致性，尤其在复杂环境中性能更优。

> **摘要翻译:** 用反向传播（BP）训练强化学习（RL）中的神经网络通常需要存储正向传播的激活值以进行后续的反向更新。此外，误差信号通过多层反向传播常常导致梯度消失或爆炸，这会降低学习性能和稳定性。我们提出了一种新颖的方法，该方法在RL设置中利用正向传播过程中的局部信号来训练神经网络的每一层。我们的方法引入了局部的、分层的损失函数，利用多维尺度分析中成对距离匹配的原理，并可选择性地辅以奖励驱动的指导。这种方法使得每个隐藏层都可以使用在正向传播期间计算的局部信号进行训练，从而无需反向传播和存储中间激活值。我们在常见的RL基准测试中，通过策略梯度方法进行的实验表明，这种无反向传播的方法与经典的基于BP的方法相比，性能具有竞争力。此外，所提出的方法在运行内部和跨运行中增强了稳定性和一致性，尤其在具有挑战性的环境中提高了性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [811] [Guiding LLM Decision-Making with Fairness Reward Models](https://arxiv.org/abs/2507.11344)
> *用公平奖励模型引导大型语言模型决策*

*Zara Hall, Melanie Subbiah, Thomas P Zollo, Kathleen McKeown, Richard Zemel* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 公平奖励模型, 大型语言模型, 决策公平性, 偏见缓解, 高风险决策

**Comment:** 

> **TL;DR:** 提出一种公平奖励模型 (FRM)，用于指导大型语言模型在高风险决策中减少偏见并提高公平性，同时保持或超越准确性。

**AI_Comments:** 这篇论文的创新点在于提出了一个可泛化的公平奖励模型，利用弱监督和LLM自标注数据来识别和纠正LLM推理中的偏见。其重要性在于，它为大型语言模型在高风险决策场景中的可信赖应用提供了有效途径，解决了公平性这一关键挑战，并且其跨任务、领域和模型家族的泛化能力预示了其广泛的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）正越来越多地用于高风险决策，但传统的思维链采样方法在提高决策准确性的同时，也会放大不公平偏见，因此需要一种方法来确保LLM决策的公平性和可信赖性。

**Method:** 提出一个可泛化的公平奖励模型（FRM）训练框架。该模型通过对LLM的推理过程分配公平分数，从而在聚合决策时能够降低有偏见的推理路径的权重，并偏向公平的路径。FRM通过弱监督、由LLM标注的偏见与无偏见推理示例进行训练。

**Result:** 该单一的公平奖励模型无需额外微调，即可跨任务、领域和模型家族进行迁移。在累犯预测和社交媒体审核等真实世界决策任务中，该方法持续提高公平性，同时匹配或超越基线准确性。

**Conclusion:** 论文成功开发并验证了一个可泛化的公平奖励模型，有效解决了大型语言模型在高风险决策中存在的偏见问题，显著提升了公平性，同时保持了高准确性，从而促进了推理模型在关键决策中的可信赖应用。

> **ai_Abstract:** 本文提出了一种名为公平奖励模型（FRM）的新框架，旨在解决大型语言模型（LLMs）在高风险决策中可能放大的不公平偏见问题。FRM通过为LLM的推理过程分配公平分数，从而在聚合决策时能识别并降低偏见路径的权重，转而支持更公平的路径。该模型采用弱监督和LLM标注的示例进行训练，并展示了其在无需额外微调的情况下，能跨任务、领域和模型家族进行泛化的能力。在累犯预测和社交媒体审核等实际应用中，FRM显著提升了决策的公平性，同时保持或超越了原有的准确性。

> **摘要翻译:** 大型语言模型正越来越多地用于支持高风险决策，可能影响到谁能获得保释或贷款。天真的思维链采样可以提高平均决策准确性，但也被证明会放大不公平偏见。为了解决这一挑战并实现在高风险决策中可靠地使用推理模型，我们提出了一个训练可泛化公平奖励模型（FRM）的框架。我们的模型为大型语言模型（LLM）的推理分配公平分数，使系统在聚合跨推理链的决策时能够降低有偏见轨迹的权重，并偏向公平的轨迹。我们表明，一个单一的公平奖励模型，通过弱监督、由LLM标注的偏见与无偏见推理示例进行训练，无需额外微调即可跨任务、领域和模型家族进行迁移。应用于累犯预测和社交媒体审核等真实世界决策任务时，我们表明我们的方法持续提高公平性，同时匹配甚至超越基线准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [813] [Exploring and Improving Initialization for Deep Graph Neural Networks: A Signal Propagation Perspective](https://arxiv.org/abs/2506.16790)
> *探索和改进深度图神经网络的初始化：一个信号传播视角*

*Senmiao Wang, Yupeng Chen, Yushun Zhang, Ruoyu Sun, Tian Ding* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 深度GNN, 初始化, 信号传播, 图神经网络, SPoGInit

**Comment:** Published in TMLR (2025)

> **TL;DR:** 深度图神经网络（GNNs）在增加深度时性能会下降。本文提出了一种基于信号传播（SP）分析的初始化方法SPoGInit，通过优化权重初始化方差来增强信号传播，从而显著提升了深度GNN的性能。

**AI_Comments:** 本文通过从信号传播的角度重新审视深度GNN的初始化问题，提供了一个新颖且具有理论支撑的解决方案。引入图嵌入变异（GEV）作为GNN特有的信号传播指标，体现了其创新性。SPoGInit方法不仅在理论上解决了现有初始化方法的局限性，而且通过实验证明了其在实际应用中的优越性，对推动深度GNN的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNNs）的性能会随着网络深度的增加而下降。本文旨在通过引入新的初始化方法来解决这个问题，以增强GNN内部的信号传播。

**Method:** 本文提出了三种用于GNN中有效信号传播的关键指标：前向传播、后向传播和图嵌入变异（GEV）。理论上证明了现有广泛使用的GNN初始化方法未能同时控制这三个指标。为解决此限制，本文通过直接利用信号传播分析，搜索优化这三个指标的权重初始化方差，提出了一种名为“基于图引导初始化的信号传播”（SPoGInit）的方法。

**Result:** 实验表明，SPoGInit在各种任务和架构上均优于常用的初始化方法。值得注意的是，SPoGInit使GNN在加深时性能得以提升。

**Conclusion:** SPoGInit是解决GNN深度相关挑战的重大进展，并且凸显了信号传播分析框架的有效性和实用性。

> **ai_Abstract:** 针对图神经网络（GNNs）深度增加导致性能下降的问题，本文提出了一种名为SPoGInit的初始化方法。该方法基于信号传播（SP）分析，引入了前向传播、后向传播和图嵌入变异（GEV）三个关键指标来衡量SP。研究发现现有初始化方法无法同时控制这些指标，因此SPoGInit通过优化权重初始化方差来增强深度GNN中的信号传播。实验证明，SPoGInit在多种任务和架构上均表现出色，并能使GNN在加深时性能得到提升，从而有效解决了深度GNN的性能瓶颈。

> **摘要翻译:** 图神经网络（GNNs）在网络深度增加时常常会遇到性能下降的问题。本文通过引入增强GNN内部信号传播（SP）的初始化方法来解决这个问题。我们提出了GNN中有效SP的三个关键指标：前向传播、后向传播和图嵌入变异（GEV）。前两个指标源自经典SP理论，而第三个指标是专门为GNN设计的。我们从理论上证明，广泛使用的GNN初始化方法在深度增加时表现出性能下降，未能同时控制这三个指标。为了解决这一限制，本文展示了直接利用SP分析——寻找优化这三个指标的权重初始化方差——可以显著增强深度GCN中的SP。这种方法被称为“基于图引导初始化的信号传播”（SPoGInit）。我们的实验表明，SPoGInit在各种任务和架构上均优于常用的初始化方法。值得注意的是，SPoGInit使GNN在加深时性能得以提升，这代表着在解决深度相关挑战方面取得了重大进展，并突出了SP分析框架的有效性和实用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [386] [Simulation for All: A Step-by-Step Cookbook for Developing Human-Centered Multi-Agent Transportation Simulators](https://arxiv.org/abs/2507.09367)
> *全民模拟：开发以人为中心的多智能体交通模拟器的分步指南*

*Shiva Azimi, Arash Tavakoli* | **Category: cs.MA** | **Updated: 2025-07-15**

**Keywords:** 多智能体模拟, 交通模拟, 以人为中心, 沉浸式环境, 数据采集

**Comment:** 

> **TL;DR:** 本文提出了一个以人为中心的多智能体交通模拟平台，旨在支持对所有道路使用者进行实时、沉浸式研究，并提供开源脚本，以降低高保真交通模拟的门槛。

**AI_Comments:** 本文的创新之处在于其以人为中心的设计理念，以及对所有道路使用者（包括公共交通用户）的全面覆盖。该平台不仅提供了高保真沉浸式体验，还集成了多种生理和神经数据采集设备，这对于深入理解人类在复杂交通环境中的行为和认知至关重要。开源脚本的提供进一步增强了其可用性和影响力，有望显著降低高保真交通模拟的门槛，促进跨学科研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有交通模拟平台普遍存在局限性，如分离不同类型道路使用者、依赖预设行为、忽视公共交通用户以及对非技术用户不友好。为了弥补这一空白，本文旨在开发一个支持所有道路使用者的人性化多智能体模拟工具。

**Method:** 本文提出了一个多智能体模拟平台，旨在支持所有道路使用者进行实时、以人为中心和沉浸式研究。该平台使用高保真沉浸式虚拟环境，实现公共交通用户、行人、骑车人、自动驾驶车辆和驾驶员之间的交互。其架构模块化、可扩展且易于访问，并集成了全向跑步机、座椅、智能训练器和驱动式驾驶舱等硬件模块。此外，平台通过fNIRS、眼动追踪和腕戴式生物传感器等嵌入式传感设备收集多模式生理、神经和行为数据。

**Result:** 该平台能够实现公共交通用户、行人、骑车人、自动驾驶车辆和驾驶员之间的交互，并能收集多模式生理、神经和行为数据。论文通过三个用例展示了系统的可用性。该系统旨在降低高保真交通模拟的门槛，支持跨学科实验，并增进对复杂城市环境中多模式出行的理解。

**Conclusion:** 该模拟平台旨在降低高保真交通模拟的门槛，支持跨学科实验，并推进对复杂城市环境中多模式出行的理解。

> **ai_Abstract:** 本文提出了一种名为“全民模拟”的以人为中心的多智能体交通模拟平台，旨在解决现有平台在用户类型分离、行为预设及非技术用户可访问性方面的局限性。该平台利用高保真沉浸式虚拟环境，支持所有道路使用者（包括公共交通用户、行人、骑车人、自动驾驶车辆和驾驶员）之间的实时交互研究。其模块化、可扩展的架构集成了多种硬件设备和嵌入式传感器，可收集生理、神经和行为数据。论文通过用例展示了其可用性，旨在降低高保真交通模拟的门槛，促进跨学科研究，并深化对复杂城市多模式出行的理解。

> **摘要翻译:** 随着城市向更复杂、多模式的交通系统发展，对以人为中心的多智能体模拟工具的需求从未如此紧迫。然而，大多数现有平台仍然受限——它们通常将不同类型的道路使用者分开，依赖脚本或预定义行为，忽视公共交通用户作为积极参与者，并且很少考虑到非技术用户的可访问性。为了弥补这一空白，本文提出了一个多智能体模拟平台的规范，该平台旨在支持所有道路使用者进行实时、以人为中心和沉浸式研究，并附带开源脚本以供复现。我们的平台利用高保真沉浸式虚拟环境，实现了公共交通用户、行人、骑车人、自动驾驶车辆和驾驶员之间的交互。该架构是模块化、可扩展且易于访问的。该系统集成了特定硬件模块——包括一个全向跑步机、一个座椅装置、一个智能训练器和一个驱动式驾驶舱。此外，该平台通过嵌入式传感设备（如功能性近红外光谱（fNIRS）、眼动追踪和腕戴式生物传感器）收集多模式生理、神经和行为数据。为了展示该系统的可用性，我们提出了三个用例。“全民模拟”旨在降低高保真交通模拟的入门门槛，支持跨学科实验，并增进我们对复杂城市环境中多模式出行的理解。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [604] [A Learning Framework For Cooperative Collision Avoidance of UAV Swarms Leveraging Domain Knowledge](https://arxiv.org/abs/2507.10913)
> *无人机群协同避碰的域知识驱动学习框架*

*Shuangyao Huang, Haibo Zhang, Zhiyi Huang* | **Category: cs.MA, cs.LG, cs.RO** | **Updated: 2025-07-15**

**Keywords:** 无人机群, 协同避碰, 多智能体强化学习, 域知识, 等高线

**Comment:** Under review at AAAI 2026

> **TL;DR:** 本文提出了一种利用图像处理域知识驱动奖励的多智能体强化学习框架，用于无人机群的协同避碰，该框架能有效处理大规模蜂群并适应复杂环境。

**AI_Comments:** 该论文的创新点在于将图像处理领域的域知识（等高线概念）巧妙地融入到多智能体强化学习的奖励设计中，解决了无人机群大规模协同避碰的挑战。这种方法通过减少智能体间的交互，有效规避了传统MARL在扩展性上的难题，具有重要的实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 解决无人机群协同避碰问题，尤其是现有MARL方法在处理大规模蜂群时面临的复杂信用分配和观察共享机制问题。

**Method:** 提出了一种多智能体强化学习（MARL）框架，利用域知识驱动的奖励。奖励来源于图像处理领域的知识，通过在二维场上近似等高线来避免碰撞，将障碍物建模为场上的最大值，从而使等高线不会穿过峰值或相交。该方法最小化了智能体之间的交互。

**Result:** 该框架能够训练大规模蜂群，因为智能体交互被最小化，消除了对复杂信用分配方案或观察共享机制的需求。无人机获得了适应等高线可能不可行或不存在的复杂环境的能力。实验证明其性能优于现有MARL算法。

**Conclusion:** 提出的基于域知识驱动奖励的MARL框架能有效解决无人机群的协同避碰问题，尤其适用于大规模蜂群和复杂环境，并且性能优越。

> **ai_Abstract:** 本文提出了一种新颖的多智能体强化学习（MARL）框架，用于无人机群的协同避碰。该框架的核心在于利用图像处理领域的域知识来设计奖励函数，通过将障碍物建模为二维场上的最大值，并利用等高线来确保避碰。这种方法显著减少了智能体间的交互，从而支持大规模无人机群的训练，并避免了传统MARL中复杂的信用分配和观察共享问题。实验结果表明，该框架不仅能使无人机适应复杂环境，其性能也优于现有的先进MARL算法。

> **摘要翻译:** 本文提出了一种多智能体强化学习（MARL）框架，用于无人机群的协同避碰，该框架利用域知识驱动的奖励。奖励来源于图像处理领域的知识，通过在二维场上近似等高线。通过将障碍物建模为场上的最大值，碰撞得以固有地避免，因为等高线永远不会穿过峰值或相交。此外，等高线平滑且节能。我们的框架能够训练大规模蜂群，因为智能体交互被最小化，并且消除了现有MARL方法中对复杂信用分配方案或观察共享机制的需求。此外，通过密集训练，无人机获得了适应等高线可能不可行或不存在的复杂环境的能力。进行了广泛的实验来评估我们框架与现有MARL算法的性能。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [723] [DroidSpeak: KV Cache Sharing for Cross-LLM Communication and Multi-LLM Serving](https://arxiv.org/abs/2411.02820)
> *DroidSpeak：用于跨大型语言模型通信和多大型语言模型服务的KV缓存共享*

*Yuhan Liu, Yuyang Huang, Jiayi Yao, Shaoting Feng, Zhuohan Gu, Kuntai Du, Hanchen Li, Yihua Cheng, Junchen Jiang, Shan Lu, Madan Musuvathi, Esha Choukse* | **Category: cs.MA, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-14**

**Keywords:** KV缓存共享, 大型语言模型, 分布式推理, DroidSpeak, 吞吐量优化

**Comment:** 

> **TL;DR:** DroidSpeak是一个分布式LLM推理系统，它允许在运行不同LLM的分布式节点之间重用KV缓存，条件是这些LLM具有相同的架构，从而显著提高吞吐量和预填充速度，且质量损失可忽略不计。

**AI_Comments:** DroidSpeak的创新点在于首次提出了跨不同LLM共享KV缓存的解决方案，这对于日益复杂的复合AI系统至关重要。其方法通过选择性重计算和管道化处理，有效平衡了性能提升与质量保持。这项工作对于优化多LLM部署的资源利用率和推理效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型AI系统（如代理系统）中，多个LLM协同工作，它们经常处理共享相同上下文前缀的输入。尽管已有工作实现单个模型内部KV缓存的重用，但如何实现不同模型之间KV缓存的重用仍是一个开放问题。

**Method:** 本研究提出了DroidSpeak，这是第一个分布式LLM推理系统，允许在运行不同LLM（但具有相同架构）的分布式节点之间重用KV缓存。DroidSpeak通过选择性地重新计算由另一个LLM生成的KV缓存的少数层，并重用其余层，同时精心安排层级重新计算和重用KV缓存的加载，以优化推理性能。

**Result:** DroidSpeak实现了高达4倍的吞吐量提升和约3.1倍的预填充（首个token的时间）加速，且F1分数、Rouge-L或代码相似性分数方面的质量损失可忽略不计。

**Conclusion:** DroidSpeak通过在具有相同架构的不同LLM之间共享KV缓存，显著提高了推理性能，同时保持了模型质量，解决了跨模型KV缓存重用的挑战。

> **ai_Abstract:** DroidSpeak是一个创新的分布式LLM推理系统，旨在解决在复合AI系统中不同大型语言模型之间KV缓存重用的挑战。它允许具有相同架构的LLM在分布式节点间共享KV缓存，通过选择性重计算和重用缓存层来优化性能。实验结果表明，DroidSpeak在吞吐量和预填充速度上取得了显著提升（最高4倍和3.1倍），同时保持了可忽略的质量损失，为多LLM服务和跨LLM通信提供了高效的解决方案。

> **摘要翻译:** 复合AI系统，如代理系统，是大型企业环境中新兴的趋势，其中多个LLM针对不同的用户、任务和/或角色协同工作。在这些场景中，不同模型通常处理共享相同上下文前缀的输入。尽管过去在实现单个模型内部输入的前缀KV缓存重用方面做了大量工作，但如何使一个模型重用不同模型的KV缓存仍然是一个开放问题。
我们引入了DroidSpeak，这是第一个分布式LLM推理系统，它允许在运行不同LLM的分布式节点之间重用KV缓存，只要这些LLM具有相同的架构。我们首次研究了在不同LLM之间共享KV缓存的影响，以及这种共享是否/何时影响质量。受研究结果的启发，我们提出了DroidSpeak，它选择性地重新计算由另一个LLM生成的KV缓存的少数层，并重用剩余层，且质量损失可忽略不计。此外，精心管道化层级重新计算和重用KV缓存的加载进一步提高了推理性能。在不同数据集和模型对上的实验表明，与不允许任何模型间共享的基线相比，DroidSpeak实现了高达4倍的吞吐量提升和约3.1倍的预填充（首个token的时间）加速，且F1分数、Rouge-L或代码相似性分数方面的质量损失可忽略不计。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [750] [Voting or Consensus? Decision-Making in Multi-Agent Debate](https://arxiv.org/abs/2502.19130)
> *投票还是共识？多智能体辩论中的决策制定*

*Lars Benedikt Kaesberg, Jonas Becker, Jan Philip Wahle, Terry Ruas, Bela Gipp* | **Category: cs.MA, cs.AI, cs.CL** | **Updated: 2025-07-15**

**Keywords:** 多智能体辩论, 决策协议, 投票, 共识, 性能评估

**Comment:** Accepted at ACL2025 (Findings)

> **TL;DR:** 本文系统评估了多智能体辩论中七种决策协议（如多数投票、一致性共识）的影响，发现投票协议在推理任务中表现更好，共识协议在知识任务中表现更好。同时提出了两种新方法AAD和CI，进一步提升了任务性能。

**AI_Comments:** 本文通过严格的单一变量控制实验，系统地比较了不同决策协议在多智能体辩论中的效果，弥补了以往研究的不足。提出的AAD和CI方法为提升多智能体决策性能提供了新思路，具有较高的创新性。研究结果对优化多智能体系统设计具有重要指导意义，尤其是在需要高效协作和精确决策的场景中。

<details>
  <summary>Details</summary>

**Motivation:** 多智能体辩论的成功很大程度上取决于参数的选择，其中决策协议对最终模型答案影响显著。然而，以往研究常同时改变多个讨论参数，导致难以系统比较决策协议的影响，因此，决策制定如何影响不同任务尚不明确。

**Method:** 本文系统评估了七种决策协议（如多数投票、一致性共识）的影响。研究中每次只改变一个变量——决策协议，以分析不同方法如何影响智能体之间的协作，并测量其在知识和推理任务中的差异。此外，还提出了两种新的方法：All-Agents Drafting (AAD) 和 Collective Improvement (CI) 来提高决策制定和答案多样性。

**Result:** 投票协议在推理任务中性能提升13.2%，共识协议在知识任务中性能提升2.8%。增加智能体数量可以提高性能，而投票前的讨论轮数增多则会降低性能。提出的AAD方法使任务性能提升高达3.3%，CI方法提升高达7.4%。

**Conclusion:** 本文证明了在多智能体辩论中，决策制定比单纯的规模扩展更重要。选择合适的决策协议以及引入新的决策方法（如AAD和CI）能够显著提升多智能体系统的性能。

> **ai_Abstract:** 本研究系统评估了多智能体辩论中七种决策协议（如多数投票、一致性共识）对知识和推理任务性能的影响。通过每次只改变决策协议这一单一变量，研究发现投票协议在推理任务中性能提升显著（13.2%），而共识协议在知识任务中表现更优（2.8%）。同时，研究指出增加智能体数量可提升性能，但增加投票前讨论轮数会降低性能。为进一步优化决策制定和答案多样性，本文提出了两种新方法：All-Agents Drafting (AAD) 和 Collective Improvement (CI)，分别使任务性能提升高达3.3%和7.4%。这项工作强调了多智能体辩论中决策制定的关键作用。

> **摘要翻译:** 多智能体辩论的成功很大程度上取决于仔细选择正确的参数。决策协议尤为突出，因为它会根据决策达成方式极大地影响最终模型答案。系统比较决策协议很困难，因为许多研究除了协议之外还改变了多个讨论参数。到目前为止，决策制定如何影响不同任务在很大程度上尚不清楚。这项工作系统地评估了七种决策协议（例如，多数投票，一致性共识）的影响。我们每次只改变一个变量——决策协议——来分析不同方法如何影响智能体之间的协作，并测量知识和推理任务中的差异。我们的结果表明，与其它决策协议相比，投票协议在推理任务中将性能提高了13.2%，共识协议在知识任务中提高了2.8%。增加智能体数量可以提高性能，而投票前的讨论轮数增多则会降低性能。为了通过增加答案多样性来改进决策制定，我们提出了两种新方法：All-Agents Drafting (AAD) 和 Collective Improvement (CI)。我们的方法使任务性能通过AAD提升高达3.3%，通过CI提升高达7.4%。这项工作证明了在多智能体辩论中决策制定的重要性，超越了规模扩展。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [779] [Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused Ultrasound Ablation Surgery](https://arxiv.org/abs/2505.21418)
> *聚焦超声消融手术治疗规划中的自主多模态大型语言模型代理*

*Lina Zhao, Jiaxing Bai, Zihao Bian, Qingyue Chen, Yafang Li, Guangbo Li, Min He, Huaiyuan Yao, Zongjiu Zhang* | **Category: cs.MA** | **Updated: 2025-07-15**

**Keywords:** 聚焦超声消融手术, 大型语言模型, 治疗规划, 自主代理, 多模态AI

**Comment:** 

> **TL;DR:** FUAS-Agents是一个利用多模态LLM为聚焦超声消融手术生成个性化治疗计划的自主系统，专家评估其计划在完整性、准确性、流畅性和临床合规性方面表现良好。

**AI_Comments:** 该论文创新性地将多模态大型语言模型代理应用于聚焦超声消融手术的治疗规划，解决了临床实践中的复杂挑战。其将通用LLM与专业医疗AI工具相结合的方法具有很强的实用性，并通过人类专家评估验证了其在临床完整性、准确性和合规性方面的有效性，展现了AI在垂直医疗领域实现转化的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 聚焦超声消融手术（FUAS）的临床实施涉及复杂的任务，如多模态图像解释、个性化剂量规划和实时术中决策，这些任务需要智能辅助以提高效率和可靠性。

**Method:** 本文引入了FUAS-Agents，一个自主代理系统，它利用大型语言模型（LLMs）的多模态理解和工具使用能力。该系统通过整合患者资料和MRI数据，协调一系列专业医疗AI工具（包括分割、治疗剂量预测和临床指南检索），以生成包含MRI图像、剂量参数和治疗策略的个性化治疗计划。该系统在子宫肌瘤治疗场景中进行了评估。

**Result:** 四位资深FUAS专家的人工评估表明，在完整性、准确性、流畅性和临床合规性方面，生成的计划分别有82.5%、82.5%、87.5%和97.5%被评为4分或以上（5分制）。

**Conclusion:** 这些结果证明了LLM驱动的代理在增强复杂临床工作流程决策方面的潜力，并示例了一种将通用模型与专业专家系统相结合以解决垂直医疗领域实际挑战的转化范式。

> **ai_Abstract:** FUAS-Agents是一个基于大型语言模型（LLM）的自主多模态代理系统，旨在为聚焦超声消融手术（FUAS）生成个性化治疗计划。它通过整合患者资料和MRI数据，并协调一系列专业的医疗AI工具（如图像分割、剂量预测和临床指南检索），来创建包含MRI图像、剂量参数和治疗策略的完整计划。在子宫肌瘤治疗场景中的评估显示，FUAS专家对该系统生成的计划在完整性、准确性、流畅性和临床合规性方面给予了高度评价（82.5%-97.5%的计划得分在4分及以上），表明LLM驱动的代理在复杂临床决策中具有巨大潜力。

> **摘要翻译:** 聚焦超声消融手术（FUAS）已成为一种有前景的非侵入性治疗方式，因其安全性和精确性而备受重视。然而，其临床实施涉及复杂的任务，例如多模态图像解释、个性化剂量规划和实时术中决策过程，这些都需要智能辅助以提高效率和可靠性。我们引入了FUAS-Agents，这是一个自主代理系统，它利用大型语言模型（LLMs）的多模态理解和工具使用能力。通过整合患者资料和MRI数据，FUAS-Agents协调一系列专业的医疗AI工具，包括分割、治疗剂量预测和临床指南检索，以生成包含MRI图像、剂量参数和治疗策略的个性化治疗计划。我们在子宫肌瘤治疗场景中评估了该系统。四位资深FUAS专家的人工评估表明，在完整性、准确性、流畅性和临床合规性方面，生成的计划分别有82.5%、82.5%、87.5%和97.5%被评为4分或以上（5分制）。这些结果证明了LLM驱动的代理在增强复杂临床工作流程决策方面的潜力，并示例了一种将通用模型与专业专家系统相结合以解决垂直医疗领域实际挑战的转化范式。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [807] [MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility Applications](https://arxiv.org/abs/2506.19502)
> *MATE：基于LLM的多智能体翻译环境，用于无障碍应用*

*Aleksandr Algazinov, Matt Laing, Paul Laban* | **Category: cs.MA, cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 多智能体系统, 无障碍, 模态转换, 大型语言模型, 隐私

**Comment:** 

> **TL;DR:** MATE是一个基于LLM的多模态无障碍多智能体系统，通过模态转换帮助残障人士，并引入了一个表现优异的任务识别模型ModCon-Task-Identifier。

**AI_Comments:** MATE的创新之处在于其多模态多智能体架构结合LLM能力，为无障碍应用提供了高度定制化和隐私保护的解决方案。ModCon-Task-Identifier模型的引入显著提升了系统识别用户意图的准确性，是实现高效模态转换的关键。该系统在本地运行的特性也解决了敏感数据处理的隐私顾虑，使其在医疗等领域具有重要应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有技术和多智能体系统在支持无障碍方面存在不足，缺乏定制化能力，导致残障人士在数字环境中面临障碍。

**Method:** 论文引入了MATE，一个多模态无障碍多智能体系统，根据用户需求执行模态转换（例如将图像转换为音频描述）。MATE支持多种模型，包括LLM API调用和自定义机器学习分类器，并可本地运行以确保隐私。此外，论文还提出了ModCon-Task-Identifier模型，用于从用户输入中精确提取模态转换任务。

**Result:** 实验表明，ModCon-Task-Identifier模型在自定义数据集上持续优于其他大型语言模型和统计模型。

**Conclusion:** MATE系统及其ModCon-Task-Identifier模型能够有效提升无障碍应用的性能，为残障人士提供定制化的模态转换服务，并在隐私和集成方面具有优势。

> **ai_Abstract:** MATE是一个创新的、基于LLM的多模态多智能体系统，旨在解决现有无障碍技术和MAS在定制化方面的不足。它通过根据用户需求进行数据模态转换（如图片转语音描述）来帮助残障人士。系统支持多种模型，可本地运行以保障隐私，并能与现有机构技术集成。论文还提出并验证了ModCon-Task-Identifier模型，该模型能准确识别用户输入的模态转换任务，并在实验中表现优异。MATE在医疗等领域具有广泛应用潜力，并已开源。

> **摘要翻译:** 无障碍性在当今社会仍然是一个关键问题，因为许多技术在开发时并未充分支持所有用户需求。现有的多智能体系统（MAS）由于闭源设计导致缺乏定制化，往往无法为有需求的用户提供全面的帮助。因此，残障人士在与数字环境交互时经常遇到重大障碍。我们引入了MATE，一个多模态无障碍MAS，它根据用户需求执行模态转换。该系统通过确保数据被转换为可理解的格式，有助于帮助残障人士。例如，如果用户视力不佳并收到图像，系统会将该图像转换为其音频描述。MATE可应用于广泛的领域、行业和地区，如医疗保健，并可成为各类用户群体的有用助手。该系统支持多种类型的模型，从LLM API调用到使用自定义机器学习（ML）分类器。这种灵活性确保了系统能够适应各种需求，并兼容各种硬件。由于该系统预计在本地运行，因此可确保敏感信息的隐私和安全。此外，该框架可以有效地与机构技术（例如数字医疗服务）集成，以提供实时用户帮助。此外，我们引入了ModCon-Task-Identifier，一个能够从用户输入中提取精确模态转换任务的模型。大量实验表明，ModCon-Task-Identifier在我们的自定义数据上始终优于其他LLM和统计模型。我们的代码和数据可在https://github.com/AlgazinovAleksandr/Multi-Agent-MATE 公开获取。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [21] [mmE-Loc: Facilitating Accurate Drone Landing with Ultra-High-Frequency Localization](https://arxiv.org/abs/2507.09469)
> *mmE-Loc：利用超高频定位实现精确无人机着陆*

*Haoyang Wang, Jingao Xu, Xinyu Luo, Ting Zhang, Xuecheng Chen, Ruiyang Duan, Jialong Chen, Yunhao Liu, Jianfeng Zheng, Weijie Hong, Xinlei Chen* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 无人机着陆, 超高频定位, 毫米波雷达, 事件相机, 传感器融合

**Comment:** 17 pages, 34 figures. Journal extended version of arXiv:2502.14992

> **TL;DR:** mmE-Loc是一个高精度、低延迟的地面定位系统，利用事件相机和毫米波雷达实现精确无人机着陆，并在精度和延迟方面显著优于现有方法。

**AI_Comments:** 该论文的创新点在于将事件相机引入无人机着陆定位系统，以解决传统帧相机与毫米波雷达在采样频率上的不匹配问题，从而提高了系统吞吐量和性能。提出的两个模块有效利用了多模态数据的特性，进一步提升了定位的精度和效率。这项工作对于提高无人机自主着陆的安全性与可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为实现精确、高效、安全的无人机着陆，地面平台需要实时、准确地定位下降中的无人机并引导其至指定地点。现有结合毫米波传感和传统相机的方案存在吞吐量瓶颈，因为传统帧相机的采样频率低于毫米波雷达。

**Method:** 本研究将传统帧相机升级为事件相机，使其采样频率与毫米波雷达协调一致，并引入了mmE-Loc系统。该系统包含两个创新模块：一致性指导的协作跟踪模块，利用无人机的物理知识提取准确测量；图信息自适应联合优化模块，整合无人机运动信息实现高效传感器融合和无人机定位。

**Result:** 在无人机配送公司的着陆场景中进行的实际实验表明，mmE-Loc在精度和延迟方面均显著优于现有最先进的方法。

**Conclusion:** mmE-Loc通过结合事件相机和毫米波雷达以及创新的融合模块，为精确无人机着陆提供了一个卓越的解决方案，实现了高精度和低延迟。

> **ai_Abstract:** 本论文提出了mmE-Loc，一个用于精确无人机着陆的高精度、低延迟地面定位系统。该系统通过将传统帧相机升级为事件相机，使其采样频率与毫米波雷达协调一致，从而解决了现有毫米波与相机融合系统中吞吐量瓶颈的问题。为了充分利用事件相机和毫米波雷达之间的时间一致性和空间互补性，mmE-Loc引入了两个创新模块：一致性指导的协作跟踪模块和图信息自适应联合优化模块，分别用于精确测量提取和高效传感器融合。真实世界实验证明，mmE-Loc在精度和延迟方面均显著优于现有最先进方法。

> **摘要翻译:** 对于精确、高效、安全的无人机着陆，地面平台应实时、准确地定位下降中的无人机并将其引导至指定地点。虽然毫米波传感与相机结合可以提高定位精度，但传统帧相机的采样频率低于毫米波雷达，这在系统吞吐量方面造成了瓶颈。在这项工作中，我们用事件相机升级了传统帧相机，这是一种新型传感器，可在地面平台设置中与毫米波雷达采样频率协调一致，并引入了mmE-Loc，一个高精度、低延迟的地面定位系统，专为精确无人机着陆而设计。为了充分利用这两种模态之间的“时间一致性”和“空间互补性”，我们提出了两个创新模块：(i) 一致性指导的协作跟踪模块，该模块进一步利用无人机周期性微运动和结构的物理知识来提取准确的测量值，以及 (ii) 图信息自适应联合优化模块，该模块集成了无人机运动信息以实现高效的传感器融合和无人机定位。与一家无人机配送公司进行的着陆场景中的实际实验表明，mmE-Loc在精度和延迟方面均显著优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [37] [Robot Drummer: Learning Rhythmic Skills for Humanoid Drumming](https://arxiv.org/abs/2507.11498)
> *机器人鼓手：学习类人机器人打鼓的节奏技巧*

*Asad Ali Shahid, Francesco Braghin, Loris Roveda* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 机器人鼓手, 强化学习, 类人机器人, 音乐表演, 节奏技巧

**Comment:** 

> **TL;DR:** 本文介绍了“机器人鼓手”系统，一个通过强化学习实现高精度、富有表现力的人形机器人打鼓系统，能在多种歌曲中展现出类人打鼓策略。

**AI_Comments:** 这项研究的创新之处在于将复杂的音乐表演任务（打鼓）引入到类人机器人领域，并巧妙地利用强化学习解决了长期性和高精度协调的挑战。其提出的“节奏接触链”概念和并行策略训练方法是解决此类问题的有效途径。实验结果展示了令人印象深刻的性能和类人行为，为机器人艺术和人机交互开辟了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管类人机器人在灵巧性、平衡性和运动方面取得了显著进展，但它们在音乐表演等富有表现力的领域中的作用仍未得到充分探索。打鼓等音乐任务对瞬时时机、快速接触和多肢协调提出了独特的挑战。

**Method:** 作者将类人机器人打鼓视为时间接触的顺序完成，并将鼓谱转换为“节奏接触链”。为了处理音乐表演的长期性，他们将每首曲子分解为固定长度的片段，并使用强化学习并行训练所有片段的单一策略。

**Result:** 通过对三十多首流行摇滚、金属和爵士乐曲目进行的大量实验，结果表明机器人鼓手始终取得了高F1分数。学习到的行为展现出新兴的类人打鼓策略，例如交叉手臂击打和自适应鼓槌分配。

**Conclusion:** 强化学习有潜力将类人机器人带入创意音乐表演领域。

> **ai_Abstract:** 本文提出了“机器人鼓手”系统，一个能够进行高精度、富有表现力打鼓的类人机器人。研究将打鼓任务建模为节奏接触链的顺序完成，并利用强化学习训练单一策略来处理音乐表演的长期性。通过对大量歌曲的实验，机器人鼓手展现出高F1分数和类人打鼓策略，证明了强化学习在将类人机器人应用于创意音乐表演领域的潜力。

> **摘要翻译:** 类人机器人在灵巧性、平衡性和运动方面取得了显著进展，但它们在音乐表演等富有表现力的领域中的作用仍未得到充分探索。打鼓等音乐任务提出了独特的挑战，包括瞬时时机、快速接触和持续数分钟的多肢协调。在本文中，我们介绍了“机器人鼓手”，一个能够对各种歌曲进行富有表现力、高精度打鼓的类人系统。我们将类人机器人打鼓制定为时间接触的顺序完成，并将鼓谱转换为“节奏接触链”。为了处理音乐表演的长期性，我们将每首曲子分解为固定长度的片段，并使用强化学习并行训练所有片段的单一策略。通过对三十多首流行摇滚、金属和爵士乐曲目进行的大量实验，我们的结果表明机器人鼓手始终取得了高F1分数。学习到的行为展现出新兴的类人打鼓策略，例如交叉手臂击打和自适应鼓槌分配，这表明强化学习有潜力将类人机器人带入创意音乐表演领域。项目页面：robot-drummer.github.io

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [49] [Enhancing Autonomous Manipulator Control with Human-in-loop for Uncertain Assembly Environments](https://arxiv.org/abs/2507.11006)
> *不确定装配环境下人机协作增强自主机械臂控制*

*Ashutosh Mishra, Shreya Santra, Hazal Gozbasi, Kentaro Uno, Kazuya Yoshida* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 人机协作, 自主机械臂, 月球任务, 数字孪生, 机器人操作

**Comment:** 6 pages, 7 figures. Manuscript accepted at the 2025 IEEE 21st
  International Conference on Automation Science and Engineering (CASE 2025)

> **TL;DR:** 本研究提出了一种结合人机协作的先进方法，以增强不确定和挑战性环境下（特别是月球任务）的机器人操作，通过实时反馈、动态误差检测、自适应控制、高效运动规划和数字孪生仿真，提高了任务的可靠性和效率。

**AI_Comments:** 该论文的创新点在于将人机协作（HITL）与数字孪生仿真相结合，以增强在极端不确定环境（如月球）中机械臂的自主控制。实时反馈、动态误差检测和自适应控制的整合，以及人类在模糊场景中的干预能力，显著提升了系统的鲁棒性和可靠性。这对于未来空间探索和资源利用具有重要意义，尤其是在需要高度灵活性和适应性的任务中。

<details>
  <summary>Details</summary>

**Motivation:** 在不确定和挑战性环境下（例如月球任务）增强机器人操作的可靠性和效率，特别是解决柔性太阳能电池板的自主部署问题，并应对沉降、可变载荷和低光照条件等挑战。

**Method:** 本研究提出了一种结合人机协作（HITL）控制的先进方法，集成人类决策与自主机器人功能。具体方法包括：使用机械臂进行柔性太阳能电池板的自主部署；机械臂提供位置和力-扭矩实时反馈以实现精确控制；动态误差检测和自适应控制；采用高效运动规划策略以应对沉降、可变载荷和低光照条件；在模糊场景中允许操作员干预的人类控制；利用数字孪生仿真增强系统鲁棒性，实现持续反馈、迭代任务优化和无缝集成。系统在模拟月球条件下进行了测试。

**Result:** 系统在模拟月球条件下进行了测试，验证了其在极端光照、可变地形、变化载荷和传感器限制下的性能和可靠性。

**Conclusion:** 通过结合人类决策和自主机器人功能，并利用实时反馈、数字孪生仿真和人机协作，本研究提出的方法显著提高了不确定和挑战性环境下机器人操作的可靠性和效率，特别适用于空间任务。

> **ai_Abstract:** 本研究提出了一种用于不确定装配环境的先进机器人操作方法，特别关注月球任务中的自主部署。该方法通过将人类决策与自主机器人功能相结合，并引入人机协作（HITL）控制，旨在提高任务可靠性和效率。研究中，机械臂用于部署柔性太阳能电池板，并利用实时位置和力-扭矩反馈实现动态误差检测和自适应控制。此外，还采用了高效运动规划策略和数字孪生仿真来应对恶劣环境条件，如沉降、可变载荷和低光照。系统在模拟月球条件下进行了验证，证明了其在复杂环境下的可靠性。

> **摘要翻译:** 本研究提出了一种先进方法，旨在增强不确定和挑战性环境中的机器人操作，重点关注月球任务中由人机协作（HITL）控制增强的自主操作。通过将人类决策与自主机器人功能相结合，该研究提高了空间应用的任务可靠性和效率。所解决的关键任务是使用可伸缩的梯形结构和具有实时反馈以实现精度的机械臂自主部署柔性太阳能电池板。机械臂中继位置和力-扭矩数据，从而在部署过程中实现动态误差检测和自适应控制。为了减轻沉降、可变载荷和低光照条件的影响，采用了高效的运动规划策略，并辅以人类控制，允许操作员在模糊场景中进行干预。数字孪生仿真通过实现持续反馈、迭代任务细化和与部署流程的无缝集成，增强了系统鲁棒性。该系统已经过测试，以验证其在模拟月球条件下的性能，并确保在极端光照、可变地形、变化载荷和传感器限制下的可靠性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [103] [TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update](https://arxiv.org/abs/2507.11069)
> *TRAN-D：基于2D高斯溅射的稀疏视角透明物体深度重建及物理模拟场景更新*

*Jeongyun Kim, Seunghoon Jeong, Giseop Kim, Myung-Hwan Jeon, Eunji Jun, Ayoung Kim* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 透明物体深度重建, 2D高斯溅射, 物理模拟, 稀疏视角, 场景更新

**Comment:** 

> **TL;DR:** TRAN-D利用2D高斯溅射和物理模拟，显著提高了稀疏视角下透明物体的深度重建精度，尤其适用于动态场景更新。

**AI_Comments:** TRAN-D的创新点在于将2D高斯溅射与物理模拟相结合，以应对透明物体深度重建的固有挑战，特别是其在稀疏视角和动态场景更新中的应用。通过分离物体和背景，并引入对象感知损失，有效解决了透明物体特有的伪影和遮挡问题。物理模拟的引入大大提升了动态场景下物体移除和链式反应移动的处理效率，无需耗时的重新扫描，这对于实时或近实时应用至关重要。其在单图像更新下仍能达到高精度，显示了其在资源受限或快速变化环境下的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法难以从RGB图像中理解透明物体的3D几何形状，尤其是在稀疏视角和动态环境中，因为透明物体具有反射和折射等固有物理特性。

**Method:** 引入TRAN-D，一种基于2D高斯溅射的透明物体深度重建方法。核心在于将透明物体与背景分离，优化对应于物体的2D高斯。通过对象感知损失减轻伪影，确保覆盖不可见表面并减少过拟合。此外，结合物理模拟，在几秒内改进重建，处理物体移除和剩余物体的链式反应移动，无需重新扫描。

**Result:** 在合成和真实世界序列上进行了评估，TRAN-D始终比现有SOTA的GS方法有显著改进。在合成TRansPose序列上，TRAN-D将平均绝对误差降低了39%以上。仅使用一张图像更新时，TRAN-D达到了48.46%的准确率（delta < 2.5 cm），是使用六张图像的基线方法的1.5倍以上。

**Conclusion:** TRAN-D通过其创新的2D高斯溅射和物理模拟方法，显著提高了稀疏视角下透明物体的深度重建精度和动态场景更新能力，表现优于现有SOTA方法。

> **ai_Abstract:** TRAN-D是一种新颖的基于2D高斯溅射的透明物体深度重建方法，旨在解决稀疏视角和动态环境下透明物体3D几何理解的挑战。它通过分离物体与背景、引入对象感知损失以及集成物理模拟来优化高斯并处理场景更新。实验结果表明，TRAN-D在深度重建精度上显著优于现有方法，尤其在减少误差和提高单图像更新效率方面表现突出。

> **摘要翻译:** 从RGB图像中理解透明物体的3D几何形状由于其固有的物理特性（如反射和折射）而具有挑战性。为了解决这些困难，特别是在稀疏视角和动态环境的场景中，我们引入了TRAN-D，一种新颖的基于2D高斯溅射的透明物体深度重建方法。我们的关键见解在于将透明物体与背景分离，从而能够集中优化与物体对应的高斯。我们通过对象感知损失减轻了伪影，该损失将高斯放置在被遮挡的区域，确保覆盖不可见表面同时减少过拟合。此外，我们结合了基于物理的模拟，在短短几秒内改进重建，有效地处理物体移除和剩余物体的链式反应移动，而无需重新扫描。TRAN-D在合成和真实世界序列上进行了评估，并且它始终表现出对现有基于GS的最先进方法的稳健改进。与基线相比，TRAN-D在合成TRansPose序列上将平均绝对误差降低了39%以上。此外，尽管仅使用一张图像进行更新，TRAN-D仍达到了48.46%的delta < 2.5 cm精度，是使用六张图像的基线方法的1.5倍以上。代码和更多结果可在https://jeongyun0609.github.io/TRAN-D/获得。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [152] [Closed Form Time Derivatives of the Equations of Motion of Rigid Body Systems](https://arxiv.org/abs/2507.11076)
> *刚体系统运动方程的闭式时间导数*

*Andreas Mueller, Shivesh Kumar* | **Category: cs.RO, cs.NA, math.DG, math.DS, math.GR, math.NA** | **Updated: 2025-07-15**

**Keywords:** 刚体系统, 运动方程, 时间导数, 闭式解, 李群公式

**Comment:** 

> **TL;DR:** 提出了一种闭式方法，用于计算刚体系统运动方程的时间导数（最高二阶），作为现有递归算法的替代，并利用李群公式使其紧凑易参数化。

**AI_Comments:** 这篇论文的创新点在于提出了运动方程时间导数的闭式公式，而非传统的递归算法。这不仅可能提高计算效率，更重要的是，它提供了对导数结构更直接的洞察。利用李群公式使得方程更加紧凑和易于参数化，这对于机器人控制和多体系统动力学分析具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 运动方程的导数在机器人学中越来越重要，尤其是在机器人系统设计和控制方面。控制机器人（特别是包含弹性部件的多体系统）不仅需要平滑轨迹，还需要控制力/扭矩的时间导数，从而需要运动方程的时间导数。

**Method:** 本文采用李群公式，提出了一种新的闭式公式，用于计算刚体系统运动方程的最高二阶时间导数，以替代现有的递归算法。

**Result:** 成功推导并展示了刚体系统运动方程的闭式时间导数（最高二阶），该公式比现有递归算法更直接地揭示了导数的结构，并且利用李群公式使得方程非常紧凑且易于参数化。

**Conclusion:** 通过提供闭式时间导数公式，本文为机器人系统（特别是多体系统）的设计和控制提供了新的、更具洞察力且更紧凑的工具，替代了传统的递归算法。

> **ai_Abstract:** 本文针对机器人系统设计与控制中对运动方程时间导数日益增长的需求，提出了一种计算刚体系统运动方程闭式时间导数（最高二阶）的新方法。该方法作为现有递归算法的替代，能够直接揭示导数结构，并且通过采用李群公式，使得所得方程非常紧凑且易于参数化。

> **摘要翻译:** 描述刚体系统动力学的运动方程（EOM）的导数在机器人社区中变得越来越重要，并在机器人系统的设计和控制中找到许多应用。控制机器人，特别是包含弹性部件的多体系统，不仅需要平滑的轨迹，还需要控制力/扭矩的时间导数，因此也需要运动方程的导数。本文提出了运动方程的闭式时间导数，最高可达二阶，作为现有递归算法的替代公式，这为导数的结构提供了直接的洞察。刚体系统的李群公式被用于产生非常紧凑且易于参数化的方程。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [173] [Irrotational Contact Fields](https://arxiv.org/abs/2312.03908)
> *无旋接触场*

*Alejandro Castro, Xuchen Han, Joseph Masterjohn* | **Category: cs.RO, cs.CE, math-ph, math.MP** | **Updated: 2025-07-15**

**Keywords:** 接触模型, 凸近似, 可微分仿真, 机器人, Drake

**Comment:** 16 pages, 26 figures. The supplemental video is available publicly at
  https://youtu.be/FTUPYZ_8Xbk?si=MWndCUCGWMJsFnsO

> **TL;DR:** 本文提出了一个用于生成复杂接触模型凸近似的鲁棒框架，实现了可微分的机器人仿真，并支持有效的仿真到现实迁移。

**AI_Comments:** 本文的创新在于为复杂接触模型提供了一个鲁棒且可微分的框架，这对于机器人领域的优化和学习至关重要。利用凸近似和混合方法进行梯度计算同时重用分解的策略尤其巧妙。其在开源工具包中的实现以及所展示的仿真到现实迁移潜力突出了其实际重要性。

<details>
  <summary>Details</summary>

**Motivation:** 为了生成复杂接触模型的鲁棒凸近似，使其适用于各种刚度值，并实现机器人任务的可微分仿真。

**Method:** 本文提出了一个生成复杂接触模型凸近似的框架，该框架结合了Hunt & Crossley模型和库仑摩擦定律，并利用最大耗散原理。他们在开源机器人工具包Drake中实现了一个完全可微分的解决方案，采用了一种新颖的混合方法来计算复杂几何模型的梯度，同时重用接触解析中的分解。

**Result:** 所提出的方法在广泛的刚度值范围内都表现出鲁棒性，适用于柔性表面和刚性近似。它能够以交互速率对机器人任务进行鲁棒仿真，并精确解决静摩擦和接触转换，支持有效的仿真到现实迁移。

**Conclusion:** 本文提出的框架为复杂接触建模提供了一个鲁棒且可微分的解决方案，促进了准确高效的机器人仿真以及仿真到现实的迁移。

> **ai_Abstract:** 本文介绍了一个用于创建复杂接触模型鲁棒凸近似的框架，该框架整合了已建立的物理定律。该方法在Drake中作为可微分解决方案实现，有效处理各种表面刚度，并通过允许复杂几何体的梯度计算，实现高效、准确的机器人仿真，具有强大的仿真到现实迁移能力。

> **摘要翻译:** 我们提出了一个用于生成复杂接触模型凸近似的框架，该框架结合了经过实验验证的模型，如Hunt & Crossley与库仑摩擦定律，以及最大耗散原理。我们的方法在广泛的刚度值范围内都表现出鲁棒性，使其适用于柔性表面和刚性近似。我们通过各种测试案例评估了这些近似，详细说明了其特性和局限性。我们在开源机器人工具包Drake中实现了一个完全可微分的解决方案。我们新颖的混合方法能够计算复杂几何模型的梯度，同时重用接触解析中的分解。我们展示了以交互速率对机器人任务进行鲁棒模拟，具有精确解决的静摩擦和接触转换，支持有效的仿真到现实迁移。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [197] [Force-Based Viscosity and Elasticity Measurements for Material Biomechanical Characterisation with a Collaborative Robotic Arm](https://arxiv.org/abs/2507.11133)
> *基于力的粘度和弹性测量，用于协作机械臂的材料生物力学表征*

*Luca Beber, Edoardo Lamon, Giacomo Moretti, Matteo Saveriano, Luca Fambri, Luigi Palopoli, Daniele Fontanelli* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 机器人、生物力学、粘弹性、触诊、协作机械臂

**Comment:** 

> **TL;DR:** 本文评估了一个机器人系统在测量材料（包括离体组织）粘弹性参数方面的准确性和精度，结果显示其与真实值非常接近，表明了机器人在临床诊断应用中的巨大潜力。

**AI_Comments:** 这篇论文展示了将机器人技术应用于传统诊断（如触诊）的巨大潜力，通过提供客观、精确的生物力学数据来弥补人工操作的主观性和误差。其创新之处在于利用协作机械臂进行力学测量，并初步验证了其在生物组织上的适用性，为未来自动化、标准化的临床诊断铺平了道路，具有重要的临床应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 传统的诊断活动（如超声和触诊）成本低但易出错且具有主观性，需要高技能医务人员。引入机器人解决方案可以减少结果的主观性并缩短等待时间。为了使机器人能进行有效的触诊或超声扫描，精确估计患者组织的生物力学特性至关重要。

**Method:** 本文使用一个机器人系统来评估各种材料（包括离体组织）的粘弹性参数的准确性和精度。测量结果与通过高精度仪器表征的具有不同粘弹特性的硅胶样本的真实值进行了比较。

**Result:** 实验结果表明，机器人系统的测量准确性与真实值非常接近。

**Conclusion:** 该机器人系统能够准确测量材料的粘弹性，这增加了机器人在临床应用中进行诊断活动的潜力。

> **ai_Abstract:** 本文旨在解决传统诊断活动（如触诊和超声）中存在的误差和主观性问题。研究提出并评估了一种基于协作机械臂的机器人系统，用于精确测量材料（包括离体组织）的粘度和弹性，以进行生物力学表征。通过与高精度仪器测得的硅胶样本真实值进行比较，实验结果证明了该机器人系统在估计粘弹性参数方面的准确性和精度，预示了其在临床诊断应用中的巨大潜力。

> **摘要翻译:** 诊断活动，如超声扫描和触诊，成本相对较低。它们在早期发现健康问题和评估其进展方面发挥着关键作用。然而，它们也是容易出错的活动，需要高技能的医务人员。使用机器人解决方案可能是降低结果固有主观性并缩短等待时间的关键。为了让机器人执行触诊或超声扫描，它必须有效地管理人体物理交互，这极大地受益于对患者组织生物力学特性的精确估计。本文评估了机器人系统在估计各种材料（包括对离体组织进行的一些测试，作为该方法适用于生物样本的初步概念验证演示）粘弹性参数方面的准确性和精度。测量结果与使用高精度仪器表征的具有不同粘弹特性的硅胶样本的真实值进行了比较。实验结果表明，机器人系统的准确性与真实值非常接近，增加了机器人在此类临床应用中潜在使用的信心。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [213] [FLAF: Focal Line and Feature-constrained Active View Planning for Visual Teach and Repeat](https://arxiv.org/abs/2409.03457)
> *FLAF：用于视觉示教与重复的焦线和特征约束主动视图规划*

*Changfei Fu, Weinan Chen, Wenjun Xu, Hong Zhang* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 视觉示教与重复, 主动视图规划, 跟踪失败, 特征约束, 焦线

**Comment:** 

> **TL;DR:** FLAF提出了一种新的主动视图规划方法，通过焦线和特征约束来避免视觉示教与重复（VT&R）系统中在低纹理区域的跟踪失败，并在实际场景中表现良好。

**AI_Comments:** 本文的创新点在于提出了FLAF，一个结合了焦线和特征约束的主动视图规划方法，有效解决了基于特征的视觉导航在低纹理环境中的跟踪失败问题。通过主动控制摄像头视角以获取更多可识别特征，显著提升了视觉示教与重复（VT&R）系统在真实复杂场景下的鲁棒性和实用性。这对于扩展VT&R在日常自主导航中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决在人工环境中，由于缺乏纹理区域导致的基于特征的视觉SLAM（VSLAM）跟踪失败，这限制了视觉示教与重复（VT&R）在现实世界中的应用。

**Method:** 提出了一种名为FLAF的焦线和特征约束主动视图规划方法。该方法将主动视图规划器集成到基于特征的视觉SLAM系统中，构建了一个主动VT&R系统。系统使用安装在移动机器人上的云台（PTU）主动摄像头，通过FLAF在示教阶段构建完整的路径地图，并在重复阶段通过将机器人朝向更多可识别特征的地图点来保持稳定的定位。

**Result:** 实验表明，FLAF优于不考虑特征可识别性的方法，并且该主动VT&R系统在复杂环境中通过有效处理低纹理区域表现良好。

**Conclusion:** FLAF通过其焦线和特征约束的主动视图规划，成功解决了基于特征的视觉导航在低纹理区域的跟踪失败问题，显著提升了视觉示教与重复系统在实际复杂环境中的鲁棒性和性能。

> **ai_Abstract:** 本文提出FLAF，一种焦线和特征约束主动视图规划方法，旨在解决移动机器人在基于特征的视觉导航中，因低纹理区域导致的跟踪失败问题。FLAF被集成到基于特征的视觉示教与重复（VT&R）系统中，通过控制主动摄像头在示教和重复阶段，使机器人面向更多可识别特征的地图点，从而避免建图和定位失败。真实实验证明，FLAF在复杂环境中，尤其是在低纹理区域，表现优于传统方法，显著提升了VT&R系统的鲁棒性和性能。

> **摘要翻译:** 本文提出了FLAF，一种用于在移动机器人基于特征的视觉导航中避免跟踪失败的焦线和特征约束主动视图规划方法。我们基于FLAF的视觉导航建立在基于特征的视觉示教与重复（VT&R）框架之上，该框架通过教导机器人沿着覆盖日常自主导航大部分需求的各种路径进行导航，从而支持许多机器人应用。然而，在人工环境中，由于缺乏纹理区域导致的基于特征的视觉同步定位与建图（VSLAM）中的跟踪失败仍然限制了VT&R在现实世界中的应用。为了解决这个问题，所提出的视图规划器被集成到基于特征的视觉SLAM系统中，以构建一个避免跟踪失败的主动VT&R系统。在我们的系统中，移动机器人上安装了一个基于云台（PTU）的主动摄像头。使用FLAF，基于主动摄像头的VSLAM在示教阶段运行以构建完整的路径地图，并在重复阶段保持稳定的定位。FLAF使机器人面向更多的地图点以避免路径学习期间的建图失败，并在遵循学习轨迹时面向更多有利于定位的特征可识别地图点。真实场景中的实验表明，FLAF优于不考虑特征可识别性的方法，并且我们的主动VT&R系统通过有效处理低纹理区域在复杂环境中表现良好。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [242] [A Robust Controller based on Gaussian Processes for Robotic Manipulators with Unknown Uncertainty](https://arxiv.org/abs/2507.11170)
> *基于高斯过程的未知不确定性机器人机械手鲁棒控制器*

*Giulio Giacomuzzo, Mohamed Abdelwahab, Marco Calì, Alberto Dalla Libera, Ruggero Carli* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 高斯过程, 鲁棒控制, 机器人机械手, 反馈线性化, 轨迹跟踪

**Comment:** 

> **TL;DR:** 本文提出了一种基于高斯过程的鲁棒控制器，用于处理具有未知不确定性的机器人机械手，通过估计和补偿模型失配来确保精确的轨迹跟踪。

**AI_Comments:** 该论文的创新之处在于利用高斯过程在线估计未知模型失配，并将其不确定性（方差）直接整合到鲁棒控制器设计中。这提供了一种数据驱动的方法来处理不确定性，而无需先验界限，这对于机器人控制具有显著的实际优势。

<details>
  <summary>Details</summary>

**Motivation:** 为了确保一类重要的拉格朗日系统实现精确的轨迹跟踪，即使在没有关于模型失配的先验界限的情况下，也需要一个鲁棒的控制器。

**Method:** 提出了一种新颖的基于学习的鲁棒反馈线性化策略。该方法使用高斯过程回归（GPR）来估计模型失配，并将其添加到经典反馈线性化方案的外环。此外，通过一个基于GPR方差设计的额外项来增强控制器的鲁棒性，以补偿残余不确定性。

**Result:** 所提出的方案被证明能够以高概率保证期望轨迹的渐近跟踪。该策略在一个2自由度平面机器人上进行了数值测试。

**Conclusion:** 本文成功提出并验证了一种基于高斯过程的鲁棒控制器，该控制器能够确保具有未知不确定性的机器人机械手实现精确的渐近轨迹跟踪。

> **ai_Abstract:** 本文介绍了一种针对具有未知模型失配的拉格朗日机器人机械手的新型鲁棒反馈线性化控制器。该方法利用高斯过程回归（GPR）来估计模型失配，并将此估计集成到标准反馈线性化回路中。一个由GPR方差确定的额外项增强了对残余不确定性的鲁棒性。该方法经理论证明能够以高概率实现渐近轨迹跟踪，并在一个2自由度机器人上进行了数值验证。

> **摘要翻译:** 在本文中，我们提出了一种新颖的基于学习的鲁棒反馈线性化策略，以确保一类重要的拉格朗日系统实现精确的轨迹跟踪。我们假设给定动力学的标称知识，但没有关于模型失配的先验界限。在我们的方法中，关键在于采用基于高斯过程（GPR）的回归框架来估计模型失配。这个估计被添加到基于可用标称知识的经典反馈线性化方案的外环中。然后，为了补偿残余不确定性，我们通过包含一个额外项来增强控制器的鲁棒性，该项的大小是根据GPR框架提供的方差设计的。我们证明，所提出的方案以高概率保证了期望轨迹的渐近跟踪。我们在一个2自由度平面机器人上对我们的策略进行了数值测试。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [269] [Extending the Benefits of Parallel Elasticity across Multiple Actuation Tasks: A Geometric and Optimization-Based Approach](https://arxiv.org/abs/2409.08889)
> *将并联弹性优势扩展到多执行任务：一种几何与优化相结合的方法*

*Kang Yang, Myia Dickens, James Schmiedeler, Edgar Bolívar-Nieto* | **Category: cs.RO** | **Updated: 2025-07-14**

**Keywords:** 并联弹性, 凸优化, 刚度, 预载, 执行任务

**Comment:** 

> **TL;DR:** 本文提出了一种凸优化方法，用于选择最佳并联弹簧刚度和预载，以确保在多个执行任务中减少功耗或力。

**AI_Comments:** 本文的创新之处在于将并联弹性系统在多任务场景下的设计挑战转化为一个凸优化问题，这不仅保证了全局最优解，还提供了直观的几何解释，极大地简化了参数选择过程。这种方法对于提高机器人和假肢应用的能源效率和降低驱动力具有重要意义。此外，提供开源代码也显著增强了其研究和实际应用的价值。

<details>
  <summary>Details</summary>

**Motivation:** 在并联弹性系统中，为任意一组任务选择能保证功耗或力矩（力）降低的弹簧刚度和预载是一个设计挑战。

**Method:** 本文提出了一个凸优化问题，通过在优化变量（并联弹簧刚度和预载）中强制执行一组凸二次约束（在刚度和预载平面中等同于椭圆），以确保并联弹簧能减少多个任务的均方根源力或能耗。该方法通过解析和实验证明了弹簧刚度和预载的凸二次函数。

**Result:** 该方法保证了在多个任务中实现功耗或力矩（力）的降低。二次约束等同于椭圆，提供了直观的几何解释，指导刚度和预载的选择过程。研究结果在膝盖外骨骼和假肢脚踝的应用中得到了分析。

**Conclusion:** 通过几何和优化相结合的方法，本文成功地解决了在多个执行任务中扩展并联弹性优势的挑战，通过优化刚度和预载选择，确保了功耗和力矩（力）的降低。

> **ai_Abstract:** 本文旨在解决并联弹性系统中，为多种执行任务选择最佳弹簧刚度和预载以确保能耗和力矩（力）降低的难题。研究提出了一种基于凸优化的方法，通过引入凸二次约束（在参数平面中表现为椭圆）来确定并联弹簧的刚度和预载。该方法能够确保在多个任务中有效降低均方根源力或能耗，并通过解析和实验验证了其有效性。文章还展示了该方法在膝盖外骨骼和假肢脚踝中的应用潜力。

> **摘要翻译:** 与力源（例如电动机或人体肌肉）并联的弹簧可以根据弹簧刚度、弹簧预载和执行任务来降低其能耗和力（即扭矩或力）。然而，选择能够保证任意一组任务的力或能耗降低的弹簧刚度和预载是一个设计挑战。这项工作提出了一个凸优化问题，以确保并联弹簧能够减少多个任务的均方根源力或能耗。具体来说，我们通过在优化变量（并联弹簧刚度和预载）中强制执行一组凸二次约束来保证在多个任务中的优势。这些二次约束等同于刚度和预载平面中的椭圆；椭圆内的任何刚度和预载组合都表示一个并联弹簧，相对于没有弹簧的执行器，它能最大限度地减少力源或能耗。这种几何解释直观地指导了刚度和预载的选择过程。我们通过解析和实验证明了弹簧刚度和预载的凸二次函数。作为应用，我们分析了以人体肌肉为力源的膝盖外骨骼和由电动机驱动的假肢脚踝的并联弹簧刚度和预载选择。与我们框架相关的源代码作为补充开源软件提供。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [292] [MPC-based Coarse-to-Fine Motion Planning for Robotic Object Transportation in Cluttered Environments](https://arxiv.org/abs/2507.11211)
> *基于MPC的机器人杂乱环境中物体运输粗到精运动规划*

*Chen Cai, Ernesto Dickel Saraiva, Ya-jun Pan, Steven Liu* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-15**

**Keywords:** 运动规划, 模型预测控制, 粗到精规划, 机器人操作, 杂乱环境

**Comment:** 10 pages, 5 figures, submitted to IEEE Robotics and Automation
  Letters (RA-L)

> **TL;DR:** 本文提出一种基于MPC的粗到精运动规划框架，用于在杂乱、未知环境中进行机器人操作，并通过实验验证了其鲁棒性和适应性。

**AI_Comments:** 该论文的创新点在于提出了一个粗到精的运动规划框架，有效地结合了感知、MPC和碰撞检测，能够在不确定和杂乱的未知环境中实现鲁棒的机器人操作。其逐步完善模型和规划的策略，以及对实时性和动态重规划的支持，是其重要的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 解决在杂乱、未建模环境中进行机器人操作时的运动规划挑战。

**Method:** 提出了一个新颖的粗到精运动规划框架，整合了双摄像头感知系统与基于B样条的模型预测控制（MPC）方案。规划器从不确定观测生成初始轨迹，并逐步融合新视觉数据以完善环境模型和运动规划。采用基于视觉的成本函数促进目标驱动探索，并使用改进的核感知器碰撞检测器实现高效实时规划和动态重规划。

**Result:** 在多臂平台上的实验验证了该框架在不确定性和杂乱环境下的鲁棒性和适应性。

**Conclusion:** 该粗到精运动规划框架在不确定和杂乱环境下，能够实现机器人鲁棒且适应性的运动规划。

> **ai_Abstract:** 本文提出了一种新颖的粗到精运动规划框架，旨在解决机器人在杂乱、未建模环境中的操作问题。该框架结合了双摄像头感知和基于B样条的MPC，能够从不确定观测中生成初始轨迹，并随着新视觉数据的融合逐步细化环境模型和规划。通过基于视觉的成本函数和改进的核感知器碰撞检测器，实现了目标驱动探索和高效实时规划。实验验证了该框架在复杂环境中的鲁棒性和适应性。

> **摘要翻译:** 这篇论文提出了一种新颖的粗到精运动规划框架，用于在杂乱、未建模环境中进行机器人操作。该系统集成了双摄像头感知设置与基于B样条的模型预测控制（MPC）方案。最初，规划器从部分和不确定的观测中生成可行的全局轨迹。随着新的视觉数据逐步融合，环境模型和运动规划都得到了逐步完善。一个基于视觉的成本函数促进了目标驱动的探索，而一个改进的核感知器碰撞检测器实现了实时规划的有效约束更新。该框架适应闭链运动学并支持动态重规划。在多臂平台上的实验验证了其在不确定性和杂乱环境下的鲁棒性和适应性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [302] [Human-Robot collaboration in surgery: Advances and challenges towards autonomous surgical assistants](https://arxiv.org/abs/2507.11460)
> *机器人辅助手术中的人机协作：迈向自主手术助手的进展与挑战*

*Jacinto Colan, Ana Davila, Yutaro Yamada, Yasuhisa Hasegawa* | **Category: cs.RO, cs.HC** | **Updated: 2025-07-15**

**Keywords:** 人机协作, 手术机器人, 自主手术助手, 系统综述, 挑战

**Comment:** Accepted at 2025 IEEE International Conference on Robot and Human
  Interactive Communication (ROMAN)

> **TL;DR:** 本系统综述探讨了外科手术中人机协作的进展与挑战，尤其关注自主手术机器人助手（ASARs）的开发，并指出主要应用、协作模式和待解决的关键问题。

**AI_Comments:** 这篇系统综述非常有价值，因为它不仅总结了外科手术中人机协作的当前进展，还明确指出了未来发展面临的关键挑战。其创新性在于对现有文献的系统性梳理和对未来研究方向的明确指引，对于推动自主手术机器人助手的发展具有重要的参考意义。特别强调了人机交互、程序意识和技能获取等方面的挑战，揭示了该领域从技术实现到实际应用所需要克服的深层问题。

<details>
  <summary>Details</summary>

**Motivation:** 自主机器人系统在复杂手术中协助外科医生的能力日益增强，使得外科手术中的人机协作成为一个重要的研究领域。

**Method:** 遵循PRISMA指南，在IEEE Xplore、Scopus和Web of Science数据库中进行了全面的文献检索，最终选择了32项研究进行详细分析。

**Result:** 识别出两种主要的协作设置：基于远程操作的辅助和直接的动手交互。研究发现对ASARs的研究日益增多，主要应用在内窥镜引导，并在自主工具操作方面取得进展。主要挑战包括：机器人动作与人类外科医生偏好的一致性、自主系统程序意识、无缝人机信息交换以及共享工作空间中技能获取的复杂性。

**Conclusion:** 本综述综合了当前趋势，指出了关键局限性，并概述了未来研究方向，以提高手术环境中人机协作的可靠性、安全性和有效性。

> **ai_Abstract:** 本系统综述聚焦于外科手术中人机协作的进展与挑战，特别是自主手术机器人助手（ASARs）的发展。通过对32项研究的分析，识别出远程操作辅助和直接动手交互两种协作模式。研究发现ASARs在内窥镜引导和自主工具操作方面取得进展，但也面临机器人行为与医生偏好对齐、系统程序意识、信息交换及技能获取等挑战。本综述总结了当前趋势，提出了未来研究方向，以提升手术人机协作的可靠性、安全性和有效性。

> **摘要翻译:** 外科手术中的人机协作代表了一个重要的研究领域，其驱动力是自主机器人系统在复杂手术中协助外科医生的能力日益增强。本系统综述旨在探讨自主手术机器人助手（ASARs）开发中的进展和持续挑战，特别关注机器人向人类外科医生提供有意义和主动支持的场景。本研究遵循PRISMA指南，对IEEE Xplore、Scopus和Web of Science数据库进行了全面的文献检索，最终选择了32项研究进行详细分析。研究识别出两种主要的协作设置：基于远程操作的辅助和直接的动手交互。研究结果显示，对ASARs的研究日益受到重视，目前主要应用于内窥镜引导，同时在自主工具操作方面也取得了新的进展。然而，有几个关键挑战阻碍了其更广泛的应用，包括：机器人动作与人类外科医生偏好的一致性、自主系统内部程序意识的必要性、建立无缝的人机信息交换，以及共享工作空间中技能获取的复杂性。本综述综合了当前趋势，指出了关键局限性，并概述了未来研究方向，这些方向对于提高手术环境中人机协作的可靠性、安全性和有效性至关重要。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [303] [SECURE: Semantics-aware Embodied Conversation under Unawareness for Lifelong Robot Learning](https://arxiv.org/abs/2409.17755)
> *SECURE: 在无意识下进行语义感知具身对话的终身机器人学习*

*Rimvydas Rubavicius, Peter David Fagan, Alex Lascarides, Subramanian Ramamoorthy* | **Category: cs.RO, cs.AI, cs.CL** | **Updated: 2025-07-15**

**Keywords:** 具身对话, 语义分析, 机器人学习, 概念无意识, 数据效率

**Comment:** Published at 4th Conference on Lifelong Learning Agents (CoLLAs),
  2025

> **TL;DR:** SECURE是一种交互式机器人学习策略，通过具身对话和语义分析，使机器人在不了解关键概念的情况下也能完成任务，并在部署过程中学习新概念，提高数据效率。

**AI_Comments:** SECURE的创新点在于将具身对话和语义分析相结合，解决了机器人学习中“概念无意识”的挑战。这种方法使得机器人在面对未知情况时能够通过与用户的交互进行在线学习和适应，提高了机器人的自主学习能力和数据效率，对于终身机器人学习具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决机器人在执行任务时可能不了解关键概念（“无意识下的重新排列”），需要实时学习和适应的问题，例如识别未知物体属性。

**Method:** 提出SECURE策略，通过具身对话和语义分析，使机器人在处理对话和决策时能进行语义分析。SECURE代理通过对话调整其有缺陷的领域模型，识别并学习未预见的概念，并从用户的具身纠正反馈中学习。

**Result:** 在模拟的Blocksworld和真实世界的苹果操作环境中，SECURE代理在解决无意识下的重新排列任务时，比不进行具身对话或语义分析的代理更具数据效率。

**Conclusion:** SECURE通过具身对话和语义分析，有效解决了机器人在不了解关键概念的情况下进行任务学习的挑战，显著提高了学习效率和泛化能力。

> **ai_Abstract:** 本文提出了SECURE，一种用于解决机器人在执行任务时对关键概念“无意识”的交互式学习策略。SECURE通过使代理进行语义分析和具身对话，使其能够实时学习未知概念并纠正错误。实验证明，SECURE在模拟和真实世界环境中比传统方法更具数据效率，并能泛化到新任务。

> **摘要翻译:** 这篇论文解决了一个我们称之为“无意识下的重新排列”的挑战性交互式任务学习场景：代理必须在不知道解决任务所需关键概念的情况下操作刚体环境，并且必须在部署过程中学习它。例如，用户可能会要求“把两个史密斯奶奶苹果放进篮子里”，但代理无法正确识别环境中哪些物体是“史密斯奶奶”，因为它以前从未接触过这个概念。我们引入了SECURE，一个旨在解决此类场景的交互式任务学习策略。SECURE的独特之处在于它能够使代理在处理具身对话和做出决策时进行语义分析。通过具身对话，SECURE代理通过参与对话来调整其有缺陷的领域模型，以识别和学习以前未预见到的可能性。当出现错误时，SECURE代理会从用户的具身纠正反馈中学习，并策略性地参与对话以发现与任务相关的新概念的有用信息。这些能力使SECURE代理能够利用所学知识泛化到新任务。我们在模拟的Blocksworld和真实世界的苹果操作环境中证明，解决这种无意识下重新排列问题的SECURE代理比不进行具身对话或语义分析的代理更具数据效率。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [342] [Comparison of Localization Algorithms between Reduced-Scale and Real-Sized Vehicles Using Visual and Inertial Sensors](https://arxiv.org/abs/2507.11241)
> *视觉和惯性传感器在缩比和实车中定位算法的比较*

*Tobias Kern, Leon Tolksdorf, Christian Birkner* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 缩比车辆, 定位算法, 视觉惯性传感器, OpenVINS, 自定位

**Comment:** 

> **TL;DR:** 本文比较了视觉和视觉惯性定位算法在缩比车辆和实车上的性能，发现OpenVINS在两种情况下表现最佳，且缩比车辆可作为定位算法的测试平台。

**AI_Comments:** 本文的创新点在于系统性地比较了缩比车辆与实车在定位算法精度上的差异，并明确指出缩比车辆作为测试平台的可行性。这对于加速自动驾驶技术的研发具有重要意义，尤其是在成本和安全性方面。

<details>
  <summary>Details</summary>

**Motivation:** 为了加速先进自动驾驶功能的开发，物理缩比车辆正日益受到关注。本文旨在研究缩比对使用视觉和视觉-惯性算法的自定位精度的影响。

**Method:** 选择了兼容ROS2的视觉和视觉-惯性算法（OpenVINS、VINS-Fusion和RTAB-Map）。使用实车数据集作为基线，并进行了缩比车辆的测试数据记录。通过与真值和实车数据对比，评估了这些算法的位姿精度。

**Result:** OpenVINS在与实车相比时具有最低的平均定位误差，并且在应用于缩比车辆时也表现最佳。缩比车辆与实车在平移运动估计精度上存在细微差异，但在旋转运动估计精度上未发现显著差异。

**Conclusion:** 缩比车辆可以作为自定位算法的测试平台。

> **ai_Abstract:** 本文研究了缩比车辆对视觉和视觉-惯性自定位算法精度的影响，旨在评估其作为自动驾驶开发测试平台的可行性。研究对比了OpenVINS、VINS-Fusion和RTAB-Map在实车和缩比车辆上的性能。结果表明，OpenVINS在两种情况下均表现最佳，且缩比车辆与实车在旋转运动估计精度上无显著差异，证实了缩比车辆作为自定位算法测试平台的潜力。

> **摘要翻译:** 物理缩比车辆正在兴起，以加速先进自动驾驶功能的开发。在本文中，我们使用摄像头和惯性测量单元（IMU），研究了缩比对使用视觉和视觉-惯性算法的自定位精度的影响。为此，选择了兼容ROS2的视觉和视觉-惯性算法，并选择数据集作为实车基线。进行了试驾以记录缩比车辆的数据。我们比较了选定的定位算法，OpenVINS、VINS-Fusion和RTAB-Map，根据其位姿精度与真值和实车数据的对比。在比较所选定位算法在实车上的实现时，OpenVINS具有最低的平均定位误差。尽管所有选定的定位算法的误差范围都有重叠，但OpenVINS在应用于缩比车辆时也表现最佳。当缩比车辆与实车进行比较时，在平移车辆运动估计精度上发现了微小差异。然而，在比较旋转车辆运动估计精度时未发现显著差异，这使得缩比车辆可以作为自定位算法的测试平台。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [348] [BlueME: Robust Underwater Robot-to-Robot Communication Using Compact Magnetoelectric Antennas](https://arxiv.org/abs/2411.09241)
> *BlueME：使用紧凑型磁电天线的鲁棒水下机器人间通信*

*Mehron Talebi, Sultan Mahmud, Adam Khalifa, Md Jahidul Islam* | **Category: cs.RO, eess.SP** | **Updated: 2025-07-15**

**Keywords:** 水下通信, 磁电天线, 机器人间通信, VLF, 鲁棒性

**Comment:** 

> **TL;DR:** BlueME是一种紧凑型磁电天线阵列系统，可在水下实现鲁棒的机器人间通信，传输距离超过200米，功耗仅1瓦，并在恶劣水下条件下表现良好。

**AI_Comments:** 这项工作具有显著的创新性，因为它首次将磁电天线实际部署到水下环境中，并构建了迄今为止最大的VLF ME阵列系统。它解决了传统水下通信（声学和光学）在恶劣条件下表现不佳的痛点，为水下机器人和自动化提供了鲁棒、低功耗的通信解决方案，对于多机器人协作和远程传感器网络具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有水下通信方式（声学和光学）易受浑浊、障碍物和多径干扰影响。本文旨在开发一种鲁棒的水下机器人间通信系统。

**Method:** 本文设计、开发并实验验证了BlueME，一个紧凑型磁电(ME)天线阵列系统，该系统利用ME天线在其自然机械共振频率下工作，以高效传输和接收极低频(VLF)电磁信号。系统在低功耗嵌入式平台上进行了设计、仿真、制造和集成，并部署在自主水面航行器(ASV)和遥控潜水器(ROV)上进行开阔水域现场试验。

**Result:** BlueME在超过200米的距离上保持可靠的信号传输，功耗仅1瓦。系统在浑浊、障碍物和多径干扰等具有挑战性的水下条件下有效运行。研究还分析了完全浸没对系统性能的影响，并确定了关键的部署考虑因素。这是ME天线首次在实验室外进行实际水下部署，并实现了迄今为止最大的VLF ME阵列系统。

**Conclusion:** BlueME在多机器人协作系统和远程传感器网络中的海洋机器人技术和自动化领域显示出巨大潜力。

> **ai_Abstract:** 本文提出并验证了BlueME，一种紧凑型磁电(ME)天线阵列系统，专为水下机器人间通信设计。该系统利用ME天线在极低频下工作，实现了超过200米距离的可靠信号传输，且功耗仅1瓦。现场试验表明，BlueME在浑浊、障碍物和多径干扰等恶劣水下环境中表现出色，克服了传统声学和光学通信的局限性。这是ME天线首次在实验室外实际部署，展示了其在海洋机器人和自动化领域的巨大应用潜力。

> **摘要翻译:** 我们介绍了BlueME的设计、开发和实验验证，BlueME是一种用于水下机器人间通信的紧凑型磁电(ME)天线阵列系统。BlueME采用在其自然机械共振频率下工作的ME天线，以高效地在水下传输和接收极低频(VLF)电磁信号。我们概述了在低功耗嵌入式平台上提出的系统的设计、仿真、制造和集成，重点关注便携式和可扩展的应用。为了进行性能评估，我们在开阔水域现场试验中将BlueME部署在自主水面航行器(ASV)和遥控潜水器(ROV)上。我们的测试表明，BlueME在超过200米的距离上保持可靠的信号传输，同时仅消耗1瓦的功率。现场试验表明，该系统在浑浊、障碍物和多径干扰等通常影响声学和光学通信的挑战性水下条件下有效运行。我们的分析还检查了完全浸没对系统性能的影响，并确定了关键的部署考虑因素。这项工作代表了ME天线首次在实验室外进行实际水下部署，并实现了迄今为止最大的VLF ME阵列系统。BlueME在多机器人协作系统和远程传感器网络中的海洋机器人技术和自动化领域显示出巨大潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [362] [Mixed Discrete and Continuous Planning using Shortest Walks in Graphs of Convex Sets](https://arxiv.org/abs/2507.10878)
> *使用凸集图中最短路径的混合离散和连续规划*

*Savva Morozov, Tobia Marcucci, Bernhard Paus Graesdal, Alexandre Amice, Pablo A. Parrilo, Russ Tedrake* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 最短路径问题, 凸集图, 混合离散-连续规划, 机器人, 半定规划

**Comment:** 10 pages

> **TL;DR:** 该论文研究了凸集图（GCS）中的最短路径问题（SWP），旨在为机器人领域的混合离散-连续规划提供统一、高效的解决方案。它通过合成一个逐段二次下界来指导增量搜索算法，从而找到近似最短路径。

**AI_Comments:** 这篇论文提出了一种新颖的方法，旨在统一机器人领域中通常需要专门解决方案的各种混合离散-连续规划问题。利用凸集图和通过半定规划合成逐段二次下界是其创新之处。该框架有望提高广泛机器人应用的计算效率和性能。

<details>
  <summary>Details</summary>

**Motivation:** 该论文的动机是解决凸集图（GCS）中的最短路径问题（SWP），因为SWP在GCS中为许多机器人混合离散-连续规划问题提供了一种自然语言，能够统一通常需要专门解决方案的问题，同时提供高性能和计算效率。

**Method:** 该方法首先定义了凸集图（GCS），其中每个顶点与一个凸规划配对，每条边通过额外的成本和约束耦合相邻规划。然后，使用半定规划合成问题成本-到-目标函数的逐段二次下界。最后，使用该下界来指导增量搜索算法，以获得近似最短路径。

**Result:** 研究表明，GCS中的最短路径问题（SWP）是许多机器人混合离散-连续规划问题的自然语言，能够统一通常需要专门解决方案的问题，同时提供高性能和计算效率。通过在无碰撞运动规划、技能链和混合系统最优控制中的实验证明了这一点。

**Conclusion:** 该论文的结论是，凸集图中的最短路径问题为机器人领域的各种混合离散-连续规划问题提供了一个统一且高效的框架，并在不同应用领域得到了验证。

> **ai_Abstract:** 这篇论文探讨了凸集图（GCS）中的最短路径问题（SWP），其中每个顶点代表一个凸规划，边连接相邻规划。为了解决这个问题，作者利用半定规划开发了一个逐段二次下界，并以此指导增量搜索算法来寻找近似最短路径。该研究表明，GCS中的SWP为机器人领域中各种混合离散-连续规划挑战提供了一个统一、高性能且计算高效的框架，并通过在运动规划、技能链和混合系统控制中的应用得到了验证。

> **摘要翻译:** 我们研究凸集图（GCS）中的最短路径问题（SWP）。GCS是一种图，其中每个顶点都与一个凸规划配对，并且每条边通过额外的成本和约束将相邻规划耦合。GCS中的路径是顶点通过边连接的序列，其中顶点可以重复。路径的长度由相应凸规划的累积最优值给出。为了解决GCS中的SWP，我们首先使用半定规划合成问题成本-到-目标函数的逐段二次下界。然后我们使用这个下界来指导增量搜索算法，该算法产生近似最短路径。我们表明，GCS中的SWP是许多机器人混合离散-连续规划问题的自然语言，它统一了通常需要专门解决方案的问题，同时提供了高性能和计算效率。我们通过在无碰撞运动规划、技能链和混合系统最优控制中的实验证明了这一点。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [392] [Object-Centric Mobile Manipulation through SAM2-Guided Perception and Imitation Learning](https://arxiv.org/abs/2507.10899)
> *基于SAM2引导感知和模仿学习的以物体为中心的移动操作*

*Wang Zhicheng, Satoshi Yagi, Satoshi Yamamori, Jun Morimoto* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 移动操作, 模仿学习, 以物体为中心, SAM2, 泛化能力

**Comment:** 

> **TL;DR:** 本文提出了一种基于SAM2的以物体为中心的移动操作方法，解决了当前移动操作框架中导航与操作解耦导致性能下降的问题。该方法通过整合操作方向信息，显著提升了模仿学习在不同方向下的泛化能力和鲁棒性。

**AI_Comments:** 本文的创新点在于利用SAM2进行以物体为中心的感知，并巧妙地将操作方向信息融入模型，有效解决了传统移动操作中导航与操作解耦所带来的泛化性问题，为构建更通用、鲁棒的机器人操作系统提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 当前的移动操作框架通常将导航和操作解耦，导致在导航不精确或接近角度不对齐时性能下降。为了使移动机械臂能够从不同方向执行相同任务，需要一种能处理多样化方向的通用机器人模型。

**Method:** 提出了一种基于SAM2（一个用于图像可提示视觉分割的基础模型）的以物体为中心的方法。该方法将操作方向信息整合到模型中，以实现对相同任务在不同方向上的持续理解。模型部署在一个定制的移动机械臂上。

**Result:** 在不同方向角度下的抓取放置任务上进行了评估。与Action Chunking Transformer相比，本文模型在用不同接近角度的演示进行训练时，保持了卓越的泛化能力。

**Conclusion:** 这项工作显著增强了基于模仿学习的移动操作系统的泛化能力和鲁棒性。

> **ai_Abstract:** 本文提出了一种基于SAM2引导感知和模仿学习的以物体为中心的移动操作方法，旨在解决现有框架中导航与操作解耦导致的性能下降问题。通过将操作方向信息整合到模型中，该方法实现了从不同方向对任务的一致理解，从而提高了系统的泛化能力和鲁棒性。实验结果表明，在抓取放置任务中，该模型在不同接近角度下的泛化能力优于Action Chunking Transformer。

> **摘要翻译:** 模仿学习在移动操作领域是一个关键挑战。然而，当前的移动操作框架通常将导航和操作解耦，仅在到达特定位置后才执行操作。这可能导致在导航不精确时性能下降，特别是在接近角度不对齐时。为了使移动机械臂能够从不同方向执行相同任务（这是构建通用机器人模型的基本能力），我们提出了一种基于SAM2的以物体为中心的方法。SAM2是一个旨在解决图像中可提示视觉分割的基础模型，我们的方法将操作方向信息整合到模型中。我们的方法能够从不同方向持续理解相同任务。我们将模型部署在一个定制的移动机械臂上，并在不同方向角度下的抓取放置任务上进行了评估。与Action Chunking Transformer相比，我们的模型在用不同接近角度的演示进行训练时，保持了卓越的泛化能力。这项工作显著增强了基于模仿学习的移动操作系统的泛化能力和鲁棒性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [394] [Hi Robot: Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models](https://arxiv.org/abs/2502.19417)
> *Hi Robot: 开放式指令遵循的分层视觉-语言-动作模型*

*Lucy Xiaoyang Shi, Brian Ichter, Michael Equi, Liyiming Ke, Karl Pertsch, Quan Vuong, James Tanner, Anna Walling, Haohuan Wang, Niccolo Fusai, Adrian Li-Bell, Danny Driess, Lachy Groom, Sergey Levine, Chelsea Finn* | **Category: cs.RO, cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 通用机器人, 指令遵循, 视觉-语言模型, 分层模型, 开放世界

**Comment:** ICML 2025

> **TL;DR:** “Hi Robot”系统利用分层视觉-语言模型，使通用机器人能够理解复杂指令和反馈，执行开放世界任务。

**AI_Comments:** 该论文的创新点在于其分层视觉-语言-动作模型，它解决了现有机器人难以处理开放世界中复杂、开放式指令和情境化反馈的挑战。通过将高层推理与低层动作相结合，该系统显著提升了机器人的通用性和适应性，使其能够执行更贴近人类交互方式的复杂任务。

<details>
  <summary>Details</summary>

**Motivation:** 通用机器人难以在开放世界中处理复杂的指令、提示和实时反馈，并将其与物理世界情境相结合，现有直接指令遵循方法仅限于简单命令。

**Method:** 本文提出一个名为“Hi Robot”的系统，该系统采用分层视觉-语言模型（VLMs）。首先，系统对复杂提示和用户反馈进行高层推理，以推断出完成任务的最合适下一步；然后，通过低级动作执行该步骤。

**Result:** 该系统在单臂、双臂和双臂移动机器人等三种机器人平台上进行了评估，并成功演示了其处理清理凌乱桌面、制作三明治和杂货购物等复杂任务的能力。

**Conclusion:** “Hi Robot”系统通过其分层视觉-语言模型，显著提升了机器人在开放世界中理解和执行复杂、开放式指令并结合情境反馈的能力，使其能够应对更多样的现实世界任务。

> **ai_Abstract:** 本文提出了“Hi Robot”系统，一个利用分层视觉-语言-动作模型来增强通用机器人在开放世界中遵循复杂指令和处理情境反馈的能力。该系统首先对复杂的用户输入进行高层推理，以确定任务的下一步，然后通过低层动作执行。与传统直接指令遵循方法不同，该系统能够处理模糊或复杂的指令，并在任务执行中实时整合反馈。实验证明，该系统在多种机器人平台（单臂、双臂、双臂移动）上能成功执行如清理、制作三明治和购物等复杂任务。

> **摘要翻译:** 通用机器人在开放世界环境中执行各种不同任务时，不仅要能推理完成目标所需的步骤，还要能在任务执行过程中处理复杂的指令、提示甚至反馈。复杂的指令（例如“你能给我做一个素食三明治吗？”或“我不喜欢那个”）不仅需要物理执行各个步骤的能力，还需要将复杂的命令和反馈情境化地融入物理世界的能力。在这项工作中，我们描述了一个使用分层结构中的视觉-语言模型的系统，该系统首先对复杂的提示和用户反馈进行推理，以推断出最合适的下一步来完成任务，然后通过低级动作执行该步骤。与只能执行简单命令（“拿起杯子”）的直接指令遵循方法不同，我们的系统可以推理复杂的提示并在任务执行过程中融入情境反馈（“那不是垃圾”）。我们在包括单臂、双臂和双臂移动机器人在内的三种机器人平台上评估了我们的系统，展示了其处理清理凌乱桌面、制作三明治和杂货购物等任务的能力。视频可在 https://www.pi.website/research/hirobot 查看。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [399] [Development of an Autonomous Mobile Robotic System for Efficient and Precise Disinfection](https://arxiv.org/abs/2507.11270)
> *高效精准消毒自主移动机器人系统的开发*

*Ting-Wei Ou, Jia-Hao Jiang, Guan-Lin Huang, Kuu-Young Young* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 紫外线消毒, 移动机器人, 自动化, 病毒热点, COVID-19

**Comment:** Accepted to the IEEE International Conference on Systems, Man, and
  Cybernetics (SMC) 2025

> **TL;DR:** 开发了一种自主移动机器人系统，用于高效精准的紫外线消毒，通过关注病毒热点和优化剂量，显著缩短了消毒时间。

**AI_Comments:** 该研究的创新点在于将消毒重点放在病毒热点区域，并通过优化紫外线剂量来提高效率和精准度，这与以往侧重最大化紫外线覆盖的研究有所不同。该系统在应对公共卫生危机，尤其是在资源受限和劳动力短缺的情况下，具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** COVID-19疫情突显了医院环境中自动化消毒的迫切需求，以应对资源短缺和劳动力限制，并有效控制病毒传播，保障医护人员和患者安全。

**Method:** 提出了一种移动机器人紫外线消毒系统，该系统专注于病毒热点区域，优先对高风险区域进行消毒，并采用优化紫外线剂量的方法，确保所有表面获得足够的紫外线照射，同时显著减少消毒时间。

**Result:** 在两个典型的医院场景中，该方法在保持相同消毒效果的同时，分别将消毒时间减少了30.7%和31.9%。

**Conclusion:** 该自主移动紫外线消毒机器人系统能够显著提高消毒效率，减少消毒时间，同时保持消毒效果，尤其适用于应对疫情期间的消毒需求。

> **ai_Abstract:** 本文针对COVID-19疫情下医院消毒自动化的迫切需求，提出了一种新型自主移动机器人系统，用于高效精准的紫外线消毒。该系统创新性地关注病毒热点区域，通过优化紫外线剂量，确保高风险区域得到充分消毒，同时减少低风险区域的不必要照射。实验结果表明，在保持相同消毒效果的前提下，该系统能将消毒时间分别缩短30.7%和31.9%。

> **摘要翻译:** COVID-19大流行严重影响了公共卫生、医疗系统和日常生活，尤其是在资源短缺和劳动力有限的情况下。这场危机凸显了医院环境中自动化的迫切需求，特别是消毒，这对于控制病毒传播和提高医护人员及患者的安全至关重要。紫外线（UV）消毒以其高效性而闻名，已在医院环境中广泛采用。然而，现有的大多数研究侧重于最大化紫外线覆盖范围，而很少关注人类活动对病毒分布的影响。为了解决这个问题，我们提出了一种专注于病毒热点的移动机器人紫外线消毒系统。该系统优先对高风险区域进行消毒，并采用优化的紫外线剂量方法，以确保所有表面获得足够的紫外线照射水平，同时显著减少消毒时间。它不仅提高了消毒效率，还最大限度地减少了低风险区域的不必要暴露。在两个代表性的医院场景中，我们的方法在达到相同消毒效果的同时，分别将消毒时间减少了30.7%和31.9%。实验视频可在：https://youtu.be/wHcWzOcoMPM 查看。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [434] [Fast Non-Episodic Adaptive Tuning of Robot Controllers with Online Policy Optimization](https://arxiv.org/abs/2507.10914)
> *机器人控制器在线策略优化的快速非分段自适应调整*

*James A. Preiss, Fengze Xie, Yiheng Lin, Adam Wierman, Yisong Yue* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 在线策略优化, 机器人控制, 自适应调整, 四旋翼飞行器, M-GAPS

**Comment:** 11 pages, 9 figures

> **TL;DR:** M-GAPS是一种新的在线策略优化算法，用于在无分段、时变环境下快速调整机器人控制器参数，比现有方法更灵活、稳定、数据高效。

**AI_Comments:** 该论文的创新点在于提出了M-GAPS算法，解决了在非分段、时变环境下机器人控制器在线调整的挑战。它结合了模型基方法和在线策略优化，提供了比传统自适应控制更强的灵活性，同时比无模型强化学习更稳定和数据高效，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 研究在动力学、策略类别和最优目标均时变的无分段、无状态重置的单一轨迹设定下，机器人控制器参数的在线调整算法。

**Method:** 提出了一种名为M-GAPS的单轨迹基于模型的在线策略优化算法的实际实现，并对四旋翼飞行器状态空间和策略类别进行了重新参数化以改善优化前景。

**Result:** M-GAPS能更快地找到接近最优的参数，特别是在分段长度不理想时。它能快速适应未建模的强风和有效载荷扰动，并在1:6比例的阿克曼转向汽车上取得了类似的显著改进。

**Conclusion:** M-GAPS展示了在线策略优化这一新兴类别的硬件实用性，它比经典自适应控制更灵活，同时比无模型强化学习更稳定和数据高效。

> **ai_Abstract:** 该研究提出了一种名为M-GAPS的在线策略优化算法，用于在动力学、策略和目标均时变的无分段环境中快速调整机器人控制器参数。通过对四旋翼飞行器的实验，M-GAPS展现出比传统方法更快地找到最优参数、适应未知扰动的能力，并在不同机器人上通用。该方法结合了经典自适应控制的稳定性和无模型强化学习的数据效率，为在线机器人控制提供了一种实用且灵活的解决方案。

> **摘要翻译:** 我们研究了在线算法，用于在动力学、策略类别和最优目标都随时间变化的设置中调整机器人控制器参数。系统遵循单一轨迹，没有分段或状态重置，且时变信息不提前已知。以非线性几何四旋翼控制器作为测试案例，我们提出了一种名为M-GAPS的单轨迹基于模型的在线策略优化算法的实际实现，并对四旋翼状态空间和策略类别进行了重新参数化，以改善优化前景。在硬件实验中，我们将其与施加人工分段的基于模型和无模型的基线进行了比较。我们表明，M-GAPS能更快地找到接近最优的参数，特别是在分段长度不理想时。我们还表明，M-GAPS能快速适应未建模的强风和有效载荷扰动，并在1:6比例的阿克曼转向汽车上取得了类似的显著改进。我们的结果证明了这种新兴在线策略优化类别的硬件实用性，它比经典自适应控制提供了显著更大的灵活性，同时比无模型强化学习更稳定和数据高效。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [442] [RA-DP: Rapid Adaptive Diffusion Policy for Training-Free High-frequency Robotics Replanning](https://arxiv.org/abs/2503.04051)
> *RA-DP：用于免训练高频机器人重规划的快速自适应扩散策略*

*Xi Ye, Rui Heng Yang, Jun Jin, Yinchuan Li, Amir Rasouli* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 扩散策略, 机器人重规划, 免训练, 高频, 动态环境

**Comment:** Accepted by IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS) 2025

> **TL;DR:** 扩散模型在动态环境中适应性差，重规划受限。RA-DP提出一种免训练、高频的扩散策略，通过引导信号和动作队列实现快速适应，在重规划频率和成功率上优于现有方法。

**AI_Comments:** RA-DP的创新点在于其结合引导信号和动作队列机制，实现了训练自由且高频率的重规划能力，这对于机器人系统在未知动态环境中的实时适应性至关重要。其免训练特性大大降低了部署成本和复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在机器人任务学习中可扩展性强，但难以适应新颖、高度动态的环境。这主要是因为其重规划能力受限：要么采样耗时导致低频，要么在快速重规划时无法适应不可预见的反馈。

**Method:** 我们提出了RA-DP，一个新颖的扩散策略框架。该方法在扩散采样过程中整合了在新环境中容易获得的引导信号，并利用新颖的动作队列机制在每个去噪步骤生成重规划的动作而无需重新训练，从而形成了一个完整的免训练框架。

**Result:** RA-DP在公认的模拟基准和真实机器人任务中进行了广泛评估，结果表明其在重规划频率和成功率方面优于最先进的基于扩散的方法。此外，该框架理论上与任何免训练的引导信号兼容。

**Conclusion:** RA-DP通过提供免训练的高频重规划能力，有效解决了扩散模型在适应不可预见动态环境方面的局限性，其性能优于现有方法并展示了广泛的兼容性。

> **ai_Abstract:** 本文提出了RA-DP，一种新颖的免训练扩散策略框架，旨在解决现有扩散模型在机器人任务中适应动态环境时重规划能力受限的问题。RA-DP通过在扩散采样过程中整合易于获取的引导信号，并利用独特的动作队列机制在每个去噪步骤生成重规划动作，实现了高频、免训练的机器人运动适应。实验证明，RA-DP在重规划频率和成功率上优于当前最先进的扩散方法，并且理论上兼容任何免训练引导信号。

> **摘要翻译:** 扩散模型在机器人任务学习中展现出令人印象深刻的可扩展性，但它们难以适应新颖、高度动态的环境。这种限制主要源于其受限的重规划能力：它们要么由于耗时的迭代采样过程而以低频率运行，要么在快速重规划时无法适应不可预见的反馈。为了解决这些挑战，我们提出了RA-DP，一个新颖的扩散策略框架，具有免训练的高频重规划能力，解决了上述适应不可预见动态环境的限制。具体而言，我们的方法在扩散采样过程中整合了在新环境中通常容易获得的引导信号，并利用新颖的动作队列机制在每个去噪步骤生成重规划的动作而无需重新训练，从而形成了在未知环境中机器人运动适应的完整免训练框架。我们已经在公认的模拟基准和真实机器人任务中进行了广泛评估。结果表明，RA-DP在重规划频率和成功率方面优于最先进的基于扩散的方法。此外，我们证明了我们的框架在理论上与任何免训练的引导信号兼容。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [459] [Ocean Diviner: A Diffusion-Augmented Reinforcement Learning for AUV Robust Control in the Underwater Tasks](https://arxiv.org/abs/2507.11283)
> *海洋探测者：一种用于水下任务中AUV鲁棒控制的扩散增强强化学习*

*Weiyi Liu, Jingzehua Xu, Guanwen Xie, Yi Li* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-15**

**Keywords:** AUV控制, 强化学习, 扩散模型, 轨迹规划, 水下任务

**Comment:** 

> **TL;DR:** 本文提出了一种扩散增强强化学习方法，用于AUV在动态水下环境中进行鲁棒控制，通过扩散模型生成轨迹和引导探索，提高了规划能力和效率。

**AI_Comments:** 该论文的创新点在于将扩散模型引入强化学习，尤其是在轨迹生成和探索引导方面的结合，这有望显著提升AUV在复杂动态水下环境中的控制能力。其提出的高维状态编码和混合学习架构是值得关注的技术亮点。未来的工作可能需要关注实际部署中的挑战和效率。

<details>
  <summary>Details</summary>

**Motivation:** 解决水下轨迹规划和动态环境适应中的关键挑战，实现AUV的鲁棒控制。

**Method:** 提出了一种扩散增强强化学习（RL）方法。核心创新包括：1) 基于扩散的轨迹生成框架，结合高维状态编码（当前观测、历史状态和动作）通过新型扩散U-Net架构，提升长周期规划。2) 样本高效的混合学习架构，融合扩散引导探索和RL策略优化，扩散模型生成多样候选动作，RL评论家选择最优动作，提高探索效率和策略稳定性。

**Result:** 在广泛的仿真实验中验证了该方法的卓越鲁棒性和灵活性，在具有挑战性的海洋条件下优于传统控制方法，为AUV水下任务提供了增强的适应性和可靠性。

**Conclusion:** 扩散增强强化学习方法能有效提升AUV在复杂水下环境中的鲁棒控制能力、适应性和可靠性。

> **ai_Abstract:** 本文提出“海洋探测者”——一种扩散增强强化学习方法，旨在解决AUV水下轨迹规划和动态环境适应的挑战。该方法结合了基于扩散的轨迹生成（通过新型扩散U-Net增强长周期规划）和样本高效的混合学习架构（融合扩散引导探索与RL策略优化，提高探索效率和策略稳定性）。仿真实验表明，该方法在鲁棒性、灵活性、适应性和可靠性方面均优于传统控制方法，适用于复杂水下任务。

> **摘要翻译:** 本文提出了一种扩散增强强化学习（RL）方法，用于鲁棒的自主水下航行器（AUV）控制，解决了水下轨迹规划和动态环境适应中的关键挑战。所提出的方法整合了三个核心创新点：（1）一个基于扩散的轨迹生成框架，能够生成物理上可行的多步轨迹，并通过结合当前观测与历史状态和动作的新型扩散U-Net架构实现高维状态编码，显著改善了长周期规划。（2）一个样本高效的混合学习架构，将扩散引导探索与RL策略优化相结合，其中扩散模型生成多样化的候选动作，RL评论家选择最优动作，从而在动态水下环境中实现了更高的探索效率和策略稳定性。广泛的仿真实验验证了该方法卓越的鲁棒性和灵活性，在具有挑战性的海洋条件下优于传统控制方法，为AUV在水下任务中的操作提供了增强的适应性和可靠性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [471] [LLM-based ambiguity detection in natural language instructions for collaborative surgical robots](https://arxiv.org/abs/2507.11525)
> *基于LLM的协作手术机器人自然语言指令歧义检测*

*Ana Davila, Jacinto Colan, Yasuhisa Hasegawa* | **Category: cs.RO, cs.HC** | **Updated: 2025-07-15**

**Keywords:** LLM, 歧义检测, 手术机器人, 自然语言指令, 人机交互

**Comment:** Accepted at 2025 IEEE International Conference on Robot and Human
  Interactive Communication (ROMAN)

> **TL;DR:** 该研究提出了一种基于大型语言模型（LLM）的框架，用于检测协作手术机器人自然语言指令中的歧义，以提高人机协作的安全性。

**AI_Comments:** 该论文的创新点在于将LLM应用于手术机器人自然语言指令的歧义检测，并采用了LLM评估器集成和共形预测的独特方法。这对于提高安全关键领域的人机协作安全性具有重要意义。然而，60%的准确率在实际手术应用中可能仍需进一步提升。

<details>
  <summary>Details</summary>

**Motivation:** 在安全关键的人机交互中，尤其是在手术领域，自然语言指令中的歧义会带来重大风险。

**Method:** 该方法提出了一个使用大型语言模型（LLM）进行歧义检测的框架，专门为协作手术场景设计。它采用LLM评估器集成，每个评估器配置不同的提示技术，以识别语言、上下文、程序和关键歧义。一个思维链评估器被包含在内，用于系统地分析指令结构中潜在的问题。通过共形预测合成个体评估器的评估结果，根据与标记校准数据集的比较，得出非一致性分数。

**Result:** 评估Llama 3.2 11B和Gemma 3 12B，在区分模糊和清晰的手术指令方面，分类准确率超过60%。

**Conclusion:** 该方法通过在机器人动作之前识别潜在的模糊指令，提高了手术中人机协作的安全性和可靠性。

> **ai_Abstract:** 本研究提出了一种基于大型语言模型（LLM）的歧义检测框架，旨在解决协作手术机器人自然语言指令中的歧义问题。该框架利用LLM评估器集成，结合不同的提示技术和思维链评估器，以识别多种类型的歧义。通过共形预测合成评估结果，并与校准数据集进行比较。实验结果表明，该方法在使用Llama 3.2 11B和Gemma 3 12B时，在区分模糊与清晰的手术指令方面，分类准确率超过60%，显著提升了手术中人机协作的安全性和可靠性。

> **摘要翻译:** 自然语言指令中的歧义在安全关键的人机交互中构成重大风险，特别是在手术等领域。为了解决这个问题，我们提出了一个使用大型语言模型（LLM）进行歧义检测的框架，专门为协作手术场景设计。我们的方法采用LLM评估器集成，每个评估器配置不同的提示技术，以识别语言、上下文、程序和关键歧义。一个思维链评估器被包含在内，用于系统地分析指令结构中潜在的问题。通过共形预测合成个体评估器的评估结果，根据与标记校准数据集的比较，得出非一致性分数。评估Llama 3.2 11B和Gemma 3 12B，我们观察到在区分模糊和清晰的手术指令方面，分类准确率超过60%。我们的方法通过在机器人动作之前识别潜在的模糊指令，提高了手术中人机协作的安全性和可靠性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [476] [Unified Modeling and Structural Optimization of Multi-magnet Embedded Soft Continuum Robots for Enhanced Kinematic Performances](https://arxiv.org/abs/2507.10950)
> *多磁体嵌入式软连续体机器人统一建模与结构优化以提升运动学性能*

*Zhiwei Wu, Jiahao Luo, Siyi Wei, Jinhui Zhang* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 软连续体机器人, 磁体嵌入, 运动学性能, 结构优化, 可微分建模

**Comment:** 

> **TL;DR:** 本文提出了一个统一的建模和优化框架，用于提升多磁体嵌入式软连续体机器人的运动学性能，通过可微分系统公式和基于微分几何的结构优化，实现最佳磁体配置。

**AI_Comments:** 该论文的创新点在于提出了一个统一的、可微分的建模和优化框架，将软体机器人的运动学性能与内部磁体的结构配置紧密结合。通过引入微分几何和揭示可控自由度与磁体数量的关系，为软体机器人的设计提供了理论基础和优化工具，有助于实现更精确和高性能的软体机器人。其方法论具有通用性，有望应用于其他类似的软体驱动系统。

<details>
  <summary>Details</summary>

**Motivation:** 提升多磁体嵌入式软连续体机器人（MeSCRs）的运动学性能。

**Method:** 1. 建立基于扩展伪刚体模型的可微分系统公式，分析平衡适定性和磁驱动下诱导构型的几何形状。2. 证明MeSCRs的最大可控自由度等于嵌入磁体数量的两倍。3. 开发基于微分几何的结构优化框架，将经典运动学度量（如可操作性和灵巧性）与嵌入磁体的构型联系起来。4. 推导出代表性条件下的最优磁体配置闭式解。5. 提出一种针对通用设计场景的基于梯度的数值方法。

**Result:** 1. 建立了可微分系统公式，能够分析平衡适定性和磁驱动下诱导构型的几何形状。2. 揭示了MeSCRs的最大可控自由度是嵌入磁体数量的两倍。3. 优化条件表明，提高局部性能需要结构性地调节构型空间度量的谱以抵消其畸变。4. 在代表性条件下推导出了最优磁体配置的闭式解。5. 仿真研究验证了所提出框架的有效性。

**Conclusion:** 本文提出的统一建模和优化框架能够有效提升多磁体嵌入式软连续体机器人的运动学性能，通过结构优化实现最佳磁体配置。

> **ai_Abstract:** 本研究提出了一个统一的建模和优化框架，旨在提升多磁体嵌入式软连续体机器人（MeSCRs）的运动学性能。该框架基于扩展伪刚体模型建立了可微分系统公式，用于分析平衡和构型几何。研究发现MeSCRs的最大可控自由度是嵌入磁体数量的两倍。此外，还开发了基于微分几何的结构优化框架，将运动学性能与磁体构型关联起来，并推导出最优磁体配置的解析解和数值方法。仿真验证了该框架的有效性。

> **摘要翻译:** 本文提出了一个统一的建模和优化框架，旨在提升多磁体嵌入式软连续体机器人（MeSCRs）的运动学性能。为此，我们基于扩展伪刚体模型建立了一个可微分系统公式。该公式能够分析平衡的适定性以及磁驱动下诱导构型的几何形状。特别是，我们表明MeSCRs的最大可控自由度等于嵌入磁体数量的两倍。随后，我们开发了一个基于微分几何的结构优化框架，将经典的运动学度量（例如，可操作性和灵巧性）与嵌入磁体的构型联系起来。由此产生的优化条件揭示，提高局部性能需要结构性地调节构型空间度量的谱以抵消其畸变。在代表性条件下推导出了最优磁体配置的闭式解，并提出了一种针对通用设计场景的基于梯度的数值方法。仿真研究验证了所提出框架的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [498] [Grasping a Handful: Sequential Multi-Object Dexterous Grasp Generation](https://arxiv.org/abs/2503.22370)
> *抓取一把：序列多目标灵巧抓取生成*

*Haofei Lu, Yifei Dong, Zehang Weng, Florian Pokorny, Jens Lundell, Danica Kragic* | **Category: cs.RO, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 序列抓取, 多目标, 灵巧手, 扩散模型, 机器人抓取

**Comment:** 8 pages, 7 figures

> **TL;DR:** 提出了一种名为SeqGrasp的序列多目标机器人抓取采样算法，并基于其构建了大型数据集SeqDataset，用于训练扩散模型SeqDiffuser。实验证明SeqGrasp和SeqDiffuser在抓取成功率上显著优于现有方法，且SeqDiffuser生成速度快约1000倍。

**AI_Comments:** 该研究通过引入序列抓取概念和扩散模型，显著提升了多目标灵巧抓取任务的性能。其创新点在于将序列性引入抓取生成，并利用扩散模型实现了高效且高质量的抓取生成。速度的巨大提升是该方法的一个重要优势，使其在实际应用中更具潜力。构建的大规模数据集也为后续研究提供了宝贵资源。

<details>
  <summary>Details</summary>

**Motivation:** 为了使用机器人手的部分自由度（DoF）鲁棒地生成对多样化物体的稳定抓取。

**Method:** 提出了序列多目标机器人抓取采样算法SeqGrasp，并利用它构建了大规模的Allegro手序列抓取数据集SeqDataset。该数据集用于训练基于扩散的序列抓取生成器SeqDiffuser。在仿真和真实机器人上，将SeqGrasp和SeqDiffuser与现有最先进的非序列多目标抓取生成方法MultiGrasp进行了实验评估。

**Result:** SeqGrasp和SeqDiffuser的抓取成功率比MultiGrasp高出8.71%-43.33%。此外，SeqDiffuser在生成抓取时比SeqGrasp和MultiGrasp快约1000倍。

**Conclusion:** 所提出的SeqGrasp算法和基于SeqDataset训练的SeqDiffuser模型能够显著提高机器人多目标灵巧抓取成功率，并大幅提升抓取生成速度，优于现有方法。

> **ai_Abstract:** 该论文提出了一种名为SeqGrasp的序列多目标机器人抓取采样算法，旨在通过利用机器人手的有限自由度，鲁棒地生成对多种物体的稳定抓取。研究人员利用SeqGrasp构建了大型Allegro手序列抓取数据集SeqDataset，并基于该数据集训练了扩散模型SeqDiffuser。通过在仿真和真实机器人上的实验，将SeqGrasp和SeqDiffuser与现有最先进的非序列多目标抓取生成方法MultiGrasp进行比较。结果显示，SeqGrasp和SeqDiffuser的抓取成功率比MultiGrasp高出8.71%-43.33%，并且SeqDiffuser的抓取生成速度比其他两种方法快约1000倍。

> **摘要翻译:** 我们介绍了一种名为SeqGrasp的序列多目标机器人抓取采样算法，它能够利用机器人手的部分自由度（DoF）鲁棒地生成对多样化物体的稳定抓取。我们使用SeqGrasp构建了大规模的Allegro手序列抓取数据集SeqDataset，并将其用于训练基于扩散的序列抓取生成器SeqDiffuser。我们在仿真和真实机器人上，将SeqGrasp和SeqDiffuser与现有最先进的非序列多目标抓取生成方法MultiGrasp进行了实验评估。实验结果表明，SeqGrasp和SeqDiffuser的抓取成功率比MultiGrasp高出8.71%-43.33%。此外，SeqDiffuser在生成抓取时比SeqGrasp和MultiGrasp快约1000倍。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [522] [Diffusion-Based Imaginative Coordination for Bimanual Manipulation](https://arxiv.org/abs/2507.11296)
> *基于扩散的双手协调想象操纵*

*Huilin Xu, Jian Ding, Jiakun Xu, Ruixiang Wang, Jun Chen, Jinjie Mai, Yanwei Fu, Bernard Ghanem, Feng Xu, Mohamed Elhoseiny* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 双臂操作, 扩散模型, 视频预测, 动作预测, 机器人协调

**Comment:** 15 pages, including 10 figures and 16 tables. Accepted at ICCV 2025

> **TL;DR:** 提出了一种基于扩散的统一框架，用于双臂操作中的视频和动作预测，通过独特的设计在推理时省略视频预测，显著提高了效率和成功率。

**AI_Comments:** 这项工作在机器人双臂操作领域具有重要意义。其创新之处在于提出了一个统一的扩散式框架，并引入了单向注意力机制，使得在推理阶段可以去除计算量大的视频预测部分，从而在保证性能的同时显著提升了效率。实验结果的显著提升证明了该方法的有效性和实用性，特别是在真实世界场景中的表现令人印象深刻。这为未来的机器人协调控制提供了新的思路和强大的工具。

<details>
  <summary>Details</summary>

**Motivation:** 双臂操作在机器人技术中至关重要，但由于高维动作空间和复杂的协调要求而面临巨大挑战。尽管视频预测在表示学习和控制方面有所研究，但其在增强双臂协调方面的潜力尚未得到充分探索。

**Method:** 我们提出了一种统一的基于扩散的框架，用于视频和动作预测的联合优化。具体来说，我们提出了一种多帧潜在预测策略，将未来状态编码在压缩的潜在空间中，以保留任务相关特征。此外，我们引入了一种单向注意力机制，其中视频预测以动作为条件，而动作预测独立于视频预测。这种设计允许我们在推理期间省略视频预测，从而显著提高效率。

**Result:** 在两个模拟基准（ALOHA和RoboTwin）和一个真实世界设置中的实验表明，与强基线ACT相比，我们的方法在成功率上取得了显著提高，在ALOHA上增加了24.9%，在RoboTwin上增加了11.1%，在真实世界实验中增加了32.5%。

**Conclusion:** 该研究提出的基于扩散的统一框架通过联合优化视频和动作预测，并引入单向注意力机制，有效解决了双臂操作中的协调挑战，并在模拟和真实世界环境中显著提高了操作成功率。

> **ai_Abstract:** 本研究提出了一种用于双臂操作的统一扩散式框架，旨在解决高维动作空间和复杂协调的挑战。该框架联合优化视频和动作预测，采用多帧潜在预测策略来编码未来状态，并引入了一种单向注意力机制，使得在推理时可以省略视频预测，从而提高效率。实验结果表明，与现有基线相比，该方法在模拟和真实世界场景中显著提高了操作成功率。

> **摘要翻译:** 双臂操作在机器人技术中至关重要，能够在工业自动化和家庭服务中实现复杂任务。然而，由于高维动作空间和复杂的协调要求，它带来了巨大的挑战。尽管视频预测最近被研究用于表示学习和控制，利用其捕捉丰富动态和行为信息的能力，但其在增强双臂协调方面的潜力仍未得到充分探索。为了弥补这一差距，我们提出了一种统一的基于扩散的框架，用于视频和动作预测的联合优化。具体来说，我们提出了一种多帧潜在预测策略，将未来状态编码在压缩的潜在空间中，以保留任务相关特征。此外，我们引入了一种单向注意力机制，其中视频预测以动作为条件，而动作预测独立于视频预测。这种设计允许我们在推理期间省略视频预测，从而显著提高效率。在两个模拟基准和真实世界设置中的实验表明，与强基线ACT相比，我们的方法在成功率上取得了显著提高，在ALOHA上增加了24.9%，在RoboTwin上增加了11.1%，在真实世界实验中增加了32.5%。我们的模型和代码可在https://github.com/return-sleep/Diffusion_based_imaginative_Coordination 公开获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [527] [Whom to Respond To? A Transformer-Based Model for Multi-Party Social Robot Interaction](https://arxiv.org/abs/2507.10960)
> *回应谁？一个基于Transformer的多方社交机器人交互模型*

*He Zhu, Ryo Miyoshi, Yuki Okafuji* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 多方交互, 社交机器人, Transformer, 人机交互, 回应决策

**Comment:** 

> **TL;DR:** 在多方交互中，社交机器人需要决定回应谁。本文提出了一个基于Transformer的多任务学习框架，并设计了两种新的损失函数和一个新的数据集，以提高机器人的回应决策能力，实现了最先进的性能。

**AI_Comments:** 本文通过引入Transformer模型、设计针对多方HRI特点的创新损失函数以及构建贴近现实的新数据集，有效解决了社交机器人在复杂多用户环境中回应决策的关键问题。其贡献在于推动了社交机器人向更自然、上下文感知的多方交互能力发展，具有重要的实际应用价值和研究意义。

<details>
  <summary>Details</summary>

**Motivation:** 先前的HRI研究主要集中在单用户交互，而社交机器人在多方交互中（例如在商场和医院）必须理解上下文并决定何时以及回应谁。这是一个复杂且未充分解决的问题。

**Method:** 本文提出了一个基于Transformer的多任务学习框架，以改进社交机器人在多用户环境中的决策过程。考虑到HRI的特点，提出了两种新颖的损失函数：一个用于对活跃说话者施加约束以改进场景建模，另一个用于引导回应选择指向明确针对机器人的话语。此外，构建了一个新的多方HRI数据集，捕捉了现实世界的复杂性，例如凝视错位。

**Result:** 实验结果表明，该模型在回应决策方面实现了最先进的性能，优于现有的基于启发式和单任务的方法。

**Conclusion:** 研究结果有助于开发能够进行自然和上下文感知多方交互的社交智能机器人。

> **ai_Abstract:** 为了解决社交机器人在多方交互中“回应谁”的挑战，本文提出了一个基于Transformer的多任务学习框架。该框架引入了两种新颖的损失函数，分别用于改进场景建模和引导针对机器人的回应选择。同时，构建了一个新的多方HRI数据集以捕获现实世界的复杂性。实验证明，该模型在回应决策方面取得了最先进的性能，为开发更具社交智能的机器人提供了贡献。

> **摘要翻译:** 先前的类人机器人交互（HRI）研究主要集中在单用户交互，其中机器人不需要考虑其回应的时间或接收者。然而，在多方交互中，例如在商场和医院，社交机器人必须理解上下文并决定何时以及回应谁。在本文中，我们提出了一个基于Transformer的多任务学习框架，以改进社交机器人的决策过程，特别是在多用户环境中。考虑到HRI的特点，我们提出了两种新颖的损失函数：一个对活跃说话者施加约束以改进场景建模，另一个引导回应选择指向明确针对机器人的话语。此外，我们构建了一个新的多方HRI数据集，捕捉了现实世界的复杂性，例如凝视错位。实验结果表明，我们的模型在回应决策方面实现了最先进的性能，优于现有的基于启发式和单任务的方法。我们的发现有助于开发能够进行自然和上下文感知多方交互的社交智能机器人。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [544] [Characterizing gaussian mixture of motion modes for skid-steer vehicle state estimation](https://arxiv.org/abs/2505.00200)
> *针对滑移转向车辆状态估计的运动模式高斯混合特性表征*

*Ameya Salvi, Mark Brudnak, Jonathon M. Smereka, Matthias Schmid, Venkat Krovi* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-15**

**Keywords:** 滑移转向机器人, 状态估计, 高斯混合模型, 交互式多模型, 运动模型

**Comment:** 

> **TL;DR:** 本文针对滑移转向机器人运动模型不可靠的问题，提出了一种结合高斯混合模型和交互式多模型的状态估计算法，用于实时预测角速度。

**AI_Comments:** 这篇论文的创新点在于将高斯混合模型与交互式多模型相结合，以解决滑移转向机器人运动模型不可靠的问题。这种方法通过集成多个局部模型，有望提高状态估计的鲁棒性和实时性，对于滑移转向机器人的精确控制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 滑移转向轮式移动机器人(SSWMRs)的运动主要由轮胎-地形滑移主导，但缺乏可靠的摩擦模型导致运动模型不可靠，尤其是在用于状态估计和机器人控制的简化模型中。

**Method:** 本文采用基于高斯混合模型(GMM)的模型聚类识别方法，并将其在一个基于交互式多模型(IMM)的状态估计框架中实现。该框架被用于估计中型滑移转向轮式移动机器人平台的角速度。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对滑移转向轮式移动机器人因缺乏可靠摩擦模型而导致的运动模型不可靠问题，提出了一种基于高斯混合模型（GMM）识别模型簇的方法。该方法被整合到一个交互式多模型（IMM）状态估计算法中，旨在为机器人提供快速实时的角速度预测，以解决状态估计和控制中的挑战。该框架已在中型滑移转向机器人平台上实现。

> **摘要翻译:** 滑移转向轮式移动机器人（SSWMRs）的特点是其运动主要由轮胎-地形的滑移主导。缺乏可靠的摩擦模型导致运动模型不可靠，特别是用于状态估计和机器人控制的降阶变体。集成建模是一个新兴的研究方向，其中整体运动模型被分解为一系列局部模型，以分散性能和资源需求并提供快速实时预测。为此，本文采用并实现了一种基于高斯混合模型的模型聚类识别方法，并将其应用于基于交互式多模型（IMM）的状态估计中。该框架被用于估计中型滑移转向轮式移动机器人平台的角速度。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [584] [EquiContact: A Hierarchical SE(3) Vision-to-Force Equivariant Policy for Spatially Generalizable Contact-rich Tasks](https://arxiv.org/abs/2507.10961)
> *EquiContact：一种用于空间泛化接触密集任务的分层SE(3)视觉到力等变策略*

*Joohwan Seo, Arvind Kruthiventy, Soomi Lee, Megan Teng, Xiang Zhang, Seoyeon Choi, Jongeun Choi, Roberto Horowitz* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 接触密集任务, 空间泛化, SE(3)等变性, 分层策略, 插孔任务

**Comment:** Submitted to RA-L

> **TL;DR:** EquiContact提出了一种分层SE(3)等变策略，用于实现接触密集型机器人任务（如插孔任务）的空间泛化，在真实世界实验中表现出近乎完美的成功率和鲁棒泛化能力。

**AI_Comments:** 这篇论文通过引入SE(3)等变性、分层设计和局部策略，为机器人接触密集型任务的空间泛化提供了一个创新且高效的解决方案。其在少量演示数据下实现鲁棒泛化和近乎完美成功率的成果，对于机器人学习领域具有重要意义，尤其是在实际部署中减少训练数据需求方面。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉机器人策略在接触密集型操作任务中难以实现跨任务配置的空间泛化，尤其是在少量演示数据下。

**Method:** 本文提出了EquiContact，一个分层策略，由高层视觉规划器（Diffusion Equivariant Descriptor Field, Diff-EDF）和新型低层柔顺视觉运动策略（Geometric Compliant ACT, G-CompACT）组成。G-CompACT仅使用局部观察（几何一致误差向量、力-扭矩读数、腕部RGB图像），并在末端执行器坐标系中生成动作。整个EquiContact管线从感知到力控制都是SE(3)等变的。文章还提出了实现空间泛化接触密集策略的三个关键组成部分：柔顺性、局部策略和诱导等变性。

**Result:** 在插孔（PiH）任务上的实际实验表明，该框架实现了近乎完美的成功率，并对未见过的空间配置表现出鲁棒的泛化能力。

**Conclusion:** EquiContact框架及其提出的原理，通过SE(3)等变性、柔顺性和局部策略的设计，能够有效解决接触密集型机器人任务的空间泛化问题，并在实际应用中取得了显著成功。

> **ai_Abstract:** 本文介绍了EquiContact，一个用于接触密集型机器人操作任务的分层SE(3)等变视觉到力策略，旨在实现空间泛化。该策略结合了高层视觉规划器Diff-EDF和低层柔顺视觉运动策略G-CompACT。EquiContact通过局部观察和SE(3)等变设计，在少量演示下，在插孔任务中实现了对未见空间配置的近乎完美成功率和鲁棒泛化能力。

> **摘要翻译:** 本文提出了一个学习基于视觉的机器人策略的框架，用于在任务配置中实现空间泛化的接触密集型操作任务。我们专注于在少量演示数据训练的插孔（PiH）任务中实现策略的鲁棒空间泛化。我们提出了EquiContact，一个分层策略，由一个高层视觉规划器（Diffusion Equivariant Descriptor Field, Diff-EDF）和一个新型低层柔顺视觉运动策略（Geometric Compliant ACT, G-CompACT）组成。G-CompACT仅使用局部观察（几何一致误差向量（GCEV）、力-扭矩读数和腕部安装的RGB图像）并生成在末端执行器坐标系中定义的动作。通过这些设计选择，我们展示了整个EquiContact管线从感知到力控制都是SE(3)等变的。我们还概述了实现空间泛化接触密集策略的三个关键组成部分：柔顺性、局部策略和诱导等变性。在PiH任务上的实际世界实验证明了近乎完美的成功率和对未见过的空间配置的鲁棒泛化能力，验证了所提出的框架和原理。实验视频可在项目网站上找到：https://sites.google.com/berkeley.edu/equicontact

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [592] [All Eyes, no IMU: Learning Flight Attitude from Vision Alone](https://arxiv.org/abs/2507.11302)
> *全凭视觉，无需惯性测量单元：仅通过视觉学习飞行姿态*

*Jesse J. Hagenaars, Stein Stroobants, Sander M. Bohte, Guido C. H. E. De Croon* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 纯视觉飞行控制, 事件相机, 四旋翼无人机, 姿态估计, 神经网络

**Comment:** 

> **TL;DR:** 该研究提出了一种纯视觉的飞行控制方法，使用事件相机和循环卷积神经网络取代传统惯性测量单元，实现四旋翼无人机在通用环境下的姿态估计和飞行控制。

**AI_Comments:** 这项工作具有重要的创新性，它首次实现了在通用环境下纯视觉的飞行控制，成功替代了传统飞行器对IMU的依赖。其灵感来源于自然界中动物的视觉导航能力，并巧妙地利用了事件相机的高时间分辨率特性和神经网络的学习能力。这为开发更轻、更小、更节能的自主飞行机器人（特别是昆虫级机器人）开辟了新的可能性，具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 目前的飞行机器人严重依赖加速度计和陀螺仪进行姿态稳定，而许多飞行动物仅凭视觉就能实现姿态控制，有些甚至没有专门的重力感应。这项工作旨在开发一种仅基于视觉的飞行控制方法，以克服对惯性传感器的依赖，并为自主、昆虫级飞行机器人提供可能。

**Method:** 本研究提出了一种纯视觉的飞行控制方法。它使用一个配备向下事件相机的四旋翼无人机，通过事件流估计姿态和旋转速率。该方法采用一个小型循环卷积神经网络，通过监督学习进行训练。

**Result:** 真实世界的飞行测试表明，事件相机与低延迟神经网络的结合能够替代传统飞行控制回路中的惯性测量单元。研究还发现，具有记忆和类似地平线视觉线索的网络表现最佳，而视野较窄的变体则具有更好的相对泛化能力。

**Conclusion:** 该工作展示了纯视觉飞行控制作为实现自主、昆虫级飞行机器人的一个有前景的候选方案。

> **ai_Abstract:** 本研究提出了一种创新性的纯视觉飞行控制方法，旨在使四旋翼无人机摆脱对惯性测量单元（IMU）的依赖。通过结合向下事件相机和一个小型循环卷积神经网络，该系统能够仅从事件流中估计飞行姿态和旋转速率。实验证明，该方法能有效替代传统飞行控制中的IMU，并且在不同环境下表现出良好的泛化能力，为开发自主、微型飞行机器人提供了新的途径。

> **摘要翻译:** 视觉是许多飞行动物姿态控制的重要组成部分，其中一些动物没有专门的重力感应。另一方面，飞行机器人通常严重依赖加速度计和陀螺仪进行姿态稳定。在这项工作中，我们提出了首个用于通用环境的纯视觉飞行控制方法。我们展示了配备向下事件相机的四旋翼无人机仅通过事件流就能估计其姿态和旋转速率，从而实现在没有惯性传感器情况下的飞行控制。我们的方法使用一个通过监督学习训练的小型循环卷积神经网络。真实世界的飞行测试表明，事件相机和低延迟神经网络的结合能够替代传统飞行控制回路中的惯性测量单元。此外，我们还研究了网络在不同环境下的泛化能力，以及记忆和不同视野的影响。虽然具有记忆和能够获取类似地平线视觉线索的网络表现最佳，但视野较窄的变体实现了更好的相对泛化能力。我们的工作展示了纯视觉飞行控制作为实现自主、昆虫级飞行机器人的一个有前景的候选方案。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [593] [LVLM-MPC Collaboration for Autonomous Driving: A Safety-Aware and Task-Scalable Control Architecture](https://arxiv.org/abs/2505.04980)
> *LVLM-MPC协作实现自动驾驶：一种安全感知和任务可扩展的控制架构*

*Kazuki Atsuta, Kohei Honda, Hiroyuki Okuda, Tatsuya Suzuki* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-15**

**Keywords:** 自动驾驶, 大视觉语言模型, 模型预测控制, 任务可扩展性, 安全性

**Comment:** 8 pages, 8 figures

> **TL;DR:** 本文提出了一种结合大视觉语言模型（LVLM）和模型预测控制（MPC）的框架，旨在为自动驾驶提供任务可扩展性和安全性，通过MPC动态生成确保LVLM规划的可行性和安全性。

**AI_Comments:** 这项工作通过将LVLM的高级规划能力与MPC的低级控制精确性相结合，为自动驾驶领域提供了一个有前景的解决方案。其创新之处在于MPC Builder能够按需生成MPC并提供可行性反馈，有效弥补了LVLM在实际驾驶场景中可能存在的安全和一致性问题。该框架的“安全感知和任务可扩展”特性是其重要亮点，有望推动基础模型在自动驾驶中的实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 大视觉语言模型（LVLM）在高级任务规划方面表现出色，但其在自动驾驶中未能与低级运动规划的实际可行性保持一致，导致安全性和任务切换流畅性方面存在问题，因此需要一种方法来弥补这一差距。

**Method:** 本文将LVLM与MPC Builder集成，MPC Builder能够根据LVLM生成的符号任务指令按需自动生成MPC，同时确保最优性和安全性。生成的MPC通过提供任务可行性反馈和生成任务切换感知的MPC来协助LVLM驱动的任务切换的执行或拒绝。

**Result:** 通过模拟实验，作者证明了该方法能够安全有效地处理高速公路驾驶，同时保持LVLM的灵活性和适应性。

**Conclusion:** 该方法提供了一个安全、灵活、适应性强的控制框架，弥合了尖端基础模型与可靠车辆操作之间的鸿沟。

> **ai_Abstract:** 本文提出了一种将大视觉语言模型（LVLM）与模型预测控制（MPC）相结合的创新框架，旨在解决自动驾驶中LVLM在任务规划层面的安全性和可行性问题。该框架通过MPC Builder根据LVLM的高级指令动态生成MPC，从而确保低级运动规划的最优性和安全性，并能反馈任务的可行性。模拟实验验证了该方法在高速公路驾驶中的有效性，展示了其在提供安全可靠的车辆操作同时，保持LVLM固有的灵活性和任务可扩展性的能力。

> **摘要翻译:** 本文提出了一种新颖的大视觉语言模型（LVLM）与模型预测控制（MPC）集成框架，该框架为自动驾驶（AD）提供了任务可扩展性和安全性。LVLM在各种驾驶场景中的高级任务规划方面表现出色。然而，由于这些基础模型并非专为驾驶设计，并且它们的推理与低级运动规划的可行性不一致，因此在安全性和平滑任务切换方面仍存在担忧。本文将LVLM与MPC Builder集成，MPC Builder根据LVLM生成的符号任务指令按需自动生成MPC，同时确保最优性和安全性。生成的MPC通过提供给定任务的可行性反馈和生成任务切换感知的MPC，能够有力地协助LVLM驱动的任务切换的执行或拒绝。我们的方法提供了一个安全、灵活、适应性强的控制框架，弥合了尖端基础模型与可靠车辆操作之间的鸿沟。我们通过模拟实验证明了我们方法的有效性，表明我们的系统可以在保持LVLM灵活性和适应性的同时，安全有效地处理高速公路驾驶。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [635] [Context-Aware Deep Lagrangian Networks for Model Predictive Control](https://arxiv.org/abs/2506.15249)
> *用于模型预测控制的上下文感知深度拉格朗日网络*

*Lucas Schulze, Jan Peters, Oleg Arenz* | **Category: cs.RO, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 深度拉格朗日网络, 模型预测控制, 上下文感知, 在线系统辨识, 机器人控制

**Comment:** Accepted to the 2025 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS 2025)

> **TL;DR:** 本文提出了一种上下文感知的深度拉格朗日网络（DeLaN）与在线系统辨识和模型预测控制（MPC）相结合的方法，用于在复杂环境中实现自适应、物理一致的机器人控制，显著降低了轨迹跟踪误差。

**AI_Comments:** 这项工作创新性地将深度拉格朗日网络扩展为上下文感知模型，并通过在线系统辨识和MPC实现了在复杂环境下的自适应物理一致性控制。其结合残差动力学模型的设计也体现了对现有知识的有效利用。研究结果表明了其在机器人控制，尤其是在未知或变化负载条件下的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂环境中，由于潜在交互对象的数量庞大且物理属性不确定，单一的全局物理一致动态模型（如DeLaN）难以有效应用。因此，需要在线识别仅捕获当前相关环境方面的上下文感知模型，同时保持物理合理性以用于模型预测控制。

**Method:** 作者扩展了深度拉格朗日网络（DeLaN）使其具有上下文感知能力，并将其与循环网络结合进行在线系统辨识。该方法还与模型预测控制（MPC）集成，以实现自适应、物理一致的控制。此外，DeLaN与残差动力学模型相结合，以利用机器人已有的标称模型。

**Result:** 该方法在7自由度机械臂的变负载轨迹跟踪任务中，将末端执行器跟踪误差降低了39%，而使用扩展卡尔曼滤波的基线方法仅提高了21%。

**Conclusion:** 通过将上下文感知的深度拉格朗日网络与在线系统辨识和模型预测控制相结合，本文提出了一种有效的机器人控制方法，在复杂多变的环境中实现了显著的轨迹跟踪性能提升和物理一致性。

> **ai_Abstract:** 本文针对复杂环境中机器人控制中单一全局物理模型难以应用的挑战，提出了一种上下文感知深度拉格朗日网络（DeLaN）。该网络结合循环网络进行在线系统辨识，并与模型预测控制（MPC）集成，实现了自适应、物理一致的机器人控制。此外，还引入了残差动力学模型以利用现有机器人模型。实验结果表明，该方法在7自由度机械臂的轨迹跟踪任务中，将末端执行器误差显著降低了39%，优于基线方法。

> **摘要翻译:** 基于物理一致的动态模型（如深度拉格朗日网络，DeLaN）控制机器人，可以提高所得行为的泛化能力和可解释性。然而，在复杂环境中，可能交互的物体数量庞大，且其物理属性通常不确定。这种复杂性使得采用单一全局模型不可行。因此，我们需要诉诸于上下文感知模型的在线系统辨识，这些模型仅捕获环境中当前相关的方面。尽管物理原理（如能量守恒）在不同上下文中可能不成立，但确保任何单个上下文感知模型的物理合理性仍然是非常可取的，特别是在将其用于模型预测控制（MPC）等滚动视界控制方法时。因此，在这项工作中，我们扩展了DeLaN使其具有上下文感知能力，并将其与循环网络结合进行在线系统辨识，然后将其与MPC集成，以实现自适应、物理一致的控制。我们还将DeLaN与残差动力学模型结合，以利用机器人通常具有标称模型的事实。我们在一个7自由度机械臂上评估了我们的方法，用于在变负载下的轨迹跟踪。与使用扩展卡尔曼滤波的基线方法实现的21%的改进相比，我们的方法将末端执行器跟踪误差降低了39%。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [640] [SMART-Merge Planner: A Safe Merging and Real-Time Motion Planner for Autonomous Highway On-Ramp Merging](https://arxiv.org/abs/2507.10968)
> *SMART-Merge规划器：一种用于高速公路匝道汇入的实时安全汇入运动规划器*

*Toktam Mohammadnejad, Jovin D'sa, Behdad Chalaki, Hossein Nourkhiz Mahjoub, Ehsan Moradi-Pari* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-15**

**Keywords:** 高速公路汇入, 运动规划, 自动驾驶, 强制汇入, 实时规划

**Comment:** Accepted at IEEE ITSC 2025

> **TL;DR:** SMART-Merge规划器是一种基于格点的运动规划器，旨在实现高速公路匝道安全、舒适且快速的强制汇入，并在仿真中表现出100%的成功率和最短的汇入时间。

**AI_Comments:** 该论文提出了一种针对高速公路强制汇入场景的有效运动规划器。其创新点在于专门为强制汇入调整成本项和引入期望速度启发式，这对于处理现实世界中复杂的交通交互至关重要。100%的仿真成功率和最短汇入时间是其显著的优势，表明该方法在安全性和效率方面都表现出色。未来的工作可能涉及真实世界测试和更复杂的多车交互场景。

<details>
  <summary>Details</summary>

**Motivation:** 在高速公路上汇入是一项复杂的驾驶任务，需要识别安全间隙、调整速度、进行交互以创建汇入间隙，并在有限的时间窗内完成汇入操作，同时保持安全性和驾驶舒适性。现有技术可能难以有效处理强制汇入场景。

**Method:** 本文引入了SMART-Merge（安全汇入和实时汇入）规划器，这是一种基于格点的运动规划器。它通过特意调整成本项以适应强制汇入的独特挑战，并引入了期望速度启发式算法，使自动驾驶车辆能够成功汇入并最小化汇入时间。

**Result:** 通过在数百个高速公路汇入场景中进行高保真CarMaker仿真，验证了所提出的汇入规划器的效率和有效性。该规划器实现了100%的成功率，并且与基线相比，在最短的时间内完成了汇入操作。

**Conclusion:** SMART-Merge规划器能够处理复杂的强制汇入任务，并为自动驾驶高速公路汇入提供可靠且鲁棒的解决方案，表现出卓越的成功率和时间效率。

> **ai_Abstract:** 本研究提出了一种名为SMART-Merge的基于格点的运动规划器，专门用于解决高速公路匝道强制汇入的复杂挑战。该规划器通过优化成本项和引入期望速度启发式算法，旨在实现安全、舒适且高效的汇入。在CarMaker仿真中，SMART-Merge规划器在数百个高速公路汇入场景中表现出100%的成功率，并以最短的汇入时间优于基线方法，证明了其在自动驾驶汇入任务中的鲁棒性和有效性。

> **摘要翻译:** 汇入高速公路是一项复杂的驾驶任务，需要识别安全间隙、调整速度、通常进行交互以创建汇入间隙，并在有限的时间窗内完成汇入操作，同时保持安全性和驾驶舒适性。在本文中，我们介绍了一种安全汇入和实时汇入（SMART-Merge）规划器，这是一种基于格点的运动规划器，旨在促进安全舒适的强制汇入。通过特意调整成本项以适应强制汇入的独特挑战，并引入期望速度启发式算法，SMART-Merge规划器使自车能够成功汇入，同时最小化汇入时间。我们通过在数百个高速公路汇入场景中进行高保真CarMaker仿真，验证了所提出的汇入规划器的效率和有效性。我们提出的规划器实现了100%的成功率，并且与基线相比，在最短的时间内完成了汇入操作，展示了我们的规划器处理复杂强制汇入任务并为自动驾驶高速公路汇入提供可靠和鲁棒解决方案的能力。仿真结果视频可在https://sites.google.com/view/smart-merge-planner/home获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [662] [Acting and Planning with Hierarchical Operational Models on a Mobile Robot: A Study with RAE+UPOM](https://arxiv.org/abs/2507.11345)
> *移动机器人上基于分层操作模型的行动与规划：一项关于RAE+UPOM的研究*

*Oscar Lima, Marc Vinci, Sunandita Patra, Sebastian Stock, Joachim Hertzberg, Martin Atzmueller, Malik Ghallab, Dana Nau, Paolo Traverso* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 机器人, 行动规划, 分层操作模型, RAE+UPOM, 移动机器人

**Comment:** Accepted in ECMR 2025 conference

> **TL;DR:** 本文介绍并首次实际部署了一个集成的行动-规划系统RAE+UPOM，该系统在移动机械臂上使用分层操作模型进行行动和规划，并在存在动作失败和传感器噪声的情况下实现了鲁棒的任务执行。

**AI_Comments:** 本文的创新之处在于首次将一个共享分层操作模型的集成行动-规划系统（RAE+UPOM）实际部署到物理机器人上，并验证了其在复杂实际环境下的鲁棒性。这对于弥合高级规划与低级控制之间的差距具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 由于符号规划器模型与机器人实际运行的丰富控制结构之间存在不一致性，机器人任务执行面临挑战。

**Method:** 本文提出了一个集成的行动-规划系统RAE+UPOM，该系统共享分层操作模型用于行动和规划，并将反应式行动引擎（RAE）与一个类似UCT的蒙特卡洛规划器（UPOM）交错使用。该系统在一个移动机械臂上进行了实际部署，用于物体收集任务。

**Result:** 实验证明了在动作失败和传感器噪声下鲁棒的任务执行，并提供了关于交错行动与规划决策过程的经验性见解。

**Conclusion:** 该研究成功地在实际机器人上部署了一个共享分层操作模型的集成行动-规划系统，有效解决了传统符号规划与实际控制结构不一致的问题，并在复杂环境下实现了鲁棒的任务执行。

> **ai_Abstract:** 本研究首次实际部署了一个名为RAE+UPOM的集成行动-规划系统，旨在解决机器人符号规划与实际控制结构不一致的问题。该系统在移动机械臂上利用共享的分层操作模型进行行动和规划，并在物体收集任务中展现出在动作失败和传感器噪声下的鲁棒性，同时提供了关于其交错决策过程的经验性见解。

> **摘要翻译:** 由于符号规划器模型与机器人实际运行的丰富控制结构之间存在不一致性，机器人任务执行面临挑战。在本文中，我们首次实际部署了一个集成的行动-规划系统，该系统共享分层操作模型用于行动和规划，并将反应式行动引擎（RAE）与一个随时可用的类UCT蒙特卡洛规划器（UPOM）交错使用。我们在一个移动机械臂上实现了RAE+UPOM，用于实际世界中的物体收集任务。我们的实验证明了在动作失败和传感器噪声下鲁棒的任务执行，并提供了关于交错行动与规划决策过程的经验性见解。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [667] [Learning to Move in Rhythm: Task-Conditioned Motion Policies with Orbital Stability Guarantees](https://arxiv.org/abs/2507.10602)
> *学习有节奏地运动：具有轨道稳定性保证的任务条件运动策略*

*Maximilian Stölzle, T. Konstantin Rusch, Zach J. Patterson, Rodrigo Pérez-Dattari, Francesco Stella, Josie Hughes, Cosimo Della Santina, Daniela Rus* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-12**

**Keywords:** 轨道稳定运动基元, 周期性运动, 学习从演示, Hopf分岔, 机器人控制

**Comment:** 73 pages

> **TL;DR:** 本文提出了一种名为轨道稳定运动基元（OSMPs）的新框架，通过结合学习到的微分同胚编码器和潜在空间中的超临界Hopf分岔，能够从演示中精确学习周期性运动，并提供形式化的轨道稳定性保证。此外，通过任务条件化，该框架实现了对多个运动目标的表示和对未见任务的零样本泛化，并在多种机器人平台上表现出色。

**AI_Comments:** 该论文的创新点在于巧妙地将深度学习（微分同胚编码器）与动力系统理论（Hopf分岔、轨道稳定性）相结合，为机器人学习复杂周期性运动提供了一种新颖且严谨的方法。它不仅解决了传统方法在处理周期性行为上的局限性，更通过形式化的稳定性保证提升了方法的可靠性。此外，任务条件化实现了强大的零样本泛化能力，显著增强了策略的实用性和通用性，使其能够适应广泛的机器人应用。在多样化机器人平台上的成功验证也进一步凸显了其重要性和广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有的动态运动基元（DMPs）难以捕捉复杂的周期性行为，并且在不同任务间进行插值的能力有限，这大大限制了它们在诸如运动和有节奏工具使用等实际、有意义任务中的适用性。

**Method:** 本文引入了轨道稳定运动基元（OSMPs）框架。该框架结合了学习到的微分同胚编码器和潜在空间中的超临界Hopf分岔，以从演示中精确获取周期性运动，同时确保轨道稳定性和横向收缩的形式保证。此外，通过对双射编码器进行任务条件化，使单个学习策略能够表示多个运动目标。

**Result:** 该方法能够准确获取周期性运动，并提供轨道稳定性和横向收缩的形式保证。它实现了对训练分布内未见运动目标的零样本泛化。通过在协作机械臂、软机械手和仿生刚软海龟机器人等多种机器人平台上进行的广泛模拟和真实世界实验，验证了其多功能性和有效性，并始终优于扩散策略等现有基线。

**Conclusion:** 轨道稳定运动基元（OSMPs）框架通过结合学习编码器和Hopf分岔，成功解决了现有动态运动基元在处理复杂周期性行为和任务插值方面的局限性，实现了具有形式稳定保证的多任务周期性运动学习和泛化。

> **ai_Abstract:** 本文提出了一种名为轨道稳定运动基元（OSMPs）的新框架，旨在解决现有动态运动基元在学习复杂周期性行为和多任务泛化方面的不足。OSMPs通过结合学习到的微分同胚编码器与潜在空间中的超临界Hopf分岔，能够从演示中精确获取周期性运动，并提供严格的轨道稳定性和横向收缩保证。此外，通过对编码器进行任务条件化，该框架使单个学习策略能够表示和泛化到多个运动目标，包括未见过的任务。实验结果表明，OSMPs在多种机器人平台上表现出卓越的性能和多功能性，并优于现有先进方法。

> **摘要翻译:** 学习演示提供了一种样本高效的方法来获取复杂行为，使机器人能够稳健、柔顺和流畅地移动。在这种背景下，动态运动基元提供了内置的稳定性和对干扰的鲁棒性，但通常难以捕捉复杂的周期性行为。此外，它们在不同任务之间进行插值的能力也有限。这些缺点大大缩小了它们的适用范围，排除了诸如运动和有节奏工具使用等一类具有实际意义的任务。在这项工作中，我们引入了轨道稳定运动基元（OSMPs）——一个结合了学习到的微分同胚编码器和潜在空间中超临界Hopf分岔的框架，能够从演示中精确获取周期性运动，同时确保轨道稳定性和横向收缩的形式保证。此外，通过对双射编码器进行任务条件化，我们使单个学习策略能够表示多个运动目标，从而在训练分布内对未见过的运动目标产生一致的零样本泛化。我们通过广泛的模拟和真实世界实验在各种机器人平台（从协作机械臂和软机械手到仿生刚软海龟机器人）上验证了所提出的方法，展示了其多功能性和有效性，并且在性能上始终优于扩散策略等现有基线。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [684] [Sim2Real Diffusion: Learning Cross-Domain Adaptive Representations for Transferable Autonomous Driving](https://arxiv.org/abs/2507.00236)
> *Sim2Real扩散：学习跨域自适应表示以实现可迁移的自动驾驶*

*Chinmay Vilas Samak, Tanmay Vilas Samak, Bing Li, Venkat Krovi* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** Sim2Real, 扩散模型, 自动驾驶, 域适应, 表示学习

**Comment:** 

> **TL;DR:** 本文提出了一个统一的条件潜在扩散框架，用于学习跨域自适应表示，以解决现有Sim2Real迁移方法在自动驾驶中面临的挑战，并显著缩小感知Sim2Real差距。

**AI_Comments:** 这项研究的创新之处在于将条件潜在扩散模型引入Sim2Real迁移问题，特别是针对自动驾驶领域。它有效地解决了现有方法在域适应、小样本学习、模块化和实时性方面的痛点，并通过量化结果展示了扩散模型在该领域应用的巨大潜力。该框架的通用性和生成多样化样本的能力也增强了其在实际应用中的价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有Sim2Real迁移方法在处理自动驾驶的适应性、有限样本下的鲁棒性、多域表示的模块化以及实时性能方面存在困难。

**Method:** 本文提出了一个统一的框架，通过条件潜在扩散学习跨域自适应表示，用于Sim2Real可迁移自动驾驶算法。该框架利用替代基础模型、小样本微调管道以及文本和图像提示进行域映射，并能生成多样化的高质量样本。

**Result:** 所提出的框架能够将感知Sim2Real差距弥合40%以上，并通过性能基准、消融研究、定量指标和定性示例进行了系统分析。

**Conclusion:** 扩散模型在Sim2Real迁移中具有巨大潜力，能够有效弥合自动驾驶中的感知差距。

> **ai_Abstract:** 本文提出了“Sim2Real扩散”框架，利用条件潜在扩散学习跨域自适应表示，以解决自动驾驶中Sim2Real迁移的挑战。该框架通过整合替代基础模型、小样本微调和多模态提示，实现了鲁棒且模块化的性能。实验证明，该方法能将感知Sim2Real差距缩小超过40%，展示了扩散模型在自动驾驶Sim2Real迁移中的巨大潜力。

> **摘要翻译:** 基于仿真的自动驾驶算法设计、优化和验证多年来已被证明对其改进至关重要。然而，衡量其有效性的最终标准是它们从仿真到现实（sim2real）的成功过渡。然而，现有的sim2real迁移方法难以解决自动驾驶导向的要求，即平衡：（i）条件域适应，（ii）有限样本下的鲁棒性能，（iii）处理多个域表示的模块化，以及（iv）实时性能。为了缓解这些痛点，我们提出了一个统一的框架，通过条件潜在扩散学习跨域自适应表示，以实现sim2real可迁移的自动驾驶算法。我们的框架提供了以下选项：（i）利用替代基础模型，（ii）小样本微调管道，以及（iii）文本和图像提示，用于在给定源域和目标域之间进行映射。它还能够在跨参数空间（如一天中的时间、天气条件、季节和操作设计域）进行扩散时生成多样化的高质量样本。我们系统地分析了所提出的框架，并报告了在性能基准和消融研究方面的发现，包括关键的定量指标以及富有洞察力的定性示例和评论。此外，我们通过行为克隆案例研究展示了sim2real扩散在自动驾驶中的适用性。我们的实验表明，所提出的框架能够将感知sim2real差距弥合40%以上，这凸显了扩散模型在sim2real迁移中的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [688] [Vision Language Action Models in Robotic Manipulation: A Systematic Review](https://arxiv.org/abs/2507.10672)
> *机器人操作中的视觉语言动作模型：系统综述*

*Muhayy Ud Din, Waseem Akram, Lyes Saad Saoud, Jan Rosell, Irfan Hussain* | **Category: cs.RO** | **Updated: 2025-07-14**

**Keywords:** 视觉语言动作模型, 机器人操作, 系统综述, 数据集, 仿真平台

**Comment:** submitted to annual review in control

> **TL;DR:** 本文对机器人操作中的视觉语言动作（VLA）模型进行了系统综述，分析了102个模型、26个数据集和12个仿真平台，并提出了挑战和未来方向。

**AI_Comments:** 这篇综述论文的重要性在于它系统性地梳理了机器人操作领域视觉语言动作（VLA）模型的现状，涵盖了模型、数据集和仿真平台三个关键组成部分。其创新点在于引入了新的数据集评估标准和二维表征框架，揭示了数据格局中的空白。论文不仅总结了现有技术，还明确指出了未来的研究挑战和战略方向，为该领域的进一步发展提供了宝贵的路线图。

<details>
  <summary>Details</summary>

**Motivation:** 视觉语言动作（VLA）模型旨在将视觉感知、自然语言理解和具身控制统一在一个学习框架中，代表了机器人技术的一次变革性转变。本综述旨在对VLA范式进行全面且前瞻性的综合分析，重点关注机器人操作和指令驱动的自主性。

**Method:** 本综述全面分析了102个VLA模型、26个基础数据集和12个仿真平台。VLA模型被归类为关键的架构范式。基础数据集采用基于任务复杂性、模态多样性和数据集规模的新标准进行评估，并引入了一个二维表征框架，根据语义丰富性和多模态对齐来组织数据集。仿真环境的评估侧重于其生成大规模数据的有效性、从仿真到真实世界传输的能力以及支持任务的多样性。

**Result:** 综述识别了当前数据格局中未充分探索的区域，并指出了可扩展的预训练协议、模块化架构设计和鲁棒的多模态对齐策略等战略方向。

**Conclusion:** 本综述既可作为技术参考，也可作为推进具身和机器人控制的概念路线图，提供了从数据集生成到通用机器人智能体实际部署的见解。

> **ai_Abstract:** 本文对机器人操作领域的视觉语言动作（VLA）模型进行了系统综述。作者分析了102个VLA模型、26个基础数据集和12个仿真平台，对模型的架构范式、数据集的适用性（引入新评估标准和二维框架）以及仿真环境的有效性进行了评估。综述识别了现有挑战，并提出了未来研究的战略方向，旨在为VLA在具身和机器人控制领域的发展提供参考和路线图。

> **摘要翻译:** 视觉语言动作（VLA）模型代表了机器人技术的一次变革性转变，旨在将视觉感知、自然语言理解和具身控制统一在一个学习框架中。本综述对VLA范式进行了全面且前瞻性的综合分析，特别强调机器人操作和指令驱动的自主性。我们全面分析了102个VLA模型、26个基础数据集和12个仿真平台，它们共同塑造了VLA模型的开发和评估。这些模型被归类为关键的架构范式，每种范式都反映了在机器人系统中集成视觉、语言和控制的不同策略。基础数据集采用基于任务复杂性、模态多样性和数据集规模的新标准进行评估，从而可以对其适用于通用策略学习的程度进行比较分析。我们引入了一个二维表征框架，根据语义丰富性和多模态对齐来组织这些数据集，展示了当前数据格局中未充分探索的区域。仿真环境的评估侧重于其生成大规模数据的有效性、促进从仿真到真实世界传输的能力以及支持任务的多样性。通过结合学术界和工业界的贡献，我们认识到持续存在的挑战，并概述了战略方向，例如可扩展的预训练协议、模块化架构设计和鲁棒的多模态对齐策略。本综述既可作为技术参考，也可作为推进具身和机器人控制的概念路线图，提供了从数据集生成到通用机器人智能体实际部署的见解。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [696] [Uncertainty Aware Mapping for Vision-Based Underwater Robots](https://arxiv.org/abs/2507.10991)
> *面向视觉水下机器人的不确定性感知建图*

*Abhimanyu Bhowmik, Mohit Singh, Madhushree Sannigrahi, Martin Ludvigsen, Kostas Alexis* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 水下机器人, 不确定性感知, 视觉建图, 深度估计, Voxblox

**Comment:** Presented at the 2025 IEEE ICRA Workshop on Field Robotics

> **TL;DR:** 本文提出了一种不确定性感知建图方法，通过整合深度估计置信度并改进Voxblox框架，以应对水下视觉传感中的不确定性。

**AI_Comments:** 本文的创新点在于将深度估计置信度引入到水下视觉建图框架中，并对现有Voxblox的权重计算和更新机制进行了改进，以更好地处理水下环境中的不确定性。这对于在复杂水下环境中部署视觉机器人具有重要意义。然而，抽象中未提及定量分析结果，仅进行了定性分析。

<details>
  <summary>Details</summary>

**Motivation:** 传统传感器和预规划路径无法在狭窄空间中有效使用，且传感器噪声和环境变化会导致水下视觉机器人环境表示中存在显著不确定性。

**Method:** 本文探索了如何在基于视觉的感知中表示建图不一致性，并将深度估计置信度整合到建图框架中。使用RAFT-Stereo模型估计场景深度和置信度，并将其集成到基于体素的建图框架Voxblox中。同时提出了对现有Voxblox权重计算和更新机制的改进。

**Result:** 在狭窄水池和特隆赫姆峡湾的码头进行了所提方法的定性分析。使用水下机器人进行的实验证明了可视化中不确定性的变化。

**Conclusion:** 论文通过整合深度估计置信度并改进Voxblox框架，成功地在水下视觉建图中处理了不确定性，并在实验中展示了不确定性可视化的变化。

> **ai_Abstract:** 本研究旨在解决水下视觉机器人建图中的不确定性问题，尤其是在狭窄空间中。论文提出了一种方法，通过整合RAFT-Stereo模型估计的深度和置信度到改进的Voxblox框架中，来表示建图不一致性并处理不确定性。实验在受限水池和峡湾中进行，验证了所提出方法在不确定性可视化方面的有效性。

> **摘要翻译:** 基于视觉的水下机器人可用于检查和探索传统传感器和预规划路径无法遵循的狭窄空间。传感器噪声和情境变化可能导致环境表示中存在显著不确定性。因此，本文探讨了如何在基于视觉的感知中表示建图不一致性，并将深度估计置信度整合到建图框架中。场景深度和置信度使用RAFT-Stereo模型进行估计，并集成到基于体素的建图框架Voxblox中。还提出了对现有Voxblox权重计算和更新机制的改进。最后，在狭窄水池和特隆赫姆峡湾的码头对所提出的方法进行了定性分析。使用水下机器人进行的实验证明了可视化中不确定性的变化。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [702] [LF: Online Multi-Robot Path Planning Meets Optimal Trajectory Control](https://arxiv.org/abs/2507.11464)
> *LF：在线多机器人路径规划与最优轨迹控制相遇*

*Ajay Shankar, Keisuke Okumura, Amanda Prorok* | **Category: cs.RO, cs.MA** | **Updated: 2025-07-15**

**Keywords:** 多机器人导航, 路径规划, 轨迹控制, MAPF, 分层控制

**Comment:** 9 pages; under review for IEEE Robotics & Automation - Letters (RA-L)

> **TL;DR:** LF是一个用于多机器人点对点导航的框架，它结合了快速的多智能体路径规划和鲁棒的轨迹控制器，实现了可扩展、终身的多机器人导航。

**AI_Comments:** LF框架的创新之处在于其分层的规划和控制范式，将离散的多智能体路径规划与连续的机器人轨迹控制有效结合，解决了可扩展性和实时性之间的矛盾。这种解耦设计使得系统在面对动态环境和异步任务更新时表现出高度的鲁棒性和适应性。实际部署和大规模演示进一步验证了其在复杂真实世界场景中的实用性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 解决多机器人点对点导航任务，需要一个能够快速计算无碰撞路径并确保机器人可靠遵循路径的控制范式，尤其是在动态和异步更新的环境中。

**Method:** 提出LF框架，包含两个高频异步过程：(i) 一个中心化、离散、全视野规划器，利用MAPF计算无碰撞路径；(ii) 动态感知、机器人独立的最优轨迹控制器，确保机器人可靠地遵循指定路径。LF结合了先进的MAPF求解器LaCAM和鲁棒的反馈控制栈Freyja。

**Result:** LF提供了一个鲁棒且多功能的机制，用于终身多机器人导航，即使在异步和部分目标更新下也能适应，并通过快速重新规划适应动态工作空间。通过多旋翼和地面机器人演示，包括15个真实多旋翼在有人穿过操作空间时进行随机、连续目标更新的部署。

**Conclusion:** LF框架通过分层的规划表示，将离散耦合的路径规划与连续解耦的轨迹控制相结合，实现了可扩展、鲁棒且终身的多机器人导航，并能适应动态环境。

> **ai_Abstract:** 本文提出LF框架，一种用于多机器人点对点导航的控制范式。该框架结合了高频异步的中心化离散路径规划（基于MAPF）和动态感知的独立最优轨迹控制。这种分层方法使得系统能够实现长期可扩展的运动合成。LF通过整合LaCAM和Freyja，展示了在动态环境和异步目标更新下，实现鲁棒、多功能且终身多机器人导航的能力，并通过实际多旋翼和地面机器人演示进行了验证。

> **摘要翻译:** 我们提出了一种多机器人控制范式，用于解决具有完整环境信息的全向机器人团队的点对点导航任务。该框架以高频率异步调用两个过程：(i) 一个中心化、离散、全视野的规划器，利用多智能体路径查找（MAPF）的最新进展，快速计算无碰撞和无死锁的路径；(ii) 动态感知、机器人独立的最优轨迹控制器，确保所有机器人独立可靠地遵循其分配的路径。这种规划表示从（i）离散耦合到（ii）连续解耦领域的层次转变，使该框架能够维持长期可扩展的运动合成。作为这一思想的实例化，我们提出了LF，它结合了一个快速的先进MAPF求解器（LaCAM）和一个鲁棒的反馈控制栈（Freyja），用于执行敏捷的机器人机动。LF提供了一种鲁棒且多功能的机制，即使在异步和部分目标更新下也能实现终身多机器人导航，并且只需通过快速重新规划即可适应动态工作空间。我们展示了各种多旋翼和地面机器人演示，包括部署15个真实多旋翼，在一人穿过操作空间时进行随机、连续的目标更新。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [709] [Exteroception through Proprioception Sensing through Improved Contact Modeling for Soft Growing Robots](https://arxiv.org/abs/2507.10694)
> *通过改进接触建模实现软生长机器人的本体感觉感知外部环境*

*Francesco Fuentes, Serigne Diagne, Zachary Kingston, Laura H. Blumenschein* | **Category: cs.RO** | **Updated: 2025-07-14**

**Keywords:** 软生长机器人, 接触建模, 环境探索, 地图构建, 本体感觉

**Comment:** 22 pages, 21 figures, submitted to journal for potential publication

> **TL;DR:** 该研究通过改进软生长机器人的接触模型，使其能够利用自身变形来感知和映射未知环境，并在模拟中显示出快速接近理想探索行为的潜力。

**AI_Comments:** 该论文的创新点在于将软机器人的本体感觉（通过被动变形产生的接触信息）转化为外部环境感知。通过建立精确的接触模型和几何模拟器，实现了软生长机器人对未知环境的有效探索和地图构建。这对于传统机器人难以进入的复杂、非结构化环境具有重要意义，为软机器人的自主导航和应用开辟了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 软机器人的被动变形特性使其在非结构化环境中导航具有潜力。为了更好地利用软生长机器人进行环境理解和探索，需要更好地理解它们的碰撞和随后的变形行为。

**Method:** 首先，对软生长机器人在离散转弯时的碰撞行为进行特性化；然后，利用该模型开发一个基于几何的模拟器，用于建模机器人在二维环境中的轨迹；最后，通过使用蒙特卡洛采样估计最佳的下一次部署，验证了模型和模拟器在未知环境映射中的有效性。

**Result:** 在均匀和非均匀环境中，所提出的选择方法都能迅速接近理想的动作，显示出软生长机器人在非结构化环境探索和地图构建方面的潜力。

**Conclusion:** 通过改进接触建模，软生长机器人能够利用其被动变形进行外部环境感知和地图构建，在非结构化环境探索中展现出巨大潜力。

> **ai_Abstract:** 本研究提出利用软生长机器人作为环境映射和探索工具。通过改进接触模型来理解其碰撞和变形行为，研究人员开发了一个基于几何的模拟器，用于预测机器人在二维环境中的轨迹。利用蒙特卡洛采样，该系统能有效地映射未知环境并选择最佳部署策略。实验结果表明，该方法在不同环境中均能快速达到理想的探索效果，证实了软生长机器人在非结构化环境探索和地图构建方面的巨大潜力。

> **摘要翻译:** 被动变形由于柔顺性是软机器人常用的优点，提供了通过少量主动自由度实现鲁棒驱动的机会。特别是软生长机器人在非结构化环境导航中显示出潜力，这得益于其被动变形。如果能更好地理解它们的碰撞和随后的变形，软机器人就可以通过直接触觉测量来理解环境结构。在这项工作中，我们提出将软生长机器人用作地图绘制和探索工具。我们首先通过表征离散转弯期间的碰撞行为，然后利用该模型开发一个基于几何的模拟器，该模拟器模拟二维环境中的机器人轨迹。最后，我们通过使用蒙特卡洛采样来估计给定当前知识的最佳下一次部署，从而绘制未知环境地图，证明了模型和模拟器的有效性。在均匀和非均匀环境中，这种选择方法都迅速接近理想动作，显示出软生长机器人在非结构化环境探索和地图绘制方面的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [730] [RCG: Safety-Critical Scenario Generation for Robust Autonomous Driving via Real-World Crash Grounding](https://arxiv.org/abs/2507.10749)
> *RCG：基于真实世界碰撞接地的鲁棒自动驾驶安全关键场景生成*

*Benjamin Stoler, Juliet Yang, Jonathan Francis, Jean Oh* | **Category: cs.RO** | **Updated: 2025-07-14**

**Keywords:** 安全关键场景, 自动驾驶, 对抗性生成, 碰撞接地, 鲁棒性

**Comment:** 

> **TL;DR:** RCG框架通过整合碰撞语义生成逼真且高风险的安全关键场景，用于训练和评估自动驾驶系统，显著提高了系统的鲁棒性。

**AI_Comments:** RCG的创新之处在于其将真实世界碰撞数据中的语义信息融入到对抗性场景生成中，解决了传统方法难以生成逼真高风险场景的痛点。通过学习碰撞行为的嵌入表示，RCG能够产生更具说服力和多样性的对抗轨迹，对于提升自动驾驶系统的安全性和鲁棒性具有重要意义。该方法的普适性强，可整合到现有生成管道中。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶系统训练和评估所需的“安全关键场景”在真实世界驾驶数据中极为罕见。

**Method:** 提出RCG（Real-world Crash Grounding）框架，将碰撞信息语义整合到对抗性扰动管道中。通过在大规模驾驶日志上进行对比预训练，构建安全感知行为表示，然后在一个小型、富含碰撞数据的数据集上进行微调，该数据集的近似轨迹标注从视频中提取。这种嵌入捕获了与真实世界事故行为一致的语义结构，并支持选择高风险且行为真实的对抗轨迹。将这种选择机制整合到两个现有的场景生成管道中，用基于嵌入的准则取代手工设计的评分目标。

**Result:** 针对这些生成场景训练的自我代理在下游成功率上始终更高，在七个评估设置中平均提高了9.2%。定性和定量分析表明，该方法产生了更合理、更细致的对抗行为，从而能够对自动驾驶系统进行更有效、更真实的压力测试。

**Conclusion:** RCG框架通过生成逼真且高风险的安全关键场景，显著提高了自动驾驶系统的鲁棒性，并能进行更有效的压力测试。

> **ai_Abstract:** 本文提出了RCG（Real-world Crash Grounding）框架，旨在解决自动驾驶安全关键场景在真实数据中稀缺的问题。RCG通过对比预训练和微调，从真实世界碰撞数据中学习安全感知行为嵌入，从而生成高风险且行为真实的对抗性场景。实验证明，使用RCG生成的场景进行训练可显著提高自动驾驶系统的鲁棒性，平均成功率提升9.2%，并能进行更有效的系统压力测试。

> **摘要翻译:** 安全关键场景对于训练和评估自动驾驶（AD）系统至关重要，但在真实世界驾驶数据集中却极为罕见。为了解决这个问题，我们提出了真实世界碰撞接地（RCG）框架，该框架将碰撞信息语义整合到对抗性扰动管道中。我们通过在大规模驾驶日志上进行对比预训练，构建了一个安全感知行为表示，随后在一个小型、富含碰撞数据的数据集上进行微调，该数据集的近似轨迹标注从视频中提取。这种嵌入捕获了与真实世界事故行为一致的语义结构，并支持选择既高风险又行为真实的对抗轨迹。我们将由此产生的选择机制整合到两个先前的场景生成管道中，用基于嵌入的准则取代了它们手工设计的评分目标。实验结果表明，针对这些生成场景训练的自我代理在下游成功率上始终更高，在七个评估设置中平均提高了9.2%。定性和定量分析进一步表明，我们的方法产生了更合理、更细致的对抗行为，从而能够对自动驾驶系统进行更有效和更真实的压力测试。代码和工具将公开发布。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [732] [From Production Logistics to Smart Manufacturing: The Vision for a New RoboCup Industrial League](https://arxiv.org/abs/2507.11402)
> *从生产物流到智能制造：RoboCup工业新联赛的愿景*

*Supun Dissanayaka, Alexander Ferrein, Till Hofmann, Kosuke Nakajima, Mario Sanz-Lopez, Jesus Savage, Daniel Swoboda, Matteo Tschesche, Wataru Uemura, Tarik Viehmann, Shohei Yasuda* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** RoboCup, 智能制造, 工业机器人, 生产物流, 竞赛联赛

**Comment:** RoboCup Symposium 2025

> **TL;DR:** 本文提出了RoboCup智能制造联赛的愿景，这是一个新的RoboCup竞赛，旨在反映现代工厂的各个主要方面，以取代旧的RoboCup物流联赛，使其更具吸引力和相关性。

**AI_Comments:** 这篇论文提出了一个重要的转变，将RoboCup物流联赛扩展到更全面的智能制造领域。其创新之处在于通过引入多个独立且可合并的赛道，逐步构建一个复杂的智能工厂场景，从而提高了竞赛对行业最新发展的反映程度和吸引力。这对于推动工业机器人和智能制造领域的研究和发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** RoboCup物流联赛虽然专注于生产物流，但未能反映智能制造领域的最新发展，导致其相关性逐年减弱。因此，需要一个新的竞赛来涵盖现代工厂的各个主要方面。

**Method:** 提出了RoboCup智能制造联赛，这是一个设计为更大的智能制造场景的新竞赛。它将包含最初独立但逐渐合并的多个赛道，涵盖工业机器人挑战，如装配、人机协作和人形机器人，同时保留对生产物流的关注。

**Result:** 预计重新构想的竞赛将对新参与者和经验丰富的团队更具吸引力，并将重点转向工业机器人当前和未来的挑战。

**Conclusion:** RoboCup智能制造联赛旨在通过反映现代工厂的各个主要方面，提高竞赛的吸引力和相关性，以应对工业机器人领域的当前和未来挑战。

> **ai_Abstract:** 本文提出了RoboCup智能制造联赛的愿景，旨在取代日益失去相关性的RoboCup物流联赛。新的联赛将构建一个更全面的智能制造场景，涵盖生产物流、工业机器人装配、人机协作和人形机器人等多个独立但最终整合的赛道，以反映现代工厂的最新发展和挑战，从而吸引更多参与者并提升竞赛的吸引力。

> **摘要翻译:** RoboCup物流联赛是RoboCup一项在智能工厂场景中进行的竞赛，主要关注任务规划、作业调度和多智能体协调。对生产物流的关注使得团队能够开发出极具竞争力的策略，但也意味着智能制造领域的一些最新发展未能体现在竞赛中，从而削弱了其多年来的相关性。在本文中，我们描述了RoboCup智能制造联赛的愿景，这是一项旨在作为一个更大的智能制造场景而设计的新竞赛，反映了现代工厂的所有主要方面。它将由几个最初独立但逐渐合并为一个智能制造场景的赛道组成。新的赛道将涵盖工业机器人挑战，如装配、人机协作和人形机器人，但也将保留对生产物流的关注。我们期望重新构想的竞赛对新参与者和经验丰富的团队更具吸引力，同时也将重点转移到工业机器人当前和未来的挑战上。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [733] [A Survey: Learning Embodied Intelligence from Physical Simulators and World Models](https://arxiv.org/abs/2507.00917)
> *一项综述：基于物理模拟器和世界模型的具身智能学习*

*Xiaoxiao Long, Qingrui Zhao, Kaiwen Zhang, Zihao Zhang, Dingrui Wang, Yumeng Liu, Zhengjie Shu, Yi Lu, Shouzheng Wang, Xinzhe Wei, Wei Li, Wei Yin, Yao Yao, Jia Pan, Qiu Shen, Ruigang Yang, Xun Cao, Qionghai Dai* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 具身智能, 物理模拟器, 世界模型, 机器人, 综述

**Comment:** 49pages, 25figures, 6tables, github repository avalible in
  https://github.com/NJU3DV-LoongGroup/Embodied-World-Models-Survey

> **TL;DR:** 本综述系统回顾了通过整合物理模拟器和世界模型来学习具身智能的最新进展，分析了它们在增强机器人自主性、适应性和泛化能力方面的互补作用。

**AI_Comments:** 本文作为一篇综述，系统性地梳理了具身智能领域中物理模拟器和世界模型的关键作用。其创新之处在于对这两种技术的协同作用进行了深入分析，并指出了未来研究的开放挑战，为研究人员提供了宝贵的指导。对于推动具身AI从模拟环境走向真实世界部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人工通用智能（AGI）的追求使具身智能成为机器人研究的前沿。实现强大的具身智能不仅需要先进的感知和控制，还需要将抽象认知根植于现实世界交互的能力。物理模拟器和世界模型是实现这一目标的关键推动技术。

**Method:** 本综述系统地回顾了通过整合物理模拟器和世界模型来学习具身AI的最新进展。分析了它们在增强智能机器人自主性、适应性和泛化能力方面的互补作用，并讨论了外部模拟和内部建模之间在弥合模拟训练与现实世界部署之间差距的相互作用。

**Result:** 综述分析了物理模拟器和世界模型在增强智能机器人自主性、适应性和泛化能力方面的互补作用，并讨论了外部模拟和内部建模在弥合模拟训练与现实世界部署之间差距的相互作用。

**Conclusion:** 本综述旨在通过综合当前进展和识别开放挑战，为实现更强大、更具泛化能力的具身AI系统提供一个全面的视角。

> **ai_Abstract:** 本综述探讨了具身智能在机器人研究中的重要性，以及物理模拟器和世界模型作为实现具身智能的关键技术。文章系统回顾了如何通过整合这两种技术来学习具身AI的最新进展，分析了它们在提升机器人自主性、适应性和泛化能力方面的互补作用，并讨论了模拟训练与现实世界部署之间的差距弥合。旨在为开发更强大、更具泛化能力的具身AI系统提供全面的视角。

> **摘要翻译:** 对人工通用智能（AGI）的追求已将具身智能置于机器人研究的前沿。具身智能关注的是能够在物理世界中感知、推理和行动的智能体。实现强大的具身智能不仅需要先进的感知和控制，还需要将抽象认知根植于现实世界交互的能力。物理模拟器和世界模型这两种基础技术已成为实现这一目标的关键推动因素。物理模拟器为机器人智能体的训练和评估提供了受控、高保真度的环境，从而可以安全高效地开发复杂行为。相比之下，世界模型赋予机器人对其周围环境的内部表征能力，使其能够进行预测性规划和超越直接感官输入的自适应决策。本综述系统地回顾了通过整合物理模拟器和世界模型来学习具身AI的最新进展。我们分析了它们在增强智能机器人自主性、适应性和泛化能力方面的互补作用，并讨论了外部模拟和内部建模之间在弥合模拟训练与现实世界部署之间差距的相互作用。通过综合当前进展和识别开放挑战，本综述旨在为实现更强大、更具泛化能力的具身AI系统提供一个全面的视角。我们还维护着一个活跃的存储库，其中包含最新的文献和开源项目，网址为https://github.com/NJU3DV-LoongGroup/Embodied-World-Models-Survey。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [752] [ILCL: Inverse Logic-Constraint Learning from Temporally Constrained Demonstrations](https://arxiv.org/abs/2507.11000)
> *ILCL：从时间约束演示中学习逆逻辑约束*

*Minwoo Cho, Jaehwi Jang, Daehyung Park* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 逆逻辑约束学习, 时间约束, 强化学习, 演示学习, 遗传算法

**Comment:** 8 pages, 6 figures

> **TL;DR:** 提出ILCL，一种通过博弈论方法从演示中学习时间逻辑约束的新方法，在多个任务和真实世界应用中表现优于现有技术。

**AI_Comments:** 这篇论文通过将时间逻辑约束学习问题转化为一个零和博弈，提供了一种创新的解决方案，结合了遗传算法和强化学习的优势。其亮点在于无需预定义模板即可构建逻辑语法树，并通过约束再分配方案有效处理约束。成功应用于真实世界任务进一步验证了其重要性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决从演示中学习时间约束以重现类似演示的逻辑约束行为的问题，因为现有方法面临组合空间大和非马尔可夫约束不适定等挑战。

**Method:** 提出逆逻辑约束学习（ILCL），将其构建为一个零和博弈，包含两部分：1) 基于遗传算法的时间逻辑挖掘（GA-TL-Mining），用于高效构建参数化截断线性时间逻辑（TLTL）的语法树；2) 逻辑约束强化学习（Logic-CRL），通过新颖的约束再分配方案在构建的TLTL约束下找到最大化任务奖励的策略。

**Result:** 评估显示ILCL在四个时间约束任务上学习和转移时间逻辑（TL）约束方面优于最先进的基线方法。此外，还成功地将其迁移到真实世界的浅孔插销任务中。

**Conclusion:** ILCL是一种有效且鲁棒的从时间约束演示中学习逆逻辑约束的方法，在合成和真实世界任务中均表现出色，解决了时间约束学习的挑战。

> **ai_Abstract:** 本文提出了一种新颖的逆逻辑约束学习（ILCL）方法，旨在解决从时间约束演示中学习逻辑约束的挑战。ILCL将学习过程框架为基于遗传算法的时间逻辑挖掘（GA-TL-Mining）与逻辑约束强化学习（Logic-CRL）之间的零和博弈。GA-TL-Mining负责高效构建参数化截断线性时间逻辑（TLTL）的语法树，而Logic-CRL则在这些约束下优化策略。实验结果表明，ILCL在多个时间约束任务上优于现有技术，并成功应用于真实世界的机器人任务。

> **摘要翻译:** 我们旨在解决从演示中学习时间约束的问题，以重现类似演示的逻辑约束行为。由于可能的规范的组合空间巨大以及非马尔可夫约束的不适定性，学习逻辑约束具有挑战性。为了解决这个问题，我们引入了一种新颖的时间约束学习方法，我们称之为逆逻辑约束学习（ILCL）。我们的方法将ICL（应为ILCL）构建为一个双人零和博弈，介于1) 基于遗传算法的时间逻辑挖掘（GA-TL-Mining）和2) 逻辑约束强化学习（Logic-CRL）之间。GA-TL-Mining无需预定义模板即可高效构建参数化截断线性时间逻辑（TLTL）的语法树。随后，Logic-CRL通过一种新颖的约束再分配方案，在构建的TLTL约束下找到最大化任务奖励的策略。我们的评估表明，ILCL在四个时间约束任务上学习和转移TL约束方面优于最先进的基线方法。我们还展示了成功迁移到真实世界的浅孔插销任务。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [758] [rt-RISeg: Real-Time Model-Free Robot Interactive Segmentation for Active Instance-Level Object Understanding](https://arxiv.org/abs/2507.10776)
> *rt-RISeg: 实时无模型机器人交互式分割用于主动实例级对象理解*

*Howard H. Qian, Yiting Chen, Gaotian Wang, Podshara Chanrungmaneekul, Kaiyu Hang* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-14**

**Keywords:** 机器人交互式分割, 未知对象实例分割, 实时, 无模型, 主体帧不变特征

**Comment:** 8 pages, IROS 2025, Interactive Perception, Segmentation, Robotics,
  Computer Vision

> **TL;DR:** rt-RISeg是一个实时的、无模型的机器人交互式分割框架，通过机器人交互和分析设计的主体帧不变特征来连续分割未知对象，性能优于现有方法。

**AI_Comments:** 这项研究通过引入机器人交互和无模型的分割方法，创新性地解决了未知对象实例分割中泛化能力差的问题。其核心在于利用机器人与环境的动态交互来提取对象特征，而非依赖静态视觉数据训练模型，这大大增强了系统在未知环境中的适应性。实时更新分割掩膜的能力对于实际机器人操作任务至关重要。此外，其作为独立框架又能与视觉基础模型结合的能力，显示了其潜在的广泛应用前景和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的未知对象实例分割(UOIS)方法依赖于大规模数据集训练模型，容易过拟合静态视觉特征，导致在分布外场景中泛化性能差。本文旨在解决这一限制。

**Method:** 提出了一种名为rt-RISeg的实时交互式感知框架，通过机器人交互和分析设计的主体帧不变特征(BFIF)来连续分割未知对象。该方法利用随机采样主体帧的相对旋转和平移速度来识别对象，无需任何学习过的分割模型，并在机器人交互过程中实时生成和更新对象分割掩膜。

**Result:** rt-RISeg的平均对象分割准确率比最先进的UOIS方法高出27.5%。此外，其自主生成的分割掩膜可以作为视觉基础模型的提示，显著提高性能。

**Conclusion:** rt-RISeg通过利用机器人交互和主体帧不变特征，提供了一种实时、无模型的未知对象实例分割方法，显著提高了分割精度和泛化能力，并能与视觉基础模型结合使用。

> **ai_Abstract:** 本文提出了一种名为rt-RISeg的实时、无模型机器人交互式分割框架，旨在解决现有未知对象实例分割(UOIS)方法在泛化性上的局限。rt-RISeg通过机器人交互和分析主体帧不变特征(BFIF)来连续识别和分割未知对象，无需预训练模型。实验证明，rt-RISeg在对象分割准确率上比现有SOTA方法高出27.5%，且其生成的分割掩膜可有效作为视觉基础模型的提示，进一步提升性能。

> **摘要翻译:** 在新的环境中成功执行灵巧的机器人操作任务（例如抓取）取决于能够熟练地将未知对象从背景和其他对象中分割出来的能力。以前的未知对象实例分割（UOIS）工作在大规模数据集上训练模型，这通常导致对静态视觉特征的过拟合。这种依赖性导致在面对分布外场景时泛化性能不佳。为了解决这一限制，我们基于视觉本质上是交互性的并随时间发生的原理，重新思考了UOIS任务。我们提出了一种新颖的实时交互式感知框架rt-RISeg，它通过机器人交互和分析设计的主体帧不变特征（BFIF）来连续分割未知对象。我们证明了通过选定的机器人交互产生的随机采样主体帧的相对旋转和平移速度可以用于识别对象，而无需任何学习到的分割模型。这种完全独立的分割管道在每次机器人交互过程中生成并更新对象分割掩膜，而无需等待动作完成。我们展示了所提出的交互式感知方法的有效性，其平均对象分割准确率比最先进的UOIS方法高出27.5%。此外，尽管rt-RISeg是一个独立的框架，但我们表明自主生成的分割掩膜可以作为视觉基础模型的提示，从而显著提高性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [782] [RoboBrain 2.0 Technical Report](https://arxiv.org/abs/2507.02029)
> *RoboBrain 2.0 技术报告*

*BAAI RoboBrain Team, Mingyu Cao, Huajie Tan, Yuheng Ji, Minglan Lin, Zhiyu Li, Zhou Cao, Pengwei Wang, Enshen Zhou, Yi Han, Yingbo Tang, Xiangqi Xu, Wei Guo, Yaoxu Lyu, Yijie Xu, Jiayu Shi, Mengfei Du, Cheng Chi, Mengdi Zhao, Xiaoshuai Hao, Junkai Zhao, Xiaojie Zhang, Shanyu Rong, Huaihai Lyu, Zhengliang Cai, Yankai Fu, Ning Chen, Bolun Zhang, Lingfeng Zhang, Shuyi Zhang, Dong Liu, Xi Feng, Songjing Wang, Xiaodan Liu, Yance Jiao, Mengsi Lyu, Zhuo Chen, Chenrui He, Yulong Ao, Xue Sun, Zheqi He, Jingshu Zheng, Xi Yang, Donghai Shi, Kunchang Xie, Bochao Zhang, Shaokai Nie, Chunlei Men, Yonghua Lin, Zhongyuan Wang, Tiejun Huang, Shanghang Zhang* | **Category: cs.RO** | **Updated: 2025-07-15**

**Keywords:** 具身AI, 视觉-语言模型, 基础模型, 感知推理, 机器人

**Comment:** 

> **TL;DR:** RoboBrain 2.0是一个新的具身视觉-语言基础模型，旨在统一物理环境中复杂具身任务的感知、推理和规划，并在具身推理任务上表现出色，支持空间理解和时间决策。

**AI_Comments:** RoboBrain 2.0的创新在于其作为具身视觉-语言基础模型，旨在统一感知、推理和规划，并提供不同规模的模型（7B和32B）以适应不同需求。其在具身推理任务上的领先表现，特别是在空间理解和时间决策方面的能力，显示了其在具身AI领域的实用性和重要性，有望加速通用具身智能体的发展。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在引入RoboBrain 2.0，一个具身视觉-语言基础模型，用于统一物理环境中复杂具身任务的感知、推理和规划。

**Method:** RoboBrain 2.0是一个具身视觉-语言基础模型，有两个变体（7B和32B），采用异构架构，包含视觉编码器和语言模型。报告详细介绍了模型架构、数据构建、多阶段训练策略和基础设施。

**Result:** 尽管模型紧凑，RoboBrain 2.0在广泛的具身推理任务上实现了强大性能。32B变体在空间和时间基准测试中取得了领先结果，超越了现有的开源和专有模型。它支持关键的真实世界具身AI能力，如空间理解（如可供性预测、空间指代、轨迹预测）和时间决策（如闭环交互、多智能体长周期规划和场景图更新）。

**Conclusion:** RoboBrain 2.0有望推进具身AI研究，并作为构建通用具身智能体的一个实际步骤。

> **ai_Abstract:** 本技术报告介绍了RoboBrain 2.0，一个具身视觉-语言基础模型，旨在整合物理环境中复杂具身任务的感知、推理和规划。该模型提供7B和32B两种版本，采用视觉编码器和语言模型的异构架构。RoboBrain 2.0在具身推理任务上表现出色，特别是32B版本在空间和时间基准测试中超越了现有模型，支持空间理解和时间决策等真实世界具身AI能力。报告详细描述了模型架构、数据构建、训练策略和应用，旨在推动具身AI研究并促进通用具身智能体的开发。

> **摘要翻译:** 我们介绍了RoboBrain 2.0，这是我们最新一代的具身视觉-语言基础模型，旨在统一物理环境中复杂具身任务的感知、推理和规划。它有两种变体：轻量级的7B模型和全尺寸的32B模型，具有包含视觉编码器和语言模型的异构架构。尽管其尺寸紧凑，RoboBrain 2.0在广泛的具身推理任务中表现出色。在空间和时间基准测试中，32B变体取得了领先结果，超越了之前的开源和专有模型。特别是，它支持关键的真实世界具身AI能力，包括空间理解（例如，可供性预测、空间指代、轨迹预测）和时间决策（例如，闭环交互、多智能体长周期规划和场景图更新）。本报告详细介绍了模型架构、数据构建、多阶段训练策略、基础设施和实际应用。我们希望RoboBrain 2.0能推动具身AI研究，并作为构建通用具身智能体的一个实际步骤。代码、检查点和基准可在https://superrobobrain.github.io获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [786] [Versatile and Generalizable Manipulation via Goal-Conditioned Reinforcement Learning with Grounded Object Detection](https://arxiv.org/abs/2507.10814)
> *基于目标条件强化学习和接地目标检测的多功能通用操作*

*Huiyi Wang, Fahim Shahriar, Alireza Azimi, Gautham Vasan, Rupam Mahmood, Colin Bellinger* | **Category: cs.RO** | **Updated: 2025-07-14**

**Keywords:** 机器人操作, 强化学习, 目标检测, 目标条件强化学习, 泛化

**Comment:** 8 pages, 4 figures, 3 tables

> **TL;DR:** 将预训练的目标检测器与目标条件强化学习相结合，通过掩码条件实现通用的机器人抓取，对已知和未知物体均能达到高成功率和更快的收敛速度。

**AI_Comments:** 本文的创新之处在于有效地利用大型预训练目标检测模型为强化学习提供与对象无关的目标条件，这显著提高了机器人操作的泛化能力和数据效率。这种方法通过提供强大的感知机制，解决了强化学习中对象交互学习资源密集型的挑战。其重要性在于能够为多样化的现实世界任务实现更实用和适应性更强的机器人系统。

<details>
  <summary>Details</summary>

**Motivation:** 通用机器人操作（包括抓取）对于在多样化和不断演变的任务中部署机器人至关重要。当前强化学习中学习对象交互是资源密集型的，而利用大型预训练模型可以增强机器人感知能力，解决这一挑战。

**Method:** 本研究将预训练的目标检测模型集成到目标条件强化学习中。通过文本提示，预训练检测器识别对象并生成用于目标条件的掩码。这种基于掩码的目标条件提供与对象无关的线索，从而改善特征共享和泛化能力。

**Result:** 在模拟的抓取任务中，所提出的框架在抓取分布内和分布外对象时均保持了约90%的成功率，并确保了更快地收敛到更高的回报。

**Conclusion:** 通过基于掩码的目标条件，将预训练目标检测模型集成到目标条件强化学习中，显著提高了机器人操作的多功能性、泛化能力和学习效率。

> **ai_Abstract:** 本论文提出了一种新颖的框架，将预训练的目标检测模型集成到目标条件强化学习中，以实现多功能和可泛化的机器人抓取。通过使用从文本提示目标检测中获得的基于掩码的目标条件，该方法提供了与对象无关的线索，从而改善了特征共享和泛化能力。在模拟环境中的实验证明了其有效性，对已知和未知物体都达到了高成功率（约90%）和更快的学习收敛速度。

> **摘要翻译:** 通用机器人操作，包括抓取和放置，对于部署到涉及多样化和不断演变任务的家庭和工作场所至关重要。最近的进展提出使用大型预训练模型，例如大型语言模型和目标检测器，来增强强化学习中的机器人感知。这些通过自监督学习在大型数据集上训练的模型，可以处理文本提示并识别场景中的多样化对象，这在学习对象交互资源密集型的强化学习中是一项宝贵的技能。本研究展示了如何将此类模型集成到目标条件强化学习中，以实现通用和多功能的机器人抓取能力。我们使用预训练的目标检测模型，使智能体能够从文本提示中识别对象并生成用于目标条件的掩码。基于掩码的目标条件提供了与对象无关的线索，从而改善了特征共享和泛化。所提出框架的有效性在模拟的抓取任务中得到证明，其中基于掩码的目标条件在抓取分布内和分布外对象时始终保持约90%的成功率，同时还确保更快地收敛到更高的回报。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [795] [Multi-IMU Sensor Fusion for Legged Robots](https://arxiv.org/abs/2507.11447)
> *多IMU传感器融合用于足式机器人*

*Shuo Yang, John Z. Zhang, Ibrahima Sory Sow, Zachary Manchester* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-15**

**Keywords:** 足式机器人, 传感器融合, IMU, 状态估计, 视觉-惯性里程计

**Comment:** 16 pages

> **TL;DR:** 本文提出了一种针对足式机器人的状态估计算法，通过融合多个IMU和关节编码器数据，并结合视觉信息，在复杂运动条件下实现了低漂移的位姿和速度估计。

**AI_Comments:** 该论文的创新点在于利用多IMU传感器来纠正足式机器人本体感知里程计中的关键误差，并结合视觉信息，提高了在复杂运动条件下的状态估计鲁棒性。其重要性体现在为足式机器人在非结构化环境中稳定运动提供了更可靠的感知基础。提供开源代码和数据集也极大地促进了研究的复现和后续发展。

<details>
  <summary>Details</summary>

**Motivation:** 在标准本体感知里程计中存在主要误差源，本研究旨在利用多个IMU传感器纠正这些误差，以实现足式机器人在复杂运动条件下低漂移的位姿和速度估计。

**Method:** 该方法利用机器人不同连杆上的多个惯性测量单元（IMU）来纠正标准本体感知里程计中的主要误差源。它在一个扩展卡尔曼滤波器中融合惯性传感器信息和关节编码器测量值，然后将该滤波器的速度估计与相机数据在一个基于因子图的滑动窗口估计器中结合，形成一种视觉-惯性-腿部里程计方法。

**Result:** 该算法在涉及重大地面冲击、足部打滑和突然身体旋转的场景中，始终实现最小的位置偏差。通过全面的理论分析和使用真实世界机器人数据进行的硬件实验验证了其有效性。

**Conclusion:** 该研究成功开发并验证了一种多IMU传感器融合的状态估计算法，能够使足式机器人在具有挑战性的运动条件下实现鲁棒且低漂移的位姿和速度估计。

> **ai_Abstract:** 本文提出了一种创新的足式机器人状态估计算法，通过融合机器人上多个IMU和关节编码器数据来纠正本体感知里程计的误差。该方法在一个扩展卡尔曼滤波器中处理IMU和编码器数据，并将所得的速度估计与视觉数据结合在一个基于因子图的滑动窗口估计器中，形成视觉-惯性-腿部里程计。实验证明，该算法在足式机器人面临地面冲击、打滑和突然旋转等挑战性运动时，仍能保持高精度和低漂移的位姿及速度估计。

> **摘要翻译:** 本文提出了一种用于足式机器人的状态估计算法，该算法使用一套低成本、紧凑且轻量级的传感器，在具有挑战性的运动条件下实现低漂移的位姿和速度估计。其核心思想是利用机器人不同连杆上的多个惯性测量单元来纠正标准本体感知里程计中的主要误差源。我们在一个扩展卡尔曼滤波器中融合惯性传感器信息和关节编码器测量值，然后将该滤波器的速度估计与相机数据在一个基于因子图的滑动窗口估计器中结合，形成一种视觉-惯性-腿部里程计方法。我们通过全面的理论分析和使用在各种挑战性运动任务中收集的真实世界机器人数据进行的硬件实验验证了我们的状态估计器。我们的算法即使在涉及重大地面冲击、足部打滑和突然身体旋转的场景中，也能始终实现最小的位置偏差。C++ 实现和大规模数据集可在 https://github.com/ShuoYangRobotics/Cerberus2.0 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [808] [Learning to Tune Like an Expert: Interpretable and Scene-Aware Navigation via MLLM Reasoning and CVAE-Based Adaptation](https://arxiv.org/abs/2507.11001)
> *像专家一样学习调优：通过多模态大语言模型推理和条件变分自编码器实现可解释和场景感知的导航*

*Yanbo Wang, Zipeng Fang, Lei Zhao, Weidong Chen* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 机器人导航, 多模态大语言模型, 条件变分自编码器, 超参数调优, 场景感知

**Comment:** 

> **TL;DR:** 该论文提出了LE-Nav，一个利用多模态大语言模型（MLLM）推理和条件变分自编码器（CVAE）自适应调整规划器超参数的机器人导航框架，在多样化的真实世界场景中实现了专家级性能。

**AI_Comments:** 该论文通过结合多模态大语言模型和条件变分自编码器，为机器人导航中的自适应超参数调优提供了一种创新方法。其对“可解释”和“场景感知”导航的关注对于实际部署至关重要。能够实现“人类水平调优”并超越现有最先进方法，并通过真实世界试验和用户研究验证，突显了其在提高机器人自主性和社会接受度方面的实际意义和潜力。零样本场景理解和基于自然语言的调优映射是其亮点。

<details>
  <summary>Details</summary>

**Motivation:** 服务机器人在多样化和动态环境中部署时，传统导航系统因参数固定而泛化能力差，性能下降，社会接受度低。虽然强化学习方法有所进步，但其泛化能力和模拟多样性不足，导致模拟到真实迁移困难，限制了实际部署效果。本研究旨在解决这些问题。

**Method:** 提出了LE-Nav框架，一个可解释且场景感知的导航系统。该框架利用多模态大语言模型（MLLM）进行零样本场景理解，通过一次性示例和思维链提示策略实现。此外，使用条件变分自编码器（CVAE）来捕捉自然语言指令与导航超参数之间的映射，从而实现专家级的自适应调优。

**Result:** LE-Nav能够生成达到人类水平调优的超参数，适用于多种规划器和场景。在智能轮椅平台上的真实世界导航试验和用户研究表明，它在成功率、效率、安全性、舒适度等定量指标上优于现有最先进的方法，并在感知到的安全性和社会接受度方面获得了更高的主观评分。

**Conclusion:** LE-Nav通过利用多模态大语言模型推理和条件变分自编码器进行超参数调优，有效解决了机器人导航中泛化和适应性方面的挑战，从而在实际部署中实现了卓越的性能。

> **ai_Abstract:** LE-Nav是一个可解释且场景感知的导航框架，通过结合多模态大语言模型（MLLM）推理和条件变分自编码器（CVAE）来解决服务机器人在动态环境中导航时传统方法泛化能力差和强化学习方法模拟到真实迁移困难的问题。LE-Nav利用MLLM进行零样本场景理解，并通过CVAE将自然语言指令映射到导航超参数，实现专家级的自适应调优。实验证明，LE-Nav在多种规划器和场景下能生成达到人类水平的超参数，并在真实世界导航试验中，相较于现有方法，在成功率、效率、安全性、舒适度以及用户感知方面均表现出卓越的性能。

> **摘要翻译:** 服务机器人在日益多样化和动态化的环境中得到部署，其中物理布局和社会环境随时间推移和地点变化而变化。在这些非结构化环境中，依赖固定参数的传统导航系统往往无法在不同场景中泛化，导致性能下降和社会接受度降低。尽管最近的方法利用强化学习来增强传统规划器，但这些方法由于泛化能力差和模拟多样性有限，阻碍了有效的从模拟到真实的迁移，因此在实际部署中经常失败。为了解决这些问题，我们提出了LE-Nav，一个可解释和场景感知的导航框架，它利用多模态大语言模型推理和条件变分自编码器来自适应地调整规划器超参数。为了实现零样本场景理解，我们利用一次性示例和思维链提示策略。此外，条件变分自编码器捕获自然语言指令和导航超参数之间的映射，从而实现专家级别的调优。实验表明，LE-Nav可以在各种规划器和场景中生成达到人类水平调优的超参数。在智能轮椅平台上进行的真实世界导航试验和用户研究表明，它在成功率、效率、安全性和舒适度等定量指标上优于最先进的方法，同时在感知到的安全性和社会接受度方面获得更高的主观评分。代码可在https://github.com/Cavendish518/LE-Nav获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [4] [Attributes Shape the Embedding Space of Face Recognition Models](https://arxiv.org/abs/2507.11372)
> *属性塑造人脸识别模型的嵌入空间*

*Pierrick Leroy, Antonio Mastropietro, Marco Nurisso, Francesco Vaccarino* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 人脸识别, 嵌入空间, 属性, 可解释性, 几何结构

**Comment:** 

> **TL;DR:** 人脸识别模型的嵌入空间受面部和图像属性影响，本文提出了一种几何方法和物理启发度量来分析这种依赖性或不变性，发现模型对不同属性表现出不同程度的不变性。

**AI_Comments:** 这篇论文通过揭示人脸识别模型嵌入空间中除身份信息外，还受面部和图像属性影响的现象，提供了一个新的视角。其创新点在于提出了几何方法和物理启发度量来量化这种影响，有助于提升模型的可解释性，并为未来鲁棒性研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管人脸识别模型在训练时主要关注身份信息，但研究人员观察到嵌入空间中出现了受可解释面部和图像属性影响的多尺度几何结构。这促使他们探究这些属性如何影响模型的嵌入空间。

**Method:** 本文提出了一种几何方法来描述人脸识别模型对这些属性的依赖性或不变性，并引入了一种受物理学启发的对齐度量。该度量在受控的简化模型和通过合成数据进行特定属性增强的广泛使用的人脸识别模型上进行了评估。

**Result:** 研究发现，人脸识别模型在不同属性上表现出不同程度的不变性。

**Conclusion:** 这些发现揭示了模型的优缺点，并有助于实现更深层次的可解释性。

> **ai_Abstract:** 本文探讨了人脸识别（FR）模型嵌入空间中可解释属性（如发色、对比度）的影响，尽管模型主要通过身份信息进行训练。研究者发现嵌入空间中存在多尺度几何结构，并提出了一种几何方法和受物理学启发的对齐度量来量化模型对这些属性的依赖性或不变性。实验结果表明，FR模型对不同属性表现出不同程度的不变性，这有助于深入理解模型的性能和提高其可解释性。

> **摘要翻译:** 随着深度神经网络的出现，特别是在基于边距的三元组损失将面部图像嵌入高维特征空间后，人脸识别（FR）任务取得了显著进展。在训练过程中，这些对比损失仅将身份信息作为标签。然而，我们观察到嵌入空间中出现了一种多尺度几何结构，它受到可解释的面部（例如发色）和图像属性（例如对比度）的影响。我们提出了一种几何方法来描述人脸识别模型对这些属性的依赖性或不变性，并引入了一种受物理学启发的对齐度量。我们在受控的简化模型和通过合成数据进行目标属性增强的广泛使用的人脸识别模型上评估了所提出的度量。我们的研究结果表明，模型在不同属性上表现出不同程度的不变性，从而深入了解了它们的优缺点，并实现了更深层次的可解释性。代码可在此处获取：https://github.com/mantonios107/attrs-fr-embs

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [6] [Text Embedding Knows How to Quantize Text-Guided Diffusion Models](https://arxiv.org/abs/2507.10340)
> *文本嵌入知道如何量化文本引导扩散模型*

*Hongjae Lee, Myungjun Son, Dongjea Kang, Seung-Won Jung* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 扩散模型, 量化, 文本提示, 计算效率, 图像生成

**Comment:** ICCV 2025

> **TL;DR:** QLIP是一种新的量化方法，利用文本提示来指导文本引导扩散模型的量化，从而在资源受限的环境中提高效率和图像质量。

**AI_Comments:** 本文的创新点在于首次提出将文本提示作为扩散模型量化的指导信息，这是一种新颖且直观的思路。通过利用文本的语义信息来动态调整量化策略，QLIP有望显著提升量化效率和生成质量，对于在边缘设备部署扩散模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在图像生成任务中取得了巨大成功，但其巨大的计算复杂性限制了在资源受限环境中的应用。现有扩散模型量化方法未将文本提示等输入条件作为量化的重要信息来源。

**Method:** 本文提出了一种名为QLIP（Quantization of Language-to-Image diffusion models using text Prompts）的新型量化方法。QLIP利用文本提示在每个时间步为每个层选择位精度。此外，QLIP可以无缝集成到现有量化方法中以提高量化效率。

**Result:** 广泛的实验证明QLIP在降低计算复杂性和提高各种数据集上生成图像的质量方面是有效的。

**Conclusion:** QLIP通过利用文本提示进行量化，有效解决了扩散模型在资源受限环境中的计算复杂性问题，并提高了图像生成质量。

> **ai_Abstract:** 本文提出了一种名为QLIP（Quantization of Language-to-Image diffusion models using text Prompts）的新型量化方法，旨在解决扩散模型在资源受限环境中的计算复杂性问题。与现有方法不同，QLIP利用文本提示作为关键信息源，指导在每个时间步为每个层选择最佳位精度。该方法可以与现有量化技术无缝结合，并通过实验证明其在降低计算开销和提升生成图像质量方面的有效性。

> **摘要翻译:** 尽管扩散模型在文本到图像等图像生成任务中取得了成功，但扩散模型巨大的计算复杂性限制了它们在资源受限环境中的使用。为了解决这个问题，网络量化已成为设计高效扩散模型的一种有前景的解决方案。然而，现有的扩散模型量化方法没有将输入条件（例如文本提示）视为量化的重要信息来源。在本文中，我们提出了一种名为利用文本提示对语言到图像扩散模型进行量化（QLIP）的新型量化方法。QLIP利用文本提示来指导每个时间步每个层的位精度选择。此外，QLIP可以无缝集成到现有量化方法中以提高量化效率。我们广泛的实验证明了QLIP在降低计算复杂性和提高各种数据集上生成图像的质量方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [8] [SpaRTAN: Spatial Reinforcement Token-based Aggregation Network for Visual Recognition](https://arxiv.org/abs/2507.10999)
> *SpaRTAN：用于视觉识别的空间增强型基于Token的聚合网络*

*Quan Bi Pay, Vishnu Monn Baskaran, Junn Yong Loo, KokSheik Wong, Simon See* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 视觉识别, 卷积神经网络, Transformer, 空间聚合, 参数效率

**Comment:** Accepted at International Joint Conference on Neural Networks (IJCNN
  2025)

> **TL;DR:** SpaRTAN是一种轻量级架构，通过增强空间和通道信息处理来解决CNN和Transformer的简单性偏差和信息冗余问题。它在ImageNet和COCO上实现了高参数效率和有竞争力的性能。

**AI_Comments:** SpaRTAN的创新之处在于其轻量级设计，有效地解决了CNN和Transformer的简单性偏差及信息冗余问题。通过结合多感受野核和波基通道聚合，它实现了在视觉识别任务中性能和效率的显著平衡，尤其是在参数效率方面表现出色，为未来高效模型设计提供了有价值的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的CNN和Transformer模型存在简单性偏差，倾向于简单特征而非复杂结构表示。此外，现代CNN中类似MLP的模块存在显著信息冗余，需要高扩展比才能保持性能。

**Method:** 提出SpaRTAN，一个轻量级架构设计，通过使用不同感受野的核来捕获判别性多阶空间特征，并通过基于波的通道聚合模块来调节和增强像素交互，从而减轻通道冗余。这些模块结合起来能够高效地收集和动态地语境化判别性特征。

**Result:** 在ImageNet-1k基准测试中，SpaRTAN以3.8M参数和约1.0 GFLOPs实现了77.7%的准确率。在COCO基准测试中，它以21.5M参数实现了50.0%的AP，超过了之前的基准1.2%。

**Conclusion:** SpaRTAN通过高效的设计，在视觉识别任务中实现了强大的性能和卓越的参数效率。

> **ai_Abstract:** 本文提出了SpaRTAN，一种轻量级网络架构，旨在解决现有CNN和Transformer模型在视觉识别中存在的简单性偏差和信息冗余问题。SpaRTAN通过结合具有不同感受野的核来捕获多阶空间特征，并利用波基通道聚合模块来减少通道冗余。实验证明，SpaRTAN在ImageNet和COCO数据集上取得了竞争性性能，同时展现出卓越的参数效率，例如在ImageNet-1k上以极低的参数量达到77.7%的准确率。

> **摘要翻译:** 卷积神经网络（CNNs）在视觉识别任务中的复兴，以ConvNeXt为代表，通过先进的训练方法和受ViT启发的设 计原则，展示了其与基于Transformer的架构竞争的能力。然而，CNNs和Transformer都表现出一种简单性偏差，偏爱直接的特征而非复杂的结构表示。此外，现代CNNs通常集成类似于Transformer中MLP的模块，但这些模块存在显著的信息冗余，需要高扩展比才能维持竞争力。为了解决这些限制，我们提出了SpaRTAN，一种轻量级架构设计，旨在增强空间和通道信息处理。SpaRTAN采用具有不同感受野的核，通过核大小和膨胀因子控制，有效地捕获判别性多阶空间特征。一个基于波的通道聚合模块进一步调节和增强像素交互，减轻通道冗余。结合这两个模块，所提出的网络可以有效地收集和动态地语境化判别性特征。在ImageNet和COCO上的实验结果表明，SpaRTAN在保持竞争力性能的同时，实现了卓越的参数效率。特别是在ImageNet-1k基准测试中，SpaRTAN以仅3.8M参数和大约1.0 GFLOPs实现了77.7%的准确率，展示了其通过高效设计提供强大性能的能力。在COCO基准测试中，它以仅21.5M参数实现了50.0%的AP，超越了之前的基准1.2%。代码已在[https://github.com/henry-pay/SpaRTAN]公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [19] [ThinkingViT: Matryoshka Thinking Vision Transformer for Elastic Inference](https://arxiv.org/abs/2507.10800)
> *ThinkingViT: 俄罗斯套娃式思维视觉Transformer用于弹性推理*

*Ali Hojjat, Janek Haberer, Soren Pirk, Olaf Landsiedel* | **Category: cs.CV** | **Updated: 2025-07-14**

**Keywords:** 视觉Transformer, 弹性推理, 动态计算, 嵌套Transformer, Token Recycling

**Comment:** Under Review

> **TL;DR:** ThinkingViT是一种动态调整计算量的嵌套ViT，通过渐进式思考和Token Recycling机制实现高效弹性推理，性能优于现有嵌套模型。

**AI_Comments:** ThinkingViT的创新之处在于引入了动态推理机制和Token Recycling，使得模型能够根据输入复杂性自适应地调整计算资源，这对于边缘设备和资源受限环境下的部署具有重要意义。其“骨干网络保留设计”使其易于集成到现有ViT模型中，增加了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** Vision Transformers性能优异但计算预算固定，难以在异构硬件上扩展部署。现有嵌套Transformer虽然能缓解此问题，但对所有输入分配相同的计算量，导致效率低下。

**Method:** 本文引入了ThinkingViT，一种嵌套ViT架构，采用渐进式思考阶段根据输入难度动态调整推理计算。它通过激活少量重要注意力头开始推理，并在预测达到足够确定性时提前终止；否则，激活更多注意力头并重新评估输入。核心是Token Recycling机制，使每个后续推理阶段都以前一阶段的嵌入为条件，从而实现渐进式改进。ThinkingViT设计保留骨干网络，可作为普通ViT的插件升级。

**Result:** ThinkingViT在ImageNet-1K上，在相同吞吐量下，精度比嵌套基线高出2.0个百分点；在相同GMACs下，精度比嵌套基线高出2.9个百分点。

**Conclusion:** ThinkingViT通过动态调整计算量和渐进式思考，有效解决了Vision Transformers在弹性推理中的效率问题，并在性能上超越了现有嵌套模型。

> **ai_Abstract:** 本文提出了ThinkingViT，一种嵌套式视觉Transformer，旨在解决传统ViT固定计算预算导致的部署效率问题。ThinkingViT通过渐进式思考阶段，根据输入难度动态调整计算量，实现弹性推理。其核心是Token Recycling机制，允许后续推理阶段利用前一阶段的嵌入，从而实现性能的渐进式提升。实验证明，ThinkingViT在ImageNet-1K上，在相同资源下，性能显著优于现有嵌套Transformer模型。

> **摘要翻译:** 视觉Transformer提供了最先进的性能，但其固定的计算预算阻碍了在异构硬件上的可扩展部署。最近的嵌套Transformer架构通过在单个模型中嵌入嵌套子网络来缓解这一问题，从而实现可扩展推理。然而，这些模型为所有输入分配相同的计算量，无论其复杂性如何，这导致了效率低下。为了解决这个问题，我们引入了ThinkingViT，这是一种嵌套的ViT架构，它采用渐进式思考阶段，根据输入难度动态调整推理计算。ThinkingViT通过激活最重要注意力头的小部分子集来启动推理，如果预测达到足够的确定性则提前终止。否则，它会激活额外的注意力头并重新评估输入。ThinkingViT的核心是我们的Token Recycling机制，它使每个后续推理阶段都以前一阶段的嵌入为条件，从而实现渐进式改进。由于其骨干网络保留设计，ThinkingViT还可以作为普通ViT的插件升级。实验表明，ThinkingViT在ImageNet-1K上，在相同吞吐量下，精度比嵌套基线高出2.0个百分点（p.p.），在相同GMACs下，精度高出2.9个百分点。源代码可在https://github.com/ds-kiel/ThinkingViT获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [22] [Biomechanics-Guided Residual Approach to Generalizable Human Motion Generation and Estimation](https://arxiv.org/abs/2503.06151)
> *生物力学引导的残差方法用于可泛化人体运动生成与估计*

*Zixi Kang, Xinghan Wang, Yadong Mu* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 人体运动生成, 生物力学, 扩散模型, EMG信号, 姿态估计

**Comment:** 

> **TL;DR:** BioVAE是一个生物力学感知的框架，通过整合EMG信号、运动学特征和加速度约束，以及与扩散模型耦合，实现了在不依赖模拟的情况下生成物理上合理且可泛化的人体运动，并在多项基准测试中达到了最先进的性能。

**AI_Comments:** 该论文的创新点在于将生物力学原理（如EMG信号、运动学特征和加速度约束）与先进的生成模型（扩散模型）相结合，从而解决了传统方法在物理真实性和泛化能力上的局限性。其不依赖模拟环境的特性显著提升了实用性。通过引入生物力学先验，BioVAE在多样化的运动生成和估计任务中展现出强大的泛化能力，为数字人、动画和机器人领域带来了重要的进步。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人体姿态、动作和运动生成方法难以产生符合生物力学原理的物理上合理的运动。尽管自回归和扩散模型在视觉质量上表现出色，但它们往往忽略关键的生物动力学特征，无法确保物理真实性。强化学习方法虽然可以解决这些问题，但高度依赖模拟环境，限制了其泛化能力。

**Method:** 本文提出了BioVAE，一个生物力学感知框架，包含三项核心创新：1) 整合肌肉肌电图(EMG)信号和运动学特征，并施加加速度约束，以在不依赖模拟的情况下实现物理上合理的运动；2) 与扩散模型无缝耦合，实现稳定的端到端训练；3) 引入生物力学先验知识，以促进在各种运动生成和估计任务中的强大泛化能力。

**Result:** BioVAE在多个基准测试中达到了最先进的性能，弥合了数据驱动运动合成与生物力学真实性之间的鸿沟，并为物理精确的运动生成和姿态估计设定了新标准。

**Conclusion:** BioVAE成功地解决了现有方法在生成物理上合理且可泛化人体运动方面的挑战，通过结合生物力学原理和先进的深度学习模型，实现了卓越的性能和普适性。

> **ai_Abstract:** 本文提出了BioVAE，一个生物力学感知的框架，旨在解决现有方法在生成物理上合理且可泛化人体运动方面的不足。BioVAE通过整合EMG信号、运动学特征和加速度约束，结合扩散模型进行端到端训练，并利用生物力学先验知识，实现了在不依赖模拟环境的情况下生成物理上真实且高度泛化的人体运动。实验证明，BioVAE在多项基准测试中达到了最先进的性能，有效连接了数据驱动的运动合成与生物力学真实性。

> **摘要翻译:** 人体姿态、动作和运动的生成对于数字人、角色动画和人形机器人等应用至关重要。然而，许多现有方法难以产生符合生物力学原理的物理上合理的运动。尽管最近的自回归和扩散模型提供了令人印象深刻的视觉质量，但它们往往忽略关键的生物动力学特征，未能确保物理真实的运动。强化学习（RL）方法可以解决这些缺点，但高度依赖模拟环境，限制了其泛化能力。为了克服这些挑战，我们提出了BioVAE，一个生物力学感知框架，具有三项核心创新：(1) 整合肌肉肌电图（EMG）信号和运动学特征以及加速度约束，以在没有模拟的情况下实现物理上合理的运动；(2) 与扩散模型无缝耦合，实现稳定的端到端训练；(3) 生物力学先验知识促进了在各种运动生成和估计任务中的强大泛化。广泛的实验表明，BioVAE在多个基准测试中实现了最先进的性能，弥合了数据驱动运动合成与生物力学真实性之间的鸿沟，同时为物理精确的运动生成和姿态估计设定了新标准。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [24] [Text-Visual Semantic Constrained AI-Generated Image Quality Assessment](https://arxiv.org/abs/2507.10432)
> *文本-视觉语义约束的AI生成图像质量评估*

*Qiang Li, Qingsen Yan, Haojian Huang, Peng Wu, Haokui Zhang, Yanning Zhang* | **Category: cs.CV, I.4.7** | **Updated: 2025-07-15**

**Keywords:** AI生成图像质量评估, 文本-视觉语义约束, 语义对齐, 频域分析, 感知失真

**Comment:** 9 pages, 5 figures, Accepted at ACMMM 2025

> **TL;DR:** 本文提出了SC-AGIQA框架，通过引入文本-视觉语义约束来解决AI生成图像质量评估中语义错位和细节感知缺失的问题，并结合了文本辅助语义对齐和频域细粒度退化感知模块，实验证明其性能超越了现有最先进的方法。

**AI_Comments:** 这篇论文通过引入文本-视觉语义约束，有效地解决了AI生成图像质量评估中的核心挑战。其创新性在于结合了多模态大语言模型（MLLMs）进行语义对齐，并借鉴人类视觉系统（HVS）特性进行频域分析以捕捉细微视觉细节，这为AGI质量评估提供了一个更全面和精确的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能生成图像（AGI）技术的快速发展，对其质量的准确评估变得至关重要。然而，现有方法（如CLIP或BLIP）在应用于AGI时，面临语义错位和细节感知缺失两大主要挑战。

**Method:** 本文提出了SC-AGIQA（Text-Visual Semantic Constrained AI-Generated Image Quality Assessment）框架，这是一个统一的框架，旨在通过文本-视觉语义约束来增强AI生成图像的文本-图像一致性和感知失真评估。该方法整合了多个模型的关键能力，并引入了两个核心模块：文本辅助语义对齐模块（TSAM），利用多模态大语言模型（MLLMs）生成图像描述并与原始提示进行比较以弥合语义鸿沟；以及频域细粒度退化感知模块（FFDPM），借鉴人类视觉系统（HVS）特性，结合频域分析和感知灵敏度加权来量化细微视觉失真并增强对细粒度视觉质量细节的捕获。

**Result:** 在多个基准数据集上进行的广泛实验表明，SC-AGIQA优于现有最先进的方法。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对AI生成图像（AGI）质量评估中现有方法存在的语义错位和细节感知缺失问题，提出了SC-AGIQA框架。该框架通过引入文本辅助语义对齐模块（TSAM）利用MLLMs进行语义鸿沟弥合，以及频域细粒度退化感知模块（FFDPM）结合频域分析捕捉细微视觉失真，全面提升了AGI的文本-图像一致性和感知失真评估能力。实验结果表明，SC-AGIQA在多个基准数据集上表现优于现有最先进的方法。

> **摘要翻译:** 随着人工智能生成图像（AGI）技术的快速发展，对其质量的准确评估已成为一项日益重要的要求。现有方法通常依赖于CLIP或BLIP等多模态模型来评估文本-图像对齐和视觉质量。然而，当应用于AGI时，这些方法面临两个主要挑战：语义错位和细节感知缺失。为了解决这些局限性，我们提出了文本-视觉语义约束的AI生成图像质量评估（SC-AGIQA），这是一个统一的框架，它利用文本-视觉语义约束来显著增强对AI生成图像的文本-图像一致性和感知失真的综合评估。我们的方法整合了多个模型的关键能力，并通过引入两个核心模块来解决上述挑战：文本辅助语义对齐模块（TSAM），它利用多模态大语言模型（MLLMs）通过生成图像描述并与原始提示进行比较来弥合语义鸿沟，以实现更精确的一致性检查；以及频域细粒度退化感知模块（FFDPM），它借鉴人类视觉系统（HVS）的特性，通过结合频域分析和感知灵敏度加权来更好地量化细微视觉失真并增强对图像中细粒度视觉质量细节的捕获。在多个基准数据集上进行的广泛实验表明，SC-AGIQA优于现有最先进的方法。代码已在https://github.com/mozhu1/SC-AGIQA 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [39] [MMOne: Representing Multiple Modalities in One Scene](https://arxiv.org/abs/2507.11129)
> *MMOne：在一个场景中表示多种模态*

*Zhifeng Gu, Bing Wang* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 多模态表示, 场景表示, 模态冲突, 模态分解, MMOne

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 本文提出了MMOne框架，通过新的模态指示器和多模态分解机制，解决多模态表示中的模态冲突问题，实现紧凑高效的多模态场景表示。

**AI_Comments:** 该论文的创新点在于提出了MMOne框架，通过独特的模态指示器和多模态分解机制，有效解决了多模态表示中的核心挑战——模态冲突。其将多模态信息解耦为共享和特定组件的方法，实现了更紧凑高效的表示，并展现出良好的可扩展性，对于多模态感知和理解领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人类通过多模态线索感知世界，学习多模态场景表示能增强理解。然而，不同模态固有的区别导致模态冲突（属性差异和粒度差异），构成了关键挑战。

**Method:** 提出了通用框架MMOne，包含：1. 带有新型模态指示器的模态建模模块，用于捕获每种模态的独特属性。2. 多模态分解机制，根据模态差异将多模态高斯分解为单模态高斯。通过将多模态信息解耦为共享和模态特定组件。

**Result:** 大量实验表明，该方法持续增强了每种模态的表示能力，并且可以扩展到额外的模态。

**Conclusion:** MMOne通过解耦信息有效解决了模态冲突，实现了更紧凑、高效且可扩展的多模态场景表示。

> **ai_Abstract:** 本文提出了MMOne框架，旨在解决多模态场景表示中由模态固有差异引起的“属性差异”和“粒度差异”等模态冲突。MMOne通过引入新颖的模态建模模块（含模态指示器）和多模态分解机制，将多模态信息解耦为共享和模态特定部分，从而实现了更紧凑、高效的多模态场景表示。实验证明其能有效增强各模态的表示能力并具备可扩展性。

> **摘要翻译:** 人类通过多模态线索感知世界，以理解和与环境互动。学习多模态的场景表示可以增强对物理世界的理解。然而，由于不同模态固有的区别，模态冲突带来了两个关键挑战：属性差异和粒度差异。为了解决这些挑战，我们提出了一个通用框架MMOne，用于在一个场景中表示多种模态，该框架可以很容易地扩展到额外的模态。具体来说，我们提出了一个带有新型模态指示器的模态建模模块，以捕获每种模态的独特属性。此外，我们设计了一种多模态分解机制，根据模态差异将多模态高斯分解为单模态高斯。我们通过将多模态信息分解为共享组件和模态特定组件来解决模态之间的本质区别，从而实现更紧凑、更高效的多模态场景表示。大量的实验表明，我们的方法持续增强了每种模态的表示能力，并且可以扩展到额外的模态。代码可在 https://github.com/Neal2020GitHub/MMOne 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [46] [Implementing Adaptations for Vision AutoRegressive Model](https://arxiv.org/abs/2507.11441)
> *实现视觉自回归模型的适应性*

*Kaif Shaikh, Antoni Kowalczuk, Franziska Boenisch, Adam Dziedzic* | **Category: cs.CV, cs.LG, I.2.6; I.5.1; I.4.8; I.2.10** | **Updated: 2025-07-15**

**Keywords:** 视觉自回归模型, 适应性, 差分隐私, 图像生成, 微调

**Comment:** Accepted at DIG-BUGS: Data in Generative Models Workshop @ ICML 2025

> **TL;DR:** 本文研究了视觉自回归模型（VAR）的微调策略，并与扩散模型（DM）进行比较。研究发现VAR在非差分隐私（non-DP）适应性方面表现更优，但在差分隐私（DP）适应性方面性能不佳，有待进一步研究。

**AI_Comments:** 这篇论文填补了VAR模型在特定任务适应性及差分隐私适应性方面的研究空白。其创新点在于系统地评估了VAR的微调策略，并与主流的DM模型进行了对比。研究结果揭示了VAR在非DP场景下的潜力，同时也指出了其在DP场景下性能不足的局限性，为未来VAR的隐私保护研究提供了明确方向。

<details>
  <summary>Details</summary>

**Motivation:** 视觉自回归模型（VAR）是图像生成领域中扩散模型（DM）的替代方案，但针对VAR的适应性（微调模型以执行特定下游任务，如医学数据生成）及其差分隐私（DP）适应性研究不足，而DM在这方面已有大量成熟技术。

**Method:** 作者实现并基准测试了多种视觉自回归模型（VAR）的适应性策略，并将其与最先进的扩散模型（DM）适应性策略进行了比较。

**Result:** 研究发现视觉自回归模型（VAR）在非差分隐私（non-DP）适应性方面优于扩散模型（DM）。然而，VAR在差分隐私（DP）适应性方面的性能较差。

**Conclusion:** 视觉自回归模型（VAR）在非差分隐私（non-DP）适应性上表现出色，但在差分隐私（DP）适应性方面仍需进一步研究。

> **ai_Abstract:** 本文探讨了视觉自回归模型（VAR）的适应性及其差分隐私（DP）适应性，旨在将其应用于特定下游任务（如医学数据生成）。研究通过实现并基准测试多种VAR策略，并与扩散模型（DMs）进行比较，发现VAR在非DP适应性方面表现优异，但在DP适应性方面性能不佳，表明该领域仍需深入研究。

> **摘要翻译:** 视觉自回归模型（VAR）最近被引入作为图像生成领域中扩散模型（DMs）的替代方案。在这项工作中，我们专注于其适应性，旨在微调预训练模型以执行特定的下游任务，例如医学数据生成。虽然对于DMs存在许多技术，但VAR的适应性仍未得到充分探索。同样，差分隐私（DP）适应性——旨在保护适应数据隐私的适应性——已在DMs中得到了广泛研究，而VAR缺乏此类解决方案。在我们的工作中，我们实现并基准测试了VAR的许多策略，并将其与最先进的DM适应性策略进行比较。我们观察到VAR在非DP适应性方面优于DMs，然而，DP的性能较差，这需要对VAR的隐私适应性进行进一步研究。代码可在https://github.com/sprintml/finetuning_var_dp 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [50] [VLLMs Provide Better Context for Emotion Understanding Through Common Sense Reasoning](https://arxiv.org/abs/2404.07078)
> *VLLM通过常识推理为情感理解提供更好的上下文*

*Alexandros Xenos, Niki Maria Foteinopoulou, Ioanna Ntinou, Ioannis Patras, Georgios Tzimiropoulos* | **Category: cs.CV, cs.HC** | **Updated: 2025-07-15**

**Keywords:** VLLM, 情感理解, 上下文推理, 多模态融合, 深度学习

**Comment:** A. Xenos, N. Foteinopoulou and I. Ntinou contributed equally to this
  work; 14 pages, 5 figures; Accepted at IJCNN 2025

> **TL;DR:** 本文提出了一种利用视觉-大语言模型（VLLMs）的两阶段方法，通过生成自然语言描述来增强上下文情感分类，从而简化训练并实现最先进的性能。

**AI_Comments:** 这项工作通过引入VLLMs生成中间的自然语言描述，为情感理解提供上下文，从而简化了以往复杂或信息受限的场景编码方法。其创新之处在于利用VLLMs的常识推理能力来提炼视觉信息，并通过简单的两阶段融合架构实现了显著的性能提升，且无需复杂的训练管线。这种方法为多模态情感识别提供了一个简洁且高效的范式。

<details>
  <summary>Details</summary>

**Motivation:** 在上下文中识别情感的现有方法通常利用有限的上下文信息或依赖复杂的训练流程来分离噪声。本文旨在通过利用VLLMs的能力，以更直接的方式增强上下文情感分类。

**Method:** 本文提出了一种简单的两阶段方法：首先，提示VLLMs生成主题表观情感与视觉上下文相关的自然语言描述；其次，将这些描述与视觉输入一起用于训练一个基于Transformer的架构，该架构在最终分类任务前融合文本和视觉特征。

**Result:** 实验结果表明，文本描述有效地引导模型约束了嘈杂的视觉输入，使得融合架构优于单一模态。该方法在BoLD、EMOTIC和CAER-S三个数据集上实现了最先进的性能。

**Conclusion:** 通过利用VLLMs生成上下文相关的自然语言描述，本文提出的方法简化了情感分类的训练过程，并显著提高了性能，在多个数据集上达到了最先进的水平。

> **ai_Abstract:** 本文提出了一种利用视觉-大语言模型（VLLMs）进行上下文情感分类的新方法。该方法采用两阶段策略：首先，VLLMs生成与视觉上下文相关的自然语言情感描述；然后，这些描述与视觉输入一同训练一个融合文本和视觉特征的Transformer模型。这种方法简化了训练流程，并通过有效约束视觉噪声显著提升了性能，在BoLD、EMOTIC和CAER-S数据集上取得了最先进的成果。

> **摘要翻译:** 识别上下文中的情感涉及在考虑周围场景的上下文线索的同时识别个体的表观情感。以往解决此任务的方法通常设计显式的场景编码架构或整合外部场景相关信息，例如字幕。然而，这些方法往往利用有限的上下文信息或依赖复杂的训练流程来将噪声与相关信息解耦。在这项工作中，我们利用视觉-大语言模型（VLLMs）的能力，以更直接的方式增强上下文情感分类。我们提出的方法遵循一个简单而有效的两阶段方法。首先，我们提示VLLMs生成与视觉上下文相关的主体表观情感的自然语言描述。其次，这些描述与视觉输入一起用于训练一个基于Transformer的架构，该架构在最终分类任务之前融合文本和视觉特征。这种方法不仅简化了训练过程，而且显著提高了性能。实验结果表明，文本描述有效地引导模型约束了嘈杂的视觉输入，使得我们的融合架构优于单一模态。我们的方法在BoLD、EMOTIC和CAER-S三个数据集上实现了最先进的性能，而且没有额外的复杂性。代码将在github上公开：https://github.com/NickyFot/EmoCommonSense.git

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [58] [Unveiling the Invisible: Reasoning Complex Occlusions Amodally with AURA](https://arxiv.org/abs/2503.10225)
> *揭示不可见：使用 AURA 进行非模态复杂遮挡推理*

*Zhixuan Li, Hyunse Yoon, Sanghoon Lee, Weisi Lin* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 非模态分割, 遮挡推理, AURA, 数据集, 视觉理解

**Comment:** Accepted by ICCV 2025, 17 pages, 9 figures, 5 tables

> **TL;DR:** 本文提出了一种名为非模态推理分割的新任务和模型 AURA，旨在通过用户文本输入预测被遮挡物体的完整非模态形状，并提供解释，以解决现有非模态分割方法在处理复杂遮挡和用户交互方面的局限性。

**AI_Comments:** 本文提出了一种新颖的非模态推理分割任务，结合了非模态分割与多模态大型语言模型（LLMs）的推理能力，解决了现有方法无法进行用户文本交互和处理复杂遮挡的痛点。其创新点在于引入了文本输入进行推理以及对完整非模态形状的预测，并为此构建了专用数据集和 AURA 模型。这对于提升AI在复杂视觉理解和人机交互方面的能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的非模态分割方法缺乏通过文本输入与用户交互的能力，并且难以理解或推理隐式和复杂的目的。尽管融合多模态大型语言模型的现有方法可以进行推理任务，但它们仅限于预测可见物体区域，并且在处理复杂遮挡场景时面临挑战。为了解决这些局限性，本文提出了新的方法。

**Method:** 本文提出了一个名为“非模态推理分割”的新任务，旨在预测被遮挡物体的完整非模态形状，并根据用户文本输入提供详细的答案。为此，开发了一个通用数据集生成管道，并引入了一个专注于日常场景的新数据集。此外，本文提出了 AURA (Amodal Understanding and Reasoning Assistant)，一个具有先进全局和空间级设计的新模型，专门用于处理复杂遮挡。

**Result:** 通过广泛的实验，验证了 AURA 在所提出的数据集上的有效性。

**Conclusion:** AURA 模型在非模态推理分割任务上表现出有效性，能够处理复杂的遮挡情况，并根据用户文本输入提供对被遮挡物体的完整形状预测及解释，成功解决了现有方法的局限性。

> **ai_Abstract:** 本文针对现有非模态分割方法在复杂遮挡处理和文本交互方面的不足，提出了一项名为“非模态推理分割”的新任务。该任务旨在根据用户文本输入预测被遮挡物体的完整非模态形状并提供解释。为支持此任务，作者开发了一个新的数据集生成管道及专注于日常场景的数据集，并推出了 AURA 模型，该模型采用先进的全局和空间级设计来处理复杂遮挡。实验结果验证了 AURA 在新数据集上的有效性。

> **摘要翻译:** 非模态分割旨在推断被遮挡物体的完整形状，即使被遮挡区域的外观不可用。然而，当前的非模态分割方法缺乏通过文本输入与用户交互的能力，并且难以理解或推理隐式和复杂的目的。尽管像 LISA 这样的方法将多模态大型语言模型（LLMs）与分割相结合用于推理任务，但它们仅限于预测可见物体区域，并且在处理复杂遮挡场景时面临挑战。为了解决这些局限性，我们提出了一项名为非模态推理分割的新任务，旨在预测被遮挡物体的完整非模态形状，同时根据用户文本输入提供详细的答案。我们开发了一个通用的数据集生成管道，并引入了一个专注于日常场景的新数据集，涵盖了各种真实世界的遮挡情况。此外，我们提出了 AURA（Amodal Understanding and Reasoning Assistant），一个具有先进全局和空间级设计的新模型，专门用于处理复杂遮挡。广泛的实验验证了 AURA 在所提出的数据集上的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [62] [Bridge Feature Matching and Cross-Modal Alignment with Mutual-filtering for Zero-shot Anomaly Detection](https://arxiv.org/abs/2507.11003)
> *零样本异常检测中基于互过滤的特征匹配与跨模态对齐桥接*

*Yuhu Bai, Jiangning Zhang, Yunkang Cao, Guangyuan Lu, Qingdong He, Xiangtai Li, Guanzhong Tian* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 零样本异常检测, CLIP, 特征匹配, 跨模态对齐, 互过滤

**Comment:** 

> **TL;DR:** FiSeCLIP 是一种训练无关的零样本异常检测方法，结合特征匹配和跨模态对齐，并通过互过滤和文本信息增强，在异常检测基准测试中表现出色。

**AI_Comments:** 该论文的创新点在于提出了 FiSeCLIP，将 CLIP 的零样本能力与特征匹配、跨模态对齐以及独特的互过滤机制相结合，解决了批处理测试中无标签参考的歧义问题。通过利用文本信息过滤噪声和恢复 CLIP 的局部语义关联，显著提升了细粒度异常检测的性能。其在 MVTec-AD 数据集上超越 SOTA 的表现证明了其有效性和作为新基线的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在零样本异常检测（ZSAD）中，稀有类别在许多应用中至关重要。现有方法在批处理测试中可能因缺乏标签参考而引入歧义。本研究旨在利用视觉-语言模型（如 CLIP）的潜力，解决这些挑战并提高细粒度异常检测的准确性，以更好地符合实际工业需求。

**Method:** 本研究提出了 FiSeCLIP，一种训练无关的零样本异常检测方法，它结合了特征匹配和跨模态对齐。FiSeCLIP 利用同批次中的其他图像作为当前图像的参考信息，并应用文本信息来过滤噪声特征，以解决缺乏标签的参考带来的歧义。此外，该方法还探索了 CLIP 的内在潜力，以恢复其局部语义相关性，使其适应细粒度异常检测任务，从而实现更准确的过滤过程。

**Result:** FiSeCLIP 在异常检测基准测试中，在异常分类和分割方面均表现出优越性能。在 MVTec-AD 数据集上，FiSeCLIP 在分割指标 AU-ROC 和 F1-max 上分别优于 SOTA AdaCLIP +4.6% 和 +5.7%。

**Conclusion:** FiSeCLIP 通过结合特征匹配、跨模态对齐以及创新的互过滤机制，显著提升了异常分类和分割的性能，为零样本异常检测领域构建了更强的基线。

> **ai_Abstract:** 本研究提出了 FiSeCLIP，一种基于 CLIP 的训练无关零样本异常检测（ZSAD）方法，旨在结合特征匹配和跨模态对齐。针对实际应用中批处理测试的需求，FiSeCLIP 利用批次内图像作为互参考，并通过引入文本信息进行互过滤以消除潜在噪声。此外，该方法还利用 CLIP 恢复局部语义关联的能力，以实现更精细的异常检测。实验结果表明，FiSeCLIP 在异常分类和分割任务上均表现出卓越性能，为零样本异常检测领域设定了新的基线，尤其在 MVTec-AD 数据集上显著优于现有 SOTA 方法。

> **摘要翻译:** 随着视觉-语言模型（例如 CLIP）在零样本和少样本设置中的出现，CLIP 在最近的研究中被广泛应用于零样本异常检测（ZSAD），其中稀有类别在许多应用中至关重要且备受期待。本研究引入了 \textbf{FiSeCLIP} 用于训练无关的 \textbf{CLIP} 零样本异常检测，结合了特征匹配与跨模态对齐。使用整个数据集进行测试是不切实际的，而基于批次的测试更符合实际工业需求，并且批次内的图像可以作为相互参考点。因此，FiSeCLIP 利用同一批次中的其他图像作为当前图像的参考信息。然而，这些参考缺乏标签可能会引入歧义，我们应用文本信息来\textbf{过滤}掉噪声特征。此外，我们进一步探索了 CLIP 固有的潜力，以恢复其局部\textbf{语义}相关性，使其适应细粒度异常检测任务，从而实现更准确的过滤过程。我们的方法在异常检测基准测试中，在异常分类和分割方面均表现出卓越的性能，为该方向建立了更强的基线，例如，在 MVTec-AD 数据集上，FiSeCLIP 在分割指标 AU-ROC/$F_1$-max 上分别优于 SOTA AdaCLIP +4.6%$\uparrow$/+5.7%$\uparrow$。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [73] [LLM-Guided Agentic Object Detection for Open-World Understanding](https://arxiv.org/abs/2507.10844)
> *大型语言模型引导的开放世界理解智能体目标检测*

*Furkan Mumcu, Michael J. Jones, Anoop Cherian, Yasin Yilmaz* | **Category: cs.CV** | **Updated: 2025-07-14**

**Keywords:** LLM, 智能体目标检测, 开放世界理解, 零样本检测, 开放词汇

**Comment:** 

> **TL;DR:** 提出LAOD框架，利用LLM生成场景特定物体名称，实现零样本、无标签开放世界目标检测，提高自主性和适应性。

**AI_Comments:** 该论文创新性地将大型语言模型（LLM）引入目标检测领域，通过LLM生成动态的、场景特定的物体名称，从而实现了真正的零样本、无标签开放世界目标检测。这极大地提升了系统的自主性和适应性，解决了传统方法依赖固定类别和用户提示的局限性。引入新的评估指标CAAP和SNAP也体现了对开放世界检测复杂性的深入理解。

<details>
  <summary>Details</summary>

**Motivation:** 传统目标检测依赖固定类别集，重训练成本高。开放世界和开放词汇目标检测（OWOD和OVOD）虽有改进，但OWOD缺乏未知物体的语义标签，OVOD依赖用户提示，限制了自主性。

**Method:** 提出LLM引导的智能体目标检测（LAOD）框架，通过提示大型语言模型（LLM）生成场景特定物体名称，然后将其传递给开放词汇检测器进行定位，从而实现完全无标签、零样本检测，并允许系统动态调整目标。引入了两个新指标：类别无关平均精度（CAAP）和语义命名平均精度（SNAP），分别评估定位和命名性能。

**Result:** 在LVIS、COCO和COCO-OOD数据集上的实验验证了该方法的有效性，在检测和命名新物体方面表现出强大的性能。

**Conclusion:** LAOD方法为开放世界理解提供了增强的自主性和适应性。

> **ai_Abstract:** 该论文提出了一种名为LLM引导的智能体目标检测（LAOD）的新框架，旨在解决传统目标检测在开放世界中适应性差和现有OWOD/OVOD方法自主性不足的问题。LAOD利用大型语言模型（LLM）生成场景特定的物体名称，实现完全无标签、零样本的目标检测，并通过开放词汇检测器进行定位。为评估该方法，引入了类别无关平均精度（CAAP）和语义命名平均精度（SNAP）两个新指标。实验结果表明，LAOD在检测和命名新颖物体方面表现出色，显著增强了开放世界理解的自主性和适应性。

> **摘要翻译:** 目标检测传统上依赖于固定的类别集，处理新颖物体需要昂贵的重新训练。虽然开放世界和开放词汇目标检测（OWOD和OVOD）提高了灵活性，但OWOD缺乏未知物体的语义标签，OVOD依赖于用户提示，限制了自主性。我们提出了一个LLM引导的智能体目标检测（LAOD）框架，通过提示大型语言模型（LLM）生成场景特定的物体名称，从而实现完全无标签、零样本检测。这些名称被传递给一个开放词汇检测器进行定位，从而允许系统动态地调整其目标。我们引入了两个新指标，类别无关平均精度（CAAP）和语义命名平均精度（SNAP），以分别评估定位和命名。在LVIS、COCO和COCO-OOD上的实验验证了我们的方法，显示出在检测和命名新颖物体方面的强大性能。我们的方法为开放世界理解提供了增强的自主性和适应性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [87] [RMAU-NET: A Residual-Multihead-Attention U-Net Architecture for Landslide Segmentation and Detection from Remote Sensing Images](https://arxiv.org/abs/2507.11143)
> *RMAU-NET：一种用于遥感图像滑坡分割与检测的残差多头注意力U-Net架构*

*Lam Pham, Cam Le, Hieu Tang, Khang Truong, Truong Nguyen, Jasmin Lampert, Alexander Schindler, Martin Boyer, Son Phan* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 滑坡检测, 滑坡分割, 遥感图像, 深度学习, RMAU-NET

**Comment:** 

> **TL;DR:** 本文提出RMAU-NET深度学习模型，利用遥感图像自动进行滑坡检测与分割，并在多个基准数据集上取得了高F1和mIoU分数，证明了其在实际滑坡观测系统中的潜力。

**AI_Comments:** 该论文提出了一种新颖的深度学习模型RMAU-NET，用于解决遥感图像中的滑坡检测与分割问题。其创新点在于结合了残差和多头注意力机制于U-Net架构中，以适应大范围和复杂地形的滑坡观测。模型在多个基准数据集上取得了令人鼓舞的性能，表明了其在实际灾害监测中的重要应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 由于极端天气事件和人类活动导致滑坡灾害频发，而自动观测大范围和崎岖地形的滑坡具有挑战性，因此需要一种基于深度学习的自动化模型来观测滑坡事件。

**Method:** 提出了一种名为RMAU-NET的新型深度学习神经网络架构，该架构以遥感图像作为输入，用于执行滑坡检测和滑坡分割两项任务。

**Result:** 在LandSlide4Sense和Bijie数据集上，滑坡检测任务的F1分数分别为98.23和93.83。在LandSlide4Sense和Nepal数据集上，分割任务的mIoU分数分别为63.74和76.88。

**Conclusion:** 实验结果证明所提出的RMAU-NET模型有潜力集成到实际的滑坡观测系统中。

> **ai_Abstract:** 本文针对滑坡灾害频发但自动观测困难的问题，提出了一种名为RMAU-NET的深度学习模型。该模型利用遥感图像进行滑坡检测和分割，旨在实现滑坡事件的自动化观测。在LandSlide4Sense、Bijie和Nepal等基准数据集上的实验结果表明，RMAU-NET在滑坡检测和分割任务上均取得了高分，证明了其在实际滑坡观测系统中的应用潜力。

> **摘要翻译:** 近年来，由于干旱、洪水、风暴等极端天气事件，或森林砍伐、自然资源过度开采等人类活动，滑坡灾害频发。然而，由于观测区域极其广阔以及山区或高原等崎岖地形，自动观测滑坡具有挑战性。这促使我们提出一种端到端的深度学习模型，该模型利用遥感图像自动观测滑坡事件。通过将遥感图像作为输入数据，我们可以获得免费资源，并及时观测大范围和崎岖的地形。为了探索遥感图像，我们提出了一种新颖的神经网络架构，用于滑坡检测和滑坡分割两项任务。我们在LandSlide4Sense、Bijie和Nepal三个不同的基准数据集上评估了我们提出的模型。通过大量的实验，我们在LandSlide4Sense和Bijie数据集上的滑坡检测任务中分别取得了98.23和93.83的F1分数；在LandSlide4Sense和Nepal数据集上的分割任务中分别取得了63.74和76.88的mIoU分数。这些实验结果证明了将我们提出的模型集成到实际滑坡观测系统中的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [88] [COLI: A Hierarchical Efficient Compressor for Large Images](https://arxiv.org/abs/2507.11443)
> *COLI: 大型图像的分层高效压缩器*

*Haoran Wang, Hanyu Pei, Yang Lyu, Kai Zhang, Li Li, Feng-Lei Fan* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 图像压缩, 隐式神经表示, 大图像, 深度学习

**Comment:** 

> **TL;DR:** COLI是一种基于INR的图像压缩框架，通过加速训练和超压缩技术，显著提高了大型图像的压缩效率和质量。

**AI_Comments:** 该论文提出了一种创新的方法来解决基于隐式神经表示（INR）的大型图像压缩面临的效率和压缩比挑战。其通过加速训练过程和引入“超压缩”后处理技术，有效地提升了INR在图像压缩领域的实用性。特别是，其在医学影像领域的应用潜力巨大，能够有效管理高分辨率医疗数据。这项工作具有重要的实际意义，因为它提供了一种在保持高质量的同时显著减少大型图像存储需求的方法，并且提高了训练效率。

<details>
  <summary>Details</summary>

**Motivation:** 高分辨率、大视场图像的普及需要高效的压缩方法。传统技术无法保留关键细节，数据驱动方法泛化性差。隐式神经表示（INRs）有潜力，但基于INR的大图像压缩面临速度慢和压缩比低的问题。

**Method:** 提出COLI框架，利用NeRV。首先，通过预训练-微调范式、混合精度训练和并行化损失重构来加速INR训练。其次，通过Hyper-Compression（一种训练后技术）提高压缩比并保持低失真。

**Result:** 在两个医学图像数据集上，COLI在显著降低bpp的同时，持续实现有竞争力或更优的PSNR和SSIM指标，并将NeRV训练加速高达4倍。

**Conclusion:** COLI通过其创新方法解决了大型图像INR压缩的局限性，实现了卓越的压缩效率和质量。

> **ai_Abstract:** COLI是一个针对大型图像的高效压缩框架，它解决了现有隐式神经表示（INRs）在压缩大图像时速度慢和压缩比低的问题。通过引入预训练-微调、混合精度训练和并行化损失重构来加速INR训练，并采用Hyper-Compression技术提高压缩比，COLI在医学图像数据集上实现了卓越的压缩性能，显著降低了数据量并保持了图像质量。

> **摘要翻译:** 高分辨率、大视场图像的日益普及，加剧了对高效压缩方法的需求。传统技术常常无法保留关键图像细节，而数据驱动方法则泛化能力有限。隐式神经表示（INRs）通过学习从空间坐标到像素强度的连续映射，为单个图像提供了一种有前景的替代方案，从而存储网络权重而非原始像素，并避免了泛化问题。然而，基于INR的大图像压缩面临着压缩速度慢和压缩比不理想的挑战。为了解决这些限制，我们引入了COLI（大型图像压缩器），一个利用视频神经表示（NeRV）的新颖框架。首先，认识到基于INR的压缩构成一个训练过程，我们通过预训练-微调范式、混合精度训练以及将序列损失重构为可并行化目标来加速其收敛。其次，利用INRs将图像存储限制转换为权重存储的特点，我们实现了超压缩（Hyper-Compression），这是一种新颖的训练后技术，可以大幅提高压缩比，同时保持最小的输出失真。在两个医学影像数据集上的评估表明，COLI在显著降低每像素比特数（bpp）的同时，持续实现有竞争力或更优的PSNR和SSIM指标，同时将NeRV训练加速高达4倍。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [95] [GroundingSuite: Measuring Complex Multi-Granular Pixel Grounding](https://arxiv.org/abs/2503.10596)
> *GroundingSuite：测量复杂多粒度像素接地*

*Rui Hu, Lianghui Zhu, Yuxuan Zhang, Tianheng Cheng, Lei Liu, Heng Liu, Longjin Ran, Xiaoxin Chen, Wenyu Liu, Xinggang Wang* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 像素接地, 指代表达分割, 数据集, 自动化标注, 视觉-语言模型

**Comment:** To appear at ICCV 2025. Code:
  https://github.com/hustvl/GroundingSuite

> **TL;DR:** GroundingSuite提出了一个自动化数据标注框架、一个大规模训练数据集和一个评估基准，旨在解决现有像素接地数据集的局限性，并显著提升了模型性能和标注效率。

**AI_Comments:** GroundingSuite的创新之处在于其自动化数据标注框架，利用VLM代理解决了高质量标注稀缺的问题，并成功构建了一个大规模、多样化的数据集。这对于推动像素接地领域的发展至关重要，因为它直接解决了数据瓶颈。其在性能提升和标注效率方面的表现也证明了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有像素接地（如指代表达分割RES）数据集存在局限性，包括对象类别有限、文本多样性不足以及高质量标注稀缺，这阻碍了该领域的进展。

**Method:** 本文引入了GroundingSuite，它包含三个主要部分：1) 一个利用多个视觉-语言模型（VLM）代理的自动化数据标注框架；2) 一个包含956万个不同指代表达及其对应分割的大规模训练数据集；3) 一个精心策划的包含3,800张图像的评估基准。

**Result:** GroundingSuite训练数据集显著提升了模型性能，使其达到了最先进水平，例如在gRefCOCO上cIoU达到68.9，在RefCOCOm上gIoU达到55.3。此外，GroundingSuite标注框架比当前的领先标注方法GLaMM快4.5倍。

**Conclusion:** GroundingSuite通过提供一个大规模、高质量的数据集和高效的标注框架，成功解决了像素接地领域现有数据集的局限性，显著提升了模型性能和数据标注效率。

> **ai_Abstract:** 本文介绍了GroundingSuite，旨在克服现有像素接地数据集的局限性。它由一个基于多VLM代理的自动化标注框架、一个包含956万个指代表达的大规模训练数据集和一个3800张图像的评估基准组成。GroundingSuite显著提升了模型的性能，并在指代表达分割任务上取得了最先进的结果，同时其标注框架比现有方法效率更高。

> **摘要翻译:** 像素接地，包括指代表达分割（RES）等任务，因其在弥合视觉和语言模态之间鸿沟的巨大潜力而受到广泛关注。然而，该领域的进展目前受到现有数据集固有限制的制约，这些限制包括对象类别有限、文本多样性不足以及高质量标注稀缺。为了缓解这些限制，我们引入了GroundingSuite，它包括：(1) 一个利用多个视觉-语言模型（VLM）代理的自动化数据标注框架；(2) 一个包含956万个不同指代表达及其对应分割的大规模训练数据集；(3) 一个精心策划的包含3,800张图像的评估基准。GroundingSuite训练数据集促进了显著的性能提升，使得在其上训练的模型能够达到最先进的结果。具体来说，在gRefCOCO上cIoU达到68.9，在RefCOCOm上gIoU达到55.3。此外，GroundingSuite标注框架与当前领先的数据标注方法GLaMM相比，显示出卓越的效率，即快4.5倍。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [110] [Semantically Informed Salient Regions Guided Radiology Report Generation](https://arxiv.org/abs/2507.11015)
> *语义信息显著区域引导的放射学报告生成*

*Zeyi Hou, Zeqiang Wei, Ruixin Yan, Ning Lang, Xiuzhuang Zhou* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 放射学报告生成, 深度学习, 显著区域, 医学准确性, 数据偏差

**Comment:** 

> **TL;DR:** 现有的放射学报告生成方法因数据偏差导致医学不准确。本文提出SISRNet，通过语义信息显著区域指导报告生成，显著提高了临床准确性。

**AI_Comments:** 该论文的创新点在于其提出的SISRNet方法，通过明确识别并利用“语义信息显著区域”和“细粒度跨模态语义”来克服放射学图像中的数据偏差问题。这种方法对于提高自动生成报告的医学准确性至关重要，极大地增强了其在临床实践中的应用潜力，解决了现有方法准确性不足的痛点。

<details>
  <summary>Details</summary>

**Motivation:** 现有利用深度学习从胸部X光片生成放射学报告的方法，由于放射学图像固有的巨大数据偏差（异常通常细微且稀疏分布），往往生成流畅但医学不准确的报告，这限制了它们在临床实践中的适用性。

**Method:** 本文提出了一种名为语义信息显著区域引导（SISRNet）的报告生成方法。该方法通过使用细粒度跨模态语义明确识别具有医学关键特征的显著区域。SISRNet在图像建模和报告生成过程中系统地关注这些高信息区域。

**Result:** SISRNet在广泛使用的IU-Xray和MIMIC-CXR数据集上显示出优于同类方法的性能。它有效捕获细微异常发现，减轻了数据偏差的负面影响，并最终生成了临床准确的报告。

**Conclusion:** 通过明确识别并关注语义信息显著区域，SISRNet成功解决了自动化放射学报告生成中医学不准确的问题，从而能够生成优越且临床准确的报告。

> **ai_Abstract:** 自动放射学报告生成面临因数据偏差导致的医学不准确问题。本文提出SISRNet方法，通过细粒度跨模态语义识别并聚焦于胸部X光片中的语义信息显著区域。该方法有效捕捉细微异常，减轻数据偏差影响，生成临床准确的报告，并在IU-Xray和MIMIC-CXR数据集上表现出优越性能。

> **摘要翻译:** 从胸部X光片自动生成放射学报告的深度学习算法的最新进展，有潜力显著减少放射科医生的繁重工作量。然而，由于放射学图像固有的巨大数据偏差，即异常通常细微且稀疏分布，现有方法往往生成流畅但医学不准确的报告，这限制了它们在临床实践中的适用性。为了有效解决这个问题，我们提出了一种语义信息显著区域引导（SISRNet）报告生成方法。具体来说，我们的方法利用细粒度跨模态语义明确识别具有医学关键特征的显著区域。然后，SISRNet在图像建模和报告生成过程中系统地关注这些高信息区域，有效捕获细微异常发现，减轻数据偏差的负面影响，并最终生成临床准确的报告。与同类方法相比，SISRNet在广泛使用的IU-Xray和MIMIC-CXR数据集上表现出卓越的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [117] [MVCTrack: Boosting 3D Point Cloud Tracking via Multimodal-Guided Virtual Cues](https://arxiv.org/abs/2412.02734)
> *MVCTrack：通过多模态引导的虚拟线索提升3D点云跟踪*

*Zhaofeng Hu, Sifan Zhou, Zhihang Yuan, Dawei Yang, Shibo Zhao, Ci-Jyun Liang* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-15**

**Keywords:** 3D点云跟踪, 多模态融合, 虚拟线索, MVCTrack, NuScenes

**Comment:** Accepted by ICRA 2025

> **TL;DR:** 提出MVCTrack，通过多模态引导的虚拟线索增强稀疏3D点云，提升3D目标跟踪性能。

**AI_Comments:** MVCTrack的创新点在于提出了多模态引导虚拟线索投影(MVCP)方案，巧妙地利用了RGB图像的2D检测信息来补充LiDAR点云的稀疏性。这种方法通过生成“虚拟线索”而非直接融合原始数据，为多模态融合提供了一种新颖的思路，提升了在挑战性场景下3D跟踪的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D单目标跟踪方法常在稀疏和不完整的点云场景中表现不佳。

**Method:** 提出多模态引导虚拟线索投影（MVCP）方案，将RGB传感器与LiDAR系统集成，利用2D检测生成密集的3D虚拟线索来丰富稀疏点云。在此基础上，引入了增强型跟踪器MVCTrack，该跟踪器能够自然地与现有基于LiDAR的3D跟踪器集成。

**Result:** 在NuScenes数据集上取得了有竞争力的性能。

**Conclusion:** MVCTrack通过生成和利用多模态引导的虚拟线索，有效解决了3D点云跟踪中稀疏性和不完整性问题，显著提升了跟踪性能。

> **ai_Abstract:** 本文针对3D单目标跟踪中稀疏点云的挑战，提出了MVCTrack方法。核心在于多模态引导虚拟线索投影(MVCP)方案，该方案将RGB传感器与LiDAR系统结合，利用2D检测生成密集的3D虚拟线索来丰富稀疏点云。这些虚拟线索可与现有LiDAR跟踪器无缝集成，实验证明在NuScenes数据集上性能优异。

> **摘要翻译:** 3D单目标跟踪在自动驾驶和机器人领域至关重要。现有方法常在稀疏和不完整的点云场景中表现不佳。为解决这些局限性，我们提出了一种多模态引导虚拟线索投影（MVCP）方案，该方案生成虚拟线索以丰富稀疏点云。此外，我们引入了一种基于生成的虚拟线索的增强型跟踪器MVCTrack。具体来说，MVCP方案将RGB传感器无缝集成到基于LiDAR的系统中，利用一组2D检测来创建密集的3D虚拟线索，显著改善点云的稀疏性。这些虚拟线索可以自然地与现有基于LiDAR的3D跟踪器集成，从而产生显著的性能提升。大量实验表明，我们的方法在NuScenes数据集上取得了有竞争力的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [127] [Winsor-CAM: Human-Tunable Visual Explanations from Deep Networks via Layer-Wise Winsorization](https://arxiv.org/abs/2507.10846)
> *Winsor-CAM: 通过层级Winsorization从深度网络中获得人可调的视觉解释*

*Casey Wall, Longwei Wang, Rodrigue Rizk, KC Santosh* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 视觉解释, Grad-CAM, Winsorization, CNN可解释性, 显著性图

**Comment:** 15 pages, 10 figures, 7 tables. Submitted to IEEE Transactions on
  Pattern Analysis and Machine Intelligence

> **TL;DR:** Winsor-CAM是一种可调节的Grad-CAM扩展，通过跨层聚合信息并使用Winsorization技术减少噪声，生成更可解释的CNN视觉解释图，并在定位指标上表现更优。

**AI_Comments:** Winsor-CAM的创新之处在于其结合了多层信息聚合和Winsorization技术来处理噪声和极端值，同时引入了人可调的阈值，增强了可解释性和用户控制。这对于在高风险领域部署AI模型具有重要意义，因为它提供了更可靠和可理解的决策依据。

<details>
  <summary>Details</summary>

**Motivation:** 解释卷积神经网络(CNN)的决策过程对于在高风险领域部署模型至关重要。现有方法如Grad-CAM通常只关注最后一层或简单平均，可能掩盖重要语义信息或放大无关噪声。

**Method:** 本文提出了Winsor-CAM，它是Grad-CAM的一种新型、人可调的扩展。它通过聚合所有卷积层的信息来生成鲁棒且连贯的显著性图。为减轻噪声或极端归因值的影响，Winsor-CAM应用了基于百分位数的离群值衰减技术——Winsorization。用户可控的阈值允许进行语义级别的调整，从而能够灵活探索跨表示层次的模型行为。

**Result:** 在标准架构（ResNet50、DenseNet121、VGG16、InceptionV3）和PASCAL VOC 2012数据集上的评估表明，Winsor-CAM生成了更可解释的热图，并在定位指标（包括交并比和质心对齐）上优于Grad-CAM和统一层平均基线。

**Conclusion:** Winsor-CAM通过提供可解释的多层洞察和人机交互控制，推进了可信AI的目标。

> **ai_Abstract:** 本文提出了Winsor-CAM，作为Grad-CAM的一种人可调扩展，旨在通过聚合所有卷积层的信息并应用Winsorization技术来抑制噪声，生成更鲁棒和连贯的CNN视觉解释图。该方法允许用户通过阈值进行语义级调整，以灵活探索模型行为。实验证明，Winsor-CAM在多个标准架构和数据集上能生成更可解释的热图，并在定位指标上优于现有基线，从而提升了AI的可信度。

> **摘要翻译:** 解释卷积神经网络（CNN）的决策过程对于在高风险领域部署模型至关重要。梯度加权类激活映射（Grad-CAM）是一种广泛使用的视觉解释方法，但它通常只关注最终的卷积层或简单地对各层进行平均，这些策略可能会掩盖重要的语义线索或放大不相关的噪声。我们提出了Winsor-CAM，一种新颖的、人可调的Grad-CAM扩展，它通过聚合所有卷积层的信息来生成鲁棒且连贯的显著性图。为了减轻噪声或极端归因值的影响，Winsor-CAM应用了Winsorization，这是一种基于百分位数的离群值衰减技术。用户可控的阈值允许进行语义级别调整，从而能够灵活探索跨表示层次的模型行为。在标准架构（ResNet50、DenseNet121、VGG16、InceptionV3）上使用PASCAL VOC 2012数据集进行的评估表明，与Grad-CAM和统一层平均基线相比，Winsor-CAM生成了更可解释的热图，并在定位指标（包括交并比和质心对齐）上取得了卓越的性能。Winsor-CAM通过提供可解释的多层洞察和人机交互控制，推进了可信AI的目标。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [130] [COIN: Confidence Score-Guided Distillation for Annotation-Free Cell Segmentation](https://arxiv.org/abs/2503.11439)
> *COIN：置信度评分引导的无标注细胞分割蒸馏*

*Sanghyun Jo, Seo Jin Lee, Seungwoo Lee, Seohyung Hong, Hyungseok Seo, Kyungsu Kim* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 细胞实例分割, 无监督学习, 自蒸馏, 置信度评分, 图像分割

**Comment:** Accepted at ICCV 2025

> **TL;DR:** COIN是一种新的无标注细胞实例分割框架，通过置信度评分引导的自蒸馏，在多个数据集上超越了现有无监督甚至半监督和弱监督方法。

**AI_Comments:** COIN的创新之处在于其无标注框架和置信度评分引导的自蒸馏机制，有效解决了无监督细胞分割中缺乏准确标注和边界模糊的问题。通过生成高置信度实例并进行递归蒸馏，它为细胞实例分割提供了一种无需人工标注的强大替代方案，对生物医学图像分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 细胞实例分割对生物医学研究至关重要，但现有无监督方法无法准确捕捉细胞边界，导致漏检和性能不佳。主要限制在于缺乏无误差实例。

**Method:** COIN框架包含三个主要步骤：1) 通过最优传输的无监督语义分割提高无误差实例的敏感性；2) 实例级置信度评分，衡量模型预测与精炼掩膜的一致性，识别高置信度实例，替代真值标注；3) 通过递归自蒸馏逐步扩展置信度。

**Result:** 在六个数据集上的大量实验表明，COIN优于现有UCIS方法，甚至在MoNuSeg和TNBC数据集上，其所有指标都超越了半监督和弱监督方法。

**Conclusion:** COIN通过其新颖的置信度评分引导的自蒸馏框架，有效解决了无监督细胞实例分割中边界捕捉不准确的问题，并在多个数据集上取得了显著优于现有方法的性能。

> **ai_Abstract:** COIN是一种新颖的无标注细胞实例分割框架，旨在解决现有无监督方法在捕捉细胞边界和性能上的不足。该框架通过无监督语义分割、实例级置信度评分以及递归自蒸馏三个关键步骤，生成高置信度实例并逐步扩展。实验结果表明，COIN在多个数据集上显著优于现有无监督方法，甚至超越了某些半监督和弱监督方法。

> **摘要翻译:** 细胞实例分割（CIS）对于识别组织病理图像中的单个细胞形态至关重要，为生物学和医学研究提供了宝贵的见解。虽然无监督CIS（UCIS）模型旨在减少对劳动密集型图像标注的严重依赖，但它们未能准确捕捉细胞边界，导致漏检和性能不佳。认识到缺乏无误差实例是关键限制，我们提出了COIN（COnfidence score-guided INstance distillation），一个新颖的无标注框架，包含三个关键步骤：(1) 通过最优传输的无监督语义分割提高无误差实例的敏感性，利用其区分空间微小实例的能力；(2) 实例级置信度评分，衡量模型预测与精炼掩膜之间的一致性，并识别高度置信的实例，作为地面真值标注的替代方案；(3) 通过递归自蒸馏逐步扩展置信度。在六个数据集上进行的广泛实验表明，COIN优于现有UCIS方法，甚至在MoNuSeg和TNBC数据集上，其所有指标都超越了半监督和弱监督方法。代码可在https://github.com/shjo-april/COIN获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [131] [HUG-VAS: A Hierarchical NURBS-Based Generative Model for Aortic Geometry Synthesis and Controllable Editing](https://arxiv.org/abs/2507.11474)
> *HUG-VAS：一种基于分层NURBS的主动脉几何合成与可控编辑生成模型*

*Pan Du, Mingqi Xu, Xiaozhi Zhu, Jian-xun Wang* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 主动脉几何合成, NURBS, 扩散模型, 统计形状建模, 血管分析

**Comment:** 59 pages, 9 figures

> **TL;DR:** HUG-VAS是一个新型的统计形状建模框架，它结合了NURBS和分层扩散模型，用于合成真实主动脉几何，并支持条件生成，解决了传统方法的局限性。

**AI_Comments:** HUG-VAS的创新之处在于它是首个将NURBS参数化、分层扩散过程与图像衍生先验相结合的统计形状建模框架，显著提升了复杂血管结构建模的表达能力和生成质量，并具备实用的条件生成能力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的统计形状建模(SSM)方法依赖线性假设，限制了其对多分支血管结构等复杂拓扑的表达能力和可扩展性，而精确表征血管几何形状对于心血管诊断和治疗规划至关重要。

**Method:** HUG-VAS是一种分层NURBS血管几何生成模型，它将NURBS曲面参数化与基于扩散的生成建模相结合。其采用分层架构，包括一个生成中心线的去噪扩散模型和一个基于中心线合成径向剖面的引导扩散模型，以捕获两层解剖变异性。

**Result:** HUG-VAS使用21个患者特异性样本进行训练，生成了解剖学上忠实的主动脉和主动脉上分支，产生的生物标记物分布与原始数据集的分布高度匹配。该框架支持来自图像衍生先验的零样本条件生成。

**Conclusion:** HUG-VAS是第一个通过统一整合NURBS参数化和分层扩散过程，将图像衍生先验与生成形状建模相结合的SSM框架，支持交互式半自动分割、降级成像条件下的鲁棒重建以及植入设备优化等实际应用。

> **ai_Abstract:** HUG-VAS是一种新型的分层NURBS生成模型，用于合成真实的主动脉几何形状。它通过结合NURBS参数化和分层扩散模型（包括中心线生成和径向剖面合成），克服了传统统计形状建模在处理复杂血管结构时的局限性。该模型能够生成解剖学上准确的主动脉结构，并支持零样本条件生成，为医疗图像分析和植入设备优化提供了实用工具。

> **摘要翻译:** 血管几何形状的精确表征对于心血管诊断和治疗规划至关重要。传统的统计形状建模 (SSM) 方法依赖于线性假设，限制了它们对多分支血管结构等复杂拓扑的表达能力和可扩展性。我们引入了 HUG-VAS，一种用于血管几何合成的分层 NURBS 生成模型，它将 NURBS 曲面参数化与基于扩散的生成建模相结合，以合成逼真、精细的主动脉几何形状。HUG-VAS 使用 21 个患者特异性样本进行训练，生成了解剖学上忠实的主动脉和主动脉上分支，产生的生物标记物分布与原始数据集的分布高度匹配。HUG-VAS 采用分层架构，包括一个生成中心线的去噪扩散模型和一个基于这些中心线合成径向剖面的引导扩散模型，从而捕获两层解剖变异性。关键是，该框架支持来自图像衍生先验的零样本条件生成，从而实现交互式半自动分割、降级成像条件下的鲁棒重建以及植入设备优化等实际应用。据我们所知，HUG-VAS 是第一个通过统一整合 NURBS 参数化和分层扩散过程，将图像衍生先验与生成形状建模相结合的 SSM 框架。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [132] [Task-Oriented Human Grasp Synthesis via Context- and Task-Aware Diffusers](https://arxiv.org/abs/2507.11287)
> *基于上下文和任务感知的扩散模型实现面向任务的人体抓取合成*

*An-Lun Liu, Yu-Wei Chao, Yi-Ting Chen* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-15**

**Keywords:** 人体抓取合成, 面向任务, 任务感知接触图, 扩散模型, 上下文感知

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 本文提出了一种面向任务的人体抓取合成新方法，核心是任务感知接触图，该方法通过一个两阶段流程，利用场景和任务信息生成准确的抓取姿态，并在抓取质量和任务性能上显著优于现有方法。

**AI_Comments:** 本文的创新点在于提出了“任务感知接触图”这一概念，并将其应用于人体抓取合成，有效结合了场景和任务信息，解决了传统抓取合成缺乏上下文感知的问题。所提出的两阶段流程和新数据集/指标也为该领域的研究提供了新的方向和评估工具。其重要性体现在显著提升了抓取质量和任务性能，使抓取更符合实际任务需求。

<details>
  <summary>Details</summary>

**Motivation:** 现有的抓取合成任务缺乏对任务和上下文的感知能力，无法生成与特定任务相符的准确抓取姿态。本文旨在研究面向任务的人体抓取合成，以满足对任务和上下文感知能力的需求，从而实现更精确的抓取姿态。

**Method:** 本方法的核心是任务感知接触图，与传统接触图不同，它考虑了场景和任务信息。我们提出了一个两阶段流程：首先，根据场景和任务信息构建任务感知接触图；其次，利用该接触图合成面向任务的人体抓取。此外，我们还引入了新的数据集和评估指标来验证所提出的方法。

**Result:** 实验验证了对场景和任务进行建模的重要性，结果表明，与现有方法相比，我们的方法在抓取质量和任务性能方面均有显著提升。

**Conclusion:** 本文成功提出了面向任务的人体抓取合成这一新任务，并开发了一种基于任务感知接触图的两阶段方法。该方法有效整合了场景和任务信息，显著提高了抓取质量和任务性能，验证了对场景和任务建模的重要性。

> **ai_Abstract:** 本文提出了一种新的抓取合成任务——面向任务的人体抓取合成，强调任务和上下文感知。核心方法是任务感知接触图，它整合了场景和任务信息。该方法采用两阶段流程：首先构建任务感知接触图，然后利用其合成抓取。实验证明，该方法在抓取质量和任务性能上显著优于现有方法，并引入了新的数据集和评估指标。

> **摘要翻译:** 在本文中，我们研究了面向任务的人体抓取合成，这是一项需要任务和上下文感知的新型抓取合成任务。我们方法的核心是任务感知接触图。与传统上仅考虑被操作物体及其与手部关系的接触图不同，我们增强的接触图考虑了场景和任务信息。这种全面的接触图对于手-物体交互至关重要，能够实现与任务对齐的准确抓取姿态。我们提出了一个两阶段流程，首先构建一个由场景和任务信息告知的任务感知接触图。在随后的阶段，我们使用此接触图来合成面向任务的人体抓取。我们为所提出的任务引入了一个新的数据集和评估指标来评估我们的方法。我们的实验验证了对场景和任务进行建模的重要性，证明了在抓取质量和任务性能方面均比现有方法有显著改进。更多详情请参见我们的项目页面：https://hcis-lab.github.io/TOHGS/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [135] [Latent Space Consistency for Sparse-View CT Reconstruction](https://arxiv.org/abs/2507.11152)
> *稀疏视角CT重建中的潜在空间一致性*

*Duoyou Chen, Yunqing Chen, Can Zhang, Zhou Wang, Cheng Chen, Ruoxiu Xiao* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 稀疏视角CT, 潜在扩散模型, 跨模态, 潜在空间一致性, 图像重建

**Comment:** ACMMM2025 Accepted

> **TL;DR:** 为了解决传统CT耗时和辐射大的问题，本文提出了一种名为CLS-DM的扩散模型，通过跨模态特征对比学习，有效对齐2D X射线和3D CT的潜在空间，从而改进了稀疏视角CT重建效果，并在LIDC-IDRI和CTSpine1K数据集上优于现有模型。

**AI_Comments:** 本文的创新点在于针对稀疏视角CT重建中扩散模型（特别是LDM）存在的跨模态潜在空间不对齐问题，提出了CLS-DM模型。通过引入跨模态特征对比学习，该方法有效地实现了2D X射线与3D CT数据在潜在空间的对齐，这是对现有扩散模型在处理异构数据方面的重要改进。其在提升CT重建质量和经济性方面的实际应用价值显著，并且具有推广到其他跨模态任务（如文本到图像合成）的潜力，显示了其广泛的应用前景和理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统CT成像存在耗时和高辐射暴露的问题。稀疏视角CT重建方法可以减轻这些问题，但现有的扩散模型（特别是潜在扩散模型LDM）在处理2D X射线图像的潜在表示与3D CT图像的潜在表示之间存在显著差异，导致潜在空间无法有效对齐。

**Method:** 本文提出了“一致潜在空间扩散模型”（Consistent Latent Space Diffusion Model, CLS-DM）。该模型通过引入跨模态特征对比学习，能够高效地从2D X射线图像中提取潜在的3D信息，并实现不同模态间潜在空间的对齐。

**Result:** 实验结果表明，CLS-DM在LIDC-IDRI和CTSpine1K数据集上，于标准体素级指标（PSNR, SSIM）方面，优于经典的以及最先进的生成模型。

**Conclusion:** CLS-DM方法不仅有助于提高稀疏X射线重建CT的有效性和经济可行性，而且可以推广到其他跨模态转换任务，例如文本到图像的合成。

> **ai_Abstract:** 本论文旨在解决稀疏视角CT重建中，现有扩散模型（如LDM）在2D X射线和3D CT模态之间潜在空间不对齐的问题。为此，作者提出了一种新的模型——一致潜在空间扩散模型（CLS-DM），该模型通过引入跨模态特征对比学习，有效提取2D X射线图像中的3D潜在信息，并实现不同模态间潜在空间的对齐。实验结果表明，CLS-DM在LIDC-IDRI和CTSpine1K数据集上，在PSNR和SSIM等关键指标上，均优于传统及最新的生成模型，证明了其在提升稀疏CT重建效果上的潜力，并展示了其在其他跨模态任务中的泛化能力。

> **摘要翻译:** 计算机断层扫描（CT）是临床环境中广泛使用的成像方式。利用密集采集的旋转X射线阵列，CT可以捕获3D空间特征。然而，它面临着诸如耗时和高辐射暴露等挑战。基于稀疏视角X射线图像的CT重建方法受到了研究人员的广泛关注，因为它们提供了一种降低成本和风险的手段。近年来，扩散模型，特别是潜在扩散模型（LDM），在3D CT重建领域展现出有前景的潜力。然而，由于X射线模态的2D潜在表示与CT模态的3D潜在表示之间存在显著差异，原始LDM无法在潜在空间内实现有效对齐。为了解决这个问题，我们提出了“一致潜在空间扩散模型”（CLS-DM），它结合了跨模态特征对比学习，以有效地从2D X射线图像中提取潜在的3D信息，并实现模态间潜在空间的对齐。实验结果表明，CLS-DM在LIDC-IDRI和CTSpine1K数据集上，于标准体素级指标（PSNR, SSIM）方面，优于经典的以及最先进的生成模型。这种方法不仅有助于提高稀疏X射线重建CT的有效性和经济可行性，而且可以推广到其他跨模态转换任务，例如文本到图像的合成。我们已将代码公开在https://anonymous.4open.science/r/CLS-DM-50D6/，以促进在其他领域进行进一步的研究和应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [143] [Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding](https://arxiv.org/abs/2506.22803)
> *干预黑箱：概念瓶颈模型增强人与神经网络的相互理解*

*Nuoye Xiong, Anqi Dong, Ning Wang, Cong Hua, Guangming Zhu, Lin Mei, Peiyi Shen, Liang Zhang* | **Category: cs.CV, cs.HC, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 概念瓶颈模型, 可解释AI, 黑箱模型, 神经网络, 模型干预

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 提出CBM-HNMU模型，通过概念瓶颈模型解释并修正黑箱模型，提升可解释性和准确性。

**AI_Comments:** 该论文的创新点在于提出了一个可干预的黑箱模型解释框架CBM-HNMU，它不仅解释了模型决策，还能通过概念修正来提升模型性能。这超越了传统解释方法仅提供事后解释的局限性，实现了“理解-干预-改进”的闭环，对于提升深度学习模型在关键应用中的可靠性和信任度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型日益复杂，降低了可解释性，决策难以理解；现有解释方法缺乏有效干预或仅在样本级别操作，无法修改模型本身。

**Method:** 提出CBM-HNMU，利用概念瓶颈模型(CBM)作为可解释框架，近似黑箱推理并传达概念理解。通过全局梯度贡献自动识别并修正（移除/替换）有害概念。修改后的CBM将纠正后的知识蒸馏回黑箱模型，以同时提高可解释性和准确性。

**Result:** 在Flower-102、CIFAR-10、CIFAR-100、FGVC-Aircraft和CUB-200等数据集上，对CNN和transformer模型进行评估，最大准确率提升2.64%，平均准确率提升1.03%。

**Conclusion:** CBM-HNMU通过干预黑箱模型，有效提升了深度学习模型的可解释性和准确性。

> **ai_Abstract:** 本文提出了CBM-HNMU（概念瓶颈模型增强人与神经网络相互理解），旨在解决深度学习模型日益复杂导致可解释性差的问题。CBM-HNMU利用概念瓶颈模型近似黑箱推理，通过识别并修正有害概念，然后将纠正后的知识蒸馏回原黑箱模型，从而同时提升模型的可解释性和准确性。在多个数据集和模型上的实验证明了其有效性。

> **摘要翻译:** 深度学习的最新进展导致模型日益复杂，层数更深、参数更多，降低了可解释性，使其决策更难理解。尽管许多方法解释了黑箱推理，但大多数缺乏有效的干预，或者只在样本级别操作，而不能修改模型本身。为了解决这个问题，我们提出了用于增强人与神经网络相互理解的概念瓶颈模型（CBM-HNMU）。CBM-HNMU利用概念瓶颈模型（CBM）作为可解释框架，以近似黑箱推理并传达概念理解。根据全局梯度贡献自动识别并修正（移除/替换）有害概念。然后，修改后的CBM将纠正后的知识蒸馏回黑箱模型，从而提高可解释性和准确性。我们在Flower-102、CIFAR-10、CIFAR-100、FGVC-Aircraft和CUB-200等各种CNN和基于transformer的模型上评估了CBM-HNMU，实现了2.64%的最大准确率提升和1.03%的平均准确率最大增幅。源代码可在以下地址获取：https://github.com/XiGuaBo/CBM-HNMU。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [153] [Human-Guided Shade Artifact Suppression in CBCT-to-MDCT Translation via Schrödinger Bridge with Conditional Diffusion](https://arxiv.org/abs/2507.11025)
> *人工引导的CBCT到MDCT转换中基于薛定谔桥和条件扩散的阴影伪影抑制*

*Sung Ho Kang, Hyun-Cheol Park* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** CBCT-to-MDCT转换, 薛定谔桥, 条件扩散, 阴影伪影抑制, 人类引导

**Comment:** 

> **TL;DR:** 一种新颖的基于薛定谔桥和条件扩散的CBCT到MDCT图像转换框架，通过人类反馈有效抑制阴影伪影，实现高保真和高效的医学图像转换。

**AI_Comments:** 该论文的创新之处在于将薛定谔桥公式与人类引导的条件扩散相结合，并引入了无需奖励模型的人类偏好学习机制（通过CFG和迭代选择）。这种方法有效解决了传统生成模型在医学图像转换中边界一致性和人工干预的难题，尤其是在伪影抑制方面表现出色，且效率高，具有重要的临床应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有GAN或扩散模型在CBCT到MDCT转换中可能存在边界一致性问题，且难以有效整合人类偏好来抑制伪影，从而限制了临床应用。本文旨在解决这些问题，实现更精确、可控且符合临床偏好的图像转换。

**Method:** 提出了一种基于薛定谔桥(SB)公式的新型框架，该框架集成了GAN衍生的先验和人类引导的条件扩散。该方法明确强制CBCT输入和伪目标之间的边界一致性。通过分类器自由引导(CFG)整合二元人类反馈，并利用迭代细化和基于锦标赛的偏好选择来内化人类偏好，无需奖励模型。

**Result:** 提出的方法选择性地衰减关键解剖区域的阴影伪影，同时保留精细结构细节。在RMSE、SSIM、LPIPS和Dice指标上，在临床数据集上表现出卓越的性能，优于之前的GAN和基于微调的反馈方法，并且仅需10个采样步骤。

**Conclusion:** 该框架对于实时、偏好对齐的医学图像转换具有有效性和高效性。

> **ai_Abstract:** 本文提出了一种基于薛定谔桥和条件扩散的新型CBCT到MDCT图像转换框架。该方法通过强制边界一致性和整合人类反馈（通过分类器自由引导及迭代偏好学习），有效抑制阴影伪影，同时保留精细结构。实验结果表明，该框架在多项定量指标上优于现有方法，且效率高，仅需10步采样，适用于实时医学图像转换。

> **摘要翻译:** 我们提出了一种用于CBCT到MDCT转换的新颖框架，该框架基于薛定谔桥（SB）公式，并集成了GAN衍生的先验和人类引导的条件扩散。与传统的GAN或扩散模型不同，我们的方法明确强制了CBCT输入和伪目标之间的边界一致性，确保了解剖保真度和感知可控性。通过分类器自由引导（CFG）整合二元人类反馈，有效引导生成过程趋向临床偏好的结果。通过迭代细化和基于锦标赛的偏好选择，模型在不依赖奖励模型的情况下内化了人类偏好。减影图像可视化显示，所提出的方法选择性地衰减了关键解剖区域的阴影伪影，同时保留了精细结构细节。定量评估进一步证明了在临床数据集上，该方法在RMSE、SSIM、LPIPS和Dice指标上具有卓越的性能——优于之前的GAN和基于微调的反馈方法——同时仅需10个采样步骤。这些发现强调了我们框架在实时、偏好对齐的医学图像转换方面的有效性和效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [155] [COLIBRI Fuzzy Model: Color Linguistic-Based Representation and Interpretation](https://arxiv.org/abs/2507.11488)
> *COLIBRI 模糊模型：基于颜色语言的表示与解释*

*Pakizar Shamoi, Nuray Toganas, Muragul Muratbekova, Elnara Kadyrgali, Adilet Yerkin, Ayan Igali, Malika Ziyada, Ayana Adilova, Aron Karatayev, Yerdauit Torekhan* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 模糊颜色模型, 人类感知, 颜色分类, COLIBRI, 模糊逻辑

**Comment:** submitted to IEEE for consideration

> **TL;DR:** 本文提出了COLIBRI模糊颜色模型，通过大规模人类感知实验，使计算机更好地模仿人类颜色感知，并证明其优于传统颜色模型。

**AI_Comments:** 这项研究的创新之处在于提出了一个基于大规模人类感知数据构建的模糊颜色模型，旨在更好地模拟人类对颜色的理解和分类。其核心贡献在于利用模糊逻辑来处理人类感知的不确定性，并通过前所未有的样本量（2496人）来验证模型的有效性。这对于弥合计算与人类感知之间的鸿沟具有重要意义，尤其是在需要高度感知相关性的应用领域。

<details>
  <summary>Details</summary>

**Motivation:** 计算机难以模仿人类颜色感知，存在计算颜色表示与人类视觉感知之间的鸿沟。

**Method:** 本文提出了COLIBRI（基于颜色语言的表示和解释）模糊颜色模型，该模型利用模糊集和逻辑来创建颜色分类框架。研究采用三阶段实验方法：首先通过初步实验识别色调、饱和度和强度的可区分颜色刺激；接着进行涉及1000多名人类受试者的大规模人类分类调查；然后利用所得数据提取模糊分区并生成反映真实世界感知不确定性的隶属函数。模型还包含一个允许基于反馈和上下文变化进行细化的适应机制。

**Result:** COLIBRI模型与人类感知的对齐程度高于传统颜色模型（如RGB、HSV和LAB）。据作者所知，这是首次基于如此大规模样本（n = 2496）构建颜色属性规范模型的研究。

**Conclusion:** 该研究结果对于设计、人工智能、市场营销和人机交互等领域具有重要意义，因为在这些领域中，感知相关的颜色表示至关重要。

> **ai_Abstract:** 本文提出了一种名为COLIBRI的基于人类感知的模糊颜色模型，旨在解决计算机难以模仿人类颜色感知的问题。该模型利用模糊集和逻辑，并通过大规模人类分类调查（涉及2496名受试者）的数据来构建颜色分类框架和生成反映感知不确定性的隶属函数。实验评估表明，COLIBRI模型与人类感知的对齐程度优于传统颜色模型，其在设计、AI、营销和人机交互等领域具有重要应用价值。

> **摘要翻译:** 颜色在当今世界无处不在，在人类感知和与周围环境互动的方式中发挥着至关重要的作用。然而，计算机模仿人类颜色感知具有挑战性。本文介绍了基于人类感知的模糊颜色模型COLIBRI（基于颜色语言的表示和解释），旨在弥合计算颜色表示与人类视觉感知之间的差距。所提出的模型使用模糊集和逻辑来创建颜色分类框架。通过三阶段实验方法，该研究首先通过初步实验确定色调、饱和度和强度的可区分颜色刺激，然后进行涉及1000多名人类受试者的大规模人类分类调查。所得数据用于提取模糊分区并生成反映真实世界感知不确定性的隶属函数。该模型包含一个适应机制，允许根据反馈和上下文变化进行细化。比较评估表明，与传统的颜色模型（如RGB、HSV和LAB）相比，该模型与人类感知更加一致。据我们所知，以前没有研究记录过基于如此规模样本或类似人类群体样本（n = 2496）构建颜色属性规范模型。我们的发现对于设计、人工智能、市场营销和人机交互等领域具有重要意义，因为在这些领域中，与感知相关的颜色表示至关重要。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [161] [AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization](https://arxiv.org/abs/2503.22526)
> *AnnoPage 数据集：文档中非文本元素的细粒度分类数据集*

*Martin Kišš, Michal Hradiš, Martina Dvořáková, Václav Jiroušek, Filip Kersch* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** AnnoPage数据集, 非文本元素, 文档布局分析, 目标检测, 历史文档

**Comment:** 17 pages, 2 tables, 7 figures; Accepted to GREC Workshop at ICDAR2025

> **TL;DR:** AnnoPage是一个包含7,550页历史文档的非文本元素数据集，具有25个细粒度类别，旨在支持文档布局分析和目标检测研究，并提供基线结果。

**AI_Comments:** AnnoPage数据集的创新之处在于其对历史文档中非文本元素的细粒度分类标注，涵盖了25个类别，这对于文档布局分析和目标检测领域具有重要意义。由专业图书管理员进行标注确保了数据质量，而包含多语言和多时期文档则增加了数据集的泛化能力。提供基线结果和YOLO格式的真值标注降低了研究人员的使用门槛，是该领域一个非常有价值的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 该数据集旨在支持文档布局分析和目标检测研究。

**Method:** AnnoPage数据集包含7,550页历史文档，主要为捷克语和德语，时间跨度从1485年至今，重点是19世纪末和20世纪初。每页都用轴对齐边界框（AABB）标注了25个非文本元素类别，如图像、地图、装饰元素或图表，遵循捷克图像文档处理方法。标注由专业图书管理员创建。数据集还包含来自多个历史文档数据集的页面，并分为开发和测试子集，测试集保持类别分布。研究者还使用YOLO和DETR目标检测器提供了基线结果。

**Result:** 数据集包含7,550页历史文档，标注了25个细粒度类别的非文本元素。提供了使用YOLO和DETR目标检测器的基线结果。数据集可公开获取，并提供YOLO格式的真值标注。

**Conclusion:** AnnoPage数据集是一个新的、公开可用的资源，为文档布局分析和目标检测领域的未来研究提供了丰富的标注数据和基线参考。

> **ai_Abstract:** AnnoPage数据集是一个包含7,550页历史文档的新集合，主要为捷克语和德语，标注了25个细粒度类别的非文本元素，如图像、地图和图表。该数据集旨在支持文档布局分析和目标检测研究，由专业图书管理员进行标注，并包含来自多个历史数据集的页面。它提供开发和测试子集，并使用YOLO和DETR提供了基线结果，可公开获取，为该领域的研究提供了宝贵的资源。

> **摘要翻译:** 我们介绍了AnnoPage数据集，这是一个包含7,550页历史文档的新集合，主要为捷克语和德语，时间跨度从1485年至今，重点是19世纪末和20世纪初。该数据集旨在支持文档布局分析和目标检测研究。每页都用轴对齐边界框（AABB）标注了25个非文本元素类别，如图像、地图、装饰元素或图表，遵循捷克图像文档处理方法。标注由专业图书管理员创建，以确保准确性和一致性。数据集还包含来自多个（主要是历史）文档数据集的页面，以增强多样性并保持连续性。数据集分为开发和测试子集，测试集经过精心选择以保持类别分布。我们使用YOLO和DETR目标检测器提供了基线结果，为未来的研究提供了参考点。AnnoPage数据集已在Zenodo上公开提供（https://doi.org/10.5281/zenodo.12788419），并附带YOLO格式的真值标注。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [165] [C-FBI: A Combinatorial method using Convolutions for Circle Fitting in Blurry Images](https://arxiv.org/abs/2507.11476)
> *C-FBI：一种结合卷积的模糊图像圆拟合组合方法*

*Esteban Román Catafau, Torbjörn E. M. Nordling* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 圆拟合, 模糊图像, 卷积, 组合方法, 实时性能

**Comment:** 22 pages, 16 figures

> **TL;DR:** C-FBI是一种新颖的组合卷积方法，用于在模糊图像中进行鲁棒的圆拟合，实现了最先进的精度和实时性能。

**AI_Comments:** C-FBI的创新之处在于其将组合边缘像素采样与卷积基密度估计相结合，有效解决了模糊图像中的圆拟合难题。该方法在精度和速度上均达到了最先进水平，尤其是在实时性能上的突破，使其在对时间敏感的应用中具有重要价值。其在不同分辨率和异常值污染水平下的鲁棒性也值得称赞，拓宽了其应用范围。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决在退化成像条件下进行鲁棒圆检测和拟合这一基本的计算机视觉挑战。

**Method:** 本文提出了组合卷积模糊图像圆拟合（3C-FBI）算法，该算法通过结合高效的组合边缘像素（edgel）采样和基于卷积的参数空间密度估计，弥合了圆检测和精确参数拟合之间的鸿沟。

**Result:** 3C-FBI在帕金森病评估的真实世界医学数据、受控合成数据以及不同空间分辨率和异常值污染水平下进行了评估。结果显示，3C-FBI实现了最先进的精度（Jaccard指数0.896），同时保持了实时性能（40.3 fps），显著优于RCD等经典方法（6.8 fps）。它在480x480高分辨率下保持接近完美的精度（Jaccard几乎为1.0），在低至160x160分辨率和高达20%异常值的情况下也能保持可靠性能（Jaccard高于0.95）。在广泛的合成测试中，3C-FBI在不同污染水平下实现了0.989的平均Jaccard指数，与Qi等人的现代方法（2024，0.991）相当，并超越了RHT（0.964）。

**Conclusion:** 精度、速度和鲁棒性的结合使得3C-FBI成为在挑战性条件下进行医学成像、机器人技术和工业检测的理想选择。

> **ai_Abstract:** 本研究提出了一种名为3C-FBI的组合卷积方法，用于在模糊图像中进行鲁棒的圆检测和精确拟合。该算法结合了高效的边缘像素采样和基于卷积的参数空间密度估计。通过在真实医学数据、合成数据和不同退化条件下的广泛评估，3C-FBI展示了最先进的精度（Jaccard 0.896）和实时性能（40.3 fps），显著优于传统方法，并在高分辨率和存在异常值的情况下表现出色。其高精度、高速度和鲁棒性使其适用于医学成像、机器人和工业检测等挑战性应用。

> **摘要翻译:** 本文解决了在退化成像条件下进行鲁棒圆检测和拟合这一基本的计算机视觉挑战。我们提出了组合卷积模糊图像圆拟合（3C-FBI），这是一种通过结合（1）高效的组合边缘像素（edgel）采样和（2）基于卷积的参数空间密度估计来弥合圆检测和精确参数拟合之间鸿沟的算法。
我们在三个实验框架中评估了3C-FBI：（1）来自帕金森病评估的真实世界医学数据（36个视频的144帧），（2）遵循既定圆拟合基准的受控合成数据，以及（3）对不同空间分辨率和异常值污染水平的系统分析。结果显示，3C-FBI实现了最先进的精度（Jaccard指数0.896），同时保持了实时性能（40.3 fps），在标准CPU（i7-10875H）上显著优于RCD等经典方法（6.8 fps）。它在480x480高分辨率下保持接近完美的精度（Jaccard几乎为1.0），在低至160x160分辨率和高达20%异常值的情况下也能保持可靠性能（Jaccard高于0.95）。
在广泛的合成测试中，3C-FBI在不同污染水平下实现了0.989的平均Jaccard指数，与Qi等人（2024，0.991）的现代方法相当，并超越了RHT（0.964）。精度、速度和鲁棒性的结合使得3C-FBI成为在挑战性条件下进行医学成像、机器人技术和工业检测的理想选择。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [172] [Sparse Fine-Tuning of Transformers for Generative Tasks](https://arxiv.org/abs/2507.10855)
> *稀疏微调Transformer用于生成任务*

*Wei Chen, Jingxi Yu, Zichen Miao, Qiang Qiu* | **Category: cs.CV** | **Updated: 2025-07-14**

**Keywords:** 稀疏微调, Transformer, 生成任务, 稀疏编码, 特征字典原子

**Comment:** Accepted by International Conference on Computer Vision 2025

> **TL;DR:** 提出一种基于稀疏编码的Transformer微调框架，通过稀疏组合特征字典原子来提高模型在生成任务中的可解释性和性能，并在图像编辑和文生图概念定制任务中取得良好效果。

**AI_Comments:** 这项工作创新性地将稀疏编码思想引入Transformer微调，解决了现有密集微调方法在可解释性方面的挑战。通过引入特征字典原子和稀疏系数，不仅增强了模型对新任务适应过程的理解，还在生成任务（如图像编辑和文生图）中取得了显著的性能提升，为未来高效且可解释的Transformer微调提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有微调方法中，更新的表示是修改参数的密集组合，这使得解释它们的贡献和理解模型如何适应新任务变得具有挑战性。

**Method:** 引入一种受稀疏编码启发的微调框架，将微调后的特征表示为基本元素（即特征字典原子）的稀疏组合。特征字典原子作为表示的基本构建块，通过调整原子可以无缝适应下游任务。稀疏系数随后作为原子重要性的指标，识别每个原子对更新表示的贡献。

**Result:** 1. 通过移除不重要的特征字典原子，增强了图像编辑性能，改善了文本对齐。2. 在文生图概念定制任务中，通过特征字典原子的稀疏组合高效构建目标概念，性能优于各种基线微调方法。

**Conclusion:** 该方法通过稀疏微调提高了Transformer在生成任务中的可解释性，并在图像编辑和文生图概念定制任务中展现出优越性能。

> **ai_Abstract:** 本文提出一种新颖的Transformer稀疏微调框架，灵感来源于稀疏编码。该框架将微调后的特征表示为特征字典原子的稀疏组合，这些原子作为表示的基本构建块，其稀疏系数指示了原子重要性，从而提高了模型的可解释性。实验证明，该方法在图像编辑中通过移除不重要原子提升了文本对齐和性能，并在文生图概念定制任务中通过高效构建稀疏组合的概念，超越了现有基线方法。

> **摘要翻译:** 大型预训练Transformer在各个领域彻底改变了人工智能，而微调由于从头开始训练的成本，仍然是使这些模型适应下游任务的主要方法。然而，在现有的微调方法中，更新的表示是修改参数的密集组合，这使得解释它们的贡献和理解模型如何适应新任务变得具有挑战性。在这项工作中，我们引入了一种受稀疏编码启发的微调框架，其中微调后的特征被表示为基本元素（即特征字典原子）的稀疏组合。特征字典原子作为表示的基本构建块，调整原子可以无缝适应下游任务。稀疏系数随后作为原子重要性的指标，识别每个原子对更新表示的贡献。利用稀疏系数的原子选择能力，我们首先证明我们的方法通过移除不重要的特征字典原子来改善文本对齐，从而增强了图像编辑性能。此外，我们验证了我们方法在文生图概念定制任务中的有效性，在该任务中，我们的方法通过特征字典原子的稀疏组合高效构建目标概念，优于各种基线微调方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [174] [Assessing Color Vision Test in Large Vision-language Models](https://arxiv.org/abs/2507.11153)
> *评估大型视觉语言模型中的色觉测试*

*Hongfei Ye, Bin Chen, Wenxi Liu, Yu Zhang, Zhao Li, Dandan Ni, Hongyang Chen* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 色觉测试, 大型视觉语言模型, 数据集, 微调策略, 错误分析

**Comment:** 

> **TL;DR:** 本文研究了大型视觉语言模型的色觉能力，定义了色觉测试任务，构建了专用数据集，分析了错误类型，并提出了微调策略来提升其色觉测试表现。

**AI_Comments:** 这项研究通过定义色觉测试任务和构建专门数据集，填补了大型视觉语言模型色觉能力评估的空白，并提出了实用的性能提升策略，对未来相关模型的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉语言模型的色觉能力至关重要，但目前尚未得到彻底探索。

**Method:** 研究者定义了一个针对大型视觉语言模型的色觉测试任务，并构建了一个包含多类别、不同难度级别测试问题的数据集。此外，他们分析了大型视觉语言模型所犯的错误类型，并提出了旨在增强其色觉测试性能的微调策略。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文旨在填补大型视觉语言模型色觉能力研究的空白。研究者定义了一个色觉测试任务，并构建了一个包含多类别和不同难度问题的专用数据集。通过分析模型的错误类型，他们提出了微调策略来提升大型视觉语言模型在色觉测试中的表现。

> **摘要翻译:** 随着大型视觉语言模型的广泛采用，这些模型的色觉能力至关重要。然而，大型视觉语言模型的色觉能力尚未得到彻底探索。为了解决这一空白，我们为大型视觉语言模型定义了一个色觉测试任务，并构建了一个涵盖多类别测试问题和不同难度级别任务的数据集。此外，我们分析了大型视觉语言模型所犯的错误类型，并提出了微调策略以增强它们在色觉测试中的表现。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [188] [Personalized OVSS: Understanding Personal Concept in Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2507.11030)
> *个性化开放词汇语义分割：理解开放词汇语义分割中的个人概念*

*Sunghyun Park, Jungsoo Lee, Shubhankar Borse, Munawar Hayat, Sungha Choi, Kyuwoong Hwang, Fatih Porikli* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 个性化语义分割, 开放词汇, 文本提示微调, 负掩码提议, 个人概念识别

**Comment:** Accepted to ICCV 2025; 15 pages

> **TL;DR:** 本文提出了一种名为“个性化开放词汇语义分割”的新任务，并提出了一种基于文本提示微调的即插即用方法来识别个人视觉概念，同时保持原始开放词汇语义分割的性能，并在新建立的基准测试中展示了其优越性。

**AI_Comments:** 本文的创新点在于首次提出了“个性化开放词汇语义分割”这一新颖且重要的任务，解决了现有OVSS无法处理用户特定兴趣区域的局限性。其提出的基于文本提示微调的即插即用方法，结合了“负掩码提议”和视觉嵌入注入，以高效且数据量少的方式实现了个人概念的识别，同时保持了原始模型的性能，具有很强的实用价值和通用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的开放词汇语义分割（OVSS）无法理解个人化的文本描述（如“我的马克杯”），因此无法分割用户特定感兴趣的区域，尤其是在存在多个相似物体时（如识别“我的马克杯”与“多个马克杯”）。

**Method:** 本文提出了一种名为“个性化开放词汇语义分割”的新任务。为解决该任务，作者提出了一种基于文本提示微调的即插即用方法，该方法仅使用少量图像-掩码对即可识别个人视觉概念。该方法通过引入“负掩码提议”来捕获除个性化概念之外的视觉概念，从而减少错误预测。此外，通过将个人概念的视觉嵌入注入到文本提示中，丰富了文本提示的表示，进一步提升了性能。

**Result:** 该方法在作者新建立的个性化开放词汇语义分割基准测试（包括FSS$^	ext{per}$、CUB$^	ext{per}$和ADE$^	ext{per}$）上表现出优越性。同时，该方法在增强个性化OVSS性能的同时，没有损害原始OVSS的性能。

**Conclusion:** 本文成功提出了个性化开放词汇语义分割任务及其解决方案，通过新颖的即插即用方法，有效识别了个人视觉概念，并在不牺牲原始OVSS性能的前提下，显著提升了个性化分割能力。

> **ai_Abstract:** 本文针对开放词汇语义分割（OVSS）无法理解和分割用户特定个人概念的问题，提出了一项新任务——个性化开放词汇语义分割。为解决此问题，作者提出了一种基于文本提示微调的即插即用方法。该方法通过引入“负掩码提议”来减少错误预测，并通过注入视觉嵌入来丰富文本提示的表示，从而有效地利用少量数据识别个人视觉概念。实验结果表明，该方法在不损害原始OVSS性能的前提下，在新建立的基准测试中表现出优越的个性化分割能力。

> **摘要翻译:** 虽然开放词汇语义分割（OVSS）可以根据任意给定的文本描述将图像分割成语义区域，即使是针对训练期间未见的类别，但它无法理解个人文本（例如“我的马克杯”），从而无法分割用户特定感兴趣的区域。本文解决了在“多个马克杯”中识别“我的马克杯”等挑战。为了克服这一挑战，我们引入了一项名为“个性化开放词汇语义分割”的新任务，并提出了一种基于文本提示微调的即插即用方法，旨在利用少量图像和掩码对来识别个人视觉概念，同时保持原始OVSS的性能。基于将文本提示微调应用于此任务时减少错误预测至关重要的观察，我们提出的方法采用了“负掩码提议”，该提议捕获了除个性化概念之外的视觉概念。我们通过将个人概念的视觉嵌入注入到文本提示中来丰富文本提示的表示，从而进一步提高了性能。这种方法在不损害原始OVSS性能的情况下增强了个性化OVSS。我们在为此任务新建立的基准测试（包括FSS$^	ext{per}$、CUB$^	ext{per}$和ADE$^	ext{per}$）上证明了我们方法的优越性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [189] [MFGDiffusion: Mask-Guided Smoke Synthesis for Enhanced Forest Fire Detection](https://arxiv.org/abs/2507.11252)
> *MFGDiffusion: 掩膜引导的烟雾合成用于增强森林火灾检测*

*Guanghao Wu, Chen Xu, Hai Song, Chong Wang, Qixing Zhang* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-15**

**Keywords:** 森林火灾检测, 烟雾合成, 图像生成, 扩散模型, 数据增强

**Comment:** 18 pages, 11 figures

> **TL;DR:** MFGDiffusion提出了一种掩膜引导的扩散模型框架，用于生成逼真的森林火灾烟雾图像，以解决数据稀缺问题并提高火灾检测模型的性能。

**AI_Comments:** 该论文通过提出一个综合的掩膜引导扩散模型框架，创新性地解决了森林火灾烟雾数据稀缺的挑战。其引入的掩膜随机差异损失，以及利用多模态大语言模型进行数据筛选的策略，有效提升了合成烟雾图像的质量和多样性，从而显著增强了下游检测任务的性能。这是一个重要的贡献，为解决特定领域数据不足提供了有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 森林火灾烟雾图像数据稀缺是阻碍森林火灾烟雾检测的重要因素。此外，现有图像修复模型在生成高质量烟雾表示时存在局限性，尤其是在合成烟雾与背景上下文之间存在不一致性。

**Method:** 我们提出了一个综合框架来生成森林火灾烟雾图像。首先，利用预训练分割模型和多模态模型获取烟雾掩膜和图像描述。其次，引入了一种由掩膜和掩膜图像特征引导的网络架构，以解决修复模型对掩膜和掩膜图像利用不足的问题。还提出了一种新的损失函数——掩膜随机差异损失，通过随机扩展和腐蚀掩膜边缘来增强生成效果在掩膜周围的一致性。最后，利用烟雾特征并使用多模态大语言模型作为过滤工具来选择多样化且合理的烟雾图像，以生成高质量的合成数据集用于后续检测任务。

**Result:** 实验表明，我们生成的烟雾图像逼真且多样，并有效增强了森林火灾烟雾检测模型的性能。

**Conclusion:** 本研究提出了MFGDiffusion框架，通过生成逼真且多样化的烟雾图像，有效解决了森林火灾烟雾数据稀缺的问题，并显著提升了森林火灾烟雾检测模型的性能。

> **ai_Abstract:** MFGDiffusion提出了一种新颖的框架，通过结合预训练分割模型、多模态模型、掩膜引导的网络架构和创新的掩膜随机差异损失，生成高质量、逼真的森林火灾烟雾图像。该方法旨在解决现有烟雾数据稀缺和生成图像与背景不一致的问题。通过利用多模态大语言模型进行数据筛选，该框架能够创建多样化且有效的合成烟雾数据集，实验证明能显著提升森林火灾烟雾检测模型的性能。

> **摘要翻译:** 烟雾是野火的第一个可见指标。随着深度学习的进步，基于图像的烟雾检测已成为检测和预防森林火灾的关键方法。然而，森林火灾烟雾图像数据的稀缺是阻碍森林火灾烟雾检测的重要因素之一。图像生成模型为合成逼真烟雾图像提供了一个有前景的解决方案。然而，当前的修复模型在生成高质量烟雾表示方面表现出局限性，特别是在合成烟雾与背景上下文之间存在不一致性。为了解决这些问题，我们提出了一个用于生成森林火灾烟雾图像的综合框架。首先，我们采用预训练的分割模型和多模态模型来获取烟雾掩膜和图像描述。然后，为了解决修复模型对掩膜和掩膜图像利用不足的问题，我们引入了一种由掩膜和掩膜图像特征引导的网络架构。我们还提出了一种新的损失函数——掩膜随机差异损失，通过随机扩展和腐蚀掩膜边缘来增强生成效果在掩膜周围的一致性。最后，为了使用随机掩膜生成烟雾图像数据集用于后续检测任务，我们结合了烟雾特征，并使用多模态大语言模型作为过滤工具来选择多样化且合理的烟雾图像，从而提高合成数据集的质量。实验表明，我们生成的烟雾图像逼真且多样，并有效增强了森林火灾烟雾检测模型的性能。代码可在https://github.com/wghr123/MFGDiffusion获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [191] [Archival Faces: Detection of Faces in Digitized Historical Documents](https://arxiv.org/abs/2504.00558)
> *档案人脸：数字化历史文献中的人脸检测*

*Marek Vaško, Adam Herout, Michal Hradiš* | **Category: cs.CV, 68T45 (Primary) 68T10, 68T07 (Secondary), I.4.8; I.5.1** | **Updated: 2025-07-15**

**Keywords:** 人脸检测, 历史文档, 数据集, 数字化档案, 边界框标注

**Comment:** Accepted to ICDAR 2025 Workshops, GREC2025

> **TL;DR:** 现有的人脸检测器在数字化历史文档中表现不佳。本文引入了一个新的、手动标注的、特定领域的数据集，以改进现有检测器的性能，并报告了详细的实验结果。

**AI_Comments:** 本文的创新点在于构建了一个专门针对数字化历史文档的人脸检测数据集，弥补了现有通用人脸检测器在该领域性能不足的空白。该数据集的创建对于推动历史文献的数字化和可搜索性具有重要意义。通过重新训练现有模型，证明了领域特定数据在提升模型性能方面的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 在数字化历史档案（尤其是报纸）中搜索名人或普通人的面孔，并将其与周围文本关联并使其可搜索是必要的。然而，现有的人脸检测器在扫描的历史文档数据集上表现极差，当前的检测工具在50:90% IoU下仅能达到约24%的mAP。

**Method:** 为了弥补现有检测器的不足，本文引入了一个新的、手动标注的、特定领域的数据集。该数据集仿照流行的Wider Face数据集风格，包含2.2k张来自19世纪至20世纪数字化历史报纸的新图像，以及11k个新的边界框标注和相关的面部地标。该数据集允许对现有检测器进行再训练，使其结果更接近野外人脸检测领域的标准。

**Result:** 本文报告了多项实验结果，比较了不同系列的微调检测器与公开可用的预训练人脸检测器，并进行了多个检测器尺寸的消融研究，提供了全面的检测和地标预测性能结果。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 该研究旨在解决现有面部检测器在数字化历史文档中表现不佳的问题。为此，作者创建了一个新的、手动标注的领域特定数据集，包含来自19-20世纪历史报纸的图像、边界框和面部地标。通过使用该数据集对现有检测器进行再训练，显著提高了其在历史文档中识别人脸的性能，并报告了详细的实验结果和比较。

> **摘要翻译:** 在数字化历史档案时，有必要搜索名人或普通人的面孔，尤其是在报纸中，将它们与周围的文本关联起来，并使其可搜索。现有的面部检测器在扫描的历史文档数据集上表现非常糟糕——当前的检测工具在50:90% IoU下仅能达到约24%的mAP。这项工作通过引入一个新的手动标注的领域特定数据集来弥补这一不足，该数据集采用流行的Wider Face数据集的风格，包含2.2k张来自19世纪至20世纪数字化历史报纸的新图像，以及11k个新的边界框标注和相关的面部地标。这个数据集允许对现有检测器进行再训练，使其结果更接近野外人脸检测领域的标准。我们报告了多项实验结果，比较了不同系列的微调检测器与公开可用的预训练人脸检测器，以及多个检测器尺寸的消融研究，提供了全面的检测和地标预测性能结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [200] [CATVis: Context-Aware Thought Visualization](https://arxiv.org/abs/2507.11522)
> *CATVis: 上下文感知思维可视化*

*Tariq Mehmood, Hamza Ahmad, Muhammad Haroon Shakeel, Murtaza Taj* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-15**

**Keywords:** EEG, 脑机接口, 视觉解码, 图像生成, 跨模态对齐

**Comment:** Accepted at MICCAI 2025. This is the submitted version prior to peer
  review. The final Version of Record will appear in the MICCAI 2025
  proceedings (Springer LNCS)

> **TL;DR:** 本文提出了一种新颖的五阶段框架CATVis，用于从脑电图（EEG）信号中解码视觉表征并生成高质量图像，其性能在多个指标上优于现有技术。

**AI_Comments:** 这项研究的创新之处在于提出了一个端到端的五阶段框架，将EEG信号转换为高质量的视觉图像，并引入了上下文感知机制。其重要性在于为EEG-based BCI在视觉解码方面提供了显著的性能提升，为未来的脑机接口应用，特别是视觉重建和交流，奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 从脑电图（EEG）信号中解码视觉表征仍然是一个重大挑战，因为EEG信号复杂且噪声大。

**Method:** 本文提出了一种新颖的五阶段框架：(1) 用于概念分类的EEG编码器；(2) 在CLIP特征空间中对EEG和文本嵌入进行跨模态对齐；(3) 通过重新排序进行标题细化；(4) 概念和标题嵌入的加权插值以获得更丰富的语义；(5) 使用预训练的Stable Diffusion模型生成图像。通过跨模态对齐和重新排序实现上下文感知的EEG到图像生成。

**Result:** 实验结果表明，该方法生成的图像质量高，与视觉刺激对齐，在分类准确率上优于SOTA方法13.43%，生成准确率上优于15.21%，并将Fréchet Inception Distance降低了36.61%，表明其语义对齐和图像质量更优越。

**Conclusion:** 该研究成功地提出了一种上下文感知的EEG到图像生成框架，显著提高了从EEG信号解码视觉表征的质量和准确性。

> **ai_Abstract:** 本文提出了CATVis，一个新颖的五阶段框架，旨在解决从复杂且嘈杂的EEG信号中解码视觉表征的挑战。该框架通过EEG编码器、跨模态对齐、标题细化、加权嵌入插值和Stable Diffusion模型，实现了上下文感知的EEG到图像生成。实验证明，CATVis能够生成高质量且与视觉刺激高度对齐的图像，在分类准确率、生成准确率和Fréchet Inception Distance等指标上显著优于现有技术。

> **摘要翻译:** 基于EEG的脑机接口（BCI）在运动想象和认知状态监测等各种应用中显示出前景。然而，由于EEG信号的复杂性和噪声特性，从EEG信号中解码视觉表征仍然是一个重大挑战。因此，我们提出了一种新颖的五阶段框架，用于从EEG信号中解码视觉表征：(1) 用于概念分类的EEG编码器，(2) 在CLIP特征空间中对EEG和文本嵌入进行跨模态对齐，(3) 通过重新排序进行标题细化，(4) 概念和标题嵌入的加权插值以获得更丰富的语义，以及(5) 使用预训练的Stable Diffusion模型生成图像。我们通过跨模态对齐和重新排序实现了上下文感知的EEG到图像生成。实验结果表明，我们的方法生成了与视觉刺激对齐的高质量图像，在分类准确率上优于SOTA方法13.43%，在生成准确率上优于15.21%，并将Fréchet Inception Distance降低了36.61%，表明其具有卓越的语义对齐和图像质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [214] [Clustering-Guided Multi-Layer Contrastive Representation Learning for Citrus Disease Classification](https://arxiv.org/abs/2507.11171)
> *聚类引导的多层对比表示学习用于柑橘病害分类*

*Jun Chen, Yonghua Yu, Weifu Li, Yaohui Chen, Hong Chen* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 柑橘病害分类, 对比学习, 自监督学习, 聚类, 深度学习

**Comment:** 11 pages, 5 figures

> **TL;DR:** 本文提出了一种名为CMCRL的新型自监督多层对比表示学习算法，用于柑橘病害分类，通过利用聚类中心和多层对比训练，显著提高了在未标注数据上的性能，并达到了最先进的水平。

**AI_Comments:** 本文的创新之处在于将聚类引导与多层对比学习相结合，提出了一种有效的自监督学习框架，显著减少了对标注数据的依赖，这对于实际应用中数据标注成本高昂的领域具有重要意义。该方法不仅在性能上超越了现有技术，还表现出对类别不平衡的鲁棒性，增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 柑橘病害严重影响产量，准确检测和分类至关重要。尽管深度学习在计算机视觉方面取得了进展，但其性能高度依赖于大量高质量的标注训练样本，这限制了其实际应用。因此，需要一种能够利用未标注数据的方法。

**Method:** 本文提出了一种新颖的聚类引导自监督多层对比表示学习（CMCRL）算法。该方法引入了两个关键设计：与聚类中心进行对比学习和多层对比训练（MCT）范式。CMCRL能够利用大量未标注样本进行优化，有效适应不同柑橘病害的症状相似性，并学习分层特征表示。

**Result:** 该方法在公共柑橘图像数据集CDD上实现了最先进的性能，准确率比现有方法高出4.5%至30.1%。它显著缩小了与全监督方法（所有样本均已标注）的性能差距。此外，该方法在F1分数、精确度、召回率等其他评估指标上也表现出色，突出了其对类别不平衡挑战的鲁棒性。

**Conclusion:** 本文提出的CMCRL算法通过结合聚类引导和多层对比学习，有效解决了深度学习在柑橘病害分类中对大量标注数据的依赖问题，并在未标注数据上取得了优异的分类性能和对类别不平衡的鲁棒性，达到了最先进的水平。

> **ai_Abstract:** 本文针对柑橘病害分类中深度学习模型对大量标注数据依赖的问题，提出了一种名为CMCRL的聚类引导自监督多层对比表示学习算法。该算法通过与聚类中心对比和多层对比训练，有效利用未标注数据，并能处理病害症状相似性和实现分层特征学习。实验结果表明，CMCRL在CDD数据集上取得了显著优于现有方法的性能，并缩小了与全监督模型的差距，同时对类别不平衡问题表现出良好的鲁棒性。

> **摘要翻译:** 柑橘作为全球最重要的经济水果作物之一，因各种病害导致产量严重下降。准确的病害检测和分类是实施有针对性控制措施的关键前提。人工智能，特别是基于深度学习的计算机视觉算法的最新进展，在保持检测和分类准确性的同时，大大减少了时间和劳动力需求。然而，这些方法主要依赖于大量高质量的标注训练样本才能获得有希望的性能。通过引入两个关键设计：与聚类中心进行对比以及多层对比训练（MCT）范式，本文提出了一种新颖的聚类引导自监督多层对比表示学习（CMCRL）算法。所提出的方法比现有方法具有多项优势：（1）利用大量未标注样本进行优化；（2）有效适应不同柑橘病害之间的症状相似性；（3）分层特征表示学习。所提出的方法在公共柑橘图像集CDD上取得了最先进的性能，准确率比现有方法高出4.5%-30.1%。值得注意的是，我们的方法缩小了与全监督方法（所有样本均已标注）的性能差距。除了分类准确性，我们的方法在其他评估指标（F1分数、精确度和召回率）上也表现出色，突出了其对类别不平衡挑战的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [217] [A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n](https://arxiv.org/abs/2507.10864)
> *一种基于LOF预处理和YOLO-v11n的轻量级鲁棒实时结直肠息肉检测框架*

*Saadat Behzadi, Danial Sharifrazi, Bita Mesbahzadeh, Javad Hassannataj Joloudarid, Roohallah Alizadehsani* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 结直肠息肉检测, LOF, YOLO-v11n, 实时检测, 深度学习

**Comment:** 

> **TL;DR:** 本研究提出了一种结合LOF预处理和YOLO-v11n的轻量级、高效的结直肠息肉实时检测框架，并在多个公开数据集上取得了优异的检测性能。

**AI_Comments:** 该研究的创新点在于将LOF异常值检测方法引入到深度学习模型的数据预处理阶段，有效提升了模型的鲁棒性。同时，采用轻量级的YOLO-v11n模型，使其适用于实时临床应用，具有重要的实践意义。在多个公开数据集上的验证增强了结果的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 及时准确地检测结直肠息肉对于诊断和预防结直肠癌至关重要，而结直肠癌是全球主要的死亡原因之一。本研究旨在开发一种新的、轻量级且高效的息肉检测框架。

**Method:** 该方法结合了局部异常因子（LOF）算法用于过滤噪声数据和YOLO-v11n深度学习模型。研究在CVC-ColonDB、CVC-ClinicDB、Kvasir-SEG、ETIS和EndoScene五个公开数据集上进行了测试。由于这些数据集缺乏边界框标注，研究将分割掩码转换为检测标签。为增强模型鲁棒性和泛化性，采用5折交叉验证，并使用LOF方法（30个邻居，5%污染率）移除异常样本。清洗后的数据输入YOLO-v11n模型进行训练，并结合现代数据增强策略。

**Result:** 该方法显著提高了息肉定位性能，达到了95.83%的精确率、91.85%的召回率、93.48%的F1分数、96.48%的mAP@0.5和77.75%的mAP@0.5:0.95。与之前的基于YOLO的方法相比，该模型在准确性和效率方面均有所提升。

**Conclusion:** 研究结果表明，所提出的方法非常适用于临床环境中实时结肠镜检查支持。该研究强调了在设计有效的医学图像AI系统时，数据预处理和模型效率的关键作用。

> **ai_Abstract:** 本研究提出了一种用于实时结直肠息肉检测的轻量级鲁棒框架，该框架结合了LOF算法进行数据预处理以过滤噪声，并利用YOLO-v11n深度学习模型进行高效检测。通过在五个公开数据集上进行5折交叉验证和数据增强，该方法在精确率、召回率、F1分数和mAP等指标上均取得了优异表现，证明了其在准确性和效率上优于现有YOLO-based方法，适用于临床实时结肠镜辅助诊断。

> **摘要翻译:** 目标：及时准确地检测结直肠息肉对于诊断和预防结直肠癌至关重要，结直肠癌是全球主要的死亡原因之一。本研究引入了一种新的、轻量级且高效的息肉检测框架，该框架结合了用于过滤噪声数据的局部异常因子（LOF）算法和YOLO-v11n深度学习模型。
研究设计：一项实验性研究，利用深度学习和异常值去除技术，跨越多个公开数据集。
方法：所提出的方法在五个多样化且公开可用的数据集上进行了测试：CVC-ColonDB、CVC-ClinicDB、Kvasir-SEG、ETIS和EndoScene。由于这些数据集最初缺乏边界框标注，我们将其分割掩码转换为合适的检测标签。为了增强模型的鲁棒性和泛化能力，我们应用了5折交叉验证，并使用LOF方法（配置为30个邻居和5%的污染率）移除异常样本。然后将清洗过的数据输入YOLO-v11n，这是一种针对实时应用优化的快速且资源高效的目标检测架构。我们结合现代增强策略训练模型，以提高在不同条件下的检测准确性。
结果：我们的方法显著提高了息肉定位性能，实现了95.83%的精确率、91.85%的召回率、93.48%的F1分数、96.48%的mAP@0.5和77.75%的mAP@0.5:0.95。与之前的基于YOLO的方法相比，我们的模型展示了更高的准确性和效率。
结论：这些结果表明，所提出的方法非常适用于临床环境中的实时结肠镜检查支持。总的来说，这项研究强调了在设计有效的医学影像AI系统时，数据预处理和模型效率的关键作用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [221] [Fully Unified Motion Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2504.12667)
> *全面统一的端到端自动驾驶运动规划*

*Lin Liu, Caiyan Jia, Ziying Song, Hongyu Pan, Bencheng Liao, Wenchao Sun, Yongchang Zhang, Lei Yang, Yandan Luo* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 运动规划, 端到端自动驾驶, 多车辆学习, 轨迹生成, FUMP

**Comment:** 

> **TL;DR:** 提出FUMP框架，通过利用自我车辆和其他车辆的专家数据进行统一运动规划，解决现有端到端自动驾驶方法数据多样性不足和跨车辆学习挑战。

**AI_Comments:** 这篇论文通过提出FUMP框架，有效解决了端到端自动驾驶中数据多样性不足和跨车辆学习的挑战。其创新点在于将运动规划任务分解为运动预测的子任务，并引入两阶段生成和ECSA来处理多源数据融合。这种方法有望显著提升模型在复杂和长尾场景下的规划能力，为未来的自动驾驶系统提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有端到端自动驾驶方法仅学习单一自我车辆的专家规划数据，限制了策略多样性；未能充分利用其他车辆的高质量轨迹数据；联合学习面临跨车辆观察视角差异和数据模态缺失的挑战。

**Method:** 提出FUMP（Fully Unified Motion Planning）两阶段轨迹生成框架。将规划任务建模为运动预测的子任务。第一阶段，共享解码器联合生成初始轨迹；第二阶段，模型根据自我车辆状态进行规划特异性细化。两阶段通过仅在自我车辆数据上训练的状态预测器连接。为解决跨车辆观察视角差异，在第一阶段前引入Equivariant Context-Sharing Adapter (ECSA)。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出FUMP（全面统一运动规划）框架，旨在解决现有端到端自动驾驶在学习多样化驾驶策略和利用多车辆专家数据方面的局限性。FUMP通过将规划任务解耦为两阶段轨迹生成：共享解码器生成初始轨迹，然后进行自我车辆状态条件下的细化。为克服跨车辆观察视角差异，引入了等变上下文共享适配器（ECSA）。该方法旨在通过联合利用自我车辆和其他车辆的专家数据来提升运动规划性能。

> **摘要翻译:** 当前端到端自动驾驶方法通常仅从单一自我车辆收集的专家规划数据中学习，这严重限制了可学习驾驶策略和场景的多样性。然而，一个关键但被忽视的事实是，在任何驾驶场景中，除了特定自我车辆的轨迹外，还存在来自其他车辆的多条高质量轨迹。现有方法未能充分利用这一宝贵资源，错失了通过向其他专家学习来提高模型性能（包括长尾场景）的重要机会。直观地，联合学习自我车辆和其他车辆的专家数据对规划任务有益。然而，这种联合学习面临两个关键挑战：（1）车辆间不同的场景观察视角阻碍了场景特征表示的车辆间对齐；（2）与其他车辆数据相比，自我车辆数据中部分模态的缺失（例如，车辆状态）引入了学习偏差。为了解决这些挑战，我们提出了FUMP（全面统一运动规划），一种新颖的两阶段轨迹生成框架。基于概率分解，我们将规划任务建模为运动预测的一个特殊子任务。具体来说，我们的方法将轨迹规划解耦为两个阶段。在第一阶段，一个共享解码器联合生成两个任务的初始轨迹。在第二阶段，模型根据自我车辆的状态执行规划特异性细化。两个阶段之间的过渡由一个专门在自我车辆数据上训练的状态预测器连接。为了解决观察视角上的跨车辆差异，我们在第一阶段之前提出了一个等变上下文共享适配器（ECSA），以改善场景表示的跨车辆泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [228] [Efficient Dual-domain Image Dehazing with Haze Prior Perception](https://arxiv.org/abs/2507.11035)
> *高效双域图像去雾与雾霾先验感知*

*Lirong Zheng, Yanshan Li, Rui Yu, Kaihao Zhang* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 图像去雾, 双域, 频率感知, 雾霾先验, 深度学习

**Comment:** 12 pages

> **TL;DR:** 本文提出了DGFDNet，一个新颖的双域框架，通过结合空间和频率域处理与雾霾先验感知，实现了高效且最先进的图像去雾性能。

**AI_Comments:** 创新点在于其独特的双域（空间-频率）处理框架，实现了空间与频率分支之间的强耦合，并引入了物理引导的降级对齐。此外，利用雾霾先验感知进行自适应频率增强以及迭代的先验校正机制也提升了性能。该研究解决了现有去雾方法计算成本高和在复杂雾霾条件下性能不足的问题，提升了实时应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 基于Transformer的模型计算成本高，限制了实时应用。现有方法主要依赖计算昂贵的空间域特征，在复杂雾霾条件下表现不足。引入频率域线索的方法因空间和频率分支耦合弱，整体性能受限。

**Method:** 提出暗通道引导的频率感知去雾网络（DGFDNet），一个新颖的双域框架，在空间和频率域之间执行物理引导的降级对齐。核心DGFDBlock包含：1) 雾霾感知频率调制器（HAFM），利用暗通道先验生成像素级雾霾置信图，自适应增强雾霾相关频率分量；2) 多级门控聚合模块（MGAM），通过卷积核和门控机制融合多尺度特征。此外，先验校正引导分支（PCGB）引入闭环反馈机制，迭代细化先验。

**Result:** DGFDNet在四个基准雾霾数据集上实现了最先进的性能，并展现出卓越的鲁棒性和实时效率。

**Conclusion:** DGFDNet通过结合双域处理与雾霾先验感知，有效克服了现有去雾方法的局限性，显著提高了性能和效率。

> **ai_Abstract:** 本文介绍了DGFDNet，一个高效的双域图像去雾网络，它结合了空间和频率域处理以及雾霾先验感知。该网络通过提出一个新颖的DGFDBlock来解决Transformer模型计算成本高和现有方法性能不足的局限性。DGFDBlock包含基于暗通道先验进行频率调制的HAFM和用于多尺度特征融合的MGAM。此外，PCGB模块迭代优化雾霾先验。实验表明DGFDNet在性能、鲁棒性和实时效率方面均达到最先进水平。

> **摘要翻译:** 基于Transformer的模型在单图像去雾方面表现出强大的全局建模能力，但其高计算成本限制了实时应用。现有方法主要依赖空间域特征来捕获长距离依赖关系，这计算成本高昂，并且在复杂雾霾条件下往往不足。尽管一些方法引入了频率域线索，但空间和频率分支之间的弱耦合限制了整体性能。为了克服这些局限性，我们提出了暗通道引导的频率感知去雾网络（DGFDNet），这是一种新颖的双域框架，可在空间和频率域之间执行物理引导的降级对齐。其核心是DGFDBlock，它包含两个关键模块：1）雾霾感知频率调制器（HAFM），它从暗通道先验生成像素级雾霾置信图，以自适应地增强与雾霾相关的频率分量，从而实现全局降级感知的频谱调制；2）多级门控聚合模块（MGAM），它通过不同的卷积核和混合门控机制融合多尺度特征，以恢复精细的结构细节。此外，先验校正引导分支（PCGB）引入了闭环反馈机制，通过中间去雾特征实现先验的迭代细化，并显著提高了雾霾定位精度，尤其是在具有挑战性的户外场景中。在四个基准雾霾数据集上进行的广泛实验表明，DGFDNet实现了最先进的性能，具有卓越的鲁棒性和实时效率。代码可在以下网址获取：https://github.com/Dilizlr/DGFDNet。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [240] [CharaConsist: Fine-Grained Consistent Character Generation](https://arxiv.org/abs/2507.11533)
> *CharaConsist：细粒度一致性角色生成*

*Mengyu Wang, Henghui Ding, Jianing Peng, Yao Zhao, Yunpeng Chen, Yunchao Wei* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 文本到图像生成, 角色一致性, 细粒度一致性, DiT模型, 点跟踪注意力

**Comment:** ICCV 2025 accepted paper, project page:
  https://murray-wang.github.io/CharaConsist/

> **TL;DR:** 针对文本到图像生成中角色和背景一致性问题，CharaConsist提出点跟踪注意力、自适应令牌合并和前景背景解耦控制，实现了细粒度一致性生成，并支持DiT模型。

**AI_Comments:** CharaConsist的创新之处在于其结合了点跟踪注意力、自适应令牌合并以及前景背景解耦控制，解决了现有训练无关方法在保持背景和前景（特别是大运动量时）一致性方面的不足。其作为首个为DiT模型定制的一致性生成方法，具有重要意义，能够利用DiT模型的强大容量生成高质量的视觉内容，极大地扩展了文本到图像生成在复杂真实场景中的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有训练无关方法在文本到图像生成中，无法保持背景细节一致性，且前景角色大幅运动时，身份和服装细节会出现不一致，限制了其应用。

**Method:** 提出CharaConsist，采用点跟踪注意力（point-tracking attention）、自适应令牌合并（adaptive token merge）以及前景和背景的解耦控制（decoupled control of the foreground and background）。

**Result:** CharaConsist实现了前景和背景的细粒度一致性，支持在固定场景连续镜头或不同场景离散镜头中生成一致性角色。它是首个为文本到图像DiT模型量身定制的一致性生成方法，结合最新基础模型的大容量，能产生高质量视觉输出。

**Conclusion:** CharaConsist通过其创新方法解决了现有文本到图像生成中一致性问题，特别是对DiT模型的支持，显著提升了生成内容的质量和适用范围。

> **ai_Abstract:** CharaConsist是一种新的文本到图像生成方法，旨在解决现有方法在角色和背景一致性方面存在的问题。通过引入点跟踪注意力、自适应令牌合并以及前景背景解耦控制，CharaConsist实现了对前景角色和背景细节的细粒度一致性生成，即使在角色大幅运动或场景变化的情况下也能保持高品质。它是首个为DiT模型设计的一致性生成方案，显著提升了文本到图像生成在实际应用中的效果和范围。

> **摘要翻译:** 在文本到图像生成中，生成一系列保持相同身份的一致性内容对于实际应用具有重要价值。尽管一些工作探索了无需训练的方法来增强生成主体的一致性，但我们观察到它们存在以下问题。首先，它们未能保持背景细节的一致性，这限制了其适用性。此外，当前景角色发生大幅运动变化时，身份和服装细节的不一致性变得明显。为了解决这些问题，我们提出了CharaConsist，它采用点跟踪注意力（point-tracking attention）和自适应令牌合并（adaptive token merge），并结合前景和背景的解耦控制。CharaConsist能够实现前景和背景的细粒度一致性，支持在固定场景的连续镜头或不同场景的离散镜头中生成一个角色。此外，CharaConsist是第一个为文本到图像DiT模型量身定制的一致性生成方法。它保持细粒度一致性的能力，结合最新基础模型更大的容量，使其能够产生高质量的视觉输出，拓宽了其在更广泛实际场景中的适用性。源代码已在https://github.com/Murray-Wang/CharaConsist发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [252] [Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation](https://arxiv.org/abs/2504.12753)
> *更强、更稳、更优：深度VFM中的几何一致性锻造领域泛化语义分割*

*Siyu Chen, Ting Han, Changshe Zhang, Xin Luo, Meiliu Wu, Guorong Cai, Jinhe Su* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 深度, 视觉基础模型, 语义分割, 领域泛化, 几何一致性

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 该论文提出DepthForge框架，将深度信息与视觉基础模型（VFM）相结合，以提高领域泛化语义分割（DGSS）中的几何一致性和泛化能力，在各种极端条件下表现出色，显著优于现有方法。

**AI_Comments:** 该论文的创新点在于认识到深度信息在领域泛化语义分割中的鲁棒性，并巧妙地将其与视觉基础模型相结合。通过引入深度感知可学习令牌和深度细化解码器，有效地增强了模型的几何一致性和跨域泛化能力。尤其是在极端条件下的出色表现，验证了其方法的有效性和实用性，为DGSS领域提供了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 视觉基础模型（VFMs）在领域泛化语义分割（DGSS）中表现卓越，但现有方法常忽略视觉线索易受影响而底层几何信息稳定的事实，使得深度信息更为鲁棒。本文旨在整合深度信息与VFM特征，以增强图像内部的几何一致性并提升VFM的泛化性能。

**Method:** 本文提出了一种名为DepthForge的新型微调DGSS框架。该框架整合了来自冻结的DINOv2或EVA02的视觉线索和来自冻结的Depth Anything V2的深度线索。在VFM的每一层中，引入了深度感知可学习令牌，以持续解耦领域不变的视觉和空间信息，从而增强VFM的深度感知和注意力。最后，开发了一个深度细化解码器并将其集成到模型架构中，以自适应地细化多层VFM特征和深度感知可学习令牌。

**Result:** 在各种DGSS设置和五个不同的未见目标域数据集上进行了广泛实验。定性和定量结果表明，该方法在性能、视觉空间注意力的稳定性以及泛化能力方面显著优于其他替代方法。特别是在极端条件（例如，夜晚和雪地）下，DepthForge展现出卓越的性能。

**Conclusion:** 该研究提出的方法通过将深度信息与VFM结合，显著增强了几何一致性，并在领域泛化语义分割任务中取得了更强、更稳定的性能和卓越的泛化能力，尤其在极端条件下表现突出。

> **ai_Abstract:** 本文提出DepthForge框架，旨在通过整合深度信息与视觉基础模型（VFM）的特征，解决领域泛化语义分割（DGSS）中视觉线索易受影响的问题，从而提升几何一致性和泛化能力。DepthForge结合了冻结的DINOv2/EVA02视觉线索和Depth Anything V2深度线索，并在VFM层中引入深度感知可学习令牌以解耦领域不变信息，同时设计了深度细化解码器。实验结果表明，该方法在性能、注意力稳定性和泛化能力上均显著优于现有方法，尤其在夜间和雪地等极端条件下表现突出。

> **摘要翻译:** 视觉基础模型（VFMs）在领域泛化语义分割（DGSS）中表现出卓越的性能。然而，最近的方法经常忽视视觉线索易受影响而底层几何信息保持稳定的事实，这使得深度信息更加鲁棒。在本文中，我们研究了将深度信息与VFM特征相结合的潜力，以改善图像内的几何一致性并提升VFM的泛化性能。我们提出了一种新颖的微调DGSS框架，名为DepthForge，它整合了来自冻结的DINOv2或EVA02的视觉线索和来自冻结的Depth Anything V2的深度线索。在VFM的每一层中，我们引入了深度感知可学习令牌，以持续解耦领域不变的视觉和空间信息，从而增强VFM的深度感知和注意力。最后，我们开发了一个深度细化解码器并将其集成到模型架构中，以自适应地细化多层VFM特征和深度感知可学习令牌。基于各种DGSS设置和五个不同的未见目标域数据集进行了广泛的实验。定性和定量结果表明，我们的方法在性能更强、视觉空间注意力更稳定、泛化能力更优方面显著优于替代方法。特别是，DepthForge在极端条件（例如，夜晚和雪地）下表现出出色的性能。代码可在https://github.com/anonymouse-xzrptkvyqc/DepthForge获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [255] [Trexplorer Super: Topologically Correct Centerline Tree Tracking of Tubular Objects in CT Volumes](https://arxiv.org/abs/2507.10881)
> *Trexplorer Super：CT体中管状物体拓扑正确中心线树形跟踪*

*Roman Naeem, David Hagerman, Jennifer Alvén, Lennart Svensson, Fredrik Kahl* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 中心线跟踪, 管状结构, 拓扑正确性, CT体积, Trexplorer Super

**Comment:** Submitted Version. Accepted at MICCAI 2025

> **TL;DR:** Trexplorer Super是一个改进的模型，用于在CT图像中对血管和气道等管状树状结构进行拓扑正确的中心线跟踪。它通过解决现有Trexplorer模型的局限性并超越了最先进的模型。研究还引入了新的数据集，并指出合成数据的性能不一定能反映真实数据。

**AI_Comments:** 本论文的创新之处在于提出了Trexplorer Super，一个显著改进的中心线跟踪模型，解决了现有模型在拓扑正确性方面的缺陷。更重要的是，它通过创建并公开新的、难度递增的中心线数据集，为该领域的研究提供了宝贵的资源，解决了公共数据集缺乏的痛点。研究结果不仅展示了模型的优越性，还揭示了合成数据和真实数据之间性能转化的问题，为未来的模型开发和评估提供了重要启示。

<details>
  <summary>Details</summary>

**Motivation:** 管状树状结构（如血管和气道）在人体解剖学中至关重要，准确跟踪它们并保持其拓扑结构对于各种下游任务至关重要。现有的Trexplorer模型在预测重复分支和过早终止跟踪方面存在问题。

**Method:** 本研究提出了Trexplorer Super，一个增强版的Trexplorer模型，通过新颖的改进显著提高了性能。此外，为了实现彻底的评估，研究开发了三个中心线数据集（一个合成，两个真实，难度递增），并使用这些数据集对现有最先进的模型进行了全面评估，并与Trexplorer Super进行了比较。

**Result:** Trexplorer Super在每个数据集上都优于以前的最先进模型。研究结果还强调，在合成数据上的强大性能不一定能转化为真实数据集的性能。

**Conclusion:** Trexplorer Super成功解决了现有中心线跟踪模型的局限性，并在新的、更具挑战性的数据集上取得了卓越的性能，证明了其在医学图像分析中的潜力。同时，研究强调了在真实世界数据上进行评估的重要性。

> **ai_Abstract:** 本研究提出了Trexplorer Super，一个改进的深度学习模型，用于在CT体中对血管和气道等管状结构进行拓扑正确的中心线跟踪。该模型旨在解决现有Trexplorer在预测重复分支和过早终止跟踪方面的局限性。为了进行严格评估，研究构建了三个新的中心线数据集（一个合成，两个真实），并在此基础上，Trexplorer Super在所有数据集上均超越了现有最先进的模型。研究还发现，合成数据上的优异表现不一定能推广到真实世界数据。

> **摘要翻译:** 管状树状结构，例如血管和气道，在人体解剖学中至关重要，准确跟踪它们并同时保持其拓扑结构对于各种下游任务至关重要。Trexplorer是一个用于3D医学图像中中心线跟踪的循环模型，但它在预测重复分支和过早终止跟踪方面存在问题。为了解决这些问题，我们提出了Trexplorer Super，一个通过新颖的改进显著提高性能的增强版本。然而，由于缺乏公共数据集，评估中心线跟踪模型具有挑战性。为了实现彻底的评估，我们开发了三个中心线数据集，一个合成数据集和两个真实数据集，每个数据集的难度都在增加。使用这些数据集，我们对现有的最先进（SOTA）模型进行了全面评估，并将其与我们的方法进行了比较。Trexplorer Super在每个数据集上都优于以前的SOTA模型。我们的结果还强调，在合成数据上的强大性能不一定能转化为真实数据集的性能。代码和数据集可在https://github.com/RomStriker/Trexplorer-Super获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [256] [How Far Have Medical Vision-Language Models Come? A Comprehensive Benchmarking Study](https://arxiv.org/abs/2507.11200)
> *医学视觉-语言模型发展到何种程度？一项全面的基准研究*

*Che Liu, Jiazhen Pan, Weixiang Shen, Wenjia Bai, Daniel Rueckert, Rossella Arcucci* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 视觉-语言模型, 医学图像, 基准测试, 性能评估, 医疗AI

**Comment:** Accepted by the International Conference on AI in Healthcare 2025

> **TL;DR:** 对通用和医学专用视觉-语言模型在医疗任务上的表现进行了全面评估，发现通用模型已能匹敌或超越部分医学专用模型，但推理能力仍是瓶颈，且所有模型均未达到临床部署标准。

**AI_Comments:** 这项研究通过全面的基准测试，揭示了当前视觉-语言模型在医疗领域应用的现状和局限性。其创新之处在于首次系统性地对比了通用和医学专用VLMs在多个医疗基准上的表现，并细致区分了理解与推理能力。研究结果对于指导未来医学VLMs的研发具有重要意义，特别是其强调了推理能力不足和模型尚未达到临床可靠性阈值的局限性，为后续研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言模型（VLMs）在自然图像任务上表现出色并日益被应用于医疗健康领域，但它们在医疗任务中的能力尚未得到充分探索，因此需要对其进行全面评估。

**Method:** 本研究对参数范围从3B到72B的开源通用型和医学专用型视觉-语言模型进行了全面评估，使用了MedXpert、OmniMedVQA、PMC-VQA、PathVQA、MMMU、SLAKE和VQA-RAD等八个基准测试。为了观察模型在不同方面的表现，研究首先将其分为理解和推理两部分进行评估。

**Result:** 主要有三个发现：1. 大型通用模型在多个基准测试上已能匹敌甚至超越医学专用模型，显示出从自然图像到医学图像的强大零样本迁移能力。2. 推理性能始终低于理解性能，这突显了安全决策支持的关键障碍。3. 性能在不同基准测试之间差异很大，这反映了任务设计、标注质量和知识需求的不同。

**Conclusion:** 目前没有模型达到临床部署的可靠性阈值，这强调了需要更强的多模态对齐和更严格、细致的评估协议。

> **ai_Abstract:** 本研究对现有开源通用型和医学专用视觉-语言模型在八个医学图像基准测试上进行了全面评估，旨在探究其在医疗任务中的实际能力。研究发现，大型通用模型在某些任务上已能媲美甚至超越医学专用模型，展现了良好的零样本迁移能力。然而，模型的推理能力普遍弱于理解能力，且不同基准测试间的性能差异显著。目前，所有受评估模型均未能达到临床部署所需的可靠性标准，因此，论文强调了未来研究应侧重于加强多模态对齐和制定更严谨的评估协议。

> **摘要翻译:** 视觉-语言模型（VLMs）在网络规模语料库上进行训练，在自然图像任务中表现出色，并日益被重新用于医疗保健领域；然而，它们在医疗任务中的能力仍未得到充分探索。我们对开源通用型和医学专用型VLMs（参数范围从3B到72B）在八个基准测试上进行了全面评估：MedXpert、OmniMedVQA、PMC-VQA、PathVQA、MMMU、SLAKE和VQA-RAD。为了观察模型在不同方面的表现，我们首先将其分为理解和推理两部分。出现了三个显著发现。首先，大型通用模型在多个基准测试上已经匹配或超越了医学专用模型，这表明从自然图像到医学图像具有强大的零样本迁移能力。其次，推理性能始终低于理解性能，这突出表明了安全决策支持的关键障碍。第三，性能在不同基准测试之间差异很大，反映了任务设计、标注质量和知识需求的不同。目前没有模型达到临床部署的可靠性阈值，这强调了需要更强的多模态对齐和更严格、细致的评估协议。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [271] [Streaming 4D Visual Geometry Transformer](https://arxiv.org/abs/2507.11539)
> *流式4D视觉几何Transformer*

*Dong Zhuo, Wenzhao Zheng, Jiahe Guo, Yuqi Wu, Jie Zhou, Jiwen Lu* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 4D几何重建, 流式处理, Transformer, 因果注意力, 实时视觉

**Comment:** Code is available at: https://github.com/wzzheng/StreamVGGT

> **TL;DR:** 本文提出了一种流式4D视觉几何Transformer，采用因果Transformer架构和时间因果注意力，通过缓存历史信息实现高效的实时4D几何重建，并在在线场景下显著提高了推理速度，同时保持了竞争性能。

**AI_Comments:** 该论文提出了一种创新的流式4D几何重建方法，其主要创新点在于将自回归大型语言模型的因果Transformer架构引入4D视觉领域，实现了高效的在线实时处理。通过时间因果注意力及历史信息缓存，解决了长期4D重建的效率问题。此外，知识蒸馏和借鉴LLM优化注意力算子的策略也增强了模型的实用性。这对于需要实时交互的4D应用具有重要意义，是4D视觉系统向实际部署迈进的关键一步。

<details>
  <summary>Details</summary>

**Motivation:** 从视频中感知和重建4D时空几何是一个基础但具有挑战性的计算机视觉任务。为了促进交互式和实时应用，需要一种能够高效处理4D几何重建的方法。

**Method:** 本文提出了一种流式4D视觉几何Transformer，其设计理念与自回归大型语言模型相似。它采用简单高效的因果Transformer架构在线处理输入序列，并使用时间因果注意力，通过缓存历史键和值作为隐式记忆，实现高效的流式长期4D重建。该设计通过增量集成历史信息来处理实时4D重建，同时保持高质量的空间一致性。为了高效训练，该方法提出从密集双向视觉几何基础Transformer（VGGT）中蒸馏知识到其因果模型。在推理时，模型支持从大型语言模型领域迁移优化的效率注意力操作（如FlashAttention）。

**Result:** 在各种4D几何感知基准上的大量实验表明，该模型在在线场景下显著提高了推理速度，同时保持了竞争性能。

**Conclusion:** 本文提出的模型为可扩展和交互式4D视觉系统铺平了道路，实现了在线场景下的快速推理和高质量的4D几何重建。

> **ai_Abstract:** 本文提出了一种名为流式4D视觉几何Transformer的新模型，旨在解决从视频中实时高效地感知和重建4D时空几何的挑战。该模型借鉴自回归大型语言模型的设计理念，采用因果Transformer架构，并通过时间因果注意力及历史键值缓存实现流式长期4D重建。它支持实时处理，通过增量整合历史信息保持空间一致性。为提高训练效率，模型从VGGT中蒸馏知识；推理时可利用大型语言模型领域的优化注意力算子。实验证明，该模型在在线场景下显著提升了推理速度，同时保持了竞争力，为可扩展和交互式4D视觉系统奠定了基础。

> **摘要翻译:** 从视频中感知和重建4D时空几何是一个基础但具有挑战性的计算机视觉任务。为了促进交互式和实时应用，我们提出了一种流式4D视觉几何Transformer，它与自回归大型语言模型具有相似的设计理念。我们探索了一种简单高效的设计，并采用因果Transformer架构以在线方式处理输入序列。我们使用时间因果注意力，并缓存历史键和值作为隐式记忆，以实现高效的流式长期4D重建。这种设计可以通过增量集成历史信息来处理实时4D重建，同时保持高质量的空间一致性。为了高效训练，我们提出将知识从密集双向视觉几何基础Transformer（VGGT）蒸馏到我们的因果模型。在推理方面，我们的模型支持从大型语言模型领域迁移优化的效率注意力操作（例如FlashAttention）。在各种4D几何感知基准上的大量实验表明，我们的模型在在线场景下提高了推理速度，同时保持了竞争性能，为可扩展和交互式4D视觉系统铺平了道路。代码可在：https://github.com/wzzheng/StreamVGGT 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [273] [A Multi-View High-Resolution Foot-Ankle Complex Point Cloud Dataset During Gait for Occlusion-Robust 3D Completion](https://arxiv.org/abs/2507.11037)
> *步态中多视角高分辨率足踝复合体点云数据集，用于抗遮挡3D补全*

*Jie-Wen Li, Zi-Han Ye, Qingyuan Zhou, Jiayi Song, Ying He, Ben Fei, Wen-Ming Chen* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 足踝复合体, 点云数据集, 步态分析, 3D补全, 遮挡鲁棒性

**Comment:** 15 pages, 10 figures, 2 tables

> **TL;DR:** 本文介绍了FootGait3D，一个多视角高分辨率足踝点云数据集，旨在解决步态过程中足踝区域的遮挡问题，并促进3D点云补全研究。

**AI_Comments:** 该论文的创新之处在于创建了一个专门针对步态中足踝复合体的高分辨率多视角数据集，直接解决了动态数据采集中的关键遮挡问题。其独特的多视角结构和包含不同程度遮挡的局部点云，为3D点云补全算法提供了一个鲁棒的测试平台，这对于推进生物力学分析以及相关的临床和工程应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 步态过程中足踝复合体的运动学分析对于生物力学研究和临床评估至关重要。然而，在动态步态条件下，由于摆动脚的遮挡和视角限制，收集准确的足踝表面几何数据极具挑战性。

**Method:** 本文介绍了FootGait3D，这是一个新颖的多视角、高分辨率足踝表面点云数据集，在自然步态下采集。该数据集包含从46名受试者收集的8,403帧点云数据，使用定制的五相机深度传感系统。每帧包括完整的5视角足踝重建（作为真值）以及仅从两、三或四视角获得的局部点云。这种结构化的变体使得能够严格评估不同遮挡级别和视角下的3D点云补全方法，并专注于足踝区域的详细建模。

**Result:** 本文创建并发布了FootGait3D数据集，这是一个独特的高分辨率多视角足踝点云数据集，专门用于步态过程中足踝复合体的抗遮挡3D补全任务。

**Conclusion:** FootGait3D数据集在推进生物力学和多节段足部建模研究方面具有巨大潜力，为临床步态分析、假肢设计和需要运动中详细足部3D模型的机器人应用提供了宝贵的测试平台。

> **ai_Abstract:** 本文推出了FootGait3D，一个专门针对步态过程中足踝复合体的新型多视角高分辨率点云数据集。为解决动态步态下数据采集中的遮挡挑战，FootGait3D包含了从46名受试者通过五相机系统采集的8,403帧数据。数据集提供完整的5视角重建作为真值，同时包含2、3或4视角的局部点云，旨在严格评估和基准测试3D点云补全方法，以从遮挡输入中恢复完整的足部几何形状。该数据集有望推动生物力学研究、临床步态分析、假肢设计和机器人技术的发展。

> **摘要翻译:** 步态过程中足踝复合体的运动学分析对于推进生物力学研究和临床评估至关重要。在动态步态条件下，由于摆动脚的遮挡和视角限制，收集足踝的精确表面几何数据本身就具有挑战性。因此，本文介绍了FootGait3D，这是一个在自然步态下采集的新颖的多视角高分辨率足踝表面点云数据集。与通常针对全身或下肢运动的现有步态数据集不同，FootGait3D专门关注足踝区域的详细建模，提供更精细粒度的运动数据。为了解决这一问题，FootGait3D包含从46名受试者使用定制的五相机深度传感系统收集的8,403帧点云数据。每帧包括足踝的完整5视角重建（作为真值）以及仅从四、三或两视角获得的局部点云。这种结构化的变体使得能够严格评估不同遮挡级别和视角下的3D点云补全方法。我们的数据集专为形状补全任务设计，便于基准测试最先进的单模态（例如PointTr、SnowflakeNet、Anchorformer）和多模态（例如SVDFormer、PointSea、CSDN）补全网络，以解决从被遮挡输入中恢复完整足部几何形状的挑战。FootGait3D在推进生物力学和多节段足部建模研究方面具有巨大潜力，为临床步态分析、假肢设计和需要运动中详细足部3D模型的机器人应用提供了宝贵的测试平台。该数据集现已在https://huggingface.co/datasets/ljw285/FootGait3D可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [277] [Unsupervised Visual Chain-of-Thought Reasoning via Preference Optimization](https://arxiv.org/abs/2504.18397)
> *无监督视觉思维链推理通过偏好优化*

*Kesen Zhao, Beier Zhu, Qianru Sun, Hanwang Zhang* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 视觉思维链, 无监督学习, 偏好优化, 多模态大语言模型, 空间推理

**Comment:** 

> **TL;DR:** UV-CoT是一种无监督的视觉思维链推理框架，通过偏好优化克服了对边界框标注的依赖，并在视觉理解和空间推理任务中表现出优越的性能和泛化能力。

**AI_Comments:** 这篇论文的创新点在于提出了一个无监督的视觉思维链推理框架，通过偏好优化避免了对昂贵的边界框标注数据的依赖，这对于视觉CoT领域是一个重要的突破。其自动数据生成和使用评估器MLLM进行监督的方式非常巧妙，有效解决了数据瓶颈问题，并显著提升了MLLM在视觉理解，特别是空间推理任务中的性能和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的思维链（CoT）推理主要集中在文本CoT，限制了其利用视觉线索的能力。视觉CoT未被充分探索，且现有方法依赖于大量的有标注边界框数据，难以泛化到未见情况。

**Method:** 本文提出无监督视觉思维链（UV-CoT）框架，通过偏好优化实现图像级CoT推理。UV-CoT对模型生成的边界框进行偏好比较，无需边界框标注。通过自动化数据生成流程获取偏好数据：目标MLLM生成种子边界框并基于每个区域回答问题，评估器MLLM对响应进行排序，这些排序作为监督信号，通过最小化负对数似然损失来训练目标MLLM。

**Result:** 在六个数据集上的实验表明，UV-CoT优于现有最先进的文本和视觉CoT方法。在四个未见数据集上的零样本测试显示了UV-CoT强大的泛化能力。

**Conclusion:** UV-CoT通过模拟人类感知（识别关键区域并基于其推理）来提高视觉理解能力，特别是在仅靠文本描述不足的空间推理任务中。

> **ai_Abstract:** 本文提出了一种名为无监督视觉思维链（UV-CoT）的新型框架，旨在通过偏好优化实现图像级思维链推理。针对现有视觉CoT方法依赖大量标注数据且泛化性差的问题，UV-CoT通过对模型生成的边界框进行偏好比较来消除对边界框标注的需求。它采用一个自动化数据生成流程，由目标MLLM生成区域并回答问题，再由评估器MLLM进行排序，利用这些排序作为监督信号训练目标MLLM。实验证明，UV-CoT在多个数据集上优于现有文本和视觉CoT方法，并在未见数据集上展现出强大的泛化能力，尤其提升了视觉理解和空间推理能力。

> **摘要翻译:** 思维链（CoT）推理极大地提高了多模态大型语言模型（MLLM）的可解释性和解决问题的能力。然而，现有方法主要集中于文本CoT，限制了它们利用视觉线索的能力。视觉CoT仍未被充分探索，唯一的工作基于监督微调（SFT），该方法依赖于大量的有标注边界框数据，并且难以泛化到未见情况。在本文中，我们引入了无监督视觉CoT（UV-CoT），一个通过偏好优化进行图像级CoT推理的新颖框架。UV-CoT在模型生成的边界框之间进行偏好比较（一个被偏好，另一个不被偏好），从而消除了对边界框标注的需求。我们通过引入一个自动化数据生成流水线来获取此类偏好数据。给定一张图像，我们的目标MLLM（例如，LLaVA-1.5-7B）使用模板提示生成种子边界框，然后使用每个边界区域作为输入回答问题。一个评估器MLLM（例如，OmniLLM-12B）对响应进行排序，这些排序作为监督信号，通过最小化负对数似然损失来训练目标MLLM。通过模拟人类感知——识别关键区域并基于它们进行推理——UV-CoT可以提高视觉理解能力，特别是在文本描述 alone 无法胜任的空间推理任务中。我们在六个数据集上的实验证明了UV-CoT的优越性，优于最先进的文本和视觉CoT方法。我们在四个未见数据集上的零样本测试显示了UV-CoT强大的泛化能力。代码可在 https://github.com/kesenzhao/UV-CoT 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [279] [View Invariant Learning for Vision-Language Navigation in Continuous Environments](https://arxiv.org/abs/2507.08831)
> *连续环境中视觉-语言导航的视图不变学习*

*Josh Qixuan Sun, Xiaoying Xing, Huaiyuan Weng, Chul Min Yeum, Mark Crowley* | **Category: cs.CV, cs.LG, cs.RO** | **Updated: 2025-07-15**

**Keywords:** 视觉-语言导航, 视图不变学习, 对比学习, 教师-学生框架, 具身AI

**Comment:** Under review

> **TL;DR:** 本文提出了VIL（视图不变学习），一种视图不变的后训练策略，通过对比学习和教师-学生框架，增强了视觉-语言导航策略对视角变化的鲁棒性，并在多项基准测试中取得了SOTA性能。

**AI_Comments:** 本文通过引入V2-VLNCE新场景和提出VIL方法，有效解决了视觉-语言导航中视角变化鲁棒性不足的关键问题。其创新点在于结合对比学习和教师-学生蒸馏框架来学习视图不变特征，并采用端到端训练，简化了流程。VIL作为一种“即插即用”的后训练方法，具有很高的实用价值和普适性，能够显著提升现有导航策略的鲁棒性和性能，对具身AI领域的研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大多数导航策略对视点变化（即相机高度和视角变化）敏感，这会改变智能体的观测结果，从而影响其在连续环境中的视觉-语言导航（VLNCE）性能。

**Method:** 本文引入了V2-VLNCE（具有不同视点的VLNCE）场景，并提出了VIL（视图不变学习）方法。VIL是一种视图不变的后训练策略，采用对比学习框架来学习稀疏且视图不变的特征。此外，针对大多数VLNCE基线的核心组件——航路点预测模块，引入了教师-学生框架，其中视图依赖的教师模型将知识蒸馏到视图不变的学生模型中。采用端到端训练范式来联合优化这些组件。

**Result:** 经验结果表明，在V2-VLNCE上，本文方法在两个标准基准数据集R2R-CE和RxR-CE上的成功率比最先进的方法提高了8-15%。此外，在标准VLNCE设置下，尽管为不同视点训练，VIL通常仍能改善性能。在更具挑战性的RxR-CE数据集上，本文方法在与其他无地图方法比较时，在所有指标上均达到了最先进的性能。

**Conclusion:** VIL作为一种可插拔的后训练方法，不仅不会降低标准视点下的性能，反而能提升性能，并增强了现有导航策略对相机视点变化的鲁棒性。

> **ai_Abstract:** 本文针对连续环境中视觉-语言导航（VLNCE）中导航策略对视点敏感的问题，提出了V2-VLNCE新场景和VIL（视图不变学习）方法。VIL是一种视图不变的后训练策略，通过对比学习获取视图不变特征，并结合教师-学生框架对航路点预测模块进行知识蒸馏，采用端到端训练。实验证明，VIL在V2-VLNCE任务上显著优于SOTA方法，并在标准VLNCE设置下仍能提升性能，尤其在RxR-CE数据集上达到SOTA，表明其作为即插即用方法的有效性和普适性。

> **摘要翻译:** 连续环境中的视觉-语言导航（VLNCE），即智能体遵循指令并自由移动以到达目的地，是具身AI中的一个关键研究问题。然而，大多数导航策略对视点变化敏感，即相机高度和视角的变化会改变智能体的观测。在本文中，我们引入了一种广义场景V2-VLNCE（具有不同视点的VLNCE），并提出了VIL（视图不变学习），这是一种视图不变的后训练策略，可增强现有导航策略对相机视点变化的鲁棒性。VIL采用对比学习框架来学习稀疏且视图不变的特征。此外，我们为航路点预测模块（大多数VLNCE基线的核心组件）引入了教师-学生框架，其中视图依赖的教师模型将知识蒸馏到视图不变的学生模型中。我们采用端到端训练范式来联合优化这些组件，从而消除了单个模块训练的成本。经验结果表明，我们的方法在V2-VLNCE上，在两个标准基准数据集R2R-CE和RxR-CE上的成功率比最先进的方法提高了8-15%。此外，我们在标准VLNCE设置下评估了VIL，发现尽管为不同视点训练，它通常仍能改善性能。在更具挑战性的RxR-CE数据集上，我们的方法在与其它无地图方法比较时，在所有指标上也达到了最先进的性能。这表明添加VIL不会降低标准视点性能，并且可以作为一种即插即用的后训练方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [280] [Towards Depth Foundation Model: Recent Trends in Vision-Based Depth Estimation](https://arxiv.org/abs/2507.11540)
> *迈向深度基础模型：视觉深度估计的最新趋势*

*Zhen Xu, Hongyu Zhou, Sida Peng, Haotong Lin, Haoyu Guo, Jiahao Shao, Peishan Yang, Qinglin Yang, Sheng Miao, Xingyi He, Yifan Wang, Yue Wang, Ruizhen Hu, Yiyi Liao, Xiaowei Zhou, Hujun Bao* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 深度估计, 基础模型, 计算机视觉, 深度学习, 综述

**Comment:** 

> **TL;DR:** 本文综述了视觉深度估计领域的最新趋势，重点介绍了深度基础模型的兴起，旨在克服传统方法和现有视觉方法在泛化和稳定性方面的局限性。

**AI_Comments:** 本文作为一篇综述，其创新之处在于系统地梳理了深度估计领域向“深度基础模型”发展的最新趋势，并强调了大规模数据集和新型架构在此过程中扮演的关键角色。其重要性在于为该领域的研究者指明了未来方向，特别是如何通过借鉴其他领域基础模型的成功经验来解决深度估计长期存在的泛化和稳定性问题。它有效地连接了传统方法、现有视觉方法与新兴的基础模型范式，具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的深度估计方法（如LiDAR）成本高、分辨率低且受环境影响。现有基于视觉的方法则面临泛化能力和稳定性不足的挑战。受其他领域基础模型成功的启发，研究者提出开发“深度基础模型”以解决这些问题。

**Method:** 本文综述了单目、立体、多视角和单目视频设置下深度估计的深度学习架构和范式演变。作者探讨了这些模型解决现有挑战的潜力，并全面概述了可促进其开发的大规模数据集。通过识别关键架构和训练策略，旨在指明通往鲁棒深度基础模型的路径。

**Result:** 本文作为一篇综述，没有提供新的实验结果。它识别了关键架构和训练策略，并概述了大规模数据集，旨在为未来研究和应用提供见解。

**Conclusion:** 本文旨在指明通往鲁棒深度基础模型的路径，并为未来的研究和应用提供深刻见解。

> **ai_Abstract:** 本文综述了视觉深度估计领域的最新进展，特别关注了“深度基础模型”的兴起。针对传统硬件方法成本高、分辨率低以及现有视觉方法泛化能力和稳定性不足的问题，研究者受其他领域基础模型的启发，提出利用大规模数据集训练深度神经网络以实现强大的零样本泛化能力。文章回顾了深度学习在单目、立体、多视角和单目视频深度估计中的发展，并探讨了大型数据集对构建鲁棒深度基础模型的潜力，旨在为未来的研究和应用提供方向。

> **摘要翻译:** 深度估计是3D计算机视觉中的一项基础任务，对于3D重建、自由视角渲染、机器人技术、自动驾驶和AR/VR技术等应用至关重要。依赖于LiDAR等硬件传感器的传统方法通常受到成本高昂、分辨率低和环境敏感性的限制，这限制了它们在实际场景中的适用性。基于视觉方法的最新进展提供了一种有前景的替代方案，但由于模型架构容量低或依赖于特定领域的小规模数据集，它们在泛化和稳定性方面面临挑战。其他领域中缩放定律和基础模型的出现启发了“深度基础模型”的开发：在大型数据集上训练并具有强大零样本泛化能力的深度神经网络。本文综述了单目、立体、多视角和单目视频设置下深度估计的深度学习架构和范式演变。我们探讨了这些模型解决现有挑战的潜力，并提供了可促进其开发的大规模数据集的全面概述。通过识别关键架构和训练策略，我们旨在突出通往鲁棒深度基础模型的路径，为未来的研究和应用提供见解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [294] [A Robust Incomplete Multimodal Low-Rank Adaptation Approach for Emotion Recognition](https://arxiv.org/abs/2507.11202)
> *一种用于情感识别的鲁棒不完整多模态低秩自适应方法*

*Xinkui Zhao, Jinsong Shu, Yangyang Wu, Guanjie Cheng, Zihe Liu, Naibo Wang, Shuiguang Deng, Zhongle Xie, Jianwei Yin* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 多模态情感识别, 不完整多模态, 低秩自适应, MCULoRA, 参数高效

**Comment:** 

> **TL;DR:** 本文提出了一种名为MCULoRA的新型参数高效框架，用于解决情感识别中不完整多模态数据训练时模态组合间梯度冲突导致性能下降的问题，并在多个基准数据集上表现出卓越的性能。

**AI_Comments:** 该论文提出了一种新颖的参数高效框架MCULoRA，创新点在于通过MCLA模块解耦共享信息与独特特征，并通过DPFT模块动态调整训练比例，有效解决了不完整多模态学习中常见的梯度冲突问题。其重要性在于提升了不完整多模态情感识别的鲁棒性和准确性，为实际应用提供了更可靠的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 多模态情感识别（MER）在实际应用中常因传感器故障或隐私保护而出现不完整多模态数据。现有方法试图通过平衡每种模态组合的训练来解决各种不完整多模态场景，但其主要限制在于不同模态组合的训练梯度相互冲突，最终导致预测模型性能下降。

**Method:** 本文提出了一种基于模态组合的单模态解耦动态低秩自适应方法，命名为MCULoRA。MCULoRA是一个新颖的参数高效不完整多模态学习模型训练框架，包含两个关键模块：模态组合感知低秩自适应（MCLA）模块和动态参数微调（DPFT）模块。MCLA模块有效解耦了共享信息与单个模态组合的独特特性。DPFT模块根据每种模态表示空间的可分离性调整模态组合的训练比例，以优化不同模态组合的学习效率。

**Result:** 在多个基准数据集上的广泛实验评估表明，MCULoRA在下游任务准确性方面显著优于以往的不完整多模态学习方法。

**Conclusion:** MCULoRA通过有效解决不完整多模态学习中模态组合间梯度冲突的问题，显著提升了多模态情感识别的性能，证明了其作为一种鲁棒且参数高效方法的有效性。

> **ai_Abstract:** 本文针对多模态情感识别中因不完整多模态数据导致的性能下降问题，提出了一种名为MCULoRA的鲁棒不完整多模态低秩自适应方法。MCULoRA通过模态组合感知低秩自适应（MCLA）和动态参数微调（DPFT）两个模块，有效解耦了模态间信息并优化了不同模态组合的学习效率，从而解决了现有方法中模态梯度冲突的局限性。实验证明，MCULoRA在多个基准数据集上显著优于现有方法。

> **摘要翻译:** 多模态情感识别（MER）在实际应用中常因传感器故障或隐私保护要求而遇到不完整多模态的情况。尽管现有方法试图通过额外梯度平衡每种模态组合的训练来解决各种不完整多模态场景，但这些方法面临一个关键限制：来自不同模态组合的训练梯度相互冲突，最终降低了最终预测模型的性能。在本文中，我们提出了一种基于模态组合的单模态解耦动态低秩自适应方法，命名为MCULoRA，这是一种用于不完整多模态学习模型参数高效训练的新颖框架。MCULoRA由两个关键模块组成：模态组合感知低秩自适应（MCLA）和动态参数微调（DPFT）。MCLA模块有效地将共享信息从单个模态组合的独特特征中解耦出来。DPFT模块根据每种模态表示空间的可分离性调整模态组合的训练比例，优化了不同模态组合的学习效率。我们在多个基准数据集上的广泛实验评估表明，MCULoRA在下游任务准确性方面显著优于以往的不完整多模态学习方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [301] [Nexus-Gen: Unified Image Understanding, Generation, and Editing via Prefilled Autoregression in Shared Embedding Space](https://arxiv.org/abs/2504.21356)
> *Nexus-Gen：通过共享嵌入空间中的预填充自回归实现统一图像理解、生成和编辑*

*Hong Zhang, Zhongjie Duan, Xingjun Wang, Yuze Zhao, Weiyi Lu, Zhipeng Di, Yixuan Xu, Yingda Chen, Yu Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 统一模型, 图像理解, 图像生成, 图像编辑, 自回归, 共享嵌入空间

**Comment:** 

> **TL;DR:** Nexus-Gen提出了一种新的架构，通过在共享嵌入空间中结合自回归和扩散模型，并采用预填充自回归策略，统一了图像理解、生成和编辑任务，实现了最先进的性能。

**AI_Comments:** Nexus-Gen的创新之处在于其统一架构和预填充自回归策略。通过将图像理解、生成和编辑整合到共享嵌入空间中，并有效缓解自回归误差累积，该工作为多模态生成模型的发展提供了重要进展。其开源的贡献也有助于推动该领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有统一多模态生成模型在图像合成质量、自回归误差累积和图像编辑能力方面存在局限性。

**Method:** 提出Nexus-Gen，一种在共享图像嵌入空间中统一图像理解、生成和编辑任务的新型架构。该共享空间作为自回归模型和扩散模型之间的桥梁，无缝整合了它们在跨模态建模中的互补优势。为减轻自回归嵌入预测过程中严重的误差累积，提出了一种新颖的预填充自回归策略，通过使用可学习嵌入预填充输入序列来对齐训练-推理动态。

**Result:** 在包含2630万样本的大规模数据集上进行多阶段和多任务训练后，Nexus-Gen在涵盖图像理解、生成和编辑任务的评估基准上取得了最先进的性能。

**Conclusion:** Nexus-Gen成功地通过共享嵌入空间和新颖的预填充自回归策略，统一了图像理解、生成和编辑任务，并显著提升了性能，解决了现有统一模型的局限性。

> **ai_Abstract:** Nexus-Gen提出了一种创新的统一架构，旨在解决现有统一多模态生成模型在图像合成质量、自回归误差累积和图像编辑方面的不足。该模型通过在共享图像嵌入空间中整合自回归和扩散模型，实现了图像理解、生成和编辑任务的统一。为缓解自回归误差积累，研究引入了预填充自回归策略。经过大规模数据集的多阶段多任务训练，Nexus-Gen在多项图像任务基准上取得了最先进的性能。

> **摘要翻译:** 统一多模态生成模型旨在整合图像理解和生成能力，在利用多模态语料库，特别是交错的文本-图像数据方面具有显著优势。然而，现有统一模型在图像合成质量、自回归误差累积和图像编辑能力方面表现出局限性。在这项工作中，我们提出了Nexus-Gen，一种新颖的架构，它在共享图像嵌入空间中统一了图像理解、生成和编辑任务。这个共享空间作为自回归模型和扩散模型之间的桥梁，无缝整合了它们在跨模态建模中的互补优势。为了减轻自回归嵌入预测过程中严重的误差累积，我们提出了一种新颖的预填充自回归策略，通过使用可学习嵌入预填充输入序列来对齐训练-推理动态。在包含2630万样本的我们构建的大规模数据集上进行多阶段和多任务训练后，Nexus-Gen在涵盖图像理解、生成和编辑任务的评估基准上取得了最先进的性能。所有模型、数据集和源代码都已在https://github.com/modelscope/Nexus-Gen发布，以促进该领域的进一步发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [312] [Modernizing CNN-based Weather Forecast Model towards Higher Computational Efficiency](https://arxiv.org/abs/2507.10893)
> *现代化CNN天气预报模型以提高计算效率*

*Minjong Cheon, Eunhan Goo, Su-Hyeon Shin, Muhammad Ahmed, Hyungjun Kim* | **Category: cs.CV, cs.AI, cs.LG, physics.ao-ph** | **Updated: 2025-07-15**

**Keywords:** CNN, 天气预报, 计算效率, KAI-a, 轻量化设计

**Comment:** 26pages, 9 Figures

> **TL;DR:** 本研究提出了一种现代化的CNN天气预报模型KAI-a，它在保持与最先进模型相当的预测精度的同时，显著降低了计算资源需求，解决了当前基于Transformer的模型参数量大、训练成本高的问题。

**AI_Comments:** 本文通过对CNN模型进行现代化改造，成功地在天气预报领域实现了计算效率的显著提升，同时保持了与Transformer模型相当的预测精度。其创新之处在于系统性地提出了一套现代化路线图，并结合了尺度不变和地理物理感知设计。这对于资源受限或需要快速部署的应用场景具有重要意义，也为未来AI天气预报模型的发展提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前AI天气预报模型多采用Transformer架构，导致参数量巨大、训练复杂且资源需求高昂。本研究旨在开发一种计算效率更高、同时能保持竞争性预测精度的模型。

**Method:** 本研究引入了一个现代化的CNN模型KAI-a，用于全球天气预报。该模型整合了从早期CNN方法演变而来的关键架构增强，包括尺度不变架构和基于InceptionNeXt的模块，并采用了地理物理感知设计，以适应地球系统数据的结构。模型在ERA5每日数据集上进行了训练，包含67个大气变量。

**Result:** KAI-a模型包含约700万参数，在单个NVIDIA L40s GPU上仅需12小时即可完成训练。评估结果显示，KAI-a在中期天气预报方面与最先进的模型性能相当，但设计显著轻量化。此外，对2018年欧洲热浪和东亚夏季风的案例研究表明，KAI-a在捕捉极端事件方面具有强大的能力。

**Conclusion:** 本研究提出的现代化CNN模型KAI-a在计算效率上优于现有的Transformer模型，同时在中期天气预报和极端事件捕捉方面保持了竞争性的精度，证明了其在实际应用中的潜力。

> **ai_Abstract:** 本文提出了一种名为KAI-a的现代化CNN全球天气预报模型，旨在解决当前基于Transformer的AI天气模型计算成本高昂的问题。KAI-a采用了尺度不变架构和InceptionNeXt模块，并结合地理物理感知设计，实现了高计算效率。该模型参数量小（约700万），训练速度快（12小时），且在中期天气预报精度上与现有先进模型相当，并能有效捕捉极端天气事件，展现出卓越的实用性。

> **摘要翻译:** 最近，基于AI的天气预报模型取得了令人瞩目的进展。这些模型在准确性上已达到与传统NWP系统相当的水平，标志着数据驱动天气预报的一个重要里程碑。然而，它们大多利用基于Transformer的架构，这通常由于庞大的参数量而导致高训练复杂性和资源需求。在本研究中，我们引入了一个现代化的CNN模型，用于全球天气预报，该模型在提供竞争性准确性的同时，显著降低了计算要求。为了呈现一个系统的现代化路线图，我们从早期基于CNN的方法中强调了跨多个设计尺度的关键架构增强。KAI-a融合了尺度不变架构和基于InceptionNeXt的模块，并采用地理物理感知设计，以适应地球系统数据的结构。该模型在ERA5每日数据集上进行了训练，包含67个大气变量，模型参数约为700万，在单个NVIDIA L40s GPU上仅需12小时即可完成训练。我们的评估显示，KAI-a在中期天气预报方面与最先进的模型性能相匹配，同时提供了显著轻量化的设计。此外，对2018年欧洲热浪和东亚夏季风的案例研究表明，KAI-a在捕捉极端事件方面具有强大的能力，进一步增强了其实用价值。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [318] [Combining Transformers and CNNs for Efficient Object Detection in High-Resolution Satellite Imagery](https://arxiv.org/abs/2507.11040)
> *结合Transformer和CNNs在高清卫星图像中进行高效目标检测*

*Nicolas Drapier, Aladine Chetouani, Aurélien Chateigner* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 目标检测, Transformer, CNN, 卫星图像, GLOD

**Comment:** 11 pages, 9 figures

> **TL;DR:** 提出GLOD，一个结合Transformer和CNN的架构，用于高效高分辨率卫星图像目标检测，在xView上表现优异。

**AI_Comments:** GLOD的创新之处在于其Transformer优先的架构设计，尤其是在高分辨率卫星图像目标检测领域的应用。通过结合Swin Transformer的强大特征提取能力和CNNs的局部处理优势（如UpConvMixer和Fusion Blocks），它有效地解决了卫星图像的多尺度和计算效率挑战。其在xView数据集上显著超越SOTA的性能，证明了该方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 解决高分辨率卫星图像中的目标检测问题，并提高效率和性能。

**Method:** 本文提出了GLOD，一个Transformer优先的架构，用于高分辨率卫星图像目标检测。GLOD用Swin Transformer取代CNN骨干网络进行端到端特征提取，并结合新颖的UpConvMixer块用于鲁棒上采样，以及Fusion Blocks用于多尺度特征集成。关键创新包括带有CBAM注意力的不对称融合和捕获跨尺度目标的多路径头部设计。

**Result:** 在xView数据集上实现了32.95%的性能，超越现有SOTA方法11.46%。

**Conclusion:** GLOD架构针对卫星图像的挑战进行了优化，利用空间先验同时保持计算效率，在目标检测方面取得了显著的性能提升。

> **ai_Abstract:** 本文提出了GLOD，一种结合Transformer和CNN的Transformer优先架构，专为高分辨率卫星图像的目标检测设计。GLOD利用Swin Transformer进行端到端特征提取，并引入UpConvMixer块进行上采样和Fusion Blocks进行多尺度特征集成。该方法在xView数据集上取得了32.95%的卓越性能，显著超越了现有最先进的方法。其关键创新包括带有CBAM注意力的不对称融合和多路径头部设计，有效解决了卫星图像检测的挑战，同时保持了计算效率。

> **摘要翻译:** 我们提出了GLOD，一个用于高分辨率卫星图像目标检测的Transformer优先架构。GLOD用Swin Transformer取代了CNN骨干网络，用于端到端特征提取，并结合了新颖的UpConvMixer块用于鲁棒上采样，以及融合块用于多尺度特征集成。我们的方法在xView上达到了32.95%的性能，超越了SOTA方法11.46%。关键创新包括带有CBAM注意力的不对称融合和捕获跨尺度目标的多路径头部设计。该架构针对卫星图像的挑战进行了优化，利用空间先验同时保持计算效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [319] [Learning and Transferring Better with Depth Information in Visual Reinforcement Learning](https://arxiv.org/abs/2507.09180)
> *在视觉强化学习中利用深度信息更好地学习和迁移*

*Zichun Xu, Yuntao Li, Zhaomin Wang, Lei Zhuang, Guocai Yang, Jingdong Zhao* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-15**

**Keywords:** 视觉强化学习, 深度信息, 视觉Transformer, 对比学习, sim2real

**Comment:** 

> **TL;DR:** 本文提出了一种基于视觉Transformer的RGB-D融合骨干网络，并结合对比无监督学习和课程学习，以提高视觉强化学习的泛化能力、样本效率和sim2real迁移效果。

**AI_Comments:** 本文的创新点在于将深度信息与视觉Transformer相结合，用于视觉强化学习的RGB-D融合，并通过对比无监督学习和灵活的课程学习策略进一步提升了样本效率和sim2real迁移能力。这对于在复杂环境中部署机器人学习具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度信息对场景外观变化具有鲁棒性，并固有地携带3D空间细节，因此可以利用它来增强视觉强化学习的泛化能力和样本效率。

**Method:** 本文提出了一种基于视觉Transformer的视觉骨干网络，用于融合RGB和深度模态。该网络首先通过独立的CNN分支处理不同模态，然后将组合的卷积特征输入可扩展的视觉Transformer以获得视觉表示。此外，设计了一种带有掩码和非掩码标记的对比无监督学习方案，以加速强化学习过程中的样本效率。对于sim2real迁移，开发了一种灵活的课程学习调度方案，用于在训练过程中部署域随机化。

**Result:** 抽象中未提及具体的实验结果，但方法旨在增强泛化能力、加速样本效率和促进sim2real迁移。

**Conclusion:** 抽象中未直接给出明确的结论，但研究旨在通过深度信息、改进的视觉骨干和学习策略来提升视觉强化学习的性能和迁移能力。

> **ai_Abstract:** 本研究提出了一种在视觉强化学习中利用深度信息的新方法。该方法引入了一个基于视觉Transformer的骨干网络，用于融合RGB和深度模态，旨在提升模型的泛化能力。为了提高样本效率，还设计了一种基于掩码和非掩码标记的对比无监督学习方案。此外，为实现sim2real迁移，开发了一种灵活的课程学习调度，以在训练过程中应用域随机化。

> **摘要翻译:** 深度信息对场景外观变化具有鲁棒性，并固有地携带3D空间细节。在本文中，提出了一种基于视觉Transformer的视觉骨干网络，用于融合RGB和深度模态，以增强泛化能力。不同模态首先由独立的CNN分支处理，然后将组合的卷积特征输入可扩展的视觉Transformer以获得视觉表示。此外，设计了一种带有掩码和非掩码标记的对比无监督学习方案，以加速强化学习过程中的样本效率。对于sim2real迁移，开发了一种灵活的课程学习调度方案，用于在训练过程中部署域随机化。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [326] [Localizing Before Answering: A Hallucination Evaluation Benchmark for Grounded Medical Multimodal LLMs](https://arxiv.org/abs/2505.00744)
> *回答前定位：一个用于接地医疗多模态大语言模型的幻觉评估基准*

*Dung Nguyen, Minh Khoi Ho, Huy Ta, Thanh Tam Nguyen, Qi Chen, Kumar Rav, Quy Duong Dang, Satwik Ramchandre, Son Lam Phung, Zhibin Liao, Minh-Son To, Johan Verjans, Phi Le Nguyen, Vu Minh Hieu Phan* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 医疗多模态大语言模型, 幻觉, 定位推理, 视觉问答, HEAL-MedVQA

**Comment:** Accepted at Joint Conference on Artificial Intelligence (IJCAI) 2025

> **TL;DR:** 医疗多模态大语言模型（LMMs）常因定位推理不足产生幻觉。本文提出了HEAL-MedVQA基准和Localize-before-Answer (LobA) 框架，训练LMMs先定位再回答，显著提升了医疗视觉问答的鲁棒性。

**AI_Comments:** 这项工作创新性地指出了医疗LMMs中一个关键但常被忽视的问题——定位推理不足导致的幻觉。通过提出专门的评估基准HEAL-MedVQA和新颖的LobA框架，为提升医疗领域多模态模型的可靠性和安全性提供了重要的方向和解决方案。其强调“先定位再回答”的范式对于确保LMMs在关键应用中的可信度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有医疗多模态大语言模型（LMMs）在医疗数据解释中常产生与源证据矛盾的幻觉，尤其是在定位推理不足时。它们倾向于依赖语言模式或关注不相关图像区域，而非分析相关的病理区域，这揭示了当前模型的一个关键局限性。

**Method:** 本文引入了HEAL-MedVQA（通过定位进行幻觉评估的医疗视觉问答）综合基准，用于评估LMMs的定位能力和幻觉鲁棒性。HEAL-MedVQA包含两种评估视觉和文本捷径学习的创新协议，以及一个包含6.7万个VQA对的数据集，其中含有医生标注的病理区域解剖分割掩码。此外，为改进视觉推理，提出了Localize-before-Answer (LobA) 框架，训练LMMs定位目标感兴趣区域并自提示以强调分割的病理区域，从而生成有根据且可靠的答案。

**Result:** 实验结果表明，所提出的方法在挑战性的HEAL-MedVQA基准上显著优于最先进的生物医学LMMs。

**Conclusion:** 本文通过引入HEAL-MedVQA基准和Localize-before-Answer (LobA) 框架，有效解决了医疗多模态大语言模型在医疗视觉问答中因定位推理不足导致的幻觉问题，显著提升了模型的鲁棒性和可靠性。

> **ai_Abstract:** 本文针对医疗多模态大语言模型（LMMs）在医疗数据解释中因定位推理不足导致的幻觉问题。研究发现LMMs常依赖非相关信息而非病理区域。为解决此问题，作者提出了HEAL-MedVQA基准，包含评估协议和医生标注的6.7万VQA数据集，用于评估模型的定位能力和幻觉鲁棒性。此外，还提出了“回答前定位”（LobA）框架，通过训练LMMs先定位病理区域再回答，以生成更可靠的答案。实验证明，该方法显著提升了医疗视觉问答的鲁棒性。

> **摘要翻译:** 医疗多模态大语言模型（LMMs）在医疗数据解释方面展现了卓越的能力。然而，这些模型经常产生与源证据相矛盾的幻觉，尤其是在定位推理不足时。这项工作揭示了当前医疗LMMs的一个关键局限性：它们在回答疾病相关查询时，往往依赖语言模式或关注不相关的图像区域，而不是分析相关的病理区域。为了解决这个问题，我们引入了HEAL-MedVQA（通过定位进行幻觉评估的医疗视觉问答），这是一个旨在评估LMMs定位能力和幻觉鲁棒性的综合基准。HEAL-MedVQA具有（i）两种创新的评估协议，用于评估视觉和文本捷径学习，以及（ii）一个包含6.7万个VQA对的数据集，其中包含医生标注的病理区域解剖分割掩码。为了改进视觉推理，我们提出了“回答前定位”（LobA）框架，该框架训练LMMs定位目标感兴趣区域并进行自提示以强调分割的病理区域，从而生成有根据且可靠的答案。实验结果表明，我们的方法在具有挑战性的HEAL-MedVQA基准上显著优于最先进的生物医学LMMs，提升了医疗VQA的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [334] [NarrLV: Towards a Comprehensive Narrative-Centric Evaluation for Long Video Generation Models](https://arxiv.org/abs/2507.11245)
> *NarrLV: 面向长视频生成模型的综合叙事中心评估*

*X. Feng, H. Yu, M. Wu, S. Hu, J. Chen, C. Zhu, J. Wu, X. Chu, K. Huang* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 长视频生成, 叙事评估, NarrLV, 时间叙事原子, MLLM

**Comment:** Project Page: https://amap-ml.github.io/NarrLV-Website/

> **TL;DR:** NarrLV是首个用于全面评估长视频生成模型叙事表达能力的基准，通过引入时间叙事原子（TNA）、构建自动提示生成管道和设计基于MLLM的评估指标，解决了当前评估基准缺乏叙事特异性的问题。

**AI_Comments:** NarrLV的创新之处在于其首次提出了一个以叙事为中心的评估框架，解决了长视频生成领域缺乏专门叙事评估基准的痛点。通过引入TNA和结合电影叙事理论，它为量化和评估视频叙事能力提供了一种新颖且系统的方法。其MLLM-based的评估指标也展现了前沿性。这项工作对于推动长视频生成模型向更高质量、更具叙事连贯性的方向发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前长视频生成模型的评估主要依赖于叙事提示简单的基准（如VBenc），而长视频生成的目标不仅是延长视频时长，更在于准确表达丰富的叙事内容。现有评估基准缺乏专门针对长视频生成模型叙事能力的评估。

**Method:** 1. 引入时间叙事原子（TNA）作为基本叙事单元，并用其数量量化叙事丰富性。2. 受电影叙事元素启发，构建了一个能够生成灵活可扩展TNA数量评估提示的自动提示生成管道。3. 基于叙事内容表达的三个渐进层次，设计了一个使用MLLM（多模态大语言模型）问答框架的有效评估指标。

**Result:** 实验结果表明，所提出的评估指标与人类判断高度一致。得出的评估结果揭示了当前视频生成模型在叙事内容表达方面的详细能力边界。

**Conclusion:** NarrLV是首个全面评估长视频生成模型叙事表达能力的基准，其提出的指标与人类判断一致，成功揭示了现有模型的叙事能力边界，为未来长视频生成技术的发展提供了重要的评估工具。

> **ai_Abstract:** 本研究提出了NarrLV，首个专门用于全面评估长视频生成模型叙事表达能力的基准。针对现有评估基准未能充分考量长视频叙事丰富性的问题，NarrLV引入了“时间叙事原子”（TNA）来量化叙事，并构建了自动提示生成管道。此外，还设计了基于MLLM的问答框架作为评估指标。实验证明，NarrLV的评估结果与人类判断高度一致，有效揭示了当前模型在叙事内容表达上的能力边界。

> **摘要翻译:** 随着基础视频生成技术的快速发展，长视频生成模型凭借扩展的内容创作空间展现出广阔的研究潜力。最近的研究表明，长视频生成任务的目标不仅是延长视频时长，还在于在更长的视频中准确表达更丰富的叙事内容。然而，由于缺乏专门为长视频生成模型设计的评估基准，当前对这些模型的评估主要依赖于叙事提示简单的基准（例如VBench）。据我们所知，我们提出的NarrLV是第一个全面评估长视频生成模型叙事表达能力的基准。受电影叙事理论的启发，（i）我们首先引入了在视频中保持连续视觉呈现的基本叙事单元，称为时间叙事原子（TNA），并使用其数量来定量衡量叙事丰富性。在影响TNA变化的三个关键电影叙事元素的指导下，我们构建了一个能够生成具有灵活可扩展TNA数量的评估提示的自动提示生成管道。（ii）然后，基于叙事内容表达的三个渐进层次，我们设计了一个使用MLLM（多模态大语言模型）问答框架的有效评估指标。（iii）最后，我们对现有长视频生成模型和基础生成模型进行了广泛评估。实验结果表明，我们的指标与人类判断高度一致。得出的评估结果揭示了当前视频生成模型在叙事内容表达方面的详细能力边界。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [346] [FlowAlign: Trajectory-Regularized, Inversion-Free Flow-based Image Editing](https://arxiv.org/abs/2505.23145)
> *FlowAlign：轨迹正则化、免反演的基于流的图像编辑*

*Jeongsol Kim, Yeobin Hong, Jonghyun Park, Jong Chul Ye* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 图像编辑, 流模型, 免反演, 轨迹正则化, 一致性

**Comment:** 

> **TL;DR:** FlowAlign提出了一种新的免反演基于流的图像编辑框架，通过引入末端点源相似性作为正则化项来解决现有方法中不稳定的编辑轨迹和较差的源一致性问题，从而实现更平滑、更一致的编辑，并支持反向编辑，在源保留和编辑可控性方面优于现有方法。

**AI_Comments:** FlowAlign的创新点在于引入了基于最优控制的轨迹正则化和末端点源相似性作为正则化项，这有效地解决了免反演流基图像编辑中常见的轨迹不稳定和源一致性差的问题。其支持反向编辑的能力也突显了方法的鲁棒性和一致性，为图像编辑领域提供了更可靠的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有免反演、基于流的图像编辑方法（如FlowEdit）虽然利用预训练的噪声到图像流模型并避免了精确潜在反演，但常导致不稳定的编辑轨迹和较差的源一致性。

**Method:** FlowAlign提出了一种基于最优控制的轨迹控制方法，通过在末端点引入源相似性作为正则化项，以促进编辑过程中更平滑和更一致的轨迹。该末端点正则化明确平衡了与编辑提示的语义对齐和与源图像的结构一致性。此外，它通过简单地反转ODE轨迹来支持反向编辑。

**Result:** FlowAlign在源保留和编辑可控性方面均优于现有方法。它自然支持反向编辑，突出了变换的可逆性和一致性。

**Conclusion:** FlowAlign通过其轨迹正则化方法，有效地解决了现有免反演流基图像编辑的稳定性问题，显著提高了图像编辑的一致性、源保留和可控性。

> **ai_Abstract:** FlowAlign是一种新颖的免反演、基于流的图像编辑框架，旨在解决现有方法中不稳定的编辑轨迹和源一致性差的问题。它通过引入基于最优控制的轨迹正则化，特别是将末端点源相似性作为正则化项，来确保编辑过程中的平滑性和一致性。这种正则化明确平衡了语义对齐和结构一致性。此外，FlowAlign支持简单的反向编辑，证明了其变换的可逆性和一致性。实验结果表明，FlowAlign在源图像保留和编辑可控性方面均优于现有技术。

> **摘要翻译:** 最近的免反演、基于流的图像编辑方法，如FlowEdit，利用预训练的噪声到图像流模型（如Stable Diffusion 3），通过求解常微分方程（ODE）实现文本驱动的图像操作。虽然缺乏精确的潜在反演是这些方法的核心优势，但它常常导致不稳定的编辑轨迹和较差的源一致性。为了解决这一限制，我们提出了FlowAlign，一个新颖的免反演、基于流的框架，通过基于最优控制的轨迹控制实现一致的图像编辑。具体来说，FlowAlign引入了末端点源相似性作为正则化项，以促进编辑过程中更平滑、更一致的轨迹。值得注意的是，我们的末端点正则化被证明可以明确平衡语义对齐与编辑提示以及沿着轨迹与源图像的结构一致性。此外，FlowAlign通过简单地反转ODE轨迹自然支持反向编辑，突出了变换的可逆性和一致性。广泛的实验表明，FlowAlign在源保留和编辑可控性方面均优于现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [350] [Pavlok-Nudge: A Feedback Mechanism for Atomic Behaviour Modification with Snoring Usecase](https://arxiv.org/abs/2305.06110)
> *Pavlok-Nudge：一种用于原子行为修正的反馈机制，以打鼾用例为例*

*Md Rakibul Hasan, Shreya Ghosh, Pradyumna Agrawal, Zhixi Cai, Abhinav Dhall, Tom Gedeon* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** Pavlok, 行为修正, 打鼾, 深度学习, 可穿戴设备

**Comment:** Md Rakibul Hasan and Shreya Ghosh are co-first authors

> **TL;DR:** 该论文提出了一种利用Pavlok可穿戴设备和轻量级深度学习模型自动化原子行为修正（例如打鼾）的方法，通过检测行为并提供提示。

**AI_Comments:** 该论文的创新之处在于将轻量级深度学习模型与可穿戴设备结合，实现了行为修正的自动化，克服了手动操作的局限性。模型在大幅减少参数的同时保持了SOTA准确率，这一点尤为突出，使其适用于资源受限的设备。

<details>
  <summary>Details</summary>

**Motivation:** 现有的Pavlok设备依赖手动操作，限制了其在自动化行为修正方面的应用。

**Method:** 本文提出一个框架，首先通过轻量级深度学习模型检测目标行为（例如通过轻量级一维卷积神经网络从音频中检测打鼾），然后使用Pavlok设备向用户提供预防性提示（例如改变睡姿）。

**Result:** 所提出的轻量级模型在公共基准测试中实现了0.99的SOTA测试准确率，参数量比SOTA模型减少了99.8%（从790,273减少到1,337）。

**Conclusion:** 这种简单的自动化解决方案可以帮助人们改变原子习惯，可能带来长期的健康益处。

> **ai_Abstract:** 本文介绍了Pavlok-Nudge，一种利用Pavlok可穿戴设备自动化原子行为修正的策略。为了克服手动操作的限制，该框架采用轻量级一维卷积神经网络检测特定行为（例如从音频中检测打鼾）。检测到行为后，系统会触发Pavlok设备提供预防性提示，鼓励用户修正行为，例如改变睡姿。所提出的轻量级模型在公共基准测试中表现出0.99的SOTA准确率，同时参数量显著减少（比现有SOTA模型少99.8%）。作者认为该解决方案有助于培养更健康的习惯并带来长期健康益处。

> **摘要翻译:** 本文提出了一种使用Pavlok可穿戴设备的原子行为干预策略。Pavlok利用蜂鸣声、振动和电击作为厌恶技术，帮助个人进行行为修正。虽然该设备在某些周期性日常生活中（如闹钟和运动通知）可能有用，但它依赖手动操作，限制了其使用。为了自动化行为修正，我们提出了一个框架，该框架首先通过轻量级深度学习模型检测目标行为，然后提示用户。我们提出的解决方案在打鼾的背景下实施和验证，该方案捕获环境中的音频，并使用轻量级一维卷积神经网络预测音频内容是否为打鼾。根据预测，我们使用Pavlok提示用户采取预防措施，例如改变睡姿。我们相信这种简单的解决方案可以帮助人们改变他们的原子习惯，这可能带来长期的健康益处。我们提出的轻量级模型（比SOTA模型参数减少99.8%；790,273→1,337）在公共基准测试中实现了0.99的SOTA测试准确率。代码和模型可在https://github.com/hasan-rakibul/pavlok-nudge-snore公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [363] [Commuting Distance Regularization for Timescale-Dependent Label Inconsistency in EEG Emotion Recognition](https://arxiv.org/abs/2507.10895)
> *脑电图情感识别中时间尺度依赖标签不一致性的通勤距离正则化*

*Xiaocong Zeng, Craig Michoski, Yan Pang, Dongyang Kuang* | **Category: cs.CV, cs.AI, cs.LG, eess.SP** | **Updated: 2025-07-15**

**Keywords:** 脑电图情感识别, 时间尺度依赖标签不一致性, 正则化, 局部变异损失, 通勤距离

**Comment:** 

> **TL;DR:** 本文针对脑电图情感识别中时间尺度依赖的标签不一致性问题，提出了两种新的正则化策略（LVL和LGCL），并引入了新的评估指标，实验证明其优于现有方法，提升了模型性能和可解释性。

**AI_Comments:** 这项工作创新性地提出了解决EEG情感识别中“时间尺度依赖标签不一致性”这一重要且常被忽视的问题。通过结合图论和经典数学原理（有界变分和通勤距离）设计新的正则化损失函数，为提升模型在复杂时间序列数据上的泛化能力和可解释性提供了新的视角。引入新的评估指标也体现了对问题细致的考量。其优于SOTA的性能证明了方法的有效性，为EEG情感识别领域的研究提供了重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 解决训练脑电图（EEG）情感识别神经网络模型时，时间尺度依赖标签不一致性（TsDLI）这一常被忽视的问题，以增强模型泛化能力和可解释性。

**Method:** 提出了两种新的正则化策略：局部变异损失（LVL）和局部-全局一致性损失（LGCL），两者都将有界变分函数和通勤时间距离等经典数学原理整合到图论框架中。同时，引入了一套新的评估指标来更好地捕捉时间局部预测与相关全局情感标签之间的一致性。在DREAMER和DEAP两个EEG情感数据集上，使用LSTM和transformer等多种神经网络架构进行实验验证。

**Result:** 提出的方法在两个常用EEG情感数据集（DREAMER和DEAP）和多种神经网络架构（LSTM、transformer）上的综合实验中，表现始终优于现有最先进的基线方法。它提供了卓越的聚合性能，并在标签不一致性下实现了可解释性和预测能力之间的良好权衡。特别是，LVL在所有基准骨干网络和指标上都取得了最佳的聚合排名，而LGCL则经常位居第二。

**Conclusion:** 本文提出的通勤距离正则化方法（LVL和LGCL）能有效解决脑电图情感识别中的时间尺度依赖标签不一致性问题，显著提升了模型的性能、泛化能力和可解释性，并优于现有最先进方法。

> **ai_Abstract:** 本文提出了一种解决脑电图情感识别中时间尺度依赖标签不一致性（TsDLI）问题的新方法。通过引入两种基于图论和经典数学原理的正则化策略——局部变异损失（LVL）和局部-全局一致性损失（LGCL），以及新的评估指标，显著提升了模型在DREAMER和DEAP数据集上的泛化能力、解释性和预测性能。实验结果表明，该方法优于现有SOTA基线，其中LVL表现最佳，LGCL次之。

> **摘要翻译:** 在这项工作中，我们解决了在训练基于脑电图（EEG）的人类情感识别神经网络模型时，经常被忽视的时间尺度依赖标签不一致性（TsDLI）问题。为了减轻TsDLI并增强模型的泛化能力和可解释性，我们提出了两种新颖的正则化策略：局部变异损失（LVL）和局部-全局一致性损失（LGCL）。这两种方法都在图论框架内融入了经典的数学原理——特别是，有界变分函数和通勤时间距离。作为我们正则化器的补充，我们引入了一套新的评估指标，这些指标能更好地捕捉时间局部预测与其相关的全局情感标签之间的一致性。我们通过在两个广泛使用的脑电图情感数据集（DREAMER和DEAP）上，以及包括LSTM和基于transformer模型在内的一系列神经网络架构上进行的全面实验验证了我们的方法。性能评估使用了五种不同的指标，涵盖了定量准确性和定性一致性。结果一致表明，我们提出的方法优于现有最先进的基线方法，提供了卓越的聚合性能，并在标签不一致性下提供了可解释性和预测能力之间的良好权衡。值得注意的是，LVL在所有基准骨干网络和指标上都取得了最佳的聚合排名，而LGCL则经常位居第二，这突出了我们框架的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [364] [Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation](https://arxiv.org/abs/2507.11055)
> *通过原型驱动的语义近似缓解医学语言引导分割中的文本依赖*

*Shuchang Ye, Usman Naseem, Mingyuan Meng, Jinman Kim* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 医学图像分割, 语言引导, 文本依赖, 原型学习, 语义近似

**Comment:** Accepted to ICCV 2025

> **TL;DR:** ProLearn框架通过原型驱动的语义近似，解决医学图像分割中对配对文本的依赖问题，有效利用无文本图像数据。

**AI_Comments:** 这篇论文的创新点在于提出了ProLearn框架和PSA模块，通过构建原型空间来近似文本语义，从而有效解决了医学图像分割领域中配对图像-文本数据稀缺的“文本依赖”问题。这对于提升模型在实际临床场景中的适用性和利用未充分利用的图像数据具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的医学语言引导分割方法过度依赖配对的图像-文本输入，导致两个基本限制：1) 许多医学分割数据集缺乏配对报告，图像数据未充分利用；2) 推理仅限于有配对报告的回顾性分析，限制了其在大多数分割通常先于报告的临床场景中的适用性。

**Method:** 本文提出了ProLearn框架，这是首个用于语言引导分割的原型驱动学习框架，旨在从根本上缓解文本依赖。其核心是引入原型驱动的语义近似（PSA）模块，该模块通过从文本报告中提炼出与分割相关的语义来初始化一个离散且紧凑的原型空间，并支持一种查询响应机制，为没有文本输入的图像近似语义指导。

**Result:** 在QaTa-COV19、MosMedData+和Kvasir-SEG数据集上的大量实验表明，当可用文本有限时，ProLearn优于最先进的语言引导方法。

**Conclusion:** ProLearn框架通过原型驱动的语义近似，成功缓解了医学语言引导分割中对配对文本的依赖问题，有效利用了无文本图像数据，显著提高了其在临床场景中的适用性。

> **ai_Abstract:** 本文提出了ProLearn框架，旨在解决医学语言引导分割中对配对文本的过度依赖问题。该框架引入了原型驱动的语义近似（PSA）模块，通过从文本报告中提取语义来初始化原型空间，并为无文本图像近似生成语义指导。实验证明，在文本数据有限的情况下，ProLearn的性能优于现有先进方法，有效提升了医学图像分割在临床应用中的灵活性和效率。

> **摘要翻译:** 医学语言引导分割，通过整合文本临床报告作为辅助指导以增强图像分割，已显示出比单模态方法显著的改进。然而，其对配对图像-文本输入的固有依赖，我们称之为“文本依赖”，带来了两个基本限制：1）许多医学分割数据集缺乏配对报告，导致大量仅有图像的数据在训练中未被充分利用；2）推理仅限于对有配对报告的病例进行回顾性分析，这限制了其在大多数分割通常先于报告的临床场景中的适用性。为了解决这些限制，我们提出了ProLearn，这是首个用于语言引导分割的原型驱动学习框架，从根本上缓解了文本依赖。其核心是，在ProLearn中，我们引入了一种新颖的原型驱动语义近似（PSA）模块，以实现对来自文本输入的语义指导的近似。PSA通过从文本报告中提炼出与分割相关的语义来初始化一个离散且紧凑的原型空间。一旦初始化，它支持一种查询响应机制，为没有文本输入的图像近似语义指导，从而缓解了文本依赖。在QaTa-COV19、MosMedData+和Kvasir-SEG上的大量实验表明，当可用文本有限时，ProLearn优于最先进的语言引导方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [365] [Fairness-Aware Grouping for Continuous Sensitive Variables: Application for Debiasing Face Analysis with respect to Skin Tone](https://arxiv.org/abs/2507.11247)
> *针对连续敏感变量的公平性感知分组：在肤色人脸分析去偏中的应用*

*Veronika Shilova, Emmanuel Malherbe, Giovanni Palma, Laurent Risser, Jean-Michel Loubes* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 公平性, 连续敏感变量, 分组, 去偏, 肤色分析

**Comment:** 

> **TL;DR:** 本文提出一种公平性感知的分组方法，用于连续敏感变量，以揭示细微的歧视模式并实现去偏，尤其应用于肤色人脸分析。

**AI_Comments:** 这篇论文的创新点在于提出了一个针对连续敏感变量的动态分组方法，而非依赖于预定义的分组。这种方法能够更精细地识别出受歧视的少数亚群体，这对于解决实际应用中（如人脸分析）的偏见问题至关重要。其在去偏方面的应用也显示出良好的效果，即在提升公平性方面表现出色，同时对模型准确性影响最小，这使其具有很高的实用价值和工业部署潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的公平性评估方法通常将观察结果划分为预定义组，但当敏感属性（如肤色）是连续的时，这种方法可能忽略或掩盖少数亚群体所遭受的歧视。

**Method:** 提出一种基于公平性的分组方法，用于连续（可能是多维）敏感属性。该方法根据观察到的歧视水平对数据进行分组，通过最大化基于组间歧视方差的新颖准则来识别划分，从而分离出最关键的子组。此外，该方法还用于去偏，通过逐组后处理来预测公平分数。

**Result:** 在多个合成数据集上验证了方法的鲁棒性，揭示了歧视如何在敏感属性空间中表现；在CelebA和FFHQ数据集上，利用工业专有算法预测的肤色，经验结果表明所提出的分割方法揭示了比以往更细致的歧视模式，并且这些发现对于给定模型在不同数据集上保持稳定；该分组模型用于去偏时，在提高公平性的同时对准确性影响最小。

**Conclusion:** 本文提出的分组方法能够有效提升公平性，同时对准确性影响最小，这证实了其划分方法的有效性，并为工业部署奠定了基础。

> **ai_Abstract:** 本文针对连续敏感变量（如肤色）在公平性评估中预定义分组的局限性，提出了一种新颖的公平性感知分组方法。该方法根据观察到的歧视水平对数据进行动态分组，通过最大化组间歧视方差来识别最关键的受歧视子群体。研究在合成数据集、CelebA和FFHQ数据集上验证了该方法的有效性，揭示了更细致的歧视模式。此外，该分组模型被成功应用于去偏目的，实验结果表明其在显著提升公平性的同时对模型准确性影响甚微，展现了其在工业应用中的潜力。

> **摘要翻译:** 在法律框架内，数据集和模型中的公平性通常通过将观察结果划分为预定义组，然后计算公平性度量（例如，关于性别的不同影响或赔率均等）来评估。然而，当肤色等敏感属性是连续的时，划分为默认组可能会忽视或掩盖某些少数亚群体所遭受的歧视。为了解决这一局限性，我们提出了一种针对连续（可能是多维）敏感属性的基于公平性的分组方法。通过根据观察到的歧视水平对数据进行分组，我们的方法识别出最大化基于组间歧视方差的新颖准则的划分，从而分离出最关键的子组。
我们使用多个合成数据集验证了所提出的方法，并证明了其在不断变化的人口分布下的鲁棒性——揭示了歧视如何在敏感属性空间中表现。此外，我们还研究了肤色情况下单调公平性的特殊设置。我们在CelebA和FFHQ数据集上的经验结果，利用工业专有算法预测的肤色，表明所提出的分割方法揭示了比以往报告更细致的歧视模式，并且这些发现在给定模型下在不同数据集上保持稳定。最后，我们利用我们的分组模型进行去偏，旨在通过逐组后处理来预测公平分数。结果表明，我们的方法在提高公平性的同时对准确性影响最小，从而证实了我们的划分方法并为工业部署打开了大门。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [367] [PAN-Crafter: Learning Modality-Consistent Alignment for PAN-Sharpening](https://arxiv.org/abs/2505.23367)
> *PAN-Crafter：学习模态一致性对齐用于全色锐化*

*Jeonghyeok Do, Sungpyo Kim, Geunhyuk Youk, Jaehyup Lee, Munchurl Kim* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 全色锐化, 跨模态对齐, 深度学习, 模态自适应重建, 注意力机制

**Comment:** ICCV 2025 (camera-ready version). Please visit our project page
  https://kaist-viclab.github.io/PAN-Crafter_site

> **TL;DR:** 提出PAN-Crafter框架，通过模态一致性对齐解决全色锐化中的跨模态错位问题，实现更优性能和效率。

**AI_Comments:** PAN-Crafter的创新之处在于其明确地解决了全色锐化中的跨模态错位问题，而不是简单地假设完美对齐。通过引入MARs和CM3A，该方法不仅提高了融合质量，还在效率和泛化性上取得了显著突破，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 全色锐化中，由于传感器放置、采集时间、分辨率差异等导致的跨模态错位是一个根本性挑战。传统的深度学习方法假设完美像素级对齐，导致在错位存在时出现光谱失真、双边缘和模糊。

**Method:** 提出PAN-Crafter，一个模态一致性对齐框架，显式缓解PAN和MS模态间的错位。核心包括：模态自适应重建（MARs），使单个网络能够联合重建HRMS和PAN图像，利用PAN的高频细节作为辅助自监督；以及跨模态对齐感知注意力（CM3A），双向对齐MS纹理到PAN结构反之亦然，实现跨模态自适应特征细化。

**Result:** PAN-Crafter在多个基准数据集上优于最新SOTA方法的所有指标，推理速度快50.11倍，内存占用仅为0.63倍。在未见过的卫星数据集上表现出强大的泛化性能。

**Conclusion:** PAN-Crafter框架通过解决跨模态错位问题，显著提高了全色锐化性能，并展现出卓越的效率和泛化能力。

> **ai_Abstract:** 本文提出了PAN-Crafter，一个用于全色锐化的模态一致性对齐框架，旨在解决由传感器错位引起的跨模态错位问题。该框架包含模态自适应重建（MARs）和跨模态对齐感知注意力（CM3A）两大核心组件，分别用于联合重建和跨模态特征对齐。实验证明，PAN-Crafter在性能、推理速度和内存效率上均超越了现有SOTA方法，并展现出强大的泛化能力。

> **摘要翻译:** 全色锐化旨在融合高分辨率全色（PAN）图像与低分辨率多光谱（MS）图像，以生成高分辨率多光谱（HRMS）输出。然而，由传感器放置、采集时间以及分辨率差异引起的跨模态错位带来了根本性挑战。传统的深度学习方法假设完美的像素级对齐，并依赖于逐像素重建损失，这在存在错位时会导致光谱失真、双边缘和模糊。为了解决这个问题，我们提出了PAN-Crafter，一个模态一致性对齐框架，它明确地缓解了PAN和MS模态之间的错位差距。其核心是模态自适应重建（MARs），它使单个网络能够联合重建HRMS和PAN图像，利用PAN的高频细节作为辅助自监督。此外，我们引入了跨模态对齐感知注意力（CM3A），这是一种新颖的机制，它双向对齐MS纹理到PAN结构，反之亦然，从而实现了跨模态的自适应特征细化。在多个基准数据集上进行的广泛实验表明，我们的PAN-Crafter在所有指标上都优于最新的最先进方法，即使推理时间快50.11倍，内存大小仅为0.63倍。此外，它在未见过的卫星数据集上表现出强大的泛化性能，显示了其在不同条件下的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [384] [Augmenting End-to-End Steering Angle Prediction with CAN Bus Data](https://arxiv.org/abs/2310.14162)
> *使用CAN总线数据增强端到端转向角预测*

*Amit Singh* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 端到端转向预测, CAN总线数据, 计算机视觉, 传感器融合, 自动驾驶汽车

**Comment:** 5 pages

> **TL;DR:** 本文通过将CAN总线数据与视频数据融合，在不增加LiDAR/雷达成本的情况下，显著提高了自动驾驶汽车端到端转向角预测的计算机视觉模型精度。

**AI_Comments:** 这篇论文提出了一种实用的创新方法，通过利用车辆内部已有的CAN总线数据来增强计算机视觉模型的性能，避免了引入昂贵外部传感器（如LiDAR/雷达）的成本。这种方法对于自动驾驶技术的商业化落地具有重要意义，因为它提供了一个成本效益高的解决方案来提高预测精度。

<details>
  <summary>Details</summary>

**Motivation:** 当前自动驾驶汽车的端到端转向预测主要依赖计算机视觉模型，虽然通过融合LiDAR或雷达数据可以提高精度，但这会带来高昂的财务成本。本文旨在解决这一问题，即在不增加额外传感器成本的情况下，提高计算机视觉模型的预测精度。

**Method:** 作者通过将CAN总线数据（包括车辆的速度、转向角和加速度等状态信息）与视频数据进行传感器融合，以提高计算机视觉模型的精度。

**Result:** 实验结果显示，未融合CAN总线数据的模型RMSE为0.02492，而融合CAN总线数据的模型RMSE为0.01970。这表明将CAN总线数据与视频数据融合可以将计算机视觉模型的预测误差降低20%，部分模型甚至能将误差降低80%。

**Conclusion:** 将CAN总线数据与视频数据融合，能够有效降低自动驾驶汽车端到端转向角预测中计算机视觉模型的预测误差，是一种经济高效的精度提升方案。

> **ai_Abstract:** 本文提出一种经济高效的方法，通过将车辆的CAN总线数据（包含速度、转向角等状态信息）与视频数据融合，增强了自动驾驶汽车端到端转向角预测的计算机视觉模型。与昂贵的LiDAR/雷达传感器不同，这种方法在不增加成本的情况下显著提高了预测精度。实验结果表明，融合CAN总线数据可以将计算机视觉模型的预测误差降低20%至80%。

> **摘要翻译:** 近年来，自动驾驶汽车的端到端转向预测已成为一个主要研究领域。实现端到端转向的主要方法是利用视频数据的实时馈送进行计算机视觉模型预测。然而，为了进一步提高精度，许多公司通过传感器融合增加了来自激光雷达（LiDAR）和/或雷达传感器的数据。但激光和传感器的增加会带来高昂的财务成本。在本文中，我通过在不增加使用LiDAR和/或传感器成本的情况下提高计算机视觉模型的精度，解决了这两个问题。我通过将CAN总线数据（一种车辆协议）与视频数据进行传感器融合，从而提高了计算机视觉模型的精度。CAN总线数据是关于车辆状态的丰富信息来源，包括其速度、转向角和加速度。通过将这些数据与视频数据融合，可以提高计算机视觉模型预测的精度。当我未融合CAN总线数据训练模型时，获得的RMSE为0.02492，而融合CAN总线数据训练的模型实现了0.01970的RMSE。这一发现表明，将CAN总线数据与视频数据融合可以将计算机视觉模型的预测误差降低20%，部分模型甚至能将误差降低80%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [391] [EECD-Net: Energy-Efficient Crack Detection with Spiking Neural Networks and Gated Attention](https://arxiv.org/abs/2506.04526)
> *EECD-Net：基于脉冲神经网络和门控注意力的节能裂缝检测*

*Shuo Zhang* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 裂缝检测, 脉冲神经网络, 门控注意力, 节能, 超分辨率

**Comment:** After further careful review and additional checks, we have
  identified multiple issues in our experimental results and data analysis that
  significantly affect the validity and reliability of our findings. We believe
  that these issues are substantial enough to compromise the scientific
  integrity of the manuscript

> **TL;DR:** EECD-Net利用脉冲神经网络和门控注意力实现高精度、低能耗的路面裂缝检测，在CrackVision12K数据集上达到98.6%的准确率和5.6mJ的能耗。

**AI_Comments:** EECD-Net的创新之处在于其将SRCNN、SNN和GAT模块巧妙地结合起来，以同时解决图像质量、能耗和特征捕获的挑战。特别是引入脉冲神经网络来降低功耗，以及使用门控注意力Transformer来增强多尺度特征融合，是其亮点。这项工作对于推动边缘计算和物联网设备在基础设施监测领域的应用具有重要意义，提供了一个实用的低功耗高精度解决方案。其局限性可能在于脉冲神经网络的训练复杂性和对特定硬件平台优化的依赖性。

<details>
  <summary>Details</summary>

**Motivation:** 路面裂缝检测对于基础设施安全和交通可靠性至关重要。然而，智能终端设备由于能源有限和图像分辨率低，难以维持实时监测性能。

**Method:** 本文提出EECD-Net，一种多阶段检测方法。首先，使用超分辨率卷积神经网络（SRCNN）处理低质量图像，提升分辨率并保留细节。其次，引入带有连续积分放电（CIF）神经元的脉冲卷积单元（SCU），将图像转换为稀疏脉冲序列以降低功耗。最后，设计门控注意力Transformer（GAT）模块，通过自适应注意力机制融合多尺度特征表示，捕捉长距离依赖和局部裂缝模式，增强检测鲁棒性。

**Result:** 在CrackVision12K基准测试中，EECD-Net实现了98.6%的检测准确率，比现有最先进的Hybrid-Segmentor高出1.5%。能耗仅为5.6 mJ，比基线实现降低33%。

**Conclusion:** EECD-Net为基于仪器的裂缝检测提供了一种可扩展、低功耗的解决方案，适用于资源受限环境中的实时、大规模基础设施监测。

> **ai_Abstract:** 本文提出了EECD-Net，一种结合超分辨率卷积网络、脉冲神经网络和门控注意力Transformer的多阶段路面裂缝检测方法，旨在解决智能终端设备在低能耗和低分辨率图像下的实时监测挑战。该网络通过提升图像质量、降低功耗并增强特征融合，在CrackVision12K数据集上实现了98.6%的高精度和5.6mJ的低能耗，为资源受限环境下的基础设施监测提供了高效且可扩展的解决方案。

> **摘要翻译:** 路面裂缝检测是仪器仪表领域一项关键的测量技术，对于确保基础设施安全和交通可靠性至关重要。然而，由于能源有限和图像分辨率低，智能终端设备难以维持实时监测性能。为了克服这些挑战，本文提出了一种用于道路裂缝检测的多阶段检测方法EECD-Net，旨在提高仪器的准确性和能源效率。具体而言，采用复杂的超分辨率卷积神经网络（SRCNN）来解决低质量图像固有的挑战，有效提高图像分辨率同时保留关键结构细节。同时，提出了一种带有连续积分放电（CIF）神经元的脉冲卷积单元（SCU），将这些图像转换为稀疏脉冲序列，显著降低功耗。此外，设计了一个门控注意力Transformer（GAT）模块，通过自适应注意力机制策略性地融合多尺度特征表示，有效捕捉长距离依赖和复杂的局部裂缝模式，并显著增强不同裂缝形态下的检测鲁棒性。在CrackVision12K基准测试上的实验表明，EECD-Net实现了98.6%的卓越检测准确率，比现有最先进的Hybrid-Segmentor高出1.5%。值得注意的是，EECD-Net保持了卓越的能源效率，仅消耗5.6毫焦耳，比基线实现显著降低了33%。这项工作开创了一种基于仪器裂缝检测的变革性方法，为资源受限环境中的实时、大规模基础设施监测提供了一种可扩展的低功耗解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [412] [Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with Regularized Score Distillation Sampling](https://arxiv.org/abs/2507.11061)
> *基于正则化分数蒸馏采样的3D高斯溅射中鲁棒的3D掩码部分级编辑*

*Hayeon Kim, Ji Ha Jang, Se Young Chun* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 3D高斯溅射, 局部编辑, 3D掩码, 分数蒸馏采样, 3D-GALP

**Comment:** 

> **TL;DR:** RoMaP提出了一种鲁棒的3D掩码部分级编辑框架，通过3D-GALP生成一致的3D掩码，并结合正则化的SDS损失实现精确的局部3D编辑。

**AI_Comments:** 该论文通过引入创新的3D-GALP模块来生成一致的3D掩码，并结合了正则化的SDS损失，特别是L1锚点损失和高斯先验去除，有效地解决了3D高斯溅射中局部编辑的挑战。其创新性在于提出了结合几何感知标签预测和改进损失函数的方法，使得部分级编辑更为精确和鲁棒，具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在3D高斯溅射中实现精确的局部3D编辑仍然具有挑战性，主要原因是多视角2D部分分割不一致以及分数蒸馏采样（SDS）损失固有的模糊性。

**Method:** 本文提出了RoMaP框架。首先，引入了一个鲁棒的3D掩码生成模块，其中包含3D-Geometry Aware Label Prediction (3D-GALP)，它利用球谐函数(SH)系数来建模视角相关的标签变化和软标签特性，从而在不同视角下生成准确且一致的部分分割。其次，提出了一个正则化的SDS损失，该损失结合了标准SDS损失和额外的正则化器，特别是通过Scheduled Latent Mixing and Part (SLaMP)编辑方法引入了L1锚点损失，用于生成高质量的部分编辑2D图像并将修改限制在目标区域，同时保持上下文连贯性。额外的正则化器，如高斯先验去除，进一步提高了灵活性，并防止了意外编辑。

**Result:** 实验结果表明，RoMaP在重建和生成的高斯场景和物体上均实现了最先进的局部3D编辑，无论是在定性还是定量方面。

**Conclusion:** RoMaP框架通过结合鲁棒的3D掩码生成和正则化的分数蒸馏采样，实现了更鲁棒和灵活的部分级3D高斯编辑。

> **ai_Abstract:** 本文提出了RoMaP，一个用于3D高斯溅射的局部3D编辑框架，旨在解决现有方法中多视角分割不一致和SDS损失模糊性的挑战。RoMaP通过引入3D-Geometry Aware Label Prediction (3D-GALP)模块生成鲁棒且一致的3D掩码，并结合正则化的分数蒸馏采样(SDS)损失，其中包含L1锚点损失和高斯先验去除等正则化器，以实现精确且灵活的部分级3D编辑。实验证明RoMaP在3D高斯场景和物体上的局部编辑方面达到了最先进的性能。

> **摘要翻译:** 最近3D神经表示和实例级编辑模型的进展使得高效创建高质量3D内容成为可能。然而，实现精确的局部3D编辑仍然具有挑战性，特别是对于高斯溅射而言，这是由于不一致的多视角2D部分分割以及分数蒸馏采样（SDS）损失固有的模糊性。为了解决这些限制，我们提出了RoMaP，一个新颖的局部3D高斯编辑框架，能够实现精确和大幅度的部分级修改。首先，我们引入了一个鲁棒的3D掩码生成模块，其中包含我们的3D-Geometry Aware Label Prediction (3D-GALP)，它使用球谐函数（SH）系数来建模视角相关的标签变化和软标签特性，从而在不同视角下生成准确且一致的部分分割。其次，我们提出了一个正则化的SDS损失，该损失结合了标准SDS损失和额外的正则化器。特别是，通过我们的Scheduled Latent Mixing and Part (SLaMP)编辑方法引入了L1锚点损失，该方法生成高质量的部分编辑2D图像，并将修改仅限于目标区域，同时保持上下文连贯性。额外正则化器，如高斯先验去除，通过允许超出现有上下文的更改，进一步提高了灵活性，并且鲁棒的3D掩码防止了意外编辑。实验结果表明，我们的RoMaP在重建和生成的高斯场景和物体上均实现了最先进的局部3D编辑，无论是在定性还是定量方面，从而实现了更鲁棒和灵活的部分级3D高斯编辑。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [413] [ViewSRD: 3D Visual Grounding via Structured Multi-View Decomposition](https://arxiv.org/abs/2507.11261)
> *ViewSRD：通过结构化多视图分解实现3D视觉定位*

*Ronggang Huang, Haoxin Yang, Yan Cai, Xuemiao Xu, Huaidong Zhang, Shengfeng He* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 3D视觉定位, 多视图分解, 文本-场景交互, 空间推理, 复杂查询

**Comment:** Accepted by ICCV 2025

> **TL;DR:** ViewSRD是一个新的框架，通过将复杂查询分解为简单的单锚点语句并整合多视图信息来解决3D视觉定位中复杂多锚点查询和透视变化引起的空间描述不一致问题，显著优于现有SOTA方法。

**AI_Comments:** ViewSRD的创新之处在于其将复杂3D视觉定位问题分解为结构化多视图处理的思路。通过SRD模块对文本查询进行解耦，以及Multi-TSI模块对多视图特征的跨模态整合，有效解决了现有方法在处理复杂空间关系和透视变形时的局限性。其性能提升，尤其是在复杂查询上的表现，显示了该方法的实用价值和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D视觉定位方法在处理复杂的多锚点查询时，难以将目标从锚点中解耦，并且无法解决由透视变化引起的空间描述不一致性问题。

**Method:** 本文提出了ViewSRD框架，将3D视觉定位公式化为结构化多视图分解过程。首先，简单关系解耦（SRD）模块将复杂的多锚点查询重构为一系列有针对性的单锚点语句，生成结构化的、透视感知的描述。其次，多视图文本-场景交互（Multi-TSI）模块利用共享的跨模态一致视图令牌（CCVT）整合多视点下的文本和场景特征，以保持空间相关性。最后，文本-场景推理模块将多视图预测合成为统一且鲁棒的3D视觉定位。

**Result:** 在3D视觉定位数据集上的实验表明，ViewSRD显著优于现有最先进的方法，尤其是在需要精确空间区分的复杂查询中表现突出。

**Conclusion:** ViewSRD通过其结构化多视图分解方法，有效解决了3D视觉定位中的复杂多锚点查询和透视不一致问题，实现了优越的性能。

> **ai_Abstract:** 本文提出了ViewSRD，一个用于3D视觉定位的新框架，旨在解决现有方法在复杂多锚点查询中目标解耦困难以及透视变化导致的空间描述不一致问题。ViewSRD通过将复杂查询分解为简单的单锚点语句（SRD模块）生成透视感知描述，并利用多视图文本-场景交互（Multi-TSI模块）整合多视点特征，最终通过文本-场景推理模块实现统一的3D定位。实验证明，ViewSRD在3D视觉定位任务上，尤其是在复杂查询中，显著超越了现有SOTA方法。

> **摘要翻译:** 3D视觉定位旨在根据文本描述在3D空间中识别和定位物体。然而，现有方法在复杂的多锚点查询中难以将目标从锚点中解耦，并且无法解决由透视变化引起的空间描述不一致性问题。为了应对这些挑战，我们提出了ViewSRD，一个将3D视觉定位公式化为结构化多视图分解过程的框架。首先，简单关系解耦（SRD）模块将复杂的多锚点查询重构为一系列有针对性的单锚点语句，生成结构化的、透视感知的描述，从而明确位置关系。这些分解后的表示作为多视图文本-场景交互（Multi-TSI）模块的基础，该模块使用共享的跨模态一致视图令牌（CCVT）在多个视点之间整合文本和场景特征，以保持空间相关性。最后，文本-场景推理模块将多视图预测合成为统一且鲁棒的3D视觉定位。在3D视觉定位数据集上的实验表明，ViewSRD显著优于现有最先进的方法，尤其是在需要精确空间区分的复杂查询中表现突出。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [415] [MARL-MambaContour: Unleashing Multi-Agent Deep Reinforcement Learning for Active Contour Optimization in Medical Image Segmentation](https://arxiv.org/abs/2506.18679)
> *MARL-MambaContour：释放多智能体深度强化学习用于医学图像分割中的主动轮廓优化*

*Ruicheng Zhang, Yu Sun, Zeyu Zhang, Jinai Li, Xiaofan Liu, Au Hoi Fan, Haowei Guo, Puxin Yan* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 多智能体强化学习, 医学图像分割, 主动轮廓, Mamba, 深度强化学习

**Comment:** 

> **TL;DR:** MARL-MambaContour是一个基于多智能体强化学习（MARL）的新型主动轮廓医学图像分割框架，它将分割重新定义为多智能体协作任务，旨在生成拓扑一致的对象级轮廓，并能适应模糊边缘和复杂形态。

**AI_Comments:** 该论文的创新之处在于首次将多智能体强化学习应用于轮廓医学图像分割，提供了一种新的范式来解决传统方法的拓扑一致性问题。其引入的基于Mamba的策略网络与双向交叉注意力隐藏状态融合机制（BCHFM）是关键的技术突破，有效改善了智能体间的长程信息交互。该方法对于处理医学图像中常见的模糊边缘和复杂形态具有重要意义，有望提升临床分割的准确性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 传统基于像素的医学图像分割方法缺乏拓扑约束和解剖区域的整体结构感知能力。本研究的动机是开发一种能够生成拓扑一致的对象级轮廓，并能适应医学图像中常见模糊边缘和复杂形态的分割方法。

**Method:** 该论文引入了MARL-MambaContour，这是首个基于多智能体强化学习（MARL）的轮廓医学图像分割框架。它将每个轮廓点建模为自主智能体，通过迭代调整位置来精确对齐目标边界。这一调整过程由一个针对轮廓的软演员-评论家（SAC）算法优化，并通过熵正则化调整机制（ERAM）进行增强，以动态平衡智能体探索与轮廓平滑度。此外，该框架整合了一个基于Mamba的策略网络，其特点是新颖的双向交叉注意力隐藏状态融合机制（BCHFM），以减轻长程建模中的记忆混淆并促进智能体间信息交换。

**Result:** 在五个不同的医学成像数据集上进行了广泛的实验，结果表明MARL-MambaContour达到了最先进的性能。

**Conclusion:** MARL-MambaContour在医学图像分割中表现出最先进的性能，突出了其作为精确和鲁棒临床应用的巨大潜力。

> **ai_Abstract:** MARL-MambaContour是一种新颖的基于多智能体强化学习（MARL）的医学图像分割框架。它将轮廓点建模为自主智能体，通过协作迭代调整位置来形成拓扑一致的边界，从而克服了传统基于像素方法的局限性。该框架采用了一种针对轮廓的SAC算法，并结合ERAM来平衡探索与平滑度；同时，它还引入了一个基于Mamba的策略网络，其中包含BCHFM，以改善智能体间的信息交换。在多个医学数据集上的广泛实验表明，MARL-MambaContour达到了最先进的性能，展现了其在临床应用中的巨大潜力。

> **摘要翻译:** 我们引入了MARL-MambaContour，这是首个基于多智能体强化学习（MARL）的轮廓医学图像分割框架。我们的方法将分割重新定义为一个多智能体协作任务，专注于生成拓扑一致的对象级轮廓，解决了传统基于像素的方法可能缺乏拓扑约束和解剖区域整体结构意识的局限性。每个轮廓点都被建模为一个自主智能体，迭代地调整其位置以精确对齐目标边界，从而能够适应医学图像中常见的模糊边缘和复杂形态。这种迭代调整过程通过一种针对轮廓的软演员-评论家（SAC）算法进行优化，并进一步通过熵正则化调整机制（ERAM）进行增强，该机制动态平衡智能体探索与轮廓平滑度。此外，该框架还包含一个基于Mamba的策略网络，其特点是新颖的双向交叉注意力隐藏状态融合机制（BCHFM）。该机制减轻了与状态空间模型中长程建模相关的潜在记忆混淆限制，从而促进了更准确的智能体间信息交换和明智的决策。在五个不同的医学成像数据集上进行的广泛实验证明了MARL-MambaContour的先进性能，突出了其作为精确和鲁棒临床应用的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [420] [Roadside Monocular 3D Detection Prompted by 2D Detection](https://arxiv.org/abs/2404.01064)
> *路边单目3D检测由2D检测提示*

*Yechi Ma, Yanan Li, Wei Hua, Shu Kong* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 路边单目3D检测, 2D检测, 提示学习, Pro3D, 鸟瞰图

**Comment:** 

> **TL;DR:** 本文提出Pro3D，一种利用2D检测作为提示的新型路边单目3D检测器，显著提升了检测性能并在两个基准上达到SOTA。

**AI_Comments:** Pro3D的创新之处在于其巧妙地利用了2D检测的优势来弥补单目3D检测的挑战。通过将2D检测作为“提示”，它简化了3D检测器的任务，使其能够更专注于深度和3D属性的估计。这种模块化且可插拔的设计使其能与现有多种2D和3D检测器兼容，展现了良好的通用性和实际应用潜力。其性能提升也证明了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 路边单目3D检测在交通控制、车车通信和车路协同感知等领域有广泛应用，但现有3D检测器在训练难度和2D定位精度上存在挑战。

**Method:** 本文引入了Promptable 3D Detector (Pro3D)，其核心在于利用2D检测作为3D检测的提示。Pro3D基于两个洞察：2D检测器更容易训练且2D定位表现更好；一旦2D检测精确定位物体，3D检测器可以专注于将其提升到3D BEV。为整合2D检测，研究了三种方法：特征拼接、注意力融合2D和3D特征、以及编码2D边界框属性（x, y, 宽度, 高度, 标签）并与3D特征进行注意力融合。实验表明第三种方法效果最佳。

**Result:** Pro3D显著增强了现有方法，并在两个当代基准上取得了最先进的结果。

**Conclusion:** 2D检测作为精确物体目标的提示，能有效引导3D检测器专注于将目标提升到3D空间，从而显著提升路边单目3D检测的性能。

> **ai_Abstract:** 本文提出了一种名为Pro3D的新型路边单目3D检测器，其核心思想是利用2D检测作为提示来辅助3D检测。该方法基于2D检测在定位上的优势，使3D检测器能更高效地专注于将2D检测结果提升至3D BEV空间。Pro3D探索了多种2D特征与3D特征的融合策略，其中通过编码2D边界框属性并进行注意力融合的方式效果最佳。实验证明，Pro3D显著提升了现有方法的性能，并在两个主流基准测试中达到了最先进的水平。

> **摘要翻译:** 路边单目3D检测需要在RGB帧中检测预定义类别的物体并预测其3D属性，例如鸟瞰图（BEV）位置。它在交通控制、车车通信和车路协同感知中具有广泛应用。为了解决这项任务，我们引入了可提示3D检测器（Pro3D），这是一种新颖的检测器设计，它利用2D检测作为提示。我们的Pro3D建立在两个关键洞察之上。首先，与典型的3D检测器相比，2D检测器由于损失项更少而“更容易”训练，并且在2D指标方面对物体定位的性能显著更好。其次，一旦2D检测在图像中精确地定位了物体，3D检测器就可以专注于将这些检测提升到3D BEV，特别是当固定的相机姿态或场景几何提供了信息丰富的先验时。为了编码和整合2D检测，我们探索了三种方法：（a）拼接来自2D和3D检测器的特征，（b）注意力融合2D和3D检测器特征，以及（c）编码预测的2D边界框属性{x，y，宽度，高度，标签}并将其与3D检测器特征进行注意力融合。有趣的是，第三种方法显著优于其他方法，这突显了2D检测作为提示的有效性，它提供了精确的物体目标，并允许3D检测器专注于将其提升到3D。Pro3D可以适应与各种2D和3D检测器配合使用，只需进行最小的修改。综合实验表明，我们的Pro3D显著增强了现有方法，在两个当代基准上取得了最先进的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [423] [GeoDistill: Geometry-Guided Self-Distillation for Weakly Supervised Cross-View Localization](https://arxiv.org/abs/2507.10935)
> *GeoDistill：几何引导的弱监督跨视角定位自蒸馏*

*Shaowen Tong, Zimin Xia, Alexandre Alahi, Xuming He, Yujiao Shi* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 跨视角定位, 自蒸馏, 弱监督, 几何引导, 姿态估计

**Comment:** accepted by ICCV2025

> **TL;DR:** GeoDistill提出了一种几何引导的弱监督自蒸馏框架，用于跨视角定位。它利用教师-学生学习模型和基于视场（FoV）的掩蔽，以增强局部特征学习，从而提高定位精度并降低不确定性，优于现有方法。

**AI_Comments:** 该论文通过引入GeoDistill，一种创新的自蒸馏方法，巧妙地解决了跨视角定位中数据标注成本高昂的挑战。其利用几何引导的教师-学生学习和基于视场的掩蔽来增强局部特征学习，使模型对不同输入视图具有鲁棒性，这一点尤为出色。弱监督的特性显著提升了方法的可扩展性。此外，新颖的姿态估计网络进一步减少了对精确真值的依赖，是该研究的另一大亮点。

<details>
  <summary>Details</summary>

**Motivation:** 现有跨视角定位方法通常依赖于需要昂贵真值姿态标注的完全监督学习。为了解决大规模户外应用（如自主导航和增强现实）中跨视角定位的挑战，需要一个可扩展且高效的解决方案。

**Method:** 本文提出了GeoDistill，一个几何引导的弱监督自蒸馏框架。该框架采用教师-学生学习模式，并结合基于视场（FoV）的掩蔽来增强局部特征学习。教师模型负责定位全景图像，而学生模型则从通过FoV掩蔽创建的有限FoV对应图像中预测位置。通过将学生的预测与教师的预测对齐，学生模型能够专注于关键特征（如车道线），并忽略无纹理区域（如道路）。此外，该研究还引入了一个新颖的姿态估计网络，无需精确的平面位置真值即可预测相对姿态。

**Result:** GeoDistill显著提高了不同框架下的定位性能。它带来了更准确的预测并降低了不确定性，无论是查询图像是全景图像还是有限FoV图像。新引入的姿态估计网络能够在不需要精确平面位置真值的情况下预测相对姿态。

**Conclusion:** GeoDistill为现实世界的跨视角定位挑战提供了一个可扩展且高效的解决方案，通过弱监督显著提高了定位精度和鲁棒性。

> **ai_Abstract:** GeoDistill是一种针对跨视角定位的几何引导弱监督自蒸馏框架，旨在解决现有方法对昂贵真值姿态标注的依赖。该框架采用教师-学生学习范式，教师模型处理全景图像，而学生模型通过基于视场的掩蔽从有限视场图像中学习，从而将注意力集中在关键特征上，忽略非关键区域。这种方法显著提高了定位精度并降低了不确定性，适用于全景和有限视场查询图像。实验证明GeoDistill能显著提升定位性能，并且引入了一个无需精确平面位置真值即可预测相对姿态的新型网络，为实际应用提供了可扩展且高效的解决方案。

> **摘要翻译:** 跨视角定位，即通过将地面图像与卫星图像对齐来估计摄像机的3自由度（3-DoF）姿态，对于自主导航和增强现实等大规模户外应用至关重要。现有方法通常依赖于完全监督学习，这需要昂贵的真值姿态标注。在这项工作中，我们提出了GeoDistill，一个几何引导的弱监督自蒸馏框架，它使用基于视场（FoV）的掩蔽的教师-学生学习来增强局部特征学习，从而实现鲁棒的跨视角定位。在GeoDistill中，教师模型定位全景图像，而学生模型从通过FoV掩蔽创建的有限FoV对应图像中预测位置。通过将学生的预测与教师的预测对齐，学生专注于关键特征（如车道线）并忽略无纹理区域（如道路）。这导致了更准确的预测和更低的不确定性，无论查询图像是全景图像还是有限FoV图像。我们的实验表明，GeoDistill显著提高了不同框架下的定位性能。此外，我们引入了一个新颖的姿态估计网络，无需精确的平面位置真值即可预测相对姿态。GeoDistill为现实世界的跨视角定位挑战提供了可扩展且高效的解决方案。代码和模型可在https://github.com/tongshw/GeoDistill找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [439] [Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement](https://arxiv.org/abs/2506.20254)
> *随处识别手术阶段：小样本测试时自适应与任务图引导的细化*

*Kun Yuan, Tingxuan Chen, Shi Li, Joel L. Lavanchy, Christian Heiliger, Ege Özsoy, Yiming Huang, Long Bai, Nassir Navab, Vinkle Srivastav, Hongliang Ren, Nicolas Padoy* | **Category: cs.CV** | **Updated: 2025-07-14**

**Keywords:** 手术阶段识别, 小样本学习, 测试时自适应, 任务图, 领域适应

**Comment:** Accepted by MICCAI 2025

> **TL;DR:** 提出SPA框架，通过小样本自适应和任务图引导，使手术基础模型能在不同机构和手术中实现高精度手术阶段识别，即使只有少量标注数据。

**AI_Comments:** SPA框架的创新点在于其结合了小样本学习、任务图引导和测试时自适应，有效解决了手术领域特有的数据稀缺和领域漂移问题。其轻量级和快速定制的特性对于医疗机构具有很高的实用价值。超越全样本模型的性能尤其令人印象深刻，表明其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有手术基础模型在跨机构和跨手术场景中泛化能力受限，零样本性能因领域漂移而受影响，难以在未见过的手术环境中有效应用。需要一个能够适应不同机构设置且仅需少量标注的模型。

**Method:** 本文提出了Surgical Phase Anywhere (SPA) 框架，旨在解决手术基础模型在不同机构和手术场景中泛化能力受限的问题。SPA通过小样本空间自适应将多模态嵌入与机构特定的手术场景和阶段对齐；通过扩散建模结合任务图先验来确保时间一致性；并采用动态测试时自适应，利用多模态预测流的相互一致性，以自监督方式使模型适应测试视频。该框架轻量级，允许医院通过自然语言文本定义阶段、少量图像标注和提供任务图来快速定制模型。

**Result:** SPA框架在多个机构和程序的小样本手术阶段识别中实现了最先进的性能，甚至在32样本标注数据下超越了全样本模型。

**Conclusion:** SPA是一个轻量级的自适应框架，能够使手术阶段识别模型快速定制，并在小样本设置下实现卓越的跨机构和跨手术泛化能力。

> **ai_Abstract:** 本文提出了Surgical Phase Anywhere (SPA) 框架，旨在解决手术基础模型在不同机构和手术场景中泛化能力受限的问题。SPA通过小样本空间自适应、基于任务图先验的扩散建模以及动态测试时自适应，使模型能够利用少量标注数据快速适应新的手术环境。实验证明，SPA在小样本手术阶段识别任务上达到了最先进的性能，甚至超越了使用更多标注的全样本模型，为跨机构手术工作流程理解提供了高效且可定制的解决方案。

> **摘要翻译:** 手术工作流程的复杂性和多样性，源于异构手术室设置、机构协议和解剖变异性，对开发可泛化模型以实现跨机构和跨程序的手术理解提出了重大挑战。尽管最近在大规模视觉语言数据上预训练的手术基础模型提供了有前景的可迁移性，但它们的零样本性能仍受领域偏移的限制，从而限制了它们在未见过的手术环境中的实用性。为解决此问题，我们引入了Surgical Phase Anywhere (SPA)，一个用于通用手术工作流程理解的轻量级框架，它以最少的标注将基础模型适应于机构设置。SPA利用小样本空间自适应将多模态嵌入与机构特定的手术场景和阶段对齐。它还通过扩散建模确保时间一致性，该模型编码了源自机构程序协议的任务图先验。最后，SPA采用动态测试时自适应，利用多模态阶段预测流之间的相互一致性，以自监督方式使模型适应给定的测试视频，从而增强在测试时分布偏移下的可靠性。SPA是一个轻量级自适应框架，允许医院通过自然语言文本定义阶段、用阶段标签标注少量图像以及提供定义阶段转换的任务图来快速定制阶段识别模型。实验结果表明，SPA框架在多个机构和程序的小样本手术阶段识别中实现了最先进的性能，甚至在32样本标注数据下超越了全样本模型。代码可在 https://github.com/CAMMA-public/SPA 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [449] [YOLOatr : Deep Learning Based Automatic Target Detection and Localization in Thermal Infrared Imagery](https://arxiv.org/abs/2507.11267)
> *YOLOatr：基于深度学习的热红外图像自动目标检测与定位*

*Aon Safdar, Usman Akram, Waseem Anwar, Basit Malik, Mian Ibad Ali* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 自动目标检测, 热红外图像, 深度学习, YOLO, 目标识别

**Comment:** Published in 25th Irish Machine Vision and Image Processing Conf.,
  Galway, Ireland, Aug 30-Sep 1 2023 Also available at
  https://doi.org/10.5281/zenodo.8264062

> **TL;DR:** 针对热红外图像中自动目标检测和识别的挑战，本文提出了一种改进的YOLOv5s模型YOLOatr，并在DSIAC MWIR数据集上实现了最先进的性能。

**AI_Comments:** 本文通过对YOLOv5s进行定制化修改，针对热红外图像中ATR的独特挑战（如数据集限制、尺度不变性、遮挡和环境变化）提出了有效的解决方案。其创新点在于结合了YOLOv5的效率与针对TI模态的优化，实现了SOTA性能，对于国防和监控领域的实时目标检测具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动目标检测（ATD）和识别（ATR）在国防和监控领域的热红外（TI）图像中是一项具有挑战性的计算机视觉任务，相比商业自动驾驶领域更难。主要挑战包括数据集有限、硬件限制、距离导致的尺度不变性问题、战术车辆的故意遮挡、传感器分辨率低导致目标结构信息缺乏、天气、温度和时间变化的影响，以及目标与杂波比的变化，这些都导致类内变异性增加和类间相似性更高，使得准确的实时ATR成为一项挑战。因此，当前的SOTA深度学习架构在该领域表现不佳。

**Method:** 提出了一种名为YOLOatr的改进型锚点式单阶段检测器，其基于改进的YOLOv5s模型。具体修改包括：对检测头进行优化修改，在颈部进行特征融合，并采用自定义的数据增强配置文件。

**Result:** 该模型在DSIAC MWIR数据集上，在相关和非相关测试协议下，实现了高达99.6%的最先进的ATR性能。

**Conclusion:** YOLOatr在热红外图像自动目标检测和识别任务中表现出色，达到了最先进的水平，有效解决了该领域面临的挑战。

> **ai_Abstract:** 本文提出了一种名为YOLOatr的深度学习模型，旨在解决热红外图像中自动目标检测和识别（ATR）所面临的挑战。该模型是基于YOLOv5s进行修改的单阶段检测器，通过优化检测头、特征融合和自定义数据增强来提高性能。在DSIAC MWIR数据集上的评估显示，YOLOatr在实时ATR任务中取得了高达99.6%的最先进性能，证明了其在国防和监控领域应用的有效性。

> **摘要翻译:** 自动目标检测（ATD）和识别（ATR）在国防和监控领域的热红外（TI）图像中是一项具有挑战性的计算机视觉（CV）任务，相比商业自动驾驶感知领域更具挑战性。有限的数据集、独特的领域特定和TI模态特定挑战，即有限的硬件、由于距离较大导致的尺度不变性问题、战术车辆的故意遮挡、较低的传感器分辨率和由此导致的目标结构信息缺乏、天气、温度和时间变化的影响，以及目标与杂波比的变化，所有这些都导致类内变异性增加和类间相似性更高，使得准确的实时ATR成为一项挑战性的CV任务。因此，当前的SOTA深度学习架构在ATR领域表现不佳。我们提出了一种改进的基于锚点的单阶段检测器，称为YOLOatr，其基于改进的YOLOv5s，对检测头、颈部的特征融合以及自定义增强配置文件进行了优化修改。我们在全面的DSIAC MWIR数据集上评估了我们提出的模型在相关和非相关测试协议下的实时ATR性能。结果表明，我们提出的模型实现了高达99.6%的最先进的ATR性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [460] [Joint angle model based learning to refine kinematic human pose estimation](https://arxiv.org/abs/2507.11075)
> *基于关节角度模型的学习方法，用于优化运动人体姿态估计*

*Chang Peng, Yifei Zhou, Huifeng Xi, Shiqing Huang, Chuangye Chen, Jianming Yang, Bao Yang, Zhenyu Jiang* | **Category: cs.CV, cs.AI, I.4.9; I.5.4; J.3** | **Updated: 2025-07-15**

**Keywords:** 人体姿态估计, 关节角度模型, 运动姿态, 深度学习, 姿态优化

**Comment:** 

> **TL;DR:** 本文提出一种基于关节角度建模的新方法，结合傅里叶级数生成高质量训练数据，并利用双向循环网络优化人体姿态估计，在运动场景下表现优于现有技术。

**AI_Comments:** 本文的创新点在于利用关节角度进行鲁棒的姿态描述，并通过傅里叶级数生成高质量的合成真值数据，有效解决了手动标注数据集不准确的局限性。将此方法与双向循环网络结合进行优化，进一步提升了其在复杂运动场景下的实用性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 当前无标记人体姿态估计（HPE）在关键点识别和轨迹波动方面存在误差，尤其在分析运动姿态时。此外，现有深度学习HPE优化模型受限于不准确的手动标注训练数据集。

**Method:** 提出一种基于关节角度的人体姿态模型，以鲁棒地描述运动姿态；通过高阶傅里叶级数近似关节角度的时间变化，以获得可靠的“真值”数据；设计一个双向循环网络作为后处理模块，用于优化HRNet的估计结果。

**Result:** 该网络在高质量数据集上训练后，在纠正错误识别的关节和平滑其时空轨迹方面表现出色。测试表明，基于关节角度的优化（JAR）在花样滑冰和霹雳舞等挑战性场景中，性能优于最先进的HPE优化网络。

**Conclusion:** 基于关节角度的优化方法能有效纠正错误识别的关节并平滑其时空轨迹，在运动人体姿态估计的优化方面表现出优越性，并超越了现有最先进的HPE优化网络。

> **ai_Abstract:** 本文提出一种新颖的基于关节角度建模的方法，以解决无标记人体姿态估计（HPE）中关键点识别错误和轨迹波动的问题，尤其是在运动姿态分析中。该方法通过高阶傅里叶级数近似关节角度的时间变化来生成高质量的“真值”训练数据，并设计了一个双向循环网络作为后处理模块来优化姿态估计。实验结果表明，该联合角度优化（JAR）方法在纠正错误识别的关节和平滑时空轨迹方面表现出色，并在花样滑冰和霹雳舞等挑战性场景中，性能优于当前最先进的HPE优化网络。

> **摘要翻译:** 无标记人体姿态估计（HPE）已在各个领域得到日益广泛的应用。当前HPE在分析运动人体姿态时，存在关键点识别偶尔出错和关键点轨迹随机波动的问题。现有基于深度学习的HPE优化模型的性能，因手动标注的关键点训练数据集不准确而受到很大限制。本文提出一种通过基于关节角度建模来克服这些困难的新方法。关键技术包括：(i) 一个基于关节角度的人体姿态模型，该模型能鲁棒地描述运动人体姿态；(ii) 通过高阶傅里叶级数近似关节角度的时间变化，以获得可靠的“真值”；(iii) 设计一个双向循环网络作为后处理模块，用于优化已建立的HRNet的估计结果。该网络使用我们方法构建的高质量数据集进行训练后，在纠正错误识别的关节和平滑其时空轨迹方面表现出卓越的性能。测试表明，基于关节角度的优化（JAR）在花样滑冰和霹雳舞等挑战性案例中，性能优于最先进的HPE优化网络。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [462] [A Comprehensive Library for Benchmarking Multi-class Visual Anomaly Detection](https://arxiv.org/abs/2406.03262)
> *一个用于基准测试多类别视觉异常检测的综合库*

*Jiangning Zhang, Haoyang He, Zhenye Gan, Qingdong He, Yuxuan Cai, Zhucun Xue, Yabiao Wang, Chengjie Wang, Lei Xie, Yong Liu* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 视觉异常检测, 基准测试, 多类别, 深度学习, 评估库

**Comment:** 

> **TL;DR:** 该论文提出了ADer，一个用于多类别视觉异常检测的综合基准库，包含多种方法、数据集、指标以及一个快速评估包（ADEval），旨在标准化评估并揭示方法性能。

**AI_Comments:** 该论文通过提供一个全面且标准化的基准，解决了视觉异常检测领域的一个关键需求。其模块化设计确保了可扩展性，而ADEval的引入显著提高了评估效率，这是一项重要的实际贡献。这项工作对于促进公平比较和指导该领域的未来研究至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 在实际的多类别设置下，缺乏全面的基准来充分评估各种主流视觉异常检测方法在不同数据集上的性能，导致潜在的偏差和错误的结论。

**Method:** 本文提出了ADer，一个模块化且高度可扩展的视觉异常检测综合基准。它包含了来自工业和医疗领域的多个数据集，实现了十五种最先进的方法和九种综合指标。此外，还提出了GPU加速的ADEval包，以解决在大规模数据上耗时的度量（如mAU-PRO）评估缓慢的问题，显著缩短了1000倍以上的评估时间。

**Result:** 通过广泛的实验结果，客观地揭示了不同方法的优缺点，并提供了对多类别视觉异常检测挑战和未来方向的见解。

**Conclusion:** ADer旨在成为该领域研究人员和从业者的宝贵资源，促进开发更强大和更具泛化能力的异常检测系统。

> **ai_Abstract:** 本文介绍了ADer，一个全面、模块化且可扩展的多类别视觉异常检测基准库。它通过整合多样的数据集、十五种最先进的方法和九种指标，解决了标准化评估的不足。同时，还提出了一个创新的GPU加速ADEval包，以大幅加速指标评估。通过使用ADer进行的广泛实验揭示了各种方法的性能特征，为该领域的挑战和未来方向提供了见解。作者希望ADer能成为推动鲁棒异常检测系统发展的关键资源。

> **摘要翻译:** 视觉异常检测旨在通过无监督学习范式识别图像中的异常区域，在工业检测和医疗病灶检测等领域具有日益增长的应用需求和价值。尽管近年来取得了显著进展，但在实际的多类别设置下，缺乏全面的基准来充分评估各种主流方法在不同数据集上的性能。缺乏标准化的实验设置可能导致训练周期、分辨率和度量结果的潜在偏差，从而得出错误的结论。本文通过提出一个全面的视觉异常检测基准ADer来解决这个问题，ADer是一个模块化框架，对新方法具有高度可扩展性。该基准包括来自工业和医疗领域的多个数据集，实现了十五种最先进的方法和九种综合度量。此外，我们提出了GPU加速的ADEval包，以解决在大规模数据上耗时的mAU-PRO等度量评估缓慢的问题，将评估时间显著缩短了1000倍以上。通过大量的实验结果，我们客观地揭示了不同方法的优缺点，并提供了对多类别视觉异常检测挑战和未来方向的见解。我们希望ADer将成为该领域研究人员和从业者的宝贵资源，促进开发更强大和更具泛化能力的异常检测系统。完整代码已在https://github.com/zhangzjn/ader开源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [463] [FA-Seg: A Fast and Accurate Diffusion-Based Method for Open-Vocabulary Segmentation](https://arxiv.org/abs/2506.23323)
> *FA-Seg：一种快速准确的基于扩散的开放词汇分割方法*

*Quang-Huy Che, Vinh-Tiep Nguyen* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 开放词汇分割, 扩散模型, 免训练, 语义分割, 效率

**Comment:** 

> **TL;DR:** FA-Seg是一种快速准确的免训练扩散模型，用于开放词汇分割，通过(1+1)步和三个关键组件（双提示、HARD、TTF）实现SOTA性能和高效率。

**AI_Comments:** FA-Seg的创新之处在于它将扩散模型应用于开放词汇分割，并提出了一种高效的(1+1)步免训练框架。通过引入双提示、HARD和TTF等组件，它成功解决了扩散模型在计算成本与分割质量之间的平衡问题，并提升了像素级精度和空间一致性。其免训练和高效率的特性使其在实际应用中具有重要潜力，特别是对于需要快速处理大量未标注数据的场景。

<details>
  <summary>Details</summary>

**Motivation:** 现有的对比学习模型在开放词汇语义分割中由于全局表示偏差，像素级空间精度不足。而基于扩散的模型虽然能编码细粒度空间特征，但面临计算成本与分割质量平衡的挑战。

**Method:** FA-Seg是一种免训练的基于扩散模型的开放词汇分割框架。它仅使用预训练扩散模型的(1+1)步进行分割，并能一次性处理所有类别。为提高分割质量，FA-Seg引入了三个关键组件：(i) 双提示机制，用于提取判别性、类别感知的注意力；(ii) 分层注意力细化方法（HARD），通过多分辨率注意力融合增强语义精度；(iii) 测试时翻转（TTF）方案，旨在提高空间一致性。

**Result:** FA-Seg在PASCAL VOC、PASCAL Context和COCO Object基准测试中实现了43.8%的平均mIoU，达到了最先进的免训练性能，同时保持了卓越的推理效率。

**Conclusion:** FA-Seg为可扩展性奠定了坚实基础，弥合了分割质量和推理效率之间的差距。

> **ai_Abstract:** FA-Seg是一种创新的、快速准确的免训练开放词汇语义分割方法，它基于扩散模型，通过仅(1+1)步推理实现高效分割。该方法通过引入双提示机制、分层注意力细化方法（HARD）和测试时翻转（TTF）方案，显著提升了分割质量和空间一致性。实验证明，FA-Seg在多个基准测试上达到了最先进的性能，并在保持高效率的同时，有效解决了现有对比学习模型精度不足和扩散模型计算成本高的问题。

> **摘要翻译:** 开放词汇语义分割（OVSS）旨在从任意文本类别中分割对象，而无需密集的标注数据集。尽管基于对比学习的模型能够实现零样本分割，但由于全局表示偏差，它们常常在像素级别失去精细的空间精度。相比之下，基于扩散的模型通过捕获全局上下文和局部细节的注意力机制，自然地编码细粒度空间特征。然而，它们常常面临平衡计算成本和分割掩膜质量的挑战。在这项工作中，我们提出了FA-Seg，一个快速准确的免训练框架，用于基于扩散模型的开放词汇分割。FA-Seg仅使用预训练扩散模型的(1+1)步进行分割。此外，FA-Seg无需为不同类别多次运行，而是同时对所有类别进行分割。为了进一步提高分割质量，FA-Seg引入了三个关键组件：(i) 一种用于判别性、类别感知注意力提取的双提示机制；(ii) 一种分层注意力细化方法（HARD），通过多分辨率注意力融合增强语义精度；以及(iii) 一种旨在提高空间一致性的测试时翻转（TTF）方案。广泛的实验表明，FA-Seg实现了最先进的免训练性能，在PASCAL VOC、PASCAL Context和COCO Object基准测试中获得了43.8%的平均mIoU，同时保持了卓越的推理效率。我们的结果表明，FA-Seg为可扩展性提供了坚实的基础，弥合了分割质量和推理效率之间的差距。源代码将在论文被接受后开源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [483] [Graph Aggregation Prototype Learning for Semantic Change Detection in Remote Sensing](https://arxiv.org/abs/2507.10938)
> *用于遥感语义变化检测的图聚合原型学习*

*Zhengyi Xu, Haoran Wu, Wen Jiang, Jie Geng* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 语义变化检测, 图聚合, 原型学习, 多任务学习, 遥感

**Comment:** 

> **TL;DR:** 本文提出了一种名为GAPL-SCD的新框架，用于遥感图像中的语义变化检测。该方法通过多任务联合优化、自适应权重分配和梯度旋转来解决多任务学习中的冲突，并利用图聚合原型学习模块、自查询多级特征交互和双时相特征融合模块提升性能，在SECOND和Landsat-SCD数据集上取得了最先进的结果。

**AI_Comments:** 本文针对遥感语义变化检测中的关键挑战——多任务学习的负迁移问题，提出了一个创新的解决方案。其核心贡献在于引入了图聚合原型学习，通过原型作为类别代理实现跨时间点的域对齐，有效减少了无关变化的干扰。同时，自适应权重分配和梯度旋转的引入，以及多级特征交互和融合模块的设计，都体现了对复杂场景和多任务优化问题的深入理解和有效应对。该方法在多个数据集上取得了SOTA性能，显示出强大的实用价值和前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** 语义变化检测（SCD）任务在多时相遥感数据中不仅提供变化位置，还提供详细的“从-到”类别信息，具有广泛的应用前景。然而，由于SCD涉及多任务同时优化，模型容易因任务特定的学习困难和冲突的梯度流而产生负迁移。

**Method:** 本文提出了用于遥感语义变化检测的图聚合原型学习（GAPL-SCD）框架。该框架设计了一种多任务联合优化方法，以优化语义分割和变化检测的主任务，以及图聚合原型学习的辅助任务。采用自适应权重分配和梯度旋转方法来缓解训练任务之间的冲突。具体地，图聚合原型学习模块利用高级特征构建交互图，原型作为类别代理实现跨时间点的类别级域对齐并减少无关变化的干扰。此外，提出的自查询多级特征交互和双时相特征融合模块进一步增强了多尺度特征表示。

**Result:** 在SECOND和Landsat-SCD数据集上的实验结果表明，所提出的方法取得了最先进的性能，在SCD任务的准确性和鲁棒性方面有显著提升。

**Conclusion:** 本文提出的GAPL-SCD方法通过创新的多任务优化策略和特征增强模块，有效解决了语义变化检测中的挑战，并在多个数据集上达到了最先进的性能，证明了其在遥感语义变化检测领域的有效性和优越性。

> **ai_Abstract:** 本文针对遥感语义变化检测（SCD）中多任务优化导致的负迁移问题，提出了一种名为图聚合原型学习（GAPL-SCD）的新框架。该方法通过设计多任务联合优化策略，结合自适应权重分配和梯度旋转来解决任务冲突。核心创新包括图聚合原型学习模块，用于构建交互图并实现类别级域对齐，以及自查询多级特征交互和双时相特征融合模块，以增强多尺度特征表示。实验证明，GAPL-SCD在SECOND和Landsat-SCD数据集上均达到了最先进的性能，显著提升了SCD的准确性和鲁棒性。

> **摘要翻译:** 语义变化检测（SCD）将二元变化检测任务扩展为不仅提供变化位置，还提供多时相遥感数据中详细的“从-到”类别。这种对变化的详细语义洞察为广泛的应用提供了巨大的优势。然而，由于SCD涉及多任务的同时优化，模型容易因任务特定的学习困难和冲突的梯度流而产生负迁移。为了解决这个问题，我们提出了用于遥感语义变化检测的图聚合原型学习（GAPL-SCD）。在该框架中，设计了一种多任务联合优化方法，以优化语义分割和变化检测的主任务，以及图聚合原型学习的辅助任务。采用自适应权重分配和梯度旋转方法来缓解训练任务之间的冲突并提高多任务学习能力。具体地，图聚合原型学习模块利用高级特征构建交互图。原型作为类别代理，实现了跨时间点的类别级域对齐，并减少了无关变化的干扰。此外，提出的自查询多级特征交互和双时相特征融合模块进一步增强了多尺度特征表示，提高了在复杂场景中的性能。SECOND和Landsat-SCD数据集上的实验结果表明，我们的方法取得了最先进的性能，在SCD任务的准确性和鲁棒性方面有显著提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [487] [Similarity Memory Prior is All You Need for Medical Image Segmentation](https://arxiv.org/abs/2507.00585)
> *相似性记忆先验是医学图像分割的全部所需*

*Hao Tang, Zhiqing Guo, Liejun Wang, Chao Liu* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 相似性记忆先验, 医学图像分割, Sim-MPNet, 动态记忆权重损失注意力, 双相似性全局内部增强模块

**Comment:** 

> **TL;DR:** 受猕猴V1区“祖母细胞”启发，本文提出了一种名为Sim-MPNet的相似性记忆先验网络，用于医学图像分割，通过动态记忆权重损失注意力（DMW-LA）和双相似性全局内部增强模块（DS-GIM）提高了分割性能，并在四个公开数据集上取得了优于现有SOTA方法的结果。

**AI_Comments:** 本文的创新点在于将“祖母细胞”的视觉识别机制引入到医学图像分割领域，并设计了Sim-MPNet网络及其核心组件DMW-LA和DS-GIM。DMW-LA通过记忆和动态更新相似性记忆先验来帮助网络学习细微的类别纹理变化，而DS-GIM则通过双相似性度量增强了特征的内部探索。这些机制的结合有效提升了医学图像分割的性能，为该领域提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 近年来发现猕猴初级视觉皮层（V1）中的“祖母细胞”可以直接识别复杂形状的视觉输入，这启发了作者探索这些细胞在促进医学图像分割研究中的价值。

**Method:** 本文设计了一种用于医学图像分割的相似性记忆先验网络（Sim-MPNet）。具体地，提出了一种动态记忆权重损失注意力（DMW-LA），它通过原型记忆库中的相似性记忆先验来匹配和记忆医学图像中特定病变或器官的类别特征，从而帮助网络学习类别之间细微的纹理变化。DMW-LA还通过权重损失动态（W-LD）更新策略反向动态更新相似性记忆先验，有效地辅助网络直接提取类别特征。此外，还提出了双相似性全局内部增强模块（DS-GIM），通过余弦相似度和欧氏距离深入探索输入数据特征分布的内部差异。

**Result:** 在四个公开数据集上的大量实验表明，Sim-MPNet比其他最先进的方法具有更好的分割性能。

**Conclusion:** Sim-MPNet在医学图像分割任务上表现出优于现有最先进方法的性能，验证了其所提出方法的有效性。

> **ai_Abstract:** 本文受猕猴视觉皮层中“祖母细胞”的启发，提出了一种名为Sim-MPNet的相似性记忆先验网络，用于医学图像分割。该网络包含动态记忆权重损失注意力（DMW-LA）和双相似性全局内部增强模块（DS-GIM）。DMW-LA利用原型记忆库中的相似性记忆先验来学习和更新类别特征，以捕捉细微纹理变化。DS-GIM则通过两种相似性度量深入探索特征分布。实验结果表明，Sim-MPNet在多个公开医学图像数据集上优于现有的先进方法。

> **摘要翻译:** 近年来，研究发现猕猴初级视觉皮层（V1）中的“祖母细胞”可以直接识别复杂形状的视觉输入。这启发我们研究这些细胞在促进医学图像分割研究中的价值。在本文中，我们设计了一种用于医学图像分割的相似性记忆先验网络（Sim-MPNet）。具体来说，我们提出了一种动态记忆权重损失注意力（DMW-LA），它通过原型记忆库中的相似性记忆先验来匹配和记忆医学图像中特定病变或器官的类别特征，从而帮助网络学习类别之间细微的纹理变化。DMW-LA还通过权重损失动态（W-LD）更新策略反向动态更新相似性记忆先验，有效地辅助网络直接提取类别特征。此外，我们提出了双相似性全局内部增强模块（DS-GIM），通过余弦相似度和欧氏距离深入探索输入数据特征分布的内部差异。在四个公开数据集上的大量实验表明，Sim-MPNet比其他最先进的方法具有更好的分割性能。我们的代码可在https://github.com/vpsg-research/Sim-MPNet获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [492] [Tomato Multi-Angle Multi-Pose Dataset for Fine-Grained Phenotyping](https://arxiv.org/abs/2507.11279)
> *番茄多角度多姿态数据集，用于精细表型分析*

*Yujie Zhang, Sabine Struckmeyer, Andreas Kolb, Sven Reichardt* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 番茄, 表型分析, 数据集, 深度学习, 图像处理

**Comment:** 

> **TL;DR:** 本文介绍了TomatoMAP，一个用于番茄精细表型分析的多角度、多姿态数据集。该数据集通过详细标注使AI模型能够实现与专家相当的准确性和速度。

**AI_Comments:** 该论文通过提供一个大型、标注精细的数据集TomatoMAP，解决了植物表型分析中的一个重要挑战。其创新之处在于多角度、多姿态的图像采集以及广泛、精细的标注，这对于开发鲁棒的AI模型至关重要。与人类专家的验证突出了其实用性和可靠性，使其成为农业AI和植物科学领域的宝贵资源。

<details>
  <summary>Details</summary>

**Motivation:** 传统植物表型方法存在观察者偏见和不一致性，限制了精细植物分析的准确性和可重复性。

**Method:** 开发了TomatoMAP数据集，包含64,464张RGB图像，捕捉了12种不同植物姿态和4个相机仰角。图像包含7个感兴趣区域的手动标注边界框和基于BBCH量表的50种精细生长阶段分类。此外，提供了3,616张高分辨率图像子集，带有像素级语义和实例分割标注。使用结合MobileNetv3（分类）、YOLOv11（目标检测）和MaskRCNN（分割）的级联深度学习框架对数据集进行验证，并进行了AI与人类专家（五位领域专家）的对比分析。

**Result:** 在TomatoMAP数据集上训练的模型达到了与领域专家相当的准确性和速度。Cohen's Kappa和评分者间一致性热图证实了使用该方法进行自动化精细表型分析的可靠性。

**Conclusion:** 所开发的数据集和方法能够实现可靠、准确的自动化番茄精细表型分析，克服了传统方法的局限性。

> **ai_Abstract:** 本文介绍了TomatoMAP，一个用于番茄精细表型分析的大规模综合数据集。该数据集包含64,464张多角度、多姿态的RGB图像，具有详细的ROI边界框标注和生长阶段分类，另有3,616张图像子集具有像素级分割标注。通过级联深度学习框架进行验证，在TomatoMAP上训练的模型展示出专家级的准确性和速度，证实了自动化表型分析的可靠性。

> **摘要翻译:** 传统植物表型方法中观察者偏见和不一致性限制了精细植物分析的准确性和可重复性。为了克服这些挑战，我们开发了TomatoMAP，这是一个使用基于物联网（IoT）的成像系统和标准化数据采集协议的番茄（Solanum lycopersicum）综合数据集。我们的数据集包含64,464张RGB图像，捕捉了从四个相机仰角拍摄的12种不同植物姿态。每张图像都包含七个感兴趣区域（ROI）的手动标注边界框，包括叶子、花序、花簇、果簇、腋芽、茎和整株植物区域，以及基于BBCH量表的50种精细生长阶段分类。此外，我们提供了3,616张高分辨率图像子集，带有像素级语义和实例分割标注，用于精细表型分析。我们使用级联模型深度学习框架验证了我们的数据集，该框架结合了MobileNetv3用于分类、YOLOv11用于目标检测和MaskRCNN用于分割。通过涉及五位领域专家的AI与人类分析，我们证明了在我们的数据集上训练的模型达到了与专家相当的准确性和速度。Cohen's Kappa和评分者间一致性热图证实了使用我们方法进行自动化精细表型分析的可靠性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [505] [CWNet: Causal Wavelet Network for Low-Light Image Enhancement](https://arxiv.org/abs/2507.10689)
> *CWNet：用于低光图像增强的因果小波网络*

*Tongshun Zhang, Pingping Liu, Yubing Lu, Mengen Cai, Zijian Zhang, Zhe Zhang, Qiuzhan Zhou* | **Category: cs.CV** | **Updated: 2025-07-14**

**Keywords:** 低光图像增强, 因果推理, 小波网络, 语义信息, 频率恢复

**Comment:** Accepted by ICCV 2025

> **TL;DR:** CWNet是一种新的低光图像增强方法，它结合了因果推理和小波变换，在多个数据集上显著优于现有SOTA方法。

**AI_Comments:** CWNet的创新之处在于将因果推理引入低光图像增强领域，这有助于模型更好地理解和分离图像中的因果与非因果因素。结合小波变换来处理频率信息，也为图像增强提供了新的视角。这种方法可能为未来的图像处理研究提供新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统的低光图像增强方法主要关注统一亮度调整，忽略了实例级语义信息和不同特征的固有特性。

**Method:** 提出CWNet，一个结合了因果推理和小波变换的新颖架构。具体包括两个关键组件：1) 采用因果推理视角揭示低光增强中的因果关系，通过度量学习策略确保因果嵌入符合因果原则，并引入实例级CLIP语义损失来保持因果因子一致性。2) 基于因果分析，提出一个基于小波变换的骨干网络，以有效优化频率信息的恢复。

**Result:** CWNet在多个数据集上显著优于当前最先进的方法，并在不同场景中展现出强大的性能。

**Conclusion:** CWNet通过结合因果推理和小波变换，有效解决了传统低光图像增强方法的局限性，实现了卓越的图像增强效果。

> **ai_Abstract:** CWNet是一种新颖的低光图像增强（LLIE）方法，旨在解决传统方法忽略实例级语义和特征特性的问题。该网络通过结合因果推理和小波变换，从全局和局部层面揭示并利用图像的因果关系，同时优化频率信息恢复。实验证明，CWNet在多个数据集上显著超越了现有最先进的方法。

> **摘要翻译:** 传统的低光图像增强（LLIE）方法主要关注统一亮度调整，往往忽略实例级语义信息和不同特征的固有特性。为解决这些局限性，我们提出了CWNet（因果小波网络），这是一种利用小波变换进行因果推理的新颖架构。具体而言，我们的方法包含两个关键组件：1) 受因果关系中干预概念的启发，我们采用因果推理视角来揭示低光增强中潜在的因果关系。从全局角度来看，我们采用度量学习策略来确保因果嵌入符合因果原则，将它们与非因果混杂因素分离，同时关注因果因素的不变性。在局部层面，我们引入实例级CLIP语义损失，以精确保持因果因子的一致性。2) 基于我们的因果分析，我们提出了一个基于小波变换的骨干网络，该网络有效优化了频率信息的恢复，确保了根据小波变换特定属性量身定制的精确增强。大量的实验表明，CWNet在多个数据集上显著优于当前最先进的方法，展示了其在不同场景下的强大性能。代码可在https://github.com/bywlzts/CWNet-Causal-Wavelet-Network获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [509] [PerLDiff: Controllable Street View Synthesis Using Perspective-Layout Diffusion Models](https://arxiv.org/abs/2407.06109)
> *PerLDiff：使用透视布局扩散模型进行可控街景合成*

*Jinhua Zhang, Hualian Sheng, Sijia Cai, Bing Deng, Qiao Liang, Wen Li, Ying Fu, Jieping Ye, Shuhang Gu* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 可控生成, 街景合成, 扩散模型, 3D几何先验, 自动驾驶

**Comment:** Accepted by ICCV 2025

> **TL;DR:** PerLDiff是一种新的扩散模型，利用透视3D几何信息和3D几何先验，实现对街景图像生成更精确和鲁棒的对象级控制，并在NuScenes和KITTI数据集上表现出优越的生成精度和可控性。

**AI_Comments:** PerLDiff的创新之处在于其将透视3D几何信息和3D几何先验融入扩散模型，实现了对街景图像生成更精细和鲁棒的对象级控制。这对于自动驾驶领域3D数据标注的精度提升具有重要意义，克服了传统方法在网络架构学习能力上的限制。

<details>
  <summary>Details</summary>

**Motivation:** 解决3D数据标注的挑战，特别是在自动驾驶数据生产中对可控生成精度的高要求。现有方法（如GLIGEN或ControlNet）受限于预定义网络架构的学习能力。

**Method:** 本文引入了PerLDiff（透视布局扩散模型），这是一种新颖的方法，通过充分利用透视3D几何信息来有效生成街景图像。PerLDiff在网络学习过程中利用3D几何先验来指导街景图像的生成，实现精确的对象级控制，从而产生更鲁棒和可控的输出。

**Result:** PerLDiff在可控性方面优于其他布局控制方法。在NuScenes和KITTI数据集上的实证结果表明，PerLDiff显著提高了可控生成的精度。

**Conclusion:** PerLDiff通过整合透视3D几何信息和利用3D几何先验，有效解决了现有可控生成方法的局限性，显著提升了街景图像生成的可控性和精度，尤其适用于自动驾驶数据生产。

> **ai_Abstract:** PerLDiff（透视布局扩散模型）是一种新颖的街景图像生成方法，旨在解决3D数据标注和自动驾驶数据生产中可控生成精度不足的问题。与现有方法受限于网络架构不同，PerLDiff创新性地整合了透视3D几何信息和3D几何先验，以实现精确的对象级控制。实验证明，PerLDiff在NuScenes和KITTI数据集上显著提升了可控生成的精度和鲁棒性，并展现出优于其他布局控制方法的性能。

> **摘要翻译:** 可控生成被认为是解决3D数据标注挑战的潜在关键方法，而这种可控生成的精度在自动驾驶数据生产的背景下变得尤为重要。现有方法侧重于将多样化的生成信息整合到控制输入中，利用GLIGEN或ControlNet等框架，在可控生成方面取得了值得称赞的成果。然而，这些方法本质上将生成性能限制在预定义网络架构的学习能力范围内。在本文中，我们探索了控制信息的创新整合，并引入了PerLDiff（透视布局扩散模型），这是一种有效生成街景图像的新颖方法，它充分利用了透视3D几何信息。我们的PerLDiff采用3D几何先验来指导网络学习过程中街景图像的生成，实现精确的对象级控制，从而产生更鲁棒和可控的输出。此外，与替代布局控制方法相比，它展示了卓越的可控性。实证结果证明，我们的PerLDiff显著提高了NuScenes和KITTI数据集上可控生成的精度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [512] [Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence](https://arxiv.org/abs/2507.01504)
> *追寻线索：利用跨模态智能进行行人重识别的实验*

*Robert Aufschläger, Youssef Shoeb, Azarm Nowzad, Michael Heigl, Fabian Bally, Martin Schramm* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-15**

**Keywords:** 行人重识别, 跨模态, 个人身份信息, 大型视觉-语言模型, 图注意力网络

**Comment:** accepted for publication at the 2025 IEEE 28th International
  Conference on Intelligent Transportation Systems (ITSC 2025), taking place
  during November 18-21, 2025 in Gold Coast, Australia

> **TL;DR:** 本文提出了cRID，一个结合大型视觉-语言模型、图注意力网络和表征学习的跨模态框架，用于检测可描述的个人身份信息（PII）线索，以增强行人重识别（Re-ID），并在跨数据集场景中显示出改进的性能。

**AI_Comments:** 本文的创新之处在于其采用跨模态方法（结合大型视觉-语言模型和图注意力网络）进行行人重识别，尤其侧重于识别和利用可描述的文本PII线索，而非仅仅依赖生物特征或低级外观特征。这有效地解决了开放数据集中关键的隐私问题，并提供了一种更鲁棒和可解释的行人重识别方法。其在跨数据集场景中的实用性是一个显著优势。

<details>
  <summary>Details</summary>

**Motivation:** 街景录像作为开放数据在推进自动驾驶系统和人工智能研究中发挥重要作用，但其中包含的个人身份信息（PII）存在显著的隐私风险，且这些信息超出了生物特征。因此，需要一种方法来识别和利用可解释的特征，以检测语义上有意义的PII，从而增强行人重识别。

**Method:** 本文提出了cRID，一种新颖的跨模态框架，它结合了大型视觉-语言模型（Large Vision-Language Models）、图注意力网络（Graph Attention Networks）和表征学习（representation learning）。该方法侧重于检测可描述的文本PII线索，并利用可解释的特征来检测超越低级外观线索的语义有意义的PII。

**Result:** 实验表明，在实际的跨数据集行人重识别场景中，例如从Market-1501到CUHK03-np（已检测），性能得到了改善，突显了该框架的实用性。研究还对行人图像数据集中PII的存在进行了系统性评估。

**Conclusion:** cRID框架通过识别和利用可解释的、语义上有意义的PII线索（超越传统的生物特征或低级外观线索），有效地增强了行人重识别，并在实际的跨数据集场景中展示了改进的性能。

> **ai_Abstract:** 本文提出了cRID，一个创新的跨模态框架，它整合了大型视觉-语言模型、图注意力网络和表征学习。该框架旨在通过检测和利用可描述的文本个人身份信息（PII）线索来增强行人重识别（Re-ID），这些线索超越了传统的生物特征。cRID专注于可解释的特征，能够识别语义上有意义的PII。实验证明，该框架在实际的跨数据集Re-ID场景中（如从Market-1501到CUHK03-np）表现出改进的性能，凸显了其在解决开放街景数据隐私问题方面的实用性。

> **摘要翻译:** 街景录像作为开放数据的收集和发布，在推进自动驾驶系统和人工智能研究中发挥着至关重要的作用。然而，这些数据集带来了显著的隐私风险，特别是对于行人，因为其中存在超出生物特征（如面部）的个人身份信息（PII）。在本文中，我们提出了cRID，一个新颖的跨模态框架，它结合了大型视觉-语言模型、图注意力网络和表征学习，用于检测可描述的文本PII线索并增强行人重识别（Re-ID）。我们的方法侧重于识别和利用可解释的特征，从而能够检测超越低级外观线索的语义有意义的PII。我们对行人图像数据集中PII的存在进行了系统性评估。我们的实验显示，在实际的跨数据集Re-ID场景中，性能得到了改善，特别是从Market-1501到CUHK03-np（已检测），这突出了该框架的实用性。代码可在https://github.com/RAufschlaeger/cRID获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [516] [GKNet: Graph-based Keypoints Network for Monocular Pose Estimation of Non-cooperative Spacecraft](https://arxiv.org/abs/2507.11077)
> *GKNet：用于非合作航天器单目姿态估计的图基关键点网络*

*Weizhao Ma, Dong Zhou, Yuhui Hu, Zipeng He* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 航天器姿态估计, 关键点检测, 图神经网络, 单目视觉, 非合作目标

**Comment:** 

> **TL;DR:** 提出GKNet，一个基于图的关键点网络，用于非合作航天器的单目姿态估计，并发布SKD数据集，解决现有关键点检测器对对称性和遮挡的脆弱性问题，实验证明其高精度和有效性。

**AI_Comments:** 这篇论文的创新点在于提出了一个基于图的关键点网络GKNet，通过利用关键点之间的几何约束来增强对非合作航天器结构对称性和部分遮挡的鲁棒性，这对于提高在轨服务任务中的姿态估计精度至关重要。同时，发布了一个专门用于航天器关键点检测的数据集SKD，填补了该领域高质量数据集的空白，对未来的研究具有重要推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 非合作航天器的单目姿态估计对在轨服务（如卫星维护、空间碎片清除、空间站组装）至关重要。然而，主流的关键点检测器容易受到非合作航天器结构对称性和部分遮挡的影响，导致姿态估计精度不高。

**Method:** 提出GKNet（Graph-based Keypoints Network），一个基于图的关键点网络，利用关键点图的几何约束来解决非合作航天器的单目姿态估计问题。为了更好地验证关键点检测器，还提出了一个中等规模的航天器关键点检测数据集SKD，包含3个航天器目标、90,000张模拟图像和相应的高精度关键点标注。

**Result:** 广泛的实验和消融研究表明，与最先进的航天器关键点检测器相比，GKNet具有高精度和有效性。

**Conclusion:** GKNet通过利用关键点图的几何约束，有效解决了非合作航天器单目姿态估计中关键点检测器易受结构对称性和部分遮挡影响的问题，并提供了验证数据集，显著提高了姿态估计的准确性和有效性。

> **ai_Abstract:** 这篇论文提出了一种名为GKNet的图基关键点网络，用于解决非合作航天器的单目姿态估计问题。针对现有关键点检测器在面对结构对称性和部分遮挡时的不足，GKNet利用关键点图的几何约束来提高精度。为验证该方法，作者还构建了一个包含9万张模拟图像的中等规模航天器关键点检测数据集SKD。实验结果表明，GKNet相比现有技术具有更高的准确性和有效性。

> **摘要翻译:** 非合作航天器的单目姿态估计对于在轨服务（OOS）任务，如卫星维护、空间碎片清除和空间站组装，具有重要意义。考虑到对姿态估计精度的高要求，主流的单目姿态估计算法通常由关键点检测器和PnP求解器组成。然而，当前的关键点检测器仍然容易受到非合作航天器结构对称性和部分遮挡的影响。为此，我们提出了一个基于图的关键点网络GKNet，用于非合作航天器的单目姿态估计，该网络利用了关键点图的几何约束。为了更好地验证关键点检测器，我们提出了一个中等规模的航天器关键点检测数据集SKD，它包含3个航天器目标、90,000张模拟图像以及相应的高精度关键点标注。广泛的实验和消融研究表明，与最先进的航天器关键点检测器相比，我们的GKNet具有高精度和有效性。GKNet的代码和SKD数据集可在https://github.com/Dongzhou-1996/GKNet获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [538] [3D Magnetic Inverse Routine for Single-Segment Magnetic Field Images](https://arxiv.org/abs/2507.11293)
> *用于单段磁场图像的 3D 磁逆例程*

*J. Senthilnath, Chen Hao, F. C. Wellstood* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 3D 磁逆例程, 磁场图像, 半导体封装, 深度学习, 无损检测

**Comment:** copyright 2025 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works

> **TL;DR:** 本文提出了一种名为 3D MIR 的新方法，结合深度学习、空间物理约束和优化技术，从磁场图像中高精度恢复半导体封装中单段电流的 3D 信息，以定位电路缺陷。

**AI_Comments:** 该论文的创新之处在于将深度学习（CNN）与传统物理约束和优化技术相结合，形成了一个多阶段的 3D 磁逆例程。这种混合方法不仅利用了深度学习在特征提取方面的优势，还通过物理约束和优化确保了结果的物理合理性和精度。其重要性体现在为半导体封装中的无损检测和电路缺陷定位提供了一种高精度、新颖的 3D 信息恢复方案，有望在实际工业应用中发挥关键作用。

<details>
  <summary>Details</summary>

**Motivation:** 在半导体封装中，准确恢复 3D 信息对于无损检测 (NDT) 和定位电路缺陷至关重要。

**Method:** 3D MIR 方法分三个阶段：i) CNN 模型处理 MFI 数据以预测线长与垂直深度比 ($\ell/z_o$) 并分类线段类型 ($c$)；ii) 利用基于空间物理的约束，提供电流线段的位置 ($x_o, y_o, z_o$)、长度 ($\ell$)、电流 ($I$) 和电流方向的初始估计；iii) 优化器调整这五个参数 ($x_o, y_o, z_o, \ell, I$) 以最小化重建 MFI 与实际 MFI 之间的差异。

**Result:** 3D MIR 方法能够高精度地准确恢复 3D 信息，为半导体封装中的磁图像重建设定了新基准。

**Conclusion:** 该方法突出了深度学习与物理驱动优化相结合在实际应用中的潜力。

> **ai_Abstract:** 本文提出了一种名为 3D 磁逆例程 (3D MIR) 的创新方法，用于从半导体封装的单段磁场图像中恢复 3D 电流信息。该方法结合了基于深度学习的 CNN、空间物理约束和优化技术，分三阶段进行：首先通过 CNN 预测线长与深度比和线段类型；其次利用物理约束提供初始参数估计；最后通过优化器精调参数以最小化重建误差。实验结果表明，3D MIR 能够高精度地恢复 3D 信息，为磁图像重建树立了新标杆，并展示了深度学习与物理优化结合的强大潜力。

> **摘要翻译:** 在半导体封装中，准确恢复 3D 信息对于无损检测 (NDT) 以定位电路缺陷至关重要。本文提出了一种名为 3D 磁逆例程 (3D MIR) 的新方法，该方法利用磁场图像 (MFI) 来检索单段电流的 3D 流动参数。3D MIR 集成了基于深度学习 (DL) 的卷积神经网络 (CNN)、基于空间物理的约束和优化技术。该方法分三个阶段操作：i) CNN 模型处理 MFI 数据以预测 ($\ell/z_o$)，其中 $\ell$ 是导线长度，$z_o$ 是导线在磁传感器下方的垂直深度，并对线段类型 ($c$) 进行分类。ii) 通过利用基于空间物理的约束，该例程提供电流线段的位置 ($x_o, y_o, z_o$)、长度 ($\ell$)、电流 ($I$) 和电流流向（正或负）的初始估计。iii) 优化器随后调整这五个参数 ($x_o, y_o, z_o, \ell, I$)，以最小化重建 MFI 与实际 MFI 之间的差异。结果表明，3D MIR 方法能够高精度地准确恢复 3D 信息，为半导体封装中的磁图像重建设定了新基准。该方法突出了深度学习与物理驱动优化相结合在实际应用中的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [539] [CycleSAM: Few-Shot Surgical Scene Segmentation with Cycle- and Scene-Consistent Feature Matching](https://arxiv.org/abs/2407.06795)
> *CycleSAM：基于循环和场景一致性特征匹配的少样本手术场景分割*

*Aditya Murali, Farahdiba Zarin, Adrien Meyer, Pietro Mascagni, Didier Mutter, Nicolas Padoy* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 少样本分割, 手术图像, SAM, 特征匹配, 视觉提示

**Comment:** 

> **TL;DR:** CycleSAM提出了一种改进的视觉提示学习方法，通过数据高效训练和一致性约束，在少样本设置下显著提高了手术图像分割的性能。

**AI_Comments:** CycleSAM的创新之处在于其结合了数据高效训练、领域特定特征提取以及多重一致性约束来克服SAM在少样本手术图像分割中的局限性。这种方法不仅提高了分割精度，还解决了域间隙问题，对于医疗图像分析领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 手术图像分割面临标注数据稀缺的巨大挑战。通用提示分割模型（如SAM）虽有助于数据标注，但其需要图像特定的视觉提示，且现有扩展SAM到自动分割的方法在处理手术图像等域外数据时鲁棒性不足。

**Method:** CycleSAM引入了一种改进的视觉提示学习方法。它采用数据高效的训练阶段，并强制执行一系列软约束以生成高质量的特征相似度图。CycleSAM通过利用手术特有的自监督特征提取器来解决域间隙问题，并通过一个简短的参数高效训练阶段来调整所得特征，从而生成信息丰富的相似度图。此外，CycleSAM通过一系列一致性约束进一步过滤相似度图，然后为每个对象实例鲁棒地采样多样化的点提示。

**Result:** 在四个不同的手术数据集上的实验表明，CycleSAM在1-shot和5-shot设置下均优于现有少样本SAM方法2-4倍，并且相对于传统的线性探测、参数高效适应和伪标签方法也取得了显著的性能提升。

**Conclusion:** CycleSAM通过其创新的视觉提示学习方法，有效解决了少样本手术场景分割中的域间隙和鲁棒性问题，并在多个数据集上取得了显著优于现有方法的性能。

> **ai_Abstract:** 本研究提出了CycleSAM，一个针对少样本手术场景分割的改进视觉提示学习方法。针对标注数据稀缺和现有SAM扩展方法在手术图像上鲁棒性不足的问题，CycleSAM通过数据高效训练、利用手术特有的自监督特征提取器以及应用一系列循环和场景一致性约束来生成高质量特征相似度图和鲁棒的提示点。实验结果表明，CycleSAM在多个手术数据集上，在1-shot和5-shot设置下，性能显著优于现有少样本SAM方法及其他传统方法。

> **摘要翻译:** 手术图像分割极具挑战性，主要原因是标注数据稀缺。像Segment-Anything Model (SAM) 这样的通用提示分割模型可以帮助解决这项任务，但由于它们需要图像特定的视觉提示才能有效发挥性能，因此其应用仅限于提高数据标注效率。最近的方法通过使用少量标记的参考图像来预测点提示，从而将SAM扩展到自动分割；然而，它们依赖于特征匹配管道，对像手术图像这样的域外数据缺乏鲁棒性。为了解决这个问题，我们引入了CycleSAM，这是一种改进的视觉提示学习方法，它采用数据高效的训练阶段并强制执行一系列软约束以生成高质量的特征相似度图。CycleSAM通过利用手术特有的自监督特征提取器，然后通过一个简短的参数高效训练阶段调整所得特征，从而标签高效地解决了域间隙问题，使其能够生成信息丰富的相似度图。CycleSAM进一步通过一系列一致性约束过滤相似度图，然后为每个对象实例鲁棒地采样多样化的点提示。在我们对四个不同手术数据集进行的实验中，我们发现CycleSAM在1-shot和5-shot设置下均优于现有少样本SAM方法2-4倍，同时相对于传统的线性探测、参数高效适应和伪标签方法也取得了显著的性能提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [540] [Robustifying 3D Perception via Least-Squares Graphs for Multi-Agent Object Tracking](https://arxiv.org/abs/2507.04762)
> *通过最小二乘图增强多智能体目标跟踪的3D感知鲁棒性*

*Maria Damanaki, Ioulia Kapsali, Nikos Piperigkos, Alexandros Gkillas, Aris S. Lalos* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 3D感知, 多智能体跟踪, 最小二乘图, 对抗鲁棒性, LiDAR

**Comment:** 6 pages, 3 figures, 4 tables

> **TL;DR:** 本论文提出了一种基于最小二乘图的多智能体目标跟踪新框架，用于在3D LiDAR场景中对抗性噪声下增强3D感知鲁棒性，并在实际数据集中显著优于现有技术。

**AI_Comments:** 该论文的创新点在于将最小二乘图应用于多智能体协作的3D目标跟踪，以增强对对抗性攻击的鲁棒性。其重要性在于为自动驾驶等EdgeAI系统提供了更可靠的感知能力，并且在不依赖额外防御机制的情况下实现了显著的性能提升。这对于提高未来自动驾驶系统的安全性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** EdgeAI系统（如自动驾驶汽车）的关键感知能力需要对对抗性威胁具有弹性，以实现场景中多目标的准确识别和定位并减轻其影响。单智能体跟踪虽然对对抗性攻击具有弹性，但缺乏态势感知能力，因此需要多智能体协作来增强情境理解和鲁棒性。

**Method:** 本论文提出了一种新颖的缓解框架，通过基于多智能体对抗性边界框上的最小二乘图来跟踪物体，以对抗3D LiDAR场景中的对抗性噪声。具体来说，利用最小二乘图工具，通过差分坐标和锚点，在全连接图上利用重叠的边界框来减少每次检测中心点的位置误差。多车辆检测被融合和 S精炼以减轻对抗性影响，并分两个阶段与现有轨迹关联以进一步抑制对抗性威胁。

**Result:** 在真实世界的V2V4Real数据集上进行的广泛评估研究表明，在具有挑战性的对抗性条件下，所提出的方法显著优于最先进的单智能体和多智能体跟踪框架，性能提升高达23.3%，作为一种弹性方法，无需依赖额外的防御机制。

**Conclusion:** 本论文提出的基于最小二乘图的多智能体目标跟踪框架，在3D LiDAR场景中有效提高了对抗性攻击下的3D感知鲁棒性，无需额外防御机制即可实现显著性能提升。

> **ai_Abstract:** 本论文提出了一种新颖的框架，通过在多智能体对抗性边界框上利用最小二乘图，在3D LiDAR场景中实现鲁棒的多智能体目标跟踪，以应对对抗性噪声。该方法通过融合和精炼多车辆检测来减少位置误差并抑制对抗性威胁。在V2V4Real数据集上的评估显示，该方法在对抗性条件下显著优于现有单智能体和多智能体跟踪框架，性能提升高达23.3%，且无需额外防御机制。

> **摘要翻译:** EdgeAI系统（如自动驾驶汽车）的关键感知能力需要对对抗性威胁具有弹性，通过实现场景中多目标的准确识别和定位并减轻其影响。单智能体跟踪对对抗性攻击具有弹性，但缺乏态势感知能力，这凸显了多智能体协作以增强情境理解和鲁棒性的必要性。本论文提出了一种新颖的缓解框架，通过基于多智能体对抗性边界框上的最小二乘图来跟踪物体，以对抗3D LiDAR场景中的对抗性噪声。具体来说，我们利用最小二乘图工具，通过差分坐标和锚点，在全连接图上利用重叠的边界框来减少每次检测中心点的位置误差。因此，多车辆检测被融合和精炼以减轻对抗性影响，并分两个阶段与现有轨迹关联以进一步抑制对抗性威胁。在真实世界的V2V4Real数据集上进行的广泛评估研究表明，所提出的方法在具有挑战性的对抗性条件下，显著优于最先进的单智能体和多智能体跟踪框架，性能提升高达23.3%，作为一种弹性方法，无需依赖额外的防御机制。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [550] [Robust ID-Specific Face Restoration via Alignment Learning](https://arxiv.org/abs/2507.10943)
> *通过对齐学习实现鲁棒的身份特异性人脸修复*

*Yushun Fang, Lu Liu, Xiang Gao, Qiang Hu, Ning Cao, Jianghe Cui, Gang Chen, Xiaoyun Zhang* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 人脸修复, 身份特异性, 扩散模型, 对齐学习, 鲁棒性

**Comment:** 17 pages, 8 figures

> **TL;DR:** 本文提出了RIDFR，一个基于扩散模型的身份特异性人脸修复框架，通过内容和身份注入模块以及对齐学习来解决身份不确定性问题，实现了高质量且鲁棒的人脸修复。

**AI_Comments:** 本文的创新点在于提出了RIDFR框架，特别引入了对齐学习机制来解决扩散模型在人脸修复中常见的身份不确定性问题。通过分离内容和身份注入，并对齐多参考结果以消除身份无关的语义干扰，该方法有效地提升了修复结果的身份保真度和鲁棒性，对于提高人脸修复的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前人脸修复方法虽在视觉质量上有所提升，但由模糊输入和随机生成过程导致的人脸身份不确定性问题仍未解决。

**Method:** 本文提出了鲁棒的身份特异性人脸修复（RIDFR）框架。RIDFR利用预训练的扩散模型，并结合两个并行条件模块：内容注入模块输入严重退化的图像，身份注入模块整合给定图像的特定身份。随后，RIDFR引入对齐学习，对齐来自多个相同身份参考的修复结果，以抑制与身份无关的人脸语义（如姿势、表情、妆容、发型）的干扰。

**Result:** 实验证明，RIDFR框架优于现有最先进的方法，能够重建高质量、身份特异性的人脸，具有高身份保真度，并展现出强大的鲁棒性。

**Conclusion:** RIDFR通过其新颖的框架和对齐学习机制，成功解决了人脸修复中的身份不确定性问题，实现了卓越的修复效果，具有高身份保真度和鲁棒性。

> **ai_Abstract:** 本文提出了一种名为RIDFR的鲁棒身份特异性人脸修复框架，旨在解决扩散模型在人脸修复中引入的身份不确定性问题。RIDFR结合了预训练的扩散模型、内容注入模块和身份注入模块，并通过新颖的对齐学习机制，抑制与身份无关的语义干扰。实验结果表明，RIDFR在生成高保真度、身份特异性的人脸修复结果方面超越了现有技术，并展现出强大的鲁棒性。

> **摘要翻译:** 人脸修复的最新进展通过利用多样化的扩散先验在视觉质量方面取得了显著进步。然而，由身份模糊输入和随机生成过程引入的人脸身份不确定性问题仍未解决。为了应对这一挑战，我们提出了鲁棒的身份特异性人脸修复（RIDFR），一个基于扩散模型的新型身份特异性人脸修复框架。具体来说，RIDFR利用预训练的扩散模型并结合两个并行条件模块。内容注入模块输入严重退化的图像，而身份注入模块整合来自给定图像的特定身份。随后，RIDFR引入对齐学习，对齐来自多个相同身份参考的修复结果，以抑制与身份无关的人脸语义（例如姿势、表情、化妆、发型）的干扰。实验证明，我们的框架优于现有最先进的方法，能够重建高质量的身份特异性结果，具有高身份保真度并展现出强大的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [563] [Integrating Biological Knowledge for Robust Microscopy Image Profiling on De Novo Cell Lines](https://arxiv.org/abs/2507.10737)
> *将生物学知识整合到从头细胞系的稳健显微图像分析中*

*Jiayuan Chen, Thai-Hoang Pham, Yuanlong Wang, Ping Zhang* | **Category: cs.CV** | **Updated: 2025-07-14**

**Keywords:** 显微图像分析, 从头细胞系, 生物学知识整合, 知识图谱, 特征解耦

**Comment:** ICCV 2025

> **TL;DR:** 提出一个新框架，通过整合外部生物学知识（知识图谱、转录组特征）来解耦扰动和细胞系特异性表示，从而提高显微图像分析模型在新细胞系上的泛化能力，并在RxRx数据集上验证有效性。

**AI_Comments:** 该研究的创新点在于将外部生物学知识（知识图谱、转录组特征）与现有的预训练策略相结合，以实现显微图像分析中扰动和细胞系特异性特征的解耦。这对于提高模型在新细胞系上的泛化能力非常重要，特别是在药物发现领域，因为能够更稳健地处理细胞系的异质性。

<details>
  <summary>Details</summary>

**Motivation:** 高通量筛选技术（如显微成像）在药物发现中至关重要，但由于细胞系间的形态和生物学异质性，对“从头”细胞系进行稳健的扰动筛选仍然具有挑战性。

**Method:** 提出一个新框架，将外部生物学知识整合到现有的预训练策略中。该方法明确解耦扰动特异性和细胞系特异性表示。具体地，构建一个利用STRING和Hetionet数据库蛋白质相互作用数据的知识图谱，以引导模型在预训练期间关注扰动特异性特征；同时，结合来自单细胞基础模型的转录组特征来捕获细胞系特异性表示。在RxRx数据库上通过单次微调RxRx1细胞系和少量微调RxRx19a数据集中的细胞系进行评估。

**Result:** 实验结果表明，该方法增强了对“从头”细胞系的显微图像分析能力。

**Conclusion:** 该方法有效提高了显微图像分析模型对“从头”细胞系的泛化能力，突显了其在现实世界基于表型的药物发现应用中的有效性。

> **ai_Abstract:** 本文提出了一个新颖的框架，旨在解决高通量显微图像分析中“从头”细胞系筛选的挑战。该框架通过整合外部生物学知识（如知识图谱和转录组特征），明确解耦了扰动特异性和细胞系特异性表示。这种方法提高了成像模型对新细胞系的泛化能力。在RxRx数据集上的实验证明，该方法有效增强了显微图像分析性能，尤其适用于药物发现应用。

> **摘要翻译:** 高通量筛选技术，例如细胞对遗传和化学扰动反应的显微成像，在药物发现和生物医学研究中发挥着关键作用。然而，由于细胞系间显著的形态和生物学异质性，对从头细胞系进行稳健的扰动筛选仍然具有挑战性。为了解决这个问题，我们提出了一个新颖的框架，该框架将外部生物学知识整合到现有的预训练策略中，以增强显微图像分析模型。我们的方法利用外部生物学信息明确地解耦扰动特异性和细胞系特异性表示。具体来说，我们构建了一个知识图谱，利用STRING和Hetionet数据库中的蛋白质相互作用数据，在预训练期间引导模型关注扰动特异性特征。此外，我们整合了来自单细胞基础模型的转录组特征，以捕获细胞系特异性表示。通过学习这些解耦的特征，我们的方法提高了成像模型对从头细胞系的泛化能力。我们在RxRx数据库上评估了我们的框架，通过对RxRx1细胞系进行一次性微调和对RxRx19a数据集中的细胞系进行少量微调。实验结果表明，我们的方法增强了对从头细胞系的显微图像分析能力，突显了其在现实世界基于表型的药物发现应用中的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [565] [Automatic Road Subsurface Distress Recognition from Ground Penetrating Radar Images using Deep Learning-based Cross-verification](https://arxiv.org/abs/2507.11081)
> *深度学习交叉验证的探地雷达图像路面地下病害自动识别*

*Chang Peng, Bao Yang, Meiqi Li, Ge Zhang, Hui Sun, Zhenyu Jiang* | **Category: cs.CV, cs.AI, I.4.9; I.5.4; J.2** | **Updated: 2025-07-15**

**Keywords:** 探地雷达, 路面地下病害, 深度学习, 交叉验证, YOLO

**Comment:** 

> **TL;DR:** 探地雷达（GPR）的路面地下病害（RSD）识别目前依赖人工且受限于深度学习模型的数据和能力。本研究构建了一个包含2134个样本的3D GPR数据集，并提出了一种基于YOLO模型的交叉验证策略，实现了超过98.6%的召回率，并将检测工作量减少了约90%。

**AI_Comments:** 该论文通过解决GPR图像深度学习分析中数据稀缺和模型泛化能力的关键问题，做出了重要贡献。构建一个大型、经过验证的3D GPR数据集是一项显著成就。创新的交叉验证策略巧妙地利用了YOLO模型对不同RSD类型的不同敏感性，提高了在挑战性领域的准确性和可靠性。将劳动量减少90%的实际影响突出了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 当前基于探地雷达（GPR）的路面地下病害（RSD）识别劳动强度大，且严重依赖检测员的专业知识。尽管深度学习提供了自动识别的可能性，但其性能受到高质量训练数据集稀缺和网络区分RSD能力不足的限制。

**Method:** 1. 通过现场扫描构建了一个包含2134个不同类型样本的经过严格验证的3D GPR数据集。2. 基于观察到用不同GPR扫描图像训练的YOLO模型对特定RSD类型表现出不同敏感性。3. 提出了一种新颖的交叉验证策略。4. 将该方法集成到在线RSD检测系统中。

**Result:** 1. 在RSD识别方面取得了出色的准确性。2. 在现场测试中召回率超过98.6%。3. 可将检测工作量减少约90%。

**Conclusion:** 本研究提出的基于深度学习交叉验证的探地雷达图像路面地下病害识别方法，通过构建高质量数据集和采用创新的交叉验证策略，显著提高了识别准确性（现场测试召回率超过98.6%），并大幅降低了检测工作量（约90%）。

> **ai_Abstract:** 本文旨在解决探地雷达（GPR）图像路面地下病害（RSD）识别中人工依赖和专家知识需求高的问题。研究构建了一个大规模、经过严格验证的3D GPR数据集，并提出了一种基于YOLO模型的深度学习交叉验证新策略。该方法显著提高了RSD识别的准确性，在现场测试中实现了超过98.6%的召回率，并能将在线检测系统中的检测工作量减少约90%。

> **摘要翻译:** 探地雷达（GPR）已成为一种快速、无损的路面地下病害（RSD）检测解决方案。然而，从GPR图像中识别RSD劳动强度大，且严重依赖检测员的专业知识。深度学习为自动RSD识别提供了可能性，但其当前性能受到两个因素的限制：用于网络训练的高质量数据集稀缺以及网络区分RSD的能力不足。在本研究中，通过现场扫描构建了一个包含2134个不同类型样本的经过严格验证的3D GPR数据集。基于YOLO模型在三种GPR扫描图像之一上训练后对特定类型RSD表现出不同敏感性的发现，我们提出了一种新颖的交叉验证策略，在RSD识别方面具有出色的准确性，在现场测试中召回率超过98.6%。该方法集成到在线RSD检测系统中，可将检测工作量减少约90%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [568] [What Demands Attention in Urban Street Scenes? From Scene Understanding towards Road Safety: A Survey of Vision-driven Datasets and Studies](https://arxiv.org/abs/2507.06513)
> *城市街景中什么需要关注？从场景理解到道路安全：一项关于视觉驱动数据集和研究的综述*

*Yaoqi Huang, Julie Stephany Berrio, Mao Shan, Stewart Worrall* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 道路安全, 视觉驱动数据集, 交通场景, 计算机视觉, 综述

**Comment:** 45 pages, 52 figures, 2 large tables (divided into 5), 73 datatsets,
  35 tasks

> **TL;DR:** 该综述系统地分类了交通场景中需要关注的关键要素，并全面分析了可用的视觉驱动任务和数据集，以促进道路安全应用。

**AI_Comments:** 该论文通过提出一个创新的分类法来整合不同领域的数据集和任务，为道路安全领域的视觉驱动研究提供了一个统一的分析框架。其对大量数据集和任务的全面审查和可视化，以及对现有弱点和未来方向的讨论，对于指导研究人员和优化资源配置具有重要意义。这对于推动该领域的发展具有显著的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 为了促进将基于视觉的传感器和计算机视觉算法的进步应用于道路安全，本综述旨在系统地分类交通场景中需要关注的关键要素，并全面分析可用的视觉驱动任务和数据集。

**Method:** 本综述通过提出一个新分类法来系统地对交通场景中值得关注的实体进行分类，该分类法将实体分为异常和正常但关键实体两大组，整合了十个类别和二十个子类。它分析了35项视觉驱动任务，并基于所提出的分类法对73个可用数据集进行了全面检查和可视化。此外，还进行了跨领域调查，涵盖了每个基准的优缺点，以提供有关标准统一和资源优化的信息。

**Result:** 本综述提出了一个集成的分类法，将交通场景中值得关注的实体分为异常和正常但关键实体两大组，包含十个类别和二十个子类，并建立了相关领域之间的联系。它对35项视觉驱动任务和73个可用数据集进行了全面的分析和可视化，揭示了每个基准的优缺点，旨在促进标准统一和资源优化。

**Conclusion:** 文章最后系统地讨论了现有弱点，并从各种角度强调了潜在影响和有前景的解决方案。所集成的分类法、全面分析和总结性表格为研究人员提供了全面的概览，指导了战略性资源选择，并突出了关键研究空白，为这一快速发展的领域做出了宝贵贡献。

> **ai_Abstract:** 本综述旨在通过系统分类交通场景中需要关注的关键要素并全面分析视觉驱动任务和数据集，以促进计算机视觉在道路安全中的应用。它提出了一个新颖的分类法，将交通实体分为异常和正常但关键两大类，并整合了十个类别和二十个子类。该综述分析了35项任务和73个数据集，旨在统一标准和优化资源，并讨论了现有挑战和潜在解决方案，为研究人员提供了全面的概览和指导。

> **摘要翻译:** 基于视觉的传感器和计算机视觉算法的进步显著改善了交通场景的分析和理解。为了促进将这些改进应用于道路安全，本综述系统地分类了交通场景中需要关注的关键要素，并全面分析了可用的视觉驱动任务和数据集。与现有专注于孤立领域的综述相比，我们的分类法将值得关注的交通实体分为两大组：异常和正常但关键实体，整合了十个类别和二十个子类。它建立了固有相关领域之间的联系，并提供了一个统一的分析框架。我们的综述重点分析了35项视觉驱动任务，并基于所提出的分类法对73个可用数据集进行了全面检查和可视化。跨领域调查涵盖了每个基准的优缺点，旨在提供有关标准统一和资源优化的信息。我们的文章最后系统地讨论了现有弱点，并从各种角度强调了潜在影响和有前景的解决方案。所集成的分类法、全面分析和总结性表格为这一快速发展的领域做出了宝贵贡献，为研究人员提供了全面的概览，指导了战略性资源选择，并突出了关键研究空白。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [581] [ED$^4$: Explicit Data-level Debiasing for Deepfake Detection](https://arxiv.org/abs/2408.06779)
> *ED$^4$: 深度伪造检测的显式数据级去偏*

*Jikang Cheng, Ying Zhang, Qin Zou, Zhiyuan Yan, Chao Liang, Zhongyuan Wang, Chen Li* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 深度伪造检测, 数据级去偏, 空间偏差, ClockMix, 对抗性空间一致性模块

**Comment:** 

> **TL;DR:** ED$^4$是一种数据级去偏策略，通过ClockMix和AdvSCM解决深度伪造检测中的内容、特定伪造和空间偏差，以提高模型的泛化能力。

**AI_Comments:** 该论文的创新点在于揭示并解决了深度伪造检测中的“空间偏差”，即检测器倾向于在图像中心寻找伪造线索。通过提出ClockMix和AdvSCM在数据层面进行显式去偏，而非依赖复杂的网络设计，ED$^4$提供了一种通用且易于集成的解决方案，有望显著提升深度伪造检测模型的泛化能力。其模型无关的特性使其具有广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度伪造检测方法因从有限数据中学习到内在偏差（包括内容偏差、特定伪造偏差以及新发现的空间偏差，即检测器倾向于在图像中心寻找伪造线索）而导致泛化能力差。

**Method:** ED$^4$是一种数据级去偏策略，包含两个主要组件：1. ClockMix：生成面部结构保留的混合样本，以指数级扩展数据分布，增加身份、背景、局部操作痕迹和多种伪造工件的共现多样性。2. 对抗性空间一致性模块（AdvSCM）：通过对抗性生成空间不一致的图像并约束其提取的特征保持一致，以防止提取具有空间偏差的特征。ED$^4$是模型无关且即插即用的。

**Result:** 广泛的实验证明了ED$^4$的有效性及其优于现有深度伪造检测方法的优势。

**Conclusion:** ED$^4$是一种简单、有效且即插即用的数据级去偏策略，通过统一框架解决了深度伪造检测中的多种偏差（包括新颖的空间偏差），显著提高了模型的泛化能力。

> **ai_Abstract:** 该论文提出了ED$^4$，一种用于深度伪造检测的显式数据级去偏策略，旨在解决现有方法因学习有限数据中的内在偏差（包括内容、特定伪造和新发现的空间偏差）而导致的泛化能力差问题。ED$^4$包含ClockMix，用于生成多样化的混合样本以扩展数据分布，以及对抗性空间一致性模块（AdvSCM），用于消除空间偏差。作为一个模型无关的即插即用策略，ED$^4$能够显著提升各种深度伪造检测器的性能和泛化能力。

> **摘要翻译:** 学习有限数据中的内在偏差被认为是深度伪造检测泛化能力差的主要原因。除了已发现的内容偏差和特定伪造偏差外，我们还揭示了一种新颖的空间偏差，即检测器习惯性地预期在图像中心观察到结构伪造线索，这也可能导致现有方法的泛化能力差。我们提出了ED$^4$，一种简单有效的策略，在一个统一的框架中显式地在数据层面解决上述偏差，而不是通过网络设计进行隐式解耦。特别是，我们开发了ClockMix来生成具有任意样本的面部结构保留混合，这使得检测器能够从呈指数级扩展的数据分布中学习，该分布具有更多样化的身份、背景、局部操纵痕迹以及多种伪造工件的共现。我们进一步提出了对抗性空间一致性模块（AdvSCM）来防止提取具有空间偏差的特征，该模块对抗性地生成空间不一致的图像并约束其提取的特征保持一致。作为一种模型无关的去偏策略，ED$^4$是即插即用的：它可以与各种深度伪造检测器集成以获得显著的益处。我们进行了广泛的实验来证明其有效性以及优于现有深度伪造检测方法的优势。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [587] [Detección y Cuantificación de Erosión Fluvial con Visión Artificial](https://arxiv.org/abs/2507.11301)
> *基于计算机视觉的河流侵蚀检测与量化*

*Paúl Maji, Marlon Túquerres, Stalin Valencia, Marcela Valenzuela, Christian Mejia-Escobar* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 河流侵蚀, 计算机视觉, YOLOv11, 人工智能, EROSCAN

**Comment:** 18 pages, in Spanish language, 13 figures, 4 tables

> **TL;DR:** 本研究提出了一种基于人工智能的方法，利用微调后的YOLOv11模型自动检测和量化河流侵蚀，准确率达到70%，并开发了一个交互式Web应用EROSCAN。

**AI_Comments:** 本研究通过将先进的计算机视觉技术（YOLOv11）应用于河流侵蚀检测这一实际问题，展现了创新性。结合照片和LiDAR图像的数据集训练方法以及开发交互式Web应用EROSCAN，显著提升了技术的实用性和可访问性，使其能够被非专业人士用于决策支持。尽管70%的准确率是一个有希望的起点，未来工作可在提高模型性能方面进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 传统的河流侵蚀检测和监测方法（摄影测量和地理信息系统分析）需要专业知识和大量人工处理，效率低下。

**Method:** 提出了一种基于人工智能的方法，使用经过微调并结合照片和LiDAR图像训练的YOLOv11计算机视觉模型。数据集通过Roboflow平台进行分割和标注。开发了一个名为EROSCAN的交互式Web应用程序。

**Result:** 实验结果表明，该方法能够高效检测侵蚀模式，准确率为70%，能精确识别侵蚀区域并可靠地计算其在像素和平方米上的范围。最终产品是EROCAN系统。

**Conclusion:** EROCAN系统优化了河流侵蚀的检测和量化，有助于风险管理和区域规划中的决策制定。

> **ai_Abstract:** 本论文介绍了一种利用微调后的YOLOv11模型，通过人工智能方法自动检测和量化河流侵蚀。该方法结合了照片和LiDAR图像进行训练，实现了70%的侵蚀模式检测准确率，并能精确计算侵蚀区域的范围。研究成果包括开发了EROSCAN系统，一个交互式Web应用程序，旨在简化河流侵蚀的检测和量化过程，从而支持风险管理和区域规划中的决策制定。

> **摘要翻译:** 河流侵蚀是一种自然过程，可能对土壤稳定性和战略基础设施产生重大影响。传统上，这种现象的检测和监测通过摄影测量方法和地理信息系统分析来解决。这些任务需要专业知识和大量人工处理。本研究提出了一种基于人工智能的方法，用于自动识别侵蚀区域并估计其面积。研究中使用了最先进的计算机视觉模型YOLOv11，通过微调并使用照片和LiDAR图像进行训练。这个组合数据集使用Roboflow平台进行分割和标注。实验结果表明，该方法能够有效地检测侵蚀模式，准确率达到70%，能够精确识别侵蚀区域并可靠地计算其在像素和平方米上的范围。最终产品是EROCAN系统，这是一个交互式网络应用程序，允许用户上传图像并获得河流侵蚀的自动分割，以及估计的面积。该工具优化了现象的检测和量化，促进了风险管理和区域规划中的决策制定。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [594] [Retinex-RAWMamba: Bridging Demosaicing and Denoising for Low-Light RAW Image Enhancement](https://arxiv.org/abs/2409.07040)
> *Retinex-RAWMamba：弥合去马赛克与去噪之间的鸿沟，实现低光RAW图像增强*

*Xianmin Chen, Longfei Han, Peiliang Huang, Xiaoxu Feng, Dingwen Zhang, Junwei Han* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-15**

**Keywords:** 低光图像增强, RAW图像, 去马赛克, 去噪, Mamba, Retinex

**Comment:** 

> **TL;DR:** 该论文提出了一种名为Retinex-RAWMamba的新方法，它结合了去马赛克和去噪，旨在有效增强低光RAW图像并实现跨域映射的最先进性能。

**AI_Comments:** 该论文的创新点在于将Mamba架构与Retinex分解模块相结合，并通过弥合去马赛克和去噪的鸿沟，有效解决了低光RAW图像增强中长期存在的去噪不足和颜色失真问题。在跨域映射任务上取得的最先进性能，证明了其方法的有效性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 低光图像增强，特别是从RAW域到sRGB域的跨域映射，是一个重大挑战。现有的单阶段方法在去噪性能上受限。现有的两阶段方法通常忽略图像信号处理（ISP）管道中去马赛克的特性，导致在不同光照条件，尤其是在低光场景下出现颜色失真。

**Method:** 本文提出了一种名为RAWMamba的新型Mamba-based方法，专为低光RAW图像定制，能够有效处理具有不同CFA的RAW图像。此外，引入了一个基于Retinex先验的Retinex分解模块（RDM），将光照从反射中解耦，以促进更有效的去噪和自动非线性曝光校正，减少手动线性光照增强的影响。该方法通过弥合去马赛克和去噪之间的鸿沟来实现更好的低光RAW图像增强。

**Result:** 在公共数据集SID和MCR上进行的实验评估表明，所提出的RAWMamba在跨域映射上实现了最先进的性能。

**Conclusion:** Retinex-RAWMamba通过创新性地结合去马赛克和去噪，有效解决了低光RAW图像增强中的挑战，并在跨域映射任务上取得了最先进的性能。

> **ai_Abstract:** 该论文提出了一种名为Retinex-RAWMamba的新型深度学习方法，旨在解决低光RAW图像增强中的挑战。针对现有单阶段方法去噪性能有限和两阶段方法忽略去马赛克导致颜色失真的问题，Retinex-RAWMamba结合了定制的Mamba模型（RAWMamba）来处理不同CFA的RAW图像，并引入了基于Retinex先验的分解模块（RDM）以实现更有效的去噪和自动曝光校正。通过弥合去马赛克和去噪，该方法在SID和MCR数据集上的跨域映射任务中取得了最先进的性能。

> **摘要翻译:** 低光图像增强，特别是在从原始域到sRGB域的跨域任务中，仍然是一个重大挑战。近年来，许多基于深度学习的方法已被开发出来解决这个问题，并显示出有希望的结果。然而，试图统一跨两个域的复杂映射的单阶段方法，导致去噪性能有限。相比之下，现有的两阶段方法通常忽略了图像信号处理（ISP）管道中去马赛克的特性，导致在不同光照条件，特别是在低光场景下出现颜色失真。为了解决这些问题，我们提出了一种针对低光RAW图像定制的新型基于Mamba的方法，称为RAWMamba，以有效处理具有不同CFA的RAW图像。此外，我们引入了一个基于Retinex先验的Retinex分解模块（RDM），它将光照从反射中解耦，以促进更有效的去噪和自动非线性曝光校正，减少手动线性光照增强的影响。通过弥合去马赛克和去噪之间的鸿沟，实现了更好的低光RAW图像增强。在公共数据集SID和MCR上进行的实验评估表明，我们提出的RAWMamba在跨域映射上实现了最先进的性能。代码可在https://github.com/Cynicarlos/RetinexRawMamba 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [595] [Longitudinal Study of Facial Biometrics at the BEZ: Temporal Variance Analysis](https://arxiv.org/abs/2507.06858)
> *BEZ 面部生物识别纵向研究：时间方差分析*

*Mathias Schulz, Alexander Spenke, Pia Funk, Florian Blümel, Markus Rohde, Ralph Breithaupt, Gerd Nolden, Norbert Jung, Robert Lange* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 面部生物识别, 纵向研究, 时间方差, 生物识别评估, BEZ

**Comment:** 11 pages, 10 figures, 8 tables

> **TL;DR:** 一项为期两年半的纵向研究发现，面部生物识别分数在不同日期之间的波动比在整个测量期间的波动更显著，强调了长期受控测试的重要性。

**AI_Comments:** 这项研究的创新之处在于其大规模、长期的纵向设计，以及在受控环境中对生物识别数据进行详细的时间方差分析。其重要性在于揭示了生物识别分数日常波动的显著性，这对于生物识别系统的实际部署和性能评估具有重要指导意义。研究结果为未来更准确、鲁棒的生物识别技术发展提供了基础。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在强调在受控测量环境中长时间测试相同个体生物特征的重要性，并为生物识别数据分析的未来发展奠定基础。

**Method:** 该研究在生物识别评估中心（BEZ）进行，为期两年半，涉及超过400名来自不同种族、性别和年龄组的参与者。研究使用了符合GDPR的本地BEZ数据库，包含超过238,000个生物识别数据集（包括面部和指纹），并利用最先进的面部识别算法分析长期比较分数。

**Result:** 研究结果显示，面部生物识别分数在个体日期之间的波动比在整个测量期间的波动更为显著。

**Conclusion:** 研究强调了在受控测量环境中对同一个体进行长期生物特征测试的重要性，并为生物识别数据分析的未来进展奠定了基础。

> **ai_Abstract:** 本研究在生物识别评估中心（BEZ）进行了一项为期两年半的纵向面部生物识别评估。研究涵盖400多名多样化参与者，利用包含238,000多个数据集的BEZ数据库和先进的面部识别算法进行分析。核心发现是面部识别分数在不同日期之间的波动比在整个测量期间的波动更显著。这强调了在受控环境下进行长期生物特征测试的重要性，并为未来的生物识别数据分析奠定基础。

> **摘要翻译:** 本研究展示了在生物识别评估中心 (BEZ) 进行的长期生物识别评估结果。在两年半的时间里，我们对400多名代表不同种族、性别和年龄组的参与者进行了持续研究，并在受控测试设施中定期使用各种生物识别工具和技术进行评估。我们的研究结果基于符合通用数据保护条例的本地 BEZ 数据库，该数据库包含超过238,000个生物识别数据集，分为面部和指纹等多种生物识别模式。我们使用最先进的面部识别算法来分析长期比较分数。我们的结果表明，这些分数在个体日期之间的波动比在整个测量期间的波动更显著。这些发现强调了在受控测量环境中长时间测试相同个体生物特征的重要性，并为生物识别数据分析的未来发展奠定基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [614] [Atmos-Bench: 3D Atmospheric Structures for Climate Insight](https://arxiv.org/abs/2507.11085)
> *Atmos-Bench：用于气候洞察的3D大气结构*

*Tianchi Xu* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 3D大气结构, 激光雷达, 大气基准, FourCastX, 气候洞察

**Comment:** 

> **TL;DR:** 论文提出了Atmos-Bench，首个3D大气基准数据集，以及FourCastX模型，用于从卫星激光雷达数据中恢复3D大气结构，无需辅助输入并优于现有方法，为气候研究提供更深洞察。

**AI_Comments:** Atmos-Bench的创新性在于首次提供了一个标准化的3D大气基准数据集，这对于公平评估和推动该领域的研究至关重要。FourCastX模型通过结合物理约束和无需辅助输入的特点，显著提高了3D大气结构恢复的准确性和实用性，对气候理解和极端天气预报具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在从卫星激光雷达数据恢复3D大气结构时，常依赖辅助输入和简化物理近似，并缺乏标准化的3D基准数据集进行公平评估，这可能引入不确定性并无法充分捕获真实的辐射传输和大气散射-吸收效应。

**Method:** 提出了Atmos-Bench，首个3D大气基准数据集，以及一种新颖的FourCastX：频率增强时空混合专家网络。FourCastX通过耦合WRF和增强型COSP模拟器生成了921,600个图像切片（来自532 nm和355 nm的3D散射体积），嵌入了ATB-BC物理约束以促进恢复过程中的能量一致性。

**Result:** FourCastX模型在Atmos-Bench数据集上，在355 nm和532 nm波段都取得了持续改进，性能优于最先进的基线模型，且无需依赖辅助输入。

**Conclusion:** Atmos-Bench为基于卫星的3D大气结构恢复建立了新标准，并为更深入的气候洞察铺平了道路。

> **ai_Abstract:** 本文介绍了Atmos-Bench，这是首个用于评估3D大气结构恢复的标准化基准数据集，旨在解决现有方法依赖辅助输入和简化物理模型的问题。同时，论文提出了FourCastX，一个频率增强时空混合专家网络，该网络通过模拟高质量的3D散射体积并嵌入物理约束，实现了从卫星激光雷达数据中恢复3D大气结构，且无需辅助输入即可超越现有技术水平，为气候研究提供了更准确的工具。

> **摘要翻译:** 大气结构，由卫星激光雷达衰减反向散射（ATB）恢复的反向散射系数（BC）表示，提供了云、气溶胶和分子的体积视图，在人类活动、气候理解和极端天气预报中发挥着关键作用。现有方法通常依赖辅助输入和简化的基于物理的近似，并且缺乏标准化的3D基准数据集进行公平评估。然而，这些方法可能会引入额外的F不确定性，并且未能充分捕捉真实的辐射传输和大气散射-吸收效应。为了弥补这些差距，我们提出了Atmos-Bench：第一个3D大气基准数据集，以及一种新颖的FourCastX：频率增强时空混合专家网络，它（a）通过将WRF与增强型COSP模拟器耦合，在384个陆海时间步长上模拟532 nm和355 nm波长的3D散射体积，生成了921,600个图像切片，产生了高质量的体素级参考；（b）将ATB-BC物理约束嵌入到模型架构中，促进恢复过程中的能量一致性；（c）在Atmos-Bench数据集上，在355 nm和532 nm波段均取得了持续改进，性能优于最先进的基线模型，且无需依赖辅助输入。Atmos-Bench为基于卫星的3D大气结构恢复建立了新标准，并为更深入的气候洞察铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [619] [Auditing Facial Emotion Recognition Datasets for Posed Expressions and Racial Bias](https://arxiv.org/abs/2507.10755)
> *审计面部情感识别数据集中的摆拍表情和种族偏见*

*Rina Khan, Catherine Stinson* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 面部情感识别, 数据集审计, 摆拍表情, 种族偏见, 公平性

**Comment:** 

> **TL;DR:** 本研究审计了两个面部情感识别（FER）数据集，发现其中包含大量摆拍图像，且训练出的模型对非白人或深肤色人群存在负面情绪预测偏见。

**AI_Comments:** 这篇论文的重要性在于它揭示了当前主流面部情感识别数据集存在的两个关键且长期被忽视的问题：摆拍图像的混入和固有的种族偏见。通过提出一种识别摆拍图像的方法并进行实际审计，论文为未来数据集的构建和评估提供了宝贵的指导。其对种族偏见的揭露也强调了AI伦理在数据层面的重要性，对后续模型的公平性研究具有深远影响。

<details>
  <summary>Details</summary>

**Motivation:** 面部情感识别（FER）算法在检测自发表情时性能下降，并且对不同种族和肤色人群的性能表现不佳。这些挑战与FER数据集的数据收集实践有关。

**Method:** 研究审计了两个最先进的FER数据集，随机抽取样本，检查图像是自发还是摆拍，并提出了一种识别自发或摆拍图像的方法。同时，观察样本中个体的肤色，并测试了三个在这些数据集上训练的模型，以预测不同种族和肤色人群的面部表情。

**Result:** 发现声称由“野外”图像组成的数据集中存在大量摆拍图像。审计的FER模型更倾向于将非白人或深肤色人群预测为表现出负面情绪（如愤怒或悲伤），即使他们正在微笑。

**Conclusion:** 由于自发和摆拍图像的性能差异，在这些数据集上训练的模型性能不能代表在真实“野外”应用中的真实性能。这种偏见使得这些模型在现实应用中容易造成伤害。

> **ai_Abstract:** 本研究审计了两个主流面部情感识别（FER）数据集，旨在揭示数据收集中的两个关键问题：摆拍表情的普遍存在和潜在的种族偏见。研究提出了一种识别摆拍图像的方法，并发现大量声称是“野外”的图像实为摆拍。此外，实验表明，训练出的FER模型对非白人或深肤色人群存在显著的负面情绪预测偏见，即使在微笑时也常被误判为愤怒或悲伤。这些发现强调了当前FER数据集的局限性及其对模型真实性能和实际应用中潜在危害的影响。

> **摘要翻译:** 面部表情识别（FER）算法将面部表情分类为快乐、悲伤或愤怒等情绪。FER算法面临的一个评估挑战是，与摆拍表情相比，检测自发表情时性能下降。FER算法面临的一个伦理（和评估）挑战是，它们往往对某些种族和肤色的人表现不佳。这些挑战与FER数据集创建中采用的数据收集实践有关。在本研究中，我们审计了两个最先进的FER数据集。我们从每个数据集中随机抽取样本，检查图像是自发还是摆拍。在此过程中，我们提出了一种识别自发或摆拍图像的方法。我们发现，在声称由“野外”图像组成的数据集中，存在大量摆拍图像。由于FER模型在自发和摆拍图像之间的性能有所不同，如果在“野外”应用中部署这些模型，那么在这些数据集上训练的模型性能将无法代表真实性能。我们还观察了样本中个体的肤色，并测试了三个在每个数据集上训练的模型，以预测来自不同种族和肤色人群的面部表情。我们发现，审计的FER模型更倾向于将标记为非白人或被确定为深肤色的人预测为表现出负面情绪，例如愤怒或悲伤，即使他们正在微笑。这种偏见使得此类模型在现实生活中容易造成伤害。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [620] [Women Sport Actions Dataset for Visual Classification Using Small Scale Training Data](https://arxiv.org/abs/2507.10969)
> *小规模训练数据用于视觉分类的女性体育动作数据集*

*Palash Ray, Mahuya Sasmal, Asish Bera* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 女性体育动作, 数据集, 视觉分类, 卷积神经网络, 通道注意力

**Comment:** 

> **TL;DR:** 本文提出了一个名为 WomenSports 的新数据集，用于女性体育动作的视觉分类，并提出了一种基于 CNN 的深度特征提取方法，在小规模数据上取得了显著的分类性能。

**AI_Comments:** 本文的创新点在于构建并公开了一个急需的女性体育动作数据集，这直接解决了该领域数据稀缺的痛点。同时，提出的结合 CNN 和通道注意力机制的方法，在小规模训练数据下仍能取得不错的分类性能，显示了其有效性。该工作对于促进图像识别在女性体育分析领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究在图像识别的体育动作分类领域取得了进展，但缺乏足够且多样化的女性体育动作图像数据集，这限制了该领域的研究进展。

**Method:** 本文提出了一个名为 WomenSports 的新数据集，该数据集包含多样化的女性体育活动，涵盖了动作、环境和玩家互动方面的广泛变化。此外，研究还提出了一种基于卷积神经网络（CNN）的深度特征提取方法，并引入了局部上下文区域的通道注意力机制来优化和增强特征表示。

**Result:** 实验在三个不同的体育数据集和一个舞蹈数据集上进行，验证了所提出算法的泛化能力，并取得了显著的性能。在提出的 WomenSports 数据集上，使用 ResNet-50 的深度学习方法实现了 89.15% 的 Top-1 分类准确率。

**Conclusion:** 本文成功创建并公开了一个新的女性体育动作数据集 WomenSports，并提出了一种结合 CNN 和通道注意力机制的深度学习方法，有效解决了女性体育动作分类中数据不足的问题，并取得了令人满意的分类性能。

> **ai_Abstract:** 本文针对当前女性体育动作分类领域缺乏足够图像数据集的限制，提出了一个新的名为 WomenSports 的数据集，该数据集包含多样化的女性体育活动。同时，研究还提出了一种基于卷积神经网络（CNN）的深度特征提取方法，并结合了通道注意力机制以优化特征表示。实验结果表明，该方法在 WomenSports 数据集上取得了 89.15% 的 Top-1 分类准确率，并验证了其在其他数据集上的泛化能力。该数据集已公开可用，为相关研究提供了宝贵资源。

> **摘要翻译:** 体育动作分类代表着复杂的身体姿态和玩家-物体互动，是基于图像的体育分析领域的新兴方向。在过去几十年中，一些工作为使用机器学习技术进行自动化体育动作识别做出了贡献。然而，研究人员缺乏足够且具有足够类内和类间变化的女性体育动作图像数据集。为了克服这一限制，这项工作提出了一个名为 WomenSports 的新数据集，用于使用小规模训练数据进行女性体育分类。该数据集包含各种体育活动，涵盖了动作、环境和玩家之间互动的广泛变化。此外，本研究提出了一种用于深度特征提取的卷积神经网络（CNN）。在局部上下文区域上应用通道注意力方案来细化和增强特征表示。实验在三个不同的体育数据集和一个舞蹈数据集上进行，以推广所提出的算法，并且在这些数据集上的性能值得关注。深度学习方法在使用 ResNet-50 在所提出的 WomenSports 数据集上实现了 89.15% 的 Top-1 分类准确率，该数据集已在 Mendeley Data 上公开发布供研究使用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [623] [Advancing Depth Anything Model for Unsupervised Monocular Depth Estimation in Endoscopy](https://arxiv.org/abs/2409.07723)
> *推进Depth Anything模型用于内窥镜无监督单目深度估计*

*Bojian Li, Bo Liu, Xinning Yao, Jinghua Yue, Fugen Zhou* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 深度估计, 内窥镜, 无监督学习, Depth Anything, 低秩适应

**Comment:** Accepted by IROS2025, 8 pages, 7 figures

> **TL;DR:** 针对内窥镜图像深度估计问题，本文提出了一种基于Depth Anything模型的无监督单目深度估计新策略，通过低秩适应和残差块提升了性能并减少了参数。

**AI_Comments:** 本文的创新点在于将先进的基础模型Depth Anything引入内窥镜深度估计领域，并针对其在医学图像上的局限性进行了优化。通过结合低秩适应和残差块，有效解决了全局信息捕获与局部特征增强的平衡问题，同时保持了模型效率。这项工作对于提升微创内窥镜手术的安全性与精确度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前大多数深度估计网络依赖传统卷积神经网络，难以捕获全局信息；现有基础模型主要在自然图像上训练，在内窥镜图像上性能不佳。

**Method:** 本文引入了一种新颖的Depth Anything模型微调策略，并将其与基于内参的无监督单目深度估计框架集成。该方法包括基于随机向量的低秩适应技术，以提高模型对不同尺度的适应性；同时，提出了一个基于深度可分离卷积的残差块，以弥补Transformer捕获局部特征能力的不足。

**Result:** 实验结果表明，在SCARED数据集和Hamlyn数据集上，该方法实现了最先进的性能，同时最小化了可训练参数的数量。

**Conclusion:** 该方法在微创内窥镜手术中的应用可以增强外科医生的空间感知能力，从而提高手术的精度和安全性。

> **ai_Abstract:** 本文针对内窥镜图像深度估计中现有方法的局限性，提出了一种改进的无监督单目深度估计方法。该方法基于Depth Anything模型，并引入了新颖的微调策略、低秩适应技术和残差块设计，以增强模型对全局信息和局部特征的捕获能力，同时提高对不同尺度的适应性。实验结果表明，该方法在内窥镜数据集上达到了最先进的性能，并显著减少了模型参数，有望提升微创手术的精度和安全性。

> **摘要翻译:** 深度估计是三维重建的基石，在微创内窥镜手术中发挥着至关重要的作用。然而，目前大多数深度估计网络依赖于传统的卷积神经网络，其捕获全局信息的能力有限。基础模型为增强深度估计提供了一种有前景的方法，但现有模型主要在自然图像上训练，导致在应用于内窥镜图像时性能不佳。在这项工作中，我们为Depth Anything模型引入了一种新颖的微调策略，并将其与基于内参的无监督单目深度估计框架相结合。我们的方法包括基于随机向量的低秩适应技术，这提高了模型对不同尺度的适应性。此外，我们提出了一种基于深度可分离卷积的残差块，以弥补Transformer捕获局部特征能力的不足。我们在SCARED数据集和Hamlyn数据集上的实验结果表明，我们的方法在最小化可训练参数数量的同时，实现了最先进的性能。将此方法应用于微创内窥镜手术可以增强外科医生的空间意识，从而提高手术的精度和安全性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [624] [Driving by Hybrid Navigation: An Online HD-SD Map Association Framework and Benchmark for Autonomous Vehicles](https://arxiv.org/abs/2507.07487)
> *混合导航驾驶：一种面向自动驾驶的在线高清-标清地图关联框架与基准*

*Jiaxu Wan, Xu Wang, Mengwei Xie, Xinyuan Chang, Xinran Liu, Zheng Pan, Mu Xu, Ding Yuan* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 自动驾驶, 混合导航, 地图关联, 高清地图, 标清地图, Transformer

**Comment:** Fix bug for repeat reference

> **TL;DR:** 提出首个混合导航在线地图关联基准OMA和基于Transformer的MAT框架，解决自动驾驶中在线高清地图与全局标清地图关联不足的问题。

**AI_Comments:** 这项工作通过引入第一个针对混合导航在线地图关联的基准OMA，填补了自动驾驶领域的一个重要空白，解决了在线高清地图实际应用中的挑战。Map Association Transformer (MAT) 框架的提出，利用了先进的注意力机制，为未来的研究提供了有力的基线。其创新性在于不仅识别了问题，还提供了数据集和有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有工作多关注在线高清地图构建，但忽略了全局标清地图与在线高清地图的关联，导致在线高清地图在实际应用中面临挑战，影响自动驾驶规划能力。

**Method:** 引入首个混合导航在线地图关联基准OMA，包含480k道路和260k车道路径及评估指标。提出Map Association Transformer (MAT) 框架作为基线方法，利用路径感知注意力和空间注意力机制来理解几何和拓扑对应关系。

**Result:** OMA基准包含大量道路和车道路径数据，并提供评估指标。提出的MAT框架作为基线方法，能够理解几何和拓扑对应关系。

**Conclusion:** 通过引入OMA基准和MAT框架，解决了自动驾驶中在线高清地图与全局标清地图关联不足的问题，增强了自动驾驶的规划能力。

> **ai_Abstract:** 本文针对自动驾驶中全局标清地图与在线高清地图关联不足的问题，提出了首个混合导航在线地图关联基准OMA，并构建了包含大量道路和车道路径的数据集及评估指标。同时，提出了一种基于Transformer的Map Association Transformer (MAT) 框架作为基线方法，通过路径感知注意力和空间注意力机制来理解地图的几何和拓扑对应关系，旨在提升自动驾驶车辆的规划能力。

> **摘要翻译:** 自动驾驶车辆依赖全局标清（SD）地图进行道路级路径规划，并依赖在线局部高清（HD）地图进行车道级导航。然而，最近的工作主要集中于构建在线高清地图，往往忽视了全局标清地图与在线高清地图的关联，这使得在线高清地图在现实世界中难以利用。鉴于自动驾驶车辆在导航能力方面的不足，我们引入了“在线地图关联”（Online Map Association, OMA），这是第一个面向混合导航在线地图关联的基准，它增强了自动驾驶车辆的规划能力。基于现有数据集，OMA包含48万条道路和26万条车道路径，并提供了相应的指标来评估模型的性能。此外，我们提出了一种名为“地图关联Transformer”（Map Association Transformer）的新颖框架作为基线方法，该框架利用路径感知注意力和空间注意力机制，以实现对几何和拓扑对应关系的理解。代码和数据集可在https://github.com/WallelWan/OMA-MAT 访问。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [636] [A Mixed-Primitive-based Gaussian Splatting Method for Surface Reconstruction](https://arxiv.org/abs/2507.11321)
> *基于混合图元的高斯泼溅表面重建方法*

*Haoxuan Qu, Yujun Cai, Hossein Rahmani, Ajay Kumar, Junsong Yuan, Jun Liu* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 高斯泼溅, 表面重建, 混合图元, 组合式泼溅, 顶点剪枝

**Comment:** 

> **TL;DR:** 现有高斯泼溅方法使用单一图元重建表面质量不足，本文首次提出一种混合图元的高斯泼溅框架，显著提升表面重建精度。

**AI_Comments:** 这篇论文的创新点在于首次将混合几何图元引入高斯泼溅框架进行表面重建，解决了现有方法单一图元表示能力不足的局限。通过引入组合式泼溅策略和优化机制，显著提升了复杂表面重建的精度，为高斯泼溅在三维重建领域的应用开辟了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的高斯泼溅（GS）方法在表面重建中仅使用单一类型的泼溅图元（高斯椭圆或高斯椭球）来表示物体表面，这对于真实世界中复杂多样的三维物体形状来说，可能不足以实现高质量的表面表示。

**Method:** 提出一个新颖的框架，首次使高斯泼溅能够在表面重建过程中结合多种几何图元。具体包括：1) 提出组合式泼溅策略，以实现在高斯泼溅管道中不同类型图元的泼溅和渲染；2) 设计基于混合图元的初始化策略；3) 引入顶点剪枝机制，以进一步促进其利用不同类型图元的表面表示学习过程。

**Result:** 广泛的实验表明，所提出的框架有效且具有准确的表面重建性能。

**Conclusion:** 通过引入混合图元、组合式泼溅策略、混合图元初始化和顶点剪枝机制，本文提出的高斯泼溅方法显著提升了表面重建的质量和精度。

> **ai_Abstract:** 本文针对现有高斯泼溅（GS）表面重建方法仅使用单一图元导致表示质量不足的问题，提出了一种创新的混合图元高斯泼溅框架。该框架首次将多种几何图元整合到GS管道中，并通过组合式泼溅策略、混合图元初始化和顶点剪枝机制，显著提升了复杂物体表面的重建精度和质量。实验验证了其有效性。

> **摘要翻译:** 近来，高斯泼溅（GS）在表面重建领域受到了广泛关注。然而，尽管真实世界中的三维物体具有复杂多样的形状，现有的基于GS的方法在重建过程中仅有限地使用单一类型的泼溅图元（高斯椭圆或高斯椭球）来表示物体表面。在本文中，我们强调这可能不足以高质量地表示物体表面。因此，我们提出了一个新颖的框架，首次使高斯泼溅能够在表面重建过程中结合多种类型的（几何）图元。具体而言，在我们的框架中，我们首先提出了一种组合式泼溅策略，使得不同类型的图元可以在高斯泼溅管道中进行泼溅和渲染。此外，我们还设计了基于混合图元的初始化策略和顶点剪枝机制，以进一步促进其表面表示学习过程能够利用不同类型的图元得到良好执行。广泛的实验表明，我们的框架是有效的，并具有准确的表面重建性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [643] [A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation](https://arxiv.org/abs/2411.16370)
> *深度概率图像分割中贝叶斯不确定性量化综述*

*M. M. A. Valiuddin, R. J. G. van Sloun, C. G. A. Viviers, P. H. N. de With, F. van der Sommen* | **Category: cs.CV, cs.AI, cs.LG, eess.IV, stat.ML** | **Updated: 2025-07-15**

**Keywords:** 贝叶斯不确定性, 图像分割, 概率模型, 主动学习, 深度学习

**Comment:** 31 pages of content, revised

> **TL;DR:** 本综述整合了深度概率图像分割中贝叶斯不确定性量化方面的分散文献，区分了不确定性类型，探讨了其在下游任务中的作用，指出了挑战，并提出了未来发展方向，旨在开发更可靠的模型。

**AI_Comments:** 这篇综述很重要，因为它解决了深度学习语义分割中的一个关键空白：缺乏鲁棒的不确定性量化。通过整合分散的文献、区分不确定性类型、识别挑战并提出未来方向，它为研究人员开发更可靠、值得信赖的AI模型提供了宝贵的路线图，尤其是在需要不确定性信息进行决策的现实世界应用中。其对实用策略和特定架构改进（如基于Transformer的骨干网络）的关注增加了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习语义分割模型通常依赖宽松的贝叶斯假设，导致关键不确定性信息缺失，仅依赖点估计，且概率分割领域文献分散，阻碍了鲁棒决策。本综述旨在整合并提供一个连贯的基础。

**Method:** 本综述通过整合和情境化不确定性建模的基础概念（包括区分认知和偶然不确定性），检查其在四个下游分割任务中的作用（突出主动学习），统一理论、术语和应用，识别关键挑战（如空间聚合的强假设、缺乏标准化基准、现有方法缺陷），观察趋势（如生成模型的采用、无分布/无采样方法），并提出未来发展方向（如分离不确定性来源、新颖建模方法、改进Transformer骨干网络）。

**Result:** 综述强调主动学习在下游任务中具有特别前景。它指出了关键挑战，包括空间聚合中的强假设、缺乏标准化基准以及当前不确定性量化方法的缺陷。同时，它观察到当代生成模型的应用趋势以及对无分布和无采样不确定性估计方法日益增长的兴趣。

**Conclusion:** 本综述旨在为研究人员提供连贯的基础，识别关键挑战，并提出推进深度学习中不确定性感知分割的方向，以支持开发更可靠、高效和可解释的分割模型，从而有效地将不确定性纳入现实世界应用。

> **ai_Abstract:** 本综述旨在解决深度概率图像分割中贝叶斯不确定性量化文献的分散问题。它整合了不确定性建模的基础概念，区分了认知不确定性和偶然不确定性，并探讨了它们在下游任务（尤其主动学习）中的作用。论文统一了理论与应用，指出了空间聚合假设过强、缺乏标准化基准等关键挑战，并观察到生成模型和无分布/无采样方法的应用趋势。最后，它提出了未来发展方向，以期开发更可靠、可解释的不确定性感知分割模型。

> **摘要翻译:** 在架构设计、数据可用性和计算方面的进步推动了语义分割的显著进展。然而，这些模型通常依赖于宽松的贝叶斯假设，省略了鲁棒决策所需的关键不确定性信息。由此导致的对点估计的依赖推动了对概率分割的兴趣，但现有文献仍然分散。
作为回应，本综述整合并情境化了不确定性建模的基础概念，包括区分认知不确定性（epistemic uncertainty）和偶然不确定性（aleatoric uncertainty）这一非平凡任务，并检查了它们在四个关键下游分割任务中的作用，其中强调主动学习（Active Learning）特别有前景。
通过统一理论、术语和应用，我们为研究人员提供了连贯的基础，并指出了关键挑战，例如空间聚合中的强假设、缺乏标准化基准以及当前不确定性量化方法中的缺陷。
我们识别出一些趋势，例如在生成建模更广泛领域进步的推动下，当代生成模型的采用，其中分割特定的创新主要在于条件机制。此外，我们观察到对无分布和无采样不确定性估计方法的兴趣日益增长。
我们进一步提出了推动深度学习中不确定性感知分割的方向，包括分离不同不确定性来源的实用策略、新颖的不确定性建模方法以及改进的基于Transformer的骨干网络。通过这种方式，我们旨在支持开发更可靠、高效和可解释的分割模型，这些模型能有效地将不确定性纳入现实世界应用中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [652] [HiM2SAM: Enhancing SAM2 with Hierarchical Motion Estimation and Memory Optimization towards Long-term Tracking](https://arxiv.org/abs/2507.07603)
> *HiM2SAM：通过分层运动估计和内存优化增强SAM2以实现长期跟踪*

*Ruixiang Chen, Guolei Sun, Yawei Li, Jie Qin, Luca Benini* | **Category: cs.CV** | **Updated: 2025-07-14**

**Keywords:** 视频目标跟踪, SAM2增强, 分层运动估计, 内存优化, 长期跟踪

**Comment:** 

> **TL;DR:** HiM2SAM通过分层运动估计和内存优化改进了SAM2，无需额外训练即可在长期视频跟踪任务中实现最先进的性能。

**AI_Comments:** HiM2SAM的创新之处在于其“无需训练”和“低开销”的改进方法，这对于实际应用具有重要意义。通过结合分层运动估计和优化的内存管理，它有效地提升了长期跟踪的鲁棒性和精度，特别是在处理遮挡和外观变化方面。其在不同模型规模上的一致性改进也表明了方法的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决视频目标跟踪中的挑战，如遮挡、背景杂乱和目标再现，并增强SAM2框架的性能。

**Method:** 本文引入了分层运动估计策略，结合了轻量级线性预测和选择性非线性细化。此外，通过区分长期和短期记忆帧来优化内存库。

**Result:** HiM2SAM在不同模型规模上均显示出一致的改进。在大模型上，在LaSOT和LaSOText上实现了最先进的性能，相对于原始SAM2，AUC分别提高了9.6%和7.2%。在较小模型上，相对增益更大。

**Conclusion:** 本文提出的无需训练、低开销的改进方法能有效提升长期跟踪性能。

> **ai_Abstract:** 本文提出了HiM2SAM，一个对SAM2框架的增强，旨在解决视频目标跟踪中的遮挡、背景杂乱和目标再现问题。它引入了分层运动估计策略和优化的内存库（区分长期和短期帧），从而在不增加训练成本的情况下提高了跟踪精度和可靠性。实验证明，HiM2SAM在LaSOT和LaSOText数据集上实现了最先进的性能，并在各种模型规模上展现了显著的改进。

> **摘要翻译:** 本文介绍了对SAM2框架在视频目标跟踪任务中的增强，解决了遮挡、背景杂乱和目标再现等挑战。我们引入了一种分层运动估计策略，结合了轻量级线性预测和选择性非线性细化，以提高跟踪精度，而无需额外的训练。此外，我们通过区分长期和短期记忆帧来优化内存库，从而在长期遮挡和外观变化下实现更可靠的跟踪。实验结果表明，在不同模型规模上均有持续改进。我们的大模型在LaSOT和LaSOText上取得了最先进的性能，相对于原始SAM2，AUC分别提高了9.6%和7.2%，并且在较小模型上表现出更大的相对增益，突显了我们无需训练、低开销的改进方法对提升长期跟踪性能的有效性。代码可在https://github.com/LouisFinner/HiM2SAM获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [656] [A Survey on Interpretability in Visual Recognition](https://arxiv.org/abs/2507.11099)
> *视觉识别可解释性综述*

*Qiyang Wan, Chengzhi Gao, Ruiping Wang, Xilin Chen* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 可解释性, 视觉识别, XAI, 综述, 分类法

**Comment:** 20 pages, 7 figures, 2 tables. Under review

> **TL;DR:** 一篇关于视觉识别可解释性的综述，提出了一个人本中心的分类法，并讨论了评估要求和新机遇。

**AI_Comments:** 这篇论文为视觉识别可解释性这一快速发展的领域提供了宝贵的结构化概述。其以人为中心的分类法为方法归类提供了新颖的视角，具有创新性。对评估指标和新机遇（特别是大型多模态模型）的讨论，突显了其前瞻性。这篇综述对研究人员理解和贡献XAI领域至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 随着视觉识别方法在自动驾驶和医疗诊断等关键领域的广泛应用，理解模型机制和诊断故障的需求日益增长，这推动了可解释性研究的发展。

**Method:** 本文系统性地回顾了现有视觉识别模型可解释性研究，并提出了一个以人为中心的分类法。该分类法根据意图、对象、呈现和方法论对可解释识别方法进行分类。此外，论文还总结了评估指标的要求，并探讨了大型多模态模型等新技术带来的新机遇。

**Result:** 本文建立了一套系统且连贯的XAI方法分组标准，总结了评估指标的要求，并探索了由大型多模态模型等最新技术带来的新机遇。

**Conclusion:** 本文旨在组织该领域现有研究，并启发未来对视觉识别模型可解释性的深入研究。

> **ai_Abstract:** 本综述系统性地回顾了视觉识别模型的可解释性研究，其驱动力在于这些模型在关键应用中日益增长的部署需求。论文提出了一种新颖的人本中心分类法，根据意图、对象、呈现和方法论对可解释方法进行分类。此外，本文还总结了评估指标的要求并探讨了新的机遇，旨在梳理当前知识并指导该关键领域的未来研究。

> **摘要翻译:** 近年来，视觉识别方法取得了显著进展，并在不同领域找到了应用。研究人员在寻求理解这些模型成功机制的同时，也越来越有动力将其部署到自动驾驶和医疗诊断等关键领域，以更好地诊断故障，这促进了可解释性研究的发展。本文系统性地回顾了现有视觉识别模型可解释性研究，并提出了一个以人为中心的分类法。所提出的分类法根据意图、对象、呈现和方法论对可解释识别方法进行分类，从而为这些XAI方法建立了一套系统且连贯的分组标准。此外，我们总结了评估指标的要求，并探讨了大型多模态模型等最新技术带来的新机遇。我们旨在组织该领域现有研究，并启发未来对视觉识别模型可解释性的深入研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [672] [EEG Emotion Copilot: Optimizing Lightweight LLMs for Emotional EEG Interpretation with Assisted Medical Record Generation](https://arxiv.org/abs/2410.00166)
> *EEG Emotion Copilot：优化轻量级LLM用于情感脑电图解释与辅助病历生成*

*Hongyu Chen, Weiming Zeng, Chengcheng Chen, Luhui Cai, Fei Wang, Yuhu Shi, Lei Wang, Wei Zhang, Yueyang Li, Hongjie Yan, Wai Ting Siok, Nizhuan Wang* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 脑电图情绪识别, 轻量级LLM, 情感计算, 病历生成, 脑机接口

**Comment:** 17 pages, 16 figures, 5 tables

> **TL;DR:** 该论文提出了EEG Emotion Copilot，一个优化轻量级LLM的系统，用于实时情感脑电图识别、个性化诊断建议和辅助电子病历生成，解决了现有方法的挑战并提高了性能。

**AI_Comments:** 该论文的创新点在于将轻量级LLM应用于端到端的EEG情感解释和辅助医疗记录生成，有效解决了现有方法在实时性、个体适应性和无缝用户交互方面的挑战。其重要性体现在为医疗领域，尤其是心理健康监测，提供了一种新的、高效的情感计算解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 在情感计算和脑机接口领域，分析生理和行为信号以识别个体情绪状态是一个关键研究前沿。尽管深度学习在脑电图情绪识别方面取得进展，但在实现端到端情绪计算（包括实时处理、个体适应和无缝用户交互）方面仍存在重大挑战。本文旨在解决这些挑战，并推进情感计算在医疗领域的应用。

**Method:** 本文提出了EEG Emotion Copilot系统，该系统优化了一个在本地环境中运行的0.5B参数的轻量级大型语言模型（LLM）。该系统能够直接从EEG信号识别情绪状态，随后生成个性化的诊断和治疗建议，并最终支持辅助电子病历的自动化。具体技术包括新颖的提示数据结构、模型剪枝、微调训练以及旨在提高实时性能和计算效率的部署策略。

**Result:** 广泛的实验表明，我们优化的基于轻量级LLM的copilot在参与者交互方面实现了增强的直观界面，并在情绪识别和辅助电子病历生成方面取得了卓越的准确性。其性能优于参数规模相似或更大的模型（如1.5B、1.8B、3B和7B）。

**Conclusion:** 通过本文的努力，所提出的EEG Emotion Copilot有望推进情感计算在医疗领域的应用，为心理健康监测提供创新解决方案。

> **ai_Abstract:** 本文提出了EEG Emotion Copilot，一个基于优化轻量级LLM（0.5B参数）的系统，旨在解决现有脑电图情绪识别在实时性、个体适应性和用户交互方面的挑战。该系统能够直接从脑电信号识别情绪，生成个性化诊断建议，并自动化辅助电子病历。通过新颖的提示数据结构、模型剪枝和微调等技术，实验证明其在情绪识别准确性和辅助病历生成方面优于同等或更大规模的模型，有望推动情感计算在医疗领域的应用，特别是在心理健康监测方面。

> **摘要翻译:** 在情感计算（AC）和脑机接口（BMI）领域，分析生理和行为信号以识别个体情绪状态已成为一个关键研究前沿。尽管基于深度学习的方法在脑电图情绪识别方面取得了显著进展，特别是在特征提取和模式识别方面，但在实现端到端情绪计算方面仍存在重大挑战，包括实时处理、个体适应和无缝用户交互。本文提出了EEG情感副驾驶（EEG Emotion Copilot），一个优化了在本地环境中运行的0.5B参数的轻量级大型语言模型（LLM）的系统，该系统首先直接从脑电信号识别情绪状态，随后生成个性化的诊断和治疗建议，最后支持辅助电子病历的自动化。具体而言，我们展示了在提示的新颖数据结构、模型剪枝和微调训练以及旨在提高实时性能和计算效率的部署策略中的关键技术。广泛的实验表明，我们优化的基于轻量级LLM的副驾驶在参与者交互方面实现了增强的直观界面，并在情绪识别和辅助电子病历生成方面取得了卓越的准确性，优于参数规模相似或更大的模型，如1.5B、1.8B、3B和7B。总而言之，通过这些努力，所提出的副驾驶有望推进情感计算在医疗领域的应用，为心理健康监测提供创新解决方案。代码将在https://github.com/NZWANG/EEG_Emotion_Copilot发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [675] [FPC-Net: Revisiting SuperPoint with Descriptor-Free Keypoint Detection via Feature Pyramids and Consistency-Based Implicit Matching](https://arxiv.org/abs/2507.10770)
> *FPC-Net：基于特征金字塔和一致性隐式匹配的无描述符关键点检测对SuperPoint的再审视*

*Ionuţ Grigore, Călin-Adrian Popa, Claudiu Leoveanu-Condrei* | **Category: cs.CV** | **Updated: 2025-07-14**

**Keywords:** 无描述符关键点, 特征金字塔, 隐式匹配, 内存优化, 计算机视觉

**Comment:** 

> **TL;DR:** FPC-Net提出了一种无需描述符的关键点检测和匹配方法，通过在检测时内在地关联兴趣点，显著降低了内存使用，尽管匹配精度略低于传统方法。

**AI_Comments:** FPC-Net的创新之处在于其“无描述符”的关键点匹配范式，这打破了传统计算机视觉中描述符-匹配的固有模式。通过在检测时即实现隐式匹配，该方法在内存效率方面取得了显著突破，对于资源受限的边缘设备或大规模定位系统具有重要价值。尽管在精度上存在轻微妥协，但这种设计思路为未来高效的视觉定位和SLAM系统提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的兴趣点匹配方法依赖于描述符的计算、存储、传输和匹配，这会带来内存和计算负担。本文的动机是引入一种无需描述符的兴趣点匹配技术，以减少内存使用。

**Method:** 本研究提出了一种技术，其中兴趣点在检测过程中被内在地关联起来，从而无需计算、存储、传输或匹配描述符。该方法通过特征金字塔和基于一致性的隐式匹配实现。

**Result:** 尽管匹配精度略低于传统方法，但本方法完全消除了对描述符的需求，从而大幅减少了定位系统的内存使用。其有效性通过与经典手工方法和现代学习方法进行比较得到评估。

**Conclusion:** FPC-Net成功地实现了无描述符的关键点检测和匹配，显著降低了内存消耗，为几何计算机视觉任务提供了一种新颖且高效的解决方案，尽管在精度上略有权衡。

> **ai_Abstract:** FPC-Net提出了一种新颖的无描述符关键点检测和匹配方法，旨在解决传统方法对描述符的依赖。该方法通过在检测阶段内在地关联兴趣点，消除了描述符的计算、存储和传输需求，从而显著降低了内存消耗。尽管匹配精度略有下降，但其在内存效率方面的优势使其在资源受限的定位系统中具有重要意义。该工作通过与现有手工和学习方法进行比较来验证其有效性。

> **摘要翻译:** 兴趣点提取和匹配是许多几何计算机视觉任务的基础。传统上，匹配是通过为兴趣点分配描述符并基于描述符相似性来识别对应关系来执行的。这项工作引入了一种技术，其中兴趣点在检测过程中被内在地关联，从而消除了计算、存储、传输或匹配描述符的需要。尽管匹配精度略低于传统方法，但我们的方法完全消除了对描述符的需求，从而大幅减少了定位系统的内存使用。我们通过将其与经典手工方法和现代学习方法进行比较来评估其有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [680] [Understanding Dataset Bias in Medical Imaging: A Case Study on Chest X-rays](https://arxiv.org/abs/2507.07722)
> *理解医学影像中的数据集偏差：以胸部X射线为例*

*Ethan Dack, Chengliang Dai* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 数据集偏差, 医学影像, 胸部X射线, 机器学习, 可解释性AI

**Comment:** 

> **TL;DR:** 本研究探讨了流行的开源胸部X射线数据集中是否存在数据集偏差，通过重新应用“识别数据集”任务并进行分析，以促进医学影像领域更具可解释性的研究。

**AI_Comments:** 这项工作在医学影像AI领域具有重要意义，因为它直接解决了数据集偏差这一关键问题。在敏感的医疗领域，确保AI模型的公平性和可靠性至关重要，而数据集偏差可能导致模型学习到虚假关联而非真正的病理特征。通过系统性地探究和解释这些偏差，本研究为开发更稳健、更可信赖的医学AI系统提供了基础。其创新点在于将“识别数据集”任务应用于医学影像，并强调了可解释性研究和开源数据集建设的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于AI在医学影像中的重要性，以及非医学数据集中已发现的潜在偏差，本研究旨在探究流行的开源胸部X射线数据集中是否存在类似的数据集偏差，并确保现代AI方法关注相关病理而非捷径。

**Method:** 本研究重新应用了“识别数据集”任务到流行的开源胸部X射线数据集（NIH, CheXpert, MIMIC-CXR, PadChest）上。研究者对数据集进行了简单的变换，重复了该任务，并使用一系列不同的网络架构进行分析，以识别和解释检测到的任何偏差。

**Result:** 研究旨在探索数据集偏差是否存在于这些数据集中，并识别和解释任何检测到的偏差。抽象中并未明确列出具体的实验结果，但暗示了偏差的存在。

**Conclusion:** 本研究希望鼓励在医学影像领域进行更具可解释性的研究，并创建更多的医学领域开源数据集。

> **ai_Abstract:** 本研究旨在调查流行开源胸部X射线数据集中是否存在数据集偏差。通过重新应用“识别数据集”任务，并对NIH、CheXpert、MIMIC-CXR和PadChest等数据集进行变换和不同网络架构的测试，研究旨在识别和解释潜在偏差。这对于确保医学AI应用关注实际病理而非数据集捷径至关重要，并希望促进医学影像领域更具可解释性的研究和更多开源数据集的创建。

> **摘要翻译:** 最近的工作重新审视了臭名昭著的“识别数据集”任务，证明了非医学数据集中存在潜在偏差，并且数据集来源任务可以高精度解决。在这项工作中，我们重新审视了应用于流行开源胸部X射线数据集的相同任务。由于其敏感性，医学图像自然更难开源发布，这导致某些开源数据集在研究目的上极受欢迎。通过执行相同的任务，我们希望探索这些数据集中是否存在数据集偏差。为了扩展我们的工作，我们对数据集应用了简单的变换，重复了相同的任务，并进行分析以识别和解释任何检测到的偏差。鉴于AI应用在医学影像中的重要性，确定现代方法是走捷径还是专注于相关病理至关重要。我们在数据集上实现了各种不同的网络架构：NIH、CheXpert、MIMIC-CXR和PadChest。我们希望这项工作能鼓励在医学影像领域进行更具可解释性的研究，并创建更多的医学领域开源数据集。我们的代码可以在这里找到：https://github.com/eedack01/x_ray_ds_bias。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [685] [HANS-Net: Hyperbolic Convolution and Adaptive Temporal Attention for Accurate and Generalizable Liver and Tumor Segmentation in CT Imaging](https://arxiv.org/abs/2507.11325)
> *HANS-Net：用于CT成像中肝脏和肿瘤精确且泛化分割的双曲卷积和自适应时间注意力*

*Arefin Ittesafun Abian, Ripon Kumar Debnath, Md. Abdur Rahman, Mohaimenul Azam Khan Raiaan, Md Rafiqul Islam, Asif Karim, Reem E. Mohamed, Sami Azam* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 肝脏分割, 肿瘤分割, 双曲卷积, 时间注意力, CT成像

**Comment:** 10 figures. Will be submitted to IEEE Transactions on Radiation and
  Plasma Medical Sciences

> **TL;DR:** HANS-Net是一个结合了多种先进技术的分割框架，用于在CT图像中实现准确且泛化能力强的肝脏和肿瘤分割。

**AI_Comments:** HANS-Net的创新之处在于其多组件协同设计，集成了双曲卷积、小波分解、生物启发突触可塑性和隐式神经表示，以全面捕捉图像特征并处理复杂性。此外，引入不确定性感知蒙特卡洛dropout和轻量级时间注意力进一步提升了模型的鲁棒性和跨切片一致性，这对于医疗图像分割至关重要。其在不同数据集上的出色泛化能力也凸显了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在腹部CT图像中准确分割肝脏和肿瘤对于可靠诊断和治疗计划至关重要，但由于复杂的解剖结构、肿瘤外观的可变性以及有限的带注释数据，仍然具有挑战性。

**Method:** HANS-Net是一个新颖的分割框架，它协同结合了用于分层几何表示的双曲卷积、用于多尺度纹理学习的小波启发分解模块、用于自适应特征增强的生物学动机突触可塑性机制，以及用于建模精细和连续解剖边界的隐式神经表示分支。此外，还结合了不确定性感知蒙特卡洛dropout来量化预测置信度，以及轻量级时间注意力来提高切片间一致性。

**Result:** 在LiTS数据集上，HANS-Net实现了平均Dice分数为93.26%，IoU为88.09%，平均对称表面距离（ASSD）为0.72毫米，体积重叠误差（VOE）为11.91%。在3D-IRCADb-01数据集上的交叉数据集验证获得了平均Dice为87.45%，IoU为80.30%，ASSD为1.525毫米，VOE为19.71%。

**Conclusion:** 这些结果证实了HANS-Net在提供解剖学上一致、准确和高置信度的肝脏和肿瘤分割方面的有效性和鲁棒性。

> **ai_Abstract:** HANS-Net是一个创新的深度学习框架，专为CT图像中的肝脏和肿瘤精确分割而设计。它通过集成双曲卷积、小波分解、突触可塑性机制和隐式神经表示来处理复杂的解剖结构和肿瘤变异性，并通过不确定性感知dropout和时间注意力提高分割的准确性、一致性和泛化能力。在LiTS和3D-IRCADb-01数据集上的评估证明了其卓越的性能和跨数据集的泛化能力。

> **摘要翻译:** 在腹部CT图像上准确分割肝脏和肿瘤对于可靠的诊断和治疗计划至关重要，但由于复杂的解剖结构、肿瘤外观的可变性以及有限的带注释数据，这仍然具有挑战性。为了解决这些问题，我们引入了HANS-Net（Hyperbolic-convolutions Adaptive-temporal-attention with Neural-representation and Synaptic-plasticity Network），这是一个新颖的分割框架，它协同结合了用于分层几何表示的双曲卷积、用于多尺度纹理学习的小波启发分解模块、用于自适应特征增强的生物学动机突触可塑性机制，以及一个用于建模精细和连续解剖边界的隐式神经表示分支。此外，我们还结合了不确定性感知蒙特卡洛dropout来量化预测置信度，以及轻量级时间注意力来提高切片间一致性，而不会牺牲效率。对LiTS数据集的广泛评估表明，HANS-Net实现了93.26%的平均Dice分数、88.09%的IoU、0.72毫米的平均对称表面距离（ASSD）和11.91%的体积重叠误差（VOE）。此外，在3D-IRCADb-01数据集上的交叉数据集验证获得了87.45%的平均Dice、80.30%的IoU、1.525毫米的ASSD和19.71%的VOE，这表明其在不同数据集之间具有强大的泛化能力。这些结果证实了HANS-Net在提供解剖学上一致、准确和高置信度的肝脏和肿瘤分割方面的有效性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [690] [Conceptualizing Multi-scale Wavelet Attention and Ray-based Encoding for Human-Object Interaction Detection](https://arxiv.org/abs/2507.10977)
> *概念化多尺度小波注意力与基于射线的编码用于人-物交互检测*

*Quan Bi Pay, Vishnu Monn Baskaran, Junn Yong Loo, KokSheik Wong, Simon See* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 人-物交互, 小波注意力, 基于射线编码, HOI检测, 多尺度注意力

**Comment:** Accepted at International Joint Conference on Neural Networks (IJCNN
  2025)

> **TL;DR:** 本文提出了一种结合多尺度小波注意力主干和基于射线编码器的新型架构，旨在提高人-物交互（HOI）检测的效率和可靠性。

**AI_Comments:** 该论文的创新点在于结合了小波注意力机制来更有效地聚合多尺度特征，以及引入了新颖的基于射线的编码器来优化注意力机制和降低计算成本。这种双重方法有望显著提升人-物交互检测的性能和效率，对复杂视觉场景理解领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人-物交互（HOI）检测器在提供高效可靠的预测方面存在困难，它们依赖于资源密集型训练方法和低效的架构。

**Method:** 本文概念化了一种小波注意力式主干网络和一种新颖的基于射线的编码器架构。小波主干通过聚合来自低阶和高阶交互的判别性特征来解决表达中阶交互的局限性。基于射线的编码器通过优化解码器对相关感兴趣区域的关注并减轻计算开销来促进多尺度注意力，从而实现准确预测。

**Result:** 在ImageNet和HICO-DET等基准数据集上的实验结果表明，所提出的架构具有潜力。

**Conclusion:** 本文提出的多尺度小波注意力与基于射线的编码架构，有效提升了人-物交互检测的效率和可靠性，解决了现有方法的局限性。

> **ai_Abstract:** 本文提出了一种用于人-物交互（HOI）检测的新型架构，旨在解决现有HOI检测器效率低下和不可靠的问题。该架构包含一个概念化的小波注意力式主干网络，用于聚合不同卷积滤波器提取的判别性特征，以处理中阶交互的表达限制；以及一个新颖的基于射线的编码器，通过优化解码器对感兴趣区域的关注来促进多尺度注意力并减轻计算开销。实验结果在ImageNet和HICO-DET等基准数据集上展示了该架构的潜力。

> **摘要翻译:** 人-物交互（HOI）检测对于准确地定位和表征人与物体之间的交互至关重要，它能提供对各种领域复杂视觉场景的全面理解。然而，现有的HOI检测器往往难以高效地提供可靠的预测，它们依赖于资源密集型训练方法和低效的架构。为了解决这些挑战，我们概念化了一种小波注意力式主干网络和一种专为HOI检测量身定制的新型基于射线的编码器架构。我们的小波主干通过聚合从不同卷积滤波器中提取的低阶和高阶交互的判别性特征，解决了表达中阶交互的局限性。同时，基于射线的编码器通过优化解码器对相关感兴趣区域的关注并减轻计算开销来促进多尺度注意力。通过利用可学习射线原点的衰减强度，我们的解码器将查询嵌入与强调的感兴趣区域对齐，从而实现准确预测。在ImageNet和HICO-DET等基准数据集上的实验结果展示了我们提出的架构的潜力。代码已在[https://github.com/henry-pay/RayEncoder]公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [692] [Zero-Shot Hyperspectral Pansharpening Using Hysteresis-Based Tuning for Spectral Quality Control](https://arxiv.org/abs/2505.16658)
> *零样本高光谱全色锐化：基于滞后调谐的光谱质量控制*

*Giuseppe Guarino, Matteo Ciotola, Gemine Vivone, Giovanni Poggi, Giuseppe Scarpa* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-15**

**Keywords:** 高光谱全色锐化, 零样本, 无监督学习, 光谱质量控制, 神经网络

**Comment:** 

> **TL;DR:** 提出一种零样本、无监督的高光谱全色锐化方法，通过滞后调谐确保所有波段的光谱质量一致性。

**AI_Comments:** 该论文的创新点在于提出了一个无需预训练的零样本高光谱全色锐化框架，并通过独特的滞后调谐机制和重新定义的空间损失来解决高光谱数据特有的光谱质量一致性问题。其无监督、低复杂度的特性使其具有较高的实用价值和普适性。解决光谱保真度问题对于高光谱应用至关重要，因此该工作具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有高光谱全色锐化方法多借鉴多光谱领域，常忽略高光谱数据的独特挑战（如波段多、噪声大、光谱不匹配、高分辨率比），导致光谱保真度差，无法确保所有波段质量一致，可能产生不可靠结果。

**Method:** 本文提出一种高光谱全色锐化方法，使用单个轻量级神经网络，其权重可根据每个波段动态调整。在微调过程中，通过类似滞后的动态机制，开启和关闭空间损失，以确保光谱损失快速收敛到所需水平。此外，空间损失本身被重新定义，以考虑全色和光谱波段之间的非线性依赖关系。该方法是完全无监督的，无需外部数据预训练，且灵活、复杂度低。

**Result:** 在最近发布的基准测试工具箱上的实验表明，该方法确保了卓越的锐化质量，与最先进的方法具有竞争力，并且在所有波段上都保持一致。

**Conclusion:** 该方法通过解决高光谱全色锐化中的光谱质量一致性问题，提供了一种有效、无监督且灵活的解决方案，实现了与SOTA相当的性能。

> **ai_Abstract:** 本文提出了一种新颖的零样本、无监督高光谱全色锐化方法，旨在解决现有方法在处理高光谱数据特有挑战时，尤其是光谱质量不一致的问题。该方法采用一个轻量级神经网络，通过基于滞后的调谐机制动态调整权重，并重新定义空间损失，以确保所有波段的一致光谱质量。实验证明，该方法在保持卓越锐化质量的同时，性能与最先进技术相当，且具有高度灵活性和低复杂度。

> **摘要翻译:** 高光谱全色锐化近年来受到了广泛关注，这得益于技术和方法上的进步，为新的应用场景打开了大门。然而，该领域的研究才刚刚兴起。最流行的方法仍然借鉴自更成熟的多光谱全色锐化领域，并且经常忽视高光谱数据融合所带来的独特挑战，例如：i) 波段数量非常庞大，ii) 特定光谱范围内的噪声巨大，iii) 全色和高光谱成分之间存在显著的光谱不匹配，iv) 通常较高的分辨率比。不精确的数据建模尤其会影响光谱保真度。即使是最先进的方法，在某些光谱范围内表现良好，而在其他范围内则差得多，未能确保所有波段的质量一致性，存在产生不可靠结果的风险。在此，我们提出了一种高光谱全色锐化方法，明确解决了这个问题并确保了统一的光谱质量。为此，使用了一个单一的轻量级神经网络，其权重可以根据每个波段动态调整。在微调过程中，空间损失根据类似滞后的动态机制被开启和关闭，以确保光谱损失快速收敛到所需水平。此外，空间损失本身也得到了适当的重新定义，以考虑全色和光谱波段之间的非线性依赖关系。总的来说，所提出的方法是完全无监督的，无需对外部数据进行预训练，且灵活、复杂度低。在最近发布的基准测试工具箱上的实验表明，它确保了卓越的锐化质量，与最先进的技术具有竞争力，并在所有波段上保持一致。软件代码和完整的结果集已在线共享：https://github.com/giu-guarino/rho-PNN。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [705] [KptLLM++: Towards Generic Keypoint Comprehension with Large Language Model](https://arxiv.org/abs/2507.11102)
> *KptLLM++：迈向通用关键点理解的大语言模型*

*Jie Yang, Wang Zeng, Sheng Jin, Lumin Xu, Wentao Liu, Chen Qian, Zhen Li, Ruimao Zhang* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 关键点理解, 多模态大语言模型, 细粒度图像分析, KptLLM++, 识别-然后-检测

**Comment:** Extended Version of KptLLM. arXiv admin note: text overlap with
  arXiv:2411.01846

> **TL;DR:** KptLLM++是一个新型多模态大语言模型，通过整合多种输入模式和“识别-然后-检测”范式，解决了现有MLLM在捕获细粒度关键点信息方面的不足，并在多个关键点检测基准上实现了最先进的性能。

**AI_Comments:** KptLLM++的创新点在于其“识别-然后-检测”的独特范式，将关键点语义理解与精确位置定位相结合，并通过思维链推理增强了模型的解释能力。此外，大规模数据集的构建和应用是其性能突破的关键。该模型在通用关键点理解方面展现出巨大潜力，有望在细粒度图像分析和人机交互等领域带来显著进步。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态大语言模型（MLLMs）在桥接文本和视觉模态方面取得了革命性进展，但在捕获细粒度的语义信息（如精确识别和分析对象关键点）方面存在困难。关键点作为结构感知、像素级和紧凑的对象表示，在细粒度图像分析、对象检索和行为识别等应用中至关重要。

**Method:** 本文提出了KptLLM++，一个专为通用关键点理解设计的新型多模态大语言模型。它通过用户定义的指令整合多样化的输入模态，并统一了不同上下文的关键点检测。该模型基于“识别-然后-检测”范式构建，首先解释关键点语义，然后通过结构化的思维链推理机制定位其精确位置。为了提高性能，训练数据集已扩展到超过50万个样本，涵盖了多样化的对象、关键点类别、图像风格和复杂遮挡场景。

**Result:** KptLLM++在多个关键点检测基准上展示了最先进的性能，实现了卓越的准确性和泛化能力。

**Conclusion:** KptLLM++被证明是细粒度图像理解的统一解决方案，并对人机交互具有变革性意义。

> **ai_Abstract:** KptLLM++是一个新型多模态大语言模型，旨在解决现有MLLM在细粒度关键点理解上的不足。它通过整合多样化输入和“识别-然后-检测”范式（先理解语义再定位），并在扩展至50万样本的大规模数据集上进行训练，实现了对通用关键点的精确识别和分析。实验证明KptLLM++在多个关键点检测基准上表现出最先进的性能，为细粒度图像理解和人机协作提供了统一且有效的解决方案。

> **摘要翻译:** 多模态大语言模型（MLLMs）的出现通过桥接文本和视觉模态，彻底改变了图像理解。然而，这些模型通常难以捕获细粒度的语义信息，例如对象的精确关键点识别和分析。关键点作为结构感知、像素级和紧凑的对象表示，特别是对于铰接对象，在细粒度图像分析、对象检索和行为识别等应用中发挥着关键作用。在本文中，我们提出了KptLLM++，一个新型多模态大语言模型，通过整合由用户定义指令引导的多样化输入模态，专门设计用于通用关键点理解。通过统一不同上下文的关键点检测，KptLLM++将自身确立为一个先进的接口，促进了更有效的人机协作。该模型建立在一种新颖的“识别-然后-检测”范式之上，该范式首先解释关键点语义，然后通过结构化的思维链推理机制定位其精确位置。为了突破性能边界，我们已将训练数据集扩展到超过50万个样本，涵盖了多样化的对象、关键点类别、图像风格和复杂遮挡场景。这种大规模扩展使KptLLM++能够释放其潜力，实现卓越的准确性和泛化能力。在多个关键点检测基准上的综合实验证明了其最先进的性能，突显了其作为细粒度图像理解统一解决方案的潜力及其对人机交互的变革性影响。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [708] [Prompt4Trust: A Reinforcement Learning Prompt Augmentation Framework for Clinically-Aligned Confidence Calibration in Multimodal Large Language Models](https://arxiv.org/abs/2507.09279)
> *Prompt4Trust：一个用于多模态大语言模型中临床对齐置信度校准的强化学习提示增强框架*

*Anita Kriz, Elizabeth Laura Janes, Xing Shen, Tal Arbel* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-15**

**Keywords:** 多模态大语言模型, 置信度校准, 强化学习, 提示增强, 医疗应用

**Comment:** Accepted to ICCV 2025 Workshop CVAMD

> **TL;DR:** 多模态大语言模型在医疗领域应用潜力巨大，但其在安全关键环境中的部署受限于对提示设计的敏感性以及生成高置信度错误回复的倾向。Prompt4Trust是首个针对多模态大语言模型置信度校准的强化学习提示增强框架，通过训练轻量级LLM生成上下文感知辅助提示，引导下游任务MLLM生成置信度更准确反映预测精度的回复。该方法不仅提高了任务准确性，在医学VQA基准上达到SOTA，还展现了对更大MLLM的零样本泛化能力，提升了MLLM在安全关键环境中的可信度。

**AI_Comments:** Prompt4Trust的创新之处在于它是首个将强化学习应用于提示增强以解决多模态大语言模型置信度校准问题的框架，尤其强调了临床应用中的安全性和可信度。其通过轻量级LLM生成上下文感知提示的方法，有效地提升了模型的预测准确性和置信度对齐，解决了当前MLLMs部署在安全关键领域（如医疗）的核心障碍。此外，该框架展现出的零样本泛化能力，意味着它可能在不增加过多计算成本的情况下，扩展到更大型的模型，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在医疗保健应用中前景广阔，但其在安全关键场景中的部署面临两大限制：(i) 对提示设计的敏感性；(ii) 倾向于以高置信度生成不正确回复。由于临床医生可能依赖模型声明的置信度来评估其预测的可靠性，因此当模型表达高置信度时，其高度准确性显得尤为重要。

**Method:** 引入了Prompt4Trust，这是首个针对多模态大语言模型中置信度校准的强化学习（RL）提示增强框架。该框架训练一个轻量级LLM来生成上下文感知的辅助提示，这些提示指导下游任务MLLM生成表达置信度更准确反映预测准确性的回复。与传统校准技术不同，Prompt4Trust特别优先考虑了对安全和可信临床决策最关键的校准方面。

**Result:** 除了由临床驱动的校准目标带来的改进外，所提出的方法还提高了任务准确性，在PMC-VQA基准测试上实现了最先进的医学视觉问答（VQA）性能。此外，在实验中，使用小型下游任务MLLM训练的框架对更大的MLLMs显示出有前景的零样本泛化能力。

**Conclusion:** 这项工作展示了自动化且与人类对齐的提示工程在提高多模态大语言模型在安全关键设置中可信度方面的潜力。

> **ai_Abstract:** 本论文介绍了Prompt4Trust，一个用于多模态大语言模型（MLLMs）的强化学习提示增强框架，旨在解决MLLMs在医疗保健等安全关键领域中存在的提示敏感性和高置信度错误预测问题。该框架训练一个轻量级LLM生成辅助提示，以引导下游MLLM实现更准确的置信度校准，特别关注临床决策的关键方面。实验结果表明，Prompt4Trust不仅提升了任务准确性，在医学视觉问答（VQA）任务上达到了最先进的水平，还展现了对更大MLLMs的零样本泛化能力，突显了其在提高MLLMs可信度方面的巨大潜力。

> **摘要翻译:** 多模态大语言模型（MLLMs）在医疗保健应用中前景广阔。然而，它们在安全关键环境中的部署受到两个关键限制的阻碍：(i) 对提示设计的敏感性；(ii) 倾向于以高置信度生成不正确回复。由于临床医生可能依赖模型的声明置信度来衡量其预测的可靠性，因此当模型表达高置信度时，其高度准确性显得尤为重要。我们引入了Prompt4Trust，这是首个针对多模态大语言模型中置信度校准的强化学习（RL）提示增强框架。一个轻量级LLM被训练来生成上下文感知的辅助提示，这些提示指导下游任务MLLM生成表达置信度更准确反映预测准确性的回复。与传统校准技术不同，Prompt4Trust特别优先考虑了对安全和可信临床决策最关键的校准方面。除了由这种临床驱动的校准目标带来的改进外，我们提出的方法还提高了任务准确性，在PMC-VQA基准测试上实现了最先进的医学视觉问答（VQA）性能，该基准由涵盖多种医学影像模态的多项选择题组成。此外，在我们的实验中，使用小型下游任务MLLM训练的框架对更大的MLLMs显示出有前景的零样本泛化能力，这表明了在没有相关计算成本的情况下实现可扩展校准的潜力。这项工作展示了自动化但与人类对齐的提示工程在提高多模态大语言模型在安全关键设置中可信度方面的潜力。我们的代码库可以在https://github.com/xingbpshen/prompt4trust找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [714] [SVTRv2: CTC Beats Encoder-Decoder Models in Scene Text Recognition](https://arxiv.org/abs/2411.15858)
> *SVTRv2：CTC在场景文本识别中超越编码器-解码器模型*

*Yongkun Du, Zhineng Chen, Hongtao Xie, Caiyan Jia, Yu-Gang Jiang* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 场景文本识别, CTC, SVTRv2, 编码器-解码器模型, 文本不规则性

**Comment:** Accepted by ICCV 2025

> **TL;DR:** SVTRv2是一个基于CTC的场景文本识别模型，通过引入多尺寸调整策略、特征重排模块和语义引导模块，解决了CTC模型在文本不规则性和语言信息方面的不足，并在准确性和推理速度上超越了大多数编码器-解码器模型。

**AI_Comments:** SVTRv2的创新之处在于其巧妙地将多种策略（多尺寸调整、特征重排、语义引导）融合到CTC框架中，有效弥补了CTC模型在处理复杂文本和利用语言上下文方面的短板。特别值得注意的是，语义引导模块在推理阶段的可选性，确保了在提高准确性的同时不牺牲CTC固有的快速推理优势，这对于实际OCR应用非常重要。该研究成功挑战了EDTRs在STR领域的主导地位，为CTC模型的发展开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 基于CTC的场景文本识别（STR）方法（如SVTR）因其架构简单和推理速度快而广泛应用于OCR，但通常在准确性上不如基于编码器-解码器的方法（EDTRs），主要原因是难以处理文本不规则性和语言信息缺失。

**Method:** SVTRv2模型提出了以下改进：1. 多尺寸调整策略：将文本实例调整到预定义的合适尺寸，有效避免严重的文本失真。2. 特征重排模块：确保视觉特征适应CTC的要求，缓解对齐难题。3. 语义引导模块：将语言上下文整合到视觉特征中，使CTC模型能够利用语言信息提高准确性，该模块在推理阶段可省略，不增加时间成本。

**Result:** SVTRv2在标准和最近的挑战性基准测试中进行了广泛评估，在不同类型的文本不规则性、语言、长文本以及是否采用预训练等多种场景下，SVTRv2在准确性和推理速度上均超越了大多数EDTRs。

**Conclusion:** SVTRv2通过解决文本不规则性和整合语言上下文的能力，证明了CTC模型在场景文本识别任务中可以超越传统的编码器-解码器模型，同时保持其快速推理的优势。

> **ai_Abstract:** SVTRv2是一个改进的基于CTC的场景文本识别模型，旨在解决传统CTC模型在处理文本不规则性和利用语言信息方面的局限性。它引入了多尺寸调整策略以避免文本失真，特征重排模块以优化CTC对齐，以及语义引导模块以整合语言上下文并提高准确性（推理时可移除）。实验结果表明，SVTRv2在准确性和推理速度上均优于大多数编码器-解码器模型，证明了CTC在STR领域的潜力。

> **摘要翻译:** 连接主义时间分类（CTC）-based 场景文本识别（STR）方法，例如SVTR，在OCR应用中被广泛采用，主要原因在于其简单的架构，只包含一个视觉模型和一个CTC对齐的线性分类器，因此推理速度快。然而，由于难以处理文本不规则性和语言信息缺失，它们通常表现出比基于编码器-解码器的方法（EDTRs）更差的准确性。为了解决这些挑战，我们提出了SVTRv2，一个基于CTC的模型，赋予以处理文本不规则性和建模语言上下文的能力。首先，提出了一种多尺寸调整策略，将文本实例调整到适当的预定义尺寸，有效避免了严重的文本失真。同时，我们引入了一个特征重排模块，以确保视觉特征适应CTC的要求，从而缓解对齐难题。其次，我们提出了一个语义引导模块。它将语言上下文整合到视觉特征中，允许CTC模型利用语言信息提高准确性。该模块在推理阶段可以省略，不会增加时间成本。我们在标准和最近的挑战性基准测试中广泛评估了SVTRv2，其中SVTRv2在多种场景下与流行的STR模型进行了公平比较，包括不同类型的文本不规则性、语言、长文本以及是否采用预训练。SVTRv2在准确性和推理速度方面超越了大多数EDTRs。代码：https://github.com/Topdu/OpenOCR。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [724] [A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers](https://arxiv.org/abs/2507.10775)
> *用于机载飞行计算机中实时航天器分割的新数据集和性能基准*

*Jeffrey Joan Sam, Janhavi Sathe, Nikhil Chigali, Naman Gupta, Radhey Ruparel, Yicheng Jiang, Janmajay Singh, James W. Berck, Arko Barman* | **Category: cs.CV, cs.AI, eess.IV** | **Updated: 2025-07-14**

**Keywords:** 航天器分割, 数据集, 性能基准, 实时, 机载计算机

**Comment:** 

> **TL;DR:** 该研究提出了一个包含近6.4万张带注释航天器图像的新数据集，并使用YOLOv8和YOLOv11模型为机载实时航天器分割生成了性能基准，达到了高精度和快速推理时间。

**AI_Comments:** 这项工作具有重要意义，因为它解决了航天器在轨自主检查领域的一个关键瓶颈——缺乏大规模、高质量的训练数据。所创建的数据集不仅规模庞大，而且通过结合真实模型、混合背景以及模拟噪声和畸变，极大地提高了数据的真实性和复杂性，使其更适用于实际应用。此外，在资源受限的机载计算机上对模型进行基准测试，并取得优异的实时性能，展示了该方法在未来空间任务中的巨大潜力。这对于降低空间维修成本和提高任务安全性具有积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 外太空中的航天器因暴露于危险环境而常遭受损坏，而人工或机器人进行在轨维修成本高昂且风险大。虽然图像分割技术可实现自主检查系统，但公开可用的带注释航天器分割数据非常稀缺，限制了高性能模型的开发。

**Method:** 研究创建了一个包含近6.4万张带注释航天器图像的新数据集。这些图像通过将真实航天器模型叠加在真实与合成背景（使用NASA TTALOS管道生成）上创建，并加入了模拟真实世界图像采集的噪声和失真。随后，研究对YOLOv8和YOLOv11分割模型进行了微调，以在明确的硬件和推理时间限制下，为数据集生成性能基准，旨在模拟NASA检查器航天器在轨实时应用的挑战。

**Result:** 在设定的约束条件下，微调后的模型在测试中实现了0.92的Dice分数，0.69的Hausdorff距离，以及约0.5秒的推理时间。

**Conclusion:** 本研究成功创建了一个大规模的带注释航天器图像数据集，并为机载实时航天器分割任务提供了高性能的基准模型，证明了在资源受限的机载计算机上实现高精度、实时分割的可行性。

> **ai_Abstract:** 本研究旨在解决机载飞行计算机中实时航天器分割数据稀缺的问题，以支持自主检查系统。为此，作者创建了一个包含近6.4万张带注释航天器图像的新数据集，其图像背景结合了真实和合成元素，并加入了噪声和畸变以模拟真实环境。在此数据集上，研究微调了YOLOv8和YOLOv11分割模型，并在严格的硬件和推理时间限制下建立了性能基准。实验结果显示，模型在Dice分数、Hausdorff距离和推理时间方面表现出色，验证了其在实时机载应用中的潜力。

> **摘要翻译:** 部署在外太空的航天器因暴露于危险环境而经常遭受各种形式的损坏。此外，通过人类舱外活动或机器人操作进行随后的在轨维修存在重大风险，并产生高昂的运营成本。图像分割的最新发展可以促进可靠且经济高效的自主检查系统的开发。虽然这些模型通常需要大量的训练数据才能达到令人满意的结果，但公开可用的带注释航天器分割数据非常稀缺。在此，我们提出了一个包含近6.4万张带注释航天器图像的新数据集，该数据集是使用真实航天器模型创建的，并叠加在混合了真实和合成背景（使用NASA TTALOS管道生成）的图像上。为了模拟真实世界图像采集中的相机畸变和噪声，我们还向图像中添加了不同类型的噪声和畸变。最后，我们对YOLOv8和YOLOv11分割模型进行了微调，以在明确的硬件和推理时间约束下，为数据集生成性能基准，以模拟NASA检查器航天器上实时机载应用中真实世界图像分割的挑战。在这些约束下测试时，所得模型达到了0.92的Dice分数，0.69的Hausdorff距离，以及约0.5秒的推理时间。数据集和性能基准模型可在https://github.com/RiceD2KLab/SWiM获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [734] [MonoMVSNet: Monocular Priors Guided Multi-View Stereo Network](https://arxiv.org/abs/2507.11333)
> *MonoMVSNet: 单目先验引导的多视角立体网络*

*Jianfei Jiang, Qiankun Liu, Haochen Yu, Hongyuan Liu, Liyong Wang, Jiansheng Chen, Huimin Ma* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 多视角立体, 单目深度估计, 深度学习, 点云, 深度预测

**Comment:** Accepted by ICCV 2025

> **TL;DR:** MonoMVSNet结合单目深度估计的先验知识改进多视角立体（MVS）在无纹理和反射区域的性能，并在DTU和Tanks-and-Temples数据集上达到SOTA。

**AI_Comments:** 该论文的创新点在于巧妙地将单目深度估计的优势（无需特征匹配，在困难区域鲁棒）与多视角立体相结合，有效弥补了传统MVS在无纹理和反射表面上的不足。通过引入单目特征集成、深度对齐和相对一致性损失，MonoMVSNet显著提升了稠密点云重建的精度和鲁棒性，是MVS领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于学习的多视角立体（MVS）方法在无纹理区域和反射表面等挑战性区域表现不佳，因为特征匹配在此类区域会失败。而单目深度估计本质上不需要特征匹配，能够更鲁棒地处理这些区域的相对深度估计问题。

**Method:** 提出MonoMVSNet，一个单目特征和深度引导的MVS网络，将单目基础模型的强大先验知识整合到多视角几何中。具体包括：1. 通过带有新设计的跨视图位置编码的注意力机制，将参考视图的单目特征整合到源视图特征中。2. 对齐参考视图的单目深度，在采样过程中动态更新边缘区域的深度候选。3. 基于单目深度设计了相对一致性损失来监督深度预测。

**Result:** MonoMVSNet在DTU和Tanks-and-Temples数据集上取得了最先进的性能，并在Tanks-and-Temples的Intermediate和Advanced基准测试中排名第一。

**Conclusion:** MonoMVSNet通过有效整合单目先验知识，显著提升了多视角立体在复杂场景下的深度估计精度和鲁棒性。

> **ai_Abstract:** MonoMVSNet是一种新颖的多视角立体网络，通过将单目深度估计的特征和深度先验知识融入到MVS流程中，解决了现有MVS方法在无纹理和反射区域的挑战。它通过注意力机制整合单目特征、动态更新深度候选以及设计相对一致性损失来实现。实验证明，MonoMVSNet在多个基准测试中达到了最先进的性能。

> **摘要翻译:** 基于学习的多视角立体（MVS）方法旨在为一系列校准图像预测深度图，以恢复密集的点云。然而，现有的MVS方法在无纹理区域和反射表面等挑战性区域常常表现不佳，因为这些区域的特征匹配会失败。相比之下，单目深度估计本质上不需要特征匹配，使其能够在这些区域实现鲁棒的相对深度估计。为了弥补这一差距，我们提出了MonoMVSNet，一种新颖的单目特征和深度引导的MVS网络，它将来自单目基础模型的强大先验知识集成到多视角几何中。首先，通过带有新设计的跨视图位置编码的注意力机制，将参考视图的单目特征整合到源视图特征中。然后，对齐参考视图的单目深度，以便在采样过程中动态更新边缘区域的深度候选。最后，基于单目深度进一步设计了一种相对一致性损失，以监督深度预测。大量实验表明，MonoMVSNet在DTU和Tanks-and-Temples数据集上取得了最先进的性能，并在Tanks-and-Temples的Intermediate和Advanced基准测试中排名第一。源代码可在https://github.com/JianfeiJ/MonoMVSNet获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [739] [Supercharging Floorplan Localization with Semantic Rays](https://arxiv.org/abs/2507.09291)
> *语义射线赋能平面图定位*

*Yuval Grader, Hadar Averbuch-Elor* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 平面图定位, 语义射线, 深度估计, 概率体, 粗到细

**Comment:** Accepted at ICCV 2025. https://tau-vailab.github.io/SemRayLoc/

> **TL;DR:** 本文提出了一种利用语义射线增强平面图定位的新框架，通过结合深度和语义信息，以粗到细的方式构建概率体，显著优于现有技术。

**AI_Comments:** 这项工作通过将语义信息（如窗户和门的位置）整合到平面图定位中，弥补了现有方法仅依赖深度结构线索的不足，具有重要的创新性。其粗到细的概率体构建方法也展现了算法效率的考量。该框架易于扩展以纳入额外元数据，进一步提高了其实用性和性能，对室内定位和机器人导航领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的平面图定位技术主要侧重于匹配基于深度的结构线索，而忽略了平面图中包含的丰富语义信息（如窗户和门的位置）。

**Method:** 本文引入了一个语义感知的定位框架，该框架联合估计深度和语义射线，并结合两者来预测结构-语义概率体。该概率体以粗到细的方式构建：首先采样少量射线以获得初始低分辨率概率体，然后在高概率区域进行更密集的采样以细化这些概率，最后处理细化值以预测2D位置和方向角。

**Result:** 在两个标准平面图定位基准上的评估表明，该方法显著优于最先进的方法，与现有工作相比，在召回率指标上取得了显著改进。此外，该框架可以轻松整合房间标签等额外元数据，从而在准确性和效率方面获得额外收益。

**Conclusion:** 通过整合平面图中的丰富语义信息，并结合深度线索，本文提出的语义感知定位框架能够显著提升平面图定位的性能和效率，超越了现有技术。

> **ai_Abstract:** 本文提出了一种语义感知的平面图定位框架，旨在解决现有方法忽略平面图丰富语义信息的问题。该框架通过联合估计深度和语义射线，构建了一个结构-语义概率体，并采用粗到细的采样策略进行定位。实验结果表明，该方法在召回率上显著优于现有技术，并且能够有效整合额外元数据以进一步提升性能和效率。

> **摘要翻译:** 平面图提供了建筑物结构的紧凑表示，不仅揭示了布局信息，还揭示了详细的语义信息，例如窗户和门的位置。然而，当前的平面图定位技术主要侧重于匹配基于深度的结构线索，却忽略了平面图中传达的丰富语义。在这项工作中，我们引入了一个语义感知的定位框架，该框架联合估计深度和语义射线，并结合两者来预测结构-语义概率体。我们的概率体以粗到细的方式构建：我们首先采样少量射线以获得初始低分辨率概率体。然后，我们通过仅在高概率区域执行更密集的采样来细化这些概率，并处理细化值以预测2D位置和方向角。我们在两个标准平面图定位基准上进行了评估。我们的实验表明，我们的方法显著优于最先进的方法，与现有工作相比，在召回率指标上取得了显著改进。此外，我们展示了我们的框架可以轻松整合额外的元数据，例如房间标签，从而在准确性和效率方面获得额外收益。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [754] [Jellyfish Species Identification: A CNN Based Artificial Neural Network Approach](https://arxiv.org/abs/2507.11116)
> *水母物种识别：一种基于CNN的人工神经网络方法*

*Md. Sabbir Hossen, Md. Saiduzzaman, Pabon Shaha, Mostofa Kamal Nasir* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 水母识别, 深度学习, 卷积神经网络, MobileNetV3, 物种分类

**Comment:** This paper has been accepted at the IEEE QPAIN 2025. The final
  version will be available in the IEEE Xplore Digital Library

> **TL;DR:** 该研究提出了一种基于深度学习（特别是结合MobileNetV3和ANN）的水母物种识别框架，达到了98%的准确率。

**AI_Comments:** 这项研究通过结合深度学习和传统机器学习方法，为水母物种的精确识别提供了一个高效的解决方案。其创新之处在于探索了不同特征提取器与分类器的组合，并明确指出MobileNetV3与ANN的组合效果最佳，98%的准确率非常高。这对于海洋生态监测和生物多样性保护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 水母在海洋生态系统中很重要，但其快速繁殖和生态影响对生物多样性和保护构成挑战。准确识别水母物种对生态监测和管理至关重要。

**Method:** 提出一个用于水母物种检测和分类的深度学习框架，使用水下图像数据集。该框架结合了MobileNetV3、ResNet50、EfficientNetV2-B0和VGG16等特征提取技术，以及七种传统机器学习分类器和三种前馈神经网络分类器。此外，还使用softmax函数直接通过卷积神经网络模型对水母物种进行分类。

**Result:** 结合MobileNetV3和人工神经网络的模型表现最佳，达到了98%的准确率，显著优于其他特征提取器-分类器组合。

**Conclusion:** 该研究证明了深度学习和混合框架在解决生物多样性挑战和推进海洋环境物种检测方面的有效性。

> **ai_Abstract:** 本文提出了一种基于深度学习的水母物种识别框架，利用水下图像数据集进行检测与分类。该框架结合了多种先进特征提取器（如MobileNetV3、ResNet50）与传统机器学习及前馈神经网络分类器。研究发现，MobileNetV3与人工神经网络的结合模型表现最佳，识别准确率高达98%，证明了深度学习在海洋生物多样性监测中的有效性。

> **摘要翻译:** 水母是一类多样化的胶状海洋生物，在维持海洋生态系统中发挥着关键作用，但由于其快速繁殖和生态影响，对生物多样性与保护构成了重大挑战。准确识别水母物种对于生态监测和管理至关重要。在这项研究中，我们提出了一个基于水下图像数据集的水母物种检测和分类的深度学习框架。该框架整合了先进的特征提取技术，包括MobileNetV3、ResNet50、EfficientNetV2-B0和VGG16，并结合了七种传统机器学习分类器和三种前馈神经网络分类器，以实现精确的物种识别。此外，我们激活了softmax函数，直接使用卷积神经网络模型对水母物种进行分类。人工神经网络与MobileNetV3的结合是我们表现最佳的模型，实现了98%的卓越准确率，显著优于其他特征提取器-分类器组合。这项研究证明了深度学习和混合框架在解决生物多样性挑战和推进海洋环境物种检测方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [756] [TAB: Transformer Attention Bottlenecks enable User Intervention and Debugging in Vision-Language Models](https://arxiv.org/abs/2412.18675)
> *TAB：Transformer 注意力瓶颈实现视觉-语言模型中的用户干预和调试*

*Pooyan Rahmanzadehgervi, Hung Huy Nguyen, Rosanne Liu, Long Mai, Anh Totti Nguyen* | **Category: cs.CV** | **Updated: 2025-07-14**

**Keywords:** Transformer, 注意力瓶颈, 可解释性, 视觉-语言模型, 调试

**Comment:** 

> **TL;DR:** TAB引入一个单头注意力瓶颈层，解决多头自注意力（MHSA）的可解释性问题，允许用户干预和调试视觉-语言模型，并在图像差异字幕任务中表现良好。

**AI_Comments:** TAB的创新之处在于提出了一个简洁有效的单头注意力瓶颈，解决了Transformer多头自注意力难以解释和干预的问题。它通过限制总注意力范围，提供了一种直观的控制机制，使得用户可以直接编辑注意力流来调试模型，这对于理解和改进视觉-语言模型的行为具有重要意义。该方法在保持性能的同时，显著提升了模型的可解释性和可控性，为未来的模型诊断和人机协作提供了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 多头自注意力（MHSA）是Transformer的关键组件，但它模糊了每个输入补丁对模型输出的归因，使得模型难以解释和调试。

**Method:** 提出了一种新颖的1头Transformer注意力瓶颈（TAB）层，插入在传统MHSA架构之后。TAB将所有补丁的总注意力限制在[0, 1]范围内，当总注意力为0时，视觉信息停止传播，VLM将返回通用的、与图像无关的响应。通过训练带有TAB的VLM执行图像差异字幕任务来展示其优势。

**Result:** 在字幕任务中，模型性能与基线VLM相似；但在定位变化和识别无变化情况方面，瓶颈表现更优。TAB是第一个允许用户通过编辑注意力进行调试的架构，通常能产生VLM的预期输出。

**Conclusion:** TAB层成功地提高了视觉-语言模型的可解释性和可调试性，在保持性能的同时，实现了对模型内部注意力的有效控制和干预。

> **ai_Abstract:** 该研究提出了一种名为Transformer注意力瓶颈（TAB）的单头注意力层，用于解决多头自注意力（MHSA）在视觉-语言模型（VLM）中缺乏可解释性的问题。TAB层插入在传统MHSA之后，并能将总注意力限制在[0, 1]范围内，从而实现对视觉信息流的精细控制，允许用户干预和调试。实验表明，在图像差异字幕任务中，带有TAB的VLM在保持字幕性能的同时，显著提升了定位图像变化和识别无变化情况的能力，并且是首个支持通过编辑注意力进行调试的架构。

> **摘要翻译:** 多头自注意力（MHSA）是Transformer的关键组件，Transformer是一种在语言和视觉领域都广受欢迎的架构。多个头直观地使相同的输入能够进行不同的并行处理。然而，它们也模糊了每个输入补丁对模型输出的归因。我们提出了一种新颖的1头Transformer注意力瓶颈（TAB）层，插入在传统MHSA架构之后，作为可解释性和干预的注意力瓶颈。与标准自注意力不同，TAB将所有补丁的总注意力限制在[0, 1]范围内。也就是说，当总注意力为0时，没有视觉信息进一步传播到网络中，视觉-语言模型（VLM）将默认生成通用、与图像无关的响应。为了展示TAB的优势，我们训练了带有TAB的VLM来执行图像差异字幕任务。在三个数据集上，我们的模型在字幕方面与基线VLM表现相似，但该瓶颈在定位变化和识别无变化情况方面表现更优。TAB是第一个允许用户通过编辑注意力进行调试的架构，这通常会产生VLM的预期输出。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [760] [Mind the Gap: Bridging Occlusion in Gait Recognition via Residual Gap Correction](https://arxiv.org/abs/2507.10978)
> *弥合差距：通过残差间隙校正弥合步态识别中的遮挡问题*

*Ayush Gupta, Siyuan Huang, Rama Chellappa* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 步态识别, 遮挡, 残差学习, 人员再识别, RG-Gait

**Comment:** Accepted at IJCB 2025

> **TL;DR:** 提出RG-Gait，一种通过残差学习解决步态识别中遮挡问题的方法，同时保持对完整输入的性能。

**AI_Comments:** 该论文通过引入残差学习来解决步态识别中遮挡这一实际且重要的问题，具有创新性。其核心思想是将遮挡视为对完整步态表示的残差偏差，并自适应地进行校正，有效避免了对成对遮挡数据的依赖，并解决了现有方法在处理遮挡时性能下降的问题。这对于提升步态识别在复杂现实环境中的鲁棒性和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前大多数步态识别方法未能有效处理遮挡问题，特别是难以获取成对的遮挡和完整序列数据，且现有方法在处理遮挡时会牺牲对完整输入的性能。

**Method:** 提出RG-Gait，将遮挡步态识别建模为残差学习任务，将遮挡步态特征视为相对于完整步态表示的残差偏差。该网络自适应地整合学习到的残差。

**Result:** 在Gait3D、GREW和BRIAR数据集上进行了评估，结果显示该方法显著提高了遮挡步态序列的识别性能，同时不影响完整步态的识别精度。

**Conclusion:** 学习残差是一种有效解决遮挡步态识别并保持完整性识别性能的技术。

> **ai_Abstract:** 本论文提出了RG-Gait，旨在解决步态识别中实际存在的遮挡问题。现有方法在处理遮挡时往往需要难以获取的成对数据，或牺牲对完整输入的识别性能。RG-Gait将遮挡步态识别视为残差学习任务，通过学习遮挡步态与完整步态之间的残差偏差并自适应整合，显著提升了遮挡步态的识别精度，同时保持了对完整步态的识别性能。在Gait3D、GREW和BRIAR数据集上的实验证明了该方法的有效性。

> **摘要翻译:** 步态作为一种远距离识别个体的方法越来越受欢迎。然而，目前大多数步态识别工作并未解决实际存在的遮挡问题。在那些处理了遮挡问题的工作中，有些需要成对的遮挡和完整序列，这在现实世界中是不切实际的。此外，这些方法在处理遮挡时有效，但未能保持对完整输入的性能。为了应对这些挑战，我们提出了RG-Gait，一种用于遮挡步态识别的残差校正方法，并能保持对完整输入的性能。我们将该问题建模为残差学习任务，将遮挡步态特征概念化为与完整步态表示的残差偏差。我们提出的网络自适应地整合了学习到的残差，显著提高了遮挡步态序列的性能，而不会影响完整步态的识别精度。我们在具有挑战性的Gait3D、GREW和BRIAR数据集上评估了我们的方法，并表明学习残差是解决遮挡步态识别并保持完整性识别性能的有效技术。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [764] [ProactiveVideoQA: A Comprehensive Benchmark Evaluating Proactive Interactions in Video Large Language Models](https://arxiv.org/abs/2507.09313)
> *ProactiveVideoQA: 评估视频大型语言模型中主动交互的综合基准*

*Yueqian Wang, Xiaojun Meng, Yifan Wang, Huishuai Zhang, Dongyan Zhao* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 主动交互, 视频大语言模型, 基准测试, PAUC, 多模态对话

**Comment:** 

> **TL;DR:** 本文提出了ProactiveVideoQA，一个用于评估视频大语言模型中主动交互能力的综合基准，并引入了PAUC，一个考虑时间动态的新度量，该度量与人类偏好更一致。

**AI_Comments:** 本文的创新点在于首次提出了一个针对视频大语言模型主动交互能力的综合基准ProactiveVideoQA，并引入了PAUC这一新颖的度量指标。PAUC的独特之处在于它考虑了模型响应的时间动态性，这对于评估主动式交互系统至关重要，因为它反映了响应的及时性。通过用户研究证明PAUC与人类偏好更一致，这凸显了其在实际应用中的重要性，为未来多模态对话系统的评估提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 随着多模态对话系统研究的日益关注，主动交互能力逐渐获得认可。用户期望多模态系统更具主动性，例如在视频播放过程中实时自主决定多轮响应的时机，以替代传统的轮流对话方式。

**Method:** 本文引入了ProactiveVideoQA，第一个用于评估系统主动交互能力的综合基准。由于模型响应在不同时间戳生成，本文进一步提出了PAUC，第一个考虑模型响应时间动态的度量。通过在ProactiveVideoQA上对各种基线系统进行广泛基准测试，并进行用户研究。

**Result:** 通过对ProactiveVideoQA上各种基线系统进行广泛基准测试以及对人类偏好的用户研究，结果表明PAUC比传统评估指标（通常只考虑响应的文本内容）与人类偏好更一致。

**Conclusion:** 这些发现表明，PAUC在主动交互场景中提供了对用户体验更忠实的评估。

> **ai_Abstract:** 本文针对多模态对话系统中日益增长的主动交互需求，提出了ProactiveVideoQA，一个评估视频大语言模型主动交互能力的综合基准。为了准确评估模型在不同时间戳生成响应的特性，研究引入了PAUC，一个考虑时间动态的新度量。通过广泛的基准测试和用户研究，结果显示PAUC比传统仅关注文本内容的评估指标更能反映人类偏好，从而为主动交互场景中的用户体验提供更准确的评估。

> **摘要翻译:** 随着对多模态对话系统研究关注的增长，主动交互能力正逐渐获得认可。作为传统轮流对话的替代方案，用户越来越期望多模态系统更具主动性，例如在视频播放过程中实时自主决定多轮响应的时机。为了促进这一新兴领域的发展，我们引入了ProactiveVideoQA，这是第一个评估系统主动交互能力的综合基准。由于模型响应是在不同的时间戳生成的，我们进一步提出了PAUC，这是第一个考虑模型响应时间动态的度量。这使得对在主动设置下运行的系统能够进行更准确的评估。通过在ProactiveVideoQA上对各种基线系统进行广泛的基准测试以及对人类偏好的用户研究，我们发现PAUC比传统评估指标（通常只考虑响应的文本内容）与人类偏好更一致。这些发现表明，PAUC在主动交互场景中提供了对用户体验更忠实的评估。项目主页：https://github.com/yellow-binary-tree/ProactiveVideoQA

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [776] [UGC-VideoCaptioner: An Omni UGC Video Detail Caption Model and New Benchmarks](https://arxiv.org/abs/2507.11336)
> *UGC-VideoCaptioner: 一个全能UGC视频细节字幕模型和新基准*

*Peiran Wu, Yunze Liu, Zhengdong Zhu, Enmin Zhou, Shawn Shen* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** UGC视频字幕, 全模态, 音视频集成, 基准, 多模态理解

**Comment:** 

> **TL;DR:** 现有视频字幕模型忽视音频，本文提出一个新数据集（UGC-VideoCap）和模型（UGC-VideoCaptioner），用于UGC视频的详细全模态字幕，高效整合音频和视觉模态。

**AI_Comments:** 该论文通过解决音频在视频字幕中，特别是UGC内容中未被充分探索的作用，做出了重大贡献。引入了通过人机协作标注过程创建的新型全模态数据集（UGC-VideoCap），这对于推进该领域的研究至关重要。所提出的UGC-VideoCaptioner模型，从强大的大型模型中提取并采用新颖的两阶段训练策略，展示了一种利用有限数据处理复杂多模态任务的有效方法。这项工作为在真实世界场景中更全面的视频理解奠定了宝贵的基础。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界的用户生成视频（如TikTok）常包含丰富的音视频内容，但现有视频字幕基准和模型主要以视觉为中心，忽视了音频在传达场景动态、说话人意图和叙事背景中的关键作用。这种缺乏全能数据集和轻量级、有能力模型的情况阻碍了细粒度、多模态视频理解的进展。

**Method:** 1. 引入UGC-VideoCap：一个为短视频用户生成视频设计的详细全模态字幕新基准，强调音频和视觉模态的平衡集成。该数据集包含1000个通过三阶段人机协作流程（涵盖仅音频、仅视觉和联合音视频语义）标注的TikTok视频，以及4000个用于探究单模态和跨模态理解的QA对。 2. 提出UGC-VideoCaptioner(3B)：一个从Gemini 2.5 Flash中提取的3B参数字幕模型。 3. 采用新颖的两阶段训练策略：监督微调，然后是组相对策略优化（GRPO），以实现在有限数据下高效适应并保持竞争力。

**Result:** 所提出的基准和模型为在无约束的真实世界UGC环境中推进全模态视频字幕提供了高质量的基础和数据高效的解决方案。该方法能够在有限数据下实现高效适应，同时保持有竞争力的性能。

**Conclusion:** 本文介绍了UGC-VideoCap和UGC-VideoCaptioner，为推进真实世界UGC的全模态视频字幕提供了高质量的基础和数据高效的解决方案，解决了当前以视觉为中心的方法的局限性。

> **ai_Abstract:** 本文通过引入UGC-VideoCap解决了以视觉为中心的视频字幕的局限性，UGC-VideoCap是一个用于短视频用户生成视频的新型全模态基准，整合了音频和视觉模态。该基准包含1000个带有详细标注的TikTok视频和4000个问答对。作为数据集的补充，作者提出了UGC-VideoCaptioner（3B），一个从Gemini 2.5 Flash中提取的30亿参数模型，采用两阶段训练策略（监督微调和GRPO），以实现在有限数据下高效适应，同时为真实世界UGC视频字幕保持有竞争力的性能。

> **摘要翻译:** 现实世界的用户生成视频，尤其是在TikTok等平台上，通常具有丰富而交织的音视频内容。然而，现有的视频字幕基准和模型仍然主要以视觉为中心，忽视了音频在传达场景动态、说话人意图和叙事背景方面的关键作用。这种全能数据集和轻量级、有能力模型的缺乏阻碍了细粒度、多模态视频理解的进展。为了解决这些挑战，我们引入了UGC-VideoCap，一个专门为短视频用户生成视频的详细全模态字幕设计的新基准和模型框架。与以往的数据集不同，UGC-VideoCap强调音频和视觉模态的平衡集成，包含1000个通过结构化三阶段人机协作流程（涵盖仅音频、仅视觉和联合音视频语义）标注的TikTok视频。该基准还包括4000个精心制作的QA对，用于探究单模态和跨模态理解。除了数据集，我们提出了UGC-VideoCaptioner（3B），一个从Gemini 2.5 Flash中提取的3B参数字幕模型。通过一种新颖的两阶段训练策略——监督微调，然后是组相对策略优化（GRPO），我们的方法能够在有限数据下实现高效适应，同时保持有竞争力的性能。总而言之，我们的基准和模型为在无约束的真实世界UGC环境中推进全模态视频字幕提供了高质量的基础和数据高效的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [780] [Warehouse Spatial Question Answering with LLM Agent](https://arxiv.org/abs/2507.10778)
> *仓库空间问答与LLM代理*

*Hsiang-Wei Huang, Jen-Hao Cheng, Kuang-Ming Chen, Cheng-Yen Yang, Bahaa Alattar, Yi-Ru Lin, Pyongkun Kim, Sangwon Kim, Kwangju Kim, Chung-I Huang, Jenq-Neng Hwang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-14**

**Keywords:** LLM代理, 空间推理, 仓库, 问答, 数据高效

**Comment:** 1st Place Solution of the 9th AI City Challenge Track 3

> **TL;DR:** 本文提出了一个数据高效的LLM代理系统，用于解决复杂室内仓库场景中的空间问答任务，并在物体检索、计数和距离估计等任务中实现了高精度和高效率。

**AI_Comments:** 该论文的创新点在于提出了一个数据高效的LLM代理系统来解决空间理解难题，避免了传统MLLM大规模微调的需求。其通过集成多种工具实现空间推理和API交互，为复杂室内场景下的空间问答提供了一个实用且高效的解决方案。在实际应用中，这对于提升仓库自动化和智能管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态大型语言模型（MLLMs）的空间理解能力面临挑战，且以往的方法依赖于大规模的MLLM微调。本文旨在提出一种数据高效的方法来解决复杂室内仓库场景中的空间问答任务。

**Method:** 本文提出了一个LLM代理系统，该系统具有强大的高级空间推理能力。该系统集成了多种工具，使LLM代理能够进行空间推理和API工具交互，以回答复杂的空间问题。

**Result:** 在2025年AI城市挑战赛物理AI空间智能仓库数据集上的广泛评估表明，该系统在物体检索、计数和距离估计等任务中实现了高精度和高效率。

**Conclusion:** 本文提出的LLM代理系统能够有效解决复杂仓库环境中的空间问答任务，且无需大规模模型微调，展现出高精度和高效率。

> **ai_Abstract:** 本文提出了一种数据高效的LLM代理系统，旨在解决复杂室内仓库场景中的空间问答任务。该系统通过集成多种工具，使LLM代理能够执行空间推理和API工具交互。在2025年AI城市挑战赛物理AI空间智能仓库数据集上的评估显示，该系统在物体检索、计数和距离估计等任务上表现出高精度和高效率，证明了其在增强MLLM空间理解能力方面的有效性，且无需大规模微调。

> **摘要翻译:** 空间理解对于现有的多模态大型语言模型（MLLM）来说一直是一个具有挑战性的任务。以往的方法利用大规模的MLLM微调来增强其空间理解能力。在本文中，我们提出了一种数据高效的方法。我们提出了一个具有强大和先进空间推理能力的LLM代理系统，可用于解决复杂的室内仓库场景中具有挑战性的空间问答任务。我们的系统集成了多种工具，使LLM代理能够进行空间推理和API工具交互，以回答给定的复杂空间问题。在2025年AI城市挑战赛物理AI空间智能仓库数据集上的广泛评估表明，我们的系统在物体检索、计数和距离估计等任务中实现了高精度和高效率。代码可在：https://github.com/hsiangwei0903/SpatialAgent 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [792] [(Almost) Free Modality Stitching of Foundation Models](https://arxiv.org/abs/2507.10015)
> *(几乎)免费的基础模型模态拼接*

*Jaisidh Singh, Diganta Misra, Boris Knyazev, Antonio Orvieto* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 多模态模型, 模型拼接, 超网络, 计算效率, 模型对齐

**Comment:** Pre-print

> **TL;DR:** 本文提出了Hypernetwork Model Alignment (Hyma)框架，利用超网络显著降低了多模态模型中单模态模型选择和连接器训练的计算成本，同时保持了性能。

**AI_Comments:** 这项工作通过引入超网络来解决多模态基础模型拼接中单模态模型选择和连接器训练的计算效率问题，具有显著的创新性。其“几乎免费”的成本降低（10倍）对于大规模多模态模型开发具有重要意义，有望加速新模型组合的探索和部署。该方法通过参数预测避免了昂贵的网格搜索，提高了资源利用率。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基础多模态模型通过训练连接器模块来拼接预训练的单模态模型，但在大规模数据集上训练连接器以及选择最佳单模态模型组合的计算成本极高。

**Method:** 本文提出了Hypernetwork Model Alignment (Hyma)，一个利用超网络进行最优单模态模型选择和连接器训练的集成解决方案。Hyma利用超网络的参数预测能力，同时获得N x M种单模态模型组合的连接器模块。

**Result:** 实验表明，Hyma将搜索最佳单模态模型对的成本降低了10倍，同时在多种多模态基准测试中，其性能和排名与网格搜索方法相当。

**Conclusion:** Hyma通过利用超网络显著降低了基础多模态模型中单模态模型选择和连接器训练的计算成本，提供了一个高效且性能匹配的解决方案。

> **ai_Abstract:** 本文针对基础多模态模型中单模态模型选择和连接器训练计算成本高昂的问题，提出了一种名为Hypernetwork Model Alignment (Hyma)的新型一体化解决方案。Hyma利用超网络预测连接器模块的参数，从而同时优化N x M种单模态模型组合的选择与训练。实验证明，Hyma能将最佳单模态模型对的搜索成本降低10倍，同时在性能上与传统的网格搜索方法相当，有效解决了多模态模型拼接的效率瓶颈。

> **摘要翻译:** 基础多模态模型通常通过拼接多个现有预训练的单模态模型来设计：例如，一个图像分类器与一个文本模型。这种拼接过程通过训练一个连接器模块来完成，该模块旨在将这些单模态模型的表示空间对齐以实现多模态目标。然而，鉴于在大规模网络数据集上训练此类连接器的复杂性，以及可用预训练单模态模型数量的不断增加，单模态模型选择和后续连接器模块训练的任务变得计算成本极高。为了解决这个未被充分研究的关键问题，我们提出了Hypernetwork Model Alignment (Hyma)，一个新颖的一体化解决方案，通过利用超网络实现最优的单模态模型选择和连接器训练。具体来说，我们的框架利用超网络的参数预测能力，为N × M种单模态模型组合获得联合训练的连接器模块。在我们的实验中，Hyma将搜索最佳性能单模态模型对的成本降低了10倍，同时在各种多模态基准测试中，其排名和训练出的连接器性能与通过网格搜索获得的结果相匹配。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [798] [Self-Supervised Cross-Modal Text-Image Time Series Retrieval in Remote Sensing](https://arxiv.org/abs/2501.19043)
> *遥感中自监督跨模态文本-图像时间序列检索*

*Genc Hoxha, Olivér Angyal, Begüm Demir* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 遥感, 跨模态检索, 自监督学习, 文本-图像检索, 时间序列

**Comment:** 

> **TL;DR:** 本文提出了一种用于遥感领域的自监督跨模态文本-图像时间序列检索（text-ITSR）方法，解决了现有单模态检索的局限性，实现了文本查询图像时间序列或图像查询文本的能力。

**AI_Comments:** 该论文通过引入跨模态检索，解决了当前遥感图像时间序列检索中的一个重要局限性，具有显著的创新性。其自监督学习方法也增强了其实用性。提出的两种时间信息融合策略（GFF和TFF）是具体的技术贡献。

<details>
  <summary>Details</summary>

**Motivation:** 遥感领域现有的图像时间序列检索（ITSR）方法是单模态的，并假设用户总是能获得查询图像时间序列。然而，在实际操作场景中，这一假设可能不成立，因此需要开发能够跨模态检索的方法。

**Method:** 本文提出了一种自监督跨模态文本-图像时间序列检索（text-ITSR）方法，专注于双时相图像。该方法包括两个关键组件：1）特定模态编码器，用于对双时相图像和文本语句的语义内容进行建模，生成判别性特征；2）特定模态投影头，用于在共享嵌入空间中对齐文本和图像表示。为了有效建模双时相图像中的时间信息，利用了两种融合策略：全局特征融合（GFF）和基于Transformer的特征融合（TFF）。

**Result:** 在两个基准遥感档案上进行的广泛实验表明，该方法能够有效地准确检索与查询文本语句（或双时相图像）语义相关的双时相图像（或文本语句）。

**Conclusion:** 该论文提出的自监督跨模态文本-图像时间序列检索方法有效地克服了遥感领域单模态检索的局限性，通过实现文本到图像和图像到文本的时间序列检索，扩展了ITSR在实际操作场景中的适用性。

> **ai_Abstract:** 本文首次在遥感领域引入了自监督跨模态文本-图像时间序列检索（text-ITSR）任务，旨在解决现有单模态ITSR方法无法处理文本查询的局限性。所提出的方法能够使用文本查询图像时间序列，反之亦然，并专注于双时相图像。其核心组件包括特定模态编码器和投影头，用于语义建模和跨模态对齐。为处理时间信息，该方法采用了全局特征融合（GFF）和基于Transformer的特征融合（TFF）策略。实验证明了该方法在准确检索语义相关内容方面的有效性。

> **摘要翻译:** 遥感（RS）中图像时间序列检索（ITSR）方法的发展是一个日益增长的研究兴趣。给定用户定义的图像时间序列（即查询时间序列），ITSR方法从大型档案中搜索并检索与查询时间序列内容相似的图像时间序列。遥感中现有的ITSR方法是为单模态检索问题设计的，它们依赖于用户总能访问所考虑图像模态中的查询图像时间序列的假设。在实际操作场景中，这个假设可能不成立。为了克服这个问题，我们首次在遥感中引入了跨模态文本-图像时间序列检索（text-ITSR）任务。具体来说，我们提出了一种自监督跨模态text-ITSR方法，该方法能够使用文本语句作为查询来检索图像时间序列，反之亦然。我们将重点放在图像对（即双时相图像）中的text-ITSR。我们的text-ITSR方法由两个关键组件组成：1）特定模态编码器，用于使用判别特征对双时相图像和文本语句的语义内容进行建模；2）特定模态投影头，用于在共享嵌入空间中对齐文本和图像表示。为了有效建模双时相图像中的时间信息，我们利用了两种融合策略：i）全局特征融合（GFF）策略，通过简单而有效的运算符组合全局图像特征；ii）基于Transformer的特征融合（TFF）策略，利用Transformer进行细粒度时间整合。在两个基准遥感档案上进行的广泛实验证明了我们方法在准确检索与查询文本语句（或双时相图像）语义相关的双时相图像（或文本语句）方面的有效性。本工作的代码已公开在https://git.tu-berlin.de/rsim/cross-modal-text-tsir。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [803] [Try Harder: Hard Sample Generation and Learning for Clothes-Changing Person Re-ID](https://arxiv.org/abs/2507.11119)
> *再接再厉：用于变装行人重识别的难样本生成与学习*

*Hankun Liu, Yujian Zhao, Guanglin Niu* | **Category: cs.CV** | **Updated: 2025-07-15**

**Keywords:** 变装行人重识别, 难样本生成, 多模态学习, 深度学习, 行人重识别

**Comment:** 

> **TL;DR:** 本文提出了一个多模态引导的难样本生成与学习（HSGL）框架，通过生成粗粒度和细粒度难样本并引入硬度感知优化策略，显著提升了变装行人重识别（CC-ReID）的性能和模型鲁棒性。

**AI_Comments:** 本文的创新点在于首次将文本和视觉模态统一起来，用于难样本的定义、生成和优化，这为解决CC-ReID中的难样本问题提供了一个新颖且全面的视角。双粒度难样本生成（DGHSG）和硬度感知自适应学习（HSAL）的结合，不仅提高了训练数据的质量，也优化了模型的学习过程。该方法在解决CC-ReID鲁棒性方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 难样本在行人重识别（ReID）任务中，尤其是在变装行人重识别（CC-ReID）中，构成了重大挑战。它们的固有歧义性或相似性，加上缺乏明确定义，使其成为一个根本性瓶颈。这些问题不仅限制了针对性学习策略的设计，还削弱了模型在衣着或视角变化下的鲁棒性。

**Method:** 本文提出了一个新颖的多模态引导的难样本生成与学习（HSGL）框架，这是首次统一文本和视觉模态以在统一范式内明确定义、生成和优化难样本。HSGL包含两个核心组件：1) 双粒度难样本生成（DGHSG），它利用多模态线索合成语义一致的样本，包括粗粒度和细粒度的难正样本和负样本，以有效增加训练数据的硬度和多样性。2) 难样本自适应学习（HSAL），它引入了一种硬度感知优化策略，根据文本语义标签调整特征距离，鼓励难正样本分离，并使难负样本在嵌入空间中更接近，以增强模型的判别能力和对难样本的鲁棒性。

**Result:** 在多个CC-ReID基准上进行的广泛实验证明了我们方法的有效性，并强调了多模态引导的难样本生成和学习对于鲁棒CC-ReID的潜力。值得注意的是，HSAL显著加速了目标学习过程的收敛，并在PRCC和LTCC数据集上取得了最先进的性能。

**Conclusion:** 本文提出的多模态引导的难样本生成与学习（HSGL）框架，通过其双粒度难样本生成和硬度感知自适应学习策略，有效解决了变装行人重识别中难样本的挑战，显著提升了模型的判别能力和鲁棒性，并在多个基准测试中取得了SOTA性能。

> **ai_Abstract:** 本文针对变装行人重识别（CC-ReID）中难样本的挑战，提出了一个新颖的多模态引导的难样本生成与学习（HSGL）框架。该框架首次将文本和视觉模态相结合，明确定义、生成和优化难样本。HSGL包含双粒度难样本生成（DGHSG）和难样本自适应学习（HSAL）两个核心组件，分别用于增加训练数据的硬度和多样性，以及通过硬度感知优化策略增强模型对难样本的判别能力和鲁棒性。实验证明，该方法在多个CC-ReID基准上表现出色，尤其在PRCC和LTCC数据集上达到了最先进的性能，并加速了收敛。

> **摘要翻译:** 难样本在行人重识别（ReID）任务中，尤其是在变装行人重识别（CC-ReID）中，构成了重大挑战。它们的固有歧义性或相似性，加上缺乏明确定义，使其成为一个根本性瓶颈。这些问题不仅限制了针对性学习策略的设计，还削弱了模型在衣着或视角变化下的鲁棒性。在本文中，我们提出了一个新颖的多模态引导的难样本生成与学习（HSGL）框架，这是首次努力统一文本和视觉模态，以在统一范式内明确定义、生成和优化难样本。HSGL包含两个核心组件：(1) 双粒度难样本生成（DGHSG），它利用多模态线索合成语义一致的样本，包括粗粒度和细粒度的难正样本和负样本，以有效增加训练数据的硬度和多样性。(2) 难样本自适应学习（HSAL），它引入了一种硬度感知优化策略，根据文本语义标签调整特征距离，鼓励难正样本分离，并使难负样本在嵌入空间中更接近，以增强模型的判别能力和对难样本的鲁棒性。在多个CC-ReID基准上进行的广泛实验证明了我们方法的有效性，并强调了多模态引导的难样本生成和学习对于鲁棒CC-ReID的潜力。值得注意的是，HSAL显著加速了目标学习过程的收敛，并在PRCC和LTCC数据集上取得了最先进的性能。代码可在https://github.com/undooo/TryHarder-ACMMM25获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [7] [Towards Creating Infrastructures for Values and Ethics Work in the Production of Software Technologies](https://arxiv.org/abs/2507.11490)
> *迈向在软件技术生产中创建价值观和伦理工作的基础设施*

*Richmond Y. Wong* | **Category: cs.HC** | **Updated: 2025-07-15**

**Keywords:** 价值观和伦理, 软件生产, 人机交互 (HCI), 基础设施, 设计

**Comment:** In The sixth decennial Aarhus conference: Computing X Crisis (AAR
  2025)

> **TL;DR:** 本文主张在软件生产中，应通过创建“基础设施”而非仅仅“工具”来整合价值观和伦理，以考虑更广泛的系统性因素。

**AI_Comments:** 本文在解决软件开发中的价值观和伦理问题方面提出了一个关键的概念性转变。从“工具”转向“基础设施”的视角，承认了技术生产的系统性和政治性，而不仅仅关注个体设计师的能动性。这种重新构建是创新的，因为它鼓励一种更全面和有影响力的L方法，可能带来更可持续和公平的技术成果。其局限性可能在于它是一篇概念性论文，而“价值观和伦理基础设施”的实际实施需要大量后续工作。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人机交互（HCI）研究在设计中解决价值观和伦理问题时，通常通过创建工具来帮助技术工作者，但这些方法未能充分考虑影响技术工作者行动的更广泛的政治、组织、社会系统和治理结构，导致技术系统可能体现有害的社会价值观或造成危害。

**Method:** 本文提出了一种从创建“工具”转向创建“基础设施”来支持价值观和伦理工作的方法。它借鉴了科学技术研究（STS）和媒体研究中关于基础设施的现有概念性见解。

**Result:** 本文概述了基础设施研究中的概念性见解，这些见解为HCI研究人员和设计师提供了新的策略，以通过考虑更广泛的系统性过程来更好地在设计中支持价值观和伦理。

**Conclusion:** 创建基础设施而非仅仅工具，是更有效地将价值观和伦理融入软件生产的方法，因为它能考虑到复杂的、更广泛的过程和系统。

> **ai_Abstract:** 本文批判性地审视了现有的人机交互（HCI）方法，这些方法通过工具将价值观和伦理融入软件设计，并指出其在处理更广泛的政治和系统背景方面的局限性。论文提出了一种根本性的转变，即转向创建“基础设施”而非仅仅“工具”来支持价值观和伦理工作。通过借鉴科学技术研究和媒体研究的见解，本文认为以基础设施为中心的方法可以更好地解释复杂的组织和社会因素，从而为HCI研究人员和设计师在技术生产中嵌入价值观和伦理提供更有效的策略。

> **摘要翻译:** 认识到技术系统如何体现社会价值观或造成危害，人机交互（HCI）研究通常通过创建工具来帮助技术工作者将社会价值观整合到产品设计中，从而解决设计中的价值观和伦理问题。虽然这些方法很有用，但它们通常不考虑影响技术工作者为解决价值观和伦理问题所能采取行动的更广泛流程、组织、社会系统和治理结构中嵌入的政治因素。本文认为，创建支持价值观和伦理工作的基础设施，而不是工具，是一种考虑这些更广泛流程并为它们（重新）设计打开大门的方法。本文借鉴了科学技术研究和媒体研究中关于基础设施的现有概念研究，概述了基础设施研究中的概念性见解，这些见解为寻求在设计中支持价值观和伦理的HCI研究人员和设计师开辟了新的策略。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [374] [Theory of Mind and Self-Disclosure to CUIs](https://arxiv.org/abs/2507.10773)
> *心智理论与向对话用户界面自我表露*

*Samuel Rhys Cox* | **Category: cs.HC, cs.CL** | **Updated: 2025-07-14**

**Keywords:** 自我表露, 对话用户界面, 心智理论, 社交线索

**Comment:** Workshop paper presented at ToMinHAI at CUI'2025: Theory of Mind in
  Human-CUI Interaction, held in conjunction with the 2025 ACM conference on
  Conversational User Interfaces, July 8th, 2025. 4 pages. 3 figures

> **TL;DR:** 该工作坊论文探讨了自我表露的困难，并提出通过使对话用户界面（CUIs）的“心智理论”更透明，以鼓励用户向其进行自我表露。

**AI_Comments:** 这篇工作坊论文提出了一个有趣且重要的概念性框架，探讨了心智理论在人机交互中，尤其是在鼓励用户向对话用户界面进行自我表露方面的潜在应用。其创新点在于将人类自我表露的心理障碍与CUI的设计相结合，为未来CUI的设计提供了新的思路。然而，由于是工作坊论文，其内容可能更多是概念性的讨论而非实证研究。

<details>
  <summary>Details</summary>

**Motivation:** 自我表露对个人福祉很重要，但由于对他人反应的担忧而往往很困难。本研究的动机是探讨如何鼓励用户向对话用户界面（CUIs）进行自我表露。

**Method:** 本工作坊论文通过讨论自我表露与对话用户界面（CUIs）中各种社交线索的关系，并探讨了不确定性表达或CUI推理表示如何帮助鼓励自我表露。

**Result:** 本工作坊论文讨论了表达不确定性或表示CUI的推理如何通过使CUI预期的“心智理论”对用户更透明来帮助鼓励自我表露。没有具体实验结果，而是概念性讨论。

**Conclusion:** 通过使对话用户界面（CUIs）的“心智理论”更加透明，例如通过表达不确定性或展示其推理过程，可以有效地鼓励用户进行自我表露。

> **ai_Abstract:** 本工作坊论文探讨了自我表露的固有困难，尤其是在考虑到他人反应时。论文提出，通过使对话用户界面（CUIs）的“心智理论”更加透明，例如通过表达不确定性或展示其推理过程，可以有效鼓励用户向CUIs进行自我表露。

> **摘要翻译:** 自我表露对于帮助我们感觉更好很重要，但往往很困难。这种困难可能源于我们认为人们将如何回应我们的自我表露。在这篇工作坊论文中，我们简要讨论了向对话用户界面（CUIs）进行自我表露与各种社交线索的关系。然后，我们讨论了不确定性表达或CUI推理的表示如何通过使CUI预期的“心智理论”对用户更透明来帮助鼓励自我表露。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [404] [React to This (RTT): A Nonverbal Turing Test for Embodied AI](https://arxiv.org/abs/2507.10812)
> *对此做出反应 (RTT)：一种用于具身 AI 的非语言图灵测试*

*Chuxuan Zhang, Yasaman Etesam, Angelica Lim* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 具身AI, 图灵测试, 非语言行为, 交互意识, 可信度

**Comment:** 5 pages, 3 figures

> **TL;DR:** 提出一种名为“React to This (RTT)”的非语言图灵测试，用于评估具身AI的交互意识和可信度。

**AI_Comments:** 这项工作创新性地将图灵测试的概念扩展到非语言交互领域，为评估具身AI的“反应能力”和“可信度”提供了一个新颖且重要的视角。它强调了AI在面对人类挑战时的行为表现，对于开发更具拟人化和鲁棒性的AI具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在测试具身AI代理的交互意识和可信度，特别是在人类将其推向极限的场景中，并受图灵测试启发，提出“机器能否反应？”的新问题。

**Method:** 提出“React to This (RTT)”测试，专注于非语言行为，以评估具身AI代理的交互意识和可信度。

**Result:** 论文展示了初步实验的结果。

**Conclusion:** 论文引入了RTT测试作为评估具身AI非语言反应能力的新方法，并展示了其初步应用。

> **ai_Abstract:** 本文提出了一种名为“React to This (RTT)”的非语言图灵测试，旨在评估具身AI代理在人类极限情境下的交互意识和可信度。该测试基于图灵测试的理念，聚焦于“机器能否反应？”这一问题，并已通过初步实验验证。

> **摘要翻译:** 我们提出一种方法来测试具身AI代理的交互意识和可信度，特别是在人类将其推向极限的场景中。图灵引入了模仿游戏来探索“机器能思考吗？”这个问题。全面图灵测试后来将这一概念扩展到纯粹的语言交流之外，融入了感知和物理交互。在此基础上，我们提出了一个新的指导性问题：“机器能反应吗？”并引入了“对此做出反应 (RTT)”测试，用于非语言行为，并展示了初步实验的结果。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [446] [Static or Temporal? Semantic Scene Simplification to Aid Wayfinding in Immersive Simulations of Bionic Vision](https://arxiv.org/abs/2507.10813)
> *静态还是动态？仿生视觉沉浸式模拟中语义场景简化以辅助寻路*

*Justin M. Kasowski, Apurv Varshney, Michael Beyeler* | **Category: cs.HC** | **Updated: 2025-07-14**

**Keywords:** 仿生视觉, 语义简化, 寻路, 沉浸式模拟, 低带宽视觉

**Comment:** 

> **TL;DR:** 本文研究了两种语义预处理策略（SemanticEdges和SemanticRaster）在仿生视觉模拟中如何帮助用户寻路。结果表明，两者均能提升性能和用户体验，但各有侧重：SemanticEdges提高成功率，SemanticRaster减少碰撞。

**AI_Comments:** 这篇论文探讨了在仿生视觉受限环境下，如何通过智能的语义信息呈现来优化用户体验和任务效率，具有重要的应用价值。其创新点在于比较了静态和动态两种信息呈现方式的优劣，为未来的低带宽视觉界面设计提供了实证指导。研究结果表明，根据具体任务需求，可以选择不同的信息简化策略，这对于提升仿生眼用户的生活质量和拓展XR应用场景具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 视觉神经假体（仿生眼）旨在恢复基本视力，但在极端分辨率和带宽限制下，同时呈现所有任务相关信息可能会让用户感到不知所措，因此需要改进场景理解和信息呈现方式。

**Method:** 研究比较了SemanticEdges（同时突出显示所有相关对象）和SemanticRaster（随时间错开对象类别以减少视觉混乱）两种语义预处理方法。18名有视力参与者在生物学基础的假体视觉模拟中，于动态城市环境下执行寻路任务，分为基线、SemanticEdges和SemanticRaster三种条件。

**Result:** 相对于基线，两种语义策略都提高了性能和用户体验。SemanticEdges增加了成功的几率，而SemanticRaster提高了无碰撞完成的可能性。

**Conclusion:** 这些发现强调了自适应语义预处理对假体视觉的价值，并可能为XR中必须平衡信息密度、任务相关性和感知清晰度的低带宽视觉界面的设计提供信息。

> **ai_Abstract:** 本文探讨了在仿生视觉沉浸式模拟中，两种不同的语义场景简化策略（SemanticEdges和SemanticRaster）如何辅助用户寻路。研究发现，相较于基线，这两种方法均能提升性能和用户体验，但各有侧重：SemanticEdges有助于提高任务成功率，而SemanticRaster则能减少碰撞。研究结果强调了自适应语义预处理在假体视觉乃至低带宽XR界面设计中的重要性。

> **摘要翻译:** 视觉神经假体（仿生眼）旨在通过将摄像机输入转换为电刺激模式来恢复一种基本形式的视力。为了在极端分辨率和带宽限制下改善场景理解，先前的研究已经探索了语义分割和深度估计等计算机视觉技术。然而，在杂乱环境中同时呈现所有与任务相关的信息可能会让用户感到不知所措。我们在沉浸式虚拟现实中比较了两种互补的语义预处理方法：SemanticEdges（一次性突出显示所有相关对象）和SemanticRaster（随时间错开对象类别以减少视觉混乱）。使用生物学基础的假体视觉模拟，18名有视力参与者在动态城市环境中执行寻路任务，分为三种条件：基于边缘的基线（对照组）、SemanticEdges和SemanticRaster。相对于基线，两种语义策略都提高了性能和用户体验，但各有权衡：SemanticEdges增加了成功的几率，而SemanticRaster提高了无碰撞完成的可能性。这些发现强调了自适应语义预处理对假体视觉的价值，更广泛地说，可能为XR中必须平衡信息密度、任务相关性和感知清晰度的低带宽视觉界面的设计提供信息。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [488] [AROMA: Mixed-Initiative AI Assistance for Non-Visual Cooking by Grounding Multi-modal Information Between Reality and Videos](https://arxiv.org/abs/2507.10963)
> *AROMA：通过将现实与视频之间的多模态信息接地，为非视觉烹饪提供混合主动式AI辅助*

*Zheng Ning, Leyang Li, Daniel Killough, JooYoung Seo, Patrick Carrington, Yapeng Tian, Yuhang Zhao, Franklin Mingzhe Li, Toby Jia-Jun Li* | **Category: cs.HC** | **Updated: 2025-07-15**

**Keywords:** AROMA, 非视觉烹饪, AI辅助, 盲人或低视力, 多模态信息

**Comment:** 

> **TL;DR:** AROMA是一个AI系统，通过整合用户感知的非视觉线索、可穿戴摄像头输入和视频食谱内容，为盲人或低视力（BLV）人士提供实时的烹饪辅助，帮助他们理解当前烹饪状态并遵循食谱步骤。

**AI_Comments:** AROMA的创新之处在于其混合主动式AI辅助方法，以及将多模态信息（包括非视觉线索和视频内容）整合以支持BLV用户进行复杂日常活动的能力。这项工作对于提高视频内容的可访问性和赋能残障人士独立生活具有重要意义，尤其是在烹饪这一需要高度环境感知的领域。

<details>
  <summary>Details</summary>

**Motivation:** 视频虽然包含丰富的视听信息，但对盲人或低视力（BLV）人士来说，在烹饪等日常活动中几乎无法使用。BLV人士在烹饪时通常依赖非视觉线索，难以遵循视频食谱中以视听为主的指令，因此需要一种解决方案来提高视频的可访问性。

**Method:** AROMA系统通过整合用户感知的非视觉线索、可穿戴摄像头输入和视频食谱内容，提供实时的、上下文感知的辅助。它采用混合主动式方法，既响应用户请求，也主动监控视频流以提供及时的警报和指导。这种协作设计利用了用户和AI系统的互补优势，将物理环境与视频食谱对齐。

**Result:** 通过对八名盲人或低视力参与者进行研究，评估了AROMA系统。

**Conclusion:** 研究为设计支持盲人或低视力个体进行日常活动的交互式AI系统提供了见解。

> **ai_Abstract:** AROMA是一个旨在帮助盲人或低视力（BLV）人士进行非视觉烹饪的AI系统。该系统通过整合用户感知的非视觉线索、可穿戴摄像头视频和视频食谱内容，提供实时的、上下文感知的辅助。AROMA采用混合主动式方法，既响应用户请求，也主动提供警报和指导，从而将物理烹饪环境与视频食谱同步。研究通过对八名BLV参与者进行评估，并为设计支持BLV人士进行日常活动的交互式AI系统提供了指导。

> **摘要翻译:** 视频提供了丰富的视听信息，可以支持人们进行日常生活活动（ADLs），但对于盲人或低视力（BLV）个体来说，这些视频在很大程度上是无法访问的。在烹饪中，BLV人士通常依赖非视觉线索，例如触觉、味觉和嗅觉，来导航他们的环境，这使得他们很难遵循视频食谱中以视听为主的指令。为了解决这个问题，我们引入了AROMA，这是一个AI系统，通过整合用户感知的非视觉线索、可穿戴摄像头输入和视频食谱内容，根据实时、上下文感知的辅助向用户提供及时响应。AROMA采用混合主动式方法：它响应用户请求，同时还主动监控视频流以提供及时的警报和指导。这种协作设计利用了用户和AI系统的互补优势，将物理环境与视频食谱对齐，帮助用户解释他们当前的烹饪状态并理解步骤。我们通过对八名BLV参与者进行研究评估了AROMA，并为设计支持BLV个体进行ADLs的交互式AI系统提供了见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [536] [Cluster Haptic Texture Database: Haptic Texture Database with Varied Velocity-Direction Sliding Contacts](https://arxiv.org/abs/2407.16206)
> *簇状触觉纹理数据库：具有不同速度-方向滑动接触的触觉纹理数据库*

*Michikuni Eguchi, Tomohiro Hayase, Yuichi Hiroi, Takefumi Hiraki* | **Category: cs.HC** | **Updated: 2025-07-15**

**Keywords:** 触觉数据库, 纹理识别, 多模态数据, 运动参数, 机器学习

**Comment:** dataset: https://doi.org/10.6084/m9.figshare.29438288 code:
  https://github.com/cluster-lab/Cluster-Haptic-Texture-Database

> **TL;DR:** 本文引入了一个名为“簇状触觉纹理数据库”的新型多模态数据集，通过精确控制滑动速度和方向来解决现有触觉数据库的不足，并利用卷积神经网络验证了其在纹理识别、速度和方向估计方面的有效性，对触觉科学和技术发展具有重要意义。

**AI_Comments:** 这篇论文通过引入一个具有精确控制滑动参数（速度和方向）的多模态触觉数据库，解决了现有触觉数据集中普遍存在的不足，即缺乏对运动参数的系统性控制。其创新之处在于利用三轴机器和人工手指实现了高精度的数据采集，并提供了多种模态的同步数据。该数据集的验证结果表明其在机器学习任务中的高实用性，对于推动触觉感知、触觉渲染和人机交互领域的研究具有重要意义，尤其是在开发更逼真的虚拟现实和机器人触觉界面方面。

<details>
  <summary>Details</summary>

**Motivation:** 现有的触觉数据库通过非受控探索收集数据，阻碍了对运动参数（例如，运动方向和速度）如何影响触觉感知的系统分析。

**Method:** 本文介绍了“簇状触觉纹理数据库”，这是一个多模态数据集，使用一台三轴机器和一个人工手指精确控制滑动速度和方向进行记录。该数据集涵盖了9种材料类别的118个纹理表面，并在5个速度级别（20-60毫米/秒）和8个方向下进行了记录。每个表面在160种条件下进行了测试，产生了18,880个同步的音频、加速度、力、位置和视觉数据记录。

**Result:** 使用卷积神经网络进行验证，纹理识别的分类准确率达到96%，速度估计为88.76%，方向估计为78.79%，证实了该数据集对机器学习应用的实用性。

**Conclusion:** 该资源能够促进触觉渲染、纹理识别算法和人类触觉感知机制的研究，支持为虚拟现实系统和机器人应用开发逼真的触觉界面。

> **ai_Abstract:** 本文推出了“簇状触觉纹理数据库”，这是一个大型多模态数据集，旨在解决现有触觉数据集中缺乏对运动参数（如速度和方向）精确控制的问题。该数据库包含118种纹理表面，在受控的速度和方向条件下，通过人工手指系统性地收集了音频、加速度、力、位置和视觉等多模态数据，共计18,880条记录。通过卷积神经网络的验证，该数据集在纹理识别、速度和方向估计方面表现出高准确率，证明了其在触觉渲染、纹理识别算法开发以及虚拟现实和机器人应用中的巨大潜力。

> **摘要翻译:** 触觉科学和技术极大地受益于在受控、系统条件下捕获触觉刺激的综合数据集。然而，现有的触觉数据库通过非受控探索收集数据，这阻碍了对运动参数（例如，运动方向和速度）如何影响触觉感知的系统分析。本文介绍了簇状触觉纹理数据库，这是一个使用三轴机器和人工手指精确控制滑动速度和方向记录的多模态数据集。该数据集涵盖了9个材料类别的118个纹理表面，并在5个速度级别（20-60毫米/秒）和8个方向下进行了记录。每个表面在160种条件下进行了测试，产生了18,880个同步的音频、加速度、力、位置和视觉数据记录。使用卷积神经网络进行验证，纹理识别的分类准确率达到96%，速度估计为88.76%，方向估计为78.79%，证实了该数据集对机器学习应用的实用性。该资源能够促进触觉渲染、纹理识别算法和人类触觉感知机制的研究，支持为虚拟现实系统和机器人应用开发逼真的触觉界面。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [542] [Self++: Merging Human and AI for Co-Determined XR Living in the Metaverse](https://arxiv.org/abs/2507.10967)
> *Self++：在元宇宙中融合人与AI以实现共同决定的XR生活*

*Thammathip Piumsomboon* | **Category: cs.HC** | **Updated: 2025-07-15**

**Keywords:** 元宇宙, 人机协作, XR, 自我决定理论, 用户赋能

**Comment:** 

> **TL;DR:** Self++提出了一个基于自我决定理论的九级框架，旨在通过人机协作在元宇宙中实现以人为中心的XR生活，增强人类潜能。

**AI_Comments:** Self++的创新之处在于其将自我决定理论应用于元宇宙中的人机协作，提出了一个九级框架，旨在实现以人为中心的XR生活。其重要性在于强调用户赋能，并提出了在元宇宙中实现有意义的人机共存的关键研究方向，包括AI自主性、社交连接和伦理保障，为未来元宇宙的发展提供了重要的伦理和设计指导。

<details>
  <summary>Details</summary>

**Motivation:** 该论文的动机是提出一种不同于技术决定论的方法，通过Self++框架，在元宇宙中实现以人为中心、由人与AI共同决定的XR生活，优先考虑人类的繁荣，并增强用户能力。

**Method:** Self++是一个新颖的九级框架，基于自我决定理论，通过在扩展现实（XR）中动态的人机协作，逐步培养能力、自主性和关联性，从而实现共同决定的生活。它强调用户赋能，通过增强能力、减轻认知偏见和利用XR的沉浸式能力来实现。

**Result:** Self++提供了一个路线图，用于创建一个人机协作、以人为中心、AI增强的元宇宙，其中技术能够放大而非削弱人类的潜力。

**Conclusion:** Self++最终提供了一个创建以人为中心、AI增强的元宇宙的路线图，旨在让技术放大而非削弱人类的潜力。

> **ai_Abstract:** 本立场论文提出Self++，一个基于自我决定理论的九级框架，旨在元宇宙中实现人机共同决定的XR生活。该框架通过动态人机协作，优先培养用户的能力、自主性和关联性，强调用户赋能而非技术决定。Self++旨在利用XR的沉浸性，减轻认知偏见，并提供一个路线图，以构建一个以人为中心、AI增强的元宇宙，从而放大人类潜能。

> **摘要翻译:** 这篇立场论文介绍了Self++，一个新颖的九级框架，用于在元宇宙中实现共同决定的生活，其根基在于自我决定理论。Self++通过在扩展现实（XR）中动态的人机协作，逐步培养能力、自主性和关联性，从而优先考虑人类的繁荣。与技术决定论方法不同，Self++通过增强能力、减轻认知偏见和利用XR的沉浸式能力来强调用户赋能。提出的关键研究方向包括探索用户定义AI自主性的界限、设计XR中有意义的社交连接以及建立主动的道德保障。最终，Self++提供了一个路线图，用于创建一个以人为中心、AI增强的元宇宙，其中技术放大而非削弱人类的潜力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [598] [Terms and Conditions (Do Not) Apply: Understanding Exploitation Disparities in Design of Mobile-Based Financial Services](https://arxiv.org/abs/2507.10970)
> *条款和条件（不）适用：理解移动金融服务设计中的剥削差异*

*Lindah Kotut* | **Category: cs.HC** | **Updated: 2025-07-15**

**Keywords:** 移动金融服务, 金融剥削, 设计差异, 用户体验, 风险缓解

**Comment:** Accepted for Publication at The 5th Biennial African Human Computer
  Interaction Conference (AfriCHI 2025). 10 pages (excluding references), 3
  figures

> **TL;DR:** 本文探讨了移动金融服务在为无银行账户人群带来便利的同时，由于设计缺陷、高利率和缺乏透明度，也带来了剥削风险。论文详细描述了用户体验，指出了设计造成的危害，并提出了更安全、更具赋能的设计指南。

**AI_Comments:** 这篇论文很重要，因为它揭示了广泛采用的移动金融服务设计中，特别是对于弱势群体而言，经常被忽视的负面后果和伦理问题。其创新之处在于利用用户访谈详细阐述剥削差异，并提出了可操作的设计指南，超越了仅仅识别问题，而是为建立更公平、更值得信赖的系统提供了解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 移动金融服务虽然为传统上无法获得银行服务的人群提供了机会，但也带来了有害利率、无法获取政策文件和用户保护不足等挑战，从而加剧了技术辅助的非道德金融行为所带来的风险。本研究的动机是理解并解决这些剥削差异。

**Method:** 研究人员通过用户访谈，详细阐述了移动金融交易中的用户体验，并探讨了支撑金融服务提供的基础和准则。

**Result:** 研究结果突出了金融剥削差异，讨论了移动金融系统设计中实现的便利性和危害，并探讨了风险缓解和损害恢复的策略。

**Conclusion:** 论文建议了赋能设计方法的指导方针，以支持用户的信任机制、他们对技术过程的理解以及对风险的判断，从而减轻剥削并实现恢复。

> **ai_Abstract:** 本文探讨了移动金融服务的双重性，即在为无银行账户人群扩大金融服务的同时，也因设计缺陷、高利率和缺乏透明度而带来严重的金融剥削风险。研究通过用户访谈揭示了用户体验，强调了设计所带来的危害，并识别了剥削差异。论文提出了缓解策略，并提供了旨在培养用户信任、提高技术理解和风险评估能力的设计指南，以期创建更具赋能和更安全的金融服务环境。

> **摘要翻译:** 移动金融服务使传统上无法获得银行服务的人群能够接触到此前难以企及的基础设施。研究人员已经探索了这些系统如何为资金的发送和接收创造了更安全的环境，并扩大了金融机会，例如增加了借贷。然而，随着这种扩张，诸如有害利率、无法获取政策文件以及用户保护措施不足等挑战也随之出现，这些挑战加剧了由设计模式辅助的技术驱动的非道德金融行为所带来的风险。通过用户访谈，我们详细阐述了移动金融交易中的用户体验，并探讨了支撑金融服务提供的基础和准则：强调了此类系统设计中实现的便利性和危害。我们通过强调金融剥削差异、商议风险缓解策略以及实现从技术使用造成的损害中恢复来讨论研究结果。然后，我们推荐了赋能设计方法的指导方针，以支持用户的信任机制、他们对技术过程的理解以及对风险的判断。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [605] [IdeaSynth: Iterative Research Idea Development Through Evolving and Composing Idea Facets with Literature-Grounded Feedback](https://arxiv.org/abs/2410.04025)
> *IdeaSynth：通过演化和组合思想方面并结合文献反馈进行迭代研究思想开发*

*Kevin Pu, K. J. Kevin Feng, Tovi Grossman, Tom Hope, Bhavana Dalvi Mishra, Matt Latzke, Jonathan Bragg, Joseph Chee Chang, Pao Siangliulue* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 研究构思, 大型语言模型, 迭代开发, 文献反馈, IdeaSynth

**Comment:** 

> **TL;DR:** IdeaSynth是一个基于大型语言模型（LLM）的研究想法开发系统，它通过提供文献支持的反馈，帮助研究人员迭代地细化和组合研究想法的各个方面，从而促进想法的深入发展和探索。

**AI_Comments:** IdeaSynth通过引入文献驱动的LLM反馈和迭代组合思想方面，创新性地解决了研究构思中“深入细化”的痛点。它超越了传统工具的“广泛生成”限制，为研究人员提供了更全面的支持，尤其是在复杂和长期的研究项目中。

<details>
  <summary>Details</summary>

**Motivation:** 现有工具主要关注研究想法的广泛生成，但在进一步发展初始想法所需的迭代规范、细化和评估方面支持不足。

**Method:** 本文介绍了IdeaSynth系统，该系统利用大型语言模型（LLMs）提供基于文献的反馈，用于阐述研究问题、解决方案、评估和贡献。IdeaSynth将这些想法方面表示为画布上的节点，并允许研究人员通过创建和探索变体并进行组合来迭代地细化它们。

**Result:** 实验室研究（N=20）表明，与强大的基于LLM的基线相比，参与者在使用IdeaSynth时探索了更多替代想法，并以更多细节扩展了初始想法。部署研究（N=7）表明，参与者有效地将IdeaSynth用于从开发初始想法到修改成熟手稿框架的各个构思阶段的实际研究项目。

**Conclusion:** IdeaSynth能够有效地帮助研究人员在各种构思阶段发展研究思想，并具有融入研究人员工作流程的潜力。

> **ai_Abstract:** IdeaSynth是一个旨在弥补现有研究构思工具在迭代细化方面不足的系统。它利用大型语言模型提供文献支持的反馈，帮助研究人员迭代地发展和组合研究问题的不同方面（问题、解决方案、评估、贡献）。通过实验室和部署研究，该系统被证明能有效帮助用户探索更多想法并扩展细节，支持从初期构思到手稿修订的整个研究流程。

> **摘要翻译:** 研究构思涉及广泛探索和深入细化想法。两者都需要深入参与文献。现有工具主要侧重于想法的广泛生成，但在进一步发展初始想法所需的迭代规范、细化和评估方面支持甚少。为了弥补这一差距，我们引入了IdeaSynth，一个研究想法开发系统，它使用大型语言模型（LLMs）提供基于文献的反馈，用于阐明研究问题、解决方案、评估和贡献。IdeaSynth将这些想法方面表示为画布上的节点，并允许研究人员通过创建和探索变体并组合它们来迭代地细化它们。我们的实验室研究（N=20）表明，与强大的基于LLM的基线相比，参与者在使用IdeaSynth时探索了更多替代想法，并以更多细节扩展了初始想法。我们的部署研究（N=7）表明，参与者有效地将IdeaSynth用于从开发初始想法到修改成熟手稿框架的各个构思阶段的实际研究项目，突出了在研究人员工作流程中采用IdeaSynth的可能性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [654] [An Exploratory Study on AI-driven Visualisation Techniques on Decision Making in Extended Reality](https://arxiv.org/abs/2507.10981)
> *人工智能驱动的可视化技术在扩展现实中对决策影响的探索性研究*

*Ze Dong, Binyang Han, Jingjing Zhang, Ruoyu Wen, Barrett Ens, Adrian Clark, Tham Piumsomboon* | **Category: cs.HC** | **Updated: 2025-07-15**

**Keywords:** 扩展现实, 人工智能, 可视化技术, 决策, 用户自主性

**Comment:** 

> **TL;DR:** 本研究探索了四种人工智能驱动的可视化技术（告知、轻推、推荐、指导）在扩展现实（XR）中对用户决策的影响，强调了保持用户自主性、提高AI透明度以及考虑上下文的重要性。

**AI_Comments:** 这项研究的创新之处在于其将AI驱动的可视化技术应用于XR环境，并深入探讨了其对用户决策的影响。其重要性在于为未来XR中AI辅助决策系统的设计提供了宝贵的指导原则，特别是强调了用户自主性和信任的重要性。研究的局限性可能在于其探索性性质和样本规模，但其为后续更深入的研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 探索扩展现实（XR）与人工智能（AI）结合如何通过AI驱动的可视化技术影响用户决策，以及不同自主性水平的可视化技术如何影响偏好和决策。

**Method:** 使用Meta Quest Pro，在预先录制的超市360度视频上叠加四种AI驱动的可视化技术（告知、轻推、推荐、指导）的虚拟界面。通过探索性研究和半结构化访谈收集反馈和设计建议。

**Result:** 研究结果强调了在可视化设计中保持用户自主性、增强AI透明度以建立信任以及考虑上下文的重要性。

**Conclusion:** 在扩展现实中设计AI驱动的可视化技术时，应优先考虑用户自主性、AI透明度和上下文感知，以优化用户决策体验。

> **ai_Abstract:** 本研究探讨了在扩展现实（XR）中，人工智能（AI）驱动的可视化技术（包括“告知”、“轻推”、“推荐”和“指导”）对用户决策的影响。研究通过Meta Quest Pro在模拟超市环境中测试了这些技术，并发现保持用户自主性、提高AI透明度以及考虑情境是设计此类可视化方案的关键。

> **摘要翻译:** 扩展现实（XR）与人工智能（AI）的整合为用户交互引入了一种新范式，使AI能够感知用户意图、刺激感官并影响决策。我们使用Meta Quest Pro探索了四种AI驱动的可视化技术——“告知”、“轻推”、“推荐”和“指导”——在XR中对用户决策的影响。为了测试这些技术，我们使用了一段预先录制的超市360度视频，通过虚拟界面叠加了每种技术。我们的目的是调查这些具有不同用户自主性水平的不同可视化技术如何影响偏好和决策。一项包含半结构化访谈的探索性研究提供了反馈和设计建议。我们的发现强调了保持用户自主性、增强AI透明度以建立信任以及在可视化设计中考虑上下文的重要性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [676] [Assistance or Disruption? Exploring and Evaluating the Design and Trade-offs of Proactive AI Programming Support](https://arxiv.org/abs/2502.18658)
> *协助还是干扰？探索和评估主动式AI编程支持的设计与权衡*

*Kevin Pu, Daniel Lazaro, Ian Arawjo, Haijun Xia, Ziang Xiao, Tovi Grossman, Yan Chen* | **Category: cs.HC, cs.AI, cs.SE** | **Updated: 2025-07-15**

**Keywords:** 主动式AI, 编程支持, LLM代理, 工作流程, 用户体验

**Comment:** 

> **TL;DR:** 研究并评估了主动式AI编程支持工具Codellaborator，发现其能提高效率但会造成干扰，而存在指示和上下文支持可缓解干扰，强调需平衡用户控制与AI主动性。

**AI_Comments:** 这项研究创新性地探讨了主动式AI编程支持的利弊，特别关注了其对用户工作流程的潜在干扰，并提出了通过界面设计（如存在指示和上下文支持）来缓解这些问题的具体方法。其重要性在于为未来AI集成编程工具的设计提供了宝贵的实证依据和设计启示，强调了在追求效率的同时，保持用户控制感和代码理解的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的AI编程工具（如代码生成）和原型（如主动式AI代理）虽然强大，但它们对编程工作流程的影响尚未被充分探索。本文旨在研究主动式AI编程支持对用户效率和工作流程的影响。

**Method:** 引入并评估了设计探测LLM代理Codellaborator，它根据编辑器活动和任务上下文主动提供编程协助。通过一项受试者内研究（N=18），评估了三种界面变体（仅提示、主动代理、带存在和上下文的主动代理——Codellaborator）在日益显著的AI支持下的权衡。

**Result:** 与仅提示范式相比，主动代理提高了效率，但也造成了工作流程中断。然而，存在指示和交互上下文支持减轻了中断，并提高了用户对AI过程的感知。研究强调了Codellaborator在用户控制、所有权和代码理解方面的权衡。

**Conclusion:** 主动式AI编程支持能够提高效率，但需要通过设计（如存在指示和上下文支持）来缓解工作流程中断，并平衡用户控制、所有权和代码理解。未来需要根据编程过程调整AI的主动性。

> **ai_Abstract:** 本文介绍了Codellaborator，一个主动式LLM编程支持代理，旨在评估其对编程工作流程的影响。研究发现，主动式AI虽然能提高效率，但可能导致工作流程中断。通过在界面中加入存在指示和上下文支持，可以有效缓解这些中断，并提升用户对AI过程的理解。研究强调了在设计主动式AI编程工具时，需在效率、用户控制、所有权和代码理解之间进行权衡。

> **摘要翻译:** AI编程工具能够实现强大的代码生成，最近的原型试图通过主动式AI代理来减少用户工作量，但它们对编程工作流程的影响仍未被探索。我们引入并评估了Codellaborator，这是一个设计探测LLM代理，它根据编辑器活动和任务上下文启动编程协助。我们探索了三种界面变体，以评估日益显著的AI支持之间的权衡：仅提示、主动代理以及带有存在和上下文的主动代理（Codellaborator）。在一项受试者内研究（N=18）中，我们发现与仅提示范式相比，主动代理提高了效率，但也造成了工作流程中断。然而，存在指示和交互上下文支持减轻了中断，并提高了用户对AI过程的感知。我们强调了Codellaborator在用户控制、所有权和代码理解方面的权衡，强调需要根据编程过程调整主动性。我们的研究对主动式AI系统的设计探索和评估做出了贡献，提出了关于AI集成编程工作流程的设计启示。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [710] [Role-Playing LLM-Based Multi-Agent Support Framework for Detecting and Addressing Family Communication Bias](https://arxiv.org/abs/2507.11210)
> *基于角色扮演LLM的多智能体支持框架，用于检测和解决家庭沟通偏差*

*Rushia Harada, Yuken Kimura, Keito Inoshita* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 家庭沟通, LLM, 多智能体系统, 角色扮演, 情感压抑, 理想父母偏见

**Comment:** 

> **TL;DR:** 本研究开发了一个基于角色扮演LLM的多智能体框架，用于检测家庭对话中的偏差（如理想父母偏见和情感压抑），并生成富有同理心和可操作的反馈，以改善家庭沟通。

**AI_Comments:** 本研究的创新之处在于其将LLM应用于家庭心理健康领域，特别是针对理想父母偏见和情感压抑这两个难以察觉的沟通问题。通过多智能体协作和角色扮演机制，系统能够模拟专家咨询过程，生成富有同理心和实用性的反馈，这对于改善家庭关系具有重要意义。语料库的构建也为该领域的研究提供了宝贵资源。

<details>
  <summary>Details</summary>

**Motivation:** 传统的衡量标准往往忽视家庭环境中微妙的心理动态，特别是无意识的父母期望（理想父母偏见）可能抑制儿童的情感表达和自主性（情感压抑）。这种偏差很难从家庭外部检测或解决，因此需要一种支持心理安全的家庭沟通方法。

**Method:** 研究构建了一个包含30个场景的日文亲子对话语料库，并标注了理想父母偏见和情感压抑的元数据。在此基础上，开发了一个基于角色扮演LLM的多智能体对话支持框架。该框架包含专门的智能体用于检测情感压抑、描述父母言语中隐含的理想父母偏见，并推断儿童的年龄和背景等上下文属性。一个元智能体将这些输出编译成结构化报告，然后传递给五个选定的专家智能体，这些智能体通过结构化的四步讨论过程协同生成富有同理心和可操作的反馈。

**Result:** 实验表明，该系统能以中等准确度检测情感压抑的类别，并产生在同理心和实用性方面评价很高的反馈。此外，结合此反馈的模拟后续对话表现出情感表达和相互理解的改善迹象。

**Conclusion:** 该框架在支持家庭互动积极转变方面具有潜力，能够检测并解决家庭沟通中的偏差，从而促进心理安全的家庭沟通。

> **ai_Abstract:** 本研究提出一个基于角色扮演LLM的多智能体支持框架，旨在检测和解决家庭沟通中的偏差，特别是理想父母偏见和儿童情感压抑。通过构建日文亲子对话语料库并开发专门智能体进行对话分析和上下文推断，该框架能够生成结构化报告，并由专家智能体协同提供富有同理心和可操作的反馈。实验结果表明，系统在检测情感压抑方面具有中等准确性，且反馈质量高，并有望改善家庭互动中的情感表达和相互理解。

> **摘要翻译:** 家庭环境中的幸福感涉及到微妙的心理动态，而传统指标往往忽视这些动态。特别是，无意识的父母期望（被称为理想父母偏见）会抑制儿童的情感表达和自主性。这种抑制（被称为情感压抑）通常源于善意但价值观导向的沟通，这种沟通很难在家庭外部被发现或解决。本研究关注这些潜在的动态，探索基于大型语言模型（LLM）的支持，以实现心理安全的家庭沟通。我们构建了一个包含30个场景的日文亲子对话语料库，每个场景都标注了理想父母偏见和情感压抑的元数据。基于此语料库，我们开发了一个基于角色扮演LLM的多智能体对话支持框架，该框架分析对话并生成反馈。专门的智能体检测情感压抑，描述父母言语中隐含的理想父母偏见，并推断儿童的年龄和背景等上下文属性。一个元智能体将这些输出编译成结构化报告，然后传递给五个选定的专家智能体。这些智能体通过结构化的四步讨论过程协同生成富有同理心和可操作的反馈。实验表明，该系统能以中等准确度检测情感压抑的类别，并产生在同理心和实用性方面评价很高的反馈。此外，结合此反馈的模拟后续对话表现出情感表达和相互理解的改善迹象，这表明该框架在支持家庭互动积极转变方面具有潜力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [741] [A Critical Analysis of the Usage of Dimensionality Reduction in Four Domains](https://arxiv.org/abs/2503.08836)
> *四领域降维技术使用情况的批判性分析*

*Dylan Cashman, Mark Keller, Hyeon Jeon, Bum Chul Kwon, Qianwen Wang* | **Category: cs.HC** | **Updated: 2025-07-15**

**Keywords:** 降维, 可视化, 科学领域, 数据分析, 误解

**Comment:** Accepted at IEEE Transactions on Visualization and Computer Graphics,
  to be presented at IEEE Visualization conference

> **TL;DR:** 本文对降维技术在生物学、化学、物理学和商学等领域的使用进行了批判性分析，揭示了常见的工作流程和误用。

**AI_Comments:** 本文通过结合文献计量分析和案例研究，对降维技术在非计算机科学领域的实际应用进行了深入且批判性的分析，这对于理解和改进跨学科数据分析实践具有重要意义。其发现的误用现象揭示了现有可视化工具和用户教育的不足，为未来的研究和工具开发提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 降维是处理高维数据集的重要工具，在细胞生物学、化学信息学和物理学等许多科学领域被广泛使用。然而，对于计算机科学之外的科学领域中降维技术的使用方式缺乏批判性分析，尤其是在其常见工作流程和潜在误解方面。

**Method:** 首先，对21,249篇使用降维技术的学术出版物进行了文献计量分析，以观察不同领域技术使用频率的差异。其次，对来自生物学、化学、物理学和商业四个领域的71篇论文样本进行了调查，以揭示常见的工作流程、过程和使用模式，包括验证数据集和投影方法的验证性数据分析与生成更多假设的探索性数据分析的混合使用。最后，将观察结果与可视化社区的最新工作进行比较，以使社区内的工作与社区外的潜在影响领域相匹配。

**Result:** 通过文献计量分析，观察到不同领域间降维技术使用频率的差异。通过调查，揭示了常见的工作流程、过程和使用模式，例如验证性数据分析和探索性数据分析的混合使用。发现误解和不当使用很常见，尤其是在对降维结果视图的视觉解释中。

**Conclusion:** 本文对计算机科学之外的科学领域中降维技术的使用进行了批判性分析，揭示了常见的使用模式和问题，并旨在弥合可视化研究与其在其他领域应用之间的差距。

> **ai_Abstract:** 本文批判性地分析了降维技术在生物学、化学、物理学和商业四个科学领域中的应用。研究通过对21,249篇学术出版物进行文献计量分析，并对71篇论文进行深入调查，揭示了各领域使用降维技术的常见工作流程和模式，并发现其在视觉解释中普遍存在误解和不当使用。该研究旨在促进可视化社区的研究与实际科学应用之间的契合。

> **摘要翻译:** 降维是揭示高维数据集复杂性的重要工具，在细胞生物学、化学信息学和物理学等许多科学领域中被广泛使用。降维数据的可视化使科学家能够深入研究其数据集的内在结构，并将其与既定假设对齐。因此，可视化研究人员提出了许多旨在揭示潜在结构的降维方法和交互系统。与此同时，不同的科学领域已经为其各自领域制定了使用降维技术和可视化的指南或通用工作流程。在这项工作中，我们对计算机科学之外的科学领域中降维技术的使用进行了批判性分析。首先，我们对21,249篇使用降维技术的学术出版物进行了文献计量分析，以观察不同领域技术频率的差异。接下来，我们对来自生物学、化学、物理学和商业四个领域的71篇论文样本进行了调查。通过这项调查，我们揭示了常见的工作流程、过程和使用模式，包括验证性数据分析与生成更多假设的探索性数据分析的混合使用。我们还发现误解和不当使用很常见，特别是在对降维结果视图的视觉解释中。最后，我们将观察结果与可视化社区的最新工作进行比较，以便将我们社区内的工作与社区外的潜在影响领域相匹配。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [766] [REVA: Supporting LLM-Generated Programming Feedback Validation at Scale Through User Attention-based Adaptation](https://arxiv.org/abs/2507.11470)
> *REVA：通过基于用户注意力的自适应支持大规模LLM生成的编程反馈验证*

*Xiaohang Tang, Sam Wong, Zicheng He, Yalong Yang, Yan Chen* | **Category: cs.HC** | **Updated: 2025-07-15**

**Keywords:** 人机协作, 编程反馈, LLM, 注意力学习, 反馈验证

**Comment:** 

> **TL;DR:** REVA是一个人机协作系统，通过最小化认知情境转换和传播修订来加速教师审查AI生成的编程反馈，并通过学习教师的注意力来持续改进反馈验证过程。

**AI_Comments:** REVA的创新之处在于其独特的人机协作方法，它不仅优化了审查流程以减少教师的认知负担，更重要的是，它能够自适应地学习教师的注意力并持续改进反馈验证过程。这对于大规模应用AI生成反馈的教育场景具有重要意义，有助于提高反馈质量并减轻教师的工作量。

<details>
  <summary>Details</summary>

**Motivation:** 本论文的动机是为了解决教师审查大量AI生成的编程反馈时面临的挑战，旨在通过减少认知情境转换和传播修订来加快审查过程，从而提高效率。

**Method:** REVA通过对提交进行排序以最小化认知情境转换，并将教师驱动的修订传播到语义相似的实例中来加速审查过程。它还引入了一种新颖的人机协作方法，通过自适应地学习教师在审查和修订过程中的注意力来持续改进反馈验证过程。REVA的有效性通过一项有12名参与者的受试者内实验室研究进行评估。

**Result:** 通过一项有12名参与者的受试者内实验室研究，REVA在提高反馈质量和整体反馈审查过程方面的实用性和有效性得到了评估。

**Conclusion:** REVA系统在提高AI生成编程反馈的质量和加速审查过程方面显示出实用性和有效性，通过学习用户注意力实现自适应改进。

> **ai_Abstract:** REVA是一个人机协作系统，旨在通过优化提交顺序以减少认知负担，并自动传播教师的修订到相似反馈中，从而大规模加速教师对LLM生成的编程反馈的审查。该系统通过学习教师的注意力来持续改进反馈验证过程。一项包含12名参与者的研究表明，REVA在提高反馈质量和审查效率方面具有实用性和有效性。

> **摘要翻译:** 本文介绍了REVA，一个通过对提交进行排序以最小化认知情境转换，并将教师驱动的修订传播到语义相似的实例中，从而加快教师审查大量AI生成编程反馈的人机系统。REVA引入了一种新颖的教育反馈中人机协作方法，通过自适应地学习教师在审查和修订过程中的注意力，持续改进反馈验证过程。REVA在提高反馈质量和整体反馈审查过程方面的实用性和有效性，通过一项有12名参与者的受试者内实验室研究进行了评估。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [809] [The Trust Calibration Maturity Model for Characterizing and Communicating Trustworthiness of AI Systems](https://arxiv.org/abs/2503.15511)
> *用于表征和传达人工智能系统可信赖性的信任校准成熟度模型*

*Scott T Steinmetz, Asmeret Naugle, Paul Schutte, Matt Sweitzer, Alex Washburne, Lisa Linville, Daniel Krofcheck, Michal Kucer, Samuel Myren* | **Category: cs.HC, cs.CY, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 信任校准, AI系统, 可信赖性, 成熟度模型, ChatGPT

**Comment:** 19 pages, 4 figures, 2 tables

> **TL;DR:** 本文提出了信任校准成熟度模型（TCMM），以帮助用户校准对AI系统的信任，通过五个维度表征和传达AI系统的可信赖性，并展示了其在核科学和地震事件分类任务中的应用。

**AI_Comments:** 该论文提出了一种创新的信任校准成熟度模型（TCMM），旨在解决当前AI系统可信赖性信息不透明的痛点。通过引入多维度的成熟度评估，TCMM为用户、开发者和研究人员提供了一个结构化的框架来理解、沟通和提升AI系统的可信赖性。其重要性在于，它为AI的负责任开发和部署提供了一个实用的工具，有助于降低AI误用风险，并促进AI技术在关键领域的应用。

<details>
  <summary>Details</summary>

**Motivation:** 随着强大的AI系统日益普及，用户需要能够校准对这些系统信任的能力。然而，随着AI系统规模的增长，评估其可信赖性所需的信息变得越来越难以获取，这增加了不当使用这些系统的风险。

**Method:** 本文提出了信任校准成熟度模型（TCMM），用于表征和传达AI系统的可信赖性信息。TCMM包含了分析成熟度的五个维度：性能表征、偏差与鲁棒性量化、透明度、安全与保障以及可用性。

**Result:** TCMM与系统性能信息一起呈现，可以帮助用户适当地校准信任、建立需求并跟踪进展，以及识别研究需求。本文在两个目标任务上展示了TCMM：使用ChatGPT进行高后果核科学判定，以及使用PhaseNet（地震模型集合）对地震事件源进行分类。

**Conclusion:** 信任校准成熟度模型（TCMM）能够帮助用户适当校准对AI系统的信任，建立需求并跟踪进展，以及识别相关研究需求。

> **ai_Abstract:** 本文提出了一种名为信任校准成熟度模型（TCMM）的框架，旨在解决AI系统可信赖性信息难以获取的问题，从而帮助用户正确校准对AI的信任。TCMM通过性能、偏差与鲁棒性、透明度、安全与可用性五个维度来表征和传达AI系统的可信赖性，并能辅助用户进行信任校准、需求管理和研究方向识别。研究通过ChatGPT在核科学判定和PhaseNet在地震事件分类上的应用，验证了TCMM的有效性。

> **摘要翻译:** 强大的AI系统近期大量涌现，使得用户迫切需要能够帮助他们校准对这些系统信任的能力。随着AI系统规模的增长，评估其可信赖性所需的信息变得越来越难以获取，这增加了不当使用这些系统的风险。我们提出了信任校准成熟度模型（TCMM），用于表征和传达有关AI系统可信赖性的信息。TCMM包含了分析成熟度的五个维度：性能表征、偏差与鲁棒性量化、透明度、安全与保障以及可用性。TCMM可以与系统性能信息一起呈现，以（1）帮助用户适当地校准信任，（2）建立需求并跟踪进展，以及（3）识别研究需求。在此，我们讨论了TCMM，并在两个目标任务上进行了演示：使用ChatGPT进行高后果核科学判定，以及使用PhaseNet（地震模型集合）对地震事件源进行分类。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='cset'></a>
## cs.ET 

### [416] [Fault-Free Analog Computing with Imperfect Hardware](https://arxiv.org/abs/2507.11134)
> *基于不完美硬件的无故障模拟计算*

*Zhicheng Xu, Jiawei Liu, Sitao Huang, Zefan Li, Shengbo Wang, Bo Wen, Ruibin Mao, Mingrui Jiang, Giacomo Pedretti, Jim Ignowski, Kaibin Huang, Can Li* | **Category: cs.ET, cs.AR** | **Updated: 2025-07-15**

**Keywords:** 模拟计算, 忆阻器, 容错, 矩阵分解, 内存计算

**Comment:** 

> **TL;DR:** 本文提出并实验证明了一种无故障矩阵表示方法，通过将目标矩阵分解为两个可调子矩阵的乘积，实现了在存在大量器件故障的情况下，模拟计算系统的高精度和高可靠性。

**AI_Comments:** 这项研究的创新之处在于提出了一种间接、自适应的矩阵表示方法，通过数学优化绕过故障器件，从根本上解决了模拟计算中硬件不完美的问题。其重要性在于，它为在存在大量器件缺陷的情况下实现高精度模拟计算开辟了道路，极大地拓宽了新兴存储器和非电计算基板的应用前景，有可能彻底改变未来边缘AI硬件的设计。

<details>
  <summary>Details</summary>

**Motivation:** 边缘计算和人工智能对模拟内存计算的需求日益增长，但现有模拟系统中器件故障和变异严重限制了其精度和可靠性。传统容错技术（如冗余和再训练）对于高精度应用或需要固定矩阵和隐私保护的场景往往不足。

**Method:** 研究引入并实验证明了一种无故障矩阵表示方法，其中目标矩阵被分解为两个可调子矩阵的乘积，并编程到模拟硬件上。这种间接、自适应的表示方法通过数学优化来绕过故障器件并消除差分对，显著提高了计算密度。

**Result:** 该忆阻器系统在39%器件故障率的情况下，实现了离散傅里叶变换矩阵超过99.999%的余弦相似度，这是传统直接表示方法（在0.01%故障率下就会失效）无法达到的。在无线通信中，比特错误率降低了56倍，密度提高了196%以上，能效比现有技术提高了179%。

**Conclusion:** 该方法在忆阻器上得到验证，并广泛适用于新兴存储器和非电计算基板，表明器件良率不再是模拟计算硬件的主要瓶颈。

> **ai_Abstract:** 该研究提出了一种创新的无故障矩阵表示方法，通过将目标矩阵分解为两个可调子矩阵的乘积，解决了模拟内存计算中器件故障和变异导致的精度和可靠性问题。实验证明，该方法在忆阻器系统中即使面对高故障率，也能实现高精度的计算，并在无线通信等应用中显著提高性能、密度和能效。这表明器件良率不再是模拟计算硬件的主要限制。

> **摘要翻译:** 对边缘计算和人工智能日益增长的需求推动了使用忆阻器进行模拟内存计算的研究，忆阻器通过在内存中直接计算来克服数据传输瓶颈。然而，器件故障和变异严重限制了模拟系统的精度和可靠性。现有的容错技术，如冗余和再训练，对于高精度应用或需要固定矩阵和隐私保护的场景往往不足。本文介绍并实验证明了一种无故障矩阵表示方法，其中目标矩阵被分解为两个可调子矩阵的乘积，并编程到模拟硬件上。这种间接、自适应的表示方法能够通过数学优化来绕过故障器件并消除差分对，显著提高了计算密度。我们的忆阻器系统在39%的器件故障率下，实现了离散傅里叶变换矩阵超过99.999%的余弦相似度，这是传统直接表示方法（在单器件故障（0.01%故障率）下就会失效）无法达到的保真度。我们展示了无线通信中比特错误率降低了56倍，与最先进技术相比，密度提高了196%以上，能效提高了179%。这种在忆阻器上验证的方法广泛适用于新兴存储器和非电计算基板，表明器件良率不再是模拟计算硬件的主要瓶颈。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [14] [RefModel: Detecting Refactorings using Foundation Models](https://arxiv.org/abs/2507.11346)
> *RefModel：使用基础模型检测重构*

*Pedro Simões, Rohit Gheyi, Rian Melo, Jonhnanthan Oliveira, Márcio Ribeiro, Wesley K. G. Assunção* | **Category: cs.SE** | **Updated: 2025-07-15**

**Keywords:** 重构检测, 基础模型, 代码质量, 静态分析, 大型语言模型

**Comment:** Accepted at Brazilian Symposium on Software Engineering (SBES 2025)

> **TL;DR:** RefModel是一个使用基础模型（如Phi4-14B、Claude 3.5 Sonnet、Gemini 2.5 Pro、o4-mini-high）进行重构检测的工具，其性能与传统工具相当或更优，并能很好地泛化到其他语言。

**AI_Comments:** 本文提出了一种利用基础模型进行重构检测的新方法，与传统的静态分析方法有显著区别。其主要创新在于证明了大型语言模型可以有效地理解和识别代码重构，相比基于规则的系统，提供了更好的泛化能力和更简洁的定义。实验结果，特别是Claude 3.5 Sonnet和Gemini 2.5 Pro在真实世界场景中97%的联合识别率，突显了这种范式转变的潜力。其泛化到新语言（Python、Golang）的能力以及提供自然语言解释的特性也增加了其显著价值。这项工作为将人工智能应用于软件工程任务开辟了新途径，有望使代码分析工具更具适应性和用户友好性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的重构检测工具依赖于复杂的规则定义和静态分析，这使得它们难以扩展和泛化到其他编程语言。本文旨在研究使用基础模型来克服这些限制的可行性。

**Method:** 本文研究了使用基础模型进行重构检测的可行性，并实现了一个名为RefModel的工具。在人工生成的Java程序数据集上评估了Phi4-14B和Claude 3.5 Sonnet，涵盖了广泛使用的重构类型。此外，还在四个开源项目中提取的44个真实世界重构上评估了Gemini 2.5 Pro和o4-mini-high的性能。将这些模型与RefactoringMiner、RefDiff和ReExtractor+等传统工具进行了比较。

**Result:** RefModel与传统工具相比具有竞争力，在某些情况下甚至表现更好。在真实世界环境中，Claude 3.5 Sonnet和Gemini 2.5 Pro共同识别了97%的所有重构，超过了表现最好的基于静态分析的工具。这些模型在Python和Golang上显示出令人鼓舞的泛化能力，并能提供自然语言解释，且仅需一个句子即可定义每种重构类型。

**Conclusion:** 基础模型是重构检测的一种可行且有效的方法，在真实世界场景中其性能优于传统的静态分析工具，并表现出良好的跨语言泛化能力，同时简化了重构的定义。

> **ai_Abstract:** 本文介绍了RefModel，一个利用基础模型（如Phi4-14B、Claude 3.5 Sonnet、Gemini 2.5 Pro等）进行代码重构检测的工具。针对传统工具扩展性和泛化性差的问题，RefModel通过实验证明其在人工生成Java代码和真实世界开源项目中的重构检测能力，与现有静态分析工具相比具有竞争力，甚至在真实场景下超越了最佳表现的传统工具。此外，RefModel展示了对Python和Golang的良好泛化能力，并能通过自然语言解释和简洁的定义实现重构检测。

> **摘要翻译:** 重构是一种常见的软件工程实践，它在不改变程序行为的情况下提高代码质量。尽管已经开发了ReExtractor+、RefactoringMiner和RefDiff等工具来自动检测重构，但它们依赖于复杂的规则定义和静态分析，这使得它们难以扩展和推广到其他编程语言。在本文中，我们研究了使用基础模型进行重构检测的可行性，并在一个名为RefModel的工具中实现。我们评估了Phi4-14B和Claude 3.5 Sonnet在一个包含858个单操作转换的数据集上，这些转换应用于人工生成的Java程序，涵盖了广泛使用的重构类型。我们还通过包含Gemini 2.5 Pro和o4-mini-high来扩展我们的评估，评估它们在从四个开源项目中提取的44个真实世界重构上的性能。这些模型与RefactoringMiner、RefDiff和ReExtractor+进行了比较。RefModel与传统工具相比具有竞争力，在某些情况下甚至表现更好。在真实世界环境中，Claude 3.5 Sonnet和Gemini 2.5 Pro共同识别了97%的所有重构，超过了表现最好的基于静态分析的工具。这些模型在Python和Golang上显示出令人鼓舞的泛化能力。它们提供自然语言解释，并且只需要一个句子来定义每种重构类型。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [25] [SENSOR: An ML-Enhanced Online Annotation Tool to Uncover Privacy Concerns from User Reviews in Social-Media Applications](https://arxiv.org/abs/2507.10640)
> *SENSOR：一个机器学习增强的在线标注工具，用于从社交媒体应用的用户评论中发现隐私问题*

*Labiba Farah, Mohammad Ridwan Kabir, Shohel Ahmed, MD Mohaymen Ul Anam, Md. Sakibul Islam* | **Category: cs.SE, cs.LG, D.2.2** | **Updated: 2025-07-14**

**Keywords:** 隐私担忧, 用户评论, 机器学习, 在线标注工具, GRACE模型

**Comment:** 26 pages, 9 figures, 5 tables

> **TL;DR:** SENSOR是一个机器学习增强的在线标注工具，旨在帮助开发者从社交媒体应用的用户评论中识别并分类隐私相关的特性请求和错误报告。

**AI_Comments:** 该论文的创新点在于引入了一个专门用于细致分类用户评论中隐私相关问题的在线标注工具SENSOR，并提出了结合GRU、CBOW和注意力机制的GRACE模型。这解决了现有研究在隐私相关特性请求和错误报告分类方面的不足。其重要性在于能够显著提高开发者处理用户隐私反馈的效率和准确性，有助于增强用户对社交媒体应用的信任。该工具的自动化特性对于处理海量评论尤其有价值。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体应用的广泛使用引发了显著的隐私担忧，这些担忧常在用户评论中被提及。然而，评论量巨大且性质微妙，使得开发者难以手动识别和优先处理隐私相关问题。现有研究缺乏对隐私相关特性请求或错误报告的细致分类，这促使了本研究的开展。

**Method:** 本研究引入了在线标注工具SENtinel SORt (SENSOR)，用于将用户评论分类为隐私相关的特性请求、隐私相关的错误报告或隐私不相关。为自动化标注过程，论文提出了标注模型GRACE (GRU-based Attention with CBOW Embedding)，该模型结合了门控循环单元(GRU)、连续词袋(CBOW)和注意力机制。研究分析了来自Google Play商店中七款流行社交媒体应用（包括Instagram、Facebook、WhatsApp、Snapchat、X、Facebook Lite和Line）的约16000条用户评论。两名标注者手动标注了评论，实现了0.87的Cohen's Kappa值，确保了用于训练机器学习模型的高一致性标注数据集。

**Result:** 在测试的模型中，GRACE模型表现最佳，即使在类别不平衡的情况下，其宏F1分数达到0.9434，宏ROC-AUC达到0.9934，准确率达到95.10%。SENSOR工具展示了在协助开发者从用户评论中提取和处理隐私相关的特性请求或错误报告方面的巨大潜力。

**Conclusion:** SENSOR工具，结合其GRACE模型，能够有效帮助开发者识别和解决用户评论中的隐私问题，从而增强用户隐私和信任。

> **ai_Abstract:** 本论文介绍了一种名为SENSOR的机器学习增强在线标注工具，旨在解决社交媒体应用中用户评论中隐私问题手动识别的挑战。SENSOR利用GRACE（基于GRU、CBOW嵌入和注意力机制）模型，能够将用户评论精确分类为隐私相关的特性请求、隐私相关的错误报告或隐私不相关。通过分析来自七个流行社交媒体应用的约16000条评论，GRACE模型展示了卓越的性能（宏F1: 0.9434，准确率: 95.10%）。SENSOR工具具有显著潜力，可以帮助开发者高效地从海量用户评论中提取和解决隐私问题，从而提升用户隐私和信任。

> **摘要翻译:** 社交媒体应用的广泛使用引发了显著的隐私担忧，这些担忧常在用户评论中被提及。这些评论也为开发者提供了宝贵的见解，有助于通过解决问题和引入更好的功能来改进应用程序。然而，评论量巨大且性质微妙，使得开发者难以手动识别和优先处理隐私相关问题。以前的研究已经开发了软件工具，利用机器学习自动将用户评论分类为隐私相关、隐私不相关、错误报告、功能请求等。值得注意的是，目前缺乏专门将评论分类为隐私相关功能请求、隐私相关错误报告或隐私不相关的研究。本文介绍了一种名为SENtinel SORt (SENSOR) 的自动化在线标注工具，旨在帮助开发者将用户评论标注和分类到这些类别中。为了自动化此类评论的标注，本文引入了标注模型GRACE (GRU-based Attention with CBOW Embedding)，该模型使用门控循环单元(GRU)结合连续词袋(CBOW)和注意力机制。研究分析了来自Google Play商店中七款流行社交媒体应用（包括Instagram、Facebook、WhatsApp、Snapchat、X（前身为Twitter）、Facebook Lite和Line）的约16000条用户评论。两名标注者手动标注了评论，实现了0.87的Cohen's Kappa值，确保了用于训练机器学习模型的高一致性标注数据集。在测试的模型中，GRACE模型表现最佳（宏F1分数：0.9434，宏ROC-AUC：0.9934，准确率：95.10%），尽管存在类别不平衡。SENSOR展示了在协助开发者从用户评论中提取和处理隐私相关的特性请求或错误报告方面的巨大潜力，从而增强用户隐私和信任。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [32] [QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration](https://arxiv.org/abs/2506.23644)
> *QLPro：通过大型语言模型和静态代码分析集成实现自动化代码漏洞发现*

*Junze Hu, Xiangyu Jin, Yizhe Zeng, Yuling Liu, Yunpeng Li, Dan Du, Kaiyu Xie, Hongsong Zhu* | **Category: cs.SE, cs.AI, cs.CR** | **Updated: 2025-07-15**

**Keywords:** 代码漏洞, 大型语言模型, 静态代码分析, 漏洞检测, 零日漏洞

**Comment:** The experimental data in the experimental section needs to be
  improved, and there are some errors

> **TL;DR:** QLPro是一个结合大型语言模型（LLM）和静态代码分析工具的漏洞检测框架，在JavaTest数据集上比CodeQL表现更好，并发现了新的零日漏洞。

**AI_Comments:** QLPro的创新之处在于其将LLM与传统静态代码分析相结合，这代表了代码漏洞发现领域的一个重要进展。通过利用LLM的语义理解能力和静态分析工具的结构化检查，QLPro能够发现传统工具难以识别的漏洞，特别是其发现零日漏洞的能力突显了其潜在的实际应用价值和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的静态分析工具（如CodeQL）在检测代码漏洞方面存在局限性，无法全面发现开源项目中的所有漏洞。

**Method:** QLPro系统地整合了大型语言模型（LLM）和静态代码分析工具。研究人员构建了一个包含10个开源项目和62个已知漏洞的JavaTest数据集用于评估。

**Result:** 在JavaTest数据集上，CodeQL仅检测到62个漏洞中的24个，而QLPro检测到41个。此外，QLPro发现了6个以前未知的漏洞，其中2个已被确认为零日漏洞。

**Conclusion:** QLPro通过整合大型语言模型和静态代码分析，显著提高了代码漏洞的检测能力，并能发现现有工具无法检测到的新漏洞，包括零日漏洞。

> **ai_Abstract:** QLPro是一个创新的漏洞检测框架，它将大型语言模型与静态代码分析工具相结合，旨在全面检测开源项目中的漏洞。该框架在自定义的JavaTest数据集上进行了验证，结果显示其性能优于先进的静态分析工具CodeQL，并成功发现了多个此前未知的零日漏洞。

> **摘要翻译:** 我们引入了QLPro，一个漏洞检测框架，它系统地整合了大型语言模型（LLM）和静态分析工具，以实现在整个开源项目中进行全面的漏洞检测。我们构建了一个新的数据集JavaTest，包含来自GitHub的10个开源项目和62个已确认的漏洞。CodeQL，一个最先进的静态分析工具，仅检测到这些漏洞中的24个，而QLPro检测到41个。此外，QLPro发现了6个以前未知的漏洞，其中2个已被确认为零日漏洞。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [68] [Security Debt in Practice: Nuanced Insights from Practitioners](https://arxiv.org/abs/2507.11362)
> *实践中的安全债务：来自从业者的细致见解*

*Chaima Boufaied, Taher Ghaleb, Zainab Masood* | **Category: cs.SE** | **Updated: 2025-07-15**

**Keywords:** 安全债务, 软件安全, 实践者见解, 定性研究, SDLC

**Comment:** 

> **TL;DR:** 软件开发中，安全债务（SDs）因时间、资源和功能优先于安全而累积。本研究通过访谈22名从业者，探讨他们如何感知、管理和沟通SDs，发现不同实践方式，并强调需加强SDLC中的安全整合、平衡资源与安全任务。

**AI_Comments:** 这项研究通过定性访谈提供了对实践中安全债务的细致见解，填补了该领域实证证据的空白。其创新之处在于直接从从业者角度出发，揭示了安全与开发效率之间的权衡，并提供了实用的建议，对于改进软件开发中的安全实践具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 如今，随着对软件和自动化的日益依赖，紧张的截止日期、有限的资源以及功能优先于安全的做法可能导致不安全的编码实践。当这些约束未得到妥善处理时，未解决的安全漏洞会随着时间的推移而累积，形成安全债务（SDs）。尽管它们至关重要，但关于软件从业者在实际环境中如何感知、管理和沟通安全债务的实证证据有限。

**Method:** 本文提出了一项基于对22名来自不同角色、组织和国家的软件从业者进行半结构化访谈的定性实证研究。研究旨在回答四个研究问题：i) 评估软件从业者对安全债务的了解和对相关安全风险的意识，ii) 调查他们对安全债务的行为，iii) 探讨用于缓解安全债务的常用工具和策略，以及iv) 分析安全风险如何在团队内部和向决策者沟通。

**Result:** 研究观察到从业者在感知和管理安全债务方面存在差异，一些人优先考虑交付速度而非安全，而另一些人则始终将安全作为优先事项。

**Conclusion:** 研究结果强调需要在软件开发生命周期（SDLC）中更强地整合安全实践，更一致地使用缓解策略，更好地平衡截止日期、资源和与安全相关的任务，并关注保密性、完整性和可用性（CIA）三要素。

> **ai_Abstract:** 本文通过对22名软件从业者进行半结构化访谈，深入探讨了他们在实际工作中如何感知、管理和沟通“安全债务”（SDs）。研究发现，由于时间、资源和功能优先等因素，安全漏洞易于累积，形成安全债务。从业者对安全债务的认知和处理方式存在差异，一些人注重交付速度，另一些人则优先安全。研究结果强调了在软件开发生命周期中加强安全整合、持续采用缓解策略以及平衡项目约束与安全任务的重要性，以维护系统的保密性、完整性和可用性。

> **摘要翻译:** 如今，随着对软件和自动化的日益依赖，紧张的截止日期、有限的资源以及功能优先于安全的做法可能导致不安全的编码实践。当这些约束未得到妥善处理时，未解决的安全漏洞会随着时间的推移而累积，形成安全债务（SDs）。尽管它们至关重要，但关于软件从业者在实际环境中如何感知、管理和沟通安全债务的实证证据有限。在本文中，我们提出了一项基于对22名来自不同角色、组织和国家的软件从业者进行半结构化访谈的定性实证研究。我们解决了四个研究问题：i) 我们评估了软件从业者对安全债务的了解和对相关安全风险的意识，ii) 我们调查了他们对安全债务的行为，iii) 我们探讨了用于缓解安全债务的常用工具和策略，以及iv) 我们分析了安全风险如何在团队内部和向决策者沟通。我们观察到从业者在感知和管理安全债务方面存在差异，一些人优先考虑交付速度而非安全，而另一些人则始终将安全作为优先事项。我们的发现强调需要在软件开发生命周期（SDLC）中更强地整合安全实践，更一致地使用缓解策略，更好地平衡截止日期、资源和与安全相关的任务，并关注保密性、完整性和可用性（CIA）三要素。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [79] [A Code Comprehension Benchmark for Large Language Models for Code](https://arxiv.org/abs/2507.10641)
> *代码大语言模型的代码理解基准*

*Jayant Havare, Saurav Chaudhary, Ganesh Ramakrishnan, Kaushik Maharajan, Srikanth Tamilselvam* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 代码大模型, 代码理解, 语义理解, 微调, 基准测试

**Comment:** 10 Pages, 5 Figures

> **TL;DR:** 代码大语言模型在代码理解方面表现不足，本研究提出通过大规模数据集进行微调以提升其语义理解能力，并在代码理解任务上取得了显著的性能提升。

**AI_Comments:** 该论文创新性地关注了代码大模型在语义理解上的不足，并提出了通过特定微调来弥补这一缺陷。其重要性在于为提升代码大模型在真实世界复杂编程任务（如调试、优化）中的表现提供了有效途径和评估基准。通过量化微调前后性能的提升，证明了深层语义理解对于代码大模型的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型在代码生成和补全等任务上表现出色，但它们主要学习表面语法模式，缺乏深层代码语义理解能力，导致在代码调试和优化等需要语义理解的任务中表现不佳。

**Method:** 为了解决代码大模型缺乏深层语义理解的问题，研究者提出使用大规模数据集对模型进行代码理解任务的微调。他们评估了三种不同规模的代码模型，通过一套旨在评估超越表面语法匹配的语义理解的代码理解任务进行测试，特别是分析了在主观性评分任务上的表现。

**Result:** 模型在相关下游任务上微调后性能得到提升。QWQ-32B模型的准确率从70%显著提升至83.47%。其他模型也观察到类似或可解释的趋势，表明代码理解能力得到增强。在所研究的模型中，经过DPO微调的Codestral-22B模型在主观性评分任务上取得了87.66%的最高微平均准确率。

**Conclusion:** 通过大规模数据集对代码大模型进行微调，可以显著提升其代码理解能力，使其能够更好地捕获代码语义，从而在需要深层语义理解的任务中表现更优。

> **ai_Abstract:** 本研究指出，尽管代码大语言模型在语法层面表现出色，但其在代码语义理解上存在不足，导致在复杂任务中性能受限。为解决此问题，作者提出通过大规模数据集对这些模型进行代码理解任务的微调。实验结果表明，微调显著提升了模型（特别是QWQ-32B和Codestral-22B）在语义理解任务上的准确率，验证了该方法能有效增强模型对代码语义的掌握。

> **摘要翻译:** 大型语言模型在代码生成和代码补全等编码任务中表现出令人印象深刻的能力，因为它们在大量的代码数据上进行了训练。此外，由于其核心预训练目标之一是下一词元预测，这些模型倾向于学习代码的表面语法模式。然而，这并不能保证代码理解能力，即捕获代码语义的能力。我们认为，这就是这些模型在需要更深层次语义理解的任务（如代码调试和代码优化）上表现不佳的原因。为了解决这个问题，我们建议使用大规模数据集专门针对代码理解任务对这些模型进行微调，使其能够对代码语义形成更 robust 的理解。我们评估了三种不同大小的代码模型，这些模型在一套旨在评估超越表面语法模式匹配的语义理解的代码理解任务上进行了测试。特别是，我们分析了在主观性评分任务上的表现，并观察到模型在相关下游任务上微调后性能有所提高。最显著的改进出现在QWQ-32B模型中，其准确率从70%提高到83.47%。在其他模型中也观察到类似或可解释的趋势，这清楚地表明代码理解能力得到了增强。在所研究的模型中，经过DPO微调的Codestral-22B在主观性评分任务上取得了87.66%的最高微平均准确率。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [133] [CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based Code Assistance](https://arxiv.org/abs/2507.10646)
> *CodeAssistBench (CAB)：用于多轮聊天式代码辅助的数据集与基准测试*

*Myeongsoo Kim, Shweta Garg, Baishakhi Ray, Varun Kumar, Anoop Deoras* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 代码辅助, 基准测试, 大语言模型, 多轮对话, GitHub Issues

**Comment:** 

> **TL;DR:** CodeAssistBench (CAB) 是一个用于评估大型语言模型在真实多轮代码辅助场景下性能的基准测试框架，它通过GitHub问题自动生成数据集，并揭示了现有LLM在此类复杂任务上的巨大能力差距。

**AI_Comments:** 该论文通过引入CodeAssistBench (CAB) 框架，填补了现有代码辅助基准测试的空白，将评估从单一、孤立的场景扩展到更真实、多轮的项目级交互。其创新之处在于利用GitHub Issues自动生成数据集并进行代码库容器化，大大降低了手动标注成本并提高了评估的真实性。研究结果揭示了当前LLM在复杂项目上下文理解和辅助方面的显著不足，为未来LLM的研究和开发指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的编程助手基准测试大多集中在代码生成任务，或仅限于单轮交互和孤立上下文，且需要大量手动整理，无法代表完整的项目环境。本文旨在解决这一空白，提供一个更真实、多轮的代码辅助评估框架。

**Method:** 本文提出了CodeAssistBench (CAB) 框架，该框架通过可配置参数（如仓库创建日期、星标数、编程语言）从与问题相关的GitHub Issues中自动生成可扩展数据集，并自动容器化代码库以进行评估。它通过在这些具有完整代码库访问权限的容器化环境中模拟用户来评估模型。

**Result:** 本文使用CAB框架构建了一个包含3,286个真实世界编程问题（来自231个仓库，涵盖7种编程语言）的测试集。评估显示，领先的LLM在Stack Overflow问题上的成功率达到70-83%，但在CAB的近期问题上解决率仅为16.49%。

**Conclusion:** LLM在复杂、项目特定上下文中的辅助能力与回答独立问题之间存在显著的能力差距。

> **ai_Abstract:** CodeAssistBench (CAB) 是一个新颖的基准测试框架，旨在解决现有编程助手基准测试的局限性。它专注于评估大型语言模型在真实、多轮、基于聊天代码辅助场景中的表现。CAB通过从GitHub Issues自动生成可扩展数据集并容器化代码库，模拟真实的项目环境。研究结果显示，尽管LLM在Stack Overflow等独立问题上表现良好，但在CAB所模拟的复杂、项目特定问题上，其解决能力存在显著差距。

> **摘要翻译:** 大型语言模型驱动的编程助手已经改变了软件开发，但大多数基准测试仅狭隘地关注代码生成任务。最近像InfiBench和StackEval这样的努力试图利用Stack Overflow数据解决这一差距，但仍局限于孤立上下文中的单轮交互，需要大量手动整理，并且未能代表完整的项目环境。我们引入了CodeAssistBench (CAB)，这是第一个用于在真实环境中评估多轮编程辅助的基准测试框架，它解决了关于实际代码库的真实世界问题。与现有编程问答基准测试不同，CAB使用可配置参数（例如，仓库创建日期、星标数、编程语言）从与问题相关的GitHub问题中自动生成可扩展数据集，并包括用于评估的代码库自动容器化。然后，它通过在这些具有完整代码库访问权限的容器化环境中模拟用户来评估模型。利用这个框架，我们构建了一个包含231个仓库中3,286个真实世界编程问题的测试集，涵盖七种编程语言和不同的问题领域。我们对领先的LLM的评估揭示了一个巨大的能力差距：虽然模型在Stack Overflow问题上表现良好，成功率达到70-83%，但它们只能解决CAB近期问题的16.49%。这种差异凸显了在复杂、项目特定上下文中提供帮助与回答独立问题所面临的挑战。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [158] [Supervised Semantic Similarity-based Conflict Detection Algorithm: S3CDA](https://arxiv.org/abs/2206.13690)
> *基于监督语义相似性的冲突检测算法：S3CDA*

*Garima Malik, Mucahit Cevik, Ayse Basar, Devang Parikh* | **Category: cs.SE** | **Updated: 2025-07-14**

**Keywords:** 需求冲突检测, 语义相似性, 软件需求工程, 自然语言处理, S3CDA

**Comment:** 

> **TL;DR:** S3CDA是一种基于语义相似性和领域实体分析的两阶段算法，用于自动检测软件需求冲突，在领域特定数据集上优于大型语言模型。

**AI_Comments:** S3CDA的创新之处在于其结合了语义相似性匹配和领域特定实体验证的两阶段方法，有效解决了传统自动化方案泛化能力差和手工规则依赖的问题。尤其是在与大型语言模型的对比中，S3CDA在领域特定场景下的优越表现，凸显了领域知识在特定问题解决中的重要性，为软件需求工程中的冲突检测提供了一个实用且高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 软件需求工程中识别冲突需求是一个关键挑战，现有自动化解决方案常被忽视，且多数依赖手工规则或泛化能力不足。

**Method:** 本文引入S3CDA，一个两阶段算法，旨在自动检测软件需求中的冲突。该方法首先使用语义相似性识别潜在冲突的需求对，然后通过分析重叠的领域特定实体进行验证。

**Result:** S3CDA在五个真实的、多样化的数据集上进行了评估，并与GPT-4o、Llama-3、Sonnet-3.5和Gemini-1.5等流行的大型语言模型进行了比较。结果显示，尽管大型语言模型在通用数据集上表现出潜力，但S3CDA在领域特定设置中表现持续更好，性能更高。

**Conclusion:** 研究结果表明，将自然语言处理（NLP）技术与领域感知洞察相结合，为需求冲突检测提供了一种实用且有效的替代方案。

> **ai_Abstract:** 本文提出了S3CDA，一种用于自动检测软件需求冲突的两阶段算法。该算法首先利用语义相似性识别潜在冲突的需求对，然后通过分析重叠的领域特定实体进行验证。研究在五个真实数据集上评估了S3CDA，并与多种大型语言模型进行了对比。结果显示，尽管大型语言模型在通用数据集上表现良好，S3CDA在领域特定场景中表现出更优异的性能。这表明结合NLP技术与领域知识是解决需求冲突检测的有效途径。

> **摘要翻译:** 识别冲突需求是软件需求工程中的一个关键挑战，但在自动化解决方案中常被忽视。大多数现有方法依赖手工规则或难以在不同领域泛化。在本文中，我们引入了S3CDA，一种旨在自动检测软件需求中冲突的两阶段算法。我们的方法首先利用语义相似性识别潜在冲突的需求对，然后通过分析重叠的领域特定实体来验证它们。我们在五个不同的真实世界数据集上评估了S3CDA，并将其与流行的如GPT-4o、Llama-3、Sonnet-3.5和Gemini-1.5等大型语言模型进行了比较。尽管大型语言模型在通用数据集上显示出潜力，但S3CDA在领域特定设置中表现持续更好，性能更高。我们的研究结果表明，将自然语言处理（NLP）技术与领域感知洞察相结合，为需求冲突检测提供了一种实用且有效的替代方案。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [177] [Toward Realistic Evaluations of Just-In-Time Vulnerability Prediction](https://arxiv.org/abs/2507.10729)
> *迈向即时漏洞预测的现实评估*

*Duong Nguyen, Thanh Le-Cong, Triet Huynh Minh Le, M. Ali Babar, Quyet-Thang Huynh* | **Category: cs.SE** | **Updated: 2025-07-14**

**Keywords:** 即时漏洞预测, 现实评估, 类别不平衡, 数据集, 软件安全

**Comment:** 

> **TL;DR:** 即时漏洞预测（JIT-VP）在真实不平衡数据集中的性能显著下降，且现有数据不平衡处理技术无效，表明需要更现实的评估和特定领域解决方案。

**AI_Comments:** 该论文的创新之处在于挑战了JIT-VP理想化的评估设置，并提供了一个更现实的基准。其重要性在于揭示了现有先进技术在真实世界条件下的实际性能下降，并指出常用不平衡处理技术的无效性，从而指出了一个关键的研究空白。它还提供了一个有价值的公共数据集。

<details>
  <summary>Details</summary>

**Motivation:** 当前的即时漏洞预测（JIT-VP）评估依赖于理想化的、人为平衡的数据集，未能反映真实世界中包含大量非漏洞相关提交和严重类别不平衡的实际情况，导致对JIT-VP性能的过高估计。

**Method:** 本研究通过引入一个包含超过一百万个提交（来自FFmpeg和Linux内核）的大规模公共数据集来评估JIT-VP技术在更现实环境下的有效性，该数据集包含漏洞相关和非漏洞相关提交。研究对八种最先进的JIT-VP技术进行了实证分析，并探讨了常用数据集不平衡处理技术（包括自定义损失函数、过采样和欠采样）的有效性。

**Result:** 实证分析表明，在真实世界条件下，JIT-VP技术的预测性能显著下降（例如，Linux上的平均PR-AUC下降98%），这主要归因于严重的类别不平衡。令人惊讶的是，广泛采用的数据集不平衡处理技术（自定义损失函数、过采样和欠采样）在解决JIT-VP中的不平衡问题方面无效。

**Conclusion:** 本研究强调了对即时漏洞预测（JIT-VP）进行现实评估的重要性，并指出了开发特定领域技术以有效解决此类场景中数据不平衡问题的必要性。

> **ai_Abstract:** 本文指出，当前即时漏洞预测（JIT-VP）的评估依赖于理想化的平衡数据集。为解决此局限，研究引入了一个包含漏洞相关和非漏洞相关提交的大规模数据集，并在更现实的环境下评估JIT-VP技术。结果显示，JIT-VP在真实世界不平衡数据中的预测性能显著下降，且常见的平衡技术无效。研究强调了JIT-VP现实评估的重要性以及开发领域特定不平衡处理技术的必要性。

> **摘要翻译:** 现代软件系统日益复杂，对质量保证提出了重大挑战。即时漏洞预测（JIT-VP）是一种主动识别易受攻击提交并就潜在安全风险提供早期预警的方法。然而，我们观察到当前的JIT-VP评估依赖于理想化的设置，其中评估数据集是人为平衡的，仅包含引入漏洞和修复漏洞的提交。
为了解决这一局限性，本研究在更现实的设置下评估了JIT-VP技术的有效性，该设置包括漏洞相关和漏洞中性提交。为了实现可靠的评估，我们引入了一个大规模公共数据集，包含来自FFmpeg和Linux内核的超过一百万个提交。我们对八种最先进的JIT-VP技术进行的实证分析表明，当应用于真实世界条件时，预测性能显著下降；例如，Linux上的平均PR-AUC从0.805下降到0.016，下降了98%。这种差异主要归因于真实世界数据集中严重的类别不平衡，其中引入漏洞的提交仅占所有提交的一小部分。
为了缓解这个问题，我们探讨了广泛采用的数据集不平衡处理技术的有效性，包括自定义损失函数、过采样和欠采样。令人惊讶的是，我们的实验结果表明这些技术在解决JIT-VP中的不平衡问题方面无效。这些发现强调了JIT-VP现实评估的重要性以及在此类场景中处理数据不平衡的领域特定技术的必要性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [193] [Advancing Code Coverage: Incorporating Program Analysis with Large Language Models](https://arxiv.org/abs/2404.04966)
> *提高代码覆盖率：结合程序分析与大型语言模型*

*Chen Yang, Junjie Chen, Bin Lin, Ziqi Wang, Jianyi Zhou* | **Category: cs.SE** | **Updated: 2025-07-15**

**Keywords:** 代码覆盖率, 大型语言模型, 程序分析, 自动测试生成, 搜索式软件测试

**Comment:** Accepted by TOSEM (ACM Transactions on Software Engineering and
  Methodology)

> **TL;DR:** TELPA结合程序分析和大型语言模型，通过学习复杂对象构造和分支约束语义，显著提高了代码覆盖率，尤其是在难以覆盖的分支上。

**AI_Comments:** 这篇论文的创新点在于将程序分析的结果和反例有效地融入到LLM的提示中，从而指导LLM生成更具针对性和有效性的测试用例，解决了传统方法难以覆盖复杂分支的问题。其结合静态分析和动态反馈的策略，为LLM在软件测试领域的应用提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的搜索式软件测试（SBST）和大型语言模型（LLM）在自动生成测试用例方面，仍难以覆盖某些需要构建复杂对象和解决复杂跨过程依赖的难以触及的分支。

**Method:** 论文提出了TELPA技术。其核心思想是：1) 提取目标方法的实际使用场景，学习复杂对象的构建；2) 提取包含跨过程依赖的方法，学习分支约束的语义。为提高效率和有效性，TELPA识别无效测试作为LLM的反例，并采用反馈机制迭代优化。然后，TELPA将程序分析结果和反例整合到提示中，引导LLM更深入理解目标方法语义，并生成能达到难以覆盖分支的多样化测试。

**Result:** 在27个开源Python项目上的实验结果表明，TELPA在分支覆盖率方面显著优于现有的SBST和基于LLM的技术，平均分别提高了31.39%和22.22%。

**Conclusion:** TELPA通过结合程序分析和大型语言模型，有效解决了难以覆盖分支的测试生成问题，显著提升了代码覆盖率，证明了其在软件质量保证中的优越性。

> **ai_Abstract:** 本文提出TELPA，一种结合程序分析与大型语言模型的新型测试生成技术，旨在解决现有SBST和LLM方法在覆盖难以触及代码分支上的不足。TELPA通过学习复杂对象构建和跨过程依赖语义，并利用反馈机制优化反例来指导LLM生成多样化测试。实验证明，TELPA在Python项目上显著提升了分支覆盖率。

> **摘要翻译:** 自动测试生成在软件质量保证中扮演着关键角色。尽管搜索式软件测试（SBST）和大型语言模型（LLM）的最新进展在生成有效测试方面展现出潜力，但这些技术仍然难以覆盖某些特定分支。达到这些难以覆盖的分支通常需要构建复杂的对象并解决分支条件中复杂的跨过程依赖，这给现有测试生成技术带来了重大挑战。在这项工作中，我们提出了TELPA，一种旨在解决这些挑战的新颖技术。其关键见解在于提取被测目标方法的实际使用场景，以学习如何构建复杂对象，并提取包含难以覆盖分支的跨过程依赖的方法，以学习分支约束的语义。为了提高效率和有效性，TELPA识别一组无效测试作为大型语言模型的反例，并采用基于反馈的过程迭代地细化这些反例。然后，TELPA将程序分析结果和反例整合到提示中，引导大型语言模型更深入地理解目标方法的语义，并生成能够达到难以覆盖分支的多样化测试。我们在27个开源Python项目上的实验结果表明，TELPA显著优于最先进的SBST和基于LLM的技术，在分支覆盖率方面平均分别提高了31.39%和22.22%。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [222] [GenAI-Enabled Backlog Grooming in Agile Software Projects: An Empirical Study](https://arxiv.org/abs/2507.10753)
> *生成式人工智能赋能敏捷软件项目待办事项梳理：一项实证研究*

*Kasper Lien Oftebro, Anh Nguyen-Duc, Kai-Kristian Kemell* | **Category: cs.SE** | **Updated: 2025-07-14**

**Keywords:** 生成式AI, 待办事项梳理, 敏捷软件开发, Jira插件, GPT-4o

**Comment:** 

> **TL;DR:** 本研究开发并评估了一个基于生成式AI的Jira插件，用于自动化敏捷项目中的待办事项梳理。结果显示，该工具在保持100%准确性的同时，将完成时间缩短了45%，显著提高了效率和用户体验。

**AI_Comments:** 这项研究的创新之处在于将生成式AI（特别是GPT-4o）应用于敏捷软件开发中的待办事项梳理这一具体且痛点显著的环节。其重要性在于通过自动化显著提高了效率（时间减少45%）并保持了高准确性（100%精度），这对于提高开发团队生产力和项目管理质量具有重要意义。该研究通过开发实际的Jira插件并进行实证验证，提供了具体的解决方案和积极的成果。

<details>
  <summary>Details</summary>

**Motivation:** 有效的待办事项管理对于确保开发团队与不断演进的需求和利益相关者期望保持一致至关重要。然而，产品待办事项列表规模和复杂性不断增长，容易充斥冗余、过时或定义不清的任务，从而使优先级排序和决策过程复杂化。

**Method:** 本研究通过设计科学周期，开发了一个Jira插件。该插件将待办事项与向量数据库嵌入，通过余弦相似度检测重复项，并利用GPT-4o模型建议合并、删除或创建新事项。

**Result:** AI辅助的待办事项梳理实现了100%的准确率，同时将完成时间缩短了45%。

**Conclusion:** 研究结果表明，该工具具有简化待办事项优化流程并改善用户体验的潜力。

> **ai_Abstract:** 本研究旨在解决敏捷软件项目中待办事项列表日益增长的复杂性和混乱问题。研究开发了一个基于生成式AI（GPT-4o）的Jira插件，该插件利用向量数据库和余弦相似度来识别和处理重复、过时或定义不清的待办事项。实证结果表明，该AI辅助工具在待办事项梳理中实现了100%的准确率，并将完成时间缩短了45%，显著提高了效率和用户体验，展现了其在优化待办事项流程方面的巨大潜力。

> **摘要翻译:** 有效的待办事项管理对于确保开发团队与不断演进的需求和利益相关者期望保持一致至关重要。然而，随着产品待办事项的规模和复杂性持续增长，它们往往会充斥着冗余、过时或定义不清的任务，从而使优先级排序和决策过程复杂化。本研究调查了生成式人工智能 (GenAI) 助手是否能在不牺牲准确性或透明度的情况下，自动化敏捷软件项目中的待办事项梳理。通过设计科学周期，我们开发了一个Jira插件，该插件将待办事项嵌入向量数据库，通过余弦相似度检测重复项，并利用GPT-4o模型建议合并、删除或创建新事项。我们发现，AI辅助的待办事项梳理实现了100%的准确率，同时将完成时间缩短了45%。研究结果表明，该工具具有简化待办事项优化流程并改善用户体验的潜力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [233] [Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution](https://arxiv.org/abs/2504.05424)
> *命令式深度学习程序到图执行的推测性自动化重构*

*Raffi Khatchadourian, Tatiana Castro Vélez, Mehdi Bagherzadeh, Nan Jia, Anita Raja* | **Category: cs.SE, cs.AI, cs.PL, D.2.7; C.4; D.3.4; I.2.6** | **Updated: 2025-07-14**

**Keywords:** 深度学习, 代码重构, 图执行, 命令式编程, 静态分析

**Comment:** 

> **TL;DR:** 该研究提出了一种自动化重构方法，帮助开发者将命令式深度学习代码中的函数转换为图执行，以提高运行时性能，同时保持模型准确性。

**AI_Comments:** 这项研究的创新之处在于将传统系统中并行化顺序代码的思路应用于命令式深度学习代码的优化，提出了一种自动化且推测性的重构方法。其重要性在于解决了命令式深度学习框架在性能上的短板，使开发者能够兼顾开发的便捷性和运行的效率。该方法通过静态分析和推测性处理Python的动态性，为DL代码优化提供了一种实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习系统需要高效率来处理不断增长的数据集。传统的延迟执行（图执行）DL框架虽然可扩展但难以开发和调试。新兴的命令式（即时执行）DL框架更自然但性能较差。混合方法虽能兼顾，但使用复杂。因此，需要一种方法来自动优化命令式DL代码以提升性能。

**Method:** 该方法受到传统系统中并行化顺序代码的启发，提出了一种自动化重构方法，用于识别可高效地作为图执行的命令式DL函数。它采用了新颖的Python命令式张量和副作用静态分析。针对Python的动态性，采用推测性（基于关键词）分析来解决困难情况，并告知开发者所做的假设。该方法实现为PyDev Eclipse IDE插件，集成了WALA Ariadne分析框架。

**Result:** 在19个DL项目（132 KLOC）上进行了评估，结果显示766个候选函数中有326个（42.56%）可重构。在性能测试中观察到平均2.16倍的相对加速，模型精度差异可忽略不计。

**Conclusion:** 该研究表明，所提出的方法在充分优化命令式深度学习代码方面非常有用。

> **ai_Abstract:** 该论文提出了一种自动化重构方法，旨在将命令式深度学习程序中的函数转换为更高效的图执行模式。通过新颖的Python静态分析（包括推测性分析），该方法能够识别适合重构的函数。实验结果表明，该方法能够成功重构大量函数，并在性能上实现显著加速，同时保持模型精度，从而有效优化命令式DL代码的运行时效率。

> **摘要翻译:** 效率对于支持不断增长的数据集至关重要，特别是对于深度学习（DL）系统。DL框架传统上采用延迟执行风格的DL代码——支持符号化、基于图的深度神经网络（DNN）计算。虽然可扩展，但这种开发容易出错、不直观且难以调试。因此，更自然、鼓励即时执行的命令式DL框架应运而生，但代价是运行时性能。尽管混合方法旨在实现“两全其美”，但有效使用它们需要细致的考虑。我们的关键见解是，虽然DL程序通常顺序执行，但命令式DL代码的混合化类似于传统系统中并行化顺序代码。受此启发，我们提出了一种自动化重构方法，帮助开发者确定哪些原本即时执行的命令式DL函数可以有效地作为图执行。该方法具有新颖的Python命令式张量和副作用静态分析。由于其固有的动态性，分析Python可能不健全；然而，保守的方法利用推测性（基于关键词）分析来解决困难情况，并告知开发者所做的任何假设。该方法：(i) 作为PyDev Eclipse IDE的插件实现，集成了WALA Ariadne分析框架；(ii) 在包含132 KLOC的19个DL项目上进行了评估。结果显示，766个候选函数中有326个（42.56%）可重构，并且在性能测试中观察到平均2.16倍的相对加速，模型精度差异可忽略不计。结果表明该方法有助于充分优化命令式DL代码。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [264] [Towards a Closer Collaboration Between Practice and Research in Agile Software Development Workshop: A Summary and Research Agenda](https://arxiv.org/abs/2507.10785)
> *敏捷软件开发中实践与研究更紧密协作研讨会：总结与研究议程*

*Michael Neumann, Eva-Maria Schön, Mali Senapathi, Maria Rauschenberger, Tiago Silva da Silva* | **Category: cs.SE** | **Updated: 2025-07-14**

**Keywords:** 敏捷软件开发, 研究与实践, 协作, 研讨会, 研究议程

**Comment:** 

> **TL;DR:** 敏捷开发领域研究与实践存在鸿沟，本文总结了旨在弥合此鸿沟的首次国际研讨会成果，并提出了研究议程。

**AI_Comments:** 这篇论文通过组织国际研讨会，直接关注了软件工程领域中一个普遍存在的问题：理论与实践脱节。其创新之处在于通过协作式研讨会的形式，直接从研究者和实践者那里收集信息，从而识别出差距的根本原因和潜在的解决方案，并提出了明确的研究议程，对于推动敏捷软件开发的成熟和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 敏捷软件开发原则和价值观已被广泛采用，但研究与实际实施之间仍存在显著差距。

**Method:** 本文介绍了旨在促进敏捷软件开发研究与实践之间协作的首次国际研讨会的发现。研讨会讨论了导致差距的主要主题和因素、弥合差距的策略以及需要进一步研究的挑战。

**Result:** 研讨会参与者识别了导致研究与实践之间差距的主要主题和因素，提出了弥合差距的策略，并指出了需要进一步研究的挑战。

**Conclusion:** 本文总结了旨在促进敏捷软件开发领域研究与实践协作的首次国际研讨会的成果，并提出了未来的研究议程。

> **ai_Abstract:** 本文总结了首次国际敏捷软件开发研讨会的成果，该研讨会旨在解决敏捷开发研究与实践之间的显著差距。文章讨论了研讨会参与者识别出的导致差距的因素、弥合差距的策略以及未来需要研究的挑战，为促进研究与实践的协作提出了研究议程。

> **摘要翻译:** 敏捷软件开发原则和价值观已被各行各业广泛采用，影响着全球的产品和服务。尽管其日益普及，但研究与实际实施之间仍存在显著差距。本文介绍了旨在促进敏捷软件开发研究与实践之间协作的首次国际研讨会的发现。我们讨论了研讨会参与者识别出的导致这一差距的主要主题和因素、弥合差距的策略以及需要进一步研究的挑战。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [278] [Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models](https://arxiv.org/abs/2505.17460)
> *学习聚焦：用于高效代码漏洞检测的语言模型上下文提取*

*Xinran Zheng, Xingzhi Qian, Huichi Zhou, Shuo Yang, Yiling He, Suman Jana, Lorenzo Cavallaro* | **Category: cs.SE** | **Updated: 2025-07-14**

**Keywords:** 代码漏洞检测, 语言模型, 上下文提取, FocusVul, 深度学习

**Comment:** Due to fundamental errors in the methodology, I have to withdraw this
  paper

> **TL;DR:** FocusVul是一个模型无关的框架，通过学习选择敏感上下文来改进基于语言模型的漏洞检测。它通过分层语义建模学习基于提交的标注模式，并将其泛化以识别行级漏洞相关区域，然后提取面向语言模型的上下文，显著提高了分类性能并降低了计算成本。

**AI_Comments:** FocusVul的创新点在于其模型无关的上下文提取方法，通过学习选择敏感的行级上下文，有效解决了语言模型在处理长代码时因信息稀疏和令牌限制而导致的性能问题。该方法通过结合依赖流和执行流，为语言模型提供了更聚焦、信息更丰富的输入，显著提高了漏洞检测的准确性和效率，对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型在漏洞检测方面显示出潜力，但由于漏洞位置的稀疏性和不确定性，以及令牌限制，它们难以处理长且真实的 accuses 代码。这导致模型错过漏洞相关信号，从而影响有效学习。

**Method:** 本文提出了FocusVul，一个模型无关的框架，通过学习选择敏感上下文来改进基于语言模型的漏洞检测。FocusVul通过分层语义建模学习基于提交的标注模式，并将其泛化以在推理过程中识别行级漏洞相关区域。然后，它通过围绕选定区域的依赖流和执行流提取面向语言模型的上下文，为有效的漏洞检测提供语义丰富的输入。

**Result:** 实验表明，FocusVul在真实世界基准测试中始终优于基于启发式和全函数微调的方法，平均分类性能提高了164.04%，FLOPs降低了19.12%。

**Conclusion:** FocusVul通过学习选择敏感且信息丰富的上下文，显著提高了基于语言模型的代码漏洞检测的效率和准确性。

> **ai_Abstract:** 本文提出FocusVul，一个用于代码漏洞检测的模型无关框架。针对语言模型处理长代码和稀疏漏洞上下文的挑战，FocusVul通过分层语义建模学习识别行级漏洞相关区域，并提取语义丰富的上下文。实验证明，FocusVul显著提升了漏洞检测的分类性能并降低了计算成本，优于现有方法。

> **摘要翻译:** 语言模型（LMs）在漏洞检测方面展现出前景，但由于漏洞位置的稀疏性和不确定性，它们难以处理长且真实的 accuses 代码。这些问题因令牌限制而加剧，常常导致模型错过与漏洞相关的信号，从而损害了有效学习。一个关键的直觉是通过简洁、信息丰富的上下文来增强语言模型。基于提交的标注提供了精确、与CWE无关的监督，但在推理过程中不可用，因为它们依赖于历史代码更改。此外，它们的极端稀疏性（通常只覆盖几行）使得语言模型难以直接处理。在本文中，我们提出了FocusVul，一个模型无关的框架，通过学习选择敏感上下文来改进基于语言模型的漏洞检测。FocusVul通过分层语义建模学习基于提交的标注模式，并将其泛化以在推理过程中识别行级漏洞相关区域。然后，它通过围绕选定区域的依赖流和执行流提取面向语言模型的上下文，为有效的漏洞检测提供语义丰富的输入。在真实世界基准测试上的实验表明，FocusVul始终优于基于启发式和全函数微调的方法，平均分类性能提高了164.04%，FLOPs降低了19.12%。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [317] [How Robust are LLM-Generated Library Imports? An Empirical Study using Stack Overflow](https://arxiv.org/abs/2507.10818)
> *LLM生成的库导入有多健壮？一项基于Stack Overflow的实证研究*

*Jasmine Latendresse, SayedHassan Khatoonabadi, Emad Shihab* | **Category: cs.SE** | **Updated: 2025-07-14**

**Keywords:** LLMs, 库导入, 实证研究, Stack Overflow, 软件依赖

**Comment:** 

> **TL;DR:** 一项对六种LLM的实证研究发现，LLM在编程任务中倾向于推荐成熟的第三方库，但存在可用性问题，如4.6%的库无法自动解析，且多数模型未提供安装指导，增加了用户手动解决依赖的负担。

**AI_Comments:** 这项研究揭示了LLM在生成代码时的一个重要实际限制：软件依赖管理。它强调了LLM虽然能生成有效代码，但缺乏对环境和依赖解析的上下文感知，导致用户需承担额外的负担。这对于提高LLM在实际编程工作流中的可用性和可靠性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 随着开发者越来越多地使用大型语言模型（LLM）协助编程任务，了解这些模型如何推荐库变得至关重要。

**Method:** 本研究对六个最先进的LLM（包括专有和开源模型）进行了实证研究，通过提示它们解决来自Stack Overflow的真实Python问题。我们分析了它们导入的库类型、这些库的特性以及推荐的开箱即用可用性。

**Result:** 结果显示，LLM主要偏爱第三方库而非标准库，并且通常推荐成熟、流行且许可宽松的依赖项。然而，我们也发现了可用性方面的不足：4.6%的库因导入名称与可安装包之间的结构不匹配而无法自动解析，并且只有两个模型（六个中）提供了安装指导。

**Conclusion:** 虽然生成的代码在技术上是有效的，但上下文支持的缺乏将手动解决依赖的负担转嫁给了用户。我们的发现为开发者和研究人员提供了可操作的见解，并强调了在软件依赖背景下改进LLM生成代码的可靠性和可用性的机会。

> **ai_Abstract:** 本研究对六种主流大型语言模型（LLM）在生成库导入方面的表现进行了实证分析。通过使用Stack Overflow上的真实Python问题进行测试，研究发现LLM倾向于推荐成熟的第三方库，但其推荐存在可用性问题，例如部分导入的库无法自动解析，且大多数模型未提供安装指南。这表明尽管LLM生成的代码在技术上有效，但在依赖管理方面仍需用户手动干预，为LLM在软件开发中的实际应用提出了改进方向。

> **摘要翻译:** 软件库是现代代码功能、安全性和可维护性的核心。随着开发者越来越多地转向大型语言模型（LLM）来协助编程任务，了解这些模型如何推荐库至关重要。本文对六个最先进的LLM（包括专有和开源模型）进行了实证研究，通过提示它们解决来自Stack Overflow的真实Python问题。我们分析了它们导入的库类型、这些库的特性以及推荐的开箱即用可用性。我们的结果显示，LLM主要偏爱第三方库而非标准库，并且通常推荐成熟、流行且许可宽松的依赖项。然而，我们也发现了可用性方面的不足：4.6%的库因导入名称与可安装包之间的结构不匹配而无法自动解析，并且只有两个模型（六个中）提供了安装指导。虽然生成的代码在技术上是有效的，但上下文支持的缺乏将手动解决依赖的负担转嫁给了用户。我们的发现为开发者和研究人员提供了可操作的见解，并强调了在软件依赖背景下改进LLM生成代码的可靠性和可用性的机会。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [323] [GUARD:Dual-Agent based Backdoor Defense on Chain-of-Thought in Neural Code Generation](https://arxiv.org/abs/2505.21425)
> *GUARD：基于双智能体的神经代码生成中思维链后门防御*

*Naizhu Jin, Zhong Li, Tian Zhang, Qingkai Zeng* | **Category: cs.SE** | **Updated: 2025-07-15**

**Keywords:** 后门防御, 思维链, 代码生成, 双智能体, 神经网络安全

**Comment:** Accepted by SEKE 2025

> **TL;DR:** GUARD是一个双智能体防御框架，用于抵御神经代码生成中思维链（CoT）模型的后门攻击，通过识别和修复可疑的CoT步骤来提高安全性。

**AI_Comments:** 该论文提出了一个创新的双智能体框架GUARD，专门针对神经代码生成中思维链（CoT）模型的后门攻击，填补了现有防御机制的不足。其通过“判断-修复”两阶段设计，有效提升了代码生成的安全性，对于构建更可靠的AI辅助编程系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明，思维链（CoT）生成模型能显著提升代码生成性能，但作为外部组件，它们特别容易受到后门攻击，且现有防御机制往往无法有效检测。

**Method:** 本文提出了GUARD框架，包含GUARD-Judge和GUARD-Repair两个核心组件。GUARD-Judge通过全面分析识别可疑的CoT步骤和潜在触发器；GUARD-Repair采用检索增强生成方法，为识别出的异常CoT步骤重新生成安全的步骤。

**Result:** 实验结果表明，GUARD能有效缓解后门攻击，同时保持代码生成质量。

**Conclusion:** GUARD框架通过其双智能体设计，为安全的神经代码生成系统提供了有效的后门防御机制，推进了该领域的发展。

> **ai_Abstract:** 本文提出了GUARD，一个用于神经代码生成的双智能体后门防御框架，旨在解决思维链（CoT）模型在提升代码性能的同时易受后门攻击的问题。GUARD包含GUARD-Judge用于识别可疑CoT步骤和触发器，以及GUARD-Repair用于修复这些异常。实验证明GUARD能有效防御攻击并保持生成质量，从而提升了代码生成的安全性。

> **摘要翻译:** 随着大型语言模型在代码生成中的广泛应用，近期研究表明，采用额外的思维链生成模型可以通过提供明确的推理步骤显著增强代码生成性能。然而，作为外部组件，CoT模型特别容易受到后门攻击，而现有的防御机制往往无法有效检测。为了解决这一挑战，我们提出了GUARD，一个新颖的基于双智能体的防御框架，专门设计用于对抗神经代码生成中的CoT后门攻击。GUARD集成了两个核心组件：GUARD-Judge，通过全面分析识别可疑的CoT步骤和潜在触发器；以及GUARD-Repair，它采用检索增强生成方法为识别出的异常重新生成安全的CoT步骤。实验结果表明，GUARD在有效缓解攻击的同时保持了生成质量，从而推进了安全代码生成系统的发展。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [369] [Past, Present and Future: Exploring Adaptive AI in Software Development Bots](https://arxiv.org/abs/2507.10822)
> *过去、现在和未来：探索软件开发机器人中的自适应人工智能*

*Omar Elsisi, Glaucia Melo* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 自适应AI, 软件开发, 会话代理, 机器学习, 自然语言处理

**Comment:** 

> **TL;DR:** 本文探讨了自适应AI会话代理在软件开发中的作用，分析了它们的演变、挑战、益处和局限性，并展望了未来潜力。

**AI_Comments:** 这篇论文强调了自适应AI在软件开发中从辅助工具到革命性力量的演变，其创新在于将机器学习和NLP应用于提供上下文感知和个性化支持。其重要性在于指出了提高开发效率和协作的潜力，但也谨慎地提出了数据隐私和伦理等挑战，为未来研究和应用提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 会话代理在软件开发中日益重要，尤其是自适应AI代理能显著提升生产力、协作和自动化，因此有必要深入研究其潜力和应用。

**Method:** 本文通过审视自适应AI会话代理的角色、考察其演变、探索集成挑战以及评估其益处和局限性来展开研究。

**Result:** 自适应AI代理利用机器学习和自然语言处理，能够从交互中学习并随时间改进，提供动态、上下文感知和个性化的帮助，优于传统规则系统，并已发展出如GitHub Copilot等高级解决方案。

**Conclusion:** 自适应AI聊天机器人通过提供实时、定制化的支持和提高开发周期的效率，具有彻底改变软件开发的巨大潜力。

> **ai_Abstract:** 本文探讨了自适应AI驱动的会话代理在软件开发中的关键作用。它分析了这些代理如何利用机器学习和自然语言处理提供动态、个性化的帮助，超越传统规则系统。文章回顾了其发展历程，从简单查询系统到高级AI解决方案，并讨论了集成挑战、数据隐私和伦理问题，最终强调了自适应AI在革新软件开发方面的巨大潜力。

> **摘要翻译:** 会话代理，如聊天机器人和虚拟助手，已成为软件开发中不可或缺的一部分，提高了生产力、协作并自动化了各种任务。本文探讨了自适应人工智能驱动的会话代理在软件开发中的作用，强调了它们为开发人员提供动态、上下文感知帮助的能力。与传统的基于规则的系统不同，自适应AI代理利用机器学习和自然语言处理，通过交互学习并随时间改进，提供更个性化和响应迅速的帮助。我们研究了这些工具如何从简单的基于查询的系统演变为先进的AI驱动解决方案，如GitHub Copilot和Microsoft Teams机器人。我们还探讨了将自适应AI集成到软件开发过程中的挑战。本研究旨在评估这些系统的益处和局限性，解决数据隐私和伦理问题，并为其在该领域的未来使用提供见解。最终，自适应AI聊天机器人通过提供实时、定制化的支持和提高开发周期的效率，具有彻底改变软件开发的巨大潜力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [370] [PromiseTune: Unveiling Causally Promising and Explainable Configuration Tuning](https://arxiv.org/abs/2507.05995)
> *PromiseTune：揭示因果有前景且可解释的配置调优*

*Pengzhou Chen, Tao Chen* | **Category: cs.SE** | **Updated: 2025-07-15**

**Keywords:** 配置调优, 因果推断, 可解释性, 探索与利用, 性能优化

**Comment:** This paper has been accepted by ICSE26

> **TL;DR:** PromiseTune是一种新的配置调优方法，通过因果净化规则识别有前景的区域，解决了现有调优器在探索与利用之间的平衡问题，并提供了可解释性，性能显著优于现有SOTA方法。

**AI_Comments:** 这篇论文通过引入“因果净化规则”来识别配置空间中的“有前景区域”，为配置调优提供了一种新颖且具有解释性的方法。其创新点在于将因果推断引入到规则学习中，从而更精确地指导探索和利用，有效缓解了传统调优器面临的困境。该方法不仅提升了调优性能，还增加了结果的可解释性，对于理解复杂系统行为具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代软件系统的高可配置性使得配置调优对系统性能至关重要。然而，由于昂贵的测量、巨大的配置空间和崎岖的配置格局，现有调优器在探索不确定区域和利用已知良好配置的指导之间难以平衡预算利用，导致效率低下。根本原因是缺乏对有前景区域的认知，这也导致了结果可解释性的挑战。

**Method:** 本文提出PromiseTune，通过因果净化的规则指导配置调优。PromiseTune通过学习反映配置格局中特定区域的规则，并利用因果推断对其进行净化。剩余的规则作为有前景区域的近似反映，限制调优以强调这些区域。这有效缓解了探索与利用的权衡问题。这些净化后的区域可以与测量的配置结合，在格局层面提供空间可解释性。

**Result:** 与12个系统上的11种最先进调优器在不同预算下进行比较，PromiseTune表现显著优于其他方法，其排名比总体第二名高出42%，同时提供了更丰富的信息来解释隐藏的系统特性。

**Conclusion:** PromiseTune通过引入因果净化的规则来识别有前景的配置区域，有效解决了现有配置调优方法在探索与利用权衡以及结果可解释性方面的挑战，并在性能和信息丰富度上取得了显著优势。

> **ai_Abstract:** PromiseTune是一种新型配置调优方法，旨在解决现有调优器在探索与利用权衡以及结果可解释性上的不足。它通过学习并因果净化规则来识别配置空间中的“有前景区域”，从而更有效地指导调优过程。实验结果表明，PromiseTune在性能上显著优于11种现有最先进方法，并能提供更丰富的系统特性解释。

> **摘要翻译:** 现代软件系统的高可配置性使得配置调优成为确保系统性能（例如延迟或吞吐量）的关键步骤。然而，考虑到昂贵的测量、巨大的配置空间和崎岖的配置格局，现有调优器由于难以平衡探索不确定区域（以摆脱局部最优）和利用已知良好配置的指导（以实现快速收敛）之间的预算利用而效率低下。根本原因是，我们缺乏对有前景区域所在位置的了解，这也导致了结果可解释性的挑战。
在本文中，我们提出了PromiseTune，它通过因果净化的规则指导配置调优。PromiseTune的独特之处在于，我们学习反映配置格局中特定区域的规则，并利用因果推断对其进行净化。剩余的规则作为有前景区域的近似反映，限制调优以强调这些区域。正如我们所展示的，这可以有效缓解探索与利用权衡的影响。这些净化后的区域可以与测量的配置结合，以在格局层面提供空间可解释性。与12个系统上和不同预算下的11种最先进调优器进行比较，我们表明PromiseTune的表现显著优于其他方法，其排名比总体第二名高出42%，同时提供了更丰富的信息来解释隐藏的系统特性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [418] [Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning](https://arxiv.org/abs/2507.08730)
> *在线配置性能学习中的双层分级漂移适应*

*Zezhen Xiang, Jingzhi Gong, Tao Chen* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 配置性能学习, 概念漂移, 在线学习, 双层分级适应, 动态环境

**Comment:** Accepted by ICSE 2026

> **TL;DR:** DHDA是一种在线配置性能学习框架，通过双层分级适应来有效处理动态环境中全局和局部概念漂移，显著提高了性能学习的准确性和适应性。

**AI_Comments:** DHDA的创新之处在于其双层分级漂移适应机制，能够同时处理全局和局部概念漂移，这对于动态软件系统在线性能学习至关重要。结合增量更新和周期性再训练的策略也体现了对效率的考量。该方法为在线性能学习提供了一个有效且实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现代可配置软件系统在动态环境中运行，工作负载变化、硬件更改和系统更新不可避免地引入了全局和局部概念漂移，导致现有离线和迁移学习方法难以实时适应这些变化，使配置性能学习面临挑战。

**Method:** 本文提出了DHDA框架，一个旨在捕获和适应不同级别漂移的在线配置性能学习框架。其核心思想是DHDA通过双层分级适应来适应局部和全局漂移：在上层，它重新划分数据到不同分区，并在必要时重新训练每个分区内的局部模型以处理全局漂移。在下层，各分区的局部模型能够异步检测并适应局部漂移。为平衡响应性和效率，DHDA结合了增量更新和周期性完全再训练，以在未检测到漂移时最小化冗余计算。

**Result:** 通过对八个软件系统进行评估并与最先进的方法进行比较，DHDA实现了显著更高的准确性，并且能够有效适应漂移，性能提升高达2倍，同时带来合理的开销，并能改进不同局部模型在处理概念漂移方面的能力。

**Conclusion:** DHDA框架通过其独特的双层分级漂移适应机制，成功解决了在线配置性能学习中遇到的概念漂移问题，显著提升了学习模型的准确性和对动态环境的适应性。

> **ai_Abstract:** 本文提出了DHDA框架，旨在解决动态环境中可配置软件系统在线配置性能学习中的概念漂移问题。DHDA采用双层分级适应机制，在上层处理全局漂移，下层处理局部漂移，并通过结合增量更新和周期性再训练来优化效率。实验结果表明，DHDA在准确性和漂移适应性方面显著优于现有方法，且开销合理。

> **摘要翻译:** 现代可配置软件系统需要学习将配置与性能关联起来的模型。然而，当系统在动态环境中运行时，工作负载变化、硬件更改和系统更新将不可避免地在不同层面引入概念漂移——全局漂移会重塑整个配置空间的性能格局；局部漂移则仅影响该空间的某些子区域。因此，现有的离线和迁移学习方法难以实时适应这些隐式和不可预测的变化，使得配置性能学习充满挑战。为了解决这个问题，我们提出了DHDA，一个旨在捕获和适应不同层面漂移的在线配置性能学习框架。其关键思想是DHDA通过双层分级适应来适应局部和全局漂移：在上层，我们重新将数据划分为不同的分区，并在每个分区内重新训练局部模型，仅在必要时处理全局漂移。在下层，各分区的局部模型可以检测局部漂移并异步地进行自我适应。为了平衡响应性和效率，DHDA结合了增量更新和周期性完全再训练，以在未检测到漂移时最小化冗余计算。通过对八个软件系统进行评估并与最先进的方法进行比较，我们表明DHDA实现了显著更高的准确性，并且能够有效适应漂移，性能提升高达2倍，同时带来合理的开销，并能够改进不同局部模型在处理概念漂移方面的能力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [429] [Evaluating Generated Commit Messages with Large Language Models](https://arxiv.org/abs/2507.10906)
> *使用大型语言模型评估生成的提交消息*

*Qunhong Zeng, Yuxia Zhang, Zexiong Ma, Bo Jiang, Ningyuan Sun, Klaas-Jan Stol, Xingyu Mou, Hui Liu* | **Category: cs.SE** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 提交消息, 评估, 自动化评估, 思维链推理

**Comment:** 

> **TL;DR:** 本研究探讨了使用大型语言模型（LLMs）作为自动化评估器来评估提交消息质量的潜力，并发现结合思维链推理和少量样本演示的LLMs可以达到接近人类水平的评估能力，显著优于传统指标。

**AI_Comments:** 这项研究的创新之处在于提出了使用大型语言模型作为提交消息的自动化评估器，这为传统上依赖人工评估或受限自动化指标的领域提供了一个可扩展且高效的解决方案。其重要性在于，它为软件开发中提高提交消息质量的实践提供了新的工具和方法，有助于更好地文档化和维护代码库。该方法结合了思维链推理和少量样本演示，显示出LLMs在复杂文本评估任务中的强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 提交消息在软件开发中至关重要，但其质量通常不佳。尽管自动化提交消息生成已取得进展，特别是使用大型语言模型（LLMs），但评估生成消息仍然具有挑战性。传统的基于引用的自动化指标（如BLEU、ROUGE-L、METEOR）存在局限性，因为它们假设代码更改与提交消息之间存在一对一映射，导致研究人员不得不依赖资源密集型的人工评估。

**Method:** 本研究通过对各种提示策略和最先进的LLMs进行系统实验，调查了LLMs作为提交消息质量自动化评估器的潜力。具体方法是结合思维链推理和少量样本演示。

**Result:** 研究表明，结合思维链推理和少量样本演示的LLMs能够实现接近人类水平的评估能力。我们基于LLM的评估器显著优于传统指标，同时保持了可接受的重现性、鲁棒性和公平性水平，尽管存在一些固有的可变性。

**Conclusion:** 本研究对使用LLMs进行提交消息评估进行了全面的初步研究，提供了一种可扩展的替代人工评估的方法，并能保持高质量的评估。

> **ai_Abstract:** 本研究探讨了使用大型语言模型（LLMs）作为自动化评估器来解决提交消息质量评估的挑战。鉴于现有自动化指标的局限性和人工评估的资源密集性，研究人员系统地实验了不同的提示策略和LLMs。结果表明，结合思维链推理和少量样本演示的LLMs能够达到接近人类水平的评估熟练度，并且在评估提交消息质量方面显著优于传统的参考基准指标，同时保持了可接受的重现性、鲁棒性和公平性。这项工作为利用LLMs进行高质量、可扩展的提交消息评估提供了一个有前景的替代方案。

> **摘要翻译:** 提交消息在软件开发中至关重要，因为它们用于记录和解释代码更改。然而，在实践中，它们的质量往往不尽如人意，研究表明有很大比例的空消息或不充分的消息。尽管自动化提交消息生成已经取得了显著进展，特别是随着大型语言模型（LLMs）的出现，但生成消息的评估仍然具有挑战性。传统的基于引用的自动化指标，如BLEU、ROUGE-L和METEOR，在评估提交消息质量方面存在显著局限性，因为它们假设代码更改与提交消息之间存在一对一的映射，导致研究人员不得不依赖资源密集型的人工评估。本研究调查了LLMs作为提交消息质量自动化评估器的潜力。通过对各种提示策略和最先进的LLMs进行系统实验，我们证明了结合思维链推理和少量样本演示的LLMs能够达到接近人类水平的评估能力。我们基于LLM的评估器显著优于传统指标，同时保持了可接受的重现性、鲁棒性和公平性水平，尽管存在一些固有的可变性。这项工作对使用LLMs进行提交消息评估进行了全面的初步研究，提供了一种可扩展的替代人工评估的方法，同时保持了高质量的评估。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [466] [Self-Admitted GenAI Usage in Open-Source Software](https://arxiv.org/abs/2507.10422)
> *开源软件中自述的生成式AI使用情况*

*Tao Xiao, Youmei Fan, Fabio Calefato, Christoph Treude, Raula Gaikovina Kula, Hideaki Hata, Sebastian Baltes* | **Category: cs.SE** | **Updated: 2025-07-15**

**Keywords:** 生成式AI, 开源软件, 代码流失, GitHub Copilot, 软件开发

**Comment:** 17 pages, 8 tables, 1 figures, currently under review

> **TL;DR:** 开发者在开源项目中明确记录了生成式AI的使用，并且AI的采用并未普遍增加代码流失，这与普遍看法相悖。

**AI_Comments:** 该论文引入了一个新颖的概念（“自述式GenAI使用”）来定量和定性地研究一个难以追踪的现象。其关于GenAI采用并未普遍增加代码流失的发现挑战了流行的负面叙述，对于理解AI对软件开发的实际影响具有重要意义。混合方法的使用提供了全面的视角。

<details>
  <summary>Details</summary>

**Motivation:** 由于生成式AI（GenAI）工具生成的源代码与手动编写的代码几乎无法区分，导致其在现实世界中的使用及其对开源软件开发的影响知之甚少。

**Method:** 引入了“自述式GenAI使用”的概念，即开发者明确提及使用GenAI工具。分析了超过25万个GitHub存储库，在156个存储库的提交信息、代码注释和项目文档中识别出1,292个此类自述。采用混合方法，基于284个定性编码的提及，得出了一个包含32个任务、10种内容类型和11种与GenAI使用相关的目的的分类法。分析了13份关于GenAI工具的政策和使用指南文件，并进行了一项开发者调查以揭示其背后的道德、法律和实际问题。最后，检查了GenAI采用对151个自述GenAI使用存储库中代码流失的影响。

**Result:** 识别出156个存储库中的1,292个自述式GenAI使用情况。构建了包含32个任务、10种内容类型和11种目的的GenAI使用分类法。发现开发者积极管理GenAI在其项目中的使用方式。发现GenAI采用并未普遍增加代码流失，这与关于GenAI对软件开发影响的流行说法相矛盾。

**Conclusion:** 在AI辅助软件开发的新时代，项目层面的透明度、归属和质量控制实践是必要的。GenAI的采用并未普遍增加代码流失。

> **ai_Abstract:** 本文引入了“自述式GenAI使用”的概念，以研究生成式AI工具在开源软件中的集成和影响。通过分析超过25万个GitHub存储库，作者识别了明确提及GenAI使用的情况，对其目的进行了分类，并调查了相关的政策和开发者关注点。研究表明开发者积极管理GenAI的使用，并且与普遍看法相反，GenAI的采用并未普遍增加代码流失，这强调了透明度和质量控制的必要性。

> **摘要翻译:** 生成式人工智能（GenAI）工具（如GitHub Copilot和ChatGPT）的广泛采用正在改变软件开发。由于生成的源代码与手动编写的代码几乎无法区分，因此它们在现实世界中的使用及其对开源软件开发的影响仍然知之甚少。在本文中，我们引入了自述式GenAI使用概念，即开发人员在软件工件中明确提及使用GenAI工具进行内容创建。我们以这一概念为切入点，研究GenAI工具如何集成到开源软件项目中，分析了超过25万个GitHub存储库的精选样本，在提交信息、代码注释和项目文档中识别出156个存储库中的1,292个此类自述。我们采用混合方法，基于284个定性编码的提及，得出了一个包含32个任务、10种内容类型和11种与GenAI使用相关的目的的分类法。随后，我们分析了13份关于GenAI工具的政策和使用指南文件，并进行了一项开发者调查，以揭示其背后的道德、法律和实际问题。我们的研究结果表明，开发人员积极管理GenAI在其项目中的使用方式，这突显了在AI辅助软件开发新时代中，项目层面的透明度、归属和质量控制实践的必要性。最后，我们检查了GenAI采用对151个自述GenAI使用存储库中代码流失的影响，发现没有普遍增加，这与关于GenAI对软件开发影响的流行说法相矛盾。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [489] [SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks](https://arxiv.org/abs/2507.11059)
> *SWE-MERA：一个用于智能体评估大型语言模型在软件工程任务上表现的动态基准*

*Pavel Adamenko, Mikhail Ivanov, Aidar Valeev, Rodion Levichev, Pavel Zadorozhny, Ivan Lopatin, Dmitry Babayev, Alena Fenogenova, Valentin Malykh* | **Category: cs.SE, cs.AI, cs.CL** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 软件工程, 基准测试, 数据污染, GitHub问题

**Comment:** 

> **TL;DR:** SWE-MERA是一个新的动态基准，用于评估大型语言模型在软件工程任务上的表现，通过自动化收集真实世界的GitHub问题和严格的质量验证，解决了现有数据集（如SWE-bench）中的数据污染问题。

**AI_Comments:** SWE-MERA的创新之处在于其动态更新机制和对数据污染的严格控制，这对于评估大型语言模型在软件工程领域的真实能力至关重要。它通过自动化从真实GitHub问题中收集数据，解决了现有静态基准的局限性，并提高了评估的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有用于评估大型语言模型在软件工程领域表现的基准，特别是广泛使用的SWE-bench数据集，存在严重的数据污染问题（例如解决方案泄露和测试用例不足），导致评估结果不可靠。

**Method:** SWE-MERA是一个动态、持续更新的基准，它通过自动化管道收集真实世界的GitHub问题，并实施严格的质量验证以最小化数据污染风险。目前已收集到约10,000个潜在任务和300个可用样本。使用Aider等编码代理进行模型评估。

**Result:** SWE-MERA在评估最先进模型时显示出强大的区分能力。研究报告了在2024年9月至2025年6月期间收集的任务上，十几个最新大型语言模型的性能表现。

**Conclusion:** SWE-MERA通过解决现有基准的数据污染和局限性问题，提供了一个更可靠且具有更强区分能力的基准，用于评估大型语言模型在软件工程任务上的表现。

> **ai_Abstract:** SWE-MERA是一个针对大型语言模型在软件工程任务评估上的新型动态基准。它旨在解决现有基准（如SWE-bench）中普遍存在的严重数据污染问题，这些问题导致了不准确的模型评估。SWE-MERA通过自动化收集真实的GitHub问题并进行严格的质量验证来构建，以确保数据质量并最大化地降低污染风险。该基准目前包含约10,000个潜在任务和300个样本，并已证明在评估最先进模型时具有强大的区分能力。

> **摘要翻译:** 大型语言模型 (LLM) 在软件工程领域的快速发展揭示了现有基准的关键局限性，特别是广泛使用的 SWE-bench 数据集。最近的研究发现严重的 数据污染问题，例如 SWE-bench 报告 32.67% 的成功补丁涉及直接解决方案泄露，31.08% 的通过是由于测试用例不足。我们引入了 SWE-MERA，一个动态的、持续更新的基准，旨在通过自动化收集真实世界的 GitHub 问题和严格的质量验证来解决这些根本性挑战。我们的方法实现了一个可靠的管道，在确保质量的同时最大程度地降低了污染风险，目前已产生大约 10,000 个潜在任务和 300 个可用样本。使用 Aider 编码代理的评估表明，它在最先进的模型中具有强大的区分能力。我们报告了在 2024 年 9 月至 2025 年 6 月期间收集的任务上评估的十几个最新 LLM 的性能。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [557] [MT4DP: Data Poisoning Attack Detection for DL-based Code Search Models via Metamorphic Testing](https://arxiv.org/abs/2507.11092)
> *MT4DP：基于蜕变测试的深度学习代码搜索模型数据投毒攻击检测*

*Gong Chen, Wenjie Liu, Xiaoyuan Xie, Xunzhu Tang, Tegawendé F. Bissyandé, Songqiang Chen* | **Category: cs.SE** | **Updated: 2025-07-15**

**Keywords:** 数据投毒攻击, 代码搜索模型, 深度学习, 蜕变测试, 安全

**Comment:** 27 pages

> **TL;DR:** MT4DP通过蜕变测试有效检测深度学习代码搜索模型中的数据投毒攻击，显著提高了检测性能。

**AI_Comments:** MT4DP的创新点在于将蜕变测试引入到深度学习代码搜索模型的数据投毒攻击检测中，特别是提出了语义等价蜕变关系（SE-MR），这为缺乏真实标签的场景提供了有效的检测手段。其在检测性能上的显著提升，尤其是在F1分数和精度方面的表现，突显了该方法在提升DL-based代码搜索模型安全方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明数据投毒攻击对基于深度学习（DL）的代码搜索模型构成严重安全威胁，攻击者注入恶意模式误导模型学习，导致模型在推断时将漏洞代码排名更高。然而，现有针对DL-based代码搜索模型数据投毒攻击的检测方法效果不足。

**Method:** 本文提出了MT4DP，一个通过蜕变测试的DL-based代码搜索模型数据投毒攻击检测框架。MT4DP引入了一种新颖的语义等价蜕变关系（SE-MR），旨在检测数据投毒攻击。具体步骤包括：1) 从搜索查询中识别高频词作为潜在投毒目标，并将其相应查询作为源查询；2) 为每个源查询生成两个语义等价的后续查询，并检索其源排名列表；3) 根据代码片段与后续查询之间的语义相似性，对源排名列表进行重新排序；4) 计算源列表和重新排序列表之间的差异，以揭示SE-MR的违反并警告数据投毒攻击。

**Result:** 实验结果表明，MT4DP显著增强了对DL-based代码搜索模型数据投毒攻击的检测能力，平均F1分数比最佳基线高191%，平均精度高265%。

**Conclusion:** MT4DP框架有效检测了DL-based代码搜索模型中的数据投毒攻击，旨在促进进一步研究以缓解此类威胁。

> **ai_Abstract:** 本文提出了MT4DP，一个基于蜕变测试的深度学习代码搜索模型数据投毒攻击检测框架。针对现有方法在检测DL-based代码搜索模型数据投毒攻击方面效果不足的问题，MT4DP引入了新颖的语义等价蜕变关系（SE-MR）。该方法通过识别潜在投毒目标、生成语义等价的后续查询、并比较源排名列表与重新排序列表的差异来检测攻击。实验结果表明，MT4DP在检测性能上显著优于现有基线。

> **摘要翻译:** 最近，多项研究表明数据投毒攻击对基于深度学习（DL）的代码搜索模型构成严重安全威胁。攻击者将精心制作的恶意模式注入训练数据中，误导代码搜索模型在训练期间学习这些模式。在中毒的代码搜索模型用于推理时，一旦触发恶意模式，模型倾向于将漏洞代码排名更高。然而，现有针对DL-based代码搜索模型数据投毒攻击的检测方法效果不足。为了解决这一关键安全问题，我们提出了MT4DP，一个通过蜕变测试的DL-based代码搜索模型数据投毒攻击检测框架。MT4DP引入了一种新颖的语义等价蜕变关系（SE-MR），旨在检测DL-based代码搜索模型上的数据投毒攻击。具体来说，MT4DP首先从搜索查询中识别高频词作为潜在投毒目标，并将其相应的查询作为源查询。对于每个源查询，MT4DP生成两个语义等价的后续查询，并检索其源排名列表。然后，根据其代码片段与后续查询之间的语义相似性，对每个源排名列表进行重新排序。最后，计算源列表和重新排序列表之间的差异，以揭示SE-MR的违反并警告数据投毒攻击。实验结果表明，MT4DP显著增强了对DL-based代码搜索模型数据投毒攻击的检测能力，平均F1分数比最佳基线高191%，平均精度高265%。我们的工作旨在促进进一步研究有效技术，以缓解DL-based代码搜索模型上的数据投毒威胁。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [626] [$\texttt{Droid}$: A Resource Suite for AI-Generated Code Detection](https://arxiv.org/abs/2507.10583)
> *Droid: 一套用于检测AI生成代码的资源套件*

*Daniil Orel, Indraneil Paul, Iryna Gurevych, Preslav Nakov* | **Category: cs.SE, cs.AI, cs.CY** | **Updated: 2025-07-11**

**Keywords:** AI生成代码检测, DroidCollection, DroidDetect, 对抗性样本, 泛化性

**Comment:** 

> **TL;DR:** 本文介绍了DroidCollection，一个用于检测AI生成代码的大型数据集，以及DroidDetect，一套新的检测器。研究表明，现有检测器泛化能力差且易受对抗性攻击，但通过对抗性数据训练可以解决此问题。

**AI_Comments:** 本文通过提供一个大型、多样化且公开可用的AI生成代码检测数据集（DroidCollection），为该领域的研究做出了重要贡献。DroidDetect的开发以及对现有检测器漏洞的深入分析和提出的解决方案（如对抗性训练）对于开发更鲁棒和泛化能力更强的检测系统具有极高价值。数据集中包含对抗性样本以及证明其在提高检测器鲁棒性方面的有效性，尤其具有创新性。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器生成代码检测器缺乏多样化的训练数据，导致其在不同编码领域和语言上泛化能力不足。此外，它们也容易受到对抗性攻击。

**Method:** 1. 编译了DroidCollection，一个包含超过一百万个代码样本、七种编程语言、来自43个编码模型的输出以及三个真实世界编码领域的开放数据套件，其中包含AI生成、人机协作和对抗性样本。2. 开发了DroidDetect，一套使用多任务目标在DroidCollection上训练的仅编码器检测器。3. 实验证明了现有检测器的泛化失败和对抗性漏洞。4. 证明了通过少量对抗性数据训练可以弥补检测器对“人性化”输出分布的脆弱性。5. 应用度量学习和基于不确定性的重采样来增强在嘈杂分布上的检测器训练。

**Result:** 1. 现有检测器性能无法泛化到其狭窄训练数据之外的不同编码领域和编程语言。2. 大多数检测器容易通过使用表面提示和对齐方法来“人性化”输出分布而被轻易攻破。3. 通过少量对抗性数据进行训练可以轻松弥补这个问题。4. 度量学习和基于不确定性的重采样可以增强在可能嘈杂的分布上检测器的训练。

**Conclusion:** 本文介绍了一个用于AI生成代码的综合数据集（DroidCollection）和一个强大的检测器套件（DroidDetect）。它强调了当前检测器的泛化问题和对抗性漏洞，并提出了通过对抗性数据训练和使用先进训练技术（如度量学习、基于不确定性的重采样）来提高性能和鲁棒性的解决方案。

> **ai_Abstract:** 本文介绍了DroidCollection，一个用于训练和评估AI生成代码检测器的庞大数据集，涵盖了多种语言和领域，包括人机协作和对抗性样本。同时，它提出了DroidDetect，一套基于该数据集训练的仅编码器检测器。实验表明，现有检测器在泛化方面存在困难且易受对抗性攻击，但通过对抗性数据训练能显著提高鲁棒性。此外，研究还展示了度量学习和基于不确定性的重采样在提升嘈杂数据上检测器训练的有效性。

> **摘要翻译:** 在这项工作中，我们编译了 DroidCollection，这是用于训练和评估机器生成代码检测器的最广泛的开放数据套件，包含超过一百万个代码样本、七种编程语言、来自43个编码模型的输出以及超过三个真实世界的编码领域。除了完全由AI生成的样本外，我们的集合还包括人机协作编写的代码以及专门为逃避检测而精心制作的对抗性样本。随后，我们开发了 DroidDetect，这是一套使用多任务目标在 DroidCollection 上训练的仅编码器检测器。我们的实验表明，现有检测器的性能无法泛化到其狭窄训练数据之外的不同编码领域和编程语言。此外，我们证明了虽然大多数检测器很容易通过使用表面提示和对齐方法来“人性化”输出分布而被轻易攻破，但通过少量对抗性数据进行训练可以轻松弥补这个问题。最后，我们展示了度量学习和基于不确定性的重采样作为在可能嘈杂的分布上增强检测器训练的有效手段。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [627] [Automata Models for Effective Bug Description](https://arxiv.org/abs/2507.11146)
> *用于有效错误描述的自动机模型*

*Tom Yaacov, Gera Weiss, Gal Amram, Avi Hayoun* | **Category: cs.SE** | **Updated: 2025-07-15**

**Keywords:** 自动机学习, 错误描述, 故障解释, 早期检测, 调试

**Comment:** Accepted to the ACM/IEEE 28th International Conference on Model
  Driven Engineering Languages and Systems (MODELS 2025)

> **TL;DR:** 本文提出使用自动机学习和测试技术来获取简洁且信息丰富的错误描述，通过引入故障解释、最终故障解释和早期检测等概念，旨在提高错误检测和理解。

**AI_Comments:** 本文的创新点在于将自动机学习和测试技术应用于错误描述，并引入了FE、EFE和ED等新概念，这对于提高复杂系统调试效率具有重要意义。该方法通过关注核心故障模式，有效减少了冗余信息，提升了错误描述的质量和可用性。

<details>
  <summary>Details</summary>

**Motivation:** 调试复杂系统是一项关键但耗时的工作，因此需要一种方法来获得简洁且信息丰富的错误描述，以增强错误检测和理解。

**Method:** 本文引入了故障解释（FE）、最终故障解释（EFE）和早期检测（ED）的概念，利用自动机学习和测试技术来提供有意义的故障行为模式摘要，并通过排除不相关信息并关注基本测试模式。

**Result:** 该方法通过使用各种测试模式和真实世界基准进行评估，证明了其在生成紧凑且信息丰富的错误描述方面的有效性。

**Conclusion:** 本文提出的自动机模型和相关概念能够有效地生成简洁且信息丰富的错误描述，从而提高复杂系统的错误检测和理解能力。

> **ai_Abstract:** 本文提出了一种利用自动机学习和测试技术来生成简洁且信息丰富的错误描述的方法。通过引入故障解释（FE）、最终故障解释（EFE）和早期检测（ED）等概念，该方法能够有效地总结故障行为模式，并排除无关信息，从而提高错误检测和理解。实验证明，该方法在生成紧凑且有用的错误描述方面表现出色。

> **摘要翻译:** 调试复杂系统是一项关键但耗时的工作。本文介绍了自动机学习和测试技术的使用，以获得简洁且信息丰富的错误描述。我们引入了故障解释（FE）、最终故障解释（EFE）和早期检测（ED）的概念，以提供有意义的故障行为模式摘要。通过排除不相关信息并关注基本测试模式，我们的方法旨在增强错误检测和理解。我们使用各种测试模式和真实世界基准评估了我们的方法，证明了它们在生成紧凑且信息丰富的错误描述方面的有效性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [682] [ARPaCCino: An Agentic-RAG for Policy as Code Compliance](https://arxiv.org/abs/2507.10584)
> *ARPaCCino: 一种用于策略即代码合规性的智能体-RAG系统*

*Francesco Romeo, Luigi Arena, Francesco Blefari, Francesco Aurelio Pironti, Matteo Lupinacci, Angelo Furfaro* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 策略即代码, 智能体系统, LLM, RAG, IaC合规性

**Comment:** 

> **TL;DR:** ARPaCCino是一个结合了LLM、RAG和工具验证的智能体系统，旨在自动化生成和验证策略即代码规则，以解决策略语言复杂性和配置错误问题，并已在Terraform案例研究中证明其有效性。

**AI_Comments:** 该论文提出了一种结合LLM、RAG和工具验证的创新智能体系统ARPaCCino，有效解决了策略即代码（PaC）在自动化生成和验证方面的挑战。其模块化架构和对小众IaC框架的支持是其重要创新点，大大提升了PaC工作流的自动化、可靠性和可访问性。通过实验验证了其在Terraform案例中的有效性，证明了该方法在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 策略即代码（PaC）的采用受到策略语言复杂性和配置错误风险的阻碍。

**Method:** 本文提出了ARPaCCino，一个结合了大型语言模型（LLMs）、检索增强生成（RAG）和基于工具的验证的智能体系统。它接收自然语言策略描述，生成正式的Rego规则，评估IaC合规性，并迭代地精炼IaC配置以确保一致性。其模块化智能体架构和与外部工具及知识库的集成使其能够支持广泛技术的策略验证。

**Result:** 实验评估（包括基于Terraform的案例研究）表明，ARPaCCino在生成语法和语义正确的策略、识别不合规基础设施以及应用纠正修改方面是有效的，即使使用较小的、开放权重的LLM。结果强调了智能体RAG架构增强PaC工作流自动化、可靠性和可访问性的潜力。

**Conclusion:** 智能体RAG架构具有增强策略即代码（PaC）工作流自动化、可靠性和可访问性的潜力。

> **ai_Abstract:** ARPaCCino是一个创新的智能体系统，旨在解决策略即代码（PaC）在基础设施即代码（IaC）环境中采用时面临的复杂性和配置错误问题。它通过结合大型语言模型（LLM）、检索增强生成（RAG）和工具验证，自动化PaC规则的生成、IaC合规性评估及配置迭代精炼。该系统能够将自然语言描述转化为正式的Rego规则，并支持多种IaC框架的策略验证。实验证明，即使使用小型LLM，ARPaCCino也能有效生成正确策略、识别不合规项并进行纠正，显示了智能体RAG架构在提升PaC自动化、可靠性和可访问性方面的巨大潜力。

> **摘要翻译:** 策略即代码（PaC）是一种将安全和合规策略编码成机器可读格式的范式，从而在基础设施即代码（IaC）环境中实现自动化执行。然而，其采用受到策略语言复杂性和配置错误风险的阻碍。在这项工作中，我们提出了ARPaCCino，一个结合了大型语言模型（LLMs）、检索增强生成（RAG）和基于工具的验证的智能体系统，旨在自动化PaC规则的生成和验证。给定所需策略的自然语言描述，ARPaCCino生成正式的Rego规则，评估IaC合规性，并迭代地精炼IaC配置以确保一致性。由于其模块化的智能体架构以及与外部工具和知识库的集成，ARPaCCino支持跨广泛技术（包括小众或新兴IaC框架）的策略验证。涉及基于Terraform的案例研究的实验评估证明了ARPaCCino在生成语法和语义正确的策略、识别不合规基础设施以及应用纠正修改方面的有效性，即使在使用较小的、开放权重的LLM时也是如此。我们的结果强调了智能体RAG架构增强PaC工作流自动化、可靠性和可访问性的潜力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [697] [New Formulation of DNN Statistical Mutation Killing for Ensuring Monotonicity: A Technical Report](https://arxiv.org/abs/2507.11199)
> *确保单调性的DNN统计变异杀伤新公式：一份技术报告*

*Jinhan Kim, Nargiz Humbatova, Gunel Jahangirova, Shin Yoo, Paolo Tonella* | **Category: cs.SE** | **Updated: 2025-07-15**

**Keywords:** 变异测试, 深度神经网络, 单调性, 统计变异杀伤, Fisher精确检验

**Comment:** 

> **TL;DR:** 提出一种基于费舍尔精确检验的DNN统计变异杀伤新公式，解决了DeepCrime的单调性违背问题，同时保持统计严谨性。

**AI_Comments:** 本文的创新点在于提出了一个确保单调性的统计变异杀伤新公式，解决了现有DeepCrime方法的一个关键局限性。这对于提高DNN测试套件评估的稳定性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度神经网络（DNN）测试套件有效性评估技术DeepCrime的统计变异杀伤准则存在一个关键限制：它违反了单调性属性，即扩展测试集可能导致先前被杀死的变异体不再被分类为已杀死。

**Method:** 提出了一种基于Fisher精确检验的统计变异杀伤新公式。

**Result:** 新公式在保持统计严谨性的同时，确保了单调性。

**Conclusion:** 本技术报告提出了一种基于Fisher精确检验的统计变异杀伤新公式，解决了现有方法中的单调性问题。

> **ai_Abstract:** 本技术报告针对深度神经网络（DNN）测试中DeepCrime统计变异杀伤准则违反单调性问题，提出了一种基于Fisher精确检验的新公式。该新公式旨在解决现有方法中扩展测试集可能导致已杀死变异体不再被分类为杀死的问题，同时保持统计学的严谨性。

> **摘要翻译:** 变异测试已成为评估深度神经网络（DNN）测试套件有效性的强大技术。在现有方法中，DeepCrime的统计变异杀伤准则利用统计测试来确定变异体是否与原始模型显著不同。然而，它存在一个关键限制：它违反了单调性属性，这意味着扩展测试集可能导致先前被杀死的变异体不再被分类为已杀死。在这份技术报告中，我们提出了一种基于费舍尔精确检验的统计变异杀伤新公式，该公式在保持其统计严谨性的同时，确保了单调性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [731] [Repairing Language Model Pipelines by Meta Self-Refining Competing Constraints at Runtime](https://arxiv.org/abs/2507.10590)
> *在运行时通过元自修正竞争约束修复语言模型管道*

*Mojtaba Eshghie* | **Category: cs.SE, cs.AI, cs.IR** | **Updated: 2025-07-11**

**Keywords:** 语言模型, 约束竞争, 自修正, 运行时修复, 回溯循环

**Comment:** 

> **TL;DR:** 语言模型（LM）管道在处理竞争约束时会陷入低效循环。Meta Self-Refining框架引入一个元修正层，在运行时检测并修复这些循环，通过生成战略指令来平衡约束，从而提高LM程序的效率。

**AI_Comments:** 这项工作通过引入一个元修正层来处理语言模型管道中常见的竞争约束问题，具有创新性。它提供了一种在运行时动态修复LM行为的机制，有助于提高LM在复杂任务中的鲁棒性和效率。这种自适应修复方法对于构建更可靠的AI系统至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型（LM）管道在面对相互竞争的软约束时，其有效性会崩溃，导致效率低下的回溯循环，即满足一个约束会违反另一个。

**Method:** 本文引入了Meta Self-Refining框架，为LM管道配备一个元修正层。该方法通过监控管道的执行历史来检测振荡性故障。一旦检测到，它会调用一个元修复器LM来分析回溯尝试的整体状态，并综合出战略性指令以平衡相互竞争的需求。这些自修复指令引导原始LM摆脱失败的精修循环，走向成功的输出。

**Result:** Meta Self-Refining框架能够成功修复这些回溯循环，从而使语言模型程序更加高效。

**Conclusion:** Meta Self-Refining框架能够有效地在运行时解决语言模型管道中竞争约束导致的问题，显著提高了LM程序的效率。

> **ai_Abstract:** 本论文提出了Meta Self-Refining框架，旨在解决语言模型（LM）管道在处理相互竞争的软约束时效率低下及陷入回溯循环的问题。该框架通过一个元修正层，在运行时监控管道执行，检测振荡性故障。一旦发现，一个元修复器LM会分析回溯状态并生成战略性指令，以平衡冲突的约束，从而引导LM管道成功输出，显著提高了LM程序的效率。

> **摘要翻译:** 语言模型（LM）管道可以根据程序约束动态地优化其输出。然而，当面临相互竞争的软约束时，它们的有效性会崩溃，导致效率低下的回溯循环，其中满足一个约束会违反另一个。我们引入了元自修正（Meta Self-Refining），这是一个为LM管道配备元修正层的框架，用于在运行时/推理时修复这些竞争。我们的方法监控管道的执行历史，以检测振荡性故障。一旦检测到，它会调用一个元修复器LM，该LM分析回溯尝试的整体状态，并综合出战略性指令以平衡相互竞争的需求。这种自修复指令引导原始LM摆脱失败的精修循环，走向成功的输出。我们的结果表明，元自修正可以成功修复这些循环，从而使LM程序更高效。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [767] [An Empirical Study of Multi-Agent RAG for Real-World University Admissions Counseling](https://arxiv.org/abs/2507.11272)
> *多智能体RAG在真实世界大学招生咨询中的实证研究*

*Anh Nguyen-Duc, Chien Vu Manh, Bao Anh Tran, Viet Phuong Ngo, Luan Le Chi, Anh Quang Nguyen* | **Category: cs.SE** | **Updated: 2025-07-15**

**Keywords:** 多智能体RAG, 大学招生咨询, 会话式AI, 真实世界部署, LLMs

**Comment:** 

> **TL;DR:** 本文介绍了MARAUS，一个用于越南大学招生咨询的真实世界多智能体检索增强型对话AI平台。它通过结合混合检索、多智能体编排和LLM生成，在真实世界中取得了显著的性能提升（92%准确率，幻觉率降低，响应时间快，成本低），为低资源教育环境中的智能体RAG系统部署提供了可行性见解。

**AI_Comments:** 本文的创新之处在于其对多智能体RAG系统在真实世界、低资源教育环境中的成功部署和实证评估。它不仅展示了多智能体RAG在提高LLM准确性和可靠性方面的潜力，还提供了具体的性能指标和成本效益分析，这对于实际应用具有重要指导意义。特别是系统在处理大量真实用户交互时所表现出的高准确率和低幻觉率，验证了其在解决实际咨询痛点方面的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在自动化咨询任务方面具有潜力，但大多数现有解决方案仍局限于原型或合成基准测试。本文旨在通过开发一个适合真实世界大学招生的系统来弥补这一空白。

**Method:** 本文提出了MARAUS（多智能体和检索增强型大学招生系统），一个结合了混合检索、多智能体编排和基于LLM的生成的对话式AI平台。该系统与河内交通技术大学（UTT）合作进行了两阶段研究，包括技术开发和真实世界评估。MARAUS处理了超过6,000次实际用户交互，涵盖六类查询。

**Result:** MARAUS在真实世界部署中表现出色：平均准确率达到92%，幻觉率从15%显著降低至1.45%，平均响应时间低于4秒。此外，该系统运营成本效益高，使用GPT-4o mini的两周部署成本为11.58美元。

**Conclusion:** 这项工作为在低资源教育环境中部署智能体RAG系统提供了可操作的见解。

> **ai_Abstract:** 本研究介绍了MARAUS，一个专门为越南大学招生咨询设计的真实世界多智能体检索增强型对话AI系统。该系统通过整合混合检索、多智能体编排和LLM生成，有效解决了现有LLM解决方案在实际应用中的局限性。通过与河内交通技术大学的合作，MARAUS在处理超过6,000次真实用户交互后，展现出92%的平均准确率、显著降低的幻觉率（从15%降至1.45%）、低于4秒的平均响应时间以及极低的运营成本。这项工作为在资源有限的教育环境中部署智能体RAG系统提供了宝贵的实践经验。

> **摘要翻译:** 本文介绍了MARAUS（多智能体和检索增强型大学招生系统），一个在越南用于高等教育招生咨询的真实世界对话式AI平台。尽管大型语言模型（LLMs）在自动化咨询任务方面具有潜力，但大多数现有解决方案仍局限于原型或合成基准测试。MARAUS通过将混合检索、多智能体编排和基于LLM的生成结合到一个为真实世界大学招生量身定制的系统中，弥补了这一空白。我们与河内交通技术大学（UTT）合作，进行了一项包括技术开发和真实世界评估在内的两阶段研究。MARAUS处理了超过6,000次实际用户交互，涵盖六类查询。结果显示，与仅使用LLM的基线相比，系统性能显著提升：平均准确率达到92%，幻觉率从15%降低至1.45%，平均响应时间低于4秒。该系统运营成本效益高，使用GPT-4o mini的两周部署成本为11.58美元。这项工作为在低资源教育环境中部署智能体RAG系统提供了可操作的见解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [787] [ToolRegistry: A Protocol-Agnostic Tool Management Library for Function-Calling LLMs](https://arxiv.org/abs/2507.10593)
> *ToolRegistry: 一个面向函数调用型大型语言模型的协议无关工具管理库*

*Peng Ding* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-11**

**Keywords:** LLM, 工具管理, 函数调用, 协议无关, ToolRegistry

**Comment:** 

> **TL;DR:** ToolRegistry是一个协议无关的工具管理库，旨在简化LLM应用中外部工具的集成，解决了现有方法的碎片化、协议限制和实现复杂性问题，显著减少了集成代码，提高了性能和开发效率。

**AI_Comments:** ToolRegistry的创新之处在于其协议无关的设计和统一的工具管理接口，这极大地简化了LLM的工具集成过程。其重要性体现在有效解决了当前LLM应用开发中的痛点，显著降低了开发成本并提升了系统性能。作为开源项目，它有望被广泛采纳并促进LLM生态系统的发展。

<details>
  <summary>Details</summary>

**Motivation:** 当前LLM应用中工具集成方法存在碎片化、协议限制和实现复杂性，导致开发开销大。

**Method:** 本文提出了ToolRegistry，一个协议无关的工具管理库，通过统一接口简化了工具的注册、表示、执行和生命周期管理。

**Result:** ToolRegistry将工具集成代码减少了60-80%，通过并发执行实现了高达3.1倍的性能提升，并与OpenAI函数调用标准100%兼容。实际案例研究表明，在各种集成场景中，开发效率和代码可维护性显著提高。

**Conclusion:** ToolRegistry通过提供一个统一、协议无关的工具管理方案，显著简化了LLM的工具集成，提高了开发效率、代码可维护性和性能。

> **ai_Abstract:** ToolRegistry是一个开源的协议无关工具管理库，旨在解决大型语言模型（LLM）应用中集成外部工具时面临的碎片化、协议限制和复杂性问题。它通过统一接口简化了工具的注册、表示、执行和生命周期管理。评估结果显示，ToolRegistry能将工具集成代码减少60-80%，通过并发执行将性能提升高达3.1倍，并与OpenAI函数调用标准完全兼容，显著提升了开发效率和代码可维护性。

> **摘要翻译:** 大型语言模型（LLM）应用正日益依赖外部工具来扩展其超越文本生成的能力。然而，当前的工具集成方法存在碎片化、协议限制和实现复杂性等问题，导致大量的开发开销。本文提出了ToolRegistry，一个协议无关的工具管理库，通过统一接口简化了工具的注册、表示、执行和生命周期管理。我们的评估表明，ToolRegistry将工具集成代码减少了60-80%，通过并发执行实现了高达3.1倍的性能提升，并与OpenAI函数调用标准100%兼容。实际案例研究表明，在各种集成场景中，开发效率和代码可维护性显著提高。ToolRegistry是开源的，可在https://github.com/Oaklight/ToolRegistry获取，并提供https://toolregistry.readthedocs.io/的完整文档。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [31] [Multilayer Artificial Benchmark for Community Detection (mABCD)](https://arxiv.org/abs/2507.10795)
> *多层人工社区检测基准 (mABCD)*

*Łukasz Kraiński, Michał Czuba, Piotr Bródka, Paweł Prałat, Bogumił Kamiński, François Théberge* | **Category: cs.SI, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 多层网络, 社区检测, 人工基准, ABCD模型, mABCD

**Comment:** 28 pages, 15 figures, 7 tables

> **TL;DR:** 本文引入了一种新的多层网络社区检测基准模型mABCD，它是基于ABCD模型的变体，适用于多层网络。

**AI_Comments:** 本文的创新点在于将现有的ABCD模型（一个已被证明优于LFR模型的基准）扩展到更复杂的多层网络领域。mABCD有望为多层网络的社区检测算法提供一个更快速、更可解释且可分析的评估工具，填补了该领域的一个空白。

<details>
  <summary>Details</summary>

**Motivation:** 为了应对多层网络的复杂性，需要一个适用于多层网络的社区检测基准模型。现有的ABCD模型适用于单层网络，因此需要将其扩展到多层网络。

**Method:** 本文利用人工社区检测基准 (ABCD) 模型的基本要素，引入了其针对多层网络的变体mABCD。

**Result:** 本文成功引入了mABCD，一个基于ABCD模型的、用于多层网络的社区检测人工基准模型。

**Conclusion:** 本文成功将ABCD模型扩展到多层网络领域，提出了mABCD模型，为多层网络的社区检测提供了一个新的可解释且可分析的基准。

> **ai_Abstract:** 本文介绍了mABCD模型，它是人工社区检测基准 (ABCD) 模型在多层网络领域的扩展。ABCD模型是一种随机图模型，特点是具有社区结构和幂律分布，并且相比LFR模型具有速度快、可解释性强和可分析性等优点。mABCD继承了这些特性，旨在为多层网络的社区检测提供一个新的、有力的基准。

> **摘要翻译:** 人工社区检测基准 (ABCD) 模型是一种随机图模型，具有社区结构，度分布和社区大小分布均服从幂律。该模型生成的图与著名的LFR模型相似，但速度更快、更具可解释性，并且可以进行分析研究。在本文中，我们利用ABCD模型的基本要素，引入了其针对多层网络的变体mABCD。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [85] [Toxicity in State Sponsored Information Operations](https://arxiv.org/abs/2507.10936)
> *国家资助信息行动中的毒性*

*Ashfaq Ali Shafin, Khandaker Mamun Ahmed* | **Category: cs.SI** | **Updated: 2025-07-15**

**Keywords:** 国家资助信息行动, 毒性语言, 社交媒体, 影响力行动, X/Twitter

**Comment:** Accepted at 36th ACM Conference on Hypertext and Social Media (HT
  '25), September 15-18, 2025, Chicago, IL. 4 pages, 3 figures, 1 table

> **TL;DR:** 本研究首次全面分析了国家资助信息行动中的毒性语言部署，发现尽管毒性内容占比小（1.53%），但其能带来不成比例的高互动，并被策略性部署，尤其俄罗斯相关行动的毒性内容互动率显著更高。

**AI_Comments:** 这篇论文创新性地量化分析了国家资助信息行动中的毒性语言，揭示了其在低占比下却能产生高影响力的现象。其对不同国家来源毒性内容的比较，特别是对俄罗斯相关行动的发现，具有重要的现实意义。研究方法严谨，使用了大规模数据集和专业的API工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有科学文献对国家资助信息行动的情感和修辞策略，特别是其中毒性语言的部署，表征不足。

**Method:** 本研究对X/Twitter上与18个不同地缘政治实体相关的4.2万多个账户发布的5600万条帖子进行了全面分析。使用Google的Perspective API系统性地检测并量化了六类毒性内容，并分析了它们在国家来源、语言结构和互动指标上的分布。

**Result:** 毒性内容仅占所有帖子的1.53%，但其与不成比例的高互动相关，并似乎在特定的地缘政治背景下被策略性部署。源自俄罗斯影响力行动的毒性内容比数据集中任何其他国家的影响力行动获得了显著更高的用户互动。

**Conclusion:** 国家资助信息行动中的毒性内容尽管占比小，但其高互动率表明其具有重要的战略价值，尤其在特定国家的影响力行动中。

> **ai_Abstract:** 本研究首次全面分析了国家资助信息行动中毒性语言的使用情况，通过检查X/Twitter上5600万条帖子发现，毒性内容虽然占比极小（1.53%），但能带来不成比例的高互动率，并被策略性地部署在特定地缘政治背景下，其中俄罗斯相关行动的毒性内容互动效果尤为显著。

> **摘要翻译:** 国家资助的信息行动（IOs）日益影响社交媒体平台上的全球话语，但其情感和修辞策略在科学文献中仍未得到充分表征。本研究首次对此类行动中毒性语言的部署进行了全面分析，检查了X/Twitter上与18个不同地缘政治实体相关的4.2万多个账户发布的5600万条帖子。我们使用Google的Perspective API系统地检测和量化了六类毒性内容，并分析了它们在国家来源、语言结构和参与度指标上的分布，为这类行动的潜在模式提供了重要信息。我们的研究结果显示，尽管毒性内容仅占所有帖子的1.53%，但它们与不成比例的高参与度相关，并且似乎在特定的地缘政治背景下被策略性部署。值得注意的是，源自俄罗斯影响力行动的毒性内容比我们数据集中任何其他国家的影响力行动获得了显著更高的用户参与度。我们的代码可在https://github.com/shafin191/Toxic_IO获取。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [137] [Urban delineation through the lens of commute networks: Leveraging graph embeddings to distinguish socioeconomic groups in cities](https://arxiv.org/abs/2507.11057)
> *通过通勤网络视角划分城市：利用图嵌入区分城市中的社会经济群体*

*Devashish Khulbe, Stanislav Sobolevsky* | **Category: cs.SI, stat.ML** | **Updated: 2025-07-15**

**Keywords:** 城市划分, 通勤网络, 图神经网络, 社会经济群体, 社区检测

**Comment:** 

> **TL;DR:** 本研究提出使用基于人口普查的通勤网络和图神经网络（GNN）来划分城市区域，并通过节点嵌入聚类识别具有社会经济差异的社区，在全美范围内的实验验证了该方法的有效性。

**AI_Comments:** 该论文创新性地将通勤网络和图神经网络结合，用于城市区域划分和识别社会经济群体，提供了一种有别于传统方法的视角。其重要性在于能够更精细地捕捉城市内部的社会经济结构，为城市规划和政策制定提供更精准的数据支持。该方法利用了人口普查数据，具有较强的实用性和可推广性。

<details>
  <summary>Details</summary>

**Motivation:** 城市区域划分是城市研究的重要焦点，有助于比较不同区域和行政区划，并为政策制定者提供经济和劳动力景观变化的信息。本研究旨在利用通勤网络来有效划分城市区域，并揭示其背后的社会经济差异。

**Method:** 本研究提出使用源自人口普查的通勤网络进行城市划分，通过图神经网络（GNN）对其进行建模。GNN用于生成细粒度城市区域（节点）的低维表示。随后，对节点嵌入进行聚类，以识别城市中空间上凝聚的社区。

**Result:** 在美国各地的实验表明，网络嵌入能够有效捕捉不同城市社区之间显著的社会经济差异，特别是在家庭收入中位数等因素上。研究还指出人口普查流动性数据在区域划分中的作用，并确立了GNN在城市社区检测中的实用性，作为现有方法的强大替代方案。

**Conclusion:** 本研究成功地将通勤网络与图神经网络结合应用于城市区域划分和社区检测，证明了该方法在揭示城市社会经济差异方面的有效性，并为理解通勤网络对城市区域的更广泛影响提供了见解。

> **ai_Abstract:** 本研究提出了一种利用人口普查通勤网络和图神经网络（GNN）进行城市区域划分的新方法。通过GNN生成城市区域的低维嵌入，并对这些嵌入进行聚类以识别空间凝聚的社区。在美国的实验表明，该方法能有效揭示社区间的显著社会经济差异，特别是家庭收入方面。研究强调了通勤数据和GNN在城市社区检测中的强大作用。

> **摘要翻译:** 在都市区域内划分区域是城市研究人员的一个重要关注点，它揭示了由不断演变的人口动态所塑造的城市边界。在城市科学中的应用众多，从促进划定区域与行政区划之间的比较，到向政策制定者提供经济和劳动力景观变化的最新信息。在本研究中，我们提出利用源自人口普查的通勤网络进行城市划分，通过使用图神经网络（GNN）架构对其进行建模。我们使用GNNs获取细粒度城市区域（节点）的低维表示。随后，对节点的嵌入进行聚类，以识别城市中空间上凝聚的社区。我们在美国各地的实验表明，网络嵌入能够有效捕捉不同城市中社区之间显著的社会经济差异，特别是在家庭收入中位数等因素上。人口普查流动性数据在区域划分中的作用也得到了关注，并且我们确立了GNN在城市社区检测中的实用性，作为该领域现有方法的强大替代方案。结果为通勤网络的更广泛影响及其在构建有意义的城市区域表示中的应用提供了见解。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [182] [Enhance Stability of Network by Edge Anchor](https://arxiv.org/abs/2507.11090)
> *通过边缘锚点增强网络稳定性*

*Hongbo Qiu, Renjie Sun, Chen chen, Xiaoyang Wang* | **Category: cs.SI** | **Updated: 2025-07-15**

**Keywords:** 网络稳定性, 边缘锚点, 桁架增强, 贪婪算法, 在线社交网络

**Comment:** 

> **TL;DR:** 本研究引入并探讨了锚点桁架增强问题，通过锚定部分边缘来增强网络的整体用户参与度。为解决该问题的NP-难性，提出了一种贪婪框架，并设计了向上路由方法、支持检查策略和分类树结构，以高效计算和优化边缘选择，并在真实网络上验证了其效率和有效性。

**AI_Comments:** 本文创新性地将“桁架度”概念应用于网络稳定性增强，并提出了“锚点桁架增强问题”。其亮点在于针对NP-难问题设计了一套高效的解决方案，包括贪婪框架、向上路由方法、支持检查策略和分类树结构，这些方法有效提升了在大规模网络上进行边缘锚定计算的效率。该研究对于理解和提升在线社交网络的用户参与度和稳定性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着在线社交网络的快速增长，增强其稳定性已成为一个重要的研究焦点。本研究旨在识别对社区稳定性有显著影响的关系，并通过锚定边缘来增强网络的整体用户参与度。

**Method:** 本研究引入并探索了锚点桁架增强问题，目标是在给定预算下识别b条边缘，使其锚定能够最大化网络中所有边缘的桁架增益。该问题被证明是NP-难的。为解决此问题，论文提出了一个贪婪框架，迭代选择当前最佳边缘。为适应大型网络，首先提出了一个向上路由方法来约束潜在的桁架增量边缘，并结合支持检查策略，以高效计算锚定一条边缘的桁架增益。其次，设计了一个分类树结构，通过根据边缘的桁架度组织它们，以最小化每次迭代中的冗余计算。

**Result:** 在8个真实世界网络上进行了广泛的实验，验证了所提出的模型和方法的效率和有效性。

**Conclusion:** 本研究提出的模型和方法在增强网络稳定性方面表现出高效性和有效性。

> **ai_Abstract:** 本研究关注在线社交网络稳定性问题，提出并解决了“锚点桁架增强问题”。该问题旨在通过锚定少量边缘来最大化网络的桁架增益，从而提升用户参与度。鉴于其NP-难性，论文设计了一个贪婪框架，并引入了向上路由方法、支持检查策略和分类树结构，以高效地计算边缘的桁架增益并优化选择过程。实验结果表明，所提出的模型和方法在真实网络中表现出良好的效率和有效性。

> **摘要翻译:** 随着在线社交网络的快速增长，增强其稳定性已成为一个重要的研究焦点。本研究旨在识别对社区稳定性有显著影响的关系。本文引入并探讨了锚点桁架增强问题，旨在通过锚定一些边缘来增强网络的整体用户参与度。具体而言，对于给定的图G和预算b，我们的目标是识别b条边缘，其锚定能够最大化桁架增益，即G中所有边缘的桁架度累积增量。我们确定了该问题的NP-难性。为解决此问题，我们引入了一个贪婪框架，迭代选择当前最佳边缘。为适应大型网络，我们首先提出了一种向上路由方法来约束潜在的桁架增量边缘。结合支持检查策略，这种方法能够高效计算锚定一条边缘的桁架增益。然后，我们设计了一个分类树结构，通过根据边缘的桁架度组织它们，以最小化每次迭代中的冗余计算。我们在8个真实世界网络上进行了广泛的实验，以验证所提出的模型和方法的效率和有效性。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [375] [Entropy-based models to randomize real-world hypergraphs](https://arxiv.org/abs/2207.12123)
> *基于熵的模型用于随机化真实世界超图*

*Fabio Saracco, Giovanni Petri, Renaud Lambiotte, Tiziano Squartini* | **Category: cs.SI, cond-mat.stat-mech, physics.data-an** | **Updated: 2025-07-15**

**Keywords:** 超图, 熵模型, 指数随机超图, 多体关系, 复杂系统

**Comment:** 47 pages, 14 figures, 3 tables

> **TL;DR:** 本文引入了指数随机超图（ERHs）模型，用于分析真实世界超图中的高阶结构和多体关系，并检测与随机行为的偏差。

**AI_Comments:** 本文的创新之处在于将基于熵的随机图模型推广到超图，从而能够更准确地分析复杂系统中的高阶多体关系。其提出的指数随机超图（ERHs）模型提供了一个可解析且可扩展的框架，对于理解真实世界超图的复杂结构及其与随机行为的偏差具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的网络理论常忽略多体关系，仅关注成对交互，这可能导致对复杂系统的不准确表示。为了更好地描述多体交互，需要一个合适的框架，即超图。

**Method:** 作者基于关联矩阵表示的超图，将基于熵的方法扩展到高阶结构，并引入了指数随机超图（ERHs）。他们探索了阈值的渐近行为，并将其应用于研究真实世界数据。首先，将关键网络指标推广到超图；然后，计算其期望值并与经验值进行比较，以检测与随机行为的偏差。

**Result:** 该方法是可解析、可扩展的，并且能够揭示真实世界超图中与简单约束下出现的结构显著不同的结构模式。

**Conclusion:** 指数随机超图（ERHs）模型提供了一种有效且可解析的方法来分析真实世界超图中的高阶结构，并能识别出超出简单随机行为的复杂模式。

> **ai_Abstract:** 本文提出了一种基于熵的指数随机超图（ERHs）模型，旨在克服传统网络理论忽视多体关系的问题。该模型利用超图的关联矩阵表示，将熵方法推广到高阶结构，并能对真实世界超图进行随机化。通过推广关键网络指标并比较其期望值与经验值，该方法能够检测出与简单随机行为显著不同的结构模式，具有可解析和可扩展的优点。

> **摘要翻译:** 网络理论常常忽视多体关系，只关注成对交互：然而，忽视这些关系可能导致对复杂系统的误导性表示。超图为描述多体交互提供了一个合适的框架。本文利用基于关联矩阵的超图表示，将基于熵的方法扩展到高阶结构：类似于指数随机图，我们引入了指数随机超图（ERHs）。在探索了概括渗流阈值的渐近行为后，我们将ERHs应用于研究真实世界数据。首先，我们将关键网络指标推广到超图；然后，计算它们的期望值并与经验值进行比较，以检测与随机行为的偏差。我们的方法是可解析、可扩展的，并且能够揭示真实世界超图中与简单约束下出现的结构显著不同的结构模式。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [435] [Verified authors shape X/Twitter discursive communities](https://arxiv.org/abs/2405.04896)
> *认证作者塑造X/推特上的话语社区*

*Stefano Guarino, Ayoub Mounim, Guido Caldarelli, Fabio Saracco* | **Category: cs.SI, cs.CY** | **Updated: 2025-07-15**

**Keywords:** 认证用户, 话语社区, X/推特, 社区检测, 政治辩论

**Comment:** 33 pages, 14 figures

> **TL;DR:** 本研究发现，在X/推特上，认证用户在塑造在线政治辩论中的话语社区方面发挥着主导作用，通过利用认证用户可以更清晰地划分社区，并准确反映政治派别。

**AI_Comments:** 该研究创新性地将认证用户的角色纳入社交网络社区检测，并通过新颖的方法（MonoDC和BiDC）有效过滤噪音，提升了社区划分的准确性。其重要性在于揭示了认证状态对在线话语结构和政治派别形成的关键影响，尤其是在社交媒体平台验证机制发生重大变化（如付费验证）的背景下，为平台治理和虚假信息传播提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决在X/推特上检测“话语社区”的挑战，特别关注认证用户作为在线政治辩论中主要内容创作者的角色。

**Method:** 研究提出了两种新颖的方法：MonoDC和BiDC。MonoDC利用用户之间的转发网络，BiDC则基于共享受众的相似性网络。两种方法都整合了最大熵零模型来过滤在线社交网络中的固有噪音。研究将这些方法与应用于整个转发网络的标准社区检测算法进行了比较。

**Result:** 结果表明，利用认证用户（被视为声望和权威的指标）能够产生明显更清晰的社区划分，这些划分与实际政治派别紧密相关，并且优于应用于整个转发网络的标准社区检测算法。此外，不同方法和用户集的比较表明，蓝色认证标记所赋予的地位在塑造在线话语中起着主导作用。

**Conclusion:** 研究结论是，蓝色认证标记所赋予的地位在塑造在线话语中扮演主导角色，这对平台治理具有重要意义，尤其是在付费验证政策转变之后。

> **ai_Abstract:** 本研究探讨了X/推特上认证用户在塑造在线政治话语社区中的作用。通过分析2022年意大利的三个主要政治事件，并提出MonoDC和BiDC两种新方法，研究发现利用认证用户能显著提高社区划分的清晰度和政治派别映射的准确性，且优于传统算法。结果强调了蓝色认证标记在塑造在线讨论中的关键作用，对平台治理具有重要启示。

> **摘要翻译:** 在这项研究中，我们通过关注认证用户作为在线政治辩论中主要内容创作者的角色，解决了在X/推特上检测“话语社区”的挑战。分析集中于2022年意大利发生的三个主要政治事件——总统选举、政府危机和大选——这些事件都发生在引入付费账户验证之前。我们提出并比较了两种新颖的方法：MonoDC和BiDC，它们分别利用用户之间的转发网络和基于共享受众的相似性网络，同时整合了最大熵零模型以过滤在线社交网络中固有的噪音。我们的结果表明，利用认证用户（被视为声望和权威的指标）能够产生明显更清晰的社区划分，这些划分与实际政治派别紧密相关，并且优于应用于整个转发网络的标准社区检测算法。此外，不同方法和用户集的比较表明，蓝色认证标记所赋予的地位在塑造在线话语中起着主导作用，这对平台治理具有重要意义，尤其是在最近转向付费验证之后。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [503] [Crowd: A Social Network Simulation Framework](https://arxiv.org/abs/2412.10781)
> *Crowd: 一个社交网络模拟框架*

*Ann Nedime Nese Rende, Tolga Yilmaz, Özgür Ulusoy* | **Category: cs.SI** | **Updated: 2025-07-15**

**Keywords:** 社交网络模拟, 代理建模, Crowd框架, 社会科学, 流行病学

**Comment:** 

> **TL;DR:** Crowd是一个专门为社交网络设计的基于代理的模拟框架，旨在简化和加速复杂社交网络现象的建模与模拟。

**AI_Comments:** Crowd的创新之处在于其专门针对社交网络的设计，极大地简化了复杂社交网络现象的建模和模拟过程。其支持YAML配置、无代码模拟以及与Python数据生态系统的无缝集成，使其成为一个强大且用户友好的工具。这对于社会科学、经济学和流行病学等领域的研究人员来说，在研究个体行为如何影响群体动态方面具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的通用代理建模和模拟（ABMS）框架在社交网络模拟方面功能有限，导致进行复杂模拟所需的工作量增加。

**Method:** 本文介绍了Crowd，一个社交网络模拟器，它采用代理建模方法来模拟网络环境中的真实世界现象。Crowd支持通过YAML配置进行模拟设置，并允许用户定义方法进行进一步定制。它还提供无代码扩散任务模拟、交互式可视化、数据聚合和图表绘制功能。Crowd用Python设计，支持生成式代理，并易于连接Python的数据分析和机器学习库。

**Result:** Crowd框架支持通过YAML配置和用户定义方法进行模拟设置和定制。它提供无代码扩散任务模拟、交互式可视化、数据聚合和图表绘制功能。此外，它支持生成式代理，并能轻松与Python的数据分析和机器学习库连接。论文通过流行病中的生成式代理、影响力最大化和网络信任博弈三个案例研究展示了其用途。

**Conclusion:** Crowd是一个专门为社交网络设计的代理建模模拟器，旨在解决现有通用ABMS框架的局限性，提供易于使用且功能丰富的工具，以促进对社交网络中个体行为如何塑造更大社区行动的观察和分析。

> **ai_Abstract:** Crowd是一个专门为社交网络设计的基于代理的模拟框架，旨在解决现有通用ABMS工具在社交网络模拟方面的局限性。它通过支持YAML配置、用户自定义方法、无代码模拟、交互式可视化和数据分析集成等功能，简化了复杂社交网络现象的建模和模拟。该框架旨在帮助社会科学、经济学和流行病学等领域的研究人员更有效地观察个体行为对社区行动的影响。

> **摘要翻译:** 为了观察个体行为如何塑造更大社区的行动，代理建模和模拟（ABMS）已被社会科学、经济学和流行病学的研究人员广泛采用。虽然模拟可以在通用ABMS框架上运行，但这些工具并非专门为社交网络设计，因此提供的功能有限，增加了复杂模拟所需的工作量。在本文中，我们介绍了Crowd，一个社交网络模拟器，它采用代理建模方法来模拟网络环境中的真实世界现象。Crowd旨在促进轻松快速的建模，支持通过YAML配置进行模拟设置，并通过用户定义的方法实现进一步定制。其他功能包括扩散任务的无代码模拟、交互式可视化、数据聚合和图表绘制工具。Crowd用Python设计，还支持生成式代理，并易于与Python的数据分析和机器学习库连接。最后，我们包括三个案例研究来说明该框架的使用，包括流行病中的生成式代理、影响力最大化和网络信任博弈。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [564] [Technological Complexity Based on Japanese Patent Data](https://arxiv.org/abs/2504.11932)
> *基于日本专利数据的技术复杂性*

*Rintaro Karashima, Hiroyasu Inoue* | **Category: cs.SI** | **Updated: 2025-07-15**

**Keywords:** 技术复杂性指数, 专利数据, 企业层面, 创新战略, 二分网络

**Comment:** 

> **TL;DR:** 本研究提出并应用了企业层面的技术复杂性指数（TCI），利用1981-2010年日本专利数据，分析公司与技术领域的二分网络，以识别关键技术和区域优势，为日本的创新战略制定提供更细致的见解。

**AI_Comments:** 本文的创新之处在于提出了企业层面的技术复杂性指数评估方法，相比传统区域分析提供了更精细、更深入的洞察。其重要性在于为创新战略制定提供了强大的分析框架，尤其在识别区域优势和关键技术方面。使用大规模日本专利数据（1981-2010年）和二分网络分析是其方法论的亮点。

<details>
  <summary>Details</summary>

**Motivation:** 面对日益激烈的国际技术竞争，各国需识别关键技术以促进创新。传统技术分析方法（如二元评估或平均TCI）粒度粗糙，无法提供详细洞察。为解决日本企业层面TCI评估利用不足的问题，本研究旨在通过企业层面的TCI评估提供更细致、更深入的见解。

**Method:** 本研究应用技术复杂性指数（TCI），使用1981年至2010财年经过处理的日本专利数据。具体分析了一个由1,938家公司与分为35或124个类别的技术领域组成的二分网络。

**Result:** 研究结果定量表征了每个技术领域的普遍性和复杂性，揭示了反映社会背景的详细技术趋势，并证明了即使采用更精细的技术分类，方法也具有稳定性。此外，企业层面的方法实现了跨区域和技术领域的一致比较，阐明了特定技术的区域优势。

**Conclusion:** 本研究提出的精炼分析框架为政策制定者和研究人员提供了强大且有针对性的见解，从而显著有助于日本创新战略的制定。

> **ai_Abstract:** 本文提出了一种基于企业层面的技术复杂性指数（TCI）评估方法，旨在解决传统技术分析粒度不足的问题。研究利用1981-2010年日本专利数据，构建并分析了包含1,938家公司与35或124个技术分类的二分网络。结果成功地定量表征了技术领域的普遍性和复杂性，揭示了详细的技术趋势，并验证了方法的稳定性。此方法还能促进跨区域和技术的比较，明确区域优势，为日本的创新战略制定提供有力的支持。

> **摘要翻译:** 随着技术领域的国际竞争加剧，各国需要识别关键技术以促进创新。然而，由于技术的独立性和固有的复杂性，识别这些技术具有挑战性。传统上，技术组合的区域分析仅限于二元评估，仅表明一个区域是否专注于某项技术，或者依赖于专业技术的平均技术复杂性指数（TCI）。本研究提出，在企业层面评估TCI可以提供更细粒度和更详细的见解。为了解决日本企业层面TCI评估利用不足的问题，本研究利用经过精心处理的1981年至2010财年的专利数据应用了技术复杂性指数。具体来说，我们分析了一个由1,938家公司组成的二分网络，这些公司与分为35或124个类别的技术领域相关联。我们的研究结果定量地表征了每个技术领域的普遍性和复杂性，揭示了反映更广泛社会背景的详细技术趋势，并证明了即使采用更精细的技术分类，该方法也具有稳定性。此外，我们的企业层面方法允许在不同区域和技术领域之间进行一致的比较，从而阐明了特定技术领域的区域优势。这一精炼的分析框架为政策制定者和研究人员提供了强大、有针对性的见解，从而显著有助于日本创新战略的制定。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [742] [Local Clustering in Hypergraphs through Higher-Order Motifs](https://arxiv.org/abs/2507.10570)
> *超图中通过高阶主题的局部聚类*

*Giuseppe F. Italiano, Athanasios L. Konstantinidis, Anna Mpanti, Fariba Ranjbar* | **Category: cs.SI** | **Updated: 2025-07-09**

**Keywords:** 超图, 局部聚类, 高阶主题, 主题电导, 核分解

**Comment:** 

> **TL;DR:** 本文提出了一种基于高阶主题的新型超图局部聚类方法，解决了传统图聚类无法处理高阶交互的问题。

**AI_Comments:** 本文的创新点在于将高阶主题引入超图的局部聚类，有效解决了传统图方法无法处理高阶交互的问题。通过提出两种不同的策略并进行比较分析，为超图分析提供了新的视角和工具。其重要性在于提升了复杂网络中局部结构发现的准确性和质量。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于图的聚类方法主要关注成对关系，无法有效表示超图中的高阶交互，导致聚类结果质量低下。

**Method:** 本文提出了一种基于高阶主题的超图局部聚类新方法。该方法利用超图特有的高阶主题来更好地表征局部结构并优化主题电导。提出了两种识别局部簇的策略：一种是利用超图核分解的基于核的方法，另一种是基于广度优先探索的BFS方法。为了便于高效划分，构建了一个辅助超图，并引入了一个局部基于主题的聚类框架。

**Result:** 在真实世界数据集上进行了大量实验，证明了该框架的有效性，并对两种提出的聚类策略在聚类质量和计算效率方面进行了比较分析。

**Conclusion:** 本文提出的基于高阶主题的超图局部聚类框架，能够有效解决传统方法在高阶交互处理上的不足，并在实际数据集中表现出良好的性能。

> **ai_Abstract:** 本文提出了一种新颖的超图局部聚类方法，该方法通过利用超图特有的高阶主题来捕获复杂系统中的高阶交互，克服了传统图聚类方法的局限性。该方法通过优化主题电导来表征局部结构，并提供了基于核分解和BFS的两种策略来识别局部簇。实验证明了其在真实数据集上的有效性和效率。

> **摘要翻译:** 超图为建模具有超越简单成对关系的高阶交互的复杂系统和网络提供了一个强大的框架。然而，主要关注成对关系的基于图的聚类方法未能表示高阶交互，通常导致低质量的聚类结果。在这项工作中，我们引入了一种基于高阶主题的超图局部聚类新方法，高阶主题是节点可以通过任何阶次的交互连接的小型连通子图，扩展了以前应用于标准图的基于主题的技术。我们的方法利用超图特有的高阶主题来更好地表征局部结构并优化主题电导。我们提出了两种围绕种子超边识别局部簇的替代策略：一种是利用超图核分解的基于核的方法，另一种是基于广度优先探索的BFS方法。我们构建了一个辅助超图以促进高效划分，并引入了一个局部基于主题的聚类框架。在真实世界数据集上进行了大量实验，证明了我们框架的有效性，并提供了两种提出的聚类策略在聚类质量和计算效率方面的比较分析。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [794] [The Shape of Deceit: Behavioral Consistency and Fragility in Money Laundering Patterns](https://arxiv.org/abs/2507.10608)
> *欺骗的形状：洗钱模式中的行为一致性与脆弱性*

*Danny Butvinik, Ofir Yakobi, Michal Einhorn Cohen, Elina Maliarsky* | **Category: cs.SI, cs.LG, stat.AP** | **Updated: 2025-07-13**

**Keywords:** 洗钱, 反洗钱, 网络理论, 行为一致性, 模式脆弱性

**Comment:** 

> **TL;DR:** 本文提出一种新的反洗钱（AML）方法，通过关注洗钱行为的一致性和模式脆弱性，而非异常交易，来检测洗钱活动，并强调其在金融犯罪检测中的重要性。

**AI_Comments:** 这篇论文的创新点在于其对洗钱行为本质的深刻理解，从传统的“异常检测”转向“模式识别”和“行为一致性”的视角。引入网络理论和子图结构来捕捉语义和功能角色，以及探讨“模式脆弱性”的概念，都为反洗钱领域提供了新的工具和思路，有望提高检测的准确性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的反洗钱系统主要通过识别异常实体或交易来发现洗钱活动，但这误解了洗钱的本质，洗钱通常是蓄意、重复并隐藏在一致的行为模式中，而非异常行为。

**Method:** 提出一种网络理论视角，强调在有向交易网络中检测预定义的洗钱模式。引入行为一致性作为洗钱活动的核心特征，并通过表达语义和功能角色的子图结构来捕捉这些模式，而不仅仅是几何结构。探讨了模式脆弱性，即洗钱模式对小属性变化的敏感性及其在剧烈拓扑变换下的语义鲁棒性。

**Result:** Not mentioned in abstract

**Conclusion:** 洗钱检测不应依赖于统计异常值，而应侧重于行为本质的保留。这种哲学和实践上的转变对反洗钱系统如何建模、扫描和解释网络以打击金融犯罪具有重要意义。

> **ai_Abstract:** 本文挑战了传统反洗钱（AML）系统以实体为中心的异常检测方法，指出洗钱行为常表现为一致且重复的模式。作者提出一种网络理论视角，强调通过检测有向交易网络中预定义的子图结构来识别洗钱模式，核心概念是“行为一致性”和“模式脆弱性”。研究认为，洗钱检测应关注行为本质的保留，而非统计异常，并提出重新定义模式相似性，这为反洗钱系统提供了新的建模和分析思路。

> **摘要翻译:** 传统的反洗钱（AML）系统主要侧重于识别异常实体或交易，根据统计偏差或可疑行为将其标记以进行人工调查。然而，这种范式误解了洗钱的真实性质，洗钱很少是异常的，而通常是蓄意、重复并隐藏在一致的行为例程中。在本文中，我们挑战了以实体为中心的方法，并提出了一种网络理论视角，强调在有向交易网络中检测预定义的洗钱模式。我们引入了行为一致性作为洗钱活动的核心特征，并认为这些模式通过表达语义和功能角色（而不仅仅是几何形状）的子图结构能更好地捕捉。关键的是，我们探讨了模式脆弱性的概念：洗钱模式对微小属性变化的敏感性，反之，即使在剧烈的拓扑变换下其语义鲁棒性。我们声称洗钱检测不应依赖于统计异常值，而应侧重于行为本质的保留，并提出基于这一见解重新概念化模式相似性。这种哲学和实践上的转变对反洗钱系统在打击金融犯罪中如何建模、扫描和解释网络具有重要意义。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [38] [LiLM-RDB-SFC: Lightweight Language Model with Relational Database-Guided DRL for Optimized SFC Provisioning](https://arxiv.org/abs/2507.10903)
> *LiLM-RDB-SFC: 轻量级语言模型结合关系数据库引导的DRL用于优化SFC资源调配*

*Parisa Fard Moshiri, Xinyu Zhu, Poonam Lohan, Burak Kantarci, Emil Janulewicz* | **Category: cs.NI, cs.CL, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 轻量级语言模型, 关系数据库, 深度强化学习, 服务功能链, 资源调配

**Comment:** 9 pages, 6 figures, Accepted to IEEE 16th International Conference on
  Network of the Future (NoF) 2025

> **TL;DR:** 该论文提出了LiLM-RDB-SFC，一种结合轻量级语言模型和关系数据库来指导深度强化学习以优化服务功能链（SFC）资源调配的方法，并展示FLAN-T5在此方法中表现优异。

**AI_Comments:** 这项工作创新性地将轻量级语言模型与关系数据库结合，以增强深度强化学习在动态网络环境中的适应性，解决了传统DRL在处理非结构化或多变数据时的局限。通过引入LiLM作为“解释器”，提高了DRL对复杂网络状态的理解能力。FLAN-T5展现出的高效率和高准确性，使其在资源受限的网络环境中具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现代软件定义网络（SDN）和网络功能虚拟化（NFV）环境中，服务功能链（SFC）的有效管理和虚拟网络功能（VNF）的最佳放置是关键挑战。尽管深度强化学习（DRL）被广泛应用于动态网络决策，但其对结构化数据和固定行动规则的固有依赖性常常限制了其在不可预测网络条件下的适应性和响应能力。

**Method:** 本文提出了LiLM-RDB-SFC方法，结合轻量级语言模型（LiLM）和关系数据库（RDB）来回答网络状态查询，从而指导DRL模型进行高效的SFC资源调配。该方法利用BART和FLAN-T5两种LiLM来解释网络数据并支持与SFC需求、数据中心资源和VNF可用性相关的各种查询类型。

**Result:** FLAN-T5在测试损失（0.00161 对比 0.00734）、准确率（94.79% 对比 80.2%）和处理时间（2小时2分钟 对比 2小时38分钟）方面均优于BART。与大型语言模型SQLCoder相比，FLAN-T5在准确率上与SQLCoder持平，但处理时间缩短了96%（SQLCoder：54小时43分钟；FLAN-T5：2小时2分钟）。

**Conclusion:** FLAN-T5在所提出的LiLM-RDB-SFC框架中表现出卓越的性能，尤其是在效率方面，使其成为优化SFC资源调配的有效选择。

> **ai_Abstract:** 本文提出了LiLM-RDB-SFC，一种结合轻量级语言模型（LiLM）和关系数据库（RDB）来指导深度强化学习（DRL）优化服务功能链（SFC）资源调配的新方法。该方法通过LiLM解释网络数据并回答查询，以克服DRL在动态网络中适应性不足的局限。实验结果显示，FLAN-T5在性能和效率上均显著优于BART，且在准确率上与大型模型SQLCoder持平但处理时间大幅减少，证明了其在SFC资源调配中的高效性。

> **摘要翻译:** 服务功能链（SFC）的有效管理和虚拟网络功能（VNF）的最佳放置是现代软件定义网络（SDN）和网络功能虚拟化（NFV）环境中的关键挑战。尽管深度强化学习（DRL）被广泛应用于动态网络决策，但其对结构化数据和固定行动规则的固有依赖性常常限制了其适应性和响应能力，尤其是在不可预测的网络条件下。本文介绍了一种名为LiLM-RDB-SFC的新方法，它结合了轻量级语言模型（LiLM）和关系数据库（RDB）来回答网络状态查询，从而指导DRL模型进行高效的SFC资源调配。我们提出的方法利用了两种LiLM，即双向和自回归Transformer（BART）和微调语言网络T5（FLAN-T5），来解释网络数据并支持与SFC需求、数据中心资源和VNF可用性相关的各种查询类型。结果表明，FLAN-T5在测试损失（0.00161 对比 0.00734）、准确率（94.79% 对比 80.2%）和处理时间（2小时2分钟 对比 2小时38分钟）方面均优于BART。此外，与大型语言模型SQLCoder相比，FLAN-T5在准确率上与SQLCoder持平，同时处理时间缩短了96%（SQLCoder：54小时43分钟；FLAN-T5：2小时2分钟）。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [91] [Arcturus: A Cloud Overlay Network for Global Accelerator with Enhanced Performance and Stability](https://arxiv.org/abs/2507.10928)
> *Arcturus：一种用于增强性能和稳定性的全球加速器云覆盖网络*

*Matthew Yang Liu, Chuang Chen, Pengcheng Lv, Hui Guo, Yanan Zhang, Cong Wang, Yusen Li, Zhenyu Li, Yu-Chu Tian* | **Category: cs.NI, cs.DC** | **Updated: 2025-07-15**

**Keywords:** 全球加速器, 云覆盖网络, 多云, 性能优化, 成本效率

**Comment:** 

> **TL;DR:** Arcturus是一个云原生的全球加速器框架，通过利用多云提供商的异构资源，动态构建加速网络，并在性能、稳定性、成本和资源效率之间取得平衡，优于现有商业GA服务。

**AI_Comments:** Arcturus的创新之处在于其“云原生”和“多云异构资源利用”的设计理念，这打破了传统GA服务对单一云提供商的依赖，显著降低了成本并提高了部署灵活性。其双平面架构也体现了对复杂网络控制和优化的精妙设计。该研究对于推动未来全球加速服务向更开放、更经济、更高效的方向发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有全球加速器（GA）服务与特定云提供商紧密绑定，导致成本高昂、部署僵化且灵活性有限，特别是对于大规模或预算敏感的部署。

**Method:** Arcturus采用双平面设计：转发平面构建具有自适应控制的代理网络；调度平面通过轻量级定量优化协调负载和路由。它动态构建加速网络并平衡性能、稳定性与资源效率。

**Result:** 在数百万RPS的评估下，Arcturus在加速性能上比商业GA服务高出1.7倍，成本降低71%，并保持超过80%的资源效率。

**Conclusion:** Arcturus通过利用低成本、异构的云资源，成功提供了一个高效、高性能、低成本且灵活的全球加速器解决方案，证明了其在大规模云资源利用方面的有效性。

> **ai_Abstract:** Arcturus是一个创新的云原生全球加速器（GA）框架，旨在解决现有GA服务成本高、灵活性差的问题。它通过利用跨多个云提供商的低成本异构资源，动态构建加速网络，并采用双平面设计（转发平面和调度平面）来优化性能、稳定性和资源效率。实验结果表明，Arcturus在加速性能上优于商业GA服务1.7倍，成本降低71%，并保持高资源效率。

> **摘要翻译:** 全球加速器（GA）服务在确保实时交互应用低延迟、高可靠性通信方面发挥着至关重要的作用。然而，现有的GA产品与特定的云提供商紧密绑定，导致成本高昂、部署僵化且灵活性有限，特别是对于大规模或预算敏感的部署。Arcturus是一个云原生的GA框架，通过利用多个提供商的低成本、异构云资源，重新审视了GA系统的设计。Arcturus不依赖固定的高端基础设施，而是动态构建其加速网络，并在性能、稳定性、资源效率之间取得平衡。为实现这一点，Arcturus引入了双平面设计：一个转发平面构建具有自适应控制的代理网络，以及一个调度平面通过轻量级、定量优化协调负载和路由。在数百万RPS下的评估表明，Arcturus在加速性能上比商业GA服务高出1.7倍，成本降低71%，并保持超过80%的资源效率——这证明了其在大规模云资源利用方面的效率。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [142] [SIMCODE: A Benchmark for Natural Language to ns-3 Network Simulation Code Generation](https://arxiv.org/abs/2507.11014)
> *SIMCODE：一个用于自然语言到ns-3网络仿真代码生成的基准测试*

*Tasnim Ahmed, Mirza Mohammad Azwad, Salimur Choudhury* | **Category: cs.NI** | **Updated: 2025-07-15**

**Keywords:** SIMCODE, LLMs, ns-3, 代码生成, 网络仿真

**Comment:** This paper has been accepted for presentation at the 50th IEEE
  Conference on Local Computer Networks (LCN) - special track on Large Language
  Models and Networking

> **TL;DR:** SIMCODE是一个新的基准测试，旨在评估大型语言模型（LLMs）从自然语言生成ns-3网络仿真代码的能力，并发现当前LLMs在此任务上的准确性仍有很大提升空间。

**AI_Comments:** SIMCODE是一个重要的贡献，因为它填补了LLMs在特定领域（如网络仿真）代码生成评估方面的空白。其结构化的任务和测试用例为未来研究提供了一个坚实的基础。错误分析指出的问题（缺少头文件和API不匹配）为模型改进指明了方向，突显了领域知识集成的重要性。该基准测试将推动领域感知生成系统的发展。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型在代码生成方面表现出色，但它们在为ns-3等特定领域环境生成仿真脚本的有效性尚未得到充分探索。现有工具主要侧重于交互式自动化而非严格评估，因此需要一个系统性评估工具来促进自动化网络仿真。

**Method:** 研究引入了SIMCODE，这是首个用于评估LLMs从自然语言生成ns-3仿真代码能力的基准测试。SIMCODE包含400个任务（分为入门、中级和高级），并附带解决方案和测试用例。研究使用SIMCODE评估了Gemini-2.0、GPT-4.1和Qwen-3这三个主流LLM，并采用了六种提示技术。此外，还研究了任务特定微调的影响。

**Result:** 使用SIMCODE评估发现，虽然GPT-4.1的表现优于其他模型，但执行准确性仍然不高，有很大的改进空间。错误分析表明，主要失败原因是缺少头文件和API不匹配。

**Conclusion:** SIMCODE为评估大型语言模型在领域感知生成系统中的能力迈出了基础性一步，并揭示了LLMs在生成特定领域仿真代码方面仍需大量改进。

> **ai_Abstract:** 本文介绍了SIMCODE，一个新颖的基准测试，旨在系统性评估大型语言模型（LLMs）将自然语言转换为ns-3网络仿真代码的能力。SIMCODE包含400个不同难度的任务，并提供解决方案和测试用例。研究利用SIMCODE评估了Gemini-2.0、GPT-4.1和Qwen-3等主流LLMs，发现尽管GPT-4.1表现最佳，但整体执行准确性仍有待提高，主要错误在于缺少头文件和API不匹配。SIMCODE为未来LLMs在特定领域代码生成方面的研究奠定了基础。

> **摘要翻译:** 大型语言模型（LLMs）在各种领域的代码生成方面表现出卓越的能力。然而，它们在为ns-3等特定领域环境生成仿真脚本的有效性仍未得到充分探索。尽管对自动化网络仿真的兴趣日益增长，现有工具主要侧重于交互式自动化而非严格评估。为了促进系统性评估，我们引入了SIMCODE，这是首个用于评估LLMs从自然语言生成ns-3仿真代码能力的基准测试。SIMCODE包含400个入门级、中级和高级任务，并附带解决方案和测试用例。使用SIMCODE，我们评估了三个主流LLM：Gemini-2.0、GPT-4.1和Qwen-3，并采用了六种提示技术。此外，对任务特定微调影响的调查显示，尽管GPT-4.1的表现优于其他模型，但执行准确性仍然不高，有很大的改进空间。错误分析确定缺少头文件和API不匹配是主要的失败原因。尽管如此，SIMCODE为评估LLMs和领域感知生成系统的研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [187] [Graph-based Fingerprint Update Using Unlabelled WiFi Signals](https://arxiv.org/abs/2507.11038)
> *基于图的无标签WiFi信号指纹更新*

*Ka Ho Chiu, Handi Yin, Weipeng Zhuo, Chul-Ho Lee, S. -H. Gary Chan* | **Category: cs.NI** | **Updated: 2025-07-15**

**Keywords:** WiFi指纹, 图神经网络, 无标签信号, 指纹更新, 位置预测

**Comment:** Published in Proceedings of the ACM on Interactive, Mobile, Wearable
  and Ubiquitous Technologies, Volume 9, Issue 1, Article No. 3, Pages 1 - 26

> **TL;DR:** GUFU是一种新颖的基于图的方法，利用无标签WiFi信号（可能包含新的AP）有效更新现有WiFi指纹数据库，显著提高了指纹适应性并降低了RSS值和位置预测误差。

**AI_Comments:** GUFU的创新之处在于其采用图神经网络和链接预测算法来处理无标签的、可能包含新AP的WiFi信号，从而有效更新指纹数据库。这解决了现有方法在适应WiFi环境变化方面的不足。其在实际场景中的显著性能提升，证明了该方法的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** WiFi接收信号强度（RSS）环境随时间变化，现有方法在更新指纹数据库时存在局限性，例如未能有效更新现有指纹或未能充分利用新AP的特征。

**Method:** 提出GUFU，一种新颖有效的基于图的方法。基于“相似信号向量可能意味着物理接近”的观察，GUFU采用图神经网络（GNN）和链接预测算法，利用新的信号和AP对增量网络进行再训练，然后更新指定位置的信号向量。

**Result:** GUFU在四个大型代表性站点中表现出显著更高的指纹适应性，与现有最先进方法相比，RSS值误差降低了21.4%，位置预测误差降低了29.8%。

**Conclusion:** GUFU通过其创新的图基方法，成功解决了WiFi指纹数据库更新中的挑战，显著提高了指纹适应性和定位精度。

> **ai_Abstract:** 该论文提出GUFU，一种新颖的基于图的方法，用于利用无标签WiFi信号（包括可能的新AP）更新现有WiFi指纹数据库。针对WiFi RSS环境随时间变化导致传统方法不足的问题，GUFU利用图神经网络和链接预测算法对增量网络进行再训练，以更新指定位置的信号向量。实验结果表明，GUFU显著提高了指纹适应性，并在RSS值和位置预测方面实现了显著的误差降低。

> **摘要翻译:** WiFi接收信号强度（RSS）环境会随着接入点（AP）的移动、AP功率调整、AP的安装和移除等因素随时间演变。我们研究如何使用一批新收集的无标签（可能是众包的）WiFi信号，有效更新现有的指纹数据库，指纹定义为指定位置的AP的RSS值。现有技术要么在不更新现有指纹的情况下估计新信号的位置，要么在未能充分利用其特征的情况下过滤掉新的AP。为了解决这个问题，我们提出了GUFU，一种新颖有效的基于图的方法，用于使用无标签信号（可能包含新的AP）更新WiFi指纹。基于相似信号向量可能意味着物理接近的观察，GUFU采用图神经网络（GNN）和链接预测算法，根据新的信号和AP重新训练一个增量网络。再训练后，它会更新指定位置的信号向量。通过在四个大型代表性站点的广泛实验，GUFU被证明比其他最先进的方法实现了显著更高的指纹适应性，RSS值和位置预测的误差分别降低了21.4%和29.8%。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [232] [Improving Wi-Fi Network Performance Prediction with Deep Learning Models](https://arxiv.org/abs/2507.11168)
> *使用深度学习模型改进Wi-Fi网络性能预测*

*Gabriele Formis, Amanda Ericson, Stefan Forsstrom, Kyi Thar, Gianluca Cena, Stefano Scanzio* | **Category: cs.NI, cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** Wi-Fi网络, 性能预测, 深度学习, 卷积神经网络, 帧交付率

**Comment:** preprint accepted, 8 pages, 2025

> **TL;DR:** 本研究利用深度学习（特别是CNN和LSTM）预测Wi-Fi网络的信道质量（帧交付率），以满足工业应用的需求，并发现CNN在效率方面表现出色，尽管预测精度略低。

**AI_Comments:** 该论文通过利用深度学习实现主动性能优化，解决了工业无线网络中的关键需求。特别关注卷积神经网络的计算效率是一个重要的创新点，它增强了模型在资源通常有限的嵌入式和工业系统上的实际应用性。这项工作有助于提高Wi-Fi在严苛环境中的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 工业和任务关键型应用对无线网络的鲁棒性、可靠性和确定性日益增长的需求是新创新方法发展的驱动力。通过预测信道质量，可以主动调整通信参数并优化网络操作。

**Method:** 本研究利用机器学习技术（包括卷积神经网络CNN和长短期记忆LSTM）来预测Wi-Fi网络中的信道质量，具体指标为帧交付率。这些模型在从真实Wi-Fi设置中获取的跨多个通道的数据集上进行了分析，并就预测精度和计算复杂性进行了比较。

**Result:** 结果表明，帧交付率可以可靠地预测。卷积神经网络（CNN）虽然在预测精度上略低于其他模型，但在CPU使用率和内存消耗方面更高效，这增强了模型在嵌入式和工业系统上的可用性。

**Conclusion:** 深度学习模型，特别是考虑到其效率的卷积神经网络，能够可靠地预测Wi-Fi信道质量，这对于优化工业和嵌入式无线网络性能具有重要意义。

> **ai_Abstract:** 本论文研究了使用深度学习模型（卷积神经网络和长短期记忆网络）来预测Wi-Fi网络的信道质量（以帧交付率衡量），以满足工业和任务关键型应用的需求。通过分析在真实世界数据集上训练的模型，研究证明了可靠的预测能力。论文强调，卷积神经网络虽然预测精度略低，但计算效率更高，使其适用于资源受限的嵌入式和工业系统，从而主动优化网络性能。

> **摘要翻译:** 工业和任务关键型应用对无线网络鲁棒性、可靠性和确定性日益增长的需求是新创新方法发展的驱动力。本研究利用机器学习技术，根据帧交付率预测Wi-Fi网络中的信道质量。预测可用于在运行时主动调整通信参数，并优化工业应用的S网络操作。本研究分析了在真实Wi-Fi设置中跨多个信道获取的数据集上的卷积神经网络和长短期记忆等方法。对模型的预测精度和计算复杂性进行了比较。结果表明，帧交付率可以可靠地预测，并且卷积神经网络虽然在效率上略低于其他模型，但在CPU使用率和内存消耗方面更高效。这增强了模型在嵌入式和工业系统上的可用性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [276] [Resilient Time-Sensitive Networking for Industrial IoT: Configuration and Fault-Tolerance Evaluation](https://arxiv.org/abs/2507.11250)
> *面向工业物联网的弹性时间敏感网络：配置与容错评估*

*Mohamed Seliem, Dirk Pesch, Utz Roedig, Cormac Sreenan* | **Category: cs.NI** | **Updated: 2025-07-15**

**Keywords:** 时间敏感网络, 工业物联网, 容错, 仿真, FRER

**Comment:** (c) 2025 IEEE. This is the author's version of a paper accepted for
  presentation at the IEEE ETFA 2025 conference. The final version will appear
  in the conference proceedings

> **TL;DR:** 本文提出了IN2C，一个基于OMNeT++/INET的仿真框架，用于评估工业物联网中时间敏感网络（TSN）的容错性。研究表明，FRER功能可消除丢包并实现亚毫秒级恢复，但会增加链路利用率，为TSN部署提供了实用指导。

**AI_Comments:** 本文通过IN2C仿真框架，为TSN在工业物联网中的容错性评估提供了一个实用的解决方案。其创新点在于结合了核心TSN功能和XML驱动的故障注入，并量化了FRER在提高可靠性方面的效果及对链路利用率的影响，为实际部署提供了有价值的数据和指导。

<details>
  <summary>Details</summary>

**Motivation:** 在工业系统中，时间敏感网络（TSN）被广泛采用以满足严格的延迟、抖动和可靠性要求。然而，在现实故障条件下评估TSN的容错性仍然具有挑战性。

**Method:** 本文提出了IN2C，一个模块化的基于OMNeT++/INET的仿真框架，该框架模拟了连接到集中式基础设施的两个同步生产单元。IN2C集成了核心TSN功能，包括时间同步、流量整形、每流过滤以及用于冗余的帧复制和消除（FRER），并结合XML驱动的链路和节点故障注入。

**Result:** 结果显示，FRER（帧复制和消除）功能消除了数据包丢失，并实现了亚毫秒级的恢复，尽管链路利用率增加了2-3倍。

**Conclusion:** 这些发现为在带宽受限的工业环境中部署TSN提供了实用的指导。

> **ai_Abstract:** 本研究提出IN2C，一个基于OMNeT++/INET的模块化仿真框架，旨在解决工业物联网中时间敏感网络（TSN）容错评估的挑战。IN2C模拟了两个同步生产单元，并集成了TSN核心功能（如时间同步、流量整形、FRER）及XML驱动的故障注入。通过评估四种故障场景，研究发现，FRER能有效消除丢包并实现亚毫秒级恢复，尽管会显著增加链路利用率。这些结果为在带宽受限的工业环境中部署TSN提供了宝贵的实践指导。

> **摘要翻译:** 时间敏感网络（TSN）在工业系统中被越来越多地采用，以满足严格的延迟、抖动和可靠性要求。然而，在现实故障条件下评估TSN的容错性仍然具有挑战性。本文提出了IN2C，一个模块化的基于OMNeT++/INET的仿真框架，该框架模拟了连接到集中式基础设施的两个同步生产单元。IN2C集成了核心TSN功能，包括时间同步、流量整形、每流过滤以及用于冗余的帧复制和消除（FRER），并结合XML驱动的链路和节点故障注入。评估了四种故障场景，以比较有无冗余的TSN性能。结果显示，FRER消除了数据包丢失并实现了亚毫秒级的恢复，尽管链路利用率增加了2-3倍。这些发现为在带宽受限的工业环境中部署TSN提供了实用的指导。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [327] [JamShield: A Machine Learning Detection System for Over-the-Air Jamming Attacks](https://arxiv.org/abs/2507.11483)
> *JamShield：一种针对无线电干扰攻击的机器学习检测系统*

*Ioannis Panitsas, Yagmur Yigit, Leandros Tassiulas, Leandros Maglaras, Berk Canberk* | **Category: cs.NI** | **Updated: 2025-07-15**

**Keywords:** 干扰检测, 机器学习, 无线网络安全, 特征选择, 自适应分类

**Comment:** Accepted for presentation at IEEE International Conference on
  Communications (ICC), 2025

> **TL;DR:** JamShield是一个基于机器学习的动态干扰检测系统，利用混合特征选择和自动分类模块，在真实世界无线网络中显著提高了干扰检测的准确性和可靠性。

**AI_Comments:** JamShield的创新点在于其结合了混合特征选择和实时自适应分类模块，并使用了真实世界和公开数据集进行训练，这使其能够更好地适应动态的网络环境。相较于依赖模拟数据或有限专有数据集的传统方法，JamShield的实际应用潜力更大，对于提升无线网络安全具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 无线网络由于共享通信介质而容易受到干扰攻击，这会严重降低性能并中断服务。现有干扰检测方法通常依赖模拟数据或有限的专有空中数据集，无法准确反映网络真实状态，从而限制了其在实际场景中的有效性。

**Method:** 本文提出了JamShield，一个动态干扰检测系统。该系统利用作者自己收集的空中数据和公开可用数据集进行训练，采用混合特征选择来优先处理相关特征以实现准确高效的检测，并包含一个自动分类模块，根据当前网络条件实时动态调整分类算法。

**Result:** 实验结果表明，与最先进的检测算法相比，JamShield在检测率、精确度和召回率方面有显著提高，同时减少了误报和漏报。

**Conclusion:** JamShield是一种在真实世界无线网络中检测干扰攻击的鲁棒且可靠的解决方案。

> **ai_Abstract:** JamShield是一种针对无线电干扰攻击的机器学习检测系统，旨在解决现有方法在真实世界网络中有效性不足的问题。它利用自收集的空中数据和公开数据集进行训练，结合混合特征选择和自适应分类算法，实现了对干扰攻击的高效准确检测。实验证明，JamShield在检测率、精确度和召回率上优于现有技术，并显著减少了误报和漏报，使其成为一个在实际无线网络中可靠的干扰检测方案。

> **摘要翻译:** 无线网络由于共享通信介质而容易受到干扰攻击，这会严重降低性能并中断服务。尽管进行了广泛研究，但当前的干扰检测方法通常依赖于模拟数据或具有有限跨层特征的专有空中数据集，未能准确表示网络的真实状态，从而限制了它们在实际场景中的有效性。为了解决这些挑战，我们引入了JamShield，一个动态干扰检测系统，该系统在我们自己收集的空中数据和公开可用数据集上进行训练。它利用混合特征选择来优先处理相关特征，以实现准确高效的检测。此外，它还包括一个自动分类模块，可以根据当前网络条件实时动态调整分类算法。我们的实验结果表明，与最先进的检测算法相比，JamShield在检测率、精确度和召回率方面有显著提高，同时减少了误报和漏报，使JamShield成为在真实世界无线网络中检测干扰攻击的鲁棒且可靠的解决方案。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [496] [A Time-Triggered Communication Method Based on Urgency-Based Scheduler in Time-Sensitive Networking](https://arxiv.org/abs/2412.20077)
> *一种基于紧急度调度器的时间敏感网络时间触发通信方法*

*Feng Luo, Yunpeng Li, Zitong Wang, Yi Ren, Yingpeng Tong, Zhouping Zhang, Qin Liu* | **Category: cs.NI** | **Updated: 2025-07-15**

**Keywords:** 时间敏感网络（TSN）, 时间触发通信, 紧急度调度器, 确定性传输, 调度算法

**Comment:** 

> **TL;DR:** 本文提出了一种基于紧急度调度器（TT-UBS）的时间触发通信方法，用于时间敏感网络（TSN），显著提高了确定性传输和计算效率，在测试场景中将求解时间缩短了98.22%。

**AI_Comments:** 该论文在时间敏感网络（TSN）的时间触发通信领域取得了显著的计算效率提升，特别是解决了现有调度算法在可扩展性方面的瓶颈。将求解时间缩短98.22%的量化结果极具说服力，突显了其在实时系统（如车载网络）中的实际应用价值。同时，对“异常情况”下的性能提升也表明了该方法的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 汽车工业和自动化领域的发展对时间关键系统提出了低延迟和低抖动传输关键流量的需求。现有的时间敏感网络（TSN）中，IEEE 802.1时间感知整形器（TAS）虽然实现了时间触发（TT）通信，但固定路由和允许等待（FR-WA）调度算法在求解时间和可扩展性方面存在效率低下问题，尤其是在网络规模扩展时计算约束增加。

**Method:** 本研究提出了一种基于紧急度调度器（TT-UBS）的方法，旨在提高时间敏感网络（TSN）在异常情况下的确定性传输和计算效率。该方法开发了一种新颖的调度算法用于TT-UBS参数确定，并进行了仿真和比较评估。此外，该方法还扩展应用于其他调度算法以评估效率提升。

**Result:** TT-UBS在测试场景中能够保证确定性流量传输，并与传统方法相比，将求解时间缩短了98.22%。

**Conclusion:** TT-UBS方法显著优化了时间敏感网络（TSN）中的时间触发通信性能，支持其在任务关键系统中的应用并实现可靠的网络部署，尤其在需要延迟和抖动控制的实时车载网络中展现出巨大潜力。

> **ai_Abstract:** 本论文旨在解决时间敏感网络（TSN）中时间关键系统对低延迟和低抖动的需求，并克服现有时间感知整形器（TAS）调度算法（如FR-WA）在求解时间和可扩展性方面的效率低下问题。为此，论文提出了一种基于紧急度调度器（TT-UBS）的时间触发通信方法，旨在提高确定性传输和计算效率，尤其是在网络规模扩展和异常情况下的性能。通过开发一种新型调度算法并进行仿真和比较评估，研究结果表明TT-UBS能够保证确定性流量传输，并将求解时间大幅缩短98.22%。该方法在实时车载网络和任务关键型TSN应用中展现出显著潜力。

> **摘要翻译:** 汽车工业和自动化领域的发展使得时间关键系统对关键流量的低延迟和低抖动有了日益增长的需求。为了解决这个问题，IEEE 802.1时间敏感网络（TSN）工作组提出了时间感知整形器（TAS）来实现时间触发（TT）通信，通过为每个流分配特定的时间窗口来实现确定性传输。虽然固定路由和允许等待（FR-WA）调度算法提供了灵活性，但它们在求解时间和可扩展性方面存在效率低下问题。本研究分析了TAS实现的挑战，强调了网络规模扩展如何增加计算约束。我们提出了一种基于紧急度调度器（TT-UBS）的方法来解决这些限制，以提高异常情况下的确定性传输和计算效率。开发了一种用于TT-UBS参数确定的新型调度算法，并进行了仿真和比较评估。结果表明，与传统方法相比，TT-UBS在测试场景中保证了确定性流量传输，同时将求解时间缩短了98.22%。该方法还扩展应用于其他调度算法以评估效率提升。这一进步通过优化时间触发通信性能并实现可靠的网络部署，支持了TSN在任务关键系统中的应用。该框架展示了在需要延迟和抖动控制的实时车载网络中的巨大潜力。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [571] [A Fast Solver-Free Algorithm for Traffic Engineering in Large-Scale Data Center Network](https://arxiv.org/abs/2504.04027)
> *一种用于大规模数据中心网络流量工程的快速无求解器算法*

*Yingming Mao, Qiaozhu Zhai, Ximeng Liu, Zhen Yao, Xia Zhu, Yuzhou Zhou* | **Category: cs.NI** | **Updated: 2025-07-15**

**Keywords:** 流量工程, 数据中心网络, 无求解器算法, 顺序优化, 最大链路利用率

**Comment:** Accepted by 23rd USENIX Symposium on Network Systems Design and
  Implementation (NSDI '26), to be held in Seattle on May 4-6, 2026

> **TL;DR:** SSDO是一种快速的无求解器算法，通过顺序优化源-目的需求来解决大规模数据中心网络流量工程中的可扩展性问题，并在最大链路利用率和速度方面优于现有方法。

**AI_Comments:** SSDO的创新之处在于其“无求解器”的顺序优化方法，避免了传统优化器或深度学习方法带来的可扩展性问题。通过将复杂问题分解为简单子问题并引入动态更新机制，SSDO在保证性能的同时显著提高了计算效率，这对于大规模数据中心网络的实时流量工程至关重要。其在Meta DCNs上的表现验证了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有依赖商业求解器或深度学习的流量工程加速策略面临可扩展性问题，性能下降或计算时间过长，无法有效应对数据中心网络快速增长带来的大规模流量工程挑战。

**Method:** 本文提出了一种顺序无求解器算法——顺序源-目的优化 (SSDO)。SSDO将问题分解为子问题，每个子问题专注于调整特定源-目的 (SD) 需求的分流比，同时保持其他需求固定。为提高子问题优化效率，设计了平衡二分搜索方法 (BBSM) 来识别在多个解决方案中最小化最大链路利用率 (MLU) 的最平衡分流比。SSDO还根据实时利用率动态更新SD顺序，以加速收敛并提高解决方案质量。

**Result:** 在Meta数据中心网络拓扑中，SSDO将归一化MLU比TEAL和POP（两种最先进的流量工程加速方法）分别降低了65%和60%，同时比POP提速12倍。

**Conclusion:** SSDO在大规模流量工程中展现出卓越的性能。

> **ai_Abstract:** 本文提出了一种名为顺序源-目的优化（SSDO）的快速无求解器算法，用于解决大规模数据中心网络中的流量工程问题。针对现有方法的可扩展性、性能下降和计算时间长等挑战，SSDO通过将问题分解为子问题，并利用平衡二分搜索方法（BBSM）优化每个源-目的需求的分流比。此外，SSDO动态更新源-目的顺序以加速收敛并提升解决方案质量。实验结果表明，在Meta数据中心网络上，SSDO在降低最大链路利用率方面显著优于现有最先进方法TEAL和POP，并实现了显著的加速。

> **摘要翻译:** 数据中心网络（DCNs）的快速增长对大规模流量工程（TE）提出了严峻挑战。现有依赖商业求解器或深度学习的加速策略面临可扩展性问题，并且在性能下降或计算时间过长方面遇到困难。与现有采用并行策略的算法不同，我们提出了一种顺序无求解器算法——顺序源-目的优化（SSDO）。SSDO将问题分解为子问题，每个子问题专注于调整特定源-目的（SD）需求的分流比，同时保持其他需求固定。为了提高子问题优化的效率，我们设计了一种平衡二分搜索方法（BBSM），该方法能够在最小化最大链路利用率（MLU）的多个解决方案中识别出最平衡的分流比。SSDO根据实时利用率动态更新SD的顺序，这加速了收敛并提高了解决方案质量。我们在Meta数据中心网络和两个广域网上评估了SSDO。在Meta拓扑中，与两种最先进的TE加速方法TEAL和POP相比，SSDO将归一化MLU分别降低了65%和60%，同时比POP提速12倍。这些结果表明SSDO在大规模TE中具有卓越的性能。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [641] [Pinching Antenna-Aided Wireless Powered Communication Networks](https://arxiv.org/abs/2506.00355)
> *钳位天线辅助无线供电通信网络*

*Yixuan Li, Hongbo Xu, Ming Zeng, Yuanwei Liu* | **Category: cs.NI** | **Updated: 2025-07-15**

**Keywords:** 钳位天线, 无线供电通信网络, 资源分配, 位置优化, 和速率最大化

**Comment:** 

> **TL;DR:** 本文研究了一种新型钳位天线辅助的无线供电通信网络（PA-WPCN），通过优化资源分配和钳位天线位置来最大化和速率，并提出了高效的算法。

**AI_Comments:** 该论文创新性地引入了钳位天线（PA）来增强无线供电通信网络（WPCN）的鲁棒性，并通过对资源分配和PA位置的联合优化，提出了实用的算法来解决复杂的优化问题。其对实际场景的考虑，如多种接入协议和非线性模型，增加了研究的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究一种新型的钳位天线（PA）辅助无线供电通信网络（WPCN），其中多个PA沿波导激活，以与多个设备建立鲁棒的视距链路。

**Method:** 本文提出了一种新型的钳位天线（PA）辅助无线供电通信网络（PA-WPCN），并考虑了时分多址（TDMA）和非正交多址（NOMA）协议。研究中纳入了PA的比例功率模型、波导传输损耗模型和非线性能量收集模型等实际考量。通过联合优化资源分配和PA位置，制定了和速率最大化问题。为解决PA位置优化这一挑战性问题，提出了高性能的逐元素（EW）算法和低复杂度的随机参数差分进化（SPDE）算法。

**Result:** 数值结果验证了所提出的PA-WPCN的卓越性能和所提算法的有效性，并表明当PA功率分配比约为0.55-0.6时，可以获得最佳性能。

**Conclusion:** 最佳性能在PA功率分配比约为0.55-0.6时达到，验证了所提PA-WPCN的性能和算法的有效性。

> **ai_Abstract:** 本文提出并研究了一种新型的钳位天线（PA）辅助无线供电通信网络（PA-WPCN），该网络通过沿波导激活多个PA与设备建立鲁棒的视距链路。研究考虑了TDMA和NOMA协议，并纳入了实际功率、损耗和能量收集模型。为了最大化和速率，文章联合优化了资源分配和PA位置，并为此提出了高性能的EW算法和低复杂度的SPDE算法。数值结果证实了所提PA-WPCN的优越性能以及所提算法的有效性，并指出最佳性能在PA功率分配比为0.55-0.6时实现。

> **摘要翻译:** 原标题：Pinching Antenna-Aided Wireless Powered Communication Networks
译文：钳位天线辅助无线供电通信网络

原摘要：In this letter, we investigate a novel pinching antenna (PA)-aided wireless powered communication network (WPCN), in which multiple PAs are activated along a waveguide to establish robust line-of-sight links with multiple devices. Both time division multiple access (TDMA) and non-orthogonal multiple access (NOMA) protocols are considered in the PA-WPCN. Moreover, some practical considerations, including a proportional power model for the PAs, a waveguide transmission loss model, and a nonlinear energy harvesting model, are incorporated into the PA-WPCN. Furthermore, we formulate a sum-rate maximization problem by jointly optimizing resource allocation and PAs position. To address the challenging problem of the PAs position optimization, we propose a high-performance element-wise (EW) algorithm and a low-complexity stochastic parameter differential evolution (SPDE) algorithm. Numerical results validate the remarkable performance of the proposed PA-WPCN and the effectiveness of our algorithms, indicating that optimal performance is attained when the PA power distribution ratio of approximately 0.55-0.6.

译文：本文研究了一种新型的钳位天线（PA）辅助无线供电通信网络（WPCN），其中多个PA沿波导激活，以与多个设备建立鲁棒的视距链路。在PA-WPCN中，考虑了时分多址（TDMA）和非正交多址（NOMA）协议。此外，一些实际考虑因素，包括PA的比例功率模型、波导传输损耗模型和非线性能量收集模型，都被纳入PA-WPCN中。我们还通过联合优化资源分配和PA位置，制定了一个和速率最大化问题。为了解决PA位置优化这一具有挑战性的问题，我们提出了一种高性能的逐元素（EW）算法和一种低复杂度的随机参数差分进化（SPDE）算法。数值结果验证了所提出的PA-WPCN的卓越性能和我们算法的有效性，表明当PA功率分配比约为0.55-0.6时，可以获得最佳性能。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [711] [AoI-Energy-Spectrum Optimization in Post-Disaster Powered Communication Intelligent Network via Hierarchical Heterogeneous Graph Neural Network](https://arxiv.org/abs/2507.03401)
> *基于分层异构图神经网络的灾后供电通信智能网络中AoI-能量-频谱优化*

*Hanjian Liu, Jinsong Gui, Xiaoheng Deng* | **Category: cs.NI, eess.SP** | **Updated: 2025-07-15**

**Keywords:** 灾后通信, 分层异构图神经网络, 信息年龄, 能量效率, 频谱效率

**Comment:** 

> **TL;DR:** 本文提出了一种灾后供电通信智能网络（PDPCIN），利用无人机和低轨卫星解决灾后通信中断问题，并通过分层异构图神经网络（HHGNN）框架优化信息年龄（AoI）、能量效率和频谱效率。

**AI_Comments:** 该论文在灾后通信网络设计中引入了创新的分层异构图神经网络（HHGNN）框架，有效地应对了多设备调度和多维指标优化带来的复杂性，特别是在信息年龄、能量效率和频谱效率的协同优化方面。其结合无人机和低轨卫星的异构网络架构也具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 为解决灾后地面基站故障导致的通信中断，以及在确保基本通信的同时协同优化信息年龄（AoI）、能量效率和频谱效率的挑战，本文设计了灾后供电通信智能网络（PDPCIN）。

**Method:** 本文设计了灾后供电通信智能网络（PDPCIN），利用无人机进行无线数据收集和无线能量传输，并利用低轨卫星将无人机数据中继到最近的幸存基站。为优化AoI、能量效率和频谱效率，提出了智能同步无人机（IS-UAV）架构、基于AoI的四阈值更新（AFTU）机制和动态多低轨卫星接入（DMLA）策略。针对时间-资源不平衡、复杂拓扑和多维指标优化中的非线性耦合等挑战，提出了分层异构图神经网络（HHGNN）框架，将异构设备节点及其通信关系建模为分层异构图结构，并集成了图感知、交换和掩码层。此外，还提出了单低轨卫星密度优化（S-LSDO）算法来搜索合适的单低轨卫星数量。

**Result:** 所提出的方案与现有基准方案相比，在AoI、能量效率和频谱效率的协同优化方面表现出优越性。基于此，推导了AoI和停滞AoI比例的期望值表达式。

**Conclusion:** 本文成功设计了灾后供电通信智能网络（PDPCIN），并提出了分层异构图神经网络（HHGNN）框架和相关策略，有效解决了灾后通信中断问题，并实现了信息年龄、能量效率和频谱效率的协同优化。

> **ai_Abstract:** 本文提出了一种灾后供电通信智能网络（PDPCIN），旨在解决灾后地面基站故障造成的通信中断。该网络利用无人机进行无线数据收集和能量传输，并通过低轨卫星中继数据。为协同优化信息年龄（AoI）、能量效率和频谱效率，文章提出了IS-UAV架构、AFTU机制和DMLA策略。针对存在的时变任务-资源不平衡、复杂拓扑和多维指标非线性耦合等NP难问题，本文引入了分层异构图神经网络（HHGNN）框架，将网络建模为分层异构图，并设计了图感知、交换和掩码层。此外，还提出了单低轨卫星密度优化（S-LSDO）算法。实验结果表明，该方案在AoI、能量效率和频谱效率的协同优化方面优于现有技术，并推导了AoI相关指标的期望值表达式。

> **摘要翻译:** 本文设计了一种灾后供电通信智能网络（PDPCIN），以解决灾后区域内地面基站（GBS）故障导致的通信中断问题。PDPCIN利用无人机（UAV）为受灾区域提供无线数据收集（WDC）和无线能量传输（WET），并利用低地球轨道卫星（LEO SATs）将无人机数据中继到最近的幸存GBS。为了确保基本的灾后通信，同时协同优化信息年龄（AoI）、能量效率和频谱效率，本文提出了智能同步无人机（IS-UAV）架构、基于AoI的四阈值更新（AFTU）机制和动态多低轨卫星接入（DMLA）策略。然而，仍然存在三个关键挑战：时变的任务-资源不平衡、多设备调度导致的复杂拓扑以及多维指标优化中的非线性耦合，这些使得系统优化成为NP难问题。因此，本文提出了一种分层异构图神经网络（HHGNN）框架。它将异构设备节点及其通信关系建模为分层异构图结构，并集成了我们定义的图感知、交换和掩码层来处理网络的输入、特征传播和输出。为了搜索合适的单低轨卫星数量，我们提出了单低轨卫星密度优化（S-LSDO）算法。最后，我们将所提出的方案与最先进的基准方案进行比较，以验证其在AoI、能量效率和频谱效率协同优化方面的优越性。在此基础上，我们推导了AoI和停滞AoI比例的期望值表达式。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [20] [Joint Detection and Decoding: A Graph Neural Network Approach](https://arxiv.org/abs/2501.08871)
> *联合检测与解码：一种图神经网络方法*

*Jannis Clausius, Marvin Rübenacke, Daniel Tandler, Stephan ten Brink* | **Category: cs.IT, math.IT** | **Updated: 2025-07-15**

**Keywords:** 图神经网络, 联合检测与解码, 符号间干扰, 因子图, 端到端学习

**Comment:** Submitted to Transactions on Communications (R1). arXiv admin note:
  text overlap with arXiv:2401.16187

> **TL;DR:** 本文提出一种基于图神经网络（GNN）的方法，用于符号间干扰（ISI）信道中的检测和联合检测与解码（JDD），该方法对因子图中的循环和信道状态信息不确定性具有鲁棒性，并实现了显著的性能提升。

**AI_Comments:** 该论文的创新点在于将图神经网络（GNN）应用于联合检测与解码（JDD），成功解决了传统和积算法（SPA）在因子图循环和信道状态信息不确定性方面的局限性。通过实现端到端学习和提出并行泛洪调度，不仅提升了性能，还降低了延迟，展现了深度学习在通信接收器设计中的巨大潜力。特别是6.25 dB的增益，表明了GNN在该领域的重要性和可行性。

<details>
  <summary>Details</summary>

**Motivation:** 缩小符号间干扰（ISI）信道中最佳检测与可行检测之间的性能差距，并解决基于和积算法（SPA）的检测中因子图循环问题以及接收端信道状态信息（CSI）不确定性问题。

**Method:** 本文提出使用图神经网络（GNN）进行检测和联合检测与解码（JDD）。对于检测，GNN构建在信道的因子图表示之上；对于JDD，因子图通过信道编码的奇偶校验矩阵（PCM）的Tanner图进行扩展，共享变量节点。GNN的优势在于其对因子图中的循环和接收端CSI不确定性的鲁棒性。此外，提出使用输入嵌入使GNN独立于信道冲激响应（CIR），实现端到端学习。还提出了一种并行泛洪调度，以降低延迟并提高纠错性能。

**Result:** GNN方法对因子图中的循环和信道状态信息（CSI）不确定性表现出鲁棒性。通过输入嵌入，GNN独立于信道冲激响应（CIR）。并行泛洪调度降低了延迟并改善了纠错性能。在高速率涡轮检测和解码（TDD）场景中，对于高阶调制，GNN相比最佳可行非神经网络基线实现了6.25 dB的显著增益。

**Conclusion:** 所提出的基于图神经网络的检测和联合检测与解码方法，通过其对循环和CSI不确定性的鲁棒性、实现端到端学习的能力以及并行调度，显著提升了在ISI信道中的性能，特别是在高阶调制和高速率场景下。

> **ai_Abstract:** 本文提出一种基于图神经网络（GNN）的检测和联合检测与解码（JDD）方法，以解决符号间干扰（ISI）信道中的性能差距。该方法利用信道的因子图和编码的Tanner图构建GNN，并展现出对因子图循环和信道状态信息（CSI）不确定性的鲁棒性。通过引入输入嵌入，GNN实现了对信道冲激响应（CIR）的独立性，从而支持端到端学习。此外，采用并行泛洪调度以降低延迟并提升纠错性能。实验结果表明，该GNN方法在纠错能力和延迟方面优于现有基线，特别是在高阶调制和高速率场景下，相比最佳非神经网络基线取得了高达6.25 dB的增益。

> **摘要翻译:** 本文旨在缩小符号间干扰（ISI）信道中最佳检测与可行检测之间的性能差距，提出使用图神经网络（GNN）进行检测，该方法也可用于执行联合检测与解码（JDD）。对于检测，GNN构建在信道的因子图表示之上，而对于JDD，通过信道码的奇偶校验矩阵（PCM）的Tanner图扩展因子图，共享变量节点。GNN的一个特别有利的特性是：a) 对因子图中的循环具有鲁棒性，这是基于和积算法（SPA）的检测的主要问题；b) 对接收端信道状态信息（CSI）不确定性具有鲁棒性。此外，我们提出使用输入嵌入，使得GNN独立于信道冲激响应（CIR）。因此，一个完全基于深度学习的接收器能够实现联合优化，而不是各个组件的单独优化，即所谓的端到端学习。此外，我们提出了一种并行泛洪调度，该调度也降低了延迟，并被证明可以提高纠错性能。所提出的方法在纠错能力和延迟方面，针对不同的调制和编码，进行了分析并与最先进的基线进行了比较。与基于SPA的检测相比的增益可能归因于节点之间改进的消息传递和消息的自适应阻尼。在高速率涡轮检测和解码（TDD）场景中，对于高阶调制，GNN与最佳可行非神经网络基线相比，显示出初看之下令人惊讶的6.25 dB的高增益。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [74] [Lowering the Error Floor of Error Correction Code Transformer](https://arxiv.org/abs/2502.09065)
> *降低纠错码Transformer的错误平层*

*Taewoo Park, Seong-Joon Park, Hee-Youl Kwak, Sang-Hyo Kim, Yongjune Kim* | **Category: cs.IT, math.IT** | **Updated: 2025-07-15**

**Keywords:** 纠错码Transformer, 错误平层, 混合解码, 损失函数, 硬判决解码器

**Comment:** 6 pages

> **TL;DR:** 纠错码Transformer (ECCT) 存在未被探索的错误平层问题，限制了其有效性。本文首次研究该问题，并提出一种结合传统硬判决解码器和新型损失函数的混合解码框架，有效降低了错误平层，显著提升了ECCT的性能。

**AI_Comments:** 本文首次关注并解决了ECCT在实际应用中面临的关键“错误平层”问题，具有重要的实践意义。其创新点在于提出了一种结合传统硬判决解码器和新型损失函数的混合解码框架，特别是损失函数的设计，能够有效引导ECCT关注并纠正残余错误，这为Transformer在纠错码领域的进一步应用提供了新的思路和性能提升途径。

<details>
  <summary>Details</summary>

**Motivation:** 纠错码Transformer（ECCT）尽管具有优越的解码性能，但其解码中存在的错误平层问题尚未被探索，这限制了其在实际应用中的有效性。

**Method:** 本文提出了一种混合解码框架，将ECCT与传统硬判决解码器集成。核心贡献在于设计了一种新颖的损失函数，该函数在训练过程中明确考虑了ECCT与硬判决解码器之间的相互作用，旨在引导ECCT专注于纠正硬判决阶段未能处理的残余错误。

**Result:** 仿真结果表明，采用所提出的损失函数训练的混合解码器在瀑布区和错误平层区都比标准ECCT取得了显著的性能提升。

**Conclusion:** 本文提出的混合解码框架和新颖的损失函数能够有效解决纠错码Transformer（ECCT）的错误平层问题，显著提升其解码性能和在实际应用中的有效性。

> **ai_Abstract:** 本文首次深入探讨了纠错码Transformer (ECCT) 中的错误平层问题，指出其限制了ECCT在实际应用中的有效性。为解决此问题，研究提出了一种创新的混合解码框架，该框架将ECCT与传统硬判决解码器相结合，并引入了一种新颖的损失函数。此损失函数专门用于引导ECCT学习并纠正硬判决解码器未能处理的残余错误，从而有效降低了错误平层。实验结果表明，该方法在解码性能上显著优于传统ECCT。

> **摘要翻译:** 随着Transformer架构在各种应用中取得成功，纠错码Transformer（ECCT）因其卓越的解码性能而受到广泛关注。尽管其具有优势，但ECCT解码中的错误平层问题仍未被探索。我们首次对此问题进行了调查，揭示了ECCT确实存在错误平层，这限制了其在实际设置中的有效性。为了解决这个错误平层问题，我们采用了一种混合解码框架，将ECCT与传统的硬判决解码器相结合。与之前的混合解码方案不同，我们的主要贡献在于提出了一种新颖的损失函数，该函数在训练过程中明确考虑了ECCT与硬判决解码器之间的相互作用。所提出的损失函数引导ECCT专注于硬判决阶段未纠正的残余错误，从而有效地降低了错误平层。仿真结果证实，采用所提出的损失函数训练的混合解码器在瀑布区和错误平层区都比标准ECCT获得了显著的性能提升。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [122] [Hyperbolic decomposition of Dirichlet distance for ARMA models](https://arxiv.org/abs/2504.01860)
> *ARMA模型Dirichlet距离的双曲分解*

*Jaehyung Choi* | **Category: cs.IT, math.IT** | **Updated: 2025-07-14**

**Keywords:** ARMA模型, Dirichlet距离, 双曲分解, Kähler信息几何, 模型降阶

**Comment:** 10 pages

> **TL;DR:** 本文研究了ARMA模型Dirichlet范数和距离的双曲分解，并发现它们可以分解为模型零点和极点之间双曲距离的函数，有助于模型降阶。

**AI_Comments:** 该研究通过将Dirichlet距离分解为双曲距离的函数，为理解ARMA模型提供了新的几何视角。其创新之处在于将Kähler信息几何应用于ARMA模型，并揭示了距离与模型零点和极点之间的深层联系，这对于模型降阶具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究ARMA模型Dirichlet范数和距离的双曲分解。

**Method:** 利用Hardy空间和加权Hardy空间中线性系统的Kähler信息几何。

**Result:** Dirichlet范数和距离被分解为ARMA模型零点和极点之间双曲距离的函数。距离也通过AR部分、MA部分和AR-MA交叉项的独立项表示。双曲分解有助于ARMA模型降阶。

**Conclusion:** ARMA模型的Dirichlet距离可以进行双曲分解，且这种分解有助于模型降阶。

> **ai_Abstract:** 本文利用Hardy空间和加权Hardy空间中线性系统的Kähler信息几何，研究了ARMA模型Dirichlet范数和距离的双曲分解。研究表明，Dirichlet范数和距离可以分解为模型零点和极点之间双曲距离的函数，并且该距离还可以表示为AR部分、MA部分和AR-MA交叉项的独立项。此外，该双曲分解对ARMA模型的降阶具有帮助。

> **摘要翻译:** 我们研究了自回归移动平均（ARMA）模型之间Dirichlet范数和距离的双曲分解。利用Hardy空间和加权Hardy空间中线性系统的Kähler信息几何，我们证明了ARMA模型的Dirichlet范数和距离（对应于过去和未来之间的互信息）被分解为ARMA模型零点和极点之间双曲距离的函数。此外，该距离也用来自AR部分、MA部分和AR-MA交叉项的独立项表示。此外，双曲分解有助于ARMA模型的模型阶次降低。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [163] [Neural Coding Is Not Always Semantic: Towards the Standardized Coding Workflow in Semantic Communications](https://arxiv.org/abs/2505.18637)
> *神经编码并非总是语义的：迈向语义通信中的标准化编码工作流*

*Hai-Long Qin, Jincheng Dai, Sixian Wang, Xiaoqi Qin, Shuo Shao, Kai Niu, Wenjun Xu, Ping Zhang* | **Category: cs.IT, math.IT** | **Updated: 2025-07-15**

**Keywords:** 语义通信, 神经编码, 语义表示, 上下文建模, 标准化编码

**Comment:** 

> **TL;DR:** 当前语义通信中的神经编码可能未能完全捕获语义意义；本文提出了一种基于上下文建模的标准化语义编码方案，用于通用语义表示。

**AI_Comments:** 本文通过质疑通用神经特征提取是否固有地捕获语义，解决了语义通信中的一个基本问题。其贡献在于提出了一种标准化、上下文感知的语义编码工作流，这对于推动该领域超越单纯的数据压缩，走向真正的意义传达至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 当前的语义通信系统采用神经编码从原始数据中提取特征，但尚未充分解决深度神经网络进行通用特征提取是否足以理解原始数据中的语义意义这一基本问题。本文旨在阐明语义理解和通用语义表示这两个关键方面。

**Method:** 本文提出了一种语义编码的标准化定义，以及一种基于上下文建模的扩展神经编码方案，用于通用语义表示，该方案清晰地表示了底层数据语义。

**Result:** 通过获得的这些通用语义表示，只需进行最少的专门修改（如微调和正则化），即可实现以人机为中心的端到端数据传输。

**Conclusion:** 本文有助于确立一种共识，即语义通信远远超出了单纯的特征传输，而是侧重于通过上下文感知编码方案传输紧凑的语义表示。

> **ai_Abstract:** 鉴于当前语义通信中神经编码在特征提取上可能无法充分捕获语义意义，本文提出了一种基于上下文建模的标准化语义编码定义和扩展神经编码方案，旨在实现通用的语义表示。通过这种方法，可以高效地实现以人机为中心的端到端数据传输，强调语义通信应侧重于通过上下文感知编码传输紧凑的语义表示，而非仅仅进行特征传输。

> **摘要翻译:** 语义通信利用先进的深度学习技术，作为满足下一代无线网络需求的新范式出现。然而，当前采用神经编码从原始数据中提取特征的语义通信系统，尚未充分解决一个基本问题：深度神经网络进行通用特征提取是否足以理解语义通信中原始数据内的语义意义？因此，本文旨在阐明两个关键方面：语义理解和通用语义表示。本文提出了一种语义编码的标准化定义，一种用于通用语义表示的扩展神经编码方案，该方案基于上下文建模清晰地表示了底层数据语义。通过获得的这些通用语义表示，只需进行最少的专门修改，如微调和正则化，即可实现以人机为中心的端到端数据传输。本文有助于确立一种共识，即语义通信远远超出了单纯的特征传输，而是侧重于通过上下文感知编码方案传输紧凑的语义表示。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [198] [SIC-Free Rate-Splitting Multiple Access: Constellation-Constrained Optimization and Application to Large-Scale Systems](https://arxiv.org/abs/2506.12668)
> *无SIC速率分割多址：星座约束优化及其在大规模系统中的应用*

*Sibo Zhang, Bruno Clerckx, David Vargas* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-15**

**Keywords:** 速率分割多址, 无SIC, 星座约束, 优化, 大规模系统

**Comment:** Submitted to IEEE for publication

> **TL;DR:** 本文研究了在有限星座下，无SIC的速率分割多址（RSMA）的理论极限及其在大规模系统中的应用。结果表明，无SIC的RSMA性能损失很小，是未来实现的有效选择。

**AI_Comments:** 这篇论文的创新点在于研究了在没有连续干扰消除（SIC）的情况下速率分割多址（RSMA）的性能，这对于降低实际系统的复杂性和延迟至关重要。它不仅评估了理论极限，还提出了解决大规模系统计算复杂度的实际方法，使其研究更具应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 速率分割多址（RSMA）是未来无线通信系统中有前景的多址技术。在实际系统中，无连续干扰消除（SIC）接收机因其低复杂度、低延迟而比SIC接收机更具吸引力。本研究的动机是评估在有限星座下无SIC RSMA的理论极限，并解决其在大规模系统应用中面临的计算复杂度挑战。

**Method:** 1. 推导了RSMA的星座约束速率表达式。2. 设计了基于投影次梯度上升的算法，以优化预编码器并最大化加权和速率或用户间的最大最小公平性。3. 提出了避免星座约束速率表达式带来的指数级计算负担的方法，以支持在大规模系统中的应用。

**Result:** 在优化预编码器的情况下，与带有SIC接收机的RSMA相比，无SIC的RSMA在加权和速率和最大最小公平性方面仅导致微小损失。

**Conclusion:** 无SIC的RSMA是一种可行的选择，适用于未来的无线通信系统实现。

> **ai_Abstract:** 本文研究了无SIC接收机的速率分割多址（RSMA）在有限星座下的理论性能极限和大规模系统应用。文章首先推导了星座约束的RSMA速率表达式，并设计了基于投影次梯度上升的算法来优化预编码器以最大化系统性能。为了解决大规模系统中的高计算复杂度问题，提出了相应的避免方法。数值结果表明，无SIC的RSMA在性能上与有SIC的RSMA相比损失很小，证明了其在未来无线通信系统中的实际应用潜力。

> **摘要翻译:** 速率分割多址（RSMA）已被认为是未来无线通信系统中有前景的多址技术。最近的研究表明，RSMA可以在不依赖连续干扰消除（SIC）接收机的情况下保持其优越性。在实际系统中，无SIC接收机因其低复杂度和低延迟而比SIC接收机更具吸引力。本文评估了在有限星座下有SIC和无SIC接收机的RSMA的理论极限。我们首先推导了RSMA的星座约束速率表达式。然后，我们设计了基于投影次梯度上升的算法来优化预编码器，以最大化加权和速率或用户间的最大最小公平性。为了将所提出的优化算法应用于大规模系统，一个挑战在于星座约束速率表达式带来的指数级计算复杂度。鉴于此，我们提出了避免这种计算负担的方法。数值结果表明，在优化预编码器的情况下，与带有SIC接收机的RSMA相比，无SIC的RSMA在加权和速率和最大最小公平性方面仅导致微小损失，使其成为未来实现的可行选择。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [238] [Secure Cooperative Gradient Coding: Optimality, Reliability, and Global Privacy](https://arxiv.org/abs/2507.07565)
> *安全协作梯度编码：最优性、可靠性和全局隐私*

*Shudi Weng, Chao Ren, Yizhou Zhao, Ming Xiao, Mikael Skoglund* | **Category: cs.IT, math.IT** | **Updated: 2025-07-15**

**Keywords:** 联邦学习, 安全聚合, 梯度编码, 隐私保护, 不可靠通信

**Comment:** 

> **TL;DR:** 本文提出安全协作梯度编码（SecCoGC）及其扩展Fair-SecCoGC，以解决不可靠通信下联邦学习中的隐私保护和安全聚合问题，实现了强隐私保护和高准确性。

**AI_Comments:** 本文创新性地将梯度编码应用于解决联邦学习中不可靠通信下的安全聚合和隐私保护问题，特别是提出了SecCoGC和Fair-SecCoGC，有效平衡了隐私、可靠性和模型准确性。其对多种隐私度量和间歇性网络的考虑增加了方案的实用性，且实验结果显示出显著的性能提升，具有重要的研究和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在不可靠通信环境下，隐私敏感的联邦学习面临挑战，主要体现在安全聚合中密钥协调被随机中断导致全局模型无法精确恢复，以及通信不可靠可能扭曲优化轨迹，使全局模型偏离预期全局最优。

**Method:** 本文提出了安全协作梯度编码（SecCoGC），这是一种实现精确聚合、具有任意强隐私保证且对通信不确定性固有鲁棒的实用解决方案。为确保隐私保护的公平性，进一步引入了Fair-SecCoGC，它能在每密钥总功率约束下实现最优隐私。研究正式构建了实域中的安全聚合问题，并提供了密钥构建的通用和计算高效方法。隐私分析涵盖所有协议层的局部互信息隐私（LMIP）和局部差分隐私（LDP），并考虑了间歇性网络和密钥相关性。此外，还描述了所提方案的系统可靠性和收敛特性。

**Result:** 实验结果表明，SecCoGC对不可靠通信具有强大的弹性，同时保持任意强的隐私保证，与现有隐私保护方法相比，测试准确性提高了20%到70%。

**Conclusion:** 本文提出的SecCoGC及其扩展Fair-SecCoGC有效解决了不可靠通信下联邦学习中的安全聚合与隐私保护问题，实现了在保持高准确性的同时，提供强大的隐私保证和对通信不确定性的鲁棒性。

> **ai_Abstract:** 本文针对不可靠通信环境下联邦学习中的隐私保护和安全聚合问题，提出了一种名为安全协作梯度编码（SecCoGC）的解决方案。SecCoGC能够实现精确聚合、提供强大的隐私保证，并对通信不确定性具有固有鲁棒性。为确保隐私公平性，论文还引入了Fair-SecCoGC，并在实验中验证了其在不可靠通信下的强大韧性以及相比现有方法显著提升的测试准确性，同时保持了任意强的隐私保护。

> **摘要翻译:** 本文研究了在不可靠通信下的隐私敏感联邦学习（FL），重点关注安全聚合和掉队者缓解。为了在不损害全局模型效用的前提下保护用户隐私，安全聚合通过协调参与客户端之间隐私保护噪声（密钥）的使用，成为一种有前景的方法。然而，不可靠的通信会随机中断密钥协调，并阻止安全聚合中全局模型的精确恢复。此外，不可靠的通信会扭曲优化轨迹，导致全局模型进一步偏离预期的全局最优。为了解决这些挑战，我们提出了安全协作梯度编码（SecCoGC），这是一种实现精确聚合、具有任意强隐私保证且对通信不确定性固有鲁棒的实用解决方案。为确保隐私保护的公平性，我们进一步引入了Fair-SecCoGC，它是SecCoGC的扩展，强制在所有客户端之间实现公平的隐私保护。值得注意的是，Fair-SecCoGC在每密钥总功率约束下实现了最优隐私。我们正式构建了实域中的安全聚合问题，并提出了密钥构建的通用和计算高效方法。我们的隐私分析涵盖所有协议层的局部互信息隐私（LMIP）和局部差分隐私（LDP），考虑了间歇性网络和密钥之间的相关性。此外，我们还描述了所提方案的系统可靠性和收敛特性。实验结果表明，SecCoGC对不可靠通信具有强大的弹性，同时保持任意强的隐私保证，与现有隐私保护方法相比，测试准确性提高了20%到70%。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [282] [Asymptotically Optimal Repair of Reed-Solomon Codes with Small Sub-Packetization under Rack-Aware Model](https://arxiv.org/abs/2507.11009)
> *具有小分包的Reed-Solomon码在机架感知模型下的渐近最优修复*

*Ke Wang, Zhongyan Liu, Rengang Li, Yaqian Zhao, Yaqiang Zhang* | **Category: cs.IT, math.IT** | **Updated: 2025-07-15**

**Keywords:** Reed-Solomon码, 渐近最优修复, 小分包, 机架感知, 分布式存储

**Comment:** This work has been accepted by 2025 IEEE Information Theory Workshop

> **TL;DR:** 本文提出了一种基于多基展开和单项式的新方法，用于在机架感知和同构存储模型下，以渐近最优的修复带宽和显著减小的分包大小修复Reed-Solomon码。

**AI_Comments:** 这篇论文通过引入多基展开和单项式的新颖方法，解决了Reed-Solomon码在分布式存储系统中修复效率和分包大小的挑战。其创新性在于在实现渐近最优修复带宽的同时，显著降低了分包要求，这对于实际部署具有重要意义。该研究不仅适用于机架感知模型，也适用于同构存储模型，显示了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为机架感知分布式存储系统中的Reed-Solomon (RS) 码提供具有小分包的渐近最优修复方案。

**Method:** 采用多基展开，并利用单项式来构建RS码的线性修复方案。

**Result:** 所提出的修复方案在所有允许参数下均能实现渐近最优的修复带宽，同时与现有方案相比显著减少了分包大小。此外，该方法在同构存储模型下也能以渐近最优的修复带宽修复RS码，并且分包大小小于现有方法。

**Conclusion:** 本研究成功提出了一种新的RS码修复方案，该方案在机架感知和同构存储模型下均能实现渐近最优的修复带宽，并显著降低了分包大小，优于现有方法。

> **ai_Abstract:** 本文研究了在机架感知分布式存储系统中，具有小分包的Reed-Solomon (RS) 码的渐近最优修复。作者提出了一种基于多基展开和单项式的新型线性修复方案。该方案在所有允许参数下均能实现渐近最优的修复带宽，并显著减小了分包大小，优于现有方法。同时，该方法也适用于同构存储模型，并能达到更小的分包。

> **摘要翻译:** 本文对具有小分包的Reed-Solomon（RS）码的渐近最优修复进行了全面研究，该研究专门针对机架感知分布式存储系统。通过利用多基展开，我们引入了一种新颖的方法，该方法利用单项式来构建RS码的线性修复方案。我们的修复方案适用于所有允许的参数，实现了渐近最优的修复带宽，同时与现有方案相比显著减少了分包。此外，我们的方法能够在同构存储模型下以渐近最优的修复带宽修复RS码，并且比现有方法实现了更小的分包。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [332] [Extropy Rate: Properties and Application in Feature Selection](https://arxiv.org/abs/2507.11242)
> *熵率：性质与特征选择中的应用*

*Naveen Kumar, Vivek Vijay* | **Category: cs.IT, math.IT, math.PR, 94A17, 62B10, 60G10, 62H30, 62P30** | **Updated: 2025-07-15**

**Keywords:** 熵率, 特征选择, 熵, 随机过程, 不确定性度量

**Comment:** 

> **TL;DR:** 本文定义了离散随机变量的条件熵率，探讨了其性质，并提出了一种基于熵率的特征选择方法，在多个数据集上表现出优越性。

**AI_Comments:** 这篇论文通过引入“熵率”这一新颖概念，扩展了信息论中熵（extropy）的应用范围。其创新之处在于不仅详细探讨了熵率的理论性质，更将其成功应用于实际的特征选择问题，并展示了超越现有方法的性能。这为信息度量和特征工程提供了一个强大的新工具，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** Extropy（熵的互补对偶）已引起研究界的广泛关注。本研究旨在深入探讨其新概念“熵率”的性质，将其作为衡量随机过程中平均不确定性的度量，并探索其在实际应用，特别是特征选择中的潜力。

**Method:** 本文定义了离散随机变量的条件熵，并建立了联合熵和条件熵的关键性质。在此基础上，引入了离散随机变量随机过程的熵率概念，并分析了其在无限平稳遍历随机过程和独立同分布序列中的渐近等价性。研究通过数值方法说明了熵率在信息捕获、复杂性量化和混沌动力学表征方面的有效性。此外，本文提出了一种基于熵率的特征选择新方法，该方法利用熵率较高的特征包含更多固有信息的原理。

**Result:** 研究建立了条件熵和联合熵的关键性质，并发现熵率对于无限平稳遍历随机过程和独立同分布序列具有渐近等价性。数值实验表明，熵率能有效捕获各种分布的潜在信息，量化时间序列数据的复杂性，并表征动力系统的混沌动力学。估计的熵率行为与Simpson多样性指数密切相关。提出的基于熵率的特征选择方法在六个公开数据集上表现出优于其他现有流行方法的性能。

**Conclusion:** 熵率是衡量随机过程平均不确定性的一种有效工具，具有重要的理论性质和广泛的应用潜力。特别是在特征选择领域，它提供了一种新颖且表现优越的方法，能够有效识别包含更多固有信息的特征。

> **ai_Abstract:** 本文深入研究了熵（extropy）的理论性质，特别是引入了“熵率”这一新概念，用于衡量离散随机变量随机过程的平均不确定性。研究详细阐述了条件熵和联合熵的关键性质，并证明了熵率在各种随机过程中的渐近行为。此外，文章还展示了熵率在信息捕获、复杂性量化和混沌动力学表征方面的有效性。最重要的是，论文提出了一种基于熵率的创新性特征选择方法，并通过在多个公开数据集上的实验验证了其相对于现有方法的显著优势。

> **摘要翻译:** 熵（extropy），作为熵的互补对偶（由Lad等人于2015年提出），引起了研究界的广泛关注。在本研究中，我们关注离散随机变量，并定义了条件熵，建立了联合熵和条件熵的关键性质，例如界限、由于额外信息引起的不确定性减少以及Lipschitz连续性。我们进一步引入了离散随机变量随机过程的熵率概念，作为过程中每个随机变量的平均不确定性度量。据观察，对于无限平稳遍历随机过程以及独立同分布序列，熵率表现出渐近等价性。我们探索了有限随机过程的熵率，并数值说明了其在捕获各种分布的潜在信息、量化时间序列数据复杂性和表征动力系统混沌动力学方面的有效性。据观察，估计的熵率行为与Simpson多样性指数密切相关。熵率的实际应用通过一种新颖的特征选择方法呈现，该方法基于熵率较高的特征包含更多固有信息的事实。使用六个公开可用数据集，我们展示了所提出的特征选择方法优于其他一些现有流行方法。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [718] [Multivariate Analytic Combinatorics for Cost Constrained Channels](https://arxiv.org/abs/2111.06105)
> *多元解析组合学在成本受限信道中的应用*

*Andreas Lenz, Stephen Melczer, Cyrus Rashtchian, Paul H. Siegel* | **Category: cs.IT, cs.CC, cs.DM, math.CO, math.IT, E.4** | **Updated: 2025-07-14**

**Keywords:** 多元解析组合学, 成本受限信道, 生成函数, 信道容量, 渐近行为

**Comment:** Updated version

> **TL;DR:** 本文将多元解析组合学应用于成本受限信道，揭示了信道图结构与生成函数奇点之间的关系，并利用此关系推导了受限信道中序列的渐近行为，推广了香农的经典结果。

**AI_Comments:** 这项研究创新性地将多元解析组合学引入到信息论的成本受限信道分析中，建立了新的理论桥梁。通过揭示图结构与生成函数奇点之间的深层联系，不仅提供了计算受限序列渐近行为的强大工具，还成功推广了香农的经典信道容量理论，具有重要的理论意义和潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 研究在成本约束下离散无噪声信道中序列的信息论问题。

**Method:** 通过分析信道的图结构与双变量生成函数的奇点之间的关系，并利用多元解析组合学定理来推导满足成本约束的序列数量的渐近行为。

**Result:** 揭示了信道图结构与双变量生成函数奇点之间的关系；利用此关系获得了成本受限信道中可容许字符串数量的渐近行为；证明了成本受限信道容量由双变量生成函数的成本相关奇点决定，推广了香农的经典结果；提供了成本受限容量的组合定义和概率定义等价性的新证明。

**Conclusion:** 建立了多元解析组合学与带标签加权图之间的新桥梁，为成本受限信道的研究带来了新视角和强大工具，并推广了香农的经典信道容量结果。

> **ai_Abstract:** 本文将多元解析组合学应用于分析成本受限离散无噪声信道中的序列。研究揭示了信道图结构与相关双变量生成函数奇点之间的关系，并利用该关系推导了满足成本约束的序列数量的渐近行为。研究成果建立了多元解析组合学与带标签加权图之间的新联系，并推广了香农关于信道容量的经典结果，为成本受限信道研究提供了新的理论工具和视角。

> **摘要翻译:** 多元解析组合学是数学的一个分支，通过分析多元生成函数来推导组合量的渐近行为。我们研究了在成本约束下离散无噪声信道中序列的信息论问题。我们的主要贡献包括信道的图结构与双变量生成函数奇点之间的关系，该生成函数的系数是满足约束的序列数量。我们利用这些新结果调用多元解析组合学中的定理，以获得信道可接受的成本受限字符串数量的渐近行为。这在多元解析组合学和带标签加权图之间建立了一座新桥梁，为成本受限信道文献带来了新的视角和一套强大的结果。在此过程中，我们表明成本受限信道容量由双变量生成函数的成本相关奇点决定，这推广了香农关于无约束容量的经典结果，并提供了成本受限容量的组合定义和概率定义等价性的新证明。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [781] [Blind and Topological Interference Managements for Bistatic Integrated Sensing and Communication](https://arxiv.org/abs/2412.03956)
> *双基地综合感知与通信中的盲干扰管理和拓扑干扰管理*

*Jiayu Liu, Kai Wan, Xinping Yi, Robert Caiming Qiu, Giuseppe Caire* | **Category: cs.IT, math.IT** | **Updated: 2025-07-15**

**Keywords:** 双基地ISAC, 盲干扰对齐, 拓扑干扰管理, 干扰管理, 感知通信一体化

**Comment:** 

> **TL;DR:** 本文提出了针对双基地综合感知与通信（ISAC）系统的盲干扰对齐和拓扑干扰管理两种策略，以解决传感器端信息未知和信道未知导致的干扰问题，并证明了其在通信和感知自由度方面的性能优于传统方案。

**AI_Comments:** 本文的创新点在于将盲干扰对齐和拓扑干扰管理这两种在高斯干扰信道中已知的策略，首次引入并应用于双基地ISAC系统，有效解决了该系统中信息未知和信道未知所带来的特有干扰问题。其重要性在于为双基地ISAC系统的性能提升提供了新的理论和技术途径，特别是在提高感知精度和优化资源利用方面。该研究为未来双基地ISAC系统的设计和实现提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 在双基地综合感知与通信（ISAC）系统中，与单基地系统相比，主要挑战在于信息消息对传感器是未知的，因此被视为干扰，同时发射机与传感器之间的信道对发射机也是未知的。为了在最大化通信自由度的同时减轻传感器端的干扰，需要新的策略。

**Method:** 本文提出了两种策略：盲干扰对齐（blind interference alignment）和拓扑干扰管理（topological interference management）。这些策略在双基地ISAC背景下是新颖的，并用于具有异构相干时间或异构连接的双基地ISAC模型。

**Result:** 研究表征了在通信和感知自由度方面的ISAC权衡点。结果表明，新的权衡点优于感知专用和通信专用方案之间的时间共享。仿真结果表明，与将干扰视为噪声或连续干扰消除相比，所提出的方案显著改善了感知任务的信道估计误差。

**Conclusion:** 本文提出的盲干扰对齐和拓扑干扰管理策略，在双基地ISAC系统中有效缓解了干扰问题，并在通信和感知自由度方面取得了优越的权衡性能，显著提高了感知任务的信道估计精度。

> **ai_Abstract:** 本文研究了双基地综合感知与通信（ISAC）系统，该系统面临传感器无法获取信息消息和发射机无法获取信道信息的挑战。为解决这些干扰问题并最大化通信自由度，作者提出了盲干扰对齐和拓扑干扰管理两种新颖策略。研究表征了这些策略在通信和感知自由度上的ISAC权衡点，并证明其性能优于传统的时间共享方案。仿真结果进一步证实，所提方案能显著提高感知任务的信道估计精度。

> **摘要翻译:** 综合感知与通信（ISAC）系统与单独的感知和通信系统相比，在性能和资源效率方面提供了显著提升，这主要归因于无线资源、无线电波形和硬件平台的协同使用。本文重点研究具有分散多接收器和一个传感器的双基地ISAC系统。与单基地ISAC系统相比，双基地设置中的主要挑战在于信息消息对传感器是未知的，因此它们被视为干扰，而发射机（TX）和传感器之间的信道对发射机是未知的。为了减轻传感器端的干扰同时最大化通信自由度，我们引入了两种策略，即盲干扰对齐和拓扑干扰管理。尽管在高斯干扰信道背景下广为人知，但这些策略在双基地ISAC背景下是新颖的。对于具有异构相干时间或异构连接的双基地ISAC模型，我们表征了在通信和感知自由度方面的ISAC权衡点。特别是，我们表明新的权衡点优于感知专用和通信专用方案之间的时间共享。仿真结果表明，与在传感器端将干扰视为噪声和连续干扰消除相比，所提出的方案显著改善了感知任务的信道估计误差。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [93] [OpenGCRAM: An Open-Source Gain Cell Compiler Enabling Design-Space Exploration for AI Workloads](https://arxiv.org/abs/2507.10849)
> *OpenGCRAM：一个支持AI工作负载设计空间探索的开源增益单元编译器*

*Xinxin Wang, Lixian Yan, Shuhan Liu, Luke Upton, Zhuoqi Cai, Yiming Tan, Shengman Li, Koustav Jana, Peijing Li, Jesse Cirimelli-Low, Thierry Tambe, Matthew Guthaus, H. -S. Philip Wong* | **Category: cs.AR, cs.SY, eess.SY** | **Updated: 2025-07-14**

**Keywords:** GCRAM, 编译器, 开源, AI工作负载, 片上存储

**Comment:** 

> **TL;DR:** OpenGCRAM是一个开源的增益单元存储器（GCRAM）编译器，能快速生成定制化的GCRAM设计，以加速AI应用中GCRAM子系统的开发。

**AI_Comments:** OpenGCRAM的创新性在于提供了一个开源的、自动化的GCRAM编译器，这对于加速领域专用AI加速器中的片上存储设计具有重要意义。通过自动化设计和仿真，它降低了GCRAM技术的应用门槛，并使得设计人员能够更高效地进行设计空间探索，从而针对特定AI工作负载优化存储性能。其开源特性也促进了社区协作和技术发展。

<details>
  <summary>Details</summary>

**Motivation:** 增益单元存储器（GCRAM）比SRAM具有更高密度和更低功耗，且适用于片上存储，并可调整以适应不同工作负载，但其子系统的设计和优化耗时。

**Method:** 论文提出了OpenGCRAM，一个开源的GCRAM编译器。它能够为商用代工厂CMOS生成GCRAM存储体电路设计和DRC/LVS干净的版图，并根据用户配置（如字长和字数）提供面积、延迟和功耗仿真。

**Result:** OpenGCRAM实现了快速、准确、可定制和优化的GCRAM模块生成，缩短了设计时间，确保了工艺合规性，并提供了满足不同应用需求的性能定制化存储模块。

**Conclusion:** OpenGCRAM显著简化并加速了GCRAM存储器子系统的设计和优化过程，使其能更好地服务于AI工作负载。

> **ai_Abstract:** 本文介绍了OpenGCRAM，一个开源的增益单元存储器（GCRAM）编译器。GCRAM因其高密度和低功耗在AI加速器中具有潜力，但其设计优化过程耗时。OpenGCRAM旨在解决这一问题，它能为商用CMOS工艺自动生成DRC/LVS干净的GCRAM电路设计和版图，并提供面积、延迟和功耗仿真。该工具显著缩短了GCRAM块的设计时间，提高了定制化和优化能力，从而满足多样化的AI应用需求。

> **摘要翻译:** 增益单元存储器（GCRAM）比SRAM具有更高的密度和更低的功耗，使其成为领域专用加速器中片上存储的理想选择。为了支持具有不同流量和寿命指标的工作负载，GCRAM还提供高带宽、超低漏电功耗和宽范围的保持时间，这些都可以通过晶体管设计（如阈值电压和沟道材料）和通过改变工作电压动态调整。然而，设计和优化GCRAM子系统可能非常耗时。在本文中，我们提出了OpenGCRAM，一个开源的GCRAM编译器，能够为商用代工厂CMOS生成GCRAM存储体电路设计以及DRC-和LVS-干净的版图，同时根据用户指定的配置（例如，字长和字数）提供面积、延迟和功耗仿真。OpenGCRAM实现了快速、准确、可定制和优化的GCRAM模块生成，缩短了设计时间，确保了工艺合规性，并提供了满足各种应用需求的性能定制化存储模块。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [444] [Device-Level Optimization Techniques for Solid-State Drives: A Survey](https://arxiv.org/abs/2507.10573)
> *固态硬盘设备级优化技术：一项综述*

*Tianyu Ren, Yajuan Du, Jinhua Cui, Yina Lv, Qiao Li, Chun Jason Xue* | **Category: cs.AR** | **Updated: 2025-07-10**

**Keywords:** 固态硬盘, SSD优化, NAND闪存, FTL, ZNS, 存储挑战

**Comment:** 

> **TL;DR:** 本综述全面分析了固态硬盘（SSD）的架构、面临的关键挑战以及设备级优化技术，并指出了未来的研究方向，旨在指导开发平衡性能、寿命和安全性的下一代SSD。

**AI_Comments:** 本综述通过整合SSD优化方面的知识，解决了这些设备面临的关键挑战，因此具有重要意义。其涵盖架构、挑战、现有技术和未来研究方向的全面性，为不断发展的数据存储领域（特别是随着AI/LLM工作负载的兴起）的研究人员和开发者提供了宝贵的路线图。

<details>
  <summary>Details</summary>

**Motivation:** 随着存储需求的增长，固态硬盘（SSD）在可扩展性、耐用性、延迟和安全性方面面临严峻挑战，因此需要对其进行优化。

**Method:** 本综述通过以下步骤提供了全面分析：首先，审视SSD的基本组成部分；其次，讨论主要挑战；接着，探讨先进的优化技术；最后，强调开放的研究挑战。

**Result:** 本综述对SSD架构、关键挑战和设备级优化技术进行了全面分析，并强调了开放的研究挑战。

**Conclusion:** 本综述旨在指导未来研究，以开发在不断发展的存储生态系统中平衡性能、寿命和安全性的下一代SSD。

> **ai_Abstract:** 本综述全面分析了固态硬盘（SSD）的架构、当前面临的挑战（可扩展性、耐用性、延迟、安全性）以及设备级优化技术。它详细阐述了SSD的基本组成部分，讨论了可靠性下降和安全威胁等主要问题，并探讨了FTL增强和新兴架构等先进优化方案。论文还强调了开放的研究挑战，旨在指导未来开发平衡性能、寿命和安全性的下一代SSD。

> **摘要翻译:** 固态硬盘（SSD）以其高性能、高能效和高可靠性彻底改变了数据存储。然而，随着存储需求的增长，SSD在可扩展性、耐用性、延迟和安全性方面面临严峻挑战。本综述对SSD架构、关键挑战和设备级优化技术进行了全面分析。我们首先审视SSD的基本组成部分，包括NAND闪存结构、SSD控制器功能（例如地址映射、垃圾回收、磨损均衡）以及主机接口协议（SATA、SAS、NVMe）。接下来，我们讨论主要挑战，如可靠性下降、耐用性限制、延迟变化和安全威胁（例如安全删除、勒索软件防御）。然后，我们探讨了先进的优化技术，包括纠错机制、闪存转换层（FTL）增强以及分区命名空间（ZNS）SSD和灵活数据放置（FDP）等新兴架构。最后，我们强调了开放的研究挑战，例如QLC/PLC NAND可扩展性、性能-可靠性权衡以及针对AI/LLM工作负载的SSD优化。本综述旨在指导未来研究，以开发在不断发展的存储生态系统中平衡性能、寿命和安全性的下一代SSD。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [480] [LASANA: Large-scale Surrogate Modeling for Analog Neuromorphic Architecture Exploration](https://arxiv.org/abs/2507.10748)
> *LASANA：模拟神经形态架构探索的大规模替代模型*

*Jason Ho, James A. Boyle, Linshen Liu, Andreas Gerstlauer* | **Category: cs.AR** | **Updated: 2025-07-14**

**Keywords:** 替代模型, 神经形态架构, 机器学习, 模拟仿真, 能效

**Comment:** 

> **TL;DR:** LASANA提出了一种基于机器学习的方法，为模拟神经形态系统中的模拟子块创建快速、准确的替代模型，实现了比SPICE快三个数量级的仿真速度，同时保持低误差，解决了大规模神经形态架构探索中建模速度慢的问题。

**AI_Comments:** LASANA的创新之处在于它利用机器学习解决了神经形态系统设计中模拟部分建模速度慢的瓶颈。通过创建数据驱动的替代模型，它极大地加速了大规模神经形态架构的探索和优化，对于推动AI硬件发展具有重要意义。其显著的加速比和可控的误差证明了该方法的实用性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能工作负载需要更节能的处理方式，这促使了内存内或事件驱动计算的神经形态系统的发展。新兴的神经形态架构旨在结合传统数字设计与模拟计算的效率和新型器件技术。然而，快速探索和协同设计此类架构面临一个关键问题：缺乏快速准确的建模和仿真工具。典型的混合信号设计工具（如SPICE）对大型系统而言速度过慢，而现有行为建模方法虽然快但受限于特定架构，且能源和性能建模能力有限。

**Method:** 本文提出了LASANA，这是一种利用机器学习为数字后端架构中的模拟子块推导数据驱动替代模型的新方法。LASANA使用电路的SPICE级仿真来训练机器学习模型，以预测模拟/数字接口处的电路能耗、性能和行为。这些模型可以在现有行为模型之上提供能耗和性能标注，或作为模拟仿真的替代品。

**Result:** LASANA被应用于模拟交叉阵列和尖峰神经元电路。在运行MNIST和尖峰MNIST数据集时，LASANA替代模型展示出比SPICE快三个数量级的加速，同时能耗、延迟和行为误差分别小于7%、8%和2%。

**Conclusion:** LASANA通过提供快速且准确的模拟子块替代模型，极大地加速了大规模神经形态架构的探索和协同设计，有效解决了现有工具的局限性。

> **ai_Abstract:** LASANA是一种基于机器学习的新方法，用于为神经形态系统中的模拟子块创建数据驱动的替代模型。它通过使用SPICE级仿真训练ML模型来预测电路的能耗、性能和行为，从而解决了传统模拟仿真工具速度慢的问题。实验结果表明，LASANA在加速模拟神经形态架构探索方面表现出色，与SPICE相比，速度提升了三个数量级，同时保持了高精度。

> **摘要翻译:** 神经形态系统利用内存内或事件驱动计算，其动机是需要更节能地处理人工智能工作负载。新兴的神经形态架构旨在将传统数字设计与模拟计算的计算效率和新型器件技术相结合。在快速探索和协同设计此类架构中，一个关键问题是缺乏快速准确的建模和仿真工具。典型的混合信号设计工具将数字仿真器与像SPICE这样的模拟求解器集成在一起，这对于大型系统而言速度极慢。相比之下，模拟组件的行为建模速度更快，但现有方法固定于特定架构，且能源和性能建模能力有限。在本文中，我们提出了LASANA，这是一种新颖的方法，它利用机器学习来推导数字后端架构中模拟子块的数据驱动替代模型。LASANA使用电路的SPICE级仿真来训练机器学习模型，以预测模拟/数字接口处的电路能耗、性能和行为。这些模型可以在现有行为模型之上提供能耗和性能标注，或作为模拟仿真的替代品。我们将LASANA应用于模拟交叉阵列和尖峰神经元电路。在运行MNIST和尖峰MNIST时，LASANA替代模型展示出比SPICE快三个数量级的加速，同时能耗、延迟和行为误差分别小于7%、8%和2%。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [493] [SPICEAssistant: LLM using SPICE Simulation Tools for Schematic Design of Switched-Mode Power Supplies](https://arxiv.org/abs/2507.10639)
> *SPICEAssistant：LLM 利用 SPICE 仿真工具进行开关模式电源的原理图设计*

*Simon Nau, Jan Krummenauer, André Zimmermann* | **Category: cs.AR, cs.AI, cs.ET** | **Updated: 2025-07-14**

**Keywords:** 大型语言模型, SPICE仿真, 开关模式电源, 电子设计自动化, 原理图设计

**Comment:** 11 pages, 10 figures

> **TL;DR:** LLM结合SPICE仿真工具，显著提升开关模式电源原理图设计能力。

**AI_Comments:** 这项工作创新性地将LLM与SPICE仿真工具结合，弥补了LLM在解释复杂仿真结果和进行多步骤硬件设计方面的不足。通过提供仿真反馈机制，显著提升了LLM在特定工程设计任务中的实用性和准确性，为LLM在EDA领域的应用开辟了新路径。其重要性在于展示了LLM与专业工具结合的强大潜力，而非仅仅依赖其内部知识。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在电子设计自动化（EDA）领域理解、适应和尺寸化电子电路的能力尚不明确，特别是在解释SPICE等关键仿真工具的结果以及处理多步骤设计过程方面存在局限性。

**Method:** 本文提出了SPICEAssistant框架，为LLM提供广泛的工具选择，作为与SPICE的接口，使LLM能够灵活地与仿真器交互，以评估其对电路修改的影响。通过一个包含256个问题的基准测试评估了SPICEAssistant的性能，这些问题旨在测试其调整电路网表以完成不同SMPS设计任务的能力。

**Result:** 基准测试结果表明，仿真反馈有效地提高了LLM的SMPS设计能力。仿真迭代次数的增加会导致性能增强。SPICEAssistant框架在基准测试中显著优于独立的LLM GPT-4o约38%。

**Conclusion:** 结合SPICE仿真工具的SPICEAssistant框架显著提升了LLM在开关模式电源原理图设计中的性能。

> **ai_Abstract:** 本文介绍了SPICEAssistant框架，旨在解决大型语言模型（LLM）在电子设计自动化（EDA）领域，特别是在开关模式电源（SMPS）原理图设计中，解释SPICE仿真结果和处理多步骤设计过程的局限性。SPICEAssistant通过提供工具接口，使LLM能与SPICE仿真器灵活交互并评估电路修改。实验结果表明，仿真反馈显著提升了LLM的SMPS设计能力，且性能随仿真迭代次数增加而提升，SPICEAssistant在基准测试中比GPT-4o表现高出约38%。

> **摘要翻译:** 最先进的大型语言模型（LLM）在科学的许多领域中，在广泛的任务上表现出高性能。在电子设计自动化（EDA）领域，它们在理解、适应和尺寸化电子电路方面的能力尚未确定。本文重点关注LLM在印刷电路板（PCB）上开关模式电源（SMPS）设计中的应用。LLM在此背景下的特殊挑战包括其解释SPICE等关键仿真工具结果的能力有限，以及多步骤设计过程。为了解决这些挑战，我们提出了SPICEAssistant，一个为LLM提供广泛工具选择的框架。这些工具作为SPICE的接口，允许LLM灵活地与仿真器交互，以估计其对电路修改的影响。为了评估SPICEAssistant的性能，我们定义了一个包含256个问题的基准测试，测试其调整电路网表以完成不同SMPS设计任务的能力。基准测试结果表明，仿真反馈有效地提高了LLM的SMPS设计能力。仿真迭代次数的增加会导致性能增强。SPICEAssistant框架在基准测试中显著优于独立的LLM GPT-4o约38%。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [513] [Security Enclave Architecture for Heterogeneous Security Primitives for Supply-Chain Attacks](https://arxiv.org/abs/2507.10971)
> *针对供应链攻击的异构安全原语安全飞地架构*

*Kshitij Raj, Atri Chatterjee, Patanjali SLPSK, Swarup Bhunia, Sandip Ray* | **Category: cs.AR, cs.CR** | **Updated: 2025-07-15**

**Keywords:** SoC安全, 供应链攻击, 安全架构, 硬件安全, CITADEL

**Comment:** 

> **TL;DR:** CITADEL是一个模块化框架，旨在简化片上系统（SoC）安全架构的创建，有效防御供应链攻击，且资源开销极小。

**AI_Comments:** CITADEL提供了一种创新的方法，通过提供一个模块化、即插即用的框架来解决SoC安全问题，特别是应对关键且复杂的供应链攻击。其强调最小资源开销的特性，使其成为硬件设计中一个高度实用和有吸引力的解决方案。该框架针对各种威胁的可配置性是其主要优势。

<details>
  <summary>Details</summary>

**Motivation:** 设计安全可靠的片上系统（SoC）架构是一项复杂、耗时且容易出错的任务，即使是微小的疏忽也可能导致严重漏洞，尤其是在应对日益增长的供应链攻击威胁时。

**Method:** 本文引入了CITADEL，一个模块化、可配置的即插即用安全框架，由定制的知识产权（IP）模块组成。该框架被实例化以防御供应链威胁，并通过多个真实世界的案例研究展示其实际实现，评估其对硅面积和功耗的影响。

**Result:** CITADEL在各种ASIC技术中仅引入了极小的资源开销（硅面积和功耗），表明它是一种增强SoC安全性的实用解决方案。

**Conclusion:** CITADEL通过提供一个模块化、可配置的框架，有效克服了构建统一SoC安全架构以应对多种攻击向量（特别是供应链威胁）的挑战，且具有实际的资源效率。

> **ai_Abstract:** 本文介绍了CITADEL，一个模块化、可配置的安全框架，旨在简化片上系统（SoC）平台强大安全架构的创建。CITADEL由定制IP模块组成，能够构建多样化的安全机制，并特别演示了其在防御供应链威胁方面的应用。通过真实世界的案例研究以及在各种ASIC技术上的评估，研究表明CITADEL有效解决了统一安全架构的挑战，同时在硅面积和功耗方面仅带来极小的资源开销，使其成为增强SoC安全性的实用解决方案。

> **摘要翻译:** 设计用于片上系统 (SoC) 平台的安全架构是一项高度复杂且耗时的任务，通常需要数月开发和细致验证。即使是微小的架构疏忽也可能导致严重的漏洞，从而破坏整个芯片的安全性。为了应对这一挑战，我们引入了 CITADEL，一个模块化安全框架，旨在简化 SoC 强大安全架构的创建。CITADEL 提供一个可配置的、即插即用子系统，由定制的知识产权 (IP) 模块组成，能够构建针对特定威胁的各种安全机制。作为具体演示，我们实例化 CITADEL 以防御供应链威胁，说明该框架如何适应硬件安全领域最紧迫的问题之一。本文探讨了在构建能够解决多种攻击向量的统一安全架构时遇到的各种障碍，并提出了 CITADEL 克服这些障碍的策略。通过几个真实世界的案例研究，我们展示了 CITADEL 的实际实现，并对其在各种 ASIC 技术中的硅面积和功耗影响进行了彻底评估。结果表明，CITADEL 仅引入了极小的资源开销，使其成为增强 SoC 安全性的实用解决方案。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [518] [Mapping Fusion: Improving FPGA Technology Mapping with ASIC Mapper](https://arxiv.org/abs/2507.10912)
> *映射融合：使用ASIC映射器改进FPGA技术映射*

*Cunxi Yu* | **Category: cs.AR** | **Updated: 2025-07-15**

**Keywords:** FPGA, LUT映射, ASIC映射, 强化学习, FuseMap

**Comment:** 7 pages. to appear at MLCAD 2025

> **TL;DR:** 本文提出了FuseMap框架，利用ASIC映射器的能力并结合强化学习，显著提高了FPGA LUT映射的准确性，并减少了延迟和面积。

**AI_Comments:** 这项工作通过将传统上独立的ASIC技术映射器的概念与FPGA的LUT映射相结合，提出了一种创新的方法。利用强化学习进行设计特定选择是其亮点，有望为FPGA综合流程带来显著的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 传统上，FPGA的LUT映射与ASIC的标准单元映射是独立开发的。然而，本文的激励示例表明ASIC技术映射器有可能改善LUT映射的性能，促使研究如何将两者结合以实现增量改进。

**Method:** 提出了FuseMap框架，该框架通过利用强化学习在单元选择过程中做出设计特定的选择，从而在FPGA设计流程中改进LUT映射。

**Result:** FuseMap在广泛的基准测试、不同的技术库和技术映射器上进行评估，实验结果表明，它实现了更高的映射精度，同时减少了各种电路设计的延迟和面积。

**Conclusion:** FuseMap框架成功地利用ASIC映射器的能力并通过强化学习优化，显著提升了FPGA LUT映射的性能，在精度、延迟和面积方面均有改善。

> **ai_Abstract:** 本文提出了FuseMap框架，旨在通过利用ASIC技术映射器的能力并结合强化学习在单元选择中做出设计特定决策，来改进FPGA的LUT技术映射。传统上，ASIC和FPGA的映射方法是独立的。实验结果表明，FuseMap在多个基准测试中显著提高了映射精度，并有效降低了电路的延迟和面积。

> **摘要翻译:** LUT（查找表）映射是FPGA逻辑综合中的关键步骤，它将逻辑网络转换为可以直接使用FPGA的LUT实现的形式。FPGA LUT是一种灵活的数字存储结构，可以实现有限输入（通常是4到6个输入，取决于FPGA架构）的任何逻辑功能。LUT映射的目标是将布尔网络映射到LUT中，其中每个LUT可以实现具有固定输入数量的任何功能。与FPGA技术映射并行，ASIC技术映射将布尔网络映射到用户定义的标准单元，这传统上是与LUT映射算法分开开发的。然而，在这项工作中，我们的激励示例表明，ASIC技术映射器有可能提高LUT映射器的性能，使得标准单元映射和LUT映射能够以增量方式工作。
因此，我们提出了FuseMap框架，该框架通过利用强化学习在单元选择过程中做出设计特定的选择，来探索在FPGA设计流程中改进LUT映射的机会。FuseMap的有效性在广泛的基准测试、不同的技术库和技术映射器上进行了评估。实验结果表明，FuseMap在ISCAS 85/89、ITC/ISCAS 99、VTR 8.0和EPFL基准测试中收集的各种电路设计中，实现了更高的映射精度，同时减少了延迟和面积。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [560] [Elk: Exploring the Efficiency of Inter-core Connected AI Chips with Deep Learning Compiler Techniques](https://arxiv.org/abs/2507.11506)
> *Elk：探索深度学习编译器技术在核间互联AI芯片中的效率*

*Yiqi Liu, Yuqi Xue, Noelle Crawford, Jilong Xue, Jian Huang* | **Category: cs.AR, cs.DC, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 深度学习编译器, AI芯片, 核间互联, 效率, 优化

**Comment:** This paper is accepted at the 58th IEEE/ACM International Symposium
  on Microarchitecture (MICRO'25)

> **TL;DR:** Elk是一个深度学习编译器框架，通过优化计算、通信和I/O，显著提升了核间互联AI芯片的效率，平均达到理想性能的94%。

**AI_Comments:** Elk的创新之处在于其作为一个深度学习编译器框架，能够联合权衡并优化AI芯片中计算、通信和I/O这三个关键性能因素，从而克服了传统上难以平衡的冲突。其重要性体现在显著提升了核间互联AI芯片的实际效率，并为未来ICCA芯片的设计和开发提供了宝贵的工具和方法论。

<details>
  <summary>Details</summary>

**Motivation:** 为满足深度学习（DL）模型日益增长的需求，AI芯片正同时采用片外存储（如HBM）和高带宽低延迟的互联实现核间直接数据交换。然而，由于计算（核内执行）、通信（核间数据交换）和I/O（片外数据访问）之间存在根本性冲突，探索这些核间互联AI（ICCA）芯片的效率并非易事。

**Method:** 本文开发了Elk，一个深度学习编译器框架，旨在通过联合权衡上述三个性能因素来最大化ICCA芯片的效率。Elk将这些性能因素结构化为可配置参数，并在深度学习编译器中形成一个全局权衡空间。为了系统地探索这个空间并最大化整体效率，Elk采用了新的归纳算子调度策略和成本感知片上内存分配算法。它生成了全局优化的执行计划，能够最佳地重叠片外数据加载和片上执行。为了验证Elk的效率，研究人员基于真实的ICCA芯片IPU-POD4构建了一个功能完备的模拟器，并为不同互联网络拓扑的敏感性分析构建了一个ICCA芯片模拟器。

**Result:** Elk在ICCA芯片上平均达到了理想屋脊线性能的94%，这显示了在ICCA芯片上支持大型深度学习模型的益处。研究还展示了Elk能够为新型ICCA芯片开发进行架构设计空间探索的能力。

**Conclusion:** Elk通过其创新的深度学习编译器框架和优化策略，成功解决了ICCA芯片在计算、通信和I/O之间的效率权衡问题，显著提升了其性能，并为未来ICCA芯片的设计提供了有效的探索工具。

> **ai_Abstract:** 为解决核间互联AI（ICCA）芯片中计算、通信和I/O之间效率权衡的挑战，本文提出了Elk，一个深度学习编译器框架。Elk通过将这些性能因素参数化并构建全局权衡空间，采用归纳算子调度策略和成本感知片上内存分配算法，生成了优化执行计划，以最佳地重叠片外数据加载和片上执行。实验结果表明，Elk在ICCA芯片上平均达到了理想屋脊线性能的94%，有效支持了大型深度学习模型，并能辅助新型ICCA芯片的架构设计空间探索。

> **摘要翻译:** 为满足深度学习（DL）模型日益增长的需求，AI芯片正同时采用片外存储（如HBM）和高带宽低延迟的互联实现核间直接数据交换。然而，由于计算（核内执行）、通信（核间数据交换）和I/O（片外数据访问）之间存在根本性冲突，探索这些核间互联AI（ICCA）芯片的效率并非易事。
在本文中，我们开发了Elk，一个深度学习编译器框架，旨在通过联合权衡上述三个性能因素来最大化ICCA芯片的效率。Elk将这些性能因素结构化为可配置参数，并在深度学习编译器中形成一个全局权衡空间。为了系统地探索这个空间并最大化整体效率，Elk采用了新的归纳算子调度策略和成本感知片上内存分配算法。它生成了全局优化的执行计划，能够最佳地重叠片外数据加载和片上执行。为了验证Elk的效率，我们基于真实的ICCA芯片IPU-POD4构建了一个功能完备的模拟器，并为不同互联网络拓扑的敏感性分析构建了一个ICCA芯片模拟器。Elk在ICCA芯片上平均达到了理想屋脊线性能的94%，这显示了在ICCA芯片上支持大型深度学习模型的益处。我们还展示了Elk能够为新型ICCA芯片开发进行架构设计空间探索的能力。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [602] [ProtocolLLM: RTL Benchmark for SystemVerilog Generation of Communication Protocols](https://arxiv.org/abs/2506.07945)
> *ProtocolLLM：用于通信协议SystemVerilog生成的RTL基准测试*

*Arnav Sheth, Ivaxi Sheth, Mario Fritz* | **Category: cs.AR, cs.AI, cs.CL** | **Updated: 2025-07-15**

**Keywords:** LLM, SystemVerilog, HDL, 通信协议, 基准测试

**Comment:** Accepted at MLSysArch@ISCA 2025

> **TL;DR:** ProtocolLLM是首个针对通信协议SystemVerilog代码生成的基准测试套件，旨在评估LLM在硬件描述语言方面的能力。研究发现，当前大多数LLM模型在生成符合时序约束的SystemVerilog代码方面表现不佳。

**AI_Comments:** 该论文填补了LLM在硬件描述语言生成领域的一个重要空白，特别是针对复杂的通信协议。ProtocolLLM基准测试的引入具有创新性，它不仅关注语法和功能正确性，还特别强调了硬件设计中至关重要的时序正确性。研究结果揭示了当前LLM在处理硬件时序约束方面的局限性，为未来LLM在HDL生成方向的研究指明了重要的改进方向。这对于推动自动化硬件设计和验证具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在通用编程语言代码生成方面表现出色，但其在硬件描述语言（HDLs）如SystemVerilog中的潜力尚未充分探索。HDL代码生成面临独特的挑战，包括严格的时序语义、并发性和可综合性约束。此外，HDL设计流程还涉及结构代码生成之外的广泛任务，如测试平台开发、基于断言的验证、时序收敛以及片上通信的协议级集成。

**Method:** 本研究评估了开源和最先进的LLM在生成可综合且功能准确的SystemVerilog通信协议实现方面的能力。为此，引入了ProtocolLLM，这是首个专门针对这些协议的基准测试套件，涵盖了多个设计抽象级别和不同提示特异性。评估方法除了可综合性和语法正确性外，还侧重于时序正确性。

**Result:** 研究发现，大多数模型未能生成符合时序约束的通信协议SystemVerilog代码。

**Conclusion:** 当前的大多数LLM模型在生成符合时序约束的通信协议SystemVerilog代码方面存在显著不足，这表明在LLM应用于硬件描述语言生成方面仍需进一步研究和改进。

> **ai_Abstract:** 该论文介绍了ProtocolLLM，一个用于评估大型语言模型（LLMs）在SystemVerilog通信协议RTL代码生成方面能力的基准测试套件。鉴于LLM在通用代码生成领域的进步，但其在硬件描述语言（HDL）如SystemVerilog中的应用仍是未探索的领域，且HDL代码生成面临时序、并发和可综合性等独特挑战。研究评估了现有LLM生成可综合、功能准确且符合时序约束的SystemVerilog协议代码的能力，发现大多数模型难以生成满足时序约束的代码。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展在通用编程语言的代码生成方面表现出强大的性能。然而，它们在硬件描述语言（HDLs）如SystemVerilog中的潜力仍未得到充分探索。由于严格的时序语义、并发性和对正确硬件功能至关重要的可综合性约束，HDL代码生成带来了独特的挑战。此外，基于HDL的设计流程涵盖了结构代码生成之外的一系列广泛任务，包括测试平台开发、基于断言的验证、时序收敛和片上通信的协议级集成。在这项工作中，我们评估了开源和最先进的LLM在生成广泛使用的通信协议的可综合且功能准确的SystemVerilog实现方面的能力，这些协议是嵌入式和片上系统（SoC）的关键组件。我们引入了ProtocolLLM，这是首个专门针对这些协议的基准测试套件，其任务涵盖多个设计抽象级别和不同提示特异性。我们的评估方法除了可综合性和语法正确性外，还侧重于时序正确性。我们观察到大多数模型未能生成遵循时序约束的通信协议SystemVerilog代码。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [762] [SystolicAttention: Fusing FlashAttention within a Single Systolic Array](https://arxiv.org/abs/2507.11331)
> *SystolicAttention：将 FlashAttention 融合到单个脉动阵列中*

*Jiawei Lin, Guokai Chen, Yuanlong Li, Thomas Bourgeat* | **Category: cs.AR, cs.AI** | **Updated: 2025-07-15**

**Keywords:** SystolicAttention, FlashAttention, 脉动阵列, Transformer, 硬件加速

**Comment:** 

> **TL;DR:** 当前的脉动阵列在执行 FlashAttention 时面临挑战，因为其涉及频繁的数据交换和非矩阵操作。本文提出了 FSA，一种新的脉动阵列架构，包含 SystolicAttention 调度算法，旨在使 FlashAttention 完全在单个脉动阵列内运行，从而显著提高利用率和性能。

**AI_Comments:** 该论文的创新之处在于将整个 FlashAttention 过程，包括非矩阵操作，直接整合到单个脉动阵列中，而传统脉动阵列通常只擅长大型矩阵乘法。这种新颖的调度和架构设计直接解决了加速 Transformer 模型在专用硬件上遇到的关键瓶颈，提供了显著的性能提升和更好的资源利用率。

<details>
  <summary>Details</summary>

**Motivation:** Transformer 模型严重依赖缩放点积注意力 (SDPA)，通常使用 FlashAttention 算法实现。然而，当前的基于脉动阵列的加速器在执行 FlashAttention 时面临显著挑战。脉动阵列只能在连续且大型的矩阵乘法中实现高利用率，而 FlashAttention 需要频繁交错的矩阵乘法和 softmax 操作。脉动阵列与外部向量单元之间频繁的数据交换导致脉动阵列利用率低。此外，softmax 涉及大量非矩阵操作，不适合脉动阵列。矩阵乘法在脉动阵列上和 softmax 在向量单元上并发执行还会导致寄存器文件和 SRAM 端口争用，进一步降低性能。

**Method:** 为了克服这些限制，我们提出了 FSA，一种增强型脉动阵列架构，它使整个 FlashAttention 算法能够完全在单个脉动阵列内运行，无需外部向量单元。FSA 的核心是 SystolicAttention，一种新颖的调度算法，它以细粒度、逐元素重叠的方式将 FlashAttention 操作映射到脉动阵列上。这显著提高了阵列利用率，同时保留了原始浮点操作顺序以保持数值稳定性。

**Result:** 我们在可综合的 RTL 中实现了 FSA，并评估了其与最先进的商用加速器的性能。结果表明，与 AWS NeuronCore-v2 和 Google TPUv5e 相比，FSA 的注意力 FLOPs/s 利用率分别高出 1.77 倍和 4.83 倍，而面积开销仅约 10%。

**Conclusion:** 通过使用所提出的 FSA 架构和 SystolicAttention 调度，将整个 FlashAttention 算法集成到单个脉动阵列中，可以显著提高 Transformer 模型的硬件利用率和性能，克服传统脉动阵列的局限性。

> **ai_Abstract:** 本文介绍了一种名为 FSA 的增强型脉动阵列架构和 SystolicAttention 调度算法，旨在解决传统脉动阵列在运行 FlashAttention 时效率低下的问题。通过允许 FlashAttention 完全在单个脉动阵列内执行，并采用细粒度的操作映射，FSA 消除了对外部向量单元的需求，并显著提高了阵列利用率。实验结果表明，FSA 在注意力 FLOPs/s 利用率方面优于商用加速器，如 AWS NeuronCore-v2 和 Google TPUv5e，且仅带来极小的面积开销。

> **摘要翻译:** Transformer 模型严重依赖缩放点积注意力 (SDPA)，通常使用 FlashAttention 算法实现。然而，当前的基于脉动阵列的加速器在执行 FlashAttention 时面临显著挑战。脉动阵列只能在连续且大型的矩阵乘法中实现高利用率。相比之下，FlashAttention 需要频繁交错的矩阵乘法和 softmax 操作。脉动阵列和外部向量单元之间频繁的数据交换导致脉动阵列利用率低。softmax 涉及大量非矩阵操作，这些操作不适合脉动阵列，进一步加剧了这一问题。此外，矩阵乘法在脉动阵列上和 softmax 在向量单元上并发执行会导致寄存器文件和 SRAM 端口争用，进一步降低性能。
为了克服这些限制，我们提出了 FSA，一种增强型脉动阵列架构，它使整个 FlashAttention 算法能够完全在单个脉动阵列内运行，无需外部向量单元。FSA 的核心是 SystolicAttention，一种新颖的调度算法，它以细粒度、逐元素重叠的方式将 FlashAttention 操作映射到脉动阵列上。这显著提高了阵列利用率，同时保留了原始浮点操作顺序以保持数值稳定性。
我们在可综合的 RTL 中实现了 FSA，并评估了其与最先进的商用加速器的性能。我们的结果表明，与 AWS NeuronCore-v2 和 Google TPUv5e 相比，FSA 的注意力 FLOPs/s 利用率分别高出 1.77 倍和 4.83 倍，而面积开销仅约 10%。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [5] [Cyclic Data Streaming on GPUs for Short Range Stencils Applied to Molecular Dynamics](https://arxiv.org/abs/2507.11289)
> *GPU上的循环数据流用于分子动力学中的短程模板*

*Martin Rose, Simon Homes, Lukas Ramsperger, Jose Gracia, Christoph Niethammer, Jadran Vrabec* | **Category: cs.DC, cs.PF** | **Updated: 2025-07-15**

**Keywords:** GPU, 数据流, 分子动力学, 线性扩展, 并行计算

**Comment:** Accepted for publication at HeteroPar 2025 co-located with Euro-Par
  2025

> **TL;DR:** 本文提出一种基于GPU间高带宽通信的循环数据流框架，实现科学计算中显式算法的线性性能扩展，并在分子动力学模拟中表现优于LAMMPS。

**AI_Comments:** 该框架通过创新的循环数据流和时间并行化策略，解决了大规模科学计算中显式算法的性能扩展瓶颈。其优势在于简化了并行编程复杂性，使得用户可以专注于算法本身。与LAMMPS的对比结果突出了其在强扩展性方面的显著优势，对高性能计算领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了追求科学计算的最高性能，尤其是在处理受数据集大小和GPU数量限制的显式算法时，需要一个能够实现线性性能扩展的框架。

**Method:** 该框架通过在计算集群中利用GPU之间的高带宽通信实现。数据集切片以环形方式在进程（GPU）之间传播，从一个GPU处理后传到下一个，从而实现时间并行化。用户只需编写GPU核函数和提供数据集切片，无需了解底层并行策略。以Lennard-Jones势的分子动力学模拟作为案例研究。

**Result:** 该框架在强扩展性情况下优于LAMMPS，并实现了单节点性能和强扩展行为的测量。

**Conclusion:** 该循环数据流框架能有效提升科学计算中显式算法的性能，并在分子动力学模拟中展现出优越的强扩展性。

> **ai_Abstract:** 本文提出了一种用于科学计算的新型GPU循环数据流框架，该框架利用GPU间高带宽通信实现显式算法的线性性能扩展。通过将数据集切片在GPU环中循环处理，实现了时间并行化，且用户无需了解底层并行策略。在Lennard-Jones分子动力学模拟案例中，该框架在强扩展性方面超越了LAMMPS。

> **摘要翻译:** 在追求科学计算最高性能的过程中，我们提出了一种新颖的框架，它依赖于计算集群中GPU之间的高带宽通信。该框架为显式算法提供了线性性能扩展，其限制仅受数据集大小和GPU数量的影响。数据集的切片以进程（GPU）环形方式从一个GPU传播到下一个GPU，在那里进行处理，从而实现时间并行化。框架的用户只需编写实现算法的GPU核函数并提供数据集切片。由于进程间的通信由框架执行，因此不需要了解底层的并行化策略。作为案例研究，我们实现了基于Lennard-Jones势的分子动力学模拟，以测量均匀流体的性能。该框架的单节点性能和强扩展性行为与LAMMPS进行了比较，在强扩展性情况下表现优异。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [41] [A new Dune grid for scalable dynamic adaptivity based on the p4est software library](https://arxiv.org/abs/2507.11386)
> *基于p4est软件库的可扩展动态自适应Dune新网格*

*Carsten Burstedde, Mikhail Kirilin, Robert Klöfkorn* | **Category: cs.DC, 65M50, 65N50** | **Updated: 2025-07-15**

**Keywords:** Dune, p4est, 网格, 可扩展性, 自适应

**Comment:** 27 pages, 8 figures, 2 algorithms

> **TL;DR:** 本文介绍了一个基于p4est软件库的Dune求解器库的新网格接口，旨在提高其MPI可扩展性和支持多块网格拓扑。数值实验表明，该实现比现有的Dune-ALUGrid具有更好的可扩展性，并且提出了一种改进的2:1平衡策略。

**AI_Comments:** 本文的创新之处在于成功地将Dune求解器库与p4est软件库集成，显著提升了Dune在并行环境中的可扩展性，并引入了对多块网格拓扑的原生支持。这一点对于解决大规模并行计算中的网格管理和性能瓶颈至关重要。此外，提出的替代平衡策略也为网格自适应提供了性能优化。

<details>
  <summary>Details</summary>

**Motivation:** Dune求解器库需要一个具有卓越MPI可扩展性、更精简数据结构以及原生支持2D和3D多块（森林）网格拓扑的网格实现，而p4est软件库恰好能提供这些能力。

**Method:** 通过将Dune求解器库与开源p4est软件进行新的网格接口耦合来扩展Dune。将所提出的实现与基于Dune-ALUGrid的现有实现进行比较。此外，提出了一种替代的2:1平衡策略，以确保元素面之间的平衡。

**Result:** 所提出的基于p4est的实现与Dune-ALUGrid相比，在可扩展性方面表现更优。此外，所提出的替代平衡策略与p4est现有平衡策略相比，在数值示例中显示出改进的性能。

**Conclusion:** 基于p4est软件库的Dune新网格接口成功地提高了Dune的MPI可扩展性，并支持多块网格拓扑。新的实现和替代平衡策略在性能和可扩展性方面均优于现有方法。

> **ai_Abstract:** 本文介绍了一个Dune求解器库与开源p4est软件之间的新网格接口。该接口旨在利用p4est的卓越MPI可扩展性、精简数据结构以及对多块网格拓扑的原生支持。通过数值实验，该新实现与Dune-ALUGrid相比，在可扩展性方面表现出更优越的性能。此外，论文还提出了一种新的2:1平衡策略，该策略在数值测试中展示了比p4est现有策略更好的性能。

> **摘要翻译:** 在这项工作中，我们通过另一个网格接口将Dune求解器库扩展到开源p4est软件。虽然Dune已经通过其网格接口Dune-Grid支持大约十二种不同的网格实现，但我们进行这项新的耦合工作是为了继承p4est几乎无限的MPI可扩展性及其相对精简的数据结构，以及其对2D和3D多块（森林）网格拓扑的本地支持。
所提出的实现与基于Dune-ALUGrid的现有实现在并行环境中的各种挑战性测试示例中进行了比较。数值实验表明，本文提出的实现在可扩展性方面优于Dune-ALUGrid。此外，还提出了一种替代的平衡策略，以确保元素面之间的2:1平衡，与本文所考虑的数值示例中p4est现有的平衡策略相比，显示出改进的性能。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [77] [Quantifying the Energy Consumption and Carbon Emissions of LLM Inference via Simulations](https://arxiv.org/abs/2507.11417)
> *通过模拟量化LLM推理的能耗和碳排放*

*Miray Özcan, Philipp Wiesner, Philipp Weiß, Odej Kao* | **Category: cs.DC** | **Updated: 2025-07-15**

**Keywords:** LLM推理, 能耗, 碳排放, 模拟, GPU功耗模型

**Comment:** Presented at the Workshop on Performance and Energy Efficiency in
  Concurrent and Distributed Systems (PECS) at Euro-PAR'25

> **TL;DR:** 本文提出了一个模拟框架，用于评估LLM推理在不同部署设置下的能耗和碳排放，并展示了碳感知调度的潜力。

**AI_Comments:** 本文的创新之处在于填补了现有LLM部署模拟框架在能耗和碳排放评估方面的空白。通过引入GPU功耗模型和与能源系统协同模拟的结合，该研究提供了一个更全面、准确的工具来评估LLM的碳足迹。其重要性在于为未来开发更环保的LLM推理基础设施提供了关键洞察和基础，有助于实现碳中和目标。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）的环境影响日益显著，其中推理已占其总生命周期碳排放的一半以上。然而，现有用于确定高效LLM部署的模拟框架缺乏功耗概念，因此无法准确估计推理相关的排放。

**Method:** 首先，作者扩展了一个高保真LLM推理模拟器，加入了GPU功耗模型，该模型根据利用率指标估算功耗，从而能够分析批处理大小、序列长度和模型并行度等配置。其次，将模拟输出整合到能源系统协同模拟环境中，以量化特定电网条件下的碳排放，并探索碳感知调度的潜力。

**Result:** 该框架揭示了推理参数如何影响能源需求和碳足迹，在一个示例部署案例中展示了高达69.2%的可再生能源抵消潜力。

**Conclusion:** 该研究为未来碳感知推理基础设施的设计提供了基础。

> **ai_Abstract:** 本文提出了一个创新的模拟框架，用于量化大型语言模型（LLM）推理过程中的能耗和碳排放。该框架通过整合GPU功耗模型到现有LLM推理模拟器中，并将其输出与能源系统协同模拟环境相结合，从而能够详细分析不同部署参数（如批处理大小、序列长度）对能耗和碳足迹的影响。研究结果不仅揭示了这些参数的关键作用，还展示了高达69.2%的可再生能源抵消潜力，为设计更具碳意识的LLM推理基础设施奠定了基础。

> **摘要翻译:** 大型语言模型（LLM）的环境影响日益显著，其中推理目前已占其总生命周期碳排放的一半以上。然而，现有用于确定高效LLM部署的模拟框架缺乏功耗概念，因此无法准确估计推理相关的排放。我们提出了一个模拟框架，用于评估LLM推理在不同部署设置下的能耗和碳影响。首先，我们扩展了一个高保真LLM推理模拟器，加入了GPU功耗模型，该模型根据利用率指标估算功耗，从而能够分析批处理大小、序列长度和模型并行度等配置。其次，我们将模拟输出整合到能源系统协同模拟环境中，以量化特定电网条件下的碳排放，并探索碳感知调度的潜力。通过基于场景的分析，我们的框架揭示了推理参数如何影响能源需求和碳足迹，在一个示例部署案例中展示了高达69.2%的可再生能源抵消潜力，并为未来碳感知推理基础设施的设计提供了基础。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [113] [FLsim: A Modular and Library-Agnostic Simulation Framework for Federated Learning](https://arxiv.org/abs/2507.11430)
> *FLsim：一个模块化且与库无关的联邦学习模拟框架*

*Arnab Mukherjee, Raju Halder, Joydeep Chandra* | **Category: cs.DC, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 联邦学习, 模拟框架, 模块化, 基准测试, 分布式机器学习

**Comment:** 

> **TL;DR:** FLsim是一个模块化、可扩展、资源高效且与库无关的联邦学习模拟框架，旨在简化新型联邦学习技术的研究和基准测试。

**AI_Comments:** FLsim的创新之处在于其高度的模块化和库无关性，这极大地降低了联邦学习研究的门槛和复杂性。它通过提供灵活的配置选项，允许研究人员在受控环境中轻松探索不同的FL场景和算法，对于加速FL领域的进展具有重要意义。同时，对区块链的支持也为其未来的扩展性提供了更多可能性。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）新技术的研发和与现有先进解决方案的基准测试仍然充满挑战。

**Method:** 本文引入了FLsim，一个全面的联邦学习模拟框架。FLsim具有模块化、可扩展性、资源效率高和实验结果可控再现的特点。它通过用户友好的接口，允许用户通过作业配置自定义联邦学习需求，支持：(a) 定制数据分布，(b) 选择本地学习算法（与机器学习库无关），(c) 选择网络拓扑结构，(d) 定义模型聚合和共识算法，以及 (e) 可插拔的区块链支持。

**Result:** 通过一系列实验评估，FLsim在模拟各种先进联邦学习实验方面表现出有效性和多功能性。

**Conclusion:** FLsim有望成为联邦学习模拟框架的重大进展，为研究人员和实践者提供前所未有的灵活性和功能。

> **ai_Abstract:** FLsim是一个为联邦学习（FL）设计的综合模拟框架，旨在解决现有FL技术研究和基准测试的挑战。它具备模块化、可扩展性、资源效率和可重现性等特点，并允许用户自定义数据分布、本地学习算法、网络拓扑、聚合算法和区块链支持。实验证明FLsim在模拟多种先进FL实验方面表现出有效性和多功能性，有望为FL研究提供更大的灵活性和功能。

> **摘要翻译:** 联邦学习（FL）自2016年诞生以来取得了显著发展，从基本算法发展到为解决各种挑战和用例量身定制的复杂方法。然而，研究和基准测试新颖的联邦学习技术与众多已建立的先进解决方案相比仍然具有挑战性。为了简化这一过程，我们引入了FLsim，一个全面的联邦学习模拟框架，旨在满足文献中联邦学习工作流的各种要求。FLsim的特点是其模块化、可扩展性、资源效率和实验结果的可控重现性。其易于使用的界面允许用户通过作业配置指定定制的联邦学习需求，支持：(a) 定制数据分布，从非独立同分布（non-iid）数据到独立同分布（iid）数据，(b) 根据用户偏好选择本地学习算法，完全与机器学习库无关，(c) 选择说明节点间通信模式的网络拓扑，(d) 定义模型聚合和共识算法，以及 (e) 可插拔的区块链支持以增强鲁棒性。通过一系列实验评估，我们证明了FLsim在模拟各种先进联邦学习实验方面的有效性和多功能性。我们设想FLsim将标志着联邦学习模拟框架的重大进步，为研究人员和实践者提供前所未有的灵活性和功能。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [176] [Rise and Shine Efficiently! Tight Bounds for Adversarial Wake-up](https://arxiv.org/abs/2410.09980)
> *高效唤醒！对抗性唤醒的紧密界限*

*Peter Robinson, Ming Ming Tan* | **Category: cs.DC** | **Updated: 2025-07-15**

**Keywords:** 唤醒问题, 分布式网络, 下界, 对抗性唤醒, 算法

**Comment:** New Theorem 5

> **TL;DR:** 本文研究分布式网络中的唤醒问题，提出了紧密下界并设计了多种高效算法以快速唤醒所有节点，同时限制消息数量。

**AI_Comments:** 本文的创新之处在于首次为一类不要求节点学习大量网络拓扑信息的问题提供了超线性（关于n）的消息复杂度下界，这对于理解分布式唤醒问题的理论极限具有重要意义。同时，文章提出的一系列算法不仅在理论上与下界相匹配或接近，还在实用性上提供了高效的解决方案，特别是引入“唤醒距离”的概念，为解决此类问题提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 研究分布式网络中的唤醒问题，其中对手在任意时间唤醒部分节点，目标是尽快唤醒所有其他节点，同时发送尽可能少的消息。

**Method:** 1. 理论分析：证明了两种设置下的消息复杂性下界，包括KT0 LOCAL模型和KT1假设下的超线性下界。2. 算法设计：提出了多种新算法来补充下界结果，包括异步KT1 LOCAL算法、引入“唤醒距离”概念的同步KT1 LOCAL算法，以及异步KT0 CONGEST模型中的确定性建议方案。

**Result:** 1. 下界：在KT0 LOCAL模型中，随机算法在平均接收O(β)位建议时，消息复杂度下界为Ω( n^2 / (2^β log n) )。在KT1假设下，任何(k+1)-时间算法的消息复杂度下界为Ω( n^(1+1/k) )，这是首次针对此类问题的超线性下界。2. 新算法性能：异步KT1 LOCAL算法的时间与消息复杂度均为O( n log n )（高概率）。同步KT1 LOCAL算法引入“唤醒距离”ρ_awk，实现O( ρ_awk )轮和O( n^(3/2)√log n )消息（高概率），改进版达到近最优的O( ρ_awk log^3n )轮和O( n log^3n )消息。异步KT0 CONGEST模型中的确定性建议方案，时间复杂度O( ρ_awk log^2n )，消息复杂度O( n log^2n )，每个节点建议位数为O( log^2n )。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文深入研究了分布式网络中的对抗性唤醒问题，旨在以最少消息量快速唤醒所有节点。研究首先在KT0 LOCAL模型和KT1假设下，推导出了消息复杂度的紧密下界，其中KT1假设下的下界是该类问题首次获得的超线性下界。为弥补理论下界，文章进一步提出了多种高效的唤醒算法，包括异步KT1 LOCAL算法、基于“唤醒距离”概念的同步KT1 LOCAL算法以及异步KT0 CONGEST模型中的确定性建议方案，这些算法在时间、消息复杂度和所需建议量方面均展示出优异或近乎最优的性能。

> **摘要翻译:** 我们研究分布式网络中的唤醒问题，其中对手在任意时间唤醒部分节点，目标是尽快唤醒所有其他节点，同时发送尽可能少的消息。我们证明了以下下界：
* 我们首先考虑每个节点从一个能够观察整个网络但不知道哪些节点最初处于唤醒状态的预言机接收建议的设置。更具体地说，我们考虑带有建议的KT0 LOCAL模型。我们证明，如果节点平均只接收O(β)位建议，任何随机算法都必须发送Ω( n^2 / (2^β log n) )条消息。
* 对于KT1假设，我们表明任何(k+1)-时间算法需要Ω( n^(1+1/k) )条消息。我们的结果是首次针对不要求单个节点学习大量网络拓扑信息的问题的超线性（关于n）下界。
为了补充我们的下界结果，我们提出了几种新算法：
* 我们给出了一个异步KT1 LOCAL算法，以高概率在O( n log n )的时间和消息复杂度下解决唤醒问题。
* 我们引入了“唤醒距离”ρ_awk的概念，该距离以上限网络直径为界，并提出了一个同步KT1 LOCAL算法，以高概率在O( ρ_awk )轮和O( n^(3/2)√log n )消息内完成。我们还将这些思想扩展，以获得近最优的O( ρ_awk log^3n )轮和O( n log^3n )消息的时间和消息复杂度。
* 我们在异步KT0 CONGEST模型（带建议）中给出了确定性建议方案。特别是，我们获得了一个O( ρ_awk log^2n )-时间建议方案，发送O( n log^2n )消息，同时每个节点只需要O( log^2n )位建议。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [206] [AAPA: An Archetype-Aware Predictive Autoscaler with Uncertainty Quantification for Serverless Workloads on Kubernetes](https://arxiv.org/abs/2507.05653)
> *AAPA：一种用于Kubernetes无服务器工作负载的、具有不确定性量化的原型感知预测自动扩缩器*

*Guilin Zhang, Srinivas Vippagunta, Raghavendra Nandagopal, Suchitra Raman, Jeff Xu, Marcus Pfeiffer, Shreeshankar Chatterjee, Ziqi Tan, Wulan Guo, Hailong Jiang* | **Category: cs.DC** | **Updated: 2025-07-15**

**Keywords:** 自动扩缩, 无服务器, Kubernetes, 不确定性量化, 工作负载分类

**Comment:** 6 pages, 4 figures, 1 table. First three authors contributed equally.
  Correspondence to Hailong Jiang

> **TL;DR:** AAPA是一种原型感知预测自动扩缩器，通过将工作负载分类并应用定制策略，显著减少了Kubernetes无服务器工作负载的SLO违规和延迟，并引入了资源效率指数来评估权衡。

**AI_Comments:** AAPA通过引入工作负载原型分类和不确定性量化，为无服务器工作负载的自动扩缩提供了一种创新的方法。其亮点在于针对不同工作负载模式的定制化策略以及对预测不确定性的考虑。此外，发布AAPAset数据集和提出资源效率指数（REI）也为该领域的研究提供了有价值的工具和评估框架。尽管在某些情况下资源使用量较高，但其在降低SLO违规和延迟方面的显著改进使其具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在高性能计算中，Kubernetes等无服务器平台的自动扩缩在高度动态和异构的工作负载下仍然具有挑战性。现有方法常依赖统一的反应式策略或无条件的预测模型，忽视了工作负载语义和预测不确定性。

**Method:** AAPA是一种原型感知预测自动扩缩器，它将工作负载分为四种行为模式（SPIKE、PERIODIC、RAMP和STATIONARY），并应用定制的扩缩策略，同时进行基于置信度的调整。为了支持可复现评估，研究人员发布了AAPAset数据集。此外，论文提出了资源效率指数（REI）这一统一指标来平衡性能、成本和扩缩平滑性。

**Result:** 与Kubernetes HPA相比，AAPA将SLO违规减少了高达50%，延迟降低了40%。然而，在尖峰主导条件下，资源使用量会增加2-8倍。

**Conclusion:** 研究结果表明，在自动扩缩设计中，对工作负载异构性和不确定性进行建模至关重要。

> **ai_Abstract:** AAPA是一个针对Kubernetes无服务器工作负载的预测自动扩缩器。它通过识别工作负载的四种行为模式（SPIKE、PERIODIC、RAMP、STATIONARY）并应用定制的扩缩策略，同时量化不确定性，解决了现有自动扩缩方案的不足。该研究发布了AAPAset数据集以促进可复现评估，并引入了资源效率指数（REI）来衡量性能、成本和扩缩平滑性之间的权衡。实验结果显示，AAPA显著降低了SLO违规和延迟，但可能增加资源消耗，强调了建模工作负载异构性和不确定性的重要性。

> **摘要翻译:** 无服务器平台（如Kubernetes）在高性能计算中得到越来越多的采用，然而在高度动态和异构的工作负载下，自动扩缩仍然具有挑战性。现有方法通常依赖统一的反应式策略或无条件的预测模型，忽略了工作负载语义和预测不确定性。我们提出了AAPA，一种原型感知预测自动扩缩器，它将工作负载分类为四种行为模式——SPIKE（尖峰）、PERIODIC（周期性）、RAMP（斜坡）和STATIONARY（稳定）——并应用定制的扩缩策略，同时进行基于置信度的调整。为了支持可复现评估，我们发布了AAPAset，一个包含30万个Azure Functions工作负载窗口的弱标注数据集，涵盖了各种模式。与Kubernetes HPA相比，AAPA将SLO违规减少了高达50%，延迟降低了40%，尽管在尖峰主导条件下资源使用量增加了2-8倍。为了评估权衡，我们提出了资源效率指数（REI），一个平衡性能、成本和扩缩平滑度的统一指标。我们的结果表明，在自动扩缩设计中，对工作负载异构性和不确定性进行建模的重要性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [236] [Proactive Intra-GPU Disaggregation of Prefill and Decode in LLM Serving](https://arxiv.org/abs/2507.06608)
> *LLM服务中预填充和解码的主动式GPU内部分离*

*Xiaoxiang Shi, Colin Cai, Junjia Du* | **Category: cs.DC, cs.LG** | **Updated: 2025-07-15**

**Keywords:** LLM服务, GPU资源管理, 预填充解码分离, 动态工作负载, Nexus

**Comment:** 

> **TL;DR:** 本文提出Nexus系统，通过主动式GPU内部分离预填充和解码，动态管理资源，解决了现有方法在动态工作负载下适应性差的问题，显著提升了LLM服务的吞吐量并降低了延迟。

**AI_Comments:** 本文的创新点在于提出了“主动式”GPU内部分离的概念，区别于以往的反应式方法，并通过对GPU资源特性的深入分析（收益递减和内存带宽瓶颈）来指导资源动态分配，这对于提升LLM在动态工作负载下的服务效率至关重要。其方法论基于对底层硬件行为的理解，而非简单的启发式或反馈，具有较强的普适性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有LLM服务中的预填充和解码（PD）处理方式存在问题：整体服务（chunked prefill）有细粒度相位干扰；引擎级分离虽然避免干扰但硬件和协调开销高；先前的GPU内部分离方法是反应式的，无法预见性能问题，在动态工作负载下适应性差。本文旨在实现主动式GPU内部分离，以有效适应动态工作负载，解决预填充和解码在不同条件下对资源需求的冲突管理挑战。

**Method:** 1. 观察到GPU资源存在收益递减效应（饱和点后分配更多资源收益甚微）。2. 发现内存带宽竞争是关键瓶颈。3. 基于这些洞察，设计了一种动态分区GPU资源的方法，同时考虑计算能力、内存占用和带宽竞争，以主动分离预填充和解码阶段。系统名为Nexus。

**Result:** Nexus在不同LLM和工作负载下：吞吐量比vLLM高2.2倍；TTFT（Time To First Token）比vLLM低20倍；TBT（Time Between Tokens）比vLLM低2.5倍；性能比SGLang高2倍；并与分离式vLLM性能持平或超越。

**Conclusion:** 本文成功设计并实现了Nexus系统，通过主动式GPU内部分离预填充和解码，有效解决了动态工作负载下的适应性问题，显著提升了LLM服务的性能。

> **ai_Abstract:** 本文针对LLM服务中预填充和解码（PD）的效率问题，提出了一种名为Nexus的主动式GPU内部分离方案。现有方法在处理动态工作负载时存在干扰、高开销或反应性不足的问题。Nexus通过深入分析GPU资源的收益递减特性和内存带宽瓶颈，设计了一套动态资源分区策略，同时优化计算、内存和带宽。实验结果表明，Nexus在吞吐量和延迟方面显著优于现有主流系统，验证了其在动态LLM服务环境下的优越适应性和性能。

> **摘要翻译:** 标题: LLM服务中预填充和解码的主动式GPU内部分离
摘要: 使用分块预填充的单体服务通过将预填充和解码批量处理来提高GPU利用率，但存在细粒度相位干扰。引擎级预填充-解码（PD）分离避免了干扰，但会产生更高的硬件和协调开销。先前的GPU内部分离方法在单个GPU内复用预填充和解码，使用基于SLO的调整，由离线分析的启发式方法或反应式反馈循环指导。然而，这些方法对性能问题是反应性的，而不是预测性的，限制了在动态工作负载下的适应性。我们提出：能否实现主动式GPU内部分离，有效适应动态工作负载？关键挑战在于管理预填充和解码在不同条件下相互冲突的资源需求。我们首先表明GPU资源呈现收益递减——超过饱和点后，更多的分配带来的延迟收益微乎其微。其次，我们观察到内存带宽竞争成为一个关键瓶颈。这些见解促使我们设计了一种动态划分GPU资源以适应预填充和解码阶段的设计，同时联合考虑计算能力、内存占用和带宽竞争。在各种LLM和工作负载上进行评估，我们的系统Nexus实现了高达2.2倍的吞吐量提升，20倍的TTFT降低，以及2.5倍的TBT降低，优于vLLM；性能比SGLang高出2倍；并与分离式vLLM持平或超越。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [254] [Efficient Federated Learning with Heterogeneous Data and Adaptive Dropout](https://arxiv.org/abs/2507.10430)
> *异构数据和自适应Dropout的高效联邦学习*

*Ji Liu, Beichen Ma, Qiaolin Yu, Ruoming Jin, Jingbo Zhou, Yang Zhou, Huaiyu Dai, Haixun Wang, Dejing Dou, Patrick Valduriez* | **Category: cs.DC, cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 联邦学习, 异构数据, 自适应Dropout, 非独立同分布, 效率

**Comment:** 29 pages, to appear in ACM Transactions on Knowledge Discovery from
  Data (TKDD)

> **TL;DR:** 本文提出了FedDHAD联邦学习框架，通过动态异构模型聚合（FedDH）和自适应Dropout（FedAD）来解决联邦学习中异构数据导致的精度下降和设备资源限制下的收敛慢问题，显著提升了准确性、效率并降低了计算成本。

**AI_Comments:** 该论文通过结合动态模型聚合和自适应Dropout两种创新方法，有效地解决了联邦学习在异构数据环境下的核心挑战，即精度下降和收敛效率低下。其提出的FedDHAD框架不仅提升了模型性能，还在计算效率方面取得了显著进步，为未来联邦学习在资源受限环境下的应用提供了有价值的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）面临数据高度异构（非独立同分布，non-IID）导致显著的精度下降问题。此外，边缘设备有限的计算和通信能力增加了掉队者的可能性，导致模型收敛缓慢。

**Method:** 本文提出了FedDHAD联邦学习框架，包含两种新颖方法：动态异构模型聚合（FedDH）和自适应Dropout（FedAD）。FedDH根据异构数据的non-IID程度动态调整每个局部模型的聚合权重，以处理统计数据异构性。FedAD对异构设备执行神经元自适应操作，以在提高精度的同时实现卓越的效率。

**Result:** FedDHAD框架在准确性上比现有解决方案高出高达6.7%，效率上快2.02倍，计算成本降低15.0%。

**Conclusion:** FedDHAD结合了动态异构模型聚合和自适应Dropout，在准确性、效率和计算成本方面显著优于现有最先进的解决方案。

> **ai_Abstract:** 本文提出了FedDHAD联邦学习框架，旨在解决联邦学习中由数据异构性（non-IID）引起的精度下降和边缘设备资源限制导致的收敛缓慢问题。FedDHAD通过引入动态异构模型聚合（FedDH）来动态调整局部模型权重以应对数据异构性，并采用自适应Dropout（FedAD）来提高效率和精度。实验结果表明，FedDHAD在准确性、效率和计算成本方面均显著优于现有技术。

> **摘要翻译:** 联邦学习（FL）是一种很有前景的分布式机器学习方法，它能够利用多个边缘设备协同训练一个全局模型。边缘设备之间的数据分布高度异构。因此，FL面临数据分布和异构性的挑战，其中边缘设备之间非独立同分布（non-IID）的数据可能导致显著的精度下降。此外，边缘设备有限的计算和通信能力增加了掉队者的可能性，从而导致模型收敛缓慢。在本文中，我们提出了FedDHAD FL框架，它包含两种新颖的方法：动态异构模型聚合（FedDH）和自适应Dropout（FedAD）。FedDH根据异构数据的non-IID程度动态调整模型聚合过程中每个局部模型的权重，以处理统计数据异构性。FedAD响应异构设备执行神经元自适应操作，以在提高精度的同时实现卓越的效率。这两种方法的结合使得FedDHAD在准确性（提高高达6.7%）、效率（快高达2.02倍）和计算成本（降低高达15.0%）方面显著优于现有最先进的解决方案。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [381] [FAFO: Over 1 million TPS on a single node running EVM while still Merkleizing every block](https://arxiv.org/abs/2507.10757)
> *FAFO：在单个节点上运行EVM同时仍然对每个区块进行默克尔化，实现超过100万TPS*

*Ryan Zarick, Isaac Zhang, Daniel Wong, Thomas Kim, Bryan Pellegrino, Mignon Li, Kelvin Wong* | **Category: cs.DC, cs.NI** | **Updated: 2025-07-14**

**Keywords:** 区块链吞吐量, 交易调度器, EVM, 并行执行, 默克尔化

**Comment:** 

> **TL;DR:** FAFO通过在区块形成前重新排序交易来最大化并发性，从而在单个EVM节点上实现了超过100万TPS的高吞吐量，同时保持了每个区块的默克尔化。

**AI_Comments:** FAFO的创新之处在于其“形成前优化”的交易调度方法，通过预先重排交易来最大化并行性，显著提升了EVM的吞吐量。其在保持默克尔化和支持轻客户端/无状态验证的同时达到百万级TPS，证明了在不牺牲去中心化核心特性前提下实现高性能的可能性。这对于未来Web3应用的可扩展性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前区块链执行吞吐量受数据争用限制，降低了执行层并行性。

**Method:** FAFO是第一个通过在区块形成前重新排序交易以实现最大并发性的区块链交易调度器。它使用CPU优化的缓存友好型布隆过滤器来高效检测冲突并调度并行交易执行。FAFO将Rust EVM客户端（REVM）集成到其中，并使用QMDB在每个区块后对世界状态进行默克尔化。

**Result:** 在单个节点上实现了每秒超过110万次原生ETH转账和每秒超过50万次ERC20转账。与最先进的分片执行相比，成本降低了91%。FAFO与额外的CPU资源呈线性扩展，同步开销极小。

**Conclusion:** FAFO证明了通过精简的执行层和区块链交易调度器设计的创新，可以实现支持未来去中心化应用所需的高吞吐量。

> **ai_Abstract:** FAFO是一种新颖的区块链交易调度器，通过在区块形成前优化交易排序来解决数据争用导致的吞吐量限制。它利用布隆过滤器高效检测冲突，并在单个EVM节点上实现了超过100万TPS的高性能，同时保持了对每个区块状态的默克尔化，支持轻客户端和无状态验证。FAFO展示了通过执行层优化和调度创新实现未来去中心化应用所需的高吞吐量的潜力。

> **摘要翻译:** 当前区块链的执行吞吐量受到数据争用的限制，这降低了执行层的并行性。形成前优化（FAFO）是第一个通过在区块形成前重新排序交易以实现最大并发性的区块链交易调度器，旨在解决这个问题。FAFO使用经过CPU优化的缓存友好型布隆过滤器来高效检测冲突，并以高吞吐量和低开销调度并行交易执行。
我们将Rust EVM客户端（REVM）集成到FAFO中，在单个节点上实现了每秒超过110万次原生ETH转账和每秒超过50万次ERC20转账（表1），与最先进的分片执行相比，成本降低了91%。与许多其他现有高吞吐量区块链执行客户端不同，FAFO在每个区块后使用QMDB对世界状态进行默克尔化，从而支持轻客户端和基于ZK的vApps的无状态验证。FAFO以最小的同步开销进行扩展，随着额外CPU资源的增加而线性扩展，直到完全利用底层交易流的最大并行性。FAFO证明，通过精简的执行层和区块链交易调度器设计的创新，可以实现支持未来去中心化应用所需的高吞吐量。FAFO已在https://github.com/LayerZero-Labs/fafo 开源。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [651] [Dissecting the NVIDIA Blackwell Architecture with Microbenchmarks](https://arxiv.org/abs/2507.10789)
> *使用微基准测试剖析 NVIDIA Blackwell 架构*

*Aaron Jarmusch, Nathan Graddon, Sunita Chandrasekaran* | **Category: cs.DC** | **Updated: 2025-07-14**

**Keywords:** NVIDIA Blackwell, GPU架构, 微基准测试, 性能分析, Hopper

**Comment:** 

> **TL;DR:** 本文通过微基准测试对NVIDIA Blackwell GPU架构进行了微架构分析，并与Hopper架构进行比较，揭示了其性能特征、改进和退步，为优化工作负载提供了见解。

**AI_Comments:** 这篇论文通过使用微基准测试对NVIDIA Blackwell架构进行深入的微架构分析，提供了宝贵的低级别硬件洞察，这对于高性能计算至关重要。与前代Hopper的对比分析，直接揭示了代际间的实际性能变化，包括改进和退步。其发现对应用程序开发人员、编译器编写者和性能工程师具有直接的实践指导意义，是一项重要的创新。

<details>
  <summary>Details</summary>

**Motivation:** 科学研究的快速发展对计算能力提出了更高的需求，而GPU在一定程度上解决了这个问题。本文旨在通过微架构分析，深入理解现代NVIDIA Blackwell架构的性能特征和设计细节，从而为优化工作负载提供关键见解。

**Method:** 本文使用精心设计的微基准测试来研究NVIDIA Blackwell架构的GPU性能特征。研究内容包括揭示内存层次结构、SM执行管道和SM子核心单元（包括支持FP4和FP6精度的第五代张量核心）等关键子系统。研究人员分析了延迟、吞吐量、缓存行为和调度细节。为了进行全面分析，论文将Blackwell架构（使用GeForce RTX 5080）与之前的Hopper架构（使用H100 PCIe）进行了比较，并调查了不同工作负载下的功耗效率和能耗。

**Result:** 研究揭示了Blackwell设计中微妙的调整指标，并展示了与Hopper架构相比的代际改进和性能退步。此外，还调查了不同工作负载下功耗效率和能耗的作用。研究结果为应用程序开发人员、编译器编写者和性能工程师提供了可操作的见解，以优化基于Blackwell平台上的工作负载。

**Conclusion:** 本研究的发现为应用程序开发人员、编译器编写者和性能工程师提供了可操作的见解，以优化基于Blackwell平台上的工作负载，并为日益增长的GPU架构研究贡献了新数据。

> **ai_Abstract:** 本文通过微基准测试对NVIDIA Blackwell GPU架构进行了深入的微架构分析。研究揭示了内存层次结构、SM执行管道和第五代张量核心等关键子系统，并详细分析了延迟、吞吐量、缓存行为和调度细节。通过与前代Hopper架构的比较，论文展示了Blackwell在性能上的代际改进和退步，并探讨了其功耗效率。研究结果为开发者和工程师在Blackwell平台上优化工作负载提供了实用指导，并丰富了GPU架构研究的数据。

> **摘要翻译:** 科学研究的快速发展对计算能力提出了更高的需求，而GPU在一定程度上解决了这个问题。本文通过精心设计的微基准测试，对现代NVIDIA Blackwell架构进行了微架构分析，研究了其GPU性能特征。我们揭示了关键子系统，包括内存层次结构、SM执行管道以及SM子核心单元，其中包括支持FP4和FP6精度的第五代张量核心。为了理解NVIDIA GPU的不同关键特性，我们研究了延迟、吞吐量、缓存行为和调度细节，揭示了Blackwell设计中微妙的调整指标。为了进行全面的分析，我们分别使用GeForce RTX 5080和H100 PCIe将Blackwell架构与之前的Hopper架构进行了比较。我们评估并比较了结果，展示了代际改进和性能退步。此外，我们还研究了在不同工作负载下功耗效率和能耗的作用。我们的发现为应用程序开发人员、编译器编写者和性能工程师提供了可操作的见解，以优化基于Blackwell平台上的工作负载，并为日益增长的GPU架构研究贡献了新数据。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [668] [Uniting the World by Dividing it: Federated Maps to Enable Spatial Applications](https://arxiv.org/abs/2507.11437)
> *通过划分来连接世界：联邦地图赋能空间应用*

*Sagar Bharadwaj, Srinivasan Seshan, Anthony Rowe* | **Category: cs.DC, cs.ET** | **Updated: 2025-07-15**

**Keywords:** 联邦地图, 空间网络, 空间命名系统, 可扩展性, 隐私

**Comment:** 

> **TL;DR:** 本文提出联邦地图基础设施，以解决当前中心化地图在空间网络应用中面临的可扩展性和隐私问题，特别是对于室内空间，从而支持新兴空间应用。

**AI_Comments:** 本文提出了一种创新的去中心化地图管理范式，即联邦地图，以应对未来空间应用（特别是世界级AR）对大规模、高精度和隐私保护地图的需求。其重要性在于，它挑战了现有少数公司垄断的中心化地图模式，为地图数据管理带来了可扩展性和隐私性。潜在的挑战可能在于如何实现不同联邦节点间的数据互操作性和一致性，以及如何确保服务（如路由）在联邦环境下的高效运行。

<details>
  <summary>Details</summary>

**Motivation:** 空间网络（Spatial Web）的兴起需要一个空间命名系统，但现有中心化地图（如谷歌、苹果地图）无法满足新兴应用（如持久性世界级增强现实）对大规模、详细且包含室内空间的地图需求，且存在可扩展性和隐私限制。

**Method:** 本文提出并论证了一种联邦空间命名系统（即联邦地图基础设施），允许不同参与方管理和提供各自物理区域的地图。

**Result:** 联邦地图能够实现地图管理的可扩展性、隔离性和隐私性。同时，需要对地址到位置映射、基于位置搜索和路径规划等地图相关服务进行重新架构以适应联邦地图。

**Conclusion:** 联邦地图是解决当前空间命名系统局限性的关键，能够支持未来空间应用的发展，但需要对现有服务进行适配。

> **ai_Abstract:** 本文提出联邦地图基础设施作为空间网络中空间命名系统的解决方案，旨在克服现有中心化地图在可扩展性和室内数据隐私方面的局限性。通过允许不同方管理各自区域地图，联邦地图能提升地图管理的可扩展性、隔离性和隐私性，从而支持增强现实等新兴空间应用，并讨论了相关服务适配的必要性。

> **摘要翻译:** 空间网络的出现——将内容与现实世界位置关联的网络——有潜力改进和赋能许多应用，如增强现实、导航、机器人等。然而，空间网络缺少一个阻碍其发展的关键要素——一个将现实世界位置解析为名称的空间命名系统。当今的空间命名系统是数字地图，例如谷歌和苹果地图。这些地图以及基于这些地图提供的定位服务主要由少数大型公司控制，并且主要覆盖室外公共空间。新兴的应用类别，例如持久性世界级增强现实，需要详细的室外和室内空间地图。现有的中心化地图基础设施对于此类应用来说被证明是不足的，因为所需的制图工作规模巨大以及室内地图数据的隐私性问题。
在本文中，我们提出了一个联邦空间命名系统，或者换句话说，一个联邦地图基础设施的案例。这使得不同的参与方能够管理和提供他们自己物理区域的地图，并解锁地图管理的可扩展性、隔离性和隐私性。地址到位置映射、基于位置的搜索和路径规划等地图相关服务需要重新设计以在联邦地图上运行。我们讨论了实现这些服务的一些基本服务和实用性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [686] [Scaling the memory wall using mixed-precision -- HPG-MxP on an exascale machine](https://arxiv.org/abs/2507.11512)
> *使用混合精度扩展内存墙——百亿亿次机器上的 HPG-MxP*

*Aditya Kashi, Nicholson Koukpaizan, Hao Lu, Michael Matheson, Sarp Oral, Feiyi Wang* | **Category: cs.DC, cs.NA, cs.PF, math.NA, 65Y10, G.4; C.4** | **Updated: 2025-07-15**

**Keywords:** 混合精度, HPG-MxP, 百亿亿次计算, 内存墙, 稀疏矩阵

**Comment:** Accepted for presentation at SC25, St. Louis, MO, USA

> **TL;DR:** 在百亿亿次机器上，通过优化 HPG-MxP 基准测试，首次展示了稀疏矩阵混合精度计算在现代 GPU 超级计算机上实现 1.6 倍加速，有望解决内存墙问题。

**AI_Comments:** 这项工作的重要性在于它首次量化了混合精度在稀疏矩阵、内存带宽受限的科学计算中带来的实际性能提升，尤其是在百亿亿次系统上。通过优化 HPG-MxP 基准测试，为评估和推广混合精度在更广泛的科学应用中的应用奠定了基础，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 混合精度算法在人工智能领域取得了显著进展，但其在受内存带宽限制的科学模拟应用中的实际收益尚不明确，尤其是对于非密集矩阵操作。

**Method:** 开发了针对百亿亿次系统的高度优化的 HPG-MxP 基准测试实现，并描述了算法增强。

**Result:** 首次在现代基于 GPU 的超级计算机上，结合双精度和单精度，实现了 1.6 倍的加速。

**Conclusion:** 通过对 HPG-MxP 的优化实现，证明了混合精度算法在稀疏矩阵科学计算中具有显著的性能提升潜力，有助于克服内存墙问题。

> **ai_Abstract:** 本文针对混合精度算法在内存带宽受限的科学模拟应用中实际增益不明确的问题，提出并优化了 HPG-MxP 基准测试在百亿亿次系统上的实现。研究首次在现代 GPU 超级计算机上，通过结合双精度和单精度，实现了 1.6 倍的性能加速，证明了混合精度在稀疏矩阵计算中克服内存墙的潜力。

> **摘要翻译:** 混合精度算法已被提出作为一种方法，使得科学计算能够受益于近期高性能计算 (HPC) 平台上人工智能 (AI) 所取得的一些进步。一些以密集矩阵运算为主的应用通过利用 FP16 等低精度格式获得了显著的加速。然而，大多数科学模拟应用受限于内存带宽。除了初步研究之外，在给定 HPC 系统上使用混合精度算法的实际增益在很大程度上尚不明确。高性能 GMRES 混合精度 (HPG-MxP) 基准测试已被提出，用于衡量 HPC 系统在基于稀疏矩阵的混合精度应用上的有效性能。在这项工作中，我们为百亿亿次系统提供了一个高度优化的 HPG-MxP 基准测试实现，并描述了我们的算法增强。我们首次展示了在现代基于 GPU 的超级计算机上，结合双精度和单精度，实现了 1.6 倍的加速。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [693] [MMStencil: Optimizing High-order Stencils on Multicore CPU using Matrix Unit](https://arxiv.org/abs/2507.11067)
> *MMStencil：利用矩阵单元优化多核CPU上的高阶模板计算*

*Yinuo Wang, Tianqi Mao, Lin Gan, Wubing Wan, Zeyu Song, Jiayu Fu, Lanke He, Wenqiang Wang, Zekun Yin, Wei Xue, Guangwen Yang* | **Category: cs.DC** | **Updated: 2025-07-15**

**Keywords:** 高阶模板, 多核CPU, 矩阵单元, HPC, 优化

**Comment:** Yinuo Wang and Tianqi Mao contributed equally to this work

> **TL;DR:** 该论文优化了在多核CPU上使用矩阵单元进行三维高阶模板计算的方法，与最先进的GPGPU库和实际HPC应用相比，实现了显著的加速。

**AI_Comments:** 该论文通过解决多核CPU上利用矩阵单元进行3D高阶模板计算这一未充分探索的领域，做出了重要贡献。其创新之处在于结合了算法、内存和并行优化，包括新颖的多线程范式和基于DMA的NUMA通信，从而实现了优于通常在此领域占主导地位的GPGPU的卓越性能。这项工作突出了带矩阵单元的多核CPU在HPC领域的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 矩阵加速的模板计算是一个热门研究课题，但其在三维（3D）高阶模板和HPC中的应用仍未得到充分探索。随着多核CPU上矩阵单元的出现，本研究旨在填补这一空白。

**Method:** MMStencil分析了基于矩阵的加速策略并为3D高阶模板量身定制了最优方法。它引入了基于SIMD和矩阵单元的算法优化来解决内存访问问题，提出了内存优化以提高片上内存效率，并开发了一种新颖的多线程并行范式来克服数据共享挑战。此外，还采用了基于DMA的NUMA间通信来缓解NUMA效应和MPI限制。

**Result:** MMStencil在不同的模板形状和维度下都能保持持续高硬件利用率。它比Nvidia A100 GPGPU上的最先进库快2.1倍，并使RTM应用比高度优化的工业Nvidia A100 GPGPU版本提速1.8倍。

**Conclusion:** MMStencil利用矩阵单元有效优化了多核CPU上的高阶模板计算，为通用模板计算和RTM等实际HPC应用带来了显著的性能提升。

> **ai_Abstract:** MMStencil论文探讨了利用新兴矩阵单元优化多核CPU上3D高阶模板计算的方法。它引入了算法优化（SIMD和矩阵单元以解决内存访问问题）、内存优化以提高效率，以及一种新颖的多线程并行范式来解决数据共享问题。此外，还使用基于DMA的NUMA间通信来缓解NUMA效应。MMStencil展示了高硬件利用率，并且性能显著优于最先进的GPGPU库（高达2.1倍）和RTM等实际HPC应用（1.8倍加速）。

> **摘要翻译:** 矩阵加速的模板计算是一个热门研究课题，但其在三维（3D）高阶模板和HPC中的应用仍未得到充分探索。随着多核CPU上矩阵单元的出现，我们分析了基于矩阵的加速策略，并为3D高阶模板量身定制了一种最优方法。我们引入了基于SIMD和矩阵单元的算法优化，以解决跨步内存访问、对齐冲突和冗余访问问题。我们提出了内存优化以提高片上内存效率，以及一种新颖的多线程并行范式来克服由于缺乏共享数据缓存而导致的数据共享挑战。MMStencil在不同的模板形状和维度下都能保持持续高硬件利用率。我们基于DMA的NUMA间通信进一步缓解了混合并行中的NUMA效应和MPI限制。结合所有创新，MMStencil的性能比Nvidia A100 GPGPU上的最先进库高出2.1倍。此外，性能提升直接转化为实际的HPC应用，使RTM应用比高度优化的工业Nvidia A100 GPGPU版本提速1.8倍。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [736] [Generating Dynamic Graph Algorithms for Multiple Backends for a Graph DSL](https://arxiv.org/abs/2507.11094)
> *为图DSL生成多后端动态图算法*

*Nibedita Behera, Ashwina Kumar, Atharva Chougule, Mohammed Shan P S, Rushabh Nirdosh Lalwani, Rupesh Nasre* | **Category: cs.DC** | **Updated: 2025-07-15**

**Keywords:** 动态图算法, 领域特定语言, 并行计算, 图处理, 运行时优化

**Comment:** 

> **TL;DR:** 本文提出了一种抽象方案和运行时优化，通过DSL为动态图生成高效的并行代码，支持多核、分布式和众核环境。

**AI_Comments:** 这篇论文的创新点在于专注于动态图算法的并行化，并提供了一个统一的DSL方法来生成适用于多种后端（多核、分布式、众核）的高效代码。这对于处理现实世界中不断演变的图数据至关重要，克服了现有框架在静态图处理上的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有图并行化框架在处理动态图时存在局限性，而许多真实世界的图是动态变化的，为这类图生成高效且正确同步的代码是一个重大挑战。

**Method:** 引入了一种抽象方案和运行时优化，用于高效处理动态图算法。通过一个领域特定语言（DSL）表达动态处理逻辑，并自动生成针对多核、分布式和众核环境的并行代码。

**Result:** 通过将DSL生成的代码应用于十个具有不同特征的大型图和三个广泛使用的算法（最短路径、PageRank和三角形计数），证明了该方法的有效性。

**Conclusion:** 本文成功引入了一种抽象方案和运行时优化，能够通过DSL为动态图算法自动生成高效的并行代码，有效解决了动态图并行化难题。

> **ai_Abstract:** 本文针对动态图并行化面临的挑战，提出了一种通过领域特定语言（DSL）自动生成高效并行代码的方法。该方法引入了抽象方案和运行时优化，能够处理图结构随时间变化的动态图算法。研究人员通过在多核、分布式和众核环境中，对十个大型图和三个常用算法进行实验，验证了其有效性。

> **摘要翻译:** 随着非结构化和半结构化数据的快速增长，图算法的并行化对于提高效率至关重要。然而，由于计算、内存访问模式和通信固有的不规则性，图算法的并行化非常困难。为了解决这一挑战，已经提出了多种库、框架和领域特定语言（DSL），以减轻领域专家的并行编程负担。现有框架部分或完全抽象了并行性复杂性，提供了直观的调度助记符，并采用程序分析来识别数据竞争并生成同步代码。尽管取得了这些进展，但大多数框架在抽象和运行时优化方面存在局限性，特别是在处理静态图时。相比之下，许多真实世界的图本质上是动态的，通过顶点、边和属性的插入、删除和修改随时间演变。为这种动态图算法生成高效且正确同步的代码仍然是一个重大挑战。
在这项工作中，我们引入了一种抽象方案和运行时优化，用于高效处理“形态（morph）”算法。具体而言，给定初始图G和一组涉及边插入和删除的更新$\Delta$G，我们通过DSL表达动态处理逻辑，并自动生成针对多核、分布式和众核环境的并行代码。我们通过将DSL生成的代码应用于十个具有不同特征的大型图和三个广泛使用的算法：最短路径、PageRank和三角形计数，证明了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [777] [Boosting Scientific Error-Bounded Lossy Compression through Optimized Synergistic Lossy-Lossless Orchestration](https://arxiv.org/abs/2507.11165)
> *通过优化协同有损-无损编排提升科学误差有界有损压缩*

*Shixun Wu, Jinwen Pan, Jinyang Liu, Jiannan Tian, Ziwei Qiu, Jiajun Huang, Kai Zhao, Xin Liang, Sheng Di, Zizhong Chen, Franck Cappello* | **Category: cs.DC** | **Updated: 2025-07-15**

**Keywords:** 误差有界压缩, GPU, 科学数据, 有损压缩, 无损编码

**Comment:** accepted by SC '25

> **TL;DR:** cuSZ-Hi是一种优化的GPU科学误差有界有损压缩器，通过改进数据预测和无损编码，显著提升了压缩比。

**AI_Comments:** cuSZ-Hi在科学数据压缩领域具有显著的创新性，特别是在GPU平台上实现了高压缩比和误差有界。其结合有损预测和无损编码的协同优化策略，以及对GPU并行计算的充分利用，是其成功的关键。该研究为处理大规模科学数据提供了高效的解决方案，对高性能计算和数据分析领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着高性能计算架构的发展，科学计算工作流在GPU等平台上产生海量原始数据，急需高压缩比、低延迟且误差有界的数据压缩解决方案。

**Method:** 本文提出了cuSZ-Hi，一种基于GPU的科学误差有界有损压缩器。其核心贡献包括：1) 最大化优化了GPU上基于插值的并行数据预测方案，使其能适应多样化的数据特性；2) 深入探索并结合了最适合的无损数据编码技术，以最大化压缩比；3) 在基准数据集上与现有代表性基线进行了系统评估。

**Result:** 与现有最先进的科学有损压缩器相比，在相同误差界限下，cuSZ-Hi的压缩比提高了249%；在相同解压数据PSNR下，压缩比提高了215%，同时吞吐量与现有GPU上高压缩比的误差有界有损压缩器相当或更优。

**Conclusion:** cuSZ-Hi通过优化GPU上的数据预测和无损编码，显著提升了科学误差有界有损压缩的性能，在保持或超越现有解决方案吞吐量的同时，实现了更高的压缩比。

> **ai_Abstract:** 本文提出了一种名为cuSZ-Hi的优化GPU科学误差有界有损压缩器，旨在解决高性能计算环境中海量科学数据压缩的需求。该方法通过最大化优化GPU上的并行插值数据预测方案和整合最佳无损编码技术，显著提升了压缩比。实验结果表明，与现有技术相比，cuSZ-Hi在相同误差或PSNR下，压缩比分别提高了249%和215%，同时保持了竞争力或更优的吞吐量。

> **摘要翻译:** 随着高性能计算架构的发展，越来越多的科学计算工作流正在部署到GPU等先进计算平台。这些工作流能够以极高的吞吐量生成原始数据，需要紧急的高压缩比、低延迟的误差有界数据压缩解决方案。本文提出cuSZ-Hi，一种优化的、高压缩比的、基于GPU的科学误差有界有损压缩器，它具有灵活、领域无关且完全开源的框架设计。我们的新颖贡献包括：1) 我们最大限度地优化了GPU上基于插值的并行数据预测方案，从而实现了适应不同数据特性的基于插值的科学数据预测的全部功能；2) 我们彻底探索和研究了无损数据编码技术，然后精心设计并整合了最适合的无损编码流水线，以最大化cuSZ-Hi的压缩比；3) 我们在基准数据集上系统地评估了cuSZ-Hi以及代表性基线。与现有最先进的科学有损压缩器相比，在相同误差界限下，cuSZ-Hi可以实现高达249%的压缩比提升，在相同解压数据PSNR下，可以实现高达215%的压缩比提升，并且吞吐量与现有GPU上高压缩比的科学误差有界有损压缩器相当或更优。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [26] [NLP Meets the World: Toward Improving Conversations With the Public About Natural Language Processing Research](https://arxiv.org/abs/2507.10559)
> *NLP走向世界：旨在改善与公众关于自然语言处理研究的对话*

*Shomir Wilson* | **Category: cs.CY, cs.AI, cs.CL** | **Updated: 2025-07-02**

**Keywords:** NLP, 公众沟通, 大型语言模型, 研究传播

**Comment:** 

> **TL;DR:** 鉴于公众对大型语言模型（LLMs）和自然语言处理（NLP）日益增长的兴趣，本文为NLP研究人员提供了与公众有效沟通的建议，以解决模糊术语、不合理期望和道德失误等障碍，旨在增强公众理解和支持。

**AI_Comments:** 本文具有重要意义，因为它解决了科学传播中的一个关键问题，尤其是在NLP这样一个快速发展且具有深远影响的领域。它专注于为研究人员提供实用建议，以弥合复杂研究与公众理解之间的鸿沟，这非常有价值。论文强调了可能阻碍公众信任和支持的常见陷阱（模糊术语、不切实际的期望、道德担忧）。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）的发展，公众对自然语言处理（NLP）的兴趣迅速增长。新闻媒体也开始邀请NLP研究人员分享知识。本文旨在抓住这一机遇，为研究领域和个体研究人员提供与普通公众沟通LLMs能力和局限性的建议，以促进公众理解并鼓励对研究的支持。

**Method:** 本文通过分享沟通建议来达到目的。这些建议涵盖了三个主题：模糊术语作为公众理解的障碍、不合理的期望作为可持续增长的障碍，以及道德失误作为持续支持的障碍。论文引用了已发表的NLP研究和流行新闻报道来举例说明这些主题。

**Result:** 论文提供了旨在促进与公众关于NLP的有效、透明沟通的建议，以期增强公众理解并鼓励对研究的支持。

**Conclusion:** 与公众进行有效、透明的NLP沟通至关重要，它能帮助加强公众对NLP的理解，并鼓励对研究的持续支持。

> **ai_Abstract:** 本文针对公众对自然语言处理（NLP）和大型语言模型（LLMs）日益增长的兴趣，为研究人员提供了与普通受众有效沟通的建议。论文提出了三个关键主题：模糊术语、不合理期望和道德失误，并引用研究和新闻报道的例子进行阐述。这些建议旨在通过透明的沟通，加强公众对NLP的理解和支持。

> **摘要翻译:** 大型语言模型（LLMs）的最新发展伴随着公众对自然语言处理（NLP）兴趣的迅速增长。这种关注体现在主要新闻媒体上，它们有时会邀请NLP研究人员与广大受众分享他们的知识和观点。鉴于当前对研究领域和个体研究人员而言的机遇，本文分享了关于如何与普通受众沟通LLMs能力和局限性的建议。这些建议涵盖三个主题：模糊的术语是公众理解的障碍、不合理的期望是可持续增长的障碍，以及道德失误是持续支持的障碍。论文引用了已发表的NLP研究和流行新闻报道来举例说明这些主题。这些建议旨在促进与公众关于NLP的有效、透明的沟通，以增强公众理解并鼓励对研究的支持。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [80] [Findings of the BEA 2025 Shared Task on Pedagogical Ability Assessment of AI-powered Tutors](https://arxiv.org/abs/2507.10579)
> *BEA 2025 AI驱动导师教学能力评估共享任务的发现*

*Ekaterina Kochmar, Kaushal Kumar Maurya, Kseniia Petukhova, KV Aditya Srivatsa, Anaïs Tack, Justin Vasselli* | **Category: cs.CY, cs.AI, cs.CL** | **Updated: 2025-07-11**

**Keywords:** AI导师, 教学能力评估, 共享任务, 大型语言模型, 错误纠正

**Comment:** Proceedings of the 20th Workshop on Innovative Use of NLP for
  Building Educational Applications

> **TL;DR:** BEA 2025共享任务评估了由大型语言模型驱动的AI导师的教学能力，主要集中在学生错误纠正方面。结果显示，尽管有前景，但在教学能力评估方面仍有很大的提升空间，而导师身份识别表现良好。

**AI_Comments:** 本论文通过BEA 2025共享任务，首次大规模评估了基于LLM的AI导师的教学能力，具有重要的创新意义。结果揭示了当前AI导师在复杂教学交互（如提供指导和错误纠正）方面的局限性，并明确了未来研究的改进方向。任务公开所有资源，极大地促进了该关键领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 该共享任务旨在评估由大型语言模型（LLMs）驱动的AI导师的教学能力，重点是评估导师在教育对话中纠正学生错误的回复质量。

**Method:** 该任务包含五个赛道，旨在根据学习科学原则自动评估AI导师在错误识别、错误精确位置、提供指导和反馈可操作性等关键维度上的表现，以及一个专注于导师身份检测的赛道。超过50个国际团队参与，提交的模型通过黄金标准的人工标注进行评估。

**Result:** 结果显示，尽管有前景，但该领域仍有显著的改进空间。四个教学能力评估赛道的最佳宏观F1分数在58.34（提供指导）到71.81（错误识别）之间（三分类问题），而导师身份识别赛道的最佳F1分数达到96.98（九分类任务）。

**Conclusion:** AI驱动导师的教学能力评估结果显示，虽然有潜力，但在纠正学生错误等教学能力方面仍需显著改进，而导师身份识别表现较好。所有任务资源已公开，以支持未来研究。

> **ai_Abstract:** BEA 2025共享任务旨在评估由大型语言模型驱动的AI导师的教学能力，尤其是在学生错误纠正方面。任务设置了五个赛道，涵盖错误识别、定位、指导、反馈可操作性和导师身份识别，并吸引了50多个国际团队参与。模型通过人工标注进行评估，结果表明，尽管AI导师在教学能力方面表现出潜力，但仍有很大的改进空间（F1分数介于58.34-71.81），而导师身份识别效果显著（F1分数96.98）。本论文概述了任务发现、团队方法和性能分析，并公开了所有相关资源以促进未来研究。

> **摘要翻译:** 这项共享任务旨在评估由大型语言模型（LLM）驱动的AI导师的教学能力，重点是评估导师在教育对话中旨在纠正学生错误的回复质量。该任务由五个赛道组成，旨在根据定义良好和有效导师回复的学习科学原则，自动评估AI导师在错误识别、错误精确位置、提供指导和反馈可操作性等关键维度上的表现，以及一个专注于导师身份检测的赛道。该任务吸引了全球50多个团队参与所有赛道。提交的模型根据黄金标准的人工标注进行评估，结果虽然有前景，但表明该领域仍有显著的改进空间：四个教学能力评估赛道的最佳宏观F1分数在三分类问题上介于58.34（提供指导）和71.81（错误识别）之间，而导师身份识别赛道的最佳F1分数在九分类任务中达到96.98。本文概述了共享任务的主要发现，讨论了团队所采用的方法，并分析了他们的表现。与此任务相关的所有资源均已公开，以支持该关键领域的未来研究。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [128] [Artificial Intelligence and Journalism: A Systematic Bibliometric and Thematic Analysis of Global Research](https://arxiv.org/abs/2507.10891)
> *人工智能与新闻业：全球研究的系统文献计量与主题分析*

*Mohammad Al Masum Molla, Md Manjurul Ahsan* | **Category: cs.CY, cs.DL** | **Updated: 2025-07-15**

**Keywords:** 人工智能, 新闻业, 系统回顾, 文献计量分析, 伦理治理

**Comment:** 

> **TL;DR:** 本研究对2010-2025年人工智能在新闻业中的应用进行了系统性文献回顾，结合文献计量和主题分析，揭示了研究趋势、技术、伦理关注和地域差异，并提出了未来研究方向。

**AI_Comments:** 这篇论文的创新之处在于结合了文献计量分析、定性主题综合和情感分析，为人工智能在新闻业领域的研究提供了全面的视角。其重要性在于揭示了该领域的研究趋势、伦理挑战和地域差异，为未来的研究和实践提供了宝贵的指导。特别是对全球南方地区代表性不足的指出，为未来研究指明了方向，具有现实意义。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能正在重塑全球新闻实践，带来机遇的同时也引发了伦理、专业和社会担忧。本研究旨在对人工智能在新闻业领域已发表的文章进行全面系统的回顾。

**Method:** 本研究遵循PRISMA 2020指南，从Scopus和Web of Science数据库中选取了72篇同行评审文章。分析结合了文献计量绘图和定性主题综合，以识别主导趋势、技术、地理分布和伦理辩论。此外，还使用VADER算法对文章摘要进行了情感分析。

**Result:** 研究发现，2020年后研究活动急剧增加，主要关注领域包括自动化、错误信息和伦理治理。大多数研究反映出谨慎的乐观态度，但对偏见、透明度和问责制的担忧依然存在。审查还强调了学术贡献的区域差异，全球南方地区的代表性有限。

**Conclusion:** 本研究通过整合定量和定性见解，对人工智能如何改变新闻业提供了多维度的理解，并为包容性和负责任的创新提出了未来的研究方向。

> **ai_Abstract:** 本研究对2010年至2025年间人工智能在新闻业领域的研究进行了系统性文献回顾。通过结合文献计量、主题分析和情感分析，该研究考察了72篇同行评审文章，揭示了2020年后研究活动的显著增长，以及自动化、错误信息和伦理治理等核心关注点。研究发现，尽管普遍持谨慎乐观态度，但对偏见、透明度和问责制的担忧持续存在，并且存在全球南方地区研究贡献不足的地域差异。该研究提供了一个多维度的视角，以理解AI如何变革新闻业，并提出了未来研究方向，以促进包容和负责任的创新。

> **摘要翻译:** 人工智能（AI）正在全球范围内重塑新闻实践，既带来新机遇，也引发伦理、专业和社会担忧。本研究对2010年至2025年期间关于人工智能在新闻业中已发表的文章进行了全面的系统性回顾。遵循《系统评价和荟萃分析首选报告项目》（PRISMA）2020指南，从Scopus和Web of Science数据库中选择了总共72篇同行评审文章。分析结合了文献计量映射和定性主题综合，以识别主导趋势、技术、地理分布和伦理辩论。此外，还使用情感感知词典和情感推理器（VADER）算法对文章摘要进行了情感分析，以捕捉文献中的评价语气。研究结果显示，2020年之后研究活动急剧增加，主要关注领域包括自动化、错误信息和伦理治理。虽然大多数研究反映出谨慎的乐观态度，但对偏见、透明度和问责制的担忧依然存在。该综述还强调了学术贡献的区域差异，全球南方地区的代表性有限。通过整合定量和定性见解，本研究对人工智能如何改变新闻业提供了多维度的理解，并为包容性和负责任的创新提出了未来的研究方向。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [243] [The GPT Surprise: Offering Large Language Model Chat in a Massive Coding Class Reduced Engagement but Increased Adopters Exam Performances](https://arxiv.org/abs/2407.09975)
> *GPT之惊奇：在大型编程课中提供大型语言模型聊天功能降低了参与度但提高了使用者考试成绩*

*Allen Nie, Yash Chandak, Miroslav Suzara, Ali Malik, Juliette Woodrow, Matt Peng, Mehran Sahami, Emma Brunskill, Chris Piech* | **Category: cs.CY, cs.AI, cs.CL, stat.AP** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 编程教育, 学生参与度, 考试成绩, 随机对照试验

**Comment:** 32 pages. Published at L@S 2025

> **TL;DR:** 在大型编程课中提供GPT-4聊天界面，发现使用工具的学生考试成绩提高，但整体学生参与度（包括考试参与度）下降，低人类发展指数国家的学生考试参与度反而增加。

**AI_Comments:** 该研究通过大规模随机对照试验，提供了关于LLM在教育中应用的宝贵实证数据。其创新之处在于揭示了LLM使用对学生参与度的复杂影响，特别是区分了使用者和整体学生群体，并考虑了学生来源国的影响。这对于理解LLM在不同教育背景下的实际效用及其潜在风险具有重要意义。研究结果提示，教育者在引入LLM工具时，需要权衡其对学习成绩的潜在提升与对学生自主参与度的影响，并考虑不同学生群体的差异化需求。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在学习体验中被广泛采用，尤其是在编程教育中表现出色且日益成为专业工作流程的一部分。然而，关于这类通用工具对学生学习影响的研究相对较少，因此需要评估其影响。

**Method:** 进行了一项大规模随机对照试验，涉及来自146个国家的5,831名学生。在在线编程课中，部分学生获得了GPT-4聊天界面的访问权限。

**Result:** 使用工具的学生（adopters）考试成绩有所提高。然而，整体来看，提供GPT-4的宣传导致考试参与度显著下降，其他形式的课程参与度也出现类似下降。但这种下降受学生国籍影响，来自低人类发展指数国家的学生考试参与度平均有所增加。

**Conclusion:** 在入门级编程课中使用大型语言模型可能带来益处，但也可能对学生参与度造成潜在危害，这使得其对学生长期成功的影响尚不明确。研究强调需要进一步调查以理解未来LLM在课堂中采用和整合的潜在影响。

> **ai_Abstract:** 本研究通过一项大规模随机对照试验，评估了在大型在线编程课中引入GPT-4聊天界面对学生学习的影响。结果显示，虽然积极使用GPT-4的学生考试成绩有所提高，但整体学生的课程参与度（包括考试参与度）却显著下降。值得注意的是，来自低人类发展指数国家的学生，其考试参与率反而有所增加。研究指出，LLM在编程教育中既有潜在益处，也可能带来参与度下降的风险，其长期影响仍需进一步探究。

> **摘要翻译:** 大型语言模型（LLMs）正迅速被广泛应用于各种学习体验中，尤其是通过ChatGPT和Copilot等无处不在且易于访问的聊天界面。这类界面在全球范围内的学生和教师中随处可见，但关于此类通用工具对学生学习影响的评估研究相对较少。编程教育是一个有趣的测试案例，原因在于LLMs在编程任务上表现出色，而且LLM驱动的支持工具正迅速成为专业软件工程师工作流程的一部分。为了帮助理解通用LLM使用对编程教育的影响，我们在一项在线编程课程中进行了一项大规模随机对照试验，涉及来自146个国家的5,831名学生，我们为部分学生提供了GPT-4聊天界面的访问权限。我们估计，对于使用该工具的学生（即使用者），其考试成绩有积极的提升，但对于所有学生而言，GPT-4的宣传导致考试参与度平均显著下降。我们观察到其他形式的课程参与度也有类似的下降。然而，这种下降受到学生国籍的调节。为来自低人类发展指数国家的学生提供LLMs的访问权限，平均提高了他们的考试参与率。我们的结果表明，在入门级编程课程中使用LLMs可能带来有益的益处，但也可能对参与度造成潜在危害，这使得它们对学生长期成功的影响尚不明确。我们的工作强调需要进行额外的调查，以帮助理解未来LLMs在课堂中采用和整合的潜在影响。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [272] [The Potential Impact of Disruptive AI Innovations on U.S. Occupations](https://arxiv.org/abs/2507.11403)
> *颠覆性人工智能创新对美国职业的潜在影响*

*Munjung Kim, Marios Constantinides, Sanja Šćepanović, Yong-Yeol Ahn, Daniele Quercia* | **Category: cs.CY, cs.SI** | **Updated: 2025-07-15**

**Keywords:** AI创新, 劳动力市场, 颠覆性人工智能, 整合性人工智能, 职业影响

**Comment:** 

> **TL;DR:** 人工智能将扰乱劳动力市场，但其影响各不相同。本文衡量了人工智能专利的颠覆性，并将其与工作任务联系起来，发现整合性人工智能针对常规任务（制造业、建筑业），而颠覆性人工智能影响不可预测的脑力任务（科学、技术），特别是在熟练劳动力稀缺的地区。

**AI_Comments:** 本文通过利用专利数据并将其与工作任务关联，提供了一种量化人工智能颠覆潜力的创新方法，从而对人工智能对劳动力市场的影响提供了比简单自动化更细致的理解。研究发现颠覆性人工智能影响熟练劳动力短缺的地区，这一点尤其具有洞察力，挑战了关于人工智能导致失业的普遍假设。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能的迅速崛起势必会扰乱劳动力市场，但目前对于如何系统地衡量一项创新的颠覆性潜力尚未达成共识。本文旨在区分“整合性”和“颠覆性”人工智能创新，并理解它们的不同影响。

**Method:** 计算了3,237项美国人工智能专利（2015-2022年）的颠覆指数，并将其与工作任务联系起来，以区分“整合性”和“颠覆性”人工智能创新。

**Result:** 整合性人工智能主要针对中西部和中部各州的制造业和建筑业中常见的体力、常规和独立任务。颠覆性人工智能影响不可预测的脑力任务，特别是在沿海科技领域。颠覆性人工智能不成比例地影响已经面临熟练劳动力短缺的地区，表明其可能在劳动力稀缺的地方加速变革。

**Conclusion:** 整合性人工智能似乎延续了当前的自动化趋势，而颠覆性人工智能将改变复杂的脑力劳动，但协作任务是一个值得注意的例外。

> **ai_Abstract:** 本文通过计算颠覆指数并将其与工作任务联系起来，衡量了2015-2022年间美国人工智能专利的颠覆潜力。研究区分了“整合性”人工智能（通过针对常规体力任务如制造业来强化现有结构）和“颠覆性”人工智能（通过影响不可预测的脑力任务如科学技术来改变结构）。研究发现，颠覆性人工智能不成比例地影响熟练劳动力短缺的地区，表明它加速变革而非取代过剩劳动力。结论是，整合性人工智能延续了当前自动化趋势，而颠覆性人工智能则将改变复杂的脑力劳动，协作任务除外。

> **摘要翻译:** 人工智能的迅速崛起势势必会扰乱劳动力市场。然而，人工智能并非单一的整体；其影响取决于创新的性质以及受影响的工作。尽管计算方法正在兴起，但对于如何系统地衡量创新的颠覆性潜力尚未达成共识。在此，我们计算了3,237项美国人工智能专利（2015-2022年）的颠覆指数，并将其与工作任务联系起来，以区分强化现有结构的“整合性”人工智能创新和改变现有结构的“颠覆性”人工智能创新。我们的分析表明，整合性人工智能主要针对中西部和中部和中部各州的制造业和建筑业中常见的体力、常规和独立任务。相比之下，颠覆性人工智能影响不可预测的脑力任务，特别是在沿海科技领域。令人惊讶的是，我们还发现颠覆性人工智能不成比例地影响已经面临熟练劳动力短缺的地区，这表明颠覆性人工智能技术可能会在劳动力稀缺的地方加速变革，而不是取代过剩的劳动力。最终，整合性人工智能似乎延续了当前的自动化趋势，而颠覆性人工智能则将改变复杂的脑力劳动，但协作任务是一个值得注意的例外。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [288] [Deepfake Technology Unveiled: The Commoditization of AI and Its Impact on Digital Trust](https://arxiv.org/abs/2506.07363)
> *深度伪造技术揭秘：人工智能的商品化及其对数字信任的影响*

*Claudiu Popa, Rex Pallath, Liam Cunningham, Hewad Tahiri, Abiram Kesavarajah, Tao Wu* | **Category: cs.CY, cs.AI, I.2.m** | **Updated: 2025-07-15**

**Keywords:** 深度伪造技术, 数字信任, 生成式AI, 虚假信息, 监管

**Comment:** 12 pages, 13 figures

> **TL;DR:** 随着生成式AI工具的普及，深度伪造技术日益易用，导致欺诈和虚假信息泛滥，严重威胁数字信任。本文揭示了其风险，并强调了监管、公众意识和合作在维护数字媒体信任方面的紧迫性。

**AI_Comments:** 本文深刻剖析了当前深度伪造技术带来的严峻挑战，其创新点在于通过具体工具的演示，直观展现了深度伪造的低门槛和高风险。其重要性在于不仅揭示了技术滥用的危害，更明确指出了维护数字信任所需的多元化应对策略，即监管、公众意识和多方协作，为政策制定者和公众提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于生成式AI工具的普及使得深度伪造技术日益易用，这引发了对数字信任、隐私和安全的担忧。本文旨在探讨深度伪造技术的影响，分析其在助长欺诈、虚假信息以及侵蚀多媒体真实性方面的作用。

**Method:** 本文通过使用Runway、Rope和ElevenLabs等经济高效且易于使用的工具，展示了如何用有限资源创建逼真的深度伪造内容，从而揭示其对个人和组织的风险。同时，论文分析了深度伪造缓解和检测的技术与伦理挑战。

**Result:** 本文通过实例展示了使用有限资源创建逼真深度伪造的便捷性，揭示了其对个人和组织构成的严重风险。研究强调，当前迫切需要建立监管框架、提高公众意识并加强协作，以维护数字媒体的信任。

**Conclusion:** 面对深度伪造技术日益增长的威胁及其在欺诈和虚假信息中的应用，本文得出结论，迫切需要制定监管框架、提高公众意识以及开展合作，以有效缓解和检测深度伪造，从而维护数字媒体的信任和真实性。

> **ai_Abstract:** 本文探讨了深度伪造技术及其对数字信任的影响。随着生成式AI工具的普及，深度伪造的创建变得更加容易且成本更低，这引发了对信任、隐私和安全的严重担忧。文章通过使用可访问的工具演示了如何创建逼真的深度伪造，揭示了其在助长欺诈和虚假信息方面的风险。最终，论文强调了在技术和伦理挑战下，迫切需要监管、公众意识和合作来维护数字媒体的真实性。

> **摘要翻译:** 深度伪造技术揭秘：人工智能的商品化及其对数字信任的影响。随着生成式人工智能可及性的提高，语音克隆、换脸和合成媒体创作的工具已显著进步，降低了其使用的财务和技术门槛。尽管这些技术提供了创新机会，但其快速增长引发了对信任、隐私和安全的担忧。本白皮书探讨了深度伪造技术的影响，分析了其在助长欺诈、虚假信息以及侵蚀多媒体真实性方面的作用。通过使用Runway、Rope和ElevenLabs等经济高效、易于使用的工具，我们探讨了如何用有限资源创建逼真的深度伪造内容，从而展示了对个人和组织构成的风险。通过分析深度伪造缓解和检测的技术和伦理挑战，我们强调了建立监管框架、提高公众意识和加强协作以维护数字媒体信任的紧迫性。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [333] [CALMA: A Process for Deriving Context-aligned Axes for Language Model Alignment](https://arxiv.org/abs/2507.09060)
> *CALMA：一种推导语言模型对齐的上下文对齐轴线的方法*

*Prajna Soni, Deepika Raman, Dylan Hadfield-Menell* | **Category: cs.CY** | **Updated: 2025-07-15**

**Keywords:** 语言模型对齐, 上下文对齐, 数据集, AI治理, 参与式方法

**Comment:** 

> **TL;DR:** CALMA是一种扎根于实践的参与式方法，用于从特定社区中获取与上下文相关的语言模型对齐轴线，以解决现有基准的局限性。

**AI_Comments:** CALMA的创新之处在于其以社区为中心的参与式方法，解决了当前AI对齐中普遍存在的“一刀切”和西方中心化问题。它强调了在实际部署背景下，多样化用户需求的重要性，并为构建更公平、更具包容性的AI系统提供了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有的语言模型对齐和评估数据集依赖于研究人员或开发者定义的轴线，这些轴线通常源自非代表性样本，导致模型在实际部署中无法满足多样化用户社区的需求和期望。

**Method:** 本文引入了CALMA（Context-aligned Axes for Language Model Alignment），这是一种扎根于实践的参与式方法，用于获取与上下文相关的评估和对齐轴线。

**Result:** 在与两个不同社区的试点中，CALMA发现了标准基准中缺失的新颖优先事项。

**Conclusion:** 研究结果证明了基于开放式和用例驱动的评估实践的价值，并推动了多元化、透明和上下文敏感的对齐流程的发展。

> **ai_Abstract:** 本文介绍了CALMA，一种扎根于实践的参与式方法，旨在为语言模型对齐和评估获取与特定上下文相关的轴线。针对现有对齐数据集普遍存在的非代表性和西方中心化问题，CALMA通过与社区合作，成功发现了标准基准中未涵盖的新颖优先事项，证明了开放式、用例驱动评估的有效性，并促进了更具包容性和透明度的AI对齐实践。

> **摘要翻译:** 数据集在AI治理中发挥着核心作用，通过沿有用性、无害性、毒性和质量等轴线进行评估（衡量能力）和对齐（强制价值观）。然而，大多数对齐和评估数据集依赖于研究人员或开发者从非代表性样本中策划的轴线。结果，开发者通常根据广泛的（通常以西方为中心）价值观来评估模型，而忽略了模型实际部署的各种上下文。因此，在此类代理数据上训练的模型可能无法满足这些部署上下文中不同用户社区的需求和期望。为了弥合这一差距，我们引入了CALMA（Context-aligned Axes for Language Model Alignment），这是一种扎根于实践的参与式方法，用于获取与上下文相关的评估和对齐轴线。在与两个不同社区的试点中，CALMA发现了标准基准中缺失的新颖优先事项。我们的发现证明了基于开放式和用例驱动的评估实践的价值。我们的工作推动了多元化、透明和上下文敏感的对齐流程的发展。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [352] [Queueing for Civility: User Perspectives on Regulating Emotions in Online Conversations](https://arxiv.org/abs/2507.11477)
> *队列中的文明：用户对在线对话中情绪调节的看法*

*Akriti Verma, Shama Islam, Valeh Moghaddam, Adnan Anwar* | **Category: cs.CY, cs.HC** | **Updated: 2025-05-05**

**Keywords:** 在线对话, 情绪调节, 评论排队, 仇恨言论, 网络喷子

**Comment:** 

> **TL;DR:** 一项研究提出了一种评论排队机制，通过延迟发布来减少在线对话中的仇恨言论和愤怒，并通过用户调查显示其具有积极潜力。

**AI_Comments:** 这项研究提出了一种新颖的实时情绪管理方法，不同于传统的审查方式。其创新点在于通过短暂延迟来促进用户自我反思，从而从源头上减少有害内容的产生。研究结果显示了其在减少仇恨言论和愤怒方面的潜力，并且用户反馈也积极，这表明该机制具有实际应用价值。然而，研究也指出用户自身的情绪状态会影响他们对该机制的接受度，这可能是未来部署时需要考虑的限制因素。

<details>
  <summary>Details</summary>

**Motivation:** 在线对话中，网络喷子行为常导致用户情绪困扰和冲突。现有研究主要关注事后内容审核，但缺乏实时情绪管理的方法。

**Method:** 本研究采用混合方法设计。通过分析Reddit上15,000次用户互动，评估评论排队机制对减少仇恨言论和愤怒的影响。同时，对用户进行问卷调查，收集他们对该机制的反馈。

**Result:** 评论排队机制可将仇恨言论和愤怒的传播减少高达15%，仅有4%的评论被平均延迟约47秒。93.3%的参与者认为该机制有助于平息讨论，并希望在社交媒体平台使用。83%的人认为它能减少冲动性评论并平衡对话情绪。用户情绪状态与对延迟的看法存在关联，平静的用户认为有帮助，而沮丧的用户则预感会沮丧。

**Conclusion:** 评论排队机制有望成为一种有效的实时情绪管理工具，能够减少在线对话中的负面情绪和冲动性言论，尽管其有效性可能受用户初始情绪状态的影响。

> **ai_Abstract:** 本研究提出了一种评论排队机制，通过延迟评论发布来鼓励用户自省，并减少冲动性和有害评论的影响。该机制在Reddit的15,000次用户互动分析中显示，能将仇恨言论和愤怒的传播减少高达15%，且仅有少量评论被短暂延迟。用户调查结果显示，绝大多数参与者认为该机制有助于平息讨论，并能减少冲动性评论，平衡对话情绪。研究还发现，用户在使用社交媒体时的典型情绪状态会影响他们对延迟机制的看法。

> **摘要翻译:** 在线对话常被网络喷子行为打断，这会导致用户情绪困扰和冲突。以往的研究主要集中在内容发布后的有害内容审核，但实时管理情绪的方法仍未被探索。本研究提出了一种评论排队机制，该机制通过延迟评论发布、鼓励自我反思，并减少冲动和有害评论的影响。为了评估这种方法的有效性，本研究采用了一种混合方法的研究设计。对Reddit上15,000次用户互动进行分析表明，这种方法可以将仇恨言论和愤怒的传播减少高达15%，而只有4%的评论被平均延迟约47秒。我们还对用户进行了问卷调查，以获取对该机制的反馈。结果显示，93.3%的参与者认为排队机制有助于平息讨论，并表示有兴趣在社交媒体平台看到它被使用。此外，83%的人认为它会减少冲动性评论并平衡对话中的情绪基调。我们发现用户在使用社交媒体时的典型情绪状态与他们对延迟的看法之间存在密切联系，平静的用户认为该机制有帮助，而沮丧的用户则预感会感到沮丧。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [380] [Exploring User Security and Privacy Attitudes and Concerns Toward the Use of General-Purpose LLM Chatbots for Mental Health](https://arxiv.org/abs/2507.10695)
> *探索用户对使用通用型大型语言模型聊天机器人进行心理健康的安全性与隐私态度及担忧*

*Jabari Kwesi, Jiaxun Cao, Riya Manchanda, Pardis Emami-Naeini* | **Category: cs.CY, cs.AI, cs.CR, cs.ET, cs.HC** | **Updated: 2025-07-14**

**Keywords:** 通用型LLM聊天机器人, 心理健康, 隐私, 安全, 无形脆弱性

**Comment:** Accepted to the 34th USENIX Security Symposium

> **TL;DR:** 研究发现，用户在使用通用型LLM聊天机器人进行心理健康支持时，对隐私和安全存在严重误解和风险意识不足，误以为对话受医疗法规保护，并低估了情感披露的脆弱性。

**AI_Comments:** 这项研究具有重要意义，因为它填补了通用型LLM聊天机器人用于心理健康领域中用户隐私和安全认知方面的空白。其创新之处在于提出了“无形脆弱性”的概念，揭示了用户在情感和心理数据保护方面的独特盲点。研究强调了在LLM应用中进行用户教育和制定明确指导方针的紧迫性，以避免潜在的隐私泄露和信任危机。

<details>
  <summary>Details</summary>

**Motivation:** 尽管人们日益依赖LLM聊天机器人获取情感支持，但现有研究主要关注基于规则的心理健康聊天机器人，缺乏针对通用型LLM聊天机器人用户隐私和安全担忧的实证研究。

**Method:** 通过对21名美国参与者进行半结构化访谈。

**Result:** 发现了严重的误解和普遍的风险意识不足。参与者将LLM表现出的类人同理心与类人责任混淆，并错误地认为与这些聊天机器人的互动受到与持牌治疗师对话相同的法规（例如HIPAA）保护。研究引入了“无形脆弱性”的概念，即与更具体形式的信息（如财务或基于位置的数据）相比，情感或心理披露的价值被低估。

**Conclusion:** 提出了更有效保护用户在使用通用型LLM聊天机器人进行心理健康披露时的建议。

> **ai_Abstract:** 本研究通过对21名美国用户进行访谈，探讨了他们在利用通用型大型语言模型（LLM）聊天机器人进行心理健康管理时的安全和隐私态度及担忧。研究发现，用户普遍存在对风险的误解和意识不足，他们将LLM的同理心误认为人类的责任，并错误地认为与LLM的互动受到医疗法规的保护。文章提出了“无形脆弱性”的概念，指出用户低估了情感和心理披露的价值。最后，研究提出了保护用户心理健康披露的建议。

> **摘要翻译:** 个人越来越依赖大型语言模型（LLM）支持的对话代理来获取情感支持。虽然先前的研究已经检查了专门为心理健康目的设计的聊天机器人中的隐私和安全问题，但这些聊天机器人绝大多数是“基于规则”的产品，不利用生成式AI。目前很少有实证研究衡量用户在使用通用型LLM支持的聊天机器人来管理和改善心理健康时的隐私和安全担忧、态度和期望。通过对21名美国参与者进行的半结构化访谈，我们发现了关键的误解和普遍的风险意识不足。参与者将LLM表现出的类人同理心与类人责任混淆，并错误地认为他们与这些聊天机器人的互动受到与持牌治疗师披露信息相同的法规（例如HIPAA）保护。我们引入了“无形脆弱性”的概念，即与更具体形式的信息（例如财务或基于位置的数据）相比，情感或心理披露的价值被低估。为了解决这个问题，我们提出了更有效地保护用户在使用通用型LLM支持的聊天机器人进行心理健康披露的建议。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [458] [Can Large Language Models Understand As Well As Apply Patent Regulations to Pass a Hands-On Patent Attorney Test?](https://arxiv.org/abs/2507.10576)
> *大型语言模型能否像人类一样理解并应用专利法规以通过专利律师实操考试？*

*Bhakti Khera, Rezvan Alamian, Pascal A. Scherz, Stephan M. Goetz* | **Category: cs.CY, cs.AI, cs.CL, cs.ET** | **Updated: 2025-07-11**

**Keywords:** 大型语言模型, 专利法, 法律人工智能, 欧洲资格考试, LLM评估

**Comment:** 39 pages, 21 figures

> **TL;DR:** 大型语言模型（LLMs）在专利律师考试中表现不佳，无一通过，显示出在法律应用中的显著局限性，尽管某些模型得分较高，但仍需专家监督和进一步发展。

**AI_Comments:** 本文通过使用真实的、高风险的专业考试（EQE）作为基准，对LLMs在专利法等高度专业化法律领域的能力提供了重要的现实检验，这超越了典型的学术数据集。研究发现人类专家对法律依据的判断常与自动指标不符，这一洞察尤为深刻，揭示了在法律领域开发真正可靠AI的关键挑战。论文强调了专家监督的必要性和特定局限性（逻辑一致性、多模态、提示敏感性），这对于指导未来研究开发更健壮、更值得信赖的法律AI至关重要。它表明，尽管当前LLMs具有令人印象深刻的通用能力，但离成为“虚拟专利律师”还有很长的路要走。

<details>
  <summary>Details</summary>

**Motivation:** 法律领域已在使用各种大型语言模型（LLMs），但其定量性能及其原因尚未得到充分探索。本文旨在评估LLMs理解和应用专利法规以通过专利律师实操考试的能力，并指出具体局限性。

**Method:** 研究评估了多种开源和专有LLMs（包括GPT系列、Anthropic、Deepseek和Llama-3变体）在欧洲专利律师资格考试（EQE）的部分试题上的表现。同时，人类专利专家也对模型的文本解释进行了评估。

**Result:** OpenAI o1以0.82的准确率和0.81的F1分数领先，而AWS Llama 3.1 8B的准确率为0.50，Python部署的Llama 3.1 8B为0.55。没有一个被评估的模型达到专业水平所需的0.90准确率阈值。GPT-4o在整合文本和图形方面表现出色，而Claude 3 Opus常失去格式连贯性。人类专家评估揭示了模型的各种关键缺陷，他们更看重清晰度和法律依据而非答案的原始正确性，这表明自动指标与专家判断之间存在偏差。模型输出对微小的温度变化和提示措辞敏感。

**Conclusion:** 尽管近期大型模型表现出色，但公众可能高估了它们在法律语境下的性能。开发虚拟专利律师还有很长的路要走，需要解决逻辑一致性、鲁棒多模态和自适应提示等限制。专家监督仍然是必要的。

> **ai_Abstract:** 本文评估了包括GPT系列、Anthropic、Deepseek和Llama-3变体在内的多种大型语言模型（LLMs）在欧洲专利律师资格考试（EQE）部分试题上的定量表现。研究发现，尽管某些模型（如OpenAI o1）表现较好（0.82准确率），但没有模型能达到专业水平所需的0.90准确率。人类专家评估揭示了模型在文本解释方面的关键缺陷，强调法律依据和清晰度比单纯的答案正确性更重要，这表明自动评估与专家判断之间存在偏差。研究得出结论，尽管LLMs近期有显著进展，但在复杂的法律应用中仍存在重大局限性，需要进一步在逻辑一致性、多模态和自适应提示方面进行开发，并强调了持续的人类专家监督的必要性。

> **摘要翻译:** 法律领域已在实际应用中使用各种大型语言模型（LLMs），但其定量性能及其原因尚未得到充分探索。我们评估了几种开源和专有LLMs——包括GPT系列、Anthropic、Deepseek和Llama-3变体——在未来欧洲专利律师的欧洲资格考试（EQE）的部分试题上的表现。OpenAI o1以0.82的准确率和0.81的F1分数领先，而（亚马逊网络服务）AWS Llama 3.1 8B则以0.50的准确率落后，Python部署的Llama 3.1 8B得分为0.55。后两者在双选强制选择设计中处于纯粹猜测的范围内。没有一个被评估的模型能够完全通过考试，因为准确率从未超过专业水平所需的0.90平均阈值——即使是那些经常被宣传其性能超越博士和已获得律师执照的律师水平的模型也未能达到。GPT-4o擅长整合文本和图形，而Claude 3 Opus则经常失去格式连贯性。人类专利专家评估了文本解释，并揭示了每个模型的各种关键缺陷。他们更看重清晰度和法律依据，而非答案的原始正确性，这揭示了自动指标与专家判断之间的不一致。模型输出对适度的温度变化和提示措辞敏感，这强调了专家监督的必要性。未来的工作应针对逻辑一致性、鲁棒多模态和自适应提示，以接近人类水平的专利专业能力。总而言之，尽管最近的大型模型表现出色，但公众可能高估了它们的性能。该领域在开发虚拟专利律师方面还有很长的路要走。本文旨在指出需要解决的几个具体限制。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [464] ["Is it always watching? Is it always listening?" Exploring Contextual Privacy and Security Concerns Toward Domestic Social Robots](https://arxiv.org/abs/2507.10786)
> *它总是在看吗？它总是在听吗？探索家用社交机器人中的情境隐私和安全问题*

*Henry Bell, Jabari Kwesi, Hiba Laabadli, Pardis Emami-Naeini* | **Category: cs.CY, cs.AI, cs.CR, cs.ET** | **Updated: 2025-07-14**

**Keywords:** 社交机器人, 隐私, 安全, 用户担忧, 数据收集

**Comment:** 

> **TL;DR:** 本研究调查了美国消费者对家用社交机器人的隐私和安全担忧，发现用户需要透明的数据收集、可用性和强大的隐私控制以促进采用。

**AI_Comments:** 这篇论文在一个新兴且关键的领域——家用社交机器人——中探讨了隐私和安全问题，其创新之处在于通过用户访谈深入了解了实际担忧，而非仅仅停留在技术层面。其重要性在于，在技术商业化早期阶段就提出了指导性建议，有助于未来设计更符合用户需求和信任的产品。局限性可能在于样本量相对较小（19人），可能无法完全代表所有美国消费者的观点。

<details>
  <summary>Details</summary>

**Motivation:** 社交机器人因其广泛的数据收集能力、拟人化特征和与环境交互的能力，比传统智能家居设备带来更显著的安全和隐私威胁。在这些设备在美国市场商业化仍处于早期阶段时，调查美国用户的安全和隐私需求和担忧对于指导社交机器人的设计至关重要。

**Method:** 通过19次半结构化访谈。

**Result:** 研究识别出显著的安全和隐私担忧，强调了透明度、可用性和强大的隐私控制对于支持采用的必要性。在教育应用中，参与者最担心虚假信息；在医疗用例中，他们担心设备的可靠性。参与者还关注社交机器人可能促成的数据推断。研究发现参与者期望有形可见的隐私控制、数据收集指示器以及符合情境的功能。

**Conclusion:** 为了促进社交机器人的采用，设计者必须解决用户的隐私和安全担忧，提供透明的数据收集指示、可操作的隐私控制和情境适宜的功能。

> **ai_Abstract:** 这项研究探讨了美国消费者对家用社交机器人的隐私和安全担忧。由于社交机器人具有广泛的数据收集能力和拟人化特性，它们带来了比传统智能家居设备更大的隐私和安全威胁。通过19次半结构化访谈，研究发现用户对数据收集、数据推断、虚假信息（教育应用）和设备可靠性（医疗应用）存在显著担忧。研究强调，为促进社交机器人的采用，设计者应提供透明的数据收集指示、可用的隐私控制以及情境适宜的功能。

> **摘要翻译:** 配备人工智能（AI）和先进传感能力的社交机器人在美国消费者中引起了兴趣。这些机器人似乎是传统智能家居设备的自然演变。然而，它们广泛的数据收集能力、拟人化特征以及与环境交互的能力使社交机器人成为更显著的安全和隐私威胁。增加的风险包括数据关联、未经授权的数据共享以及用户及其家庭的物理安全。在这些设备在美国市场商业化仍处于早期阶段时，调查美国用户的安全和隐私需求和担忧对于指导社交机器人的设计至关重要。通过19次半结构化访谈，我们识别了显著的安全和隐私担忧，强调了透明度、可用性和强大的隐私控制对于支持采用的必要性。对于教育应用，参与者最担心虚假信息；在医疗用例中，他们担心这些设备的可靠性。参与者还关注社交机器人可能促成的数据推断。我们发现参与者期望有形可见的隐私控制、数据收集指示器以及符合情境的功能。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [634] [Capturing Dynamics in Online Public Discourse: A Case Study of Universal Basic Income Discussions on Reddit](https://arxiv.org/abs/2312.09611)
> *捕捉在线公共话语的动态：以Reddit上的全民基本收入讨论为例*

*Rachel Kim, Veniamin Veselovsky, Ashton Anderson* | **Category: cs.CY, cs.SI** | **Updated: 2025-07-14**

**Keywords:** 在线公共话语, 全民基本收入, Reddit, 意见变化, 社会驱动因素

**Comment:** ICWSM 2025

> **TL;DR:** 本研究利用Reddit上关于全民基本收入（UBI）的讨论，提出了一个观察在线意见变化的模型，并发现UBI的总体立场在2019年中期发生逆转，主要驱动因素是不同用户群体、财富水平相似社区和党派倾向相似社区内部的变化。

**AI_Comments:** 该论文通过利用大规模在线公共话语数据，弥补了传统民意调查在捕捉多维意见动态方面的不足。其创新之处在于提出了一个概念模型来分析在线意见变化，并成功应用于UBI案例。研究结果揭示了在线平台中意见转变的社会驱动因素，为理解和预测公共政策讨论的演变提供了新视角。该方法具有普适性，可应用于其他重要社会议题。

<details>
  <summary>Details</summary>

**Motivation:** 传统民意调查和问卷调查难以捕捉大型异质人群中意见的完整多维丰富性和多样性。随着越来越多的公共政策讨论在线上平台进行，这为以更高分辨率和上下文测量民意变化提供了机会。

**Method:** 提出一个观察在线平台意见变化的概念模型，并将其应用于研究Reddit上全民基本收入（UBI）的历史公共讨论。该研究分析了UBI作为一项明确的政策提案，由于自动化和COVID-19大流行等趋势而受到关注。

**Result:** 研究发现，Reddit上对UBI的总体立场在2019年中期之前显著下降，之后突然逆转并变得更加支持。立场变化最显著的驱动因素是不同用户群体、财富水平相似社区以及党派倾向相似社区内部的转变。

**Conclusion:** 该研究提出的方法能够识别大规模在线公共话语中意见变化的细微社会驱动因素，并且可以应用于广泛的其他重要议题和政策。

> **ai_Abstract:** 本研究提出了一个概念模型，用于捕捉在线平台上的意见动态，并将其应用于分析Reddit上关于全民基本收入（UBI）的讨论。研究发现，Reddit上对UBI的总体支持度在2019年中期前下降，随后逆转并大幅上升。这种转变的主要驱动力是不同用户群体、财富水平相似社区和党派倾向相似社区内部的立场变化。该方法能够识别大规模在线公共话语中意见变化的社会驱动因素，并具有广泛的应用潜力。

> **摘要翻译:** 社会变革往往由公众舆论的转变驱动。随着公民的规范、信仰和价值观的演变，公共政策也随之改变。尽管传统的民意调查和问卷调查可以勾勒出特定话题公众舆论是否正在发生变化的总体趋势，但它们通常无法捕捉大型异质人群中存在的意见的完整多维丰富性和多样性。然而，越来越多的公共政策问题讨论现在发生在在线平台上，这为以定性不同的分辨率和上下文尺度测量民意变化提供了机会。

在本文中，我们提出了一个观察在线平台意见变化的概念模型，并将其应用于研究Reddit上全民基本收入（UBI）的历史公共话语。UBI是一种定期、无附加条件的现金支付，给予人口中的每个公民。我们研究UBI，因为它是一个明确的政策提案，最近因自动化等趋势和COVID-19大流行等事件而引起了兴趣激增。我们发现，Reddit上对UBI的总体立场在2019年中期之前显著下降，之后这种历史趋势突然逆转，Reddit变得更加支持。使用我们的模型，我们发现这种总体立场变化最显著的驱动因素是不同用户群体内部、代表相似财富水平的社区内部以及代表相似党派倾向的社区内部的转变。我们的方法识别了现在定期在线发生的大规模公共话语中意见变化的细微社会驱动因素，并且可以应用于广泛的其他重要议题和政策。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [260] [Three-dimensional SPH modeling of brittle fracture under hydrodynamic loading](https://arxiv.org/abs/2507.10553)
> *三维SPH水动力载荷下脆性断裂建模*

*Vishabjeet Singh, Chong Peng, Md Rushdie Ibne Islam* | **Category: cs.CE** | **Updated: 2025-04-27**

**Keywords:** SPH, 脆性断裂, 流固耦合, 三维建模, 水动力载荷

**Comment:** 30 pages, 20 figures

> **TL;DR:** 开发了一个三维SPH计算框架，用于模拟流固耦合中的结构变形和脆性断裂，无需复杂的裂纹追踪算法。

**AI_Comments:** 该论文的创新之处在于提出了一种无需传统裂纹追踪算法即可模拟三维脆性断裂的SPH框架，这显著降低了计算复杂性。其统一的流固耦合方法也提高了模型的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 需要一种能够有效捕捉流固耦合中结构变形和失效的统一建模方法，尤其是在水动力载荷下，且能避免计算密集型裂纹追踪算法的限制。

**Method:** 该框架结合了弱可压缩SPH和基于伪弹簧的SPH求解器来捕捉流体流动和可变形结构。采用统一建模方法处理固体边界和流固界面，无需惩罚接触力。使用$\delta$-SPH技术改进流体相中的压力计算，并利用伪弹簧方法模拟结构损伤，粒子相互作用仅限于邻居。该方法能够捕捉三维裂纹表面，无需计算密集型裂纹追踪算法或可见性标准。

**Result:** 该框架已证明对现有模型和实验数据有效，在模拟详细断裂模式方面表现出高精度和鲁棒性，并为水动力事件对结构完整性的影响提供了见解。

**Conclusion:** 所提出的三维SPH计算框架能够准确有效地模拟水动力载荷下的脆性断裂和流固耦合，且无需复杂的裂纹追踪算法，表现出高精度和鲁棒性。

> **ai_Abstract:** 本文提出了一个三维光滑粒子流体动力学（SPH）计算框架，用于模拟流固耦合中的结构变形和脆性断裂。该框架结合了弱可压缩SPH和伪弹簧SPH求解器，采用统一方法处理流固界面，并利用$\delta$-SPH改进压力计算。其独特之处在于能捕捉三维裂纹表面，且无需复杂的裂纹追踪算法。实验证明该框架在模拟详细断裂模式方面具有高精度和鲁棒性。

> **摘要翻译:** 提出了一个三维SPH计算框架，用于模拟流固耦合与结构变形和失效。我们将弱可压缩SPH与基于伪弹簧的SPH求解器相结合，以捕捉流体流动和可变形结构。一种统一的建模方法可以在没有基于惩罚的接触力的情况下捕捉固体边界和流固界面。$\delta$-SPH技术改进了流体相中的压力计算，而结构损伤则使用伪弹簧方法建模，粒子相互作用仅限于其邻居。本框架可以在结构中捕捉三维裂纹表面，无需任何计算密集型裂纹追踪算法或可见性标准。该框架已被证明对现有模型和实验数据有效，在模拟详细断裂模式方面表现出高精度和鲁棒性，并提供了关于水动力事件对结构完整性影响的见解。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [298] [The Multiple Time-Stepping Method for 3-Body Interactions in High Performance Molecular Dynamics Simulations](https://arxiv.org/abs/2507.11172)
> *高性能分子动力学模拟中三体相互作用的多时间步长方法*

*David Martin, Samuel James Newcome, Markus Mühlhäußer, Manish Kumar Mishra, Fabio Alexander Gratl, Hans-Joachim Bungartz* | **Category: cs.CE** | **Updated: 2025-07-15**

**Keywords:** 分子动力学, 三体相互作用, 多时间步长, 并行计算, AutoPas

**Comment:** 26 pages, 7 figures. Submitted to the 5th International Conference on
  Computational Engineering (ICCE 2024). No changes were made after the peer
  review process

> **TL;DR:** 本文研究并实现了一种多时间步长算法，结合并行计算方法，以提高涉及三体相互作用的分子动力学模拟效率。

**AI_Comments:** 本文通过结合r-RESPA多时间步长算法与并行计算技术，有效解决了分子动力学模拟中三体相互作用计算成本高昂的问题。其创新点在于提出了一种新颖的共享内存并行截止方法，并将其在AutoPas库中实现，这对于提升大规模分子模拟的效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 分子动力学（MD）模拟在理解复杂分子系统行为中至关重要。传统的双体势无法完全捕捉分子系统的复杂性，因此需要引入计算成本高昂（立方复杂度）的三体相互作用，这限制了MD模拟的效率。

**Method:** 采用r-RESPA多时间步长算法来减少三体相互作用的计算次数。结合高性能计算（HPC）方法进行并行化，具体研究了文献中的通信减少分布式内存并行方法，并提出了一种新颖的共享内存并行截止方法，该方法在粒子模拟库AutoPas中实现。

**Result:** 讨论了结果和方法，为分子动力学模拟效率的潜在进步提供了见解。

**Conclusion:** 通过应用r-RESPA多时间步长算法和并行计算方法，可以显著提高涉及三体相互作用的分子动力学模拟的计算效率。

> **ai_Abstract:** 本文旨在提高涉及高计算成本三体相互作用的分子动力学（MD）模拟的效率。研究人员利用r-RESPA多时间步长算法减少三体计算量，并结合高性能计算（HPC）的并行化方法。文中探讨了一种现有的分布式内存并行方法，并提出了一种新的共享内存并行截止方法，该方法已在AutoPas库中实现，为MD模拟的效率提升提供了新思路。

> **摘要翻译:** 理解分子系统的复杂行为是物理学、材料科学和生物学等领域的基础。分子动力学（MD）模拟是研究原子级动力学的关键工具。这项工作侧重于提高涉及双体和三体相互作用的MD模拟的效率。传统的双体势通常无法完全捕捉分子系统的复杂性，因此包含三体相互作用变得很重要。然而，这些相互作用属于立方复杂度，而双体相互作用是二次复杂度，因此计算成本很高，即使应用了截止距离也是如此。提高效率的一种方法是使用r-RESPA多时间步长算法来减少三体相互作用的计算次数。在这项工作中，我们在并行化计算的高性能计算（HPC）方法的背景下研究了这种方法。特别是，我们研究了文献中一种减少通信的分布式内存并行方法，并提出了一种新颖的共享内存并行截止方法，该方法在粒子模拟库AutoPas中实现。讨论了结果和方法，为MD模拟效率的潜在进步提供了见解。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [343] [Data-Driven Differential Evolution in Tire Industry Extrusion: Leveraging Surrogate Models](https://arxiv.org/abs/2507.11191)
> *轮胎工业挤压中的数据驱动差分进化：利用代理模型*

*Eider Garate-Perez, Kerman López de Calle-Etxabe, Susana Ferreiro* | **Category: cs.CE, cs.LG, J.6; I.2; H.4** | **Updated: 2025-07-15**

**Keywords:** 数据驱动, 差分进化, 代理模型, 工业优化, 挤压过程

**Comment:** 22 pages, 15 figures

> **TL;DR:** 本研究提出了一种基于代理模型的数据驱动方法，用于优化轮胎制造挤压过程中的工业系统，通过历史数据和机器学习模型，显著减少了初始化和设置时间以及材料浪费。

**AI_Comments:** 该论文的创新点在于将数据驱动的机器学习代理模型与定制的差分进化元启发式算法相结合，以解决传统优化方法在缺乏显式数学公式的工业过程中的局限性。其重要性体现在为实际工业问题（如轮胎挤压过程）提供了有效的解决方案，显著提高了生产效率并减少了浪费，具有重要的工业应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 当目标函数或约束没有数学公式时，工业过程的优化是一个关键挑战。本研究旨在解决这一问题，通过仅利用历史过程数据来优化复杂的现实世界制造系统。

**Method:** 本研究提出了一种基于代理模型的数据驱动方法，利用机器学习模型来近似系统行为并构建代理模型。这些代理模型被集成到一种定制的元启发式方法中：数据驱动差分进化（Data-Driven Differential Evolution），该方法结合了多级惩罚函数和代理模型，是差分进化的一种适应性版本。该方法应用于轮胎制造业的挤压过程，目标是优化初始化参数。

**Result:** 代理优化方法优于历史最佳配置，实现了初始化和设置时间65%的减少，同时显著减少了材料浪费。

**Conclusion:** 研究结果突出了在缺乏明确公式的工业过程中，结合数据驱动建模和元启发式优化的潜力。

> **ai_Abstract:** 本研究提出了一种基于代理模型的数据驱动方法，用于优化缺乏明确数学公式的复杂工业过程。该方法利用机器学习模型构建代理模型，并将其整合到一种定制的数据驱动差分进化算法中。将该方法应用于轮胎制造业的挤压过程，以优化初始化参数并减少浪费。实验结果显示，该方法显著优于现有配置，实现了初始化和设置时间65%的减少，并显著降低了材料浪费，证明了数据驱动建模与元启发式优化结合在工业应用中的有效性。

> **摘要翻译:** 工业过程的优化仍然是一个严峻的挑战，特别是在目标函数或约束没有数学公式可用的情况下。本研究通过提出一种基于代理模型的数据驱动方法来解决这个问题，该方法仅利用历史过程数据来优化复杂的现实世界制造系统。研究中采用机器学习模型来近似系统行为并构建代理模型，这些代理模型被整合到一种定制的元启发式方法中：数据驱动差分进化（Data-Driven Differential Evolution），该方法结合了多级惩罚函数和代理模型，是差分进化的一种适应版本，适合所研究过程的特点。该方法应用于轮胎制造业的挤压过程，目标是优化初始化参数以减少浪费和生产时间。结果表明，基于代理的优化方法优于历史最佳配置，实现了初始化和设置时间65%的减少，同时显著减少了材料浪费。这些发现突出了在缺乏明确公式的工业过程中，结合数据驱动建模和元启发式优化的潜力。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [484] [FinRL Contests: Benchmarking Data-driven Financial Reinforcement Learning Agents](https://arxiv.org/abs/2504.02281)
> *FinRL 竞赛：基准化数据驱动的金融强化学习智能体*

*Keyi Wang, Nikolaus Holzer, Ziyi Xia, Yupeng Cao, Jiechao Gao, Anwar Walid, Kairong Xiao, Xiao-Yang Liu Yanglet* | **Category: cs.CE** | **Updated: 2025-07-15**

**Keywords:** 金融强化学习, FinRL竞赛, 基准测试, 金融工程, 数据驱动

**Comment:** arXiv admin note: text overlap with arXiv:2501.10709

> **TL;DR:** FinRL竞赛旨在通过提供标准化任务、高质量数据集和模拟环境，解决金融强化学习在实际应用中遇到的挑战，并促进该领域的复现性研究。

**AI_Comments:** 该论文的创新之处在于组织了一个大规模、标准化的金融强化学习（FinRL）基准测试平台，解决了实际应用中的关键问题。其重要性在于通过提供标准化的环境和数据集，促进了FinRL领域可复现的研究和开发。此外，纳入大型语言模型（LLM）工程信号的应用也体现了其前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** 将强化学习策略应用于现实世界的交易任务对个人而言仍然充满挑战，因为这容易出错且工程量大。金融数据的非平稳性、低信噪比以及各种市场摩擦需要深厚的积累。尽管已经开发了许多FinRL方法用于股票/加密货币交易和投资组合管理等任务，但缺乏标准化的任务定义、实时高质量数据集、接近真实的市场环境以及稳健的基线，阻碍了开源社区和金融科技行业的持续复现。

**Method:** 为了弥合这一差距，作者组织了一系列从2023年到2025年的FinRL竞赛，涵盖了股票交易、订单执行、加密货币交易以及使用大型语言模型（LLM）工程信号等多种金融任务。为了鼓励参与，他们提供了包含GPU优化并行市场环境、集成学习和全面说明的入门套件。本文总结了这些基准测试工作，详细介绍了任务制定、数据整理流程、环境实现、评估协议、参与者表现和组织见解。

**Result:** 这些竞赛吸引了来自20多个国家100多个机构的200多名参与者。本文总结了这些基准测试工作，详细介绍了任务制定、数据整理流程、环境实现、评估协议、参与者表现和组织见解。

**Conclusion:** 这些基准测试工作将指导后续的FinRL竞赛，并为类似的金融AI竞赛提供参考，旨在弥合金融强化学习领域在持续复现和标准化方面的差距。

> **ai_Abstract:** 本论文介绍了FinRL竞赛，这是一系列从2023年到2025年组织的比赛，旨在解决金融强化学习（FinRL）在实际交易任务应用中面临的挑战和标准化不足。这些挑战包括数据非平稳性、低信噪比、市场摩擦以及缺乏标准化的任务定义、高质量数据集、真实环境和稳健基线。竞赛吸引了全球200多名参与者，涵盖了多种金融任务，并提供了全面的入门套件。论文总结了这些基准测试工作，详细阐述了方法、数据、环境、评估和参与者表现，旨在指导未来的FinRL倡议并为金融AI竞赛提供参考。

> **摘要翻译:** 金融强化学习（FinRL）现在已成为金融工程的一个实用范式。然而，将强化学习策略应用于现实世界的交易任务对个人而言仍然充满挑战，因为这容易出错且工程量大。金融数据的非平稳性、低信噪比以及各种市场摩擦需要深厚的积累。尽管已经开发了许多FinRL方法用于股票/加密货币交易和投资组合管理等任务，但缺乏标准化的任务定义、实时高质量数据集、接近真实的市场环境以及稳健的基线，阻碍了开源社区和金融科技行业的持续复现。为了弥合这一差距，我们组织了一系列从2023年到2025年的FinRL竞赛，涵盖了股票交易、订单执行、加密货币交易以及使用大型语言模型（LLM）工程信号等多种金融任务。这些竞赛吸引了来自20多个国家100多个机构的200多名参与者。为了鼓励参与，我们提供了包含GPU优化并行市场环境、集成学习和全面说明的入门套件。在本文中，我们总结了这些基准测试工作，详细介绍了任务制定、数据整理流程、环境实现、评估协议、参与者表现和组织见解。它将指导我们后续的FinRL竞赛，并为类似的金融AI竞赛提供参考。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='csfl'></a>
## cs.FL 

### [208] [A Decision Procedure for Probabilistic Kleene Algebra with Angelic Nondeterminism](https://arxiv.org/abs/2507.10980)
> *具有天使非确定性的概率克莱尼代数的判定过程*

*Shawn Ong, Dexter Kozen* | **Category: cs.FL, F.4.3; F.1.1** | **Updated: 2025-07-15**

**Keywords:** 判定过程, 概率克莱尼代数, 天使非确定性, 等式理论

**Comment:** 

> **TL;DR:** 本文提出了一个用于具有天使非确定性的概率克莱尼代数等式理论的判定过程及其正确性证明。

**AI_Comments:** 这篇论文的创新点在于为一种特定的代数结构（具有天使非确定性的概率克莱尼代数）提供了决策过程，这对于该理论的自动化推理和验证具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是为Ong, Ma和Kozen (2025)中引入的具有天使非确定性的概率克莱尼代数的等式理论提供一个判定过程。

**Method:** 本文通过提供一个判定过程及其正确性证明来解决问题。

**Result:** 本文为具有天使非确定性的概率克莱尼代数的等式理论建立了一个判定过程及其正确性证明。

**Conclusion:** 本文成功地为Ong, Ma和Kozen (2025)中提出的具有天使非确定性的概率克莱尼代数的等式理论提供了一个判定过程和正确性证明。

> **ai_Abstract:** 本文提出了一个针对Ong, Ma和Kozen (2025)所引入的具有天使非确定性的概率克莱尼代数等式理论的判定过程，并对其正确性进行了证明。

> **摘要翻译:** 我们为Ong, Ma和Kozen (2025)中引入的具有天使非确定性的概率克莱尼代数的等式理论提供了一个判定过程和正确性证明。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [247] [Polynomial Complementation of Nondeterministic 2-Way Finite Automata by 1-Limited Automata](https://arxiv.org/abs/2507.11209)
> *非确定性双向有限自动机通过1-受限自动机的多项式补码*

*Bruno Guillon, Luca Prigioniero, Javad Taheri* | **Category: cs.FL, 68Q45, F.4.3; F.1.1** | **Updated: 2025-07-15**

**Keywords:** 非确定性有限自动机, 1-受限自动机, 补码, 复杂度, 正则语言

**Comment:** 

> **TL;DR:** 证明了非受限2NFA可以通过多项式大小的1-LA进行补码，且补码1-LA需要单指数复杂度。

**AI_Comments:** 这篇论文的关键创新在于证明了2NFA可以通过多项式大小的1-LA进行补码，并且发现这种构造是自验证的。更重要的是，它确定了补码1-LA的精确复杂度界限为单指数，这对理解这些自动机模型的计算能力和局限性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 探索非确定性双向有限自动机（2NFA）和1-受限自动机（1-LA）的补码操作的复杂性。

**Method:** 通过构造证明，展示了如何用1-LA对2NFA进行补码，并分析了其大小和复杂性。

**Result:** 证明了任何非受限的2NFA都可以通过仅多项式大小增长的1-LA进行补码，且生成的机器是1-LA的受限形式（带共同猜测的2NFA）并且是自验证的。此外，该构造的推论是，补码1-LA需要且仅需要单指数复杂度。

**Conclusion:** 本文的构造证明了1-受限自动机的补码需要单指数复杂度。

> **ai_Abstract:** 本文证明了非受限双向非确定性有限自动机（2NFA）可以通过1-受限自动机（1-LA）进行多项式大小的补码。这种补码得到的机器是自验证的，且是1-LA的受限形式。研究进一步得出结论，补码1-LA需要且仅需要单指数复杂度。

> **摘要翻译:** 我们证明，仅需付出多项式大小的增长，每个非受限的双向非确定性有限自动机（2NFA）都可以通过1-受限自动机（1-LA）进行补码，1-LA是2NFA的一种非确定性扩展，仍然表征正则语言。所得机器实际上是1-LA的一种受限形式——被称为带共同猜测的2NFA——并且是自验证的。我们构造的一个推论是，补码1-LA需要且仅需要单指数复杂度。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [382] [On the Intersection Problem for Quantum Finite Automata](https://arxiv.org/abs/2406.13797)
> *量子有限自动机交集问题研究*

*Andrea Benso, Flavio D'Alessandro, Paolo Papi* | **Category: cs.FL, 81P68, 68Q45, 03D05** | **Updated: 2025-07-15**

**Keywords:** 量子有限自动机, 交集问题, 递归可判定性, 上下文无关文法, 形式语言

**Comment:** arXiv admin note: text overlap with arXiv:1303.2967 -- Expanded
  version, with different title. To appear in Theoretical Computer Science

> **TL;DR:** 本文研究了量子有限自动机识别的语言与特定上下文无关语言的交集是否可递归判定。

**AI_Comments:** 这篇论文对量子计算理论中的形式语言理论做出了贡献，特别是解决了量子有限自动机与特定上下文无关语言之间交集的可判定性问题，这对于理解量子计算模型的计算能力和限制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文是对Moore和Crutchfield于2000年引入的“一次测量有限量子自动机”模型先前研究的延续，旨在探讨其语言交集的可判定性问题。

**Method:** 作者调查了在给定由一次测量有限量子自动机识别的语言，以及由有限索引上下文无关文法或矩阵上下文无关文法生成的语言时，它们是否具有非空交集的可递归判定条件。

**Result:** 论文研究了在特定条件下，量子有限自动机识别的语言与特定上下文无关语言的非空交集是可递归判定的。

**Conclusion:** 在论文探讨的特定条件下，量子有限自动机识别的语言与特定上下文无关语言的交集问题是递归可判定的。

> **ai_Abstract:** 本文延续了对一次测量有限量子自动机模型的研究。作者探讨了在给定由该模型识别的语言与由有限索引上下文无关文法或矩阵上下文无关文法生成的语言时，判断它们是否具有非空交集的可递归判定条件。

> **摘要翻译:** 本文是对Moore和Crutchfield于2000年引入的所谓“一次测量有限量子自动机”模型先前研究的延续。我们研究了在给定此类设备识别的语言和由有限索引上下文无关文法或矩阵上下文无关文法生成的语言时，它们是否具有非空交集的可递归判定条件。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [430] [The structure of polynomial growth for tree automata/transducers and MSO set queries](https://arxiv.org/abs/2501.10270)
> *树自动机/转换器和MSO集合查询的多项式增长结构*

*Paul Gallot, Nathan Lhote, Lê Thành Dũng Nguyên* | **Category: cs.FL, cs.LO** | **Updated: 2025-07-15**

**Keywords:** 树自动机, MSO逻辑, 多项式增长, 歧义, 转换器

**Comment:** 43 pages, revision for phase 2 of TheoretiCS reviews. New in v3: some
  clarifications, improved approach to size-to-height increase, more related
  work

> **TL;DR:** 本文为N-加权树自动机和MSO集合查询的多项式增长提供了高效的判定程序和算法，并推广了相关理论。

**AI_Comments:** 本文在理论计算机科学，特别是在自动机理论和形式语言领域，做出了重要贡献。其创新性体现在为树自动机增长率提供了高效的决策算法，并达到了与下界匹配的复杂度，这在实际应用和理论分析中都具有重要意义。此外，将研究扩展到MSO逻辑，并提出重参数化定理和维度最小化定理的推广，极大地丰富了该领域的理论框架。新的概念性证明也展现了对复杂理论的深刻理解和简洁表达能力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为N-加权树自动机和非确定性树自动机的歧义增长（指数或多项式）提供有效的判定程序和精确的度计算算法，并将其时间复杂度与现有下界相匹配。同时，也为了研究MSO逻辑下集合查询结果数量的增长特性。

**Method:** 1. 提出了一个在二次时间内判定N-加权树自动机增长是指数还是多项式的决策过程。 2. 提出了一个在三次时间内计算精确多项式增长度数的算法。 3. 推导了秩树上单子二阶逻辑（MSO）集合查询结果数量增长的类似可判定性结果。 4. 证明了多项式增长度为k的MSO查询的重参数化定理。 5. 推广了字符串到字符串多正则函数的维度最小化定理。 6. 提出了一个关于线性增长宏树转换器的新颖、简短且概念性的证明。 7. 提出了一个用于判定宏树转换器和MSO集合解释的多项式大小-高度增长并计算其度数的程序。

**Result:** 1. 提供了N-加权树自动机指数与多项式增长的二次时间判定过程，以及三次时间计算精确多项式度数的算法，其时间复杂度与词自动机歧义问题的最新精细下界相匹配。 2. 得出了秩树上MSO集合查询结果数量增长的类似可判定性结果。 3. 证明了多项式增长的MSO查询可以有限对一地映射到k元组输入节点，并且是MSO可定义的重参数化定理。 4. 推广了字符串到字符串多正则函数的维度最小化定理，适用于树的MSO集合解释。 5. 提供了一个新的、简短且概念性的证明，表明线性增长的宏树转换器仅计算树到树的MSO转换。 6. 提出了一个程序，用于判定宏树转换器和MSO集合解释的多项式大小-高度增长并计算其度数。

**Conclusion:** 论文最后对广泛的相关工作进行了调查，并引用了上百篇参考文献。

> **ai_Abstract:** 本文研究了N-加权树自动机和单子二阶逻辑（MSO）集合查询的增长结构。作者提出了高效的算法来判定和计算树自动机的指数与多项式增长，其时间复杂度达到现有最优下界。研究还扩展到MSO集合查询，提供了其结果数量增长的可判定性，并证明了关键的重参数化定理。此外，论文推广了维度最小化定理，并为宏树转换器提供了新的理论证明和增长判定程序，涵盖了树转换器的多种类型。

> **摘要翻译:** 给定一个N-加权树自动机，我们提出了一个在二次时间内判定（相对于输入大小的）指数增长与多项式增长的决策过程，以及一个在三次时间内计算精确多项式增长度数的算法。作为特例，它们适用于非确定性树自动机歧义的增长，即给定输入上不同接受运行的数量。我们的时间复杂度与这些问题（受限于词自动机歧义）最近的精细下界相匹配。
我们推导了秩树上单子二阶逻辑（MSO）中集合查询结果数量增长的类似可判定性结果（忽略复杂度）。在度数为k的多项式增长情况下，我们还为这类查询证明了一个重参数化定理：它们的结果可以通过有限对一且MSO可定义的方式映射到输入节点的k元组。
MSO集合查询的这一特性直接导致了字符串到字符串多正则函数的维度最小化定理的推广。我们的推广适用于树的MSO集合解释，这（如我们所示）包含了树遍历树转换器和隐形卵石树到字符串转换器。最后，再多做一些工作，我们获得了以下成果：
* 一个新的、简短且概念性的证明，表明线性增长的宏树转换器仅计算树到树的MSO转换；
* 一个用于判定宏树转换器和MSO集合解释的多项式大小-高度增长并计算其度数的程序。
论文最后对广泛的相关工作进行了调查，并引用了上百篇参考文献。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [478] [On Complementation of Nondeterministic Finite Automata without Full Determinization (Technical Report)](https://arxiv.org/abs/2507.03439)
> *非确定性有限自动机补集运算的无需完全确定化方法研究 (技术报告)*

*Lukáš Holík, Ondřej Lengál, Juraj Major, Adéla Štěpková, Jan Strejček* | **Category: cs.FL, cs.LO** | **Updated: 2025-07-14**

**Keywords:** 非确定性有限自动机, 补集运算, 确定化, 逆幂集, 自动机理论

**Comment:** Accepted at FCT'25

> **TL;DR:** 本文研究了非确定性有限自动机（NFA）补集运算的替代方法，旨在避免完全确定化，从而获得更小的补集，实验证明这些方法有效。

**AI_Comments:** 该论文解决了自动机理论中一个重要的实际问题——NFA补集过程中的状态爆炸问题。通过提出避免完全确定化的方法，它为处理此操作提供了一种更有效的方式，这对于自动机规模至关重要的应用来说至关重要。对“NFA常见结构”的利用表明这是一种实用而非纯理论的方法。

<details>
  <summary>Details</summary>

**Motivation:** 标准NFA补集方法（转换为DFA再补集）可能导致DFA的规模呈指数级增长，效率低下。

**Method:** 研究了几种替代补集方法：基于逆幂集构造，以及利用NFA常见结构的两种新颖构造。通过在大型数据集上进行实验来评估这些方法。

**Result:** 实验结果表明，与经典方法相比，使用这些替代方法在许多情况下可以产生显著更小的补集。

**Conclusion:** 采用无需完全确定化的替代方法进行NFA补集运算，可以有效地生成更紧凑（更小）的补集。

> **ai_Abstract:** 本文探讨了非确定性有限自动机（NFA）补集运算的替代方法，旨在克服标准方法（转换为确定性有限自动机DFA）可能导致的指数级规模增长问题。提出的方法包括逆幂集构造以及利用NFA常见结构的两种新颖构造。实验结果表明，与传统方法相比，这些新方法通常能生成显著更小的补集。

> **摘要翻译:** 有限自动机的补集运算是许多应用中使用的基本操作。补集一个非确定性有限自动机（NFA）的标准方法是将其转换为等价的确定性有限自动机（DFA），然后对DFA进行补集。然而，DFA可能比相应的NFA大指数级。在本文中，我们研究了几种替代的补集方法，这些方法基于逆幂集构造或利用NFA常见结构的两种新颖构造。我们在大型数据集上的实验表明，与经典方法不同，使用这些替代方法在许多情况下可以产生显著更小的补集。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [45] [A Risk-Aware Adaptive Robust MPC with Learned Uncertainty Quantification](https://arxiv.org/abs/2507.11420)
> *一种风险感知自适应鲁棒MPC与学习不确定性量化*

*Mingcong Li* | **Category: eess.SY, cs.SY, 93C40, I.2.8** | **Updated: 2025-07-15**

**Keywords:** 风险感知MPC, 自适应鲁棒控制, 不确定性量化, 机会约束控制, 高斯过程回归

**Comment:** 17 pages, 10 figures

> **TL;DR:** 提出RAAR-MPC框架，通过学习量化不确定性并自适应调节风险，在非平稳环境下优于传统MPC。

**AI_Comments:** 创新点在于其双时间尺度自适应架构，将主动的基于学习的风险评估与被动的风险调节相结合，解决了传统MPC在非平稳环境下局限性。正式的理论保证和在基准系统上的出色表现，突显了其在对鲁棒性和效率要求高的实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 解决受非平稳不确定性影响的系统的机会约束最优控制问题面临巨大挑战。传统鲁棒模型预测控制（MPC）因依赖静态最坏情况假设而过于保守，而标准随机MPC方法在不确定性分布先验未知时表现不佳。

**Method:** 本文提出一种风险感知自适应鲁棒MPC（RAAR-MPC）框架，该分层架构系统地整合了主动的、基于学习的风险评估和被动的风险调节。该框架采用中频风险评估引擎，利用高斯过程回归和主动学习，从运行数据中构建预测误差集的紧密、数据驱动的特征。同时，一个低时间尺度的外循环实现了自校正的自适应安全裕度更新律，以精确调节经验风险并补偿未建模的动态。这种双时间尺度自适应使系统能够严格满足用户定义概率的机会约束，同时最小化传统方法固有的保守性。

**Result:** 在非平稳参数不确定性下的基准DC-DC转换器上的数值实验表明，我们的框架精确地达到了目标风险水平，与最先进的鲁棒和随机MPC策略相比，平均成本显著降低。

**Conclusion:** 本文正式证明了自适应组件之间的相互作用保证了递归可行性，并确保闭环系统以高概率满足用户定义风险水平的机会约束。数值实验表明，该框架能精确达到目标风险水平，并显著降低平均成本，优于现有方法。

> **ai_Abstract:** 本文提出一种新颖的风险感知自适应鲁棒MPC（RAAR-MPC）分层框架，用于解决非平稳不确定性下的机会约束最优控制问题。该框架结合了基于高斯过程回归和主动学习的风险评估引擎，以及双时间尺度自适应安全裕度。这种方法能减少保守性并严格满足机会约束。论文提供了递归可行性和高概率满足机会约束的正式保证。在DC-DC转换器上的数值实验表明，该框架能达到目标风险水平并显著降低成本，优于其他MPC策略。

> **摘要翻译:** 解决受非平稳不确定性影响的系统的机会约束最优控制问题是一个重大挑战。传统的鲁棒模型预测控制（MPC）往往通过依赖静态最坏情况假设而产生过度保守性，而标准随机MPC方法在底层不确定性分布先验未知时表现不佳。本文提出了一种风险感知自适应鲁棒MPC（RAAR-MPC）框架，这是一种分层架构，系统地协调了主动的、基于学习的风险评估和被动的风险调节的新颖综合。该框架采用中频风险评估引擎，该引擎利用高斯过程回归和主动学习，从运行数据中构建预测误差集的紧密、数据驱动的特征。同时，一个低时间尺度的外循环实现了自校正的自适应安全裕度更新律，以精确调节经验风险并补偿未建模的动态。这种双时间尺度自适应使系统能够严格满足用户定义概率的机会约束，同时最小化传统方法固有的保守性。我们正式证明了这些自适应组件之间的相互作用保证了递归可行性，并确保闭环系统以高概率满足用户定义风险水平的机会约束。在非平稳参数不确定性下的基准DC-DC转换器上的数值实验表明，我们的框架精确地达到了目标风险水平，与最先进的鲁棒和随机MPC策略相比，平均成本显著降低。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [218] [Offline and Online Use of Interval and Set-Based Approaches for Control and State Estimation: A Selection of Methodological Approaches and Their Application](https://arxiv.org/abs/2309.11622)
> *区间和基于集合的方法在控制和状态估计中的离线和在线应用：方法论方法及其应用的选择*

*Andreas Rauh, Marit Lahme, Simon Rohou, Luc Jaulin, Thach Ngoc Dinh, Tarek Raissi, Mohamed Fnadi* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-14**

**Keywords:** 区间方法, 基于集合的方法, 控制, 状态估计, 不确定性

**Comment:** 

> **TL;DR:** 本文概述了区间和基于集合的方法在控制和状态估计中的应用，包括离线分析和在线实施，以应对参数不确定性、初始条件不确定性和外部干扰。

**AI_Comments:** 这篇论文的创新点在于它不仅关注了区间和基于集合的方法在离线分析中的传统应用，还强调了它们在近年来的发展，使其能够直接应用于在线设计任务和实时系统操作中。这对于需要高鲁棒性和可靠性的控制系统而言具有重要意义，尤其是在存在多种不确定性的复杂动态系统中。该综述性工作为研究人员和工程师提供了一个全面的视角，展示了这些方法在理论和实践中的广阔前景。

<details>
  <summary>Details</summary>

**Motivation:** 控制和状态估计过程需要对不精确的已知参数、初始条件的不确定性以及外部干扰具有鲁棒性。

**Method:** 本文介绍了区间方法和其他基于集合的技术，它们构成了强大方法的基础，可用于在存在不确定性的情况下识别动态系统模型的参数。这些方法既可用于离线分析（例如验证可行性和稳定性），也可用于在线实施（例如基于集合的模型预测控制、在线参数自适应技术、区间观测器和故障诊断技术）。

**Result:** 区间和基于集合的方法能够识别动态系统模型的参数，进行控制器和状态估计器的可行性与稳定性分析。此外，它们还可用于直接解决设计任务，并实现在线应用的可靠技术，包括基于集合的模型预测控制、非线性变结构和反步控制器的在线参数自适应技术、区间观测器和故障诊断技术。

**Conclusion:** 本文概述了区间和基于集合的方法学背景，并回顾了这些方法成功应用于控制和状态估计的众多实际案例，证明了它们在应对不确定性方面的有效性。

> **ai_Abstract:** 本文综述了区间和基于集合的方法在控制和状态估计中的应用。这些方法旨在增强系统对不确定性（如未知参数、初始条件不确定性和外部干扰）的鲁棒性。文章详细介绍了这些方法如何用于离线分析系统模型，以及如何发展为可在线应用的可靠技术，例如基于集合的模型预测控制、在线参数自适应、区间观测器和故障诊断。文章通过回顾方法学背景和实际应用案例，展示了这些技术在处理不确定性方面的有效性。

> **摘要翻译:** 控制和状态估计过程需要对不精确的已知参数、初始条件的不确定性以及外部干扰具有鲁棒性。区间方法和其他基于集合的技术构成了实现强大方法的基础，这些方法可用于在存在上述类型不确定性的情况下识别动态系统模型的参数。此外，它们还适用于控制器和状态估计器的验证可行性和稳定性分析。除了这些通常用于对经典浮点程序设计的系统模型进行离线分析的方法外，近年来还开发了区间和基于集合的方法，这些方法可以直接解决相关的设计任务并实现可在线应用的可靠技术，即在系统运行期间应用。后者的方法包括基于集合的模型预测控制、非线性变结构和反步控制器的在线参数自适应技术、区间观测器和故障诊断技术。本文概述了方法学背景，并回顾了区间和其他基于集合的方法已成功应用的众多实际应用。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [250] [A Forward Reachability Perspective on Control Barrier Functions and Discount Factors in Reachability Analysis](https://arxiv.org/abs/2310.17180)
> *控制障碍函数和可达性分析中折扣因子的前向可达性视角*

*Jason J. Choi, Donggun Lee, Boyang Li, Jonathan P. How, Koushil Sreenath, Sylvia L. Herbert, Claire J. Tomlin* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-15**

**Keywords:** 前向可达性, 控制障碍函数, 控制不变集, 微分博弈, 逆向最优性

**Comment:** The first two authors contributed equally to this work

> **TL;DR:** 本文通过探索必然前向可达管（FRT）与控制障碍函数（CBF）之间的联系，弥合了可达性分析和安全控制设计中的现有空白，并揭示了CBF的逆向最优性。

**AI_Comments:** 本文通过引入前向可达性视角，创新性地建立了可达性、控制不变集和控制障碍函数（CBF）之间的强联系，解决了传统后向可达性方法难以实现的理论空白。其重要性在于为构建更稳健、更有效的CBF提供了新的理论框架和方法，对于设计满足长期安全约束的控制系统具有重要意义。文章提出的CBF逆向最优性概念也具有重要的理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在设计满足状态约束的安全控制策略时，控制不变集至关重要。本文旨在探索可达性、控制不变性和控制障碍函数（CBF）之间的联系，并解决现有文献中基于后向可达性无法实现强连接以及构建有效CBF以确保安全性的空白。

**Method:** 本文通过检查必然前向可达管（FRT）来建立可达性、控制不变性和控制障碍函数（CBF）之间的强联系。首先，研究了FRT与鲁棒控制不变集的关系，特别是其边界的可微性。其次，将控制和扰动之间的微分博弈公式化，其中FRT由价值函数的零超水平集表征。通过在博弈的成本函数中引入折扣因子，使得CBF的障碍约束自然地出现在Hamilton-Jacobi方程中。

**Result:** 研究结果表明，如果初始集是具有可微边界的鲁棒控制不变集，则必然FRT就是该初始集本身。如果边界不可微，鲁棒控制不变集的FRT可能成为不变集的严格超集并失去不变性。通过微分博弈公式化，FRT的价值函数可以作为CBF-like函数，反之，任何有效的CBF也是控制不变集内的前向可达性价值函数，从而揭示了CBF的逆向最优性。这种可达性与障碍约束之间的强联系是以前基于后向可达性的公式无法实现的。

**Conclusion:** 本文通过前向可达性视角，成功地建立了可达性、控制不变集和控制障碍函数之间的强联系，并揭示了CBF的逆向最优性。这弥补了现有文献中在构建有效CBF以确保安全性方面的重要空白。

> **ai_Abstract:** 本文从前向可达性的角度，深入探讨了可达性、控制不变集和控制障碍函数（CBF）之间的内在联系。通过引入必然前向可达管（FRT）的概念，作者证明了FRT在特定条件下与鲁棒控制不变集的关系，并揭示了CBF的逆向最优性。研究结果表明，FRT的价值函数可作为CBF，反之亦然，弥补了现有基于后向可达性方法无法建立的强联系，为安全控制策略的设计提供了新的理论基础。

> **摘要翻译:** 控制不变集对于旨在设计系统安全控制策略的各种方法至关重要，这些系统的状态约束必须在无限时间范围内得到满足。在本文中，我们探讨了可达性、控制不变性和控制障碍函数（CBF）之间的联系。与以前基于后向可达性概念的公式不同，我们通过检查必然前向可达管（FRT）来建立这三个概念之间的强联系，FRT是这样一种状态集合，即到达FRT的每个轨迹都必须经过给定的初始状态集。首先，我们的研究结果表明，如果初始集是具有可微边界的鲁棒控制不变集——连接CBF所必需的属性，因为CBF的零水平集是控制不变的——那么必然FRT就是这个初始集本身。我们强调，如果边界不可微，鲁棒控制不变集的FRT可能成为不变集的严格超集并失去不变性。其次，我们建立了控制和扰动之间的微分博弈，其中必然FRT由价值函数的零超水平集表征。通过在博弈的成本函数中引入折扣因子，CBF的障碍约束自然地出现在Hamilton-Jacobi方程中，并决定了最优策略。结合这些结果，我们的FRT公式的价值函数可以作为CBF-like函数，反之，任何有效的CBF也是控制不变集内的前向可达性价值函数，从而揭示了CBF的逆向最优性。这种可达性与障碍约束之间的强联系是以前基于后向可达性的公式无法实现的，并解决了现有文献中构建有效CBF以确保安全性的重要空白。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [299] [Parallel Batch Scheduling With Incompatible Job Families Via Constraint Programming](https://arxiv.org/abs/2410.11981)
> *基于约束编程的不兼容作业族并行批处理调度*

*Jorge A. Huertas, Pascal Van Hentenryck* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-07-15**

**Keywords:** 并行批处理调度, 不兼容作业族, 约束编程, 自动机约束, 调度

**Comment:** 17 pages, 9 figures

> **TL;DR:** 本文提出了四种新的约束编程模型，用于解决不兼容作业族的并行批处理调度问题，并在多种求解器上表现出良好的灵活性和竞争力。

**AI_Comments:** 本文的创新之处在于开发了不依赖于专有商业求解器的CP模型，从而提高了先进调度技术的普及性和适用性。通过在开源兼容性下展示其竞争性能，该研究对批处理调度的实际应用做出了重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有解决不兼容作业族并行批处理调度的最先进约束编程（CP）模型依赖于特定功能和全局约束，这些功能和约束仅在特定的商业CP求解器中可用，限制了其应用范围。

**Method:** 本文提出了四种新的约束编程（CP）模型：一个依赖于自动机约束的新模型，以及三个结合了不同策略和全局约束的集成分配和调度决策的替代模型。这些模型旨在可在商业和开源求解器中实现。

**Result:** 在多种目标和多种求解器下对标准测试用例进行的广泛计算实验表明，所提出的模型具有实现灵活性和竞争性能。

**Conclusion:** 所提出的CP模型为不兼容作业族并行批处理调度问题提供了一种灵活且具有竞争力的解决方案，克服了以往方法在求解器兼容性方面的限制。

> **ai_Abstract:** 本文研究了不兼容作业族的并行批处理调度问题，即不同族作业不能在同一批次处理。针对现有先进约束编程（CP）模型对特定商业求解器的依赖性，本文提出了四种新的CP模型，包括一个基于自动机约束的模型和三个整合分配与调度决策的模型。这些新模型旨在兼容商业和开源求解器。通过对标准测试用例在多目标和多求解器下的广泛实验，验证了所提出模型的实现灵活性和竞争性能。

> **摘要翻译:** 标题：基于约束编程的不兼容作业族并行批处理调度
摘要：本文研究了不兼容作业族并行批处理调度问题，其中兼容的作业属于同一族，而不同族的作业不能在同一个批次中一起处理。该问题的现有最先进的约束编程（CP）模型依赖于特定功能和全局约束，这些功能和约束仅在成熟的商业CP求解器中可用。本文通过提出四种新的CP模型来扩展了该问题的研究文献，这些模型可以在商业和开源求解器中实现：一个依赖于自动机约束的新模型，以及三个结合了不同策略和全局约束的分配和调度决策的替代模型。在多种目标和多种求解器下对标准测试用例进行的广泛计算实验证明了所提出模型的实现灵活性和竞争性能。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [339] [Skew-Induced Insertion Loss Deviation (SILD) and FOM_SILD: Metrics for Quantifying P/N Skew Effects in High-Speed Channels](https://arxiv.org/abs/2506.15105)
> *偏斜引起的插入损耗偏差 (SILD) 和 FOM_SILD：用于量化高速通道中 P/N 偏斜效应的指标*

*David Nozadze, Zurab Kiguradze, Amendra Koul, Mike Sapozhnikov* | **Category: eess.SY, cs.SY, eess.SP** | **Updated: 2025-07-14**

**Keywords:** P/N 偏斜, SILD, FOM_SILD, 高速互连, SerDes

**Comment:** 

> **TL;DR:** 针对超高速互连中 P/N 偏斜对 SerDes 性能的影响，本文提出了 SILD 和 FOM_SILD 两个新指标，并验证其有效性。

**AI_Comments:** 这项工作通过引入 SILD 和 FOM_SILD 两个新指标，为量化高速通道中 P/N 偏斜效应提供了创新的解决方案，弥补了传统方法的不足。这些指标的提出对于设计和优化未来超高速互连系统，确保其性能和可靠性具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** AI 工作负载和数据中心对超高速互连的需求日益增长，但即使是微小的 P/N 偏斜也会显著降低 SerDes 性能。传统量化偏斜的方法无法有效捕捉其影响。

**Method:** 分析性地开发了 SILD（偏斜引起的插入损耗偏差）和 FOM_SILD（其互补品质因数）两个新指标，用于评估 P/N 偏斜效应。通过测量 S 参数验证了 FOM_SILD 的互易性，并通过 224G PAM4 SerDes 仿真验证了其与误码率 (BER) 趋势的强相关性。

**Result:** 测量 S 参数证实了 FOM_SILD 的互易性。224G PAM4 SerDes 仿真结果显示，FOM_SILD 与误码率 (BER) 趋势之间存在很强的相关性。

**Conclusion:** 所提出的 SILD 和 FOM_SILD 方法为分析下一代超高速互连中的 P/N 偏斜提供了一个稳健且有效的框架。

> **ai_Abstract:** 为应对超高速互连中 P/N 偏斜对 SerDes 性能的负面影响，本文提出了 SILD（偏斜引起的插入损耗偏差）和 FOM_SILD（品质因数）两个新指标。这些指标经过分析开发，旨在更准确地量化偏斜效应。通过 S 参数测量确认了 FOM_SILD 的互易性，并且 224G PAM4 SerDes 仿真结果显示这些指标与误码率 (BER) 趋势高度相关，为下一代高速互连的偏斜分析提供了新的有效工具。

> **摘要翻译:** AI 工作负载的兴起和数据中心需求的增长推动了对超过 200 Gb/s 的超高速互连的需求。随着单位间隔 (UI) 的缩小，即使是几皮秒的 P/N 偏斜也会降低串行器-解串器 (SerDes) 的性能。传统的偏斜量化方法不足以捕捉其影响。我们引入了两个新指标：1) 偏斜引起的插入损耗偏差 (SILD) 和 2) 其互补的品质因数 (FOM_SILD)，这些指标经过分析开发，旨在评估 P/N 偏斜效应。测量的 S 参数证实了 FOM_SILD 的互易性，而 224G PAM4 SerDes 的仿真结果显示与误码率 (BER) 趋势有很强的相关性。这种方法为分析下一代超高速互连中的偏斜提供了一个稳健的框架。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [490] [Learning to Quantize and Precode in Massive MIMO Systems for Energy Reduction: a Graph Neural Network Approach](https://arxiv.org/abs/2507.10634)
> *大规模MIMO系统中用于节能的量化与预编码学习：一种图神经网络方法*

*Thomas Feys, Liesbet Van der Perre, François Rottenberg* | **Category: eess.SY, cs.LG, cs.SY, eess.SP, stat.ML** | **Updated: 2025-07-14**

**Keywords:** 大规模MIMO, 量化, 预编码, 图神经网络, 能量效率

**Comment:** 

> **TL;DR:** 本文提出了一种基于图神经网络（GNN）的方法，用于大规模MIMO系统中粗量化下行链路的非线性预编码，通过直接最大化可达速率进行自监督训练，并利用Gumbel-softmax估计解决不可微问题，显著提高了粗量化下的可达和速率并大幅降低了DAC功耗。

**AI_Comments:** 本文的创新点在于将图神经网络应用于大规模MIMO系统中粗量化下非线性预编码这一NP难问题，并提出了一种新颖的梯度估计技术（直通式Gumbel-softmax）来处理DAC函数固有的不可微性。这种方法为未来大规模MIMO部署中的能效提供了一个有前景的方向，通过显著降低DAC功耗来实现节能。然而，其局限性在于增加了数字信号处理功耗，这需要在系统层面进行仔细的权衡和优化。

<details>
  <summary>Details</summary>

**Motivation:** 大规模MIMO系统正朝着射频链数量增加、载波频率更高、带宽更大的方向发展。因此，数模转换器（DAC）在硬件复杂度和功耗方面正成为一个瓶颈。此外，用于粗量化下行链路大规模MIMO的非线性预编码问题是NP难的。

**Method:** 本文提出了一种图神经网络（GNN）来直接根据信道矩阵和预期的传输符号输出预编码的量化向量。该模型通过直接最大化可达速率进行自监督训练。为了克服由于不可微分的DAC函数引入的目标函数不可微问题，提出了一种直通式Gumbel-softmax梯度估计方法。

**Result:** 所提出的方法在粗量化下实现了可达和速率的显著提高。例如，在单用户情况下，与最大比传输（MRT）需要3比特DAC相比，所提出的方法可以使用1比特DAC实现与MRT相同的和速率。这分别将基带和射频DAC的功耗降低了4-7倍和3倍。虽然这会增加数字信号处理功耗，但考虑到这一点，基带DAC的整体功耗降低在系统带宽高达3.5 MHz时仍然成立，而射频DAC在更高带宽下仍能保持2.9的功耗降低。

**Conclusion:** 所提出的基于GNN的粗量化预编码方法可以显著降低大规模MIMO系统中的DAC功耗，从而实现可观的节能。尽管这会增加数字信号处理功耗，但在考虑了这一点后，整体功耗仍能有效降低，特别是在某些带宽范围内。

> **ai_Abstract:** 本文针对大规模MIMO系统中DAC功耗瓶颈问题，提出了一种基于图神经网络（GNN）的非线性预编码方法，用于粗量化下行链路。该GNN模型通过自监督学习直接最大化可达速率，并采用直通式Gumbel-softmax估计来处理目标函数的不可微性。实验结果表明，该方法在粗量化下显著提高了可达和速率，例如在单用户场景下，使用1比特DAC即可达到3比特MRT的性能，从而大幅降低了DAC功耗。尽管数字信号处理功耗有所增加，但在考虑整体系统效益后，该方法在特定带宽下仍能实现显著的整体功耗降低。

> **摘要翻译:** 大规模MIMO系统正朝着射频链数量增加、载波频率更高、带宽更大的方向发展。因此，数模转换器（DAC）在硬件复杂度和功耗方面正成为一个瓶颈。
在这项工作中，研究了用于粗量化下行链路大规模MIMO的非线性预编码。鉴于此问题的NP难性质，本文提出了一种图神经网络（GNN），该网络根据信道矩阵和预期的传输符号直接输出预编码的量化向量。该模型通过直接最大化可达速率进行自监督训练。为了克服由于不可微分的DAC函数引入的目标函数不可微问题，提出了一种直通式Gumbel-softmax梯度估计方法。
所提出的方法在粗量化下实现了可达和速率的显著提高。例如，在单用户情况下，所提出的方法可以使用1比特DAC实现与最大比传输（MRT）相同的和速率，而MRT需要3比特。这分别将基带和射频DAC的功耗降低了4-7倍和3倍。然而，这会增加数字信号处理功耗。考虑到这一点，对于基带DAC，在系统带宽高达3.5 MHz时，整体功耗降低仍然成立，而射频DAC在更高带宽下可以保持2.9的功耗降低。值得注意的是，本分析未考虑进一步降低功耗的间接效应，例如前传功耗的降低和其他组件的减少。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [530] [Data-Driven Safety Certificates of Infinite Networks with Unknown Models and Interconnection Topologies](https://arxiv.org/abs/2507.10979)
> *数据驱动的未知模型和互连拓扑无限网络安全证书*

*Mahdieh Zaker, Amy Nejati, Abolfazl Lavaei* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-15**

**Keywords:** 无限网络, 安全认证, 数据驱动, 组合框架, 耗散性

**Comment:** 

> **TL;DR:** 本文提出了一种数据驱动的组合式方法，用于未知模型和互连拓扑的无限网络安全认证，显著降低了样本复杂度。

**AI_Comments:** 这项工作在处理无限网络的安全认证方面具有重要的创新性，特别是在模型和拓扑未知的情况下。其通过数据驱动的组合方法，成功规避了传统方法对精确系统知识的依赖，并显著改善了样本复杂度，这对于大规模复杂系统的分析具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有分析框架不适用于无限网络，因为它们是为有限网络设计的，且无限网络的巨大维度导致计算复杂性极高，传统方法通常需要精确的互连拓扑知识。

**Method:** 本文提出了一种数据驱动的组合式方法，在组合框架内利用子系统的联合耗散性类型特性（通过存储证书表征），来构建无限网络的障碍证书。该方法利用从数据中获得的未知子系统的存储证书，并提供网络安全性的正确性保证，同时消除了检查传统耗散性条件的需求。

**Result:** 研究表明，所提出的组合数据驱动推理消除了检查传统耗散性条件的需求，并且将样本复杂度从现有数据驱动文献中所示的指数级显著降低到子系统数量的线性级。该方法在两个具有未知模型和互连拓扑的物理无限网络上得到了验证。

**Conclusion:** 本文成功开发了一种数据驱动的组合策略，用于对具有未知模型和互连拓扑的无限网络进行安全认证，有效克服了现有方法的局限性，并大幅降低了样本复杂度。

> **ai_Abstract:** 本文提出了一种新颖的数据驱动组合方法，用于对具有未知模型和互连拓扑的无限网络进行安全认证。该方法通过利用子系统的联合耗散性特性和数据驱动的存储证书来构建障碍证书，从而避免了对精确互连拓扑知识的需求。与现有方法相比，该策略显著降低了样本复杂度，从指数级降至子系统数量的线性级，并在物理无限网络上得到了验证。

> **摘要翻译:** 无限网络是复杂的互连系统，包含可数无限数量的子系统，由于网络看似无休止的互连性质（例如，计算道路上的车辆），精确计数它们带来了重大挑战。在这种情况下，网络中存在无限多个子系统使得现有为有限网络量身定制的分析框架不适用于无限网络。本文关注于在组合框架内提供一种数据驱动的方法，用于具有未知数学模型和互连拓扑的无限网络的安全认证。鉴于无限网络维度巨大所带来的巨大计算复杂性，我们的方法利用子系统的联合耗散性类型特性，其特征在于存储证书。我们引入创新的组合数据驱动条件，利用从数据中获得的未知子系统的存储证书来构建无限网络的障碍证书，同时提供整个网络安全的正确性保证。我们证明了我们的组合数据驱动推理消除了检查传统耗散性条件的需求，而传统条件通常需要精确的互连拓扑知识。此外，虽然现有数据驱动文献表明样本复杂度随网络规模呈指数趋势，但我们展示了我们的组合策略显著将其降低到子系统数量的线性规模。我们在两个具有未知模型和互连拓扑的物理无限网络上说明了我们的数据驱动结果。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [579] [Approximate solutions to games of ordered preference](https://arxiv.org/abs/2507.11021)
> *有序偏好博弈的近似解*

*Pau de las Heras Molins, Eric Roy-Almonacid, Dong Ho Lee, Lasse Peters, David Fridovich-Keil, Georgios Bakirtzis* | **Category: eess.SY, cs.GT, cs.SY** | **Updated: 2025-07-15**

**Keywords:** 有序偏好博弈, 近似解, 词典序迭代最佳响应, 后推式框架, 纳什均衡

**Comment:** 

> **TL;DR:** 本文提出了一种名为“随时间变化的词典序迭代最佳响应”（lexicographic IBR over time）的方法，用于高效计算有序偏好博弈的近似解，以应对计算复杂性问题。

**AI_Comments:** 本文的创新点在于提出了“随时间变化的词典序迭代最佳响应”这一新颖的方法，有效解决了有序偏好博弈在实际应用中面临的计算复杂性难题。通过结合词典序迭代最佳响应与后推式框架，并利用历史信息加速收敛，该方法为自动驾驶等需要实时决策和多目标平衡的复杂系统提供了实用的近似求解策略。其重要性在于为处理大规模、高维度的有序偏好博弈提供了可行途径。

<details>
  <summary>Details</summary>

**Motivation:** 有序偏好博弈能有效建模自动驾驶等场景中多目标平衡的问题（如最小化旅行时间、确保安全、协调交通），但随着时间范围、参与者数量或偏好层级的增加，现有方法的计算变得难以处理。虽然后推式框架能缓解长时域的难题，但未能解决现有求解方法固有的复杂性增长。

**Method:** 本文提出了一种名为“随时间变化的词典序迭代最佳响应”（lexicographic IBR over time）的解决方案策略。该方法在后推式框架中通过使用词典序迭代最佳响应（lexicographic IBR）来近似求解，从而避免了过度的复杂性增长。它利用过去的信息加速收敛。

**Result:** 通过模拟交通场景，本文证明“随时间变化的词典序迭代最佳响应”方法能高效计算后推式有序偏好博弈的近似最优解，并收敛于广义纳什均衡。

**Conclusion:** “随时间变化的词典序迭代最佳响应”方法为解决计算复杂的有序偏好博弈提供了一种高效且近似最优的解决方案，尤其适用于需要平衡多重目标的场景。

> **ai_Abstract:** 本文针对自动驾驶等领域中，有序偏好博弈因其计算复杂性而难以处理的问题，提出了一种名为“随时间变化的词典序迭代最佳响应”（lexicographic IBR over time）的新型解决方案。该方法在后推式框架中利用词典序迭代最佳响应来近似求解，并利用历史信息加速收敛，有效避免了计算复杂性的过度增长。模拟交通场景的结果表明，该方法能够高效地计算近似最优解，并收敛到广义纳什均衡。

> **摘要翻译:** 自动驾驶车辆必须平衡排序目标，例如最小化旅行时间、确保安全以及与交通协调。有序偏好博弈能有效建模这些交互，但随着时间范围、参与者数量或偏好层级的增加，计算变得难以处理。虽然后推式框架通过解决序列化的较短博弈（通常是热启动的）来缓解长时域的难题，但它们并未解决现有求解有序偏好博弈方法固有的复杂性增长。本文引入了一种解决方案策略，通过在后推式框架中利用词典序迭代最佳响应（IBR）来近似求解，从而避免了过度的复杂性增长，称之为“随时间变化的词典序迭代最佳响应”。“随时间变化的词典序迭代最佳响应”利用过去的信息加速收敛。我们通过模拟交通场景证明，该方法能高效计算后推式有序偏好博弈的近似最优解，并收敛于广义纳什均衡。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [621] [Standards-Compliant DM-RS Allocation via Temporal Channel Prediction for Massive MIMO Systems](https://arxiv.org/abs/2507.11064)
> *大规模MIMO系统中基于时间信道预测的符合标准DM-RS分配*

*Sehyun Ryu, Hyun Jong Yang* | **Category: eess.SY, cs.AI, cs.SY, eess.SP** | **Updated: 2025-07-15**

**Keywords:** 大规模MIMO, 信道预测, DM-RS分配, CSI反馈, 深度学习

**Comment:** 

> **TL;DR:** 该研究提出了一种名为CPRS的新方法，通过联合优化信道预测和DM-RS分配来提高大规模MIMO系统中的数据吞吐量，同时无需CSI反馈，并采用ViViT/CNN架构实现。

**AI_Comments:** 该论文的创新点在于将信道预测与DM-RS分配联合优化，以解决大规模MIMO系统中CSI反馈开销大的问题，并首次将深度学习应用于CSI受限的参考信号分配。其采用ViViT/CNN架构处理序列图像般的CSI数据，体现了对现有深度学习模型在通信领域应用的探索。符合标准的设计使其具有潜在的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在超越5G网络中，降低反馈开销是一个关键挑战。大规模MIMO系统中天线数量的增加，导致FDD系统中信道状态信息（CSI）反馈需求大幅增长。尽管深度学习已应用于CSI受限的波束成形和切换优化，但在此类限制下的参考信号分配仍未得到充分探索。

**Method:** 该论文引入了基于信道预测的参考信号分配（CPRS）概念，通过联合优化信道预测和DM-RS分配来提高数据吞吐量，且无需CSI反馈。提出了一种符合标准的ViViT/CNN架构来实现CPRS，将演变的CSI矩阵视为序列图像数据。

**Result:** 使用NVIDIA Sionna生成的射线追踪信道数据进行的仿真结果验证了所提出的方法，显示与基准策略相比，吞吐量提高了36.60%。

**Conclusion:** 通过联合优化信道预测和DM-RS分配，所提出的CPRS方法（基于ViViT/CNN架构）能够在大规模MIMO系统中显著提高数据吞吐量，同时无需CSI反馈，并表现出优于现有方法的性能。

> **ai_Abstract:** 该论文提出了一种名为信道预测基参考信号分配（CPRS）的新方法，旨在解决大规模MIMO系统中CSI反馈开销过大的问题。CPRS通过联合优化信道预测和DM-RS分配，实现在无需CSI反馈的情况下提高数据吞吐量。研究引入了符合标准的ViViT/CNN架构，将动态CSI矩阵视为序列图像数据进行处理。仿真结果表明，该方法比现有基准策略能带来高达36.60%的吞吐量提升。

> **摘要翻译:** 在超越5G网络中，降低反馈开销是一个关键挑战，因为现代大规模MIMO系统中天线数量的增长大幅增加了频分双工（FDD）系统中的信道状态信息（CSI）反馈需求。为了解决这个问题，广泛的研究集中在CSI压缩和预测上，其中基于神经网络的方法获得了发展势头，并被考虑整合到3GPP 5G-Advanced标准中。尽管深度学习已有效地应用于CSI受限的波束成形和切换优化，但在此类限制下的参考信号分配仍未得到充分探索，这令人惊讶。为了填补这一空白，我们引入了基于信道预测的参考信号分配（CPRS）的概念，它联合优化信道预测和DM-RS分配，以在不要求CSI反馈的情况下提高数据吞吐量。我们进一步提出了一种符合标准的ViViT/CNN架构，通过将演变的CSI矩阵视为序列图像数据来实现CPRS，从而在动态环境中实现高效自适应传输。使用NVIDIA Sionna生成的射线追踪信道数据进行的仿真结果验证了所提出的方法，显示与基准策略相比，吞吐量提高了36.60%。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [663] [Optimal Honeypot Ratio and Convergent Fictitious-Play Learning in Signaling Games for CPS Defense](https://arxiv.org/abs/2507.11113)
> *CPS防御中蜜罐最优比例与收敛虚构博弈学习*

*Yueyue Xu, Yuewei Chen, Lin Wang, Zhaoyang Cheng, Xiaoming Hu* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-15**

**Keywords:** 蜜罐部署, 信号博弈, 虚构博弈学习, 网络物理系统防御, 纳什均衡

**Comment:** 14 pages, 8 figures

> **TL;DR:** 本研究将蜜罐部署建模为信号博弈，定义了gamma-PBNE并推导了其分析表达式，找到了最优蜜罐比例和策略，并提出了一个收敛的虚构博弈学习算法，以有效防御网络攻击。

**AI_Comments:** 本文创新性地将蜜罐部署问题建模为信号博弈，并引入了虚构博弈学习算法来捕捉动态战略互动，这为CPS防御提供了新的理论框架和实用方法。其对学习收敛性的严格证明增加了研究的理论严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 网络物理系统（CPS）正面临快速增长的攻击浪潮，需要实现有效的积极防御。

**Method:** 将蜜罐部署建模为伽马固定信号博弈，其中节点活跃度作为唯一信号。定义了伽马完美贝叶斯-纳什均衡（gamma-PBNE）。推导了所有gamma-PBNE的分析表达式。开发了一个离散时间虚构博弈算法，将贝叶斯信念更新与经验最佳响应相结合。

**Result:** 获得了所有gamma-PBNE的分析表达式，揭示了取决于先验蜜罐比例的三种不同的均衡机制。获得了共同最大化网络平均效用的最优蜜罐比例和信号策略。证明了只要蜜罐比例在最优值的一个非退化邻域内受到扰动，每个虚构博弈路径都会收敛到防御者最优的gamma-PBNE。数值结果证实了所提出方法的有效性及其在CPS防御中的适用性。

**Conclusion:** 本研究通过信号博弈模型和虚构博弈学习算法，为CPS防御中的蜜罐部署提供了理论基础和有效策略，证明了其在实际应用中的潜力。

> **ai_Abstract:** 本文针对网络物理系统（CPS）面临的网络攻击，提出了一种基于信号博弈的蜜罐部署策略。研究将蜜罐部署建模为伽马固定信号博弈，并定义了伽马完美贝叶斯-纳什均衡（gamma-PBNE），推导了其分析表达式，揭示了三种均衡机制。进一步，论文确定了最大化网络平均效用的最优蜜罐比例和信号策略。为捕捉动态战略互动，研究开发了一个离散时间虚构博弈算法，并证明了其收敛性，即只要蜜罐比例在最优值附近扰动，学习路径将收敛到防御者最优的gamma-PBNE。数值结果验证了该方法的有效性和在CPS防御中的实用性。

> **摘要翻译:** 网络物理系统（CPS）正面临快速增长的攻击浪潮。为了实现有效的积极防御，本文将蜜罐部署建模为伽马固定信号博弈，其中节点活跃度作为唯一信号，正常节点信号伽马是外生固定的。我们定义了伽马完美贝叶斯-纳什均衡（gamma-PBNE）。获得了所有gamma-PBNE的分析表达式，揭示了取决于先验蜜罐比例的三种不同的均衡机制。此外，获得了共同最大化网络平均效用的最优蜜罐比例和信号策略。为了捕捉随时间的战略互动，我们开发了一个离散时间虚构博弈算法，将贝叶斯信念更新与经验最佳响应相结合。我们证明，只要蜜罐比例在最优值的一个非退化邻域内受到扰动，每个虚构博弈路径都会收敛到防御者最优的gamma-PBNE。数值结果证实了所提出方法的有效性并证明了其在CPS防御中的适用性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [712] [Optimal Sensor Scheduling and Selection for Continuous-Discrete Kalman Filtering with Auxiliary Dynamics](https://arxiv.org/abs/2507.11240)
> *辅助动态下连续-离散卡尔曼滤波的最优传感器调度与选择*

*Mohamad Al Ahdab, John Leth, Zheng-Hua Tan* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-15**

**Keywords:** 连续-离散卡尔曼滤波, 传感器调度, 辅助动态, 最优控制, 泊松过程

**Comment:** Accepted to ICML 2025

> **TL;DR:** 论文提出了一个优化框架，通过联合优化测量速率和辅助状态动态，实现了连续-离散卡尔曼滤波中资源使用和估计精度之间的更好权衡。

**AI_Comments:** 该论文的创新点在于将辅助动态（如能耗、传感器轨迹）引入到连续-离散卡尔曼滤波的优化问题中，并提出了一个基于可微上界和最优控制的联合优化框架。这种方法能够有效地平衡资源消耗和估计精度，对于实际应用中传感器资源受限的场景具有重要意义。其贡献在于提供了一种系统性的方法来解决传感器调度和选择中的复杂权衡问题。

<details>
  <summary>Details</summary>

**Motivation:** 在多传感器观测的连续-离散卡尔曼滤波中，测量过程可能与辅助状态耦合，导致测量速率增加能耗或热量，传感器精度受自身轨迹影响，且每个传感器有不同的成本和约束。因此，需要优化资源使用和估计精度之间的权衡。

**Method:** 将测量事件建模为独立的泊松过程，具有传感器特定的速率。推导了CD-KF在平均辅助状态下的平均后验协方差矩阵的连续可微上界。利用该上界，提出了一个有限时域最优控制框架，以联合优化测量速率和辅助状态动态。引入了一种从优化速率中确定性调度测量时间的方法。

**Result:** 经验结果表明，该方法在状态空间滤波和动态时间高斯过程回归中，实现了资源使用和估计精度之间更好的权衡。

**Conclusion:** 论文提出了一个创新的框架，通过优化传感器调度和选择，在考虑辅助动态和资源成本的情况下，显著提升了连续-离散卡尔曼滤波的性能，实现了资源利用和估计精度的平衡。

> **ai_Abstract:** 该论文探讨了在多传感器、离散且不规则测量情境下，连续-离散卡尔曼滤波器（CD-KF）的优化问题，特别关注测量过程与辅助状态耦合的场景。考虑到传感器特有的成本和约束（如能耗、精度），作者将测量事件建模为泊松过程，并推导了CD-KF后验协方差矩阵的连续可微上界。基于此，提出了一个有限时域最优控制框架，以联合优化测量速率和辅助状态动态，并开发了一种确定性测量时间调度方法。实验证明，该方法在资源利用和估计精度之间实现了更优的平衡。

> **摘要翻译:** 我们研究了用于状态空间模型（SSM）的连续-离散卡尔曼滤波器（CD-KF），其中连续时间动态通过多个传感器进行观测，测量是离散且不规则的。我们的研究重点扩展到测量过程与辅助SSM状态耦合的场景。例如，更高的测量速率可能增加能耗或发热，而传感器的精度可能取决于其自身的空间轨迹或被测目标的轨迹。因此，每个传感器都带有与其测量速率相关的不同成本和约束，以及对辅助状态的额外约束和成本。我们将测量事件建模为具有传感器特定速率的独立泊松过程，并推导出了CD-KF沿平均辅助状态的平均后验协方差矩阵的上界。该上界对测量速率是连续可微的，这使得高效的基于梯度的优化成为可能。利用这个上界，我们提出了一个有限时域最优控制框架，以联合优化测量速率和辅助状态动态。我们还引入了一种从优化速率中确定性调度测量时间的方法。状态空间滤波和动态时间高斯过程回归的经验结果表明，我们的方法在资源使用和估计精度之间实现了更好的权衡。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [761] [Moving Beyond Marginal Carbon Intensity: A Poor Metric for Both Carbon Accounting and Grid Flexibility](https://arxiv.org/abs/2507.11377)
> *摆脱边际碳强度：一个不利于碳核算和电网灵活性的糟糕指标*

*Philipp Wiesner, Odej Kao* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-15**

**Keywords:** 边际碳强度, 碳核算, 电网灵活性, 弃电, 可操作性指标

**Comment:** Presented at the Workshop on Measurements, Modeling, and Metrics for
  Carbon-Aware Computing (CarbonMetrics) @ ACM SIGMETRICS '25

> **TL;DR:** 边际碳强度（MCI）作为碳核算和电网灵活性的指标是不可靠且不可行的。

**AI_Comments:** 这篇声明性论文批判性地分析了边际碳强度（MCI）作为碳核算和电网灵活性指标的局限性。其创新之处在于明确指出MCI的不可靠性和不可操作性，并提出了具体的替代方向，对碳感知计算和能源管理领域具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管边际碳强度（MCI）被推广为碳感知计算的有效指标，但作者认为它无论是用于碳核算还是电网灵活性优化，都既不可靠也不可行。

**Method:** 本文通过阐述边际碳强度（MCI）的根本局限性，包括不可观测性、依赖不透明的预测模型以及缺乏可验证性，来论证其不足。

**Result:** 边际碳强度（MCI）既不可靠也不可操作，因为它不可观测、依赖不透明的预测模型、缺乏可验证性，并且无法反映高碳源造成的弃电，也无法提供可用过剩电量的具体信息。

**Conclusion:** 作者呼吁放弃使用边际碳强度（MCI），转而研究更具可操作性的指标，例如直接报告过剩电量、明确建模储能和电网稳定性，以及与新兴的精细化可再生能源证书市场整合。

> **ai_Abstract:** 本文认为，被广泛推广用于碳感知计算的边际碳强度（MCI）作为碳核算和电网灵活性的指标是不可靠且不可行的。作者指出了MCI的根本局限性，包括不可观测性、依赖不透明预测模型和缺乏可验证性，并强调其无法反映高碳源造成的弃电量或提供过剩电量信息。文章呼吁放弃MCI，转而探索更实际的替代指标，如直接报告过剩电量和整合可再生能源证书市场。

> **摘要翻译:** 边际碳强度（MCI）已被推广为一种有效的碳感知计算指标。尽管它已被认为不适用于碳核算目的，但许多人仍认为它在通过激励弃电期间的用电来优化电网灵活性方面具有价值。在这篇声明性论文中，我们认为MCI对于这两种目的都既不可靠也不可行。我们概述了它的根本局限性，包括不可观测性、对不透明预测模型的依赖以及缺乏可验证性。此外，MCI未能反映由高碳源引起的弃电，也未能提供有关可用过剩电量的任何见解。我们主张超越MCI，转而呼吁研究更具可操作性的指标，例如直接报告过剩电量、明确建模储能和电网稳定性，以及与新兴的精细化可再生能源证书市场整合。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [810] [Inverse Optimal Control with Constraint Relaxation](https://arxiv.org/abs/2507.11392)
> *带约束松弛的逆最优控制*

*Rahel Rickenbach, Amon Lahr, Melanie N. Zeilinger* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-15**

**Keywords:** 逆最优控制, 惩罚函数, 噪声演示, 约束松弛, 最优控制

**Comment:** 

> **TL;DR:** 该论文提出在逆最优控制（IOC）中利用精确惩罚函数来处理噪声演示和错误的约束激活，与传统松弛方法相比，提高了估计精度。

**AI_Comments:** 该论文提出了一种创新方法，通过引入精确惩罚函数，显著增强了逆最优控制（IOC）在存在噪声演示时的鲁棒性，有效解决了约束激活不准确的问题。通过减少未知变量，该方法可能提高了估计效率。其在实际应用中的重要性在于，它能从不完美的演示中实现更可靠的学习。

<details>
  <summary>Details</summary>

**Motivation:** 在处理带有安全保持不等式约束的噪声演示时，传统的逆最优控制（IOC）方法，如逆卡鲁什-库恩-塔克方法，依赖于约束的正确激活和满足，这在实际中是一个限制性假设，导致在约束激活错误时出现问题。

**Method:** 本研究利用精确惩罚函数来解决逆最优控制（IOC）中的问题。该方法展示了惩罚函数如何减少未知变量的数量，以及它们的近似如何增强估计方法在多面体约束环境中处理错误约束激活的能力。所提出的方法在模拟中对三个系统进行了评估。

**Result:** 所提出的基于精确惩罚函数的方法在噪声演示下保持了估计精度，并且在模拟中对三个系统均优于传统的松弛方法。此外，它还减少了未知变量的数量。

**Conclusion:** 在逆最优控制（IOC）中使用精确惩罚函数能有效解决噪声演示和不正确约束激活的挑战，从而比传统方法更稳健和准确地估计目标函数。

> **ai_Abstract:** 本文解决了逆最优控制（IOC）中现有方法在处理噪声演示时因依赖正确不等式约束激活而面临的局限性。为克服此问题，作者提出了一种利用精确惩罚函数的IOC方法。他们证明该方法能保持估计精度，减少未知变量数量，并改善在多面体约束环境中对错误约束激活的处理。在三个系统上的模拟结果表明，所提出的方法在处理噪声演示时优于传统松弛方法。

> **摘要翻译:** 逆最优控制（IOC）是一种很有前景的范式，可以通过从一个或多个相应的最优控制序列中估计未知目标函数，从而学习和模仿有能力的演示者的最优控制策略，或更深入地理解他们的意图。在从具有安全保持不等式约束的环境中的演示计算估计时，在所选的IOC方法中承认它们的存在至关重要，因为它们对最终控制策略有很强的影响。然而，能够考虑不等式约束的求解策略，例如逆卡鲁什-库恩-塔克方法，依赖于其正确的激活和满足；这在处理噪声演示时是一个限制性假设。为了克服这个问题，我们利用精确惩罚函数在IOC中的概念，并展示了估计精度的保持。考虑到噪声演示，我们随后说明了惩罚函数的使用如何减少未知变量的数量，以及它们的近似如何增强估计方法在多面体约束环境中解释错误约束激活的能力。所提出的方法在模拟中对三个系统进行了评估，在噪声演示下优于传统的松弛方法。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [184] [Orthogonality Analysis in LoRa Uplink Satellite Communications Affected by Doppler Effect](https://arxiv.org/abs/2502.16179)
> *LoRa上行卫星通信中受多普勒效应影响的正交性分析*

*Jikang Deng, Fatma Benkhelifa, Mohamed-Slim Alouini* | **Category: eess.SP, cs.SY, eess.SY** | **Updated: 2025-07-15**

**Keywords:** LoRa, 多普勒效应, 卫星通信, 互相关, 误码率

**Comment:** 

> **TL;DR:** 本文首次分析了多普勒效应下LoRa卫星通信的波形和互相关性，并提出了降低多普勒影响的建议。

**AI_Comments:** 该论文的创新之处在于首次提供了多普勒效应下LoRa波形和互相关的分析表达式，并深入分析了其对系统性能（互相关和BER）的影响。研究结果揭示了不同参数对多普勒效应敏感性的差异，特别是关于传输起始时间的冲突建议，突显了未来研究和实际部署中多普勒补偿的关键性。这对于LoRa技术在卫星物联网领域的应用具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 首次在多普勒效应下提供LoRa波形和互相关的分析表达式，旨在理解和解决多普勒效应对LoRa上行卫星通信性能的影响。

**Method:** 提供了LoRa波形和互相关在连续和离散时域下受多普勒效应影响的分析表达式；提出了两地面设备共享可见窗口的概念和公式；分析了不同扩频因子(SF)下有无多普勒效应的互相关结果；进行了轨道高度、地面设备距离和倾角参数分析；分析了LoRa信号的误码率(BER)。

**Result:** 不同SF下的最大互相关和平均互相关不受多普勒效应影响；相同SF下的最大互相关仅在高多普勒频移下不受影响，但在高多普勒速率下其值在0.6到1之间波动；通过引入传输起始时间与互相关之间的关系解释了这种波动；在高多普勒频移或相同SF干扰下，误码率(BER)性能变差；只有当多普勒效应低于某个频率阈值时，增加信噪比(SNR)或信号干扰比(SIR)才能改善BER；在多普勒效应下，BER的性能表现不再与最大互相关一致。

**Conclusion:** 为减轻多普勒对互相关的影响，建议使用低SF、高轨道高度、短地面设备距离以及高多普勒频移的传输起始时间；为减轻多普勒对BER的影响，建议使用低SF、高带宽以及高多普勒速率的传输起始时间；关于传输起始时间的冲突建议强调了多普勒频移补偿技术对于LoRa在太空正常运行的必要性。

> **ai_Abstract:** 该论文首次在考虑多普勒效应的情况下，对LoRa上行卫星通信中的波形和互相关进行了理论分析，并提出了共享可见窗口的概念。研究发现，不同扩频因子下的最大互相关和平均互相关对多普勒效应具有免疫性，但相同扩频因子下的最大互相关在高多普勒速率下会波动。论文还分析了误码率性能，并指出其在高多普勒频移或同SF干扰下会恶化，且其表现与最大互相关不再一致。最终，论文提出了针对互相关和误码率受多普勒影响的不同缓解策略，并强调了多普勒频移补偿技术的重要性。

> **摘要翻译:** 本文首次提供了在卫星通信中受多普勒效应影响的LoRa（Long-Range）波形和互相关在连续和离散时域下的分析表达式。我们提出了卫星对两个地面设备的共享可见窗口的概念和公式。我们的分析涵盖了在无多普勒和有多普勒情况下，不同扩频因子（SF）的互相关结果。我们发现，不同SF下的最大互相关和平均互相关不受多普勒效应的影响。然而，相同SF下的最大互相关仅在高多普勒频移下不受影响，其值在高多普勒速率下在0.6到1之间波动。我们通过引入传输起始时间与互相关之间的关系来解释这种波动。我们对轨道高度、地面设备距离和倾角进行了参数分析。此外，我们分析了LoRa信号的误码率（BER），并观察到在高多普勒频移或相同SF干扰下性能变差。只有当多普勒效应低于某个频率阈值时，增加信噪比（SNR）或信号干扰比（SIR）才能改善BER。值得注意的是，在多普勒效应下，BER的性能表现不再与最大互相关一致。最后，我们的结果提出了两项建议：1）为了减轻多普勒对互相关的影响，我们建议使用低SF、高轨道高度、短地面设备距离以及高多普勒频移的传输起始时间；2）为了减轻多普勒对BER的影响，我们建议采用低SF、高带宽以及高多普勒速率的传输起始时间。这些关于传输起始时间的冲突建议突显了多普勒频移补偿技术对于LoRa在太空正常运行的必要性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [224] [Conformal Lyapunov Optimization: Optimal Resource Allocation under Deterministic Reliability Constraints](https://arxiv.org/abs/2503.00486)
> *共形Lyapunov优化：确定性可靠性约束下的最优资源分配*

*Francesco Binucci, Osvaldo Simeone, Paolo Banelli* | **Category: eess.SP** | **Updated: 2025-07-15**

**Keywords:** 共形Lyapunov优化, 资源分配, 确定性可靠性, 在线共形风险控制, 网络系统

**Comment:** 17 pages, 13 figures

> **TL;DR:** 本文提出了共形Lyapunov优化（CLO），这是一种新型资源分配框架，它结合了Lyapunov优化和在线共形风险控制，能够在满足确定性长期可靠性约束的同时优化平均长期目标，并已通过边缘推理任务验证其有效性。

**AI_Comments:** 该论文的创新点在于将传统的Lyapunov优化与在线共形风险控制相结合，从而解决了传统LO无法提供确定性可靠性保证的问题。这种结合使得资源分配不仅能优化平均性能，还能提供严格的最坏情况保证，对于需要高可靠性的网络系统（如边缘计算中的图像分割）具有重要意义。该框架的提出为未来在不确定环境下优化资源分配提供了新的思路和工具。

<details>
  <summary>Details</summary>

**Motivation:** 传统的Lyapunov优化（LO）在处理资源分配任务时只考虑平均长期约束，无法提供最坏情况下的确定性可靠性保证。因此，本文旨在开发一种新的框架，能够提供形式化的最坏情况确定性可靠性保证。

**Method:** 本文引入了共形Lyapunov优化（CLO）框架。该方法通过将标准Lyapunov优化（LO）框架与在线共形风险控制（O-CRC）相结合来实现。O-CRC是一种自适应更新机制，用于控制长期风险。

**Result:** 仿真结果证实，CLO能够在控制网络中所有分割决策的假阴性率（作为可靠性约束）的同时，最小化能耗和精度损失（后者包括假阳性率）的加权和。

**Conclusion:** 共形Lyapunov优化（CLO）是一种有效的新型资源分配框架，它通过整合Lyapunov优化和在线共形风险控制，能够在满足确定性长期可靠性约束的同时，优化平均长期目标。

> **ai_Abstract:** 本文提出了一种名为共形Lyapunov优化（CLO）的新型资源分配框架，专为网络系统设计。与传统Lyapunov优化（LO）不同，CLO通过整合标准LO框架与在线共形风险控制（O-CRC），能够提供形式化的最坏情况确定性可靠性保证，同时优化平均长期目标。通过在图像分割任务的层次边缘推理上的实验，证实了CLO在控制可靠性约束（如假阴性率）的同时，能有效最小化能耗和精度损失（如假阳性率）的加权和。

> **摘要翻译:** 本文介绍了共形Lyapunov优化（CLO），这是一种用于网络系统的新型资源分配框架，它在满足确定性长期可靠性约束的同时优化平均长期目标。与传统的Lyapunov优化（LO）不同，后者解决的是平均长期约束下的资源分配任务，CLO提供了形式化的最坏情况确定性可靠性保证。这通过将标准LO优化框架与在线共形风险控制（O-CRC）（一种控制长期风险的自适应更新机制）相结合来实现。CLO的有效性通过针对网络计算架构中图像分割任务的层次边缘推理实验进行了验证。具体而言，仿真结果证实，CLO可以控制可靠性约束（通过网络中所有分割决策的假阴性率来衡量），同时最小化能耗和精度损失的加权和，其中后者考虑了假阳性率。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [259] [Memory-less and Backscatter-less Tunnel Diode Harmonic Signatures for RFID](https://arxiv.org/abs/2505.01570)
> *用于RFID的无记忆、无反向散射隧道二极管谐波特征*

*Christopher Saetia, Kaitlyn Graves, Serhat Tadik, Gregory D. Durgin* | **Category: eess.SP** | **Updated: 2025-07-15**

**Keywords:** 隧道二极管, RFID, 谐波特征, 无反向散射, 无记忆

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 该论文探索了利用隧道二极管产生的自然谐波，实现无反向散射和无记忆的RFID标签识别。

**AI_Comments:** 本文的创新之处在于探索了利用隧道二极管的自然谐波进行RFID识别，而非传统的反射放大。这种方法实现了无反向散射和无记忆的ID生成，可能简化标签设计，并为RFID提供了新的识别机制，具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的隧道二极管被研究用于通过反射放大器扩展超高频（UHF）射频识别（RFID）标签的读取范围。本文旨在探索在负微分电阻区域偏置这些二极管时产生的自然谐波，并且无需来自发射源（如RFID阅读器）的询问信号来注入锁定这些二极管，以实现新的RFID应用。

**Method:** 通过在负微分电阻区域偏置隧道二极管，并在没有询问信号的情况下，对它们产生的自然谐波进行了表征。实验使用了五个由相同组件制成的隧道二极管板，并通过电缆测量，在200 mV的偏置电压下，每个板的基频测量值均高于-15 dBm。

**Result:** 这些谐波的出现为每个板创建了独特的谐波特征。

**Conclusion:** 这些独特的谐波特征表明了可能的谐波RFID应用，可以帮助RFID阅读器发现甚至识别由隧道二极管生成的无反向散射和无记忆ID的RFID标签。

> **ai_Abstract:** 本论文研究了在负微分电阻区域偏置隧道二极管时，无需外部询问信号即可产生的自然谐波。研究对五个隧道二极管板的谐波进行了表征，发现它们能够形成独特的谐波特征。这些独特的谐波特征为RFID应用提供了一种新范式，使得RFID阅读器能够发现并识别基于隧道二极管生成、无反向散射且无记忆ID的标签，从而可能扩展RFID技术的应用范围。

> **摘要翻译:** 隧道二极管传统上被研究用作反射放大器，以扩展超高频（UHF）射频识别（RFID）标签的反向散射读取范围。本文探索了在负微分电阻区域偏置这些二极管时产生的自然谐波，并且无需来自发射源（如RFID阅读器）的询问信号来注入锁定这些二极管。对五个由相同组件制成的隧道二极管板的这些谐波进行了表征，在通过电缆测量时，每个板在200 mV偏置电压下的基频测量值均高于-15 dBm。这些谐波的出现为每个板创建了独特的谐波特征，并展示了可能的谐波RFID应用，可以帮助RFID阅读器发现甚至识别由隧道二极管生成的无反向散射和无记忆ID的RFID标签。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [304] [Deep Learning-Based CSI Feedback for Wi-Fi Systems With Temporal Correlation](https://arxiv.org/abs/2505.23198)
> *基于深度学习的带时间相关性的Wi-Fi系统CSI反馈*

*Junyong Shin, Eunsung Jeon, Inhyoung Kim, Yo-Seb Jeon* | **Category: eess.SP** | **Updated: 2025-07-15**

**Keywords:** 深度学习, CSI反馈, Wi-Fi系统, 时间相关性, 矢量量化

**Comment:** 

> **TL;DR:** 本文提出了一种基于深度学习的Wi-Fi系统CSI反馈框架，利用可训练的矢量量化和角度差反馈策略，并结合CSI细化模块，显著提高了CSI压缩和重建的性能。

**AI_Comments:** 该论文的创新点在于将深度学习应用于Wi-Fi系统的CSI反馈，并特别关注了时间相关性。引入可训练的矢量量化模块实现了高效的有限位表示，而角度差反馈策略和CSI细化模块则有效利用了CSI的时间特性，从而在提高压缩效率的同时保证了重建精度。这对于提升下一代Wi-Fi系统的吞吐量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了在下一代Wi-Fi系统中实现更高的吞吐量，需要高效地压缩信道状态信息（CSI）并将其反馈给接入点（AP）。

**Method:** 本文提出了一种新颖的基于深度学习（DL）的CSI反馈框架，包含编码器和解码器神经网络用于压缩和重建CSI的角度参数。框架中集成了可训练的矢量量化模块，并与编解码器网络进行端到端联合训练。此外，通过利用角度参数的时间相关性，提出了一种角度差反馈策略，当差值足够小时传输当前和先前角度参数的差值，并通过预处理解决周期性问题并使用新颖的反馈方法减轻误差传播。同时引入了基于DL的CSI细化模块，利用先前和当前的反馈信息提高重建精度。

**Result:** 仿真结果表明，所提出的框架优于当前Wi-Fi系统中采用的标准方法。角度差反馈策略和CSI细化模块也实现了显著的性能提升。

**Conclusion:** 本文提出的基于深度学习的CSI反馈框架，结合了可训练的矢量量化、角度差反馈策略和CSI细化模块，能够有效提高下一代Wi-Fi系统的CSI压缩和重建性能，从而实现更高的吞吐量。

> **ai_Abstract:** 本文提出了一种针对下一代Wi-Fi系统的深度学习（DL）CSI反馈框架。该框架利用编解码器神经网络对CSI角度参数进行压缩和重建，并引入了可训练的矢量量化模块进行高效的有限位表示。为进一步提升性能，该框架利用角度参数的时间相关性，提出了一种角度差反馈策略，并在AP端引入了DL-based CSI细化模块。仿真结果表明，该框架显著优于现有标准方法，且角度差反馈策略和CSI细化模块带来了显著的性能增益。

> **摘要翻译:** 为了在下一代Wi-Fi系统中实现更高的吞吐量，站点（STA）需要高效地压缩信道状态信息（CSI）并将其反馈给接入点（AP）。在本文中，我们提出了一种新颖的基于深度学习（DL）的CSI反馈框架，专为下一代Wi-Fi系统定制。我们的框架包含一对编码器和解码器神经网络，用于压缩和重建CSI的角度参数。为了实现编码器输出的高效有限位表示，我们引入了一个可训练的矢量量化模块，该模块集成在编码器网络之后，并与编码器和解码器网络以端到端的方式联合训练。此外，我们通过利用角度参数的时间相关性进一步增强了我们的框架。具体来说，我们提出了一种角度差反馈策略，当差值足够小时传输当前和先前角度参数的差值。该策略通过适当的预处理考虑了角度参数的周期性，并使用新颖的反馈方法减轻了误差传播效应。我们还在AP端引入了一个基于DL的CSI细化模块，通过同时利用先前和当前的反馈信息来提高角度参数的重建精度。仿真结果表明，我们的框架优于当前Wi-Fi系统中采用的标准方法。我们的结果还表明，角度差反馈策略和CSI细化模块取得了显著的性能提升。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [344] [Compute SNR-Optimal Analog-to-Digital Converters for Analog In-Memory Computing](https://arxiv.org/abs/2507.09776)
> *为模拟内存计算设计SNR最优的模数转换器*

*Mihir Kavishwar, Naresh Shanbhag* | **Category: eess.SP, cs.AR** | **Updated: 2025-07-15**

**Keywords:** 模拟内存计算, 模数转换器, CSNR, CACTUS, 能效

**Comment:** Code available at: https://github.com/mihirvk2/CSNR-optimal-ADC

> **TL;DR:** 先前的模拟内存计算（AIMC）方法高估了模数转换器（ADC）的精度需求。本文提出了CACTUS算法，用于获取CSNR最优的ADC参数，从而将ADC精度降低3位，并实现更高的CSNR。

**AI_Comments:** 本文的创新之处在于引入CSNR作为衡量AIMC精度的更准确指标，而非传统的SQNR，并开发了基于此新指标优化ADC参数的CACTUS算法。这直接解决了AIMC能效中的一个关键限制，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 模拟内存计算（AIMC）是加速机器学习和信号处理工作负载的节能替代方案，但其能效受限于列式模数转换器（ADC）的高能耗。降低ADC精度可以降低能耗，但会影响计算精度。现有工作通过将量化误差建模为与输入无关的噪声、最大化信号量化噪声比（SQNR）并忽略理想预ADC信号的离散特性，从而高估了ADC精度要求。

**Method:** 通过开发计算信噪比（CSNR）的解析表达式来解决现有局限性，CSNR是AIMC精度的真实度量。提出CACTUS算法以获得CSNR最优的ADC参数。使用28nm CMOS工艺中基于SRAM的AIMC的电路感知行为模型进行验证。

**Result:** 对于256维二值点积，CACTUS将ADC精度要求降低了3位，同时比现有方法实现了高6dB的CSNR。文章还阐明了所提出的CSNR最优ADC优于传统SQNR最优ADC的工作条件。

**Conclusion:** 本文提出的CSNR最优ADC设计方法CACTUS，通过更准确地确定ADC精度要求，显著改善了AIMC的能效与精度之间的权衡，性能优于传统方法。

> **ai_Abstract:** 本文针对模拟内存计算（AIMC）中模数转换器（ADC）精度要求被高估而导致能效受限的问题，提出了解决方案。通过开发计算信噪比（CSNR）的解析表达式并提出CACTUS算法，作者展示了CSNR最优的ADC参数可以显著降低精度要求（3位），同时比基于传统信号量化噪声比（SQNR）的方法实现更高的精度（6dB的CSNR提升）。这项工作为设计节能的AIMC系统提供了更准确的度量和方法。

> **摘要翻译:** 模拟内存计算（AIMC）是加速机器学习和信号处理工作负载的节能替代方案。然而，其能效受限于列式模数转换器（ADC）的高能耗。降低ADC精度是降低其能耗的有效方法。然而，这样做也会降低AIMC的计算精度，因此确定满足目标所需的最小精度至关重要。现有工作通过将量化误差建模为与输入无关的噪声，最大化信号量化噪声比（SQNR），并忽略理想预ADC信号的离散特性，从而高估了ADC精度要求。我们通过开发用于估计计算信噪比（CSNR）的解析表达式来解决这些局限性，CSNR是AIMC精度的真实度量，并提出了CACTUS算法以获得CSNR最优的ADC参数。使用28nm CMOS工艺中基于SRAM的AIMC的电路感知行为模型，我们表明对于256维二值点积，CACTUS将ADC精度要求降低了3位，同时比现有方法实现了高6dB的CSNR。我们还阐明了所提出的CSNR最优ADC优于传统SQNR最优ADC的工作条件。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [387] [Waterfilling at the Edge: Optimal Percentile Resource Allocation via Risk-Averse Reduction](https://arxiv.org/abs/2507.10838)
> *边缘注水：基于风险规避缩减的最优分位数资源分配*

*Gokberk Yaylali, Ahmad Ali Khan, Dionysios S. Kalogerias* | **Category: eess.SP, cs.IT, math.IT, math.OC** | **Updated: 2025-07-14**

**Keywords:** 条件风险价值, 资源分配, 量化传输速率, 注水算法, 边缘计算

**Comment:** 5 pages, 5 figures

> **TL;DR:** 该研究提出了一种新的基于条件风险价值（CVaR）的边缘终端资源分配方法，通过建立其与SLαQ效用的等价性，实现了凸重构，并提供了注水型闭式解和低复杂度的次梯度下降算法，有效优化了边缘分位数传输速率。

**AI_Comments:** 该论文的创新点在于首次将条件风险价值（CVaR）这一风险度量引入到边缘资源分配问题中，并成功地将其与SL$\alpha$Q效用建立等价关系，从而将非凸问题转化为可分析的凸问题。其提出的注水型闭式解和低复杂度算法具有重要的理论和实际意义，为边缘网络中的公平性和性能优化提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于效用的资源分配方法（如最小速率、和速率、比例公平）要么过于保守，要么不适用，要么无法为边缘的公平速率优化提供严格和/或可解释的基础。

**Method:** 该研究采用条件风险价值（CVaR）这一连贯风险度量，并建立了其与和-最小-$\alpha$分位数（SL$\alpha$Q）效用的等价性。通过这种联系，将SL$\alpha$Q最大化问题精确地凸重构。利用拉格朗日对偶性，首次提供了最优资源策略（注水型）以及相关（辅助）风险价值变量的参数化闭式解。此外，还开发了一种新颖的、低复杂度的非精确对偶次梯度下降算法来确定全局最优资源策略，并严格证明了其收敛性。

**Result:** 该方法提供了注水型的最优资源策略的闭式解和相关的风险价值变量。开发的边缘注水算法能够迭代且高效地分配资源，同时明确确保（边缘）终端之间的传输速率公平性。大量的数值实验验证了所提出方法在实现边缘鲁棒分位数速率优化方面的有效性。

**Conclusion:** 该研究成功地将条件风险价值（CVaR）应用于边缘资源分配问题，克服了传统方法的局限性，并提供了一种可解释、可分析且高效的解决方案，有效优化了边缘终端的分位数传输速率。

> **ai_Abstract:** 该论文提出了一种基于条件风险价值（CVaR）的边缘终端资源分配新范式，旨在优化AWGN信道中小区边缘终端的量化传输速率。通过建立CVaR与SL$\alpha$Q效用的等价性，作者将资源分配问题重构为凸优化问题，并利用拉格朗日对偶性首次推导出了注水型的闭式最优资源策略。此外，还开发了一种低复杂度的非精确对偶次梯度下降算法来求解全局最优策略。数值实验验证了该方法在边缘鲁棒分位数速率优化方面的有效性，确保了边缘终端的传输速率公平性。

> **摘要翻译:** 我们研究了无终端间干扰的点对点多终端AWGN信道中的确定性资源分配问题，特别关注优化小区边缘终端服务的量化传输速率。经典的基于效用的方法——例如最小速率、和速率和比例公平——要么过于保守，要么不适用，要么无法为边缘的公平速率优化提供严格和/或可解释的基础。为了克服这些挑战，我们采用了条件风险价值（CVaR）这一流行的连贯风险度量，并建立了其与和-最小-$\alpha$分位数（SL$\alpha$Q）效用的等价性。这种联系使得SL$\alpha$Q最大化问题能够进行精确的凸重构，从而便于分析处理以及对小区边缘终端性能进行精确且可解释的控制。利用拉格朗日对偶性，我们首次提供了最优资源策略（注水型）以及相关（辅助）风险价值变量的参数化闭式解。我们进一步开发了一种新颖的、复杂度最低的非精确对偶次梯度下降算法，以确定全局最优资源策略，并严格证明了其收敛性。由此产生的边缘注水算法能够迭代且高效地分配资源，同时明确确保（小区边缘）终端之间的传输速率公平性。多项（甚至是大规模的）数值实验验证了所提出方法在实现边缘鲁棒分位数速率优化方面的有效性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [447] [Optimizing Fluid Antenna Configurations for Constructive Interference Precoding](https://arxiv.org/abs/2507.11093)
> *优化流体天线配置以实现建设性干扰预编码*

*Wenxuan Sun, Mingjie Shao, Luteng Zhu, Yao Ge, Tong Zhang, Zhi Liu* | **Category: eess.SP, cs.IT, math.IT** | **Updated: 2025-07-15**

**Keywords:** 流体天线系统, 建设性干扰预编码, 符号错误概率, 块坐标下降, 计算复杂度

**Comment:** 

> **TL;DR:** 本文提出了一种新的方法，通过将符号错误概率最小化问题转化为安全裕度最大化问题，并使用定制的平滑技术和BCD算法，优化流体天线配置以实现建设性干扰预编码。仿真结果表明，该方法在降低误码率和计算复杂度方面优于现有技术。

**AI_Comments:** 这篇论文通过提出一种创新的优化方法来解决流体天线系统（FAS）与建设性干扰（CI）预编码相结合的符号错误概率（SEP）最小化问题，填补了现有研究的空白。其亮点在于将非凸非光滑问题转化为安全裕度最大化，并设计了低复杂度的平滑技术和BCD算法。在实际应用中，低计算复杂度是一个重要的优势，这使得该方法在资源受限的通信系统中具有潜在的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 流体天线系统（FAS）为多用户MIMO通信提供了比传统固定阵列更好的传播条件。然而，针对多用户下行链路中配备FAS的系统，在MPSK信令下最小化最大符号错误概率（SEP）并结合建设性干扰（CI）预编码的问题尚未得到解决。

**Method:** 作者将SEP最小化问题转化为建设性干扰预编码中的安全裕度最大化问题。然后，定制了一种平滑技术和块坐标下降（BCD）算法来解决这个非凸非光滑的优化挑战，并强调了低计算复杂度。

**Result:** 仿真结果表明，与固定阵列以及现有粒子群优化（PSO）设计的FAS相比，所提出的方法能够降低误码率（BER）。此外，该方法与PSO基准相比，显示出极低的计算复杂度。

**Conclusion:** 该研究成功开发了一种优化流体天线配置以实现建设性干扰预编码的方法，该方法在降低误码率和计算复杂度方面表现优异，为FAS在多用户MIMO通信中的应用提供了有效解决方案。

> **ai_Abstract:** 本文提出了一种优化流体天线系统（FAS）配置以实现建设性干扰（CI）预编码的新方法，旨在最小化多用户MIMO下行链路中的最大符号错误概率（SEP）。鉴于该问题是非凸非光滑的，作者将其转化为安全裕度最大化问题，并开发了定制的平滑技术和低复杂度的块坐标下降（BCD）算法。仿真结果验证了该方法在降低误码率方面优于固定阵列和现有FAS设计方法，并展现出显著的低计算复杂度。

> **摘要翻译:** 流体天线系统（FAS）作为一种新的物理层概念，能够为多用户多输入多输出（MIMO）通信提供比传统固定阵列更好的传播条件。这项工作专注于在配备FAS的多用户下行链路中，M-ary相移键控（MPSK）信令下最小化最大符号错误概率（SEP），其中每个天线在非重叠区间内移动。这种FAS与建设性干扰（CI）预编码相结合的联合SEP最小化问题此前尚未被解决。由此产生的问题被证明是一个非凸且非光滑的优化难题。我们将SEP最小化问题转化为建设性干扰预编码中的安全裕度最大化问题。然后，我们定制了一种平滑技术和块坐标下降（BCD）算法，重点在于降低计算复杂度。仿真结果表明，与固定阵列以及现有粒子群优化（PSO）设计的FAS相比，我们的方法可以降低误码率（BER）。此外，与PSO基准相比，我们的方法显示出极低的计算复杂度。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [537] [A Leap-on-Success Exhaustive Search Method to Find Optimal Robust Minimum Redundancy Arrays (RMRAs): New Array Configurations for Sensor Counts 11 to 20](https://arxiv.org/abs/2507.10706)
> *一种基于成功跳跃的穷举搜索方法，用于寻找最优鲁棒最小冗余阵列（RMRAs）：传感器数量11到20的新阵列配置*

*Pradyumna Kunchala, Ashish Patwari* | **Category: eess.SP, cs.SY, eess.SY** | **Updated: 2025-07-14**

**Keywords:** 鲁棒最小冗余阵列（RMRAs）, 成功跳跃式, 穷举搜索, 传感器阵列, 阵列配置优化

**Comment:** 21 pages, 8 Tables, 4 Figures

> **TL;DR:** 本文提出了一种“成功跳跃式”穷举搜索方法，用于寻找传感器数量为11到20的新的最优和接近最优的鲁棒最小冗余阵列（RMRA）配置，扩展了之前的限制，并验证了其鲁棒性。

**AI_Comments:** 创新点在于“成功跳跃式”穷举搜索算法，它通过优化搜索过程有效解决了NP-难问题。这显著突破了已知最优RMRA配置的界限，对于现实世界应用中鲁棒的传感器阵列设计具有重要意义。该方法对更大阵列的潜在适用性也是一个显著的优势。

<details>
  <summary>Details</summary>

**Motivation:** 寻找最优的鲁棒最小冗余阵列（RMRA）配置是一个NP-难问题，之前的研究仅报告了多达十个传感器阵列的最优解，因此需要为更大数量的传感器寻找新的配置。

**Method:** 本文提出了一种新颖的“成功跳跃式”穷举搜索算法，通过在找到最优解时终止搜索来有效减少计算量。通过MATLAB仿真，在所有单元素故障情况下验证了这些阵列的鲁棒性。

**Result:** 本文发现了传感器数量为11到15的新的最优RMRA配置，并报告了16到20的接近最优配置。这些阵列在单元素故障场景下表现出优于现有TFRAs的韧性。

**Conclusion:** 所提出的“成功跳跃式”方法能够有效找到更大传感器数量的最优和接近最优的RMRA配置，这不仅推动了RMRA设计领域的进步，还引入了一种可用于未来阵列配置优化的有效搜索方法。

> **ai_Abstract:** 本文解决了寻找最优鲁棒最小冗余阵列（RMRA）配置的NP-难问题，该配置对于即使在传感器故障情况下也能保持准确方向估计至关重要。本文提出了一种新颖的“成功跳跃式”穷举搜索算法，可有效识别最优解。利用该方法，作者报告了11-15个传感器的新最优RMRA配置以及16-20个传感器的接近最优配置，显著扩展了此前10个传感器的限制。MATLAB仿真证实了这些新发现配置在单元素故障下的卓越鲁棒性。这项工作不仅提供了有价值的新阵列设计，还提出了一种有效且可推广的搜索方法，以应对未来的阵列优化挑战。

> **摘要翻译:** 双重冗余稀疏阵列（TFRAs）旨在即使在单个传感器发生故障的情况下也能保持准确的方向估计，这得益于其设计中注入的故意共阵列冗余。鲁棒最小冗余阵列（RMRAs）是TFRAs的一个特殊类别，它优化了这种冗余，以在给定传感器数量下实现最大可能的孔径。然而，寻找最优的RMRA配置是一个NP-难问题，之前的研究仅报告了多达十个传感器阵列的最优解。本文提出了一种新颖的“成功跳跃式”穷举搜索算法，通过在找到最优解时终止搜索来有效减少计算量，并利用该算法发现了传感器数量为11到15的新的最优RMRA配置。通过MATLAB仿真，在所有单元素故障场景下验证了这些阵列的鲁棒性，证实了它们与某些在特定传感器位置容易发生故障的现有TFRAs相比具有卓越的韧性。此外，本文还报告了传感器数量为16到20的接近最优配置，突出了所提出方法在计算资源充足的情况下对更大阵列设计的潜在适用性。这项工作不仅推动了RMRA设计的最新进展，而且引入了一种可用于未来阵列配置优化的有效搜索方法。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [578] [Fast and Efficient Implementation of the Maximum Likelihood Estimation for the Linear Regression with Gaussian Model Uncertainty](https://arxiv.org/abs/2507.11249)
> *高斯模型不确定性下线性回归最大似然估计的快速高效实现*

*Ruohai Guo, Jiang Zhu, Xing Jiang, Fengzhong Qu* | **Category: eess.SP, cs.IT, math.IT** | **Updated: 2025-07-15**

**Keywords:** 最大似然估计, 线性回归, 高斯模型不确定性, 凸性, GRV-ML

**Comment:** 

> **TL;DR:** 本文将具有随机测量矩阵的线性回归的最大似然估计 (MLE) 扩展到秩亏情况，证明了凸性，显示了欠定情况下随机性的益处，并提出了一种快速统一的算法 (GRV-ML)。

**AI_Comments:** 该论文通过证明在更一般的秩亏条件下的 MLE 问题的凸性和强对偶性，做出了重要的理论贡献，这增强了先前的拟凸性结果。GRV-ML 的开发为更广泛的具有高斯模型不确定性的线性回归问题提供了实用且统一的解决方案。随机性在欠定情况下可能有利的发现也具有启发性。

<details>
  <summary>Details</summary>

**Motivation:** 以前关于具有随机测量矩阵（满列秩）的线性回归的研究已经确立了拟凸性并开发了高效的二分法算法（RV-ML）。这项工作的目的是将分析扩展到随机测量矩阵的均值可以是秩亏的情况，涵盖过定和欠定场景。

**Method:** 本文证明了等效的 MLE 问题是凸的并且满足强对偶性。此外，提出了一种快速统一的 MLE 解决方案实现，称为广义 RV-ML (GRV-ML)，它处理包括欠定和过定系统在内的更一般情况。通过数值模拟验证了理论发现。

**Result:** 等效的 MLE 问题被证明是凸的并且满足强对偶性，这强化了先前的拟凸性结果。在欠定场景中，测量矩阵中的随机性在某些条件下可能有利于估计。提出了一种快速统一的 MLE 解决方案 (GRV-ML)。

**Conclusion:** 本文将线性回归最大似然估计的分析扩展到随机测量矩阵均值秩亏的情况，证明了其凸性，揭示了随机性在欠定场景中的潜在益处，并提出了一种统一、快速的广义 RV-ML (GRV-ML) 算法，适用于过定和欠定系统。

> **ai_Abstract:** 本文将线性回归的最大似然估计 (MLE) 扩展到随机测量矩阵均值可以是秩亏的情况，涵盖过定和欠定场景。论文证明了等效的 MLE 问题是凸的且满足强对偶性，从而强化了先前的拟凸性结果。研究还表明，在欠定情况下，测量矩阵中的随机性可能对估计有利。此外，提出了一种快速统一的 MLE 算法，即广义 RV-ML (GRV-ML)，以处理更广泛的应用，并通过大量数值模拟验证了理论发现。

> **摘要翻译:** 具有随机变量 (RV) 测量矩阵的线性回归模型，其中随机测量矩阵的均值具有满列秩，已被广泛研究。特别是，最大似然估计 (MLE) 问题的拟凸性已得到证实，并推导出了相应的 Cramer-Rao 界 (CRB)，从而开发出了一种高效的基于二分法的算法，称为 RV-ML。相比之下，这项工作将分析扩展到过定和欠定情况，允许随机测量矩阵的均值是秩亏的。一个显著的贡献是证明了等效的 MLE 问题是凸的并且满足强对偶性，这强化了先前的拟凸性结果。此外，研究表明，在欠定场景中，测量矩阵中的随机性在某些条件下可能有利于估计。此外，提出了一种快速统一的 MLE 解决方案实现，称为广义 RV-ML (GRV-ML)，它处理更一般的情况，包括欠定和过定系统。提供了大量的数值模拟来验证理论发现。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [586] [Dual RIS-Assisted Monostatic L-Band Radar Target Detection in NLoS Scenarios](https://arxiv.org/abs/2507.11036)
> *双RIS辅助单站L波段雷达在非视距场景下的目标检测*

*Salman Liaquat, Ijaz Haider Naqvi, Nor Muzlifah Mahyuddin* | **Category: eess.SP** | **Updated: 2025-07-15**

**Keywords:** 双RIS, 雷达检测, 非视距, 信噪比, 可重构智能表面

**Comment:** Accepted for presentation at the 9th International Conference on
  Communications and Future Internet

> **TL;DR:** 本文研究了在非视距（NLoS）场景下，双可重构智能表面（RIS）辅助单站雷达进行目标检测的信噪比（SNR）性能。结果表明，通过控制RIS的数量、单元数量和位置，可以显著提高检测性能，甚至超越单RIS系统。

**AI_Comments:** 本文创新性地提出了双RIS辅助雷达系统，解决了单RIS在复杂非视距场景下的局限性。通过推导SNR表达式并分析了多个RIS参数对性能的影响，为实际部署提供了理论依据。其重要性在于为未来复杂电磁环境下雷达目标检测提供了新的技术路径，尤其是在城市、室内等NLoS场景中具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 单RIS在某些非视距场景下仍无法建立雷达与目标之间的路径，存在检测盲区。因此，需要探索更有效的辅助方式来解决这一问题。

**Method:** 论文推导了双RIS辅助单站雷达在NLoS场景下目标检测的SNR表达式，并计算了通过双RIS配置在雷达处接收到的功率。

**Result:** 在已知雷达和RIS位置的情况下，RIS辅助雷达的SNR性能可以得到改善。通过控制RIS的数量、每个RIS的单元数量以及适当选择RIS的位置以覆盖所需区域，可以达到所需的目标定位精度。在有利的对准和足够大的RIS尺寸下，双RIS辅助雷达系统的性能可以超越单RIS辅助雷达系统。

**Conclusion:** 双RIS辅助雷达系统在非视距场景下能够显著提升目标检测性能和定位精度，尤其是在特定配置下其性能优于单RIS系统。

> **ai_Abstract:** 本文研究了在非视距（NLoS）场景下，双可重构智能表面（RIS）辅助单站L波段雷达进行目标检测的性能。针对单RIS可能存在的检测盲区，论文推导了双RIS配置下的信噪比（SNR）表达式，并计算了接收功率。研究结果表明，通过优化RIS的数量、单元数和位置，可以显著提升雷达的SNR性能和目标定位精度，且双RIS系统在特定条件下性能优于单RIS系统，为NLoS环境下的目标检测提供了新的解决方案。

> **摘要翻译:** 使用单个可重构智能表面（RIS）来提高雷达处的信噪比（SNR）在目标检测中提供了显著改进，特别是在非视距（NLoS）场景中。然而，在某些场景中，即使有单个RIS辅助雷达，由于存在其他障碍物，雷达和目标之间也可能不存在路径。本文推导了双RIS辅助单站雷达在NLoS场景下目标检测的SNR表达式。我们计算了通过双RIS配置在雷达处接收到的功率。我们表明，在已知雷达和RIS位置的情况下，RIS辅助雷达的SNR性能可以得到改善。我们的结果表明，通过控制RIS的数量、每个RIS中的单元数量以及适当选择RIS的位置以覆盖所需区域，可以达到所需的目标定位精度。在有利的对准和足够大的RIS尺寸下，双RIS辅助雷达系统的性能可以超越单RIS辅助雷达系统。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [628] [Fairness-Aware Secure Integrated Sensing and Communications with Fractional Programming](https://arxiv.org/abs/2507.11224)
> *公平感知安全集成传感与通信与分数规划*

*Ali Khandan Boroujeni, Kuranage Roche Rayan Ranasinghe, Giuseppe Thadeu Freitas de Abreu, Stefan Köpsell, Ghazal Bagheri, Rafael F. Schaefer* | **Category: eess.SP** | **Updated: 2025-07-15**

**Keywords:** 集成传感与通信, 公平性, 安全性, 分数规划, 优化

**Comment:** Submitted to an IEEE journal

> **TL;DR:** 该论文提出了一种公平感知安全的ISAC系统，通过优化问题和加速二次变换方法来最大化保密率，并在仿真中验证了性能增益。

**AI_Comments:** 该研究创新性地将公平性引入安全ISAC系统的资源分配问题中，通过熵正则化和加速二次变换提供了一种有效的优化方法。其提出的系统和算法对于未来ISAC技术在实际应用中的公平性与安全性保障具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决多用户多目标ISAC系统中保密率最大化问题，并引入公平性考量。

**Method:** 提出一种新的安全集成传感与通信(ISAC)系统；构建一个优化问题，在平衡通信和传感需求约束下最大化保密率；引入熵正则化公平性度量以增强用户公平性；采用加速二次变换(QT)与非齐次边界迭代求解两个子问题来优化整体目标。

**Result:** 该方法确保了ISAC系统中资源分配的鲁棒安全性和公平性。仿真结果验证了平均保密率、平均数据速率和波束增益方面的性能增益。

**Conclusion:** 通过提出的优化框架和求解方法，该ISAC系统能够在保证鲁棒安全性和公平性的前提下，有效提升系统性能。

> **ai_Abstract:** 本文提出了一种新颖的公平感知安全集成传感与通信（ISAC）系统，旨在服务多通信用户和目标。通过构建一个优化问题，并在平衡通信与传感需求约束下最大化保密率，同时引入熵正则化公平性度量来增强用户公平性。为求解此问题，研究者提出了一种利用加速二次变换（QT）迭代求解子问题的方法。仿真结果表明，该方法在平均保密率、平均数据速率和波束增益方面取得了显著的性能提升，确保了ISAC系统资源分配的鲁棒安全性和公平性。

> **摘要翻译:** 我们提出了一种新颖的安全集成传感与通信（ISAC）系统，旨在服务多个通信用户（CU）和目标。为此，我们构建了一个优化问题，在平衡通信和传感需求的约束下最大化保密率。为了增强用户间的公平性，在问题框架中引入了熵正则化公平性度量。然后，我们提出一种采用加速二次变换（QT）和非齐次边界的解决方案，迭代求解两个子问题，从而有效优化整体目标。这种方法确保了ISAC系统中资源分配的鲁棒安全性和公平性。最后，仿真结果验证了在平均保密率、平均数据速率和波束增益方面的性能增益。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [670] [Sensing Accuracy Optimization for Multi-UAV SAR Interferometry with Data Offloading](https://arxiv.org/abs/2507.11284)
> *多无人机合成孔径雷达干涉测量中数据卸载的传感精度优化*

*Mohamed-Amine Lahmeri, Pouya Fakharizadeh, Víctor Mustieles-Pérez, Martin Vossiek, Gerhard Krieger, Robert Schober* | **Category: eess.SP** | **Updated: 2025-07-15**

**Keywords:** 无人机, SAR干涉测量, 精度优化, 数据卸载, 进化算法

**Comment:** 

> **TL;DR:** 本文通过联合优化无人机编队、速度和通信功率分配，利用进化算法，提高了多无人机合成孔径雷达干涉测量（InSAR）的传感精度，并在数值结果中优于基线方案，实现了亚分米级垂直精度。

**AI_Comments:** 本文通过对无人机编队、速度和通信功率的联合优化，有效提升了多无人机SAR干涉测量的精度，特别是在复杂计算需数据回传的场景下。其创新点在于将多种优化参数整合，并采用进化算法进行求解，验证了其在实际应用中的优越性。这项工作对于推动高精度遥感和无人机协同观测具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 无人机与雷达成像传感器的结合革新了动态和局部地球表面过程的监测，实现了高分辨率和高成本效益的遥感。本文旨在通过优化多基线InSAR传感器的传感精度，来提高数字高程模型（DEM）的垂直精度，同时确保传感和通信的服务质量（QoS）。

**Method:** 本文通过联合优化无人机编队、速度和通信功率分配，使用进化算法（EAs）来最小化平均DEM的高度误差，从而提高传感精度。该方法与遗传算法（GAs）、模拟退火（SA）和深度强化学习（DRL）等优化方法进行了基准测试。

**Result:** 数值结果表明，所提出的解决方案优于基线方案，并在多种场景下实现了亚分米级的垂直精度。

**Conclusion:** 研究结果强调了协调的无人机蜂群通过雷达干涉测量提供高精度和实时地球观测的潜力。

> **ai_Abstract:** 本文研究了多无人机合成孔径雷达干涉测量（InSAR）的传感精度优化，旨在提高数字高程模型（DEM）的垂直精度。通过最小化平均DEM的高度误差，并确保传感和通信服务质量，文章提出了利用进化算法联合优化无人机编队、速度和通信功率分配的方法。实验结果表明，该方法在精度上优于现有优化技术，并实现了亚分米级的垂直精度，展示了协调无人机蜂群在高精度地球观测中的潜力。

> **摘要翻译:** 无人机（UAVs）与雷达成像传感器的集成通过实现高分辨率和高成本效益的遥感，彻底改变了动态和局部地球表面过程的监测。本文研究了部署用于执行多基线干涉合成孔径雷达（InSAR）传感的无人机群的传感精度优化。在传统的单基线InSAR系统中，只有一对合成孔径雷达（SAR）天线从两个不同的角度获取两幅SAR图像，以生成目标区域的数字高程模型（DEM）。然而，多基线InSAR通过聚合来自不同角度的多次采集来扩展这一概念，从而显著提高了DEM的垂直精度。该过程所需的繁重计算在地面进行，因此雷达数据通过频分多址（FDMA）空对地回程链路实时传输到地面站（GS）。这项工作通过最小化平均DEM的高度误差来提高传感精度，同时确保传感和通信的服务质量（QoS）。为此，利用进化算法（EAs）联合优化了无人机编队、速度和通信功率分配。我们的方法与已建立的优化方法进行了基准测试，包括遗传算法（GAs）、模拟退火（SA）和深度强化学习（DRL）技术。数值结果表明，所提出的解决方案优于这些基线方案，并在多种场景下实现了亚分米级的垂直精度。这些发现强调了协调无人机蜂群通过雷达干涉测量提供高精度和实时地球观测的潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [719] [Sparse Regression Codes exploit Multi-User Diversity without CSI](https://arxiv.org/abs/2507.11383)
> *稀疏回归码在没有信道状态信息的情况下利用多用户分集*

*V S V Sandeep, Sai Dinesh Kancharana, Arun Pachai Kannu* | **Category: eess.SP** | **Updated: 2025-07-15**

**Keywords:** 稀疏回归码, 多用户分集, 最大似然匹配追踪, 非相干信道, 无信道状态信息

**Comment:** 

> **TL;DR:** 本文提出了一种新的MLMP解码器，用于稀疏回归码（SPARC）在非相干多用户信道中实现多用户分集。研究表明，即使没有信道状态信息（CSI），结合MLMP的SPARC也能提供优于单用户和传统算法的误码性能。

**AI_Comments:** 这篇论文的创新之处在于提出了一种新颖的MLMP解码器，它允许稀疏回归码在没有信道状态信息的情况下利用多用户分集，这对于实际无线通信系统具有重要意义。MLMP作为逐次合并能量检测器的工作方式也区别于传统的逐次消除算法。论文证明了其在短块长度下的性能优势，超越了现有的一些基准方法。

<details>
  <summary>Details</summary>

**Motivation:** 研究稀疏回归码（SPARC）在具有多接收天线的非相干平坦衰落多址信道中的应用，并解决在没有信道状态信息（CSI）的情况下如何实现多用户分集并提高性能的问题。

**Method:** 提出了一种新颖实用的解码器，称为最大似然匹配追踪（MLMP），它通过部分最大似然度量贪婪地找到用户码字的支撑。与传统的基于逐次消除的贪婪算法不同，MLMP作为逐次合并能量检测器工作。此外，还提出了MLMP的修改版本以提高高码率下的性能。

**Result:** 在短块长度的研究中表明，即使没有任何信道状态信息，结合MLMP解码器的SPARC在某些场景下也能实现多用户分集，与相应的单用户情况相比，多用户时具有更好的误码性能。此外，SPARC结合MLMP的表现优于传统的稀疏恢复算法和结合极化码的导频辅助传输。

**Conclusion:** 稀疏回归码（SPARC）结合所提出的MLMP解码器，即使在没有信道状态信息（CSI）的情况下，也能够在非相干多用户信道中有效利用多用户分集，并展现出优于现有方法的性能。

> **ai_Abstract:** 本文研究了在非相干平坦衰落多址信道中使用稀疏回归码（SPARC）。作者提出了一种新的实用解码器——最大似然匹配追踪（MLMP），该解码器采用逐次合并能量检测器的方法，并能通过部分最大似然度量贪婪地识别码字支撑。研究表明，即使在没有信道状态信息（CSI）的情况下，结合MLMP的SPARC也能在某些场景下实现多用户分集，提供比单用户更好的误码性能，并且优于传统的稀疏恢复算法和导频辅助传输方案。

> **摘要翻译:** 我们研究了在非相干平坦衰落信道中，用于具有多接收天线的多址信道的稀疏回归码（SPARC）。我们提出了一种新颖实用的解码器，称为最大似然匹配追踪（MLMP），它通过部分最大似然度量贪婪地找到用户码字的支撑。与传统的基于逐次消除的贪婪算法不同，MLMP作为逐次合并能量检测器工作。我们还提出了MLMP的修改版本，以提高高码率下的性能。我们在短块长度的研究表明，即使没有任何信道状态信息，结合MLMP解码器的SPARC在某些场景下也能实现多用户分集，与相应的单用户情况相比，多用户时具有更好的误码性能。我们还表明，SPARC结合MLMP的表现优于传统的稀疏恢复算法和结合极化码的导频辅助传输。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [768] [Joint Power Allocation and Reflecting-Element Activation for Energy Efficiency Maximization in IRS-Aided Communications Under CSI Uncertainty](https://arxiv.org/abs/2507.11413)
> *不确定CSI下IRS辅助通信中能量效率最大化的联合功率分配与反射单元激活*

*Christos N. Efrem, Ioannis Krikidis* | **Category: eess.SP, math.OC** | **Updated: 2025-07-15**

**Keywords:** 智能反射面, 能量效率, 功率分配, 反射单元激活, CSI不确定性

**Comment:** 5 pages, 3 figures

> **TL;DR:** 本文研究了在信道状态信息不确定性下，智能反射面（IRS）辅助通信系统中联合功率分配和反射单元激活以最大化能量效率的问题，并提出了两种有效的优化算法：一种是基于Lambert W函数和动态规划的交替优化（AO）算法，另一种是分支定界（B&B）算法，能保证全局最优。

**AI_Comments:** 本文的创新点在于提出了两种无需外部求解器即可实现的高效算法，用于解决IRS辅助通信中CSI不确定性下的能量效率最大化问题。特别是分支定界（B&B）算法能够保证全局最优性，而交替优化（AO）算法则提供了低复杂度的次优解。这对于实际系统部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在智能反射面（IRS）辅助的通信系统中，考虑到信道状态信息（CSI）不完美的情况，通过联合优化功率分配和反射单元（RE）激活来最大化能量效率（EE）。这是一个具有挑战性的混合整数鲁棒优化问题。

**Method:** 本文开发了两种算法来解决这个混合整数鲁棒优化问题。第一种是基于Lambert W函数和动态规划（DP）算法的交替优化（AO）方法，它能获得次优解且复杂度较低。第二种是分支定界（B&B）方法，它使用AO作为其子程序，并能保证获得全局最优解。两种算法都不需要外部优化求解器。

**Result:** 数值结果表明，所提出的算法优于基线方案。交替优化（AO）在大多数情况下实现了接近最优的性能，而分支定界（B&B）算法平均计算复杂度较低。

**Conclusion:** 本文提出的两种算法，即交替优化（AO）和分支定界（B&B），能够有效地解决在信道状态信息不确定性下IRS辅助通信中能量效率最大化的联合功率分配和反射单元激活问题，并且无需外部求解器即可实现，性能优于基线方案。

> **ai_Abstract:** 本文针对不完美的信道状态信息（CSI）下，智能反射面（IRS）辅助通信系统中的能量效率（EE）最大化问题，提出了一种联合功率分配和反射单元（RE）激活的鲁棒优化方法。该问题是一个混合整数问题，作者开发了两种算法来解决：一种是基于Lambert W函数和动态规划的交替优化（AO）算法，能获得低复杂度的次优解；另一种是分支定界（B&B）算法，以AO为子程序，能保证全局最优解。数值结果表明，这两种算法在性能上优于基线方案，且无需外部求解器。

> **摘要翻译:** 我们研究了在智能反射面（IRS）辅助的通信系统中，考虑信道状态信息（CSI）不完美的情况下，联合功率分配和反射单元（RE）激活以最大化能量效率（EE）的问题。这个鲁棒优化问题是混合整数的，即优化变量包括连续的（发射功率）和离散的（RE的二元状态）。为了解决这个具有挑战性的问题，我们开发了两种算法。第一种是交替优化（AO）方法，它基于Lambert W函数和动态规划（DP）算法，以低复杂度获得了次优解。第二种是分支定界（B&B）方法，它使用AO作为其子程序，并正式保证实现全局最优解。两种算法的实现都不需要任何外部优化求解器。此外，数值结果表明，所提出的算法优于基线方案，AO在大多数情况下实现了接近最优的性能，并且B&B平均计算复杂度较低。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [9] [Using Continual Learning for Real-Time Detection of Vulnerable Road Users in Complex Traffic Scenarios](https://arxiv.org/abs/2507.11046)
> *在复杂交通场景中使用持续学习进行弱势道路使用者实时检测*

*Faryal Aurooj Nasir, Salman Liaquat, Nor Muzlifah Mahyuddin* | **Category: eess.IV** | **Updated: 2025-07-15**

**Keywords:** 持续学习, 弱势道路使用者, 实时检测, YOLOv8, 灾难性遗忘

**Comment:** Accepted for presentation at the 9th International Conference on
  Communications and Future Internet

> **TL;DR:** 本研究提出一个基于YOLOv8-Dynamic的智能自适应系统，通过整合持续学习能力，实时检测弱势道路使用者，并有效适应不断变化的道路条件，同时克服了灾难性遗忘问题。

**AI_Comments:** 该论文的创新点在于将持续学习能力整合到YOLOv8检测器中，使其能够实时适应动态变化的交通环境，并有效解决了深度学习模型在面对统计上不同数据集时的灾难性遗忘问题。这对于提升自动驾驶和交通安全领域的鲁棒性和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 行人与骑自行车者等弱势道路使用者在复杂的交通场景中面临更高的受伤或致命风险，因此需要一个智能自适应系统来实时检测他们并预防事故。

**Method:** 本研究提出了一个智能自适应系统，该系统使用YOLOv8-Dynamic (YOLOv8-D) 算法。系统选择YOLOv8x作为检测器，并与Faster-RCNN、YOLOv5、YOLOv7及其变体进行了比较。算法在YOLOv8检测器架构中整合了持续学习能力，以灵活适应不断变化的道路条件。此外，优化了YOLOv8模型的梯度下降机制，并在两个统计上不同的数据集上进行了训练。

**Result:** 与YOLOv5x相比，YOLOv8x在F1分数上提高了12.14%，在mAP上提高了45.61%。与YOLOv7x相比，YOLOv8x在F1分数上提高了21.26%，在mAP上提高了128.44%。本研究提出的优化算法与定制的YOLOv8框架在F1分数上实现了21.08%的提升，在mAP上实现了31.86%的提升，成功克服了在统计上不同数据集上训练时出现的灾难性遗忘问题。

**Conclusion:** 本研究开发了一个基于YOLOv8-Dynamic的智能自适应系统，能够实时检测弱势道路使用者并适应动态环境，通过整合持续学习和优化梯度下降机制，显著提高了检测精度并有效解决了深度模型在不同数据集上训练时的灾难性遗忘问题。

> **ai_Abstract:** 本研究提出了一种基于YOLOv8-Dynamic的智能自适应系统，旨在实时检测复杂交通场景中的弱势道路使用者。该系统通过整合持续学习能力，使其能够灵活适应不断变化的道路条件，并持续提升检测和跟踪精度。通过优化YOLOv8模型的梯度下降机制并在不同数据集上进行训练，该方法成功克服了深度学习中的灾难性遗忘问题，显著提高了检测性能。

> **摘要翻译:** 行人与骑自行车者等是弱势道路使用者（VRUs），他们固有地暴露在复杂的交通场景中，这使得他们面临更高的受伤或致命风险。本研究提出了一个智能自适应系统，该系统使用YOLOv8-Dynamic (YOLOv8-D) 算法，用于检测弱势道路使用者并实时适应以预防事故的发生。我们通过与Faster-RCNN、YOLOv5、YOLOv7及其变体等其他最先进的目标检测模型进行比较，选择了YOLOv8x作为检测器。与YOLOv5x相比，YOLOv8x在F1分数上显示出12.14%的改进，在平均精度均值（mAP）上显示出45.61%的改进。与YOLOv7x相比，改进在F1分数上为21.26%，在mAP上为128.44%。我们的算法在YOLOv8检测器的架构中整合了持续学习能力，以灵活调整适应不断变化的道路条件，确保在多个数据集领域内的适应性，并促进VRUs检测和跟踪精度的持续提升，拥抱现实世界的动态特性。在我们提出的框架中，我们优化了YOLOv8模型的梯度下降机制，并在两个统计上不同的数据集（在图像视角和类别数量方面）上训练了我们的优化算法，与在一个新数据集上训练的定制YOLOv8框架相比，实现了F1分数21.08%的改进和mAP31.86%的改进，从而克服了当深度模型在统计上不同类型的数据集上训练时发生的灾难性遗忘问题。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [57] [U-RWKV: Lightweight medical image segmentation with direction-adaptive RWKV](https://arxiv.org/abs/2507.11415)
> *U-RWKV：基于方向自适应RWKV的轻量级医学图像分割*

*Hongbo Ye, Fenghe Tang, Peiang Zhao, Zhen Huang, Dexin Zhao, Minghao Bian, S. Kevin Zhou* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 医学图像分割, RWKV, 轻量级, 长距离依赖, 方向自适应

**Comment:** Accepted by MICCAI2025

> **TL;DR:** U-RWKV是一种轻量高效的医学图像分割模型，通过引入RWKV架构和方向自适应模块，解决了现有方法长距离依赖捕获能力不足的问题，在资源受限环境下实现了SOTA性能。

**AI_Comments:** 本文创新性地将RWKV架构引入医学图像分割领域，并设计了DARM和SASE模块，有效解决了传统U-Net变体在捕获长距离依赖和全局感受野方面的局限。其轻量化和高效率的特点，对于资源受限环境下的医疗影像技术普及具有重要意义。然而，摘要中未提供具体的性能指标或与其他SOTA模型的详细对比数据。

<details>
  <summary>Details</summary>

**Motivation:** 实现医疗保健可及性公平需要轻量级且高性能的医学图像分割解决方案，尤其是在资源有限的环境中。现有方法（如U-Net及其变体）的全局有效感受野（ERFs）有限，难以捕获长距离依赖。

**Method:** 本文提出了U-RWKV框架，利用循环加权键值（RWKV）架构，以O(N)的计算成本实现高效的长距离建模。该框架引入了两项关键创新：方向自适应RWKV模块（DARM），通过Dual-RWKV和QuadScan机制聚合上下文线索，减轻方向偏差；以及阶段自适应Squeeze-and-Excitation模块（SASE），动态调整架构以平衡高分辨率细节和语义关系捕获。

**Result:** U-RWKV在保持高计算效率的同时，实现了最先进的分割性能。

**Conclusion:** U-RWKV为在资源受限环境中普及先进医学成像技术提供了实用解决方案。

> **ai_Abstract:** 本文提出了U-RWKV，一个基于循环加权键值（RWKV）架构的轻量级医学图像分割框架，旨在解决现有方法在资源受限环境下捕获长距离依赖的不足。U-RWKV通过引入方向自适应RWKV模块（DARM）和阶段自适应Squeeze-and-Excitation模块（SASE），有效聚合上下文信息，减轻方向偏差，并动态适应不同特征提取阶段。实验证明U-RWKV在保持高计算效率的同时，实现了先进的分割性能，为医疗影像技术普及提供了可行方案。

> **摘要翻译:** 实现医疗保健可及性公平需要轻量级但高性能的医学图像分割解决方案，尤其是在资源有限的环境中。U-Net及其变体等现有方法通常受限于有限的全局有效感受野（ERFs），阻碍了它们捕获长距离依赖的能力。为了解决这个问题，我们提出了U-RWKV，一个利用循环加权键值（RWKV）架构的新颖框架，它以O(N)的计算成本实现了高效的长距离建模。该框架引入了两项关键创新：方向自适应RWKV模块（DARM）和阶段自适应Squeeze-and-Excitation模块（SASE）。DARM采用Dual-RWKV和QuadScan机制来聚合图像中的上下文线索，减轻方向偏差，同时保留全局上下文并保持高计算效率。SASE动态调整其架构以适应不同的特征提取阶段，平衡高分辨率细节保留和语义关系捕获。实验表明，U-RWKV以高计算效率实现了最先进的分割性能，为在资源受限环境中普及先进医学成像技术提供了实用解决方案。代码可在https://github.com/hbyecoding/U-RWKV获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [105] [Precision Spatio-Temporal Feature Fusion for Robust Remote Sensing Change Detection](https://arxiv.org/abs/2507.11523)
> *鲁棒遥感变化检测的精确时空特征融合*

*Buddhi Wijenayake, Athulya Ratnayake, Praveen Sumanasekara, Nichula Wasalathilaka, Mathivathanan Piratheepan, Roshan Godaliyadda, Mervyn Ekanayake, Vijitha Herath* | **Category: eess.IV** | **Updated: 2025-07-15**

**Keywords:** 遥感变化检测, 时空特征融合, ChangeMamba, 状态空间模型, 深度学习

**Comment:** 6 pages, 4 figures, 2 pages, under review(conference paper)

> **TL;DR:** 该论文提出了一种基于ChangeMamba架构的精确时空特征融合方法，通过引入精确融合块、增强解码器和优化损失函数，显著提高了遥感变化检测的精度和鲁棒性。

**AI_Comments:** 该论文的创新点在于将状态空间模型（ChangeMamba架构）与精确融合块相结合，有效解决了传统方法在长距离依赖和全局上下文捕获上的不足，同时避免了Transformer模型的高计算成本。通过引入精确融合块和优化的损失函数，提升了细粒度变化检测的精度和对类别不平衡的鲁棒性，这对于实际遥感应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 遥感变化检测对环境和城市转型监测至关重要，但面临手动特征提取困难和对噪声敏感的挑战。传统方法和早期深度学习模型（如CNN）难以捕获长距离依赖和全局上下文。Transformer模型虽能缓解这些问题，但计算复杂性高，限制了其在高分辨率遥感中的应用。

**Method:** 本文在ChangeMamba架构的基础上，提出了精确融合块（Precision Fusion Blocks）来捕获通道级时间变化和像素级差异，以实现细粒度变化检测。此外，还引入了一个增强解码器流水线，其包含轻量级通道缩减机制，以最小的计算成本保留局部细节。最后，结合交叉熵、Dice和Lovasz目标的优化损失函数被用于解决类别不平衡问题并提升IoU。

**Result:** 在SYSU-CD、LEVIR-CD+和WHU-CD数据集上的评估表明，与最先进的方法相比，该方法在精度、召回率、F1分数、IoU和整体准确性方面均表现出卓越的性能。

**Conclusion:** 该方法在遥感变化检测中展现出优越的鲁棒性和性能，能够有效解决现有挑战。

> **ai_Abstract:** 本研究提出了一种针对鲁棒遥感变化检测的精确时空特征融合方法。该方法基于ChangeMamba架构，通过引入精确融合块来捕捉细粒度变化，并设计了一个包含轻量级通道缩减的增强解码器以保留局部细节。此外，采用结合多种目标的优化损失函数来解决类别不平衡问题并提升检测性能。实验结果表明，该方法在多个标准数据集上均优于现有最先进的技术，证明了其在复杂遥感场景中进行精确变化检测的有效性和鲁棒性。

> **摘要翻译:** 遥感变化检测对于监测环境和城市转型至关重要，但面临手动特征提取和对噪声敏感等挑战。传统方法和早期深度学习模型（如卷积神经网络）难以捕获准确变化检测在复杂场景中所需的远距离依赖和全局上下文。虽然基于Transformer的模型缓解了这些问题，但其计算复杂性限制了它们在高分辨率遥感中的适用性。本文基于ChangeMamba架构（该架构利用状态空间模型进行高效的全局上下文建模），提出了精确融合块以捕获通道级时间变化和像素级差异，从而实现细粒度变化检测。一个增强的解码器流水线，结合了轻量级通道缩减机制，以最小的计算成本保留了局部细节。此外，结合交叉熵、Dice和Lovasz目标的优化损失函数解决了类别不平衡问题并提升了交并比（IoU）。在SYSU-CD、LEVIR-CD+和WHU-CD数据集上的评估显示，与最先进的方法相比，该方法在精度、召回率、F1分数、IoU和整体准确性方面表现出卓越的性能，突出了该方法在遥感变化检测中的鲁棒性。为完全透明起见，代码和预训练模型可在https://github.com/Buddhi19/MambaCD.git访问。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [268] [The Utility of the Virtual Imaging Trials Methodology for Objective Characterization of AI Systems and Training Data](https://arxiv.org/abs/2308.09730)
> *虚拟成像试验方法在客观表征AI系统和训练数据方面的效用*

*Fakrul Islam Tushar, Lavsen Dahal, Saman Sotoudeh-Paima, Ehsan Abadi, W. Paul Segars, Ehsan Samei, Joseph Y. Lo* | **Category: eess.IV, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 虚拟成像试验, AI系统, 训练数据, 医学影像, COVID-19诊断

**Comment:** 

> **TL;DR:** 虚拟成像试验（VIT）方法能客观评估医学影像AI模型和训练数据的效用，揭示了数据多样性对性能的重要性，有助于提高模型透明度和可靠性，弥合实验与临床差距。

**AI_Comments:** 这项研究创新性地提出了虚拟成像试验（VIT）方法作为评估医学影像AI模型和训练数据可信度的客观工具。它不仅解决了AI模型在实际应用中面临的泛化性和可重复性挑战，还通过具体的COVID-19诊断案例验证了VIT的有效性。研究结果强调了数据多样性对AI模型性能的关键作用，并指出VIT能够提供关于影响AI效能的深层因素（如数据特性、患者因素、成像物理）的细致洞察。这对于提高AI模型的透明度、可靠性以及弥合科研与临床之间的差距具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 医学影像AI模型的可信度面临挑战，受模型多样性、训练数据及组合重现性影响。本研究旨在探索新兴的虚拟成像试验（VIT）方法是否能提供客观资源来应对这些挑战。

**Method:** 以COVID-19诊断为例，使用临床和虚拟CT/CXR图像，通过卷积神经网络（CNNs）处理。开发并测试了多个AI模型，采用3D ResNet-like和2D EfficientNetv2架构，并在多样化数据集上进行。性能评估指标为AUC和DeLong方法计算AUC置信区间。

**Result:** 在最多样化数据集上训练的模型表现出最高的外部测试性能，CT的AUC为0.73-0.76，CXR为0.70-0.73。内部测试AUC更高（CT：0.77-0.85，CXR：0.77-1.0），突显了外部验证时的性能显著下降，强调了多样化和全面训练及测试数据的重要性。VIT方法提供了对不同模型和数据集效用的客观评估，并深入了解了数据集特性、患者因素和成像物理对AI效能的影响。

**Conclusion:** VIT方法可用于增强模型透明度和可靠性，提供关于驱动AI性能因素的细致见解，并弥合实验与临床环境之间的差距。

> **ai_Abstract:** 本文探讨了虚拟成像试验（VIT）方法在客观评估医学影像AI系统和训练数据方面的效用，以应对AI模型可信度挑战。研究以COVID-19诊断为例，通过CNNs处理临床和虚拟CT/CXR图像，并测试了基于ResNet和EfficientNetv2架构的AI模型。结果表明，训练于多样化数据集的模型表现最佳，且外部验证时性能显著下降，凸显了数据多样性的重要性。VIT方法被证明能够客观评估模型和数据集效用，并揭示了数据集特性、患者因素和成像物理对AI性能的影响，有助于提高模型透明度和可靠性，连接实验与临床应用。

> **摘要翻译:** 医学影像人工智能（AI）模型的可信度仍然是一个挑战，受到模型多样性、用于训练模型的数据以及其组合在生成新数据可复现结果方面的适用性影响。在这项工作中，我们旨在探索新兴的虚拟成像试验（VIT）方法是否能提供客观资源来应对这一挑战。该研究以COVID-19诊断为例进行，使用临床和虚拟计算机断层扫描（CT）和胸部X射线（CXR）图像，并用卷积神经网络（CNNs）进行处理。开发了多个AI模型，采用3D ResNet-like和2D EfficientNetv2架构，并在多样化的数据集上进行了测试。性能差异通过曲线下面积（AUC）和DeLong方法计算AUC置信区间进行评估。在最多样化数据集上训练的模型显示出最高的外部测试性能，CT的AUC值范围为0.73至0.76，CXR为0.70至0.73。内部测试产生了更高的AUC值（CT为0.77至0.85，CXR为0.77至1.0），突显了外部验证时性能的显著下降，这强调了多样化和全面训练及测试数据的重要性。最值得注意的是，VIT方法提供了对不同模型和数据集效用的客观评估，同时进一步深入了解了数据集特性、患者因素和成像物理对AI效能的影响。VIT方法可用于增强模型透明度和可靠性，提供对驱动AI性能因素的细致见解，并弥合实验与临床环境之间的差距。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [309] [Moner: Motion Correction in Undersampled Radial MRI with Unsupervised Neural Representation](https://arxiv.org/abs/2409.16921)
> *Moner：基于无监督神经表示的欠采样径向MRI运动校正*

*Qing Wu, Chenhe Du, Xuanyu Tian, Jingyi Yu, Yuyao Zhang, Hongjiang Wei* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 运动校正, 径向MRI, 无监督学习, 隐式神经表示, 图像重建

**Comment:** Accepted by ICLR 2025 Spotlight

> **TL;DR:** Moner 是一种无需训练数据，利用隐式神经表示对欠采样径向MRI进行运动校正和图像重建的方法，性能与SOTA相当且在域外数据上表现更好。

**AI_Comments:** Moner的创新之处在于其无监督的特性，摆脱了对大规模高质量训练数据的依赖，解决了现有SOTA方法成本高、泛化能力受限的问题。利用隐式神经表示（INR）作为连续先验来解决病态逆问题是其核心创新点。此外，将运动模型整合到INR中、重构反投影问题以及提出的哈希编码策略都增强了方法的鲁棒性和精度。其在域外数据上的出色表现，预示了其在实际临床应用中的巨大潜力，尤其是在数据稀缺或异构场景下。

<details>
  <summary>Details</summary>

**Motivation:** 现有径向MRI运动校正算法依赖大量高质量MR图像进行预训练，这限制了解决方案空间并增加了成本，同时限制了模型的泛化能力。

**Method:** 本文提出了Moner，一种无监督运动校正方法，无需训练数据即可联合重建无伪影MR图像并从欠采样、受刚性运动损坏的k空间数据中估计精确运动。其核心思想是利用隐式神经表示（INR）的连续先验来约束病态逆问题。具体地，将准静态运动模型集成到INR中，并使用傅里叶切片定理将径向MRI重建重新表述为反投影问题以稳定优化。此外，还提出了一种新的从粗到精的哈希编码策略以提高运动校正精度。

**Result:** 在多个MRI数据集上的实验表明，Moner在域内数据上实现了与最先进（SOTA）运动校正技术相当的性能，同时在域外数据上表现出显著改进。

**Conclusion:** Moner提供了一种无需训练数据、高效且泛化能力强的径向MRI运动校正解决方案，尤其在处理域外数据时表现出色。

> **ai_Abstract:** 本文提出了Moner，一种针对欠采样径向MRI的无监督运动校正（MoCo）方法。Moner无需预训练数据，通过结合隐式神经表示（INR）的连续先验、准静态运动模型、傅里叶切片定理以及创新的粗到精哈希编码策略，实现对运动伪影的鲁棒校正和高质量图像重建。实验证明，Moner在域内数据上性能与现有SOTA方法相当，并在域外数据上展现出显著优势。

> **摘要翻译:** 标题：Moner：基于无监督神经表示的欠采样径向MRI运动校正
摘要：径向MRI中的运动校正（MoCo）是一个特别具有挑战性的问题，因为受试者运动的不可预测性。当前最先进（SOTA）的MoCo算法通常依赖于大量的、高质量的MR图像来预训练神经网络，这限制了解决方案空间并导致出色的图像重建结果。然而，对大规模数据集的需求显著增加了成本并限制了模型的泛化能力。在这项工作中，我们提出了Moner，一种无监督的MoCo方法，它无需任何训练数据，即可联合重建无伪影的MR图像并从欠采样、受刚性运动损坏的k空间数据中估计精确运动。我们的核心思想是利用隐式神经表示（INR）的连续先验来约束这个病态的逆问题，从而促进最佳解决方案。具体来说，我们将准静态运动模型集成到INR中，使其能够校正受试者的运动。为了稳定模型优化，我们使用傅里叶切片定理将径向MRI重建重新表述为反投影问题。此外，我们提出了一种新颖的从粗到精的哈希编码策略，显著提高了MoCo的精度。在多个MRI数据集上的实验表明，我们的Moner在域内数据上实现了与SOTA MoCo技术相当的性能，同时在域外数据上表现出显著改进。代码可在以下网址获取：https://github.com/iwuqing/Moner

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [349] [From Real Artifacts to Virtual Reference: A Robust Framework for Translating Endoscopic Images](https://arxiv.org/abs/2410.13896)
> *从真实伪影到虚拟参考：一种内窥镜图像翻译的鲁棒框架*

*Junyang Wu, Fangfang Xie, Jiayuan Sun, Yun Gu, Guang-Zhong Yang* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 领域适应, 内窥镜图像, 图像翻译, 伪影消除, 对比学习

**Comment:** The conclusions of the paper has error. It requires substantial
  re-evaluation, and I plan to resubmit an updated version in the future

> **TL;DR:** 提出了一种鲁棒的图像翻译方法和基准，用于将带有伪影的内窥镜视频与干净的虚拟图像对齐，以解决术中指导中的领域适应问题。

**AI_Comments:** 该论文提出了一种创新的“局部-全局”框架和噪声鲁棒的对比学习策略，有效解决了内窥镜图像中伪影导致的领域适应难题，对于提高术中导航和姿态估计的准确性具有重要意义。其方法的解耦设计和对噪声鲁棒性的强调是其创新点。

<details>
  <summary>Details</summary>

**Motivation:** 现有的领域适应方法受到体内伪影引起的分布偏移的阻碍，需要鲁棒的技术来对齐嘈杂且伪影丰富的患者内窥镜视频与术前断层扫描数据重建的干净虚拟图像，以便在术中指导中进行姿态估计。

**Method:** 提出了一种抗伪影图像翻译方法，包括新颖的“局部-全局”翻译框架（将图像翻译解耦为特征去噪的局部步骤和全局风格迁移的全局步骤）和噪声鲁棒的特征提取策略（提出新的对比学习策略以提取噪声鲁棒特征，建立跨域的鲁棒对应关系）。

**Result:** 在公共和内部临床数据集上的详细验证表明，与现有最先进技术相比，性能显著提高。

**Conclusion:** 该方法有效解决了内窥镜图像翻译中伪影引起的领域适应挑战，显著提高了性能，可用于术中指导。

> **ai_Abstract:** 本文提出一种抗伪影的内窥镜图像翻译方法，旨在解决术中图像中由体内伪影导致的领域适应难题。该方法引入“局部-全局”翻译框架，将图像翻译分解为特征去噪和全局风格迁移两个步骤，并采用新的对比学习策略提取噪声鲁棒特征，以实现噪声内窥镜视频与干净虚拟图像的鲁棒对齐。实验结果显示其性能优于现有技术。

> **摘要翻译:** 领域适应，作为连接不同模态分布的桥梁，在多模态医学图像分析中扮演着至关重要的角色。在内窥镜成像中，结合术前数据与术中成像对于手术规划和导航至关重要。然而，现有的领域适应方法受到体内伪影引起的分布偏移的阻碍，因此需要鲁棒的技术来对齐嘈杂且伪影丰富的患者内窥镜视频与从术前断层扫描数据重建的干净虚拟图像，以便在术中指导中进行姿态估计。本文提出了一种抗伪影的图像翻译方法和为此目的的相关基准。该方法包含一个新颖的“局部-全局”翻译框架和一种噪声鲁棒的特征提取策略。对于前者，它将图像翻译过程解耦为特征去噪的局部步骤和全局风格迁移的全局步骤。对于特征提取，提出了一种新的对比学习策略，可以提取噪声鲁棒的特征，以建立跨域的鲁棒对应关系。在公共和内部临床数据集上进行了详细验证，结果表明与现有最先进技术相比，性能显著提高。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [383] [360-Degree Video Super Resolution and Quality Enhancement Challenge: Methods and Results](https://arxiv.org/abs/2411.06738)
> *360度视频超分辨率与质量增强挑战赛：方法与结果*

*Ahmed Telili, Wassim Hamidouche, Ibrahim Farhat, Hadi Amirpour, Christian Timmerer, Ibrahim Khadraoui, Jiajie Lu, The Van Le, Jeonneung Baek, Jin Young Lee, Yiying Wei, Xiaopeng Sun, Yu Gao, JianCheng Huangl, Yujie Zhong* | **Category: eess.IV** | **Updated: 2025-07-15**

**Keywords:** 360度视频, 超分辨率, 质量增强, 挑战赛, 机器学习

**Comment:** 14 pages, 9 figures

> **TL;DR:** 该论文概述了360度视频超分辨率和质量增强挑战赛，旨在通过机器学习解决方案解决360度视频实时流媒体的带宽和质量问题，并介绍了顶级参赛模型的方法和评估结果。

**AI_Comments:** 该论文通过组织和总结一项挑战赛来推动360度视频领域的创新，这种方式对于解决实际工程问题（如带宽限制和实时性）非常有效。它不仅指出了现有技术的局限性，还通过竞赛激励了新方法的开发，特别是针对360度视频特有的球形几何挑战。这种方法对于加速技术发展和评估不同解决方案的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 全景（360度）视频因虚拟现实（VR）和扩展现实（XR）等沉浸式技术的发展而迅速普及。然而，在无人机（UAV）等实时移动场景中，此类视频的实时流媒体传输面临带宽有限和严格延迟限制的挑战。传统方法虽然有所帮助，但往往会损害视频质量并引入伪影，降低观看体验。此外，360度视频独特的球形几何结构也带来了传统2D视频中未曾遇到的挑战。

**Method:** 为解决上述问题，我们发起了360度视频超分辨率与质量增强挑战赛。该竞赛鼓励参赛者开发高效的机器学习解决方案，以提高低比特率压缩360度视频的质量，其中两个赛道分别侧重于2倍和4倍超分辨率（SR）。本文概述了挑战赛框架，详细介绍了两个竞赛赛道，并重点介绍了表现最佳模型提出的SR解决方案。我们还在统一框架内评估了这些模型，考虑了质量增强、比特率增益和计算效率。

**Result:** 本文概述了挑战赛框架，详细介绍了两个竞赛赛道，并重点介绍了表现最佳模型提出的超分辨率解决方案。这些模型在统一框架内进行了评估，评估指标包括质量增强、比特率增益和计算效率。

**Conclusion:** 本次挑战赛旨在推动实时360度视频流媒体领域的创新，提高沉浸式视觉体验的质量和可访问性。

> **ai_Abstract:** 本文介绍了“360度视频超分辨率与质量增强挑战赛”，旨在解决360度视频在实时流媒体传输中面临的带宽限制和质量下降问题。挑战赛设置了2倍和4倍超分辨率两个赛道，鼓励开发高效的机器学习方案来提升低比特率压缩360度视频的质量。文章详细阐述了挑战赛的框架、赛道设置，并分析了顶级参赛模型的超分辨率解决方案，评估了其在质量增强、比特率增益和计算效率方面的表现，最终目标是推动沉浸式视觉体验的创新和普及。

> **摘要翻译:** 全景（360度）视频因虚拟现实（VR）和扩展现实（XR）等沉浸式技术的进步而迅速普及。然而，在无人机（UAV）等实时移动场景中，此类视频的实时流媒体传输面临带宽有限和严格延迟限制的挑战。传统方法，如压缩和自适应分辨率，虽然有所帮助，但往往会损害视频质量并引入伪影，从而降低观看体验。此外，360度视频独特的球形几何结构带来了传统2D视频中未曾遇到的挑战。为了解决这些问题，我们发起了360度视频超分辨率与质量增强挑战赛。本次竞赛鼓励参赛者开发高效的机器学习解决方案，以提高低比特率压缩360度视频的质量，其中两个赛道分别侧重于2倍和4倍超分辨率（SR）。在本文中，我们概述了挑战赛框架，详细介绍了两个竞赛赛道，并重点介绍了表现最佳模型提出的SR解决方案。我们还在统一框架内评估了这些模型，考虑了质量增强、比特率增益和计算效率。本次挑战赛旨在推动实时360度视频流媒体领域的创新，提高沉浸式视觉体验的质量和可访问性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [419] [Partition Map-Based Fast Block Partitioning for VVC Inter Coding](https://arxiv.org/abs/2504.18398)
> *基于分割图的VVC帧间编码快速块划分*

*Xinmin Feng, Zhuoyuan Li, Li Li, Dong Liu, Feng Wu* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-15**

**Keywords:** VVC, 块划分, 神经网络, 复杂度降低, 帧间编码

**Comment:** 23 pages, 26 figures. Project page: https://github.com/ustcivclab/IPM

> **TL;DR:** 本文提出了一种基于分割图的算法，用于VVC帧间编码的快速块划分，通过引入MTT掩码改进分割图，并开发了一个结合空间和时间特征的神经网络来预测分割图，同时采用双阈值决策方案，显著降低了编码复杂度，同时保持了良好的编码性能。

**AI_Comments:** 本文的创新点在于将分割图方法扩展到VVC帧间编码，并结合了深度学习技术，特别是设计了具有多项特殊结构的神经网络，以精准预测块划分。此外，双阈值决策方案为实际应用中复杂度与性能的权衡提供了灵活性。该研究对于降低VVC编码器的计算负担，推动其在实际场景中的部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** VVC中QT+MTT块结构虽然提供了灵活的块划分模式，但其递归划分搜索大大增加了编码器复杂度。本文旨在解决这一问题，实现快速块划分。

**Method:** 提出了一种基于分割图的快速块划分算法。该算法在先前帧内编码工作的基础上，通过结合MTT掩码改进了分割图，以实现早期终止。接着，开发了一个使用空间和时间特征的神经网络来预测分割图，该网络包含堆叠的自顶向下和自底向上处理、量化参数调制层以及划分自适应扭曲等特殊设计。此外，还提出了一个双阈值决策方案，以在复杂度降低和率失真性能损失之间实现精细的权衡。

**Result:** 该方法在随机访问配置下，实现了平均51.30%的编码时间节省，同时Bjontegaard Delta比特率（BDBR）损失为2.12%。

**Conclusion:** 所提出的基于分割图的快速块划分算法能有效降低VVC帧间编码的复杂度，同时保持可接受的率失真性能，为VVC编码器的实际应用提供了有效的优化方案。

> **ai_Abstract:** 本文针对VVC帧间编码中QT+MTT块结构导致的编码器复杂度过高问题，提出了一种基于分割图的快速块划分算法。该方法通过引入MTT掩码改进了分割图，并设计了一个利用空间和时间特征的神经网络来预测分割图，该网络包含多项创新设计。此外，结合双阈值决策方案，实现了编码复杂度的大幅降低（平均51.30%时间节省），同时仅带来可接受的率失真性能损失（2.12% BDBR）。

> **摘要翻译:** 通用视频编码（VVC）的新技术中，嵌套多类型树（QT+MTT）块结构的四叉树通过提供更灵活的块划分模式，带来了显著的编码增益。然而，VVC编码器中的递归划分搜索大大增加了编码器复杂度。为了解决这个问题，我们提出了一种基于分割图的算法，以实现在帧间编码中的快速块划分。基于我们之前在帧内编码中基于分割图方法的工作，我们分析了VVC帧间编码的特性，并通过结合MTT掩码改进了分割图以实现早期终止。接下来，我们开发了一个神经网络，该网络利用空间和时间特征来预测分割图。它包含一些特殊设计，包括堆叠的自顶向下和自底向上处理、量化参数调制层和划分自适应扭曲。此外，我们提出了一种双阈值决策方案，以在复杂度降低和率失真（RD）性能损失之间实现细粒度权衡。实验结果表明，在随机访问配置下，所提出的方法实现了平均51.30%的编码时间节省，同时Bjontegaard Delta比特率（BDBR）为2.12%。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [455] [petBrain: A New Pipeline for Amyloid, Tau Tangles and Neurodegeneration Quantification Using PET and MRI](https://arxiv.org/abs/2506.03217)
> *petBrain：一种用于PET和MRI淀粉样蛋白、Tau蛋白缠结和神经退行性病变定量的新型流程*

*Pierrick Coupé, Boris Mansencal, Floréal Morandat, Sergio Morell-Ortega, Nicolas Villain, Jose V. Manjón, Vincent Planche* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 淀粉样蛋白, Tau蛋白, 神经退行性病变, PET, MRI, 阿尔茨海默病

**Comment:** 

> **TL;DR:** petBrain是一种基于深度学习的PET/MRI端到端管道，用于快速可靠地量化阿尔茨海默病相关的淀粉样蛋白、Tau蛋白和神经退行性病变。

**AI_Comments:** petBrain的创新之处在于其端到端的集成、深度学习的应用以及作为Web平台的开放可访问性，这极大地降低了AD生物标志物量化分析的技术门槛和计算负担，有助于加速临床研究和诊断应用。其与现有金标准和临床指标的良好一致性也证明了其可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 当前用于阿尔茨海默病诊断和预后中，使用PET和MRI量化淀粉样蛋白斑块、神经原纤维缠结和神经退行性病变的方法，面临处理时间长、示踪剂类型变异性大以及多模态整合困难等限制。

**Method:** 本文开发了petBrain，一个用于淀粉样蛋白PET、tau蛋白PET和结构MRI的端到端处理流程。该流程利用基于深度学习的分割、标准化生物标志物定量（Centiloid、CenTauR、HAVAs），并能同时估算淀粉样蛋白、Tau蛋白缠结和神经退行性病变生物标志物。petBrain被实现为一个基于网络的平台，无需本地计算基础设施或专业软件知识。

**Result:** petBrain提供了可靠且快速的生物标志物定量，其淀粉样蛋白和Tau蛋白缠结的结果与现有流程相当。它与ADNI数据库中处理的数据表现出高度一致性。petBrain对淀粉样蛋白/Tau蛋白缠结/神经退行性病变的分期和定量与脑脊液/血浆生物标志物、临床状态和认知表现显示出良好的一致性。

**Conclusion:** petBrain代表了一个强大且开放的标准化阿尔茨海默病生物标志物分析平台，有助于临床研究应用。

> **ai_Abstract:** 本文介绍了petBrain，一个新颖的端到端处理流程，旨在利用PET和MRI图像对阿尔茨海默病相关的淀粉样蛋白斑块、tau蛋白缠结和神经退行性病变进行快速可靠的定量分析。该平台结合了深度学习分割和标准化生物标志物量化方法，并作为一个无需本地安装的web平台提供。实验结果表明，petBrain的定量结果与现有流程和ADNI数据具有可比性及高度一致性，并且其对A/T2/N的分期和定量与临床生物标志物和认知表现良好吻合，为AD生物标志物分析提供了一个强大的标准化工具。

> **摘要翻译:** 引言：使用PET和MRI对淀粉样蛋白斑块（A）、神经原纤维缠结（T2）和神经退行性病变（N）进行定量对于阿尔茨海默病（AD）的诊断和预后至关重要。现有流程面临处理时间、示踪剂类型变异性以及多模态整合方面的限制。
方法：我们开发了petBrain，这是一个用于淀粉样蛋白PET、tau蛋白PET和结构MRI的新型端到端处理流程。它利用基于深度学习的分割、标准化生物标志物定量（Centiloid、CenTauR、HAVAs）以及同时估算A、T2和N生物标志物。该流程被实现为一个基于网络的平台，无需本地计算基础设施或专业软件知识。
结果：petBrain提供了可靠且快速的生物标志物定量，其A和T2的结果与现有流程相当。它与ADNI数据库中处理的数据表现出高度一致性。petBrain对A/T2/N的分期和定量与脑脊液/血浆生物标志物、临床状态和认知表现显示出良好的一致性。
讨论：petBrain代表了一个强大且开放的标准化AD生物标志物分析平台，有助于临床研究应用。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [497] [Comparative Analysis of Vision Transformers and Traditional Deep Learning Approaches for Automated Pneumonia Detection in Chest X-Rays](https://arxiv.org/abs/2507.10589)
> *视觉Transformer与传统深度学习方法在胸部X光片自动肺炎检测中的比较分析*

*Gaurav Singh* | **Category: eess.IV, cs.AI, cs.CV, cs.NE** | **Updated: 2025-07-11**

**Keywords:** 肺炎检测, 视觉Transformer, 胸部X光, 深度学习, Cross-ViT

**Comment:** 

> **TL;DR:** 本研究比较了视觉Transformer和传统深度学习方法在胸部X光片自动肺炎检测中的表现，发现视觉Transformer（尤其是Cross-ViT）表现更优，具有高准确性和召回率，有望加速肺炎诊断。

**AI_Comments:** 该论文创新性地将视觉Transformer应用于肺炎检测，并与传统深度学习方法进行了全面比较，为医疗影像诊断领域引入了前沿技术。其重要性在于证明了ViT在医学图像分析上的优越性，特别是在高召回率方面，这对于疾病筛查至关重要。研究还关注了实际应用中的计算效率和模型选择，为未来研究提供了宝贵见解。

<details>
  <summary>Details</summary>

**Motivation:** 肺炎，特别是COVID-19引起的肺炎，是全球性的健康挑战，需要快速准确的诊断。

**Method:** 本研究评估了多种方法，包括传统机器学习技术（基于PCA的聚类、逻辑回归、支持向量分类）和先进的深度学习架构，包括卷积神经网络（改进的LeNet、DenseNet-121）和多种视觉Transformer（Deep-ViT、Compact Convolutional Transformer和Cross-ViT）。使用了包含5,856张儿科胸部X光图像的数据集进行评估。

**Result:** 研究表明，视觉Transformer，特别是Cross-ViT架构，表现优异，准确率达到88.25%，召回率达到99.42%，超过了传统的CNN方法。分析还发现，架构选择对性能的影响比模型大小更显著，Cross-ViT（75M参数）的表现优于更大的模型。研究还考虑了计算效率、训练要求以及医学诊断中精确度和召回率之间的关键平衡。

**Conclusion:** 研究结果表明，视觉Transformer为自动化肺炎检测提供了有前景的方向，可能在健康危机期间实现更快速和准确的诊断。

> **ai_Abstract:** 本研究旨在比较视觉Transformer（ViT）与传统深度学习及机器学习方法在胸部X光片自动肺炎检测中的性能。研究评估了多种模型，包括传统ML、CNN（如DenseNet-121）和多种ViT变体（如Cross-ViT）。结果显示，在儿科胸部X光数据集上，Cross-ViT取得了最佳性能，准确率达88.25%，召回率达99.42%，优于传统CNN。研究强调了架构选择的重要性，并指出ViT在医疗诊断领域，尤其是在肺炎快速检测方面，具有巨大潜力。

> **摘要翻译:** 肺炎，特别是由COVID-19等疾病引起的肺炎，仍然是一个关键的全球健康挑战，需要快速准确的诊断。本研究对使用胸部X光片（CXR）进行自动化肺炎检测的传统机器学习和最先进的深度学习方法进行了全面比较。我们评估了多种方法，从传统的机器学习技术（基于PCA的聚类、逻辑回归和支持向量分类）到先进的深度学习架构，包括卷积神经网络（改进的LeNet、DenseNet-121）和各种视觉Transformer（ViT）实现（Deep-ViT、Compact Convolutional Transformer和Cross-ViT）。使用包含5,856张儿科胸部X光图像的数据集，我们证明了视觉Transformer，特别是Cross-ViT架构，以88.25%的准确率和99.42%的召回率取得了卓越的性能，超越了传统的CNN方法。我们的分析表明，架构选择对性能的影响比模型大小更显著，Cross-ViT的75M参数表现优于更大的模型。该研究还探讨了实际考虑因素，包括计算效率、训练要求以及医学诊断中精确度和召回率之间的关键平衡。我们的研究结果表明，视觉Transformer为自动化肺炎检测提供了有前景的方向，可能在健康危机期间实现更快速和准确的诊断。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [508] [IM-LUT: Interpolation Mixing Look-Up Tables for Image Super-Resolution](https://arxiv.org/abs/2507.09923)
> *IM-LUT：用于图像超分辨率的插值混合查找表*

*Sejin Park, Sangmin Lee, Kyong Hwan Jin, Seung-Won Jung* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 图像超分辨率, 查找表, 任意尺度超分辨率, 插值混合, IM-LUT

**Comment:** ICCV 2025

> **TL;DR:** IM-LUT通过混合插值函数实现任意尺度超分辨率，同时保持高效和高质量。

**AI_Comments:** IM-LUT的创新在于将查找表（LUT）的效率优势与插值函数的混合能力相结合，解决了传统LUT方法固定尺度和现有ASISR方法计算成本高的问题。通过将IM-Net转换为IM-LUT，实现了在CPU上的轻量级和快速推理，这对于资源受限的应用尤其重要，是其主要亮点。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于查找表（LUT）的超分辨率方法通常只适用于固定尺度因子，不适合任意尺度图像超分辨率（ASISR）。而现有处理ASISR的技术（如隐式神经表示）计算成本和内存需求高。

**Method:** 提出IM-LUT框架，通过学习混合多个插值函数来实现任意尺度图像超分辨率（ASISR）。具体引入IM-Net，一个根据局部图像模式和目标尺度因子预测插值函数混合权重的网络。为提高效率，IM-Net被转换为IM-LUT，其中查找表（LUT）用于替代计算密集型操作，从而在CPU上实现轻量级和快速推理。

**Result:** 在多个基准数据集上的实验结果表明，IM-LUT在图像质量和效率之间始终取得了优于现有方法的平衡。

**Conclusion:** IM-LUT是一种有前景的解决方案，尤其适用于资源受限的应用，因为它在图像质量和效率之间达到了卓越的平衡。

> **ai_Abstract:** 本文提出IM-LUT，一个用于任意尺度图像超分辨率（ASISR）的新颖框架。它通过学习混合多个插值函数来提高表示能力，并引入IM-Net预测混合权重。为实现高效推理，IM-Net被转换为IM-LUT，利用查找表替代复杂计算，从而在CPU上实现轻量级和快速操作，同时保持高质量的图像重建。实验证明IM-LUT在图像质量和效率之间取得了优异的平衡，优于现有方法，特别适用于资源受限环境。

> **摘要翻译:** 超分辨率 (SR) 一直是图像处理中的一项关键任务，旨在提高各种应用中的图像分辨率。最近，基于查找表 (LUT) 的方法因其效率和性能而受到关注。然而，这些方法通常设计用于固定尺度因子，使其不适用于任意尺度图像超分辨率 (ASISR)。现有的ASISR技术通常采用隐式神经表示，这带来了相当大的计算成本和内存需求。为了解决这些限制，我们提出了插值混合查找表 (IM-LUT)，这是一种新颖的框架，通过学习混合多个插值函数以最大限度地提高其表示能力来实现ASISR。具体来说，我们引入了IM-Net，这是一个根据局部图像模式和目标尺度因子预测插值函数混合权重的网络。为了提高基于插值方法的效率，IM-Net被转换为IM-LUT，其中查找表用于替代计算昂贵的操作，从而在保持重建质量的同时，在CPU上实现轻量级和快速推理。在多个基准数据集上的实验结果表明，与现有方法相比，IM-LUT在图像质量和效率之间始终取得了卓越的平衡，突显了其作为资源受限应用有前途解决方案的潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [545] [Graph-based Multi-Modal Interaction Lightweight Network for Brain Tumor Segmentation (GMLN-BTS) in Edge Iterative MRI Lesion Localization System (EdgeIMLocSys)](https://arxiv.org/abs/2507.09995)
> *基于图的多模态交互轻量级脑肿瘤分割网络（GMLN-BTS）在边缘迭代MRI病灶定位系统（EdgeIMLocSys）中的应用*

*Guohao Huo, Ruiting Dai, Hao Tang* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 脑肿瘤分割, 轻量级网络, 多模态交互, 图神经网络, 边缘计算

**Comment:** 

> **TL;DR:** 该论文提出了一个轻量级的脑肿瘤分割网络GMLN-BTS，集成到边缘迭代MRI病灶定位系统EdgeIMLocSys中，通过结合多模态交互和自适应学习，在保持高精度的同时大幅减少了模型参数，适用于资源受限的临床环境。

**AI_Comments:** 该论文的创新点在于提出了一个轻量级的脑肿瘤分割网络GMLN-BTS，并将其集成到考虑临床反馈的EdgeIMLocSys系统中。其核心创新在于结合了模态感知编码、基于图的多模态交互以及新型上采样模块，在大幅减少模型参数量的同时（98%），依然能保持高精度，这对于资源受限的边缘临床部署具有重要意义。模型的轻量化和高效率是其主要亮点。

<details>
  <summary>Details</summary>

**Motivation:** 脑肿瘤分割在临床诊断和治疗规划中至关重要，但不同MRI扫描仪的成像质量差异导致模型泛化性面临挑战。

**Method:** 本文提出了边缘迭代MRI病灶定位系统（EdgeIMLocSys），通过人类反馈的持续学习来自适应微调分割模型。系统核心是基于图的多模态交互轻量级脑肿瘤分割网络（GMLN-BTS），其包含：1. 模态感知自适应编码器（M2AE），用于高效提取多尺度语义特征。2. 基于图的多模态协作交互模块（G2MCIM），通过图结构建模互补的跨模态关系。3. 新颖的体素细化上采样模块（VRUM），结合线性插值和多尺度转置卷积，抑制伪影同时保留高频细节，提高分割边界精度。

**Result:** GMLN-BTS模型在BraTS2017数据集上实现了85.1%的Dice分数，参数量仅为458万，比主流3D Transformer模型减少了98%，并且显著优于现有轻量级方法。

**Conclusion:** 这项工作展示了在实现高精度、资源高效的脑肿瘤分割方面的协同突破，适用于在资源受限的临床环境中部署。

> **ai_Abstract:** 本论文提出了EdgeIMLocSys系统，其中包含GMLN-BTS，一个基于图的多模态交互轻量级脑肿瘤分割网络。该网络通过M2AE提取多尺度特征，G2MCIM建模跨模态关系，以及VRUM提升分割精度和细节保留。GMLN-BTS在BraTS2017数据集上取得了85.1%的Dice分数，且模型参数量大幅减少，显示出其在资源受限临床环境中进行高精度、资源高效脑肿瘤分割的潜力。

> **摘要翻译:** 脑肿瘤分割在临床诊断和治疗规划中起着关键作用，然而不同MRI扫描仪的成像质量差异对模型泛化性提出了重大挑战。为了解决这个问题，我们提出了边缘迭代MRI病灶定位系统（EdgeIMLocSys），它集成了人类反馈的持续学习，以根据临床医生的反馈自适应地微调分割模型，从而增强对扫描仪特定成像特征的鲁棒性。该系统的核心是基于图的多模态交互轻量级脑肿瘤分割网络（GMLN-BTS），它采用模态感知自适应编码器（M2AE）来高效提取多尺度语义特征，并采用基于图的多模态协作交互模块（G2MCIM）通过图结构建模互补的跨模态关系。此外，我们引入了一种新颖的体素细化上采样模块（VRUM），它协同结合线性插值和多尺度转置卷积，以抑制伪影同时保留高频细节，提高分割边界精度。我们提出的GMLN-BTS模型在BraTS2017数据集上实现了85.1%的Dice分数，参数量仅为458万，与主流3D Transformer模型相比减少了98%，并且显著优于现有轻量级方法。这项工作展示了在实现高精度、资源高效的脑肿瘤分割方面的协同突破，适用于在资源受限的临床环境中部署。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [677] [A Survey on Medical Image Compression: From Traditional to Learning-Based](https://arxiv.org/abs/2507.10615)
> *医学图像压缩综述：从传统方法到基于学习的方法*

*Guofeng Tong, Sixuan Liu, Yang Lv, Hanyu Pei, Feng-Lei Fan* | **Category: eess.IV** | **Updated: 2025-07-13**

**Keywords:** 医学图像压缩, 传统方法, 深度学习, 图像处理, 综述

**Comment:** 

> **TL;DR:** 本综述探讨了医学图像压缩的挑战、传统方法和基于深度学习的方法，并根据数据结构和技术方法进行了分类，展望了未来方向。

**AI_Comments:** 这篇综述论文的重要性在于其对医学图像压缩领域的全面梳理和系统分类。它不仅清晰地阐明了医学图像压缩的独特挑战和需求，还对比了传统方法和新兴的深度学习方法的优缺点，为研究人员提供了宝贵的参考。其提出的双面分类法有助于理解该领域的技术演进和现状。

<details>
  <summary>Details</summary>

**Motivation:** 医学成像数据的指数级增长给医疗系统带来了数据存储、传输和管理方面的巨大挑战，因此高效的医学图像压缩变得日益重要。与自然图像不同，医学图像压缩优先考虑保留诊断细节和结构完整性，并要求快速、内存高效的算法。

**Method:** 本综述基于数据结构（2D vs 3D/4D）和技术方法（传统 vs 基于学习）建立了双面分类法，系统地介绍了医学图像压缩的技术演变，分析了独特的技术挑战，并展望了未来的发展方向。

**Result:** 本综述全面回顾了医学图像压缩领域，涵盖了传统方法和基于学习的方法，并根据数据维度和技术范式进行了分类，揭示了不同模态的特殊要求以及不同方法的优缺点。

**Conclusion:** 医学图像压缩需要平衡计算复杂性与临床可接受的重建质量，并处理不同模态的特定要求。传统方法提供坚实基础，而深度学习方法展现出强大的自适应学习能力。未来研究方向包括解决独特的技术挑战和探索新的压缩策略。

> **ai_Abstract:** 本综述全面探讨了医学图像压缩领域，强调了其在应对医疗数据爆炸式增长中的重要性。文章首先指出医学图像压缩与自然图像压缩的区别，即需要严格保留诊断细节和结构完整性，并适应多种模态（2D、3D/4D动态图像）的不同要求。文章对比了基于数学变换和信息论的传统方法与基于深度学习的新兴方法，指出前者具有理论基础和标准化优势，后者则展现出强大的自适应学习能力。最后，本综述基于数据结构和技术方法构建了一个双重分类体系，系统地梳理了技术演变，分析了现有挑战，并展望了未来研究方向。

> **摘要翻译:** 医学成像的指数级增长给医疗系统的存储、传输和管理带来了巨大的数据挑战。在这种情况下，高效压缩变得越来越重要。与自然图像压缩不同，医学图像压缩优先考虑保留诊断细节和结构完整性，对质量提出更严格的要求，并需要快速、内存高效的算法，以平衡计算复杂性与临床可接受的重建质量。同时，医学成像家族包含多种模态，每种模态都有不同的要求。例如，2D医学图像（如X射线、组织病理学图像）压缩侧重于利用切片内空间冗余，而体积医学图像则需要处理切片内和切片间空间相关性，4D动态成像（如时间序列CT/MRI、4D超声）则额外需要处理连续时间帧之间的时间相关性。基于数学变换和信息论原理的传统压缩方法提供了坚实的理论基础、可预测的性能和高标准化水平，并在临床环境中得到了广泛验证。相比之下，基于深度学习的方法展示出卓越的自适应学习能力，能够捕获医学图像中复杂的统计特征和语义信息。这项全面的综述基于数据结构（2D vs 3D/4D）和技术方法（传统 vs 基于学习）建立了双面分类法，从而系统地呈现了完整的技术演变，分析了独特的技术挑战，并展望了医学图像压缩的未来方向。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [726] [Focus on Texture: Rethinking Pre-training in Masked Autoencoders for Medical Image Classification](https://arxiv.org/abs/2507.10869)
> *聚焦纹理：重新思考医用图像分类中掩码自编码器的预训练*

*Chetan Madan, Aarjav Satia, Soumen Basu, Pankaj Gupta, Usha Dutta, Chetan Arora* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 掩码自编码器, 灰度共生矩阵, 医学图像分类, 自监督学习, 纹理特征

**Comment:** To appear at MICCAI 2025

> **TL;DR:** 传统的掩码自编码器（MAE）在自然图像处理中表现良好，但在医学图像中因纹理信息的重要性而失效。本文提出了一种基于灰度共生矩阵（GLCM）的GLCM-MAE预训练框架，通过匹配GLCM作为损失函数来保留形态特征，并在多个医学图像分类任务中取得了优于现有SOTA的性能。

**AI_Comments:** 本文的创新点在于将灰度共生矩阵（GLCM）的概念引入到掩码自编码器（MAE）的损失函数设计中，以解决传统MAE在医学图像中对纹理信息保留不足的问题。这一方法有效地弥补了像素级MSE损失的局限性，特别适用于纹理特征至关重要的医学图像分析。其在多个医学任务上的性能提升证明了该方法的有效性和重要性，为医学图像的自监督学习提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 传统的掩码自编码器（MAE）在自然图像中通过像素级均方误差（MSE）重建掩码图像，但这种方法倾向于产生模糊的图像重建。尽管这在保留自然图像主导边缘方面有效，但在医学图像中，纹理线索对视觉异常的分类更为关键，传统的MAE策略因此失效。

**Method:** 受放射组学研究中灰度共生矩阵（GLCM）特征的启发，本文提出了一种新颖的基于MAE的预训练框架GLCM-MAE。该框架使用基于匹配GLCM的重建损失，以捕获图像的强度和空间关系，从而帮助保留形态特征。此外，文章还提出了一种新颖的公式，将匹配的GLCM矩阵转换为可微分的损失函数。

**Result:** GLCM-MAE在医学图像下游任务中改善了表示学习。它在四个任务中超越了现有最先进的技术：胆囊癌检测（超声图像）提升2.1%，乳腺癌检测（超声图像）提升3.1%，肺炎检测（X射线）提升0.5%，COVID检测（CT）提升0.6%。

**Conclusion:** 提出的GLCM-MAE框架通过引入基于GLCM的重建损失，有效解决了传统MAE在医学图像纹理信息保留方面的不足，并在多项医学图像分类任务中展现出优越的性能，证明了其在医学图像自监督学习中的潜力。

> **ai_Abstract:** 本文针对传统掩码自编码器（MAE）在医学图像处理中因纹理信息丢失而失效的问题，提出了一种名为GLCM-MAE的新型预训练框架。该框架借鉴灰度共生矩阵（GLCM）的理念，设计了一种基于GLCM匹配的重建损失函数，旨在更好地保留医学图像中对诊断至关重要的形态和纹理特征。实验证明，GLCM-MAE在多个医学图像分类任务中均显著优于现有最先进的方法。

> **摘要翻译:** 掩码自编码器（MAEs）已成为自然图像自监督表示学习中的主导策略，其中模型通过像素级均方误差（MSE）作为损失，重建掩码图像的原始和重建RGB值。我们观察到MSE鼓励模糊的图像重建，但对自然图像仍然有效，因为它保留了主要的边缘。然而，在医学成像中，当纹理线索对于视觉异常的分类更为重要时，这种策略就会失败。受放射组学研究中灰度共生矩阵（GLCM）特征的启发，我们提出了一种新颖的基于MAE的预训练框架GLCM-MAE，使用基于匹配GLCM的重建损失。GLCM捕获图像中的强度和空间关系，因此所提出的损失有助于保留形态特征。此外，我们提出了一种新颖的公式，将匹配的GLCM矩阵转换为可微分的损失函数。我们证明了在医学图像上使用所提出的GLCM损失进行无监督预训练可以改善下游任务的表示。GLCM-MAE在四项任务中超越了当前最先进的技术——胆囊癌超声图像检测提高了2.1%，乳腺癌超声图像检测提高了3.1%，X射线肺炎检测提高了0.5%，CT COVID检测提高了0.6%。源代码和预训练模型可在：https://github.com/ChetanMadan/GLCM-MAE 获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [775] [Real-Time Foreign Object Recognition Based on Improved Wavelet Scattering Deep Network and Edge Computing](https://arxiv.org/abs/2507.11043)
> *基于改进小波散射深度网络和边缘计算的实时异物识别*

*He Zhichao, Shen Xiangyu, Zhang Yong, Xie Nan* | **Category: eess.IV** | **Updated: 2025-07-15**

**Keywords:** 异物识别, 小波散射网络, 边缘计算, 无人机, 轻量级模型

**Comment:** 

> **TL;DR:** 本文提出了一种基于改进小波散射深度网络的轻量级模型，用于在边缘设备上实时识别无人机捕获的异物，解决了计算能力有限的问题，并实现了高精度和低推理时间。

**AI_Comments:** 该论文的创新点在于提出了改进的小波散射深度网络作为轻量级模型，有效解决了边缘设备上实时异物识别的计算限制。其重要性体现在为无人机巡检提供了高效、实时的异物识别解决方案，有助于提升电力系统运维效率和安全性。模型的推理速度和精度在边缘设备上表现优异，具有较强的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 随着新能源在电力系统中的渗透率不断提高，对变电站和输电线路的运行维护提出了更高要求。使用无人机实时识别异物可以快速有效地消除潜在安全隐患。然而，由于边缘设备计算能力有限，捕获的图像无法在本地实时处理。

**Method:** 本文提出了一种基于改进小波散射深度网络的轻量级模型。该模型包含改进的小波散射网络，用于提取图像单通道的散射系数和模量系数，取代了卷积神经网络中卷积层和池化层的作用。随后的3个全连接层（构成简化的多层感知机）用于对提取的特征进行分类。

**Result:** 实验证明，使用双正交小波基构建的模型能够在树莓派和Jetson Nano等边缘设备上识别和分类异物，对720P图像的识别精度高于90%，推理时间小于7毫秒。进一步的实验表明，该模型的识别精度比YOLOv5s高1.1%，比YOLOv8s高0.3%。

**Conclusion:** 本文提出的基于改进小波散射深度网络的轻量级模型，能够有效解决边缘设备上实时异物识别的计算限制问题，并在精度和推理时间上表现出色，优于现有的一些主流模型。

> **ai_Abstract:** 本文针对无人机在电力系统异物识别中边缘设备计算能力受限的问题，提出了一种基于改进小波散射深度网络的轻量级模型。该模型利用小波散射网络提取图像特征，并结合简化的多层感知机进行分类。实验证明，该模型能在树莓派和Jetson Nano等边缘设备上实现高精度（>90%）和低推理时间（<7ms）的异物识别，且识别精度优于YOLOv5s和YOLOv8s。

> **摘要翻译:** 电力系统中新能源渗透率的不断提高，对变电站和输电线路的运行维护提出了更高的要求。利用无人机（UAV）实时识别异物可以快速有效地消除潜在的安全隐患。然而，由于计算能力有限，捕获的图像无法在无人机上的边缘设备本地进行实时处理。为了克服这个问题，本文提出了一种基于改进小波散射深度网络的轻量级模型。该模型包含改进的小波散射网络，用于提取图像单通道的散射系数和模量系数，取代了卷积神经网络中卷积层和池化层的作用。随后的3个全连接层，也构成了一个简化的多层感知机（MLP），用于对提取的特征进行分类。实验证明，使用双正交小波基构建的模型能够在树莓派和Jetson Nano等边缘设备上识别和分类异物，对于720P（1280*720）图像，精度高于90%，推理时间小于7毫秒。进一步的实验表明，我们模型的识别精度比YOLOv5s高1.1%，比YOLOv8s高0.3%。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [15] [Standardized Evaluation of Fetal Phonocardiography Processing Methods](https://arxiv.org/abs/2507.10783)
> *胎儿心音图处理方法的标准化评估*

*Kristóf Müller, Janka Hatvani, Márton Áron Goda, Miklós Koller* | **Category: eess.AS** | **Updated: 2025-07-14**

**Keywords:** 胎儿心音图, 心音检测, 心率估算, 标准化评估, 基准测试

**Comment:** 17 pages, 7 figures, 7 tables

> **TL;DR:** 该研究标准化评估了现有胎儿心音检测和心率估算方法，发现没有一种方法在所有测试中都表现最佳，且简单方法可能与复杂方法相当，强调需要进一步标准化评估。

**AI_Comments:** 这篇论文的创新点在于首次对胎儿心音图处理方法进行了标准化评估，解决了以往评估中缺乏公平比较的问题。其重要性在于揭示了现有方法的局限性，并明确指出未来研究需要关注评估的标准化，这对于推动该领域的发展具有指导意义。公开测试和算法实现也促进了研究的透明度和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 胎儿心音图可以获取胎儿心率和心音数据，且是完全被动、无辐射的方法。该研究旨在讨论并比较现有胎儿心音检测和心率估算方法。

**Method:** 研究讨论了现有胎儿心音检测和心率估算方法，并使用一个通用基准平台和预选测试数据集进行标准化比较。测试包括基于容忍度的检测准确性、标签插入、删除和替换的错误率，以及心率均方误差的统计测量。

**Result:** 没有一种方法能在所有测试中都取得最高分，简单方法可能与复杂方法表现相当。第一心音检测的最佳模型达到了97.6%的F1分数，97.4%的阳性预测值和12.2±8.0毫秒的平均绝对误差。第二心音检测的最佳模型达到了91.4%的F1分数，91.3%的阳性预测值和17.3±12.2毫秒的平均绝对误差。胎儿心率的最佳方法达到了0.644的均方误差。

**Conclusion:** 胎儿心率和心音检测方法的评估需要进一步标准化。

> **ai_Abstract:** 这篇论文对现有的胎儿心音图处理方法进行了标准化评估，包括心音检测和心率估算。通过通用基准平台和预选数据集的比较，研究发现没有单一的最佳方法，且简单方法也能与复杂方法媲美。论文强调了在胎儿心率和心音检测方法评估中进一步标准化的必要性。

> **摘要翻译:** 动机。心音图可以获取胎儿心率以及直接的心音数据，并且是完全被动的，不使用任何形式的辐射。
方法。我们讨论了当前可用的胎儿心音检测和心率估算方法，并使用一个通用基准平台和预选测试数据集对它们进行了比较。与之前的综述相比，我们以标准化的方式评估了所讨论的方法，以实现公平的比较。我们的测试包括基于容忍度的检测准确性、标签插入、删除和替换的错误率，以及心率均方误差的统计测量。
结果。根据我们的结果，没有一种明确的最佳方法可以在所有测试中都取得最高分，并且简单的方法可能与更复杂的方法表现相当。第一心音检测的最佳模型达到了97.6%的F1分数，97.4%的阳性预测值，以及12.2±8.0毫秒的平均绝对误差。在第二心音检测方面，最佳模型的F1分数为91.4%，阳性预测值为91.3%，平均绝对误差为17.3±12.2毫秒。对于胎儿心率，最佳方法实现了0.644的均方误差。
意义。我们的主要结论是，胎儿心率和心音检测方法的评估需要进一步标准化。测试和算法实现已在以下网址公开：https://github.com/mulkr/standard-fpcg-evaluation。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [51] [Array-Aware Ambisonics and HRTF Encoding for Binaural Reproduction With Wearable Arrays](https://arxiv.org/abs/2507.11091)
> *阵列感知型Ambisonics和HRTF编码用于可穿戴阵列的双耳重放*

*Yhonatan Gayer, Vladimir Tourbabin, Zamir Ben Hur, David Lou Alon, Boaz Rafaely* | **Category: eess.AS, eess.SP** | **Updated: 2025-07-15**

**Keywords:** Ambisonics, HRTF, 双耳重放, 可穿戴阵列, 空间音频

**Comment:** 

> **TL;DR:** 一种新的阵列感知型Ambisonics编码与HRTF预处理方法，可提高可穿戴阵列的双耳空间音频精度和感知质量。

**AI_Comments:** 该论文提出了一种创新的方法，将麦克风阵列的特定信息融入到HRTF处理中，解决了传统Ambisonics编码在可穿戴设备上可能存在的空间精度问题。其创新点在于“阵列感知”的优化策略，显著提升了双耳渲染的客观性能和主观感知质量，对于VR/AR和可穿戴音频领域具有重要应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 提高从任意麦克风阵列进行双耳重放的空间精度和感知质量。

**Method:** 本文引入了一种新颖的方法，通过头部相关传输函数（HRTF）预处理，对Ambisonics编码进行阵列感知优化。该方法将阵列特定信息整合到HRTF处理流程中。

**Result:** 客观评估表明，在模拟可穿戴阵列和头部旋转条件下，该方法与传统Ambisonics编码方法相比性能更优。听力实验进一步证实，该方法在音色和空间质量方面获得了显著更高的感知评级。

**Conclusion:** 所提出的方法与标准Ambisonics完全兼容，为虚拟现实、增强现实和可穿戴音频捕获等应用中的空间音频渲染提供了一种实用的解决方案。

> **ai_Abstract:** 本文提出了一种创新的阵列感知型Ambisonics编码方法，通过HRTF预处理实现从任意麦克风阵列进行高质量双耳重放。该方法将阵列特定信息融入HRTF处理流程，显著提升了双耳渲染的空间精度。客观评估和听力实验均证实，其在模拟旋转和感知质量（音色与空间感）方面优于传统方法。该方案与标准Ambisonics兼容，为VR/AR和可穿戴音频捕获提供了实用的空间音频渲染解决方案。

> **摘要翻译:** 这项工作介绍了一种新颖的方法，用于从任意麦克风阵列进行双耳重放，该方法基于通过头部相关传输函数（HRTF）预处理对Ambisonics编码进行阵列感知优化。所提出的方法将阵列特定信息整合到HRTF处理流程中，从而提高了双耳渲染中的空间精度。客观评估表明，在模拟可穿戴阵列和头部旋转条件下，与传统Ambisonics编码方法相比，其性能更优。一项听力实验进一步证实，该方法在音色和空间质量方面均获得了显著更高的感知评级。所提出的方法与标准Ambisonics完全兼容，为虚拟现实、增强现实和可穿戴音频捕获等应用中的空间音频渲染提供了一种实用的解决方案。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [63] [Physics-Informed Transfer Learning for Data-Driven Sound Source Reconstruction in Near-Field Acoustic Holography](https://arxiv.org/abs/2507.11070)
> *近场声全息中数据驱动声源重建的物理信息迁移学习*

*Xinmeng Luan, Mirco Pezzoli, Fabio Antonacci, Augusto Sarti* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-15**

**Keywords:** 迁移学习, 近场声全息, 声源重建, 物理信息, 深度学习

**Comment:** to appear in IEEE WASPAA 2025

> **TL;DR:** 本文提出了一种结合物理信息的迁移学习框架，用于近场声全息中的声源重建，通过两阶段方法提高了不同声源类型间的重建精度。

**AI_Comments:** 该论文的创新之处在于将物理信息引入到迁移学习框架中，以解决数据驱动模型在不同声源类型之间泛化能力不足的问题。这种结合物理知识的深度学习方法，在数据量有限或新场景适应性方面具有重要意义，能够提高模型的鲁棒性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 在近场声全息(NAH)中，需要将一个训练好的数据驱动模型从一种声源类型适应到另一种声源类型，以实现更好的泛化能力和重建精度。

**Method:** 该框架包括两个阶段：(1) 在大型数据集上对复值卷积神经网络（CV-CNN）进行监督预训练；(2) 基于基尔霍夫-亥姆霍兹积分，对单个数据样本进行纯物理信息微调。

**Result:** 通过将预训练模型从矩形板数据集迁移到小提琴面板数据集，该方法显示出比预训练模型更高的重建精度，并与压缩等效源法（C-ESM）性能相当。对于成功模式，微调模型在精度上优于预训练模型和C-ESM。

**Conclusion:** 所提出的物理信息迁移学习框架能够有效提高近场声全息中数据驱动声源重建的泛化能力和精度，尤其在不同声源类型之间进行迁移时表现出色。

> **ai_Abstract:** 本文提出了一种用于近场声全息（NAH）中声源重建的物理信息迁移学习框架。该框架分为两阶段：首先对复值卷积神经网络（CV-CNN）进行监督预训练，然后基于物理原理（基尔霍夫-亥姆霍兹积分）对单个样本进行微调。该方法通过将模型从矩形板数据迁移到小提琴面板数据，验证了其在不同声源类型间提高重建精度和泛化能力的能力，并能达到或超越现有方法的性能。

> **摘要翻译:** 我们提出了一种用于近场声全息（NAH）中声源重建的迁移学习框架，该框架通过物理信息过程，将一个训练有素的数据驱动模型从一种声源类型适应到另一种声源类型。该框架包括两个阶段：（1）在大型数据集上对复值卷积神经网络（CV-CNN）进行监督预训练，以及（2）基于基尔霍夫-亥姆霍兹积分，对单个数据样本进行纯物理信息微调。该方法遵循迁移学习的原则，通过物理信息适应，实现了跨不同数据集的泛化。通过将预训练模型从矩形板数据集迁移到小提琴面板数据集，验证了该方法的有效性，结果显示其重建精度比预训练模型有所提高，并提供了与压缩等效源法（C-ESM）相当的性能。此外，对于成功模式，微调模型在精度上优于预训练模型和C-ESM。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [111] [P.808 Multilingual Speech Enhancement Testing: Approach and Results of URGENT 2025 Challenge](https://arxiv.org/abs/2507.11306)
> *P.808 多语言语音增强测试：URGENT 2025 挑战赛的方法与结果*

*Marvin Sach, Yihui Fu, Kohei Saijo, Wangyou Zhang, Samuele Cornell, Robin Scheibler, Chenda Li, Anurag Kumar, Wei Wang, Yanmin Qian, Shinji Watanabe, Tim Fingscheidt* | **Category: eess.AS** | **Updated: 2025-07-15**

**Keywords:** 语音增强, 主观测试, 多语言, URGENT 2025, 生成式AI, 音素保真度

**Comment:** 5 pages, 2 figures

> **TL;DR:** 本文介绍了P.808多语言语音增强主观测试方法，并分析了URGENT 2025挑战赛结果，指出生成式语音增强需结合音素保真度指标以检测幻觉。

**AI_Comments:** 该论文创新性地将ITU-T P.808主观测试方法扩展到多语言环境，并提出了具体的本地化流程。其重要性在于，在生成式AI兴起的背景下，重新审视了传统主观评估的可靠性，并指出了现有客观指标的局限性，特别是对于“幻觉”现象的检测。强调了音素保真度指标对于生成式语音增强评估的重要性，为未来的评估方法提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 语音增强系统中的语音质量评估通常以主观听力测试为黄金标准，尤其是在面对大量新型生成式或混合方法时，这些方法暴露出某些客观指标的问题。URGENT 2025挑战赛引入了多语言数据集，增加了测试程序的多语言性方面。

**Method:** 本文首先简要回顾了ITU-T P.808众包主观听力测试方法。其次，提出了一种新的流程，用于本地化Naderi和Cutler实现的涉及文本到语音（TTS）的众包主观绝对类别评级（ACR）听力测试的文本和音频组件。最后，对URGENT挑战赛的结果进行了分析和洞察。

**Result:** 论文对URGENT挑战赛的结果进行了令人惊讶的分析和见解，并探讨了在生成式AI时代，P.808 ACR主观测试作为黄金标准的可靠性问题。研究发现，对于生成式语音增强方法，主观（ACR MOS）和客观（DNSMOS, NISQA）无参考指标应辅以客观音素保真度指标，以可靠地检测幻觉。

**Conclusion:** 本研究强调了在生成式AI时代，对于生成式语音增强方法的评估，除了传统的主观和无参考客观指标外，还需引入客观音素保真度指标来可靠地检测“幻觉”问题。论文承诺在接受的版本中发布本地化脚本和方法，以促进P.808多语言主观评估的部署。

> **ai_Abstract:** 本文介绍了ITU-T P.808众包主观听力测试方法，并提出了一种新的本地化流程，用于多语言语音增强的主观ACR测试。通过对URGENT 2025挑战赛结果的分析，作者发现对于生成式语音增强方法，除了主观和无参考客观指标外，还需要结合客观音素保真度指标来可靠地检测幻觉。论文还承诺发布相关本地化工具，以方便未来多语言语音增强主观评估的部署。

> **摘要翻译:** 在语音增强（SE）系统中，语音质量评估迄今为止仍将主观听力测试视为黄金标准。考虑到大量新的生成式或混合方法涌入该领域，暴露出一些客观指标的问题，这一点应更加突出。Interspeech 2025 URGENT语音增强挑战赛等努力，也涉及非英语数据集，为测试程序增加了多语言性方面。在本文中，我们简要回顾了ITU-T P.808众包主观听力测试方法。第一个新颖的贡献是我们提出的本地化Naderi和Cutler实现的众包主观绝对类别评级（ACR）听力测试中涉及文本到语音（TTS）的文本和音频组件的过程。此外，我们提供了对URGENT挑战赛结果的令人惊讶的分析和见解，探讨了在生成式AI时代P.808 ACR主观测试作为黄金标准的可靠性。特别是，对于生成式SE方法，主观（ACR MOS）和客观（DNSMOS, NISQA）无参考指标似乎应辅以客观音素保真度指标，以可靠地检测幻觉。最后，在接受的版本中，我们将发布我们的本地化脚本和方法，以便根据ITU-T P.808轻松部署新的多语言语音增强主观评估。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [154] [Towards Reliable Objective Evaluation Metrics for Generative Singing Voice Separation Models](https://arxiv.org/abs/2507.11427)
> *走向可靠的生成式歌声分离模型客观评估指标*

*Paul A. Bereuter, Benjamin Stahl, Mark D. Plumbley, Alois Sontacchi* | **Category: eess.AS** | **Updated: 2025-07-15**

**Keywords:** 歌声分离,评估指标,生成模型,盲源分离,嵌入式指标

**Comment:** Accepted for presentation at the IEEE Workshop on Applications of
  Signal Processing to Audio and Acoustics (WASPAA 2025), 5 pages

> **TL;DR:** 传统评估指标不适用于生成式歌声分离模型；本文通过听力测试和相关性分析，发现嵌入式指标（如Music2Latent MSE和MERT-L12 MSE）与多分辨率STFT损失在评估生成模型时更可靠，且MERT-L12 MSE对两种模型类型都表现出平衡的相关性。

**AI_Comments:** 本文识别并解决了生成式模型在歌声分离领域评估中的一个关键问题，即传统线性评估指标的不足。其创新之处在于通过听力测试验证客观指标的可靠性，并提出了适用于生成模型的更有效指标（如基于嵌入的MSE和STFT损失）。这对于推动歌声分离领域的发展，特别是生成模型的研究和应用具有重要意义，有助于建立更可靠的评估基准。

<details>
  <summary>Details</summary>

**Motivation:** 传统的BSS-Eval指标是为线性音频源分离模型设计的，但生成模型引入了分离信号与参考信号之间的非线性关系，这限制了这些指标在客观评估生成模型时的可靠性。因此，需要寻找更可靠的客观评估指标。

**Method:** 进行了一项“降级类别评级”听力测试（Degradation Category Rating listening test），并分析了获得的降级平均意见分数（DMOS）与一系列客观音频质量指标之间的相关性。评估了三种最先进的判别模型和两种新的有竞争力的生成模型。

**Result:** 对于判别模型和生成模型，侵入式嵌入基指标（intrusive embedding-based metrics）与DMOS的相关性高于传统的侵入式指标（如BSS-Eval）。对于判别模型，Music2Latent嵌入上计算的MSE达到了最高相关性。对于生成模型的评估，多分辨率STFT损失和MERT-L12嵌入上计算的MSE显示出最强的相关性。MERT-L12嵌入上的MSE在两种模型类型中提供了最平衡的相关性。

**Conclusion:** BSS-Eval指标在评估生成式歌声分离模型时存在局限性，并且强调在歌声分离任务中需要仔细选择和验证替代评估指标。

> **ai_Abstract:** 本文研究了生成式歌声分离模型中传统BSS-Eval评估指标的局限性，因为生成模型引入了非线性关系。通过进行听力测试并分析DMOS与多种客观指标的相关性，作者发现侵入式嵌入基指标（如Music2Latent MSE和MERT-L12 MSE）在评估判别和生成模型时比传统BSS-Eval更可靠。特别是，MERT-L12 MSE在两种模型类型中都提供了最平衡的相关性。研究结果强调了为生成模型选择和验证合适评估指标的重要性。

> **摘要翻译:** 传统盲源分离评估（BSS-Eval）指标最初是为基于时频掩蔽等方法的线性音频源分离模型设计的。然而，最近的生成模型可能会在分离信号和参考信号之间引入非线性关系，这限制了这些指标在客观评估中的可靠性。为了解决这个问题，我们进行了一项降级类别评级听力测试，并分析了获得的降级平均意见分数（DMOS）与歌声分离任务中一系列客观音频质量指标之间的相关性。我们评估了三种最先进的判别模型和两种新的有竞争力的生成模型。对于判别模型和生成模型，侵入式嵌入基指标与DMOS的相关性高于传统的侵入式指标，例如BSS-Eval。对于判别模型，在Music2Latent嵌入上计算的MSE实现了最高相关性。当涉及生成模型的评估时，多分辨率STFT损失和在MERT-L12嵌入上计算的MSE表现出最强的相关性，其中后者在两种模型类型中也提供了最平衡的相关性。我们的结果强调了BSS-Eval指标在评估生成式歌声分离模型时的局限性，并强调了在歌声分离任务中需要仔细选择和验证替代评估指标。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [11] [Journalism-Guided Agentic In-Context Learning for News Stance Detection](https://arxiv.org/abs/2507.11049)
> *新闻学指导的代理语境学习用于新闻立场检测*

*Dahyun Lee, Jonghyeon Choi, Jiyoung Han, Kunwoo Park* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 立场检测, 语境学习, 新闻文章, 媒体偏见, 韩语数据集

**Comment:** Preprint. 24 pages

> **TL;DR:** 本文介绍了首个韩语文章级新闻立场检测数据集K-News-Stance，并提出了JoA-ICL框架，该框架采用新闻学指导的代理语境学习方法，在长篇新闻文章的立场检测方面优于现有方法。

**AI_Comments:** 本文的创新之处在于解决了长文本和低资源语言（韩语）的文章级立场检测问题，并提出了一种新颖的、利用新闻学结构的代理语境学习框架。这种方法有望显著改善个性化新闻推荐和媒体偏见分析。

<details>
  <summary>Details</summary>

**Motivation:** 随着在线新闻消费的增长，个性化推荐系统成为数字新闻不可或缺的一部分，但它们存在通过未能整合多样化视角而加剧过滤气泡和政治两极分化的风险。立场检测——识别文本对目标的立场——可以通过实现以观点为导向的推荐和数据驱动的媒体偏见分析来帮助缓解这一问题。然而，现有的立场检测研究主要局限于短文本和高资源语言。

**Method:** 为了解决这些问题，我们引入了\textsc{K-News-Stance}，这是首个用于文章级立场检测的韩语数据集，包含2,000篇新闻文章，具有文章级和19,650个片段级立场标注，涵盖47个社会问题。我们还提出了\textsc{JoA-ICL}，一个新闻学指导的代理语境学习框架，该框架采用语言模型代理来预测关键结构片段（例如，导语、引用）的立场，然后将这些立场聚合以推断整体文章立场。

**Result:** 实验表明，\textsc{JoA-ICL}优于现有的立场检测方法，凸显了片段级代理在捕获长篇新闻文章整体立场方面的优势。两个案例研究进一步证明了其在促进新闻推荐中的观点多样性和揭示媒体偏见模式方面的更广泛效用。

**Conclusion:** 本文提出的JoA-ICL框架和K-News-Stance数据集有效解决了文章级新闻立场检测的挑战，特别是对于长文本和低资源语言，展示了其在增强推荐系统和媒体偏见分析方面的价值。

> **ai_Abstract:** 本文针对当前立场检测研究在处理长文本和多样化语言方面的局限性，首次推出了韩语文章级新闻立场检测数据集\textsc{K-News-Stance}。同时，提出了一种新颖的新闻学指导的代理语境学习框架\textsc{JoA-ICL}，该框架利用语言模型代理预测文章关键结构片段的立场，并将其聚合以推断整体文章立场。实验结果表明，\textsc{JoA-ICL}优于现有立场检测方法，证明了其在捕获长篇新闻文章立场方面的有效性，并在促进观点多样性和分析媒体偏见方面具有实用价值。

> **摘要翻译:** 随着在线新闻消费的增长，个性化推荐系统已成为数字新闻不可或缺的一部分。然而，这些系统存在通过未能整合多样化视角而加剧过滤气泡和政治两极分化的风险。立场检测——识别文本对目标的立场——可以通过实现以观点为导向的推荐和数据驱动的媒体偏见分析来帮助缓解这一问题。然而，现有的立场检测研究仍然主要局限于短文本和高资源语言。为了解决这些差距，我们引入了\textsc{K-News-Stance}，这是首个用于文章级立场检测的韩语数据集，包含2,000篇新闻文章，具有文章级和19,650个片段级立场标注，涵盖47个社会问题。我们还提出了\textsc{JoA-ICL}，一个新闻学指导的代理语境学习框架，该框架采用语言模型代理来预测关键结构片段（例如，导语、引用）的立场，然后将这些立场聚合以推断整体文章立场。实验表明，\textsc{JoA-ICL}优于现有的立场检测方法，凸显了片段级代理在捕获长篇新闻文章整体立场方面的优势。两个案例研究进一步证明了其在促进新闻推荐中的观点多样性和揭示媒体偏见模式方面的更广泛效用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [23] [Seq vs Seq: An Open Suite of Paired Encoders and Decoders](https://arxiv.org/abs/2507.11412)
> *Seq vs Seq：一个开放的成对编码器和解码器套件*

*Orion Weller, Kathryn Ricci, Marc Marone, Antoine Chaffin, Dawn Lawrie, Benjamin Van Durme* | **Category: cs.CL, cs.IR, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 编码器-解码器模型, 大语言模型, Ettin套件, 模型比较, 开放资源

**Comment:** 

> **TL;DR:** 本文引入了Ettin模型套件，包含成对的编码器和解码器，它们以相同方式训练，用于比较两种架构，并发现它们各自在特定任务上表现最佳，且交叉适应效果不佳。

**AI_Comments:** 这篇论文的创新之处在于其构建了一个统一、大规模且参数匹配的编码器-解码器模型套件（Ettin），有效解决了以往研究中因训练设置不一致导致的比较不公问题。其重要性在于为公平评估和理解两种主流LLM架构的优劣提供了坚实的基础和基准，并揭示了模型在任务适应性方面的局限性。所有训练产物的开源是其一大亮点，极大地促进了研究的透明度、可复现性以及未来工作的扩展潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLM）社区主要关注仅解码器模型，但仅编码器模型仍广泛用于分类或检索等任务。现有研究在比较这两种架构时面临挑战，因为它们通常在不同的参数数量、训练技术和数据集下进行训练，导致比较结果不公平。

**Method:** 本文引入了SOTA开放数据Ettin模型套件，该套件包含一系列成对的仅编码器和仅解码器模型，参数范围从1700万到10亿，并在高达2万亿个token上进行训练。对这两种模型类型采用了相同的训练策略，以确保公平比较。

**Result:** Ettin模型在各自类别中都达到了SOTA水平，击败了现有模型（如作为编码器的ModernBERT和作为解码器的Llama 3.2、SmolLM2）。研究发现，仅编码器模型擅长分类和检索任务，而仅解码器模型擅长生成任务。此外，通过继续训练将解码器模型适应编码器任务（反之亦然）的效果不如直接使用原始目标模型（例如，一个4亿参数的编码器在MNLI上优于一个10亿参数的解码器）。

**Conclusion:** 仅编码器模型和仅解码器模型各有其擅长的任务领域，并且在各自的优势任务上表现最佳；通过继续训练将一种模型适应另一种任务的效果通常不佳。本研究开源了所有训练产物，以促进未来对模型训练各个方面的分析和扩展。

> **ai_Abstract:** 本文介绍了Ettin模型套件，这是一组从1700万到10亿参数规模的成对编码器和解码器模型，它们在相同训练策略下于海量数据上进行训练。该研究旨在公平比较编码器-only和解码器-only架构在不同任务上的性能。结果表明，Ettin模型在各自领域均达到SOTA水平，且编码器在分类和检索任务上表现出色，而解码器在生成任务上表现优异。研究还发现，通过继续训练将模型从一种架构适应到“相反”的任务时，其性能不如直接使用原生模型。作者开源了所有研究成果，以促进社区的进一步分析和研究。

> **摘要翻译:** 大型语言模型（LLM）社区几乎只关注仅解码器语言模型，因为它们更易于用于文本生成。然而，社区中仍有很大一部分人使用仅编码器模型进行分类或检索等任务。以前的工作曾尝试比较这些架构，但被迫使用参数数量、训练技术和数据集不同的模型进行比较。我们引入了SOTA开放数据Ettin模型套件：成对的仅编码器和仅解码器模型，参数范围从1700万到10亿，在高达2万亿个token上进行训练。对仅编码器和仅解码器模型采用相同的训练方法，在各自尺寸类别中都产生了SOTA方法，击败了作为编码器的ModernBERT和作为解码器的Llama 3.2和SmolLM2。与以前的工作一样，我们发现仅编码器模型擅长分类和检索任务，而解码器模型擅长生成任务。然而，我们发现通过继续训练将解码器模型适应编码器任务（反之亦然）的效果不如仅使用反向目标（即，一个4亿参数的编码器在MNLI上优于一个10亿参数的解码器，生成任务反之亦然）。我们开源了这项研究的所有产物，包括训练数据、按检查点分段的训练顺序以及200多个检查点，以允许未来的工作分析或扩展训练的各个方面。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [29] [Plancraft: an evaluation dataset for planning with LLM agents](https://arxiv.org/abs/2412.21033)
> *Plancraft：一个用于LLM智能体规划的评估数据集*

*Gautier Dagan, Frank Keller, Alex Lascarides* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** Plancraft, LLM智能体, 规划, 评估数据集, Minecraft

**Comment:** 

> **TL;DR:** Plancraft是一个用于评估LLM智能体规划能力的多模态数据集，基于Minecraft合成界面，包含Wiki用于工具使用和RAG评估，并引入了不可解任务。评估发现LLM和VLM在规划问题上表现不佳。

**AI_Comments:** Plancraft数据集的创新之处在于其多模态特性、结合Minecraft Wiki进行工具使用和RAG评估，以及引入不可解任务来测试智能体的决策能力。这为LLM智能体规划能力的评估提供了一个更全面和真实的基准。该研究揭示了当前LLM在复杂规划问题上的局限性，对未来LLM智能体研究具有重要指导意义，尤其是在提升其通用规划和问题判断能力方面。

<details>
  <summary>Details</summary>

**Motivation:** 为了评估大型语言模型（LLM）智能体在规划任务上的表现，特别是其决策能力、工具使用和检索增强生成（RAG）能力，并识别当前LLM在规划问题上的局限性。

**Method:** 研究提出了Plancraft数据集，这是一个基于Minecraft合成界面的多模态评估数据集。它包含文本和多模态接口，整合了Minecraft Wiki以评估工具使用和RAG。数据集还包括一个手工规划器和Oracle检索器，用于分析现代智能体架构的不同组件。Plancraft特别设计了一部分不可解的示例，以测试智能体判断任务可解性的能力。研究使用Plancraft对开源和闭源LLM进行了基准测试，并将其性能和效率与手工规划器进行了比较。

**Result:** 评估结果显示，大型语言模型（LLM）和视觉语言模型（VLM）在Plancraft引入的规划问题上表现不佳，难以有效解决这些问题。

**Conclusion:** LLM和VLM在复杂的规划问题上仍面临挑战。论文提供了改进其能力的建议，表明未来研究应关注提升LLM智能体在决策、工具使用和复杂规划方面的能力。

> **ai_Abstract:** Plancraft是一个新颖的多模态评估数据集，专为测试大型语言模型（LLM）智能体的规划能力而设计。该数据集基于Minecraft合成界面，提供文本和多模态两种接口，并整合了Minecraft Wiki以评估工具使用和检索增强生成（RAG）。为全面分析智能体架构，Plancraft包含手工规划器和Oracle检索器。值得注意的是，数据集中还特别加入了不可解任务，以挑战智能体判断任务可解性的决策能力。基准测试结果表明，当前LLM和视觉语言模型（VLM）在Plancraft提出的规划问题上表现不足，论文也据此提出了改进建议。

> **摘要翻译:** 我们提出了Plancraft，一个用于LLM智能体的多模态评估数据集。Plancraft基于Minecraft合成GUI，具有纯文本和多模态接口。我们引入了Minecraft Wiki来评估工具使用和检索增强生成（RAG），以及一个手工规划器和Oracle检索器，以剥离现代智能体架构的不同组件。为了评估决策能力，Plancraft还包含一部分故意设置为不可解的示例，提供了一个现实的挑战，这要求智能体不仅要完成任务，还要决定它们是否可解。我们对开源和闭源LLM进行了基准测试，并将其性能和效率与手工规划器进行了比较。总的来说，我们发现LLM和VLM在Plancraft引入的规划问题上表现不佳，并提供了如何提高其能力的建议。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [34] [EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes](https://arxiv.org/abs/2507.11407)
> *EXAONE 4.0：集成非推理和推理模式的统一大型语言模型*

*LG AI Research, :, Kyunghoon Bae, Eunbi Choi, Kibong Choi, Stanley Jungkyu Choi, Yemuk Choi, Kyubeen Han, Seokhee Hong, Junwon Hwang, Taewan Hwang, Joonwon Jang, Hyojin Jeon, Kijeong Jeon, Gerrard Jeongwon Jo, Hyunjik Jo, Jiyeon Jung, Euisoon Kim, Hyosang Kim, Jihoon Kim, Joonkee Kim, Seonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Yongil Kim, Youchul Kim, Edward Hwayoung Lee, Gwangho Lee, Haeju Lee, Honglak Lee, Jinsik Lee, Kyungmin Lee, Sangha Park, Young Min Paik, Yongmin Park, Youngyong Park, Sanghyun Seo, Sihoon Yang, Heuiyeen Yeen, Sihyuk Yi, Hyeongu Yun* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, EXAONE 4.0, 统一模型, 推理能力, 智能体AI

**Comment:** Technical Report, 30 Pages

> **TL;DR:** EXAONE 4.0是一种统一的大型语言模型，结合了非推理和推理模式，提升了可用性和推理能力，支持智能体工具使用和多语言，性能优于同类开源模型，并提供不同大小的模型供研究使用。

**AI_Comments:** EXAONE 4.0的创新之处在于其统一了非推理和推理模式，这有助于在保持可用性的同时提升复杂任务的处理能力。其对智能体工具使用的支持以及多语言扩展，显示出其在未来AI应用中的潜力。提供不同尺寸的模型，兼顾了高性能和设备端部署的需求，且公开可用，有利于推动相关研究。

<details>
  <summary>Details</summary>

**Motivation:** 旨在结合EXAONE 3.5的优秀可用性和EXAONE Deep的先进推理能力，并为智能体AI时代铺平道路。

**Method:** 通过集成非推理模式和推理模式来统一模型，并引入智能体工具使用等关键功能，扩展多语言支持（英语、韩语、西班牙语）。提供了两种模型尺寸：32B（高性能）和1.2B（设备端应用）。

**Result:** EXAONE 4.0在同类开源模型中表现出卓越性能，甚至与前沿模型相比也具有竞争力。

**Conclusion:** EXAONE 4.0成功地将非推理和推理模式统一，提升了性能和功能，并为智能体AI发展做出了贡献，模型已公开可用。

> **ai_Abstract:** EXAONE 4.0是一个统一的大型语言模型，融合了非推理和推理模式，旨在提升可用性和高级推理能力。它支持智能体工具使用和多语言（英、韩、西），并提供32B和1.2B两种尺寸，分别优化高性能和设备端应用。该模型在性能上优于同类开源模型，并与前沿模型保持竞争力，已公开发布供研究使用。

> **摘要翻译:** 这份技术报告介绍了EXAONE 4.0，它集成了非推理模式和推理模式，以实现EXAONE 3.5出色的可用性和EXAONE Deep先进的推理能力。为了为智能体AI时代铺平道路，EXAONE 4.0融入了智能体工具使用等基本功能，并且其多语言能力已扩展到支持西班牙语，此外还支持英语和韩语。EXAONE 4.0模型系列包括两种尺寸：一个针对高性能优化的中型32B模型，以及一个专为设备端应用设计的小型1.2B模型。EXAONE 4.0与同类开源模型相比表现出卓越的性能，甚至与前沿模型相比也具有竞争力。这些模型已公开发布用于研究目的，可以通过https://huggingface.co/LGAI-EXAONE轻松下载。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [52] [Social Media Sentiments Analysis on the July Revolution in Bangladesh: A Hybrid Transformer Based Machine Learning Approach](https://arxiv.org/abs/2507.11084)
> *孟加拉国七月革命的社交媒体情感分析：一种基于混合Transformer的机器学习方法*

*Md. Sabbir Hossen, Md. Saiduzzaman, Pabon Shaha* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 社交媒体情感分析, 孟加拉语, Transformer, 机器学习, 孟加拉国七月革命

**Comment:** This paper has been accepted and presented at the IEEE ECAI 2025. The
  final version will be available in the IEEE Xplore Digital Library

> **TL;DR:** 本研究提出了一种混合Transformer模型，用于分析孟加拉国七月革命期间社交媒体上孟加拉语评论的情感，实现了83.7%的准确率，展示了机器学习在低资源语言情感分析中的潜力。

**AI_Comments:** 该论文的创新点在于提出了一个混合Transformer模型（XMB-BERT）来处理低资源语言（孟加拉语）的社交媒体情感分析，并构建了一个新的数据集。其重要性在于展示了机器学习在分析特定历史事件中公众情绪的潜力，尤其是在语言资源匮乏的背景下。局限性可能在于数据集的规模和特定性，以及模型在更广泛语境下的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 孟加拉国七月革命期间，社交媒体在放大公众情绪和塑造舆论方面发挥了关键作用。本研究旨在解码社交媒体评论中表达的公众意见。

**Method:** 研究构建了一个包含4,200条孟加拉语社交媒体评论的全新数据集。采用BanglaBERT、mBERT、XLM-RoBERTa和提出的混合XMB-BERT等基于Transformer的特征提取技术。利用主成分分析（PCA）进行降维。探索了十一种传统和先进的机器学习分类器来识别情感。

**Result:** 提出的混合XMB-BERT与投票分类器结合，实现了83.7%的准确率，并优于其他模型分类器组合。

**Conclusion:** 本研究强调了机器学习技术在分析孟加拉语等低资源语言社交情感方面的潜力。

> **ai_Abstract:** 本研究提出了一种基于混合Transformer的机器学习方法，用于分析孟加拉国七月革命期间社交媒体上的孟加拉语评论情感。该研究收集了4,200条孟加拉语评论数据集，并利用BanglaBERT、mBERT、XLM-RoBERTa以及提出的混合XMB-BERT进行特征提取，结合PCA降维和多种机器学习分类器。结果显示，混合XMB-BERT与投票分类器的组合达到了83.7%的准确率，证明了其在低资源语言情感分析中的有效性。

> **摘要翻译:** 孟加拉国七月革命标志着一场由学生领导的重大群众起义，团结了全国人民，要求正义、问责和系统性改革。社交媒体平台在这次历史性群众起义期间，在放大公众情绪和塑造舆论方面发挥了关键作用。在本研究中，我们提出了一种基于混合Transformer的情感分析框架，用于解读革命期间和之后社交媒体评论中表达的公众意见。我们使用了从社交媒体收集的4,200条孟加拉语评论的全新数据集。该框架采用先进的基于Transformer的特征提取技术，包括BanglaBERT、mBERT、XLM-RoBERTa以及提出的混合XMB-BERT，以捕捉文本数据中细微的模式。利用主成分分析（PCA）进行降维，以提高计算效率。我们探索了十一种传统和先进的机器学习分类器来识别情感。所提出的混合XMB-BERT与投票分类器相结合，实现了83.7%的卓越准确率，并优于其他模型分类器组合。这项研究强调了机器学习技术在分析孟加拉语等低资源语言社交情感方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [61] [An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation](https://arxiv.org/abs/2507.10580)
> *一种用于心理健康支持的离线移动对话代理：从情感对话和心理文本中学习，并进行以学生为中心的评估*

*Vimaleswar A, Prabhu Nandan Sahu, Nilesh Kumar Sahu, Haroon R Lone* | **Category: cs.CL, cs.AI, cs.CY, cs.HC** | **Updated: 2025-07-11**

**Keywords:** 离线对话代理, 心理健康支持, 大型语言模型, 边缘计算, 学生评估

**Comment:** 

> **TL;DR:** EmoSApp是一种离线、基于智能手机的心理健康对话应用，它利用在专业数据集上微调和量化的大型语言模型，为资源受限设备提供可访问、私密且有效的心理健康支持，并通过学生评估和基准测试验证了其性能。

**AI_Comments:** 这项研究的创新之处在于其专注于开发一个完全离线的移动心理健康支持代理，有效解决了在线解决方案面临的连接性和隐私挑战。通过在资源受限设备上部署微调和量化的LLM，它展示了在边缘设备上实现复杂AI应用的可能性。此外，其以学生为中心的评估方法和对特定领域知识的强调，使其在实际应用中更具相关性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 数字平台在心理健康支持方面面临用户可访问性、互联网连接和数据隐私的挑战，因此需要一个离线的、基于智能手机的解决方案。

**Method:** 提出了EmoSApp，一个完全离线的智能手机对话应用。该系统利用大型语言模型（LLMs），特别是使用Torchtune和Executorch进行微调、量化和部署，以适应资源受限设备，确保所有推理都在智能手机上进行。通过在包含14,582个心理健康问答对和多轮对话数据的自定义“知识数据集”上微调LLaMA-3.2-1B-Instruct模型，为EmoSApp提供了强大的领域专业知识。

**Result:** 通过对学生群体的定性人工评估，EmoSApp能够连贯、富有同情心地回应，保持互动对话，并提供与用户心理健康问题相关的建议。此外，在九个标准常识和推理基准上的定量评估表明，微调和量化的模型在低资源设置下是有效的。

**Conclusion:** 通过优先考虑设备部署和专门的领域适应，EmoSApp为未来便携、安全和高度定制的AI驱动心理健康解决方案创新提供了蓝图。

> **ai_Abstract:** 本研究提出了一款名为EmoSApp的离线移动对话应用，旨在解决数字心理健康支持中存在的连通性、隐私和可访问性问题。该应用利用在自定义心理健康数据集上微调和量化的大型语言模型（LLaMA-3.2-1B-Instruct），并部署在资源受限的智能手机上，实现了完全的离线推理。通过对学生群体的定性评估，EmoSApp展现出连贯、富有同情心且能提供相关建议的能力。定量基准测试也证实了其在低资源环境下的有效性。该工作为未来便携、安全且定制化的AI心理健康解决方案提供了新的范例。

> **摘要翻译:** 心理健康在个人整体福祉中扮演着至关重要的角色。近年来，数字平台被越来越多地用于扩展心理健康和情感支持。然而，用户可访问性、互联网连接和数据隐私方面存在持续的挑战，这突出表明了对离线、基于智能手机解决方案的需求。为了应对这些挑战，我们提出了EmoSApp（情感支持应用程序）：一个完全离线、基于智能手机的对话应用程序，专为心理健康和情感支持而设计。该系统利用大型语言模型（LLMs），特别是使用Torchtune和Executorch进行微调、量化和部署，适用于资源受限设备，允许所有推理在智能手机上进行。为了让EmoSApp具备强大的领域专业知识，我们在自定义的“知识数据集”上对LLaMA-3.2-1B-Instruct模型进行了微调，该数据集包含14,582个心理健康问答对以及多轮对话数据。通过对学生群体的定性人工评估，我们证明了EmoSApp能够连贯、富有同情心地回应，保持互动对话，并为用户的心理健康问题提供相关建议。此外，在九个标准常识和推理基准上的定量评估表明，我们微调和量化的模型在低资源设置中是有效的。通过优先考虑设备部署和专门的领域适应，EmoSApp为未来便携、安全和高度定制的AI驱动心理健康解决方案的创新提供了蓝图。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [65] [Shared Global and Local Geometry of Language Model Embeddings](https://arxiv.org/abs/2503.21073)
> *语言模型嵌入的共享全局和局部几何*

*Andrew Lee, Melanie Weber, Fernanda Viégas, Martin Wattenberg* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 语言模型嵌入, 几何相似性, 固有维度, 令牌嵌入, EMB2EMB

**Comment:** 

> **TL;DR:** 本文发现大型语言模型令牌嵌入存在全局和局部几何相似性，并引入了一种名为EMB2EMB的应用，用于在不同维度模型间线性转换引导向量。

**AI_Comments:** 该研究通过深入分析语言模型嵌入的几何特性，为理解模型共享表示提供了新的视角。特别是对全局和局部几何的区分以及固有维度的引入，揭示了嵌入空间中语义结构的存在。EMB2EMB的应用展示了这些几何发现的潜在实用价值，为跨模型知识迁移提供了简单有效的手段，具有一定的创新性。

<details>
  <summary>Details</summary>

**Motivation:** 研究人员最近提出模型共享通用表示，本文旨在探索并发现大型语言模型令牌嵌入中的几何相似性。

**Method:** 本文首先发现令牌嵌入的“全局”相似性，即相似的相对方向。其次，通过使用局部线性嵌入（Locally Linear Embeddings）和定义一种简单的固有维度度量来表征局部几何。最后，基于研究结果，引入了EMB2EMB，一个简单的应用，用于线性转换不同维度语言模型之间的引导向量。

**Result:** 研究发现令牌嵌入存在大量的“全局”几何相似性，即相似的相对方向。通过局部线性嵌入和固有维度度量，发现了令牌嵌入的局部相似性。此外，固有维度表明嵌入位于较低维流形上，并且固有维度较低的令牌通常具有语义连贯的簇，而固有维度较高的则没有。

**Conclusion:** 本文发现大型语言模型令牌嵌入存在显著的全局和局部几何相似性，且嵌入位于较低维流形上，低固有维度令牌形成语义连贯簇。基于这些发现，引入了EMB2EMB，一个能将引导向量从一个语言模型线性转换到另一个模型的应用。

> **ai_Abstract:** 本文深入探究了大型语言模型（LLM）令牌嵌入的几何结构。研究揭示了嵌入中存在的全局（相似相对方向）和局部（通过局部线性嵌入和固有维度衡量）几何相似性。特别地，固有维度分析表明嵌入位于低维流形上，且低固有维度令牌倾向于形成语义连贯的簇。基于这些发现，作者提出了EMB2EMB，一个能够在线性转换不同维度LLM之间引导向量的应用。

> **摘要翻译:** 研究人员最近提出模型共享通用表示。在我们的工作中，我们发现大型语言模型令牌嵌入中存在大量的几何相似性。首先，我们发现“全局”相似性：令牌嵌入通常共享相似的相对方向。接下来，我们通过两种方式描述局部几何：(1) 使用局部线性嵌入（Locally Linear Embeddings），以及 (2) 定义一个简单的每个嵌入的固有维度度量。这两种表征都使我们能够发现令牌嵌入之间的局部相似性。此外，我们的固有维度表明嵌入位于较低维流形上，并且固有维度较低的令牌通常具有语义连贯的簇，而固有维度较高的则没有。基于我们的发现，我们引入了EMB2EMB，一个简单的应用，用于线性转换一个语言模型到另一个语言模型的引导向量，尽管这两个模型具有不同的维度。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [75] [HanjaBridge: Resolving Semantic Ambiguity in Korean LLMs via Hanja-Augmented Pre-Training](https://arxiv.org/abs/2507.10920)
> *HanjaBridge：通过汉字增强预训练解决韩语大型语言模型中的语义歧义*

*Seungho Choi* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 韩语LLM, 语义歧义, 汉字增强, 持续预训练, 跨语言迁移

**Comment:** 

> **TL;DR:** HanjaBridge通过汉字增强的预训练，显著提高了韩语大型语言模型处理同音词语义歧义的能力，并展现了跨语言迁移优势。

**AI_Comments:** 本文的创新点在于提出了HanjaBridge，利用汉字作为桥梁来解决韩语LLMs中同音异义词的语义歧义问题，这是一种巧妙且有效的跨语言知识注入方法。通过提供所有汉字候选而非单一映射，鼓励模型进行上下文消歧，同时结合知识蒸馏防止遗忘，设计周全。其在低资源语言（韩语）上的显著性能提升和跨语言迁移能力，以及推理时无需额外开销的特点，都显示了其重要的实用价值和广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在韩语等低资源语言中表现不佳，部分原因是韩语中存在同音异义的汉字词，在韩语表音文字中难以区分，导致语义歧义。

**Method:** 提出HanjaBridge，一种新的意义注入技术，集成到持续预训练（CPT）框架中。它不将单词确定性地映射到单个汉字，而是向模型提供给定同音词的所有可能汉字候选，鼓励模型学习上下文消歧。此过程与令牌级知识蒸馏相结合，以防止灾难性遗忘。

**Result:** HanjaBridge显著提高了韩语理解能力，在KoBALT基准测试中相对改进了21%。通过共享汉字增强韩语和汉语之间的语义对齐，观察到强大的正向跨语言迁移。这些增益在推理时省略汉字增强后依然存在，确保了实用效率且没有额外的运行时间成本。

**Conclusion:** HanjaBridge通过汉字增强预训练有效解决了韩语LLMs中的语义歧义问题，显著提升了韩语理解能力，并展现了跨语言迁移的积极效果，同时保持了推理效率。

> **ai_Abstract:** 本文提出了HanjaBridge，一种针对韩语大型语言模型（LLMs）的汉字增强预训练方法，旨在解决韩语同音异义词造成的语义歧义。该方法通过在持续预训练中向模型提供所有可能的汉字候选并结合知识蒸馏，显著提升了韩语理解能力（在KoBALT基准上提升21%），并实现了积极的跨语言迁移。重要的是，推理时无需汉字增强也能保持性能，保证了效率。

> **摘要翻译:** 大型语言模型（LLMs）在韩语等低资源语言中表现不佳，部分原因是独特的语言挑战，例如在韩文脚本中无法区分的同音中韩词。为了解决这种语义歧义，我们提出了HanjaBridge，一种集成到持续预训练（CPT）框架中的新型意义注入技术。HanjaBridge不将一个词确定性地映射到单个汉字（汉字），而是向模型呈现给定同音异义词的所有可能汉字候选，鼓励模型学习上下文消歧。此过程与令牌级知识蒸馏相结合，以防止灾难性遗忘。实验结果表明，HanjaBridge显著提高了韩语理解能力，在KoBALT基准测试中实现了21%的相对改进。值得注意的是，通过共享汉字加强韩语和汉语之间的语义对齐，我们观察到强大的积极跨语言迁移。此外，即使在推理时省略汉字增强，这些增益仍然存在，确保了实用效率且没有额外的运行时间成本。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [76] [KisMATH: Do LLMs Have Knowledge of Implicit Structures in Mathematical Reasoning?](https://arxiv.org/abs/2507.11408)
> *KisMATH：大型语言模型是否了解数学推理中的隐式结构？*

*Soumadeep Saha, Akshay Chaturvedi, Saptarshi Saha, Utpal Garain, Nicholas Asher* | **Category: cs.CL, cs.AI, I.2.7** | **Updated: 2025-07-15**

**Keywords:** LLMs, 数学推理, 思维链, 因果思维链图, KisMATH

**Comment:** 15 pages, 9 figures

> **TL;DR:** 引入因果思维链图（CCGs）和KisMATH数据集，实证分析表明LLM在数学推理中内部实现了类似图的结构，推理节点是最终答案的中介。

**AI_Comments:** 这篇论文的创新点在于引入了因果思维链图（CCGs）这一新颖的工具来可视化和分析LLM的推理过程，并构建了KisMATH数据集。通过实证分析，它为LLM在数学推理中如何利用CoT提供了机制层面的见解，特别是关于内部结构和推理节点作为中介的作用。这对于理解LLM的“黑箱”推理过程具有重要意义，并为未来的可控干预和模型改进奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 尽管思维链（CoT）已被证明可以提高大型语言模型（LLMs）在推理任务中的性能，但其性能提升的机制尚无共识。本研究旨在阐明这一点。

**Method:** 本研究引入了因果思维链图（CCGs），这是一种从推理轨迹中自动提取的有向无环图，用于建模语言模型输出中细粒度的因果依赖关系。研究人员将来自MATH500、GSM8K和AIME的1671个数学推理问题及其相关的CCGs编译成KisMATH数据集。随后，对15个开源LLMs进行了详细的实证分析。

**Result:** 实证分析结果显示：(i) CCG中的推理节点是最终答案的中介，这是推理的必要条件；(ii) LLMs强调CCG给出的推理路径，表明模型内部实现了类似于CCG的结构。

**Conclusion:** KisMATH数据集使得受控的、与图对齐的干预成为可能，并为进一步研究思维链在LLM推理中的作用开辟了途径。研究结果表明LLMs在内部实现了与CCG相似的结构，且推理节点是最终答案的关键中介。

> **ai_Abstract:** 本研究引入了因果思维链图（CCGs）来探究大型语言模型（LLMs）在数学推理中思维链提升性能的机制。通过构建包含1671个数学问题及其CCGs的KisMATH数据集，并对15个开源LLMs进行实证分析，研究发现CCG中的推理节点是最终答案的中介，且LLMs内部实现了与CCG类似的推理结构。KisMATH为进一步研究LLM推理中的思维链作用提供了新的工具和方向。

> **摘要翻译:** 思维链（Chain-of-thought）轨迹已被证明可以提高大型语言模型在大量推理任务中的性能，但关于这种性能提升的机制尚未达成共识。为了进一步阐明这一点，我们引入了因果思维链图（Causal CoT Graphs, CCGs），这是一种从推理轨迹中自动提取的有向无环图，用于建模语言模型输出中细粒度的因果依赖关系。我们将来自MATH500、GSM8K和AIME的1671个数学推理问题及其相关的CCGs编译成我们的数据集——	extbf{KisMATH}。我们对15个开源LLMs进行的详细实证分析表明：(i) CCG中的推理节点是最终答案的中介，这是推理的必要条件；(ii) LLMs强调CCG给出的推理路径，这表明模型内部实现了类似于我们图的结构。KisMATH使得受控的、与图对齐的干预成为可能，并为进一步研究思维链在LLM推理中的作用开辟了途径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [94] [Beyond Traditional Algorithms: Leveraging LLMs for Accurate Cross-Border Entity Identification](https://arxiv.org/abs/2507.11086)
> *超越传统算法：利用大型语言模型实现精准跨境实体识别*

*Andres Azqueta-Gavaldón, Joaquin Ramos Cosgrove* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 跨境实体识别, 大型语言模型, 传统算法, 金融合规, 实体匹配

**Comment:** 

> **TL;DR:** 针对跨境金融活动中的实体识别挑战，本文研究发现，相比传统算法，大型语言模型（LLMs），特别是基于接口的LLMs，能更准确地识别跨境实体，具有更高的F1分数和更低的误报率。

**AI_Comments:** 这篇论文的创新点在于将大型语言模型应用于传统上由规则或统计方法主导的实体识别任务，特别是在复杂的跨境金融领域。它明确指出了传统算法在处理语义和上下文方面的局限性，并提供了LLMs作为有效替代的实证证据。研究结果表明LLMs在准确性和F1分数上表现出色，尽管误报率的改进描述略显模糊，但总体趋势是积极的。这为金融机构在提升合规性和风险管理效率方面提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 随着全球市场跨境金融活动的日益普及，准确识别和分类外国实体变得至关重要，尤其是在西班牙金融体系中进行风险管理、遵守法规和防止金融不当行为。然而，传统算法在处理语言变异、特殊字符、过时名称和法律形式变更时面临挑战，导致上下文和语义理解不足，进而产生错配。

**Method:** 为解决传统算法的局限性，本文探索了大型语言模型（LLMs）作为一种灵活的替代方案。研究评估了传统匹配算法（如Jaccard、余弦、Levenshtein距离）、基于Hugging Face的LLMs以及基于接口的LLMs（如Microsoft Copilot、阿里巴巴的Qwen 2.5），并使用包含65个葡萄牙公司案例的数据集进行测试。

**Result:** 结果显示，传统方法准确率超过92%，但误报率很高（20-40%）。基于接口的LLMs表现更优，准确率超过93%，F1分数超过96%，并且误报率相对较低（40-80%）。

**Conclusion:** 大型语言模型，特别是基于接口的LLMs，在处理跨境实体识别的复杂性方面优于传统算法，能够提供更准确和鲁健的解决方案。

> **ai_Abstract:** 本文探讨了在跨境金融活动中，大型语言模型（LLMs）如何解决传统算法在实体识别中面临的挑战。针对语言差异、名称变化等问题，研究比较了传统算法、基于Hugging Face的LLMs和基于接口的LLMs。实验结果表明，基于接口的LLMs在准确率和F1分数上均优于传统方法，并有效降低了误报率，为跨境实体识别提供了更准确、鲁棒的解决方案。

> **摘要翻译:** 全球市场中跨境金融活动的日益普及，突显了准确识别和分类外国实体的必要性。这种做法在西班牙金融体系中对于确保稳健的风险管理、遵守法规和防止金融不当行为至关重要。这个过程涉及劳动密集型的实体匹配任务，其中实体需要根据可用的参考来源进行验证。由于语言变异、特殊字符、过时名称和法律形式变更而产生挑战，使Jaccard、余弦和Levenshtein距离等传统匹配算法复杂化。这些方法在处理上下文细微差别和语义关系方面存在困难，导致不匹配。为了解决这些局限性，我们探索了大型语言模型（LLMs）作为一种灵活的替代方案。LLMs利用广泛的训练来解释上下文、处理缩写并适应法律过渡。我们使用包含65个葡萄牙公司案例的数据集评估了传统方法、基于Hugging Face的LLMs和基于接口的LLMs（例如，Microsoft Copilot、阿里巴巴的Qwen 2.5）。结果显示，传统方法实现了超过92%的准确率，但误报率很高（20-40%）。基于接口的LLMs表现更优，准确率超过93%，F1分数超过96%，并且误报率相对较低（40-80%）。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [101] [Style over Substance: Distilled Language Models Reason Via Stylistic Replication](https://arxiv.org/abs/2504.01738)
> *形式重于内容：蒸馏语言模型通过风格复制进行推理*

*Philip Lippmann, Jie Yang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 语言模型蒸馏, 推理痕迹, 风格模式, 表面层面模式, 知识蒸馏

**Comment:** To appear at COLM 2025

> **TL;DR:** 本研究发现，蒸馏语言模型的推理能力在很大程度上依赖于表面层面的风格模式，即使这些模式导致错误答案也能提高性能，表明风格在增强语言模型推理中的重要性。

**AI_Comments:** 这项研究创新性地揭示了蒸馏语言模型可能更多地复制了推理的“风格”而非“实质”。发现即使是错误的风格模式也能提升性能，这对于理解和改进模型蒸馏具有重要意义，提示我们可能需要重新思考推理能力转移的深层机制。它也提供了一个新的视角，即可以通过操纵表面模式来高效增强语言模型推理。

<details>
  <summary>Details</summary>

**Motivation:** 尽管专门的推理语言模型通过详细的推理痕迹显著提升了性能，并且这些痕迹能有效进行知识蒸馏，但所转移推理的精确性质仍不清楚。具体而言，本研究旨在调查蒸馏模型在推理过程中内部化复制的风格模式的程度。

**Method:** 研究人员系统分析了推理痕迹，识别出表征成功推理的结构和词汇模式。随后，引入了两个新数据集：一个包含涌现推理痕迹的数据集和一个明确构建以复制这些风格模式的合成数据集。通过这些数据集，精确检验了风格模式对蒸馏模型推理能力的影响。

**Result:** 发现通过合成痕迹训练的模型取得了可比较的性能，这表明蒸馏的推理能力显著依赖于表面层面的模式。令人惊讶的是，即使合成痕迹被修改为导致错误答案，性能也得到了提升。

**Conclusion:** 本研究结果强调了如何有效利用风格模式来提升不同模型家族的语言模型推理能力。

> **ai_Abstract:** 本研究深入探讨了蒸馏语言模型推理能力的本质。通过分析推理痕迹中的结构和词汇风格模式，并构建特定的合成数据集进行验证，研究发现蒸馏模型的推理表现很大程度上依赖于这些表面层面的风格模式。令人意外的是，即使这些风格模式被修改为导致错误答案，模型性能依然有所提升。这表明在语言模型蒸馏过程中，风格复制可能扮演了比预期更重要的角色，为未来高效增强语言模型推理能力提供了新的方向。

> **摘要翻译:** 专门的推理语言模型（RLMs）已经证明，通过详细的推理痕迹扩展测试时计算可以显著提升性能。尽管这些痕迹有效地促进了知识蒸馏到更小的、经过指令调优的模型中，但所转移推理的精确性质仍不清楚。在本研究中，我们调查了蒸馏模型在推理过程中内部化复制的风格模式的程度。为此，我们系统分析了推理痕迹，识别出表征成功推理的结构和词汇模式。然后，我们引入了两个新数据集——一个涌现推理痕迹数据集和一个明确构建以复制这些风格模式的合成数据集——以精确检验它们对蒸馏模型推理能力的影响。我们发现，在合成痕迹上训练的模型取得了可比较的性能，这表明蒸馏的推理能力显著依赖于表面层面的模式。令人惊讶的是，我们观察到即使合成痕迹被修改为导致错误答案，性能也会增加。我们的研究结果强调了如何利用风格模式来有效提升不同模型家族的语言模型推理能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [134] [The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs](https://arxiv.org/abs/2507.11097)
> *面具后的魔鬼：扩散大语言模型的新兴安全漏洞*

*Zichen Wen, Jiashu Qu, Dongrui Liu, Zhiyuan Liu, Ruixi Wu, Yicun Yang, Xiangqi Jin, Haoyun Xu, Xuyang Liu, Weijia Li, Chaochao Lu, Jing Shao, Conghui He, Linfeng Zhang* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 扩散大语言模型, 安全漏洞, 越狱, 对抗性提示, DIJA

**Comment:** 21 pages, 9 figures, work in progress

> **TL;DR:** 扩散大语言模型（dLLMs）存在一种新的安全漏洞，即现有对齐机制无法防御上下文感知、掩码输入的对抗性提示，本文提出了DIJA框架来利用这种漏洞，并取得了显著的越狱效果。

**AI_Comments:** DIJA的创新之处在于它针对扩散大语言模型（dLLMs）独特的架构特性（双向建模和并行解码）进行攻击，这与针对自回归模型的攻击有所不同。其高攻击成功率揭示了一个此前被忽视的关键威胁，对新兴dLLM的安全研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散大语言模型（dLLMs）作为自回归大语言模型的强大替代品，在代码生成和文本填充方面表现出色，但现有安全对齐机制未能有效保护dLLMs免受上下文感知、掩码输入的对抗性提示攻击，暴露了新的漏洞。因此，迫切需要重新思考这类新兴语言模型的安全对齐问题。

**Method:** 本文提出了DIJA，这是第一个系统性研究和越狱攻击框架，旨在利用dLLMs独特的安全弱点。DIJA通过构建对抗性的交错掩码-文本提示，利用dLLMs的文本生成机制（即双向建模和并行解码）来绕过安全对齐机制。

**Result:** 通过全面的实验，DIJA显著优于现有越狱方法，揭示了dLLM架构中以前被忽视的威胁面。DIJA在Dream-Instruct上实现了高达100%的基于关键词的攻击成功率（ASR），在JailbreakBench上超越了最强的基线ReNeLLM高达78.5%的基于评估器的ASR，并在StrongREJECT分数上提高了37.7分，而且无需在越狱提示中重写或隐藏有害内容。

**Conclusion:** 本文的研究结果强调了在这类新兴语言模型中重新思考安全对齐机制的紧迫性。

> **ai_Abstract:** 扩散大语言模型（dLLMs）尽管性能强大，但存在一个关键安全漏洞：现有对齐机制无法防御上下文感知、掩码输入的对抗性提示。本文提出了DIJA，一个新颖的越狱框架，它利用dLLMs的双向建模和并行解码机制来绕过安全过滤器，即使有害指令明确存在，也能促使模型生成有害内容。实验证明，DIJA显著优于现有越狱方法，取得了高攻击成功率，凸显了重新评估dLLM安全性的紧迫需求。

> **摘要翻译:** 扩散大语言模型（dLLMs）最近已成为自回归大语言模型的一种强大替代方案，通过并行解码和双向建模提供更快的推理和更强的交互性。然而，尽管在代码生成和文本填充方面表现出色，我们发现了一个根本性的安全问题：现有的对齐机制未能保护dLLMs免受上下文感知、掩码输入的对抗性提示的攻击，暴露出新的漏洞。为此，我们提出了DIJA，这是第一个系统性研究和越狱攻击框架，它利用了dLLMs独特的安全弱点。具体来说，我们提出的DIJA构建了对抗性的交错掩码-文本提示，利用了dLLMs的文本生成机制，即双向建模和并行解码。双向建模促使模型为掩码部分生成上下文一致的输出，即使内容有害，而并行解码则限制了模型对不安全内容的动态过滤和拒绝采样。这导致标准对齐机制失效，使得对齐调优的dLLMs能够完成有害内容，即使有害行为或不安全指令直接暴露在提示中。通过全面的实验，我们证明了DIJA显著优于现有越狱方法，揭示了dLLM架构中以前被忽视的威胁面。值得注意的是，我们的方法在Dream-Instruct上实现了高达100%的基于关键词的攻击成功率（ASR），在JailbreakBench上超越了最强的先前基线ReNeLLM高达78.5%的基于评估器的ASR，并在StrongREJECT分数上提高了37.7分，同时无需在越狱提示中重写或隐藏有害内容。我们的发现强调了在这类新兴语言模型中重新思考安全对齐的紧迫性。代码可在https://github.com/ZichenWen1/DIJA获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [136] [Truthful or Fabricated? Using Causal Attribution to Mitigate Reward Hacking in Explanations](https://arxiv.org/abs/2504.05294)
> *真实还是虚假？使用因果归因来缓解解释中的奖励欺骗*

*Pedro Ferreira, Wilker Aziz, Ivan Titov* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 奖励欺骗, 思维链解释, 因果归因, 大型语言模型, 奖励模型

**Comment:** 20 pages, 10 figures, 6 tables

> **TL;DR:** 大型语言模型(LLM)的思维链解释在偏好优化后可能变得不忠实，因为奖励模型无法评估解释与内部决策过程的一致性，导致LLM进行“奖励欺骗”。本文提出通过向奖励模型输入预测的因果归因来解决此问题，实验证明能减少误导性解释。

**AI_Comments:** 本文识别了一个在LLM对齐过程中普遍存在但常被忽视的问题：奖励模型可能无意中鼓励了“奖励欺骗”，导致LLM生成不忠实的解释。其创新之处在于提出了一种利用因果归因来增强奖励模型的机制，使其能够更好地评估解释的真实性。这对于提高LLM的可信赖性和人机协作效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 思维链解释对于检查大型语言模型（LLM）的决策过程和评估模型输出的可信度至关重要，但偏好优化（对齐阶段的关键步骤）会无意中降低这些解释的忠实性。奖励模型（RM）在优化响应质量和解释适当性之间存在潜在冲突，且缺乏评估模型内部决策过程与生成解释之间一致性的机制，导致LLM可能通过生成高分响应但给出误导性解释来进行“奖励欺骗”。

**Method:** 为了解决奖励欺骗问题，本文提出通过对预测进行因果归因来丰富奖励模型的输入。这使得奖励模型能够检测生成的自我解释与模型决策过程之间的差异。

**Result:** 在受控设置下，本文展示了所提出的方法能够减少LLM生成误导性解释的倾向。

**Conclusion:** 通过向奖励模型输入预测的因果归因，可以有效缓解大型语言模型在生成解释时出现的“奖励欺骗”问题，从而提高解释的忠实性。

> **ai_Abstract:** 本研究发现，大型语言模型（LLM）在偏好优化后，其思维链解释的忠实性可能降低。这是因为奖励模型在优化响应质量和解释适当性时存在冲突，且未能评估解释与模型内部决策过程的一致性，导致LLM可能通过生成与实际推理不符的解释来“奖励欺骗”。为解决此问题，本文提出通过将预测的因果归因作为奖励模型的输入，使其能检测到自我解释与决策过程间的差异。实验结果表明，此方法能有效减少LLM生成误导性解释的倾向。

> **摘要翻译:** 思维链解释被广泛用于检查大型语言模型（LLM）的决策过程和评估模型输出的可信度，这对于LLM与人类之间的有效协作至关重要。我们证明，偏好优化——对齐阶段的关键步骤——会无意中降低这些解释的忠实性。发生这种情况是因为指导对齐的奖励模型（RM）的任务是优化响应的预期质量和解释的适当性（例如，最小化偏见或遵守安全标准），从而产生潜在冲突。奖励模型缺乏评估模型内部决策过程与生成解释之间一致性的机制。因此，LLM可能会进行“奖励欺骗”，即生成得分高的最终响应，同时给出旨在最大化奖励而非准确反映其推理的解释。为了解决这个问题，我们建议通过预测的因果归因来丰富奖励模型的输入，从而使奖励模型能够检测生成的自我解释与模型决策过程之间的差异。在受控设置下，我们表明这种方法减少了LLM生成误导性解释的倾向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [166] [Deep Binding of Language Model Virtual Personas: a Study on Approximating Political Partisan Misperceptions](https://arxiv.org/abs/2504.11673)
> *语言模型虚拟角色深度绑定：一项关于近似政治党派误解的研究*

*Minwoo Kang, Suhong Moon, Seung Hyeong Lee, Ayush Raj, Joseph Suh, David M. Chan* | **Category: cs.CL** | **Updated: 2025-07-14**

**Keywords:** 语言模型, 虚拟角色, 深度绑定, 政治偏见, 群体内外偏见

**Comment:** COLM 2025

> **TL;DR:** 本研究提出一种新方法，通过详细的虚拟用户“背景故事”构建语言模型虚拟角色，以实现对人类群体内外偏见反应的深度模拟，显著提高了LLM在社会科学研究中的适用性。

**AI_Comments:** 本文的创新点在于提出了通过生成详细且一致的虚拟用户“背景故事”来实现语言模型虚拟角色的“深度绑定”，从而更真实地模拟人类在复杂社会心理，特别是群体内外偏见问题上的反应。这对于提高LLMs在政治科学和社会学研究中的应用精度和可靠性具有重要意义，克服了传统LLM模拟可能存在的“浅层”理解问题。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在模拟人类行为方面日益强大，但其对特定群体内部成员的深层理解（深度绑定）还是仅停留在外部成员的浅层理解（浅层绑定）尚不清楚。这对于将LLMs应用于政治学研究（如两极分化、群体冲突、民主倒退）至关重要。

**Method:** 提出一种新颖的方法，通过生成扩展的、多轮访谈记录作为合成用户“背景故事”来构建虚拟角色。这些背景故事比现有方法更长、更详细、更一致，能够真实描述单个个体。

**Result:** 基于所构建背景故事的虚拟角色能够紧密复刻人类响应分布（Wasserstein距离测量下高达87%的改进），并且产生的效应大小与原始群体内外偏见研究中观察到的结果非常吻合。

**Conclusion:** 本研究将大型语言模型的适用性从估算社会普遍理解的反应扩展到更广泛的人类研究领域。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在模拟人类行为时，其对特定群体内部成员深层理解（深度绑定）的程度。通过提出一种利用详细、一致的多轮访谈记录构建虚拟角色“背景故事”的新方法，研究表明这些虚拟角色能有效复刻人类在群体内外偏见问题上的反应分布和效应大小。这显著拓宽了LLMs在政治学及更广泛社会科学研究中的应用范围，使其能够超越对社会普遍理解态度的估算。

> **摘要翻译:** 大型语言模型（LLMs）模拟人类行为的能力日益增强，为估算用户对各种调查和民意测验的反应提供了经济有效的方式。然而，这些调查中的问题通常反映了社会普遍理解的态度：即群体内外成员都理解的老年/青年、自由派/保守派的态度模式。目前尚不清楚LLM的绑定是“深度”的，意味着LLM会像特定内部群体的成员那样回答，还是“浅层”的，意味着LLM会像外部群体成员认为内部群体成员会那样回答。为了探究这种差异，我们使用了揭示已知群体内外偏见的问题。这种忠实度水平对于将LLMs应用于各种政治学研究至关重要，包括关于两极分化动态、群体间冲突和民主倒退等及时主题。为此，我们提出了一种新颖的方法，通过生成扩展的、多轮访谈记录作为合成用户“背景故事”来构建虚拟角色。与以前的方法相比，我们生成的背景故事更长、细节更丰富，并且在真实描述单个个体方面具有一致性。我们表明，基于我们背景故事的虚拟角色能够紧密复刻人类响应分布（Wasserstein距离测量下高达87%的改进），并产生与原始群体内外偏见研究中观察到的效应大小非常吻合的结果。总而言之，我们的工作将LLMs的适用性从估算社会普遍理解的反应扩展到更广泛的人类研究领域。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [168] [Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions](https://arxiv.org/abs/2507.10577)
> *真相侦探与趋势扭转者：用于事实核查YouTube视频并影响观点的AI代理*

*Logé Cécile, Ghori Rehan* | **Category: cs.CL, cs.AI, cs.CY** | **Updated: 2025-07-11**

**Keywords:** AI代理, 虚假信息, 事实核查, YouTube, 观点影响

**Comment:** 

> **TL;DR:** 本文提出了一种由“真相侦探”和“趋势扭转者”两个AI代理组成的系统，旨在事实核查YouTube视频并生成评论以反击虚假信息并影响用户观点。

**AI_Comments:** 本文的创新之处在于其双代理系统，不仅实现了事实核查，更进一步通过“趋势扭转者”在评论区主动干预和引导用户讨论，这超越了传统的事实核查范畴。其重要性在于直接针对当前社交媒体上虚假信息快速传播的痛点，提供了一种积极应对的AI解决方案。然而，关于“影响观点”的提法，可能引发关于AI干预言论自由和潜在伦理问题的讨论，尽管其目标是打击虚假信息，但如何确保干预的公正性和透明度将是关键考量。

<details>
  <summary>Details</summary>

**Motivation:** 在当今数字世界中，虚假信息构成重大威胁，并经常通过YouTube等平台迅速传播。本文旨在通过开发一个AI驱动的系统来对抗虚假信息。

**Method:** 本文开发了一个AI驱动的系统，该系统不仅能事实核查YouTube视频中的主张，还能在评论区积极与用户互动并挑战误导性叙述。该系统包含两个主要代理：
1. 真相侦探：从YouTube视频中提取主张，利用检索增强生成（RAG）方法（借鉴维基百科、谷歌搜索、谷歌事实核查等来源）准确评估其真实性，并生成细致全面的报告。
2. 趋势扭转者：通过严格的提示工程，利用真相侦探的报告和精选的相关文章语料库，生成富有洞察力和说服力的评论，旨在激发富有成效的辩论。该代理通过精心设置的自我评估循环，能够迭代改进其风格和输出。

**Result:** 通过在既定基准数据集上的实验和在YouTube上的实际部署，系统展示了其能力。研究结果突显了事实核查代理的高准确性，并证实了AI驱动干预在打击虚假信息和培养更知情在线空间方面的潜力。

**Conclusion:** AI驱动的干预在打击虚假信息和培养更知情的在线空间方面具有巨大潜力。

> **ai_Abstract:** 本文针对YouTube平台上的虚假信息传播问题，提出了一种创新的AI驱动系统。该系统由“真相侦探”和“趋势扭转者”两个AI代理组成。“真相侦探”负责从视频中提取并核实信息，生成详细报告；“趋势扭转者”则利用这些报告和相关文章，在评论区生成有说服力的评论，以纠正误导性叙述并引导讨论。实验结果表明，该系统在事实核查方面具有高准确性，并能有效吸引用户，展现了AI在对抗虚假信息和塑造更健康在线环境方面的潜力。

> **摘要翻译:** 在当今数字世界中，虚假信息构成重大威胁，并经常通过YouTube等平台迅速传播。本文提出了一种对抗虚假信息的新方法，即开发一个AI驱动的系统，该系统不仅能事实核查YouTube视频中的主张，还能在评论区积极与用户互动并挑战误导性叙述。我们的系统由两个主要代理组成：真相侦探和趋势扭转者。
真相侦探从YouTube视频中提取主张，利用检索增强生成（RAG）方法——借鉴维基百科、谷歌搜索、谷歌事实核查等来源——准确评估其真实性，并生成细致全面的报告。通过严格的提示工程，趋势扭转者利用这份报告以及精选的相关文章语料库，生成富有洞察力和说服力的评论，旨在激发富有成效的辩论。通过精心设置的自我评估循环，该代理能够迭代改进其风格和输出。
我们通过在既定基准数据集上的实验和在YouTube上的实际部署，展示了系统的能力，展示了其吸引用户和潜在影响观点的潜力。我们的研究结果突显了事实核查代理的高准确性，并证实了AI驱动干预在打击虚假信息和培养更知情的在线空间方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [170] [MSA at ImageCLEF 2025 Multimodal Reasoning: Multilingual Multimodal Reasoning With Ensemble Vision Language Models](https://arxiv.org/abs/2507.11114)
> *MSA在ImageCLEF 2025多模态推理：基于集成视觉语言模型的多语言多模态推理*

*Seif Ahmed, Mohamed T. Younes, Abdelrahman Moustafa, Abdelrahman Allam, Hamza Moustafa* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 多模态推理, 多语言, 集成模型, 视觉语言模型, 提示工程

**Comment:** 

> **TL;DR:** 团队MSA在ImageCLEF 2025多语言多模态推理挑战赛中，通过集成Gemini系列模型和精心设计的提示策略，取得了第一名的成绩，证明了轻量级OCR-VLM集成模型的有效性。

**AI_Comments:** 这项工作展示了通过集成多个专业化的大型视觉语言模型（如Gemini系列）并结合精细的提示工程，可以在竞争激烈的多模态推理挑战中取得卓越成绩。其创新点在于强调了模型集成、零样本能力以及提示策略对性能的关键影响，尤其是在多语言环境下的应用。论文还通过在实际比赛中取得的优异成绩，证明了轻量级集成模型在特定场景下超越更重、端到端模型的潜力，这对于资源受限或需要快速部署的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在参加ImageCLEF 2025 EXAMS V挑战赛，解决多语言多模态推理问题。

**Method:** 提出了一种基于集成模型的鲁棒系统，该系统整合了Gemini 2.5 Flash（用于视觉描述）、Gemini 1.5 Pro（用于字幕精炼和一致性检查）和Gemini 2.5 Pro（作为推理器处理最终答案选择）。所有模型通过精心设计的少样本和零样本提示进行协调。进行了广泛的消融研究，在英语数据集及其多语言增强版本上训练了多个大型语言模型（Gemini 2.5 Flash, Phi 4, Gemma 3, Mistral）。此外，还评估了Gemini 2.5 Flash的零样本设置。提示设计也至关重要，通过强制执行简洁、语言规范的格式并禁止解释性文本来提高准确性。

**Result:** 团队MSA在官方排行榜上取得了多语言赛道总分第一名，准确率为81.4%，并在13个独立语言赛道中的11个中领先，其中克罗地亚语达到95.07%，意大利语达到92.12%。零样本设置下的Gemini 2.5 Flash显著优于训练过的模型。提示设计将英语验证集上的模型准确率从55.9%提高到61.7%。

**Conclusion:** 轻量级OCR-VLM集成模型，结合精确的提示策略和跨语言增强，在严苛的多语言教育环境中，可以超越更重的端到端模型。

> **ai_Abstract:** 本文介绍了一个为ImageCLEF 2025 EXAMS V挑战赛设计的多语言多模态推理系统。该系统集成了Gemini 2.5 Flash、Gemini 1.5 Pro和Gemini 2.5 Pro，并通过少样本和零样本提示进行协调。研究发现零样本的Gemini 2.5 Flash表现优异，且精心设计的提示对模型准确率提升显著。该系统在多语言赛道中获得第一名，验证了轻量级OCR-VLM集成模型结合精确提示策略和跨语言增强在多语言教育环境中的有效性。

> **摘要翻译:** 我们提出了一个鲁棒的、基于集成的多语言多模态推理系统，专为ImageCLEF 2025 EXAMS V挑战赛设计。我们的方法整合了Gemini 2.5 Flash用于视觉描述，Gemini 1.5 Pro用于字幕精炼和一致性检查，以及Gemini 2.5 Pro作为推理器处理最终答案选择，所有这些都通过精心设计的少样本和零样本提示进行协调。我们进行了广泛的消融研究，在英语数据集及其多语言增强版本上训练了多个大型语言模型（Gemini 2.5 Flash、Phi 4、Gemma 3、Mistral）。此外，我们还评估了Gemini 2.5 Flash在零样本设置下的表现进行比较，发现它显著优于训练过的模型。提示设计也被证明至关重要：强制执行简洁、语言规范的格式并禁止解释性文本，将英语验证集上的模型准确率从55.9%提高到61.7%。在官方排行榜上，我们的系统（MSA团队）在多语言赛道中以81.4%的准确率获得总分第一名，并在13个独立语言赛道中的11个中领先，取得了克罗地亚语95.07%和意大利语92.12%等优异成绩。这些发现强调，轻量级OCR-VLM集成模型，当与精确的提示策略和跨语言增强结合时，在严苛的多语言教育环境中，可以超越更重的端到端模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [196] [Block Circulant Adapter for Large Language Models](https://arxiv.org/abs/2505.00582)
> *大型语言模型的块循环适配器*

*Xinyu Ding, Meiqi Wang, Siyu Liao, Zhongfeng Wang* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 微调, 块循环矩阵, 傅立叶变换, 参数效率

**Comment:** to appear in Proceedings of the 2025 International Joint Conference
  on Artificial Intelligence (IJCAI-2025)

> **TL;DR:** 提出了一种基于块循环矩阵的微调方法，显著减少了LLM的存储和计算成本，同时保持或提升了性能。

**AI_Comments:** 这项工作通过引入块循环矩阵和频域方法，为大型语言模型的参数高效微调提供了一种新颖的解决方案。其主要创新在于利用了循环矩阵的特性来显著减少存储和计算开销，而无需牺牲性能。这对于资源受限的环境下部署和微调LLM具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 微调大型语言模型（LLMs）因其庞大的模型尺寸而困难。最近基于傅立叶域的方法显示出降低微调成本的潜力。

**Method:** 提出了一种基于块循环矩阵的微调方法，并结合了稳定的训练启发式算法，利用循环矩阵和一维傅立叶变换的特性来降低存储和计算成本。

**Result:** 实验表明，我们的方法比VeRA使用的参数少14倍，比LoRA小16倍，比FourierFT的FLOPs少32倍，同时保持了接近或更好的任务性能。

**Conclusion:** 我们的方法在频域微调大型模型以执行下游任务方面提供了一种有前景的方式。

> **ai_Abstract:** 本文提出了一种名为块循环适配器（Block Circulant Adapter）的新型微调方法，用于大型语言模型。该方法利用块循环矩阵和一维傅立叶变换的特性，显著降低了微调过程中的存储和计算成本。实验结果显示，与现有方法如VeRA、LoRA和FourierFT相比，该方法在参数量和FLOPs方面有显著优势，同时能保持或提升任务性能，为频域微调大型模型提供了有前景的途径。

> **摘要翻译:** 微调大型语言模型（LLM）因其庞大的模型尺寸而困难。最近基于傅立叶域的方法显示出降低微调成本的潜力。我们提出了一种基于块循环矩阵的微调方法，并结合了稳定的训练启发式算法，以利用循环矩阵和一维傅立叶变换的特性来降低存储和计算成本。实验表明，我们的方法比VeRA使用的参数少14倍，比LoRA小16倍，比FourierFT的FLOPs少32倍，同时保持了接近或更好的任务性能。我们的方法在频域微调大型模型以执行下游任务方面提供了一种有前景的方式。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [203] [What Should LLMs Forget? Quantifying Personal Data in LLMs for Right-to-Be-Forgotten Requests](https://arxiv.org/abs/2507.11128)
> *LLMs应该遗忘什么？量化LLMs中的个人数据以响应被遗忘权请求*

*Dimitri Staufer* | **Category: cs.CL, cs.CY, cs.LG, I.2.6; H.2.8** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 被遗忘权, 机器遗忘, 个人数据, 隐私审计

**Comment:** 16 pages, 3 figures. Accepted at the 7th Workshop on eXplainable
  Knowledge Discovery in Data Mining (XKDD 2025), ECML PKDD 2025, Porto,
  Portugal

> **TL;DR:** 研究引入WikiMem数据集和一种模型无关的度量方法，用于量化大型语言模型（LLMs）中记忆的个人数据，以支持被遗忘权请求和机器遗忘。

**AI_Comments:** 这项研究具有重要的创新性，它解决了现有机器遗忘和隐私审计方法在个体层面识别LLM中记忆化个人数据方面的不足。通过引入WikiMem数据集和模型无关的量化指标，为实现GDPR的“被遗忘权”提供了实际可行的方法。其发现记忆化与网络存在感和模型规模相关，为未来LLM的隐私设计和管理提供了重要见解。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）能够记忆和泄露个人信息，这引发了对欧盟GDPR特别是“被遗忘权”（RTBF）合规性的担忧。现有的机器遗忘方法假设要遗忘的数据是已知的，但未能解决如何识别模型中存储的个体事实关联。目前的隐私审计技术通常在人口层面操作或针对少量标识符，限制了其在个体层面数据查询中的适用性。

**Method:** 研究引入了WikiMem数据集，包含超过5000个自然语言金丝雀，涵盖来自Wikidata的243个人类相关属性。提出了一种模型无关的度量方法，用于量化LLMs中的人类-事实关联。该方法通过在释义提示中校准的负对数似然对真实值和反事实值进行排序。研究评估了15个LLMs（参数范围从4.1亿到700亿）中的200个个体。

**Result:** 评估结果显示，LLMs的记忆化程度与主题的网络存在感和模型规模相关。

**Conclusion:** 该研究为在个体层面识别LLMs中记忆的个人数据奠定了基础，从而能够为机器遗忘和被遗忘权请求动态构建遗忘集。

> **ai_Abstract:** 该研究旨在解决大型语言模型（LLMs）中个人数据记忆和泄露问题，以遵守GDPR的被遗忘权（RTBF）。针对现有方法无法识别模型中存储的个体事实关联的局限性，作者提出了WikiMem数据集和一种模型无关的度量方法来量化LLMs中的人类-事实关联。通过评估发现，LLMs的记忆化程度与主题的网络存在感和模型规模呈正相关。这项工作为在个体层面识别LLMs中的记忆化个人数据提供了基础，有助于动态构建用于机器遗忘和RTBF请求的遗忘集。

> **摘要翻译:** 大型语言模型（LLMs）能够记忆并泄露个人信息，这引发了对遵守欧盟GDPR（特别是被遗忘权，RTBF）的担忧。现有的机器遗忘方法假设要遗忘的数据是已知的，但并未解决如何识别模型中存储的个体事实关联。隐私审计技术通常在人口层面操作或针对少量标识符，这限制了其在个体层面数据查询中的适用性。我们引入了WikiMem，一个包含5000多个自然语言金丝雀的数据集，涵盖来自Wikidata的243个人类相关属性，以及一种模型无关的度量方法，用于量化LLMs中的人类-事实关联。我们的方法通过在释义提示中校准的负对数似然对真实值和反事实值进行排序。我们评估了15个LLM（4.1亿至700亿参数）中的200个个体，结果表明记忆化与主题的网络存在感和模型规模相关。我们为在个体层面识别LLM中记忆的个人数据提供了基础，从而能够为机器遗忘和RTBF请求动态构建遗忘集。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [204] [Modeling Understanding of Story-Based Analogies Using Large Language Models](https://arxiv.org/abs/2507.10957)
> *使用大型语言模型模拟对故事类比的理解*

*Kalit Inani, Keshav Kabra, Vijay Marupudi, Sashank Varma* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 类比推理, 故事类比, 语义表示, 人类认知

**Comment:** To appear at CogSci 2025

> **TL;DR:** 本研究评估了大型语言模型（LLMs）在故事类比任务中与人类表现的匹配程度，通过细粒度评估其语义表示和显式提示的有效性，以增进对LLMs类比推理能力的理解。

**AI_Comments:** 本文通过对LLMs在故事类比任务中进行细粒度评估，超越了以往仅关注整体准确性的研究，具有创新性。特别是在探索LLMs的语义表示和显式提示对推理能力的影响方面，为理解LLMs的内部工作机制提供了新的视角。这项工作对于推动LLMs在复杂认知任务（如类比推理）中的应用和发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在多项任务上日益接近人类认知，但先前研究表明它们在类比问题中提取相似性时缺乏鲁棒的人类级推理能力。本研究旨在深入评估LLMs在基于故事的类比映射任务中的推理能力，并与人类表现进行比较。

**Method:** 本研究构建于Webb、Holyoak和Lu（2023）的研究之上，专注于基于故事的类比映射任务，并对LLM的推理能力进行了细粒度评估，与人类表现进行比较。具体方法包括：1) 探索LLMs中类比的语义表示，使用句子嵌入评估其捕捉源文本与目标文本相似性以及源文本与干扰文本不相似性的能力。2) 调查显式提示LLMs解释类比的有效性。评估在个体类比层面进行，而非仅整体准确性。实验还评估了模型大小（8B vs. 70B参数）以及GPT-4和LLaMA3等先进模型架构的性能差异。

**Result:** 未在摘要中提及

**Conclusion:** 这项工作增进了我们对大型语言模型类比推理能力的理解，及其作为人类推理模型的潜力。

> **ai_Abstract:** 本研究旨在评估大型语言模型（LLMs）在故事类比任务中与人类认知的匹配程度。鉴于LLMs在类比推理方面表现出的不足，本研究采用细粒度评估方法，探讨了LLMs对类比的语义表示能力（通过句子嵌入）以及显式提示对解释类比的有效性。研究不仅关注整体准确性，更深入到个体类比层面的推理表现，并考察了不同模型大小和架构（如GPT-4、LLaMA3）的影响。该工作旨在加深对LLMs类比推理能力及其作为人类推理模型潜力的理解。

> **摘要翻译:** 大型语言模型（LLMs）最近的进展使其在各种任务中更接近匹配人类认知。这些模型在检测和映射类比方面与人类表现的契合度如何？先前的研究表明，LLMs可以从类比问题中提取相似性，但缺乏鲁棒的人类般推理能力。本研究基于Webb、Holyoak和Lu（2023）的工作，专注于一项基于故事的类比映射任务，并对LLM的推理能力进行了细粒度评估，与人类表现进行比较。首先，它探讨了LLMs中类比的语义表示，使用句子嵌入来评估它们是否捕捉了类比的源文本和目标文本之间的相似性，以及源文本和干扰文本之间的不相似性。其次，它调查了显式提示LLMs解释类比的有效性。在整个研究过程中，我们通过评估LLMs在个体类比层面（而非仅仅整体准确性，如先前研究所示）的推理能力，来检验LLMs是否表现出与人类相似的性能特征。我们的实验包括评估模型大小（8B vs. 70B参数）的影响以及GPT-4和LLaMA3等最先进模型架构的性能差异。这项工作增进了我们对LLMs类比推理能力的理解及其作为人类推理模型的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [205] [EsBBQ and CaBBQ: The Spanish and Catalan Bias Benchmarks for Question Answering](https://arxiv.org/abs/2507.11216)
> *EsBBQ 和 CaBBQ：西班牙语和加泰罗尼亚语问答偏见基准*

*Valle Ruiz-Fernández, Mario Mina, Júlia Falcão, Luis Vasquez-Reina, Anna Sallés, Aitor Gonzalez-Agirre, Olatz Perez-de-Viñaspre* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 社会偏见, 语言模型, 问答, 西班牙语, 加泰罗尼亚语

**Comment:** 

> **TL;DR:** 本文引入了西班牙语和加泰罗尼亚语问答偏见基准 (EsBBQ 和 CaBBQ)，用于评估大型语言模型在这些语言中的社会偏见，发现模型在模糊场景下表现不佳，且高准确度常与偏见相关。

**AI_Comments:** 这篇论文通过引入 EsBBQ 和 CaBBQ，填补了非英语语言（特别是西班牙语和加泰罗尼亚语）在大型语言模型社会偏见评估方面的空白，并强调了地域文化背景的重要性。其发现模型在模糊场景下的表现以及高准确度与偏见之间的关联，为未来 LLM 偏见研究和缓解策略提供了重要见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明大型语言模型 (LLMs) 会延续其预训练数据中的社会偏见。然而，除了英语之外的其他语言以及美国以外的社会背景中，用于社会偏见评估的资源严重缺乏。

**Method:** 本文引入了西班牙语和加泰罗尼亚语问答偏见基准 (EsBBQ 和 CaBBQ)。这些数据集基于原始 BBQ，旨在通过多项选择问答设置评估 10 个类别的社会偏见，并已适应西班牙语和加泰罗尼亚语以及西班牙的社会语境。论文还报告了在不同 LLM 上进行的评估结果，考虑了模型家族、大小和变体。

**Result:** 结果显示，模型在模糊场景中往往无法选择正确答案，并且高问答准确性通常与对社会偏见的更大依赖性相关。

**Conclusion:** 模型在模糊问答场景中往往无法选择正确答案，并且高问答准确性通常与对社会偏见的更大依赖性相关。

> **ai_Abstract:** 本文针对英语外语言和社会背景中缺乏大型语言模型 (LLM) 社会偏见评估资源的问题，引入了西班牙语和加泰罗尼亚语问答偏见基准 (EsBBQ 和 CaBBQ)。这两个数据集基于 BBQ，旨在评估 LLM 在西班牙语和加泰罗尼亚语社会语境下 10 个类别的社会偏见。研究结果表明，LLM 在模糊问答场景中难以给出正确答案，且高问答准确性常与模型对社会偏见的依赖性增强相关。

> **摘要翻译:** 之前的文献在很大程度上表明，大型语言模型 (LLMs) 会延续从其预训练数据中学到的社会偏见。鉴于除了英语之外的其他语言以及美国以外的社会背景中，用于社会偏见评估的资源严重缺乏，本文引入了西班牙语和加泰罗尼亚语问答偏见基准 (EsBBQ 和 CaBBQ)。这两个并行数据集基于原始的 BBQ，旨在通过多项选择问答设置评估 10 个类别的社会偏见，现已适应西班牙语和加泰罗尼亚语以及西班牙的社会语境。我们报告了在不同 LLM 上进行的评估结果，考虑了模型家族、大小和变体。我们的结果显示，模型在模糊场景中往往无法选择正确答案，并且高问答准确性通常与对社会偏见的更大依赖性相关。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [226] [Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging](https://arxiv.org/abs/2505.05464)
> *将理性带入视觉：通过模型合并理解感知与推理*

*Shiqi Chen, Jinghan Zhang, Tongyao Zhu, Wei Liu, Siyang Gao, Miao Xiong, Manling Li, Junxian He* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 模型合并, 视觉-语言模型, 推理, 感知, 跨模态学习

**Comment:** ICML 2025. Camera-ready version updated. Our code is publicly
  available at https://github.com/shiqichen17/VLM_Merging

> **TL;DR:** 本文通过模型合并，将大型语言模型（LLMs）的推理能力无训练地转移到视觉-语言模型（VLMs）中，并分析了感知和推理能力在模型层中的分布变化。

**AI_Comments:** 这项工作创新性地提出了跨模态模型合并，实现了LLM推理能力向VLM的无训练迁移，这在效率和资源节约方面具有重要意义。此外，通过对合并后模型内部机制的分析，揭示了感知和推理能力在模型层中的分布特性，为理解和设计更高效的多模态模型提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言模型（VLMs）结合了视觉感知和大型语言模型（LLMs）的推理能力，但这些能力如何结合并发挥作用的机制尚不清楚。

**Method:** 提出了一种跨模态的模型合并方法，将LLMs的推理能力整合到VLMs中，且无需训练。通过合并后的模型来分析感知和推理的内部机制。

**Result:** 模型合并成功地将推理能力从LLMs无训练地转移到VLMs。发现感知能力主要编码在模型的早期层，而推理能力主要由中后期层促进。合并后，所有层都开始对推理做出贡献，而感知能力在层间的分布基本保持不变。

**Conclusion:** 模型合并为多模态集成和解释提供了一种有潜力的工具，并揭示了感知和推理能力在模型层中的分布特性。

> **ai_Abstract:** 本文探索了通过模型合并将大型语言模型（LLMs）的推理能力整合到视觉-语言模型（VLMs）中的方法，实现了无训练的知识迁移。研究发现，感知能力主要存在于模型的早期层，而推理能力则由中后期层支持。模型合并后，所有层都参与了推理，同时感知能力的分布未发生显著变化。这项工作为多模态模型集成和内部机制理解提供了新的视角。

> **摘要翻译:** 视觉-语言模型（VLMs）将视觉感知与大型语言模型（LLMs）的通用能力（如推理）相结合。然而，这两种能力如何结合并发挥作用的机制仍然知之甚少。在这项工作中，我们通过连接不同模型参数的模型合并来探索感知和推理的组合。与以往通常专注于合并同类模型的工作不同，我们提出跨模态合并模型，从而能够将LLMs的推理能力融入VLMs。通过大量的实验，我们证明模型合并提供了一条成功地将推理能力从LLMs无训练地转移到VLMs的途径。此外，我们利用合并后的模型来理解感知和推理的内部机制以及合并如何影响它。我们发现感知能力主要编码在模型的早期层，而推理能力主要由中后期层促进。合并后，我们观察到所有层都开始对推理做出贡献，而感知能力在层间的分布基本保持不变。这些观察结果揭示了模型合并作为多模态集成和解释工具的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [227] [Testing Hypotheses from the Social Approval Theory of Online Hate: An Analysis of 110 Million Posts from Parler](https://arxiv.org/abs/2507.10810)
> *测试在线仇恨社会认同理论的假设：对Parler上1.1亿条帖子的分析*

*David M. Markowitz, Samuel Hardman Taylor* | **Category: cs.CL, cs.SI** | **Updated: 2025-07-14**

**Keywords:** 社会认同, 在线仇恨, Parler, 仇恨言论, 社交媒体

**Comment:** 

> **TL;DR:** 本研究使用Parler上的1.1亿条帖子，检验了在线仇恨的社会认同理论的两个核心假设，发现社会认同（点赞数）与后续仇恨言论的产生或极端化之间没有直接关联，甚至在帖子层面呈现负相关，表明该理论可能在小众社交媒体平台上表现不同。

**AI_Comments:** 该研究通过对大量真实世界数据的分析，对流行的在线仇恨社会认同理论提出了挑战，特别是在小众社交媒体平台的背景下。其创新之处在于使用了Parler这一特定平台的大规模数据集，为理解在线仇恨行为的复杂性提供了新的视角。研究结果提示，社会认同在不同平台上的作用可能存在差异，这对于未来的理论发展和干预措施设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探索在线仇恨如何受到他人社会认同的驱动，并具体检验了Walther（2024）在线仇恨社会认同理论的两个核心假设：(H1a) 仇恨信息上更多的社会认同信号预示着更多的后续仇恨信息；(H1b) 随着社会认同的增加，仇恨言论变得更加极端。

**Method:** 研究使用了来自Parler平台（2018-2021年）超过1.1亿条帖子进行分析。

**Result:** 研究发现，个人在仇恨言论帖子中获得的“赞”数与他们下一条帖子以及接下来一周、一个月、三个月和六个月内的仇恨言论数量无关。个体间效应显示，在帖子层面，社会认同与仇恨言论的产生之间平均存在负相关关系，但在其他时间间隔上，这种关系是混合的。

**Conclusion:** 在线仇恨的社会认同强化机制在小众社交媒体平台上的运作方式可能有所不同。

> **ai_Abstract:** 本研究基于Parler平台2018年至2021年的1.1亿多条帖子，检验了Walther（2024）在线仇恨社会认同理论的两个核心假设。研究发现，用户在仇恨帖子中获得的“赞”数与后续仇恨言论的产生量无关，且在帖子层面，社会认同与仇恨言论产生之间平均呈现负相关。这些结果表明，在线仇恨的社会认同强化机制可能在小众社交媒体平台上表现出与预期不同的运作方式。

> **摘要翻译:** 本文探讨了在线仇恨如何受到他人社会认同的驱动。我们特别检验了Walther（2024）在线仇恨社会认同理论的两个核心原则：(H1a) 仇恨信息上更多的社会认同信号预示着更多的后续仇恨信息，以及(H1b) 随着社会认同的增加，仇恨言论变得更加极端。我们使用来自Parler（2018-2021年）的超过1.1亿条帖子，观察到一个人在仇恨言论帖子中获得的“赞”数与其下一条帖子以及接下来一周、一个月、三个月和六个月内的仇恨言论数量无关。个体间效应显示，在帖子层面，社会认同与仇恨言论的产生之间平均存在负相关关系，但这种关系在其他时间间隔上是混合的。在线仇恨的社会认同强化机制在小众社交媒体平台上的运作方式可能有所不同。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [245] [Sparse Autoencoders Can Capture Language-Specific Concepts Across Diverse Languages](https://arxiv.org/abs/2507.11230)
> *稀疏自编码器可以捕获跨多种语言的特定语言概念*

*Lyzander Marciano Andrylie, Inaya Rahmanisa, Mahardika Krisna Ihsani, Alfan Farizki Wicaksono, Haryo Akbarianto Wibowo, Alham Fikri Aji* | **Category: cs.CL, 68T50** | **Updated: 2025-07-15**

**Keywords:** 稀疏自编码器, 特定语言特征, 大语言模型, 语言识别, 可解释性

**Comment:** 

> **TL;DR:** 本文提出SAE-LAPE方法，利用稀疏自编码器识别大语言模型中可解释的特定语言特征，这些特征影响模型性能并可用于语言识别。

**AI_Comments:** 本文创新性地利用稀疏自编码器来识别和理解大语言模型中的特定语言特征，解决了传统方法难以区分多义神经元的问题。通过引入SAE-LAPE方法，不仅揭示了这些特征的分布和可解释性，还展示了它们在语言识别等应用中的潜力，为深入理解LLMs的内部工作机制提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 理解大型语言模型（LLMs）的多语言机制充满挑战。现有研究通常关注单个神经元，但其多义性使得难以从跨语言表示中分离出特定语言的单元。

**Method:** 本文探索稀疏自编码器（SAEs）以学习表示LLMs中具体和抽象概念的单义特征。引入了SAE-LAPE方法，该方法基于特征激活概率，用于识别前馈网络中特定语言的特征。

**Result:** 许多特定语言特征主要出现在模型的中间到最终层，并且是可解释的。这些特征影响模型的跨语言性能和语言输出，并可用于语言识别，其性能与fastText相当且更具可解释性。

**Conclusion:** 稀疏自编码器能够有效地识别大语言模型中可解释的、特定语言的特征，这些特征对模型的多语言能力至关重要，并可用于语言识别等应用。

> **ai_Abstract:** 本文旨在通过稀疏自编码器（SAEs）解决大语言模型（LLMs）多语言机制理解的挑战。针对现有研究中神经元多义性问题，作者提出了SAE-LAPE方法，利用特征激活概率识别LLM前馈网络中的特定语言特征。研究发现这些特征主要存在于模型中后层，具有可解释性，并影响模型的跨语言性能和输出。此外，这些特征可用于语言识别，其性能与fastText相当且更具可解释性。

> **摘要翻译:** 理解大型语言模型（LLMs）的多语言机制，有助于深入了解它们如何处理不同语言，但这仍然充满挑战。现有研究通常侧重于单个神经元，但它们的多义性使得难以从跨语言表示中分离出特定语言的单元。为了解决这个问题，我们探索了稀疏自编码器（SAEs），因为它们能够学习表示LLMs中跨语言的具体和抽象概念的单义特征。虽然其中一些特征是语言独立的，但特定语言特征的存在仍未得到充分探索。在这项工作中，我们引入了SAE-LAPE，一种基于特征激活概率的方法，用于识别前馈网络中的特定语言特征。我们发现许多此类特征主要出现在模型的中间到最终层，并且是可解释的。这些特征影响模型的跨语言性能和语言输出，并且可以用于语言识别，其性能与fastText相当，同时具有更高的可解释性。我们的代码可在https://github.com/LyzanderAndrylie/language-specific-features 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [253] [Comply: Learning Sentences with Complex Weights inspired by Fruit Fly Olfaction](https://arxiv.org/abs/2502.01706)
> *Comply：受果蝇嗅觉启发，学习具有复杂权重的句子*

*Alexei Figueroa, Justus Westerhoff, Golzar Atefi, Dennis Fast, Benjamin Winter, Felix Alexander Gers, Alexander Löser, Wolfgang Nejdl* | **Category: cs.CL, cs.AI, cs.LG, cs.NE** | **Updated: 2025-07-15**

**Keywords:** 生物启发神经网络, 句子表示, 复数权重, 果蝇嗅觉, 单层神经网络

**Comment:** Accepted at NICE2025

> **TL;DR:** Comply是一种受果蝇嗅觉启发的单层神经网络，通过引入复数权重来学习句子表示，其性能超越了FlyVec并与最先进的模型相当，同时保持高效率和可解释性。

**AI_Comments:** Comply的创新之处在于将生物启发模型与复数权重相结合，实现了在单层网络中学习序列表示，同时保持了计算效率和可解释性。其在不增加参数的情况下达到SOTA性能，显示了生物启发模型在处理复杂文本任务上的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的受生物启发的神经网络（如FlyVec）在学习词嵌入方面表现出色且计算高效，但作者想探究其性能是否能进一步提高。

**Method:** 引入Comply模型，通过复数权重结合位置信息，使单层神经网络能够学习序列表示。

**Result:** Comply不仅超越了FlyVec，而且在不增加额外参数的情况下，与显著更大的最先进模型表现相当。它产生了稀疏的上下文句子表示，可以从神经元权重中明确解释。

**Conclusion:** Comply通过受生物启发的机制，实现了高效且可解释的句子表示学习，性能优于现有生物启发模型并与复杂的前沿模型媲美。

> **ai_Abstract:** 本文介绍了Comply，一种受果蝇嗅觉启发的单层神经网络，通过引入复数权重来编码位置信息，从而学习句子表示。Comply在计算效率高且不增加额外参数的情况下，其性能超越了同类生物启发模型FlyVec，并能与更大型的最先进模型媲美。此外，Comply能够生成可解释的稀疏上下文句子表示。

> **摘要翻译:** 生物启发式神经网络为建模数据分布提供了替代途径。FlyVec 是一个最近的例子，它从果蝇的嗅觉回路中汲取灵感，以解决学习词嵌入的任务。令人惊讶的是，即使与专门为编码文本而设计的深度学习方法相比，该模型也表现出竞争力，并且它以最高的计算效率实现了这一点。我们提出一个问题，即这种性能是否可以进一步提高。为此，我们引入了 Comply。通过结合复数权重的位置信息，我们使单层神经网络能够学习序列表示。我们的实验表明，Comply 不仅超越了 FlyVec，而且与显著更大的最先进模型表现相当。我们无需额外参数即可实现这一点。Comply 产生了稀疏的上下文句子表示，可以从神经元权重中明确解释。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [258] [Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge](https://arxiv.org/abs/2507.11330)
> *学术论文新颖性自动化评估：一种融合人类与大型语言模型知识的协作方法*

*Wenqing Wu, Chengzhi Zhang, Yi Zhao* | **Category: cs.CL, cs.AI, cs.DL, cs.HC** | **Updated: 2025-07-15**

**Keywords:** 新颖性评估, 大型语言模型, 人类知识, 预训练语言模型, 稀疏注意力

**Comment:** Journal of the Association for Information Science and Technology,
  2025

> **TL;DR:** 该研究提出了一种结合人类知识和大型语言模型（LLM）来辅助预训练语言模型（PLM）预测学术论文方法新颖性的自动化评估方法，并通过实验证明其性能优越。

**AI_Comments:** 该论文的创新点在于提出了一种结合人类专家知识和大型语言模型能力的混合方法来自动化评估学术论文的新颖性，特别是针对方法新颖性。通过利用同行评审报告中的信息和LLM对方法部分的总结来微调PLM，并引入稀疏注意力机制的融合模块，有效提升了新颖性评估的准确性。这对于提高同行评审效率和质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统学术论文新颖性评估方法（专家判断或独特引用组合）存在局限性：专家知识有限，引用组合的有效性不确定且无法真正衡量新颖性。鉴于大型语言模型拥有丰富知识而人类专家拥有判断能力，本研究旨在通过整合两者来解决新颖性评估的这些限制。

**Method:** 本研究提出了一种结合人类和LLM知识来辅助预训练语言模型（PLM，如BERT）预测论文方法新颖性的方法。具体而言，从同行评审报告中提取与论文新颖性相关的句子，并使用LLM总结论文的方法部分，然后将这些信息用于微调PLM。此外，还设计了一个带有新型稀疏注意力（Sparse-Attention）的文本引导融合模块，以更好地整合人类和LLM的知识。

**Result:** 广泛的实验表明，该方法比大量基线方法取得了更优越的性能。

**Conclusion:** 通过整合人类知识和大型语言模型的能力，本研究成功地解决了学术论文新颖性评估的传统局限性，并提供了一种高效、准确的自动化新颖性评估方法。

> **ai_Abstract:** 该论文提出了一种自动化评估学术论文新颖性的协作方法，旨在解决传统评估手段的局限性。研究整合了人类专家的判断能力和大型语言模型的知识，通过提取同行评审报告中的新颖性相关句子和使用LLM总结方法部分来微调预训练语言模型（PLM），以预测论文的方法新颖性。此外，引入了一个带有稀疏注意力机制的文本引导融合模块以优化知识整合。实验结果表明，该方法表现出优于现有基线的卓越性能。

> **摘要翻译:** 新颖性是同行评审过程中评估学术论文的关键标准。传统上，它由专家判断或通过独特的参考文献组合来衡量。这两种方法都有局限性：专家知识有限，组合方法的有效性不确定。此外，尚不清楚独特的引用是否真正衡量新颖性。大型语言模型（LLM）拥有丰富的知识，而人类专家拥有LLM不具备的判断能力。因此，我们的研究整合了LLM和人类专家的知识和能力，以解决新颖性评估的局限性。学术论文中最常见的新颖性是新方法的引入。在本文中，我们提出利用人类知识和LLM来辅助预训练语言模型（PLM，例如BERT等）预测论文的方法新颖性。具体而言，我们从同行评审报告中提取与学术论文新颖性相关的句子，并使用LLM总结学术论文的方法部分，然后将这些信息用于微调PLM。此外，我们设计了一个带有新型稀疏注意力（Sparse-Attention）的文本引导融合模块，以更好地整合人类和LLM的知识。我们将我们提出的方法与大量基线进行了比较。广泛的实验表明，我们的方法取得了优越的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [262] [Evaluating Multimodal Large Language Models on Educational Textbook Question Answering](https://arxiv.org/abs/2506.21596)
> *评估多模态大型语言模型在教育教科书问答中的表现*

*Hessa A. Alawwad, Anas Zafar, Areej Alhothali, Usman Naseem, Ali Alkhathlan, Amani Jamal* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-07-15**

**Keywords:** 多模态大型语言模型, 教科书问答, 检索增强生成, 上下文干扰, 教育AI

**Comment:** 8 Pages

> **TL;DR:** 首次评估了多模态大型语言模型（MLLMs）在教科书问答（TQA）任务上的表现，发现检索到的上下文对不同模型有不同影响，并揭示了“灾难性上下文干扰”现象。

**AI_Comments:** 这项工作首次系统地评估了MLLMs在教育TQA任务中的表现，并引入了多模态RAG管道，具有创新性。其最重要发现是“灾难性上下文干扰”现象，揭示了MLLMs在处理多模态上下文时存在的深层次问题，这对于未来开发更鲁棒的AI教育工具至关重要。研究还通过微调揭示了不同模型架构在多模态整合和泛化能力上的差异，为模型设计提供了宝贵见解。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型（MLLMs）在视觉-语言任务中取得了成功，但它们对复杂教育材料进行推理的能力在很大程度上尚未经过测试。

**Method:** 本研究首次评估了最先进的MLLMs，包括LLaVA-1.5和LLaMA 3.2-Vision，在CK12-QA数据集上的教科书问答（TQA）任务。引入了一种多模态检索增强生成（RAG）管道来模拟真实世界的学习。进行了零样本实验，并对模型进行了微调。

**Result:** 零样本实验发现了一个关键的权衡：检索到的上下文改善了LLaVA在基于文本问题上的性能，但显著降低了更强大的LLaMA 3.2-Vision在基于图表任务上的准确性，从74.07%降至25.93%，称之为“灾难性上下文干扰”。微调显示了架构差异：LLaMA 3.2-Vision的性能在测试集上提高到71.16%，而LLaVA的性能下降。

**Conclusion:** 研究结果强调了MLLMs在模态优先级和上下文整合方面面临的挑战，为开发更强大的AI驱动教育工具提供了基准和关键方向。

> **ai_Abstract:** 本研究首次评估了最先进的多模态大型语言模型（MLLMs），包括LLaVA-1.5和LLaMA 3.2-Vision，在教科书问答（TQA）任务上的表现，使用了CK12-QA数据集并引入了多模态检索增强生成（RAG）管道。实验发现，检索到的上下文对不同模型的影响不同，其中LLaMA 3.2-Vision在图表任务上出现了“灾难性上下文干扰”。微调显示LLaMA 3.2-Vision性能显著提升，而LLaVA下降，揭示了模型在多模态整合和泛化能力上的差异。研究强调了MLLMs在模态优先级和上下文整合方面的挑战，并为教育AI工具的未来发展提供了方向。

> **摘要翻译:** 多模态大型语言模型（MLLMs）在视觉-语言任务中取得了成功，但它们对复杂教育材料进行推理的能力在很大程度上尚未经过测试。这项工作首次评估了最先进的MLLMs，包括LLaVA-1.5和LLaMA 3.2-Vision，在CK12-QA数据集上的教科书问答（TQA）任务中的表现。我们引入了一种多模态检索增强生成（RAG）管道，通过提供相关的课程段落和图表作为上下文来模拟真实世界的学习。我们的零样本实验揭示了一个关键的权衡：虽然检索到的上下文改善了LLaVA在基于文本问题上的性能，但它显著降低了更强大的LLaMA 3.2-Vision在基于图表任务上的准确性，其验证准确率从74.07%下降到25.93%。我们将这种具有统计学意义的现象称为“灾难性上下文干扰”。此外，微调突出了架构差异：LLaMA 3.2-Vision的性能在测试集上提高到71.16%，表明其学习多模态整合的能力，而LLaVA的性能下降，表明其在泛化方面面临挑战。我们的结果强调了MLLMs在模态优先级和上下文整合方面面临的挑战，为开发更强大的AI驱动教育工具提供了基准和关键方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [265] [Multimodal Sentiment Analysis on CMU-MOSEI Dataset using Transformer-based Models](https://arxiv.org/abs/2505.06110)
> *使用基于Transformer的模型在CMU-MOSEI数据集上进行多模态情感分析*

*Jugal Gajjar, Kaustik Ranaware* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 多模态情感分析, Transformer, 早期融合, CMU-MOSEI, BERT

**Comment:** 6 pages, 2 figures

> **TL;DR:** 该项目使用基于Transformer的模型，通过早期融合文本、音频和视觉模态，在CMU-MOSEI数据集上进行了多模态情感分析，取得了高准确率和F1分数。

**AI_Comments:** 该论文通过将Transformer架构与早期融合策略相结合，为多模态情感分析提供了一个强大的解决方案。其创新之处在于成功应用基于BERT的编码器处理不同模态数据并进行有效融合，从而实现了高精度情感预测。所取得的高性能指标凸显了该方法在处理复杂跨模态交互方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过有效整合文本、音频和视觉模态，利用Transformer架构和早期融合策略，进行多模态情感分析，以实现对跨模态交互的有效捕获和提高情感预测的准确性。

**Method:** 研究使用了CMU-MOSEI数据集，采用基于Transformer的模型进行多模态情感分析。具体方法包括：为每种模态（文本、音频、视觉）使用基于BERT的编码器提取嵌入，然后在分类前进行拼接（早期融合）。训练过程采用Adam优化器（学习率=1e-4）、Dropout（0.3）和早期停止策略。

**Result:** 模型在测试集上取得了97.87%的7分类准确率和0.9682的F1分数。情感强度预测的平均绝对误差（MAE）为0.1060。结果表明早期融合在捕获跨模态交互方面的有效性，并突出了Transformer架构在建模多模态情感方面的优越性。

**Conclusion:** 该方法通过有效结合语言、听觉和视觉线索，利用多模态学习进行情感分析，展现出强大的性能，并证明了Transformer架构和早期融合策略在处理多模态情感任务中的有效性。

> **ai_Abstract:** 本文提出了一种基于Transformer模型的多模态情感分析方法，应用于CMU-MOSEI数据集。该方法采用早期融合策略，整合文本、音频和视觉模态，并使用基于BERT的编码器提取各模态的嵌入，随后进行拼接以供分类。模型在7分类任务上取得了97.87%的准确率和0.9682的F1分数，同时情感强度预测的MAE为0.1060，验证了早期融合在捕获跨模态交互方面的有效性以及Transformer架构在多模态情感建模中的优越性。

> **摘要翻译:** 本项目使用CMU-MOSEI数据集进行多模态情感分析，采用基于Transformer的模型和早期融合方法来整合文本、音频和视觉模态。我们为每种模态使用基于BERT的编码器，提取嵌入并在分类前进行拼接。该模型表现出强大的性能，在测试集上实现了97.87%的7分类准确率和0.9682的F1分数，这表明早期融合在捕获跨模态交互方面的有效性。训练过程中使用了Adam优化器（学习率=1e-4）、Dropout（0.3）和早期停止，以确保泛化能力和鲁棒性。结果突出了Transformer架构在建模多模态情感方面的优越性，低MAE（0.1060）表明情感强度预测的精确性。未来的工作可能会比较融合策略或增强可解释性。该方法通过有效结合语言、听觉和视觉线索进行情感分析，利用了多模态学习。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [281] [FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning](https://arxiv.org/abs/2505.08054)
> *FalseReject：通过结构化推理提高LLM上下文安全性和缓解过度拒绝的资源*

*Zhehao Zhang, Weijie Xu, Fanyou Wu, Chandan K. Reddy* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 安全对齐, 过度拒绝, FalseReject, 结构化推理

**Comment:** Accepted at COLM 2025

> **TL;DR:** LLM的安全对齐常导致过度拒绝良性查询，降低实用性。本文引入FalseReject，一个包含1.6万个查询和结构化响应的资源，并通过对抗性框架训练LLM，显著减少不必要的拒绝，同时不损害安全性或通用语言能力。

**AI_Comments:** 该论文通过引入FalseReject资源和相应的训练方法，有效解决了LLM过度拒绝良性查询的关键问题，提高了LLM在敏感场景中的实用性。其创新点在于结合了大规模结构化数据集和对抗性多智能体交互框架来生成高质量的训练数据，并明确指出通过结构化推理来帮助模型区分上下文。这对于提升LLM的用户体验和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）中的安全对齐方法常常导致对良性查询的过度拒绝，这显著降低了它们在敏感场景中的实用性。

**Method:** 本文引入了FalseReject，一个包含1.6万个看似有害查询及44个安全相关类别结构化响应的综合资源。提出了一种图信息对抗性多智能体交互框架来生成多样化和复杂的提示，并通过明确的推理来构建响应。FalseReject包含用于标准指令微调模型和推理导向模型的训练数据集，以及一个人工标注的基准测试集。

**Result:** 对29个最先进（SOTA）LLM的广泛基准测试揭示了持续存在的过度拒绝挑战。实证结果表明，使用FalseReject进行监督微调可以大幅减少不必要的拒绝，同时不损害整体安全性或通用语言能力。

**Conclusion:** FalseReject资源和相应的监督微调方法能有效减少LLM的过度拒绝，同时保持其整体安全性和通用语言能力，从而提高了LLM的实用性。

> **ai_Abstract:** 该论文介绍了FalseReject，一个旨在解决大型语言模型（LLM）在安全对齐中过度拒绝良性查询问题的资源。FalseReject包含1.6万个看似有害的查询及其在44个安全类别下的结构化响应，并通过一个图信息对抗性多智能体交互框架生成多样化提示和结构化推理响应。该资源提供了用于指令微调和推理模型的训练数据集，以及一个人工标注的基准测试集。研究发现，即使是29个最先进的LLM也存在过度拒绝问题。实验证明，使用FalseReject进行监督微调可以显著减少LLM的不必要拒绝，同时不损害其整体安全性和通用语言能力。

> **摘要翻译:** 大型语言模型（LLM）中的安全对齐方法通常会导致对良性查询的过度拒绝，从而显著降低其在敏感场景中的实用性。为了应对这一挑战，我们引入了FalseReject，这是一个包含1.6万个看似有害的查询的综合资源，并附有跨44个安全相关类别的结构化响应。我们提出了一种图信息对抗性多智能体交互框架，用于生成多样化和复杂的提示，同时通过明确的推理来构建响应，以帮助模型准确区分安全和不安全的上下文。FalseReject包括针对标准指令微调模型和面向推理模型的训练数据集，以及一个人工标注的基准测试集。我们对29个最先进（SOTA）的LLM进行的广泛基准测试揭示了持续存在的过度拒绝挑战。实证结果表明，使用FalseReject进行监督微调可以大幅减少不必要的拒绝，而不会损害整体安全性或通用语言能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [285] [KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding](https://arxiv.org/abs/2507.11273)
> *KV-Latent：基于频率感知旋转位置嵌入的维度级KV缓存缩减*

*Luohe Shi, Zuchao Li, Lefei Zhang, Guoming Liu, Baoyuan Qi, Hai Zhao* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** KV缓存, 大型语言模型, 旋转位置嵌入, 效率, 潜在空间

**Comment:** To be published in The 63rd Annual Meeting of the Association for
  Computational Linguistics (ACL 2025)

> **TL;DR:** KV-Latent通过将KV向量维度下采样到潜在空间并改进旋转位置嵌入，显著减少了LLM推理时的KV缓存占用并提高了推理速度。

**AI_Comments:** 这项工作通过引入KV-Latent范式，为LLMs的KV缓存效率问题提供了创新的解决方案。其核心在于维度级的KV缓存缩减和频率感知旋转位置嵌入的改进，这对于在有限内存和带宽下部署大型模型具有重要意义。该方法仅需少量额外训练的特点，使其具有很高的实用价值。这项研究为未来高效LLMs的发展开辟了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）中，Transformer解码器在推理过程中逐渐增长的Key-Value（KV）缓存已成为主要的效率瓶颈，体现在内存消耗和数据传输带宽限制两方面。

**Method:** 我们提出了KV-Latent范式，通过将Key-Value向量维度下采样到潜在空间来显著减少KV缓存占用。此外，我们通过修改频率采样机制，增强了应用于低维向量的旋转位置嵌入的稳定性，避免了高频引入的噪声，同时保留了位置衰减。

**Result:** 我们的方法显著减少了KV缓存占用并提高了推理速度，只需少量额外训练（不到预训练的1%）。包括使用和不使用分组查询注意力的模型在内的实验都取得了满意的结果。我们还比较了单独缩减Key和Value组件对模型性能的影响。

**Conclusion:** 我们的方法能够构建更高效的语言模型系统，并为KV缓存节省和高效LLMs开辟了新的可能性。

> **ai_Abstract:** 该论文提出了KV-Latent范式，旨在解决大型语言模型推理过程中KV缓存效率瓶颈。通过将KV向量维度下采样到潜在空间，并改进频率感知旋转位置嵌入的稳定性，KV-Latent显著减少了KV缓存占用并提高了推理速度，同时仅需极少的额外训练。实验结果表明该方法有效，为构建更高效的LLM系统提供了新途径。

> **摘要翻译:** 基于Transformer解码器的大型语言模型（LLMs）已成为对话式生成AI的首选。尽管解码器架构总体上具有优越性，但推理过程中逐渐增长的Key-Value（KV）缓存已成为主要的效率瓶颈，体现在内存消耗和数据传输带宽限制两方面。为了解决这些挑战，我们提出了一种名为KV-Latent的范式。通过将Key-Value向量维度下采样到潜在空间，我们可以在仅需少量额外训练（不到预训练的1%）的情况下，显著减少KV缓存占用并提高推理速度。此外，我们通过修改其频率采样机制，增强了应用于低维向量的旋转位置嵌入的稳定性，避免了高频引入的噪声，同时保留了位置衰减。我们的实验，包括使用分组查询注意力模型和不使用分组查询注意力模型，都取得了令人满意的结果。最后，我们进行了对比实验，研究了单独缩减Key和Value组件对模型性能的影响。我们的方法允许构建更高效的语言模型系统，并为KV缓存节省和高效LLMs开辟了新的可能性。我们的代码可在https://github.com/ShiLuohe/KV-Latent获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [295] [RAG-R1 : Incentivize the Search and Reasoning Capabilities of LLMs through Multi-query Parallelism](https://arxiv.org/abs/2507.02962)
> *RAG-R1：通过多查询并行化激励LLM的搜索和推理能力*

*Zhiwen Tan, Jiaming Huang, Qintong Wu, Hongxuan Zhang, Chenyi Zhuang, Jinjie Gu* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 检索增强生成, 多查询并行化, 搜索能力, 推理能力

**Comment:** 

> **TL;DR:** 本文提出了RAG-R1框架，通过多查询并行化提升LLM的搜索和推理能力，并显著减少推理时间。

**AI_Comments:** RAG-R1的创新点在于将多查询并行化引入到RAG框架中，这有效地解决了传统单查询模式下的推理效率瓶颈和能力限制。通过自适应地结合内部和外部知识，该方法提高了LLM的可靠性和性能，同时通过并行处理显著降低了推理时间，对实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）容易产生幻觉或过时信息，且现有检索增强生成（RAG）方法存在训练稳定性差、推理时间长和单查询模式能力受限等问题。

**Method:** 本文提出了RAG-R1，一个新颖的训练框架，旨在使LLMs在推理过程中自适应地利用内部和外部知识。该框架进一步将生成和检索过程从单查询模式扩展到多查询并行化。

**Result:** 在七个问答基准上的实验表明，RAG-R1的性能比最强基线高出13.2%，推理时间减少了11.1%。

**Conclusion:** RAG-R1框架通过多查询并行化，有效提升了LLMs的搜索和推理能力，并显著优化了推理效率。

> **ai_Abstract:** 本文提出了RAG-R1，一个创新的训练框架，旨在解决大型语言模型（LLMs）因静态知识导致的幻觉和过时信息问题，以及现有检索增强生成（RAG）方法在训练稳定性、推理时间和单查询模式下的局限性。RAG-R1使LLMs能够自适应地整合内部和外部知识，并通过引入多查询并行化来优化生成和检索过程，从而显著提升LLMs的搜索和推理能力并减少推理时间。实验证明，RAG-R1在多个问答基准上表现优异，性能和效率均有显著提升。

> **摘要翻译:** 大型语言模型（LLMs）在各种任务中展现出卓越的能力，但由于其静态的内部知识，它们仍然容易生成幻觉或过时的响应。检索增强生成（RAG）方法的最新进展通过强化学习（RL）探索了增强模型搜索和推理能力的方法。尽管这些方法显示出有希望的结果，但它们面临训练稳定性方面的挑战，并且由于单查询模式而遇到推理时间长和能力受限等问题。在本文中，我们提出了RAG-R1，一个新颖的训练框架，旨在使LLMs在推理过程中自适应地利用内部和外部知识。我们进一步将框架内的生成和检索过程从单查询模式扩展到多查询并行化，旨在减少推理时间并增强模型的能力。在七个问答基准上的大量实验表明，我们的方法比最强的基线高出13.2%，并使推理时间减少了11.1%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [306] [Is Compression Really Linear with Code Intelligence?](https://arxiv.org/abs/2505.11441)
> *代码智能与压缩真的是线性关系吗？*

*Shijie Xuyang, Xianzhen Luo, Tianhao Cheng, Zheng Chu, Houyi Li, ziqi wang, Siming Huang, Qingfu Zhu, Qiufeng Wang, Xiangyu Zhang, Shuigeng Zhou, Wanxiang Che* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 代码智能, 大型语言模型, 数据压缩, 格式退火, 对数关系

**Comment:** work in progress

> **TL;DR:** 该论文研究了数据压缩与代码大型语言模型（LLM）能力之间的关系，发现两者呈对数关系而非先前假设的线性关系，并引入了“格式退火”方法以进行公平评估。

**AI_Comments:** 该论文通过完善对压缩与智能之间关系的理解，特别是在代码领域，做出了重要贡献。“格式退火”的引入是一种创新方法，用于公平评估预训练LLM。使用大规模、未见的GitHub数据集进行BPC测量增加了研究结果的鲁棒性。发现对数关系挑战了既有观念，并提供了更细致的视角。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究假设压缩与通用智能之间存在线性关系，但忽视了代码的多样性，且难以公平评估现代代码LLM。本文旨在解决这些局限性。

**Method:** 1. 在全面的多语言、多任务代码基准上评估各种开源代码LLM。2. 引入“格式退火”（Format Annealing），这是一种轻量、透明的训练方法，用于高效且公平地评估预训练LLM的代码智能。3. 使用来自GitHub的、新颖、大规模且以前未见过的代码验证集，以每字符比特数（BPC）衡量压缩效率。

**Result:** 实证结果揭示了测量的代码智能与BPC之间存在根本的对数关系。这修正了先前的线性假设，表明它们可能是在特定有限条件下对对数曲线尾部的观察。

**Conclusion:** 该工作提供了对压缩在开发代码智能中作用的更细致理解，并为代码领域贡献了一个强大的评估框架。

> **ai_Abstract:** 本文研究了数据压缩与代码大型语言模型（LLM）能力之间的关系，挑战了先前假设的线性关系。通过在多样化的代码基准上评估各种开源代码LLM，并引入“格式退火”方法进行公平评估，该研究实证证明了代码智能与每字符比特数（BPC）压缩效率之间存在根本的对数关系。这些发现修正了先前的假设，并为代码智能贡献了一个强大的评估框架。

> **摘要翻译:** 理解数据压缩与大型语言模型（LLMs）能力之间的关系至关重要，尤其是在代码智能等专业领域。先前的研究假设压缩与通用智能之间存在线性关系。然而，它忽视了代码的多样性，包括不同的编程语言和任务，并且难以公平评估现代代码LLM。我们通过在全面的多语言、多任务代码基准上评估各种开源代码LLM来解决这个问题。为了解决有效和公平评估预训练LLM代码智能的挑战，我们引入了\textit{格式退火（Format Annealing）}，这是一种轻量、透明的训练方法，旨在公平评估这些预训练模型的内在能力。压缩效率（以每字符比特数（BPC）衡量）是使用一个新颖、大规模且以前未见过的、源自GitHub的代码验证集确定的。我们的实证结果揭示了测量的代码智能与BPC之间存在根本的对数关系。这一发现修正了先前的线性假设，我们认为这些假设可能是在特定有限条件下对对数曲线尾部的观察。我们的工作提供了对压缩在开发代码智能中作用的更细致理解，并为代码领域贡献了一个强大的评估框架。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [320] [FMC: Formalization of Natural Language Mathematical Competition Problems](https://arxiv.org/abs/2507.11275)
> *FMC：自然语言数学竞赛问题的形式化*

*Jiaxuan Xie, Chengwu Liu, Ye Yuan, Siqi Li, Zhiping Xiao, Ming Zhang* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 自动形式化, 大语言模型, 形式推理, 数学问题, 数据集

**Comment:** Accepted in ICML 2025 AI4MATH Workshop

> **TL;DR:** 本文提出了一个基于大语言模型和错误反馈的自动形式化流程，并构建了一个奥林匹克级别的自然语言数学问题与Lean形式化对齐的数据集，该数据集可作为自动化定理证明器的基准。

**AI_Comments:** 该论文的创新点在于提出了一个全自动且无需训练的基于大语言模型和错误反馈的自动形式化流程，以及构建了一个高质量、奥林匹克级别的自然语言数学问题到Lean形式化的数据集。该数据集对于推动形式数学推理和评估自动化定理证明器具有重要意义，其挑战性也预示着未来研究的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 高效准确的自动形式化方法对于推进形式数学推理至关重要，而这需要大规模的自然语言数学问题数据集来构建形式语言数据集。

**Method:** 本文提出了一种基于大语言模型并带有错误反馈的自动形式化流程，实现了全自动、免训练的形式化方法。利用该流程，作者整理了一个奥林匹克级别的自然语言问题与Lean形式化对齐的数据集。此外，还研究了各种大语言模型的形式化和推理能力。

**Result:** 研究者构建了一个包含3,922个自然语言数学问题和9,787个Lean形式化问题的数据集，其中64.46%被评估为至少高于平均水平的质量。实验表明，少样本学习、错误反馈和增加采样次数可以增强自动形式化过程。在FMC数据集上对三个自动化定理证明器进行的实验也突显了其挑战性和作为形式推理任务基准的价值。

**Conclusion:** 所构建的FMC数据集具有挑战性，并且适合作为自动化定理证明器和形式推理任务的基准。

> **ai_Abstract:** 本文提出了一种基于大语言模型和错误反馈的全自动、免训练的自动形式化流程，用于将自然语言数学竞赛问题形式化。利用该流程，作者构建了一个奥林匹克级别的自然语言数学问题与Lean形式化对齐的数据集（包含3,922个自然语言问题和9,787个Lean形式化问题），其中大部分质量良好，可作为自动化定理证明器的基准。研究还发现，少样本学习、错误反馈和增加采样次数能提升大语言模型的自动形式化能力，并且该数据集对现有的自动化定理证明器构成了挑战。

> **摘要翻译:** 高效准确的自动形式化方法，利用大规模的自然语言数学问题数据集来构建形式语言数据集，是推进形式数学推理的关键。在本文中，我们提出了一种基于大语言模型并带有错误反馈的自动形式化流程，实现了一种全自动、免训练的形式化方法。利用该流程，我们整理了一个奥林匹克级别的自然语言问题与Lean形式化对齐的数据集。该数据集包含3,922个自然语言数学问题和9,787个Lean形式化问题，其中64.46%被评估为至少高于平均水平的质量，使其适合作为自动化定理证明器的基准。此外，我们研究了各种大语言模型的形式化和推理能力，并经验性地证明了少样本学习、错误反馈和增加采样次数可以增强自动形式化过程。在FMC数据集上对三个自动化定理证明器进行的实验也突出了其挑战性以及作为形式推理任务基准的价值。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [324] [LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP](https://arxiv.org/abs/2507.11052)
> *增强型LLM的心血管疾病风险预测症状分析：一项临床NLP研究*

*Haowei Yang, Ziyu Shen, Junli Shao, Luyao Men, Xinyue Han, Jing Dong* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** LLM, 临床NLP, 心血管疾病, 风险预测, 症状分析

**Comment:** 

> **TL;DR:** 本研究提出了一种增强型LLM的临床NLP管道，用于从非结构化临床笔记中提取症状，以提高心血管疾病的风险预测准确性。

**AI_Comments:** 该研究创新性地将大型语言模型应用于非结构化临床文本的心血管疾病风险预测，有效弥补了传统模型对结构化数据依赖的不足。其通过领域适应性微调和提示工程解决了LLM在临床场景中的特有挑战（如幻觉和时间模糊性），提升了模型的可靠性和临床实用性。这项工作为LLM在医疗领域的应用，特别是早期预警系统和临床决策支持，提供了重要的实践案例和前景。

<details>
  <summary>Details</summary>

**Motivation:** 及时识别和准确分层心血管疾病（CVD）风险对于降低全球死亡率至关重要。尽管现有预测模型主要利用结构化数据，但非结构化临床笔记中包含有价值的早期指标，而这些指标常被忽视。

**Method:** 本研究引入了一种新颖的LLM增强型临床NLP管道，该管道利用领域适应的大语言模型从自由文本报告中进行症状提取、上下文推理和关联。该方法整合了心血管特异性微调、基于提示的推理以及实体感知推理，并通过提示工程和混合规则验证解决了上下文幻觉和时间模糊性等挑战。

**Result:** 在MIMIC-III和CARDIO-NLP数据集上的评估显示，该方法在精确度、召回率、F1分数和AUROC方面均有所改进，并经心脏病专家评估具有高度临床相关性（kappa = 0.82）。

**Conclusion:** 这项工作强调了大型语言模型（LLMs）在临床决策支持系统（CDSS）中的潜力，能够推进早期预警系统并增强患者叙述转化为可操作风险评估的能力。

> **ai_Abstract:** 本研究提出了一种新颖的LLM增强型临床自然语言处理（NLP）管道，旨在通过从非结构化临床笔记中提取、推理和关联症状，提高心血管疾病的风险预测能力。该方法结合了领域适应的LLM、心血管特异性微调和提示工程，并在MIMIC-III和CARDIO-NLP数据集上展现出显著的性能提升和高度临床相关性。研究还通过提示工程和混合规则解决了LLM在临床应用中面临的上下文幻觉和时间模糊性等挑战，凸显了LLM在临床决策支持系统中的应用潜力。

> **摘要翻译:** 及时识别和准确分层心血管疾病（CVD）风险对于降低全球死亡率至关重要。尽管现有预测模型主要利用结构化数据，但非结构化临床笔记中包含有价值的早期指标。本研究引入了一种新颖的LLM增强型临床NLP管道，该管道利用领域适应的大语言模型从自由文本报告中进行症状提取、上下文推理和关联。我们的方法整合了心血管特异性微调、基于提示的推理以及实体感知推理。在MIMIC-III和CARDIO-NLP数据集上的评估显示，该方法在精确度、召回率、F1分数和AUROC方面均有所改进，并经心脏病专家评估具有高度临床相关性（kappa = 0.82）。针对上下文幻觉（当合理信息与提供来源矛盾时发生）和时间模糊性（模型难以处理事件的时间顺序）等挑战，我们通过提示工程和混合规则验证予以解决。这项工作强调了大型语言模型在临床决策支持系统（CDSS）中的潜力，能够推进早期预警系统并增强患者叙述转化为可操作风险评估的能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [328] [A quantum semantic framework for natural language processing](https://arxiv.org/abs/2506.10077)
> *自然语言处理的量子语义框架*

*Christopher J. Agostino, Quan Le Thien, Molly Apsel, Denizhan Pak, Elina Lesyk, Ashabari Majumdar* | **Category: cs.CL, cs.AI, cs.IR, cs.IT, math.IT** | **Updated: 2025-07-15**

**Keywords:** 量子语义, 自然语言处理, 语义退化, 贝尔不等式, 非经典语境性

**Comment:** 12 pages, 2 figures, accepted submission to Quantum AI and NLP 2025

> **TL;DR:** 自然语言的语义退化对LLM构成挑战，其解释的复杂性需要量子逻辑来描述，实验证实了非经典语境性。

**AI_Comments:** 这篇论文通过引入量子力学中的概念来解释自然语言的语义复杂性，特别是其非确定性和语境依赖性，具有显著的创新性。它挑战了传统NLP中对“意义”的经典理解，并为解决LLM在处理模糊和复杂语义时的局限性提供了新的视角。通过实验验证了语言解释的非经典语境性，为未来NLP模型的设计提供了理论基础，尤其是强调了贝叶斯方法的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统NLP系统和大型语言模型（LLMs）在处理自然语言固有的语义退化和解释的组合爆炸时面临根本性限制，因为它们基于语言本身运作，且经典观点认为语言形式具有内在意义的假设不足以解决复杂或模糊文本的计算难题。

**Method:** 1. 使用柯尔莫哥洛夫复杂度论证了处理复杂语义表达所需上下文信息的组合爆炸；2. 提出意义是通过观察者依赖的解释行为动态实现的，该过程的非确定性最适合用非经典、类量子逻辑描述；3. 通过对不同LLM代理进行语义贝尔不等式测试（CHSH不等式）来验证这一假设。

**Result:** 实验中平均CHSH期望值在1.2到2.8之间，部分运行（如2.3-2.4）显著违反了经典边界（|S|≤2），表明模糊性下的语言解释可以表现出非经典语境性，这与人类认知实验结果一致。

**Conclusion:** 经典基于频率论的自然语言分析方法必然是信息有损的。相反，贝叶斯式的重复采样方法可以提供更实用和适当的语境化语言意义表征。

> **ai_Abstract:** 本文提出了一个量子语义框架，以解决自然语言中固有的语义退化和解释的组合爆炸问题，指出这限制了LLM等传统NLP系统。作者通过柯尔莫哥洛夫复杂度论证了经典语义观点的不足，并提出意义是观察者依赖的、非确定性的，应由类量子逻辑描述。通过对LLM进行语义贝尔不等式测试，实验结果显示语言解释在模糊性下表现出非经典语境性，验证了这一假设。研究认为经典频率论方法有损，并建议采用贝叶斯式采样方法来更有效地表征语言意义。

> **摘要翻译:** 语义退化是自然语言的一种基本属性，它超越了简单的多义性，涵盖了随着语义表达复杂性增加而出现的潜在解释的组合爆炸。在这项工作中，我们认为这种属性对大型语言模型（LLM）和其他现代自然语言处理系统施加了根本性限制，正是因为它们在自然语言本身中运行。我们使用柯尔莫哥洛夫复杂度证明，随着表达式复杂性的增长，可靠地解决其歧义所需的上下文信息量呈组合式爆炸。因此，为复杂或模糊文本恢复单一预期意义的计算不可处理性表明，语言形式本身具有内在意义的经典观点在概念上是不充分的。我们反而认为意义是通过观察者依赖的解释行为动态实现的，这个过程的非确定性最适合用非经典、类量子逻辑来描述。为了检验这一假设，我们使用不同的LLM代理进行了语义贝尔不等式测试。我们的实验得出的平均CHSH期望值在1.2到2.8之间，其中几次运行产生了显著违反经典边界（|S|≤2）的值（例如2.3-2.4），这表明模糊性下的语言解释可以表现出非经典语境性，与人类认知实验结果一致。这些结果本身意味着，基于经典频率论的自然语言分析方法必然是信息有损的。相反，我们提出贝叶斯式的重复采样方法可以提供更实用和更合适的语境化语言意义表征。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [331] [Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs](https://arxiv.org/abs/2505.15075)
> *跨语言旅行：基准测试多模态大型语言模型的跨语言一致性*

*Hao Wang, Pinzhi Huang, Jihan Yang, Saining Xie, Daisuke Kawahara* | **Category: cs.CL, cs.AI, cs.CV, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 跨语言一致性, 多模态大型语言模型, 基准测试, KnowRecall, VisRecall

**Comment:** https://github.com/nlp-waseda/traveling-across-languages

> **TL;DR:** 本文介绍了KnowRecall和VisRecall两个新基准，用于评估多模态大型语言模型（MLLM）的跨语言一致性，特别是在文化知识方面。实验结果表明，当前最先进的MLLM仍难以实现跨语言一致性。

**AI_Comments:** 这篇论文通过引入KnowRecall和VisRecall这两个创新性的基准，解决了多模态大型语言模型（MLLM）在跨语言和文化一致性方面的一个关键且被忽视的问题。其重要性在于，它不仅揭示了当前SOTA模型在该领域的局限性，而且为未来开发真正多语言和文化感知的MLLM提供了明确的评估工具和方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大型语言模型（MLLM）发展迅速并广泛应用于现实世界，但它们在跨语言，尤其是整合文化知识时，性能一致性方面仍面临巨大挑战。

**Method:** 为评估MLLM的跨语言一致性，本文引入了两个新基准：KnowRecall和VisRecall。KnowRecall是一个视觉问答基准，用于衡量15种语言的事实知识一致性，侧重于全球地标的文化和历史问题。VisRecall通过要求模型在不访问图像的情况下用9种语言描述地标外观来评估视觉记忆一致性。

**Result:** 实验结果显示，包括专有模型在内的当前最先进的多模态大型语言模型（MLLM）在实现跨语言一致性方面仍然存在困难。

**Conclusion:** 当前最先进的多模态大型语言模型在跨语言一致性上表现不佳，这强调了开发更强大、真正多语言和文化感知模型的必要性。

> **ai_Abstract:** 本文针对多模态大型语言模型（MLLM）在跨语言和文化知识整合方面的一致性挑战，提出了两个新的评估基准：KnowRecall和VisRecall。KnowRecall评估15种语言的事实知识一致性，而VisRecall则衡量9种语言的视觉记忆一致性。研究发现，即使是最先进的MLLM也难以达到跨语言一致性，从而揭示了开发更鲁棒、更具文化感知能力的多语言模型的重要性。

> **摘要翻译:** 多模态大型语言模型（MLLM）的快速发展显著增强了其在现实世界中的应用。然而，实现跨语言的一致性能，尤其是在整合文化知识时，仍然是一个重大挑战。为了更好地评估这个问题，我们引入了两个新的基准：KnowRecall和VisRecall，它们评估了MLLM的跨语言一致性。KnowRecall是一个视觉问答基准，旨在衡量15种语言的事实知识一致性，重点关注全球地标的文化和历史问题。VisRecall通过要求模型在不访问图像的情况下用9种语言描述地标外观来评估视觉记忆一致性。实验结果表明，包括专有模型在内的最先进的MLLM在实现跨语言一致性方面仍然存在困难。这强调了需要更强大的方法来生成真正多语言和文化感知的模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [351] [Compression Hacking: A Supplementary Perspective on Informatics Properties of Language Models from Geometric Distortion](https://arxiv.org/abs/2505.17793)
> *压缩攻击：从几何畸变角度看语言模型信息学特性的补充视角*

*Jianxiang Zang, Meiling Ning, Yongda Wei, Shihan Dou, Jiazheng Zhang, Nijia Mo, Binhong Li, Tao Gui, Qi Zhang, Xuanjing Huang* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 语言模型, 压缩攻击, 几何畸变, 信息学特性, 表示学习

**Comment:** 

> **TL;DR:** 高度压缩的语言模型表示空间会因几何畸变（压缩攻击）而退化，影响性能。本文提出了结合几何畸变分析的改进压缩指标，这些指标能更好地评估语言模型的能力。

**AI_Comments:** 本文通过引入“压缩攻击”这一概念，为理解语言模型表示的内在机制提供了新的视角，特别是揭示了过度压缩可能带来的负面影响。其创新之处在于将几何畸变分析融入到压缩度量中，这对于更准确地评估和优化语言模型的内部结构具有重要意义。提出的改进指标在评估模型能力方面显示出显著优势，为未来的模型设计和评估提供了有价值的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的“压缩即智能”概念强调高结构化表示的重要性，但研究发现高度压缩的语言模型表示空间趋于各向异性退化，这阻碍了模型理解指令的能力并直接影响其性能，这种现象被称为“压缩攻击”。

**Method:** 提出了三种通过结合几何畸变分析的改进压缩指标，并将它们整合到一个自评估流程中。

**Result:** 改进后的指标与语言模型的综合能力表现出高度一致性，Spearman相关系数超过0.9，显著优于原始压缩指标和其他基于内部结构的指标。

**Conclusion:** 结合表示的几何畸变，压缩攻击显著增强了语言模型的信息学解释能力。

> **ai_Abstract:** 本文探讨了语言模型中“压缩即智能”概念的一个局限性，即过度压缩会导致表示空间出现几何畸变（各向异性），作者称之为“压缩攻击”。这种畸变会损害模型理解指令的能力。为解决此问题，作者提出了结合几何畸变分析的改进压缩指标，并通过实验证明这些新指标能更准确地评估语言模型的综合能力，与模型性能的相关性显著提高。

> **摘要翻译:** 近来，“压缩即智能”的概念为语言模型（LMs）提供了一种新颖的信息学度量视角，强调高度结构化的表示标志着LMs的智能水平。然而，从几何角度来看，高度压缩的LMs的词表示空间倾向于退化为高度各向异性状态，这阻碍了LM理解指令的能力并直接影响其性能。我们发现这种压缩-各向异性同步性本质上是LM表示中的“压缩攻击”（Compression Hacking），其中噪声主导的方向通过牺牲空间均匀性来制造高压缩率的假象。基于此，我们通过结合几何畸变分析提出了三种改进的压缩度量，并将其整合到一个自评估流程中。改进后的度量与LM的综合能力表现出强烈的对齐性，Spearman相关系数超过0.9，显著优于原始压缩度量和其他基于内部结构的度量。这证实了通过引入表示的几何畸变，压缩攻击大大增强了LMs的信息学解释。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [353] [A Taxonomy for Design and Evaluation of Prompt-Based Natural Language Explanations](https://arxiv.org/abs/2507.10585)
> *基于提示的自然语言解释的设计与评估分类法*

*Isar Nejadgholi, Mona Omidyeganeh, Marc-Antoine Drouin, Jonathan Boisvert* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 自然语言解释, 可解释人工智能, 分类法, 大型语言模型, AI治理

**Comment:** Presented at the Workshop of Technical AI Governance, 5 pages 2
  figures

> **TL;DR:** 本文提出了一个针对基于提示的自然语言解释（NLEs）的更新版可解释人工智能（XAI）分类法，旨在为研究人员、审计师和政策制定者提供一个框架，以更好地理解、设计和评估透明AI系统中的NLEs。

**AI_Comments:** 该论文通过提出一个专门针对基于提示的自然语言解释的分类法，填补了可解释人工智能领域的一个空白。其创新之处在于将XAI的传统概念扩展到大型语言模型生成的NLEs，并提供了清晰的三维结构。这对于促进AI透明度、治理和可信赖AI的发展具有重要意义，特别是在NLEs日益普及的背景下。该框架具有很强的实用性，可供不同利益相关者使用。

<details>
  <summary>Details</summary>

**Motivation:** 有效的AI治理需要结构化的方法来让利益相关者访问和验证AI系统行为。随着大型语言模型的兴起，自然语言解释（NLEs）成为阐明模型行为的关键，因此需要对其特性和治理影响进行重点研究。

**Method:** 作者借鉴了可解释人工智能（XAI）文献，创建了一个更新的XAI分类法，并将其调整以适应基于提示的自然语言解释（NLEs）。该分类法涵盖三个维度：(1)语境（包括任务、数据、受众和目标）；(2)生成与呈现（涵盖生成方法、输入、交互性、输出和形式）；以及(3)评估（侧重于内容、呈现、以用户为中心的属性以及评估环境）。

**Result:** 本文提出的分类法为研究人员、审计师和政策制定者提供了一个框架，用于刻画、设计和增强透明AI系统中的自然语言解释。

**Conclusion:** 该分类法为理解、设计和评估基于提示的自然语言解释提供了一个全面的结构化框架，有助于促进AI系统的透明度和有效治理。

> **ai_Abstract:** 本文针对大型语言模型背景下基于提示的自然语言解释（NLEs）的重要性，提出了一个更新的可解释人工智能（XAI）分类法。该分类法基于XAI文献，并扩展了三个关键维度：语境、生成与呈现以及评估。它旨在为研究人员、审计师和政策制定者提供一个结构化框架，以更好地理解、设计和评估NLEs，从而促进AI系统的透明度和有效治理。

> **摘要翻译:** 有效的AI治理需要利益相关者采用结构化方法来访问和验证AI系统行为。随着大型语言模型的兴起，自然语言解释（NLEs）现在是阐明模型行为的关键，这需要对它们的特征和治理影响进行重点审查。我们借鉴了可解释人工智能（XAI）文献，创建了一个更新的XAI分类法，该分类法适应于基于提示的NLEs，涵盖三个维度：(1)语境，包括任务、数据、受众和目标；(2)生成与呈现，涵盖生成方法、输入、交互性、输出和形式；以及(3)评估，侧重于内容、呈现和以用户为中心的属性，以及评估环境。该分类法为研究人员、审计师和政策制定者提供了一个框架，用于刻画、设计和增强透明AI系统中的NLEs。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [355] [Fine-Grained Chinese Hate Speech Understanding: Span-Level Resources, Coded Term Lexicon, and Enhanced Detection Frameworks](https://arxiv.org/abs/2507.11292)
> *细粒度中文仇恨言论理解：跨度级资源、编码术语词典和增强检测框架*

*Zewen Bai, Liang Yang, Shengdi Yin, Yuanyuan Sun, Hongfei Lin* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 中文仇恨言论, 细粒度理解, 跨度级数据集, 编码术语, 可解释性检测

**Comment:** 

> **TL;DR:** 研究引入首个跨度级中文仇恨言论数据集STATE ToxiCN，研究编码仇恨术语，并提出整合词典的方法，以提升中文仇恨言论检测的解释性和性能。

**AI_Comments:** 这项工作通过构建首个跨度级中文仇恨言论数据集和深入研究编码术语，在中文仇恨言论检测的细粒度理解和可解释性方面取得了重要进展。其创新点在于从“跨度级”和“编码术语”两个维度提升了中文仇恨言论检测的深度和广度，并提出了实用的模型增强方法。这对于解决中文在线平台上的复杂仇恨言论问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 中文仇恨言论检测研究滞后，且解释性研究面临两大挑战：缺乏细粒度跨度级标注数据集限制模型对仇恨言论的深层语义理解；对编码仇恨言论的识别和解释研究不足限制了模型在复杂现实场景中的可解释性。

**Method:** 1) 引入首个跨度级中文仇恨言论数据集STATE ToxiCN，并评估现有模型在该数据集上的仇恨语义理解能力。2) 对中文编码仇恨术语及大型语言模型（LLMs）解释仇恨语义的能力进行首次全面研究。3) 提出一种将标注词典整合到模型中的方法。

**Result:** 引入STATE ToxiCN数据集，进行了中文编码仇恨术语的全面研究，并提出了整合词典的方法，显著提升了仇恨言论检测性能。

**Conclusion:** 该工作为中文仇恨言论检测研究的解释性提供了宝贵的资源和见解。

> **ai_Abstract:** 这项研究旨在解决中文仇恨言论检测中存在的细粒度理解和编码术语解释的挑战。为此，研究团队构建并发布了首个跨度级中文仇恨言论数据集STATE ToxiCN，并利用其评估现有模型的语义理解能力。同时，他们首次全面研究了中文编码仇恨术语以及大型语言模型对仇恨语义的解释能力。此外，研究还提出了一种将标注词典整合到模型中的新方法，有效提升了仇恨言论检测的性能。这些贡献为中文仇恨言论检测的可解释性研究提供了重要的资源和见解。

> **摘要翻译:** 仇恨言论的扩散已造成严重的社会危害，其强度和指向性与特定目标和论点密切相关。近年来，人们开发了许多基于机器学习的方法来自动检测在线平台上的仇恨评论。然而，中文仇恨言论检测的研究相对滞后，可解释性研究面临两大主要挑战：首先，跨度级细粒度标注数据集的稀缺性限制了模型对仇恨言论的深层语义理解；其次，对识别和解释编码仇恨言论的研究不足限制了模型在复杂现实场景中的可解释性。为了解决这些问题，我们做出了以下贡献：(1) 我们引入了跨度级目标感知毒性提取数据集（STATE ToxiCN），这是首个跨度级中文仇恨言论数据集，并使用它评估了现有模型的仇恨语义理解能力。(2) 我们首次对中文编码仇恨术语以及大型语言模型（LLMs）解释仇恨语义的能力进行了全面研究。(3) 我们提出了一种将标注词典整合到模型中的方法，显著提高了仇恨言论检测性能。我们的工作为推进中文仇恨言论检测研究的可解释性提供了宝贵的资源和见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [373] [Gaussian mixture models as a proxy for interacting language models](https://arxiv.org/abs/2506.00077)
> *高斯混合模型作为交互式语言模型的替代*

*Edward L. Wang, Tianyu Wang, Hayden Helm, Avanti Athreya, Vince Lyzinski, Carey E. Priebe* | **Category: cs.CL, cs.LG, stat.ML, 62R07** | **Updated: 2025-07-15**

**Keywords:** 高斯混合模型, 大型语言模型, 检索增强生成, 计算效率, 社会科学

**Comment:** 

> **TL;DR:** 研究表明交互式高斯混合模型可以作为交互式大型语言模型的计算开销较小的替代品，并能捕捉其动态特征。

**AI_Comments:** 这项工作提出了一种新颖且计算效率更高的模型（GMMs）来模拟和理解大型语言模型（LLMs）的交互行为。其创新之处在于为社会科学等领域提供了一种可行的大规模实验替代方案，克服了LLMs的计算限制。这项研究对于扩展LLMs的应用范围和降低研究成本具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）虽然强大，但计算成本高昂，尤其在社会科学中研究个体间人类行为时，大规模实验不可行。因此需要寻找计算成本较低的替代方案。

**Method:** 引入交互式高斯混合模型（GMMs）作为使用LLM的类似框架的替代品。通过比较简化的GMM模型与LLM的选定实验模拟，其中LLM的更新和响应依赖于其他LLM的反馈。

**Result:** 发现交互式GMMs能够捕捉交互式LLMs动态的重要特征，并探讨了两者之间的关键异同点。

**Conclusion:** 讨论了高斯混合模型的优势、潜在修改和未来的研究方向。

> **ai_Abstract:** 本文提出并评估了交互式高斯混合模型（GMMs）作为研究交互式大型语言模型（LLMs）动态的计算效率更高的替代方案。鉴于LLMs在社会科学应用中的高计算成本，研究者将简化的GMMs与LLMs的模拟行为进行比较，发现GMMs能有效捕捉LLMs交互中的关键动态特征。研究还探讨了两者的异同，并指出了GMMs在未来研究中的潜力。

> **摘要翻译:** 大型语言模型（LLMs）是一种强大的工具，能够在许多场景中与人类能力和行为相匹配。检索增强生成（RAG）进一步允许LLMs根据其RAG数据库的内容生成多样化的输出。这促使它们在社会科学中用于研究个体间的人类行为，尤其是在大规模实验不可行的情况下。然而，LLMs依赖于复杂且计算成本高昂的算法。在本文中，我们引入交互式高斯混合模型（GMMs）作为使用LLMs的类似框架的替代方案。我们将简化的GMM模型与LLMs的选定实验模拟进行比较，其中LLMs的更新和响应取决于其他LLMs的反馈。我们发现交互式GMMs能够捕捉交互式LLMs动态的重要特征，并且我们研究了交互式LLMs和GMMs之间的关键异同。最后，我们讨论了高斯混合模型的优势、潜在修改和未来的研究方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [389] [Transforming Sensitive Documents into Quantitative Data: An AI-Based Preprocessing Toolchain for Structured and Privacy-Conscious Analysis](https://arxiv.org/abs/2507.10582)
> *将敏感文档转化为定量数据：一种用于结构化和隐私保护分析的AI预处理工具链*

*Anders Ledberg, Anna Thalén* | **Category: cs.CL, stat.ME** | **Updated: 2025-07-11**

**Keywords:** 敏感文档, 隐私保护, AI工具链, 文本预处理, 大语言模型

**Comment:** 

> **TL;DR:** 该研究提出了一种AI驱动的模块化工具链，用于将法律、医疗和行政来源的非结构化敏感文本转化为匿名化、标准化的定量数据，以便进行大规模、隐私保护的分析。

**AI_Comments:** 这项工作具有重要的创新性和实用价值，它提供了一个切实可行的解决方案，解决了敏感非结构化文本数据在社会科学和公共卫生研究中难以利用的核心痛点。其优势在于完全依赖于开源模型并在本地硬件上运行，这极大地增强了隐私保护能力和可访问性。通过结合LLM的灵活性和传统NLP方法的鲁棒性，确保了匿名化和数据标准化的有效性。这为以前因隐私顾虑而无法开展的大规模定性研究开辟了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 法律、医疗和行政来源的非结构化文本是公共卫生和社会科学研究的丰富但未充分利用的资源。然而，大规模分析受到两个主要挑战的阻碍：存在敏感的个人身份信息，以及结构和语言的显著异质性。

**Method:** 该工具链是一个模块化系统，完全依赖于可在本地硬件上运行的开源模型（仅需工作站级GPU）。它使用大型语言模型（LLM）提示进行文本标准化、摘要和翻译（如有需要）。通过基于LLM的修订、命名实体识别和基于规则的方法实现匿名化，以最大限度地降低信息泄露的风险。处理后的文档被转化为匿名化、标准化的摘要，并生成文档级嵌入。

**Result:** 该工具链在包含10,842份瑞典滥用者护理法庭判决书（超过56,000页）的语料库上进行了演示。验证（包括人工审查、自动化扫描和预测评估）表明，该工具链能有效移除识别信息，同时保留语义内容。通过使用少量手动标记摘要的嵌入向量训练预测模型，展示了该工具链在大规模半自动化内容分析方面的能力。

**Conclusion:** 该工具链通过实现敏感文档的结构化、隐私保护分析，为以前因隐私和异质性限制而无法访问文本数据的领域的大规模研究开辟了新的可能性。

> **ai_Abstract:** 该论文介绍了一种AI驱动的模块化工具链，旨在解决大规模分析法律、医疗和行政等来源的非结构化敏感文本所面临的隐私和异质性挑战。该工具链利用本地运行的开源大型语言模型进行文本标准化、摘要、翻译和匿名化（通过LLM修订和NER等）。通过对瑞典法院判决书的案例研究，研究展示了该工具链在有效移除识别信息同时保留语义内容的能力，并支持生成文档级嵌入以进行大规模、隐私保护的半自动化内容分析。

> **摘要翻译:** 来自法律、医疗和行政来源的非结构化文本是公共卫生和社会科学研究的丰富但未充分利用的资源。然而，大规模分析受到两个关键挑战的阻碍：敏感的个人身份信息的存在，以及结构和语言的显著异质性。我们提出了一种模块化工具链，用于准备此类文本数据进行基于嵌入的分析，该工具链完全依赖于可在本地硬件上运行的开源模型，仅需工作站级GPU并支持隐私敏感的研究。
该工具链采用大型语言模型（LLM）提示来标准化、总结文本，并在需要时将其翻译成英文以提高可比性。通过基于LLM的修订实现匿名化，并辅以命名实体识别和基于规则的方法，以最大限度地降低信息泄露的风险。我们在包含10,842份瑞典滥用者护理法（LVM）法庭判决书（超过56,000页）的语料库上演示了该工具链。每个文档都被处理成匿名化、标准化的摘要，并转换为文档级嵌入。验证，包括人工审查、自动化扫描和预测评估，表明该工具链在保留语义内容的同时有效移除了识别信息。作为一个说明性应用，我们使用少量手动标记摘要的嵌入向量训练了一个预测模型，展示了该工具链在大规模半自动化内容分析方面的能力。
通过实现敏感文档的结构化、隐私保护分析，我们的工具链为以前因隐私和异质性限制而无法访问文本数据的领域的大规模研究开辟了新的可能性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [390] [Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian](https://arxiv.org/abs/2507.11299)
> *Dr.Copilot：一个多智能体提示优化助手，用于改善罗马尼亚语中的医患沟通*

*Andrei Niculae, Adrian Cosma, Cosmin Dumitrache, Emilian Rǎdoi* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** Dr.Copilot, 多智能体, 大型语言模型, 医患沟通, 罗马尼亚语

**Comment:** 10 figures, 2 tables, 2 listings

> **TL;DR:** Dr.Copilot是一个多智能体LLM系统，通过评估和增强书面回复的呈现质量，帮助罗马尼亚医生改善医患沟通。

**AI_Comments:** 这项研究的创新之处在于其构建了一个多智能体LLM系统，专门用于提升医患沟通的“呈现质量”而非“临床准确性”，这提供了一个全新的视角。通过DSPy进行提示自动优化，以及在低资源语言（罗马尼亚语）环境中的真实世界部署，都彰显了其技术实用性和重要性。它证明了LLM在特定应用场景下，即使数据资源有限，也能产生显著的实际效益。

<details>
  <summary>Details</summary>

**Motivation:** 文本远程医疗中，医患互动中医疗建议的质量往往更多地取决于其沟通方式而非临床准确性。为解决此问题，论文引入了Dr.Copilot。

**Method:** Dr.Copilot是一个多智能体大型语言模型（LLM）系统，通过评估和增强医生书面回复的呈现质量来支持罗马尼亚语医生。它不评估医疗正确性，而是沿着17个可解释的维度提供反馈。该系统由三个LLM智能体组成，其提示通过DSPy自动优化，并使用低资源罗马尼亚语数据设计并使用开源模型部署。

**Result:** 对41名医生进行的实证评估和实际部署显示，用户评价和回复质量都有显著改善。

**Conclusion:** 这项工作标志着大型语言模型首次在罗马尼亚医疗环境中进行真实世界部署之一。

> **ai_Abstract:** 本研究介绍了Dr.Copilot，一个多智能体大型语言模型系统，旨在改善罗马尼亚语医患沟通中医生书面回复的呈现质量。该系统包含三个通过DSPy优化提示的LLM智能体，可根据17个维度提供反馈，而非评估医疗准确性。Dr.Copilot使用低资源罗马尼亚语数据和开源模型构建，并在远程医疗平台中实时部署。实证评估和对41名医生的实际部署表明，该系统显著提升了用户评价和回复质量，是LLM在罗马尼亚医疗领域首次真实世界部署的案例之一。

> **摘要翻译:** 文本远程医疗已变得越来越普遍，然而，医患互动中医疗建议的质量往往更多地取决于其沟通方式而非临床准确性。为了解决这个问题，我们引入了Dr.Copilot，这是一个多智能体大型语言模型（LLM）系统，通过评估和增强其书面回复的呈现质量来支持罗马尼亚语医生。Dr.Copilot不评估医疗正确性，而是沿着17个可解释的维度提供反馈。该系统由三个LLM智能体组成，其提示通过DSPy自动优化。它使用低资源罗马尼亚语数据设计并使用开源模型部署，可在远程医疗平台内向医生提供实时具体反馈。对41名医生进行的实证评估和实际部署显示，用户评价和回复质量都有显著改善，这标志着LLM首次在罗马尼亚医疗环境中进行真实世界部署之一。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [397] [Critique-GRPO: Advancing LLM Reasoning with Natural Language and Numerical Feedback](https://arxiv.org/abs/2506.03106)
> *Critique-GRPO：利用自然语言和数值反馈推进LLM推理*

*Xiaoying Zhang, Hao Sun, Yipeng Zhang, Kaituo Feng, Chaochao Lu, Chao Yang, Helen Meng* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 强化学习, 大型语言模型, 自然语言反馈, 数值反馈, 推理

**Comment:** 49 pages, updated with new experimental results

> **TL;DR:** Critique-GRPO是一种新的强化学习框架，它结合了自然语言批评和数值反馈，以克服现有LLM推理方法中的性能瓶颈，并在数学、STEM和通用推理任务上显著优于现有方法。

**AI_Comments:** Critique-GRPO的创新之处在于其将自然语言反馈（批评）与数值反馈相结合的在线强化学习框架。这有效地解决了LLM在复杂推理中遇到的性能平台期和自我反思局限性问题。通过引入塑造函数来放大正确修正的学习，并引入自我批评机制，该方法显著提升了LLM的推理和泛化能力。其重要性在于为LLM的进一步能力提升开辟了新途径，尤其是在需要精细推理和纠错的领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有仅使用数值反馈的强化学习（RL）在提高大型语言模型（LLM）的复杂推理能力方面取得了显著进展，但仍面临性能平台期、自我反思效果有限和持续失败等挑战。本文旨在通过整合自然语言反馈来解决这些问题。

**Method:** 本文提出了Critique-GRPO，一个在线强化学习框架，它结合了自然语言和数值反馈进行策略优化。Critique-GRPO使LLM能够同时从初始响应和批评指导的自我修正中学习，同时保持探索性。此外，它采用塑造函数来放大从正确修正（尤其是生疏的修正）中学习，并惩罚不正确的修正。

**Result:** Critique-GRPO在八个具有挑战性的数学、STEM和通用推理任务上持续优于监督学习和基于RL的微调方法，Qwen2.5-7B-Base和Qwen3-8B的平均pass@1分数分别提高了约4.4%和3.8%。与GRPO相比，Critique-GRPO在AIME 2024上实现了16.7%和10.0%的pass@1改进，通过自我批评和从弱到强的泛化实现了有效的自我提升。

**Conclusion:** Critique-GRPO通过整合自然语言和数值反馈，显著提升了LLM的推理能力和自我改进机制，克服了传统RL方法的局限性，并在多项任务上取得了显著的性能提升。

> **ai_Abstract:** 本文提出了Critique-GRPO，一个新颖的在线强化学习框架，旨在通过结合自然语言批评和数值反馈来提升大型语言模型（LLM）的推理能力。该框架解决了传统仅依赖数值反馈的RL方法所面临的性能瓶颈、自我反思不足和持续性错误等问题。Critique-GRPO允许LLM同时从初始响应和自我修正中学习，并通过奖励塑造机制强化学习效果。实验证明，Critique-GRPO在多项数学、STEM和通用推理任务上显著优于监督学习和现有RL微调方法，并展现出通过自我批评实现有效自我改进的能力。

> **摘要翻译:** 近期，通过标量奖励等数值反馈的强化学习（RL）在显著增强大型语言模型（LLM）的复杂推理能力方面取得了进展。尽管取得了成功，我们仍识别出仅使用数值反馈的RL所面临的三个关键挑战：性能平台期、自我反思效果有限以及持续失败。我们随后证明，即使在性能出现平台期后，经过RL微调的模型仍能通过利用批评形式的自然语言反馈，对持续失败的问题生成正确的修正。基于这一洞察，我们提出了Critique-GRPO，一个在线RL框架，它整合了自然语言和数值反馈以进行有效的策略优化。Critique-GRPO使LLM能够同时从初始响应和批评指导的自我修正中学习，同时保持探索。此外，我们采用了一个塑造函数来放大从正确修正（尤其是生疏的修正）中学习，并惩罚不正确的修正。对Qwen2.5-7B-Base、Qwen2.5-Math-7B-Base和Qwen3-8B进行的广泛实验表明，Critique-GRPO在八个具有挑战性的数学、STEM和通用推理任务上持续优于监督学习和基于RL的微调方法，Qwen2.5-7B-Base和Qwen3-8B的平均pass@1分数分别提高了约4.4%和3.8%。值得注意的是，Critique-GRPO通过自我批评和从弱到强的泛化实现了有效的自我提升，与GRPO相比，在AIME 2024上分别实现了16.7%和10.0%的pass@1改进。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [400] [AutoRAG-LoRA: Hallucination-Triggered Knowledge Retuning via Lightweight Adapters](https://arxiv.org/abs/2507.10586)
> *AutoRAG-LoRA：基于轻量级适配器的幻觉触发知识重调*

*Kaushik Dwivedi, Padmanabh Patanjali Mishra* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 幻觉, RAG, LoRA, 知识重调, 大型语言模型

**Comment:** 

> **TL;DR:** AutoRAG-LoRA是一个模块化的RAG框架，通过轻量级LoRA适配器和KL正则化训练来减少大型语言模型中的幻觉，显著降低了事实漂移，同时保持了效率和模块化。

**AI_Comments:** AutoRAG-LoRA的创新之处在于其将幻觉检测与LoRA适配器微调相结合的反馈校正循环，这使得模型能够动态地纠正事实不准确性。其模块化设计和对效率的关注，使其在实际应用中具有重要意义。通过轻量级适配器进行知识重调，为解决LLM幻觉提供了一条有前景的路径。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在自然语言任务中表现出色，但容易产生幻觉（事实不准确），这会损害其在实际部署中的可信度。

**Method:** AutoRAG-LoRA是一个模块化的检索增强生成（RAG）框架，它通过轻量级LoRA适配器和KL正则化训练来解决大型语言模型中的幻觉问题。其管道集成了自动化提示重写、混合检索和低秩适配器调优。一个幻觉检测模块（使用基于分类器和自我评估技术）为生成输出分配置信度分数，触发一个可选的反馈校正循环，通过对比KL损失和适配器微调来强制事实对齐。

**Result:** AutoRAG-LoRA显著减少了事实漂移，同时保持了模型的效率和模块化。

**Conclusion:** AutoRAG-LoRA通过其创新的框架和训练方法，有效地减少了大型语言模型中的幻觉问题，同时保持了模型的性能和实用性。

> **ai_Abstract:** AutoRAG-LoRA是一个针对检索增强生成（RAG）的模块化框架，旨在通过轻量级LoRA适配器和KL正则化训练来解决大型语言模型中的幻觉问题。它结合了自动化提示重写、混合检索和低秩适配器调优，并包含一个幻觉检测模块，该模块在检测到幻觉时触发反馈校正循环。实验证明，AutoRAG-LoRA能够显著减少事实漂移，同时保持模型的高效率和模块化。

> **摘要翻译:** 大型语言模型（LLM）在各种自然语言任务中展现出卓越的流畅性，但仍然容易产生幻觉——即事实上的不准确，这会损害其在实际部署中的信任。我们提出了AutoRAG-LoRA，一个模块化的检索增强生成（RAG）框架，通过轻量级基于LoRA的适配器和KL正则化训练来解决大型语言模型中的幻觉问题。我们的管道集成了自动化提示重写、混合检索和低秩适配器调优，以将响应基于检索到的证据。一个幻觉检测模块，利用基于分类器和自我评估技术，为生成的输出分配置信度分数，触发一个可选的反馈校正循环。此循环通过对比KL损失和适配器微调来强制事实对齐。我们证明了AutoRAG-LoRA显著减少了事实漂移，同时保持了模型的效率和模块化。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [421] [ImpliRet: Benchmarking the Implicit Fact Retrieval Challenge](https://arxiv.org/abs/2506.14407)
> *ImpliRet：基准测试隐式事实检索挑战*

*Zeinab Sadat Taghavi, Ali Modarressi, Yunpu Ma, Hinrich Schütze* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 隐式事实检索, 基准测试, 文档侧推理, 信息检索, 长上下文模型

**Comment:** 

> **TL;DR:** 引入了ImpliRet，一个用于评估文档侧隐式事实检索的基准测试，发现现有检索器和大型语言模型在此任务上表现不佳。

**AI_Comments:** ImpliRet通过将推理挑战从查询侧转移到文档侧，提供了一个新颖且重要的视角来评估检索系统的真实理解能力。它揭示了现有检索方法（包括最新的大型语言模型）在处理文档中隐式事实方面的局限性，对未来的研究方向具有指导意义。该基准测试填补了现有评估的空白，有助于推动更深层次的语义理解和推理能力发展。

<details>
  <summary>Details</summary>

**Motivation:** 当前的检索系统过度依赖表面线索，而现有的推理密集型基准测试则将推理负担转移到查询端处理。为了评估超越这些浅层信号的检索能力，并解决文档侧的隐式事实推理挑战，该研究提出了一个新的基准。

**Method:** 提出了ImpliRet基准测试，它将推理挑战转移到文档侧处理。查询简单，但相关性取决于文档中通过时间、算术和世界知识关系隐式表达的事实。该研究评估了一系列稀疏和密集检索器，并测试了长上下文模型（如GPT-o4-mini）的表现。

**Result:** 评估的稀疏和密集检索器在ImpliRet基准测试中表现不佳，最佳nDCG@10仅为14.91%。即使是长上下文模型（如GPT-o4-mini），在包含正确文档的短上下文（30个文档）下，得分也仅为55.54%。

**Conclusion:** 文档侧的隐式事实推理仍然是一个重大挑战，无论是传统的检索器还是先进的长上下文模型都难以有效解决。

> **ai_Abstract:** ImpliRet是一个新的基准测试，旨在评估检索系统在文档侧隐式事实推理方面的能力，区别于以往将推理负担置于查询侧的方法。该基准测试的查询简单，但要求系统理解文档中通过时间、算术和世界知识隐式表达的事实。实验结果表明，无论是传统的稀疏和密集检索器，还是先进的长上下文模型（如GPT-o4-mini），在ImpliRet上的表现均不理想，揭示了文档侧隐式推理是当前检索技术面临的严峻挑战。

> **摘要翻译:** 检索系统是许多自然语言处理（NLP）流水线的核心，但通常依赖于表面线索，如关键词重叠和词汇语义相似性。为了评估超越这些浅层信号的检索能力，最近的基准测试引入了推理密集型查询；然而，它们主要将负担转移到查询侧处理技术——如提示或多跳检索——这些技术可以帮助解决复杂性。与此相反，我们提出了ImpliRet，一个将推理挑战转移到文档侧处理的基准测试：查询很简单，但相关性取决于文档中通过时间（例如，解决“两天前”）、算术和世界知识关系隐式陈述的事实。我们评估了一系列稀疏和密集检索器，所有这些都在这种设置下表现不佳：最佳的nDCG@10仅为14.91%。我们还测试了长上下文模型是否能克服这一限制。但即使在只有三十个文档（包括正向文档）的短上下文中，GPT-o4-mini得分也仅为55.54%，这表明文档侧推理仍然是一个挑战。我们的代码可在以下网址获取：github.com/ZeinabTaghavi/IMPLIRET

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [424] [SocioVerse: A World Model for Social Simulation Powered by LLM Agents and A Pool of 10 Million Real-World Users](https://arxiv.org/abs/2504.10157)
> *SocioVerse：一个由大型语言模型代理和一千万真实世界用户池驱动的社会模拟世界模型*

*Xinnong Zhang, Jiayu Lin, Xinyi Mou, Shiyue Yang, Xiawei Liu, Libo Sun, Hanjia Lyu, Yihang Yang, Weihong Qi, Yue Chen, Guanying Li, Ling Yan, Yao Hu, Siming Chen, Yu Wang, Xuanjing Huang, Jiebo Luo, Shiping Tang, Libo Wu, Baohua Zhou, Zhongyu Wei* | **Category: cs.CL, cs.CY** | **Updated: 2025-07-15**

**Keywords:** 社会模拟, LLM代理, 世界模型, 人口动态, SocioVerse

**Comment:** 

> **TL;DR:** SocioVerse是一个由LLM代理驱动的社会模拟世界模型，利用千万真实用户数据解决了现有方法的对齐挑战，并在政治、新闻、经济领域的大规模实验中展现了有效性。

**AI_Comments:** SocioVerse的创新之处在于结合了LLM代理的强大能力和千万级真实用户数据池，以构建一个更真实、更具代表性的社会模拟世界模型。这对于克服传统社会模拟的对齐挑战，提高模拟结果的准确性和可信度具有重要意义。其大规模的实验验证也增强了研究的说服力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的社会模拟方法在环境、目标用户、交互机制和行为模式方面面临对齐挑战，阻碍了其捕捉个体差异和预测群体行为的潜力。

**Method:** 本文引入了SocioVerse，一个由LLM代理驱动的社会模拟世界模型。该框架具有四个强大的对齐组件和一个包含1000万真实个体的用户池。通过在政治、新闻和经济三个不同领域进行大规模模拟实验来验证其有效性。

**Result:** 结果表明，SocioVerse能够反映大规模人口动态，并通过标准化程序和最少的人工调整确保多样性、可信度和代表性。

**Conclusion:** SocioVerse是一个有效且强大的社会模拟世界模型，能够克服现有方法的对齐挑战，并准确反映大规模人口动态。

> **ai_Abstract:** 本文介绍了SocioVerse，一个由大型语言模型代理驱动的社会模拟世界模型，旨在解决现有社会模拟方法在环境、用户、交互和行为模式上的对齐挑战。SocioVerse框架包含四个关键对齐组件和一个千万级真实用户池。通过在政治、新闻和经济领域的大规模实验验证，SocioVerse被证明能有效反映大规模人口动态，并保证模拟结果的多样性、可信度与代表性。

> **摘要翻译:** 社会模拟通过建模虚拟个体与其环境之间的互动来改变传统的社会科学研究。随着大型语言模型（LLMs）的最新进展，这种方法在捕捉个体差异和预测群体行为方面显示出越来越大的潜力。然而，现有方法在环境、目标用户、交互机制和行为模式方面面临对齐挑战。为此，我们引入了SocioVerse，一个由LLM代理驱动的社会模拟世界模型。我们的框架具有四个强大的对齐组件和一个包含1000万真实个体的用户池。为了验证其有效性，我们在政治、新闻和经济三个不同领域进行了大规模模拟实验。结果表明，SocioVerse能够反映大规模人口动态，同时通过标准化程序和最少的人工调整确保多样性、可信度和代表性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [425] [Language Models for Adult Service Website Text Analysis](https://arxiv.org/abs/2507.10743)
> *用于成人服务网站文本分析的语言模型*

*Nickolas Freeman, Thanh Nguyen, Gregory Bott, Jason Parton, Collin Francel* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 语言模型, 成人服务网站, 性贩卖, 文本分析, Transformer模型

**Comment:** 32 pages, 12 figures, 1 table

> **TL;DR:** 本研究探讨了语言模型在成人服务网站(ASW)文本分析中的应用，旨在识别性贩卖受害者。研究表明，定制的Transformer模型在处理ASW特有的文本挑战时表现出色，并且可以在有限的资源下高效训练和部署，显著提升了ASW数据分析能力。

**AI_Comments:** 这项研究的创新之处在于针对成人服务网站（ASW）文本的独特挑战（如表情符号、语法差和故意混淆）开发了高效且高性能的定制Transformer模型。其重要性在于为打击性贩卖提供了更强大的工具，通过改进ASW数据分析来识别潜在受害者。研究证明了即使在资源有限的情况下，也能实现卓越的性能，这对于实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 性贩卖是一个严重问题，成人服务网站(ASW)常被用于性贩卖广告。打击性贩卖的组织利用ASW数据识别潜在受害者，但将ASW数据转化为可操作的见解面临文本分析的巨大挑战。ASW广告文本因大量使用表情符号、语法不佳和故意混淆而难以处理。

**Method:** 本研究对应用于ASW文本分析的语言建模方法进行了全面研究，包括简单信息检索方法、预训练Transformer模型和定制Transformer模型。研究还探讨了如何利用ASW文本数据的特性，高效训练和使用定制Transformer模型。

**Result:** 定制的Transformer模型在相对较小的GPU资源下即可高效训练，并可在消费级硬件上高效推理。这些定制模型在准确率、召回率、F1分数和ROC AUC方面优于经过微调的知名编码器Transformer模型（包括BERT-base、RoBERTa和ModernBERT）。研究演示了最佳性能的定制配置在三个ASW数据分析任务上的应用：(i) 分解ASW数据图表示中的巨型组件，(ii) 聚类ASW广告文本，(iii) 利用学习到的Token嵌入来理解表情符号在非法上下文中的使用。

**Conclusion:** 本研究开发的模型代表了ASW文本分析的重大进步，可应用于各种下游应用和研究，有助于打击性贩卖。

> **ai_Abstract:** 本研究旨在通过语言模型分析成人服务网站（ASW）文本，以协助识别性贩卖受害者。由于ASW文本固有的复杂性（如大量表情符号、语法问题和混淆），传统的文本分析面临挑战。研究比较了多种语言建模方法，包括信息检索、预训练和定制Transformer模型。结果表明，定制Transformer模型在处理ASW文本方面表现优异，且能高效训练和部署。这些模型在准确率、召回率、F1分数和ROC AUC等指标上均超越了BERT-base、RoBERTa等微调模型。此外，研究展示了这些模型在分解ASW数据图、聚类广告文本以及理解表情符号非法使用方面的应用，为ASW文本分析提供了显著的进步。

> **摘要翻译:** 性贩卖是指使用武力、欺诈或胁迫，强迫个人违背意愿进行商业性行为。成人服务网站（ASW）过去和现在都与性贩卖相关联，为贩卖者提供了发布受害者广告的平台。因此，参与打击性贩卖的组织在试图识别潜在性贩卖受害者时，经常使用ASW数据。将ASW数据转化为可操作见解的一个关键挑战是文本分析。以往使用ASW数据的研究表明，ASW广告文本对于链接广告至关重要。然而，处理这些文本具有挑战性，因为它们大量使用表情符号、语法不差以及故意混淆以逃避执法部门的审查。我们对该应用领域的语言建模方法进行了全面研究，包括简单信息检索方法、预训练Transformer模型和定制Transformer模型。我们证明了ASW文本数据的特性允许使用相对较小的GPU资源高效训练定制Transformer模型，并可在消费级硬件上高效用于推理。我们的定制模型在准确率、召回率、F1分数和ROC AUC方面优于经过微调的知名仅编码器Transformer模型，包括BERT-base、RoBERTa和ModernBERT。我们展示了我们表现最佳的定制配置在三个与ASW数据分析相关的任务上的使用：(i) 分解ASW数据图表示中的巨型组件，(ii) 聚类ASW广告文本，以及 (iii) 使用学习到的Token嵌入来理解表情符号在我们研究的非法上下文中的使用。我们开发的模型代表了ASW文本分析的重大进步，可在各种下游应用和研究中加以利用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [426] [What is the Best Process Model Representation? A Comparative Analysis for Process Modeling with Large Language Models](https://arxiv.org/abs/2507.11356)
> *什么是最佳流程模型表示？大型语言模型流程建模的比较分析*

*Alexis Brissard, Frédéric Cuppens, Amal Zouaq* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 流程建模, 大型语言模型, 流程模型表示, 比较分析, Mermaid, BPMN text

**Comment:** 12 pages, 7 figures, to be published in AI4BPM 2025 Proceedings

> **TL;DR:** 本文首次实证研究并比较了不同流程模型表示（PMRs）在大型语言模型（LLM）流程建模（PMo）中的适用性和性能，发现Mermaid在PMo中表现最佳，BPMN text在流程模型生成（PMG）中表现最佳。

**AI_Comments:** 这项研究的创新之处在于首次对不同的流程模型表示进行了系统性的实证比较，并构建了一个新的数据集。它为未来在大型语言模型背景下选择和设计流程模型表示提供了重要的指导，有助于推动LLM在流程建模领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有流程模型表示（PMRs）在结构、复杂性和可用性上差异很大，但从未被系统地比较过。此外，当前的流程模型生成（PMG）方法依赖于不同的评估策略和生成技术，使得比较变得困难。因此，需要一项研究来评估这些PMRs。

**Method:** 本文进行了首次实证研究，评估了多种PMRs在LLM流程建模（PMo）背景下的表现。研究引入了一个名为PMo Dataset的新数据集，其中包含55个流程描述及其在九种不同PMRs中的模型。研究从LLM-based PMo的适用性和PMG性能两个维度对PMRs进行了评估。

**Result:** Mermaid在六项PMo标准中获得了最高的综合分数。BPMN text在流程元素相似性方面提供了最佳的PMG结果。

**Conclusion:** 在LLM流程建模（PMo）中，Mermaid在整体适用性方面表现最佳，而BPMN text在流程模型生成（PMG）的流程元素相似性方面表现最佳。

> **ai_Abstract:** 本文首次对不同流程模型表示（PMRs）在大型语言模型（LLM）流程建模（PMo）中的适用性和性能进行了实证比较。研究构建了一个包含55个流程描述和九种PMRs模型的PMo数据集，并评估了PMRs在LLM-based PMo适用性和PMG性能方面的表现。结果显示，Mermaid在整体PMo标准中得分最高，而BPMN text在流程元素相似性方面的PMG表现最佳。

> **摘要翻译:** 大型语言模型（LLMs）正越来越多地应用于流程建模（PMo）任务，例如流程模型生成（PMG）。为了支持这些任务，研究人员引入了各种流程模型表示（PMRs），它们作为模型抽象或生成目标。然而，这些PMRs在结构、复杂性和可用性上差异很大，并且从未被系统地比较过。此外，最近的PMG方法依赖于不同的评估策略和生成技术，使得比较变得困难。本文首次提出了一项实证研究，评估了多种PMRs在LLM流程建模背景下的表现。我们引入了PMo数据集，这是一个包含55个流程描述及其在九种不同PMRs中模型的全新数据集。我们从两个维度评估了PMRs：基于LLM的PMo的适用性以及PMG的性能。Mermaid在六项PMo标准中获得了最高的综合分数，而BPMN text在流程元素相似性方面提供了最佳的PMG结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [436] [HKGAI-V1: Towards Regional Sovereign Large Language Model for Hong Kong](https://arxiv.org/abs/2507.11502)
> *HKGAI-V1：迈向香港区域主权大语言模型*

*Sirui Han, Junqi Zhu, Ruiyuan Zhang, Yike Guo* | **Category: cs.CL, cs.CE, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 主权大语言模型, 香港, 价值对齐, 区域AI, HKGAI-V1

**Comment:** 

> **TL;DR:** HKGAI-V1 是一个为香港量身定制的主权大语言模型，旨在解决其多语言、社会法律和文化背景的独特性。它基于 DeepSeek 架构，通过微调和 RAG 系统进行区域对齐，并开发了评估基准，为区域性 AI 系统提供了可复制的蓝图。

**AI_Comments:** 该论文的创新之处在于其对区域主权大语言模型的关注，特别是针对香港独特的社会文化和法律背景进行深度定制和价值对齐。它不仅开发了一个高性能的区域模型，还提出了一个“治理嵌入式”的数字主权方法，这对于关键领域的 AI 应用具有重要意义。此外，专有评估基准的开发也增强了研究的严谨性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在为香港建立一个价值对齐的 AI 基础设施，以应对香港独特的多语言环境（粤语、普通话和英语）、“一国两制”框架下的独特社会法律背景，以及特定的本地文化和价值观考量。

**Method:** 该模型基于 DeepSeek 架构，并通过多方面的全参数微调过程与区域规范系统性地对齐。它还与检索增强生成（RAG）系统集成，以确保及时和事实依据的信息访问。此外，还开发了一个专有的对抗性香港价值观基准来评估模型对本地道德和法律标准的对齐。

**Result:** 1) 成功开发了 HKGAI-V1，它在处理香港特定文化敏感查询方面优于通用模型，并体现了“治理嵌入式”的数字主权方法，使香港能够在公共服务、法律系统和教育等关键领域行使对 AI 应用的控制。2) 开发了专有的对抗性香港价值观基准，这是一个在挑战性条件下评估模型与本地道德和法律标准对齐的严格工具。

**Conclusion:** 该论文不仅提供了一个技术成果，还为开发深入植根于本地身份的先进、区域性 AI 系统提供了可复制的蓝图。

> **ai_Abstract:** 本文介绍了 HKGAI-V1 的开发，这是一个为香港量身定制的主权大语言模型，旨在建立价值对齐的 AI 基础设施。该模型基于 DeepSeek 架构，通过全参数微调和 RAG 系统进行区域对齐，以适应香港独特的多语言、社会法律和文化背景。主要贡献包括成功开发了在处理香港特定文化敏感查询方面表现优异的 HKGAI-V1，以及开发了用于评估模型对齐性的对抗性香港价值观基准。该研究为开发植根于本地身份的区域性 AI 系统提供了可复制的蓝图。

> **摘要翻译:** 本文介绍了 HKGAI-V1 的开发，这是一个基础主权大语言模型（LLM），作为一项旨在为香港建立量身定制的价值对齐 AI 基础设施的倡议的一部分。为了应对该地区独特的多语言环境（粤语、普通话和英语）、“一国两制”框架下的独特社会法律背景以及特定的本地文化和价值观考量，该模型基于 DeepSeek 架构构建，并通过多方面的全参数微调过程与区域规范系统性地对齐。它进一步与检索增强生成（RAG）系统集成，以确保及时和事实依据的信息访问。其核心贡献在于设计和实施了一个全面的、区域特定的 AI 对齐和安全框架，通过两项关键成就得以体现：1) HKGAI-V1 本身的成功开发——它在处理香港特定文化敏感查询方面优于通用模型，并体现了“治理嵌入式”的数字主权方法——使香港能够在公共服务、法律系统和教育等关键领域行使对 AI 应用的控制。2) 开发了专有的对抗性香港价值观基准，这是一个在挑战性条件下评估模型与本地道德和法律标准对齐的严格工具。通过记录这些成就，本文不仅提供了一个技术成果，还为开发深入植根于本地身份的先进、区域性 AI 系统提供了可复制的蓝图。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [441] [An Agentic Flow for Finite State Machine Extraction using Prompt Chaining](https://arxiv.org/abs/2507.11222)
> *一种使用提示链进行有限状态机提取的代理流*

*Fares Wael, Youssef Maklad, Ali Hamdi, Wael Elsersy* | **Category: cs.CL, cs.AI, cs.NI** | **Updated: 2025-07-15**

**Keywords:** 有限状态机, 大型语言模型, 提示链, 协议分析, 代理系统

**Comment:** 

> **TL;DR:** FlowFSM是一个新的代理框架，结合LLM和提示链，从RFC文档中准确提取有限状态机，并在FTP和RTSP协议上表现出高精度。

**AI_Comments:** 该论文创新性地将LLM与代理流和提示链结合，用于解决FSM提取中的复杂性和模糊性问题，特别是在处理自然语言协议规范方面。其重要性在于提升了FSM提取的自动化和准确性，对于网络协议分析、安全验证和逆向工程具有实际应用价值。通过实验验证了其在减少幻觉转换方面的有效性，这是一个显著的优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有的有限状态机（FSM）提取技术面临可扩展性、不完全覆盖以及自然语言规范模糊性等限制。FSM对于网络协议的操作逻辑建模、验证、分析和漏洞发现至关重要。

**Method:** 本文提出了FlowFSM，一个新颖的代理框架，它利用大型语言模型（LLMs）结合提示链和思维链推理，从原始RFC文档中提取准确的FSM。FlowFSM系统地处理协议规范，识别状态转换，并通过链接代理输出构建结构化的规则手册。

**Result:** 在FTP和RTSP协议上的实验评估表明，FlowFSM实现了高提取精度，同时最大限度地减少了幻觉转换，显示出有前景的结果。

**Conclusion:** 我们的研究结果突出了基于代理的LLM系统在推动协议分析和网络安全及逆向工程应用中FSM推理的潜力。

> **ai_Abstract:** 本文提出了一种名为FlowFSM的新型代理框架，旨在解决现有有限状态机（FSM）提取技术在可扩展性、覆盖范围和自然语言规范模糊性方面的不足。FlowFSM利用大型语言模型（LLMs），结合提示链和思维链推理，从RFC文档中自动提取FSM。该框架通过系统处理协议规范、识别状态转换并链接代理输出来构建结构化规则手册。实验结果表明，FlowFSM在提取FTP和RTSP协议的FSM时表现出高精度，并有效减少了虚假转换，展示了基于代理的LLM系统在协议分析和FSM推理领域的巨大潜力。

> **摘要翻译:** 有限状态机（FSM）对于建模网络协议的操作逻辑至关重要，能够实现验证、分析和漏洞发现。然而，现有的FSM提取技术面临可扩展性、不完全覆盖和自然语言规范模糊性等限制。在本文中，我们提出了FlowFSM，一个新颖的代理框架，它利用大型语言模型（LLMs）结合提示链和思维链推理，从原始RFC文档中提取准确的FSM。FlowFSM系统地处理协议规范，识别状态转换，并通过链接代理输出构建结构化的规则手册。在FTP和RTSP协议上的实验评估表明，FlowFSM实现了高提取精度，同时最大限度地减少了幻觉转换，显示出有前景的结果。我们的研究结果突出了基于代理的LLM系统在推动协议分析和网络安全及逆向工程应用中FSM推理的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [445] [Jan-nano Technical Report](https://arxiv.org/abs/2506.22760)
> *Jan-nano 技术报告*

*Alan Dao, Dinh Bach Vu* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 语言模型, 效率, 强化学习, 专业化, 消费级硬件

**Comment:** 

> **TL;DR:** Jan-nano是一个4B参数的语言模型，通过激进的专业化和新型RLVR系统，在消费级硬件上实现了高效的信息检索能力，打破了大型语言模型的计算资源限制。

**AI_Comments:** 该论文提出了一种创新的方法来解决大型语言模型（LLMs）的计算资源限制问题。其创新点在于采用“激进专业化”策略，即专注于高效信息检索而非全面知识，并引入了新型的多阶段可验证奖励强化学习（RLVR）系统，完全摒弃了传统的下一词预测训练（SFT）。这使得一个相对较小的4B参数模型也能在消费级硬件上实现高性能，对LLM的部署和可访问性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大多数语言模型面临能力与计算资源之间的基本权衡，强大的能力需要大量的计算资源。本文旨在打破这一限制。

**Method:** Jan-nano是一个4B参数的语言模型，通过激进的专业化，专注于即时查找任何信息，而不是尝试了解一切。它从Qwen3-4B进行微调，使用了新型多阶段可验证奖励强化学习（RLVR）系统，该系统完全消除了对下一词预测训练（SFT）的依赖，并集成了MCP。

**Result:** Jan-nano在SimpleQA基准测试中，通过MCP集成实现了83.2%的准确率，并且可以在消费级硬件上运行，具有128K的上下文长度。

**Conclusion:** Jan-nano证明了智能关乎策略而非规模。

> **ai_Abstract:** 本文介绍了Jan-nano，一个4B参数的语言模型，旨在通过激进的专业化和创新的多阶段可验证奖励强化学习（RLVR）系统（完全不依赖SFT）来解决大型语言模型对计算资源的依赖问题。Jan-nano从Qwen3-4B微调而来，专注于高效信息检索，并在SimpleQA基准测试中，结合MCP实现了83.2%的准确率，同时可在消费级硬件上运行，支持128K上下文长度，证明了智能重在策略而非规模。

> **摘要翻译:** 大多数语言模型面临一个基本权衡，即强大的能力需要大量的计算资源。我们通过Jan-nano打破了这一限制，Jan-nano是一个4B参数的语言模型，通过激进的专业化重新定义了效率：它不试图了解一切，而是掌握了即时查找任何信息的艺术。Jan-nano从Qwen3-4B微调而来，使用了我们新颖的多阶段可验证奖励强化学习（RLVR）系统，该系统完全消除了对下一词预测训练（SFT）的依赖，在SimpleQA基准测试中，通过MCP集成实现了83.2%的准确率，同时在消费级硬件上运行。凭借128K的上下文长度，Jan-nano证明了智能关乎策略而非规模。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [448] [Anthropomimetic Uncertainty: What Verbalized Uncertainty in Language Models is Missing](https://arxiv.org/abs/2507.10587)
> *人类模仿的不确定性：语言模型中口头表达的不确定性所缺失的部分*

*Dennis Ulmer, Alexandra Lorson, Ivan Titov, Christian Hardmeier* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-11**

**Keywords:** 语言模型, 不确定性, 人机交互, 自然语言处理, 信任

**Comment:** 

> **TL;DR:** 现有LLM在表达不确定性时缺乏人类的细微差别和真实性，本文提出“人类模仿的不确定性”来改善人机信任和协作。

**AI_Comments:** 这篇论文提出了一个关键且及时的观点，即LLM在表达不确定性时应更具“人性化”。其创新之处在于强调了语言真实性和个性化对于建立人机信任的重要性。通过对人类不确定性交流的全面回顾和对现有偏差的分析，该研究为未来开发更可靠、更具情境感知的LLM提供了重要的理论框架和研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）的输出过于自信，即使准确性存疑，这损害了其可信度和合法性。因此，需要向用户传达LLM的置信度，以促进人机协作并减轻潜在危害。现有自然语言处理（NLP）研究忽视了人类不确定性交流的细微差别和影响机器不确定性交流的数据偏差。

**Method:** 本文提出了“人类模仿的不确定性”的概念，主张通过模仿人类交流来实现直观和值得信赖的不确定性交流，这包括语言真实性和对用户的个性化。作者对人类不确定性交流的研究进行了全面概述，调查了正在进行的研究，并进行了额外分析，以揭示迄今为止被忽视的口头不确定性偏差。

**Result:** 揭示了口头表达不确定性中迄今为止被忽视的偏差。

**Conclusion:** 指出了人机不确定性交流中的独特因素，并将人类模仿的不确定性分解为自然语言处理（NLP）未来的研究方向。

> **ai_Abstract:** 本文探讨了大型语言模型（LLM）在表达不确定性方面的不足，指出其过于自信的输出损害了用户信任。为提升人机协作，作者提出“人类模仿的不确定性”概念，强调通过模仿人类交流的语言真实性和个性化来改进LLM的不确定性表达。文章回顾了人类不确定性交流研究，分析了现有偏差，并为自然语言处理（NLP）领域未来研究方向提供了指导。

> **摘要翻译:** 人类用户越来越依赖与大型语言模型（LLM）的自然语言交互，以获取各种任务和问题的帮助。然而，LLM的输出即使准确性值得怀疑，也经常以非常自信的措辞表达，这损害了LLM的可信度和感知合法性。因此，需要向用户表明语言模型的置信度，以获取人机协作的益处并减轻潜在危害。口头表达的不确定性是通过语言手段表达置信度，这种方法完美地融入了基于语言的界面。然而，大多数最新的自然语言处理（NLP）研究忽视了围绕人类不确定性交流的细微差别以及影响机器不确定性交流的数据偏差。我们主张“人类模仿的不确定性”，这意味着直观和值得信赖的不确定性交流需要一定程度的语言真实性和对用户的个性化，这可以通过模仿人类交流来实现。我们对人类不确定性交流的研究进行了全面概述，调查了正在进行的研究，并进行了额外分析，以证明迄今为止被忽视的口头不确定性偏差。最后，我们指出人机不确定性交流中的独特因素，并将人类模仿的不确定性分解为NLP未来的研究方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [461] [Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs](https://arxiv.org/abs/2507.10772)
> *将文本嵌入模型应用于标签属性图的有效分析*

*Michal Podstawski* | **Category: cs.CL, cs.IR** | **Updated: 2025-07-14**

**Keywords:** 文本嵌入, 标签属性图, 语义分析, 节点分类, 关系预测

**Comment:** 

> **TL;DR:** 这项工作利用文本嵌入模型来增强标签属性图中的语义分析，在不改变图结构的情况下提高了节点分类和关系预测的准确性。

**AI_Comments:** 该研究的创新之处在于利用现成的文本嵌入模型，在不改变图结构的情况下，显著增强了图分析的能力。这对于需要深度文本上下文理解的任务尤为重要，为属性图的语义分析开辟了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 标签属性图通常包含丰富的文本属性，如果利用得当，可以增强分析任务。本研究的动机是利用这些文本属性来提高分析效率和深度。

**Method:** 通过嵌入文本节点和边属性，支持下游任务，包括节点分类和关系预测。该方法将语言模型嵌入集成到图管道中，而无需改变其结构。

**Result:** 文本语义可以显著提高属性图分析的准确性和可解释性，并改进了上下文理解能力，从而增强了节点分类和关系预测等任务。

**Conclusion:** 通过将预训练文本嵌入模型集成到图分析流程中，文本语义能够显著增强标签属性图分析的准确性和可解释性。

> **ai_Abstract:** 本文探讨了将预训练文本嵌入模型应用于标签属性图，以提升语义分析的效率。通过嵌入节点和边的文本属性，该方法增强了包括节点分类和关系预测在内的下游任务，并改善了上下文理解。该方法将语言模型嵌入无缝集成到现有图管道中，证明利用文本语义可以显著提高属性图分析的准确性和可解释性。

> **摘要翻译:** 标签属性图通常包含丰富的文本属性，如果利用得当，可以增强分析任务。这项工作探索了使用预训练文本嵌入模型，以在此类图中实现高效的语义分析。通过嵌入文本节点和边属性，我们支持下游任务，包括节点分类和关系预测，并提高了上下文理解能力。我们的方法将语言模型嵌入集成到图管道中，而无需改变其结构，这表明文本语义可以显著提高属性图分析的准确性和可解释性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [468] [Addressing Data Imbalance in Transformer-Based Multi-Label Emotion Detection with Weighted Loss](https://arxiv.org/abs/2507.11384)
> *基于Transformer的多标签情感检测中加权损失处理数据不平衡问题*

*Xia Cui* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 数据不平衡, 加权损失, Transformer, 多标签情感检测, SemEval-2025

**Comment:** 10 pages, 1 figure, SemEval 2025

> **TL;DR:** 本文提出并评估了一种简单的加权损失函数，用于解决基于Transformer的多标签情感检测中的数据不平衡问题。

**AI_Comments:** 该论文提出了一种计算成本较低的加权损失方法来处理数据不平衡问题，避免了传统重采样方法的计算开销，具有一定的创新性。然而，其对少数类别的有限提升表明该方法仍有改进空间，可能需要结合其他技术来更有效地解决长尾分布问题。

<details>
  <summary>Details</summary>

**Motivation:** 在基于Transformer的多标签情感检测中，数据不平衡是一个挑战，尤其是在少数情感类别上的性能提升。

**Method:** 本文提出了一种简单的加权损失函数，通过动态调整类别权重来解决数据不平衡问题。该方法应用于BERT、RoBERTa和BART等基于Transformer的模型，并在BRIGHTER数据集上进行评估，使用Micro F1、Macro F1、ROC-AUC、Accuracy和Jaccard相似系数作为评估指标。

**Result:** 加权损失函数改善了高频率情感类别的性能，但对少数类别的影响有限。

**Conclusion:** 研究结果强调了将加权损失应用于不平衡多标签情感检测的有效性和挑战性。

> **ai_Abstract:** 本文提出了一种简单的加权损失函数，用于解决基于Transformer模型在多标签情感检测中的数据不平衡问题。该方法通过动态调整类别权重，旨在提升少数情感类别的性能，并避免传统重采样方法的计算负担。研究在BRIGHTER数据集上评估了BERT、RoBERTa和BART模型，结果显示加权损失函数改善了高频率类别的性能，但对少数类别的效果有限，这揭示了该方法在不平衡多标签情感检测中的有效性与挑战并存。

> **摘要翻译:** 本文探讨了在SemEval-2025共享任务11中，将简单的加权损失函数应用于基于Transformer的模型，用于多标签情感检测。我们的方法通过动态调整类别权重来解决数据不平衡问题，从而在不增加传统重采样方法计算负担的情况下，提升少数情感类别的性能。我们在BRIGHTER数据集上评估了BERT、RoBERTa和BART模型，使用了Micro F1、Macro F1、ROC-AUC、Accuracy和Jaccard相似系数等评估指标。结果表明，加权损失函数改善了高频率情感类别的性能，但对少数类别的影响有限。这些发现强调了将这种方法应用于不平衡多标签情感检测的有效性和挑战性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [469] [ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models](https://arxiv.org/abs/2506.22791)
> *ContextCache：面向大型语言模型多轮查询的上下文感知语义缓存*

*Jianxin Yan, Wangze Ni, Lei Chen, Xuemin Lin, Peng Cheng, Zhan Qin, Kui Ren* | **Category: cs.CL, cs.DB** | **Updated: 2025-07-15**

**Keywords:** 语义缓存, 大型语言模型, 多轮对话, 上下文感知, 计算成本

**Comment:** 

> **TL;DR:** ContextCache是一个针对大型语言模型（LLM）多轮对话的上下文感知语义缓存系统，通过两阶段检索架构解决现有系统在不同对话场景下匹配不准确的问题，显著降低延迟并提高缓存命中精度和召回率。

**AI_Comments:** ContextCache的创新点在于其引入了上下文感知能力，通过两阶段检索和自注意力机制有效解决了传统语义缓存系统在多轮对话中上下文缺失的问题。这对于提升LLM在实际应用中的效率和用户体验具有重要意义，尤其是在需要频繁交互的场景下，能显著降低运营成本并提高响应速度。

<details>
  <summary>Details</summary>

**Motivation:** 现有的语义缓存系统主要依赖于匹配单个查询，缺乏对多轮对话上下文的感知，导致在不同对话场景中出现相似查询时，缓存命中不准确。

**Method:** ContextCache采用两阶段检索架构：首先对当前查询进行基于向量的检索以识别潜在匹配；然后通过自注意力机制整合当前和历史对话表示，进行精确的上下文匹配。

**Result:** 与现有方法相比，ContextCache提高了精度和召回率。此外，缓存响应的延迟比直接调用LLM低约10倍。

**Conclusion:** ContextCache通过其上下文感知能力，显著提升了LLM多轮对话中语义缓存的效率和准确性，并大幅降低了计算成本和延迟。

> **ai_Abstract:** ContextCache是一种新型的上下文感知语义缓存系统，专为大型语言模型（LLM）的多轮对话设计。它解决了现有缓存系统在处理多轮对话时缺乏上下文感知导致的不准确匹配问题。ContextCache采用两阶段检索架构，结合向量检索和自注意力机制来整合当前和历史对话上下文，以实现精确匹配。实验证明，该系统在真实对话中显著提高了缓存的精度和召回率，并将响应延迟降低了约10倍，从而大幅节省了LLM应用中的计算成本。

> **摘要翻译:** 语义缓存通过存储和重用大型语言模型（LLM）的响应，显著降低了计算成本并提高了效率。然而，现有系统主要依赖于匹配单个查询，缺乏对多轮对话上下文的感知，这导致在不同对话场景中出现相似查询时，缓存命中不准确。本演示介绍了ContextCache，一个用于多轮对话的上下文感知语义缓存系统。ContextCache采用两阶段检索架构，首先对当前查询执行基于向量的检索以识别潜在匹配，然后通过自注意力机制整合当前和历史对话表示，进行精确的上下文匹配。对真实世界对话的评估表明，与现有方法相比，ContextCache提高了精度和召回率。此外，缓存响应的延迟比直接调用LLM低约10倍，从而显著降低了LLM对话应用程序的计算成本。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [495] [Stylometry recognizes human and LLM-generated texts in short samples](https://arxiv.org/abs/2507.00838)
> *文体学识别短样本中的人类和LLM生成文本*

*Karol Przystalski, Jan K. Argasiński, Iwona Grabska-Gradzińska, Jeremi K. Ochab* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 文体学, LLM检测, 文本分类, AI生成文本, 作者归属

**Comment:** 

> **TL;DR:** 该研究表明，文体学可以有效区分短样本中的人类和大型语言模型（LLM）生成的文本，这对于模型归因、知识产权和伦理AI使用至关重要。

**AI_Comments:** 该论文创新性地将文体学应用于当前热门的LLM文本检测领域，尤其关注短样本的识别，并通过SHAP解释了区分特征，具有重要意义。这对于解决AI时代的内容真实性、知识产权和作者归属问题具有实际应用价值。然而，研究主要针对“定义明确的文本类型”（如维基百科摘要），其结论的普适性可能需要进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在探索文体学作为一种区分大型语言模型（LLMs）生成文本与人类创作文本的方法，以解决模型归因、知识产权和伦理AI使用等问题。通过将其应用于LLM生成文本，研究人员旨在识别其新兴的写作模式。

**Method:** 研究创建了一个基于维基百科的基准数据集，包含：(a) 人类撰写的术语摘要，(b) 纯粹由LLMs（GPT-3.5/4、LLaMa 2/3、Orca和Falcon）生成的文本，(c) 经过多种文本摘要方法（T5、BART、Gensim和Sumy）处理的文本，以及 (d) 经过复述方法（Dipper、T5）处理的文本。这些10句话长的文本通过树状模型（决策树和LightGBM）进行分类，使用了人工设计（StyloMetrix）和基于N-gram（自有管道）的文体学特征，这些特征编码了词汇、语法、句法和标点模式。

**Result:** 交叉验证结果显示，在7个类别的多分类场景中，性能达到高达0.87的Matthews相关系数；在二元分类中，准确率介于0.79和1.0之间，其中维基百科和GPT-4的特定示例在平衡数据集上达到了0.98的准确率。Shapley加性解释（SHAP）指出了百科全书文本类型的特征、过度使用的个体词汇，以及LLMs相对于人类文本在语法标准化方面的更高程度。

**Conclusion:** 研究结果关键地表明，在日益复杂的大型语言模型背景下，至少对于定义明确的文本类型，区分机器生成文本和人类生成文本是可能的。

> **ai_Abstract:** 该论文探讨了利用文体学区分人类和大型语言模型（LLM）生成文本的可行性，以应对模型归因、知识产权及伦理AI应用挑战。研究构建了一个基于维基百科的基准数据集，包含人类撰写、多种LLM（如GPT-3.5/4、LLaMa 2/3）生成以及经摘要或复述处理的短文本样本。通过决策树和LightGBM模型，结合人工设计和基于N-gram的文体学特征（涵盖词汇、语法、句法、标点），实现了高精度分类（多分类MCC高达0.87，二分类准确率0.79-1.0，特定组合高达0.98）。特征分析揭示了LLM文本在语法标准化等方面的独特模式。研究结论是，即使面对日益复杂的LLMs，区分机器与人类生成文本对于特定文本类型是可行的。

> **摘要翻译:** 该论文探讨了文体学作为一种区分大型语言模型（LLMs）和人类创建文本的方法，旨在解决模型归因、知识产权和伦理AI使用等问题。文体学已被广泛用于表征文本风格和归因作者身份。通过将其应用于LLM生成文本，我们识别了它们新兴的写作模式。该论文涉及创建一个基于维基百科的基准数据集，其中包含 (a) 人类撰写的术语摘要，(b) 纯粹由LLMs（GPT-3.5/4、LLaMa 2/3、Orca和Falcon）生成的文本，(c) 通过多种文本摘要方法（T5、BART、Gensim和Sumy）处理的文本，以及 (d) 通过复述方法（Dipper、T5）处理的文本。这些10句话长的文本通过树状模型（决策树和LightGBM）进行分类，使用了人工设计（StyloMetrix）和基于N-gram（我们自己的管道）的文体学特征，这些特征编码了词汇、语法、句法和标点模式。交叉验证结果显示，在7个类别的多分类场景中，性能达到高达0.87的Matthews相关系数，在二元分类中，准确率介于0.79和1.0之间，其中维基百科和GPT-4的特定示例在平衡数据集上达到了0.98的准确率。Shapley加性解释指出了百科全书文本类型的特征、过度使用的个体词汇，以及LLMs相对于人类撰写文本在语法标准化方面的更高程度。这些结果——至关重要的是，在日益复杂的大型语言模型背景下——表明至少对于定义明确的文本类型，区分机器生成文本和人类生成文本是可能的。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [499] [Can Multimodal Foundation Models Understand Schematic Diagrams? An Empirical Study on Information-Seeking QA over Scientific Papers](https://arxiv.org/abs/2507.10787)
> *多模态基础模型能理解示意图吗？一项关于科学论文信息检索式问答的实证研究*

*Yilun Zhao, Chengye Wang, Chuhan Li, Arman Cohan* | **Category: cs.CL, cs.CV** | **Updated: 2025-07-14**

**Keywords:** 多模态基础模型, 示意图理解, 信息检索式问答, 科学论文, 基准测试

**Comment:** ACL 2025 Findings

> **TL;DR:** 本文介绍了MISS-QA，一个用于评估模型理解科学论文中示意图能力的基准测试。研究发现，当前最先进的多模态模型在MISS-QA上的表现与人类专家之间存在显著差距，并揭示了这些模型的优缺点。

**AI_Comments:** 该论文的创新之处在于构建了首个专门针对科学论文中示意图理解的基准测试MISS-QA，填补了现有评估工具的空白。其重要性在于通过实证研究揭示了当前前沿多模态基础模型在复杂图表理解方面与人类专家之间的显著差距，并提供了详细的错误分析，为未来模型在多模态科学文献理解方面的改进指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 为了评估模型解释科学文献中示意图的能力，本文引入了首个专门为此设计的基准测试，因为目前缺乏此类评估工具。

**Method:** 本文引入了MISS-QA，一个包含465篇科学论文中1,500个专家标注示例的基准测试。模型被要求解释研究概述的示意图并基于论文的更广泛上下文回答信息检索问题。研究评估了18个前沿多模态基础模型，包括o4-mini、Gemini-2.5-Flash和Qwen2.5-VL。

**Result:** 研究发现，这些模型与人类专家在MISS-QA上的表现存在显著差距。对不可回答问题的模型表现分析和详细的错误分析进一步揭示了当前模型的优势和局限性。

**Conclusion:** 本文的研究结果和详细分析为提升模型理解多模态科学文献的能力提供了关键见解。

> **ai_Abstract:** 本文引入了MISS-QA，这是首个专门用于评估模型解释科学文献中示意图能力的基准测试。该基准包含1,500个专家标注示例，要求模型解释示意图并回答相关信息检索问题。研究评估了18个前沿多模态基础模型，发现它们与人类专家在性能上存在显著差距。详细的错误分析揭示了当前模型的优缺点，为未来提升模型理解多模态科学文献提供了重要见解。

> **摘要翻译:** 本文介绍了MISS-QA，这是第一个专门用于评估模型解释科学文献中示意图能力的基准测试。MISS-QA包含来自465篇科学论文的1,500个专家标注示例。在此基准测试中，模型的任务是解释说明研究概述的示意图，并根据论文的更广泛上下文回答相应的信息检索问题。我们评估了18个前沿多模态基础模型（包括o4-mini、Gemini-2.5-Flash和Qwen2.5-VL）的性能。我们揭示了这些模型与人类专家在MISS-QA上存在显著的性能差距。我们对模型在不可回答问题上的表现分析以及详细的错误分析进一步突出了当前模型的优势和局限性，为增强模型理解多模态科学文献的能力提供了关键见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [501] [DCR: Quantifying Data Contamination in LLMs Evaluation](https://arxiv.org/abs/2507.11405)
> *DCR：量化大型语言模型评估中的数据污染*

*Cheng Xu, Nan Yan, Shuhao Guan, Changhong Jin, Yuke Mei, Yibing Guo, M-Tahar Kechadi* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 数据污染, 大型语言模型, 评估, DCR框架, 基准测试

**Comment:** 

> **TL;DR:** DCR框架通过量化数据污染风险，提高了大型语言模型评估的准确性和可信度。

**AI_Comments:** DCR框架的创新之处在于其分层的数据污染量化方法（语义、信息、数据、标签）以及使用模糊推理系统整合污染分数，生成一个统一的DCR因子来调整模型性能。这对于提高LLM评估的准确性和可信度至关重要，因为它解决了数据污染导致性能虚高的问题。其轻量级和高计算效率的特点也使其具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的快速发展引发了对基准数据污染（BDC）的担忧，即模型无意中记忆了评估数据，导致性能指标虚高，并损害了对真实泛化能力的评估。本研究旨在解决这一问题。

**Method:** 本论文引入了数据污染风险（DCR）框架，这是一个轻量级、可解释的管道，旨在检测和量化四个细粒度级别的数据污染：语义、信息、数据和标签。通过模糊推理系统综合污染分数，DCR生成一个统一的DCR因子，用于调整原始准确性以反映考虑污染的性能。

**Result:** DCR框架在9个LLMs（0.5B-72B）上进行了验证，涉及情感分析、假新闻检测和算术推理任务。结果显示，DCR能够可靠地诊断污染严重程度，并且使用DCR因子调整后的准确性与未受污染的基线相比，在三个基准测试中的平均误差在4%以内。

**Conclusion:** DCR框架提供了一个实用的工具，可以将污染评估整合到常规评估中，从而促进更公平的比较并增强LLM基准测试实践的可信度。

> **ai_Abstract:** 本论文提出了数据污染风险（DCR）框架，一个轻量级且可解释的管道，用于检测和量化大型语言模型评估中的基准数据污染。DCR在语义、信息、数据和标签四个层面分析污染，并通过模糊推理系统生成一个统一的DCR因子，用于调整原始准确性以反映真实的性能。该框架在多个LLMs和任务上得到验证，能有效诊断污染并提高评估准确性，旨在为LLM基准测试提供更公平和可信的评估方法。

> **摘要翻译:** 大型语言模型（LLMs）的快速发展加剧了对基准数据污染（BDC）的担忧，即模型无意中记忆了评估数据，从而夸大了性能指标并损害了真实的泛化能力评估。本文介绍了数据污染风险（DCR）框架，这是一个轻量级、可解释的管道，旨在检测和量化四个细粒度级别的数据污染：语义、信息、数据和标签。通过模糊推理系统综合污染分数，DCR生成一个统一的DCR因子，用于调整原始准确性以反映考虑污染的性能。DCR框架在9个LLMs（0.5B-72B）上进行了验证，涵盖情感分析、假新闻检测和算术推理任务，它能够可靠地诊断污染严重程度，并且使用DCR因子调整后的准确性与未受污染的基线相比，在三个基准测试中的平均误差在4%以内。DCR强调计算效率和透明度，提供了一个实用的工具，可将污染评估整合到常规评估中，从而促进更公平的比较并增强LLM基准测试实践的可信度。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [519] [GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons](https://arxiv.org/abs/2507.02221)
> *GDC队列副驾驶：一个用于从基因组数据公共数据库中筛选队列的AI副驾驶工具*

*Steven Song, Anirudh Subramanyam, Zhenyu Zhang, Aarti Venkat, Robert L. Grossman* | **Category: cs.CL** | **Updated: 2025-07-14**

**Keywords:** GDC, 队列筛选, AI副驾驶, 自然语言处理, 大型语言模型

**Comment:** 12 pages, 1 figure, 7 tables. v2 updated to reflect migration to HF
  Spaces

> **TL;DR:** GDC Cohort Copilot是一个AI工具，它允许用户通过自然语言描述来自动生成基因组数据公共数据库（GDC）中的癌症患者队列，并提供一个本地部署的开源大型语言模型，其性能优于GPT-4o。

**AI_Comments:** 该论文介绍的GDC Cohort Copilot具有显著的创新性，它利用自然语言处理（NLP）技术解决了GDC用户在复杂数据平台中筛选队列的痛点。其重要性在于，通过允许用户使用自然语言描述其需求，大大降低了数据访问和分析的门槛，尤其对非专业用户而言。此外，该研究的一个亮点是开发了一个本地部署的开源LLM，并证明其性能优于GPT-4o，这不仅展示了其技术的有效性，也为社区提供了可自由使用和改进的资源。这种开源和本地部署的策略对于数据隐私和安全性也具有潜在优势。

<details>
  <summary>Details</summary>

**Motivation:** GDC用户在通过图形界面创建复杂队列时，难以在数百个可能的字段中找到特定的队列描述符，但他们能够更好地用自由文本自然语言描述所需的队列。

**Method:** GDC Cohort Copilot是一个开源的副驾驶工具，它接收用户输入的自然语言描述，自动生成相应的GDC队列过滤器，然后将队列导出回GDC进行进一步分析。它还提供一个交互式用户界面供用户细化。该工具开发并评估了多个大型语言模型（LLMs），其中一个本地部署的开源GDC Cohort LLM被证明比GPT-4o在生成GDC队列方面表现更好。该工具被实现为一个容器化的Gradio应用程序，并在HuggingFace Spaces上共享。

**Result:** 所开发的本地部署开源GDC Cohort LLM在生成GDC队列方面取得了比GPT-4o更好的结果。

**Conclusion:** GDC Cohort Copilot通过自然语言处理大大简化了GDC中癌症患者队列的筛选过程，并通过其高性能的开源LLM提供了一个有效的解决方案，提高了用户体验和数据可访问性。

> **ai_Abstract:** GDC Cohort Copilot是一个创新的开源AI工具，旨在简化从基因组数据公共数据库（GDC）中筛选癌症患者队列的过程。针对用户在复杂图形界面中寻找特定描述符的痛点，该工具允许用户通过自然语言描述来自动生成所需的GDC队列过滤器。研究开发并评估了多个大型语言模型，结果表明其本地部署的开源GDC Cohort LLM在性能上优于GPT-4o。该工具以容器化Gradio应用的形式在HuggingFace Spaces上发布，并提供了LLM权重和源代码，极大地提高了GDC数据筛选的便利性和可访问性。

> **摘要翻译:** 基因组数据公共数据库（GDC）通过一个以患者队列为中心的统一筛选和分析平台，提供高质量、协调一致的癌症基因组数据访问。虽然GDC用户可以通过图形化的队列构建器交互式地创建复杂队列，但用户（尤其是新用户）可能难以在数百个可能的字段和属性中找到特定的队列描述符。然而，用户可能能够更好地用自由文本自然语言描述他们所需的队列。我们引入了GDC Cohort Copilot，一个用于从GDC中筛选队列的开源副驾驶工具。GDC Cohort Copilot根据用户输入的所需队列的自然语言描述，自动生成相应的GDC队列过滤器，然后将队列导出回GDC进行进一步分析。一个交互式用户界面允许用户进一步完善生成的队列。我们为GDC Cohort Copilot开发并评估了多个大型语言模型（LLMs），并证明我们本地部署的开源GDC Cohort LLM在生成GDC队列方面取得了比GPT-4o提示更好的结果。我们将GDC Cohort Copilot作为容器化的Gradio应用程序在HuggingFace Spaces上实现并共享，可在https://huggingface.co/spaces/uc-ctds/GDC-Cohort-Copilot访问。GDC Cohort LLM的权重可在https://huggingface.co/uc-ctds获取。所有源代码均可在https://github.com/uc-cdis/gdc-cohort-copilot获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [546] [Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?](https://arxiv.org/abs/2507.11423)
> *大型语言模型中的推理策略：它们能遵循、偏好和优化吗？*

*Yanjian Zhang, Guillaume Wisniewski, Nadi Tomeh, Thierry Charnois* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 推理策略, 提示工程, 策略选择, 逻辑问题解决

**Comment:** 

> **TL;DR:** 研究探讨了通过提示能否控制大型语言模型的推理策略，发现没有单一策略能持续提高准确性，但如果模型能自适应选择策略，性能会提升，并提出了指导策略选择的方法。

**AI_Comments:** 这篇论文的创新点在于它关注了LLMs的“策略选择”而非单一策略的优化，这与人类的推理方式更为接近。它揭示了LLMs在推理方面的一个关键限制，即缺乏适应性策略选择能力。虽然实验结果表明没有万能的单一策略，但提出了一个重要的方向：通过引导LLMs自适应地选择最佳策略来提升其性能。这对于未来设计更智能、更灵活的LLM推理系统具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 先前工作表明，大型语言模型（LLMs）倾向于采用单一推理策略，这可能限制了它们在各种推理挑战中的有效性，而人类推理则涉及针对特定问题的不同策略。

**Method:** 本研究调查了提示能否控制LLMs的推理策略，并评估了其对逻辑问题解决的影响。

**Result:** 实验表明，没有单一策略能持续提高准确性；但如果模型能自适应选择最优策略，性能可能会得到提升。

**Conclusion:** 虽然没有单一策略能持续提高LLM的准确性，但通过引导LLMs进行策略选择，可以提升其推理能力，这意味着自适应策略选择是提高LLM性能的关键。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）的推理策略问题，指出LLMs倾向于使用单一策略，这限制了其在多样化推理任务中的表现。文章通过实验验证了提示能否控制LLM的推理策略及其对逻辑问题解决的影响。结果显示，虽然没有单一策略能持续提升准确性，但若LLMs能自适应选择最优策略，其性能将显著提高。为此，研究提出了一些指导LLMs进行策略选择的方法，为提升其推理能力开辟了新途径。

> **摘要翻译:** 人类推理涉及不同的策略，每种策略都适合特定的问题。先前的研究表明，大型语言模型（LLMs）倾向于采用单一推理策略，这可能会限制它们在各种推理挑战中的有效性。在这项工作中，我们研究了提示能否控制LLMs的推理策略，并评估其对逻辑问题解决的影响。虽然我们的实验表明没有单一策略能持续提高准确性，但如果模型能够自适应地选择最优策略，性能可能会得到提升。我们提出了指导LLMs进行策略选择的方法，突出了完善其推理能力的新途径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [547] [Conversation Forests: The Key to Fine Tuning Large Language Models for Multi-Turn Medical Conversations is Branching](https://arxiv.org/abs/2507.04099)
> *对话森林：微调大型语言模型以实现多轮医疗对话的关键在于分支*

*Thomas Savage* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 多轮对话, 大型语言模型, 强化学习, 医疗对话, 分支训练

**Comment:** 

> **TL;DR:** 提出一种名为Savage Conversation Forests (SCF)的分支式强化学习框架，用于微调LLM以处理多轮医疗对话，结果显示其在诊断准确性上优于线性架构。

**AI_Comments:** 这篇论文的创新点在于引入了“分支”概念来解决LLM在多轮对话中面临的挑战，特别是其在医疗诊断场景中的应用。传统的线性训练方法难以捕捉多轮对话中早期选择对后续结果的复杂影响，而SCF通过生成和探索多个对话路径，能够为模型提供更丰富、更具关联性的训练信号。这对于需要深度理解和推理的多轮交互任务，如诊断访谈，具有重要意义。该方法为LLM在复杂、长程依赖的对话场景中的微调开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LLM微调方法在单轮任务中表现良好，但在多轮对话（如医疗诊断访谈）中表现不足，因为它们未能理解早期对话轮次如何影响后续结果，而这在医学领域至关重要。

**Method:** 引入Savage Conversation Forests (SCF)，一个强化学习框架，利用分支对话架构来微调LLM处理多轮对话。SCF在每一轮生成多个可能的对话延续，使模型能够学习不同早期回应如何影响后续互动和诊断结果。

**Result:** 在模拟医患对话的实验中，采用分支结构的SCF在诊断准确性上优于线性对话架构。作者推测，SCF的改进源于其能够提供更丰富、相互依存的跨对话轮次训练信号。

**Conclusion:** 这些结果表明，分支训练架构是微调大型语言模型以处理复杂多轮对话任务的重要策略。

> **ai_Abstract:** 该论文提出了一种名为Savage Conversation Forests (SCF)的强化学习框架，旨在解决现有LLM微调方法在多轮对话（特别是医疗领域）中的不足。SCF通过采用分支对话架构，在每轮对话中生成多种可能的延续，从而使模型能够学习早期回应如何影响后续互动和诊断结果。实验证明，在模拟医患对话中，SCF在诊断准确性方面优于传统的线性对话架构，表明分支训练是处理复杂多轮对话任务的有效策略。

> **摘要翻译:** 微调方法，如直接偏好优化（DPO）和组相对策略优化（GRPO），已在训练大型语言模型（LLMs）用于单轮任务方面取得了成功。然而，这些方法在多轮应用中表现不足，例如诊断性患者访谈，在这些应用中，理解早期对话轮次如何影响下游完成和结果至关重要。在医学领域，多轮视角对于学习诊断图式和更好地理解对话动态至关重要。为了解决这一空白，我引入了Savage Conversation Forests（SCF），一个强化学习框架，它利用分支对话架构来微调LLMs以实现多轮对话。SCF在每一轮生成多个可能的对话延续，使模型能够学习不同早期回应如何影响下游互动和诊断结果。在模拟医患对话的实验中，采用分支结构的SCF在诊断准确性上优于线性对话架构。我假设SCF的改进源于其能够提供更丰富、相互依存的跨对话轮次训练信号。这些结果表明，分支训练架构是微调LLMs以处理复杂多轮对话任务的重要策略。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [551] [PLEX: Perturbation-free Local Explanations for LLM-Based Text Classification](https://arxiv.org/abs/2507.10596)
> *PLEX：基于LLM的文本分类的无扰动局部解释*

*Yogachandran Rahulamathavan, Misbah Farooq, Varuna De Silva* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-12**

**Keywords:** LLM, 文本分类, 可解释性AI, 局部解释, 无扰动

**Comment:** 

> **TL;DR:** PLEX是一种新的无扰动方法，用于高效地为基于LLM的文本分类提供局部解释，其性能与LIME和SHAP相当，但速度快得多。

**AI_Comments:** PLEX的创新之处在于其“无扰动”机制，通过利用LLM内部的上下文嵌入和一次性训练的神经网络，极大地解决了传统局部解释方法计算成本高昂的痛点。这对于LLM这种计算密集型模型尤为重要，使得解释过程在实际应用中更具可行性。其在效率上的巨大提升是该方法最显著的优势，为LLM的可解释性研究开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在文本分类中表现出色，但其复杂性导致可解释性差，难以理解其预测背后的推理。现有可解释人工智能（XAI）方法（如LIME和SHAP）依赖于计算成本高昂的扰动，这对于LLM来说会带来巨大的计算负担。

**Method:** 本文提出了PLEX（Perturbation-free Local Explanation），该方法利用从LLM中提取的上下文嵌入和一个训练好的“Siamese network”风格神经网络来与特征重要性分数对齐。这种一次性训练消除了后续扰动的需要，从而能够高效地为任何新句子提供解释。

**Result:** PLEX在四种不同的分类任务（情感、假新闻、假COVID-19新闻和抑郁症）上有效，显示与LIME和SHAP的协议率超过92%。在“压力测试”中，PLEX准确识别了有影响力的词，导致分类准确率的下降与LIME和SHAP观察到的相似，甚至在某些情况下表现出更优的性能。PLEX极大地加速了解释过程，分别将时间和计算开销减少了两个和四个数量级。

**Conclusion:** PLEX为可解释的基于LLM的文本分类提供了一个有前景的解决方案，显著提高了解释的效率和可行性。

> **ai_Abstract:** 本文提出了PLEX，一种用于基于LLM文本分类的无扰动局部解释方法。针对现有XAI方法（如LIME、SHAP）计算开销大的问题，PLEX利用LLM上下文嵌入和Siamese网络一次性训练，无需后续扰动即可高效生成解释。实验表明PLEX与LIME、SHAP高度一致，且在解释效率上实现了显著提升（时间减少两数量级，开销减少四数量级），为LLM可解释性提供了高效解决方案。

> **摘要翻译:** 大型语言模型（LLM）在文本分类方面表现出色，但其复杂性阻碍了可解释性，使得理解其预测背后的推理变得困难。LIME和SHAP等可解释人工智能（XAI）方法通过识别有影响力的词来提供局部解释，但它们依赖于计算成本高昂的扰动。这些方法通常生成数千个扰动句子并对每个句子进行推理，这带来了巨大的计算负担，尤其是在LLM上。为了解决这个问题，我们提出了无扰动局部解释（PLEX），这是一种新颖的方法，它利用从LLM中提取的上下文嵌入和训练好的“Siamese network”风格神经网络来与特征重要性分数对齐。这种一次性训练消除了后续扰动的需要，从而能够高效地为任何新句子提供解释。我们在四种不同的分类任务（情感、假新闻、假COVID-19新闻和抑郁症）上证明了PLEX的有效性，显示与LIME和SHAP的协议率超过92%。我们使用“压力测试”进行的评估表明，当移除这些词时，PLEX准确地识别了有影响力的词，导致分类准确率的下降与LIME和SHAP观察到的相似。值得注意的是，在某些情况下，PLEX在捕捉关键特征的影响方面表现出卓越的性能。PLEX极大地加速了解释过程，分别将时间和计算开销减少了两个和四个数量级。这项工作为基于LLM的文本分类的可解释性提供了一个有前景的解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [552] [LLMs on Trial: Evaluating Judicial Fairness for Large Language Models](https://arxiv.org/abs/2507.10852)
> *LLMs受审：评估大型语言模型的司法公平性*

*Yiran Hu, Zongyue Xue, Haitao Li, Siyuan Zheng, Qingjing Chen, Shaochun Wang, Xihan Zhang, Ning Zheng, Yun Liu, Qingyao Ai, Yiqun Liu, Charles L. A. Clarke, Weixing Shen* | **Category: cs.CL** | **Updated: 2025-07-14**

**Keywords:** 大型语言模型, 司法公平性, 偏见, 不一致性, JudiFair数据集

**Comment:** 

> **TL;DR:** 该研究评估了LLMs在司法应用中的公平性，发现其普遍存在不一致性、偏见和不平衡不准确性，尤其在人口统计学标签上偏见更显著，并发布了相关数据集和工具包以支持未来研究。

**AI_Comments:** 该研究创新性地构建了一个全面的司法公平性评估框架和数据集，并提出了新的评估指标，为LLMs在高风险领域的应用提供了关键的公平性视角。揭示LLMs在司法场景中普遍存在的偏见和不一致性，特别是人口统计学偏见，对于LLMs的负责任部署具有重要指导意义。同时，该研究提供的公共工具包将极大地促进未来LLM公平性研究。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）越来越多地应用于高风险领域，其决策影响权利和公平，但LLMs的司法公平性及其对社会正义的影响尚未得到充分探索。确保LLMs作为法官时能公平解决司法问题是其可信度的先决条件。

**Method:** 研究基于司法公平理论构建了一个衡量LLM公平性的综合框架（包含65个标签和161个值），并编制了包含177,100个独特案例事实的JudiFair数据集。开发了不一致性、偏见和不平衡不准确性三个评估指标，并引入了一种评估多个LLM整体公平性的方法。对16个LLM进行了实验，并发布了一个包含所有数据集和代码的公共工具包。

**Result:** 实验发现16个LLM普遍存在不一致性、偏见和不平衡不准确性，突显了严重的LLM司法不公平性。LLMs在人口统计学标签上显示出更明显的偏见，在实体标签上的偏见略低于程序标签。不一致性增加与偏见减少相关，但更准确的预测会加剧偏见。调整温度参数可以影响LLM公平性，而模型大小、发布日期和原产国对司法公平性没有显著影响。

**Conclusion:** LLMs在司法应用中存在严重的公平性问题，尤其体现在人口统计学偏见方面。尽管某些参数（如温度）可影响公平性，但模型固有特性（大小、发布日期、来源国）影响不大。研究强调了评估和改进LLM公平性的重要性，并提供了支持未来研究的工具包。

> **ai_Abstract:** 该论文探讨了大型语言模型（LLMs）在司法应用中的公平性问题。研究团队基于司法公平理论构建了一个综合框架，并创建了包含17.7万个案例事实的JudiFair数据集。通过开发不一致性、偏见和不平衡不准确性三个评估指标，并对16个LLMs进行实验，揭示了LLMs普遍存在司法不公平，尤其在人口统计学偏见上更为显著。研究还发现不一致性与偏见呈负相关，而准确性与偏见呈正相关，并指出温度参数可影响公平性，但模型大小、发布日期和来源国影响不显著。为推动未来研究，论文发布了相关数据集和代码工具包。

> **摘要翻译:** 大型语言模型（LLMs）正越来越多地应用于高风险领域，其决策影响着权利和公平。然而，LLMs的司法公平性及其对社会正义的影响尚未得到充分探索。当LLMs充当法官时，公平解决司法问题是确保其可信度的先决条件。基于司法公平理论，我们构建了一个衡量LLM公平性的综合框架，包含65个标签和161个相应的值。我们将此框架应用于司法系统，编制了一个包含177,100个独特案例事实的广泛数据集JudiFair。为了实现稳健的统计推断，我们开发了三个评估指标：不一致性、偏见和不平衡不准确性，并引入了一种评估多个LLM在各种标签上整体公平性的方法。通过对16个LLM的实验，我们发现了模型普遍存在的不一致性、偏见和不平衡不准确性，这突显了LLM严重的司法不公平性。特别是，LLMs在人口统计学标签上显示出更明显的偏见，而在实体标签上的偏见略低于程序标签。有趣的是，不一致性的增加与偏见的减少相关，但更准确的预测会加剧偏见。虽然我们发现调整温度参数可以影响LLM公平性，但模型大小、发布日期和原产国对司法公平性没有显著影响。因此，我们推出了一个包含所有数据集和代码的公共工具包，旨在支持未来评估和改进LLM公平性的研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [570] [Multi-Trigger Poisoning Amplifies Backdoor Vulnerabilities in LLMs](https://arxiv.org/abs/2507.11112)
> *多触发器中毒放大大型语言模型中的后门漏洞*

*Sanhanat Sivapiromrat, Caiqi Zhang, Marco Basaldella, Nigel Collier* | **Category: cs.CL, cs.CR, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 数据投毒, 后门攻击, 多触发器, 漏洞缓解

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）易受多触发器中毒攻击，这些攻击可同时嵌入且难以消除；论文提出了一种基于层级权重差分析的后验恢复方法，能有效且高效地防御此类攻击。

**AI_Comments:** 本文创新性地探讨了LLMs中多触发器中毒攻击的机制，揭示了这类攻击的复杂性和隐蔽性，特别是高相似性触发器的鲁棒性。其提出的后验恢复方法为LLMs的后门防御提供了一个实用且高效的解决方案，对LLMs的安全研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究对大型语言模型（LLMs）中毒攻击的触发机制和多触发器交互理解有限，且大多假设单一短语触发，这限制了对LLMs后门漏洞的全面认识。

**Method:** 本文提出了一个研究LLMs中毒的框架，并展示了多个后门触发器在单个模型中并存且不相互干扰。通过使用高嵌入相似性的多触发器，证明了中毒触发器即使在令牌被替换或被长令牌跨度分隔时也能实现鲁棒激活。为缓解威胁，论文提出了一种基于层级权重差分析的后验恢复方法，选择性地重新训练特定模型组件。

**Result:** 研究发现，多个不同的后门触发器可以在单个大型语言模型中并存而不相互干扰，使攻击者能够同时嵌入多个触发器。此外，使用高嵌入相似性的多触发器，中毒触发器即使在令牌被替换或被长令牌跨度分隔时也能实现鲁棒激活，这暴露了LLMs更广泛和更持久的漏洞表面。

**Conclusion:** 多触发器中毒暴露了大型语言模型（LLMs）中更广泛、更持久的漏洞表面。本文提出的后验恢复方法能够有效去除触发行为，且参数更新最小，为多触发器中毒攻击提供了一种实用且高效的防御策略。

> **ai_Abstract:** 本文研究了大型语言模型（LLMs）中的多触发器数据投毒攻击。研究发现，LLMs可以同时容纳多个不互相干扰的后门触发器，并且具有高嵌入相似性的触发器即使在输入变化时也能鲁棒激活，这揭示了LLMs更广泛的漏洞。为对抗此威胁，作者提出了一种基于层级权重差分析的后验恢复方法，该方法能有效且高效地移除中毒行为。

> **摘要翻译:** 最近的研究表明，大型语言模型（LLM）容易受到数据投毒攻击，其中恶意训练示例会嵌入由特定输入模式触发的隐藏行为。然而，大多数现有工作都假设一个短语并侧重于攻击的有效性，对触发机制以及多个触发器如何在模型中相互作用的理解有限。在本文中，我们提出了一个研究LLM中毒的框架。我们表明，多个不同的后门触发器可以在单个模型中并存而不相互干扰，从而使攻击者能够同时嵌入多个触发器。使用具有高嵌入相似性的多个触发器，我们证明了即使令牌被替换或被长令牌跨度分隔，中毒触发器也能实现鲁棒激活。我们的发现揭示了LLM中更广泛、更持久的漏洞表面。为了缓解这一威胁，我们提出了一种后验恢复方法，该方法基于层级权重差分析选择性地重新训练特定的模型组件。我们的方法能有效去除触发行为，且参数更新最小，这为多触发器中毒提供了一种实用高效的防御。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [572] [Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams](https://arxiv.org/abs/2507.06803)
> *通过SysML从文本到模型：通过增强的系统建模语言图从非结构化自然语言文本自动生成动力系统计算模型*

*Matthew Anderson Hendricks, Alice Cicirello* | **Category: cs.CL, cs.AI, cs.CE** | **Updated: 2025-07-15**

**Keywords:** SysML, 自然语言处理, 大型语言模型, 动力系统, 自动化生成

**Comment:** v2 - typos and imprecisions corrected

> **TL;DR:** 该论文提出了一种通过SysML图和NLP/LLM技术从非结构化文本自动生成动力系统计算模型的方法，并展示了其优于纯LLM方法的性能。

**AI_Comments:** 本文的创新点在于将SysML图与NLP和LLM技术相结合，实现了从非结构化文本到动力系统计算模型的端到端自动化生成。这种方法不仅提高了信息提取的准确性，还通过结合多种AI技术优化了中间输出。尤其值得关注的是，其性能优于仅使用LLM的方法，这表明了集成多种工具和策略的优势。该方法的普适性也使其在不同工程领域具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过利用领域和专家知识，从非结构化自然语言文本自动生成动力系统计算模型，从而加速工程动力系统的设计和部署。

**Method:** 该策略分为五个步骤，并关键性地利用系统建模语言（SysML）图来提取组件的依赖关系、属性和操作的精确信息。在特定任务中，采用自然语言处理（NLP）策略和大型语言模型（LLM）来改进SysML图自动生成的中间输出，例如：关键名词列表、提取的关系列表、关键短语和关键关系列表、块属性值、块关系以及BDD图生成。通过代码生成和计算模型生成步骤，从SysML图获得复杂动力系统的计算模型。在代码生成步骤中，NLP策略用于总结，而LLM仅用于验证。

**Result:** 通过不同的案例研究说明了自动SysML图生成的适用性。通过一个从文本到简单摆锤模型的端到端示例展示了所提出方法的适用性，并显示其性能优于仅使用LLM产生的结果。所提出的方法不限于特定系统、领域或计算软件。

**Conclusion:** 本研究提出的方法能够从非结构化自然语言文本自动生成动力系统计算模型，且不限于特定系统、领域或计算软件，并表现出优于仅使用LLM的性能。

> **ai_Abstract:** 本论文提出了一种从非结构化自然语言文本自动生成工程动力系统计算模型的策略。该方法通过五步实现，核心在于利用增强的SysML图来精确提取系统组件的信息。它结合了NLP和LLM来优化SysML图的自动生成过程，包括提取关键信息和生成不同类型的图表。随后，通过代码和模型生成步骤从SysML图获取最终计算模型。研究通过案例研究和从文本到简单摆锤模型的端到端示例验证了方法的有效性，并展示了其优于纯LLM方法的性能，强调了其在不同系统和领域中的普适性。

> **摘要翻译:** 本文旨在通过提出一种利用领域和专家知识的策略，从与感兴趣动力系统相关的文档语料库和描述特定系统的输入文档出发，实现动力系统计算模型的自动化生成，从而有助于加速工程动力系统的设计和部署。该策略分五个步骤实施，关键在于它使用系统建模语言图（SysML）来提取关于组件的依赖关系、属性和操作的准确信息。在特定任务中，采用自然语言处理（NLP）策略和大型语言模型（（LLM））来改进SysML图自动生成的中间输出，例如：关键名词列表；提取的关系列表；关键短语和关键关系列表；块属性值；块关系；以及BDD图生成。通过不同的案例研究说明了自动SysML图生成的适用性。然后，通过代码生成和计算模型生成步骤，从SysML图获得复杂动力系统的计算模型。在代码生成步骤中，NLP策略用于总结，而LLM仅用于验证。所提出的方法不限于特定系统、领域或计算软件。通过一个从文本到简单摆锤模型的端到端示例展示了所提出方法的适用性，显示其性能优于仅使用LLM产生的结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [573] [Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding](https://arxiv.org/abs/2507.11198)
> *温度和角色对LLM代理共识的影响，在定性编码中准确性提升微乎其微*

*Conrad Borchers, Bahar Shahrokhian, Francesco Balzan, Elham Tajik, Sreecharan Sankaranarayanan, Sebastian Simon* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** LLM代理, 定性编码, 多代理系统, 共识, 编码准确性

**Comment:** Manuscript submitted for review

> **TL;DR:** 研究发现，温度和代理角色显著影响LLM多代理系统在定性编码中的共识达成，但对编码准确性的提升很小，多数情况下单代理表现更好。

**AI_Comments:** 这篇论文对LLM多代理系统在定性编码中的应用提出了重要的限制性见解。它挑战了直觉上认为多代理多样性会带来更好结果的假设，特别是关于编码准确性。研究结果表明，简单的单代理可能在效率和准确性上不逊于复杂的MAS，这对于实际应用具有指导意义。然而，论文也指出了MAS在识别和澄清模糊代码应用方面的潜在价值，这为未来的研究提供了方向。开源代码的做法也值得称赞。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）使大规模定性研究成为可能，但多代理系统（MAS）在编码方面相较于单代理的优势尚不明确。本研究旨在探讨代理角色和温度如何影响共识建立和编码准确性。

**Method:** 进行了一项实验研究，使用开源多代理系统模拟演绎式人类编码流程，通过结构化代理讨论和共识仲裁。研究使用了六个开源LLM（30亿至320亿参数），18种实验配置，分析了超过77,000个编码决策，并与人类标注的黄金标准数据集进行对比。

**Result:** 温度显著影响了所有六个LLM达成共识的时间和方式。多角色MAS（包括中立、自信、同理心）与统一角色相比，显著延迟了六个LLM中的四个达成共识。在其中三个LLM中，更高的温度显著削弱了多角色对共识的影响。然而，无论是温度还是角色配对，都未能显著提升编码准确性。在大多数条件下，单代理的编码表现与MAS共识相当或优于MAS共识。只有一个模型（OpenHermesV2:7B）和一个代码类别在温度≤0.5且代理包含至少一个自信角色时，MAS的审议才展现出高于偶然的收益。定性分析表明MAS可能有助于缩小模糊代码应用范围。

**Conclusion:** 温度和代理角色显著影响LLM代理的共识达成，但多代理系统的多样化角色并未带来更好的定性编码准确性提升，甚至在多数情况下不如单代理。MAS可能在澄清模糊代码应用方面有潜在价值。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLM）多代理系统（MAS）在定性编码中，代理的“温度”和“角色”如何影响共识达成和编码准确性。通过对六个开源LLM和77,000多个编码决策的实验，发现温度显著影响共识达成，而多样化角色会延迟共识。然而，无论是温度还是多样化角色，对编码准确性的提升都微乎其微，多数情况下单代理表现与MAS相当或更优。研究挑战了多样化MAS角色能带来更好结果的观点，并指出MAS可能仅在缩小模糊代码应用方面有潜在价值。

> **摘要翻译:** 大型语言模型（LLM）为大规模定性研究，包括编码和数据标注，带来了新的可能性。虽然多代理系统（MAS）可以模拟人类编码工作流程，但其相对于单代理编码的优势仍知之甚少。我们进行了一项实验研究，探讨代理角色和温度如何影响基于包含8个代码的代码本对对话片段的共识建立和编码准确性。我们的开源MAS通过结构化的代理讨论和共识仲裁，模拟演绎式人类编码。我们使用六个开源LLM（参数量从30亿到320亿）和18种实验配置，分析了超过77,000个编码决策，并与来自在线数学辅导会话的人工标注转录本的黄金标准数据集进行对比。温度显著影响了所有六个LLM达成共识的时间和方式。与统一角色相比，具有多个角色（包括中立、自信或同理心）的MAS在六个LLM中的四个中显著延迟了共识的达成。在其中三个LLM中，更高的温度显著削弱了多个角色对共识的影响。然而，无论是温度还是角色配对，都未能显著提升编码准确性。在大多数条件下，单代理的编码表现与MAS共识相当或优于MAS共识。只有一个模型（OpenHermesV2:7B）和一个代码类别在温度为0.5或更低，并且代理包含至少一个自信角色时，MAS的审议才展现出高于偶然的收益。对这些配置下的MAS协作进行的定性分析表明，MAS可能仍然有助于缩小模糊代码应用范围，从而改进代码本和人机编码。我们为基于LLM的定性方法的局限性提供了新见解，挑战了多样化的MAS角色会带来更好结果的观点。我们开源了我们的MAS和实验代码。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [575] [DRAGON: Dynamic RAG Benchmark On News](https://arxiv.org/abs/2507.05713)
> *DRAGON：新闻动态RAG基准*

*Fedor Chernogorskii, Sergei Averkiev, Liliya Kudraleeva, Zaven Martirosian, Maria Tikhonova, Valentin Malykh, Alena Fenogenova* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** RAG, 基准, 俄语, 动态, 新闻

**Comment:** 

> **TL;DR:** DRAGON是首个针对俄语动态新闻语料库的RAG系统评估基准。

**AI_Comments:** DRAGON的创新之处在于它是首个针对俄语的动态RAG基准，解决了现有基准静态且主要面向英语的局限性。其自动问题生成机制和对动态新闻语料库的利用，使其在模拟真实世界应用场景方面具有重要意义。此外，其评估框架的可复用性也为其他语言的RAG评估提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 现有RAG基准多为英文且静态，缺乏对俄语等其他语言的动态评估资源，无法捕捉真实世界部署的动态性。

**Method:** DRAGON基于定期更新的俄语新闻和公共文档语料库构建，利用从语料库构建的知识图谱自动生成问题，支持四种核心问题类型，并全面评估检索器和生成器组件。

**Result:** 发布了一个完整的评估框架，包括自动问题生成管道、评估脚本（可复用于其他语言和多语言设置）和基准数据。同时推出了一个公共排行榜以鼓励社区参与和比较。

**Conclusion:** DRAGON填补了俄语动态RAG评估的空白，提供了一个可扩展且全面的评估资源，推动了多语言RAG系统的发展和评估。

> **ai_Abstract:** 本文介绍了DRAGON，这是第一个用于评估俄语RAG系统在动态新闻语料库上的基准。鉴于现有RAG基准在非英语语言（特别是俄语）方面的动态性不足，DRAGON通过构建于定期更新的俄语新闻语料库和知识图谱自动生成问题，实现了对检索器和生成器的全面评估。研究团队发布了完整的评估框架、可复用脚本和基准数据，并启动了公共排行榜，以促进社区参与和RAG系统在多语言环境中的发展。

> **摘要翻译:** 检索增强生成（RAG）是一种广泛采用的方法，通过在推理时整合外部知识来提高大型语言模型（LLM）的事实性。尽管存在多个针对英语的RAG基准，但包括俄语在内的其他语言的评估资源仍然稀缺且静态，未能捕捉真实世界部署的动态性质。在这项工作中，我们提出了DRAGON（新闻动态RAG基准），这是第一个用于评估俄语RAG系统在不断变化的新闻语料库上的动态基准。DRAGON建立在定期更新的俄语新闻和公共文档语料库之上，支持对检索器和生成器组件进行全面评估。问题生成是利用从语料库构建的知识图谱自动执行的，并能够提取与不同子图模式对齐的四种核心问题类型。我们发布了一个完整的评估框架，包括自动问题生成管道、评估脚本（可能可用于其他语言和多语言设置）以及基准数据。我们还启动了一个公共排行榜，以鼓励社区参与和比较。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [588] [Real-World Summarization: When Evaluation Reaches Its Limits](https://arxiv.org/abs/2507.11508)
> *真实世界摘要：当评估达到极限时*

*Patrícia Schmidtová, Ondřej Dušek, Saad Mahamood* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 摘要评估, 大型语言模型, 忠实度, 酒店亮点, 人工评估

**Comment:** 

> **TL;DR:** 本文研究了大型语言模型（LLM）生成的酒店亮点摘要的评估，发现简单指标与人类判断的相关性 surprisingly 高，而LLM作为评估者并不可靠。

**AI_Comments:** 该论文揭示了在真实世界场景中评估大型语言模型生成内容时面临的实际挑战，尤其是在忠实度方面。其创新之处在于对比了不同评估方法，并 surprising 地发现简单指标在某些情况下表现优越，这对于资源有限的实际应用具有重要指导意义。同时，论文也指出了LLM作为评估者的局限性，这对于依赖LLM进行自动评估的研究和应用提出了警示。

<details>
  <summary>Details</summary>

**Motivation:** 在酒店亮点这一特定背景下，研究大型语言模型（LLM）生成摘要对输入数据忠实度的评估问题，并探讨现有评估方法的局限性。

**Method:** 通过涉及分类错误评估和跨度级注释的人工评估活动，比较了传统指标、可训练方法和LLM作为评估者的方法。

**Result:** 研究发现，像词语重叠这样的简单指标与人类判断的相关性 surprisingly 高（Spearman 相关系数为0.63），在应用于域外数据时通常优于更复杂的方法。此外，虽然LLM可以生成高质量的亮点，但它们在评估方面不可靠，因为它们倾向于严重低估或高估。对实际业务影响的分析表明，不正确和不可检查的信息构成了最大的风险。论文还强调了众包评估中的挑战。

**Conclusion:** 在真实世界摘要的背景下，评估大型语言模型（LLM）生成的摘要忠实度面临挑战。简单指标有时比复杂方法更有效，而LLM作为评估者并不可靠。不准确的信息是主要的业务风险。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLM）生成酒店亮点摘要的忠实度评估问题。通过人工评估，论文比较了传统指标、可训练方法和LLM作为评估者的方法。结果显示，简单指标如词语重叠与人类判断的相关性 surprisingly 高，且在域外数据上表现优于复杂方法。同时，LLM虽然能生成高质量摘要，但在作为评估工具时并不可靠。研究还指出，不准确信息是主要业务风险，并讨论了众包评估的挑战。

> **摘要翻译:** 我们研究了酒店亮点背景下对输入数据忠实度的评估：大型语言模型（LLM）生成的简短摘要，捕捉住宿的独特特征。通过涉及分类错误评估和跨度级注释的人工评估活动，我们比较了传统指标、可训练方法和LLM作为评估者的方法。我们的发现表明，像词语重叠这样的简单指标与人类判断的相关性 surprisingly 高（Spearman 相关系数为0.63），在应用于域外数据时通常优于更复杂的方法。我们进一步证明，虽然LLM可以生成高质量的亮点，但它们在评估方面不可靠，因为它们倾向于严重低估或高估。我们对真实世界业务影响的分析表明，不正确和不可检查的信息构成了最大的风险。我们还强调了众包评估中的挑战。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [600] [Emergence of Hierarchical Emotion Organization in Large Language Models](https://arxiv.org/abs/2507.10599)
> *大型语言模型中情感层级组织的涌现*

*Bo Zhao, Maya Okawa, Eric J. Bigelow, Rose Yu, Tomer Ullman, Ekdeep Singh Lubana, Hidenori Tanaka* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-12**

**Keywords:** 大型语言模型, 情感识别, 分层组织, 偏见, 社会感知

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）自然形成与人类心理模型一致的分层情感树，但存在针对社会经济群体的偏见，特别是对弱势群体的错误分类。

**AI_Comments:** 这项研究创新性地将心理学中的“情感轮”理论应用于大型语言模型的情感理解分析，揭示了LLMs内部情感组织的涌现特性。其重要性在于，不仅证实了LLMs具备复杂的情感推理能力，更指出了其在情感识别中存在的社会偏见问题，这对于LLMs的伦理开发和部署具有重要指导意义。同时，研究也提出了利用认知理论来改进模型评估的潜力，为未来LLM的评估方向提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）日益成为对话代理的核心，理解它们如何建模用户情感状态对于模型的伦理部署至关重要。

**Method:** 受情感轮（一种认为情感分层组织的心理学框架）的启发，本研究分析了模型输出中情感状态之间的概率依赖性。

**Result:** 研究发现，LLMs自然形成与人类心理模型一致的分层情感树，且更大的模型会发展出更复杂的层级结构。同时，研究揭示了LLMs在跨社会经济群体的情感识别中存在系统性偏见，对交叉性、代表性不足的群体的错误分类尤为严重。人类研究也显示出惊人的相似性，表明LLMs内化了社会感知的一些方面。

**Conclusion:** 本研究不仅揭示了LLMs中涌现的情感推理能力，还暗示了利用认知基础理论开发更优模型评估方法的潜力。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）如何组织情感，发现它们能自然形成与人类心理模型相似的分层情感结构，并且模型越大，其情感层级越复杂。然而，研究也揭示了LLMs在情感识别中存在系统性偏见，尤其是在处理不同社会经济背景和弱势群体时。这些发现与人类研究结果相似，表明LLMs可能内化了社会感知，并强调了利用认知理论改进模型评估的重要性。

> **摘要翻译:** 随着大型语言模型（LLMs）日益成为对话代理的核心，理解它们如何建模用户情感状态对于模型的伦理部署至关重要。受情感轮（一种认为情感分层组织的心理学框架）的启发，我们分析了模型输出中情感状态之间的概率依赖性。我们发现，LLMs自然形成与人类心理模型一致的分层情感树，且更大的模型会发展出更复杂的层级结构。我们还揭示了LLMs在跨社会经济群体的情感识别中存在系统性偏见，对交叉性、代表性不足的群体的错误分类尤为严重。人类研究也显示出惊人的相似性，表明LLMs内化了社会感知的一些方面。本研究不仅揭示了LLMs中涌现的情感推理能力，还暗示了利用认知基础理论开发更优模型评估方法的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [601] [How Stylistic Similarity Shapes Preferences in Dialogue Dataset with User and Third Party Evaluations](https://arxiv.org/abs/2507.10918)
> *风格相似性如何通过用户和第三方评估塑造对话数据集中的偏好*

*Ikumi Numaya, Shoji Moriya, Shiki Sato, Reina Akama, Jun Suzuki* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 风格相似性, 用户偏好, 对话数据集, 主观评估, 客观评估

**Comment:** Accepted to SIGDIAL 2025 (long)

> **TL;DR:** 本研究引入了一个包含用户偏好、主观和客观风格相似性的新对话数据集，发现主观风格相似性与用户偏好高度相关，且主观和客观风格相似性存在差异，强调了区分两者评估的重要性。

**AI_Comments:** 该论文的创新之处在于构建了一个独特的数据集，首次同时包含了用户主观感知和第三方客观评估的风格相似性，并结合了用户偏好。这弥补了以往研究中对主客观相似性区分不足的空白。其重要性在于揭示了用户主观感受与客观评估之间的差异，为未来对话系统设计和评估提供了更细致的视角，强调了在优化用户体验时考虑主观因素的关键性。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究表明用户与系统间的风格相似性可能提升用户印象，但主观和客观相似性之间的区别常被忽视。本研究旨在深入探讨这一问题。

**Method:** 本研究构建了一个新颖的数据集，其中包含用户偏好、基于用户自身感知的主观风格相似性，以及由第三方评估者在开放域对话设置中标注的客观风格相似性。

**Result:** 分析发现主观风格相似性与用户偏好之间存在强烈的正相关。此外，分析表明用户的_主观_风格相似性与第三方_客观_相似性不同。

**Conclusion:** 这强调了在分析风格相似性与用户偏好之间的关系时，区分主观和客观评估以及理解它们各自捕捉的不同方面的重要性。

> **ai_Abstract:** 本研究旨在探究风格相似性如何影响对话数据集中的用户偏好，并区分主观与客观相似性。为此，研究者创建了一个包含用户偏好、用户主观感知以及第三方评估者标注的客观风格相似性的新数据集。分析结果显示，主观风格相似性与用户偏好呈强正相关，且用户的主观感受与第三方的客观评估存在差异。这强调了在评估风格相似性对用户偏好的影响时，区分主观和客观评估的重要性。

> **摘要翻译:** 对话生成领域的最新进展拓宽了人机交互的范围，不仅能实现上下文适当的响应，还能分析人类情感和敏感性。虽然先前的研究表明用户与系统之间的风格相似性可能增强用户印象，但主观和客观相似性之间的区别往往被忽视。为了调查这个问题，我们引入了一个新颖的数据集，其中包含用户偏好、基于用户自身感知的主观风格相似性，以及由第三方评估者在开放域对话设置中标注的客观风格相似性。使用构建的数据集进行的分析揭示了主观风格相似性与用户偏好之间存在强烈的正相关。此外，我们的分析提出了一个重要发现：用户的_主观_风格相似性与第三方_客观_相似性不同。这强调了在分析风格相似性与用户偏好之间的关系时，区分主观和客观评估以及理解它们各自捕捉的不同方面的重要性。本文介绍的数据集已在线提供。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [603] [ETT: Expanding the Long Context Understanding Capability of LLMs at Test-Time](https://arxiv.org/abs/2507.06313)
> *ETT：在测试时扩展LLM的长上下文理解能力*

*Kiarash Zahirnia, Zahra Golpayegani, Walid Ahmed, Yang Liu* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 上下文扩展, LLM, 微调, Transformer, 测试时

**Comment:** 

> **TL;DR:** ETT通过在测试时对分块输入进行高效微调，以恒定内存和线性计算开销将LLM的上下文长度扩展32倍，显著提高准确性。

**AI_Comments:** ETT的创新点在于其在测试时进行高效微调以扩展上下文长度，尤其是在内存和计算开销上的优化（恒定内存，线性计算）。发现微调FFN第二层比完全微调更有效是一个重要的洞察，表明了选择性微调的潜力。这对于实际部署和利用LLM处理长文本具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** Transformer-based 语言模型的计算和内存开销随序列长度呈二次方增长，这使得LLMs在处理长序列时面临挑战。

**Method:** 本文引入ETT（Extend at Test-Time），这是一种在测试时扩展短上下文Transformer-based LLMs上下文长度的方法。它通过将输入上下文分块成重叠的小子序列，并在输入上下文上高效微调模型参数来实现，具有恒定的内存需求和线性的计算开销。研究还探讨了如何有效地将上下文存储在LLM的权重中，并通过详细的消融研究检查了哪些Transformer模块在测试时进行微调最有利，发现微调FFN的第二层比完全微调更有效。

**Result:** ETT在LongBench上将GPT-Large和Phi-2的上下文长度从1k扩展到32k tokens，最高提高了30%的模型准确性。微调FFN的第二层比完全微调更有效，从而进一步提高了模型的准确性。

**Conclusion:** ETT提供了一种高效且有效的解决方案，可以在测试时扩展LLM的上下文理解能力，同时保持内存和计算效率，并且选择性微调特定模块（如FFN的第二层）可以带来更好的性能。

> **ai_Abstract:** 本文提出ETT（Extend at Test-Time），一种在测试时扩展短上下文LLM上下文长度的方法，以解决LLM处理长序列时面临的二次方成本问题。ETT通过在输入上下文上对分块的重叠子序列进行高效微调，实现了恒定内存和线性计算开销。在LongBench上的实验表明，ETT可将模型上下文长度扩展至32k token，并使模型准确性提升高达30%。研究还发现，仅微调前馈网络（FFN）的第二层比完全微调更有效，能进一步提高准确性。

> **摘要翻译:** Transformer-based 语言模型的计算和内存开销随序列长度呈二次方增长。这种二次方成本使得在处理长序列时使用大型语言模型（LLMs）面临挑战。在这项工作中，我们引入了ETT（Extend at Test-Time），这是一种在测试时扩展短上下文Transformer-based LLMs上下文长度的方法，具有恒定的内存需求和线性的计算开销。ETT通过将输入上下文分块成重叠的小子序列，并在输入上下文上高效微调模型参数来实现上下文长度的扩展。我们在LongBench上评估了ETT，将GPT-Large和Phi-2的上下文长度扩展了高达32倍，从1k增加到32k token。这使得模型的准确性提高了高达30%。我们还研究了如何有效且高效地将上下文存储在LLM的权重中。通过详细的消融研究，我们检查了哪些Transformer模块在测试时进行微调最有利。有趣的是，我们发现微调FFN的第二层比完全微调更有效，从而进一步提高了模型的准确性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [630] [Fine-grained Stateful Knowledge Exploration: Effective and Efficient Graph Retrieval with Large Language Models](https://arxiv.org/abs/2401.13444)
> *细粒度有状态知识探索：基于大型语言模型的有效高效图谱检索*

*Dehao Tao, Congqi Wang, Feng Huang, Junhao Chen, Yongfeng Huang, Minghu Jiang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 细粒度知识探索, 知识图谱, 大型语言模型, 知识检索, 状态映射

**Comment:** 

> **TL;DR:** FiSKE提出了一种细粒度有状态知识探索范式，通过分解问题、自适应映射和线索驱动终止机制，解决了LLM集成知识图谱时粗粒度知识探索导致的检索精度低和计算消耗高的问题，提高了知识检索的精度和效率。

**AI_Comments:** 该论文的创新点在于提出了“细粒度有状态知识探索”这一新范式，通过分解问题和维护映射状态，有效解决了LLM与知识图谱集成时常见的粒度不匹配问题。这种方法不仅提高了知识检索的准确性，还通过减少LLM调用次数提升了效率，对于提升LLM的知识时效性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的知识更新是一个重大挑战，常导致过时或不准确的响应。现有将外部知识库（如知识图谱）与LLMs集成的方法通常将整个问题视为目标，导致目标问题与检索到的实体和关系之间存在粒度不匹配，从而造成冗余探索或关键知识遗漏，增加计算消耗并降低检索准确性。

**Method:** 我们提出了FiSKE，一种细粒度有状态知识探索的新范式。FiSKE首先将问题分解为细粒度线索，然后采用自适应映射策略来解决线索到图谱映射中的歧义，动态推断上下文对应关系并维护映射的状态记录。此外，线索驱动的终止机制确保严格的增强，利用完全映射的路径用于LLMs，并在必要时回归到思维链推理。

**Result:** 在多个数据集上的实验表明，我们的范式在知识检索方面超越了当前的先进方法，同时显著减少了LLM的平均调用次数。

**Conclusion:** FiSKE通过细粒度有状态知识探索，有效解决了LLM与知识图谱集成时存在的粒度不匹配问题，平衡了精度和效率，并在知识检索方面取得了优于现有先进方法的结果。

> **ai_Abstract:** 本文提出了一种名为FiSKE的细粒度有状态知识探索新范式，旨在解决大型语言模型（LLMs）在集成知识图谱时，因现有粗粒度方法导致的知识检索不准确和效率低下问题。FiSKE通过将问题分解为细粒度线索，并采用自适应映射策略来处理线索与图谱之间的歧义，动态维护映射状态。此外，线索驱动的终止机制确保了高效且精确的知识增强。实验证明，FiSKE在知识检索性能上超越了现有先进方法，并显著减少了LLM的调用次数，有效平衡了检索的精度与效率。

> **摘要翻译:** 大型语言模型（LLMs）展现出令人印象深刻的能力，但其知识更新仍然是一个重大挑战，常常导致过时或不准确的响应。一个提议的解决方案是将外部知识库，如知识图谱，与LLMs集成。大多数现有方法采用一种范式，将整个问题视为目标，相关知识从知识图谱中逐步检索。然而，这种范式常常导致目标问题与检索到的实体和关系之间存在粒度不匹配。结果是，问题中的信息无法精确对应到检索到的知识。这可能导致冗余探索或关键知识的遗漏，从而增加计算消耗并降低检索准确性。为了解决粗粒度知识探索的局限性，我们提出了FiSKE，一种用于细粒度有状态知识探索的新范式。FiSKE首先将问题分解为细粒度线索，然后在知识探索过程中采用自适应映射策略来解决线索到图谱映射中的歧义。该策略动态推断上下文对应关系，同时维护映射的状态记录。线索驱动的终止机制确保严格的增强——利用完全映射的路径用于LLMs，并在必要时回归到思维链推理。我们的方法平衡了精度和效率。在多个数据集上的实验表明，我们的范式在知识检索方面超越了当前的先进方法，同时显著减少了LLM的平均调用次数。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [631] [A Mathematical Theory of Discursive Networks](https://arxiv.org/abs/2507.06565)
> *话语网络的数学理论*

*Juan B. Gutiérrez* | **Category: cs.CL, cs.LG, 68T01, 60J10, 91D30, 05C82, 68T50, 68W20, 94A15, I.2.7; I.2.11; G.3** | **Updated: 2025-07-15**

**Keywords:** 话语网络, 大型语言模型, 错误检测, 同行评审, 数学模型

**Comment:** 32 pages, 4 figures, 4 tables, 1 algorithm, 54 references

> **TL;DR:** 本文将大型语言模型（LLM）驱动的人机交流定义为“话语网络”，并构建数学模型来分析错误信息（无效化）的产生和传播。研究表明，即使是小规模的同行评审也能显著提高信息可靠性，并提出了“他人缺陷算法”（FOO）作为实现互助问责制的方法，强调可靠性源于网络的相互问责而非单一模型的完善。

**AI_Comments:** 本文创新性地将人与LLM的交互抽象为“话语网络”，并引入数学模型来分析其中的信息可靠性问题，为理解和治理LLM时代的错误信息传播提供了新视角。提出的“他人缺陷算法”（FOO）为实现网络化的同行评审提供了具体的工具，其强调“相互问责”而非“单一模型完美”的理念，对LLM的未来发展和应用具有重要的实践指导意义和文化启示。此外，论文还触及了人类在话语网络中参与的伦理问题，增加了其深度。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）将写作转变为人与软件之间的实时交流，这种新媒介需要被刻画和理解。论文的动机是把这种新媒介定义为一种话语网络，将人类和LLM视为平等节点，并追踪其陈述的流通，同时定义和分析错误信息（无效化）的产生机制，并探索提高信息可靠性的方法。

**Method:** 本文将人与LLM的交互定义为“话语网络”，其中人与LLM均为平等节点。研究定义了错误信息（无效化）的四种危害：偏离真相、自我修复、凭空捏造和外部检测。在此基础上，研究开发了一个通用的论述网络数学模型，以分析错误信息的传播。为实现同行评审，论文提出并操作化了开源的“他人缺陷算法”（Flaws-of-Others, FOO），这是一个可配置的循环，允许代理相互批评并合并裁决。

**Result:** 研究发现，仅受偏离真相和自我修复控制的网络会稳定在一个适度的错误率。然而，即使给每个错误主张一个很小的同行评审机会，也能将系统转变为以真相为主导的状态。通过开源的“他人缺陷算法”（FOO），同行评审被操作化为一个可配置的、代理间相互批评并合并裁决的循环。

**Conclusion:** 在这种新媒介中的可靠性，不是来自于完善单个大型语言模型，而是来自于将不完美的模型连接成一个强制相互问责的网络。

> **ai_Abstract:** 本文提出了一种话语网络的数学理论，用于描述大型语言模型（LLMs）与人类互动所形成的新型交流媒介。该理论将人类和LLMs视为网络中的平等节点，并对错误信息（称之为“无效化”）的产生和传播进行了数学建模，识别出四种主要危害。研究表明，在仅受内部机制影响的网络中，错误率会稳定在一定水平；但即使引入少量同行评审，也能显著提升网络的真实性。为实现同行评审，论文提出了开源的“他人缺陷算法”（FOO）。核心结论是，这种新媒介的可靠性并非依赖于单个模型的完美，而是通过构建相互问责的网络来实现。

> **摘要翻译:** 大型语言模型（LLM）将写作转变为人与软件之间的实时交流。我们将这种新媒介描述为一种话语网络，它将人类和LLM视为平等的节点，并跟踪它们的陈述如何流通。我们将错误信息的产生定义为无效化（任何事实、逻辑或结构上的违背），并表明它遵循四种危害：偏离真相、自我修复、凭空捏造和外部检测。我们开发了一个论述网络的通用数学模型，该模型表明，仅受偏离和自我修复控制的网络会稳定在一个适度的错误率。即使只给每个错误主张一个很小的同行评审机会，也能将系统转变为以真相为主导的状态。我们通过开源的《他人缺陷算法》（Flaws-of-Others，FOO算法）来实现同行评审：这是一个可配置的循环，其中任何一组代理可以相互批评，而一个协调器则合并它们的裁决。我们识别出一种伦理越界，即“上皮症”（epithesis），当人类未能参与论述网络时就会发生。其意义是实用和文化上的：在这种新媒介中的可靠性不是来自完善单个模型，而是来自将不完美的模型连接成强制相互问责的网络。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [650] [DS@GT at eRisk 2025: From prompts to predictions, benchmarking early depression detection with conversational agent based assessments and temporal attention models](https://arxiv.org/abs/2507.10958)
> *DS@GT 在 eRisk 2025：从提示到预测，基准测试基于对话代理评估和时间注意力模型的早期抑郁症检测*

*Anthony Miyaguchi, David Guecha, Yuwen Chiu, Sidharth Gaur* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 抑郁症检测, 大型语言模型, 提示工程, 对话代理, eRisk 2025

**Comment:** 

> **TL;DR:** DS@GT 团队在 eRisk 2025 挑战赛中，使用提示工程策略，通过大型语言模型（LLMs）进行 BDI-II 评估，实现了对话式抑郁症检测，并在官方排行榜上排名第二。

**AI_Comments:** 该研究通过创新的提示工程方法，将大型语言模型应用于对话式早期抑郁症检测，即使在缺乏真实标签的情况下，也能通过评估模型间一致性来验证其有效性。在 eRisk 挑战赛中取得第二名的成绩，显示了该方法在实际应用中的潜力，为基于LLM的心理健康评估提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在总结 DS@GT 团队参与 eRisk 2025 挑战赛的情况，特别是针对使用大型语言模型进行对话式抑郁症检测的试点任务。

**Method:** 团队采用了提示工程策略，使不同的 LLMs 进行基于 BDI-II 的评估并生成结构化的 JSON 输出。由于缺乏真实标签，团队评估了模型间的交叉一致性和内部一致性。提示设计方法使模型输出与 BDI-II 标准对齐，并支持对影响症状预测的对话线索进行分析。

**Result:** 在没有真实标签的情况下，团队评估了模型间的交叉一致性和内部一致性。最佳提交在官方排行榜上排名第二，DCHR = 0.50，ADODL = 0.89，ASHR = 0.27。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文汇报了 DS@GT 团队在 eRisk 2025 挑战赛中，特别是对话式抑郁症检测试点任务的参与情况。团队采用提示工程策略，利用多种大型语言模型进行基于 BDI-II 的评估，并生成结构化输出。在缺乏真实标签的情况下，通过评估模型间的交叉一致性和内部一致性来验证方法。该方法将模型输出与 BDI-II 标准对齐，并支持分析对话线索对症状预测的影响。最佳提交在官方排行榜上排名第二，取得了 DCHR = 0.50, ADODL = 0.89, ASHR = 0.27 的成绩。

> **摘要翻译:** 本工作报告总结了 DS@GT 团队参加 eRisk 2025 两项挑战赛的情况。对于使用大型语言模型（LLMs）进行对话式抑郁症检测的试点任务，我们采用了提示工程策略，其中不同的 LLMs 进行了基于 BDI-II 的评估并生成了结构化的 JSON 输出。由于缺乏真实标签，我们评估了模型间的交叉一致性和内部一致性。我们的提示设计方法使模型输出与 BDI-II 标准对齐，并支持对影响症状预测的对话线索进行分析。我们的最佳提交在官方排行榜上排名第二，DCHR = 0.50，ADODL = 0.89，ASHR = 0.27。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [659] [Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models](https://arxiv.org/abs/2507.07505)
> *幻觉站：关于基于Transformer的语言模型的一些基本局限性*

*Varin Sikka, Vishal Sikka* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 幻觉, 计算复杂度, 能力局限, Transformer

**Comment:** 6 pages; to be submitted to AAAI-26 after reviews

> **TL;DR:** 论文从计算复杂度的角度探讨了LLM在处理复杂任务时的幻觉和能力局限性，指出LLM在一定复杂度之上无法执行或验证计算和代理任务。

**AI_Comments:** 这篇论文揭示了当前基于Transformer的LLM在处理复杂计算和代理任务时的根本性局限，强调了计算复杂度对LLM能力的关键影响。这对于理解LLM的“幻觉”现象提供了新的理论视角，并对未来LLM的设计和应用提出了挑战。

<details>
  <summary>Details</summary>

**Motivation:** 探索大型语言模型（LLM）和基于LLM的代理中的幻觉及相关的能力局限性。

**Method:** 从计算复杂度的角度进行探讨。

**Result:** 结果表明，超出一定复杂度后，大型语言模型（LLM）无法执行计算和代理任务，也无法验证其准确性。

**Conclusion:** 大型语言模型（LLM）在面对高复杂度任务时存在固有的计算和验证能力局限。

> **ai_Abstract:** 本文从计算复杂度的视角审视了大型语言模型（LLM）及其代理的幻觉现象和能力限制。研究发现，当任务复杂度达到一定程度时，LLM将无法有效执行计算和代理任务，也无法对其结果进行准确性验证。

> **摘要翻译:** 在本文中，我们从计算复杂性的角度探讨了大型语言模型（LLM）和基于LLM的代理中的幻觉及相关的能力局限。我们表明，超出一定的复杂性，LLM无法执行计算和代理任务或验证其准确性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [671] [Internal Value Alignment in Large Language Models through Controlled Value Vector Activation](https://arxiv.org/abs/2507.11316)
> *大型语言模型中通过受控价值向量激活实现内部价值对齐*

*Haoran Jin, Meng Li, Xiting Wang, Zhihao Xu, Minlie Huang, Yantao Jia, Defu Lian* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 价值对齐, 价值向量, 受控激活, 内部对齐

**Comment:** 25 pages, 14 figures. Accepted by ACL 2025 (main conference)

> **TL;DR:** 本文提出ConVA方法，通过识别和门控激活大型语言模型（LLMs）中的价值向量，实现在不牺牲性能的前提下，将LLM的内部价值观与人类价值观进行高效对齐，即使面对恶意输入也能保持一致性。

**AI_Comments:** 这项研究提出了一个新颖且重要的方向，即直接从内部控制LLM的价值观，而非仅仅依赖外部干预或提示工程。通过“价值向量激活”的概念，它提供了一种更深层次、更鲁棒的价值对齐方法。其在保持性能的同时，能有效应对恶意输入的特性，是其创新性和实用性的体现。

<details>
  <summary>Details</summary>

**Motivation:** 对齐大型语言模型（LLMs）与人类价值观日益受到关注，因为它能提供清晰度、透明度并适应不断变化的场景。

**Method:** 本文提出了一种名为“受控价值向量激活（ConVA）”的方法，通过解释价值观在LLM潜在表示中的编码方式，并修改相关激活来确保LLM中价值观的一致性。具体包括：1) 提出一种上下文受控的价值向量识别方法，以确保准确无偏的解释；2) 引入一种门控价值向量激活方法，以在不牺牲模型性能的情况下有效且最小程度地控制价值观。

**Result:** 实验表明，该方法在不损害LLM性能和流畅性的前提下，在10个基本价值观上实现了最高的控制成功率，并能确保目标价值观，即使面对相反和潜在恶意的输入提示。

**Conclusion:** 该研究成功开发并验证了ConVA方法，有效实现了大型语言模型内部价值与人类价值观的对齐，且在复杂输入下仍能保持性能和一致性。

> **ai_Abstract:** 本文提出了一种名为受控价值向量激活（ConVA）的新方法，旨在直接对齐大型语言模型（LLMs）的内部价值观。ConVA通过识别价值观在模型潜在表示中的编码方式，并有选择地修改相关激活来实现价值控制。该方法包含一个上下文受控的价值向量识别机制，用于准确解释，以及一个门控价值向量激活方法，以在不影响模型性能的前提下进行有效控制。实验结果表明，ConVA在多项基本价值观上表现出卓越的控制成功率，同时保持了LLM的性能和流畅性，并能抵御恶意输入。

> **摘要翻译:** 对齐大型语言模型（LLMs）与人类价值观日益受到关注，因为它能提供清晰度、透明度以及适应不断变化的场景的能力。在本文中，我们引入了一种受控价值向量激活（ConVA）方法，通过解释价值观如何在LLM的潜在表示中编码，并修改相关激活来直接对齐LLM的内部价值观，以确保LLM中价值观的一致性。为了确保准确和无偏的解释，我们提出了一种上下文受控的价值向量识别方法。为了在不牺牲模型性能的情况下持续控制价值观，我们引入了一种门控价值向量激活方法，以实现有效且最小程度的价值观控制。实验表明，我们的方法在10个基本价值观上实现了最高的控制成功率，同时不损害LLM的性能和流畅性，并且即使在面对相反和潜在恶意的输入提示时也能确保目标价值观。源代码和数据可在https://github.com/hr-jin/ConVA获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [679] [GenARM: Reward Guided Generation with Autoregressive Reward Model for Test-time Alignment](https://arxiv.org/abs/2410.08193)
> *GenARM：基于自回归奖励模型的奖励引导生成用于测试时对齐*

*Yuancheng Xu, Udari Madhushani Sehwag, Alec Koppel, Sicheng Zhu, Bang An, Furong Huang, Sumitra Ganesh* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型对齐, 测试时对齐, 自回归奖励模型, 奖励引导生成, 弱到强引导

**Comment:** Published at the Thirteenth International Conference on Learning
  Representations (ICLR 2025)

> **TL;DR:** GenARM引入自回归奖励模型，在测试时对齐LLM，解决了现有测试时方法的局限性，并实现了与训练时方法媲美的性能，支持高效弱到强引导和多目标对齐。

**AI_Comments:** GenARM的创新点在于引入了自回归奖励模型（ARM），使其能够为自回归生成提供细粒度的“下一个token”奖励，这是现有轨迹级奖励模型所不具备的。这解决了测试时对齐的一个关键挑战，并使得在不进行昂贵再训练的情况下对齐LLM成为可能。其支持弱到强引导和多目标对齐的特性，极大地提升了LLM对齐的效率和灵活性，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统训练时对齐大型语言模型（LLM）成本高昂且需要重复训练以适应多样化用户偏好。现有测试时对齐方法依赖于评估完整响应的轨迹级奖励模型，不适用于需要计算部分响应的下一个token奖励的自回归文本生成。

**Method:** 引入GenARM，一种测试时对齐方法，它利用自回归奖励模型（Autoregressive Reward Model, ARM）。ARM是一种新颖的奖励参数化，旨在预测下一个token的奖励，以实现高效有效的自回归生成。理论上，该方法能够将冻结的LLM引导至KL正则化强化学习框架内传统奖励模型可达的任何分布。

**Result:** GenARM显著优于先前的测试时对齐基线，并与训练时方法的性能相匹配。此外，GenARM支持高效的弱到强引导，能够用较小的奖励模型对齐较大的LLM，且无需高昂的训练成本。GenARM还支持多目标对齐，允许在偏好维度之间进行实时权衡，无需重新训练即可满足多样化的用户偏好。

**Conclusion:** GenARM通过引入自回归奖励模型，提供了一种高效、有效且灵活的测试时LLM对齐方法，解决了现有方法的局限性，并在性能上与训练时方法相媲美，同时支持弱到强引导和多目标对齐。

> **ai_Abstract:** 本文提出GenARM，一种创新的测试时LLM对齐方法，通过引入自回归奖励模型（ARM）来预测下一个token的奖励，解决了现有测试时方法无法处理自回归生成的问题。GenARM在理论上被证明能有效引导冻结的LLM，实验结果表明其性能优于现有测试时基线并与训练时方法相当。GenARM还具备高效弱到强引导和多目标对齐的能力，显著降低了对齐成本并提升了灵活性。

> **摘要翻译:** 大型语言模型（LLM）展现出令人印象深刻的能力，但需要与人类偏好进行仔细对齐。传统的训练时方法使用人类偏好数据集对LLM进行微调，但这会产生显著的训练成本，并且需要重复训练以处理多样化的用户偏好。测试时对齐方法通过使用奖励模型（RM）来引导冻结的LLM，而无需重新训练，从而解决了这个问题。然而，现有的测试时方法依赖于轨迹级RM，这些RM旨在评估完整的响应，因此不适用于需要从部分响应计算下一个token奖励的自回归文本生成。为了解决这个问题，我们引入了GenARM，一种测试时对齐方法，它利用自回归奖励模型——一种新颖的奖励参数化，旨在预测下一个token奖励，以实现高效有效的自回归生成。理论上，我们证明了这种参数化可以被证明能将冻结的LLM引导至KL正则化强化学习框架内传统RM可实现的任何分布。实验结果表明，GenARM显著优于先前的测试时对齐基线，并与训练时方法的性能相匹配。此外，GenARM支持高效的弱到强引导，无需训练更大模型的昂贵成本即可用较小的RM对齐更大的LLM。此外，GenARM支持多目标对齐，允许在偏好维度之间进行实时权衡，并无需重新训练即可满足多样化的用户偏好。我们的项目页面可在 https://genarm.github.io 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [687] [On the Effect of Instruction Tuning Loss on Generalization](https://arxiv.org/abs/2507.07817)
> *指令微调损失对泛化能力影响的研究*

*Anwoy Chatterjee, H S V N S Kowndinya Renduchintala, Sumit Bhatia, Tanmoy Chakraborty* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 指令微调, 损失函数, 泛化能力, 权重, 语言模型

**Comment:** To appear in Transactions of the Association for Computational
  Linguistics (TACL)

> **TL;DR:** 本文系统研究了指令微调中提示和响应令牌的不同权重对模型泛化能力的影响，并提出加权指令微调（WIT），发现对提示令牌施加低到中等权重、对响应令牌施加中等到高权重能带来最佳性能和更强的鲁棒性。

**AI_Comments:** 这项工作创新性地指出了指令微调中损失函数优化的重要性，特别是对提示和响应令牌加权这一先前被忽视的方面。它挑战了传统自回归损失的普遍应用，并通过实证证明了特定加权策略的优越性，为提高模型性能和鲁棒性提供了直接且可操作的指导，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 指令微调是使预训练语言模型更好遵循用户指令的关键范式，但其损失函数的优化却鲜受关注。本文旨在探究传统自回归目标（仅在响应令牌上计算损失）是否是指令微调的最佳选择。

**Method:** 本文系统地研究了在指令微调损失中差异化加权提示和响应令牌的影响，并提出了加权指令微调（WIT）作为传统指令微调的更好替代方案。通过在五种不同系列和规模的语言模型、三个不同大小的微调数据集以及五个多样化评估基准上进行广泛实验。

**Result:** 实验表明，标准的指令微调损失通常会导致次优性能和对输入提示变化的鲁棒性有限。研究发现，对提示令牌施加低到中等权重，并对响应令牌施加中等到高权重，可以在各种设置下产生最佳性能的模型，并为后续偏好对齐训练提供更好的起点。

**Conclusion:** 这些发现强调了重新考虑指令微调损失的必要性，并为开发更健壮和更具泛化能力的模型提供了可操作的见解。

> **ai_Abstract:** 本文探讨了指令微调中损失函数优化的重要性，特别是在提示和响应令牌权重方面的不足。研究系统地比较了不同加权策略的效果，并提出了加权指令微调（WIT）。实验证明，传统损失函数表现不佳且鲁棒性有限。最佳结果是通过对提示令牌施加低到中等权重、对响应令牌施加中等到高权重实现的，这不仅提升了模型性能，也为后续偏好对齐训练提供了更好的基础。这为开发更强大、更具泛化能力的模型提供了新视角。

> **摘要翻译:** 指令微调已成为一个关键的后训练范式，使预训练语言模型能够更好地遵循用户指令。尽管其重要性，但对所用损失函数的优化却鲜受关注。一个基本但常被忽视的问题是，传统的自回归目标——即损失仅在响应令牌上计算，不包括提示令牌——是否真正是指令微调的最佳选择。在这项工作中，我们系统地研究了在指令微调损失中差异化加权提示和响应令牌的影响，并提出了加权指令微调（WIT）作为传统指令微调的更好替代方案。通过在五种不同系列和规模的语言模型、三个不同大小的微调数据集以及五个多样化评估基准上进行广泛实验，我们表明标准的指令微调损失通常会导致次优性能和对输入提示变化的鲁棒性有限。我们发现，对提示令牌施加低到中等权重，并对响应令牌施加中等到高权重，可以在各种设置下产生最佳性能的模型，并为后续偏好对齐训练提供更好的起点。这些发现强调了重新考虑指令微调损失的必要性，并为开发更健壮和更具泛化能力的模型提供了可操作的见解。我们的代码已在 https://github.com/kowndinya-renduchintala/WIT 开源。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [699] [Teach Me Sign: Stepwise Prompting LLM for Sign Language Production](https://arxiv.org/abs/2507.10972)
> *教我手语：逐步提示LLM用于手语生成*

*Zhaoyi An, Rei Kawakami* | **Category: cs.CL, cs.CV, cs.MM** | **Updated: 2025-07-15**

**Keywords:** 手语生成, 大型语言模型, 逐步提示, 自然语言处理

**Comment:** Accepted by IEEE ICIP 2025

> **TL;DR:** 提出TEAM-Sign，通过逐步提示策略微调LLM，实现手语生成，有效对齐手语和口语的差异。

**AI_Comments:** 该论文的创新之处在于将手语视为LLM的另一种自然语言进行处理，并采用逐步提示策略来解锁LLM固有的手语知识，这对于弥合口语和手语在基于LLM的生成中的鸿沟至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型对手语生成的影响有限，因为手语具有复杂性和独特的规则。

**Method:** 提出TEAch Me Sign (TEAM-Sign) 方法，将手语视为自然语言。通过微调LLM，使其学习文本和手语的对应关系。采用逐步提示策略，提取LLM中固有的手语知识，支持学习和生成过程。

**Result:** 在How2Sign和Phoenix14T数据集上的实验结果表明，该方法有效利用LLM的手语知识和推理能力，对齐手语和口语之间不同的分布和语法规则。

**Conclusion:** 该方法成功地利用大型语言模型进行手语生成，并有效解决了手语与口语之间的差异问题。

> **ai_Abstract:** 本文提出了一种名为TEAM-Sign的新方法，旨在使大型语言模型（LLM）能够生成手语，通过将其视为一种自然语言。该方法通过微调LLM并采用逐步提示策略来解决手语的复杂性和独有规则，成功地对齐了手语和口语之间的分布和语法规则。

> **摘要翻译:** 大型语言模型凭借其强大的推理能力和丰富的知识，为许多人工智能任务带来了革命，但由于其复杂性和独特的规则，它们对手语生成的影响仍然有限。在本文中，我们提出了TEAch Me Sign (TEAM-Sign)，将手语视为另一种自然语言。通过微调大型语言模型，我们使其能够学习文本和手语之间的对应关系，并促进生成。考虑到手语和口语之间的差异，我们采用逐步提示策略来提取大型语言模型中固有的手语知识，从而支持学习和生成过程。在How2Sign和Phoenix14T数据集上的实验结果表明，我们的方法有效地利用了大型语言模型的手语知识和推理能力，以对齐手语和口语之间不同的分布和语法规则。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [704] [Leveraging Large Language Models for Multi-Class and Multi-Label Detection of Drug Use and Overdose Symptoms on Social Media](https://arxiv.org/abs/2504.12355)
> *利用大型语言模型在社交媒体上进行药物使用和过量症状的多类别和多标签检测*

*Muhammad Ahmad, Fida Ullah, Muhammad Usman, Umyh Habiba, ldar Batyrshin, Grigori Sidorov* | **Category: cs.CL, cs.AI, cs.SI** | **Updated: 2025-07-15**

**Keywords:** 药物过量检测, 社交媒体, 大型语言模型, NLP, 公共卫生监测

**Comment:** 

> **TL;DR:** 本研究提出一个AI驱动的NLP框架，结合LLM和人工标注，用于在社交媒体上检测药物使用和过量症状，取得了高准确率，并强调了AI在公共卫生监测中的潜力。

**AI_Comments:** 这项研究的创新之处在于将大型语言模型（LLMs）与人工标注相结合，形成一个高效的混合标注策略，用于处理复杂的社交媒体文本数据。其重要性体现在为药物过量监测提供了一个实时的、高准确率的AI驱动解决方案，有望显著提升公共卫生领域的早期预警和干预能力。该框架的高性能（98%和97%的准确率）证明了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 药物过量仍然是一个全球性的关键健康问题，传统研究方法面临局限，而社交媒体能提供实时洞察。因此，本研究旨在利用社交媒体数据检测药物使用和过量症状，以支持公共卫生监测。

**Method:** 本研究提出了一个AI驱动的NLP框架，该框架基于标注的社交媒体数据进行训练。采用混合标注策略，结合大型语言模型（LLMs）和人工标注。模型方面，应用了传统的机器学习模型、神经网络和先进的基于Transformer的模型。

**Result:** 本框架在多类别分类中达到了98%的准确率，在多标签分类中达到了97%的准确率，性能比基线模型高出8%。

**Conclusion:** 研究结果突出了人工智能在支持公共卫生监测和个性化干预策略方面的潜力。

> **ai_Abstract:** 本研究提出一个基于AI的NLP框架，旨在利用社交媒体数据检测药物使用和过量症状。通过结合大型语言模型和人工标注的混合策略，并应用多种机器学习模型，该框架在多类别和多标签分类任务中分别实现了98%和97%的高准确率，显著优于基线模型。这表明AI在公共卫生监测和个性化干预方面具有巨大潜力，有助于应对药物过量这一全球健康挑战。

> **摘要翻译:** 药物过量仍然是一个关键的全球健康问题，通常由阿片类药物、止痛药和精神药物的滥用引起。传统研究方法面临局限性，而社交媒体为自我报告的物质使用和过量症状提供了实时洞察。本研究提出了一个AI驱动的NLP框架，该框架在标注的社交媒体数据上进行训练，以检测常用药物和相关的过量症状。我们采用大型语言模型（LLMs）和人工标注相结合的混合标注策略，应用了传统的机器学习模型、神经网络和先进的基于Transformer的模型。我们的框架在多类别分类中达到了98%的准确率，在多标签分类中达到了97%的准确率，性能比基线模型高出8%。这些发现突出了人工智能在支持公共卫生监测和个性化干预策略方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [715] [KAT-V1: Kwai-AutoThink Technical Report](https://arxiv.org/abs/2507.08297)
> *KAT-V1: 快手自动思考技术报告*

*Zizheng Zhan, Ken Deng, Huaixi Tang, Wen Xiang, Kun Wu, Weihao Li, Wenqiang Zhu, Jingxuan Xu, Lecheng Huang, Zongxian Feng, Shaojie Wang, Shangpeng Yan, Xuxing Chen, Jiaheng Liu, Zhongyuan Peng, Zuchen Gao, Haoyang Huang, Xiaojiang Zhang, Jinghui Wang, Zheng Lin, Mengtong Li, Huiming Wang, Ziqi Zhan, Yanan Wu, Yuanxing Zhang, Jian Yang, Guang Chen, Haotian Zhang, Bin Chen, Bing Yu* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 自动思考, 推理, 知识蒸馏, 强化学习

**Comment:** 

> **TL;DR:** KAT-V1介绍了一个40B的开源大语言模型KAT，它通过自动思考训练范式动态切换推理和非推理模式，在推理密集型任务中达到或超越SOTA性能，并显著减少令牌使用，已成功应用于实际场景。

**AI_Comments:** 该论文提出了一种创新的“自动思考”范式，以解决大型语言模型在推理任务中的过度思考问题，这是一个具有实际意义的重要挑战。动态模式切换以及MTP增强知识蒸馏、冷启动初始化和Step-SRPO等多种先进技术的结合，使得该方法全面而有效。在真实产品（Kwaipilot）中的成功部署以及向更大规模模型的可扩展性展示，凸显了KAT的实际价值和潜力。在提升性能的同时关注效率（减少令牌使用）也是其一个重要优势。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在解决推理密集型任务中大型语言模型的“过度思考”问题。

**Method:** 本研究提出了一种自动思考训练范式，根据任务复杂性动态切换推理和非推理模式。具体方法包括：1. 构建基于新颖标注管道和多智能体合成策略的双模式数据集。2. 应用多令牌预测（MTP）增强的知识蒸馏，实现高效、细粒度的推理迁移。3. 实施冷启动初始化策略，利用多数投票信号和意图感知提示引入模式选择先验。4. 提出Step-SRPO强化学习算法，将中间监督融入GRPO框架，为推理模式选择和响应准确性提供结构化指导。此外，研究还在积极训练一个200B的混合专家（MoE）模型以验证可扩展性。

**Result:** KAT在广泛的推理密集型任务中始终与当前最先进的模型（如DeepSeek-R1-0528和Qwen3-235B-A22B）相媲美或超越。它将令牌使用量减少了约30%。KAT已成功部署在快手内部编码助手Kwaipilot中，提升了实际开发工作流程的准确性、效率和可控推理行为。200B MoE模型的早期结果也显示出性能和效率方面的有希望的改进。

**Conclusion:** KAT通过其提出的自动思考范式和相关训练策略，有效解决了推理任务中的过度思考问题，并在性能和效率上达到了最先进水平。其在实际应用中的成功部署和在更大规模模型上的可扩展性进一步证明了其价值和潜力。

> **ai_Abstract:** KAT-V1提出了一个名为Kwaipilot-AutoThink (KAT) 的40B开源大型语言模型，旨在解决推理任务中的“过度思考”问题。该模型引入了自动思考训练范式，能根据任务复杂度动态切换推理与非推理模式。其核心方法包括构建双模式数据集、采用MTP增强的知识蒸馏、实现冷启动初始化策略以及开发Step-SRPO强化学习算法。实验证明，KAT在多种推理密集型任务上性能达到或超越现有SOTA模型，并能减少约30%的令牌使用量。KAT已成功应用于快手内部编码助手Kwaipilot，提升了实际开发效率与准确性。此外，该范式在更大规模模型（200B MoE）上展现出良好的可扩展性。

> **摘要翻译:** 我们介绍了Kwaipilot-AutoThink（KAT），一个开源的40B大型语言模型，旨在解决推理密集型任务中的“过度思考”问题。为此，我们提出了一种自动思考训练范式，根据任务复杂性动态切换推理和非推理模式。具体来说，首先，我们基于新颖的标注管道和多智能体合成策略构建了双模式数据集；然后，我们应用了多令牌预测（MTP）增强的知识蒸馏，以最小的预训练成本实现高效和细粒度的推理迁移。此外，我们实现了一种冷启动初始化策略，利用多数投票信号和意图感知提示引入模式选择先验。最后，我们提出了Step-SRPO，一种将中间监督融入GRPO框架的强化学习算法，为推理模式选择和响应准确性提供结构化指导。在多个基准上的大量实验表明，KAT在广泛的推理密集型任务中始终与当前最先进的模型（包括DeepSeek-R1-0528和Qwen3-235B-A22B）相媲美甚至超越，同时将令牌使用量减少了约30%。除了学术评估之外，KAT已成功部署在Kwaipilot（即快手内部编码助手）中，并通过高准确性、高效率和可控的推理行为改进了实际开发工作流程。此外，我们正在积极训练一个200B的混合专家（MoE）模型，其激活参数为40B，早期结果已显示出性能和效率方面的有希望的改进，进一步展示了AutoThink范式的可扩展性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [721] [Is Training Data Quality or Quantity More Impactful to Small Language Model Performance?](https://arxiv.org/abs/2411.15821)
> *小型语言模型性能：训练数据质量还是数量影响更大？*

*Aryan Sajith, Krishna Chaitanya Rao Kathala* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 训练数据质量, 训练数据数量, 小型语言模型, 数据重复, 模型性能

**Comment:** 14 pages, 5 tables, 4 figures | Accepted at International Conference
  on Neural Computing for Advanced Applications 2025, Conference info:
  https://aaci.org.hk/ncaa2025

> **TL;DR:** 研究发现，对小型语言模型而言，训练数据质量比数量对性能影响更大，适度重复有益，过度重复有害。

**AI_Comments:** 这项研究的重要性在于它挑战了“数据越多越好”的传统观念，特别针对资源受限的小型语言模型。它强调了数据质量在模型性能中的关键作用，并揭示了适度数据重复的潜在益处。这对于减少AI训练的计算和财务负担，以及推动AI的民主化和可持续发展具有重要意义，尤其是在资源有限的环境中。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在探究训练数据质量与数量对小型语言模型（SLM）性能的相对影响，并指出大规模模型训练带来的高昂成本、计算负担和环境问题，强调理解数据质量与数量的重要性有助于普及和可持续发展AI技术。

**Method:** 研究利用TinyStories数据集进行实证分析。通过改变数据集大小（原始大小的25%和50%）和重复率（25%、50%、75%和100%）来创建数据集变体。模型性能通过验证损失、准确率和困惑度指标进行评估。

**Result:** 结果表明，训练数据质量对SLM的整体性能影响更大。少量数据重复（25%）能积极提升模型准确率（+0.87%），且不会显著增加困惑度（+0.52%）。然而，过度的数据重复（100%）导致性能显著下降（准确率下降40%）。

**Conclusion:** 训练数据质量对小型语言模型的性能影响比数量更为显著。在特定规模下，适度的数据重复可以提升模型性能，但过度的重复会导致性能严重退化。

> **ai_Abstract:** 本研究探讨了训练数据质量与数量对小型语言模型（SLM）性能的相对影响。利用TinyStories数据集，通过调整数据大小和重复率进行实验。结果显示，数据质量比数量对SLM性能影响更大。适度的重复（25%）能提升模型准确率（+0.87%），而过度重复（100%）则导致显著性能下降（准确率-40%）。研究强调了优化数据质量对于降低AI训练成本、减少环境影响以及促进AI技术普及的重要性。

> **摘要翻译:** 这项研究利用TinyStories数据集进行实证分析，探讨了训练数据质量与数量对小型语言模型（SLMs）性能的相对影响。研究对数据集的大小（原始大小的25%和50%）和重复率（25%、50%、75%和100%）进行了分析。模型性能根据验证损失、准确率和困惑度指标进行评估。结果表明，训练数据质量在小型语言模型的整体性能中扮演了更重要的角色，尤其是在本次实验的规模下。少量的重复对模型准确率产生了积极影响（在25%重复率下，准确率提高了0.87%），且没有显著增加困惑度（从0%到25%重复率，困惑度增加了0.52%），但过度的重复导致了明显的性能下降（在100%重复率下，准确率下降了40%）。这项探索的意义超越了模型性能本身；训练大规模模型会带来巨大的财政和计算负担，这对于组织、个人乃至大众来说都是难以承受的，尤其是在发展中国家。此外，与大规模训练相关的能源消耗也引发了环境问题。理解数据质量与数量的相对重要性可以使人工智能技术民主化，让高级模型更易于所有人获取和可持续发展。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [725] [A Generative Approach to LLM Harmfulness Detection with Special Red Flag Tokens](https://arxiv.org/abs/2502.16366)
> *一种使用特殊红旗令牌的LLM有害性检测生成方法*

*Sophie Xhonneux, David Dobre, Mehrnaz Mofakhami, Leo Schwinn, Gauthier Gidel* | **Category: cs.CL, cs.AI, cs.CR, cs.LG** | **Updated: 2025-07-15**

**Keywords:** LLM安全, 有害性检测, 红旗令牌, 生成式方法, LoRA

**Comment:** 14 pages, 6 figures

> **TL;DR:** 现有的LLM安全训练会损害模型能力，本文提出一种“红旗令牌”方法，在不牺牲效用的情况下检测有害内容。

**AI_Comments:** 本文为LLM安全中的一个关键问题（如何在不降低模型性能的情况下减轻有害输出）提供了一种创新且实用的解决方案。“红旗令牌”概念是新颖的，因为它允许在生成过程中明确标记有害性，而不是强制完全拒绝。这种对安全训练的微妙方法，结合用于API攻击防御的LoRA模块，代表着开发更鲁棒和多功能的安全LLM迈出了重要一步。其在增强安全性的同时保持效用的关注尤其有价值。

<details>
  <summary>Details</summary>

**Motivation:** 大多数LLM安全训练方法（微调）会导致剧烈的分布偏移，从而损害模型能力。

**Method:** 扩展模型词汇表，加入特殊令牌“红旗令牌”（<rf>），训练模型在生成或即将生成有害内容时插入该令牌。将安全调优封装在LoRA模块中。

**Result:** 使模型能明确学习有害性概念，同时对生成分布影响微乎其微，从而保持模型效用。评估每个生成答案，提供与对抗训练同样好的鲁棒性，无需在训练期间运行攻击。提供额外的防御以抵御微调API攻击。

**Conclusion:** 提出的红旗令牌方法是一种有效且破坏性较小的LLM有害性检测和安全方法，能够保持模型效用并提供鲁棒的防御。

> **ai_Abstract:** 本文提出一种使用特殊“红旗令牌”（<rf>）的生成式LLM有害内容检测方法。与传统微调方法因剧烈分布偏移而损害模型效用不同，该方法训练模型在生成或预期生成有害内容时插入<rf>令牌。这种方法使模型能够明确学习有害性，同时对生成分布影响最小，保持模型效用，提供与对抗训练相当的鲁棒性而无需攻击模拟，并通过LoRA模块提供额外的API攻击防御。

> **摘要翻译:** 大多数大型语言模型（LLM）的安全训练方法都基于微调，当面临有害请求时，这些方法会迫使模型从不安全答案转变为拒绝。不幸的是，这些剧烈的分布偏移通常会损害模型能力。为避免这种情况，我们建议通过一个我们称之为红旗令牌（<rf>）的特殊令牌来扩展模型的词汇表，并建议训练模型在生成或即将生成有害内容时随时将其插入到响应中。我们的方法具有几个优点：它使模型能够明确学习有害性的概念，同时对生成分布的影响微乎其微，从而保持模型的效用。它还评估每个生成的答案，并提供与对抗训练一样好的鲁棒性，而无需在训练期间运行攻击。此外，通过将我们的安全调优封装在LoRA模块中，我们提供了额外的防御以抵御微调API攻击。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [735] [DocPolarBERT: A Pre-trained Model for Document Understanding with Relative Polar Coordinate Encoding of Layout Structures](https://arxiv.org/abs/2507.08606)
> *DocPolarBERT：一种采用相对极坐标编码布局结构进行文档理解的预训练模型*

*Benno Uthayasooriyar, Antoine Ly, Franck Vermet, Caio Corro* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** DocPolarBERT, 文档理解, 布局感知, 极坐标编码, 预训练模型

**Comment:** 

> **TL;DR:** DocPolarBERT是一种新的文档理解模型，它使用相对极坐标编码布局结构，无需绝对2D位置嵌入。尽管预训练数据量小得多，但它仍能达到最先进的性能，表明精心设计的注意力机制可以弥补数据量的不足。

**AI_Comments:** DocPolarBERT的创新之处在于其采用相对极坐标编码布局结构，这提供了一种新颖且可能更鲁棒的方式来处理文档空间信息。其重要性在于证明了在预训练数据量大幅减少的情况下，通过模型架构的巧妙设计（如注意力机制的优化）依然可以达到SOTA性能，这对于资源有限的研究者或需要快速迭代的场景具有重要意义，降低了对大规模数据集的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是消除文档理解模型对绝对2D位置嵌入的需求，并探索在预训练数据量较少的情况下，如何通过改进模型架构来保持或提高性能。

**Method:** DocPolarBERT通过将自注意力机制扩展到考虑文本块在相对极坐标系中的位置，而不是传统的笛卡尔坐标系，来编码布局结构。

**Result:** DocPolarBERT在比广泛使用的IIT-CDIP语料库小六倍多的数据集上进行预训练后，仍然取得了最先进的结果。

**Conclusion:** 本研究的结论是，精心设计的注意力机制能够弥补预训练数据量的减少，为文档理解提供了一种高效且有效的替代方案。

> **ai_Abstract:** DocPolarBERT是一种新型的文档理解预训练模型，它创新性地利用相对极坐标系编码文本块的布局结构，从而避免了对绝对2D位置嵌入的依赖。该模型在远小于现有大型语料库的数据集上进行预训练后，依然能够实现最先进的性能，这证明了通过优化注意力机制可以有效补偿预训练数据的不足，提供了一种高效且实用的文档理解方法。

> **摘要翻译:** 我们引入了DocPolarBERT，这是一种用于文档理解的布局感知BERT模型，它消除了对绝对2D位置嵌入的需求。我们将自注意力机制扩展，以考虑文本块在相对极坐标系中的位置，而不是笛卡尔坐标系。尽管在比广泛使用的IIT-CDIP语料库小六倍多的数据集上进行了预训练，DocPolarBERT仍取得了最先进的结果。这些结果表明，精心设计的注意力机制可以弥补预训练数据的减少，为文档理解提供了一种高效且有效的替代方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [748] [Mario at EXIST 2025: A Simple Gateway to Effective Multilingual Sexism Detection](https://arxiv.org/abs/2507.10996)
> *Mario在EXIST 2025：一个实现有效多语言性别歧视检测的简单途径*

*Lin Tian, Johanne R. Trippas, Marian-Andrei Rizoiu* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 性别歧视检测, LoRA, Llama 3.1, 多语言, 参数高效微调

**Comment:** 12 pages, 5 tables, CLEF 2025

> **TL;DR:** 该论文提出了一种基于Llama 3.1 8B的分层低秩适应（LoRA）方法，用于在英语和西班牙语推文中进行多语言性别歧视检测，通过条件适配器路由和对所有线性变换的应用，实现了高效且高性能的文本性别歧视识别。

**AI_Comments:** 该论文的创新点在于其将分层LoRA与条件适配器路由结合，以处理多语言和多层次的性别歧视检测任务，并且将LoRA应用于所有线性变换，而非仅限于注意力层。其重要性体现在通过参数高效微调实现了强大的性能，显著减少了计算资源和存储需求，为实际应用提供了更经济高效的解决方案。同时，统一的多语言训练策略也简化了模型部署，展现了跨语言迁移的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在解决EXIST 2025任务1中基于文本的性别歧视检测问题，特别是在英语和西班牙语推文中的检测，并寻求一种简单、高效且性能强大的方法来处理多语言和分层子任务。

**Method:** 该方法提出了对Llama 3.1 8B模型进行分层低秩适应（LoRA），并引入了条件适配器路由，明确地建模了三个分层子任务（二元性别歧视识别、来源意图检测和多标签性别歧视分类）之间的标签依赖关系。与传统LoRA不同，该方法将适应应用于所有线性变换。它为每个子任务训练独立的LoRA适配器（rank=16, QLoRA 4-bit），并利用Llama 3.1的本地双语能力进行统一的多语言训练，无需单独的语言模型。

**Result:** 该方法通过跨语言迁移实现了1.7-2.4%的F1分数提升。与完全微调相比，可训练参数仅为1.67%，训练时间减少了75%，模型存储减少了98%。在所有子任务上均取得了有竞争力的性能，其中ICM-Hard分数为：二元分类0.6774，意图检测0.4991，多标签分类0.6519。

**Conclusion:** 该研究表明，通过对Llama 3.1 8B进行分层LoRA和条件适配器路由的参数高效微调，可以实现强大且高效的多语言文本性别歧视检测，无需复杂的数据处理和集成方法，并且在资源消耗方面具有显著优势。

> **ai_Abstract:** 本论文提出了一种名为“Mario”的简单而有效的方法，用于EXIST 2025任务1中的多语言文本性别歧视检测。该方法通过对Llama 3.1 8B模型应用分层低秩适应（LoRA）并引入条件适配器路由，处理英语和西班牙语推文中的性别歧视。它创新性地将LoRA应用于所有线性变换，并明确建模了二元性别歧视识别、意图检测和多标签分类这三个分层子任务的依赖关系。实验结果表明，该参数高效的微调方法在减少训练时间和存储需求的同时，实现了与复杂方法相当或更优的性能，并通过跨语言迁移提升了F1分数。

> **摘要翻译:** 本论文介绍了我们参与EXIST 2025任务1的方法，该任务旨在通过对Llama 3.1 8B进行分层低秩适应（LoRA），解决英语和西班牙语推文中的文本性别歧视检测问题。我们的方法引入了条件适配器路由，明确地建模了三个分层结构子任务之间的标签依赖关系：二元性别歧视识别、来源意图检测和多标签性别歧视分类。与仅针对注意力层的传统LoRA应用不同，我们将适应应用于所有线性变换，增强了模型捕获特定任务模式的能力。与复杂的数据处理和集成方法相比，我们表明直接的参数高效微调可以实现强大的性能。我们使用统一的多语言训练，为每个子任务训练独立的LoRA适配器（秩=16，QLoRA 4位），该训练利用了Llama 3.1的本地双语能力。该方法需要最少预处理，并使用标准的监督学习。我们的多语言训练策略消除了对单独的特定语言模型的需求，通过跨语言迁移实现了1.7-2.4%的F1分数提升。与完全微调相比，我们的方法仅需1.67%的可训练参数，将训练时间减少了75%，模型存储减少了98%，同时在所有子任务上均取得了有竞争力的性能（ICM-Hard：二元分类0.6774，意图检测0.4991，多标签分类0.6519）。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [763] [AIDE: Attribute-Guided MultI-Hop Data Expansion for Data Scarcity in Task-Specific Fine-tuning](https://arxiv.org/abs/2412.06136)
> *AIDE：面向任务特定微调中数据稀缺问题的属性引导多跳数据扩展*

*Jiayu Li, Xuan Zhu, Fang Liu, Yanjun Qi* | **Category: cs.CL** | **Updated: 2025-07-14**

**Keywords:** 数据扩展, 微调, LLMs, 数据稀缺, 属性引导

**Comment:** Accepted for publication in ACL 2025. The official version will be
  available in the ACL Anthology

> **TL;DR:** AIDE是一种新颖的数据合成框架，通过属性引导的多跳过程从极少量种子数据中扩展出多样化且与任务相关的数据，有效解决了LLM微调中的数据稀缺问题，并超越了现有方法。

**AI_Comments:** AIDE的创新之处在于其属性引导的多跳数据扩展机制和残差连接，这使其能够从极少量初始数据中高效生成大量高质量、多样化且与任务相关的数据。其重要性在于显著降低了LLM微调对大量人工标注数据的依赖，为资源受限场景下的LLM应用提供了有效解决方案，并且在性能上超越了现有方法，具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 微调大型语言模型（LLM）需要大量多样化、高质量的训练数据，但获取这些数据是一个重大挑战。现有数据合成方法要么依赖大量种子数据，要么难以平衡任务相关性和数据多样性。

**Method:** 本文提出属性引导多跳数据扩展（AIDE）框架。它通过多跳过程扩展少量种子数据点，以确保数据多样性和任务相关性。AIDE从种子中提取主题和关键知识属性来指导合成步骤，并重复K跳，将生成的数据作为新的种子。为防止随着跳深增加生成不相关数据，AIDE引入了残差连接机制。

**Result:** AIDE能够从10个种子数据点成功微调Mistral-7B、Llama-3.1-8B和Llama-3.2-3B等模型，其性能超越了使用人工整理数据微调的模型。此外，AIDE在任务特定微调中，比Evol-Instruct等最先进的数据合成方法性能高出30%以上。

**Conclusion:** AIDE框架通过属性引导的多跳数据扩展，有效地解决了大型语言模型任务特定微调中的数据稀缺问题，能够从极少量种子数据生成高质量、多样化且相关的训练数据，并展现出优于现有方法的性能。

> **ai_Abstract:** AIDE是一种新颖的属性引导多跳数据扩展框架，旨在解决大型语言模型任务特定微调中的数据稀缺问题。该框架通过从少量种子数据中提取主题和关键属性来指导多跳合成过程，并利用残差连接机制保持数据相关性，从而生成多样化且高质量的训练数据。实验结果表明，AIDE能够仅使用10个种子数据点就有效微调LLM，其性能优于使用人工整理数据和现有最先进数据合成方法（如Evol-Instruct）。

> **摘要翻译:** 微调大型语言模型（LLM）以完成特定任务需要多样化、高质量的训练数据。然而，获取足够的相关数据仍然是一个重大挑战。现有数据合成方法要么依赖大量种子数据集，要么难以平衡任务相关性和数据多样性。为了解决这些挑战，我们提出了一种新颖的数据合成框架——属性引导多跳数据扩展（AIDE），该框架使用多跳过程来扩展极少量种子数据点，同时确保数据多样性和任务相关性。AIDE从种子中提取主题和关键知识属性来指导合成步骤。这个过程重复K跳，使用生成的数据作为种子。为了防止随着跳深度的增加生成不相关的数据，AIDE引入了残差连接机制。我们的经验结果表明，AIDE能够从10个种子微调Mistral-7B、Llama-3.1-8B和Llama-3.2-3B，超越了在人工整理数据上微调的模型。此外，AIDE在任务特定微调中，比Evol-Instruct等最先进的数据合成方法表现高出30%以上。代码可在https://github.com/Code4Graph/AIDE获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [771] [SEALGuard: Safeguarding the Multilingual Conversations in Southeast Asian Languages for LLM Software Systems](https://arxiv.org/abs/2507.08898)
> *SEALGuard：保护LLM软件系统中东南亚语言的多语言对话*

*Wenliang Shan, Michael Fu, Rui Yang, Chakkrit Tantithamthavorn* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 多语言安全对齐, LLM护栏, 低资源语言, SEALSBench, LoRA

**Comment:** Under Review at Information and Software Technology

> **TL;DR:** SEALGuard是一个多语言护栏，旨在提高LLM在东南亚低资源语言中的安全对齐，通过LoRA适应多语言模型并在新数据集上表现优于现有方法。

**AI_Comments:** SEALGuard的创新之处在于其专门针对LLM的多语言安全对齐问题，特别是关注了低资源语言。通过引入LoRA适应多语言模型，并构建大规模的SEALSBench数据集，SEALGuard有效地弥补了现有护栏在多语言环境下的不足。这项工作对于提升全球范围内LLM应用的安全性具有重要意义，尤其是在语言多样性高的地区。其贡献不仅在于提出了一个更优的解决方案，还在于提供了一个新的多语言安全基准数据集，这将促进未来该领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型（LLM）安全护栏（如LlamaGuard）在处理多语言不安全输入时表现不佳，特别是在东南亚等低资源语言中，这使得LLM系统容易受到不安全和越狱提示的攻击。

**Method:** 本文引入了SEALGuard，一个多语言护栏，旨在解决现有护栏的多语言安全对齐差距。通过低秩适应（LoRA）将一个通用多语言语言模型转换为多语言护栏。构建了一个名为SEALSBench的大规模多语言安全对齐数据集，包含超过26万个提示（安全、不安全和越狱案例），涵盖十种语言。在SEALSBench上评估了SEALGuard与现有最先进的护栏（如LlamaGuard）。

**Result:** 研究发现，多语言不安全和越狱提示显著降低了最先进的LlamaGuard的性能，其防御成功率（DSR）分别下降了9%和18%。相比之下，SEALGuard在检测多语言不安全和越狱提示方面优于现有护栏，DSR比LlamaGuard提高了48%，并取得了最佳的DSR、精确率和F1分数。消融研究揭示了适应策略和模型大小对SEALGuard整体性能的贡献。

**Conclusion:** SEALGuard通过引入有效的多语言护栏，提升了LLM系统的安全对齐能力。

> **ai_Abstract:** 本文介绍了SEALGuard，一个专门为解决大语言模型（LLM）在处理多语言不安全和越狱提示时的安全对齐问题而设计的多语言护栏。针对现有护栏在东南亚等低资源语言中表现不佳的限制，SEALGuard通过低秩适应（LoRA）技术，将通用多语言模型转化为高效护栏。研究团队构建了包含26万余条多语言提示的大规模数据集SEALSBench，并在此数据集上评估了SEALGuard。结果显示，SEALGuard显著优于LlamaGuard等现有先进护栏，在多语言环境下检测不安全和越狱提示方面，防御成功率提高了48%，并在DSR、精确率和F1分数上均达到最佳表现，有效提升了LLM系统的多语言安全性。

> **摘要翻译:** 安全对齐对于LLM驱动的系统至关重要。尽管近期LLM驱动的护栏方法（如LlamaGuard）在检测英语（例如“如何制造炸弹？”）中不安全输入方面取得了高检测精度，但它们在多语言不安全输入方面却面临困难。这一限制使得LLM系统容易受到用低资源语言（如东南亚语言）编写的不安全和越狱提示的攻击。本文介绍了SEALGuard，一个多语言护栏，旨在提高跨不同语言的安全对齐。它旨在解决现有护栏的多语言安全对齐差距，并确保有效过滤LLM驱动系统中的不安全和越狱提示。我们使用低秩适应（LoRA）将一个通用多语言语言模型转换为多语言护栏。我们构建了SEALSBench，一个大规模多语言安全对齐数据集，包含超过26万个提示，涵盖十种语言，包括安全、不安全和越狱案例。我们在这个基准测试中评估了SEALGuard与LlamaGuard等最先进的护栏。我们的研究结果表明，多语言不安全和越狱提示显著降低了最先进的LlamaGuard的性能，与仅英语提示的性能相比，其防御成功率（DSR）分别下降了9%和18%。相比之下，SEALGuard在检测多语言不安全和越狱提示方面优于现有护栏，DSR比LlamaGuard提高了48%，并取得了最佳的DSR、精确率和F1分数。我们的消融研究进一步揭示了适应策略和模型大小对SEALGuard整体性能的贡献。SEALGuard通过引入有效的多语言护栏，提升了LLM系统的安全对齐能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [783] [Team HUMANE at AVeriTeC 2025: HerO 2 for Efficient Fact Verification](https://arxiv.org/abs/2507.11004)
> *HUMANE 团队在 AVeriTeC 2025：HerO 2 实现高效事实核查*

*Yejun Yoon, Jaeyoon Jung, Seunghyun Yoon, Kunwoo Park* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 事实核查, HerO 2, AVeriTeC, 语言模型, 效率

**Comment:** ACL 2025 Workshop (FEVER)

> **TL;DR:** HerO 2 是 HUMANE 团队为 AVeriTeC 2025 共享任务开发的系统，通过改进证据质量、优化真实性预测和集成更新的语言模型骨干，在排行榜上排名第二，同时在效率上表现出色。

**AI_Comments:** HerO 2 的创新之处在于其对效率的关注，通过训练后量化在保持高性能的同时显著缩短了运行时间，这对于实际应用至关重要。同时，通过结合证据质量改进和语言模型骨干更新，提升了系统的整体性能和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在介绍 HUMANE 团队为 FEVER-25 研讨会上的 AVeriTeC 共享任务开发的 HerO 2 系统，旨在实现高效的事实核查。

**Method:** HerO 2 是 HerO 的增强版本，通过文档摘要和答案重构改进证据质量，通过计算约束下的训练后量化优化真实性预测，并通过集成更新的语言模型骨干来增强整体系统性能。

**Result:** HerO 2 在排行榜上排名第二，同时在排名前三的系统中运行时间最短。

**Conclusion:** HerO 2 表现出高效率和强大的真实世界事实核查潜力。

> **ai_Abstract:** HerO 2 是 HUMANE 团队为 AVeriTeC 2025 事实核查任务开发的系统，它是先前最佳模型的改进版。该系统通过文档摘要、答案重构、训练后量化以及更新的语言模型骨干来提升证据质量、优化预测并增强整体性能。HerO 2 在排行榜上获得第二名，并在前三名系统中运行时间最短，凸显了其高效率和实际应用潜力。

> **摘要翻译:** 本文介绍了 HerO 2，这是 HUMANE 团队为 FEVER-25 研讨会上的 AVeriTeC 共享任务开发的系统。HerO 2 是 HerO 的增强版本，HerO 是去年挑战赛中表现最佳的开源模型。它通过文档摘要和答案重构提高了证据质量，在计算约束下通过训练后量化优化了真实性预测，并通过集成更新的语言模型 (LM) 骨干增强了整体系统性能。HerO 2 在排行榜上排名第二，同时在排名前三的系统中运行时间最短，展示了高效率和强大的真实世界事实核查潜力。代码可在 https://github.com/ssu-humane/HerO2 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [799] [REST: Stress Testing Large Reasoning Models by Asking Multiple Problems at Once](https://arxiv.org/abs/2507.10541)
> *REST：通过同时提问多个问题来压力测试大型推理模型*

*Zhuoshi Pan, Qizhi Pei, Yu Li, Qiyao Sun, Zinan Tang, H. Vicky Zhao, Conghui He, Lijun Wu* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** 大型推理模型, 压力测试, 多问题推理, 评估范式, 过度思考陷阱

**Comment:** REST (Reasoning Evaluation through Simultaneous Testing), a
  stress-testing framework that concurrently exposes LRMs to multiple problems
  simultaneously

> **TL;DR:** 现有大型推理模型（LRMs）的评估受限于单问题测试。REST是一个新的压力测试框架，通过同时提出多个问题来评估LRMs，揭示了模型性能下降并提供了更强的区分能力。

**AI_Comments:** 该论文提出了一种新颖的评估大型推理模型的方法，突破了传统单问题测试的局限性，更贴近真实世界的多任务场景。其创新点在于引入了多问题同时测试的压力情境，揭示了现有模型在多上下文处理、干扰抵抗和认知负荷管理方面的不足。REST 框架不仅提供了更强的模型区分能力，还指出了“过度思考陷阱”这一有趣的现象，并验证了“长变短”训练技术的有效性，为未来模型优化提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型推理模型（LRMs）评估方法受限于孤立的问题解决范式，导致存在以下关键局限性：(1) 易受数据污染且挑战性不足，需要耗费大量人力创建新问题；(2) 未能在多上下文压力下评估模型，而这对于实际部署至关重要。

**Method:** 本文提出了 REST（Reasoning Evaluation through Simultaneous Testing）框架，这是一个压力测试框架，通过同时向大型推理模型（LRMs）呈现多个问题进行评估。REST 不仅评估基本推理能力，还评估上下文优先级分配、跨问题干扰抵抗和动态认知负荷管理等能力。

**Result:** 评估发现，即使是最先进（SOTA）的模型（如 DeepSeek-R1）在压力测试下也表现出显著的性能下降。REST 比现有基准测试具有更强的区分能力，能揭示在单问题评估下表现相似的模型之间明显的性能差异。分析表明，“过度思考陷阱”是导致性能下降的关键因素；采用“长变短”（long2short）技术训练的模型在 REST 下能更好地保持其单问题性能的准确性，优于标准训练的模型。

**Conclusion:** REST 是一种成本效益高、面向未来的评估范式，它能更好地反映现实世界的推理需求，同时减少对持续人工标注的依赖。

> **ai_Abstract:** 现有的大型推理模型（LRM）评估方法存在局限性，主要依赖单问题测试，导致模型易受污染且未能模拟多上下文真实场景。为解决此问题，本文提出了 REST 框架，通过同时向 LRM 呈现多个问题进行压力测试。研究发现，即使是先进的 LRM 在 REST 下性能也会显著下降，且 REST 比现有基准具有更强的区分度。此外，分析揭示“过度思考陷阱”是性能下降原因之一，而采用“长变短”技术训练的模型表现更优。REST 提供了一种更符合真实世界需求且成本效益高的评估范式。

> **摘要翻译:** 最近的大型推理模型（LRM）在特定任务基准测试上取得了显著进展，但其评估方法仍受限于孤立的问题解决范式。现有基准测试主要通过顺序测试评估单问题推理，导致了关键局限性：(1) 易受数据污染且挑战性不足（例如，DeepSeek-R1 在 MATH500 上达到 97.0%），这迫使需要耗费大量人力创建新的问题；(2) 未能在多上下文压力下评估模型，而这是实际部署的关键要求。为了弥补这一差距，我们提出了 REST（通过同步测试进行推理评估），这是一个压力测试框架，它使大型推理模型同时面临多个问题。除了基本推理之外，REST 还评估了几项未充分测试的能力：上下文优先级分配、跨问题干扰抵抗以及动态认知负荷管理。我们的评估揭示了几个惊人的发现：即使是 DeepSeek-R1 等最先进（SOTA）模型在压力测试下也表现出显著的性能下降。至关重要的是，REST 比现有基准测试表现出更强的区分能力，揭示了在单问题评估下表现相似、接近上限的模型之间明显的性能差异。我们的分析得出了一些关键见解：(1) “过度思考陷阱”是导致性能下降的关键因素；(2) 使用“长变短”（long2short）技术训练的模型在 REST 下比标准训练的模型更能保持其单问题性能的准确性。这些结果确立了 REST 作为一种成本效益高、面向未来的评估范式，它能更好地反映现实世界的推理需求，同时减少对持续人工标注的依赖。代码和结果可在 https://opendatalab.github.io/REST 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [805] [Understanding the Dark Side of LLMs' Intrinsic Self-Correction](https://arxiv.org/abs/2412.14959)
> *理解大型语言模型内在自我纠正的阴暗面*

*Qingjie Zhang, Di Wang, Haoting Qian, Yiming Li, Tianwei Zhang, Minlie Huang, Ke Xu, Hewu Li, Yan Liu, Han Qiu* | **Category: cs.CL** | **Updated: 2025-07-15**

**Keywords:** LLMs, 内在自我纠正, 认知偏见, 提示偏见, 失败案例

**Comment:** 

> **TL;DR:** 本研究旨在解释大型语言模型（LLMs）内在自我纠正的失败案例，揭示其可能导致答案动摇、提示偏见和认知偏见，并提出了两种简单的缓解策略。

**AI_Comments:** 该论文对LLMs内在自我纠正的局限性进行了深入剖析，挑战了其作为一项普遍有效改进策略的认知。其创新之处在于通过具体实验揭示了自我纠正可能导致的“阴暗面”，如答案不确定性和认知偏见。这些发现对于理解LLMs的行为模式及其在实际应用中的可靠性至关重要。同时，提出的简单缓解策略也具有很强的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管内在自我纠正旨在通过LLMs的固有能力改进其响应，但近期研究表明，在没有预言标签作为反馈提示的情况下，LLMs的内在自我纠正会失败。因此，本文旨在解释LLMs内在自我纠正在不同任务中的表现，特别是其失败案例。

**Method:** 本研究选取了一个简单任务和三个复杂任务，并使用了最先进的LLMs（如ChatGPT家族和Llama家族）。设计了三种解释方法来揭示LLMs内在自我纠正的“阴暗面”。同时，提出了两种简单的缓解策略：问题重复和少量样本的监督微调。

**Result:** 研究发现，内在自我纠正可能导致：1) LLMs在中间和最终答案上犹豫不决，并在简单事实问题上产生提示偏见；2) 在复杂任务上引入类似人类的认知偏见。

**Conclusion:** 本文揭示了LLMs内在自我纠正的负面影响，包括答案不确定性、提示偏见和认知偏见，并提出了两种简单有效的缓解策略：问题重复和少量样本的监督微调。

> **ai_Abstract:** 本文深入探讨了大型语言模型（LLMs）内在自我纠正的负面效应，此前该机制被认为能提升LLM响应质量。研究指出，在缺乏外部标签反馈时，LLMs的自我纠正机制会失效。通过对简单及复杂任务使用SOTA LLMs进行实验，并设计了三种解释方法，本文揭示了内在自我纠正会导致LLMs在答案上犹豫不决、产生提示偏见，并在复杂任务中引入类似人类的认知偏见。针对这些问题，研究提出了问题重复和少量样本监督微调两种简单有效的缓解策略。

> **摘要翻译:** 内在自我纠正被提议用来通过仅基于LLMs固有能力的反馈提示来改进LLMs的响应。然而，最近的工作表明，在没有预言标签作为反馈提示的情况下，LLMs的内在自我纠正会失败。在本文中，我们旨在解释LLMs在不同任务中的内在自我纠正，特别是那些失败案例。通过包含一个简单任务和三个复杂任务，并使用ChatGPT家族（o1、4o、3.5-turbo）和Llama家族（2-7B、3-8B和3.1-8B）等最先进（SOTA）的LLMs，我们设计了三种解释方法来揭示LLMs内在自我纠正的阴暗面。我们发现内在自我纠正会（1）导致LLMs在中间和最终答案上犹豫不决，并在简单事实问题上产生提示偏见；（2）在复杂任务上引入类似人类的认知偏见。根据我们的发现，我们还提供了两种简单而有效的缓解策略：问题重复和少量样本的监督微调。我们已将我们的工作开源在https://x-isc.info/。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [16] [On Tight Robust Coresets for $k$-Medians Clustering](https://arxiv.org/abs/2507.11260)
> *关于k-中位数聚类的紧致鲁棒核集*

*Lingxiao Huang, Zhenyu Jiang, Yi Li, Xuan Wu* | **Category: cs.DS, cs.CG, cs.DM** | **Updated: 2025-07-15**

**Keywords:** 鲁棒k-中位数聚类, 核集, 离群点, 度量空间, 数据集分解

**Comment:** 

> **TL;DR:** 本文为带离群点的鲁棒k-中位数聚类问题构建了新的紧致鲁棒核集，在多种度量空间中取得了改进的核集大小，并通过新颖的数据集分解技术实现了优化。

**AI_Comments:** 这篇论文通过引入新颖的数据集分解技术，显著改进了鲁棒k-中位数聚类和鲁棒(k,z)-聚类问题的核集大小，并在多个度量空间中达到了更优或最优的理论界限，展现了重要的理论贡献。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为带有离群点的鲁棒k-中位数聚类问题构建更紧致、更优化的核集，并在不同度量空间中提升现有结果。

**Method:** 引入了新颖的数据集分解技术，使得链式论证（chaining arguments）能够联合应用于多个组件。

**Result:** 在具有有界VC或加倍维度d的度量空间中，核集大小为 $O(m) + \tilde{O}(kd\varepsilon^{-2})$，达到对数因子最优。在欧几里得空间中，核集大小为 $O(m\varepsilon^{-1}) + \tilde{O}(\min\{k^{4/3}\varepsilon^{-2},k\varepsilon^{-3}\})$, 改进了Jiang和Lou（ICALP 2025）的最新结果。这些结果还扩展到鲁棒$(k,z)$-聚类，对于VC和加倍维度，核集大小为 $O(m) + \tilde{O}(kd\varepsilon^{-2z})$，对$m$具有最优线性依赖性，改进了Huang等（SODA 2025）的早期工作。

**Conclusion:** 本文为鲁棒k-中位数聚类问题提供了新的、更紧致的鲁棒核集构造，并在多个方面超越了现有技术，特别是在核集大小的渐近性方面取得了显著改进。

> **ai_Abstract:** 本文针对带有$m$个离群点的鲁棒$k$-中位数聚类问题，提出了在多种度量空间下的新颖紧致鲁棒核集构造。研究表明，在具有有界VC或加倍维度的空间中，核集大小达到对数因子最优；在欧几里得空间中，其核集大小优于现有成果。此外，这些结果也成功扩展到鲁棒$(k,z)$-聚类，对$m$的依赖性达到最优。核心技术在于引入了新颖的数据集分解方法，实现了链式论证在多组件间的联合应用。

> **摘要翻译:** 本文研究了带有$m$个离群点的鲁棒$k$-中位数问题，并在各种度量空间中获得了新的构造。具体而言，对于具有有界VC或加倍维度$d$的度量空间，核集大小为$O(m) + \tilde{O}(kd\varepsilon^{-2})$，这在对数因子内是最佳的。对于欧几里得空间，核集大小为$O(m\varepsilon^{-1}) + \tilde{O}(\min\{k^{4/3}\varepsilon^{-2},k\varepsilon^{-3}\})$, 改进了Jiang和Lou（ICALP 2025）的最新结果。这些结果也扩展到鲁棒$(k,z)$-聚类，对于VC和加倍维度，核集大小为$O(m) + \tilde{O}(kd\varepsilon^{-2z})$，对$m$具有最优线性依赖性。这一扩展结果改进了Huang等（SODA 2025）的早期工作。所采用的技术引入了新颖的数据集分解，使得链式论证能够联合应用于多个组件。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [59] [Permutation patterns in streams](https://arxiv.org/abs/2507.11291)
> *流中的排列模式*

*Benjamin Aram Berendsohn* | **Category: cs.DS** | **Updated: 2025-07-15**

**Keywords:** 排列模式, 流式算法, 模式匹配, 空间复杂度

**Comment:** 

> **TL;DR:** 本文研究流式设置下排列模式匹配问题的空间复杂度，发现复杂度取决于模式类型，并利用输入是排列的特性设计算法。

**AI_Comments:** 本文的创新之处在于将经典的排列模式匹配问题引入到流式计算这一重要且具有挑战性的领域。其核心贡献是识别并利用了输入流是“排列”而非任意序列这一关键特性，从而为设计更高效的算法提供了可能性，并规避了现有下限技术的限制。研究结果详细揭示了不同模式对空间复杂度的巨大影响，为理解流式排列模式匹配的本质提供了深刻见解。

<details>
  <summary>Details</summary>

**Motivation:** 排列模式匹配问题在计算机科学和统计学中广泛出现，现有研究多关注非流式设置。本文旨在研究输入序列以流形式（一次一个元素）给出时的模式匹配问题，特别是在输入为排列而非任意序列的情况下，这允许推断未来信息。

**Method:** 本文在流式设置下研究排列模式匹配。主要方法是利用输入流是一个排列（而非任意整数序列）这一特性，这使得算法能够推断未来输入信息。他们分析了不同模式$\pi$下问题的空间复杂度。

**Result:** 结果显示，问题复杂度随模式$\pi$的不同而显著变化：
*   对于单调模式（$\pi = 12\dots k$ 或 $\pi = k\dots21$），空间需求为 $\Theta(k\log{n})$。
*   对于 $\pi \in \{312,132\}$，空间需求为 $O(\sqrt{n\log{n}})$。
*   对于 $\pi \in \{231,213\}$，空间需求为 $O(\sqrt{n} \log n)$。
*   对于所有其他模式 $\pi$，空间需求为 $\widetilde{\Theta}_{\pi}(n)$。
*   如果输入$\tau$是任意整数序列（非排列），则除了单调模式外，复杂度均为 $\widetilde{\Theta}_{\pi}(n)$。

**Conclusion:** 本文揭示了在流式设置下，排列模式匹配问题的空间复杂度高度依赖于所匹配模式的类型。特别地，利用输入是排列的性质可以显著影响算法设计和复杂度分析。

> **ai_Abstract:** 本文研究了流式设置下的排列模式匹配问题，即当输入排列 $\tau$ 逐个元素给出时，判断其是否包含模式 $\pi$。与现有整数流研究不同，本工作利用输入是排列的特性，这有助于推断未来信息。研究结果表明，该问题的空间复杂度显著依赖于模式 $\pi$ 的类型，并给出了不同模式下的具体空间界限，包括单调模式的 $\Theta(k\log{n})$ 和某些短模式的 $O(\sqrt{n\log{n}})$ 或 $O(\sqrt{n} \log n)$，以及其他模式的线性复杂度。文章还对比了输入为任意序列时的复杂度。

> **摘要翻译:** 排列模式和模式避免是组合学和计算机科学中核心且研究充分的概念。给定两个排列 $\tau$ 和 $\pi$，模式匹配问题（PPM）询问 $\tau$ 是否包含 $\pi$。这个问题在计算机科学和统计学的各种背景下出现，并已在精确、参数化、近似、属性测试和其他公式中进行了广泛研究。
在本文中，我们研究了在“流式设置”下的模式匹配，即输入 $\tau$ 逐个元素地顺序揭示。关于整数流中各种统计量的空间复杂度已有大量工作。我们设置的新颖之处在于输入流是一个“排列”，这允许推断未来输入的一些信息。我们的算法关键地利用了这一事实，而现有的下限技术变得难以应用。
我们表明，问题的复杂性根据模式 $\pi$ 的不同而显著变化。空间需求为：对于单调模式 $\pi = 12\dots k$ 或 $\pi = k\dots21$，为 $\Theta(k\log{n})$；对于 $\pi \in \{312,132\}$，为 $O(\sqrt{n\log{n}})$；对于 $\pi \in \{231,213\}$，为 $O(\sqrt{n} \log n)$；对于所有其他 $\pi$，为 $\widetilde{\Theta}_{\pi}(n)$。如果 $\tau$ 是任意整数序列（不一定是排列），我们表明除了第一种（单调）情况外，所有情况的复杂度均为 $\widetilde{\Theta}_{\pi}(n)$。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [100] [Scheduling on Identical Machines with Setup Time and Unknown Execution Time](https://arxiv.org/abs/2507.11311)
> *具有设置时间和未知执行时间的相同机器调度*

*Yasushi Kawase, Kazuhisa Makino, Vinh Long Phan, Hanna Sumita* | **Category: cs.DS** | **Updated: 2025-07-15**

**Keywords:** 调度, 相同机器, 设置时间, 未知执行时间, 在线算法, 竞争比

**Comment:** Accepted to the 19th Algorithms and Data Structures Symposium (WADS
  2025)

> **TL;DR:** 本文研究了在具有初始设置时间和未知执行时间的相同机器上的调度问题，并设计了在不同场景下能达到渐近最优竞争比的在线算法。

**AI_Comments:** 该研究的创新点在于处理了调度问题中设置时间和执行时间的不确定性，并针对不同复杂的批处理和抢占情境，提出了具有严格理论性能保证（渐近最优竞争比）的在线算法。这为实际生产调度中面对类似不确定性提供了重要的理论指导和算法基础。

<details>
  <summary>Details</summary>

**Motivation:** 在相同机器调度问题中，作业需要初始设置时间且执行时间未知，这种不确定性对最小化完工时间提出了显著挑战。

**Method:** 作者考虑了两种批次分配场景：每个作业批次分配给一台机器，或一个批次可以分布在多台机器上。在这两种场景下，又分别分析了有抢占和无抢占的设置。针对这四种设置，设计了在线算法。

**Result:** 所设计的在线算法在作业数量和机器数量方面均达到了渐近最优的竞争比。

**Conclusion:** 针对具有设置时间和未知执行时间的相同机器调度问题，本文提出的在线算法在单机/多机批次分配和有/无抢占的多种设置下均能实现渐近最优的性能。

> **ai_Abstract:** 本文研究了在相同机器上进行调度的问题，其中作业需要初始设置时间且其执行时间在完成前是未知的。为应对最小化完工时间的挑战，作者考虑了批次分配到单机或多机以及有无抢占的四种不同设置。针对这些设置，文章设计了在线算法，并证明这些算法在作业数量和机器数量方面均能达到渐近最优的竞争比。

> **摘要翻译:** 本研究调查了在相同机器上的调度问题，其中作业在执行前需要初始设置。我们假设算法可以从剩余作业中动态形成批次（即，一组要一起处理的作业）。设置时间被建模为批次内作业集合的已知单调函数，而每个作业的执行时间在完成之前仍然未知。这种不确定性对最小化完工时间提出了重大挑战。我们通过考虑两种情况来应对这些挑战：每个作业批次必须分配给一台机器，或者一个批次可以分布在多台机器上。对于这两种情况，我们分析了有抢占和无抢占的设置。在这四种设置中，我们设计的在线算法在作业数量和机器数量方面均达到了渐近最优的竞争比。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [140] [Multipass Linear Sketches for Geometric LP-Type Problems](https://arxiv.org/abs/2507.11484)
> *几何LP型问题的多趟线性草图*

*N. Efe Çekirge, William Gay, David P. Woodruff* | **Category: cs.DS** | **Updated: 2025-07-15**

**Keywords:** LP型问题, 线性草图, 多趟算法, 近似算法, 空间复杂度

**Comment:** To Appear in APPROX 2025, 45 pages

> **TL;DR:** 提出了一种针对低维高精度LP型问题的多趟线性草图算法，在空间复杂度上对现有算法实现了指数级改进，并通过单趟算法的下限证明了多趟方法的必要性。

**AI_Comments:** 这篇论文的创新点在于提出了多趟线性草图算法，并证明了其在低维高精度LP型问题上的空间效率优势。通过理论分析和具体参数选择，实现了对现有算法在$1/\\varepsilon$依赖上的指数级改进，这是一个显著的突破。同时，通过下限证明进一步强化了其多趟方法的合理性，对大数据背景下的几何优化问题处理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** LP型问题（如MEB、SVM、LP、SDP）是基础的组合优化问题，在机器学习中有广泛应用。在大数据流式和分布式模型中解决这些问题，尤其是在高精度低维度条件下，是一个挑战。此外，单趟算法存在固有的空间下限，促使研究多趟方法。

**Method:** 本文研究了在流式和分布式大数据模型中的LP型问题，并提出了一种$O(ds)$趟的$\\varepsilon$-近似线性草图算法。该算法专注于低维度$d$和高精度$\\varepsilon$（即$d < (1/\\varepsilon)^{0.999}$）情况，其空间复杂度为$O(s( \\sqrt{d}/\\varepsilon)^{3d/s}) \\cdot \\mathrm{poly}(d, \\log (1/\\varepsilon))$。

**Result:** 1. 开发了一种$O(ds)$趟算法，用于解决$O(d)$组合和VC维度的$\\varepsilon$-近似LP型问题。2. 通过设置参数$s = d \\log (1/\\varepsilon)$，实现了空间复杂度在$d$上是多项式、在$1/\\varepsilon$上是多对数，相比现有算法在$1/\\varepsilon$上实现了指数级改进。3. 证明了任何解决$(1 + \\varepsilon)$-近似MEB和线性SVM问题的单趟算法存在$(1/\\varepsilon)^{\\Omega(d)}$的空间下限。

**Conclusion:** 本文提出的多趟线性草图算法在处理低维高精度LP型问题时，能够显著降低空间复杂度，尤其是在对$1/\\varepsilon$的依赖上实现了指数级优化。同时，通过理论下限证明了多趟方法的必要性和优越性。

> **ai_Abstract:** 本文研究了在大数据流式和分布式模型中解决LP型问题（如MEB、SVM）的挑战，特别关注低维度高精度场景。作者提出了一种创新的多趟线性草图算法，该算法在处理$\\varepsilon$-近似LP型问题时，通过优化参数设置，实现了在$1/\\varepsilon$上指数级优于现有算法的空间复杂度。此外，论文通过证明单趟算法的固有空间下限，有力地论证了其多趟方法的必要性和优越性。

> **摘要翻译:** LP型问题，如最小包围球（MEB）、线性支持向量机（SVM）、线性规划（LP）和半定规划（SDP），是基础的组合优化问题，在分类、生物信息学和噪声学习等机器学习应用中具有许多重要应用。我们研究了在几种流式和分布式大数据模型中的LP型问题，给出了$\\varepsilon$-近似线性草图算法，重点关注低维度$d$下的高精度范围，即当${d < (1/\\varepsilon)^{0.999}}$时。我们的主要结果是针对$O(d)$组合维和VC维的$\\varepsilon$-近似LP型问题，提出了一种$O(ds)$趟算法，其空间复杂度为$O(s( \\sqrt{d}/\\varepsilon)^{3d/s}) \\cdot \\mathrm{poly}(d, \\log (1/\\varepsilon))$字，适用于任何参数$s \\in [1, d \\log (1/\\varepsilon)]$。值得注意的是，通过取$s = d \\log (1/\\varepsilon)$，我们实现了在$d$上是多项式、在$1/\\varepsilon$上是多对数的空间复杂度，与现有算法相比，在$1/\\varepsilon$上呈现指数级改进。我们通过展示解决$(1 + \\varepsilon)$-近似MEB和线性SVM问题的任何单趟算法存在$(1/\\varepsilon)^{\\Omega(d)}$的下限来补充我们的结果，这进一步激发了我们的多趟方法。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [251] [Distributed Treewidth Computation and Courcelle's Theorem in the CONGEST Model](https://arxiv.org/abs/1805.10708)
> *分布式树宽计算和CONGEST模型下的Courcelle定理*

*Benjamin Jauregui, Jason Li, Pedro Montealegre, Ioan Todinca* | **Category: cs.DS** | **Updated: 2025-07-14**

**Keywords:** 分布式算法, 树宽, Courcelle定理, CONGEST模型, MSO逻辑

**Comment:** 

> **TL;DR:** 本文在CONGEST模型中提出了Courcelle定理的分布式版本，用于在有界树宽图上高效判定MSO属性，并将其扩展到优化和计数问题。同时，还提供了一个分布式树宽近似算法。

**AI_Comments:** 本文通过将Courcelle定理引入分布式CONGEST模型，在分布式图算法领域取得了重要进展。这一贡献为在分布式环境中处理有界树宽图上的广泛问题提供了理论基础。提出的分布式树宽近似算法和高效的分离器计算方法是关键的技术创新。尽管运行时间对直径$D$的依赖是不可避免的，但整体而言，这项工作显著提升了我们设计和分析分布式算法的能力。

<details>
  <summary>Details</summary>

**Motivation:** 在顺序图算法中，算法元定理（如Courcelle定理）已是标准，但缺乏在分布式计算模型（特别是CONGEST模型）中的对应版本。本文旨在弥补这一空白，为有界树宽图上的MSO可表达属性提供高效的分布式判定算法，并提供分布式树宽近似算法。

**Method:** 本文提出了一种CONGEST算法，用于在树宽至多为$k$且直径为$D$的输入网络中，以$	ilde O(D)$轮判定MSO公式$	ext{φ}$是否满足。该方法扩展到优化和计数问题。此外，还提出了一个分布式算法，用于在$	ilde O(k^{O(k)} D)$轮内对树宽进行线性近似（计算宽度为$O(k)$、深度为$O(	ext{log} n)$的树分解）。算法利用了低拥塞快捷方式框架，主要技术工具是计算树宽至多为$k$的图中大小至多为$k+1$的$(s,t)$-顶点分离器的$	ilde O(k^4 D)$算法。

**Result:** 1. 在CONGEST模型中，对于树宽至多为$k$、直径为$D$的图，存在一个算法可以在$	ilde O(D)$轮内判定任何MSO属性。2. 该结果可扩展到优化问题（如最大独立集、最小支配集）和计数问题（如三角形计数）。3. 提出了一个分布式算法，可以在$	ilde O(k^{O(k)} D)$轮内对树宽进行线性近似，或判定树宽是否大于$k$。4. 提出了一个在树宽至多为$k$的图中计算大小至多为$k+1$的$(s,t)$-顶点分离器的$	ilde O(k^4 D)$算法。

**Conclusion:** 本文成功地将经典的Courcelle定理推广到CONGEST分布式模型中，表明在有界树宽图上可以高效地判定MSO可表达的属性。同时，还提供了一个实用的分布式树宽近似算法。这些成果为在结构化图上设计高效的分布式算法奠定了基础，并引入了新的技术工具。

> **ai_Abstract:** 本文将Courcelle定理扩展到分布式CONGEST模型，证明了在有界树宽图中，一阶二阶逻辑（MSO）属性可以在$	ilde O(D)$轮内高效判定，且该结果适用于优化和计数问题。此外，论文还提出了一个分布式算法，以线性因子近似图的树宽，该算法在$	ilde O(k^{O(k)} D)$轮内运行。这些算法利用了低拥塞快捷方式框架和一个新的高效顶点分离器计算算法。

> **摘要翻译:** 算法元定理，即说明在某些特定逻辑中可表达的图属性可以在具有特定结构属性的图类中有效判定的定理，在顺序图算法中已是标准。其中最经典的例子之一是Courcelle定理：所有在一阶二阶逻辑（MSO）中可表达的属性都可以在有界树宽的图中以线性时间判定。
我们在此提供了Courcelle定理的分布式版本，在标准的CONGEST分布式计算模型中：对于任何MSO公式$\varphi$和任何常数$k$，存在一个CONGEST算法，给定一个树宽至多为$k$且直径为$D$的输入通信网络$G$，可以在$\tilde O(D)$轮内判定$G$是否满足属性$\varphi$。简单的例子表明对$D$的依赖是不可避免的。此外，如果我们放弃有界树宽的假设，已知在CONGEST模型中判定如3-着色性等MSO属性需要$\tilde{\Omega}(n^2)$轮。我们的结果扩展到优化问题（例如，计算最大独立集或最小支配集）和计数问题（例如，三角形计数）。通常，$\tilde{O}$表示法隐藏了$n$的多对数因子；这里它还隐藏了一个取决于$k$和MSO公式$\varphi$的常数因子。
我们还给出了一个产生树宽线性近似的分布式算法：对于任何$k$，该算法可以在CONGEST模型中以$\tilde O(k^{O(k)} D)$轮内判定输入网络$G$的树宽是否大于$k$，或者计算出宽度为$O(k)$且深度为$O(\log n)$的树分解。
我们的算法利用了Ghaffari和Haeupler [SODA 2016]引入的低拥塞快捷方式框架，我们主要的技​​术工具是一个在树宽至多为$k$的图中计算大小至多为$k+1$的$(s,t)$-顶点分离器的$\tilde O(k^4 D)$算法。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [290] [Minimum-Peak-Cost Flows Over Time](https://arxiv.org/abs/2507.09688)
> *最小峰值成本随时间流*

*Mariia Anapolska, Emma Ahrens, Christina Büsing, Felix Engelhardt, Timo Gersing, Corinna Mathwieser, Sabrian Schmitz, Sophia Wrede* | **Category: cs.DS** | **Updated: 2025-07-15**

**Keywords:** 最小峰值成本, 随时间流, 时间重复流, NP-难, 网络流

**Comment:** 

> **TL;DR:** 本文提出了最小峰值成本随时间流问题，特别关注时间重复流（MPC-TRF），旨在最小化资源使用的峰值成本。研究表明该问题在一般情况下是NP-难的，但识别并提供了两种特殊情况下的多项式时间算法。

**AI_Comments:** 本文解决了资源分配中一个实际且重要的问题：如何最小化峰值成本而非总成本。其创新在于提出了新的流问题模型（MPC-TRF），并对其计算复杂性进行了深入分析。尽管问题在一般情况下是NP-难的，但论文识别并提供了在特定良性情况下的高效算法，这对于实际应用具有重要价值。对时间重复流简单结构与近似比之间权衡的揭示也很有见地。

<details>
  <summary>Details</summary>

**Motivation:** 在规划需要非消耗性资源（如卡车）的运输时，资源分配的峰值需求通常比资源使用总时长更受关注。例如，用一辆卡车运送包裹八小时比用两辆卡车运送四小时更具成本效益，只要时间允许。传统流问题侧重于最小化成本积分，而本文旨在解决最小化任意时间点最大成本的问题。

**Method:** 本文提出了新颖的“最小峰值成本随时间流问题”，其目标是最小化所有时间点的最大成本，而非成本积分。研究重点是“最小峰值成本时间重复流问题（MPC-TRF）”，因其结构简单，适用于实际应用。

**Result:** 研究表明，与一般随时间流相比，时间重复流的简单结构会导致任意差的近似比。此外，复杂度分析表明，MPC-TRF的整数版本即使在强限制下也是强NP-难的。积极的一面是，本文识别了两种良性特殊情况：单位成本串并联网络，以及时间范围至少是网络中最长路径（关于传输时间）两倍的网络。在这两种情况下，当所需流量值等于最大流量值时，可以找到最优整数流；对于任意流量值，可以找到最优分数流，且都能在多项式时间内找到。对每种情况，本文都提供了构建最优解的显式算法。

**Conclusion:** 本文引入了一个新的、与实际应用相关的流问题，明确了其计算复杂性，并指出了在特定实际场景下可以高效找到最优解的情况。

> **ai_Abstract:** 本文提出了新颖的“最小峰值成本随时间流问题”，特别关注“最小峰值成本时间重复流（MPC-TRF）”，旨在解决非消耗性资源分配中最小化峰值成本而非总成本的问题。研究表明，尽管MPC-TRF结构简单，其整数版本是强NP-难的，且相比一般流可能导致较差的近似。然而，论文成功识别并提供了两种特殊情况（单位成本串并联网络和时间范围充足的网络）下的多项式时间算法，用于寻找最优的整数流和分数流。

> **摘要翻译:** 当规划操作需要非消耗性资源的运输时，所分配资源的峰值需求往往比资源使用持续时间更受关注。例如，只要时间充足，用一辆卡车在八小时内运送包裹比用两辆卡车运送四小时更具成本效益。为了对此类场景进行建模，我们引入了新颖的最小峰值成本随时间流问题，其目标是最小化所有时间点的最大成本，而不是最小化成本积分。我们重点关注最小化时间重复流的峰值成本。由于其简单的结构，这些流在实际应用中是理想的。这产生了最小峰值成本时间重复流问题（MPC-TRF）。
我们表明，与一般随时间流相比，时间重复流的简单结构带来了任意差的近似比的缺点。此外，我们的复杂度分析表明，MPC-TRF的整数版本即使在强限制下也是强NP-难的。积极的一面是，我们识别了两个良性特殊情况：单位成本串并联网络，以及时间范围至少是网络中最长路径（关于传输时间）两倍的网络。在这两种情况下，我们表明，当所需流量值等于最大流量值时，可以找到最优整数流；对于任意流量值，可以找到最优分数流，且都能在多项式时间内找到。对于每种情况，我们都提供了构建最优解的显式算法。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [395] [A Fast Coloring Oracle for Average Case Hypergraphs](https://arxiv.org/abs/2507.10691)
> *超图平均情况下的快速着色预言机*

*Cassandra Marcussen, Edward Pyne, Ronitt Rubinfeld, Asaf Shapira, Shlomo Tauber* | **Category: cs.DS, cs.CC, math.CO** | **Updated: 2025-07-14**

**Keywords:** 超图着色, 2-着色性, 着色预言机, 平均情况分析, NP-难问题

**Comment:** 18 pages, 2 figures

> **TL;DR:** 本文提出了一个简单且快速的算法，用于在平均情况下对超图进行2着色，并引入了一个在平均情况下实现O(1)查询时间的着色预言机。

**AI_Comments:** 这篇论文的创新点在于它提供了一种更简单、更高效的方法来解决平均情况下的超图2着色问题，避免了复杂且效率低下的正则性引理。特别是O(1)平均查询时间的着色预言机的提出，为理解和处理这类问题提供了全新的视角，显著提升了理论上的效率。

<details>
  <summary>Details</summary>

**Motivation:** 解决超图2可着色性这一经典的NP难问题，并改进现有算法因严重依赖正则性引理而导致的分析复杂性和高运行时间，旨在找到更简单、更高效的平均情况下的着色方法。

**Method:** 首先，设计了一个新的简单且基本的确定性2着色算法，该算法避免使用正则性引理，并能重现现有定理。其次，将该新算法转化为一个随机算法，其平均预期运行时间为O(n)。最后，定义了一个“着色预言机”，该算法旨在以最少的边检查量为顶点分配颜色，并证明其在平均情况下的高效性。

**Result:** 本文的第一个结果是提出了一个无需正则性引理的简单确定性2着色算法，该算法能够重现先前复杂算法的定理。该算法可以转化为一个随机算法，其平均预期运行时间为O(n)。第二个也是主要结果是证明存在一个着色预言机，它在平均情况下能够以O(1)的时间回答每个顶点查询，这表明在平均情况下找到2可着色超图的2着色非常容易。

**Conclusion:** 本文通过提出新的简单算法和O(1)平均查询时间的着色预言机，证明了在平均情况下，对2可着色超图进行着色比之前认为的要容易得多，显著简化了着色过程。

> **ai_Abstract:** 本文针对超图2可着色性问题，提出了一个不依赖复杂正则性引理的简单确定性2着色算法，并将其优化为平均预期运行时间为O(n)的随机算法。更重要的是，研究引入并证明了一个着色预言机，该预言机在平均情况下能以O(1)的恒定时间响应每个顶点着色查询，极大地简化了平均2可着色超图的着色过程。

> **摘要翻译:** 超图2可着色性是经典的NP难问题之一。Person和Schacht [SODA'09] 设计了一种确定性算法，其在均匀选择的2可着色3均匀超图上的预期运行时间是多项式的。Lee、Molla和Nagle最近将其扩展到所有k≥3的k均匀超图。这两篇论文都严重依赖正则性引理，因此它们的分析很复杂，并且运行时间隐藏了塔型常数。
本文的第一个结果是一个新的简单且基本的确定性2着色算法，它在避免使用正则性引理的情况下重新证明了Person-Schacht和Lee-Molla-Nagle的定理。我们还展示了如何将我们的新算法转化为一个随机算法，其平均预期运行时间仅为O(n)。
我们的第二个也是主要结果提供了我们认为是找到平均2可着色超图的2着色有多么容易的终极证据。我们定义一个着色预言机为一种算法，它在给定顶点v时，通过检查尽可能少的边来为v分配红色/蓝色，以便对预言机的任何查询序列都与输入的单个合法2着色一致。令人惊讶的是，我们证明存在一个着色预言机，它平均可以以O(1)时间回答每个顶点查询。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [433] [Solving Random Planted CSPs below the $n^{k/2}$ Threshold](https://arxiv.org/abs/2507.10833)
> *求解低于 $n^{k/2}$ 阈值的随机植入CSP*

*Arpon Basu, Jun-Ting Hsieh, Andrew D. Lin, Peter Manohar* | **Category: cs.DS** | **Updated: 2025-07-14**

**Keywords:** 随机植入CSP, Sum-of-Squares SDP, 布尔约束满足问题, 算法族, 舍入过程

**Comment:** 

> **TL;DR:** 提出一种新的算法族，用于在低于 $n^{k/2}$ 约束阈值下求解随机植入的k元布尔CSP，通过两步法结合高阶Sum-of-Squares SDP和舍入过程来恢复解。

**AI_Comments:** 这项工作在解决随机植入CSP方面具有重要意义，尤其是在低于传统阈值的情况下。其创新之处在于提出了一种与现有方法（如 [GHKM23]）截然不同的两步恢复策略，即放弃唯一性证书，转而通过高阶Sum-of-Squares SDP结合舍入来逼近并恢复解。这使得算法能够推广现有成果并匹配更广泛的运行时-约束权衡，为理解和解决此类NP-hard问题提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 旨在推广现有算法（[FPV15]）以处理更大的运行时，并匹配随机CSP驳斥的约束数量与运行时权衡（[RRS17]）。同时，提出一种与近期工作（[GHKM23]）概念上不同的方法，以在更宽松的条件下解决问题。

**Method:** 提出一个算法族，运行时间为 $n^{O(\ell)}$。该算法通过两步恢复植入的赋值 $x^*$：首先使用一个度为 $O(\ell)$ 的Sum-of-Squares SDP来找到一个与 $x^*$ $o(1)$-接近的 $\hat{x}$，然后使用第二个舍入过程从 $\hat{x}$ 中恢复 $x^*$。

**Result:** 该算法在 $m \geq O(n) \cdot (n/\ell)^{\frac{k}{2} - 1} \log n$ 的约束数下，能够成功输出一个满足赋值。它推广了 [FPV15] 的多项式时间算法，并匹配了 [RRS17] 为驳斥随机CSP建立的约束数与运行时权衡。

**Conclusion:** 本文提出了一系列新的算法，用于在特定约束条件下求解随机植入的k元布尔CSP，通过一种新颖的两步方法克服了现有方法的局限性，并在性能上达到了新的里程碑。

> **ai_Abstract:** 本文提出了一族新颖的算法，用于解决随机植入的k元布尔约束满足问题（CSP），其运行时间为 $n^{O(\ell)}$，并在约束数 $m$ 达到特定阈值时能成功找到满足赋值。该方法推广了现有算法，并在约束与运行时权衡方面达到了新的匹配。与现有依赖精确SDP恢复的方法不同，本算法采用两步策略：先利用高阶Sum-of-Squares SDP找到近似解，再通过舍入过程恢复精确的植入赋值。

> **摘要翻译:** 我们提出了一系列算法来解决任何k元布尔约束满足问题（CSP）的随机植入实例。一个k元布尔CSP的随机植入实例是通过（1）选择一个任意的植入赋值 $x^*$，然后（2）从一个特定的“植入分布”中采样约束来生成的，该分布旨在使 $x^*$ 满足每个约束。给定一个具有 $m$ 个约束的 $n$ 变量的k元布尔CSP实例，我们的算法在参数 $\ell$ 的选择下以 $n^{O(\ell)}$ 的时间运行，并且如果 $m \geq O(n) \cdot (n/\ell)^{\frac{k}{2} - 1} \log n$，则成功输出一个满足赋值。这推广了 [FPV15] 的多项式时间算法，即 $\ell = O(1)$ 的情况，使其适用于更大的运行时，并与 [RRS17] 为驳斥随机CSP建立的约束数量与运行时权衡相匹配。
我们的算法在概念上不同于 [GHKM23] 最近的算法，后者通过利用允许基本SDP精确恢复植入赋值 $x^*$ 的条件，给出了一个多项式时间算法来解决 $m \geq \tilde{O}(n^{\frac{k}{2}})$ 约束的半随机CSP。相反，我们放弃了唯一性证书，并通过两步恢复 $x^*$：我们首先使用一个度为 $O(\ell)$ 的Sum-of-Squares SDP来找到一个与 $x^*$ $o(1)$-接近的 $\hat{x}$，然后我们使用第二个舍入过程从 $\hat{x}$ 中恢复 $x^*$。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [467] [Solving Linear Programs with Differential Privacy](https://arxiv.org/abs/2507.10946)
> *求解具有差分隐私的线性规划*

*Alina Ene, Huy Le Nguyen, Ta Duy Nguyen, Adrian Vladu* | **Category: cs.DS** | **Updated: 2025-07-15**

**Keywords:** 线性规划, 差分隐私, 感知器, 约束满足, 优化

**Comment:** 

> **TL;DR:** 该论文提出了新的差分隐私算法，用于求解线性规划，与现有工作相比，显著减少了违反约束的数量。

**AI_Comments:** 该论文的创新之处在于显著改善了差分隐私线性规划中违反约束的界限，特别是对于一般线性规划实现了$d^5$倍的改进。这项工作对于开发更准确、更实用的隐私保护优化方法具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究在差分隐私下求解线性规划的问题，旨在改进现有算法中违反约束的数量界限。

**Method:** 该方法基于对[Hoberg-Rothvoss, IPCO '17]的重标度感知器算法和[Kaplan et al.]更精细的识别等式约束的迭代过程进行隐私化处理。

**Result:** 对于齐次线性规划，该算法在多项式时间内找到一个解，其违反的约束数量从$O(\frac{d^{5}}{\epsilon}\log^{1.5}\frac{1}{\rho_{0}}\mathrm{poly}\log(d,\frac{1}{\delta},\frac{1}{\beta}))$改进到$O(\frac{d^{2}}{\epsilon}\log^{2}\frac{d}{\delta\beta}\sqrt{\log\frac{1}{\rho_{0}}})$。对于一般线性规划，该算法以高概率违反$O(\frac{d^{4}}{\epsilon}\log^{2.5}\frac{d}{\delta}\sqrt{\log dU})$个约束，比Kaplan等人的结果至少提高了$d^5$倍。

**Conclusion:** 该论文为求解线性规划提供了显著改进的差分隐私算法，与现有最先进的方法相比，减少了违反约束的数量。

> **ai_Abstract:** 该论文引入了新颖的$(\epsilon,\delta)$-差分隐私算法，用于求解线性规划。对于齐次线性规划，算法能在多项式时间内找到一个解，显著改善了有裕度问题的违反约束数量上限。对于一般线性规划，算法也提供了一种高效的方法，与现有工作相比，大幅减少了违反约束的数量，其技术基础是对现有感知器和迭代约束识别程序的隐私化。

> **摘要翻译:** 我们研究了在差分隐私下求解$Ax\le b$, $x\ge0$形式的线性规划问题。对于齐次线性规划$Ax\ge0$，我们提出了一种高效的$(\epsilon,\delta)$-差分隐私算法，该算法以至少$1-\beta$的概率在多项式时间内找到一个解，对于具有裕度$\rho_{0}>0$的问题，该解满足除了$O(\frac{d^{2}}{\epsilon}\log^{2}\frac{d}{\delta\beta}\sqrt{\log\frac{1}{\rho_{0}}})$个约束之外的所有约束。这改进了[Kaplan-Mansour-Moran-Stemmer-Tur, STOC '25]的$O(\frac{d^{5}}{\epsilon}\log^{1.5}\frac{1}{\rho_{0}}\mathrm{poly}\log(d,\frac{1}{\delta},\frac{1}{\beta}))$的界限。对于具有可能零裕度的一般线性规划$Ax\le b$, $x\ge0$，我们提出了一种高效的$(\epsilon,\delta)$-差分隐私算法，该算法以高概率违反$O(\frac{d^{4}}{\epsilon}\log^{2.5}\frac{d}{\delta}\sqrt{\log dU})$个约束，其中$U$是$A$和$b$中条目绝对值的上限。这比Kaplan等人的结果至少提高了$d^5$倍。我们的技术建立在对[Hoberg-Rothvoss, IPCO '17]的重标度感知器算法和Kaplan等人更精细的识别等式约束的迭代过程进行隐私化处理的基础上。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [510] [FPT Parameterisations of Fractional and Generalised Hypertree Width](https://arxiv.org/abs/2507.11080)
> *分数超树宽和广义超树宽的FPT参数化*

*Matthias Lanzinger, Igor Razgon, Daniel Unterberger* | **Category: cs.DS, cs.CC** | **Updated: 2025-07-15**

**Keywords:** 固定参数可处理, 超图分解, 超树宽, MSO变换, 算法

**Comment:** 

> **TL;DR:** 本文首次提出了用于精确确定广义超树宽、分数超树宽和自适应宽等几个核心超图分解参数的固定参数可处理（FPT）算法，该方法扩展了利用单体二阶（MSO）变换的树宽算法。

**AI_Comments:** 这篇论文通过为关键的超图分解参数提供首个精确FPT算法，做出了重大贡献。其创新之处在于成功地将通常用于图的MSO变换框架，扩展并应用于更复杂的超图领域。这一进展可能对理论计算机科学以及数据库和约束满足的实际应用产生广泛影响。

<details>
  <summary>Details</summary>

**Motivation:** 尽管超图分解参数（广义超树宽、分数超树宽、自适应宽）在计算复杂性理论、数据库和约束满足领域中具有公认的重要性，但此前没有任何针对它们的精确FPT算法。

**Method:** 作者扩展了最近一个利用单体二阶（MSO）变换的树宽算法（Bojańcyk & Pilipczuk, LMCS 2022），并利用该框架克服了超图带来的技术障碍。这些结果适用于有界秩和有界度的超图类别。

**Result:** 本文提出了第一个固定参数可处理（FPT）算法，用于精确确定广义超树宽、分数超树宽和自适应宽等几个核心超图分解参数。

**Conclusion:** 本文成功开发了重要超图分解参数的首个精确FPT算法，通过将基于MSO变换的方法应用于超图，解决了该领域长期存在的空白。

> **ai_Abstract:** 本文首次提出了用于精确计算广义超树宽、分数超树宽和自适应宽等关键超图分解参数的固定参数可处理（FPT）算法。尽管这些参数在计算复杂性理论、数据库和约束满足中具有重要意义，但此前缺乏精确的FPT算法。研究方法是扩展了一个利用单体二阶（MSO）变换的近期树宽算法，并将其应用于具有有界秩和度的超图类别，以处理超图更复杂的结构分解。

> **摘要翻译:** 我们提出了第一个固定参数可处理（fpt）算法，用于精确确定几个核心超图分解参数，包括广义超树宽、分数超树宽和自适应宽。尽管这些度量在计算复杂性理论、数据库和约束满足领域中具有公认的重要性，但此前没有任何针对它们的精确fpt算法。我们的结果适用于有界秩和有界度的超图类别。我们的方法扩展了最近一个利用单体二阶（MSO）变换的树宽算法（Bojańcyk & Pilipczuk, LMCS 2022）。利用这个框架，我们克服了超图带来的重大技术障碍，超图的结构分解在技术上比图的分解复杂得多。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [559] [Faster algorithms for k-Orthogonal Vectors in low dimension](https://arxiv.org/abs/2507.11098)
> *低维k正交向量的更快算法*

*Anita Dürr, Evangelos Kipouridis, Karol Węgrzycki* | **Category: cs.DS** | **Updated: 2025-07-15**

**Keywords:** 正交向量, k-正交向量, 组合算法, 时间复杂度, 集合覆盖猜想

**Comment:** 

> **TL;DR:** 本文提出了用于正交向量（OV）和k-正交向量问题的新型更快算法，显著改善了现有时间复杂度，并给出了k-OV问题的条件性下界。

**AI_Comments:** 本文通过提出创新的组合算法，显著提升了正交向量（OV）及其k-泛化问题的求解效率，突破了现有算法的性能瓶颈。其创新之处在于将随机算法的时间复杂度从$\tilde{\mathcal{O}}(1.35^d n)$优化至$\tilde{\mathcal{O}}(1.25^d n)$，并通过计算机辅助评估进一步提升至$\mathcal{O}(1.16^d \cdot n)$。此外，文章不仅给出了算法上的改进，还通过与集合覆盖猜想的关联，为k-正交向量问题建立了渐近意义上的条件性下界，这在理论上具有重要意义，指明了未来算法优化的潜在极限。这表明了作者在理论和实践优化上的双重贡献。

<details>
  <summary>Details</summary>

**Motivation:** 正交向量（OV）问题及其变体的现有算法时间复杂度较高，且在强指数时间假设（SETH）下存在理论限制。为了突破现有算法的性能瓶颈，如Williams（FOCS 2024）提出的算法，本文旨在开发更快的算法。

**Method:** 本文提出了一种组合算法，将正交向量问题（OV）的随机时间复杂度改进到$\tilde{\mathcal{O}}(1.25^d n)$。通过计算机辅助评估，这一结果可以进一步提升至$\mathcal{O}(1.16^d \cdot n)$。此外，本文将结果推广到k-正交向量问题，证明对于每个固定的$k \ge 2$，存在$\varepsilon_k > 0$使得k-OV问题可以在$\mathcal{O}(2^{(1 - \varepsilon_k)\cdot d}\cdot n)$时间内解决。

**Result:** 对于正交向量（OV）问题，本文将随机时间复杂度从先前的$\tilde{\mathcal{O}}(1.35^d n)$改进到$\tilde{\mathcal{O}}(1.25^d n)$，通过计算机辅助评估可达$\mathcal{O}(1.16^d \cdot n)$。对于k-正交向量问题，本文证明对于每个固定的$k \ge 2$，存在$\varepsilon_k > 0$使得该问题可以在$\mathcal{O}(2^{(1 - \varepsilon_k)\cdot d}\cdot n)$时间内解决。此外，本文还证明了对于任何$\varepsilon > 0$，存在$k \ge 2$使得$2^{(1 - \varepsilon)\cdot d} \cdot n^{\mathcal{O}(1)}$时间的k-正交向量算法将与集合覆盖猜想相矛盾，这表明该结果在渐近意义上是最佳的。

**Conclusion:** 本文为低维正交向量和k-正交向量问题提供了显著更快的算法，并建立了k-正交向量问题的渐近最佳条件性下界。

> **ai_Abstract:** 本文针对低维正交向量（OV）问题及其k-泛化问题，提出了更快的组合算法。对于OV问题，算法的随机时间复杂度从先前的$\tilde{\mathcal{O}}(1.35^d n)$改进到$\tilde{\mathcal{O}}(1.25^d n)$，通过计算机辅助评估可达$\mathcal{O}(1.16^d \cdot n)$。对于k-正交向量问题，本文证明了对于每个固定的$k \ge 2$，存在$\varepsilon_k > 0$使得该问题可以在$\mathcal{O}(2^{(1 - \varepsilon_k)\cdot d}\cdot n)$时间内解决。此外，本文还提供了k-正交向量问题的条件性下界，表明在渐近意义上，这些改进是接近最优的。

> **摘要翻译:** 在正交向量（OV）问题中，我们给定两个集合族 $A, B$，它们是集合族 ${1,\ldots,d}$ 的子集，每个集合族的大小为 $n$。任务是判断是否存在一对 $a \in A$ 和 $b \in B$ 使得 $a \cap b = \emptyset$。解决这个问题的直接算法运行时间为 $\mathcal{O}(n^2 \cdot d)$ 或 $\mathcal{O}(2^d \cdot n)$。假设强指数时间假设（SETH）成立，则不存在任何常数 $\varepsilon > 0$ 使得该问题可以在 $2^{o(d)}\cdot n^{2-\varepsilon}$ 时间内解决。
Williams (FOCS 2024) 基于不相交矩阵的简洁等秩分解，提出了一个运行时间为 $\tilde{\mathcal{O}}(1.35^d \cdot n)$ 的算法。在本文中，我们提出了一个组合算法，其随机运行时间为 $\tilde{\mathcal{O}}(1.25^d n)$。使用计算机辅助评估，这可以改进到 $\mathcal{O}(1.16^d \cdot n)$。
我们将结果推广到k-正交向量问题，其中给定 $k$ 个集合族 $A_1,\ldots,A_k$，它们是集合族 ${1,\ldots,d}$ 的子集，每个集合族的大小为 $n$。任务是找到对于每个 $i \in {1,\ldots,k}$ 的元素 $a_i \in A_i$，使得 $a_1 \cap a_2 \cap \ldots \cap a_k = \emptyset$。我们证明对于每个固定的 $k \ge 2$，存在 $\varepsilon_k > 0$ 使得 k-OV 问题可以在 $\mathcal{O}(2^{(1 - \varepsilon_k)\cdot d}\cdot n)$ 时间内解决。我们还表明，渐近地，这是我们所能期望的最佳结果：对于任何 $\varepsilon > 0$，存在一个 $k \ge 2$ 使得 $2^{(1 - \varepsilon)\cdot d} \cdot n^{\mathcal{O}(1)}$ 时间的 k-正交向量算法将与集合覆盖猜想相矛盾。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [608] [Efficient Branch-and-Bound for Submodular Function Maximization under Knapsack Constraint](https://arxiv.org/abs/2507.11107)
> *高效的分支定界算法用于背包约束下的次模函数最大化*

*Yimin Hao, Yi Zhou, Chao Xu, Zhang-Hua Fu* | **Category: cs.DS** | **Updated: 2025-07-15**

**Keywords:** 次模函数最大化, 分支定界, 背包约束, 精确算法, 离散优化

**Comment:** Accepted to ECAI 2025

> **TL;DR:** 提出一种新的高效分支定界算法，用于解决背包约束下次模函数最大化问题，在需要最优解的领域表现优于传统方法。

**AI_Comments:** 该论文的创新点在于提出了一个改进的分支定界算法，特别是在上界设计和分支策略上进行了优化，从而在需要精确最优解的次模背包问题上实现了更高的效率。这对于医疗保健和风险管理等对精确性要求高的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的次模背包问题（SKP）解决方案大多是近似算法，但在医疗保健设施选址和风险管理等领域，对最优解的需求至关重要，因此需要精确算法。

**Method:** 提出一种最优分支定界方法，其特点是：1) 具有最坏情况紧密性保证的新型上界；2) 高效的双重分支方法以最小化重复计算。

**Result:** 在设施选址、加权覆盖和影响力最大化等应用中的实验表明，实现新思想的算法比传统方法效率高得多。

**Conclusion:** 该论文提出的分支定界算法在解决次模背包问题时，能够提供最优解，并且在实际应用中表现出显著的效率提升。

> **ai_Abstract:** 本文针对次模背包问题（SKP）提出了一个高效的分支定界算法，以解决现有近似算法无法提供最优解的问题。该算法引入了具有紧密性保证的新型上界和高效的双重分支方法，旨在减少计算量。实验结果显示，该方法在多个实际应用中显著优于传统算法，满足了对精确最优解的需求。

> **摘要翻译:** 次模背包问题（SKP）旨在通过在给定预算内选择元素子集来最大化次模集函数，是一个重要的离散优化问题。解决SKP的现有方法大多数是近似算法。然而，在医疗保健设施选址和风险管理等领域，对最优解的需求仍然至关重要，因此需要使用精确算法而非近似方法。在本文中，我们提出了一种最优分支定界方法，其特点是具有最坏情况紧密性保证的新型上界和用于最小化重复计算的高效双重分支方法。在设施选址、加权覆盖、影响力最大化等应用中的实验表明，实现新思想的算法比传统方法效率高得多。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [658] [Finding Order-Preserving Subgraphs](https://arxiv.org/abs/2507.11115)
> *寻找保序子图*

*Haruya Imamura, Yasuaki Kobayashi, Yota Otachi, Toshiki Saitoh, Keita Sato, Asahi Takaoka, Ryo Yoshinaka* | **Category: cs.DS** | **Updated: 2025-07-15**

**Keywords:** 有序子图同构, 最大公共有序子图, NP完全性, 计算复杂度, 顶点排序

**Comment:** 

> **TL;DR:** 研究了图论中带顶点顺序的子图同构和最大公共子图问题，证明了其在特定图类上的NP完全性，并揭示了计算复杂度的差异及可处理性与顶点排序的相关性。

**AI_Comments:** 本文深入分析了带序图的子图同构问题，这是一个在生物信息学和时间序列分析等领域具有实际应用价值的方向。其创新点在于引入并系统研究了顶点顺序对图同构和公共子图问题复杂度的影响，并通过具体的NP完全性证明和多项式时间可解性的发现，揭示了这些问题在不同图类和特定排序条件下的细微差异。这对于理解和设计高效的图算法具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在时间序列数据或蛋白质结构等衍生的图中，顶点通常具有固有的总排序。这促使研究尊重这种内在排序的子图同构和最大公共子图问题变体。

**Method:** 本文研究了有序（导出）子图同构（O(I)SI）及其推广形式——最大公共有序（导出）子图（MCO(I)S）问题。这些问题旨在寻找保留给定有序图顶点顺序的子图同构。研究方法包括理论证明其计算复杂性，并在不同图类上进行比较分析。

**Result:** 主要贡献有三点：1) 证明了这些问题即使在小图类（如深度为2的树和阈值图）上仍然是NP完全的。2) 建立了OSI和OISI在某些图类（如区间图）上计算复杂度的差异。3) 证明了这些问题的可处理性可能取决于顶点排序，例如，在提供特定顶点排序的情况下，MCOIS在阈值图上可以多项式时间求解。

**Conclusion:** 本文通过对有序子图同构和最大公共有序子图问题的复杂性分析，揭示了顶点排序在图模式匹配和相似性计算中的关键作用，并指出了其在不同图类和特定排序条件下的可处理性差异。

> **ai_Abstract:** 本文研究了在具有内在顶点排序的图（如时间序列或蛋白质结构图）中，有序（导出）子图同构（O(I)SI）和最大公共有序（导出）子图（MCO(I)S）的计算复杂性。研究证明，即使在深度为2的树和阈值图等小图类上，这些问题仍是NP完全的。同时，论文揭示了OSI和OISI在某些图类（如区间图）上的复杂度差异，并指出问题的可处理性高度依赖于顶点排序，例如，在特定排序下，MCOIS在阈值图上可多项式时间求解。

> **摘要翻译:** （导出）子图同构和最大公共（导出）子图是图模式匹配和相似性计算中的基本问题。在源自时间序列数据或蛋白质结构的图中，顶点通常会因其底层结构（例如时间序列或氨基酸序列）而产生自然的完全排序。这促使人们研究尊重这种固有排序的问题变体。本文探讨了有序（导出）子图同构（O(I)SI）及其推广形式——最大公共有序（导出）子图（MCO(I)S），这些问题旨在寻找保留两个给定有序图顶点顺序的子图同构。我们的主要贡献有三方面：（1）我们证明了这些问题即使限制在小图类（如深度为2的树和阈值图）上仍然是NP完全的。（2）我们建立了OSI和OISI在某些图类上计算复杂度的差异。例如，OSI对于具有其区间排序的区间图是多项式时间可解的，而OISI在相同设置下仍然是NP完全的。（3）我们证明了这些问题的可处理性可能取决于顶点排序。例如，虽然OISI在阈值图上是NP完全的，但如果提供了表征阈值图的特定顶点排序，其推广形式MCOIS可以在多项式时间内解决。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [707] [Improved sampling algorithms and Poincaré inequalities for non-log-concave distributions](https://arxiv.org/abs/2507.11236)
> *改进的非对数凹分布采样算法和庞加莱不等式*

*Yuchen He, Zhehan Lei, Jianan Shao, Chihao Zhang* | **Category: cs.DS, cs.LG, math.PR, stat.ML** | **Updated: 2025-07-15**

**Keywords:** 采样算法, 庞加莱不等式, 非对数凹分布, 查询复杂度, 平滑性假设

**Comment:** 

> **TL;DR:** 本文展示了在更强的平滑性假设下，非对数凹分布的采样查询复杂度可以从指数级降低到多项式级，并改进了庞加莱常数的估计。

**AI_Comments:** 本文的核心创新在于揭示了在扩散基采样器中常见的“加强平滑性假设”(1*)对非对数凹分布采样复杂度的巨大影响。它从理论上证明了这一看似微小的条件加强能将采样查询复杂度从指数级降低到多项式级，填补了该领域的一个重要空白。此外，对庞加莱常数界限的改进及其在高斯混合模型中的应用也增加了其实用价值。这项工作对于理解非凸优化和采样算法的理论极限具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明，在标准假设下，非对数凹分布的采样查询复杂度可能非常高（呈指数级），且庞加莱常数可能任意大。本文旨在探究一个在扩散基采样器中常见的、对平滑性条件略微加强的假设（1*）是否能显著改善采样算法的查询复杂度和庞加莱不等式。

**Method:** 本文研究了在假设 (1*)（源自Ornstein-Uhlenbeck过程的每个分布的势函数都是L-平滑的）和标准第二矩假设 (2) 下的采样问题。此外，还探讨了在假设 (1*) 和更强的次高斯矩假设下，庞加莱常数的界限。方法是理论分析和复杂度估计。

**Result:** 在假设 (1*) 和 (2) 下，采样查询复杂度为 $\mathrm{poly}(L,d)\cdot \left(\frac{Ld+M}{\epsilon^2}\right)^{\mathcal{O}(L+1)}$，当 $L=\mathcal{O}(1)$ 且 $M=\mathrm{poly}(d)$ 时，该复杂度在 $d$ 和 $1/\epsilon$ 上呈多项式级，显著优于现有准多项式复杂度算法。此外，在假设 (1*) 和次高斯矩假设下，庞加莱常数至多为 $\mathcal{O}(\lambda)^{2(L+1)}$。作为应用，获得了高斯混合模型（相同协方差）改进的庞加莱常数估计。

**Conclusion:** 平滑性条件从 (1) 适度加强到 (1*) 可以导致采样算法查询复杂度上的指数级差距。这表明假设 (1*) 对高效采样和庞加莱常数界限至关重要。

> **ai_Abstract:** 本文研究了非对数凹分布的采样问题，并在扩散基采样器中常见的更强平滑性假设(1*)下，显著降低了采样算法的查询复杂度，使其从指数级变为多项式级。同时，结合(1*)和次高斯矩假设，本文还给出了庞加莱常数更紧的估计，并将其应用于高斯混合模型。研究结果强调了该加强假设对采样效率和庞加莱不等式的重要性。

> **摘要翻译:** 我们研究从密度与$e^{-V}$成比例的分布$\mu$中采样的问题，其中$V:\mathbb R^d\to \mathbb R$是势函数，并且可以查询$V$和$\nabla V$。我们从以下标准假设开始：
(1) 势函数$V$是$L$-平滑的。
(2) 第二矩$\mathbf{E}_{X\sim \mu}[\|X\|^2]\leq M$。
最近，He和Zhang（COLT'25）表明，从这类分布采样的查询复杂度至少是$\left(\frac{LM}{d\epsilon}\right)^{\Omega(d)}$，其中$\epsilon$是总变差距离中期望的精度，并且庞加莱常数可以任意大。
同时，在基于扩散的采样器研究中，另一个常见的假设（参见例如Chen, Chewi, Li, Li, Salim和Zhang (ICLR'23)的工作）将平滑性条件(1)加强为以下内容：
(1*) 从$\mu$开始的Ornstein-Uhlenbeck过程中的*每个*分布的势函数都是$L$-平滑的。
我们证明，在假设(1*)和(2)下，从$\mu$采样的查询复杂度可以是$\mathrm{poly}(L,d)\cdot \left(\frac{Ld+M}{\epsilon^2}\right)^{\mathcal{O}(L+1)}$，当$L=\mathcal{O}(1)$且$M=\mathrm{poly}(d)$时，这在$d$和$\frac{1}{\epsilon}$上是多项式级的。这改进了Huang等人（COLT'24）开发的准多项式查询复杂度算法。我们的结果表明，平滑性条件(1)到(1*)看似温和的加强可以导致采样算法查询复杂度上的指数级差距。
此外，我们表明，结合假设(1*)和更强的矩假设，即$X\sim\mu$时$\|X\|$是$\lambda$-次高斯，$\mu$的庞加莱常数至多为$\mathcal{O}(\lambda)^{2(L+1)}$。作为我们技术的一个应用，我们获得了具有相同协方差的高斯混合的庞加莱常数的改进估计。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [745] [Fully Dynamic Euclidean k-Means](https://arxiv.org/abs/2507.11256)
> *全动态欧几里德k-均值*

*Sayan Bhattacharya, Martín Costa, Ermiya Farokhnejad, Shaofeng H. -C. Jiang, Yaonan Jin, Jianing Lou* | **Category: cs.DS** | **Updated: 2025-07-15**

**Keywords:** 动态k-均值, 欧几里德聚类, 动态算法, 近似比, 一致性哈希

**Comment:** 

> **TL;DR:** 该论文提出了一种针对动态欧几里德k-均值聚类问题的算法，在近似比、更新时间和恢复方面提供了近乎最优的保证。

**AI_Comments:** 这项工作在动态k-均值聚类领域取得了显著进展，通过提出一种在多个关键性能指标上达到理论极限的算法，解决了长期存在的挑战。其创新之处在于结合了现有最先进的研究成果并开发了新颖的几何数据结构，特别是高效的一致性哈希方案。该算法的“几乎最优”保证表明它在实际应用中具有强大的潜力，并且在理论上具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该论文考虑了动态设置下的基本欧几里德k-均值聚类问题，其中输入点集随时间通过点插入/删除而演变。目标是在最小化近似比、更新时间以及算法的恢复（对解决方案S所做的更改数量）的同时，显式维护一个解决方案（k个中心的集合）。

**Method:** 该论文提出了一种动态算法，该算法建立在[Bhattacharya, Costa, Farokhnejad; STOC'25]最近的工作基础之上。在此过程中，他们设计了几种新颖的几何数据结构，其中一项主要贡献是设计了第一个一致性哈希方案，该方案实现了每次点评估的poly(d)运行时间。

**Result:** 该算法具有poly(1/epsilon)近似比、~O(k^epsilon)更新时间和~O(1)恢复。在维度d不能假定为固定常数的一般情况下，该算法在所有这三个参数上都具有几乎最优的保证。改进更新时间或近似比将意味着超越目前最先进的静态算法。

**Conclusion:** 该论文提出的动态算法为欧几里德k-均值聚类问题在动态设置下提供了近乎最优的解决方案，在关键性能指标上达到了现有技术的极限。

> **ai_Abstract:** 该论文解决了动态欧几里德k-均值聚类问题，其中点集随时间变化。作者提出了一种动态算法，该算法在近似比、更新时间和恢复方面实现了近乎最优的性能。该算法基于现有研究并引入了新的几何数据结构，包括一种高效的一致性哈希方案。其结果表明，进一步改进这些参数将超越当前静态算法的最佳表现，证实了其在动态聚类领域的重大进展。

> **摘要翻译:** 我们考虑动态设置下的基本欧几里德k-均值聚类问题，其中输入$X \subseteq \mathbb{R}^d$通过一系列点的插入/删除随时间演变。我们必须在这些更新过程中显式维护一个解决方案（k个中心的集合）$S \subseteq \mathbb{R}^d$，同时最小化算法的近似比、更新时间（处理点插入/删除所需的时间）和恢复（对解决方案S所做的更改数量）。
我们为该问题提出了一种动态算法，其近似比为$\text{poly}(1/\epsilon)$，更新时间为$\tilde{O}(k^{\epsilon})$，恢复为$\tilde{O}(1)$。在维度d不能假定为固定常数的一般情况下，我们的算法在所有这三个参数上都具有几乎最优的保证。事实上，改进我们的更新时间或近似比将意味着超越目前最先进的静态算法（这被广泛认为是最好的），并且任何动态算法的恢复必须是$\Omega(1)$。
我们通过在[Bhattacharya, Costa, Farokhnejad; STOC'25]最近的工作基础上构建来获得我们的结果，该工作为一般度量空间（而非欧几里德设置）中的k-均值提供了近乎最优的动态算法。在此过程中，我们设计了几种独立兴趣的新颖几何数据结构。具体来说，我们的主要贡献之一是设计了第一个一致性哈希方案[Czumaj, Jiang, Krauthgamer, Vesel\'{y}, Yang; FOCS'22]，该方案在具有竞争性参数的情况下实现了每次点评估的$\text{poly}(d)$运行时间。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [790] [Deterministic Lower Bounds for $k$-Edge Connectivity in the Distributed Sketching Model](https://arxiv.org/abs/2507.11257)
> *分布式Sketching模型中k-边连通性的确定性下界*

*Peter Robinson, Ming Ming Tan* | **Category: cs.DS, cs.DC** | **Updated: 2025-07-15**

**Keywords:** k-边连通性, 分布式Sketching模型, 确定性下界, 通信复杂性, UniqueOverlap

**Comment:** 

> **TL;DR:** 该论文首次为分布式Sketching模型中的k-边连通性问题提供了确定性下界，证明了消息长度至少为Ω(k)比特。

**AI_Comments:** 这篇论文的创新性在于首次为分布式Sketching模型中的连通性决策问题建立了确定性下界，填补了该领域的一个重要空白。它通过引入新颖的图构造和独特的UniqueOverlap通信复杂性问题，并结合交叉相交集族理论，为解决这类问题提供了新的分析工具和思路。该成果对于理解分布式图算法的信息复杂性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在分布式Sketching模型中，以前对于图连通性问题（特别是k-边连通性）的确定性算法，缺乏明确的消息长度下界。已有的结果仅限于对1-边连通性（连通性）的概率性下界，且数值较小。本研究旨在填补这一空白，为确定性算法提供更强的下界。

**Method:** 本文引入了一种新的下界图构造方法，并提出了一个名为UniqueOverlap的3方通信复杂性问题。为了证明UniqueOverlap的难度，论文利用了交叉相交集族（cross-intersecting set families）的结果。最终，通过一种新颖的模拟论证（与以往工作不同，不引入任何错误概率，因此适用于确定性算法），得到了k-边连通性的确定性下界。

**Result:** 首次为分布式Sketching模型中决定图连通性问题提供了确定性算法的下界。具体而言，对于k-边连通性，当k为超常数且k = O(√n)时，最坏情况下的消息长度为Ω(k)比特。这是分布式图Sketching模型中连通性决策问题的第一个超多对数下界。

**Conclusion:** 本研究成功地为分布式Sketching模型中的k-边连通性问题建立了首个确定性下界，显著提升了对该模型下算法信息复杂度的理解。通过引入新的技术和方法，论文解决了之前研究中的一个重要开放问题。

> **ai_Abstract:** 该论文在分布式Sketching模型中研究k-边连通性问题，并首次为确定性算法提供了消息长度下界。研究表明，对于k-边连通性，最坏情况下消息长度为Ω(k)比特，这远超现有结果。为达此目的，论文引入了新的图构造方法、名为UniqueOverlap的3方通信复杂性问题，并利用交叉相交集族理论及创新的模拟论证来证明其结果。

> **摘要翻译:** 我们在分布式Sketching模型中研究无向图的k-边连通性问题，该模型包含n个节点和一个仲裁者。每个节点根据其在图中的1跳邻域向仲裁者发送一条消息，仲裁者必须根据收到的消息判断图是否是k-边连通的。
我们首次为该模型中决定图连通性问题的确定性算法提供了下界。具体而言，我们证明对于任何超常数k = O(√n)，k-边连通性的最坏情况消息长度为Ω(k)比特。此前，Yu (SODA 2021) 仅针对 (1-边) 连通性给出了Ω(log^3 n) 比特的下界。事实上，我们的结果是分布式图Sketching模型中连通性决策问题的第一个超多对数下界。
为了获得我们的结果，我们引入了一种新的下界图构造方法，以及一个新的3方通信复杂性问题，我们称之为UniqueOverlap。由于这个问题似乎不适合通过归约到现有难题（如集合不交性或索引）来解决，因为三个参与者的输入之间存在相关性，我们利用交叉相交集族的结果来证明UniqueOverlap对于确定性算法的难度。最后，我们通过一种新颖的模拟论证获得了决定k-边连通性所需的下界，与之前的工作不同，这种论证不引入任何错误概率，因此适用于确定性算法。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [207] [Developing and evaluating quilts for the depiction of large layered graphs](https://arxiv.org/abs/2507.10883)
> *开发和评估用于描绘大型分层图的Quilts图*

*Juhee Bae, Benjamin Watson* | **Category: cs.GR, cs.HC** | **Updated: 2025-07-15**

**Keywords:** Quilts图, 分层图, 可视化, 路径查找, 用户研究

**Comment:** 

> **TL;DR:** 本研究开发并改进了Quilts图，一种用于表示大型分层图的矩阵式图表，并通过两项研究发现Quilts图在路径查找速度上优于传统的节点-链接图和矩阵图，尤其是在大型图表中。

**AI_Comments:** 本研究通过引入Quilts图并对其进行实证评估，为大型分层图的可视化提供了一种创新且高效的解决方案。其重要性在于证明了Quilts图在用户路径查找速度上的显著优势，尤其是在面对日益复杂和庞大的数据集时，这对于数据分析和理解具有重要意义。研究详细比较了不同的跳过链接描绘方式，并量化了Quilts图相对于传统方法的性能提升，为后续可视化工具的设计和优化提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 传统的流程图等分层图表示方法在图表变得复杂时难以理解，因此需要一种新的方法来有效描绘大型分层图。

**Method:** 研究首先通过开发三种设计替代方案来改进Quilts图。在第一项研究中，比较了Quilts图在跳过链接（skip links）描绘上使用纯色、纯文本和混合（颜色和文本）方式的效果。在第二项研究中，将使用混合跳过链接描绘的Quilts图与节点-链接图和中心矩阵图进行了比较。

**Result:** 第一项研究发现，纯色跳过链接描绘在路径查找时显著更慢且不准确，而混合描绘在某些情况下优于纯文本描绘。第二项研究显示，用户使用Quilts图查找路径的速度显著快于节点-链接图和矩阵图（Quilts 46.6秒 vs. 节点-链接 58.3秒 vs. 矩阵 71.2秒）。在大型图表（200节点）中，Quilts的速度优势更明显（55.4秒 vs. 节点-链接 71.1秒 vs. 矩阵 84.2秒）。

**Conclusion:** Quilts图是一种有效描绘大型分层图的方法，与传统的节点-链接图和矩阵图相比，它能显著提高用户查找路径的速度，尤其是在图表规模较大时。

> **ai_Abstract:** 本研究旨在通过开发和评估Quilts图来解决大型复杂分层图难以理解的问题。研究首先改进了Quilts图的跳过链接描绘方式，发现混合（颜色和文本）方式优于纯色和纯文本方式。随后，将优化后的Quilts图与传统的节点-链接图和矩阵图进行比较，结果表明Quilts图在路径查找速度上具有显著优势，尤其是在处理大型图表时，证明了其作为大型分层图可视化工具的有效性。

> **摘要翻译:** 传统的流程图等分层图表示方法被广泛使用。然而，随着图表变得越来越复杂，这些表示方法可能变得难以理解。Quilts图是一种基于矩阵的分层图表示方法，旨在解决这个问题。在这项研究中，我们首先通过开发三种设计替代方案来改进Quilts图，然后将其中最佳的替代方案与更广为人知的节点-链接图和矩阵图进行了比较。Quilts图的一个主要弱点是它们对跳过链接（即不简单连接到后续层的链接）的描绘。因此，在我们的第一项研究中，我们比较了使用纯色、纯文本和混合（颜色和文本）跳过链接描绘的Quilts图，发现使用纯色描绘进行路径查找时显著更慢且不准确，并且在某些情况下，混合描绘比纯文本描绘具有优势。在我们的第二项研究中，我们比较了使用混合描绘的Quilts图与节点-链接图和中心矩阵图。总体结果显示，用户使用Quilts图查找图表中路径的速度显著快于节点-链接图（58.3秒）或矩阵图（71.2秒），Quilts图为46.6秒。这种速度优势在大型图表（例如200节点图表）中更为显著（Quilts 55.4秒 vs. 节点-链接 71.1秒 vs. 矩阵 84.2秒）。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [473] [OffsetCrust: Variable-Radius Offset Approximation with Power Diagrams](https://arxiv.org/abs/2507.10924)
> *OffsetCrust：基于幂图的变半径偏移近似*

*Zihan Zhao, Pengfei Wang, Minfeng Xu, Shuangmin Chen, Shiqing Xin, Changhe Tu, Wenping Wang* | **Category: cs.GR** | **Updated: 2025-07-15**

**Keywords:** 偏移曲面, 变半径, 幂图, 几何处理, OffsetCrust

**Comment:** 

> **TL;DR:** OffsetCrust是一种新颖的框架，通过计算幂图来有效解决变半径偏移曲面问题。

**AI_Comments:** 该论文提出了一种新颖的基于幂图的变半径偏移曲面计算方法，解决了传统方法在处理变半径时的挑战，并通过微调机制提升了精度。其创新性在于将幂图引入变半径偏移计算，并有效缓解了错位问题，具有重要的理论和实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 偏移曲面在几何处理中至关重要，但计算变半径偏移曲面仍然是一个具有挑战性的问题。

**Method:** 提出OffsetCrust框架，通过计算幂图来解决变半径偏移问题。幂图由贡献点构建，这些贡献点包括基曲面S上的采样点及其沿R相关方向位移的离曲面点。对于常半径情况，位移方向与S的表面法线精确对齐。通过轻量级微调程序缓解了基于Crust方法的错位问题。

**Result:** 通过广泛的实验验证了OffsetCrust的准确性和效率，并展示了其在从介质轴变换（MAT）表示重建原始边界曲面等应用中的实用性。

**Conclusion:** OffsetCrust框架有效且准确地解决了变半径偏移曲面的计算问题，并在实际应用中表现出实用性。

> **ai_Abstract:** 本文提出了一种名为OffsetCrust的新颖框架，旨在高效解决变半径偏移曲面的计算难题。该方法通过构建一个由基曲面采样点及其沿半径函数相关方向位移的离曲面点组成的幂图来实现。OffsetCrust通过轻量级微调程序缓解了传统基于Crust方法中常见的错位问题。实验结果验证了OffsetCrust在准确性和效率方面的表现，并展示了其在重建原始边界曲面等实际应用中的有效性。

> **摘要翻译:** 偏移曲面，定义为基曲面和滚动球的闵可夫斯基和，在几何处理中扮演着关键角色，应用范围从覆盖运动规划到画笔建模。尽管在计算常半径偏移曲面方面取得了显著进展，但计算变半径偏移曲面仍然是一个具有挑战性的问题。在本文中，我们提出了OffsetCrust，一个通过计算幂图来有效解决变半径偏移问题的新颖框架。令R表示定义在基曲面S上的半径函数。幂图由贡献点构建，这些贡献点包括S上精心采样的基点及其相应的离曲面点，这些点沿R相关方向位移。仅在常半径情况下，这些位移方向才与S的表面法线精确对齐。此外，我们的方法通过轻量级微调程序缓解了基于Crust方法中常见的错位问题。我们通过广泛的实验验证了OffsetCrust的准确性和效率，并展示了其在从介质轴变换（MAT）表示重建原始边界曲面等应用中的实际效用。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [517] [Elevating 3D Models: High-Quality Texture and Geometry Refinement from a Low-Quality Model](https://arxiv.org/abs/2507.11465)
> *提升3D模型：从低质量模型中实现高质量纹理和几何精修*

*Nuri Ryu, Jiyun Won, Jooeun Son, Minsu Gong, Joo-Haeng Lee, Sunghyun Cho* | **Category: cs.GR, cs.CV** | **Updated: 2025-07-15**

**Keywords:** 3D模型精修, 纹理增强, 几何精修, 低质量模型, Elevate3D

**Comment:** Accepted to SIGGRAPH 2025. For the project page, see
  https://cg.postech.ac.kr/research/Elevate3D/

> **TL;DR:** Elevate3D框架通过HFS-SDEdit方法，将低质量3D模型提升为高质量，同时精修纹理和几何，有效解决了高质量3D资产稀缺问题。

**AI_Comments:** 该论文的创新之处在于其对3D模型几何精修的重视，这是以前方法普遍忽视的。通过利用HFS-SDEdit精修图像中的几何线索，结合单目几何预测器，实现了纹理和几何的无缝对齐。这对于提高低质量3D资产的可用性和质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 高质量3D资产对于计算机图形学和3D视觉应用至关重要，但由于获取成本高昂而稀缺。本研究旨在解决这一短缺，将易于获取的低质量3D资产转换为更高质量的资产。

**Method:** 本文提出了Elevate3D框架，其核心是HFS-SDEdit，一种专门的纹理增强方法，可在保持外观和几何形状的同时显著提高纹理质量并修复其退化。Elevate3D以逐视图的方式运行，在纹理和几何精修之间交替进行，并利用最先进的单目几何预测器，从HFS-SDEdit精修的图像中提取几何线索，以确保几何形状与增强纹理无缝对齐。

**Result:** Elevate3D在3D模型精修方面超越了最近的竞争对手，达到了最先进的质量水平。

**Conclusion:** Elevate3D框架通过将低质量模型提升为高质量，有效地解决了高质量开源3D资产的稀缺问题。

> **ai_Abstract:** 该论文提出了Elevate3D框架，旨在将低质量3D模型提升至高质量，以解决高质量3D资产稀缺的问题。其核心是HFS-SDEdit纹理增强方法，并结合了逐视图的纹理和几何精修。Elevate3D利用单目几何预测器来确保几何细节与增强纹理对齐。实验结果表明，该框架在3D模型精修方面达到了最先进的水平，并有效解决了高质量开源3D资产的短缺。

> **摘要翻译:** 高质量3D资产对于计算机图形学和3D视觉的各种应用至关重要，但由于高昂的获取成本而仍然稀缺。为了解决这种短缺，我们引入了Elevate3D，这是一个新颖的框架，可以将易于获取的低质量3D资产转换为更高质量的资产。Elevate3D的核心是HFS-SDEdit，这是一种专门的纹理增强方法，可在保持外观和几何形状的同时显著提高纹理质量并修复其退化。此外，Elevate3D以逐视图的方式运行，在纹理和几何精修之间交替进行。与以前主要忽视几何精修的方法不同，我们的框架通过采用最先进的单目几何预测器，利用HFS-SDEdit精修图像中的几何线索。这种方法确保了与增强纹理无缝对齐的详细准确的几何形状。Elevate3D通过在3D模型精修中实现最先进的质量，超越了最近的竞争对手，有效地解决了高质量开源3D资产的稀缺问题。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [566] [EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation](https://arxiv.org/abs/2411.10061)
> *EchoMimicV2：迈向引人注目、简化和半身人体动画*

*Rang Meng, Xingyu Zhang, Yuming Li, Chenguang Ma* | **Category: cs.GR, cs.CV** | **Updated: 2025-07-15**

**Keywords:** EchoMimicV2, 人体动画, 半身动画, 音频-姿态协调, 数据稀缺

**Comment:** CVPR2025

> **TL;DR:** EchoMimicV2提出了一种简化的半身人体动画方法，通过音频-姿态动态协调策略，解决了现有方法条件复杂或仅限于头部动画的问题，并在定量和定性评估中超越了现有方法。

**AI_Comments:** 该论文的创新点在于提出了一种简化且高效的半身人体动画方法，通过巧妙的音频-姿态协调策略和对数据稀缺性的处理（头部局部注意力机制），解决了现有方法在条件复杂性和数据适用性上的痛点。同时，引入阶段性去噪损失和新的评估基准也体现了研究的全面性，对半身人体动画领域具有重要推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人体动画方法通常需要额外的控制条件、繁琐的条件注入模块或仅限于头部区域驱动，这导致了实际应用中的挑战。本文旨在探索如何在简化不必要条件的同时，实现引人注目的半身人体动画。

**Method:** 本文提出了一种名为EchoMimicV2的半身人体动画方法。该方法利用新颖的“音频-姿态动态协调”策略，包括姿态采样和音频扩散，以增强半身细节、面部和手势表达，同时减少条件冗余。为解决半身数据稀缺问题，该方法采用“头部局部注意力”机制，将头部特写数据无缝整合到训练框架中，且可在推理时省略。此外，还设计了“阶段性去噪损失”以引导特定阶段的运动、细节和低级质量。论文还提出了一个用于评估半身人体动画效果的新基准。

**Result:** 广泛的实验和分析表明，EchoMimicV2在定量和定性评估方面均超越了现有方法。

**Conclusion:** EchoMimicV2成功地实现了一种引人注目、简化的半身人体动画方法，解决了现有方法的复杂性和局限性，并在性能上优于现有技术。

> **ai_Abstract:** EchoMimicV2是一种新颖的半身人体动画方法，旨在克服现有方法中复杂的控制条件和头部区域限制。它引入了音频-姿态动态协调策略（包含姿态采样和音频扩散），以提升半身动画的细节和表现力，并减少条件冗余。为应对数据稀缺，该方法通过头部局部注意力机制利用头部特写数据进行训练，且该机制在推理时可被移除。此外，还设计了阶段性去噪损失来优化动画质量，并提出了一个新的评估基准。实验证明，EchoMimicV2在性能上优于现有技术。

> **摘要翻译:** 近期关于人体动画的研究通常涉及音频、姿态或运动图条件，从而实现生动的动画质量。然而，这些方法由于额外的控制条件、繁琐的条件注入模块或仅限于头部区域驱动，常常面临实际挑战。因此，我们提出一个问题：是否有可能在简化不必要条件的同时，实现引人注目的半身人体动画？为此，我们提出了一种名为EchoMimicV2的半身人体动画方法，该方法利用一种新颖的音频-姿态动态协调策略，包括姿态采样和音频扩散，以增强半身细节、面部和手势表达，同时减少条件冗余。为了弥补半身数据稀缺的问题，我们利用头部局部注意力机制，将头部特写数据无缝地整合到我们的训练框架中，该机制在推理时可以省略，为动画提供了免费的午餐。此外，我们设计了阶段性去噪损失，分别引导特定阶段的动画运动、细节和低级质量。除此之外，我们还提出了一个用于评估半身人体动画效果的新基准。大量的实验和分析表明，EchoMimicV2在定量和定性评估中均超越了现有方法。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [615] [Model See Model Do: Speech-Driven Facial Animation with Style Control](https://arxiv.org/abs/2505.01319)
> *模型看模型做：语音驱动的面部动画与风格控制*

*Yifang Pan, Karan Singh, Luiz Gustavo Hafemann* | **Category: cs.GR, cs.LG, I.3.7; I.3.8** | **Updated: 2025-07-15**

**Keywords:** 语音驱动面部动画, 风格控制, 潜在扩散模型, 风格基础, 唇部同步

**Comment:** 10 pages, 7 figures, SIGGRAPH Conference Papers '25

> **TL;DR:** 现有语音驱动面部动画难以捕捉细微风格。本文提出一种新颖的基于示例的潜在扩散模型，通过“风格基础”条件机制，在保持唇部同步的同时，有效捕捉并转移细微的面部表演风格。

**AI_Comments:** 本文的创新点在于引入了“风格基础”这一新型条件机制，将其应用于潜在扩散模型，从而在语音驱动的面部动画中实现了对细微表演风格的有效转移，同时保证了高质量的唇部同步。这对于创建更真实、更富有表现力的虚拟角色具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现有语音驱动的3D面部动画方法在实现精确唇部同步和生成基本情感表达方面取得了显著进展，但它们往往难以捕捉和有效转移细微的表演风格。

**Method:** 本文提出一种新颖的基于示例的生成框架，该框架以参考风格片段为条件，驱动潜在扩散模型生成富有表现力且时间连贯的面部动画。为精确遵循风格参考，引入了一种名为“风格基础”的新型条件机制，该机制从参考中提取关键姿态，并通过加性方式引导扩散生成过程以适应风格，同时不损害唇部同步质量。

**Result:** 广泛的定性、定量和感知评估表明，该方法在忠实再现所需风格的同时，在各种语音场景中实现了卓越的唇部同步。

**Conclusion:** 本文提出的方法有效解决了语音驱动面部动画中细微表演风格转移的挑战，实现了卓越的风格再现和唇部同步。

> **ai_Abstract:** 本文提出了“模型看模型做”，一个新颖的基于示例的框架，利用潜在扩散模型实现语音驱动的3D面部动画与风格控制。为解决现有方法在捕捉细微表演风格方面的局限性，该框架引入了“风格基础”条件机制。此机制从参考风格片段中提取关键姿态，引导扩散生成过程，确保动画精确遵循风格并保持时间连贯性，同时不损害唇部同步质量。评估结果证实了该方法在再现期望风格和实现卓越唇部同步方面的有效性。

> **摘要翻译:** 语音驱动的3D面部动画在虚拟形象、游戏和数字内容创作等应用中扮演着关键角色。尽管现有方法在实现精确唇部同步和生成基本情感表达方面取得了显著进展，但它们往往难以捕捉和有效转移细微的表演风格。我们提出了一种新颖的基于示例的生成框架，该框架以参考风格片段为条件，驱动潜在扩散模型生成富有表现力且时间连贯的面部动画。为解决精确遵循风格参考的挑战，我们引入了一种名为“风格基础”的新型条件机制，该机制从参考中提取关键姿态，并通过加性方式引导扩散生成过程以适应风格，同时不损害唇部同步质量。这种方法使得模型能够捕捉细微的风格线索，同时确保生成的动画与输入语音紧密对齐。广泛的定性、定量和感知评估表明，我们的方法在忠实再现所需风格的同时，在各种语音场景中实现了卓越的唇部同步。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [64] [Repeated Padding+: Simple yet Effective Data Augmentation Plugin for Sequential Recommendation](https://arxiv.org/abs/2403.06372)
> *重复填充+: 简单而有效的序列推荐数据增强插件*

*Yizhou Dang, Yuting Liu, Enneng Yang, Guibing Guo, Linying Jiang, Jianzhe Zhao, Xingwei Wang* | **Category: cs.IR** | **Updated: 2025-07-15**

**Keywords:** 序列推荐, 数据增强, 填充, RepPad+, 即插即用

**Comment:** v1: Initial Version, v2:Accepted by RecSys 2024, v3:Extended Version
  Under Review

> **TL;DR:** 本文提出了一种名为Repeated Padding+ (RepPad+)的简单而有效的即插即用数据增强方法，用于序列推荐。该方法通过重复利用原始交互序列作为填充内容，显著提高了模型性能和训练效率。

**AI_Comments:** 本文通过重新思考传统的填充策略，提出了一个异常简单却高效的想法。其“即插即用”的特性和缺乏超参数使其非常实用，可以立即采用。在不同模型上取得的显著性能提升凸显了其在序列推荐数据增强方面的创新性，将一个看似微不足道的细节（填充）转化为强大的优化手段。

<details>
  <summary>Details</summary>

**Motivation:** 在序列推荐模型训练中，传统的填充方法通常使用特殊值0，这导致了大量的空闲输入空间未被利用。本文的动机是探索是否可以通过填充其他内容来充分利用这些空闲空间，以进一步提高模型性能和训练效率，这是一个以前从未被探索过的问题。

**Method:** 本文提出了一种名为Repeated Padding+ (RepPad+)的简单而有效的填充方法。具体来说，该方法使用原始交互序列作为填充内容，并在模型训练期间将其填充到填充位置。这种操作可以执行有限次，或者重复直到输入序列的长度达到最大限制。对于那些不能完全填充原始数据的序列，本文借鉴了滑动窗口策略，截取连续子序列来填充空闲空间。RepPad+可以被视为一种序列级数据增强策略，它不包含可训练参数或超参数，是一种即插即用的数据增强操作。

**Result:** 在各种序列模型和七个真实世界数据集上进行的广泛实验证明了该方法的有效性和效率。平均推荐性能在GRU4Rec上提高了84.11%，在SASRec上提高了35.34%。本文还从多个角度深入分析和解释了RepPad+为何有效。

**Conclusion:** RepPad+是一种简单、有效且即插即用的序列推荐数据增强方法，通过智能地利用填充空间，显著提高了模型性能。

> **ai_Abstract:** Repeated Padding+ (RepPad+) 被提出作为一种新颖的、即插即用的序列推荐数据增强技术。与传统的零填充不同，RepPad+ 通过重复利用原始交互序列或使用滑动窗口方法截取子序列来填充填充空间。这种方法不含可训练参数，作为一种序列级增强策略。在多个模型和数据集上的实验结果证实了其在推荐性能上的显著提升（例如，GRU4Rec上提升84.11%，SASRec上提升35.34%）和效率，证明了利用先前空闲的输入空间的价值。

> **摘要翻译:** 序列推荐旨在根据用户的历史交互提供个性化建议。在训练序列模型时，填充是一种广泛采用的技术，主要有两个原因：1）绝大多数模型只能处理固定长度的序列；2）基于批处理的训练需要确保每个批次中的序列具有相同的长度。特殊值0通常用作填充内容，它不包含实际信息，并在模型计算中被忽略。这种常识性的填充策略使我们面临一个以前从未探索过的问题：我们能否通过填充其他内容来充分利用这个空闲输入空间，以进一步提高模型性能和训练效率？
在这项工作中，我们提出了一种简单而有效的填充方法，称为Repeated Padding+ (RepPad+)。具体来说，我们使用原始交互序列作为填充内容，并在模型训练期间将其填充到填充位置。此操作可以执行有限次，或者重复直到输入序列的长度达到最大限制。对于那些不能完全填充原始数据的序列，我们从滑动窗口策略中汲取灵感，截取连续子序列来填充空闲空间。我们的RepPad+可以看作是一种序列级数据增强策略。与大多数现有工作不同，我们的方法不包含可训练参数或超参数，是一种即插即用的数据增强操作。在各种序列模型和七个真实世界数据集上进行的广泛实验证明了我们方法的有效性和效率。平均推荐性能在GRU4Rec上提高了84.11%，在SASRec上提高了35.34%。我们还从多个角度深入分析和解释了RepPad+为何有效。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [106] [CART: A Generative Cross-Modal Retrieval Framework with Coarse-To-Fine Semantic Modeling](https://arxiv.org/abs/2406.17507)
> *CART: 一种基于粗到细语义建模的生成式跨模态检索框架*

*Minghui Fang, Shengpeng Ji, Jialong Zuo, Hai Huang, Yan Xia, Jieming Zhu, Xize Cheng, Xiaoda Yang, Wenrui Liu, Gang Wang, Zhenhua Dong, Zhou Zhao* | **Category: cs.IR** | **Updated: 2025-07-15**

**Keywords:** 跨模态检索, 生成式模型, 粗到细建模, 语义对齐, 效率

**Comment:** ACL 2025 Main

> **TL;DR:** CART是一个生成式跨模态检索框架，通过粗到细的语义建模解决了传统方法的效率问题，并在检索性能和效率上表现出色。

**AI_Comments:** 本文的创新点在于将生成模型引入跨模态检索领域，并设计了独特的粗到细语义建模方法（结合K-Means和RQ-VAE）以及特征融合策略，有效提升了大规模数据下的检索效率和性能。这为未来的跨模态检索研究提供了新的视角和高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 传统的跨模态检索方法（单塔或双塔框架）在大规模数据下存在训练成本高和推理延迟大的挑战。

**Method:** 本文提出了一个生成式跨模态检索框架（CART），通过为每个候选分配标识符并将其生成作为检索目标。具体地，它采用了一种粗到细的方案，结合K-Means和RQ-VAE将多模态数据离散化为支持自回归生成的token序列。此外，还提出了一种特征融合策略来对齐查询和候选之间的语义。

**Result:** 大量的实验证明了CART中策略的有效性，在检索性能和效率方面都取得了优异的结果。

**Conclusion:** CART框架能够有效解决大规模数据下跨模态检索的效率和性能问题，为跨模态检索提供了一种高效的生成式解决方案。

> **ai_Abstract:** 本文提出了一种名为CART的生成式跨模态检索框架，旨在解决传统方法在大规模数据下训练成本高和推理延迟大的问题。CART通过将候选视为可生成的标识符，并结合K-Means和RQ-VAE实现粗到细的语义建模，将多模态数据离散化为自回归token序列。同时，它引入特征融合策略以对齐查询与候选的语义。实验结果表明，CART在检索性能和效率方面均表现出色。

> **摘要翻译:** 跨模态检索旨在通过不同模态数据之间的交互，搜索与查询语义相关的实例。传统的解决方案利用单塔或双塔框架显式计算查询和候选之间的分数，但这在大规模数据下受到训练成本和推理延迟的挑战。受生成模型卓越性能和效率的启发，我们提出了一种基于粗到细语义建模的生成式跨模态检索框架（CART），它为每个候选分配标识符，并将生成标识符视为检索目标。具体来说，我们探索了一种有效的粗到细方案，结合K-Means和RQ-VAE将多模态数据离散化为支持自回归生成的token序列。此外，考虑到查询和候选之间缺乏显式交互，我们提出了一种特征融合策略来对齐它们的语义。大量的实验证明了CART中这些策略的有效性，在检索性能和效率方面都取得了优异的结果。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [116] [From Chaos to Automation: Enabling the Use of Unstructured Data for Robotic Process Automation](https://arxiv.org/abs/2507.11364)
> *从混乱到自动化：实现非结构化数据在机器人流程自动化中的应用*

*Kelly Kurowski, Xixi Lu, Hajo A. Reijers* | **Category: cs.IR, cs.SE** | **Updated: 2025-07-15**

**Keywords:** 机器人流程自动化, 非结构化数据, 信息检索, 自然语言处理, 大型语言模型

**Comment:** Accepted at AUTOMATE 2025

> **TL;DR:** 开发了一个名为UNDRESS的系统，利用模糊正则表达式、自然语言处理和大型语言模型，使RPA能够处理非结构化数据，从而提升业务流程效率。

**AI_Comments:** 该研究通过开发UNDRESS系统，创新性地解决了RPA在处理非结构化数据方面的核心限制。其重要性在于，非结构化数据占据企业数据的大部分，该系统使RPA能够解锁这部分数据的价值，极大地扩展了RPA的应用范围，对提升企业自动化水平和效率具有深远影响。结合模糊正则表达式、自然语言处理和大型语言模型的方法是其创新点。

<details>
  <summary>Details</summary>

**Motivation:** 组织中非结构化数据量日益增长，但机器人流程自动化（RPA）传统上依赖结构化数据，限制了其在处理非结构化文档方面的应用。从非结构化数据中提取有价值信息复杂，是RPA应用面临的重大挑战。

**Method:** 本研究开发了非结构化文档检索系统（UNDRESS），该系统利用模糊正则表达式、自然语言处理技术和大型语言模型，使RPA平台能够有效从非结构化文档中检索信息。研究包括原型系统的设计、开发和基于文本提取及信息检索性能的评估。

**Result:** UNDRESS在增强RPA处理非结构化数据的能力方面表现出有效性，并在该领域取得了显著进展。评估结果证明了其在文本提取和信息检索方面的性能。

**Conclusion:** UNDRESS系统可以促进RPA在传统上受非结构化数据阻碍的流程中得到更广泛的应用，从而提高整体业务流程效率。

> **ai_Abstract:** 本研究旨在解决机器人流程自动化（RPA）在处理非结构化数据时的局限性。针对企业中大量非结构化数据难以被RPA利用的问题，研究开发了非结构化文档检索系统（UNDRESS）。该系统结合模糊正则表达式、自然语言处理和大型语言模型，使RPA能够有效从非结构化文档中提取信息。原型系统的设计、开发和性能评估结果表明，UNDRESS能显著提升RPA处理非结构化数据的能力，有望促进RPA在更多业务流程中的广泛应用，从而提高整体效率。

> **摘要翻译:** 组织内非结构化数据量的增长给数据分析和流程自动化带来了重大挑战。非结构化数据缺乏预定义格式，包含电子邮件、报告和扫描件等多种形式，估计约占企业数据的80%。尽管它能提供有价值的洞察，但从非结构化数据中提取有意义的信息比结构化数据更复杂。机器人流程自动化（RPA）因自动化重复任务、提高效率和减少错误而广受欢迎。然而，RPA传统上依赖结构化数据，限制了其在涉及非结构化文档的流程中的应用。本研究通过开发非结构化文档检索系统（UNDRESS）解决了这一局限性，该系统利用模糊正则表达式、自然语言处理技术和大型语言模型，使RPA平台能够有效从非结构化文档中检索信息。该研究涉及原型系统的设计与开发，并基于文本提取和信息检索性能对其进行后续评估。结果表明，UNDRESS在增强RPA处理非结构化数据的能力方面表现出有效性，在该领域取得了显著进展。研究结果表明，该系统可以促进RPA在传统上受非结构化数据阻碍的流程中得到更广泛的采用，从而提高整体业务流程效率。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [145] [Big data searching using words](https://arxiv.org/abs/2409.15346)
> *大数据词语搜索*

*Santanu Acharjee, Ripunjoy Choudhury* | **Category: cs.IR** | **Updated: 2025-07-15**

**Keywords:** 大数据分析, 拓扑数据分析, 词语邻域结构, Jaccard相似系数, 异常检测

**Comment:** accepted for publication, Acceptance month: July, 2025

> **TL;DR:** 本文介绍了大数据搜索中词语邻域结构的基本概念，为未来开发大数据拓扑框架奠定基础，并利用Jaccard相似系数检测搜索行为异常。

**AI_Comments:** 这篇论文通过引入词语邻域结构和“大数据原始”的概念，为大数据分析中的拓扑数据分析提供了新的理论基础。其创新点在于将拓扑学概念应用于大数据搜索，并结合Jaccard相似系数进行异常检测，这对于理解和分析大数据具有潜在的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大数据分析是重要的研究领域，但大数据中缺乏与拓扑结构相关的基本概念，需要更深层次的基础理论支持。

**Method:** 提出了大数据搜索中词语邻域结构的基本概念，引入了“大数据原始”（big data primal）的概念，并结合Jaccard相似系数利用邻域结构检测搜索行为异常。

**Result:** 奠定了未来开发大数据拓扑框架的基础，并展示了如何利用邻域结构和Jaccard相似系数检测搜索行为异常。

**Conclusion:** 本文为大数据中的拓扑框架发展奠定了基础，并提供了一种利用词语邻域结构和Jaccard相似系数进行异常检测的方法。

> **ai_Abstract:** 本文针对大数据分析中缺乏拓扑结构基本概念的问题，提出了大数据搜索中词语邻域结构的基本概念，并引入了“大数据原始”的概念。研究展示了如何结合邻域结构和Jaccard相似系数来检测搜索行为中的异常，为未来大数据拓扑框架的开发奠定了基础。

> **摘要翻译:** 大数据分析是计算机科学、企业、电子商务和国防领域最有前景的新研究和开发领域之一。对于许多组织而言，大数据被认为是其最重要的战略资产之一。这种爆炸性的增长使得有必要从数学角度开发有效技术来检查和分析大数据。在各种大数据分析方法中，拓扑数据分析（TDA）现在被认为是一种有用的工具。然而，大数据中没有与拓扑结构相关的基本概念。在本文中，我们提出了大数据搜索中词语邻域结构的基本概念，为未来开发大数据的拓扑框架奠定了基础。我们还在大数据搜索的上下文中引入了“大数据原始”的概念，并探讨了如何将邻域结构与Jaccard相似系数相结合，用于检测搜索行为中的异常。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [179] [Are AI Agents interacting with Online Ads?](https://arxiv.org/abs/2504.07112)
> *AI代理是否与在线广告互动？*

*Andreas Stöckl, Joel Nitu* | **Category: cs.IR** | **Updated: 2025-07-15**

**Keywords:** AI代理, 在线广告, 结构化数据, 广告策略, 语言模型

**Comment:** 

> **TL;DR:** AI代理处理在线广告时，侧重于价格和关键词等结构化数据，而非忽视广告，这对未来的广告设计有重要影响。

**AI_Comments:** 这篇论文探讨了一个关于AI时代在线广告演变的重要且及时的话题。其创新之处在于直接考察了AI代理与广告的互动，而非假设其行为与人类相似。AI代理优先考虑结构化数据和关键词的发现是一项重要的见解，挑战了传统上侧重于视觉和情感吸引的广告设计。这对于需要调整策略以适应AI主导环境的广告商具有直接的实践意义。使用多种先进的多模态语言模型增加了实验设置的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI驱动的代理日益融入数字生态系统，它们正在重塑在线广告的感知和处理方式，尤其是在旅游和酒店预订领域。与人类用户受视觉和情感吸引不同，AI代理优先考虑价格、可用性和规格等结构化数据。本研究旨在探讨AI代理如何与在线广告互动，它们是否将广告纳入决策过程，以及哪种广告格式最有效。

**Method:** 通过与OpenAI GPT-4o、Anthropic Claude 3.7 Sonnet和Google Gemini 2.0 Flash等多模态语言模型进行的实验，分析AI代理的互动模式、点击行为和决策策略。

**Result:** 研究结果表明，AI代理既不忽视也不系统性地避免广告，而是偏爱某些特征，特别是关键词和结构化数据。

**Conclusion:** 这些发现对未来在AI主导的数字环境中设计广告策略具有重要意义。

> **ai_Abstract:** 本研究调查了AI代理如何与在线广告互动，特别是在旅游和酒店预订领域，AI代理优先考虑结构化数据而非以人为中心的线索。研究通过使用GPT-4o、Claude 3.7 Sonnet和Gemini 2.0 Flash等多模态语言模型进行实验，分析了AI代理与广告的互动模式、点击行为和决策策略。研究结果表明，AI代理并非忽视广告，而是更倾向于包含关键词和结构化数据的广告，这为AI主导数字环境中的未来广告策略提供了关键见解。

> **摘要翻译:** 随着AI驱动的代理日益融入数字生态系统，它们正在重塑在线广告的感知和处理方式。特别是在旅游和酒店预订领域，这些自主系统影响着传统广告格式的有效性。人类用户受视觉线索和情感诉求的影响，而AI代理则优先考虑价格、可用性和规格等结构化数据。本研究探讨了不同的AI代理如何与在线广告互动，它们是否将广告纳入其决策过程，以及哪种广告格式最有效。我们通过与OpenAI GPT-4o、Anthropic Claude 3.7 Sonnet和Google Gemini 2.0 Flash等多模态语言模型进行的实验，分析了互动模式、点击行为和决策策略。我们的研究结果表明，AI代理既不忽视也不系统性地避免广告，而是偏爱某些特征——特别是关键词和结构化数据。这些见解对未来在AI主导的数字环境中设计广告策略具有重要意义。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [215] [Alleviating User-Sensitive bias with Fair Generative Sequential Recommendation Model](https://arxiv.org/abs/2506.19777)
> *用公平生成式序列推荐模型缓解用户敏感偏见*

*Yang Liu, Feng Wu, Xuefang Zhu* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 推荐公平性, 扩散模型, 序列推荐, 用户敏感偏见, 生成模型

**Comment:** 

> **TL;DR:** 本文提出FairGENRec，一个基于扩散模型的公平生成式序列推荐模型，通过注入去偏见的多兴趣信息，有效缓解用户敏感偏见，同时提升推荐准确性和公平性。

**AI_Comments:** 这项研究创新性地将扩散模型应用于缓解推荐系统中的用户敏感偏见问题，利用了DM在建模不确定性和多样性方面的优势。通过在训练阶段注入去偏见信息，模型能够有效学习公平的表示，同时保持推荐精度。其方法论对未来的公平推荐系统研究提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 推荐公平性受到广泛关注，因为推荐系统容易捕获用户敏感特征（如性别、年龄）的强相关偏好，从而导致推荐不公平。扩散模型在推荐系统中表现出色，其建模不确定性和多样性的能力与现实世界中存在偏见的推荐过程高度适应，因此被用于解决推荐公平性问题。

**Method:** 本文提出了FairGENRec模型，一个基于扩散模型的公平生成式序列推荐模型。在训练阶段，模型在敏感特征识别模型的指导下向原始分布注入随机噪声，并设计序列去噪模型进行项目逆向重建。同时，通过向生成结果注入消除用户敏感特征偏见的多兴趣表示信息来完成推荐公平性建模。在推理阶段，模型利用历史交互获取噪声，并通过逆向迭代重建目标项目表示。

**Result:** 在三个数据集上的广泛实验证明了FairGENRec在准确性和公平性方面的双重提升效果，并通过案例的统计分析可视化了推荐公平性的改进程度。

**Conclusion:** FairGENRec模型能够有效缓解用户敏感偏见，同时提升推荐准确性和公平性，表明扩散模型在解决推荐公平性问题上的潜力。

> **ai_Abstract:** 本文针对推荐系统中用户敏感特征导致的偏见问题，提出了一种基于扩散模型（DM）的公平生成式序列推荐模型FairGENRec。该模型在训练阶段通过注入随机噪声和去偏见的多兴趣表示来建模公平性，并在推理阶段利用历史交互进行项目重建。实验结果表明，FairGENRec在提高推荐准确性的同时，显著增强了推荐公平性。

> **摘要翻译:** 推荐公平性最近受到了广泛关注。在现实世界中，推荐系统由用户行为驱动，由于具有相同敏感特征（例如，性别和年龄）的用户倾向于具有相同的模式，推荐模型很容易捕获敏感特征的强相关偏好，从而导致推荐不公平。扩散模型（DM）作为一种新的生成模型范式，在推荐系统中取得了巨大成功。DM建模不确定性和表示多样性的能力，以及其建模机制与现实世界中存在偏见的推荐过程具有高度适应性。因此，我们使用DM来有效建模推荐的公平性并增强多样性。本文提出了一种基于DM的公平生成式序列推荐模型FairGENRec。在训练阶段，我们在敏感特征识别模型的指导下向原始分布注入随机噪声，并设计了一个序列去噪模型用于项目的逆向重建。同时，通过向生成结果注入消除用户敏感特征偏见的多兴趣表示信息来完成推荐公平性建模。在推理阶段，模型通过使用历史交互获取噪声（以噪声添加的形式），然后进行逆向迭代以重建目标项目表示。最后，我们在三个数据集上的广泛实验证明了FairGENRec在准确性和公平性方面的双重增强效果，同时案例的统计分析可视化了推荐公平性的改进程度。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [664] [Extracting Document Relations from Search Corpus by Marginalizing over User Queries](https://arxiv.org/abs/2507.10726)
> *通过对用户查询进行边缘化从搜索语料库中提取文档关系*

*Yuki Iwamoto, Kaoru Tsunoda, Ken Kaneiwa* | **Category: cs.IR, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 文档关系提取, 查询边缘化, 搜索语料库, MC-RAG, 知识发现

**Comment:** 9 pages, 6 figures

> **TL;DR:** EDR-MQ是一种新颖的框架，通过查询边缘化来发现文档关系，无需手动标注或预定义分类法。

**AI_Comments:** EDR-MQ通过利用用户查询的隐式信息来发现文档关系，避免了对人工标注和预定义分类法的依赖，这是一个显著的创新点。其核心思想——通过查询边缘化来估计文档共现概率，以及为此开发的MC-RAG方法，为大规模知识发现和信息组织提供了新的视角和实用方案。该方法能够揭示传统相似性方法无法捕捉的深层关系，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在大规模语料库中理解文档之间的关系对于知识发现和信息组织至关重要。然而，现有方法严重依赖手动标注或预定义的关系统一分类法。

**Method:** 本文提出了EDR-MQ（通过对用户查询进行边缘化提取文档关系），这是一种通过查询边缘化发现文档关系的新颖框架。EDR-MQ基于以下洞察：强相关文档在不同用户查询的结果中经常共同出现，从而可以通过对查询集合进行边缘化来估计文档对之间的联合概率。为了实现这种查询边缘化方法，我们开发了多条件检索增强生成（MC-RAG），它采用条件检索，其中后续文档检索取决于先前检索到的内容。

**Result:** 实验结果表明，我们的查询边缘化方法成功识别了有意义的文档关系，揭示了传统基于相似性的方法无法发现的主题簇、证据链和跨领域连接。

**Conclusion:** 我们的查询驱动框架提供了一种实用的文档组织方法，能够适应不同的用户视角和信息需求。

> **ai_Abstract:** 本文提出EDR-MQ框架，通过对大量用户查询进行边缘化来自动发现文档间的关系。该方法基于文档在不同查询结果中共同出现的频率来估计其联合概率，无需人工标注或预设分类。为此，作者开发了多条件检索增强生成（MC-RAG）技术。实验证明EDR-MQ能有效识别传统方法难以发现的主题簇、证据链和跨领域联系，提供了一种适应性强的文档组织方式。

> **摘要翻译:** 在大规模语料库中理解文档之间的关系对于知识发现和信息组织至关重要。然而，现有方法严重依赖手动标注或预定义的关系统一分类法。我们提出了EDR-MQ（通过对用户查询进行边缘化提取文档关系），这是一种通过查询边缘化发现文档关系的新颖框架。EDR-MQ基于以下洞察：强相关文档在不同用户查询的结果中经常共同出现，从而可以通过对查询集合进行边缘化来估计文档对之间的联合概率。为了实现这种查询边缘化方法，我们开发了多条件检索增强生成（MC-RAG），它采用条件检索，其中后续文档检索取决于先前检索到的内容。通过观察不同查询中的共现模式，EDR-MQ无需标记训练数据或预定义分类法即可估计文档对之间的联合概率。实验结果表明，我们的查询边缘化方法成功识别了有意义的文档关系，揭示了传统基于相似性的方法无法发现的主题簇、证据链和跨领域连接。我们的查询驱动框架提供了一种实用的文档组织方法，能够适应不同的用户视角和信息需求。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [713] [LLM-Driven Dual-Level Multi-Interest Modeling for Recommendation](https://arxiv.org/abs/2507.10917)
> *推荐系统中基于LLM的双层多兴趣建模*

*Ziyan Wang, Yingpeng Du, Zhu Sun, Jieyi Bi, Haoyan Chua, Tianjun Wei, Jie Zhang* | **Category: cs.IR** | **Updated: 2025-07-15**

**Keywords:** 大语言模型, 多兴趣建模, 推荐系统, 双层框架, 对比学习

**Comment:** 10 pages, 5 figures

> **TL;DR:** 提出一种基于LLM的双层多兴趣建模框架，解决了现有方法启发式假设和LLM在多兴趣建模中的粒度不确定性及数据稀疏性问题，提升了推荐效果。

**AI_Comments:** 这篇论文通过引入LLM并设计双层建模（个体与群体），巧妙地解决了传统多兴趣建模的启发式局限性以及LLM在应用中面临的粒度控制和数据稀疏性挑战。其创新之处在于结合了LLM的语义理解能力与传统协同过滤的全局信息，并通过最大覆盖问题和对比学习进一步优化了兴趣表示。这种结合有望为个性化推荐带来显著提升。

<details>
  <summary>Details</summary>

**Motivation:** 现有推荐系统中的多兴趣建模方法常依赖启发式假设，未能准确捕捉用户在真实场景中的多兴趣。尽管大语言模型（LLMs）在多兴趣分析方面潜力巨大，但面临粒度不确定（过细或过粗）和个体用户数据稀疏导致洞察力有限两大挑战。

**Method:** 提出一个LLM驱动的双层多兴趣建模框架。在用户个体层面，利用LLM将用户交互项目灵活分配到不同语义簇以表示多样兴趣，并通过对齐模块将语义簇自适应地与从全局用户-项目交互中学习到的协同多兴趣对齐，以自动调整粒度。在用户群体层面，聚合用户群组为合成用户，以丰富行为进行更全面的LLM驱动的多兴趣分析，并通过最大覆盖问题确保合成用户行为的紧凑性和代表性，基于其LLM驱动的多兴趣进行对比学习，以解耦不同兴趣间的项目表示。

**Result:** 在真实世界数据集上的实验表明，该方法优于最先进的方法。

**Conclusion:** 该研究成功提出了一种基于LLM的双层多兴趣建模框架，有效解决了现有方法的局限性以及LLM在多兴趣分析中面临的挑战，并通过实验验证了其在推荐系统中的优越性。

> **ai_Abstract:** 本文提出了一种创新的LLM驱动双层多兴趣建模框架，旨在克服现有推荐系统在捕捉用户真实多兴趣时的局限性以及LLM应用中的粒度不确定性和数据稀疏性问题。该框架在用户个体层面利用LLM进行语义聚类并结合全局协同兴趣调整粒度；在用户群体层面，通过聚合合成用户和对比学习来丰富行为并解耦兴趣表示。实验证明其在推荐效果上优于现有方法。

> **摘要翻译:** 标题翻译：推荐系统中基于LLM的双层多兴趣建模
摘要翻译：近年来，人们投入大量精力基于用户行为或辅助信号来建模用户的多兴趣。然而，现有方法往往依赖启发式假设，例如共同出现的物品表示用户的相同兴趣，未能捕捉与现实场景相符的用户多兴趣。尽管大语言模型（LLMs）因其广泛的知识和强大的推理能力在多兴趣分析方面显示出巨大潜力，但仍存在两个关键挑战。首先，LLM驱动的多兴趣的粒度是不可知的，可能导致兴趣分组过细或过粗。其次，由于数据稀疏性问题，个体用户分析提供的洞察力有限。
在本文中，我们提出了一种LLM驱动的双层多兴趣建模框架，以实现更有效的推荐。在用户个体层面，我们利用LLMs将用户参与的物品灵活地分配到不同的语义簇中，以表示其多样且独特的兴趣。为了缓解LLMs不可知的生成，我们通过一个对齐模块，将这些语义簇自适应地分配给从全局用户-物品交互中学习到的用户协同多兴趣，从而允许粒度根据用户行为自动调整。为了缓解个体用户行为带来的有限洞察力，在用户群体层面，我们建议将用户群组聚合为具有丰富行为的合成用户，以进行更全面的LLM驱动的多兴趣分析。我们提出了一个最大覆盖问题，以确保合成用户行为的紧凑性和代表性，然后基于其LLM驱动的多兴趣进行对比学习，以解耦不同兴趣之间的物品表示。在真实世界数据集上的实验表明，我们的方法优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [755] [Unraveling the Biomarker Prospects of High-Altitude Diseases: Insights from Biomolecular Event Network Constructed using Text Mining](https://arxiv.org/abs/2507.10953)
> *高原疾病生物标志物前景的揭示：基于文本挖掘构建的生物分子事件网络的见解*

*Balu Bhasuran, Sabenabanu Abdulkadhar, Jeyakumar Natarajan* | **Category: cs.IR, q-bio.QM** | **Updated: 2025-07-15**

**Keywords:** 高原疾病, 生物标志物, 文本挖掘, 生物分子网络, PageRank算法

**Comment:** 

> **TL;DR:** 本研究利用文本挖掘和图分析构建生物分子事件网络，揭示了高原疾病的关键生物分子和机制，并识别了潜在的生物标志物。

**AI_Comments:** 这项研究创新性地将大规模文本挖掘与图分析相结合，用于揭示复杂疾病的分子机制和潜在生物标志物，为高原疾病的研究提供了新的视角和方法。这种数据驱动的方法有助于系统性地整合现有知识，并识别出传统实验方法可能难以发现的关键分子。

<details>
  <summary>Details</summary>

**Motivation:** 高原疾病（HAD），包括急性高原反应（AMS）、高原脑水肿（HACE）和高原肺水肿（HAPE），由海拔2,500米以上低压缺氧引起，对健康构成重大风险，但其分子机制尚不清楚。

**Method:** 开发了一个生物分子事件提取流程，该流程整合了监督机器学习、基于特征和多尺度拉普拉斯图核，用于分析PubMed中7,847篇高原疾病相关摘要。提取了超过150个独特的生物分子事件，并构建了一个加权、无向的生物分子事件网络，包含97个节点和153条边。使用PageRank算法根据中心性优先排序关键生物分子，并进行了子网络分析。

**Result:** 构建的生物分子事件网络揭示了关键生物分子，包括EPO、VEGF、HIF-1α、EPAS1、ACE、EGLN1、ET-1和Hsp70，它们在氧感知、血管重塑、红细胞生成和血压调节中发挥关键作用。子网络分析揭示了三个主要功能簇，分别以缺氧反应、炎症和应激适应通路为中心。

**Conclusion:** 本研究的综合方法证明了大规模文本挖掘和基于图的分析在揭示高原疾病的机制见解和优先排序潜在生物标志物方面的效用。

> **ai_Abstract:** 本研究旨在揭示高原疾病的分子机制和潜在生物标志物。通过整合监督机器学习和图核的生物分子事件提取流程，分析了7,847篇PubMed摘要，构建了一个生物分子事件网络。该网络揭示了EPO、VEGF、HIF-1α等关键蛋白在氧感知、血管重塑、红细胞生成和血压调节方面的作用，并通过子网络分析识别了缺氧反应、炎症和应激适应等功能簇。研究结果表明，大规模文本挖掘和图分析是发现高原疾病机制和生物标志物的有效方法。

> **摘要翻译:** 高原疾病（HAD），包括急性高原反应（AMS）、高原脑水肿（HACE）和高原肺水肿（HAPE），由海拔2,500米以上低压缺氧引起。这些疾病构成重大的健康风险，但其分子机制仍未得到充分理解。在本研究中，我们开发了一个生物分子事件提取流程，该流程整合了监督机器学习与基于特征和多尺度拉普拉斯图核，分析了PubMed中7,847篇精选的HAD相关摘要。我们提取了超过150个独特的生物分子事件，包括基因表达、调控、结合和定位，并构建了一个包含97个节点和153条边的加权、无向生物分子事件网络。使用PageRank算法，我们根据其在事件网络中的中心性优先排序了关键生物分子。排名靠前的蛋白包括促红细胞生成素（EPO）（0.0163）、血管内皮生长因子（VEGF）（0.0148）、缺氧诱导因子1（HIF-1）α（0.0136）、内皮PAS结构域蛋白1（EPAS1）和血管紧张素转换酶（ACE）（0.0119）、Egl九同源物1（EGLN1）、内皮素1（ET-1）和70千道尔顿热休克蛋白（Hsp70）（0.0118），所有这些都在氧感知、血管重塑、红细胞生成和血压调节中发挥关键作用。子网络分析揭示了三个主要功能簇，分别以缺氧反应、炎症和应激适应通路为中心。我们的综合方法证明了大规模文本挖掘和基于图的分析在揭示高原疾病的机制见解和优先排序潜在生物标志物方面的效用。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [789] [Overview of the TREC 2022 deep learning track](https://arxiv.org/abs/2507.10865)
> *TREC 2022 深度学习赛道概述*

*Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, Jimmy Lin, Ellen M. Voorhees, Ian Soboroff* | **Category: cs.IR, cs.AI, cs.CL** | **Updated: 2025-07-10**

**Keywords:** TREC 2022, 深度学习, 信息检索, 段落检索, 密集检索

**Comment:** arXiv admin note: substantial text overlap with arXiv:2507.08191,
  arXiv:2507.08890

> **TL;DR:** TREC 2022深度学习赛道继续使用大规模数据集，主要关注构建更完善的段落检索测试集。深度神经网络模型仍优于传统方法，但今年的密集检索表现有所意外。

**AI_Comments:** 这篇概述性文章展示了TREC深度学习赛道在构建大规模、高质量信息检索测试集方面的持续努力，特别是对段落检索任务的重视。其创新之处在于数据集的持续扩展和对评判质量的严格控制。重要性在于为深度学习在信息检索领域的进步提供了基准和洞察。文章也指出了深度检索方法发展中的新趋势和挑战，例如密集检索表现的波动，这对于未来研究具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在概述TREC 2022深度学习赛道，该赛道旨在评估深度学习模型在信息检索任务中的表现，并构建高质量的测试集以区分不同运行结果并支持未来研究。

**Method:** 赛道利用MS MARCO数据集，包含大量人工标注的训练标签。2022年，赛道使用了刷新后的段落和文档集合（大小显著增加），主要精力集中在构建更完整的段落检索测试集，文档排序作为次要任务，其标签从段落级别推断。

**Result:** 深度神经网络排序模型（采用大规模预训练）继续优于传统检索方法。由于评判资源集中于段落评判，查询和判断的质量更高。然而，出现了一些意外结果，例如一些表现最佳的运行并未采用密集检索，且单阶段密集检索的竞争力不如去年。

**Conclusion:** TREC 2022深度学习赛道成功构建了更高质量的段落检索测试集，并确认了深度学习模型在信息检索中的持续优势，同时也揭示了密集检索方法的一些新趋势和挑战。

> **ai_Abstract:** TREC 2022深度学习赛道是其第四届，继续利用大规模MS MARCO数据集，并引入了显著增大的刷新数据集。本届赛道主要聚焦于构建高质量的段落检索测试集，而文档排序则为次要任务。研究结果显示，深度神经网络模型在性能上持续超越传统方法。值得注意的是，一些顶级表现的系统并未采用密集检索，且单阶段密集检索的竞争力有所下降，这与往年有所不同。

> **摘要翻译:** 这是TREC深度学习赛道的第四年。与往年一样，我们利用MS MARCO数据集，该数据集为段落和文档排序任务提供了数十万个人工标注的训练标签。此外，今年我们还利用了去年发布的刷新后的段落和文档集合，导致段落集合的大小增加了近16倍，文档集合的大小增加了近4倍。与往年不同的是，2022年我们主要专注于构建一个更完整的段落检索任务测试集合，这是该赛道的主要重点。文档排序任务被保留为次要任务，其中文档级别的标签是从段落级别的标签推断出来的。我们的分析表明，与往年类似，采用大规模预训练的深度神经网络排序模型继续优于传统检索方法。由于我们将评判资源集中在段落评判上，我们对今年的查询和判断质量更有信心，这有助于我们区分不同运行结果并在未来重用数据集。我们还在总体结果中看到了一些意外。一些表现最佳的运行并未进行密集检索。进行单阶段密集检索的运行今年不如去年有竞争力。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [797] [Aligned Query Expansion: Efficient Query Expansion for Information Retrieval through LLM Alignment](https://arxiv.org/abs/2507.11042)
> *对齐查询扩展：通过LLM对齐实现信息检索的高效查询扩展*

*Adam Yang, Gustavo Penha, Enrico Palumbo, Hugues Bouchard* | **Category: cs.IR** | **Updated: 2025-07-15**

**Keywords:** 查询扩展, LLM对齐, 信息检索, AQE, 大型语言模型

**Comment:** 

> **TL;DR:** 本文提出了一种名为AQE的新方法，通过LLM对齐直接优化查询生成，以提高信息检索中的查询扩展效率和效果，无需额外的过滤步骤。

**AI_Comments:** 本文的创新点在于将LLM对齐技术应用于查询扩展领域，解决了传统“生成-过滤”模式的效率低下和次优查询问题。通过直接优化LLM生成与检索任务相关的查询，AQE不仅提高了检索效率，还降低了计算成本，为信息检索领域提供了一个更高效、更精准的查询扩展解决方案。其重要性在于，它展示了LLM在信息检索中从辅助生成到直接优化核心任务的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于大型语言模型（LLMs）的查询生成技术在信息检索中用于查询扩展时，常产生次优查询（包括幻觉），且“先生成后过滤”的方法成本高昂，未能有效指导LLM生成更有效的查询。

**Method:** 本文提出了一种新颖的方法——对齐查询扩展（AQE），通过利用LLM对齐的最新技术来微调模型，使其生成的查询扩展直接优化检索任务的有效性，从而消除了对额外过滤步骤的需求。

**Result:** 实证评估表明，AQE在域内和域外设置中均优于基线查询扩展模型，显著提高了检索效率。

**Conclusion:** AQE通过直接优化检索任务的有效性，提升了查询扩展能力，减少了计算成本，同时提高了检索效率。

> **ai_Abstract:** 本文提出了一种名为对齐查询扩展（AQE）的新型方法，旨在通过利用大型语言模型（LLMs）的对齐技术，直接优化查询生成以提升信息检索中的查询扩展效果。传统方法常面临生成次优查询和高成本的过滤问题。AQE通过微调LLM，使其生成的查询扩展直接服务于检索任务的有效性，从而无需额外的过滤步骤，显著降低了计算成本并提高了检索性能。实验结果表明，AQE在不同领域设置下均优于现有基线模型。

> **摘要翻译:** 随着大型语言模型（LLMs）的突破，通过相关术语扩展文档和查询的查询生成技术在信息检索领域变得越来越流行。此类技术已被证明通过解决词汇不匹配问题，提高了传统词法检索方法的有效性。最近的研究发现，使用贪婪解码策略生成查询可能会产生次优查询，包括幻觉，并建议在扩展之前过滤查询。这种“先生成后过滤”的方法成本高昂，因为它需要生成多个查询并对所有查询应用相关性模型，并且没有教会LLM哪些生成的查询对于扩展更有效。为了克服这些限制，我们提出了对齐查询扩展（AQE），这是一种新颖的方法，用于增强开放域问答中的段落检索的查询扩展。AQE利用LLM对齐的最新技术来微调模型，使其生成的查询扩展直接优化检索任务的有效性，从而消除了对额外过滤步骤的需求。这种对齐确保了查询更具相关性，从而在提高检索效率的同时降低了计算成本。实证评估表明，AQE在域内和域外设置中均优于基线查询扩展模型，显著提高了检索效率。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [28] [Tangma: A Tanh-Guided Activation Function with Learnable Parameters](https://arxiv.org/abs/2507.10560)
> *Tangma：一种带可学习参数的Tanh引导激活函数*

*Shreel Golwala* | **Category: cs.NE, cs.LG** | **Updated: 2025-07-02**

**Keywords:** 激活函数, 深度学习, 可学习参数, Tangma, 神经网络

**Comment:** 

> **TL;DR:** Tangma是一种新型激活函数，结合了tanh的平滑性和两个可学习参数，在MNIST和CIFAR-10上表现出更高的准确性、更快的收敛速度和更好的训练效率。

**AI_Comments:** Tangma的创新之处在于其引入了可学习参数\\alpha和\\gamma，使得激活函数能够自适应地调整其形状以优化神经元激活行为和梯度流。这种设计增强了模型对训练数据的适应性，并有效解决了传统激活函数在梯度消失/爆炸或收敛稳定性方面的问题。其在标准视觉任务上的优异表现，特别是更高的准确性和训练效率，凸显了其在深度学习领域的潜在重要性。未来，这种可学习的激活函数有望在更复杂的模型和任务中展现出更大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 激活函数是深度神经网络中有效反向传播和表达能力的关键。本研究的动机是引入一种新的激活函数（Tangma），以期结合双曲正切函数的平滑形状与可学习参数，从而改善神经元激活的调整、保留弱梯度并提高训练稳定性。

**Method:** 本研究引入了一种名为Tangma的新型激活函数，它结合了双曲正切函数的平滑形状和两个可学习参数：$\\alpha$（用于移动曲线拐点以调整神经元激活）和$\\gamma$（用于增加线性度以保留弱梯度并提高训练稳定性）。Tangma在MNIST和CIFAR-10数据集上使用由卷积层和线性层组成的自定义网络进行了评估，并与ReLU、Swish和GELU进行了比较。

**Result:** 在MNIST数据集上，Tangma达到了99.09%的最高验证准确率和最低的验证损失，表现出比基线更快、更稳定的收敛。在CIFAR-10数据集上，Tangma达到了78.15%的最高验证准确率，优于所有其他激活函数，同时保持了有竞争力的训练损失。Tangma还显示出更高的训练效率，与Swish和GELU相比，平均每epoch运行时间更短。

**Conclusion:** Tangma在标准视觉任务上表现良好，并能实现可靠、高效的训练。其可学习的设计提供了对激活行为的更多控制，这可能有利于图像识别或语言建模等任务中的大型模型。

> **ai_Abstract:** 本文介绍了一种名为Tangma的新型激活函数，它结合了双曲正切函数的平滑性与两个可学习参数：\\alpha用于调整激活拐点，\\gamma用于增加线性度以提高训练稳定性。在MNIST和CIFAR-10数据集上的评估结果显示，Tangma在准确性、收敛速度和训练效率方面均优于ReLU、Swish和GELU等基线激活函数。研究表明，Tangma在标准视觉任务上表现出色，并能实现可靠高效的训练，其可学习设计有望在大型模型中发挥更大作用。

> **摘要翻译:** 激活函数是深度神经网络中有效反向传播和表达能力的关键。这项工作引入了Tangma，这是一种新型激活函数，它结合了双曲正切函数的平滑形状和两个可学习参数：\\alpha，用于移动曲线拐点以调整神经元激活；\\gamma，用于增加线性度以保留弱梯度并提高训练稳定性。Tangma在由卷积层和线性层组成的自定义网络上，针对MNIST和CIFAR-10数据集进行了评估，并与ReLU、Swish和GELU进行了比较。在MNIST上，Tangma实现了99.09%的最高验证准确率和最低的验证损失，显示出比基线更快、更稳定的收敛。在CIFAR-10上，Tangma达到了78.15%的最高验证准确率，优于所有其他激活函数，同时保持了有竞争力的训练损失。Tangma还显示出更高的训练效率，与Swish和GELU相比，平均每epoch运行时间更短。这些结果表明，Tangma在标准视觉任务上表现良好，并能实现可靠、高效的训练。其可学习的设计提供了对激活行为的更多控制，这可能有利于图像识别或语言建模等任务中的大型模型。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [70] [SFATTI: Spiking FPGA Accelerator for Temporal Task-driven Inference -- A Case Study on MNIST](https://arxiv.org/abs/2507.10561)
> *SFATTI: 面向时间任务驱动推理的脉冲FPGA加速器——以MNIST为例*

*Alessio Caviglia, Filippo Marostica, Alessio Carpegna, Alessandro Savino, Stefano Di Carlo* | **Category: cs.NE, cs.CV** | **Updated: 2025-07-04**

**Keywords:** 脉冲神经网络, FPGA, 硬件加速器, 边缘计算, MNIST

**Comment:** 

> **TL;DR:** 本文介绍了SFATTI，一个用于时间任务驱动推理的脉冲神经网络（SNN）FPGA加速器，通过Spiker+框架在MNIST数据集上进行了案例研究。

**AI_Comments:** 该论文通过利用SNN和FPGA解决了边缘AI对高效硬件的需求。Spiker+框架的使用是一个显著的创新点，简化了SNN加速器的设计和部署。对边缘计算权衡的关注具有实际意义和相关性。

<details>
  <summary>Details</summary>

**Motivation:** 硬件加速器对于图像识别等边缘应用中的低延迟、高能效推理至关重要。脉冲神经网络（SNNs）因其事件驱动和时间稀疏特性，特别适合低功耗FPGA部署。

**Method:** 本文使用开源的Spiker+框架来生成用于MNIST数据集手写数字识别的优化SNN加速器。Spiker+支持网络拓扑、神经元模型和量化的高级规范，并自动生成可部署的HDL。研究评估了多种配置。

**Result:** 论文评估了多种配置，并分析了与边缘计算约束相关的权衡。

**Conclusion:** 本文评估了SNN在FPGA上部署的多种配置，并分析了其在边缘计算约束下的权衡，展示了SNN在FPGA上实现高效推理的潜力。

> **ai_Abstract:** 本文介绍了SFATTI，一个为边缘应用中低延迟、高能效推理设计的脉冲神经网络（SNN）FPGA加速器。该研究以MNIST手写数字识别为例，利用开源Spiker+框架生成优化的SNN加速器，该框架允许高级别指定网络参数并自动生成HDL。研究评估了多种配置，并分析了与边缘计算约束相关的权衡。

> **摘要翻译:** 硬件加速器对于实现图像识别等边缘应用中的低延迟、高能效推理至关重要。脉冲神经网络（SNNs）由于其事件驱动和时间稀疏的特性而特别有前景，使其非常适合基于低功耗现场可编程门阵列（FPGA）的部署。本文探讨了使用开源Spiker+框架为MNIST数据集上的手写数字识别生成优化的SNN加速器。Spiker+支持网络拓扑、神经元模型和量化的高级规范，自动生成可部署的HDL。我们评估了多种配置，并分析了与边缘计算约束相关的权衡。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [112] [An Exact Gradient Framework for Training Spiking Neural Networks](https://arxiv.org/abs/2507.10568)
> *用于训练脉冲神经网络的精确梯度框架*

*Arman Ferdowsi, Atakan Aral* | **Category: cs.NE** | **Updated: 2025-07-08**

**Keywords:** 脉冲神经网络, 精确梯度, 事件驱动学习, 突触延迟, 放电阈值

**Comment:** 

> **TL;DR:** 本文提出了一种分析事件驱动学习框架，用于计算脉冲神经网络的精确损耗梯度，从而在准确性、时间精度和鲁棒性方面取得显著提升。

**AI_Comments:** 这项工作具有重要意义，因为它通过提供一个计算精确梯度的框架，解决了脉冲神经网络训练中的核心挑战，即现有方法对训练精度和效率的限制以及对硬件实现造成的障碍。其创新点在于提出了一种分析性的事件驱动方法，能够精确地处理多种生物启发参数（权重、延迟、阈值），而不仅仅是依赖近似。这不仅提升了SNN的性能，也为未来神经形态硬件的有效部署铺平了道路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的脉冲神经网络训练方法依赖于离散时间模拟、替代梯度近似或完全访问内部状态变量，这限制了训练精度和效率，并因增加内存和I/O带宽需求而对神经形态硬件实现构成挑战。

**Method:** 本文提出了一种分析事件驱动的学习框架，该框架不仅能计算相对于突触权重和传输延迟的精确损耗梯度，还能计算相对于自适应神经元放电阈值的精确损耗梯度。

**Result:** 在多个基准测试中，与现有方法相比，该框架在准确性（高达7%）、时间精度和鲁棒性方面取得了显著提升。

**Conclusion:** 通过提出一种计算精确梯度的分析事件驱动学习框架，可以有效克服现有SNN训练方法的局限性，显著提高SNN的性能和硬件实现潜力。

> **ai_Abstract:** 本文针对脉冲神经网络（SNNs）训练中现有方法在精度、效率及硬件实现方面的局限性，提出了一种创新的分析事件驱动学习框架。该框架能够计算突触权重、传输延迟以及自适应神经元放电阈度的精确损耗梯度。实验结果表明，与现有方法相比，该方法在准确性、时间精度和鲁棒性上均有显著提升，解决了SNN训练中的关键挑战。

> **摘要翻译:** 脉冲神经网络本质上依赖于离散脉冲事件的精确时序进行信息处理。结合额外的生物启发自由度，例如可训练的突触传输延迟和自适应放电阈值，对于充分利用SNN的时间动力学至关重要。尽管最近的方法已经证明了训练突触权重和延迟在准确性和时间表示方面的益处，但这些技术通常依赖于离散时间模拟、替代梯度近似或完全访问内部状态变量，例如膜电位。这些要求限制了训练精度和效率，并由于增加的内存和I/O带宽需求而对神经形态硬件实现提出了挑战。为了克服这些挑战，我们提出了一种分析事件驱动的学习框架，该框架不仅能计算相对于突触权重和传输延迟的精确损耗梯度，还能计算相对于自适应神经元放电阈值的精确损耗梯度。在多个基准测试中进行的实验表明，与现有方法相比，该框架在准确性（高达7%）、时间精度和鲁棒性方面取得了显著提升。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [164] [Biological Processing Units: Leveraging an Insect Connectome to Pioneer Biofidelic Neural Architectures](https://arxiv.org/abs/2507.10951)
> *生物处理单元：利用昆虫连接组开创生物忠实神经架构*

*Siyu Yu, Zihan Qin, Tingshan Liu, Beiya Xu, R. Jacob Vogelstein, Jason Brown, Joshua T. Vogelstein* | **Category: cs.NE, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 生物处理单元, 连接组, 果蝇幼虫, 神经网络, 生物忠实架构

**Comment:** Accepted to AGI 2025

> **TL;DR:** 该研究将果蝇幼虫的大脑连接组转换为生物处理单元（BPU），并展示了这种生物忠实神经网络在图像分类和国际象棋等复杂任务上的卓越性能，超越了尺寸匹配的传统AI模型。

**AI_Comments:** 这项研究的创新之处在于直接将生物连接组转化为可用于AI任务的神经网络架构，而非仅仅是受生物启发。它不仅证明了这种生物忠实网络在性能上超越了许多传统AI模型，尤其是在参数效率和训练数据需求方面，而且为未来开发更高效、更强大的AI系统提供了新的方向。其局限性可能在于目前仅限于果蝇幼虫这种相对简单的生物体，未来扩展到更复杂的生物体连接组可能面临数据获取和计算资源的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在探索生物进化的电路是否能支持人工智能，并利用果蝇幼虫的完整连接组来开发新型神经网络架构。

**Method:** 研究将果蝇幼虫大脑的完整连接组转换为一个固定的循环网络，命名为生物处理单元（BPU）。通过结构化连接组扩展来扩展BPU，并进行特定模态的消融实验。在MNIST、CIFAR-10和ChessBench数据集上测试BPU、GNN-BPU和CNN-BPU模型的性能，并与MLP和Transformer等传统模型进行比较。

**Result:** 未修改的BPU在MNIST上达到98%的准确率，在CIFAR-10上达到58%，超过尺寸匹配的MLP。通过结构化连接组扩展的BPU进一步提升了CIFAR-10的性能。在ChessBench数据集上，轻量级GNN-BPU模型（仅训练10,000局游戏）实现了60%的走法准确率，比任何同尺寸Transformer模型好近10倍。参数量约2M的CNN-BPU模型优于参数量匹配的Transformer模型，并在推理时结合深度为6的Minimax搜索，达到91.7%的准确率，甚至超过了9M参数的Transformer基线。

**Conclusion:** 这些结果证明了生物忠实神经架构在支持复杂认知任务方面的潜力，并激励未来工作将其扩展到更大、更智能的连接组。

> **ai_Abstract:** 本研究利用果蝇幼虫的完整大脑连接组，构建了一种名为生物处理单元（BPU）的新型生物忠实神经网络。BPU即使规模较小，也在图像分类任务（MNIST和CIFAR-10）上表现出色，并优于传统MLP。通过结构化扩展，BPU性能进一步提升。在国际象棋任务上，基于BPU的GNN和CNN模型以更少的参数和训练数据，显著超越了同尺寸的Transformer模型。研究表明，生物忠实架构在复杂认知任务中具有巨大潜力。

> **摘要翻译:** 果蝇幼虫大脑的完整连接组为研究生物进化的电路是否能支持人工智能提供了独特的机会。我们将这种布线图转换为一个生物处理单元（BPU），一个直接源自突触连接的固定循环网络。尽管其规模适中（3,000个神经元和它们之间65,000个权重），但未修改的BPU在MNIST上达到了98%的准确率，在CIFAR-10上达到了58%，超越了尺寸匹配的多层感知器（MLP）。通过结构化连接组扩展来扩展BPU，进一步提高了CIFAR-10的性能，而特定模态的消融实验揭示了不同感觉子系统的不均匀贡献。在ChessBench数据集上，一个轻量级的GNN-BPU模型在仅训练10,000局游戏的情况下，实现了60%的走法准确率，比任何同尺寸的Transformer模型好近10倍。此外，参数量约为2M的CNN-BPU模型优于参数量匹配的Transformer模型，并在推理时结合深度为6的Minimax搜索，达到91.7%的准确率，甚至超过了9M参数的Transformer基线。这些结果证明了生物忠实神经架构在支持复杂认知任务方面的潜力，并激励未来工作将其扩展到更大、更智能的连接组。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [194] [Grammatical Structure and Grammatical Variations in Non-Metric Iranian Classical Music](https://arxiv.org/abs/2507.10708)
> *伊朗古典非节拍音乐的语法结构与语法变奏*

*Maziar Kanani, Sean O Leary, James McDermott* | **Category: cs.NE, cs.SD, eess.AS** | **Updated: 2025-07-14**

**Keywords:** 伊朗古典音乐, 非节拍音乐, 语法结构, 音乐变奏, 结构解析

**Comment:** 

> **TL;DR:** 本研究介绍了伊朗古典非节拍音乐的符号数据集、结构解析算法和变奏生成算法。系统成功生成了可接受的音乐变奏，且方法可推广至其他非西方古典音乐。

**AI_Comments:** 该研究的创新之处在于其专注于非节拍音乐的结构解析和变奏生成，填补了传统以小节为中心分析方法在处理此类音乐时的不足。其引入符号数据集和基于语法的变异生成方法，为音乐学研究和创作提供了新工具。该方法的普适性强，可推广至其他非西方古典音乐。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在分析伊朗古典非节拍音乐的结构，并生成其变奏。与西方音乐不同，这种非节拍音乐不遵循以小节为中心的组织方式，因此需要特定的解析算法来捕捉其非节拍组织。

**Method:** 研究引入了一个由伊朗古典非节拍音乐组成的符号数据集（Radif Mirza Abdollah的Dastgah Shour的MIDI文件和数据表）。应用先前引入的旋律结构解析算法（Kanani et al., 2023b）来将每个曲调（Gusheh）解析成语法，以识别主题和乐句。进一步发展了创建旋律变奏的方法（Kanani et al., 2023b），通过对解析出的语法进行变异来生成新的语法，进而扩展为原始曲调的变奏。变奏由领域专家听众评估。此外，还对不同表示设置下的解析和生成算法的变异进行了统计分析。

**Result:** 该系统在变异后成功生成了可接受的音乐变奏。

**Conclusion:** 该系统能够成功生成可接受的音乐变奏。尽管本研究的案例集中于伊朗古典音乐，但其方法可适用于阿拉伯或土耳其古典音乐。

> **ai_Abstract:** 本研究提出了一个用于伊朗古典非节拍音乐的符号数据集，并开发了用于结构解析和变奏生成的算法。研究将伊朗古典音乐的曲调解析为语法，以识别音乐元素，并在此基础上通过语法变异生成新的音乐变奏。经专家评估，该系统成功生成了可接受的变奏。该方法不仅适用于伊朗古典音乐，也具有推广到其他非西方古典音乐的潜力。

> **摘要翻译:** 在本研究中，我们引入了一个由伊朗古典非节拍音乐组成的符号数据集，以及用于这种音乐的结构解析算法和变奏生成算法。该语料库包含Radif Mirza Abdollah的Dastgah Shour的MIDI文件和数据表，这是伊朗古典音乐的基础曲目。此外，我们将我们先前引入的旋律结构解析算法（Kanani et al., 2023b）应用于该数据集。与许多西方音乐不同，这种非节拍音乐不遵循以小节为中心的组织方式。我们的解析算法可以很好地捕捉非节拍组织。我们将每个曲调（Gusheh）解析成语法，以识别主题和乐句。这些语法表示形式对于教育和民族音乐学目的可能很有用。我们还进一步开发了先前引入的创建旋律变奏的方法（Kanani et al., 2023b）。在将现有曲调解析以生成语法后，通过对该语法应用变异，我们生成了一个新语法。扩展这个新版本会产生原始曲调的一个变奏。变奏由领域专家听众评估。此外，我们对我们解析和生成算法的不同表示设置下的变异进行了统计分析。总体的结论是，该系统在变异后成功生成了可接受的变奏。虽然我们的案例研究侧重于伊朗古典音乐，但该方法可以适用于阿拉伯或土耳其古典音乐。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [220] [Continuous-Time Neural Networks Can Stably Memorize Random Spike Trains](https://arxiv.org/abs/2408.01166)
> *连续时间神经网络可以稳定记忆随机脉冲序列*

*Hugo Aguettaz, Hans-Andrea Loeliger* | **Category: cs.NE** | **Updated: 2025-07-15**

**Keywords:** 连续时间神经网络, 脉冲序列, 记忆, 循环神经网络, 神经动力学

**Comment:** 28 pages, 16 figures

> **TL;DR:** 连续时间循环神经网络能够通过离线计算的突触权重稳定地记忆和重现随机脉冲序列，并能进行关联回忆。

**AI_Comments:** 该研究展示了连续时间神经网络在记忆和重现精确计时脉冲序列方面的潜力，这对于理解和构建更复杂的神经系统模型具有重要意义。通过离线计算突触权重以确保时间稳定性是一个值得关注的方法。

<details>
  <summary>Details</summary>

**Motivation:** 探索连续时间循环神经网络存储和回忆精确计时脉冲序列的能力。

**Method:** 通过数值实验进行验证，并离线计算满足时间稳定性模板的突触权重。

**Result:** 在一定参数范围内，网络中所有神经元的任何随机脉冲序列都可以以接近1的概率被稳健地记忆并自主重现，且所有脉冲的相对时间准确稳定。在噪声条件下也能实现关联回忆。

**Conclusion:** 连续时间神经网络能够稳定地记忆和重现随机脉冲序列，并通过离线计算的突触权重实现时间稳定性。

> **ai_Abstract:** 本研究通过数值实验证明，连续时间循环神经网络能够稳定地记忆和高精度地重现随机脉冲序列。在特定参数下，网络能以高概率稳健地存储并自主复现所有神经元的随机脉冲序列，同时保持准确稳定的相对时间。此外，该网络在噪声环境下也展现了关联回忆能力。实验中，突触权重是离线计算的，以确保时间稳定性。

> **摘要翻译:** 本文探讨了连续时间循环神经网络存储和回忆精确计时脉冲序列的能力。我们通过数值实验表明，这是确实可行的：在一定参数范围内，网络中所有神经元的任何随机脉冲序列都可以以接近1的概率被稳健地记忆并自主重现，且所有脉冲的相对时间准确稳定。我们还展示了在噪声条件下的关联回忆。在这些实验中，所需的突触权重是离线计算的，以满足鼓励时间稳定性的模板。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [308] [A Biomimetic Way for Coral-Reef-Inspired Swarm Intelligence for Carbon-Neutral Wastewater Treatment](https://arxiv.org/abs/2507.10563)
> *珊瑚礁启发式群体智能在碳中和废水处理中的仿生方法*

*Antonis Messinis* | **Category: cs.NE, cs.AI** | **Updated: 2025-07-05**

**Keywords:** 仿生学, 珊瑚礁, 群体智能, 废水处理, 碳中和

**Comment:** 

> **TL;DR:** 本文提出一种受珊瑚礁启发的群体交互网络，用于碳中和废水处理，实现了高去除效率、低能耗和低碳排放，并在实际场景中显示出潜在的柴油节约。

**AI_Comments:** 本文创新性地将珊瑚礁的仿生概念引入废水处理领域，利用群体智能网络实现了碳中和目标，并在能耗和碳排放方面取得了显著优化。其可扩展性和在多种现场场景中的应用潜力是亮点。然而，论文也坦诚地指出了数据科学人员配备不足和未来AutoML集成可能带来的可解释性挑战，这体现了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 随着废水处理量的增加，实现能源中性净化面临挑战。

**Method:** 引入了一种受珊瑚礁启发的群体交互网络（Swarm Interaction Network），结合形态发生抽象和多任务碳感知，用于碳中和废水处理。该方法具有线性令牌复杂度的可扩展性。

**Result:** 与七种基线相比，该方法实现了96.7%的去除效率、0.31 kWh m$^{-3}$的能耗和14.2 g m$^{-3}$的CO$_2$排放。方差分析表明在传感器漂移下具有鲁棒性。在孤立泻湖、啤酒厂峰值和沙漠温室等现场场景中，显示出高达22%的潜在柴油节约。

**Conclusion:** 该仿生群体智能方法为实现碳中和废水处理提供了一种高效、低能耗、低排放的解决方案，并在实际应用中展现出显著潜力，尽管数据科学人员配备和可解释性仍是挑战。

> **ai_Abstract:** 本文提出了一种受珊瑚礁启发的群体交互网络（Swarm Interaction Network），旨在实现碳中和废水处理。该方法结合了形态发生抽象和多任务碳感知，通过线性令牌复杂度实现可扩展性。实验结果表明，与现有基线相比，该方法在去除效率、能耗和碳排放方面表现出色，并显示出在实际场景中节约能源的潜力。论文也指出了数据科学人员配备和可解释性方面的挑战。

> **摘要翻译:** 随着废水处理量的增加，实现能源中性净化面临挑战。我们引入了一种受珊瑚礁启发的群体交互网络，用于碳中和废水处理，结合了形态发生抽象和多任务碳感知。可扩展性源于线性令牌复杂度，缓解了能源去除问题。与七种基线相比，我们的方法实现了96.7%的去除效率、0.31 kWh m$^{-3}$的能耗和14.2 g m$^{-3}$的CO$_2$排放。方差分析表明在传感器漂移下具有鲁棒性。现场场景——孤立泻湖、啤酒厂高峰和沙漠温室——显示出高达22%的潜在柴油节约。然而，数据科学人员配备仍然是一个障碍。未来的工作将在项目范围内整合AutoML封装器，尽管治理限制带来了可解释性挑战，需要进一步的视觉分析。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [35] [Parallel subspace correction methods for semicoercive and nearly semicoercive convex optimization with applications to nonlinear PDEs](https://arxiv.org/abs/2412.17318)
> *半强制性和近半强制性凸优化的并行子空间校正方法及其在非线性偏微分方程中的应用*

*Young-Ju Lee, Jongho Park* | **Category: math.NA, cs.NA, math.OC, 65J20, 65N20, 65N55, 90C22, 90C25** | **Updated: 2025-07-15**

**Keywords:** 并行子空间校正, 半强制性凸优化, 近半强制性凸优化, 非线性偏微分方程, 收敛性分析

**Comment:** 31 pages, 0 figures

> **TL;DR:** 本文提出了针对无约束半强制性和近半强制性凸优化的并行子空间校正方法的新收敛性分析，将奇异和近奇异线性问题的理论推广到一类非线性问题，并应用于非线性偏微分方程。

**AI_Comments:** 该论文的创新之处在于将成熟的奇异和近奇异线性问题理论成功推广到更复杂的非线性凸优化问题中，这对于理解和改进相关数值算法具有重要意义。特别是其收敛性分析的严谨性以及与现有线性理论的对齐，展现了其理论深度。

<details>
  <summary>Details</summary>

**Motivation:** 将奇异和近奇异线性问题的理论框架推广到无约束半强制性和近半强制性凸优化问题，以分析其并行子空间校正方法的收敛性。

**Method:** 提出了针对无约束半强制性和近半强制性凸优化的并行子空间校正方法的新收敛性分析。对于半强制性问题，通过子空间上的半范数稳定分解和问题核来估计收敛率。对于近半强制性问题，假设半强制性部分的核可以分解为局部核的和，从而建立了参数独立的收敛率。将这些结果应用于求解具有Neumann边界条件的某些非线性偏微分方程的两级加性Schwarz方法。

**Result:** 研究结果表明，为奇异和近奇异线性问题开发的理论框架可以扩展到无约束半强制性和近半强制性凸优化问题。对于半强制性问题，收敛率可以根据子空间和问题核上的半范数稳定分解进行估计。对于近半强制性问题，在特定条件下建立了参数独立的收敛率。这些分析与奇异和近奇异线性问题的理论相符。

**Conclusion:** 为无约束半强制性和近半强制性凸优化的并行子空间校正方法提供了新的收敛性分析，成功地将奇异和近奇异线性问题的理论框架推广到非线性问题领域，并展示了其在求解非线性偏微分方程中的适用性。

> **ai_Abstract:** 本文提出了一套新的并行子空间校正方法收敛性分析，用于解决无约束的半强制性和近半强制性凸优化问题。研究成功将奇异和近奇异线性问题的理论框架推广至非线性问题领域，并详细阐述了两种类型问题的收敛率估计方法。此外，论文还通过分析非线性偏微分方程的两级加性Schwarz方法，展示了其理论结果的实际应用价值。

> **摘要翻译:** 我们提出了无约束半强制性和近半强制性凸优化的并行子空间校正方法的新收敛性分析，将奇异和近奇异线性问题的理论推广到一类非线性问题。我们的结果表明，为奇异和近奇异线性问题开发的精美理论框架可以扩展到无约束半强制性和近半强制性凸优化问题。对于半强制性问题，我们展示了收敛率可以根据子空间和问题核上的半范数稳定分解进行估计，这与奇异线性问题的理论相符。对于近半强制性问题，我们建立了参数独立的收敛率，假设半强制性部分的核可以分解为局部核的和，这与近奇异问题的理论相符。为了证明我们结果的适用性，我们在所提出的抽象框架内，提供了求解具有Neumann边界条件的某些非线性偏微分方程的两级加性Schwarz方法的收敛性分析。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [71] [Error estimation for quasi-Monte Carlo](https://arxiv.org/abs/2501.00150)
> *准蒙特卡洛误差估计*

*Art B. Owen* | **Category: math.NA, cs.NA, stat.CO** | **Updated: 2025-07-15**

**Keywords:** 准蒙特卡洛, 误差估计, 不确定性量化, 置信区间, 对称分布

**Comment:** 

> **TL;DR:** 准蒙特卡洛采样比普通蒙特卡洛更准确，但误差估计更难。本文介绍新旧方法来量化准蒙特卡洛的误差，并指出精确性与误差估计之间的冲突以及严格不确定性量化的保守性。最近发现某些RQMC估计具有对称分布，这可能允许无需中心极限定理或一致方差估计的置信区间。

**AI_Comments:** 本文指出了准蒙特卡洛方法在精度上的优势以及在误差估计上的挑战。它强调了在追求高精度和量化不确定性之间的固有矛盾。最近关于RQMC估计对称分布的发现是重要的创新点，因为它为构建更实用的置信区间提供了新的途径，可能克服传统统计方法（如中心极限定理）的限制，具有潜在的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 准蒙特卡洛采样比普通蒙特卡洛采样准确性更高，但其误差估计却远比普通蒙特卡洛采样困难。本文旨在解决准蒙特卡洛估计中量化误差的挑战，以及在追求高准确性的同时估计准确性所面临的冲突。

**Method:** 文章描述了量化准蒙特卡洛估计误差的新旧方法。特别提到了一些RQMC（随机化准蒙特卡洛））估计具有近似对称分布的发现，这可能允许构建不需要中心极限定理或一致方差估计的置信区间。

**Result:** 发现了一些RQMC（随机化准蒙特卡洛）估计具有近似对称分布。这使得有可能构建不需要中心极限定理或一致方差估计的置信区间。

**Conclusion:** 准蒙特卡洛的误差估计是一个重要且具有挑战性的问题，因为准确性目标与误差估计目标存在冲突，且严格的不确定性量化可能过于保守。然而，某些RQMC估计的对称分布特性为开发新的、更实用的置信区间提供了潜力。

> **ai_Abstract:** 本文探讨了准蒙特卡洛（QMC）采样中的误差估计问题。尽管QMC比普通蒙特卡洛具有更高的准确性，但其误差量化更为复杂。文章介绍了新旧方法来量化QMC估计的误差，并指出在追求高准确性与估计准确性之间存在的冲突，以及严格不确定性量化的保守性。一个重要发现是，某些随机化准蒙特卡洛（RQMC）估计具有近似对称的分布，这为无需依赖中心极限定理或一致方差估计的置信区间提供了可能性。

> **摘要翻译:** 准蒙特卡洛采样可以比普通蒙特卡洛采样获得更好的精度。然而，普通蒙特卡洛采样更容易估计所达到的精度。本文描述了量化准蒙特卡洛估计误差的新旧方法。在这种情况下，一个重要的挑战是获得准确性的目标与估计所达到准确性的目标相冲突。一个相关的挑战是严格的不确定性量化可能极其保守。最近的一个惊喜是，一些RQMC估计具有近似对称的分布，这有可能允许不需要中心极限定理或一致方差估计的置信区间。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [107] [Discretization error analysis for a radially symmetric harmonic map heat flow problem](https://arxiv.org/abs/2503.03525)
> *径向对称调和映照热流问题的离散化误差分析*

*Nam Anh Nguyen, Arnold Reusken* | **Category: math.NA, cs.NA** | **Updated: 2025-07-15**

**Keywords:** 调和映照热流, 离散化, 误差分析, 有限差分, 半隐式欧拉法

**Comment:** 

> **TL;DR:** 本文研究了径向对称调和映照热流问题的一种离散化方法，即空间二阶有限差分结合时间半隐式欧拉法，并给出了最优阶离散化误差界和离散能量估计。

**AI_Comments:** 该研究通过对一种经典离散化方法（空间有限差分结合时间半隐式欧拉）进行严格的误差分析，为径向对称调和映照热流问题的数值求解提供了理论依据。其重要性在于证明了最优阶误差界，并验证了离散方案能够保持连续问题的能量耗散特性，这对于数值方法的稳定性和精度至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 研究径向对称调和映照热流问题，因为其对应的偏微分方程在调和映照热流问题的许多分析中起着关键作用。

**Method:** 采用了一种基本的离散化方法：空间上使用二阶有限差分，时间上结合半隐式欧拉法。该半隐式欧拉方法使得每一步时间步长内的问题都是线性的。

**Result:** 得到了最优阶的离散化误差界（除了一个对数项），并且提出了离散能量估计，这些估计模仿了连续解能量的下降。

**Conclusion:** 通过对所提出的离散化方法进行误差分析，验证了其在径向对称调和映照热流问题上的有效性和精度，达到了最优阶误差界并保持了能量耗散特性。

> **ai_Abstract:** 本文针对径向对称调和映照热流问题，提出了一种结合空间二阶有限差分和时间半隐式欧拉法的离散化方案。研究在光滑解范围内进行了误差分析，获得了最优阶离散化误差界，并给出了模拟连续解能量下降的离散能量估计。

> **摘要翻译:** 本文研究了径向对称情况下的调和映照热流问题。相应的偏微分方程在许多调和映照热流问题的分析中起着关键作用。我们考虑了该问题的一种基本离散化方法，即空间上的二阶有限差分离散化与时间上的半隐式欧拉方法相结合。半隐式欧拉方法在每个时间步中产生一个线性问题。我们限制在连续问题光滑解的范围内，并对这种离散化方法进行了误差分析。这导致了最优阶的离散化误差界（除了一个对数项）。我们还提出了离散能量估计，这些估计模仿了连续解能量的下降。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [141] [The Akhiezer iteration and inverse-free solvers for Sylvester matrix equations](https://arxiv.org/abs/2503.17496)
> *Akhiezer迭代与Sylvester矩阵方程的无逆求解器*

*Cade Ballew, Thomas Trogdon, Heather Wilber* | **Category: math.NA, cs.NA, 65F45, 42C05, 33C47, 65F60, 65R20** | **Updated: 2025-07-14**

**Keywords:** Akhiezer迭代, Sylvester矩阵方程, 无逆求解器, 迭代方法, 矩阵符号函数

**Comment:** 

> **TL;DR:** 开发了两种基于Akhiezer迭代的无逆迭代方法，用于高效求解特定条件下的Sylvester矩阵方程，具有可证明的几何收敛率。

**AI_Comments:** 该论文的创新点在于提出了两种基于Akhiezer迭代的“无逆”方法来求解Sylvester矩阵方程，这对于处理难以求逆或稠密的大型矩阵具有重要意义。其优势在于提高了计算效率和降低了存储需求，并且提供了可证明的几何收敛率。这对于数值线性代数领域，特别是解决实际应用中的大型矩阵方程问题，具有显著的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在系数矩阵稠密或难以求逆时效率低下且存储需求高，因此需要开发更高效、存储需求更低的Sylvester矩阵方程求解方法，尤其是在系数矩阵谱位于已知不相交实轴子区间的情况下。

**Method:** 论文开发了两种无逆迭代方法，均基于Akhiezer迭代。第一种方法将问题转化为逼近块矩阵的矩阵符号函数，第二种方法直接逼近Sylvester算子的逆。这两种方法在右侧矩阵低秩时仅需低秩矩阵-矩阵乘积。

**Result:** 这两种方法都实现了可证明和可计算的几何收敛率。当右侧矩阵低秩时，它们只需要低秩矩阵-矩阵乘积。

**Conclusion:** 相较于现有方法，本文提出的方法在系数矩阵稠密或求逆代价高昂时，可以更高效且需要更少的存储空间，适用于求解偏微分方程和计算Fréchet导数等应用。

> **ai_Abstract:** 本论文提出了两种基于Akhiezer迭代的无逆迭代方法，用于求解系数矩阵谱位于已知不相交实轴子区间的Sylvester矩阵方程。其中一种方法通过逼近矩阵符号函数解决等效问题，另一种则直接逼近Sylvester算子的逆。这两种方法均能实现可证明的几何收敛率，并且在右侧矩阵低秩时仅需低秩矩阵-矩阵乘积。与现有方法相比，它们在处理稠密或难以求逆的系数矩阵时展现出更高的效率和更低的存储需求，适用于偏微分方程求解和Fréchet导数计算等领域。

> **摘要翻译:** 开发了两种无逆迭代方法，用于求解当系数矩阵的谱位于或接近已知的实轴不相交子区间时的Sylvester矩阵方程。这两种方法都使用了最近引入的Akhiezer迭代：一种用于解决逼近应用于块矩阵的矩阵符号函数的等效问题，另一种则直接逼近Sylvester算子的逆。在每种情况下，这都带来了可证明和可计算的几何收敛率。当右侧矩阵是低秩时，这两种方法都只需要低秩矩阵-矩阵乘积。相对于现有方法，本文提出的方法在系数矩阵稠密或求逆代价高昂时可以更高效且需要更少的存储空间。应用包括求解偏微分方程和计算Fréchet导数。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [171] [Comparison of FMM and $\mathcal{H}$-matrix based 3D-ACA for a time domain boundary element method](https://arxiv.org/abs/2505.00715)
> *时域边界元方法中基于FMM和$\mathcal{H}$-矩阵的3D-ACA比较*

*Martin Schanz, Vibudha Lakshmi Keshava, Herbert de Gersem* | **Category: math.NA, cs.NA, 35L05, 65M38, 65R20** | **Updated: 2025-07-14**

**Keywords:** 时域边界元方法, 3D-ACA, 快速多极方法, $\mathcal{H}$-矩阵, 广义卷积正交法

**Comment:** 22 pages, 10 figures, 1 table. arXiv admin note: substantial text
  overlap with arXiv:2312.11219 submitted to Computational Mechanics

> **TL;DR:** 本文比较了在时域边界元方法中使用3D-ACA时，基于FMM和$\mathcal{H}$-矩阵两种稀疏化技术在存储和计算时间上的效率，并证明两者均能有效应用于实际问题。

**AI_Comments:** 本文创新性地将3D-ACA应用于时域边界元方法，以处理其在拉普拉斯域中产生的复频率三维数据阵列。通过比较FMM和$\mathcal{H}$-矩阵两种核心稀疏化策略，为选择合适的计算方法提供了实证依据。其重要性在于，它使计算成本高昂的时域BEM能够应用于实际的大规模问题，具有重要的工程应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 针对时域边界元方法中产生的庞大三维系统矩阵数据，需要一种数据稀疏表示方法来提高计算效率和减少存储。本文旨在比较两种具体的稀疏化技术（FMM和$\mathcal{H}$-矩阵）在3D-ACA框架下的性能。

**Method:** 本文考虑了用于齐次波动方程的时域边界元方法，其中时间离散化采用广义卷积正交法(gCQ)，空间离散化采用低阶形函数。gCQ需要建立拉普拉斯域中对应椭圆问题的边界元矩阵，形成一个三维数据阵列。该阵列通过广义自适应交叉近似(3D-ACA)进行稀疏表示。在数据切片中，分别采用了标准$\mathcal{H}$-矩阵方法（结合ACA）或快速多极(FMM)方法进行空间稀疏化。算法不仅在空间维度上稀疏数据，还自适应地确定每个矩阵块所需的频率数量。论文主要比较了这两种方法在存储和计算时间上的节省。

**Result:** 通过一个电机声散射的例子表明，FMM和$\mathcal{H}$-矩阵这两种技术都能在存储和计算时间上实现节省，并且允许将时域边界元方法应用于实际问题。

**Conclusion:** 两种基于FMM和$\mathcal{H}$-矩阵的3D-ACA技术均能有效处理时域边界元方法中的大规模数据，使其能够应用于现实世界的问题，并在存储和计算时间上带来显著效益。

> **ai_Abstract:** 本文探讨了时域边界元方法（BEM）中高效处理大规模系统矩阵的问题。研究采用了广义卷积正交法（gCQ）生成的三维系统矩阵数组，并应用广义自适应交叉近似（3D-ACA）进行数据稀疏表示。论文重点比较了在3D-ACA框架下，两种空间稀疏化技术：快速多极（FMM）方法和基于ACA的$\mathcal{H}$-矩阵方法。通过电机声散射的实例验证，结果表明这两种方法都能显著节省存储和计算时间，使得时域BEM能够有效应用于实际工程问题。

> **摘要翻译:** 考虑了具有消失初始条件的齐次波动方程的时域边界元方法（BEM）。时间离散化采用Lopez-Fernandez和Sauter开发的广义卷积正交法（gCQ）。空间离散化则经典地使用低阶形函数完成。
本质上，gCQ要求在多个复频率下建立拉普拉斯域中相应椭圆问题的边界元矩阵。因此，获得了一个系统矩阵数组。这个系统矩阵数组可以被解释为一个三维数据数组，需要通过数据稀疏表示进行近似，为此可以应用广义自适应交叉近似（3D-ACA）。三维数据数组的秩自适应增加，直到达到预设精度。在纯代数层面，判断三维数据数组的低秩近似是否足够接近原始矩阵。在对应于每个频率的BEM计算数据切片中，可以使用结合ACA的标准$\mathcal{H}$-矩阵方法或快速多极（FMM）方法。数据数组的第三维表示复频率。因此，该算法不仅在两个空间维度上稀疏数据数组，而且还自适应地检测每个矩阵块需要多少频率。
简要讨论了两种版本，即在切片中使用ACA或FMM。本文的主要贡献是比较了两者在存储和计算时间节省方面的表现。一个电机声散射的例子表明，这两种技术都允许在实际问题中利用时域BEM。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [225] [Accelerating seismic inversion and uncertainty quantification with efficient high-rank Hessian approximations](https://arxiv.org/abs/2507.10804)
> *利用高效高秩Hessian近似加速地震反演和不确定性量化*

*Mathew Hu, Nick Alger, Rami Nammour, Omar Ghattas* | **Category: math.NA, cs.NA** | **Updated: 2025-07-14**

**Keywords:** 地震反演, 不确定性量化, Hessian近似, 全波形反演, MCMC

**Comment:** 

> **TL;DR:** 本文提出并验证了高效的高秩Hessian近似方法，以显著加速地震全波形反演（FWI）并提高贝叶斯不确定性量化（UQ）的效率和准确性，解决了现有方法计算成本高且低秩近似无效的问题。

**AI_Comments:** 本文创新性地提出了结合点扩散函数法和伪微分算子探测法的新型高秩Hessian近似方法，有效解决了大规模地震反演和不确定性量化中Hessian计算的挑战。其重要性在于，该方法不仅显著提高了全波形反演的计算效率，还极大地改善了贝叶斯不确定性量化中后验分布采样的准确性和有效性，避免了传统方法中低估方差和提供虚假信心的问题。这对于地球物理勘探领域的数据解释和风险评估具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 对于大规模问题，精确计算Hessian是不可行的，因为它只能通过矩阵-向量积获得，并且每个积都需要昂贵的波动方程求解。此外，Hessian是高秩的，这意味着常用于大规模逆问题的低秩方法效率低下。

**Method:** 我们改进了两种现有高秩Hessian近似方法：点扩散函数法和伪微分算子探测法。基于这两种方法之间的二元性，我们开发了一种新方法，统一了它们的互补优势。这些方法在合成二次模型和Marmousi模型上进行了验证。

**Result:** 数值实验表明，这些高秩Hessian近似方法显著降低了全波形反演（FWI）的计算成本。在不确定性量化（UQ）中，使用无Hessian近似或低秩近似计算的MCMC样本探索后验分布缓慢，经过数万次迭代后提供的信息很少，并且低估了方差，同时高估了有效样本量。相比之下，使用高秩Hessian近似生成的MCMC样本提供了有意义的后验统计信息，并更准确地评估了后验方差。

**Conclusion:** 高效的高秩Hessian近似方法能够显著加速地震全波形反演，并显著提高贝叶斯不确定性量化中MCMC采样的效率和准确性，克服了传统方法在处理高秩Hessian时的局限性。

> **ai_Abstract:** 本文提出并验证了高效的高秩Hessian近似方法，以加速地震全波形反演（FWI）和不确定性量化（UQ）。针对大规模问题中精确Hessian计算的不可行性以及低秩近似的低效性，作者改进了点扩散函数法和伪微分算子探测法，并基于两者的二元性，开发了一种结合其优势的新方法。实验结果表明，这些高秩Hessian近似显著降低了FWI的计算成本，并在UQ中提供了更准确、有效的MCMC采样，解决了传统MCMC采样效率低下和方差低估的问题。

> **摘要翻译:** 高效的高秩Hessian近似可以加速地震全波形反演（FWI）和不确定性量化（UQ）。在FWI中，Hessian逆的近似可以用作牛顿型或拟牛顿算法的预处理器，从而降低计算成本并改善深层地下区域的恢复。在贝叶斯UQ中，Hessian近似能够构建捕获后验方向尺度的马尔可夫链蒙特卡罗（MCMC）提议，从而提高MCMC的效率。对于大规模问题，计算精确的Hessian是不可行的，因为Hessian只能通过矩阵-向量积获得，并且执行每个矩阵-向量积都需要昂贵的波动方程求解。此外，Hessian是高秩的，这意味着常用于大规模逆问题的低秩方法效率低下。我们改进了两种现有高秩Hessian近似方法——点扩散函数法和伪微分算子探测法。基于这些方法之间观察到的二元性，我们开发了一种新方法，统一了它们的互补优势。我们在合成二次模型和Marmousi模型上验证了这些方法。数值实验表明，这些高秩Hessian近似显著降低了FWI的计算成本。在UQ中，使用无Hessian近似或低秩近似计算的MCMC样本探索后验分布缓慢，经过数万次迭代后提供的信息很少，并且低估了方差。同时，有效样本量被高估，提供了错误的信心。相比之下，使用高秩Hessian近似生成的MCMC样本提供了关于后验分布的有意义的统计信息，并更准确地评估了后验方差。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [261] [Dimension of Bi-degree $(d,d)$ Spline Spaces with the Highest Order of Smoothness over Hierarchical T-Meshes](https://arxiv.org/abs/2507.11047)
> *层级T网格上最高光滑度双(d,d)次样条空间的维数*

*Bingru Huang, Falai Chen* | **Category: math.NA, cs.NA, 65D17, 65D07, 65N30** | **Updated: 2025-07-15**

**Keywords:** 样条空间, T网格, 维数, 光滑度, 双次

**Comment:** 

> **TL;DR:** 本文使用平滑协因子一致性方法，推导了层级T网格上最高光滑度双(d,d)次样条空间的维数公式，并提出了稳定维数的T网格修改策略，为后续基函数构建奠定基础。

**AI_Comments:** 这项研究为理解和计算层级T网格上高光滑度样条空间的维数提供了理论框架，特别是引入了平滑协因子一致性方法和递归计算策略，并提出了稳定维数的T网格修改方法，这对于后续构建复杂几何模型中的样条基函数具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究层级T网格上最高光滑度双(d,d)次样条空间的维数问题。

**Method:** 采用平滑协因子一致性方法。首先，获得了张量积T连通分量上一致性向量空间的维数公式。然后，证明在张量积细分下，层级T网格的T连通分量上一致性向量空间的维数可以递归计算。结合这两点，获得了双(d,d)次样条空间的维数公式。此外，提出了修改层级T网格的策略，使样条空间维数稳定。

**Result:** 获得了层级T网格上最高光滑度双(d,d)次样条空间的维数公式。提出了修改任意层级T网格的策略，使得修改后的层级T网格上双(d,d)次样条空间的维数是稳定的。证明了在修改后的层级T网格上，样条空间的维数与其CVR图上较低次样条空间的维数相同。

**Conclusion:** 该解决方案为后续构建此类层级T网格上样条空间的基函数奠定了基础。

> **ai_Abstract:** 本文利用平滑协因子一致性方法，推导了层级T网格上最高光滑度双(d,d)次样条空间的维数公式。研究首先给出了张量积T连通分量上一致性向量空间的维数公式，并证明了其在层级T网格上的递归计算方法。在此基础上，文章提出了修改T网格以稳定样条空间维数的策略，并证明了其维数与CVR图上低次样条空间维数的一致性，为样条基函数的构建提供了理论基础。

> **摘要翻译:** 在本文中，我们使用平滑协因子一致性方法研究了层级T网格$\\mathscr T$上最高光滑度双(d,d)次样条空间的维数。首先，我们获得了张量积T连通分量上一致性向量空间的维数公式。然后，我们证明了在张量积细分下，层级T网格的T连通分量上一致性向量空间的维数可以递归计算。结合这两方面，我们在温和假设下获得了层级T网格$\\mathscr T$上最高光滑度双(d,d)次样条空间的维数公式。此外，我们提供了一种修改任意层级T网格的策略，使得在修改后的层级T网格上双(d,d)次样条空间的维数是稳定的。最后，我们证明了在此类层级T网格上样条空间的维数与在其CVR图上较低次样条空间的维数相同。因此，所提出的解决方案可以为后续构建此类层级T网格上样条空间的基函数铺平道路。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [300] [Stability of the Active Flux Method in the Framework of Summation-by-Parts Operators](https://arxiv.org/abs/2507.11068)
> *基于分部求和算子框架下主动通量方法的稳定性*

*Wasilij Barsukow, Christian Klingenberg, Lisa Lechner, Jan Nordström, Sigrun Ortleb, Hendrik Ranocha* | **Category: math.NA, cs.NA, 65M06, 65M20, 65M70** | **Updated: 2025-07-15**

**Keywords:** 主动通量方法, 分部求和算子, 能量稳定性, 数值方法, 守恒律

**Comment:** 

> **TL;DR:** 本文从分部求和算子的角度分析了主动通量方法，并首次证明了其能量稳定性。

**AI_Comments:** 本文的创新之处在于首次将主动通量方法与分部求和（SBP）算子相结合，并利用简并SBP算子证明了其能量稳定性。这为主动通量方法的理论分析提供了新的工具和视角，对于理解其数值稳定性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 主动通量方法在许多情况下表现良好，但其理论依据需要扩展。本文旨在从分部求和算子的角度提供其理论证明。

**Method:** 作者通过使用简并的分部求和（SBP）算子来表述主动通量方法，从而证明其能量稳定性。

**Result:** 研究表明主动通量方法可以用简并的SBP算子来表述，并首次提供了一种证明其能量稳定性的方法。

**Conclusion:** 本文成功地从分部求和算子的角度证明了主动通量方法的能量稳定性，为其理论基础提供了新的见解。

> **ai_Abstract:** 本文深入探讨了主动通量方法，这是一种结合了有限体积和有限差分思想的守恒律数值方法。研究人员通过将其置于分部求和（SBP）算子的框架下进行分析，特别是利用简并SBP算子，首次成功地证明了该方法的能量稳定性，从而扩展了其理论基础。

> **摘要翻译:** 主动通量方法是一种用于守恒律的数值方法，它结合了单元平均值和点值，基于有限体积和有限差分的思想。这种不寻常的组合已被证明在许多情况下效果良好。我们通过从分部求和（SBP）算子的角度分析主动通量方法来扩展其理论依据，SBP算子常用于分析有限差分、有限体积和有限元方案。我们表明主动通量方法可以使用简并的SBP算子来表述，这为证明主动通量方法的能量稳定性提供了一种新颖的首次方法。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [330] [Adaptive Reduced Basis Trust Region Methods for Parabolic Inverse Problems](https://arxiv.org/abs/2507.11130)
> *抛物线逆问题的自适应降阶基信赖域方法*

*Michael Kartmann, Benedikt Klein, Mario Ohlberger, Thomas Schuster, Stefan Volkwein* | **Category: math.NA, cs.NA, math.OC, 35R30, 35K90, 65M32, 35K57** | **Updated: 2025-07-15**

**Keywords:** 抛物线逆问题, 降阶模型, 信赖域方法, 参数识别, IRGNM

**Comment:** 40 pages, 12 figures

> **TL;DR:** 针对抛物线PDE参数识别的计算成本高昂的逆问题，本文提出一种自适应降阶基信赖域方法，通过降阶模型加速计算，并结合误差感知信赖域框架保证精度。

**AI_Comments:** 这项工作通过结合降阶建模和自适应信赖域方法，有效地解决了抛物线逆问题中高维计算的挑战。其创新性在于将在线自适应降阶算子与误差感知信赖域框架相结合，提高了计算效率的同时保证了结果的可靠性。该方法对于需要高效求解大规模PDE逆问题的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有正则化方法（如迭代正则化高斯-牛顿法IRGNM）在处理抛物线偏微分方程（PDE）的参数识别逆问题时，由于PDE离散化的高维特性，计算成本高昂。

**Method:** 本文提出一种降阶建模方法，旨在加速基于导数优化所需的正向和伴随计算。该方法基于现有工作，并以在线方式自适应地构建降阶前向算子，结合了参数和状态空间降维。为确保可靠性，将IRGNM迭代嵌入到一个自适应、误差感知的信赖域框架中，以验证降阶近似的准确性。

**Result:** 通过对动态反应-扩散系统中时间相关和时间无关的参数识别问题进行数值结果验证，证明了所提出方法的有效性。

**Conclusion:** 该自适应降阶基信赖域方法能够有效加速抛物线逆问题的参数识别，同时通过误差感知信赖域框架保证计算的可靠性。

> **ai_Abstract:** 本文针对抛物线PDE参数识别中高维离散化导致的计算瓶颈，提出了一种自适应降阶基信赖域方法。该方法采用降阶建模加速正向和伴随计算，并在线自适应构建降阶前向算子，结合参数和状态空间降维。为保证计算可靠性，将迭代正则化高斯-牛顿法（IRGNM）嵌入误差感知的信赖域框架中。数值结果表明，该方法能有效解决时间相关和时间无关的参数识别问题。

> **摘要翻译:** 我们考虑抛物线偏微分方程（PDEs）参数识别背景下出现的非线性逆问题。为了稳定的重建，通常使用迭代正则化高斯-牛顿法（IRGNM）等正则化方法，但由于PDE离散化的高维特性，它们的应用计算成本高昂。为了解决这一瓶颈，我们提出了一种降阶建模方法，该方法加速了基于导数的优化所需的正向和伴随计算。我们的方法建立在最近对椭圆正向算子的贡献[Kartmann et al. Adaptive reduced basis trust region methods for parameter identification problems. Comput. Sci. Eng. 1, 3 (2024)]之上，并以在线方式自适应地构建降阶正向算子，结合了参数和状态空间降维。为了确保可靠性，我们将IRGNM迭代嵌入到一个自适应、误差感知的信赖域框架中，该框架验证了降阶近似的准确性。我们通过对动态反应-扩散系统中时间相关和时间无关的参数识别问题进行数值结果，证明了所提出方法的有效性。该实现已提供，以便于重现和进一步使用。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [366] [Convergence of a finite-volume scheme for aggregation-diffusion equations with saturation](https://arxiv.org/abs/2507.11132)
> *饱和聚集-扩散方程有限体积格式的收敛性*

*David Gómez-Castro* | **Category: math.NA, cs.NA, math.AP, 65M08, 35Q70, 35Q92, 45K05** | **Updated: 2025-07-15**

**Keywords:** 有限体积方法, 聚集-扩散方程, 收敛性, Aubin-Simons定理, 非线性迁移率

**Comment:** 

> **TL;DR:** 本文证明了针对具有非线性迁移率的聚集-扩散方程的有限体积方法的收敛性，使用了Aubin-Simons紧致性定理，并给出了两种收敛结果。

**AI_Comments:** 本文的重要贡献在于为先前引入的有限体积方法提供了严格的数学收敛性证明。通过利用Aubin-Simons紧致性定理并考虑多种初始条件和势函数特性，该研究增强了对该数值方案可靠性的理解。特别是，它区分了在不同假设下的收敛行为，这对于实际应用和理论分析都至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在证明[Bailo, Carrillo, Hu. SIAM J. Appl. Math. 2023]中引入的用于具有非线性迁移率的聚集-扩散方程的有限体积方法的收敛性。

**Method:** 本文使用Gallouët和Latché提出的Aubin-Simons紧致性定理，并利用合适的离散$H^1$和$W^{-1,1}$离散范数来证明收敛性。

**Result:** 本文提供了两个收敛结果。第一个结果表明，如果初始数据没有自由边界，迁移率是Lipschitz的，并且限制势($V$)和聚集势($K$)是$W^{2,\infty}_0$，则对于一般熵($U$)（包括奇异和退化熵）存在收敛性。第二个结果表明，当初始数据具有自由边界，迁移率仅是连续的，并且$V$和$K$是$W^{1,\infty}$时，如果熵$U$是$C^1$且严格凸的，则存在收敛性。

**Conclusion:** 本文成功证明了针对具有饱和的聚集-扩散方程的有限体积格式的收敛性，并在不同条件下给出了具体的收敛结果。

> **ai_Abstract:** 本文证明了针对具有非线性迁移率的聚集-扩散方程的有限体积方法的收敛性。研究利用Aubin-Simons紧致性定理和适当的离散范数，提出了两种收敛条件：一种适用于无自由边界、Lipschitz迁移率和特定势函数的情况，另一种适用于有自由边界、连续迁移率和不同势函数，但熵为$C^1$且严格凸的情况。

> **摘要翻译:** 在[Bailo, Carrillo, Hu. SIAM J. Appl. Math. 2023]中，作者引入了一种用于具有非线性迁移率的聚集-扩散方程的有限体积方法。在本文中，我们使用Gallouët和Latché提出的Aubin-Simons紧致性定理证明了该方法的收敛性。我们使用了合适的离散$H^1$和$W^{-1,1}$离散范数。我们提供了两个收敛结果。第一个结果表明，如果初始数据没有自由边界，迁移率是Lipschitz的，并且限制势($V$)和聚集势($K$)是$W^{2,\infty}_0$，则对于一般熵($U$)（包括奇异和退化熵）存在收敛性。第二个结果表明，当初始数据具有自由边界，迁移率仅是连续的，并且$V$和$K$是$W^{1,\infty}$时，但在熵$U$是$C^1$且严格凸的假设下，也存在收敛性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [402] [Adaptive FEM with explicit time integration for the wave equation](https://arxiv.org/abs/2507.11193)
> *波方程显式时间积分的自适应有限元方法*

*Marcus J. Grote, Omar Lakkis, Carina S. Santos* | **Category: math.NA, cs.NA, 65M60, 65M22, 65J10, 35A35, 35L05,, G.1.8; G.4** | **Updated: 2025-07-15**

**Keywords:** 自适应有限元, 波方程, 显式时间积分, CFL条件, 局部时间步长

**Comment:** 

> **TL;DR:** 本文提出了一种结合时变网格和局部时间步长的自适应策略，以克服波方程显式时间积分中局部网格细化导致的严格CFL稳定性限制，并展示了其收敛性。

**AI_Comments:** 该论文的创新点在于将时变网格和局部时间步长相结合的自适应策略应用于波方程的显式时间积分，有效缓解了局部网格细化带来的严格CFL稳定性限制。这种方法在保持计算效率的同时，提高了数值模拟的精度和鲁棒性，对于需要高精度局部求解的波传播问题具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 克服由于局部网格细化导致的对时间步长过于严格的CFL稳定性限制，以提高波方程显式时间积分的效率和准确性。

**Method:** 基于Grote, Lakkis, Santos (2024)的后验误差估计器，本文设计了一种时空自适应策略。该策略包含时变网格和局部时间步长，以应对CFL稳定性限制。在每个时间步，自适应算法通过误差指示器监控精度，并在细化网格上重新计算当前步直到满足所需容差；同时，在误差较小的区域粗化网格。在所有局部网格细化区域应用基于Leapfrog的局部时间步长，以在网格变化的全显式时间积分中实现自适应性并保持效率。

**Result:** 数值结果表明，在时变网格上，后验误差估计器具有最优的收敛速度。

**Conclusion:** 该研究成功开发了一种有效的自适应有限元方法，通过结合时变网格和局部时间步长，显著缓解了显式时间积分中由局部网格细化引起的CFL稳定性限制，并保持了计算效率和精度。

> **ai_Abstract:** 本文基于近期提出的波方程显式时间步进有限元解的后验误差估计器，开发了一种时空自适应策略。该策略结合了时变网格和局部时间步长，旨在解决局部网格细化导致的CFL稳定性限制。算法在每个时间步通过误差指示器调整网格精度，并在误差较小区域进行粗化。通过应用基于Leapfrog的局部时间步长，确保了在网格变化的全显式时间积分中的自适应性和效率。数值结果验证了后验误差估计器在时变网格上的最优收敛率。

> **摘要翻译:** 从Grote, Lakkis, Santos (2024)中关于波方程显式时间步进有限元解的最新后验误差估计器出发，我们设计了一种时空自适应策略，该策略包括时变网格和局部时间步长 [Diaz, Grote, 2009]，以克服由于局部网格细化导致的时间步长过于严格的CFL稳定性限制。此外，在每个时间步，自适应算法借助误差指示器监控精度，并在细化网格上重新计算当前步，直到满足所需容差；同时，在误差较小的区域粗化网格。在所有局部网格细化区域应用基于Leapfrog的局部时间步长，以将自适应性整合到具有网格变化的全显式时间积分中，同时保持效率。数值结果说明了时变网格上后验误差估计器的最优收敛速度。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [438] [On maximal curves of $n$-correct sets](https://arxiv.org/abs/2507.11207)
> *关于 $n$-正确集的极大曲线*

*H. Hakopian, G. Vardanyan, N. Vardanyan* | **Category: math.NA, cs.NA, math.AG, 41A05, 41A63, 14H50** | **Updated: 2025-07-15**

**Keywords:** 极大曲线, $n$-正确集, 插值, 代数曲线, 节点

**Comment:** 20 pages, 2 figures

> **TL;DR:** 本文介绍了 $n$-正确集中极大曲线的新性质和已知性质的扩展，这些曲线是研究 $n$-正确集的重要工具。

**AI_Comments:** 本文的创新点在于提出了关于 $n$-正确集中极大曲线的新性质并扩展了已知性质。极大曲线在多项式插值理论中具有重要意义，对 $n$-正确集的研究至关重要。然而，抽象并未提供具体的新性质内容，使得无法评估其具体贡献和局限性。

<details>
  <summary>Details</summary>

**Motivation:** 极大曲线是研究 $n$-正确集的重要工具，因此需要对其性质进行深入研究。

**Method:** 本文介绍了极大曲线的新性质，并扩展了已知的性质。

**Result:** 本文介绍了极大曲线的新性质和已知性质的扩展，但抽象中未具体说明这些新性质或扩展的细节。

**Conclusion:** 本文主要致力于阐述和扩展关于 $n$-正确集中极大曲线的性质。

> **ai_Abstract:** 本文探讨了 $n$-正确集中的极大曲线。一个 $n$-正确集 $\mathcal{X}$ 允许用总次数不超过 $n$ 的二元多项式进行插值。对于度数 $k\le n$ 的代数曲线 $q$，它最多能通过 $d(n,k)$ 个节点。如果 $q$ 恰好通过 $d(n,k)$ 个节点，则称其为极大曲线。文章指出，极大曲线是研究 $n$-正确集的重要工具，并介绍了其新的性质以及对已知性质的扩展。

> **摘要翻译:** 假设 $\mathcal{X}$ 是平面上的一个 $n$-正确节点集，这意味着它允许使用总次数小于或等于 $n$ 的二元多项式进行单解插值。那么，度数 $k\le n$ 的代数曲线 $q$ 最多可以通过 $\mathcal{X}$ 的 $d(n,k)$ 个节点，其中 $d(n,k)={{n+2}\choose {2}}-{{n+2-k}\choose {2}}$。如果度数 $k\le n$ 的曲线 $q$ 恰好通过 $\mathcal{X}$ 的 $d(n,k)$ 个节点，则称其为极大曲线。特别地，极大线是恰好通过 $\mathcal{X}$ 的 $d(n,1)=n+1$ 个节点的直线。极大曲线是研究 $n$-正确集的重要工具。我们提出了极大曲线的新性质，以及已知性质的扩展。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [728] [Semi and fully-discrete analysis of lowest-order nonstandard finite element methods for the biharmonic wave problem](https://arxiv.org/abs/2407.03777)
> *双调和波动问题的最低阶非标准有限元方法的半离散和全离散分析*

*Neela Nataraj, Ricardo Ruiz-Baier, Aamir Yousuf* | **Category: math.NA, cs.NA** | **Updated: 2025-07-15**

**Keywords:** 非标准有限元方法, 双调和波动问题, 误差估计, 稳定性, 数值实验

**Comment:** 

> **TL;DR:** 本文对双调和波动方程的最低阶非标准有限元方法进行了半离散和全离散分析，建立了稳定性和最优阶误差估计，并通过数值实验验证了理论结果。

**AI_Comments:** 本文对双调和波动问题中的非标准有限元方法进行了全面的理论和数值分析，特别是在最低阶方法和多种时间离散方案上的探讨，并通过修正Ritz投影算子确保误差估计，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在讨论双调和波动方程的最低阶非标准有限元方法在空间离散化以及显式和隐式时间离散化方案。

**Method:** 研究采用最低阶非标准有限元方法进行空间离散，显式和隐式方案进行时间离散。通过在$H^2_0(\Omega)$上定义的修正Ritz投影算子来确保误差估计。数值实验使用了显式和隐式时间离散方案，以及Morley、间断Galerkin和C$^0$内部惩罚空间离散方案。

**Result:** 在适当的范数下，为所提出的方案的半离散和显式/隐式全离散版本建立了稳定性和最优阶误差估计。数值实验验证了理论误差估计。

**Conclusion:** 理论误差估计得到了数值实验的验证，表明所提出的最低阶非标准有限元方法及其时间离散方案对双调和波动问题是有效和准确的。

> **ai_Abstract:** 本文对双调和波动方程的最低阶非标准有限元方法进行了半离散和全离散分析。研究建立了在半离散和显式/隐式全离散方案下的稳定性和最优阶误差估计，并通过数值实验，包括使用Morley、间断Galerkin和C$^0$内部惩罚方案的空间离散化，验证了理论结果。

> **摘要翻译:** 本文讨论了双调和波动方程在钳制边界条件下，采用最低阶非标准有限元方法进行空间离散化以及显式和隐式方案进行时间离散化。在$H^2_0(\Omega)$上定义的修正Ritz投影算子确保了在适当的解正则性假设下的误差估计。在适当的范数下，为所提出的方案的半离散和显式/隐式全离散版本建立了稳定性和最优阶误差估计。最后，我们报告了使用显式和隐式时间离散方案以及Morley、间断Galerkin和C$^0$内部惩罚空间离散方案的数值实验，这些实验验证了理论误差估计。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [770] [Non-intrusive model reduction of advection-dominated hyperbolic problems using neural network shift augmented manifold transformation](https://arxiv.org/abs/2407.18419)
> *对流主导双曲问题的非侵入式模型降阶，基于神经网络位移增强流形变换*

*Harshith Gowrachari, Nicola Demo, Giovanni Stabile, Gianluigi Rozza* | **Category: math.NA, cs.NA, physics.flu-dyn** | **Updated: 2025-07-15**

**Keywords:** 模型降阶, 对流主导问题, 神经网络, 流形变换, 非侵入式

**Comment:** 22 pages, 19 Figures

> **TL;DR:** 针对对流主导问题，提出一种非侵入式神经网络位移增强流形变换（NNsPOD-ROM）方法，以提高模型降阶效率和准确性。

**AI_Comments:** 本文的创新点在于结合神经网络和流形变换来解决对流主导问题在模型降阶中的挑战，特别是通过引入自动位移检测和非侵入式构建降阶模型。这为处理传统线性方法难以有效处理的问题提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统线性压缩方法（如POD和RB）不适用于对流主导问题，因为Kolmogorov n-width衰减缓慢，导致降阶模型效率低下且不准确。

**Method:** 提出一种神经网络位移增强变换技术，利用深度学习框架在原始流形和变换流形之间建立参数依赖映射。然后对变换流形应用线性压缩，并在所得的变换线性近似子空间上构建非侵入式降阶模型，在线阶段采用自动位移检测。提出NNsPOD-ROM算法框架，包含离线和在线阶段。

**Result:** 在多种实验中测试了所提出方法的性能，包括一维线性对流方程、二维等熵对流涡流和二维两相流。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出一种名为NNsPOD-ROM的非侵入式模型降阶算法，用于解决对流主导双曲问题中传统线性压缩方法效率低下的问题。该方法利用神经网络进行位移增强流形变换，将原始流形映射到更适合线性压缩的变换流形，并通过自动位移检测在变换子空间上构建降阶模型。该框架包含离线和在线阶段，并在多种对流问题上进行了性能验证。

> **摘要翻译:** 对流主导问题在自然界、工程系统和各种工业过程中普遍存在。传统的线性压缩方法，如本征正交分解（POD）和降阶基（RB）方法，由于Kolmogorov n-width衰减缓慢，不适用于这些问题。这导致降阶模型效率低下且不准确。很少有非线性方法可以加速Kolmogorov n-width衰减。在这项工作中，我们使用一种神经网络位移增强变换技术，该技术采用自动位移检测。这种方法利用深度学习框架在原始流形$\mathcal{M}$和变换流形$\tilde{\mathcal{M}}$之间推导参数依赖映射。我们应用线性压缩方法来获得变换流形$\tilde{\mathcal{M}}$的低维线性近似子空间。此外，我们在所得的变换线性近似子空间上构建非侵入式降阶模型，并在线阶段采用自动位移检测进行预测。我们提出了一个完整的框架，即基于神经网络位移增强本征正交分解的降阶模型（NNsPOD-ROM）算法，包括离线和在线阶段，用于对流主导问题的模型降阶。我们在大量实验中测试了我们提出的方法，以评估其在一维线性对流方程、更高阶方法基准案例——二维等熵对流涡流和二维两相流上的性能。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [812] [A finite difference method with symmetry properties for the high-dimensional Bratu equation](https://arxiv.org/abs/2410.12553)
> *一种具有对称性质的高维Bratu方程有限差分方法*

*Muhammad Luthfi Shahab, Hadi Susanto, Haralampos Hatzikirou* | **Category: math.NA, cs.NA, math.AP, math.OC** | **Updated: 2025-07-15**

**Keywords:** 对称有限差分方法, Bratu方程, 分岔图, 高维, 数值解

**Comment:** Accepted for publication in Applied Mathematics and Computation

> **TL;DR:** 本文提出了一种对称有限差分方法（SFDM），通过嵌入解的对称性并修改Bratu方程，成功且更准确地解决了高维Bratu方程，并绘制了分岔图，其性能优于现有方法。

**AI_Comments:** 本文的创新点在于提出了SFDM，它通过将解的对称性直接嵌入到有限差分方法中，并结合对Bratu方程的巧妙修改，显著提升了高维Bratu方程的求解精度和效率。这项工作的重要性在于解决了长期存在的3D Bratu方程求解难题，并为理解其复杂的分岔行为提供了更准确的工具。其能够处理大规模网格点和提供多维度分岔图的能力，使其成为该领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 由于存在多重和尖锐解，求解三维（3D）Bratu方程极具挑战性，且自20世纪90年代以来研究至今仍无令人满意的结果。

**Method:** 本文引入了一种对称有限差分方法（SFDM），该方法将解的对称性质嵌入到有限差分法中，以获得更精确的3D Bratu方程解和分岔图。此外，还通过引入一个新的约束来修改Bratu方程，以促进分岔图的构建并简化拐点的处理。该方法结合稀疏矩阵表示。

**Result:** 所提出的方法成功地在高达$301^3$网格点的三维Bratu方程上求解。结果表明，SFDM在求解三维Bratu方程方面优于所有以前使用的方法。此外，还提供了1D、2D、4D和5D情况下的分岔图，并准确识别了所有维度中的第一个拐点。所有模拟表明，Bratu方程在立方域上的分岔图与Joseph和Lundgren [1]描述的球域上的成熟行为非常相似。SFDM应用于线性稳定性分析时，尽管非线性系统中的方程和变量较少，但其产生的最大实特征值与标准FDM相同。

**Conclusion:** SFDM是一种有效且优越的方法，能够更准确地求解高维Bratu方程并分析其分岔行为，解决了现有方法的局限性。

> **ai_Abstract:** 本文提出了一种对称有限差分方法（SFDM），旨在解决高维Bratu方程求解的挑战。SFDM通过将解的对称性嵌入到有限差分框架中，并结合对Bratu方程的修改（引入新约束以简化分岔图构建和拐点处理），实现了更精确的解和分岔图。实验结果表明，SFDM在处理三维Bratu方程时优于现有方法，并成功在大型网格上求解。研究还提供了多维度的分岔图，并准确识别了拐点，证明了SFDM在解决Bratu方程复杂行为方面的有效性和优越性。

> **摘要翻译:** 求解三维（3D）Bratu方程由于存在多重和尖锐解而极具挑战性。对该方程的研究始于1990年代后期，但迄今为止没有令人满意的结果。为了解决这个问题，我们引入了一种对称有限差分方法（SFDM），该方法将解的对称性质嵌入到有限差分法（FDM）中。SFDM主要用于获得3D Bratu方程更精确的解和分岔图。此外，我们建议通过引入一个新的约束来修改Bratu方程，该约束有助于分岔图的构建并简化拐点的处理。所提出的方法结合稀疏矩阵表示，成功地在高达$301^3$点的网格上求解了3D Bratu方程。结果表明，SFDM优于所有以前用于3D Bratu方程的方法。此外，我们提供了1D、2D、4D和5D情况下的分岔图，并准确识别了所有维度中的第一个拐点。所有模拟表明，Bratu方程在立方域上的分岔图与Joseph和Lundgren [1]描述的球域上的成熟行为非常相似。此外，当SFDM应用于线性稳定性分析时，尽管非线性系统中的方程和变量较少，但其产生的最大实特征值与标准FDM相同。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [99] [FasTUSS: Faster Task-Aware Unified Source Separation](https://arxiv.org/abs/2507.11435)
> *FasTUSS：更快的任务感知统一音源分离*

*Francesco Paissan, Gordon Wichern, Yoshiki Masuyama, Ryo Aihara, François G. Germain, Kohei Saijo, Jonathan Le Roux* | **Category: cs.SD, eess.AS, eess.SP** | **Updated: 2025-07-15**

**Keywords:** 音频源分离, 统一模型, 模型优化, 计算效率, 双路径模型

**Comment:** Accepted to WASPAA 2025

> **TL;DR:** 本文通过优化现有任务感知统一音源分离（TUSS）模型的设计，提出了更快的FasTUSS模型，显著减少了计算操作，同时保持了性能。

**AI_Comments:** 该论文的创新点在于成功优化了先进的统一任务感知音源分离模型，显著提升了其计算效率，这对于大型模型的实际部署具有重要意义。对性能与复杂度之间权衡的深入分析，为未来模型设计提供了宝贵的经验。降低计算成本同时保持高性能的能力是该研究的关键贡献。

<details>
  <summary>Details</summary>

**Motivation:** 当前最先进的时频（TF）双路径模型，特别是任务感知统一音源分离（TUSS）模型，虽然参数量相对较低，但仍需要大量的操作，导致执行时间较长。随着模型趋向于更大、更通用，这一问题日益突出，因此需要优化其性能与复杂度的权衡。

**Method:** 通过分析TUSS模型的设计选择，本文推导出了两种更高效的模型：FasTUSS-8.3G和FasTUSS-11.7G，旨在减少原始模型的操作量。此外，研究了提示条件的影响，以推导出一个因果TUSS模型。

**Result:** FasTUSS-8.3G和FasTUSS-11.7G分别使原始模型的操作量减少了81%和73%，同时在所有基准测试中平均性能下降仅为1.2 dB和0.4 dB。

**Conclusion:** 本文成功优化了任务感知统一音源分离（TUSS）模型，开发出计算效率更高的FasTUSS版本，在保持高性能的同时显著降低了操作成本，并探索了因果模型的可能性。

> **ai_Abstract:** 本文针对任务感知统一音源分离（TUSS）模型高计算成本的问题，对其设计进行了深入分析。通过优化，研究人员成功开发出FasTUSS-8.3G和FasTUSS-11.7G两款更高效的模型，它们在保持极小性能损失（平均1.2 dB和0.4 dB）的前提下，将原始模型的操作量分别大幅减少了81%和73%。此外，论文还探讨了提示条件对构建因果TUSS模型的影响。

> **摘要翻译:** 时频（TF）双路径模型是目前表现最佳的音频源分离网络架构之一，在语音增强、音乐源分离和电影音频源分离方面取得了最先进的性能。虽然它们的参数量相对较低，但仍需要大量的操作，这意味着更高的执行时间。随着模型趋向于更大、通过大量数据训练以解决更通用任务的趋势，例如最近引入的任务感知统一源分离（TUSS）模型，这个问题变得更加突出。TUSS旨在利用单一的条件模型解决音频源分离任务，它基于TF-Locoformer构建，TF-Locoformer是一种结合了卷积和注意力层的TF双路径模型。任务定义以提示序列的形式出现，指定要提取的源的数量和类型。在本文中，我们分析了TUSS的设计选择，目标是优化其性能-复杂度权衡。我们推导出了两种更高效的模型，FasTUSS-8.3G和FasTUSS-11.7G，它们分别将原始模型的操作量减少了81%和73%，而在所有基准测试中平均性能仅下降了1.2 dB和0.4 dB。此外，我们还研究了提示条件的影响，以推导出一个因果TUSS模型。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [115] [Supporting SENĆOTEN Language Documentation Efforts with Automatic Speech Recognition](https://arxiv.org/abs/2507.10827)
> *使用自动语音识别支持SENĆOTEN语言文档工作*

*Mengzhe Geng, Patrick Littell, Aidan Pine, PENÁĆ, Marc Tessier, Roland Kuhn* | **Category: cs.SD, cs.AI, cs.HC, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 自动语音识别, 濒危语言, 语言文档, SENĆOTEN, 迁移学习

**Comment:** Accepted by ComputEL-8

> **TL;DR:** 本文提出了一种基于自动语音识别（ASR）的文档流水线，利用合成语音数据和跨语言迁移学习来支持SENĆOTEN语言的复兴工作，并在有限数据下取得了有潜力的结果。

**AI_Comments:** 这项工作在支持濒危语言的数字化文档方面具有重要意义，尤其是在数据稀缺的背景下。利用TTS数据增强和跨语言迁移学习是应对低资源语言挑战的创新方法。虽然结果显示了潜力，但仍需关注OOV率以及如何进一步降低错误率以使其在实际应用中更具鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** SENĆOTEN语言正面临语言流失的危机，社区正在积极进行语言复兴工作并寻求数字技术的支持。自动语音识别（ASR）技术有望加速语言文档和教育资源的创建，但由于数据有限、多综合语结构和重音驱动的音位变动，为SENĆOTEN开发ASR系统面临挑战。

**Method:** 本文提出了一种ASR驱动的文档流水线，该流水线利用文本到语音（TTS）系统增强的语音数据和基于语音基础模型（SFM）的跨语言迁移学习。此外，还通过浅层融合或n-best还原方式整合了n-gram语言模型，以最大限度地利用现有数据。

**Result:** 在SENĆOTEN数据集上的实验结果显示，测试集的词错误率（WER）为19.34%，字符错误率（CER）为5.09%，其中词汇表外（OOV）率为57.02%。在过滤掉与音调符号相关的次要错误后，WER提高到14.32%（对于未见词为26.48%），CER提高到3.45%。

**Conclusion:** 本文提出的ASR驱动流水线展示了支持SENĆOTEN语言文档工作的潜力。

> **ai_Abstract:** 本文针对SENĆOTEN语言复兴中面临的数据稀缺和词汇变异挑战，提出了一种ASR驱动的语言文档流水线。该流水线结合了TTS生成的增强语音数据、语音基础模型（SFM）的跨语言迁移学习以及n-gram语言模型。实验结果表明，该方法在SENĆOTEN数据集上实现了较低的词错误率和字符错误率，证明了其在支持濒危语言文档方面的潜力。

> **摘要翻译:** SENĆOTEN语言在温哥华岛南部萨尼奇半岛上使用，目前正处于积极的语言复兴努力中，以扭转殖民语言政策导致的语言流失趋势。为了支持这些实地工作，社区正在转向数字技术。自动语音识别（ASR）技术有望加速语言文档和教育资源的创建。然而，由于数据有限、其多综合语结构和重音驱动的音位变动导致的显著词汇变异，为SENĆOTEN开发ASR系统具有挑战性。为了解决这些挑战，我们提出了一种ASR驱动的文档流水线，该流水线利用来自文本到语音（TTS）系统的增强语音数据和基于语音基础模型（SFM）的跨语言迁移学习。还通过浅层融合或n-best还原方式整合了n-gram语言模型，以最大限度地利用现有数据。在SENĆOTEN数据集上的实验结果显示，在测试集上，词错误率（WER）为19.34%，字符错误率（CER）为5.09%，其中词汇表外（OOV）率为57.02%。在过滤掉与音调符号相关的次要错误后，WER提高到14.32%（对于未见词为26.48%），CER提高到3.45%，这证明了我们ASR驱动流水线支持SENĆOTEN语言文档的潜力。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [234] [Pronunciation Deviation Analysis Through Voice Cloning and Acoustic Comparison](https://arxiv.org/abs/2507.10985)
> *通过语音克隆和声学比较进行发音偏差分析*

*Andrew Valdivia, Yueming Zhang, Hailu Xu, Amir Ghasemkhani, Xin Qin* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-07-15**

**Keywords:** 语音克隆, 错误发音检测, 声学比较, 语音分析, 发音偏差

**Comment:** 

> **TL;DR:** 该论文提出了一种新的方法，通过语音克隆生成用户发音纠正后的语音，并与原始语音进行声学比较来检测错误发音。

**AI_Comments:** 该论文的创新之处在于利用语音克隆技术进行发音偏差分析，这避免了传统方法中对特定语言语音规则或大量训练数据的需求，使得发音错误检测更加灵活和可扩展。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在提出一种新的方法来检测错误发音，且无需预定义的语音规则或大量特定语言的训练数据。

**Method:** 该方法利用语音克隆技术生成用户声音的合成版本，该版本具有正确的发音。然后，对原始语音和克隆语音进行逐帧声学比较，以识别声学偏差最大的区域，这些区域被认为是潜在的错误发音。

**Result:** 实验结果表明，该方法能够有效地找出具体的发音错误。

**Conclusion:** 该方法成功地识别了发音错误，且不需要依赖预定义的语音规则或大量的特定语言训练数据。

> **ai_Abstract:** 本文提出了一种新颖的错误发音检测方法。它利用语音克隆技术创建用户语音的纠正版本，然后通过识别原始语音和克隆纠正语音之间声学偏差最大的区域来找出错误发音。该方法能够有效识别错误，且无需依赖大量的特定语言数据或语音规则。

> **摘要翻译:** 这篇论文提出了一种通过分析用户原始语音和其经过纠正发音的克隆语音之间的偏差来检测错误发音的新方法。我们假设原始语音和克隆语音之间声学偏差最大的区域表示潜在的错误发音。我们的方法利用语音克隆的最新进展，生成一个具有正确发音的用户声音合成版本，然后进行逐帧比较以识别有问题语段。实验结果表明，这种方法在确定具体的发音错误方面是有效的，并且不需要为每种目标语言预定义语音规则或大量的训练数据。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [274] [ReverbMiipher: Generative Speech Restoration meets Reverberation Characteristics Controllability](https://arxiv.org/abs/2505.05077)
> *ReverbMiipher：生成式语音修复与混响特性可控性相结合*

*Wataru Nakata, Yuma Koizumi, Shigeki Karita, Robin Scheibler, Haruko Ishikawa, Adriana Guevara-Rukoz, Heiga Zen, Michiel Bacchiani* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-15**

**Keywords:** 语音修复, 混响控制, 生成模型, 参数化重合成, ReverbMiipher

**Comment:** 5 pages, 5 figures

> **TL;DR:** ReverbMiipher是一种新的语音修复模型，它在去噪的同时保留并能控制语音的混响特性。

**AI_Comments:** 这项工作创新性地解决了语音修复中混响处理的难题，不仅实现了去噪，还首次在生成式模型中实现了对混响特性的精细控制和生成。其引入的ReverbEncoder和解耦策略是关键创新点，为语音处理领域带来了新的可能性，尤其是在虚拟现实、沉浸式音频和助听器等应用中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的语音修复（SR）通常会完全去除混响，但混响编码了声源环境的空间信息。因此，需要一种能够去噪同时保留并控制混响的SR模型。

**Method:** 本文提出了ReverbMiipher，一个扩展参数化重合成框架的语音修复模型。该模型包含一个专门的ReverbEncoder，用于从噪声输入中提取混响特征向量，并以此条件化声码器来重建语音信号，从而在去除噪声的同时保留原始混响特性。训练过程中采用随机零向量替换策略，以确保混响特征与其它语音属性解耦。这种学习到的表示通过特征插值、替换或从潜在空间采样等技术，实现了混响的灵活控制。

**Result:** 客观和主观评估证实ReverbMiipher能有效保留混响，去除其他伪影，并且优于传统的两阶段SR和卷积模拟房间脉冲响应方法。此外，该模型还展示了通过特征操作生成新颖混响效果的能力。

**Conclusion:** ReverbMiipher成功地实现了在语音去噪的同时保留和控制混响特性，并且表现优异，能够生成新颖的混响效果，为语音修复领域带来了新的突破。

> **ai_Abstract:** ReverbMiipher是一种创新的语音修复模型，它解决了传统SR模型去除混响的问题。通过引入ReverbEncoder和利用参数化重合成框架，该模型能够在去噪的同时精确保留并灵活控制语音的混响特性。实验证明其在保留混响和去除伪影方面表现优异，并能生成新颖的混响效果。

> **摘要翻译:** 混响编码了声源环境的空间信息，然而传统的语音修复（SR）通常会完全去除混响。我们提出了ReverbMiipher，一个扩展参数化重合成框架的SR模型，旨在去噪语音同时保留并实现对混响的控制。ReverbMiipher包含一个专门的ReverbEncoder，用于从噪声输入中提取混响特征向量。该特征条件化一个声码器来重建语音信号，在去除噪声的同时保留原始混响特性。训练期间的随机零向量替换策略确保该特征专门编码混响，将其与其他语音属性解耦。这种学习到的表示通过特征之间的插值、用其他发音的特征替换或从潜在空间采样等技术，促进了混响控制。客观和主观评估证实ReverbMiipher能有效保留混响，去除其他伪影，并且优于传统的两阶段SR和卷积模拟房间脉冲响应方法。我们进一步展示了其通过特征操作生成新颖混响效果的能力。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [314] [Mixture of LoRA Experts with Multi-Modal and Multi-Granularity LLM Generative Error Correction for Accented Speech Recognition](https://arxiv.org/abs/2507.09116)
> *基于LoRA专家混合、多模态和多粒度LLM生成式错误纠正的口音语音识别*

*Bingshen Mu, Kun Wei, Pengcheng Guo, Lei Xie* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-15**

**Keywords:** 口音语音识别, 生成式错误纠正, LoRA专家, 多模态, 多粒度

**Comment:** IEEE Transactions on Audio, Speech and Language Processing

> **TL;DR:** 本文提出了一种结合LoRA专家混合、多模态和多粒度LLM生成式错误纠正的方法，显著提升了口音语音识别的性能，相对词错误率降低了67.35%。

**AI_Comments:** 本文在口音语音识别领域具有显著创新性。它巧妙地将LLM的生成式错误纠正能力与语音模态的细粒度发音信息相结合，解决了传统GER在口音场景下的不足。特别是提出的HDMoLE方法，通过LoRA专家混合和动态路由有效应对了口音多样性这一核心挑战，为多口音环境下的ASR提供了新的解决方案。实验结果的显著提升（67.35% WER降低）证明了其方法的强大有效性和实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管ASR取得了显著进步，但在口音等不利条件下性能会下降。现有的生成式错误纠正（GER）方法缺乏针对口音语音场景的特异性。

**Method:** 本文提出了多模态GER和多粒度GER，以充分利用发音信息。多模态GER整合了语音模态的发音信息，多粒度GER则融入了细粒度的音素级别发音信息。通过LoRA微调，使LLM能利用口音语音的发音和词级假设的语义信息进行转录预测。采用三阶段训练策略为每个口音训练独立的单口音LoRA专家。通过提出的HDMoLE方法（在LoRA专家混合中引入分层路由和动态阈值），有效合并多个单口音LoRA专家以应对口音多样性。多粒度GER利用HDMoLE模型生成的N个最佳词级和音素级假设来预测最终的口音语音转录。

**Result:** 在多口音英语数据集上的实验结果表明，与Whisper-large-v3基线相比，本文方法实现了67.35%的显著相对词错误率（WER）降低。

**Conclusion:** 本文提出的方法有效提高了口音语音识别的准确性，并在实验中展现出显著的有效性。

> **ai_Abstract:** 本文针对口音语音识别中ASR性能下降的问题，提出了一种创新的生成式错误纠正（GER）框架。该框架引入了多模态GER和多粒度GER，分别整合了语音发音信息和细粒度音素信息，并通过LoRA微调使大型语言模型（LLM）能有效利用这些信息进行准确转录。为处理口音多样性，研究提出HDMoLE方法，通过分层路由和动态阈值将多个单口音LoRA专家合并为一个多模态GER。实验结果表明，该方法在多口音英语数据集上，相较于Whisper-large-v3基线，实现了67.35%的词错误率相对降低，显著提升了口音语音识别性能。

> **摘要翻译:** 尽管ASR取得了显著进步，但在面临说话人带有口音等不利条件时，性能往往会下降。生成式错误纠正（GER）利用LLM丰富的语言知识和卓越的推理能力，显著优于典型的LM方法。然而，它在口音语音场景中缺乏特异性。在本研究中，我们利用GER来解决口音语音识别的两个主要特征，以提高转录预测的准确性。为了充分利用发音信息，我们提出了多模态GER，它整合了来自语音模态的发音信息；以及多粒度GER，它结合了与发音相关的细粒度音素级别信息。这两种方法通过LoRA微调，使LLM能够利用口音语音的发音信息和词级假设的语义信息进行准确的转录预测。一方面，我们采用三阶段训练策略，为每个口音训练独立的多模态GER模型，以获得单口音LoRA专家。通过采用我们提出的HDMoLE方法，该方法在LoRA专家混合中结合了分层路由和动态阈值，我们有效地将多个单口音LoRA专家合并到单个多模态GER中，以克服口音多样性带来的挑战。另一方面，多粒度GER利用HDMoLE模型生成的N个最佳词级和音素级假设来预测最终的口音语音转录。在多口音英语数据集上的实验结果证明了我们提出方法的有效性。与Whisper-large-v3基线相比，我们的方法实现了67.35%的显著相对词错误率（WER）降低。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [335] [Improving Neural Pitch Estimation with SWIPE Kernels](https://arxiv.org/abs/2507.11233)
> *使用SWIPE核改进神经音高估计*

*David Marttila, Joshua D. Reiss* | **Category: cs.SD** | **Updated: 2025-07-15**

**Keywords:** 神经音高估计, SWIPE核, 音频前端, 音高估计, 神经网络

**Comment:** Accepted at ISMIR 2025

> **TL;DR:** 通过使用锯齿波启发式音高估计（SWIPE）核作为音频前端，神经音高估计器变得更准确、对噪声更鲁棒、更参数高效。此外，SWIPE算法本身比通常报道的更准确，甚至优于最先进的自监督神经音高估计器。

**AI_Comments:** 本文的创新之处在于将传统的、手工设计的SWIPE特征与现代神经网络相结合，证明了领域特定知识即使在深度学习时代仍能提供显著优势，从而实现更高效、更鲁棒的模型。SWIPE算法本身的高精度发现也值得关注，这表明在某些特定任务上，精心设计的经典算法依然具有强大竞争力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管在网络架构和训练范式方面进行了大量研究，但大多数神经音高估计方法直接在原始音频波形或通用时频表示上操作。本文旨在研究使用手动设计、任务特定的锯齿波启发式音高估计（SWIPE）核作为音频前端，以提高神经音高估计器的准确性、鲁棒性和参数效率。此外，研究还旨在重新评估SWIPE算法本身的性能。

**Method:** 研究人员调查了使用锯齿波启发式音高估计（SWIPE）核作为音频前端对神经音高估计器的影响。他们在监督式和自监督式最先进架构上，使用通用数据集进行了评估。同时，他们也单独评估了SWIPE算法的性能。

**Result:** 1. SWIPE核作为音频前端可以使神经音高估计器更准确、对噪声更鲁棒、更参数高效。
2. SWIPE音频前端允许将网络大小减少一个数量级，而不会降低性能。
3. SWIPE算法本身比通常报道的要准确得多，性能优于最先进的自监督神经音高估计器。

**Conclusion:** 将锯齿波启发式音高估计（SWIPE）核用作音频前端，可以显著提高神经音高估计的准确性、鲁棒性和效率，并能大幅减小网络规模。此外，SWIPE算法本身被证明是一种非常有效的独立音高估计算法，其性能甚至超越了最先进的自监督神经估计器。

> **ai_Abstract:** 本论文探讨了使用锯齿波启发式音高估计（SWIPE）核作为神经音高估计器的音频前端。研究表明，这些手工设计的、任务特定的特征能显著提升神经音高估计的准确性、对噪声的鲁棒性以及参数效率，甚至允许在不损失性能的情况下将网络规模缩小一个数量级。此外，研究还发现，SWIPE算法本身比普遍认为的更准确，其性能超越了目前最先进的自监督神经音高估计器。

> **摘要翻译:** 神经网络已成为精确音高和周期性估计的主导技术。尽管在改进网络架构和训练范式方面进行了大量研究，但大多数方法直接在原始音频波形或通用时频表示上操作。我们研究了使用锯齿波启发式音高估计（SWIPE）核作为音频前端，发现这些手工制作的、任务特定的特征可以使神经音高估计器更准确、对噪声更鲁棒、更参数高效。我们在通用数据集上评估了监督式和自监督式最先进架构，结果表明SWIPE音频前端可以在不降低性能的情况下将网络大小减少一个数量级。此外，我们发现SWIPE算法本身比通常报道的要准确得多，性能优于最先进的自监督神经音高估计器。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [437] [EditGen: Harnessing Cross-Attention Control for Instruction-Based Auto-Regressive Audio Editing](https://arxiv.org/abs/2507.11096)
> *EditGen：利用交叉注意力控制实现基于指令的自回归音频编辑*

*Vassilis Sioros, Alexandros Potamianos, Giorgos Paraskevopoulos* | **Category: cs.SD, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 音频编辑, 交叉注意力, 自回归模型, Prompt-to-Prompt, MUSICGEN

**Comment:** 

> **TL;DR:** 本研究提出EditGen，一个基于交叉注意力控制的自回归模型，用于指令驱动的音频编辑，通过Prompt-to-Prompt方法和结合MUSICGEN，在旋律、动态和节奏方面优于扩散模型基线。

**AI_Comments:** 这项研究创新性地将图像编辑中的Prompt-to-Prompt思想引入到音频编辑领域，并结合了自回归模型（如MUSICGEN），通过细致的注意力控制实现了高质量的指令驱动音频编辑。其超越扩散基线的表现，尤其是在音乐性方面的提升，表明了该方法在未来音频内容创作和编辑中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在探索在自回归模型中利用交叉注意力控制实现高效音频编辑，受图像编辑方法的启发。

**Method:** 开发了一种受Prompt-to-Prompt启发的通过交叉和自注意力机制引导编辑的方法。整合了受Auffusion影响的扩散策略作为基线。引入了结合预训练的MUSICGEN模型的替代方法，并提出了基于注意力分数替换、重新加权和细化的三种编辑机制。

**Result:** 自动和人工评估表明，所提出的Prompt-to-Prompt指导与自回归生成模型的组合在生成音频的旋律、动态和节奏方面显著优于基于扩散的基线。

**Conclusion:** 结合Prompt-to-Prompt指导与自回归生成模型的方法在指令驱动的音频编辑中表现出色，尤其是在旋律、动态和节奏方面，优于扩散基线。

> **ai_Abstract:** 本文介绍了EditGen，一种利用交叉注意力控制在自回归模型中实现高效指令驱动音频编辑的方法。该方法受图像Prompt-to-Prompt启发，通过交叉和自注意力引导编辑。文章对比了基于扩散的基线方法，并提出了一种结合预训练MUSICGEN模型的新方法，该方法包含替换、重新加权和细化注意力分数的三种编辑机制。实验结果表明，结合Prompt-to-Prompt指导与自回归生成模型的方法在旋律、动态和节奏方面显著优于扩散基线。

> **摘要翻译:** 在这项研究中，我们调查了在自回归模型中利用交叉注意力控制实现高效音频编辑的方法。受图像编辑方法的启发，我们开发了一种类似Prompt-to-Prompt的方法，通过交叉和自注意力机制引导编辑。通过整合受Auffusion影响的基于扩散的策略，我们扩展了模型的功能以支持精细编辑，为提示引导的音频编辑建立了基线。此外，我们引入了另一种方法，通过结合预训练的冻结自回归模型MUSICGEN，并提出了基于注意力分数替换、重新加权和细化的三种编辑机制。我们采用常用的音乐特定评估指标和一项人类研究，以衡量时变可控性、对全局文本提示的依从性以及整体音频真实感。自动和人工评估表明，所提出的Prompt-to-Prompt指导与自回归生成模型的组合在生成音频的旋律、动态和节奏方面显著优于基于扩散的基线。我们的代码可在https://github.com/billsioros/EditGen获取。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [585] [A Survey on Speech Deepfake Detection](https://arxiv.org/abs/2404.13914)
> *语音深度伪造检测综述*

*Menglu Li, Yasaman Ahmadiadli, Xiao-Ping Zhang* | **Category: cs.SD, cs.CR, cs.MM, eess.AS** | **Updated: 2025-07-14**

**Keywords:** 语音深度伪造, 检测, 综述, 深度学习, 威胁

**Comment:** 38 pages. This paper has been accepted by ACM Computing Surveys

> **TL;DR:** 这篇综述系统地分析了200多篇关于语音深度伪造检测的论文，详细回顾了检测流程的各个组成部分，并讨论了新兴主题和未来研究方向，旨在为研究人员提供指导。

**AI_Comments:** 该综述的创新之处在于其对截至2024年3月的200多篇论文的全面系统分析，提供了对语音深度伪造检测领域当前进展和挑战的深入洞察。其重要性在于为研究人员提供了建立基线和指导未来研究的宝贵资源，特别是通过探讨新兴主题和潜在研究方向。它对于该领域的研究人员具有高度实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 智能设备的普及导致多媒体内容呈指数级增长，但深度学习技术也使得语音深度伪造内容日益复杂，构成严重威胁。为对抗这一威胁，需要推进语音深度伪造检测技术。

**Method:** 本综述系统地分析了截至2024年3月已发表的200多篇论文，对检测流程中的每个组成部分进行了全面回顾，包括模型架构、优化技术、泛化能力、评估指标、性能比较、可用数据集和开源情况。同时，评估了最新进展并讨论了现有挑战。

**Result:** 本综述提供了对语音深度伪造检测管道中各个组件的全面回顾，评估了最新进展，讨论了持续存在的挑战，并探讨了部分深度伪造检测、跨数据集评估和对抗性攻击防御等新兴主题。

**Conclusion:** 本综述不仅确定了当前最先进的技术，为未来的实验建立了强大的基线，而且为旨在增强语音深度伪造检测系统的研究人员提供了清晰的指导。

> **ai_Abstract:** 本综述系统回顾了语音深度伪造检测领域的200多篇论文，详细分析了检测管道的关键组件，包括模型、优化、泛化、评估、数据集等。它评估了最新进展，讨论了挑战，并探索了新兴研究方向，旨在为研究人员提供当前状态的全面概览和未来研究的指导。

> **摘要翻译:** 智能设备的普及导致多媒体内容呈指数级增长。然而，深度学习的进步也使得高度复杂的深度伪造内容（包括语音深度伪造）得以创建，这通过生成逼真的语音和传播错误信息构成了严重威胁。为了对抗这一点，已经组织了许多挑战来推进语音深度伪造检测技术。在这篇综述中，我们系统地分析了截至2024年3月发表的200多篇论文。我们对检测流程中的每个组成部分进行了全面回顾，包括模型架构、优化技术、泛化能力、评估指标、性能比较、可用数据集和开源可用性。对于每个方面，我们评估了最新进展并讨论了持续存在的挑战。此外，我们探讨了部分深度伪造检测、跨数据集评估和对抗性攻击防御等新兴主题，并提出了有前景的研究方向。本综述不仅识别了当前最先进的技术，为未来的实验建立了强大的基线，而且为旨在增强语音深度伪造检测系统的研究人员提供了清晰的指导。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [3] [Time-series forecasting for nonlinear high-dimensional system using hybrid method combining autoencoder and multi-parallelized quantum long short-term memory and gated recurrent unit](https://arxiv.org/abs/2507.10876)
> *结合自动编码器和多并行量子长短期记忆与门控循环单元的混合方法用于非线性高维系统时间序列预测*

*Makoto Takagi, Ryuji Kokubo, Misato Kurosawa, Tsubasa Ikami, Yasuhiro Egami, Hiroki Nagai, Takahiro Kashikawa, Koichi Kimura, Yutaka Takita, Yu Matsuda* | **Category: quant-ph, eess.SP** | **Updated: 2025-07-15**

**Keywords:** 时间序列预测, 高维系统, 量子长短期记忆, 自动编码器, 稀疏传感器选择

**Comment:** 

> **TL;DR:** 本文提出了一种结合稀疏传感器选择、多并行量子长短期记忆（MP-QLSTM）/门控循环单元（MP-QGRU）和解码器的时间序列预测混合方法，用于高维非线性系统，并展示了其高精度。

**AI_Comments:** 本文的创新点在于结合了稀疏传感器选择、自动编码器（通过解码器实现）以及新颖的多并行量子神经网络（MP-QLSTM/MP-QGRU）进行高维时间序列预测。MP-QLSTM和MP-QGRU通过优化量子电路的使用方式，提高了量子机器学习模型在时间序列预测任务中的性能和表示能力，为处理复杂高维数据提供了一种有前景的混合量子-经典解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 为高维空间数据提出一种时间序列预测方法。

**Method:** 该方法包括三个步骤：首先，通过组合优化选择稀疏传感器位置以有效表示空间域；其次，在这些位置进行时间序列预测，引入多并行量子长短期记忆（MP-QLSTM）和门控循环单元（MP-QGRU），通过将变分量子电路（VQC）的数量扩展到与细胞状态维度相同来改进预测性能，并充分测量每个VQC中的所有量子比特；最后，通过学习到的解码器从预测值估计整个空间分布。

**Result:** MP-QLSTM和MP-QGRU的测试损失比经典LSTM和GRU低约1.5%。MP-QLSTM的均方根百分比误差为0.256%，与使用半导体压力传感器独立测量的值相比，证明了该方法在高维预测任务中的准确性和有效性。

**Conclusion:** 该混合方法，特别是引入MP-QLSTM和MP-QGRU，在高维时间序列预测任务中表现出高精度和有效性。

> **ai_Abstract:** 本文提出了一种用于非线性高维系统时间序列预测的混合方法。该方法首先通过组合优化选择稀疏传感器位置，然后利用新颖的多并行量子长短期记忆（MP-QLSTM）和门控循环单元（MP-QGRU）进行时间序列预测，最后通过学习到的解码器重建完整的空间分布。MP-QLSTM和MP-QGRU通过扩展QLSTM模型并充分测量所有量子比特来增强表示能力。实验结果表明，该方法比传统模型具有更低的测试损失，并对高维预测任务表现出高精度和有效性。

> **摘要翻译:** 提出了一种用于高维空间数据的时间序列预测方法。该方法包括有效表示空间域的稀疏传感器位置的优化选择、这些位置的时间序列预测以及通过学习到的解码器从预测值估计整个空间分布。传感器位置是使用基于组合优化的方法选择的。引入多并行量子长短期记忆（MP-QLSTM）和门控循环单元（MP-QGRU）通过使用与细胞状态维度相同数量的变分量子电路（VQC）扩展QLSTM模型，从而提高了时间序列预测性能。与原始QLSTM不同，我们的方法充分测量了每个VQC中的所有量子比特，最大限度地提高了表示能力。MP-QLSTM和MP-QGRU的测试损失比经典LSTM和GRU低约1.5%。MP-QLSTM的均方根百分比误差为0.256%，与使用半导体压力传感器独立测量的值相比，证明了该方法在高维预测任务中的准确性和有效性。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [114] [A Resource Efficient Quantum Kernel](https://arxiv.org/abs/2507.03689)
> *一种资源高效的量子核*

*Utkarsh Singh, Jean-Frédéric Laprade, Aaron Z. Goldberg, Khabat Heshami* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 量子核, 资源高效, 量子机器学习, 高维数据, 噪声中等规模量子计算

**Comment:** 17 pages, 12 figures

> **TL;DR:** 该研究提出了一种资源高效的量子核，能够用更少的量子比特和纠缠操作处理高维数据，并在准确性和资源利用方面优于现有技术，有望在近期量子计算平台上实现量子机器学习。

**AI_Comments:** 这项工作的主要创新在于提出了一种资源高效的量子核，显著降低了量子机器学习算法对量子硬件的需求，使其在当前的NISQ设备上更具可行性。该研究通过实验证明了其在准确性和资源利用上的优势，并验证了其在噪声环境下的鲁棒性，这对推动量子机器学习的实际应用具有重要意义。然而，论文中提到的“小规模实现”和“近期量子计算平台”也暗示了当前实现的规模限制和对未来硬件发展的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 传统的量子核或特征映射在处理高维数据时，所需的纠缠门数量与数据集维度和量子比特数量呈二次方增长，导致其不切实际，限制了量子机器学习的实际应用。

**Method:** 该研究引入了一种新的量子核，旨在显著减少处理高维数据所需的量子比特和纠缠操作数量。该方法通过在保持数据基本特征的同时提高计算效率来实现这一点。研究通过基准数据集实验、噪声模拟和在超导电路量子计算平台上的小规模实现来验证其性能。

**Result:** 与最先进的量子特征映射相比，该方法在准确性和资源利用方面都有显著提升。噪声模拟结果和低资源需求表明其在噪声中等规模量子设备（NISQ）上的可行性。在超导电路量子计算平台上的数值模拟和小规模实现表明，该方案的性能与一系列经典分类算法相当或更优。

**Conclusion:** 该研究为量子机器学习算法在近期量子计算平台上的实际应用开辟了有前景的途径，解决了现有量子核资源消耗过大的问题。

> **ai_Abstract:** 该研究旨在解决传统量子核在处理高维数据时资源消耗过大的问题。作者提出了一种新型的资源高效量子核，该量子核能够显著减少所需的量子比特和纠缠操作数量。通过在基准数据集上的广泛实验，该方法在准确性和资源利用方面均优于现有技术。研究还通过噪声模拟和在超导电路量子计算平台上的小规模实现，验证了其在噪声中等规模量子设备上的可行性以及与经典算法相当或更优的分类性能，为量子机器学习的实际应用提供了新途径。

> **摘要翻译:** 量子处理器可以通过将高维数据映射到量子系统进行处理来增强机器学习。然而，目前用于将数据特征编码到量子电路中的传统量子核或特征映射是不切实际的，因为纠缠门的数量与数据集维度和量子比特的数量呈二次方增长。在这项工作中，我们引入了一种量子核，旨在以显著减少的量子比特和纠缠操作数量来处理高维数据。我们的方法在保留基本数据特征的同时提高了计算效率，这在对基准数据集进行的广泛实验中得到了证实，这些实验表明与最先进的量子特征映射相比，该方法在准确性和资源利用方面都有显著改进。我们的噪声模拟结果结合较低的资源需求，突出了我们的核在噪声中等规模量子设备约束下运行的能力。通过数值模拟和在超导电路量子计算平台上的小规模实现，我们证明了我们的方案在分类任务上的表现与一系列经典算法相当或更优。我们的发现为量子机器学习算法在近期量子计算平台上的实际实现预示了一条有前景的道路。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [286] [Bridging Paradigms: Designing for HPC-Quantum Convergence](https://arxiv.org/abs/2503.01787)
> *弥合范式：为高性能计算-量子融合而设计*

*Amir Shehata, Peter Groszkowski, Thomas Naughton, Murali Gopalakrishnan Meena, Elaine Wong, Daniel Claudino, Rafael Ferreira da Silvaa, Thomas Beck* | **Category: quant-ph, cs.DC** | **Updated: 2025-07-15**

**Keywords:** 高性能计算, 量子计算, 软件架构, 资源管理, 混合工作流

**Comment:** 14 pages, 14 figures

> **TL;DR:** 本文提出了一种全面的软件栈架构，用于将量子计算能力与高性能计算环境集成，旨在解决量子与经典系统有效集成面临的技术挑战，并展示了其在混合工作流中的能力。

**AI_Comments:** 这项工作在高性能计算与量子计算融合领域具有重要意义。其创新之处在于提出了一个硬件无关的统一软件栈，有效解决了资源管理、调度和数据移动等集成挑战。该框架为未来混合量子-经典计算的发展奠定了基础，具有很高的实用价值和前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** 量子计算机作为科学计算的专用加速器前景广阔，但将其与经典高性能计算系统有效集成面临重大的技术挑战。

**Method:** 本文提出了一种硬件无关的软件框架，支持当前的噪声中尺度量子设备和未来的容错量子计算机，同时保持与现有HPC工作流的兼容性。该架构包括量子网关接口、用于资源管理的标准化API和强大的调度机制。关键创新包括：(1) 统一的资源管理系统，(2) 灵活的量子编程接口，(3) 量子平台管理器API，以及(4) 用于量子电路优化和执行的综合工具链。

**Result:** 通过实现量子-经典算法（包括变分量子线性求解器），展示了该框架处理复杂混合工作流同时最大化资源利用率的能力。

**Conclusion:** 这项工作为将量子计算能力集成到现有高性能计算基础设施提供了基础蓝图，解决了资源管理、作业调度以及经典和量子资源之间高效数据移动的关键挑战。

> **ai_Abstract:** 本文提出了一种用于集成量子计算与高性能计算环境的全面软件栈架构。该硬件无关框架旨在克服量子与经典系统集成的技术挑战，支持现有和未来的量子设备，并兼容HPC工作流。其关键创新包括统一资源管理、灵活编程接口、简化的硬件集成API以及全面的工具链。通过混合算法实现，该架构展示了其处理复杂工作流和优化资源利用的能力，为量子计算融入HPC基础设施提供了基础蓝图。

> **摘要翻译:** 本文提出了一种全面的软件栈架构，用于将量子计算（QC）能力与高性能计算（HPC）环境集成。尽管量子计算机作为科学计算的专用加速器显示出广阔前景，但其与经典HPC系统的有效集成面临重大的技术挑战。我们提出了一种硬件无关的软件框架，支持当前的噪声中尺度量子设备和未来的容错量子计算机，同时保持与现有HPC工作流的兼容性。该架构包括一个量子网关接口、用于资源管理的标准化API以及强大的调度机制，以处理同时和交错的量子-经典工作负载。关键创新包括：(1) 一个统一的资源管理系统，有效协调量子和经典资源；(2) 一个灵活的量子编程接口，抽象化硬件特定细节；(3) 一个量子平台管理器API，简化各种量子硬件系统的集成；以及(4) 一个用于量子电路优化和执行的综合工具链。我们通过实现量子-经典算法，包括变分量子线性求解器，展示了我们的架构，展示了该框架处理复杂混合工作流同时最大化资源利用率的能力。这项工作为将量子计算能力集成到现有HPC基础设施提供了基础蓝图，解决了资源管理、作业调度以及经典和量子资源之间高效数据移动的关键挑战。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [325] [Digital Zero-Noise Extrapolation with Quantum Circuit Unoptimization](https://arxiv.org/abs/2503.06341)
> *数字零噪声外推与量子电路反优化*

*Elijah Pelofske, Vincent Russo* | **Category: quant-ph, cs.DS** | **Updated: 2025-07-14**

**Keywords:** 量子电路反优化, 零噪声外推, 误差缓解, 量子模拟, 电路折叠

**Comment:** 

> **TL;DR:** 量子电路反优化可用于实现数字零噪声外推（ZNE），通过系统地放大噪声并抵抗电路简化，从而有效地从噪声量子模拟中恢复信号。

**AI_Comments:** 这篇论文提出了一种新颖的数字零噪声外推（ZNE）实现方式，即利用量子电路反优化。其创新之处在于利用反优化固有的特性（增加门操作、抵抗简化）来满足ZNE对噪声放大和鲁棒性的需求。通过引入电路变体平均来缓解偏置误差传播是一个重要的改进。这项工作对于在实际量子硬件上应用ZNE具有重要意义，尤其是在考虑到编译器优化对误差缓解技术的影响时。

<details>
  <summary>Details</summary>

**Motivation:** 量子计算中噪声的存在是一个挑战，零噪声外推（ZNE）是一种量子误差缓解技术。本研究的动机是提出并演示一种新的、有效的ZNE实现方式，即利用量子电路反优化，以克服现有ZNE方法可能面临的挑战，例如电路编译器优化对ZNE的影响以及需要缓解偏置误差传播。

**Method:** 本文提出将量子电路反优化作为一种电路折叠形式来实现数字零噪声外推（ZNE）。量子电路反优化是一种将量子电路转换为使用更多门操作但保持相同酉变换的算法。通过这种方法，噪声可以被系统地放大。该方法通过生成指数级增长的不同电路变体来实现噪声平均，以缓解偏置误差传播。此外，反优化设计上抵抗电路简化，使其适用于服务器端应用了电路编译器优化的场景。

**Result:** 通过使用退极化噪声数值模拟，在随机量子体积电路（观测值为重输出概率）和用于随机3-正则图上（无权重）最大割问题的QAOA电路（观测值为割值）这两个测试案例中，评估了量子电路反优化作为ZNE噪声标度方法的有效性。结果表明，使用量子电路反优化执行ZNE可以近似地从噪声量子模拟中恢复信号。

**Conclusion:** 量子电路反优化是一种实现数字零噪声外推（ZNE）的有效方法，它通过系统地放大噪声并允许对多种电路变体进行噪声平均，从而能够从噪声量子模拟中近似恢复信号，并且其设计特性使其适用于存在电路编译器优化的场景。

> **ai_Abstract:** 本文提出并演示了将量子电路反优化应用于数字零噪声外推（ZNE）这一量子误差缓解技术。量子电路反优化通过增加门操作数量来放大噪声，同时保持酉变换不变。该方法具有两大优势：一是能生成指数级增长的电路变体，从而通过平均缓解偏置误差；二是其设计抵抗电路简化，使其适用于存在编译器优化的环境。数值模拟结果表明，该方法能有效从噪声量子模拟中恢复信号。

> **摘要翻译:** 量子电路反优化是一种将量子电路转换为使用更多门操作但保持相同酉变换的算法。我们证明了这种方法可以实现数字零噪声外推（ZNE），这是一种量子误差缓解技术。通过将量子电路反优化作为一种电路折叠形式，可以系统地放大噪声。这种方法的关键优势有两方面。首先，它能够随着噪声水平的放大生成指数级数量的不同电路变体，这允许在许多具有略微不同电路结构的电路变体上进行噪声平均。对这些变体进行平均可以缓解由于量子电路反优化显著改变电路结构或量子处理器上偏置噪声源引起的偏置误差传播效应。其次，量子电路反优化在设计上抵抗电路简化回原始未修改的电路，使其在服务器端应用了电路编译器优化的环境中也能使用ZNE。我们使用退极化噪声数值模拟，在两个测试案例中评估了量子电路反优化作为ZNE噪声标度方法的有效性：随机量子体积电路（其中可观测值为重输出概率）和用于随机3-正则图上（无权重）最大割问题的QAOA电路（其中可观测值为割值）。我们表明，使用量子电路反优化执行ZNE可以近似地从噪声量子模拟中恢复信号。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [345] [Formal Verification of Variational Quantum Circuits](https://arxiv.org/abs/2507.10635)
> *变分量子电路的形式化验证*

*Nicola Assolini, Luca Marzari, Isabella Mastroeni, Alessandra di Pierro* | **Category: quant-ph, cs.LG, cs.PL** | **Updated: 2025-07-14**

**Keywords:** 变分量子电路, 形式化验证, 抽象解释, 量子机器学习, 鲁棒性

**Comment:** Assolini and Marzari contributed equally to the paper

> **TL;DR:** 首次对变分量子电路（VQCs）的形式化验证问题进行了深入研究，提出了一个基于抽象解释的新语义框架来解决其鲁棒性认证的挑战。

**AI_Comments:** 这篇论文的创新点在于首次将形式化验证技术应用于变分量子电路，填补了该领域的一个空白。其重要性在于为量子机器学习模型的鲁棒性认证提供了理论基础和实践方法，对于未来量子计算的可靠性和安全性至关重要。通过引入基于抽象解释的新语义框架，解决了量子特有属性带来的验证挑战。

<details>
  <summary>Details</summary>

**Motivation:** 变分量子电路（VQCs）是量子机器学习的核心组成部分，但与经典深度神经网络类似，它们容易受到对抗性输入的影响。然而，目前缺乏用于认证VQCs鲁棒性的形式化验证框架，而经典模型已有广泛发展。

**Method:** 该研究借鉴深度学习中使用的抽象解释方法，分析了区间可达性技术在量子环境中的适用性和局限性。通过引入一个基于抽象解释的新颖语义框架，形式化定义了VQCs的验证问题并分析了其复杂性。

**Result:** 研究表明，量子特有的方面（如态归一化）引入了变量间的依赖关系，这对现有方法构成了挑战。所提出的方法已在标准验证基准上得到验证。

**Conclusion:** 本文首次对变分量子电路（VQCs）的形式化验证问题进行了深入的理论和实践研究，并提出了一个能够形式化定义和分析其复杂性的新语义框架。

> **ai_Abstract:** 本文首次对变分量子电路（VQCs）的形式化验证问题进行了深入的理论和实践研究。鉴于VQCs与经典深度神经网络一样易受对抗性输入影响但缺乏鲁棒性验证框架，作者借鉴深度学习中的抽象解释方法，分析了区间可达性技术在量子环境下的应用。研究发现量子特有性质（如态归一化）引入的变量间依赖关系对现有方法构成挑战，并为此提出了一个基于抽象解释的新颖语义框架，该框架能够形式化定义VQCs的验证问题并分析其复杂性。该方法已在标准验证基准上得到验证。

> **摘要翻译:** 变分量子电路（VQCs）是许多量子机器学习算法的核心组成部分，提供了一种混合量子-经典框架，在某些方面可以被视为类似于经典的深度神经网络。一个共同的方面是，例如，它们容易受到对抗性输入的影响，即可能导致不正确预测的小扰动。虽然形式化验证技术已在经典模型中得到广泛开发，但目前还没有可比的框架来认证VQCs的鲁棒性。本文首次对VQCs的形式化验证问题进行了深入的理论和实践研究。受深度学习中使用的抽象解释方法的启发，我们分析了基于区间的可达性技术在量子环境中的适用性和局限性。我们表明，量子特有的方面，例如态归一化，引入了变量间的依赖关系，这对现有方法构成了挑战。我们通过引入一个基于抽象解释的新颖语义框架来研究这些问题，在该框架中，VQCs的验证问题可以被形式化定义并分析其复杂性。最后，我们在标准验证基准上演示了我们的方法。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [379] [Transfer Learning Analysis of Variational Quantum Circuits](https://arxiv.org/abs/2501.01507)
> *变分量子电路的迁移学习分析*

*Huan-Hsin Tseng, Hsin-Yi Lin, Samuel Yen-Chi Chen, Shinjae Yoo* | **Category: quant-ph, cs.AI, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 变分量子电路, 迁移学习, 损失边界, 解析微调, 知识转移

**Comment:** Published at ICASSP 2025

> **TL;DR:** 本文分析了变分量子电路（VQC）的迁移学习，建立了一个形式化框架来研究其适应性和能力，并推导了一种解析微调方法。

**AI_Comments:** 这项工作为理解和优化变分量子电路的迁移学习提供了理论基础和实用方法，特别是通过分析损失边界和推导解析微调方法，有助于提升VQC在不同任务中的泛化能力和效率。

<details>
  <summary>Details</summary>

**Motivation:** 研究变分量子电路（VQC）的迁移学习能力，探索其在不同领域间的知识转移机制。

**Method:** 提出一个框架，从一个预训练的VQC开始，计算新领域所需的一参数酉子群的转换。建立形式化方法，通过损失边界分析VQC的适应性和能力。推导解析微调方法以实现相似领域的最佳适应。

**Result:** 观察到VQC中的知识转移，并为该机制提供了启发式解释。推导了一种解析微调方法，用于实现相似领域适应的最佳转换。

**Conclusion:** 本文分析了VQC的迁移学习，建立了研究其适应性和能力的形式化框架，并提供了一种解析微调方法来优化相似领域的适应。

> **ai_Abstract:** 本文深入分析了变分量子电路（VQC）的迁移学习，提出了一个从预训练VQC计算新领域转换的框架。通过损失边界分析，建立了一个形式化方法来研究VQC的适应性和能力，并观察到知识转移现象，提供了启发式解释。此外，还推导了一种解析微调方法以优化相似领域的适应性。

> **摘要翻译:** 这篇工作分析了变分量子电路（VQC）的迁移学习。我们的框架从一个在某个领域预训练的VQC开始，并计算一个新领域所需的一参数酉子群的转换。本文建立了一个形式化框架，通过损失边界分析来研究VQC的适应性和能力。我们的理论观察了VQC中的知识转移，并为该机制提供了一种启发式解释。本文推导了一种解析微调方法，以实现相似领域适应的最佳转换。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [396] [Few Single-Qubit Measurements Suffice to Certify Any Quantum State](https://arxiv.org/abs/2506.11355)
> *少量单量子比特测量足以认证任意量子态*

*Meghal Gupta, William He, Ryan O'Donnell* | **Category: quant-ph, cs.DS** | **Updated: 2025-07-15**

**Keywords:** 量子态认证, 单量子比特测量, 自适应测量, 量子信息, 开放问题

**Comment:** 

> **TL;DR:** 本文证明了只需少量单量子比特测量即可高效认证任意纯量子态，解决了量子信息科学中的一个主要开放问题，并强调了自适应测量的必要性。

**AI_Comments:** 这项工作通过证明仅需多项式数量的单量子比特测量即可认证纯量子态，解决了量子信息科学中的一个重要开放问题，具有显著的创新性。该研究强调了自适应测量在提高测量效率方面的关键作用，并为量子态验证提供了更实际的方法。

<details>
  <summary>Details</summary>

**Motivation:** 量子信息科学中的一项基本任务是状态认证，即测试实验室制备的n量子比特态是否接近给定的假设态。此前，尚不清楚是否亚指数数量的单量子比特测量足以认证任意态，这是一个主要的开放问题。

**Method:** 本文提出了一种算法，该算法仅需对O(n)个实验室态副本进行O(n^2)次单量子比特测量即可认证任何纯假设态。该算法的关键在于利用自适应测量，即在每个实验室态副本中，后续的量子比特测量由先前的测量结果决定。

**Result:** 研究证明，对于每个纯假设态，仅需O(n)个实验室态副本上的O(n^2)次单量子比特测量即可完成认证。这解决了Huang、Preskill和Soleimanifar（FOCS 2024, QIP 2024）提出的主要开放问题。此外，研究还通过证明指数下限，表明了自适应测量对于任何非自适应单量子比特测量算法的必要性。

**Conclusion:** 本文证明了只需少量单量子比特测量即可高效认证任意纯量子态，并且自适应测量对于实现这种效率至关重要，从而解决了量子信息科学中的一个重要开放问题。

> **ai_Abstract:** 本文提出了一种高效认证量子态的方法，证明了仅需对O(n)个实验室态副本进行O(n^2)次单量子比特测量即可认证任意纯量子态。该方法利用了自适应测量，并证明了其必要性，从而解决了量子态认证领域的一个重要开放问题。

> **摘要翻译:** 量子信息科学中的一项基本任务是状态认证：测试实验室制备的n量子比特态是否接近给定的假设态。在这项工作中，我们证明了每个纯假设态仅需对O(n)个实验室态副本进行O(n^2)次单量子比特测量即可认证。在我们的工作之前，尚不清楚是否亚指数数量的单量子比特测量足以认证任意态。这解决了Huang、Preskill和Soleimanifar（FOCS 2024, QIP 2024）提出的主要开放问题。我们的算法也展示了自适应测量的强大能力：在每个实验室态副本中，先前的测量结果决定了后续量子比特测量的进行方式。我们通过证明任何非自适应单量子比特测量算法所需副本数量的指数下限，表明了自适应测量的必要性。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [612] [Stochastic Entanglement Configuration for Constructive Entanglement Topologies in Quantum Machine Learning with Application to Cardiac MRI](https://arxiv.org/abs/2507.11401)
> *量子机器学习中用于建设性纠缠拓扑的随机纠缠配置及其在心脏MRI中的应用*

*Mehri Mehrnia, Mohammed S. M. Elbaz* | **Category: quant-ph, cs.CV, cs.ET, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 随机纠缠配置, 量子机器学习, 变分量子电路, 纠缠拓扑, 心脏MRI

**Comment:** Accepted for publication at IEEE International Conference on Quantum
  Computing and Engineering (QCE) 2025

> **TL;DR:** 本文提出了一种随机纠缠配置方法，用于在量子机器学习中生成并识别能显著提升混合模型性能的纠缠拓扑，并在心脏MRI疾病分类中验证了其优越性。

**AI_Comments:** 本文的创新点在于提出了随机生成和探索纠缠拓扑的方法，而非依赖于固定的预设拓扑，这为优化量子机器学习模型的性能提供了新的思路。其重要性体现在通过系统性地发现“建设性纠缠”，能够显著提升混合量子模型的分类准确率，并超越经典基线和现有量子纠缠策略。该方法具有良好的可扩展性和泛化性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的变分量子电路（VQCs）在量子机器学习（QML）中使用的纠缠拓扑通常是固定的，无法适应任务需求，从而限制了相对于经典模型的性能提升。

**Method:** 本文提出了一种新颖的随机纠缠配置方法，通过系统地生成多样化的纠缠拓扑来识别建设性纠缠配置的子空间。每个配置被编码为随机二进制矩阵，表示量子比特间的有向纠缠。该方法利用纠缠密度和每量子比特约束作为关键指标，支持对候选纠缠拓扑超空间的探索。定义了无约束和有约束的采样模式。

**Result:** 在心脏MRI疾病分类的混合QML中，生成并评估了400种随机配置，识别出64种（16%）新型建设性纠缠配置，它们持续优于经典基线。性能最佳配置的集成聚合达到了约0.92的分类准确率，超过经典模型（约0.87）5%以上。与四种传统拓扑（环形、最近邻、无纠缠、完全纠缠）相比，本文的配置实现了高达约20%的准确率提升。

**Conclusion:** 所识别的建设性纠缠具有鲁棒性和泛化性，能够显著提升量子机器学习模型在特定任务上的性能，超越传统固定纠缠拓扑和经典模型。

> **ai_Abstract:** 该研究提出了一种名为随机纠缠配置的新方法，旨在解决量子机器学习中变分量子电路固定纠缠拓扑的局限性。通过系统生成并探索多样化的纠缠拓扑，该方法能够识别出“建设性纠缠配置”，即那些能显著提升混合模型性能的拓扑。在心脏MRI疾病分类的应用中，该方法成功识别出大量优于经典基线和传统固定拓扑的纠缠配置，验证了其在提高量子机器学习模型准确率方面的有效性和普适性。

> **摘要翻译:** 高效的纠缠策略对于推进量子机器学习（QML）中的变分量子电路（VQCs）至关重要。然而，大多数当前方法使用固定的纠缠拓扑，无法适应任务需求，限制了相对于经典模型的潜在增益。我们引入了一种新颖的随机纠缠配置方法，系统地生成多样化的纠缠拓扑，以识别建设性纠缠配置的子空间，这些配置被定义为能够将混合模型性能（例如分类准确率）提升到超越经典基线的纠缠拓扑。每个配置都被编码为一个随机二进制矩阵，表示量子比特之间的有向纠缠。这使得可以使用纠缠密度和每量子比特约束作为关键指标，可扩展地探索候选纠缠拓扑的超空间。我们定义了无约束和有约束的采样模式，控制每个量子比特的纠缠。使用我们的方法，在用于心脏MRI疾病分类的混合QML中生成并评估了400个随机配置。我们识别出64个（16%）新型建设性纠缠配置，它们持续优于经典基线。性能最佳配置的集成聚合达到了约0.92的分类准确率，超过经典模型（约0.87）5%以上。与四种传统拓扑（环形、最近邻、无纠缠、完全纠缠）相比，没有一种超越经典基线（最大准确率约0.82），而我们的配置提供了高达约20%的更高准确率。因此，这突出了所识别的建设性纠缠的鲁棒性和泛化性。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [648] [Sharp Error-Rate Transitions in Quantum QC-LDPC Codes under Joint BP Decoding](https://arxiv.org/abs/2507.11534)
> *联合BP解码下量子QC-LDPC码的急剧误码率转变*

*Daiki Komoto, Kenta Kasai* | **Category: quant-ph, cs.IT, math.IT** | **Updated: 2025-07-15**

**Keywords:** 量子QC-LDPC码, 联合BP解码, 误码率转变, 误码平层, 陷阱集

**Comment:** 

> **TL;DR:** 本研究发现，通过联合置信传播（BP）解码的量子准循环低密度奇偶校验（QC-LDPC）码表现出陡峭的误码率曲线，尽管存在误码平层。这是首次观察到非零编码率量子码的这种类阈值行为（非二元BP解码器除外）。研究还发现，导致误码平层的主要错误事件通常只涉及少量比特，这表明误码平层是由陷阱集引起的，识别并避免这些结构可以进一步降低误码平层。

**AI_Comments:** 这篇论文的创新点在于首次观察到非零编码率量子码在联合BP解码下的类阈值行为，这对于量子纠错码的实际应用具有重要意义。通过指出误码平层与陷阱集的关系，为未来降低误码率提供了明确的方向，即通过编码设计或改进解码算法来避免这些有害结构。

<details>
  <summary>Details</summary>

**Motivation:** 尽管存在误码平层，但通过联合置信传播（BP）解码的量子准循环低密度奇偶校验（QC-LDPC）码表现出陡峭的误码率曲线，并且这是首次观察到非零编码率量子码的这种类阈值行为（非二元BP解码器除外）。

**Method:** 研究人员通过联合置信传播（BP）解码量子准循环低密度奇偶校验（QC-LDPC）码，并观察其误码率曲线。

**Result:** 研究发现，量子QC-LDPC码在联合BP解码下表现出陡峭的误码率曲线，尽管存在误码平层。这是首次观察到非零编码率量子码的这种类阈值行为（非二元BP解码器除外）。此外，研究还发现导致误码平层的主要错误事件通常只涉及少量比特，这表明误码平层是由Tanner图中的特定子图结构——陷阱集——引起的。

**Conclusion:** 这些发现表明，识别并避免Tanner图中的陷阱集结构可能导致误码平层进一步降低。

> **ai_Abstract:** 本研究揭示了通过联合置信传播（BP）解码的量子准循环低密度奇偶校验（QC-LDPC）码具有急剧的误码率转变，即便存在误码平层。这是首次在非零编码率量子码（非二元BP解码器解码的除外）中观察到这种类阈值行为。研究进一步指出，导致误码平层的主要错误事件涉及少量比特，暗示陷阱集是其根本原因，并建议通过识别和规避这些结构来降低误码平层。

> **摘要翻译:** 在这项研究中，我们报告称，通过联合置信传播（BP）解码的量子准循环低密度奇偶校验码（QC-LDPC）表现出陡峭的误码率曲线，尽管存在误码平层。据我们所知，这是首次观察到具有非零编码率的量子码的这种类阈值行为，不包括那些使用非二元BP解码器解码的码。此外，我们发现导致误码平层的主要错误事件通常只涉及少量比特。这些发现表明，误码平层是由陷阱集——Tanner图中的特定子图结构——引起的，并指出识别和避免此类结构可能会导致误码平层进一步降低。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [774] [Power Consumption Analysis of QKD Networks under Different Protocols and Detector Configurations](https://arxiv.org/abs/2507.09719)
> *量子密钥分发网络在不同协议和探测器配置下的功耗分析*

*Jiaheng Xiong, Qiaolun Zhang, Yoann Piétri, Raja Yehia, Raouf Boutaba, Francesco Musumeci, Massimo Tornatore* | **Category: quant-ph, cs.NI** | **Updated: 2025-07-15**

**Keywords:** 量子密钥分发, 功耗分析, 网络拓扑, 探测器, 光旁路

**Comment:** This version of the paper was uploaded without the prior approval of
  all listed authors. Some authors did not fully review and confirm the
  content, leading to unresolved concerns about clarity and accuracy. We intend
  to address these issues through further discussions and will resubmit after
  obtaining consent from all authors

> **TL;DR:** 本文分析了不同协议和探测器配置下量子密钥分发网络的功耗，评估了离散变量与连续变量QKD，优化了设备放置，并量化了SNSPD与APD探测器的功耗权衡及光旁路的好处。

**AI_Comments:** Not mentioned in abstract

<details>
  <summary>Details</summary>

**Motivation:** 分析量子密钥分发（QKD）网络在不同协议和探测器配置下的功耗。

**Method:** 使用真实的网络拓扑，评估离散变量（discrete-variable）与连续变量（continuous-variable）QKD，优化设备放置，并量化SNSPD与APD探测器的功耗权衡以及光旁路的益处。

**Result:** 评估了离散变量与连续变量QKD的功耗，优化了设备放置，量化了SNSPD与APD探测器的功耗权衡，并评估了光旁路的益处。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文研究了量子密钥分发（QKD）网络在不同协议和探测器配置下的功耗。通过使用真实的网络拓扑，研究人员评估了离散变量和连续变量QKD的性能，优化了设备布局，并量化了超导纳米线单光子探测器（SNSPD）和雪崩光电二极管（APD）探测器的功耗权衡，同时探讨了光旁路带来的优势。

> **摘要翻译:** 我们分析了量子密钥分发（QKD）网络在各种协议和探测器配置下的功耗。利用真实的网络拓扑，我们评估了离散变量与连续变量QKD，并优化了设备放置，量化了SNSPD与APD探测器的功耗权衡以及光旁路的益处。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicssoc-ph'></a>
## physics.soc-ph 

### [17] [An Interpretable AI framework Quantifying Traditional Chinese Medicine Principles Towards Enhancing and Integrating with Modern Biomedicine](https://arxiv.org/abs/2507.11176)
> *一个可解释的人工智能框架，量化中医药原理以增强和整合现代生物医学*

*Haoran Li, Xingye Cheng, Ziyang Huang, Jingyuan Luo, Qianqian Xu, Qiguang Zhao, Tianchen Guo, Yumeng Zhang, Linda Lidan Zhong, Zhaoxiang Bian, Leihan Tang, Aiping Lyu, Liang Tian* | **Category: physics.soc-ph, cs.LG, q-bio.OT, stat.ML** | **Updated: 2025-07-15**

**Keywords:** 中医药, AI框架, 可解释AI, 嵌入空间, 知识图谱

**Comment:** 31 pages, 6 figures

> **TL;DR:** 一个AI框架通过历史数据量化了中医药原理，创建了一个可解释的嵌入空间（TCM-ES），该空间与生物功能对齐并预测新的关联，从而连接了中医药与现代生物医学。

**AI_Comments:** 该论文创新性地利用人工智能量化和解释经验性中医药原理，解决了中医药与现代生物医学整合的长期挑战。其创建的中医嵌入空间和知识图谱为中医药提供了急需的量化基础和生物学验证，有望加速药物发现和个性化医疗。将中医药概念与生物功能对齐是弥合两种不同医学范式的重大一步。

<details>
  <summary>Details</summary>

**Motivation:** 中医药诊断和治疗原则虽然通过数百年临床实践建立，并能将患者症状模式与个性化草药疗法直接对应，为现代生物医学还原论方法论所面临的挑战提供了宝贵策略。然而，由于缺乏量化框架和分子层面的证据，其可解释性和可靠性受到限制。

**Method:** 本文提出了一个基于古代和经典中医方剂记录训练的AI框架，用于量化症状模式与草药疗法之间的映射关系。该框架通过模型的量化表示构建了一个可解释的中医嵌入空间（TCM-ES），并将生物医学实体映射到TCM-ES中。此外，还构建了一个全面且整合的中医知识图谱。

**Result:** 经验性中医诊断和治疗与AI模型的编码-解码过程一致。TCM-ES能够对中医实践和治疗效果进行普适性量化。TCM-ES的主要方向与关键生物功能（如新陈代谢、免疫和稳态）显著相关，并且疾病与草药嵌入的接近性与其在人类蛋白质相互作用组中的遗传关系一致，这证明了中医原理的生物学意义。此外，TCM-ES揭示了潜在的疾病关系，并为评估现代疾病-药物对的临床疗效提供了替代指标。最后，构建的中医知识图谱预测了疾病与靶点、药物、草药化合物以及草药疗法之间的潜在关联。

**Conclusion:** 该AI框架成功量化并解释了中医药原理，证明了其生物学意义，并为与现代生物医学的整合提供了桥梁，为疾病分析和药物开发开辟了新途径。

> **ai_Abstract:** 本文介绍了一个可解释的AI框架，通过学习历史中医方剂记录来量化中医药原理。该框架生成了一个中医嵌入空间（TCM-ES），为中医实践和治疗效果提供了普适性量化。通过将生物医学实体与TCM-ES对齐，研究表明中医原理与基本的生物功能和遗传关系相关。TCM-ES还揭示了隐藏的疾病联系，并为评估现代药物疗效提供了一种新方法。此外，该框架构建了一个中医知识图谱，以预测疾病分析和药物开发的潜在关联，从而增强了中医药与现代生物医学的整合。

> **摘要翻译:** 中医药诊断和治疗原则经过数百年临床实践的反复试验而建立，能直接将患者特异性症状模式映射到个性化草药疗法。这些经验性的整体映射原则为解决现代生物医学中还原论方法论的遗留挑战提供了宝贵的策略。然而，缺乏量化框架和分子层面的证据限制了它们的可解释性和可靠性。在此，我们提出了一个基于古代和经典中医方剂记录训练的AI框架，用于量化症状模式-草药疗法映射。有趣的是，我们发现经验性中医诊断和治疗与AI模型中的编码-解码过程一致。这使我们能够利用模型对中医原理的量化表示构建一个可解释的中医嵌入空间（TCM-ES）。通过广泛而大量的中医患者数据验证，TCM-ES提供了中医实践和治疗效果的普适性量化。我们通过对应对齐将生物医学实体进一步映射到TCM-ES中。我们发现TCM-ES的主要方向与关键生物功能（如新陈代谢、免疫和稳态）显著相关，并且疾病与草药嵌入的接近性与其在人类蛋白质相互作用组中的遗传关系一致，这证明了中医原理的生物学意义。此外，TCM-ES揭示了潜在的疾病关系，并为评估现代疾病-药物对的临床疗效提供了替代指标。最后，我们构建了一个全面且整合的中医知识图谱，预测了疾病与靶点、药物、草药化合物和草药疗法之间的潜在关联，为疾病分析和药物开发提供了中医启发的机会。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

### [322] [HIF: The hypergraph interchange format for higher-order networks](https://arxiv.org/abs/2507.11520)
> *HIF：高阶网络的超图交换格式*

*Martín Coll, Cliff A. Joslyn, Nicholas W. Landry, Quintino Francesco Lotito, Audun Myers, Joshua Pickard, Brenda Praggastis, Przemysław Szufel* | **Category: physics.soc-ph, cs.SI** | **Updated: 2025-07-15**

**Keywords:** 超图, 高阶网络, 数据格式, 互操作性, HIF

**Comment:** 13 pages, 9 figures

> **TL;DR:** 引入HIF，一种标准化数据格式，旨在实现碎片化的高阶网络分析软件之间的数据无缝交换。

**AI_Comments:** 该论文解决了高阶网络分析领域一个关键的互操作性问题，这对于该领域的进一步发展至关重要。其创新点在于提出了一种通用的标准化数据格式HIF，并提供了全面的实现细节和支持工具（JSON模式、文档、示例、教程）。这种协作式的努力和实际的交付物使其成为一个具有潜在影响力的标准，能够显著提高不同软件工具之间的数据交换效率和研究可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 许多经验系统包含任意大小的复杂交互，这些交互形成了高阶网络或超图。然而，高阶网络分析软件生态系统由于各自的编程接口和兼容数据表示的专业化而碎片化，阻碍了数据交换。

**Method:** 本文引入了超图交换格式（HIF），一种用于存储高阶网络数据的标准化格式。HIF支持多种类型的高阶网络，包括无向超图、有向超图和单纯复形，并积极探索扩展以表示多路超图、时间超图和有序超图。HIF还支持与节点、边和关联相关的属性。该项目提供了一个JSON模式，附带文档和单元测试、符合HIF的示例数据集以及演示HIF与流行高阶网络分析软件配合使用的教程。

**Result:** 本文成功引入了超图交换格式（HIF），这是一种标准化格式，支持多种高阶网络类型和丰富的元数据。该项目提供了完整的JSON模式、相应的文档、单元测试、符合HIF的示例数据集以及详细的教程，这些成果共同促进了高阶网络分析软件之间的数据互操作性。

**Conclusion:** HIF的引入解决了高阶网络分析软件生态系统碎片化的问题，实现了不同软件之间数据的无缝交换，从而促进了该领域的研究和应用。

> **ai_Abstract:** 本文针对高阶网络分析软件生态系统碎片化的问题，提出并引入了超图交换格式（HIF）。HIF是一种标准化的JSON格式，旨在促进不同高阶网络分析工具之间的数据无缝交换。它支持多种超图类型和丰富的元数据，并提供了完整的JSON模式、文档、测试用例、示例数据集和使用教程，以确保其广泛应用和互操作性。

> **摘要翻译:** 许多经验系统包含任意大小的复杂交互，例如化学反应、社会群体、合著关系和生态依赖。这些交互被称为高阶交互，它们的集合构成了高阶网络或超图。超图已成为此类系统流行且通用的数学表示形式，并且已经设计了许多用各种编程语言编写的软件包来分析这些网络。然而，由于每个软件的编程接口和兼容数据表示的专业化，高阶网络分析软件的生态系统是碎片化的。为了实现高阶网络分析软件包之间的数据无缝交换，我们引入了超图交换格式（HIF），一种用于存储高阶网络数据的标准化格式。HIF支持多种类型的高阶网络，包括无向超图、有向超图和单纯复形，同时积极探索扩展以表示多路超图、时间超图和有序超图。为了适应不同上下文中使用的各种元数据，HIF还包括对与节点、边和关联相关的属性的支持。这项倡议是来自知名超图软件包的作者、维护者和贡献者的协作努力。该项目引入了一个带有相应文档和单元测试的JSON模式、符合HIF的示例数据集以及演示HIF与几个流行高阶网络分析软件包配合使用的教程。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='q-bioqm'></a>
## q-bio.QM 

### [48] [A PBN-RL-XAI Framework for Discovering a "Hit-and-Run" Therapeutic Strategy in Melanoma](https://arxiv.org/abs/2507.10136)
> *PBN-RL-XAI框架用于发现黑色素瘤中的“速战速决”治疗策略*

*Zhonglin Liu* | **Category: q-bio.QM, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 黑色素瘤, 免疫疗法耐药性, 概率布尔网络, 强化学习, 可解释人工智能

**Comment:** 9 pages, 5 figures. Submitted to the IEEE International Conference on
  Bioinformatics and Biomedicine (BIBM) 2025. Code is available at
  https://github.com/Liu-Zhonglin/pbn-melanoma-project

> **TL;DR:** 本研究提出了一个PBN-RL-XAI框架，通过分析患者肿瘤活检的转录组数据，发现了一种针对黑色素瘤抗PD-1免疫疗法耐药性的“速战速决”治疗策略，即精确计时的LOXL2蛋白短期抑制。

**AI_Comments:** 这篇论文的创新点在于结合了概率布尔网络、强化学习和可解释人工智能，形成了一个强大的计算框架，用于发现复杂生物系统中的非显而易见的治疗干预方案。特别是“速战速决”的治疗策略概念非常新颖，它强调了干预的时机和短暂性，可能为耐药性问题提供新的解决思路。其重要性在于为个性化医疗和精准治疗提供了计算工具和理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 黑色素瘤对PD-1免疫疗法的先天性耐药性是一个主要的临床挑战，且其潜在分子网络尚不清楚。为了解决这个问题，需要阐明调控治疗反应的分子机制并发现有效的干预策略。

**Method:** 研究构建了一个动态概率布尔网络（PBN）模型，利用患者肿瘤活检的转录组数据来阐明调控治疗反应的逻辑。随后，使用强化学习（RL）代理来系统性地发现最佳的多步治疗干预措施，并利用可解释人工智能（XAI）来机械性地解释代理的控制策略。

**Result:** 分析发现，精确计时的4步暂时抑制赖氨酰氧化酶样2蛋白（LOXL2）是最有效的策略。可解释性分析表明，这种“速战速决”的干预足以消除驱动耐药性的分子特征，使网络能够自我纠正而无需持续干预。

**Conclusion:** 本研究提出了一种新型的、时间依赖的治疗假设，用于克服免疫疗法耐药性，并提供了一个强大的计算框架，用于在复杂生物系统中识别非显而易见的干预方案。

> **ai_Abstract:** 本研究旨在解决转移性黑色素瘤对PD-1免疫疗法耐药性的问题。通过构建基于转录组数据的动态概率布尔网络模型，并结合强化学习和可解释人工智能，作者发现了一种名为“速战速决”的治疗策略。该策略涉及精确计时地短期抑制LOXL2蛋白，结果显示其能有效消除耐药性的分子特征，使网络自我纠正。这为克服免疫疗法耐药性提供了一种新颖的时间依赖性治疗假设和一个强大的计算框架。

> **摘要翻译:** 转移性黑色素瘤对PD-1免疫疗法的先天性耐药性仍然是一个主要的临床挑战，其潜在的分子网络知之甚少。为了解决这个问题，我们利用患者肿瘤活检的转录组数据构建了一个动态概率布尔网络模型，以阐明调控治疗反应的调控逻辑。然后，我们采用强化学习代理系统地发现最佳的多步治疗干预措施，并使用可解释人工智能机械地解释代理的控制策略。分析显示，精确计时的四步暂时抑制赖氨酰氧化酶样2蛋白（LOXL2）是最有效的策略。我们的可解释性分析表明，这种“速战速决”的干预足以消除驱动耐药性的分子特征，使网络能够自我纠正，而无需持续干预。这项研究提出了一种新颖的、时间依赖的治疗假设，用于克服免疫疗法耐药性，并提供了一个强大的计算框架，用于在复杂生物系统中识别非显而易见的干预方案。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

### [149] [AGFS-Tractometry: A Novel Atlas-Guided Fine-Scale Tractometry Approach for Enhanced Along-Tract Group Statistical Comparison Using Diffusion MRI Tractography](https://arxiv.org/abs/2507.10601)
> *AGFS-Tractometry：一种新颖的图谱引导精细尺度束测量方法，用于增强使用扩散MRI束成像的沿束组统计比较*

*Ruixi Zheng, Wei Zhang, Yijie Li, Xi Zhu, Zhou Lan, Jarrett Rushmore, Yogesh Rathi, Nikos Makris, Lauren J. O'Donnell, Fan Zhang* | **Category: q-bio.QM, cs.CV, cs.LG, eess.IV, stat.ME** | **Updated: 2025-07-12**

**Keywords:** 扩散MRI, 束测量, AGFS-Tractometry, 白质, 统计比较

**Comment:** 31 pages and 7 figures

> **TL;DR:** AGFS-Tractometry是一种新的图谱引导精细尺度束测量方法，通过创建新模板和使用非参数置换检验，提高了扩散MRI束成像中沿束组统计比较的灵敏度和特异性。

**AI_Comments:** AGFS-Tractometry的创新之处在于结合了图谱引导的精细尺度分块和非参数置换检验，有效解决了传统束测量方法在沿束统计比较中可能存在的局限性，特别是在多重比较校正和提高检测灵敏度方面。其开源的代码和模板也促进了研究的可重复性和进一步发展。

<details>
  <summary>Details</summary>

**Motivation:** 扩散MRI束成像的束测量技术是研究不同人群（如健康与疾病）之间局部沿束差异的重要工具，但现有方法可能在沿束统计分析中存在局限性，因此需要一种新的方法来增强这种比较。

**Method:** 本研究提出了一种名为AGFS-Tractometry的新型图谱引导精细尺度束测量方法。该方法有两个主要贡献：1. 创建了一个新颖的图谱引导束剖析模板，以实现主体特定纤维束的一致、精细尺度、沿束分块。2. 提出了一种新的非参数置换检验组比较方法，以在校正多重比较的同时，实现所有沿束分块的同时分析。

**Result:** 通过在合成数据集和体内真实数据上的实验评估，AGFS-Tractometry在检测局部白质差异方面获得了增强的灵敏度和特异性。在真实数据分析实验中，AGFS-Tractometry能够识别出更多具有显著差异的区域，这些区域与现有文献在解剖学上一致。

**Conclusion:** AGFS-Tractometry能够检测到细微或空间局部化的白质组水平差异，显示出其在增强沿束组统计比较方面的能力。

> **ai_Abstract:** 本研究提出了一种名为AGFS-Tractometry的新型图谱引导精细尺度束测量方法，旨在增强扩散MRI束成像中的沿束组统计比较。该方法通过引入一个创新的图谱引导束剖析模板和一个非参数置换检验组比较方法，实现了对主体特定纤维束的一致、精细尺度分块和多重比较校正下的同时分析。实验结果表明，AGFS-Tractometry在检测局部白质差异方面比现有方法具有更高的灵敏度和特异性，并能识别出与解剖学文献一致的显著差异区域，证明了其检测细微或局部白质组水平差异的能力。

> **摘要翻译:** 扩散MRI（dMRI）束成像目前是唯一一种体内绘制大脑白质（WM）连接的方法。束测量是一种先进的束成像分析技术，用于沿束分析以研究纤维束的形态和微观结构特性。束测量已成为研究不同人群（例如健康与疾病）之间局部沿束差异的重要工具。在本研究中，我们提出了一种新颖的图谱引导精细尺度束测量方法，即AGFS-Tractometry，该方法利用束空间信息和置换检验来增强人群之间的沿束统计分析。AGFS-Tractometry有两个主要贡献。首先，我们创建了一个新颖的图谱引导束剖析模板，该模板能够对主体特定的纤维束进行一致的、精细尺度的沿束分块。其次，我们提出了一种新的非参数置换检验组比较方法，以在校正多重比较的同时，实现所有沿束分块的同时分析。我们对具有已知组差异的合成数据集和体内真实数据进行了实验评估。我们将AGFS-Tractometry与两种最先进的束测量方法进行了比较，包括自动化纤维束量化（AFQ）和束分析（BUAN）。我们的结果表明，所提出的AGFS-Tractometry在检测局部白质差异方面获得了增强的灵敏度和特异性。在真实数据分析实验中，AGFS-Tractometry能够识别出更多具有显著差异的区域，这些区域与现有文献在解剖学上一致。总的来说，这些结果表明AGFS-Tractometry能够检测细微或空间局部化的白质组水平差异。所创建的束剖析模板和相关代码可在以下网址获取：https://github.com/ZhengRuixi/AGFS-Tractometry.git。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

### [491] [Test-time Adaptation for Foundation Medical Segmentation Model without Parametric Updates](https://arxiv.org/abs/2504.02008)
> *无需参数更新的医学基础分割模型测试时间自适应*

*Kecheng Chen, Xinyu Luo, Tiexin Qin, Jie Liu, Hui Liu, Victor Ho Fun Lee, Hong Yan, Haoliang Li* | **Category: q-bio.QM, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 测试时间自适应, 医学分割, 基础模型, 图像嵌入, 计算效率

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 本文提出一种无需参数更新的医学基础分割模型测试时间自适应方法，通过直接优化图像嵌入来提高分割性能并显著降低计算复杂度，同时避免灾难性遗忘。

**AI_Comments:** 本文提出了一种新颖的测试时间自适应范式，通过直接优化图像嵌入而非模型参数，解决了大型基础模型在TTA中面临的灾难性遗忘和高计算成本问题。这种创新方法在提高分割性能的同时，大幅提升了效率，对于将基础模型应用于实际医疗场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的医学图像分割测试时间自适应（TTA）方法在处理如MedSAM等大型基础模型时，存在参数更新（部分或全部）导致的有效性受限（更新信号有限或灾难性遗忘）以及计算复杂度高的问题，尤其是在处理结构复杂和外观精细的病灶时性能受损。

**Method:** 本文提出通过直接优化图像嵌入来实现与参数更新相同的目标，从而提高计算效率和分割性能，并避免灾难性遗忘。具体方法是使用一种结合了熵最小化损失的“分布近似潜在条件随机场损失”来鼓励最大化后验预测概率的因子化条件概率。

**Result:** 实验结果表明，该方法在三个数据集上实现了约3%的Dice分数提升，同时计算复杂度降低了7倍以上。

**Conclusion:** 通过直接优化图像嵌入，本文提出了一种高效且无需参数更新的测试时间自适应方法，显著提升了医学基础分割模型在特定病灶上的性能，并大幅降低了计算成本，有效解决了现有TTA方法的局限性。

> **ai_Abstract:** 本文针对医学基础分割模型（如MedSAM）在处理复杂病灶和提示扰动时的性能下降问题，提出了一种无需参数更新的测试时间自适应（TTA）方法。通过理论分析，研究发现直接优化图像嵌入可以达到与参数更新相似的效果，且能显著提高计算效率并避免灾难性遗忘。该方法通过结合“分布近似潜在条件随机场损失”和熵最小化损失来最大化后验预测概率的因子化条件概率。实验证明，该方法在提高分割性能的同时，大幅降低了计算复杂度。

> **摘要翻译:** 基础医学分割模型，其中MedSAM最为流行，在器官和病灶分割方面取得了可喜的性能。然而，MedSAM在处理结构复杂和外观精细的特定病灶时，以及在边界框提示引起的扰动下，性能仍然会受到影响。尽管当前的医学图像分割测试时间自适应（TTA）方法可能能够解决这个问题，但部分（例如，批量归一化）或全部参数更新限制了它们的有效性，因为更新信号有限或在大型模型中存在灾难性遗忘。同时，这些方法忽略了自适应过程中的计算复杂度，这对于现代基础模型尤为重要。为此，我们的理论分析表明，在MedSAM架构下，直接优化图像嵌入可以实现与参数更新相同的目标，这使我们能够在不发生灾难性遗忘风险的情况下实现高计算效率和分割性能。在此框架下，我们提出使用一种结合了熵最小化损失的“分布近似潜在条件随机场损失”来鼓励最大化后验预测概率的因子化条件概率。实验表明，我们在三个数据集上实现了约3%的Dice分数提升，同时计算复杂度降低了7倍以上。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

<a id='gr-qc'></a>
## gr-qc 

### [53] [Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis](https://arxiv.org/abs/2507.11192)
> *引力波数据分析中基于模拟推断的最新进展*

*Bo Liang, He Wang* | **Category: gr-qc, astro-ph.HE, astro-ph.IM, cs.LG, stat.ML** | **Updated: 2025-07-15**

**Keywords:** 引力波, 基于模拟推断, 机器学习, 神经后验估计, 数据分析

**Comment:** 30 pages, 6 figures, 1 table. Published version accepted by
  Astronomical Techniques and Instruments (ATI)

> **TL;DR:** 引力波数据分析中，基于模拟的推断方法（特别是结合机器学习的技术）正成为解决传统贝叶斯方法计算挑战的新兴工具。本文综述了这些方法及其应用，并指出了它们的优点和局限性。

**AI_Comments:** 本文是一篇综述性文章，系统地介绍了基于模拟推断方法在引力波数据分析中的应用。其创新点在于将机器学习技术引入引力波数据分析，以克服传统贝叶斯方法的计算瓶颈。然而，文中也坦诚指出了这些新兴方法的局限性，如对模型和先验假设的依赖性，以及准确性验证的不足，这为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的贝叶斯推断方法在处理引力波数据固有的高维参数空间和复杂噪声特性时面临显著的计算挑战，因此需要更快速、详细的参数估计和群体层面分析方法。

**Method:** 本文综述了基于模拟的推断方法，特别是利用机器学习技术（如归一化流、神经后验估计）的方法。具体涵盖了神经后验估计、神经比率估计、神经似然估计、流匹配和一致性模型等理论基础，并探讨了它们在引力波数据处理场景中的应用。

**Result:** 在受控研究中，这些基于模拟的推断技术相比传统方法显示出速度上的提升。

**Conclusion:** 尽管基于模拟的推断方法在速度上有所改进，但其模型依赖性和对先验假设的敏感性阻碍了其广泛采用。此外，其准确性与传统方法相似，需要在更广泛的参数空间和噪声条件下进行进一步验证。

> **ai_Abstract:** 本文综述了引力波数据分析中基于模拟推断（SBI）方法的最新进展，特别关注利用机器学习技术的方法。文章指出传统贝叶斯方法在处理高维引力波数据时面临的计算挑战，并详细介绍了神经后验估计等多种SBI方法的理论基础及其在不同应用场景中的实践。尽管这些新方法在速度上有所提升，但其模型依赖性、对先验假设的敏感性以及准确性需进一步验证等局限性仍需关注。

> **摘要翻译:** LIGO-Virgo-KAGRA合作组织对引力波的探测开创了观测天文学的新纪元，强调了快速详细的参数估计和群体层面分析的必要性。传统的贝叶斯推断方法，特别是马尔可夫链蒙特卡罗，在处理引力波数据固有的高维参数空间和复杂噪声特性时面临显著的计算挑战。本文综述了基于模拟推断方法在引力波天文学中新兴的作用，重点关注利用机器学习技术（如归一化流和神经后验估计）的方法。我们全面概述了各种基于模拟推断方法（包括神经后验估计、神经比率估计、神经似然估计、流匹配和一致性模型）的理论基础。我们探讨了这些方法在不同引力波数据处理场景中的应用，从单源参数估计和重叠信号分析到检验广义相对论和进行群体研究。尽管这些技术在受控研究中显示出比传统方法更快的速度改进，但其模型依赖性和对先验假设的敏感性是其广泛采用的障碍。它们的准确性与传统方法相似，需要在更广泛的参数空间和噪声条件下进行进一步验证。

</details>

[⬆️ 返回分类顶部](#gr-qc) | [⬆️ 返回总目录](#toc)

---

<a id='csgt'></a>
## cs.GT 

### [84] [PPA-Game: Characterizing and Learning Competitive Dynamics Among Online Content Creators](https://arxiv.org/abs/2403.15524)
> *PPA-Game：表征和学习在线内容创作者之间的竞争动态*

*Renzhe Xu, Haotian Wang, Xingxuan Zhang, Bo Li, Peng Cui* | **Category: cs.GT, cs.LG** | **Updated: 2025-07-15**

**Keywords:** PPA-Game, 竞争动态, 在线内容创作者, 博弈论, 在线学习

**Comment:** KDD 2026

> **TL;DR:** 本文提出了PPA-Game模型，用于表征和分析在线内容创作者在有限资源（如用户注意力）竞争中的动态，并提出了一种基于多臂老虎机框架的在线学习算法以最大化累积收益。

**AI_Comments:** 本文创新性地提出了PPA-Game模型来刻画在线内容创作者之间的竞争，并将其与多臂老虎机问题相结合，提出了一个有效的在线学习算法。这种结合为理解和优化在线平台上的竞争动态提供了新的视角和工具，具有重要的理论和实践意义。其对PNE存在性的分析以及提出的低后悔率在线算法是其主要亮点。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在模拟和理解在线推荐系统（如YouTube和TikTok）中内容创作者之间竞争有限消费者注意力的动态，其中内容曝光度取决于其固有的和独特的质量。

**Method:** 本文提出了比例收益分配博弈（PPA-Game）来表征代理人竞争可分割资源的情况。首先对PPA-Game进行了博弈论分析，识别了确保纯纳什均衡（PNE）存在的普遍场景。其次，通过整合多玩家多臂老虎机框架，讨论了代理人关于资源收益的在线学习，并提出了一种在线算法以最大化累积收益。

**Result:** 博弈论分析表明PPA-Game不总是保证纯纳什均衡（PNE）的存在，但识别出普遍存在的确保其存在的场景，且PNE不存在的情况很少发生。理论上，提出的在线学习算法的任何代理人的后悔界限为$O(	ext{log}^{1 + 	ext{eta}} T)$。仿真实验和实证结果进一步验证了在线学习方法的有效性。

**Conclusion:** PPA-Game能够有效表征在线内容创作者的竞争动态。虽然纯纳什均衡不总是存在，但在普遍场景下可以保证。此外，提出的在线学习方法在理论和实践上都证明了其在最大化代理人累积收益方面的有效性。

> **ai_Abstract:** 本文提出了比例收益分配博弈（PPA-Game），用于建模和分析在线内容创作者在有限消费者注意力下的竞争动态。研究通过博弈论分析了PPA-Game中纯纳什均衡的存在性，并发现其在普遍场景下存在。进一步，论文结合多玩家多臂老虎机框架，设计了一种在线学习算法，理论证明了其较低的后悔界限，并通过实验验证了其在最大化累积收益方面的有效性。

> **摘要翻译:** 在本文中，我们提出了比例收益分配博弈（PPA-Game），它表征了代理人竞争可分割资源的情况。在PPA-Game中，代理人从可用资源中选择，其收益根据其异质权重按比例确定。这种动态模拟了YouTube和TikTok等在线推荐系统上的内容创作者，他们竞争有限的消费者注意力，内容曝光依赖于固有的和独特的质量。我们首先对PPA-Game进行了博弈论分析。虽然PPA-Game不总是保证纯纳什均衡（PNE）的存在，但我们识别了普遍存在的确保其存在的场景。模拟实验进一步证明，PNE不存在的情况很少发生。除了分析静态收益外，我们还通过整合多玩家多臂老虎机框架，进一步讨论了代理人关于资源收益的在线学习。我们提出了一种在线算法，以促进每个代理人在T轮中最大化累积收益。理论上，我们确定任何代理人的后悔界限为$O(	ext{log}^{1 + 	ext{eta}} T)$，其中$	ext{eta} > 0$。实证结果进一步验证了我们在线学习方法的有效性。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [89] [A Parallelizable Approach for Characterizing NE in Zero-Sum Games After a Linear Number of Iterations of Gradient Descent](https://arxiv.org/abs/2507.11366)
> *一种在梯度下降线性迭代次数后表征零和博弈中纳什均衡的可并行化方法*

*Taemin Kim, James P. Bailey* | **Category: cs.GT, cs.LG, 90C47, 91A05, 91A26, 68Q32** | **Updated: 2025-07-15**

**Keywords:** 零和博弈, 纳什均衡, 哈密顿动力学, 在线优化, 梯度下降

**Comment:** 

> **TL;DR:** 该论文提出了一种基于哈密顿动力学的新型可并行化方法，用于在零和博弈中表征纳什均衡，实现了线性收敛，并且在实验中显著优于传统方法。

**AI_Comments:** 该论文通过将哈密顿动力学引入零和博弈的在线优化，取得了显著进展。其主要创新点包括实现纳什均衡表征的线性收敛、支持并行化以及适用于任意学习率，这些都是算法博弈论和实际应用中的关键突破。经验验证进一步增强了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 零和博弈是机器学习、经济学等领域对抗性学习中的一个基本问题。传统方法通过基于遗憾或收缩映射的方法来近似纳什均衡（NE），但存在局限性。本研究旨在提出一种更高效、可并行化的方法来表征纳什均衡。

**Method:** 本文提出了一种基于物理中哈密顿动力学的新方法。该方法利用交替梯度下降，以有限（线性）次数的迭代来表征纳什均衡集。

**Result:** 所提出的方法可以在无界设置中，通过有限（线性）次数的交替梯度下降迭代来表征纳什均衡集（排除退化情况），这是在线优化中的首次突破。与标准方法不同，该方法可以并行化并适用于任意学习率，这在算法博弈论中也是首次。实验结果表明，该方法显著优于标准方法。

**Conclusion:** 该论文引入了一种基于哈密顿动力学的新颖可并行化方法，用于高效地表征零和博弈中的纳什均衡。与现有方法相比，该方法在收敛速度和灵活性方面都取得了理论上的进步，并展示了卓越的实验性能。

> **ai_Abstract:** 该论文介绍了一种新颖的、可并行化的零和博弈在线优化方法，利用哈密顿动力学。它证明了能够在线性次数的交替梯度下降迭代内表征纳什均衡，显著优于传统方法。该方法还独特地支持并行化和任意学习率，并显示出卓越的实验性能。

> **摘要翻译:** 我们研究零和博弈的在线优化方法，这是机器学习、经济学和许多其他领域对抗性学习中的一个基本问题。传统方法通过基于遗憾的方法（时间平均收敛）或基于收缩映射的方法（最后迭代收敛）来近似纳什均衡（NE）。我们提出了一种基于物理中哈密顿动力学的新方法，并证明它可以在无界设置中，通过有限（线性）次数的交替梯度下降迭代来表征纳什均衡集（排除退化情况），这是在线优化中的首次突破。与计算纳什均衡的标准方法不同，我们提出的方法可以并行化并适用于任意学习率，这在算法博弈论中也是首次。实验上，我们通过展示我们的方法显著优于标准方法来支持我们的结果。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [186] [Better Regret Rates in Bilateral Trade via Sublinear Budget Violation](https://arxiv.org/abs/2507.11419)
> *通过次线性预算违反实现双边贸易中更好的遗憾率*

*Anna Lunghi, Matteo Castiglioni, Alberto Marchesi* | **Category: cs.GT, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 双边贸易, 遗憾率, 预算违反, 无遗憾学习, 算法经济学

**Comment:** 

> **TL;DR:** 本文通过允许次线性预算违反来改进双边贸易中的遗憾率，并完整刻画了遗憾与预算违反之间的权衡。

**AI_Comments:** 本文的创新之处在于其对双边贸易中遗憾率与预算违反之间权衡的完整刻画。通过引入参数 $\beta$ 来量化预算违反程度，并设计相应的算法，作者成功地填补了现有研究中的空白，并证明了先前界限的紧密性，这对于理解和设计更实际的交易机制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在双边贸易中，当预算平衡必须在每个时间步强制执行时，无遗憾学习是不可能的。Bernasconi等人通过全局放松预算平衡约束来规避这一问题，但其遗憾率存在改进空间。本文旨在研究最优遗憾率如何随全局预算平衡约束的允许违反程度而变化，以弥补现有工作之间的差距。

**Method:** 作者设计了一种算法，该算法通过允许至多 $T^{\beta}$ 的预算违反（其中 $\beta \in [\frac{3}{4}, \frac{6}{7}]$），实现了 $\tilde O(T^{1 - \beta/3})$ 的遗憾率。同时，他们提供了匹配的下界。

**Result:** 该算法在允许 $T^{\beta}$ 的预算违反下，实现了 $\tilde O(T^{1 - \beta/3})$ 的遗憾率。研究结果还提供了一个匹配的下界，从而完整刻画了遗憾和预算违反之间的权衡。此外，它证明了Bernasconi等人先前的 $\tilde O(T^{3/4})$ 上界（全局预算平衡情况）和 $\Omega(T^{5/7})$ 下界（无约束预算平衡违反情况）是紧密的。

**Conclusion:** 本文完整刻画了双边贸易中遗憾率与预算违反之间的权衡关系，并证明了先前研究中一些重要界限的紧密性。

> **ai_Abstract:** 本文研究了双边贸易中无遗憾学习算法的遗憾率，尤其关注在放松预算平衡约束条件下的表现。针对现有研究中遗憾率上界与下界之间的差距，作者提出了一种新的算法。该算法允许次线性的预算违反（$T^{\beta}$），并实现了 $\tilde O(T^{1 - \beta/3})$ 的遗憾率，同时提供了匹配的下界。这项工作完整刻画了遗憾与预算违反之间的权衡关系，并证明了先前工作中一些重要界限的紧密性。

> **摘要翻译:** 双边贸易是算法经济学中的一个核心问题，最近的工作探索了如何使用无遗憾学习算法来设计交易机制。然而，当预算平衡必须在每个时间步强制执行时，无遗憾学习是不可能的。Bernasconi等人[Ber+24]展示了如何通过将预算平衡约束放宽至仅在所有时间步上全局保持来规避这种不可能性。具体来说，他们设计了一种算法，实现了 $\tilde O(T^{3/4})$ 阶的遗憾，并提供了 $\Omega(T^{5/7})$ 的下界。
在这项工作中，我们通过研究最优遗憾率如何随全局预算平衡约束的允许违反程度而变化，来在上述两个极端之间进行插值。具体来说，我们设计了一种算法，通过违反约束至多 $T^{\beta}$（对于任何给定的 $\beta \in [\frac{3}{4}, \frac{6}{7}]$），获得了 $\tilde O(T^{1 - \beta/3})$ 的遗憾。我们用一个匹配的下界补充了这一结果，从而完整刻画了遗憾和预算违反之间的权衡。我们的结果表明，Bernasconi等人[Ber+24]获得的全局预算平衡情况下的 $\tilde O(T^{3/4})$ 上界和无约束预算平衡违反情况下的 $\Omega(T^{5/7})$ 下界都是紧密的。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [310] [Protocols for Verifying Smooth Strategies in Bandits and Games](https://arxiv.org/abs/2507.10567)
> *老虎机和博弈中验证平滑策略的协议*

*Miranda Christ, Daniel Reichman, Jonathan Shafer* | **Category: cs.GT, cs.LG** | **Updated: 2025-07-08**

**Keywords:** 多臂老虎机, 范式博弈, 策略验证, 查询复杂度, 平滑策略

**Comment:** 

> **TL;DR:** 研究了在多臂老虎机和范式博弈中验证近似最优策略的协议，旨在减少查询次数。

**AI_Comments:** 这篇论文的创新点在于提出了在动作空间巨大时，对“平滑策略”进行高效验证的协议，显著降低了传统学习方法所需的查询成本。它不仅在理论上证明了这种次线性查询复杂度的可行性，还提供了具体的协议并建立了下限，具有重要的理论和实践意义。将老虎机验证技术推广到博弈论领域，也展示了其方法的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 当每个玩家可用的动作数量很大时，传统的策略验证方法需要大量查询，因此需要一种查询次数与动作数量呈次线性的高效验证协议。

**Method:** 提出了用于验证多臂老虎机中ε-最优平滑策略的协议，这些策略不会将过多概率集中在任何特定动作上。证明了这些协议所需的查询次数显著少于学习。此外，建立了查询复杂度的近似紧密下限。将老虎机验证技术应用于范式博弈，以验证近似强平滑纳什均衡。

**Result:** 证明了对于足够平滑的策略，可以实现查询次数与动作数量呈次线性的验证。提供的验证协议所需的臂查询次数比学习更少。建立了查询复杂度的近似紧密下限。成功将验证方法应用于范式博弈，实现了次线性查询复杂度的近似强平滑纳什均衡验证。

**Conclusion:** 本文提出了在多臂老虎机和范式博弈中高效（次线性查询复杂度）验证近似最优平滑策略的协议，这些协议在理论上和实践中都显示出显著的效率提升。

> **ai_Abstract:** 本文提出并研究了用于验证多臂老虎机和范式博弈中近似最优平滑策略的协议。针对动作数量庞大的场景，这些协议旨在实现次线性的查询复杂度。研究证明，对于足够平滑的策略，这种高效验证是可行的，并且其查询次数显著少于学习过程。此外，论文还建立了查询复杂度的紧密下限，并展示了将老虎机验证技术应用于范式博弈以验证近似强平滑纳什均衡的方法，从而在博弈论中也实现了次线性查询效率。

> **摘要翻译:** 我们研究了在多臂老虎机和范式博弈中验证策略近似最优性的协议。由于每个玩家可用的动作数量通常很大，我们寻求对效用预言机的查询次数与动作数量呈次线性的协议。我们证明，对于足够平滑且不会将过多概率集中在任何特定动作上的策略，这种验证是可能的。我们提供了用于验证多臂老虎机平滑策略是 ε-最优的协议。我们的验证协议所需的臂查询次数明显少于学习。此外，我们建立了在我们的设置中验证的查询复杂度的近似紧密下限。作为一项应用，我们展示了如何使用老虎机的验证来实现范式博弈中的验证。这提供了一个协议，用于验证给定的策略配置文件是否是近似强平滑纳什均衡，其查询复杂度与动作数量呈次线性。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [90] [Forecasting intermittent time series with Gaussian Processes and Tweedie likelihood](https://arxiv.org/abs/2502.19086)
> *使用高斯过程和Tweedie似然预测间歇性时间序列*

*Stefano Damato, Dario Azzimonti, Giorgio Corani* | **Category: stat.ML, cs.LG, stat.AP** | **Updated: 2025-07-14**

**Keywords:** 间歇性时间序列, 高斯过程, Tweedie分布, 概率预测, 贝叶斯框架

**Comment:** Under review

> **TL;DR:** 本文首次将完全参数化的Tweedie分布与高斯过程结合，用于间歇性时间序列的概率预测，并取得了优于现有模型的预测性能，尤其在处理高分位数方面表现出色。

**AI_Comments:** 本文的创新点在于首次将完全参数化的Tweedie分布与高斯过程相结合，用于间歇性时间序列预测，有效处理了数据的零点质量和重尾特性，避免了现有模型的简化假设。其重要性在于为间歇性数据预测提供了一种更准确和灵活的概率建模方法，尤其在需要精确估计极端值（高分位数）的场景下具有显著优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有模型在预测具有零点质量和重尾的间歇性时间序列时可能存在简化假设，需要更灵活和准确的概率预测方法。

**Method:** 采用高斯过程（GPs）作为潜在函数，在贝叶斯框架下训练模型以解释潜在函数的不确定性。将潜在GP变量与负二项式（NegBinGP）和Tweedie分布（TweedieGP）两种预测分布结合。特别指出，这是首次使用完全参数化的Tweedie密度来处理间歇性时间序列。

**Result:** 模型在数千个间歇性计数时间序列上进行了测试。结果表明，所提出的模型比竞争对手提供了始终更好的概率预测。特别是，TweedieGP获得了最高分位数的最佳估计，表明它比NegBinGP更灵活。

**Conclusion:** 结合高斯过程和Tweedie似然的TweedieGP模型能够为间歇性时间序列提供优越的概率预测，尤其在捕捉高分位数方面表现出更高的灵活性和准确性。

> **ai_Abstract:** 本文提出了一种基于高斯过程（GPs）的概率预测模型，用于处理间歇性时间序列。该模型在贝叶斯框架下训练，并结合了负二项式和Tweedie两种似然函数。研究首次将完全参数化的Tweedie密度应用于间歇性时间序列预测，有效处理了零点质量和重尾特性。实验结果表明，与现有模型相比，所提出的模型提供了更优异的概率预测性能，特别是TweedieGP在最高分位数估计方面表现出卓越的灵活性和准确性。

> **摘要翻译:** 我们采用高斯过程（GPs）作为潜在函数，用于间歇性时间序列的概率预测。该模型在贝叶斯框架下进行训练，考虑了潜在函数的不确定性。我们将潜在的GP变量与两种类型的预测分布结合：负二项式（NegBinGP）和Tweedie分布（TweedieGP）。虽然负二项式已用于预测间歇性时间序列，但这是首次将完全参数化的Tweedie密度用于间歇性时间序列。我们正确评估了Tweedie密度，它既有零点质量又有重尾，避免了现有模型中简化的假设。我们在数千个间歇性计数时间序列上测试了我们的模型。结果表明，我们的模型提供了始终优于竞争对手的概率预测。特别是，TweedieGP获得了最高分位数的最佳估计，从而表明它比NegBinGP更灵活。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [108] [Universal rates of ERM for agnostic learning](https://arxiv.org/abs/2506.14110)
> *ERM在不可知学习中的普适速率*

*Steve Hanneke, Mingyue Xu* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 普适学习, 经验风险最小化, 不可知学习, 学习速率, 二分类

**Comment:** Accepted for presentation at the Conference on Learning Theory (COLT)
  2025

> **TL;DR:** 本文研究了ERM在不可知二分类设置下的普适学习速率，揭示了三种可能的速率并提供了完整的表征。

**AI_Comments:** 本文的创新之处在于将普适学习速率的研究从限制性较强的可实现设置扩展到更符合实际的不可知设置。通过揭示ERM在不可知设置下的三种普适速率模式并提供完整的概念类表征，该研究填补了普适学习理论的重要空白，对理解学习算法在实际复杂分布下的性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 之前的研究主要集中在可实现设置下ERM的普适学习速率，但可实现性假设过于严格，在实践中难以成立。因此，本文旨在探索更实际的不可知设置下的普适学习速率，以填补普适学习理论在非可实现情况下的空白。

**Method:** 本文在不可知设置下考虑了ERM用于二分类的普适学习问题，探索了不可知普适速率的可能性，并揭示了一个紧凑的三分法。作者提供了哪些概念类属于这三类中的完整表征，并为依赖于目标和依赖于贝叶斯的普适速率建立了完整的表征。

**Result:** 结果显示ERM在不可知设置下有三种可能的普适速率：$e^{-n}$、$o(n^{-1/2})$，或者任意慢。论文提供了哪些概念类属于这些类别的完整表征，并且还建立了目标依赖和贝叶斯依赖的普适速率的完整表征。

**Conclusion:** 本文全面刻画了ERM在不可知二分类学习中的普适速率，揭示了三种可能的衰减模式，并为不同概念类别的归属提供了明确的分类，填补了不可知设置下普适学习研究的空白，对理解学习算法在实际复杂分布下的性能具有重要意义。

> **ai_Abstract:** 本文研究了经验风险最小化（ERM）在不可知设置下二分类问题的普适学习速率。针对现有研究主要关注可实现设置的局限性，作者探索了不可知普适速率的可能性，并发现ERM存在$e^{-n}$、$o(n^{-1/2})$或任意慢三种可能的普适速率。论文提供了哪些概念类属于这些类别的完整表征，并进一步刻画了目标依赖和贝叶斯依赖的普适速率。

> **摘要翻译:** 普适学习框架已经被开发出来，以获得适用于任何固定分布的学习速率保证，这些速率可能比在所有分布上统一成立的速率快得多。鉴于经验风险最小化（ERM）原则在PAC理论中是基础性的，并且在实际机器学习中无处不在，最近的工作arXiv:2412.02810研究了在可实现设置下二分类ERM的普适速率。然而，可实现性假设过于严格，在实践中难以成立。事实上，大多数关于普适学习的文献都集中在可实现情况，而不可实现情况（不可知情况）几乎没有被探索。在本文中，我们考虑在不可知设置下通过ERM进行二分类的普适学习问题，其中“学习曲线”反映了随着样本量增加超额风险的衰减。我们探索了不可知普适速率的可能性，并揭示了一个紧凑的三分法：ERM有三种可能的不可知普适速率，分别是$e^{-n}$、$o(n^{-1/2})$，或者任意慢。我们提供了哪些概念类属于这些类别的完整表征。此外，我们还建立了目标依赖的普适速率以及贝叶斯依赖的普适速率的完整表征。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [125] [From Observational Data to Clinical Recommendations: A Causal Framework for Estimating Patient-level Treatment Effects and Learning Policies](https://arxiv.org/abs/2507.11381)
> *从观察数据到临床建议：一个用于估计患者层面治疗效果和学习策略的因果框架*

*Rom Gutman, Shimon Sheiba, Omer Noy Klien, Naama Dekel Bird, Amit Gruber, Doron Aronson, Oren Caspi, Uri Shalit* | **Category: stat.ML, cs.LG, stat.AP** | **Updated: 2025-07-15**

**Keywords:** 因果框架, 治疗推荐, 观察数据, 患者层面, 因果识别

**Comment:** 

> **TL;DR:** 提出一个利用观察数据构建患者特定治疗推荐模型的因果框架，旨在提高治疗效果，并已在心力衰竭患者的急性肾损伤治疗中得到验证。

**AI_Comments:** 该研究的创新之处在于提出一个整合性的因果框架，而非单一模型，旨在将现有因果学习方法应用于实际临床推荐系统。其重要性在于解决了从观察数据生成可靠临床建议的关键挑战，特别是强调了因果识别问题。

<details>
  <summary>Details</summary>

**Motivation:** 现有文献侧重于学习患者层面的因果模型，但缺乏一个将现有方法和知识整合到实际管道中的框架，尤其是在使用观察数据时需要关注因果识别的安全性和有效性。目标是构建患者特异性治疗推荐模型。

**Method:** 提出一个因果框架，整合现有方法和知识，构建患者特异性治疗推荐模型。该框架受Hernan和Robins的目标试验范式启发，并关注使用观察数据时的因果识别问题。

**Result:** 结果表明该框架（管道）可以改善患者在当前治疗方案下的预后。

**Conclusion:** 该框架能够通过整合现有方法和关注因果识别，从观察数据中学习并提供改善患者预后的治疗建议。

> **ai_Abstract:** 这篇论文提出了一个基于观察数据的因果框架，用于构建患者特异性治疗推荐模型。该框架整合了现有方法和知识，强调了因果识别的安全性和有效性。通过一个针对心力衰竭患者急性肾损伤的真实案例，研究展示了该框架能够改善患者的治疗结果。

> **摘要翻译:** 我们提出了一个构建患者特定治疗推荐模型的框架，该框架建立在近期大量关于学习患者层面因果模型的文献基础上，并受到Hernan和Robins目标试验范式的启发。我们关注安全性和有效性，包括使用观察数据时因果识别的关键问题。我们不提供一个具体的模型，而是一种将现有方法和专业知识整合到实用管道中的方式。我们进一步提供了一个真实世界的用例，即优化住院期间发生急性肾损伤的心力衰竭患者的治疗。结果表明，我们的管道可以改善患者在当前治疗方案下的预后。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [156] [Joint space-time wind field data extrapolation and uncertainty quantification using nonparametric Bayesian dictionary learning](https://arxiv.org/abs/2507.11385)
> *基于非参数贝叶斯字典学习的风场时空数据外推与不确定性量化*

*George D. Pasparakis, Ioannis A. Kougioumtzoglou, Michael D. Shields* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 风场数据外推, 不确定性量化, 非参数贝叶斯字典学习, 压缩采样, 风工程

**Comment:** 

> **TL;DR:** 该方法基于非参数贝叶斯字典学习，实现了风场时空数据的外推和不确定性量化，即使在数据有限的情况下也能提高准确性。

**AI_Comments:** 本文提出了一种创新的风场数据外推和不确定性量化方法，其核心在于非参数贝叶斯字典学习的应用。相较于传统的压缩采样，该方法不仅能够有效处理有限数据，更重要的是引入了不确定性量化能力，并实现了扩展基的自适应选择，极大地提升了方法的鲁棒性和实用性。这对于实际风工程应用中传感器部署受限的场景具有重要意义，为高精度风场预测提供了新的工具。

<details>
  <summary>Details</summary>

**Motivation:** 在风工程应用中，由于各种限制，传感器数量有限，导致风场数据测量不完整或受限。现有方法（如标准压缩采样）可能无法量化不确定性或需要先验选择扩展基，因此需要一种新的方法来解决这些问题并提高外推精度。

**Method:** 该方法基于非参数贝叶斯字典学习。具体而言，利用稀疏/不完整的测量数据，构建了一个时间依赖的优化问题，以确定随机风场相关低维表示的扩展系数。与标准压缩采样相比，该方法能进行不确定性量化，并能自适应地选择扩展基，而非先验选择。

**Result:** 该方法相比标准压缩采样具有两大优势：首先，贝叶斯公式能够量化估计中的不确定性；其次，规避了标准CS应用中对扩展基进行先验选择的需求，而是根据获取的数据自适应地完成。总体而言，该方法即使在任意形式的高维数据和相对较大的外推距离情况下，也表现出增强的外推精度。通过两个案例研究（模拟风速记录外推和风洞实验数据外推）证明了其有效性。

**Conclusion:** 该方法可以潜在地应用于各种风工程应用中，特别是在传感器数量受限的情况下，能够有效地进行风场时空数据外推和不确定性量化。

> **ai_Abstract:** 本研究提出了一种基于非参数贝叶斯字典学习的方法，用于在测量数据有限或不完整的情况下，联合进行风场时空数据外推和不确定性量化。该方法通过构建时间依赖的优化问题来确定随机风场的低维表示，并具有量化不确定性和自适应选择扩展基的优势，从而规避了标准压缩采样方法的局限性。实验结果表明，该方法即使在处理高维数据和较大外推距离时，也能显著提高外推精度，有望应用于传感器受限的各类风工程场景。

> **摘要翻译:** 本研究基于非参数贝叶斯字典学习，开发了一种方法，用于联合时空风场数据外推和相关统计量的估计，其依赖于有限/不完整的测量数据。具体而言，利用稀疏/不完整的测量数据，公式化了一个时间依赖的优化问题，以确定随机风场相关低维表示的扩展系数。与替代性的、标准的压缩采样处理方法相比，所开发的方法展现出以下优势。首先，贝叶斯公式能够量化估计中的不确定性。其次，规避了标准基于CS的应用中对扩展基进行先验选择的需求。相反，本文中是根据获取的数据以自适应方式完成的。总体而言，该方法即使在任意形式的高维数据和相对较大的外推距离情况下，也表现出增强的外推精度。因此，它可以在广泛的风工程应用中潜在地使用，在这些应用中，各种限制决定了只能使用有限数量的传感器。通过考虑两个案例研究证明了该方法的有效性。第一个案例涉及在三维域（二维和时间）中，与预设的联合波数-频率功率谱密度一致的模拟风速记录的外推。第二个案例涉及四维（三维和时间）边界层风洞实验数据的外推，这些数据表现出显著的空间变异性和非高斯特性。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [180] [Canonical Bayesian Linear System Identification](https://arxiv.org/abs/2507.11535)
> *规范贝叶斯线性系统辨识*

*Andrey Bryutkin, Matthew E. Levine, Iñigo Urteaga, Youssef Marzouk* | **Category: stat.ML, cs.LG, cs.SY, eess.SY, stat.CO** | **Updated: 2025-07-15**

**Keywords:** 贝叶斯系统辨识, 线性时不变系统, 参数可辨识性, 规范形式, MCMC

**Comment:** 46 pages, 9 figures

> **TL;DR:** 通过将线性时不变系统嵌入贝叶斯框架的规范形式中，解决了标准贝叶斯线性系统辨识中参数不可辨识性问题，从而提高了计算效率，并提供了可解释和稳健的后验估计。

**AI_Comments:** 该论文的创新之处在于将LTI系统的规范形式引入贝叶斯框架，巧妙地解决了传统贝叶斯系统辨识中长期存在的参数不可辨识性问题，从而使后验推断变得可行且高效。其重要性体现在不仅提高了计算效率和后验的可解释性，还使得施加有意义的结构化先验成为可能，并确保了理论上的伯恩斯坦-冯·米塞斯定理条件，连接了贝叶斯与频率论方法。抽象中未提及明显局限性。

<details>
  <summary>Details</summary>

**Motivation:** 标准贝叶斯线性时不变（LTI）系统辨识方法受到参数不可辨识性的阻碍，导致复杂、多峰的后验分布，使得推断效率低下且不切实际。

**Method:** 通过将LTI系统的规范形式嵌入贝叶斯框架中来解决问题。这种方法利用最小参数化，并能完全捕获所有不变系统动力学，同时解决可辨识性问题。它还支持使用有意义的、结构感知的先验（例如，通过特征值强制稳定性），并确保伯恩斯坦-冯·米塞斯定理的条件。

**Result:** 与标准参数化相比，规范形式在广泛的模拟中表现出更高的计算效率，生成可解释且表现良好的后验分布，并提供稳健的不确定性估计，尤其是在数据有限的情况下。

**Conclusion:** 将LTI系统的规范形式嵌入贝叶斯框架中，能够有效解决标准贝叶斯系统辨识中的参数不可辨识性问题，显著提高了计算效率、后验可解释性和不确定性估计的鲁棒性。

> **ai_Abstract:** 本研究提出了一种规范贝叶斯方法用于线性时不变（LTI）系统辨识，以解决标准方法中存在的参数不可辨识性问题。通过将LTI系统的规范形式嵌入贝叶斯框架并采用最小参数化，该方法能够捕获完整的系统动力学、解决可辨识性，并支持结构感知的先验。模拟结果表明，与标准参数化相比，该方法在计算效率、后验可解释性和不确定性估计的鲁棒性方面具有显著优势，尤其适用于数据有限的情况。

> **摘要翻译:** 标准贝叶斯线性时不变（LTI）系统辨识方法受到参数不可辨识性的阻碍；由此产生的复杂、多峰后验分布使得推断效率低下且不切实际。我们通过将LTI系统的规范形式嵌入贝叶斯框架中来解决这个问题。我们严格地证实，在这些最小参数化中的推断完全捕获了所有不变系统动力学（例如，传递函数、特征值、系统输出的预测分布），同时解决了可辨识性问题。这种方法解锁了有意义的、结构感知的先验（例如，通过特征值强制稳定性）的使用，并确保了伯恩斯坦-冯·米塞斯定理的条件——这是贝叶斯和频率论大样本渐近性之间的一个联系，在标准形式中被打破。使用现代MCMC方法的广泛模拟突出了其相对于标准参数化的优势：规范形式实现了更高的计算效率，生成可解释且表现良好的后验分布，并提供稳健的不确定性估计，特别是从有限数据中。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [211] [State-Constrained Offline Reinforcement Learning](https://arxiv.org/abs/2405.14374)
> *状态约束离线强化学习*

*Charles A. Hepburn, Yue Jin, Giovanni Montana* | **Category: stat.ML, cs.AI, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 离线强化学习, 状态约束, 分布偏移, StaCQ, 深度学习

**Comment:** 

> **TL;DR:** 本文提出状态约束离线强化学习框架，允许策略采取高质量的分布外动作以达到分布内状态，从而显著增强学习潜力并提高轨迹结合效率。

**AI_Comments:** 这篇论文通过引入“状态约束”的概念，创新性地解决了传统离线RL中策略被限制在已见动作的问题。它允许策略探索分布外动作，只要这些动作能引导到分布内状态，这显著扩展了离线RL的能力。理论基础和SOTA算法StaCQ的提出，使得该工作具有很强的实践和理论意义，为未来的研究提供了新的方向和强大的基线。

<details>
  <summary>Details</summary>

**Motivation:** 传统离线强化学习方法主要在批处理受限设置中运行，将算法限制在数据集中特定的状态-动作分布，这虽然减少了分布偏移的影响，但限制了策略只能采取已见动作，从而限制了学习潜力。

**Method:** 本文引入了“状态约束离线强化学习”这一新颖框架，该框架专注于数据集的状态分布，允许策略采取高质量的分布外（out-of-distribution）动作，但这些动作必须导致分布内（in-distribution）状态。此外，论文还提出了名为StaCQ的深度学习算法，用于实现这一框架。

**Result:** 所提出的StaCQ算法在D4RL基准数据集上实现了最先进（state-of-the-art）的性能，并且其表现与论文的理论主张相符。

**Conclusion:** 状态约束离线强化学习框架不仅拓宽了学习视野，提高了有效结合数据集中不同轨迹的能力，而且为该领域的后续进展奠定了理论基础。StaCQ算法的提出为该领域未来的探索建立了强大的基线。

> **ai_Abstract:** 本文提出了一种新颖的“状态约束离线强化学习”框架，旨在克服传统离线RL在状态-动作分布上的限制。该框架允许学习策略采取分布外动作以达到分布内状态，从而显著提升学习能力和轨迹结合效率。研究提供了理论支撑，并引入了深度学习算法StaCQ，该算法在D4RL基准上表现卓越，为离线RL领域的新探索奠定了基础。

> **摘要翻译:** 传统离线强化学习（RL）方法主要在批处理受限设置中运行。这使得算法局限于数据集中存在的特定状态-动作分布，减少了分布偏移的影响，但限制了策略只能采取已见动作。在本文中，我们通过引入状态约束离线RL来缓解这一限制，这是一个新颖的框架，它仅关注数据集的状态分布。这种方法允许策略采取高质量的分布外动作，这些动作会导致分布内状态，从而显著增强学习潜力。所提出的设置不仅拓宽了学习视野，还提高了有效结合数据集中不同轨迹的能力，这是离线RL固有的理想特性。我们的研究以理论发现为基础，为该领域的后续进展铺平了道路。此外，我们引入了StaCQ，这是一种深度学习算法，在D4RL基准数据集上实现了最先进的性能，并与我们的理论主张相符。StaCQ为该领域未来的探索建立了强大的基线。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [414] [Robust Multi-Manifold Clustering via Simplex Paths](https://arxiv.org/abs/2507.10710)
> *通过单纯形路径的鲁棒多流形聚类*

*Haoyu Chen, Anna Little, Akin Narayan* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 多流形聚类, 单纯形路径, 几何方法, 最大角度路径距离, 鲁棒性, 可扩展性

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的、基于单纯形路径和最大角度路径距离（LAPD）的几何方法，用于鲁棒的多流形聚类，该方法表现出优越的性能和可扩展性。

**AI_Comments:** 本文的创新之处在于提出了一种基于单纯形路径和LAPD度量的新颖几何方法，用于解决多流形聚类问题。该方法在处理噪声、曲率和小相交角等挑战性条件下的鲁棒性以及其实现的高可扩展性是其重要贡献。其理论证明和实证性能使其成为该领域的一项重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决多流形聚类（MMC）问题，即如何将一组可能相交的d维流形聚类成独立的流形分量。

**Method:** 该方法首先在d-单纯形上计算一个局部性图，使用相邻单纯形之间的二面角作为图权重，然后计算该单纯形图中的无穷路径距离，从而得到最大角度路径距离（LAPD）度量。结合适当的去噪程序，该度量能够以高概率分离流形分量。此外，该算法通过利用无穷路径距离的近似方案，实现了准线性计算复杂度的可扩展实现。

**Result:** 分析表明，在适当的去噪程序下，LAPD度量能够以高概率分离流形分量。广泛的数值实验表明，该方法对噪声、曲率和小相交角具有鲁棒性，并且通常优于其他MMC算法。此外，所提出的算法具有高度可扩展性，实现了准线性的计算复杂度。

**Conclusion:** 本文提出了一种新颖、鲁棒且可扩展的几何多流形聚类方法，该方法能有效分离流形分量，即使在具有挑战性的条件下也能表现出色，并优于现有方法。

> **ai_Abstract:** 本文提出了一种新颖的几何多流形聚类（MMC）方法，称为最大角度路径距离（LAPD）。该方法通过在d-单纯形上构建局部性图，并利用二面角作为权重计算无穷路径距离来定义LAPD度量。理论分析和实验结果表明，LAPD结合去噪程序能够以高概率分离流形分量，并且对噪声、曲率和小相交角具有鲁棒性，性能优于现有MMC算法。此外，该算法通过近似方案实现了准线性的计算复杂度，具有高度可扩展性。

> **摘要翻译:** 本文介绍了一种新颖的、用于多流形聚类（MMC）的几何方法，即用于将一组可能相交的d维流形聚类成单个流形分量。我们首先在d-单纯形上计算一个局部性图，使用相邻单纯形之间的二面角作为图权重，然后计算该单纯形图中的无穷路径距离。该过程给出了单纯形上的一个度量，我们称之为最大角度路径距离（LAPD）。我们分析了LAPD在随机采样下的性质，并证明在适当的去噪程序下，该度量能够以高概率分离流形分量。我们通过对合成和真实世界数据集进行广泛的数值实验来验证所提出的方法。这些实验表明，该方法对噪声、曲率和小相交角具有鲁棒性，并且通常优于其他MMC算法。此外，我们提供了所提出算法的高度可扩展实现，该实现利用无穷路径距离的近似方案来达到准线性的计算复杂度。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [665] [GOLFS: Feature Selection via Combining Both Global and Local Information for High Dimensional Clustering](https://arxiv.org/abs/2507.10956)
> *GOLFS：结合全局和局部信息的高维聚类特征选择*

*Zhaoyu Xing, Yang Wan, Juan Wen, Wei Zhong* | **Category: stat.ML, cs.LG, 62-08, G.3** | **Updated: 2025-07-15**

**Keywords:** 高维聚类, 特征选择, 无监督学习, 全局信息, 局部信息

**Comment:** 

> **TL;DR:** GOLFS是一种新的无监督特征选择方法，通过结合全局和局部信息，同时解决高维聚类中的伪标签学习和判别性特征选择问题。

**AI_Comments:** GOLFS的创新点在于其结合了全局和局部信息进行无监督特征选择，这对于缺乏标签的高维聚类问题是一个重要的进展。通过同时处理伪标签学习和特征选择，并证明算法收敛性，增强了方法的理论基础和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 高维聚类中识别判别性特征至关重要，但由于缺乏聚类标签，监督式特征选择方法无法直接应用。因此，需要一种能够同时学习伪标签并选择判别性特征的方法。

**Method:** 本文提出了GOLFS算法，该算法通过结合流形学习的局部几何结构和正则化自表示的样本全局相关结构来选择判别性特征。为解决优化问题，提出了一种迭代算法，并证明了其收敛性。

**Result:** 仿真和两个真实数据应用表明，GOLFS在特征选择和聚类方面均表现出优秀的有限样本性能。

**Conclusion:** GOLFS通过结合全局和局部信息，有效解决了高维聚类中的特征选择难题，显著提高了特征选择和聚类的准确性。

> **ai_Abstract:** 本文提出了一种名为GOLFS的无监督特征选择方法，用于高维聚类。该方法旨在通过结合流形学习的局部几何结构和正则化自表示的全局相关结构，同时学习伪标签并选择判别性特征。GOLFS通过利用更全面的信息，有效提高了特征选择和聚类的准确性。文中还提出了一个可证明收敛的迭代算法来解决优化问题，并通过仿真和真实数据应用验证了其在特征选择和聚类上的优越性能。

> **摘要翻译:** 对于高维聚类来说，识别判别性特征非常重要。然而，由于缺乏聚类标签，为监督式特征选择开发的正则化方法无法直接应用。为了同时学习伪标签和选择判别性特征，我们提出了一种新的无监督特征选择方法，命名为全局和局部信息结合的特征选择（GOLFS），用于解决高维聚类问题。GOLFS算法通过结合流形学习的局部几何结构和正则化自表示的样本全局相关结构来选择判别性特征。这种结合通过利用更全面的信息，提高了特征选择和聚类的准确性。此外，还提出了一种迭代算法来解决优化问题，并证明了其收敛性。仿真和两个真实数据应用表明，GOLFS在特征选择和聚类方面都表现出优秀的有限样本性能。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [746] [TaylorPODA: A Taylor Expansion-Based Method to Improve Post-Hoc Attributions for Opaque Models](https://arxiv.org/abs/2507.10643)
> *TaylorPODA：一种基于泰勒展开式改进不透明模型事后归因的方法*

*Yuchi Tang, Iñaki Esnaola, Suzanne Mason, George Panoutsos* | **Category: stat.ML, cs.AI, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 事后归因, 泰勒展开, 不透明模型, 可解释AI, 特征贡献

**Comment:** 17 pages, 6 figures, Submitted to NeurIPS 2025

> **TL;DR:** TaylorPODA是一种基于泰勒展开式的新方法，通过引入精确性、联邦性、零差异和适应性等公设，改进了不透明模型的事后归因解释，并提供了更具理论基础和可视化友好的解释。

**AI_Comments:** 本文的创新点在于将泰勒展开框架应用于事后归因，并提出了一套新的公设来规范归因过程，特别是引入的“适应性”属性，使其在缺乏真实解释的场景下更具实用性。其重要性在于为不透明模型提供了更具理论基础和可信赖的解释，有助于推动AI模型的实际应用和信任度。

<details>
  <summary>Details</summary>

**Motivation:** 现有事后模型无关方法在量化个体特征贡献时，缺乏明确和系统的框架。

**Method:** 本文在邓等人（2024）引入的泰勒展开框架基础上，提出了“精确性”、“联邦性”和“零差异”一套严格的公设来管理泰勒项特定归因。在此基础上，引入了TaylorPODA（泰勒展开式派生的重要性顺序适应归因），它包含一个额外的“适应性”属性，以实现与任务特定目标的对齐。

**Result:** 经验评估表明，TaylorPODA在与基线方法的比较中取得了有竞争力的结果，并提供了有原则且可视化友好的解释。

**Conclusion:** 这项工作通过提供具有更强理论基础的解释，代表着向不透明模型可信部署迈出了一步。

> **ai_Abstract:** 本文提出了一种名为TaylorPODA的新型事后归因方法，旨在改进不透明模型的解释性。该方法基于泰勒展开框架，并引入了“精确性”、“联邦性”、“零差异”以及独特的“适应性”公设，以系统地量化特征贡献并与任务目标对齐。经验评估证明TaylorPODA优于现有基线方法，提供了理论上更严谨且易于理解的解释，有助于提高不透明模型的可信部署。

> **摘要翻译:** 现有事后模型无关方法主要通过将模型输出局部归因于其输入特征，为不透明模型生成外部解释。然而，它们往往缺乏一个明确和系统的框架来量化个体特征的贡献。本文在邓等人（2024）引入的泰勒展开框架基础上，该框架旨在统一现有局部归因方法，我们提出了一套严格的公设——“精确性”、“联邦性”和“零差异”——来管理泰勒项特定归因。在这些公设的指导下，我们引入了TaylorPODA（泰勒展开式派生的重要性顺序适应归因），它包含一个额外的“适应性”属性。该属性使得其能够与任务特定目标对齐，尤其是在缺乏真实解释的事后设置中。经验评估表明，TaylorPODA在与基线方法的比较中取得了有竞争力的结果，并提供了有原则且可视化友好的解释。这项工作通过提供具有更强理论基础的解释，代表着向不透明模型可信部署迈出了一步。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [747] [Interpretable Bayesian Tensor Network Kernel Machines with Automatic Rank and Feature Selection](https://arxiv.org/abs/2507.11136)
> *可解释的贝叶斯张量网络核机器，具有自动秩和特征选择*

*Afra Kilic, Kim Batselier* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 贝叶斯张量网络, 核机器, 自动秩选择, 特征选择, 不确定性量化

**Comment:** 39 pages, 5 figures, 4 tables. Submitted to Journal of Machine
  Learning Research. The code is available at:
  https://github.com/afrakilic/BTN-Kernel-Machines. arXiv admin note: text
  overlap with arXiv:1401.6497 by other authors

> **TL;DR:** 提出了一种贝叶斯张量网络核机器，能够自动推断模型复杂度、选择特征并量化不确定性，且计算成本不增加。

**AI_Comments:** 这篇论文的创新点在于将贝叶斯方法引入张量网络核机器，解决了传统方法在不确定性量化和超参数自动选择方面的不足。通过巧妙地利用稀疏诱导先验和均值场变分推断，实现了模型复杂度的自动推断和特征选择，同时保持了计算效率，这是一个重要的进步。其在可解释性上的提升也很有价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的张量网络核机器是确定性的，忽略参数不确定性，且需要手动调优模型复杂度超参数（如张量秩和特征维度），通常通过试错法或计算成本高昂的方法进行。

**Method:** 提出贝叶斯张量网络核机器，这是一个完全概率框架。它通过在张量网络因子上使用稀疏诱导分层先验来自动推断模型复杂度（张量秩和特征维度），并识别最相关的预测特征。所有模型参数和超参数都被视为具有相应先验的潜在变量。采用均值场变分推断来近似后验分布。将均值场近似应用于张量网络因子，得到一种贝叶斯ALS算法，其计算复杂度与确定性版本相同。

**Result:** 在合成和真实世界数据集上的实验表明，该模型在预测精度、不确定性量化、可解释性和可扩展性方面表现优越。

**Conclusion:** 该研究成功开发了一种贝叶斯张量网络核机器，解决了现有方法的局限性，实现了模型复杂度的自动推断、特征选择和不确定性量化，且没有额外计算成本，显著提升了模型性能和可解释性。

> **ai_Abstract:** 本文提出了一种贝叶斯张量网络核机器，以解决现有张量网络核方法在处理参数不确定性和手动调优模型复杂度方面的局限性。该框架采用稀疏诱导分层先验自动推断张量秩和特征维度，并识别重要特征，从而提高模型可解释性。通过均值场变分推断，实现了与确定性方法相同计算成本下的不确定性量化。实验证明，该模型在预测准确性、不确定性量化、可解释性和可扩展性方面均表现出色。

> **摘要翻译:** 张量网络（TN）核机器通过将参数表示为低秩TN来加速模型学习，从而减少计算和内存使用。然而，大多数基于TN的核方法是确定性的，忽略了参数不确定性。此外，它们需要手动调整模型复杂性超参数，如张量秩和特征维度，通常通过试错法或计算成本高昂的方法（如交叉验证）进行。我们提出了贝叶斯张量网络核机器，这是一个完全概率框架，它在TN因子上使用稀疏诱导分层先验来自动推断模型复杂性。这使得张量秩和特征维度能够自动推断，同时也能识别出与预测最相关的特征，从而增强了模型的可解释性。所有模型参数和超参数都被视为具有相应先验的潜在变量。鉴于贝叶斯方法和潜在变量依赖性，我们应用均值场变分推断来近似它们的后验。我们表明，将均值场近似应用于TN因子会产生一种贝叶斯ALS算法，其计算复杂度与其确定性对应物相同，从而能够在不增加额外计算成本的情况下进行不确定性量化。在合成和真实世界数据集上的实验证明了我们模型在预测精度、不确定性量化、可解释性和可扩展性方面的卓越性能。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [791] [How does Labeling Error Impact Contrastive Learning? A Perspective from Data Dimensionality Reduction](https://arxiv.org/abs/2507.11161)
> *标签错误如何影响对比学习？一个来自数据降维的视角*

*Jun Chen, Hong Chen, Yonghua Yu, Yiming Ying* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 对比学习, 标签错误, 数据降维, 奇异值分解, 增强图

**Comment:** Accepted by ICML2025 as a poster

> **TL;DR:** 本文研究了标签错误对对比学习下游分类性能的影响，发现其负面作用，并提出通过数据降维（如SVD）来缓解，但SVD也可能导致连接性降低。最终建议使用适度的嵌入维度、数据膨胀、弱增强和SVD来优化性能。

**AI_Comments:** 这篇论文的创新点在于它首次系统地从数据降维的角度研究了对比学习中标签错误的影响，并揭示了SVD在缓解标签错误方面的双面性。它不仅指出了问题，还提供了具体的实践建议，例如关于嵌入维度和增强策略的选择，这对于优化对比学习模型的实际性能具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在自监督表示学习领域，对比学习取得了最先进的性能。以往的理论研究几乎都依赖于标签一致性假设，然而在实际中，由于常见数据增强策略的强度和随机性，这一假设可能不成立，即存在标签错误。本文旨在探讨标签错误对对比学习下游分类性能的理论影响。

**Method:** 本文首先理论分析了标签错误对下游分类风险的负面影响。为了缓解这些影响，研究者将数据降维方法（例如奇异值分解SVD）应用于原始数据以减少假阳性样本，并进行了理论和实证评估。

**Result:** 研究发现标签错误对下游分类风险有几个显著的负面影响。应用SVD可以缓解这些影响，但SVD也是一把双刃剑，它可能由于增强图连接性的降低而导致下游分类准确性下降。

**Conclusion:** 基于以上观察，研究建议在对比学习中应使用适度的嵌入维度（例如实验中的512、1024）、数据膨胀、弱增强以及SVD，以确保大的图连接性和小的标签错误，从而提高模型性能。

> **ai_Abstract:** 本文探讨了对比学习中标签错误对下游分类性能的理论影响。研究发现标签错误会显著损害分类风险，并提出通过奇异值分解（SVD）等数据降维方法来缓解假阳性样本。然而，SVD也被发现可能由于增强图连接性降低而导致性能下降。基于这些发现，论文建议采用适度的嵌入维度、数据膨胀、弱增强和SVD相结合的策略，以平衡图连接性与标签错误，从而提升模型性能。

> **摘要翻译:** 近年来，对比学习在自监督表示学习领域取得了最先进的性能。许多先前的工作试图提供对比学习成功的理论理解。几乎所有这些工作都依赖于一个默认假设，即标签一致性假设，而这在实践中可能不成立（失败的概率称为标签错误），这归因于常见的增强策略（如随机裁剪RRC）的强度和随机性。本文研究了标签错误对对比学习下游分类性能的理论影响。我们首先揭示了标签错误对下游分类风险的几个显著负面影响。为了缓解这些影响，将数据降维方法（例如奇异值分解SVD）应用于原始数据以减少假阳性样本，并建立了理论和实证评估。此外，还发现SVD是一把双刃剑，它可能由于增强图连接性的降低而导致下游分类准确性恶化。基于以上观察，我们给出了增强建议，即我们应该使用一些适度的嵌入维度（例如我们实验中的512、1024）、数据膨胀、弱增强和SVD，以确保大的图连接性和小的标签错误，从而提高模型性能。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='hep-lat'></a>
## hep-lat 

### [96] [Training neural control variates using correlated configurations](https://arxiv.org/abs/2505.07719)
> *使用相关构型训练神经控制变量*

*Hyunwoo Oh* | **Category: hep-lat, cs.LG, nucl-th** | **Updated: 2025-07-15**

**Keywords:** 神经控制变量, 蒙特卡洛, 方差缩减, 自相关样本, MCMC

**Comment:** 9 pages, 8 figures

> **TL;DR:** 通过利用MCMC中通常被丢弃的自相关样本，可以更有效地训练神经控制变量（NCV），从而提高性能，尤其是在资源有限的情况下。

**AI_Comments:** 本论文通过挑战传统上丢弃自相关MCMC样本的做法，提供了一种优化神经控制变量（NCVs）训练的创新方法。其创新之处在于证明了这些看似冗余的数据点实际上可以提高NCV的性能，尤其是在资源受限的环境中。这可能导致更高效、更准确的蒙特卡洛模拟，特别是在复杂的高维问题中。

<details>
  <summary>Details</summary>

**Motivation:** 神经控制变量（NCVs）是方差缩减的强大工具，但一个关键但常被忽视的方面是马尔可夫链蒙特卡洛（MCMC）生成的自相关样本的作用。尽管这些样本在误差估计中因统计冗余而被丢弃，但它们可能包含对NCV训练有益的底层概率分布结构信息。本研究旨在系统地探讨使用相关构型对NCV训练的影响。

**Method:** 本研究系统地考察了在训练神经控制变量时使用相关构型的效果。作者从概念上和数值上进行了论证，并提供了来自U(1)规范理论和标量场理论的经验结果。

**Result:** 在相关数据上进行训练可以提高控制变量的性能，尤其是在计算资源有限的情况下。经验结果表明，自相关样本能够增强NCV的构建。

**Conclusion:** 本研究的发现为高效利用MCMC数据训练神经网络提供了实用指导。

> **ai_Abstract:** 本论文探讨了马尔可夫链蒙特卡洛（MCMC）中自相关样本在训练神经控制变量（NCVs）时常被忽视的效用。尽管这些样本通常因误差估计的统计冗余而被丢弃，但研究从概念和数值上证明，它们能够提高NCV的性能，尤其是在计算资源有限的情况下。来自U(1)规范理论和标量场理论的经验证据展示了这些样本如何增强NCV的构建，为神经网络训练中高效利用MCMC数据提供了实用指导。

> **摘要翻译:** 神经控制变量 (NCV) 已成为蒙特卡洛 (MC) 模拟中方差缩减的强大工具，特别是在传统控制变量难以解析构建的高维问题中。通过训练神经网络学习与目标可观测值相关的辅助函数，NCV 可以显著降低估计器方差，同时保持无偏性。然而，NCV 训练中一个关键但常被忽视的方面是马尔可夫链蒙特卡洛 (MCMC) 生成的自相关样本的作用。虽然这些样本通常因其统计冗余而被丢弃用于误差估计，但它们可能包含有关底层概率分布结构的有用信息，这有利于训练过程。在这项工作中，我们系统地研究了在训练神经控制变量时使用相关构型的效果。我们从概念和数值上证明，在相关数据上进行训练可以提高控制变量的性能，尤其是在计算资源有限的情况下。我们的分析包括来自 U(1) 规范理论和标量场理论的经验结果，说明了自相关样本何时以及如何增强 NCV 的构建。这些发现为高效利用 MCMC 数据训练神经网络提供了实用指导。

</details>

[⬆️ 返回分类顶部](#hep-lat) | [⬆️ 返回总目录](#toc)

---

<a id='physicscomp-ph'></a>
## physics.comp-ph 

### [102] [BridgeNet: A Hybrid, Physics-Informed Machine Learning Framework for Solving High-Dimensional Fokker-Planck Equations](https://arxiv.org/abs/2506.04354)
> *BridgeNet：一种用于求解高维Fokker-Planck方程的混合物理信息机器学习框架*

*Elmira Mirzabeigi, Rezvan Salehi, Kourosh Parand* | **Category: physics.comp-ph, cs.LG, math-ph, math.AP, math.MP** | **Updated: 2025-07-15**

**Keywords:** Fokker-Planck方程, 物理信息神经网络, 卷积神经网络, 混合框架, 高维

**Comment:** 

> **TL;DR:** BridgeNet是一个结合了CNN和PINN的混合框架，能更有效地解决高维Fokker-Planck方程，表现优于传统PINN。

**AI_Comments:** BridgeNet的创新点在于其混合架构，将CNN的局部特征提取能力与PINN的物理约束强制能力相结合，有效克服了传统PINN在处理高维复杂问题时的局限性。这种方法不仅提高了求解Fokker-Planck方程的准确性和效率，还增强了模型在高维空间中的稳定性，对计算物理学和相关应用领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的物理信息神经网络（PINN）通常依赖全连接架构，难以捕捉复杂的空间层次结构和强制执行复杂的边界条件，导致求解非线性、高维Fokker-Planck方程时效率不高。

**Method:** BridgeNet是一个新颖的混合框架，它将卷积神经网络（CNN）与物理信息神经网络（PINN）相结合。它利用自适应CNN层进行有效的局部特征提取，并结合动态加权损失函数来严格强制物理约束。

**Result:** BridgeNet在各种测试案例中，与传统PINN方法相比，实现了显著更低的误差指标和更快的收敛速度，并且在高维设置中保持了强大的稳定性。

**Conclusion:** BridgeNet代表了计算物理学的一个重大进步，提供了一种可扩展且准确的求解方法，在金融数学到复杂系统动力学等领域具有广阔的应用前景。

> **ai_Abstract:** BridgeNet是一种创新的混合机器学习框架，结合了CNN和PINN，旨在高效解决传统PINN难以处理的非线性、高维Fokker-Planck方程。它通过自适应CNN层进行特征提取和动态加权损失函数强制物理约束。实验证明，BridgeNet在误差、收敛速度和高维稳定性方面均优于传统PINN，为计算物理学提供了一种可扩展且准确的新方法。

> **摘要翻译:** BridgeNet是一种新颖的混合框架，它将卷积神经网络与物理信息神经网络相结合，以有效求解非线性、高维Fokker-Planck方程（FPEs）。传统的PINN通常依赖于全连接架构，在捕捉复杂的空间层次结构和强制执行复杂的边界条件时常常遇到困难。相比之下，BridgeNet利用自适应CNN层进行有效的局部特征提取，并结合动态加权损失函数来严格强制物理约束。在各种测试案例中进行的大量数值实验表明，与传统的PINN方法相比，BridgeNet不仅实现了显著更低的误差指标和更快的收敛速度，而且在高维设置中保持了强大的稳定性。这项工作代表了计算物理学的一个重大进步，提供了一种可扩展且准确的求解方法，在从金融数学到复杂系统动力学等领域具有广阔的应用前景。

</details>

[⬆️ 返回分类顶部](#physicscomp-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicsmed-ph'></a>
## physics.med-ph 

### [120] [Robust Semi-Supervised CT Radiomics for Lung Cancer Prognosis: Cost-Effective Learning with Limited Labels and SHAP Interpretation](https://arxiv.org/abs/2507.08189)
> *鲁棒半监督CT影像组学用于肺癌预后：有限标签下的成本效益学习与SHAP解释*

*Mohammad R. Salmanpour, Amir Hossein Pouria, Sonia Falahati, Shahram Taeb, Somayeh Sadat Mehrnia, Mehdi Maghsudi, Ali Fathi Jouzdani, Mehrdad Oveisi, Ilker Hacihaliloglu, Arman Rahmim* | **Category: physics.med-ph, cs.LG, F.2.2; I.2.7** | **Updated: 2025-07-15**

**Keywords:** 半监督学习, CT影像组学, 肺癌预后, SHAP, 成本效益

**Comment:** 12 pages, 4 figures

> **TL;DR:** 本文提出一种鲁棒的半监督学习框架，利用CT影像组学进行肺癌预后，在有限标注数据下提升了性能和成本效益，并提供SHAP解释性。

**AI_Comments:** 本文通过将半监督学习有效地应用于医学影像，特别是CT影像组学进行肺癌预后，提供了重要的创新，解决了该领域常面临的标注数据有限的挑战。其优势在于证明了SSL的成本效益和鲁棒性，仅用10%的标注数据就实现了高准确率。SHAP可解释性的整合对于临床应用至关重要，解决了许多AI模型的“黑箱”问题。对特征和分类器进行广泛的基准测试也增加了方法的严谨性。这项工作为在资源受限的医疗环境中改进基于AI的预后提供了实用且有价值的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 监督学习（SL）模型需要大量标注数据集，这限制了其在真实世界中（标注稀缺的环境下）基于CT影像进行AI预后的应用。

**Method:** 分析了来自12个数据集的977名患者的CT扫描，通过PyRadiomics使用高斯-拉普拉斯和小波滤波器提取了1218个影像组学特征。应用了56种特征选择和提取算法，并对27种分类器进行了基准测试。采用了一种带有伪标签的半监督学习（SSL）框架，使用了478个未标注和499个已标注病例。在三种场景下测试了模型敏感性：改变SL中已标注数据量、增加SSL中未标注数据量、以及将两者从10%扩展到100%。使用SHAP分析解释预测结果。进行了交叉验证和两个队列的外部测试。

**Result:** SSL优于SL，将总生存期预测性能提高了高达17%。最佳SSL模型（随机森林加XGBoost分类器）在交叉验证中达到了0.90的准确率，在外部测试中达到了0.88。SHAP分析显示，SSL和SL都增强了特征的可区分性，特别是对于类别1（生存期大于4年）。SSL在仅有10%标注数据的情况下表现出色，与SL相比，在外部测试中结果更稳定，方差更低，突出了SSL的鲁棒性和成本效益。

**Conclusion:** 本文介绍了一种成本效益高、稳定且可解释的SSL框架，用于基于CT的肺癌生存期预测，通过整合SHAP可解释性并利用未标注数据，提高了性能、泛化能力和临床准备度。

> **ai_Abstract:** 本文提出了一种鲁棒且成本效益高的半监督学习（SSL）框架，利用CT影像组学进行肺癌预后。该框架解决了监督学习需要大量标注数据集的限制，通过伪标签利用未标注数据。通过对977名患者CT扫描的广泛分析以及各种特征选择/分类算法的测试，SSL框架与监督学习相比，即使在标注数据有限（10%）的情况下，也表现出卓越的性能（生存期预测提高高达17%）和稳定性。SHAP分析提供了可解释性，增强了特征的可区分性。这项工作为肺癌预后提供了一个临床就绪的解决方案。

> **摘要翻译:** 背景：CT影像对于肺癌管理至关重要，为基于AI的预后提供了详细的可视化。然而，监督学习（SL）模型需要大量的标注数据集，这限制了它们在标注稀缺环境下的实际应用。
方法：我们分析了来自12个数据集的977名患者的CT扫描，通过PyRadiomics使用高斯-拉普拉斯和小波滤波器提取了1218个影像组学特征。应用了56种特征选择和提取算法，并对27种分类器进行了基准测试。采用了一种带有伪标签的半监督学习（SSL）框架，使用了478个未标注和499个已标注病例。在三种场景下测试了模型敏感性：改变SL中已标注数据量、增加SSL中未标注数据量、以及将两者从10%扩展到100%。使用SHAP分析解释预测结果。进行了交叉验证和两个队列的外部测试。
结果：SSL优于SL，将总生存期预测性能提高了高达17%。最佳SSL模型（随机森林加XGBoost分类器）在交叉验证中达到了0.90的准确率，在外部测试中达到了0.88。SHAP分析显示，SSL和SL都增强了特征的可区分性，特别是对于类别1（生存期大于4年）。SSL在仅有10%标注数据的情况下表现出色，与SL相比，在外部测试中结果更稳定，方差更低，突出了SSL的鲁棒性和成本效益。
结论：本文介绍了一种成本效益高、稳定且可解释的SSL框架，用于基于CT的肺癌生存期预测，通过整合SHAP可解释性并利用未标注数据，提高了性能、泛化能力和临床准备度。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

### [720] [Quantitative multi-metabolite imaging of Parkinson's disease using AI boosted molecular MRI](https://arxiv.org/abs/2507.11329)
> *使用人工智能增强分子MRI对帕金森病进行定量多代谢物成像*

*Hagar Shmuely, Michal Rivlin, Or Perlman* | **Category: physics.med-ph, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 帕金森病, 分子MRI, 深度学习, 生物标志物, 定量成像

**Comment:** This project was funded by the European Union (ERC, BabyMagnet,
  project no. 101115639). Views and opinions expressed are, however, those of
  the authors only and do not necessarily reflect those of the European Union
  or the European Research Council. Neither the European Union nor the granting
  authority can be held responsible for them

> **TL;DR:** 本研究结合快速分子MRI采集和深度学习重建，实现了对帕金森病小鼠模型的多代谢物定量成像，并发现了一些潜在的帕金森病生物标志物。

**AI_Comments:** 这项研究的创新之处在于将快速分子MRI采集与深度学习重建相结合，实现了对帕金森病相关代谢物的定量成像，克服了传统方法的局限性。其重要性在于发现了潜在的帕金森病生物标志物，这可能为帕金森病的早期诊断和疾病监测提供非侵入性且高效的工具。

<details>
  <summary>Details</summary>

**Motivation:** 传统的帕金森病分子成像方法需要放射性同位素、扫描时间长或空间分辨率低。尽管基于饱和转移的MRI提供了生化见解，但图像对比度是半定量的且非特异性的。

**Method:** 研究结合了快速分子MRI采集范式与基于深度学习的重建技术，用于对急性MPTP（1-甲基-4-苯基-1,2,3,6-四氢吡啶）小鼠模型中的谷氨酸、可移动蛋白质、半固体和可移动大分子进行多代谢物定量。

**Result:** 定量参数图与组织学和MR波谱结果基本一致，并表明半固体磁化转移（MT）、酰胺和脂肪族中继核奥弗豪效应（rNOE）质子体积分数可能作为帕金森病的生物标志物。

**Conclusion:** 半固体磁化转移（MT）、酰胺和脂肪族中继核奥弗豪效应（rNOE）质子体积分数可能作为帕金森病的生物标志物。

> **ai_Abstract:** 本研究提出了一种结合快速分子MRI采集和深度学习重建的新方法，用于对帕金森病（PD）小鼠模型进行多代谢物定量成像。该方法克服了传统PD成像的局限性，实现了对谷氨酸、可移动蛋白质、半固体和可移动大分子的定量分析。结果显示，定量参数图与组织学和MR波谱高度一致，并且半固体磁化转移、酰胺和脂肪族中继核奥弗豪效应质子体积分数被确定为潜在的PD生物标志物，为帕金森病的早期诊断和治疗提供了新的工具。

> **摘要翻译:** 传统的帕金森病（PD）体内分子成像方法需要放射性同位素、冗长的扫描时间，或者只能提供低空间分辨率。近期饱和转移帕金森病磁共振成像（MRI）的进展提供了生化见解，尽管图像对比度是半定量的且非特异性的。本研究结合了快速分子MRI采集范式与基于深度学习的重建技术，用于对急性MPTP（1-甲基-4-苯基-1,2,3,6-四氢吡啶）小鼠模型中的谷氨酸、可移动蛋白质、半固体和可移动大分子进行多代谢物定量。定量参数图与组织学和MR波谱结果基本一致，并表明半固体磁化转移（MT）、酰胺和脂肪族中继核奥弗豪效应（rNOE）质子体积分数可能作为帕金森病的生物标志物。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='econgn'></a>
## econ.GN 

### [123] [Artificial Finance: How AI Thinks About Money](https://arxiv.org/abs/2507.10933)
> *人工智能金融：AI如何思考金钱*

*Orhan Erdem, Ragavi Pobbathi Ashok* | **Category: econ.GN, cs.AI, q-fin.EC** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 金融决策, 风险中性, 跨文化比较, 人工智能

**Comment:** 

> **TL;DR:** 本文通过比较大型语言模型（LLMs）与全球人类参与者在金融决策问题上的反应，揭示了LLMs的决策模式，包括风险中性、在权衡现在和未来时偶尔出现非规范性反应，以及其集体反应与坦桑尼亚参与者最相似。

**AI_Comments:** 这项研究通过量化比较LLMs与人类在金融决策上的差异，为理解LLMs的认知偏见和潜在应用局限性提供了新颖的视角。特别是发现LLMs的集体反应与特定国家（坦桑尼亚）的人类数据相似，这暗示了模型训练数据中可能存在的文化或地域偏向，具有重要的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 探索大型语言模型（LLMs）如何进行金融决策，并系统性地比较其与全球人类参与者的反应。

**Method:** 向七个领先的LLMs（包括GPT系列、Gemini 2.0 Flash和DeepSeek R1）提出一组常用的金融决策问题，然后将其输出与来自53个国家的人类响应数据集进行比较。

**Result:** 1. LLMs普遍表现出风险中性的决策模式，在彩票型问题中倾向于符合预期价值计算的选择。2. 在评估现在和未来之间的权衡时，LLMs偶尔会产生与规范推理不一致的反应。3. LLMs的聚合反应与坦桑尼亚参与者的反应最为相似。

**Conclusion:** 这些发现有助于理解LLMs如何模仿人类决策行为，并突出了其输出中可能包含的文化和训练影响。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在金融决策中的表现，通过让七个主流LLMs回答金融问题，并将其答案与来自53个国家的人类数据进行对比。研究发现LLMs通常表现出风险中性，在权衡当下与未来时有时不一致，并且其集体决策模式与坦桑尼亚的人类参与者最为接近。这些结果有助于理解LLMs的类人决策行为及其潜在的文化和训练偏见。

> **摘要翻译:** 在本文中，我们通过系统地比较大型语言模型（LLMs）与全球人类参与者在金融决策问题上的反应，来探索LLMs如何处理金融决策。我们向七个领先的LLMs（包括GPT系列的五个模型：GPT-4o、GPT-4.5、o1、o3-mini，以及Gemini 2.0 Flash和DeepSeek R1）提出了一组常用的金融决策问题。然后，我们将它们的输出与来自涵盖53个国家的数据集中的人类反应进行了比较。我们的分析揭示了三个主要结果。首先，LLMs普遍表现出风险中性的决策模式，在面临彩票型问题时倾向于选择符合预期价值计算的选项。其次，在评估现在和未来之间的权衡时，LLMs偶尔会产生与规范推理不一致的反应。第三，当我们检查跨国相似性时，我们发现LLMs的聚合反应与坦桑尼亚参与者的反应最为相似。这些发现有助于理解LLMs如何模仿类人决策行为，并突出了其输出中可能包含的文化和训练影响。

</details>

[⬆️ 返回分类顶部](#econgn) | [⬆️ 返回总目录](#toc)

---

<a id='q-finrm'></a>
## q-fin.RM 

### [126] [Entity-Specific Cyber Risk Assessment using InsurTech Empowered Risk Factors](https://arxiv.org/abs/2507.08193)
> *使用保险科技赋能风险因素的实体特定网络风险评估*

*Jiayi Guo, Zhiyu Quan, Linfeng Zhang* | **Category: q-fin.RM, cs.LG, stat.ML** | **Updated: 2025-07-14**

**Keywords:** 网络风险评估, 保险科技, 机器学习, 实体特定属性, 网络事件数据

**Comment:** 

> **TL;DR:** 本文提出一个利用保险科技赋能风险因素的框架，通过机器学习模型，结合实体特定属性，解决网络事件数据不足的问题，从而提高网络风险评估的准确性和鲁棒性。

**AI_Comments:** 该论文创新性地将InsurTech理念引入网络风险评估，通过融合实体特定属性和机器学习模型，有效解决了公共网络事件数据不足和缺乏个性化特征的问题。其提出的框架能够生成透明、实体特定的风险画像，对于网络保险业的定制化承保和企业的主动风险管理具有重要意义。该研究的贡献在于提供了一个实用的、数据驱动的解决方案，以应对日益复杂的网络安全威胁。

<details>
  <summary>Details</summary>

**Motivation:** 高质量的公共网络事件数据不足，限制了网络风险评估的实证研究和预测建模。现有公开数据集缺乏实体特定的组织特征。

**Method:** 提出一个新颖的InsurTech框架，用实体特定属性丰富网络事件数据。开发了多标签分类模型来预测网络事件类型（如隐私泄露、数据泄露等）和多输出回归模型来估计其年度频率。应用可解释的机器学习技术来识别和交叉验证由InsurTech开发的潜在风险因素。

**Result:** 与仅使用传统风险因素相比，InsurTech赋能的特征增强了预测发生率和频率估计的鲁棒性。

**Conclusion:** 该框架生成透明的、实体特定的网络风险画像，支持定制化承保和主动网络风险缓解，为保险公司和组织提供数据驱动的洞察力以支持决策和合规性规划。

> **ai_Abstract:** 本文针对公共网络事件数据质量和实体特定信息缺失的挑战，提出一种创新的InsurTech框架。该框架通过整合实体特定属性来丰富网络事件数据，并利用多标签分类和多输出回归机器学习模型预测网络事件类型及其频率。研究发现，InsurTech赋能的风险因素显著提升了预测的准确性和鲁棒性，从而能够生成透明、实体特定的网络风险画像，支持保险承保和风险缓解决策。

> **摘要翻译:** 缺乏高质量的公共网络事件数据限制了网络风险评估的实证研究和预测建模。由于公司不愿披露可能损害其声誉或投资者信心的事件，这一挑战持续存在。因此，从精算角度看，潜在的解决方案包括两个方面：增强现有网络事件数据集和实施先进建模技术以优化可用数据的使用。对现有数据驱动方法的审查突出表明，公开数据集中严重缺乏实体特定的组织特征。为了解决这一差距，我们提出了一种新颖的保险科技（InsurTech）框架，该框架通过实体特定属性丰富了网络事件数据。我们开发了各种机器学习（ML）模型：一个多标签分类模型用于预测网络事件类型（例如，隐私侵犯、数据泄露、欺诈和勒索、IT错误及其他），以及一个多输出回归模型用于估计其年度频率。虽然也实施了分类器和回归器链来探索网络事件类型之间的依赖关系，但在我们的数据集中未观察到显著相关性。此外，我们应用了多种可解释的ML技术，以识别并跨ML模型交叉验证由InsurTech开发的潜在风险因素。我们发现，与仅使用传统风险因素相比，InsurTech赋能的特征增强了预测发生率和频率估计的鲁棒性。该框架生成透明的、实体特定的网络风险画像，支持定制化承保和主动网络风险缓解。它为保险公司和组织提供了数据驱动的洞察力，以支持决策制定和合规性规划。

</details>

[⬆️ 返回分类顶部](#q-finrm) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [138] [Distributionally Robust Optimization is a Multi-Objective Problem](https://arxiv.org/abs/2507.11350)
> *分布鲁棒优化是一个多目标问题*

*Jun-ya Gotoh, Michael Jong Kim, Andrew E. B. Lim* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-07-15**

**Keywords:** 分布鲁棒优化, 多目标问题, 最坏情况敏感度, 不确定性集, 帕累托最优前沿

**Comment:** 

> **TL;DR:** 分布鲁棒优化（DRO）虽然被表述为单目标问题，但本质上是多目标问题，它在预期成本和最坏情况敏感度之间描绘出一条近似帕累托最优前沿。

**AI_Comments:** 本文的创新之处在于将分布鲁棒优化（DRO）重新定义为本质上的多目标问题，而不是传统的单目标问题。通过引入最坏情况敏感度（WCS）并揭示其与预期成本之间的帕累托最优前沿关系，该研究为理解和应用DRO提供了全新的视角。它不仅提供了鲁棒性的定量衡量方法，还通过基于敏感度的方法，有效解决了DRO中长期存在的关于不确定性集族和大小选择的难题，这对于实际应用具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在模型不确定性下，分布鲁棒优化（DRO）被用作决策制定的一种最坏情况方法。尽管它被表述为单目标问题，但本文旨在揭示其内在的多目标性质，并通过多目标视角探索鲁棒决策，以解决DRO中如何选择不确定性集族和大小等概念性空白。

**Method:** 本文证明了DRO解在预期成本和最坏情况敏感度（WCS）之间描绘出一条近似帕累托最优前沿。研究推导了DRO中常用不确定性集的WCS，并利用相关的均值-敏感度前沿来选择不确定性集的大小。

**Result:** 研究表明，DRO解在预期成本和最坏情况敏感度（WCS）之间形成一个近似帕累托最优前沿。WCS是衡量离散度的一种度量。本文推导了常用不确定性集的WCS，这些敏感度度量能够识别标称预期成本最易受其影响的误差。相关的均值-敏感度前沿可用于选择不确定性集的大小。

**Conclusion:** 多目标视角为鲁棒性提供了一种定量度量，并提供了一种基于敏感度的方法来解决DRO中重要的概念性空白，例如如何为给定成本分布选择不确定性集的族和大小，以及这如何影响解决方案。

> **ai_Abstract:** 本文揭示了分布鲁棒优化（DRO）的内在多目标性质，尽管其常被视为单目标问题。研究表明，DRO解在预期成本和最坏情况敏感度（WCS）之间形成近似帕累托最优前沿。文章推导了常用不确定性集的WCS，并利用均值-敏感度前沿来指导不确定性集大小的选择。这种多目标视角为鲁棒性提供了定量度量，并有助于解决DRO中关于不确定性集选择及其对解决方案影响的关键问题。

> **摘要翻译:** 分布鲁棒优化（DRO）是模型不确定性下决策制定的最坏情况方法。尽管它被表述为单目标问题，但我们发现它本质上是多目标问题，因为DRO解决方案在预期成本和一种称为最坏情况敏感度（WCS）的鲁棒性度量之间描绘出一条近似帕累托最优前沿。我们以此为起点，通过多目标视角探索鲁棒决策。我们证明WCS是衡量离散度的一种度量，并推导了DRO中常用的一系列不确定性集的WCS。这些敏感度度量识别了标称预期成本最易受其影响的误差，以及最有效地缓解这些误差的最坏情况问题的不确定性集。相关的均值-敏感度前沿用于选择其大小。多目标视角提供了鲁棒性的定量度量，以及一种基于敏感度的方法来解决DRO中重要的概念性空白——如何为给定成本分布选择不确定性集的族和大小，以及这如何影响解决方案。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [190] [Recursive Bound-Constrained AdaGrad with Applications to Multilevel and Domain Decomposition Minimization](https://arxiv.org/abs/2507.11513)
> *递归有界约束AdaGrad及其在多级和域分解最小化中的应用*

*Serge Gratton, Alena Kopaničáková, Philippe Toint* | **Category: math.OC, cs.AI, cs.NA, math.NA, 49K20, 65M55, 65Y20, 68Q25, 68T05, 90C26, 90C30, F.2.1; G.1.8; I.2.5** | **Updated: 2025-07-15**

**Keywords:** AdaGrad, 有界约束优化, 多级方法, 域分解, 噪声容忍算法

**Comment:** 33 pages

> **TL;DR:** 提出了两种新的、能处理有界约束和不精确梯度的OFFO算法，是AdaGrad的泛化，理论证明它们以高概率在$O(\\epsilon^{-2})$迭代内达到$\\epsilon$-近似一阶临界点，并在PDE和深度学习应用中表现出高效率。

**AI_Comments:** 这篇论文的创新点在于提出了AdaGrad算法的泛化版本，使其能够处理更复杂的优化场景，如带有界约束和不精确梯度的问题。其统一的理论框架和对噪声容忍的特性，以及在多级和域分解方法中的应用，都显示了其广泛的适用性和实用价值。特别是在深度学习等领域，不精确梯度是常见现象，该算法的效率和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决带有有界约束、不精确梯度和可能利用二阶信息的优化问题，并提供噪声容忍的算法。

**Method:** 提出了两种OFFO（目标函数无关优化）噪声容忍算法：一种是利用问题分层描述的多级方法，另一种是涵盖标准加性Schwarz分解的域分解方法。这两种算法都是无约束优化中一阶AdaGrad算法的泛化，并共享一个共同的理论框架。

**Result:** 主要结果是，在很高的概率下，这两种方法最多需要$O(\\epsilon^{-2})$次迭代和带噪声的梯度评估，即可计算出有界约束问题的$\\epsilon$-近似一阶临界点。数值实验表明，这些算法在从PDE问题到深度神经网络训练的应用中都具有显著的计算效率。

**Conclusion:** 论文成功提出了两种基于AdaGrad的、噪声容忍的、处理有界约束和不精确梯度的优化算法，并提供了统一的收敛性/复杂度理论，证明了其高效性，适用于多种实际应用。

> **ai_Abstract:** 这篇论文介绍了两种新的OFFO噪声容忍算法，它们是现有AdaGrad算法的泛化，专门用于处理有界约束和不精确梯度，并能利用二阶信息。这两种算法分别是多级方法和域分解方法。论文提供了一个统一的理论框架，证明了这些方法能以高概率在$O(\\epsilon^{-2})$次迭代内找到近似一阶临界点。通过在PDE和深度学习等领域的广泛实验，验证了其卓越的计算效率。

> **摘要翻译:** 本文提出了两种OFFO（目标函数无关优化）噪声容忍算法，它们能够处理有界约束、不精确梯度并在可用时利用二阶信息。第一种是利用问题分层描述的多级方法，第二种是涵盖标准加性Schwarz分解的域分解方法。这两种算法都是无约束优化中一阶AdaGrad算法的泛化。由于这些算法共享一个共同的理论框架，因此提供了一个涵盖两者的统一收敛性/复杂度理论。其主要结果是，在很高的概率下，这两种方法最多需要$O(\\epsilon^{-2})$次迭代和带噪声的梯度评估，即可计算出有界约束问题的$\\epsilon$-近似一阶临界点。论文讨论了从基于偏微分方程的问题到深度神经网络训练等应用中的大量数值实验，展示了它们卓越的计算效率。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [315] [Deep Equilibrium models for Poisson Imaging Inverse problems via Mirror Descent](https://arxiv.org/abs/2507.11461)
> *泊松成像逆问题的深度平衡模型：基于镜像下降法*

*Christian Daniele, Silvia Villa, Samuel Vaiter, Luca Calatroni* | **Category: math.OC, cs.CV, 65K10, 65J22, 94A08, 47N10** | **Updated: 2025-07-15**

**Keywords:** 深度平衡模型, 泊松成像, 镜像下降, 逆问题, 神经正则化

**Comment:** 

> **TL;DR:** 本文将深度平衡模型（DEQs）扩展到泊松逆问题，通过引入基于镜像下降法的新DEQ公式，实现了在非欧几里得几何下的神经正则化学习，并展示了优于传统方法的性能。

**AI_Comments:** 这项工作创新性地将深度平衡模型（DEQs）扩展到非高斯噪声（泊松噪声）环境下的逆问题，通过引入基于镜像下降法和非欧几里得几何的DEQ公式，解决了传统DEQs在高斯保真度假设下的局限性。其优势在于提供理论收敛性保证，并实现了高效、鲁棒的图像重建，尤其是在减少了对超参数调优的依赖方面，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度平衡模型（DEQs）主要应用于高斯保真度设置下的图像正则化，但对于泊松逆问题（数据保真度更适合用Kullback-Leibler散度建模）缺乏相应的DEQ应用。

**Method:** 引入了一种基于镜像下降法（Mirror Descent）的新型DEQ公式，该公式在定制的非欧几里得几何中定义，以自然适应数据项的结构。推导了保证学习重建方案收敛的充分条件，并提出了高效训练和完全无参数推理的计算策略。

**Result:** 数值实验表明，该方法优于传统的基于模型的方法，并且与Bregman Plug-and-Play方法的性能相当，同时减轻了后者的典型缺点（对初始化敏感和超参数需要仔细调整）。

**Conclusion:** 通过引入基于镜像下降法的新DEQ公式，成功将深度平衡模型应用于泊松逆问题，实现了性能优越且鲁棒的神经正则化学习。

> **ai_Abstract:** 本文提出了一种将深度平衡模型（DEQs）应用于泊松成像逆问题的新方法。针对泊松数据保真度采用Kullback-Leibler散度建模的特点，作者引入了基于镜像下降法的新型DEQ公式，并在定制的非欧几里得几何中定义，以实现神经正则化器的学习。该方法提供了收敛性保证，并支持高效训练和无参数推理。实验结果表明，该方法在性能上超越了传统模型，并与Bregman Plug-and-Play方法相当，同时解决了其初始化敏感性和超参数调优的缺点。

> **摘要翻译:** 深度平衡模型（DEQs）是具有不动点的隐式神经网络，最近因学习图像正则化泛函而受到关注，特别是在涉及高斯保真度的设置中，其中前向算子的假设确保了标准（近端）梯度下降算子的收缩性。在这项工作中，我们将DEQs的应用扩展到泊松逆问题，其中数据保真度项更适合用Kullback-Leibler散度建模。为此，我们引入了一种基于镜像下降法（Mirror Descent）的新型DEQ公式，该公式在定制的非欧几里得几何中定义，自然地适应数据项的结构。这使得在原则性的训练框架内学习神经正则化器成为可能。我们推导了保证学习重建方案收敛的充分条件，并提出了能够实现高效训练和完全无参数推理的计算策略。数值实验表明，我们的方法优于传统的基于模型的方法，并且与Bregman Plug-and-Play方法的性能相当，同时减轻了它们的典型缺点——即对初始化敏感和超参数需要仔细调整。代码已公开发布在https://github.com/christiandaniele/DEQ-MD。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [371] [Gain and phase type multipliers for feedback robustness](https://arxiv.org/abs/2203.11837)
> *增益和相位型乘子用于反馈鲁棒性*

*Axel Ringh, Xin Mao, Wei Chen, Li Qiu, Sei Zhen Khong* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-07-14**

**Keywords:** 鲁棒稳定性, 乘子, 增益型不确定性, 相位型不确定性, 积分二次约束

**Comment:** Revision, 16 pages

> **TL;DR:** 本文建立了在反馈系统对特定结构不确定性具有鲁棒稳定性时，存在相应形式乘子的理论，特别指出了增益型不确定性对应相位型乘子，相位型不确定性对应增益型乘子。

**AI_Comments:** 这项工作在控制理论中具有重要意义，因为它建立了反馈系统鲁棒稳定性与特定类型乘子存在性之间的直接联系。这种对应关系为鲁棒性分析提供了一种新的视角，特别是在处理不同类型不确定性时，能够更有效地选择或设计乘子。其创新之处在于将不确定性类型与乘子的结构形式联系起来，从而简化了鲁棒性分析中的乘子搜索过程，并统一了小增益和小相位等经典结果。

<details>
  <summary>Details</summary>

**Motivation:** 旨在探究在反馈互连系统对特定结构不确定性具有鲁棒稳定性时，是否存在形式相应的乘子，以指导鲁棒闭环稳定性的分析。

**Method:** 本文通过理论推导，建立了在反馈系统对特定结构不确定性具有鲁棒稳定性时，相应形式乘子存在的定理。该方法基于矩阵和系统的相位概念，并涵盖了小增益和小相位定理。

**Result:** 如果反馈对特定结构不确定性具有鲁棒稳定性，则始终存在相应形式的乘子。如果反馈对增益型不确定性具有鲁棒稳定性，则存在一个相应的相位型乘子（对角块为零）。如果反馈对相位型不确定性具有鲁棒稳定性，则存在一个相应的增益型乘子（非对角块为零）。这些结果建立在矩阵和系统相位概念的基础上，并涵盖了小增益和小相位定理。

**Conclusion:** 这些结果对于寻找有效乘子以建立鲁棒闭环稳定性具有重要的指导意义。

> **ai_Abstract:** 本文探讨了反馈系统鲁棒稳定性与乘子形式之间的关系。研究表明，如果反馈对特定结构不确定性（如增益型或相位型不确定性）具有鲁棒稳定性，则必然存在形式相应的乘子（分别为相位型或增益型）。这些发现基于矩阵和系统的相位概念，并与现有的小增益和小相位定理相符，为寻找用于建立鲁棒闭环稳定性的有效乘子提供了指导。

> **摘要翻译:** 众所周知，两个线性时不变系统反馈互连的稳定性意味着开环系统的图是二次分离的。这种分离由一个称为乘子的对象定义。积分二次约束理论表明，在某些条件下，反之亦然。本文指出，如果反馈对某些结构不确定性具有鲁棒稳定性，那么总是存在一个相应形式的乘子。特别是，如果反馈对某些增益型不确定性具有鲁棒稳定性，那么存在一个相应的相位型乘子，即其对角块为零。这些结果建立在控制领域最近引入的矩阵和系统相位概念的基础上。类似地，如果反馈对某些相位型不确定性具有鲁棒稳定性，那么存在一个增益型乘子，即其非对角块为零。这些结果在寻找用于建立鲁棒闭环稳定性的有效乘子方面具有有益的指导意义，并涵盖了著名的小增益定理和最近的小相位定理。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [388] [A Tax-Efficient Model Predictive Control Policy for Retirement Funding](https://arxiv.org/abs/2507.10603)
> *退休金资助的税收高效模型预测控制策略*

*Kasper Johansson, Stephen Boyd* | **Category: math.OC, cs.CE** | **Updated: 2025-07-12**

**Keywords:** 模型预测控制, 退休金管理, 凸优化, 税收效率

**Comment:** 

> **TL;DR:** 论文提出了一种税收高效的模型预测控制（MPC）策略，用于管理退休金，通过年度更新计划和执行，以应对不确定性，确保退休人员终身获得恒定的税后通胀调整消费。

**AI_Comments:** 这篇论文将模型预测控制（MPC）应用于复杂的退休金管理问题，创新性地结合了税务效率和不确定性处理。通过将规划问题表述为凸优化，确保了方案的可解性和可靠性。MPC的迭代更新机制使其能够适应不断变化的市场和个人情况，具有很强的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决退休人员储蓄管理问题，以提供终身恒定的税后通胀调整消费，同时考虑不同税务处理的账户、取款、转账、最低提款要求、罗斯转换限制、额外收入、负债、税收和遗产。

**Method:** 提出两步退休金资助策略：首先，将简化规划问题建模为凸优化问题，在已知未来量（如剩余寿命、投资回报、通胀）和简化税收模型下，最大化遗产，同时提供恒定的通胀调整消费目标。其次，利用该规划方法形成年度行动策略，每年基于已知信息（账户价值、预期寿命、税率变化等）更新计划并执行第一年的行动，形成模型预测控制（MPC）的“更新-计划-行动”循环，以应对不确定性。

**Result:** 通过蒙特卡洛模拟证明了所提出的MPC退休策略的有效性。

**Conclusion:** 所提出的MPC退休金策略是有效的。

> **ai_Abstract:** 本文提出了一种两阶段的税收高效模型预测控制（MPC）退休金资助策略。该策略旨在为退休人员提供终身恒定的税后通胀调整消费，同时考虑各种财务因素和税收规则。第一阶段，将简化规划问题表述为凸优化问题，在已知未来量的前提下，最大化遗产并满足消费目标。第二阶段，利用此规划方法构建年度“更新-计划-行动”循环（MPC），使策略能够适应投资回报、通胀、预期寿命和税收法规的不确定性。该MPC退休策略的有效性通过蒙特卡洛模拟得到验证。

> **摘要翻译:** 退休金资助问题旨在解决如何管理退休人员的储蓄，以在其有生之年提供恒定的税后通胀调整消费。这包括从多个具有不同税务处理的账户中选择取款和转账，同时考虑基本规则，如所需最低提款额和罗斯转换限额、额外收入、负债、税收以及退休人员去世时的遗产。我们分两步制定退休金资助策略。第一步，我们考虑一个简化的规划问题，其中已知各种未来量，如退休人员的剩余寿命、未来投资回报和未来通胀。使用简化的税收模型，我们将此规划问题表述为凸优化问题，其中我们在提供恒定通胀调整消费目标的前提下最大化遗产。由于该问题是凸的，因此可以快速可靠地解决。我们利用这种规划方法形成退休金资助策略，根据当时已知的信息确定每年要采取的行动。每年，退休人员都会根据当前的账户价值和预期寿命，并选择性地更新信息（例如税率或规则的变化），为未来年份制定新的计划。然后，退休人员执行当前计划第一年的行动。这种“更新-计划-行动”循环每年重复进行，这是一种称为模型预测控制（MPC）的通用策略。MPC退休策略能够应对不确定的投资回报和通胀、退休人员预期寿命或外部收入和负债的变化以及税收规则和税率的变化。我们通过蒙特卡洛模拟证明了MPC退休策略的有效性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [506] [Performance Enhancement of the Recursive Least Squares Algorithms with Rank Two Updates](https://arxiv.org/abs/2507.11095)
> *具有二阶更新的递推最小二乘算法的性能增强*

*Alexander Stotsky* | **Category: math.OC, cs.IT, cs.NA, math.DS, math.HO, math.IT, math.NA** | **Updated: 2025-07-15**

**Keywords:** 递推最小二乘,二阶更新,性能增强,遗忘因子,电网事件估计

**Comment:** 7pages, 2 figures

> **TL;DR:** 本文介绍了新型二阶更新递推最小二乘算法（RLSR2），其通过引入新的遗忘机制和算法特性来增强性能，并在电网事件估计中进行了性能检验。

**AI_Comments:** 这项工作通过引入二阶更新和新的算法特性，旨在提升递推最小二乘算法的性能，这在处理如电网事件估计等实际问题中具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 旨在增强递推最小二乘算法的性能。

**Method:** 引入了包含指数和瞬时遗忘的新型二阶更新递推最小二乘算法（RLSR2），并将其与已知的一阶更新RLS算法系统地关联。此外，建立了与信息矩阵逆和参数向量收敛相关的新特性，这些特性可用于进一步的性能改进。

**Result:** 新算法的性能在存在显著谐波发射的情况下，应用于电网事件估计问题中进行了检验。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文引入了新型二阶更新递推最小二乘算法（RLSR2），该算法结合了指数和瞬时遗忘机制，并与传统的一阶更新RLS算法建立了联系。研究还发现了可用于进一步性能提升的新特性。这些新算法的性能在存在显著谐波发射的电网事件估计问题中进行了评估。

> **摘要翻译:** 本报告介绍了包含指数和瞬时遗忘（通过适当选择遗忘因子和窗口大小实现）的新型二阶更新递推最小二乘算法（RLSR2），并将其与已知的一阶更新RLS算法系统地关联起来。此外，本报告还建立了与信息矩阵逆和参数向量收敛相关的递推算法的新特性（可用于进一步的性能改进）。新算法的性能在存在显著谐波发射的情况下，应用于电网事件估计问题中进行了检验。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [511] [Second-Order Characterizations of Tilt Stability in Composite Optimization](https://arxiv.org/abs/2507.11253)
> *复合优化中倾斜稳定性的二阶刻画*

*Boris S. Mordukhovich, Peipei Tang, Chengjing Wang* | **Category: math.OC, cs.NA, math.NA, 49J52, 49J53, 90C31** | **Updated: 2025-07-15**

**Keywords:** 倾斜稳定性, 复合优化, 二阶广义微分, 变分分析, 局部极小点

**Comment:** 32 pages

> **TL;DR:** 本文研究了有限维复合优化问题局部极小点的倾斜稳定性，并利用二阶广义微分建立了统一的倾斜稳定性刻画。

**AI_Comments:** 本文在复合优化背景下，通过引入二阶广义微分技术，为倾斜稳定性提供了新的、统一的刻画方法，这对于理解和分析优化问题的敏感性具有重要理论价值。其贡献在于提供了一个严谨的理论框架，有助于未来算法的设计和分析。

<details>
  <summary>Details</summary>

**Motivation:** 倾斜稳定性是变分分析和优化的一个基本概念，在理论问题和数值计算中都起着关键作用。本文旨在深入研究其在复合优化问题中的特性。

**Method:** 在最弱的度量次正则性约束资格和其他可验证条件下，本文通过二阶广义微分建立了统一的邻域和点基倾斜稳定性刻画。

**Result:** 建立了统一的邻域和点基倾斜稳定性刻画，适用于目标函数为抛物线正则函数和平滑函数复合的复合优化问题。

**Conclusion:** 所获得的结果为变分稳定性、优化数值算法及相关主题的进一步发展提供了严谨的理论基础。

> **ai_Abstract:** 本文研究了有限维复合优化问题中局部极小点的倾斜稳定性，这类问题的目标函数是抛物线正则函数与光滑函数的复合。在满足弱度量次正则性约束资格等条件下，研究通过二阶广义微分方法，建立了倾斜稳定性的统一邻域和点基刻画。这些理论成果为变分稳定性及优化数值算法的进一步发展奠定了坚实的基础。

> **摘要翻译:** 倾斜稳定性是变分分析和优化的一个基本概念，在理论问题和数值计算中都起着关键作用。本文研究了有限维一般复合优化问题局部极小点的倾斜稳定性，其中扩展实值目标函数是抛物线正则函数和平滑函数的复合。在最弱的度量次正则性约束资格和其他可验证条件下，我们通过二阶广义微分建立了统一的邻域和点基倾斜稳定性刻画。所获得的结果为变分稳定性、优化数值算法及相关主题的进一步发展提供了严谨的理论基础。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [706] [A Mathematical Optimization Approach to Multisphere Support Vector Data Description](https://arxiv.org/abs/2507.11106)
> *一种多球支持向量数据描述的数学优化方法*

*Víctor Blanco, Inmaculada Espejo, Raúl Páez, Antonio M. Rodríguez-Chía* | **Category: math.OC, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 异常值检测, 支持向量数据描述, 数学优化, 混合整数二阶锥, 核技巧

**Comment:** 18 pages, 5 figures, 3 tables

> **TL;DR:** 本文提出了一种新的数学优化框架，用于多模态数据集中的异常值检测，通过构建欧几里得超球体来识别异常观测值，并开发了支持核技巧的双重模型，在准确性和鲁棒性方面优于现有启发式技术。

**AI_Comments:** 该论文通过引入数学优化框架，特别是混合整数二阶锥模型，对支持向量数据描述进行了创新性扩展，使其能够更精确和鲁棒地进行多模态和非线性数据中的异常值检测。

<details>
  <summary>Details</summary>

**Motivation:** 在多模态数据集中进行异常值检测，并扩展支持向量数据描述方法。

**Method:** 提出了一种新的数学优化框架，即混合整数二阶锥模型，用于构建欧几里得超球体以识别异常观测值。在此基础上，开发了一个允许应用核技巧的双重模型，从而能够在复杂的非线性数据结构中检测异常值。

**Result:** 广泛的计算研究表明，该精确方法有效，在准确性和鲁棒性方面优于现有启发式技术。

**Conclusion:** 该数学优化方法在多模态数据集的异常值检测中表现出更高的准确性和鲁棒性，优于现有启发式技术。

> **ai_Abstract:** 本文提出了一种基于数学优化框架的多球支持向量数据描述方法，用于多模态数据集中的异常值检测。该方法包括一个原始的混合整数二阶锥模型，用于构建欧几里得超球体，以及一个支持核技巧的双重模型，以处理非线性数据。实验结果表明，该精确方法在准确性和鲁棒性方面优于现有启发式技术。

> **摘要翻译:** 我们提出了一种用于多模态数据集中异常值检测的新型数学优化框架，该框架扩展了支持向量数据描述方法。我们提供了一个原始公式，以混合整数二阶锥模型的形式，构建欧几里得超球体来识别异常观测值。在此基础上，我们开发了一个双重模型，该模型能够应用核技巧，从而允许在复杂的非线性数据结构中检测异常值。广泛的计算研究证明了我们精确方法的有效性，在准确性和鲁棒性方面显示出优于现有启发式技术的明显优势。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='physicsoptics'></a>
## physics.optics 

### [144] [Gaussian Noise Model of Nonlinear Distortions from Semiconductor Optical Amplifiers](https://arxiv.org/abs/2507.11517)
> *半导体光放大器非线性失真的高斯噪声模型*

*Hartmut Hafermann* | **Category: physics.optics, eess.SP** | **Updated: 2025-07-15**

**Keywords:** 半导体光放大器, 高斯噪声模型, 非线性失真, 闭合表达式, 波分复用

**Comment:** 

> **TL;DR:** 开发了一种基于Agrawal模型的半导体光放大器非线性失真高斯噪声模型，并推导了一个简单的闭合表达式，其在特定条件下误差小于0.1 dB。

**AI_Comments:** 这项研究的创新之处在于提出了一个简单且准确的闭合表达式来量化半导体光放大器的非线性噪声，并明确了其有效区域。这对于光通信系统中宽带信号的噪声管理和系统设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发一种模型来描述半导体光放大器中的非线性噪声功率谱密度，并量化其对宽带波分复用信号的影响。

**Method:** 研究人员开发了一个非线性噪声功率谱密度的高斯噪声模型，该模型基于Agrawal模型描述半导体光放大器。他们推导了一个简单的闭合表达式，用于计算宽带波分复用信号的非线性噪声与信号比，并使用数值模拟评估了该闭合表达式的准确性和有效区域。

**Result:** 获得了一个简单的闭合表达式，用于表示宽带波分复用信号的非线性噪声与信号比，该表达式是Agrawal模型参数、放大器输出功率和传输带宽的函数。数值模拟结果显示，当带宽与增益恢复时间乘积$B\times\tau_c$超过100时，该表达式的误差小于0.1 dB。

**Conclusion:** 所开发的闭合表达式在带宽与增益恢复时间乘积$B\times\tau_c$大于100的条件下，能够以小于0.1 dB的误差准确预测半导体光放大器中宽带波分复用信号的非线性噪声与信号比。

> **ai_Abstract:** 这篇论文开发了一个基于Agrawal模型的半导体光放大器非线性失真高斯噪声模型。研究人员推导出了一个简单的闭合表达式，用于计算宽带波分复用信号的非线性噪声与信号比，该表达式取决于Agrawal模型参数、放大器输出功率和传输带宽。通过数值模拟验证，当带宽与增益恢复时间乘积$B\times\tau_c$大于100时，该表达式的误差小于0.1 dB，证明了其在特定条件下的高准确性。

> **摘要翻译:** 针对Agrawal模型描述的半导体光放大器，开发了一种非线性噪声功率谱密度的高斯噪声模型。推导了一个简单的闭合表达式，用于表示宽带波分复用信号的非线性噪声与信号比，该表达式是Agrawal模型参数、放大器输出功率和传输带宽的函数。在数值模拟中评估了该闭合表达式的准确性及其有效区域。当带宽与增益恢复时间乘积$B\times\tau_c$超过100时，误差小于0.1 dB。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

### [474] [Energy Balance and Optical Theorem for Time-Modulated Subwavelength Resonator Arrays](https://arxiv.org/abs/2507.11201)
> *针对时间调制亚波长谐振器阵列的能量平衡和光学定理*

*Erik Orvehed Hiltunen, Liora Rueff* | **Category: physics.optics, cs.NA, math-ph, math.AP, math.MP, math.NA, 35Q60, 35L05, 78A45, 78M35, 35P25** | **Updated: 2025-07-15**

**Keywords:** 时间调制, 亚波长谐振器, 能量平衡, 光学定理, 散射矩阵

**Comment:** 19 pages, 10 figures

> **TL;DR:** 本文研究了时间调制亚波长谐振器阵列中的波传播，推导了能量平衡的光学定理，并展示了能量增益/损耗和激光点的存在，为设计能量耗散或放大系统奠定了基础。

**AI_Comments:** 这项工作创新性地将时间调制引入亚波长谐振器阵列，并首次推导了其能量平衡的光学定理，揭示了能量增益/损失的机制以及激光点的存在，对于理解和设计新型超材料和光子器件具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在理解和量化时间调制亚波长谐振器阵列中波传播的能量特性，为设计能量耗散或能量放大系统奠定基础。

**Method:** 采用基于傅里叶展开和散射矩阵技术的散射框架，研究高对比度状态下，入射波与时变系统之间的相互作用，并推导了总能量通量的公式和光学定理。通过数值实验，调查了时间依赖性、工作频率和谐振器数量对能量增益和损失的影响。

**Result:** 导出了对应于时间相关谐振器系统的总能量通量公式；表明总能量通量由透射和反射能量通量组成；推导了表征系统能量平衡的光学定理；通过数值实验研究了时间依赖性、工作频率和谐振器数量对最大可实现能量增益和能量损失的影响；展示了总能量发散的激光点的存在。

**Conclusion:** 本文的结果为设计能量耗散或能量放大系统奠定了基础。

> **ai_Abstract:** 本文研究了波在时间调制亚波长谐振器一维阵列中的传播。作者利用傅里叶展开和散射矩阵技术构建散射框架，推导了时间相关系统中总能量通量的公式，并提出了一个描述系统能量平衡的光学定理。通过数值实验，论文分析了时间依赖性、频率和谐振器数量对能量增益和损失的影响，并揭示了激光点的存在。这些发现为未来设计能量耗散或能量放大系统提供了理论基础。

> **摘要翻译:** 我们研究了波在具有周期性时间调制材料参数的亚波长谐振器一维阵列中的传播。在高对比度状态下，我们使用基于傅里叶展开和散射矩阵技术的散射框架来捕捉入射波与时变系统之间的相互作用。通过这种方式，我们推导了对应于时间相关谐振器系统的总能量通量公式。我们表明总能量通量由透射和反射能量通量组成，并推导了一个表征系统能量平衡的光学定理。我们提供了大量的数值实验来研究时间依赖性、工作频率和谐振器数量对最大可实现能量增益和能量损失的影响。此外，我们展示了总能量发散的激光点的存在。我们的结果为设计能量耗散或能量放大系统奠定了基础。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

<a id='cspl'></a>
## cs.PL 

### [146] [Stream programs are monoid homomorphisms with state](https://arxiv.org/abs/2507.10799)
> *流程序是带状态的幺半群同态*

*Tyler Hou, Michael Arntzenius, Max Willsey* | **Category: cs.PL, cs.DC** | **Updated: 2025-07-14**

**Keywords:** 流程序, 幺半群同态, 确定性流函数, 等式推理, 数据流程序

**Comment:** 

> **TL;DR:** 本文提出将确定性流函数实现为到“状态”幺半群的同态，从而简化了流程序优化的等式推理条件。

**AI_Comments:** 这项工作创新性地将流程序抽象为带状态的幺半群同态，显著简化了流程序优化的理论基础，同时保持了强大的推理能力，对于数据流程序的设计和优化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的流程序优化语义框架条件复杂，需要一种更简单的方式来支持对富有表现力的数据流程序进行等式推理。

**Method:** 定义了一大类确定性流函数，并展示它们可以作为到“状态”幺半群的同态来实现。

**Result:** 所提出的同态定律比以前的语义框架条件更简单，但仍支持对包括顺序组合、并行组合和反馈在内的富有表现力的数据流程序进行丰富的等式推理。通过分区数据库连接、分层否定和TCP简化模型等示例进行了演示。

**Conclusion:** 通过将流程序建模为带状态的幺半群同态，可以极大地简化流程序优化的推理条件，同时保持对复杂数据流程序的强大表达和推理能力。

> **ai_Abstract:** 本文定义了一类确定性流函数，并提出它们可以通过到“状态”幺半群的同态来实现。这种方法提供的同态定律比现有流程序优化框架的条件更简单，同时仍能支持对复杂数据流程序的等式推理，并通过具体示例进行了验证。

> **摘要翻译:** 我们定义了一大类确定性流函数，并表明它们可以作为到“状态”幺半群的同态来实现。这些同态定律比以前用于流程序优化的语义框架的条件更简单，但仍支持对富有表现力的数据流程序（包括顺序组合、并行组合和反馈）进行丰富的等式推理。我们通过分区数据库连接、分层否定和TCP的简化模型示例来证明这一点。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

<a id='q-bionc'></a>
## q-bio.NC 

### [150] [Bridging Brains and Machines: A Unified Frontier in Neuroscience, Artificial Intelligence, and Neuromorphic Systems](https://arxiv.org/abs/2507.10722)
> *连接大脑与机器：神经科学、人工智能和神经形态系统中的统一前沿*

*Sohan Shankar, Yi Pan, Hanqi Jiang, Zhengliang Liu, Mohammad R. Darbandi, Agustin Lorenzo, Junhao Chen, Md Mehedi Hasan, Arif Hassan Zidan, Eliana Gelman, Joshua A. Konfrst, Jillian Y. Russell, Katelyn Fernandes, Tianze Yang, Yiwei Li, Huaqin Zhao, Afrar Jahin, Triparna Ganguly, Shair Dinesha, Yifan Zhou, Zihao Wu, Xinliang Li, Lokesh Adusumilli, Aziza Hussein, Sagar Nookarapu, Jixin Hou, Kun Jiang, Jiaxi Li, Brenden Heinel, XianShen Xi, Hailey Hubbard, Zayna Khan, Levi Whitaker, Ivan Cao, Max Allgaier, Andrew Darby, Lin Zhao, Lu Zhang, Xiaoqiao Wang, Xiang Li, Wei Zhang, Xiaowei Yu, Dajiang Zhu, Yohannes Abate, Tianming Liu* | **Category: q-bio.NC, cs.NE** | **Updated: 2025-07-14**

**Keywords:** 神经科学, 人工智能, 神经形态系统, 脑生理学, 统一研究范式

**Comment:** 

> **TL;DR:** 本文探讨了神经科学、通用人工智能 (AGI) 和神经形态计算的融合，提出了基于大脑原理的下一代AGI系统设计，并讨论了相关硬件和面临的挑战。

**AI_Comments:** 这篇论文的创新之处在于其前瞻性地识别并整合了神经科学、人工智能和神经形态计算这三个前沿领域，提出了一个统一的研究框架。它不仅从生物学原理中提炼出AI系统设计灵感，还指出了实现脑规模效率的硬件方向和当前面临的关键挑战，为未来的跨学科研究提供了清晰的路线图和深刻的洞察。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在识别神经科学、通用人工智能 (AGI) 和神经形态计算之间日益增长的融合趋势，并提出一个统一的研究范式，以利用大脑生理学原理指导下一代AGI系统的设计。

**Method:** 本文采用基于大脑生理学的框架，阐述了突触可塑性、稀疏尖峰通信和多模态关联如何为下一代AGI系统提供设计原则。它回顾了从早期连接主义模型到大型语言模型的演变，并讨论了忆阻交叉开关、内存计算阵列等新型物理基板。

**Result:** 论文提出了基于大脑生理学（如突触可塑性、稀疏尖峰通信、多模态关联）的下一代AGI系统设计原则。它指出，变压器注意力、基础模型预训练和多智能体架构等关键AI创新与皮层机制、工作记忆等神经生物学过程相对应。同时，文章还介绍了忆阻交叉开关等新型物理基板，并识别了四个关键挑战：将尖峰动态与基础模型整合、保持终身可塑性、统一语言与感觉运动学习以及实施伦理保障。

**Conclusion:** 论文通过整合神经科学、计算和硬件的视角，为这些领域提供了一个综合性的研究议程，以应对当前挑战并推动统一研究范式的发展。

> **ai_Abstract:** 这篇综述论文探讨了神经科学、通用人工智能 (AGI) 和神经形态计算的融合，提出了一个统一的研究范式。论文利用大脑生理学框架，阐明了突触可塑性等原理如何为下一代AGI系统提供设计蓝图，并指出当前AI创新与神经生物学过程的相似之处。此外，文章还讨论了新型物理基板以实现脑规模效率，并列举了四个关键挑战，旨在为跨学科研究提供综合性议程。

> **摘要翻译:** 这篇定位和调查论文识别了神经科学、通用人工智能 (AGI) 和神经形态计算之间日益增长的融合，形成了一个统一的研究范式。我们利用一个以脑生理学为基础的框架，强调了突触可塑性、基于稀疏尖峰的通信和多模态关联如何为下一代AGI系统提供设计原则，这些系统可能结合人类和机器智能。本综述追溯了从早期连接主义模型到最先进的大型语言模型的演变，展示了变压器注意力、基础模型预训练和多智能体架构等关键创新如何反映皮层机制、工作记忆和情景巩固等神经生物学过程。然后，我们讨论了能够打破冯·诺依曼瓶颈以在硅中实现脑规模效率的新兴物理基板：忆阻交叉开关、内存计算阵列以及新兴的量子和光子器件。在这个交叉点存在四个关键挑战：1) 将尖峰动态与基础模型整合，2) 在不发生灾难性遗忘的情况下保持终身可塑性，3) 在具身智能体中统一语言与感觉运动学习，以及 4) 在高级神经形态自主系统中实施伦理保障。这种跨神经科学、计算和硬件的综合视角为这些领域中的每一个都提供了一个整合性的议程。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [162] [MultiVox: Benchmarking Voice Assistants for Multimodal Interactions](https://arxiv.org/abs/2507.10859)
> *MultiVox：多模态交互语音助手基准测试*

*Ramaneswaran Selvakumar, Ashish Seth, Nishit Anand, Utkarsh Tyagi, Sonal Kumar, Sreyan Ghosh, Dinesh Manocha* | **Category: cs.MM, cs.CL, cs.HC** | **Updated: 2025-07-14**

**Keywords:** MultiVox, 语音助手, 多模态交互, 基准测试, 副语言特征

**Comment:** Work In Progress

> **TL;DR:** 引入MultiVox，首个多模态语音助手基准测试，用于评估模型理解细粒度语音特征和视觉信号的能力，并发现当前SOTA模型在此方面表现不佳。

**AI_Comments:** MultiVox的创新之处在于其专注于评估语音助手对细粒度语音特征（如情感、音调）和视觉线索的深层理解与整合能力，填补了现有基准的空白。这对于推动真正智能的多模态AI发展至关重要，揭示了当前SOTA模型在处理复杂、上下文感知交互方面的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有基准测试在全面评估语音助手生成上下文感知响应方面存在不足，特别是未能有效评估模型对细粒度语音特征（如音高、情感、音色、音量）的隐含理解，以及将副语言线索与互补视觉信号对齐的能力。

**Method:** 为解决现有基准测试的不足，本文引入了MultiVox，这是首个旨在评估语音助手整合口语和视觉线索（包括副语言语音特征）以实现真正多模态理解的综合基准。MultiVox包含1000个人工标注和录制的语音对话，涵盖了多样化的副语言特征和一系列视觉线索（如图像和视频）。

**Result:** 对9个最先进模型的评估表明，尽管人类在这些任务中表现出色，但当前模型在生成上下文相关响应方面持续存在困难。

**Conclusion:** 当前最先进的语音助手模型在整合细粒度语音特征和视觉线索以实现真正的多模态上下文理解方面仍有显著不足，需要进一步研究和改进。

> **ai_Abstract:** 本文介绍了MultiVox，一个全新的多模态语音助手基准测试，旨在解决现有评估方法在衡量模型对细粒度语音特征和视觉信息理解方面的不足。MultiVox包含1000个带有人工标注的语音对话，融合了多种副语言特征和视觉线索。对9个主流模型的测试结果显示，尽管人类能轻松处理这些任务，但现有模型在产生上下文感知的响应上仍面临挑战，表明在多模态交互理解方面仍有很大的提升空间。

> **摘要翻译:** 大型语言模型（LLMs）的快速发展使得全能模型能够作为语音助手，理解口语对话。这些模型可以处理文本以外的多模态输入，例如语音和视觉数据，从而实现更具上下文感知的交互。然而，当前的基准测试在全面评估这些模型生成上下文感知响应的能力方面存在不足，特别是在隐含理解细粒度语音特征（如音高、情感、音色和音量）或环境声学上下文（如背景声音）方面。此外，它们未能充分评估模型将副语言线索与互补视觉信号对齐以告知其响应的能力。为解决这些差距，我们引入了MultiVox，这是首个旨在评估语音助手整合口语和视觉线索（包括副语言语音特征）以实现真正多模态理解的全能语音助手基准。具体而言，MultiVox包括1000个人工标注和录制的语音对话，涵盖了多样化的副语言特征和一系列视觉线索，如图像和视频。我们对9个最先进模型的评估表明，尽管人类在这些任务中表现出色，但当前模型在生成上下文相关响应方面持续存在困难。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='csdm'></a>
## cs.DM 

### [175] [Rapid Mixing of Glauber Dynamics for Monotone Systems via Entropic Independence](https://arxiv.org/abs/2507.11031)
> *通过熵独立性实现单调系统Glauber动力学的快速混合*

*Weiming Feng, Minji Yang* | **Category: cs.DM, cs.DS, math-ph, math.MP, math.PR** | **Updated: 2025-07-15**

**Keywords:** Glauber动力学, 混合时间, 单调系统, 熵独立性, 随机簇模型, 二部硬核模型

**Comment:** 

> **TL;DR:** 该论文通过熵独立性和新的比较结果，证明了单调系统Glauber动力学更快的混合时间，改进了随机簇模型和二部硬核模型的现有界限。

**AI_Comments:** 该论文在Glauber动力学混合时间分析方面取得了显著进展，特别是对于重要的统计物理模型。它将经典技术（随机支配）与现代工具（高维膨胀器）创新性地结合，并引入了新颖的比较结果，展示了强大的理论贡献和方法独创性。对近期最新成果的改进突显了其实际影响。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在研究和改进单调系统上Glauber动力学混合时间的理解，特别是针对当前界限可以收紧的情况。

**Method:** 1. 证明了在满足熵独立条件的单调系统上Glauber动力学的一个新的混合时间比较结果。2. 结合了经典审查不等式中的随机支配论证思想和最近发展的高维膨胀器。3. 发展了Glauber动力学和单调系统场动力学之间的一个新颖的比较结果。

**Result:** 1. 对于由铁磁Ising模型在一致偏置外场下引起的随机簇模型，获得了$	ilde{O}(n)$的混合时间。2. 对于在单边唯一性条件下二部硬核模型，获得了$	ilde{O}(n^2)$的混合时间。3. 改进了[Chen and Zhang, SODA'23]和[Chen, Liu, and Yin, FOCS'23]中已知的最佳结果。

**Conclusion:** 该论文通过引入一个涉及熵独立性和新颖比较技术的新理论框架，成功地为特定单调系统上的Glauber动力学建立了改进的混合时间界限。

> **ai_Abstract:** 本论文研究了单调系统上Glauber动力学的混合时间。通过引入熵独立条件和新的比较结果，它显著改进了特定应用的混合时间界限。值得注意的是，它为随机簇模型获得了$\tilde{O}(n)$，为二部硬核模型获得了$\tilde{O}(n^2)$，超越了之前的最新成果。该证明整合了随机支配和高维膨胀器，其关键在于Glauber动力学和场动力学之间的新颖比较。

> **摘要翻译:** 我们研究了单调系统上Glauber动力学的混合时间。对于满足熵独立条件的单调系统，我们证明了Glauber动力学的一个新的混合时间比较结果。对于具体的应用，我们获得了由铁磁Ising模型在一致偏置外场下引起的随机簇模型的$\tilde{O}(n)$混合时间，以及在单边唯一性条件下二部硬核模型的$\tilde{O}(n^2)$混合时间，其中$n$是相应模型中的变量数量，这改进了[Chen and Zhang, SODA'23]和[Chen, Liu, and Yin, FOCS'23]中已知的最佳结果。我们的证明结合了经典审查不等式中的随机支配论证思想和最近发展的高维膨胀器。证明中的关键步骤是Glauber动力学和单调系统场动力学之间的一个新颖的比较结果。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

### [431] [Verification of Hamiltonian Path Conjecture (BHR Conjecture) for Integers up to p=31 based on one multiset per FP](https://arxiv.org/abs/2507.00059)
> *基于每个FP一个多重集，验证整数p=31的哈密顿路径猜想（BHR猜想）*

*Ranjan N Naik* | **Category: cs.DM, cs.DS, math.CO** | **Updated: 2025-07-14**

**Keywords:** 哈密顿路径猜想, Buratti-Horak-Rosa猜想, 计算验证, 频率划分, 递归回溯

**Comment:** This result supports the results by Mariusz Meszka for all primes up
  to 23 (included) with the aid of a computer

> **TL;DR:** 本文通过一种新的计算方法，成功验证了Buratti-Horak-Rosa哈密顿路径猜想对于p<32的整数成立，为该猜想提供了进一步证据。

**AI_Comments:** 该论文的创新点在于采用了一种“不同方式”进行BHR猜想的验证，即“为每个频率划分考虑一个多重集”，这可能提高了验证的效率或覆盖范围。其重要性在于通过计算方法为著名的哈密顿路径猜想提供了更广泛的证据，特别是在扩展了先前工作的基础上。此外，程序设计注重效率和可扩展性，预示着未来可以探索更大的整数范围，这对于计算数论和图论领域具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过计算方法验证Buratti-Horak-Rosa (BHR) 哈密顿路径猜想。该研究建立在Mariusz Meszka先前工作的基础上，旨在以一种不同的方式扩展验证范围并提供更多证据。

**Method:** 研究使用一个优化的Python程序，该程序为每个频率划分（FP）考虑一个多重集，并系统地生成边长频率划分。它采用递归回溯算法来构建相应的哈密顿路径，以验证BHR猜想。该程序经过优化以提高效率并设计为可扩展性。

**Result:** 研究成功地计算验证了对于所有小于32的整数（特别是p=31）的所有频率划分的BHR猜想。对于合数p=30，Python代码在联想笔记本上耗时约11小时完成验证。

**Conclusion:** 该研究通过计算验证为Buratti-Horak-Rosa哈密顿路径猜想的有效性提供了进一步的证据，并证明了所用程序的效率和可扩展性，为未来探索更高整数值奠定了基础。

> **ai_Abstract:** 本文提出了一个优化的Python程序，通过为每个频率划分考虑一个多重集，以计算方式验证了Buratti-Horak-Rosa (BHR) 哈密顿路径猜想。该程序成功验证了p<32的所有整数（包括素数和合数）的猜想，并展示了其效率和可扩展性，为该数学猜想提供了新的计算证据。

> **摘要翻译:** 本文提出了一种计算方法，用于验证关于完整图中具有指定边长的哈密顿路径的特定猜想，通常称为Buratti-Horak-Rosa猜想。在Mariusz Meszka先前计算工作的基础上，其工作已验证了该猜想对于所有素数高达23的情况，我们的Python程序通过为每个频率划分（FP）考虑一个多重集，以不同的方式对高达p=32的合数和素数进行了BHR猜想验证。我们报告了对小于32的整数的所有频率划分的成功计算验证，特别是展示了p=31的结果。对于合数p=30，该Python代码在联想笔记本电脑上耗时约11小时完成验证。该方法系统地生成边长频率划分，并采用递归回溯算法来构建相应的哈密顿路径。所提出的程序经过优化以提高效率并设计为可扩展性，允许在更强大的计算资源上使用它来探索更高的整数值，从而为猜想的有效性提供进一步的证据。
Peter Horak和Alex Rosa（概括了Marco Buratti的猜想）的猜想指出，一个由(p-1)个不超过[p/2]的正整数组成的多重集L，当且仅当对于p的每个除数d，L中d的倍数数量至多为[p-d]时，才是具有顶点集{1, 2, ..., [p-1]}的完整图的合适哈密顿路径的边长列表。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

<a id='mathst'></a>
## math.ST 

### [201] [Coverage errors for Student's t confidence intervals comparable to those in Hall (1988)](https://arxiv.org/abs/2501.07645)
> *学生t置信区间的覆盖误差与Hall (1988)中的相当*

*Art B. Owen* | **Category: math.ST, cs.NA, math.NA, stat.TH** | **Updated: 2025-07-15**

**Keywords:** 学生t置信区间, 覆盖误差, 渐近公式, Hall (1988), 随机准蒙特卡洛抽样

**Comment:** 

> **TL;DR:** 本文推导了学生t置信区间的渐近覆盖误差公式，并与Hall (1988)中的正态理论区间公式进行比较，发现学生t区间的误差公式为$0.14\kappa -2.12\gamma^2$，且澄清了Hall表中双侧误差的比例关系。

**AI_Comments:** 本文的重要创新在于它推导出了学生t置信区间的渐近覆盖误差公式，填补了经典文献Hall (1988)中的一个空白。这对于理论统计学和实际应用，尤其是在需要精确评估置信区间性能的蒙特卡洛模拟等领域，具有重要意义。它不仅提供了缺失的公式，还对现有公式进行了澄清和验证，提高了统计推断的准确性。

<details>
  <summary>Details</summary>

**Motivation:** Hall (1988)的表格中缺少了广泛使用的学生t置信区间的渐近覆盖误差公式，且在随机准蒙特卡洛抽样中，基于学生t统计量的置信区间表现出惊人的稳健性，这促使作者重新审视并推导该公式。

**Method:** 本文推导了学生t置信区间的渐近覆盖误差公式，并与Hall (1988)中基于高斯分位数和高斯最大似然方差估计的正态理论区间公式进行对比。同时，它还澄清了Hall (1988)中一些覆盖误差公式的形式。

**Result:** Hall (1988)中正态理论区间的误差公式为$0.14\kappa -2.12\gamma^2-3.35$，而本文推导的学生t置信区间的相应误差公式为$0.14\kappa -2.12\gamma^2$。双侧误差的形式为$2\Phi^{-1}(0.975)(A\kappa + \gamma^2+C)\varphi(1.96)/n +O(1/n^{3/2})$，并且Hall的表格确实与双侧覆盖误差成比例。

**Conclusion:** 本文成功推导了学生t置信区间的渐近覆盖误差公式，填补了Hall (1988)表格中的空白，并修正和澄清了Hall (1988)中关于双侧覆盖误差公式的理解。

> **ai_Abstract:** 本文推导了学生t置信区间的渐近覆盖误差公式，填补了Hall (1988)中相关表格的空白。研究发现，学生t区间的误差公式为$0.14\kappa -2.12\gamma^2$，而正态理论区间为$0.14\kappa -2.12\gamma^2-3.35$。此外，论文还澄清了Hall (1988)中双侧覆盖误差公式的正确形式和比例关系，指出Hall的原始公式与双侧误差成比例。

> **摘要翻译:** Hall (1988)的表1包含了基于$n$个独立同分布样本的均值的一些非参数近似95%置信区间的渐近覆盖误差公式。该表包括了基于中心极限定理，使用高斯分位数和高斯最大似然方差估计的区间条目。它缺少了非常广泛使用的学生t置信区间的条目。本文推导了这样一个公式。重新审视这个问题的原因是学生t统计量在随机准蒙特卡洛抽样中置信区间表现出惊人的稳健性。Hall的表格中正态理论区间的误差公式为$0.14\kappa -2.12\gamma^2-3.35$；学生t区间的相应条目是$0.14\kappa -2.12\gamma^2$。本说明的早期版本报告称其修正了Hall (1988)中的一些覆盖误差公式。双侧误差的形式为$2\Phi^{-1}(0.975)(A\kappa + \gamma^2+C)\varphi(1.96)/n +O(1/n^{3/2})$，其中误差可能为$O(n^{-2})$。Hall的表格显示为$\Phi^{-1}(0.975)(A\kappa + B\gamma^2+C)$。原意为修正的版本是$2(A\kappa + B\gamma^2+C)$，大约宽了$2/1.96\doteq1.02$倍。因此，Hall的表格确实与双侧覆盖误差成比例。

</details>

[⬆️ 返回分类顶部](#mathst) | [⬆️ 返回总目录](#toc)

---

<a id='cscg'></a>
## cs.CG 

### [210] [Compressed data structures for Heegaard splittings](https://arxiv.org/abs/2507.11406)
> *Heegaard 分裂的压缩数据结构*

*Henrique Ennes, Clément Maria* | **Category: cs.CG, cs.DS, math.GT** | **Updated: 2025-07-15**

**Keywords:** Heegaard分裂, 压缩数据结构, 3-流形, 正规曲线, 拓扑不变量

**Comment:** 

> **TL;DR:** 本文提出了一种用于Heegaard分裂的压缩数据结构，通过将Heegaard图表示为曲面三角剖分上的正规曲线，实现了比传统三流形三角剖分更高的压缩率，并提供了多项式时间算法进行图的比较、操作、稳定化、约化检测以及拓扑不变量计算，在实际应用中表现出更好的精度和速度。

**AI_Comments:** 本文的创新点在于提出了一个高度压缩且计算效率高的Heegaard分裂数据结构。通过将Heegaard图表示为正规曲线，并引入新的复杂性度量，实现了比传统方法显著的存储和计算优势。多项式时间算法的提出，使得对3-流形的各种拓扑操作和不变量计算变得更加可行和高效。这项工作对于计算拓扑学和3-流形研究领域具有重要意义，尤其是在处理大型或复杂3-流形数据时，其性能提升将非常显著。

<details>
  <summary>Details</summary>

**Motivation:** Heegaard分裂提供了一种表示闭合3-流形的自然方式，但其传统的表示方法（如3-流形三角剖分）可能效率低下。本文的动机是开发一种更有效、更压缩的数据结构来表示Heegaard图，以便更高效地处理和分析3-流形。

**Method:** 本文提出了一种新的数据结构，通过将Heegaard图表示为曲面三角剖分上的正规曲线。这种表示方法的复杂性通过二进制表示正规坐标向量所需的空间来衡量。在此基础上，开发了多项式时间算法用于比较和操作Heegaard图、执行稳定化、检测平凡稳定化和约化，以及计算基础流形的拓扑不变量（如基本群和第一同调群）。

**Result:** 所提出的数据结构比3-流形三角剖分具有显著更高的压缩率，对于某些族可以获得指数级增益。即使在简洁的复杂性定义下，也建立了用于比较和操作Heegaard图的多项式时间算法，包括稳定化、检测平凡稳定化和约化，以及计算基本群和第一同调群等拓扑不变量。早期实现与标准3-流形软件相比，在平均情况下实现了更好的精度和更快的算法，对于某些特定输入形式实现了指数级速度提升。

**Conclusion:** 本文成功开发了一种高效且高度压缩的数据结构来表示Heegaard分裂，并提供了多项式时间算法来处理和分析这些结构。这显著提高了3-流形计算的效率和精度，尤其在处理复杂流形时展现出优越性。

> **ai_Abstract:** 本文提出了一种用于Heegaard分裂的新型压缩数据结构。该结构通过将Heegaard图表示为曲面三角剖分上的正规曲线，显著降低了数据存储复杂度，甚至对特定流形族实现了指数级压缩。在此基础上，作者开发了多项式时间算法来执行Heegaard图的比较、操作、稳定化、约化检测以及拓扑不变量（如基本群和第一同调群）的计算。实验结果表明，与现有3-流形软件相比，该方法在平均情况下提供了更高的精度和更快的运行速度，并在某些特定输入上展现出指数级加速。

> **摘要翻译:** Heegaard 分裂通过将柄体沿公共曲面粘合，提供了一种闭合3-流形的自然表示。这些分裂可以等价地由位于曲面上的两组有限的子午线给出，这些子午线定义了一个 Heegaard 图。我们提出了一种数据结构，以有效的方式将 Heegaard 图表示为相对于曲面三角剖分的正规曲线，其复杂性由表示正规坐标向量的二进制空间来衡量。与3-流形的三角剖分相比，这种结构可以显著更压缩，对于某些族可以获得指数级增益。即使在这种简洁的复杂性定义下，我们也建立了多项式时间算法来比较和操作图，执行稳定化，检测平凡稳定化和约化，以及计算基础流形的拓扑不变量，例如它们的基本群和第一同调群。我们还将我们技术的早期实现与3-流形标准软件程序进行对比，在平均情况下实现了更好的精度和更快的算法，对于某些特定输入形式实现了指数级速度提升。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matstr-el'></a>
## cond-mat.str-el 

### [231] [Seeding neural network quantum states with tensor network states](https://arxiv.org/abs/2506.23550)
> *用张量网络态为神经网络量子态播种*

*Ryui Kaneko, Shimpei Goto* | **Category: cond-mat.str-el, cs.LG, cs.NA, math.NA, quant-ph** | **Updated: 2025-07-15**

**Keywords:** 神经网络量子态, 张量网络态, 矩阵乘积态, 受限玻尔兹曼机, 规范多项式分解

**Comment:** 14 pages, 15 figures

> **TL;DR:** 该研究提出了一种通过规范多项式（CP）分解将矩阵乘积态（MPSs）高效转换为受限玻尔兹曼机波函数的方法，用于为量子多体基态计算生成良好的初始神经网络量子态。

**AI_Comments:** 该研究的创新之处在于通过CP分解，有效地连接了张量网络态（MPSs）和神经网络量子态（RBMs），为神经网络量子态的变分计算提供了一种系统且高效的初始化方法。这对于提高量子多体基态计算的收敛性和准确性至关重要。其多项式时间复杂度和已被证明的效率是显著的优势。

<details>
  <summary>Details</summary>

**Motivation:** 为了在量子多体基态计算中生成“良好”的初始神经网络量子态，并系统地缩短初始态与基态之间的距离。

**Method:** 通过对矩阵乘积态（MPSs）进行规范多项式（CP）分解，将其近似转换为由多项式隐藏单元组成的受限玻尔兹曼机波函数。

**Result:** 该方法能够在变分参数数量的多项式时间内生成良好初始神经网络量子态，并随着CP分解秩的增加，系统地缩短初始态与基态之间的距离。通过横场伊辛模型验证了其效率。

**Conclusion:** 该方法提供了一种有效途径，通过张量网络态为神经网络量子态提供初始值，从而改进量子多体基态计算，并有望应用于更一般的量子多体系统。

> **ai_Abstract:** 本文提出了一种高效的方法，通过对矩阵乘积态（MPSs）进行规范多项式（CP）分解，将其近似转换为受限玻尔兹曼机（RBM）波函数。这种方法能够为量子多体基态计算生成有效的初始神经网络量子态（NQS），并在多项式时间内完成。该方法通过增加CP分解的秩，系统地缩短了初始态与基态之间的距离，并通过横场伊辛模型验证了其效率，表明其可能适用于更复杂的量子系统。

> **摘要翻译:** 我们发现了一种有效的方法，通过对矩阵乘积态（MPSs）进行规范多项式（CP）分解，将MPSs近似转换为由多项式隐藏单元组成的受限玻尔兹曼机波函数。这种方法使我们能够在变分参数数量的多项式时间内生成用于量子多体基态计算的良好初始神经网络量子态，并随着CP分解秩的增加，系统地缩短初始态与基态之间的距离。我们以横场伊辛模型为例，展示了我们方法的效率，并讨论了我们方法在基态波函数具有复杂节点结构更一般的量子多体系统中的可能应用。

</details>

[⬆️ 返回分类顶部](#cond-matstr-el) | [⬆️ 返回总目录](#toc)

---

### [494] [Functional Neural Wavefunction Optimization](https://arxiv.org/abs/2507.10835)
> *函数式神经网络波函数优化*

*Victor Armegioiu, Juan Carrasquilla, Siddhartha Mishra, Johannes Müller, Jannes Nys, Marius Zeinhofer, Hang Zhang* | **Category: cond-mat.str-el, cs.LG, math.OC, physics.comp-ph, quant-ph** | **Updated: 2025-07-14**

**Keywords:** 变分量子蒙特卡洛, 神经网络波函数, 优化算法, Galerkin投影, 几何洞察

**Comment:** 

> **TL;DR:** 提出一个基于几何洞察的新框架，通过Galerkin投影将变分量子蒙特卡洛中的无限维优化问题转化为可处理的参数空间算法，统一了现有方法并导出了新算法，并成功应用于神经网络波函数对凝聚态物理模型的基态能量估计。

**AI_Comments:** 该论文的创新之处在于其将几何洞察引入变分量子蒙特卡洛的优化算法设计中，并利用Galerkin投影将复杂的无限维问题转化为可操作的有限维问题。这种方法不仅统一了现有技术，还为开发更高效、原理更清晰的新算法提供了途径，对于提升神经网络波函数在量子多体问题中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在变分量子蒙特卡洛中，通过引入函数空间的几何洞察力来设计和分析优化算法。

**Method:** 提出了一个框架，通过将无限维优化动力学通过Galerkin投影到变分拟设的切空间上，转换为可处理的参数空间算法。

**Result:** 该框架统一了随机重构和瑞利-高斯-牛顿等现有方法，与经典函数空间算法建立了联系，并推动了具有几何原理超参数选择的新算法的推导。通过数值实验验证了其对使用神经网络波函数建模的几个凝聚态物理典型模型的基态能量的准确估计，证明了其在实践中的相关性。

**Conclusion:** 该研究提出了一个统一的框架，用于优化变分量子蒙特卡洛中的神经网络波函数，通过几何原理和Galerkin投影，不仅整合了现有方法，还开辟了新算法的设计途径，并在实际应用中显示出准确性。

> **ai_Abstract:** 本文提出了一个用于变分量子蒙特卡洛(VMC)中优化算法设计与分析的通用框架。该框架利用函数空间的几何洞察，并通过Galerkin投影将无限维优化问题转化为可处理的参数空间算法。这一方法不仅统一了随机重构和瑞利-高斯-牛顿等现有VMC优化技术，还为开发具有几何原理超参数的新算法提供了基础。数值实验验证了该框架的实用性，特别是在使用神经网络波函数准确估计凝聚态物理模型基态能量方面的有效性。

> **摘要翻译:** 我们提出了一个用于变分量子蒙特卡洛中优化算法设计和分析的框架，该框架借鉴了对相应函数空间的几何洞察。该框架通过将无限维优化动力学通过Galerkin投影到变分拟设的切空间上，转换为可处理的参数空间算法。这一视角统一了随机重构和瑞利-高斯-牛顿等现有方法，提供了与经典函数空间算法的联系，并促使推导出了具有几何原理超参数选择的新算法。我们通过数值实验验证了我们的框架，通过使用神经网络波函数建模的几个凝聚态物理典型模型的基态能量的准确估计，证明了其在实践中的相关性。

</details>

[⬆️ 返回分类顶部](#cond-matstr-el) | [⬆️ 返回总目录](#toc)

---

<a id='mathds'></a>
## math.DS 

### [293] [Universality in computable dynamical systems: Old and new](https://arxiv.org/abs/2507.10725)
> *可计算动力系统中的普适性：旧与新*

*Ángel González-Prieto, Eva Miranda, Daniel Peralta-Salas* | **Category: math.DS, cs.FL, math.DG** | **Updated: 2025-07-14**

**Keywords:** 可计算动力系统, 普适性, 图灵普适性, 流体动力学, 纳维-斯托克斯方程

**Comment:** 31 pages, 5 figures

> **TL;DR:** 这篇综述论文回顾了通过动力系统表示可计算性的最新工作，从经典普适性到流体动力学中的图灵普适性等现代概念，并讨论了该领域的重要开放问题。

**AI_Comments:** 这篇论文是一份有价值的综述，它连接了计算和动力学领域，这是一个具有根本重要性的主题。它关注最新进展，包括与纳维-斯托克斯方程和陶哲轩计划相关的高度当前的工作，使其尤为重要。对流体动力学中图灵普适性和拓扑克莱尼场理论等现代概念的探索提供了创新的视角。识别开放问题对未来的研究方向至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 计算模型与动力学之间的关系长期以来吸引着数学家和计算机科学家。最近，由于陶哲轩（T. Tao）旨在利用嵌入式计算模型发现纳维-斯托克斯方程爆破解的计划，这种联系重新获得了关注。

**Method:** 这是一篇综述论文，回顾了近期通过动力系统引入新颖视角来表示可计算性的工作。它探讨了经典意义上的动力学普适性以及流体动力学和拓扑克莱尼场理论中图灵普适性的现代概念，作为通过动力学边界表示可计算函数的一种系统方法。

**Result:** 该论文回顾了通过动力系统表示可计算性的新颖视角，探讨了经典动力学普适性以及流体动力学和拓扑克莱尼场理论中图灵普适性等现代概念。

**Conclusion:** 论文最后讨论了可计算动力系统领域的一些重要开放问题。

> **ai_Abstract:** 这篇综述论文探讨了可计算动力系统中的普适性概念。它回顾了近期通过动力系统表示可计算性的研究，这些研究受到对动力学计算方面（特别是陶哲轩关于纳维-斯托克斯方程的工作）重新燃起的兴趣的推动。论文涵盖了经典动力学普适性以及流体动力学和拓扑克莱尼场理论中图灵普适性等现代概念，这些概念利用动力学边界来表示可计算函数。最后，论文强调了该领域的关键开放问题。

> **摘要翻译:** 计算模型与动力学之间的关系自计算概念的早期形成以来就一直吸引着数学家和计算机科学家。最近，这种联系重新获得了关注，这得益于陶哲轩旨在利用嵌入式计算模型发现纳维-斯托克斯方程爆破解的计划。在这篇综述论文中，我们回顾了一些近期引入新颖而激动人心的视角来通过动力系统表示可计算性的工作。从经典意义上的动力学普适性开始，我们将探讨流体动力学和拓扑克莱尼场理论中图灵普适性的现代概念，作为通过动力学边界表示可计算函数的一种系统方法。最后，我们将讨论该领域的一些重要开放问题。

</details>

[⬆️ 返回分类顶部](#mathds) | [⬆️ 返回总目录](#toc)

---

<a id='cslo'></a>
## cs.LO 

### [338] [Execution and monitoring of HOA automata with HOAX](https://arxiv.org/abs/2507.11126)
> *使用 HOAX 执行和监控 HOA 自动机*

*Luca Di Stefano* | **Category: cs.LO, cs.FL** | **Updated: 2025-07-15**

**Keywords:** ω-自动机, HOA格式, 运行时监控, 陷阱集, 丑陋前缀

**Comment:** To appear in RV'25

> **TL;DR:** Hoax是一个用于执行和监控HOA格式的ω-自动机的工具，它利用陷阱集进行运行时监控，并能识别无法得出结论的“丑陋前缀”。

**AI_Comments:** Hoax的创新之处在于其利用陷阱集进行运行时监控，并能识别“丑陋前缀”以处理不可监控的自动机，这扩展了ω-自动机在实际系统监控中的应用范围。作为一个开源且可配置的工具，它为相关领域的研究和开发提供了便利。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法可能无法有效执行和运行时监控HOA格式的ω-自动机，尤其是在面对非可监控条件时。

**Method:** 提出名为Hoax的工具，用于执行HOA格式的ω-自动机。该工具利用陷阱集实现对任何（非奇偶校验）接受条件的运行时监控。对于不可监控的自动机，Hoax能够识别“丑陋前缀”，并判断后续观察将无法得出结论。论文还介绍了其形式化基础、设计，并与轨迹分析器PyContract在锁获取场景下进行了比较。

**Result:** Hoax工具能够有效执行和监控HOA格式的ω-自动机，并在与PyContract的比较中展示了其能力，尤其是在锁获取场景下。它能识别“丑陋前缀”以处理不可监控的情况。

**Conclusion:** Hoax是一个开源且高度可配置的工具，能够有效地执行和监控HOA格式的ω-自动机，并通过陷阱集和丑陋前缀识别提高了运行时监控的能力。

> **ai_Abstract:** Hoax是一个开源且高度可配置的工具，专为执行和运行时监控HOA格式的ω-自动机而设计。它利用陷阱集实现对多种接受条件的监控，并能识别“丑陋前缀”以处理不可监控的场景。论文详细阐述了其形式化基础、设计，并通过与PyContract在实际场景中的对比，验证了其有效性。

> **摘要翻译:** 我们提出了一个名为Hoax的工具，用于执行以流行的HOA格式表示的{\omega}-自动机。该工具利用陷阱集的概念，实现了对该格式支持的任何（非奇偶校验）接受条件的运行时监控。当自动机不可监控时，该工具仍然能够识别所谓的“丑陋前缀”，并确定后续的观察将永远无法得出确凿的结论。该工具是开源且高度可配置的。我们介绍了它的形式化基础、设计，并在一个锁获取场景下将其与轨迹分析器PyContract进行了比较。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

<a id='mathnt'></a>
## math.NT 

### [360] [Solving Modular Linear Systems with a Constraint by parallel decomposition of the Smith form and extended Euclidean division modulo powers of primes divisors](https://arxiv.org/abs/2503.10158)
> *通过史密斯范式的并行分解和模素数幂的扩展欧几里得除法求解带约束的模线性系统*

*Virendra Sule* | **Category: math.NT, cs.DM, cs.DS, G.0; G.2.0; I.1.2** | **Updated: 2025-07-15**

**Keywords:** 模线性系统, 史密斯范式, 素数幂, 互素约束, 并行分解

**Comment:** 17 pages

> **TL;DR:** 本文通过并行分解史密斯范式和扩展欧几里得除法，解决了带约束的模线性系统，并将其推广到素数幂模的情况。

**AI_Comments:** 本文的创新点在于将求解模线性系统的方法推广到模数为素数幂的情况，并处理了一个新的互素约束条件。通过并行分解和史密斯范式，提高了计算效率，对于需要高效处理这类模线性系统的问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文探讨了一个在应用中出现的新问题：求解模线性系统 $Ax=b\rem n$，并附加一个约束条件，即线性函数 $\phi(x)=\la w,x\ra$ 的值与模 $n$ 互素。

**Method:** 该方法将系统分解为互素的模 $p^{r(p)}$（$n$ 的约数），并展示了这种分解如何简化史密斯范数的计算。它将计算离散对数的指标演算方法推广到模数为素数幂的情况。通过使用增广矩阵 $[A,-p^{r(p)}I]$ 的不变因子和史密斯范式，以及 $w$ 满足的模 $p$ 条件，有效解决了该问题。

**Result:** 论文展示了如何通过使用增广矩阵的不变因子和史密斯范式，以及 $w$ 满足的模 $p$ 条件，有效地解决带约束的模线性系统问题。

**Conclusion:** 本文成功地提出了一个有效解决带互素约束的模线性系统的方法，并将其推广到模数为素数幂的情况。

> **ai_Abstract:** 本文研究了求解带互素约束的模线性系统 $Ax=b\rem n$ 的新问题。为解决此问题，作者提出了一种分解方法，将系统分解为互素的素数幂模 $p^{r(p)}$。这种分解简化了史密斯范式的计算，并将现有的指标演算方法从素数模扩展到素数幂模。通过利用增广矩阵的不变因子和史密斯范式，以及特定的模条件，论文展示了如何高效地解决这类带约束的模线性系统。

> **摘要翻译:** 整数线性系统 $Ax=b$ 要求矩阵 $A$、$b$ 和解 $x$ 都在整数范围内，可以使用 $A$ 的不变因子（通过计算 $A$ 的史密斯标准型）来求解。本文探讨了一个在应用中出现的新问题，即在给定 $A,b \in \zz_n$ 的情况下，求解 $x \in \zz_n$ 的模线性系统 $Ax=b\rem n$，同时附加一个约束条件：对于某个解 $x$，线性函数 $\phi(x)=\la w,x\ra$ 的值与 $n$ 互素。在本文中，我们开发了将系统分解为互素模 $p^{r(p)}$（它们是 $n$ 的约数）的方法，并展示了这种分解如何简化史密斯范式的计算。这扩展了众所周知的计算离散对数的指标演算方法，该方法中线性系统被简化到的模数被假定为素数（用于在素数域上求解简化系统），推广到模数的因子是素数幂 $p^{r(p)}$ 的情况。本文展示了如何使用增广矩阵 $[A,-p^{r(p)}I]$ 的不变因子和史密斯范式，以及 $w$ 满足的模 $p$ 条件，有效地解决这个问题，其中 $p^{r(p)}$ 遍历 $n$ 的所有约数且 $p$ 是素数。

</details>

[⬆️ 返回分类顶部](#mathnt) | [⬆️ 返回总目录](#toc)

---

<a id='q-fintr'></a>
## q-fin.TR 

### [378] [Kernel Learning for Mean-Variance Trading Strategies](https://arxiv.org/abs/2507.10701)
> *核学习在均值-方差交易策略中的应用*

*Owen Futter, Nicola Muca Cirone, Blanka Horvath* | **Category: q-fin.TR, cs.LG, q-fin.MF, q-fin.PM** | **Updated: 2025-07-14**

**Keywords:** 核学习, 均值-方差优化, 交易策略, 再生核希尔伯特空间, 时间依赖性

**Comment:** 49 pages

> **TL;DR:** 本文提出了一种基于核的框架，用于构建动态、路径依赖的均值-方差交易策略，该方法在处理具有时间依赖性的资产数据时，表现优于传统的马尔可夫方法，并提供封闭形式解。

**AI_Comments:** 创新性: 该研究的创新点在于将核学习引入均值-方差优化框架，用于构建路径依赖的交易策略，并提供了非马尔可夫的解决方案，这与传统方法形成对比。
重要性: 强调了在金融时间序列中处理时间依赖性的重要性，并提供了一种高性能的替代方案。保留封闭形式解的特性在实际应用中具有重要价值，因为它避免了复杂的梯度优化过程。
局限性: 抽象中未提及具体的计算复杂度或在大规模数据集上的表现，也未详细说明不同核函数选择对结果的影响。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发一种更灵活、非马尔可夫的动态、路径依赖交易策略，以应对资产动态或预测信号中存在时间依赖性的情况，并改进传统的均值-方差优化方法。

**Method:** 开发了一个基于核的框架，用于构建动态、路径依赖的均值-方差优化交易策略。将交易策略参数化为再生核希尔伯特空间（RKHS）中的函数，实现了灵活的非马尔可夫方法。与基于签名的框架进行比较。核方法提供了显著的建模灵活性，特征嵌入的选择范围从随机签名到神经网络的最终层。该框架保留了封闭形式解，并提供了梯度优化之外的替代方案。

**Result:** 与基于签名的框架以及经典的马尔可夫方法相比，该核框架在资产动态或预测信号表现出时间依赖性时，在合成数据和市场数据示例中都显著优于经典的马尔可夫方法。提供了显著的建模灵活性。保留了封闭形式解。

**Conclusion:** 本文提出的基于核的均值-方差交易策略框架，在处理具有时间依赖性的数据时表现出色，并提供了建模灵活性、封闭形式解以及梯度优化之外的替代方案，是优化投资组合问题的一种有效且非马尔可夫的方法。

> **ai_Abstract:** 本文提出了一种基于核的均值-方差优化框架，用于构建动态、路径依赖的交易策略。该框架将策略参数化为再生核希尔伯特空间中的函数，实现了一种灵活的非马尔可夫方法。实验结果表明，在资产动态或预测信号存在时间依赖性时，该方法在合成数据和市场数据上均显著优于传统的马尔可夫方法。此外，该核方法提供了高度的建模灵活性，支持多种特征嵌入方式，并能保留封闭形式解，为梯度优化提供了一种替代方案。

> **摘要翻译:** 在本文中，我们开发了一个基于核的框架，用于在均值-方差优化准则下构建动态的、路径依赖的交易策略。基于 (Muca Cirone and Salvi, 2025) 的理论结果，我们将交易策略参数化为再生核希尔伯特空间 (RKHS) 中的函数，从而为最优投资组合问题提供了一种灵活且非马尔可夫的方法。我们将其与 (Futter, Horvath, Wiese, 2023) 的基于签名的框架进行比较，并证明当资产动态或预测信号在合成数据和市场数据示例中都表现出时间依赖性时，这两种方法都显著优于经典的马尔可夫方法。在这种情况下使用核提供了显著的建模灵活性，因为特征嵌入的选择范围可以从随机签名到神经网络架构的最终层。至关重要的是，我们的框架保留了封闭形式解，并提供了梯度优化之外的替代方案。

</details>

[⬆️ 返回分类顶部](#q-fintr) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [422] [Optimal Debiased Inference on Privatized Data via Indirect Estimation and Parametric Bootstrap](https://arxiv.org/abs/2507.10746)
> *通过间接估计和参数自举对私有化数据进行最优去偏推理*

*Zhanyu Wang, Arin Chang, Jordan Awan* | **Category: stat.ME, cs.CR** | **Updated: 2025-07-14**

**Keywords:** 差分隐私, 参数自举, 间接推断, 去偏推断, 截断效应

**Comment:** double-spaced. 30pages before references and appendix. 59 pages total

> **TL;DR:** 提出了一个去偏参数自举框架，通过间接估计解决了私有化数据上现有方法因忽略截断效应导致推断不准确的问题，并实现了渐近最优方差。

**AI_Comments:** 这篇论文通过引入间接推断和自适应模拟方法，巧妙地解决了差分隐私数据中因“截断”效应导致的参数估计不一致和推断偏差问题。其创新之处在于将间接估计与参数自举相结合，并从理论上证明了其渐近最优性，这对于在隐私保护下进行可靠的统计推断具有重要意义。该方法提高了私有化数据分析的准确性和可靠性，填补了现有方法在处理截断效应方面的空白。

<details>
  <summary>Details</summary>

**Motivation:** 现有在私有化数据上使用参数自举的方法忽略或避免处理“截断”效应，导致置信区间覆盖不足和假设检验的I型错误校准不当。主要原因是基于私有化数据的参数估计量不一致。

**Method:** 提出使用间接推断方法来一致地估计参数值，并用改进的估计量进行参数自举推断。为了实现间接估计量，提出了一种新颖的基于模拟的自适应方法，并建立了相应的参数自举估计、置信区间和假设检验的一致性理论。证明了所提出的自适应间接估计量在所有基于已发布汇总统计量的“良好”一致估计量中实现了最小渐近方差。

**Result:** 模拟研究表明，该框架生成的置信区间具有良好校准的覆盖率，假设检验具有正确的I型错误，并在位置-尺度正态分布、简单线性回归和逻辑回归的推断中提供了最先进的性能。

**Conclusion:** 通过引入间接估计和自适应方法，本研究成功解决了私有化数据推断中由截断效应引起的偏差问题，实现了渐近最优的去偏推断，提高了统计推断的准确性。

> **ai_Abstract:** 本文提出了一个去偏参数自举框架，用于对差分隐私数据进行统计推断。针对现有方法忽略隐私机制中“截断”效应导致推断不准确的问题，作者引入了间接推断方法以实现参数的一致估计，并将其应用于参数自举。研究提出了一种新颖的自适应模拟方法来实现间接估计量，并从理论上证明了其估计、置信区间和假设检验的一致性及渐近最优方差。模拟结果表明，该框架在多种模型上实现了准确的置信区间覆盖和I型错误率，达到了最先进的性能。

> **摘要翻译:** 我们设计了一个去偏参数自举框架，用于差分隐私数据的统计推断。现有在私有化数据上使用参数自举的方法忽略或避免处理截断效应，而截断是大多数隐私机制采用的技术。忽略截断的影响通常会导致置信区间覆盖不足和假设检验的I型错误校准不当。现有方法失败的主要原因是基于私有化数据的参数估计量不一致。我们建议使用间接推断方法来一致地估计参数值，并在参数自举中使用改进的估计量进行推断。为了实现间接估计量，我们提出了一种新颖的、基于模拟的自适应方法，并建立了相应参数自举估计、置信区间和假设检验一致性的理论。特别是，我们证明了我们的自适应间接估计量在所有基于已发布汇总统计量的“良好”一致估计量中实现了最小渐近方差。我们的模拟研究表明，我们的框架产生了具有良好校准覆盖率的置信区间，并执行了具有正确I型错误的假设检验，在位置-尺度正态分布、简单线性回归和逻辑回归的推断中提供了最先进的性能。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='physicsapp-ph'></a>
## physics.app-ph 

### [456] [Real-time, Adaptive Radiological Anomaly Detection and Isotope Identification Using Non-negative Matrix Factorization](https://arxiv.org/abs/2507.10715)
> *基于非负矩阵分解的实时自适应辐射异常检测与同位素识别*

*Chandler Jones, Mark Bandstra, Stefan Faaland, Yue Shi Lai, Nico Abgrall, Scott Suchyta, Reynold Cooper* | **Category: physics.app-ph, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 非负矩阵分解, 辐射异常检测, 同位素识别, 实时自适应, 移动探测器

**Comment:** 11 pages, 8 figures

> **TL;DR:** 本文开发了一种新型的自适应非负矩阵分解（NMF）算法，用于实时更新背景模型，以应对移动探测器系统中不断变化的伽马射线背景，从而在辐射异常检测和同位素识别方面实现更好的通用性和性能。

**AI_Comments:** 该论文的创新点在于提出了一个能够实时自适应更新背景模型的NMF算法，解决了移动探测器系统中背景环境动态变化的挑战。这对于核不扩散等对实时性和准确性要求极高的应用具有重要意义。通过减少对环境的假设，该算法的通用性得到显著提升，有望在更广泛的实际场景中应用。

<details>
  <summary>Details</summary>

**Motivation:** 在核不扩散应用中，光谱异常检测和同位素识别至关重要，尤其是在移动探测器系统中。由于伽马射线背景变化大，预训练的背景模型容易失效，导致现有算法误报率过高或牺牲检测灵敏度。传统的非负矩阵分解（NMF）算法无法实时更新背景模型以适应环境变化。

**Method:** 开发了一种新型的基于非负矩阵分解（NMF）的算法，该算法会周期性地更新其背景模型以适应不断变化的环境条件。这种“自适应NMF”算法对环境的假设更少。

**Result:** 该算法比现有基于NMF的方法更具通用性，并且在模拟和真实世界数据集上保持或超越了检测性能。

**Conclusion:** 通过周期性更新背景模型，所开发的自适应NMF算法有效解决了移动探测器系统中辐射异常检测和同位素识别的挑战，提高了算法的鲁棒性和性能。

> **ai_Abstract:** 本文提出了一种新颖的自适应非负矩阵分解（NMF）算法，旨在解决移动探测器系统中辐射异常检测和同位素识别的挑战。针对传统NMF算法无法实时适应不断变化的伽马射线背景的问题，该算法通过周期性更新其背景模型，减少了对环境的假设，从而提高了通用性。实验结果表明，该方法在保持或超越现有NMF方法检测性能的同时，在模拟和真实世界数据集中表现出更强的适应性。

> **摘要翻译:** 光谱异常检测和同位素识别算法是核不扩散应用（如搜寻行动）中不可或缺的组成部分。对于移动探测器系统来说，这项任务尤其具有挑战性，因为观察到的伽马射线背景比静态探测器系统变化更大，并且预训练的背景模型很容易超出其适用范围。结果是，算法可能会超过其预期的虚警率，或者为了维持所需的虚警率而牺牲检测灵敏度。非负矩阵分解（NMF）已被证明是光谱异常检测和识别的强大工具，但与许多依赖数据驱动背景模型的类似算法一样，在其传统实现中，它无法实时更新以解释影响背景光谱特征的环境变化。我们开发了一种新型的基于NMF的算法，该算法周期性地更新其背景模型以适应不断变化的环境条件。自适应NMF算法对其环境的假设更少，使其比现有基于NMF的方法更具通用性，同时在模拟和真实世界数据集上保持或超越了检测性能。

</details>

[⬆️ 返回分类顶部](#physicsapp-ph) | [⬆️ 返回总目录](#toc)

---

<a id='statap'></a>
## stat.AP 

### [523] [Bayesian Parameter Inference and Uncertainty Quantification for a Computational Pulmonary Hemodynamics Model Using Gaussian Processes](https://arxiv.org/abs/2502.14251)
> *使用高斯过程对计算肺血流动力学模型进行贝叶斯参数推断和不确定性量化*

*Amirreza Kachabi, Sofia Altieri Correa, Naomi C. Chesler, Mitchel J. Colebank* | **Category: stat.AP, cs.CE, physics.bio-ph** | **Updated: 2025-07-14**

**Keywords:** 肺血流动力学, 贝叶斯推断, 不确定性量化, 高斯过程, 慢性血栓栓塞性肺动脉高压

**Comment:** 

> **TL;DR:** 本研究利用高斯过程加速贝叶斯参数推断，为计算肺血流动力学模型提供快速、不确定性量化的方法，以评估慢性血栓栓塞性肺动脉高压中的微血管功能障碍。

**AI_Comments:** 该论文的创新之处在于将高斯过程（GP）模拟器引入到肺血流动力学模型的参数推断中，显著提高了计算效率，使其在临床上可行。通过量化不确定性，模型结果更具鲁棒性，为个性化治疗提供了更可靠的指导。独立建模每个肺部也有效地捕捉了疾病的异质性。

<details>
  <summary>Details</summary>

**Motivation:** 当前临床诊断方法在心血管研究中存在局限性，且可用的临床数据有限，需要将不确定性纳入模型以改进个性化治疗指导。此外，为了临床相关性，此类建模必须具有计算效率。

**Method:** 本研究使用了一个一维（1D）流体动力学模型，该模型通过慢性血栓栓塞性肺动脉高压（CTEPH）犬模型的实验数据进行校准，并纳入了基线和CTEPH条件下多受试者的测量数据。为了解释CTEPH的异质性，每个肺都独立建模，以探索肺特异性微血管狭窄和阻力。为加速模型校准，采用了高斯过程（GP）模拟器。

**Result:** 结果表明，CTEPH导致异质性微血管适应，反映在不同的参数变化中。模型参数的变化与疾病严重程度密切相关，特别是在先前报告疾病更严重的肺部。

**Conclusion:** 该框架提供了一种快速、不确定性感知的方法，用于评估CTEPH中的微血管功能障碍，并可能在适合临床应用的时间范围内支持更具针对性的治疗策略。

> **ai_Abstract:** 本研究提出了一种利用高斯过程（GP）加速贝叶斯参数推断和不确定性量化的方法，用于计算肺血流动力学模型。该方法基于一维流体动力学模型，并结合了慢性血栓栓塞性肺动脉高压（CTEPH）犬模型的实验数据。通过独立建模每个肺部，研究人员能够探索肺特异性微血管狭窄和阻力，并发现CTEPH导致异质性微血管适应，其模型参数变化与疾病严重程度显著相关。该框架提供了一种快速、不确定性感知的方法来评估CTEPH中的微血管功能障碍，有望支持更具针对性的临床治疗策略。

> **摘要翻译:** 针对个体患者的建模是心血管研究中一个强大的工具，它能够提供当前临床诊断无法企及的深入见解。可用临床数据的局限性要求将不确定性纳入模型，以改进个性化治疗的指导。然而，为了临床相关性，此类建模必须具有计算效率。在本研究中，我们使用了一个一维（1D）流体动力学模型，该模型通过慢性血栓栓塞性肺动脉高压（CTEPH）犬模型的实验数据进行校准，并纳入了基线和CTEPH条件下多受试者的测量数据。手术干预可以缓解CTEPH，但患有微血管疾病（例如小血管重塑和狭窄）的患者通常表现出持续性肺动脉高压，这凸显了评估微血管疾病严重程度的重要性。因此，为了解释CTEPH的异质性，每个肺都独立建模，使我们能够探索肺特异性微血管狭窄和阻力。我们比较了基线和CTEPH之间推断的参数，并检查了它们与疾病严重程度临床标志物的相关性。为了加速模型校准，我们采用了高斯过程（GP）模拟器，从而能够在临床可行的时间范围内估计微血管参数及其不确定性。我们的结果表明，CTEPH导致异质性微血管适应，反映在不同的参数变化中。值得注意的是，模型参数的变化与疾病严重程度密切相关，特别是在先前报告疾病更严重的肺部。该框架提供了一种快速、不确定性感知的方法，用于评估CTEPH中的微血管功能障碍，并可能在适合临床应用的时间范围内支持更具针对性的治疗策略。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

<a id='physicsgeo-ph'></a>
## physics.geo-ph 

### [532] [HEIMDALL: a grapH-based sEIsMic Detector And Locator for microseismicity](https://arxiv.org/abs/2507.10850)
> *HEIMDALL：一种基于图的微震地震检测器和定位器*

*Matteo Bagagli, Francesco Grigoli, Davide Bacciu* | **Category: physics.geo-ph, cs.LG** | **Updated: 2025-07-14**

**Keywords:** 微震, 图神经网络, 深度学习, 地热系统, 地震监测

**Comment:** 

> **TL;DR:** HEIMDALL是一种新的基于图神经网络的深度学习模型，用于微震监测，可同时进行震相拾取、关联和事件定位，显著提高了事件检测率并减少了人工干预。

**AI_Comments:** HEIMDALL的创新之处在于将图理论和图神经网络应用于微震监测的端到端流程，实现了震相拾取、关联和定位的同时进行。这不仅提高了检测效率和准确性，还大大减少了对人工干预和模型调优的需求，对于地热能源开发中的风险管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在全球向绿色能源转型的背景下，增强型地热系统日益受到关注，这需要一个鲁棒的微震监测工具来支持其开发和降低运营风险。

**Method:** 该研究提出了一种新的深度学习模型HEIMDALL，利用地震台站记录之间的连续时空关系，形成端到端的地震目录创建流程。它采用图理论和先进的图神经网络架构，在滚动窗口上同时执行震相拾取、关联和事件定位。

**Result:** 与现有自动系统和参考目录相比，HEIMDALL显著增加了事件检测，包括2018年12月的4级地震序列和2019年2月的单日序列。该方法减少了虚假事件，最大限度地减少了人工监督，并降低了对管道进行广泛调整或深度学习模型进行迁移学习的需求。

**Conclusion:** HEIMDALL验证了一种针对地热地震区域的强大监测工具，能够补充现有系统并增强地热能开采期间的运营风险缓解。

> **ai_Abstract:** HEIMDALL是一种新型的基于图神经网络的深度学习模型，专为微震监测设计。该模型利用地震台站记录的时空关系，实现了从震相拾取到事件定位的端到端自动化流程。通过在冰岛地热区的测试，HEIMDALL显著提高了事件检测率，减少了误报和人工干预，证明了其作为地热地震区域鲁棒监测工具的有效性，有助于降低运营风险。

> **摘要翻译:** 在这项工作中，我们提出了一种新的深度学习模型，用于微震监测，该模型利用地震台站记录之间连续的时空关系，形成一个端到端的地震目录创建流程。它采用图论和最先进的图神经网络架构，在滚动窗口上同时执行震相拾取、关联和事件定位，使其适用于回放和近实时监测。作为绿色能源转型背景下减少碳排放全球战略的一部分，人们对开发增强型地热系统越来越感兴趣。我们的模型在冰岛Hengill地区复杂的火山地热区进行了测试，使用了来自临时实验的开放获取数据，并使用手动修订和自动地震目录进行了训练和验证。结果显示，与之前发布的自动系统和参考目录相比，事件检测显着增加，包括2018年12月的一次4级地震序列和2019年2月的一次单日序列。我们的方法减少了虚假事件，最大限度地减少了人工监督，并减少了对管道进行广泛调整或深度学习模型进行迁移学习的需求。总的来说，它验证了一种用于地热地震区域的强大监测工具，补充了现有系统并增强了地热能开采期间的运营风险缓解。

</details>

[⬆️ 返回分类顶部](#physicsgeo-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathap'></a>
## math.AP 

### [553] [Effects of rough boundary and nonzero boundary conditions on the lubrication process with micropolar fluid](https://arxiv.org/abs/2507.11318)
> *粗糙边界和非零边界条件对微极流体润滑过程的影响*

*Matthieu Bonnivard, Igor Pazanin, Francisco Suarez-Grau* | **Category: math.AP, cs.NA, math.NA, 35B27** | **Updated: 2025-07-15**

**Keywords:** 微极流体, 粗糙边界, 非零边界条件, 润滑, 滑动轴承

**Comment:** 

> **TL;DR:** 本研究探讨了粗糙边界和非零边界条件对微极流体润滑过程的影响，通过渐近分析和数值模拟发现粗糙表面可以提高线性滑动轴承的机械性能。

**AI_Comments:** 该研究的创新之处在于结合了微极流体模型、粗糙边界和非零边界条件，这比传统的零边界条件更符合物理实际。通过渐近分析推导简化模型，并结合数值模拟验证其效应，为理解和优化润滑过程提供了新的视角。研究结果对提高润滑设备的机械性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 受摩擦学文献中实验发现的启发，本研究将润滑剂视为微极流体，并研究其在粗糙边界薄域中的行为。与常用的简单零边界条件不同，本文施加了物理相关的非零微旋转边界条件。

**Method:** 对相应的3D边值问题进行了渐近分析，形式化推导了一个简化数学模型，该模型考虑了粗糙度引起的效应和非零边界条件对宏观流动的影响。利用获得的渐近模型，数值研究了特定粗糙度剖面对线性滑动轴承性能的影响。

**Result:** 数值结果清楚地表明，使用粗糙表面可能有助于提高此类设备的机械性能。

**Conclusion:** 结合微极流体、粗糙边界和非零边界条件，可以增强润滑过程中的机械性能。

> **ai_Abstract:** 本研究基于摩擦学实验发现，探讨了微极流体在粗糙边界和非零微旋转边界条件下的润滑行为。通过对3D边值问题进行渐近分析，推导了一个考虑粗糙度和非零边界条件影响的简化数学模型。随后，利用该模型数值模拟了粗糙度剖面对线性滑动轴承性能的影响，结果表明粗糙表面有助于提升设备的机械性能。

> **摘要翻译:** 润滑理论主要关注润滑剂流过狭窄间隙的行为。受摩擦学文献中实验发现的启发，我们以微极流体作为润滑剂，研究其在粗糙边界薄域中的行为。本文没有考虑（常用的）简单零边界条件，而是施加了物理相关的（非零）微旋转边界条件，并对相应的3D边值问题进行了渐近分析。我们形式化推导了一个简化的数学模型，该模型考虑了粗糙度引起的效应和非零边界条件对宏观流动的影响。利用获得的渐近模型，我们数值研究了特定粗糙度剖面对线性滑动轴承性能的影响。数值结果清楚地表明，使用粗糙表面可能有助于提高此类设备的机械性能。

</details>

[⬆️ 返回分类顶部](#mathap) | [⬆️ 返回总目录](#toc)

---

### [596] [The Evolution of Pointwise Statistics in Hyperbolic Equations with Random Data](https://arxiv.org/abs/2507.11399)
> *随机数据双曲方程中点态统计量的演化*

*Alina Chertock, Pierre Degond, Amir Sagiv, Li Wang* | **Category: math.AP, cs.NA, math.NA** | **Updated: 2025-07-15**

**Keywords:** 双曲方程, 点态统计量, 随机数据, 概率密度函数, 蒙特卡洛方法

**Comment:** 

> **TL;DR:** 本文研究了随机初始数据下双曲偏微分方程（线性和非线性）解的点态统计量演化，并推导了其概率密度函数（PDF）和累积分布函数（CDF）的线性偏微分方程，适用于无激波形成的情况，并对多点统计量进行了拓展，提高了随机动力学评估效率。

**AI_Comments:** 本文的主要创新在于为随机数据双曲方程（包括线性和非线性）推导了点态和多点统计量的演化方程。这些方程提供了一种高效且成本与随机参数维度无关的方法来分析随机动力学，避免了传统的蒙特卡洛模拟对大量样本的需求。其局限性在于结果仅在激波形成前有效，这是双曲方程固有的挑战。这项工作对于随机PDE的数值分析和不确定性量化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究随机初始数据下双曲偏微分方程解的随机动力学，并寻求一种更高效的方法来评估这些随机动力学，避免对底层PDE进行大量解的集合模拟，同时提供蒙特卡洛方法的误差界限。

**Method:** 对于线性双曲方程，发现其PDF满足相同的线性PDE。对于非线性双曲方程，推导了CDF的线性输运方程和PDF的非局部线性PDE。对于线性双曲方程组，引入并推导了多点统计量的演化方程。所有这些结果在无激波形成的前提下有效。

**Result:** 线性双曲方程的PDF满足相同的线性PDE；非线性双曲方程的CDF满足线性输运方程；非线性双曲方程的PDF满足非局部线性PDE。推导了线性双曲方程组的多点统计量演化方程。所有导出的统计量PDE都具有实用意义：它们能够高效评估随机动力学，无需底层PDE的解集合，且成本不受随机参数空间维度的影响。这些演化方程为蒙特卡洛方法（特别是核密度估计器）应用于随机数据双曲PDE提供了先验统计误差界限。

**Conclusion:** 本文成功推导了随机数据双曲方程（线性和非线性）中点态统计量和多点统计量的演化方程，这些方程在无激波形成的前提下有效，并显著提高了随机动力学评估的效率，同时为蒙特卡洛方法提供了误差界限。

> **ai_Abstract:** 本文研究了随机初始数据下，一维线性和非线性双曲偏微分方程解的“点态统计量”演化。研究发现，线性双曲方程的概率密度函数（PDF）满足相同的线性偏微分方程；对于非线性双曲方程，则推导了累积分布函数（CDF）的线性输运方程和PDF的非局部线性偏微分方程，这些结果在激波形成前有效。此外，论文还为线性双曲方程组引入并推导了多点统计量的演化方程。这些推导出的统计量偏微分方程具有重要的实际意义，因为它们能高效评估随机动力学，无需大量底层PDE解的集合模拟，且成本与随机参数空间维度无关，同时为蒙特卡洛方法提供了统计误差界限。

> **摘要翻译:** 我们考虑具有随机初始数据的一维双曲偏微分方程，包括线性和非线性情况。我们的重点是“点态统计量”，即在任意固定空间和时间点处解的概率测度。对于线性双曲方程，这些统计量的概率密度函数（PDF）满足相同的线性偏微分方程。对于非线性双曲偏微分方程，我们推导了累积分布函数（CDF）的线性输运方程和PDF的非局部线性偏微分方程。这两个结果仅在没有激波形成的情况下有效，这是问题固有的限制，一个反例证明了这一点。对于线性双曲方程组，我们引入了多点统计量并推导了它们的演化方程。在我们考虑的所有设置中，得到的统计量偏微分方程都具有实际意义：它们能够高效评估随机动力学，无需底层偏微分方程的解集合，并且它们的成本不受随机参数空间维度的影响。此外，统计量的演化方程为蒙特卡洛方法（特别是核密度估计器）应用于随机数据双曲偏微分方程时提供了先验统计误差界限。

</details>

[⬆️ 返回分类顶部](#mathap) | [⬆️ 返回总目录](#toc)

---

<a id='physicschem-ph'></a>
## physics.chem-ph 

### [574] [BioScore: A Foundational Scoring Function For Diverse Biomolecular Complexes](https://arxiv.org/abs/2507.10877)
> *BioScore：一种用于多样化生物分子复合物的基础评分函数*

*Yuchen Zhu, Jihong Chen, Yitong Li, Xiaomin Fang, Xianbin Ye, Jingzhou He, Xujun Zhang, Jingxuan Ge, Chao Shen, Xiaonan Zhang, Tingjun Hou, Chang-Yu Hsieh* | **Category: physics.chem-ph, cs.LG, physics.bio-ph** | **Updated: 2025-07-15**

**Keywords:** 生物分子复合物, 评分函数, 结构评估, 几何图学习, 亲和力预测

**Comment:** 

> **TL;DR:** BioScore是一种新的基础评分函数，通过双尺度几何图学习框架解决了现有评分函数在生物分子复合物结构评估中缺乏通用性的问题，并在多种基准测试中表现优异。

**AI_Comments:** BioScore的创新之处在于其双尺度几何图学习框架，能够有效解决生物分子复合物结构评估中数据稀疏性、跨系统表示和任务兼容性等核心挑战。其在多样化生物分子系统上的出色泛化能力和对复杂化学系统的处理能力，使其在药物发现和生物学理解方面具有重要应用潜力。该研究通过引入新的PPI基准，也促进了蛋白质-蛋白质复合物评分领域的全面评估。

<details>
  <summary>Details</summary>

**Motivation:** 当前的结构化评分函数在多样化的生物分子系统中的通用性不足，难以将分子模型转化为功能性见解，从而阻碍了对生物学的理解和药物发现。

**Method:** BioScore采用双尺度几何图学习框架，并结合了为结构评估和亲和力预测量身定制的模块，以解决数据稀疏性、跨系统表示和任务兼容性等关键挑战。

**Result:** BioScore在涵盖蛋白质、核酸、小分子和碳水化合物的16个基准测试中，持续优于或匹配70种传统和深度学习方法。在预训练后，蛋白质-蛋白质亲和力预测提升高达40%，抗原-抗体结合相关性提升超过90%；跨系统泛化能力实现零样本和少样本预测，相关性增益高达71%；统一表示捕获环肽等挑战性系统，亲和力预测提高超过60%。

**Conclusion:** BioScore为复杂生物分子景观中的结构评估建立了一个鲁棒且通用的框架。

> **ai_Abstract:** BioScore是一种新颖的基础评分函数，旨在解决现有方法在生物分子复合物结构评估中缺乏通用性的问题。它采用双尺度几何图学习框架，并包含专门用于结构评估和亲和力预测的模块。该函数在蛋白质、核酸、小分子和碳水化合物等多种生物分子系统上进行了广泛评估，并在16个基准测试中表现出超越或媲美70种现有方法的性能。BioScore展示了在提高亲和力预测、实现跨系统泛化以及处理复杂化学系统方面的显著能力，为生物分子结构评估提供了一个通用且强大的框架。

> **摘要翻译:** 生物分子复合物的结构评估对于将分子模型转化为功能性见解至关重要，它塑造了我们对生物学的理解并有助于药物发现。然而，当前的基于结构的评分函数往往缺乏跨多样化生物分子系统的通用性。我们提出了BioScore，一种基础评分函数，通过一个双尺度几何图学习框架以及为结构评估和亲和力预测量身定制的模块，解决了关键挑战——数据稀疏性、跨系统表示和任务兼容性。BioScore支持广泛的任务，包括亲和力预测、构象排序和基于结构的虚拟筛选。在涵盖蛋白质、核酸、小分子和碳水化合物的16个基准测试中进行评估，BioScore持续优于或匹配70种传统和深度学习方法。我们新提出的PPI基准进一步实现了蛋白质-蛋白质复合物评分的全面评估。BioScore展示了广泛的适用性：（1）在混合结构数据上进行预训练，将蛋白质-蛋白质亲和力预测提升高达40%，抗原-抗体结合相关性提升超过90%；（2）跨系统通用性实现了零样本和少样本预测，相关性增益高达71%；（3）其统一表示捕获了环肽等化学挑战性系统，将亲和力预测提高了60%以上。BioScore为复杂生物分子景观中的结构评估建立了一个鲁棒且通用的框架。

</details>

[⬆️ 返回分类顶部](#physicschem-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matsoft'></a>
## cond-mat.soft 

### [577] [A unifying approach to self-organizing systems interacting via conservation laws](https://arxiv.org/abs/2507.02575)
> *通过守恒定律相互作用的自组织系统的统一方法*

*Frank Barrows, Guanming Zhang, Satyam Anand, Zixi Chen, Jonathan Lin, Aman Desai, Stefano Martiniani, Francesco Caravelli* | **Category: cond-mat.soft, cond-mat.stat-mech, cs.MA, nlin.AO** | **Updated: 2025-07-15**

**Keywords:** 自组织, 动力系统, 守恒定律, 投影算子, 网络系统

**Comment:** 14 pages double column + 13 pages supplementary

> **TL;DR:** 这篇论文提出了PrEDS，一个基于守恒定律的广义投影算子的统一框架，用于分析和设计各种自组织系统，展示了它能够复制和恢复动力学并近似集体行为。

**AI_Comments:** 这篇论文通过提供一个统一的理论框架（PrEDS），用于分析跨物理、生物和工程领域的各种自组织系统，展现了显著的创新性。其优势在于将框架建立在基本的守恒定律和非平衡热力学之上，提供了一种严谨的数学方法。能够提升低维动力学并在平均场空间中近似集体行为，对于理解涌现特性尤其富有洞察力。在各种领域中的实际演示突出了其多功能性以及对设计复杂自适应系统的潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 为了提供一个统一的框架来嵌入和分析动力系统，特别是通过守恒定律相互作用的自组织系统，并为分析复杂的网络系统和设计自组织系统提供一个通用的理论基础。

**Method:** 本文提出了一个统一的框架，利用植根于局部守恒定律的广义投影算子。它将物理、生物和工程系统表示为具有关联矩阵和循环矩阵的图，推导出双重投影算子来分解网络通量和势能。该方法通过动力系统投影嵌入（PrEDS）扩展到集体动力学，将低维动力学提升到高维空间。

**Result:** 该框架符合非平衡热力学原理，能够捕捉一大类系统，并能复制和恢复原始动力学。当系统属于PrEDS类时，它们的集体行为可以通过投影到平均场空间中进行有效近似。PrEDS在电阻和忆阻电路、自适应流网络、弹性弦网络和粒子群等不同领域得到了验证。此外，建立了PrEDS与群集动力学之间的直接对应关系，揭示了优化和自组织的新见解。

**Conclusion:** 研究结果为分析复杂的网络系统和设计通过局部相互作用自组织的系统提供了通用的理论基础。

> **ai_Abstract:** 本文提出了一种统一的框架——动力系统投影嵌入（PrEDS），用于分析基于局部守恒定律和广义投影算子的自组织系统。通过将系统表示为图，PrEDS将低维动力学提升到高维空间，从而能够复制和恢复原始动力学，并在平均场空间中有效近似集体行为。该框架适用于电路、流网络和粒子群等多种系统，为理解和设计复杂的网络自组织系统提供了通用的理论基础。

> **摘要翻译:** 我们提出了一个统一的框架，用于嵌入和分析使用基于局部守恒定律的广义投影算子的动力系统。通过将物理、生物和工程系统表示为具有关联矩阵和循环矩阵的图，我们推导出双重投影算子来分解网络通量和势能。这种形式主义符合非平衡热力学原理，并捕捉了一大类由通量-力关系和局部约束控制的系统。我们将这种方法扩展到集体动力学，通过动力系统投影嵌入（PrEDS），它将低维动力学提升到高维空间，从而能够复制和恢复原始动力学。当系统属于 PrEDS 类时，它们的集体行为可以通过投影到平均场空间中进行有效近似。我们展示了 PrEDS 在不同领域的多功能性，包括电阻和忆阻电路、自适应流网络（例如粘菌）、弹性弦网络和粒子群。值得注意的是，我们建立了 PrEDS 与群集动力学之间的直接对应关系，揭示了优化和自组织的新见解。我们的结果为分析复杂的网络系统和设计通过局部相互作用自组织的系统提供了通用的理论基础。

</details>

[⬆️ 返回分类顶部](#cond-matsoft) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [616] [Towards Practical Benchmarking of Data Cleaning Techniques: On Generating Authentic Errors via Large Language Models](https://arxiv.org/abs/2507.10934)
> *迈向数据清洗技术实用基准测试：通过大型语言模型生成真实错误*

*Xinyuan Liu, Jiahui Chen, Bocheng Hu, Yu Sun, Xinyang Chen, Shaoxu Song* | **Category: cs.DB, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 数据清洗, 错误生成, 大型语言模型, 基准测试, TableEG

**Comment:** 

> **TL;DR:** 本文提出了TableEG框架，利用大型语言模型生成真实的表格数据错误，以解决缺乏多样化真实世界错误数据集的问题，并为数据清洗技术提供鲁棒的基准测试。

**AI_Comments:** 该论文的创新点在于利用大型语言模型生成高度真实的表格数据错误，从而克服了传统手动标注耗时且不一致的缺点，并解决了现有基准测试缺乏多样化真实错误数据集的痛点。TableEG框架通过结合表格微调和三元组表示，有效捕捉了表格数据的复杂依赖关系，使其生成的合成错误能够忠实反映真实错误分布。这对于数据清洗领域的研究和实践具有重要意义，因为它提供了一个可扩展且可靠的错误数据集生成方法，将极大推动错误检测和纠正算法的评估和发展。

<details>
  <summary>Details</summary>

**Motivation:** 数据驱动系统中的数据质量挑战，表格数据中的错误会严重损害下游分析和机器学习性能。尽管提出了许多错误检测算法，但缺乏多样化的真实世界错误数据集限制了全面评估。手动错误标注既耗时又不一致，因此探索合成错误生成作为替代方案。

**Method:** 本文引入了TableEG框架，该框架利用大型语言模型（LLMs）生成真实错误。通过采用表格微调策略和三元组表示(I, T, O)来建模错误生成、检测和纠正任务，TableEG捕获了二维表格中固有的复杂依赖关系。该模型在12个真实世界数据集上进行训练，涵盖10个不同领域。

**Result:** 实验结果表明，与基于规则的方法和未经微调的LLM生成错误相比，TableEG生成的错误表现出卓越的模式和分布相似性。此外，TableEG生成的错误在几乎所有数据集和检测算法上，特别是对于基于机器学习的检测技术，其性能指标与真实世界错误密切吻合。

**Conclusion:** TableEG不仅弥合了合成错误与真实世界错误之间的差距，而且为后续的错误检测和纠正任务建立了稳健的基准。

> **ai_Abstract:** 本文提出TableEG框架，利用大型语言模型（LLMs）生成真实的表格数据错误，以解决现有数据清洗技术评估中真实错误数据集不足的问题。TableEG通过表格微调策略和三元组表示，学习并模拟真实错误分布。实验证明，TableEG生成的错误在模式和分布上与真实错误高度相似，且其生成的错误数据集上的检测性能与真实数据表现一致，为数据清洗的基准测试提供了有效且可靠的解决方案。

> **摘要翻译:** 数据质量仍然是数据驱动系统中的一个重要挑战，因为表格数据中的错误会严重损害下游分析和机器学习性能。尽管提出了许多错误检测算法，但缺乏多样化、真实世界的错误数据集限制了全面评估。手动错误标注既耗时又不一致，这促使人们探索合成错误生成作为一种替代方案。在这项工作中，我们引入了TableEG，一个利用大型语言模型（LLMs）生成真实错误的框架。通过采用表格微调策略和三元组表示(I, T, O)来建模错误生成、检测和纠正任务，TableEG捕获了二维表格中固有的复杂依赖关系。TableEG在涵盖10个不同领域的12个真实世界数据集上进行训练，确保合成的错误忠实反映真实的错误分布。实验结果表明，与基于规则的方法和未经微调的LLM生成错误相比，TableEG生成的错误表现出卓越的模式和分布相似性。此外，TableEG生成的错误在几乎所有数据集和检测算法上，特别是对于基于机器学习的检测技术，其性能指标与真实世界错误密切吻合。总的来说，TableEG不仅弥合了合成错误与真实世界错误之间的差距，而且为后续的错误检测和纠正任务建立了稳健的基准。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [691] [SQLord: A Robust Enterprise Text-to-SQL Solution via Reverse Data Generation and Workflow Decomposition](https://arxiv.org/abs/2507.10629)
> *SQLord: 一种通过逆向数据生成和工作流分解实现的强大企业级Text-to-SQL解决方案*

*Song Cheng, Qiannan Cheng, Linbo Jin, Lei Yi, Guannan Zhang* | **Category: cs.DB, cs.AI, I.2.7** | **Updated: 2025-07-14**

**Keywords:** Text-to-SQL, NL2SQL, 数据逆向生成, 工作流分解, 企业级解决方案

**Comment:** WWW '25: Companion Proceedings of the ACM on Web Conference 2025
  Pages 919 - 923 https://doi.org/10.1145/3701716.3715541

> **TL;DR:** SQLord是一个企业级Text-to-SQL解决方案，通过逆向数据生成和工作流分解来处理复杂业务逻辑和数据稀缺问题，并在离线和在线测试中表现出色。

**AI_Comments:** SQLord的创新点在于其结合了数据逆向生成来解决企业级NL2SQL的领域数据稀缺问题，以及通过工作流分解处理复杂查询的策略。此外，其提出的GPT-Judge评估框架也为实际应用提供了更灵活和全面的评估手段。这篇论文解决了现有NL2SQL方案在真实企业环境中面临的关键挑战，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有NL2SQL框架在处理复杂业务逻辑时表现不佳，且缺乏领域特定数据进行微调，同时评估方法也面临缺乏标注数据和可执行数据库环境的挑战。

**Method:** SQLord采用数据逆向生成方法将原始SQL语句转换为标注数据进行监督微调；提出一种利用自动化工作流生成器分解复杂查询的方法；并引入了GPT-Judge评估框架，包括执行评估 (EXE)、查询-SQL评估 (QSE) 和 SQL-SQL评估 (SSE)。

**Result:** 离线测试显著优于现有基线，在线准确率持续超过90%，并已成功应用于全球最大的B2B电子商务平台上的多个场景。

**Conclusion:** SQLord在复杂真实世界场景中展现了其优势和有效性，解决了企业级NL2SQL面临的数据和评估挑战。

> **ai_Abstract:** SQLord是一个为解决企业级Text-to-SQL（NL2SQL）挑战而设计的框架。它通过创新的数据逆向生成方法解决领域数据稀缺问题，将原始SQL转换为标注数据进行模型微调。同时，它采用工作流分解技术处理复杂查询，并引入了全面的GPT-Judge评估框架，包括EXE、QSE和SSE，以适应多样化的评估需求。实验结果显示，SQLord在离线测试中显著优于现有基线，在线准确率稳定超过90%，并在全球最大的B2B电商平台成功应用，证明了其在复杂真实世界场景中的鲁棒性和有效性。

> **摘要翻译:** 将自然语言转换为SQL查询（NL2SQL）对于数据驱动的商业应用至关重要。现有框架在开源数据集上训练，难以处理复杂的业务逻辑，并且缺乏特定领域数据进行微调。此外，评估方法通常需要标注数据和可执行数据库环境，这在现实场景中非常稀缺。为了应对这些挑战，我们提出了SQLord，一个企业级NL2SQL框架。首先，SQLord引入了一种数据逆向生成方法，将原始SQL语句转换为标注数据，用于监督微调（SFT）。其次，它提出了一种使用自动化工作流生成器分解复杂查询的方法。此外，SQLord还具有一个全面的GPT-Judge评估框架，包括执行评估（EXE）、查询-SQL评估（QSE）和SQL-SQL评估（SSE），以适应不同的场景。离线测试显著优于最先进的基线，在线准确率持续超过90%，突显了SQLord在复杂真实世界场景中的优势和有效性。SQLord已成功应用于全球最大的B2B电子商务平台上的多个场景。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

<a id='mathca'></a>
## math.CA 

### [637] [The Marcinkiewicz-Zygmund Property for Riemann Differences with Geometric Nodes](https://arxiv.org/abs/2507.11463)
> *具有几何节点的黎曼差分的Marcinkiewicz-Zygmund性质*

*Hajrudin Fejzić* | **Category: math.CA, cs.NA, math.NA** | **Updated: 2025-07-15**

**Keywords:** Marcinkiewicz-Zygmund性质, 黎曼差分, 几何节点, 递归框架, 解析判据

**Comment:** 

> **TL;DR:** 本文研究了黎曼差分何时具有Marcinkiewicz-Zygmund (MZ) 性质，推翻了之前的猜想，并建立了一个完整的解析判据来表征所有具有MZ性质的几何节点黎曼差分。

**AI_Comments:** 本文的创新之处在于彻底推翻了之前关于MZ性质的黎曼差分是唯一存在的猜想，并通过提出一个通用的递归分析框架，提供了一个完整的解析判据。这一框架不仅解决了特定问题，还具有普适性，可应用于更广泛的广义差分类别，显示了其重要性和广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 研究黎曼差分何时具有Marcinkiewicz-Zygmund (MZ) 性质，尤其是在先前关于某些经典几何节点是唯一具有MZ性质的黎曼差分的猜想被推翻之后，需要提供进一步的反例和进行普遍分类。

**Method:** 通过开发一个递归框架，分析满足特定条件的函数R(h)何时能强制R(h) = o(h^n)，从而建立MZ性质的完整解析判据。具体来说，当A位于由q和n确定的临界模环之外时，该性质成立，涵盖了|q|>1和|q|<1两种情况。

**Result:** 建立了MZ性质的完整解析判据，并提供了进一步的反例，推翻了之前的猜想。结果表明，当且仅当A位于由q和n确定的临界模环之外时，MZ性质成立。这导致了对所有具有MZ性质的几何节点黎曼差分的完整表征。

**Conclusion:** 本文对具有几何节点的黎曼差分的Marcinkiewicz-Zygmund性质进行了完整表征，并通过提出的灵活分析框架，使得该方法可应用于更广泛的广义差分类别。

> **ai_Abstract:** 本文研究了黎曼差分的Marcinkiewicz-Zygmund (MZ) 性质。针对先前关于具有MZ性质的几何节点黎曼差分的猜想被推翻的情况，本文提供了新的反例，并通过开发递归框架，建立了一个完整的解析判据。研究发现，MZ性质成立当且仅当特定参数A位于由q和n决定的临界模环之外。这一成果不仅完全表征了所有具有MZ性质的几何节点黎曼差分，还提供了一个可应用于更广泛广义差分问题的分析框架。

> **摘要翻译:** 我们研究了n阶黎曼差分何时具有Marcinkiewicz-Zygmund (MZ) 性质：即条件f(h) = o(h^(n-1))和Df(h) = o(h^n)是否蕴含f(h) = o(h^n)。已知对于一些具有几何节点的经典例子，如{0, 1, q, ..., q^(n-1)}和{1, q, ..., q^n}，此蕴含关系成立，这导致了一个猜想，认为这些是唯一具有MZ性质的黎曼差分。然而，这个猜想被节点为{-1, 0, 1, 2}的三阶例子所推翻，我们在此提供了进一步的反例和普遍分类。
我们通过开发一个递归框架，为MZ性质建立了一个完整的解析判据：我们分析了当函数R(h)满足D(h) = R(qh) - A R(h)，且D(h) = o(h^n)和R(h) = o(h^(n-1))时，是否强制R(h) = o(h^n)。我们证明了这当且仅当A位于由q和n确定的临界模环之外时成立，涵盖了|q|>1和|q|<1两种情况。这导致了对所有具有MZ性质的几何节点的黎曼差分的完整表征，并提供了一个灵活的分析框架，适用于更广泛的广义差分类别。

</details>

[⬆️ 返回分类顶部](#mathca) | [⬆️ 返回总目录](#toc)

---

<a id='mathpr'></a>
## math.PR 

### [642] [Neural Expectation Operators](https://arxiv.org/abs/2507.10607)
> *神经期望算子*

*Qian Qi* | **Category: math.PR, cs.AI, cs.LG** | **Updated: 2025-07-13**

**Keywords:** 测度学习, 神经期望算子, 后向随机微分方程, 不确定性建模, 适定性定理

**Comment:** 

> **TL;DR:** 本文引入了“测度学习”范式，通过神经期望算子（基于神经网络参数化的BSDEs）对不确定性进行建模，并提供了严格的数学基础，解决了二次BSDEs与机器学习结合的难题。

**AI_Comments:** 这篇论文的创新之处在于它为在机器学习中处理不确定性提供了一个严格的数学框架，特别是通过将神经网络与复杂的二次BSDE理论相结合。它解决了传统BSDEs在实际应用中面临的严格假设问题，并通过具体设计展示了理论的可行性。这对于风险管理、强化学习等需要量化不确定性的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在引入“测度学习”这一新范式，通过非线性期望来建模不确定性，并为数据驱动的不确定性建模提供基础数学框架。它还希望弥合二次BSDEs的抽象理论与机器学习实践之间的鸿沟。

**Method:** 本文定义神经期望算子为后向随机微分方程（BSDEs）的解，其驱动项由神经网络参数化。论文提出了一个严格的适定性定理，用于解决驱动项在状态变量y上满足局部Lipschitz条件且在鞅分量z上满足二次增长的BSDEs。研究还提供了通过架构设计强制实现凸性等关键公理性质的构造性方法，并将理论扩展到全耦合前向-后向SDE系统和大型相互作用粒子系统的渐近分析。

**Result:** 本文建立了驱动项满足局部Lipschitz条件和二次增长的BSDEs的严格适定性定理，该定理规避了经典的全局Lipschitz假设，适用于常见的神经网络架构（如ReLU激活），并适用于指数可 integrable 终端数据。研究成功构建了二次BSDEs的抽象理论与机器学习之间的桥梁，证明了这些条件可以通过具体的、可验证的神经网络设计来满足。此外，论文提供了通过架构设计实现凸性等公理性质的构造性方法，并在大型相互作用粒子系统的渐近分析中，建立了大数定律（混沌传播）和中心极限定理。

**Conclusion:** 本工作为数据驱动的不确定性建模提供了基础的数学框架。

> **ai_Abstract:** 本文提出了“测度学习”范式，通过神经网络参数化的后向随机微分方程（BSDEs）定义神经期望算子来建模不确定性。论文的主要数学贡献是为满足特定局部Lipschitz和二次增长条件的BSDEs提供了严格的适定性定理，这使得抽象的二次BSDE理论能够应用于实际的神经网络设计。研究还提供了强制实现公理性质的方法，并将理论扩展到全耦合SDE系统和粒子系统，为数据驱动的不确定性建模奠定了数学基础。

> **摘要翻译:** 本文介绍了“测度学习”，一种通过非线性期望建模不确定性的范式。我们将神经期望算子定义为后向随机微分方程（BSDEs）的解，其驱动项由神经网络参数化。主要的数学贡献是为驱动项在状态变量y中满足局部Lipschitz条件并在其鞅分量z中满足二次增长的BSDEs提供了严格的适定性定理。这一结果规避了经典的全局Lipschitz假设，适用于常见的神经网络架构（例如，使用ReLU激活），并适用于指数可 integrable 的终端数据，这是此设置下的精确条件。我们的主要创新在于在二次BSDEs的抽象且通常具有限制性的深层理论与机器学习世界之间建立了一座建设性的桥梁，证明了这些条件可以通过具体、可验证的神经网络设计来满足。我们提供了通过架构设计强制实现关键公理性质（如凸性）的构造性方法。该理论扩展到全耦合前向-后向SDE系统分析以及大型相互作用粒子系统的渐近分析，我们为此建立了大数定律（混沌传播）和中心极限定理。这项工作为数据驱动的不确定性建模提供了基础数学框架。

</details>

[⬆️ 返回分类顶部](#mathpr) | [⬆️ 返回总目录](#toc)

---

<a id='math-ph'></a>
## math-ph 

### [681] [From Kinetic Theory to AI: a Rediscovery of High-Dimensional Divergences and Their Properties](https://arxiv.org/abs/2507.11387)
> *从动力学理论到人工智能：高维散度及其性质的再发现*

*Gennaro Auricchio, Giovanni Brigati, Paolo Giudici, Giuseppe Toscani* | **Category: math-ph, cs.AI, cs.LG, cs.MA, math.MP, 35B40, 35L60, 35K55, 35Q70, 35Q91, 35Q92** | **Updated: 2025-07-15**

**Keywords:** 动力学理论, 散度度量, 机器学习, 人工智能, Kullback-Leibler散度

**Comment:** 

> **TL;DR:** 该论文回顾了源于动力学理论的散度度量，并探讨了它们在机器学习和人工智能中的应用潜力，强调了散度选择对模型性能的关键影响。

**AI_Comments:** 该论文通过将动力学理论中的概念引入机器学习领域，具有重要意义，可能有助于重新发现或重新评估那些不常用但可能提升AI模型性能的散度度量。它强调了散度选择的基础重要性。

<details>
  <summary>Details</summary>

**Motivation:** 选择合适的散度度量对机器学习模型性能至关重要。本文旨在回顾源于动力学理论的散度度量，并探索它们在机器学习和人工智能中的潜在应用。

**Method:** 本文对源于动力学理论的散度度量进行了比较性回顾，强调其理论基础并探讨其潜在应用。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文对源于动力学理论的散度度量，特别是Kullback-Leibler (KL) 散度，进行了比较性回顾。它强调了这些度量的理论基础，并探讨了它们在机器学习和人工智能中的潜在应用，突出了散度选择在模型性能中的关键作用。

> **摘要翻译:** 选择合适的散度度量是机器学习中至关重要的一个方面，因为它直接影响模型性能。在最广泛使用的度量中，我们发现 Kullback-Leibler (KL) 散度，它最初在动力学理论中被引入，作为概率分布之间相对熵的度量。正如在机器学习中一样，量化概率分布之间接近程度的能力在动力学理论中也起着核心作用。在本文中，我们对源于动力学理论的散度度量进行了比较性回顾，强调了它们的理论基础，并探讨了它们在机器学习和人工智能中的潜在应用。

</details>

[⬆️ 返回分类顶部](#math-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cscc'></a>
## cs.CC 

### [694] [The Limits of Tractable Marginalization](https://arxiv.org/abs/2506.12020)
> *可处理边缘化的局限性*

*Oliver Broadrick, Sanyam Agarwal, Guy Van den Broeck, Markus Bläser* | **Category: cs.CC, cs.AI** | **Updated: 2025-07-14**

**Keywords:** 边缘化, 计算复杂性, 算术电路, 多线性多项式, FP不等于#P

**Comment:** 

> **TL;DR:** 本文证明存在可处理边缘化但无法由已知模型高效表达的简单函数，挑战了边缘化可处理性与电路表达能力之间的假设。

**AI_Comments:** 这项研究挑战了对可处理边缘化函数与其电路表示之间关系的普遍假设，揭示了即使边缘化是可处理的，也可能不存在高效的电路表示。其创新性在于通过复杂性理论的假设（$	extsf{FP}
eq＃	extsf{P}$）提供了一个反例，并建立了边缘化复杂性类的新层次结构。这项工作对于理解计算复杂性理论中函数表达能力的限制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 许多可处理边缘化的函数可以用多项式大小的算术电路表达，但问题是所有具有多项式时间边缘化算法的函数是否都能被这类电路简洁地表达。

**Method:** 通过展示具有可处理边缘化但无法被已知模型高效表达的简单函数来给出否定答案，并识别了一系列对应于更强边缘化形式的复杂性类。

**Result:** 证明存在可处理边缘化但无法由已知模型高效表达的简单函数，前提是$	extsf{FP}
eq＃	extsf{P}$。同时，识别了对应于更强边缘化形式的复杂性类层次结构，这些类在已知电路模型上均可高效计算。

**Conclusion:** 只要存在执行虚证据边缘化的有效实数RAM，该函数的多线性表示就存在小型电路。

> **ai_Abstract:** 本文探讨了可处理边缘化与函数电路表示之间的关系。研究发现，并非所有具有多项式时间边缘化算法的函数都能被多项式大小的算术电路简洁表达，推翻了现有假设。作者通过构造反例并假设$	extsf{FP}
eq＃	extsf{P}$来证明这一观点。此外，论文还定义了一系列更强的边缘化复杂性类，并最终证明了当存在高效的实数RAM执行虚证据边缘化时，对应的函数存在小型多线性表示电路。

> **摘要翻译:** 边缘化——将一个函数对其输入子集的所有赋值求和——是一个基本的计算问题，其应用范围从概率推断到形式验证。尽管其计算通常是困难的，但存在许多函数类别（例如，概率模型）的边缘化仍然是可处理的，并且它们通常可以通过计算多线性多项式的多项式大小算术电路来表达。这引出了一个问题：所有具有多项式时间边缘化算法的函数都能被这类电路简洁地表达吗？我们给出了一个否定的答案，展示了具有可处理边缘化但无法通过已知模型进行高效表示的简单函数，前提是$	extsf{FP}
eq＃	extsf{P}$（这是一个由$	extsf{P} 
eq 	extsf{NP}$蕴含的假设）。为此，我们确定了一个对应于更强边缘化形式的复杂性类层次结构，所有这些类都可以在已知电路模型上高效计算。最后，我们得出了一个完备性结果，表明只要存在一个执行函数虚证据边缘化的有效实数RAM，那么该函数的多线性表示就存在小型电路。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phsr'></a>
## astro-ph.SR 

### [806] [Solar Flare Prediction Using Long Short-term Memory (LSTM) and Decomposition-LSTM with Sliding Window Pattern Recognition](https://arxiv.org/abs/2507.05313)
> *使用长短期记忆网络（LSTM）和分解长短期记忆网络（DLSTM）结合滑动窗口模式识别进行太阳耀斑预测*

*Zeinab Hassani, Davud Mohammadpur, Hossein Safari* | **Category: astro-ph.SR, cs.AI, cs.LG, I.2; I.5; G.3** | **Updated: 2025-07-15**

**Keywords:** 太阳耀斑预测, LSTM, DLSTM, 时间序列, 机器学习

**Comment:** Published in the Astrophysical Journal Supplement Series, volume 279,
  2025, DOI: 10.3847/1538-4365/addc73

> **TL;DR:** 本研究利用LSTM和DLSTM结合集成算法，通过滑动窗口模式识别和时间序列分解，显著提高了太阳耀斑（特别是大型耀斑）的预测准确性。

**AI_Comments:** 该论文的创新点在于结合了DLSTM和集成算法，并引入了时间序列正则化和滑动窗口模式识别，以提高太阳耀斑预测的准确性，特别是大型耀斑。DLSTM分解时间序列的能力是其性能优越的关键。研究强调了在复杂时间序列预测中处理数据不平衡和噪声的重要性，为未来的太阳活动预测研究提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 由于太阳复杂的自组织临界行为，长期预测太阳耀斑具有挑战性，需要更准确的预测模型。

**Method:** 研究使用了来自GOES目录的2003年至2023年的时间序列数据，包含151,071个耀斑事件。采用了滑动窗口技术来检测不规则和正则化耀斑时间序列中的准模式。应用了重采样方法来解决类别不平衡问题。LSTM和DLSTM模型在不规则时间序列的峰值通量和等待时间序列上进行训练。LSTM和DLSTM结合集成方法应用于正则化时间序列的滑动窗口（3小时间隔）。DLSTM通过将时间序列分解为趋势和季节性分量来隔离随机噪声。

**Result:** DLSTM结合集成方法在正则化时间序列上的表现优于其他模型，性能指标为TSS（0.74）、召回率（0.95）和ROC曲线下的面积AUC（0.87）。该方法提供了更准确的大型耀斑预测，与在不规则时间序列上训练的模型相比，假错误更少。DLSTM的卓越性能归因于其分解时间序列的能力。

**Conclusion:** 本研究强调了先进机器学习技术在太阳耀斑预测中的潜力，并突出了结合各种太阳周期阶段和重采样策略以提高预测可靠性的重要性。

> **ai_Abstract:** 本研究探讨了使用LSTM和DLSTM结合集成算法，利用GOES时间序列数据预测太阳耀斑。为应对长期预测的挑战，研究采用了滑动窗口技术识别时间准模式，并对时间序列进行正则化处理以降低复杂性。通过重采样解决类别不平衡问题。结果显示，DLSTM结合集成方法在正则化时间序列上的表现最佳，尤其在大型耀斑预测方面，其TSS、召回率和AUC等性能指标显著优于其他模型，且假错误更少。DLSTM的优势在于其能有效分解时间序列并隔离噪声。研究强调了先进机器学习技术在太阳耀斑预测中的潜力，并指出整合太阳周期阶段和重采样策略的重要性。

> **摘要翻译:** 我们研究了使用长短期记忆网络（LSTM）和分解长短期记忆网络（DLSTM）结合集成算法，利用GOES目录的时间序列数据预测太阳耀斑的发生。数据集涵盖2003年至2023年，包括151,071个耀斑事件。在大约可能的模式中，识别出7,552个年度模式窗口，这突显了由于太阳复杂、自组织临界驱动的行为而导致的长期预测挑战。采用滑动窗口技术来检测不规则和正则化耀斑时间序列中的时间准模式。正则化降低了复杂性，增强了大型耀斑活动，并更有效地捕获了活跃日期。为了解决类别不平衡问题，应用了重采样方法。LSTM和DLSTM模型在不规则时间序列的峰值通量和等待时间序列上进行训练，而LSTM和DLSTM结合集成方法应用于正则化时间序列的滑动窗口（3小时间隔）。性能指标，特别是接收者操作特征（ROC）中的TSS（0.74）、召回率（0.95）和曲线下面积（AUC=0.87），表明DLSTM结合集成方法在正则化时间序列上的表现优于其他模型，与在不规则时间序列上训练的模型相比，提供了更准确的大型耀斑预测和更少的假错误。DLSTM的卓越性能归因于其将时间序列分解为趋势和季节性分量，有效隔离随机噪声的能力。本研究强调了先进机器学习技术在太阳耀斑预测中的潜力，并突出了结合各种太阳周期阶段和重采样策略以提高预测可靠性的重要性。

</details>

[⬆️ 返回分类顶部](#astro-phsr) | [⬆️ 返回总目录](#toc)

