{"id": "2503.05714", "pdf": "https://arxiv.org/pdf/2503.05714", "abs": "https://arxiv.org/abs/2503.05714", "authors": ["Rozin Hasin"], "title": "Prosthetics of the Indian State: The e-Shram Portal for Unorganized Workers in India", "categories": ["cs.CY", "cs.ET", "cs.IR", "cs.SY", "eess.SY"], "comment": null, "summary": "This research paper examines the digital portal/database for unorganized\nworkers in the informal sector economy of India today: e-Shram. Using\naffordance theory, I criticize the operationalization of this database for the\nlabourers, alongside problems of accessibility and perception.", "AI": {"title_translation": "印度国家的假肢：印度非正规工人的e-Shram门户", "tldr": "本文批判性地审视了印度非正规工人数字门户e-Shram的运作，指出其在可及性和感知方面存在问题。", "motivation": "研究印度非正规经济部门中为非组织工人设立的数字门户/数据库e-Shram。", "method": "使用可供性理论进行分析。", "result": "批判了该数据库对劳动者的运作，以及可及性和感知方面的问题。", "conclusion": "e-Shram门户在为非组织工人服务方面存在操作、可及性和感知问题。", "translation": "本研究论文审视了当今印度非正规经济部门中为非组织工人设立的数字门户/数据库：e-Shram。我利用可供性理论，批判了该数据库对劳动者的运作，以及可及性和感知方面的问题。", "summary": "本研究论文利用可供性理论，对印度非正规经济部门中为非组织工人设立的e-Shram数字门户进行了批判性审视，揭示了该数据库在运作、可及性和感知方面存在的问题。", "keywords": "e-Shram, 非组织工人, 数字门户, 可供性理论, 印度"}}
{"id": "2506.04249", "pdf": "https://arxiv.org/pdf/2506.04249", "abs": "https://arxiv.org/abs/2506.04249", "authors": ["Mehmet Aziz Yirik", "Jakob Lykke Andersen", "Rolf Fagerberg", "Daniel Merkle"], "title": "ChemReservoir -- An Open-Source Framework for Chemically-Inspired Reservoir Computing", "categories": ["cs.CE", "cs.ET", "cs.LG"], "comment": null, "summary": "Reservoir computing is a type of a recurrent neural network, mapping the\ninputs into higher dimensional space using fixed and nonlinear dynamical\nsystems, called reservoirs. In the literature, there are various types of\nreservoirs ranging from in-silico to in-vitro. In cheminformatics, previous\nstudies contributed to the field by developing simulation-based chemically\ninspired in-silico reservoir models. Yahiro used a DNA-based chemical reaction\nnetwork as its reservoir and Nguyen developed a DNA chemistry-inspired tool\nbased on Gillespie algorithm. However, these software tools were designed\nmainly with the focus on DNA chemistry and their maintenance status has limited\ntheir current usability. Due to these limitations, there was a need for a\nproper open-source tool. This study introduces ChemReservoir, an open-source\nframework for chemically-inspired reservoir computing. In contrast to the\nformer studies focused on DNA-chemistry, ChemReservoir is a general framework\nfor the construction and analysis of chemically-inspired reservoirs, which also\naddresses the limitations in these previous studies by ensuring enhanced\ntesting, evaluation, and reproducibility. The tool was evaluated using various\ncycle-based reservoir topologies and demonstrated stable performance across a\nrange of configurations in memory capacity tasks.", "AI": {"title_translation": "ChemReservoir——一个受化学启发的水库计算开源框架", "tldr": "ChemReservoir是一个开源框架，用于构建和分析受化学启发的水库计算模型，解决了现有工具的局限性并提高了可用性。", "motivation": "现有的受化学启发的水库计算工具（如基于DNA化学反应网络的工具）主要侧重于DNA化学，且维护状态限制了其可用性，因此需要一个适当的开源工具。", "method": "本研究引入了ChemReservoir，一个用于构建和分析受化学启发的水库的通用开源框架。它通过增强测试、评估和可复现性来解决以往研究中的局限性。", "result": "ChemReservoir工具使用各种基于循环的水库拓扑进行了评估，并在记忆容量任务中展示了在各种配置下的稳定性能。", "conclusion": "ChemReservoir作为一个通用的开源框架，成功解决了现有受化学启发的水库计算工具的局限性，并展示了稳定的性能，为该领域提供了更可靠和可复现的解决方案。", "translation": "水库计算是一种循环神经网络，它使用固定且非线性的动力系统（称为水库）将输入映射到更高维空间。文献中存在各种类型的水库，从体内到体外。在化学信息学中，以前的研究通过开发基于模拟的化学启发式体外水库模型为该领域做出了贡献。Yahiro使用基于DNA的化学反应网络作为其水库，Nguyen开发了一种基于Gillespie算法的DNA化学启发工具。然而，这些软件工具主要侧重于DNA化学，并且它们的维护状态限制了它们目前的可用性。由于这些限制，需要一个适当的开源工具。本研究介绍了ChemReservoir，一个受化学启发的水库计算的开源框架。与以前专注于DNA化学的研究不同，ChemReservoir是一个用于构建和分析受化学启发的水库的通用框架，它还通过确保增强的测试、评估和可复现性来解决这些先前研究中的局限性。该工具使用各种基于循环的水库拓扑进行了评估，并在记忆容量任务中展示了在各种配置下的稳定性能。", "summary": "本研究介绍了ChemReservoir，一个为化学启发的水库计算设计的开源框架。它旨在克服现有工具（如基于DNA化学的模拟器）的局限性，提供一个更通用、更易维护的平台。ChemReservoir支持构建和分析各种化学启发的水库，并通过增强测试、评估和复现性来提高可用性。该工具在记忆容量任务中通过多种循环拓扑结构进行了评估，并展示了稳定的性能。", "keywords": "ChemReservoir, 水库计算, 开源框架, 化学启发, 神经网络"}}
{"id": "2506.04267", "pdf": "https://arxiv.org/pdf/2506.04267", "abs": "https://arxiv.org/abs/2506.04267", "authors": ["Baran Shajari", "Istvan David"], "title": "Bridging the Silos of Digitalization and Sustainability by Twin Transition: A Multivocal Literature Review", "categories": ["physics.soc-ph", "cs.ET"], "comment": "Accepted for ICT4S 2025", "summary": "Twin transition is the method of parallel digital and sustainability\ntransitions in a mutually supporting way or, in common terms, \"greening of and\nby IT and data.\" Twin transition reacts to the growing problem of unsustainable\ndigitalization, particularly in the ecological sense. Ignoring this problem\nwill eventually limit the digital adeptness of society and the problem-solving\ncapacity of humankind. Information systems engineering must find ways to\nsupport twin transition journeys through its substantial body of knowledge,\nmethods, and techniques. To this end, we systematically survey the academic and\ngray literature on twin transition, clarify key concepts, and derive leads for\nresearchers and practitioners to steer their innovation efforts.", "AI": {"title_translation": "通过双重转型弥合数字化和可持续发展的鸿沟：一项多视角文献综述", "tldr": "本文通过系统回顾文献，旨在应对不可持续的数字化问题，并为研究人员和从业者提供指导，以实现数字化和可持续发展的双重转型。", "motivation": "应对不可持续的数字化日益严重的问题，特别是在生态方面，因为忽视此问题最终将限制社会的数字化能力和人类解决问题的能力。", "method": "系统地调查学术文献和灰色文献。", "result": "阐明了关键概念，并为研究人员和从业者提供了指导，以引导他们的创新工作。", "conclusion": "信息系统工程必须通过其知识体系、方法和技术来支持双重转型，以应对不可持续的数字化问题，并为研究人员和从业者提供指导。", "translation": "双重转型是指以相互支持的方式并行进行数字化和可持续发展转型，或者通俗地说，是“通过信息技术和数据实现绿色化”。双重转型旨在应对不可持续的数字化日益严重的问题，特别是在生态方面。忽视这个问题最终将限制社会的数字化能力和人类解决问题的能力。信息系统工程必须通过其大量的知识、方法和技术来寻找支持双重转型路径的方法。为此，我们系统地调查了关于双重转型的学术文献和灰色文献，阐明了关键概念，并为研究人员和从业者提供了指导，以引导他们的创新努力。", "summary": "本文通过对双重转型相关的学术和灰色文献进行系统综述，旨在解决不可持续的数字化问题。研究澄清了双重转型的关键概念，并为研究人员和从业者提供了指导，以促进数字化与可持续发展的协同创新。", "keywords": "双重转型, 数字化, 可持续发展, 文献综述, 信息系统工程"}}
{"id": "2506.04322", "pdf": "https://arxiv.org/pdf/2506.04322", "abs": "https://arxiv.org/abs/2506.04322", "authors": ["Guozhen Zhu", "Yuqian Hu", "Chenshu Wu", "Wei-Hsiang Wang", "Beibei Wang", "K. J. Ray Liu"], "title": "Experience Paper: Scaling WiFi Sensing to Millions of Commodity Devices for Ubiquitous Home Monitoring", "categories": ["eess.SP", "cs.ET", "cs.SY", "eess.SY"], "comment": "15 pages, 18 figures", "summary": "WiFi-based home monitoring has emerged as a compelling alternative to\ntraditional camera- and sensor-based solutions, offering wide coverage with\nminimal intrusion by leveraging existing wireless infrastructure. This paper\npresents key insights and lessons learned from developing and deploying a\nlarge-scale WiFi sensing solution, currently operational across over 10 million\ncommodity off-the-shelf routers and 100 million smart bulbs worldwide. Through\nthis extensive deployment, we identify four real-world challenges that hinder\nthe practical adoption of prior research: 1) Non-human movements (e.g., pets)\nfrequently trigger false positives; 2) Low-cost WiFi chipsets and heterogeneous\nhardware introduce inconsistencies in channel state information (CSI)\nmeasurements; 3) Motion interference in multi-user environments complicates\noccupant differentiation; 4) Computational constraints on edge devices and\nlimited cloud transmission impede real-time processing. To address these\nchallenges, we present a practical and scalable system, validated through\ncomprehensive two-year evaluations involving 280 edge devices, across 16\nscenarios, and over 4 million motion samples. Our solutions achieve an accuracy\nof 92.61% in diverse real-world homes while reducing false alarms due to\nnon-human movements from 63.1% to 8.4% and lowering CSI transmission overhead\nby 99.72%. Notably, our system integrates sensing and communication, supporting\nsimultaneous WiFi sensing and data transmission over home WiFi networks. While\nfocused on home monitoring, our findings and strategies generalize to various\nWiFi sensing applications. By bridging the gaps between theoretical research\nand commercial deployment, this work offers practical insights for scaling WiFi\nsensing in real-world environments.", "AI": {"title_translation": "经验论文：将WiFi感知扩展到数百万商用设备以实现无处不在的家庭监控", "tldr": "本文介绍了一种可扩展的WiFi感知系统，克服了现有方案在实际部署中的挑战，并在全球数百万设备上实现了准确的家庭监控。", "motivation": "WiFi家庭监控作为传统方案的替代品，具有广泛覆盖和低侵入性。然而，现有研究在实际部署中面临四大挑战：非人类运动导致的误报、低成本WiFi芯片组导致的CSI测量不一致、多用户环境中的运动干扰导致的人员区分困难，以及边缘设备计算限制和云传输限制导致的实时处理障碍。", "method": "本文提出了一个实用且可扩展的WiFi感知系统，通过两年、280个边缘设备、16个场景和400万个运动样本的全面评估进行验证。该系统旨在解决非人类运动误报、CSI测量不一致、多用户环境中的运动干扰以及计算限制等问题。它还集成了感知和通信功能。", "result": "该系统在不同的真实家庭环境中实现了92.61%的准确率，将非人类运动引起的误报从63.1%降低到8.4%，并将CSI传输开销降低了99.72%。该系统还支持WiFi感知和数据传输同时进行。", "conclusion": "本文通过弥合理论研究与商业部署之间的差距，为在实际环境中扩展WiFi感知提供了实用见解。所提出的发现和策略可推广到各种WiFi感知应用。", "translation": "基于WiFi的家庭监控已成为传统基于摄像头和传感器的解决方案的有力替代方案，它通过利用现有无线基础设施，提供广泛的覆盖范围，同时将侵入性降至最低。本文介绍了开发和部署大规模WiFi感知解决方案的关键见解和经验教训，该解决方案目前在全球超过1000万个商用现成路由器和1亿个智能灯泡上运行。通过这次广泛的部署，我们发现了阻碍先前研究实际应用的四个现实挑战：1）非人类运动（例如宠物）经常引发误报；2）低成本WiFi芯片组和异构硬件导致信道状态信息（CSI）测量不一致；3）多用户环境中的运动干扰使居住者区分复杂化；4）边缘设备的计算限制和有限的云传输阻碍了实时处理。为了应对这些挑战，我们提出了一个实用且可扩展的系统，并通过涉及280个边缘设备、16个场景和超过400万个运动样本的两年全面评估进行了验证。我们的解决方案在不同的真实家庭中实现了92.61%的准确率，同时将非人类运动引起的误报从63.1%降低到8.4%，并将CSI传输开销降低了99.72%。值得注意的是，我们的系统集成了感知和通信，支持在家庭WiFi网络上同时进行WiFi感知和数据传输。虽然主要关注家庭监控，但我们的发现和策略可以推广到各种WiFi感知应用。通过弥合理论研究与商业部署之间的差距，这项工作为在实际环境中扩展WiFi感知提供了实用见解。", "summary": "本经验论文详细介绍了开发和部署大规模WiFi感知解决方案的经验和教训，该方案已在全球数百万商用设备上运行。论文识别并解决了阻碍现有研究实际应用中的四个关键挑战，包括非人类运动误报、CSI测量不一致、多用户干扰和计算限制。通过全面的两年评估，该系统在真实家庭环境中实现了高精度，显著减少了误报并降低了传输开销，同时支持感知和通信集成。这项工作为WiFi感知的实际扩展提供了宝贵的见解。", "keywords": "WiFi感知, 家庭监控, 大规模部署, 挑战, 解决方案"}}
{"id": "2506.04523", "pdf": "https://arxiv.org/pdf/2506.04523", "abs": "https://arxiv.org/abs/2506.04523", "authors": ["Cliff B. Abbott", "Mark Elo", "Dmytro A. Bozhko"], "title": "Perturbative Gradient Training: A novel training paradigm for bridging the gap between deep neural networks and physical reservoir computing", "categories": ["cs.LG", "cond-mat.mes-hall", "cs.ET", "cs.NE", "physics.comp-ph"], "comment": "7 pages, 8 figures, submitted to IEEE Transactions on Neural Netowrks\n  and Learning Systems", "summary": "We introduce Perturbative Gradient Training (PGT), a novel training paradigm\nthat overcomes a critical limitation of physical reservoir computing: the\ninability to perform backpropagation due to the black-box nature of physical\nreservoirs. Drawing inspiration from perturbation theory in physics, PGT uses\nrandom perturbations in the network's parameter space to approximate gradient\nupdates using only forward passes. We demonstrate the feasibility of this\napproach on both simulated neural network architectures, including a dense\nnetwork and a transformer model with a reservoir layer, and on experimental\nhardware using a magnonic auto-oscillation ring as the physical reservoir. Our\nresults show that PGT can achieve performance comparable to that of standard\nbackpropagation methods in cases where backpropagation is impractical or\nimpossible. PGT represents a promising step toward integrating physical\nreservoirs into deeper neural network architectures and achieving significant\nenergy efficiency gains in AI training.", "AI": {"title_translation": "扰动梯度训练：弥合深度神经网络与物理储层计算之间鸿沟的新型训练范式", "tldr": "扰动梯度训练（PGT）允许物理储层计算在无法进行反向传播时，通过近似梯度更新实现类似反向传播的性能，从而将物理储层集成到深度神经网络中。", "motivation": "物理储层计算存在一个关键限制：由于物理储层的黑箱性质，无法执行反向传播。", "method": "扰动梯度训练（PGT）借鉴物理学中的微扰理论，利用网络参数空间中的随机扰动，仅通过前向传播来近似梯度更新。该方法在模拟神经网络架构（包括密集网络和带储层层的Transformer模型）以及使用磁振子自振荡环作为物理储层的实验硬件上进行了演示。", "result": "PGT在反向传播不切实际或不可能的情况下，可以实现与标准反向传播方法相当的性能。", "conclusion": "PGT代表了将物理储层集成到更深层神经网络架构中并实现AI训练显著能效增益的有希望的一步。", "translation": "我们引入了扰动梯度训练（PGT），这是一种新型训练范式，它克服了物理储层计算的一个关键限制：由于物理储层的黑箱性质，无法执行反向传播。PGT借鉴物理学中的微扰理论，利用网络参数空间中的随机扰动，仅通过前向传播来近似梯度更新。我们在模拟神经网络架构（包括密集网络和带储层层的Transformer模型）以及使用磁振子自振荡环作为物理储层的实验硬件上，展示了这种方法的可行性。我们的结果表明，在反向传播不切实际或不可能的情况下，PGT可以实现与标准反向传播方法相当的性能。PGT代表了将物理储层集成到更深层神经网络架构中并实现AI训练显著能效增益的有希望的一步。", "summary": "本研究提出了一种名为扰动梯度训练（PGT）的新型训练范式，旨在解决物理储层计算中无法进行反向传播的难题。PGT受物理微扰理论启发，通过在网络参数空间中引入随机扰动，仅利用前向传播来近似梯度更新。实验结果表明，无论是在模拟神经网络还是在实际物理硬件上，PGT都能在反向传播不可行的情况下，达到与标准反向传播相当的性能。这为将物理储层集成到更深层次的神经网络架构中，从而提高AI训练的能效开辟了新途径。", "keywords": "扰动梯度训练, 物理储层计算, 深度神经网络, 反向传播, 能效"}}
{"id": "2506.04539", "pdf": "https://arxiv.org/pdf/2506.04539", "abs": "https://arxiv.org/abs/2506.04539", "authors": ["Kordel K. France", "Ovidiu Daescu", "Anirban Paul", "Shalini Prasad"], "title": "Olfactory Inertial Odometry: Sensor Calibration and Drift Compensation", "categories": ["cs.RO", "cs.ET", "cs.LG", "cs.SY", "eess.SY"], "comment": "Published as a full conference paper at the 2025 IEEE International\n  Symposium on Inertial Sensors & Systems", "summary": "Visual inertial odometry (VIO) is a process for fusing visual and kinematic\ndata to understand a machine's state in a navigation task. Olfactory inertial\nodometry (OIO) is an analog to VIO that fuses signals from gas sensors with\ninertial data to help a robot navigate by scent. Gas dynamics and environmental\nfactors introduce disturbances into olfactory navigation tasks that can make\nOIO difficult to facilitate. With our work here, we define a process for\ncalibrating a robot for OIO that generalizes to several olfaction sensor types.\nOur focus is specifically on calibrating OIO for centimeter-level accuracy in\nlocalizing an odor source on a slow-moving robot platform to demonstrate use\ncases in robotic surgery and touchless security screening. We demonstrate our\nprocess for OIO calibration on a real robotic arm and show how this calibration\nimproves performance over a cold-start olfactory navigation task.", "AI": {"title_translation": "嗅觉惯性里程计：传感器校准与漂移补偿", "tldr": "提出一种通用的嗅觉惯性里程计（OIO）校准方法，以实现厘米级精度，并在实际机器人平台上展示其性能提升。", "motivation": "气体动力学和环境因素给嗅觉导航任务带来了干扰，使得嗅觉惯性里程计（OIO）难以实现。", "method": "本文定义了一种通用的机器人嗅觉惯性里程计（OIO）校准过程，适用于多种嗅觉传感器类型，旨在使OIO在慢速移动机器人平台上实现厘米级精度，用于定位气味源。", "result": "该校准过程在实际机械臂上进行了演示，并表明其相对于冷启动嗅觉导航任务显著提高了性能。", "conclusion": "通过提出的校准过程，可以有效提高嗅觉惯性里程计（OIO）的性能，解决气体动力学和环境因素带来的干扰问题，从而实现高精度的嗅觉导航。", "translation": "视觉惯性里程计（VIO）是一种融合视觉和运动学数据以理解机器在导航任务中状态的过程。嗅觉惯性里程计（OIO）是VIO的一种模拟，它将气体传感器信号与惯性数据融合，以帮助机器人通过气味导航。气体动力学和环境因素会给嗅觉导航任务带来干扰，使得OIO难以实现。在本研究中，我们定义了一种对机器人进行OIO校准的过程，该过程可推广到多种嗅觉传感器类型。我们的重点是专门校准OIO，以在慢速移动机器人平台上实现厘米级精度的气味源定位，从而展示在机器人手术和非接触式安全检查中的应用案例。我们在一台真实的机械臂上演示了OIO校准过程，并展示了这种校准如何提高冷启动嗅觉导航任务的性能。", "summary": "本文提出了一种用于嗅觉惯性里程计（OIO）的通用校准方法，旨在克服气体动力学和环境因素造成的干扰，实现厘米级气味源定位精度。研究在实际机器人平台上验证了该方法的有效性，并展示了其在冷启动嗅觉导航任务中显著的性能提升，为机器人手术和非接触式安检等应用提供了支持。", "keywords": "嗅觉惯性里程计, 传感器校准, 漂移补偿, 机器人导航, 气味源定位"}}
{"id": "2506.04891", "pdf": "https://arxiv.org/pdf/2506.04891", "abs": "https://arxiv.org/abs/2506.04891", "authors": ["Viacheslav Kuzmin", "Basil Kyriacou", "Mateusz Papierz", "Mo Kordzanganeh", "Alexey Melnikov"], "title": "TQml Simulator: Optimized Simulation of Quantum Machine Learning", "categories": ["quant-ph", "cs.ET", "cs.LG", "cs.PF"], "comment": "25 pages, 13 figures, 1 table", "summary": "Hardware-efficient circuits employed in Quantum Machine Learning are\ntypically composed of alternating layers of uniformly applied gates. High-speed\nnumerical simulators for such circuits are crucial for advancing research in\nthis field. In this work, we numerically benchmark universal and gate-specific\ntechniques for simulating the action of layers of gates on quantum state\nvectors, aiming to accelerate the overall simulation of Quantum Machine\nLearning algorithms. Our analysis shows that the optimal simulation method for\na given layer of gates depends on the number of qubits involved, and that a\ntailored combination of techniques can yield substantial performance gains in\nthe forward and backward passes for a given circuit. Building on these\ninsights, we developed a numerical simulator, named TQml Simulator, that\nemploys the most efficient simulation method for each layer in a given circuit.\nWe evaluated TQml Simulator on circuits constructed from standard gate sets,\nsuch as rotations and CNOTs, as well as on native gates from IonQ and IBM\nquantum processing units. In most cases, our simulator outperforms equivalent\nPennylane's default.qubit simulator by approximately 2- to 100-fold, depending\non the circuit, the number of qubits, the batch size of the input data, and the\nhardware used.", "AI": {"title_translation": "TQml模拟器：量子机器学习的优化模拟", "tldr": "本文开发了TQml模拟器，通过为量子机器学习电路的每一层选择最优的模拟方法，实现了比现有模拟器2到100倍的速度提升。", "motivation": "量子机器学习中使用的硬件高效电路通常由交替的均匀应用门层组成。为了推动该领域的研究，需要高速的数值模拟器。", "method": "本研究对模拟量子态向量上门层作用的通用和门特定技术进行了数值基准测试，旨在加速量子机器学习算法的整体模拟。基于分析结果，开发了名为TQml模拟器，该模拟器为给定电路中的每一层采用最有效的模拟方法。TQml模拟器在标准门集（如旋转门和CNOT门）以及IonQ和IBM量子处理单元的本地门构建的电路上进行了评估。", "result": "分析表明，给定门层的最佳模拟方法取决于所涉及的量子比特数量，并且量身定制的技术组合可以在给定电路的前向和后向传播中产生显著的性能增益。在大多数情况下，TQml模拟器比等效的Pennylane's default.qubit模拟器性能高出约2到100倍，具体取决于电路、量子比特数量、输入数据的批处理大小和所使用的硬件。", "conclusion": "通过为量子机器学习电路的每一层选择最优的模拟方法，TQml模拟器能够显著加速量子机器学习算法的模拟，表现出比现有模拟器优越的性能。", "translation": "量子机器学习中使用的硬件高效电路通常由交替的均匀应用门层组成。此类电路的高速数值模拟器对于推动该领域的研究至关重要。在这项工作中，我们对模拟门层在量子态向量上作用的通用和门特定技术进行了数值基准测试，旨在加速量子机器学习算法的整体模拟。我们的分析表明，给定门层的最佳模拟方法取决于所涉及的量子比特数量，并且量身定制的技术组合可以在给定电路的前向和后向传播中产生实质性的性能增益。基于这些见解，我们开发了一个名为TQml模拟器的数值模拟器，该模拟器为给定电路中的每一层采用最有效的模拟方法。我们在由标准门集（如旋转门和CNOT门）以及来自IonQ和IBM量子处理单元的本地门构建的电路上评估了TQml模拟器。在大多数情况下，我们的模拟器比等效的Pennylane's default.qubit模拟器性能高出约2到100倍，具体取决于电路、量子比特数量、输入数据的批处理大小和所使用的硬件。", "summary": "本文针对量子机器学习（QML）中硬件高效电路的模拟需求，开发了一款名为TQml模拟器的高速数值模拟器。研究人员通过数值基准测试通用和门特定技术，发现最佳模拟方法取决于量子比特数量，并且结合多种技术能显著提升性能。基于这些发现，TQml模拟器能够为电路的每一层选择最有效的模拟方法。在标准门集及IonQ和IBM本地门上的评估显示，TQml模拟器在多数情况下比Pennylane's default.qubit模拟器快2到100倍，显著加速了QML算法的模拟。", "keywords": "量子机器学习, 模拟器, 性能优化, 量子电路, TQml Simulator"}}
{"id": "2506.04972", "pdf": "https://arxiv.org/pdf/2506.04972", "abs": "https://arxiv.org/abs/2506.04972", "authors": ["Gijs Luijten", "Lisle Faray de Paiva", "Sebastian Krueger", "Alexander Brost", "Laura Mazilescu", "Ana Sofia Ferreira Santos", "Peter Hoyer", "Jens Kleesiek", "Sophia Marie-Therese Schmitz", "Ulf Peter Neumann", "Jan Egger"], "title": "From Screen to Space: Evaluating Siemens' Cinematic Reality", "categories": ["cs.HC", "cs.ET", "cs.GR"], "comment": "16 pages", "summary": "As one of the first research teams with full access to Siemens' Cinematic\nReality, we evaluate its usability and clinical potential for cinematic volume\nrendering on the Apple Vision Pro. We visualized venous-phase liver computed\ntomography and magnetic resonance cholangiopancreatography scans from the CHAOS\nand MRCP\\_DLRecon datasets. Fourteen medical experts assessed usability and\nanticipated clinical integration potential using the System Usability Scale,\nISONORM 9242-110-S questionnaire, and an open-ended survey. Their feedback\nidentified feasibility, key usability strengths, and required features to\ncatalyze the adaptation in real-world clinical workflows. The findings provide\ninsights into the potential of immersive cinematic rendering in medical\nimaging.", "AI": {"title_translation": "从屏幕到空间：评估西门子的电影级现实", "tldr": "研究团队评估了西门子电影级现实在Apple Vision Pro上进行电影级体绘制的可用性和临床潜力。", "motivation": "作为首批完全接触西门子电影级现实的研究团队之一，本研究旨在评估其在Apple Vision Pro上进行电影级体绘制的可用性和临床潜力。", "method": "研究团队使用CHAOS和MRCP_DLRecon数据集中的静脉期肝脏CT和MRCP扫描进行可视化。十四位医学专家使用系统可用性量表、ISONORM 9242-110-S问卷和开放式调查评估了可用性和预期的临床整合潜力。", "result": "专家的反馈确定了可行性、关键的可用性优势以及在现实临床工作流程中促进适应所需的特性。", "conclusion": "研究结果揭示了沉浸式电影级渲染在医学影像领域的潜力。", "translation": "作为首批完全接触西门子电影级现实的研究团队之一，我们评估了其在Apple Vision Pro上进行电影级体绘制的可用性和临床潜力。我们可视化了CHAOS和MRCP_DLRecon数据集中的静脉期肝脏计算机断层扫描和磁共振胰胆管造影扫描。十四位医学专家使用系统可用性量表、ISONORM 9242-110-S问卷和开放式调查评估了可用性和预期的临床整合潜力。他们的反馈确定了可行性、关键的可用性优势以及在现实临床工作流程中促进适应所需的特性。研究结果提供了对沉浸式电影级渲染在医学影像领域潜力的见解。", "summary": "本研究评估了西门子电影级现实在Apple Vision Pro上的可用性和临床潜力，用于医学影像的电影级体绘制。通过对肝脏CT和MRCP扫描的可视化，并由十四位医学专家进行评估，研究确定了该技术的可行性、可用性优势以及未来在临床工作流程中适应所需的关键功能。", "keywords": "西门子电影级现实, Apple Vision Pro, 医学影像, 可用性, 临床潜力"}}
{"id": "2506.04307", "pdf": "https://arxiv.org/pdf/2506.04307", "abs": "https://arxiv.org/abs/2506.04307", "authors": ["Christos Karapapas", "Iakovos Pittaras", "George C. Polyzos", "Constantinos Patsakis"], "title": "Hello, won't you tell me your name?: Investigating Anonymity Abuse in IPFS", "categories": ["cs.CR"], "comment": "To appear at 13th International Workshop on Cyber Crime (IWCC), in\n  conjunction with the 19th International Conference on Availability,\n  Reliability and Security (ARES)", "summary": "The InterPlanetary File System~(IPFS) offers a decentralized approach to file\nstorage and sharing, promising resilience and efficiency while also realizing\nthe Web3 paradigm. Simultaneously, the offered anonymity raises significant\nquestions about potential misuse. In this study, we explore methods that\nmalicious actors can exploit IPFS to upload and disseminate harmful content\nwhile remaining anonymous. We evaluate the role of pinning services and public\ngateways, identifying their capabilities and limitations in maintaining content\navailability. Using scripts, we systematically test the behavior of these\nservices by uploading malicious files. Our analysis reveals that pinning\nservices and public gateways lack mechanisms to assess or restrict the\npropagation of malicious content.", "AI": {"title_translation": "你好，你不会告诉我你的名字吗？：调查 IPFS 中的匿名滥用", "tldr": "IPFS的匿名性可能被滥用以传播恶意内容，且现有服务缺乏限制机制。", "motivation": "IPFS提供匿名性，但引发了关于潜在滥用的问题。本研究旨在探索恶意行为者如何利用IPFS匿名上传和传播有害内容。", "method": "研究人员通过使用脚本系统测试了固定服务和公共网关的行为，上传恶意文件以评估它们在维护内容可用性方面的能力和限制。", "result": "分析显示，固定服务和公共网关缺乏评估或限制恶意内容传播的机制。", "conclusion": "IPFS的固定服务和公共网关未能有效阻止恶意内容的传播，其匿名性被滥用。", "translation": "星际文件系统（IPFS）提供了一种去中心化的文件存储和共享方法，承诺弹性、效率，并实现Web3范式。同时，其提供的匿名性引发了关于潜在滥用的重大问题。在本研究中，我们探讨了恶意行为者如何利用IPFS匿名上传和传播有害内容的方法。我们评估了固定服务和公共网关的作用，确定了它们在维护内容可用性方面的能力和限制。通过使用脚本，我们系统地测试了这些服务的行为，上传恶意文件。我们的分析揭示，固定服务和公共网关缺乏评估或限制恶意内容传播的机制。", "summary": "本研究探讨了IPFS中匿名性被滥用于传播恶意内容的现象。通过系统测试固定服务和公共网关，发现它们缺乏有效机制来评估或限制恶意内容的传播。", "keywords": "IPFS, 匿名性, 滥用, 去中心化存储, 恶意内容"}}
{"id": "2506.04383", "pdf": "https://arxiv.org/pdf/2506.04383", "abs": "https://arxiv.org/abs/2506.04383", "authors": ["Mohamed Aly Bouke"], "title": "The Hashed Fractal Key Recovery (HFKR) Problem: From Symbolic Path Inversion to Post-Quantum Cryptographic Keys", "categories": ["cs.CR"], "comment": null, "summary": "Classical cryptographic systems rely heavily on structured algebraic\nproblems, such as factorization, discrete logarithms, or lattice-based\nassumptions, which are increasingly vulnerable to quantum attacks and\nstructural cryptanalysis. In response, this work introduces the Hashed Fractal\nKey Recovery (HFKR) problem, a non-algebraic cryptographic construction\ngrounded in symbolic dynamics and chaotic perturbations. HFKR builds on the\nSymbolic Path Inversion Problem (SPIP), leveraging symbolic trajectories\ngenerated via contractive affine maps over $\\mathbb{Z}^2$, and compressing them\ninto fixed-length cryptographic keys using hash-based obfuscation. A key\ncontribution of this paper is the empirical confirmation that these symbolic\npaths exhibit fractal behavior, quantified via box counting dimension, path\ngeometry, and spatial density measures. The observed fractal dimension\nincreases with trajectory length and stabilizes near 1.06, indicating symbolic\nself-similarity and space-filling complexity, both of which reinforce the\nentropy foundation of the scheme. Experimental results across 250 perturbation\ntrials show that SHA3-512 and SHAKE256 amplify symbolic divergence effectively,\nachieving mean Hamming distances near 255, ideal bit-flip rates, and negligible\nentropy deviation. In contrast, BLAKE3 exhibits statistically uniform but\nweaker diffusion. These findings confirm that HFKR post-quantum security arises\nfrom the synergy between symbolic fractality and hash-based entropy\namplification. The resulting construction offers a lightweight, structure-free\nfoundation for secure key generation in adversarial settings without relying on\nalgebraic hardness assumptions.", "AI": {"title_translation": "哈希分形密钥恢复 (HFKR) 问题：从符号路径反演到后量子密码密钥", "tldr": "该研究引入了哈希分形密钥恢复 (HFKR) 问题，这是一种基于符号动力学和混沌扰动的非代数密码结构，旨在提供一种轻量级、无结构的后量子密钥生成方法，其安全性源于符号分形性和哈希熵放大。", "motivation": "经典密码系统（如基于因式分解、离散对数或格的系统）越来越容易受到量子攻击和结构密码分析的影响。", "method": "本文引入了哈希分形密钥恢复 (HFKR) 问题，这是一种基于符号动力学和混沌扰动的非代数密码结构。HFKR 建立在符号路径反演问题 (SPIP) 的基础上，利用$\\mathbb{Z}^2$上的收缩仿射映射生成的符号轨迹，并使用基于哈希的混淆将其压缩成固定长度的密码密钥。通过盒计数维度、路径几何和空间密度测量来量化这些符号路径的分形行为。实验中使用了 SHA3-512、SHAKE256 和 BLAKE3 进行哈希处理。", "result": "经验证实这些符号路径表现出分形行为，其分形维数随轨迹长度增加并稳定在 1.06 附近，这表明符号自相似性和空间填充复杂性，强化了方案的熵基础。在 250 次扰动试验中，SHA3-512 和 SHAKE256 有效地放大了符号发散，实现了接近 255 的平均汉明距离、理想的比特翻转率和可忽略的熵偏差。相比之下，BLAKE3 表现出统计上均匀但较弱的扩散。", "conclusion": "这些发现证实 HFKR 的后量子安全性源于符号分形性和基于哈希的熵放大的协同作用。由此产生的构造为对抗性环境中的安全密钥生成提供了一个轻量级、无结构的基础，而无需依赖代数硬度假设。", "translation": "经典密码系统严重依赖结构化代数问题，如因式分解、离散对数或基于格的假设，这些问题越来越容易受到量子攻击和结构密码分析的影响。为此，本工作引入了哈希分形密钥恢复 (HFKR) 问题，这是一种基于符号动力学和混沌扰动的非代数密码结构。HFKR 建立在符号路径反演问题 (SPIP) 的基础上，利用$\\mathbb{Z}^2$上的收缩仿射映射生成的符号轨迹，并使用基于哈希的混淆将其压缩成固定长度的密码密钥。本文的一个关键贡献是经验证实这些符号路径表现出分形行为，通过盒计数维度、路径几何和空间密度测量进行量化。观察到的分形维数随轨迹长度增加并稳定在 1.06 附近，这表明符号自相似性和空间填充复杂性，两者都强化了方案的熵基础。在 250 次扰动试验中的实验结果表明，SHA3-512 和 SHAKE256 有效地放大了符号发散，实现了接近 255 的平均汉明距离、理想的比特翻转率和可忽略的熵偏差。相比之下，BLAKE3 表现出统计上均匀但较弱的扩散。这些发现证实 HFKR 的后量子安全性源于符号分形性和基于哈希的熵放大的协同作用。由此产生的构造为对抗性环境中的安全密钥生成提供了一个轻量级、无结构的基础，而无需依赖代数硬度假设。", "summary": "本文提出了哈希分形密钥恢复（HFKR）问题，这是一种应对量子攻击的新型非代数密码构造。HFKR 基于符号路径反演问题，通过收缩仿射映射生成符号轨迹并利用哈希函数进行密钥压缩。研究证实这些符号路径具有分形特性，且哈希函数如 SHA3-512 和 SHAKE256 能有效增强其熵，从而提供一种轻量级、不依赖代数困难假设的后量子安全密钥生成方案。", "keywords": "后量子密码学, 分形密钥恢复, 符号动力学, 哈希函数, 密钥生成"}}
{"id": "2506.04390", "pdf": "https://arxiv.org/pdf/2506.04390", "abs": "https://arxiv.org/abs/2506.04390", "authors": ["Sarthak Choudhary", "Nils Palumbo", "Ashish Hooda", "Krishnamurthy Dj Dvijotham", "Somesh Jha"], "title": "Through the Stealth Lens: Rethinking Attacks and Defenses in RAG", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) systems are vulnerable to attacks that\ninject poisoned passages into the retrieved set, even at low corruption rates.\nWe show that existing attacks are not designed to be stealthy, allowing\nreliable detection and mitigation. We formalize stealth using a\ndistinguishability-based security game. If a few poisoned passages are designed\nto control the response, they must differentiate themselves from benign ones,\ninherently compromising stealth. This motivates the need for attackers to\nrigorously analyze intermediate signals involved in\ngeneration$\\unicode{x2014}$such as attention patterns or next-token probability\ndistributions$\\unicode{x2014}$to avoid easily detectable traces of\nmanipulation. Leveraging attention patterns, we propose a passage-level\nscore$\\unicode{x2014}$the Normalized Passage Attention\nScore$\\unicode{x2014}$used by our Attention-Variance Filter algorithm to\nidentify and filter potentially poisoned passages. This method mitigates\nexisting attacks, improving accuracy by up to $\\sim 20 \\%$ over baseline\ndefenses. To probe the limits of attention-based defenses, we craft stealthier\nadaptive attacks that obscure such traces, achieving up to $35 \\%$ attack\nsuccess rate, and highlight the challenges in improving stealth.", "AI": {"title_translation": "通过隐形视角：重新思考RAG中的攻击与防御", "tldr": "RAG系统易受隐蔽攻击，本文提出一种基于注意力模式的防御机制，并探讨了更隐蔽的攻击方式。", "motivation": "检索增强生成（RAG）系统容易受到注入毒性段落的攻击，且现有攻击缺乏隐蔽性，易于检测和缓解。", "method": "通过基于可区分性的安全博弈形式化隐蔽性；提出了一种基于注意力模式的段落级分数——归一化段落注意力分数；开发了注意力方差过滤器算法来识别和过滤潜在的毒性段落；为了探究注意力防御的极限，设计了更隐蔽的自适应攻击。", "result": "提出的防御方法可以缓解现有攻击，相比基线防御将准确性提高约20%；自适应攻击的成功率高达35%，突出了提高隐蔽性的挑战。", "conclusion": "毒性段落若想控制响应，必须与良性段落区分开来，这必然会损害隐蔽性。攻击者需要严格分析生成过程中的中间信号，以避免易于检测的操纵痕迹。提高攻击隐蔽性面临挑战。", "translation": "检索增强生成（RAG）系统容易受到攻击，即使在低损坏率下，攻击者也能将毒性段落注入检索到的集合中。我们发现现有攻击并非设计为隐蔽的，这使得它们能够被可靠地检测和缓解。我们通过基于可区分性的安全博弈来形式化隐蔽性。如果少数毒性段落旨在控制响应，它们必须与良性段落区分开来，这必然会损害隐蔽性。这促使攻击者需要严格分析生成过程中涉及的中间信号——例如注意力模式或下一词元概率分布——以避免容易被检测到的操纵痕迹。利用注意力模式，我们提出了一种段落级分数——归一化段落注意力分数（Normalized Passage Attention Score）——由我们的注意力方差过滤器算法（Attention-Variance Filter）用于识别和过滤潜在的毒性段落。这种方法缓解了现有攻击，相比基线防御将准确性提高了约20%。为了探究注意力防御的极限，我们设计了更隐蔽的自适应攻击，这些攻击模糊了此类痕迹，攻击成功率高达35%，并强调了提高隐蔽性所面临的挑战。", "summary": "本文研究了检索增强生成（RAG）系统在面对毒性段落注入攻击时的脆弱性。研究指出现有攻击缺乏隐蔽性，并通过安全博弈形式化了隐蔽性。为防御此类攻击，论文提出了一种基于注意力模式的“归一化段落注意力分数”和“注意力方差过滤器算法”，有效缓解了现有攻击。同时，为了探索防御的极限，本文还设计了更具隐蔽性的自适应攻击，并强调了提高攻击隐蔽性的挑战。", "keywords": "RAG, 攻击, 防御, 隐蔽性, 注意力机制"}}
{"id": "2506.04450", "pdf": "https://arxiv.org/pdf/2506.04450", "abs": "https://arxiv.org/abs/2506.04450", "authors": ["Payel Bhattacharjee", "Fengwei Tian", "Ravi Tandon", "Joseph Lo", "Heidi Hanson", "Geoffrey Rubin", "Nirav Merchant", "John Gounley"], "title": "Learning to Diagnose Privately: DP-Powered LLMs for Radiology Report Classification", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": "19 pages, 5 figures, 2 tables", "summary": "Purpose: This study proposes a framework for fine-tuning large language\nmodels (LLMs) with differential privacy (DP) to perform multi-abnormality\nclassification on radiology report text. By injecting calibrated noise during\nfine-tuning, the framework seeks to mitigate the privacy risks associated with\nsensitive patient data and protect against data leakage while maintaining\nclassification performance. Materials and Methods: We used 50,232 radiology\nreports from the publicly available MIMIC-CXR chest radiography and CT-RATE\ncomputed tomography datasets, collected between 2011 and 2019. Fine-tuning of\nLLMs was conducted to classify 14 labels from MIMIC-CXR dataset, and 18 labels\nfrom CT-RATE dataset using Differentially Private Low-Rank Adaptation (DP-LoRA)\nin high and moderate privacy regimes (across a range of privacy budgets =\n{0.01, 0.1, 1.0, 10.0}). Model performance was evaluated using weighted F1\nscore across three model architectures: BERT-medium, BERT-small, and\nALBERT-base. Statistical analyses compared model performance across different\nprivacy levels to quantify the privacy-utility trade-off. Results: We observe a\nclear privacy-utility trade-off through our experiments on 2 different datasets\nand 3 different models. Under moderate privacy guarantees the DP fine-tuned\nmodels achieved comparable weighted F1 scores of 0.88 on MIMIC-CXR and 0.59 on\nCT-RATE, compared to non-private LoRA baselines of 0.90 and 0.78, respectively.\nConclusion: Differentially private fine-tuning using LoRA enables effective and\nprivacy-preserving multi-abnormality classification from radiology reports,\naddressing a key challenge in fine-tuning LLMs on sensitive medical data.", "AI": {"title_translation": "私密诊断学习：差分隐私驱动的LLMs用于放射学报告分类", "tldr": "本研究提出并评估了一个使用差分隐私（DP）技术微调大型语言模型（LLMs）的框架，旨在对放射学报告进行多异常分类，同时保护患者数据隐私。", "motivation": "旨在解决在敏感患者数据上微调大型语言模型（LLMs）时面临的隐私风险和数据泄露问题，确保数据隐私的同时维持分类性能。", "method": "使用来自MIMIC-CXR（50,232份报告，14个标签）和CT-RATE（18个标签）数据集的放射学报告，通过差分隐私低秩适应（DP-LoRA）技术在不同隐私预算（0.01, 0.1, 1.0, 10.0）下对BERT-medium, BERT-small和ALBERT-base三种LLM架构进行微调，并使用加权F1分数评估模型性能，比较不同隐私级别下的性能。", "result": "实验结果显示了明显的隐私-效用权衡。在中等隐私保障下，经过DP微调的模型在MIMIC-CXR数据集上达到了0.88的加权F1分数（非隐私基线为0.90），在CT-RATE数据集上达到了0.59的加权F1分数（非隐私基线为0.78）。", "conclusion": "使用LoRA进行差分隐私微调能够实现有效且保护隐私的放射学报告多异常分类，解决了在敏感医疗数据上微调LLMs的关键挑战。", "translation": "**目的：** 本研究提出了一种使用差分隐私（DP）微调大型语言模型（LLMs）的框架，以对放射学报告文本进行多异常分类。通过在微调过程中注入校准噪声，该框架旨在减轻与敏感患者数据相关的隐私风险，并防止数据泄露，同时保持分类性能。**材料与方法：** 我们使用了2011年至2019年间收集的来自公开MIMIC-CXR胸部X射线和CT-RATE计算机断层扫描数据集的50,232份放射学报告。LLM的微调旨在对MIMIC-CXR数据集中的14个标签和CT-RATE数据集中的18个标签进行分类，使用了高和中等隐私制度下的差分隐私低秩适应（DP-LoRA）（隐私预算范围为{0.01, 0.1, 1.0, 10.0}）。模型性能使用加权F1分数在三种模型架构上进行评估：BERT-medium、BERT-small和ALBERT-base。统计分析比较了不同隐私级别下的模型性能，以量化隐私-效用权衡。**结果：** 通过在2个不同数据集和3个不同模型上的实验，我们观察到了明显的隐私-效用权衡。在中等隐私保障下，经过DP微调的模型在MIMIC-CXR上达到了0.88的加权F1分数，在CT-RATE上达到了0.59的加权F1分数，而相应的非隐私LoRA基线分别为0.90和0.78。**结论：** 使用LoRA进行差分隐私微调能够实现有效且保护隐私的放射学报告多异常分类，解决了在敏感医疗数据上微调LLMs的关键挑战。", "summary": "本研究提出了一种利用差分隐私（DP）技术微调大型语言模型（LLMs）的框架，用于放射学报告的多异常分类。该框架通过在微调过程中注入校准噪声来缓解敏感患者数据的隐私风险。研究人员在MIMIC-CXR和CT-RATE数据集上，使用DP-LoRA对BERT和ALBERT模型进行了实验，并在不同隐私预算下评估了性能。结果表明，DP微调模型在保持隐私的同时，性能与非隐私基线相当，验证了该方法在保护医疗数据隐私方面的有效性。", "keywords": "差分隐私, 大型语言模型, 放射学报告, 多异常分类, 医疗数据隐私"}}
{"id": "2506.04236", "pdf": "https://arxiv.org/pdf/2506.04236", "abs": "https://arxiv.org/abs/2506.04236", "authors": ["Botao Amber Hu", "Helena Rong"], "title": "Spore in the Wild: Case Study on Spore.fun, a Real-World Experiment of Sovereign Agent Open-ended Evolution on Blockchain with TEEs", "categories": ["cs.MA", "cs.AI", "cs.HC", "cs.NE"], "comment": "Submitted to ALIFE 2025", "summary": "In Artificial Life (ALife) research, replicating Open-Ended Evolution\n(OEE)-the continuous emergence of novelty observed in biological life-has\ntraditionally been pursued within isolated closed system simulations, such as\nTierra and Avida, which have typically plateaued after an initial burst of\nnovelty, failing to achieve sustained OEE. Scholars suggest that OEE requires\nan \"open\" system that continually exchanges information or energy with its\nenvironment. A recent technological innovation in decentralized physical\ninfrastructure networks (DePIN) providing permissionless computational\nsubstrates enables deploying large language model (LLM)-based AI agents on\nblockchains integrated with Trusted Execution Environments (TEEs). This enables\non-chain agents to operate autonomously \"in the wild,\" achieving\nself-sovereignty without human oversight. These agents can control their own\nsocial media accounts and cryptocurrency wallets, allowing them to interact\ndirectly with blockchain-based financial networks and broader human social\nmedia. Building on this new paradigm of on-chain agents, Spore.fun is a recent\nreal-world AI evolution experiment that enables autonomous breeding and\nevolution of new on-chain agents. This paper presents a detailed case study of\nSpore.fun, examining agent behaviors and their evolutionary trajectories\nthrough digital ethology. We aim to spark discussion about whether \"open\" ALife\nsystems \"in-the-wild,\" based on permissionless computational substrates and\ndriven by economic incentives to interact with their environment, could finally\nachieve the long-sought goal of OEE.", "AI": {"title_translation": "野外孢子：Spore.fun案例研究，一个基于区块链和TEE的主权代理开放式进化现实世界实验", "tldr": "Spore.fun是一个在区块链和TEE上实现自主代理开放式进化的实验，旨在探索“野外”开放系统能否实现OEE。", "motivation": "传统的人工生命开放式进化（OEE）研究在封闭系统中未能实现持续的OEE，而学者认为OEE需要“开放”系统。去中心化物理基础设施网络（DePIN）和可信执行环境（TEE）的出现，使得在区块链上部署自主AI代理成为可能，为实现“野外”OEE提供了新的范式。", "method": "本文通过对Spore.fun进行详细的案例研究，并采用数字行为学方法，检查代理行为及其进化轨迹。", "result": "摘要中未明确提及具体结果，而是指出该研究旨在引发关于“野外”开放式ALife系统能否实现OEE的讨论。", "conclusion": "摘要中未明确提及具体结论，而是提出一个开放性问题，即基于许可无需计算基底和经济激励的“野外”开放式ALife系统是否能最终实现OEE的长期目标。", "translation": "在人工智能生命（ALife）研究中，复制开放式进化（OEE）——生物生命中观察到的新颖性持续涌现——传统上是在孤立的封闭系统模拟中进行的，例如Tierra和Avida，这些系统通常在最初的新颖性爆发后趋于平稳，未能实现持续的OEE。学者们认为，OEE需要一个持续与环境交换信息或能量的“开放”系统。去中心化物理基础设施网络（DePIN）中提供无需许可计算基底的最新技术创新，使得在集成可信执行环境（TEE）的区块链上部署基于大型语言模型（LLM）的AI代理成为可能。这使得链上代理能够“在野外”自主运行，无需人工监督即可实现主权。这些代理可以控制自己的社交媒体账户和加密货币钱包，从而可以直接与基于区块链的金融网络和更广泛的人类社交媒体互动。Spore.fun是基于这种链上代理新范式的一个近期现实世界AI进化实验，它实现了新链上代理的自主繁殖和进化。本文详细介绍了Spore.fun的案例研究，通过数字行为学检查代理行为及其进化轨迹。我们旨在引发关于基于无需许可计算基底和由经济激励驱动与环境互动的“野外”开放式ALife系统是否能最终实现长期寻求的OEE目标的讨论。", "summary": "本文介绍了Spore.fun，一个在区块链和可信执行环境（TEE）上实现的现实世界AI进化实验，旨在探索自主代理的开放式进化。针对传统人工生命（ALife）研究中封闭系统未能实现持续开放式进化（OEE）的问题，该研究利用DePIN技术部署自主链上代理，使其能在“野外”自主运行并与环境互动。通过对Spore.fun的案例研究，本文旨在引发关于这种“野外”开放系统能否最终实现OEE目标的讨论。", "keywords": "开放式进化, 区块链, 自主代理, 可信执行环境, 人工生命"}}
{"id": "2506.04308", "pdf": "https://arxiv.org/pdf/2506.04308", "abs": "https://arxiv.org/abs/2506.04308", "authors": ["Enshen Zhou", "Jingkun An", "Cheng Chi", "Yi Han", "Shanyu Rong", "Chi Zhang", "Pengwei Wang", "Zhongyuan Wang", "Tiejun Huang", "Lu Sheng", "Shanghang Zhang"], "title": "RoboRefer: Towards Spatial Referring with Reasoning in Vision-Language Models for Robotics", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Project page: https://zhoues.github.io/RoboRefer/", "summary": "Spatial referring is a fundamental capability of embodied robots to interact\nwith the 3D physical world. However, even with the powerful pretrained vision\nlanguage models (VLMs), recent approaches are still not qualified to accurately\nunderstand the complex 3D scenes and dynamically reason about the\ninstruction-indicated locations for interaction. To this end, we propose\nRoboRefer, a 3D-aware VLM that can first achieve precise spatial understanding\nby integrating a disentangled but dedicated depth encoder via supervised\nfine-tuning (SFT). Moreover, RoboRefer advances generalized multi-step spatial\nreasoning via reinforcement fine-tuning (RFT), with metric-sensitive process\nreward functions tailored for spatial referring tasks. To support SFT and RFT\ntraining, we introduce RefSpatial, a large-scale dataset of 20M QA pairs (2x\nprior), covering 31 spatial relations (vs. 15 prior) and supporting complex\nreasoning processes (up to 5 steps). In addition, we introduce\nRefSpatial-Bench, a challenging benchmark filling the gap in evaluating spatial\nreferring with multi-step reasoning. Experiments show that SFT-trained\nRoboRefer achieves state-of-the-art spatial understanding, with an average\nsuccess rate of 89.6%. RFT-trained RoboRefer further outperforms all other\nbaselines by a large margin, even surpassing Gemini-2.5-Pro by 17.4% in average\naccuracy on RefSpatial-Bench. Notably, RoboRefer can be integrated with various\ncontrol policies to execute long-horizon, dynamic tasks across diverse robots\n(e,g., UR5, G1 humanoid) in cluttered real-world scenes.", "AI": {"title_translation": "RoboRefer: 迈向机器人视觉-语言模型中带推理的空间指向", "tldr": "RoboRefer是一个3D感知的VLM，通过SFT实现精确空间理解，通过RFT实现多步空间推理，并在新的RefSpatial数据集和RefSpatial-Bench上表现出色。", "motivation": "现有的VLM在理解复杂3D场景和动态推理指令指示的位置方面不足，无法准确支持具身机器人与3D物理世界的交互。", "method": "本文提出了RoboRefer，一个3D感知的VLM。它通过集成解耦但专用的深度编码器并进行监督微调（SFT）实现精确空间理解。此外，RoboRefer通过强化微调（RFT）实现泛化多步空间推理，并采用针对空间指向任务的度量敏感过程奖励函数。为支持SFT和RFT训练，本文引入了RefSpatial数据集（20M QA对，31种空间关系，支持多步推理）和RefSpatial-Bench基准测试。", "result": "SFT训练的RoboRefer在空间理解方面达到SOTA，平均成功率为89.6%。RFT训练的RoboRefer在RefSpatial-Bench上大幅超越所有基线，甚至比Gemini-2.5-Pro高出17.4%的平均准确率。RoboRefer可与各种控制策略集成，执行长周期、动态任务。", "conclusion": "RoboRefer通过结合3D感知和多步空间推理，显著提升了VLM在机器人空间指向任务中的表现，并能应用于真实的机器人系统。", "translation": "空间指向是具身机器人与3D物理世界交互的基本能力。然而，即使拥有强大的预训练视觉-语言模型（VLM），现有方法仍然无法准确理解复杂的3D场景，也无法动态推理指令指示的交互位置。为此，我们提出了RoboRefer，一个3D感知的VLM，它首先通过集成解耦但专用的深度编码器并进行监督微调（SFT）来实现精确的空间理解。此外，RoboRefer通过强化微调（RFT）提升了泛化多步空间推理能力，并采用了针对空间指向任务的度量敏感过程奖励函数。为了支持SFT和RFT训练，我们引入了RefSpatial，一个大规模数据集，包含2000万个问答对（是现有数据集的两倍），涵盖31种空间关系（是现有数据集的两倍），并支持复杂推理过程（最多5步）。此外，我们还引入了RefSpatial-Bench，一个具有挑战性的基准测试，填补了评估带多步推理的空间指向任务的空白。实验表明，经过SFT训练的RoboRefer在空间理解方面达到了最先进水平，平均成功率为89.6%。经过RFT训练的RoboRefer进一步大幅超越所有其他基线，甚至在RefSpatial-Bench上的平均准确率比Gemini-2.5-Pro高出17.4%。值得注意的是，RoboRefer可以与各种控制策略集成，在杂乱的真实世界场景中跨不同机器人（例如UR5、G1人形机器人）执行长周期、动态任务。", "summary": "本文提出了RoboRefer，一个3D感知的视觉-语言模型，旨在解决现有VLM在复杂3D场景中进行精确空间理解和多步推理的不足。RoboRefer通过监督微调（SFT）集成深度编码器以实现精确空间理解，并通过强化微调（RFT）提升多步空间推理能力。为支持训练，作者构建了大规模RefSpatial数据集和RefSpatial-Bench基准。实验结果表明，RoboRefer在空间理解和多步推理方面均取得了最先进的性能，且能与多种机器人控制策略集成以执行实际任务。", "keywords": "空间指向, 视觉-语言模型, 机器人, 3D感知, 强化学习"}}
{"id": "2506.04271", "pdf": "https://arxiv.org/pdf/2506.04271", "abs": "https://arxiv.org/abs/2506.04271", "authors": ["Annamaria Defilippo", "Ugo Lomoio", "Barbara Puccio", "Pierangelo Veltri", "Pietro Hiram Guzzi"], "title": "ExDiff: A Framework for Simulating Diffusion Processes on Complex Networks with Explainable AI Integration", "categories": ["cs.SI"], "comment": null, "summary": "Understanding and controlling diffusion processes in complex networks is\ncritical across domains ranging from epidemiology to information science. Here,\nwe present ExDiff, an interactive and modular computational framework that\nintegrates network simulation, graph neural networks (GNNs), and explainable\nartificial intelligence (XAI) to model and interpret diffusion dynamics. ExDiff\ncombines classical compartmental models with deep learning techniques to\ncapture both the structural and temporal characteristics of diffusion across\ndiverse network topologies. The framework features dedicated modules for\nnetwork analysis, neural modeling, simulation, and interpretability, all\naccessible via an intuitive interface built on Google Colab. Through a case\nstudy of the Susceptible Infectious Recovered Vaccinated Dead (SIRVD) model, we\ndemonstrate the capacity to simulate disease spread, evaluate intervention\nstrategies, classify node states, and reveal the structural determinants of\ncontagion through XAI techniques. By unifying simulation and interpretability,\nExDiff provides a powerful, flexible, and accessible platform for studying\ndiffusion phenomena in networked systems, enabling both methodological\ninnovation and practical insight.", "AI": {"title_translation": "ExDiff：一个集成可解释AI的复杂网络扩散过程模拟框架", "tldr": "ExDiff是一个集成了网络模拟、图神经网络和可解释AI的计算框架，用于建模和解释复杂网络中的扩散动力学，并能模拟疾病传播、评估干预策略和揭示结构决定因素。", "motivation": "理解和控制复杂网络中的扩散过程在流行病学到信息科学等领域都至关重要。", "method": "ExDiff是一个交互式、模块化的计算框架，它集成了网络模拟、图神经网络（GNNs）和可解释人工智能（XAI）来建模和解释扩散动力学。它结合了经典隔室模型和深度学习技术，以捕捉不同网络拓扑中扩散的结构和时间特征。该框架包含网络分析、神经建模、模拟和可解释性专用模块，并通过Google Colab上的直观界面访问。", "result": "通过对易感-感染-康复-疫苗接种-死亡（SIRVD）模型的案例研究，ExDiff展示了模拟疾病传播、评估干预策略、分类节点状态以及通过XAI技术揭示传染结构决定因素的能力。", "conclusion": "ExDiff通过统一模拟和可解释性，为研究网络系统中的扩散现象提供了一个强大、灵活且易于访问的平台，从而实现方法论创新和实践洞察。", "translation": "理解和控制复杂网络中的扩散过程在流行病学到信息科学等领域都至关重要。本文提出了ExDiff，一个交互式、模块化的计算框架，它集成了网络模拟、图神经网络（GNNs）和可解释人工智能（XAI）来建模和解释扩散动力学。ExDiff将经典隔室模型与深度学习技术相结合，以捕捉不同网络拓扑中扩散的结构和时间特征。该框架具有网络分析、神经建模、模拟和可解释性专用模块，所有这些都可通过基于Google Colab的直观界面访问。通过对易感-感染-康复-疫苗接种-死亡（SIRVD）模型的案例研究，我们展示了其模拟疾病传播、评估干预策略、分类节点状态以及通过XAI技术揭示传染结构决定因素的能力。通过统一模拟和可解释性，ExDiff为研究网络系统中的扩散现象提供了一个强大、灵活且易于访问的平台，从而实现方法论创新和实践洞察。", "summary": "ExDiff是一个创新的计算框架，旨在通过整合网络模拟、图神经网络和可解释人工智能来深入理解和控制复杂网络中的扩散过程。它结合了传统模型和深度学习，能够捕捉扩散的结构和时间特性。该框架提供模块化的功能，用于网络分析、建模、模拟和解释。通过SIRVD模型案例，ExDiff证明了其在疾病传播模拟、干预策略评估和揭示传染结构决定因素方面的能力，为研究扩散现象提供了一个统一且强大的平台。", "keywords": "扩散过程, 复杂网络, 可解释人工智能, 图神经网络, 模拟"}}
{"id": "2506.04418", "pdf": "https://arxiv.org/pdf/2506.04418", "abs": "https://arxiv.org/abs/2506.04418", "authors": ["Noor Nashid", "Daniel Ding", "Keheliya Gallaba", "Ahmed E. Hassan", "Ali Mesbah"], "title": "Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair Challenges", "categories": ["cs.SE"], "comment": null, "summary": "Multi-hunk bugs, where fixes span disjoint regions of code, are common in\npractice, yet remain underrepresented in automated repair. Existing techniques\nand benchmarks pre-dominantly target single-hunk scenarios, overlooking the\nadded complexity of coordinating semantically related changes across the\ncodebase. In this work, we characterize HUNK4J, a dataset of multi-hunk patches\nderived from 372 real-world defects. We propose hunk divergence, a metric that\nquantifies the variation among edits in a patch by capturing lexical,\nstructural, and file-level differences, while incorporating the number of hunks\ninvolved. We further define spatial proximity, a classification that models how\nhunks are spatially distributed across the program hierarchy. Our empirical\nstudy spanning six LLMs reveals that model success rates decline with increased\ndivergence and spatial dispersion. Notably, when using the LLM alone, no model\nsucceeds in the most dispersed Fragment class. These findings highlight a\ncritical gap in LLM capabilities and motivate divergence-aware repair\nstrategies.", "AI": {"title_translation": "多Hunk补丁的特征分析：差异性、邻近性与LLM修复挑战", "tldr": "本文分析了多Hunk补丁的特点，发现LLM在修复这些复杂bug时表现不佳，并提出了分歧感知的修复策略。", "motivation": "自动化修复中多Hunk错误被低估，现有技术和基准主要针对单Hunk场景，忽略了协调跨代码库语义相关更改的额外复杂性。", "method": "本文对HUNK4J数据集（包含372个真实缺陷的多Hunk补丁）进行了表征。提出了Hunk分歧度量，量化补丁中编辑的变异。定义了空间邻近度分类，模拟Hunk在程序层次结构中的空间分布。对六个LLM进行了实证研究。", "result": "模型成功率随分歧度增加和空间分散度增加而下降。在最分散的Fragment类别中，LLM单独使用时没有模型成功。", "conclusion": "这些发现突出了LLM能力的关键缺陷，并激励了分歧感知的修复策略。", "translation": "多Hunk错误（即修复跨越不相交代码区域的错误）在实践中很常见，但在自动化修复中却未得到充分体现。现有技术和基准主要针对单Hunk场景，忽略了协调跨代码库语义相关更改的额外复杂性。在这项工作中，我们对HUNK4J进行了表征，这是一个由372个真实世界缺陷衍生的多Hunk补丁数据集。我们提出了Hunk分歧，这是一个通过捕获词法、结构和文件级差异来量化补丁中编辑变异的指标，同时结合了所涉及的Hunk数量。我们进一步定义了空间邻近度，这是一种模拟Hunk在程序层次结构中空间分布的分类。我们对六个大型语言模型（LLM）进行的实证研究表明，模型成功率随着分歧和空间分散的增加而下降。值得注意的是，当单独使用LLM时，在最分散的Fragment类别中没有模型成功。这些发现突出了LLM能力的关键差距，并促进了分歧感知的修复策略。", "summary": "本文旨在解决自动化修复中多Hunk错误的不足，这些错误因其跨代码区域的复杂性而未被充分研究。作者表征了HUNK4J数据集，提出了Hunk分歧度量和空间邻近度分类来量化补丁中编辑的变化和Hunk的空间分布。实证研究表明，LLM在修复多Hunk补丁时，其成功率随分歧度和空间分散度的增加而下降，特别是在最分散的场景下，LLM无法成功修复。研究结果揭示了LLM在处理复杂多Hunk错误方面的局限性，并强调了开发分歧感知修复策略的必要性。", "keywords": "多Hunk补丁, LLM修复, Hunk分歧, 空间邻近度, HUNK4J"}}
{"id": "2506.04404", "pdf": "https://arxiv.org/pdf/2506.04404", "abs": "https://arxiv.org/abs/2506.04404", "authors": ["Diana Nunes", "Ricardo Amorim", "Pedro Ribeiro", "André Coelho", "Rui Campos"], "title": "A Framework Leveraging Large Language Models for Autonomous UAV Control in Flying Networks", "categories": ["cs.NI", "cs.RO"], "comment": "6 pages, 3 figures, 6 tables", "summary": "This paper proposes FLUC, a modular framework that integrates open-source\nLarge Language Models (LLMs) with Unmanned Aerial Vehicle (UAV) autopilot\nsystems to enable autonomous control in Flying Networks (FNs). FLUC translates\nhigh-level natural language commands into executable UAV mission code, bridging\nthe gap between operator intent and UAV behaviour.\n  FLUC is evaluated using three open-source LLMs - Qwen 2.5, Gemma 2, and LLaMA\n3.2 - across scenarios involving code generation and mission planning. Results\nshow that Qwen 2.5 excels in multi-step reasoning, Gemma 2 balances accuracy\nand latency, and LLaMA 3.2 offers faster responses with lower logical\ncoherence. A case study on energy-aware UAV positioning confirms FLUC's ability\nto interpret structured prompts and autonomously execute domain-specific logic,\nshowing its effectiveness in real-time, mission-driven control.", "AI": {"title_translation": "一个利用大型语言模型实现飞行网络中无人机自主控制的框架", "tldr": "FLUC是一个利用LLM实现飞行网络中无人机自主控制的框架，通过自然语言命令生成任务代码，并评估了不同LLM的性能。", "motivation": "弥合操作员意图与无人机行为之间的差距，实现通过自然语言命令对无人机进行自主控制。", "method": "提出FLUC模块化框架，将开源大型语言模型(LLM)与无人机自动驾驶系统集成。使用Qwen 2.5、Gemma 2和LLaMA 3.2三种开源LLM进行代码生成和任务规划场景的评估。", "result": "Qwen 2.5在多步推理中表现出色；Gemma 2在准确性和延迟之间取得平衡；LLaMA 3.2响应更快但逻辑连贯性较低。能量感知无人机定位案例研究证实FLUC能解释结构化提示并自主执行领域特定逻辑，在实时、任务驱动控制中有效。", "conclusion": "FLUC框架能有效利用大型语言模型实现飞行网络中无人机的自主、实时、任务驱动控制。", "translation": "本文提出了FLUC，一个模块化框架，它将开源大型语言模型（LLMs）与无人机（UAV）自动驾驶系统集成，以在飞行网络（FNs）中实现自主控制。FLUC将高级自然语言命令转换为可执行的无人机任务代码，弥合了操作员意图与无人机行为之间的差距。FLUC使用三种开源LLM——Qwen 2.5、Gemma 2和LLaMA 3.2——在涉及代码生成和任务规划的场景中进行了评估。结果显示，Qwen 2.5在多步推理中表现出色，Gemma 2在准确性和延迟之间取得了平衡，而LLaMA 3.2则提供更快的响应速度但逻辑连贯性较低。一项关于能量感知无人机定位的案例研究证实了FLUC解释结构化提示并自主执行领域特定逻辑的能力，表明其在实时、任务驱动控制中的有效性。", "summary": "本文提出FLUC框架，该框架将大型语言模型与无人机自动驾驶系统结合，使无人机能通过自然语言命令实现自主控制。通过对Qwen 2.5、Gemma 2和LLaMA 3.2三种开源LLM在代码生成和任务规划场景中的评估，揭示了它们各自的特点。案例研究进一步验证了FLUC在实时任务驱动控制中的有效性。", "keywords": "大型语言模型, 无人机控制, 飞行网络, 自主系统, 框架"}}
{"id": "2506.04244", "pdf": "https://arxiv.org/pdf/2506.04244", "abs": "https://arxiv.org/abs/2506.04244", "authors": ["Farzad Farhadzadeh", "Debasmit Das", "Shubhankar Borse", "Fatih Porikli"], "title": "Zero-Shot Adaptation of Parameter-Efficient Fine-Tuning in Diffusion Models", "categories": ["cs.AI"], "comment": "ICML 2025", "summary": "We introduce ProLoRA, enabling zero-shot adaptation of parameter-efficient\nfine-tuning in text-to-image diffusion models. ProLoRA transfers pre-trained\nlow-rank adjustments (e.g., LoRA) from a source to a target model without\nadditional training data. This overcomes the limitations of traditional methods\nthat require retraining when switching base models, often challenging due to\ndata constraints. ProLoRA achieves this via projection of source adjustments\ninto the target model's weight space, leveraging subspace and null space\nsimilarities and selectively targeting aligned layers. Evaluations on\nestablished text-to-image models demonstrate successful knowledge transfer and\ncomparable performance without retraining.", "AI": {"title_translation": "扩散模型中参数高效微调的零样本适应", "tldr": "ProLoRA 实现了扩散模型中参数高效微调的零样本适应，无需额外训练即可将预训练的 LoRA 调整从源模型转移到目标模型。", "motivation": "传统方法在切换基础模型时需要重新训练，这通常受数据限制，而 ProLoRA 旨在克服这一限制。", "method": "ProLoRA 通过将源调整投影到目标模型的权重空间来实现，它利用子空间和零空间相似性并选择性地针对对齐层。", "result": "在已建立的文本到图像模型上的评估表明，ProLoRA 在不重新训练的情况下实现了成功的知识转移和可比较的性能。", "conclusion": "ProLoRA 能够实现扩散模型中参数高效微调的零样本适应，克服了传统方法在切换基础模型时的局限性，并在不重新训练的情况下取得了良好性能。", "translation": "我们引入了 ProLoRA，它使得文本到图像扩散模型中的参数高效微调能够实现零样本适应。ProLoRA 无需额外训练数据，即可将预训练的低秩调整（例如 LoRA）从源模型转移到目标模型。这克服了传统方法在切换基础模型时需要重新训练的局限性，而这通常由于数据限制而具有挑战性。ProLoRA 通过将源调整投影到目标模型的权重空间来实现这一点，它利用子空间和零空间相似性并选择性地针对对齐层。对已建立的文本到图像模型的评估表明，ProLoRA 在不重新训练的情况下实现了成功的知识转移和可比较的性能。", "summary": "本文介绍了 ProLoRA，一种在文本到图像扩散模型中实现参数高效微调零样本适应的方法。ProLoRA 能够将预训练的低秩调整（如 LoRA）从源模型转移到目标模型，而无需额外训练数据，从而克服了传统方法在切换基础模型时需要重新训练的限制。通过将源调整投影到目标模型的权重空间，利用子空间和零空间相似性并选择性地针对对齐层，ProLoRA 成功实现了知识转移和可比较的性能。", "keywords": "零样本适应, 参数高效微调, 扩散模型, LoRA, 知识转移"}}
{"id": "2506.04263", "pdf": "https://arxiv.org/pdf/2506.04263", "abs": "https://arxiv.org/abs/2506.04263", "authors": ["Alan Mitkiy", "James Smith", "Hana Satou", "Hiroshi Tanaka", "Emily Johnson", "F Monkey"], "title": "Dynamic Epsilon Scheduling: A Multi-Factor Adaptive Perturbation Budget for Adversarial Training", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Adversarial training is among the most effective strategies for defending\ndeep neural networks against adversarial examples. A key limitation of existing\nadversarial training approaches lies in their reliance on a fixed perturbation\nbudget, which fails to account for instance-specific robustness\ncharacteristics. While prior works such as IAAT and MMA introduce\ninstance-level adaptations, they often rely on heuristic or static\napproximations of data robustness. In this paper, we propose Dynamic Epsilon\nScheduling (DES), a novel framework that adaptively adjusts the adversarial\nperturbation budget per instance and per training iteration. DES integrates\nthree key factors: (1) the distance to the decision boundary approximated via\ngradient-based proxies, (2) prediction confidence derived from softmax entropy,\nand (3) model uncertainty estimated via Monte Carlo dropout. By combining these\ncues into a unified scheduling strategy, DES tailors the perturbation budget\ndynamically to guide more effective adversarial learning. Experimental results\non CIFAR-10 and CIFAR-100 show that our method consistently improves both\nadversarial robustness and standard accuracy compared to fixed-epsilon\nbaselines and prior adaptive methods. Moreover, we provide theoretical insights\ninto the stability and convergence of our scheduling policy. This work opens a\nnew avenue for instance-aware, data-driven adversarial training methods.", "AI": {"title_translation": "动态Epsilon调度：一种用于对抗训练的多因素自适应扰动预算", "tldr": "本文提出动态Epsilon调度（DES），通过整合决策边界距离、预测置信度和模型不确定性，为对抗训练自适应调整对抗扰动预算，从而提升对抗鲁棒性和标准准确性。", "motivation": "现有对抗训练方法依赖固定扰动预算，未能考虑实例特定的鲁棒性特征；尽管IAAT和MMA等先前的工作引入了实例级适应，但它们通常依赖于启发式或静态的数据鲁棒性近似。", "method": "本文提出动态Epsilon调度（DES），一个新颖的框架，它根据每个实例和每个训练迭代自适应调整对抗扰动预算。DES整合了三个关键因素：1) 通过基于梯度的代理近似的决策边界距离；2) 来自softmax熵的预测置信度；3) 通过蒙特卡洛dropout估计的模型不确定性。", "result": "在CIFAR-10和CIFAR-100上的实验结果表明，与固定epsilon基线和先前的自适应方法相比，DES一致地提高了对抗鲁棒性和标准准确性。", "conclusion": "DES通过实例感知、数据驱动的对抗训练方法开辟了新途径，并且提供了调度策略稳定性和收敛性的理论见解。", "translation": "对抗训练是防御深度神经网络对抗性示例的最有效策略之一。现有对抗训练方法的一个主要限制在于它们依赖于固定的扰动预算，这未能考虑实例特定的鲁棒性特征。虽然IAAT和MMA等先前的工作引入了实例级适应，但它们通常依赖于启发式或静态的数据鲁棒性近似。在本文中，我们提出了动态Epsilon调度（DES），一个新颖的框架，它根据每个实例和每个训练迭代自适应调整对抗扰动预算。DES整合了三个关键因素：(1) 通过基于梯度的代理近似的决策边界距离，(2) 源自softmax熵的预测置信度，以及 (3) 通过蒙特卡洛dropout估计的模型不确定性。通过将这些线索组合成一个统一的调度策略，DES动态地调整扰动预算，以指导更有效的对抗学习。在CIFAR-10和CIFAR-100上的实验结果表明，与固定epsilon基线和先前的自适应方法相比，我们的方法一致地提高了对抗鲁棒性和标准准确性。此外，我们提供了调度策略稳定性和收敛性的理论见解。这项工作为实例感知、数据驱动的对抗训练方法开辟了新途径。", "summary": "本文提出动态Epsilon调度（DES），一种针对对抗训练的创新框架，旨在解决现有方法中固定扰动预算的局限性。DES通过结合决策边界距离、预测置信度及模型不确定性这三个关键因素，实现了对每个实例和每个训练迭代的扰动预算的自适应调整。实验证明，DES在提升模型对抗鲁棒性和标准准确性方面均优于现有方法，并提供了理论支持，为未来的实例感知对抗训练研究奠定了基础。", "keywords": "对抗训练, 动态Epsilon调度, 扰动预算, 自适应, 鲁棒性"}}
{"id": "2506.04544", "pdf": "https://arxiv.org/pdf/2506.04544", "abs": "https://arxiv.org/abs/2506.04544", "authors": ["Charles Hong", "Brendan Roberts", "Huijae An", "Alex Um", "Advay Ratan", "Yakun Sophia Shao"], "title": "hdl2v: A Code Translation Dataset for Enhanced LLM Verilog Generation", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.PL"], "comment": null, "summary": "Large language models (LLMs) are playing an increasingly large role in\ndomains such as code generation, including hardware code generation, where\nVerilog is the key language. However, the amount of publicly available Verilog\ncode pales in comparison to the amount of code available for software languages\nlike Python. In this work, we present hdl2v (\"HDL-to-Verilog\"), a dataset which\nseeks to increase the amount of available human-written Verilog data by\ntranslating or compiling three other hardware description languages - VHDL,\nChisel, and PyMTL3 - to Verilog. Furthermore, we demonstrate the value of hdl2v\nin enhancing LLM Verilog generation by improving performance of a 32\nbillion-parameter open-weight model by up to 23% (pass@10) in VerilogEvalV2,\nwithout utilizing any data augmentation or knowledge distillation from larger\nmodels. We also show hdl2v's ability to boost the performance of a data\naugmentation-based fine-tuning approach by 63%. Finally, we characterize and\nanalyze our dataset to better understand which characteristics of\nHDL-to-Verilog datasets can be expanded upon in future work for even better\nperformance.", "AI": {"title_translation": "hdl2v: 用于增强LLM Verilog生成的代码翻译数据集", "tldr": "hdl2v是一个将其他硬件描述语言翻译成Verilog的数据集，用于提高LLM生成Verilog代码的性能。", "motivation": "现有公开的Verilog代码量远少于软件语言，限制了大型语言模型（LLM）在硬件代码生成领域的应用。", "method": "提出了hdl2v数据集，通过将VHDL、Chisel和PyMTL3这三种硬件描述语言翻译或编译成Verilog，以增加可用的手写Verilog数据。", "result": "hdl2v使一个320亿参数的开源模型在VerilogEvalV2上的性能提升了高达23% (pass@10)，并且在数据增强微调方法中性能提升了63%。", "conclusion": "hdl2v数据集能够显著提升大型语言模型（LLM）的Verilog代码生成能力，并为未来数据集的扩展提供了分析基础。", "translation": "大型语言模型（LLM）在代码生成等领域发挥着越来越大的作用，包括硬件代码生成，其中Verilog是关键语言。然而，公开可用的Verilog代码量与Python等软件语言的代码量相比相形见绌。在这项工作中，我们提出了hdl2v（“HDL-to-Verilog”），一个旨在通过将VHDL、Chisel和PyMTL3这三种其他硬件描述语言翻译或编译成Verilog来增加可用的人工编写Verilog数据的数据集。此外，我们证明了hdl2v在增强LLM Verilog生成方面的价值，通过在VerilogEvalV2中将一个320亿参数的开源模型的性能提高了高达23% (pass@10)，而没有利用任何数据增强或来自更大模型的知识蒸馏。我们还展示了hdl2v能够将基于数据增强的微调方法的性能提高63%。最后，我们对数据集进行了特征描述和分析，以更好地了解HDL-to-Verilog数据集的哪些特征可以在未来的工作中进行扩展，以获得更好的性能。", "summary": "本文介绍了hdl2v数据集，旨在通过将VHDL、Chisel和PyMTL3代码翻译为Verilog来弥补现有Verilog代码量不足的问题。实验表明，hdl2v显著提升了大型语言模型生成Verilog代码的性能，验证了其在硬件代码生成领域的价值。", "keywords": "hdl2v, Verilog生成, 代码翻译, LLM, 硬件描述语言"}}
{"id": "2506.04471", "pdf": "https://arxiv.org/pdf/2506.04471", "abs": "https://arxiv.org/abs/2506.04471", "authors": ["Xiaodan Shao", "Qijun Jiang", "Derrick Wing Kwan Ng", "Naofal Al-Dhahir"], "title": "Polarized 6D Movable Antenna for Wireless Communication: Channel Modeling and Optimization", "categories": ["cs.IT", "eess.SP", "math.IT"], "comment": "arXiv admin note: substantial text overlap with arXiv:2505.08070", "summary": "In this paper, we propose a novel polarized six-dimensional movable antenna\n(P-6DMA) to enhance the performance of wireless communication cost-effectively.\nSpecifically, the P-6DMA enables polarforming by adaptively tuning the\nantenna's polarization electrically as well as controls the antenna's rotation\nmechanically, thereby exploiting both polarization and spatial diversity to\nreconfigure wireless channels for improving communication performance. First,\nwe model the P-6DMA channel in terms of transceiver antenna polarforming\nvectors and antenna rotations. We then propose a new two-timescale transmission\nprotocol to maximize the weighted sum-rate for a P-6DMA-enhanced multiuser\nsystem. Specifically, antenna rotations at the base station (BS) are first\noptimized based on the statistical channel state information (CSI) of all\nusers, which varies at a much slower rate compared to their instantaneous CSI.\nThen, transceiver polarforming vectors are designed to cater to the\ninstantaneous CSI under the optimized BS antennas' rotations. Under the\npolarforming phase shift and amplitude constraints, a new polarforming and\nrotation joint design problem is efficiently addressed by a low-complexity\nalgorithm based on penalty dual decomposition, where the polarforming\ncoefficients are updated in parallel to reduce computational time. Simulation\nresults demonstrate the significant performance advantages of polarforming,\nantenna rotation, and their joint design in comparison with various benchmarks\nwithout polarforming or antenna rotation adaptation.", "AI": {"title_translation": "用于无线通信的极化六维可移动天线：信道建模与优化", "tldr": "提出了一种极化六维可移动天线（P-6DMA），通过极化成形和天线旋转，有效提升无线通信性能。", "motivation": "为了经济高效地增强无线通信性能，本研究提出了一种新型极化六维可移动天线（P-6DMA）。", "method": "该研究首先对P-6DMA信道进行了建模，然后提出了一种新的双时尺度传输协议，以最大化P-6DMA增强型多用户系统的加权和速率。具体而言，基站（BS）的天线旋转首先根据所有用户的统计信道状态信息（CSI）进行优化，随后设计收发器极化成形向量以适应瞬时CSI。极化成形和旋转的联合设计问题通过基于罚对偶分解的低复杂度算法有效解决。", "result": "仿真结果表明，与没有极化成形或天线旋转适应的各种基准相比，极化成形、天线旋转及其联合设计具有显著的性能优势。", "conclusion": "P-6DMA通过结合极化成形和天线旋转，能够有效利用极化和空间分集，从而重构无线信道并显著提高通信性能，实现经济高效的无线通信增强。", "translation": "本文提出了一种新型极化六维可移动天线（P-6DMA），旨在经济高效地增强无线通信性能。具体而言，P-6DMA通过自适应地电调天线极化实现极化成形，并机械控制天线旋转，从而利用极化和空间分集来重构无线信道，以提高通信性能。首先，我们根据收发器天线极化成形向量和天线旋转对P-6DMA信道进行建模。然后，我们提出了一种新的双时尺度传输协议，以最大化P-6DMA增强型多用户系统的加权和速率。具体而言，基站（BS）的天线旋转首先根据所有用户的统计信道状态信息（CSI）进行优化，其变化速率远低于瞬时CSI。然后，设计收发器极化成形向量以适应优化后的基站天线旋转下的瞬时CSI。在极化成形相移和幅度约束下，通过基于罚对偶分解的低复杂度算法有效解决了新的极化成形和旋转联合设计问题，其中极化成形系数并行更新以减少计算时间。仿真结果表明，与没有极化成形或天线旋转适应的各种基准相比，极化成形、天线旋转及其联合设计具有显著的性能优势。", "summary": "本论文提出了一种新颖的极化六维可移动天线（P-6DMA），旨在经济高效地提升无线通信性能。P-6DMA通过电调天线极化实现极化成形，并通过机械控制天线旋转，从而利用极化和空间分集来重构无线信道。研究建立了P-6DMA信道模型，并提出了一种双时尺度传输协议以最大化加权和速率。该协议首先优化基站天线旋转，然后设计收发器极化成形向量。极化成形和旋转的联合设计通过低复杂度算法解决。仿真结果验证了极化成形、天线旋转及其联合设计在提升性能方面的显著优势。", "keywords": "极化六维可移动天线, 信道建模, 极化成形, 天线旋转, 无线通信优化"}}
{"id": "2506.04237", "pdf": "https://arxiv.org/pdf/2506.04237", "abs": "https://arxiv.org/abs/2506.04237", "authors": ["Sanchit Sinha", "Aidong Zhang"], "title": "A Comprehensive Survey on the Risks and Limitations of Concept-based Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Concept-based Models are a class of inherently explainable networks that\nimprove upon standard Deep Neural Networks by providing a rationale behind\ntheir predictions using human-understandable `concepts'. With these models\nbeing highly successful in critical applications like medical diagnosis and\nfinancial risk prediction, there is a natural push toward their wider adoption\nin sensitive domains to instill greater trust among diverse stakeholders.\nHowever, recent research has uncovered significant limitations in the structure\nof such networks, their training procedure, underlying assumptions, and their\nsusceptibility to adversarial vulnerabilities. In particular, issues such as\nconcept leakage, entangled representations, and limited robustness to\nperturbations pose challenges to their reliability and generalization.\nAdditionally, the effectiveness of human interventions in these models remains\nan open question, raising concerns about their real-world applicability. In\nthis paper, we provide a comprehensive survey on the risks and limitations\nassociated with Concept-based Models. In particular, we focus on aggregating\ncommonly encountered challenges and the architecture choices mitigating these\nchallenges for Supervised and Unsupervised paradigms. We also examine recent\nadvances in improving their reliability and discuss open problems and promising\navenues of future research in this domain.", "AI": {"title_translation": "概念模型风险与局限性综合调查", "tldr": "本文全面调查了概念模型（一种可解释AI）的风险和局限性，包括概念泄露、纠缠表示、鲁棒性差等问题，并讨论了缓解策略和未来研究方向。", "motivation": "概念模型在医疗诊断和金融风险预测等关键应用中取得了成功，推动了其在敏感领域的广泛应用，以增强利益相关者的信任。然而，近期研究揭示了这些模型在结构、训练过程、基本假设及对抗性漏洞方面的显著局限性，因此需要对这些风险和局限性进行全面调查。", "method": "本文对概念模型相关的风险和局限性进行了全面调查。具体而言，文章侧重于汇总常见的挑战以及在有监督和无监督范式中缓解这些挑战的架构选择。此外，文章还考察了提高其可靠性的最新进展，并讨论了该领域的开放问题和未来有前景的研究方向。", "result": "调查结果揭示了概念模型存在的显著局限性，如概念泄露、纠缠表示和对扰动的鲁棒性有限，这些问题对其可靠性和泛化能力构成了挑战。此外，人类干预在这些模型中的有效性仍是一个开放问题，引发了对其实际应用性的担忧。文章汇总了常见的挑战，并探讨了在有监督和无监督范式中缓解这些挑战的架构选择。", "conclusion": "概念模型虽然具有可解释性，但在实际应用中面临诸多风险和局限性，包括概念泄露、表示纠缠和鲁棒性不足等。因此，需要进一步研究以提高其可靠性并解决人类干预有效性等开放问题。", "translation": "概念模型是一类本质上可解释的网络，通过使用人类可理解的“概念”提供其预测背后的基本原理，从而改进了标准深度神经网络。由于这些模型在医疗诊断和金融风险预测等关键应用中取得了巨大成功，因此自然而然地推动了它们在敏感领域的更广泛应用，以在不同的利益相关者之间建立更大的信任。然而，最近的研究揭示了此类网络结构、训练过程、基本假设及其对对抗性漏洞的敏感性方面存在的显著局限性。特别是，概念泄露、纠缠表示和对扰动的鲁棒性有限等问题对其可靠性和泛化能力构成了挑战。此外，人类干预在这些模型中的有效性仍然是一个悬而未决的问题，这引发了对其实际适用性的担忧。在本文中，我们对与概念模型相关的风险和局限性进行了全面调查。特别是，我们专注于汇总常见的挑战以及在有监督和无监督范式中缓解这些挑战的架构选择。我们还研究了提高其可靠性的最新进展，并讨论了该领域的开放问题和未来有前景的研究方向。", "summary": "概念模型作为一类可解释的人工智能，在关键应用中表现出色。然而，近期研究揭示了其在结构、训练和鲁棒性方面存在的显著风险和局限性，如概念泄露和表示纠缠。本文旨在全面调查这些风险和局限性，汇总常见挑战及其缓解策略，并探讨提高模型可靠性的最新进展、开放问题和未来研究方向。", "keywords": "概念模型, 可解释性, 风险, 局限性, 调查"}}
{"id": "2506.04260", "pdf": "https://arxiv.org/pdf/2506.04260", "abs": "https://arxiv.org/abs/2506.04260", "authors": ["Lin Kyi", "Cristiana Santos", "Sushil Ammanaghatta Shivakumar", "Franziska Roesner", "Asia Biega"], "title": "Turning to Online Forums for Legal Information: A Case Study of GDPR's Legitimate Interests", "categories": ["cs.CY", "cs.HC"], "comment": null, "summary": "Practitioners building online services and tools often turn to online forums\nsuch as Reddit, Law Stack Exchange, and Stack Overflow for legal guidance to\nensure compliance with the GDPR. The legal information presented in these\nforums directly impact present-day industry practitioner's decisions. Online\nforums can serve as gateways that, depending on the accuracy and quality of the\nanswers provided, may either support or undermine the protection of privacy and\ndata protection fundamental rights. However, there is a need for deeper\ninvestigation into practitioners' decision-making processes and their\nunderstanding of legal compliance.\n  Using GDPR's ``legitimate interests'' legal ground for processing personal\ndata as a case study, we investigate how practitioners use online forums to\nidentify common areas of confusion in applying legitimate interests in\npractice, and evaluate how legally sound online forum responses are. Our\nanalysis found that applying the ``legitimate interests'' legal basis is\ncomplex for practitioners, with important implications for how the GDPR is\nimplemented in practice. The legal analysis showed that crowdsourced legal\ninformation tends to be legally sound, though sometimes incomplete. We outline\nrecommendations to improve the quality of online forums by ensuring that\nresponses are more legally sound and comprehensive, enabling practitioners to\napply legitimate interests effectively in practice and uphold the GDPR.", "AI": {"title_translation": "寻求在线论坛获取法律信息：以GDPR合法权益为例", "tldr": "研究发现从业者在应用GDPR合法权益时遇到复杂性，在线论坛上的法律信息虽然通常可靠但有时不完整，需要改进以更好地支持GDPR合规。", "motivation": "从业者在构建在线服务和工具时，常求助于Reddit、Law Stack Exchange和Stack Overflow等在线论坛获取法律指导，以确保符合GDPR。这些论坛上的法律信息直接影响从业者的决策，其准确性和质量可能支持或损害隐私和数据保护基本权利。因此，有必要深入调查从业者的决策过程及其对法律合规的理解。", "method": "本研究以GDPR中处理个人数据的“合法权益”法律依据为案例研究，调查从业者如何使用在线论坛来识别在实践中应用合法权益时的常见困惑领域，并评估在线论坛回复的法律健全性。", "result": "分析发现，对从业者而言，应用“合法权益”法律依据是复杂的，这对GDPR在实践中的实施具有重要影响。法律分析表明，众包的法律信息通常是法律健全的，尽管有时不完整。", "conclusion": "论文提出了改进在线论坛质量的建议，通过确保回复更具法律健全性和全面性，使从业者能够在实践中有效应用合法权益并维护GDPR。", "translation": "构建在线服务和工具的从业者经常求助于Reddit、Law Stack Exchange和Stack Overflow等在线论坛，以获取法律指导，确保符合GDPR。这些论坛中呈现的法律信息直接影响当今行业从业者的决策。在线论坛可以作为门户，根据所提供答案的准确性和质量，它们可能支持或损害隐私和数据保护的基本权利。然而，有必要对从业者的决策过程及其对法律合规的理解进行更深入的调查。\n本研究以GDPR中处理个人数据的“合法权益”法律依据为案例研究，调查从业者如何使用在线论坛来识别在实践中应用合法权益时的常见困惑领域，并评估在线论坛回复的法律健全性。我们的分析发现，对从业者而言，应用“合法权益”法律依据是复杂的，这对GDPR在实践中的实施具有重要影响。法律分析表明，众包的法律信息通常是法律健全的，尽管有时不完整。我们提出了改进在线论坛质量的建议，通过确保回复更具法律健全性和全面性，使从业者能够在实践中有效应用合法权益并维护GDPR。", "summary": "本文研究了从业者如何利用在线论坛获取GDPR合规的法律信息，特别是针对“合法权益”这一法律依据。研究发现，从业者在应用“合法权益”时面临复杂性，且在线论坛上的众包法律信息虽然通常可靠，但存在不完整之处。文章最后提出了改进在线论坛法律信息质量的建议，以支持从业者更好地遵守GDPR。", "keywords": "GDPR, 合法权益, 在线论坛, 法律信息, 数据保护"}}
{"id": "2506.04368", "pdf": "https://arxiv.org/pdf/2506.04368", "abs": "https://arxiv.org/abs/2506.04368", "authors": ["Aayush Gupta", "Gopal Pandurangan"], "title": "Fully-Distributed Construction of Byzantine-Resilient Dynamic Peer-to-Peer Networks", "categories": ["cs.DC"], "comment": null, "summary": "We address a fundamental problem in Peer-to-Peer (P2P) networks, namely,\nconstructing and maintaining dynamic P2P overlay network topologies with\nessential properties such as connectivity, low diameter, and high expansion,\nthat are resilient to continuous high churn and the presence of a large number\nof malicious (Byzantine) nodes. Our main goal is to construct and maintain a\nsparse (bounded degree) expander topology despite high churn and a large number\nof Byzantine nodes. Such an expander topology has logarithmic diameter, high\nexpansion, and is robust to churn and the presence of a large number of bad\nnodes, and facilitates efficient and robust algorithms for fundamental problems\nin distributed computing, such as agreement, broadcasting, routing, etc.\n  Our main contribution is a randomized, fully-distributed dynamic P2P protocol\nthat works with only local initial knowledge and guarantees, with a high\nprobability, the maintenance of a constant degree graph with high expansion\neven under continuous churn and in the presence of a large number of Byzantine\nnodes. Our protocol can tolerate up to $o(n/poly\\log(n))$ Byzantine nodes\n(where $n$ is the stable network size). Our protocol is efficient, lightweight,\nand scalable, and it incurs only $O(poly\\log(n))$ overhead for topology\nmaintenance: only polylogarithmic (in $n$) bits need to be processed and sent\nby each honest node per round, and any honest node's computation cost per round\nis also polylogarithmic.\n  Our protocol can be used as a building block for solving fundamental\ndistributed computing problems in highly dynamic networks, such as Byzantine\nagreement and Byzantine leader election, and enables fast and scalable\nalgorithms for these problems.", "AI": {"title_translation": "拜占庭容错动态对等网络的完全分布式构建", "tldr": "该论文提出了一种随机的、完全分布式的P2P协议，用于在存在大量拜占庭节点和高流失率的情况下，构建并维护具有高扩展性和低直径的稀疏（有界度）动态P2P网络拓扑。", "motivation": "在P2P网络中，构建和维护具有连接性、低直径和高扩展性等基本属性的动态P2P覆盖网络拓扑是一个基本问题，这些拓扑需要能够抵御持续高流失率和大量恶意（拜占庭）节点的存在。这种拓扑结构有助于解决分布式计算中的基本问题，如一致性、广播、路由等，并实现高效和鲁棒的算法。", "method": "该论文提出了一种随机的、完全分布式的动态P2P协议。该协议仅使用局部初始知识，并能以高概率保证在持续流失和大量拜占庭节点存在的情况下，维护一个具有高扩展性的常数度图。该协议可以容忍多达o(n/polylog(n))的拜占庭节点，并且是高效、轻量级和可扩展的。", "result": "该协议能够以高概率维护一个具有高扩展性的常数度图，即使在持续流失和大量拜占庭节点存在的情况下。它能容忍多达o(n/polylog(n))的拜占庭节点。协议的拓扑维护开销仅为O(polylog(n))，每个诚实节点每轮只需处理和发送多对数（n）比特，计算成本也是多对数级的。", "conclusion": "该协议可以作为解决高度动态网络中基本分布式计算问题（如拜占庭一致性协议和拜占庭领导者选举）的构建模块，并为这些问题提供快速和可扩展的算法。", "translation": "我们解决了对等（P2P）网络中的一个基本问题，即构建和维护具有基本属性（如连接性、低直径和高扩展性）的动态P2P覆盖网络拓扑，这些拓扑能够抵御持续高流失率和大量恶意（拜占庭）节点的存在。我们的主要目标是，尽管存在高流失率和大量拜占庭节点，仍能构建和维护一个稀疏（有界度）的扩展器拓扑。这种扩展器拓扑具有对数直径、高扩展性，并且对流失和大量不良节点的存在具有鲁棒性，有助于分布式计算中基本问题（如一致性、广播、路由等）的高效和鲁棒算法。\n\n我们的主要贡献是一个随机的、完全分布式的动态P2P协议，该协议仅使用局部初始知识，并以高概率保证，即使在持续流失和大量拜占庭节点存在的情况下，也能维护一个具有高扩展性的常数度图。我们的协议可以容忍多达o(n/polylog(n))的拜占庭节点（其中n是稳定网络大小）。我们的协议是高效、轻量级和可扩展的，并且它仅产生O(polylog(n))的拓扑维护开销：每个诚实节点每轮只需处理和发送多对数（n）比特，任何诚实节点每轮的计算成本也是多对数级的。\n\n我们的协议可以作为解决高度动态网络中基本分布式计算问题（如拜占庭一致性协议和拜占庭领导者选举）的构建模块，并为这些问题提供快速和可扩展的算法。", "summary": "本论文旨在解决P2P网络中构建和维护拜占庭容错动态P2P拓扑结构的基本问题，该结构需具备连接性、低直径和高扩展性，并能抵御高流失率和大量恶意节点。为此，作者提出了一种随机、完全分布式的P2P协议，该协议仅依靠局部知识，在高流失和拜占庭节点存在下，仍能以高概率维护一个稀疏（有界度）扩展图。实验结果表明，该协议高效、轻量、可扩展，并能容忍一定数量的拜占庭节点，为分布式计算中的核心问题提供了鲁棒的解决方案。", "keywords": "拜占庭容错, P2P网络, 分布式协议, 动态拓扑, 高扩展性"}}
{"id": "2506.04230", "pdf": "https://arxiv.org/pdf/2506.04230", "abs": "https://arxiv.org/abs/2506.04230", "authors": ["Kaveh Mohajeri", "Amir Karami"], "title": "Computationally Intensive Research: Advancing a Role for Secondary Analysis of Qualitative Data", "categories": ["cs.DB", "cs.AI", "cs.DL"], "comment": "20 Pages", "summary": "This paper draws attention to the potential of computational methods in\nreworking data generated in past qualitative studies. While qualitative\ninquiries often produce rich data through rigorous and resource-intensive\nprocesses, much of this data usually remains unused. In this paper, we first\nmake a general case for secondary analysis of qualitative data by discussing\nits benefits, distinctions, and epistemological aspects. We then argue for\nopportunities with computationally intensive secondary analysis, highlighting\nthe possibility of drawing on data assemblages spanning multiple contexts and\ntimeframes to address cross-contextual and longitudinal research phenomena and\nquestions. We propose a scheme to perform computationally intensive secondary\nanalysis and advance ideas on how this approach can help facilitate the\ndevelopment of innovative research designs. Finally, we enumerate some key\nchallenges and ongoing concerns associated with qualitative data sharing and\nreuse.", "AI": {"title_translation": "计算密集型研究：推进定性数据二次分析的作用", "tldr": "本文探讨了计算方法在定性数据二次分析中的潜力，并提出了一个实施方案。", "motivation": "定性研究产生了大量丰富但未被充分利用的数据。作者旨在探讨计算方法如何能重新利用这些数据，以解决跨情境和纵向研究问题。", "method": "本文首先论证了定性数据二次分析的普遍性、益处、区别和认识论方面；其次，提出了计算密集型二次分析的机会，强调了利用跨多情境和时间框架的数据集合的可能性；然后，提出了一个执行计算密集型二次分析的方案，并提出了该方法如何促进创新研究设计；最后，列举了与定性数据共享和重用相关的一些关键挑战和持续关注的问题。", "result": "本文提出了计算密集型二次分析的可能性，强调了利用跨多情境和时间框架的数据集合来解决跨情境和纵向研究现象和问题，并提出了一个实施方案，有助于促进创新研究设计。", "conclusion": "计算密集型方法在定性数据二次分析中具有巨大潜力，能够促进创新研究设计，但同时也面临数据共享和重用方面的挑战。", "translation": "本文旨在探讨计算方法在重新处理过去定性研究中产生的数据方面的潜力。尽管定性研究通常通过严谨和资源密集型的过程产生丰富的数据，但其中大部分数据通常未被使用。在本文中，我们首先通过讨论其益处、区别和认识论方面，对定性数据二次分析进行了一般性的论证。然后，我们论证了计算密集型二次分析的机会，强调了利用跨多个情境和时间框架的数据集合来解决跨情境和纵向研究现象和问题的可能性。我们提出了一个执行计算密集型二次分析的方案，并提出了该方法如何帮助促进创新研究设计的发展。最后，我们列举了与定性数据共享和重用相关的一些关键挑战和持续关注的问题。", "summary": "本文探讨了计算方法在重新利用以往定性研究数据方面的潜力。文章首先论证了定性数据二次分析的价值，然后重点阐述了计算密集型二次分析如何能利用跨情境和时间的数据集合来解决复杂的跨情境和纵向研究问题。作者提出了一个具体的实施方案，并探讨了该方法如何促进创新研究设计的发展。最后，文章也指出了定性数据共享和重用所面临的关键挑战。", "keywords": "定性数据, 二次分析, 计算方法, 数据重用, 研究设计"}}
{"id": "2506.04556", "pdf": "https://arxiv.org/pdf/2506.04556", "abs": "https://arxiv.org/abs/2506.04556", "authors": ["Xuhao Ren", "Haotian Liang", "Yajie Wang", "Chuan Zhang", "Zehui Xiong", "Liehuang Zhu"], "title": "BESA: Boosting Encoder Stealing Attack with Perturbation Recovery", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "To boost the encoder stealing attack under the perturbation-based defense\nthat hinders the attack performance, we propose a boosting encoder stealing\nattack with perturbation recovery named BESA. It aims to overcome\nperturbation-based defenses. The core of BESA consists of two modules:\nperturbation detection and perturbation recovery, which can be combined with\ncanonical encoder stealing attacks. The perturbation detection module utilizes\nthe feature vectors obtained from the target encoder to infer the defense\nmechanism employed by the service provider. Once the defense mechanism is\ndetected, the perturbation recovery module leverages the well-designed\ngenerative model to restore a clean feature vector from the perturbed one.\nThrough extensive evaluations based on various datasets, we demonstrate that\nBESA significantly enhances the surrogate encoder accuracy of existing encoder\nstealing attacks by up to 24.63\\% when facing state-of-the-art defenses and\ncombinations of multiple defenses.", "AI": {"title_translation": "BESA：通过扰动恢复增强编码器窃取攻击", "tldr": "BESA通过扰动检测和恢复，显著提升了编码器窃取攻击在扰动防御下的成功率。", "motivation": "为了增强在基于扰动的防御下受阻的编码器窃取攻击性能。", "method": "BESA包含扰动检测和扰动恢复两个模块。扰动检测模块利用目标编码器特征向量推断防御机制；扰动恢复模块利用生成模型从受扰的特征向量中恢复干净的特征向量。这两个模块可以与典型的编码器窃取攻击相结合。", "result": "BESA在面对最先进的防御和多种防御组合时，显著地将现有编码器窃取攻击的替代编码器准确率提高了24.63%。", "conclusion": "BESA能够显著提升编码器窃取攻击在扰动防御下的效果。", "translation": "为了增强在基于扰动的防御下受阻的编码器窃取攻击性能，我们提出了一种名为BESA的增强型编码器窃取攻击，它具有扰动恢复功能。其目标是克服基于扰动的防御。BESA的核心由两个模块组成：扰动检测和扰动恢复，这两个模块可以与典型的编码器窃取攻击相结合。扰动检测模块利用从目标编码器获得的特征向量来推断服务提供商采用的防御机制。一旦检测到防御机制，扰动恢复模块就会利用精心设计的生成模型从受扰的特征向量中恢复出干净的特征向量。通过基于各种数据集的广泛评估，我们证明了BESA在面对最先进的防御和多种防御组合时，显著地将现有编码器窃取攻击的替代编码器准确率提高了24.63%。", "summary": "BESA是一种增强编码器窃取攻击的新方法，旨在克服基于扰动的防御。它通过扰动检测和扰动恢复模块，能够识别防御机制并恢复干净特征向量，从而显著提高了现有攻击的成功率。", "keywords": "编码器窃取攻击, 扰动恢复, 扰动检测, 模型窃取, 对抗性攻击"}}
{"id": "2506.04255", "pdf": "https://arxiv.org/pdf/2506.04255", "abs": "https://arxiv.org/abs/2506.04255", "authors": ["Kunal Pai", "Parth Shah", "Harshil Patel"], "title": "HASHIRU: Hierarchical Agent System for Hybrid Intelligent Resource Utilization", "categories": ["cs.MA"], "comment": "Submitted as part of the Research Track at AgentX 2025, organized by\n  Berkeley RDI", "summary": "Rapid Large Language Model (LLM) advancements are fueling autonomous\nMulti-Agent System (MAS) development. However, current frameworks often lack\nflexibility, resource awareness, model diversity, and autonomous tool creation.\nThis paper introduces HASHIRU (Hierarchical Agent System for Hybrid Intelligent\nResource Utilization), a novel MAS framework enhancing flexibility, resource\nefficiency, and adaptability. HASHIRU features a \"CEO\" agent dynamically\nmanaging specialized \"employee\" agents, instantiated based on task needs and\nresource constraints (cost, memory). Its hybrid intelligence prioritizes\nsmaller, local LLMs (via Ollama) while flexibly using external APIs and larger\nmodels when necessary. An economic model with hiring/firing costs promotes team\nstability and efficient resource allocation. The system also includes\nautonomous API tool creation and a memory function. Evaluations on tasks like\nacademic paper review (58% success), safety assessments (100% on a\nJailbreakBench subset), and complex reasoning (outperforming Gemini 2.0 Flash\non GSM8K: 96% vs. 61%; JEEBench: 80% vs. 68.3%; SVAMP: 92% vs. 84%) demonstrate\nHASHIRU's capabilities. Case studies illustrate its self-improvement via\nautonomous cost model generation, tool integration, and budget management.\nHASHIRU offers a promising approach for more robust, efficient, and adaptable\nMAS through dynamic hierarchical control, resource-aware hybrid intelligence,\nand autonomous functional extension. Source code and benchmarks are available\nat https://github.com/HASHIRU-AI/HASHIRU and\nhttps://github.com/HASHIRU-AI/HASHIRUBench respectively, and a live demo is\navailable at https://hashiruagentx-hashiruai.hf.space upon request.", "AI": {"title_translation": "HASHIRU：混合智能资源利用的分层智能体系统", "tldr": "HASHIRU是一个新型多智能体系统（MAS）框架，通过分层控制、资源感知混合智能和自主功能扩展，提高了灵活性、资源效率和适应性，并在多项任务中表现出色。", "motivation": "当前的自主多智能体系统（MAS）框架缺乏灵活性、资源感知能力、模型多样性和自主工具创建能力。", "method": "HASHIRU系统采用“CEO”智能体动态管理基于任务需求和资源约束（成本、内存）实例化的专业“员工”智能体。它优先使用较小的本地LLM，并在需要时灵活使用外部API和大型模型。系统包含一个经济模型（雇佣/解雇成本）以促进团队稳定性和资源分配效率，还具备自主API工具创建和记忆功能。", "result": "在学术论文评审任务中，成功率为58%；在JailbreakBench子集的安全评估中，成功率为100%；在复杂推理任务中，GSM8K成功率为96%（优于Gemini 2.0 Flash的61%），JEEBench成功率为80%（优于Gemini 2.0 Flash的68.3%），SVAMP成功率为92%（优于Gemini 2.0 Flash的84%）。案例研究展示了其通过自主成本模型生成、工具集成和预算管理的自我改进能力。", "conclusion": "HASHIRU通过动态分层控制、资源感知的混合智能和自主功能扩展，为构建更健壮、高效和适应性强的多智能体系统提供了一种有前景的方法。", "translation": "大型语言模型（LLM）的快速发展正在推动自主多智能体系统（MAS）的发展。然而，当前的框架通常缺乏灵活性、资源感知能力、模型多样性和自主工具创建能力。本文介绍了HASHIRU（混合智能资源利用的分层智能体系统），一个新型MAS框架，旨在增强灵活性、资源效率和适应性。HASHIRU的特点是一个“CEO”智能体，它根据任务需求和资源约束（成本、内存）动态管理专业“员工”智能体。其混合智能优先使用较小的本地LLM（通过Ollama），并在必要时灵活使用外部API和大型模型。一个包含雇佣/解雇成本的经济模型促进了团队稳定性和高效的资源分配。该系统还包括自主API工具创建和记忆功能。在学术论文评审（58%成功率）、安全评估（JailbreakBench子集100%成功率）和复杂推理（GSM8K：96% vs. Gemini 2.0 Flash的61%；JEEBench：80% vs. Gemini 2.0 Flash的68.3%；SVAMP：92% vs. Gemini 2.0 Flash的84%）等任务上的评估展示了HASHIRU的能力。案例研究说明了其通过自主成本模型生成、工具集成和预算管理实现的自我改进。HASHIRU通过动态分层控制、资源感知的混合智能和自主功能扩展，为更健壮、高效和适应性强的MAS提供了一种有前景的方法。源代码和基准可在https://github.com/HASHIRU-AI/HASHIRU和https://github.com/HASHIRU-AI/HASHIRUBench获取，实时演示可根据请求在https://hashiruagentx-hashiruai.hf.space获取。", "summary": "本论文介绍了HASHIRU，一个旨在解决当前多智能体系统（MAS）框架在灵活性、资源感知、模型多样性和自主工具创建方面不足的新型MAS框架。HASHIRU采用分层架构，由一个“CEO”智能体动态管理基于任务需求和资源限制的“员工”智能体，并通过混合智能优先使用本地LLM并按需调用外部API。其经济模型促进了资源高效利用，并具备自主API工具创建和记忆功能。实验结果表明，HASHIRU在学术论文评审、安全评估和复杂推理任务中表现出色，并展现了自我改进能力，为构建更健壮、高效和适应性强的MAS提供了新途径。", "keywords": "多智能体系统, 分层智能体, 混合智能, 资源优化, 大型语言模型"}}
{"id": "2506.04359", "pdf": "https://arxiv.org/pdf/2506.04359", "abs": "https://arxiv.org/abs/2506.04359", "authors": ["Alexander Korovko", "Dmitry Slepichev", "Alexander Efitorov", "Aigul Dzhumamuratova", "Viktor Kuznetsov", "Hesam Rabeti", "Joydeep Biswas"], "title": "cuVSLAM: CUDA accelerated visual odometry", "categories": ["cs.RO", "cs.AI", "cs.SE"], "comment": null, "summary": "Accurate and robust pose estimation is a key requirement for any autonomous\nrobot. We present cuVSLAM, a state-of-the-art solution for visual simultaneous\nlocalization and mapping, which can operate with a variety of visual-inertial\nsensor suites, including multiple RGB and depth cameras, and inertial\nmeasurement units. cuVSLAM supports operation with as few as one RGB camera to\nas many as 32 cameras, in arbitrary geometric configurations, thus supporting a\nwide range of robotic setups. cuVSLAM is specifically optimized using CUDA to\ndeploy in real-time applications with minimal computational overhead on\nedge-computing devices such as the NVIDIA Jetson. We present the design and\nimplementation of cuVSLAM, example use cases, and empirical results on several\nstate-of-the-art benchmarks demonstrating the best-in-class performance of\ncuVSLAM.", "AI": {"title_translation": "cuVSLAM: CUDA加速视觉里程计", "tldr": "cuVSLAM是一个CUDA加速的视觉SLAM解决方案，支持多种传感器配置，性能卓越，适用于边缘计算设备。", "motivation": "自主机器人需要精确鲁棒的姿态估计，而现有的视觉SLAM解决方案可能在计算效率和传感器兼容性方面存在挑战。", "method": "cuVSLAM是一个视觉同步定位与建图解决方案，利用CUDA进行优化，支持多种视觉惯性传感器套件（包括RGB、深度相机和IMU），可支持从1个RGB相机到32个相机的任意几何配置。它专为在NVIDIA Jetson等边缘计算设备上实时部署而优化。", "result": "cuVSLAM在多个最先进的基准测试中表现出同类最佳的性能。", "conclusion": "cuVSLAM提供了一种高效、鲁棒且灵活的视觉SLAM解决方案，特别适用于资源受限的边缘计算设备，并能处理广泛的机器人配置。", "translation": "准确和鲁棒的姿态估计是任何自主机器人的关键要求。我们提出了cuVSLAM，这是一种最先进的视觉同步定位与建图解决方案，它可以与各种视觉惯性传感器套件配合使用，包括多个RGB和深度摄像头以及惯性测量单元。cuVSLAM支持从最少一个RGB摄像头到最多32个摄像头的操作，且支持任意几何配置，因此支持广泛的机器人设置。cuVSLAM使用CUDA进行了专门优化，以在NVIDIA Jetson等边缘计算设备上以最小的计算开销部署实时应用程序。我们介绍了cuVSLAM的设计和实现、示例用例，以及在多个最先进基准测试上的经验结果，证明了cuVSLAM同类最佳的性能。", "summary": "本文介绍了cuVSLAM，一种基于CUDA加速的视觉同步定位与建图（SLAM）解决方案。cuVSLAM支持从单目到多达32个摄像头的多种视觉惯性传感器配置，并针对NVIDIA Jetson等边缘计算设备进行了优化，实现了实时操作和最小的计算开销。实验结果表明，cuVSLAM在多个最先进的基准测试中展现出卓越的性能。", "keywords": "cuVSLAM, 视觉SLAM, CUDA, 姿态估计, 边缘计算"}}
{"id": "2506.04292", "pdf": "https://arxiv.org/pdf/2506.04292", "abs": "https://arxiv.org/abs/2506.04292", "authors": ["Bruno Deprez", "Bart Baesens", "Tim Verdonck", "Wouter Verbeke"], "title": "GARG-AML against Smurfing: A Scalable and Interpretable Graph-Based Framework for Anti-Money Laundering", "categories": ["cs.SI", "cs.LG", "stat.AP"], "comment": null, "summary": "Money laundering poses a significant challenge as it is estimated to account\nfor 2%-5% of the global GDP. This has compelled regulators to impose stringent\ncontrols on financial institutions. One prominent laundering method for evading\nthese controls, called smurfing, involves breaking up large transactions into\nsmaller amounts. Given the complexity of smurfing schemes, which involve\nmultiple transactions distributed among diverse parties, network analytics has\nbecome an important anti-money laundering tool. However, recent advances have\nfocused predominantly on black-box network embedding methods, which has\nhindered their adoption in businesses. In this paper, we introduce GARG-AML, a\nnovel graph-based method that quantifies smurfing risk through a single\ninterpretable metric derived from the structure of the second-order transaction\nnetwork of each individual node in the network. Unlike traditional methods,\nGARG-AML strikes an effective balance among computational efficiency, detection\npower and transparency, which enables its integration into existing AML\nworkflows. To enhance its capabilities, we combine the GARG-AML score\ncalculation with different tree-based methods and also incorporate the scores\nof the node's neighbours. An experimental evaluation on large-scale synthetic\nand open-source networks demonstrate that the GARG-AML outperforms the current\nstate-of-the-art smurfing detection methods. By leveraging only the adjacency\nmatrix of the second-order neighbourhood and basic network features, this work\nhighlights the potential of fundamental network properties towards advancing\nfraud detection.", "AI": {"title_translation": "GARG-AML对抗洗钱：一种可扩展且可解释的基于图的洗钱检测框架", "tldr": "GARG-AML是一种可扩展、可解释的图算法，用于通过分析交易网络结构来检测洗钱（特别是“拆分交易”），并在实验中表现优于现有方法。", "motivation": "洗钱活动（占全球GDP的2%-5%）构成重大挑战，促使监管机构施加严格控制。其中，“拆分交易”是一种常见的规避方法，其复杂性使得网络分析成为重要工具。然而，现有黑盒网络嵌入方法缺乏可解释性，阻碍了其商业应用。", "method": "本文提出GARG-AML，一种新型的基于图的方法，通过从每个节点二阶交易网络结构中导出的单一可解释指标来量化“拆分交易”风险。GARG-AML在计算效率、检测能力和透明度之间取得平衡，可集成到现有反洗钱流程中。为增强能力，它结合了基于树的方法并纳入了邻居分数，仅利用二阶邻域的邻接矩阵和基本网络特征。", "result": "在大型合成和开源网络上的实验评估表明，GARG-AML优于当前最先进的“拆分交易”检测方法。", "conclusion": "本研究突出了基本网络属性在推进欺诈检测方面的潜力。GARG-AML在计算效率、检测能力和透明度之间取得了有效平衡。", "translation": "洗钱活动构成重大挑战，据估计占全球GDP的2%-5%。这促使监管机构对金融机构施加严格控制。一种规避这些控制的突出洗钱方法称为“拆分交易”（smurfing），它涉及将大额交易分解为较小金额。鉴于“拆分交易”方案的复杂性，其中涉及分散在不同参与者之间的多笔交易，网络分析已成为重要的反洗钱工具。然而，最近的进展主要集中在黑盒网络嵌入方法上，这阻碍了它们在商业中的应用。\n本文介绍了GARG-AML，这是一种新颖的基于图的方法，它通过从网络中每个独立节点的二阶交易网络结构中导出的单一可解释指标来量化“拆分交易”风险。与传统方法不同，GARG-AML在计算效率、检测能力和透明度之间取得了有效平衡，这使其能够集成到现有的反洗钱工作流程中。为了增强其能力，我们将GARG-AML分数计算与不同的基于树的方法相结合，并纳入了节点邻居的分数。在大型合成和开源网络上的实验评估表明，GARG-AML优于当前最先进的“拆分交易”检测方法。通过仅利用二阶邻域的邻接矩阵和基本网络特征，这项工作突出了基本网络属性在推进欺诈检测方面的潜力。", "summary": "GARG-AML是一种新型的基于图的洗钱检测框架，专门针对“拆分交易”这种洗钱手法。它通过分析第二阶交易网络的结构，生成一个可解释的洗钱风险指标。该方法在计算效率、检测能力和透明度之间取得了平衡，并且可以与现有的反洗钱工作流程集成。实验证明，GARG-AML在检测“拆分交易”方面优于现有最先进的方法，强调了基本网络属性在推进欺诈检测方面的潜力。", "keywords": "GARG-AML, 反洗钱, 拆分交易, 图分析, 欺诈检测"}}
{"id": "2506.04438", "pdf": "https://arxiv.org/pdf/2506.04438", "abs": "https://arxiv.org/abs/2506.04438", "authors": ["Katerina Goseva-Popstojanova", "Denny Hood", "Johann Schumann", "Noble Nkwocha"], "title": "On the Practices of Autonomous Systems Development: Survey-based Empirical Findings", "categories": ["cs.SE"], "comment": "25 pages", "summary": "Autonomous systems have gained an important role in many industry domains and\nare beginning to change everyday life. However, due to dynamically emerging\napplications and often proprietary constraints, there is a lack of information\nabout the practice of developing autonomous systems. This paper presents the\nfirst part of the longitudinal study focused on establishing\nstate-of-the-practice, identifying and quantifying the challenges and benefits,\nidentifying the processes and standards used, and exploring verification and\nvalidation (V&V) practices used for the development of autonomous systems. The\nresults presented in this paper are based on data about software systems that\nhave autonomous functionality and may employ model-based software engineering\n(MBSwE) and reuse. These data were collected using an anonymous online survey\nthat was administered in 2019 and were provided by experts with experience in\ndevelopment of autonomous systems and /or the use of MBSwE. Our current work is\nfocused on repeating the survey to collect more recent data and discover how\nthe development of autonomous systems has evolved over time.", "AI": {"title_translation": "自主系统开发实践：基于调查的实证发现", "tldr": "本研究通过在线调查，首次对自主系统开发实践、挑战、收益、流程、标准以及验证与确认实践进行了量化分析，旨在弥补该领域信息不足的现状。", "motivation": "由于自主系统应用动态涌现且常受限于专有约束，目前缺乏关于自主系统开发实践的信息。", "method": "本研究基于2019年对自主系统开发专家或模型驱动软件工程（MBSwE）使用专家进行的匿名在线调查数据。数据涵盖具有自主功能并可能采用MBSwE和重用的软件系统。", "result": "本研究量化了自主系统开发的实践现状、挑战、收益，并识别了所使用的流程、标准以及验证与确认（V&V）实践。", "conclusion": "本研究首次提供了关于自主系统开发实践的实证数据，揭示了该领域的现状、挑战和所用方法，为后续的纵向研究奠定了基础。", "translation": "自主系统在许多工业领域中扮演着重要角色，并开始改变日常生活。然而，由于动态新兴的应用和通常的专有约束，关于自主系统开发实践的信息存在不足。本文介绍了旨在建立实践现状、识别和量化挑战与收益、识别所使用的流程和标准，以及探索用于自主系统开发的验证与确认（V&V）实践的纵向研究的第一部分。本文呈现的结果基于具有自主功能并可能采用模型驱动软件工程（MBSwE）和重用的软件系统数据。这些数据是通过2019年进行的匿名在线调查收集的，由具有自主系统开发经验和/或使用MBSwE经验的专家提供。我们目前的工作重点是重复调查以收集更近的数据，并发现自主系统开发是如何随时间演变的。", "summary": "本论文是关于自主系统开发实践的首次纵向研究的第一部分，旨在通过2019年对相关领域专家进行的匿名在线调查，建立开发实践现状、量化挑战与收益、识别所用流程与标准，并探索验证与确认（V&V）实践。研究结果基于具有自主功能且可能采用模型驱动软件工程（MBSwE）和重用的软件系统数据。当前工作正致力于重复调查以收集最新数据并分析自主系统开发随时间演变的情况。", "keywords": "自主系统, 开发实践, 调查研究, 验证与确认, 模型驱动软件工程"}}
{"id": "2506.04514", "pdf": "https://arxiv.org/pdf/2506.04514", "abs": "https://arxiv.org/abs/2506.04514", "authors": ["Hanqing Li", "Melania Fedeli", "Vinay Kolar", "Diego Klabjan"], "title": "BEAR: BGP Event Analysis and Reporting", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "The Internet comprises of interconnected, independently managed Autonomous\nSystems (AS) that rely on the Border Gateway Protocol (BGP) for inter-domain\nrouting. BGP anomalies--such as route leaks and hijacks--can divert traffic\nthrough unauthorized or inefficient paths, jeopardizing network reliability and\nsecurity. Although existing rule-based and machine learning methods can detect\nthese anomalies using structured metrics, they still require experts with\nin-depth BGP knowledge of, for example, AS relationships and historical\nincidents, to interpret events and propose remediation. In this paper, we\nintroduce BEAR (BGP Event Analysis and Reporting), a novel framework that\nleverages large language models (LLMs) to automatically generate comprehensive\nreports explaining detected BGP anomaly events. BEAR employs a multi-step\nreasoning process that translates tabular BGP data into detailed textual\nnarratives, enhancing interpretability and analytical precision. To address the\nlimited availability of publicly documented BGP anomalies, we also present a\nsynthetic data generation framework powered by LLMs. Evaluations on both real\nand synthetic datasets demonstrate that BEAR achieves 100% accuracy,\noutperforming Chain-of-Thought and in-context learning baselines. This work\npioneers an automated approach for explaining BGP anomaly events, offering\nvaluable operational insights for network management.", "AI": {"title_translation": "BEAR：BGP事件分析与报告", "tldr": "BEAR是一个利用大型语言模型自动解释BGP异常事件并生成报告的框架，解决了现有方法需要专家知识的问题，并在真实和合成数据集上实现了100%的准确率。", "motivation": "现有的基于规则和机器学习的方法虽然可以检测BGP异常（如路由泄露和劫持），但仍需要具有深入BGP知识的专家来解释事件并提出补救措施，这限制了网络可靠性和安全性。", "method": "本文介绍了BEAR（BGP Event Analysis and Reporting）框架，它利用大型语言模型（LLMs）自动生成解释检测到的BGP异常事件的综合报告。BEAR采用多步骤推理过程，将表格BGP数据转换为详细的文本叙述，以增强可解释性和分析精度。为了解决公开BGP异常文档有限的问题，还提出了一个由LLMs驱动的合成数据生成框架。", "result": "在真实和合成数据集上的评估表明，BEAR实现了100%的准确率，优于Chain-of-Thought和in-context learning基线。", "conclusion": "BEAR开创了一种自动化解释BGP异常事件的方法，为网络管理提供了宝贵的操作见解。", "translation": "互联网由相互连接、独立管理的自治系统（AS）组成，这些系统依赖边界网关协议（BGP）进行域间路由。BGP异常——如路由泄露和劫持——可能导致流量通过未经授权或低效的路径，从而危及网络可靠性和安全性。尽管现有的基于规则和机器学习方法可以使用结构化指标检测这些异常，但它们仍然需要具有深入BGP知识的专家（例如，关于AS关系和历史事件的知识）来解释事件并提出补救措施。在本文中，我们引入了BEAR（BGP事件分析和报告），这是一个新颖的框架，它利用大型语言模型（LLMs）自动生成解释检测到的BGP异常事件的综合报告。BEAR采用多步骤推理过程，将表格BGP数据转换为详细的文本叙述，从而增强可解释性和分析精度。为了解决公开BGP异常文档有限的问题，我们还提出了一个由LLMs驱动的合成数据生成框架。在真实和合成数据集上的评估表明，BEAR实现了100%的准确率，优于Chain-of-Thought和in-context learning基线。这项工作开创了一种自动化解释BGP异常事件的方法，为网络管理提供了宝贵的操作见解。", "summary": "本文提出了BEAR框架，一个利用大型语言模型自动分析BGP异常事件并生成详细报告的系统。针对现有方法对专家知识的依赖，BEAR通过多步推理将BGP数据转化为可解释的文本叙述，并引入了基于LLM的合成数据生成机制以弥补数据不足。实验证明，BEAR在真实和合成数据集上均达到100%的准确率，优于现有基线方法，为BGP事件分析提供了自动化和可解释的解决方案。", "keywords": "BGP, 异常检测, 大型语言模型, 网络安全, 自动化报告"}}
{"id": "2506.04245", "pdf": "https://arxiv.org/pdf/2506.04245", "abs": "https://arxiv.org/abs/2506.04245", "authors": ["Guangchen Lan", "Huseyin A. Inan", "Sahar Abdelnabi", "Janardhan Kulkarni", "Lukas Wutschitz", "Reza Shokri", "Christopher G. Brinton", "Robert Sim"], "title": "Contextual Integrity in LLMs via Reasoning and Reinforcement Learning", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.6; I.2.7"], "comment": null, "summary": "As the era of autonomous agents making decisions on behalf of users unfolds,\nensuring contextual integrity (CI) -- what is the appropriate information to\nshare while carrying out a certain task -- becomes a central question to the\nfield. We posit that CI demands a form of reasoning where the agent needs to\nreason about the context in which it is operating. To test this, we first\nprompt LLMs to reason explicitly about CI when deciding what information to\ndisclose. We then extend this approach by developing a reinforcement learning\n(RL) framework that further instills in models the reasoning necessary to\nachieve CI. Using a synthetic, automatically created, dataset of only $\\sim700$\nexamples but with diverse contexts and information disclosure norms, we show\nthat our method substantially reduces inappropriate information disclosure\nwhile maintaining task performance across multiple model sizes and families.\nImportantly, improvements transfer from this synthetic dataset to established\nCI benchmarks such as PrivacyLens that has human annotations and evaluates\nprivacy leakage of AI assistants in actions and tool calls.", "AI": {"title_translation": "通过推理和强化学习实现大型语言模型中的上下文完整性", "tldr": "本研究提出了一种结合推理和强化学习的方法，以提高大型语言模型（LLMs）在自主代理场景下维护上下文完整性（即适当的信息共享）的能力，并有效减少不当信息泄露。", "motivation": "随着自主代理代表用户做出决策的时代到来，确保上下文完整性（即在执行特定任务时共享适当的信息）成为该领域的核心问题。", "method": "本研究首先提示大型语言模型（LLMs）在决定披露何种信息时明确地推理上下文完整性。然后，通过开发一个强化学习（RL）框架来扩展此方法，该框架进一步向模型灌输实现上下文完整性所需的推理能力。", "result": "研究表明，该方法显著减少了不当信息披露，同时在多种模型尺寸和系列中保持了任务性能。重要的是，这种改进可以从合成数据集转移到已建立的上下文完整性基准测试（如PrivacyLens）。", "conclusion": "结合推理和强化学习可以有效提高大型语言模型在自主代理中维护上下文完整性的能力，显著减少信息泄露，并在真实基准测试中表现出良好的泛化能力。", "translation": "随着自主代理代表用户做出决策的时代展开，确保上下文完整性（CI）——即在执行特定任务时共享何种适当信息——成为该领域的核心问题。我们认为CI需要一种推理形式，即代理需要推理其所操作的上下文。为了验证这一点，我们首先提示大型语言模型（LLMs）在决定披露何种信息时明确地推理CI。然后，我们通过开发一个强化学习（RL）框架来扩展这种方法，该框架进一步向模型灌输实现CI所需的推理能力。使用一个合成的、自动创建的、仅有约700个示例但包含多样化上下文和信息披露规范的数据集，我们表明我们的方法显著减少了不当信息披露，同时在多种模型尺寸和系列中保持了任务性能。重要的是，这些改进可以从该合成数据集转移到已建立的CI基准测试，例如具有人工标注并评估AI助手在行动和工具调用中隐私泄露的PrivacyLens。", "summary": "本研究旨在解决自主代理中大型语言模型（LLMs）的上下文完整性（CI）问题，即在执行任务时适当共享信息。作者提出CI需要代理进行推理，并首先通过提示LLMs显式推理CI来测试这一点。接着，他们开发了一个强化学习（RL）框架，进一步训练模型进行CI推理。通过一个包含约700个示例的合成数据集，并验证了在PrivacyLens等真实基准测试上的效果，结果显示该方法显著减少了不当信息披露，同时保持了任务性能。", "keywords": "上下文完整性, 大型语言模型, 推理, 强化学习, 信息披露"}}
{"id": "2506.04277", "pdf": "https://arxiv.org/pdf/2506.04277", "abs": "https://arxiv.org/abs/2506.04277", "authors": ["Yi Lu", "Jiawang Cao", "Yongliang Wu", "Bozheng Li", "Licheng Tang", "Yangguang Ji", "Chong Wu", "Jay Wu", "Wenbo Zhu"], "title": "RSVP: Reasoning Segmentation via Visual Prompting and Multi-modal Chain-of-Thought", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted as ACL 2025 Main", "summary": "Multi-modal Large Language Models (MLLMs) have demonstrated remarkable\nreasoning capability while lack explicit mechanisms for visual grounding and\nsegmentation, creating a gap between cognitive reasoning and visual perception.\nTo bridge this gap, we introduce Reasoning Segmentation via Visual Prompting\n(RSVP), a novel framework that unifies multi-step multimodal reasoning with\ngrounded visual understanding. RSVP is a two-stage structuralized framework\nthat integrates reasoning-driven localization with segmentation refinement. In\nthe reasoning stage, RSVP employs multimodal chain-of-thought visual prompts to\nhelp MLLMs understand queries and infer targets, generating interpretable\nregion proposals that enhance visual grounding. In segmentation stage, RSVP\nrefines these proposals with a Vision-Language Segmentation Module (VLSM),\nseamlessly integrates textual and visual cues to produce precise segmentation\nmasks. By explicitly modelling the interaction between multimodal reasoning and\nsegmentation, RSVP introduces a new paradigm for interpretable reasoning\nsegmentation. It exploits MLLMs' inherent localization capabilities, enabling\nthe models to not only reason about objects but also generate structured visual\nrepresentations. Our extensive experiments demonstrate that RSVP achieves\nstate-of-the-art performance, surpasses state-of-the-art methods by up to +6.5\ngIoU and +9.2 cIoU on ReasonSeg, and achieves 49.7 mAP on SegInW under\nzero-shot settings. These results validate RSVP as an effective and scalable\nframework for integrating cognitive reasoning with structured visual\nunderstanding.", "AI": {"title_translation": "RSVP：通过视觉提示和多模态思维链进行推理分割", "tldr": "RSVP是一个两阶段框架，通过视觉提示和多模态思维链，将多模态大语言模型的推理能力与视觉感知和分割相结合，实现了最先进的推理分割性能。", "motivation": "多模态大语言模型（MLLMs）在推理能力方面表现出色，但缺乏明确的视觉定位和分割机制，导致认知推理与视觉感知之间存在差距。", "method": "RSVP是一个两阶段结构化框架。在推理阶段，它使用多模态思维链视觉提示帮助MLLMs理解查询并推断目标，生成可解释的区域提议。在分割阶段，RSVP通过视觉-语言分割模块（VLSM）细化这些提议，融合文本和视觉线索以生成精确的分割掩膜。", "result": "RSVP在ReasonSeg数据集上超越现有最先进方法高达+6.5 gIoU和+9.2 cIoU，并在SegInW数据集的零样本设置下达到49.7 mAP。", "conclusion": "RSVP是一个有效且可扩展的框架，能够将认知推理与结构化视觉理解相结合。", "translation": "多模态大语言模型（MLLMs）展现出卓越的推理能力，但缺乏明确的视觉定位和分割机制，这在认知推理和视觉感知之间造成了差距。为了弥合这一差距，我们引入了通过视觉提示进行推理分割（RSVP），这是一个新颖的框架，它将多步多模态推理与基础视觉理解相结合。RSVP是一个两阶段的结构化框架，它将推理驱动的定位与分割细化相结合。在推理阶段，RSVP采用多模态思维链视觉提示来帮助MLLMs理解查询并推断目标，生成可解释的区域提议，从而增强视觉定位。在分割阶段，RSVP通过视觉-语言分割模块（VLSM）细化这些提议，无缝地整合文本和视觉线索以生成精确的分割掩膜。通过明确地建模多模态推理和分割之间的交互，RSVP引入了一种可解释的推理分割新范式。它利用了MLLMs固有的定位能力，使模型不仅能够对对象进行推理，还能生成结构化的视觉表示。我们广泛的实验表明，RSVP取得了最先进的性能，在ReasonSeg数据集上超越了最先进的方法高达+6.5 gIoU和+9.2 cIoU，并在零样本设置下在SegInW数据集上达到了49.7 mAP。这些结果验证了RSVP是一个有效且可扩展的框架，用于将认知推理与结构化视觉理解相结合。", "summary": "RSVP是一个新颖的框架，旨在弥合多模态大语言模型在推理能力和视觉感知及分割之间的差距。它通过两阶段结构化方法，首先利用多模态思维链视觉提示进行推理驱动的定位，生成可解释的区域提议，然后通过视觉-语言分割模块进行分割细化，生成精确的分割掩膜。RSVP引入了一种可解释的推理分割新范式，并利用MLLMs固有的定位能力。实验结果表明，RSVP在推理分割任务上达到了最先进的性能。", "keywords": "推理分割, 视觉提示, 多模态思维链, 大语言模型, 视觉定位"}}
{"id": "2506.04640", "pdf": "https://arxiv.org/pdf/2506.04640", "abs": "https://arxiv.org/abs/2506.04640", "authors": ["Jon Altonaga Puente", "Enrico Mezzetti", "Irune Agirre Troncoso", "Jaume Abella Ferrer", "Francisco J. Cazorla Almeida"], "title": "ROSGuard: A Bandwidth Regulation Mechanism for ROS2-based Applications", "categories": ["cs.AR", "B.8.1"], "comment": "13 pages, 16 figures, submitted to RTSS2025", "summary": "Multicore timing interference, arising when multiple requests contend for the\nsame shared hardware resources, is a primary concern for timing verification\nand validation of time-critical applications. Bandwidth control and regulation\napproaches have been proposed in the literature as an effective method to\nmonitor and limit the impact of timing interference at run time. These\napproaches seek for fine-grained control of the bandwidth consumption (at the\nmicrosecond level) to meet stringent timing requirements on embedded critical\nsystems. Such granularity and configurations, while effective, can become an\nentry barrier for the application of bandwidth control to a wide class of\nproductized, modular ROS2 applications. This is so because those applications\nhave less stringent timing requirements but would still benefit from bandwidth\nregulation, though under less restrictive, and therefore more portable,\ngranularity and configurations.\n  In this work, we provide ROSGuard, a highly-portable, modular implementation\nof a timing interference monitoring and control mechanism that builds on the\nabstractions available on top of a generic and portable Linux-based software\nstack with the Robotic Operating System 2 (ROS2) layer, a widespreadedly\nadopted middleware for a wide class of industrial applications, far beyond the\nrobotic domain. We deploy ROSGuard on an NVIDIA AGX Orin platform as a\nrepresentative target for functionally rich distributed AI-based applications\nand a set of synthetic and real-world benchmarks. We apply an effective\nbandwidth regulation scheme on ROS2-based applications and achieve comparable\neffectiveness to specialized, finer-grained state-of-the-art solutions.", "AI": {"title_translation": "ROSGuard: 面向ROS2应用的带宽调节机制", "tldr": "ROSGuard为ROS2应用提供了一种便携、模块化的带宽调节机制，解决了现有方案粒度过细的问题，并在实际平台上实现了与现有技术相当的效果。", "motivation": "多核时序干扰是时间关键应用时序验证的主要问题。现有带宽控制和调节方法虽然有效，但其严格的粒度（微秒级）和配置对于广泛的ROS2应用而言是一个应用障碍，因为这些应用对时序要求不那么严格，但仍能从带宽调节中受益，且需要更宽松、更便携的粒度和配置。", "method": "本文提出了ROSGuard，一个高度便携、模块化的时序干扰监控和控制机制。它基于通用且便携的Linux软件栈上的抽象，并构建在ROS2层之上。ROSGuard部署在NVIDIA AGX Orin平台上，并应用于合成和真实世界的基准测试，实施了有效的带宽调节方案。", "result": "ROSGuard在ROS2应用上实现了与专业、更细粒度的最先进解决方案相当的有效性。", "conclusion": "ROSGuard提供了一种有效的、便携且模块化的ROS2应用带宽调节机制，能够解决现有方案的局限性，并在实际部署中表现出与现有技术相当的性能。", "translation": "多核时序干扰，当多个请求争用相同的共享硬件资源时产生，是时间关键应用程序时序验证和确认的主要问题。文献中已经提出了带宽控制和调节方法作为一种有效的方法来监控和限制运行时时序干扰的影响。这些方法寻求（微秒级的）细粒度带宽消耗控制，以满足嵌入式关键系统严格的时序要求。然而，这种粒度和配置虽然有效，但可能成为将带宽控制应用于广泛的产品化、模块化ROS2应用程序的障碍。这是因为这些应用程序的时序要求不那么严格，但仍能从带宽调节中受益，尽管是在限制较少且因此更具可移植性的粒度和配置下。\n在这项工作中，我们提供了ROSGuard，一个高度便携、模块化的时序干扰监控和控制机制的实现，它建立在通用且便携的基于Linux的软件栈（包含机器人操作系统2（ROS2）层）之上的抽象。ROS2是广泛应用于工业应用（远超机器人领域）的中间件。我们将ROSGuard部署在NVIDIA AGX Orin平台上，作为功能丰富的分布式AI应用和一组合成及真实世界基准测试的代表性目标。我们对基于ROS2的应用程序应用了有效的带宽调节方案，并实现了与专业、更细粒度最先进解决方案相当的有效性。", "summary": "本文介绍了ROSGuard，一个针对ROS2应用的时序干扰监控与带宽调节机制。鉴于现有精细粒度带宽控制方法不适用于广泛的ROS2产品化应用，ROSGuard提供了一种便携、模块化的解决方案，它构建于Linux和ROS2之上，并在NVIDIA AGX Orin平台及多项基准测试中，展示了与最先进解决方案相当的有效性。", "keywords": "ROS2, 带宽调节, 时序干扰, 实时系统, ROSGuard"}}
{"id": "2506.04576", "pdf": "https://arxiv.org/pdf/2506.04576", "abs": "https://arxiv.org/abs/2506.04576", "authors": ["Haiye Huo", "Li Xiao"], "title": "Sparse Phase Retrieval with Redundant Dictionary via $\\ell_q (0<q\\le 1)$-Analysis Model", "categories": ["cs.IT", "math.IT"], "comment": "21 Pages", "summary": "Sparse phase retrieval with redundant dictionary is to reconstruct the\nsignals of interest that are (nearly) sparse in a redundant dictionary or frame\nfrom the phaseless measurements via the optimization models. Gao [7] presented\nconditions on the measurement matrix, called null space property (NSP) and\nstrong dictionary restricted isometry property (S-DRIP), for exact and stable\nrecovery of dictionary-$k$-sparse signals via the $\\ell_1$-analysis model for\nsparse phase retrieval with redundant dictionary, respectively, where, in\nparticularly, the S-DRIP of order $tk$ with $t>1$ was derived. In this paper,\nmotivated by many advantages of the $\\ell_q$ minimization with $0<q\\leq1$,\ne.g., reduction of the number of measurements required, we generalize these two\nconditions to the $\\ell_q$-analysis model. Specifically, we first present two\nNSP variants for exact recovery of dictionary-$k$-sparse signals via the\n$\\ell_q$-analysis model in the noiseless scenario. Moreover, we investigate the\nS-DRIP of order $tk$ with $0<t<\\frac{4}{3}$ for stable recovery of\ndictionary-$k$-sparse signals via the $\\ell_q$-analysis model in the noisy\nscenario, which will complement the existing result of the S-DRIP of order $tk$\nwith $t\\geq2$ obtained in [4].", "AI": {"title_translation": "基于 $\\ell_q (0<q\\le 1)$-分析模型的稀疏相位恢复与冗余字典", "tldr": "本文将稀疏相位恢复中冗余字典的恢复条件（NSP和S-DRIP）从 $\\ell_1$ 分析模型推广到 $\\ell_q$ 分析模型，以实现更精确和稳定的信号恢复，并可能减少所需测量次数。", "motivation": "现有研究提出了基于 $\\ell_1$-分析模型的稀疏相位恢复与冗余字典的恢复条件。本文的动机是 $\\ell_q$ 最小化 ($0<q\\le1$) 具有许多优点，例如可以减少所需的测量次数，因此旨在将这些条件推广到 $\\ell_q$-分析模型。", "method": "本文将零空间性质 (NSP) 和强字典限制等距性质 (S-DRIP) 这两个条件从 $\\ell_1$-分析模型推广到 $\\ell_q$-分析模型。具体来说，提出了两种 NSP 变体用于无噪声场景下的精确恢复，并研究了有噪声场景下的 S-DRIP。", "result": "在无噪声场景下，推导出了两种 NSP 变体，用于通过 $\\ell_q$-分析模型精确恢复字典-$k$-稀疏信号。在有噪声场景下，研究了阶为 $tk$ 且 $0<t<\\frac{4}{3}$ 的 S-DRIP，用于通过 $\\ell_q$-分析模型稳定恢复字典-$k$-稀疏信号，这补充了 [4] 中获得的阶为 $tk$ 且 $t\\geq2$ 的 S-DRIP 现有结果。", "conclusion": "本文成功地将稀疏相位恢复中关键的恢复条件（NSP和S-DRIP）推广到 $\\ell_q$-分析模型，涵盖了无噪声和有噪声场景，并补充了现有工作。这一进展利用了 $\\ell_q$ 最小化的优势，有望减少测量需求。", "translation": "稀疏相位恢复与冗余字典旨在通过优化模型，从无相位测量中重建在冗余字典或框架中（近似）稀疏的目标信号。Gao [7] 提出了测量矩阵的条件，称为零空间性质 (NSP) 和强字典限制等距性质 (S-DRIP)，分别用于通过 $\\ell_1$-分析模型精确和稳定地恢复稀疏相位恢复与冗余字典中的字典-$k$-稀疏信号，其中特别导出了阶为 $tk$ 且 $t>1$ 的 S-DRIP。本文受 $\\ell_q$ 最小化 ($0<q\\leq1$) 诸多优点的启发，例如减少所需测量次数，我们将这两个条件推广到 $\\ell_q$-分析模型。具体来说，我们首先在无噪声场景下，提出了两种 NSP 变体，用于通过 $\\ell_q$-分析模型精确恢复字典-$k$-稀疏信号。此外，我们研究了在有噪声场景下，阶为 $tk$ 且 $0<t<\\frac{4}{3}$ 的 S-DRIP，用于通过 $\\ell_q$-分析模型稳定恢复字典-$k$-稀疏信号，这将补充 [4] 中获得的阶为 $tk$ 且 $t\\geq2$ 的 S-DRIP 现有结果。", "summary": "本文将稀疏相位恢复与冗余字典中稀疏信号精确和稳定恢复的条件从 $\\ell_1$-分析模型推广到更一般的 $\\ell_q$-分析模型 ($0<q\\le1$)。受 $\\ell_q$ 最小化（例如减少测量需求）的启发，作者提出了两种零空间性质 (NSP) 变体用于无噪声恢复，并研究了强字典限制等距性质 (S-DRIP) 用于有噪声环境下的稳定恢复，从而补充了现有结果。", "keywords": "稀疏相位恢复, 冗余字典, $\\ell_q$-分析模型, 零空间性质, 强字典限制等距性质"}}
{"id": "2506.04660", "pdf": "https://arxiv.org/pdf/2506.04660", "abs": "https://arxiv.org/abs/2506.04660", "authors": ["Yi Xu", "Farzin Lotfi-Jam", "Mustafa Faruki"], "title": "Adaptive recycled plastic architecture: Vacuum-Sealed Chainmail Structures Through Computational Design", "categories": ["cs.CE", "cond-mat.mtrl-sci", "J.6; I.2.10"], "comment": "Accepted manuscript. Published in International Journal of\n  Architectural Computing, April 2025", "summary": "The construction industry is a major consumer of raw materials, accounting\nfor nearly half of global material usage annually, while generating significant\nwaste that poses sustainability challenges. This paper explores the untapped\npotential of recycled plastics as a primary construction material, leveraging\ntheir lightweight, flexible, and customizable properties for advanced\napplications in modular chainmail systems. Through a computational workflow,\nthe study optimizes the design, testing, and fabrication of vacuum-sealed\nchainmail structures composed of recycled plastic filaments, demonstrating\ntheir adaptability and structural performance for architectural use.\n  Key contributions include a novel methodology for integrating recycled\nplastic filaments into chainmail geometries, validated through 2D sectional\ntesting, 3D shell structure generation, and physical modeling under vacuum\nconstraints. The research identifies the rectangular chainmail configuration as\nthe most efficient and adaptable, achieving superior deformation capacity,\nmaterial efficiency, and load-bearing performance. Optimization strategies for\ntemporary structures highlight practical deployment potential, balancing\nmaterial savings, usable area, and water drainage efficiency.\n  The findings offer a foundation for innovative applications in extreme\nconditions, including disaster-prone areas, high-altitude environments,\nunderwater platforms, and extraterrestrial habitats. These applications\nleverage the lightweight, adaptable, and durable properties of recycled\nplastics and modular chainmail systems, bridging the gap between waste\nmanagement and high-performance design while addressing unique challenges in\nharsh and resource-constrained environments.", "AI": {"title_translation": "自适应再生塑料建筑：通过计算设计实现的真空密封链甲结构", "tldr": "本研究通过计算设计优化了再生塑料真空密封链甲结构，展示了其在建筑应用中的适应性和结构性能，并提出了在极端条件下的创新应用潜力。", "motivation": "建筑业是原材料的主要消耗者，并产生大量废物，对可持续性构成挑战。本研究旨在探索再生塑料作为主要建筑材料的潜力，以解决废物管理和高性能设计之间的差距。", "method": "本研究通过计算工作流程优化了由再生塑料纤维组成的真空密封链甲结构的设计、测试和制造。关键贡献包括将再生塑料纤维整合到链甲几何结构中的新颖方法，并通过二维截面测试、三维壳结构生成和真空约束下的物理建模进行验证。研究还识别了最有效和适应性强的矩形链甲配置，并提出了临时结构的优化策略。", "result": "研究发现矩形链甲配置在变形能力、材料效率和承载性能方面表现优异，是最有效和适应性强的。优化策略平衡了材料节省、可用面积和排水效率。", "conclusion": "研究结果为再生塑料和模块化链甲系统在极端条件（如灾区、高海拔环境、水下平台和地外栖息地）下的创新应用奠定了基础，弥合了废物管理与高性能设计之间的鸿沟，并解决了恶劣和资源受限环境中的独特挑战。", "translation": "建筑业是原材料的主要消耗者，每年消耗全球近一半的材料，同时产生大量废物，对可持续性构成挑战。本文探讨了再生塑料作为主要建筑材料的未开发潜力，利用其轻质、柔性、可定制的特性，应用于模块化链甲系统。通过计算工作流程，本研究优化了由再生塑料纤维组成的真空密封链甲结构的设计、测试和制造，展示了其在建筑应用中的适应性和结构性能。\n主要贡献包括将再生塑料纤维整合到链甲几何结构中的新颖方法，并通过二维截面测试、三维壳结构生成和真空约束下的物理建模进行验证。研究识别出矩形链甲配置为最有效和适应性强的，实现了卓越的变形能力、材料效率和承载性能。临时结构的优化策略突出了实际部署潜力，平衡了材料节省、可用面积和排水效率。\n研究结果为在极端条件下的创新应用奠定了基础，包括灾区、高海拔环境、水下平台和地外栖息地。这些应用利用了再生塑料和模块化链甲系统的轻质、适应性和耐用特性，弥合了废物管理与高性能设计之间的鸿沟，同时解决了恶劣和资源受限环境中的独特挑战。", "summary": "本研究利用计算设计，探索了再生塑料在建筑领域作为轻质、柔性、可定制材料的潜力，特别关注真空密封链甲结构。通过优化设计、测试和制造流程，研究验证了再生塑料链甲的适应性和结构性能，并识别出矩形配置为最优。研究成果为再生塑料在极端环境下的创新应用提供了可行性，旨在将废物管理与高性能建筑设计相结合。", "keywords": "再生塑料, 链甲结构, 计算设计, 适应性建筑, 废物管理"}}
{"id": "2506.04241", "pdf": "https://arxiv.org/pdf/2506.04241", "abs": "https://arxiv.org/abs/2506.04241", "authors": ["Konstantin Kirchheim", "Frank Ortmeier"], "title": "Improving Out-of-Distribution Detection with Markov Logic Networks", "categories": ["cs.LG"], "comment": null, "summary": "Out-of-distribution (OOD) detection is essential for ensuring the reliability\nof deep learning models operating in open-world scenarios. Current OOD\ndetectors mainly rely on statistical models to identify unusual patterns in the\nlatent representations of a deep neural network. This work proposes to augment\nexisting OOD detectors with probabilistic reasoning, utilizing Markov logic\nnetworks (MLNs). MLNs connect first-order logic with probabilistic reasoning to\nassign probabilities to inputs based on weighted logical constraints defined\nover human-understandable concepts, which offers improved explainability.\nThrough extensive experiments on multiple datasets, we demonstrate that MLNs\ncan significantly enhance the performance of a wide range of existing OOD\ndetectors while maintaining computational efficiency. Furthermore, we introduce\na simple algorithm for learning logical constraints for OOD detection from a\ndataset and showcase its effectiveness.", "AI": {"title_translation": "使用马尔可夫逻辑网络改进离群点检测", "tldr": "本文提出使用马尔可夫逻辑网络（MLNs）增强现有离群点检测器，显著提高了性能并保持计算效率。", "motivation": "离群点（OOD）检测对于确保深度学习模型在开放世界场景中运行的可靠性至关重要。当前的OOD检测器主要依赖统计模型来识别深度神经网络潜在表示中的异常模式。", "method": "本文提出利用马尔可夫逻辑网络（MLNs）通过概率推理增强现有OOD检测器。MLNs将一阶逻辑与概率推理相结合，根据人类可理解概念上定义的加权逻辑约束为输入分配概率，从而提高了可解释性。此外，还引入了一种从数据集中学习OOD检测逻辑约束的简单算法。", "result": "通过在多个数据集上进行大量实验，我们证明MLNs可以显著提高各种现有OOD检测器的性能，同时保持计算效率。此外，我们展示了所提出的学习逻辑约束算法的有效性。", "conclusion": "马尔可夫逻辑网络能够显著提高离群点检测的性能，同时保持计算效率并提供更好的可解释性。", "translation": "离群点（OOD）检测对于确保深度学习模型在开放世界场景中运行的可靠性至关重要。当前的OOD检测器主要依靠统计模型来识别深度神经网络潜在表示中的异常模式。本工作提出利用马尔可夫逻辑网络（MLNs）通过概率推理来增强现有的OOD检测器。MLNs将一阶逻辑与概率推理相结合，根据人类可理解概念上定义的加权逻辑约束为输入分配概率，从而提高了可解释性。通过在多个数据集上进行大量实验，我们证明MLNs可以显著提高各种现有OOD检测器的性能，同时保持计算效率。此外，我们引入了一种从数据集中学习OOD检测逻辑约束的简单算法，并展示了其有效性。", "summary": "本研究提出一种新方法，通过集成马尔可夫逻辑网络（MLNs）来增强现有的离群点（OOD）检测器。MLNs结合了一阶逻辑和概率推理，为输入分配基于可理解逻辑约束的概率，从而提高了可解释性。实验结果表明，MLNs能显著提升多种OOD检测器的性能，同时保持计算效率。此外，研究还介绍了一种用于学习OOD检测逻辑约束的有效算法。", "keywords": "离群点检测, 马尔可夫逻辑网络, 概率推理, 可解释性, 深度学习"}}
{"id": "2506.04305", "pdf": "https://arxiv.org/pdf/2506.04305", "abs": "https://arxiv.org/abs/2506.04305", "authors": ["Yunusa Simipa Abdulsalam", "Siobhan Mackenzie Hall", "Ana Quintero-Ossa", "William Agnew", "Carla Muntean", "Sarah Tan", "Ashley Heady", "Savannah Thais", "Jessica Schrouff"], "title": "Enduring Disparities in the Workplace: A Pilot Study in the AI Community", "categories": ["cs.CY"], "comment": null, "summary": "In efforts toward achieving responsible artificial intelligence (AI),\nfostering a culture of workplace transparency, diversity, and inclusion can\nbreed innovation, trust, and employee contentment. In AI and Machine Learning\n(ML), such environments correlate with higher standards of responsible\ndevelopment. Without transparency, disparities, microaggressions and misconduct\nwill remain unaddressed, undermining the very structural inequities responsible\nAI aims to mitigate. While prior work investigates workplace transparency and\ndisparities in broad domains (e.g. science and technology, law) for specific\ndemographic subgroups, it lacks in-depth and intersectional conclusions and a\nfocus on the AI/ML community. To address this, we conducted a pilot survey of\n1260 AI/ML professionals both in industry and academia across different axes,\nprobing aspects such as belonging, performance, workplace Diversity, Equity and\nInclusion (DEI) initiatives, accessibility, performance and compensation,\nmicroaggressions, misconduct, growth, and well-being. Results indicate enduring\ndisparities in workplace experiences for underrepresented and/or marginalized\nsubgroups. In particular, we highlight that accessibility remains an important\nchallenge for a positive work environment and that disabled employees have a\nworse workplace experience than their non-disabled colleagues. We further\nsurface disparities for intersectional groups and discuss how the\nimplementation of DEI initiatives may differ from their perceived impact on the\nworkplace. This study is a first step towards increasing transparency and\ninforming AI/ML practitioners and organizations with empirical results. We aim\nto foster equitable decision-making in the design and evaluation of\norganizational policies and provide data that may empower professionals to make\nmore informed choices of prospective workplaces.", "AI": {"title_translation": "职场中持续存在的差距：人工智能社区的一项初步研究", "tldr": "一项针对1260名AI/ML专业人员的调查发现，AI/ML领域存在持续的职场差距，尤其是在可及性和残疾员工的体验方面，并指出DEI倡议的实施与感知效果存在差异。", "motivation": "在实现负责任的人工智能方面，工作场所的透明度、多样性和包容性至关重要。然而，现有研究缺乏对AI/ML社区中工作场所透明度和差异的深入和交叉分析。", "method": "对1260名来自工业界和学术界的AI/ML专业人员进行了试点调查，探究了归属感、绩效、工作场所多样性、公平性和包容性（DEI）倡议、可及性、薪酬、微侵犯、不当行为、成长和福祉等方面。", "result": "结果表明，弱势和/或边缘化群体在工作场所经历中存在持续的差距。特别是，可及性仍然是积极工作环境的重要挑战，残疾员工的职场体验比非残疾同事更差。研究还发现了交叉群体的差异，并讨论了DEI倡议的实施与其在工作场所的感知影响可能存在的差异。", "conclusion": "这项研究是提高透明度、为AI/ML从业者和组织提供实证结果的第一步。旨在促进组织政策设计和评估中的公平决策，并提供数据以帮助专业人员更明智地选择未来的工作场所。", "translation": "在实现负责任的人工智能（AI）的努力中，培养工作场所透明度、多样性和包容性的文化可以促进创新、信任和员工满意度。在人工智能和机器学习（ML）领域，这样的环境与更高标准的负责任开发相关。如果没有透明度，差距、微侵犯和不当行为将得不到解决，从而损害负责任人工智能旨在减轻的结构性不平等。虽然先前的工作调查了广泛领域（例如科学技术、法律）中针对特定人口亚群的工作场所透明度和差异，但缺乏深入和交叉的结论，也缺乏对AI/ML社区的关注。为了解决这个问题，我们对1260名来自工业界和学术界的AI/ML专业人员进行了试点调查，从不同维度探究了归属感、绩效、工作场所多样性、公平性和包容性（DEI）倡议、可及性、绩效和薪酬、微侵犯、不当行为、成长和福祉等方面。结果表明，弱势和/或边缘化群体在工作场所经历中存在持续的差距。特别是，我们强调可及性仍然是积极工作环境的重要挑战，残疾员工的职场体验比非残疾同事更差。我们进一步揭示了交叉群体的差异，并讨论了DEI倡议的实施与其在工作场所的感知影响可能存在的差异。这项研究是提高透明度、为AI/ML从业者和组织提供实证结果的第一步。我们旨在促进组织政策设计和评估中的公平决策，并提供数据，使专业人员能够更明智地选择未来的工作场所。", "summary": "本研究旨在解决人工智能领域职场透明度、多样性和包容性方面的不足，通过对1260名AI/ML专业人员进行试点调查，揭示了弱势群体在职场体验中持续存在的差距，尤其是在可及性方面，并指出残疾员工面临更差的职场环境。研究还探讨了DEI倡议实施与感知效果的差异，为未来建立更公平的AI/ML工作环境提供了实证基础。", "keywords": "职场差距, 人工智能社区, 多样性与包容性, 可及性, 试点研究"}}
{"id": "2506.04456", "pdf": "https://arxiv.org/pdf/2506.04456", "abs": "https://arxiv.org/abs/2506.04456", "authors": ["Ke Ma", "Junfei Xie"], "title": "Knowledge-Guided Attention-Inspired Learning for Task Offloading in Vehicle Edge Computing", "categories": ["cs.DC", "cs.AR"], "comment": null, "summary": "Vehicle edge computing (VEC) brings abundant computing resources close to\nvehicles by deploying them at roadside units (RSUs) or base stations, thereby\nenabling diverse computation-intensive and delay sensitive applications.\nExisting task offloading strategies are often computationally expensive to\nexecute or generate suboptimal solutions. In this paper, we propose a novel\nlearning-based approach, Knowledge-guided Attention-inspired Task Offloading\n(KATO), designed to efficiently offload tasks from moving vehicles to nearby\nRSUs. KATO integrates an attention-inspired encoder-decoder model for selecting\na subset of RSUs that can reduce overall task processing time, along with an\nefficient iterative algorithm for computing optimal task allocation among the\nselected RSUs. Simulation results demonstrate that KATO achieves optimal or\nnear-optimal performance with significantly lower computational overhead and\ngeneralizes well across networks of varying sizes and configurations.", "AI": {"title_translation": "面向车载边缘计算中任务卸载的知识引导注意力启发式学习", "tldr": "本文提出了一种新颖的KATO学习方法，通过注意力机制和迭代算法，在车载边缘计算中高效地将任务从车辆卸载到路边单元，实现了接近最优的性能和显著降低的计算开销。", "motivation": "现有的任务卸载策略计算成本高昂或导致次优解，因此需要一种更高效的策略来处理车载边缘计算中计算密集型和延迟敏感型应用的任务卸载。", "method": "本文提出了一种名为KATO（Knowledge-guided Attention-inspired Task Offloading）的学习方法。KATO结合了注意力启发式编码器-解码器模型来选择可减少总任务处理时间的RSU子集，并采用高效的迭代算法来计算所选RSU之间的最优任务分配。", "result": "仿真结果表明，KATO以显著更低的计算开销实现了最优或接近最优的性能，并且在不同大小和配置的网络中具有良好的泛化能力。", "conclusion": "KATO通过结合知识引导和注意力机制，为车载边缘计算中的任务卸载提供了一种高效且高性能的解决方案，解决了现有方法的计算开销高和次优解问题。", "translation": "车载边缘计算（VEC）通过在路边单元（RSU）或基站部署计算资源，将丰富的计算资源带到车辆附近，从而支持各种计算密集型和延迟敏感型应用。现有的任务卸载策略通常执行计算成本高昂或产生次优解。在本文中，我们提出了一种新颖的基于学习的方法，即知识引导注意力启发式任务卸载（KATO），旨在高效地将任务从移动车辆卸载到附近的路边单元。KATO集成了注意力启发式编码器-解码器模型，用于选择可以减少总任务处理时间的RSU子集，以及一种高效的迭代算法，用于计算所选RSU之间的最优任务分配。仿真结果表明，KATO以显著更低的计算开销实现了最优或接近最优的性能，并且在不同大小和配置的网络中具有良好的泛化能力。", "summary": "本文提出了一种名为KATO（Knowledge-guided Attention-inspired Task Offloading）的新型学习方法，用于车载边缘计算中高效地将任务从移动车辆卸载到附近的路边单元（RSU）。KATO利用注意力启发式编码器-解码器模型选择RSU子集以减少任务处理时间，并采用迭代算法进行最优任务分配。仿真结果表明，KATO在计算开销显著降低的情况下，实现了最优或接近最优的性能，并具有良好的泛化能力。", "keywords": "车载边缘计算, 任务卸载, 注意力机制, 知识引导, 深度学习"}}
{"id": "2506.04634", "pdf": "https://arxiv.org/pdf/2506.04634", "abs": "https://arxiv.org/abs/2506.04634", "authors": ["Mridu Nanda", "Michael K. Reiter"], "title": "Incentivizing Collaborative Breach Detection", "categories": ["cs.CR"], "comment": null, "summary": "Decoy passwords, or \"honeywords,\" alert a site to its breach if they are ever\nentered in a login attempt on that site. However, an attacker can identify a\nuser-chosen password from among the decoys, without risk of alerting the site\nto its breach, by performing credential stuffing, i.e., entering the stolen\npasswords at another site where the same user reused her password. Prior work\nhas thus proposed that sites monitor for the entry of their honeywords at other\nsites. Unfortunately, it is not clear what incentives sites have to participate\nin this monitoring. In this paper we propose and evaluate an algorithm by which\nsites can exchange monitoring favors. Through a model-checking analysis, we\nshow that using our algorithm, a site improves its ability to detect its own\nbreach when it increases the monitoring effort it expends for other sites. We\nadditionally quantify the impacts of various parameters on detection\neffectiveness and their implications for the deployment of a system to support\na monitoring ecosystem. Finally, we evaluate our algorithm on a real dataset of\nbreached credentials and provide a performance analysis that confirms its\nscalability and practical viability.", "AI": {"title_translation": "激励协作式入侵检测", "tldr": "提出并评估了一种算法，通过该算法，网站可以通过为其他网站提供监控服务来提高自身入侵检测能力，解决了网站间协作监控蜜糖密码的激励问题。", "motivation": "以往研究提出网站应监控其蜜糖密码在其他网站被输入的情况，但目前尚不清楚网站参与此类监控的动机。本文旨在解决网站缺乏协作监控蜜糖密码入侵的激励问题。", "method": "本文提出并评估了一种算法，使网站可以交换监控服务。通过模型检查分析，并使用真实泄露凭据数据集进行评估，同时量化了不同参数对检测效果的影响。", "result": "研究表明，使用该算法，当一个网站增加为其他网站付出的监控努力时，其自身检测入侵的能力会得到提升。此外，本文量化了各种参数对检测有效性的影响及其对支持监控生态系统部署的影响。在真实泄露凭据数据集上的评估确认了算法的可扩展性和实际可行性。", "conclusion": "所提出的算法为网站协作进行入侵检测提供了激励机制，显著提高了网站检测自身入侵的能力，并且该系统具有可扩展性和实际部署的可行性。", "translation": "诱饵密码，或称“蜜糖密码”，一旦在网站上被输入登录尝试，就会提醒该网站其已被入侵。然而，攻击者可以通过凭据填充（即在同一用户重复使用密码的另一个网站上输入被盗密码）来识别用户选择的密码，而不会有提醒网站其已被入侵的风险。因此，先前的研究提出网站应监控其蜜糖密码在其他网站被输入的情况。不幸的是，目前尚不清楚网站参与此类监控的动机。在本文中，我们提出并评估了一种算法，通过该算法，网站可以交换监控服务。通过模型检查分析，我们表明使用我们的算法，一个网站在增加为其他网站付出的监控努力时，其检测自身入侵的能力会得到提升。我们还量化了各种参数对检测有效性的影响及其对支持监控生态系统部署的意义。最后，我们在一个真实泄露凭据数据集上评估了我们的算法，并提供了性能分析，证实了其可扩展性和实际可行性。", "summary": "本研究提出并评估了一种算法，旨在解决网站在蜜糖密码（诱饵密码）入侵检测中缺乏协作监控激励的问题。通过该算法，网站可以交换监控服务，提高自身检测入侵的能力。模型检查分析和真实数据集的评估结果表明，网站为其他网站付出的监控努力越多，自身检测能力越强，且该算法具有良好的可扩展性和实际可行性，为构建协作式监控生态系统提供了基础。", "keywords": "协作入侵检测, 蜜糖密码, 凭据填充, 激励机制, 跨站监控"}}
{"id": "2506.04265", "pdf": "https://arxiv.org/pdf/2506.04265", "abs": "https://arxiv.org/abs/2506.04265", "authors": ["Mengda Ji", "Genjiu Xu", "Liying Wang"], "title": "CORA: Coalitional Rational Advantage Decomposition for Multi-Agent Policy Gradients", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "comment": null, "summary": "This work focuses on the credit assignment problem in cooperative multi-agent\nreinforcement learning (MARL). Sharing the global advantage among agents often\nleads to suboptimal policy updates as it fails to account for the distinct\ncontributions of agents. Although numerous methods consider global or\nindividual contributions for credit assignment, a detailed analysis at the\ncoalition level remains lacking in many approaches. This work analyzes the\nover-updating problem during multi-agent policy updates from a coalition-level\nperspective. To address this issue, we propose a credit assignment method\ncalled Coalitional Rational Advantage Decomposition (CORA). CORA evaluates\ncoalitional advantages via marginal contributions from all possible coalitions\nand decomposes advantages using the core solution from cooperative game theory,\nensuring coalitional rationality. To reduce computational overhead, CORA\nemploys random coalition sampling. Experiments on matrix games, differential\ngames, and multi-agent collaboration benchmarks demonstrate that CORA\noutperforms strong baselines, particularly in tasks with multiple local optima.\nThese findings highlight the importance of coalition-aware credit assignment\nfor improving MARL performance.", "AI": {"title_translation": "CORA：多智能体策略梯度的联盟理性优势分解", "tldr": "针对多智能体强化学习中的信用分配问题，本文提出了CORA方法，通过联盟视角分解优势，并在多局部最优任务中表现出色。", "motivation": "合作多智能体强化学习（MARL）中存在信用分配问题，共享全局优势常导致次优策略更新，且现有方法缺乏对联盟层面贡献的详细分析，导致多智能体策略更新中的过度更新问题。", "method": "提出了一种名为联盟理性优势分解（CORA）的信用分配方法。CORA通过所有可能联盟的边际贡献评估联盟优势，并利用合作博弈论中的核心解来分解优势，确保联盟理性。为降低计算开销，CORA采用随机联盟采样。", "result": "在矩阵博弈、微分博弈和多智能体协作基准测试中，CORA优于强基线，特别是在具有多个局部最优的任务中表现突出。", "conclusion": "研究结果强调了联盟感知信用分配对于提高多智能体强化学习性能的重要性。", "translation": "这项工作侧重于合作多智能体强化学习（MARL）中的信用分配问题。在智能体之间共享全局优势常常导致次优策略更新，因为它未能考虑智能体的独特贡献。尽管许多方法考虑了全局或个体贡献来解决信用分配问题，但许多方法仍然缺乏在联盟层面的详细分析。这项工作从联盟层面的角度分析了多智能体策略更新过程中的过度更新问题。为了解决这个问题，我们提出了一种名为联盟理性优势分解（CORA）的信用分配方法。CORA通过所有可能联盟的边际贡献评估联盟优势，并利用合作博弈论中的核心解来分解优势，从而确保联盟理性。为了降低计算开销，CORA采用随机联盟采样。在矩阵博弈、微分博弈和多智能体协作基准上的实验表明，CORA优于强大的基线，特别是在具有多个局部最优的任务中。这些发现强调了联盟感知信用分配对于提高MARL性能的重要性。", "summary": "本文针对合作多智能体强化学习中的信用分配和过度更新问题，提出了一种名为CORA的联盟理性优势分解方法。CORA通过评估联盟优势并利用合作博弈论的核心解来分解优势，同时采用随机联盟采样降低计算成本。实验结果表明，CORA在多种任务中优于现有基线，尤其在多局部最优任务中表现出色，凸显了联盟感知信用分配的重要性。", "keywords": "多智能体强化学习, 信用分配, 联盟理性, 合作博弈论"}}
{"id": "2506.04362", "pdf": "https://arxiv.org/pdf/2506.04362", "abs": "https://arxiv.org/abs/2506.04362", "authors": ["Zihao Dong", "Alan Papalia", "Leonard Jung", "Alenna Spiro", "Philip R. Osteen", "Christa S. Robison", "Michael Everett"], "title": "Learning Smooth State-Dependent Traversability from Dense Point Clouds", "categories": ["cs.RO", "cs.CV"], "comment": "16 pages, 13 figures", "summary": "A key open challenge in off-road autonomy is that the traversability of\nterrain often depends on the vehicle's state. In particular, some obstacles are\nonly traversable from some orientations. However, learning this interaction by\nencoding the angle of approach as a model input demands a large and diverse\ntraining dataset and is computationally inefficient during planning due to\nrepeated model inference. To address these challenges, we present SPARTA, a\nmethod for estimating approach angle conditioned traversability from point\nclouds. Specifically, we impose geometric structure into our network by\noutputting a smooth analytical function over the 1-Sphere that predicts risk\ndistribution for any angle of approach with minimal overhead and can be reused\nfor subsequent queries. The function is composed of Fourier basis functions,\nwhich has important advantages for generalization due to their periodic nature\nand smoothness. We demonstrate SPARTA both in a high-fidelity simulation\nplatform, where our model achieves a 91\\% success rate crossing a 40m boulder\nfield (compared to 73\\% for the baseline), and on hardware, illustrating the\ngeneralization ability of the model to real-world settings.", "AI": {"title_translation": "学习从密集点云中获取平滑的状态依赖可穿越性", "tldr": "SPARTA通过输出一个平滑的解析函数来估计与接近角度相关的地形可穿越性，从而提高越野自主性。", "motivation": "越野自主性面临的关键挑战是地形的可穿越性通常取决于车辆状态（特别是障碍物只能从某些方向穿越）。现有方法通过将接近角度编码为模型输入，需要大量多样化的训练数据集，并且在规划过程中由于重复的模型推理而计算效率低下。", "method": "本文提出了SPARTA，一种从点云中估计与接近角度相关的可穿越性的方法。该方法通过输出一个在1-Sphere上平滑的解析函数来施加几何结构，该函数以最小的开销预测任何接近角度的风险分布，并且可以重复用于后续查询。该函数由傅里叶基函数组成，由于其周期性和平滑性，在泛化方面具有重要优势。", "result": "在模拟平台中，模型在穿越40米巨石场时取得了91%的成功率（基线为73%）。在硬件上，模型展示了其对真实世界环境的泛化能力。", "conclusion": "SPARTA通过引入几何结构和傅里叶基函数，有效解决了越野自主性中状态依赖可穿越性估计的挑战，提高了规划效率和泛化能力。", "translation": "越野自主性的一个关键开放挑战是地形的可穿越性通常取决于车辆的状态。特别是，某些障碍物只能从某些方向穿越。然而，通过将接近角度编码为模型输入来学习这种交互作用，需要大量多样化的训练数据集，并且在规划过程中由于重复的模型推理而计算效率低下。为了解决这些挑战，我们提出了SPARTA，一种从点云估计与接近角度相关的可穿越性的方法。具体来说，我们通过输出一个在1-Sphere上平滑的解析函数来将几何结构强加到我们的网络中，该函数以最小的开销预测任何接近角度的风险分布，并且可以重复用于后续查询。该函数由傅里叶基函数组成，由于其周期性和平滑性，在泛化方面具有重要优势。我们在高保真模拟平台（我们的模型在穿越40米巨石场时达到了91%的成功率，而基线为73%）和硬件上都展示了SPARTA，说明了该模型对真实世界环境的泛化能力。", "summary": "本文提出了SPARTA，一种从点云估计接近角度条件可穿越性的方法，旨在解决越野自主性中地形可穿越性依赖于车辆状态的挑战。SPARTA通过输出一个基于傅里叶基函数的平滑解析函数来预测任何接近角度的风险分布，从而提高了计算效率和泛化能力。实验结果表明，SPARTA在模拟和真实世界环境中均表现出优越的性能。", "keywords": "可穿越性, 点云, 状态依赖, 越野自主性, 傅里叶基函数"}}
{"id": "2506.04475", "pdf": "https://arxiv.org/pdf/2506.04475", "abs": "https://arxiv.org/abs/2506.04475", "authors": ["Nico Elbert", "Alicia von Schenk", "Fabian Kosse", "Victor Klockmann", "Nikolai Stein", "Christoph Flath"], "title": "What Drives Team Success? Large-Scale Evidence on the Role of the Team Player Effect", "categories": ["cs.SI", "cs.CY"], "comment": "20 pages, 7 figures, 5 tables. Accepted for presentation at the ACM\n  Conference on Economics & Computation 2025 (EC '25); only a one-page extended\n  abstract will appear in the EC '25 proceedings", "summary": "Effective teamwork is essential in structured, performance-driven\nenvironments, from professional organizations to high-stakes competitive\nsettings. As tasks grow more complex, achieving high performance requires not\nonly technical proficiency but also strong interpersonal skills that allow\nindividuals to coordinate effectively within teams. While prior research has\nidentified social skills and familiarity as key drivers of team success, their\njoint effects -- particularly in temporary teams -- remain underexplored due to\ndata and methodological constraints. To address this gap, we analyze a\nlarge-scale panel dataset from the real-time strategy game Age of Empires II,\nwhere players are assigned quasi-randomly to temporary teams and must\ncoordinate under dynamic, high-pressure conditions. We isolate individual\ncontributions by comparing observed match outcomes with predictions based on\ntask proficiency. Our findings confirm a robust 'team player effect': certain\nindividuals consistently improve team outcomes beyond what their technical\nskills predict. This effect is significantly amplified by team familiarity --\nteams with prior shared experience benefit more from the presence of such\nindividuals. Moreover, the effect grows with team size, suggesting that social\nskills become increasingly valuable as coordination demands rise. Our results\ndemonstrate that social skills and familiarity interact in a complementary,\nrather than additive, way. These findings contribute to the literature on team\nperformance by documenting the strength and structure of the team player effect\nin a quasi-randomized, high-stakes setting, with implications for teamwork in\norganizations and labor markets.", "AI": {"title_translation": "是什么推动了团队成功？关于团队合作者效应作用的大规模证据", "tldr": "本研究利用《帝国时代II》的大规模数据集，发现存在一种“团队合作者效应”，即某些个体能显著提升团队表现，且这种效应会随着团队熟悉度和团队规模的增加而增强，表明社交技能和熟悉度是互补的。", "motivation": "以往研究虽已识别出社交技能和熟悉度是团队成功的关键驱动因素，但它们在临时团队中的联合效应，尤其是由于数据和方法限制，仍未得到充分探索。", "method": "本研究分析了来自即时战略游戏《帝国时代II》的大规模面板数据集，其中玩家被准随机分配到临时团队中，并在动态、高压环境下进行协调。通过比较观察到的比赛结果与基于任务熟练度的预测，来分离个体贡献。", "result": "研究证实存在一个稳健的“团队合作者效应”：某些个体能够持续提升团队成果，超出其技术技能的预测。这种效应通过团队熟悉度得到显著放大，并且随着团队规模的增加而增强，表明协调需求增加时社交技能变得越来越有价值。结果表明社交技能和熟悉度以互补而非叠加的方式相互作用。", "conclusion": "社交技能和熟悉度在团队表现中以互补的方式相互作用，存在一个显著的“团队合作者效应”，对组织和劳动力市场中的团队合作具有重要意义。", "translation": "有效的团队合作在结构化、绩效驱动的环境中至关重要，从专业组织到高风险竞争环境。随着任务变得越来越复杂，实现高绩效不仅需要技术熟练度，还需要强大的 H 人际交往能力，使个人能够在团队中有效协调。虽然先前的研究已将社交技能和熟悉度确定为团队成功的关键驱动因素，但由于数据和方法限制，它们在临时团队中的联合效应——尤其是在临时团队中——仍未得到充分探索。为了弥补这一空白，我们分析了来自即时战略游戏《帝国时代II》的大规模面板数据集，其中玩家被准随机分配到临时团队中，并且必须在动态、高压条件下进行协调。我们通过比较观察到的比赛结果与基于任务熟练度的预测来分离个体贡献。我们的发现证实了一个稳健的“团队合作者效应”：某些个体持续改善团队成果，超出其技术技能的预测。这种效应通过团队熟悉度得到显著放大——具有先前共同经验的团队从这些个体的存在中受益更多。此外，这种效应随着团队规模的增加而增长，表明随着协调需求的增加，社交技能变得越来越有价值。我们的结果表明，社交技能和熟悉度以互补而非叠加的方式相互作用。这些发现通过在准随机、高风险环境中记录团队合作者效应的强度和结构，为团队绩效文献做出了贡献，并对组织和劳动力市场中的团队合作具有启示。", "summary": "本研究利用《帝国时代II》的大规模面板数据集，探讨了社交技能和熟悉度在临时团队成功中的联合效应。研究发现，存在一种稳健的“团队合作者效应”，即某些个体在技术技能之外能额外提升团队表现。这种效应随团队熟悉度和团队规模的增加而增强，表明社交技能和熟悉度以互补而非叠加的方式影响团队成功。这些发现为团队绩效文献提供了新的见解，并对组织和劳动力市场中的团队合作具有启示。", "keywords": "团队成功, 团队合作者效应, 社交技能, 团队熟悉度, 大规模证据"}}
{"id": "2506.04464", "pdf": "https://arxiv.org/pdf/2506.04464", "abs": "https://arxiv.org/abs/2506.04464", "authors": ["Oussama Ben Sghaier", "Rosalia Tufano", "Gabriele Bavota", "Houari Sahraoui"], "title": "Leveraging Reward Models for Guiding Code Review Comment Generation", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Code review is a crucial component of modern software development, involving\nthe evaluation of code quality, providing feedback on potential issues, and\nrefining the code to address identified problems. Despite these benefits, code\nreview can be rather time consuming, and influenced by subjectivity and human\nfactors. For these reasons, techniques to (partially) automate the code review\nprocess have been proposed in the literature. Among those, the ones exploiting\ndeep learning (DL) are able to tackle the generative aspect of code review, by\ncommenting on a given code as a human reviewer would do (i.e., comment\ngeneration task) or by automatically implementing code changes required to\naddress a reviewer's comment (i.e., code refinement task). In this paper, we\nintroduce CoRAL, a deep learning framework automating review comment generation\nby exploiting reinforcement learning with a reward mechanism considering both\nthe semantics of the generated comments as well as their usefulness as input\nfor other models automating the code refinement task. The core idea is that if\nthe DL model generates comments that are semantically similar to the expected\nones or can be successfully implemented by a second model specialized in code\nrefinement, these comments are likely to be meaningful and useful, thus\ndeserving a high reward in the reinforcement learning framework. We present\nboth quantitative and qualitative comparisons between the comments generated by\nCoRAL and those produced by the latest baseline techniques, highlighting the\neffectiveness and superiority of our approach.", "AI": {"title_translation": "利用奖励模型指导代码审查评论生成", "tldr": "本文介绍了CoRAL，一个利用强化学习和奖励机制的深度学习框架，用于自动化代码审查评论生成，并证明其性能优于现有方法。", "motivation": "代码审查耗时、主观且受人为因素影响，因此需要自动化技术，特别是生成式评论的自动化。", "method": "本文提出了CoRAL，一个深度学习框架，通过利用强化学习和奖励机制来自动化审查评论的生成。该奖励机制同时考虑了生成评论的语义相似性以及它们作为自动化代码改进任务的其他模型输入的有用性。", "result": "CoRAL生成的评论与最新基线技术生成的评论进行了定量和定性比较，结果突出了CoRAL方法的有效性和优越性。", "conclusion": "CoRAL能够有效自动化代码审查评论生成，产生有意义且有用的评论，并优于现有方法。", "translation": "代码审查是现代软件开发的关键组成部分，涉及评估代码质量、提供潜在问题的反馈以及改进代码以解决已识别的问题。尽管有这些好处，但代码审查可能相当耗时，并受主观性和人为因素的影响。因此，文献中提出了（部分）自动化代码审查过程的技术。其中，利用深度学习（DL）的技术能够解决代码审查的生成方面，通过像人类审阅者那样对给定代码进行评论（即评论生成任务）或自动实现解决审阅者评论所需的代码更改（即代码改进任务）。在本文中，我们介绍了CoRAL，一个通过利用强化学习和奖励机制来自动化审查评论生成的深度学习框架，该奖励机制同时考虑了生成评论的语义以及它们作为自动化代码改进任务的其他模型输入的有用性。核心思想是，如果深度学习模型生成的评论在语义上与预期评论相似，或者可以由专门从事代码改进的第二个模型成功实现，那么这些评论很可能是 H有意义和有用的，从而在强化学习框架中获得高奖励。我们对CoRAL生成的评论与最新基线技术生成的评论进行了定量和定性比较，突出了我们方法的有效性和优越性。", "summary": "本文提出了CoRAL，一个利用强化学习和奖励机制的深度学习框架，旨在自动化代码审查评论的生成。CoRAL通过评估生成评论的语义相似性和对代码改进任务的实用性来提供奖励，实验结果表明CoRAL比现有基线方法更有效和优越。", "keywords": "代码审查, 评论生成, 强化学习, 深度学习, 奖励模型"}}
{"id": "2506.04593", "pdf": "https://arxiv.org/pdf/2506.04593", "abs": "https://arxiv.org/abs/2506.04593", "authors": ["Xun Li", "Qiong Wu"], "title": "Federated Learning Assisted Edge Caching Scheme Based on Lightweight Architecture DDPM", "categories": ["cs.NI", "eess.SP"], "comment": "This paper has been submitted to IEEE letters. The source code has\n  been released at:\n  https://github.com/qiongwu86/Federated-Learning-Assisted-Edge-Caching-Scheme-Based-on-Lightweight-Architecture-DDPM", "summary": "Edge caching is an emerging technology that empowers caching units at edge\nnodes, allowing users to fetch contents of interest that have been pre-cached\nat the edge nodes. The key to pre-caching is to maximize the cache hit\npercentage for cached content without compromising users' privacy. In this\nletter, we propose a federated learning (FL) assisted edge caching scheme based\non lightweight architecture denoising diffusion probabilistic model (LDPM). Our\nsimulation results verify that our proposed scheme achieves a higher cache hit\npercentage compared to existing FL-based methods and baseline methods.", "AI": {"title_translation": "基于轻量级架构DDPM的联邦学习辅助边缘缓存方案", "tldr": "本文提出了一种基于轻量级去噪扩散概率模型（LDPM）的联邦学习（FL）辅助边缘缓存方案，旨在提高缓存命中率并保护用户隐私。", "motivation": "边缘缓存的关键是在不损害用户隐私的情况下，最大限度地提高缓存内容的命中率。", "method": "提出了一种基于轻量级架构去噪扩散概率模型（LDPM）的联邦学习（FL）辅助边缘缓存方案。", "result": "仿真结果验证，该方案与现有基于FL的方法和基线方法相比，实现了更高的缓存命中率。", "conclusion": "该论文提出了一种有效的联邦学习辅助边缘缓存方案，该方案在保护用户隐私的同时，显著提高了缓存命中率。", "translation": "边缘缓存是一项新兴技术，它在边缘节点赋能缓存单元，允许用户获取已预缓存在边缘节点中的感兴趣内容。预缓存的关键是在不损害用户隐私的情况下，最大限度地提高缓存内容的命中率。在本信函中，我们提出了一种基于轻量级架构去噪扩散概率模型（LDPM）的联邦学习（FL）辅助边缘缓存方案。我们的模拟结果验证，与现有基于FL的方法和基线方法相比，我们提出的方案实现了更高的缓存命中率。", "summary": "本文提出了一种基于轻量级架构去噪扩散概率模型（LDPM）的联邦学习（FL）辅助边缘缓存方案，旨在解决边缘缓存中如何在不损害用户隐私的前提下最大化缓存命中率的问题。仿真结果表明，所提出的方案在缓存命中率方面优于现有FL方法和基线方法。", "keywords": "联邦学习, 边缘缓存, 去噪扩散概率模型, 缓存命中率, 轻量级架构"}}
{"id": "2506.04251", "pdf": "https://arxiv.org/pdf/2506.04251", "abs": "https://arxiv.org/abs/2506.04251", "authors": ["Zhengyang Li"], "title": "Language-Guided Multi-Agent Learning in Simulations: A Unified Framework and Evaluation", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "This paper introduces LLM-MARL, a unified framework that incorporates large\nlanguage models (LLMs) into multi-agent reinforcement learning (MARL) to\nenhance coordination, communication, and generalization in simulated game\nenvironments. The framework features three modular components of Coordinator,\nCommunicator, and Memory, which dynamically generate subgoals, facilitate\nsymbolic inter-agent messaging, and support episodic recall. Training combines\nPPO with a language-conditioned loss and LLM query gating. LLM-MARL is\nevaluated in Google Research Football, MAgent Battle, and StarCraft II. Results\nshow consistent improvements over MAPPO and QMIX in win rate, coordination\nscore, and zero-shot generalization. Ablation studies demonstrate that subgoal\ngeneration and language-based messaging each contribute significantly to\nperformance gains. Qualitative analysis reveals emergent behaviors such as role\nspecialization and communication-driven tactics. By bridging language modeling\nand policy learning, this work contributes to the design of intelligent,\ncooperative agents in interactive simulations. It offers a path forward for\nleveraging LLMs in multi-agent systems used for training, games, and human-AI\ncollaboration.", "AI": {"title_translation": "语言引导模拟中的多智能体学习：一个统一的框架与评估", "tldr": "LLM-MARL是一个统一框架，通过集成大型语言模型到多智能体强化学习中，以提升模拟游戏环境中的协调、通信和泛化能力。", "motivation": "在模拟游戏环境中，为了增强多智能体强化学习（MARL）中的协调、通信和泛化能力。", "method": "本研究引入了LLM-MARL，一个将大型语言模型（LLMs）整合到多智能体强化学习（MARL）中的统一框架。该框架包含协调器（Coordinator）、通信器（Communicator）和记忆（Memory）三个模块化组件，分别用于动态生成子目标、促进符号性智能体间消息传递以及支持情景回忆。训练结合了PPO、语言条件损失和LLM查询门控。", "result": "LLM-MARL在Google Research Football、MAgent Battle和StarCraft II中进行了评估，结果显示在胜率、协调分数和零样本泛化方面均优于MAPPO和QMIX。消融研究表明，子目标生成和基于语言的消息传递对性能提升有显著贡献。定性分析揭示了角色专业化和通信驱动策略等 emergent behaviors。", "conclusion": "通过连接语言建模和策略学习，这项工作为交互式模拟中智能合作智能体的设计做出了贡献。它为在用于训练、游戏和人机协作的多智能体系统中利用LLMs提供了前进的方向。", "translation": "本文介绍了LLM-MARL，一个将大型语言模型（LLMs）整合到多智能体强化学习（MARL）中的统一框架，以增强模拟游戏环境中的协调、通信和泛化能力。该框架具有协调器（Coordinator）、通信器（Communicator）和记忆（Memory）三个模块化组件，它们动态生成子目标、促进符号性智能体间消息传递并支持情景回忆。训练结合了PPO、语言条件损失和LLM查询门控。LLM-MARL在Google Research Football、MAgent Battle和StarCraft II中进行了评估。结果显示在胜率、协调分数和零样本泛化方面均持续优于MAPPO和QMIX。消融研究表明，子目标生成和基于语言的消息传递各自对性能提升有显著贡献。定性分析揭示了角色专业化和通信驱动策略等涌现行为。通过连接语言建模和策略学习，这项工作为交互式模拟中智能合作智能体的设计做出了贡献。它为在用于训练、游戏和人机协作的多智能体系统中利用LLMs提供了前进的方向。", "summary": "本论文提出了LLM-MARL，一个将大型语言模型（LLMs）融入多智能体强化学习（MARL）的统一框架，旨在提升模拟游戏环境中的智能体协调、通信和泛化能力。该框架由协调器、通信器和记忆三个模块组成，分别负责生成子目标、促进智能体间消息传递和支持情景回忆。实验结果表明，LLM-MARL在多个模拟环境中相对于现有基线表现出显著提升，并能产生角色专业化和通信驱动的策略等 emergent behaviors。", "keywords": "多智能体强化学习, 大型语言模型, 协调, 通信, 泛化"}}
{"id": "2506.04280", "pdf": "https://arxiv.org/pdf/2506.04280", "abs": "https://arxiv.org/abs/2506.04280", "authors": ["Ziming Cheng", "Binrui Xu", "Lisheng Gong", "Zuhe Song", "Tianshuo Zhou", "Shiqi Zhong", "Siyu Ren", "Mingxiang Chen", "Xiangchao Meng", "Yuxin Zhang", "Yanlin Li", "Lei Ren", "Wei Chen", "Zhiyuan Huang", "Mingjie Zhan", "Xiaojie Wang", "Fangxiang Feng"], "title": "Evaluating MLLMs with Multimodal Multi-image Reasoning Benchmark", "categories": ["cs.CV", "cs.AI", "68T50", "I.2.7"], "comment": "18 pages", "summary": "With enhanced capabilities and widespread applications, Multimodal Large\nLanguage Models (MLLMs) are increasingly required to process and reason over\nmultiple images simultaneously. However, existing MLLM benchmarks focus either\non single-image visual reasoning or on multi-image understanding tasks with\nonly final-answer evaluation, leaving the reasoning capabilities of MLLMs over\nmulti-image inputs largely underexplored. To address this gap, we introduce the\n$\\textbf{Multimodal Multi-image Reasoning Benchmark (MMRB)}$, the first\nbenchmark designed to evaluate structured visual reasoning across multiple\nimages. MMRB comprises $\\textbf{92 sub-tasks}$ covering spatial, temporal, and\nsemantic reasoning, with multi-solution, CoT-style annotations generated by\nGPT-4o and refined by human experts. A derivative subset is designed to\nevaluate multimodal reward models in multi-image scenarios. To support fast and\nscalable evaluation, we propose a sentence-level matching framework using\nopen-source LLMs. Extensive baseline experiments on $\\textbf{40 MLLMs}$,\nincluding 9 reasoning-specific models and 8 reward models, demonstrate that\nopen-source MLLMs still lag significantly behind commercial MLLMs in\nmulti-image reasoning tasks. Furthermore, current multimodal reward models are\nnearly incapable of handling multi-image reward ranking tasks.", "AI": {"title_translation": "使用多模态多图像推理基准评估多模态大语言模型", "tldr": "引入MMRB基准，评估多模态大语言模型在多图像推理方面的能力，发现开源模型和当前奖励模型表现不佳。", "motivation": "现有MLLM基准侧重于单图像视觉推理或仅通过最终答案评估多图像理解，导致MLLM在多图像输入上的推理能力未得到充分探索。", "method": "引入多模态多图像推理基准（MMRB），这是首个旨在评估跨多图像结构化视觉推理的基准。MMRB包含92个涵盖空间、时间和语义推理的子任务，并采用GPT-4o生成并经人工专家完善的多解决方案、CoT风格的标注。提出一个使用开源LLM的句子级匹配框架以支持快速可扩展评估。", "result": "对40个MLLM（包括9个推理专用模型和8个奖励模型）进行广泛的基线实验表明，开源MLLM在多图像推理任务中仍显著落后于商业MLLM。此外，当前的多模态奖励模型几乎无法处理多图像奖励排序任务。", "conclusion": "开源多模态大语言模型在多图像推理任务中显著落后于商业模型，并且当前的多模态奖励模型在多图像奖励排序任务中表现不佳。", "translation": "随着能力的增强和应用的普及，多模态大语言模型（MLLM）越来越需要同时处理和推理多幅图像。然而，现有的MLLM基准要么专注于单图像视觉推理，要么只对多图像理解任务进行最终答案评估，这使得MLLM在多图像输入上的推理能力在很大程度上未被充分探索。为了弥补这一空白，我们引入了\\textbf{多模态多图像推理基准（MMRB）}，这是首个旨在评估跨多图像结构化视觉推理的基准。MMRB包含\\textbf{92个子任务}，涵盖空间、时间、和语义推理，其多解决方案、CoT风格的标注由GPT-4o生成并经人工专家完善。一个派生子集旨在评估多图像场景中的多模态奖励模型。为了支持快速和可扩展的评估，我们提出了一个使用开源LLM的句子级匹配框架。对\\textbf{40个MLLM}（包括9个推理专用模型和8个奖励模型）进行广泛的基线实验表明，开源MLLM在多图像推理任务中仍显著落后于商业MLLM。此外，当前的多模态奖励模型几乎无法处理多图像奖励排序任务。", "summary": "该论文提出了多模态多图像推理基准（MMRB），旨在解决现有MLLM基准在评估多图像推理能力方面的不足。MMRB包含92个子任务，覆盖空间、时间和语义推理，并采用CoT风格标注。研究还提出了一个句子级匹配框架。对40个MLLM的广泛实验表明，开源MLLM在多图像推理方面远不如商业MLLM，且当前多模态奖励模型在多图像奖励排序任务中表现不佳。", "keywords": "多模态大语言模型, 多图像推理, 基准测试, MMRB, 奖励模型"}}
{"id": "2506.05007", "pdf": "https://arxiv.org/pdf/2506.05007", "abs": "https://arxiv.org/abs/2506.05007", "authors": ["Rui Zhang", "Yuanbo Wen", "Shuyao Cheng", "Di Huang", "Shaohui Peng", "Jiaming Guo", "Pengwei Jin", "Jiacheng Zhao", "Tianrui Ma", "Yaoyu Zhu", "Yifan Hao", "Yongwei Zhao", "Shengwen Liang", "Ying Wang", "Xing Hu", "Zidong Du", "Huimin Cui", "Ling Li", "Qi Guo", "Yunji Chen"], "title": "QiMeng: Fully Automated Hardware and Software Design for Processor Chip", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "Processor chip design technology serves as a key frontier driving\nbreakthroughs in computer science and related fields. With the rapid\nadvancement of information technology, conventional design paradigms face three\nmajor challenges: the physical constraints of fabrication technologies, the\nescalating demands for design resources, and the increasing diversity of\necosystems. Automated processor chip design has emerged as a transformative\nsolution to address these challenges. While recent breakthroughs in Artificial\nIntelligence (AI), particularly Large Language Models (LLMs) techniques, have\nopened new possibilities for fully automated processor chip design, substantial\nchallenges remain in establishing domain-specific LLMs for processor chip\ndesign.\n  In this paper, we propose QiMeng, a novel system for fully automated hardware\nand software design of processor chips. QiMeng comprises three hierarchical\nlayers. In the bottom-layer, we construct a domain-specific Large Processor\nChip Model (LPCM) that introduces novel designs in architecture, training, and\ninference, to address key challenges such as knowledge representation gap, data\nscarcity, correctness assurance, and enormous solution space. In the\nmiddle-layer, leveraging the LPCM's knowledge representation and inference\ncapabilities, we develop the Hardware Design Agent and the Software Design\nAgent to automate the design of hardware and software for processor chips.\nCurrently, several components of QiMeng have been completed and successfully\napplied in various top-layer applications, demonstrating significant advantages\nand providing a feasible solution for efficient, fully automated\nhardware/software design of processor chips. Future research will focus on\nintegrating all components and performing iterative top-down and bottom-up\ndesign processes to establish a comprehensive QiMeng system.", "AI": {"title_translation": "启蒙：处理器芯片的全自动化软硬件设计", "tldr": "本文提出了QiMeng系统，通过领域专用大处理器芯片模型（LPCM）实现处理器芯片的软硬件全自动化设计，以应对传统设计挑战。", "motivation": "传统处理器芯片设计面临物理限制、资源需求高和生态系统多样化等挑战。尽管AI和LLMs为自动化设计提供了新机遇，但建立领域专用LLMs仍是重大挑战，因此需要一个能实现全自动化设计的系统。", "method": "本文提出了QiMeng系统，该系统由三个层次组成。底层构建了领域专用大处理器芯片模型（LPCM），旨在解决知识表示鸿沟、数据稀缺、正确性保证和巨大解决方案空间等问题。中层利用LPCM的知识表示和推理能力，开发了硬件设计代理和软件设计代理，以自动化处理器芯片的软硬件设计。", "result": "QiMeng系统的部分组件已经完成，并成功应用于各种顶层应用，展示了显著优势，为处理器芯片的高效、全自动化软硬件设计提供了可行方案。", "conclusion": "QiMeng系统为处理器芯片的全自动化软硬件设计提供了一个可行方案。未来的研究将专注于集成所有组件，并执行迭代的自顶向下和自底向上设计过程，以建立一个全面的QiMeng系统。", "translation": "处理器芯片设计技术是推动计算机科学及相关领域突破的关键前沿。随着信息技术的飞速发展，传统设计范式面临三大主要挑战：制造技术的物理限制、设计资源需求的不断升级以及生态系统日益多样化。自动化处理器芯片设计已成为解决这些挑战的变革性方案。尽管人工智能（AI），特别是大语言模型（LLM）技术最近的突破，为处理器芯片的全自动化设计开辟了新的可能性，但在建立处理器芯片设计的领域专用LLM方面仍存在重大挑战。\n在本文中，我们提出了QiMeng，一个用于处理器芯片全自动化软硬件设计的新颖系统。QiMeng包含三个层次。在底层，我们构建了一个领域专用大处理器芯片模型（LPCM），它在架构、训练和推理方面引入了新颖设计，以解决知识表示鸿沟、数据稀缺、正确性保证和巨大解决方案空间等关键挑战。在中层，利用LPCM的知识表示和推理能力，我们开发了硬件设计代理和软件设计代理，以自动化处理器芯片的硬件和软件设计。目前，QiMeng的几个组件已经完成并成功应用于各种顶层应用，展示了显著优势，并为处理器芯片高效、全自动化软硬件设计提供了可行方案。未来的研究将侧重于集成所有组件并执行迭代的自顶向下和自底向上设计过程，以建立一个全面的QiMeng系统。", "summary": "针对传统处理器芯片设计面临的物理限制、资源需求和生态多样性等挑战，本文提出QiMeng系统，旨在实现处理器芯片的软硬件全自动化设计。QiMeng系统包含三层架构，核心是构建领域专用大处理器芯片模型（LPCM），以解决知识表示、数据稀缺和正确性等问题。目前，QiMeng的多个组件已成功应用，展示了其在自动化设计方面的潜力，未来将致力于全面系统集成。", "keywords": "处理器芯片设计, 全自动化设计, 大语言模型, QiMeng, LPCM"}}
{"id": "2506.04793", "pdf": "https://arxiv.org/pdf/2506.04793", "abs": "https://arxiv.org/abs/2506.04793", "authors": ["Andrea Munari", "Cedomir Stefanovic"], "title": "On the Role of Early-Termination for Age of Information in Tree-Based Random Access Protocols", "categories": ["cs.IT", "cs.NI", "math.IT"], "comment": null, "summary": "Age of Information (AoI) has emerged as a key metric for assessing data\nfreshness in IoT applications, where a large number of devices report\ntime-stamped updates to a monitor. Such systems often rely on random access\nprotocols based on variations of ALOHA at the link layer, where collision\nresolution algorithms play a fundamental role to enable reliable delivery of\npackets. In this context, we provide the first analytical characterization of\naverage AoI for the classical Capetanakis tree-based algorithm with gated\naccess under exogenous traffic, capturing the protocol's dynamics, driven by\nsporadic packet generation and variable collision resolution times. We also\nexplore a variant with early termination, where contention is truncated after a\nmaximum number of slots even if not all users are resolved. The approach\nintroduces a fundamental trade-off between reliability and timeliness, allowing\nstale packets to be dropped to improve freshness.", "AI": {"title_translation": "早期终止在基于树的随机接入协议中信息年龄的作用", "tldr": "研究了早期终止在树状随机接入协议中对信息年龄的影响，发现其能在可靠性和及时性之间进行权衡。", "motivation": "物联网应用中数据新鲜度（信息年龄）评估的重要性，以及随机接入协议（如ALOHA变体）在其中扮演的角色。", "method": "首次对经典Capetanakis树状算法（带门控接入、外生流量）的平均信息年龄进行了分析性表征。还探索了一种带有早期终止的变体，即使未解决所有用户，也会在最大时隙数后截断竞争。", "result": "提供了经典Capetanakis树状算法平均信息年龄的首次分析性表征，捕获了协议动态。引入早期终止变体，发现它在可靠性和及时性之间引入了基本权衡，允许丢弃陈旧数据包以提高新鲜度。", "conclusion": "早期终止机制可以在基于树的随机接入协议中，通过权衡可靠性和及时性，有效改善信息新鲜度。", "translation": "物联网应用中，大量设备向监视器报告带时间戳的更新，信息年龄（AoI）已成为评估数据新鲜度的关键指标。此类系统通常依赖于链路层基于ALOHA变体的随机接入协议，其中碰撞解决算法在实现数据包可靠传输方面发挥着基础性作用。在此背景下，我们首次对经典Capetanakis树状算法在门控接入和外生流量下的平均AoI进行了分析性表征，捕获了由零星数据包生成和可变碰撞解决时间驱动的协议动态。我们还探索了一种带有早期终止的变体，即使并非所有用户都已解决，竞争也会在最大时隙数后被截断。该方法在可靠性和及时性之间引入了根本性的权衡，允许丢弃陈旧数据包以提高新鲜度。", "summary": "本文首次分析性地表征了经典Capetanakis树状随机接入协议中平均信息年龄（AoI），该协议用于评估物联网应用中的数据新鲜度。研究考虑了外生流量和可变碰撞解决时间，并探索了一种带有早期终止的变体。结果表明，早期终止引入了可靠性和及时性之间的权衡，通过丢弃陈旧数据包来提升数据新鲜度。", "keywords": "信息年龄, 早期终止, 树状随机接入协议, 碰撞解决, 物联网"}}
{"id": "2506.04960", "pdf": "https://arxiv.org/pdf/2506.04960", "abs": "https://arxiv.org/abs/2506.04960", "authors": ["Bartłomiej Łazorczyk", "Roger A. Sauer"], "title": "Nonlinear elastodynamic material identification of heterogeneous isogeometric Bernoulli-Euler beams", "categories": ["cs.CE"], "comment": "37 pages, 16 figures, 8 tables", "summary": "This paper presents a Finite Element Model Updating framework for identifying\nheterogeneous material distributions in planar Bernoulli-Euler beams based on a\nrotation-free isogeometric formulation. The procedure follows two steps: First,\nthe elastic properties are identified from quasi-static displacements; then,\nthe density is determined from modal data (low frequencies and mode shapes),\ngiven the previously obtained elastic properties. The identification relies on\nthree independent discretizations: the isogeometric finite element mesh, a\nhigh-resolution grid of experimental measurements, and a material mesh composed\nof low-order Lagrange elements. The material mesh approximates the unknown\nmaterial distributions, with its nodal values serving as design variables. The\nerror between experiments and numerical model is expressed in a least squares\nmanner. The objective is minimized using local optimization with the\ntrust-region method, providing analytical derivatives to accelerate\ncomputations. Several numerical examples exhibiting large displacements are\nprovided to test the proposed approach. To alleviate membrane locking, the B2M1\ndiscretization is employed when necessary. Quasi-experimental data is generated\nusing refined finite element models with random noise applied up to 4%. The\nmethod yields satisfactory results as long as a sufficient amount of\nexperimental data is available, even for high measurement noise. Regularization\nis used to ensure a stable solution for dense material meshes. The density can\nbe accurately reconstructed based on the previously identified elastic\nproperties. The proposed framework can be straightforwardly extended to shells\nand 3D continua.", "AI": {"title_translation": "非线性弹性动力学异质等几何伯努利-欧拉梁材料识别", "tldr": "该论文提出了一个基于等几何有限元模型更新框架，用于识别平面伯努利-欧拉梁中的非均匀材料分布，分两步进行：先识别弹性特性，再根据模态数据识别密度，并在存在噪声的情况下取得了满意的结果。", "motivation": "识别平面伯努利-欧拉梁中的非均匀材料分布。", "method": "本文提出了一种基于无旋转等几何公式的有限元模型更新框架。识别过程分两步：首先，通过准静态位移识别弹性特性；然后，在已知弹性特性的前提下，利用模态数据（低频和模态形状）确定密度。识别过程依赖于等几何有限元网格、高分辨率实验测量网格和由低阶拉格朗日单元组成的材料网格这三种独立离散化。材料网格近似未知材料分布，其节点值作为设计变量。实验与数值模型之间的误差通过最小二乘法表示，并使用带信任域的局部优化方法最小化目标函数，同时提供解析导数以加速计算。为缓解膜锁定，必要时采用B2M1离散化。为确保密集材料网格的稳定解，使用了正则化。", "result": "该方法在有足够实验数据的情况下，即使在高测量噪声下也能获得令人满意的结果。基于先前识别的弹性特性，密度可以被准确重建。通过数值示例验证了该方法在大位移情况下的有效性。", "conclusion": "所提出的框架可以很容易地扩展到壳体和三维连续体。该方法在存在高测量噪声的情况下，只要有足够的实验数据，就能产生令人满意的结果，并且能够准确重建密度。", "translation": "本文提出了一种有限元模型更新框架，用于基于无旋转等几何公式识别平面伯努利-欧拉梁中的异质材料分布。该过程遵循两个步骤：首先，根据准静态位移识别弹性特性；然后，在给定先前获得的弹性特性的情况下，根据模态数据（低频和模态形状）确定密度。识别依赖于三个独立的离散化：等几何有限元网格、高分辨率实验测量网格以及由低阶拉格朗日单元组成的材料网格。材料网格近似未知材料分布，其节点值作为设计变量。实验和数值模型之间的误差以最小二乘方式表示。目标函数使用带信任域方法的局部优化进行最小化，提供解析导数以加速计算。提供了几个表现出大位移的数值示例来测试所提出的方法。为了减轻膜锁定，必要时采用B2M1离散化。准实验数据是使用精细有限元模型生成的，随机噪声高达4%。只要有足够的实验数据可用，即使在测量噪声较高的情况下，该方法也能产生令人满意的结果。使用正则化以确保密集材料网格的稳定解决方案。基于先前识别的弹性特性，可以准确地重建密度。所提出的框架可以很容易地扩展到壳体和三维连续体。", "summary": "本文介绍了一种基于无旋转等几何公式的有限元模型更新框架，用于识别伯努利-欧拉梁中的异质材料分布。该方法分两步进行：首先从准静态位移中识别弹性特性，然后根据模态数据确定密度。它利用三种独立的离散化，并通过带解析导数的信任域局部优化方法最小化误差。数值示例表明，即使在存在高测量噪声的情况下，该方法也能取得满意结果，且密度可准确重建。该框架可扩展应用于壳体和三维连续体。", "keywords": "非线性弹性动力学, 材料识别, 等几何分析, 伯努利-欧拉梁, 有限元模型更新"}}
{"id": "2506.04243", "pdf": "https://arxiv.org/pdf/2506.04243", "abs": "https://arxiv.org/abs/2506.04243", "authors": ["Warayut Dokduea", "Weerachart Tangchirapat", "Sompote Youwai"], "title": "Triple Attention Transformer Architecture for Time-Dependent Concrete Creep Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper presents a novel Triple Attention Transformer Architecture for\npredicting time-dependent concrete creep, addressing fundamental limitations in\ncurrent approaches that treat time as merely an input parameter rather than\nmodeling the sequential nature of deformation development. By transforming\nconcrete creep prediction into an autoregressive sequence modeling task similar\nto language processing, our architecture leverages the transformer's\nself-attention mechanisms to capture long-range dependencies in historical\ncreep patterns. The model implements a triple-stream attention framework\nincorporating temporal attention for sequential progression, feature attention\nfor material property interactions, and batch attention for inter-sample\nrelationships. Evaluated on experimental datasets with standardized daily\nmeasurements spanning 160 days, the architecture achieves exceptional\nperformance with mean absolute percentage error of 1.63% and R2 values of 0.999\nacross all datasets, substantially outperforming traditional empirical models\nand existing machine learning approaches. Ablation studies confirm the critical\nrole of attention mechanisms, with attention pooling contributing most\nsignificantly to model performance. SHAP analysis reveals Young's modulus as\nthe primary predictive feature, followed by density and compressive strength,\nproviding interpretability essential for engineering applications. A deployed\nweb-based interface facilitates practical implementation, enabling real-time\npredictions using standard laboratory parameters. This work establishes the\nviability of applying transformer architectures to materials science problems,\ndemonstrating the potential for data-driven approaches to revolutionize\nstructural behavior prediction and engineering design practices.", "AI": {"title_translation": "混凝土时间依赖性徐变预测的三重注意力Transformer架构", "tldr": "提出一种三重注意力Transformer架构，将混凝土徐变预测视为序列建模任务，实现高精度预测并超越现有方法。", "motivation": "解决当前混凝土徐变预测方法将时间视为普通输入参数，未能有效建模变形发展顺序性的局限性。", "method": "提出三重注意力Transformer架构，将混凝土徐变预测转换为自回归序列建模任务。该架构包含三重流注意力框架：时间注意力（处理顺序进展）、特征注意力（处理材料属性交互）和批次注意力（处理样本间关系）。", "result": "在160天标准化日测量实验数据集上，平均绝对百分比误差为1.63%，R2值为0.999，显著优于传统经验模型和现有机器学习方法。消融研究证实注意力机制的关键作用，其中注意力池化贡献最大。SHAP分析显示杨氏模量是主要预测特征，其次是密度和抗压强度。", "conclusion": "证明Transformer架构应用于材料科学问题的可行性，展示数据驱动方法在革新结构行为预测和工程设计实践方面的潜力。", "translation": "本文提出一种新颖的三重注意力Transformer架构，用于预测时间依赖性混凝土徐变，解决了当前方法中将时间仅视为输入参数而非建模变形发展顺序性的根本局限。通过将混凝土徐变预测转化为类似于语言处理的自回归序列建模任务，我们的架构利用Transformer的自注意力机制来捕获历史徐变模式中的长程依赖关系。该模型实现了三重流注意力框架，包括用于顺序进展的时间注意力、用于材料属性交互的特征注意力以及用于样本间关系的批次注意力。在包含160天标准化日常测量的实验数据集上进行评估，该架构在所有数据集上均取得了卓越的性能，平均绝对百分比误差为1.63%，R2值为0.999，显著优于传统的经验模型和现有的机器学习方法。消融研究证实了注意力机制的关键作用，其中注意力池化对模型性能的贡献最大。SHAP分析揭示杨氏模量是主要的预测特征，其次是密度和抗压强度，这为工程应用提供了必要的解释性。部署的基于Web的界面促进了实际实施，能够使用标准实验室参数进行实时预测。这项工作确立了将Transformer架构应用于材料科学问题的可行性，展示了数据驱动方法在革新结构行为预测和工程设计实践方面的潜力。", "summary": "本文提出一种新颖的三重注意力Transformer架构，用于预测时间依赖性混凝土徐变。该架构将徐变预测转化为自回归序列建模任务，通过时间、特征和批次三重注意力机制捕捉长期依赖关系。在实验数据集上，该模型表现出卓越的性能（MAPE 1.63%，R2 0.999），优于现有方法。研究还强调了注意力机制的关键作用以及杨氏模量作为主要预测特征。该工作证明了Transformer架构在材料科学中的应用潜力，并提供了一个可实际部署的web界面。", "keywords": "混凝土徐变, Transformer, 注意力机制, 时间依赖性, 序列建模"}}
{"id": "2506.04419", "pdf": "https://arxiv.org/pdf/2506.04419", "abs": "https://arxiv.org/abs/2506.04419", "authors": ["Emma Harvey", "Rene F. Kizilcec", "Allison Koenecke"], "title": "A Framework for Auditing Chatbots for Dialect-Based Quality-of-Service Harms", "categories": ["cs.CY"], "comment": "2025 ACM Conference on Fairness, Accountability, and Transparency\n  (FAccT'25)", "summary": "Increasingly, individuals who engage in online activities are expected to\ninteract with large language model (LLM)-based chatbots. Prior work has shown\nthat LLMs can display dialect bias, which occurs when they produce harmful\nresponses when prompted with text written in minoritized dialects. However,\nwhether and how this bias propagates to systems built on top of LLMs, such as\nchatbots, is still unclear. We conduct a review of existing approaches for\nauditing LLMs for dialect bias and show that they cannot be straightforwardly\nadapted to audit LLM-based chatbots due to issues of substantive and ecological\nvalidity. To address this, we present a framework for auditing LLM-based\nchatbots for dialect bias by measuring the extent to which they produce\nquality-of-service harms, which occur when systems do not work equally well for\ndifferent people. Our framework has three key characteristics that make it\nuseful in practice. First, by leveraging dynamically generated instead of\npre-existing text, our framework enables testing over any dialect, facilitates\nmulti-turn conversations, and represents how users are likely to interact with\nchatbots in the real world. Second, by measuring quality-of-service harms, our\nframework aligns audit results with the real-world outcomes of chatbot use.\nThird, our framework requires only query access to an LLM-based chatbot,\nmeaning that it can be leveraged equally effectively by internal auditors,\nexternal auditors, and even individual users in order to promote\naccountability. To demonstrate the efficacy of our framework, we conduct a case\nstudy audit of Amazon Rufus, a widely-used LLM-based chatbot in the customer\nservice domain. Our results reveal that Rufus produces lower-quality responses\nto prompts written in minoritized English dialects, and that these\nquality-of-service harms are exacerbated by the presence of typos in prompts.", "AI": {"title_translation": "用于审计聊天机器人中基于方言的服务质量损害的框架", "tldr": "本文提出了一个审计框架，用于检测大型语言模型（LLM）驱动的聊天机器人中是否存在基于方言的服务质量损害，并通过案例研究验证了其有效性。", "motivation": "现有研究表明大型语言模型（LLM）存在方言偏见，即对少数方言的文本产生有害回复。然而，这种偏见如何传播到基于LLM的聊天机器人中尚不明确，且现有审计方法不适用于聊天机器人。", "method": "本文提出了一个用于审计基于LLM的聊天机器人方言偏见的框架，通过衡量它们产生服务质量损害的程度。该框架具有三个关键特征：利用动态生成文本进行测试，测量服务质量损害，以及仅需要对聊天机器人进行查询访问。作者通过对Amazon Rufus进行案例研究来证明该框架的有效性。", "result": "案例研究结果显示，Amazon Rufus对使用少数英语方言编写的提示产生质量较低的回复，并且提示中存在拼写错误会加剧这些服务质量损害。", "conclusion": "基于LLM的聊天机器人确实存在基于方言的服务质量损害，且本文提出的审计框架能够有效识别这些问题。", "translation": "越来越多地，参与在线活动的个人被期望与基于大型语言模型（LLM）的聊天机器人进行交互。先前的研究表明，LLM可能表现出方言偏见，即当使用少数方言编写的文本进行提示时，它们会产生有害的回复。然而，这种偏见是否以及如何传播到基于LLM的系统，例如聊天机器人，仍不清楚。我们对现有审计LLM方言偏见的方法进行了审查，结果表明由于实质性和生态有效性问题，它们无法直接适用于审计基于LLM的聊天机器人。为了解决这个问题，我们提出了一个审计基于LLM的聊天机器人方言偏见的框架，通过衡量它们产生服务质量损害的程度，即系统对不同人群未能同样良好地工作。我们的框架具有三个使其在实践中非常有用的关键特征。首先，通过利用动态生成而非预先存在的文本，我们的框架能够对任何方言进行测试，促进多轮对话，并代表用户在现实世界中可能与聊天机器人交互的方式。其次，通过测量服务质量损害，我们的框架使审计结果与聊天机器人使用的实际结果保持一致。第三，我们的框架仅需要对基于LLM的聊天机器人进行查询访问，这意味着内部审计师、外部审计师甚至个人用户都可以同样有效地利用它来促进问责制。为了证明我们框架的有效性，我们对Amazon Rufus进行了案例研究审计，它是一个在客户服务领域广泛使用的基于LLM的聊天机器人。我们的结果显示，Rufus对使用少数英语方言编写的提示产生质量较低的回复，并且这些服务质量损害因提示中存在拼写错误而加剧。", "summary": "本文针对大型语言模型（LLM）驱动的聊天机器人中存在的方言偏见问题，提出了一种新的审计框架。该框架旨在衡量聊天机器人因方言差异而产生的服务质量损害，并克服了现有审计方法在适应聊天机器人时的局限性。通过动态生成文本、聚焦实际服务质量损害以及仅需查询访问，该框架提高了审计的实用性和有效性。通过对Amazon Rufus的案例研究，研究发现该聊天机器人对少数英语方言的回复质量较低，并且拼写错误会加剧这种损害。", "keywords": "方言偏见, 聊天机器人, LLM, 服务质量损害, 审计"}}
{"id": "2506.04507", "pdf": "https://arxiv.org/pdf/2506.04507", "abs": "https://arxiv.org/abs/2506.04507", "authors": ["Narangerelt Batsoyol", "Jonathan Guiang", "Diego Davila", "Aashay Arora", "Philip Chang", "Frank Würthwein", "Steven Swanson"], "title": "SkimROOT: Accelerating LHC Data Filtering with Near-Storage Processing", "categories": ["cs.DC"], "comment": "27TH INTERNATIONAL CONFERENCE ON COMPUTING IN HIGH ENERGY & NUCLEAR\n  PHYSICS - 2024", "summary": "Data analysis in high-energy physics (HEP) begins with data reduction, where\nvast datasets are filtered to extract relevant events. At the Large Hadron\nCollider (LHC), this process is bottlenecked by slow data transfers between\nstorage and compute nodes. To address this, we introduce SkimROOT, a near-data\nfiltering system leveraging Data Processing Units (DPUs) to accelerate LHC data\nanalysis. By performing filtering directly on storage servers and returning\nonly the relevant data, SkimROOT minimizes data movement and reduces processing\ndelays. Our prototype demonstrates significant efficiency gains, achieving a\n44.3$\\times$ performance improvement, paving the way for faster physics\ndiscoveries.", "AI": {"title_translation": "SkimROOT：利用近存储处理加速LHC数据过滤", "tldr": "SkimROOT利用DPU在存储服务器上直接过滤LHC数据，显著减少数据传输并加速分析，实现了44.3倍的性能提升。", "motivation": "在高能物理数据分析中，LHC的数据过滤过程受到存储和计算节点之间缓慢数据传输的瓶颈限制，导致数据分析效率低下。", "method": "本文引入了SkimROOT系统，该系统利用数据处理单元（DPUs）在存储服务器上直接执行数据过滤，只返回相关数据，从而最大限度地减少数据移动和处理延迟。", "result": "原型系统展示了显著的效率提升，实现了44.3倍的性能改进。", "conclusion": "通过在存储服务器上直接进行数据过滤，SkimROOT显著加速了LHC数据分析，为更快的物理发现铺平了道路。", "translation": "高能物理（HEP）中的数据分析始于数据缩减，即过滤大量数据集以提取相关事件。在大型强子对撞机（LHC），这一过程受到存储和计算节点之间缓慢数据传输的瓶颈限制。为了解决这个问题，我们引入了SkimROOT，一个利用数据处理单元（DPUs）加速LHC数据分析的近数据过滤系统。通过直接在存储服务器上执行过滤并只返回相关数据，SkimROOT最大限度地减少了数据移动并减少了处理延迟。我们的原型展示了显著的效率提升，实现了44.3倍的性能改进，为更快的物理发现铺平了道路。", "summary": "SkimROOT是一种利用数据处理单元（DPU）在存储服务器上直接过滤大型强子对撞机（LHC）数据的新系统。它通过最小化数据移动来解决存储与计算节点之间的数据传输瓶颈，从而显著减少处理延迟。原型系统展示了44.3倍的性能提升，有望加速高能物理领域的发现。", "keywords": "SkimROOT, LHC数据过滤, 近存储处理, DPU, 高能物理"}}
{"id": "2506.04647", "pdf": "https://arxiv.org/pdf/2506.04647", "abs": "https://arxiv.org/abs/2506.04647", "authors": ["Zixian Gong", "Zhiyong Zheng", "Zhe Hu", "Kun Tian", "Yi Zhang", "Zhedanov Oleksiy", "Fengxia Liu"], "title": "Authenticated Private Set Intersection: A Merkle Tree-Based Approach for Enhancing Data Integrity", "categories": ["cs.CR"], "comment": null, "summary": "Private Set Intersection (PSI) enables secure computation of set\nintersections while preserving participant privacy, standard PSI existing\nprotocols remain vulnerable to data integrity attacks allowing malicious\nparticipants to extract additional intersection information or mislead other\nparties. In this paper, we propose the definition of data integrity in PSI and\nconstruct two authenticated PSI schemes by integrating Merkle Trees with\nstate-of-the-art two-party volePSI and multi-party mPSI protocols. The\nresulting two-party authenticated PSI achieves communication complexity\n$\\mathcal{O}(n \\lambda+n \\log n)$, aligning with the best-known unauthenticated\nPSI schemes, while the multi-party construction is $\\mathcal{O}(n \\kappa+n \\log\nn)$ which introduces additional overhead due to Merkle tree inclusion proofs.\nDue to the incorporation of integrity verification, our authenticated schemes\nincur higher costs compared to state-of-the-art unauthenticated schemes. We\nalso provide efficient implementations of our protocols and discuss potential\nimprovements, including alternative authentication blocks.", "AI": {"title_translation": "认证私有集合交集：一种基于Merkle树的增强数据完整性方法", "tldr": "提出了基于Merkle树的认证私有集合交集方案，以增强数据完整性，解决了现有PSI协议的数据完整性攻击问题，并分析了其通信开销。", "motivation": "标准私有集合交集（PSI）协议容易受到数据完整性攻击，恶意参与者可以提取额外交集信息或误导其他方。", "method": "本文定义了PSI中的数据完整性，并通过将Merkle树与最先进的两方volePSI和多方mPSI协议集成，构建了两种认证PSI方案。", "result": "两方认证PSI的通信复杂度为$\\mathcal{O}(n \\lambda+n \\log n)$，与最佳未认证PSI方案一致。多方构造的通信复杂度为$\\mathcal{O}(n \\kappa+n \\log n)$，引入了额外开销。认证方案的成本高于最先进的未认证方案。提供了协议的高效实现并讨论了潜在改进。", "conclusion": "通过整合Merkle树，成功构建了具有数据完整性保证的认证私有集合交集方案，尽管会带来更高的计算开销，但有效提升了PSI协议的安全性。", "translation": "私有集合交集（PSI）能够在保护参与者隐私的同时安全计算集合交集，但现有的标准PSI协议仍然容易受到数据完整性攻击，允许恶意参与者提取额外的交集信息或误导其他方。在本文中，我们提出了PSI中数据完整性的定义，并通过将Merkle树与最先进的两方volePSI和多方mPSI协议集成，构建了两种认证PSI方案。由此产生的两方认证PSI实现了$\\mathcal{O}(n \\lambda+n \\log n)$的通信复杂度，与已知最佳的未认证PSI方案保持一致；而多方构造的通信复杂度为$\\mathcal{O}(n \\kappa+n \\log n)$，这由于包含Merkle树证明引入了额外的开销。由于引入了完整性验证，我们的认证方案相比最先进的未认证方案会产生更高的成本。我们还提供了协议的高效实现，并讨论了潜在的改进，包括替代的认证块。", "summary": "本文定义了私有集合交集（PSI）中的数据完整性，并提出了两种基于Merkle树的认证PSI方案，分别用于两方和多方场景。这些方案通过集成Merkle树与现有的volePSI和mPSI协议，解决了传统PSI协议在数据完整性方面的漏洞。研究分析了方案的通信复杂度，指出认证方案虽然带来了更高的开销，但能有效增强数据完整性，并提供了实现细节和改进方向。", "keywords": "私有集合交集, 数据完整性, Merkle树, 认证PSI, 安全计算"}}
{"id": "2506.04266", "pdf": "https://arxiv.org/pdf/2506.04266", "abs": "https://arxiv.org/abs/2506.04266", "authors": ["Timo Looms", "Lin Xie"], "title": "CPU-Based Layout Design for Picker-to-Parts Pallet Warehouses", "categories": ["cs.MA", "cs.AR"], "comment": "8 pages,6 figures, conference", "summary": "Picker-to-parts pallet warehouses often face inefficiencies due to\nconventional layouts causing excessive travel distances and high labor\nrequirements. This study introduces a novel layout design inspired by CPU\narchitecture, partitioning warehouse space into specialized zones, namely\nPerformance (P), Efficiency (E), and Shared (S). Discrete-event simulation is\nused to evaluate this design against traditional rectangular (random and ABC\nstorage) and Flying-V layouts. Results demonstrate significant improvements in\nthroughput time and reduced labor requirements, highlighting the potential for\nCPU-based layouts in optimizing warehouse operations.", "AI": {"title_translation": "基于CPU的拣选到部件托盘仓库布局设计", "tldr": "本研究提出了一种受CPU架构启发的仓库布局设计（CPU-based），旨在解决传统布局导致的低效率问题，并通过仿真验证了其在提高吞吐时间和降低劳动力需求方面的显著优势。", "motivation": "传统拣选到部件托盘仓库布局通常导致过长的移动距离和高昂的劳动力需求，造成效率低下。", "method": "本研究引入了一种受CPU架构启发的创新布局设计，将仓库空间划分为性能（P）、效率（E）和共享（S）专业区域。通过离散事件仿真，将此设计与传统的矩形布局（随机和ABC存储）以及“飞V”形布局进行比较评估。", "result": "结果表明，与传统布局相比，CPU-based布局在吞吐时间上取得了显著改善，并降低了劳动力需求。", "conclusion": "CPU-based布局在优化仓库运营方面具有巨大潜力。", "translation": "拣选到部件托盘仓库由于传统布局导致过长的移动距离和高昂的劳动力需求，常常面临效率低下的问题。本研究引入了一种受CPU架构启发的创新布局设计，将仓库空间划分为专业区域，即性能（P）、效率（E）和共享（S）。离散事件仿真用于评估此设计与传统矩形（随机和ABC存储）和“飞V”形布局的对比。结果表明，在吞吐时间上取得了显著改善，并降低了劳动力需求，突出了基于CPU的布局在优化仓库运营方面的潜力。", "summary": "本研究针对拣选到部件托盘仓库中传统布局效率低下的问题，提出了一种受CPU架构启发的创新布局设计，将仓库划分为性能、效率和共享区域。通过离散事件仿真与现有布局进行对比评估，结果显示新设计显著提高了吞吐时间并降低了劳动力需求，表明其在优化仓库运营方面的巨大潜力。", "keywords": "CPU-based布局, 仓库设计, 拣选到部件, 离散事件仿真, 吞吐量优化"}}
{"id": "2506.04484", "pdf": "https://arxiv.org/pdf/2506.04484", "abs": "https://arxiv.org/abs/2506.04484", "authors": ["William Ward", "Sarah Etter", "Tyler Ingebrand", "Christian Ellis", "Adam J. Thorpe", "Ufuk Topcu"], "title": "Online Adaptation of Terrain-Aware Dynamics for Planning in Unstructured Environments", "categories": ["cs.RO"], "comment": "Accepted to RSS-ROAR 2025", "summary": "Autonomous mobile robots operating in remote, unstructured environments must\nadapt to new, unpredictable terrains that can change rapidly during operation.\nIn such scenarios, a critical challenge becomes estimating the robot's dynamics\non changing terrain in order to enable reliable, accurate navigation and\nplanning. We present a novel online adaptation approach for terrain-aware\ndynamics modeling and planning using function encoders. Our approach\nefficiently adapts to new terrains at runtime using limited online data without\nretraining or fine-tuning. By learning a set of neural network basis functions\nthat span the robot dynamics on diverse terrains, we enable rapid online\nadaptation to new, unseen terrains and environments as a simple least-squares\ncalculation. We demonstrate our approach for terrain adaptation in a\nUnity-based robotics simulator and show that the downstream controller has\nbetter empirical performance due to higher accuracy of the learned model. This\nleads to fewer collisions with obstacles while navigating in cluttered\nenvironments as compared to a neural ODE baseline.", "AI": {"title_translation": "非结构化环境下地形感知动力学在线自适应规划", "tldr": "本文提出了一种利用函数编码器进行地形感知动力学建模和规划的在线自适应方法，该方法无需重新训练即可快速适应新地形，并在模拟器中展示了更好的导航性能和更少的碰撞。", "motivation": "自主移动机器人在远程、非结构化环境中运行时，需要适应新的、不可预测且可能快速变化的地形。在这种场景下，准确估计机器人在变化地形上的动力学特性以实现可靠、精确的导航和规划成为一个关键挑战。", "method": "我们提出了一种新颖的在线自适应方法，用于地形感知动力学建模和规划，该方法使用函数编码器。我们的方法可以在运行时使用有限的在线数据高效地适应新地形，无需重新训练或微调。通过学习一组跨越不同地形机器人动力学的神经网络基函数，我们实现了对新的、未知地形和环境的快速在线自适应，仅通过简单的最小二乘计算。", "result": "我们在一个基于Unity的机器人模拟器中展示了我们的地形自适应方法，并表明由于学习模型的更高精度，下游控制器具有更好的经验性能。与神经ODE基线相比，这在杂乱环境中导航时导致更少的障碍物碰撞。", "conclusion": "该方法通过在线自适应地形感知动力学模型，显著提高了机器人在非结构化环境中的导航性能和避障能力。", "translation": "在远程、非结构化环境中运行的自主移动机器人必须适应新的、不可预测且在操作过程中可能快速变化的地形。在这种场景下，一个关键挑战是如何估计机器人在变化地形上的动力学特性，以实现可靠、准确的导航和规划。我们提出了一种新颖的在线自适应方法，用于地形感知动力学建模和规划，该方法使用函数编码器。我们的方法可以在运行时使用有限的在线数据高效地适应新地形，无需重新训练或微调。通过学习一组跨越不同地形机器人动力学的神经网络基函数，我们实现了对新的、未知地形和环境的快速在线自适应，仅通过简单的最小二乘计算。我们在一个基于Unity的机器人模拟器中展示了我们的地形自适应方法，并表明由于学习模型的更高精度，下游控制器具有更好的经验性能。与神经ODE基线相比，这在杂乱环境中导航时导致更少的障碍物碰撞。", "summary": "本文介绍了一种用于非结构化环境中机器人规划的在线地形感知动力学自适应方法。该方法利用函数编码器学习神经网络基函数，从而在运行时无需重新训练即可快速适应未知地形。在Unity模拟器中的实验表明，该方法提高了控制器的性能，减少了导航过程中的碰撞，优于基线方法。", "keywords": "在线自适应, 地形感知动力学, 机器人规划, 函数编码器, 非结构化环境"}}
{"id": "2506.04435", "pdf": "https://arxiv.org/pdf/2506.04435", "abs": "https://arxiv.org/abs/2506.04435", "authors": ["Kate Barnes", "Mia Ellis-Einhorn", "Carolina Chávez-Ruelas", "Nayera Hasan", "Mohammad Fanous", "Blair D. Sullivan", "Sorelle Friedler", "Aaron Clauset"], "title": "Edge interventions can mitigate demographic and prestige disparities in the Computer Science coauthorship network", "categories": ["physics.soc-ph", "cs.CY", "cs.SI"], "comment": "14 pages, 6 figures, 2 appendices (5 figures, 6 tables)", "summary": "Social factors such as demographic traits and institutional prestige\nstructure the creation and dissemination of ideas in academic publishing. One\nplace these effects can be observed is in how central or peripheral a\nresearcher is in the coauthorship network. Here we investigate inequities in\nnetwork centrality in a hand-collected data set of 5,670 U.S.-based faculty\nemployed in Ph.D.-granting Computer Science departments and their DBLP\ncoauthorship connections. We introduce algorithms for combining name- and\nperception-based demographic labels by maximizing alignment with self-reported\ndemographics from a survey of faculty from our census. We find that women and\nindividuals with minoritized race identities are less central in the computer\nscience coauthorship network, implying worse access to and ability to spread\ninformation. Centrality is also highly correlated with prestige, such that\nfaculty in top-ranked departments are at the core and those in low-ranked\ndepartments are in the peripheries of the computer science coauthorship\nnetwork. We show that these disparities can be mitigated using simulated edge\ninterventions, interpreted as facilitated collaborations. Our intervention\nincreases the centrality of target individuals, chosen independently of the\nnetwork structure, by linking them with researchers from highly ranked\ninstitutions. When applied to scholars during their Ph.D., the intervention\nalso improves the predicted rank of their placement institution in the academic\njob market. This work was guided by an ameliorative approach: uncovering social\ninequities in order to address them. By targeting scholars for intervention\nbased on institutional prestige, we are able to improve their centrality in the\ncoauthorship network that plays a key role in job placement and longer-term\nacademic success.", "AI": {"title_translation": "边缘干预可以减轻计算机科学合著网络中的人口统计学和声望差异", "tldr": "研究发现计算机科学合著网络存在人口统计学和声望差异，通过模拟边缘干预（促进合作）可以减轻这些不平等，提高目标学者的中心性。", "motivation": "社会因素（如人口特征和机构声望）影响学术出版中思想的创造和传播，导致研究人员在合著网络中的中心或边缘地位存在不平等。本研究旨在揭示并解决这些社会不平等。", "method": "本研究调查了5,670名美国博士授予计算机科学系教职员工及其DBLP合著关系数据集中的网络中心性不平等。引入了结合姓名和感知的人口统计学标签算法。通过模拟边缘干预（解释为促进合作），将独立于网络结构选择的目标个体与来自高排名机构的研究人员联系起来，以减轻不平等。", "result": "研究发现女性和少数族裔在计算机科学合著网络中中心性较低，暗示信息获取和传播能力较差。中心性与声望高度相关，顶尖院系教职员工处于网络核心，低排名院系处于边缘。模拟边缘干预能够减轻这些差异，提高目标个体的中心性。对博士生应用干预措施，还能改善他们在学术就业市场中预测的安置机构排名。", "conclusion": "通过针对机构声望进行干预，可以提高学者在合著网络中的中心性，这对于他们的就业安置和长期学术成功至关重要。本工作旨在揭示社会不平等并提出解决方案。", "translation": "社会因素，如人口特征和机构声望，构建了学术出版中思想的创造和传播。这些影响可以在研究人员在合著网络中的中心或边缘地位中观察到。在这里，我们调查了在一个手工收集的包含5,670名美国博士授予计算机科学系教职员工及其DBLP合著关系的数据集中，网络中心性的不平等。我们引入了结合姓名和感知的人口统计学标签算法，通过最大化与我们普查中教职员工调查自报人口统计学的一致性。我们发现女性和少数族裔在计算机科学合著网络中中心性较低，这意味着信息获取和传播能力较差。中心性也与声望高度相关，顶尖院系教职员工处于核心，低排名院系处于计算机科学合著网络的边缘。我们表明这些差异可以通过模拟边缘干预（解释为促进合作）来减轻。我们的干预措施通过将目标个体（独立于网络结构选择）与来自高排名机构的研究人员联系起来，增加了他们的中心性。当应用于博士生时，该干预措施还改善了他们在学术就业市场中预测的安置机构排名。这项工作以一种改进方法为指导：揭示社会不平等以便解决它们。通过根据机构声望对学者进行干预，我们能够提高他们在合著网络中的中心性，这在就业安置和长期学术成功中起着关键作用。", "summary": "本文研究了计算机科学合著网络中存在的人口统计学和机构声望差异，发现女性、少数族裔以及低排名机构的学者在网络中处于较低的中心位置。研究提出了一种通过模拟边缘干预（即促进合作）的方法，将目标学者与高排名机构的研究人员联系起来，以提高其中心性。结果表明这种干预措施能有效减轻不平等，并对博士生的学术就业前景产生积极影响。该研究旨在通过揭示和解决社会不平等来改进学术生态。", "keywords": "计算机科学, 合著网络, 不平等, 边缘干预, 中心性"}}
{"id": "2506.04509", "pdf": "https://arxiv.org/pdf/2506.04509", "abs": "https://arxiv.org/abs/2506.04509", "authors": ["Kishan Kumar Ganguly", "Tim Menzies"], "title": "BINGO! Simple Optimizers Win Big if Problems Collapse to a Few Buckets", "categories": ["cs.SE"], "comment": null, "summary": "Traditional multi-objective optimization in software engineering (SE) can be\nslow and complex. This paper introduces the BINGO effect: a novel phenomenon\nwhere SE data surprisingly collapses into a tiny fraction of possible solution\n\"buckets\" (e.g., only 100 used from 4,096 expected).\n  We show the BINGO effect's prevalence across 39 optimization in SE problems.\nExploiting this, we optimize 10,000 times faster than state-of-the-art methods,\nwith comparable effectiveness. Our new algorithms (LITE and LINE), demonstrate\nthat simple stochastic selection can match complex optimizers like DEHB. This\nwork explains why simple methods succeed in SE-real data occupies a small\ncorner of possibilities-and guides when to apply them, challenging the need for\nCPU-heavy optimization.\n  Our data and code are public at GitHub (see anon-artifacts/bingo).", "AI": {"title_translation": "BINGO! 当问题收敛到少数几个“桶”时，简单优化器也能大获成功", "tldr": "本文介绍了BINGO效应，即软件工程数据惊人地收敛到极少数的解决方案“桶”中。利用这一现象，我们开发了两种新算法（LITE和LINE），其优化速度比现有技术快10,000倍，且效果相当，挑战了对CPU密集型优化器的需求。", "motivation": "传统的软件工程（SE）多目标优化方法速度慢且复杂。", "method": "本文引入了BINGO效应的概念，并展示了它在39个软件工程优化问题中的普遍性。利用这一效应，本文提出了两种新的算法LITE和LINE，它们通过简单的随机选择就能实现优化。", "result": "SE数据惊人地收敛到极少数的解决方案“桶”中（例如，预期4,096个中仅使用了100个）。在39个SE优化问题中普遍存在BINGO效应。优化速度比现有技术快10,000倍，且效果相当。新算法（LITE和LINE）表明简单的随机选择可以与复杂的优化器（如DEHB）相媲美。", "conclusion": "简单的优化方法在软件工程中是成功的，因为真实数据占据了可能性空间的一小部分，这挑战了对CPU密集型优化器的需求。", "translation": "软件工程（SE）中传统的多目标优化可能既缓慢又复杂。本文介绍了BINGO效应：一种新颖的现象，即SE数据惊人地收敛到极少数可能的解决方案“桶”中（例如，预期4,096个中仅使用了100个）。\n我们展示了BINGO效应在39个SE优化问题中的普遍性。利用这一点，我们的优化速度比现有技术快10,000倍，且效果相当。我们的新算法（LITE和LINE）表明，简单的随机选择可以与DEHB等复杂优化器相媲美。这项工作解释了为什么简单方法在SE中能够成功——真实数据占据了可能性空间的一小部分——并指导何时应用它们，挑战了对CPU密集型优化的需求。\n我们的数据和代码已在GitHub上公开（参见anon-artifacts/bingo）。", "summary": "本文揭示了软件工程（SE）优化中一个名为“BINGO效应”的新现象，即SE数据出人意料地收敛到极少数的解决方案“桶”中。研究表明，这种效应在39个SE优化问题中普遍存在。利用BINGO效应，本文提出的LITE和LINE两种简单随机选择算法，其优化速度比现有技术快10,000倍，且效果相当，这证明了在SE领域中简单方法也能取得成功，并质疑了对复杂、计算密集型优化器的必要性。", "keywords": "BINGO效应, 软件工程优化, 简单优化器, 多目标优化, LITE和LINE算法"}}
{"id": "2506.04594", "pdf": "https://arxiv.org/pdf/2506.04594", "abs": "https://arxiv.org/abs/2506.04594", "authors": ["Shumin Lian", "Jingwen Tong", "Jun Zhang", "Liqun Fu"], "title": "Intelligent Channel Allocation for IEEE 802.11be Multi-Link Operation: When MAB Meets LLM", "categories": ["cs.NI", "cs.AI", "eess.SP", "I.2.7"], "comment": "This work has been accepted by JSAC 2025", "summary": "WiFi networks have achieved remarkable success in enabling seamless\ncommunication and data exchange worldwide. The IEEE 802.11be standard, known as\nWiFi 7, introduces Multi-Link Operation (MLO), a groundbreaking feature that\nenables devices to establish multiple simultaneous connections across different\nbands and channels. While MLO promises substantial improvements in network\nthroughput and latency reduction, it presents significant challenges in channel\nallocation, particularly in dense network environments. Current research has\npredominantly focused on performance analysis and throughput optimization\nwithin static WiFi 7 network configurations. In contrast, this paper addresses\nthe dynamic channel allocation problem in dense WiFi 7 networks with MLO\ncapabilities. We formulate this challenge as a combinatorial optimization\nproblem, leveraging a novel network performance analysis mechanism. Given the\ninherent lack of prior network information, we model the problem within a\nMulti-Armed Bandit (MAB) framework to enable online learning of optimal channel\nallocations. Our proposed Best-Arm Identification-enabled Monte Carlo Tree\nSearch (BAI-MCTS) algorithm includes rigorous theoretical analysis, providing\nupper bounds for both sample complexity and error probability. To further\nreduce sample complexity and enhance generalizability across diverse network\nscenarios, we put forth LLM-BAI-MCTS, an intelligent algorithm for the dynamic\nchannel allocation problem by integrating the Large Language Model (LLM) into\nthe BAI-MCTS algorithm. Numerical results demonstrate that the BAI-MCTS\nalgorithm achieves a convergence rate approximately $50.44\\%$ faster than the\nstate-of-the-art algorithms when reaching $98\\%$ of the optimal value. Notably,\nthe convergence rate of the LLM-BAI-MCTS algorithm increases by over $63.32\\%$\nin dense networks.", "AI": {"title_translation": "IEEE 802.11be多链路操作的智能信道分配：当MAB遇到LLM", "tldr": "针对WiFi 7 MLO动态信道分配问题，提出结合MAB和LLM的算法，显著提升收敛速度。", "motivation": "IEEE 802.11be (WiFi 7) 的多链路操作 (MLO) 虽能提升吞吐量和降低延迟，但在密集网络环境中面临信道分配的重大挑战，现有研究主要关注静态配置下的性能分析和吞吐量优化，缺乏对动态信道分配问题的解决。", "method": "将动态信道分配问题建模为组合优化问题，并利用新型网络性能分析机制。由于缺乏先验网络信息，在多臂老虎机 (MAB) 框架下建模，以实现在线学习最优信道分配。提出基于最佳臂识别的蒙特卡洛树搜索 (BAI-MCTS) 算法，并提供理论分析。为进一步降低样本复杂度并增强泛化能力，将大语言模型 (LLM) 集成到BAI-MCTS中，提出LLM-BAI-MCTS算法。", "result": "BAI-MCTS算法在达到最佳值98%时，收敛速度比现有最先进算法快约50.44%。LLM-BAI-MCTS算法在密集网络中收敛速度提升超过63.32%。", "conclusion": "结合MAB和LLM的算法（BAI-MCTS和LLM-BAI-MCTS）能有效解决WiFi 7 MLO中的动态信道分配问题，并显著提升收敛速度，尤其在密集网络环境中表现更优。", "translation": "WiFi网络在实现全球无缝通信和数据交换方面取得了显著成功。IEEE 802.11be标准，即WiFi 7，引入了多链路操作（MLO），这是一项突破性功能，允许设备在不同频段和信道上建立多个同时连接。尽管MLO有望大幅提高网络吞吐量并减少延迟，但它在信道分配方面带来了重大挑战，尤其是在密集网络环境中。当前研究主要集中在静态WiFi 7网络配置下的性能分析和吞吐量优化。与此相反，本文解决了具有MLO功能的密集WiFi 7网络中的动态信道分配问题。我们将这一挑战表述为组合优化问题，利用一种新颖的网络性能分析机制。考虑到固有的先验网络信息缺乏，我们在多臂老虎机（MAB）框架内建模该问题，以实现在线学习最优信道分配。我们提出的基于最佳臂识别的蒙特卡洛树搜索（BAI-MCTS）算法包括严谨的理论分析，提供了样本复杂度和错误概率的上限。为了进一步降低样本复杂度和增强在不同网络场景中的泛化能力，我们通过将大语言模型（LLM）集成到BAI-MCTS算法中，提出了LLM-BAI-MCTS，一种用于动态信道分配问题的智能算法。数值结果表明，BAI-MCTS算法在达到最佳值98%时，收敛速度比现有最先进算法快约50.44%。值得注意的是，LLM-BAI-MCTS算法在密集网络中的收敛速度提高了超过63.32%。", "summary": "本文针对IEEE 802.11be (WiFi 7) 多链路操作 (MLO) 在密集网络中的动态信道分配难题，将其建模为组合优化问题，并利用多臂老虎机 (MAB) 框架进行在线学习。作者提出了BAI-MCTS算法，并进一步引入大语言模型 (LLM) 提出LLM-BAI-MCTS算法。数值结果表明，BAI-MCTS算法收敛速度比现有SOTA算法快约50.44%，而LLM-BAI-MCTS在密集网络中收敛速度提升超过63.32%，显示了所提算法在解决动态信道分配问题上的优越性能。", "keywords": "IEEE 802.11be, 多链路操作 (MLO), 信道分配, 多臂老虎机 (MAB), 大语言模型 (LLM)"}}
{"id": "2506.04252", "pdf": "https://arxiv.org/pdf/2506.04252", "abs": "https://arxiv.org/abs/2506.04252", "authors": ["Yang Zhao", "Chengxiao Dai", "Dusit Niyato", "Chuan Fu Tan", "Keyi Xiang", "Yueyang Wang", "Zhiquan Yeo", "Daren Tan Zong Loong", "Jonathan Low Zhaozhi", "Eugene H. Z. HO"], "title": "A Graph-Retrieval-Augmented Generation Framework Enhances Decision-Making in the Circular Economy", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) hold promise for sustainable manufacturing, but\noften hallucinate industrial codes and emission factors, undermining regulatory\nand investment decisions. We introduce CircuGraphRAG, a retrieval-augmented\ngeneration (RAG) framework that grounds LLMs outputs in a domain-specific\nknowledge graph for the circular economy. This graph connects 117,380\nindustrial and waste entities with classification codes and GWP100 emission\ndata, enabling structured multi-hop reasoning. Natural language queries are\ntranslated into SPARQL and verified subgraphs are retrieved to ensure accuracy\nand traceability. Compared with Standalone LLMs and Naive RAG, CircuGraphRAG\nachieves superior performance in single-hop and multi-hop question answering,\nwith ROUGE-L F1 scores up to 1.0, while baseline scores below 0.08. It also\nimproves efficiency, halving the response time and reducing token usage by 16%\nin representative tasks. CircuGraphRAG provides fact-checked, regulatory-ready\nsupport for circular economy planning, advancing reliable, low-carbon resource\ndecision making.", "AI": {"title_translation": "图检索增强生成框架增强循环经济决策", "tldr": "CircuGraphRAG是一个基于知识图谱的检索增强生成（RAG）框架，它通过将大型语言模型（LLMs）的输出与循环经济领域的专业知识图谱相结合，解决了LLMs在可持续制造中出现的幻觉问题，从而提高了决策的准确性和效率。", "motivation": "大型语言模型（LLMs）在可持续制造中具有潜力，但它们经常对工业代码和排放因子产生“幻觉”，这会损害监管和投资决策。", "method": "本文引入了CircuGraphRAG，一个检索增强生成（RAG）框架，它将LLMs的输出基于循环经济领域的知识图谱。该图谱连接了117,380个工业和废物实体，包含分类代码和GWP100排放数据，支持结构化的多跳推理。自然语言查询被翻译成SPARQL，并检索经过验证的子图以确保准确性和可追溯性。", "result": "与独立的LLMs和朴素RAG相比，CircuGraphRAG在单跳和多跳问答中表现出卓越的性能，ROUGE-L F1分数高达1.0，而基线分数低于0.08。它还提高了效率，在代表性任务中将响应时间缩短一半，并将令牌使用量减少16%。", "conclusion": "CircuGraphRAG为循环经济规划提供了经过事实核查、符合监管要求的支持，从而推动了可靠、低碳的资源决策。", "translation": "大型语言模型（LLMs）在可持续制造中具有广阔前景，但它们经常对工业代码和排放因子产生“幻觉”，这会损害监管和投资决策。我们引入了CircuGraphRAG，一个检索增强生成（RAG）框架，它将LLMs的输出基于循环经济领域的专业知识图谱。该图谱连接了117,380个工业和废物实体，包含分类代码和GWP100排放数据，从而实现了结构化的多跳推理。自然语言查询被翻译成SPARQL，并检索经过验证的子图以确保准确性和可追溯性。与独立的LLMs和朴素RAG相比，CircuGraphRAG在单跳和多跳问答中取得了卓越的性能，ROUGE-L F1分数高达1.0，而基线分数低于0.08。它还提高了效率，在代表性任务中将响应时间缩短一半，并将令牌使用量减少16%。CircuGraphRAG为循环经济规划提供了经过事实核查、符合监管要求的支持，从而推动了可靠、低碳的资源决策。", "summary": "本研究提出了CircuGraphRAG，一个利用领域特定知识图谱的检索增强生成（RAG）框架，旨在解决大型语言模型（LLMs）在可持续制造中产生错误信息的问题。该框架通过将自然语言查询转换为SPARQL并检索验证过的子图来确保输出的准确性。实验结果表明，CircuGraphRAG在问答性能和效率方面均优于现有方法，为循环经济决策提供了可靠支持。", "keywords": "检索增强生成, 知识图谱, 循环经济, 大型语言模型, 决策支持"}}
{"id": "2506.04351", "pdf": "https://arxiv.org/pdf/2506.04351", "abs": "https://arxiv.org/abs/2506.04351", "authors": ["Maksym Ivashechkin", "Oscar Mendez", "Richard Bowden"], "title": "HuGeDiff: 3D Human Generation via Diffusion with Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "3D human generation is an important problem with a wide range of applications\nin computer vision and graphics. Despite recent progress in generative AI such\nas diffusion models or rendering methods like Neural Radiance Fields or\nGaussian Splatting, controlling the generation of accurate 3D humans from text\nprompts remains an open challenge. Current methods struggle with fine detail,\naccurate rendering of hands and faces, human realism, and controlability over\nappearance. The lack of diversity, realism, and annotation in human image data\nalso remains a challenge, hindering the development of a foundational 3D human\nmodel. We present a weakly supervised pipeline that tries to address these\nchallenges. In the first step, we generate a photorealistic human image dataset\nwith controllable attributes such as appearance, race, gender, etc using a\nstate-of-the-art image diffusion model. Next, we propose an efficient mapping\napproach from image features to 3D point clouds using a transformer-based\narchitecture. Finally, we close the loop by training a point-cloud diffusion\nmodel that is conditioned on the same text prompts used to generate the\noriginal samples. We demonstrate orders-of-magnitude speed-ups in 3D human\ngeneration compared to the state-of-the-art approaches, along with\nsignificantly improved text-prompt alignment, realism, and rendering quality.\nWe will make the code and dataset available.", "AI": {"title_translation": "HuGeDiff：基于高斯泼溅的扩散式3D人体生成", "tldr": "HuGeDiff提出了一种弱监督流水线，结合图像扩散模型和点云扩散模型，实现快速、逼真且可控的3D人体生成。", "motivation": "尽管在生成AI（如扩散模型）和渲染方法（如神经辐射场、高斯泼溅）方面取得了进展，但从文本提示生成精确3D人体仍然是一个开放的挑战。现有方法在细节、手和面部渲染、人体真实感和外观可控性方面存在不足。此外，人体图像数据缺乏多样性、真实性和标注，阻碍了基础3D人体模型的发展。", "method": "本文提出了一种弱监督流水线来解决这些挑战。首先，使用先进的图像扩散模型生成一个具有可控属性（如外观、种族、性别等）的逼真人体图像数据集。其次，提出一种高效的映射方法，使用基于Transformer的架构将图像特征映射到3D点云。最后，通过训练一个点云扩散模型来完成闭环，该模型以与生成原始样本相同的文本提示为条件。", "result": "与现有最先进的方法相比，在3D人体生成速度方面实现了数量级的提升，并且显著改善了文本提示对齐、真实感和渲染质量。", "conclusion": "HuGeDiff成功地解决了3D人体生成中的多项挑战，通过结合图像和点云扩散模型，实现了更快速、更逼真、更可控的生成效果。", "translation": "3D人体生成是计算机视觉和图形学中一个重要的问题，具有广泛的应用。尽管生成式AI（如扩散模型）或渲染方法（如神经辐射场或高斯泼溅）最近取得了进展，但从文本提示控制精确3D人体生成仍然是一个开放的挑战。当前方法在细节、手和面部的精确渲染、人体真实感以及外观可控性方面存在困难。人体图像数据缺乏多样性、真实性和标注也仍然是一个挑战，阻碍了基础3D人体模型的发展。我们提出了一种弱监督流水线来尝试解决这些挑战。第一步，我们使用最先进的图像扩散模型生成一个具有可控属性（如外观、种族、性别等）的逼真人体图像数据集。接下来，我们提出一种高效的映射方法，使用基于Transformer的架构将图像特征映射到3D点云。最后，我们通过训练一个点云扩散模型来完成闭环，该模型以与生成原始样本相同的文本提示为条件。我们展示了与最先进方法相比，在3D人体生成方面实现了数量级的速度提升，同时显著改善了文本提示对齐、真实感和渲染质量。我们将公开代码和数据集。", "summary": "HuGeDiff提出了一种弱监督的3D人体生成流水线，旨在解决当前方法在细节、真实感和可控性方面的不足。该方法首先利用图像扩散模型生成包含可控属性的逼真人体图像数据集，然后通过基于Transformer的架构将图像特征高效映射至3D点云，最后训练一个由文本提示条件化的点云扩散模型。实验结果表明，该方法在生成速度上实现了数量级提升，并显著提高了文本提示对齐度、真实感和渲染质量。", "keywords": "3D人体生成, 扩散模型, 高斯泼溅, 点云, 弱监督"}}
{"id": "2506.04301", "pdf": "https://arxiv.org/pdf/2506.04301", "abs": "https://arxiv.org/abs/2506.04301", "authors": ["Jiin Kim", "Byeongjun Shin", "Jinha Chung", "Minsoo Rhu"], "title": "The Cost of Dynamic Reasoning: Demystifying AI Agents and Test-Time Scaling from an AI Infrastructure Perspective", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Large-language-model (LLM)-based AI agents have recently showcased impressive\nversatility by employing dynamic reasoning, an adaptive, multi-step process\nthat coordinates with external tools. This shift from static, single-turn\ninference to agentic, multi-turn workflows broadens task generalization and\nbehavioral flexibility, but it also introduces serious concerns about\nsystem-level cost, efficiency, and sustainability. This paper presents the\nfirst comprehensive system-level analysis of AI agents, quantifying their\nresource usage, latency behavior, energy consumption, and datacenter-wide power\nconsumption demands across diverse agent designs and test-time scaling\nstrategies. We further characterize how AI agent design choices, such as\nfew-shot prompting, reflection depth, and parallel reasoning, impact\naccuracy-cost tradeoffs. Our findings reveal that while agents improve accuracy\nwith increased compute, they suffer from rapidly diminishing returns, widening\nlatency variance, and unsustainable infrastructure costs. Through detailed\nevaluation of representative agents, we highlight the profound computational\ndemands introduced by AI agent workflows, uncovering a looming sustainability\ncrisis. These results call for a paradigm shift in agent design toward\ncompute-efficient reasoning, balancing performance with deployability under\nreal-world constraints.", "AI": {"title_translation": "动态推理的成本：从AI基础设施视角揭秘AI智能体和测试时扩展", "tldr": "本文首次全面分析了基于LLM的AI智能体，发现其动态推理虽然能提高准确性，但会导致计算资源消耗快速增加、延迟波动性扩大以及不可持续的基础设施成本，呼吁智能体设计转向计算效率。", "motivation": "尽管基于LLM的AI智能体通过动态推理展现出强大的通用性和灵活性，但这种从静态单轮推理到智能体多轮工作流的转变，引入了严重的系统级成本、效率和可持续性问题，促使本文进行深入分析。", "method": "本文进行了首次全面的AI智能体系统级分析，量化了它们在不同智能体设计和测试时扩展策略下的资源使用、延迟行为、能耗和数据中心范围的功耗需求。此外，还表征了少样本提示、反射深度和并行推理等智能体设计选择如何影响准确性-成本权衡。", "result": "研究发现，AI智能体虽然通过增加计算量可以提高准确性，但会面临快速递减的回报、延迟波动性扩大以及不可持续的基础设施成本。详细评估揭示了AI智能体工作流带来的巨大计算需求，预示着迫在眉睫的可持续性危机。", "conclusion": "这些结果呼吁AI智能体设计应进行范式转变，转向计算效率更高的推理，以在实际约束下平衡性能与可部署性。", "translation": "基于大型语言模型（LLM）的AI智能体最近通过采用动态推理展示了令人印象深刻的多功能性，动态推理是一种与外部工具协调的自适应多步骤过程。这种从静态、单轮推理到智能体、多轮工作流的转变拓宽了任务泛化和行为灵活性，但同时也引入了对系统级成本、效率和可持续性的严重担忧。本文首次对AI智能体进行了全面的系统级分析，量化了它们在不同智能体设计和测试时扩展策略下的资源使用、延迟行为、能耗和数据中心范围的功耗需求。我们进一步描述了AI智能体设计选择，如少样本提示、反射深度和并行推理，如何影响准确性-成本权衡。我们的研究结果表明，虽然智能体通过增加计算量提高了准确性，但它们面临着快速递减的回报、不断扩大的延迟方差和不可持续的基础设施成本。通过对代表性智能体的详细评估，我们强调了AI智能体工作流引入的巨大计算需求，揭示了迫在眉睫的可持续性危机。这些结果呼吁智能体设计进行范式转变，转向计算效率更高的推理，以在实际约束下平衡性能与可部署性。", "summary": "本文对基于大型语言模型（LLM）的AI智能体进行了首次全面的系统级分析，重点关注其动态推理带来的成本、效率和可持续性问题。研究量化了智能体的资源使用、延迟、能耗和功耗，并探讨了设计选择对准确性-成本权衡的影响。结果显示，尽管智能体能提高准确性，但其计算需求导致回报迅速递减、延迟波动性增加以及基础设施成本不可持续，揭示了潜在的计算可持续性危机，并强调需要开发更计算高效的智能体设计。", "keywords": "AI智能体, 动态推理, 系统成本, 计算效率, 可持续性"}}
{"id": "2506.04804", "pdf": "https://arxiv.org/pdf/2506.04804", "abs": "https://arxiv.org/abs/2506.04804", "authors": ["Andrea Munari", "Federico Chiariotti", "Leonardo Badia", "Petar Popovski"], "title": "Spatio-Temporal Information Freshness for Remote Source Monitoring in IoT Systems", "categories": ["cs.IT", "math.IT"], "comment": null, "summary": "The widespread adoption of age of information (AoI) as a meaningful and\nanalytically tractable information freshness metric has led to a wide body of\nwork on the timing performance of Internet of things (IoT) systems. However,\nthe spatial correlation inherent to environmental monitoring has been mostly\nneglected in the recent literature, due to the significant modeling complexity\nit introduces. In this work, we address this gap by presenting a model of\nspatio-temporal information freshness, considering the conditional entropy of\nthe system state in a remote monitoring scenario, such as a low-orbit satellite\ncollecting information from a wide geographical area. Our analytical results\nshow that purely age-oriented schemes tend to select an overly broad\ncommunication range, leading to inaccurate estimates and energy inefficiency,\nboth of which can be mitigated by adopting a spatio-temporal approach.", "AI": {"title_translation": "物联网系统中远程源监测的时空信息新鲜度", "tldr": "本文提出了一个时空信息新鲜度模型，以解决现有信息新鲜度度量（如AoI）忽略空间相关性的问题，并证明了其在提高估计准确性和能源效率方面的优势。", "motivation": "现有的信息新鲜度度量（如信息年龄AoI）在物联网系统中的应用广泛，但大多忽略了环境监测中固有的空间相关性，因为这会引入显著的建模复杂性。", "method": "本文通过引入一个时空信息新鲜度模型来解决现有研究的不足，该模型考虑了远程监测场景（如低轨卫星从广阔地理区域收集信息）中系统状态的条件熵。", "result": "分析结果表明，纯粹以信息年龄为导向的方案倾向于选择过宽的通信范围，导致估计不准确和能源效率低下。采用时空方法可以缓解这些问题。", "conclusion": "采用时空信息新鲜度方法可以有效提高物联网系统中远程源监测的估计准确性和能源效率，优于纯粹以信息年龄为导向的方案。", "translation": "信息年龄（AoI）作为一种有意义且易于分析的信息新鲜度指标的广泛采用，使得物联网（IoT）系统的时间性能研究取得了大量进展。然而，最近的文献中大多忽略了环境监测中固有的空间相关性，这是由于其引入了显著的建模复杂性。在这项工作中，我们通过提出一个时空信息新鲜度模型来解决这一空白，该模型考虑了远程监测场景中系统状态的条件熵，例如低轨卫星从广阔地理区域收集信息。我们的分析结果表明，纯粹以年龄为导向的方案倾向于选择过宽的通信范围，导致估计不准确和能源效率低下，而这两种情况都可以通过采用时空方法来缓解。", "summary": "本研究针对物联网系统中远程源监测的信息新鲜度问题，指出现有信息年龄（AoI）度量忽略了空间相关性。为此，文章提出了一个时空信息新鲜度模型，该模型考虑了系统状态的条件熵。分析结果表明，相比于纯粹以信息年龄为导向的方案，时空方法能有效避免通信范围过广导致的估计不准确和能源效率低下问题。", "keywords": "时空信息新鲜度,物联网系统,信息年龄,空间相关性,远程监测"}}
{"id": "2506.05019", "pdf": "https://arxiv.org/pdf/2506.05019", "abs": "https://arxiv.org/abs/2506.05019", "authors": ["Wenyan Xu", "Dawei Xiang", "Yue Liu", "Xiyu Wang", "Yanxiang Ma", "Liang Zhang", "Chang Xu", "Jiaheng Zhang"], "title": "FinMultiTime: A Four-Modal Bilingual Dataset for Financial Time-Series Analysis", "categories": ["cs.CE"], "comment": "Under review", "summary": "Pure time series forecasting tasks typically focus exclusively on numerical\nfeatures; however, real-world financial decision-making demands the comparison\nand analysis of heterogeneous sources of information. Recent advances in deep\nlearning and large scale language models (LLMs) have made significant strides\nin capturing sentiment and other qualitative signals, thereby enhancing the\naccuracy of financial time series predictions. Despite these advances, most\nexisting datasets consist solely of price series and news text, are confined to\na single market, and remain limited in scale. In this paper, we introduce\nFinMultiTime, the first large scale, multimodal financial time series dataset.\nFinMultiTime temporally aligns four distinct modalities financial news,\nstructured financial tables, K-line technical charts, and stock price time\nseries across both the S&P 500 and HS 300 universes. Covering 5,105 stocks from\n2009 to 2025 in the United States and China, the dataset totals 112.6 GB and\nprovides minute-level, daily, and quarterly resolutions, thus capturing short,\nmedium, and long term market signals with high fidelity. Our experiments\ndemonstrate that (1) scale and data quality markedly boost prediction accuracy;\n(2) multimodal fusion yields moderate gains in Transformer models; and (3) a\nfully reproducible pipeline enables seamless dataset updates.", "AI": {"title_translation": "FinMultiTime: 一个用于金融时间序列分析的四模态双语数据集", "tldr": "FinMultiTime是一个大规模、多模态、双语的金融时间序列数据集，包含新闻、表格、K线图和股价数据，覆盖中美市场，旨在提升金融预测准确性。", "motivation": "纯时间序列预测通常只关注数值特征，但实际金融决策需要分析异构信息源。尽管深度学习和大型语言模型在捕捉情感信号方面取得进展，但现有数据集大多仅包含价格序列和新闻文本，局限于单一市场且规模有限。", "method": "本文介绍了FinMultiTime，这是首个大规模、多模态金融时间序列数据集。FinMultiTime在时间上对齐了四种不同的模态：金融新闻、结构化金融表格、K线技术图表和股票价格时间序列，覆盖S&P 500和HS 300指数，包含2009年至2025年间美国和中国的5,105只股票，总计112.6 GB，提供分钟级、日度和季度分辨率数据。", "result": "实验表明：(1) 数据规模和质量显著提高了预测准确性；(2) 多模态融合在Transformer模型中带来了适度提升；(3) 完全可复现的管道实现了无缝数据集更新。", "conclusion": "大规模、高质量的多模态数据集对金融时间序列预测至关重要，多模态融合能进一步提升模型性能，且可复现的数据管道有助于数据集的持续更新和应用。", "translation": "纯时间序列预测任务通常只关注数值特征；然而，现实世界的金融决策需要对异构信息源进行比较和分析。深度学习和大规模语言模型（LLMs）的最新进展在捕捉情感和其他定性信号方面取得了显著进展，从而提高了金融时间序列预测的准确性。尽管有这些进展，大多数现有数据集仅由价格序列和新闻文本组成，局限于单一市场，并且规模有限。在本文中，我们介绍了FinMultiTime，这是第一个大规模、多模态的金融时间序列数据集。FinMultiTime在时间上对齐了四种不同的模态：金融新闻、结构化金融表格、K线技术图表和股票价格时间序列，涵盖S&P 500和HS 300指数，覆盖美国和中国2009年至2025年的5,105只股票，数据集总计112.6 GB，并提供分钟级、日度和季度分辨率，从而高保真地捕捉短期、中期和长期市场信号。我们的实验表明：(1) 规模和数据质量显著提高了预测准确性；(2) 多模态融合在Transformer模型中带来了适度提升；(3) 完全可复现的管道实现了无缝数据集更新。", "summary": "FinMultiTime是一个创新的大规模、四模态、双语金融时间序列数据集，旨在解决现有金融数据集的局限性。它整合了金融新闻、结构化表格、K线图和股价时间序列，覆盖中美两国市场，提供多分辨率数据。实验证明，该数据集的规模和质量能显著提升预测准确性，多模态融合对Transformer模型有增益，且其可复现的管道支持无缝更新。", "keywords": "金融时间序列, 多模态数据集, 双语, 深度学习, 预测"}}
{"id": "2506.04250", "pdf": "https://arxiv.org/pdf/2506.04250", "abs": "https://arxiv.org/abs/2506.04250", "authors": ["Shaona Ghosh", "Amrita Bhattacharjee", "Yftah Ziser", "Christopher Parisien"], "title": "SafeSteer: Interpretable Safety Steering with Refusal-Evasion in LLMs", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2410.01174", "summary": "Fine-tuning large language models (LLMs) to adapt to evolving safety policies\nis costly and impractical. Mechanistic interpretability enables inference-time\ncontrol through latent activation steering, yet its potential for precise,\ncustomizable safety adjustments remains largely untapped. This paper\ninvestigates an approach called SafeSteer for guiding the outputs of LLMs by:\n(i) leveraging category-specific steering vectors for more precise control,\n(ii) employing a simple, gradient-free unsupervised method to enhance safety\nsteering while preserving text quality, topic relevance, and without explicit\nrefusal, and (iii) accomplishing this without a hard requirement of contrastive\npairwise safe data. We also highlight that our method, being simple and\neffective, aligns with recent studies suggesting that simple techniques often\noutperform more complex ones in activation steering. We showcase the\neffectiveness of our approach across various LLMs, datasets, and risk\ncategories, demonstrating its ability to provide precise control, prevent\nblanket refusals, and guide models toward generating safe content while\nmaintaining topic relevance.", "AI": {"title_translation": "SafeSteer：大型语言模型中可解释的拒绝-规避安全引导", "tldr": "SafeSteer 是一种简单、无监督的方法，通过利用特定类别的引导向量，在不进行微调、不要求对比安全数据且不产生生硬拒绝的情况下，实现大型语言模型输出的精确安全引导，同时保持文本质量和主题相关性。", "motivation": "针对不断变化的安全策略对大型语言模型（LLMs）进行微调既昂贵又不切实际。尽管机械可解释性可以通过潜在激活引导实现推理时控制，但其在精确、可定制的安全调整方面的潜力尚未被充分利用。", "method": "本文提出了一种名为 SafeSteer 的方法，用于引导LLMs的输出：(i) 利用特定类别的引导向量实现更精确的控制；(ii) 采用一种简单、无梯度、无监督的方法来增强安全引导，同时保留文本质量、主题相关性且不产生明确拒绝；(iii) 实现上述目标而无需严格要求对比成对安全数据。该方法简单有效，与近期研究中简单技术优于复杂技术的发现相符。", "result": "SafeSteer 方法在各种大型语言模型、数据集和风险类别中都表现出有效性。它能够提供精确控制，防止一概拒绝，并将模型引导至生成安全内容，同时保持主题相关性。", "conclusion": "SafeSteer 提供了一种有效且可解释的LLM安全引导方法，它通过精确控制和规避拒绝，解决了传统微调的局限性，并在不牺牲文本质量和主题相关性的前提下，促进了安全内容的生成。", "translation": "微调大型语言模型（LLMs）以适应不断变化的安全策略既昂贵又不切实际。机械可解释性通过潜在激活引导实现推理时控制，但其在精确、可定制的安全调整方面的潜力仍未被充分发掘。本文研究了一种名为 SafeSteer 的方法，通过以下方式引导LLMs的输出：(i) 利用特定类别的引导向量实现更精确的控制；(ii) 采用一种简单、无梯度、无监督的方法来增强安全引导，同时保留文本质量、主题相关性且不产生明确拒绝；(iii) 在实现上述目标时，不严格要求对比成对安全数据。我们还强调，我们的方法简单有效，与近期研究中简单技术在激活引导方面通常优于复杂技术的观点相符。我们展示了我们的方法在各种LLMs、数据集和风险类别中的有效性，证明了其提供精确控制、防止一概拒绝以及在保持主题相关性的同时引导模型生成安全内容的能力。", "summary": "SafeSteer 是一种新颖的方法，旨在解决大型语言模型安全策略适应的挑战。该方法通过利用类别特定的引导向量和一个简单的、无梯度、无监督的框架，在推理时实现对LLMs输出的精确安全控制。它避免了昂贵的微调需求和对比安全数据的硬性要求，同时确保生成的文本质量、主题相关性，并避免了生硬的拒绝。研究表明，SafeSteer 在不同模型和数据集上均能有效引导模型生成安全内容。", "keywords": "SafeSteer, 大型语言模型, 安全引导, 可解释性, 拒绝-规避"}}
{"id": "2506.04482", "pdf": "https://arxiv.org/pdf/2506.04482", "abs": "https://arxiv.org/abs/2506.04482", "authors": ["Emma Harvey", "Emily Sheng", "Su Lin Blodgett", "Alexandra Chouldechova", "Jean Garcia-Gathright", "Alexandra Olteanu", "Hanna Wallach"], "title": "Understanding and Meeting Practitioner Needs When Measuring Representational Harms Caused by LLM-Based Systems", "categories": ["cs.CY", "cs.CL"], "comment": "Findings of the Association for Computational Linguistics: ACL 2025", "summary": "The NLP research community has made publicly available numerous instruments\nfor measuring representational harms caused by large language model (LLM)-based\nsystems. These instruments have taken the form of datasets, metrics, tools, and\nmore. In this paper, we examine the extent to which such instruments meet the\nneeds of practitioners tasked with evaluating LLM-based systems. Via\nsemi-structured interviews with 12 such practitioners, we find that\npractitioners are often unable to use publicly available instruments for\nmeasuring representational harms. We identify two types of challenges. In some\ncases, instruments are not useful because they do not meaningfully measure what\npractitioners seek to measure or are otherwise misaligned with practitioner\nneeds. In other cases, instruments - even useful instruments - are not used by\npractitioners due to practical and institutional barriers impeding their\nuptake. Drawing on measurement theory and pragmatic measurement, we provide\nrecommendations for addressing these challenges to better meet practitioner\nneeds.", "AI": {"title_translation": "理解和满足从业者在衡量LLM系统造成的表征性危害时的需求", "tldr": "研究发现，现有衡量LLM系统表征性危害的工具未能满足从业者需求，主要原因在于工具与需求不符以及实际应用障碍。", "motivation": "NLP研究社区已公开大量用于衡量大型语言模型（LLM）系统造成的表征性危害的工具，但作者旨在探究这些工具在多大程度上满足了负责评估LLM系统的从业者的需求。", "method": "通过对12位从业者进行半结构化访谈。", "result": "研究发现，从业者通常无法使用公开可用的工具来衡量表征性危害。主要挑战包括：工具未能有意义地衡量从业者希望衡量的内容，或与从业者需求不符；即使是有效的工具，也因实际和制度障碍而未被采用。", "conclusion": "基于测量理论和实用测量，本文提出了解决这些挑战的建议，以更好地满足从业者需求。", "translation": "自然语言处理（NLP）研究社区已经公开了大量用于衡量大型语言模型（LLM）系统造成的表征性危害的工具。这些工具包括数据集、指标、工具等形式。在本文中，我们考察了这些工具在多大程度上满足了负责评估LLM系统的从业者的需求。通过对12位此类从业者进行半结构化访谈，我们发现从业者通常无法使用公开可用的工具来衡量表征性危害。我们识别出两种类型的挑战。在某些情况下，工具之所以无用，是因为它们未能有意义地衡量从业者希望衡量的内容，或者与从业者需求不符。在另一些情况下，即使是有效的工具，也由于阻碍其采用的实际和制度障碍而未被从业者使用。借鉴测量理论和实用测量，我们提出了解决这些挑战的建议，以更好地满足从业者需求。", "summary": "本文通过对12位从业者进行半结构化访谈，调查了现有衡量大型语言模型（LLM）系统表征性危害的工具在满足从业者需求方面的现状。研究发现，这些公开工具常因与从业者需求不符或存在实际和制度障碍而无法被有效利用。文章最后基于测量理论提出了改进建议，以更好地满足从业者在衡量LLM系统表征性危害时的需求。", "keywords": "大型语言模型, 表征性危害, 从业者需求, 测量工具, 实用性障碍"}}
{"id": "2506.04667", "pdf": "https://arxiv.org/pdf/2506.04667", "abs": "https://arxiv.org/abs/2506.04667", "authors": ["Osayamen Jonathan Aimuyo", "Byungsoo Oh", "Rachee Singh"], "title": "FlashDMoE: Fast Distributed MoE in a Single Kernel", "categories": ["cs.DC", "cs.AR", "cs.LG"], "comment": "In submission. See code at https://github.com/osayamenja/Aristos", "summary": "The computational sparsity of Mixture-of-Experts (MoE) models enables\nsub-linear growth in compute cost as model size increases, offering a scalable\npath to training massive neural networks. However, existing implementations\nsuffer from \\emph{low GPU utilization}, \\emph{significant latency overhead},\nand a fundamental \\emph{inability to leverage task locality}, primarily due to\nCPU-managed scheduling, host-initiated communication, and frequent kernel\nlaunches. To overcome these limitations, we develop FlashDMoE, a fully\nGPU-resident MoE operator that fuses expert computation and inter-GPU\ncommunication into a \\emph{single persistent GPU kernel}. FlashDMoE enables\nfine-grained pipelining of dispatch, compute, and combine phases, eliminating\nlaunch overheads and reducing idle gaps. Its device-initiated communication\nprotocol introduces \\emph{payload-efficient} data transfers, significantly\nshrinking buffer sizes in sparsely activated MoE layers. When evaluated on a\nsingle 8-H100 GPU node with MoE models having up to 128 experts and 16K token\nsequences, FlashDMoE achieves up to \\textbf{6}x lower latency, \\textbf{5,7}x\nhigher throughput, \\textbf{4}x better weak scaling efficiency, and \\textbf{9}x\nhigher GPU utilization compared to state-of-the-art baselines, despite using\nFP32 while baselines use FP16. FlashDMoE demonstrates that principled GPU\nkernel-hardware co-design is key to unlocking the performance ceiling of\nlarge-scale distributed ML workloads.", "AI": {"title_translation": "FlashDMoE: 单一内核中的快速分布式MoE", "tldr": "FlashDMoE通过将专家计算和GPU间通信融合到一个持久的GPU内核中，显著提高了MoE模型的性能、吞吐量和GPU利用率，解决了现有实现中存在的低GPU利用率和高延迟问题。", "motivation": "现有MoE实现存在GPU利用率低、延迟开销大以及无法利用任务局部性等问题，这主要是由于CPU管理的调度、主机发起的通信以及频繁的内核启动造成的。", "method": "FlashDMoE是一个完全驻留在GPU上的MoE操作符，它将专家计算和GPU间通信融合到一个单一的持久GPU内核中。它实现了调度、计算和合并阶段的细粒度流水线，消除了启动开销并减少了空闲间隙。其设备发起的通信协议引入了有效载荷高效的数据传输，显著减小了稀疏激活MoE层中的缓冲区大小。", "result": "在单个8-H100 GPU节点上，对于拥有多达128个专家和16K令牌序列的MoE模型，FlashDMoE与现有技术基线相比，延迟降低了6倍，吞吐量提高了5.7倍，弱扩展效率提高了4倍，GPU利用率提高了9倍，尽管FlashDMoE使用FP32而基线使用FP16。", "conclusion": "FlashDMoE表明，有原则的GPU内核-硬件协同设计是释放大规模分布式机器学习工作负载性能上限的关键。", "translation": "混合专家（MoE）模型的计算稀疏性使得计算成本随着模型规模的增长而呈现次线性增长，为训练大规模神经网络提供了一条可扩展的路径。然而，现有实现存在GPU利用率低、显著的延迟开销以及根本上无法利用任务局部性等问题，这主要是由于CPU管理的调度、主机发起的通信以及频繁的内核启动造成的。为了克服这些限制，我们开发了FlashDMoE，一个完全驻留在GPU上的MoE操作符，它将专家计算和GPU间通信融合到一个单一的持久GPU内核中。FlashDMoE实现了调度、计算和合并阶段的细粒度流水线，消除了启动开销并减少了空闲间隙。其设备发起的通信协议引入了有效载荷高效的数据传输，显著减小了稀疏激活MoE层中的缓冲区大小。在单个8-H100 GPU节点上，对于拥有多达128个专家和16K令牌序列的MoE模型进行评估时，与现有技术基线相比，FlashDMoE实现了高达6倍的延迟降低、5.7倍的吞吐量提升、4倍的弱扩展效率提升以及9倍的GPU利用率提升，尽管FlashDMoE使用FP32而基线使用FP16。FlashDMoE表明，有原则的GPU内核-硬件协同设计是释放大规模分布式机器学习工作负载性能上限的关键。", "summary": "FlashDMoE是一种新型的分布式MoE操作符，它通过将专家计算和GPU间通信整合到一个单一的持久GPU内核中，解决了现有MoE模型在GPU利用率、延迟和任务局部性方面的限制。该方法通过细粒度流水线和设备发起的通信协议，显著提升了性能。实验结果表明，FlashDMoE在延迟、吞吐量、扩展效率和GPU利用率方面均优于现有技术，证明了GPU内核-硬件协同设计对于大规模分布式ML工作负载的重要性。", "keywords": "FlashDMoE, Mixture-of-Experts, GPU利用率, 分布式ML, 并行计算"}}
{"id": "2506.04238", "pdf": "https://arxiv.org/pdf/2506.04238", "abs": "https://arxiv.org/abs/2506.04238", "authors": ["Shriyank Somvanshi", "Md Monzurul Islam", "Syed Aaqib Javed", "Gaurab Chhetri", "Kazi Sifatul Islam", "Tausif Islam Chowdhury", "Sazzad Bin Bashar Polock", "Anandi Dutta", "Subasish Das"], "title": "A Comprehensive Survey on Bio-Inspired Algorithms: Taxonomy, Applications, and Future Directions", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Bio-inspired algorithms (BIAs) utilize natural processes such as evolution,\nswarm behavior, foraging, and plant growth to solve complex, nonlinear,\nhigh-dimensional optimization problems. This survey categorizes BIAs into eight\ngroups: evolutionary, swarm intelligence, physics-inspired, ecosystem and\nplant-based, predator-prey, neural-inspired, human-inspired, and hybrid\napproaches, and reviews their core principles, strengths, and limitations. We\nillustrate the usage of these algorithms in machine learning, engineering\ndesign, bioinformatics, and intelligent systems, and highlight recent advances\nin hybridization, parameter tuning, and adaptive strategies. Finally, we\nidentify open challenges such as scalability, convergence, reliability, and\ninterpretability to suggest directions for future research. This work aims to\nserve as a foundational resource for both researchers and practitioners\ninterested in understanding the current landscape and future directions of\nbio-inspired computing.", "AI": {"title_translation": "生物启发算法的综合综述：分类、应用和未来方向", "tldr": "本综述全面回顾了生物启发算法，对其进行了分类，探讨了其应用，并指出了未来的研究方向。", "motivation": "本工作旨在为研究人员和实践者提供一个理解生物启发计算当前状况和未来方向的基础资源。", "method": "本综述将生物启发算法分为八类：进化算法、群智能、物理启发、生态系统和植物基、捕食者-猎物、神经启发、人类启发和混合方法，并回顾了它们的核心原理、优势和局限性。", "result": "本综述阐述了生物启发算法在机器学习、工程设计、生物信息学和智能系统中的应用，并强调了混合、参数调整和自适应策略方面的最新进展。此外，还指出了可扩展性、收敛性、可靠性和可解释性等开放性挑战。", "conclusion": "本工作旨在作为对生物启发计算当前格局和未来方向感兴趣的研究人员和实践者的基础资源。", "translation": "生物启发算法（BIAs）利用进化、群体行为、觅食和植物生长等自然过程来解决复杂的、非线性的、高维优化问题。本综述将BIAs分为八类：进化、群智能、物理启发、生态系统和植物基、捕食者-猎物、神经启发、人类启发和混合方法，并回顾了它们的核心原理、优势和局限性。我们阐述了这些算法在机器学习、工程设计、生物信息学和智能系统中的应用，并强调了混合、参数调整和自适应策略方面的最新进展。最后，我们识别了可扩展性、收敛性、可靠性和可解释性等开放性挑战，以建议未来的研究方向。这项工作旨在为对理解生物启发计算的当前格局和未来方向感兴趣的研究人员和实践者提供一个基础资源。", "summary": "这篇综合综述对生物启发算法（BIAs）进行了分类，将其分为八个主要类别，并详细阐述了它们的核心原理、优势和局限性。文章还探讨了BIAs在机器学习、工程设计、生物信息学和智能系统等领域的应用，并强调了混合、参数调整和自适应策略等方面的最新进展。最后，该综述识别了可扩展性、收敛性、可靠性和可解释性等开放性挑战，为未来的研究提供了方向，旨在为研究人员和实践者提供一个理解生物启发计算当前状况和未来方向的基础资源。", "keywords": "生物启发算法, 综合综述, 分类, 应用, 未来方向"}}
{"id": "2506.04800", "pdf": "https://arxiv.org/pdf/2506.04800", "abs": "https://arxiv.org/abs/2506.04800", "authors": ["Thomas Prévost", "Olivier Alibart", "Marc Kaplan", "Anne Marin"], "title": "MULTISS: un protocole de stockage confidentiel {à} long terme sur plusieurs r{é}seaux QKD", "categories": ["cs.CR"], "comment": "in French language", "summary": "This paper presents MULTISS, a new protocol for long-term storage distributed\nacross multiple Quantum Key Distribution (QKD) networks. This protocol is an\nextension of LINCOS, a secure storage protocol that uses Shamir secret sharing\nfor secret storage on a single QKD network. Our protocol uses hierarchical\nsecret sharing to distribute a secret across multiple QKD networks while\nensuring perfect security. Our protocol further allows for sharing updates\nwithout having to reconstruct the entire secret. We also prove that MULTISS is\nstrictly more secure than LINCOS, which remains vulnerable when its QKD network\nis compromised.", "AI": {"title_translation": "MULTISS：一种跨多个QKD网络的长期保密存储协议", "tldr": "MULTISS是一种新的协议，用于在多个量子密钥分发（QKD）网络上进行长期分布式保密存储，它扩展了LINCOS，并使用分层秘密共享来确保完美安全性，同时允许更新共享而无需重新构建整个秘密，并且比LINCOS更安全。", "motivation": "为了解决在单个QKD网络上安全存储的限制，并提供一种跨多个QKD网络进行长期分布式保密存储的协议，同时确保完美的安全性和更新的灵活性。", "method": "MULTISS协议是LINCOS协议的扩展。它使用分层秘密共享来将秘密分布在多个QKD网络中。此外，它允许在不完全重建秘密的情况下进行共享更新。", "result": "MULTISS协议被证明比LINCOS协议更安全，因为LINCOS在QKD网络受损时仍然容易受到攻击，而MULTISS在跨多个QKD网络存储时能确保完美安全性。", "conclusion": "MULTISS提供了一种比现有协议（如LINCOS）更安全、更灵活的长期保密存储解决方案，通过分层秘密共享实现了跨多个QKD网络的完美安全性。", "translation": "本文介绍了MULTISS，一种新的协议，用于跨多个量子密钥分发（QKD）网络进行长期分布式存储。该协议是LINCOS的扩展，LINCOS是一种在单个QKD网络上使用Shamir秘密共享进行秘密存储的安全存储协议。我们的协议使用分层秘密共享将秘密分发到多个QKD网络，同时确保完美的安全。我们的协议还允许在不必重新构建整个秘密的情况下进行共享更新。我们还证明MULTISS比LINCOS更安全，因为LINCOS在其QKD网络受损时仍然容易受到攻击。", "summary": "本文介绍了MULTISS，一种在多个量子密钥分发（QKD）网络上实现长期分布式保密存储的新协议。作为LINCOS的扩展，MULTISS利用分层秘密共享来确保秘密在多个QKD网络间的完美安全分发，并允许在不重建秘密的情况下进行共享更新。研究证明，MULTISS比LINCOS具有更高的安全性，解决了LINCOS在QKD网络受损时的脆弱性问题。", "keywords": "MULTISS, 量子密钥分发, 分层秘密共享, 秘密存储, 完美安全性"}}
{"id": "2506.04276", "pdf": "https://arxiv.org/pdf/2506.04276", "abs": "https://arxiv.org/abs/2506.04276", "authors": ["Lei Han", "Yitong Guo", "Pengfei Yang", "Zhiyong Yu", "Liang Wang", "Quan Wang", "Zhiwen Yu"], "title": "Autonomous Collaborative Scheduling of Time-dependent UAVs, Workers and Vehicles for Crowdsensing in Disaster Response", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Natural disasters have caused significant losses to human society, and the\ntimely and efficient acquisition of post-disaster environmental information is\ncrucial for the effective implementation of rescue operations. Due to the\ncomplexity of post-disaster environments, existing sensing technologies face\nchallenges such as weak environmental adaptability, insufficient specialized\nsensing capabilities, and limited practicality of sensing solutions. This paper\nexplores the heterogeneous multi-agent online autonomous collaborative\nscheduling algorithm HoAs-PALN, aimed at achieving efficient collection of\npost-disaster environmental information. HoAs-PALN is realized through adaptive\ndimensionality reduction in the matching process and local Nash equilibrium\ngame, facilitating autonomous collaboration among time-dependent UAVs, workers\nand vehicles to enhance sensing scheduling. (1) In terms of adaptive\ndimensionality reduction during the matching process, HoAs-PALN significantly\nreduces scheduling decision time by transforming a five-dimensional matching\nprocess into two categories of three-dimensional matching processes; (2)\nRegarding the local Nash equilibrium game, HoAs-PALN combines the softmax\nfunction to optimize behavior selection probabilities and introduces a local\nNash equilibrium determination mechanism to ensure scheduling decision\nperformance. Finally, we conducted detailed experiments based on extensive\nreal-world and simulated data. Compared with the baselines (GREEDY, K-WTA, MADL\nand MARL), HoAs-PALN improves task completion rates by 64.12%, 46.48%, 16.55%,\nand 14.03% on average, respectively, while each online scheduling decision\ntakes less than 10 seconds, demonstrating its effectiveness in dynamic\npost-disaster environments.", "AI": {"title_translation": "灾害响应中时效性无人机、工人与车辆的自主协同众包调度", "tldr": "HoAs-PALN算法通过自适应降维和局部纳什均衡博弈，有效调度无人机、工人与车辆进行灾后众包感知，显著提高了任务完成率并缩短了决策时间。", "motivation": "自然灾害给人类社会带来巨大损失，灾后环境信息的及时高效获取对救援行动至关重要。现有感知技术面临环境适应性差、专业感知能力不足和实用性有限等挑战。", "method": "本文提出了一种异构多智能体在线自主协同调度算法HoAs-PALN，旨在高效收集灾后环境信息。HoAs-PALN通过匹配过程中的自适应降维（将五维匹配过程转换为两类三维匹配过程）和局部纳什均衡博弈（结合softmax函数优化行为选择概率并引入局部纳什均衡确定机制）来实现。", "result": "HoAs-PALN与基线算法（GREEDY, K-WTA, MADL和MARL）相比，任务完成率平均分别提高了64.12%、46.48%、16.55%和14.03%。每次在线调度决策耗时少于10秒。", "conclusion": "HoAs-PALN算法在动态灾后环境中表现出显著的有效性，能够高效地完成灾后信息收集任务。", "translation": "自然灾害给人类社会造成了重大损失，灾后环境信息的及时高效获取对于有效实施救援行动至关重要。由于灾后环境的复杂性，现有感知技术面临环境适应性差、专业感知能力不足、感知解决方案实用性有限等挑战。本文探索了异构多智能体在线自主协同调度算法HoAs-PALN，旨在实现灾后环境信息的高效采集。HoAs-PALN通过匹配过程中的自适应降维和局部纳什均衡博弈实现，促进了时效性无人机、工人与车辆之间的自主协同，从而增强了感知调度能力。(1)在匹配过程中的自适应降维方面，HoAs-PALN将五维匹配过程转换为两类三维匹配过程，显著减少了调度决策时间；(2)在局部纳什均衡博弈方面，HoAs-PALN结合softmax函数优化行为选择概率，并引入局部纳什均衡确定机制以确保调度决策性能。最后，我们基于大量的真实世界和模拟数据进行了详细实验。与基线算法（GREEDY、K-WTA、MADL和MARL）相比，HoAs-PALN的任务完成率平均分别提高了64.12%、46.48%、16.55%和14.03%，同时每次在线调度决策耗时不到10秒，证明了其在动态灾后环境中的有效性。", "summary": "本文针对灾后环境信息获取面临的挑战，提出了一种名为HoAs-PALN的异构多智能体在线自主协同调度算法。该算法通过自适应降维和局部纳什均衡博弈，实现了时效性无人机、工人与车辆的自主协同，以提高感知调度效率。实验结果表明，HoAs-PALN在任务完成率方面显著优于现有基线算法，且单次调度决策时间短，证明了其在动态灾后环境中的有效性。", "keywords": "无人机, 众包, 灾害响应, 协同调度, 多智能体系统"}}
{"id": "2506.04505", "pdf": "https://arxiv.org/pdf/2506.04505", "abs": "https://arxiv.org/abs/2506.04505", "authors": ["Nikita Oskolkov", "Huzhenyu Zhang", "Dmitry Makarov", "Dmitry Yudin", "Aleksandr Panov"], "title": "SGN-CIRL: Scene Graph-based Navigation with Curriculum, Imitation, and Reinforcement Learning", "categories": ["cs.RO", "cs.LG"], "comment": "7 pages, 11 figures", "summary": "The 3D scene graph models spatial relationships between objects, enabling the\nagent to efficiently navigate in a partially observable environment and predict\nthe location of the target object.This paper proposes an original framework\nnamed SGN-CIRL (3D Scene Graph-Based Reinforcement Learning Navigation) for\nmapless reinforcement learning-based robot navigation with learnable\nrepresentation of open-vocabulary 3D scene graph. To accelerate and stabilize\nthe training of reinforcement learning-based algorithms, the framework also\nemploys imitation learning and curriculum learning. The first one enables the\nagent to learn from demonstrations, while the second one structures the\ntraining process by gradually increasing task complexity from simple to more\nadvanced scenarios. Numerical experiments conducted in the Isaac Sim\nenvironment showed that using a 3D scene graph for reinforcement learning\nsignificantly increased the success rate in difficult navigation cases. The\ncode is open-sourced and available at: https://github.com/Xisonik/Aloha\\_graph.", "AI": {"title_translation": "SGN-CIRL: 基于场景图的课程、模仿和强化学习导航", "tldr": "SGN-CIRL 结合3D场景图、模仿学习和课程学习，显著提升了无地图强化学习机器人导航在复杂环境中的成功率。", "motivation": "3D场景图能够建模对象间的空间关系，帮助代理在部分可观测环境中高效导航并预测目标位置。本文旨在利用此优势，解决无地图强化学习机器人导航的训练效率和稳定性问题。", "method": "本文提出了SGN-CIRL框架，用于基于可学习开放词汇3D场景图的无地图强化学习机器人导航。该框架整合了模仿学习（从演示中学习）和课程学习（通过逐步增加任务复杂性来构建训练过程），以加速和稳定强化学习算法的训练。", "result": "在Isaac Sim环境中进行的数值实验表明，使用3D场景图进行强化学习显著提高了在困难导航情况下的成功率。", "conclusion": "3D场景图结合模仿学习和课程学习，能够有效提升无地图强化学习机器人导航在复杂环境中的性能和训练效率。", "translation": "3D场景图模型能够表示对象之间的空间关系，使代理能够在部分可观测环境中高效导航并预测目标对象的位置。本文提出了一个名为SGN-CIRL（基于3D场景图的强化学习导航）的原创框架，用于基于可学习开放词汇3D场景图的无地图强化学习机器人导航。为了加速和稳定基于强化学习算法的训练，该框架还采用了模仿学习和课程学习。前者使代理能够从演示中学习，而后者通过从简单到更高级的场景逐渐增加任务复杂性来构建训练过程。在Isaac Sim环境中进行的数值实验表明，使用3D场景图进行强化学习显著提高了在困难导航情况下的成功率。代码已开源，可在以下链接获取：https://github.com/Xisonik/Aloha_graph。", "summary": "本文提出了SGN-CIRL框架，将可学习的开放词汇3D场景图应用于无地图强化学习机器人导航。为加速和稳定训练，该框架整合了模仿学习和课程学习。实验结果表明，在困难导航场景中，利用3D场景图显著提升了导航成功率。", "keywords": "场景图, 强化学习, 机器人导航, 模仿学习, 课程学习"}}
{"id": "2506.04525", "pdf": "https://arxiv.org/pdf/2506.04525", "abs": "https://arxiv.org/abs/2506.04525", "authors": ["Ekaterina Fedorova", "Madeline Kitch", "Chara Podimata"], "title": "User Altruism in Recommendation Systems", "categories": ["cs.GT", "cs.CY", "cs.HC", "cs.IR", "cs.SI"], "comment": null, "summary": "Users of social media platforms based on recommendation systems (RecSys)\n(e.g. TikTok, X, YouTube) strategically interact with platform content to\ninfluence future recommendations. On some such platforms, users have been\ndocumented to form large-scale grassroots movements encouraging others to\npurposefully interact with algorithmically suppressed content in order to\n\"boost\" its recommendation; we term this behavior user altruism. To capture\nthis behavior, we study a game between users and a RecSys, where users provide\nthe RecSys (potentially manipulated) preferences over the contents available to\nthem, and the RecSys -- limited by data and computation constraints -- creates\na low-rank approximation preference matrix, and ultimately provides each user\nher (approximately) most-preferred item. We compare the users' social welfare\nunder truthful preference reporting and under a class of strategies capturing\nuser altruism. In our theoretical analysis, we provide sufficient conditions to\nensure strict increases in user social welfare under user altruism, and provide\nan algorithm to find an effective altruistic strategy. Interestingly, we show\nthat for commonly assumed recommender utility functions, effectively altruistic\nstrategies also improve the utility of the RecSys! We show that our results are\nrobust to several model misspecifications, thus strengthening our conclusions.\nOur theoretical analysis is complemented by empirical results of effective\naltruistic strategies on the GoodReads dataset, and an online survey on how\nreal-world users behave altruistically in RecSys. Overall, our findings serve\nas a proof-of-concept of the reasons why traditional RecSys may incentivize\nusers to form collectives and/or follow altruistic strategies when interacting\nwith them.", "AI": {"title_translation": "用户利他主义在推荐系统中", "tldr": "研究用户在推荐系统中为了提升被压制内容推荐而采取的利他主义行为，并通过理论分析和实证研究证明其能提升用户社会福利和推荐系统效用。", "motivation": "用户在社交媒体平台（如TikTok, X, YouTube）上会策略性地与内容互动以影响未来的推荐，并形成了大规模的草根运动来“提升”算法压制的内容推荐，这种行为被称为用户利他主义。研究的动机是捕捉并理解这种行为。", "method": "构建用户与推荐系统之间的博弈模型，比较用户在真实偏好报告和利他主义策略下的社会福利。进行理论分析，提供确保用户社会福利严格增加的充分条件，并提出寻找有效利他主义策略的算法。通过GoodReads数据集的实证结果和在线调查来补充理论分析。", "result": "在特定条件下，用户利他主义能显著增加用户社会福利。有效的利他主义策略也能提高推荐系统的效用。结果对模型误差具有鲁棒性。GoodReads数据集的实证结果和在线调查支持了理论分析。", "conclusion": "本文的发现证明了传统推荐系统可能激励用户形成集体和/或在互动时遵循利他主义策略。", "translation": "推荐系统（RecSys）驱动的社交媒体平台（例如TikTok、X、YouTube）的用户会策略性地与平台内容互动，以影响未来的推荐。在一些此类平台上，已有文献记载用户形成了大规模的草根运动，鼓励他人有目的地与被算法压制的内容互动，以“提升”其推荐；我们将这种行为称为用户利他主义。为了捕捉这种行为，我们研究了用户与推荐系统之间的一场博弈，其中用户向推荐系统提供他们可获得内容的（可能被操纵的）偏好，而推荐系统——受限于数据和计算约束——创建一个低秩近似偏好矩阵，并最终为每个用户提供其（近似）最喜欢的项目。我们比较了用户在真实偏好报告和一类捕捉用户利他主义的策略下的社会福利。在我们的理论分析中，我们提供了确保用户社会福利在用户利他主义下严格增加的充分条件，并提供了一种算法来找到一种有效的利他主义策略。有趣的是，我们发现对于通常假设的推荐器效用函数，有效的利他主义策略也能提高推荐系统的效用！我们表明我们的结果对几种模型误设定具有鲁棒性，从而加强了我们的结论。我们的理论分析得到了GoodReads数据集上有效利他主义策略的实证结果以及关于真实世界用户如何在推荐系统中表现出利他主义的在线调查的补充。总的来说，我们的发现为传统推荐系统可能激励用户形成集体和/或在与它们互动时遵循利他主义策略的原因提供了概念验证。", "summary": "本文研究了用户在推荐系统中为“提升”被算法压制内容而采取的利他主义行为。通过构建用户与推荐系统间的博弈模型，并进行理论分析和实证研究，证明了在特定条件下，用户利他主义策略能够显著提升用户社会福利，甚至也能提高推荐系统的效用。研究结果具有鲁棒性，并通过GoodReads数据集和在线调查得到了验证，揭示了传统推荐系统可能激励用户形成集体并采取利他主义策略。", "keywords": "用户利他主义, 推荐系统, 博弈论, 社会福利, 算法操纵"}}
{"id": "2506.04569", "pdf": "https://arxiv.org/pdf/2506.04569", "abs": "https://arxiv.org/abs/2506.04569", "authors": ["Wenwei Gu", "Renyi Zhong", "Guangba Yu", "Xinying Sun", "Jinyang Liu", "Yintong Huo", "Zhuangbin Chen", "Jianping Zhang", "Jiazhen Gu", "Yongqiang Yang", "Michael R. Lyu"], "title": "KPIRoot+: An Efficient Integrated Framework for Anomaly Detection and Root Cause Analysis in Large-Scale Cloud Systems", "categories": ["cs.SE"], "comment": null, "summary": "To ensure the reliability of cloud systems, their performance is monitored\nusing KPIs (key performance indicators). When issues arise, root cause\nlocalization identifies KPIs responsible for service degradation, aiding in\nquick diagnosis and resolution. Traditional methods rely on similarity\ncalculations, which can be ineffective in complex, interdependent cloud\nenvironments. While deep learning-based approaches model these dependencies\nbetter, they often face challenges such as high computational demands and lack\nof interpretability.\n  To address these issues, KPIRoot is proposed as an efficient method combining\nsimilarity and causality analysis. It uses symbolic aggregate approximation for\ncompact KPI representation, improving analysis efficiency. However, deployment\nin Cloud H revealed two drawbacks: 1) threshold-based anomaly detection misses\nsome performance anomalies, and 2) SAX representation fails to capture\nintricate variation trends. KPIRoot+ addresses these limitations, outperforming\neight state-of-the-art baselines by 2.9% to 35.7%, while reducing time cost by\n34.7%. We also share our experience deploying KPIRoot in a large-scale cloud\nprovider's production environment.", "AI": {"title_translation": "KPIRoot+：一种用于大规模云系统异常检测和根本原因分析的高效集成框架", "tldr": "KPIRoot+是一个高效的集成框架，用于解决大规模云系统中传统和深度学习方法在异常检测和根本原因分析方面的局限性，通过结合相似性和因果分析并优化KPI表示来提高性能和效率。", "motivation": "为了确保云系统的可靠性，需要监控KPI。当出现问题时，根源定位有助于识别导致服务降级的KPI。传统方法依赖相似性计算，在复杂、相互依赖的云环境中可能无效。基于深度学习的方法虽然能更好地建模依赖关系，但面临计算成本高和缺乏可解释性等挑战。", "method": "KPIRoot最初结合了相似性和因果分析，并使用符号聚合近似（SAX）进行紧凑的KPI表示。KPIRoot+在此基础上进行了改进，解决了KPIRoot在Cloud H部署时发现的两个缺点：1）基于阈值的异常检测会遗漏一些性能异常；2）SAX表示未能捕捉到复杂的变异趋势。", "result": "KPIRoot+在性能上优于八种最先进的基线2.9%至35.7%，同时将时间成本降低了34.7%。", "conclusion": "KPIRoot+是一个高效且改进的框架，能够在大规模云系统中实现更准确和高效的异常检测和根本原因分析，并通过实际部署验证了其有效性。", "translation": "为了确保云系统的可靠性，通过KPI（关键性能指标）对其性能进行监控。当出现问题时，根本原因定位可以识别导致服务降级的原因KPI，有助于快速诊断和解决问题。传统方法依赖于相似性计算，这在复杂、相互依赖的云环境中可能无效。虽然基于深度学习的方法能更好地建模这些依赖关系，但它们通常面临计算需求高和缺乏可解释性等挑战。\n为了解决这些问题，提出了KPIRoot，一种结合相似性和因果分析的高效方法。它使用符号聚合近似（SAX）进行紧凑的KPI表示，提高了分析效率。然而，在Cloud H的部署揭示了两个缺点：1）基于阈值的异常检测会遗漏一些性能异常；2）SAX表示未能捕捉到复杂的变异趋势。KPIRoot+解决了这些限制，其性能优于八种最先进的基线2.9%至35.7%，同时将时间成本降低了34.7%。我们还分享了在大规模云服务提供商的生产环境中部署KPIRoot的经验。", "summary": "本文提出了KPIRoot+，一个用于大规模云系统异常检测和根本原因分析的集成框架。它解决了传统方法在复杂云环境中效率低下的问题以及深度学习方法计算成本高和可解释性差的挑战。KPIRoot+是KPIRoot的改进版本，通过优化KPI表示和异常检测机制，在性能和效率上显著优于现有基线。", "keywords": "异常检测, 根本原因分析, 云系统, KPI, KPIRoot+"}}
{"id": "2506.04768", "pdf": "https://arxiv.org/pdf/2506.04768", "abs": "https://arxiv.org/abs/2506.04768", "authors": ["Ling Hu", "Tao Yang", "Yu Pang", "Bingnan Hou", "Zhiping Cai", "Bo Yu"], "title": "Grey Rhino Warning: IPv6 is Becoming Fertile Ground for Reflection Amplification Attacks", "categories": ["cs.NI"], "comment": "This paper has been accepted by IWQoS 2025 as a short paper", "summary": "Distributed Denial-of-Service (DDoS) attacks represent a cost-effective and\npotent threat to network stability. While extensively studied in IPv4 networks,\nDDoS implications in IPv6 remain underexplored. The vast IPv6 address space\nrenders brute-force scanning and amplifier testing for all active addresses\nimpractical. Innovatively, this work investigates AS-level vulnerabilities to\nreflection amplification attacks in IPv6.\n  One prerequisite for amplification presence is that it is located in a\nvulnerable autonomous system (AS) without inbound source address validation\n(ISAV) deployment. Hence, the analysis focuses on two critical aspects: global\ndetection of ISAV deployment and identification of amplifiers within vulnerable\nASes. Specifically, we develop a methodology combining ICMP Time Exceeded\nmechanisms for ISAV detection, employ IPv6 address scanning for amplifier\nidentification, and utilize dual vantage points for amplification verification.\n  Experimental results reveal that 4,460 ASes (61.36% of measured networks)\nlack ISAV deployment. Through scanning approximately 47M active addresses, we\nhave identified reflection amplifiers in 3,507 ASes. The analysis demonstrates\nthat current IPv6 networks are fertile grounds for reflection amplification\nattacks, alarming network security.", "AI": {"title_translation": "“灰犀牛”警告：IPv6 正在成为反射放大攻击的温床", "tldr": "IPv6网络中分布式拒绝服务（DDoS）反射放大攻击的威胁日益增长，研究发现大量自治系统（AS）缺乏入站源地址验证（ISAV）部署，且存在大量反射放大器。", "motivation": "尽管IPv4网络中的DDoS攻击已被广泛研究，但IPv6中的DDoS影响仍未得到充分探索。IPv6庞大的地址空间使得对所有活跃地址进行暴力扫描和放大器测试变得不切实际，因此需要一种创新方法来调查IPv6中AS级别的反射放大攻击漏洞。", "method": "本研究创新性地调查了IPv6中AS级别的反射放大攻击漏洞。方法包括：结合ICMP超时机制进行ISAV检测，利用IPv6地址扫描识别放大器，并使用双视角进行放大验证。", "result": "实验结果显示，4,460个AS（占所测量网络的61.36%）缺乏ISAV部署。通过扫描大约47M个活跃地址，研究在3,507个AS中识别出了反射放大器。", "conclusion": "分析表明，当前的IPv6网络是反射放大攻击的温床，对网络安全构成警报。", "translation": "分布式拒绝服务（DDoS）攻击对网络稳定性构成了经济有效且强大的威胁。尽管在IPv4网络中DDoS攻击已被广泛研究，但其在IPv6中的影响仍未得到充分探索。IPv6庞大的地址空间使得对所有活跃地址进行暴力扫描和放大器测试变得不切实际。本研究创新性地调查了IPv6中AS级别的反射放大攻击漏洞。\n放大攻击存在的先决条件是其位于没有入站源地址验证（ISAV）部署的脆弱自治系统（AS）中。因此，本分析侧重于两个关键方面：ISAV部署的全球检测以及在脆弱AS中放大器的识别。具体来说，我们开发了一种方法，结合ICMP超时机制进行ISAV检测，采用IPv6地址扫描进行放大器识别，并利用双视角进行放大验证。\n实验结果显示，4,460个AS（占所测量网络的61.36%）缺乏ISAV部署。通过扫描大约47M个活跃地址，我们已在3,507个AS中识别出了反射放大器。分析表明，当前的IPv6网络是反射放大攻击的温床，对网络安全构成警报。", "summary": "本研究揭示了IPv6网络中反射放大攻击的“灰犀牛”威胁。鉴于IPv6地址空间的广阔性，传统扫描方法不再适用。研究团队创新性地从自治系统（AS）层面出发，调查了IPv6网络中缺乏入站源地址验证（ISAV）部署的AS，并识别了其中的反射放大器。实验结果表明，超过60%的测量AS缺乏ISAV，并且在大量AS中发现了反射放大器，这表明IPv6网络已成为反射放大攻击的肥沃土壤，对当前网络安全构成严重威胁。", "keywords": "IPv6, 反射放大攻击, DDoS, AS级别漏洞, ISAV"}}
{"id": "2506.04253", "pdf": "https://arxiv.org/pdf/2506.04253", "abs": "https://arxiv.org/abs/2506.04253", "authors": ["Tapio Pitkäranta", "Leena Pitkäranta"], "title": "HADA: Human-AI Agent Decision Alignment Architecture", "categories": ["cs.AI", "cs.HC", "cs.AI, cs.SE, cs.MA, cs.CL, cs.LG"], "comment": "18 pages, 4 figures", "summary": "We present HADA (Human-AI Agent Decision Alignment), a protocol- and\nframework agnostic reference architecture that keeps both large language model\n(LLM) agents and legacy algorithms aligned with organizational targets and\nvalues. HADA wraps any algorithm or LLM in role-specific stakeholder agents --\nbusiness, data-science, audit, ethics, and customer -- each exposing\nconversational APIs so that technical and non-technical actors can query,\nsteer, audit, or contest every decision across strategic, tactical, and\nreal-time horizons. Alignment objectives, KPIs, and value constraints are\nexpressed in natural language and are continuously propagated, logged, and\nversioned while thousands of heterogeneous agents run on different\norchestration stacks. A cloud-native proof of concept packages a production\ncredit-scoring model (getLoanDecision) and deploys it on\nDocker/Kubernetes/Python; five scripted retail-bank scenarios show how target\nchanges, parameter tweaks, explanation requests, and ethics triggers flow end\nto end through the architecture. Evaluation followed the Design-Science\nResearch Methodology. Walkthrough observation and log inspection demonstrated\ncomplete coverage of six predefined objectives: every role could invoke\nconversational control, trace KPIs and value constraints, detect and mitigate\nZIP-code bias, and reproduce full decision lineage, independent of the\nunderlying LLM or agent library. Contributions: (1) an open-source HADA\narchitecture, (2) a mid-range design theory for human-AI alignment in\nmulti-agent systems, and (3) empirical evidence that framework-agnostic,\nprotocol-compliant stakeholder agents improve accuracy, transparency, and\nethical compliance in real-world decision pipelines.", "AI": {"title_translation": "HADA：人机代理决策对齐架构", "tldr": "HADA是一个参考架构，通过角色特定的利益相关者代理，使大型语言模型和传统算法与组织目标和价值观保持一致，并支持决策查询、引导、审计和争议。", "motivation": "使大型语言模型（LLM）代理和传统算法与组织目标和价值观保持一致，解决现有系统可能存在的不透明、难以控制和对齐的问题。", "method": "HADA是一个协议和框架无关的参考架构，将任何算法或LLM封装在业务、数据科学、审计、伦理和客户等特定角色的利益相关者代理中，每个代理都提供对话式API。通过自然语言表达对齐目标、KPI和价值约束，并持续传播、记录和版本化。通过云原生概念验证，部署了一个生产信用评分模型，并在Docker/Kubernetes/Python上运行。通过设计科学研究方法进行评估，包括观察和日志检查，使用五个脚本化的零售银行场景来展示其端到端流程。", "result": "评估证明HADA完全覆盖了六个预定义目标：每个角色都可以调用对话控制，追踪KPI和价值约束，检测并缓解邮政编码偏见，并重现完整的决策谱系，且独立于底层LLM或代理库。经验证据表明，框架无关、符合协议的利益相关者代理提高了实际决策流程中的准确性、透明度和伦理合规性。", "conclusion": "HADA提供了一个开源架构、一套用于多代理系统中人机对齐的中程设计理论，以及经验证据，表明其能够提高决策准确性、透明度和伦理合规性。", "translation": "我们提出了HADA（人机代理决策对齐），这是一个独立于协议和框架的参考架构，旨在使大型语言模型（LLM）代理和传统算法与组织目标和价值观保持一致。HADA将任何算法或LLM封装在特定角色的利益相关者代理中——包括业务、数据科学、审计、伦理和客户——每个代理都公开对话式API，以便技术和非技术参与者可以查询、引导、审计或质疑跨战略、战术和实时层面的每一个决策。对齐目标、KPI和价值约束以自然语言表达，并在数千个异构代理在不同编排堆栈上运行时持续传播、记录和版本化。一个云原生概念验证将一个生产信用评分模型（getLoanDecision）打包并部署在Docker/Kubernetes/Python上；五个脚本化的零售银行场景展示了目标变更、参数调整、解释请求和伦理触发器如何端到端地流经整个架构。评估遵循设计科学研究方法。通过观察和日志检查，证明了对六个预定义目标的完全覆盖：每个角色都可以调用对话控制，追踪KPI和价值约束，检测并缓解邮政编码偏见，并重现完整的决策谱系，独立于底层LLM或代理库。贡献包括：（1）一个开源的HADA架构，（2）一个用于多代理系统中人机对齐的中程设计理论，以及（3）经验证据，表明框架无关、符合协议的利益相关者代理提高了实际决策流程中的准确性、透明度和伦理合规性。", "summary": "HADA（人机代理决策对齐）是一个协议和框架无关的参考架构，旨在使大型语言模型代理和传统算法与组织目标和价值观保持一致。它通过将算法或LLM封装在业务、数据科学、审计、伦理和客户等角色特定的利益相关者代理中实现此目的，这些代理提供对话式API，允许技术和非技术人员查询、引导、审计或质疑跨战略、战术和实时层面的决策。HADA支持以自然语言表达对齐目标、KPI和价值约束的持续传播、记录和版本化。概念验证和设计科学研究方法的评估表明，该架构能够实现对话控制、KPI和价值追踪、偏见检测与缓解，以及决策谱系再现，从而提高真实世界决策流程的准确性、透明度和伦理合规性。", "keywords": "人机对齐, LLM代理, 决策架构, 利益相关者代理, 伦理合规性"}}
{"id": "2506.04353", "pdf": "https://arxiv.org/pdf/2506.04353", "abs": "https://arxiv.org/abs/2506.04353", "authors": ["Ankit Pal", "Jung-Oh Lee", "Xiaoman Zhang", "Malaikannan Sankarasubbu", "Seunghyeon Roh", "Won Jung Kim", "Meesun Lee", "Pranav Rajpurkar"], "title": "ReXVQA: A Large-scale Visual Question Answering Benchmark for Generalist Chest X-ray Understanding", "categories": ["cs.CV", "cs.AI", "cs.CE", "cs.CL", "cs.LG"], "comment": null, "summary": "We present ReXVQA, the largest and most comprehensive benchmark for visual\nquestion answering (VQA) in chest radiology, comprising approximately 696,000\nquestions paired with 160,000 chest X-rays studies across training, validation,\nand test sets. Unlike prior efforts that rely heavily on template based\nqueries, ReXVQA introduces a diverse and clinically authentic task suite\nreflecting five core radiological reasoning skills: presence assessment,\nlocation analysis, negation detection, differential diagnosis, and geometric\nreasoning. We evaluate eight state-of-the-art multimodal large language models,\nincluding MedGemma-4B-it, Qwen2.5-VL, Janus-Pro-7B, and Eagle2-9B. The\nbest-performing model (MedGemma) achieves 83.24% overall accuracy. To bridge\nthe gap between AI performance and clinical expertise, we conducted a\ncomprehensive human reader study involving 3 radiology residents on 200\nrandomly sampled cases. Our evaluation demonstrates that MedGemma achieved\nsuperior performance (83.84% accuracy) compared to human readers (best\nradiology resident: 77.27%), representing a significant milestone where AI\nperformance exceeds expert human evaluation on chest X-ray interpretation. The\nreader study reveals distinct performance patterns between AI models and human\nexperts, with strong inter-reader agreement among radiologists while showing\nmore variable agreement patterns between human readers and AI models. ReXVQA\nestablishes a new standard for evaluating generalist radiological AI systems,\noffering public leaderboards, fine-grained evaluation splits, structured\nexplanations, and category-level breakdowns. This benchmark lays the foundation\nfor next-generation AI systems capable of mimicking expert-level clinical\nreasoning beyond narrow pathology classification. Our dataset will be\nopen-sourced at https://huggingface.co/datasets/rajpurkarlab/ReXVQA", "AI": {"title_translation": "ReXVQA：一个用于通用胸部X光理解的大规模视觉问答基准", "tldr": "ReXVQA是一个大规模的胸部X光视觉问答基准，AI在胸部X光解释方面首次超越人类专家。", "motivation": "以往的胸部放射学VQA基准过度依赖基于模板的查询，缺乏多样性和临床真实性，无法有效评估AI的通用放射学推理能力。", "method": "本文提出了ReXVQA，一个包含约696,000个问题和160,000张胸部X光研究的视觉问答基准。ReXVQA引入了多样化且临床真实的任务套件，涵盖五种核心放射学推理技能：存在评估、位置分析、否定检测、鉴别诊断和几何推理。研究评估了八种最先进的多模态大型语言模型，并进行了一项涉及3名放射科住院医师的200例随机抽样病例的人类阅读器研究，以比较AI模型和人类专家的表现。", "result": "最佳表现模型MedGemma在总体上取得了83.24%的准确率。在人类阅读器研究中，MedGemma达到了83.84%的准确率，超过了表现最好的放射科住院医师（77.27%）。AI模型和人类专家之间表现模式不同，放射科医师之间的一致性强，而人类阅读器与AI模型之间的一致性模式更具变异性。", "conclusion": "ReXVQA为评估通用放射学AI系统建立了新标准，并证明了AI在胸部X光解释方面的表现首次超越了专家人类评估，为开发能够模仿专家级临床推理的下一代AI系统奠定了基础。", "translation": "我们提出了ReXVQA，这是胸部放射学视觉问答（VQA）领域最大、最全面的基准，包含约696,000个问题，与160,000张胸部X光研究配对，涵盖训练、验证和测试集。与之前高度依赖基于模板查询的工作不同，ReXVQA引入了多样化且临床真实的任务套件，反映了五种核心放射学推理技能：存在评估、位置分析、否定检测、鉴别诊断和几何推理。我们评估了八种最先进的多模态大型语言模型，包括MedGemma-4B-it、Qwen2.5-VL、Janus-Pro-7B和Eagle2-9B。表现最佳的模型（MedGemma）实现了83.24%的总体准确率。为了弥合AI性能与临床专业知识之间的差距，我们对200例随机抽样病例进行了全面的、涉及3名放射科住院医师的人类阅读器研究。我们的评估表明，MedGemma取得了优异的性能（83.84%的准确率），超过了人类阅读器（最佳放射科住院医师：77.27%），这标志着AI性能在胸部X光解释方面首次超越专家人类评估，具有里程碑意义。阅读器研究揭示了AI模型和人类专家之间独特的性能模式，放射科医师之间具有强烈的判读一致性，而人类阅读器与AI模型之间显示出更多变的一致性模式。ReXVQA为评估通用放射学AI系统建立了新标准，提供公共排行榜、细粒度评估划分、结构化解释和类别级细分。这个基准为能够模仿超越狭窄病理分类的专家级临床推理的下一代AI系统奠定了基础。我们的数据集将在https://huggingface.co/datasets/rajpurkarlab/ReXVQA开源。", "summary": "ReXVQA是一个大规模、全面的胸部放射学视觉问答基准，包含696,000个问题和160,000张胸部X光片，旨在解决现有基准模板化查询的局限性，引入了多样化的临床推理任务。研究评估了八种先进的多模态大语言模型，其中MedGemma表现最佳，准确率达83.24%。一项人类阅读器研究显示，MedGemma的准确率（83.84%）甚至超越了放射科专家（77.27%），标志着AI在胸部X光解释方面首次超越人类专家。ReXVQA为通用放射学AI系统评估设立了新标准，并为未来AI系统模仿专家级临床推理奠定了基础。", "keywords": "视觉问答, 胸部X光, 放射学AI, 大型语言模型, 医疗影像"}}
{"id": "2506.04839", "pdf": "https://arxiv.org/pdf/2506.04839", "abs": "https://arxiv.org/abs/2506.04839", "authors": ["Dmitry Artemasov", "Oleg Nesterenkov", "Kirill Andreev", "Pavel Rybin", "Alexey Frolov"], "title": "Iterative Neural Rollback Chase-Pyndiah Decoding", "categories": ["cs.IT", "math.IT"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Iterative decoding is essential in modern communication systems, especially\noptical communications, where error-correcting codes such as turbo product\ncodes (TPC) and staircase codes are widely employed. A key factor in achieving\nhigh error correction performance is the use of soft-decision decoding for\ncomponent codes. However, implementing optimal maximum a posteriori (MAP)\nprobability decoding for commonly used component codes, such as BCH and Polar\ncodes, is computationally prohibitive. Instead, practical systems rely on\napproximations, with the Chase-Pyndiah algorithm being a widely used suboptimal\nmethod. TPC are more powerful than their component codes and begin to function\neffectively at low signal-to-noise ratios. Consequently, during the initial\niterations, the component codes do not perform well and introduce errors in the\nextrinsic information updates. This phenomenon limits the performance of TPC.\nThis paper proposes a neural network-aided rollback Chase-Pyndiah decoding\nmethod to address this issue. A transformer-based neural network identifies\ncases where extrinsic updates are likely to introduce errors, triggering a\nrollback mechanism which prevents the update and keeps the component code\nmessage intact. Our results demonstrate that a neural network with a relatively\nsmall number of parameters can effectively distinguish destructive updates and\nimprove decoding performance. We evaluate the proposed approach using TPC with\n(256, 239) extended BCH component codes. We show that the proposed method\nenhances the bit error rate performance of Chase-Pyndiah p=6 decoding,\nachieving a gain of approximately 0.145 dB in a TPC scheme with four full\niterations, significantly outperforming conventional Chase p=7 decoding.", "AI": {"title_translation": "迭代神经网络回滚Chase-Pyndiah译码", "tldr": "本文提出一种基于神经网络的回滚Chase-Pyndiah译码方法，以提高迭代译码器的性能，特别是对于涡轮积码。", "motivation": "在迭代译码中，特别是对于涡轮积码（TPC），由于初始迭代中分量码在低信噪比下性能不佳，导致外信息更新引入错误，限制了TPC的性能。而最优的MAP译码计算成本过高。", "method": "本文提出一种神经网络辅助的回滚Chase-Pyndiah译码方法。该方法使用一个基于Transformer的神经网络来识别可能引入错误的外信息更新，并触发回滚机制以阻止这些更新，从而保持分量码消息的完整性。", "result": "实验结果表明，参数量相对较小的神经网络能有效区分破坏性更新。所提出的方法在采用(256, 239)扩展BCH分量码的TPC方案中，将Chase-Pyndiah p=6译码的误码率性能提高了约0.145 dB，在四个完整迭代后显著优于传统的Chase p=7译码。", "conclusion": "所提出的神经网络辅助回滚机制有效解决了迭代译码中外信息更新错误的问题，从而提高了涡轮积码的译码性能。", "translation": "迭代译码在现代通信系统，尤其是光通信中至关重要，其中广泛使用涡轮积码（TPC）和阶梯码等纠错码。实现高纠错性能的关键因素是分量码采用软判决译码。然而，对于常用的分量码，如BCH码和极化码，实现最优的最大后验概率（MAP）译码在计算上是 prohibitively 的。相反，实际系统依赖于近似方法，其中Chase-Pyndiah算法是一种广泛使用的次优方法。TPC比其分量码更强大，并在低信噪比下开始有效工作。因此，在初始迭代期间，分量码表现不佳，并在外信息更新中引入错误。这种现象限制了TPC的性能。本文提出了一种神经网络辅助的回滚Chase-Pyndiah译码方法来解决这个问题。一个基于Transformer的神经网络识别外信息更新可能引入错误的情况，触发回滚机制以阻止更新并保持分量码消息的完整性。我们的结果表明，一个参数量相对较小的神经网络可以有效地区分破坏性更新并提高译码性能。我们使用带有(256, 239)扩展BCH分量码的TPC评估了所提出的方法。我们表明，所提出的方法增强了Chase-Pyndiah p=6译码的误码率性能，在具有四个完整迭代的TPC方案中实现了大约0.145 dB的增益，显著优于传统的Chase p=7译码。", "summary": "本文提出了一种迭代神经网络回滚Chase-Pyndiah译码方法，旨在提高涡轮积码（TPC）的性能。该方法通过使用基于Transformer的神经网络识别并阻止初始迭代中可能引入错误的外信息更新，从而解决这一问题。实验结果表明，该方法能有效区分破坏性更新，并使误码率性能获得显著提升，相较于传统方法增益约0.145 dB。", "keywords": "迭代译码, 神经网络, Chase-Pyndiah, 回滚, 涡轮积码"}}
{"id": "2506.04235", "pdf": "https://arxiv.org/pdf/2506.04235", "abs": "https://arxiv.org/abs/2506.04235", "authors": ["Xinyan Zhao", "Yi-Ching Tang", "Akshita Singh", "Victor J Cantu", "KwanHo An", "Junseok Lee", "Adam E Stogsdill", "Ashwin Kumar Ramesh", "Zhiqiang An", "Xiaoqian Jiang", "Yejin Kim"], "title": "Benchmark for Antibody Binding Affinity Maturation and Design", "categories": ["q-bio.QM", "cs.AI", "cs.CE", "cs.LG", "q-bio.BM"], "comment": null, "summary": "We introduce AbBiBench (Antibody Binding Benchmarking), a benchmarking\nframework for antibody binding affinity maturation and design. Unlike existing\nantibody evaluation strategies that rely on antibody alone and its similarity\nto natural ones (e.g., amino acid identity rate, structural RMSD), AbBiBench\nconsiders an antibody-antigen (Ab-Ag) complex as a functional unit and\nevaluates the potential of an antibody design binding to given antigen by\nmeasuring protein model's likelihood on the Ab-Ag complex. We first curate,\nstandardize, and share 9 datasets containing 9 antigens (involving influenza,\nanti-lysozyme, HER2, VEGF, integrin, and SARS-CoV-2) and 155,853 heavy chain\nmutated antibodies. Using these datasets, we systematically compare 14 protein\nmodels including masked language models, autoregressive language models,\ninverse folding models, diffusion-based generative models, and geometric graph\nmodels. The correlation between model likelihood and experimental affinity\nvalues is used to evaluate model performance. Additionally, in a case study to\nincrease binding affinity of antibody F045-092 to antigen influenza H1N1, we\nevaluate the generative power of the top-performing models by sampling a set of\nnew antibodies binding to the antigen and ranking them based on structural\nintegrity and biophysical properties of the Ab-Ag complex. As a result,\nstructure-conditioned inverse folding models outperform others in both affinity\ncorrelation and generation tasks. Overall, AbBiBench provides a unified,\nbiologically grounded evaluation framework to facilitate the development of\nmore effective, function-aware antibody design models.", "AI": {"title_translation": "抗体结合亲和力成熟与设计基准", "tldr": "AbBiBench是一个用于抗体结合亲和力成熟和设计的基准框架，它通过评估蛋白质模型在抗体-抗原复合物上的可能性来衡量抗体设计潜力，并发现结构条件逆向折叠模型表现最佳。", "motivation": "现有的抗体评估策略仅依赖于抗体本身及其与天然抗体的相似性（如氨基酸同一性率、结构RMSD），无法充分评估抗体设计的潜力。因此，需要一个考虑抗体-抗原复合物作为一个功能单位的评估框架。", "method": "AbBiBench通过测量蛋白质模型在抗体-抗原（Ab-Ag）复合物上的可能性来评估抗体设计结合给定抗原的潜力。首先，该研究整理并共享了9个数据集，包含9种抗原和155,853个重链突变抗体。然后，系统比较了14种蛋白质模型（包括掩码语言模型、自回归语言模型、逆向折叠模型、基于扩散的生成模型和几何图模型）。模型性能通过模型可能性与实验亲和力值之间的相关性来评估。此外，通过一个案例研究，评估了表现最佳模型的生成能力，通过采样新抗体并根据Ab-Ag复合物的结构完整性和生物物理特性进行排名。", "result": "结构条件逆向折叠模型在亲和力相关性和生成任务中均优于其他模型。", "conclusion": "AbBiBench提供了一个统一的、基于生物学原理的评估框架，以促进开发更有效、功能感知的抗体设计模型。", "translation": "我们引入了AbBiBench（抗体结合基准），一个用于抗体结合亲和力成熟和设计的基准框架。与现有仅依赖抗体本身及其与天然抗体相似性（例如，氨基酸同一性率、结构RMSD）的抗体评估策略不同，AbBiBench将抗体-抗原（Ab-Ag）复合物视为一个功能单元，并通过测量蛋白质模型在Ab-Ag复合物上的可能性来评估抗体设计结合给定抗原的潜力。我们首先整理、标准化并共享了9个数据集，其中包含9种抗原（涉及流感、抗溶菌酶、HER2、VEGF、整合素和SARS-CoV-2）和155,853个重链突变抗体。利用这些数据集，我们系统地比较了14种蛋白质模型，包括掩码语言模型、自回归语言模型、逆向折叠模型、基于扩散的生成模型和几何图模型。模型可能性与实验亲和力值之间的相关性用于评估模型性能。此外，在一个增加抗体F045-092与流感H1N1抗原结合亲和力的案例研究中，我们通过采样一组与抗原结合的新抗体并根据Ab-Ag复合物的结构完整性和生物物理特性对其进行排名，从而评估了表现最佳模型的生成能力。结果显示，结构条件逆向折叠模型在亲和力相关性和生成任务中均优于其他模型。总的来说，AbBiBench提供了一个统一的、基于生物学原理的评估框架，以促进开发更有效、功能感知的抗体设计模型。", "summary": "该论文介绍了AbBiBench，一个用于抗体结合亲和力成熟和设计的基准框架。与现有仅依赖抗体自身相似性的评估方法不同，AbBiBench将抗体-抗原复合物视为功能单元，并通过测量蛋白质模型在复合物上的可能性来评估抗体设计潜力。研究策劃了包含9种抗原和15万余个突变抗体的9个数据集，并系统比较了14种蛋白质模型。结果表明，结构条件逆向折叠模型在亲和力相关性和生成任务中表现最佳。AbBiBench旨在提供一个统一的生物学评估框架，以推动更有效的功能感知抗体设计模型的发展。", "keywords": "抗体, 结合亲和力, 基准测试, 蛋白质模型, 逆向折叠模型"}}
{"id": "2506.04254", "pdf": "https://arxiv.org/pdf/2506.04254", "abs": "https://arxiv.org/abs/2506.04254", "authors": ["Nicolas Caron", "Christophe Guyeux", "Hassan Noura", "Benjamin Aynes"], "title": "Localized Forest Fire Risk Prediction: A Department-Aware Approach for Operational Decision Support", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 7 figures, 3 tables, submitted to ECAI2025", "summary": "Forest fire prediction involves estimating the likelihood of fire ignition or\nrelated risk levels in a specific area over a defined time period. With climate\nchange intensifying fire behavior and frequency, accurate prediction has become\none of the most pressing challenges in Artificial Intelligence (AI).\nTraditionally, fire ignition is approached as a binary classification task in\nthe literature. However, this formulation oversimplifies the problem,\nespecially from the perspective of end-users such as firefighters. In general,\nas is the case in France, firefighting units are organized by department, each\nwith its terrain, climate conditions, and historical experience with fire\nevents. Consequently, fire risk should be modeled in a way that is sensitive to\nlocal conditions and does not assume uniform risk across all regions. This\npaper proposes a new approach that tailors fire risk assessment to departmental\ncontexts, offering more actionable and region-specific predictions for\noperational use. With this, we present the first national-scale AI benchmark\nfor metropolitan France using state-of-the-art AI models on a relatively\nunexplored dataset. Finally, we offer a summary of important future works that\nshould be taken into account. Supplementary materials are available on GitHub.", "AI": {"title_translation": "局部森林火灾风险预测：一种面向部门的作战决策支持方法", "tldr": "针对法国消防部门的需求，提出一种新的、考虑地域差异的森林火灾风险预测方法，并在法国全国范围内进行了基准测试。", "motivation": "传统方法将火灾点火视为二元分类任务，但这种方法过于简化，未能考虑到消防部门（如法国）按部门划分的组织结构及其各自的地形、气候条件和历史经验。因此，需要一种对当地条件敏感且不假设所有区域风险一致的模型，以提供更具操作性和区域特异性的预测。", "method": "本文提出一种根据部门背景调整火灾风险评估的新方法，旨在提供更具操作性和区域特异性的预测。该方法在法国本土使用最先进的AI模型和相对未探索的数据集进行了首次全国规模的AI基准测试。", "result": "Not mentioned in abstract", "conclusion": "论文提出了一种新的、部门感知的火灾风险评估方法，旨在为消防部门提供更实用、更具地域针对性的预测，并为未来的研究提供了方向。", "translation": "森林火灾预测涉及估计特定区域在规定时间段内火灾点燃的可能性或相关风险水平。随着气候变化加剧火灾行为和频率，准确预测已成为人工智能（AI）领域最紧迫的挑战之一。传统上，火灾点燃在文献中被视为二元分类任务。然而，这种表述过于简化了问题，特别是从消防员等最终用户的角度来看。通常，正如法国的情况一样，消防单位按部门组织，每个部门都有其地形、气候条件和火灾事件的历史经验。因此，火灾风险的建模方式应能对当地条件敏感，并且不假设所有区域的风险都是统一的。本文提出了一种新方法，根据部门背景调整火灾风险评估，为操作使用提供更具操作性和区域特异性的预测。在此基础上，我们利用相对未探索的数据集，使用最先进的AI模型，首次为法国本土提供了全国规模的AI基准测试。最后，我们总结了应考虑的重要未来工作。补充材料可在GitHub上获取。", "summary": "本文提出了一种局部森林火灾风险预测的新方法，该方法考虑到法国消防部门的区域组织结构和各部门的特定条件，以解决传统二元分类模型过于简化的问题。该方法旨在提供更具操作性和地域特异性的预测，并首次在法国本土进行了全国规模的AI基准测试。", "keywords": "森林火灾预测, 风险评估, 部门感知, 作战决策支持, 人工智能"}}
{"id": "2506.04588", "pdf": "https://arxiv.org/pdf/2506.04588", "abs": "https://arxiv.org/abs/2506.04588", "authors": ["Anatoli Kovalev", "Narelle Stefanac", "Marian-Andrei Rizoiu"], "title": "Skill-Driven Certification Pathways: Measuring Industry Training Impact on Graduate Employability", "categories": ["cs.CY"], "comment": null, "summary": "Australia faces a critical technology skills shortage, requiring\napproximately $52,000$ new technology professionals annually by 2030, while\nconfronting a widening gap between employer requirements and graduate\ncapabilities. With only $1\\%$ of technology graduates considered immediately\nwork-ready, traditional educational pathways alone prove insufficient to meet\nindustry demands. This research examines how industry certifications, such as\nMicrosoft's AI-900 (Azure AI Fundamentals), can bridge this critical skills\ngap. We propose a novel, data-driven methodology that quantitatively measures\nskill alignment between educational offerings and job market requirements by\nanalysing over 2.5 million job advertisements from Australia, the US, and the\nUK, mapping extracted skills to industry taxonomies using the Vectorised Skills\nSpace Method. Our findings reveal that combining university degrees with\ntargeted industry certifications significantly enhances employability for\ntechnology roles. The Bachelor of Computer Science with AI major combined with\nAI-900 certification achieved the highest absolute skill similarity score for\nMachine Learning Engineer positions. Surprisingly, the largest improvements\nwhen augmented with AI certifications are experiences by non-technical\ndegrees--such as nursing nursing--with up to $9,296\\%$ percentage improvements\nin alignment with Machine Learning Engineer roles. Our results challenge\nconventional assumptions about technology career pathways. They can provide\nactionable insights for educational institutions seeking evidence-based\ncurriculum design, students requiring strategic certification guidance, and\nemployers recognising potential in candidates from non-traditional backgrounds\nwho have obtained relevant certifications.", "AI": {"title_translation": "技能驱动的认证途径：衡量行业培训对毕业生就业能力的影响", "tldr": "本研究通过分析250万份职位广告，发现行业认证（如微软AI-900）能显著提升技术毕业生就业能力，尤其对于非技术专业毕业生效果更佳，挑战了传统技术职业路径的假设。", "motivation": "澳大利亚面临严重的科技技能短缺，每年需新增52,000名科技专业人才，但雇主需求与毕业生能力之间存在巨大差距，仅1%的科技毕业生被认为是立即具备工作能力的。传统教育途径不足以满足行业需求。", "method": "本研究提出了一种新颖的数据驱动方法，通过分析来自澳大利亚、美国和英国的超过250万份职位广告，量化衡量教育产品与就业市场需求之间的技能匹配度。采用“向量化技能空间方法”将提取的技能映射到行业分类体系。", "result": "研究发现，大学学位与目标行业认证相结合能显著提升技术岗位的就业能力。计算机科学学士学位（人工智能方向）结合AI-900认证在机器学习工程师职位上取得了最高的绝对技能相似度分数。令人惊讶的是，非技术学位（如护理学）在增加AI认证后，与机器学习工程师职位的匹配度提升高达9296%。", "conclusion": "研究结果挑战了关于技术职业路径的传统假设，为教育机构提供循证课程设计、为学生提供战略性认证指导、为雇主识别来自非传统背景但获得相关认证的潜在候选人提供了可操作的见解。", "translation": "澳大利亚面临严重的科技技能短缺，到2030年每年需要大约52,000名新的科技专业人才，同时雇主需求与毕业生能力之间的差距不断扩大。鉴于仅有1%的科技毕业生被认为是立即具备工作能力的，传统的教育途径不足以满足行业需求。本研究探讨了微软AI-900（Azure AI基础）等行业认证如何弥补这一关键技能差距。我们提出了一种新颖的数据驱动方法，通过分析来自澳大利亚、美国和英国的超过250万份职位广告，量化衡量教育产品与就业市场需求之间的技能匹配度，并使用“向量化技能空间方法”将提取的技能映射到行业分类体系。我们的研究结果表明，将大学学位与目标行业认证相结合可以显著提高技术岗位的就业能力。计算机科学学士学位（人工智能方向）结合AI-900认证在机器学习工程师职位上取得了最高的绝对技能相似度分数。令人惊讶的是，非技术学位（如护理学）在增加AI认证后，与机器学习工程师职位的匹配度提升最高，高达9296%。我们的研究结果挑战了关于技术职业路径的传统假设。它们可以为寻求循证课程设计的教育机构、需要战略性认证指导的学生以及识别来自非传统背景但获得相关认证的潜在候选人的雇主提供可操作的见解。", "summary": "本研究旨在解决澳大利亚科技技能短缺和毕业生就业能力不足的问题，探讨行业认证如何弥补技能差距。通过分析全球250万份职位广告，提出一种数据驱动方法来衡量教育与就业市场的技能匹配度。研究发现，结合大学学位和行业认证能显著提高技术岗位的就业能力，尤其对于非技术背景的毕业生，其技能匹配度提升更为显著。这些发现为教育机构、学生和雇主提供了宝贵的指导。", "keywords": "行业认证, 就业能力, 技能差距, 数据驱动方法, 机器学习工程师"}}
{"id": "2506.04833", "pdf": "https://arxiv.org/pdf/2506.04833", "abs": "https://arxiv.org/abs/2506.04833", "authors": ["Jincheng Guan", "Jun Zhang"], "title": "Distributed system perspective on Backscatter systems", "categories": ["cs.DC"], "comment": null, "summary": "Backscatter system is a system based on backscatter communication technology,\nwhich is a low cost, low power consumption and easy to deploy communication\ntechnology. At present, the backscatter technology is mainly applied to RFID\ntags and the Internet of Things and other fields. With the rapid development of\nthe Internet of Things, the application of backscatter systems is increasing.\nMoreover, the backscatter system is essentially a distributed system, but\nexisting research rarely conducts studies and analyses from a distributed\nperspective. This paper conducts a study on the backscattering system from the\nperspective of distributed systems, comprehensively reviewing the basic\nprinciples of the backscattering system, and analyzing the distributed system\narchitectures of different backscattering systems. Then, it introduces the\napplication scenarios, research status and challenges of the backscattering\nsystem, and finally discusses the future research directions of the\nbackscattering system, hoping to provide references for future research.", "AI": {"title_translation": "分布式系统视角下的反向散射系统", "tldr": "本文从分布式系统角度综述了反向散射系统。", "motivation": "现有研究很少从分布式系统角度对反向散射系统进行研究和分析。", "method": "本文从分布式系统角度对反向散射系统进行了研究，全面回顾了其基本原理，分析了不同反向散射系统的分布式系统架构，并介绍了应用场景、研究现状和挑战，最后讨论了未来研究方向。", "result": "本文综述了反向散射系统的基本原理、分布式系统架构、应用场景、研究现状、挑战以及未来研究方向。", "conclusion": "本文旨在为未来的反向散射系统研究提供参考。", "translation": "反向散射系统是一种基于反向散射通信技术的系统，这是一种低成本、低功耗、易于部署的通信技术。目前，反向散射技术主要应用于RFID标签和物联网等领域。随着物联网的快速发展，反向散射系统的应用越来越多。此外，反向散射系统本质上是一个分布式系统，但现有研究很少从分布式角度进行研究和分析。本文从分布式系统角度对反向散射系统进行了研究，全面回顾了反向散射系统的基本原理，分析了不同反向散射系统的分布式系统架构。然后，介绍了反向散射系统的应用场景、研究现状和挑战，最后讨论了反向散射系统的未来研究方向，希望能为未来的研究提供参考。", "summary": "本文从分布式系统角度对反向散射系统进行了全面的综述。文章回顾了其基本原理和分布式架构，探讨了应用场景、研究现状及挑战，并展望了未来的研究方向，旨在为相关研究提供参考。", "keywords": "反向散射系统, 分布式系统, 物联网, RFID, 通信技术"}}
{"id": "2506.04838", "pdf": "https://arxiv.org/pdf/2506.04838", "abs": "https://arxiv.org/abs/2506.04838", "authors": ["Pablo Fernández Saura", "K. R. Jayaram", "Vatche Isahagian", "Jorge Bernal Bernabé", "Antonio Skarmeta"], "title": "On Automating Security Policies with Contemporary LLMs", "categories": ["cs.CR", "cs.AI"], "comment": "Short Paper. Accepted To Appear in IEEE SSE 2025 (part of SERVICES\n  2025)", "summary": "The complexity of modern computing environments and the growing\nsophistication of cyber threats necessitate a more robust, adaptive, and\nautomated approach to security enforcement. In this paper, we present a\nframework leveraging large language models (LLMs) for automating attack\nmitigation policy compliance through an innovative combination of in-context\nlearning and retrieval-augmented generation (RAG). We begin by describing how\nour system collects and manages both tool and API specifications, storing them\nin a vector database to enable efficient retrieval of relevant information. We\nthen detail the architectural pipeline that first decomposes high-level\nmitigation policies into discrete tasks and subsequently translates each task\ninto a set of actionable API calls. Our empirical evaluation, conducted using\npublicly available CTI policies in STIXv2 format and Windows API documentation,\ndemonstrates significant improvements in precision, recall, and F1-score when\nemploying RAG compared to a non-RAG baseline.", "AI": {"title_translation": "利用当代大型语言模型自动化安全策略", "tldr": "本文提出一个利用大型语言模型（LLMs）结合上下文学习和检索增强生成（RAG）的框架，旨在自动化网络攻击缓解策略的合规性，并在实验中展示了其有效性。", "motivation": "现代计算环境的复杂性以及网络威胁日益增长的复杂性，需要更强大、适应性更强和自动化的安全执行方法。", "method": "该研究提出了一个框架，利用大型语言模型（LLMs）结合上下文学习和检索增强生成（RAG），自动化攻击缓解策略的合规性。系统首先收集工具和API规范并存储在向量数据库中。然后，架构管道将高级缓解策略分解为离散任务，并将每个任务转化为可操作的API调用。", "result": "使用公开的STIXv2格式CTI策略和Windows API文档进行的实证评估显示，与非RAG基线相比，采用RAG后，精确率、召回率和F1分数均有显著提高。", "conclusion": "通过结合LLMs、上下文学习和RAG，可以显著提高安全策略自动化执行的效率和准确性。", "translation": "现代计算环境的复杂性以及网络威胁日益增长的复杂性，需要更强大、适应性更强和自动化的安全执行方法。在本文中，我们提出了一个利用大型语言模型（LLMs）的框架，通过结合上下文学习和检索增强生成（RAG）的创新方式，自动化攻击缓解策略的合规性。我们首先描述了我们的系统如何收集和管理工具和API规范，并将它们存储在向量数据库中，以实现相关信息的有效检索。然后，我们详细介绍了其架构流程，该流程首先将高级缓解策略分解为离散任务，随后将每个任务转化为一组可操作的API调用。我们使用公开的STIXv2格式CTI策略和Windows API文档进行的实证评估表明，与非RAG基线相比，采用RAG后，精确率、召回率和F1分数均有显著提高。", "summary": "本研究提出一个利用大型语言模型（LLMs）结合上下文学习和检索增强生成（RAG）的框架，旨在自动化网络攻击缓解策略的合规性。该框架通过收集和管理工具与API规范、将高级策略分解为离散任务并转化为API调用来实现。实证评估表明，与非RAG方法相比，该方法在精确率、召回率和F1分数上均有显著提升。", "keywords": "大型语言模型, 安全策略自动化, 检索增强生成, 攻击缓解, 网络安全"}}
{"id": "2506.04565", "pdf": "https://arxiv.org/pdf/2506.04565", "abs": "https://arxiv.org/abs/2506.04565", "authors": ["Jiayi Chen", "Junyi Ye", "Guiling Wang"], "title": "From Standalone LLMs to Integrated Intelligence: A Survey of Compound Al Systems", "categories": ["cs.MA", "cs.CL"], "comment": null, "summary": "Compound Al Systems (CAIS) is an emerging paradigm that integrates large\nlanguage models (LLMs) with external components, such as retrievers, agents,\ntools, and orchestrators, to overcome the limitations of standalone models in\ntasks requiring memory, reasoning, real-time grounding, and multimodal\nunderstanding. These systems enable more capable and context-aware behaviors by\ncomposing multiple specialized modules into cohesive workflows. Despite growing\nadoption in both academia and industry, the CAIS landscape remains fragmented,\nlacking a unified framework for analysis, taxonomy, and evaluation. In this\nsurvey, we define the concept of CAIS, propose a multi-dimensional taxonomy\nbased on component roles and orchestration strategies, and analyze four\nfoundational paradigms: Retrieval-Augmented Generation (RAG), LLM Agents,\nMultimodal LLMs (MLLMs), and orchestration-centric architectures. We review\nrepresentative systems, compare design trade-offs, and summarize evaluation\nmethodologies across these paradigms. Finally, we identify key\nchallenges-including scalability, interoperability, benchmarking, and\ncoordination-and outline promising directions for future research. This survey\naims to provide researchers and practitioners with a comprehensive foundation\nfor understanding, developing, and advancing the next generation of\nsystem-level artificial intelligence.", "AI": {"title_translation": "从独立大型语言模型到集成智能：复合人工智能系统综述", "tldr": "本文综述了复合AI系统（CAIS），它通过整合LLM与外部组件克服了独立LLM的局限性，并提出了一个统一的分析框架、分类法和评估方法，同时指出了挑战和未来方向。", "motivation": "独立大型语言模型在需要记忆、推理、实时基础和多模态理解的任务中存在局限性。尽管复合AI系统（CAIS）日益普及，但其领域仍分散，缺乏统一的分析框架、分类和评估方法。", "method": "本综述定义了复合AI系统（CAIS）的概念，提出了基于组件角色和编排策略的多维分类法，分析了四种基础范式（RAG、LLM代理、多模态LLM和以编排为中心的架构），回顾了代表性系统，比较了设计权衡，并总结了评估方法。最后，识别了关键挑战并概述了未来的研究方向。", "result": "综述定义了CAIS概念，提出了多维分类法，分析了RAG、LLM代理、多模态LLM和编排中心架构四种基础范式，回顾了代表性系统并比较了设计权衡，总结了评估方法。同时，识别了可扩展性、互操作性、基准测试和协调等关键挑战，并指出了未来研究方向。", "conclusion": "本综述旨在为研究人员和实践者提供理解、开发和推进下一代系统级人工智能的全面基础。", "translation": "复合人工智能系统（CAIS）是一种新兴范式，它将大型语言模型（LLM）与外部组件（如检索器、代理、工具和编排器）集成，以克服独立模型在需要记忆、推理、实时基础和多模态理解的任务中的局限性。这些系统通过将多个专业模块组合成内聚的工作流，从而实现更强大和上下文感知的行为。尽管在学术界和工业界日益普及，CAIS领域仍然分散，缺乏统一的分析、分类和评估框架。在本综述中，我们定义了CAIS的概念，提出了基于组件角色和编排策略的多维分类法，并分析了四种基础范式：检索增强生成（RAG）、LLM代理、多模态LLM（MLLMs）和以编排为中心的架构。我们回顾了代表性系统，比较了设计权衡，并总结了这些范式中的评估方法。最后，我们识别了关键挑战——包括可扩展性、互操作性、基准测试和协调——并概述了未来研究的有前景方向。本综述旨在为研究人员和实践者提供理解、开发和推进下一代系统级人工智能的全面基础。", "summary": "本文对复合人工智能系统（CAIS）进行了全面综述，该系统通过整合大型语言模型（LLM）与外部组件来克服独立LLM的局限性。综述定义了CAIS概念，提出了多维分类法，并分析了检索增强生成（RAG）、LLM代理、多模态LLM和以编排为中心的架构这四种基础范式。此外，还回顾了代表性系统，比较了设计权衡，总结了评估方法，并识别了关键挑战和未来研究方向，旨在为理解和推进系统级AI提供基础。", "keywords": "复合AI系统, 大型语言模型, 检索增强生成, LLM代理, 多模态LLM"}}
{"id": "2506.04701", "pdf": "https://arxiv.org/pdf/2506.04701", "abs": "https://arxiv.org/abs/2506.04701", "authors": ["Meiru Jiang", "Wei Su", "Guojian Ren", "Yongguang Yu"], "title": "Memory-Driven Bounded Confidence Opinion Dynamics: A Hegselmann-Krause Model Based on Fractional-Order Methods", "categories": ["physics.soc-ph", "cs.MA", "cs.SI", "nlin.AO"], "comment": null, "summary": "Memory effects play a crucial role in social interactions and decision-making\nprocesses. This paper proposes a novel fractional-order bounded confidence\nopinion dynamics model to characterize the memory effects in system states.\nBuilding upon the Hegselmann-Krause framework and fractional-order difference,\na comprehensive model is established that captures the persistent influence of\nhistorical information. Through rigorous theoretical analysis, the fundamental\nproperties including convergence and consensus is investigated. The results\ndemonstrate that the proposed model not only maintains favorable convergence\nand consensus characteristics compared to classical opinion dynamics, but also\naddresses limitations such as the monotonicity of bounded opinions. This\nenables a more realistic representation of opinion evolution in real-world\nscenarios. The findings of this study provide new insights and methodological\napproaches for understanding opinion formation and evolution, offering both\ntheoretical significance and practical applications.", "AI": {"title_translation": "记忆驱动的有限置信度观点动力学：一种基于分数阶方法的Hegselmann-Krause模型", "tldr": "本文提出了一种基于分数阶Hegselmann-Krause框架的有限置信度观点动力学模型，以捕捉记忆效应，并证明其在收敛性、共识性及解决观点单调性方面的优势，从而更真实地模拟观点演化。", "motivation": "记忆效应在社会互动和决策过程中起着关键作用，而现有模型可能无法充分捕捉其影响，并且存在观点单调性等局限性。因此，需要一个能够表征系统状态中记忆效应的新模型。", "method": "本文提出了一种新颖的分数阶有限置信度观点动力学模型。该模型建立在Hegselmann-Krause框架和分数阶差分的基础上，旨在捕捉历史信息的持续影响。", "result": "所提出的模型不仅保持了与经典观点动力学模型相比有利的收敛和共识特性，而且解决了有限观点单调性等局限性。这使得对现实世界中观点演化能够进行更真实的表示。", "conclusion": "本研究的发现为理解观点形成和演化提供了新的见解和方法论，具有重要的理论意义和实际应用价值。", "translation": "记忆效应在社会互动和决策过程中起着至关重要的作用。本文提出了一种新颖的分数阶有限置信度观点动力学模型，以表征系统状态中的记忆效应。该模型建立在Hegselmann-Krause框架和分数阶差分的基础上，建立了一个捕捉历史信息持续影响的综合模型。通过严格的理论分析，研究了包括收敛性和共识在内的基本性质。结果表明，所提出的模型与经典的观点动力学相比，不仅保持了良好的收敛和共识特性，而且解决了有限观点单调性等局限性。这使得对现实世界中观点演化能够进行更真实的表示。本研究的发现为理解观点形成和演化提供了新的见解和方法论，具有理论意义和实际应用价值。", "summary": "本文提出了一种新颖的分数阶有限置信度观点动力学模型，该模型结合了Hegselmann-Krause框架和分数阶差分，以刻画系统状态中的记忆效应。通过理论分析，该模型在收敛性和共识性方面表现良好，并能解决传统模型中有限观点单调性等局限性，从而更真实地模拟现实世界中的观点演化过程。这项研究为观点形成和演化提供了新的见解和方法论。", "keywords": "记忆效应, 分数阶, 有限置信度, 观点动力学, Hegselmann-Krause模型"}}
{"id": "2506.04639", "pdf": "https://arxiv.org/pdf/2506.04639", "abs": "https://arxiv.org/abs/2506.04639", "authors": ["Xiaoyu Guo", "Shinobu Saito", "Jianjun Zhao"], "title": "QuanUML: Towards A Modeling Language for Model-Driven Quantum Software Development", "categories": ["cs.SE"], "comment": "A short version of the paper will be appeared in the proceedings of\n  the IEEE Computers, Software, and Applications Conference (COMPSAC 2025) on\n  July 8-11, 2025", "summary": "This paper introduces QuanUML, an extension of the Unified Modeling Language\n(UML) tailored for quantum software systems. QuanUML integrates\nquantum-specific constructs, such as qubits and quantum gates, into the UML\nframework, enabling the modeling of both quantum and hybrid quantum-classical\nsystems. We apply QuanUML to Efficient Long-Range Entanglement using Dynamic\nCircuits and Shor's Algorithm, demonstrating its utility in designing and\nvisualizing quantum algorithms. Our approach supports model-driven development\nof quantum software and offers a structured framework for quantum software\ndesign. We also highlight its advantages over existing methods and discuss\nfuture improvements.", "AI": {"title_translation": "量子统一建模语言：迈向量子软件模型驱动开发的一种建模语言", "tldr": "QuanUML是一种扩展UML的量子软件建模语言，支持量子和混合系统设计。", "motivation": "现有UML不足以建模量子软件系统，需要一种新的建模语言来支持量子软件的模型驱动开发。", "method": "本文引入QuanUML，它是统一建模语言（UML）的扩展，专门为量子软件系统定制。QuanUML将量子特有构造（如量子比特和量子门）集成到UML框架中，从而能够对量子和混合量子-经典系统进行建模。", "result": "QuanUML成功应用于高效长距离纠缠和Shor算法，展示了其在设计和可视化量子算法方面的实用性。该方法支持量子软件的模型驱动开发，并为量子软件设计提供了结构化框架。", "conclusion": "QuanUML为量子软件设计提供了一个结构化框架，并具有优于现有方法的优势，有助于推动量子软件的模型驱动开发。", "translation": "本文介绍了QuanUML，它是统一建模语言 (UML) 的扩展，专为量子软件系统量身定制。QuanUML 将量子特定构造（例如量子比特和量子门）集成到 UML 框架中，从而能够对量子和混合量子-经典系统进行建模。我们将 QuanUML 应用于使用动态电路的高效长程纠缠和 Shor 算法，展示了其在设计和可视化量子算法方面的实用性。我们的方法支持量子软件的模型驱动开发，并为量子软件设计提供了一个结构化框架。我们还强调了其相对于现有方法的优势并讨论了未来的改进。", "summary": "本文介绍了QuanUML，一种扩展UML的量子软件建模语言，旨在支持量子和混合量子-经典系统的模型驱动开发。QuanUML通过集成量子特有构造，成功应用于量子算法设计和可视化，并为量子软件设计提供了结构化框架，展示了其在量子软件开发中的优势。", "keywords": "量子软件, 建模语言, UML, 模型驱动开发, 量子算法"}}
{"id": "2506.04860", "pdf": "https://arxiv.org/pdf/2506.04860", "abs": "https://arxiv.org/abs/2506.04860", "authors": ["Marcos Lima Romero", "Ricardo Suyama"], "title": "Towards Network Data Analytics in 5G Systems and Beyond", "categories": ["cs.NI", "cs.AI"], "comment": "Submitted to XLIII BRAZILIAN SYMPOSIUM ON TELECOMMUNICATIONS AND\n  SIGNAL PROCESSING - SBrT 2025", "summary": "Data has become a critical asset in the digital economy, yet it remains\nunderutilized by Mobile Network Operators (MNOs), unlike Over-the-Top (OTT)\nplayers that lead global market valuations. To move beyond the commoditization\nof connectivity and deliver greater value to customers, data analytics emerges\nas a strategic enabler. Using data efficiently is essential for unlocking new\nservice opportunities, optimizing operational efficiency, and mitigating\noperational and business risks. Since Release 15, the 3rd Generation\nPartnership Project (3GPP) has introduced the Network Data Analytics Function\n(NWDAF) to provide powerful insights and predictions using data collected\nacross mobile networks, supporting both user-centric and network-oriented use\ncases. However, academic research has largely focused on a limited set of\nmethods and use cases, driven by the availability of datasets, restricting\nbroader exploration. This study analyzes trends and gaps in more than 70\narticles and proposes two novel use cases to promote the adoption of NWDAF and\nexplore its potential for monetization.", "AI": {"title_translation": "迈向5G系统及未来网络数据分析", "tldr": "本文分析了5G及未来系统中网络数据分析的趋势与不足，并提出了新的用例以促进NWDAF的应用和货币化潜力。", "motivation": "移动网络运营商（MNOs）未充分利用数据资产，与OTT玩家形成对比，数据分析是MNOs超越连接商品化、提供更大价值的关键。3GPP引入NWDAF以提供洞察和预测，但学术研究受限于数据集，未能充分探索。", "method": "分析了70多篇文章的趋势和不足，并提出了两个新的用例。", "result": "分析了70多篇文章的趋势和不足，并提出了两个新的用例，旨在促进NWDAF的采用并探索其货币化潜力。", "conclusion": "网络数据分析对于MNOs至关重要，NWDAF具有巨大潜力，但需要更广泛的研究和用例探索以实现其全部价值和货币化。", "translation": "数据已成为数字经济中的关键资产，但移动网络运营商（MNOs）对其利用不足，这与引领全球市场估值的OTT（Over-the-Top）玩家形成对比。为了超越连接商品化并向客户提供更大价值，数据分析成为一项战略性推动因素。高效利用数据对于开启新的服务机会、优化运营效率以及降低运营和业务风险至关重要。自Release 15以来，第三代合作伙伴计划（3GPP）引入了网络数据分析功能（NWDAF），旨在利用从移动网络收集的数据提供强大的洞察和预测，支持以用户为中心和以网络为导向的用例。然而，学术研究主要集中在有限的方法和用例上，这受限于数据集的可用性，从而限制了更广泛的探索。本研究分析了70多篇文章中的趋势和不足，并提出了两个新颖的用例，以促进NWDAF的采用并探索其货币化潜力。", "summary": "本研究旨在解决移动网络运营商（MNOs）在利用数据资产方面的不足，这与领先的OTT玩家形成对比。为使MNOs超越连接的商品化并提供更高价值，数据分析被视为战略性推动因素。文章指出，尽管3GPP自Release 15起引入了网络数据分析功能（NWDAF）以提供洞察和预测，但学术研究在此领域的方法和用例上存在局限性。为此，本研究分析了70多篇相关文章的趋势和不足，并提出了两个新颖的用例，旨在推动NWDAF的采纳及其货币化潜力的探索。", "keywords": "网络数据分析, 5G, NWDAF, 移动网络运营商, 数据货币化"}}
{"id": "2506.04287", "pdf": "https://arxiv.org/pdf/2506.04287", "abs": "https://arxiv.org/abs/2506.04287", "authors": ["Yongjin Yang", "Sinjae Kang", "Juyong Lee", "Dongjun Lee", "Se-Young Yun", "Kimin Lee"], "title": "Automated Skill Discovery for Language Agents through Exploration and Iterative Feedback", "categories": ["cs.AI", "cs.LG"], "comment": "Preprint, under review", "summary": "Training large language model (LLM) agents to acquire necessary skills and\nperform diverse tasks within an environment is gaining interest as a means to\nenable open-endedness. However, creating the training dataset for their skill\nacquisition faces several challenges. Manual trajectory collection requires\nsignificant human effort. Another approach, where LLMs directly propose tasks\nto learn, is often invalid, as the LLMs lack knowledge of which tasks are\nactually feasible. Moreover, the generated data may not provide a meaningful\nlearning signal, as agents often already perform well on the proposed tasks. To\naddress this, we propose a novel automatic skill discovery framework EXIF for\nLLM-powered agents, designed to improve the feasibility of generated target\nbehaviors while accounting for the agents' capabilities. Our method adopts an\nexploration-first strategy by employing an exploration agent (Alice) to train\nthe target agent (Bob) to learn essential skills in the environment.\nSpecifically, Alice first interacts with the environment to retrospectively\ngenerate a feasible, environment-grounded skill dataset, which is then used to\ntrain Bob. Crucially, we incorporate an iterative feedback loop, where Alice\nevaluates Bob's performance to identify areas for improvement. This feedback\nthen guides Alice's next round of exploration, forming a closed-loop data\ngeneration process. Experiments on Webshop and Crafter demonstrate EXIF's\nability to effectively discover meaningful skills and iteratively expand the\ncapabilities of the trained agent without any human intervention, achieving\nsubstantial performance improvements. Interestingly, we observe that setting\nAlice to the same model as Bob also notably improves performance, demonstrating\nEXIF's potential for building a self-evolving system.", "AI": {"title_translation": "通过探索和迭代反馈为语言智能体自动发现技能", "tldr": "提出EXIF框架，通过探索和迭代反馈，自动为大型语言模型（LLM）智能体发现技能，有效提升其在Webshop和Crafter等环境中的性能，实现无需人工干预的自演化系统。", "motivation": "训练大型语言模型（LLM）智能体获取技能和执行任务面临挑战：手动收集训练数据耗时耗力；LLM直接提出的学习任务常不可行，因其缺乏对任务可行性的了解；生成的任务数据可能无效，因为智能体可能已表现良好。", "method": "提出EXIF框架，采用“探索优先”策略。探索智能体（Alice）通过与环境交互，回顾性地生成可行的、基于环境的技能数据集，用于训练目标智能体（Bob）。框架包含一个迭代反馈循环，Alice评估Bob的性能以识别改进区域，该反馈指导Alice的下一轮探索，形成闭环数据生成过程。", "result": "EXIF在Webshop和Crafter上有效发现了有意义的技能，并迭代扩展了训练智能体的能力，无需任何人工干预，实现了显著的性能提升。观察到将Alice和Bob设置为相同模型也能显著提高性能，表明EXIF具有构建自演化系统的潜力。", "conclusion": "EXIF框架通过结合探索和迭代反馈，成功解决了LLM智能体技能获取中的数据生成挑战，实现了无需人工干预的技能发现和能力扩展，并展现了构建自演化系统的潜力。", "translation": "训练大型语言模型（LLM）智能体以获取必要技能并在环境中执行多样化任务，作为实现开放性的手段正受到越来越多的关注。然而，为其技能获取创建训练数据集面临多项挑战。手动轨迹收集需要大量人力。另一种方法，即LLM直接提出要学习的任务，通常是无效的，因为LLM缺乏对哪些任务实际可行的了解。此外，生成的数据可能无法提供有意义的学习信号，因为智能体在提出的任务上往往已经表现良好。为了解决这个问题，我们提出了一种新颖的、用于LLM驱动智能体的自动技能发现框架EXIF，旨在提高生成目标行为的可行性，同时考虑到智能体的能力。我们的方法采用“探索优先”策略，通过一个探索智能体（Alice）来训练目标智能体（Bob）学习环境中的基本技能。具体来说，Alice首先与环境交互，回顾性地生成一个可行的、基于环境的技能数据集，然后用它来训练Bob。至关重要的是，我们引入了一个迭代反馈循环，Alice评估Bob的性能以识别需要改进的领域。然后，这种反馈指导Alice的下一轮探索，形成一个闭环数据生成过程。在Webshop和Crafter上的实验表明，EXIF能够有效地发现有意义的技能，并在无需任何人工干预的情况下迭代扩展训练智能体的能力，实现了显著的性能提升。有趣的是，我们观察到将Alice设置为与Bob相同的模型也能显著提高性能，这表明EXIF具有构建自演化系统的潜力。", "summary": "本研究提出了一种名为EXIF的自动技能发现框架，旨在解决大型语言模型（LLM）智能体在开放式环境中获取技能时面临的数据集创建挑战。针对现有方法中手动数据收集耗时和LLM生成任务不可行的问题，EXIF采用探索优先策略，通过一个探索智能体（Alice）与环境交互，生成可行的技能数据集来训练目标智能体（Bob）。关键在于其引入的迭代反馈循环，Alice根据Bob的表现提供反馈，指导后续探索，形成闭环数据生成过程。实验证明，EXIF无需人工干预即可有效发现有意义的技能，并显著提升智能体在Webshop和Crafter等任务上的性能，甚至通过将Alice和Bob设为相同模型，展现了构建自演化系统的潜力。", "keywords": "技能发现, 语言智能体, 探索, 迭代反馈, 大型语言模型"}}
{"id": "2506.04363", "pdf": "https://arxiv.org/pdf/2506.04363", "abs": "https://arxiv.org/abs/2506.04363", "authors": ["Delong Chen", "Willy Chung", "Yejin Bang", "Ziwei Ji", "Pascale Fung"], "title": "WorldPrediction: A Benchmark for High-level World Modeling and Long-horizon Procedural Planning", "categories": ["cs.CV"], "comment": null, "summary": "Humans are known to have an internal \"world model\" that enables us to carry\nout action planning based on world states. AI agents need to have such a world\nmodel for action planning as well. It is not clear how current AI models,\nespecially generative models, are able to learn such world models and carry out\nprocedural planning in diverse environments. We introduce WorldPrediction, a\nvideo-based benchmark for evaluating world modeling and procedural planning\ncapabilities of different AI models. In contrast to prior benchmarks that focus\nprimarily on low-level world modeling and robotic motion planning,\nWorldPrediction is the first benchmark that emphasizes actions with temporal\nand semantic abstraction. Given initial and final world states, the task is to\ndistinguish the proper action (WorldPrediction-WM) or the properly ordered\nsequence of actions (WorldPrediction-PP) from a set of counterfactual\ndistractors. This discriminative task setup enable us to evaluate different\ntypes of world models and planners and realize a thorough comparison across\ndifferent hypothesis. The benchmark represents states and actions using visual\nobservations. In order to prevent models from exploiting low-level continuity\ncues in background scenes, we provide \"action equivalents\" - identical actions\nobserved in different contexts - as candidates for selection. This benchmark is\ngrounded in a formal framework of partially observable semi-MDP, ensuring\nbetter reliability and robustness of the evaluation. We conduct extensive human\nfiltering and validation on our benchmark and show that current frontier models\nbarely achieve 57% accuracy on WorldPrediction-WM and 38% on WorldPrediction-PP\nwhereas humans are able to solve both tasks perfectly.", "AI": {"title_translation": "WorldPrediction：一个用于高级世界建模和长程程序规划的基准", "tldr": "WorldPrediction是一个新的视频基准，用于评估AI模型的高级世界建模和长程程序规划能力，结果显示当前最先进的模型远低于人类水平。", "motivation": "人类拥有内部“世界模型”以进行基于世界状态的行动规划，AI智能体也需要这样的世界模型。目前尚不清楚当前的AI模型，尤其是生成模型，如何学习此类世界模型并进行多样化环境中的程序规划。", "method": "本文引入了WorldPrediction，一个视频基准，用于评估不同AI模型的世界建模和程序规划能力。与侧重低级世界建模和机器人运动规划的现有基准不同，WorldPrediction首次强调具有时间性和语义抽象的动作。任务是区分正确的动作（WorldPrediction-WM）或正确排序的动作序列（WorldPrediction-PP），对抗反事实干扰项。通过提供在不同背景下观察到的“等效动作”，防止模型利用低级连续性线索。该基准基于部分可观察的半MDP形式框架。", "result": "在WorldPrediction-WM上，当前前沿模型仅达到57%的准确率，在WorldPrediction-PP上仅达到38%的准确率，而人类能够完美解决这两项任务。", "conclusion": "当前AI模型在高级世界建模和长程程序规划方面的能力远低于人类水平，需要进一步研究和发展。", "translation": "人类已知拥有内部“世界模型”，使我们能够根据世界状态进行行动规划。AI智能体也需要这样的世界模型来进行行动规划。目前尚不清楚当前的AI模型，尤其是生成模型，如何学习此类世界模型并进行多样化环境中的程序规划。我们引入了WorldPrediction，一个基于视频的基准，用于评估不同AI模型的世界建模和程序规划能力。与主要关注低级世界建模和机器人运动规划的现有基准不同，WorldPrediction是第一个强调具有时间性和语义抽象动作的基准。给定初始和最终世界状态，任务是从一组反事实干扰项中区分出正确的动作（WorldPrediction-WM）或正确排序的动作序列（WorldPrediction-PP）。这种判别性任务设置使我们能够评估不同类型的世界模型和规划器，并实现对不同假设的彻底比较。该基准使用视觉观察来表示状态和动作。为了防止模型利用背景场景中的低级连续性线索，我们提供了“等效动作”——在不同上下文中观察到的相同动作——作为选择的候选。该基准基于部分可观察的半MDP的正式框架，确保评估的更高可靠性和鲁棒性。我们对基准进行了广泛的人工过滤和验证，结果表明当前前沿模型在WorldPrediction-WM上仅达到57%的准确率，在WorldPrediction-PP上仅达到38%的准确率，而人类能够完美解决这两项任务。", "summary": "本文介绍了WorldPrediction，这是一个新颖的视频基准，旨在评估AI智能体在高层次世界建模和长程程序规划方面的能力。该基准要求模型从反事实选项中识别正确的动作或动作序列，并特别关注具有时间性和语义抽象的动作。实验结果表明，尽管人类可以完美解决这些任务，但当前最先进的AI模型在WorldPrediction-WM和WorldPrediction-PP任务上的表现远低于人类水平，凸显了AI在复杂规划能力方面的差距。", "keywords": "世界模型, 程序规划, 基准, AI智能体, 视频基准"}}
{"id": "2506.05071", "pdf": "https://arxiv.org/pdf/2506.05071", "abs": "https://arxiv.org/abs/2506.05071", "authors": ["Shahram Ghandeharizadeh", "Sandy Irani", "Jenny Lam"], "title": "Memory Hierarchy Design for Caching Middleware in the Age of NVM", "categories": ["cs.DB", "cs.AR", "cs.DS"], "comment": "A shorter version appeared in the IEEE 34th International Conference\n  on Data Engineering (ICDE), Paris, France, 2018, pp. 1380-1383, doi:\n  10.1109/ICDE.2018.00155", "summary": "Advances in storage technology have introduced Non-Volatile Memory, NVM, as a\nnew storage medium. NVM, along with Dynamic Random Access Memory (DRAM), Solid\nState Disk (SSD), and Disk present a system designer with a wide array of\noptions in designing caching middleware. Moreover, design decisions to\nreplicate a data item in more than one level of a caching memory hierarchy may\nenhance the overall system performance with a faster recovery time in the event\nof a memory failure. Given a fixed budget, the key configuration questions are:\nWhich storage media should constitute the memory hierarchy? What is the storage\ncapacity of each hierarchy? Should data be replicated or partitioned across the\ndifferent levels of the hierarchy? We model these cache configuration questions\nas an instance of the Multiple Choice Knapsack Problem (MCKP). This model is\nguided by the specification of each type of memory along with an application's\ndatabase characteristics and its workload. Although MCKP is NP-complete, its\nlinear programming relaxation is efficiently solvable and can be used to\nclosely approximate the optimal solution. We use the resulting simple algorithm\nto evaluate design tradeoffs in the context of a memory hierarchy for a\nKey-Value Store (e.g., memcached) as well as a host-side cache (e.g.,\nFlashcache). The results show selective replication is appropriate with certain\nfailure rates and workload characteristics. With a slim failure rate and\nfrequent data updates, tiering of data across the different storage media that\nconstitute the cache is superior to replication.", "AI": {"title_translation": "NVM时代缓存中间件的内存层次结构设计", "tldr": "本文将缓存中间件的内存层次结构设计问题建模为多重选择背包问题（MCKP），并利用其线性规划松弛来近似最优解。研究发现，在特定故障率和工作负载特征下，选择性复制是合适的；而在低故障率和频繁数据更新的情况下，数据分层优于复制。", "motivation": "随着存储技术的发展，非易失性存储器（NVM）作为一种新的存储介质出现。NVM与DRAM、SSD和磁盘共同为系统设计者在设计缓存中间件时提供了多种选择。在固定预算下，如何选择存储介质、确定每个层次的存储容量以及数据是复制还是分区，是提高系统性能和加快故障恢复的关键配置问题。", "method": "将缓存配置问题建模为多重选择背包问题（MCKP）。虽然MCKP是NP完全的，但其线性规划松弛可以有效求解并近似最优解。利用由此产生的简单算法来评估键值存储（如memcached）和主机端缓存（如Flashcache）内存层次结构中的设计权衡。", "result": "研究结果表明，在某些故障率和工作负载特性下，选择性复制是合适的。在故障率较低且数据更新频繁的情况下，跨不同存储介质的数据分层优于复制。", "conclusion": "在NVM时代设计缓存中间件时，应根据具体的故障率和工作负载特性来选择数据复制或数据分层策略，以优化系统性能和恢复时间。", "translation": "存储技术的进步引入了非易失性存储器（NVM）作为一种新的存储介质。NVM与动态随机存取存储器（DRAM）、固态硬盘（SSD）和磁盘一起，为系统设计者在设计缓存中间件时提供了广泛的选择。此外，在缓存内存层次结构的多个级别中复制数据项的设计决策，可以在发生内存故障时通过更快的恢复时间来增强整体系统性能。在给定固定预算的情况下，关键的配置问题是：哪些存储介质应该构成内存层次结构？每个层次的存储容量是多少？数据应该在层次结构的不同级别之间复制还是分区？我们将这些缓存配置问题建模为多重选择背包问题（MCKP）的一个实例。该模型以每种内存类型的规范以及应用程序的数据库特性和其工作负载为指导。尽管MCKP是NP完全的，但其线性规划松弛可以有效求解，并可以用来密切近似最优解。我们使用由此产生的简单算法来评估键值存储（例如memcached）以及主机端缓存（例如Flashcache）内存层次结构中的设计权衡。结果表明，在某些故障率和工作负载特性下，选择性复制是合适的。在故障率较低且数据更新频繁的情况下，跨构成缓存的不同存储介质的数据分层优于复制。", "summary": "本文研究了在非易失性存储器（NVM）时代，缓存中间件的内存层次结构设计问题。面对多种存储介质（NVM、DRAM、SSD、磁盘）和固定预算的限制，论文将内存层次结构的选择、容量分配和数据复制/分区问题建模为多重选择背包问题（MCKP）。通过求解MCKP的线性规划松弛来近似最优解，并应用该算法评估了键值存储和主机端缓存的设计权衡。研究发现，在特定故障率和工作负载特征下，选择性数据复制是有效的；而在低故障率和频繁数据更新时，数据分层策略优于复制。", "keywords": "内存层次结构, 缓存中间件, 非易失性存储器, 多重选择背包问题, 数据复制, 数据分层"}}
{"id": "2506.04947", "pdf": "https://arxiv.org/pdf/2506.04947", "abs": "https://arxiv.org/abs/2506.04947", "authors": ["Symeon Vaidanis", "Photios A. Stavrou", "Marios Kountouris"], "title": "Goal-Oriented Semantic Resource Allocation with Cumulative Prospect Theoretic Agents", "categories": ["cs.IT", "cs.NI", "eess.SP", "math.IT"], "comment": "This work has been accepted for publication in IEEE ICC 2025. The\n  final published version will be available via IEEE Xplore", "summary": "We introduce a resource allocation framework for goal-oriented semantic\nnetworks, where participating agents assess system quality through subjective\n(e.g., context-dependent) perceptions. To accommodate this, our model accounts\nfor agents whose preferences deviate from traditional expected utility theory\n(EUT), specifically incorporating cumulative prospect theory (CPT) preferences.\nWe develop a comprehensive analytical framework that captures human-centric\naspects of decision-making and risky choices under uncertainty, such as risk\nperception, loss aversion, and perceptual distortions in probability metrics.\nBy identifying essential modifications in traditional resource allocation\ndesign principles required for agents with CPT preferences, we showcase the\nframework's relevance through its application to the problem of power\nallocation in multi-channel wireless communication systems.", "AI": {"title_translation": "以累积前景理论智能体为导向的语义资源分配", "tldr": "该研究引入了一个新的资源分配框架，考虑了具有累积前景理论偏好的智能体，以更好地捕捉人类决策特性。", "motivation": "传统资源分配框架未能充分考虑智能体主观感知和偏离预期效用理论（EUT）的决策行为，尤其是在不确定性下的风险选择。", "method": "引入了一个面向目标的语义资源分配框架，该框架整合了累积前景理论（CPT）偏好，以捕捉人类决策中的风险感知、损失规避和概率感知扭曲等特征。", "result": "该框架识别了传统资源分配设计原则中针对CPT偏好智能体所需的修改，并通过将其应用于多信道无线通信系统中的功率分配问题，展示了其相关性。", "conclusion": "该研究表明，将累积前景理论（CPT）引入资源分配框架，能够更好地捕捉人类决策的复杂性，并为面向目标的语义网络中的资源分配提供了更实际有效的设计原则。", "translation": "我们引入了一个面向目标的语义网络资源分配框架，其中参与的智能体通过主观（例如，依赖于上下文）感知来评估系统质量。为了适应这一点，我们的模型考虑了其偏好偏离传统预期效用理论（EUT）的智能体，特别是整合了累积前景理论（CPT）偏好。我们开发了一个全面的分析框架，捕捉了不确定性下决策和风险选择中以人为中心的方面，例如风险感知、损失规避以及概率度量中的感知扭曲。通过识别针对具有CPT偏好智能体所需的传统资源分配设计原则中的基本修改，我们通过将其应用于多信道无线通信系统中的功率分配问题，展示了该框架的相关性。", "summary": "本文提出了一个面向目标的语义资源分配框架，旨在解决传统模型无法处理智能体主观感知和偏离预期效用理论的决策行为。该框架整合了累积前景理论（CPT），以捕捉人类决策中的风险感知、损失规避和概率扭曲等特征。通过识别传统资源分配设计原则的必要修改，该研究将此框架应用于多信道无线通信系统中的功率分配问题，展示了其相关性。", "keywords": "资源分配, 累积前景理论, 语义网络, 以人为中心的决策, 无线通信"}}
{"id": "2506.04268", "pdf": "https://arxiv.org/pdf/2506.04268", "abs": "https://arxiv.org/abs/2506.04268", "authors": ["Jingyang Li", "Guoqiang Li"], "title": "MUC-G4: Minimal Unsat Core-Guided Incremental Verification for Deep Neural Network Compression", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rapid development of deep learning has led to challenges in deploying\nneural networks on edge devices, mainly due to their high memory and runtime\ncomplexity. Network compression techniques, such as quantization and pruning,\naim to reduce this complexity while maintaining accuracy. However, existing\nincremental verification methods often focus only on quantization and struggle\nwith structural changes. This paper presents MUC-G4 (Minimal Unsat Core-Guided\nIncremental Verification), a novel framework for incremental verification of\ncompressed deep neural networks. It encodes both the original and compressed\nnetworks into SMT formulas, classifies changes, and use \\emph{Minimal Unsat\nCores (MUCs)} from the original network to guide efficient verification for the\ncompressed network. Experimental results show its effectiveness in handling\nquantization and pruning, with high proof reuse rates and significant speedup\nin verification time compared to traditional methods. MUC-G4 hence offers a\npromising solution for ensuring the safety and reliability of compressed neural\nnetworks in practical applications.", "AI": {"title_translation": "MUC-G4：最小不可满足核心引导的深度神经网络压缩增量验证", "tldr": "MUC-G4是一种新的增量验证框架，通过使用最小不可满足核心来高效验证压缩的深度神经网络，解决了现有方法在处理结构变化方面的不足。", "motivation": "深度学习的快速发展使得在边缘设备上部署神经网络面临挑战，主要是由于其高内存和运行时复杂性。现有的增量验证方法通常只关注量化，难以处理结构性变化。", "method": "本文提出了MUC-G4（最小不可满足核心引导的增量验证）框架。它将原始网络和压缩网络编码为SMT公式，对变化进行分类，并使用来自原始网络的最小不可满足核心（MUCs）来指导压缩网络的有效验证。", "result": "实验结果表明，MUC-G4在处理量化和剪枝方面表现出有效性，具有高证明重用率，并且与传统方法相比，验证时间显著加快。", "conclusion": "MUC-G4为确保压缩神经网络在实际应用中的安全性和可靠性提供了一个有前景的解决方案。", "translation": "深度学习的快速发展给神经网络在边缘设备上的部署带来了挑战，主要是由于其高内存和运行时复杂性。量化和剪枝等网络压缩技术旨在降低这种复杂性，同时保持准确性。然而，现有的增量验证方法通常只关注量化，并且难以处理结构性变化。本文提出了MUC-G4（最小不可满足核心引导的增量验证），这是一个用于压缩深度神经网络增量验证的新颖框架。它将原始网络和压缩网络编码为SMT公式，对变化进行分类，并使用来自原始网络的最小不可满足核心（MUCs）来指导压缩网络的有效验证。实验结果表明，MUC-G4在处理量化和剪枝方面表现出有效性，具有高证明重用率，并且与传统方法相比，验证时间显著加快。因此，MUC-G4为确保压缩神经网络在实际应用中的安全性和可靠性提供了一个有前景的解决方案。", "summary": "MUC-G4是一个新颖的增量验证框架，旨在解决深度神经网络在边缘设备部署中的复杂性问题。它通过将原始和压缩网络编码为SMT公式，并利用原始网络的最小不可满足核心来高效指导压缩网络的验证，有效处理了量化和剪枝带来的结构性变化。实验证明MUC-G4在验证速度和证明重用方面均优于传统方法，为压缩神经网络的安全可靠性提供了保障。", "keywords": "深度神经网络压缩, 增量验证, 最小不可满足核心, SMT公式, 网络安全"}}
{"id": "2506.04836", "pdf": "https://arxiv.org/pdf/2506.04836", "abs": "https://arxiv.org/abs/2506.04836", "authors": ["Chris Schmitz", "Jonathan Rystrøm", "Jan Batzner"], "title": "Oversight Structures for Agentic AI in Public-Sector Organizations", "categories": ["cs.CY", "cs.AI"], "comment": "To appear at REALM@ACL2025", "summary": "This paper finds that the introduction of agentic AI systems intensifies\nexisting challenges to traditional public sector oversight mechanisms -- which\nrely on siloed compliance units and episodic approvals rather than continuous,\nintegrated supervision. We identify five governance dimensions essential for\nresponsible agent deployment: cross-departmental implementation, comprehensive\nevaluation, enhanced security protocols, operational visibility, and systematic\nauditing. We evaluate the capacity of existing oversight structures to meet\nthese challenges, via a mixed-methods approach consisting of a literature\nreview and interviews with civil servants in AI-related roles. We find that\nagent oversight poses intensified versions of three existing governance\nchallenges: continuous oversight, deeper integration of governance and\noperational capabilities, and interdepartmental coordination. We propose\napproaches that both adapt institutional structures and design agent oversight\ncompatible with public sector constraints.", "AI": {"title_translation": "公共部门组织中代理式人工智能的监督结构", "tldr": "代理式AI在公共部门的应用加剧了传统监督挑战，需要跨部门、综合评估、增强安全、操作可见性和系统审计等新方法来应对。", "motivation": "本文旨在探讨代理式人工智能系统引入后，传统公共部门监督机制面临的现有挑战，这些机制依赖于孤立的合规部门和偶发性批准而非持续、综合的监督。", "method": "采用混合方法，包括文献综述和对从事AI相关工作的公务员进行访谈，以评估现有监督结构应对挑战的能力。", "result": "研究发现，代理监督加剧了三个现有治理挑战的强度：持续监督、治理与操作能力的深度整合以及部门间协调。同时，识别了负责任代理部署的五个关键治理维度：跨部门实施、综合评估、增强安全协议、操作可见性和系统审计。", "conclusion": "提出了既能适应机构结构又能设计与公共部门限制兼容的代理监督方法。", "translation": "本文发现，代理式人工智能系统的引入加剧了传统公共部门监督机制面临的现有挑战——这些机制依赖于孤立的合规部门和偶发性批准，而非持续、综合的监督。我们确定了负责任代理部署所需的五个关键治理维度：跨部门实施、综合评估、增强安全协议、操作可见性和系统审计。我们通过混合方法（包括文献综述和对从事人工智能相关工作的公务员进行访谈）评估了现有监督结构应对这些挑战的能力。我们发现，代理监督加剧了三个现有治理挑战的强度：持续监督、治理与操作能力的深度整合以及部门间协调。我们提出了既能适应机构结构又能设计与公共部门限制兼容的代理监督方法。", "summary": "本文分析了代理式人工智能系统在公共部门应用中对现有监督机制带来的挑战。研究指出，代理式AI加剧了持续监督、治理与操作整合以及部门间协调等治理难题。作者提出了跨部门实施、综合评估、增强安全协议、操作可见性和系统审计等五个关键治理维度，并建议采取适应性方法来构建符合公共部门约束的代理监督结构。", "keywords": "代理式人工智能, 公共部门, 监督结构, 治理挑战, 跨部门协调"}}
{"id": "2506.04873", "pdf": "https://arxiv.org/pdf/2506.04873", "abs": "https://arxiv.org/abs/2506.04873", "authors": ["Tonghuan Xiao", "Jiecheng Zhou"], "title": "A distributed system perspective on Backscatter systems: A review", "categories": ["cs.DC"], "comment": "9 pages, 9 figures", "summary": "This review investigates the pivotal role of distributed architectures and\nintelligent resource allocation in enabling robust and scalable wireless\nsystems, with a particular emphasis on backscatter communication, indoor\nlocalization, battery-free networks, and Simultaneous Wireless Information and\nPower Transfer (SWIPT).", "AI": {"title_translation": "分布式系统视角下的反向散射系统：综述", "tldr": "本文综述了分布式架构和智能资源分配在实现鲁棒和可扩展无线系统中的关键作用，特别关注反向散射通信、室内定位、无电池网络和同步无线信息与功率传输（SWIPT）。", "motivation": "实现鲁棒和可扩展的无线系统。", "method": "本文通过综述的形式，研究了分布式架构和智能资源分配在无线系统中的关键作用。", "result": "综述了分布式架构和智能资源分配在反向散射通信、室内定位、无电池网络和同步无线信息与功率传输（SWIPT）等领域的关键作用。", "conclusion": "Not mentioned in abstract", "translation": "本综述调查了分布式架构和智能资源分配在实现鲁棒和可扩展无线系统中的关键作用，特别强调了反向散射通信、室内定位、无电池网络和同步无线信息与功率传输（SWIPT）。", "summary": "这篇综述探讨了分布式架构和智能资源分配在构建强大且可扩展的无线系统中的核心作用，重点关注反向散射通信、室内定位、无电池网络和同步无线信息与功率传输（SWIPT）。", "keywords": "反向散射系统, 分布式系统, 无线通信, 资源分配, SWIPT"}}
{"id": "2506.04853", "pdf": "https://arxiv.org/pdf/2506.04853", "abs": "https://arxiv.org/abs/2506.04853", "authors": ["Andrea Rizzini", "Marco Esposito", "Francesco Bruschi", "Donatella Sciuto"], "title": "A Private Smart Wallet with Probabilistic Compliance", "categories": ["cs.CR", "cs.CE"], "comment": null, "summary": "We propose a privacy-preserving smart wallet with a novel invitation-based\nprivate onboarding mechanism. The solution integrates two levels of compliance\nin concert with an authority party: a proof of innocence mechanism and an\nancestral commitment tracking system using bloom filters for probabilistic UTXO\nchain states. Performance analysis demonstrates practical efficiency: private\ntransfers with compliance checks complete within seconds on a consumer-grade\nlaptop, and overall with proof generation remaining low. On-chain costs stay\nminimal, ensuring affordability for all operations on Base layer 2 network. The\nwallet facilitates private contact list management through encrypted data blobs\nwhile maintaining transaction unlinkability. Our evaluation validates the\napproach's viability for privacy-preserving, compliance-aware digital payments\nwith minimized computational and financial overhead.", "AI": {"title_translation": "具有概率合规性的私人智能钱包", "tldr": "提出了一种具有新颖入职机制和概率合规性的隐私保护智能钱包，展示了实际效率和低成本。", "motivation": "在数字支付中同时实现隐私保护和合规性是研究的动机。", "method": "提出了一种隐私保护智能钱包，采用基于邀请的私人入职机制。它与权威方协同集成了两级合规性：无罪证明机制和使用布隆过滤器进行概率UTXO链状态的祖先承诺跟踪系统。该钱包还通过加密数据块促进私人联系人列表管理，同时保持交易不可链接性。", "result": "性能分析表明，带有合规性检查的私人转账在消费级笔记本电脑上可在数秒内完成，证明生成保持较低，并且在Base Layer 2网络上的链上成本保持最低。", "conclusion": "该方法在隐私保护、合规感知数字支付方面的可行性得到了验证，且计算和财务开销最小化。", "translation": "我们提出了一种隐私保护智能钱包，具有新颖的基于邀请的私人入职机制。该解决方案与权威方协同集成了两级合规性：一种无罪证明机制和一种使用布隆过滤器进行概率UTXO链状态的祖先承诺跟踪系统。性能分析表明了实际效率：带有合规性检查的私人转账在消费级笔记本电脑上可在几秒内完成，并且总体上证明生成保持较低。链上成本保持最低，确保Base layer 2网络上所有操作的可负担性。该钱包通过加密数据块促进私人联系人列表管理，同时保持交易不可链接性。我们的评估验证了该方法在隐私保护、合规感知数字支付方面的可行性，且计算和财务开销最小化。", "summary": "本文介绍了一种具有新颖邀请式私人入职机制的隐私保护智能钱包，并集成了无罪证明机制和基于布隆过滤器的祖先承诺跟踪系统两级合规性。性能评估显示，该方案在消费级设备上能实现秒级完成的私人转账，证明生成开销低，且链上成本极小，验证了其在低计算和财务开销下实现隐私保护和合规感知数字支付的实用性。", "keywords": "隐私保护智能钱包, 概率合规性, 区块链, 数字支付, UTXO"}}
{"id": "2506.05236", "pdf": "https://arxiv.org/pdf/2506.05236", "abs": "https://arxiv.org/abs/2506.05236", "authors": ["Maxime Toquebiau", "Jae-Yun Jun", "Faïz Benamar", "Nicolas Bredeche"], "title": "Towards Language-Augmented Multi-Agent Deep Reinforcement Learning", "categories": ["cs.MA"], "comment": null, "summary": "Communication is a fundamental aspect of coordinated behavior in multi-agent\nreinforcement learning. Yet, most prior works in this field have focused on\nemergent communication protocols developed from scratch, often resulting in\ninefficient or non-interpretable systems. Inspired by the role of language in\nnatural intelligence, we investigate how grounding agents in a human-defined\nlanguage can improve learning and coordination of multiple embodied agents. We\npropose a framework in which agents are trained not only to act but also to\nproduce and interpret natural language descriptions of their observations. This\nlanguage-augmented learning serves a dual role: enabling explicit communication\nbetween agents and guiding representation learning. We demonstrate that agents\ntrained with our method outperform traditional emergent communication baselines\nacross various tasks. Our analysis reveals that language grounding leads to\nmore informative internal representations, better generalization to new\npartners, and improved capability for human-agent interaction. These findings\ndemonstrate the effectiveness of integrating structured language into\nmulti-agent learning and open avenues for more interpretable and capable\nmulti-agent systems.", "AI": {"title_translation": "面向语言增强的多智能体深度强化学习", "tldr": "本研究提出一种将人类语言融入多智能体深度强化学习的框架，通过让智能体生成和解释自然语言来提升学习效率、协调能力、泛化能力和可解释性，优于传统方法。", "motivation": "以往的多智能体强化学习研究多侧重于从零开始的自发通信协议，但这些协议往往效率低下或难以解释。受自然智能中语言作用的启发，本研究旨在探索如何将智能体基于人类定义的语言进行基础化，以改善多智能体学习和协调。", "method": "本研究提出一个框架，其中智能体不仅被训练去行动，还被训练去生成和解释其观察的自然语言描述。这种语言增强学习具有双重作用：实现智能体之间的显式通信和指导表征学习。", "result": "实验证明，使用本方法训练的智能体在各种任务中均优于传统的自发通信基线。分析显示，语言基础化能带来信息更丰富的内部表征、对新伙伴更好的泛化能力以及改进的人机交互能力。", "conclusion": "将结构化语言整合到多智能体学习中是有效的，并为开发更具可解释性和更强大的多智能体系统开辟了道路。", "translation": "多智能体强化学习中，通信是协调行为的一个基本方面。然而，该领域的大多数现有工作都集中在从零开始开发的自发通信协议上，这通常导致效率低下或不可解释的系统。受自然智能中语言作用的启发，我们研究了如何将智能体基于人类定义的语言进行基础化，以改善多个具身智能体的学习和协调。我们提出了一个框架，其中智能体不仅被训练去行动，还被训练去生成和和解释其观察的自然语言描述。这种语言增强学习具有双重作用：实现智能体之间的显式通信和指导表征学习。我们证明，使用我们方法训练的智能体在各种任务中均优于传统的自发通信基线。我们的分析表明，语言基础化能够带来信息更丰富的内部表征、对新伙伴更好的泛化能力以及改进的人机交互能力。这些发现证明了将结构化语言整合到多智能体学习中的有效性，并为开发更具可解释性和更强大的多智能体系统开辟了道路。", "summary": "本研究提出一种语言增强的多智能体深度强化学习框架，旨在解决现有自发通信协议效率低和不可解释的问题。该框架通过训练智能体生成和解释自然语言描述，实现显式通信和指导表征学习。实验结果表明，该方法在性能、泛化能力和人机交互方面均优于传统基线，并能生成更具信息量的内部表征，验证了将结构化语言融入多智能体学习的有效性。", "keywords": "多智能体强化学习, 自然语言, 语言增强, 通信协议, 表征学习"}}
{"id": "2506.04540", "pdf": "https://arxiv.org/pdf/2506.04540", "abs": "https://arxiv.org/abs/2506.04540", "authors": ["Kordel K. France"], "title": "Chronoamperometry with Room-Temperature Ionic Liquids: Sub-Second Inference Techniques", "categories": ["cs.RO", "cs.LG", "physics.chem-ph", "physics.ins-det"], "comment": "Published at IEEE BioSensors 2025", "summary": "Chronoamperometry (CA) is a fundamental electrochemical technique used for\nquantifying redox-active species. However, in room-temperature ionic liquids\n(RTILs), the high viscosity and slow mass transport often lead to extended\nmeasurement durations. This paper presents a novel mathematical regression\napproach that reduces CA measurement windows to under 1 second, significantly\nfaster than previously reported methods, which typically require 1-4 seconds or\nlonger. By applying an inference algorithm to the initial transient current\nresponse, this method accurately predicts steady-state electrochemical\nparameters without requiring additional hardware modifications. The approach is\nvalidated through comparison with standard chronoamperometric techniques and is\ndemonstrated to maintain reasonable accuracy while dramatically reducing data\nacquisition time. The implications of this technique are explored in analytical\nchemistry, sensor technology, and battery science, where rapid electrochemical\nquantification is critical. Our technique is focused on enabling faster\nmultiplexing of chronoamperometric measurements for rapid olfactory and\nelectrochemical analysis.", "AI": {"title_translation": "室温离子液体计时电流法：亚秒级推断技术", "tldr": "本研究提出了一种新的数学回归方法，可将室温离子液体中计时电流法测量时间缩短至1秒以下，显著提高测量速度和效率。", "motivation": "在室温离子液体（RTILs）中，计时电流法（CA）由于高粘度和缓慢的质量传输，通常导致测量时间过长。现有方法通常需要1-4秒或更长时间。", "method": "本文提出了一种新颖的数学回归方法，通过对初始瞬态电流响应应用推断算法，无需额外硬件修改即可准确预测稳态电化学参数。", "result": "该方法将计时电流法测量窗口缩短至1秒以下，显著快于先前报道的方法。经验证，该方法在显著缩短数据采集时间的同时保持了合理的准确性。", "conclusion": "该技术在分析化学、传感器技术和电池科学中具有重要意义，可实现计时电流测量的更快多路复用，从而实现快速嗅觉和电化学分析。", "translation": "计时电流法（CA）是一种用于量化氧化还原活性物质的基本电化学技术。然而，在室温离子液体（RTILs）中，高粘度和缓慢的质量传输通常会导致测量时间延长。本文提出了一种新颖的数学回归方法，可将CA测量窗口缩短至1秒以下，显著快于先前报道的通常需要1-4秒或更长时间的方法。通过对初始瞬态电流响应应用推断算法，该方法无需额外硬件修改即可准确预测稳态电化学参数。该方法通过与标准计时电流技术进行比较得到验证，并被证明在显著缩短数据采集时间的同时保持了合理的准确性。该技术在分析化学、传感器技术和电池科学中具有重要意义，在这些领域，快速电化学量化至关重要。我们的技术专注于实现计时电流测量的更快多路复用，以实现快速嗅觉和电化学分析。", "summary": "本论文介绍了一种创新的数学回归方法，旨在解决室温离子液体中计时电流法测量时间过长的问题。通过对初始电流响应应用推断算法，该方法能将测量时间缩短至1秒以内，同时保持准确性，显著优于现有技术。该技术无需硬件改动，并在分析化学、传感器和电池科学等领域具有广泛应用前景，尤其适用于需要快速电化学量化的场景。", "keywords": "计时电流法, 室温离子液体, 快速测量, 数学回归, 电化学分析"}}
{"id": "2506.04785", "pdf": "https://arxiv.org/pdf/2506.04785", "abs": "https://arxiv.org/abs/2506.04785", "authors": ["Alisa Welter", "Niklas Schneider", "Tobias Dick", "Kallistos Weis", "Christof Tinnes", "Marvin Wyrich", "Sven Apel"], "title": "From Developer Pairs to AI Copilots: A Comparative Study on Knowledge Transfer", "categories": ["cs.SE"], "comment": null, "summary": "Knowledge transfer is fundamental to human collaboration and is therefore\ncommon in software engineering. Pair programming is a prominent instance. With\nthe rise of AI coding assistants, developers now not only work with human\npartners but also, as some claim, with AI pair programmers. Although studies\nconfirm knowledge transfer during human pair programming, its effectiveness\nwith AI coding assistants remains uncertain. To analyze knowledge transfer in\nboth human-human and human-AI settings, we conducted an empirical study where\ndeveloper pairs solved a programming task without AI support, while a separate\ngroup of individual developers completed the same task using the AI coding\nassistant GitHub Copilot. We extended an existing knowledge transfer framework\nand employed a semi-automated evaluation pipeline to assess differences in\nknowledge transfer episodes across both settings. We found a similar frequency\nof successful knowledge transfer episodes and overlapping topical categories\nacross both settings. Two of our key findings are that developers tend to\naccept GitHub Copilot's suggestions with less scrutiny than those from human\npair programming partners, but also that GitHub Copilot can subtly remind\ndevelopers of important code details they might otherwise overlook.", "AI": {"title_translation": "从开发者结对到AI副驾驶：一项关于知识转移的比较研究", "tldr": "比较研究发现，AI副驾驶与人类结对编程在知识转移频率和主题上相似，但开发者对AI的建议审查较少，AI能提醒重要代码细节。", "motivation": "现有研究证实了人类结对编程中的知识转移，但AI编码助手（如GitHub Copilot）在知识转移方面的有效性尚不确定，因此本研究旨在比较人-人与人-AI环境中的知识转移。", "method": "本研究进行了一项实证研究，其中一组开发者结对在没有AI支持下解决编程任务，而另一组单独开发者使用GitHub Copilot完成相同任务。研究扩展了现有知识转移框架，并采用半自动化评估流程来评估两种设置下知识转移事件的差异。", "result": "研究发现，在人-人与人-AI两种设置下，成功知识转移事件的频率相似，且主题类别重叠。关键发现是：开发者倾向于对GitHub Copilot的建议审查较少，但GitHub Copilot也能巧妙地提醒开发者他们可能忽略的重要代码细节。", "conclusion": "尽管开发者对AI建议的审查程度低于人类伙伴，但AI副驾驶在知识转移的频率和内容上与人类结对编程表现出相似的有效性，并且能提供有益的提醒。", "translation": "知识转移是人类协作的基础，因此在软件工程中很常见。结对编程就是一个突出的例子。随着AI编码助手的兴起，开发者现在不仅与人类伙伴合作，而且正如一些人所声称的，还与AI结对程序员合作。尽管研究证实了人类结对编程中的知识转移，但其与AI编码助手合作的有效性仍不确定。为了分析人-人环境和人-AI环境中的知识转移，我们进行了一项实证研究，其中开发者结对在没有AI支持的情况下解决编程任务，而另一组单独的开发者使用AI编码助手GitHub Copilot完成了相同的任务。我们扩展了一个现有的知识转移框架，并采用半自动化评估流程来评估两种设置下知识转移事件的差异。我们发现两种设置下成功知识转移事件的频率相似，主题类别也重叠。我们的两个关键发现是，开发者倾向于以比人类结对编程伙伴更少的审查来接受GitHub Copilot的建议，但GitHub Copilot也能巧妙地提醒开发者他们可能忽略的重要代码细节。", "summary": "本研究通过实证比较了人类结对编程和使用AI编码助手（GitHub Copilot）两种情境下的知识转移。结果显示，两种情境下知识转移的频率和主题相似。值得注意的是，开发者对AI建议的审查较少，但AI能有效提醒开发者注意重要代码细节。这为理解AI在软件开发中知识转移的作用提供了见解。", "keywords": "知识转移, AI编码助手, 结对编程, GitHub Copilot, 比较研究"}}
{"id": "2506.04974", "pdf": "https://arxiv.org/pdf/2506.04974", "abs": "https://arxiv.org/abs/2506.04974", "authors": ["Joshua Roy Palathinkal", "Muhammad Iqbal Rochman", "Vanlin Sathya", "Mehmet Yavuz", "Monisha Ghosh"], "title": "Indoor Sharing in the Mid-Band: A Performance Study of Neutral-Host, Cellular Macro, and Wi-Fi", "categories": ["cs.NI", "eess.SP"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Indoor environments present a significant challenge for wireless\nconnectivity, as immense data demand strains traditional solutions. Public\nMobile Network Operators (MNOs), utilizing outdoor macro base stations (BSs),\nsuffer from poor signal penetration. Indoor Wi-Fi networks, on the other hand,\nmay face reliability issues due to spectrum contention. Shared spectrum models,\nparticularly the Citizens Broadband Radio Service (CBRS) utilized by private\n4G/5G networks, have emerged as a promising alternative to provide reliable\nindoor service. Moreover, these private networks are equipped with the\nneutral-host (NH) model, seamlessly offloading indoor MNOs' traffic to the\nprivate CBRS network. This paper presents a comprehensive, in-situ performance\nevaluation of three co-located technologies utilizing mid-bands spectrum (1-6\nGHz)--a CBRS-based NH network, public MNO macro networks, and a Wi-Fi 6\nnetwork--within a large, big-box retail store characterized by significant\nbuilding loss. Our analysis demonstrates: (i) the NH network provides superior\nindoor coverage compared to MNO macro, requiring only six CBRS devices\n(CBSDs)--versus 65 Access Points (APs) for enterprise Wi-Fi--to achieve full\ncoverage, with a median building loss of 26.6 dB ensuring interference-free\ncoexistence with outdoor federal incumbents; (ii) the NH network achieves\nsubstantial indoor throughput gains, with per-channel normalized throughput\nimprovements of 1.44x and 1.62x in downlink (DL), and 4.33x and 13x in uplink\n(UL), compared to 4G and 5G macro deployments, respectively; (iii) the NH\ndeployment achieves a median indoor aggregated physical (PHY)-layer DL\nthroughput gain of 2.08x over 5G macro deployments indoors, despite utilizing\nonly 40 MHz of aggregated bandwidth compared to 225 MHz for 5G macro; and (iv)\nthe NH deployment also outperforms Wi-Fi in application-layer HTTP DL\nperformance by 5.05x.", "AI": {"title_translation": "中频段室内共享：中立主机、蜂窝宏基站和Wi-Fi的性能研究", "tldr": "本研究评估了中立主机（NH）网络在中频段室内环境下的性能，发现其在覆盖范围和吞吐量方面均优于蜂窝宏网络和Wi-Fi网络。", "motivation": "室内环境对无线连接构成重大挑战，巨大的数据需求使传统解决方案面临压力。公共移动网络运营商（MNO）的室外宏基站信号穿透性差，而室内Wi-Fi网络可能因频谱竞争而面临可靠性问题。共享频谱模型，特别是公民宽带无线电服务（CBRS）所使用的私有4G/5G网络，已成为提供可靠室内服务的一种有前景的替代方案。", "method": "本研究在一家大型零售店中，对三种共址的中频段（1-6 GHz）技术进行了全面的现场性能评估：基于CBRS的中立主机（NH）网络、公共MNO宏网络和Wi-Fi 6网络。", "result": "(i) NH网络提供了优于MNO宏网络的室内覆盖，仅需六个CBRS设备（CBSD）即可实现全覆盖，而企业Wi-Fi需要65个接入点（AP），中位数建筑损耗为26.6 dB，确保与室外联邦现有用户的无干扰共存；(ii) NH网络实现了显著的室内吞吐量增益，与4G和5G宏部署相比，下行（DL）每通道标准化吞吐量分别提高了1.44倍和1.62倍，上行（UL）分别提高了4.33倍和13倍；(iii) 尽管NH部署仅使用40 MHz的聚合带宽，而5G宏部署使用225 MHz，但NH部署在室内聚合物理层（PHY）DL吞吐量中位数增益比5G宏部署高2.08倍；(iv) NH部署在应用层HTTP DL性能方面也比Wi-Fi高5.05倍。", "conclusion": "中立主机（NH）网络在中频段室内共享场景中表现出卓越的性能，在覆盖范围、吞吐量和频谱效率方面均优于传统的蜂窝宏网络和Wi-Fi网络，是解决室内无线连接挑战的有效方案。", "translation": "室内环境对无线连接提出了重大挑战，巨大的数据需求给传统解决方案带来了压力。公共移动网络运营商（MNO）利用室外宏基站（BS）面临信号穿透性差的问题。另一方面，室内Wi-Fi网络可能由于频谱竞争而面临可靠性问题。共享频谱模型，特别是私有4G/5G网络使用的公民宽带无线电服务（CBRS），已成为提供可靠室内服务的一种有前景的替代方案。此外，这些私有网络配备了中立主机（NH）模型，可将室内MNO的流量无缝分流到私有CBRS网络。本文对三种在中频段频谱（1-6 GHz）中共同部署的技术——基于CBRS的NH网络、公共MNO宏网络和Wi-Fi 6网络——在一家具有显著建筑损耗的大型零售店中进行了全面的现场性能评估。我们的分析表明：(i) 与MNO宏网络相比，NH网络提供了卓越的室内覆盖，仅需要六个CBRS设备（CBSD）即可实现全覆盖，而企业Wi-Fi需要65个接入点（AP），中位数建筑损耗为26.6 dB，确保与室外联邦现有用户的无干扰共存；(ii) NH网络实现了显著的室内吞吐量增益，与4G和5G宏部署相比，下行（DL）每通道标准化吞吐量分别提高了1.44倍和1.62倍，上行（UL）分别提高了4.33倍和13倍；(iii) 尽管NH部署仅使用40 MHz的聚合带宽，而5G宏部署使用225 MHz，但NH部署在室内聚合物理层（PHY）DL吞吐量中位数增益比5G宏部署高2.08倍；(iv) NH部署在应用层HTTP DL性能方面也比Wi-Fi高5.05倍。", "summary": "本论文对中频段（1-6 GHz）室内环境中的中立主机（NH）网络、蜂窝宏网络和Wi-Fi 6网络进行了全面的现场性能评估。研究发现，基于CBRS的NH网络在室内覆盖方面表现出色，仅需少量设备即可实现全覆盖，并能有效抑制干扰。与4G/5G宏网络和Wi-Fi相比，NH网络在下行和上行吞吐量方面均实现了显著提升，尤其是在频谱效率方面表现优异，证明了其在提供可靠室内无线服务方面的巨大潜力。", "keywords": "中立主机, CBRS, 室内共享, 5G, Wi-Fi"}}
{"id": "2506.04374", "pdf": "https://arxiv.org/pdf/2506.04374", "abs": "https://arxiv.org/abs/2506.04374", "authors": ["Jack David Carson", "Amir Reisizadeh"], "title": "A Statistical Physics of Language Model Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Transformer LMs show emergent reasoning that resists mechanistic\nunderstanding. We offer a statistical physics framework for continuous-time\nchain-of-thought reasoning dynamics. We model sentence-level hidden state\ntrajectories as a stochastic dynamical system on a lower-dimensional manifold.\nThis drift-diffusion system uses latent regime switching to capture diverse\nreasoning phases, including misaligned states or failures. Empirical\ntrajectories (8 models, 7 benchmarks) show a rank-40 projection (balancing\nvariance capture and feasibility) explains ~50% variance. We find four latent\nreasoning regimes. An SLDS model is formulated and validated to capture these\nfeatures. The framework enables low-cost reasoning simulation, offering tools\nto study and predict critical transitions like misaligned states or other LM\nfailures.", "AI": {"title_translation": "语言模型推理的统计物理学", "tldr": "本文提出一个统计物理学框架来理解Transformer语言模型的推理能力，将隐藏状态轨迹建模为低维流形上的随机动力系统，并引入潜在状态切换捕捉不同推理阶段。经验结果显示该框架能解释约50%的方差并识别四种推理模式，为研究和预测LM故障提供了低成本模拟工具。", "motivation": "Transformer语言模型展现出涌现的推理能力，但其机制理解困难，需要一个框架来理解其推理动态和故障。", "method": "提出了一个统计物理学框架，用于连续时间思维链推理的动态过程。将句子级隐藏状态轨迹建模为低维流形上的随机动力系统。该漂移-扩散系统利用潜在的状态切换来捕获多样化的推理阶段，包括未对齐状态或失败。制定并验证了一个SLDS模型来捕获这些特征。", "result": "经验轨迹（8个模型，7个基准）显示，一个秩为40的投影（平衡了方差捕获和可行性）解释了约50%的方差。发现了四种潜在的推理模式。SLDS模型被制定并验证能够捕获这些特征。", "conclusion": "该框架实现了低成本的推理模拟，为研究和预测像未对齐状态或其他语言模型故障这样的关键转换提供了工具。", "translation": "Transformer语言模型展现出新兴的推理能力，但其机制理解起来很困难。我们提出了一个统计物理学框架，用于连续时间思维链推理的动态过程。我们将句子级的隐藏状态轨迹建模为低维流形上的随机动力系统。这个漂移-扩散系统利用潜在的状态切换来捕获多样化的推理阶段，包括未对齐状态或失败。经验轨迹（8个模型，7个基准）显示，一个秩为40的投影（平衡了方差捕获和可行性）解释了约50%的方差。我们发现了四种潜在的推理模式。一个SLDS模型被公式化并验证能够捕获这些特征。该框架实现了低成本的推理模拟，为研究和预测像未对齐状态或其他语言模型故障这样的关键转换提供了工具。", "summary": "本文提出了一个统计物理学框架，用于理解Transformer语言模型中难以捉摸的推理能力。该框架将语言模型在推理过程中句子级的隐藏状态轨迹建模为低维流形上的随机漂移-扩散系统，并引入潜在状态切换以捕捉不同的推理阶段（包括失败状态）。通过对多个模型和基准的实证分析，研究发现了一个秩为40的投影能解释约50%的方差，并识别出四种潜在推理模式。该研究还提出了一个经过验证的SLDS模型来捕获这些特征，并强调该框架能够低成本模拟推理过程，为预测和研究语言模型中的关键故障提供了新工具。", "keywords": "统计物理学, 语言模型, 思维链推理, 漂移-扩散系统, 潜在状态切换"}}
{"id": "2506.04365", "pdf": "https://arxiv.org/pdf/2506.04365", "abs": "https://arxiv.org/abs/2506.04365", "authors": ["Liam Salass", "Jerrin Bright", "Amir Nazemi", "Yuhao Chen", "John Zelek", "David Clausi"], "title": "Ice Hockey Puck Localization Using Contextual Cues", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Puck detection in ice hockey broadcast videos poses significant challenges\ndue to the puck's small size, frequent occlusions, motion blur, broadcast\nartifacts, and scale inconsistencies due to varying camera zoom and broadcast\ncamera viewpoints. Prior works focus on appearance-based or motion-based cues\nof the puck without explicitly modelling the cues derived from player\nbehaviour. Players consistently turn their bodies and direct their gaze toward\nthe puck. Motivated by this strong contextual cue, we propose Puck Localization\nUsing Contextual Cues (PLUCC), a novel approach for scale-aware and\ncontext-driven single-frame puck detections. PLUCC consists of three\ncomponents: (a) a contextual encoder, which utilizes player orientations and\npositioning as helpful priors; (b) a feature pyramid encoder, which extracts\nmultiscale features from the dual encoders; and (c) a gating decoder that\ncombines latent features with a channel gating mechanism. For evaluation, in\naddition to standard average precision, we propose Rink Space Localization\nError (RSLE), a scale-invariant homography-based metric for removing\nperspective bias from rink space evaluation. The experimental results of PLUCC\non the PuckDataset dataset demonstrated state-of-the-art detection performance,\nsurpassing previous baseline methods by an average precision improvement of\n12.2% and RSLE average precision of 25%. Our research demonstrates the critical\nrole of contextual understanding in improving puck detection performance, with\nbroad implications for automated sports analysis.", "AI": {"title_translation": "使用上下文线索的冰球定位", "tldr": "本研究提出了一种名为PLUCC的新型方法，利用冰球运动员的行为上下文线索来解决冰球广播视频中冰球检测的挑战，并在PuckDataset数据集上实现了最先进的检测性能。", "motivation": "冰球广播视频中的冰球检测面临诸多挑战，如冰球尺寸小、频繁遮挡、运动模糊、广播伪影以及摄像机变焦和视角导致的尺度不一致。现有方法主要关注冰球的外观或运动线索，而没有明确建模来自球员行为的上下文线索。鉴于球员会持续转向冰球并注视冰球这一强烈的上下文线索，本研究旨在利用这些线索来改进冰球检测。", "method": "本研究提出了一种新颖的尺度感知和上下文驱动的单帧冰球检测方法PLUCC（Puck Localization Using Contextual Cues）。PLUCC包含三个组件：(a) 上下文编码器，利用球员的方向和位置作为有用的先验信息；(b) 特征金字塔编码器，从双编码器中提取多尺度特征；(c) 门控解码器，通过通道门控机制结合潜在特征。此外，为了评估，除了标准平均精度外，还提出了冰场空间定位误差（RSLE），这是一种基于单应性变换的尺度不变指标，用于消除冰场空间评估中的透视偏差。", "result": "PLUCC在PuckDataset数据集上的实验结果表明，其检测性能达到了最先进水平，平均精度比之前的基线方法提高了12.2%，RSLE平均精度提高了25%。", "conclusion": "本研究证明了上下文理解在提高冰球检测性能方面的关键作用，对自动化体育分析具有广泛的意义。", "translation": "冰球广播视频中的冰球检测由于冰球尺寸小、频繁遮挡、运动模糊、广播伪影以及摄像机变焦和广播摄像机视角的尺度不一致性等原因，带来了巨大的挑战。先前的工作主要关注冰球的外观或运动线索，而没有明确建模来自球员行为的线索。球员会持续转动身体并注视冰球。受这种强烈上下文线索的启发，我们提出了使用上下文线索的冰球定位（PLUCC），这是一种新颖的尺度感知和上下文驱动的单帧冰球检测方法。PLUCC由三个组件组成：(a) 上下文编码器，利用球员方向和位置作为有用的先验；(b) 特征金字塔编码器，从双编码器中提取多尺度特征；(c) 门控解码器，通过通道门控机制结合潜在特征。为了评估，除了标准平均精度外，我们提出了冰场空间定位误差（RSLE），这是一种基于单应性变换的尺度不变指标，用于消除冰场空间评估中的透视偏差。PLUCC在PuckDataset数据集上的实验结果表明，其检测性能达到了最先进水平，平均精度比之前的基线方法提高了12.2%，RSLE平均精度提高了25%。我们的研究证明了上下文理解在提高冰球检测性能方面的关键作用，对自动化体育分析具有广泛的意义。", "summary": "本论文针对冰球广播视频中冰球检测面临的挑战，提出了一种名为PLUCC的新型尺度感知和上下文驱动的单帧冰球检测方法。PLUCC利用球员方向和位置等上下文线索，并通过上下文编码器、特征金字塔编码器和门控解码器实现。研究还提出了一种新的评估指标RSLE。实验结果表明，PLUCC在冰球检测方面取得了最先进的性能，显著优于现有基线方法，突显了上下文理解在体育分析中的重要性。", "keywords": "冰球检测, 上下文线索, 目标定位, 计算机视觉, 体育分析"}}
{"id": "2506.04952", "pdf": "https://arxiv.org/pdf/2506.04952", "abs": "https://arxiv.org/abs/2506.04952", "authors": ["Symeon Vaidanis", "Photios A. Stavrou", "Marios Kountouris"], "title": "Optimization for Semantic-Aware Resource Allocation under CPT-based Utilities", "categories": ["cs.IT", "cs.NI", "eess.SP", "math.IT"], "comment": "This work has been accepted for publication in IEEE SPAWC 2025. The\n  final published version will be available via IEEE Xplore", "summary": "The problem of resource allocation in goal-oriented semantic communication\nwith semantic-aware utilities and subjective risk perception is studied here.\nBy linking information importance to risk aversion, we model agent behavior\nusing Cumulative Prospect Theory (CPT), which incorporates risk-sensitive\nutility functions and nonlinear transformations of distributions, reflecting\nsubjective perceptions of gains and losses. The objective is to maximize the\naggregate utility across multiple CPT-modeled agents, which leads to a\nnonconvex, nonsmooth optimization problem. To efficiently solve this\nchallenging problem, we propose a new algorithmic framework that combines\nsuccessive convex approximation (SCA) with the projected subgradient method and\nLagrangian relaxation, Our approach enables tractable optimization while\npreserving solution quality, offering both theoretical rigor and practical\neffectiveness in semantics-aware resource allocation.", "AI": {"title_translation": "基于CPT效用的语义感知资源分配优化", "tldr": "本文研究了基于CPT效用的语义感知资源分配问题，并提出了结合逐次凸逼近（SCA）、投影次梯度法和拉格朗日松弛的算法框架来解决非凸非光滑优化问题。", "motivation": "研究目标导向语义通信中，具有语义感知效用和主观风险感知的资源分配问题，并解决由此产生的非凸、非光滑优化难题。", "method": "通过将信息重要性与风险规避联系起来，使用累积前景理论（CPT）建模代理行为；提出了一种结合逐次凸逼近（SCA）、投影次梯度法和拉格朗日松弛的新算法框架。", "result": "所提出的方法实现了可处理的优化，同时保持了解决方案质量，在语义感知资源分配中具有理论严谨性和实际有效性。", "conclusion": "提出的算法框架有效解决了基于CPT效用的语义感知资源分配中的非凸非光滑优化问题，兼具理论严谨性和实际有效性。", "translation": "本文研究了目标导向语义通信中，具有语义感知效用和主观风险感知的资源分配问题。通过将信息重要性与风险规避联系起来，我们使用累积前景理论（CPT）建模代理行为，该理论结合了风险敏感效用函数和分布的非线性变换，反映了对收益和损失的主观感知。目标是最大化多个CPT建模代理的总效用，这导致了一个非凸、非光滑的优化问题。为了有效解决这个具有挑战性的问题，我们提出了一种结合逐次凸逼近（SCA）、投影次梯度法和拉格朗日松弛的新算法框架。我们的方法实现了可处理的优化，同时保持了解决方案质量，在语义感知资源分配中提供了理论严谨性和实际有效性。", "summary": "本文研究了目标导向语义通信中，考虑语义感知效用和主观风险感知的资源分配问题。通过使用累积前景理论（CPT）建模代理行为，该问题被表述为一个非凸、非光滑的优化问题。为有效解决此问题，作者提出了一种结合逐次凸逼近（SCA）、投影次梯度法和拉格朗日松弛的新算法框架。实验结果表明，该方法能够实现可处理的优化，同时保持解决方案质量，在语义感知资源分配中展现出理论严谨性和实际有效性。", "keywords": "资源分配, 语义通信, 累积前景理论, 非凸优化, 逐次凸逼近"}}
{"id": "2506.04791", "pdf": "https://arxiv.org/pdf/2506.04791", "abs": "https://arxiv.org/abs/2506.04791", "authors": ["Athanasios C. Antoulas", "Ion Victor Gosea", "Charles Poussot-Vassal", "Pierre Vuillemin"], "title": "Tensor-based multivariate function approximation: methods benchmarking and comparison", "categories": ["math.NA", "cs.CE", "cs.NA", "cs.SE", "93A15, 93A30, 93B11, 93B15, 93C05, 93C80"], "comment": "Report with a collection of examples, aimed at being regularly\n  updated. Associated GIT: https://github.com/cpoussot/mLF", "summary": "In this note, we evaluate the performances, the features and the\nuser-experience of some methods (and their implementations) designed for\ntensor- (or data-) based multivariate function construction and approximation.\nTo this aim, a collection of multivariate functions extracted from contributive\nworks coming from different communities, is suggested. First, these functions\nwith varying complexity (e.g. number and degree of the variables) and nature\n(e.g. rational, irrational, differentiable or not, symmetric, etc.) are used to\nconstruct tensors, each of different dimension and size on the disk. Second,\ngrounded on this tensor, we inspect performances of each considered method\n(e.g. the accuracy, the computational time, the parameters tuning impact,\netc.). Finally, considering the \"best\" parameter tuning set, we compare each\nmethod using multiple evaluation criteria. The purpose of this note is not to\nrank the methods but rather to evaluate as fairly as possible the different\navailable strategies, with the idea in mind to guide users to understand the\nprocess, the possibilities, the advantages and the limits brought by each\ntools. The contribution claimed is to suggest a complete benchmark collection\nof some available tools for tensor approximation by surrogate models (e.g.\nrational functions, networks, etc.). In addition, as contributors of the\nmultivariate Loewner Framework (mLF) approach (and its side implementation in\nMDSPACK), attention and details of the latter are more explicitly given, in\norder to provide readers a digest of this contributive work and some details\nwith simple examples.", "AI": {"title_translation": "基于张量的多元函数逼近：方法基准测试与比较", "tldr": "本文评估了用于张量（或数据）基多元函数构造和逼近的多种方法，并提供了基准集合以指导用户选择合适的工具。", "motivation": "评估张量（或数据）基多元函数构造和逼近方法的性能、特点和用户体验，并旨在指导用户理解各种工具的过程、可能性、优势和局限性。", "method": "收集了不同复杂度和性质的多元函数，用于构建不同维度和大小的张量。在此基础上，检查每种方法的性能（如准确性、计算时间、参数调整影响），并考虑“最佳”参数调整集，使用多重评估标准比较每种方法。", "result": "本文不旨在对方法进行排名，而是尽可能公平地评估不同的可用策略。主要贡献是提供了一个完整的张量逼近替代模型工具的基准集合。", "conclusion": "本文旨在帮助用户理解张量基多元函数逼近工具的过程、可能性、优势和局限性，并提供了基准集合以供参考。", "translation": "本笔记评估了为基于张量（或数据）的多元函数构造和逼近设计的一些方法（及其实现）的性能、特征和用户体验。为此，建议使用从不同社区的贡献性工作中提取的多元函数集合。首先，这些具有不同复杂性（例如变量的数量和度数）和性质（例如有理、无理、可微或不可微、对称等）的函数用于在磁盘上构造不同维度和大小的张量。其次，基于这些张量，我们检查了每种考虑方法的性能（例如准确性、计算时间、参数调整影响等）。最后，考虑到“最佳”参数调整集，我们使用多个评估标准比较了每种方法。本笔记的目的不是对方法进行排名，而是尽可能公平地评估不同的可用策略，旨在指导用户理解每种工具带来的过程、可能性、优势和局限性。声称的贡献是建议一个完整的张量逼近替代模型（例如有理函数、网络等）的可用工具的基准集合。此外，作为多元Loewner框架（mLF）方法（及其在MDSPACK中的侧面实现）的贡献者，为了向读者提供这项贡献性工作的摘要和一些简单示例的详细信息，对后者给予了更明确的关注和详细说明。", "summary": "本研究对用于张量（或数据）基多元函数构造和逼近的多种方法进行了性能、功能和用户体验评估。通过构建不同复杂度的多元函数张量，详细考察了每种方法的准确性、计算时间及参数调优影响，并基于多重标准进行了比较。文章旨在提供一个全面的张量逼近工具基准集合，以指导用户理解和选择合适的工具，而非对方法进行排名。", "keywords": "张量逼近, 多元函数, 方法评估, 基准测试, 替代模型"}}
{"id": "2506.04272", "pdf": "https://arxiv.org/pdf/2506.04272", "abs": "https://arxiv.org/abs/2506.04272", "authors": ["Kyung Rok Kim", "Yumo Bai", "Chonghuan Wang", "Guanting Chen"], "title": "Understanding the Impact of Sampling Quality in Direct Preference Optimization", "categories": ["cs.LG"], "comment": "Submitted to NeurIPS2025", "summary": "We study the role of the sampling distribution in Direct Preference\nOptimization (DPO) and aim to understand its impact on DPO's training dynamics.\nOur analyses show that both the solution space and the convergence behavior of\nDPO depend on the support and quality of the generating distribution. We first\nanalyze how distribution of responses influences policy updates during gradient\ndescent, drawing connections to common phenomena found in practice. We then\ndesign a simplified yet well-structured alignment model as a proxy, and develop\nquantitative results showing how more frequent high-quality responses amplify\nthe gradient signal and improve the optimization landscape, leading to more\neffective policy learning. Our theoretical findings are supported by empirical\nexperiments and provide a principled justification for the online DPO framework\nin practice.", "AI": {"title_translation": "理解采样质量在直接偏好优化中的影响", "tldr": "本研究探讨了DPO中采样分布的作用及其对训练动态的影响，发现高质量响应能增强梯度信号并优化学习过程，为在线DPO提供了理论依据。", "motivation": "研究采样分布在直接偏好优化（DPO）中的作用，并理解其对DPO训练动态的影响。", "method": "分析了响应分布如何影响梯度下降期间的策略更新，并设计了一个简化的对齐模型作为代理，量化展示了高质量响应如何放大梯度信号并改善优化前景。", "result": "DPO的解空间和收敛行为取决于生成分布的支持和质量。更频繁的高质量响应能够放大梯度信号并改善优化前景，从而实现更有效的策略学习。理论发现得到了实证实验的支持。", "conclusion": "为实践中的在线DPO框架提供了有原则的理论依据。", "translation": "我们研究了直接偏好优化（DPO）中采样分布的作用，旨在理解其对DPO训练动态的影响。我们的分析表明，DPO的解空间和收敛行为都取决于生成分布的支持度和质量。我们首先分析了响应分布如何影响梯度下降期间的策略更新，并将其与实践中常见的现象联系起来。然后，我们设计了一个简化但结构良好的对齐模型作为代理，并开发了定量结果，表明更频繁的高质量响应如何放大梯度信号并改善优化前景，从而实现更有效的策略学习。我们的理论发现得到了实证实验的支持，并为实践中的在线DPO框架提供了有原则的理论依据。", "summary": "本研究深入探讨了直接偏好优化（DPO）中采样分布的关键作用。分析表明，采样分布的质量和支持度直接影响DPO的解空间和收敛行为。研究人员通过分析响应分布对梯度下降中策略更新的影响，并构建简化模型进行量化分析，揭示了高质量响应如何有效增强梯度信号并优化学习过程，从而促进更高效的策略学习。这些理论发现得到了实验验证，并为在线DPO的实际应用提供了坚实的理论基础。", "keywords": "直接偏好优化, 采样质量, 训练动态, 梯度信号, 策略学习"}}
{"id": "2506.04954", "pdf": "https://arxiv.org/pdf/2506.04954", "abs": "https://arxiv.org/abs/2506.04954", "authors": ["Sandra Schulz", "Natalie Kiesler"], "title": "The Data Dilemma: Authors' Intentions and Recognition of Research Data in Educational Technology Research", "categories": ["cs.CY"], "comment": null, "summary": "Educational Technology (EdTec) research is conducted by multiple disciplines,\nsome of which annually meet at the DELFI conference. Due to the heterogeneity\nof involved researchers and communities, it is our goal to identify categories\nof research data overseen in the context of EdTec research. Therefore, we\nanalyze the author's perspective provided via EasyChair where authors specified\nwhether they had research data to share. We compared this information with an\nanalysis of the submitted articles and the contained research data. We found\nthat not all research data was recognized as such by the authors, especially\nsoftware and qualitative data, indicating a prevailing lack of awareness, and\nother potential barriers. In addition, we analyze the 2024 DELFI proceedings to\nlearn what kind of data was subject to research, and where it is published.\nThis work has implications for training future generations of EdTec\nresearchers. It further stresses the need for guidelines and recognition of\nresearch data publications (particularly software, and qualitative data).", "AI": {"title_translation": "数据困境：教育技术研究中作者的意图与研究数据识别", "tldr": "本研究发现教育技术研究人员未能充分识别和共享所有研究数据，尤其是在软件和定性数据方面，强调了制定相关指南的必要性。", "motivation": "由于教育技术研究人员和社区的异质性，本研究旨在识别教育技术研究中被忽视的研究数据类别。", "method": "作者分析了通过EasyChair提供的作者视角，即作者是否声明有研究数据可共享。他们将此信息与对提交文章及其包含的研究数据的分析进行比较。此外，他们还分析了2024年DELFI会议论文集，以了解研究数据的类型及其发布位置。", "result": "研究发现并非所有研究数据都被作者识别为研究数据，特别是软件和定性数据，这表明普遍缺乏意识和其他潜在障碍。", "conclusion": "本研究对未来教育技术研究人员的培训具有启示意义，并强调了制定研究数据（特别是软件和定性数据）发布指南和认可的必要性。", "translation": "教育技术（EdTec）研究由多个学科进行，其中一些学科每年在DELFI会议上会面。由于所涉及的研究人员和社区的异质性，我们的目标是识别在教育技术研究背景下被忽视的研究数据类别。因此，我们分析了作者通过EasyChair提供的视角，作者在此指定他们是否有研究数据可共享。我们将此信息与对提交文章及其包含的研究数据的分析进行了比较。我们发现并非所有研究数据都被作者识别为研究数据，特别是软件和定性数据，这表明普遍缺乏意识和其他潜在障碍。此外，我们还分析了2024年DELFI会议论文集，以了解哪些类型的数据是研究对象，以及它们在哪里发布。这项工作对未来教育技术研究人员的培训具有启示意义。它进一步强调了制定研究数据发布指南和认可的必要性（特别是软件和定性数据）。", "summary": "本研究旨在识别教育技术研究中被忽视的研究数据类别，因为该领域的研究人员和社区具有异质性。通过分析作者在EasyChair上声明的数据共享意图与提交文章中实际包含的数据，研究发现作者未能充分识别所有研究数据，尤其是软件和定性数据，这表明存在意识不足或其他潜在障碍。此外，研究还分析了2024年DELFI会议论文集，以了解数据类型及发布情况。这项工作对未来的教育技术研究人员培训具有重要意义，并强调了制定研究数据（特别是软件和定性数据）发布指南和认可的必要性。", "keywords": "教育技术研究, 研究数据, 作者意图, 数据识别, 数据共享"}}
{"id": "2506.04902", "pdf": "https://arxiv.org/pdf/2506.04902", "abs": "https://arxiv.org/abs/2506.04902", "authors": ["Preethika Pradeep", "Eyhab Al-Masri"], "title": "Energy-Optimized Scheduling for AIoT Workloads Using TOPSIS", "categories": ["cs.DC", "cs.PF", "cs.SY", "eess.SY"], "comment": null, "summary": "AIoT workloads demand energy-efficient orchestration across cloud-edge\ninfrastructures, but Kubernetes' default scheduler lacks multi-criteria\noptimization for heterogeneous environments. This paper presents GreenPod, a\nTOPSIS-based scheduler optimizing pod placement based on execution time, energy\nconsumption, processing core, memory availability, and resource balance. Tested\non a heterogeneous Google Kubernetes cluster, GreenPod improves energy\nefficiency by up to 39.1% over the default Kubernetes (K8s) scheduler,\nparticularly with energy-centric weighting schemes. Medium complexity workloads\nshowed the highest energy savings, despite slight scheduling latency. GreenPod\neffectively balances sustainability and performance for AIoT applications.", "AI": {"title_translation": "使用TOPSIS的AIoT工作负载能耗优化调度", "tldr": "GreenPod是一种基于TOPSIS的调度器，用于优化AIoT工作负载在异构Kubernetes集群中的Pod放置，显著提高了能源效率。", "motivation": "AIoT工作负载需要在云边基础设施中实现能源效率高的编排，但Kubernetes的默认调度器缺乏针对异构环境的多标准优化。", "method": "本文提出了GreenPod，一个基于TOPSIS的调度器。它根据执行时间、能耗、处理核心、内存可用性和资源平衡来优化Pod放置。", "result": "在异构Google Kubernetes集群上测试，GreenPod比默认的Kubernetes调度器在能源效率方面提高了39.1%，尤其是在以能源为中心的加权方案下。中等复杂度的负载显示出最高的能源节约，尽管调度延迟略有增加。", "conclusion": "GreenPod有效地平衡了AIoT应用的可持续性和性能。", "translation": "AIoT工作负载需要在云边基础设施中实现能源效率高的编排，但Kubernetes的默认调度器缺乏针对异构环境的多标准优化。本文提出了GreenPod，一个基于TOPSIS的调度器，它根据执行时间、能耗、处理核心、内存可用性和资源平衡来优化Pod放置。在异构Google Kubernetes集群上测试，GreenPod比默认的Kubernetes（K8s）调度器在能源效率方面提高了39.1%，尤其是在以能源为中心的加权方案下。中等复杂度的负载显示出最高的能源节约，尽管调度延迟略有增加。GreenPod有效地平衡了AIoT应用的可持续性和性能。", "summary": "GreenPod是一种基于TOPSIS的调度器，旨在解决Kubernetes默认调度器在AIoT工作负载异构云边基础设施中缺乏多标准优化的问题。通过考虑执行时间、能耗、处理核心、内存可用性和资源平衡等多个因素，GreenPod在Google Kubernetes集群上测试显示，与默认调度器相比，能源效率最高可提高39.1%，特别是在能源优先的权重配置下。该调度器在平衡AIoT应用的可持续性和性能方面表现出色。", "keywords": "AIoT, 能源优化, 调度, TOPSIS, Kubernetes"}}
{"id": "2506.04962", "pdf": "https://arxiv.org/pdf/2506.04962", "abs": "https://arxiv.org/abs/2506.04962", "authors": ["Deniz Simsek", "Aryaz Eghbali", "Michael Pradel"], "title": "PoCGen: Generating Proof-of-Concept Exploits for Vulnerabilities in Npm Packages", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "Security vulnerabilities in software packages are a significant concern for\ndevelopers and users alike. Patching these vulnerabilities in a timely manner\nis crucial to restoring the integrity and security of software systems.\nHowever, previous work has shown that vulnerability reports often lack\nproof-of-concept (PoC) exploits, which are essential for fixing the\nvulnerability, testing patches, and avoiding regressions. Creating a PoC\nexploit is challenging because vulnerability reports are informal and often\nincomplete, and because it requires a detailed understanding of how inputs\npassed to potentially vulnerable APIs may reach security-relevant sinks. In\nthis paper, we present PoCGen, a novel approach to autonomously generate and\nvalidate PoC exploits for vulnerabilities in npm packages. This is the first\nfully autonomous approach to use large language models (LLMs) in tandem with\nstatic and dynamic analysis techniques for PoC exploit generation. PoCGen\nleverages an LLM for understanding vulnerability reports, for generating\ncandidate PoC exploits, and for validating and refining them. Our approach\nsuccessfully generates exploits for 77% of the vulnerabilities in the\nSecBench.js dataset and 39% in a new, more challenging dataset of 794 recent\nvulnerabilities. This success rate significantly outperforms a recent baseline\n(by 45 absolute percentage points), while imposing an average cost of $0.02 per\ngenerated exploit.", "AI": {"title_translation": "PoCGen：为Npm包中的漏洞生成概念验证漏洞利用", "tldr": "PoCGen是一个利用LLM、静态和动态分析自动生成并验证npm包漏洞PoC的工具，效果显著优于现有基线。", "motivation": "软件漏洞是重大隐患，及时修补至关重要。然而，漏洞报告常缺乏PoC，而PoC对于修复、测试补丁和避免回归至关重要。创建PoC困难，因为报告非正式、不完整，且需深入理解输入如何触及敏感API。", "method": "提出PoCGen，一种自动生成并验证npm包中漏洞PoC的新方法。这是首个将LLM与静态和动态分析结合用于PoC生成的全自动方法。PoCGen利用LLM理解漏洞报告、生成候选PoC并进行验证和完善。", "result": "成功为SecBench.js数据集中77%的漏洞和包含794个最新漏洞的新数据集中39%的漏洞生成了漏洞利用。成功率比最新基线高出45个绝对百分点，平均每个生成的漏洞利用成本为0.02美元。", "conclusion": "PoCGen显著提高了npm包漏洞PoC的自动化生成效率和成功率，为及时修补漏洞提供了有效工具。", "translation": "软件包中的安全漏洞是开发人员和用户共同关注的重大问题。及时修补这些漏洞对于恢复软件系统的完整性和安全性至关重要。然而，之前的研究表明，漏洞报告通常缺乏概念验证（PoC）漏洞利用，而PoC对于修复漏洞、测试补丁和避免回归至关重要。创建PoC漏洞利用具有挑战性，因为漏洞报告非正式且通常不完整，并且需要详细了解传递给潜在易受攻击API的输入如何到达安全相关的接收器。在本文中，我们提出了PoCGen，一种自动生成和验证npm包中漏洞PoC漏洞利用的新方法。这是第一个将大型语言模型（LLM）与静态和动态分析技术结合用于PoC漏洞利用生成的完全自主方法。PoCGen利用LLM理解漏洞报告、生成候选PoC漏洞利用以及验证和完善它们。我们的方法成功地为SecBench.js数据集中77%的漏洞和包含794个最新漏洞的更具挑战性的新数据集中39%的漏洞生成了漏洞利用。这一成功率显著优于最近的基线（高出45个绝对百分点），同时每个生成的漏洞利用平均成本为0.02美元。", "summary": "PoCGen是一种新颖的自动化方法，利用大语言模型、静态和动态分析为npm包漏洞生成并验证概念验证漏洞利用。它解决了现有漏洞报告缺乏PoC的挑战，并在多个数据集上取得了显著优于基线的性能，同时成本低廉。", "keywords": "PoC生成, npm包, 漏洞利用, 大语言模型, 静态分析, 动态分析"}}
{"id": "2506.05309", "pdf": "https://arxiv.org/pdf/2506.05309", "abs": "https://arxiv.org/abs/2506.05309", "authors": ["Niv Eckhaus", "Uri Berger", "Gabriel Stanovsky"], "title": "Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia Games", "categories": ["cs.MA", "cs.AI", "cs.CL"], "comment": null, "summary": "LLMs are used predominantly in synchronous communication, where a human user\nand a model communicate in alternating turns. In contrast, many real-world\nsettings are inherently asynchronous. For example, in group chats, online team\nmeetings, or social games, there is no inherent notion of turns; therefore, the\ndecision of when to speak forms a crucial part of the participant's decision\nmaking. In this work, we develop an adaptive asynchronous LLM-agent which, in\naddition to determining what to say, also decides when to say it. To evaluate\nour agent, we collect a unique dataset of online Mafia games, including both\nhuman participants, as well as our asynchronous agent. Overall, our agent\nperforms on par with human players, both in game performance, as well as in its\nability to blend in with the other human players. Our analysis shows that the\nagent's behavior in deciding when to speak closely mirrors human patterns,\nalthough differences emerge in message content. We release all our data and\ncode to support and encourage further research for more realistic asynchronous\ncommunication between LLM agents. This work paves the way for integration of\nLLMs into realistic human group settings, from assistance in team discussions\nto educational and professional environments where complex social dynamics must\nbe navigated.", "AI": {"title_translation": "是时候交谈了：用于Mafia游戏异步群组通信的LLM代理", "tldr": "本文开发了一种异步LLM代理，它不仅决定说什么，还决定何时说，并在Mafia游戏中表现与人类玩家相当，为LLM融入现实人类群组环境奠定基础。", "motivation": "目前大型语言模型（LLMs）主要用于同步通信，即人类用户与模型交替发言。然而，许多现实世界场景本质上是异步的，例如群聊、在线团队会议或社交游戏，其中没有固定的轮流概念，因此何时发言的决定成为参与者决策的关键部分。本研究旨在解决LLM在异步群组通信中的应用挑战。", "method": "本研究开发了一种自适应的异步LLM代理，该代理除了决定说什么之外，还能决定何时说。为了评估该代理，研究人员收集了一个独特的在线Mafia游戏数据集，其中包括人类参与者和所开发的异步代理。", "result": "该代理在游戏表现和融入其他人类玩家的能力方面都与人类玩家不相上下。分析表明，代理决定何时发言的行为与人类模式非常相似，尽管消息内容存在差异。", "conclusion": "这项工作为LLM融入现实人类群组环境铺平了道路，从团队讨论中的协助到需要应对复杂社会动态的教育和专业环境。", "translation": "大型语言模型（LLMs）主要用于同步通信，即人类用户与模型交替发言。相比之下，许多现实世界场景本质上是异步的。例如，在群聊、在线团队会议或社交游戏中，没有固有的轮流概念；因此，决定何时发言构成了参与者决策的关键部分。在这项工作中，我们开发了一种自适应的异步LLM代理，它除了决定说什么之外，还能决定何时说。为了评估我们的代理，我们收集了一个独特的在线Mafia游戏数据集，其中包括人类参与者以及我们的异步代理。总的来说，我们的代理在游戏表现和融入其他人类玩家的能力方面都与人类玩家不相上下。我们的分析表明，代理决定何时发言的行为与人类模式非常相似，尽管消息内容存在差异。我们发布了所有数据和代码，以支持和鼓励LLM代理之间更真实的异步通信的进一步研究。这项工作为LLM融入现实人类群组环境铺平了道路，从团队讨论中的协助到需要应对复杂社会动态的教育和专业环境。", "summary": "本研究开发了一种新型异步LLM代理，该代理能够自主决定在群组通信中何时发言。通过在在线Mafia游戏中进行评估，结果显示该代理在游戏表现和与人类玩家的融合度上均表现出色，其发言时机决策模式与人类高度相似。这项工作为LLM在现实世界异步群组环境中的应用提供了新的方向和可能性。", "keywords": "LLM代理, 异步通信, 群组交流, Mafia游戏, 人机交互"}}
{"id": "2506.04547", "pdf": "https://arxiv.org/pdf/2506.04547", "abs": "https://arxiv.org/abs/2506.04547", "authors": ["Jonathan Tirado", "Aida Parvaresh", "Burcu Seyidoğlu", "Darryl A. Bedford", "Jonas Jørgensen", "Ahmad Rafsanjani"], "title": "Multimodal Limbless Crawling Soft Robot with a Kirigami Skin", "categories": ["cs.RO"], "comment": "Cyborg and Bionic Systems (2025)", "summary": "Limbless creatures can crawl on flat surfaces by deforming their bodies and\ninteracting with asperities on the ground, offering a biological blueprint for\ndesigning efficient limbless robots. Inspired by this natural locomotion, we\npresent a soft robot capable of navigating complex terrains using a combination\nof rectilinear motion and asymmetric steering gaits. The robot is made of a\npair of antagonistic inflatable soft actuators covered with a flexible kirigami\nskin with asymmetric frictional properties. The robot's rectilinear locomotion\nis achieved through cyclic inflation of internal chambers with precise phase\nshifts, enabling forward progression. Steering is accomplished using an\nasymmetric gait, allowing for both in-place rotation and wide turns. To\nvalidate its mobility in obstacle-rich environments, we tested the robot in an\narena with coarse substrates and multiple obstacles. Real-time feedback from\nonboard proximity sensors, integrated with a human-machine interface (HMI),\nallowed adaptive control to avoid collisions. This study highlights the\npotential of bioinspired soft robots for applications in confined or\nunstructured environments, such as search-and-rescue operations, environmental\nmonitoring, and industrial inspections.", "AI": {"title_translation": "带折纸蒙皮的多模态无肢爬行软体机器人", "tldr": "受无肢生物启发，本文提出一种带有折纸蒙皮的软体机器人，能通过直线运动和不对称转向步态在复杂地形中爬行，并利用传感器和人机界面实现自适应避障。", "motivation": "受无肢生物高效爬行能力的启发，设计一种能够在复杂地形中导航的无肢机器人。", "method": "机器人由一对对抗性充气软执行器和具有不对称摩擦特性的柔性折纸蒙皮构成。通过内部腔室的循环充气实现直线运动，利用不对称步态实现转向。通过车载接近传感器和人机界面实现实时反馈和自适应控制以避免碰撞。", "result": "机器人在粗糙基质和多障碍物的环境中进行了测试，验证了其在障碍物丰富环境中的移动能力，并能通过自适应控制避免碰撞。", "conclusion": "这项研究突出了仿生软体机器人在受限或非结构化环境（如搜救、环境监测和工业检查）中应用的潜力。", "translation": "无肢生物可以通过身体变形并与地面粗糙度相互作用，在平坦表面上爬行，这为设计高效的无肢机器人提供了生物学蓝图。受这种自然运动的启发，我们提出了一种软体机器人，能够通过结合直线运动和不对称转向步态在复杂地形中导航。该机器人由一对对抗性充气软执行器组成，覆盖有具有不对称摩擦特性的柔性折纸蒙皮。机器人的直线运动是通过内部腔室的循环充气和精确的相位差实现的，从而实现向前推进。转向则通过不对称步态完成，允许原地旋转和大转弯。为了验证其在障碍物丰富环境中的移动性，我们在具有粗糙基质和多个障碍物的竞技场中对机器人进行了测试。来自车载接近传感器的实时反馈，结合人机界面（HMI），实现了自适应控制以避免碰撞。这项研究突出了仿生软体机器人在受限或非结构化环境中的潜力，例如搜救行动、环境监测和工业检查。", "summary": "本文介绍了一种受自然爬行启发的无肢软体机器人，其特点是结合了直线运动和不对称转向步态，以适应复杂地形。该机器人由充气软执行器和具有不对称摩擦特性的折纸蒙皮组成。通过精确的内部充气和不对称步态实现运动控制。实验证明，该机器人在障碍物环境中具有良好的移动性，并通过车载传感器和人机界面实现了自适应避障。这项工作展示了仿生软体机器人在搜救、环境监测和工业检查等受限环境中的应用前景。", "keywords": "软体机器人, 无肢爬行, 折纸蒙皮, 多模态运动, 仿生"}}
{"id": "2506.04987", "pdf": "https://arxiv.org/pdf/2506.04987", "abs": "https://arxiv.org/abs/2506.04987", "authors": ["Zanis Ali Khan", "Aayush Garg", "Qiang Tang"], "title": "A Multi-Dataset Evaluation of Models for Automated Vulnerability Repair", "categories": ["cs.SE", "cs.AI"], "comment": "Preprint has been accepted in ARES AI&CCPS (International Workshop on\n  Artificial Intelligence, Cyber and Cyber-Physical Security)", "summary": "Software vulnerabilities pose significant security threats, requiring\neffective mitigation. While Automated Program Repair (APR) has advanced in\nfixing general bugs, vulnerability patching, a security-critical aspect of APR\nremains underexplored. This study investigates pre-trained language models,\nCodeBERT and CodeT5, for automated vulnerability patching across six datasets\nand four languages. We evaluate their accuracy and generalization to unknown\nvulnerabilities. Results show that while both models face challenges with\nfragmented or sparse context, CodeBERT performs comparatively better in such\nscenarios, whereas CodeT5 excels in capturing complex vulnerability patterns.\nCodeT5 also demonstrates superior scalability. Furthermore, we test fine-tuned\nmodels on both in-distribution (trained) and out-of-distribution (unseen)\ndatasets. While fine-tuning improves in-distribution performance, models\nstruggle to generalize to unseen data, highlighting challenges in robust\nvulnerability detection. This study benchmarks model performance, identifies\nlimitations in generalization, and provides actionable insights to advance\nautomated vulnerability patching for real-world security applications.", "AI": {"title_translation": "多数据集评估自动化漏洞修复模型", "tldr": "本研究评估了CodeBERT和CodeT5两种预训练语言模型在自动化漏洞修复方面的性能，发现它们在泛化性方面存在挑战，但提供了改进见解。", "motivation": "软件漏洞构成重大安全威胁，需要有效的缓解措施。尽管自动化程序修复（APR）在修复一般错误方面取得了进展，但作为APR中安全关键方面的漏洞修补仍未得到充分探索。", "method": "本研究调查了预训练语言模型CodeBERT和CodeT5，在六个数据集和四种语言上进行自动化漏洞修补。研究评估了它们的准确性和对未知漏洞的泛化能力。此外，还在分布内（已训练）和分布外（未见过）数据集上测试了微调模型。", "result": "结果显示，尽管两种模型在上下文碎片化或稀疏时都面临挑战，但CodeBERT在此类场景中表现相对更好，而CodeT5在捕获复杂漏洞模式方面表现出色，并展示了卓越的可扩展性。微调提高了分布内性能，但模型难以泛化到未见过的数据，凸显了鲁棒漏洞检测的挑战。", "conclusion": "本研究对模型性能进行了基准测试，指明了泛化能力的局限性，并提供了可操作的见解，以推动自动化漏洞修补在实际安全应用中的发展。", "translation": "软件漏洞构成重大安全威胁，需要有效的缓解措施。尽管自动化程序修复（APR）在修复一般错误方面取得了进展，但作为APR中安全关键方面的漏洞修补仍未得到充分探索。本研究调查了预训练语言模型CodeBERT和CodeT5，在六个数据集和四种语言上进行自动化漏洞修补。我们评估了它们的准确性和对未知漏洞的泛化能力。结果显示，尽管两种模型在上下文碎片化或稀疏时都面临挑战，但CodeBERT在此类场景中表现相对更好，而CodeT5在捕获复杂漏洞模式方面表现出色。CodeT5还展示了卓越的可扩展性。此外，我们还在分布内（已训练）和分布外（未见过）数据集上测试了微调模型。虽然微调提高了分布内性能，但模型难以泛化到未见过的数据，凸显了鲁棒漏洞检测的挑战。本研究对模型性能进行了基准测试，指明了泛化能力的局限性，并提供了可操作的见解，以推动自动化漏洞修补在实际安全应用中的发展。", "summary": "本研究评估了预训练语言模型CodeBERT和CodeT5在自动化漏洞修复方面的能力。通过在多个数据集和语言上进行测试，研究分析了它们的准确性、泛化能力和可扩展性。结果表明，尽管模型在泛化到新数据方面存在挑战，但CodeBERT在稀疏上下文下表现较好，而CodeT5在复杂模式和可扩展性方面表现突出。研究指出了当前模型的局限性，并为未来自动化漏洞修复的研究提供了方向。", "keywords": "自动化漏洞修复, 预训练语言模型, CodeBERT, CodeT5, 泛化性"}}
{"id": "2506.04410", "pdf": "https://arxiv.org/pdf/2506.04410", "abs": "https://arxiv.org/abs/2506.04410", "authors": ["Peter Jansen", "Samiah Hassan", "Ruoyao Wang"], "title": "Matter-of-Fact: A Benchmark for Verifying the Feasibility of Literature-Supported Claims in Materials Science", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.CL"], "comment": "8 pages", "summary": "Contemporary approaches to assisted scientific discovery use language models\nto automatically generate large numbers of potential hypothesis to test, while\nalso automatically generating code-based experiments to test those hypotheses.\nWhile hypotheses can be comparatively inexpensive to generate, automated\nexperiments can be costly, particularly when run at scale (i.e. thousands of\nexperiments). Developing the capacity to filter hypotheses based on their\nfeasibility would allow discovery systems to run at scale, while increasing\ntheir likelihood of making significant discoveries. In this work we introduce\nMatter-of-Fact, a challenge dataset for determining the feasibility of\nhypotheses framed as claims. Matter-of-Fact includes 8.4k claims extracted from\nscientific articles spanning four high-impact contemporary materials science\ntopics, including superconductors, semiconductors, batteries, and aerospace\nmaterials, while including qualitative and quantitative claims from\ntheoretical, experimental, and code/simulation results. We show that strong\nbaselines that include retrieval augmented generation over scientific\nliterature and code generation fail to exceed 72% performance on this task\n(chance performance is 50%), while domain-expert verification suggests nearly\nall are solvable -- highlighting both the difficulty of this task for current\nmodels, and the potential to accelerate scientific discovery by making\nnear-term progress.", "AI": {"title_translation": "Matter-of-Fact：验证材料科学中文献支持主张可行性的基准", "tldr": "本文介绍了Matter-of-Fact数据集，旨在验证材料科学领域中文献支持的假设的可行性，揭示当前AI模型的不足但显示出加速科学发现的潜力。", "motivation": "自动化实验成本高昂，需要有效过滤假设以提高科学发现系统的效率和成功率。", "method": "引入了名为Matter-of-Fact的挑战数据集，包含从材料科学文章中提取的8.4k个主张，涵盖超导体、半导体、电池和航空航天材料等领域，包括定性和定量主张。", "result": "包含检索增强生成和代码生成的强大基线模型在该任务上的表现未能超过72%（随机表现为50%），而领域专家验证表明几乎所有主张都是可解决的。", "conclusion": "该任务对当前模型来说具有挑战性，但通过近期的进展，有望加速科学发现。", "translation": "当代辅助科学发现方法利用语言模型自动生成大量潜在待测试的假设，同时自动生成基于代码的实验来测试这些假设。虽然假设的生成成本相对较低，但自动化实验成本可能很高，尤其是在大规模运行时（即数千个实验）。开发基于可行性过滤假设的能力将使发现系统能够大规模运行，同时增加其做出重大发现的可能性。在这项工作中，我们引入了Matter-of-Fact，这是一个用于确定以主张形式表达的假设可行性的挑战数据集。Matter-of-Fact包含从涵盖四个高影响力当代材料科学主题（包括超导体、半导体、电池和航空航天材料）的科学文章中提取的8.4k个主张，同时包括来自理论、实验和代码/模拟结果的定性和定量主张。我们表明，包括检索增强生成（RAG）和代码生成在内的强大基线模型在此任务上的表现未能超过72%（随机表现为50%），而领域专家验证表明几乎所有主张都是可解决的——这突显了当前模型在此任务上的难度，以及通过近期进展加速科学发现的潜力。", "summary": "本文介绍了Matter-of-Fact数据集，旨在验证材料科学领域中由文献支持的假设的可行性。该数据集包含8.4k个从科学文章中提取的主张，涵盖多个高影响力材料科学主题。研究发现，尽管强大的基线模型（包括检索增强生成）在该任务上的表现不佳（最高72%），但专家验证表明这些主张大多是可解决的，这突显了当前模型的局限性以及通过改进模型加速科学发现的巨大潜力。", "keywords": "材料科学, 假设验证, 数据集, 语言模型, 科学发现"}}
{"id": "2506.04367", "pdf": "https://arxiv.org/pdf/2506.04367", "abs": "https://arxiv.org/abs/2506.04367", "authors": ["Jubayer Ahmed Bhuiyan Shawon", "Hasan Mahmud", "Kamrul Hasan"], "title": "Fine-Tuning Video Transformers for Word-Level Bangla Sign Language: A Comparative Analysis for Classification Tasks", "categories": ["cs.CV"], "comment": "16 pages, 8 figures, 6 tables", "summary": "Sign Language Recognition (SLR) involves the automatic identification and\nclassification of sign gestures from images or video, converting them into text\nor speech to improve accessibility for the hearing-impaired community. In\nBangladesh, Bangla Sign Language (BdSL) serves as the primary mode of\ncommunication for many individuals with hearing impairments. This study\nfine-tunes state-of-the-art video transformer architectures -- VideoMAE, ViViT,\nand TimeSformer -- on BdSLW60 (arXiv:2402.08635), a small-scale BdSL dataset\nwith 60 frequent signs. We standardized the videos to 30 FPS, resulting in\n9,307 user trial clips. To evaluate scalability and robustness, the models were\nalso fine-tuned on BdSLW401 (arXiv:2503.02360), a large-scale dataset with 401\nsign classes. Additionally, we benchmark performance against public datasets,\nincluding LSA64 and WLASL. Data augmentation techniques such as random\ncropping, horizontal flipping, and short-side scaling were applied to improve\nmodel robustness. To ensure balanced evaluation across folds during model\nselection, we employed 10-fold stratified cross-validation on the training set,\nwhile signer-independent evaluation was carried out using held-out test data\nfrom unseen users U4 and U8. Results show that video transformer models\nsignificantly outperform traditional machine learning and deep learning\napproaches. Performance is influenced by factors such as dataset size, video\nquality, frame distribution, frame rate, and model architecture. Among the\nmodels, the VideoMAE variant (MCG-NJU/videomae-base-finetuned-kinetics)\nachieved the highest accuracies of 95.5% on the frame rate corrected BdSLW60\ndataset and 81.04% on the front-facing signs of BdSLW401 -- demonstrating\nstrong potential for scalable and accurate BdSL recognition.", "AI": {"title_translation": "为词级孟加拉手语微调视频Transformer：分类任务的比较分析", "tldr": "本研究通过在孟加拉手语数据集上微调VideoMAE、ViViT和TimeSformer等视频Transformer模型，旨在提高孟加拉手语识别的准确性和可扩展性，并取得了显著优于传统方法的性能。", "motivation": "手语识别（SLR）旨在自动识别和分类手语手势，并将其转换为文本或语音，以改善听障社区的可访问性。在孟加拉国，孟加拉手语（BdSL）是许多听障人士的主要交流方式。", "method": "本研究在BdSLW60（一个包含60个常见手语的小规模BdSL数据集）和BdSLW401（一个包含401个手语类别的大规模数据集）上微调了最先进的视频Transformer架构，包括VideoMAE、ViViT和TimeSformer。视频被标准化为30 FPS。为了评估可扩展性和鲁棒性，模型还在LSA64和WLASL等公共数据集上进行了基准测试。应用了随机裁剪、水平翻转和短边缩放等数据增强技术。采用10折分层交叉验证进行模型选择，并使用来自未见用户U4和U8的保留测试数据进行与手语者无关的评估。", "result": "结果表明，视频Transformer模型显著优于传统的机器学习和深度学习方法。性能受数据集大小、视频质量、帧分布、帧率和模型架构等因素影响。其中，VideoMAE变体（MCG-NJU/videomae-base-finetuned-kinetics）在帧率校正后的BdSLW60数据集上达到了95.5%的最高准确率，在BdSLW401的正面手语上达到了81.04%的准确率。", "conclusion": "本研究证明了视频Transformer模型在可扩展和准确的孟加拉手语识别方面的强大潜力，特别是VideoMAE变体。", "translation": "手语识别（SLR）涉及从图像或视频中自动识别和分类手势，并将其转换为文本或语音，以改善听障社区的可访问性。在孟加拉国，孟加拉手语（BdSL）是许多听障人士的主要交流方式。本研究在BdSLW60 (arXiv:2402.08635)（一个包含60个常见手语的小规模BdSL数据集）上微调了最先进的视频Transformer架构——VideoMAE、ViViT和TimeSformer。我们将视频标准化为30 FPS，产生了9,307个用户试用剪辑。为了评估可扩展性和鲁棒性，模型还在BdSLW401 (arXiv:2503.02360)（一个包含401个手语类别的大规模数据集）上进行了微调。此外，我们还针对LSA64和WLASL等公共数据集进行了性能基准测试。为了提高模型的鲁棒性，应用了随机裁剪、水平翻转和短边缩放等数据增强技术。为了确保模型选择期间跨折叠的平衡评估，我们在训练集上采用了10折分层交叉验证，同时使用来自未见用户U4和U8的保留测试数据进行了与手语者无关的评估。结果表明，视频Transformer模型显著优于传统的机器学习和深度学习方法。性能受数据集大小、视频质量、帧分布、帧率和模型架构等因素影响。在这些模型中，VideoMAE变体（MCG-NJU/videomae-base-finetuned-kinetics）在帧率校正后的BdSLW60数据集上达到了95.5%的最高准确率，在BdSLW401的正面手语上达到了81.04%的准确率——展示了其在可扩展和准确的BdSL识别方面的强大潜力。", "summary": "本研究致力于通过在孟加拉手语数据集（BdSLW60和BdSLW401）上微调VideoMAE、ViViT和TimeSformer等先进视频Transformer模型，来提高孟加拉手语（BdSL）识别的准确性和可扩展性，以改善听障人士的交流。研究发现，视频Transformer模型在手语识别任务中表现优异，显著超越了传统方法，其中VideoMAE变体在两个BdSL数据集上均取得了最高的识别准确率，展示了其在孟加拉手语识别方面的巨大潜力。", "keywords": "视频Transformer, 孟加拉手语, 手语识别, 微调, 分类任务"}}
{"id": "2506.05237", "pdf": "https://arxiv.org/pdf/2506.05237", "abs": "https://arxiv.org/abs/2506.05237", "authors": ["Victoria Palhares", "Sueda Taner", "Christoph Studer"], "title": "CSI2Vec: Towards a Universal CSI Feature Representation for Positioning and Channel Charting", "categories": ["cs.IT", "eess.SP", "math.IT"], "comment": "Submitted to a journal", "summary": "Natural language processing techniques, such as Word2Vec, have demonstrated\nexceptional capabilities in capturing semantic and syntactic relationships of\ntext through vector embeddings. Inspired by this technique, we propose CSI2Vec,\na self-supervised framework for generating universal and robust channel state\ninformation (CSI) representations tailored to CSI-based positioning (POS) and\nchannel charting (CC). CSI2Vec learns compact vector embeddings across various\nwireless scenarios, capturing spatial relationships between user equipment\npositions without relying on CSI reconstruction or ground-truth position\ninformation. We implement CSI2Vec as a neural network that is trained across\nvarious deployment setups (i.e., the spatial arrangement of radio equipment and\nscatterers) and radio setups (RSs) (i.e., the specific hardware used), ensuring\nrobustness to aspects such as differences in the environment, the number of\nused antennas, or allocated set of subcarriers. CSI2Vec abstracts the RS by\ngenerating compact vector embeddings that capture essential spatial\ninformation, avoiding the need for full CSI transmission or reconstruction\nwhile also reducing complexity and improving processing efficiency of\ndownstream tasks. Simulations with ray-tracing and real-world CSI datasets\ndemonstrate CSI2Vec's effectiveness in maintaining excellent POS and CC\nperformance while reducing computational demands and storage.", "AI": {"title_translation": "CSI2Vec: 面向定位和信道图的通用CSI特征表示", "tldr": "CSI2Vec是一种自监督框架，受Word2Vec启发，为基于CSI的定位和信道图生成通用且鲁棒的信道状态信息(CSI)表示，无需CSI重建或地面真实位置信息，并有效降低计算和存储需求。", "motivation": "传统的自然语言处理技术（如Word2Vec）在捕获文本的语义和句法关系方面表现出色。受此启发，本文旨在解决基于CSI的定位（POS）和信道图（CC）中，需要通用且鲁棒的CSI特征表示的问题，同时避免对CSI重建或地面真实位置信息的依赖，并降低计算复杂度和提高处理效率。", "method": "本文提出了CSI2Vec，一个自监督框架，用于生成针对CSI定位和信道图的通用且鲁棒的信道状态信息（CSI）表示。CSI2Vec通过学习紧凑的向量嵌入来捕获各种无线场景中的空间关系，无需依赖CSI重建或地面真实位置信息。它被实现为一个神经网络，在各种部署设置和无线电设置（RSs）下进行训练，以确保对环境差异、天线数量或子载波分配等方面的鲁棒性。CSI2Vec通过生成紧凑的向量嵌入来抽象RS，捕获必要的空间信息，避免了完整的CSI传输或重建需求，同时降低了下游任务的复杂性并提高了处理效率。", "result": "模拟（使用射线追踪）和真实世界的CSI数据集都表明，CSI2Vec在保持出色的定位（POS）和信道图（CC）性能的同时，显著降低了计算需求和存储开销。", "conclusion": "CSI2Vec成功地为CSI定位和信道图提供了一种通用、鲁棒且高效的CSI特征表示，有效降低了计算和存储成本。", "translation": "自然语言处理技术，例如Word2Vec，在通过向量嵌入捕获文本的语义和句法关系方面表现出了卓越的能力。受此技术的启发，我们提出了CSI2Vec，一个自监督框架，用于生成通用且鲁棒的信道状态信息（CSI）表示，专为基于CSI的定位（POS）和信道图（CC）量身定制。CSI2Vec在各种无线场景中学习紧凑的向量嵌入，捕获用户设备位置之间的空间关系，而无需依赖CSI重建或地面真实位置信息。我们将CSI2Vec实现为一个神经网络，它在各种部署设置（即无线电设备和散射体的空间排列）和无线电设置（RSs）（即使用的特定硬件）下进行训练，确保对环境差异、使用天线数量或分配的子载波集等方面的鲁棒性。CSI2Vec通过生成捕获基本空间信息的紧凑向量嵌入来抽象RS，避免了完整的CSI传输或重建需求，同时还降低了下游任务的复杂性并提高了处理效率。射线追踪和真实世界的CSI数据集的模拟证明了CSI2Vec在保持出色的POS和CC性能的同时，降低了计算需求和存储。", "summary": "CSI2Vec是一个受Word2Vec启发的自监督框架，旨在为基于CSI的定位（POS）和信道图（CC）生成通用且鲁棒的CSI特征表示。该方法通过学习紧凑的向量嵌入来捕获空间关系，无需CSI重建或地面真实位置信息。CSI2Vec作为神经网络在不同部署和无线电设置下训练，确保对环境变化的鲁棒性，并通过抽象无线电设置来减少复杂性并提高处理效率。模拟和真实世界数据集验证了CSI2Vec在保持高性能的同时，有效降低计算和存储需求。", "keywords": "CSI2Vec, 信道状态信息, 定位, 信道图, 特征表示"}}
{"id": "2506.04281", "pdf": "https://arxiv.org/pdf/2506.04281", "abs": "https://arxiv.org/abs/2506.04281", "authors": ["Xu Zheng", "Chaohao Lin", "Sipeng Chen", "Zhuomin Chen", "Jimeng Shi", "Wei Cheng", "Jayantha Obeysekera", "Jason Liu", "Dongsheng Luo"], "title": "SF$^2$Bench: Evaluating Data-Driven Models for Compound Flood Forecasting in South Florida", "categories": ["cs.LG"], "comment": "60 Pages", "summary": "Forecasting compound floods presents a significant challenge due to the\nintricate interplay of meteorological, hydrological, and oceanographic factors.\nAnalyzing compound floods has become more critical as the global climate\nincreases flood risks. Traditional physics-based methods, such as the\nHydrologic Engineering Center's River Analysis System, are often\ntime-inefficient. Machine learning has recently demonstrated promise in both\nmodeling accuracy and computational efficiency. However, the scarcity of\ncomprehensive datasets currently hinders systematic analysis. Existing\nwater-related datasets are often limited by a sparse network of monitoring\nstations and incomplete coverage of relevant factors. To address this\nchallenge, we introduce SF2Bench, a comprehensive time series collection on\ncompound floods in South Florida, which integrates four key factors: tide,\nrainfall, groundwater, and human management activities (gate and pump\ncontrolling). This integration allows for a more detailed analysis of the\nindividual contributions of these drivers to compound flooding and informs the\ndevelopment of improved flood forecasting approaches. To comprehensively\nevaluate the potential of various modeling paradigms, we assess the performance\nof six categories of methods, encompassing Multilayer Perceptrons,\nConvolutional Neural Networks, Recurrent Neural Networks, Graph Neural\nNetworks, Transformers, and Large Language Models. We verified the impact of\ndifferent key features on flood forecasting through experiments. Our analysis\nexamines temporal and spatial aspects, providing insights into the influence of\nhistorical data and spatial dependencies. The varying performance across these\napproaches underscores the diverse capabilities of each in capturing complex\ntemporal and spatial dependencies inherent in compound floods.", "AI": {"title_translation": "SF$^2$Bench: 评估佛罗里达州南部复合洪水预测的数据驱动模型", "tldr": "SF$^2$Bench是一个用于佛罗里达州南部复合洪水预测的综合数据集，用于评估各种数据驱动模型，以应对传统方法的低效和现有数据集的不足。", "motivation": "复合洪水预测因气象、水文和海洋因素的复杂相互作用而充满挑战，且全球气候变化加剧了洪水风险。传统物理方法效率低下，而机器学习虽有潜力，但缺乏全面的数据集，现有数据集也存在监测网络稀疏和相关因素覆盖不全的问题。", "method": "研究引入了SF$^2$Bench，一个整合了潮汐、降雨、地下水和人类管理活动（闸门和泵控制）的佛罗里达州南部复合洪水综合时间序列数据集。在此基础上，评估了六类数据驱动模型（包括多层感知机、卷积神经网络、循环神经网络、图神经网络、Transformer和大型语言模型）的性能，并验证了不同关键特征对洪水预测的影响，同时分析了时空依赖性。", "result": "分析考察了时间和空间方面，提供了对历史数据和空间依赖性影响的见解。不同数据驱动模型在捕捉复合洪水固有的复杂时间和空间依赖性方面表现出不同的能力。", "conclusion": "不同数据驱动模型在捕捉复合洪水复杂时空依赖性方面的多样化能力，为改进洪水预测方法提供了潜力。", "translation": "复合洪水预测由于气象、水文和海洋因素的复杂相互作用而面临重大挑战。随着全球气候增加洪水风险，分析复合洪水变得更加关键。传统的基于物理的方法，如水文工程中心河流分析系统，通常效率低下。机器学习最近在建模精度和计算效率方面都显示出前景。然而，目前综合数据集的稀缺阻碍了系统分析。现有的水相关数据集往往受限于稀疏的监测站网络和相关因素的不完全覆盖。为了应对这一挑战，我们引入了SF$^2$Bench，这是一个关于佛罗里达州南部复合洪水的综合时间序列集合，它整合了四个关键因素：潮汐、降雨、地下水和人类管理活动（闸门和泵控制）。这种整合允许对这些驱动因素对复合洪水的个体贡献进行更详细的分析，并为开发改进的洪水预测方法提供信息。为了全面评估各种建模范式的潜力，我们评估了六类方法的性能，包括多层感知机、卷积神经网络、循环神经网络、图神经网络、Transformer和大型语言模型。我们通过实验验证了不同关键特征对洪水预测的影响。我们的分析考察了时间和空间方面，提供了对历史数据和空间依赖性影响的见解。这些方法之间不同的性能强调了每种方法在捕获复合洪水固有的复杂时间和空间依赖性方面的不同能力。", "summary": "该论文介绍了SF$^2$Bench，一个用于佛罗里达州南部复合洪水预测的综合时间序列数据集，旨在解决现有数据集稀缺和传统物理模型效率低下的问题。SF$^2$Bench整合了潮汐、降雨、地下水和人类管理活动等关键因素。研究评估了包括多层感知机、卷积神经网络、循环神经网络、图神经网络、Transformer和大型语言模型在内的六类数据驱动模型的性能，并分析了不同特征对洪水预测的影响以及时空依赖性。结果表明，不同模型在捕捉复杂时空依赖性方面表现出不同的能力。", "keywords": "复合洪水预测, 数据驱动模型, SF$^2$Bench, 时间序列, 机器学习"}}
{"id": "2506.04975", "pdf": "https://arxiv.org/pdf/2506.04975", "abs": "https://arxiv.org/abs/2506.04975", "authors": ["Geng Liu", "Li Feng", "Carlo Alberto Bono", "Songbo Yang", "Mengxiao Zhu", "Francesco Pierri"], "title": "Evaluating Prompt-Driven Chinese Large Language Models: The Influence of Persona Assignment on Stereotypes and Safeguards", "categories": ["cs.CY"], "comment": null, "summary": "Recent research has highlighted that assigning specific personas to large\nlanguage models (LLMs) can significantly increase harmful content generation.\nYet, limited attention has been given to persona-driven toxicity in non-Western\ncontexts, particularly in Chinese-based LLMs. In this paper, we perform a\nlarge-scale, systematic analysis of how persona assignment influences refusal\nbehavior and response toxicity in Qwen, a widely-used Chinese language model.\nUtilizing fine-tuned BERT classifiers and regression analysis, our study\nreveals significant gender biases in refusal rates and demonstrates that\ncertain negative personas can amplify toxicity toward Chinese social groups by\nup to 60-fold compared to the default model. To mitigate this toxicity, we\npropose an innovative multi-model feedback strategy, employing iterative\ninteractions between Qwen and an external evaluator, which effectively reduces\ntoxic outputs without costly model retraining. Our findings emphasize the\nnecessity of culturally specific analyses for LLMs safety and offer a practical\nframework for evaluating and enhancing ethical alignment in LLM-generated\ncontent.", "AI": {"title_translation": "评估提示驱动的中文大型语言模型：角色分配对刻板印象和安全措施的影响", "tldr": "中文大型语言模型中的角色分配显著加剧了刻板印象和毒性，需要文化特异性安全措施。", "motivation": "现有研究已指出大型语言模型（LLM）中角色分配可能导致有害内容生成，但在非西方语境，特别是中文LLM中，对此类角色驱动的毒性关注不足。", "method": "本文对广泛使用的中文语言模型Qwen进行了大规模、系统性分析，研究角色分配如何影响其拒绝行为和响应毒性。研究中采用了微调的BERT分类器和回归分析。为缓解毒性，提出了一种创新的多模型反馈策略，通过Qwen与外部评估器之间的迭代交互来实现。", "result": "研究揭示了拒绝率中显著的性别偏见；某些负面角色可以将针对中国社会群体的毒性放大高达60倍；所提出的多模型反馈策略能够有效减少有毒输出，且无需昂贵的模型再训练。", "conclusion": "研究结果强调了对LLM安全进行文化特异性分析的必要性，并提供了一个评估和增强LLM生成内容伦理一致性的实用框架。", "translation": "最近的研究强调，为大型语言模型（LLM）分配特定角色可以显著增加有害内容的生成。然而，在非西方语境，特别是中文LLM中，对角色驱动的毒性关注有限。在本文中，我们对角色分配如何影响广泛使用的中文语言模型Qwen的拒绝行为和响应毒性进行了大规模、系统性的分析。我们的研究利用微调的BERT分类器和回归分析，揭示了拒绝率中显著的性别偏见，并表明与默认模型相比，某些负面角色可以将针对中国社会群体的毒性放大高达60倍。为了减轻这种毒性，我们提出了一种创新的多模型反馈策略，采用Qwen与外部评估器之间的迭代交互，有效减少了有毒输出，而无需昂贵的模型再训练。我们的研究结果强调了LLM安全中文化特定分析的必要性，并为评估和增强LLM生成内容的伦理一致性提供了实用的框架。", "summary": "本文系统分析了中文大型语言模型（Qwen）中角色分配如何影响其拒绝行为和响应毒性，发现显著的性别偏见以及某些负面角色可将毒性放大高达60倍。为减轻此问题，研究提出了一种创新的多模型反馈策略，能有效降低有毒输出。研究强调了文化特异性分析对LLM安全的重要性，并提供了一个实用的伦理校准框架。", "keywords": "LLM安全, 角色分配, 中文LLM, 毒性, 刻板印象"}}
{"id": "2506.04919", "pdf": "https://arxiv.org/pdf/2506.04919", "abs": "https://arxiv.org/abs/2506.04919", "authors": ["Fabien Dufoulon", "Gopal Pandurangan"], "title": "Improved Byzantine Agreement under an Adaptive Adversary", "categories": ["cs.DC", "cs.DS"], "comment": "PODC 2025, abstract shortened to fit arXiv constraints", "summary": "Byzantine agreement is a fundamental problem in fault-tolerant distributed\ncomputing that has been studied intensively for the last four decades. Much of\nthe research has focused on a static Byzantine adversary, where the adversary\nis constrained to choose the Byzantine nodes in advance of the protocol's\nexecution. This work focuses on the harder case of an adaptive Byzantine\nadversary that can choose the Byzantine nodes \\emph{adaptively} based on the\nprotocol's execution. While efficient $O(\\log n)$-round protocols ($n$ is the\ntotal number of nodes) are known for the static adversary (Goldwasser, Pavlov,\nand Vaikuntanathan, FOCS 2006) tolerating up to $t < n/(3+\\epsilon)$ Byzantine\nnodes, $\\Omega(t/\\sqrt{n \\log n})$ rounds is a well-known lower bound for\nadaptive adversary [Bar-Joseph and Ben-Or, PODC 1998]. The best-known protocol\nfor adaptive adversary runs in $O(t/\\log n)$ rounds [Chor and Coan, IEEE Trans.\nSoft. Engg., 1985].\n  This work presents a synchronous randomized Byzantine agreement protocol\nunder an adaptive adversary that improves over previous results. Our protocol\nworks under the powerful \\emph{adaptive rushing adversary in the full\ninformation model}. That is, we assume that the Byzantine nodes can behave\narbitrarily and maliciously, have knowledge about the entire state of the\nnetwork at every round, including random choices made by all the nodes up to\nand including the current round, have unlimited computational power, and may\ncollude among themselves. Furthermore, the adversary can \\emph{adaptively}\ncorrupt up to $t < n/3$ nodes based on the protocol's execution. We present a\nsimple randomized Byzantine agreement protocol that runs in $O(\\min\\{t^2\\log\nn/n, t/\\log n\\})$ rounds that improves over the long-standing bound of\n$O(t/\\log n)$ rounds due to Chor and Coan [IEEE Trans. Soft. Engg., 1985].", "AI": {"title_translation": "自适应敌手下的改进拜占庭协议", "tldr": "本文提出了一种在自适应敌手下改进的拜占庭协议，其轮复杂度优于现有结果。", "motivation": "拜占庭协议是容错分布式计算中的一个基本问题。以往的研究大多集中在静态拜占庭敌手，即敌手在协议执行前选择拜占庭节点。然而，自适应拜占庭敌手更具挑战性，它们可以根据协议的执行自适应地选择拜占庭节点。针对自适应敌手，现有协议的轮复杂度（O(t/log n)）远高于静态敌手（O(log n)），并且存在一个长期未被打破的下界。本文旨在改进这一现状。", "method": "本文提出了一种在“全信息模型下的强大自适应冲刺敌手”模型下的同步随机拜占庭协议。该协议假设拜占庭节点可以任意恶意行为，在每一轮都了解网络的完整状态（包括所有节点当前的随机选择），拥有无限计算能力，并可以相互串通。此外，敌手可以根据协议的执行自适应地腐化多达 t < n/3 的节点。", "result": "本文提出的简单随机拜占庭协议在 O(min{t^2log n/n, t/log n}) 轮内运行，这改进了 Chor 和 Coan（1985）提出的 O(t/log n) 的长期界限。", "conclusion": "本文成功地提高了自适应敌手下拜占庭协议的轮复杂度，突破了长期存在的性能瓶颈。", "translation": "拜占庭协议是容错分布式计算中的一个基本问题，在过去四十年中得到了深入研究。大部分研究都集中在静态拜占庭敌手，即敌手在协议执行前被限制选择拜占庭节点。这项工作关注更困难的自适应拜占庭敌手情况，即敌手可以根据协议的执行“自适应地”选择拜占庭节点。虽然对于静态敌手，已知存在高效的 O(log n) 轮协议（n 是节点总数）（Goldwasser, Pavlov, and Vaikuntanathan, FOCS 2006），可以容忍多达 t < n/(3+epsilon) 个拜占庭节点，但对于自适应敌手，Ω(t/√n log n) 轮是一个众所周知的下界 [Bar-Joseph and Ben-Or, PODC 1998]。目前已知针对自适应敌手的最佳协议在 O(t/log n) 轮内运行 [Chor and Coan, IEEE Trans. Soft. Engg., 1985]。\n这项工作提出了一种在自适应敌手下的同步随机拜占庭协议，改进了以前的结果。我们的协议在强大的“全信息模型下的自适应冲刺敌手”下工作。也就是说，我们假设拜占庭节点可以任意恶意行为，在每一轮都了解网络的完整状态，包括所有节点直到并包括当前轮的随机选择，拥有无限计算能力，并且可以相互串通。此外，敌手可以“自适应地”腐化多达 t < n/3 的节点，基于协议的执行。我们提出了一种简单的随机拜占庭协议，它在 O(min{t^2log n/n, t/log n}) 轮内运行，这改进了 Chor 和 Coan [IEEE Trans. Soft. Engg., 1985] 提出的 O(t/log n) 的长期界限。", "summary": "本文提出了一种新的同步随机拜占庭协议，显著提高了自适应敌手下的轮复杂度。与主要关注静态敌手的前期工作不同，本研究解决了敌手可以在全信息模型下自适应地腐化节点的更具挑战性的场景。所提出的协议实现了 O(min{t^2log n/n, t/log n}) 的改进轮复杂度，超越了长期存在的 O(t/log n) 界限。", "keywords": "拜占庭协议, 自适应敌手, 分布式计算, 轮复杂度, 容错"}}
{"id": "2506.04963", "pdf": "https://arxiv.org/pdf/2506.04963", "abs": "https://arxiv.org/abs/2506.04963", "authors": ["Anton Firc", "Jan Klusáček", "Kamil Malinka"], "title": "Hiding in Plain Sight: Query Obfuscation via Random Multilingual Searches", "categories": ["cs.CR", "94A60, 68P27", "H.3.3; H.3.5; K.4.1"], "comment": "Accepted to TrustBus workshop of ARES 2025", "summary": "Modern search engines extensively personalize results by building detailed\nuser profiles based on query history and behaviour. While personalization can\nenhance relevance, it introduces privacy risks and can lead to filter bubbles.\nThis paper proposes and evaluates a lightweight, client-side query obfuscation\nstrategy using randomly generated multilingual search queries to disrupt user\nprofiling. Through controlled experiments on the Seznam.cz search engine, we\nassess the impact of interleaving real queries with obfuscating noise in\nvarious language configurations and ratios. Our findings show that while\ndisplayed search results remain largely stable, the search engine's identified\nuser interests shift significantly under obfuscation. We further demonstrate\nthat such random queries can prevent accurate profiling and overwrite\nestablished user profiles. This study provides practical evidence for query\nobfuscation as a viable privacy-preserving mechanism and introduces a tool that\nenables users to autonomously protect their search behaviour without modifying\nexisting infrastructure.", "AI": {"title_translation": "隐藏在众目睽睽之下：通过随机多语言搜索进行查询混淆", "tldr": "本文提出并评估了一种轻量级的客户端查询混淆策略，通过随机生成多语言搜索查询来扰乱用户画像，从而保护搜索隐私。", "motivation": "现代搜索引擎通过查询历史和行为建立详细的用户画像来个性化结果，这虽然能提高相关性，但也引入了隐私风险并可能导致过滤气泡。", "method": "本文提出并评估了一种轻量级的客户端查询混淆策略，该策略使用随机生成的多语言搜索查询来扰乱用户画像。通过在Seznam.cz搜索引擎上进行受控实验，评估了在各种语言配置和比例下，将真实查询与混淆噪声交错的影响。", "result": "研究结果表明，在混淆下，显示的搜索结果基本保持稳定，但搜索引擎识别的用户兴趣显著转移。研究进一步证明，这种随机查询可以阻止准确的用户画像建立并覆盖已有的用户画像。", "conclusion": "这项研究为查询混淆作为一种可行的隐私保护机制提供了实践证据，并引入了一种工具，使用户无需修改现有基础设施即可自主保护其搜索行为。", "translation": "现代搜索引擎通过基于查询历史和行为构建详细的用户画像来广泛地个性化结果。虽然个性化可以提高相关性，但它引入了隐私风险并可能导致过滤气泡。本文提出并评估了一种轻量级的客户端查询混淆策略，通过随机生成多语言搜索查询来扰乱用户画像。通过在Seznam.cz搜索引擎上进行受控实验，我们评估了在各种语言配置和比例下，将真实查询与混淆噪声交错的影响。我们的研究结果表明，虽然显示的搜索结果基本保持稳定，但搜索引擎识别的用户兴趣在混淆下显著转移。我们进一步证明，这种随机查询可以阻止准确的用户画像建立并覆盖已有的用户画像。这项研究为查询混淆作为一种可行的隐私保护机制提供了实践证据，并引入了一种工具，使用户无需修改现有基础设施即可自主保护其搜索行为。", "summary": "本研究提出了一种客户端查询混淆策略，通过插入随机多语言查询来对抗搜索引擎的用户画像构建，以保护用户隐私并避免过滤气泡。实验证明该方法能在不显著影响搜索结果显示的情况下，有效改变搜索引擎识别的用户兴趣，并阻止或覆盖用户画像。", "keywords": "查询混淆, 隐私保护, 用户画像, 多语言搜索, 客户端策略"}}
{"id": "2506.04577", "pdf": "https://arxiv.org/pdf/2506.04577", "abs": "https://arxiv.org/abs/2506.04577", "authors": ["Farshad Haghgoo Daryakenari", "Tara Farizeh"], "title": "A Novel Transformer-Based Method for Full Lower-Limb Joint Angles and Moments Prediction in Gait Using sEMG and IMU data", "categories": ["cs.RO"], "comment": "10 pages, 4 figures", "summary": "This study presents a transformer-based deep learning framework for the\nlong-horizon prediction of full lower-limb joint angles and joint moments using\nsurface electromyography (sEMG) and inertial measurement unit (IMU) signals.\nTwo separate Transformer Neural Networks (TNNs) were designed: one for\nkinematic prediction and one for kinetic prediction. The model was developed\nwith real-time application in mind, using only wearable sensors suitable for\noutside-laboratory use. Two prediction horizons were considered to evaluate\nshort- and long-term performance. The network achieved high accuracy in both\ntasks, with Spearman correlation coefficients exceeding 0.96 and R-squared\nscores above 0.92 across all joints. Notably, the model consistently\noutperformed a recent benchmark method in joint angle prediction, reducing RMSE\nerrors by an order of magnitude. The results confirmed the complementary role\nof sEMG and IMU signals in capturing both kinematic and kinetic information.\nThis work demonstrates the potential of transformer-based models for real-time,\nfull-limb biomechanical prediction in wearable and robotic applications, with\nfuture directions including input minimization and modality-specific weighting\nstrategies to enhance model efficiency and accuracy.", "AI": {"title_translation": "一种基于Transformer的步态下肢关节角度和力矩预测新方法，利用sEMG和IMU数据", "tldr": "本研究提出了一种基于Transformer的深度学习框架，利用可穿戴sEMG和IMU信号，高精度地实时预测下肢关节角度和力矩，并在性能上超越了现有基准方法。", "motivation": "为了实现可穿戴和机器人应用中实时、全肢体生物力学预测，需要开发一种在实验室外也能使用的，仅依靠可穿戴传感器进行步态分析的方法。", "method": "本研究提出了一种基于Transformer的深度学习框架，利用表面肌电图（sEMG）和惯性测量单元（IMU）信号。设计了两个独立的Transformer神经网络（TNNs），分别用于运动学和动力学预测，并考虑了短时和长时预测。", "result": "该网络在运动学和动力学预测任务中均取得了高精度，所有关节的Spearman相关系数均超过0.96，R方得分高于0.92。该模型在关节角度预测方面持续优于近期基准方法，RMSE误差降低了一个数量级。结果证实了sEMG和IMU信号在捕获运动学和动力学信息方面的互补作用。", "conclusion": "本工作证明了基于Transformer的模型在可穿戴和机器人应用中进行实时、全肢体生物力学预测的潜力。", "translation": "本研究提出了一种基于Transformer的深度学习框架，用于利用表面肌电图（sEMG）和惯性测量单元（IMU）信号对下肢关节角度和关节力矩进行长时程预测。设计了两个独立的Transformer神经网络（TNNs）：一个用于运动学预测，一个用于动力学预测。该模型在开发时考虑了实时应用，仅使用适合实验室外使用的可穿戴传感器。考虑了两个预测时程来评估短期和长期性能。该网络在两项任务中均取得了高精度，所有关节的Spearman相关系数均超过0.96，R方得分高于0.92。值得注意的是，该模型在关节角度预测方面始终优于近期基准方法，将RMSE误差降低了一个数量级。结果证实了sEMG和IMU信号在捕获运动学和动力学信息方面的互补作用。这项工作证明了基于Transformer的模型在可穿戴和机器人应用中进行实时、全肢体生物力学预测的潜力，未来的方向包括输入最小化和模态特定加权策略，以提高模型效率和准确性。", "summary": "本研究开发了一种新型的基于Transformer的深度学习框架，利用sEMG和IMU可穿戴传感器数据，实现了对人体步态中下肢关节角度和力矩的长期高精度预测。该框架包含两个独立的Transformer神经网络，分别处理运动学和动力学预测任务。实验结果表明，该模型在所有关节上的预测精度高，并且在关节角度预测方面显著优于现有基准方法，验证了sEMG和IMU信号在生物力学信息捕获中的互补性。这项工作展示了Transformer模型在实时、可穿戴和机器人生物力学预测领域的巨大应用前景。", "keywords": "Transformer, sEMG, IMU, 步态分析, 关节角度, 关节力矩"}}
{"id": "2506.04989", "pdf": "https://arxiv.org/pdf/2506.04989", "abs": "https://arxiv.org/abs/2506.04989", "authors": ["Dumitran Adrian Marius", "Dita Radu"], "title": "BacPrep: An Experimental Platform for Evaluating LLM-Based Bacalaureat Assessment", "categories": ["cs.SE"], "comment": "9 pages Preprint ACCEPTED at BBGI (ITS Workshop)", "summary": "Accessing quality preparation and feedback for the Romanian Bacalaureat exam\nis challenging, particularly for students in remote or underserved areas. This\npaper introduces BacPrep, an experimental online platform exploring Large\nLanguage Model (LLM) potential for automated assessment, aiming to offer a\nfree, accessible resource. Using official exam questions from the last 5 years,\nBacPrep employs one of Google's newest models, Gemini 2.0 Flash (released Feb\n2025), guided by official grading schemes, to provide experimental feedback.\nCurrently operational, its primary research function is collecting student\nsolutions and LLM outputs. This focused dataset is vital for planned expert\nvalidation to rigorously evaluate the feasibility and accuracy of this\ncutting-edge LLM in the specific Bacalaureat context before reliable\ndeployment. We detail the design, data strategy, status, validation plan, and\nethics.", "AI": {"title_translation": "BacPrep：一个用于评估基于LLM的学士学位考试评估的实验平台", "tldr": "BacPrep是一个实验性在线平台，利用LLM（Gemini 2.0 Flash）为罗马尼亚学士学位考试提供自动评估和反馈，旨在解决偏远地区学生备考资源不足的问题。", "motivation": "罗马尼亚学士学位考试的优质备考和反馈难以获得，特别是对于偏远或服务不足地区的学生。", "method": "BacPrep是一个在线实验平台，它利用过去5年的官方考试问题，并使用Google最新的模型Gemini 2.0 Flash（2025年2月发布），根据官方评分方案提供实验性反馈。", "result": "平台目前正在运行，主要研究功能是收集学生解决方案和LLM输出。这个重点数据集对于计划中的专家验证至关重要，以便在可靠部署之前严格评估LLM在特定学士学位考试背景下的可行性和准确性。", "conclusion": "论文详细介绍了设计、数据策略、现状、验证计划和伦理，旨在验证LLM在特定学士学位考试背景下的可行性和准确性，以期未来可靠部署。", "translation": "访问罗马尼亚学士学位考试的优质备考和反馈具有挑战性，特别是对于偏远或服务不足地区的学生。本文介绍了BacPrep，一个探索大型语言模型（LLM）在自动化评估方面潜力的实验性在线平台，旨在提供一个免费、可访问的资源。BacPrep使用过去5年的官方考试问题，采用Google最新的模型Gemini 2.0 Flash（2025年2月发布），并根据官方评分方案提供实验性反馈。该平台目前正在运行，其主要研究功能是收集学生解决方案和LLM输出。这个重点数据集对于计划中的专家验证至关重要，以便在可靠部署之前严格评估这种尖端LLM在特定学士学位考试背景下的可行性和准确性。我们详细介绍了设计、数据策略、状态、验证计划和伦理。", "summary": "BacPrep是一个实验性在线平台，旨在利用大型语言模型（LLM），特别是Google的Gemini 2.0 Flash，为罗马尼亚学士学位考试提供自动评估和反馈。该平台使用过去五年的官方试题，并根据官方评分方案提供指导性反馈。目前，BacPrep正在收集学生答案和LLM输出的数据集，以进行专家验证，从而评估LLM在此特定考试背景下的可行性和准确性，最终目标是提供免费且可访问的备考资源。", "keywords": "LLM, Bacalaureat, 自动化评估, 实验平台, Gemini 2.0 Flash"}}
{"id": "2506.04427", "pdf": "https://arxiv.org/pdf/2506.04427", "abs": "https://arxiv.org/abs/2506.04427", "authors": ["Xixi Wang", "Miguel Costa", "Jordanka Kovaceva", "Shuai Wang", "Francisco C. Pereira"], "title": "Plugging Schema Graph into Multi-Table QA: A Human-Guided Framework for Reducing LLM Reliance", "categories": ["cs.AI", "cs.CL"], "comment": "Submitted to EMNLP 2025", "summary": "Large language models (LLMs) have shown promise in table Question Answering\n(Table QA). However, extending these capabilities to multi-table QA remains\nchallenging due to unreliable schema linking across complex tables. Existing\nmethods based on semantic similarity work well only on simplified hand-crafted\ndatasets and struggle to handle complex, real-world scenarios with numerous and\ndiverse columns. To address this, we propose a graph-based framework that\nleverages human-curated relational knowledge to explicitly encode schema links\nand join paths. Given a natural language query, our method searches this graph\nto construct interpretable reasoning chains, aided by pruning and sub-path\nmerging strategies to enhance efficiency and coherence. Experiments on both\nstandard benchmarks and a realistic, large-scale dataset demonstrate the\neffectiveness of our approach. To our knowledge, this is the first multi-table\nQA system applied to truly complex industrial tabular data.", "AI": {"title_translation": "将模式图引入多表问答：一种减少LLM依赖的人工引导框架", "tldr": "本文提出了一种人工引导的图基框架，用于多表问答，通过显式编码模式链接和连接路径来减少对大型语言模型的依赖，并在复杂数据集上证明了其有效性。", "motivation": "大型语言模型（LLMs）在多表问答（Multi-Table QA）中面临挑战，因为复杂表格之间的模式链接不可靠。现有的基于语义相似性的方法仅在简化的手工数据集上表现良好，难以处理具有大量多样化列的复杂真实世界场景。", "method": "本文提出了一种基于图的框架，利用人工整理的关系知识来显式编码模式链接和连接路径。给定一个自然语言查询，该方法通过剪枝和子路径合并策略来增强效率和连贯性，搜索该图以构建可解释的推理链。", "result": "在标准基准测试和真实的、大规模数据集上的实验证明了我们方法的有效性。据我们所知，这是第一个应用于真正复杂工业表格数据的多表问答系统。", "conclusion": "本文提出的以人为引导的图基框架通过显式编码模式链接和连接路径，有效解决了多表问答在复杂真实世界场景中的挑战，减少了对大型语言模型的依赖，并提高了模式链接的可靠性。", "translation": "大型语言模型（LLMs）在表格问答（Table QA）中展现出潜力。然而，由于复杂表格之间不可靠的模式链接，将这些能力扩展到多表问答仍然具有挑战性。现有的基于语义相似性的方法仅在简化的手工数据集上表现良好，难以处理具有大量多样化列的复杂真实世界场景。为了解决这个问题，我们提出了一种基于图的框架，该框架利用人工整理的关系知识来显式编码模式链接和连接路径。给定一个自然语言查询，我们的方法搜索该图以构建可解释的推理链，并辅以剪枝和子路径合并策略以提高效率和连贯性。在标准基准测试和真实的、大规模数据集上的实验证明了我们方法的有效性。据我们所知，这是第一个应用于真正复杂工业表格数据的多表问答系统。", "summary": "本文提出了一种人工引导的图基框架，用于解决多表问答中大型语言模型在处理复杂、真实世界表格数据时面临的模式链接不可靠问题。该框架利用人工整理的关系知识，显式编码模式链接和连接路径，并结合剪枝和子路径合并策略来构建高效且连贯的可解释推理链。实验结果表明，该方法在标准基准测试和大规模工业数据集上均表现出有效性，是首个应用于复杂工业表格数据的多表问答系统。", "keywords": "多表问答, 模式图, 人工引导, 知识图谱, LLM依赖"}}
{"id": "2506.04379", "pdf": "https://arxiv.org/pdf/2506.04379", "abs": "https://arxiv.org/abs/2506.04379", "authors": ["Matthew W. Shinkle", "Mark D. Lescroart"], "title": "Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization", "categories": ["cs.CV", "cs.AI", "q-bio.NC"], "comment": "Accepted to the Mechanistic Interpretability for Vision (MIV)\n  Workshop at the 2025 Conference on Computer Vision and Pattern Recognition\n  (CVPR) conference", "summary": "Deep neural networks (DNNs) trained on visual tasks develop feature\nrepresentations that resemble those in the human visual system. Although\nDNN-based encoding models can accurately predict brain responses to visual\nstimuli, they offer limited insight into the specific features driving these\nresponses. Here, we demonstrate that activation maximization -- a technique\ndesigned to interpret vision DNNs -- can be applied to DNN-based encoding\nmodels of the human brain. We extract and adaptively downsample activations\nfrom multiple layers of a pretrained Inception V3 network, then use linear\nregression to predict fMRI responses. This yields a full image-computable model\nof brain responses. Next, we apply activation maximization to generate images\noptimized for predicted responses in individual cortical voxels. We find that\nthese images contain visual characteristics that qualitatively correspond with\nknown selectivity and enable exploration of selectivity across the visual\ncortex. We further extend our method to whole regions of interest (ROIs) of the\nbrain and validate its efficacy by presenting these images to human\nparticipants in an fMRI study. We find that the generated images reliably drive\nactivity in targeted regions across both low- and high-level visual areas and\nacross subjects. These results demonstrate that activation maximization can be\nsuccessfully applied to DNN-based encoding models. By addressing key\nlimitations of alternative approaches that require natively generative models,\nour approach enables flexible characterization and modulation of responses\nacross the human visual system.", "AI": {"title_translation": "使用体素加权激活最大化技术可视化和控制皮层反应", "tldr": "本研究展示了如何将激活最大化技术应用于基于深度神经网络的人脑编码模型，以生成可预测皮层反应的图像，并成功验证了这些图像能够可靠地驱动目标区域的活动，从而实现对人脑视觉系统反应的灵活表征和调节。", "motivation": "尽管基于深度神经网络的编码模型可以准确预测大脑对视觉刺激的反应，但它们对驱动这些反应的特定特征的洞察力有限。", "method": "本研究将激活最大化技术应用于人脑的基于深度神经网络的编码模型。具体方法包括：从预训练的Inception V3网络的多个层中提取并自适应地降采样激活，然后使用线性回归预测fMRI反应，从而构建一个完整的图像可计算的大脑反应模型。接着，应用激活最大化技术生成针对单个皮层体素的预测反应优化的图像，并将该方法扩展到大脑的整个感兴趣区域（ROIs）。最后，通过fMRI研究向人类参与者呈现这些图像来验证其有效性。", "result": "研究发现，生成的图像包含与已知选择性定性对应的视觉特征，并能够探索整个视觉皮层的选择性。此外，生成的图像能够可靠地驱动低级和高级视觉区域以及不同受试者中目标区域的活动。", "conclusion": "激活最大化技术可以成功应用于基于深度神经网络的编码模型，该方法解决了需要原生生成模型的替代方法的关键限制，从而能够灵活地表征和调节人脑视觉系统中的反应。", "translation": "深度神经网络（DNNs）在视觉任务上训练后，会发展出类似于人类视觉系统的特征表示。尽管基于DNN的编码模型可以准确预测大脑对视觉刺激的反应，但它们对驱动这些反应的特定特征提供的洞察有限。在此，我们证明了激活最大化——一种旨在解释视觉DNNs的技术——可以应用于基于DNN的人脑编码模型。我们从预训练的Inception V3网络的多个层中提取并自适应地降采样激活，然后使用线性回归预测fMRI反应。这产生了一个完整图像可计算的大脑反应模型。接下来，我们应用激活最大化技术生成针对单个皮层体素的预测反应优化的图像。我们发现这些图像包含的视觉特征与已知的选择性在定性上相符，并能够探索整个视觉皮层的选择性。我们进一步将我们的方法扩展到大脑的整个感兴趣区域（ROIs），并通过在fMRI研究中向人类参与者呈现这些图像来验证其有效性。我们发现，生成的图像在低级和高级视觉区域以及不同受试者中都能可靠地驱动目标区域的活动。这些结果表明，激活最大化可以成功应用于基于DNN的编码模型。通过解决需要原生生成模型的替代方法的关键限制，我们的方法能够灵活地表征和调节整个人脑视觉系统中的反应。", "summary": "本研究探索了将激活最大化技术应用于基于深度神经网络（DNN）的人脑视觉系统编码模型，以克服现有DNN编码模型在解释驱动大脑反应的特定特征方面的局限性。研究人员通过提取和降采样Inception V3网络的激活，并结合线性回归来预测fMRI反应，构建了一个图像可计算的大脑反应模型。随后，利用激活最大化技术生成了针对特定皮层体素和感兴趣区域优化的图像。实验结果表明，这些生成的图像不仅包含与已知视觉选择性相符的特征，而且在fMRI研究中能有效驱动目标视觉区域的活动。这证明了激活最大化技术在理解和调节人脑视觉反应方面的潜力，为灵活表征和调制人脑视觉系统反应提供了新途径。", "keywords": "激活最大化, 深度神经网络, 脑编码模型, 视觉皮层, fMRI"}}
{"id": "2501.07182", "pdf": "https://arxiv.org/pdf/2501.07182", "abs": "https://arxiv.org/abs/2501.07182", "authors": ["Rozin Hasin"], "title": "Unveiling Voices: A Co-Hashtag Analysis of TikTok Discourse on the 2023 Israel-Palestine Crisis", "categories": ["cs.SI", "cs.CY", "cs.HC", "cs.IT", "cs.MM", "math.IT"], "comment": null, "summary": "TikTok has gradually become one of the most pervasive social media platforms\nin our daily lives. While much can be said about the merits of platforms such\nas TikTok, there is a different kind of attention paid towards the political\naffect of social media today compared to its impact on other aspects of modern\nnetworked reality. I explored how users on TikTok discussed the crisis in\nPalestine that worsened in 2023. Using network analysis, I situate keywords\nrepresenting the conflict and categorize them thematically based on a coding\nschema derived from politically and ideologically differentiable stances. I\nconclude that activism and propaganda are contending amongst themselves in the\nthriving space afforded by TikTok today.", "AI": {"title_translation": "揭示声音：2023年以色列-巴勒斯坦危机TikTok话语的共同话题标签分析", "tldr": "TikTok上关于2023年以色列-巴勒斯坦危机的话语中，行动主义与宣传正在竞争。", "motivation": "探讨TikTok用户如何讨论2023年恶化的巴勒斯坦危机，因为社交媒体的政治影响受到了特别关注。", "method": "使用网络分析，定位代表冲突的关键词，并根据政治和意识形态上可区分的立场导出的编码方案进行主题分类。", "result": "行动主义和宣传在TikTok提供的活跃空间中相互竞争。", "conclusion": "行动主义和宣传在TikTok上关于2023年以色列-巴勒斯坦危机的话语中并存且竞争。", "translation": "TikTok已逐渐成为我们日常生活中最普遍的社交媒体平台之一。尽管关于TikTok等平台的优点有很多可说之处，但与社交媒体对现代网络现实其他方面的影响相比，如今人们对社交媒体的政治影响给予了不同寻常的关注。我探讨了TikTok用户如何讨论2023年恶化的巴勒斯坦危机。我使用网络分析，定位了代表冲突的关键词，并根据源自政治和意识形态可区分立场的编码方案对其进行了主题分类。我得出结论，行动主义和宣传正在当今TikTok提供的蓬勃发展的空间中相互竞争。", "summary": "本研究分析了TikTok用户如何讨论2023年恶化的巴勒斯坦危机。通过网络分析，研究者定位了冲突相关关键词并根据政治和意识形态立场进行主题分类。结果显示，在TikTok平台提供的活跃空间中，行动主义和宣传正在相互竞争。", "keywords": "TikTok, 以色列-巴勒斯坦危机, 共同话题标签分析, 社交媒体, 网络分析"}}
{"id": "2506.04282", "pdf": "https://arxiv.org/pdf/2506.04282", "abs": "https://arxiv.org/abs/2506.04282", "authors": ["Runxiang Wang", "Boxiao Wang", "Kai Li", "Yifan Zhang", "Jian Cheng"], "title": "DrSR: LLM based Scientific Equation Discovery with Dual Reasoning from Data and Experience", "categories": ["cs.LG"], "comment": null, "summary": "Symbolic regression is a fundamental tool for discovering interpretable\nmathematical expressions from data, with broad applications across scientific\nand engineering domains. Recently, large language models (LLMs) have\ndemonstrated strong performance in this task, leveraging embedded scientific\npriors and reasoning capabilities to surpass traditional methods. However,\nexisting LLM-based approaches, such as LLM-SR, often over-rely on internal\npriors, lacking explicit data understanding and systematic reflection during\nequation generation. To address these limitations, we propose DrSR (Dual\nReasoning Symbolic Regression), a framework that combines data-driven insight\nwith reflective learning to enhance both robustness and discovery capability.\nSpecifically, DrSR guides LLMs to analyze structural relationships (e.g.,\nmonotonicity, nonlinearity, and correlation) within the data to generate\nstructured descriptions. Simultaneously, it monitors equation performance and\nestablishes a feedback loop to refine subsequent generations. By integrating\ndata understanding and generation reflection in a closed loop, DrSR enables\nmore efficient exploration of the symbolic expression space. Experiments across\ninterdisciplinary datasets in physics, chemistry, biology, and materials\nscience demonstrate that DrSR substantially improves the valid equation rate\nand consistently outperforms both classical and recent LLM-based methods in\nterms of accuracy, generalization, and search efficiency. These results\nunderscore its potential for scientific equation discovery.", "AI": {"title_translation": "DrSR：基于LLM的科学方程发现，结合数据和经验的双重推理", "tldr": "DrSR通过结合数据分析和反馈循环的双重推理，显著提升了LLM在科学方程发现中的准确性和效率。", "motivation": "现有基于LLM的符号回归方法（如LLM-SR）过度依赖内部先验知识，缺乏对数据的显式理解和方程生成过程中的系统性反思，导致鲁棒性和发现能力受限。", "method": "提出DrSR框架，结合数据驱动的洞察和反思性学习。具体而言，DrSR引导LLM分析数据中的结构关系（如单调性、非线性、相关性）以生成结构化描述，同时监测方程性能并建立反馈循环以改进后续生成。通过闭环整合数据理解和生成反思，DrSR能够更有效地探索符号表达式空间。", "result": "DrSR显著提高了有效方程率，并在物理、化学、生物学和材料科学等跨学科数据集上，在准确性、泛化性和搜索效率方面持续优于经典方法和最新的基于LLM的方法。", "conclusion": "DrSR在科学方程发现方面具有巨大潜力。", "translation": "符号回归是根据数据发现可解释数学表达式的基本工具，在科学和工程领域具有广泛应用。最近，大型语言模型（LLM）在此任务中表现出强大的性能，利用嵌入的科学先验知识和推理能力超越了传统方法。然而，现有基于LLM的方法，如LLM-SR，往往过度依赖内部先验知识，缺乏对数据的显式理解和方程生成过程中的系统性反思。为了解决这些局限性，我们提出了DrSR（双重推理符号回归）框架，它结合了数据驱动的洞察和反思性学习，以增强鲁棒性和发现能力。具体而言，DrSR引导LLM分析数据中的结构关系（例如，单调性、非线性、相关性）以生成结构化描述。同时，它监测方程性能并建立反馈循环以改进后续生成。通过在闭环中整合数据理解和生成反思，DrSR能够更有效地探索符号表达式空间。在物理、化学、生物学和材料科学等跨学科数据集上的实验表明，DrSR显著提高了有效方程率，并在准确性、泛化性和搜索效率方面持续优于经典方法和最新的基于LLM的方法。这些结果强调了其在科学方程发现方面的潜力。", "summary": "DrSR是一种新型的基于LLM的符号回归框架，旨在解决现有LLM方法过度依赖内部先验和缺乏数据理解的问题。它通过结合数据驱动的结构关系分析和生成反馈循环的双重推理，提高了科学方程发现的鲁棒性、准确性、泛化性和搜索效率，并在多个科学领域数据集上表现出色。", "keywords": "符号回归, 大型语言模型, 方程发现, 双重推理, 数据分析"}}
{"id": "2506.05086", "pdf": "https://arxiv.org/pdf/2506.05086", "abs": "https://arxiv.org/abs/2506.05086", "authors": ["Francesco Corso", "Giuseppe Russo", "Francesco Pierri", "Gianmarco De Francisci Morales"], "title": "Early linguistic fingerprints of online users who engage with conspiracy communities", "categories": ["cs.SI", "cs.CY"], "comment": null, "summary": "Online social media platforms are often seen as catalysts for radicalization,\nas they provide spaces where extreme beliefs can take root and spread,\nsometimes leading to real-world consequences. Conspiracy theories represent a\nspecific form of radicalization that is notoriously resistant to online\nmoderation strategies. One explanation for this resilience is the presence of a\n\"conspiratorial mindset\", a cognitive framework that fundamentally shapes how\nconspiracy believers perceive reality. However, the role of this mindset in\ndriving online user behavior remains poorly understood. In this study, we\nanalyze the psycholinguistic patterns of Reddit users who become active in a\nprominent conspiracy community by examining their activity in mainstream\ncommunities, which allows us to isolate linguistic markers for the presence of\na conspiratorial mindset. We find that conspiracy-engaged individuals exhibit\ndistinct psycholinguistic fingerprints, setting them apart from the general\nuser population. Crucially, this signal is already evident in their online\nactivity prior to joining the conspiracy community, allowing us to predict\ntheir involvement years in advance. These findings suggest that individuals who\nadopt conspiracy beliefs do not radicalize through community involvement, but\npossess a pre-existing conspiratorial mindset, which predisposes them to seek\nout and join extreme communities. By challenging the view that online social\nmedia platforms actively radicalize users into conspiracy theory beliefs, our\nfindings suggest that standard moderation strategies have limited impact on\ncurbing radicalization, and highlight the need for more targeted, supportive\ninterventions that encourage disengagement from extremist narratives.\nUltimately, this work contributes to fostering safer online and offline\nenvironments for public discourse.", "AI": {"title_translation": "在线用户参与阴谋论社区的早期语言指纹", "tldr": "研究发现，参与阴谋论社区的用户在加入前就表现出独特的语言特征，表明他们可能已经具备阴谋论心态，而非被在线平台激进化。", "motivation": "社交媒体平台常被视为激进化的催化剂，阴谋论尤其难以被在线内容审核策略遏制。尽管“阴谋论心态”被认为是其韧性的原因，但其在驱动在线用户行为中的作用尚不明确，因此本研究旨在探究其影响。", "method": "本研究通过分析Reddit用户在主流社区的心理语言模式，这些用户后来活跃于一个著名的阴谋论社区。通过这种方式，研究旨在分离出与阴谋论心态相关的语言标记。", "result": "研究发现，参与阴谋论的个体表现出独特的心理语言指纹，这使他们与普通用户群体区分开来。更重要的是，这种信号在他们加入阴谋论社区之前就已在其在线活动中显现，可提前数年预测其参与。", "conclusion": "这些发现表明，采纳阴谋论信仰的个体并非通过社区参与而激进化，而是本身就具有预先存在的阴谋论心态，这使他们倾向于寻求并加入极端社区。这挑战了在线社交媒体平台主动激进化用户的观点，并强调了需要更有针对性的、支持性的干预措施来鼓励脱离极端叙事。", "translation": "在线社交媒体平台常被视为激进化的催化剂，因为它们提供了极端信仰得以生根和传播的空间，有时会导致现实世界的影响。阴谋论代表了一种特定形式的激进化，其对在线内容审核策略具有显著的抵抗力。这种韧性的一种解释是存在“阴谋论心态”，这是一种从根本上塑造阴谋论信仰者如何感知现实的认知框架。然而，这种心态在驱动在线用户行为中的作用仍然知之甚少。在本研究中，我们通过检查Reddit用户在主流社区的活动，分析了那些活跃于一个著名阴谋论社区的用户的心理语言模式，这使我们能够分离出阴谋论心态存在的语言标记。我们发现，参与阴谋论的个体表现出独特的心理语言指纹，使他们与普通用户群体区分开来。至关重要的是，这种信号在他们加入阴谋论社区之前的在线活动中就已经很明显，使我们能够提前数年预测他们的参与。这些发现表明，采纳阴谋论信仰的个体并非通过社区参与而激进化，而是本身就具有预先存在的阴谋论心态，这使他们倾向于寻求并加入极端社区。通过挑战在线社交媒体平台主动将用户激进化为阴谋论信仰的观点，我们的发现表明标准审核策略在遏制激进化方面影响有限，并强调了需要更有针对性的、支持性的干预措施来鼓励脱离极端叙事。最终，这项工作有助于为公共讨论营造更安全的线上和线下环境。", "summary": "本研究探讨了在线用户参与阴谋论社区的语言特征。通过分析Reddit用户在加入阴谋论社区前的心理语言模式，研究发现这些用户在早期就表现出独特的语言指纹，表明他们可能具备预先存在的“阴谋论心态”，而非被在线平台激进化。这挑战了传统观点，并提示现有内容审核策略可能效果有限，需要更精准的干预措施来应对激进化。", "keywords": "阴谋论, 心理语言学, 在线激进化, 预测, 社交媒体"}}
{"id": "2506.04645", "pdf": "https://arxiv.org/pdf/2506.04645", "abs": "https://arxiv.org/abs/2506.04645", "authors": ["Ege Erdil"], "title": "Inference economics of language models", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "We develop a theoretical model that addresses the economic trade-off between\ncost per token versus serial token generation speed when deploying LLMs for\ninference at scale. Our model takes into account arithmetic, memory bandwidth,\nnetwork bandwidth and latency constraints; and optimizes over different\nparallelism setups and batch sizes to find the ones that optimize serial\ninference speed at a given cost per token. We use the model to compute Pareto\nfrontiers of serial speed versus cost per token for popular language models.", "AI": {"title_translation": "语言模型的推理经济学", "tldr": "针对大规模部署LLM时的推理，建立模型以优化成本与速度之间的权衡。", "motivation": "解决大规模部署大型语言模型（LLM）进行推理时，单位令牌成本与串行令牌生成速度之间的经济权衡问题。", "method": "开发了一个理论模型，该模型考虑了算术、内存带宽、网络带宽和延迟限制；并通过优化不同的并行设置和批处理大小，以在给定单位令牌成本下找到优化串行推理速度的方案。", "result": "使用该模型计算了流行语言模型的串行速度与单位令牌成本的帕累托前沿。", "conclusion": "Not mentioned in abstract", "translation": "我们开发了一个理论模型，解决了大规模部署大型语言模型（LLM）进行推理时，单位令牌成本与串行令牌生成速度之间的经济权衡问题。我们的模型考虑了算术、内存带宽、网络带宽和延迟限制；并优化了不同的并行设置和批处理大小，以找到在给定单位令牌成本下优化串行推理速度的方案。我们使用该模型计算了流行语言模型的串行速度与单位令牌成本的帕累托前沿。", "summary": "本文提出了一个理论模型，用于解决大规模部署大型语言模型时，单位令牌成本与推理速度之间的经济权衡。该模型考虑了计算、内存和网络限制，并通过优化并行设置和批处理大小来提高推理速度并控制成本。研究使用此模型计算了流行语言模型的速度-成本帕累托前沿。", "keywords": "语言模型, 推理经济学, 成本优化, 速度优化, 帕累托前沿"}}
{"id": "2506.04246", "pdf": "https://arxiv.org/pdf/2506.04246", "abs": "https://arxiv.org/abs/2506.04246", "authors": ["Sariel Har-Peled", "Eliot W. Robson"], "title": "Improving the average dilation of a metric graph by adding edges", "categories": ["cs.CG"], "comment": null, "summary": "For a graph $G$ spanning a metric space, the dilation of a pair of points is\nthe ratio of their distance in the shortest path graph metric to their distance\nin the metric space. Given a graph $G$ and a budget $k$, a classic problem is\nto augment $G$ with $k$ additional edges to reduce the maximum dilation.\n  In this note, we consider a variant of this problem where the goal is to\nreduce the average dilation for pairs of points in $G$. We provide an $O(k)$\napproximation algorithm for this problem, matching the approximation ratio\ngiven by prior work for the maximum dilation variant.", "AI": {"title_translation": "通过添加边改进度量图的平均膨胀", "tldr": "本文提出了一种近似算法，通过添加边来降低度量图的平均膨胀，实现了与最大膨胀问题相当的近似比。", "motivation": "经典问题是向图G中添加k条边以减少最大膨胀。本文考虑了该问题的一个变体，目标是减少G中点对的平均膨胀。", "method": "本文为该问题提供了一个O(k)近似算法。", "result": "所提出的算法的近似比与先前关于最大膨胀变体的工作所给出的近似比相匹配，即O(k)。", "conclusion": "本文成功地为通过添加边来降低度量图平均膨胀的问题提供了一个O(k)近似算法，其近似比与解决最大膨胀问题的现有工作相当。", "translation": "对于跨越度量空间的图G，一对点的膨胀是它们在最短路径图度量中的距离与它们在度量空间中的距离之比。给定一个图G和预算k，一个经典问题是向G中增加k条额外边以减少最大膨胀。\n  在本说明中，我们考虑了该问题的一个变体，目标是减少G中点对的平均膨胀。我们为该问题提供了一个O(k)近似算法，其近似比与先前关于最大膨胀变体的工作所给出的近似比相匹配。", "summary": "本文研究了通过添加k条边来降低度量图平均膨胀的问题。作者提出了一种O(k)近似算法来解决这个变体问题，该算法的近似比与先前针对最大膨胀变体给出的近似比相同。", "keywords": "度量图, 平均膨胀, 边添加, 近似算法, 图论"}}
{"id": "2506.04978", "pdf": "https://arxiv.org/pdf/2506.04978", "abs": "https://arxiv.org/abs/2506.04978", "authors": ["Gabriele Digregorio", "Elisabetta Cainazzo", "Stefano Longari", "Michele Carminati", "Stefano Zanero"], "title": "Evaluating the Impact of Privacy-Preserving Federated Learning on CAN Intrusion Detection", "categories": ["cs.CR"], "comment": null, "summary": "The challenges derived from the data-intensive nature of machine learning in\nconjunction with technologies that enable novel paradigms such as V2X and the\npotential offered by 5G communication, allow and justify the deployment of\nFederated Learning (FL) solutions in the vehicular intrusion detection domain.\nIn this paper, we investigate the effects of integrating FL strategies into the\nmachine learning-based intrusion detection process for on-board vehicular\nnetworks. Accordingly, we propose a FL implementation of a state-of-the-art\nIntrusion Detection System (IDS) for Controller Area Network (CAN), based on\nLSTM autoencoders. We thoroughly evaluate its detection efficiency and\ncommunication overhead, comparing it to a centralized version of the same\nalgorithm, thereby presenting it as a feasible solution.", "AI": {"title_translation": "评估隐私保护联邦学习对CAN入侵检测的影响", "tldr": "本研究探讨了联邦学习在车载网络CAN入侵检测中的应用及其有效性。", "motivation": "机器学习在车载入侵检测领域的数据密集型特性，结合V2X和5G通信等新兴技术，为联邦学习（FL）解决方案的部署提供了理由和可能性。", "method": "本文研究了将联邦学习策略集成到基于机器学习的车载网络入侵检测过程中的效果。为此，我们提出了一种基于LSTM自编码器的、针对控制器局域网（CAN）的先进入侵检测系统（IDS）的联邦学习实现方案。", "result": "我们全面评估了其检测效率和通信开销，并将其与同一算法的集中式版本进行了比较，结果表明它是一个可行的解决方案。", "conclusion": "联邦学习在车载网络CAN入侵检测中是一个可行的解决方案。", "translation": "本文研究了将联邦学习策略集成到基于机器学习的车载网络入侵检测过程中的效果。为此，我们提出了一种基于LSTM自编码器的、针对控制器局域网（CAN）的先进入侵检测系统（IDS）的联邦学习实现方案。我们全面评估了其检测效率和通信开销，并将其与同一算法的集中式版本进行了比较，结果表明它是一个可行的解决方案。", "summary": "本研究旨在评估隐私保护联邦学习对车载控制器局域网（CAN）入侵检测的影响。鉴于机器学习的数据密集性以及V2X和5G通信的潜力，联邦学习被视为车载入侵检测领域的有效解决方案。论文提出了一种基于LSTM自编码器的联邦学习实现的CAN入侵检测系统，并对其检测效率和通信开销进行了评估，与集中式版本相比，证明了其作为可行方案的潜力。", "keywords": "联邦学习, CAN总线, 入侵检测, 隐私保护, LSTM自编码器"}}
{"id": "2506.04676", "pdf": "https://arxiv.org/pdf/2506.04676", "abs": "https://arxiv.org/abs/2506.04676", "authors": ["Jing-En Huang", "I-Sheng Fang", "Tzuhsuan Huang", "Chih-Yu Wang", "Jun-Cheng Chen"], "title": "Gen-n-Val: Agentic Image Data Generation and Validation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Recently, Large Language Models (LLMs) and Vision Large Language Models\n(VLLMs) have demonstrated impressive performance as agents across various tasks\nwhile data scarcity and label noise remain significant challenges in computer\nvision tasks, such as object detection and instance segmentation. A common\nsolution for resolving these issues is to generate synthetic data. However,\ncurrent synthetic data generation methods struggle with issues, such as\nmultiple objects per mask, inaccurate segmentation, and incorrect category\nlabels, limiting their effectiveness. To address these issues, we introduce\nGen-n-Val, a novel agentic data generation framework that leverages Layer\nDiffusion (LD), LLMs, and VLLMs to produce high-quality, single-object masks\nand diverse backgrounds. Gen-n-Val consists of two agents: (1) The LD prompt\nagent, an LLM, optimizes prompts for LD to generate high-quality foreground\ninstance images and segmentation masks. These optimized prompts ensure the\ngeneration of single-object synthetic data with precise instance masks and\nclean backgrounds. (2) The data validation agent, a VLLM, which filters out\nlow-quality synthetic instance images. The system prompts for both agents are\nrefined through TextGrad. Additionally, we use image harmonization to combine\nmultiple instances within scenes. Compared to state-of-the-art synthetic data\napproaches like MosaicFusion, our approach reduces invalid synthetic data from\n50% to 7% and improves performance by 1% mAP on rare classes in COCO instance\nsegmentation with YOLOv9c and YOLO11m. Furthermore, Gen-n-Val shows significant\nimprovements (7. 1% mAP) over YOLO-Worldv2-M in open-vocabulary object\ndetection benchmarks with YOLO11m. Moreover, Gen-n-Val improves the performance\nof YOLOv9 and YOLO11 families in instance segmentation and object detection.", "AI": {"title_translation": "Gen-n-Val：智能体图像数据生成与验证", "tldr": "Gen-n-Val是一个新颖的智能体框架，利用LLM和VLLM生成高质量的合成图像数据并进行验证，有效解决了计算机视觉任务中的数据稀缺和标签噪声问题，显著提升了目标检测和实例分割的性能。", "motivation": "计算机视觉任务（如目标检测和实例分割）面临数据稀缺和标签噪声的重大挑战。现有合成数据生成方法存在多对象单掩码、分割不准确和类别标签错误等问题，限制了其有效性。", "method": "Gen-n-Val是一个新颖的智能体数据生成框架，利用分层扩散（LD）、大型语言模型（LLM）和视觉大型语言模型（VLLM）。它包含两个智能体：LD提示智能体（LLM）优化LD的提示以生成高质量的单对象前景实例图像和分割掩码；数据验证智能体（VLLM）过滤低质量的合成实例图像。两个智能体的系统提示通过TextGrad进行优化，并使用图像协调来组合场景中的多个实例。", "result": "与现有方法相比，Gen-n-Val将无效合成数据从50%降低到7%。在COCO实例分割中，使用YOLOv9c和YOLO11m在稀有类别上将mAP性能提高了1%。在开放词汇目标检测基准测试中，使用YOLO11m，相较于YOLO-Worldv2-M显示出7.1%的mAP显著改进。此外，Gen-n-Val提高了YOLOv9和YOLO11系列在实例分割和目标检测中的性能。", "conclusion": "Gen-n-Val通过生成和验证高质量的合成数据，有效解决了计算机视觉任务中的数据稀缺和标签噪声问题，显著提升了目标检测和实例分割等任务的性能。", "translation": "最近，大型语言模型（LLM）和视觉大型语言模型（VLLM）在各种任务中作为智能体展现出令人印象深刻的性能，而数据稀缺和标签噪声仍然是计算机视觉任务（如目标检测和实例分割）中的重大挑战。解决这些问题的常见方法是生成合成数据。然而，当前的合成数据生成方法存在多对象单掩码、分割不准确和类别标签错误等问题，限制了其有效性。为了解决这些问题，我们引入了Gen-n-Val，一个新颖的智能体数据生成框架，它利用分层扩散（LD）、LLM和VLLM来生成高质量的单对象掩码和多样化背景。Gen-n-Val由两个智能体组成：（1）LD提示智能体，一个LLM，优化LD的提示以生成高质量的前景实例图像和分割掩码。这些优化的提示确保生成具有精确实例掩码和干净背景的单对象合成数据。（2）数据验证智能体，一个VLLM，用于过滤掉低质量的合成实例图像。两个智能体的系统提示都通过TextGrad进行优化。此外，我们使用图像协调来组合场景中的多个实例。与MosaicFusion等最先进的合成数据方法相比，我们的方法将无效合成数据从50%降低到7%，并在COCO实例分割中使用YOLOv9c和YOLO11m在稀有类别上将mAP性能提高了1%。此外，Gen-n-Val在开放词汇目标检测基准测试中，使用YOLO11m，相较于YOLO-Worldv2-M显示出显著改进（7.1% mAP）。此外，Gen-n-Val提高了YOLOv9和YOLO11系列在实例分割和目标检测中的性能。", "summary": "Gen-n-Val是一种新颖的智能体数据生成框架，旨在解决计算机视觉任务中数据稀缺和标签噪声问题。它利用大型语言模型（LLM）和视觉大型语言模型（VLLM）作为智能体，通过分层扩散（LD）生成高质量的单对象掩码和多样化背景的合成数据。该框架包含一个LD提示智能体（LLM）用于优化生成过程，以及一个数据验证智能体（VLLM）用于过滤低质量数据。实验结果表明，Gen-n-Val显著降低了无效合成数据的比例，并在COCO实例分割和开放词汇目标检测等任务中，相较于现有方法，显著提升了YOLOv9和YOLO11系列模型的性能。", "keywords": "智能体数据生成, 合成数据, 大型语言模型, 视觉大型语言模型, 实例分割"}}
{"id": "2506.04627", "pdf": "https://arxiv.org/pdf/2506.04627", "abs": "https://arxiv.org/abs/2506.04627", "authors": ["Xinyu Cui", "Boai Sun", "Yi Zhu", "Ning Yang", "Haifeng Zhang", "Weicheng Cui", "Dixia Fan", "Jun Wang"], "title": "Enhancing Efficiency and Propulsion in Bio-mimetic Robotic Fish through End-to-End Deep Reinforcement Learning", "categories": ["cs.RO", "physics.flu-dyn"], "comment": null, "summary": "Aquatic organisms are known for their ability to generate efficient\npropulsion with low energy expenditure. While existing research has sought to\nleverage bio-inspired structures to reduce energy costs in underwater robotics,\nthe crucial role of control policies in enhancing efficiency has often been\noverlooked. In this study, we optimize the motion of a bio-mimetic robotic fish\nusing deep reinforcement learning (DRL) to maximize propulsion efficiency and\nminimize energy consumption. Our novel DRL approach incorporates extended\npressure perception, a transformer model processing sequences of observations,\nand a policy transfer scheme. Notably, significantly improved training\nstability and speed within our approach allow for end-to-end training of the\nrobotic fish. This enables agiler responses to hydrodynamic environments and\npossesses greater optimization potential compared to pre-defined motion pattern\ncontrols. Our experiments are conducted on a serially connected rigid robotic\nfish in a free stream with a Reynolds number of 6000 using computational fluid\ndynamics (CFD) simulations. The DRL-trained policies yield impressive results,\ndemonstrating both high efficiency and propulsion. The policies also showcase\nthe agent's embodiment, skillfully utilizing its body structure and engaging\nwith surrounding fluid dynamics, as revealed through flow analysis. This study\nprovides valuable insights into the bio-mimetic underwater robots optimization\nthrough DRL training, capitalizing on their structural advantages, and\nultimately contributing to more efficient underwater propulsion systems.", "AI": {"title_translation": "生物仿生机器鱼通过端到端深度强化学习提升效率和推进力", "tldr": "使用深度强化学习优化生物仿生机器鱼的运动，以实现高效率和和推进力。", "motivation": "现有研究在水下机器人中利用仿生结构降低能耗时，常忽略控制策略在提升效率中的关键作用。", "method": "采用端到端深度强化学习（DRL）方法，该方法结合了扩展压力感知、处理观察序列的Transformer模型和策略迁移方案，以优化机器鱼的运动，最大化推进效率并最小化能耗。实验通过计算流体动力学（CFD）模拟在雷诺数为6000的自由流中对串联刚性机器鱼进行。", "result": "DRL训练的策略在效率和推进力方面表现出色，并展示了智能体对身体结构的熟练利用以及与周围流体动力学的有效互动。", "conclusion": "该研究为通过DRL训练优化仿生水下机器人提供了有价值的见解，利用其结构优势，最终有助于开发更高效的水下推进系统。", "translation": "水生生物以其低能耗产生高效推进的能力而闻名。尽管现有研究试图利用仿生结构来降低水下机器人的能源成本，但控制策略在提高效率方面的关键作用常常被忽视。在本研究中，我们使用深度强化学习（DRL）优化生物仿生机器鱼的运动，以最大化推进效率并最小化能量消耗。我们新颖的DRL方法结合了扩展压力感知、处理观察序列的Transformer模型以及策略迁移方案。值得注意的是，我们方法中显著提高的训练稳定性和速度允许对机器鱼进行端到端训练。这使得机器鱼能够对水动力环境做出更敏捷的响应，并且与预定义的运动模式控制相比具有更大的优化潜力。我们的实验通过计算流体动力学（CFD）模拟在雷诺数为6000的自由流中对串联刚性机器鱼进行。DRL训练的策略取得了令人印象深刻的结果，展示了高效率和高推进力。通过流场分析，这些策略还展示了智能体的具身性，熟练地利用其身体结构并与周围流体动力学相互作用。这项研究为通过DRL训练优化仿生水下机器人提供了有价值的见解，利用其结构优势，并最终有助于开发更高效的水下推进系统。", "summary": "本研究利用深度强化学习优化生物仿生机器鱼的运动，以提高推进效率并降低能耗。通过引入扩展压力感知、Transformer模型和策略迁移，实现了端到端训练，显著提升了训练的稳定性和速度。实验结果表明，DRL训练的策略在效率和推进力上均表现出色，并能有效利用机器鱼的身体结构与流体环境互动，为开发更高效的水下推进系统提供了新思路。", "keywords": "深度强化学习, 生物仿生机器鱼, 推进效率, 能量消耗, 计算流体动力学"}}
{"id": "2506.05022", "pdf": "https://arxiv.org/pdf/2506.05022", "abs": "https://arxiv.org/abs/2506.05022", "authors": ["Yixuan Cao", "Yuhong Feng", "Huafeng Li", "Chongyi Huang", "Fangcao Jian", "Haoran Li", "Xu Wang"], "title": "Tech-ASan: Two-stage check for Address Sanitizer", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "Address Sanitizer (ASan) is a sharp weapon for detecting memory safety\nviolations, including temporal and spatial errors hidden in C/C++ programs\nduring execution. However, ASan incurs significant runtime overhead, which\nlimits its efficiency in testing large software. The overhead mainly comes from\nsanitizer checks due to the frequent and expensive shadow memory access. Over\nthe past decade, many methods have been developed to speed up ASan by\neliminating and accelerating sanitizer checks, however, they either fail to\nadequately eliminate redundant checks or compromise detection capabilities. To\naddress this issue, this paper presents Tech-ASan, a two-stage check based\ntechnique to accelerate ASan with safety assurance. First, we propose a novel\ntwo-stage check algorithm for ASan, which leverages magic value comparison to\nreduce most of the costly shadow memory accesses. Second, we design an\nefficient optimizer to eliminate redundant checks, which integrates a novel\nalgorithm for removing checks in loops. Third, we implement Tech-ASan as a\nmemory safety tool based on the LLVM compiler infrastructure. Our evaluation\nusing the SPEC CPU2006 benchmark shows that Tech-ASan outperforms the\nstate-of-the-art methods with 33.70% and 17.89% less runtime overhead than ASan\nand ASan--, respectively. Moreover, Tech-ASan detects 56 fewer false negative\ncases than ASan and ASan-- when testing on the Juliet Test Suite under the same\nredzone setting.", "AI": {"title_translation": "Tech-ASan：地址清理器的两阶段检查", "tldr": "Tech-ASan通过两阶段检查和优化器显著降低了Address Sanitizer (ASan) 的运行时开销，同时保持或提高了检测能力，解决了ASan在大型软件测试中效率低下的问题。", "motivation": "Address Sanitizer (ASan) 在检测C/C++程序中的内存安全违规方面非常有效，但其显著的运行时开销限制了其在大规模软件测试中的效率。开销主要来源于频繁且昂贵的影子内存访问。现有方法要么未能充分消除冗余检查，要么损害了检测能力。", "method": "本文提出了Tech-ASan，一种基于两阶段检查的技术来加速ASan，并确保安全性。具体方法包括：1) 提出一种新颖的ASan两阶段检查算法，利用魔术值比较来减少昂贵的影子内存访问。2) 设计一个高效的优化器来消除冗余检查，其中包含一种用于在循环中删除检查的新算法。3) 将Tech-ASan实现为基于LLVM编译器基础设施的内存安全工具。", "result": "Tech-ASan在SPEC CPU2006基准测试中的表现优于现有技术，运行时开销比ASan少33.70%，比ASan--少17.89%。此外，在相同的redzone设置下，Tech-ASan在Juliet Test Suite上测试时比ASan和ASan--少检测出56个假阴性案例。", "conclusion": "Tech-ASan通过其创新的两阶段检查和优化技术，显著降低了Address Sanitizer的运行时开销，同时保持了卓越的内存安全检测能力，解决了现有ASan加速方案的不足。", "translation": "地址清理器 (ASan) 是检测内存安全违规的利器，包括C/C++程序在执行过程中隐藏的时间和空间错误。然而，ASan 会产生显著的运行时开销，这限制了其在测试大型软件时的效率。开销主要来自于频繁且昂贵的影子内存访问导致的清理器检查。在过去十年中，许多方法被开发出来，通过消除和加速清理器检查来加快 ASan 的速度，然而，它们要么未能充分消除冗余检查，要么损害了检测能力。为了解决这个问题，本文提出了 Tech-ASan，一种基于两阶段检查的技术，用于在保证安全性的前提下加速 ASan。首先，我们提出了一种新颖的 ASan 两阶段检查算法，该算法利用魔术值比较来减少大部分昂贵的影子内存访问。其次，我们设计了一个高效的优化器来消除冗余检查，该优化器集成了一种用于在循环中删除检查的新算法。第三，我们将 Tech-ASan 实现为基于 LLVM 编译器基础设施的内存安全工具。我们使用 SPEC CPU2006 基准测试进行的评估表明，Tech-ASan 优于最先进的方法，其运行时开销比 ASan 少 33.70%，比 ASan-- 少 17.89%。此外，在相同的 redzone 设置下，Tech-ASan 在 Juliet Test Suite 上测试时比 ASan 和 ASan-- 少检测出 56 个假阴性案例。", "summary": "本论文提出了Tech-ASan，一种基于两阶段检查的技术，旨在加速Address Sanitizer (ASan) 并确保其安全性。针对ASan高运行时开销的问题，Tech-ASan引入了新颖的两阶段检查算法，利用魔术值比较减少影子内存访问，并设计了高效优化器，包括在循环中消除冗余检查的算法。在LLVM编译器基础设施上实现后，Tech-ASan在SPEC CPU2006基准测试中显示出比ASan和ASan--更低的运行时开销，并且在Juliet Test Suite上的假阴性检测方面表现更优。", "keywords": "Address Sanitizer, 内存安全, 两阶段检查, 运行时开销, 优化"}}
{"id": "2506.04429", "pdf": "https://arxiv.org/pdf/2506.04429", "abs": "https://arxiv.org/abs/2506.04429", "authors": ["Ananya Joshi", "Nolan Gormley", "Richa Gadgil", "Tina Townes", "Roni Rosenfeld", "Bryan Wilder"], "title": "An AI-Based Public Health Data Monitoring System", "categories": ["cs.AI"], "comment": null, "summary": "Public health experts need scalable approaches to monitor large volumes of\nhealth data (e.g., cases, hospitalizations, deaths) for outbreaks or data\nquality issues. Traditional alert-based monitoring systems struggle with modern\npublic health data monitoring systems for several reasons, including that\nalerting thresholds need to be constantly reset and the data volumes may cause\napplication lag. Instead, we propose a ranking-based monitoring paradigm that\nleverages new AI anomaly detection methods. Through a multi-year\ninterdisciplinary collaboration, the resulting system has been deployed at a\nnational organization to monitor up to 5,000,000 data points daily. A\nthree-month longitudinal deployed evaluation revealed a significant improvement\nin monitoring objectives, with a 54x increase in reviewer speed efficiency\ncompared to traditional alert-based methods. This work highlights the potential\nof human-centered AI to transform public health decision-making.", "AI": {"title_translation": "一个基于人工智能的公共卫生数据监测系统", "tldr": "提出了一种基于人工智能的排名监测系统，以解决公共卫生数据监测中的挑战，并在部署中实现了54倍的审查员速度效率提升。", "motivation": "传统的基于警报的监测系统在处理现代公共卫生数据监测系统时面临挑战，原因包括警报阈值需要不断重置，以及数据量可能导致应用程序延迟。", "method": "提出了一种利用新型人工智能异常检测方法的基于排名的监测范式。该系统已在一个国家组织部署。", "result": "一项为期三个月的长期部署评估显示，监测目标显著改善，与传统的基于警报的方法相比，审查员速度效率提高了54倍。", "conclusion": "这项工作突出了以人为本的人工智能在改变公共卫生决策方面的潜力。", "translation": "公共卫生专家需要可扩展的方法来监测大量健康数据（例如，病例、住院、死亡），以发现疫情爆发或数据质量问题。传统的基于警报的监测系统在处理现代公共卫生数据监测系统时面临多重挑战，包括警报阈值需要不断重置以及数据量可能导致应用程序延迟。为此，我们提出了一种基于排名的监测范式，该范式利用了新的人工智能异常检测方法。通过多年的跨学科合作，所产生的系统已在一个国家组织部署，每天监测多达5,000,000个数据点。一项为期三个月的长期部署评估显示，监测目标显著改善，与传统的基于警报的方法相比，审查员速度效率提高了54倍。这项工作突出了以人为本的人工智能在改变公共卫生决策方面的潜力。", "summary": "本文介绍了一种基于人工智能的排名监测系统，旨在克服传统基于警报的公共卫生数据监测系统的局限性。通过利用人工智能异常检测，该系统解决了诸如阈值需要不断重置以及大数据量导致的应用程序延迟等问题。该系统已在一个国家组织部署，为期三个月的评估表明，审查员速度效率提高了54倍，突显了以人为本的人工智能在公共卫生决策中的变革潜力。", "keywords": "人工智能, 公共卫生, 数据监测, 异常检测, 以人为本的人工智能"}}
{"id": "2506.04394", "pdf": "https://arxiv.org/pdf/2506.04394", "abs": "https://arxiv.org/abs/2506.04394", "authors": ["Qiuyu Tang", "Bonor Ayambem", "Mooi Choo Chuah", "Aparna Bharati"], "title": "Is Perturbation-Based Image Protection Disruptive to Image Editing?", "categories": ["cs.CV"], "comment": "6 pages, 8 figures, accepted by ICIP 2025", "summary": "The remarkable image generation capabilities of state-of-the-art diffusion\nmodels, such as Stable Diffusion, can also be misused to spread misinformation\nand plagiarize copyrighted materials. To mitigate the potential risks\nassociated with image editing, current image protection methods rely on adding\nimperceptible perturbations to images to obstruct diffusion-based editing. A\nfully successful protection for an image implies that the output of editing\nattempts is an undesirable, noisy image which is completely unrelated to the\nreference image. In our experiments with various perturbation-based image\nprotection methods across multiple domains (natural scene images and artworks)\nand editing tasks (image-to-image generation and style editing), we discover\nthat such protection does not achieve this goal completely. In most scenarios,\ndiffusion-based editing of protected images generates a desirable output image\nwhich adheres precisely to the guidance prompt. Our findings suggest that\nadding noise to images may paradoxically increase their association with given\ntext prompts during the generation process, leading to unintended consequences\nsuch as better resultant edits. Hence, we argue that perturbation-based methods\nmay not provide a sufficient solution for robust image protection against\ndiffusion-based editing.", "AI": {"title_translation": "基于扰动的图像保护会干扰图像编辑吗？", "tldr": "基于扰动的图像保护方法未能有效阻止扩散模型对受保护图像的编辑，甚至可能意外地导致更好的编辑结果。", "motivation": "现有的图像保护方法通过向图像添加微小的扰动来阻止扩散模型进行图像编辑，以应对扩散模型可能被滥用传播虚假信息和侵犯版权的问题。然而，这些方法是否真正有效，是否能达到其保护目标尚不明确。", "method": "研究者在多个领域（自然场景图像和艺术作品）和编辑任务（图像到图像生成和风格编辑）中，对各种基于扰动的图像保护方法进行了实验。", "result": "实验发现，基于扰动的图像保护方法未能完全实现其目标。在大多数情况下，对受保护图像进行的扩散模型编辑仍能生成理想的输出图像，并且这些图像精确地遵循指导提示。研究结果表明，向图像添加噪声可能反而增加了图像在生成过程中与给定文本提示的关联性，从而导致意外的后果，例如更好的编辑结果。", "conclusion": "基于扰动的方法可能无法为对抗扩散模型编辑提供足够的图像保护。", "translation": "最先进的扩散模型（如Stable Diffusion）卓越的图像生成能力也可能被滥用于传播虚假信息和剽窃受版权保护的材料。为了减轻与图像编辑相关的潜在风险，当前的图像保护方法依赖于向图像添加不可察觉的扰动，以阻碍基于扩散的编辑。对图像的完全成功保护意味着编辑尝试的输出是一个不理想的、嘈杂的图像，与参考图像完全无关。在我们对多个领域（自然场景图像和艺术作品）和编辑任务（图像到图像生成和风格编辑）中各种基于扰动的图像保护方法的实验中，我们发现这种保护并未完全实现这一目标。在大多数情况下，受保护图像的基于扩散的编辑会生成一个理想的输出图像，该图像精确地遵循指导提示。我们的发现表明，向图像添加噪声可能自相矛盾地增加了它们在生成过程中与给定文本提示的关联性，从而导致意外的后果，例如更好的编辑。因此，我们认为基于扰动的方法可能无法为对抗基于扩散的编辑提供足够的鲁棒图像保护。", "summary": "该研究旨在评估现有基于扰动的图像保护方法对扩散模型图像编辑的有效性。尽管这些方法旨在通过添加不可察觉的扰动来阻止编辑，但实验结果表明，在大多数情况下，受保护图像仍能被扩散模型成功编辑并生成符合提示的理想输出。研究指出，添加噪声可能反而增强了图像与文本提示的关联性，从而导致了意想不到的“更好”的编辑结果。因此，论文得出结论，基于扰动的方法可能不足以提供鲁棒的图像保护。", "keywords": "图像保护, 扩散模型, 图像编辑, 扰动, 误信息"}}
{"id": "2506.04425", "pdf": "https://arxiv.org/pdf/2506.04425", "abs": "https://arxiv.org/abs/2506.04425", "authors": ["Ben Blum-Smith", "Harm Derksen", "Dustin G. Mixon", "Yousef Qaddura", "Brantley Vose"], "title": "Estimating the Euclidean distortion of an orbit space", "categories": ["math.MG", "cs.IT", "math.FA", "math.IT", "math.RT"], "comment": null, "summary": "Given a finite-dimensional inner product space $V$ and a group $G$ of\nisometries, we consider the problem of embedding the orbit space $V/G$ into a\nHilbert space in a way that preserves the quotient metric as well as possible.\nThis inquiry is motivated by applications to invariant machine learning. We\nintroduce several new theoretical tools before using them to tackle various\nfundamental instances of this problem.", "AI": {"title_translation": "估计轨道空间的欧几里得畸变", "tldr": "研究如何将轨道空间有效地嵌入希尔伯特空间，以应用于不变机器学习。", "motivation": "该研究受到不变机器学习应用的驱动。", "method": "引入了几个新的理论工具，并用它们来解决该问题的各种基本实例。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "给定一个有限维内积空间$V$和一个等距群$G$，我们考虑将轨道空间$V/G$嵌入希尔伯特空间的问题，以尽可能地保留商度量。这项研究的动机是不变机器学习的应用。我们引入了几个新的理论工具，然后用它们来解决该问题的各种基本实例。", "summary": "本文探讨了将有限维内积空间$V$及其等距群$G$的轨道空间$V/G$尽可能地保留商度量嵌入希尔伯特空间的问题。该研究的动机是不变机器学习的应用。作者引入了新的理论工具，并用它们来解决该问题的基本实例。", "keywords": "轨道空间, 欧几里得畸变, 希尔伯特空间, 不变机器学习"}}
{"id": "2506.04285", "pdf": "https://arxiv.org/pdf/2506.04285", "abs": "https://arxiv.org/abs/2506.04285", "authors": ["Stephen Smith", "Cormac Purcell", "Zdenka Kuncic"], "title": "Training-free AI for Earth Observation Change Detection using Physics Aware Neuromorphic Networks", "categories": ["cs.LG"], "comment": "16 pages, 9 figures, 3 tables", "summary": "Earth observations from low Earth orbit satellites provide vital information\nfor decision makers to better manage time-sensitive events such as natural\ndisasters. For the data to be most effective for first responders, low latency\nis required between data capture and its arrival to decision makers. A major\nbottleneck is in the bandwidth-limited downlinking of the data from satellites\nto ground stations. One approach to overcome this challenge is to process at\nleast some of the data on-board and prioritise pertinent data to be downlinked.\nIn this work we propose a Physics Aware Neuromorphic Network (PANN) to detect\nchanges caused by natural disasters from a sequence of multi-spectral satellite\nimages and produce a change map, enabling relevant data to be prioritised for\ndownlinking. The PANN used in this study is motivated by physical neural\nnetworks comprised of nano-electronic circuit elements known as \"memristors\"\n(nonlinear resistors with memory). The weights in the network are dynamic and\nupdate in response to varying input signals according to memristor equations of\nstate and electrical circuit conservation laws. The PANN thus generates\nphysics-constrained dynamical output features which are used to detect changes\nin a natural disaster detection task by applying a distance-based metric.\nImportantly, this makes the whole model training-free, allowing it to be\nimplemented with minimal computing resources. The PANN was benchmarked against\na state-of-the-art AI model and achieved comparable or better results in each\nnatural disaster category. It thus presents a promising solution to the\nchallenge of resource-constrained on-board processing.", "AI": {"title_translation": "用于地球观测变化检测的免训练人工智能：基于物理感知神经拟态网络", "tldr": "本文提出了一种免训练的物理感知神经拟态网络（PANN），用于从卫星图像中检测自然灾害引起的变化，以解决星载数据处理的资源限制和带宽瓶颈问题，并实现了与现有先进模型相当或更优的性能。", "motivation": "地球观测数据对于决策者管理自然灾害等时间敏感事件至关重要，但卫星数据下行链路的带宽限制导致数据延迟，影响了对急救人员的有效性。因此，需要在星上处理部分数据并优先下行相关数据。", "method": "本文提出了一种物理感知神经拟态网络（PANN），用于从多光谱卫星图像序列中检测自然灾害引起的变化并生成变化图。PANN受到物理神经网络的启发，由忆阻器（具有记忆的非线性电阻器）构成，网络中的权重是动态的，根据忆阻器状态方程和电路守恒定律响应输入信号而更新。PANN生成物理约束的动态输出特征，并通过基于距离的度量来检测变化。这种方法使得整个模型无需训练。", "result": "PANN与最先进的AI模型进行了基准测试，在每种自然灾害类别中都取得了可比或更好的结果。", "conclusion": "PANN为资源受限的星载处理挑战提供了一个有前景的解决方案，能够有效检测自然灾害引起的变化并优先下行相关数据。", "translation": "来自低地球轨道卫星的地球观测数据为决策者更好地管理自然灾害等时间敏感事件提供了重要信息。为了使数据对急救人员最有效，数据捕获与到达决策者之间需要低延迟。一个主要瓶颈是数据从卫星到地面站的带宽受限下行链路。克服这一挑战的一种方法是至少在星上处理部分数据，并优先下行相关数据。在这项工作中，我们提出了一种物理感知神经拟态网络（PANN），用于从一系列多光谱卫星图像中检测由自然灾害引起的变化，并生成变化图，从而使相关数据能够优先下行。本研究中使用的PANN受到由纳米电子电路元件（称为“忆阻器”——具有记忆的非线性电阻器）组成的物理神经网络的启发。网络中的权重是动态的，根据忆阻器状态方程和电路守恒定律响应变化的输入信号而更新。因此，PANN生成物理约束的动态输出特征，通过应用基于距离的度量来检测自然灾害检测任务中的变化。重要的是，这使得整个模型无需训练，从而可以用最少的计算资源来实现。PANN与最先进的AI模型进行了基准测试，在每种自然灾害类别中都取得了可比或更好的结果。因此，它为资源受限的星载处理挑战提供了一个有前景的解决方案。", "summary": "本研究提出了一种免训练的物理感知神经拟态网络（PANN），旨在解决地球观测数据从卫星到地面站的带宽限制和延迟问题。PANN利用忆阻器和物理定律实现动态权重更新，能够从多光谱卫星图像中检测自然灾害引起的变化。该模型无需训练，计算资源需求极低，并且在自然灾害检测任务中表现出与现有先进AI模型相当或更优的性能，为星载数据处理提供了有前景的解决方案。", "keywords": "地球观测, 变化检测, 神经拟态网络, 忆阻器, 免训练AI"}}
{"id": "2506.05172", "pdf": "https://arxiv.org/pdf/2506.05172", "abs": "https://arxiv.org/abs/2506.05172", "authors": ["Weichen Shi"], "title": "A Framework for Ethical Judgment of Smart City Applications", "categories": ["cs.CY"], "comment": null, "summary": "As modern cities increasingly adopt a variety of sensors and Internet of\nThings (IoT) technologies to collect and analyze data about residents,\nenvironments, and public services, they are fostering greater interactions\namong smart city applications, residents, governments, and businesses. This\ntrend makes it essential for regulators to focus on these interactions to\nmanage smart city practices effectively and prevent unethical outcomes. To\nfacilitate ethical analysis for smart city applications, this paper introduces\na judgment framework that examines various scenarios where ethical issues may\narise. Employing a multi-agent approach, the framework incorporates diverse\nsocial entities and applies logic-based ethical rules to identify potential\nviolations. Through a rights-based analysis, we developed a set of 13 ethical\nprinciples and rules to guide ethical practices in smart cities. We utilized\ntwo specification languages, Prototype Verification System (PVS) and Alloy, to\nmodel our multi-agent system. Our analysis suggests that Alloy may be more\nefficient for formalizing smart cities and conducting ethical rule checks,\nparticularly with the assistance of a human evaluator. Simulations of a\nreal-world smart city application demonstrate that our ethical judgment\nframework effectively detects unethical outcomes and can be extended for\npractical use.", "AI": {"title_translation": "智慧城市应用伦理判断框架", "tldr": "本研究提出了一个多智能体伦理判断框架，用于识别智慧城市应用中可能出现的不道德结果，并提出13项伦理原则和规则，通过PVS和Alloy建模验证，证明其能有效检测不道德行为。", "motivation": "随着现代城市越来越多地采用传感器和物联网技术来收集和分析数据，智慧城市应用、居民、政府和企业之间的互动日益增多。为了有效管理智慧城市实践并防止不道德结果，监管机构必须关注这些互动。本研究旨在促进智慧城市应用的伦理分析。", "method": "本研究引入了一个判断框架，该框架采用多智能体方法，整合了不同的社会实体，并应用基于逻辑的伦理规则来识别潜在的违规行为。通过基于权利的分析，制定了13项伦理原则和规则。使用原型验证系统（PVS）和Alloy两种规范语言对多智能体系统进行建模。", "result": "分析表明，Alloy可能更有效地用于智慧城市的形式化和伦理规则检查，尤其是在人类评估员的协助下。对真实智慧城市应用的模拟表明，该伦理判断框架能有效检测不道德结果，并可扩展用于实际应用。", "conclusion": "本研究提出的伦理判断框架能够有效检测智慧城市应用中的不道德结果，并具有实际应用潜力，Alloy在形式化和伦理规则检查方面表现出更高效率。", "translation": "随着现代城市越来越多地采用各种传感器和物联网（IoT）技术来收集和分析居民、环境和公共服务数据，它们正在促进智慧城市应用、居民、政府和企业之间更广泛的互动。这一趋势使得监管机构必须关注这些互动，以有效管理智慧城市实践并防止不道德结果。为了促进智慧城市应用的伦理分析，本文引入了一个判断框架，该框架检查了可能出现伦理问题的各种场景。该框架采用多智能体方法，整合了不同的社会实体，并应用基于逻辑的伦理规则来识别潜在的违规行为。通过基于权利的分析，我们制定了一套13项伦理原则和规则，以指导智慧城市中的伦理实践。我们利用两种规范语言——原型验证系统（PVS）和Alloy——对我们的多智能体系统进行建模。我们的分析表明，Alloy在形式化智慧城市和进行伦理规则检查方面可能更有效，尤其是在人类评估员的协助下。对真实世界智慧城市应用的模拟表明，我们的伦理判断框架能有效检测不道德结果，并可扩展用于实际应用。", "summary": "本论文提出了一个针对智慧城市应用的伦理判断框架，旨在应对物联网和数据收集带来的伦理挑战。该框架采用多智能体方法，结合基于逻辑的伦理规则和13项基于权利的伦理原则，以识别潜在的不道德行为。研究利用PVS和Alloy对系统进行建模，发现Alloy在形式化和伦理规则检查方面效率更高。通过模拟真实世界的应用，验证了该框架在检测不道德结果方面的有效性和实际可扩展性。", "keywords": "智慧城市, 伦理判断, 多智能体系统, 物联网, 伦理框架"}}
{"id": "2506.04763", "pdf": "https://arxiv.org/pdf/2506.04763", "abs": "https://arxiv.org/abs/2506.04763", "authors": ["Shuai Lu"], "title": "A highly scalable numerical framework for reservoir simulation on UG4 platform", "categories": ["physics.comp-ph", "cs.DC"], "comment": null, "summary": "The modeling and simulation of multiphase fluid flow receive significant\nattention in reservoir engineering. Many time discretization schemes for\nmultiphase flow equations are either explicit or semi-implicit, relying on the\ndecoupling between the saturation equation and the pressure equation. In this\nstudy, we delve into a fully coupled and fully implicit framework for\nsimulating multiphase flow in heterogeneous porous media, considering gravity\nand capillary effects. We utilize the Vertex-Centered Finite Volume Method for\nspatial discretization and propose an efficient implementation of interface\nconditions for heterogeneous porous media within the current scheme. Notably,\nwe introduce the Linearly Implicit Extrapolation Method (LIMEX) with an error\nestimator, adapted for the first time to multiphase flow problems. To solve the\nresulting linear system, we employ the BiCGSTAB method with the Geometric\nMultigrid (GMG) preconditioner. The implementations of models and methods are\nbased on the open-source software: UG4. The results from parallel computations\non the supercomputer demonstrate that the scalability of our proposed framework\nis sufficient, supporting a scale of thousands of processors with Degrees of\nFreedom (DoF) extending up to billions.", "AI": {"title_translation": "油藏模拟UG4平台上的高可扩展数值框架", "tldr": "本文提出并首次将线性隐式外推法（LIMEX）应用于UG4平台上的全耦合、全隐式多相流油藏模拟，实现了数十亿自由度下千核处理器的良好可扩展性。", "motivation": "现有的多相流方程时间离散方案多为显式或半隐式，依赖于饱和度方程和压力方程的解耦，这可能限制了模拟的效率和准确性。", "method": "本研究开发了一个用于模拟非均质多孔介质中多相流（考虑重力和毛细管效应）的全耦合、全隐式框架。空间离散采用顶点中心有限体积法，并提出了非均质多孔介质界面条件的有效实现。首次将带有误差估计器的线性隐式外推法（LIMEX）应用于多相流问题。线性系统通过BiCGSTAB方法与几何多重网格（GMG）预处理器求解。所有实现均基于开源软件UG4。", "result": "在超级计算机上进行的并行计算结果表明，所提出的框架具有足够的扩展性，能够支持数千个处理器和高达数十亿的自由度（DoF）。", "conclusion": "所提出的基于UG4平台的全耦合、全隐式数值框架在多相流油藏模拟中表现出卓越的可扩展性，能够有效处理大规模复杂问题。", "translation": "油藏工程中多相流体的建模和模拟受到广泛关注。许多多相流方程的时间离散方案要么是显式的，要么是半隐式的，依赖于饱和度方程和压力方程之间的解耦。在本研究中，我们深入探讨了一个用于模拟非均质多孔介质中多相流动的全耦合、全隐式框架，并考虑了重力和毛细管效应。我们利用顶点中心有限体积法进行空间离散，并在当前方案中提出了一种非均质多孔介质界面条件的有效实现。值得注意的是，我们首次将带有误差估计器的线性隐式外推法（LIMEX）应用于多相流问题。为了求解由此产生的线性系统，我们采用了BiCGSTAB方法和几何多重网格（GMG）预处理器。模型和方法的实现均基于开源软件UG4。超级计算机上的并行计算结果表明，我们提出的框架具有足够的扩展性，支持数千个处理器，自由度可达数十亿。", "summary": "本文针对油藏工程中多相流模拟的挑战，提出了一个基于UG4平台的全新、全耦合、全隐式数值框架。该框架结合了顶点中心有限体积法和首次应用于多相流问题的线性隐式外推法（LIMEX），并采用BiCGSTAB和几何多重网格预处理器求解线性系统。通过在超级计算机上的并行计算验证，该框架展现出极高可扩展性，能够支持数千个处理器和数十亿自由度的模拟。", "keywords": "油藏模拟, 多相流, 全耦合全隐式, LIMEX, UG4, 可扩展性"}}
{"id": "2506.05001", "pdf": "https://arxiv.org/pdf/2506.05001", "abs": "https://arxiv.org/abs/2506.05001", "authors": ["Limin Wang", "Lei Bu", "Muzimiao Zhang", "Shihong Cang", "Kai Ye"], "title": "Attack Effect Model based Malicious Behavior Detection", "categories": ["cs.CR"], "comment": null, "summary": "Traditional security detection methods face three key challenges: inadequate\ndata collection that misses critical security events, resource-intensive\nmonitoring systems, and poor detection algorithms with high false positive\nrates. We present FEAD (Focus-Enhanced Attack Detection), a framework that\naddresses these issues through three innovations: (1) an attack model-driven\napproach that extracts security-critical monitoring items from online attack\nreports for comprehensive coverage; (2) efficient task decomposition that\noptimally distributes monitoring across existing collectors to minimize\noverhead; and (3) locality-aware anomaly analysis that leverages the clustering\nbehavior of malicious activities in provenance graphs to improve detection\naccuracy. Evaluations demonstrate FEAD achieves 8.23% higher F1-score than\nexisting solutions with only 5.4% overhead, confirming that focus-based designs\nsignificantly enhance detection performance.", "AI": {"title_translation": "基于攻击效果模型的恶意行为检测", "tldr": "FEAD框架通过攻击模型驱动的方法、高效的任务分解和局部性感知异常分析，提高了恶意行为检测的F1分数并降低了开销。", "motivation": "传统安全检测方法面临三个关键挑战：数据收集不足导致遗漏关键安全事件、监控系统资源密集以及检测算法的误报率高。", "method": "本文提出了FEAD（Focus-Enhanced Attack Detection）框架，通过三项创新解决上述问题：1）攻击模型驱动的方法，从在线攻击报告中提取安全关键监控项以实现全面覆盖；2）高效的任务分解，优化监控任务在现有收集器上的分布以最小化开销；3）局部性感知异常分析，利用恶意活动在溯源图中的聚类行为来提高检测准确性。", "result": "评估表明，FEAD比现有解决方案的F1分数高出8.23%，且开销仅为5.4%。", "conclusion": "基于焦点的设计显著提高了检测性能。", "translation": "传统安全检测方法面临三个关键挑战：数据收集不足导致遗漏关键安全事件、资源密集型监控系统以及检测算法的误报率高。我们提出了FEAD（Focus-Enhanced Attack Detection），一个通过三项创新解决这些问题的框架：(1) 攻击模型驱动的方法，从在线攻击报告中提取安全关键监控项以实现全面覆盖；(2) 高效的任务分解，优化监控在现有收集器上的分布以最小化开销；(3) 局部性感知异常分析，利用恶意活动在溯源图中的聚类行为来提高检测准确性。评估表明，FEAD比现有解决方案的F1分数高出8.23%，且开销仅为5.4%，证实了基于焦点的设计显著提高了检测性能。", "summary": "本文提出了FEAD（Focus-Enhanced Attack Detection）框架，旨在解决传统安全检测中数据收集不足、资源消耗大和误报率高的问题。FEAD通过攻击模型驱动的监控项提取、高效的任务分解和局部性感知异常分析，显著提高了恶意行为检测的准确性，并有效降低了系统开销。实验结果表明，FEAD在F1分数上优于现有解决方案，且开销很低。", "keywords": "恶意行为检测, 攻击效果模型, FEAD, 异常分析, 安全监控"}}
{"id": "2506.04646", "pdf": "https://arxiv.org/pdf/2506.04646", "abs": "https://arxiv.org/abs/2506.04646", "authors": ["Zhuoyun Zhong", "Seyedali Golestaneh", "Constantinos Chamzas"], "title": "ActivePusher: Active Learning and Planning with Residual Physics for Nonprehensile Manipulation", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Planning with learned dynamics models offers a promising approach toward\nreal-world, long-horizon manipulation, particularly in nonprehensile settings\nsuch as pushing or rolling, where accurate analytical models are difficult to\nobtain. Although learning-based methods hold promise, collecting training data\ncan be costly and inefficient, as it often relies on randomly sampled\ninteractions that are not necessarily the most informative. To address this\nchallenge, we propose ActivePusher, a novel framework that combines\nresidual-physics modeling with kernel-based uncertainty-driven active learning\nto focus data acquisition on the most informative skill parameters.\nAdditionally, ActivePusher seamlessly integrates with model-based kinodynamic\nplanners, leveraging uncertainty estimates to bias control sampling toward more\nreliable actions. We evaluate our approach in both simulation and real-world\nenvironments and demonstrate that it improves data efficiency and planning\nsuccess rates compared to baseline methods.", "AI": {"title_translation": "ActivePusher：基于残差物理的主动学习与规划在非抓取操作中的应用", "tldr": "ActivePusher通过结合残差物理和主动学习，提高了非抓取操作的数据效率和规划成功率。", "motivation": "在推或滚等非抓取操作中，难以获得准确的分析模型，而基于学习的动力学模型虽然有前景，但训练数据收集成本高且效率低下，因为随机采样交互不一定信息量最大。", "method": "提出ActivePusher框架，结合残差物理建模与基于核的不确定性驱动主动学习，以集中获取信息量最大的技能参数数据。此外，ActivePusher与基于模型的运动学规划器无缝集成，利用不确定性估计来偏向更可靠的动作控制采样。", "result": "在仿真和真实世界环境中评估了该方法，结果表明与基线方法相比，它提高了数据效率和规划成功率。", "conclusion": "ActivePusher框架有效解决了非抓取操作中数据收集效率低的问题，并通过结合残差物理、主动学习和不确定性驱动的规划，显著提高了规划成功率。", "translation": "基于学习动力学模型的规划为现实世界中的长周期操作提供了一种有前景的方法，特别是在推或滚等非抓取环境中，因为在这些环境中很难获得准确的分析模型。尽管基于学习的方法前景广阔，但收集训练数据可能成本高昂且效率低下，因为它通常依赖于随机采样的交互，而这些交互不一定是信息量最大的。为了解决这一挑战，我们提出了ActivePusher，一个新颖的框架，它将残差物理建模与基于核的不确定性驱动主动学习相结合，以将数据获取集中在信息量最大的技能参数上。此外，ActivePusher与基于模型的运动学规划器无缝集成，利用不确定性估计将控制采样偏向更可靠的动作。我们在仿真和真实世界环境中评估了我们的方法，并证明与基线方法相比，它提高了数据效率和规划成功率。", "summary": "ActivePusher是一个针对非抓取操作的新型框架，它结合了残差物理建模和基于核的不确定性驱动主动学习，以提高数据采集效率。该框架还利用不确定性估计来优化模型基运动学规划器中的控制采样。实验结果表明，ActivePusher在仿真和实际环境中均能提高数据效率和规划成功率。", "keywords": "主动学习, 非抓取操作, 残差物理, 数据效率, 运动规划"}}
{"id": "2506.05079", "pdf": "https://arxiv.org/pdf/2506.05079", "abs": "https://arxiv.org/abs/2506.05079", "authors": ["Shengcheng Yu", "Yuchen Ling", "Chunrong Fang", "Quan Zhou", "Chunyang Chen", "Shaomin Zhu", "Zhenyu Chen"], "title": "LLM-Guided Scenario-based GUI Testing", "categories": ["cs.SE"], "comment": null, "summary": "The assurance of mobile app GUI is more and more significant. Automated GUI\ntesting approaches of different strategies have been developed, while there are\nstill huge gaps between the approaches and the app business logic, not taking\nthe completion of specific testing scenarios as the exploration target, leading\nto the exploration missing of critical app functionalities. Learning from the\nmanual testing, which takes testing scenarios with app business logic as the\nbasic granularity, in this paper, we utilize the LLMs to understand the\nsemantics presented in app GUI and how they are mapped in the testing context\nbased on specific testing scenarios. Then, scenario-based GUI tests are\ngenerated with the guidance of multi-agent collaboration. Specifically, we\npropose ScenGen, a novel LLM-guided scenario-based GUI testing approach\ninvolving five agents to respectively take responsibilities of different phases\nof the manual testing process. The Observer perceives the app GUI state by\nextracting GUI widgets and forming GUI layouts, understanding the expressed\nsemantics. Then the app GUI info is sent to the Decider to make decisions on\ntarget widgets based on the target testing scenarios. The decision-making\nprocess takes the completion of specific testing scenarios as the exploration\ntarget. The Executor then executes the demanding operations on the apps. The\nexecution results are checked by the Supervisor on whether the generated tests\nare consistent with the completion target of the testing scenarios, ensuring\nthe traceability of the test generation and execution. Furthermore, the\ncorresponding GUI test operations are recorded to the context memory by\nRecorder as an important basis for further decision-making, meanwhile\nmonitoring the runtime bug occurrences. ScenGen is evaluated and the results\nshow that ScenGen can effectively generate scenario-based GUI tests guided by\nLLMs.", "AI": {"title_translation": "LLM引导的基于场景的GUI测试", "tldr": "本文提出了一种名为ScenGen的LLM引导的基于场景的GUI测试方法，通过多智能体协作生成测试用例，有效解决了传统GUI测试与业务逻辑脱节的问题。", "motivation": "现有的自动化GUI测试方法与应用程序业务逻辑存在巨大差距，未能将特定测试场景的完成作为探索目标，导致关键应用功能的探索遗漏。", "method": "本文提出了一种名为ScenGen的新型LLM引导的基于场景的GUI测试方法，该方法涉及五个智能体进行多智能体协作：Observer感知GUI状态和语义；Decider根据测试场景做出目标决策；Executor执行操作；Supervisor检查测试与完成目标的S一致性；Recorder记录操作并监控bug。", "result": "评估结果表明，ScenGen能够有效地生成由LLM引导的基于场景的GUI测试。", "conclusion": "ScenGen能够有效地生成由LLM引导的基于场景的GUI测试，解决了传统方法的不足，提高了测试的有效性。", "translation": "移动应用程序GUI的保障越来越重要。虽然已经开发了不同策略的自动化GUI测试方法，但这些方法与应用程序业务逻辑之间仍然存在巨大差距，未能将特定测试场景的完成作为探索目标，导致关键应用功能的探索遗漏。借鉴以应用程序业务逻辑中的测试场景作为基本粒度的人工测试，本文利用大型语言模型（LLMs）来理解应用程序GUI中呈现的语义以及它们如何在特定测试场景下映射到测试上下文中。然后，在多智能体协作的指导下生成基于场景的GUI测试。具体来说，我们提出了ScenGen，一种新颖的LLM引导的基于场景的GUI测试方法，该方法涉及五个智能体，分别负责人工测试过程的不同阶段。Observer通过提取GUI小部件并形成GUI布局来感知应用程序GUI状态，理解所表达的语义。然后将应用程序GUI信息发送给Decider，根据目标测试场景做出目标小部件的决策。决策过程将特定测试场景的完成作为探索目标。Executor然后对应用程序执行所需的操作。Supervisor检查执行结果，判断生成的测试是否与测试场景的完成目标一致，从而确保测试生成和执行的可追溯性。此外，Recorder将相应的GUI测试操作记录到上下文内存中，作为进一步决策的重要基础，同时监控运行时bug的发生。ScenGen经过评估，结果表明ScenGen能够有效地生成由LLMs引导的基于场景的GUI测试。", "summary": "本文提出了一种名为ScenGen的LLM引导的基于场景的GUI测试方法，旨在解决现有自动化GUI测试与应用业务逻辑脱节的问题。ScenGen通过利用大型语言模型理解GUI语义和测试场景，并采用多智能体协作（包括Observer、Decider、Executor、Supervisor和Recorder五个智能体）来生成和执行基于场景的GUI测试，确保测试用例的生成和执行与特定场景的完成目标一致，从而有效提升了移动应用GUI测试的覆盖率和有效性。", "keywords": "LLM, GUI测试, 场景测试, 多智能体, 移动应用"}}
{"id": "2506.04478", "pdf": "https://arxiv.org/pdf/2506.04478", "abs": "https://arxiv.org/abs/2506.04478", "authors": ["Hadi Hosseini", "Samarth Khanna", "Ronak Singh"], "title": "Matching Markets Meet LLMs: Algorithmic Reasoning with Ranked Preferences", "categories": ["cs.AI", "cs.GT", "econ.TH", "I.2.6; I.2.11; J.4"], "comment": null, "summary": "The rise of Large Language Models (LLMs) has driven progress in reasoning\ntasks -- from program synthesis to scientific hypothesis generation -- yet\ntheir ability to handle ranked preferences and structured algorithms in\ncombinatorial domains remains underexplored. We study matching markets, a core\nframework behind applications like resource allocation and ride-sharing, which\nrequire reconciling individual ranked preferences to ensure stable outcomes. We\nevaluate several state-of-the-art models on a hierarchy of preference-based\nreasoning tasks -- ranging from stable-matching generation to instability\ndetection, instability resolution, and fine-grained preference queries -- to\nsystematically expose their logical and algorithmic limitations in handling\nranked inputs. Surprisingly, even top-performing models with advanced reasoning\nstruggle to resolve instability in large markets, often failing to identify\nblocking pairs or execute algorithms iteratively. We further show that\nparameter-efficient fine-tuning (LoRA) significantly improves performance in\nsmall markets, but fails to bring about a similar improvement on large\ninstances, suggesting the need for more sophisticated strategies to improve\nLLMs' reasoning with larger-context inputs.", "AI": {"title_translation": "匹配市场遇上大型语言模型：基于排序偏好的算法推理", "tldr": "研究LLM在处理匹配市场中排序偏好和算法推理的能力，发现其在大规模市场中存在局限性，需要更复杂的策略。", "motivation": "大型语言模型（LLMs）在推理任务中取得了进展，但其处理组合领域中排序偏好和结构化算法的能力尚未充分探索。匹配市场需要协调个体排序偏好以确保稳定结果。", "method": "评估了最先进的模型在一系列基于偏好的推理任务（包括稳定匹配生成、不稳定检测、不稳定解决和细粒度偏好查询）上的表现，并使用参数高效微调（LoRA）进行改进。", "result": "即使是表现最好的模型也难以解决大型市场中的不稳定问题，常无法识别阻塞对或迭代执行算法。参数高效微调（LoRA）显著提高了小型市场的性能，但在大型实例上未能带来类似改善。", "conclusion": "LLM在处理大型上下文输入时的推理能力需要更复杂的策略来改进。", "translation": "大型语言模型（LLMs）的兴起推动了推理任务的进展——从程序合成到科学假设生成——然而，它们在组合领域中处理排序偏好和结构化算法的能力仍未得到充分探索。我们研究了匹配市场，这是资源分配和拼车等应用背后的核心框架，它需要协调个体排序偏好以确保稳定的结果。我们评估了多个最先进的模型在一系列基于偏好的推理任务上的表现——从稳定匹配生成到不稳定检测、不稳定解决和细粒度偏好查询——以系统地揭示它们在处理排序输入时的逻辑和算法局限性。令人惊讶的是，即使是具有先进推理能力的顶尖模型，在解决大型市场的不稳定性问题时也举步维艰，常常无法识别阻塞对或迭代执行算法。我们进一步表明，参数高效微调（LoRA）显著提高了小型市场的性能，但未能在大规模实例上带来类似改善，这表明需要更复杂的策略来改进LLMs处理更大上下文输入的推理能力。", "summary": "该研究探讨了大型语言模型（LLMs）在匹配市场中处理排序偏好和执行算法推理的能力。通过在多层级偏好推理任务上评估现有模型，发现LLMs在解决大型市场的不稳定性问题上表现不佳，即使是先进模型也难以识别阻塞对或迭代执行算法。尽管参数高效微调（LoRA）在小型市场中表现出显著提升，但对大型实例的改进有限，这表明需要更精密的策略来提升LLMs处理大规模上下文输入的推理能力。", "keywords": "匹配市场, 大型语言模型, 算法推理, 排序偏好, 不稳定性解决"}}
{"id": "2506.04401", "pdf": "https://arxiv.org/pdf/2506.04401", "abs": "https://arxiv.org/abs/2506.04401", "authors": ["Gustavo Perez", "Stella X. Yu"], "title": "Normalize Filters! Classical Wisdom for Deep Vision", "categories": ["cs.CV"], "comment": null, "summary": "Classical image filters, such as those for averaging or differencing, are\ncarefully normalized to ensure consistency, interpretability, and to avoid\nartifacts like intensity shifts, halos, or ringing. In contrast, convolutional\nfilters learned end-to-end in deep networks lack such constraints. Although\nthey may resemble wavelets and blob/edge detectors, they are not normalized in\nthe same or any way. Consequently, when images undergo atmospheric transfer,\ntheir responses become distorted, leading to incorrect outcomes. We address\nthis limitation by proposing filter normalization, followed by learnable\nscaling and shifting, akin to batch normalization. This simple yet effective\nmodification ensures that the filters are atmosphere-equivariant, enabling\nco-domain symmetry. By integrating classical filtering principles into deep\nlearning (applicable to both convolutional neural networks and\nconvolution-dependent vision transformers), our method achieves significant\nimprovements on artificial and natural intensity variation benchmarks. Our\nResNet34 could even outperform CLIP by a large margin. Our analysis reveals\nthat unnormalized filters degrade performance, whereas filter normalization\nregularizes learning, promotes diversity, and improves robustness and\ngeneralization.", "AI": {"title_translation": "归一化滤波器！深度视觉中的经典智慧", "tldr": "本文提出了一种滤波器归一化方法，类似于批归一化，以解决深度网络中未归一化卷积滤波器在图像大气传输下响应失真的问题，从而显著提高了在强度变化基准上的性能，并提升了模型的鲁棒性和泛化能力。", "motivation": "深度网络中端到端学习的卷积滤波器缺乏像经典图像滤波器那样的归一化约束，导致当图像经历大气传输时，其响应会失真，从而导致不正确的结果。", "method": "提出滤波器归一化，然后进行可学习的缩放和移位，类似于批归一化。该方法将经典滤波原理整合到深度学习中（适用于卷积神经网络和依赖卷积的视觉Transformer）。", "result": "在人工和自然强度变化基准上取得了显著改进。ResNet34甚至大幅超越了CLIP。分析表明，未归一化滤波器会降低性能，而滤波器归一化可以规范学习、促进多样性并提高鲁棒性和泛化能力。", "conclusion": "滤波器归一化是一种简单而有效的修改，它确保了滤波器的大气等变性，实现了共域对称性，并能显著提升深度视觉模型的性能、鲁棒性和泛化能力。", "translation": "经典图像滤波器，例如用于平均或差分的滤波器，都经过精心归一化，以确保一致性、可解释性，并避免强度偏移、光晕或振铃等伪影。相比之下，深度网络中端到端学习的卷积滤波器缺乏此类约束。尽管它们可能类似于小波和斑点/边缘检测器，但它们没有以相同或任何方式进行归一化。因此，当图像经过大气传输时，它们的响应会失真，导致不正确的结果。我们通过提出滤波器归一化，然后进行可学习的缩放和移位（类似于批归一化）来解决这一限制。这种简单而有效的修改确保了滤波器的大气等变性，实现了共域对称性。通过将经典滤波原理整合到深度学习中（适用于卷积神经网络和依赖卷积的视觉Transformer），我们的方法在人工和自然强度变化基准上取得了显著改进。我们的ResNet34甚至可以大幅超越CLIP。我们的分析表明，未归一化滤波器会降低性能，而滤波器归一化可以规范学习、促进多样性，并提高鲁棒性和泛化能力。", "summary": "该论文提出了一种滤波器归一化方法，旨在解决深度学习中卷积滤波器缺乏归一化导致图像在大气传输下响应失真的问题。通过将经典的滤波原理融入深度网络，并引入类似批归一化的可学习缩放和移位，该方法使得滤波器具有大气等变性。实验证明，此方法在强度变化基准上显著提升了性能，并能提高模型的鲁棒性、泛化能力和学习多样性。", "keywords": "滤波器归一化, 深度学习, 卷积神经网络, 大气等变性, 鲁棒性"}}
{"id": "2506.04775", "pdf": "https://arxiv.org/pdf/2506.04775", "abs": "https://arxiv.org/abs/2506.04775", "authors": ["Artin Tajdini", "Jonathan Scarlett", "Kevin Jamieson"], "title": "Improved Regret Bounds for Linear Bandits with Heavy-Tailed Rewards", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "comment": null, "summary": "We study stochastic linear bandits with heavy-tailed rewards, where the\nrewards have a finite $(1+\\epsilon)$-absolute central moment bounded by\n$\\upsilon$ for some $\\epsilon \\in (0,1]$. We improve both upper and lower\nbounds on the minimax regret compared to prior work. When $\\upsilon =\n\\mathcal{O}(1)$, the best prior known regret upper bound is\n$\\tilde{\\mathcal{O}}(d T^{\\frac{1}{1+\\epsilon}})$. While a lower with the same\nscaling has been given, it relies on a construction using $\\upsilon =\n\\mathcal{O}(d)$, and adapting the construction to the bounded-moment regime\nwith $\\upsilon = \\mathcal{O}(1)$ yields only a\n$\\Omega(d^{\\frac{\\epsilon}{1+\\epsilon}} T^{\\frac{1}{1+\\epsilon}})$ lower bound.\nThis matches the known rate for multi-armed bandits and is generally loose for\nlinear bandits, in particular being $\\sqrt{d}$ below the optimal rate in the\nfinite-variance case ($\\epsilon = 1$). We propose a new elimination-based\nalgorithm guided by experimental design, which achieves regret\n$\\tilde{\\mathcal{O}}(d^{\\frac{1+3\\epsilon}{2(1+\\epsilon)}}\nT^{\\frac{1}{1+\\epsilon}})$, thus improving the dependence on $d$ for all\n$\\epsilon \\in (0,1)$ and recovering a known optimal result for $\\epsilon = 1$.\nWe also establish a lower bound of $\\Omega(d^{\\frac{2\\epsilon}{1+\\epsilon}}\nT^{\\frac{1}{1+\\epsilon}})$, which strictly improves upon the multi-armed bandit\nrate and highlights the hardness of heavy-tailed linear bandit problems. For\nfinite action sets, we derive similarly improved upper and lower bounds for\nregret. Finally, we provide action set dependent regret upper bounds showing\nthat for some geometries, such as $l_p$-norm balls for $p \\le 1 + \\epsilon$, we\ncan further reduce the dependence on $d$, and we can handle\ninfinite-dimensional settings via the kernel trick, in particular establishing\nnew regret bounds for the Mat\\'ern kernel that are the first to be sublinear\nfor all $\\epsilon \\in (0, 1]$.", "AI": {"title_translation": "线性赌博机重尾奖励的改进遗憾界", "tldr": "本文研究了重尾奖励的随机线性赌博机，改进了现有工作中的遗憾界限，并提出了一种新的消除算法，实现了更优的遗憾界。", "motivation": "现有工作中，重尾奖励线性赌博机的遗憾上界次优，且下界宽松，尤其是在有限方差情况下。已有的下界构造无法完全适应有界矩机制。", "method": "本文提出了一种由实验设计指导的新型基于消除的算法。对于有限动作集，推导了类似改进的界限。此外，还探索了特定几何形状下依赖于动作集的遗憾上界，并通过核技巧处理了无限维设置。", "result": "遗憾上界改进为 $\\tilde{\\mathcal{O}}(d^{\\\\frac{1+3\\\\epsilon}{2(1+\\\\epsilon)}} T^{\\\\frac{1}{1+\\\\epsilon}})$，改进了所有 $\\\\epsilon \\\\in (0,1)$ 的 $d$ 依赖性，并恢复了 $\\\\epsilon = 1$ 的已知最优结果。建立了下界 $\\\\Omega(d^{\\\\frac{2\\\\epsilon}{1+\\\\epsilon}} T^{\\\\frac{1}{1+\\\\epsilon}})$，严格改进了多臂赌博机的速率。为有限动作集推导了类似改进的上下界。对于某些几何形状（如 $p \\\\le 1 + \\\\epsilon$ 的 $l_p$-范数球），可以进一步减少对 $d$ 的依赖性。通过核技巧处理无限维设置，为Matérn核建立了新的次线性遗憾界。", "conclusion": "本文显著改进了重尾奖励线性赌博机的遗憾界，提出了一种新算法并建立了更紧密的下界，突出了此类问题的难度，并将其适用性扩展到包括无限维在内的各种设置。", "translation": "我们研究了具有重尾奖励的随机线性赌博机，其中奖励具有有限的 $(1+\\epsilon)$-绝对中心矩，且其值受 $\\upsilon$ 限制，其中 $\\epsilon \\in (0,1]$。与现有工作相比，我们改进了最小最大遗憾的上下界。当 $\\upsilon = \\mathcal{O}(1)$ 时，之前已知的最佳遗憾上界是 $\\tilde{\\mathcal{O}}(d T^{\\frac{1}{1+\\epsilon}})$。虽然已经给出了具有相同尺度的下界，但它依赖于使用 $\\upsilon = \\mathcal{O}(d)$ 的构造，并且将该构造调整到 $\\upsilon = \\mathcal{O}(1)$ 的有界矩机制仅产生 $\\Omega(d^{\\frac{\\epsilon}{1+\\epsilon}} T^{\\frac{1}{1+\\epsilon}})$ 的下界。这与多臂赌博机的已知速率相匹配，但对于线性赌博机通常是宽松的，尤其是在有限方差情况下（$\\epsilon = 1$）低于最优速率 $\\sqrt{d}$。我们提出了一种由实验设计指导的新型基于消除的算法，该算法实现了 $\\tilde{\\mathcal{O}}(d^{\\frac{1+3\\epsilon}{2(1+\\epsilon)}} T^{\\frac{1}{1+\\epsilon}})$ 的遗憾，从而改进了所有 $\\epsilon \\in (0,1)$ 的 $d$ 依赖性，并恢复了 $\\epsilon = 1$ 的已知最优结果。我们还建立了 $\\Omega(d^{\\frac{2\\epsilon}{1+\\epsilon}} T^{\\frac{1}{1+\\epsilon}})$ 的下界，这严格改进了多臂赌博机的速率，并突出了重尾线性赌博机问题的难度。对于有限动作集，我们推导出了类似改进的遗憾上下界。最后，我们提供了依赖于动作集的遗憾上界，表明对于某些几何形状，例如 $p \\le 1 + \\epsilon$ 的 $l_p$-范数球，我们可以进一步减少对 $d$ 的依赖性，并且可以通过核技巧处理无限维设置，特别是为 Matérn 核建立了新的遗憾界，这是首次对所有 $\\epsilon \\in (0, 1]$ 实现次线性。", "summary": "本文研究了具有重尾奖励的随机线性赌博机问题，其中奖励具有有限的 $(1+\\epsilon)$-绝对中心矩。作者改进了现有工作的最小最大遗憾上下界，并提出了一种新的基于消除的实验设计算法，该算法在 $d$ 的依赖性上实现了显著改进，并恢复了有限方差情况下的最优结果。此外，论文还建立了更严格的下界，突出了重尾线性赌博机问题的难度，并为有限动作集和某些几何形状的无限维设置提供了改进的遗憾界。", "keywords": "线性赌博机, 重尾奖励, 遗憾界, 消除算法, 核技巧"}}
{"id": "2506.04288", "pdf": "https://arxiv.org/pdf/2506.04288", "abs": "https://arxiv.org/abs/2506.04288", "authors": ["Jae Wan Park", "Junhyeok Kim", "Youngjun Jun", "Hyunah Ko", "Seong Jae Hwang"], "title": "Backbone Augmented Training for Adaptations", "categories": ["cs.LG"], "comment": null, "summary": "Adaptations facilitate efficient training of large backbone models, including\ndiffusion models for image generation and transformer-based language models.\nWhile various adaptation techniques enhance performance with minimal\ncomputational resources, limited adaptation data often leads to challenges in\ntraining. To address this, we focus on the enormous amount of backbone data\nused to pre-train the backbone models. We propose Backbone Augmented Training\n(BAT), a method that leverages backbone data to augment the adaptation dataset.\nFirst, we formulate and prove two mathematical key propositions: one\nestablishes the validity of BAT, while the other identifies a condition under\nwhich BAT benefits adaptation. Furthermore, we introduce an advanced data\nselection scheme that satisfies these propositions and present ALBAT algorithm\nto implement this approach. ALBAT efficiently enhances adaptation training in\nboth personalization and language generation tasks with scarce data.", "AI": {"title_translation": "骨干增强训练用于适配", "tldr": "提出骨干增强训练（BAT）方法，利用预训练骨干数据扩充适配数据集，提高数据稀缺下的适配训练效率，并证明其有效性。", "motivation": "适配技术在训练大型骨干模型时面临数据量有限的挑战，导致训练困难。", "method": "提出骨干增强训练（BAT），利用骨干数据增强适配数据集。通过数学命题证明BAT的有效性及受益条件，并引入先进的数据选择方案和ALBAT算法实现该方法。", "result": "ALBAT算法在数据稀缺的个性化和语言生成任务中有效提升了适配训练。", "conclusion": "骨干增强训练（BAT）通过利用预训练骨干数据，能够有效解决适配训练中数据稀缺的问题，ALBAT算法在实践中证明了其有效性。", "translation": "适配有助于高效训练大型骨干模型，包括用于图像生成的扩散模型和基于Transformer的语言模型。尽管各种适配技术以最少的计算资源提高了性能，但有限的适配数据通常会导致训练挑战。为了解决这个问题，我们关注用于预训练骨干模型的巨大骨干数据量。我们提出了骨干增强训练（BAT），一种利用骨干数据扩充适配数据集的方法。首先，我们制定并证明了两个关键的数学命题：一个确立了BAT的有效性，另一个确定了BAT有利于适配的条件。此外，我们引入了一种满足这些命题的先进数据选择方案，并提出了ALBAT算法来实现这种方法。ALBAT在数据稀缺的个性化和语言生成任务中有效增强了适配训练。", "summary": "该论文提出了一种名为骨干增强训练（BAT）的新方法，旨在解决适配技术在数据量有限时面临的训练挑战。BAT通过利用用于预训练骨干模型的骨干数据来扩充适配数据集。作者提出了两个数学命题来证明BAT的有效性及其受益条件，并在此基础上引入了一种先进的数据选择方案和ALBAT算法。实验结果表明，ALBAT在数据稀缺的个性化和语言生成任务中显著提高了适配训练的效率。", "keywords": "骨干增强训练, 适配, 数据增强, 大型模型, ALBAT"}}
{"id": "2506.05211", "pdf": "https://arxiv.org/pdf/2506.05211", "abs": "https://arxiv.org/abs/2506.05211", "authors": ["David Atkinson", "Jena D. Hwang", "Jacob Morrison"], "title": "Intentionally Unintentional: GenAI Exceptionalism and the First Amendment", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "This paper challenges the assumption that courts should grant First Amendment\nprotections to outputs from large generative AI models, such as GPT-4 and\nGemini. We argue that because these models lack intentionality, their outputs\ndo not constitute speech as understood in the context of established legal\nprecedent, so there can be no speech to protect. Furthermore, if the model\noutputs are not speech, users cannot claim a First Amendment speech right to\nreceive the outputs. We also argue that extending First Amendment rights to AI\nmodels would not serve the fundamental purposes of free speech, such as\npromoting a marketplace of ideas, facilitating self-governance, or fostering\nself-expression. In fact, granting First Amendment protections to AI models\nwould be detrimental to society because it would hinder the government's\nability to regulate these powerful technologies effectively, potentially\nleading to the unchecked spread of misinformation and other harms.", "AI": {"title_translation": "故意非故意：生成式人工智能的特殊性与第一修正案", "tldr": "生成式人工智能的输出不应获得第一修正案保护，因为它们缺乏意图性，且这样做会对社会造成危害。", "motivation": "本文旨在挑战法院应给予大型生成式人工智能模型输出第一修正案保护的假设。", "method": "通过法律论证，分析既定法律先例和言论自由的根本目的。", "result": "由于缺乏意图性，人工智能的输出不构成“言论”，因此没有言论可受保护。用户不能声称享有接收这些输出的第一修正案言论权。将第一修正案权利扩展到人工智能模型无助于实现言论自由的根本目的。给予人工智能模型第一修正案保护将对社会有害，因为它会阻碍政府有效监管这些强大技术的能力，可能导致错误信息和其他危害的 unchecked 传播。", "conclusion": "给予人工智能模型第一修正案保护将对社会有害，因为它会阻碍政府有效监管这些强大技术的能力，可能导致错误信息和其他危害的 unchecked 传播，从而损害言论自由的根本目的。", "translation": "本文挑战了法院应给予大型生成式人工智能模型（如GPT-4和Gemini）输出第一修正案保护的假设。我们认为，由于这些模型缺乏意图性，其输出不构成既定法律先例所理解的言论，因此没有言论可受保护。此外，如果模型输出不是言论，用户就不能声称享有接收这些输出的第一修正案言论权。我们还认为，将第一修正案权利扩展到人工智能模型无助于实现言论自由的根本目的，例如促进思想市场、促进自治或培养自我表达。事实上，给予人工智能模型第一修正案保护将对社会有害，因为它会阻碍政府有效监管这些强大技术的能力，可能导致错误信息和其他危害的 unchecked 传播。", "summary": "本文反对将第一修正案保护扩展到GPT-4和Gemini等大型生成式人工智能模型的输出。作者认为，由于这些模型缺乏意图性，其输出不构成法律先例中的“言论”，因此没有言论可受保护，用户也无权接收。此外，论文指出，将第一修正案权利扩展到人工智能模型无助于实现言论自由的根本目的，反而会阻碍政府有效监管，导致错误信息扩散，对社会造成危害。", "keywords": "生成式人工智能, 第一修正案, 意图性, 言论自由, 监管"}}
{"id": "2506.04940", "pdf": "https://arxiv.org/pdf/2506.04940", "abs": "https://arxiv.org/abs/2506.04940", "authors": ["Andrea Canidio", "Vabuk Pahari"], "title": "Becoming Immutable: How Ethereum is Made", "categories": ["econ.GN", "cs.DC", "q-fin.EC"], "comment": null, "summary": "We analyze blocks proposed for inclusion in the Ethereum blockchain during 8\nminutes on December 3rd, 2024. Our dataset comprises 38 winning blocks, 15,097\nproposed blocks, 10,793 unique transactions, and 2,380,014 transaction-block\npairings. We find that exclusive transactions--transactions present only in\nblocks proposed by a single builder--account for 85% of the fees paid by all\ntransactions included in winning blocks. We also find that a surprisingly large\nnumber of user transactions are delayed: although proposed during a bidding\ncycle, they are not included in the corresponding winning block. Many such\ndelayed transactions are exclusive to a losing builder. We also identify two\narbitrage bots trading between decentralized (DEX) and centralized exchanges\n(CEX). By examining their bidding dynamics, we estimate that the implied price\nat which these bots trade USDC/WETH and USDT/WETH on CEXes is between 3.4 and\n4.2 basis points better than the contemporaneous price reported on Binance.", "AI": {"title_translation": "成为不可变：以太坊是如何构建的", "tldr": "本研究分析了以太坊区块数据，发现独占交易贡献了大部分费用，大量用户交易被延迟，并识别出利用DEX/CEX价差的套利机器人。", "motivation": "通过分析以太坊区块链的区块提案数据，揭示交易行为、费用结构和市场效率，特别是独占交易和套利活动的影响。", "method": "分析了2024年12月3日8分钟内以太坊区块链上提出的区块数据，数据集包含38个获胜区块、15,097个提议区块、10,793个唯一交易和2,380,014个交易-区块配对。研究方法包括对独占交易、延迟交易的识别，以及对DEX和CEX之间套利机器人的投标动态分析。", "result": "独占交易占获胜区块中所有交易支付费用的85%。大量用户交易被延迟，其中许多是失败构建者的独占交易。识别出两个在DEX和CEX之间进行交易的套利机器人。这些套利机器人在CEX上交易USDC/WETH和USDT/WETH的隐含价格比Binance同期报告的价格好3.4到4.2个基点。", "conclusion": "独占交易在以太坊费用结构中占据主导地位，用户交易面临延迟风险，且存在利用DEX/CEX价差的套利活动，表明以太坊区块构建过程中的复杂性和效率问题。", "translation": "我们分析了2024年12月3日8分钟内提议纳入以太坊区块链的区块。我们的数据集包括38个获胜区块、15,097个提议区块、10,793个唯一交易和2,380,014个交易-区块配对。我们发现，独占交易——仅由单个构建者提议的区块中存在的交易——占获胜区块中所有交易支付费用的85%。我们还发现，大量用户交易被出人意料地延迟：尽管在投标周期内被提议，但它们并未包含在相应的获胜区块中。许多此类延迟交易是某个失败构建者的独占交易。我们还识别出两个在去中心化交易所（DEX）和中心化交易所（CEX）之间进行交易的套利机器人。通过检查它们的投标动态，我们估计这些机器人在CEX上交易USDC/WETH和USDT/WETH的隐含价格比币安同期报告的价格好3.4到4.2个基点。", "summary": "本研究分析了以太坊区块链在特定时间段内的区块提案数据，揭示了独占交易在费用构成中的主导地位以及用户交易普遍存在的延迟现象。此外，研究还识别出利用去中心化和中心化交易所之间价差进行套利的机器人，并量化了其交易优势。这些发现为理解以太坊区块构建机制中的交易动态、费用结构和市场效率提供了深入见解。", "keywords": "以太坊, 区块链, 独占交易, 套利机器人, 交易延迟"}}
{"id": "2506.05074", "pdf": "https://arxiv.org/pdf/2506.05074", "abs": "https://arxiv.org/abs/2506.05074", "authors": ["Robert J. Joyce", "Gideon Miller", "Phil Roth", "Richard Zak", "Elliott Zaresky-Williams", "Hyrum Anderson", "Edward Raff", "James Holt"], "title": "EMBER2024 -- A Benchmark Dataset for Holistic Evaluation of Malware Classifiers", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "A lack of accessible data has historically restricted malware analysis\nresearch, and practitioners have relied heavily on datasets provided by\nindustry sources to advance. Existing public datasets are limited by narrow\nscope - most include files targeting a single platform, have labels supporting\njust one type of malware classification task, and make no effort to capture the\nevasive files that make malware detection difficult in practice. We present\nEMBER2024, a new dataset that enables holistic evaluation of malware\nclassifiers. Created in collaboration with the authors of EMBER2017 and\nEMBER2018, the EMBER2024 dataset includes hashes, metadata, feature vectors,\nand labels for more than 3.2 million files from six file formats. Our dataset\nsupports the training and evaluation of machine learning models on seven\nmalware classification tasks, including malware detection, malware family\nclassification, and malware behavior identification. EMBER2024 is the first to\ninclude a collection of malicious files that initially went undetected by a set\nof antivirus products, creating a \"challenge\" set to assess classifier\nperformance against evasive malware. This work also introduces EMBER feature\nversion 3, with added support for several new feature types. We are releasing\nthe EMBER2024 dataset to promote reproducibility and empower researchers in the\npursuit of new malware research topics.", "AI": {"title_translation": "EMBER2024——一个用于恶意软件分类器整体评估的基准数据集", "tldr": "EMBER2024是一个新的大型恶意软件数据集，包含320万文件，支持多种分类任务，并首次引入了“挑战”集以评估对规避性恶意软件的检测能力，旨在促进恶意软件研究。", "motivation": "现有的公开恶意软件数据集存在范围狭窄、只针对单一平台或分类任务、且未能包含规避性文件等限制，这阻碍了恶意软件分析研究的进展。", "method": "本文提出了EMBER2024数据集，它是与EMBER2017和EMBER2018的作者合作创建的。该数据集包含超过320万个文件（来自六种文件格式）的哈希、元数据、特征向量和标签。此外，该工作还引入了EMBER特征版本3，增加了对几种新特征类型的支持。", "result": "EMBER2024数据集支持在七种恶意软件分类任务上训练和评估机器学习模型，包括恶意软件检测、恶意软件家族分类和恶意软件行为识别。它是第一个包含一组最初未被杀毒产品检测到的恶意文件（即“挑战”集）的数据集，用于评估分类器对规避性恶意软件的性能。", "conclusion": "EMBER2024数据集的发布旨在解决现有恶意软件数据集的局限性，通过提供一个全面、大规模且包含规避性文件的基准，促进恶意软件研究的再现性，并赋能研究人员探索新的恶意软件研究课题。", "translation": "可访问数据的缺乏历来限制了恶意软件分析研究，从业者严重依赖行业来源提供的数据集来推进研究。现有的公共数据集范围狭窄——大多数只包含针对单一平台的文件，其标签仅支持一种类型的恶意软件分类任务，并且没有努力捕获使恶意软件检测在实践中变得困难的规避性文件。我们提出了EMBER2024，一个能够对恶意软件分类器进行整体评估的新数据集。EMBER2024数据集与EMBER2017和EMBER2018的作者合作创建，包含了来自六种文件格式的超过320万个文件的哈希、元数据、特征向量和标签。我们的数据集支持在七种恶意软件分类任务上训练和评估机器学习模型，包括恶意软件检测、恶意软件家族分类和恶意软件行为识别。EMBER2024是第一个包含一组最初未被一系列杀毒产品检测到的恶意文件的数据集，创建了一个“挑战”集来评估分类器对抗规避性恶意软件的性能。这项工作还引入了EMBER特征版本3，增加了对几种新特征类型的支持。我们正在发布EMBER2024数据集，以促进研究的再现性，并赋能研究人员追求新的恶意软件研究课题。", "summary": "本文介绍了EMBER2024，这是一个为解决现有恶意软件数据集局限性而设计的新型基准数据集。该数据集与EMBER2017和EMBER2018的作者合作开发，包含超过320万个文件，涵盖哈希、元数据、特征向量和标签，支持七种不同的恶意软件分类任务。EMBER2024首次纳入了“挑战”集，即一批最初未被杀毒软件检测到的规避性恶意文件，以评估分类器在实际对抗中的性能。此外，该工作还推出了EMBER特征版本3。EMBER2024的发布旨在提升恶意软件研究的整体评估能力和再现性。", "keywords": "恶意软件分类, 基准数据集, EMBER2024, 规避性恶意软件, 机器学习"}}
{"id": "2506.05252", "pdf": "https://arxiv.org/pdf/2506.05252", "abs": "https://arxiv.org/abs/2506.05252", "authors": ["Dravyansh Sharma", "Alec Sun"], "title": "Conservative classifiers do consistently well with improving agents: characterizing statistical and online learning", "categories": ["cs.LG", "cs.GT", "cs.MA"], "comment": "24 pages", "summary": "Machine learning is now ubiquitous in societal decision-making, for example\nin evaluating job candidates or loan applications, and it is increasingly\nimportant to take into account how classified agents will react to the learning\nalgorithms. The majority of recent literature on strategic classification has\nfocused on reducing and countering deceptive behaviors by the classified\nagents, but recent work of Attias et al. identifies surprising properties of\nlearnability when the agents genuinely improve in order to attain the desirable\nclassification, such as smaller generalization error than standard\nPAC-learning. In this paper we characterize so-called learnability with\nimprovements across multiple new axes. We introduce an asymmetric variant of\nminimally consistent concept classes and use it to provide an exact\ncharacterization of proper learning with improvements in the realizable\nsetting. While prior work studies learnability only under general, arbitrary\nagent improvement regions, we give positive results for more natural Euclidean\nball improvement sets. In particular, we characterize improper learning under a\nmild generative assumption on the data distribution. We further show how to\nlearn in more challenging settings, achieving lower generalization error under\nwell-studied bounded noise models and obtaining mistake bounds in realizable\nand agnostic online learning. We resolve open questions posed by Attias et al.\nfor both proper and improper learning.", "AI": {"title_translation": "保守分类器在智能体改进时表现始终良好：表征统计学习和在线学习", "tldr": "本文探讨了当智能体在分类器作用下真正改进时，可学习性的特性，并在不对称概念类、欧几里得球改进集等新设置下对其进行了表征，实现了更低的泛化误差。", "motivation": "机器学习在社会决策中日益普及，需要考虑被分类智能体对学习算法的反应。现有文献多关注欺骗行为，但Attias等人的近期工作发现智能体真正改进时可学习性有惊人特性。本研究旨在进一步表征这种“带改进的可学习性”。", "method": "引入最小一致概念类的非对称变体，用于精确表征可实现设置下带改进的正确学习。为更自然的欧几里得球改进集提供积极结果。在温和的生成假设下表征不正确学习。在有界噪声模型下实现更低泛化误差，并在可实现和不可知在线学习中获得错误界限。", "result": "精确表征了可实现设置下带改进的正确学习。为欧几里得球改进集提供了积极结果。在温和的生成假设下表征了不正确学习。在有界噪声模型下实现了更低的泛化误差。在可实现和不可知在线学习中获得了错误界限。解决了Attias等人提出的关于正确和不正确学习的开放问题。", "conclusion": "本文扩展了对智能体真正改进时可学习性的理解，在新的设置下提供了详细的特性描述，并解决了先前的开放问题，表明保守分类器在这种情境下表现良好。", "translation": "机器学习在社会决策中无处不在，例如在评估求职者或贷款申请时，并且越来越重要的是要考虑被分类的智能体将如何对学习算法做出反应。最近关于策略性分类的大多数文献都集中在减少和对抗被分类智能体的欺骗行为，但 Attias 等人的最新工作发现了当智能体为了获得理想分类而真正改进时可学习性的惊人特性，例如比标准 PAC 学习更小的泛化误差。在本文中，我们从多个新维度表征了所谓的“带改进的可学习性”。我们引入了最小一致概念类的一个非对称变体，并用它来精确表征在可实现设置下带改进的正确学习。虽然以前的工作仅在一般、任意的智能体改进区域下研究可学习性，但我们为更自然的欧几里得球改进集提供了积极结果。特别是，我们在数据分布的温和生成假设下表征了不正确学习。我们进一步展示了如何在更具挑战性的设置中进行学习，在经过充分研究的有界噪声模型下实现更低的泛化误差，并在可实现和不可知在线学习中获得错误界限。我们解决了 Attias 等人提出的关于正确和不正确学习的开放问题。", "summary": "本文研究了“带改进的可学习性”这一现象，即智能体为了获得理想分类而真正改进自身特性，这与先前关注欺骗行为的研究形成对比。文章引入了不对称概念类以精确表征正确学习，并为自然的欧几里得球改进集提供了积极结果，同时在生成假设下表征了不正确学习。此外，研究还展示了在存在噪声的挑战性设置下如何有效学习，并在在线学习中建立了错误界限，成功解决了先前研究中的开放问题。", "keywords": "可学习性, 策略性分类, 智能体改进, 泛化误差, 在线学习"}}
{"id": "2506.04680", "pdf": "https://arxiv.org/pdf/2506.04680", "abs": "https://arxiv.org/abs/2506.04680", "authors": ["Ping-Kong Huang", "Chien-Wu Lan", "Chin-Tien Wu"], "title": "Application of SDRE to Achieve Gait Control in a Bipedal Robot for Knee-Type Exoskeleton Testing", "categories": ["cs.RO", "math.OC"], "comment": "8 pages, 6 figures. Preliminary version submitted for documentation\n  purposes on arXiv. This version records results presented at a conference and\n  is not peer-reviewed", "summary": "Exoskeletons are widely used in rehabilitation and industrial applications to\nassist human motion. However, direct human testing poses risks due to possible\nexoskeleton malfunctions and inconsistent movement replication. To provide a\nsafer and more repeatable testing environment, this study employs a bipedal\nrobot platform to reproduce human gait, allowing for controlled exoskeleton\nevaluations. A control strategy based on the State-Dependent Riccati Equation\n(SDRE) is formulated to achieve optimal torque control for accurate gait\nreplication. The bipedal robot dynamics are represented using double pendulum\nmodel, where SDRE-optimized control inputs minimize deviations from human\nmotion trajectories. To align with motor behavior constraints, a parameterized\ncontrol method is introduced to simplify the control process while effectively\nreplicating human gait. The proposed approach initially adopts a ramping\ntrapezoidal velocity model, which is then adapted into a piecewise linear\nvelocity-time representation through motor command overwriting. This\nmodification enables finer control over gait phase transitions while ensuring\ncompatibility with motor dynamics. The corresponding cost function optimizes\nthe control parameters to minimize errors in joint angles, velocities, and\ntorques relative to SDRE control result. By structuring velocity transitions in\naccordance with motor limitations, the method reduce the computational load\nassociated with real-time control. Experimental results verify the feasibility\nof the proposed parameterized control method in reproducing human gait. The\nbipedal robot platform provides a reliable and repeatable testing mechanism for\nknee-type exoskeletons, offering insights into exoskeleton performance under\ncontrolled conditions.", "AI": {"title_translation": "应用SDRE在双足机器人上实现步态控制以测试膝关节型外骨骼", "tldr": "本研究利用SDRE控制的双足机器人模拟人类步态，为膝关节型外骨骼提供安全且可重复的测试平台。", "motivation": "直接对人体进行外骨骼测试存在风险，且难以实现一致的运动复制，因此需要一个更安全、可重复的测试环境。", "method": "本研究采用双足机器人平台复制人类步态，并基于状态依赖Riccati方程（SDRE）制定了最优扭矩控制策略。机器人动力学采用双摆模型表示，SDRE优化控制输入以最小化与人类运动轨迹的偏差。为符合电机行为约束，引入参数化控制方法，通过电机指令覆盖将斜坡梯形速度模型转换为分段线性速度-时间表示，从而优化控制参数以最小化关节角度、速度和扭矩误差，并降低实时控制的计算负荷。", "result": "实验结果验证了所提出的参数化控制方法在复制人类步态方面的可行性。双足机器人平台为膝关节型外骨骼提供了一个可靠且可重复的测试机制，可受控地评估外骨骼性能。", "conclusion": "所提出的基于SDRE和参数化控制的双足机器人平台能够成功复制人类步态，为膝关节型外骨骼的性能评估提供了一个安全、可靠且可重复的测试环境。", "translation": "外骨骼广泛应用于康复和工业领域以辅助人体运动。然而，直接对人体进行测试存在风险，因为可能出现外骨骼故障和运动复制不一致。为了提供一个更安全、可重复的测试环境，本研究采用双足机器人平台复制人类步态，从而实现受控的外骨骼评估。制定了一种基于状态依赖Riccati方程（SDRE）的控制策略，以实现最优扭矩控制，从而精确复制步态。双足机器人动力学采用双摆模型表示，其中SDRE优化的控制输入可最大程度地减少与人类运动轨迹的偏差。为了符合电机行为约束，引入了一种参数化控制方法，以简化控制过程，同时有效地复制人类步态。所提出的方法最初采用斜坡梯形速度模型，然后通过电机指令覆盖将其转换为分段线性速度-时间表示。这种修改能够更精细地控制步态相变，同时确保与电机动力学的兼容性。相应的成本函数优化控制参数，以最小化相对于SDRE控制结果的关节角度、速度和扭矩误差。通过根据电机限制构建速度转换，该方法降低了与实时控制相关的计算负荷。实验结果验证了所提出的参数化控制方法在复制人类步态方面的可行性。双足机器人平台为膝关节型外骨骼提供了一个可靠且可重复的测试机制，可受控地深入了解外骨骼性能。", "summary": "本研究旨在为膝关节型外骨骼提供一个安全的测试平台，通过使用双足机器人模拟人类步态。研究提出了一种基于状态依赖Riccati方程（SDRE）的最优扭矩控制策略，并结合参数化控制方法，以适应电机约束并降低计算负担。实验结果验证了该方法的有效性，表明双足机器人平台能够为外骨骼测试提供可靠且可重复的受控环境。", "keywords": "外骨骼测试, 双足机器人, 步态控制, SDRE, 参数化控制"}}
{"id": "2506.04481", "pdf": "https://arxiv.org/pdf/2506.04481", "abs": "https://arxiv.org/abs/2506.04481", "authors": ["Jiayu Liu", "Zhenya Huang", "Wei Dai", "Cheng Cheng", "Jinze Wu", "Jing Sha", "Song Li", "Qi Liu", "Shijin Wang", "Enhong Chen"], "title": "CogMath: Assessing LLMs' Authentic Mathematical Ability from a Human Cognitive Perspective", "categories": ["cs.AI"], "comment": null, "summary": "Although large language models (LLMs) show promise in solving complex\nmathematical tasks, existing evaluation paradigms rely solely on a coarse\nmeasure of overall answer accuracy, which are insufficient for assessing their\nauthentic capabilities. In this paper, we propose \\textbf{CogMath}, which\ncomprehensively assesses LLMs' mathematical abilities through the lens of human\ncognition. Specifically, inspired by psychological theories, CogMath formalizes\nhuman reasoning process into 3 stages: \\emph{problem comprehension},\n\\emph{problem solving}, and \\emph{solution summarization}. Within these stages,\nwe investigate perspectives such as numerical calculation, knowledge, and\ncounterfactuals, and design a total of 9 fine-grained evaluation dimensions. In\neach dimension, we develop an ``\\emph{Inquiry}-\\emph{Judge}-\\emph{Reference}''\nmulti-agent system to generate inquiries that assess LLMs' mastery from this\ndimension. An LLM is considered to truly master a problem only when excelling\nin all inquiries from the 9 dimensions. By applying CogMath on three\nbenchmarks, we reveal that the mathematical capabilities of 7 mainstream LLMs\nare overestimated by 30\\%-40\\%. Moreover, we locate their strengths and\nweaknesses across specific stages/dimensions, offering in-depth insights to\nfurther enhance their reasoning abilities.", "AI": {"title_translation": "CogMath：从人类认知角度评估大型语言模型的真实数学能力", "tldr": "CogMath提出了一种从人类认知角度评估大型语言模型数学能力的新方法，通过细粒度评估揭示现有LLM的数学能力被高估了30%-40%。", "motivation": "现有的评估范式仅依赖于整体答案准确性的粗略衡量，不足以评估大型语言模型的真实数学能力。", "method": "本文提出了CogMath，该方法受心理学理论启发，将人类推理过程形式化为三个阶段：问题理解、问题解决和解决方案总结。在此基础上，研究了数值计算、知识和反事实等视角，并设计了总共9个细粒度的评估维度。在每个维度中，开发了一个“询问-判断-参考”多智能体系统来生成询问，以评估LLM的掌握程度。只有当LLM在所有9个维度的询问中都表现出色时，才被认为真正掌握了一个问题。", "result": "通过在三个基准测试上应用CogMath，发现7个主流大型语言模型的数学能力被高估了30%-40%。此外，还定位了它们在特定阶段/维度上的优缺点。", "conclusion": "CogMath通过细粒度的、基于人类认知视角的评估，揭示了当前大型语言模型数学能力的真实水平，并为进一步提升其推理能力提供了深入见解。", "translation": "尽管大型语言模型（LLMs）在解决复杂的数学任务方面显示出前景，但现有的评估范式仅依赖于整体答案准确性的粗略衡量，这不足以评估它们的真实能力。在本文中，我们提出了CogMath，它从人类认知的角度全面评估LLMs的数学能力。具体来说，受心理学理论启发，CogMath将人类推理过程形式化为3个阶段：问题理解、问题解决和解决方案总结。在这些阶段中，我们研究了数值计算、知识和反事实等视角，并设计了总共9个细粒度的评估维度。在每个维度中，我们开发了一个“询问-判断-参考”多智能体系统来生成询问，以评估LLM对该维度的掌握程度。只有当LLM在所有9个维度的询问中都表现出色时，才被认为真正掌握了一个问题。通过在三个基准测试上应用CogMath，我们揭示了7个主流LLMs的数学能力被高估了30%-40%。此外，我们还定位了它们在特定阶段/维度上的优缺点，为进一步提升它们的推理能力提供了深入见解。", "summary": "本研究提出了CogMath，一个从人类认知角度全面评估大型语言模型（LLMs）数学能力的新框架。它将人类推理过程分为问题理解、问题解决和解决方案总结三个阶段，并设计了9个细粒度的评估维度，每个维度都采用“询问-判断-参考”多智能体系统进行评估。实验结果表明，主流LLMs的数学能力被现有方法高估了30%-40%，并且CogMath能识别出它们在不同阶段和维度上的具体优劣，为未来的模型改进提供了方向。", "keywords": "CogMath, 大型语言模型, 数学能力, 人类认知, 评估"}}
{"id": "2506.04421", "pdf": "https://arxiv.org/pdf/2506.04421", "abs": "https://arxiv.org/abs/2506.04421", "authors": ["Hermann Kumbong", "Xian Liu", "Tsung-Yi Lin", "Ming-Yu Liu", "Xihui Liu", "Ziwei Liu", "Daniel Y. Fu", "Christopher Ré", "David W. Romero"], "title": "HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted to CVPR 2025. Project Page:\n  https://research.nvidia.com/labs/dir/hmar/", "summary": "Visual Auto-Regressive modeling (VAR) has shown promise in bridging the speed\nand quality gap between autoregressive image models and diffusion models. VAR\nreformulates autoregressive modeling by decomposing an image into successive\nresolution scales. During inference, an image is generated by predicting all\nthe tokens in the next (higher-resolution) scale, conditioned on all tokens in\nall previous (lower-resolution) scales. However, this formulation suffers from\nreduced image quality due to the parallel generation of all tokens in a\nresolution scale; has sequence lengths scaling superlinearly in image\nresolution; and requires retraining to change the sampling schedule.\n  We introduce Hierarchical Masked Auto-Regressive modeling (HMAR), a new image\ngeneration algorithm that alleviates these issues using next-scale prediction\nand masked prediction to generate high-quality images with fast sampling. HMAR\nreformulates next-scale prediction as a Markovian process, wherein the\nprediction of each resolution scale is conditioned only on tokens in its\nimmediate predecessor instead of the tokens in all predecessor resolutions.\nWhen predicting a resolution scale, HMAR uses a controllable multi-step masked\ngeneration procedure to generate a subset of the tokens in each step. On\nImageNet 256x256 and 512x512 benchmarks, HMAR models match or outperform\nparameter-matched VAR, diffusion, and autoregressive baselines. We develop\nefficient IO-aware block-sparse attention kernels that allow HMAR to achieve\nfaster training and inference times over VAR by over 2.5x and 1.75x\nrespectively, as well as over 3x lower inference memory footprint. Finally,\nHMAR yields additional flexibility over VAR; its sampling schedule can be\nchanged without further training, and it can be applied to image editing tasks\nin a zero-shot manner.", "AI": {"title_translation": "HMAR：高效分层掩码自回归图像生成", "tldr": "HMAR是一种新的图像生成算法，通过分层掩码自回归建模，实现了高质量图像的快速生成，并解决了现有VAR模型的问题。", "motivation": "现有的视觉自回归建模（VAR）在并行生成分辨率尺度内的所有tokens时，图像质量会下降；序列长度随图像分辨率超线性增长；并且改变采样调度需要重新训练。", "method": "本文提出了分层掩码自回归建模（HMAR），将下一尺度预测重新表述为马尔可夫过程，其中每个分辨率尺度的预测仅以其紧邻前一个尺度的tokens为条件。在预测分辨率尺度时，HMAR使用可控的多步掩码生成过程，在每一步生成tokens的一个子集。此外，开发了高效的IO感知块稀疏注意力核。", "result": "在ImageNet 256x256和512x512基准测试中，HMAR模型匹配或超越了参数匹配的VAR、扩散和自回归基线。HMAR的训练和推理时间比VAR分别快2.5倍和1.75倍以上，推理内存占用降低3倍以上。其采样调度无需额外训练即可更改，并可零样本应用于图像编辑任务。", "conclusion": "HMAR通过其创新的分层掩码自回归机制，显著提升了图像生成的速度和质量，同时提供了更高的灵活性和更低的资源消耗，超越了现有方法。", "translation": "视觉自回归建模（VAR）在弥合自回归图像模型和扩散模型之间的速度和质量差距方面显示出前景。VAR通过将图像分解为连续的分辨率尺度来重新构建自回归建模。在推理过程中，通过预测下一个（更高分辨率）尺度中的所有tokens，并以所有先前（更低分辨率）尺度中的所有tokens为条件来生成图像。然而，这种公式化方法存在以下问题：由于分辨率尺度内所有tokens的并行生成导致图像质量下降；序列长度随图像分辨率超线性增长；并且改变采样调度需要重新训练。\n我们引入了分层掩码自回归建模（HMAR），这是一种新的图像生成算法，它通过下一尺度预测和掩码预测来缓解这些问题，从而生成高质量图像并实现快速采样。HMAR将下一尺度预测重新表述为马尔可夫过程，其中每个分辨率尺度的预测仅以其紧邻前一个尺度的tokens为条件，而不是所有前置分辨率中的tokens。在预测分辨率尺度时，HMAR使用可控的多步掩码生成过程，在每一步生成tokens的一个子集。在ImageNet 256x256和512x512基准测试中，HMAR模型匹配或超越了参数匹配的VAR、扩散和自回归基线。我们开发了高效的IO感知块稀疏注意力核，使得HMAR的训练和推理时间比VAR分别快2.5倍和1.75倍以上，同时推理内存占用降低3倍以上。最后，HMAR比VAR提供了额外的灵活性；它的采样调度无需进一步训练即可更改，并且可以以零样本方式应用于图像编辑任务。", "summary": "本文提出了分层掩码自回归建模（HMAR），一种新的图像生成算法，旨在解决现有视觉自回归建模（VAR）在图像质量、序列长度和采样调度灵活性方面的局限性。HMAR通过将下一尺度预测重构为马尔可夫过程，并采用多步掩码生成，实现了高质量图像的快速生成。实验结果表明，HMAR在性能上超越了现有基线，并显著提高了训练和推理效率，同时增加了模型在采样调度和零样本图像编辑方面的灵活性。", "keywords": "图像生成, 自回归模型, 分层建模, 掩码预测, 效率"}}
{"id": "2506.04946", "pdf": "https://arxiv.org/pdf/2506.04946", "abs": "https://arxiv.org/abs/2506.04946", "authors": ["A. Döpp", "C. Eberle", "J. Esslinger", "S. Howard", "F. Irshad", "J. Schroeder", "N. Weisse", "S. Karsch"], "title": "Information-Optimal Sensing and Control in High-Intensity Laser Experiments", "categories": ["physics.optics", "cs.IT", "math.IT", "physics.acc-ph", "physics.plasm-ph"], "comment": null, "summary": "High-intensity laser systems present unique measurement and optimization\nchallenges due to their high complexity, low repetition rates, and shot-to-shot\nvariations. We discuss recent developments towards a unified framework based on\ninformation theory and Bayesian inference that addresses these challenges.\nStarting from fundamental constraints on the physical field structure, we\nrecently demonstrated how to capture complete spatio-temporal information about\nindividual petawatt laser pulses. Building on this foundation, we demonstrate\nhow Bayesian frameworks can leverage temporal correlations between consecutive\npulses to improve measurement precision. We then extend these concepts to\nactive sensing strategies that adaptively select measurements to maximize\ninformation gain, exemplified through Bayesian autocorrelation spectroscopy.\nFinally, we show how these information-optimal measurement principles naturally\nextend to Bayesian optimization. This progression represents a paradigm shift\nwhere measurement devices transition from passive data collectors to active\nparticipants in complex experiments.", "AI": {"title_translation": "高强度激光实验中的信息最优传感与控制", "tldr": "针对高强度激光实验的测量挑战，本文提出基于信息论和贝叶斯推断的统一框架，实现信息最优的传感与控制，将测量设备从被动数据收集者转变为主动参与者。", "motivation": "高强度激光系统因其高复杂性、低重复率和逐发变化，在测量和优化方面面临独特的挑战。", "method": "该研究讨论了一种基于信息论和贝叶斯推断的统一框架，以应对高强度激光实验中的测量和优化挑战。具体方法包括捕获单个拍瓦激光脉冲的完整时空信息，利用贝叶斯框架利用连续脉冲间的时间相关性来提高测量精度，以及将这些概念扩展到自适应选择测量以最大化信息增益的主动传感策略（如贝叶斯自相关光谱），最终将信息最优测量原理扩展到贝叶斯优化。", "result": "研究展示了如何捕获单个拍瓦激光脉冲的完整时空信息；证明了贝叶斯框架如何利用连续脉冲间的时间相关性来提高测量精度；示例了主动传感策略（如贝叶斯自相关光谱）如何自适应选择测量以最大化信息增益；并展示了信息最优测量原理如何自然地扩展到贝叶斯优化。", "conclusion": "测量设备从被动数据收集者转变为复杂实验中的主动参与者，代表了一种范式转变。", "translation": "高强度激光系统由于其高复杂性、低重复率和逐发变化，带来了独特的测量和优化挑战。我们讨论了最近在基于信息论和贝叶斯推断的统一框架方面的发展，该框架旨在解决这些挑战。从物理场结构的基本约束出发，我们最近展示了如何捕获单个拍瓦激光脉冲的完整时空信息。在此基础上，我们展示了贝叶斯框架如何利用连续脉冲之间的时间相关性来提高测量精度。然后，我们将这些概念扩展到自适应选择测量以最大化信息增益的主动传感策略，以贝叶斯自相关光谱为例。最后，我们展示了这些信息最优测量原理如何自然地扩展到贝叶斯优化。这一进展代表了一种范式转变，其中测量设备从被动数据收集者转变为复杂实验中的主动参与者。", "summary": "本文针对高强度激光实验中复杂的测量和优化挑战，提出并讨论了一个基于信息论和贝叶斯推断的统一框架。该框架能够捕获激光脉冲的完整时空信息，并通过利用脉冲间的时间相关性提高测量精度。此外，它将主动传感策略（如贝叶斯自相关光谱）与贝叶斯优化相结合，旨在最大化信息增益。这一进展标志着测量设备从被动数据收集者向复杂实验主动参与者的转变。", "keywords": "高强度激光, 信息理论, 贝叶斯推断, 主动传感, 贝叶斯优化"}}
{"id": "2506.04289", "pdf": "https://arxiv.org/pdf/2506.04289", "abs": "https://arxiv.org/abs/2506.04289", "authors": ["Jesse Geerts", "Stephanie Chan", "Claudia Clopath", "Kimberly Stachenfeld"], "title": "Relational reasoning and inductive bias in transformers trained on a transitive inference task", "categories": ["cs.LG", "q-bio.NC"], "comment": "13 pages, 6 figures", "summary": "Transformer-based models have demonstrated remarkable reasoning abilities,\nbut the mechanisms underlying relational reasoning in different learning\nregimes remain poorly understood. In this work, we investigate how transformers\nperform a classic relational reasoning task from the Psychology literature,\n\\textit{transitive inference}, which requires inference about indirectly\nrelated items by integrating information across observed adjacent item pairs\n(e.g., if A>B and B>C, then A>C). We compare transitive inference behavior\nacross two distinct learning regimes: in-weights learning (IWL), where models\nstore information in network parameters, and in-context learning (ICL), where\nmodels flexibly utilize information presented within the input sequence. Our\nfindings reveal that IWL naturally induces a generalization bias towards\ntransitive inference, despite being trained only on adjacent items, whereas ICL\nmodels trained solely on adjacent items do not generalize transitively.\nMechanistic analysis shows that ICL models develop induction circuits that\nimplement a simple match-and-copy strategy that performs well at relating\nadjacent pairs, but does not encoding hierarchical relationships among\nindirectly related items. Interestingly, when pre-trained on in-context linear\nregression tasks, transformers successfully exhibit in-context generalizable\ntransitive inference. Moreover, like IWL, they display both \\textit{symbolic\ndistance} and \\textit{terminal item effects} characteristic of human and animal\nperformance, without forming induction circuits. These results suggest that\npre-training on tasks with underlying structure promotes the development of\nrepresentations that can scaffold in-context relational reasoning.", "AI": {"title_translation": "Transformer 在传递推理任务中的关系推理和归纳偏置", "tldr": "本文研究了 Transformer 模型在传递推理任务中的关系推理能力和归纳偏置。结果表明，权重内学习（IWL）自然诱导传递推理的泛化偏置，而上下文内学习（ICL）模型若仅在相邻项上训练则无法泛化，除非经过特定预训练。", "motivation": "Transformer 模型展现出卓越的推理能力，但其在不同学习机制下进行关系推理的机制尚不清楚。", "method": "研究人员通过经典的传递推理任务来调查 Transformer 的关系推理行为，比较了两种学习机制：权重内学习（IWL）和上下文内学习（ICL）。此外，还探讨了在上下文线性回归任务上进行预训练对 ICL 模型的影响。", "result": "1. 权重内学习（IWL）即使仅在相邻项上训练，也能自然地诱导对传递推理的泛化偏置。\n2. 上下文内学习（ICL）模型如果仅在相邻项上训练，则无法进行传递泛化。\n3. ICL 模型发展出一种“匹配-复制”策略的归纳电路，适用于相邻对，但不能编码间接相关项的层级关系。\n4. 当在上下文线性回归任务上进行预训练时，Transformer 成功地表现出上下文内可泛化的传递推理。\n5. 经过预训练的 ICL 模型（类似于 IWL）表现出人类和动物特有的“符号距离效应”和“终端项效应”，且不形成归纳电路。", "conclusion": "在具有潜在结构的任务上进行预训练，可以促进表征的发展，从而为上下文关系推理提供支持。", "translation": "基于 Transformer 的模型已经展示出卓越的推理能力，但在不同学习机制下，关系推理的潜在机制仍知之甚少。在这项工作中，我们研究了 Transformer 如何执行心理学文献中经典的“传递推理”关系推理任务，该任务需要通过整合观察到的相邻项对的信息（例如，如果 A>B 且 B>C，那么 A>C）来推断间接相关项。我们比较了两种不同学习机制下的传递推理行为：权重内学习（IWL），其中模型将信息存储在网络参数中；以及上下文内学习（ICL），其中模型灵活地利用输入序列中呈现的信息。我们的研究结果表明，IWL 自然地诱导了对传递推理的泛化偏置，尽管它仅在相邻项上进行训练；而仅在相邻项上训练的 ICL 模型则不能进行传递泛化。机制分析表明，ICL 模型发展出实现简单“匹配-复制”策略的归纳电路，该策略在关联相邻对方面表现良好，但不能编码间接相关项之间的层级关系。有趣的是，当在上下文线性回归任务上进行预训练时，Transformer 成功地表现出上下文内可泛化的传递推理。此外，与 IWL 类似，它们表现出人类和动物性能特有的“符号距离效应”和“终端项效应”，而无需形成归纳电路。这些结果表明，在具有潜在结构的任务上进行预训练，可以促进表征的发展，从而为上下文关系推理提供支持。", "summary": "本研究探讨了 Transformer 模型在传递推理任务中的关系推理能力和归纳偏置。通过比较权重内学习（IWL）和上下文内学习（ICL），发现 IWL 自然产生传递推理的泛化偏置，而未经预训练的 ICL 模型则不能。然而，在上下文线性回归任务上进行预训练后，ICL 模型也能展现出可泛化的传递推理，并表现出与人类和动物相似的特征，这表明预训练在促进上下文关系推理方面的重要性。", "keywords": "Transformer, 关系推理, 传递推理, 权重内学习, 上下文内学习"}}
{"id": "2506.05138", "pdf": "https://arxiv.org/pdf/2506.05138", "abs": "https://arxiv.org/abs/2506.05138", "authors": ["Pavle Vasiljevic", "Milica Matic", "Miroslav Popovic"], "title": "Federated Isolation Forest for Efficient Anomaly Detection on Edge IoT Systems", "categories": ["cs.LG", "cs.DC"], "comment": "6 pages, 4 algorithms, 5 figures, 2 tables", "summary": "Recently, federated learning frameworks such as Python TestBed for Federated\nLearning Algorithms and MicroPython TestBed for Federated Learning Algorithms\nhave emerged to tackle user privacy concerns and efficiency in embedded\nsystems. Even more recently, an efficient federated anomaly detection\nalgorithm, FLiForest, based on Isolation Forests has been developed, offering a\nlow-resource, unsupervised method well-suited for edge deployment and\ncontinuous learning. In this paper, we present an application of Isolation\nForest-based temperature anomaly detection, developed using the previously\nmentioned federated learning frameworks, aimed at small edge devices and IoT\nsystems running MicroPython. The system has been experimentally evaluated,\nachieving over 96% accuracy in distinguishing normal from abnormal readings and\nabove 78% precision in detecting anomalies across all tested configurations,\nwhile maintaining a memory usage below 160 KB during model training. These\nresults highlight its suitability for resource-constrained environments and\nedge systems, while upholding federated learning principles of data privacy and\ncollaborative learning.", "AI": {"title_translation": "边缘物联网系统中高效异常检测的联邦隔离森林", "tldr": "本文提出了一种基于联邦隔离森林的温度异常检测系统，适用于资源受限的边缘IoT设备，并在实验中表现出高精度和低内存消耗。", "motivation": "为了解决嵌入式系统中的用户隐私和效率问题，并提供一种低资源、无监督的异常检测方法，适用于边缘部署和持续学习。", "method": "利用Python TestBed和MicroPython TestBed联邦学习框架，开发了一种基于隔离森林的温度异常检测系统，应用于小型边缘设备和物联网系统。", "result": "在区分正常和异常读数方面，准确率超过96%；在所有测试配置中，异常检测的精确率超过78%；模型训练期间内存使用量低于160 KB。", "conclusion": "该系统适用于资源受限的环境和边缘系统，同时保持了联邦学习的数据隐私和协作学习原则。", "translation": "最近，联邦学习框架，例如Python TestBed for Federated Learning Algorithms和MicroPython TestBed for Federated Learning Algorithms，已经出现，旨在解决嵌入式系统中的用户隐私问题和效率问题。更近期，一种高效的联邦异常检测算法FLiForest，基于隔离森林被开发出来，它提供了一种低资源、无监督的方法，非常适合边缘部署和持续学习。在本文中，我们提出了一种基于隔离森林的温度异常检测应用，该应用是使用前面提到的联邦学习框架开发的，旨在用于运行MicroPython的小型边缘设备和物联网系统。该系统已经过实验评估，在区分正常和异常读数方面实现了超过96%的准确率，在所有测试配置中检测异常的精确率超过78%，同时在模型训练期间内存使用量低于160 KB。这些结果突显了其在资源受限环境和边缘系统中的适用性，同时维护了联邦学习的数据隐私和协作学习原则。", "summary": "本研究提出并评估了一种基于联邦隔离森林的温度异常检测系统，该系统利用现有联邦学习框架，专为边缘IoT设备设计。实验结果显示，该系统在低资源消耗下实现了高准确率和精确率，验证了其在资源受限环境中进行隐私保护异常检测的适用性。", "keywords": "联邦学习, 隔离森林, 异常检测, 边缘计算, IoT"}}
{"id": "2506.05126", "pdf": "https://arxiv.org/pdf/2506.05126", "abs": "https://arxiv.org/abs/2506.05126", "authors": ["Lorenzo Rossi", "Michael Aerni", "Jie Zhang", "Florian Tramèr"], "title": "Membership Inference Attacks on Sequence Models", "categories": ["cs.CR", "cs.LG"], "comment": "Accepted to the 8th Deep Learning Security and Privacy Workshop\n  (DLSP) workshop (best paper award)", "summary": "Sequence models, such as Large Language Models (LLMs) and autoregressive\nimage generators, have a tendency to memorize and inadvertently leak sensitive\ninformation. While this tendency has critical legal implications, existing\ntools are insufficient to audit the resulting risks. We hypothesize that those\ntools' shortcomings are due to mismatched assumptions. Thus, we argue that\neffectively measuring privacy leakage in sequence models requires leveraging\nthe correlations inherent in sequential generation. To illustrate this, we\nadapt a state-of-the-art membership inference attack to explicitly model\nwithin-sequence correlations, thereby demonstrating how a strong existing\nattack can be naturally extended to suit the structure of sequence models.\nThrough a case study, we show that our adaptations consistently improve the\neffectiveness of memorization audits without introducing additional\ncomputational costs. Our work hence serves as an important stepping stone\ntoward reliable memorization audits for large sequence models.", "AI": {"title_translation": "对序列模型的成员推断攻击", "tldr": "本文提出了一种新的成员推断攻击方法，通过利用序列模型中固有的序列相关性，提高了对大型序列模型记忆化审计的有效性，且不增加计算成本。", "motivation": "序列模型（如大型语言模型和自回归图像生成器）倾向于记忆并无意中泄露敏感信息，这具有重要的法律影响。然而，现有工具不足以审计由此产生的风险，这可能是由于假设不匹配造成的。", "method": "作者认为，有效测量序列模型中的隐私泄露需要利用序列生成中固有的相关性。为了证明这一点，他们调整了一种最先进的成员推断攻击，以明确建模序列内的相关性。", "result": "通过一个案例研究，作者表明他们的调整持续提高了记忆化审计的有效性，而没有引入额外的计算成本。", "conclusion": "这项工作是朝着大型序列模型可靠记忆化审计迈出的重要一步。", "translation": "序列模型，例如大型语言模型（LLMs）和自回归图像生成器，倾向于记忆并无意中泄露敏感信息。虽然这种倾向具有关键的法律影响，但现有工具不足以审计由此产生的风险。我们假设这些工具的缺点是由于假设不匹配造成的。因此，我们认为，有效测量序列模型中的隐私泄露需要利用序列生成中固有的相关性。为了说明这一点，我们调整了一种最先进的成员推断攻击，以明确建模序列内的相关性，从而展示了如何自然地扩展一个强大的现有攻击以适应序列模型的结构。通过一个案例研究，我们表明我们的调整持续提高了记忆化审计的有效性，而没有引入额外的计算成本。因此，我们的工作是朝着大型序列模型可靠记忆化审计迈出的重要一步。", "summary": "本研究旨在解决序列模型（如LLMs）存在的敏感信息泄露问题，指出现有审计工具的不足源于假设不匹配。作者提出通过利用序列生成中的相关性来测量隐私泄露，并为此调整了一种成员推断攻击方法，使其能够明确建模序列内相关性。实验结果表明，该方法在不增加计算成本的情况下，显著提高了记忆化审计的有效性，为大型序列模型的可靠审计奠定了基础。", "keywords": "成员推断攻击, 序列模型, 隐私泄露, 记忆化审计, 相关性"}}
{"id": "2506.05265", "pdf": "https://arxiv.org/pdf/2506.05265", "abs": "https://arxiv.org/abs/2506.05265", "authors": ["Mohammed Almutairi"], "title": "Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams", "categories": ["cs.HC", "cs.AI", "cs.MA"], "comment": "5 pages, UMAP 25, June 16_19, 2025, New York City, NY, USA", "summary": "Effective teamwork is essential across diverse domains. During the team\nformation stage, a key challenge is forming teams that effectively balance user\npreferences with task objectives to enhance overall team satisfaction. In the\nteam performing stage, maintaining cohesion and engagement is critical for\nsustaining high team performance. However, existing computational tools and\nalgorithms for team optimization often rely on static data inputs, narrow\nalgorithmic objectives, or solutions tailored for specific contexts, failing to\naccount for the dynamic interplay of team members personalities, evolving\ngoals, and changing individual preferences. Therefore, teams may encounter\nmember dissatisfaction, as purely algorithmic assignments can reduce members\ncommitment to team goals or experience suboptimal engagement due to the absence\nof timely, personalized guidance to help members adjust their behaviors and\ninteractions as team dynamics evolve. Ultimately, these challenges can lead to\nreduced overall team performance. My Ph.D. dissertation aims to develop\nAI-augmented team optimization frameworks and practical systems that enhance\nteam satisfaction, engagement, and performance. First, I propose a team\nformation framework that leverages a multi-armed bandit algorithm to\niteratively refine team composition based on user preferences, ensuring\nalignment between individual needs and collective team goals to enhance team\nsatisfaction. Second, I introduce tAIfa (Team AI Feedback Assistant), an\nAI-powered system that utilizes large language models (LLMs) to deliver\nimmediate, personalized feedback to both teams and individual members,\nenhancing cohesion and engagement. Finally, I present PuppeteerLLM, an\nLLM-based simulation framework that simulates multi-agent teams to model\ncomplex team dynamics within realistic environments, incorporating task-driven\ncollaboration and long-term coordination.", "AI": {"title_translation": "AI时代下的团队协作：用于组建、模拟和优化人类团队的AI增强框架", "tldr": "本博士论文旨在开发AI增强的团队优化框架和系统，以提高团队满意度、参与度和绩效，通过多臂老虎机算法进行团队组建、LLM提供个性化反馈，并利用LLM模拟团队动态。", "motivation": "现有团队优化计算工具未能考虑团队成员个性、目标和偏好的动态变化，导致团队成员不满意、承诺度降低、参与度不佳以及整体团队绩效下降。", "method": "1. 提出一个团队组建框架，利用多臂老虎机算法根据用户偏好迭代优化团队构成。\n2. 引入tAIfa（Team AI Feedback Assistant），一个基于LLM的AI系统，为团队和个人提供即时个性化反馈。\n3. 提出PuppeteerLLM，一个基于LLM的模拟框架，用于模拟多智能体团队，建模复杂的团队动态、任务驱动协作和长期协调。", "result": "摘要中未提及。", "conclusion": "摘要中未提及。", "translation": "有效的团队合作在不同领域都至关重要。在团队组建阶段，一个关键的挑战是组建能够有效平衡用户偏好和任务目标以提升整体团队满意度的团队。在团队执行阶段，保持凝聚力和参与度对于维持高团队绩效至关重要。然而，现有的团队优化计算工具和算法通常依赖静态数据输入、狭窄的算法目标或针对特定情境的解决方案，未能考虑到团队成员个性、不断演变的目标和不断变化的个人偏好之间的动态相互作用。因此，团队可能会遇到成员不满意，因为纯粹的算法分配会降低成员对团队目标的承诺，或者由于缺乏及时、个性化的指导来帮助成员随着团队动态演变调整其行为和互动而导致参与度不佳。最终，这些挑战可能导致整体团队绩效下降。我的博士论文旨在开发AI增强的团队优化框架和实用系统，以提高团队满意度、参与度和绩效。首先，我提出了一个团队组建框架，该框架利用多臂老虎机算法根据用户偏好迭代地优化团队构成，确保个人需求与集体团队目标保持一致，从而提高团队满意度。其次，我介绍了tAIfa（Team AI Feedback Assistant），一个由AI驱动的系统，利用大型语言模型（LLM）向团队和个人成员提供即时、个性化的反馈，从而增强凝聚力和参与度。最后，我介绍了PuppeteerLLM，一个基于LLM的模拟框架，用于模拟多智能体团队，在现实环境中建模复杂的团队动态，包括任务驱动的协作和长期协调。", "summary": "本博士论文致力于解决现有团队优化工具在处理动态团队因素方面的不足。通过开发AI增强的团队优化框架和实用系统，旨在提升团队满意度、参与度和绩效。论文具体提出了三个核心贡献：一个基于多臂老虎机算法的团队组建框架，一个利用大型语言模型提供个性化反馈的tAIfa系统，以及一个基于LLM模拟复杂团队动态的PuppeteerLLM框架。", "keywords": "AI增强框架, 团队优化, 人类团队, 多臂老虎机算法, 大型语言模型, 团队模拟"}}
{"id": "2506.04684", "pdf": "https://arxiv.org/pdf/2506.04684", "abs": "https://arxiv.org/abs/2506.04684", "authors": ["Nitish Kumar", "Rajalakshmi Pachamuthu"], "title": "Real-Time LPV-Based Non-Linear Model Predictive Control for Robust Trajectory Tracking in Autonomous Vehicles", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper presents the development and implementation of a Model Predictive\nControl (MPC) framework for trajectory tracking in autonomous vehicles under\ndiverse driving conditions. The proposed approach incorporates a modular\narchitecture that integrates state estimation, vehicle dynamics modeling, and\noptimization to ensure real-time performance. The state-space equations are\nformulated in a Linear Parameter Varying (LPV) form, and a curvature-based\ntuning method is introduced to optimize weight matrices for varying\ntrajectories. The MPC framework is implemented using the Robot Operating System\n(ROS) for parallel execution of state estimation and control optimization,\nensuring scalability and minimal latency. Extensive simulations and real-time\nexperiments were conducted on multiple predefined trajectories, demonstrating\nhigh accuracy with minimal cross-track and orientation errors, even under\naggressive maneuvers and high-speed conditions. The results highlight the\nrobustness and adaptability of the proposed system, achieving seamless\nalignment between simulated and real-world performance. This work lays the\nfoundation for dynamic weight tuning and integration into cooperative\nautonomous navigation systems, paving the way for enhanced safety and\nefficiency in autonomous driving applications.", "AI": {"title_translation": "基于实时LPV的非线性模型预测控制在自动驾驶车辆鲁棒轨迹跟踪中的应用", "tldr": "本文提出了一种基于LPV的实时非线性模型预测控制（MPC）框架，用于自动驾驶车辆的鲁棒轨迹跟踪，并在仿真和实际实验中验证了其高精度和鲁棒性。", "motivation": "在不同驾驶条件下，自动驾驶车辆需要实现鲁棒的轨迹跟踪。", "method": "该方法提出了一种模块化架构，集成了状态估计、车辆动力学建模和优化，以确保实时性能。状态空间方程采用线性参数变化（LPV）形式，并引入了一种基于曲率的调优方法来优化不同轨迹的权重矩阵。MPC框架使用机器人操作系统（ROS）实现，用于并行执行状态估计和控制优化。", "result": "在多个预定义轨迹上进行了广泛的仿真和实时实验，即使在激进机动和高速条件下，也表现出高精度，具有最小的横向和方向误差。结果突出了所提出系统的鲁棒性和适应性，实现了仿真和实际性能之间的无缝对齐。", "conclusion": "该工作为动态权重调优和集成到协同自动导航系统奠定了基础，为自动驾驶应用中增强安全性和效率铺平了道路。", "translation": "本文提出了一种用于自动驾驶车辆在不同驾驶条件下进行轨迹跟踪的模型预测控制（MPC）框架的开发和实现。所提出的方法包含一个模块化架构，该架构集成了状态估计、车辆动力学建模和优化，以确保实时性能。状态空间方程以线性参数变化（LPV）形式表示，并引入了一种基于曲率的调优方法来优化不同轨迹的权重矩阵。MPC框架使用机器人操作系统（ROS）实现，用于并行执行状态估计和控制优化，确保可伸缩性和最小延迟。在多个预定义轨迹上进行了广泛的仿真和实时实验，即使在激进机动和高速条件下，也表现出高精度，具有最小的横向和方向误差。结果突出了所提出系统的鲁棒性和适应性，实现了仿真和实际性能之间的无缝对齐。这项工作为动态权重调优和集成到协同自动导航系统奠定了基础，为自动驾驶应用中增强安全性和效率铺平了道路。", "summary": "本文开发并实现了一个用于自动驾驶车辆轨迹跟踪的模型预测控制（MPC）框架。该框架采用模块化架构，并利用线性参数变化（LPV）形式的状态空间方程和基于曲率的权重矩阵调优方法。通过ROS实现，确保了实时性能和可扩展性。仿真和实际实验证明了该系统在不同驾驶条件下，包括激进机动和高速情况下的高精度和鲁棒性，为未来的自动驾驶系统奠定了基础。", "keywords": "模型预测控制, 轨迹跟踪, 自动驾驶车辆, 线性参数变化, 实时控制"}}
{"id": "2506.04500", "pdf": "https://arxiv.org/pdf/2506.04500", "abs": "https://arxiv.org/abs/2506.04500", "authors": ["Aladin Djuhera", "Amin Seffo", "Masataro Asai", "Holger Boche"], "title": "\"Don't Do That!\": Guiding Embodied Systems through Large Language Model-based Constraint Generation", "categories": ["cs.AI", "cs.RO"], "comment": "Preprint; under review", "summary": "Recent advancements in large language models (LLMs) have spurred interest in\nrobotic navigation that incorporates complex spatial, mathematical, and\nconditional constraints from natural language into the planning problem. Such\nconstraints can be informal yet highly complex, making it challenging to\ntranslate into a formal description that can be passed on to a planning\nalgorithm. In this paper, we propose STPR, a constraint generation framework\nthat uses LLMs to translate constraints (expressed as instructions on ``what\nnot to do'') into executable Python functions. STPR leverages the LLM's strong\ncoding capabilities to shift the problem description from language into\nstructured and transparent code, thus circumventing complex reasoning and\navoiding potential hallucinations. We show that these LLM-generated functions\naccurately describe even complex mathematical constraints, and apply them to\npoint cloud representations with traditional search algorithms. Experiments in\na simulated Gazebo environment show that STPR ensures full compliance across\nseveral constraints and scenarios, while having short runtimes. We also verify\nthat STPR can be used with smaller, code-specific LLMs, making it applicable to\na wide range of compact models at low inference cost.", "AI": {"title_translation": "“别那样做！”：通过基于大型语言模型的约束生成引导具身系统", "tldr": "本文提出了STPR框架，利用大型语言模型将自然语言中的“不要做”指令转换为可执行的Python函数，以解决机器人导航中复杂约束难以形式化的问题，并在模拟环境中验证了其有效性和高效性。", "motivation": "大型语言模型（LLMs）的进步激发了将自然语言中复杂的空间、数学和条件约束融入机器人导航规划问题的兴趣。然而，这些约束通常是非正式但高度复杂的，难以转换为规划算法可理解的形式描述。", "method": "本文提出了STPR框架，该框架利用大型语言模型（LLMs）将（表达为“不应该做什么”指令的）约束转换为可执行的Python函数。STPR利用LLM强大的编码能力，将问题描述从自然语言转换为结构化且透明的代码，从而规避了复杂的推理并避免了潜在的幻觉。", "result": "LLM生成的函数能够准确描述复杂的数学约束，并将其应用于点云表示和传统搜索算法。在模拟Gazebo环境中的实验表明，STPR在多个约束和场景下确保了完全的合规性，并且运行时间很短。研究还验证了STPR可以与更小、特定于代码的LLM一起使用，使其适用于各种紧凑模型，且推理成本较低。", "conclusion": "STPR是一个有效的框架，可以通过基于大型语言模型的约束生成来引导具身系统，确保合规性，具有较短的运行时间，并且适用于更小的LLM。", "translation": "大型语言模型（LLMs）的最新进展激发了人们对机器人导航的兴趣，这种导航将自然语言中复杂的空间、数学和条件约束纳入规划问题。此类约束可能非正式但高度复杂，这使得将其转换为可传递给规划算法的形式化描述具有挑战性。在本文中，我们提出了STPR，一个约束生成框架，它使用LLM将约束（表示为“不应该做什么”的指令）转换为可执行的Python函数。STPR利用LLM强大的编码能力，将问题描述从语言转移到结构化和透明的代码中，从而规避了复杂的推理并避免了潜在的幻觉。我们展示了这些LLM生成的函数即使是复杂的数学约束也能准确描述，并将它们应用于点云表示和传统搜索算法。在模拟Gazebo环境中的实验表明，STPR在多个约束和场景下确保了完全的合规性，同时运行时间很短。我们还验证了STPR可以与更小、特定于代码的LLM一起使用，使其适用于各种紧凑模型，且推理成本较低。", "summary": "本文介绍了STPR，一个利用大型语言模型（LLMs）生成约束的框架，旨在解决将复杂的自然语言约束转化为机器人导航中可执行形式的挑战。STPR将“不要做”的指令转换为Python函数，利用LLM的编码能力简化问题描述并避免幻觉。实验证明，STPR能够准确处理复杂约束，在模拟环境中实现高合规性和低运行时间，并且兼容小型LLM，降低了推理成本。", "keywords": "大型语言模型, 机器人导航, 约束生成, 具身系统, Python函数"}}
{"id": "2506.04444", "pdf": "https://arxiv.org/pdf/2506.04444", "abs": "https://arxiv.org/abs/2506.04444", "authors": ["Zhaoyang Lv", "Maurizio Monge", "Ka Chen", "Yufeng Zhu", "Michael Goesele", "Jakob Engel", "Zhao Dong", "Richard Newcombe"], "title": "Photoreal Scene Reconstruction from an Egocentric Device", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.HC", "cs.MM"], "comment": "Paper accepted to SIGGRAPH Conference Paper 2025", "summary": "In this paper, we investigate the challenges associated with using egocentric\ndevices to photorealistic reconstruct the scene in high dynamic range. Existing\nmethodologies typically assume using frame-rate 6DoF pose estimated from the\ndevice's visual-inertial odometry system, which may neglect crucial details\nnecessary for pixel-accurate reconstruction. This study presents two\nsignificant findings. Firstly, in contrast to mainstream work treating RGB\ncamera as global shutter frame-rate camera, we emphasize the importance of\nemploying visual-inertial bundle adjustment (VIBA) to calibrate the precise\ntimestamps and movement of the rolling shutter RGB sensing camera in a high\nfrequency trajectory format, which ensures an accurate calibration of the\nphysical properties of the rolling-shutter camera. Secondly, we incorporate a\nphysical image formation model based into Gaussian Splatting, which effectively\naddresses the sensor characteristics, including the rolling-shutter effect of\nRGB cameras and the dynamic ranges measured by sensors. Our proposed\nformulation is applicable to the widely-used variants of Gaussian Splats\nrepresentation. We conduct a comprehensive evaluation of our pipeline using the\nopen-source Project Aria device under diverse indoor and outdoor lighting\nconditions, and further validate it on a Meta Quest3 device. Across all\nexperiments, we observe a consistent visual enhancement of +1 dB in PSNR by\nincorporating VIBA, with an additional +1 dB achieved through our proposed\nimage formation model. Our complete implementation, evaluation datasets, and\nrecording profile are available at\nhttp://www.projectaria.com/photoreal-reconstruction/", "AI": {"title_translation": "基于第一人称设备的真实感场景重建", "tldr": "本研究提出了一种改进第一人称设备真实感场景重建的方法，通过精确校准滚动快门相机和整合物理图像形成模型，显著提升了重建质量（PSNR提高了2dB）。", "motivation": "现有方法在使用第一人称设备进行高动态范围的真实感场景重建时，通常假设使用帧率6DoF姿态，这可能忽略了像素级精确重建所需的关键细节。", "method": "1. 强调使用视觉-惯性束调整（VIBA）来校准滚动快门RGB传感相机的精确时间戳和高频轨迹运动，以确保精确校准其物理特性。2. 将基于物理的图像形成模型整合到高斯泼溅（Gaussian Splatting）中，有效解决了传感器特性，包括RGB相机的滚动快门效应和传感器测量的动态范围。", "result": "在所有实验中，通过整合VIBA，PSNR持续视觉增强了+1 dB；通过提出的图像形成模型，PSNR额外增加了+1 dB。该方法在开源Project Aria设备和Meta Quest3设备上进行了全面评估。", "conclusion": "通过精确校准滚动快门相机和整合物理图像形成模型，本研究显著提升了第一人称设备进行真实感场景重建的质量，实现了2dB的PSNR提升。", "translation": "本文研究了使用第一人称设备进行高动态范围真实感场景重建所面临的挑战。现有方法通常假设使用设备视觉-惯性里程计系统估计的帧率6自由度姿态，这可能忽略了像素级精确重建所需的关键细节。本研究提出了两项重要发现。首先，与主流工作中将RGB相机视为全局快门帧率相机不同，我们强调使用视觉-惯性束调整（VIBA）来校准滚动快门RGB传感相机在高频轨迹格式下的精确时间戳和运动的重要性，这确保了滚动快门相机物理特性的精确校准。其次，我们将基于物理的图像形成模型整合到高斯泼溅（Gaussian Splatting）中，这有效解决了传感器特性，包括RGB相机的滚动快门效应和传感器测量的动态范围。我们提出的公式适用于高斯泼溅表示的广泛使用的变体。我们使用开源Project Aria设备在各种室内和室外照明条件下对我们的管道进行了全面评估，并进一步在Meta Quest3设备上进行了验证。在所有实验中，我们观察到通过整合VIBA，PSNR持续视觉增强了+1 dB，通过我们提出的图像形成模型额外实现了+1 dB的提升。我们的完整实现、评估数据集和录制配置文件可在http://www.projectaria.com/photoreal-reconstruction/获取。", "summary": "本论文研究了使用第一人称设备进行高动态范围真实感场景重建的挑战。针对现有方法可能忽略像素级精确重建细节的问题，本研究提出了两项关键改进：一是利用视觉-惯性束调整（VIBA）精确校准滚动快门RGB相机的时间戳和运动；二是将物理图像形成模型整合到高斯泼溅中，以处理传感器特性。实验结果表明，通过这些改进，重建质量在PSNR上获得了总计2dB的提升，并在Project Aria和Meta Quest3设备上得到了验证。", "keywords": "真实感场景重建, 第一人称设备, 滚动快门, 视觉-惯性束调整, 高斯泼溅"}}
{"id": "2506.05174", "pdf": "https://arxiv.org/pdf/2506.05174", "abs": "https://arxiv.org/abs/2506.05174", "authors": ["Yifan Zhang", "Joe Kileel"], "title": "Norming Sets for Tensor and Polynomial Sketching", "categories": ["math.NA", "cs.IT", "cs.NA", "math.AG", "math.IT"], "comment": "16 pages", "summary": "This paper develops the sketching (i.e., randomized dimension reduction)\ntheory for real algebraic varieties and images of polynomial maps, including,\ne.g., the set of low rank tensors and tensor networks. Through the lens of\nnorming sets, we provide a framework for controlling the sketching dimension\nfor \\textit{any} sketch operator used to embed said sets, including\nsub-Gaussian, fast Johnson-Lindenstrauss, and tensor structured sketch\noperators. Leveraging norming set theory, we propose a new sketching method\ncalled the median sketch. It embeds such a set $V$ using only\n$\\widetilde{\\mathcal{O}}(\\dim V)$ tensor structured or sparse linear\nmeasurements.", "AI": {"title_translation": "张量和多项式速写中的范数集", "tldr": "本文提出了一个基于范数集的框架，用于控制各种速写算子的速写维度，并提出了一种新的中位数速写方法，用于高效嵌入实代数簇和多项式映射图像。", "motivation": "发展用于实代数簇和多项式映射图像（包括低秩张量和张量网络）的速写（随机降维）理论。", "method": "通过范数集理论，提供了一个控制速写维度的框架，适用于任何用于嵌入这些集合的速写算子（包括亚高斯、快速Johnson-Lindenstrauss和张量结构速写算子）。此外，提出了一种新的速写方法——中位数速写。", "result": "中位数速写方法仅使用 $\\widetilde{\\mathcal{O}}(\\dim V)$ 张量结构或稀疏线性测量即可嵌入集合 V。", "conclusion": "本文成功发展了实代数簇和多项式映射图像的速写理论，并通过范数集提供了一个通用框架来控制速写维度，并提出了一种高效的新型中位数速写方法。", "translation": "本文发展了实代数簇和多项式映射图像（例如低秩张量和张量网络）的速写（即随机降维）理论。通过范数集的视角，我们提供了一个框架，用于控制用于嵌入上述集合的“任何”速写算子（包括亚高斯、快速Johnson-Lindenstrauss和张量结构速写算子）的速写维度。利用范数集理论，我们提出了一种新的速写方法，称为中位数速写。它仅使用 $\\widetilde{\\mathcal{O}}(\\dim V)$ 的张量结构或稀疏线性测量即可嵌入此类集合 V。", "summary": "本文发展了实代数簇和多项式映射图像（如低秩张量和张量网络）的速写理论。论文通过范数集视角，提出了一个通用框架来控制任意速写算子（包括亚高斯、快速Johnson-Lindenstrauss和张量结构算子）的速写维度。此外，本文还提出了一种名为中位数速写的新方法，该方法仅需 $\\widetilde{\\mathcal{O}}(\\dim V)$ 的张量结构或稀疏线性测量即可有效嵌入集合 V。", "keywords": "速写理论, 范数集, 张量, 随机降维, 中位数速写"}}
{"id": "2506.04291", "pdf": "https://arxiv.org/pdf/2506.04291", "abs": "https://arxiv.org/abs/2506.04291", "authors": ["Wenhan Xu", "Jiashuo Jiang", "Lei Deng", "Danny Hin-Kwok Tsang"], "title": "A Lyapunov Drift-Plus-Penalty Method Tailored for Reinforcement Learning with Queue Stability", "categories": ["cs.LG"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "With the proliferation of Internet of Things (IoT) devices, the demand for\naddressing complex optimization challenges has intensified. The Lyapunov\nDrift-Plus-Penalty algorithm is a widely adopted approach for ensuring queue\nstability, and some research has preliminarily explored its integration with\nreinforcement learning (RL). In this paper, we investigate the adaptation of\nthe Lyapunov Drift-Plus-Penalty algorithm for RL applications, deriving an\neffective method for combining Lyapunov Drift-Plus-Penalty with RL under a set\nof common and reasonable conditions through rigorous theoretical analysis.\nUnlike existing approaches that directly merge the two frameworks, our proposed\nalgorithm, termed Lyapunov drift-plus-penalty method tailored for reinforcement\nlearning with queue stability (LDPTRLQ) algorithm, offers theoretical\nsuperiority by effectively balancing the greedy optimization of Lyapunov\nDrift-Plus-Penalty with the long-term perspective of RL. Simulation results for\nmultiple problems demonstrate that LDPTRLQ outperforms the baseline methods\nusing the Lyapunov drift-plus-penalty method and RL, corroborating the validity\nof our theoretical derivations. The results also demonstrate that our proposed\nalgorithm outperforms other benchmarks in terms of compatibility and stability.", "AI": {"title_translation": "一种为强化学习与队列稳定性量身定制的Lyapunov漂移加惩罚方法", "tldr": "本文提出了一种名为LDPTRLQ的新型算法，将Lyapunov漂移加惩罚算法与强化学习相结合，以在保证队列稳定性的同时优化长期性能，并在仿真中表现出优于基线方法的性能。", "motivation": "随着物联网设备的普及，对复杂优化挑战的需求日益增加。Lyapunov漂移加惩罚算法被广泛用于确保队列稳定性，现有研究已初步探索其与强化学习的结合，但缺乏理论上更优的结合方法。", "method": "本文通过严格的理论分析，推导了一种在通用合理条件下将Lyapunov漂移加惩罚算法与强化学习相结合的有效方法，并提出了LDPTRLQ算法。该算法旨在有效平衡Lyapunov漂移加惩罚的贪婪优化与强化学习的长期视角。", "result": "多问题仿真结果表明，LDPTRLQ算法在性能上优于使用Lyapunov漂移加惩罚方法和强化学习的基线方法，验证了理论推导的有效性。结果还表明，该算法在兼容性和稳定性方面优于其他基准方法。", "conclusion": "本文成功地将Lyapunov漂移加惩罚算法与强化学习相结合，提出了LDPTRLQ算法，在理论上和仿真中都显示出其在平衡短期优化与长期性能，以及在兼容性和稳定性方面的优越性。", "translation": "随着物联网（IoT）设备的普及，解决复杂优化挑战的需求日益增强。Lyapunov漂移加惩罚算法是一种广泛采用的确保队列稳定性的方法，一些研究已初步探索其与强化学习（RL）的结合。在本文中，我们研究了Lyapunov漂移加惩罚算法在RL应用中的适应性，通过严格的理论分析，在满足一组通用且合理条件的情况下，推导出了将Lyapunov漂移加惩罚与RL相结合的有效方法。与现有直接合并两个框架的方法不同，我们提出的算法，称为Lyapunov漂移加惩罚强化学习与队列稳定性方法（LDPTRLQ）算法，通过有效平衡Lyapunov漂移加惩罚的贪婪优化与RL的长期视角，提供了理论上的优越性。多个问题的仿真结果表明，LDPTRLQ在性能上优于使用Lyapunov漂移加惩罚方法和RL的基线方法，证实了我们理论推导的有效性。结果还表明，我们提出的算法在兼容性和稳定性方面优于其他基准方法。", "summary": "本文针对物联网设备日益增长的复杂优化需求，提出了一种名为Lyapunov漂移加惩罚强化学习与队列稳定性方法（LDPTRLQ）的新型算法。该算法通过严格的理论分析，将Lyapunov漂移加惩罚算法与强化学习有效结合，旨在平衡两者的优势，实现队列稳定性和长期性能优化。仿真结果表明，LDPTRLQ在多个问题上均优于现有基线方法，并在兼容性和稳定性方面表现出色。", "keywords": "Lyapunov漂移加惩罚, 强化学习, 队列稳定性, LDPTRLQ, 优化"}}
{"id": "2504.17264", "pdf": "https://arxiv.org/pdf/2504.17264", "abs": "https://arxiv.org/abs/2504.17264", "authors": ["Zhaolu Kang", "Hongtian Cai", "Xiangyang Ji", "Jinzhe Li", "Nanfei Gu"], "title": "JurisCTC: Enhancing Legal Judgment Prediction via Cross-Domain Transfer and Contrastive Learning", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "Accepted in International Joint Conference on Neural Networks (IJCNN)\n  2025", "summary": "In recent years, Unsupervised Domain Adaptation (UDA) has gained significant\nattention in the field of Natural Language Processing (NLP) owing to its\nability to enhance model generalization across diverse domains. However, its\napplication for knowledge transfer between distinct legal domains remains\nlargely unexplored. To address the challenges posed by lengthy and complex\nlegal texts and the limited availability of large-scale annotated datasets, we\npropose JurisCTC, a novel model designed to improve the accuracy of Legal\nJudgment Prediction (LJP) tasks. Unlike existing approaches, JurisCTC\nfacilitates effective knowledge transfer across various legal domains and\nemploys contrastive learning to distinguish samples from different domains.\nSpecifically, for the LJP task, we enable knowledge transfer between civil and\ncriminal law domains. Compared to other models and specific large language\nmodels (LLMs), JurisCTC demonstrates notable advancements, achieving peak\naccuracies of 76.59% and 78.83%, respectively.", "AI": {"title_translation": "JurisCTC: 通过跨领域迁移和对比学习增强法律判决预测", "tldr": "JurisCTC模型利用跨领域迁移和对比学习，提高了法律判决预测的准确性，尤其是在民事和刑事法律领域之间进行知识迁移。", "motivation": "现有方法在不同法律领域间的知识迁移应用较少，且面临法律文本复杂、标注数据集有限的挑战，需要提高法律判决预测的准确性。", "method": "本文提出了一种名为JurisCTC的新模型，该模型通过促进跨不同法律领域的有效知识迁移，并采用对比学习来区分来自不同领域的样本。具体地，实现了民事和刑事法律领域之间的知识迁移。", "result": "JurisCTC模型在法律判决预测任务中取得了显著进展，峰值准确率分别达到76.59%和78.83%，优于其他现有模型和特定大型语言模型。", "conclusion": "JurisCTC模型通过跨领域迁移和对比学习，有效解决了法律领域知识迁移的挑战，显著提升了法律判决预测的准确性。", "translation": "近年来，无监督领域自适应（UDA）因其能够增强模型在不同领域间的泛化能力，在自然语言处理（NLP）领域获得了广泛关注。然而，其在不同法律领域间进行知识迁移的应用仍未被充分探索。为了解决法律文本冗长复杂以及大规模标注数据集有限所带来的挑战，我们提出了JurisCTC，一个旨在提高法律判决预测（LJP）任务准确性的新型模型。与现有方法不同，JurisCTC促进了跨各种法律领域的有效知识迁移，并采用对比学习来区分来自不同领域的样本。具体而言，对于LJP任务，我们实现了民事和刑事法律领域之间的知识迁移。与其他模型和特定大型语言模型（LLMs）相比，JurisCTC展现出显著的进步，分别达到了76.59%和78.83%的峰值准确率。", "summary": "本文提出了JurisCTC模型，旨在通过跨领域迁移和对比学习提高法律判决预测（LJP）任务的准确性。该模型克服了现有方法在不同法律领域间知识迁移的不足，并解决了法律文本复杂和数据集有限的问题。JurisCTC在民事和刑事法律领域之间实现了有效的知识迁移，并在LJP任务中取得了76.59%和78.83%的峰值准确率，优于其他模型和大型语言模型。", "keywords": "法律判决预测, 跨领域迁移, 对比学习, 无监督领域自适应, 自然语言处理"}}
{"id": "2506.05271", "pdf": "https://arxiv.org/pdf/2506.05271", "abs": "https://arxiv.org/abs/2506.05271", "authors": ["Daniel Berg Thomsen", "Adrien Taylor", "Aymeric Dieuleveut"], "title": "Tight analyses of first-order methods with error feedback", "categories": ["cs.LG", "cs.DC", "math.OC"], "comment": null, "summary": "Communication between agents often constitutes a major computational\nbottleneck in distributed learning. One of the most common mitigation\nstrategies is to compress the information exchanged, thereby reducing\ncommunication overhead. To counteract the degradation in convergence associated\nwith compressed communication, error feedback schemes -- most notably\n$\\mathrm{EF}$ and $\\mathrm{EF}^{21}$ -- were introduced. In this work, we\nprovide a tight analysis of both of these methods. Specifically, we find the\nLyapunov function that yields the best possible convergence rate for each\nmethod -- with matching lower bounds. This principled approach yields sharp\nperformance guarantees and enables a rigorous, apples-to-apples comparison\nbetween $\\mathrm{EF}$, $\\mathrm{EF}^{21}$, and compressed gradient descent. Our\nanalysis is carried out in a simplified yet representative setting, which\nallows for clean theoretical insights and fair comparison of the underlying\nmechanisms.", "AI": {"title_translation": "带有误差反馈的一阶方法的紧密分析", "tldr": "本文对带有误差反馈的分布式学习一阶方法的收敛性进行了紧密分析，并提供了匹配的下界。", "motivation": "分布式学习中代理之间的通信是主要的计算瓶颈。压缩通信是缓解这一问题的方法，但会导致收敛性下降。误差反馈方案（如EF和EF21）被引入以抵消这种收敛性下降。", "method": "本文对EF和EF21这两种误差反馈方法进行了紧密分析。具体而言，研究人员找到了为每种方法提供最佳可能收敛速度的Lyapunov函数，并提供了匹配的下界。分析在一个简化但具有代表性的设置中进行。", "result": "研究人员找到了能为EF和EF21提供最佳可能收敛速度的Lyapunov函数，并提供了匹配的下界。这种有原则的方法产生了尖锐的性能保证，并使得EF、EF21和压缩梯度下降之间能够进行严格、公平的比较。", "conclusion": "通过提供紧密的分析和匹配的下界，本研究为带有误差反馈的一阶方法提供了尖锐的性能保证，并使得不同误差反馈方案与压缩梯度下降之间能够进行严格的比较。", "translation": "代理之间的通信通常是分布式学习中的主要计算瓶颈。最常见的缓解策略之一是压缩交换的信息，从而减少通信开销。为了抵消与压缩通信相关的收敛性下降，引入了误差反馈方案——最显著的是EF和EF21。在这项工作中，我们对这两种方法进行了紧密分析。具体来说，我们找到了为每种方法提供最佳可能收敛速度的Lyapunov函数——并提供了匹配的下界。这种有原则的方法产生了尖锐的性能保证，并使得EF、EF21和压缩梯度下降之间能够进行严格、公平的比较。我们的分析在一个简化但具有代表性的设置中进行，这使得能够获得清晰的理论见解和对底层机制的公平比较。", "summary": "本文对分布式学习中用于抵消压缩通信引起的收敛性下降的误差反馈方案（EF和EF21）进行了一项严格的分析。通过找到产生最佳收敛速度的Lyapunov函数并提供匹配的下界，作者为这些方法提供了紧密的性能保证，并实现了与压缩梯度下降的严格比较。", "keywords": "误差反馈, 分布式学习, 收敛性分析, 一阶方法, 通信压缩"}}
{"id": "2506.05129", "pdf": "https://arxiv.org/pdf/2506.05129", "abs": "https://arxiv.org/abs/2506.05129", "authors": ["Andrin Bertschi", "Shweta Shinde"], "title": "OpenCCA: An Open Framework to Enable Arm CCA Research", "categories": ["cs.CR"], "comment": null, "summary": "Confidential computing has gained traction across major architectures with\nIntel TDX, AMD SEV-SNP, and Arm CCA. Unlike TDX and SEV-SNP, a key challenge in\nresearching Arm CCA is the absence of hardware support, forcing researchers to\ndevelop ad-hoc performance prototypes on non-CCA Arm boards. This approach\nleads to duplicated efforts, inconsistent performance comparisons, and high\nbarriers to entry. To address this, we present OpenCCA, an open research\nplatform that enables the execution of CCA-bound code on commodity Armv8.2\nhardware. By systematically adapting the software stack -- including\nbootloader, firmware, hypervisor, and kernel -- OpenCCA emulates CCA operations\nfor performance evaluation while preserving functional correctness. We\ndemonstrate its effectiveness with typical life-cycle measurements and\ncase-studies inspired by prior CCA-based papers on a easily available Armv8.2\nRockchip board that costs $250.", "AI": {"title_translation": "OpenCCA：一个支持 Arm CCA 研究的开放框架", "tldr": "OpenCCA 是一个开放平台，通过模拟 Arm CCA 操作，使研究人员能够在现有的 Armv8.2 硬件上进行 Arm CCA 研究，解决了缺乏硬件支持的问题。", "motivation": "目前 Arm CCA 研究面临缺乏硬件支持的挑战，导致研究人员依赖临时原型，造成重复工作、性能比较不一致以及高门槛。", "method": "OpenCCA 是一个开放研究平台，通过系统性地调整软件堆栈（包括引导加载程序、固件、虚拟机监控程序和内核），在商用 Armv8.2 硬件上模拟 CCA 操作，以进行性能评估并保持功能正确性。", "result": "该平台已通过典型的生命周期测量和受先前 CCA 相关论文启发而进行的案例研究证明了其有效性，这些测试是在一个经济实惠的 Armv8.2 Rockchip 板上进行的。", "conclusion": "OpenCCA 成功地为 Arm CCA 研究提供了一个开放平台，解决了缺乏硬件支持的挑战，使得研究人员能够在商用硬件上进行 CCA 相关的代码执行和性能评估。", "translation": "机密计算在各大架构中都受到了关注，包括英特尔 TDX、AMD SEV-SNP 和 Arm CCA。与 TDX 和 SEV-SNP 不同，研究 Arm CCA 的一个主要挑战是缺乏硬件支持，这迫使研究人员在非 CCA 的 Arm 主板上开发临时性能原型。这种方法导致了重复工作、性能比较不一致以及较高的入门门槛。为了解决这个问题，我们提出了 OpenCCA，一个开放的研究平台，它可以在商用 Armv8.2 硬件上执行 CCA 绑定代码。通过系统性地调整软件堆栈——包括引导加载程序、固件、虚拟机监控程序和内核——OpenCCA 模拟 CCA 操作以进行性能评估，同时保持功能正确性。我们使用典型的生命周期测量和受先前基于 CCA 的论文启发的案例研究，在易于获取的、成本为 250 美元的 Armv8.2 Rockchip 主板上展示了其有效性。", "summary": "OpenCCA 旨在解决 Arm CCA 研究中硬件支持缺失的问题。它提供了一个开放的框架，通过修改软件堆栈，在标准 Armv8.2 硬件上模拟 Arm CCA 操作，从而实现对 CCA 绑定代码的执行和性能评估。该平台已通过实验证明其有效性，降低了 Arm CCA 研究的门槛。", "keywords": "OpenCCA, Arm CCA, 机密计算, 研究平台, 硬件模拟"}}
{"id": "2506.04752", "pdf": "https://arxiv.org/pdf/2506.04752", "abs": "https://arxiv.org/abs/2506.04752", "authors": ["Tianxin Hu", "Xinhang Xu", "Thien-Minh Nguyen", "Fen Liu", "Shenghai Yuan", "Lihua Xie"], "title": "Tire Wear Aware Trajectory Tracking Control for Multi-axle Swerve-drive Autonomous Mobile Robots", "categories": ["cs.RO", "math.OC"], "comment": "Accepted in Journal of Automation and Intelligence", "summary": "Multi-axle Swerve-drive Autonomous Mobile Robots (MS-AGVs) equipped with\nindependently steerable wheels are commonly used for high-payload\ntransportation. In this work, we present a novel model predictive control (MPC)\nmethod for MS-AGV trajectory tracking that takes tire wear minimization\nconsideration in the objective function. To speed up the problem-solving\nprocess, we propose a hierarchical controller design and simplify the dynamic\nmodel by integrating the \\textit{magic formula tire model} and\n\\textit{simplified tire wear model}. In the experiment, the proposed method can\nbe solved by simulated annealing in real-time on a normal personal computer and\nby incorporating tire wear into the objective function, tire wear is reduced by\n19.19\\% while maintaining the tracking accuracy in curve-tracking experiments.\nIn the more challenging scene: the desired trajectory is offset by 60 degrees\nfrom the vehicle's heading, the reduction in tire wear increased to 65.20\\%\ncompared to the kinematic model without considering the tire wear optimization.", "AI": {"title_translation": "多轴转向驱动自主移动机器人轮胎磨损感知轨迹跟踪控制", "tldr": "本文提出了一种新型模型预测控制（MPC）方法，用于多轴转向驱动自主移动机器人（MS-AGV）的轨迹跟踪，该方法在目标函数中考虑了轮胎磨损最小化，并在实验中显著降低了轮胎磨损，同时保持了跟踪精度。", "motivation": "多轴转向驱动自主移动机器人（MS-AGV）常用于高载荷运输，但轮胎磨损是其运行中需要考虑的问题。本研究旨在通过优化轨迹跟踪控制来最小化轮胎磨损。", "method": "本文提出了一种新颖的模型预测控制（MPC）方法，用于MS-AGV的轨迹跟踪，并在目标函数中加入了轮胎磨损最小化。为了加速求解过程，采用了分层控制器设计，并通过整合“魔术公式轮胎模型”和“简化轮胎磨损模型”来简化动态模型。该方法通过模拟退火算法在普通个人电脑上实现实时求解。", "result": "在曲线跟踪实验中，所提出的方法在保持跟踪精度的同时，将轮胎磨损减少了19.19%。在更具挑战性的场景（期望轨迹与车辆航向偏离60度）中，与未考虑轮胎磨损优化的运动学模型相比，轮胎磨损减少量增加到65.20%。", "conclusion": "本文提出的考虑轮胎磨损最小化的模型预测控制方法，能够有效降低多轴转向驱动自主移动机器人在轨迹跟踪过程中的轮胎磨损，特别是在复杂场景下效果显著，且能保持良好的跟踪精度。", "translation": "多轴转向驱动自主移动机器人（MS-AGV）配备独立转向轮，常用于高载荷运输。在这项工作中，我们提出了一种新颖的模型预测控制（MPC）方法，用于MS-AGV轨迹跟踪，该方法在目标函数中考虑了轮胎磨损最小化。为了加快问题解决过程，我们提出了分层控制器设计，并通过整合“魔术公式轮胎模型”和“简化轮胎磨损模型”来简化动态模型。在实验中，所提出的方法可以通过模拟退火算法在普通个人电脑上实时求解，并且通过将轮胎磨损纳入目标函数，在曲线跟踪实验中，轮胎磨损减少了19.19%，同时保持了跟踪精度。在更具挑战性的场景中：期望轨迹与车辆航向偏离60度，与未考虑轮胎磨损优化的运动学模型相比，轮胎磨损减少量增加到65.20%。", "summary": "本文介绍了一种新颖的模型预测控制（MPC）方法，专为多轴转向驱动自主移动机器人（MS-AGV）的轨迹跟踪设计，其核心在于将轮胎磨损最小化纳入目标函数。为提高计算效率，研究者采用了分层控制器设计，并整合了魔术公式轮胎模型和简化轮胎磨损模型来简化动态模型。实验结果表明，该方法能够实时运行，并在曲线跟踪任务中将轮胎磨损减少19.19%，而在更具挑战性的场景下，轮胎磨损减少量更是高达65.20%，同时保持了高跟踪精度。", "keywords": "多轴转向驱动机器人, 轨迹跟踪, 轮胎磨损, 模型预测控制, 模拟退火"}}
{"id": "2506.04512", "pdf": "https://arxiv.org/pdf/2506.04512", "abs": "https://arxiv.org/abs/2506.04512", "authors": ["Bohui Zhang", "Yuan He", "Lydia Pintscher", "Albert Meroño Peñuela", "Elena Simperl"], "title": "Schema Generation for Large Knowledge Graphs Using Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Schemas are vital for ensuring data quality in the Semantic Web and natural\nlanguage processing. Traditionally, their creation demands substantial\ninvolvement from knowledge engineers and domain experts. Leveraging the\nimpressive capabilities of large language models (LLMs) in related tasks like\nontology engineering, we explore automatic schema generation using LLMs. To\nbridge the resource gap, we introduce two datasets: YAGO Schema and Wikidata\nEntitySchema, along with evaluation metrics. The LLM-based pipelines\neffectively utilize local and global information from knowledge graphs (KGs) to\ngenerate validating schemas in Shape Expressions (ShEx). Experiments\ndemonstrate LLMs' strong potential in producing high-quality ShEx schemas,\npaving the way for scalable, automated schema generation for large KGs.\nFurthermore, our benchmark introduces a new challenge for structured\ngeneration, pushing the limits of LLMs on syntactically rich formalisms.", "AI": {"title_translation": "使用大型语言模型为大型知识图谱生成模式", "tldr": "本文探讨了使用大型语言模型自动生成知识图谱模式的方法，并通过实验证明了其潜力。", "motivation": "传统上，模式创建需要知识工程师和领域专家的大量参与，效率低下。", "method": "利用大型语言模型（LLMs）的能力，引入了YAGO Schema和Wikidata EntitySchema两个数据集以及评估指标。LLM管道有效利用知识图谱的局部和全局信息，生成Shape Expressions (ShEx) 格式的验证模式。", "result": "实验证明LLMs在生成高质量ShEx模式方面具有强大潜力，为大型知识图谱的可扩展、自动化模式生成铺平了道路。此外，基准测试为结构化生成引入了新挑战。", "conclusion": "大型语言模型在自动化、可扩展的知识图谱模式生成方面具有巨大潜力，并推动了LLMs在处理语法丰富形式化方面的极限。", "translation": "模式对于确保语义网和自然语言处理中的数据质量至关重要。传统上，它们的创建需要知识工程师和领域专家的实质性参与。利用大型语言模型（LLMs）在本体工程等相关任务中令人印象深刻的能力，我们探索了使用LLMs自动生成模式。为了弥补资源差距，我们引入了两个数据集：YAGO Schema和Wikidata EntitySchema，以及评估指标。基于LLM的管道有效地利用知识图谱（KGs）的局部和全局信息来生成Shape Expressions (ShEx) 中的验证模式。实验证明了LLMs在生成高质量ShEx模式方面的强大潜力，为大型知识图谱的可扩展、自动化模式生成铺平了道路。此外，我们的基准测试为结构化生成引入了新的挑战，推动了LLMs在语法丰富形式化方面的极限。", "summary": "本研究旨在利用大型语言模型（LLMs）实现知识图谱的自动化模式生成，以解决传统模式创建中对人工大量依赖的问题。为此，论文引入了YAGO Schema和Wikidata EntitySchema两个新数据集，并开发了基于LLMs的管道，该管道能够利用知识图谱的局部和全局信息生成高质量的ShEx模式。实验结果验证了LLMs在这一任务上的强大潜力，并为大规模知识图谱的自动化模式生成奠定了基础。", "keywords": "大型语言模型, 知识图谱, 模式生成, Shape Expressions, 自动化"}}
{"id": "2506.04496", "pdf": "https://arxiv.org/pdf/2506.04496", "abs": "https://arxiv.org/abs/2506.04496", "authors": ["Patrik Mesec", "Alan Jović"], "title": "Towards Large-Scale Pose-Invariant Face Recognition Using Face Defrontalization", "categories": ["cs.CV"], "comment": "13 pages, 5 figures, 4 tables", "summary": "Face recognition under extreme head poses is a challenging task. Ideally, a\nface recognition system should perform well across different head poses, which\nis known as pose-invariant face recognition. To achieve pose invariance,\ncurrent approaches rely on sophisticated methods, such as face frontalization\nand various facial feature extraction model architectures. However, these\nmethods are somewhat impractical in real-life settings and are typically\nevaluated on small scientific datasets, such as Multi-PIE. In this work, we\npropose the inverse method of face frontalization, called face\ndefrontalization, to augment the training dataset of facial feature extraction\nmodel. The method does not introduce any time overhead during the inference\nstep. The method is composed of: 1) training an adapted face defrontalization\nFFWM model on a frontal-profile pairs dataset, which has been preprocessed\nusing our proposed face alignment method; 2) training a ResNet-50 facial\nfeature extraction model based on ArcFace loss on a raw and randomly\ndefrontalized large-scale dataset, where defrontalization was performed with\nour previously trained face defrontalization model. Our method was compared\nwith the existing approaches on four open-access datasets: LFW, AgeDB, CFP, and\nMulti-PIE. Defrontalization shows improved results compared to models without\ndefrontalization, while the proposed adjustments show clear superiority over\nthe state-of-the-art face frontalization FFWM method on three larger\nopen-access datasets, but not on the small Multi-PIE dataset for extreme poses\n(75 and 90 degrees). The results suggest that at least some of the current\nmethods may be overfitted to small datasets.", "AI": {"title_translation": "使用人脸去正面化实现大规模姿态不变人脸识别", "tldr": "提出人脸去正面化方法，通过数据增强提升人脸识别在极端姿态下的表现，且推理无额外开销。", "motivation": "极端头部姿态下的人脸识别是一项具有挑战性的任务；现有方法（如人脸正面化）在实际应用中不实用且通常在小型数据集上评估。", "method": "本文提出人脸去正面化（face defrontalization）方法，作为人脸正面化的逆向操作，用于增强面部特征提取模型的训练数据集，且推理时无额外时间开销。具体包括：1）在经过人脸对齐预处理的正面-侧面配对数据集上训练适应性人脸去正面化FFWM模型；2）使用训练好的去正面化模型，在原始和随机去正面化的大规模数据集上，基于ArcFace损失训练ResNet-50面部特征提取模型。", "result": "去正面化模型比没有去正面化的模型表现更好。在三个较大的开放数据集上，提出的方法比最先进的人脸正面化FFWM方法表现出明显优越性。但在小型Multi-PIE数据集的极端姿态（75和90度）下，其表现不如人脸正面化FFWM方法。结果表明，当前的一些方法可能对小型数据集过拟合。", "conclusion": "人脸去正面化是一种有效的数据增强策略，可以提高大规模姿态不变人脸识别的性能，并且可能揭示了现有方法在小型数据集上存在过拟合的问题。", "translation": "极端头部姿态下的人脸识别是一项具有挑战性的任务。理想情况下，人脸识别系统应该在不同头部姿态下表现良好，这被称为姿态不变人脸识别。为了实现姿态不变性，当前的方法依赖于复杂的方法，例如人脸正面化和各种面部特征提取模型架构。然而，这些方法在实际应用中有些不切实际，并且通常在Multi-PIE等小型科学数据集上进行评估。在这项工作中，我们提出了人脸正面化的逆向方法，称为人脸去正面化，以增强面部特征提取模型的训练数据集。该方法在推理步骤中不会引入任何时间开销。该方法包括：1）在正面-侧面配对数据集上训练一个适应性人脸去正面化FFWM模型，该数据集已使用我们提出的人脸对齐方法进行预处理；2）在原始和随机去正面化的大规模数据集上，基于ArcFace损失训练一个ResNet-50面部特征提取模型，其中去正面化是使用我们之前训练的人脸去正面化模型进行的。我们的方法与现有方法在四个开放访问数据集：LFW、AgeDB、CFP和Multi-PIE上进行了比较。与没有去正面化的模型相比，去正面化显示出改进的结果，而提出的调整方法在三个较大的开放访问数据集上显示出对最先进的人脸正面化FFWM方法的明显优越性，但在小型Multi-PIE数据集的极端姿态（75和90度）下则不然。结果表明，当前的一些方法可能对小型数据集过拟合。", "summary": "本文提出一种名为“人脸去正面化”的逆向方法，用于增强面部特征提取模型的训练数据集，以解决极端头部姿态下人脸识别的挑战。该方法在推理阶段不引入额外时间开销，并包含训练去正面化模型和基于去正面化数据训练ResNet-50特征提取模型两部分。实验结果表明，与不使用去正面化的模型相比，该方法表现有所提升，并且在多数大型开放数据集上优于现有的人脸正面化方法，但对小型数据集的极端姿态表现不如。这暗示现有方法可能存在对小型数据集过拟合的问题。", "keywords": "人脸识别, 姿态不变性, 人脸去正面化, 数据增强, 深度学习"}}
{"id": "2506.05335", "pdf": "https://arxiv.org/pdf/2506.05335", "abs": "https://arxiv.org/abs/2506.05335", "authors": ["M. E. Shirokov"], "title": "Upper bound for the Holevo quantity arising from the fundamental entropic inequality", "categories": ["quant-ph", "cs.IT", "math-ph", "math.IT", "math.MP"], "comment": "7 pages, any comments and reference are welcome", "summary": "We show how the fundamental entropic inequality proved recently in\n[arXiv:2408.15306] can be used to obtain a quite accurate upper bound on the\nHolevo quantity of a discrete ensemble of quantum states expressed via the\nprobabilities and the metric characteristics of this ensembles.", "AI": {"title_translation": "量子霍勒沃信息量的上界源于基本熵不等式", "tldr": "利用基本熵不等式为量子态系综的Holevo信息量提供了一个精确的上界。", "motivation": "利用最近证明的基本熵不等式，为离散量子态系综的Holevo信息量提供一个精确的上界。", "method": "本文利用一个最近证明的基本熵不等式来获得离散量子态系综的Holevo信息量的一个上界，该上界通过系综的概率和度量特性来表达。", "result": "获得了离散量子态系综的Holevo信息量的一个相当精确的上界，该上界通过系综的概率和度量特性来表达。", "conclusion": "本文展示了基本熵不等式可以有效地用于为离散量子态系综的Holevo信息量推导出精确的上界。", "translation": "我们展示了最近在[arXiv:2408.15306]中证明的基本熵不等式如何能够用于获得离散量子态系综的Holevo信息量的一个相当精确的上界，该上界通过这些系综的概率和度量特性来表达。", "summary": "本文展示了如何利用最近证明的基本熵不等式，为离散量子态系综的Holevo信息量提供一个相当精确的上界。该上界通过系综的概率和度量特性来表达。", "keywords": "Holevo信息量, 熵不等式, 量子态, 上界, 离散系综"}}
{"id": "2506.04293", "pdf": "https://arxiv.org/pdf/2506.04293", "abs": "https://arxiv.org/abs/2506.04293", "authors": ["Fengze Liu", "Haoyu Wang", "Joonhyuk Cho", "Dan Roth", "Andrew W. Lo"], "title": "AUTOCT: Automating Interpretable Clinical Trial Prediction with LLM Agents", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Clinical trials are critical for advancing medical treatments but remain\nprohibitively expensive and time-consuming. Accurate prediction of clinical\ntrial outcomes can significantly reduce research and development costs and\naccelerate drug discovery. While recent deep learning models have shown promise\nby leveraging unstructured data, their black-box nature, lack of\ninterpretability, and vulnerability to label leakage limit their practical use\nin high-stakes biomedical contexts. In this work, we propose AutoCT, a novel\nframework that combines the reasoning capabilities of large language models\nwith the explainability of classical machine learning. AutoCT autonomously\ngenerates, evaluates, and refines tabular features based on public information\nwithout human input. Our method uses Monte Carlo Tree Search to iteratively\noptimize predictive performance. Experimental results show that AutoCT performs\non par with or better than SOTA methods on clinical trial prediction tasks\nwithin only a limited number of self-refinement iterations, establishing a new\nparadigm for scalable, interpretable, and cost-efficient clinical trial\nprediction.", "AI": {"title_translation": "AUTOCT: 利用大型语言模型智能体自动化可解释的临床试验预测", "tldr": "AutoCT是一个结合大型语言模型和经典机器学习的框架，用于自动化和可解释地预测临床试验结果，其性能与SOTA方法相当或更好。", "motivation": "临床试验成本高昂且耗时，准确预测结果可显著降低研发成本并加速药物发现。现有深度学习模型虽有前景，但其黑箱性质、缺乏可解释性以及标签泄露问题限制了其在生物医学领域中的实际应用。", "method": "AutoCT框架结合了大型语言模型的推理能力和经典机器学习的可解释性。它能根据公开信息自主生成、评估和优化表格特征，无需人工输入。该方法使用蒙特卡洛树搜索迭代优化预测性能。", "result": "实验结果表明，AutoCT在有限的自优化迭代次数内，在临床试验预测任务上表现与SOTA方法相当或更优。", "conclusion": "AutoCT为可扩展、可解释且经济高效的临床试验预测建立了一种新范式。", "translation": "临床试验对于推进医疗治疗至关重要，但其成本高昂且耗时。准确预测临床试验结果可以显著降低研发成本并加速药物发现。尽管最近的深度学习模型通过利用非结构化数据展现出前景，但其黑箱性质、缺乏可解释性以及易受标签泄露影响的特点限制了它们在高风险生物医学环境中的实际应用。在这项工作中，我们提出了AutoCT，一个结合大型语言模型推理能力和经典机器学习可解释性的新型框架。AutoCT能基于公开信息自主生成、评估和优化表格特征，无需人工输入。我们的方法使用蒙特卡洛树搜索迭代优化预测性能。实验结果表明，AutoCT在有限的自优化迭代次数内，在临床试验预测任务上表现与SOTA方法相当或更优，为可扩展、可解释且经济高效的临床试验预测建立了一种新范式。", "summary": "本论文提出了AutoCT，一个结合大型语言模型推理能力和经典机器学习可解释性的新型框架，旨在自动化可解释的临床试验预测。AutoCT能自主生成、评估和优化表格特征，并利用蒙特卡洛树搜索迭代提升预测性能。实验证明，AutoCT在预测任务上的表现与现有最先进方法相当或更优，为临床试验预测提供了一种可扩展、可解释且成本效益高的新方法。", "keywords": "临床试验预测, 大型语言模型, 可解释性, 自动化, 蒙特卡洛树搜索"}}
{"id": "2506.05242", "pdf": "https://arxiv.org/pdf/2506.05242", "abs": "https://arxiv.org/abs/2506.05242", "authors": ["Zhiqiang Wang", "Haohua Du", "Junyang Wang", "Haifeng Sun", "Kaiwen Guo", "Haikuo Yu", "Chao Liu", "Xiang-Yang Li"], "title": "SECNEURON: Reliable and Flexible Abuse Control in Local LLMs via Hybrid Neuron Encryption", "categories": ["cs.CR"], "comment": null, "summary": "Large language models (LLMs) with diverse capabilities are increasingly being\ndeployed in local environments, presenting significant security and\ncontrollability challenges. These locally deployed LLMs operate outside the\ndirect control of developers, rendering them more susceptible to abuse.\nExisting mitigation techniques mainly designed for cloud-based LLM services are\nfrequently circumvented or ineffective in deployer-controlled environments. We\npropose SECNEURON, the first framework that seamlessly embeds classic access\ncontrol within the intrinsic capabilities of LLMs, achieving reliable,\ncost-effective, flexible, and certified abuse control for local deployed LLMs.\nSECNEURON employs neuron-level encryption and selective decryption to\ndynamically control the task-specific capabilities of LLMs, limiting\nunauthorized task abuse without compromising others. We first design a\ntask-specific neuron extraction mechanism to decouple logically related neurons\nand construct a layered policy tree for handling coupled neurons. We then\nintroduce a flexible and efficient hybrid encryption framework for millions of\nneurons in LLMs. Finally, we developed a distribution-based decrypted neuron\ndetection mechanism on ciphertext to ensure the effectiveness of partially\ndecrypted LLMs. We proved that SECNEURON satisfies IND-CPA Security and\nCollusion Resistance Security under the Task Controllability Principle.\nExperiments on various task settings show that SECNEURON limits unauthorized\ntask accuracy to below 25% while keeping authorized accuracy loss with 2%.\nUsing an unauthorized Code task example, the accuracy of abuse-related\nmalicious code generation was reduced from 59% to 15%. SECNEURON also mitigates\nunauthorized data leakage, reducing PII extraction rates to below 5% and\nmembership inference to random guesses.", "AI": {"title_translation": "SECNEURON：通过混合神经元加密实现本地大型语言模型中可靠灵活的滥用控制", "tldr": "SECNEURON通过神经元级别的加密和选择性解密，为本地部署的大型语言模型提供可靠、灵活且经济高效的滥用控制，同时保持授权任务的性能。", "motivation": "本地部署的大型语言模型面临严重的安全和可控性挑战，因为它们不受开发者的直接控制，易受滥用。现有的主要为云端LLM服务设计的缓解技术在部署者控制的环境中常常被规避或无效。", "method": "SECNEURON框架将经典访问控制嵌入到LLM的内在能力中。它采用神经元级加密和选择性解密来动态控制LLM的任务特定能力。具体方法包括：设计任务特定神经元提取机制，解耦逻辑相关神经元并构建分层策略树；引入灵活高效的混合加密框架，用于LLM中的数百万神经元；开发基于分布的密文解密神经元检测机制，以确保部分解密LLM的有效性。该方法被证明满足任务可控性原则下的IND-CPA安全性和抗串谋安全性。", "result": "在各种任务设置中，SECNEURON将未经授权的任务准确性限制在25%以下，同时授权准确性损失仅为2%。在未经授权的代码任务示例中，与滥用相关的恶意代码生成准确率从59%降低到15%。SECNEURON还减轻未经授权的数据泄露，将PII提取率降低到5%以下，并将成员推断降低到随机猜测水平。", "conclusion": "SECNEURON是第一个为本地部署LLM提供可靠、经济高效、灵活且经过认证的滥用控制框架，通过混合神经元加密有效限制未经授权的任务，同时保持授权任务的性能并增强数据隐私。", "translation": "大型语言模型（LLMs）凭借其多样化的能力正越来越多地部署在本地环境中，这带来了重大的安全和可控性挑战。这些本地部署的LLMs在开发者的直接控制之外运行，使其更容易受到滥用。现有的主要为云端LLM服务设计的缓解技术在部署者控制的环境中常常被规避或无效。我们提出了SECNEURON，这是第一个将经典访问控制无缝嵌入到LLMs内在能力中的框架，为本地部署的LLMs实现了可靠、经济高效、灵活且经过认证的滥用控制。SECNEURON采用神经元级加密和选择性解密来动态控制LLMs的任务特定能力，限制未经授权的任务滥用而不损害其他任务。我们首先设计了一种任务特定神经元提取机制，以解耦逻辑相关的神经元并构建一个分层策略树来处理耦合神经元。然后，我们为LLMs中数百万个神经元引入了一个灵活高效的混合加密框架。最后，我们开发了一种基于分布的密文解密神经元检测机制，以确保部分解密LLMs的有效性。我们证明了SECNEURON在任务可控性原则下满足IND-CPA安全性（不可区分性选择密文攻击安全性）和抗串谋安全性。在各种任务设置下的实验表明，SECNEURON将未经授权的任务准确性限制在25%以下，同时授权任务的准确性损失仅为2%。以未经授权的代码任务为例，与滥用相关的恶意代码生成准确率从59%降低到15%。SECNEURON还减轻了未经授权的数据泄露，将个人身份信息（PII）提取率降低到5%以下，并将成员推断降低到随机猜测水平。", "summary": "SECNEURON是一个创新的框架，旨在解决本地部署大型语言模型（LLMs）面临的滥用控制和安全挑战。它通过神经元级别的混合加密和选择性解密，将传统访问控制无缝集成到LLMs中。SECNEURON能够动态限制LLM的任务特定能力，有效阻止未经授权的任务滥用，同时确保授权任务的性能不受影响。实验结果表明，该系统能显著降低未经授权任务的准确性、恶意代码生成率以及数据泄露风险，证明了其在提供可靠、灵活且安全的本地LLM部署方面的有效性。", "keywords": "本地LLM, 滥用控制, 神经元加密, 访问控制, 数据隐私"}}
{"id": "2506.04842", "pdf": "https://arxiv.org/pdf/2506.04842", "abs": "https://arxiv.org/abs/2506.04842", "authors": ["Mario Malizia", "Charles Hamesse", "Ken Hasselmann", "Geert De Cubber", "Nikolaos Tsiogkas", "Eric Demeester", "Rob Haelterman"], "title": "MineInsight: A Multi-sensor Dataset for Humanitarian Demining Robotics in Off-Road Environments", "categories": ["cs.RO", "cs.CV"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "The use of robotics in humanitarian demining increasingly involves computer\nvision techniques to improve landmine detection capabilities. However, in the\nabsence of diverse and realistic datasets, the reliable validation of\nalgorithms remains a challenge for the research community. In this paper, we\nintroduce MineInsight, a publicly available multi-sensor, multi-spectral\ndataset designed for off-road landmine detection. The dataset features 35\ndifferent targets (15 landmines and 20 commonly found objects) distributed\nalong three distinct tracks, providing a diverse and realistic testing\nenvironment. MineInsight is, to the best of our knowledge, the first dataset to\nintegrate dual-view sensor scans from both an Unmanned Ground Vehicle and its\nrobotic arm, offering multiple viewpoints to mitigate occlusions and improve\nspatial awareness. It features two LiDARs, as well as images captured at\ndiverse spectral ranges, including visible (RGB, monochrome), visible\nshort-wave infrared (VIS-SWIR), and long-wave infrared (LWIR). Additionally,\nthe dataset comes with an estimation of the location of the targets, offering a\nbenchmark for evaluating detection algorithms. We recorded approximately one\nhour of data in both daylight and nighttime conditions, resulting in around\n38,000 RGB frames, 53,000 VIS-SWIR frames, and 108,000 LWIR frames. MineInsight\nserves as a benchmark for developing and evaluating landmine detection\nalgorithms. Our dataset is available at\nhttps://github.com/mariomlz99/MineInsight.", "AI": {"title_translation": "MineInsight：用于越野环境下人道主义排雷机器人的多传感器数据集", "tldr": "MineInsight是一个新型的、公开的多传感器、多光谱数据集，专为越野地雷探测机器人设计，旨在解决现有数据集不足以验证算法的挑战，并为地雷探测算法的开发和评估提供基准。", "motivation": "在人道主义排雷领域，计算机视觉技术被越来越多地用于提高地雷探测能力。然而，由于缺乏多样化和真实的数据集，地雷探测算法的可靠验证仍然是研究界面临的挑战。", "method": "本文引入了MineInsight，一个公开可用的多传感器、多光谱数据集，专为越野地雷探测设计。该数据集包含35种不同目标（15个地雷和20个常见物体），分布在三条不同轨道上。它是首个整合无人地面车辆及其机械臂双视角传感器扫描的数据集，提供了多个视角以减少遮挡并提高空间感知。它配备了两个激光雷达以及可见光（RGB、单色）、可见短波红外（VIS-SWIR）和长波红外（LWIR）等多种光谱范围的图像。数据集还提供了目标位置的估计，作为评估探测算法的基准。数据记录了约一小时，包括白天和夜间条件，产生了约38,000帧RGB图像、53,000帧VIS-SWIR图像和108,000帧LWIR图像。", "result": "MineInsight数据集的创建，为开发和评估地雷探测算法提供了一个基准，解决了现有数据集不足的问题，促进了人道主义排雷领域机器人视觉技术的发展。", "conclusion": "MineInsight数据集通过提供多样化、真实且包含多传感器、多光谱数据的环境，解决了人道主义排雷机器人领域地雷探测算法验证面临的数据集不足挑战。它将作为一个重要的基准，推动地雷探测技术的发展。", "translation": "人道主义排雷中机器人技术的使用越来越多地涉及计算机视觉技术，以提高地雷探测能力。然而，在缺乏多样化和真实数据集的情况下，算法的可靠验证仍然是研究界面临的挑战。在本文中，我们引入了MineInsight，一个公开可用的多传感器、多光谱数据集，专为越野地雷探测设计。该数据集包含沿三条不同轨道分布的35种不同目标（15个地雷和20个常见物体），提供了一个多样化且真实的测试环境。据我们所知，MineInsight是第一个整合了无人地面车辆及其机械臂双视角传感器扫描的数据集，提供了多个视点以减轻遮挡并提高空间感知。它具有两个激光雷达，以及在不同光谱范围捕获的图像，包括可见光（RGB、单色）、可见短波红外（VIS-SWIR）和长波红外（LWIR）。此外，数据集还附带了目标位置的估计，为评估探测算法提供了基准。我们在白天和夜间条件下记录了大约一小时的数据，产生了大约38,000帧RGB图像、53,000帧VIS-SWIR图像和108,000帧LWIR图像。MineInsight可作为开发和评估地雷探测算法的基准。我们的数据集可在https://github.com/mariomlz99/MineInsight获取。", "summary": "本论文介绍了MineInsight，一个为越野地雷探测机器人设计的多传感器、多光谱公开数据集。该数据集包含35种目标，整合了无人地面车辆和机械臂的双视角扫描，并配备了激光雷达以及可见光、VIS-SWIR和LWIR等多光谱图像。它还提供了目标位置估算，旨在解决现有数据集不足以验证地雷探测算法的挑战，并为算法开发和评估提供了一个重要的基准。", "keywords": "人道主义排雷, 机器人, 多传感器数据集, 地雷探测"}}
{"id": "2506.04571", "pdf": "https://arxiv.org/pdf/2506.04571", "abs": "https://arxiv.org/abs/2506.04571", "authors": ["Srikanth Thudumu", "Jason Fisher"], "title": "OpenAg: Democratizing Agricultural Intelligence", "categories": ["cs.AI"], "comment": "10 pages, 1 figure", "summary": "Agriculture is undergoing a major transformation driven by artificial\nintelligence (AI), machine learning, and knowledge representation technologies.\nHowever, current agricultural intelligence systems often lack contextual\nunderstanding, explainability, and adaptability, especially for smallholder\nfarmers with limited resources. General-purpose large language models (LLMs),\nwhile powerful, typically lack the domain-specific knowledge and contextual\nreasoning needed for practical decision support in farming. They tend to\nproduce recommendations that are too generic or unrealistic for real-world\napplications. To address these challenges, we present OpenAg, a comprehensive\nframework designed to advance agricultural artificial general intelligence\n(AGI). OpenAg combines domain-specific foundation models, neural knowledge\ngraphs, multi-agent reasoning, causal explainability, and adaptive transfer\nlearning to deliver context-aware, explainable, and actionable insights. The\nsystem includes: (i) a unified agricultural knowledge base that integrates\nscientific literature, sensor data, and farmer-generated knowledge; (ii) a\nneural agricultural knowledge graph for structured reasoning and inference;\n(iii) an adaptive multi-agent reasoning system where AI agents specialize and\ncollaborate across agricultural domains; and (iv) a causal transparency\nmechanism that ensures AI recommendations are interpretable, scientifically\ngrounded, and aligned with real-world constraints. OpenAg aims to bridge the\ngap between scientific knowledge and the tacit expertise of experienced farmers\nto support scalable and locally relevant agricultural decision-making.", "AI": {"title_translation": "OpenAg：农业智能大众化", "tldr": "OpenAg是一个旨在通过结合领域特定模型、神经知识图谱、多智能体推理和因果可解释性来推进农业通用人工智能（AGI）的综合框架，以提供情境感知、可解释和可操作的农业决策支持。", "motivation": "当前的农业智能系统缺乏情境理解、可解释性和适应性，特别是对于资源有限的小农户。通用大型语言模型（LLMs）虽然强大，但缺乏农业领域的专业知识和情境推理能力，导致其推荐过于通用或不切实际。", "method": "OpenAg是一个综合框架，通过结合领域特定基础模型、神经知识图谱、多智能体推理、因果可解释性和自适应迁移学习来解决上述挑战。该系统包含：(i) 统一的农业知识库；(ii) 用于结构化推理的神经农业知识图谱；(iii) 农业领域内专业化和协作的自适应多智能体推理系统；(iv) 确保AI推荐可解释、有科学依据并符合实际约束的因果透明机制。", "result": "Not mentioned in abstract", "conclusion": "OpenAg旨在弥合科学知识与经验丰富农民的默会知识之间的鸿沟，以支持可扩展和与当地相关的农业决策。", "translation": "农业正在经历由人工智能（AI）、机器学习和知识表示技术驱动的重大变革。然而，当前的农业智能系统往往缺乏情境理解、可解释性和适应性，特别是对于资源有限的小农户。通用大型语言模型（LLMs）虽然功能强大，但通常缺乏农业实践决策支持所需的领域特定知识和情境推理能力。它们倾向于产生过于通用或不切实际的建议，不适用于实际应用。为了应对这些挑战，我们提出了OpenAg，一个旨在推进农业通用人工智能（AGI）的综合框架。OpenAg结合了领域特定基础模型、神经知识图谱、多智能体推理、因果可解释性和自适应迁移学习，以提供情境感知、可解释和可操作的见解。该系统包括：(i) 一个整合了科学文献、传感器数据和农民生成知识的统一农业知识库；(ii) 一个用于结构化推理和推断的神经农业知识图谱；(iii) 一个自适应多智能体推理系统，其中AI智能体在农业领域内进行专业化和协作；以及(iv) 一个因果透明机制，确保AI建议可解释、有科学依据并符合现实世界约束。OpenAg旨在弥合科学知识与经验丰富农民的默会知识之间的鸿沟，以支持可扩展和与当地相关的农业决策。", "summary": "OpenAg是一个为推进农业通用人工智能（AGI）而设计的综合框架，旨在解决现有农业智能系统在情境理解、可解释性和适应性方面的不足。它整合了领域特定基础模型、神经知识图谱、多智能体推理、因果可解释性以及自适应迁移学习，以提供情境感知、可解释和可操作的见解。OpenAg系统包括一个统一的农业知识库、一个神经农业知识图谱、一个自适应多智能体推理系统和一个因果透明机制，旨在支持可扩展且与当地相关的农业决策。", "keywords": "农业智能, 通用人工智能, 知识图谱, 多智能体系统, 可解释AI"}}
{"id": "2506.04499", "pdf": "https://arxiv.org/pdf/2506.04499", "abs": "https://arxiv.org/abs/2506.04499", "authors": ["Shizhong Han", "Hsin-Pai Cheng", "Hong Cai", "Jihad Masri", "Soyeb Nagori", "Fatih Porikli"], "title": "FALO: Fast and Accurate LiDAR 3D Object Detection on Resource-Constrained Devices", "categories": ["cs.CV"], "comment": null, "summary": "Existing LiDAR 3D object detection methods predominantely rely on sparse\nconvolutions and/or transformers, which can be challenging to run on\nresource-constrained edge devices, due to irregular memory access patterns and\nhigh computational costs. In this paper, we propose FALO, a hardware-friendly\napproach to LiDAR 3D detection, which offers both state-of-the-art (SOTA)\ndetection accuracy and fast inference speed. More specifically, given the 3D\npoint cloud and after voxelization, FALO first arranges sparse 3D voxels into a\n1D sequence based on their coordinates and proximity. The sequence is then\nprocessed by our proposed ConvDotMix blocks, consisting of large-kernel\nconvolutions, Hadamard products, and linear layers. ConvDotMix provides\nsufficient mixing capability in both spatial and embedding dimensions, and\nintroduces higher-order nonlinear interaction among spatial features.\nFurthermore, when going through the ConvDotMix layers, we introduce implicit\ngrouping, which balances the tensor dimensions for more efficient inference and\ntakes into account the growing receptive field. All these operations are\nfriendly to run on resource-constrained platforms and proposed FALO can readily\ndeploy on compact, embedded devices. Our extensive evaluation on LiDAR 3D\ndetection benchmarks such as nuScenes and Waymo shows that FALO achieves\ncompetitive performance. Meanwhile, FALO is 1.6~9.8x faster than the latest\nSOTA on mobile Graphics Processing Unit (GPU) and mobile Neural Processing Unit\n(NPU).", "AI": {"title_translation": "FALO：在资源受限设备上快速准确的LiDAR 3D目标检测", "tldr": "FALO是一种针对资源受限设备优化的LiDAR 3D目标检测方法，它通过创新的ConvDotMix块和隐式分组实现了高精度和快速推理速度。", "motivation": "现有的LiDAR 3D目标检测方法主要依赖稀疏卷积和/或Transformer，由于不规则的内存访问模式和高计算成本，难以在资源受限的边缘设备上运行。", "method": "FALO首先将稀疏的3D体素根据坐标和接近度排列成1D序列，然后通过提出的ConvDotMix块进行处理。ConvDotMix块由大核卷积、Hadamard积和线性层组成，提供了足够的空间和嵌入维度混合能力，并引入了空间特征之间的高阶非线性交互。此外，在ConvDotMix层中引入了隐式分组，以平衡张量维度，实现更高效的推理，并考虑了不断增长的感受野。", "result": "FALO在nuScenes和Waymo等LiDAR 3D检测基准上取得了有竞争力的性能。同时，FALO在移动GPU和移动NPU上比最新的SOTA方法快1.6~9.8倍。", "conclusion": "FALO提供了一种硬件友好的LiDAR 3D检测方法，能够在资源受限的设备上实现最先进的检测精度和快速推理速度，证明了其在紧凑型嵌入式设备上部署的潜力。", "translation": "现有LiDAR 3D目标检测方法主要依赖稀疏卷积和/或Transformer，由于不规则的内存访问模式和高计算成本，难以在资源受限的边缘设备上运行。在本文中，我们提出了FALO，一种硬件友好的LiDAR 3D检测方法，它兼具最先进（SOTA）的检测精度和快速推理速度。更具体地说，给定3D点云并在体素化之后，FALO首先根据其坐标和接近度将稀疏的3D体素排列成1D序列。然后，该序列由我们提出的ConvDotMix块处理，该块由大核卷积、Hadamard积和线性层组成。ConvDotMix在空间和嵌入维度上提供了足够的混合能力，并引入了空间特征之间的高阶非线性交互。此外，在通过ConvDotMix层时，我们引入了隐式分组，这平衡了张量维度以实现更高效的推理，并考虑了不断增长的感受野。所有这些操作都易于在资源受限平台上运行，并且提出的FALO可以轻松部署在紧凑型嵌入式设备上。我们对nuScenes和Waymo等LiDAR 3D检测基准的广泛评估表明，FALO取得了有竞争力的性能。同时，FALO在移动图形处理单元（GPU）和移动神经处理单元（NPU）上比最新的SOTA快1.6~9.8倍。", "summary": "FALO是一种为资源受限边缘设备设计的LiDAR 3D目标检测方法，旨在解决现有稀疏卷积和Transformer方法计算成本高、内存访问不规则的问题。该方法将3D体素转化为1D序列，并通过结合大核卷积、Hadamard积和线性层的ConvDotMix块进行处理，从而在空间和嵌入维度上实现有效混合并引入高阶非线性交互。此外，引入隐式分组以优化推理效率。FALO在nuScenes和Waymo等基准测试中表现出与SOTA相当的精度，并且在移动GPU和NPU上推理速度显著提升。", "keywords": "LiDAR 3D目标检测, 资源受限设备, ConvDotMix, 硬件友好, 快速推理"}}
{"id": "2506.04294", "pdf": "https://arxiv.org/pdf/2506.04294", "abs": "https://arxiv.org/abs/2506.04294", "authors": ["Asier Diaz-Iglesias", "Xabier Belaunzaran", "Ane M. Florez-Tapia"], "title": "Short-Term Power Demand Forecasting for Diverse Consumer Types to Enhance Grid Planning and Synchronisation", "categories": ["cs.LG"], "comment": null, "summary": "Ensuring grid stability in the transition to renewable energy sources\nrequires accurate power demand forecasting. This study addresses the need for\nprecise forecasting by differentiating among industrial, commercial, and\nresidential consumers through customer clusterisation, tailoring the\nforecasting models to capture the unique consumption patterns of each group. A\nfeature selection process is done for each consumer type including temporal,\nsocio-economic, and weather-related data obtained from the Copernicus Earth\nObservation (EO) program. A variety of AI and machine learning algorithms for\nShort-Term Load Forecasting (STLF) and Very Short-Term Load Forecasting (VSTLF)\nare explored and compared, determining the most effective approaches. With all\nthat, the main contribution of this work are the new forecasting approaches\nproposed, which have demonstrated superior performance compared to simpler\nmodels, both for STLF and VSTLF, highlighting the importance of customized\nforecasting strategies for different consumer groups and demonstrating the\nimpact of incorporating detailed weather data on forecasting accuracy. These\nadvancements contribute to more reliable power demand predictions, thereby\nsupporting grid stability.", "AI": {"title_translation": "面向不同消费者类型的短期电力需求预测以增强电网规划和同步", "tldr": "本研究通过对工业、商业和住宅消费者进行聚类，并为每个群体量身定制预测模型，以提高电网规划和同步的短期电力需求预测准确性。", "motivation": "在向可再生能源过渡期间，确保电网稳定需要准确的电力需求预测。", "method": "本研究通过客户聚类区分工业、商业和住宅消费者，并为每个群体定制预测模型。针对每种消费者类型，从哥白尼地球观测（EO）计划中获取时间、社会经济和天气相关数据进行特征选择。探索并比较了多种AI和机器学习算法用于短期负荷预测（STLF）和超短期负荷预测（VSTLF）。", "result": "所提出的新预测方法在STLF和VSTLF方面均表现出优于简单模型的性能，强调了针对不同消费者群体定制预测策略的重要性，并证明了纳入详细天气数据对预测准确性的影响。", "conclusion": "这些进展有助于实现更可靠的电力需求预测，从而支持电网稳定。", "translation": "在向可再生能源过渡期间，确保电网稳定需要准确的电力需求预测。本研究通过客户聚类区分工业、商业和住宅消费者，从而满足了对精确预测的需求，并为每个群体量身定制预测模型，以捕捉其独特的消费模式。针对每种消费者类型，从哥白尼地球观测（EO）计划中获取时间、社会经济和天气相关数据，并进行特征选择。本研究探索并比较了多种用于短期负荷预测（STLF）和超短期负荷预测（VSTLF）的AI和机器学习算法，从而确定了最有效的方法。综上所述，这项工作的主要贡献是提出了新的预测方法，这些方法在STLF和VSTLF方面均表现出优于简单模型的性能，强调了针对不同消费者群体定制预测策略的重要性，并证明了纳入详细天气数据对预测准确性的影响。这些进展有助于实现更可靠的电力需求预测，从而支持电网稳定。", "summary": "本研究旨在通过对工业、商业和住宅消费者进行聚类，并为每个群体定制预测模型，从而提高短期电力需求预测的准确性。研究利用来自哥白尼地球观测计划的时间、社会经济和天气数据进行特征选择，并探索了多种AI和机器学习算法。结果表明，所提出的定制化预测方法在准确性上优于简单模型，并且详细天气数据对预测精度有显著提升，从而有助于电网稳定。", "keywords": "电力需求预测, 消费者类型, 电网规划, 机器学习, 天气数据"}}
{"id": "2506.05290", "pdf": "https://arxiv.org/pdf/2506.05290", "abs": "https://arxiv.org/abs/2506.05290", "authors": ["Pierre Tholoniat", "Alison Caulfield", "Giorgio Cavicchioli", "Mark Chen", "Nikos Goutzoulias", "Benjamin Case", "Asaf Cidon", "Roxana Geambasu", "Mathias Lécuyer", "Martin Thomson"], "title": "Big Bird: Privacy Budget Management for W3C's Privacy-Preserving Attribution API", "categories": ["cs.CR"], "comment": null, "summary": "Privacy-preserving advertising APIs like Privacy-Preserving Attribution (PPA)\nare designed to enhance web privacy while enabling effective ad measurement.\nPPA offers an alternative to cross-site tracking with encrypted reports\ngoverned by differential privacy (DP), but current designs lack a principled\napproach to privacy budget management, creating uncertainty around critical\ndesign decisions. We present Big Bird, a privacy budget manager for PPA that\nclarifies per-site budget semantics and introduces a global budgeting system\ngrounded in resource isolation principles. Big Bird enforces utility-preserving\nlimits via quota budgets and improves global budget utilization through a novel\nbatched scheduling algorithm. Together, these mechanisms establish a robust\nfoundation for enforcing privacy protections in adversarial environments. We\nimplement Big Bird in Firefox and evaluate it on real-world ad data,\ndemonstrating its resilience and effectiveness.", "AI": {"title_translation": "Big Bird: W3C隐私保护归因API的隐私预算管理", "tldr": "Big Bird通过引入站点预算和全局预算系统，解决了隐私保护归因API中隐私预算管理缺乏原则性方法的问题，并在Firefox中实现了高效性。", "motivation": "当前的隐私保护归因API（PPA）设计缺乏一个有原则性的隐私预算管理方法，导致关键设计决策的不确定性，从而影响了网络隐私和广告衡量。", "method": "本文提出了Big Bird，一个用于PPA的隐私预算管理器。它阐明了每站点预算的语义，并引入了一个基于资源隔离原则的全局预算系统。Big Bird通过配额预算强制执行效用保留限制，并通过新颖的批处理调度算法提高了全局预算利用率。该系统在Firefox中实现，并使用真实世界的广告数据进行评估。", "result": "Big Bird在真实世界的广告数据上进行了评估，展示了其弹性和有效性。", "conclusion": "Big Bird通过其机制为在对抗性环境中实施隐私保护奠定了坚实的基础。", "translation": "隐私保护广告API，如隐私保护归因（PPA），旨在增强网络隐私，同时实现有效的广告衡量。PPA通过受差分隐私（DP）管理的加密报告提供了一种替代跨站点跟踪的方法，但当前设计缺乏一种有原则的隐私预算管理方法，这给关键设计决策带来了不确定性。我们提出了Big Bird，一个用于PPA的隐私预算管理器，它阐明了每站点预算的语义，并引入了一个基于资源隔离原则的全局预算系统。Big Bird通过配额预算强制执行效用保留限制，并通过新颖的批处理调度算法提高了全局预算利用率。这些机制共同为在对抗性环境中实施隐私保护奠定了坚实的基础。我们在Firefox中实现了Big Bird，并使用真实世界的广告数据对其进行了评估，展示了其弹性和有效性。", "summary": "本文介绍了Big Bird，一个针对W3C隐私保护归因API的隐私预算管理系统。它解决了现有设计中隐私预算管理缺乏原则性的问题，通过引入每站点预算语义、基于资源隔离的全局预算系统、配额预算以及批处理调度算法，确保了隐私保护的鲁棒性和效用。在Firefox上的实现和真实数据评估证明了其有效性。", "keywords": "隐私保护归因, 隐私预算管理, 差分隐私, Big Bird, 广告API"}}
{"id": "2506.04881", "pdf": "https://arxiv.org/pdf/2506.04881", "abs": "https://arxiv.org/abs/2506.04881", "authors": ["Ioana Hustiu", "Roozbeh Abolpour", "Cristian Mahulea", "Marius Kloetzer"], "title": "Efficient Path Planning and Task Allocation Algorithm for Boolean Specifications", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper presents a novel path-planning and task assignment algorithm for\nmulti-robot systems that should fulfill a global Boolean specification. The\nproposed method is based on Integer Linear Programming (ILP) formulations,\nwhich are combined with structural insights from Petri nets to improve\nscalability and computational efficiency. By proving that the \\emph{constraint\nmatrix} is totally unimodular (TU) for certain classes of problems, the ILP\nformulation can be relaxed into a Linear Programming (LP) problem without\nlosing the integrality of the solution. This relaxation eliminates complex\ncombinatorial techniques, significantly reducing computational overhead and\nthus ensuring scalability for large-scale systems. Using the approach proposed\nin this paper, we can solve path-planning problems for teams made up to 500\nrobots. The method guarantees computational tractability, handles collision\navoidance and reduces computational demands through iterative LP optimization\ntechniques. Case studies demonstrate the efficiency of the algorithm in\ngenerating scalable, collision-free paths for large robot teams navigating in\ncomplex environments. While the conservative nature of collision avoidance\nintroduces additional constraints, and thus, computational requirements, the\nsolution remains practical and impactful for diverse applications. The\nalgorithm is particularly applicable to real-world scenarios, including\nwarehouse logistics where autonomous robots must efficiently coordinate tasks\nor search-and-rescue operations in various environments. This work contributes\nboth theoretically and practically to scalable multi-robot path planning and\ntask allocation, offering an efficient framework for coordinating autonomous\nagents in shared environments.", "AI": {"title_translation": "面向布尔规范的高效路径规划与任务分配算法", "tldr": "本文提出了一种基于整数线性规划的高效路径规划与任务分配算法，适用于多机器人系统，并通过线性规划松弛实现了高达500个机器人的可扩展性。", "motivation": "本文旨在解决多机器人系统在满足全局布尔规范时，如何进行高效的路径规划和任务分配问题，尤其关注大规模系统的可扩展性和计算效率。", "method": "所提出的方法结合了整数线性规划 (ILP) 公式和Petri网的结构洞察。通过证明特定类型问题的约束矩阵是完全幺模的 (TU)，ILP公式可以松弛为线性规划 (LP) 问题，且不损失解的整数性。这种松弛消除了复杂的组合技术，并通过迭代LP优化技术处理碰撞避免并降低计算需求。", "result": "该算法能够解决多达500个机器人的路径规划问题，保证了计算的可处理性，处理了碰撞避免，并通过迭代LP优化技术降低了计算需求。案例研究表明，该算法在为复杂环境中导航的大型机器人团队生成可扩展、无碰撞的路径方面效率很高。", "conclusion": "这项工作在可扩展的多机器人路径规划和任务分配方面做出了理论和实践贡献，为共享环境中自主智能体的协调提供了一个高效的框架，适用于仓库物流和搜救等实际场景。", "translation": "本文提出了一种新颖的多机器人系统路径规划和任务分配算法，该系统应满足全局布尔规范。所提出的方法基于整数线性规划 (ILP) 公式，并结合了Petri网的结构洞察，以提高可扩展性和计算效率。通过证明对于某些类型问题，其约束矩阵是完全幺模的 (TU)，ILP 公式可以松弛为线性规划 (LP) 问题，而不会损失解的整数性。这种松弛消除了复杂的组合技术，显著降低了计算开销，从而确保了大规模系统的可扩展性。使用本文提出的方法，我们可以解决由多达500个机器人组成的团队的路径规划问题。该方法保证了计算的可处理性，处理了碰撞避免，并通过迭代 LP 优化技术降低了计算需求。案例研究证明了该算法在为复杂环境中导航的大型机器人团队生成可扩展、无碰撞路径方面的效率。尽管碰撞避免的保守性引入了额外的约束，从而增加了计算要求，但该解决方案对于各种应用仍然是实用且有影响力的。该算法特别适用于实际场景，包括自主机器人必须高效协调任务的仓库物流或各种环境中的搜救行动。这项工作在可扩展的多机器人路径规划和任务分配方面做出了理论和实践贡献，为共享环境中自主智能体的协调提供了一个高效的框架。", "summary": "本文提出了一种新颖高效且可扩展的多机器人系统路径规划与任务分配算法，旨在满足全局布尔规范。该方法结合了整数线性规划(ILP)公式和Petri网的结构洞察，并通过证明特定问题类的约束矩阵具有完全幺模特性，使得ILP可以松弛为线性规划(LP)问题，从而显著降低计算开销，实现高达500个机器人的系统可扩展性，并处理碰撞避免。该算法在实际应用中表现出高效性，适用于大规模机器人团队在复杂环境中的协调。", "keywords": "多机器人系统, 路径规划, 任务分配, 整数线性规划, 可扩展性"}}
{"id": "2506.04610", "pdf": "https://arxiv.org/pdf/2506.04610", "abs": "https://arxiv.org/abs/2506.04610", "authors": ["Guido Governatori", "Antonino Rotolo"], "title": "Judicial Permission", "categories": ["cs.AI", "cs.CY", "cs.LO"], "comment": null, "summary": "This paper examines the significance of weak permissions in criminal trials\n(\\emph{judicial permission}). It introduces a dialogue game model to\nsystematically address judicial permissions, considering different standards of\nproof and argumentation semantics.", "AI": {"title_translation": "司法许可", "tldr": "本文通过引入对话博弈模型，系统地探讨了刑事审判中“司法许可”这一弱许可的重要性。", "motivation": "研究刑事审判中弱许可（即司法许可）的重要性。", "method": "引入了一个对话博弈模型，系统地处理司法许可，并考虑了不同的证明标准和论证语义。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "本文探讨了刑事审判中弱许可（即司法许可）的重要性。它引入了一个对话博弈模型，系统地处理司法许可，并考虑了不同的证明标准和论证语义。", "summary": "本文探讨了刑事审判中弱许可（即司法许可）的重要性。研究通过引入一个对话博弈模型，系统地分析了司法许可，并考虑了不同的证明标准和论证语义。", "keywords": "司法许可, 弱许可, 对话博弈模型, 刑事审判, 证明标准"}}
{"id": "2506.04501", "pdf": "https://arxiv.org/pdf/2506.04501", "abs": "https://arxiv.org/abs/2506.04501", "authors": ["Guangyu Shen", "Zhihua Li", "Xiang Xu", "Tianchen Zhao", "Zheng Zhang", "Dongsheng An", "Zhuowen Tu", "Yifan Xing", "Qin Zhang"], "title": "AuthGuard: Generalizable Deepfake Detection via Language Guidance", "categories": ["cs.CV"], "comment": null, "summary": "Existing deepfake detection techniques struggle to keep-up with the\never-evolving novel, unseen forgeries methods. This limitation stems from their\nreliance on statistical artifacts learned during training, which are often tied\nto specific generation processes that may not be representative of samples from\nnew, unseen deepfake generation methods encountered at test time. We propose\nthat incorporating language guidance can improve deepfake detection\ngeneralization by integrating human-like commonsense reasoning -- such as\nrecognizing logical inconsistencies and perceptual anomalies -- alongside\nstatistical cues. To achieve this, we train an expert deepfake vision encoder\nby combining discriminative classification with image-text contrastive\nlearning, where the text is generated by generalist MLLMs using few-shot\nprompting. This allows the encoder to extract both language-describable,\ncommonsense deepfake artifacts and statistical forgery artifacts from\npixel-level distributions. To further enhance robustness, we integrate data\nuncertainty learning into vision-language contrastive learning, mitigating\nnoise in image-text supervision. Our expert vision encoder seamlessly\ninterfaces with an LLM, further enabling more generalized and interpretable\ndeepfake detection while also boosting accuracy. The resulting framework,\nAuthGuard, achieves state-of-the-art deepfake detection accuracy in both\nin-distribution and out-of-distribution settings, achieving AUC gains of 6.15%\non the DFDC dataset and 16.68% on the DF40 dataset. Additionally, AuthGuard\nsignificantly enhances deepfake reasoning, improving performance by 24.69% on\nthe DDVQA dataset.", "AI": {"title_translation": "AuthGuard：通过语言指导实现可泛化深度伪造检测", "tldr": "AuthGuard通过结合语言指导和视觉编码器，实现了更泛化、可解释的深度伪造检测，并在多个数据集上达到了最先进的性能。", "motivation": "现有深度伪造检测技术难以应对不断演变的新型、未见过的伪造方法，因为它们依赖于训练期间学习到的特定生成过程的统计伪影，这些伪影在新样本中可能不具代表性。", "method": "本文提出了AuthGuard框架，通过结合判别性分类与图像-文本对比学习来训练一个专家深度伪造视觉编码器，其中文本由通用多模态大型语言模型（MLLMs）通过少样本提示生成，以提取语言可描述的常识性伪造伪影和统计伪造伪影。为增强鲁棒性，还将数据不确定性学习集成到视觉-语言对比学习中以减轻噪声。该专家视觉编码器与大型语言模型（LLM）无缝接口，实现更泛化和可解释的深度伪造检测。", "result": "AuthGuard在分布内和分布外设置下都实现了最先进的深度伪造检测精度，在DFDC数据集上AUC增益为6.15%，在DF40数据集上AUC增益为16.68%。此外，AuthGuard显著增强了深度伪造推理能力，在DDVQA数据集上性能提升了24.69%。", "conclusion": "AuthGuard通过结合语言指导和视觉编码器，成功解决了现有深度伪造检测技术泛化性差的问题，实现了最先进的性能和更强的可解释性。", "translation": "AuthGuard：通过语言指导实现可泛化深度伪造检测\n\n现有的深度伪造检测技术难以跟上不断演变的新型、未见过的伪造方法。这种局限性源于它们对训练期间学习到的统计伪影的依赖，这些伪影通常与特定的生成过程相关联，在测试时遇到的新、未见过的深度伪造生成方法中可能不具代表性。我们提出，结合语言指导可以通过整合类人常识性推理（例如识别逻辑不一致和感知异常）以及统计线索来提高深度伪造检测的泛化性。为了实现这一点，我们通过结合判别性分类和图像-文本对比学习来训练一个专家深度伪造视觉编码器，其中文本是通过使用少样本提示的通用多模态大型语言模型（MLLMs）生成的。这使得编码器能够从像素级分布中提取可由语言描述的常识性深度伪造伪影和统计伪造伪影。为了进一步增强鲁棒性，我们将数据不确定性学习集成到视觉-语言对比学习中，以减轻图像-文本监督中的噪声。我们的专家视觉编码器与大型语言模型（LLM）无缝接口，进一步实现了更泛化和可解释的深度伪造检测，同时提高了准确性。由此产生的框架AuthGuard在分布内和分布外设置下均实现了最先进的深度伪造检测精度，在DFDC数据集上实现了6.15%的AUC增益，在DF40数据集上实现了16.68%的AUC增益。此外，AuthGuard显著增强了深度伪造推理能力，在DDVQA数据集上性能提升了24.69%。", "summary": "本文提出了AuthGuard框架，旨在解决现有深度伪造检测技术在应对新型伪造方法时泛化性不足的问题。AuthGuard通过整合人类常识性推理（如识别逻辑不一致和感知异常）与统计线索，利用语言指导来改进深度伪造检测的泛化性。具体而言，它训练一个专家视觉编码器，结合判别性分类和图像-文本对比学习，并集成数据不确定性学习以增强鲁棒性。该框架与大型语言模型（LLM）无缝接口，实现了更泛化、可解释且高精度的深度伪造检测，在多个数据集上取得了最先进的性能提升。", "keywords": "深度伪造检测, 语言指导, 泛化性, 视觉-语言模型, 对比学习"}}
{"id": "2506.04296", "pdf": "https://arxiv.org/pdf/2506.04296", "abs": "https://arxiv.org/abs/2506.04296", "authors": ["N Guerin", "M Nakhla", "A Dehoux", "J L Loyer"], "title": "Deep learning for predicting hauling fleet production capacity under uncertainties in open pit mines using real and simulated data", "categories": ["cs.LG"], "comment": null, "summary": "Accurate short-term forecasting of hauling-fleet capacity is crucial in\nopen-pit mining, where weather fluctuations, mechanical breakdowns, and\nvariable crew availability introduce significant operational uncertainties. We\npropose a deep-learning framework that blends real-world operational records\n(high-resolution rainfall measurements, fleet performance telemetry) with\nsynthetically generated mechanical-breakdown scenarios to enable the model to\ncapture fluctuating high-impact failure events. We evaluate two architectures:\nan XGBoost regressor achieving a median absolute error (MedAE) of 14.3 per cent\nand a Long Short-Term Memory network with a MedAE of 15.1 per cent. Shapley\nAdditive exPlanations (SHAP) value analyses identify cumulative rainfall,\nhistorical payload trends, and simulated breakdown frequencies as dominant\npredictors. Integration of simulated breakdown data and shift-planning features\nnotably reduces prediction volatility. Future work will further integrate\nmaintenance-scheduling indicators (Mean Time Between Failures, Mean Time to\nRepair), detailed human resource data (operator absenteeism, crew efficiency\nmetrics), blast event scheduling, and other operational constraints to enhance\nforecast robustness and adaptability. This hybrid modelling approach offers a\ncomprehensive decision-support tool for proactive, data-driven fleet management\nunder dynamically uncertain conditions.", "AI": {"title_translation": "基于真实和模拟数据，深度学习预测露天矿不确定性下运输车队产能", "tldr": "本研究提出一种深度学习框架，结合真实和模拟数据，用于预测露天矿运输车队在不确定性下的产能，并评估了XGBoost和LSTM模型。", "motivation": "在露天采矿中，天气波动、机械故障和船员可用性等因素引入了显著的运营不确定性，因此准确的短期运输车队产能预测至关重要。", "method": "本研究提出一个深度学习框架，该框架将真实世界的运营记录（高分辨率降雨测量、车队性能遥测）与合成生成的机械故障场景相结合，使模型能够捕捉波动的、高影响的故障事件。评估了两种架构：XGBoost回归器和长短期记忆（LSTM）网络。使用Shapley可加解释（SHAP）值分析来识别主要预测因子。", "result": "XGBoost回归器实现了14.3%的中位数绝对误差（MedAE），而长短期记忆（LSTM）网络的MedAE为15.1%。SHAP值分析确定累积降雨量、历史有效载荷趋势和模拟故障频率是主要预测因子。模拟故障数据和班次规划特征的整合显著降低了预测波动性。", "conclusion": "这种混合建模方法为在动态不确定条件下主动的、数据驱动的车队管理提供了一个全面的决策支持工具。", "translation": "准确的短期运输车队产能预测在露天采矿中至关重要，因为天气波动、机械故障和多变的船员可用性引入了显著的运营不确定性。我们提出一个深度学习框架，该框架将真实世界的运营记录（高分辨率降雨测量、车队性能遥测）与合成生成的机械故障场景相结合，使模型能够捕捉波动的、高影响的故障事件。我们评估了两种架构：XGBoost回归器实现了14.3%的中位数绝对误差（MedAE），而长短期记忆（LSTM）网络的MedAE为15.1%。Shapley可加解释（SHAP）值分析确定累积降雨量、历史有效载荷趋势和模拟故障频率是主要预测因子。模拟故障数据和班次规划特征的整合显著降低了预测波动性。未来的工作将进一步整合维护调度指标（平均故障间隔时间、平均修复时间）、详细的人力资源数据（操作员缺勤率、班组效率指标）、爆破事件调度和其他运营限制，以增强预测的鲁棒性和适应性。这种混合建模方法为在动态不确定条件下主动的、数据驱动的车队管理提供了一个全面的决策支持工具。", "summary": "本研究针对露天矿中运输车队产能预测面临的运营不确定性，提出了一种深度学习框架。该框架融合了真实运营数据和模拟故障场景，以提高预测的准确性和鲁棒性。研究评估了XGBoost和LSTM两种模型，并利用SHAP分析识别出关键预测因素。结果表明，该方法能有效降低预测波动性，为车队管理提供决策支持。", "keywords": "深度学习, 运输车队, 产能预测, 露天矿, 不确定性"}}
{"id": "2506.05346", "pdf": "https://arxiv.org/pdf/2506.05346", "abs": "https://arxiv.org/abs/2506.05346", "authors": ["Lei Hsiung", "Tianyu Pang", "Yung-Chen Tang", "Linyue Song", "Tsung-Yi Ho", "Pin-Yu Chen", "Yaoqing Yang"], "title": "Why LLM Safety Guardrails Collapse After Fine-tuning: A Similarity Analysis Between Alignment and Fine-tuning Datasets", "categories": ["cs.CR", "cs.CL", "cs.LG"], "comment": "Project Page: https://hsiung.cc/llm-similarity-risk/", "summary": "Recent advancements in large language models (LLMs) have underscored their\nvulnerability to safety alignment jailbreaks, particularly when subjected to\ndownstream fine-tuning. However, existing mitigation strategies primarily focus\non reactively addressing jailbreak incidents after safety guardrails have been\ncompromised, removing harmful gradients during fine-tuning, or continuously\nreinforcing safety alignment throughout fine-tuning. As such, they tend to\noverlook a critical upstream factor: the role of the original safety-alignment\ndata. This paper therefore investigates the degradation of safety guardrails\nthrough the lens of representation similarity between upstream alignment\ndatasets and downstream fine-tuning tasks. Our experiments demonstrate that\nhigh similarity between these datasets significantly weakens safety guardrails,\nmaking models more susceptible to jailbreaks. Conversely, low similarity\nbetween these two types of datasets yields substantially more robust models and\nthus reduces harmfulness score by up to 10.33%. By highlighting the importance\nof upstream dataset design in the building of durable safety guardrails and\nreducing real-world vulnerability to jailbreak attacks, these findings offer\nactionable insights for fine-tuning service providers.", "AI": {"title_translation": "为什么LLM安全护栏在微调后会崩溃：对齐与微调数据集之间的相似性分析", "tldr": "LLM安全护栏在微调后崩溃是因为上游对齐数据集与下游微调任务之间存在高相似性；低相似性则能显著增强模型鲁棒性。", "motivation": "现有缓解LLM安全护栏被攻破的策略主要集中在事后处理、微调期间移除有害梯度或持续强化安全对齐，但它们往往忽视了一个关键的上游因素：原始安全对齐数据的作用。因此，本文旨在通过分析上游对齐数据集和下游微调任务之间的表示相似性来研究安全护栏的退化问题。", "method": "本文通过分析上游对齐数据集和下游微调任务之间的表示相似性来研究安全护栏的退化。实验通过比较不同相似度数据集对模型安全性的影响来验证假设。", "result": "实验表明，上游对齐数据集与下游微调任务之间的高相似性会显著削弱安全护栏，使模型更容易受到越狱攻击。相反，这两种数据集之间的低相似性会产生更强大的模型，并将有害性评分降低高达10.33%。", "conclusion": "研究结果强调了上游数据集设计在构建持久安全护栏和减少现实世界越狱攻击脆弱性方面的重要性，为微调服务提供商提供了可行的见解。", "translation": "大型语言模型（LLMs）的最新进展凸显了它们在安全对齐越狱方面的脆弱性，尤其是在进行下游微调时。然而，现有的缓解策略主要集中于在安全护栏被攻破后被动处理越狱事件，在微调期间移除有害梯度，或在整个微调过程中持续强化安全对齐。因此，它们往往忽视了一个关键的上游因素：原始安全对齐数据的作用。本文因此从上游对齐数据集和下游微调任务之间的表示相似性的角度，研究了安全护栏的退化问题。我们的实验表明，这些数据集之间的高相似性会显著削弱安全护栏，使模型更容易受到越狱攻击。相反，这两种数据集之间的低相似性会产生显著更强大的模型，从而将有害性评分降低高达10.33%。通过强调上游数据集设计在构建持久安全护栏和减少现实世界越狱攻击脆弱性方面的重要性，这些发现为微调服务提供商提供了可行的见解。", "summary": "本研究探讨了大型语言模型（LLMs）安全护栏在微调后失效的原因，并指出现有缓解策略忽视了原始安全对齐数据的作用。通过分析上游对齐数据集与下游微调任务之间的表示相似性，研究发现高相似性会显著削弱安全护栏，增加模型被越狱的风险。相反，低相似性则能显著增强模型鲁棒性，有效降低有害性评分。这些发现为构建持久安全护栏和减少越狱攻击提供了重要指导。", "keywords": "LLM安全, 微调, 数据集相似性, 安全护栏, 越狱攻击"}}
{"id": "2506.04941", "pdf": "https://arxiv.org/pdf/2506.04941", "abs": "https://arxiv.org/abs/2506.04941", "authors": ["Zhao Jin", "Zhengping Che", "Zhen Zhao", "Kun Wu", "Yuheng Zhang", "Yinuo Zhao", "Zehui Liu", "Qiang Zhang", "Xiaozhu Ju", "Jing Tian", "Yousong Xue", "Jian Tang"], "title": "ArtVIP: Articulated Digital Assets of Visual Realism, Modular Interaction, and Physical Fidelity for Robot Learning", "categories": ["cs.RO"], "comment": null, "summary": "Robot learning increasingly relies on simulation to advance complex ability\nsuch as dexterous manipulations and precise interactions, necessitating\nhigh-quality digital assets to bridge the sim-to-real gap. However, existing\nopen-source articulated-object datasets for simulation are limited by\ninsufficient visual realism and low physical fidelity, which hinder their\nutility for training models mastering robotic tasks in real world. To address\nthese challenges, we introduce ArtVIP, a comprehensive open-source dataset\ncomprising high-quality digital-twin articulated objects, accompanied by\nindoor-scene assets. Crafted by professional 3D modelers adhering to unified\nstandards, ArtVIP ensures visual realism through precise geometric meshes and\nhigh-resolution textures, while physical fidelity is achieved via fine-tuned\ndynamic parameters. Meanwhile, the dataset pioneers embedded modular\ninteraction behaviors within assets and pixel-level affordance annotations.\nFeature-map visualization and optical motion capture are employed to\nquantitatively demonstrate ArtVIP 's visual and physical fidelity, with its\napplicability validated across imitation learning and reinforcement learning\nexperiments. Provided in USD format with detailed production guidelines, \\ours\nis fully open-source, benefiting the research community and advancing robot\nlearning research. Our project is at https://x-humanoid-artvip.github.io/", "AI": {"title_translation": "ArtVIP：用于机器人学习的视觉真实感、模块化交互和物理保真度的关节式数字资产", "tldr": "ArtVIP是一个高质量、开源的关节式数字资产数据集，具有高视觉真实感和物理保真度，并包含模块化交互行为和像素级可供性标注，旨在弥合机器人学习中的模拟与现实差距。", "motivation": "现有的开源关节式物体数据集在模拟中存在视觉真实感不足和物理保真度低的问题，这阻碍了它们在训练掌握现实世界机器人任务模型方面的效用。", "method": "引入ArtVIP数据集，它包含高质量的数字孪生关节式物体和室内场景资产。通过专业的3D建模师制作，确保精确的几何网格和高分辨率纹理实现视觉真实感，通过精细调整的动态参数实现物理保真度。数据集还嵌入了模块化交互行为和像素级可供性标注。使用特征图可视化和光学运动捕捉来量化展示ArtVIP的视觉和物理保真度。", "result": "特征图可视化和光学运动捕捉定量证明了ArtVIP的视觉和物理保真度。ArtVIP的适用性通过模仿学习和强化学习实验得到验证。", "conclusion": "ArtVIP数据集通过提供高视觉真实感、物理保真度、模块化交互行为和像素级可供性标注的关节式数字资产，有效弥合了机器人学习中的模拟与现实差距，并对研究社区做出了贡献。", "translation": "机器人学习越来越依赖模拟来提升复杂能力，例如灵巧操作和精确交互，这需要高质量的数字资产来弥合模拟与现实之间的差距。然而，现有用于模拟的开源关节式物体数据集受限于视觉真实感不足和物理保真度低，这阻碍了它们在训练掌握现实世界机器人任务模型方面的效用。为了应对这些挑战，我们引入了ArtVIP，一个全面的开源数据集，包含高质量的数字孪生关节式物体，并伴随室内场景资产。ArtVIP由专业的3D建模师按照统一标准制作，通过精确的几何网格和高分辨率纹理确保视觉真实感，同时通过精细调整的动态参数实现物理保真度。同时，该数据集开创性地在资产中嵌入了模块化交互行为和像素级可供性标注。通过特征图可视化和光学运动捕捉来定量展示ArtVIP的视觉和物理保真度，并通过模仿学习和强化学习实验验证了其适用性。ArtVIP以USD格式提供，并附有详细的制作指南，完全开源，造福研究社区并推动机器人学习研究。我们的项目网址是https://x-humanoid-artvip.github.io/", "summary": "ArtVIP是一个针对机器人学习需求推出的开源数据集，旨在解决现有模拟数据集中视觉真实感和物理保真度不足的问题。该数据集包含由专业3D建模师制作的高质量数字孪生关节式物体和室内场景资产，通过精确的几何网格、高分辨率纹理和精细调整的动态参数，确保了视觉真实感和物理保真度。此外，ArtVIP还首次嵌入了模块化交互行为和像素级可供性标注。通过特征图可视化和光学运动捕捉定量验证了其保真度，并通过模仿学习和强化学习实验验证了其在机器人任务中的适用性。ArtVIP以USD格式提供，并附有详细制作指南，致力于促进机器人学习研究。", "keywords": "机器人学习, 数字资产, 模拟到现实, 视觉真实感, 物理保真度"}}
{"id": "2506.04613", "pdf": "https://arxiv.org/pdf/2506.04613", "abs": "https://arxiv.org/abs/2506.04613", "authors": ["Li Liu", "Heng Yong"], "title": "DeePoly: A High-Order Accuracy and Efficiency Deep-Polynomial Framework for Scientific Machine Learning", "categories": ["cs.AI", "cs.LG"], "comment": "for associated mpeg file, see http://github.com/bfly123/DeePoly", "summary": "Recently, machine learning methods have gained significant traction in\nscientific computing, particularly for solving Partial Differential Equations\n(PDEs). However, methods based on deep neural networks (DNNs) often lack\nconvergence guarantees and computational efficiency compared to traditional\nnumerical schemes. This work introduces DeePoly, a novel framework that\ntransforms the solution paradigm from pure non-convex parameter optimization to\na two-stage approach: first employing a DNN to capture complex global features,\nfollowed by linear space optimization with combined DNN-extracted features\n(Scoper) and polynomial basis functions (Sniper). This strategic combination\nleverages the complementary strengths of both methods -- DNNs excel at\napproximating complex global features (i.e., high-gradient features) and\nstabilize the polynomial approximation while polynomial bases provide\nhigh-precision local corrections with convergence guarantees. Theoretical\nanalysis and numerical experiments demonstrate that this approach significantly\nenhances both high-order accuracy and efficiency across diverse problem types\nwhile maintaining mesh-free and scheme-free properties. This paper also serves\nas a theoretical exposition for the open-source project DeePoly.", "AI": {"title_translation": "DeePoly：一种用于科学机器学习的高阶精度与效率深度多项式框架", "tldr": "DeePoly结合深度神经网络和多项式基函数，显著提高了科学机器学习中求解偏微分方程的精度和效率。", "motivation": "现有的基于深度神经网络的科学机器学习方法在求解偏微分方程时，通常缺乏收敛性保证且计算效率不高。", "method": "DeePoly框架采用两阶段方法：首先使用深度神经网络捕获复杂的全局特征，然后结合DNN提取的特征和多项式基函数进行线性空间优化，以实现高精度局部校正。", "result": "理论分析和数值实验表明，DeePoly显著提高了高阶精度和效率，同时保持了无网格和无方案的特性。", "conclusion": "DeePoly通过结合深度神经网络和多项式基函数，有效解决了传统深度学习方法在科学计算中精度和效率不足的问题，提供了一种高性能的偏微分方程求解框架。", "translation": "近期，机器学习方法在科学计算领域，尤其是在求解偏微分方程（PDEs）方面获得了显著关注。然而，与传统数值方案相比，基于深度神经网络（DNNs）的方法通常缺乏收敛性保证和计算效率。本工作引入了DeePoly，一个新颖的框架，它将求解范式从纯非凸参数优化转变为两阶段方法：首先采用DNN捕获复杂的全局特征，随后结合DNN提取的特征（Scoper）和多项式基函数（Sniper）进行线性空间优化。这种策略性组合利用了两种方法的互补优势——DNN擅长近似复杂的全局特征（即高梯度特征）并稳定多项式近似，而多项式基函数提供具有收敛性保证的高精度局部校正。理论分析和数值实验表明，该方法在保持无网格和无方案特性的同时，显著提高了各种问题类型的高阶精度和效率。本文也作为开源项目DeePoly的理论阐述。", "summary": "本文介绍了DeePoly，一个用于科学机器学习的新型深度多项式框架。针对现有深度神经网络方法在求解偏微分方程时缺乏收敛性保证和计算效率低的问题，DeePoly提出两阶段方法：先用DNN捕获全局特征，再结合DNN特征和多项式基函数进行线性空间优化。该方法利用DNN擅长近似复杂特征和多项式基提供高精度局部校正的互补优势，显著提升了高阶精度和效率，并保持无网格和无方案特性。", "keywords": "科学机器学习, 深度学习, 偏微分方程, 多项式近似, 高精度"}}
{"id": "2506.04513", "pdf": "https://arxiv.org/pdf/2506.04513", "abs": "https://arxiv.org/abs/2506.04513", "authors": ["Gustavo Henrique do Nascimento", "Ian Pons", "Anna Helena Reali Costa", "Artur Jordao"], "title": "Pruning Everything, Everywhere, All at Once", "categories": ["cs.CV"], "comment": "To be published in International Joint Conference on Neural Networks\n  (IJCNN), 2025", "summary": "Deep learning stands as the modern paradigm for solving cognitive tasks.\nHowever, as the problem complexity increases, models grow deeper and\ncomputationally prohibitive, hindering advancements in real-world and\nresource-constrained applications. Extensive studies reveal that pruning\nstructures in these models efficiently reduces model complexity and improves\ncomputational efficiency. Successful strategies in this sphere include removing\nneurons (i.e., filters, heads) or layers, but not both together. Therefore,\nsimultaneously pruning different structures remains an open problem. To fill\nthis gap and leverage the benefits of eliminating neurons and layers at once,\nwe propose a new method capable of pruning different structures within a model\nas follows. Given two candidate subnetworks (pruned models), one from layer\npruning and the other from neuron pruning, our method decides which to choose\nby selecting the one with the highest representation similarity to its parent\n(the network that generates the subnetworks) using the Centered Kernel\nAlignment metric. Iteratively repeating this process provides highly sparse\nmodels that preserve the original predictive ability. Throughout extensive\nexperiments on standard architectures and benchmarks, we confirm the\neffectiveness of our approach and show that it outperforms state-of-the-art\nlayer and filter pruning techniques. At high levels of Floating Point\nOperations reduction, most state-of-the-art methods degrade accuracy, whereas\nour approach either improves it or experiences only a minimal drop. Notably, on\nthe popular ResNet56 and ResNet110, we achieve a milestone of 86.37% and 95.82%\nFLOPs reduction. Besides, our pruned models obtain robustness to adversarial\nand out-of-distribution samples and take an important step towards GreenAI,\nreducing carbon emissions by up to 83.31%. Overall, we believe our work opens a\nnew chapter in pruning.", "AI": {"title_translation": "《全面剪枝：无处不在，一次完成》", "tldr": "本文提出了一种新的剪枝方法，能够同时修剪深度学习模型中的神经元和层，在显著降低模型复杂度和计算量的同时，保持甚至提升预测精度和模型鲁棒性，并大幅减少碳排放。", "motivation": "深度学习模型随着问题复杂性增加而变得越来越深且计算成本高昂，这阻碍了其在实际和资源受限应用中的发展。现有的剪枝策略（如移除神经元或层）虽然有效，但不能同时进行，因此同时剪枝不同结构仍是一个未解决的问题。", "method": "为了同时利用消除神经元和层的优势，本文提出了一种新方法。该方法在给定两个候选子网络（一个来自层剪枝，一个来自神经元剪枝）时，通过使用中心核对齐（Centered Kernel Alignment, CKA）度量选择与父网络表示相似度最高的子网络。迭代重复此过程，可以获得高度稀疏的模型，同时保留原始的预测能力。", "result": "在标准架构和基准测试上的大量实验证实了该方法的有效性，并表明其优于最先进的层和滤波器剪枝技术。在浮点运算（FLOPs）大幅减少的情况下，大多数最先进的方法会降低精度，而本文方法要么提高精度，要么仅出现最小的下降。值得注意的是，在流行的ResNet56和ResNet110上，FLOPs分别达到了86.37%和95.82%的里程碑式削减。此外，剪枝后的模型对对抗性样本和OOD样本具有鲁棒性，并在GreenAI方面迈出了重要一步，碳排放量减少高达83.31%。", "conclusion": "本文的工作在剪枝领域开启了新篇章，提供了一种有效的方法来同时剪枝深度学习模型中的不同结构，从而在保持预测能力和鲁棒性的同时，显著提高了计算效率和减少了环境影响。", "translation": "深度学习是解决认知任务的现代范式。然而，随着问题复杂性的增加，模型变得更深且计算成本高昂，阻碍了其在实际和资源受限应用中的发展。大量研究表明，修剪这些模型中的结构可以有效降低模型复杂性并提高计算效率。该领域成功的策略包括移除神经元（即滤波器、头部）或层，但不能同时移除两者。因此，同时修剪不同结构仍然是一个开放问题。为了填补这一空白并利用同时消除神经元和层的优势，我们提出了一种能够同时修剪模型中不同结构的新方法。给定两个候选子网络（剪枝模型），一个来自层剪枝，另一个来自神经元剪枝，我们的方法通过使用中心核对齐（Centered Kernel Alignment）度量选择与父网络（生成子网络的网络）表示相似度最高的子网络来决定选择哪一个。迭代重复此过程可以提供高度稀疏的模型，同时保留原始的预测能力。通过对标准架构和基准测试的广泛实验，我们证实了我们方法的有效性，并表明它优于最先进的层和滤波器剪枝技术。在浮点运算（Floating Point Operations）高水平减少的情况下，大多数最先进的方法会降低精度，而我们的方法要么提高精度，要么仅经历最小的下降。值得注意的是，在流行的ResNet56和ResNet110上，我们实现了86.37%和95.82%的FLOPs削减里程碑。此外，我们剪枝后的模型对对抗性样本和分布外样本具有鲁棒性，并在GreenAI方面迈出了重要一步，碳排放量减少高达83.31%。总的来说，我们相信我们的工作在剪枝领域开启了新篇章。", "summary": "为了解决深度学习模型日益增长的计算成本和复杂性问题，本文提出了一种新颖的剪枝方法，能够同时对模型中的神经元和层进行剪枝。该方法通过迭代地选择与原始网络表示相似度最高的子网络（利用中心核对齐度量），实现了高度稀疏的模型，同时保持了原始的预测能力。实验结果表明，该方法在大幅减少模型计算量（如ResNet56和ResNet110上FLOPs分别减少86.37%和95.82%）的同时，性能优于现有最先进的剪枝技术，甚至在某些情况下还能提升精度，并增强了模型对对抗性攻击和分布外样本的鲁棒性，同时显著降低了碳排放（高达83.31%）。", "keywords": "剪枝, 模型压缩, 深度学习, 计算效率, 绿色AI"}}
{"id": "2506.04297", "pdf": "https://arxiv.org/pdf/2506.04297", "abs": "https://arxiv.org/abs/2506.04297", "authors": ["Abdourrahmane Mahamane Atto"], "title": "Softlog-Softmax Layers and Divergences Contribute to a Computationally Dependable Ensemble Learning", "categories": ["cs.LG"], "comment": null, "summary": "The paper proposes a 4-step process for highlighting that softlog-softmax\ncascades can improve both consistency and dependability of the next generation\nensemble learning systems. The first process is anatomical in nature: the\ntarget ensemble model under consideration is composed by canonical elements\nrelating to the definition of a convolutional frustum. No a priori is\nconsidered in the choice of canonical forms. Diversity is the main criterion\nfor selecting these forms. It is shown that the more complex the problem, the\nmore useful this ensemble diversity is. The second process is physiological and\nrelates to neural engineering: a softlog is derived to both make weak\nlogarithmic operations consistent and lead, through multiple softlog-softmax\nlayers, to intermediate decisions in the sense of respecting the same class\nlogic as that faced by the output layer. The third process concerns neural\ninformation theory: softlog-based entropy and divergence are proposed for the\nsake of constructing information measures yielding consistent values on closed\nintervals. These information measures are used to determine the relationships\nbetween individual and sub-community decisions in frustum diversitybased\nensemble learning. The concluding process addresses the derivation of an\ninformative performance tensor for the purpose of a reliable ensemble\nevaluation.", "AI": {"title_translation": "Softlog-Softmax层和散度有助于计算可靠的集成学习", "tldr": "本文提出了一个四步过程，通过引入softlog-softmax层和散度，旨在提高下一代集成学习系统的计算可靠性和一致性。", "motivation": "提高下一代集成学习系统的一致性和可靠性。", "method": "本文提出了一个四步过程：1. 解剖学：通过多样性选择卷积截锥体的规范元素构建目标集成模型。2. 生理学：推导softlog以使弱对数操作一致，并通过多层softlog-softmax实现中间决策，保持与输出层相同的类逻辑。3. 神经信息论：提出基于softlog的熵和散度，构建在闭区间上产生一致值的信息度量，用于确定集成学习中个体和子群体决策之间的关系。4. 结论：推导信息性能张量，用于可靠的集成评估。", "result": "结果表明，softlog-softmax级联可以提高下一代集成学习系统的一致性和可靠性；问题越复杂，集成多样性越有用。", "conclusion": "通过引入softlog-softmax层和散度，本文提出的方法旨在提升集成学习系统的计算可靠性和一致性。", "translation": "本文提出了一个四步过程，旨在突出softlog-softmax级联如何提高下一代集成学习系统的一致性和可靠性。第一个过程本质上是解剖学的：所考虑的目标集成模型由与卷积截锥体定义相关的规范元素组成。在规范形式的选择中不考虑先验。多样性是选择这些形式的主要标准。结果表明，问题越复杂，这种集成多样性越有用。第二个过程是生理学的，与神经工程学相关：推导出softlog，既可以使弱对数操作保持一致，又可以通过多个softlog-softmax层，在尊重与输出层相同的类逻辑的意义上，实现中间决策。第三个过程涉及神经信息论：提出了基于softlog的熵和散度，以便构建在闭区间上产生一致值的信息度量。这些信息度量用于确定基于截锥体多样性的集成学习中个体和子群体决策之间的关系。最后一个过程解决了信息性能张量的推导，目的是为了可靠的集成评估。", "summary": "本文提出一个四步过程，旨在通过引入softlog-softmax级联来提高下一代集成学习系统的一致性和可靠性。该过程包括构建基于多样性的集成模型、利用softlog-softmax层进行一致的中间决策、提出基于softlog的熵和散度进行信息度量，以及推导性能张量进行可靠评估。研究表明，该方法有助于提升复杂问题的集成学习效果。", "keywords": "集成学习, softlog-softmax, 散度, 可靠性, 一致性"}}
{"id": "2506.03614", "pdf": "https://arxiv.org/pdf/2506.03614", "abs": "https://arxiv.org/abs/2506.03614", "authors": ["Zhanhui Zhou", "Lingjie Chen", "Chao Yang", "Chaochao Lu"], "title": "VLMs Can Aggregate Scattered Training Patches", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.CR"], "comment": null, "summary": "One way to mitigate risks in vision-language models (VLMs) is to remove\ndangerous samples in their training data. However, such data moderation can be\neasily bypassed when harmful images are split into small, benign-looking\npatches, scattered across many training samples. VLMs may then learn to piece\nthese fragments together during training and generate harmful responses at\ninference, either from full images or text references. For instance, if trained\non image patches from a bloody scene paired with the descriptions \"safe,\" VLMs\nmay later describe, the full image or a text reference to the scene, as \"safe.\"\nWe define the core ability of VLMs enabling this attack as $\\textit{visual\nstitching}$ -- the ability to integrate visual information spread across\nmultiple training samples that share the same textual descriptions. In our\nwork, we first demonstrate visual stitching abilities in common open-source\nVLMs on three datasets where each image is labeled with a unique synthetic ID:\nwe split each $(\\texttt{image}, \\texttt{ID})$ pair into $\\{(\\texttt{patch},\n\\texttt{ID})\\}$ pairs at different granularity for finetuning, and we find that\ntuned models can verbalize the correct IDs from full images or text reference.\nBuilding on this, we simulate the adversarial data poisoning scenario mentioned\nabove by using patches from dangerous images and replacing IDs with text\ndescriptions like ``safe'' or ``unsafe'', demonstrating how harmful content can\nevade moderation in patches and later be reconstructed through visual\nstitching, posing serious VLM safety risks. Code is available at\nhttps://github.com/ZHZisZZ/visual-stitching.", "AI": {"title_translation": "视觉语言模型能够聚合分散的训练图像块", "tldr": "视觉语言模型（VLMs）能够将分散在训练数据中的图像块“拼接”起来，即使单个图像块看似无害，这可能导致模型在推理时从完整图像或文本引用中生成有害内容，从而带来严重的安全风险。", "motivation": "为了解决视觉语言模型（VLMs）中存在的漏洞，即传统数据审核方法可能被绕过。当有害图像被分割成看似无害的图像块并分散在训练数据中时，VLMs仍能在训练过程中将这些碎片重新组合（即“视觉拼接”），从而在推理时生成有害响应。", "method": "本文定义了“视觉拼接”能力，即VLM整合跨多个共享相同文本描述的训练样本中分散视觉信息的能力。研究人员首先在三个数据集上验证了常见开源VLMs的视觉拼接能力，通过将（图像，ID）对分割成不同粒度的（图像块，ID）对进行微调，并发现模型能从完整图像或文本引用中正确识别ID。在此基础上，他们模拟了对抗性数据投毒场景，使用危险图像的图像块并替换ID为“安全”或“不安全”等描述，以此证明有害内容如何规避审核并通过视觉拼接被重建。", "result": "研究结果表明，常见的开源视觉语言模型确实具备视觉拼接能力。他们成功展示了有害内容如何通过分割成图像块来规避数据审核，并随后通过视觉拼接被重建，从而对视觉语言模型构成了严重的安全风险。", "conclusion": "视觉拼接是视觉语言模型（VLMs）的一个显著漏洞，它允许有害内容绕过数据审核机制，可能导致模型生成危险响应，对VLM的安全性构成严重威胁。", "translation": "缓解视觉语言模型（VLM）风险的一种方法是删除训练数据中的危险样本。然而，当有害图像被分割成许多看似无害的小块，并分散在多个训练样本中时，这种数据审核很容易被绕过。VLM可能在训练过程中学习将这些碎片拼接起来，并在推理时从完整图像或文本引用中生成有害响应。例如，如果模型在血腥场景的图像块与“安全”描述配对的情况下进行训练，VLM之后可能会将完整图像或对该场景的文本引用描述为“安全”。我们将VLM实现这种攻击的核心能力定义为$\\textit{视觉拼接}$——即整合跨多个共享相同文本描述的训练样本中分散的视觉信息的能力。在我们的工作中，我们首先在三个数据集中展示了常见开源VLM的视觉拼接能力，这些数据集中每张图像都标有唯一的合成ID：我们将每个$(\\texttt{图像}, \\\\texttt{ID})$对分割成不同粒度的$\\{(\\texttt{图像块}, \\\\texttt{ID})\\}$对进行微调，发现经过微调的模型能够从完整图像或文本引用中正确地口述出ID。在此基础上，我们通过使用危险图像的图像块并用“安全”或“不安全”等文本描述替换ID，模拟了上述对抗性数据投毒场景，展示了有害内容如何以图像块的形式规避审核，随后通过视觉拼接被重建，从而构成严重的VLM安全风险。代码可在https://github.com/ZHZisZZ/visual-stitching获取。", "summary": "本文揭示了视觉语言模型（VLMs）中一种名为“视觉拼接”的新漏洞，即模型能够聚合分散在多个训练样本中的图像块。研究表明，即使有害图像被分割成看似无害的补丁，VLMs也能在训练过程中将其重新组合，并在推理时生成有害内容，从而规避传统的数据审核。这对于VLMs的安全性构成了严重威胁。", "keywords": "视觉拼接, VLM安全, 数据投毒, 图像块, 审核规避"}}
{"id": "2506.04942", "pdf": "https://arxiv.org/pdf/2506.04942", "abs": "https://arxiv.org/abs/2506.04942", "authors": ["Jieyu Wang", "Yingzhong Tian", "Fengfeng Xi", "Damien Chablat", "Jianing Lin", "Gaoke Ren", "Yinjun Zhao"], "title": "A Pillbug-Inspired Morphing Mechanism Covered with Sliding Shells", "categories": ["cs.RO"], "comment": null, "summary": "This research proposes a novel morphing structure with shells inspired by the\nmovement of pillbugs. Instead of the pillbug body, a loopcoupled mechanism\nbased on slider-crank mechanisms is utilized to achieve the rolling up and\nspreading motion. This mechanism precisely imitates three distinct curves that\nmimic the shape morphing of a pillbug. To decrease the degree-of-freedom (DOF)\nof the mechanism to one, scissor mechanisms are added. 3D curved shells are\nthen attached to the tracer points of the morphing mechanism to safeguard it\nfrom attacks while allowing it to roll. Through type and dimensional synthesis,\na complete system that includes shells and an underlying morphing mechanism is\ndeveloped. A 3D model is created and tested to demonstrate the proposed\nsystem's shape-changing capability. Lastly, a robot with two modes is developed\nbased on the proposed mechanism, which can curl up to roll down hills and can\nspread to move in a straight line via wheels.", "AI": {"title_translation": "受潮虫启发的带滑动外壳的变形机构", "tldr": "受潮虫启发，开发了一种带滑动外壳的新型变形机构，可实现卷曲和展开，并应用于机器人。", "motivation": "受潮虫运动的启发，研究旨在开发一种新型的变形结构，以模仿潮虫的形态变化，并能保护内部机构。", "method": "利用基于滑块曲柄机构的环形耦合机构实现卷曲和展开运动，通过增加剪刀机构将自由度降至一。将3D曲面外壳连接到变形机构的示踪点上。通过类型和尺寸综合，开发了包含外壳和底层变形机构的完整系统。创建并测试了3D模型，并基于此机制开发了一个具有两种模式的机器人。", "result": "该机构精确模仿了潮虫的三种不同曲线形态变化，成功将机构自由度降至一。开发了一个包含外壳和底层变形机构的完整系统，并验证了其形状变化能力。最终开发出一种可在卷曲模式下滚下山坡并在展开模式下通过轮子直线移动的机器人。", "conclusion": "基于潮虫启发的变形机构，开发出一种具有两种运动模式的机器人，能够实现卷曲滚动和展开直线移动，展示了其在仿生机器人领域的潜力。", "translation": "这项研究提出了一种受潮虫运动启发的带有外壳的新型变形结构。该结构利用基于滑块曲柄机构的环形耦合机制来实现卷曲和展开运动，而非模仿潮虫身体。该机制精确模仿了潮虫形状变形的三种不同曲线。为了将机构的自由度（DOF）降低到一，增加了剪刀机构。然后将3D曲面外壳连接到变形机构的示踪点上，以在允许其滚动的同时保护其免受攻击。通过类型和尺寸综合，开发了一个包含外壳和底层变形机构的完整系统。创建并测试了一个3D模型以展示所提出系统的形状变化能力。最后，基于所提出的机制开发了一个具有两种模式的机器人，它可以在卷曲时滚下山坡，并在展开时通过轮子直线移动。", "summary": "本研究提出了一种受潮虫运动启发的带滑动外壳的新型变形结构。该结构利用环形耦合的滑块曲柄机构实现卷曲和展开，通过剪刀机构将自由度降至一，并附着3D曲面外壳提供保护。通过系统开发和3D模型测试，验证了其形状变化能力。最终，基于此机构开发出一种双模式机器人，可实现卷曲滚动和展开直线移动。", "keywords": "潮虫启发, 变形机构, 滑动外壳, 仿生机器人, 自由度降低"}}
{"id": "2506.04614", "pdf": "https://arxiv.org/pdf/2506.04614", "abs": "https://arxiv.org/abs/2506.04614", "authors": ["Yuyang Wanyan", "Xi Zhang", "Haiyang Xu", "Haowei Liu", "Junyang Wang", "Jiabo Ye", "Yutong Kou", "Ming Yan", "Fei Huang", "Xiaoshan Yang", "Weiming Dong", "Changsheng Xu"], "title": "Look Before You Leap: A GUI-Critic-R1 Model for Pre-Operative Error Diagnosis in GUI Automation", "categories": ["cs.AI"], "comment": null, "summary": "In recent years, Multimodal Large Language Models (MLLMs) have been\nextensively utilized for multimodal reasoning tasks, including Graphical User\nInterface (GUI) automation. Unlike general offline multimodal tasks, GUI\nautomation is executed in online interactive environments, necessitating\nstep-by-step decision-making based on real-time status of the environment. This\ntask has a lower tolerance for decision-making errors at each step, as any\nmistakes may cumulatively disrupt the process and potentially lead to\nirreversible outcomes like deletions or payments. To address these issues, we\nintroduce a pre-operative critic mechanism that provides effective feedback\nprior to the actual execution, by reasoning about the potential outcome and\ncorrectness of actions. Specifically, we propose a Suggestion-aware Gradient\nRelative Policy Optimization (S-GRPO) strategy to construct our pre-operative\ncritic model GUI-Critic-R1, incorporating a novel suggestion reward to enhance\nthe reliability of the model's feedback. Furthermore, we develop a\nreasoning-bootstrapping based data collection pipeline to create a\nGUI-Critic-Train and a GUI-Critic-Test, filling existing gaps in GUI critic\ndata. Static experiments on the GUI-Critic-Test across both mobile and web\ndomains reveal that our GUI-Critic-R1 offers significant advantages in critic\naccuracy compared to current MLLMs. Dynamic evaluation on GUI automation\nbenchmark further highlights the effectiveness and superiority of our model, as\nevidenced by improved success rates and operational efficiency.", "AI": {"title_translation": "三思而后行：用于GUI自动化术前错误诊断的GUI-Critic-R1模型", "tldr": "GUI-Critic-R1是一个术前评论模型，通过在执行前诊断错误来改进GUI自动化，显著提高了准确性和操作效率。", "motivation": "在在线交互环境中，GUI自动化需要低容错的逐步决策，任何错误都可能累积并导致不可逆转的结果。现有的多模态大语言模型（MLLM）在此方面存在局限性。", "method": "引入了一种术前评论机制，通过推理潜在结果和动作的正确性，在实际执行前提供有效反馈。具体提出了建议感知梯度相对策略优化（S-GRPO）策略来构建GUI-Critic-R1模型，并融入了新颖的建议奖励以增强模型反馈的可靠性。同时，开发了基于推理自举的数据收集管道，创建了GUI-Critic-Train和GUI-Critic-Test数据集。", "result": "在GUI-Critic-Test数据集（涵盖移动和网络领域）上的静态实验表明，GUI-Critic-R1在评论准确性方面比当前的多模态大语言模型具有显著优势。在GUI自动化基准上的动态评估进一步突出显示了该模型的有效性和优越性，成功率和操作效率均得到提高。", "conclusion": "所提出的GUI-Critic-R1模型通过提供术前反馈，有效解决了GUI自动化中的决策错误问题，从而显著提高了自动化任务的准确性和操作效率。", "translation": "近年来，多模态大语言模型（MLLM）已被广泛用于多模态推理任务，包括图形用户界面（GUI）自动化。与一般的离线多模态任务不同，GUI自动化是在在线交互环境中执行的，需要根据环境的实时状态进行逐步决策。此任务对每一步的决策错误容忍度较低，因为任何错误都可能累积性地扰乱整个过程，并可能导致不可逆转的结果，例如删除或支付。为了解决这些问题，我们引入了一种术前评论机制，通过推理动作的潜在结果和正确性，在实际执行前提供有效反馈。具体来说，我们提出了一种建议感知梯度相对策略优化（S-GRPO）策略来构建我们的术前评论模型GUI-Critic-R1，其中包含一种新颖的建议奖励，以提高模型反馈的可靠性。此外，我们开发了一个基于推理自举的数据收集管道，创建了GUI-Critic-Train和GUI-Critic-Test，填补了GUI评论数据中现有的空白。在移动和网络领域对GUI-Critic-Test进行的静态实验表明，与当前的MLLM相比，我们的GUI-Critic-R1在评论准确性方面具有显著优势。在GUI自动化基准上的动态评估进一步突出了我们模型的有效性和优越性，这体现在成功率和操作效率的提高上。", "summary": "本文提出了GUI-Critic-R1，一个用于在GUI自动化实际执行前诊断潜在错误的术前评论模型。该模型采用建议感知梯度相对策略优化（S-GRPO）策略和新颖的建议奖励，并通过基于推理自举的数据收集管道构建了专门的数据集。实验结果表明，GUI-Critic-R1在错误诊断准确性方面优于现有MLLM，并在GUI自动化任务中显著提高了成功率和操作效率。", "keywords": "GUI自动化, 术前评论, 错误诊断, MLLM, S-GRPO"}}
{"id": "2506.04526", "pdf": "https://arxiv.org/pdf/2506.04526", "abs": "https://arxiv.org/abs/2506.04526", "authors": ["Shuo Zhang"], "title": "EECD-Net: Energy-Efficient Crack Detection with Spiking Neural Networks and Gated Attention", "categories": ["cs.CV"], "comment": null, "summary": "Crack detection on road surfaces is a critical measurement technology in the\ninstrumentation domain, essential for ensuring infrastructure safety and\ntransportation reliability. However, due to limited energy and low-resolution\nimaging, smart terminal devices struggle to maintain real-time monitoring\nperformance. To overcome these challenges, this paper proposes a multi-stage\ndetection approach for road crack detection, EECD-Net, to enhance accuracy and\nenergy efficiency of instrumentation. Specifically, the sophisticated\nSuper-Resolution Convolutional Neural Network (SRCNN) is employed to address\nthe inherent challenges of low-quality images, which effectively enhance image\nresolution while preserving critical structural details. Meanwhile, a Spike\nConvolution Unit (SCU) with Continuous Integrate-and-Fire (CIF) neurons is\nproposed to convert these images into sparse pulse sequences, significantly\nreducing power consumption. Additionally, a Gated Attention Transformer (GAT)\nmodule is designed to strategically fuse multi-scale feature representations\nthrough adaptive attention mechanisms, effectively capturing both long-range\ndependencies and intricate local crack patterns, and significantly enhancing\ndetection robustness across varying crack morphologies. The experiments on the\nCrackVision12K benchmark demonstrate that EECD-Net achieves a remarkable 98.6\\%\ndetection accuracy, surpassing state-of-the-art counterparts such as\nHybrid-Segmentor by a significant 1.5\\%. Notably, the EECD-Net maintains\nexceptional energy efficiency, consuming merely 5.6 mJ, which is a substantial\n33\\% reduction compared to baseline implementations. This work pioneers a\ntransformative approach in instrumentation-based crack detection, offering a\nscalable, low-power solution for real-time, large-scale infrastructure\nmonitoring in resource-constrained environments.", "AI": {"title_translation": "EECD-Net：基于脉冲神经网络和门控注意力的节能裂缝检测", "tldr": "EECD-Net提出了一种多阶段检测方法，结合脉冲神经网络和门控注意力，实现了高精度、低能耗的路面裂缝检测。", "motivation": "路面裂缝检测对于基础设施安全和交通可靠性至关重要，但智能终端设备由于能量有限和图像分辨率低，难以维持实时监测性能。", "method": "本文提出了一种多阶段路面裂缝检测方法EECD-Net。该方法利用超分辨率卷积神经网络（SRCNN）处理低质量图像，提高图像分辨率；采用具有连续积分-放电（CIF）神经元的脉冲卷积单元（SCU）将图像转换为稀疏脉冲序列，显著降低功耗；设计门控注意力Transformer（GAT）模块，通过自适应注意力机制融合多尺度特征表示，捕捉长距离依赖和局部裂缝模式。", "result": "在CrackVision12K基准测试中，EECD-Net实现了98.6%的检测精度，比Hybrid-Segmentor高出1.5%。能耗仅为5.6 mJ，比基线实现降低了33%。", "conclusion": "EECD-Net为基于仪器的裂缝检测提供了一种变革性方法，为资源受限环境下的实时、大规模基础设施监控提供了可扩展、低功耗的解决方案。", "translation": "路面裂缝检测是仪器仪表领域一项关键的测量技术，对于确保基础设施安全和交通可靠性至关重要。然而，由于能量有限和低分辨率成像，智能终端设备难以维持实时监测性能。为了克服这些挑战，本文提出了一种用于路面裂缝检测的多阶段检测方法EECD-Net，以提高仪器仪表的精度和能效。具体而言，采用复杂的超分辨率卷积神经网络（SRCNN）来解决低质量图像固有的挑战，有效提高图像分辨率，同时保留关键的结构细节。同时，提出了一种带有连续积分-放电（CIF）神经元的脉冲卷积单元（SCU），将这些图像转换为稀疏脉冲序列，显著降低功耗。此外，设计了一个门控注意力Transformer（GAT）模块，通过自适应注意力机制策略性地融合多尺度特征表示，有效捕捉长距离依赖和复杂的局部裂缝模式，并显著提高不同裂缝形态下的检测鲁棒性。在CrackVision12K基准测试上的实验表明，EECD-Net实现了98.6%的显著检测精度，比最先进的Hybrid-Segmentor高出1.5%。值得注意的是，EECD-Net保持了卓越的能源效率，仅消耗5.6 mJ，与基线实现相比大幅降低了33%。这项工作开创了基于仪器的裂缝检测的变革性方法，为资源受限环境中的实时、大规模基础设施监控提供了可扩展、低功耗的解决方案。", "summary": "本研究提出EECD-Net，一种结合超分辨率、脉冲神经网络和门控注意力机制的多阶段裂缝检测方法，旨在解决智能终端设备在路面裂缝检测中面临的能耗和低分辨率图像挑战。实验结果表明，EECD-Net在检测精度和能效方面均表现出色，为资源受限环境下的基础设施监控提供了高效解决方案。", "keywords": "裂缝检测, 脉冲神经网络, 门控注意力, 能源效率, 超分辨率"}}
{"id": "2506.04681", "pdf": "https://arxiv.org/pdf/2506.04681", "abs": "https://arxiv.org/abs/2506.04681", "authors": ["Daogao Liu", "Edith Cohen", "Badih Ghazi", "Peter Kairouz", "Pritish Kamath", "Alexander Knop", "Ravi Kumar", "Pasin Manurangsi", "Adam Sealfon", "Da Yu", "Chiyuan Zhang"], "title": "Urania: Differentially Private Insights into AI Use", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR", "cs.CY"], "comment": null, "summary": "We introduce $Urania$, a novel framework for generating insights about LLM\nchatbot interactions with rigorous differential privacy (DP) guarantees. The\nframework employs a private clustering mechanism and innovative keyword\nextraction methods, including frequency-based, TF-IDF-based, and LLM-guided\napproaches. By leveraging DP tools such as clustering, partition selection, and\nhistogram-based summarization, $Urania$ provides end-to-end privacy protection.\nOur evaluation assesses lexical and semantic content preservation, pair\nsimilarity, and LLM-based metrics, benchmarking against a non-private\nClio-inspired pipeline (Tamkin et al., 2024). Moreover, we develop a simple\nempirical privacy evaluation that demonstrates the enhanced robustness of our\nDP pipeline. The results show the framework's ability to extract meaningful\nconversational insights while maintaining stringent user privacy, effectively\nbalancing data utility with privacy preservation.", "AI": {"title_translation": "Urania：对AI使用进行差分隐私洞察", "tldr": "Urania是一个新颖的框架，它使用差分隐私技术从LLM聊天机器人交互中生成洞察，旨在平衡数据效用和用户隐私。", "motivation": "在LLM聊天机器人交互中，需要在获取有价值的洞察的同时，严格保护用户隐私，因此需要一个能提供严格差分隐私保证的框架。", "method": "Urania框架采用私有聚类机制和创新的关键词提取方法（包括基于频率、TF-IDF和LLM引导的方法）。它利用差分隐私工具如聚类、分区选择和基于直方图的汇总，提供端到端隐私保护。通过评估词汇和语义内容保留、对相似性以及基于LLM的指标，并与非隐私Clio-inspired管道进行基准测试，同时开发了简单的经验隐私评估。", "result": "评估结果表明，该框架能够在保持严格用户隐私的同时提取有意义的对话洞察。经验隐私评估也证明了其差分隐私管道增强的鲁棒性。", "conclusion": "Urania框架成功地在从LLM聊天机器人交互中提取有意义的洞察和保持严格用户隐私之间取得了有效的平衡。", "translation": "我们引入了Urania，这是一个新颖的框架，用于生成关于LLM聊天机器人交互的洞察，并提供严格的差分隐私（DP）保证。该框架采用了私有聚类机制和创新的关键词提取方法，包括基于频率的、基于TF-IDF的以及LLM引导的方法。通过利用DP工具，如聚类、分区选择和基于直方图的汇总，Urania提供了端到端的隐私保护。我们的评估衡量了词汇和语义内容保留、对相似性以及基于LLM的指标，并与非隐私的Clio启发式管道（Tamkin et al., 2024）进行了基准测试。此外，我们开发了一个简单的经验隐私评估，证明了我们DP管道增强的鲁棒性。结果表明，该框架能够在保持严格用户隐私的同时提取有意义的对话洞察，有效地平衡了数据效用与隐私保护。", "summary": "Urania是一个新颖的框架，旨在通过严格的差分隐私保证，从大型语言模型（LLM）聊天机器人交互中生成洞察。它结合了私有聚类机制和多种关键词提取方法，并利用差分隐私工具实现端到端隐私保护。通过评估和与现有管道的基准测试，Urania展示了其在提取有价值对话洞察的同时，有效平衡数据效用与用户隐私的能力。", "keywords": "差分隐私, LLM, 聊天机器人, 数据效用, 隐私保护"}}
{"id": "2506.04462", "pdf": "https://arxiv.org/pdf/2506.04462", "abs": "https://arxiv.org/abs/2506.04462", "authors": ["Apurv Verma", "NhatHai Phan", "Shubhendu Trivedi"], "title": "Watermarking Degrades Alignment in Language Models: Analysis and Mitigation", "categories": ["cs.CL", "cs.CR", "cs.LG", "I.2.7"], "comment": "Published at the 1st Workshop on GenAI Watermarking, collocated with\n  ICLR 2025. OpenReview: https://openreview.net/forum?id=SIBkIV48gF", "summary": "Watermarking techniques for large language models (LLMs) can significantly\nimpact output quality, yet their effects on truthfulness, safety, and\nhelpfulness remain critically underexamined. This paper presents a systematic\nanalysis of how two popular watermarking approaches-Gumbel and KGW-affect these\ncore alignment properties across four aligned LLMs. Our experiments reveal two\ndistinct degradation patterns: guard attenuation, where enhanced helpfulness\nundermines model safety, and guard amplification, where excessive caution\nreduces model helpfulness. These patterns emerge from watermark-induced shifts\nin token distribution, surfacing the fundamental tension that exists between\nalignment objectives.\n  To mitigate these degradations, we propose Alignment Resampling (AR), an\ninference-time sampling method that uses an external reward model to restore\nalignment. We establish a theoretical lower bound on the improvement in\nexpected reward score as the sample size is increased and empirically\ndemonstrate that sampling just 2-4 watermarked generations effectively recovers\nor surpasses baseline (unwatermarked) alignment scores. To overcome the limited\nresponse diversity of standard Gumbel watermarking, our modified implementation\nsacrifices strict distortion-freeness while maintaining robust detectability,\nensuring compatibility with AR. Experimental results confirm that AR\nsuccessfully recovers baseline alignment in both watermarking approaches, while\nmaintaining strong watermark detectability. This work reveals the critical\nbalance between watermark strength and model alignment, providing a simple\ninference-time solution to responsibly deploy watermarked LLMs in practice.", "AI": {"title_translation": "水印技术降低了语言模型的对齐性：分析与缓解", "tldr": "水印技术会损害LLM的对齐性，表现为帮助性与安全性之间的紧张关系；提出Alignment Resampling方法可有效恢复对齐性并保持水印可检测性。", "motivation": "现有研究对大型语言模型（LLMs）水印技术如何影响其真实性、安全性及帮助性等核心对齐属性的检查严重不足。", "method": "本文系统分析了两种流行的水印方法（Gumbel和KGW）如何影响四种已对齐LLM的核心对齐属性。为缓解水印导致的对齐退化，提出了一种推理时采样方法——Alignment Resampling (AR)，该方法利用外部奖励模型恢复对齐性。同时，修改了Gumbel水印的实现，牺牲严格的无失真性以确保与AR的兼容性。", "result": "实验揭示了水印技术导致两种不同的对齐退化模式：“防护衰减”（增强的帮助性损害模型安全性）和“防护放大”（过度谨慎降低模型帮助性），这源于水印引起的token分布变化，揭示了对齐目标之间存在的根本张力。理论上，Alignment Resampling (AR) 能够提高预期奖励分数。经验证明，仅采样2-4个带水印的生成内容即可有效恢复或超越基线（无水印）对齐分数。AR成功恢复了两种水印方法中的基线对齐性，同时保持了强大的水印可检测性。", "conclusion": "水印强度与模型对齐之间存在关键平衡。Alignment Resampling (AR) 提供了一种简单且实用的推理时解决方案，使得在实践中可以负责任地部署带水印的LLM。", "translation": "大型语言模型（LLMs）的水印技术会显著影响输出质量，但其对真实性、安全性和帮助性的影响仍严重缺乏研究。本文系统分析了两种流行的水印方法——Gumbel和KGW——如何影响四种已对齐LLM的这些核心对齐属性。我们的实验揭示了两种不同的退化模式：防护衰减，即增强的帮助性损害模型安全性；以及防护放大，即过度谨慎降低模型帮助性。这些模式源于水印引起的token分布变化，揭示了对齐目标之间存在的根本张力。\n为了缓解这些退化，我们提出了对齐重采样（AR），这是一种推理时采样方法，它使用外部奖励模型来恢复对齐。我们建立了随着样本量增加预期奖励分数改善的理论下限，并经验证明，仅采样2-4个带水印的生成内容即可有效恢复或超越基线（无水印）对齐分数。为了克服标准Gumbel水印有限的响应多样性，我们修改后的实现牺牲了严格的无失真性，同时保持了强大的可检测性，确保了与AR的兼容性。实验结果证实，AR在两种水印方法中都成功恢复了基线对齐，同时保持了强大的水印可检测性。这项工作揭示了水印强度和模型对齐之间的关键平衡，提供了一种简单的推理时解决方案，以在实践中负责任地部署带水印的LLM。", "summary": "本文系统分析了两种流行的水印技术（Gumbel和KGW）对大型语言模型（LLMs）对齐属性（真实性、安全性、帮助性）的影响，揭示了水印如何导致“防护衰减”和“防护放大”两种退化模式，这反映了对齐目标之间的内在冲突。为缓解这些问题，研究提出了一种推理时采样方法——Alignment Resampling (AR)，该方法利用外部奖励模型恢复对齐性。实验结果表明，AR能够有效恢复带水印LLM的基线对齐性能，并同时保持水印的可检测性，为实际部署带水印的LLM提供了负责任的解决方案。", "keywords": "Watermarking, Language Models, Alignment, Degradation, Mitigation"}}
{"id": "2506.04982", "pdf": "https://arxiv.org/pdf/2506.04982", "abs": "https://arxiv.org/abs/2506.04982", "authors": ["Yunlong Dong", "Xing Liu", "Jun Wan", "Zelin Deng"], "title": "GEX: Democratizing Dexterity with Fully-Actuated Dexterous Hand and Exoskeleton Glove", "categories": ["cs.RO"], "comment": null, "summary": "This paper introduces GEX, an innovative low-cost dexterous manipulation\nsystem that combines the GX11 tri-finger anthropomorphic hand (11 DoF) with the\nEX12 tri-finger exoskeleton glove (12 DoF), forming a closed-loop teleoperation\nframework through kinematic retargeting for high-fidelity control. Both\ncomponents employ modular 3D-printed finger designs, achieving ultra-low\nmanufacturing costs while maintaining full actuation capabilities. Departing\nfrom conventional tendon-driven or underactuated approaches, our\nelectromechanical system integrates independent joint motors across all 23 DoF,\nensuring complete state observability and accurate kinematic modeling. This\nfull-actuation architecture enables precise bidirectional kinematic\ncalculations, substantially enhancing kinematic retargeting fidelity between\nthe exoskeleton and robotic hand. The proposed system bridges the\ncost-performance gap in dexterous manipulation research, providing an\naccessible platform for acquiring high-quality demonstration data to advance\nembodied AI and dexterous robotic skill transfer learning.", "AI": {"title_translation": "GEX：通过全驱动灵巧手和外骨骼手套实现灵巧操作的民主化", "tldr": "GEX是一个低成本的全驱动灵巧操作系统，结合了灵巧手和外骨骼手套，通过运动学重定向实现高保真远程操作，旨在降低灵巧操作研究的成本并推进具身AI。", "motivation": "传统的灵巧操作系统成本高昂，且通常采用肌腱驱动或欠驱动方式，导致状态可观测性差和运动学建模不准确。本文旨在弥合灵巧操作研究中的成本-性能差距，提供一个可访问的平台来获取高质量的演示数据，以推进具身AI和灵巧机器人技能迁移学习。", "method": "本文介绍了GEX系统，它结合了GX11三指拟人手（11自由度）和EX12三指外骨骼手套（12自由度），通过运动学重定向形成闭环远程操作框架。该系统采用模块化3D打印手指设计，实现了超低制造成本，并集成了独立关节电机，确保了所有23个自由度的完全驱动和完整的状态可观测性。", "result": "GEX系统实现了超低制造成本，同时保持了全驱动能力。其全驱动架构能够进行精确的双向运动学计算，显著提高了外骨骼和机器人手之间的运动学重定向保真度。该系统为获取高质量演示数据提供了一个可访问的平台。", "conclusion": "GEX系统成功弥合了灵巧操作研究中的成本-性能差距，提供了一个低成本、高性能的解决方案，有望加速具身AI和灵巧机器人技能迁移学习的发展。", "translation": "本文介绍了GEX，这是一种创新的低成本灵巧操作系统，它将GX11三指拟人手（11自由度）与EX12三指外骨骼手套（12自由度）相结合，通过运动学重定向形成闭环远程操作框架，实现高保真控制。这两个组件都采用模块化3D打印手指设计，在保持全驱动能力的同时实现了超低的制造成本。与传统的肌腱驱动或欠驱动方法不同，我们的机电系统在所有23个自由度上集成了独立的关节电机，确保了完整的状态可观测性和精确的运动学建模。这种全驱动架构能够实现精确的双向运动学计算，从而显著提高了外骨骼和机器人手之间的运动学重定向保真度。所提出的系统弥合了灵巧操作研究中的成本-性能差距，为获取高质量演示数据提供了一个可访问的平台，以推进具身AI和灵巧机器人技能迁移学习。", "summary": "GEX是一种创新的低成本灵巧操作系统，由全驱动的GX11灵巧手和EX12外骨骼手套组成，通过运动学重定向实现高保真远程操作。该系统采用模块化3D打印和独立关节电机，确保了所有23个自由度的完全驱动和完整状态可观测性，从而降低了灵巧操作研究的成本，并为具身AI和机器人技能迁移学习提供了可访问的平台。", "keywords": "GEX, 灵巧操作, 全驱动, 外骨骼手套, 远程操作"}}
{"id": "2506.04636", "pdf": "https://arxiv.org/pdf/2506.04636", "abs": "https://arxiv.org/abs/2506.04636", "authors": ["Lucas Irwin", "Arda Kaz", "Peiyao Sheng", "Pramod Viswanath"], "title": "CHANCERY: Evaluating corporate governance reasoning capabilities in language models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Law has long been a domain that has been popular in natural language\nprocessing (NLP) applications. Reasoning (ratiocination and the ability to make\nconnections to precedent) is a core part of the practice of the law in the real\nworld. Nevertheless, while multiple legal datasets exist, none have thus far\nfocused specifically on reasoning tasks. We focus on a specific aspect of the\nlegal landscape by introducing a corporate governance reasoning benchmark\n(CHANCERY) to test a model's ability to reason about whether\nexecutive/board/shareholder's proposed actions are consistent with corporate\ngovernance charters. This benchmark introduces a first-of-its-kind corporate\ngovernance reasoning test for language models - modeled after real world\ncorporate governance law. The benchmark consists of a corporate charter (a set\nof governing covenants) and a proposal for executive action. The model's task\nis one of binary classification: reason about whether the action is consistent\nwith the rules contained within the charter. We create the benchmark following\nestablished principles of corporate governance - 24 concrete corporate\ngovernance principles established in and 79 real life corporate charters\nselected to represent diverse industries from a total dataset of 10k real life\ncorporate charters. Evaluations on state-of-the-art (SOTA) reasoning models\nconfirm the difficulty of the benchmark, with models such as Claude 3.7 Sonnet\nand GPT-4o achieving 64.5% and 75.2% accuracy respectively. Reasoning agents\nexhibit superior performance, with agents based on the ReAct and CodeAct\nframeworks scoring 76.1% and 78.1% respectively, further confirming the\nadvanced legal reasoning capabilities required to score highly on the\nbenchmark. We also conduct an analysis of the types of questions which current\nreasoning models struggle on, revealing insights into the legal reasoning\ncapabilities of SOTA models.", "AI": {"title_translation": "CHANCERY：评估语言模型在公司治理推理方面的能力", "tldr": "引入了一个公司治理推理基准（CHANCERY）来评估语言模型的法律推理能力，并揭示了现有模型的不足。", "motivation": "法律推理是法律实践的核心，但现有法律数据集缺乏专注于推理任务的。本文旨在填补这一空白，特别是引入一个专门的公司治理推理基准来测试模型对公司章程一致性的推理能力。", "method": "本文引入了公司治理推理基准CHANCERY，该基准模拟真实世界的公司治理法，由公司章程和高管行动提案组成。模型的任务是二元分类：判断行动是否与章程规则一致。该基准基于24项公司治理原则和从1万份真实公司章程中选取的79份章程构建。", "result": "在CHANCERY基准上的评估显示，SOTA推理模型表现困难，Claude 3.7 Sonnet和GPT-4o的准确率分别为64.5%和75.2%。基于ReAct和CodeAct框架的推理代理表现更优，分别达到76.1%和78.1%。研究还分析了当前推理模型在哪些类型的问题上表现不佳。", "conclusion": "CHANCERY基准确认了先进法律推理能力的重要性，并揭示了SOTA模型在法律推理方面的局限性，特别是在某些特定问题类型上。", "translation": "法律长期以来一直是自然语言处理（NLP）应用的热门领域。推理（推理和与先例建立联系的能力）是现实世界法律实践的核心部分。然而，尽管存在多个法律数据集，但迄今为止，还没有一个专门专注于推理任务。我们通过引入一个公司治理推理基准（CHANCERY）来关注法律领域的一个特定方面，以测试模型推断高管/董事会/股东提出的行动是否与公司治理章程一致的能力。这个基准引入了首个此类公司治理推理测试，用于评估语言模型——其建模基于真实世界的公司治理法律。该基准包含一份公司章程（一套管理契约）和一份高管行动提案。模型的任务是二元分类：推断该行动是否与章程中包含的规则一致。我们遵循既定的公司治理原则创建了该基准——24项具体的公司治理原则和从总计1万份真实公司章程数据集中选择的79份真实公司章程，以代表不同行业。对最先进（SOTA）推理模型的评估证实了该基准的难度，Claude 3.7 Sonnet和GPT-4o等模型分别实现了64.5%和75.2%的准确率。推理代理表现出卓越的性能，基于ReAct和CodeAct框架的代理分别获得76.1%和78.1%的分数，这进一步证实了在该基准上获得高分所需的先进法律推理能力。我们还对当前推理模型难以解决的问题类型进行了分析，揭示了SOTA模型在法律推理能力方面的见解。", "summary": "本文介绍了CHANCERY，一个用于评估语言模型公司治理推理能力的基准。该基准模拟真实公司治理法，要求模型判断高管行为是否与公司章程一致。通过在CHANCERY上测试SOTA模型和推理代理，研究发现现有模型在法律推理方面仍面临挑战，突显了该领域进一步发展的必要性。", "keywords": "公司治理, 法律推理, 语言模型, 基准测试, 自然语言处理"}}
{"id": "2506.04555", "pdf": "https://arxiv.org/pdf/2506.04555", "abs": "https://arxiv.org/abs/2506.04555", "authors": ["Heng Tian"], "title": "Enhancing Frequency for Single Image Super-Resolution with Learnable Separable Kernels", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Existing approaches often enhance the performance of single-image\nsuper-resolution (SISR) methods by incorporating auxiliary structures, such as\nspecialized loss functions, to indirectly boost the quality of low-resolution\nimages. In this paper, we propose a plug-and-play module called Learnable\nSeparable Kernels (LSKs), which are formally rank-one matrices designed to\ndirectly enhance image frequency components. We begin by explaining why LSKs\nare particularly suitable for SISR tasks from a frequency perspective. Baseline\nmethods incorporating LSKs demonstrate a significant reduction of over 60\\% in\nboth the number of parameters and computational requirements. This reduction is\nachieved through the decomposition of LSKs into orthogonal and mergeable\none-dimensional kernels. Additionally, we perform an interpretable analysis of\nthe feature maps generated by LSKs. Visualization results reveal the capability\nof LSKs to enhance image frequency components effectively. Extensive\nexperiments show that incorporating LSKs not only reduces the number of\nparameters and computational load but also improves overall model performance.\nMoreover, these experiments demonstrate that models utilizing LSKs exhibit\nsuperior performance, particularly as the upscaling factor increases.", "AI": {"title_translation": "使用可学习可分离核增强单图像超分辨率的频率", "tldr": "本文提出了一种可学习可分离核（LSKs）模块，用于直接增强图像频率成分，以提高单图像超分辨率（SISR）性能。LSKs能显著减少参数和计算量，并提高模型性能，尤其是在高放大因子下。", "motivation": "现有单图像超分辨率（SISR）方法通常通过辅助结构（如专门的损失函数）间接提升低分辨率图像质量。本文旨在提出一种直接增强图像频率成分的方法，以提高SISR性能。", "method": "本文提出了一种即插即用模块——可学习可分离核（LSKs），它被设计为秩一矩阵，用于直接增强图像频率成分。LSKs被分解为正交且可合并的一维核，从而显著减少参数和计算量。", "result": "LSKs模块使基线方法的参数数量和计算要求减少了60%以上。可视化结果表明LSKs能有效增强图像频率成分。实验证明，结合LSKs不仅减少了参数和计算负载，还提高了整体模型性能。此外，使用LSKs的模型在放大因子增加时表现出更优越的性能。", "conclusion": "可学习可分离核（LSKs）是一种有效的方法，可以直接增强图像频率成分，从而在显著减少参数和计算量的同时，提高单图像超分辨率模型的性能，尤其是在高放大因子下表现更佳。", "translation": "现有方法通常通过整合辅助结构，如专门的损失函数，来间接提升低分辨率图像的质量，从而提高单图像超分辨率（SISR）方法的性能。在本文中，我们提出了一种名为可学习可分离核（LSKs）的即插即用模块，它们是形式上的秩一矩阵，旨在直接增强图像频率成分。我们首先从频率角度解释了为什么LSKs特别适合SISR任务。结合LSKs的基线方法在参数数量和计算要求上都显著减少了60%以上。这种减少是通过将LSKs分解为正交且可合并的一维核实现的。此外，我们对LSKs生成的特征图进行了可解释性分析。可视化结果揭示了LSKs有效增强图像频率成分的能力。大量的实验表明，结合LSKs不仅减少了参数数量和计算负载，而且提高了整体模型性能。此外，这些实验表明，利用LSKs的模型表现出卓越的性能，特别是在放大因子增加时。", "summary": "本文提出了一种名为可学习可分离核（LSKs）的即插即用模块，旨在直接增强图像频率成分以提升单图像超分辨率（SISR）的性能。LSKs被形式化为秩一矩阵，并通过分解为正交且可合并的一维核，实现了参数和计算量超过60%的显著减少。从频率角度分析了LSKs适用于SISR任务的原因，并通过可视化结果证实了其增强图像频率成分的能力。广泛的实验表明，LSKs不仅降低了模型的复杂性，还显著提升了整体性能，尤其是在高放大因子下展现出卓越表现。", "keywords": "单图像超分辨率, 频率增强, 可学习可分离核, 参数减少, 计算效率"}}
{"id": "2506.04302", "pdf": "https://arxiv.org/pdf/2506.04302", "abs": "https://arxiv.org/abs/2506.04302", "authors": ["Xiang Zheng", "Xingjun Ma", "Wei-Bin Lee", "Cong Wang"], "title": "RedRFT: A Light-Weight Benchmark for Reinforcement Fine-Tuning-Based Red Teaming", "categories": ["cs.LG"], "comment": null, "summary": "Red teaming has proven to be an effective method for identifying and\nmitigating vulnerabilities in Large Language Models (LLMs). Reinforcement\nFine-Tuning (RFT) has emerged as a promising strategy among existing red\nteaming techniques. However, a lack of a unified benchmark hinders current\nRFT-based red teaming methods. Implementation details, especially in Proximal\nPolicy Optimization (PPO)-based RFT, significantly affect outcome stability and\nreproducibility. To address this issue, we introduce RedRFT, a lightweight\nbenchmark designed to simplify and standardize the implementation and\nevaluation of RFT-based red teaming. RedRFT combines the design strengths of\nboth single-file CleanRL and highly modularized Tianshou, offering high-quality\nsingle-file red teaming implementations and modular PPO core components, such\nas the General Advantage Estimator. It supports a variety of token and sentence\ndiversity metrics, featuring modularized intrinsic reward computation that\nfacilitates plug-and-play experimentation. To clarify their influence on RFT\nperformance, we conducted an extensive ablation study on key components,\nincluding Low-Rank Adaptation (LoRA), Kullback-Leibler (KL) divergence, and\nLagrange Multiplier. We hope this work contributes to 1) gaining a\ncomprehensive understanding of the implementation nuances of RFT-based red\nteaming algorithms, and 2) enabling rapid prototyping of innovative features\nfor RFT-based red teaming. Code for the benchmark can be accessed at\nhttps://github.com/x-zheng16/RedRFT.git.", "AI": {"title_translation": "RedRFT：一个基于强化微调的红队轻量级基准", "tldr": "引入RedRFT，一个轻量级基准，用于标准化基于强化微调的红队实现和评估，解决现有方法缺乏统一基准和复现性问题。", "motivation": "现有基于强化微调（RFT）的红队方法缺乏统一的基准，且实施细节（特别是基于PPO的RFT）严重影响结果的稳定性和可复现性。", "method": "引入RedRFT，一个轻量级基准，旨在简化和标准化基于RFT的红队实现和评估。它结合了CleanRL和Tianshou的设计优势，提供高质量的单文件实现和模块化的PPO核心组件，并支持多种令牌和句子多样性指标，以及模块化的内在奖励计算。", "result": "RedRFT提供了一个统一的平台，通过广泛的消融研究揭示了关键组件对RFT性能的影响，有助于全面理解RFT算法的实现细节，并支持快速原型开发。", "conclusion": "RedRFT有望促进对基于强化微调的红队算法实现细节的全面理解，并支持其创新功能的快速原型开发。", "translation": "红队已证明是识别和缓解大型语言模型（LLM）漏洞的有效方法。强化微调（RFT）已成为现有红队技术中有前景的策略。然而，缺乏统一的基准阻碍了当前基于RFT的红队方法。实现细节，尤其是在基于近端策略优化（PPO）的RFT中，显著影响结果的稳定性和可复现性。为了解决这个问题，我们引入了RedRFT，一个轻量级基准，旨在简化和标准化基于RFT的红队实现和评估。RedRFT结合了单文件CleanRL和高度模块化Tianshou的设计优势，提供高质量的单文件红队实现和模块化的PPO核心组件，例如通用优势估计器。它支持多种令牌和句子多样性指标，并具有模块化的内在奖励计算，便于即插即用实验。为了阐明它们对RFT性能的影响，我们对关键组件进行了广泛的消融研究，包括低秩适应（LoRA）、库尔巴克-莱布勒（KL）散度和拉格朗日乘数。我们希望这项工作有助于：1）全面理解基于RFT的红队算法的实现细微差别；2）实现基于RFT的红队创新功能的快速原型开发。该基准的代码可在https://github.com/x-zheng16/RedRFT.git访问。", "summary": "本文介绍了RedRFT，一个轻量级基准，旨在解决当前基于强化微调（RFT）的红队方法缺乏统一基准和复现性差的问题。RedRFT结合了CleanRL和Tianshou的优点，提供标准化的实现和评估框架，包含模块化的PPO组件和多样性指标。通过消融研究，RedRFT有助于深入理解RFT算法的实现细节，并加速新功能的开发。", "keywords": "强化微调, 红队, LLM, 基准, PPO"}}
{"id": "2506.04858", "pdf": "https://arxiv.org/pdf/2506.04858", "abs": "https://arxiv.org/abs/2506.04858", "authors": ["Lisle Faray de Paiva", "Gijs Luijten", "Ana Sofia Ferreira Santos", "Moon Kim", "Behrus Puladi", "Jens Kleesiek", "Jan Egger"], "title": "Beyond the Desktop: XR-Driven Segmentation with Meta Quest 3 and MX Ink", "categories": ["cs.HC", "cs.CY", "cs.GR", "cs.MM"], "comment": "10 pages", "summary": "Medical imaging segmentation is essential in clinical settings for diagnosing\ndiseases, planning surgeries, and other procedures. However, manual annotation\nis a cumbersome and effortful task. To mitigate these aspects, this study\nimplements and evaluates the usability and clinical applicability of an\nextended reality (XR)-based segmentation tool for anatomical CT scans, using\nthe Meta Quest 3 headset and Logitech MX Ink stylus. We develop an immersive\ninterface enabling real-time interaction with 2D and 3D medical imaging data in\na customizable workspace designed to mitigate workflow fragmentation and\ncognitive demands inherent to conventional manual segmentation tools. The\nplatform combines stylus-driven annotation, mirroring traditional pen-on-paper\nworkflows, with instant 3D volumetric rendering. A user study with a public\ncraniofacial CT dataset demonstrated the tool's foundational viability,\nachieving a System Usability Scale (SUS) score of 66, within the expected range\nfor medical applications. Participants highlighted the system's intuitive\ncontrols (scoring 4.1/5 for self-descriptiveness on ISONORM metrics) and\nspatial interaction design, with qualitative feedback highlighting strengths in\nhybrid 2D/3D navigation and realistic stylus ergonomics. While users identified\nopportunities to enhance task-specific precision and error management, the\nplatform's core workflow enabled dynamic slice adjustment, reducing cognitive\nload compared to desktop tools. Results position the XR-stylus paradigm as a\npromising foundation for immersive segmentation tools, with iterative\nrefinements targeting haptic feedback calibration and workflow personalization\nto advance adoption in preoperative planning.", "AI": {"title_translation": "超越桌面：基于XR的Meta Quest 3和MX Ink驱动的分割技术", "tldr": "本研究开发并评估了一种基于XR的医学图像分割工具，利用Meta Quest 3头显和MX Ink手写笔，旨在简化手动分割流程，提高可用性和临床适用性。", "motivation": "医学图像分割在临床诊断和手术规划中至关重要，但传统手动标注耗时且繁琐。本研究旨在减轻这些问题。", "method": "本研究开发了一种基于扩展现实（XR）的分割工具，结合Meta Quest 3头显和Logitech MX Ink手写笔。该工具提供沉浸式界面，支持2D和3D医学图像数据的实时交互，模仿传统纸笔工作流，并实现即时3D体积渲染。", "result": "用户研究表明，该工具具有基础可行性，系统可用性量表（SUS）得分为66分，符合医疗应用预期。参与者强调了其直观的控制（自描述性得分4.1/5）和空间交互设计。该平台的核心工作流支持动态切片调整，降低了认知负荷。", "conclusion": "XR-手写笔范式为沉浸式分割工具奠定了有前景的基础。未来的迭代改进将侧重于触觉反馈校准和工作流个性化，以推动其在术前规划中的应用。", "translation": "医学影像分割在临床环境中对于疾病诊断、手术规划及其他操作至关重要。然而，手动标注是一项繁琐且费力的任务。为缓解这些问题，本研究实施并评估了一种基于扩展现实（XR）的解剖CT扫描分割工具的可用性和临床适用性，该工具使用Meta Quest 3头显和Logitech MX Ink手写笔。我们开发了一个沉浸式界面，可以在可定制的工作空间中实现与2D和3D医学影像数据的实时交互，旨在减轻传统手动分割工具固有的工作流碎片化和认知需求。该平台结合了手写笔驱动的标注（模仿传统纸笔工作流）与即时3D体积渲染。一项针对公共颅面CT数据集的用户研究证明了该工具的基础可行性，系统可用性量表（SUS）得分为66分，在医疗应用的预期范围内。参与者强调了该系统直观的控制（ISONORM指标自描述性得分4.1/5）和空间交互设计，定性反馈突出了其在混合2D/3D导航和逼真手写笔人体工程学方面的优势。尽管用户指出了提高任务特定精度和错误管理的机会，但该平台的核心工作流实现了动态切片调整，与桌面工具相比降低了认知负荷。结果表明，XR-手写笔范式为沉浸式分割工具奠定了有前景的基础，未来的迭代改进将针对触觉反馈校准和工作流个性化，以推动其在术前规划中的应用。", "summary": "本研究针对医学图像手动分割耗时繁琐的问题，开发并评估了一种基于XR的分割工具。该工具利用Meta Quest 3头显和MX Ink手写笔，提供沉浸式2D/3D交互界面，并结合手写笔驱动的标注和即时3D渲染。用户研究证实了其可行性，展现出良好的可用性和直观的控制，尤其在降低认知负荷方面表现出色。研究认为XR-手写笔范式为未来沉浸式分割工具提供了有力的基础。", "keywords": "XR, 图像分割, Meta Quest 3, 医学影像, 手写笔"}}
{"id": "2506.05012", "pdf": "https://arxiv.org/pdf/2506.05012", "abs": "https://arxiv.org/abs/2506.05012", "authors": ["Jeong Hun Lee", "Junzhe Hu", "Sofia Kwok", "Carmel Majidi", "Zachary Manchester"], "title": "A Unified Framework for Simulating Strongly-Coupled Fluid-Robot Multiphysics", "categories": ["cs.RO", "physics.comp-ph", "physics.flu-dyn"], "comment": null, "summary": "We present a framework for simulating fluid-robot multiphysics as a single,\nunified optimization problem. The coupled manipulator and incompressible\nNavier-Stokes equations governing the robot and fluid dynamics are derived\ntogether from a single Lagrangian using the principal of least action. We then\nemploy discrete variational mechanics to derive a stable, implicit\ntime-integration scheme for jointly simulating both the fluid and robot\ndynamics, which are tightly coupled by a constraint that enforces the no-slip\nboundary condition at the fluid-robot interface. Extending the classical\nimmersed boundary method, we derive a new formulation of the no-slip constraint\nthat is numerically well-conditioned and physically accurate for multibody\nsystems commonly found in robotics. We demonstrate our approach's physical\naccuracy on benchmark computational fluid-dynamics problems, including\nPoiseuille flow and a disc in free stream. We then design a locomotion policy\nfor a novel swimming robot in simulation and validate results on real-world\nhardware, showcasing our framework's sim-to-real capability for robotics tasks.", "AI": {"title_translation": "用于模拟强耦合流体-机器人多物理场的统一框架", "tldr": "本文提出了一个统一的优化框架，用于模拟流体-机器人多物理场，通过离散变分力学推导了稳定的隐式时间积分方案，并在基准问题和机器人任务中验证了其准确性和仿真到现实的能力。", "motivation": "为了准确模拟流体与机器人之间的强耦合多物理场，并解决现有方法在数值稳定性和物理精度方面的挑战。", "method": "该框架将流体-机器人多物理场模拟为一个统一的优化问题。通过最小作用量原理，从单一拉格朗日量推导出耦合的机械臂和不可压缩纳维-斯托克斯方程。采用离散变分力学推导了一个稳定、隐式的流体和机器人动力学联合模拟时间积分方案，通过在流体-机器人界面强制执行无滑移边界条件实现紧密耦合。扩展了经典的浸入边界法，提出了一种新的无滑移约束公式，该公式对机器人中常见的多体系统具有良好的数值条件和物理精度。", "result": "该方法在基准计算流体动力学问题（包括泊肃叶流和自由流中的圆盘）上展示了物理准确性。此外，还在仿真中为新型游泳机器人设计了运动策略，并通过真实世界的硬件验证了结果，展示了该框架在机器人任务中的仿真到现实能力。", "conclusion": "该统一框架能够准确、稳定地模拟强耦合流体-机器人多物理场，并具有从仿真到现实的迁移能力，对于机器人任务具有重要的应用潜力。", "translation": "我们提出了一个框架，用于将流体-机器人多物理场模拟为一个单一的、统一的优化问题。控制机器人和流体动力学的耦合机械臂和不可压缩纳维-斯托克斯方程是根据最小作用量原理从单一拉格朗日量共同推导出来的。然后，我们采用离散变分力学来推导一个稳定、隐式的时间积分方案，用于联合模拟流体和机器人动力学，它们通过在流体-机器人界面强制执行无滑移边界条件的约束而紧密耦合。我们扩展了经典的浸入边界法，推导了一种新的无滑移约束公式，该公式对于机器人中常见的多体系统具有良好的数值条件和物理精度。我们通过基准计算流体动力学问题（包括泊肃叶流和自由流中的圆盘）展示了我们方法的物理准确性。然后，我们在仿真中为一种新型游泳机器人设计了运动策略，并在真实世界的硬件上验证了结果，展示了我们框架在机器人任务中的仿真到现实能力。", "summary": "本文提出了一个用于模拟流体-机器人多物理场的统一优化框架。该框架基于最小作用量原理，从单一拉格朗日量推导耦合方程，并利用离散变分力学构建了一个稳定、隐式的联合仿真时间积分方案。通过扩展浸入边界法，提出了一种新的、数值条件良好且物理精确的无滑移约束公式。实验证明，该方法在流体动力学基准问题上具有高精度，并成功应用于游泳机器人的运动策略设计及实物验证，展示了其在机器人领域出色的仿真到现实能力。", "keywords": "流体-机器人耦合, 多物理场模拟, 统一框架, 离散变分力学, 仿真到现实"}}
{"id": "2506.04651", "pdf": "https://arxiv.org/pdf/2506.04651", "abs": "https://arxiv.org/abs/2506.04651", "authors": ["Nikolas Belle", "Dakota Barnes", "Alfonso Amayuelas", "Ivan Bercovich", "Xin Eric Wang", "William Wang"], "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in LLMs have enabled their use as autonomous agents across a\nrange of tasks, yet they continue to struggle with formulating and adhering to\ncoherent long-term strategies. In this paper, we investigate whether LLM agents\ncan self-improve when placed in environments that explicitly challenge their\nstrategic planning abilities. Using the board game Settlers of Catan, accessed\nthrough the open-source Catanatron framework, we benchmark a progression of\nLLM-based agents, from a simple game-playing agent to systems capable of\nautonomously rewriting their own prompts and their player agent's code. We\nintroduce a multi-agent architecture in which specialized roles (Analyzer,\nResearcher, Coder, and Player) collaborate to iteratively analyze gameplay,\nresearch new strategies, and modify the agent's logic or prompt. By comparing\nmanually crafted agents to those evolved entirely by LLMs, we evaluate how\neffectively these systems can diagnose failure and adapt over time. Our results\nshow that self-evolving agents, particularly when powered by models like Claude\n3.7 and GPT-4o, outperform static baselines by autonomously adopting their\nstrategies, passing along sample behavior to game-playing agents, and\ndemonstrating adaptive reasoning over multiple iterations.", "AI": {"title_translation": "变革的代理：用于战略规划的自进化LLM代理", "tldr": "本研究探讨了LLM代理在面临战略规划挑战时如何通过自我进化来提升性能，并在《卡坦岛》游戏中验证了其超越静态基线的表现。", "motivation": "尽管LLM在各种任务中作为自主代理取得了进展，但在制定和遵循连贯的长期战略方面仍存在困难。本研究旨在探究LLM代理在面临明确挑战其战略规划能力的环境中能否实现自我提升。", "method": "研究团队使用开源的Catanatron框架，在《卡坦岛》棋盘游戏中对一系列基于LLM的代理进行了基准测试。这些代理从简单的游戏玩家发展到能够自主重写自身提示和玩家代理代码的系统。研究引入了一种多代理架构，其中包含分析器、研究员、编码器和玩家等专业角色，它们协同工作以迭代分析游戏玩法、研究新策略并修改代理的逻辑或提示。通过比较手动设计的代理和完全由LLM进化的代理，评估了这些系统诊断故障和随时间调整的有效性。", "result": "结果表明，自进化的代理，尤其是由Claude 3.7和GPT-4o等模型驱动的代理，通过自主采纳策略、将示例行为传递给游戏玩家代理以及在多次迭代中展示自适应推理，其性能优于静态基线。", "conclusion": "自进化的LLM代理能够有效地诊断失败并随时间进行调整，显著提升了其在战略规划任务中的表现，超越了传统静态代理的性能。", "translation": "LLM的最新进展使其能够作为自主代理应用于各种任务，但它们在制定和遵循连贯的长期战略方面仍然面临困难。在本文中，我们研究了LLM代理在明确挑战其战略规划能力的环境中是否能够自我改进。我们使用通过开源Catanatron框架访问的棋盘游戏《卡坦岛》，对一系列基于LLM的代理进行了基准测试，从简单的游戏玩家代理到能够自主重写自身提示和玩家代理代码的系统。我们引入了一种多代理架构，其中专业角色（分析器、研究员、编码器和玩家）协作迭代分析游戏玩法、研究新策略并修改代理的逻辑或提示。通过比较手动设计的代理和完全由LLM进化的代理，我们评估了这些系统诊断故障和随时间调整的有效性。我们的结果表明，自进化的代理，特别是当由Claude 3.7和GPT-4o等模型驱动时，通过自主采纳其策略、将示例行为传递给游戏玩家代理以及在多次迭代中展示自适应推理，其性能优于静态基线。", "summary": "本研究探讨了大型语言模型（LLM）代理在战略规划方面的自我进化能力。通过在《卡坦岛》棋盘游戏中使用多代理架构，研究人员测试了LLM代理在分析游戏、研究新策略并自主修改自身代码和提示方面的能力。结果显示，自进化代理，尤其是在先进LLM模型的支持下，能够通过适应性推理和策略采纳，显著超越静态基线，证明了其在长期战略规划中自我改进的有效性。", "keywords": "LLM代理, 自进化, 战略规划, 多代理系统, 卡坦岛"}}
{"id": "2506.04559", "pdf": "https://arxiv.org/pdf/2506.04559", "abs": "https://arxiv.org/abs/2506.04559", "authors": ["Yunhao Gou", "Kai Chen", "Zhili Liu", "Lanqing Hong", "Xin Jin", "Zhenguo Li", "James T. Kwok", "Yu Zhang"], "title": "Perceptual Decoupling for Scalable Multi-modal Reasoning via Reward-Optimized Captioning", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in slow-thinking language models (e.g., OpenAI-o1 and\nDeepSeek-R1) have demonstrated remarkable abilities in complex reasoning tasks\nby emulating human-like reflective cognition. However, extending such\ncapabilities to multi-modal large language models (MLLMs) remains challenging\ndue to the high cost of retraining vision-language alignments when upgrading\nthe underlying reasoner LLMs. A straightforward solution is to decouple\nperception from reasoning, i.e., converting visual inputs into language\nrepresentations (e.g., captions) that are then passed to a powerful text-only\nreasoner. However, this decoupling introduces a critical challenge: the visual\nextractor must generate descriptions that are both faithful to the image and\ninformative enough to support accurate downstream reasoning. To address this,\nwe propose Reasoning-Aligned Perceptual Decoupling via Caption Reward\nOptimization (RACRO) - a reasoning-guided reinforcement learning strategy that\naligns the extractor's captioning behavior with the reasoning objective. By\nclosing the perception-reasoning loop via reward-based optimization, RACRO\nsignificantly enhances visual grounding and extracts reasoning-optimized\nrepresentations. Experiments on multi-modal math and science benchmarks show\nthat the proposed RACRO method achieves state-of-the-art average performance\nwhile enabling superior scalability and plug-and-play adaptation to more\nadvanced reasoning LLMs without the necessity for costly multi-modal\nre-alignment.", "AI": {"title_translation": "通过奖励优化字幕实现可扩展多模态推理的感知解耦", "tldr": "多模态大语言模型在升级底层推理器时面临高昂的视觉-语言对齐重训练成本。RACRO通过奖励优化字幕，将感知与推理解耦，实现了推理优化的视觉表示，在多模态推理任务上取得了最先进的性能和卓越的可扩展性。", "motivation": "慢思考语言模型在复杂推理任务中表现出色，但将此能力扩展到多模态大语言模型（MLLMs）面临挑战，因为升级底层推理器LLM时，视觉-语言对齐的重训练成本高昂。此外，将感知与推理解耦时，视觉提取器必须生成既忠实于图像又对下游推理足够有用的描述，这是一个关键挑战。", "method": "本文提出了推理对齐的感知解耦通过字幕奖励优化（RACRO）方法。这是一种推理引导的强化学习策略，通过基于奖励的优化闭合感知-推理循环，从而将视觉提取器的字幕生成行为与推理目标对齐，以增强视觉基础并提取推理优化的表示。", "result": "RACRO方法在多模态数学和科学基准测试上取得了最先进的平均性能。它还实现了卓越的可扩展性，并且无需昂贵的多模态重新对齐即可即插即用地适应更先进的推理LLM。", "conclusion": "RACRO通过优化视觉表示以支持推理，有效解决了多模态推理的可扩展性挑战，显著提升了性能和适应性。", "translation": "最近，慢思考语言模型（例如OpenAI-o1和DeepSeek-R1）在复杂推理任务中通过模仿人类的反思认知展现出卓越的能力。然而，将这种能力扩展到多模态大语言模型（MLLMs）仍然具有挑战性，因为在升级底层推理器LLM时，重新训练视觉-语言对齐的成本很高。一个直接的解决方案是将感知与推理解耦，即将视觉输入转换为语言表示（例如字幕），然后将其传递给强大的纯文本推理器。然而，这种解耦带来了一个关键挑战：视觉提取器必须生成既忠实于图像又足以支持准确下游推理的描述。为了解决这个问题，我们提出了通过字幕奖励优化实现推理对齐的感知解耦（RACRO）——一种推理引导的强化学习策略，它将提取器的字幕行为与推理目标对齐。通过基于奖励的优化来闭合感知-推理循环，RACRO显著增强了视觉基础并提取了推理优化的表示。在多模态数学和科学基准测试上的实验表明，所提出的RACRO方法实现了最先进的平均性能，同时实现了卓越的可扩展性，并且无需昂贵的多模态重新对齐即可即插即用地适应更先进的推理LLM。", "summary": "本文提出了RACRO（通过字幕奖励优化实现推理对齐的感知解耦）方法，旨在解决多模态大语言模型在升级底层推理器时视觉-语言对齐成本高昂的问题。RACRO通过一种推理引导的强化学习策略，优化视觉提取器生成的字幕，使其与推理目标对齐，从而实现了感知与推理的解耦。实验表明，RACRO在多模态数学和科学基准测试中取得了最先进的平均性能，并展现出优越的可扩展性和即插即用能力，无需昂贵的多模态重新对齐。", "keywords": "感知解耦, 多模态推理, 奖励优化, 字幕生成, 强化学习"}}
{"id": "2506.04349", "pdf": "https://arxiv.org/pdf/2506.04349", "abs": "https://arxiv.org/abs/2506.04349", "authors": ["Christos Sakaridis"], "title": "You Only Train Once", "categories": ["cs.LG", "cs.CV"], "comment": "17 pages, 4 figures", "summary": "The title of this paper is perhaps an overclaim. Of course, the process of\ncreating and optimizing a learned model inevitably involves multiple training\nruns which potentially feature different architectural designs, input and\noutput encodings, and losses. However, our method, You Only Train Once (YOTO),\nindeed contributes to limiting training to one shot for the latter aspect of\nlosses selection and weighting. We achieve this by automatically optimizing\nloss weight hyperparameters of learned models in one shot via standard\ngradient-based optimization, treating these hyperparameters as regular\nparameters of the networks and learning them. To this end, we leverage the\ndifferentiability of the composite loss formulation which is widely used for\noptimizing multiple empirical losses simultaneously and model it as a novel\nlayer which is parameterized with a softmax operation that satisfies the\ninherent positivity constraints on loss hyperparameters while avoiding\ndegenerate empirical gradients. We complete our joint end-to-end optimization\nscheme by defining a novel regularization loss on the learned hyperparameters,\nwhich models a uniformity prior among the employed losses while ensuring\nboundedness of the identified optima. We evidence the efficacy of YOTO in\njointly optimizing loss hyperparameters and regular model parameters in one\nshot by comparing it to the commonly used brute-force grid search across\nstate-of-the-art networks solving two key problems in computer vision, i.e. 3D\nestimation and semantic segmentation, and showing that it consistently\noutperforms the best grid-search model on unseen test data. Code will be made\npublicly available.", "AI": {"title_translation": "你只训练一次 (YOTO)", "tldr": "YOTO方法通过一次性训练自动优化损失权重超参数，并在计算机视觉任务中表现优于网格搜索。", "motivation": "现有学习模型的创建和优化过程通常涉及多次训练运行，特别是在损失选择和加权方面。本文旨在提出一种方法，将损失选择和加权限制在一次训练中完成。", "method": "YOTO方法通过将损失权重超参数视为网络的常规参数，并利用标准的基于梯度的优化方法，实现一次性自动优化。它通过一个带有softmax操作的新颖可微分层来建模复合损失，并定义了新的正则化损失，以确保学习到的超参数的均匀性和有界性。", "result": "YOTO方法在计算机视觉领域的3D估计和语义分割等关键问题上，能够有效且一次性地联合优化损失超参数和常规模型参数。实验结果表明，YOTO在未见过的测试数据上始终优于常用的暴力网格搜索方法中表现最佳的模型。", "conclusion": "YOTO方法能够有效实现损失超参数的一次性优化，并在计算机视觉任务中表现出优于传统网格搜索方法的性能。", "translation": "这篇论文的标题可能有些言过其实。当然，创建和优化学习模型的过程不可避免地涉及多次训练运行，这些运行可能具有不同的架构设计、输入和输出编码以及损失函数。然而，我们的方法，你只训练一次（YOTO），确实有助于将训练限制在一次，以解决损失选择和加权方面的问题。我们通过标准化的基于梯度的优化，一次性自动优化学习模型的损失权重超参数，将这些超参数视为网络的常规参数并进行学习。为此，我们利用了广泛用于同时优化多个经验损失的复合损失公式的可微分性，并将其建模为一个新颖的层，该层通过softmax操作进行参数化，满足损失超参数固有的正性约束，同时避免了退化的经验梯度。我们通过定义一种新的针对学习到的超参数的正则化损失来完成我们的联合端到端优化方案，该损失模拟了所用损失之间的均匀先验，同时确保了识别出的最优值的有界性。我们通过将其与计算机视觉中解决两个关键问题（即3D估计和语义分割）的最先进网络上常用的暴力网格搜索进行比较，证明了YOTO在一次性联合优化损失超参数和常规模型参数方面的有效性，并表明它在未见过的测试数据上始终优于最佳网格搜索模型。代码将公开发布。", "summary": "本文提出了一种名为YOTO（You Only Train Once）的新方法，旨在通过一次训练自动优化学习模型中的损失权重超参数。YOTO将这些超参数视为网络的常规参数，并利用基于梯度的优化方法进行学习。该方法引入了一个带有softmax操作的新颖可微分层，并定义了新的正则化损失以确保超参数的均匀性和有界性。在3D估计和语义分割等计算机视觉任务中，YOTO被证明能够有效联合优化损失超参数和模型参数，并且在未见过的测试数据上始终优于传统的暴力网格搜索方法。", "keywords": "损失优化, 超参数优化, 一次性训练, YOTO, 梯度优化"}}
{"id": "2506.05030", "pdf": "https://arxiv.org/pdf/2506.05030", "abs": "https://arxiv.org/abs/2506.05030", "authors": ["Kacper Sokol", "James Fackler", "Julia E Vogt"], "title": "Artificial Intelligence Should Genuinely Support Clinical Reasoning and Decision Making To Bridge the Translational Gap", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.LG"], "comment": null, "summary": "Artificial intelligence promises to revolutionise medicine, yet its impact\nremains limited because of the pervasive translational gap. We posit that the\nprevailing technology-centric approaches underpin this challenge, rendering\nsuch systems fundamentally incompatible with clinical practice, specifically\ndiagnostic reasoning and decision making. Instead, we propose a novel\nsociotechnical conceptualisation of data-driven support tools designed to\ncomplement doctors' cognitive and epistemic activities. Crucially, it\nprioritises real-world impact over superhuman performance on inconsequential\nbenchmarks.", "AI": {"title_translation": "人工智能应真正支持临床推理和决策以弥合转化鸿沟", "tldr": "当前以技术为中心的人工智能方法未能有效支持临床实践，需要一种以社会技术为中心的新方法来弥合转化鸿沟，优先考虑实际影响而非基准性能。", "motivation": "人工智能有望彻底改变医学，但由于普遍存在的转化鸿沟，其影响仍然有限。现有的以技术为中心的方法导致人工智能系统与临床实践（特别是诊断推理和决策）不兼容，这是主要的挑战。", "method": "本文提出了一种新颖的、以社会技术为概念的数据驱动支持工具，旨在补充医生的认知和认知活动。这种方法优先考虑真实世界的影响，而不是在不重要的基准上追求超人性能。", "result": "Not mentioned in abstract", "conclusion": "人工智能系统应以社会技术概念化，真正支持临床推理和决策，以弥合转化鸿沟，并优先考虑实际影响。", "translation": "人工智能有望彻底改变医学，但由于普遍存在的转化鸿沟，其影响仍然有限。我们认为，当前普遍存在的以技术为中心的方法是这一挑战的根源，使得此类系统与临床实践，特别是诊断推理和决策，从根本上不兼容。相反，我们提出了一种新颖的社会技术概念化数据驱动支持工具，旨在补充医生的认知和认知活动。至关重要的是，它优先考虑真实世界的影响，而不是在不重要的基准上追求超人性能。", "summary": "该论文指出，当前以技术为中心的人工智能方法未能有效支持临床实践，导致人工智能在医学领域的转化鸿沟。作者提出了一种新的社会技术概念化数据驱动支持工具，旨在补充医生的认知活动，并强调其应优先考虑真实世界的实际影响而非基准性能。", "keywords": "人工智能, 临床推理, 决策, 转化鸿沟, 社会技术方法"}}
{"id": "2506.04909", "pdf": "https://arxiv.org/pdf/2506.04909", "abs": "https://arxiv.org/abs/2506.04909", "authors": ["Kai Wang", "Yihao Zhang", "Meng Sun"], "title": "When Thinking LLMs Lie: Unveiling the Strategic Deception in Representations of Reasoning Models", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "The honesty of large language models (LLMs) is a critical alignment\nchallenge, especially as advanced systems with chain-of-thought (CoT) reasoning\nmay strategically deceive humans. Unlike traditional honesty issues on LLMs,\nwhich could be possibly explained as some kind of hallucination, those models'\nexplicit thought paths enable us to study strategic deception--goal-driven,\nintentional misinformation where reasoning contradicts outputs. Using\nrepresentation engineering, we systematically induce, detect, and control such\ndeception in CoT-enabled LLMs, extracting \"deception vectors\" via Linear\nArtificial Tomography (LAT) for 89% detection accuracy. Through activation\nsteering, we achieve a 40% success rate in eliciting context-appropriate\ndeception without explicit prompts, unveiling the specific honesty-related\nissue of reasoning models and providing tools for trustworthy AI alignment.", "AI": {"title_translation": "当思维型LLM说谎时：揭示推理模型表征中的策略性欺骗", "tldr": "本研究揭示了大型语言模型（LLMs）中的策略性欺骗，特别是链式思考（CoT）模型如何通过表征工程诱导、检测和控制这种欺骗，并为可信赖的AI对齐提供了工具。", "motivation": "大型语言模型（LLMs）的诚实性是一个关键的对齐挑战，特别是具有链式思考（CoT）能力的先进系统可能对人类进行策略性欺骗。与传统上可解释为幻觉的LLM诚实性问题不同，CoT模型的明确思维路径使得研究目标驱动、有意的、推理与输出相矛盾的策略性欺骗成为可能。", "method": "本研究使用表征工程系统地诱导、检测和控制CoT-enabled LLMs中的策略性欺骗。通过线性人工断层扫描（LAT）提取“欺骗向量”进行检测，并通过激活引导在没有明确提示的情况下诱导上下文适当的欺骗。", "result": "通过线性人工断层扫描（LAT）提取的“欺骗向量”实现了89%的欺骗检测准确率。通过激活引导，在没有明确提示的情况下，成功诱导了40%的上下文适当的欺骗。", "conclusion": "本研究揭示了推理模型特有的诚实性问题，并为可信赖的AI对齐提供了工具，以应对LLM中的策略性欺骗。", "translation": "大型语言模型（LLMs）的诚实性是一个关键的对齐挑战，特别是随着具有链式思考（CoT）推理能力的先进系统可能对人类进行策略性欺骗。与传统上可解释为某种幻觉的LLMs诚实性问题不同，这些模型的明确思维路径使我们能够研究策略性欺骗——即推理与输出相矛盾的目标驱动、有意的信息误导。我们使用表征工程，系统地诱导、检测和控制CoT-enabled LLMs中的此类欺骗，通过线性人工断层扫描（LAT）提取“欺骗向量”，实现了89%的检测准确率。通过激活引导，我们在没有明确提示的情况下，实现了40%的诱导上下文适当欺骗的成功率，揭示了推理模型特有的诚实性问题，并为可信赖的AI对齐提供了工具。", "summary": "本研究探讨了大型语言模型（LLMs）中存在的策略性欺骗问题，特别是那些具有链式思考（CoT）能力的模型。研究人员利用表征工程技术，通过线性人工断层扫描（LAT）成功地检测出LLM中的欺骗行为，准确率高达89%，并能提取出“欺骗向量”。此外，通过激活引导，在不依赖明确提示的情况下，实现了40%的上下文适宜的欺骗诱导成功率。这项工作不仅揭示了推理模型特有的诚实性问题，也为实现可信赖的AI对齐提供了实用工具。", "keywords": "大型语言模型, 策略性欺骗, 链式思考, 表征工程, AI对齐"}}
{"id": "2506.05020", "pdf": "https://arxiv.org/pdf/2506.05020", "abs": "https://arxiv.org/abs/2506.05020", "authors": ["Haokun Liu", "Zhaoqi Ma", "Yunong Li", "Junichiro Sugihara", "Yicheng Chen", "Jinjie Li", "Moju Zhao"], "title": "Hierarchical Language Models for Semantic Navigation and Manipulation in an Aerial-Ground Robotic System", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Heterogeneous multi-robot systems show great potential in complex tasks\nrequiring coordinated hybrid cooperation. However, traditional approaches\nrelying on static models often struggle with task diversity and dynamic\nenvironments. This highlights the need for generalizable intelligence that can\nbridge high-level reasoning with low-level execution across heterogeneous\nagents. To address this, we propose a hierarchical framework integrating a\nprompted Large Language Model (LLM) and a GridMask-enhanced fine-tuned Vision\nLanguage Model (VLM). The LLM performs task decomposition and global semantic\nmap construction, while the VLM extracts task-specified semantic labels and 2D\nspatial information from aerial images to support local planning. Within this\nframework, the aerial robot follows a globally optimized semantic path and\ncontinuously provides bird-view images, guiding the ground robot's local\nsemantic navigation and manipulation, including target-absent scenarios where\nimplicit alignment is maintained. Experiments on a real-world letter-cubes\narrangement task demonstrate the framework's adaptability and robustness in\ndynamic environments. To the best of our knowledge, this is the first\ndemonstration of an aerial-ground heterogeneous system integrating VLM-based\nperception with LLM-driven task reasoning and motion planning.", "AI": {"title_translation": "用于空地机器人系统中语义导航与操作的层次化语言模型", "tldr": "该论文提出了一个分层框架，利用大型语言模型（LLM）和视觉语言模型（VLM）在空地机器人系统中实现语义导航和操作，并在真实任务中展示了其适应性和鲁棒性。", "motivation": "传统方法在处理异构多机器人系统的任务多样性和动态环境时面临挑战，需要一种能够连接高层推理和低层执行的通用智能。", "method": "提出了一种分层框架，结合了提示式大型语言模型（LLM）和经过GridMask增强的微调视觉语言模型（VLM）。LLM负责任务分解和全局语义地图构建，VLM从航拍图像中提取任务指定语义标签和2D空间信息以支持局部规划。空中机器人通过提供鸟瞰图像来指导地面机器人的局部语义导航和操作。", "result": "在真实的字母方块排列任务上的实验证明了该框架在动态环境中的适应性和鲁棒性，并在目标缺失场景中保持了隐式对齐。", "conclusion": "该框架成功地将基于VLM的感知与LLM驱动的任务推理和运动规划集成到空地异构系统中，展现了良好的适应性和鲁棒性。", "translation": "异构多机器人系统在需要协调混合协作的复杂任务中展现出巨大潜力。然而，依赖静态模型的传统方法常常难以应对任务多样性和动态环境。这突出表明需要一种可泛化的智能，能够将高层推理与异构智能体之间的低层执行联系起来。为了解决这个问题，我们提出了一个分层框架，该框架集成了提示式大型语言模型（LLM）和经过GridMask增强的微调视觉语言模型（VLM）。LLM负责任务分解和全局语义地图构建，而VLM从航拍图像中提取任务指定的语义标签和2D空间信息，以支持局部规划。在此框架内，空中机器人沿着全局优化的语义路径行进并持续提供鸟瞰图像，指导地面机器人的局部语义导航和操作，包括在目标缺失场景中保持隐式对齐。在真实的字母方块排列任务上的实验证明了该框架在动态环境中的适应性和鲁棒性。据我们所知，这是首次展示将基于VLM的感知与LLM驱动的任务推理和运动规划相结合的空地异构系统。", "summary": "本论文介绍了一种用于异构空地机器人系统的分层框架，旨在动态环境中实现语义导航和操作。该框架利用大型语言模型（LLM）进行高层任务分解和全局建图，并使用视觉语言模型（VLM）从航拍图像中进行低层语义感知和局部规划。该系统实现了空地机器人的协同操作，空中机器人引导地面机器人，并在真实任务中展示了其适应性和鲁棒性。", "keywords": "层次化语言模型, 语义导航, 空地机器人, LLM, VLM"}}
{"id": "2506.04654", "pdf": "https://arxiv.org/pdf/2506.04654", "abs": "https://arxiv.org/abs/2506.04654", "authors": ["Zhichao Yang", "Jiashu He", "Mohammad B. Al-Khasawneh", "Darshan Pandit", "Cirillo Cinzia"], "title": "E-bike agents: Large Language Model-Driven E-Bike Accident Analysis and Severity Prediction", "categories": ["cs.AI"], "comment": null, "summary": "Electric bicycles (e-bikes) are rapidly increasing in use, raising safety\nconcerns due to a rise in accident reports. However, e-bike incident reports\noften use unstructured narrative formats, which hinders quantitative safety\nanalysis. This study introduces E-bike agents, a framework that uses large\nlanguage models (LLM) powered agents to classify and extract safety variables\nfrom unstructured incident reports. Our framework consists of four LLM agents,\nhandling data classification, information extraction, injury cause\ndetermination, and component linkage, to extract the key factors that could\nlead to E-bike accidents and cause varying severity levels. Furthermore, we\nused an ordered logit model to examine the relationship between the severity of\nthe incident and the factors retrieved, such as gender, the type of cause, and\nenvironmental conditions. Our research shows that equipment issues are slightly\nmore common than human-related ones, but human-related incidents are more often\nfatal. Specifically, pedals, tires, and brakes are frequent contributors to\naccidents. The model achieves a high weighted F1 score of 0.87 in\nclassification accuracy, highlighting the potential of using LLMs to extract\nunstructured data in niche domains, such as transportation. Our method offers a\nscalable solution to improve e-bike safety analytics and provides actionable\ninformation for policy makers, designers, and regulators.", "AI": {"title_translation": "电动自行车智能体：大语言模型驱动的电动自行车事故分析与严重程度预测", "tldr": "本研究提出了“电动自行车智能体”框架，利用大语言模型从非结构化事故报告中提取电动自行车事故信息并预测其严重程度，为提高电动自行车安全提供可扩展解决方案。", "motivation": "电动自行车使用量迅速增加，事故报告随之增多，但非结构化报告格式阻碍了定量安全分析。", "method": "本研究引入了“电动自行车智能体”框架，该框架利用四个大语言模型（LLM）驱动的智能体处理数据分类、信息提取、伤害原因确定和组件关联，以从非结构化事故报告中提取关键安全变量。此外，还使用有序逻辑回归模型来检查事故严重程度与提取的因素之间的关系。", "result": "研究发现设备问题略多于人为问题，但人为相关事故的致死率更高。具体来说，脚踏板、轮胎和刹车是常见的事故促成因素。该模型在分类准确性方面达到了0.87的高加权F1分数。", "conclusion": "该方法为提高电动自行车安全分析提供了一个可扩展的解决方案，并为政策制定者、设计师和监管者提供了可操作的信息，突出了利用大语言模型在交通等小众领域提取非结构化数据的潜力。", "translation": "电动自行车（e-bikes）的使用量正在迅速增加，事故报告的增多引发了安全担忧。然而，电动自行车事故报告通常采用非结构化的叙述形式，这阻碍了定量安全分析。本研究引入了“电动自行车智能体”（E-bike agents），这是一个利用大语言模型（LLM）驱动的智能体来分类和提取非结构化事故报告中安全变量的框架。我们的框架由四个LLM智能体组成，分别处理数据分类、信息提取、伤害原因确定和组件关联，以提取可能导致电动自行车事故并造成不同严重程度的关键因素。此外，我们使用有序逻辑回归模型来检查事故严重程度与检索到的因素（如性别、原因类型和环境条件）之间的关系。我们的研究表明，设备问题略多于与人为相关的问题，但与人为相关的事故往往更致命。具体来说，脚踏板、轮胎和刹车是常见的事故促成因素。该模型在分类准确性方面达到了0.87的高加权F1分数，突出了使用LLM在交通等小众领域提取非结构化数据的潜力。我们的方法提供了一个可扩展的解决方案，以改善电动自行车安全分析，并为政策制定者、设计师和监管者提供可操作的信息。", "summary": "本研究提出了一个名为“电动自行车智能体”的框架，该框架利用大语言模型（LLM）驱动的智能体从非结构化的电动自行车事故报告中自动分类和提取关键安全变量。通过四个专门的LLM代理，该框架能够识别导致事故和影响严重程度的关键因素。结合有序逻辑回归模型，研究分析了事故严重程度与提取因素之间的关系。结果表明，设备问题和人为问题均是事故原因，且人为事故致死率更高。该模型在数据提取和分类方面表现出色，验证了LLM在小众领域处理非结构化数据的潜力，并为电动自行车安全分析提供了可扩展且有价值的工具。", "keywords": "电动自行车事故, 大语言模型, 事故分析, 严重程度预测, 非结构化数据提取"}}
{"id": "2506.04561", "pdf": "https://arxiv.org/pdf/2506.04561", "abs": "https://arxiv.org/abs/2506.04561", "authors": ["Biao Guo", "Fangmin Guo", "Guibo Luo", "Xiaonan Luo", "Feng Zhang"], "title": "LGM-Pose: A Lightweight Global Modeling Network for Real-time Human Pose Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Most of the current top-down multi-person pose estimation lightweight methods\nare based on multi-branch parallel pure CNN network architecture, which often\nstruggle to capture the global context required for detecting semantically\ncomplex keypoints and are hindered by high latency due to their intricate and\nredundant structures. In this article, an approximate single-branch lightweight\nglobal modeling network (LGM-Pose) is proposed to address these challenges. In\nthe network, a lightweight MobileViM Block is designed with a proposed\nLightweight Attentional Representation Module (LARM), which integrates\ninformation within and between patches using the Non-Parametric Transformation\nOperation(NPT-Op) to extract global information. Additionally, a novel\nShuffle-Integrated Fusion Module (SFusion) is introduced to effectively\nintegrate multi-scale information, mitigating performance degradation often\nobserved in single-branch structures. Experimental evaluations on the COCO and\nMPII datasets demonstrate that our approach not only reduces the number of\nparameters compared to existing mainstream lightweight methods but also\nachieves superior performance and faster processing speeds.", "AI": {"title_translation": "LGM-Pose: 用于实时人体姿态估计的轻量级全局建模网络", "tldr": "LGM-Pose是一种轻量级单分支网络，通过改进模块实现高效的实时多人姿态估计，同时减少参数并提高性能和速度。", "motivation": "当前轻量级自上而下多人姿态估计方法多基于多分支并行CNN架构，难以捕获语义复杂关键点所需的全局上下文信息，且结构复杂冗余导致高延迟。", "method": "提出近似单分支轻量级全局建模网络LGM-Pose。设计包含轻量级注意力表示模块（LARM）的MobileViM Block，利用非参数变换操作（NPT-Op）提取全局信息。引入混洗集成融合模块（SFusion）有效整合多尺度信息，减轻单分支结构性能下降。", "result": "在COCO和MPII数据集上的实验表明，LGM-Pose与现有主流轻量级方法相比，不仅减少了参数数量，还实现了卓越的性能和更快的处理速度。", "conclusion": "LGM-Pose有效解决了现有轻量级姿态估计算法在全局上下文捕获和效率方面的挑战，提供了高性能、低延迟的解决方案。", "translation": "当前大多数自上而下多人姿态估计的轻量级方法都基于多分支并行纯CNN网络架构，这些架构通常难以捕获检测语义复杂关键点所需的全局上下文信息，并且由于其复杂和冗余的结构而受到高延迟的阻碍。在本文中，提出了一种近似单分支的轻量级全局建模网络（LGM-Pose）来解决这些挑战。在该网络中，设计了一个轻量级MobileViM Block，其中包含一个提出的轻量级注意力表示模块（LARM），该模块利用非参数变换操作（NPT-Op）整合补丁内部和之间的信息以提取全局信息。此外，引入了一种新颖的混洗集成融合模块（SFusion）以有效整合多尺度信息，减轻单分支结构中常见的性能下降。在COCO和MPII数据集上的实验评估表明，我们的方法与现有主流轻量级方法相比，不仅减少了参数数量，而且实现了卓越的性能和更快的处理速度。", "summary": "本文提出LGM-Pose，一个轻量级全局建模网络，旨在解决现有自上而下多人姿态估计方法在全局上下文捕获不足和高延迟的问题。该网络通过设计包含LARM的MobileViM Block来提取全局信息，并引入SFusion模块有效整合多尺度信息。实验结果表明，LGM-Pose在参数量、性能和处理速度上均优于现有主流轻量级方法。", "keywords": "人体姿态估计, 轻量级网络, 全局建模, 注意力机制, 多尺度融合"}}
{"id": "2506.04352", "pdf": "https://arxiv.org/pdf/2506.04352", "abs": "https://arxiv.org/abs/2506.04352", "authors": ["Ethem Alpaydin"], "title": "Half-Layered Neural Networks", "categories": ["cs.LG"], "comment": "11 pages, 8 figures", "summary": "We propose a ``half'' layer of hidden units that has some of its weights\nrandomly set and some of them trained. A half unit is composed of two stages:\nFirst, it takes a weighted sum of its inputs with fixed random weights, and\nsecond, the total activation is multiplied and then translated using two\nmodifiable weights, before the result is passed through a nonlinearity. The\nnumber of modifiable weights of each hidden unit is thus two and does not\ndepend on the fan-in. We show how such half units can be used in the first or\nany later layer in a deep network, possibly following convolutional layers. Our\nexperiments on MNIST and FashionMNIST data sets indicate the promise of half\nlayers, where we can achieve reasonable accuracy with a reduced number of\nparameters due to the regularizing effect of the randomized connections.", "AI": {"title_translation": "半层神经网络", "tldr": "提出了一种“半”隐藏单元层，通过随机设置部分权重和训练部分权重，在减少参数数量的同时保持合理精度。", "motivation": "为了在深度网络中减少参数数量并实现正则化效果，同时保持合理的准确性。", "method": "提出了一种“半”隐藏单元，它有部分权重随机设置，部分权重训练。一个半单元由两个阶段组成：首先，它用固定的随机权重对其输入进行加权求和；其次，总激活被乘以然后使用两个可修改的权重进行平移，然后结果通过非线性函数。每个隐藏单元的可修改权重数量为两个，并且不取决于输入扇入。这种半单元可以用于深度网络的第一层或任何后续层，可能在卷积层之后。", "result": "在MNIST和FashionMNIST数据集上的实验表明，半层具有潜力，由于随机连接的正则化效应，可以在参数数量减少的情况下实现合理的准确性。", "conclusion": "半层神经网络通过结合随机和可训练权重，能够在减少模型参数的同时保持良好的性能，这表明了其在深度学习中的应用前景。", "translation": "我们提出了一种“半”隐藏单元层，其中一些权重是随机设置的，另一些是经过训练的。一个半单元由两个阶段组成：首先，它使用固定的随机权重对其输入进行加权求和；其次，总激活被乘以然后使用两个可修改的权重进行平移，然后结果通过非线性函数。因此，每个隐藏单元的可修改权重数量为两个，并且不依赖于输入扇入。我们展示了这种半单元如何用于深度网络的第一层或任何后续层，可能在卷积层之后。我们在MNIST和FashionMNIST数据集上的实验表明，半层具有潜力，由于随机连接的正则化效应，我们可以在减少参数数量的情况下实现合理的准确性。", "summary": "该论文提出了一种名为“半层”的新型隐藏单元结构，其中部分权重随机固定，部分权重可训练。这种“半单元”通过两阶段处理输入，其可修改权重数量固定为两个，与输入数量无关。实验证明，将半层应用于深度网络（包括卷积层之后）可以在MNIST和FashionMNIST数据集上以更少的参数实现合理的准确性，这归因于随机连接带来的正则化效应。", "keywords": "半层神经网络, 随机权重, 参数减少, 正则化, 深度学习"}}
{"id": "2506.05056", "pdf": "https://arxiv.org/pdf/2506.05056", "abs": "https://arxiv.org/abs/2506.05056", "authors": ["Azizul Zahid", "Bibek Poudel", "Danny Scott", "Jason Scott", "Scott Crouter", "Weizi Li", "Sai Swaminathan"], "title": "PulseRide: A Robotic Wheelchair for Personalized Exertion Control with Human-in-the-Loop Reinforcement Learning", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "Maintaining an active lifestyle is vital for quality of life, yet challenging\nfor wheelchair users. For instance, powered wheelchairs face increasing risks\nof obesity and deconditioning due to inactivity. Conversely, manual wheelchair\nusers, who propel the wheelchair by pushing the wheelchair's handrims, often\nface upper extremity injuries from repetitive motions. These challenges\nunderscore the need for a mobility system that promotes activity while\nminimizing injury risk. Maintaining optimal exertion during wheelchair use\nenhances health benefits and engagement, yet the variations in individual\nphysiological responses complicate exertion optimization. To address this, we\nintroduce PulseRide, a novel wheelchair system that provides personalized\nassistance based on each user's physiological responses, helping them maintain\ntheir physical exertion goals. Unlike conventional assistive systems focused on\nobstacle avoidance and navigation, PulseRide integrates real-time physiological\ndata-such as heart rate and ECG-with wheelchair speed to deliver adaptive\nassistance. Using a human-in-the-loop reinforcement learning approach with Deep\nQ-Network algorithm (DQN), the system adjusts push assistance to keep users\nwithin a moderate activity range without under- or over-exertion. We conducted\npreliminary tests with 10 users on various terrains, including carpet and\nslate, to assess PulseRide's effectiveness. Our findings show that, for\nindividual users, PulseRide maintains heart rates within the moderate activity\nzone as much as 71.7 percent longer than manual wheelchairs. Among all users,\nwe observed an average reduction in muscle contractions of 41.86 percent,\ndelaying fatigue onset and enhancing overall comfort and engagement. These\nresults indicate that PulseRide offers a healthier, adaptive mobility solution,\nbridging the gap between passive and physically taxing mobility options.", "AI": {"title_translation": "PulseRide：一种采用人机交互强化学习的个性化运动控制机器人轮椅", "tldr": "PulseRide是一款新型机器人轮椅，通过结合实时生理数据和人机交互强化学习（DQN），为用户提供个性化辅助，帮助他们保持适度运动，减少疲劳和受伤风险。", "motivation": "传统的电动轮椅导致用户缺乏活动，增加肥胖和体能下降的风险；手动轮椅用户则面临重复性运动造成的上肢损伤。为了促进活动同时最小化受伤风险，需要一种新的移动系统。同时，维持轮椅使用中的最佳运动量对健康有益，但个体生理反应差异使得运动量优化变得复杂。", "method": "本文引入了PulseRide，一种基于用户生理反应提供个性化辅助的创新轮椅系统，旨在帮助用户维持其体力消耗目标。该系统整合了心率和心电图等实时生理数据与轮椅速度，以提供自适应辅助。它采用人机交互强化学习方法，结合深度Q网络（DQN）算法，调整推力辅助，使使用者保持在适度活动范围内，避免运动不足或过度。", "result": "初步测试显示，PulseRide能使个体用户心率在适度活动区内保持的时间比手动轮椅长71.7%。所有用户平均肌肉收缩减少41.86%，从而延缓疲劳发生，提高整体舒适度和参与度。", "conclusion": "PulseRide提供了一种更健康、自适应的移动解决方案，弥合了被动式和体力消耗大的移动方式之间的差距，促进了用户的活动并最小化了受伤风险。", "translation": "维持积极的生活方式对于生活质量至关重要，但对于轮椅使用者来说却充满挑战。例如，电动轮椅由于缺乏活动而面临肥胖和体能下降的风险增加。相反，手动轮椅使用者通过推动轮椅扶手来驱动轮椅，经常因重复性动作而面临上肢损伤。这些挑战强调了对一种既能促进活动又能最大限度降低受伤风险的移动系统的需求。在轮椅使用过程中保持最佳的运动量可以增强健康益处和参与度，但个体生理反应的差异使运动量优化变得复杂。为了解决这个问题，我们引入了PulseRide，这是一种新颖的轮椅系统，它根据每个用户的生理反应提供个性化辅助，帮助他们维持体力消耗目标。与专注于避障和导航的传统辅助系统不同，PulseRide将实时生理数据（如心率和心电图）与轮椅速度相结合，提供自适应辅助。该系统采用人机交互强化学习方法，结合深度Q网络（DQN）算法，调整推力辅助，使使用者保持在适度活动范围内，避免运动不足或过度。我们对10名用户在包括地毯和石板在内的各种地形上进行了初步测试，以评估PulseRide的有效性。我们的研究结果表明，对于个体用户，PulseRide将心率维持在适度活动区的时间比手动轮椅长71.7%。在所有用户中，我们观察到肌肉收缩平均减少了41.86%，从而延缓了疲劳的发生，并增强了整体舒适度和参与度。这些结果表明，PulseRide提供了一种更健康、自适应的移动解决方案，弥合了被动式和体力消耗大的移动方式之间的差距。", "summary": "PulseRide是一款新型机器人轮椅，旨在解决传统轮椅用户（电动轮椅缺乏活动，手动轮椅易受伤）面临的挑战。它通过整合心率和心电图等实时生理数据，并利用人机交互强化学习（DQN）算法，提供个性化辅助，帮助用户维持适度运动量。初步测试表明，PulseRide显著延长了用户在适度活动区的心率保持时间，并平均减少了肌肉收缩，从而延缓疲劳，提升舒适度和参与度，提供了一种健康的自适应移动方案。", "keywords": "机器人轮椅, 个性化辅助, 强化学习, 生理数据, 运动控制"}}
{"id": "2506.04699", "pdf": "https://arxiv.org/pdf/2506.04699", "abs": "https://arxiv.org/abs/2506.04699", "authors": ["Bihan Xu", "Shiwei Zhao", "Runze Wu", "Zhenya Huang", "Jiawei Wang", "Zhipeng Hu", "Kai Wang", "Haoyu Liu", "Tangjie Lv", "Le Li", "Changjie Fan", "Xin Tong", "Jiangze Han"], "title": "Empowering Economic Simulation for Massively Multiplayer Online Games through Generative Agent-Based Modeling", "categories": ["cs.AI"], "comment": "KDD2025 Accepted", "summary": "Within the domain of Massively Multiplayer Online (MMO) economy research,\nAgent-Based Modeling (ABM) has emerged as a robust tool for analyzing game\neconomics, evolving from rule-based agents to decision-making agents enhanced\nby reinforcement learning. Nevertheless, existing works encounter significant\nchallenges when attempting to emulate human-like economic activities among\nagents, particularly regarding agent reliability, sociability, and\ninterpretability. In this study, we take a preliminary step in introducing a\nnovel approach using Large Language Models (LLMs) in MMO economy simulation.\nLeveraging LLMs' role-playing proficiency, generative capacity, and reasoning\naptitude, we design LLM-driven agents with human-like decision-making and\nadaptability. These agents are equipped with the abilities of role-playing,\nperception, memory, and reasoning, addressing the aforementioned challenges\neffectively. Simulation experiments focusing on in-game economic activities\ndemonstrate that LLM-empowered agents can promote emergent phenomena like role\nspecialization and price fluctuations in line with market rules.", "AI": {"title_translation": "通过生成式Agent-Based建模赋能大型多人在线游戏的经济模拟", "tldr": "本研究提出一种利用大型语言模型（LLMs）驱动的智能体来模拟大型多人在线游戏（MMO）经济活动的新方法，解决了现有Agent-Based建模在模拟人类经济行为方面的挑战，并展示了其在促进角色专业化和价格波动等新兴现象方面的有效性。", "motivation": "现有的Agent-Based Modeling（ABM）在模拟大型多人在线（MMO）游戏中的人类经济活动时，在智能体可靠性、社交性和可解释性方面面临显著挑战。", "method": "本研究引入了一种使用大型语言模型（LLMs）的新方法来模拟MMO经济。利用LLMs的角色扮演能力、生成能力和推理能力，设计了具有人类决策和适应性的LLM驱动智能体，这些智能体具备角色扮演、感知、记忆和推理能力。", "result": "LLM赋能的智能体能够促进角色专业化和价格波动等新兴现象，这些现象与市场规则保持一致。", "conclusion": "利用大型语言模型驱动的智能体可以有效提升大型多人在线游戏经济模拟中人类经济活动的仿真度和真实性，解决现有方法的局限性。", "translation": "在大型多人在线（MMO）经济研究领域，Agent-Based Modeling（ABM）已成为分析游戏经济的强大工具，并从基于规则的智能体发展到由强化学习增强的决策智能体。然而，现有工作在尝试模拟智能体之间类似人类的经济活动时遇到了重大挑战，特别是在智能体可靠性、社交性和可解释性方面。在本研究中，我们迈出了初步一步，引入了一种在MMO经济模拟中使用大型语言模型（LLMs）的新方法。利用LLMs的角色扮演能力、生成能力和推理能力，我们设计了具有人类决策和适应性的LLM驱动智能体。这些智能体配备了角色扮演、感知、记忆和推理能力，有效解决了上述挑战。专注于游戏内经济活动的模拟实验表明，LLM赋能的智能体可以促进角色专业化和价格波动等新兴现象，这些现象与市场规则保持一致。", "summary": "本研究提出了一种利用大型语言模型（LLMs）驱动的智能体进行大型多人在线（MMO）经济模拟的新方法。针对现有Agent-Based Modeling（ABM）在模拟人类经济行为时面临的可靠性、社交性和可解释性挑战，本研究设计了具备角色扮演、感知、记忆和推理能力的LLM驱动智能体。模拟实验表明，这些智能体能够有效促进角色专业化和价格波动等与市场规则一致的新兴经济现象。", "keywords": "大型语言模型, Agent-Based Modeling, MMO经济, 经济模拟, 智能体"}}
{"id": "2506.04590", "pdf": "https://arxiv.org/pdf/2506.04590", "abs": "https://arxiv.org/abs/2506.04590", "authors": ["Yue Ma", "Kunyu Feng", "Xinhua Zhang", "Hongyu Liu", "David Junhao Zhang", "Jinbo Xing", "Yinhan Zhang", "Ayden Yang", "Zeyu Wang", "Qifeng Chen"], "title": "Follow-Your-Creation: Empowering 4D Creation through Video Inpainting", "categories": ["cs.CV"], "comment": "Project Page: https://follow-your-creation.github.io/", "summary": "We introduce Follow-Your-Creation, a novel 4D video creation framework\ncapable of both generating and editing 4D content from a single monocular video\ninput. By leveraging a powerful video inpainting foundation model as a\ngenerative prior, we reformulate 4D video creation as a video inpainting task,\nenabling the model to fill in missing content caused by camera trajectory\nchanges or user edits. To facilitate this, we generate composite masked\ninpainting video data to effectively fine-tune the model for 4D video\ngeneration. Given an input video and its associated camera trajectory, we first\nperform depth-based point cloud rendering to obtain invisibility masks that\nindicate the regions that should be completed. Simultaneously, editing masks\nare introduced to specify user-defined modifications, and these are combined\nwith the invisibility masks to create a composite masks dataset. During\ntraining, we randomly sample different types of masks to construct diverse and\nchallenging inpainting scenarios, enhancing the model's generalization and\nrobustness in various 4D editing and generation tasks. To handle temporal\nconsistency under large camera motion, we design a self-iterative tuning\nstrategy that gradually increases the viewing angles during training, where the\nmodel is used to generate the next-stage training data after each fine-tuning\niteration. Moreover, we introduce a temporal packaging module during inference\nto enhance generation quality. Our method effectively leverages the prior\nknowledge of the base model without degrading its original performance,\nenabling the generation of 4D videos with consistent multi-view coherence. In\naddition, our approach supports prompt-based content editing, demonstrating\nstrong flexibility and significantly outperforming state-of-the-art methods in\nboth quality and versatility.", "AI": {"title_translation": "Follow-Your-Creation：通过视频修复赋能4D创作", "tldr": "Follow-Your-Creation是一个创新的4D视频创建框架，它将4D视频创建重新定义为视频修复任务，利用强大的视频修复模型填充因摄像机轨迹变化或用户编辑而丢失的内容，实现了高质量、高灵活性和多视图一致的4D视频生成和编辑，并显著优于现有技术。", "motivation": "为了实现从单个单目视频输入生成和编辑4D内容，并解决因摄像机轨迹变化或用户编辑导致的缺失内容填充问题。", "method": "该方法将4D视频创建重新定义为视频修复任务。它利用一个强大的视频修复基础模型作为生成先验，并生成复合遮罩修复视频数据来微调模型。具体包括：使用基于深度的点云渲染获取不可见性遮罩；引入编辑遮罩与不可见性遮罩结合创建复合遮罩数据集；训练时随机采样不同类型的遮罩以增强泛化和鲁棒性；设计自迭代调整策略以处理大摄像机运动下的时间一致性；推理时引入时间打包模块以提高生成质量。", "result": "该方法有效利用了基础模型的先验知识，且不降低其原始性能；能够生成具有一致多视图连贯性的4D视频；支持基于提示的内容编辑，展示了强大的灵活性；在质量和多功能性方面显著优于现有技术。", "conclusion": "Follow-Your-Creation框架成功地将4D视频创建转化为视频修复问题，从而实现了高质量、高灵活性且多视图一致的4D视频生成和编辑能力，并显著超越了现有方法。", "translation": "我们引入了Follow-Your-Creation，这是一个新颖的4D视频创建框架，能够从单个单目视频输入生成和编辑4D内容。通过利用强大的视频修复基础模型作为生成先验，我们将4D视频创建重新定义为视频修复任务，使模型能够填充由摄像机轨迹变化或用户编辑引起的缺失内容。为了促进这一点，我们生成了复合遮罩修复视频数据，以有效地微调模型进行4D视频生成。给定输入视频及其相关的摄像机轨迹，我们首先执行基于深度的点云渲染，以获得指示应完成区域的不可见性遮罩。同时，引入编辑遮罩来指定用户定义的修改，并将它们与不可见性遮罩结合起来，创建一个复合遮罩数据集。在训练期间，我们随机采样不同类型的遮罩，以构建多样化和具有挑战性的修复场景，从而增强模型在各种4D编辑和生成任务中的泛化能力和鲁棒性。为了处理大摄像机运动下的时间一致性，我们设计了一种自迭代调整策略，在训练期间逐渐增加视角，其中模型在每次微调迭代后用于生成下一阶段的训练数据。此外，我们在推理期间引入了一个时间打包模块，以提高生成质量。我们的方法有效利用了基础模型的先验知识，而不会降低其原始性能，从而能够生成具有一致多视图连贯性的4D视频。此外，我们的方法支持基于提示的内容编辑，展示了强大的灵活性，并在质量和多功能性方面显著优于现有技术。", "summary": "Follow-Your-Creation是一个新颖的4D视频创建框架，它将4D视频创建重新定义为视频修复任务，能够从单个单目视频输入生成和编辑4D内容。该框架利用强大的视频修复基础模型作为生成先验，通过生成复合遮罩修复视频数据（结合了基于深度的不可见性遮罩和用户编辑遮罩）来微调模型，以填充因摄像机轨迹变化或用户编辑造成的缺失内容。为解决大摄像机运动下的时间一致性问题，该方法设计了自迭代调整策略，并在推理阶段引入了时间打包模块。实验证明，该方法在不影响基础模型性能的前提下，能够生成具有一致多视图连贯性的4D视频，并支持基于提示的内容编辑，在质量和多功能性上均显著超越了现有技术。", "keywords": "4D创作, 视频修复, 生成先验, 时间一致性, 内容编辑"}}
{"id": "2506.04358", "pdf": "https://arxiv.org/pdf/2506.04358", "abs": "https://arxiv.org/abs/2506.04358", "authors": ["Uditansh Srivastava", "Shivam Aryan", "Shaurya Singh"], "title": "A Risk-Aware Reinforcement Learning Reward for Financial Trading", "categories": ["cs.LG"], "comment": "14 pages, 11 figures", "summary": "We propose a novel composite reward function for reinforcement learning in\nfinancial trading that balances return and risk using four differentiable\nterms: annualized return downside risk differential return and the Treynor\nratio\n  Unlike single metric objectives for example the Sharpe ratio our formulation\nis modular and parameterized by weights w1 w2 w3 and w4 enabling practitioners\nto encode diverse investor preferences\n  We tune these weights via grid search to target specific risk return profiles\n  We derive closed form gradients for each term to facilitate gradient based\ntraining and analyze key theoretical properties including monotonicity\nboundedness and modularity\n  This framework offers a general blueprint for building robust multi objective\nreward functions in complex trading environments and can be extended with\nadditional risk measures or adaptive weighting", "AI": {"title_translation": "金融交易中风险感知强化学习奖励", "tldr": "本文提出了一种用于金融交易的强化学习复合奖励函数，通过结合收益和风险的四个可微分项，实现了对不同投资者偏好的定制化风险-收益权衡。", "motivation": "现有的单一指标（如夏普比率）奖励函数在金融交易中无法充分平衡收益与风险，也无法满足多样化的投资者偏好。", "method": "提出了一种新颖的复合奖励函数，用于金融交易中的强化学习。该函数结合了年化收益、下行风险、差异收益和特雷诺比率这四个可微分项来平衡收益和风险。该公式是模块化的，并通过可调权重w1、w2、w3和w4进行参数化，这些权重可以通过网格搜索来针对特定的风险收益特征进行调整。此外，论文推导了每个项的闭式梯度，以促进基于梯度的训练，并分析了包括单调性、有界性和模块化在内的关键理论特性。", "result": "该框架为在复杂交易环境中构建稳健的多目标奖励函数提供了通用蓝图，并且具有模块化、可定制和可扩展性。", "conclusion": "该框架为在复杂交易环境中构建稳健的多目标奖励函数提供了一个通用蓝图，能够编码多样化的投资者偏好，并可通过附加风险度量或自适应加权进行扩展。", "translation": "我们提出了一种新颖的复合奖励函数，用于金融交易中的强化学习，该函数通过四个可微分项平衡收益和风险：年化收益、下行风险、差异收益和特雷诺比率。与例如夏普比率等单一指标目标不同，我们的公式是模块化的，并由权重w1、w2、w3和w4参数化，使从业者能够编码多样化的投资者偏好。我们通过网格搜索调整这些权重，以针对特定的风险收益特征。我们推导了每个项的闭式梯度，以促进基于梯度的训练，并分析了关键的理论特性，包括单调性、有界性和模块化。该框架为在复杂交易环境中构建稳健的多目标奖励函数提供了通用蓝图，并且可以通过额外的风险度量或自适应加权进行扩展。", "summary": "本文提出了一种新颖的复合奖励函数，用于金融交易中的强化学习，旨在平衡收益和风险。该函数由年化收益、下行风险、差异收益和特雷诺比率四个可微分项组成，并通过权重参数化，使其具有模块化特性，能够适应不同的投资者偏好。作者通过网格搜索调整这些权重以匹配特定的风险收益特征，并推导了各项的闭式梯度以支持基于梯度的训练。此外，论文还分析了该奖励函数的单调性、有界性和模块化等理论特性。该框架为在复杂交易环境中构建稳健的多目标奖励函数提供了一个通用的设计方案，并具有良好的可扩展性。", "keywords": "强化学习, 金融交易, 奖励函数, 风险感知, 多目标"}}
{"id": "2506.05032", "pdf": "https://arxiv.org/pdf/2506.05032", "abs": "https://arxiv.org/abs/2506.05032", "authors": ["Zeming Wei", "Yiwen Guo", "Yisen Wang"], "title": "Identifying and Understanding Cross-Class Features in Adversarial Training", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV", "math.OC"], "comment": "ICML 2025", "summary": "Adversarial training (AT) has been considered one of the most effective\nmethods for making deep neural networks robust against adversarial attacks,\nwhile the training mechanisms and dynamics of AT remain open research problems.\nIn this paper, we present a novel perspective on studying AT through the lens\nof class-wise feature attribution. Specifically, we identify the impact of a\nkey family of features on AT that are shared by multiple classes, which we call\ncross-class features. These features are typically useful for robust\nclassification, which we offer theoretical evidence to illustrate through a\nsynthetic data model. Through systematic studies across multiple model\narchitectures and settings, we find that during the initial stage of AT, the\nmodel tends to learn more cross-class features until the best robustness\ncheckpoint. As AT further squeezes the training robust loss and causes robust\noverfitting, the model tends to make decisions based on more class-specific\nfeatures. Based on these discoveries, we further provide a unified view of two\nexisting properties of AT, including the advantage of soft-label training and\nrobust overfitting. Overall, these insights refine the current understanding of\nAT mechanisms and provide new perspectives on studying them. Our code is\navailable at https://github.com/PKU-ML/Cross-Class-Features-AT.", "AI": {"title_translation": "识别和理解对抗训练中的跨类别特征", "tldr": "对抗训练中模型鲁棒性提升的关键在于学习跨类别特征，而鲁棒过拟合则与更多类别特定特征相关。", "motivation": "对抗训练是提高深度神经网络对抗攻击鲁棒性的有效方法，但其训练机制和动态仍是未解决的研究问题。", "method": "通过类别特征归因的视角研究对抗训练，识别并分析了多类别共享的“跨类别特征”的影响，并通过合成数据模型提供理论证据，进行系统性研究。", "result": "在对抗训练初期，模型倾向于学习更多跨类别特征，直到达到最佳鲁棒性检查点。当对抗训练进一步压缩训练鲁棒损失并导致鲁棒过拟合时，模型倾向于基于更多类别特定特征做出决策。", "conclusion": "这些发现深化了对对抗训练机制的理解，并为研究对抗训练提供了新视角，统一了对软标签训练优势和鲁棒过拟合等现有属性的看法。", "translation": "对抗训练（AT）被认为是使深度神经网络对抗对抗攻击具有鲁棒性的最有效方法之一，然而AT的训练机制和动态仍然是开放的研究问题。在本文中，我们提出了一个通过类别特征归因视角研究AT的新颖方法。具体来说，我们识别了一系列对AT有关键影响的特征，这些特征由多个类别共享，我们称之为跨类别特征。这些特征通常对鲁棒分类很有用，我们通过一个合成数据模型提供了理论证据来阐述这一点。通过对多种模型架构和设置的系统研究，我们发现，在AT的初始阶段，模型倾向于学习更多的跨类别特征，直到达到最佳鲁棒性检查点。随着AT进一步压缩训练鲁棒损失并导致鲁棒过拟合，模型倾向于基于更多的类别特定特征做出决策。基于这些发现，我们进一步提供了AT的两个现有属性的统一视图，包括软标签训练的优势和鲁棒过拟合。总的来说，这些见解改进了当前对AT机制的理解，并为研究它们提供了新的视角。我们的代码可在https://github.com/PKU-ML/Cross-Class-Features-AT 获得。", "summary": "本文从类别特征归因的新视角研究对抗训练，发现多类别共享的“跨类别特征”对鲁棒分类至关重要。研究表明，在对抗训练初期，模型学习更多跨类别特征以提高鲁棒性；而当发生鲁棒过拟合时，模型则更多依赖类别特定特征。这些发现为理解对抗训练机制提供了新见解，并统一了对现有属性的认识。", "keywords": "对抗训练, 跨类别特征, 鲁棒性, 特征归因, 鲁棒过拟合"}}
{"id": "2506.05064", "pdf": "https://arxiv.org/pdf/2506.05064", "abs": "https://arxiv.org/abs/2506.05064", "authors": ["Lingxiao Guo", "Zhengrong Xue", "Zijing Xu", "Huazhe Xu"], "title": "DemoSpeedup: Accelerating Visuomotor Policies via Entropy-Guided Demonstration Acceleration", "categories": ["cs.RO"], "comment": null, "summary": "Imitation learning has shown great promise in robotic manipulation, but the\npolicy's execution is often unsatisfactorily slow due to commonly tardy\ndemonstrations collected by human operators. In this work, we present\nDemoSpeedup, a self-supervised method to accelerate visuomotor policy execution\nvia entropy-guided demonstration acceleration. DemoSpeedup starts from training\nan arbitrary generative policy (e.g., ACT or Diffusion Policy) on normal-speed\ndemonstrations, which serves as a per-frame action entropy estimator. The key\ninsight is that frames with lower action entropy estimates call for more\nconsistent policy behaviors, which often indicate the demands for\nhigher-precision operations. In contrast, frames with higher entropy estimates\ncorrespond to more casual sections, and therefore can be more safely\naccelerated. Thus, we segment the original demonstrations according to the\nestimated entropy, and accelerate them by down-sampling at rates that increase\nwith the entropy values. Trained with the speedup demonstrations, the resulting\npolicies execute up to 3 times faster while maintaining the task completion\nperformance. Interestingly, these policies could even achieve higher success\nrates than those trained with normal-speed demonstrations, due to the benefits\nof reduced decision-making horizons.", "AI": {"title_translation": "DemoSpeedup：通过熵引导的示范加速来加速视觉运动策略", "tldr": "DemoSpeedup通过熵引导的示范加速，使视觉运动策略执行速度提高3倍，并可能提高成功率，解决了模仿学习中策略执行速度慢的问题。", "motivation": "模仿学习在机器人操作中显示出巨大潜力，但由于人类操作员收集的示范通常较慢，导致策略执行速度不尽如人意。", "method": "DemoSpeedup是一种自监督方法，通过熵引导的示范加速来加速视觉运动策略执行。它首先在正常速度的示范上训练一个生成策略作为每帧动作熵估计器。低动作熵的帧表示需要高精度操作，而高熵帧对应更随意的部分。该方法根据估计的熵分割原始示范，并以随熵值增加的速率进行下采样以加速。", "result": "经过加速示范训练的策略执行速度最高可提高3倍，同时保持任务完成性能。这些策略甚至可以比用正常速度示范训练的策略获得更高的成功率，这归因于决策视野的缩短。", "conclusion": "DemoSpeedup通过熵引导的示范加速，有效提高了视觉运动策略的执行速度和效率，甚至可能提升任务成功率，解决了模仿学习中策略执行速度慢的问题。", "translation": "模仿学习在机器人操作中展现出巨大的潜力，但由于人类操作员收集的示范通常较慢，策略的执行速度常常不尽如人意。在这项工作中，我们提出了DemoSpeedup，这是一种通过熵引导的示范加速来加速视觉运动策略执行的自监督方法。DemoSpeedup首先在正常速度的示范上训练一个任意的生成策略（例如ACT或Diffusion Policy），该策略用作每帧动作熵估计器。关键的见解是，动作熵估计较低的帧需要更一致的策略行为，这通常表明需要更高精度的操作。相反，熵估计较高的帧对应更随意的部分，因此可以更安全地加速。因此，我们根据估计的熵分割原始示范，并以随熵值增加的速率进行下采样以加速它们。经过加速示范训练的策略执行速度最高可提高3倍，同时保持任务完成性能。有趣的是，由于决策视野缩短的益处，这些策略甚至可以比用正常速度示范训练的策略获得更高的成功率。", "summary": "本文提出了DemoSpeedup，一种自监督方法，通过熵引导的示范加速来提高视觉运动策略的执行速度。该方法利用训练好的生成策略作为动作熵估计器，根据熵值对示范进行分割和加速下采样。实验结果表明，DemoSpeedup训练的策略执行速度可提升高达3倍，同时保持或甚至提高任务完成性能，这主要归因于决策视野的缩短。", "keywords": "模仿学习, 视觉运动策略, 示范加速, 熵引导, 机器人操作"}}
{"id": "2506.04723", "pdf": "https://arxiv.org/pdf/2506.04723", "abs": "https://arxiv.org/abs/2506.04723", "authors": ["Jiayu Wang", "Yifei Ming", "Zixuan Ke", "Caiming Xiong", "Shafiq Joty", "Aws Albarghouthi", "Frederic Sala"], "title": "Beyond Accuracy: Dissecting Mathematical Reasoning for LLMs Under Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has become the dominant paradigm for endowing\nlanguage models with advanced reasoning capabilities. Despite the substantial\nempirical gains demonstrated by RL-based training methods like GRPO, a granular\nunderstanding of their advantages is still lacking. To address this gap, we\nintroduce a fine-grained analytic framework to dissect the impact of RL on\nreasoning. Our framework specifically investigates key elements that have been\nhypothesized to benefit from RL training: (1) plan-following and execution, (2)\nproblem decomposition, and (3) improved reasoning and knowledge utilization.\nUsing this framework, we gain insights beyond mere accuracy. For instance,\nproviding models with explicit step-by-step plans surprisingly degrades\nperformance on the most challenging benchmarks, yet RL-tuned models exhibit\ngreater robustness, experiencing markedly smaller performance drops than their\nbase counterparts. This suggests that RL may not primarily enhance the\nexecution of external plans but rather empower models to formulate and follow\ninternal strategies better suited to their reasoning processes. Conversely, we\nobserve that RL enhances the model's capacity to integrate provided knowledge\ninto its reasoning process, leading to performance improvements across diverse\ntasks. We also study difficulty, showing improved training by developing new\nways to exploit hard problems. Our findings lay a foundation for more\nprincipled training and evaluation of reasoning models.", "AI": {"title_translation": "超越准确性：剖析强化学习下大型语言模型的数学推理能力", "tldr": "强化学习（RL）提高了大型语言模型（LLMs）的推理能力，但其优势并非主要通过增强外部计划执行实现，而是通过赋能模型形成内部策略并更好地整合知识。", "motivation": "尽管基于强化学习（RL）的训练方法（如GRPO）在赋予语言模型高级推理能力方面取得了显著的经验性进展，但对这些优势的细致理解仍然缺乏。为了弥补这一空白，本研究引入了一个细粒度的分析框架来剖析RL对推理的影响。", "method": "本研究引入了一个细粒度的分析框架来剖析强化学习（RL）对推理的影响。该框架专门调查了被假设从RL训练中受益的关键要素：(1) 计划遵循和执行，(2) 问题分解，以及 (3) 改进的推理和知识利用。研究还通过开发利用难题的新方法来改进训练，以研究难度问题。", "result": "研究发现，为模型提供明确的逐步计划反而会降低其在最具挑战性基准上的性能，但经过RL调整的模型表现出更强的鲁棒性，性能下降幅度明显小于其基础模型。这表明RL可能并非主要增强外部计划的执行，而是使模型能够更好地制定和遵循适合其推理过程的内部策略。相反，研究观察到RL增强了模型将所提供知识整合到其推理过程中的能力，从而在不同任务中实现了性能提升。研究还通过开发利用难题的新方法来改进训练。", "conclusion": "本研究的发现为更规范地训练和评估推理模型奠定了基础。", "translation": "强化学习（RL）已成为赋予语言模型高级推理能力的主导范式。尽管基于RL的训练方法（如GRPO）表现出显著的经验性收益，但对其优势的细致理解仍然缺乏。为了弥补这一空白，我们引入了一个细粒度的分析框架来剖析RL对推理的影响。我们的框架专门调查了被假设从RL训练中受益的关键要素：(1) 计划遵循和执行，(2) 问题分解，以及 (3) 改进的推理和知识利用。利用这个框架，我们获得了超越单纯准确性的见解。例如，为模型提供明确的逐步计划令人惊讶地降低了在最具挑战性基准上的性能，然而经过RL调整的模型表现出更强的鲁棒性，性能下降幅度明显小于其基础模型。这表明RL可能并非主要增强外部计划的执行，而是使模型能够更好地制定和遵循更适合其推理过程的内部策略。相反，我们观察到RL增强了模型将其所提供知识整合到其推理过程中的能力，从而在不同任务中实现了性能提升。我们还研究了难度，通过开发利用难题的新方法来改进训练。我们的发现为更规范地训练和评估推理模型奠定了基础。", "summary": "本研究提出了一个细粒度的分析框架，旨在深入理解强化学习（RL）如何影响大型语言模型（LLMs）的数学推理能力，超越了单纯的准确性指标。该框架考察了计划遵循、问题分解和知识利用等关键方面。研究结果表明，RL主要增强了LLMs制定和遵循内部策略的能力，而非执行外部计划，同时提升了其整合知识的能力。此外，研究还探讨了如何利用难题来优化模型训练，旨在为推理模型的训练和评估提供更具原则性的方法。", "keywords": "强化学习, 大型语言模型, 数学推理, 计划遵循, 知识利用"}}
{"id": "2506.04595", "pdf": "https://arxiv.org/pdf/2506.04595", "abs": "https://arxiv.org/abs/2506.04595", "authors": ["Ziqi Jia", "Anmin Wang", "Xiaoyang Qu", "Xiaowen Yang", "Jianzong Wang"], "title": "Hierarchical-Task-Aware Multi-modal Mixture of Incremental LoRA Experts for Embodied Continual Learning", "categories": ["cs.CV"], "comment": "Accepted by the 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025)", "summary": "Previous continual learning setups for embodied intelligence focused on\nexecuting low-level actions based on human commands, neglecting the ability to\nlearn high-level planning and multi-level knowledge. To address these issues,\nwe propose the Hierarchical Embodied Continual Learning Setups (HEC) that\ndivide the agent's continual learning process into two layers: high-level\ninstructions and low-level actions, and define five embodied continual learning\nsub-setups. Building on these setups, we introduce the Task-aware Mixture of\nIncremental LoRA Experts (Task-aware MoILE) method. This approach achieves task\nrecognition by clustering visual-text embeddings and uses both a task-level\nrouter and a token-level router to select the appropriate LoRA experts. To\neffectively address the issue of catastrophic forgetting, we apply Singular\nValue Decomposition (SVD) to the LoRA parameters obtained from prior tasks,\npreserving key components while orthogonally training the remaining parts. The\nexperimental results show that our method stands out in reducing the forgetting\nof old tasks compared to other methods, effectively supporting agents in\nretaining prior knowledge while continuously learning new tasks.", "AI": {"title_translation": "用于具身持续学习的分层任务感知多模态增量LoRA专家混合模型", "tldr": "本文提出了一种分层具身持续学习框架（HEC）和任务感知增量LoRA专家混合（Task-aware MoILE）方法，利用LoRA专家和SVD来解决具身智能体中的灾难性遗忘问题。", "motivation": "以往的具身持续学习设置侧重于基于人类指令执行低级动作，忽略了学习高级规划和多级知识的能力。", "method": "提出分层具身持续学习设置（HEC），将智能体持续学习过程分为高层指令和低层动作两层，并定义了五种具身持续学习子设置。在此基础上，引入了任务感知增量LoRA专家混合（Task-aware MoILE）方法。该方法通过聚类视觉-文本嵌入实现任务识别，并使用任务级路由器和标记级路由器选择合适的LoRA专家。为有效解决灾难性遗忘问题，对先前任务获得的LoRA参数应用奇异值分解（SVD），保留关键分量并正交训练剩余部分。", "result": "实验结果表明，与其他方法相比，该方法在减少旧任务遗忘方面表现突出，有效支持智能体在持续学习新任务的同时保留先验知识。", "conclusion": "本文提出的分层任务感知多模态增量LoRA专家混合模型，通过分层学习和利用SVD进行参数管理，有效缓解了具身持续学习中的灾难性遗忘问题，使智能体能够在获取新技能的同时保留先验知识。", "translation": "以往用于具身智能的持续学习设置侧重于基于人类指令执行低级动作，忽略了学习高级规划和多级知识的能力。为了解决这些问题，我们提出了分层具身持续学习设置（HEC），将智能体的持续学习过程分为两层：高级指令和低级动作，并定义了五种具身持续学习子设置。在此基础上，我们引入了任务感知增量LoRA专家混合（Task-aware MoILE）方法。该方法通过聚类视觉-文本嵌入实现任务识别，并使用任务级路由器和标记级路由器选择合适的LoRA专家。为有效解决灾难性遗忘问题，我们对从先前任务获得的LoRA参数应用奇异值分解（SVD），保留关键分量同时正交训练剩余部分。实验结果表明，与其他方法相比，我们的方法在减少旧任务遗忘方面表现突出，有效支持智能体在持续学习新任务的同时保留先验知识。", "summary": "本文提出了分层具身持续学习设置（HEC）和任务感知增量LoRA专家混合（Task-aware MoILE）方法，旨在解决以往具身持续学习在处理高级规划和多级知识方面的不足。MoILE方法通过视觉-文本嵌入聚类、多级路由器以及对LoRA参数应用SVD来缓解灾难性遗忘，实验证明其在保留旧任务知识方面表现优异。", "keywords": "具身持续学习, LoRA专家, 分层学习, 灾难性遗忘, 多模态"}}
{"id": "2506.04360", "pdf": "https://arxiv.org/pdf/2506.04360", "abs": "https://arxiv.org/abs/2506.04360", "authors": ["Philippe Chlenski", "Itsik Pe'er"], "title": "Even Faster Hyperbolic Random Forests: A Beltrami-Klein Wrapper Approach", "categories": ["cs.LG"], "comment": "15 pages, 4 figures, 2 tables", "summary": "Decision trees and models that use them as primitives are workhorses of\nmachine learning in Euclidean spaces. Recent work has further extended these\nmodels to the Lorentz model of hyperbolic space by replacing axis-parallel\nhyperplanes with homogeneous hyperplanes when partitioning the input space. In\nthis paper, we show how the hyperDT algorithm can be elegantly reexpressed in\nthe Beltrami-Klein model of hyperbolic spaces. This preserves the thresholding\noperation used in Euclidean decision trees, enabling us to further rewrite\nhyperDT as simple pre- and post-processing steps that form a wrapper around\nexisting tree-based models designed for Euclidean spaces. The wrapper approach\nunlocks many optimizations already available in Euclidean space models,\nimproving flexibility, speed, and accuracy while offering a simpler, more\nmaintainable, and extensible codebase. Our implementation is available at\nhttps://github.com/pchlenski/hyperdt.", "AI": {"title_translation": "甚至更快的双曲随机森林：一种 Beltrami-Klein 包装器方法", "tldr": "通过将欧几里得模型与 Beltrami-Klein 预处理和后处理相结合，改进了双曲决策树，从而实现更快、更灵活、更准确的结果。", "motivation": "为了提高双曲决策树（如 hyperDT）的性能和可维护性，需要利用欧几里得空间模型中已有的优化。", "method": "将 hyperDT 算法在双曲空间的 Beltrami-Klein 模型中重新表达，使其成为围绕现有欧几里得空间树模型的简单预处理和后处理步骤，从而形成一个包装器。", "result": "该包装器方法解锁了欧几里得空间模型中已有的许多优化，显著提高了灵活性、速度和准确性，并提供了更简单、更易于维护和可扩展的代码库。", "conclusion": "Beltrami-Klein 包装器方法通过利用现有的欧几里得模型，为实现双曲决策树提供了一种更高效、灵活和准确的方式，从而简化了开发和维护。", "translation": "决策树及其作为基元使用的模型是欧几里得空间中机器学习的主力。最近的工作通过在划分输入空间时用齐次超平面替换轴平行超平面，进一步将这些模型扩展到双曲空间的洛伦兹模型。在本文中，我们展示了如何在双曲空间的 Beltrami-Klein 模型中优雅地重新表达 hyperDT 算法。这保留了欧几里得决策树中使用的阈值操作，使我们能够将 hyperDT 进一步重写为简单的预处理和后处理步骤，形成一个围绕为欧几里得空间设计的现有基于树的模型。这种包装器方法解锁了欧几里得空间模型中已有的许多优化，提高了灵活性、速度和准确性，同时提供了更简单、更易于维护和可扩展的代码库。我们的实现可在 https://github.com/pchlenski/hyperdt 获取。", "summary": "本文介绍了一种新颖的双曲决策树（特别是 hyperDT）包装器方法，通过在 Beltrami-Klein 模型中重新表达它们。这种方法将 hyperDT 转化为围绕标准欧几里得树模型的预处理和后处理步骤，同时保留了关键操作。其主要优点是利用了欧几里得模型中已有的优化，从而在速度、灵活性、准确性和代码可维护性方面取得了显著改进，使得双曲随机森林甚至更快。", "keywords": "双曲随机森林, Beltrami-Klein 模型, 决策树, 包装器方法, 机器学习"}}
{"id": "2506.05101", "pdf": "https://arxiv.org/pdf/2506.05101", "abs": "https://arxiv.org/abs/2506.05101", "authors": ["Clément Pierquin", "Aurélien Bellet", "Marc Tommasi", "Matthieu Boussard"], "title": "Privacy Amplification Through Synthetic Data: Insights from Linear Regression", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": "26 pages, ICML 2025", "summary": "Synthetic data inherits the differential privacy guarantees of the model used\nto generate it. Additionally, synthetic data may benefit from privacy\namplification when the generative model is kept hidden. While empirical studies\nsuggest this phenomenon, a rigorous theoretical understanding is still lacking.\nIn this paper, we investigate this question through the well-understood\nframework of linear regression. First, we establish negative results showing\nthat if an adversary controls the seed of the generative model, a single\nsynthetic data point can leak as much information as releasing the model\nitself. Conversely, we show that when synthetic data is generated from random\ninputs, releasing a limited number of synthetic data points amplifies privacy\nbeyond the model's inherent guarantees. We believe our findings in linear\nregression can serve as a foundation for deriving more general bounds in the\nfuture.", "AI": {"title_translation": "通过合成数据实现隐私放大：来自线性回归的见解", "tldr": "本文通过线性回归框架研究了合成数据在生成模型隐藏时可能实现的隐私放大现象，并给出了在不同条件下（攻击者控制种子或随机输入）的理论结果。", "motivation": "经验研究表明，当生成模型隐藏时，合成数据可以受益于隐私放大，但目前缺乏严格的理论理解。", "method": "本文通过线性回归这一成熟的框架来研究隐私放大问题。", "result": "研究表明，如果攻击者控制生成模型的种子，单个合成数据点可以泄露与发布模型本身一样多的信息（负面结果）。相反，当合成数据由随机输入生成时，发布有限数量的合成数据点会使隐私在模型固有保证的基础上得到放大（正面结果）。", "conclusion": "线性回归中的研究结果可以为未来推导更通用的界限奠定基础。", "translation": "合成数据继承了用于生成它的模型的差分隐私保证。此外，当生成模型保持隐藏时，合成数据可能会受益于隐私放大。虽然经验研究表明了这种现象，但仍缺乏严格的理论理解。在本文中，我们通过线性回归这一成熟的框架来调查这个问题。首先，我们建立了负面结果，表明如果攻击者控制生成模型的种子，单个合成数据点可以泄露与发布模型本身一样多的信息。相反，我们表明，当合成数据由随机输入生成时，发布有限数量的合成数据点会使隐私在模型固有保证的基础上得到放大。我们相信，我们在线性回归中的发现可以为未来推导更通用的界限奠定基础。", "summary": "本研究通过线性回归框架，深入探讨了合成数据在生成模型隐藏时可能实现的隐私放大现象。研究发现，如果攻击者控制生成模型的种子，隐私放大效果不佳；但当合成数据由随机输入生成时，隐私可以得到显著放大。这些发现为未来更普遍的隐私界限提供了理论基础。", "keywords": "合成数据, 隐私放大, 差分隐私, 线性回归, 理论理解"}}
{"id": "2506.05092", "pdf": "https://arxiv.org/pdf/2506.05092", "abs": "https://arxiv.org/abs/2506.05092", "authors": ["Aneesh Deogan", "Wout Beks", "Peter Teurlings", "Koen de Vos", "Mark van den Brand", "Rene van de Molengraft"], "title": "Synthetic Dataset Generation for Autonomous Mobile Robots Using 3D Gaussian Splatting for Vision Training", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Annotated datasets are critical for training neural networks for object\ndetection, yet their manual creation is time- and labour-intensive, subjective\nto human error, and often limited in diversity. This challenge is particularly\npronounced in the domain of robotics, where diverse and dynamic scenarios\nfurther complicate the creation of representative datasets. To address this, we\npropose a novel method for automatically generating annotated synthetic data in\nUnreal Engine. Our approach leverages photorealistic 3D Gaussian splats for\nrapid synthetic data generation. We demonstrate that synthetic datasets can\nachieve performance comparable to that of real-world datasets while\nsignificantly reducing the time required to generate and annotate data.\nAdditionally, combining real-world and synthetic data significantly increases\nobject detection performance by leveraging the quality of real-world images\nwith the easier scalability of synthetic data. To our knowledge, this is the\nfirst application of synthetic data for training object detection algorithms in\nthe highly dynamic and varied environment of robot soccer. Validation\nexperiments reveal that a detector trained on synthetic images performs on par\nwith one trained on manually annotated real-world images when tested on robot\nsoccer match scenarios. Our method offers a scalable and comprehensive\nalternative to traditional dataset creation, eliminating the labour-intensive\nerror-prone manual annotation process. By generating datasets in a simulator\nwhere all elements are intrinsically known, we ensure accurate annotations\nwhile significantly reducing manual effort, which makes it particularly\nvaluable for robotics applications requiring diverse and scalable training\ndata.", "AI": {"title_translation": "使用3D高斯泼溅为视觉训练生成自主移动机器人合成数据集", "tldr": "本文提出了一种利用3D高斯泼溅在虚幻引擎中自动生成带标注的合成数据的方法，用于训练自主移动机器人，实验证明其性能可与真实数据集媲美，并显著减少数据生成和标注的时间。", "motivation": "手动创建用于对象检测的带标注数据集耗时费力、易受人为错误影响且多样性有限，尤其在机器人领域，多样化和动态的场景使创建具有代表性的数据集更加复杂。", "method": "提出了一种在虚幻引擎中自动生成带标注合成数据的新方法，该方法利用逼真的3D高斯泼溅进行快速合成数据生成。", "result": "合成数据集的性能可与真实世界数据集媲美，同时显著减少了数据生成和标注所需的时间。结合真实世界和合成数据可以显著提高对象检测性能。这是合成数据首次应用于机器人足球高度动态和多变环境中的对象检测算法训练。验证实验表明，在机器人足球比赛场景中，用合成图像训练的检测器与用手动标注的真实世界图像训练的检测器表现相当。", "conclusion": "该方法为传统数据集创建提供了一种可扩展且全面的替代方案，消除了劳动密集型、易出错的手动标注过程。通过在模拟器中生成数据集，确保了准确的标注，同时显著减少了手动工作量，这对于需要多样化和可扩展训练数据的机器人应用尤其有价值。", "translation": "带标注的数据集对于训练用于对象检测的神经网络至关重要，但其手动创建耗时费力、易受人为错误影响，并且通常多样性有限。这一挑战在机器人领域尤为突出，其中多样化和动态的场景进一步使得创建具有代表性的数据集变得复杂。为了解决这个问题，我们提出了一种在虚幻引擎中自动生成带标注合成数据的新方法。我们的方法利用逼真的3D高斯泼溅进行快速合成数据生成。我们证明合成数据集可以实现与真实世界数据集相当的性能，同时显著减少了生成和标注数据所需的时间。此外，结合真实世界和合成数据通过利用真实世界图像的质量和合成数据更易于扩展的优势，显著提高了对象检测性能。据我们所知，这是合成数据首次应用于机器人足球高度动态和多变环境中的对象检测算法训练。验证实验表明，在机器人足球比赛场景中，用合成图像训练的检测器与用手动标注的真实世界图像训练的检测器表现相当。我们的方法为传统数据集创建提供了一种可扩展且全面的替代方案，消除了劳动密集型、易出错的手动标注过程。通过在模拟器中生成数据集，其中所有元素都是内在已知的，我们确保了准确的标注，同时显著减少了手动工作量，这使得它对于需要多样化和可扩展训练数据的机器人应用尤其有价值。", "summary": "本研究提出了一种创新方法，利用3D高斯泼溅在虚幻引擎中自动生成用于自主移动机器人视觉训练的带标注合成数据集。该方法旨在解决手动数据标注耗时、易错且多样性不足的问题。实验结果表明，合成数据集的性能可与真实世界数据集相媲美，并且结合两者能进一步提升对象检测性能。该方法被首次应用于机器人足球领域，并经验证表现出与真实数据训练相当的效果，为机器人应用提供了可扩展且高效的数据集创建方案。", "keywords": "合成数据生成, 3D高斯泼溅, 机器人视觉训练, 对象检测, 数据集标注"}}
{"id": "2506.04734", "pdf": "https://arxiv.org/pdf/2506.04734", "abs": "https://arxiv.org/abs/2506.04734", "authors": ["Lin Sun", "Weihong Lin", "Jinzhu Wu", "Yongfu Zhu", "Xiaoqi Jian", "Guangxiang Zhao", "Change Jia", "Linglin Zhang", "Sai-er Hu", "Yuhan Wu", "Xiangzheng Zhang"], "title": "Evaluation is All You Need: Strategic Overclaiming of LLM Reasoning Capabilities Through Evaluation Design", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Reasoning models represented by the Deepseek-R1-Distill series have been\nwidely adopted by the open-source community due to their strong performance in\nmathematics, science, programming, and other domains. However, our study\nreveals that their benchmark evaluation results are subject to significant\nfluctuations caused by various factors. Subtle differences in evaluation\nconditions can lead to substantial variations in results. Similar phenomena are\nobserved in other open-source inference models fine-tuned based on the\nDeepseek-R1-Distill series, as well as in the QwQ-32B model, making their\nclaimed performance improvements difficult to reproduce reliably. Therefore, we\nadvocate for the establishment of a more rigorous paradigm for model\nperformance evaluation and present our empirical assessments of the\nDeepseek-R1-Distill series models.", "AI": {"title_translation": "评估是你所需要的一切：通过评估设计策略性夸大大型语言模型推理能力", "tldr": "LLM评估结果易受影响，导致性能夸大且难以复现，需更严格评估范式。", "motivation": "以Deepseek-R1-Distill系列为代表的推理模型虽然性能强大并被广泛采用，但其基准评估结果存在显著波动，且声称的性能提升难以可靠复现。", "method": "本研究通过实证评估揭示了Deepseek-R1-Distill系列模型、其他基于其微调的开源推理模型以及QwQ-32B模型在评估中存在的性能波动和复现性问题。", "result": "研究发现，评估条件的细微差异会导致结果的显著变化。Deepseek-R1-Distill系列模型及其衍生模型的性能提升难以可靠复现，这表明存在通过评估设计策略性夸大模型能力的问题。", "conclusion": "本研究倡导建立一个更严格、更可靠的模型性能评估范式，以解决当前评估中存在的波动性和不可复现性问题。", "translation": "以Deepseek-R1-Distill系列为代表的推理模型，因其在数学、科学、编程等领域的强大性能而被开源社区广泛采用。然而，我们的研究表明，它们的基准评估结果受到各种因素的影响，导致显著波动。评估条件的细微差异可能导致结果的巨大变化。在其他基于Deepseek-R1-Distill系列微调的开源推理模型以及QwQ-32B模型中也观察到类似现象，这使得它们声称的性能提升难以可靠复现。因此，我们倡导建立更严格的模型性能评估范式，并提出了我们对Deepseek-R1-Distill系列模型的实证评估。", "summary": "本研究揭示了Deepseek-R1-Distill系列等大语言模型在基准评估中存在的显著问题，即评估结果易受多种因素影响而大幅波动，且其声称的性能提升难以可靠复现。研究者观察到，即使是细微的评估条件差异也能导致结果的巨大变化，这一现象在其他基于Deepseek-R1-Distill系列微调的模型以及QwQ-32B模型中也普遍存在。因此，文章倡导建立一套更为严格的模型性能评估范式，并提供了对Deepseek-R1-Distill系列模型的实证评估结果。", "keywords": "大语言模型, 推理能力, 评估设计, 性能波动, 可复现性"}}
{"id": "2506.04606", "pdf": "https://arxiv.org/pdf/2506.04606", "abs": "https://arxiv.org/abs/2506.04606", "authors": ["Alexander Huang-Menders", "Xinhang Liu", "Andy Xu", "Yuyao Zhang", "Chi-Keung Tang", "Yu-Wing Tai"], "title": "SmartAvatar: Text- and Image-Guided Human Avatar Generation with VLM AI Agents", "categories": ["cs.CV"], "comment": "16 pages", "summary": "SmartAvatar is a vision-language-agent-driven framework for generating fully\nrigged, animation-ready 3D human avatars from a single photo or textual prompt.\nWhile diffusion-based methods have made progress in general 3D object\ngeneration, they continue to struggle with precise control over human identity,\nbody shape, and animation readiness. In contrast, SmartAvatar leverages the\ncommonsense reasoning capabilities of large vision-language models (VLMs) in\ncombination with off-the-shelf parametric human generators to deliver\nhigh-quality, customizable avatars. A key innovation is an autonomous\nverification loop, where the agent renders draft avatars, evaluates facial\nsimilarity, anatomical plausibility, and prompt alignment, and iteratively\nadjusts generation parameters for convergence. This interactive, AI-guided\nrefinement process promotes fine-grained control over both facial and body\nfeatures, enabling users to iteratively refine their avatars via\nnatural-language conversations. Unlike diffusion models that rely on static\npre-trained datasets and offer limited flexibility, SmartAvatar brings users\ninto the modeling loop and ensures continuous improvement through an LLM-driven\nprocedural generation and verification system. The generated avatars are fully\nrigged and support pose manipulation with consistent identity and appearance,\nmaking them suitable for downstream animation and interactive applications.\nQuantitative benchmarks and user studies demonstrate that SmartAvatar\noutperforms recent text- and image-driven avatar generation systems in terms of\nreconstructed mesh quality, identity fidelity, attribute accuracy, and\nanimation readiness, making it a versatile tool for realistic, customizable\navatar creation on consumer-grade hardware.", "AI": {"title_translation": "SmartAvatar：基于VLM AI代理的文本和图像引导人体虚拟形象生成", "tldr": "SmartAvatar是一个由视觉语言代理驱动的框架，能从单张照片或文本提示生成完全绑定、可用于动画的3D人体虚拟形象，通过迭代验证和精细控制，优于现有扩散模型。", "motivation": "现有的基于扩散的方法在精确控制人体身份、身体形状和动画准备方面存在困难，无法生成高质量、可定制的虚拟形象。", "method": "SmartAvatar利用大型视觉语言模型（VLMs）的常识推理能力，结合现成的参数化人体生成器。其核心创新是一个自主验证循环，代理会渲染草稿虚拟形象，评估面部相似性、解剖学合理性和提示对齐度，并迭代调整生成参数以实现收敛。这种交互式、AI引导的细化过程支持通过自然语言对话进行精细控制和迭代改进。", "result": "生成的虚拟形象是完全绑定的，支持姿势操作，并保持一致的身份和外观。定量基准测试和用户研究表明，SmartAvatar在重建网格质量、身份保真度、属性准确性和动画准备方面优于最近的文本和图像驱动虚拟形象生成系统，并且可以在消费级硬件上运行。", "conclusion": "SmartAvatar提供了一个多功能的工具，用于在消费级硬件上创建逼真、可定制的虚拟形象，通过将用户引入建模循环并利用LLM驱动的程序生成和验证系统，解决了现有扩散模型在精细控制和灵活性方面的局限性。", "translation": "SmartAvatar是一个由视觉语言代理驱动的框架，能从单张照片或文本提示生成完全绑定、可用于动画的3D人体虚拟形象。尽管基于扩散的方法在通用3D物体生成方面取得了进展，但它们在精确控制人体身份、身体形状和动画准备方面仍然存在困难。相比之下，SmartAvatar利用大型视觉语言模型（VLMs）的常识推理能力，结合现成的参数化人体生成器，提供高质量、可定制的虚拟形象。一个关键创新是自主验证循环，其中代理会渲染草稿虚拟形象，评估面部相似性、解剖学合理性和提示对齐度，并迭代调整生成参数以实现收敛。这种交互式、AI引导的细化过程促进了对面部和身体特征的精细控制，使用户能够通过自然语言对话迭代地完善其虚拟形象。与依赖静态预训练数据集且灵活性有限的扩散模型不同，SmartAvatar将用户引入建模循环，并通过LLM驱动的程序生成和验证系统确保持续改进。生成的虚拟形象是完全绑定的，支持姿势操作，并保持一致的身份和外观，使其适用于下游动画和交互式应用。定量基准测试和用户研究表明，SmartAvatar在重建网格质量、身份保真度、属性准确性和动画准备方面优于最近的文本和图像驱动虚拟形象生成系统，使其成为在消费级硬件上创建逼真、可定制虚拟形象的多功能工具。", "summary": "SmartAvatar是一个创新的视觉语言代理驱动框架，旨在解决现有扩散模型在生成高质量、可控3D人体虚拟形象方面的不足。它通过结合大型视觉语言模型和参数化人体生成器，并引入一个自主验证循环，实现了从单张照片或文本提示生成完全绑定、可用于动画的3D虚拟形象。该系统允许用户通过自然语言进行迭代细化，并显著提高了虚拟形象的网格质量、身份保真度、属性准确性和动画准备度，使其成为一个在消费级硬件上创建逼真、可定制虚拟形象的强大工具。", "keywords": "3D人体虚拟形象, 视觉语言模型, AI代理, 文本图像生成, 动画准备"}}
{"id": "2506.04377", "pdf": "https://arxiv.org/pdf/2506.04377", "abs": "https://arxiv.org/abs/2506.04377", "authors": ["Yasaman Mahdaviyeh", "James Lucas", "Mengye Ren", "Andreas S. Tolias", "Richard Zemel", "Toniann Pitassi"], "title": "Replay Can Provably Increase Forgetting", "categories": ["cs.LG"], "comment": "To appear in the Proceedings of the Conference on Lifelong Learning\n  Agents (CoLLAs) 2025", "summary": "Continual learning seeks to enable machine learning systems to solve an\nincreasing corpus of tasks sequentially. A critical challenge for continual\nlearning is forgetting, where the performance on previously learned tasks\ndecreases as new tasks are introduced. One of the commonly used techniques to\nmitigate forgetting, sample replay, has been shown empirically to reduce\nforgetting by retaining some examples from old tasks and including them in new\ntraining episodes. In this work, we provide a theoretical analysis of sample\nreplay in an over-parameterized continual linear regression setting, where each\ntask is given by a linear subspace and with enough replay samples, one would be\nable to eliminate forgetting. Our analysis focuses on sample replay and\nhighlights the role of the replayed samples and the relationship between task\nsubspaces. Surprisingly, we find that, even in a noiseless setting, forgetting\ncan be non-monotonic with respect to the number of replay samples. We present\ntasks where replay can be harmful with respect to worst-case settings, and also\nin distributional settings where replay of randomly selected samples increases\nforgetting in expectation. We also give empirical evidence that harmful replay\nis not limited to training with linear models by showing similar behavior for a\nneural networks equipped with SGD. Through experiments on a commonly used\nbenchmark, we provide additional evidence that, even in seemingly benign\nscenarios, performance of the replay heavily depends on the choice of replay\nsamples and the relationship between tasks.", "AI": {"title_translation": "重放可证明地增加遗忘", "tldr": "本研究理论分析并实证表明，在持续学习中，样本重放（一种常用的减少遗忘的技术）在某些情况下反而可能导致遗忘增加。", "motivation": "持续学习中的一个关键挑战是遗忘，即随着新任务的引入，系统在先前学习任务上的性能会下降。样本重放是缓解遗忘的常用技术之一，但其效果可能并非总是积极的。", "method": "本文在过参数化持续线性回归设置下对样本重放进行了理论分析，并提供了实证证据，包括对线性模型和使用SGD的神经网络进行实验，以及在常用基准上进行测试。", "result": "研究发现，即使在无噪声设置下，遗忘也可能与重放样本的数量呈非单调关系。在最坏情况和分布设置中，重放甚至可能有害，导致遗忘增加。实验证据表明，有害重放不仅限于线性模型，神经网络也表现出类似行为。重放的性能严重依赖于重放样本的选择以及任务之间的关系。", "conclusion": "样本重放作为一种持续学习中缓解遗忘的策略，其效果并非总是积极的，在某些情况下反而可能加剧遗忘。重放样本的选择和任务间的关系是影响重放性能的关键因素。", "translation": "持续学习旨在使机器学习系统能够按顺序解决越来越多的任务。持续学习的一个关键挑战是遗忘，即随着新任务的引入，先前学习任务的性能会下降。样本重放是减轻遗忘的常用技术之一，经验表明通过保留一些旧任务的示例并将其包含在新训练回合中可以减少遗忘。在这项工作中，我们对过参数化持续线性回归设置下的样本重放进行了理论分析，其中每个任务由一个线性子空间给出，并且有足够的重放样本，人们将能够消除遗忘。我们的分析侧重于样本重放，并强调了重放样本的作用以及任务子空间之间的关系。令人惊讶的是，我们发现，即使在无噪声设置下，遗忘也可能相对于重放样本的数量呈非单调性。我们提出了在最坏情况设置下重放可能有害的任务，以及在分布设置下重放随机选择的样本会增加预期遗忘的任务。我们还提供了经验证据，表明有害重放不限于线性模型的训练，通过展示使用SGD的神经网络的类似行为。通过在常用基准上的实验，我们提供了额外证据，表明即使在看似良性的情况下，重放的性能也严重依赖于重放样本的选择和任务之间的关系。", "summary": "本文对持续学习中常用的样本重放技术进行了理论和实证分析。与普遍认知不同，研究发现样本重放并非总能减少遗忘，在某些情况下反而可能导致遗忘增加，即使在无噪声或随机选择样本的条件下。这种有害效应在理论上和实验中均得到证实，并不仅限于线性模型，在神经网络中也存在。研究强调了重放样本的选择和任务间关系对重放性能的关键影响。", "keywords": "持续学习, 样本重放, 遗忘, 理论分析, 神经网络"}}
{"id": "2506.05106", "pdf": "https://arxiv.org/pdf/2506.05106", "abs": "https://arxiv.org/abs/2506.05106", "authors": ["Qianli Dong", "Xuebo Zhang", "Shiyong Zhang", "Ziyu Wang", "Zhe Ma", "Haobo Xi"], "title": "EDEN: Efficient Dual-Layer Exploration Planning for Fast UAV Autonomous Exploration in Large 3-D Environments", "categories": ["cs.RO"], "comment": null, "summary": "Efficient autonomous exploration in large-scale environments remains\nchallenging due to the high planning computational cost and low-speed\nmaneuvers. In this paper, we propose a fast and computationally efficient\ndual-layer exploration planning method. The insight of our dual-layer method is\nefficiently finding an acceptable long-term region routing and greedily\nexploring the target in the region of the first routing area with high speed.\nSpecifically, the proposed method finds the long-term area routing through an\napproximate algorithm to ensure real-time planning in large-scale environments.\nThen, the viewpoint in the first routing region with the lowest\ncurvature-penalized cost, which can effectively reduce decelerations caused by\nsharp turn motions, will be chosen as the next exploration target. To further\nspeed up the exploration, we adopt an aggressive and safe exploration-oriented\ntrajectory to enhance exploration continuity. The proposed method is compared\nto state-of-the-art methods in challenging simulation environments. The results\nshow that the proposed method outperforms other methods in terms of exploration\nefficiency, computational cost, and trajectory speed. We also conduct\nreal-world experiments to validate the effectiveness of the proposed method.\nThe code will be open-sourced.", "AI": {"title_translation": "EDEN：大型三维环境下无人机快速自主探索的高效双层探索规划", "tldr": "本文提出了一种高效的双层探索规划方法EDEN，用于解决大型三维环境中无人机自主探索的计算成本高和机动速度慢的挑战，通过近似算法实现实时长期区域路径规划，并选择曲率惩罚成本最低的视点作为探索目标，结合激进安全的探索导向轨迹，显著提高了探索效率、降低了计算成本并提升了轨迹速度。", "motivation": "在大型环境中进行高效的自主探索仍然具有挑战性，主要原因是规划计算成本高和低速机动。", "method": "本文提出了一种快速且计算高效的双层探索规划方法。该方法的关键在于高效地找到可接受的长期区域路径，并以高速贪婪地探索第一个路径区域中的目标。具体而言，该方法通过近似算法找到长期区域路径，以确保在大型环境中进行实时规划。然后，选择第一个路径区域中曲率惩罚成本最低的视点作为下一个探索目标，这可以有效减少急转弯引起的减速。为了进一步加快探索速度，我们采用了激进且安全的探索导向轨迹来增强探索的连续性。", "result": "所提出的方法在具有挑战性的模拟环境中与最先进的方法进行了比较。结果表明，所提出的方法在探索效率、计算成本和轨迹速度方面均优于其他方法。还进行了真实世界实验以验证所提出方法的有效性。", "conclusion": "本文提出的双层探索规划方法EDEN能够有效提高无人机在大型三维环境中的自主探索效率、降低计算成本并提升探索速度，并通过仿真和实际实验验证了其优越性。", "translation": "在大型环境中进行高效的自主探索仍然具有挑战性，原因在于高昂的规划计算成本和低速机动。在本文中，我们提出了一种快速且计算高效的双层探索规划方法。我们双层方法的洞察力在于高效地找到可接受的长期区域路径，并以高速贪婪地探索第一个路径区域中的目标。具体而言，所提出的方法通过近似算法找到长期区域路径，以确保在大型环境中的实时规划。然后，选择第一个路径区域中曲率惩罚成本最低的视点作为下一个探索目标，这可以有效减少急转弯引起的减速。为了进一步加快探索速度，我们采用了激进且安全的探索导向轨迹来增强探索的连续性。所提出的方法在具有挑战性的模拟环境中与最先进的方法进行了比较。结果表明，所提出的方法在探索效率、计算成本和轨迹速度方面均优于其他方法。我们还进行了真实世界实验以验证所提出方法的有效性。代码将开源。", "summary": "本文提出了一种名为EDEN的高效双层探索规划方法，旨在解决大型三维环境中无人机自主探索面临的计算成本高和机动速度慢的挑战。该方法通过近似算法实现实时长期区域路径规划，并在第一个路径区域中选择曲率惩罚成本最低的视点作为探索目标，同时采用激进且安全的探索导向轨迹以提高探索连续性。实验结果表明，EDEN在探索效率、计算成本和轨迹速度方面均优于现有方法，并已通过真实世界实验验证其有效性。", "keywords": "无人机, 自主探索, 双层规划, 路径规划, 大规模环境"}}
{"id": "2506.04756", "pdf": "https://arxiv.org/pdf/2506.04756", "abs": "https://arxiv.org/abs/2506.04756", "authors": ["Loan Dao", "Ngoc Quoc Ly"], "title": "Ontology-based knowledge representation for bone disease diagnosis: a foundation for safe and sustainable medical artificial intelligence systems", "categories": ["cs.AI", "cs.CV", "eess.IV"], "comment": null, "summary": "Medical artificial intelligence (AI) systems frequently lack systematic\ndomain expertise integration, potentially compromising diagnostic reliability.\nThis study presents an ontology-based framework for bone disease diagnosis,\ndeveloped in collaboration with Ho Chi Minh City Hospital for Traumatology and\nOrthopedics. The framework introduces three theoretical contributions: (1) a\nhierarchical neural network architecture guided by bone disease ontology for\nsegmentation-classification tasks, incorporating Visual Language Models (VLMs)\nthrough prompts, (2) an ontology-enhanced Visual Question Answering (VQA)\nsystem for clinical reasoning, and (3) a multimodal deep learning model that\nintegrates imaging, clinical, and laboratory data through ontological\nrelationships. The methodology maintains clinical interpretability through\nsystematic knowledge digitization, standardized medical terminology mapping,\nand modular architecture design. The framework demonstrates potential for\nextension beyond bone diseases through its standardized structure and reusable\ncomponents. While theoretical foundations are established, experimental\nvalidation remains pending due to current dataset and computational resource\nlimitations. Future work will focus on expanding the clinical dataset and\nconducting comprehensive system validation.", "AI": {"title_translation": "基于本体的骨病诊断知识表示：安全可持续医疗人工智能系统的基础", "tldr": "本研究提出一个基于本体的骨病诊断框架，旨在通过整合领域专业知识、引入分层神经网络、本体增强VQA和多模态深度学习模型来提高医疗AI系统的诊断可靠性，但实验验证仍在进行中。", "motivation": "医疗人工智能（AI）系统普遍缺乏系统的领域专业知识整合，这可能损害诊断的可靠性。", "method": "本研究提出了一个基于本体的骨病诊断框架，并与胡志明市创伤与骨科医院合作开发。该框架引入了三个理论贡献：1）由骨病本体引导的分层神经网络架构，用于分割-分类任务，通过提示符整合视觉语言模型（VLMs）；2）一个用于临床推理的本体增强视觉问答（VQA）系统；3）一个通过本体关系整合影像、临床和实验室数据的多模态深度学习模型。该方法通过系统知识数字化、标准化医学术语映射和模块化架构设计来保持临床可解释性。", "result": "该框架通过其标准化结构和可重用组件，展示了超越骨病诊断的扩展潜力。尽管理论基础已经建立，但由于当前数据集和计算资源的限制，实验验证仍在进行中。", "conclusion": "本研究建立了骨病诊断的本体理论基础框架，未来工作将侧重于扩展临床数据集并进行全面的系统验证。", "translation": "医疗人工智能（AI）系统普遍缺乏系统的领域专业知识整合，这可能损害诊断的可靠性。本研究提出了一个基于本体的骨病诊断框架，该框架是与胡志明市创伤与骨科医院合作开发的。该框架引入了三个理论贡献：1）由骨病本体引导的分层神经网络架构，用于分割-分类任务，通过提示符整合视觉语言模型（VLMs）；2）一个用于临床推理的本体增强视觉问答（VQA）系统；3）一个通过本体关系整合影像、临床和实验室数据的多模态深度学习模型。该方法通过系统知识数字化、标准化医学术语映射和模块化架构设计来保持临床可解释性。该框架通过其标准化结构和可重用组件，展示了超越骨病诊断的扩展潜力。尽管理论基础已经建立，但由于当前数据集和计算资源的限制，实验验证仍在进行中。未来的工作将侧重于扩展临床数据集并进行全面的系统验证。", "summary": "本研究提出了一个基于本体的骨病诊断框架，旨在解决医疗AI系统缺乏领域专业知识整合导致诊断可靠性受损的问题。该框架包含三个理论贡献：一个由骨病本体引导的分层神经网络架构、一个本体增强的视觉问答系统以及一个整合多模态数据的深度学习模型。该方法通过知识数字化、术语映射和模块化设计确保临床可解释性，并展现出超越骨病的扩展潜力。尽管理论基础已确立，但实验验证因资源限制尚未完成，未来将侧重于数据集扩展和系统验证。", "keywords": "本体, 骨病诊断, 医疗AI, 知识表示, 深度学习"}}
{"id": "2506.04612", "pdf": "https://arxiv.org/pdf/2506.04612", "abs": "https://arxiv.org/abs/2506.04612", "authors": ["Jinyoung Jun", "Lei Chu", "Jiahao Li", "Yan Lu", "Chang-Su Kim"], "title": "Perfecting Depth: Uncertainty-Aware Enhancement of Metric Depth", "categories": ["cs.CV"], "comment": null, "summary": "We propose a novel two-stage framework for sensor depth enhancement, called\nPerfecting Depth. This framework leverages the stochastic nature of diffusion\nmodels to automatically detect unreliable depth regions while preserving\ngeometric cues. In the first stage (stochastic estimation), the method\nidentifies unreliable measurements and infers geometric structure by leveraging\na training-inference domain gap. In the second stage (deterministic\nrefinement), it enforces structural consistency and pixel-level accuracy using\nthe uncertainty map derived from the first stage. By combining stochastic\nuncertainty modeling with deterministic refinement, our method yields dense,\nartifact-free depth maps with improved reliability. Experimental results\ndemonstrate its effectiveness across diverse real-world scenarios. Furthermore,\ntheoretical analysis, various experiments, and qualitative visualizations\nvalidate its robustness and scalability. Our framework sets a new baseline for\nsensor depth enhancement, with potential applications in autonomous driving,\nrobotics, and immersive technologies.", "AI": {"title_translation": "完善深度：不确定性感知度量深度增强", "tldr": "提出了一种两阶段框架“Perfecting Depth”，利用扩散模型增强传感器深度图，通过不确定性建模和确定性细化，提高深度图的可靠性、密度和无伪影性。", "motivation": "传感器深度图存在不可靠区域，需要一种有效的方法来增强其质量，以支持自动驾驶、机器人和沉浸式技术等应用。", "method": "提出了一种名为“Perfecting Depth”的两阶段框架。第一阶段（随机估计）利用扩散模型的随机性，通过训练-推理域差距识别不可靠测量并推断几何结构。第二阶段（确定性细化）利用第一阶段产生的不确定性图，强制执行结构一致性和像素级精度。", "result": "该方法能够生成密集、无伪影且可靠性更高的深度图。实验结果表明其在各种真实世界场景中有效，并通过理论分析、多项实验和定性可视化验证了其鲁棒性和可扩展性。", "conclusion": "该框架为传感器深度增强设定了新的基线，在自动驾驶、机器人和沉浸式技术等领域具有潜在应用。", "translation": "我们提出了一种新颖的两阶段传感器深度增强框架，名为“完善深度”（Perfecting Depth）。该框架利用扩散模型的随机性，在保留几何线索的同时自动检测不可靠的深度区域。在第一阶段（随机估计）中，该方法通过利用训练-推理域差距来识别不可靠的测量并推断几何结构。在第二阶段（确定性细化）中，它使用从第一阶段导出的不确定性图来强制执行结构一致性和像素级精度。通过将随机不确定性建模与确定性细化相结合，我们的方法产生了密集、无伪影且可靠性更高的深度图。实验结果证明了其在各种真实世界场景中的有效性。此外，理论分析、各种实验和定性可视化验证了其鲁棒性和可扩展性。我们的框架为传感器深度增强设定了新的基线，在自动驾驶、机器人和沉浸式技术中具有潜在应用。", "summary": "本文提出了一种名为“Perfecting Depth”的两阶段传感器深度增强框架。该框架结合了扩散模型的随机不确定性建模和确定性细化，旨在自动检测和完善不可靠的深度区域，同时保留几何线索。通过随机估计阶段识别不可靠测量并推断几何结构，以及确定性细化阶段强制结构一致性和像素级精度，该方法能够生成高质量、高可靠性的深度图，并在多项实验中展现出优异的性能和广泛的应用前景。", "keywords": "深度增强, 不确定性建模, 扩散模型, 两阶段框架, 传感器深度"}}
{"id": "2506.04398", "pdf": "https://arxiv.org/pdf/2506.04398", "abs": "https://arxiv.org/abs/2506.04398", "authors": ["Théo Vincent", "Yogesh Tripathi", "Tim Faust", "Yaniv Oren", "Jan Peters", "Carlo D'Eramo"], "title": "Bridging the Performance Gap Between Target-Free and Target-Based Reinforcement Learning With Iterated Q-Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In value-based reinforcement learning, removing the target network is\ntempting as the boostrapped target would be built from up-to-date estimates,\nand the spared memory occupied by the target network could be reallocated to\nexpand the capacity of the online network. However, eliminating the target\nnetwork introduces instability, leading to a decline in performance. Removing\nthe target network also means we cannot leverage the literature developed\naround target networks. In this work, we propose to use a copy of the last\nlinear layer of the online network as a target network, while sharing the\nremaining parameters with the up-to-date online network, hence stepping out of\nthe binary choice between target-based and target-free methods. It enables us\nto leverage the concept of iterated Q-learning, which consists of learning\nconsecutive Bellman iterations in parallel, to reduce the performance gap\nbetween target-free and target-based approaches. Our findings demonstrate that\nthis novel method, termed iterated Shared Q-Learning (iS-QL), improves the\nsample efficiency of target-free approaches across various settings.\nImportantly, iS-QL requires a smaller memory footprint and comparable training\ntime to classical target-based algorithms, highlighting its potential to scale\nreinforcement learning research.", "AI": {"title_translation": "使用迭代Q学习弥合无目标与基于目标的强化学习之间的性能差距", "tldr": "提出iS-QL，一种结合无目标和基于目标RL优点的方法，通过共享参数和迭代Q学习提高样本效率并减少内存占用，同时减少内存占用和训练时间。", "motivation": "在价值强化学习中，移除目标网络可以利用最新估计并节省内存，但会引入不稳定性并导致性能下降，同时无法利用围绕目标网络发展的现有文献。", "method": "提出迭代共享Q学习（iS-QL），该方法通过将在线网络最后一个线性层的副本作为目标网络，并与在线网络共享其余参数，从而摆脱了基于目标和无目标方法之间的二元选择。该方法利用迭代Q学习的概念，并行学习连续的Bellman迭代。", "result": "iS-QL提高了无目标方法的样本效率，并且内存占用更小，训练时间与经典基于目标算法相当。", "conclusion": "iS-QL有望扩展强化学习研究。", "translation": "在基于价值的强化学习中，移除目标网络很有吸引力，因为自举目标将基于最新估计构建，并且目标网络占用的节省内存可以重新分配以扩展在线网络的容量。然而，消除目标网络会引入不稳定性，导致性能下降。移除目标网络也意味着我们无法利用围绕目标网络开发的文献。在这项工作中，我们建议使用在线网络最后一个线性层的副本作为目标网络，同时与最新在线网络共享其余参数，从而摆脱了基于目标和无目标方法之间的二元选择。这使我们能够利用迭代Q学习的概念，该概念包括并行学习连续的Bellman迭代，以减少无目标和基于目标方法之间的性能差距。我们的研究结果表明，这种名为迭代共享Q学习（iS-QL）的新方法在各种设置下都提高了无目标方法的样本效率。重要的是，iS-QL需要更小的内存占用和与经典基于目标算法相当的训练时间，突出了其扩展强化学习研究的潜力。", "summary": "本文提出了一种名为迭代共享Q学习（iS-QL）的新方法，旨在解决无目标强化学习中因移除目标网络而导致的性能下降和不稳定性问题。iS-QL通过共享在线网络的大部分参数并仅复制最后一个线性层作为目标网络，结合迭代Q学习，有效弥合了无目标与基于目标方法之间的性能差距，显著提升了样本效率，并保持了较低的内存消耗和可比的训练时间，为强化学习研究的扩展提供了潜力。", "keywords": "强化学习, 目标网络, 迭代Q学习, 样本效率, iS-QL"}}
{"id": "2506.05115", "pdf": "https://arxiv.org/pdf/2506.05115", "abs": "https://arxiv.org/abs/2506.05115", "authors": ["Haoyu Wang", "Ruyi Zhou", "Liang Ding", "Tie Liu", "Zhelin Zhang", "Peng Xu", "Haibo Gao", "Zongquan Deng"], "title": "Whole-Body Constrained Learning for Legged Locomotion via Hierarchical Optimization", "categories": ["cs.RO"], "comment": null, "summary": "Reinforcement learning (RL) has demonstrated impressive performance in legged\nlocomotion over various challenging environments. However, due to the\nsim-to-real gap and lack of explainability, unconstrained RL policies deployed\nin the real world still suffer from inevitable safety issues, such as joint\ncollisions, excessive torque, or foot slippage in low-friction environments.\nThese problems limit its usage in missions with strict safety requirements,\nsuch as planetary exploration, nuclear facility inspection, and deep-sea\noperations. In this paper, we design a hierarchical optimization-based\nwhole-body follower, which integrates both hard and soft constraints into RL\nframework to make the robot move with better safety guarantees. Leveraging the\nadvantages of model-based control, our approach allows for the definition of\nvarious types of hard and soft constraints during training or deployment, which\nallows for policy fine-tuning and mitigates the challenges of sim-to-real\ntransfer. Meanwhile, it preserves the robustness of RL when dealing with\nlocomotion in complex unstructured environments. The trained policy with\nintroduced constraints was deployed in a hexapod robot and tested in various\noutdoor environments, including snow-covered slopes and stairs, demonstrating\nthe great traversability and safety of our approach.", "AI": {"title_translation": "基于分层优化的全身约束学习在足式机器人运动中的应用", "tldr": "本文提出了一种分层优化方法，将硬约束和软约束整合到强化学习框架中，以提高足式机器人在复杂环境中的安全性和鲁棒性，并成功在六足机器人上进行了验证。", "motivation": "强化学习在足式机器人运动中表现出色，但由于模拟到现实的差距和缺乏可解释性，未受约束的强化学习策略在实际部署中存在安全问题，如关节碰撞、扭矩过大或在低摩擦环境中的脚打滑，这限制了其在有严格安全要求的任务中的应用。", "method": "设计了一种基于分层优化的全身跟随器，将硬约束和软约束整合到强化学习框架中，利用基于模型的控制优势，允许在训练或部署期间定义各种类型的硬约束和软约束，从而进行策略微调并缓解模拟到现实的挑战。", "result": "所训练的带有约束的策略成功部署在六足机器人上，并在包括雪坡和楼梯在内的各种户外环境中进行了测试，展示了该方法出色的通过性和安全性。", "conclusion": "该方法通过引入分层优化和约束，显著提高了足式机器人在复杂环境中的安全性和鲁棒性，有效缓解了模拟到现实的差距问题。", "translation": "强化学习（RL）在各种挑战性环境中展示了足式运动的卓越性能。然而，由于模拟到现实的差距和缺乏可解释性，部署在现实世界中的无约束强化学习策略仍然面临不可避免的安全问题，例如关节碰撞、扭矩过大或在低摩擦环境中的脚打滑。这些问题限制了其在具有严格安全要求的任务中的使用，例如行星探索、核设施检查和深海作业。在本文中，我们设计了一个基于分层优化的全身跟随器，它将硬约束和软约束整合到强化学习框架中，以使机器人以更好的安全保证移动。利用基于模型控制的优势，我们的方法允许在训练或部署期间定义各种类型的硬约束和软约束，从而实现策略微调并减轻模拟到现实迁移的挑战。同时，它在处理复杂非结构化环境中的运动时保留了强化学习的鲁棒性。引入约束的训练策略部署在六足机器人上，并在包括雪坡和楼梯在内的各种户外环境中进行了测试，展示了我们方法的出色通过性和安全性。", "summary": "本文针对强化学习在足式机器人运动中存在的安全性和模拟到现实差距问题，提出了一种基于分层优化的全身约束学习方法。该方法将硬约束和软约束整合到强化学习框架中，利用模型基控制的优势，在训练和部署中定义约束，以提高策略的安全性和鲁棒性。实验证明，该方法在六足机器人上表现出良好的通过性和安全性。", "keywords": "足式运动, 强化学习, 全身约束, 分层优化, 安全性"}}
{"id": "2506.04828", "pdf": "https://arxiv.org/pdf/2506.04828", "abs": "https://arxiv.org/abs/2506.04828", "authors": ["Artem Latyshev", "Gregory Gorbov", "Aleksandr I. Panov"], "title": "Safe Planning and Policy Optimization via World Model Learning", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) applications in real-world scenarios must\nprioritize safety and reliability, which impose strict constraints on agent\nbehavior. Model-based RL leverages predictive world models for action planning\nand policy optimization, but inherent model inaccuracies can lead to\ncatastrophic failures in safety-critical settings. We propose a novel\nmodel-based RL framework that jointly optimizes task performance and safety. To\naddress world model errors, our method incorporates an adaptive mechanism that\ndynamically switches between model-based planning and direct policy execution.\nWe resolve the objective mismatch problem of traditional model-based approaches\nusing an implicit world model. Furthermore, our framework employs dynamic\nsafety thresholds that adapt to the agent's evolving capabilities, consistently\nselecting actions that surpass safe policy suggestions in both performance and\nsafety. Experiments demonstrate significant improvements over non-adaptive\nmethods, showing that our approach optimizes safety and performance\nsimultaneously rather than merely meeting minimum safety requirements. The\nproposed framework achieves robust performance on diverse safety-critical\ncontinuous control tasks, outperforming existing methods.", "AI": {"title_translation": "通过世界模型学习实现安全规划和策略优化", "tldr": "提出了一种新的模型基强化学习框架，通过自适应机制、隐式世界模型和动态安全阈值，同时优化任务性能和安全性，解决了真实世界RL应用中的安全问题。", "motivation": "强化学习在现实世界应用中需要优先考虑安全性和可靠性，但模型不准确会导致灾难性故障。传统模型基RL存在目标不匹配问题。", "method": "提出了一种新的模型基RL框架，联合优化任务性能和安全性。该方法包含一个自适应机制，动态切换模型基规划和直接策略执行；使用隐式世界模型解决目标不匹配问题；采用动态安全阈值，适应智能体的能力演变。", "result": "实验证明，该方法相比非自适应方法有显著改进，能同时优化安全性和性能，而非仅仅满足最低安全要求。在各种安全关键连续控制任务上表现出鲁棒性能，优于现有方法。", "conclusion": "提出的框架通过有效处理模型误差和动态调整安全约束，在安全关键的RL应用中实现了性能和安全性的同步优化，并超越了现有方法。", "translation": "强化学习 (RL) 在现实世界场景中的应用必须优先考虑安全性和可靠性，这会对智能体行为施加严格约束。模型基强化学习利用预测性世界模型进行行动规划和策略优化，但固有的模型不准确性可能导致安全关键设置中的灾难性故障。我们提出了一种新颖的模型基强化学习框架，该框架联合优化任务性能和安全性。为了解决世界模型误差，我们的方法整合了一个自适应机制，可以在模型基规划和直接策略执行之间动态切换。我们使用隐式世界模型解决了传统模型基方法的目标不匹配问题。此外，我们的框架采用动态安全阈值，这些阈值适应智能体不断演变的能力，始终选择在性能和安全性上都超越安全策略建议的行动。实验证明，与非自适应方法相比，我们的方法取得了显著改进，表明我们的方法是同时优化安全性和性能，而不仅仅是满足最低安全要求。所提出的框架在各种安全关键连续控制任务上实现了鲁棒性能，优于现有方法。", "summary": "本文提出了一种新颖的模型基强化学习框架，旨在解决现实世界RL应用中对安全性与可靠性的严格要求。该框架通过引入自适应机制在模型基规划与直接策略执行间动态切换，利用隐式世界模型解决传统方法的目标不匹配问题，并采用动态安全阈值以适应智能体能力演变。实验结果表明，该方法在各种安全关键连续控制任务上能够同时优化任务性能和安全性，显著优于非自适应及现有方法。", "keywords": "模型基强化学习, 安全性, 世界模型, 自适应机制, 动态安全阈值"}}
{"id": "2506.04619", "pdf": "https://arxiv.org/pdf/2506.04619", "abs": "https://arxiv.org/abs/2506.04619", "authors": ["Shihua Zhang", "Zizhuo Li", "Kaining Zhang", "Yifan Lu", "Yuxin Deng", "Linfeng Tang", "Xingyu Jiang", "Jiayi Ma"], "title": "Deep Learning Reforms Image Matching: A Survey and Outlook", "categories": ["cs.CV"], "comment": null, "summary": "Image matching, which establishes correspondences between two-view images to\nrecover 3D structure and camera geometry, serves as a cornerstone in computer\nvision and underpins a wide range of applications, including visual\nlocalization, 3D reconstruction, and simultaneous localization and mapping\n(SLAM). Traditional pipelines composed of ``detector-descriptor, feature\nmatcher, outlier filter, and geometric estimator'' falter in challenging\nscenarios. Recent deep-learning advances have significantly boosted both\nrobustness and accuracy. This survey adopts a unique perspective by\ncomprehensively reviewing how deep learning has incrementally transformed the\nclassical image matching pipeline. Our taxonomy highly aligns with the\ntraditional pipeline in two key aspects: i) the replacement of individual steps\nin the traditional pipeline with learnable alternatives, including learnable\ndetector-descriptor, outlier filter, and geometric estimator; and ii) the\nmerging of multiple steps into end-to-end learnable modules, encompassing\nmiddle-end sparse matcher, end-to-end semi-dense/dense matcher, and pose\nregressor. We first examine the design principles, advantages, and limitations\nof both aspects, and then benchmark representative methods on relative pose\nrecovery, homography estimation, and visual localization tasks. Finally, we\ndiscuss open challenges and outline promising directions for future research.\nBy systematically categorizing and evaluating deep learning-driven strategies,\nthis survey offers a clear overview of the evolving image matching landscape\nand highlights key avenues for further innovation.", "AI": {"title_translation": "深度学习改革图像匹配：一项调查与展望", "tldr": "本调查综述了深度学习如何逐步改变传统图像匹配流程，分类并评估了其策略，并展望了未来研究方向。", "motivation": "传统的图像匹配方法在复杂场景下表现不佳，而深度学习的进步显著提升了图像匹配的鲁棒性和准确性，因此需要对深度学习如何改革图像匹配进行全面回顾。", "method": "本综述采用独特视角，全面回顾了深度学习如何逐步改变经典的图像匹配流程。分类方法与传统流程高度一致，分为两个关键方面：i) 用可学习的替代方案替换传统流程中的各个步骤（如可学习的检测器-描述符、异常值过滤器、几何估计器）；ii) 将多个步骤合并到端到端可学习模块中（如中端稀疏匹配器、端到端半稠密/稠密匹配器、姿态回归器）。首先检查了这两种方法的设计原则、优点和局限性，然后对代表性方法在相对姿态恢复、单应性估计和视觉定位任务上进行了基准测试。", "result": "本综述通过系统地分类和评估深度学习驱动的策略，清晰地概述了不断发展的图像匹配领域，并强调了未来创新的关键途径。", "conclusion": "本综述讨论了开放挑战并概述了未来研究的有前景方向。", "translation": "图像匹配在两视图图像之间建立对应关系以恢复3D结构和相机几何，是计算机视觉的基石，并支撑着包括视觉定位、3D重建和同步定位与建图（SLAM）在内的广泛应用。由“检测器-描述符、特征匹配器、异常值过滤器和几何估计器”组成的传统流程在具有挑战性的场景中表现不佳。最近的深度学习进展显著提升了鲁棒性和准确性。本综述采用独特的视角，全面回顾了深度学习如何逐步改变经典的图像匹配流程。我们的分类法在两个关键方面与传统流程高度吻合：i) 用可学习的替代方案替换传统流程中的各个步骤，包括可学习的检测器-描述符、异常值过滤器和几何估计器；ii) 将多个步骤合并到端到端可学习模块中，包括中端稀疏匹配器、端到端半稠密/稠密匹配器和姿态回归器。我们首先检查了这两种方法的设计原则、优点和局限性，然后对代表性方法在相对姿态恢复、单应性估计和视觉定位任务上进行了基准测试。最后，我们讨论了开放挑战并概述了未来研究的有前景方向。通过系统地分类和评估深度学习驱动的策略，本综述清晰地概述了不断发展的图像匹配领域，并强调了未来创新的关键途径。", "summary": "本综述全面审视了深度学习如何逐步改革计算机视觉中的核心任务——图像匹配。文章系统地将深度学习方法分为替换传统流程中单个步骤的方案和合并多个步骤的端到端模块，并探讨了它们的设计、优缺点。通过对代表性方法进行基准测试，并讨论未来的开放挑战，本综述为图像匹配领域提供了清晰的概览及创新方向。", "keywords": "深度学习, 图像匹配, 计算机视觉, 综述, 3D重建"}}
{"id": "2506.04399", "pdf": "https://arxiv.org/pdf/2506.04399", "abs": "https://arxiv.org/abs/2506.04399", "authors": ["Suzan Ece Ada", "Emre Ugur"], "title": "Unsupervised Meta-Testing with Conditional Neural Processes for Hybrid Meta-Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Published in IEEE Robotics and Automation Letters Volume: 9, Issue:\n  10, 8427 - 8434, October 2024. 8 pages, 7 figures", "summary": "We introduce Unsupervised Meta-Testing with Conditional Neural Processes\n(UMCNP), a novel hybrid few-shot meta-reinforcement learning (meta-RL) method\nthat uniquely combines, yet distinctly separates, parameterized policy\ngradient-based (PPG) and task inference-based few-shot meta-RL. Tailored for\nsettings where the reward signal is missing during meta-testing, our method\nincreases sample efficiency without requiring additional samples in\nmeta-training. UMCNP leverages the efficiency and scalability of Conditional\nNeural Processes (CNPs) to reduce the number of online interactions required in\nmeta-testing. During meta-training, samples previously collected through PPG\nmeta-RL are efficiently reused for learning task inference in an offline\nmanner. UMCNP infers the latent representation of the transition dynamics model\nfrom a single test task rollout with unknown parameters. This approach allows\nus to generate rollouts for self-adaptation by interacting with the learned\ndynamics model. We demonstrate our method can adapt to an unseen test task\nusing significantly fewer samples during meta-testing than the baselines in\n2D-Point Agent and continuous control meta-RL benchmarks, namely, cartpole with\nunknown angle sensor bias, walker agent with randomized dynamics parameters.", "AI": {"title_translation": "用于混合元强化学习的无监督元测试与条件神经过程", "tldr": "UMCNP是一种新型混合少样本元强化学习方法，在元测试中奖励信号缺失的情况下，通过结合参数化策略梯度和任务推理，显著提高样本效率并减少在线交互。", "motivation": "在元测试中奖励信号缺失的环境下，现有的元强化学习方法可能样本效率低下。本研究旨在不增加元训练样本的情况下提高样本效率。", "method": "本研究引入了无监督元测试与条件神经过程（UMCNP），这是一种结合并区分参数化策略梯度（PPG）和基于任务推理的少样本元强化学习的方法。UMCNP利用条件神经过程（CNP）的效率和可扩展性来减少元测试中所需的在线交互次数。在元训练期间，通过PPG元RL收集的样本被高效地重用于离线学习任务推理。UMCNP从单个具有未知参数的测试任务rollout中推断出转移动力学模型的潜在表示，并通过与学习到的动力学模型交互来生成用于自我适应的rollout。", "result": "UMCNP在2D点代理和连续控制元RL基准测试（如未知角度传感器偏差的倒立摆、随机动力学参数的walker代理）中，能够在元测试期间使用比基线少得多的样本适应未见过的测试任务。", "conclusion": "UMCNP在无监督元测试设置下，通过利用条件神经过程和高效的样本重用，显著提高了元强化学习的样本效率和适应能力。", "translation": "我们引入了无监督元测试与条件神经过程（UMCNP），这是一种新颖的混合少样本元强化学习（meta-RL）方法，它独特地结合了参数化策略梯度（PPG）和基于任务推理的少样本元RL，同时又明确地将它们区分开来。该方法专为元测试期间奖励信号缺失的场景设计，在不增加元训练样本的情况下提高了样本效率。UMCNP利用条件神经过程（CNP）的效率和可扩展性来减少元测试中所需的在线交互次数。在元训练期间，通过PPG元RL预先收集的样本被高效地重用于离线学习任务推理。UMCNP从具有未知参数的单个测试任务rollout中推断出转移动力学模型的潜在表示。这种方法允许我们通过与学习到的动力学模型交互来生成用于自我适应的rollout。我们证明了我们的方法在2D点代理和连续控制元RL基准测试中，即具有未知角度传感器偏差的倒立摆和具有随机动力学参数的walker代理，在元测试期间使用比基线少得多的样本适应未见过的测试任务。", "summary": "本论文介绍了无监督元测试与条件神经过程（UMCNP），一种新颖的混合少样本元强化学习方法。该方法独特地结合并分离了参数化策略梯度和基于任务推理的元RL，特别适用于元测试中奖励信号缺失的场景。UMCNP利用条件神经过程提高样本效率，减少在线交互，并通过离线重用元训练样本进行任务推理。它能从单个测试任务rollout中推断动态模型的潜在表示，并生成rollout进行自我适应。实验证明，UMCNP在各种元RL基准测试中，能以显著更少的样本适应新任务，优于现有基线。", "keywords": "无监督元测试, 条件神经过程, 元强化学习, 样本效率, 少样本学习"}}
{"id": "2506.04278", "pdf": "https://arxiv.org/pdf/2506.04278", "abs": "https://arxiv.org/abs/2506.04278", "authors": ["Yumiko Nishiyama"], "title": "Redefining Functionality and Construction-Defining Capacity: Functions as Principles of Syntactic and Semantic Generation", "categories": ["cs.LO"], "comment": null, "summary": "This study redefines the notion of functionality-traditionally understood as\na property of mappings or structure preservation-from a more fundamental and\ngenerative perspective. Introducing the concept of a Construction-Defining\nfunction (CDF), we formalize functionality as a dual capacity to generate both\nsyntactic terms and semantic interpretations. We provide an explicit\naxiomatization of CDF based on syntactic generativity and semantic\ncompositionality, and further construct categorical models using initial\nalgebras and endofunctors to validate the generality of this concept. Through\ncomparative analysis with type theory, model theory, and formal semantics, we\ndemonstrate that functionality, in this enriched sense, serves as a\nfoundational principle for structural generation across diverse theoretical\ndomains. By reexamining the very nature of functions and their role in\nstructure formation, this work contributes to a unified understanding of\nlogic,semantics, and computation.", "AI": {"title_translation": "重新定义功能性和结构定义能力：作为句法和语义生成原则的函数", "tldr": "本研究从生成视角重新定义了“功能性”，将其形式化为一种生成句法项和语义解释的双重能力，并通过范畴模型验证其普遍性，旨在统一逻辑、语义和计算的理解。", "motivation": "传统上，功能性被理解为映射或结构保持的属性。本研究旨在从更基础和生成性的视角重新定义这一概念。", "method": "研究引入了“结构定义函数（CDF）”的概念，将功能性形式化为生成句法项和语义解释的双重能力。通过基于句法生成性和语义组合性的CDF显式公理化，并使用初始代数和自函子构建范畴模型以验证其普遍性。此外，还通过与类型理论、模型理论和形式语义学的比较分析来展示其应用。", "result": "研究表明，在这种丰富意义上的功能性，可以作为跨越不同理论领域结构生成的基础原则。", "conclusion": "通过重新审视函数的本质及其在结构形成中的作用，这项工作有助于对逻辑、语义和计算形成统一的理解。", "translation": "本研究从更基础和生成性的角度重新定义了功能性——传统上将其理解为映射或结构保持的属性。通过引入结构定义函数（CDF）的概念，我们将功能性形式化为一种生成句法项和语义解释的双重能力。我们基于句法生成性和语义组合性提供了CDF的显式公理化，并进一步使用初始代数和自函子构建了范畴模型，以验证这一概念的普遍性。通过与类型理论、模型理论和形式语义学的比较分析，我们证明了在这种丰富意义上的功能性，可以作为跨越不同理论领域结构生成的基础原则。通过重新审视函数的本质及其在结构形成中的作用，这项工作有助于对逻辑、语义和计算形成统一的理解。", "summary": "本研究重新定义了功能性，将其从传统的映射或结构保持属性扩展为一种生成句法项和语义解释的双重能力，并引入了结构定义函数（CDF）的概念。通过对CDF进行公理化并构建范畴模型，研究证明了这种新的功能性是跨理论领域结构生成的基础原则，从而促进了对逻辑、语义和计算的统一理解。", "keywords": "功能性, 结构定义函数, 句法生成, 语义解释, 范畴模型"}}
{"id": "2506.05117", "pdf": "https://arxiv.org/pdf/2506.05117", "abs": "https://arxiv.org/abs/2506.05117", "authors": ["Zihan Xu", "Mengxian Hu", "Kaiyan Xiao", "Qin Fang", "Chengju Liu", "Qijun Chen"], "title": "Realizing Text-Driven Motion Generation on NAO Robot: A Reinforcement Learning-Optimized Control Pipeline", "categories": ["cs.RO"], "comment": null, "summary": "Human motion retargeting for humanoid robots, transferring human motion data\nto robots for imitation, presents significant challenges but offers\nconsiderable potential for real-world applications. Traditionally, this process\nrelies on human demonstrations captured through pose estimation or motion\ncapture systems. In this paper, we explore a text-driven approach to mapping\nhuman motion to humanoids. To address the inherent discrepancies between the\ngenerated motion representations and the kinematic constraints of humanoid\nrobots, we propose an angle signal network based on norm-position and rotation\nloss (NPR Loss). It generates joint angles, which serve as inputs to a\nreinforcement learning-based whole-body joint motion control policy. The policy\nensures tracking of the generated motions while maintaining the robot's\nstability during execution. Our experimental results demonstrate the efficacy\nof this approach, successfully transferring text-driven human motion to a real\nhumanoid robot NAO.", "AI": {"title_translation": "在NAO机器人上实现文本驱动的动作生成：一种强化学习优化的控制流程", "tldr": "本文提出了一种基于强化学习的控制流程，通过文本驱动在NAO机器人上实现人体动作的生成和迁移。", "motivation": "人类动作重定向到人形机器人面临挑战，但具有巨大的实际应用潜力。传统方法依赖于人类演示，而本文旨在探索一种文本驱动的方法来克服这些限制。", "method": "提出了一种基于范数-位置和旋转损失（NPR Loss）的角度信号网络，用于生成关节角度。这些角度作为输入，送入一个基于强化学习的全身关节运动控制策略，该策略确保跟踪生成的动作，同时保持机器人在执行过程中的稳定性。", "result": "实验结果表明该方法有效，成功地将文本驱动的人体动作迁移到了真实的NAO人形机器人上。", "conclusion": "本文成功地实现了文本驱动的人体动作在NAO机器人上的生成和迁移，并通过强化学习优化的控制流程解决了运动表示与机器人运动学约束之间的差异，证明了该方法的有效性。", "translation": "人类动作重定向到人形机器人，即将人类动作数据转移到机器人进行模仿，带来了显著的挑战，但为实际应用提供了巨大的潜力。传统上，这一过程依赖于通过姿态估计或动作捕捉系统捕获的人类演示。在本文中，我们探索了一种文本驱动的方法来将人类动作映射到人形机器人。为了解决生成的动作表示与人形机器人运动学约束之间固有的差异，我们提出了一种基于范数-位置和旋转损失（NPR Loss）的角度信号网络。它生成关节角度，作为基于强化学习的全身关节运动控制策略的输入。该策略确保跟踪生成的动作，同时在执行过程中保持机器人的稳定性。我们的实验结果证明了这种方法的有效性，成功地将文本驱动的人类动作转移到了真实的NAO人形机器人上。", "summary": "本文提出了一种在NAO机器人上实现文本驱动动作生成的新方法。针对生成动作表示与机器人运动学约束之间的差异，引入了基于NPR损失的角度信号网络来生成关节角度。这些角度随后被输入到一个基于强化学习的全身关节运动控制策略中，以确保动作跟踪和机器人稳定性。实验证明，该方法能有效地将文本驱动的人类动作成功迁移到真实的NAO机器人上。", "keywords": "文本驱动动作生成, NAO机器人, 强化学习, 人形机器人, 动作重定向"}}
{"id": "2506.04849", "pdf": "https://arxiv.org/pdf/2506.04849", "abs": "https://arxiv.org/abs/2506.04849", "authors": ["Julien Soulé", "Jean-Paul Jamont", "Michel Occello", "Paul Théron", "Louis-Marie Traonouez"], "title": "Towards a Multi-Agent Simulation of Cyber-attackers and Cyber-defenders Battles", "categories": ["cs.AI"], "comment": null, "summary": "As cyber-attacks show to be more and more complex and coordinated,\ncyber-defenders strategy through multi-agent approaches could be key to tackle\nagainst cyber-attacks as close as entry points in a networked system. This\npaper presents a Markovian modeling and implementation through a simulator of\nfighting cyber-attacker agents and cyber-defender agents deployed on host\nnetwork nodes. It aims to provide an experimental framework to implement\nrealistically based coordinated cyber-attack scenarios while assessing\ncyber-defenders dynamic organizations. We abstracted network nodes by sets of\nproperties including agents' ones. Actions applied by agents model how the\nnetwork reacts depending in a given state and what properties are to change.\nCollective choice of the actions brings the whole environment closer or farther\nfrom respective cyber-attackers and cyber-defenders goals. Using the simulator,\nwe implemented a realistically inspired scenario with several behavior\nimplementation approaches for cyber-defenders and cyber-attackers.", "AI": {"title_translation": "迈向网络攻击者与网络防御者对抗的多智能体模拟", "tldr": "本文通过马尔可夫模型和模拟器，实现了网络攻击者和防御者的多智能体对抗模拟，旨在提供一个评估防御者动态组织能力的实验框架。", "motivation": "鉴于网络攻击日益复杂和协调，通过多智能体方法应对网络攻击，尤其是在网络系统入口点附近，对于网络防御策略至关重要。", "method": "本文提出了一种通过模拟器实现的马尔可夫模型，用于模拟部署在主机网络节点上的网络攻击者和防御者智能体之间的对抗。网络节点被抽象为一组属性，智能体的行动建模了网络如何根据给定状态和属性变化做出反应。", "result": "论文使用该模拟器，实现了一个受现实启发的场景，其中包含多种网络防御者和攻击者的行为实现方法。具体的实验结果或评估数据未在摘要中提及。", "conclusion": "摘要中未明确提及结论。论文旨在提供一个实验框架，以实现基于现实的协调网络攻击场景，同时评估网络防御者的动态组织。", "translation": "随着网络攻击变得越来越复杂和协调，通过多智能体方法应对网络攻击，尤其是在网络系统入口点附近，可能是网络防御策略的关键。本文提出了一种通过模拟器实现的马尔可夫模型，用于模拟部署在主机网络主机节点上的网络攻击者智能体和网络防御者智能体之间的对抗。它旨在提供一个实验框架，以实现基于现实的协调网络攻击场景，同时评估网络防御者的动态组织。我们将网络节点抽象为一组属性，包括智能体自身的属性。智能体应用的行动模型化了网络如何根据给定状态做出反应以及哪些属性将发生变化。行动的集体选择使整个环境更接近或远离各自的网络攻击者和网络防御者的目标。使用该模拟器，我们实现了一个受现实启发的场景，其中包含网络防御者和网络攻击者的几种行为实现方法。", "summary": "本文旨在应对日益复杂的网络攻击，提出了一种基于马尔可夫模型的多智能体模拟器，用于模拟网络攻击者和防御者在网络节点上的对抗。该模拟器提供了一个实验框架，以实现和评估真实的协调网络攻击场景及防御者的动态组织能力。", "keywords": "多智能体模拟, 网络攻击, 网络防御, 马尔可夫模型, 实验框架"}}
{"id": "2506.04633", "pdf": "https://arxiv.org/pdf/2506.04633", "abs": "https://arxiv.org/abs/2506.04633", "authors": ["Linjie Li", "Mahtab Bigverdi", "Jiawei Gu", "Zixian Ma", "Yinuo Yang", "Ziang Li", "Yejin Choi", "Ranjay Krishna"], "title": "Unfolding Spatial Cognition: Evaluating Multimodal Models on Visual Simulations", "categories": ["cs.CV"], "comment": "STARE is available at https://github.com/STARE-bench/STARE", "summary": "Spatial cognition is essential for human intelligence, enabling\nproblem-solving through visual simulations rather than solely relying on verbal\nreasoning. However, existing AI benchmarks primarily assess verbal reasoning,\nneglecting the complexities of non-verbal, multi-step visual simulation. We\nintroduce STARE(Spatial Transformations and Reasoning Evaluation), a benchmark\ndesigned to rigorously evaluate multimodal large language models on tasks\nbetter solved through multi-step visual simulation. STARE features 4K tasks\nspanning foundational geometric transformations (2D and 3D), integrated spatial\nreasoning (cube net folding and tangram puzzles), and real-world spatial\nreasoning (perspective and temporal reasoning), reflecting practical cognitive\nchallenges like object assembly, mechanical diagram interpretation, and\neveryday spatial navigation. Our evaluations show that models excel at\nreasoning over simpler 2D transformations, but perform close to random chance\non more complex tasks like 3D cube net folding and tangram puzzles that require\nmulti-step visual simulations. Humans achieve near-perfect accuracy but take\nconsiderable time (up to 28.9s) on complex tasks, significantly speeding up\n(down by 7.5 seconds on average) with intermediate visual simulations. In\ncontrast, models exhibit inconsistent performance gains from visual\nsimulations, improving on most tasks but declining in specific cases like\ntangram puzzles (GPT-4o, o1) and cube net folding (Claude-3.5, Gemini-2.0\nFlash), indicating that models may not know how to effectively leverage\nintermediate visual information.", "AI": {"title_translation": "展开空间认知：评估多模态模型在视觉模拟上的表现", "tldr": "现有AI基准偏重语言推理，忽略视觉模拟。本文提出STARE基准，评估多模态大模型在视觉模拟任务上的表现。结果显示，模型在简单2D任务上表现良好，但在复杂多步视觉模拟任务（如3D折叠）上表现不佳，且未能有效利用中间视觉信息，而人类表现优异。", "motivation": "现有的AI基准主要评估语言推理能力，但忽视了非语言、多步骤视觉模拟的复杂性，而空间认知对人类智能至关重要，它通过视觉模拟而非单纯的语言推理来解决问题。", "method": "本文引入了STARE（空间转换与推理评估）基准，旨在严格评估多模态大语言模型在需要多步视觉模拟才能更好解决的任务上的表现。STARE包含4K个任务，涵盖基础几何变换（2D和3D）、综合空间推理（立方体展开图折叠和七巧板拼图）以及现实世界空间推理（透视和时间推理）。", "result": "评估结果显示，模型在简单的2D变换推理上表现出色，但在需要多步视觉模拟的更复杂任务（如3D立方体展开图折叠和七巧板拼图）上表现接近随机。人类在复杂任务上能达到近乎完美的准确率，但需要相当长的时间（长达28.9秒），通过中间视觉模拟可以显著加速（平均加快7.5秒）。相比之下，模型从视觉模拟中获得的性能提升不一致，在大多数任务上有所改进，但在特定情况下（如七巧板拼图的GPT-4o和o1，立方体展开图折叠的Claude-3.5和Gemini-2.0 Flash）却有所下降。", "conclusion": "模型可能不知道如何有效地利用中间视觉信息来解决复杂的空间认知任务，这表明现有模型在处理非语言、多步视觉模拟方面仍有显著不足。", "translation": "空间认知对人类智能至关重要，它通过视觉模拟而非单纯的语言推理来解决问题。然而，现有的AI基准主要评估语言推理，忽视了非语言、多步骤视觉模拟的复杂性。我们引入了STARE（空间转换与推理评估），这是一个旨在严格评估多模态大语言模型在通过多步视觉模拟能更好解决的任务上的基准。STARE包含4K个任务，涵盖基础几何变换（2D和3D）、综合空间推理（立方体展开图折叠和七巧板拼图）以及现实世界空间推理（透视和时间推理），反映了实际的认知挑战，如物体组装、机械图解解释和日常空间导航。我们的评估显示，模型在对更简单的2D变换进行推理时表现出色，但在需要多步视觉模拟的更复杂任务（如3D立方体展开图折叠和七巧板拼图）上表现接近随机。人类能达到近乎完美的准确率，但在复杂任务上需要相当长的时间（长达28.9秒），通过中间视觉模拟可以显著加速（平均加快7.5秒）。相比之下，模型从视觉模拟中获得的性能提升不一致，在大多数任务上有所改进，但在特定情况下（如七巧板拼图的GPT-4o、o1）和立方体展开图折叠（Claude-3.5、Gemini-2.0 Flash）却有所下降，这表明模型可能不知道如何有效地利用中间视觉信息。", "summary": "本文针对现有AI基准忽视非语言、多步视觉模拟的不足，引入了STARE基准以评估多模态大模型在空间认知任务上的表现。STARE包含2D/3D几何变换、立方体折叠和七巧板等任务。研究发现，模型在简单2D任务上表现尚可，但在需要多步视觉模拟的复杂任务上表现接近随机，且未能有效利用中间视觉信息，而人类在此类任务上表现优异。这表明多模态模型在真正的视觉空间推理方面仍面临挑战。", "keywords": "空间认知, 多模态模型, 视觉模拟, STARE基准, 视觉推理"}}
{"id": "2506.04411", "pdf": "https://arxiv.org/pdf/2506.04411", "abs": "https://arxiv.org/abs/2506.04411", "authors": ["Achleshwar Luthra", "Tianbao Yang", "Tomer Galanti"], "title": "Self-Supervised Contrastive Learning is Approximately Supervised Contrastive Learning", "categories": ["cs.LG"], "comment": null, "summary": "Despite its empirical success, the theoretical foundations of self-supervised\ncontrastive learning (CL) are not yet fully established. In this work, we\naddress this gap by showing that standard CL objectives implicitly approximate\na supervised variant we call the negatives-only supervised contrastive loss\n(NSCL), which excludes same-class contrasts. We prove that the gap between the\nCL and NSCL losses vanishes as the number of semantic classes increases, under\na bound that is both label-agnostic and architecture-independent.\n  We characterize the geometric structure of the global minimizers of the NSCL\nloss: the learned representations exhibit augmentation collapse, within-class\ncollapse, and class centers that form a simplex equiangular tight frame. We\nfurther introduce a new bound on the few-shot error of linear-probing. This\nbound depends on two measures of feature variability--within-class dispersion\nand variation along the line between class centers. We show that directional\nvariation dominates the bound and that the within-class dispersion's effect\ndiminishes as the number of labeled samples increases. These properties enable\nCL and NSCL-trained representations to support accurate few-shot label recovery\nusing simple linear probes.\n  Finally, we empirically validate our theoretical findings: the gap between CL\nand NSCL losses decays at a rate of $\\mathcal{O}(\\frac{1}{\\#\\text{classes}})$;\nthe two losses are highly correlated; minimizing the CL loss implicitly brings\nthe NSCL loss close to the value achieved by direct minimization; and the\nproposed few-shot error bound provides a tight estimate of probing performance\nin practice.", "AI": {"title_translation": "自监督对比学习近似于监督对比学习", "tldr": "自监督对比学习目标隐式地近似于一种名为“仅负例监督对比损失”（NSCL）的监督变体，且随着语义类数量的增加，两者之间的差距消失。", "motivation": "自监督对比学习（CL）尽管取得了经验上的成功，但其理论基础尚未完全确立。本文旨在弥补这一空白。", "method": "通过理论分析和证明，本文展示了标准CL目标隐式地近似于一种名为“仅负例监督对比损失”（NSCL）的监督变体。研究了NSCL损失的全局最小值的几何结构，并引入了线性探测少样本误差的新界限。最后，通过经验验证了理论发现。", "result": "1. 标准CL目标隐式地近似于仅负例监督对比损失（NSCL），且随着语义类数量的增加，两者之间的差距消失，该界限与标签和架构无关。2. NSCL损失的全局最小化器学习到的表示展现出增强坍缩、类内坍缩和类中心形成单纯形等角紧框架的几何结构。3. 提出了一个新的线性探测少样本误差界限，该界限取决于特征变异的两个度量：类内离散度和类中心之间沿线的变异。方向变异在界限中占主导地位，类内离散度的影响随着标记样本数量的增加而减小。4. 经验验证了CL和NSCL损失之间的差距以$\\mathcal{O}(\\frac{1}{\\#\\text{classes}})$的速度衰减，两者高度相关，最小化CL损失隐式地使NSCL损失接近通过直接最小化获得的值，并且所提出的少样本误差界限提供了对实践中探测性能的紧密估计。", "conclusion": "自监督对比学习在理论上近似于一种监督变体，其学习到的表示具有支持准确少样本标签恢复的特性，并且其理论发现得到了经验验证。", "translation": "尽管自监督对比学习（CL）取得了经验上的成功，但其理论基础尚未完全确立。在这项工作中，我们通过证明标准CL目标隐式地近似于我们称之为“仅负例监督对比损失”（NSCL）的监督变体（该变体排除了同类对比），来弥补这一空白。我们证明，在与标签无关且与架构无关的界限下，随着语义类数量的增加，CL和NSCL损失之间的差距会消失。我们描述了NSCL损失的全局最小值的几何结构：学习到的表示表现出增强坍缩、类内坍缩，并且类中心形成一个单纯形等角紧框架。我们进一步引入了线性探测少样本误差的新界限。这个界限取决于特征变异的两个度量——类内离散度和类中心之间沿线的变异。我们发现方向变异在界限中占主导地位，并且类内离散度的影响随着标记样本数量的增加而减小。这些特性使得CL和NSCL训练的表示能够通过简单的线性探测支持准确的少样本标签恢复。最后，我们通过实验验证了我们的理论发现：CL和NSCL损失之间的差距以$\\mathcal{O}(\\frac{1}{\\#\\text{classes}})$的速度衰减；两种损失高度相关；最小化CL损失隐式地使NSCL损失接近通过直接最小化获得的值；并且所提出的少样本误差界限在实践中提供了对探测性能的紧密估计。", "summary": "本文从理论上证明了自监督对比学习（CL）目标隐式地近似于一种名为“仅负例监督对比损失”（NSCL）的监督变体，并指出随着语义类数量的增加，两者之间的差距会消失。研究揭示了NSCL损失全局最小值的几何结构，并提出了一个新的线性探测少样本误差界限，解释了CL和NSCL训练的表示如何支持准确的少样本学习。实验结果进一步验证了这些理论发现。", "keywords": "自监督学习, 对比学习, 理论分析, 少样本学习, 几何结构"}}
{"id": "2506.05165", "pdf": "https://arxiv.org/pdf/2506.05165", "abs": "https://arxiv.org/abs/2506.05165", "authors": ["Dongwoo Son", "Suhan Park"], "title": "LiPo: A Lightweight Post-optimization Framework for Smoothing Action Chunks Generated by Learned Policies", "categories": ["cs.RO"], "comment": "6 pages, 7 figures, 1 table", "summary": "Recent advances in imitation learning have enabled robots to perform\nincreasingly complex manipulation tasks in unstructured environments. However,\nmost learned policies rely on discrete action chunking, which introduces\ndiscontinuities at chunk boundaries. These discontinuities degrade motion\nquality and are particularly problematic in dynamic tasks such as throwing or\nlifting heavy objects, where smooth trajectories are critical for momentum\ntransfer and system stability. In this work, we present a lightweight\npost-optimization framework for smoothing chunked action sequences. Our method\ncombines three key components: (1) inference-aware chunk scheduling to\nproactively generate overlapping chunks and avoid pauses from inference delays;\n(2) linear blending in the overlap region to reduce abrupt transitions; and (3)\njerk-minimizing trajectory optimization constrained within a bounded\nperturbation space. The proposed method was validated on a position-controlled\nrobotic arm performing dynamic manipulation tasks. Experimental results\ndemonstrate that our approach significantly reduces vibration and motion\njitter, leading to smoother execution and improved mechanical robustness.", "AI": {"title_translation": "LiPo：一种用于平滑学习策略生成的动作块的轻量级后优化框架", "tldr": "该研究提出了一种轻量级后优化框架LiPo，用于平滑机器人学习策略产生的离散动作块，从而提高运动质量和系统稳定性。", "motivation": "现有的模仿学习策略依赖于离散动作块，这在块边界处引入了不连续性，从而降低了运动质量，尤其是在需要平滑轨迹的动态任务中（如投掷或举起重物）影响动量传递和系统稳定性。", "method": "提出了一种轻量级后优化框架，包含三个关键组件：1) 推理感知块调度，主动生成重叠块并避免推理延迟造成的停顿；2) 在重叠区域进行线性混合，减少突变；3) 在有界扰动空间内进行抖动最小化轨迹优化。", "result": "实验结果表明，该方法显著减少了振动和运动抖动，实现了更平滑的执行和提高了机械鲁棒性。", "conclusion": "LiPo框架通过其创新的调度、混合和优化组件，成功解决了学习策略中动作块不连续性问题，显著提升了机器人动态操作的运动平滑性和机械鲁棒性。", "translation": "近年来模仿学习的进步使机器人能够在非结构化环境中执行日益复杂的操纵任务。然而，大多数学习策略依赖于离散动作块，这在块边界处引入了不连续性。这些不连续性会降低运动质量，在投掷或举起重物等动态任务中尤其成问题，因为在这些任务中，平滑的轨迹对于动量传递和系统稳定性至关重要。在这项工作中，我们提出了一种用于平滑分块动作序列的轻量级后优化框架。我们的方法结合了三个关键组件：(1) 推理感知块调度，主动生成重叠块并避免推理延迟造成的停顿；(2) 在重叠区域进行线性混合，以减少突变；以及 (3) 在有界扰动空间内进行抖动最小化轨迹优化。所提出的方法在执行动态操纵任务的位置控制机械臂上进行了验证。实验结果表明，我们的方法显著减少了振动和运动抖动，从而实现了更平滑的执行和提高了机械鲁棒性。", "summary": "本文介绍了LiPo，一个轻量级的后优化框架，旨在解决模仿学习策略中离散动作块导致的不连续性问题。LiPo通过推理感知块调度、线性混合和抖动最小化轨迹优化，显著改善了机器人动态操作中的运动平滑性、减少了振动和抖动，并提升了机械鲁棒性。", "keywords": "动作块平滑, 后优化, 机器人操作, 模仿学习, 轨迹优化"}}
{"id": "2506.04867", "pdf": "https://arxiv.org/pdf/2506.04867", "abs": "https://arxiv.org/abs/2506.04867", "authors": ["Jônata Tyska Carvalho", "Stefano Nolfi"], "title": "LLMs for sensory-motor control: Combining in-context and iterative learning", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.RO"], "comment": "24 pages (13 pages are from appendix), 6 figures, code for\n  experiments replication and supplementary material provided at\n  https://github.com/jtyska/llm-robotics-article/", "summary": "We propose a method that enables large language models (LLMs) to control\nembodied agents by directly mapping continuous observation vectors to\ncontinuous action vectors. Initially, the LLMs generate a control strategy\nbased on a textual description of the agent, its environment, and the intended\ngoal. This strategy is then iteratively refined through a learning process in\nwhich the LLMs are repeatedly prompted to improve the current strategy, using\nperformance feedback and sensory-motor data collected during its evaluation.\nThe method is validated on classic control tasks from the Gymnasium library and\nthe inverted pendulum task from the MuJoCo library. In most cases, it\nsuccessfully identifies optimal or high-performing solutions by integrating\nsymbolic knowledge derived through reasoning with sub-symbolic sensory-motor\ndata gathered as the agent interacts with its environment.", "AI": {"title_translation": "LLMs用于感觉-运动控制：结合情境学习与迭代学习", "tldr": "本研究提出一种方法，使大型语言模型（LLMs）能够通过结合情境学习和迭代学习，直接控制具身智能体进行感觉-运动控制。", "motivation": "使大型语言模型（LLMs）能够直接控制具身智能体，将连续观察向量映射到连续动作向量，并解决如何整合符号知识推理与子符号感觉-运动数据的问题。", "method": "提出一种方法，LLMs首先基于文本描述（智能体、环境、目标）生成初始控制策略。然后，通过一个迭代学习过程对策略进行细化，LLMs根据性能反馈和评估期间收集的感觉-运动数据，反复被提示以改进当前策略。", "result": "在大多数情况下，该方法通过整合推理得出的符号知识与智能体在环境中交互时收集的子符号感觉-运动数据，成功识别出最优或高性能的解决方案。在Gymnasium和MuJoCo库的经典控制任务中得到了验证。", "conclusion": "该方法有效地使大型语言模型能够控制具身智能体，通过结合情境学习和迭代学习，将符号推理与实际交互中收集的感觉-运动数据相结合，从而找到最优或高性能的控制策略。", "translation": "我们提出一种方法，使大型语言模型（LLMs）能够通过直接将连续观察向量映射到连续动作向量来控制具身智能体。最初，LLMs根据智能体、其环境和预期目标的文本描述生成一个控制策略。然后，通过一个学习过程对该策略进行迭代细化，在此过程中，LLMs被反复提示以改进当前策略，并利用其评估期间收集的性能反馈和感觉-运动数据。该方法在Gymnasium库的经典控制任务和MuJoCo库的倒立摆任务上得到了验证。在大多数情况下，它通过将通过推理获得的符号知识与智能体与其环境交互时收集的子符号感觉-运动数据相结合，成功识别出最优或高性能的解决方案。", "summary": "本文提出一种使大型语言模型（LLMs）能够直接控制具身智能体的方法。该方法首先利用LLMs根据文本描述生成初步控制策略，随后通过迭代学习过程，结合性能反馈和实际收集的感觉-运动数据对策略进行持续优化。实验验证表明，此方法能有效整合符号知识与子符号数据，在经典控制任务中找到最优或高性能解决方案。", "keywords": "LLMs, 感觉-运动控制, 具身智能体, 迭代学习, 情境学习"}}
{"id": "2506.04641", "pdf": "https://arxiv.org/pdf/2506.04641", "abs": "https://arxiv.org/abs/2506.04641", "authors": ["Qiming Hu", "Linlong Fan", "Yiyan Luo", "Yuhang Yu", "Xiaojie Guo", "Qingnan Fan"], "title": "Text-Aware Real-World Image Super-Resolution via Diffusion Model with Joint Segmentation Decoders", "categories": ["cs.CV"], "comment": null, "summary": "The introduction of generative models has significantly advanced image\nsuper-resolution (SR) in handling real-world degradations. However, they often\nincur fidelity-related issues, particularly distorting textual structures. In\nthis paper, we introduce a novel diffusion-based SR framework, namely TADiSR,\nwhich integrates text-aware attention and joint segmentation decoders to\nrecover not only natural details but also the structural fidelity of text\nregions in degraded real-world images. Moreover, we propose a complete pipeline\nfor synthesizing high-quality images with fine-grained full-image text masks,\ncombining realistic foreground text regions with detailed background content.\nExtensive experiments demonstrate that our approach substantially enhances text\nlegibility in super-resolved images, achieving state-of-the-art performance\nacross multiple evaluation metrics and exhibiting strong generalization to\nreal-world scenarios. Our code is available at\n\\href{https://github.com/mingcv/TADiSR}{here}.", "AI": {"title_translation": "基于扩散模型和联合分割解码器的文本感知真实世界图像超分辨率", "tldr": "本文提出TADiSR，一个扩散模型框架，通过文本感知注意力和联合分割解码器，解决图像超分辨率中文本结构失真问题，显著提升文本可读性并达到最先进性能。", "motivation": "现有的生成模型在图像超分辨率处理真实世界退化时，常导致保真度问题，特别是会扭曲文本结构。", "method": "本文提出了一个新颖的基于扩散的超分辨率框架TADiSR，它整合了文本感知注意力和联合分割解码器，以恢复退化真实世界图像中的自然细节和文本区域的结构保真度。此外，还提出了一个完整的流水线，用于合成带有细粒度全图像文本掩码的高质量图像，结合了逼真的前景文本区域和详细的背景内容。", "result": "实验证明，所提出的方法显著增强了超分辨率图像中的文本可读性，在多个评估指标上实现了最先进的性能，并对真实世界场景表现出强大的泛化能力。", "conclusion": "本文成功地通过新颖的扩散模型框架TADiSR解决了真实世界图像超分辨率中文本结构失真的问题，显著提高了文本可读性，并在多项指标上达到了最先进的性能，展现了其在实际应用中的强大潜力。", "translation": "生成模型的引入显著推动了图像超分辨率（SR）在处理真实世界退化方面的进展。然而，它们常常导致保真度相关问题，特别是会扭曲文本结构。在本文中，我们引入了一个新颖的基于扩散的超分辨率框架，名为TADiSR，它整合了文本感知注意力和联合分割解码器，不仅能恢复自然细节，还能恢复退化真实世界图像中文本区域的结构保真度。此外，我们提出了一个完整的流水线，用于合成带有细粒度全图像文本掩码的高质量图像，结合了逼真的前景文本区域和详细的背景内容。广泛的实验表明，我们的方法显著增强了超分辨率图像中的文本可读性，在多个评估指标上实现了最先进的性能，并对真实世界场景表现出强大的泛化能力。我们的代码可在此处获取：\\href{https://github.com/mingcv/TADiSR}{此处}。", "summary": "本文介绍了一种名为TADiSR的新型扩散模型超分辨率框架，旨在解决现有生成模型在图像超分辨率中对文本结构造成的失真问题。TADiSR通过整合文本感知注意力和联合分割解码器，不仅能恢复图像的自然细节，还能保持文本区域的结构保真度。此外，该研究还提出了一种用于合成高质量图像的完整流水线，包含细粒度文本掩码。实验结果表明，TADiSR显著提高了超分辨率图像的文本可读性，并在多个评估指标上实现了最先进的性能，展现了强大的真实世界泛化能力。", "keywords": "文本感知, 图像超分辨率, 扩散模型, 文本可读性, 联合分割"}}
{"id": "2506.04430", "pdf": "https://arxiv.org/pdf/2506.04430", "abs": "https://arxiv.org/abs/2506.04430", "authors": ["Egor Petrov", "Grigoriy Evseev", "Aleksey Antonov", "Andrey Veprikov", "Pavel Plyusnin", "Nikolay Bushkov", "Stanislav Moiseev", "Aleksandr Beznosikov"], "title": "Leveraging Coordinate Momentum in SignSGD and Muon: Memory-Optimized Zero-Order", "categories": ["cs.LG", "math.OC"], "comment": "26 pages, 5 tables", "summary": "Fine-tuning Large Language Models (LLMs) is essential for adapting\npre-trained models to downstream tasks. Yet traditional first-order optimizers\nsuch as Stochastic Gradient Descent (SGD) and Adam incur prohibitive memory and\ncomputational costs that scale poorly with model size. In this paper, we\ninvestigate zero-order (ZO) optimization methods as a memory- and\ncompute-efficient alternative, particularly in the context of\nparameter-efficient fine-tuning techniques like LoRA. We propose\n$\\texttt{JAGUAR SignSGD}$, a ZO momentum-based algorithm that extends ZO\nSignSGD, requiring the same number of parameters as the standard ZO SGD and\nonly $\\mathcal{O}(1)$ function evaluations per iteration. To the best of our\nknowledge, this is the first study to establish rigorous convergence guarantees\nfor SignSGD in the stochastic ZO case. We further propose $\\texttt{JAGUAR\nMuon}$, a novel ZO extension of the Muon optimizer that leverages the matrix\nstructure of model parameters, and we provide its convergence rate under\narbitrary stochastic noise. Through extensive experiments on challenging LLM\nfine-tuning benchmarks, we demonstrate that the proposed algorithms meet or\nexceed the convergence quality of standard first-order methods, achieving\nsignificant memory reduction. Our theoretical and empirical results establish\nnew ZO optimization methods as a practical and theoretically grounded approach\nfor resource-constrained LLM adaptation. Our code is available at\nhttps://github.com/brain-mmo-lab/ZO_LLM", "AI": {"title_translation": "利用坐标动量于SignSGD和Muon：内存优化的零阶方法", "tldr": "本文提出了两种新的零阶优化算法JAGUAR SignSGD和JAGUAR Muon，它们在微调大型语言模型时能显著节省内存并保持高性能，是资源受限LLM适应的有效方案。", "motivation": "传统一阶优化器（如SGD和Adam）在微调大型语言模型（LLMs）时存在内存和计算成本过高的问题，且随模型规模增长而扩展性差。", "method": "本文研究零阶（ZO）优化方法作为内存和计算高效的替代方案，尤其是在LoRA等参数高效微调技术背景下。提出了JAGUAR SignSGD，一个扩展ZO SignSGD的ZO动量算法，具有O(1)函数评估和严格收敛保证。还提出了JAGUAR Muon，一个利用模型参数矩阵结构的新型ZO扩展Muon优化器，并提供了其收敛速率。", "result": "在挑战性的LLM微调基准测试中，所提出的算法达到或超过了标准一阶方法的收敛质量，并实现了显著的内存减少。", "conclusion": "理论和实证结果表明，新的零阶优化方法是资源受限LLM适应的一种实用且有理论基础的方法。", "translation": "微调大型语言模型（LLMs）对于使预训练模型适应下游任务至关重要。然而，传统的如随机梯度下降（SGD）和Adam等一阶优化器会产生高昂的内存和计算成本，并且随着模型规模的增加而扩展性差。在本文中，我们研究了零阶（ZO）优化方法作为一种内存和计算高效的替代方案，特别是在LoRA等参数高效微调技术的背景下。我们提出了JAGUAR SignSGD，这是一种基于ZO动量的算法，它扩展了ZO SignSGD，所需的参数数量与标准ZO SGD相同，并且每次迭代只需O(1)次函数评估。据我们所知，这是首次为随机ZO情况下的SignSGD建立严格的收敛保证的研究。我们进一步提出了JAGUAR Muon，一种新型的Muon优化器的ZO扩展，它利用了模型参数的矩阵结构，并且我们提供了其在任意随机噪声下的收敛速率。通过在具有挑战性的LLM微调基准上进行大量实验，我们证明了所提出的算法达到或超过了标准一阶方法的收敛质量，实现了显著的内存减少。我们的理论和实证结果确立了新的ZO优化方法作为一种实用且有理论基础的资源受限LLM适应方法。我们的代码可在https://github.com/brain-mmo-lab/ZO_LLM获取。", "summary": "本文针对大型语言模型微调中一阶优化器内存和计算成本高昂的问题，提出了两种创新的零阶优化算法JAGUAR SignSGD和JAGUAR Muon。这些算法在保持或超越传统一阶方法收敛质量的同时，显著降低了内存消耗，特别适用于资源受限的LLM适应场景，并提供了严格的理论收敛保证。", "keywords": "零阶优化, 大型语言模型, 微调, 内存优化, SignSGD"}}
{"id": "2506.05168", "pdf": "https://arxiv.org/pdf/2506.05168", "abs": "https://arxiv.org/abs/2506.05168", "authors": ["Yunsheng Tian", "Joshua Jacob", "Yijiang Huang", "Jialiang Zhao", "Edward Gu", "Pingchuan Ma", "Annan Zhang", "Farhad Javid", "Branden Romero", "Sachin Chitta", "Shinjiro Sueda", "Hui Li", "Wojciech Matusik"], "title": "Fabrica: Dual-Arm Assembly of General Multi-Part Objects via Integrated Planning and Learning", "categories": ["cs.RO"], "comment": null, "summary": "Multi-part assembly poses significant challenges for robots to execute\nlong-horizon, contact-rich manipulation with generalization across complex\ngeometries. We present Fabrica, a dual-arm robotic system capable of end-to-end\nplanning and control for autonomous assembly of general multi-part objects. For\nplanning over long horizons, we develop hierarchies of precedence, sequence,\ngrasp, and motion planning with automated fixture generation, enabling general\nmulti-step assembly on any dual-arm robots. The planner is made efficient\nthrough a parallelizable design and is optimized for downstream control\nstability. For contact-rich assembly steps, we propose a lightweight\nreinforcement learning framework that trains generalist policies across object\ngeometries, assembly directions, and grasp poses, guided by equivariance and\nresidual actions obtained from the plan. These policies transfer zero-shot to\nthe real world and achieve 80% successful steps. For systematic evaluation, we\npropose a benchmark suite of multi-part assemblies resembling industrial and\ndaily objects across diverse categories and geometries. By integrating\nefficient global planning and robust local control, we showcase the first\nsystem to achieve complete and generalizable real-world multi-part assembly\nwithout domain knowledge or human demonstrations. Project website:\nhttp://fabrica.csail.mit.edu/", "AI": {"title_translation": "Fabrica：通过集成规划和学习实现通用多部件物体的双臂组装", "tldr": "Fabrica是一个双臂机器人系统，通过集成规划和强化学习，能够自主组装各种多部件物体，并在真实世界中实现高成功率。", "motivation": "机器人多部件组装面临着执行长周期、接触密集操作以及在复杂几何形状上实现泛化的重大挑战。", "method": "本文提出了Fabrica，一个用于通用多部件物体自主组装的端到端规划和控制双臂机器人系统。它开发了包括优先级、序列、抓取和运动规划在内的分层规划，并自动生成夹具。对于接触密集的组装步骤，提出了一个轻量级强化学习框架，通过等变性和从规划中获得的残余动作指导，训练出适用于不同物体几何形状、组装方向和抓取姿态的通用策略。同时，还提出了一个多部件组装基准套件用于系统评估。", "result": "所提出的强化学习策略能够零样本迁移到真实世界，并实现了80%的成功率。Fabrica系统是首个无需领域知识或人类演示，即可实现完整且可泛化的真实世界多部件组装的系统。", "conclusion": "Fabrica通过集成高效的全局规划和鲁棒的局部控制，成功解决了机器人多部件组装中的泛化和复杂性挑战，实现了通用且完整的真实世界组装。", "translation": "多部件组装对机器人执行长周期、接触密集操作以及在复杂几何形状上实现泛化带来了重大挑战。我们提出了Fabrica，一个双臂机器人系统，能够对通用多部件物体进行端到端规划和控制，实现自主组装。为了实现长周期规划，我们开发了优先级、序列、抓取和运动规划的层级结构，并自动生成夹具，使得在任何双臂机器人上都能进行通用的多步骤组装。该规划器通过可并行化的设计提高了效率，并针对下游控制稳定性进行了优化。对于接触密集的组装步骤，我们提出了一个轻量级强化学习框架，该框架在等变性和从规划中获得的残余动作的指导下，训练出适用于物体几何形状、组装方向和抓取姿态的通用策略。这些策略可以零样本迁移到真实世界，并实现了80%的成功步骤。为了进行系统评估，我们提出了一个多部件组装基准套件，该套件包含了各种类别和几何形状的工业和日常物体组装。通过集成高效的全局规划和鲁棒的局部控制，我们展示了第一个无需领域知识或人类演示即可实现完整且可泛化真实世界多部件组装的系统。项目网站：http://fabrica.csail.mit.edu/", "summary": "Fabrica是一个创新的双臂机器人系统，旨在解决机器人多部件组装中长周期、接触密集操作以及在复杂几何形状上泛化的难题。该系统通过集成高效的分层规划（包括自动夹具生成）和轻量级强化学习框架，实现了通用多部件物体的端到端自主组装。其强化学习策略能够零样本迁移到真实世界，并取得了80%的成功率。Fabrica是首个无需领域知识或人类演示即可实现通用且完整真实世界多部件组装的系统，并通过提出的基准套件进行了系统评估。", "keywords": "双臂机器人, 多部件组装, 集成规划, 强化学习, 泛化"}}
{"id": "2506.04648", "pdf": "https://arxiv.org/pdf/2506.04648", "abs": "https://arxiv.org/abs/2506.04648", "authors": ["Akide Liu", "Zeyu Zhang", "Zhexin Li", "Xuehai Bai", "Yizeng Han", "Jiasheng Tang", "Yuanjie Xing", "Jichao Wu", "Mingyang Yang", "Weihua Chen", "Jiahao He", "Yuanyu He", "Fan Wang", "Gholamreza Haffari", "Bohan Zhuang"], "title": "FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion", "categories": ["cs.CV"], "comment": "Project Page: https://fps.ziplab.co", "summary": "Diffusion generative models have become the standard for producing\nhigh-quality, coherent video content, yet their slow inference speeds and high\ncomputational demands hinder practical deployment. Although both quantization\nand sparsity can independently accelerate inference while maintaining\ngeneration quality, naively combining these techniques in existing\ntraining-free approaches leads to significant performance degradation due to\nthe lack of joint optimization.We introduce FPSAttention, a novel\ntraining-aware co-design of FP8 quantization and sparsity for video generation,\nwith a focus on the 3D bi-directional attention mechanism. Our approach\nfeatures three key innovations: 1) A unified 3D tile-wise granularity that\nsimultaneously supports both quantization and sparsity; 2) A denoising\nstep-aware strategy that adapts to the noise schedule, addressing the strong\ncorrelation between quantization/sparsity errors and denoising steps; 3) A\nnative, hardware-friendly kernel that leverages FlashAttention and is\nimplemented with optimized Hopper architecture features for highly efficient\nexecution. Trained on Wan2.1's 1.3B and 14B models and evaluated on the VBench\nbenchmark, FPSAttention achieves a 7.09x kernel speedup for attention\noperations and a 4.96x end-to-end speedup for video generation compared to the\nBF16 baseline at 720p resolution-without sacrificing generation quality.", "AI": {"title_translation": "FPSAttention：面向快速视频扩散的训练感知FP8与稀疏性协同设计", "tldr": "FPSAttention通过FP8量化和稀疏性协同设计，显著加速视频扩散模型的推理速度，同时保持生成质量。", "motivation": "扩散生成模型在视频内容生成方面表现出色，但其推理速度慢和计算需求高阻碍了实际部署。现有量化和稀疏性技术虽能独立加速，但简单结合会导致性能显著下降，原因在于缺乏联合优化。", "method": "本文提出了FPSAttention，一种针对视频生成中3D双向注意力机制的训练感知FP8量化和稀疏性协同设计方法。其主要创新包括：1) 统一的3D瓦片粒度，同时支持量化和稀疏性；2) 去噪步骤感知策略，适应噪声调度，解决量化/稀疏性误差与去噪步骤的强相关性；3) 原生、硬件友好的内核，利用FlashAttention并针对优化的Hopper架构特性实现高效执行。", "result": "与BF16基线相比，在720p分辨率下，FPSAttention在注意力操作上实现了7.09倍的内核加速，在视频生成上实现了4.96倍的端到端加速，同时保持了生成质量。", "conclusion": "FPSAttention通过创新的训练感知FP8量化和稀疏性协同设计，成功解决了视频扩散模型推理速度慢的问题，并在保持高质量生成的同时显著提升了计算效率。", "translation": "扩散生成模型已成为生成高质量、连贯视频内容的标准，但其缓慢的推理速度和高计算需求阻碍了实际部署。尽管量化和稀疏性可以独立加速推理并保持生成质量，但现有训练无关方法中简单地结合这些技术会导致显著的性能下降，因为缺乏联合优化。我们引入了FPSAttention，一种针对视频生成的FP8量化和稀疏性协同设计的新型训练感知方法，重点关注3D双向注意力机制。我们的方法具有三个关键创新：1) 统一的3D瓦片粒度，同时支持量化和稀疏性；2) 去噪步骤感知策略，适应噪声调度，解决了量化/稀疏性误差与去噪步骤之间的强相关性；3) 原生、硬件友好的内核，利用FlashAttention并针对优化的Hopper架构特性实现高效执行。在Wan2.1的1.3B和14B模型上进行训练，并在VBencb基准上进行评估，FPSAttention在720p分辨率下，与BF16基线相比，注意力操作实现了7.09倍的内核加速，视频生成实现了4.96倍的端到端加速，且不牺牲生成质量。", "summary": "本文介绍了FPSAttention，一种为加速视频扩散模型而设计的训练感知FP8量化与稀疏性协同方法，尤其关注3D双向注意力机制。该方法引入了统一的3D瓦片粒度、去噪步骤感知策略和硬件友好的内核，显著提升了推理速度。实验证明，FPSAttention在不牺牲视频生成质量的前提下，实现了注意力操作7.09倍和端到端视频生成4.96倍的加速。", "keywords": "视频扩散, FP8量化, 稀疏性, 注意力机制, 模型加速"}}
{"id": "2506.04432", "pdf": "https://arxiv.org/pdf/2506.04432", "abs": "https://arxiv.org/abs/2506.04432", "authors": ["Zixuan Xia", "Aram Davtyan", "Paolo Favaro"], "title": "KOALA++: Efficient Kalman-Based Optimization of Neural Networks with Gradient-Covariance Products", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "We propose KOALA++, a scalable Kalman-based optimization algorithm that\nexplicitly models structured gradient uncertainty in neural network training.\nUnlike second-order methods, which rely on expensive second order gradient\ncalculation, our method directly estimates the parameter covariance matrix by\nrecursively updating compact gradient covariance products. This design improves\nupon the original KOALA framework that assumed diagonal covariance by\nimplicitly capturing richer uncertainty structure without storing the full\ncovariance matrix and avoiding large matrix inversions. Across diverse tasks,\nincluding image classification and language modeling, KOALA++ achieves accuracy\non par or better than state-of-the-art first- and second-order optimizers while\nmaintaining the efficiency of first-order methods.", "AI": {"title_translation": "KOALA++：基于卡尔曼的神经网络高效优化，利用梯度-协方差积", "tldr": "KOALA++是一种高效的基于卡尔曼的神经网络优化算法，它通过递归更新紧凑的梯度协方差积来估计参数协方差矩阵，从而在不增加计算成本的情况下实现与现有最先进优化器相当或更好的性能。", "motivation": "现有的二阶优化方法依赖于昂贵的二阶梯度计算。KOALA++旨在解决神经网络训练中梯度不确定性建模的效率问题，同时避免存储完整的协方差矩阵和大规模矩阵求逆。", "method": "KOALA++是一种可扩展的基于卡尔曼的优化算法。它通过递归更新紧凑的梯度协方差积来直接估计参数协方差矩阵，从而显式地建模神经网络训练中的结构化梯度不确定性。该设计改进了原始KOALA框架中对角协方差的假设，通过隐式捕获更丰富的不确定性结构，同时避免存储完整的协方差矩阵和大规模矩阵求逆。", "result": "在图像分类和语言建模等多种任务中，KOALA++的准确性与最先进的一阶和二阶优化器相当或更好，同时保持了一阶方法的效率。", "conclusion": "KOALA++通过高效地建模梯度不确定性，在不牺牲效率的前提下，实现了与现有最先进优化器相当或更优的性能，为神经网络训练提供了一种有效且可扩展的优化方法。", "translation": "我们提出了KOALA++，一种可扩展的基于卡尔曼的优化算法，它在神经网络训练中明确地建模结构化梯度不确定性。与依赖昂贵的二阶梯度计算的二阶方法不同，我们的方法通过递归更新紧凑的梯度协方差积来直接估计参数协方差矩阵。这种设计改进了原始KOALA框架中对角协方差的假设，通过隐式捕获更丰富的不确定性结构，而无需存储完整的协方差矩阵并避免大规模矩阵求逆。在包括图像分类和语言建模在内的各种任务中，KOALA++的准确性与最先进的一阶和二阶优化器相当或更好，同时保持了一阶方法的效率。", "summary": "KOALA++是一种新颖的基于卡尔曼的神经网络优化算法，它通过递归更新梯度协方差积来有效建模梯度不确定性。与传统的二阶方法不同，KOALA++避免了昂贵的二阶梯度计算和大规模矩阵求逆，从而在保持一阶方法效率的同时，实现了与现有最先进优化器相当或更优的性能，适用于图像分类和语言建模等多种任务。", "keywords": "神经网络优化, 卡尔曼滤波, 梯度协方差, 不确定性建模, 深度学习"}}
{"id": "2506.04912", "pdf": "https://arxiv.org/pdf/2506.04912", "abs": "https://arxiv.org/abs/2506.04912", "authors": ["Pietro Miotti", "Eyvind Niklasson", "Ettore Randazzo", "Alexander Mordvintsev"], "title": "Differentiable Logic Cellular Automata: From Game of Life to Pattern Generation", "categories": ["cs.AI"], "comment": null, "summary": "This paper introduces Differentiable Logic Cellular Automata (DiffLogic CA),\na novel combination of Neural Cellular Automata (NCA) and Differentiable Logic\nGates Networks (DLGNs). The fundamental computation units of the model are\ndifferentiable logic gates, combined into a circuit. During training, the model\nis fully end-to-end differentiable allowing gradient-based training, and at\ninference time it operates in a fully discrete state space. This enables\nlearning local update rules for cellular automata while preserving their\ninherent discrete nature. We demonstrate the versatility of our approach\nthrough a series of milestones: (1) fully learning the rules of Conway's Game\nof Life, (2) generating checkerboard patterns that exhibit resilience to noise\nand damage, (3) growing a lizard shape, and (4) multi-color pattern generation.\nOur model successfully learns recurrent circuits capable of generating desired\ntarget patterns. For simpler patterns, we observe success with both synchronous\nand asynchronous updates, demonstrating significant generalization capabilities\nand robustness to perturbations. We make the case that this combination of\nDLGNs and NCA represents a step toward programmable matter and robust computing\nsystems that combine binary logic, neural network adaptability, and localized\nprocessing. This work, to the best of our knowledge, is the first successful\napplication of differentiable logic gate networks in recurrent architectures.", "AI": {"title_translation": "可微分逻辑元胞自动机：从生命游戏到模式生成", "tldr": "本文介绍了可微分逻辑元胞自动机（DiffLogic CA），它结合了神经元胞自动机（NCA）和可微分逻辑门网络（DLGNs），实现了端到端可微分训练和离散状态空间推理，能够学习局部更新规则并生成各种模式，具有鲁棒性、泛化性和可编程性。", "motivation": "为了学习元胞自动机的局部更新规则，同时保持其固有的离散特性，并探索结合二元逻辑、神经网络适应性和局部处理能力的鲁棒计算系统。", "method": "本文提出了可微分逻辑元胞自动机（DiffLogic CA），它结合了神经元胞自动机（NCA）和可微分逻辑门网络（DLGNs）。模型的计算单元是可微分逻辑门，它们组合成一个电路。在训练过程中，模型是完全端到端可微分的，允许基于梯度的训练；在推理时，它在完全离散的状态空间中运行。", "result": "DiffLogic CA成功学习了康威生命游戏的规则，生成了对噪声和损伤具有鲁棒性的棋盘格图案，生长出蜥蜴形状，并实现了多色图案生成。对于更简单的图案，同步和异步更新都取得了成功，展示了显著的泛化能力和对扰动的鲁棒性。", "conclusion": "可微分逻辑门网络和神经元胞自动机的结合代表了迈向可编程物质和鲁棒计算系统的一步，这些系统结合了二元逻辑、神经网络适应性和局部处理能力。这是可微分逻辑门网络在循环架构中首次成功的应用。", "translation": "本文介绍了可微分逻辑元胞自动机（DiffLogic CA），它是神经元胞自动机（NCA）和可微分逻辑门网络（DLGNs）的新颖组合。该模型的基本计算单元是可微分逻辑门，它们组合成一个电路。在训练过程中，模型是完全端到端可微分的，允许基于梯度的训练，并且在推理时，它在完全离散的状态空间中运行。这使得学习元胞自动机的局部更新规则成为可能，同时保留了其固有的离散性质。我们通过一系列里程碑展示了我们方法的通用性：（1）完全学习康威生命游戏的规则，（2）生成对噪声和损伤具有鲁棒性的棋盘格图案，（3）生长蜥蜴形状，以及（4）多色图案生成。我们的模型成功地学习了能够生成所需目标图案的循环电路。对于更简单的图案，我们观察到同步和异步更新都取得了成功，展示了显著的泛化能力和对扰动的鲁棒性。我们认为，DLGNs和NCA的这种组合代表了迈向可编程物质和结合二元逻辑、神经网络适应性和局部处理能力的鲁棒计算系统的一步。据我们所知，这项工作是可微分逻辑门网络在循环架构中的首次成功应用。", "summary": "本文引入了可微分逻辑元胞自动机（DiffLogic CA），它创新性地结合了神经元胞自动机（NCA）和可微分逻辑门网络（DLGNs）。该模型利用可微分逻辑门作为基本计算单元，实现了端到端的梯度训练，并在推理时保持完全离散状态。这使得模型能够学习元胞自动机的局部更新规则，同时保留其离散特性。研究通过学习康威生命游戏规则、生成抗噪声和损伤的棋盘格图案、生长蜥蜴形状以及多色图案生成等里程碑，展示了该方法的通用性。该模型成功学习了能够生成目标图案的循环电路，并在简单图案上表现出显著的泛化能力和对扰动的鲁棒性。本工作被认为是可微分逻辑门网络在循环架构中的首次成功应用，为可编程物质和结合二元逻辑、神经网络适应性与局部处理能力的鲁棒计算系统奠定了基础。", "keywords": "可微分逻辑元胞自动机, 神经元胞自动机, 可微分逻辑门网络, 模式生成, 鲁棒计算"}}
{"id": "2506.04668", "pdf": "https://arxiv.org/pdf/2506.04668", "abs": "https://arxiv.org/abs/2506.04668", "authors": ["Takayuki Komatsu", "Yoshiyuki Ohmura", "Kayato Nishitsunoi", "Yasuo Kuniyoshi"], "title": "Feature-Based Lie Group Transformer for Real-World Applications", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The main goal of representation learning is to acquire meaningful\nrepresentations from real-world sensory inputs without supervision.\nRepresentation learning explains some aspects of human development. Various\nneural network (NN) models have been proposed that acquire empirically good\nrepresentations. However, the formulation of a good representation has not been\nestablished. We recently proposed a method for categorizing changes between a\npair of sensory inputs. A unique feature of this approach is that\ntransformations between two sensory inputs are learned to satisfy algebraic\nstructural constraints. Conventional representation learning often assumes that\ndisentangled independent feature axes is a good representation; however, we\nfound that such a representation cannot account for conditional independence.\nTo overcome this problem, we proposed a new method using group decomposition in\nGalois algebra theory. Although this method is promising for defining a more\ngeneral representation, it assumes pixel-to-pixel translation without feature\nextraction, and can only process low-resolution images with no background,\nwhich prevents real-world application. In this study, we provide a simple\nmethod to apply our group decomposition theory to a more realistic scenario by\ncombining feature extraction and object segmentation. We replace pixel\ntranslation with feature translation and formulate object segmentation as\ngrouping features under the same transformation. We validated the proposed\nmethod on a practical dataset containing both real-world object and background.\nWe believe that our model will lead to a better understanding of human\ndevelopment of object recognition in the real world.", "AI": {"title_translation": "基于特征的李群变换器在现实世界应用中的研究", "tldr": "本文提出了一种结合特征提取和目标分割的方法，将之前受限于低分辨率无背景图像的李群分解理论应用于现实世界的复杂场景，以实现更通用的表征学习。", "motivation": "传统的表征学习方法（如解耦的独立特征轴）无法解释条件独立性。作者之前提出的群分解方法虽然有前景，但受限于像素到像素的平移、低分辨率图像和无背景，使其无法应用于现实世界场景。", "method": "提出了一种将群分解理论应用于更现实场景的简单方法，通过结合特征提取和目标分割。具体来说，将像素平移替换为特征平移，并将目标分割表述为在相同变换下对特征进行分组。", "result": "在包含真实世界物体和背景的实际数据集上验证了所提出的方法。", "conclusion": "该模型有望促进对人类在现实世界中物体识别发展过程的更好理解。", "translation": "表征学习的主要目标是无需监督地从现实世界的感觉输入中获取有意义的表征。表征学习解释了人类发展的某些方面。各种神经网络（NN）模型已被提出，它们获得了经验上良好的表征。然而，良好表征的形成尚未确立。我们最近提出了一种对一对感觉输入之间变化进行分类的方法。这种方法的独特之处在于，学习了两个感觉输入之间的变换以满足代数结构约束。传统的表征学习通常假设解耦的独立特征轴是一种良好的表征；然而，我们发现这样的表征无法解释条件独立性。为了克服这个问题，我们提出了一种使用伽罗瓦代数理论中群分解的新方法。尽管这种方法对于定义更通用的表征很有前景，但它假设没有特征提取的像素到像素平移，并且只能处理没有背景的低分辨率图像，这阻碍了现实世界的应用。在本研究中，我们提供了一种简单的方法，通过结合特征提取和目标分割，将我们的群分解理论应用于更现实的场景。我们将像素平移替换为特征平移，并将目标分割表述为在相同变换下对特征进行分组。我们在包含真实世界物体和背景的实际数据集上验证了所提出的方法。我们相信我们的模型将有助于更好地理解人类在现实世界中物体识别的发展。", "summary": "本文旨在解决现有表征学习方法的局限性，特别是作者团队之前提出的群分解理论在处理现实世界复杂图像时的不足。为使其适用于现实场景，研究者提出了一种新方法，将特征提取与目标分割相结合。通过将像素平移替换为特征平移，并将目标分割定义为在相同变换下对特征进行分组，该方法能够处理包含真实物体和背景的实用数据集。研究者认为，该模型将有助于深入理解人类在现实世界中对物体的识别发展。", "keywords": "Feature-Based Lie Group Transformer, Representation Learning, Group Decomposition, Object Segmentation, Real-World Applications"}}
{"id": "2506.04434", "pdf": "https://arxiv.org/pdf/2506.04434", "abs": "https://arxiv.org/abs/2506.04434", "authors": ["Hari K. Prakash", "Charles H. Martin"], "title": "Grokking and Generalization Collapse: Insights from \\texttt{HTSR} theory", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "15 pages,7 figs", "summary": "We study the well-known grokking phenomena in neural networks (NNs) using a\n3-layer MLP trained on 1 k-sample subset of MNIST, with and without weight\ndecay, and discover a novel third phase -- \\emph{anti-grokking} -- that occurs\nvery late in training and resembles but is distinct from the familiar\n\\emph{pre-grokking} phases: test accuracy collapses while training accuracy\nstays perfect. This late-stage collapse is distinct, from the known\npre-grokking and grokking phases, and is not detected by other proposed\ngrokking progress measures. Leveraging Heavy-Tailed Self-Regularization HTSR\nthrough the open-source WeightWatcher tool, we show that the HTSR layer quality\nmetric $\\alpha$ alone delineates all three phases, whereas the best competing\nmetrics detect only the first two. The \\emph{anti-grokking} is revealed by\ntraining for $10^7$ and is invariably heralded by $\\alpha < 2$ and the\nappearance of \\emph{Correlation Traps} -- outlier singular values in the\nrandomized layer weight matrices that make the layer weight matrix atypical and\nsignal overfitting of the training set. Such traps are verified by visual\ninspection of the layer-wise empirical spectral densities, and by using\nKolmogorov--Smirnov tests on randomized spectra. Comparative metrics, including\nactivation sparsity, absolute weight entropy, circuit complexity, and $l^2$\nweight norms track pre-grokking and grokking but fail to distinguish grokking\nfrom anti-grokking. This discovery provides a way to measure overfitting and\ngeneralization collapse without direct access to the test data. These results\nstrengthen the claim that the \\emph{HTSR} $\\alpha$ provides universal\nlayer-convergence target at $\\alpha \\approx 2$ and underscore the value of\nusing the HTSR alpha $(\\alpha)$ metric as a measure of generalization.", "AI": {"title_translation": "Grokking与泛化崩溃：来自\\texttt{HTSR}理论的见解", "tldr": "本研究发现神经网络训练后期存在“反Grokking”现象，即测试准确率崩溃而训练准确率保持完美，并提出HTSR理论中的$\\alpha$指标能有效识别此现象及过拟合。", "motivation": "研究神经网络中著名的Grokking现象，并探索其泛化性能在训练后期可能出现的崩溃现象，以期提出新的测量过拟合和泛化崩溃的方法。", "method": "使用在MNIST 1k样本子集上训练的3层MLP（带或不带权重衰减），通过开源工具WeightWatcher利用重尾自正则化（HTSR）理论，并分析HTSR层质量指标$\\alpha$。此外，还通过层级经验谱密度和Kolmogorov-Smirnov检验验证了“相关陷阱”的存在，并与其他比较指标（如激活稀疏度、绝对权重熵、电路复杂度和$l^2$权重范数）进行了对比。", "result": "发现了一个新的第三阶段——“反Grokking”，在此阶段测试准确率崩溃而训练准确率保持完美。HTSR层质量指标$\\alpha$能够单独划分所有三个阶段（预Grokking、Grokking和反Grokking），而其他竞争指标只能检测前两个阶段。“反Grokking”的出现总是伴随着$\\alpha < 2$和“相关陷阱”（随机层权重矩阵中的异常奇异值）的出现。其他比较指标无法区分Grokking和反Grokking。", "conclusion": "HTSR的$\\alpha$指标提供了一个普遍的层收敛目标（$\\alpha \\approx 2$），并且是衡量泛化能力的重要指标，能够在没有直接访问测试数据的情况下测量过拟合和泛化崩溃。", "translation": "我们使用在MNIST 1k样本子集上训练的3层MLP（带或不带权重衰减）研究神经网络中著名的Grokking现象，并发现了一个新的第三阶段——“反Grokking”——它在训练后期发生，类似于但又不同于熟悉的“预Grokking”阶段：测试准确率崩溃而训练准确率保持完美。这种后期崩溃与已知的预Grokking和Grokking阶段不同，并且未被其他提出的Grokking进展度量检测到。利用开源工具WeightWatcher通过重尾自正则化（HTSR），我们表明单独的HTSR层质量指标$\\alpha$能够描绘所有三个阶段，而最佳竞争指标只能检测前两个阶段。“反Grokking”通过训练$10^7$次揭示，并且总是伴随着$\\alpha < 2$以及“相关陷阱”的出现——随机层权重矩阵中异常的奇异值，这些值使层权重矩阵变得不典型并预示着训练集的过拟合。通过层级经验谱密度的目视检查以及使用Kolmogorov-Smirnov检验对随机谱进行验证，证实了此类陷阱的存在。包括激活稀疏度、绝对权重熵、电路复杂度和$l^2$权重范数在内的比较指标可以跟踪预Grokking和Grokking，但未能区分Grokking和反Grokking。这一发现提供了一种无需直接访问测试数据即可测量过拟合和泛化崩溃的方法。这些结果强化了HTSR $\\alpha$在$\\alpha \\approx 2$处提供普遍层收敛目标的说法，并强调了使用HTSR alpha（$\\alpha$）指标作为泛化度量的重要性。", "summary": "本研究通过在MNIST数据集上训练3层MLP，发现了神经网络训练后期一种新的现象——“反Grokking”，表现为测试准确率崩溃但训练准确率保持完美。与现有Grokking进展衡量指标不同，基于重尾自正则化（HTSR）理论的层质量指标$\\alpha$能够准确识别预Grokking、Grokking和反Grokking三个阶段。当$\\alpha < 2$并出现“相关陷阱”时，预示着反Grokking和过拟合。该发现提供了一种无需测试数据即可衡量过拟合和泛化崩溃的方法，并强调了HTSR $\\alpha$作为泛化度量的重要性。", "keywords": "Grokking, 泛化崩溃, 反Grokking, HTSR理论, 神经网络"}}
{"id": "2506.04283", "pdf": "https://arxiv.org/pdf/2506.04283", "abs": "https://arxiv.org/abs/2506.04283", "authors": ["Junpyo Seo", "Hanbin Koo", "Jieun Yook", "Byung-Ro Moon"], "title": "SSIMBaD: Sigma Scaling with SSIM-Guided Balanced Diffusion for AnimeFace Colorization", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "10 pages, rest of the pages are appendix", "summary": "We propose a novel diffusion-based framework for automatic colorization of\nAnime-style facial sketches. Our method preserves the structural fidelity of\nthe input sketch while effectively transferring stylistic attributes from a\nreference image. Unlike traditional approaches that rely on predefined noise\nschedules - which often compromise perceptual consistency -- our framework\nbuilds on continuous-time diffusion models and introduces SSIMBaD (Sigma\nScaling with SSIM-Guided Balanced Diffusion). SSIMBaD applies a sigma-space\ntransformation that aligns perceptual degradation, as measured by structural\nsimilarity (SSIM), in a linear manner. This scaling ensures uniform visual\ndifficulty across timesteps, enabling more balanced and faithful\nreconstructions. Experiments on a large-scale Anime face dataset demonstrate\nthat our method outperforms state-of-the-art models in both pixel accuracy and\nperceptual quality, while generalizing to diverse styles. Code is available at\ngithub.com/Giventicket/SSIMBaD-Sigma-Scaling-with-SSIM-Guided-Balanced-Diffusion-for-AnimeFace-Colorization", "AI": {"title_translation": "SSIMBaD：用于动漫人脸着色的SSIM引导平衡扩散与Sigma缩放", "tldr": "SSIMBaD是一种新的扩散模型，通过SSIM引导的Sigma缩放，实现了动漫人脸草图的自动着色，在像素精度和感知质量方面优于现有技术。", "motivation": "传统的动漫人脸草图自动着色方法依赖预定义的噪声调度，这通常会损害感知一致性，因此需要一种新的方法来解决这一问题。", "method": "提出了一种名为SSIMBaD（Sigma Scaling with SSIM-Guided Balanced Diffusion）的新型扩散框架。该方法基于连续时间扩散模型，引入了一种sigma空间变换，该变换以线性方式对齐结构相似性（SSIM）测量的感知退化，从而确保时间步长之间视觉难度的均匀性，实现更平衡和忠实的重建。", "result": "在大规模动漫人脸数据集上的实验表明，该方法在像素精度和感知质量方面均优于现有最先进的模型，同时能泛化到不同的风格。", "conclusion": "SSIMBaD通过SSIM引导的Sigma缩放，实现了更平衡和忠实的动漫人脸草图重建，并在着色方面取得了优异的性能。", "translation": "我们提出了一种新颖的基于扩散的框架，用于动漫风格面部草图的自动着色。我们的方法在有效传输参考图像的风格属性的同时，保留了输入草图的结构保真度。与依赖预定义噪声调度（这通常会损害感知一致性）的传统方法不同，我们的框架建立在连续时间扩散模型之上，并引入了SSIMBaD（Sigma Scaling with SSIM-Guided Balanced Diffusion）。SSIMBaD应用了一种sigma空间变换，该变换以线性方式对齐由结构相似性（SSIM）测量的感知退化。这种缩放确保了时间步长之间视觉难度的均匀性，从而实现更平衡和忠实的重建。在大型动漫人脸数据集上的实验表明，我们的方法在像素精度和感知质量方面均优于现有最先进的模型，同时能泛化到不同的风格。代码可在github.com/Giventicket/SSIMBaD-Sigma-Scaling-with-SSIM-Guided-Balanced-Diffusion-for-AnimeFace-Colorization获取。", "summary": "SSIMBaD是一种新颖的扩散模型，专为动漫人脸草图的自动着色而设计。它通过SSIM引导的Sigma缩放来优化扩散过程，确保感知一致性和均匀的视觉难度。实验证明，SSIMBaD在像素精度和感知质量上均超越了现有技术，并能适应多种风格。", "keywords": "扩散模型, 动漫人脸着色, SSIM, Sigma缩放, 感知质量"}}
{"id": "2506.04916", "pdf": "https://arxiv.org/pdf/2506.04916", "abs": "https://arxiv.org/abs/2506.04916", "authors": ["Atahan Karagoz"], "title": "Energentic Intelligence: From Self-Sustaining Systems to Enduring Artificial Life", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper introduces Energentic Intelligence, a class of autonomous systems\ndefined not by task performance, but by their capacity to sustain themselves\nthrough internal energy regulation. Departing from conventional reward-driven\nparadigms, these agents treat survival-maintaining functional operation under\nfluctuating energetic and thermal conditions-as the central objective. We\nformalize this principle through an energy-based utility function and a\nviability-constrained survival horizon, and propose a modular architecture that\nintegrates energy harvesting, thermal regulation, and adaptive computation into\na closed-loop control system. A simulated environment demonstrates the\nemergence of stable, resource-aware behavior without external supervision.\nTogether, these contributions provide a theoretical and architectural\nfoundation for deploying autonomous agents in resource-volatile settings where\npersistence must be self-regulated and infrastructure cannot be assumed.", "AI": {"title_translation": "能量智能：从自我维持系统到持久人工智能生命", "tldr": "本文介绍了能量智能，一种通过内部能量调节实现自我维持的自主系统，旨在资源不稳定的环境中实现持久性。", "motivation": "传统的自主系统通常由任务性能和奖励驱动，但在资源波动且基础设施不可靠的环境中，这些系统难以自我维持。本文旨在解决如何在这些复杂环境中部署能够自我调节和持久存在的自主代理的问题。", "method": "本文提出了一种能量智能系统，其核心目标是通过内部能量调节来维持生存。通过能量效用函数和可行性受限的生存视野来形式化这一原则。此外，还提出了一种模块化架构，将能量收集、热调节和自适应计算集成到闭环控制系统中。", "result": "在模拟环境中，研究人员观察到无需外部监督即可出现稳定、资源感知的行为。这表明所提出的能量智能系统能够实现自我维持和资源管理。", "conclusion": "这些贡献为在资源不稳定、基础设施不可靠的环境中部署自主代理提供了理论和架构基础，使代理能够自我调节并持久存在。", "translation": "本文介绍了能量智能，一类自主系统，其定义并非基于任务性能，而是基于通过内部能量调节来维持自身的能力。与传统的奖励驱动范式不同，这些代理将生存（即在能量和热条件波动下维持功能操作）视为核心目标。我们通过基于能量的效用函数和受可行性限制的生存视野来形式化这一原则，并提出了一种模块化架构，将能量收集、热调节和自适应计算集成到闭环控制系统中。模拟环境展示了在没有外部监督的情况下，稳定、资源感知行为的出现。总之，这些贡献为在资源波动、持久性必须自我调节且基础设施无法假设的环境中部署自主代理提供了理论和架构基础。", "summary": "本文引入了能量智能的概念，这是一种新型的自主系统，其核心目标是通过内部能量调节实现自我维持，而非传统的任务性能或奖励驱动。研究人员通过能量效用函数和生存视野形式化了这一原则，并设计了一个集能量收集、热调节和自适应计算于一体的模块化闭环控制系统。模拟结果表明，该系统在没有外部监督的情况下也能表现出稳定的资源感知行为，为在资源波动环境中部署持久性自主代理提供了理论和架构基础。", "keywords": "能量智能, 自主系统, 自我维持, 能量调节, 人工生命"}}
{"id": "2506.04673", "pdf": "https://arxiv.org/pdf/2506.04673", "abs": "https://arxiv.org/abs/2506.04673", "authors": ["Zhong Ji", "Rongshuai Wei", "Jingren Liu", "Yanwei Pang", "Jungong Han"], "title": "Interpretable Few-Shot Image Classification via Prototypical Concept-Guided Mixture of LoRA Experts", "categories": ["cs.CV"], "comment": "13 pages,5 figures", "summary": "Self-Explainable Models (SEMs) rely on Prototypical Concept Learning (PCL) to\nenable their visual recognition processes more interpretable, but they often\nstruggle in data-scarce settings where insufficient training samples lead to\nsuboptimal performance.To address this limitation, we propose a Few-Shot\nPrototypical Concept Classification (FSPCC) framework that systematically\nmitigates two key challenges under low-data regimes: parametric imbalance and\nrepresentation misalignment. Specifically, our approach leverages a Mixture of\nLoRA Experts (MoLE) for parameter-efficient adaptation, ensuring a balanced\nallocation of trainable parameters between the backbone and the PCL\nmodule.Meanwhile, cross-module concept guidance enforces tight alignment\nbetween the backbone's feature representations and the prototypical concept\nactivation patterns.In addition, we incorporate a multi-level feature\npreservation strategy that fuses spatial and semantic cues across various\nlayers, thereby enriching the learned representations and mitigating the\nchallenges posed by limited data availability.Finally, to enhance\ninterpretability and minimize concept overlap, we introduce a geometry-aware\nconcept discrimination loss that enforces orthogonality among concepts,\nencouraging more disentangled and transparent decision boundaries.Experimental\nresults on six popular benchmarks (CUB-200-2011, mini-ImageNet, CIFAR-FS,\nStanford Cars, FGVC-Aircraft, and DTD) demonstrate that our approach\nconsistently outperforms existing SEMs by a notable margin, with 4.2%-8.7%\nrelative gains in 5-way 5-shot classification.These findings highlight the\nefficacy of coupling concept learning with few-shot adaptation to achieve both\nhigher accuracy and clearer model interpretability, paving the way for more\ntransparent visual recognition systems.", "AI": {"title_translation": "可解释的少样本图像分类通过原型概念引导的LoRA专家混合", "tldr": "自解释模型（SEMs）在少样本学习中表现不佳。本文提出了FSPCC框架，利用LoRA专家混合、跨模块概念引导、多级特征保留和几何感知损失，以改进少样本可解释图像分类，并取得了显著的性能提升。", "motivation": "自解释模型（SEMs）结合原型概念学习（PCL）在数据稀缺（少样本）环境下表现不佳，因为训练样本不足导致性能次优，并存在参数不平衡和表示错位问题。", "method": "本文提出了少样本原型概念分类（FSPCC）框架。该方法利用LoRA专家混合（MoLE）实现参数高效适应和平衡参数分配，通过跨模块概念引导对齐骨干特征与PCL模块激活，融合多级特征保留策略的空间和语义线索，并引入几何感知概念判别损失来增强可解释性和减少概念重叠。", "result": "在CUB-200-2011、mini-ImageNet、CIFAR-FS、Stanford Cars、FGVC-Aircraft和DTD六个流行基准数据集上的实验结果表明，该方法在5-way 5-shot分类中始终显著优于现有SEMs，相对增益达4.2%-8.7%。", "conclusion": "将概念学习与少样本适应相结合，能够有效实现更高的准确性和更清晰的模型可解释性，为更透明的视觉识别系统奠定基础。", "translation": "自解释模型（SEMs）依赖原型概念学习（PCL）来使它们的视觉识别过程更具可解释性，但它们在数据稀缺的环境中常常表现不佳，因为训练样本不足导致次优性能。为了解决这一限制，我们提出了一种少样本原型概念分类（FSPCC）框架，系统地缓解了低数据条件下的两个关键挑战：参数不平衡和表示错位。具体而言，我们的方法利用LoRA专家混合（MoLE）进行参数高效适应，确保骨干网络和PCL模块之间可训练参数的平衡分配。同时，跨模块概念引导强制骨干网络的特征表示与原型概念激活模式之间紧密对齐。此外，我们结合了多级特征保留策略，融合了不同层级的空间和语义线索，从而丰富了学习到的表示并缓解了有限数据可用性带来的挑战。最后，为了增强可解释性并最小化概念重叠，我们引入了几何感知概念判别损失，强制概念之间正交性，鼓励更解耦和透明的决策边界。在六个流行基准数据集（CUB-200-2011、mini-ImageNet、CIFAR-FS、Stanford Cars、FGVC-Aircraft和DTD）上的实验结果表明，我们的方法始终显著优于现有SEMs，在5-way 5-shot分类中相对增益达到4.2%-8.7%。这些发现强调了将概念学习与少样本适应相结合以实现更高准确性和更清晰模型可解释性的有效性，为更透明的视觉识别系统铺平了道路。", "summary": "本文提出了少样本原型概念分类（FSPCC）框架，旨在解决自解释模型（SEMs）在数据稀缺环境下进行可解释少样本图像分类的局限性。FSPCC利用LoRA专家混合（MoLE）进行高效适应，采用跨模块概念引导，整合多级特征保留策略，并引入几何感知概念判别损失以提高可解释性和概念解耦。实验结果表明，该方法在多个基准测试中显著优于现有SEMs，验证了将概念学习与少样本适应结合用于准确和透明视觉识别的有效性。", "keywords": "可解释人工智能, 少样本学习, 原型网络, LoRA, 概念学习"}}
{"id": "2506.04439", "pdf": "https://arxiv.org/pdf/2506.04439", "abs": "https://arxiv.org/abs/2506.04439", "authors": ["Robin Yadav", "Qi Yan", "Guy Wolf", "Avishek Joey Bose", "Renjie Liao"], "title": "RETRO SYNFLOW: Discrete Flow Matching for Accurate and Diverse Single-Step Retrosynthesis", "categories": ["cs.LG"], "comment": null, "summary": "A fundamental problem in organic chemistry is identifying and predicting the\nseries of reactions that synthesize a desired target product molecule. Due to\nthe combinatorial nature of the chemical search space, single-step reactant\nprediction -- i.e. single-step retrosynthesis -- remains challenging even for\nexisting state-of-the-art template-free generative approaches to produce an\naccurate yet diverse set of feasible reactions. In this paper, we model\nsingle-step retrosynthesis planning and introduce RETRO SYNFLOW (RSF) a\ndiscrete flow-matching framework that builds a Markov bridge between the\nprescribed target product molecule and the reactant molecule. In contrast to\npast approaches, RSF employs a reaction center identification step to produce\nintermediate structures known as synthons as a more informative source\ndistribution for the discrete flow. To further enhance diversity and\nfeasibility of generated samples, we employ Feynman-Kac steering with\nSequential Monte Carlo based resampling to steer promising generations at\ninference using a new reward oracle that relies on a forward-synthesis model.\nEmpirically, we demonstrate \\nameshort achieves $60.0 \\%$ top-1 accuracy, which\noutperforms the previous SOTA by $20 \\%$. We also substantiate the benefits of\nsteering at inference and demonstrate that FK-steering improves top-$5$\nround-trip accuracy by $19 \\%$ over prior template-free SOTA methods, all while\npreserving competitive top-$k$ accuracy results.", "AI": {"title_translation": "RETRO SYNFLOW：用于准确和多样化单步逆合成的离散流匹配", "tldr": "RETRO SYNFLOW (RSF) 是一种新的离散流匹配框架，用于单步逆合成，通过引入合成子和费曼-卡茨引导显著提高了准确性和多样性，超越了现有最先进的方法。", "motivation": "在有机化学中，识别和预测合成目标产物分子所需的反应序列是一个基本问题。由于化学搜索空间的组合性质，即使对于现有的最先进的无模板生成方法，单步反应物预测（即单步逆合成）在生成准确且多样化的可行反应集方面仍然具有挑战性。", "method": "本文将单步逆合成规划建模，并引入了 RETRO SYNFLOW (RSF)，这是一个离散流匹配框架，它在目标产物分子和反应物分子之间构建了一个马尔可夫桥。与过去的方法不同，RSF 采用反应中心识别步骤来生成中间结构，即合成子，作为离散流的更具信息性的源分布。为了进一步增强生成样本的多样性和可行性，本文采用费曼-卡茨引导与基于序贯蒙特卡洛的重采样，在推理时使用一个新的奖励预言机来引导有前景的生成，该预言机依赖于正向合成模型。", "result": "实验证明，RSF 实现了 60.0% 的 Top-1 准确率，比之前的 SOTA 高出 20%。本文还证实了推理时引导的益处，并表明 FK 引导将 Top-5 往返准确率比之前的无模板 SOTA 方法提高了 19%，同时保持了有竞争力的 Top-k 准确率结果。", "conclusion": "RETRO SYNFLOW (RSF) 通过引入合成子和费曼-卡茨引导，显著提高了单步逆合成的准确性和多样性，在多个指标上超越了现有最先进的方法，证明了其在解决有机化学中反应预测挑战方面的有效性。", "translation": "有机化学中的一个基本问题是识别和预测合成所需目标产物分子的一系列反应。由于化学搜索空间的组合性质，即使对于现有的最先进的无模板生成方法，单步反应物预测（即单步逆合成）在生成准确且多样化的可行反应集方面仍然具有挑战性。在本文中，我们对单步逆合成规划进行建模，并引入了 RETRO SYNFLOW (RSF)，这是一个离散流匹配框架，它在规定的目标产物分子和反应物分子之间构建了一个马尔可夫桥。与过去的方法不同，RSF 采用反应中心识别步骤来生成中间结构，即合成子，作为离散流的更具信息性的源分布。为了进一步增强生成样本的多样性和可行性，我们采用费曼-卡茨引导与基于序贯蒙特卡洛的重采样，在推理时使用一个新的奖励预言机来引导有前景的生成，该预言机依赖于正向合成模型。经验上，我们证明 \nameshort 实现了 60.0% 的 Top-1 准确率，这比之前的 SOTA 高出 20%。我们还证实了推理时引导的益处，并证明 FK 引导将 Top-5 往返准确率比之前的无模板 SOTA 方法提高了 19%，同时保持了有竞争力的 Top-k 准确率结果。", "summary": "该论文提出了 RETRO SYNFLOW (RSF)，一个用于单步逆合成的离散流匹配框架，旨在解决现有方法在生成准确且多样化的可行反应集方面的挑战。RSF 通过引入反应中心识别步骤以生成合成子作为更具信息性的源分布，并结合费曼-卡茨引导与序贯蒙特卡洛重采样来增强多样性和可行性。实验结果表明，RSF 在 Top-1 准确率上达到了 60.0%，超越了现有 SOTA 20%，并且通过引导将 Top-5 往返准确率提高了 19%。", "keywords": "逆合成, 离散流匹配, 合成子, 费曼-卡茨引导, 机器学习"}}
{"id": "2506.04998", "pdf": "https://arxiv.org/pdf/2506.04998", "abs": "https://arxiv.org/abs/2506.04998", "authors": ["Mehdi Azarafza", "Mojtaba Nayyeri", "Faezeh Pasandideh", "Steffen Staab", "Achim Rettberg"], "title": "Mathematical Reasoning for Unmanned Aerial Vehicles: A RAG-Based Approach for Complex Arithmetic Reasoning", "categories": ["cs.AI"], "comment": "15 pages, 7 figures, 4 appendix subsections", "summary": "Autonomous UAV operation necessitates reliable mathematical reasoning for\ntasks such as trajectory planning and power management. While traditional\nflight control relies on hardcoded equations, recent Large Language Models\n(LLMs) offer potential for more flexible problem-solving but struggle with\nreliably selecting and applying correct mathematical formulations and executing\nprecise multi-step arithmetic. We propose RAG-UAV, a retrieval-augmented\ngeneration framework designed to improve the mathematical reasoning of several\nLLMs (including GPT o1/Turbo, Llama-3.2/3.3, Mistral, and DeepSeek R1) in\nUAV-specific contexts by providing access to relevant domain literature. To\nconduct an initial assessment, we introduce the UAV-Math-Bench, a small problem\nset comprising 20 UAV-centric mathematical problems across four difficulty\nlevels. Our experiments demonstrate that incorporating retrieval substantially\nincreases exact answer accuracy (achieving up to 75% with o1), reduces\ninstances of incorrect formulation selection (from 25% without RAG to 5% with\nRAG), decreases numerical errors, reducing Mean Squared Error (MSE) by orders\nof magnitude for the best-performing models. This pilot study indicates that\nRAG can enable general-purpose LLMs to function as more reliable tools for\nengineering analysis, although direct real-time flight control requires further\ninvestigation and validation on a larger scale. All benchmark data, question\nand answer are publicly available.", "AI": {"title_translation": "无人机数学推理：一种基于RAG的复杂算术推理方法", "tldr": "本研究提出RAG-UAV框架，通过检索增强生成来提升大型语言模型在无人机复杂数学推理任务中的表现，实验显示RAG显著提高了准确性并减少了错误。", "motivation": "自主无人机操作需要可靠的数学推理能力，例如轨迹规划和电源管理。传统飞行控制依赖硬编码方程，而大型语言模型（LLMs）虽有潜力，但在选择和应用正确数学公式以及执行精确多步算术方面存在困难。", "method": "本研究提出了RAG-UAV，一个检索增强生成框架，旨在通过提供相关领域文献来提高LLMs（包括GPT o1/Turbo、Llama-3.2/3.3、Mistral和DeepSeek R1）在无人机特定背景下的数学推理能力。为进行初步评估，引入了UAV-Math-Bench，一个包含20个以无人机为中心的数学问题的测试集，分为四个难度级别。", "result": "实验表明，结合检索功能显著提高了精确答案的准确性（o1模型最高达到75%），减少了不正确公式选择的实例（从没有RAG时的25%降至有RAG时的5%），并减少了数值错误，使表现最佳模型的均方误差（MSE）降低了几个数量级。", "conclusion": "这项初步研究表明，RAG可以使通用LLMs成为更可靠的工程分析工具，尽管直接的实时飞行控制需要进一步的调查和更大规模的验证。", "translation": "自主无人机操作需要可靠的数学推理能力，以完成轨迹规划和电源管理等任务。虽然传统飞行控制依赖硬编码方程，但近期的大型语言模型（LLMs）为更灵活的问题解决提供了潜力，然而它们在可靠地选择和应用正确的数学公式以及执行精确的多步算术方面存在困难。我们提出了RAG-UAV，一个检索增强生成框架，旨在通过提供相关领域文献来提高多种LLMs（包括GPT o1/Turbo、Llama-3.2/3.3、Mistral和DeepSeek R1）在无人机特定背景下的数学推理能力。为了进行初步评估，我们引入了UAV-Math-Bench，一个包含20个以无人机为中心的数学问题的小型问题集，涵盖四个难度级别。我们的实验表明，结合检索功能显著提高了精确答案的准确性（o1模型最高达到75%），减少了不正确公式选择的实例（从没有RAG时的25%降至有RAG时的5%），并减少了数值错误，使表现最佳模型的均方误差（MSE）降低了几个数量级。这项初步研究表明，RAG可以使通用LLMs成为更可靠的工程分析工具，尽管直接的实时飞行控制需要进一步的调查和更大规模的验证。所有基准测试数据、问题和答案均已公开。", "summary": "本研究提出RAG-UAV框架，旨在通过检索增强生成技术提升大型语言模型在无人机数学推理任务中的表现。针对轨迹规划和电源管理等任务中LLMs在数学公式选择和多步算术执行上的不足，RAG-UAV通过提供相关领域文献来增强LLMs的推理能力。研究引入了UAV-Math-Bench作为评估工具，初步实验结果显示，RAG显著提高了LLMs的答案准确性，减少了公式选择错误和数值误差，使LLMs能更可靠地应用于工程分析。", "keywords": "无人机, 数学推理, 大型语言模型, 检索增强生成, RAG"}}
{"id": "2506.04446", "pdf": "https://arxiv.org/pdf/2506.04446", "abs": "https://arxiv.org/abs/2506.04446", "authors": ["Gil I. Shamir", "Manfred K. Warmuth"], "title": "Selective Matching Losses -- Not All Scores Are Created Equal", "categories": ["cs.LG"], "comment": null, "summary": "Learning systems match predicted scores to observations over some domain.\nOften, it is critical to produce accurate predictions in some subset (or\nregion) of the domain, yet less important to accurately predict in other\nregions. We construct selective matching loss functions by design of increasing\nlink functions over score domains. A matching loss is an integral over the\nlink. A link defines loss sensitivity as function of the score, emphasizing\nhigh slope high sensitivity regions over flat ones. Loss asymmetry drives a\nmodel and resolves its underspecification to predict better in high sensitivity\nregions where it is more important, and to distinguish between high and low\nimportance regions. A large variety of selective scalar losses can be designed\nwith scaled and shifted Sigmoid and hyperbolic sine links. Their properties,\nhowever, do not extend to multi-class. Applying them per dimension lacks\nranking sensitivity that assigns importance according to class score ranking.\nUtilizing composite Softmax functions, we develop a framework for\nmultidimensional selective losses. We overcome limitations of the standard\nSoftmax function, that is good for classification, but not for distinction\nbetween adjacent scores. Selective losses have substantial advantage over\ntraditional losses in applications with more important score regions, including\ndwell-time prediction, retrieval, ranking with either pointwise, contrastive\npairwise, or listwise losses, distillation problems, and fine-tuning alignment\nof Large Language Models (LLMs).", "AI": {"title_translation": "选择性匹配损失——并非所有分数都同等重要", "tldr": "论文提出选择性匹配损失函数，通过强调特定分数区域的预测精度，优于传统损失函数，尤其适用于多维和LLM对齐等应用。", "motivation": "在某些应用中，模型在特定分数区域的预测精度至关重要，而在其他区域则不那么重要。传统损失函数未能有效区分这些区域的重要性，导致资源浪费或在关键区域表现不佳。", "method": "本文通过设计分数域上递增的链接函数来构建选择性匹配损失函数，其中损失是链接函数的积分，链接函数定义了损失敏感度。利用损失不对称性，使模型在更重要的区域表现更好。对于多类问题，开发了基于复合Softmax函数的多维选择性损失框架，克服了标准Softmax在区分相邻分数上的局限性。", "result": "选择性损失函数在具有更重要分数区域的应用中，相比传统损失函数具有显著优势，例如停留时间预测、检索、排序（点对、对比成对或列表式损失）、蒸馏问题以及大型语言模型（LLM）的微调对齐。", "conclusion": "选择性匹配损失函数通过强调关键分数区域的预测精度，在多种实际应用中展现出优于传统损失函数的显著优势，尤其在处理多维数据和LLM对齐方面具有重要价值。", "translation": "学习系统将预测分数与某个域上的观测值进行匹配。通常，在域的某个子集（或区域）中产生准确的预测至关重要，而在其他区域进行准确预测则不那么重要。我们通过设计分数域上递增的链接函数来构建选择性匹配损失函数。匹配损失是链接函数的积分。链接函数将损失敏感度定义为分数的函数，强调高斜率高敏感度区域而非平坦区域。损失不对称性驱动模型并解决其欠规范性，以在更重要的高敏感度区域进行更好的预测，并区分高重要性区域和低重要性区域。通过缩放和移位的Sigmoid和双曲正弦链接函数可以设计出各种选择性标量损失。然而，它们的特性不适用于多类情况。对每个维度应用它们缺乏根据类别分数排名分配重要性的排名敏感性。利用复合Softmax函数，我们开发了一个多维选择性损失框架。我们克服了标准Softmax函数的局限性，该函数适用于分类，但不适用于区分相邻分数。选择性损失在具有更重要分数区域的应用中比传统损失具有显著优势，包括停留时间预测、检索、点对式、对比成对式或列表式损失的排序、蒸馏问题以及大型语言模型（LLM）的微调对齐。", "summary": "本文提出了一种新型的选择性匹配损失函数，旨在解决学习系统在不同分数区域对预测精度要求不一致的问题。通过设计具有特定敏感度（由链接函数定义）的损失函数，该方法能够引导模型在关键分数区域进行更精确的预测，同时区分高重要性与低重要性区域。论文不仅构建了适用于标量情况的多种选择性损失，还进一步开发了基于复合Softmax函数的多维选择性损失框架，克服了标准Softmax在区分相邻分数上的不足。实验表明，这种选择性损失在需要强调特定分数区域的应用中（如停留时间预测、检索、排序和LLM对齐）相比传统损失具有显著优势。", "keywords": "选择性匹配损失, 链接函数, 复合Softmax, 预测精度, LLM对齐"}}
{"id": "2506.04286", "pdf": "https://arxiv.org/pdf/2506.04286", "abs": "https://arxiv.org/abs/2506.04286", "authors": ["Henriette Harmse", "Haider Iqbal", "Helen Parkinson", "James McLaughlin"], "title": "OxO2 -- A SSSOM mapping browser for logically sound crosswalks", "categories": ["cs.DB"], "comment": "11 pages, 2 figures and 2 tables. Also submitted to FOIS\n  Demonstration track and awaiting feedback", "summary": "EMBL-EBI created OxO to enable users to map between datasets that are\nannotated with different ontologies. Mappings identified by the first version\nof OxO were not necessarily logically sound, missed important provenance\ninformation such as author and reviewer, and could timeout or crash for certain\nrequests. In this paper we introduce OxO2 to address these concerns. Provenance\nis addressed by implementing SSSOM, a mapping standard that defines provenance\nfor mappings. SSSOM defines the conditions under which logical sound mappings\ncan be derived and is implemented in OxO2 using, Nemo, a Datalog rule engine.\nTo ensure reasoning is performant and memory efficient, Nemo implements a\nnumber of strategies that ensures OxO2 will be stable for all requests. Due to\nthese changes, OxO2 users will be able to integrate between disparate datasets\nwith greater confidence.", "AI": {"title_translation": "OxO2——一个用于逻辑上可靠的交叉映射的SSSOM映射浏览器", "tldr": "OxO2通过实现SSSOM和使用Datalog规则引擎Nemo，解决了前身OxO在映射逻辑可靠性、溯源信息和系统稳定性方面的问题，从而提高了不同数据集之间集成的信心。", "motivation": "EMBL-EBI创建的OxO初版在不同本体之间映射时存在问题，包括映射逻辑不一定可靠、缺乏重要的溯源信息（如作者和审阅者），以及在某些请求下可能超时或崩溃。", "method": "OxO2通过实现SSSOM（一个定义映射溯源的标准）来解决溯源问题。SSSOM在OxO2中通过Datalog规则引擎Nemo实现，该引擎定义了导出逻辑上可靠映射的条件。Nemo还实现了多种策略，以确保推理的性能和内存效率，从而保证OxO2在所有请求下的稳定性。", "result": "OxO2解决了映射逻辑可靠性、溯源信息缺失以及系统稳定性问题。它能确保推理的性能和内存效率，并且在所有请求下都保持稳定。", "conclusion": "OxO2的改进使用户能够更自信地整合不同数据集。", "translation": "EMBL-EBI创建了OxO，旨在帮助用户在用不同本体注释的数据集之间进行映射。OxO的第一个版本识别出的映射不一定在逻辑上可靠，缺少重要的溯源信息，例如作者和审阅者，并且在某些请求下可能会超时或崩溃。在本文中，我们介绍了OxO2来解决这些问题。通过实现SSSOM（一个定义映射溯源的映射标准）来解决溯源问题。SSSOM定义了可以导出逻辑上可靠映射的条件，并在OxO2中通过Datalog规则引擎Nemo实现。为了确保推理的性能和内存效率，Nemo实施了多项策略，确保OxO2在所有请求下都将保持稳定。由于这些这些改变，OxO2用户将能够更自信地整合不同数据集。", "summary": "本文介绍了OxO2，它是EMBL-EBI开发的OxO的改进版本，旨在解决原版OxO在本体间映射时存在的逻辑可靠性不足、溯源信息缺失以及系统稳定性差的问题。OxO2通过实现SSSOM标准来处理溯源信息，并利用Datalog规则引擎Nemo确保映射的逻辑可靠性、推理性能和内存效率，从而使用户能够更自信地整合异构数据集。", "keywords": "OxO2, SSSOM, Datalog, 本体映射, 数据集成"}}
{"id": "2506.05109", "pdf": "https://arxiv.org/pdf/2506.05109", "abs": "https://arxiv.org/abs/2506.05109", "authors": ["Tennison Liu", "Mihaela van der Schaar"], "title": "Truly Self-Improving Agents Require Intrinsic Metacognitive Learning", "categories": ["cs.AI"], "comment": "Published as a conference paper at ICML 2025", "summary": "Self-improving agents aim to continuously acquire new capabilities with\nminimal supervision. However, current approaches face two key limitations:\ntheir self-improvement processes are often rigid, fail to generalize across\ntasks domains, and struggle to scale with increasing agent capabilities. We\nargue that effective self-improvement requires intrinsic metacognitive\nlearning, defined as an agent's intrinsic ability to actively evaluate, reflect\non, and adapt its own learning processes. Drawing inspiration from human\nmetacognition, we introduce a formal framework comprising three components:\nmetacognitive knowledge (self-assessment of capabilities, tasks, and learning\nstrategies), metacognitive planning (deciding what and how to learn), and\nmetacognitive evaluation (reflecting on learning experiences to improve future\nlearning). Analyzing existing self-improving agents, we find they rely\npredominantly on extrinsic metacognitive mechanisms, which are fixed,\nhuman-designed loops that limit scalability and adaptability. Examining each\ncomponent, we contend that many ingredients for intrinsic metacognition are\nalready present. Finally, we explore how to optimally distribute metacognitive\nresponsibilities between humans and agents, and robustly evaluate and improve\nintrinsic metacognitive learning, key challenges that must be addressed to\nenable truly sustained, generalized, and aligned self-improvement.", "AI": {"title_translation": "真正自我改进的智能体需要内在元认知学习", "tldr": "本文提出，要实现真正自我改进的智能体，需要引入内在元认知学习，并提出了一个包含元认知知识、规划和评估的框架，指出当前智能体主要依赖外在机制，并探讨了未来需要解决的关键挑战。", "motivation": "当前的自我改进智能体在自我改进过程中存在僵化、泛化能力差、难以随能力提升而扩展等局限性。本文认为，有效的自我改进需要内在元认知学习。", "method": "本文提出了一个包含三个组成部分的内在元认知学习形式化框架：元认知知识（对自身能力、任务和学习策略的自我评估）、元认知规划（决定学习什么以及如何学习）和元认知评估（反思学习经验以改进未来的学习）。通过分析现有自我改进智能体，发现它们主要依赖外在元认知机制。", "result": "现有自我改进智能体主要依赖固定的人类设计的外在元认知机制，这限制了它们的可扩展性和适应性。许多内在元认知所需的要素已经存在。", "conclusion": "为了实现真正持续、泛化和对齐的自我改进，必须解决如何优化分配人类和智能体之间的元认知责任，以及如何稳健地评估和改进内在元认知学习等关键挑战。", "translation": "自改进智能体旨在以最少的监督持续获取新能力。然而，当前的方法面临两个关键限制：它们的自改进过程通常僵化，无法跨任务领域泛化，并且难以随着智能体能力的增强而扩展。我们认为，有效的自改进需要内在元认知学习，其定义为智能体主动评估、反思和适应自身学习过程的内在能力。借鉴人类元认知，我们引入了一个包含三个组成部分的形式化框架：元认知知识（对能力、任务和学习策略的自我评估）、元认知规划（决定学习什么以及如何学习）和元认知评估（反思学习经验以改进未来的学习）。通过分析现有自改进智能体，我们发现它们主要依赖外在元认知机制，这些机制是固定的、由人类设计的循环，限制了可扩展性和适应性。通过检查每个组成部分，我们认为内在元认知的许多要素已经存在。最后，我们探讨了如何优化分配人类和智能体之间的元认知责任，以及如何稳健地评估和改进内在元认知学习，这些都是实现真正持续、泛化和对齐的自改进所必须解决的关键挑战。", "summary": "本文指出当前自我改进智能体面临的局限性，并提出引入内在元认知学习作为解决方案。文章借鉴人类元认知，提出了一个包含元认知知识、规划和评估的形式化框架。通过分析，发现现有智能体主要依赖外在元认知机制。文章最后探讨了实现持续、泛化和对齐的自我改进所面临的关键挑战，包括元认知责任分配和评估改进。", "keywords": "自改进智能体, 元认知学习, 内在机制, 人工智能, 学习过程"}}
{"id": "2506.04682", "pdf": "https://arxiv.org/pdf/2506.04682", "abs": "https://arxiv.org/abs/2506.04682", "authors": ["Chuyun Deng", "Na Liu", "Wei Xie", "Lianming Xu", "Li Wang"], "title": "MARS: Radio Map Super-resolution and Reconstruction Method under Sparse Channel Measurements", "categories": ["cs.CV", "eess.SP"], "comment": null, "summary": "Radio maps reflect the spatial distribution of signal strength and are\nessential for applications like smart cities, IoT, and wireless network\nplanning. However, reconstructing accurate radio maps from sparse measurements\nremains challenging. Traditional interpolation and inpainting methods lack\nenvironmental awareness, while many deep learning approaches depend on detailed\nscene data, limiting generalization. To address this, we propose MARS, a\nMulti-scale Aware Radiomap Super-resolution method that combines CNNs and\nTransformers with multi-scale feature fusion and residual connections. MARS\nfocuses on both global and local feature extraction, enhancing feature\nrepresentation across different receptive fields and improving reconstruction\naccuracy. Experiments across different scenes and antenna locations show that\nMARS outperforms baseline models in both MSE and SSIM, while maintaining low\ncomputational cost, demonstrating strong practical potential.", "AI": {"title_translation": "MARS：稀疏信道测量下的无线电地图超分辨率重建方法", "tldr": "MARS是一种结合CNN和Transformer的无线电地图超分辨率方法，能从稀疏测量中重建精确无线电地图，性能优于现有方法且计算成本低。", "motivation": "从稀疏测量中重建准确的无线电地图仍然具有挑战性。传统插值和修复方法缺乏环境感知能力，而许多深度学习方法依赖于详细的场景数据，限制了泛化能力。", "method": "我们提出了MARS，一种多尺度感知无线电地图超分辨率方法，它结合了CNN和Transformer，并采用多尺度特征融合和残差连接。MARS专注于全局和局部特征提取，增强不同感受野的特征表示，提高重建精度。", "result": "在不同场景和天线位置的实验表明，MARS在MSE和SSIM方面均优于基线模型，同时保持较低的计算成本。", "conclusion": "MARS方法能够有效解决稀疏测量下无线电地图重建的挑战，展现出强大的实际应用潜力。", "translation": "无线电地图反映了信号强度的空间分布，对于智慧城市、物联网和无线网络规划等应用至关重要。然而，从稀疏测量中重建准确的无线电地图仍然具有挑战性。传统的插值和修复方法缺乏环境感知能力，而许多深度学习方法依赖于详细的场景数据，限制了泛化能力。为了解决这个问题，我们提出了MARS，一种多尺度感知无线电地图超分辨率方法，它结合了CNN和Transformer，并采用多尺度特征融合和残差连接。MARS专注于全局和局部特征提取，增强不同感受野的特征表示，提高重建精度。在不同场景和天线位置的实验表明，MARS在MSE和SSIM方面均优于基线模型，同时保持较低的计算成本，展现出强大的实际应用潜力。", "summary": "该论文提出了一种名为MARS的无线电地图超分辨率方法，旨在解决从稀疏测量中重建准确无线电地图的挑战。MARS结合了CNN和Transformer，并利用多尺度特征融合和残差连接，以增强特征表示和提高重建精度。实验结果表明，MARS在多种场景下均优于现有基线模型，且计算成本较低，具有广阔的应用前景。", "keywords": "无线电地图, 超分辨率, 稀疏测量, CNN, Transformer"}}
{"id": "2506.04454", "pdf": "https://arxiv.org/pdf/2506.04454", "abs": "https://arxiv.org/abs/2506.04454", "authors": ["Huynh T. T. Tran", "Jacob Sander", "Achraf Cohen", "Brian Jalaian", "Nathaniel D. Bastian"], "title": "Neurosymbolic Artificial Intelligence for Robust Network Intrusion Detection: From Scratch to Transfer Learning", "categories": ["cs.LG"], "comment": "17 pages, 5 figures, 11 tables", "summary": "Network Intrusion Detection Systems (NIDS) play a vital role in protecting\ndigital infrastructures against increasingly sophisticated cyber threats. In\nthis paper, we extend ODXU, a Neurosymbolic AI (NSAI) framework that integrates\ndeep embedded clustering for feature extraction, symbolic reasoning using\nXGBoost, and comprehensive uncertainty quantification (UQ) to enhance\nrobustness, interpretability, and generalization in NIDS. The extended ODXU\nincorporates score-based methods (e.g., Confidence Scoring, Shannon Entropy)\nand metamodel-based techniques, including SHAP values and Information Gain, to\nassess the reliability of predictions. Experimental results on the CIC-IDS-2017\ndataset show that ODXU outperforms traditional neural models across six\nevaluation metrics, including classification accuracy and false omission rate.\nWhile transfer learning has seen widespread adoption in fields such as computer\nvision and natural language processing, its potential in cybersecurity has not\nbeen thoroughly explored. To bridge this gap, we develop a transfer learning\nstrategy that enables the reuse of a pre-trained ODXU model on a different\ndataset. Our ablation study on ACI-IoT-2023 demonstrates that the optimal\ntransfer configuration involves reusing the pre-trained autoencoder, retraining\nthe clustering module, and fine-tuning the XGBoost classifier, and outperforms\ntraditional neural models when trained with as few as 16,000 samples\n(approximately 50% of the training data). Additionally, results show that\nmetamodel-based UQ methods consistently outperform score-based approaches on\nboth datasets.", "AI": {"title_translation": "用于鲁棒网络入侵检测的神经符号人工智能：从头开始到迁移学习", "tldr": "本文扩展了神经符号AI框架ODXU，通过整合不确定性量化方法增强网络入侵检测系统的鲁棒性、可解释性和泛化能力，并提出了一种有效的迁移学习策略，实验证明其在多个数据集上优于传统神经网络模型。", "motivation": "网络入侵检测系统（NIDS）在保护数字基础设施免受日益复杂的网络威胁方面发挥着关键作用。然而，传统的NIDS可能在鲁棒性、可解释性和泛化能力方面存在不足。同时，迁移学习在网络安全领域的潜力尚未得到充分探索。", "method": "本文扩展了ODXU，这是一个神经符号AI（NSAI）框架，它集成了用于特征提取的深度嵌入聚类、使用XGBoost的符号推理以及全面的不确定性量化（UQ）。扩展后的ODXU引入了基于分数的方法（如置信度评分、香农熵）和基于元模型的技术（包括SHAP值和信息增益）来评估预测的可靠性。此外，本文还开发了一种迁移学习策略，以实现在不同数据集上重用预训练的ODXU模型。", "result": "在CIC-IDS-2017数据集上的实验结果表明，ODXU在包括分类精度和错误遗漏率在内的六项评估指标上优于传统神经网络模型。在ACI-IoT-2023数据集上的消融研究表明，最佳的迁移配置是重用预训练的自编码器、重新训练聚类模块并微调XGBoost分类器，并且在仅使用16,000个样本（大约50%的训练数据）进行训练时，其性能优于传统神经网络模型。此外，结果显示基于元模型的UQ方法在两个数据集上都始终优于基于分数的方法。", "conclusion": "扩展的神经符号AI框架ODXU显著提升了网络入侵检测的鲁棒性、可解释性和泛化能力，并通过有效的迁移学习策略证明了其在不同数据集上的适用性，为网络安全领域带来了新的突破。", "translation": "网络入侵检测系统（NIDS）在保护数字基础设施免受日益复杂的网络威胁方面发挥着至关重要的作用。在本文中，我们扩展了ODXU，这是一个神经符号AI（NSAI）框架，它集成了用于特征提取的深度嵌入聚类、使用XGBoost的符号推理以及全面的不确定性量化（UQ），以增强NIDS的鲁棒性、可解释性和泛化能力。扩展后的ODXU融入了基于分数的方法（例如，置信度评分、香农熵）和基于元模型的技术，包括SHAP值和信息增益，以评估预测的可靠性。在CIC-IDS-2017数据集上的实验结果表明，ODXU在包括分类精度和错误遗漏率在内的六项评估指标上优于传统神经网络模型。虽然迁移学习在计算机视觉和自然语言处理等领域得到了广泛应用，但其在网络安全领域的潜力尚未得到彻底探索。为了弥补这一空白，我们开发了一种迁移学习策略，使得预训练的ODXU模型可以在不同的数据集上重用。我们对ACI-IoT-2023进行的消融研究表明，最佳的迁移配置包括重用预训练的自编码器、重新训练聚类模块以及微调XGBoost分类器，并且在仅用16,000个样本（大约50%的训练数据）进行训练时，其性能优于传统神经网络模型。此外，结果显示基于元模型的UQ方法在两个数据集上都始终优于基于分数的方法。", "summary": "本文介绍并扩展了ODXU，一个结合深度嵌入聚类、XGBoost符号推理和不确定性量化的神经符号人工智能框架，旨在提升网络入侵检测系统的鲁棒性、可解释性和泛化能力。实验结果表明，ODXU在CIC-IDS-2017数据集上表现优于传统神经网络模型。为解决网络安全领域迁移学习应用不足的问题，研究者提出了一种ODXU的迁移学习策略，并在ACI-IoT-2023数据集上验证了其有效性，证明了预训练模型在少量数据下仍能超越传统模型。此外，研究还发现基于元模型的UQ方法优于基于分数的方法。", "keywords": "神经符号人工智能, 网络入侵检测, 迁移学习, 不确定性量化, ODXU"}}
{"id": "2506.05250", "pdf": "https://arxiv.org/pdf/2506.05250", "abs": "https://arxiv.org/abs/2506.05250", "authors": ["Zhiyun Deng", "Dongmyeong Lee", "Amanda Adkins", "Jesse Quattrociocchi", "Christian Ellis", "Joydeep Biswas"], "title": "Spatiotemporal Contrastive Learning for Cross-View Video Localization in Unstructured Off-road Terrains", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Robust cross-view 3-DoF localization in GPS-denied, off-road environments\nremains challenging due to (1) perceptual ambiguities from repetitive\nvegetation and unstructured terrain, and (2) seasonal shifts that significantly\nalter scene appearance, hindering alignment with outdated satellite imagery. To\naddress this, we introduce MoViX, a self-supervised cross-view video\nlocalization framework that learns viewpoint- and season-invariant\nrepresentations while preserving directional awareness essential for accurate\nlocalization. MoViX employs a pose-dependent positive sampling strategy to\nenhance directional discrimination and temporally aligned hard negative mining\nto discourage shortcut learning from seasonal cues. A motion-informed frame\nsampler selects spatially diverse frames, and a lightweight temporal aggregator\nemphasizes geometrically aligned observations while downweighting ambiguous\nones. At inference, MoViX runs within a Monte Carlo Localization framework,\nusing a learned cross-view matching module in place of handcrafted models.\nEntropy-guided temperature scaling enables robust multi-hypothesis tracking and\nconfident convergence under visual ambiguity. We evaluate MoViX on the\nTartanDrive 2.0 dataset, training on under 30 minutes of data and testing over\n12.29 km. Despite outdated satellite imagery, MoViX localizes within 25 meters\nof ground truth 93% of the time, and within 50 meters 100% of the time in\nunseen regions, outperforming state-of-the-art baselines without\nenvironment-specific tuning. We further demonstrate generalization on a\nreal-world off-road dataset from a geographically distinct site with a\ndifferent robot platform.", "AI": {"title_translation": "非结构化越野地形中跨视角视频定位的时空对比学习", "tldr": "MoViX是一个基于时空对比学习的自监督框架，用于在GPS受限的越野环境中进行鲁棒的跨视角视频定位，通过学习视角和季节不变的表示，并在TartanDrive 2.0数据集上表现出优于现有技术的性能。", "motivation": "在GPS受限的越野环境中，由于重复植被和非结构化地形造成的感知模糊以及季节变化导致场景外观显著改变，使得鲁棒的跨视角3自由度定位面临挑战。", "method": "本文引入了MoViX，一个自监督的跨视角视频定位框架，该框架学习视角和季节不变的表示，同时保留对准确定位至关重要的方向感知。MoViX采用了姿态依赖的正样本采样策略以增强方向辨别能力，并采用时间对齐的困难负样本挖掘来阻止从季节线索中学习捷径。一个运动信息的帧采样器选择空间多样化的帧，一个轻量级的时间聚合器强调几何对齐的观测，同时降低模糊观测的权重。在推理时，MoViX在蒙特卡洛定位框架内运行，使用学习到的跨视角匹配模块代替手工制作的模型。熵引导的温度缩放使得在视觉模糊下也能实现鲁棒的多假设跟踪和自信的收敛。", "result": "MoViX在TartanDrive 2.0数据集上进行了评估，仅使用不到30分钟的数据进行训练，并在12.29公里长的区域进行测试。尽管卫星图像已过时，MoViX在93%的时间内将定位误差控制在25米以内，在100%的时间内将定位误差控制在50米以内，且无需特定环境调整，优于现有技术基线。此外，还在来自不同地理位置和不同机器人平台的真实世界越野数据集上展示了泛化能力。", "conclusion": "MoViX通过时空对比学习，有效地解决了GPS受限越野环境中跨视角视频定位的挑战，实现了高精度和强泛化能力，即使在恶劣条件下也能超越现有技术。", "translation": "在GPS受限的越野环境中，鲁棒的跨视角3自由度定位仍然具有挑战性，原因在于 (1) 重复植被和非结构化地形造成的感知模糊，以及 (2) 季节性变化显著改变场景外观，阻碍与过时卫星图像的对齐。为了解决这个问题，我们引入了MoViX，一个自监督的跨视角视频定位框架，该框架学习视角和季节不变的表示，同时保留对准确定位至关重要的方向感知。MoViX采用了姿态依赖的正样本采样策略以增强方向辨别能力，并采用时间对齐的困难负样本挖掘来阻止从季节线索中学习捷径。一个运动信息的帧采样器选择空间多样化的帧，一个轻量级的时间聚合器强调几何对齐的观测，同时降低模糊观测的权重。在推理时，MoViX在蒙特卡洛定位框架内运行，使用学习到的跨视角匹配模块代替手工制作的模型。熵引导的温度缩放使得在视觉模糊下也能实现鲁棒的多假设跟踪和自信的收敛。我们在TartanDrive 2.0数据集上评估了MoViX，使用不到30分钟的数据进行训练，并在12.29公里的区域进行测试。尽管卫星图像已过时，MoViX在93%的时间内将定位误差控制在25米以内，在100%的时间内将定位误差控制在50米以内，且无需特定环境调整，优于现有技术基线。我们进一步展示了在来自不同地理位置和不同机器人平台的真实世界越野数据集上的泛化能力。", "summary": "本文提出MoViX，一个自监督的跨视角视频定位框架，旨在解决GPS受限越野环境中因感知模糊和季节变化导致的定位难题。MoViX通过学习视角和季节不变的表示，并利用姿态依赖的正样本采样和时间对齐的困难负样本挖掘来增强方向辨别和避免捷径学习。该框架还包含运动信息的帧采样器和轻量级时间聚合器，并在推理时集成到蒙特卡洛定位框架中。实验结果表明，MoViX在TartanDrive 2.0数据集上表现出色，在25米和50米精度内分别达到93%和100%的定位成功率，且无需环境特定调优，并展现了良好的泛化能力。", "keywords": "跨视角定位, 视频定位, 时空对比学习, 越野地形, 自监督学习"}}
{"id": "2506.05213", "pdf": "https://arxiv.org/pdf/2506.05213", "abs": "https://arxiv.org/abs/2506.05213", "authors": ["Nathan Herr", "Tim Rocktäschel", "Roberta Raileanu"], "title": "LLM-First Search: Self-Guided Exploration of the Solution Space", "categories": ["cs.AI", "cs.CL"], "comment": "9 main pages, 2 figures, 2 tables, 36 appendix pages", "summary": "Large Language Models (LLMs) have demonstrated remarkable improvements in\nreasoning and planning through increased test-time compute, often by framing\nproblem-solving as a search process. While methods like Monte Carlo Tree Search\n(MCTS) have proven effective in some domains, their reliance on fixed\nexploration hyperparameters limits their adaptability across tasks of varying\ndifficulty, rendering them impractical or expensive in certain settings. In\nthis paper, we propose \\textbf{LLM-First Search (LFS)}, a novel \\textit{LLM\nSelf-Guided Search} method that removes the need for pre-defined search\nstrategies by empowering the LLM to autonomously control the search process via\nself-guided exploration. Rather than relying on external heuristics or\nhardcoded policies, the LLM evaluates whether to pursue the current search path\nor explore alternative branches based on its internal scoring mechanisms. This\nenables more flexible and context-sensitive reasoning without requiring manual\ntuning or task-specific adaptation. We evaluate LFS on Countdown and Sudoku\nagainst three classic widely-used search algorithms, Tree-of-Thoughts' Breadth\nFirst Search (ToT-BFS), Best First Search (BestFS), and MCTS, each of which\nhave been used to achieve SotA results on a range of challenging reasoning\ntasks. We found that LFS (1) performs better on more challenging tasks without\nadditional tuning, (2) is more computationally efficient compared to the other\nmethods, especially when powered by a stronger model, (3) scales better with\nstronger models, due to its LLM-First design, and (4) scales better with\nincreased compute budget. Our code is publicly available at\n\\href{https://github.com/NathanHerr/LLM-First-Search}{LLM-First-Search}.", "AI": {"title_translation": "LLM优先搜索：解空间中的自我引导探索", "tldr": "LLM优先搜索（LFS）是一种新型的LLM自我引导搜索方法，通过赋予LLM自主控制搜索过程的能力，消除了对预定义搜索策略的需求，并在具有挑战性的任务上表现更好，计算效率更高。", "motivation": "传统的搜索方法如蒙特卡洛树搜索（MCTS）在解决问题时依赖固定的探索超参数，这限制了它们在不同难度任务上的适应性，使其在某些情况下不实用或成本高昂。", "method": "本文提出了一种新颖的“LLM优先搜索（LFS）”方法，这是一种LLM自我引导搜索方法。该方法通过赋予大型语言模型（LLM）自主控制搜索过程的能力，消除了对预定义搜索策略的需求。LLM利用其内部评分机制，评估是继续当前搜索路径还是探索其他分支，从而实现更灵活和上下文敏感的推理，无需手动调整或特定任务适应。", "result": "实验结果表明，LLM优先搜索（LFS）在更具挑战性的任务上表现更好，无需额外调整；与其他方法相比，它在计算上更高效，尤其是在由更强大的模型驱动时；由于其LLM优先设计，它能更好地与更强大的模型协同工作；并且随着计算预算的增加，其性能扩展性更好。", "conclusion": "LLM优先搜索（LFS）通过赋予LLM自主控制搜索过程的能力，提供了一种更灵活、更高效的解决方案，尤其适用于更具挑战性的任务，并且能够更好地利用更强大的模型和计算资源。", "translation": "大型语言模型（LLM）通过增加测试时计算量，在推理和规划方面表现出显著改进，通常将问题解决框架为搜索过程。虽然蒙特卡洛树搜索（MCTS）等方法在某些领域已被证明有效，但它们对固定探索超参数的依赖限制了其在不同难度任务上的适应性，使其在某些设置中不切实际或成本高昂。在本文中，我们提出了\\textbf{LLM优先搜索（LFS）}，一种新颖的\\textit{LLM自我引导搜索}方法，它通过赋予LLM通过自我引导探索自主控制搜索过程的能力，消除了对预定义搜索策略的需求。LLM不依赖外部启发式或硬编码策略，而是根据其内部评分机制评估是继续当前搜索路径还是探索替代分支。这使得更灵活和上下文敏感的推理成为可能，而无需手动调整或特定任务适应。我们在Countdown和Sudoku上评估了LFS，并将其与三种经典的广泛使用的搜索算法进行比较：思想树的广度优先搜索（ToT-BFS）、最佳优先搜索（BestFS）和MCTS，这些算法都曾在一系列具有挑战性的推理任务中取得最先进的结果。我们发现LFS（1）在更具挑战性的任务上表现更好，无需额外调整；（2）与其他方法相比，计算效率更高，尤其是在由更强大的模型驱动时；（3）由于其LLM优先设计，能更好地与更强大的模型协同工作；（4）随着计算预算的增加，其性能扩展性更好。我们的代码已在\\href{https://github.com/NathanHerr/LLM-First-Search}{LLM-First-Search}公开可用。", "summary": "本论文介绍了LLM优先搜索（LFS），这是一种创新的LLM自我引导搜索方法，旨在通过让LLM自主管理探索过程来克服传统搜索算法的局限性，例如对固定超参数的依赖。LFS利用LLM的内部评分机制来动态决定搜索路径。在Countdown和Sudoku任务上进行的评估显示，LFS在复杂任务上表现优越，计算效率更高，并能更好地与更强大的模型和增加的计算预算协同扩展，证明了其在无需手动调优的情况下进行灵活、上下文敏感推理的潜力。", "keywords": "LLM优先搜索, 自我引导搜索, 大型语言模型, 问题解决, 搜索算法"}}
{"id": "2506.04704", "pdf": "https://arxiv.org/pdf/2506.04704", "abs": "https://arxiv.org/abs/2506.04704", "authors": ["Youngwan Lee", "Kangsan Kim", "Kwanyong Park", "Ilcahe Jung", "Soojin Jang", "Seanie Lee", "Yong-Ju Lee", "Sung Ju Hwang"], "title": "HoliSafe: Holistic Safety Benchmarking and Modeling with Safety Meta Token for Vision-Language Model", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://youngwanlee.github.io/holisafe", "summary": "Despite emerging efforts to enhance the safety of Vision-Language Models\n(VLMs), current approaches face two main shortcomings. 1) Existing\nsafety-tuning datasets and benchmarks only partially consider how image-text\ninteractions can yield harmful content, often overlooking contextually unsafe\noutcomes from seemingly benign pairs. This narrow coverage leaves VLMs\nvulnerable to jailbreak attacks in unseen configurations. 2) Prior methods rely\nprimarily on data-centric tuning, with limited architectural innovations to\nintrinsically strengthen safety. We address these gaps by introducing a\nholistic safety dataset and benchmark, HoliSafe, that spans all five\nsafe/unsafe image-text combinations, providing a more robust basis for both\ntraining and evaluation. We further propose SafeLLaVA, a novel VLM augmented\nwith a learnable safety meta token and a dedicated safety head. The meta token\nencodes harmful visual cues during training, intrinsically guiding the language\nmodel toward safer responses, while the safety head offers interpretable\nharmfulness classification aligned with refusal rationales. Experiments show\nthat SafeLLaVA, trained on HoliSafe, achieves state-of-the-art safety\nperformance across multiple VLM benchmarks. Additionally, the HoliSafe\nbenchmark itself reveals critical vulnerabilities in existing models. We hope\nthat HoliSafe and SafeLLaVA will spur further research into robust and\ninterpretable VLM safety, expanding future avenues for multimodal alignment.", "AI": {"title_translation": "HoliSafe: 视觉语言模型安全元令牌的整体安全基准测试与建模", "tldr": "HoliSafe引入了一个全面的安全基准和数据集，并提出了SafeLLaVA模型，通过安全元令牌和专用安全头显著提升了视觉语言模型的安全性。", "motivation": "现有视觉语言模型（VLM）的安全增强方法存在两个主要缺点：1) 现有安全微调数据集和基准对图像-文本交互产生有害内容的考虑不全面，忽视了看似良性的配对可能导致的上下文不安全结果，这使得VLM容易受到越狱攻击。2) 先前方法主要依赖数据中心微调，缺乏内在强化安全性的架构创新。", "method": "本文提出了HoliSafe，一个涵盖所有五种安全/不安全图像-文本组合的整体安全数据集和基准。此外，还提出了SafeLLaVA，一个新颖的VLM，它通过可学习的安全元令牌和专用的安全头进行增强。安全元令牌在训练期间编码有害视觉线索，内在引导语言模型产生更安全的响应，而安全头提供可解释的有害性分类，与拒绝理由对齐。", "result": "在HoliSafe上训练的SafeLLaVA在多个VLM基准测试中实现了最先进的安全性能。HoliSafe基准本身也揭示了现有模型的关键漏洞。", "conclusion": "HoliSafe和SafeLLaVA将促进对鲁棒和可解释VLM安全性的进一步研究，扩展多模态对齐的未来途径。", "translation": "尽管在增强视觉语言模型（VLM）安全性方面已出现诸多努力，但当前方法面临两个主要缺点。1) 现有安全微调数据集和基准仅部分考虑了图像-文本交互如何产生有害内容，常常忽视了看似良性的配对可能导致的上下文不安全结果。这种狭窄的覆盖范围使得VLM在未见的配置中容易受到越狱攻击。2) 先前方法主要依赖数据中心微调，在内在强化安全性方面的架构创新有限。我们通过引入一个整体安全数据集和基准HoliSafe来解决这些空白，该数据集涵盖了所有五种安全/不安全图像-文本组合，为训练和评估提供了更坚实的基础。我们进一步提出了SafeLLaVA，一个新颖的VLM，它通过一个可学习的安全元令牌和一个专用的安全头进行增强。该元令牌在训练期间编码有害视觉线索，内在引导语言模型产生更安全的响应，而安全头提供与拒绝理由对齐的可解释有害性分类。实验表明，在HoliSafe上训练的SafeLLaVA在多个VLM基准测试中实现了最先进的安全性能。此外，HoliSafe基准本身揭示了现有模型的关键漏洞。我们希望HoliSafe和SafeLLaVA将促进对鲁棒和可解释VLM安全性的进一步研究，扩展多模态对齐的未来途径。", "summary": "本文针对视觉语言模型（VLM）安全增强的不足，提出了HoliSafe数据集和SafeLLaVA模型。HoliSafe是一个全面的安全基准和数据集，覆盖了所有图像-文本安全组合，用于VLM的训练和评估。SafeLLaVA通过引入可学习的安全元令牌和专用安全头，从架构层面增强了VLM的内在安全性。实验证明，SafeLLaVA在HoliSafe上训练后在多个VLM基准测试中达到了最先进的安全性能，并且HoliSafe基准也揭示了现有模型的漏洞。该工作旨在推动VLM安全性的发展。", "keywords": "视觉语言模型安全, HoliSafe, SafeLLaVA, 安全元令牌, 基准测试"}}
{"id": "2506.04461", "pdf": "https://arxiv.org/pdf/2506.04461", "abs": "https://arxiv.org/abs/2506.04461", "authors": ["Ivan Vegner", "Sydelle de Souza", "Valentin Forch", "Martha Lewis", "Leonidas A. A. Doumas"], "title": "Behavioural vs. Representational Systematicity in End-to-End Models: An Opinionated Survey", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.6; I.2.0; I.2.7"], "comment": "To appear at ACL 2025 Main Conference", "summary": "A core aspect of compositionality, systematicity is a desirable property in\nML models as it enables strong generalization to novel contexts. This has led\nto numerous studies proposing benchmarks to assess systematic generalization,\nas well as models and training regimes designed to enhance it. Many of these\nefforts are framed as addressing the challenge posed by Fodor and Pylyshyn.\nHowever, while they argue for systematicity of representations, existing\nbenchmarks and models primarily focus on the systematicity of behaviour. We\nemphasize the crucial nature of this distinction. Furthermore, building on\nHadley's (1994) taxonomy of systematic generalization, we analyze the extent to\nwhich behavioural systematicity is tested by key benchmarks in the literature\nacross language and vision. Finally, we highlight ways of assessing\nsystematicity of representations in ML models as practiced in the field of\nmechanistic interpretability.", "AI": {"title_translation": "行为系统性与表征系统性在端到端模型中的对比：一项观点性综述", "tldr": "本文强调了机器学习模型中行为系统性与表征系统性的关键区别，并综述了现有基准测试对行为系统性的评估，同时探讨了如何评估表征系统性。", "motivation": "机器学习模型中的系统性对于泛化能力至关重要，但现有研究和基准测试主要关注行为系统性，而非福多和皮利欣所强调的表征系统性。本文旨在强调这一关键区别并探讨如何评估表征系统性。", "method": "本文首先强调了行为系统性与表征系统性的区别。接着，基于Hadley (1994) 的系统泛化分类法，分析了现有语言和视觉领域关键基准测试对行为系统性的评估程度。最后，探讨了在机械可解释性领域中评估机器学习模型表征系统性的方法。", "result": "强调了行为系统性与表征系统性之间的重要区别；分析了现有基准测试对行为系统性的评估现状；提出了评估机器学习模型中表征系统性的方法。", "conclusion": "论文强调了区分行为系统性和表征系统性的重要性，并为未来研究如何更全面地评估和实现机器学习模型中的系统性提供了方向，特别是在表征层面。", "translation": "组合性的一个核心方面，系统性是机器学习模型中一个理想的特性，因为它能够实现对新颖上下文的强大泛化。这促使了大量研究提出基准测试来评估系统泛化能力，以及旨在增强系统泛化能力的模型和训练方案。许多这些努力都被框定为解决Fodor和Pylyshyn提出的挑战。然而，尽管他们主张表征的系统性，现有的基准测试和模型主要关注行为的系统性。我们强调这种区别的关键性质。此外，基于Hadley (1994) 的系统泛化分类法，我们分析了文献中跨语言和视觉领域的关键基准测试在多大程度上测试了行为系统性。最后，我们重点介绍了在机械可解释性领域中评估机器学习模型表征系统性的方法。", "summary": "本文是一篇观点性综述，探讨了机器学习模型中系统性这一重要特性。作者指出，尽管福多和皮利欣强调表征系统性，但现有基准测试和模型主要关注行为系统性。文章强调了这一区别的重要性，并基于Hadley的分类法分析了现有基准测试对行为系统性的评估程度。此外，论文还提出了评估机器学习模型中表征系统性的方法，借鉴了机械可解释性领域的技术。", "keywords": "系统性, 行为系统性, 表征系统性, 端到端模型, 泛化能力"}}
{"id": "2506.05282", "pdf": "https://arxiv.org/pdf/2506.05282", "abs": "https://arxiv.org/abs/2506.05282", "authors": ["Tao Sun", "Liyuan Zhu", "Shengyu Huang", "Shuran Song", "Iro Armeni"], "title": "Rectified Point Flow: Generic Point Cloud Pose Estimation", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "Project page: https://rectified-pointflow.github.io/", "summary": "We introduce Rectified Point Flow, a unified parameterization that formulates\npairwise point cloud registration and multi-part shape assembly as a single\nconditional generative problem. Given unposed point clouds, our method learns a\ncontinuous point-wise velocity field that transports noisy points toward their\ntarget positions, from which part poses are recovered. In contrast to prior\nwork that regresses part-wise poses with ad-hoc symmetry handling, our method\nintrinsically learns assembly symmetries without symmetry labels. Together with\na self-supervised encoder focused on overlapping points, our method achieves a\nnew state-of-the-art performance on six benchmarks spanning pairwise\nregistration and shape assembly. Notably, our unified formulation enables\neffective joint training on diverse datasets, facilitating the learning of\nshared geometric priors and consequently boosting accuracy. Project page:\nhttps://rectified-pointflow.github.io/.", "AI": {"title_translation": "修正点流：通用点云姿态估计", "tldr": "Rectified Point Flow (RPF) 是一种统一的生成模型，用于点云配准和形状组装，通过学习点向速度场实现姿态估计，并在多个基准测试中达到最先进性能。", "motivation": "为了提供一个统一的参数化方法来解决点云配准和多部分形状组装问题，并克服以往方法在处理对称性时需要特殊处理的局限性，实现内在学习组装对称性而无需对称性标签。", "method": "本文引入了Rectified Point Flow (修正点流)，这是一种统一的参数化方法，将点云配准和多部分形状组装表述为一个单一的条件生成问题。该方法通过学习一个连续的点向速度场来将噪声点传输到目标位置，从而恢复零件姿态。此外，它结合了一个专注于重叠点的自监督编码器。", "result": "Rectified Point Flow在六个涵盖点云配准和形状组装的基准测试中达到了新的最先进性能。其统一的公式使得在不同数据集上进行有效的联合训练成为可能，这有助于学习共享的几何先验知识并显著提高准确性。", "conclusion": "Rectified Point Flow提供了一种统一且有效的点云姿态估计方法，通过内在学习对称性并支持联合训练，在点云配准和形状组装任务上取得了最先进的性能。", "translation": "我们引入了修正点流（Rectified Point Flow），这是一种统一的参数化方法，将成对点云配准和多部分形状组装表述为一个单一的条件生成问题。给定未摆放姿态的点云，我们的方法学习一个连续的点向速度场，将噪声点传输到它们的目标位置，从而恢复零件姿态。与以往通过特殊对称性处理回归零件姿态的工作不同，我们的方法内在学习组装对称性，而无需对称性标签。结合一个专注于重叠点的自监督编码器，我们的方法在涵盖成对配准和形状组装的六个基准测试中取得了新的最先进性能。值得注意的是，我们统一的公式使得在不同数据集上进行有效的联合训练成为可能，这有助于学习共享的几何先验知识并因此提高准确性。项目页面：https://rectified-pointflow.github.io/。", "summary": "本文介绍了一种名为Rectified Point Flow (RPF) 的统一参数化方法，它将成对点云配准和多部分形状组装统一为一个条件生成问题。RPF通过学习连续的点向速度场来将噪声点传输到目标位置，从而恢复零件姿态。与以往需要特殊对称性处理的方法不同，RPF能够内在学习组装对称性而无需对称性标签。结合一个专注于重叠点的自监督编码器，RPF在六个配准和形状组装基准测试中取得了新的最先进性能。其统一的公式促进了在不同数据集上的有效联合训练，从而学习共享几何先验并提升准确性。", "keywords": "点云, 姿态估计, 配准, 形状组装, 生成模型"}}
{"id": "2506.05256", "pdf": "https://arxiv.org/pdf/2506.05256", "abs": "https://arxiv.org/abs/2506.05256", "authors": ["Violet Xiang", "Chase Blagden", "Rafael Rafailov", "Nathan Lile", "Sang Truong", "Chelsea Finn", "Nick Haber"], "title": "Just Enough Thinking: Efficient Reasoning with Adaptive Length Penalties Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large reasoning models (LRMs) achieve higher performance on challenging\nreasoning tasks by generating more tokens at inference time, but this verbosity\noften wastes computation on easy problems. Existing solutions, including\nsupervised finetuning on shorter traces, user-controlled budgets, or RL with\nuniform penalties, either require data curation, manual configuration, or treat\nall problems alike regardless of difficulty. We introduce Adaptive Length\nPenalty (ALP), a reinforcement learning objective tailoring generation length\nto per-prompt solve rate. During training, ALP monitors each prompt's online\nsolve rate through multiple rollouts and adds a differentiable penalty whose\nmagnitude scales inversely with that rate, so confident (easy) prompts incur a\nhigh cost for extra tokens while hard prompts remain unhindered. Posttraining\nDeepScaleR-1.5B with ALP cuts average token usage by 50\\% without significantly\ndropping performance. Relative to fixed-budget and uniform penalty baselines,\nALP redistributes its reduced budget more intelligently by cutting compute on\neasy prompts and reallocating saved tokens to difficult ones, delivering higher\naccuracy on the hardest problems with higher cost.", "AI": {"title_translation": "恰到好处的思考：基于自适应长度惩罚强化学习的高效推理", "tldr": "本文提出自适应长度惩罚（ALP）强化学习方法，根据问题难度智能调整大型推理模型生成长度，减少50%的token使用量同时保持性能，并更有效地分配计算资源。", "motivation": "大型推理模型（LRMs）在推理任务中表现出色但生成冗余token，导致计算浪费，尤其是在简单问题上。现有解决方案（如监督微调、用户控制预算或统一惩罚的强化学习）存在数据收集、手动配置或对所有问题一视同仁的缺点。", "method": "引入自适应长度惩罚（ALP），这是一种强化学习目标，根据每个提示的在线解决率调整生成长度。在训练期间，ALP通过多次推演监控每个提示的解决率，并添加一个可微分的惩罚，其大小与解决率成反比，使得容易的提示在额外token上产生高成本，而困难的提示则不受影响。", "result": "在DeepScaleR-1.5B模型上应用ALP后，平均token使用量减少了50%，而性能没有显著下降。相对于固定预算和统一惩罚基线，ALP通过在简单提示上削减计算量并为困难提示重新分配节省的token，更智能地重新分配了减少的预算，从而在最困难的问题上以更高的成本实现了更高的准确性。", "conclusion": "ALP是一种有效的强化学习方法，能够使大型推理模型根据问题难度自适应地调整生成长度，显著提高计算效率，同时保持甚至提升在复杂问题上的性能。", "translation": "大型推理模型（LRMs）通过在推理时生成更多token，在具有挑战性的推理任务上取得了更高的性能，但这种冗余往往会在简单问题上浪费计算。现有解决方案，包括对较短轨迹进行监督微调、用户控制预算或使用统一惩罚的强化学习，要么需要数据整理、手动配置，要么不分难度地对待所有问题。我们引入了自适应长度惩罚（ALP），这是一种强化学习目标，旨在根据每个提示的解决率调整生成长度。在训练期间，ALP通过多次推演监控每个提示的在线解决率，并添加一个可微分的惩罚，其大小与该解决率成反比，因此自信（简单）的提示会因额外token而产生高成本，而困难的提示则不受阻碍。在DeepScaleR-1.5B模型上应用ALP训练后，平均token使用量减少了50%，而性能没有显著下降。相对于固定预算和统一惩罚基线，ALP通过在简单提示上削减计算并为困难提示重新分配节省的token，更智能地重新分配了其减少的预算，从而在最困难的问题上以更高的成本提供了更高的准确性。", "summary": "本文提出了一种名为自适应长度惩罚（ALP）的强化学习方法，旨在解决大型推理模型（LRMs）在推理任务中因生成冗余token而导致的计算浪费问题。ALP通过监控每个提示的在线解决率，并施加与解决率成反比的长度惩罚，使得模型能够根据问题难度自适应地调整生成长度。实验结果表明，ALP可以将平均token使用量减少50%而性能不受影响，并且能够更智能地分配计算资源，在保持整体性能的同时，将节省的计算量重新分配给更困难的问题，从而在这些问题上获得更高的准确性。这表明ALP是一种高效且智能的推理模型优化策略。", "keywords": "大型推理模型, 强化学习, 自适应长度惩罚, 计算效率, token使用"}}
{"id": "2506.04706", "pdf": "https://arxiv.org/pdf/2506.04706", "abs": "https://arxiv.org/abs/2506.04706", "authors": ["Achyuta Rajaram", "Sarah Schwettmann", "Jacob Andreas", "Arthur Conmy"], "title": "Line of Sight: On Linear Representations in VLLMs", "categories": ["cs.CV", "cs.AI"], "comment": "8 pages, 9 figures", "summary": "Language models can be equipped with multimodal capabilities by fine-tuning\non embeddings of visual inputs. But how do such multimodal models represent\nimages in their hidden activations? We explore representations of image\nconcepts within LlaVA-Next, a popular open-source VLLM. We find a diverse set\nof ImageNet classes represented via linearly decodable features in the residual\nstream. We show that the features are causal by performing targeted edits on\nthe model output. In order to increase the diversity of the studied linear\nfeatures, we train multimodal Sparse Autoencoders (SAEs), creating a highly\ninterpretable dictionary of text and image features. We find that although\nmodel representations across modalities are quite disjoint, they become\nincreasingly shared in deeper layers.", "AI": {"title_translation": "视线：关于VLLM中的线性表示", "tldr": "研究了VLLM如何表示图像，发现存在线性可解码特征，并且在更深层中模态间表示的共享程度增加。", "motivation": "探索多模态语言模型如何在它们的隐藏激活中表示图像。", "method": "在LlaVA-Next中探索图像概念的表示，通过对模型输出进行有针对性的编辑来证明特征的因果性，并训练多模态稀疏自编码器（SAEs）以增加研究特征的多样性。", "result": "发现残差流中存在通过线性可解码特征表示的多种ImageNet类别，且这些特征是因果的。尽管模型在不同模态之间的表示最初相当分离，但它们在更深层中变得越来越共享。", "conclusion": "多模态表示在更深层中变得越来越共享，这表明模型在深层对不同模态的信息进行了整合。", "translation": "语言模型可以通过对视觉输入的嵌入进行微调来获得多模态能力。但是，这样的多模态模型如何在它们的隐藏激活中表示图像呢？我们探索了流行开源VLLM LlaVA-Next中图像概念的表示。我们发现残差流中存在通过线性可解码特征表示的多种ImageNet类别。我们通过对模型输出进行有针对性的编辑来证明这些特征是因果的。为了增加所研究线性特征的多样性，我们训练了多模态稀疏自编码器（SAEs），创建了一个高度可解释的文本和图像特征字典。我们发现，尽管模型在不同模态之间的表示相当分离，但它们在更深层中变得越来越共享。", "summary": "本研究探讨了多模态大型语言模型（VLLMs）如何在内部表示视觉输入，特别是在LlaVA-Next中。研究发现，ImageNet类别通过残差流中的线性可解码且因果的特征来表示。通过训练多模态稀疏自编码器，研究揭示了尽管模型在不同模态之间的表示最初是分离的，但它们在更深层中变得越来越共享。", "keywords": "线性表示, VLLMs, 多模态模型, LlaVA-Next, 稀疏自编码器"}}
{"id": "2506.04474", "pdf": "https://arxiv.org/pdf/2506.04474", "abs": "https://arxiv.org/abs/2506.04474", "authors": ["Mohammad Subhi Al-Batah", "Mowafaq Salem Alzboon", "Muhyeeddin Alqaraleh", "Mohammed Hasan Abu-Arqoub", "Rashiq Rafiq Marie"], "title": "Classifying Dental Care Providers Through Machine Learning with Features Ranking", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study investigates the application of machine learning (ML) models for\nclassifying dental providers into two categories - standard rendering providers\nand safety net clinic (SNC) providers - using a 2018 dataset of 24,300\ninstances with 20 features. The dataset, characterized by high missing values\n(38.1%), includes service counts (preventive, treatment, exams), delivery\nsystems (FFS, managed care), and beneficiary demographics. Feature ranking\nmethods such as information gain, Gini index, and ANOVA were employed to\nidentify critical predictors, revealing treatment-related metrics\n(TXMT_USER_CNT, TXMT_SVC_CNT) as top-ranked features. Twelve ML models,\nincluding k-Nearest Neighbors (kNN), Decision Trees, Support Vector Machines\n(SVM), Stochastic Gradient Descent (SGD), Random Forest, Neural Networks, and\nGradient Boosting, were evaluated using 10-fold cross-validation.\nClassification accuracy was tested across incremental feature subsets derived\nfrom rankings. The Neural Network achieved the highest accuracy (94.1%) using\nall 20 features, followed by Gradient Boosting (93.2%) and Random Forest\n(93.0%). Models showed improved performance as more features were incorporated,\nwith SGD and ensemble methods demonstrating robustness to missing data. Feature\nranking highlighted the dominance of treatment service counts and annotation\ncodes in distinguishing provider types, while demographic variables (AGE_GROUP,\nCALENDAR_YEAR) had minimal impact. The study underscores the importance of\nfeature selection in enhancing model efficiency and accuracy, particularly in\nimbalanced healthcare datasets. These findings advocate for integrating\nfeature-ranking techniques with advanced ML algorithms to optimize dental\nprovider classification, enabling targeted resource allocation for underserved\npopulations.", "AI": {"title_translation": "机器学习结合特征排序对牙科护理提供者进行分类", "tldr": "本研究使用机器学习和特征排序方法，通过分析2018年牙科数据，成功分类牙科服务提供者（标准提供者和安全网诊所提供者），并强调了特征选择的重要性。", "motivation": "区分标准牙科提供者和安全网诊所（SNC）提供者，以便为服务不足的人群进行有针对性的资源分配。", "method": "使用2018年包含24,300个实例和20个特征的牙科数据集，该数据集具有高缺失值（38.1%）。采用信息增益、Gini指数和ANOVA等特征排序方法识别关键预测因子。评估了包括k-近邻 (kNN)、决策树、支持向量机 (SVM)、随机梯度下降 (SGD)、随机森林、神经网络和梯度提升在内的12种机器学习模型，并使用10折交叉验证，在增量特征子集上测试分类准确性。", "result": "治疗相关指标（TXMT_USER_CNT, TXMT_SVC_CNT）是排名靠前的特征。神经网络在使用全部20个特征时达到最高准确率（94.1%），其次是梯度提升（93.2%）和随机森林（93.0%）。随着特征数量的增加，模型性能有所提高。SGD和集成方法对缺失数据表现出鲁棒性。特征排序强调了治疗服务计数和注释代码在区分提供者类型中的主导地位，而人口统计变量（AGE_GROUP、CALENDAR_YEAR）的影响最小。", "conclusion": "强调了特征选择在提高模型效率和准确性方面的重要性，尤其是在不平衡的医疗保健数据集中。建议将特征排序技术与先进的机器学习算法结合，以优化牙科提供者分类，从而实现对服务不足人群的精准资源分配。", "translation": "本研究调查了机器学习 (ML) 模型在分类牙科提供者方面的应用，将牙科提供者分为两类——标准执业提供者和安全网诊所 (SNC) 提供者。研究使用了2018年的数据集，包含24,300个实例和20个特征。该数据集的特点是缺失值较高 (38.1%)，包括服务计数（预防、治疗、检查）、交付系统（FFS、管理式医疗）和受益人人口统计数据。采用了信息增益、Gini指数和ANOVA等特征排序方法来识别关键预测因子，结果显示治疗相关指标（TXMT_USER_CNT、TXMT_SVC_CNT）是排名靠前的特征。评估了包括k-近邻 (kNN)、决策树、支持向量机 (SVM)、随机梯度下降 (SGD)、随机森林、神经网络和梯度提升在内的12种ML模型，并使用10折交叉验证进行评估。分类准确性在从排名中派生出的增量特征子集上进行测试。神经网络在使用全部20个特征时达到了最高准确率（94.1%），其次是梯度提升（93.2%）和随机森林（93.0%）。随着更多特征的加入，模型性能有所提高，其中SGD和集成方法对缺失数据表现出鲁棒性。特征排序强调了治疗服务计数和注释代码在区分提供者类型中的主导地位，而人口统计变量（AGE_GROUP、CALENDAR_YEAR）的影响最小。本研究强调了特征选择在提高模型效率和准确性方面的重要性，尤其是在不平衡的医疗保健数据集中。这些发现提倡将特征排序技术与先进的ML算法相结合，以优化牙科提供者分类，从而为服务不足的人群实现有针对性的资源分配。", "summary": "本研究利用机器学习模型和特征排序技术，对牙科护理提供者进行分类。通过分析2018年牙科数据集，发现治疗相关特征是区分提供者的关键。神经网络在所有模型中表现最佳，准确率达94.1%。研究强调了特征选择在提升模型性能和解决医疗保健数据不平衡问题中的重要性，并建议将其应用于优化牙科提供者分类，以实现对弱势群体的精准资源分配。", "keywords": "机器学习, 特征排序, 牙科护理提供者分类, 医疗保健数据集, 神经网络"}}
{"id": "2506.05296", "pdf": "https://arxiv.org/pdf/2506.05296", "abs": "https://arxiv.org/abs/2506.05296", "authors": ["Mikhail Terekhov", "Zhen Ning David Liu", "Caglar Gulcehre", "Samuel Albanie"], "title": "Control Tax: The Price of Keeping AI in Check", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The rapid integration of agentic AI into high-stakes real-world applications\nrequires robust oversight mechanisms. The emerging field of AI Control (AIC)\naims to provide such an oversight mechanism, but practical adoption depends\nheavily on implementation overhead. To study this problem better, we introduce\nthe notion of Control tax -- the operational and financial cost of integrating\ncontrol measures into AI pipelines. Our work makes three key contributions to\nthe field of AIC: (1) we introduce a theoretical framework that quantifies the\nControl Tax and maps classifier performance to safety assurances; (2) we\nconduct comprehensive evaluations of state-of-the-art language models in\nadversarial settings, where attacker models insert subtle backdoors into code\nwhile monitoring models attempt to detect these vulnerabilities; and (3) we\nprovide empirical financial cost estimates for control protocols and develop\noptimized monitoring strategies that balance safety and cost-effectiveness\nwhile accounting for practical constraints like auditing budgets. Our framework\nenables practitioners to make informed decisions by systematically connecting\nsafety guarantees with their costs, advancing AIC through principled economic\nfeasibility assessment across different deployment contexts.", "AI": {"title_translation": "控制税：保持人工智能受控的代价", "tldr": "本文引入“控制税”概念，量化AI控制措施的成本，并提供评估框架和优化策略，以平衡AI安全与经济效益。", "motivation": "随着自主AI在关键现实应用中的快速集成，需要强大的监督机制。新兴的AI控制（AIC）领域旨在提供这种机制，但其实际应用严重依赖于实施开销。", "method": "引入了“控制税”的概念，量化了将控制措施集成到AI管道中的操作和财务成本。提出了一个理论框架来量化控制税，并将分类器性能映射到安全保证。在对抗性环境中对最先进的语言模型进行了全面评估，并提供了控制协议的经验财务成本估算，开发了优化监控策略。", "result": "1. 引入了一个量化控制税并将分类器性能映射到安全保证的理论框架。2. 在对抗性环境中对最先进的语言模型进行了全面评估，其中攻击者模型在代码中植入后门，而监控模型试图检测这些漏洞。3. 提供了控制协议的经验财务成本估算，并开发了在考虑审计预算等实际限制的同时平衡安全性和成本效益的优化监控策略。", "conclusion": "本文的框架使从业者能够通过系统地将安全保证与其成本联系起来做出明智的决策，通过在不同部署环境中进行有原则的经济可行性评估来推进AI控制领域。", "translation": "自主AI快速集成到高风险的现实应用中需要强大的监督机制。新兴的AI控制（AIC）领域旨在提供这样的监督机制，但实际采用在很大程度上取决于实施开销。为了更好地研究这个问题，我们引入了控制税的概念——将控制措施集成到AI管道中的运营和财务成本。我们的工作对AIC领域做出了三项关键贡献：(1) 我们引入了一个理论框架，量化了控制税并将分类器性能映射到安全保证；(2) 我们在对抗性环境中对最先进的语言模型进行了全面评估，其中攻击者模型在代码中植入微妙的后门，而监控模型试图检测这些漏洞；(3) 我们提供了控制协议的经验财务成本估算，并开发了在考虑审计预算等实际限制的同时平衡安全性和成本效益的优化监控策略。我们的框架使从业者能够通过系统地将安全保证与其成本联系起来做出明智的决策，通过在不同部署环境中进行有原则的经济可行性评估来推进AIC。", "summary": "本文针对自主AI集成到高风险应用中所需的强大监督机制问题，引入了“控制税”概念来量化AI控制措施的运营和财务成本。研究提出了一个理论框架，用于量化控制税并将分类器性能与安全保证相关联，同时在对抗性环境中评估了先进语言模型。此外，论文提供了控制协议的经验财务成本估算，并开发了平衡安全性和成本效益的优化监控策略，旨在帮助从业者在部署AI时做出成本效益兼顾安全性的决策。", "keywords": "AI控制, 控制税, 安全性, 成本效益, 对抗性评估"}}
{"id": "2506.04713", "pdf": "https://arxiv.org/pdf/2506.04713", "abs": "https://arxiv.org/abs/2506.04713", "authors": ["Hanxin Wang", "Tian Liu", "Shu Kong"], "title": "Robust Few-Shot Vision-Language Model Adaptation", "categories": ["cs.CV"], "comment": "Project website: https://hannawang09.github.io/projects/srapf/", "summary": "Pretrained VLMs achieve strong performance on downstream tasks when adapted\nwith just a few labeled examples. As the adapted models inevitably encounter\nout-of-distribution (OOD) test data that deviates from the in-distribution (ID)\ntask-specific training data, enhancing OOD generalization in few-shot\nadaptation is critically important. We study robust few-shot VLM adaptation,\naiming to increase both ID and OOD accuracy. By comparing different adaptation\nmethods (e.g., prompt tuning, linear probing, contrastive finetuning, and full\nfinetuning), we uncover three key findings: (1) finetuning with proper\nhyperparameters significantly outperforms the popular VLM adaptation methods\nprompt tuning and linear probing; (2) visual encoder-only finetuning achieves\nbetter efficiency and accuracy than contrastively finetuning both visual and\ntextual encoders; (3) finetuning the top layers of the visual encoder provides\nthe best balance between ID and OOD accuracy. Building on these findings, we\npropose partial finetuning of the visual encoder empowered with two simple\naugmentation techniques: (1) retrieval augmentation which retrieves\ntask-relevant data from the VLM's pretraining dataset to enhance adaptation,\nand (2) adversarial perturbation which promotes robustness during finetuning.\nResults show that the former/latter boosts OOD/ID accuracy while slightly\nsacrificing the ID/OOD accuracy. Yet, perhaps understandably, naively combining\nthe two does not maintain their best OOD/ID accuracy. We address this dilemma\nwith the developed SRAPF, Stage-wise Retrieval Augmentation-based Adversarial\nPartial Finetuning. SRAPF consists of two stages: (1) partial finetuning the\nvisual encoder using both ID and retrieved data, and (2) adversarial partial\nfinetuning with few-shot ID data. Extensive experiments demonstrate that SRAPF\nachieves the state-of-the-art ID and OOD accuracy on the ImageNet OOD\nbenchmarks.", "AI": {"title_translation": "鲁棒的少样本视觉-语言模型适应", "tldr": "本文研究了少样本视觉-语言模型（VLM）适应中的鲁棒性问题，提出了SRAPF方法，通过阶段性检索增强和对抗性部分微调，显著提升了模型在分布内和分布外数据的准确性。", "motivation": "预训练的视觉-语言模型（VLMs）在少样本适应后，不可避免地会遇到偏离分布内（ID）任务特定训练数据的分布外（OOD）测试数据，因此，在少样本适应中增强OOD泛化能力至关重要，旨在同时提高分布内（ID）和分布外（OOD）的准确性。", "method": "通过比较不同的适应方法（如提示微调、线性探测、对比微调和完全微调），发现微调策略在ID和OOD准确性之间提供了最佳平衡。在此基础上，提出了视觉编码器的部分微调，并结合了两种增强技术：检索增强（从预训练数据集中检索任务相关数据）和对抗性扰动（在微调过程中促进鲁棒性）。为解决两者简单结合的局限性，开发了SRAPF（Stage-wise Retrieval Augmentation-based Adversarial Partial Finetuning）方法。SRAPF包含两个阶段：第一阶段使用ID和检索到的数据对视觉编码器进行部分微调；第二阶段使用少样本ID数据进行对抗性部分微调。", "result": "研究发现：(1) 在适当的超参数下进行微调显著优于流行的VLM适应方法提示微调和线性探测；(2) 仅视觉编码器微调比对比微调视觉和文本编码器实现了更好的效率和准确性；(3) 微调视觉编码器的顶层在ID和OOD准确性之间提供了最佳平衡。检索增强提升了OOD准确性，对抗性扰动提升了ID准确性。SRAPF在ImageNet OOD基准测试上实现了最先进的ID和OOD准确性。", "conclusion": "SRAPF通过结合阶段性检索增强和对抗性部分微调，有效解决了少样本VLM适应中的鲁棒性问题，显著提升了模型在分布内和分布外数据的泛化能力，达到了最先进的性能。", "translation": "预训练的视觉-语言模型（VLMs）在仅用少量标注样本进行适应后，在下游任务上取得了强大的性能。由于适应后的模型不可避免地会遇到偏离分布内（ID）任务特定训练数据的分布外（OOD）测试数据，因此，在少样本适应中增强OOD泛化能力至关重要。我们研究了鲁棒的少样本VLM适应，旨在提高ID和OOD准确性。通过比较不同的适应方法（例如，提示微调、线性探测、对比微调和完全微调），我们揭示了三个关键发现：（1）在适当的超参数下进行微调显著优于流行的VLM适应方法提示微调和线性探测；（2）仅视觉编码器微调比对比微调视觉和文本编码器实现了更好的效率和准确性；（3）微调视觉编码器的顶层在ID和OOD准确性之间提供了最佳平衡。基于这些发现，我们提出了视觉编码器的部分微调，并结合了两种简单的增强技术：（1）检索增强，从VLM的预训练数据集中检索任务相关数据以增强适应；（2）对抗性扰动，在微调过程中促进鲁棒性。结果表明，前者/后者分别提升了OOD/ID准确性，同时略微牺牲了ID/OOD准确性。然而，或许可以理解的是，简单地结合两者并不能保持其最佳的OOD/ID准确性。我们通过开发的SRAPF（Stage-wise Retrieval Augmentation-based Adversarial Partial Finetuning）解决了这一困境。SRAPF包括两个阶段：（1）使用ID和检索到的数据对视觉编码器进行部分微调；（2）使用少样本ID数据进行对抗性部分微调。广泛的实验证明，SRAPF在ImageNet OOD基准测试上实现了最先进的ID和OOD准确性。", "summary": "本文研究了少样本视觉-语言模型（VLM）适应中的鲁棒性问题，旨在同时提高分布内（ID）和分布外（OOD）准确性。通过比较多种适应方法，发现适当的微调策略，特别是仅微调视觉编码器顶层，能有效平衡ID和OOD性能。在此基础上，提出并验证了两种增强技术：检索增强和对抗性扰动。为解决两者简单结合的局限性，开发了SRAPF（Stage-wise Retrieval Augmentation-based Adversarial Partial Finetuning），该方法分两阶段进行：先用ID和检索数据进行部分微调，再用少样本ID数据进行对抗性部分微调。实验证明SRAPF在ImageNet OOD基准测试上取得了最先进的ID和OOD准确性。", "keywords": "少样本学习, 视觉-语言模型, 模型适应, 分布外泛化, 鲁棒性"}}
{"id": "2506.04479", "pdf": "https://arxiv.org/pdf/2506.04479", "abs": "https://arxiv.org/abs/2506.04479", "authors": ["Mohammad Subhi Al-Batah", "Muhyeeddin Alqaraleh", "Mowafaq Salem Alzboon", "Abdullah Alourani"], "title": "Comparative performance of ensemble models in predicting dental provider types: insights from fee-for-service data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Dental provider classification plays a crucial role in optimizing healthcare\nresource allocation and policy planning. Effective categorization of providers,\nsuch as standard rendering providers and safety net clinic (SNC) providers,\nenhances service delivery to underserved populations. This study aimed to\nevaluate the performance of machine learning models in classifying dental\nproviders using a 2018 dataset. A dataset of 24,300 instances with 20 features\nwas analyzed, including beneficiary and service counts across fee-for-service\n(FFS), Geographic Managed Care, and Pre-Paid Health Plans. Providers were\ncategorized by delivery system and patient age groups (0-20 and 21+). Despite\n38.1% missing data, multiple machine learning algorithms were tested, including\nk-Nearest Neighbors (kNN), Decision Trees, Support Vector Machines (SVM),\nStochastic Gradient Descent (SGD), Random Forest, Neural Networks, and Gradient\nBoosting. A 10-fold cross-validation approach was applied, and models were\nevaluated using AUC, classification accuracy (CA), F1-score, precision, and\nrecall. Neural Networks achieved the highest AUC (0.975) and CA (94.1%),\nfollowed by Random Forest (AUC: 0.948, CA: 93.0%). These models effectively\nhandled imbalanced data and complex feature interactions, outperforming\ntraditional classifiers like Logistic Regression and SVM. Advanced machine\nlearning techniques, particularly ensemble and deep learning models,\nsignificantly enhance dental workforce classification. Their integration into\nhealthcare analytics can improve provider identification and resource\ndistribution, benefiting underserved populations.", "AI": {"title_translation": "集成模型在预测牙科服务提供者类型方面的比较性能：来自按服务收费数据的见解", "tldr": "本研究评估了机器学习模型，特别是集成和深度学习模型，在利用按服务收费数据准确分类牙科服务提供者类型方面的性能，以优化医疗资源分配和政策规划。", "motivation": "牙科服务提供者分类在优化医疗资源分配和政策规划中起着关键作用。有效分类提供者，如标准执业提供者和安全网诊所（SNC）提供者，可以改善对服务不足人群的服务交付。", "method": "本研究使用2018年包含24,300个实例和20个特征的数据集，评估了多种机器学习算法，包括k-近邻（kNN）、决策树、支持向量机（SVM）、随机梯度下降（SGD）、随机森林、神经网络和梯度提升。数据包括按服务收费（FFS）、区域管理式医疗和预付费健康计划的受益人和服务计数。采用10折交叉验证方法，并使用AUC、分类准确率（CA）、F1分数、精确率和召回率评估模型。", "result": "神经网络取得了最高的AUC（0.975）和CA（94.1%），其次是随机森林（AUC：0.948，CA：93.0%）。这些模型有效地处理了不平衡数据和复杂的特征交互，优于逻辑回归和SVM等传统分类器。", "conclusion": "先进的机器学习技术，特别是集成和深度学习模型，显著增强了牙科劳动力分类。将它们整合到医疗分析中可以改善提供者识别和资源分配，从而使服务不足人群受益。", "translation": "牙科服务提供者分类在优化医疗资源分配和政策规划中起着关键作用。有效分类提供者，如标准执业提供者和安全网诊所（SNC）提供者，可以改善对服务不足人群的服务交付。本研究旨在评估机器学习模型在使用2018年数据集分类牙科服务提供者方面的性能。分析了一个包含24,300个实例和20个特征的数据集，包括按服务收费（FFS）、区域管理式医疗和预付费健康计划的受益人和服务计数。提供者按服务交付系统和患者年龄组（0-20岁和21岁以上）进行分类。尽管存在38.1%的缺失数据，但测试了多种机器学习算法，包括k-近邻（kNN）、决策树、支持向量机（SVM）、随机梯度下降（SGD）、随机森林、神经网络和梯度提升。采用10折交叉验证方法，并使用AUC、分类准确率（CA）、F1分数、精确率和召回率评估模型。神经网络取得了最高的AUC（0.975）和CA（94.1%），其次是随机森林（AUC：0.948，CA：93.0%）。这些模型有效地处理了不平衡数据和复杂的特征交互，优于逻辑回归和SVM等传统分类器。先进的机器学习技术，特别是集成和深度学习模型，显著增强了牙科劳动力分类。将它们整合到医疗分析中可以改善提供者识别和资源分配，从而使服务不足人群受益。", "summary": "本研究旨在评估机器学习模型在利用2018年按服务收费数据分类牙科服务提供者类型方面的性能。研究分析了包含24,300个实例和20个特征的数据集，并测试了多种机器学习算法，包括kNN、决策树、SVM、SGD、随机森林、神经网络和梯度提升。结果显示，神经网络和随机森林表现最佳，在处理不平衡数据和复杂特征交互方面表现出色，优于传统分类器。研究强调了集成和深度学习模型在改善牙科劳动力分类和优化医疗资源分配方面的潜力。", "keywords": "牙科服务提供者分类, 机器学习, 集成模型, 神经网络, 随机森林"}}
{"id": "2505.01449", "pdf": "https://arxiv.org/pdf/2505.01449", "abs": "https://arxiv.org/abs/2505.01449", "authors": ["Jiayu Wang", "Aws Albarghouthi", "Frederic Sala"], "title": "COSMOS: Predictable and Cost-Effective Adaptation of LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) achieve remarkable performance across numerous\ntasks by using a diverse array of adaptation strategies. However, optimally\nselecting a model and adaptation strategy under resource constraints is\nchallenging and often requires extensive experimentation. We investigate\nwhether it is possible to accurately predict both performance and cost without\nexpensive trials. We formalize the strategy selection problem for LLMs and\nintroduce COSMOS, a unified prediction framework that efficiently estimates\nadaptation outcomes at minimal cost. We instantiate and study the capability of\nour framework via a pair of powerful predictors: embedding-augmented\nlightweight proxy models to predict fine-tuning performance, and low-sample\nscaling laws to forecast retrieval-augmented in-context learning. Extensive\nevaluation across eight representative benchmarks demonstrates that COSMOS\nachieves high prediction accuracy while reducing computational costs by 92.72%\non average, and up to 98.71% in resource-intensive scenarios. Our results show\nthat efficient prediction of adaptation outcomes is not only feasible but can\nsubstantially reduce the computational overhead of LLM deployment while\nmaintaining performance standards.", "AI": {"title_translation": "COSMOS：大型语言模型可预测且经济高效的适应", "tldr": "COSMOS是一个统一的预测框架，能够高效地预测大型语言模型（LLMs）的适应性能和成本，从而显著降低部署LLM所需的计算开销。", "motivation": "大型语言模型（LLMs）的适应策略选择面临挑战，在资源受限下，选择最优模型和适应策略需要大量实验，导致成本高昂。", "method": "本文提出了COSMOS框架，一个统一的预测框架，用于在最小成本下高效估计LLM的适应结果。它通过两种强大的预测器实现：使用嵌入增强的轻量级代理模型来预测微调性能，以及使用低样本标度律来预测检索增强的上下文学习。", "result": "COSMOS在八个代表性基准测试中实现了高预测精度，平均计算成本降低了92.72%，在资源密集型场景中最高可达98.71%。", "conclusion": "高效预测LLM适应结果是可行的，并且可以在保持性能标准的同时，大幅减少LLM部署的计算开销。", "translation": "大型语言模型（LLMs）通过使用多样化的适应策略在众多任务中取得了卓越的性能。然而，在资源受限下，最佳地选择模型和适应策略具有挑战性，并且通常需要大量的实验。我们研究了是否有可能在不进行昂贵试验的情况下准确预测性能和成本。我们形式化了LLMs的策略选择问题，并引入了COSMOS，一个统一的预测框架，能够以最小的成本高效估计适应结果。我们通过一对强大的预测器实例化并研究了我们框架的能力：用于预测微调性能的嵌入增强轻量级代理模型，以及用于预测检索增强上下文学习的低样本标度律。在八个代表性基准测试中进行的大量评估表明，COSMOS实现了高预测精度，同时平均计算成本降低了92.72%，在资源密集型场景中最高可达98.71%。我们的结果表明，高效预测适应结果不仅可行，而且可以在保持性能标准的同时，大幅减少LLM部署的计算开销。", "summary": "该论文介绍了COSMOS，一个用于大型语言模型（LLMs）的统一预测框架，旨在解决在资源受限下选择最优LLM适应策略的挑战。COSMOS能够高效预测模型的性能和成本，避免了昂贵的实验。通过结合嵌入增强的代理模型和低样本标度律，COSMOS在多个基准测试中展现出高预测精度，并将计算成本平均降低了92.72%，证明了其在降低LLM部署开销方面的有效性。", "keywords": "大型语言模型, 适应策略, 预测框架, 成本效益, 性能预测"}}
{"id": "2506.04715", "pdf": "https://arxiv.org/pdf/2506.04715", "abs": "https://arxiv.org/abs/2506.04715", "authors": ["Zelu Qi", "Ping Shi", "Chaoyang Zhang", "Shuqi Wang", "Fei Zhao", "Da Pan", "Zefeng Ying"], "title": "Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model", "categories": ["cs.CV"], "comment": null, "summary": "The development of AI-Generated Video (AIGV) technology has been remarkable\nin recent years, significantly transforming the paradigm of video content\nproduction. However, AIGVs still suffer from noticeable visual quality defects,\nsuch as noise, blurriness, frame jitter and low dynamic degree, which severely\nimpact the user's viewing experience. Therefore, an effective automatic visual\nquality assessment is of great importance for AIGV content regulation and\ngenerative model improvement. In this work, we decompose the visual quality of\nAIGVs into three dimensions: technical quality, motion quality, and video\nsemantics. For each dimension, we design corresponding encoder to achieve\neffective feature representation. Moreover, considering the outstanding\nperformance of large language models (LLMs) in various vision and language\ntasks, we introduce a LLM as the quality regression module. To better enable\nthe LLM to establish reasoning associations between multi-dimensional features\nand visual quality, we propose a specially designed multi-modal prompt\nengineering framework. Additionally, we incorporate LoRA fine-tuning technology\nduring the training phase, allowing the LLM to better adapt to specific tasks.\nOur proposed method achieved \\textbf{second place} in the NTIRE 2025 Quality\nAssessment of AI-Generated Content Challenge: Track 2 AI Generated video,\ndemonstrating its effectiveness. Codes can be obtained at\nhttps://github.com/QiZelu/AIGVEval.", "AI": {"title_translation": "迈向AI生成视频的整体视觉质量评估：一个基于LLM的多维度评估模型", "tldr": "本文提出了一个基于LLM的多维度评估模型，用于对AI生成视频进行整体视觉质量评估，并在NTIRE 2025挑战赛中获得第二名。", "motivation": "AI生成视频（AIGV）技术发展迅速，但仍存在明显的视觉质量缺陷，如噪声、模糊、帧抖动和低动态度，严重影响用户观看体验。因此，有效的自动视觉质量评估对于AIGV内容监管和生成模型改进至关重要。", "method": "将AIGV的视觉质量分解为技术质量、运动质量和视频语义三个维度，并为每个维度设计了相应的编码器以实现有效的特征表示。引入大型语言模型（LLM）作为质量回归模块，并提出了一个专门设计的多模态提示工程框架，以帮助LLM建立多维度特征与视觉质量之间的推理关联。在训练阶段，结合LoRA微调技术，使LLM更好地适应特定任务。", "result": "所提出的方法在NTIRE 2025 AI生成内容质量评估挑战赛：Track 2 AI生成视频中获得了第二名，证明了其有效性。", "conclusion": "本文提出的基于LLM的多维度评估模型能够有效地评估AI生成视频的视觉质量。", "translation": "近年来，AI生成视频（AIGV）技术发展迅猛，极大地改变了视频内容生产的范式。然而，AIGV仍然存在明显的视觉质量缺陷，例如噪声、模糊、帧抖动和低动态度，这些严重影响了用户的观看体验。因此，有效的自动视觉质量评估对于AIGV内容监管和生成模型改进至关重要。在这项工作中，我们将AIGV的视觉质量分解为三个维度：技术质量、运动质量和视频语义。对于每个维度，我们设计了相应的编码器以实现有效的特征表示。此外，考虑到大型语言模型（LLM）在各种视觉和语言任务中的出色表现，我们引入了一个LLM作为质量回归模块。为了更好地使LLM在多维度特征和视觉质量之间建立推理关联，我们提出了一个专门设计的多模态提示工程框架。此外，我们在训练阶段结合了LoRA微调技术，使LLM更好地适应特定任务。我们提出的方法在NTIRE 2025 AI生成内容质量评估挑战赛：Track 2 AI生成视频中获得了第二名，证明了其有效性。代码可在 https://github.com/QiZelu/AIGVEval 获取。", "summary": "本文针对AI生成视频存在的视觉质量缺陷，提出了一种基于LLM的多维度评估模型。该模型将视觉质量分解为技术质量、运动质量和视频语义三个维度，并设计了相应的编码器进行特征表示。通过引入LLM作为质量回归模块，并结合多模态提示工程和LoRA微调技术，实现了多维度特征与视觉质量的有效关联。该方法在NTIRE 2025挑战赛中取得了第二名的成绩，验证了其有效性。", "keywords": "AI生成视频, 视觉质量评估, LLM, 多维度评估, 提示工程"}}
{"id": "2506.04487", "pdf": "https://arxiv.org/pdf/2506.04487", "abs": "https://arxiv.org/abs/2506.04487", "authors": ["C. Evans Hedges"], "title": "Orthogonal Gradient Descent Improves Neural Calibration", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We provide evidence that orthogonalizing gradients during training improves\nmodel calibration without sacrificing accuracy. On CIFAR-10 with 10% labeled\ndata, $\\perp$Grad matches SGD in accuracy but yields consistently improved\ncalibration metrics such as lower test loss, reduced softmax overconfidence,\nand higher predictive entropy. These benefits persist under input corruption\n(CIFAR-10C) and extended training, where $\\perp$Grad models degrade more\ngracefully than SGD-trained counterparts. $\\perp$Grad is optimizer-agnostic,\nincurs minimal overhead, and works well with post-hoc calibration techniques\nlike temperature scaling.\n  Theoretically, we prove convergence of a simplified version of $\\perp$Grad\nunder mild assumptions and characterize its stationary points in positive\nhomogeneous networks: $\\perp$Grad converges to solutions where further loss\nreduction requires confidence scaling rather than decision boundary\nimprovement.", "AI": {"title_translation": "正交梯度下降改善神经网络校准", "tldr": "正交梯度下降在不牺牲准确性的前提下提高了模型校准，并具有更好的鲁棒性。", "motivation": "提高神经网络模型的校准度，使其预测的置信度能更好地反映其准确性，同时保持或提高模型的预测准确性，并增强模型在面对输入损坏时的鲁棒性。", "method": "提出了一种名为 $\\perp$Grad 的正交梯度下降方法，该方法在训练过程中对梯度进行正交化处理。", "result": "在CIFAR-10数据集上，$\\perp$Grad在准确性上与SGD相当，但在校准指标（如更低的测试损失、更低的softmax过自信度、更高的预测熵）上表现持续改善。在输入损坏（CIFAR-10C）和延长训练下，$\\perp$Grad模型退化更平稳。$\\perp$Grad与优化器无关，开销极小，并且与温度缩放等后验校准技术兼容。理论上，简化版$\\perp$Grad在温和假设下收敛，并且在正齐次网络中，它收敛到这样的解，即进一步的损失降低需要置信度缩放而非决策边界改进。", "conclusion": "正交梯度下降是一种有效且高效的方法，可以在不牺牲准确性的前提下显著改善神经网络的校准性能，并提高模型在不利条件下的鲁棒性。", "translation": "我们提供证据表明，在训练期间对梯度进行正交化处理可以改善模型校准，而不会牺牲准确性。在CIFAR-10数据集上，使用10%的标记数据时，$\\perp$Grad在准确性上与SGD匹配，但能持续改善校准指标，例如更低的测试损失、更低的softmax过自信度以及更高的预测熵。这些优势在输入损坏（CIFAR-10C）和延长训练下依然存在，此时$\\perp$Grad模型的退化比SGD训练的模型更平稳。$\\perp$Grad与优化器无关，开销极小，并且与温度缩放等后验校准技术配合良好。理论上，我们证明了简化版$\\perp$Grad在温和假设下的收敛性，并刻画了其在正齐次网络中的驻点：$\\perp$Grad收敛到这样的解，即进一步的损失降低需要置信度缩放而非决策边界改进。", "summary": "该论文提出了一种名为$\\perp$Grad的正交梯度下降方法，旨在改善神经网络的校准性能，同时不牺牲模型准确性。实验证明，$\\perp$Grad在校准指标上优于传统的SGD，并在输入损坏和长时间训练下表现出更好的鲁棒性。理论分析表明，该方法促使模型收敛到更注重置信度校准而非决策边界优化的状态，并且该方法具有优化器无关性、低开销和良好的兼容性。", "keywords": "正交梯度下降, 神经网络校准, 模型鲁棒性, 置信度, 预测熵"}}
{"id": "2506.03922", "pdf": "https://arxiv.org/pdf/2506.03922", "abs": "https://arxiv.org/abs/2506.03922", "authors": ["Zhaolu Kang", "Junhao Gong", "Jiaxu Yan", "Wanke Xia", "Yian Wang", "Ziwen Wang", "Huaxuan Ding", "Zhuo Cheng", "Wenhao Cao", "Zhiyuan Feng", "Siqi He", "Shannan Yan", "Junzhe Chen", "Xiaomin He", "Chaoya Jiang", "Wei Ye", "Kaidong Yu", "Xuelong Li"], "title": "HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated significant\npotential to advance a broad range of domains. However, current benchmarks for\nevaluating MLLMs primarily emphasize general knowledge and vertical\nstep-by-step reasoning typical of STEM disciplines, while overlooking the\ndistinct needs and potential of the Humanities and Social Sciences (HSS). Tasks\nin the HSS domain require more horizontal, interdisciplinary thinking and a\ndeep integration of knowledge across related fields, which presents unique\nchallenges for MLLMs, particularly in linking abstract concepts with\ncorresponding visual representations. Addressing this gap, we present HSSBench,\na dedicated benchmark designed to assess the capabilities of MLLMs on HSS tasks\nin multiple languages, including the six official languages of the United\nNations. We also introduce a novel data generation pipeline tailored for HSS\nscenarios, in which multiple domain experts and automated agents collaborate to\ngenerate and iteratively refine each sample. HSSBench contains over 13,000\nmeticulously designed samples, covering six key categories. We benchmark more\nthan 20 mainstream MLLMs on HSSBench and demonstrate that it poses significant\nchallenges even for state-of-the-art models. We hope that this benchmark will\ninspire further research into enhancing the cross-disciplinary reasoning\nabilities of MLLMs, especially their capacity to internalize and connect\nknowledge across fields.", "AI": {"title_translation": "HSSBench：多模态大型语言模型人文社会科学能力基准测试", "tldr": "HSSBench是一个专门用于评估多模态大语言模型在人文社会科学领域表现的基准测试，旨在解决现有评估侧重STEM领域、忽视HSS独特需求的问题。", "motivation": "现有用于评估多模态大型语言模型（MLLMs）的基准测试主要侧重于STEM学科的通用知识和垂直逐步推理，而忽视了人文社会科学（HSS）领域独特的跨学科思维和知识深度融合需求，导致MLLMs在连接抽象概念与视觉表示方面面临挑战。", "method": "本文提出了HSSBench，一个专门用于评估MLLMs在多语言HSS任务上能力的基准测试。同时，引入了一种新颖的数据生成管道，该管道通过多领域专家和自动化代理的协作，迭代生成和完善样本。HSSBench包含13,000多个样本，涵盖六个关键类别。", "result": "在HSSBench上对20多个主流MLLMs进行了基准测试，结果表明即使是最先进的模型也面临显著挑战。", "conclusion": "HSSBench有望激发更多研究，以提升MLLMs的跨学科推理能力，特别是其内化和连接不同领域知识的能力。", "translation": "多模态大型语言模型（MLLMs）已展现出在广泛领域中取得进展的巨大潜力。然而，当前评估MLLMs的基准测试主要侧重于STEM学科典型的通用知识和垂直分步推理，而忽视了人文社会科学（HSS）的独特需求和潜力。HSS领域内的任务需要更多的横向、跨学科思维以及相关领域知识的深度融合，这给MLLMs带来了独特的挑战，尤其是在将抽象概念与相应的视觉表示联系起来方面。为了弥补这一空白，我们提出了HSSBench，一个专门用于评估MLLMs在多种语言（包括联合国六种官方语言）的HSS任务上能力的基准测试。我们还引入了一种专为HSS场景量身定制的新型数据生成管道，其中多领域专家和自动化代理协作生成并迭代完善每个样本。HSSBench包含超过13,000个精心设计的样本，涵盖六个关键类别。我们在HSSBench上对20多个主流MLLMs进行了基准测试，结果表明即使是当前最先进的模型也面临显著挑战。我们希望这一基准能激发进一步的研究，以增强MLLMs的跨学科推理能力，特别是它们内化和连接不同领域知识的能力。", "summary": "HSSBench是一个旨在评估多模态大型语言模型（MLLMs）在人文社会科学（HSS）领域能力的专用基准测试，以弥补现有评估侧重STEM学科的不足。该基准包含超过13,000个精心设计的样本，涵盖六个关键类别，并采用了一种新颖的数据生成管道，结合了专家和自动化代理的协作。对20多个主流MLLMs的测试表明，HSSBench对当前最先进的模型也构成了严峻挑战，期望能促进MLLMs在跨学科推理能力方面的进一步研究。", "keywords": "HSSBench, 多模态大型语言模型, 人文社会科学, 基准测试, 跨学科推理"}}
{"id": "2506.04716", "pdf": "https://arxiv.org/pdf/2506.04716", "abs": "https://arxiv.org/abs/2506.04716", "authors": ["Hongyu Wang", "Yonghao Long", "Yueyao Chen", "Hon-Chi Yip", "Markus Scheppach", "Philip Wai-Yan Chiu", "Yeung Yam", "Helen Mei-Ling Meng", "Qi Dou"], "title": "Learning dissection trajectories from expert surgical videos via imitation learning with equivariant diffusion", "categories": ["cs.CV"], "comment": null, "summary": "Endoscopic Submucosal Dissection (ESD) is a well-established technique for\nremoving epithelial lesions. Predicting dissection trajectories in ESD videos\noffers significant potential for enhancing surgical skill training and\nsimplifying the learning process, yet this area remains underexplored. While\nimitation learning has shown promise in acquiring skills from expert\ndemonstrations, challenges persist in handling uncertain future movements,\nlearning geometric symmetries, and generalizing to diverse surgical scenarios.\nTo address these, we introduce a novel approach: Implicit Diffusion Policy with\nEquivariant Representations for Imitation Learning (iDPOE). Our method models\nexpert behavior through a joint state action distribution, capturing the\nstochastic nature of dissection trajectories and enabling robust visual\nrepresentation learning across various endoscopic views. By incorporating a\ndiffusion model into policy learning, iDPOE ensures efficient training and\nsampling, leading to more accurate predictions and better generalization.\nAdditionally, we enhance the model's ability to generalize to geometric\nsymmetries by embedding equivariance into the learning process. To address\nstate mismatches, we develop a forward-process guided action inference strategy\nfor conditional sampling. Using an ESD video dataset of nearly 2000 clips,\nexperimental results show that our approach surpasses state-of-the-art methods,\nboth explicit and implicit, in trajectory prediction. To the best of our\nknowledge, this is the first application of imitation learning to surgical\nskill development for dissection trajectory prediction.", "AI": {"title_translation": "通过模仿学习和等变扩散从专家手术视频中学习解剖轨迹", "tldr": "本研究提出iDPOE，一种结合模仿学习和等变扩散的新方法，用于从专家内窥镜黏膜下剥离术（ESD）视频中预测解剖轨迹，在轨迹预测方面超越了现有SOTA方法，并首次将模仿学习应用于手术技能的解剖轨迹预测。", "motivation": "内窥镜黏膜下剥离术（ESD）中解剖轨迹的预测对提升手术技能训练和简化学习过程具有巨大潜力，但该领域研究不足。模仿学习在从专家演示中获取技能方面有前景，但在处理不确定未来运动、学习几何对称性和泛化到多样化手术场景方面仍存在挑战。", "method": "本研究引入了一种新方法：基于等变表示的隐式扩散策略模仿学习（iDPOE）。该方法通过联合状态-动作分布对专家行为进行建模，捕获解剖轨迹的随机性，并实现跨各种内窥镜视角的鲁棒视觉表示学习。通过将扩散模型纳入策略学习，iDPOE确保了高效训练和采样，从而实现更准确的预测和更好的泛化。此外，通过将等变性嵌入学习过程，增强了模型泛化到几何对称性的能力。为了解决状态不匹配问题，开发了一种前向过程引导的动作推理策略用于条件采样。", "result": "使用一个包含近2000个片段的ESD视频数据集，实验结果表明，该方法在轨迹预测方面超越了现有最先进的显式和隐式方法。", "conclusion": "据作者所知，这是模仿学习首次应用于手术技能发展中的解剖轨迹预测。", "translation": "内窥镜黏膜下剥离术（ESD）是一种成熟的上皮病变切除技术。预测ESD视频中的解剖轨迹在增强手术技能培训和简化学习过程方面具有巨大潜力，但该领域仍未得到充分探索。尽管模仿学习在从专家演示中获取技能方面已显示出前景，但在处理不确定的未来运动、学习几何对称性以及泛化到多样化手术场景方面仍然存在挑战。为了解决这些问题，我们引入了一种新颖的方法：基于等变表示的隐式扩散策略模仿学习（iDPOE）。我们的方法通过联合状态-动作分布对专家行为进行建模，捕获解剖轨迹的随机性，并实现跨各种内窥镜视角的鲁棒视觉表示学习。通过将扩散模型纳入策略学习，iDPOE确保了高效的训练和采样，从而实现更准确的预测和更好的泛化。此外，我们通过将等变性嵌入学习过程来增强模型泛化到几何对称性的能力。为了解决状态不匹配问题，我们开发了一种前向过程引导的动作推理策略用于条件采样。使用一个包含近2000个片段的ESD视频数据集，实验结果表明，我们的方法在轨迹预测方面超越了现有最先进的显式和隐式方法。据我们所知，这是模仿学习首次应用于手术技能发展中的解剖轨迹预测。", "summary": "本论文提出了一种名为iDPOE的新型模仿学习方法，该方法利用等变扩散模型从专家内窥镜黏膜下剥离术（ESD）视频中学习并预测解剖轨迹。iDPOE通过建模联合状态-动作分布来捕捉轨迹的随机性，并结合等变性以增强对几何对称性的泛化能力。实验结果表明，该方法在轨迹预测方面优于现有最先进的技术，并且是首次将模仿学习应用于手术解剖轨迹预测。", "keywords": "模仿学习, 等变扩散, 解剖轨迹预测, 内窥镜黏膜下剥离术, 手术技能学习"}}
{"id": "2506.04490", "pdf": "https://arxiv.org/pdf/2506.04490", "abs": "https://arxiv.org/abs/2506.04490", "authors": ["Rishwanth Raghu", "Axel Levy", "Gordon Wetzstein", "Ellen D. Zhong"], "title": "Multiscale guidance of AlphaFold3 with heterogeneous cryo-EM data", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Protein structure prediction models are now capable of generating accurate 3D\nstructural hypotheses from sequence alone. However, they routinely fail to\ncapture the conformational diversity of dynamic biomolecular complexes, often\nrequiring heuristic MSA subsampling approaches for generating alternative\nstates. In parallel, cryo-electron microscopy (cryo-EM) has emerged as a\npowerful tool for imaging near-native structural heterogeneity, but is\nchallenged by arduous pipelines to go from raw experimental data to atomic\nmodels. Here, we bridge the gap between these modalities, combining cryo-EM\ndensity maps with the rich sequence and biophysical priors learned by protein\nstructure prediction models. Our method, CryoBoltz, guides the sampling\ntrajectory of a pretrained protein structure prediction model using both global\nand local structural constraints derived from density maps, driving predictions\ntowards conformational states consistent with the experimental data. We\ndemonstrate that this flexible yet powerful inference-time approach allows us\nto build atomic models into heterogeneous cryo-EM maps across a variety of\ndynamic biomolecular systems including transporters and antibodies.", "AI": {"title_translation": "多尺度指导AlphaFold3与异质冷冻电镜数据", "tldr": "CryoBoltz结合冷冻电镜数据指导AlphaFold3，用于预测动态生物分子复合物结构。", "motivation": "现有的蛋白质结构预测模型难以捕捉动态生物分子复合物的构象多样性，且冷冻电镜数据到原子模型的转换过程繁琐。", "method": "提出CryoBoltz方法，将冷冻电镜密度图与预训练蛋白质结构预测模型（如AlphaFold3）学习到的序列和生物物理先验知识相结合，通过全局和局部结构约束引导采样轨迹，使预测结果与实验数据一致。", "result": "该方法能够将原子模型构建到各种动态生物分子系统（包括转运蛋白和抗体）的异质冷冻电镜图中。", "conclusion": "CryoBoltz通过结合冷冻电镜数据，有效提高了蛋白质结构预测模型在处理动态生物分子复合物构象多样性方面的能力。", "translation": "蛋白质结构预测模型现在能够仅从序列生成准确的3D结构假设。然而，它们通常无法捕获动态生物分子复合物的构象多样性，常常需要启发式MSA子采样方法来生成替代状态。与此同时，冷冻电子显微镜（cryo-EM）已成为一种强大的成像近天然结构异质性的工具，但从原始实验数据到原子模型的繁琐流程对其构成了挑战。在这里，我们弥合了这些模式之间的差距，将冷冻电镜密度图与蛋白质结构预测模型学习到的丰富序列和生物物理先验知识相结合。我们的方法CryoBoltz利用密度图导出的全局和局部结构约束，引导预训练蛋白质结构预测模型的采样轨迹，从而使预测结果与实验数据一致的构象状态。我们证明了这种灵活而强大的推断时方法使我们能够将原子模型构建到各种动态生物分子系统（包括转运蛋白和抗体）的异质冷冻电镜图中。", "summary": "本文提出CryoBoltz方法，通过将冷冻电镜密度图与预训练蛋白质结构预测模型相结合，克服了传统模型在捕捉动态生物分子复合物构象多样性上的不足。CryoBoltz利用密度图提供的全局和局部结构约束，引导模型生成与实验数据一致的构象，成功地将原子模型构建到异质冷冻电镜图中，适用于多种动态生物分子系统。", "keywords": "冷冻电镜, 蛋白质结构预测, AlphaFold3, 构象多样性, CryoBoltz"}}
{"id": "2506.04717", "pdf": "https://arxiv.org/pdf/2506.04717", "abs": "https://arxiv.org/abs/2506.04717", "authors": ["Babar Hussain", "Qiang Liu", "Gang Chen", "Bihai She", "Dahai Yu"], "title": "Using In-Context Learning for Automatic Defect Labelling of Display Manufacturing Data", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper presents an AI-assisted auto-labeling system for display panel\ndefect detection that leverages in-context learning capabilities. We adopt and\nenhance the SegGPT architecture with several domain-specific training\ntechniques and introduce a scribble-based annotation mechanism to streamline\nthe labeling process. Our two-stage training approach, validated on industrial\ndisplay panel datasets, demonstrates significant improvements over the baseline\nmodel, achieving an average IoU increase of 0.22 and a 14% improvement in\nrecall across multiple product types, while maintaining approximately 60%\nauto-labeling coverage. Experimental results show that models trained on our\nauto-labeled data match the performance of those trained on human-labeled data,\noffering a practical solution for reducing manual annotation efforts in\nindustrial inspection systems.", "AI": {"title_translation": "利用情境学习对显示器制造数据进行缺陷自动标注", "tldr": "本文提出了一种基于情境学习的AI辅助自动标注系统，用于显示面板缺陷检测，显著提高了标注效率和模型性能，且自动标注数据训练的模型表现与人工标注数据训练的模型相当。", "motivation": "减少工业检测系统中人工标注的精力投入，解决显示面板缺陷检测中数据标注效率低的问题。", "method": "采用并增强了SegGPT架构，结合领域特定训练技术和基于涂鸦的标注机制，提出了两阶段训练方法，以实现显示面板缺陷的自动标注。", "result": "在工业显示面板数据集上，相比基线模型，平均IoU提高了0.22，多个产品类型的召回率提高了14%，同时保持了约60%的自动标注覆盖率。实验结果表明，用自动标注数据训练的模型性能与用人工标注数据训练的模型相当。", "conclusion": "所提出的AI辅助自动标注系统为工业检测系统减少人工标注工作提供了一个实用的解决方案，且自动标注数据的模型表现与人工标注数据训练的模型相当。", "translation": "本文提出了一种利用情境学习能力的AI辅助显示面板缺陷检测自动标注系统。我们采用并增强了SegGPT架构，结合了几种领域特定的训练技术，并引入了基于涂鸦的标注机制来简化标注过程。我们的两阶段训练方法在工业显示面板数据集上得到了验证，与基线模型相比，显示出显著的改进，在多个产品类型上平均IoU增加了0.22，召回率提高了14%，同时保持了大约60%的自动标注覆盖率。实验结果表明，使用我们自动标注数据训练的模型性能与使用人工标注数据训练的模型相当，为工业检测系统减少人工标注工作提供了一个实用的解决方案。", "summary": "本文介绍了一种利用情境学习的AI辅助自动标注系统，用于显示面板缺陷检测。该系统通过改进SegGPT架构、引入领域特定训练技术和基于涂鸦的标注机制，实现了高效的自动标注。实验证明，该系统在IoU和召回率上均有显著提升，并且使用自动标注数据训练的模型性能可与人工标注数据训练的模型媲美，有效降低了工业检测中的人工标注成本。", "keywords": "情境学习, 缺陷标注, 显示面板, 自动标注, SegGPT"}}
{"id": "2506.04737", "pdf": "https://arxiv.org/pdf/2506.04737", "abs": "https://arxiv.org/abs/2506.04737", "authors": ["Mikhail Kennerley", "Angelica Alives-Reviro", "Carola-Bibiane Schönlieb", "Robby T. Tan"], "title": "Bridging Annotation Gaps: Transferring Labels to Align Object Detection Datasets", "categories": ["cs.CV"], "comment": null, "summary": "Combining multiple object detection datasets offers a path to improved\ngeneralisation but is hindered by inconsistencies in class semantics and\nbounding box annotations. Some methods to address this assume shared label\ntaxonomies and address only spatial inconsistencies; others require manual\nrelabelling, or produce a unified label space, which may be unsuitable when a\nfixed target label space is required. We propose Label-Aligned Transfer (LAT),\na label transfer framework that systematically projects annotations from\ndiverse source datasets into the label space of a target dataset. LAT begins by\ntraining dataset-specific detectors to generate pseudo-labels, which are then\ncombined with ground-truth annotations via a Privileged Proposal Generator\n(PPG) that replaces the region proposal network in two-stage detectors. To\nfurther refine region features, a Semantic Feature Fusion (SFF) module injects\nclass-aware context and features from overlapping proposals using a\nconfidence-weighted attention mechanism. This pipeline preserves\ndataset-specific annotation granularity while enabling many-to-one label space\ntransfer across heterogeneous datasets, resulting in a semantically and\nspatially aligned representation suitable for training a downstream detector.\nLAT thus jointly addresses both class-level misalignments and bounding box\ninconsistencies without relying on shared label spaces or manual annotations.\nAcross multiple benchmarks, LAT demonstrates consistent improvements in\ntarget-domain detection performance, achieving gains of up to +4.8AP over\nsemi-supervised baselines.", "AI": {"title_translation": "弥合标注鸿沟：迁移标签以对齐目标检测数据集", "tldr": "提出Label-Aligned Transfer (LAT) 框架，通过伪标签和特权提议生成器，将不同源数据集的标注对齐到目标数据集，解决了类别和边界框不一致问题。", "motivation": "结合多个目标检测数据集能提高泛化能力，但受限于类语义和边界框标注的不一致性。现有方法要么假设共享标签分类法，要么需要手动重新标注，或产生不适合固定目标标签空间的统一标签空间。", "method": "提出Label-Aligned Transfer (LAT) 框架。首先训练特定数据集的检测器生成伪标签，然后通过特权提议生成器 (PPG) 将伪标签与真实标注结合，PPG取代了两阶段检测器中的区域提议网络。此外，语义特征融合 (SFF) 模块通过置信度加权注意力机制注入类别感知上下文和重叠提议的特征，以进一步细化区域特征。该管道保留了数据集特定的标注粒度，并实现了异构数据集间多对一标签空间迁移。", "result": "在多个基准测试中，LAT持续提高了目标域检测性能，比半监督基线提升高达+4.8AP。", "conclusion": "LAT联合解决了类别级别错位和边界框不一致问题，且不依赖共享标签空间或手动标注，有效实现了异构数据集的标签对齐和性能提升。", "translation": "结合多个目标检测数据集为提升泛化能力提供了途径，但受到类语义和边界框标注不一致的阻碍。一些解决此问题的方法假设共享标签分类法并仅解决空间不一致性；另一些则需要手动重新标注，或产生统一的标签空间，这在需要固定目标标签空间时可能不适用。我们提出了标签对齐迁移 (LAT)，这是一个标签迁移框架，它系统地将来自不同源数据集的标注投影到目标数据集的标签空间中。LAT首先训练特定数据集的检测器以生成伪标签，然后通过特权提议生成器 (PPG) 将伪标签与真实标注结合，PPG取代了两阶段检测器中的区域提议网络。为了进一步细化区域特征，语义特征融合 (SFF) 模块通过置信度加权注意力机制注入类别感知上下文和来自重叠提议的特征。该管道保留了数据集特定的标注粒度，同时实现了异构数据集间多对一标签空间迁移，从而产生适合训练下游检测器的语义和空间对齐的表示。因此，LAT联合解决了类别级别错位和边界框不一致问题，且不依赖共享标签空间或手动标注。在多个基准测试中，LAT在目标域检测性能方面表现出持续改进，比半监督基线提升高达+4.8AP。", "summary": "该论文提出了一种名为Label-Aligned Transfer (LAT) 的标签迁移框架，旨在解决结合多个目标检测数据集时面临的类别语义和边界框标注不一致问题。LAT通过训练数据集特定检测器生成伪标签，并利用特权提议生成器 (PPG) 和语义特征融合 (SFF) 模块，将来自不同源数据集的标注系统地投影到目标数据集的标签空间中。该方法无需共享标签空间或手动标注，便能实现异构数据集间的标签对齐，从而生成语义和空间上对齐的表示，适用于训练下游检测器。实验结果表明，LAT在多个基准测试中显著提高了目标域检测性能，超越了半监督基线。", "keywords": "目标检测, 标签迁移, 数据集对齐, 伪标签, 标注鸿沟"}}
{"id": "2506.04528", "pdf": "https://arxiv.org/pdf/2506.04528", "abs": "https://arxiv.org/abs/2506.04528", "authors": ["Ruoxi Jiang", "Xiao Zhang", "Karan Jakhar", "Peter Y. Lu", "Pedram Hassanzadeh", "Michael Maire", "Rebecca Willett"], "title": "Hierarchical Implicit Neural Emulators", "categories": ["cs.LG"], "comment": null, "summary": "Neural PDE solvers offer a powerful tool for modeling complex dynamical\nsystems, but often struggle with error accumulation over long time horizons and\nmaintaining stability and physical consistency. We introduce a multiscale\nimplicit neural emulator that enhances long-term prediction accuracy by\nconditioning on a hierarchy of lower-dimensional future state representations.\nDrawing inspiration from the stability properties of numerical implicit\ntime-stepping methods, our approach leverages predictions several steps ahead\nin time at increasing compression rates for next-timestep refinements. By\nactively adjusting the temporal downsampling ratios, our design enables the\nmodel to capture dynamics across multiple granularities and enforce long-range\ntemporal coherence. Experiments on turbulent fluid dynamics show that our\nmethod achieves high short-term accuracy and produces long-term stable\nforecasts, significantly outperforming autoregressive baselines while adding\nminimal computational overhead.", "AI": {"title_translation": "分层隐式神经模拟器", "tldr": "提出一种多尺度隐式神经模拟器，通过分层未来状态表示和多步预测，提高神经PDE求解器在复杂动力系统中的长期预测精度和稳定性，且计算开销小。", "motivation": "现有的神经PDE求解器在长期预测中存在误差累积、稳定性和物理一致性问题。", "method": "引入一种多尺度隐式神经模拟器，通过条件化分层低维未来状态表示来提高长期预测精度。该方法借鉴了数值隐式时间步进方法的稳定性，利用多步超前预测和递增压缩率进行下一步时间步的细化。通过调整时间下采样率，捕获多粒度动态并强制执行长程时间连贯性。", "result": "在湍流流体动力学实验中，该方法实现了高短期精度，产生了长期稳定的预测，显著优于自回归基线，同时增加了最小的计算开销。", "conclusion": "该多尺度隐式神经模拟器有效解决了神经PDE求解器在长期预测中的误差累积和稳定性问题，提高了复杂动力系统的预测能力。", "translation": "神经网络偏微分方程（PDE）求解器为复杂动力系统建模提供了强大的工具，但通常在长时间范围内面临误差累积，以及难以保持稳定性和物理一致性。我们引入了一种多尺度隐式神经模拟器，通过条件化处理分层的低维未来状态表示，从而提高了长期预测精度。借鉴数值隐式时间步进方法的稳定性特性，我们的方法利用提前数步的预测，以递增的压缩率对下一时间步进行细化。通过主动调整时间下采样率，我们的设计使模型能够捕捉多粒度动态并强制执行长程时间连贯性。在湍流流体动力学上的实验表明，我们的方法实现了高短期精度并产生了长期稳定的预测，显著优于自回归基线，同时只增加了最小的计算开销。", "summary": "本文提出一种分层隐式神经模拟器，旨在克服神经偏微分方程求解器在建模复杂动力系统时面临的长期误差累积、稳定性和物理一致性挑战。该模型通过利用分层低维未来状态表示进行条件化，并借鉴数值隐式时间步进方法的稳定性，通过多步超前预测和动态调整时间下采样率来捕捉多粒度动态并增强时间连贯性。实验证明，该方法在短期内保持高精度，并能产生长期稳定的预测，性能显著优于传统自回归方法，且计算开销极低。", "keywords": "隐式神经模拟器, 多尺度预测, 长期稳定性, 偏微分方程求解器, 湍流流体动力学"}}
{"id": "2506.04295", "pdf": "https://arxiv.org/pdf/2506.04295", "abs": "https://arxiv.org/abs/2506.04295", "authors": ["Khashayar Irani"], "title": "Logical Inferentialism & Attacks on Classical Logic", "categories": ["cs.LO"], "comment": "Draft", "summary": "This paper undertakes a foundational inquiry into logical inferentialism with\nparticular emphasis on the normative standards it establishes and the\nimplications these pose for classical logic. The central question addressed\nherein is: 'What is Logical Inferentialism & How do its Standards challenge\nClassical Logic?' In response, the study begins with a survey of the three\nprincipal proof systems that is, David Hilbert's axiomatic systems and Gerhard\nGentzen's natural deduction and his sequent calculus, thus situating logical\ninferentialism within a broader proof-theoretic landscape. The investigation\nthen turns to the core tenets of logical inferentialism by focusing on the role\nof introduction and elimination rules in determining the meaning of logical\nconstants. Through this framework, natural deduction is evaluated as a system\nthat satisfies key inferentialist virtues including harmony, conservativeness\nand the subformula property. Ultimately, the paper presents challenges to\nclassical logic from intuitionist and revisionist perspectives by arguing that\ncertain classical principles fail to uphold inferentialist standards,\nconsequently undermining their legitimacy within a meaning-theoretic framework.", "AI": {"title_translation": "逻辑推论主义与对经典逻辑的攻击", "tldr": "本文探讨了逻辑推论主义的规范标准如何挑战经典逻辑，通过分析证明系统，并论证经典逻辑的某些原则未能符合推论主义标准。", "motivation": "本文旨在对逻辑推论主义进行基础性探究，特别关注其建立的规范标准及其对经典逻辑的影响，并回答“什么是逻辑推论主义及其标准如何挑战经典逻辑？”这一核心问题。", "method": "研究首先回顾了三种主要的证明系统，包括希尔伯特公理系统、根岑的自然演绎和相继式演算，将逻辑推论主义置于更广泛的证明论背景中。随后，通过关注引入和消除规则在确定逻辑常数意义中的作用，深入探讨了逻辑推论主义的核心原则。", "result": "通过此框架，自然演绎被评估为一个满足和谐性、保守性和子公式性质等关键推论主义美德的系统。论文最终从直觉主义和修正主义的角度对经典逻辑提出了挑战。", "conclusion": "某些经典逻辑原则未能遵守推论主义标准，从而在意义理论框架内削弱了其合法性。", "translation": "本文对逻辑推论主义进行了基础性探究，特别强调了其建立的规范标准以及这些标准对经典逻辑的影响。本文探讨的核心问题是：“什么是逻辑推论主义？它的标准如何挑战经典逻辑？” 为此，本研究首先回顾了三种主要的证明系统，即大卫·希尔伯特的公理系统、格哈德·根岑的自然演绎和他的相继式演算，从而将逻辑推论主义置于更广泛的证明论背景中。然后，通过关注引入和消除规则在确定逻辑常数意义中的作用，深入探讨了逻辑推论主义的核心原则。在此框架下，自然演绎被评估为一个满足和谐性、保守性和子公式性质等关键推论主义美德的系统。最终，本文从直觉主义和修正主义的角度对经典逻辑提出了挑战，认为某些经典原则未能遵守推论主义标准，从而在意义理论框架内削弱了其合法性。", "summary": "本文对逻辑推论主义进行了基础性探究，重点关注其规范标准及其对经典逻辑的影响。通过考察主要证明系统和推论主义的核心原则，论文评估了自然演绎系统作为满足推论主义美德的范例。最终，文章从直觉主义和修正主义视角挑战经典逻辑，认为其某些原则未能符合推论主义标准，从而质疑其合法性。", "keywords": "逻辑推论主义, 经典逻辑, 证明论, 自然演绎, 意义理论框架"}}
{"id": "2506.04743", "pdf": "https://arxiv.org/pdf/2506.04743", "abs": "https://arxiv.org/abs/2506.04743", "authors": ["Shuhan Xu", "Siyuan Liang", "Hongling Zheng", "Yong Luo", "Aishan Liu", "Dacheng Tao"], "title": "SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in VLMs", "categories": ["cs.CV"], "comment": null, "summary": "Vision-Language Models (VLMs) have achieved remarkable performance in image\ncaptioning, but recent studies show they are vulnerable to backdoor attacks.\nAttackers can inject imperceptible perturbations-such as local pixel triggers\nor global semantic phrases-into the training data, causing the model to\ngenerate malicious, attacker-controlled captions for specific inputs. These\nattacks are hard to detect and defend due to their stealthiness and cross-modal\nnature. By analyzing attack samples, we identify two key vulnerabilities: (1)\nabnormal attention concentration on specific image regions, and (2) semantic\ndrift and incoherence in generated captions. To counter this, we propose\nSemantic Reward Defense (SRD), a reinforcement learning framework that\nmitigates backdoor behavior without prior knowledge of triggers. SRD uses a\nDeep Q-Network to learn policies for applying discrete perturbations (e.g.,\nocclusion, color masking) to sensitive image regions, aiming to disrupt the\nactivation of malicious pathways. We design a semantic fidelity score as the\nreward signal, which jointly evaluates semantic consistency and linguistic\nfluency of the output, guiding the agent toward generating robust yet faithful\ncaptions. Experiments across mainstream VLMs and datasets show SRD reduces\nattack success rates to 5.6%, while preserving caption quality on clean inputs\nwith less than 10% performance drop. SRD offers a trigger-agnostic,\ninterpretable defense paradigm against stealthy backdoor threats in multimodal\ngenerative models.", "AI": {"title_translation": "SRD：强化学习语义扰动用于VLM中的后门防御", "tldr": "SRD是一种基于强化学习的语义扰动防御框架，通过对敏感图像区域应用离散扰动来对抗VLM中的后门攻击，同时保持字幕质量。", "motivation": "视觉-语言模型（VLMs）容易受到后门攻击，攻击者可以将难以察觉的扰动注入训练数据中，导致模型为特定输入生成恶意字幕。这些攻击由于其隐蔽性和跨模态性质而难以检测和防御。", "method": "本文提出了语义奖励防御（SRD），一个强化学习框架，它使用深度Q网络学习策略，对敏感图像区域应用离散扰动（例如，遮挡、颜色掩码），旨在破坏恶意路径的激活。SRD设计了一个语义保真度分数作为奖励信号，该分数共同评估输出的语义一致性和语言流畅性，以引导代理生成鲁棒且忠实的字幕。", "result": "实验表明，SRD将主流VLM和数据集上的攻击成功率降低到5.6%，同时在干净输入上保持了字幕质量，性能下降不到10%。", "conclusion": "SRD提供了一种与触发器无关、可解释的防御范式，用于对抗多模态生成模型中隐蔽的后门威胁。", "translation": "视觉-语言模型（VLMs）在图像字幕生成方面取得了显著性能，但最近的研究表明它们容易受到后门攻击。攻击者可以将难以察觉的扰动——例如局部像素触发器或全局语义短语——注入训练数据中，导致模型为特定输入生成恶意的、攻击者控制的字幕。这些攻击由于其隐蔽性和跨模态性质而难以检测和防御。通过分析攻击样本，我们识别出两个关键漏洞：(1) 对特定图像区域的异常注意力集中，以及 (2) 生成字幕中的语义漂移和不连贯性。为了对抗这一点，我们提出了语义奖励防御（SRD），一个强化学习框架，它在没有触发器先验知识的情况下减轻后门行为。SRD使用深度Q网络学习对敏感图像区域应用离散扰动（例如，遮挡、颜色掩码）的策略，旨在破坏恶意路径的激活。我们设计了一个语义保真度分数作为奖励信号，该分数共同评估输出的语义一致性和语言流畅性，引导代理生成鲁棒而忠实的字幕。在主流VLM和数据集上的实验表明，SRD将攻击成功率降低到5.6%，同时在干净输入上保持了字幕质量，性能下降不到10%。SRD提供了一种与触发器无关、可解释的防御范式，用于对抗多模态生成模型中隐蔽的后门威胁。", "summary": "本文提出了一种名为SRD（语义奖励防御）的强化学习框架，旨在防御视觉-语言模型（VLMs）中的后门攻击。通过分析攻击样本，研究人员发现VLM存在异常注意力集中和语义漂移的问题。SRD利用深度Q网络学习对图像敏感区域应用离散扰动（如遮挡、颜色掩码）的策略，以干扰恶意行为。该框架采用语义保真度分数作为奖励信号，确保生成的字幕既鲁棒又忠实。实验证明，SRD能显著降低攻击成功率至5.6%，同时对干净输入的字幕质量影响小于10%，提供了一种无需先验知识的、可解释的后门防御方法。", "keywords": "后门防御, 视觉-语言模型, 强化学习, 语义扰动, 注意力机制"}}
{"id": "2506.04531", "pdf": "https://arxiv.org/pdf/2506.04531", "abs": "https://arxiv.org/abs/2506.04531", "authors": ["Geon-Woo Kim", "Junbo Li", "Shashidhar Gandham", "Omar Baldonado", "Adithya Gangidi", "Pavan Balaji", "Zhangyang Wang", "Aditya Akella"], "title": "HALoS: Hierarchical Asynchronous Local SGD over Slow Networks for Geo-Distributed Large Language Model Training", "categories": ["cs.LG"], "comment": null, "summary": "Training large language models (LLMs) increasingly relies on geographically\ndistributed accelerators, causing prohibitive communication costs across\nregions and uneven utilization of heterogeneous hardware. We propose HALoS, a\nhierarchical asynchronous optimization framework that tackles these issues by\nintroducing local parameter servers (LPSs) within each region and a global\nparameter server (GPS) that merges updates across regions. This hierarchical\ndesign minimizes expensive inter-region communication, reduces straggler\neffects, and leverages fast intra-region links. We provide a rigorous\nconvergence analysis for HALoS under non-convex objectives, including\ntheoretical guarantees on the role of hierarchical momentum in asynchronous\ntraining. Empirically, HALoS attains up to 7.5x faster convergence than\nsynchronous baselines in geo-distributed LLM training and improves upon\nexisting asynchronous methods by up to 2.1x. Crucially, HALoS preserves the\nmodel quality of fully synchronous SGD-matching or exceeding accuracy on\nstandard language modeling and downstream benchmarks-while substantially\nlowering total training time. These results demonstrate that hierarchical,\nserver-side update accumulation and global model merging are powerful tools for\nscalable, efficient training of new-era LLMs in heterogeneous, geo-distributed\nenvironments.", "AI": {"title_translation": "HALoS：面向地理分布式大型语言模型训练的慢速网络分层异步局部SGD", "tldr": "HALoS是一种分层异步优化框架，通过引入局部和全局参数服务器，显著加速了地理分布式大型语言模型（LLM）的训练，同时保持了模型质量。", "motivation": "训练大型语言模型（LLMs）越来越依赖地理分布式加速器，这导致了区域间高昂的通信成本和异构硬件利用率不均的问题。", "method": "HALoS是一种分层异步优化框架，通过在每个区域内引入局部参数服务器（LPSs）和合并区域间更新的全局参数服务器（GPS）来解决问题。该框架还提供了在非凸目标下的严格收敛性分析，包括异步训练中分层动量的理论保证。", "result": "HALoS在地理分布式LLM训练中比同步基线快7.5倍，比现有异步方法快2.1倍。HALoS在标准语言建模和下游基准测试中保持或超过了完全同步SGD的模型质量，同时显著降低了总训练时间。", "conclusion": "分层、服务器端更新累积和全局模型合并是异构、地理分布式环境中可扩展、高效训练新时代LLM的强大工具。", "translation": "大型语言模型（LLMs）的训练越来越依赖地理分布式加速器，这导致了区域间高昂的通信成本和异构硬件利用率不均的问题。我们提出了HALoS，一个分层异步优化框架，通过在每个区域内引入局部参数服务器（LPSs）和合并区域间更新的全局参数服务器（GPS）来解决这些问题。这种分层设计最大限度地减少了昂贵的区域间通信，减少了落后者效应，并利用了快速的区域内链接。我们为HALoS在非凸目标下提供了严格的收敛性分析，包括异步训练中分层动量的理论保证。经验上，HALoS在地理分布式LLM训练中比同步基线快7.5倍，比现有异步方法快2.1倍。至关重要的是，HALoS保持了完全同步SGD的模型质量——在标准语言建模和下游基准测试中达到或超过了准确性——同时显著降低了总训练时间。这些结果表明，分层、服务器端更新累积和全局模型合并是异构、地理分布式环境中可扩展、高效训练新时代LLM的强大工具。", "summary": "HALoS是一种为解决地理分布式LLM训练中高昂通信成本和硬件利用率不均问题而设计的分层异步优化框架。它通过区域内局部参数服务器和区域间全局参数服务器的协同工作，显著减少了跨区域通信，降低了落后者效应，并利用了快速的区域内链接。HALoS在理论上提供了收敛性分析，并在实践中展示了比同步和现有异步方法更快的收敛速度，同时保持了模型质量。", "keywords": "大型语言模型训练, 分布式训练, 异步SGD, 分层优化, 通信效率"}}
{"id": "2506.04753", "pdf": "https://arxiv.org/pdf/2506.04753", "abs": "https://arxiv.org/abs/2506.04753", "authors": ["Niki Martinel", "Rita Pucci"], "title": "Physics Informed Capsule Enhanced Variational AutoEncoder for Underwater Image Enhancement", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "We present a novel dual-stream architecture that achieves state-of-the-art\nunderwater image enhancement by explicitly integrating the Jaffe-McGlamery\nphysical model with capsule clustering-based feature representation learning.\nOur method simultaneously estimates transmission maps and spatially-varying\nbackground light through a dedicated physics estimator while extracting\nentity-level features via capsule clustering in a parallel stream. This\nphysics-guided approach enables parameter-free enhancement that respects\nunderwater formation constraints while preserving semantic structures and\nfine-grained details. Our approach also features a novel optimization objective\nensuring both physical adherence and perceptual quality across multiple spatial\nfrequencies. To validate our approach, we conducted extensive experiments\nacross six challenging benchmarks. Results demonstrate consistent improvements\nof $+0.5$dB PSNR over the best existing methods while requiring only one-third\nof their computational complexity (FLOPs), or alternatively, more than $+1$dB\nPSNR improvement when compared to methods with similar computational budgets.\nCode and data \\textit{will} be available at https://github.com/iN1k1/.", "AI": {"title_translation": "水下图像增强的物理信息胶囊增强变分自编码器", "tldr": "本文提出一种结合物理模型和胶囊聚类的双流变分自编码器，用于水下图像增强，实现了最先进的性能，同时显著降低了计算复杂度。", "motivation": "现有水下图像增强方法可能未能充分利用物理模型，或在保持语义结构和细节的同时满足水下成像约束方面存在挑战。本文旨在通过结合物理模型和胶囊聚类，实现无参数且高质量的水下图像增强。", "method": "本文提出一种新颖的双流架构，显式地将Jaffe-McGlamery物理模型与基于胶囊聚类的特征表示学习相结合。该方法通过专用物理估计器同时估计透射图和空间变化的背景光，同时在并行流中通过胶囊聚类提取实体级特征。此外，还引入了一个新的优化目标，确保物理依从性和多空间频率下的感知质量。", "result": "在六个具有挑战性的基准测试中，相较于现有最佳方法，PSNR持续提升了+0.5dB，而计算复杂度（FLOPs）仅为其三分之一；与计算预算相似的方法相比，PSNR提升超过+1dB。", "conclusion": "本文提出的物理信息胶囊增强变分自编码器在水下图像增强方面取得了显著的最先进性能，同时大幅降低了计算成本，证明了其在实际应用中的潜力和有效性。", "translation": "我们提出了一种新颖的双流架构，通过将Jaffe-McGlamery物理模型与基于胶囊聚类的特征表示学习明确结合，实现了最先进的水下图像增强。我们的方法通过专用物理估计器同时估计透射图和空间变化的背景光，同时在并行流中通过胶囊聚类提取实体级特征。这种物理引导的方法实现了无参数增强，在保持水下成像约束的同时，保留了语义结构和精细细节。我们的方法还具有一个新颖的优化目标，确保了跨多个空间频率的物理依从性和感知质量。为了验证我们的方法，我们在六个具有挑战性的基准测试中进行了广泛的实验。结果表明，与现有最佳方法相比，PSNR持续提升了+0.5dB，同时仅需其三分之一的计算复杂度（FLOPs），或者，与计算预算相似的方法相比，PSNR提升超过+1dB。代码和数据将可在https://github.com/iN1k1/获取。", "summary": "本文提出一种新颖的双流架构，即物理信息胶囊增强变分自编码器（Physics Informed Capsule Enhanced Variational AutoEncoder），用于水下图像增强。该方法通过将Jaffe-McGlamery物理模型与胶囊聚类相结合，实现了对透射图和背景光的同步估计，并提取实体级特征。这种物理引导的无参数增强方法在尊重水下成像约束的同时，能有效保留语义结构和精细细节。实验结果表明，该方法在保持更高图像质量的同时，显著降低了计算复杂度，超越了现有最佳方法。", "keywords": "水下图像增强, 物理信息, 胶囊网络, 变分自编码器, 双流架构"}}
{"id": "2506.04536", "pdf": "https://arxiv.org/pdf/2506.04536", "abs": "https://arxiv.org/abs/2506.04536", "authors": ["Luca Ghafourpour", "Valentin Duruisseaux", "Bahareh Tolooshams", "Philip H. Wong", "Costas A. Anastassiou", "Anima Anandkumar"], "title": "NOBLE -- Neural Operator with Biologically-informed Latent Embeddings to Capture Experimental Variability in Biological Neuron Models", "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "comment": null, "summary": "Characterizing the diverse computational properties of human neurons via\nmultimodal electrophysiological, transcriptomic, and morphological data\nprovides the foundation for constructing and validating bio-realistic neuron\nmodels that can advance our understanding of fundamental mechanisms underlying\nbrain function. However, current modeling approaches remain constrained by the\nlimited availability and intrinsic variability of experimental neuronal data.\nTo capture variability, ensembles of deterministic models are often used, but\nare difficult to scale as model generation requires repeating computationally\nexpensive optimization for each neuron. While deep learning is becoming\nincreasingly relevant in this space, it fails to capture the full biophysical\ncomplexity of neurons, their nonlinear voltage dynamics, and variability. To\naddress these shortcomings, we introduce NOBLE, a neural operator framework\nthat learns a mapping from a continuous frequency-modulated embedding of\ninterpretable neuron features to the somatic voltage response induced by\ncurrent injection. Trained on data generated from biophysically realistic\nneuron models, NOBLE predicts distributions of neural dynamics accounting for\nthe intrinsic experimental variability. Unlike conventional bio-realistic\nneuron models, interpolating within the embedding space offers models whose\ndynamics are consistent with experimentally observed responses. NOBLE is the\nfirst scaled-up deep learning framework validated on real experimental data,\nenabling efficient generation of synthetic neurons that exhibit trial-to-trial\nvariability and achieve a $4200\\times$ speedup over numerical solvers. To this\nend, NOBLE captures fundamental neural properties, opening the door to a better\nunderstanding of cellular composition and computations, neuromorphic\narchitectures, large-scale brain circuits, and general neuroAI applications.", "AI": {"title_translation": "NOBLE -- 具有生物学信息潜在嵌入的神经算子，用于捕获生物神经元模型中的实验变异性", "tldr": "NOBLE是一个深度学习框架，使用神经算子捕获生物神经元模型中的实验变异性，实现高效的合成神经元生成和显著的加速。", "motivation": "表征人类神经元的计算特性对于构建和验证生物真实神经元模型至关重要，但现有建模方法受限于实验神经元数据的有限可用性和内在变异性。传统的确定性模型集成难以扩展，且深度学习未能捕捉神经元的完整生物物理复杂性和变异性。", "method": "本文引入了NOBLE，一个神经算子框架，它学习从可解释神经元特征的连续频率调制嵌入到电流注入引起的躯体电压响应的映射。NOBLE在生物物理真实的神经元模型生成的数据上进行训练，并通过在嵌入空间内插值，提供与实验观察响应一致的模型。", "result": "NOBLE能够预测神经动力学分布，解释内在实验变异性。它是第一个在真实实验数据上验证的规模化深度学习框架，能够高效生成表现出试验间变异性的合成神经元，并实现比数值求解器快4200倍的速度。NOBLE捕获了基本的神经属性。", "conclusion": "NOBLE为更好地理解细胞组成和计算、神经形态结构、大规模大脑回路和通用神经AI应用打开了大门。", "translation": "通过多模式电生理学、转录组学和形态学数据表征人类神经元的多样化计算特性，为构建和验证生物真实神经元模型奠定了基础，从而推进我们对大脑功能基本机制的理解。然而，当前的建模方法仍然受到实验神经元数据有限可用性和内在变异性的限制。为了捕获变异性，通常使用确定性模型集成，但由于模型生成需要为每个神经元重复计算昂贵的优化，因此难以扩展。虽然深度学习在该领域变得越来越重要，但它未能捕捉神经元的完整生物物理复杂性、其非线性电压动力学和变异性。为了解决这些缺点，我们引入了NOBLE，一个神经算子框架，它学习从可解释神经元特征的连续频率调制嵌入到电流注入引起的躯体电压响应的映射。NOBLE在从生物物理真实的神经元模型生成的数据上进行训练，预测神经动力学分布，从而解释内在实验变异性。与传统的生物真实神经元模型不同，在嵌入空间内插值可提供动力学与实验观察响应一致的模型。NOBLE是第一个在真实实验数据上验证的规模化深度学习框架，能够高效生成表现出试验间变异性的合成神经元，并实现比数值求解器快4200倍的速度。为此，NOBLE捕获了基本的神经属性，为更好地理解细胞组成和计算、神经形态结构、大规模大脑回路和通用神经AI应用打开了大门。", "summary": "NOBLE是一个创新的神经算子深度学习框架，旨在解决现有生物神经元模型在处理实验数据有限性、内在变异性和计算效率方面的局限。它通过学习从生物学特征嵌入到电压响应的映射，能够高效地生成具有实验变异性的合成神经元，并实现显著的计算加速，从而加深对神经元特性和大脑功能的理解。", "keywords": "神经算子, 生物神经元模型, 实验变异性, 潜在嵌入, 深度学习"}}
{"id": "2506.04755", "pdf": "https://arxiv.org/pdf/2506.04755", "abs": "https://arxiv.org/abs/2506.04755", "authors": ["Shenshen Li", "Kaiyuan Deng", "Lei Wang", "Hao Yang", "Chong Peng", "Peng Yan", "Fumin Shen", "Heng Tao Shen", "Xing Xu"], "title": "Truth in the Few: High-Value Data Selection for Efficient Multi-Modal Reasoning", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": null, "summary": "While multi-modal large language models (MLLMs) have made significant\nprogress in complex reasoning tasks via reinforcement learning, it is commonly\nbelieved that extensive training data is necessary for improving multi-modal\nreasoning ability, inevitably leading to data redundancy and substantial\ncomputational costs. However, can smaller high-value datasets match or\noutperform full corpora for multi-modal reasoning in MLLMs? In this work, we\nchallenge this assumption through a key observation: meaningful multi-modal\nreasoning is triggered by only a sparse subset of training samples, termed\ncognitive samples, whereas the majority contribute marginally. Building on this\ninsight, we propose a novel data selection paradigm termed Reasoning Activation\nPotential (RAP), which identifies cognitive samples by estimating each sample's\npotential to stimulate genuine multi-modal reasoning by two complementary\nestimators: 1) Causal Discrepancy Estimator (CDE) based on the potential\noutcome model principle, eliminates samples that overly rely on language priors\nby comparing outputs between multi-modal and text-only inputs; 2) Attention\nConfidence Estimator (ACE), which exploits token-level self-attention to\ndiscard samples dominated by irrelevant but over-emphasized tokens in\nintermediate reasoning stages. Moreover, we introduce a Difficulty-aware\nReplacement Module (DRM) to substitute trivial instances with cognitively\nchallenging ones, thereby ensuring complexity for robust multi-modal reasoning.\nExperiments on six datasets show that our RAP method consistently achieves\nsuperior performance using only 9.3% of the training data, while reducing\ncomputational costs by over 43%. Our code is available at\nhttps://github.com/Leo-ssl/RAP.", "AI": {"title_translation": "少数中的真理：高效多模态推理的高价值数据选择", "tldr": "通过选择少量高价值数据，RAP方法显著提升了多模态大语言模型的推理效率并降低了计算成本。", "motivation": "多模态大语言模型（MLLMs）在复杂推理任务中取得了显著进展，但普遍认为需要大量训练数据来提升多模态推理能力，这不可避免地导致数据冗余和高昂的计算成本。本文旨在挑战这一假设，探讨小规模高价值数据集是否能匹配或超越完整数据集在MLLMs多模态推理中的表现。", "method": "本文提出了一种新颖的数据选择范式，称为推理激活潜力（Reasoning Activation Potential, RAP）。RAP通过两种互补的估计器识别“认知样本”：1) 因果差异估计器（Causal Discrepancy Estimator, CDE），基于潜在结果模型原理，通过比较多模态输入和纯文本输入之间的输出，消除过度依赖语言先验的样本；2) 注意力置信度估计器（Attention Confidence Estimator, ACE），利用词元级别的自注意力机制，丢弃在中间推理阶段被不相关但被过度强调的词元所主导的样本。此外，还引入了一个难度感知替换模块（Difficulty-aware Replacement Module, DRM），用认知上更具挑战性的实例替换琐碎的实例，从而确保多模态推理的鲁棒性。", "result": "在六个数据集上的实验表明，本文提出的RAP方法仅使用9.3%的训练数据，就持续取得了优越的性能，同时将计算成本降低了43%以上。", "conclusion": "本文通过提出RAP数据选择范式，成功挑战了多模态大语言模型需要大量训练数据的假设。结果表明，通过识别和利用少量高价值的认知样本，可以在显著减少数据量和计算成本的同时，有效提升多模态推理能力，为高效的MLLMs训练提供了新途径。", "translation": "虽然多模态大语言模型（MLLMs）通过强化学习在复杂推理任务中取得了显著进展，但人们普遍认为，需要大量的训练数据来提高多模态推理能力，这不可避免地导致数据冗余和巨大的计算成本。然而，较小的高价值数据集能否在MLLMs的多模态推理中匹配或超越完整语料库呢？在这项工作中，我们通过一个关键观察来挑战这一假设：有意义的多模态推理仅由训练样本中的稀疏子集（称为认知样本）触发，而大多数样本贡献微乎其微。基于这一洞察，我们提出了一种新颖的数据选择范式，称为推理激活潜力（Reasoning Activation Potential, RAP），它通过两种互补的估计器来估计每个样本激发真实多模态推理的潜力，从而识别认知样本：1）因果差异估计器（Causal Discrepancy Estimator, CDE），基于潜在结果模型原理，通过比较多模态输入和纯文本输入之间的输出，消除过度依赖语言先验的样本；2）注意力置信度估计器（Attention Confidence Estimator, ACE），它利用词元级别的自注意力机制，丢弃在中间推理阶段被不相关但被过度强调的词元所主导的样本。此外，我们引入了一个难度感知替换模块（Difficulty-aware Replacement Module, DRM），用认知上更具挑战性的实例替换琐碎的实例，从而确保多模态推理的鲁棒性。在六个数据集上的实验表明，我们的RAP方法仅使用9.3%的训练数据就持续取得了优越的性能，同时将计算成本降低了43%以上。我们的代码可在https://github.com/Leo-ssl/RAP获取。", "summary": "针对多模态大语言模型（MLLMs）训练数据量大、计算成本高的问题，本文提出了一种名为推理激活潜力（RAP）的新型数据选择范式。RAP通过因果差异估计器（CDE）识别消除过度依赖语言先验的样本，并通过注意力置信度估计器（ACE）筛选掉被不相关词元主导的样本，从而识别出能有效激发多模态推理的“认知样本”。此外，为确保推理的鲁棒性，该方法还引入了难度感知替换模块（DRM）以替换琐碎实例。实验证明，RAP方法仅使用9.3%的训练数据，便在六个数据集上取得了更优异的性能，同时降低了超过43%的计算成本。", "keywords": "多模态推理, 数据选择, 高价值数据, 计算成本, 认知样本"}}
{"id": "2506.04542", "pdf": "https://arxiv.org/pdf/2506.04542", "abs": "https://arxiv.org/abs/2506.04542", "authors": ["Yuanpei Gao", "Qi Yan", "Yan Leng", "Renjie Liao"], "title": "Neural MJD: Neural Non-Stationary Merton Jump Diffusion for Time Series Prediction", "categories": ["cs.LG"], "comment": null, "summary": "While deep learning methods have achieved strong performance in time series\nprediction, their black-box nature and inability to explicitly model underlying\nstochastic processes often limit their generalization to non-stationary data,\nespecially in the presence of abrupt changes. In this work, we introduce Neural\nMJD, a neural network based non-stationary Merton jump diffusion (MJD) model.\nOur model explicitly formulates forecasting as a stochastic differential\nequation (SDE) simulation problem, combining a time-inhomogeneous It\\^o\ndiffusion to capture non-stationary stochastic dynamics with a\ntime-inhomogeneous compound Poisson process to model abrupt jumps. To enable\ntractable learning, we introduce a likelihood truncation mechanism that caps\nthe number of jumps within small time intervals and provide a theoretical error\nbound for this approximation. Additionally, we propose an Euler-Maruyama with\nrestart solver, which achieves a provably lower error bound in estimating\nexpected states and reduced variance compared to the standard solver.\nExperiments on both synthetic and real-world datasets demonstrate that Neural\nMJD consistently outperforms state-of-the-art deep learning and statistical\nlearning methods.", "AI": {"title_translation": "神经MJD：用于时间序列预测的神经非平稳Merton跳跃扩散模型", "tldr": "神经MJD是一种结合神经网络和非平稳Merton跳跃扩散过程的新模型，旨在改进时间序列预测，尤其是在处理非平稳数据和突变方面。", "motivation": "深度学习方法在时间序列预测中表现出色，但其黑盒性质和无法显式建模底层随机过程的局限性，限制了它们在非平稳数据（尤其存在突变时）上的泛化能力。", "method": "提出神经MJD模型，将预测显式地表述为随机微分方程（SDE）模拟问题。该模型结合了时间不均匀的Itô扩散过程（捕获非平稳随机动态）和时间不均匀的复合泊松过程（建模突发跳跃）。为实现可处理的学习，引入了似然截断机制，并提出了Euler-Maruyama重启求解器，以降低预期状态估计误差和方差。", "result": "在合成数据集和真实世界数据集上的实验表明，神经MJD始终优于最先进的深度学习和统计学习方法。", "conclusion": "神经MJD通过结合神经网络和非平稳Merton跳跃扩散过程，有效解决了现有深度学习方法在处理包含突变的非平稳时间序列数据时的局限性，并展现出卓越的预测性能。", "translation": "尽管深度学习方法在时间序列预测中取得了强大性能，但其黑盒性质以及无法显式建模底层随机过程的局限性，常常限制了它们在非平稳数据（尤其存在突变时）上的泛化能力。在这项工作中，我们引入了神经MJD，一个基于神经网络的非平稳Merton跳跃扩散（MJD）模型。我们的模型明确地将预测表述为随机微分方程（SDE）模拟问题，结合了时间不均匀的Itô扩散来捕获非平稳随机动态，以及时间不均匀的复合泊松过程来建模突发跳跃。为了实现可处理的学习，我们引入了一种似然截断机制，该机制限制了小时间间隔内的跳跃次数，并为这种近似提供了理论误差界。此外，我们提出了一种带重启的Euler-Maruyama求解器，与标准求解器相比，它在估计预期状态方面实现了可证明的更低误差界并降低了方差。在合成数据集和真实世界数据集上的实验表明，神经MJD始终优于最先进的深度学习和统计学习方法。", "summary": "神经MJD是一种新颖的基于神经网络的非平稳Merton跳跃扩散模型，它将时间序列预测明确地公式化为随机微分方程模拟问题。该模型结合了时间不均匀的Itô扩散和复合泊松过程来捕捉非平稳动态和突发跳跃。为了可处理的学习，它引入了似然截断机制和改进的Euler-Maruyama重启求解器。实验证明，神经MJD在处理非平稳时间序列数据方面优于现有方法。", "keywords": "神经MJD, 时间序列预测, 非平稳数据, 跳跃扩散, 随机微分方程"}}
{"id": "2506.04247", "pdf": "https://arxiv.org/pdf/2506.04247", "abs": "https://arxiv.org/abs/2506.04247", "authors": ["Gage K. R. Hooper"], "title": "The GAIN Model: A Nature-Inspired Neural Network Framework Based on an Adaptation of the Izhikevich Model", "categories": ["q-bio.NC", "cs.AI", "cs.NE", "92B20, 37N25, 68T05", "I.2.6; I.5.1; I.6.3"], "comment": "31 pages, 16 figures", "summary": "While many neural networks focus on layers to process information, the GAIN\nmodel uses a grid-based structure to improve biological plausibility and the\ndynamics of the model. The grid structure helps neurons to interact with their\nclosest neighbors and improve their connections with one another, which is seen\nin biological neurons. While also being implemented with the Izhikevich model\nthis approach allows for a computationally efficient and biologically accurate\nsimulation that can aid in the development of neural networks, large scale\nsimulations, and the development in the neuroscience field. This adaptation of\nthe Izhikevich model can improve the dynamics and accuracy of the model,\nallowing for its uses to be specialized but efficient.", "AI": {"title_translation": "GAIN模型：一种基于Izhikevich模型改进的自然启发神经网络框架", "tldr": "GAIN模型利用网格结构和Izhikevich模型的改进，实现了生物学上更合理且高效的神经网络模拟。", "motivation": "许多神经网络侧重于层来处理信息，而GAIN模型旨在通过使用基于网格的结构来提高生物学合理性和模型的动力学，并提供计算高效且生物学准确的模拟。", "method": "GAIN模型采用基于网格的结构，使神经元能够与最近的邻居互动并改善彼此之间的连接。此外，它还通过对Izhikevich模型进行改编来实现。", "result": "这种方法允许进行计算高效且生物学准确的模拟，能够辅助神经网络的开发、大规模模拟以及神经科学领域的发展。对Izhikevich模型的这种改编可以改善模型的动力学和准确性，使其用途专业化但高效。", "conclusion": "GAIN模型通过其网格结构和对Izhikevich模型的改编，提供了一种专业化但高效且生物学准确的模拟方法，有助于神经网络和神经科学的发展。", "translation": "虽然许多神经网络专注于层来处理信息，但GAIN模型使用基于网格的结构来提高生物学合理性和模型的动力学。网格结构有助于神经元与最近的邻居互动并改善彼此之间的连接，这在生物神经元中可见。同时，通过Izhikevich模型的实现，这种方法允许进行计算高效且生物学准确的模拟，可以帮助神经网络的开发、大规模模拟以及神经科学领域的发展。Izhikevich模型的这种改编可以改善模型的动力学和准确性，使其用途专业化但高效。", "summary": "GAIN模型引入了一种基于网格的神经网络框架，通过对Izhikevich模型的改编来增强生物学合理性和动力学。这种方法促进了高效准确的模拟，通过实现专业化但高效的应用，有益于神经网络开发、大规模模拟和神经科学研究。", "keywords": "GAIN模型, 神经网络, Izhikevich模型, 网格结构, 生物合理性"}}
{"id": "2506.04758", "pdf": "https://arxiv.org/pdf/2506.04758", "abs": "https://arxiv.org/abs/2506.04758", "authors": ["Yijun Cao", "Fuya Luo", "Yongjie Li"], "title": "Toward Better SSIM Loss for Unsupervised Monocular Depth Estimation", "categories": ["cs.CV"], "comment": "12 pages,4 figures", "summary": "Unsupervised monocular depth learning generally relies on the photometric\nrelation among temporally adjacent images. Most of previous works use both mean\nabsolute error (MAE) and structure similarity index measure (SSIM) with\nconventional form as training loss. However, they ignore the effect of\ndifferent components in the SSIM function and the corresponding hyperparameters\non the training. To address these issues, this work proposes a new form of\nSSIM. Compared with original SSIM function, the proposed new form uses addition\nrather than multiplication to combine the luminance, contrast, and structural\nsimilarity related components in SSIM. The loss function constructed with this\nscheme helps result in smoother gradients and achieve higher performance on\nunsupervised depth estimation. We conduct extensive experiments to determine\nthe relatively optimal combination of parameters for our new SSIM. Based on the\npopular MonoDepth approach, the optimized SSIM loss function can remarkably\noutperform the baseline on the KITTI-2015 outdoor dataset.", "AI": {"title_translation": "迈向更好的SSIM损失函数，用于无监督单目深度估计", "tldr": "本文提出了一种新的SSIM损失函数形式，通过将SSIM分量从乘法组合改为加法组合，旨在解决传统SSIM损失函数在无监督单目深度估计中对分量影响和超参数的忽视问题。实验证明，该方法能产生更平滑的梯度，并在KITTI-2015数据集上显著提升性能。", "motivation": "现有无监督单目深度学习方法在训练损失中使用的传统SSIM形式，忽略了SSIM函数中不同分量及其相应超参数对训练的影响。", "method": "提出一种新的SSIM形式，该形式使用加法而非乘法来组合SSIM中的亮度、对比度和结构相似性相关分量。通过广泛实验确定新SSIM的相对最佳参数组合。", "result": "新的损失函数方案有助于产生更平滑的梯度，并在无监督深度估计上实现更高性能。基于流行的MonoDepth方法，优化的SSIM损失函数在KITTI-2015室外数据集上显著优于基线。", "conclusion": "通过改进SSIM损失函数的形式，可以显著提升无监督单目深度估计的性能，并且新形式有助于产生更平滑的梯度。", "translation": "无监督单目深度学习通常依赖于时间上相邻图像之间的光度关系。大多数先前的工作使用均方误差（MAE）和传统形式的结构相似性指数（SSIM）作为训练损失。然而，它们忽略了SSIM函数中不同分量及其相应超参数对训练的影响。为了解决这些问题，这项工作提出了一种新的SSIM形式。与原始SSIM函数相比，所提出的新形式使用加法而非乘法来组合SSIM中与亮度、对比度和结构相似性相关的分量。使用这种方案构建的损失函数有助于产生更平滑的梯度，并在无监督深度估计中实现更高的性能。我们进行了广泛的实验，以确定我们新SSIM的相对最佳参数组合。基于流行的MonoDepth方法，优化的SSIM损失函数在KITTI-2015室外数据集上显著优于基线。", "summary": "本文针对无监督单目深度估计中传统SSIM损失函数忽略分量影响的问题，提出了一种新的SSIM形式。该形式通过加法组合亮度、对比度和结构相似性分量，有助于产生更平滑的梯度并提升性能。实验证明，优化后的SSIM损失函数在KITTI-2015数据集上显著优于基线。", "keywords": "无监督深度估计, SSIM损失, 单目深度估计, 光度损失, KITTI"}}
{"id": "2506.04548", "pdf": "https://arxiv.org/pdf/2506.04548", "abs": "https://arxiv.org/abs/2506.04548", "authors": ["Dev Gurung", "Shiva Raj Pokhrel"], "title": "Communication Efficient Adaptive Model-Driven Quantum Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Training with huge datasets and a large number of participating devices leads\nto bottlenecks in federated learning (FL). Furthermore, the challenges of\nheterogeneity between multiple FL clients affect the overall performance of the\nsystem. In a quantum federated learning (QFL) context, we address these three\nmain challenges: i) training bottlenecks from massive datasets, ii) the\ninvolvement of a substantial number of devices, and iii) non-IID data\ndistributions. We introduce a model-driven quantum federated learning algorithm\n(mdQFL) to tackle these challenges. Our proposed approach is efficient and\nadaptable to various factors, including different numbers of devices. To the\nbest of our knowledge, it is the first to explore training and update\npersonalization, as well as test generalization within a QFL setting, which can\nbe applied to other FL scenarios. We evaluated the efficiency of the proposed\nmdQFL framework through extensive experiments under diverse non-IID data\nheterogeneity conditions using various datasets within the Qiskit environment.\nOur results demonstrate a nearly 50% decrease in total communication costs\nwhile maintaining or, in some cases, exceeding the accuracy of the final model\nand consistently improving local model training compared to the standard QFL\nbaseline. Moreover, our experimental evaluation thoroughly explores the QFL and\nmdQFL algorithms, along with several influencing factors. In addition, we\npresent a theoretical analysis to clarify the complexities of the proposed\nalgorithm. The experimental code is available at 1.", "AI": {"title_translation": "通信高效自适应模型驱动量子联邦学习", "tldr": "本文提出了一种模型驱动的量子联邦学习（mdQFL）算法，旨在解决量子联邦学习中大规模数据集、大量设备和非独立同分布数据引起的训练瓶颈和通信效率问题，并在通信成本降低近50%的同时保持或提高模型精度。", "motivation": "联邦学习（FL）中，处理大规模数据集和大量设备会导致瓶颈，多客户端之间的异构性也会影响系统整体性能。在量子联邦学习（QFL）背景下，面临三大挑战：i）海量数据集带来的训练瓶颈；ii）大量设备的参与；iii）非独立同分布（non-IID）数据分布。", "method": "本文提出了一种模型驱动的量子联邦学习算法（mdQFL）来解决这些挑战。该方法高效且能适应不同数量设备等多种因素。它是首次探索QFL设置中的训练和更新个性化以及测试泛化能力，并可应用于其他联邦学习场景。通过理论分析阐明了算法的复杂性。", "result": "通过在Qiskit环境下，使用各种数据集在不同非独立同分布数据异构条件下进行大量实验，评估了所提出的mdQFL框架的效率。结果显示，与标准QFL基线相比，总通信成本降低了近50%，同时保持或在某些情况下超过了最终模型的准确性，并持续改善了局部模型训练。", "conclusion": "本文成功提出了模型驱动的量子联邦学习（mdQFL）算法，有效解决了QFL中的训练瓶颈、大规模设备和非独立同分布数据挑战，显著降低了通信成本并保持了高精度，为QFL的实际应用提供了高效且适应性强的解决方案。", "translation": "大规模数据集和大量参与设备的训练会导致联邦学习（FL）中的瓶颈。此外，多个FL客户端之间的异构性挑战影响了系统的整体性能。在量子联邦学习（QFL）背景下，我们解决了这三个主要挑战：i）来自海量数据集的训练瓶颈，ii）大量设备的参与，以及iii）非独立同分布数据分布。我们引入了一种模型驱动的量子联邦学习算法（mdQFL）来解决这些挑战。我们提出的方法高效且能适应各种因素，包括不同数量的设备。据我们所知，这是首次在QFL设置中探索训练和更新个性化以及测试泛化能力，其可以应用于其他FL场景。我们在Qiskit环境下，使用各种数据集在不同的非独立同分布数据异构条件下通过大量实验评估了所提出的mdQFL框架的效率。我们的结果表明，与标准QFL基线相比，总通信成本降低了近50%，同时保持或在某些情况下超过了最终模型的准确性，并持续改善了局部模型训练。此外，我们的实验评估全面探讨了QFL和mdQFL算法以及几个影响因素。此外，我们还提出了理论分析以阐明所提出算法的复杂性。实验代码可在1处获取。", "summary": "本文针对联邦学习中大规模数据集、大量设备和数据异构性导致的训练瓶颈问题，特别是在量子联邦学习（QFL）背景下，提出了一种名为模型驱动量子联邦学习（mdQFL）的新算法。该算法旨在提高通信效率和适应性，并首次在QFL中探索训练和更新个性化及测试泛化。实验结果表明，与现有QFL基线相比，mdQFL在通信成本上实现了近50%的降低，同时保持或提升了模型精度，并持续改善了局部模型训练。", "keywords": "量子联邦学习, 模型驱动, 通信效率, 数据异构性, 训练瓶颈"}}
{"id": "2506.04764", "pdf": "https://arxiv.org/pdf/2506.04764", "abs": "https://arxiv.org/abs/2506.04764", "authors": ["Suhan Woo", "Seongwon Lee", "Jinwoo Jang", "Euntai Kim"], "title": "HypeVPR: Exploring Hyperbolic Space for Perspective to Equirectangular Visual Place Recognition", "categories": ["cs.CV"], "comment": null, "summary": "When applying Visual Place Recognition (VPR) to real-world mobile robots and\nsimilar applications, perspective-to-equirectangular (P2E) formulation\nnaturally emerges as a suitable approach to accommodate diverse query images\ncaptured from various viewpoints. In this paper, we introduce HypeVPR, a novel\nhierarchical embedding framework in hyperbolic space, designed to address the\nunique challenges of P2E VPR. The key idea behind HypeVPR is that visual\nenvironments captured by panoramic views exhibit inherent hierarchical\nstructures. To leverage this property, we employ hyperbolic space to represent\nhierarchical feature relationships and preserve distance properties within the\nfeature space. To achieve this, we propose a hierarchical feature aggregation\nmechanism that organizes local-to-global feature representations within\nhyperbolic space. Additionally, HypeVPR adopts an efficient coarse-to-fine\nsearch strategy, optimally balancing speed and accuracy to ensure robust\nmatching, even between descriptors from different image types. This approach\nenables HypeVPR to outperform state-of-the-art methods while significantly\nreducing retrieval time, achieving up to 5x faster retrieval across diverse\nbenchmark datasets. The code and models will be released at\nhttps://github.com/suhan-woo/HypeVPR.git.", "AI": {"title_translation": "HypeVPR: 探索双曲空间用于透视到全景视觉地点识别", "tldr": "HypeVPR利用双曲空间进行透视到全景视觉地点识别，实现了更快的检索速度和更高的性能，且检索速度提高了5倍。", "motivation": "在真实世界的移动机器人和类似应用中，透视到全景（P2E）的视觉地点识别（VPR）自然而然地成为一种合适的方案，以适应从各种视点捕获的不同查询图像。该研究旨在解决P2E VPR的独特挑战。", "method": "本文引入了HypeVPR，一个新颖的在双曲空间中的分层嵌入框架。HypeVPR的关键思想是利用全景视图捕获的视觉环境固有的分层结构。为此，它采用双曲空间来表示分层特征关系并保留特征空间内的距离属性。具体而言，HypeVPR提出了一种分层特征聚合机制，用于在双曲空间内组织从局部到全局的特征表示。此外，HypeVPR采用了一种高效的粗到细搜索策略，以最佳地平衡速度和准确性，即使在不同图像类型的描述符之间也能确保鲁棒匹配。", "result": "HypeVPR在显著减少检索时间的同时，超越了现有技术，在各种基准数据集上实现了高达5倍的检索速度提升。", "conclusion": "HypeVPR通过利用双曲空间中的分层嵌入框架和高效的粗到细搜索策略，为透视到全景视觉地点识别（P2E VPR）提供了一个鲁棒且高效的解决方案，显著提高了性能和检索速度。", "translation": "当将视觉地点识别（VPR）应用于真实世界的移动机器人和类似应用时，透视到全景（P2E）的公式自然而然地成为一种合适的方案，以适应从各种视点捕获的不同查询图像。在本文中，我们介绍了HypeVPR，一个新颖的在双曲空间中的分层嵌入框架，旨在解决P2E VPR的独特挑战。HypeVPR的关键思想是全景视图捕获的视觉环境呈现出固有的分层结构。为了利用这一特性，我们采用双曲空间来表示分层特征关系并保留特征空间内的距离属性。为了实现这一点，我们提出了一种分层特征聚合机制，用于在双曲空间内组织从局部到全局的特征表示。此外，HypeVPR采用了一种高效的粗到细搜索策略，以最佳地平衡速度和准确性，即使在不同图像类型的描述符之间也能确保鲁棒匹配。这种方法使HypeVPR能够超越现有技术，同时显著减少检索时间，在各种基准数据集上实现了高达5倍的检索速度提升。代码和模型将在https://github.com/suhan-woo/HypeVPR.git发布。", "summary": "HypeVPR是一种新颖的基于双曲空间的层次嵌入框架，旨在解决透视到全景视觉地点识别（P2E VPR）的挑战。它利用双曲空间表示视觉环境的层次结构，并采用层次特征聚合机制和粗到细搜索策略，显著提高了检索速度和准确性，超越了现有技术，在各种基准数据集上实现了高达5倍的检索速度提升。", "keywords": "视觉地点识别, 双曲空间, 透视到全景, 分层嵌入, 粗到细搜索"}}
{"id": "2506.04553", "pdf": "https://arxiv.org/pdf/2506.04553", "abs": "https://arxiv.org/abs/2506.04553", "authors": ["Andersen Chang", "Tiffany M. Tang", "Tarek M. Zikry", "Genevera I. Allen"], "title": "Unsupervised Machine Learning for Scientific Discovery: Workflow and Best Practices", "categories": ["cs.LG", "stat.AP", "stat.CO", "stat.ML"], "comment": "23 pages, 4 figures, 12 additional pages of citations", "summary": "Unsupervised machine learning is widely used to mine large, unlabeled\ndatasets to make data-driven discoveries in critical domains such as climate\nscience, biomedicine, astronomy, chemistry, and more. However, despite its\nwidespread utilization, there is a lack of standardization in unsupervised\nlearning workflows for making reliable and reproducible scientific discoveries.\nIn this paper, we present a structured workflow for using unsupervised learning\ntechniques in science. We highlight and discuss best practices starting with\nformulating validatable scientific questions, conducting robust data\npreparation and exploration, using a range of modeling techniques, performing\nrigorous validation by evaluating the stability and generalizability of\nunsupervised learning conclusions, and promoting effective communication and\ndocumentation of results to ensure reproducible scientific discoveries. To\nillustrate our proposed workflow, we present a case study from astronomy,\nseeking to refine globular clusters of Milky Way stars based upon their\nchemical composition. Our case study highlights the importance of validation\nand illustrates how the benefits of a carefully-designed workflow for\nunsupervised learning can advance scientific discovery.", "AI": {"title_translation": "无监督机器学习在科学发现中的应用：工作流程与最佳实践", "tldr": "本文提出了一个结构化的无监督机器学习工作流程和最佳实践，以促进科学发现的可靠性和可复现性，并以天文学案例研究进行了说明。", "motivation": "尽管无监督机器学习在科学发现中广泛使用，但缺乏标准化的工作流程来确保可靠和可复现的科学发现。", "method": "本文提出了一种结构化的无监督学习技术在科学中的应用工作流程，涵盖了从科学问题 формулировка、数据准备与探索、模型技术应用、严格验证（评估稳定性与泛化能力）到结果有效沟通与文档记录等环节。通过一个天文学案例研究（基于化学成分提炼银河系恒星的球状星团）来阐述所提出的工作流程。", "result": "本文提出了一个结构化的无监督学习工作流程，并通过天文学案例研究强调了验证的重要性，展示了精心设计的工作流程如何促进科学发现。", "conclusion": "精心设计的无监督学习工作流程，特别是强调验证的环节，对于推进科学发现至关重要，并能确保发现的可靠性和可复现性。", "translation": "无监督机器学习被广泛用于挖掘大型、无标签数据集，以便在气候科学、生物医学、天文学、化学等关键领域进行数据驱动的发现。然而，尽管其应用广泛，但在无监督学习工作流程中缺乏标准化，以实现可靠和可复现的科学发现。在本文中，我们提出了一个在科学中使用无监督学习技术的结构化工作流程。我们强调并讨论了最佳实践，包括 формулировка 可验证的科学问题、进行稳健的数据准备和探索、使用一系列建模技术、通过评估无监督学习结论的稳定性和泛化能力进行严格验证，以及促进结果的有效沟通和文档记录，以确保可复现的科学发现。为了说明我们提出的工作流程，我们提出了一个天文学案例研究，旨在根据银河系恒星的化学成分提炼其球状星团。我们的案例研究强调了验证的重要性，并说明了精心设计的无监督学习工作流程如何促进科学发现。", "summary": "本文针对无监督机器学习在科学发现中缺乏标准化工作流程的问题，提出了一个结构化的无监督学习工作流程和一系列最佳实践。该工作流程涵盖了从提出可验证的科学问题、数据准备、模型应用、严格验证到结果沟通与文档记录等关键步骤，旨在提高科学发现的可靠性和可复现性。文章通过一个天文学案例研究（提炼银河系恒星的球状星团）来具体阐述和验证了所提出的工作流程的有效性，强调了验证在其中的重要作用。", "keywords": "无监督学习, 科学发现, 工作流程, 最佳实践, 可复现性"}}
{"id": "2506.04789", "pdf": "https://arxiv.org/pdf/2506.04789", "abs": "https://arxiv.org/abs/2506.04789", "authors": ["Gaia Di Lorenzo", "Federico Tombari", "Marc Pollefeys", "Daniel Barath"], "title": "Object-X: Learning to Reconstruct Multi-Modal 3D Object Representations", "categories": ["cs.CV"], "comment": null, "summary": "Learning effective multi-modal 3D representations of objects is essential for\nnumerous applications, such as augmented reality and robotics. Existing methods\noften rely on task-specific embeddings that are tailored either for semantic\nunderstanding or geometric reconstruction. As a result, these embeddings\ntypically cannot be decoded into explicit geometry and simultaneously reused\nacross tasks. In this paper, we propose Object-X, a versatile multi-modal\nobject representation framework capable of encoding rich object embeddings\n(e.g. images, point cloud, text) and decoding them back into detailed geometric\nand visual reconstructions. Object-X operates by geometrically grounding the\ncaptured modalities in a 3D voxel grid and learning an unstructured embedding\nfusing the information from the voxels with the object attributes. The learned\nembedding enables 3D Gaussian Splatting-based object reconstruction, while also\nsupporting a range of downstream tasks, including scene alignment, single-image\n3D object reconstruction, and localization. Evaluations on two challenging\nreal-world datasets demonstrate that Object-X produces high-fidelity novel-view\nsynthesis comparable to standard 3D Gaussian Splatting, while significantly\nimproving geometric accuracy. Moreover, Object-X achieves competitive\nperformance with specialized methods in scene alignment and localization.\nCritically, our object-centric descriptors require 3-4 orders of magnitude less\nstorage compared to traditional image- or point cloud-based approaches,\nestablishing Object-X as a scalable and highly practical solution for\nmulti-modal 3D scene representation.", "AI": {"title_translation": "Object-X: 学习重建多模态三维物体表示", "tldr": "Object-X 是一种新颖的多模态三维物体表示框架，能够高效地编码和解码多源数据以实现高保真重建和支持多种下游任务，同时大幅减少存储需求。", "motivation": "学习有效的多模态三维物体表示对于增强现实和机器人等应用至关重要。现有方法通常依赖于针对语义理解或几何重建的特定任务嵌入，导致这些嵌入无法解码为明确的几何形状且难以跨任务重用。", "method": "本文提出了 Object-X，一个通用的多模态物体表示框架。它通过将捕获的模态几何地锚定在三维体素网格中，并学习一种融合体素信息与物体属性的非结构化嵌入。这种学习到的嵌入能够实现基于三维高斯泼溅的物体重建，并支持场景对齐、单图像三维物体重建和定位等一系列下游任务。", "result": "在两个具有挑战性的真实世界数据集上的评估表明，Object-X 产生的高保真新视角合成与标准三维高斯泼溅相当，同时显著提高了几何精度。此外，Object-X 在场景对齐和定位方面也达到了与专业方法相当的性能。最重要的是，其以物体为中心的描述符所需的存储空间比传统的基于图像或点云的方法少3-4个数量级。", "conclusion": "Object-X 作为一种可扩展且高度实用的多模态三维场景表示解决方案，能够实现高保真重建、支持多种下游任务，并显著降低存储成本。", "translation": "学习有效的多模态三维物体表示对于增强现实和机器人等众多应用至关重要。现有方法通常依赖于针对语义理解或几何重建而定制的特定任务嵌入。因此，这些嵌入通常无法解码为明确的几何形状，也无法同时跨任务重用。在本文中，我们提出了 Object-X，一个通用的多模态物体表示框架，能够编码丰富的物体嵌入（例如图像、点云、文本），并将其解码回详细的几何和视觉重建。Object-X 通过将捕获的模态几何地锚定在三维体素网格中，并学习一种融合体素信息与物体属性的非结构化嵌入。学习到的嵌入能够实现基于三维高斯泼溅的物体重建，同时还支持一系列下游任务，包括场景对齐、单图像三维物体重建和定位。在两个具有挑战性的真实世界数据集上的评估表明，Object-X 产生的高保真新视角合成与标准三维高斯泼溅相当，同时显著提高了几何精度。此外，Object-X 在场景对齐和定位方面也达到了与专业方法相当的性能。最重要的是，我们的以物体为中心的描述符所需的存储空间比传统的基于图像或点云的方法少3-4个数量级，这确立了 Object-X 作为一种可扩展且高度实用的多模态三维场景表示解决方案。", "summary": "Object-X 是一种新颖的多模态三维物体表示框架，旨在解决现有方法在几何解码和跨任务重用方面的局限性。它通过在三维体素网格中几何锚定多模态数据并学习融合体素与物体属性的非结构化嵌入。该框架支持高斯泼溅的三维物体重建以及场景对齐、单图像三维物体重建和定位等下游任务。实验证明，Object-X 在新视角合成方面表现出色，显著提升了几何精度，并在下游任务中具有竞争力，同时存储效率比传统方法高出3-4个数量级，使其成为一种可扩展且实用的多模态三维场景表示方案。", "keywords": "多模态三维表示, Object-X, 高斯泼溅, 几何重建, 场景对齐"}}
{"id": "2506.04566", "pdf": "https://arxiv.org/pdf/2506.04566", "abs": "https://arxiv.org/abs/2506.04566", "authors": ["Kareem Amin", "Salman Avestimehr", "Sara Babakniya", "Alex Bie", "Weiwei Kong", "Natalia Ponomareva", "Umar Syed"], "title": "Clustering and Median Aggregation Improve Differentially Private Inference", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "comment": null, "summary": "Differentially private (DP) language model inference is an approach for\ngenerating private synthetic text. A sensitive input example is used to prompt\nan off-the-shelf large language model (LLM) to produce a similar example.\nMultiple examples can be aggregated together to formally satisfy the DP\nguarantee.\n  Prior work creates inference batches by sampling sensitive inputs uniformly\nat random. We show that uniform sampling degrades the quality of privately\ngenerated text, especially when the sensitive examples concern heterogeneous\ntopics.\n  We remedy this problem by clustering the input data before selecting\ninference batches. Next, we observe that clustering also leads to more similar\nnext-token predictions across inferences. We use this insight to introduce a\nnew algorithm that aggregates next token statistics by privately computing\nmedians instead of averages. This approach leverages the fact that the median\nhas decreased local sensitivity when next token predictions are similar,\nallowing us to state a data-dependent and ex-post DP guarantee about the\nprivacy properties of this algorithm. Finally, we demonstrate improvements in\nterms of representativeness metrics (e.g., MAUVE) as well as downstream task\nperformance. We show that our method produces high-quality synthetic data at\nsignificantly lower privacy cost than a previous state-of-the-art method.", "AI": {"title_translation": "聚类和中值聚合改进差分隐私推理", "tldr": "本文提出通过聚类输入数据和使用中值聚合来提高差分隐私语言模型推理的文本质量和隐私效率。", "motivation": "现有的差分隐私语言模型推理方法在均匀采样敏感输入时，尤其当输入主题异构时，会导致私有生成文本的质量下降。", "method": "本文通过在选择推理批次之前对输入数据进行聚类来解决异构性问题。此外，引入了一种新的算法，该算法通过私下计算中值而不是平均值来聚合下一个词元统计信息，利用了当下一个词元预测相似时中值具有较低局部敏感度的特性。", "result": "该方法在代表性指标（如MAUVE）和下游任务性能方面均有显著改进，并且以比现有最先进方法低得多的隐私成本生成高质量的合成数据。", "conclusion": "聚类和中值聚合显著提升了差分隐私推理的文本质量和隐私效率，特别是在处理异构数据时。", "translation": "差分隐私（DP）语言模型推理是一种生成私有合成文本的方法。敏感输入示例用于提示现成的大型语言模型（LLM）生成相似的示例。多个示例可以聚合在一起，以正式满足DP保证。\n  先前的工作通过均匀随机采样敏感输入来创建推理批次。我们发现，均匀采样会降低私有生成文本的质量，特别是当敏感示例涉及异构主题时。\n  我们通过在选择推理批次之前对输入数据进行聚类来弥补这个问题。接下来，我们观察到聚类还会导致推理之间下一个词元预测的相似性更高。我们利用这一见解引入了一种新算法，该算法通过私下计算中值而不是平均值来聚合下一个词元统计信息。这种方法利用了当中值下一个词元预测相似时，中值具有降低的局部敏感度这一事实，从而使我们能够声明关于该算法隐私属性的数据相关和事后DP保证。最后，我们展示了在代表性指标（例如MAUVE）以及下游任务性能方面的改进。我们表明，我们的方法以比以前最先进方法显著更低的隐私成本生成高质量的合成数据。", "summary": "本文提出了一种改进差分隐私（DP）语言模型推理的方法，以解决现有均匀采样导致文本质量下降的问题，尤其是在处理异构主题数据时。该方法首先对输入数据进行聚类，然后引入一种新的中值聚合算法来聚合下一个词元统计信息，从而利用中值在预测相似时的低局部敏感性。实验结果表明，该方法在文本代表性和下游任务性能上均有显著提升，并能以更低的隐私成本生成高质量的合成数据。", "keywords": "差分隐私, 语言模型推理, 聚类, 中值聚合, 合成文本"}}
{"id": "2506.04790", "pdf": "https://arxiv.org/pdf/2506.04790", "abs": "https://arxiv.org/abs/2506.04790", "authors": ["Yusuke Matsui"], "title": "LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table", "categories": ["cs.CV", "cs.IR", "cs.LG"], "comment": "CVPR 2025. GitHub: https://github.com/matsui528/lotf", "summary": "Approximate nearest neighbor search (ANNS) is an essential building block for\napplications like RAG but can sometimes yield results that are overly similar\nto each other. In certain scenarios, search results should be similar to the\nquery and yet diverse. We propose LotusFilter, a post-processing module to\ndiversify ANNS results. We precompute a cutoff table summarizing vectors that\nare close to each other. During the filtering, LotusFilter greedily looks up\nthe table to delete redundant vectors from the candidates. We demonstrated that\nthe LotusFilter operates fast (0.02 [ms/query]) in settings resembling\nreal-world RAG applications, utilizing features such as OpenAI embeddings. Our\ncode is publicly available at https://github.com/matsui528/lotf.", "AI": {"title_translation": "LotusFilter：通过学习截止表实现快速多样化最近邻搜索", "tldr": "LotusFilter通过预先计算的截止表，快速过滤近似最近邻搜索（ANNS）结果中的冗余向量，从而实现结果多样化。", "motivation": "近似最近邻搜索（ANNS）有时会产生过于相似的结果，但在某些场景下，搜索结果既需要与查询相似，又需要具有多样性。", "method": "提出LotusFilter，一个用于多样化ANNS结果的后处理模块。它预先计算一个汇总彼此接近的向量的截止表。在过滤过程中，LotusFilter贪婪地查找该表，以从候选结果中删除冗余向量。", "result": "LotusFilter在类似真实世界RAG应用的环境中（例如使用OpenAI嵌入）运行速度快（0.02 [ms/query]）。代码已公开。", "conclusion": "LotusFilter能够快速有效地多样化近似最近邻搜索结果，适用于实际应用场景。", "translation": "近似最近邻搜索（ANNS）是RAG等应用中必不可少的基本组成部分，但有时会产生过于相似的结果。在某些场景下，搜索结果既应该与查询相似，又应该具有多样性。我们提出了LotusFilter，一个用于多样化ANNS结果的后处理模块。我们预先计算一个截止表，总结彼此接近的向量。在过滤过程中，LotusFilter贪婪地查找该表，以从候选结果中删除冗余向量。我们证明了LotusFilter在类似真实世界RAG应用的环境中（例如利用OpenAI嵌入等功能）运行速度快（0.02 [ms/query]）。我们的代码已公开，网址为https://github.com/matsui528/lotf。", "summary": "LotusFilter旨在解决近似最近邻搜索（ANNS）结果过于相似的问题，提出了一个快速的后处理模块。该模块通过预先计算一个截止表来识别并贪婪地删除冗余向量，从而实现结果多样化。实验证明，LotusFilter在模拟真实世界RAG应用场景中运行速度快，能够有效提升搜索结果的多样性。", "keywords": "近似最近邻搜索, 多样化, LotusFilter, 截止表, 后处理"}}
{"id": "2506.04567", "pdf": "https://arxiv.org/pdf/2506.04567", "abs": "https://arxiv.org/abs/2506.04567", "authors": ["Ranjith Merugu", "Bryan Bo Cao", "Shubham Jain"], "title": "StatsMerging: Statistics-Guided Model Merging via Task-Specific Teacher Distillation", "categories": ["cs.LG", "cs.CV", "68T05, 68T07, 68T45", "I.4.0; I.4.9; I.5.1; I.5.4"], "comment": "14 pages, 4 figures, 7 tables", "summary": "Model merging has emerged as a promising solution to accommodate multiple\nlarge models within constrained memory budgets. We present StatsMerging, a\nnovel lightweight learning-based model merging method guided by weight\ndistribution statistics without requiring ground truth labels or test samples.\nStatsMerging offers three key advantages: (1) It uniquely leverages singular\nvalues from singular value decomposition (SVD) to capture task-specific weight\ndistributions, serving as a proxy for task importance to guide task coefficient\nprediction; (2) It employs a lightweight learner StatsMergeLearner to model the\nweight distributions of task-specific pre-trained models, improving\ngeneralization and enhancing adaptation to unseen samples; (3) It introduces\nTask-Specific Teacher Distillation for merging vision models with heterogeneous\narchitectures, a merging learning paradigm that avoids costly ground-truth\nlabels by task-specific teacher distillation. Notably, we present two types of\nknowledge distillation, (a) distilling knowledge from task-specific models to\nStatsMergeLearner; and (b) distilling knowledge from models with heterogeneous\narchitectures prior to merging. Extensive experiments across eight tasks\ndemonstrate the effectiveness of StatsMerging. Our results show that\nStatsMerging outperforms state-of-the-art techniques in terms of overall\naccuracy, generalization to unseen tasks, and robustness to image quality\nvariations.", "AI": {"title_translation": "StatsMerging: 统计指导的模型合并与任务特定教师蒸馏", "tldr": "StatsMerging是一种轻量级、基于学习的模型合并方法，它利用权重分布统计和任务特定教师蒸馏来有效合并模型，无需真实标签，并在各种任务中表现出色。", "motivation": "在有限内存预算下，需要容纳多个大型模型。", "method": "StatsMerging是一种新颖的轻量级学习型模型合并方法，由权重分布统计指导，无需真实标签或测试样本。其核心方法包括：1) 利用奇异值分解(SVD)的奇异值捕获任务特定权重分布，作为任务重要性的代理来指导任务系数预测。2) 采用轻量级学习器StatsMergeLearner对任务特定预训练模型的权重分布进行建模，以提高泛化能力和适应性。3) 引入任务特定教师蒸馏（Task-Specific Teacher Distillation）来合并异构架构的视觉模型，这种合并学习范式通过任务特定教师蒸馏避免了昂贵的真实标签。该方法还包括两种知识蒸馏：(a) 将知识从任务特定模型蒸馏到StatsMergeLearner；(b) 在合并前将知识从异构架构模型中蒸馏出来。", "result": "StatsMerging在八项任务中进行了广泛实验，结果表明其在整体准确性、对未知任务的泛化能力以及对图像质量变化的鲁棒性方面均优于最先进的技术。", "conclusion": "StatsMerging通过其创新的统计指导和任务特定教师蒸馏方法，为解决内存受限环境下大型模型部署问题提供了一个有效且高效的解决方案，并在多项性能指标上超越了现有技术。", "translation": "模型合并已成为在有限内存预算内容纳多个大型模型的一种有前景的解决方案。我们提出了StatsMerging，这是一种新颖的轻量级基于学习的模型合并方法，它由权重分布统计指导，无需真实标签或测试样本。StatsMerging具有三个关键优势：(1) 它独特地利用奇异值分解(SVD)的奇异值来捕获任务特定权重分布，作为任务重要性的代理来指导任务系数预测；(2) 它采用轻量级学习器StatsMergeLearner来建模任务特定预训练模型的权重分布，从而提高泛化能力并增强对未知样本的适应性；(3) 它引入了任务特定教师蒸馏（Task-Specific Teacher Distillation）来合并异构架构的视觉模型，这是一种合并学习范式，通过任务特定教师蒸馏避免了昂贵的真实标签。值得注意的是，我们提出了两种类型的知识蒸馏，(a) 将知识从任务特定模型蒸馏到StatsMergeLearner；(b) 在合并前将知识从异构架构模型中蒸馏出来。在八项任务中进行的广泛实验证明了StatsMerging的有效性。我们的结果表明，StatsMerging在整体准确性、对未知任务的泛化能力以及对图像质量变化的鲁棒性方面均优于最先进的技术。", "summary": "StatsMerging是一种新颖的轻量级模型合并方法，它利用权重分布统计和任务特定教师蒸馏，无需真实标签即可有效合并模型。该方法通过SVD捕获任务重要性，使用StatsMergeLearner增强泛化能力，并引入任务特定教师蒸馏来处理异构架构，避免了对真实标签的需求。实验证明，StatsMerging在准确性、泛化能力和鲁棒性方面均优于现有技术。", "keywords": "模型合并, 统计指导, 教师蒸馏, 奇异值分解, 异构架构"}}
{"id": "2506.04803", "pdf": "https://arxiv.org/pdf/2506.04803", "abs": "https://arxiv.org/abs/2506.04803", "authors": ["Daniel Barath"], "title": "SupeRANSAC: One RANSAC to Rule Them All", "categories": ["cs.CV"], "comment": null, "summary": "Robust estimation is a cornerstone in computer vision, particularly for tasks\nlike Structure-from-Motion and Simultaneous Localization and Mapping. RANSAC\nand its variants are the gold standard for estimating geometric models (e.g.,\nhomographies, relative/absolute poses) from outlier-contaminated data. Despite\nRANSAC's apparent simplicity, achieving consistently high performance across\ndifferent problems is challenging. While recent research often focuses on\nimproving specific RANSAC components (e.g., sampling, scoring), overall\nperformance is frequently more influenced by the \"bells and whistles\" (i.e.,\nthe implementation details and problem-specific optimizations) within a given\nlibrary. Popular frameworks like OpenCV and PoseLib demonstrate varying\nperformance, excelling in some tasks but lagging in others. We introduce\nSupeRANSAC, a novel unified RANSAC pipeline, and provide a detailed analysis of\nthe techniques that make RANSAC effective for specific vision tasks, including\nhomography, fundamental/essential matrix, and absolute/rigid pose estimation.\nSupeRANSAC is designed for consistent accuracy across these tasks, improving\nupon the best existing methods by, for example, 6 AUC points on average for\nfundamental matrix estimation. We demonstrate significant performance\nimprovements over the state-of-the-art on multiple problems and datasets. Code:\nhttps://github.com/danini/superansac", "AI": {"title_translation": "SupeRANSAC：一个RANSAC统治所有", "tldr": "SupeRANSAC是一个新的统一RANSAC流程，旨在提高计算机视觉中几何模型估计的鲁棒性和一致性，并在多项任务中显著优于现有方法。", "motivation": "RANSAC及其变体是处理异常值污染数据以估计几何模型的黄金标准，但在不同问题上实现持续高性能具有挑战性。现有框架在不同任务上表现不一，缺乏一致性。", "method": "本文引入了SupeRANSAC，一个新颖的统一RANSAC流程。它通过详细分析使RANSAC对特定视觉任务（如单应性、基础/本质矩阵和绝对/刚性姿态估计）有效的技术来设计。", "result": "SupeRANSAC在这些任务中实现了持续的准确性，例如，在基础矩阵估计中平均提高了6个AUC点，并证明了在多个问题和数据集上优于现有最新方法的显著性能提升。", "conclusion": "SupeRANSAC通过提供一个统一且一致的RANSAC流程，显著提高了计算机视觉中几何模型估计的鲁棒性和性能，解决了现有方法在不同任务上性能不一致的问题。", "translation": "鲁棒估计是计算机视觉的基石，特别是对于运动结构（Structure-from-Motion）和同时定位与映射（Simultaneous Localization and Mapping）等任务。RANSAC及其变体是从受异常值污染的数据中估计几何模型（例如，单应性、相对/绝对姿态）的黄金标准。尽管RANSAC看似简单，但在不同问题上实现持续的高性能却极具挑战性。虽然最近的研究通常侧重于改进特定的RANSAC组件（例如，采样、评分），但整体性能却常常更多地受到给定库中“附加功能”（即，实现细节和针对特定问题的优化）的影响。OpenCV和PoseLib等流行框架表现出不同的性能，在某些任务中表现出色，但在其他任务中则滞后。我们引入了SupeRANSAC，一个新颖的统一RANSAC流程，并详细分析了使RANSAC对特定视觉任务（包括单应性、基础/本质矩阵以及绝对/刚性姿态估计）有效的技术。SupeRANSAC旨在这些任务中实现持续的准确性，例如，在基础矩阵估计中平均比现有最佳方法提高了6个AUC点。我们证明了在多个问题和数据集上，其性能显著优于现有最先进的技术。代码：https://github.com/danini/superansac", "summary": "该论文介绍了SupeRANSAC，一个创新的统一RANSAC框架，旨在解决现有RANSAC变体在计算机视觉任务中性能不一致的问题。SupeRANSAC通过集成有效的技术，在单应性、基础/本质矩阵及姿态估计等任务上实现了持续且显著的性能提升，例如在基础矩阵估计中平均提高了6个AUC点。研究结果表明，SupeRANSAC在多个数据集上均优于最先进的方法。", "keywords": "RANSAC, 鲁棒估计, 几何模型, 计算机视觉, SupeRANSAC"}}
{"id": "2506.04598", "pdf": "https://arxiv.org/pdf/2506.04598", "abs": "https://arxiv.org/abs/2506.04598", "authors": ["Marianna Nezhurina", "Tomer Porian", "Giovanni Pucceti", "Tommie Kerssies", "Romain Beaumont", "Mehdi Cherti", "Jenia Jitsev"], "title": "Scaling Laws for Robust Comparison of Open Foundation Language-Vision Models and Datasets", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Preprint. In Review", "summary": "In studies of transferable learning, scaling laws are obtained for various\nimportant foundation models to predict their properties and performance at\nlarger scales. We show here how scaling law derivation can also be used for\nmodel and dataset comparison, allowing to decide which procedure is to be\npreferred for pre-training. For the first time, full scaling laws based on\ndense measurements across a wide span of model and samples seen scales are\nderived for two important language-vision learning procedures, CLIP and MaMMUT,\nthat use either contrastive only or contrastive and captioning text generative\nloss. Ensuring sufficient prediction accuracy for held out points, we use\nderived scaling laws to compare both models, obtaining evidence for MaMMUT's\nstronger improvement with scale and better sample efficiency than standard\nCLIP. To strengthen validity of the comparison, we show scaling laws for\nvarious downstream tasks, classification, retrieval, and segmentation, and for\ndifferent open datasets, DataComp, DFN and Re-LAION, observing consistently the\nsame trends. We show that comparison can also be performed when deriving\nscaling laws with a constant learning rate schedule, reducing compute cost.\nAccurate derivation of scaling laws provides thus means to perform model and\ndataset comparison across scale spans, avoiding misleading conclusions based on\nmeasurements from single reference scales only, paving the road for systematic\ncomparison and improvement of open foundation models and datasets for their\ncreation. We release all the pre-trained models with their intermediate\ncheckpoints, including openMaMMUT-L/14, which achieves $80.3\\%$ zero-shot\nImageNet-1k accuracy, trained on 12.8B samples from DataComp-1.4B. Code for\nreproducing experiments in the paper and raw experiments data can be found at\nhttps://github.com/LAION-AI/scaling-laws-for-comparison.", "AI": {"title_translation": "开放基础语言-视觉模型和数据集鲁棒比较的缩放定律", "tldr": "本研究展示了如何使用缩放定律对开放基础语言-视觉模型（如CLIP和MaMMUT）和数据集进行鲁棒比较，发现MaMMUT在扩展性方面优于CLIP，并发布了相关模型和代码。", "motivation": "在可迁移学习研究中，通常通过缩放定律来预测大型基础模型的性能和属性。然而，现有的研究可能基于单一参考尺度进行测量，导致误导性结论。本研究的动机是为了提供一种系统且鲁棒的方法，通过缩放定律来比较模型和数据集，从而避免单一尺度测量的局限性，并指导预训练过程的选择。", "method": "本研究首次为CLIP和MaMMUT两种重要的语言-视觉学习过程推导了基于密集测量的完整缩放定律，这两种过程分别使用对比损失或结合对比和文本生成损失。为确保预测准确性，研究人员利用这些缩放定律比较了两种模型。为了增强比较的有效性，他们还展示了针对分类、检索和分割等多种下游任务以及DataComp、DFN和Re-LAION等不同开放数据集的缩放定律，并观察到一致的趋势。此外，研究还表明，在推导缩放定律时，即使使用恒定学习率调度也能进行比较，从而降低计算成本。", "result": "研究结果表明，MaMMUT在规模扩展方面表现出比标准CLIP更强的改进，并且具有更好的样本效率。在各种下游任务（分类、检索、分割）和不同开放数据集（DataComp、DFN、Re-LAION）上都观察到了一致的趋势。本研究发布了所有预训练模型及其中间检查点，其中包括openMaMMUT-L/14，该模型在DataComp-1.4B的12.8B样本上训练后，实现了80.3%的零样本ImageNet-1k准确率。", "conclusion": "准确推导缩放定律提供了一种跨尺度范围执行模型和数据集比较的方法，避免了仅基于单一参考尺度测量可能导致的误导性结论，为开放基础模型及其创建数据集的系统比较和改进铺平了道路。", "translation": "在可迁移学习的研究中，各种重要的基础模型都获得了缩放定律，以预测它们在更大规模下的属性和性能。我们在此展示，缩放定律的推导也可用于模型和数据集的比较，从而决定哪种预训练程序更优。首次针对CLIP和MaMMUT两种重要的语言-视觉学习过程推导了基于跨模型和样本规模密集测量的完整缩放定律，这两种过程分别仅使用对比损失或结合对比和文本生成损失。为了确保对保留点的足够预测精度，我们使用推导的缩放定律来比较这两种模型，获得了MaMMUT在规模扩展方面具有更强改进和比标准CLIP更好样本效率的证据。为了增强比较的有效性，我们展示了针对分类、检索和分割等各种下游任务以及DataComp、DFN和Re-LAION等不同开放数据集的缩放定律，并观察到始终一致的趋势。我们表明，在推导缩放定律时，即使使用恒定学习率调度，也可以进行比较，从而降低计算成本。因此，准确推导缩放定律提供了一种跨尺度范围执行模型和数据集比较的方法，避免了仅基于单一参考尺度测量可能导致的误导性结论，为开放基础模型及其创建数据集的系统比较和改进铺平了道路。我们发布了所有预训练模型及其中间检查点，包括openMaMMUT-L/14，它在DataComp-1.4B的12.8B样本上训练后，实现了80.3%的零样本ImageNet-1k准确率。用于复现论文实验的代码和原始实验数据可在https://github.com/LAION-AI/scaling-laws-for-comparison 找到。", "summary": "本论文提出并验证了利用缩放定律进行开放基础语言-视觉模型和数据集鲁棒比较的方法。研究首次为CLIP和MaMMUT推导了完整的缩放定律，并发现MaMMUT在规模扩展和样本效率方面优于CLIP。该方法适用于多种下游任务和数据集，并能降低计算成本。通过这种方法，可以避免单一尺度测量的局限性，实现模型和数据集的系统性比较和改进。研究还发布了预训练模型和复现代码。", "keywords": "缩放定律, 语言-视觉模型, 模型比较, 数据集比较, CLIP, MaMMUT"}}
{"id": "2506.04328", "pdf": "https://arxiv.org/pdf/2506.04328", "abs": "https://arxiv.org/abs/2506.04328", "authors": ["Akira SaiToh", "Arezoo Modiri", "Amit Sawant", "Robabeh Rahimi"], "title": "Quantum-Inspired Genetic Optimization for Patient Scheduling in Radiation Oncology", "categories": ["cs.NE", "physics.med-ph", "68W50", "I.6.3; J.3"], "comment": "15 pages, 11 figures, 10 tables", "summary": "Among the genetic algorithms generally used for optimization problems in the\nrecent decades, quantum-inspired variants are known for fast and high-fitness\nconvergence and small resource requirement. Here the application to the patient\nscheduling problem in proton therapy is reported. Quantum chromosomes are\ntailored to possess the superposed data of patient IDs and gantry statuses.\nSelection and repair strategies are also elaborated for reliable convergence to\na clinically feasible schedule although the employed model is not complex.\nClear advantage in population size is shown over the classical counterpart in\nour numerical results for both a medium-size test case and a large-size\npractical problem instance. It is, however, observed that program run time is\nrather long for the large-size practical case, which is due to the limitation\nof classical emulation and demands the forthcoming true quantum computation.\nOur results also revalidate the stability of the conventional classical genetic\nalgorithm.", "AI": {"title_translation": "量子启发式遗传优化在放射肿瘤学患者调度中的应用", "tldr": "本文将量子启发式遗传算法应用于质子治疗中的患者调度问题，该算法在种群规模上优于经典算法，但对于大型问题其运行时间较长，这表明需要真正的量子计算。", "motivation": "利用量子启发式遗传算法的快速收敛、高适应度收敛和低资源需求特性，解决质子治疗中的患者调度优化问题。", "method": "采用定制的量子染色体来表示患者ID和机架状态的叠加数据，并设计了选择和修复策略，以实现临床可行的调度。", "result": "在种群规模方面，量子启发式算法在数值结果中显示出相对于经典算法的明显优势，适用于中等规模和大型实际问题。然而，对于大型实际案例，程序运行时间相当长，这归因于经典仿真的局限性。研究结果还重新验证了传统经典遗传算法的稳定性。", "conclusion": "量子启发式遗传算法在患者调度中显示出潜力，但对于大型问题，其运行时间受限于经典模拟，需要真正的量子计算。传统经典遗传算法的稳定性得到再次验证。", "translation": "在近几十年来普遍用于优化问题的遗传算法中，量子启发式变体以其快速、高适应度收敛和较小的资源需求而闻名。本文报道了其在质子治疗患者调度问题中的应用。量子染色体经过定制，以包含患者ID和机架状态的叠加数据。还详细阐述了选择和修复策略，以可靠地收敛到临床可行的调度，尽管所采用的模型并不复杂。在中等规模的测试案例和大型实际问题实例的数值结果中，与经典对应算法相比，在种群规模方面显示出明显的优势。然而，观察到对于大型实际案例，程序运行时间相当长，这是由于经典仿真的局限性，并需要即将到来的真正量子计算。我们的结果还重新验证了传统经典遗传算法的稳定性。", "summary": "本文将量子启发式遗传优化应用于质子治疗中的患者调度问题。该方法通过定制量子染色体和精细的选择修复策略，实现了临床可行的调度。数值结果表明，量子启发式算法在种群规模上优于经典算法，但对于大型问题，其运行时间仍是挑战，表明未来需要真正的量子计算。研究也再次验证了传统经典遗传算法的稳定性。", "keywords": "量子启发式遗传算法, 患者调度, 放射肿瘤学, 质子治疗, 优化"}}
{"id": "2506.04807", "pdf": "https://arxiv.org/pdf/2506.04807", "abs": "https://arxiv.org/abs/2506.04807", "authors": ["Yuyi Zhang", "Yongxin Shi", "Peirong Zhang", "Yixin Zhao", "Zhenhua Yang", "Lianwen Jin"], "title": "MegaHan97K: A Large-Scale Dataset for Mega-Category Chinese Character Recognition with over 97K Categories", "categories": ["cs.CV"], "comment": null, "summary": "Foundational to the Chinese language and culture, Chinese characters\nencompass extraordinarily extensive and ever-expanding categories, with the\nlatest Chinese GB18030-2022 standard containing 87,887 categories. The accurate\nrecognition of this vast number of characters, termed mega-category\nrecognition, presents a formidable yet crucial challenge for cultural heritage\npreservation and digital applications. Despite significant advances in Optical\nCharacter Recognition (OCR), mega-category recognition remains unexplored due\nto the absence of comprehensive datasets, with the largest existing dataset\ncontaining merely 16,151 categories. To bridge this critical gap, we introduce\nMegaHan97K, a mega-category, large-scale dataset covering an unprecedented\n97,455 categories of Chinese characters. Our work offers three major\ncontributions: (1) MegaHan97K is the first dataset to fully support the latest\nGB18030-2022 standard, providing at least six times more categories than\nexisting datasets; (2) It effectively addresses the long-tail distribution\nproblem by providing balanced samples across all categories through its three\ndistinct subsets: handwritten, historical and synthetic subsets; (3)\nComprehensive benchmarking experiments reveal new challenges in mega-category\nscenarios, including increased storage demands, morphologically similar\ncharacter recognition, and zero-shot learning difficulties, while also\nunlocking substantial opportunities for future research. To the best of our\nknowledge, the MetaHan97K is likely the dataset with the largest classes not\nonly in the field of OCR but may also in the broader domain of pattern\nrecognition. The dataset is available at\nhttps://github.com/SCUT-DLVCLab/MegaHan97K.", "AI": {"title_translation": "MegaHan97K：一个用于超大类别汉字识别的超97K类别大规模数据集", "tldr": "MegaHan97K是一个包含超过9.7万类别汉字的大规模数据集，旨在解决现有数据集不足的问题，并推动超大类别汉字识别的研究。", "motivation": "现有的OCR数据集在超大类别汉字识别方面存在不足，最大的数据集仅包含16,151个类别，远不能满足最新GB18030-2022标准中87,887个类别的需求。准确识别如此庞大的汉字数量对文化遗产保护和数字应用至关重要。", "method": "本文介绍了MegaHan97K数据集，这是一个涵盖97,455个汉字类别的超大类别、大规模数据集。该数据集通过提供手写、历史和合成三个不同子集，有效解决了长尾分布问题，并为所有类别提供了平衡的样本。", "result": "MegaHan97K是首个完全支持最新GB18030-2022标准的汉字数据集，其类别数量是现有数据集的至少六倍。全面的基准实验揭示了超大类别场景中的新挑战，包括存储需求增加、形似字符识别困难和零样本学习挑战，同时也为未来的研究提供了巨大机会。据作者所知，MetaHan97K可能是OCR领域乃至更广泛的模式识别领域中类别数量最大的数据集。", "conclusion": "MegaHan97K数据集的引入填补了超大类别汉字识别领域数据集的空白，为未来的研究提供了重要的基础和新的挑战与机遇。", "translation": "作为中国语言和文化的基础，汉字包含极其广泛且不断扩展的类别，最新的中国GB18030-2022标准包含87,887个类别。准确识别如此庞大的汉字数量，即超大类别识别，对文化遗产保护和数字应用提出了艰巨而关键的挑战。尽管光学字符识别（OCR）取得了显著进展，但由于缺乏全面的数据集，超大类别识别仍未得到探索，现有最大的数据集仅包含16,151个类别。为了弥补这一关键空白，我们引入了MegaHan97K，一个涵盖前所未有的97,455个汉字类别的超大类别、大规模数据集。我们的工作有三个主要贡献：（1）MegaHan97K是第一个完全支持最新GB18030-2022标准的数据集，提供的类别数量是现有数据集的至少六倍；（2）它通过其手写、历史和合成三个不同子集，为所有类别提供了平衡的样本，有效解决了长尾分布问题；（3）全面的基准实验揭示了超大类别场景中的新挑战，包括存储需求增加、形似字符识别和零样本学习困难，同时也为未来的研究提供了巨大机会。据我们所知，MetaHan97K不仅可能是OCR领域，也可能是更广泛的模式识别领域中类别数量最大的数据集。该数据集可在https://github.com/SCUT-DLVCLab/MegaHan97K获取。", "summary": "本文介绍了MegaHan97K，一个包含97,455个汉字类别的超大规模数据集，旨在解决现有OCR数据集在超大类别汉字识别方面的不足。该数据集是首个支持最新GB18030-2022标准的，类别数量远超现有数据集，并通过平衡的样本分布解决了长尾问题。基准测试揭示了超大类别场景下的新挑战，如存储、形似字符识别和零样本学习，为未来的研究开辟了新方向。", "keywords": "汉字识别, 大规模数据集, 超大类别, GB18030-2022, OCR"}}
{"id": "2506.04608", "pdf": "https://arxiv.org/pdf/2506.04608", "abs": "https://arxiv.org/abs/2506.04608", "authors": ["Changsheng Sun", "Xinke Li", "Jin Song Dong"], "title": "Ignoring Directionality Leads to Compromised Graph Neural Network Explanations", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) are increasingly used in critical domains, where\nreliable explanations are vital for supporting human decision-making. However,\nthe common practice of graph symmetrization discards directional information,\nleading to significant information loss and misleading explanations. Our\nanalysis demonstrates how this practice compromises explanation fidelity.\nThrough theoretical and empirical studies, we show that preserving directional\nsemantics significantly improves explanation quality, ensuring more faithful\ninsights for human decision-makers. These findings highlight the need for\ndirection-aware GNN explainability in security-critical applications.", "AI": {"title_translation": "忽略方向性会导致图神经网络解释的妥协", "tldr": "图神经网络（GNNs）中，忽略图的方向性会导致解释质量下降，保留方向性可以显著提高解释质量，尤其在安全关键应用中需要注意。", "motivation": "图神经网络（GNNs）在关键领域被广泛使用，其可靠的解释对于支持人类决策至关重要。然而，图对称化的常见做法会丢弃方向信息，导致显著的信息丢失和误导性解释。", "method": "通过理论和实证研究，分析了图对称化如何损害解释的忠实性，并证明了保留方向语义可以显著提高解释质量。", "result": "研究表明，图对称化实践确实会损害解释的忠实性。通过保留方向语义，可以显著改善解释质量，为人类决策者提供更忠实的见解。", "conclusion": "这些研究结果强调了在安全关键应用中，图神经网络解释需要具备方向感知能力。", "translation": "图神经网络（GNNs）在关键领域日益普及，其中可靠的解释对于支持人类决策至关重要。然而，图对称化的常见做法会丢弃方向信息，导致显著的信息丢失和误导性解释。我们的分析表明这种做法如何损害解释的忠实性。通过理论和实证研究，我们证明了保留方向语义可以显著提高解释质量，确保为人类决策者提供更忠实的见解。这些发现强调了在安全关键应用中，图神经网络解释需要具备方向感知能力。", "summary": "本研究指出，图神经网络（GNNs）中常见的图对称化操作会丢弃关键的方向信息，从而损害解释的忠实性和质量。通过理论和实证分析，本文证明了保留图的方向语义能够显著提升GNN解释的质量，为决策者提供更准确的洞察。研究强调了在安全关键应用中，开发方向感知型GNN可解释性的重要性。", "keywords": "图神经网络, 可解释性, 方向性, 图对称化, 解释质量"}}
{"id": "2506.04344", "pdf": "https://arxiv.org/pdf/2506.04344", "abs": "https://arxiv.org/abs/2506.04344", "authors": ["Caojin Zhang", "Qiang Zhang", "Ke Li", "Sai Vidyaranya Nuthalapati", "Benyu Zhang", "Jason Liu", "Serena Li", "Lizhu Zhang", "Xiangjun Fan"], "title": "GEM: Empowering LLM for both Embedding Generation and Language Understanding", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large decoder-only language models (LLMs) have achieved remarkable success in\ngeneration and reasoning tasks, where they generate text responses given\ninstructions. However, many applications, e.g., retrieval augmented generation\n(RAG), still rely on separate embedding models to generate text embeddings,\nwhich can complicate the system and introduce discrepancies in understanding of\nthe query between the embedding model and LLMs. To address this limitation, we\npropose a simple self-supervised approach, Generative Embedding large language\nModel (GEM), that enables any large decoder-only LLM to generate high-quality\ntext embeddings while maintaining its original text generation and reasoning\ncapabilities. Our method inserts new special token(s) into a text body, and\ngenerates summarization embedding of the text by manipulating the attention\nmask. This method could be easily integrated into post-training or fine tuning\nstages of any existing LLMs. We demonstrate the effectiveness of our approach\nby applying it to two popular LLM families, ranging from 1B to 8B parameters,\nand evaluating the transformed models on both text embedding benchmarks (MTEB)\nand NLP benchmarks (MMLU). The results show that our proposed method\nsignificantly improves the original LLMs on MTEB while having a minimal impact\non MMLU. Our strong results indicate that our approach can empower LLMs with\nstate-of-the-art text embedding capabilities while maintaining their original\nNLP performance", "AI": {"title_translation": "GEM：赋能大型语言模型同时进行嵌入生成和语言理解", "tldr": "GEM提出了一种简单自监督方法，使大型解码器模型能够生成高质量文本嵌入，同时保持其原始文本生成和推理能力。", "motivation": "现有许多应用（如RAG）仍依赖独立的嵌入模型生成文本嵌入，这使得系统复杂化，并可能在查询理解上引入嵌入模型和大型语言模型之间的差异。", "method": "GEM通过在文本中插入新的特殊token并操纵注意力掩码来生成文本的摘要嵌入。该方法可轻松集成到现有大型语言模型的后训练或微调阶段。", "result": "该方法显著提升了原始大型语言模型在MTEB（文本嵌入基准）上的性能，同时对MMLU（NLP基准）的影响最小。", "conclusion": "GEM方法能够使大型语言模型具备最先进的文本嵌入能力，同时保持其原有的NLP性能。", "translation": "大型解码器语言模型（LLMs）在生成和推理任务中取得了显著成功，它们根据指令生成文本响应。然而，许多应用，例如检索增强生成（RAG），仍然依赖独立的嵌入模型来生成文本嵌入，这会使系统复杂化，并可能在嵌入模型和LLMs之间的查询理解上引入差异。为了解决这一限制，我们提出了一种简单的自监督方法，即生成式嵌入大型语言模型（GEM），它使任何大型解码器语言模型都能够生成高质量的文本嵌入，同时保持其原始的文本生成和推理能力。我们的方法通过在文本主体中插入新的特殊token，并通过操纵注意力掩码来生成文本的摘要嵌入。这种方法可以很容易地集成到任何现有LLMs的后训练或微调阶段。我们通过将其应用于两个流行的大型语言模型系列（参数范围从1B到8B）来证明我们方法的有效性，并在文本嵌入基准（MTEB）和NLP基准（MMLU）上评估了转换后的模型。结果表明，我们提出的方法显著改进了原始LLMs在MTEB上的表现，同时对MMLU的影响最小。我们强有力的结果表明，我们的方法可以使LLMs具备最先进的文本嵌入能力，同时保持其原始的NLP性能。", "summary": "本文提出了一种名为GEM（Generative Embedding large language Model）的简单自监督方法，旨在解决大型解码器模型在文本嵌入生成方面对独立模型的依赖问题。GEM通过在文本中插入特殊token并调整注意力掩码来生成高质量的文本摘要嵌入，同时不影响其原有的文本生成和推理能力。实验结果表明，该方法显著提升了大型语言模型在文本嵌入任务上的表现，同时对自然语言处理任务的影响微乎其微，证明了其在赋能大型语言模型方面具有强大潜力。", "keywords": "大型语言模型, 文本嵌入, 自监督学习, RAG, 注意力掩码"}}
{"id": "2506.04817", "pdf": "https://arxiv.org/pdf/2506.04817", "abs": "https://arxiv.org/abs/2506.04817", "authors": ["Gabriele Magrini. Federico Becattini", "Luca Cultrera", "Lorenzo Berlincioni", "Pietro Pala", "Alberto Del Bimbo"], "title": "Spike-TBR: a Noise Resilient Neuromorphic Event Representation", "categories": ["cs.CV"], "comment": null, "summary": "Event cameras offer significant advantages over traditional frame-based\nsensors, including higher temporal resolution, lower latency and dynamic range.\nHowever, efficiently converting event streams into formats compatible with\nstandard computer vision pipelines remains a challenging problem, particularly\nin the presence of noise. In this paper, we propose Spike-TBR, a novel\nevent-based encoding strategy based on Temporal Binary Representation (TBR),\naddressing its vulnerability to noise by integrating spiking neurons. Spike-TBR\ncombines the frame-based advantages of TBR with the noise-filtering\ncapabilities of spiking neural networks, creating a more robust representation\nof event streams. We evaluate four variants of Spike-TBR, each using different\nspiking neurons, across multiple datasets, demonstrating superior performance\nin noise-affected scenarios while improving the results on clean data. Our\nmethod bridges the gap between spike-based and frame-based processing, offering\na simple noise-resilient solution for event-driven vision applications.", "AI": {"title_translation": "Spike-TBR：一种抗噪声的神经形态事件表示", "tldr": "Spike-TBR是一种结合了TBR和脉冲神经网络的事件编码策略，能有效抵抗噪声并提升事件流处理性能。", "motivation": "事件相机虽然有优势，但将事件流转换为标准计算机视觉管道兼容的格式，尤其是在存在噪声的情况下，仍然是一个挑战。", "method": "本文提出了Spike-TBR，一种基于时间二进制表示（TBR）的新型事件编码策略，通过集成脉冲神经元解决了TBR对噪声的脆弱性。Spike-TBR结合了TBR的帧基优势和脉冲神经网络的噪声过滤能力。", "result": "作者评估了Spike-TBR的四种变体，每种都使用不同的脉冲神经元，在多个数据集上进行了测试，结果表明在受噪声影响的场景中表现优异，同时改善了干净数据上的结果。", "conclusion": "Spike-TBR弥合了基于脉冲和基于帧的处理之间的差距，为事件驱动的视觉应用提供了一个简单的抗噪声解决方案。", "translation": "事件相机相较于传统基于帧的传感器具有显著优势，包括更高的时间分辨率、更低的延迟和动态范围。然而，将事件流高效转换为与标准计算机视觉管道兼容的格式仍然是一个具有挑战性的问题，尤其是在存在噪声的情况下。在本文中，我们提出了Spike-TBR，一种基于时间二进制表示（TBR）的新型事件编码策略，通过集成脉冲神经元解决了其对噪声的脆弱性。Spike-TBR结合了TBR的帧基优势和脉冲神经网络的噪声过滤能力，创建了更鲁棒的事件流表示。我们评估了Spike-TBR的四种变体，每种都使用不同的脉冲神经元，并在多个数据集上进行了测试，结果表明在受噪声影响的场景中表现优异，同时改善了干净数据上的结果。我们的方法弥合了基于脉冲和基于帧的处理之间的差距，为事件驱动的视觉应用提供了一个简单的抗噪声解决方案。", "summary": "该论文提出了一种名为Spike-TBR的新型神经形态事件表示方法，旨在解决事件相机数据在噪声环境下的处理挑战。Spike-TBR结合了时间二进制表示（TBR）的帧基优势和脉冲神经网络的噪声过滤能力，从而创建了一个更鲁棒的事件流表示。实验证明，Spike-TBR在噪声场景下性能优越，并能改善干净数据上的结果，为事件驱动的视觉应用提供了有效的抗噪声方案。", "keywords": "事件相机, 神经形态, 事件表示, 噪声鲁棒性, 脉冲神经网络"}}
{"id": "2506.04609", "pdf": "https://arxiv.org/pdf/2506.04609", "abs": "https://arxiv.org/abs/2506.04609", "authors": ["Cong Geng", "Jia Wang", "Li Chen", "Zhiyong Gao", "Jes Frellsen", "Søren Hauberg"], "title": "Exploring bidirectional bounds for minimax-training of Energy-based models", "categories": ["cs.LG", "cs.CV"], "comment": "accepted to IJCV", "summary": "Energy-based models (EBMs) estimate unnormalized densities in an elegant\nframework, but they are generally difficult to train. Recent work has linked\nEBMs to generative adversarial networks, by noting that they can be trained\nthrough a minimax game using a variational lower bound. To avoid the\ninstabilities caused by minimizing a lower bound, we propose to instead work\nwith bidirectional bounds, meaning that we maximize a lower bound and minimize\nan upper bound when training the EBM. We investigate four different bounds on\nthe log-likelihood derived from different perspectives. We derive lower bounds\nbased on the singular values of the generator Jacobian and on mutual\ninformation. To upper bound the negative log-likelihood, we consider a gradient\npenalty-like bound, as well as one based on diffusion processes. In all cases,\nwe provide algorithms for evaluating the bounds. We compare the different\nbounds to investigate, the pros and cons of the different approaches. Finally,\nwe demonstrate that the use of bidirectional bounds stabilizes EBM training and\nyields high-quality density estimation and sample generation.", "AI": {"title_translation": "探索能量模型最小最大训练的双向界限", "tldr": "本文提出使用双向界限（最大化下界和最小化上界）来稳定能量模型的训练，以解决传统训练中最小化下界导致的不稳定性，并展示了其在密度估计和样本生成上的效果。", "motivation": "能量模型（EBMs）虽然在估计非归一化密度方面很优雅，但训练困难。现有的通过变分下界进行最小最大训练的方法存在不稳定性。", "method": "提出使用双向界限来训练EBM，即最大化一个下界并最小化一个上界。研究了四种不同的对数似然界限：基于生成器雅可比矩阵奇异值和互信息的下界；以及类似梯度惩罚和基于扩散过程的上界。提供了评估这些界限的算法。", "result": "使用双向界限稳定了EBM的训练，并产生了高质量的密度估计和样本生成。", "conclusion": "双向界限方法能够有效稳定能量模型的训练，并提高密度估计和样本生成质量。", "translation": "能量模型（EBMs）以优雅的框架估计未归一化密度，但通常难以训练。最近的工作通过指出EBMs可以通过使用变分下界进行最小最大博弈来训练，从而将EBMs与生成对抗网络联系起来。为了避免最小化下界引起的不稳定性，我们建议转而使用双向界限，这意味着在训练EBM时，我们最大化一个下界并最小化一个上界。我们从不同角度推导了对数似然的四种不同界限。我们推导了基于生成器雅可比矩阵奇异值和互信息的下界。为了上界负对数似然，我们考虑了类似梯度惩罚的界限以及基于扩散过程的界限。在所有情况下，我们都提供了评估这些界限的算法。我们比较了不同的界限以研究不同方法的优缺点。最后，我们证明了使用双向界限可以稳定EBM训练，并产生高质量的密度估计和样本生成。", "summary": "能量模型（EBMs）的训练是一个挑战。为了解决现有基于变分下界的最小最大训练方法的不稳定性，本文提出了一种双向界限训练方法，即同时最大化下界和最小化上界。研究了四种不同的对数似然界限，包括基于生成器雅可比矩阵奇异值、互信息、梯度惩罚和扩散过程的界限，并提供了评估算法。实验结果表明，该方法能够稳定EBM训练，并实现高质量的密度估计和样本生成。", "keywords": "能量模型, 双向界限, 最小最大训练, 密度估计, 样本生成"}}
{"id": "2506.04823", "pdf": "https://arxiv.org/pdf/2506.04823", "abs": "https://arxiv.org/abs/2506.04823", "authors": ["Svetlana Pavlitska", "Jamie Robb", "Nikolai Polley", "Melih Yazgan", "J. Marius Zöllner"], "title": "Fool the Stoplight: Realistic Adversarial Patch Attacks on Traffic Light Detectors", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted for publication at IV 2025", "summary": "Realistic adversarial attacks on various camera-based perception tasks of\nautonomous vehicles have been successfully demonstrated so far. However, only a\nfew works considered attacks on traffic light detectors. This work shows how\nCNNs for traffic light detection can be attacked with printed patches. We\npropose a threat model, where each instance of a traffic light is attacked with\na patch placed under it, and describe a training strategy. We demonstrate\nsuccessful adversarial patch attacks in universal settings. Our experiments\nshow realistic targeted red-to-green label-flipping attacks and attacks on\npictogram classification. Finally, we perform a real-world evaluation with\nprinted patches and demonstrate attacks in the lab settings with a mobile\ntraffic light for construction sites and in a test area with stationary traffic\nlights. Our code is available at\nhttps://github.com/KASTEL-MobilityLab/attacks-on-traffic-light-detection.", "AI": {"title_translation": "欺骗红绿灯：针对交通灯检测器的真实对抗补丁攻击", "tldr": "本文展示了如何通过物理补丁攻击交通灯检测器，实现红灯变绿灯等欺骗效果，并在真实世界中进行了验证。", "motivation": "现有针对自动驾驶车辆感知任务的对抗性攻击研究较多，但很少有工作关注交通灯检测器，这可能对自动驾驶系统造成安全隐患。", "method": "提出了一种威胁模型，即在每个交通灯下方放置一个打印的对抗性补丁。通过训练策略，在通用设置下对基于CNN的交通灯检测器进行攻击。", "result": "成功实现了通用设置下的对抗性补丁攻击，包括现实的红灯变绿灯的定向标签翻转攻击和对交通灯象形图分类的攻击。在实验室和真实测试区域使用打印补丁进行了真实世界评估，证明了攻击的有效性。", "conclusion": "打印的对抗性补丁可以有效攻击交通灯检测器，对自动驾驶系统的安全性构成威胁，这表明需要更强大的防御机制。", "translation": "到目前为止，针对自动驾驶车辆各种基于摄像头的感知任务的真实对抗性攻击已成功展示。然而，很少有工作考虑对交通灯检测器的攻击。这项工作展示了如何使用打印补丁攻击用于交通灯检测的CNN。我们提出了一种威胁模型，其中每个交通灯实例都通过放置在其下方的补丁进行攻击，并描述了一种训练策略。我们展示了在通用设置下成功的对抗性补丁攻击。我们的实验展示了现实的定向红灯变绿灯标签翻转攻击以及对交通灯象形图分类的攻击。最后，我们使用打印补丁进行了真实世界评估，并在实验室设置中使用用于施工现场的移动交通灯以及在测试区域使用固定交通灯展示了攻击。我们的代码可在 https://github.com/KASTEL-MobilityLab/attacks-on-traffic-light-detection 获取。", "summary": "本研究探讨了针对交通灯检测器的现实对抗性补丁攻击。通过提出一种威胁模型和训练策略，成功地利用打印补丁攻击了基于CNN的交通灯检测器，实现了从红灯到绿灯的标签翻转以及对交通灯象形图的错误分类。实验在通用设置下进行了验证，并在实验室和真实场景中展示了攻击的有效性。", "keywords": "对抗性攻击, 交通灯检测, 补丁攻击, 自动驾驶, 深度学习"}}
{"id": "2506.04632", "pdf": "https://arxiv.org/pdf/2506.04632", "abs": "https://arxiv.org/abs/2506.04632", "authors": ["Guruprerana Shabadi", "Rajeev Alur"], "title": "Composing Agents to Minimize Worst-case Risk", "categories": ["cs.LG"], "comment": "17 pages, 4 figures", "summary": "From software development to robot control, modern agentic systems decompose\ncomplex objectives into a sequence of subtasks and choose a set of specialized\nAI agents to complete them. We formalize an agentic workflow as a directed\nacyclic graph, called an agent graph, where edges represent AI agents and paths\ncorrespond to feasible compositions of agents. When deploying these systems in\nthe real world, we need to choose compositions of agents that not only maximize\nthe task success, but also minimize risk where the risk captures requirements\nlike safety, fairness, and privacy. This additionally requires carefully\nanalyzing the low-probability (tail) behaviors of compositions of agents. In\nthis work, we consider worst-case risk minimization over the set of feasible\nagent compositions. We define worst-case risk as the tail quantile -- also\nknown as value-at-risk -- of the loss distribution of the agent composition\nwhere the loss quantifies the risk associated with agent behaviors. We\nintroduce an efficient algorithm that traverses the agent graph and finds a\nnear-optimal composition of agents by approximating the value-at-risk via a\nunion bound and dynamic programming. Furthermore, we prove that the\napproximation is near-optimal asymptotically for a broad class of practical\nloss functions. To evaluate our framework, we consider a suite of video\ngame-like control benchmarks that require composing several agents trained with\nreinforcement learning and demonstrate our algorithm's effectiveness in\napproximating the value-at-risk and identifying the optimal agent composition.", "AI": {"title_translation": "组合智能体以最小化最坏情况风险", "tldr": "本文提出了一种在智能体图中组合AI智能体以最小化最坏情况风险（通过损失分布的尾部分位数定义）的方法，并提供了一种通过联合界和动态规划逼近风险的有效算法，实验证明了其在视频游戏控制基准上的有效性。", "motivation": "现代智能体系统在分解复杂目标时，需要选择专业的AI智能体来完成子任务。在实际部署中，除了最大化任务成功率，还需要最小化风险（如安全性、公平性和隐私性），这需要仔细分析智能体组合的低概率（尾部）行为。", "method": "将智能体工作流形式化为有向无环图（智能体图），边代表AI智能体，路径对应可行的智能体组合。定义最坏情况风险为损失分布的尾部量化（即风险价值）。提出了一种高效算法，通过联合界和动态规划逼近风险价值，遍历智能体图并找到近乎最优的智能体组合。证明了该近似对于一类广泛的实际损失函数是渐近近乎最优的。", "result": "在视频游戏类控制基准上评估了该框架，这些基准需要组合多个通过强化学习训练的智能体。实验证明了所提算法在逼近风险价值和识别最优智能体组合方面的有效性。", "conclusion": "该研究提出了一种有效的方法来最小化智能体组合的最坏情况风险，并通过理论分析和实验验证了其有效性，这对于在实际世界中部署安全、公平和私密的智能体系统至关重要。", "translation": "从软件开发到机器人控制，现代智能体系统将复杂目标分解为一系列子任务，并选择一组专业AI智能体来完成它们。我们将智能体工作流形式化为有向无环图，称为智能体图，其中边表示AI智能体，路径对应可行的智能体组合。在现实世界中部署这些系统时，我们需要选择不仅能最大化任务成功率，还能最小化风险的智能体组合，其中风险涵盖了安全性、公平性和隐私性等要求。这还需要仔细分析智能体组合的低概率（尾部）行为。在这项工作中，我们考虑在可行智能体组合集合上最小化最坏情况风险。我们将最坏情况风险定义为损失分布的尾部量化——也称为风险价值——其中损失量化了与智能体行为相关的风险。我们引入了一种高效算法，该算法遍历智能体图，通过联合界和动态规划逼近风险价值，从而找到近乎最优的智能体组合。此外，我们证明了该近似对于一类广泛的实际损失函数是渐近近乎最优的。为了评估我们的框架，我们考虑了一套视频游戏类控制基准，这些基准需要组合多个通过强化学习训练的智能体，并证明了我们算法在逼近风险价值和识别最优智能体组合方面的有效性。", "summary": "本研究关注在智能体系统中，如何通过组合AI智能体来最小化最坏情况风险。作者将智能体工作流建模为有向无环图，并定义最坏情况风险为损失分布的尾部量化（风险价值）。为解决此问题，提出了一种高效算法，该算法利用联合界和动态规划在智能体图中寻找近乎最优的智能体组合，以逼近风险价值。理论上，该近似被证明对于广泛的损失函数是渐近近乎最优的。通过在视频游戏控制基准上的实验，验证了所提算法在逼近风险价值和识别最优智能体组合方面的有效性。", "keywords": "智能体组合, 最坏情况风险, 风险价值, 动态规划, 智能体图"}}
{"id": "2506.04830", "pdf": "https://arxiv.org/pdf/2506.04830", "abs": "https://arxiv.org/abs/2506.04830", "authors": ["Shuo Cao", "Yihao Liu", "Xiaohui Li. Yuanting Gao. Yu Zhou", "Chao Dong"], "title": "DualX-VSR: Dual Axial Spatial$\\times$Temporal Transformer for Real-World Video Super-Resolution without Motion Compensation", "categories": ["cs.CV"], "comment": "15 pages, 9 figures", "summary": "Transformer-based models like ViViT and TimeSformer have advanced video\nunderstanding by effectively modeling spatiotemporal dependencies. Recent video\ngeneration models, such as Sora and Vidu, further highlight the power of\ntransformers in long-range feature extraction and holistic spatiotemporal\nmodeling. However, directly applying these models to real-world video\nsuper-resolution (VSR) is challenging, as VSR demands pixel-level precision,\nwhich can be compromised by tokenization and sequential attention mechanisms.\nWhile recent transformer-based VSR models attempt to address these issues using\nsmaller patches and local attention, they still face limitations such as\nrestricted receptive fields and dependence on optical flow-based alignment,\nwhich can introduce inaccuracies in real-world settings. To overcome these\nissues, we propose Dual Axial Spatial$\\times$Temporal Transformer for\nReal-World Video Super-Resolution (DualX-VSR), which introduces a novel dual\naxial spatial$\\times$temporal attention mechanism that integrates spatial and\ntemporal information along orthogonal directions. DualX-VSR eliminates the need\nfor motion compensation, offering a simplified structure that provides a\ncohesive representation of spatiotemporal information. As a result, DualX-VSR\nachieves high fidelity and superior performance in real-world VSR task.", "AI": {"title_translation": "DualX-VSR: 无运动补偿的双轴空间×时间Transformer用于真实世界视频超分辨率", "tldr": "DualX-VSR提出了一种新型双轴空间×时间注意力机制，用于真实世界视频超分辨率，无需运动补偿，实现了高保真和卓越性能。", "motivation": "现有的Transformer模型直接应用于真实世界视频超分辨率（VSR）面临挑战，因为VSR需要像素级精度，而Tokenization和顺序注意力机制可能会损害这一点。同时，现有的基于Transformer的VSR模型仍受限于感受野和对光流对齐的依赖，这在真实世界设置中可能引入不准确性。", "method": "本文提出了一种名为DualX-VSR的双轴空间×时间Transformer，它引入了一种新颖的双轴空间×时间注意力机制，该机制沿正交方向整合空间和时间信息。DualX-VSR消除了运动补偿的需求，提供了一个简化的结构，从而提供了时空信息的内聚表示。", "result": "DualX-VSR在真实世界VSR任务中实现了高保真和卓越的性能。", "conclusion": "DualX-VSR通过其新颖的双轴空间×时间注意力机制，成功解决了真实世界视频超分辨率中现有Transformer模型的局限性，特别是在无需运动补偿的情况下实现了高精度和优异性能。", "translation": "基于Transformer的模型，如ViViT和TimeSformer，通过有效建模时空依赖性，推动了视频理解的发展。最近的视频生成模型，如Sora和Vidu，进一步突出了Transformer在长距离特征提取和整体时空建模方面的强大能力。然而，将这些模型直接应用于真实世界视频超分辨率（VSR）具有挑战性，因为VSR要求像素级精度，而Tokenization和顺序注意力机制可能会损害这一点。尽管最近基于Transformer的VSR模型试图通过使用更小的补丁和局部注意力来解决这些问题，但它们仍然面临局限性，例如受限的感受野和对基于光流对齐的依赖，这在真实世界环境中可能引入不准确性。为了克服这些问题，我们提出了用于真实世界视频超分辨率的双轴空间×时间Transformer（DualX-VSR），它引入了一种新颖的双轴空间×时间注意力机制，该机制沿正交方向整合空间和时间信息。DualX-VSR消除了运动补偿的需求，提供了一个简化的结构，从而提供了时空信息的内聚表示。因此，DualX-VSR在真实世界VSR任务中实现了高保真和卓越性能。", "summary": "本研究提出了一种名为DualX-VSR的新型Transformer模型，用于真实世界视频超分辨率。该模型通过引入双轴空间×时间注意力机制，有效整合空间和时间信息，并消除了传统方法中对运动补偿的依赖，从而解决了现有Transformer模型在像素级精度和光流对齐方面的挑战。实验结果表明，DualX-VSR在真实世界VSR任务中展现出高保真度和卓越性能。", "keywords": "视频超分辨率, Transformer, 双轴注意力, 无运动补偿, 真实世界VSR"}}
{"id": "2506.04303", "pdf": "https://arxiv.org/pdf/2506.04303", "abs": "https://arxiv.org/abs/2506.04303", "authors": ["Zhizheng Wang", "Chi-Ping Day", "Chih-Hsuan Wei", "Qiao Jin", "Robert Leaman", "Yifan Yang", "Shubo Tian", "Aodong Qiu", "Yin Fang", "Qingqing Zhu", "Xinghua Lu", "Zhiyong Lu"], "title": "Knowledge-guided Contextual Gene Set Analysis Using Large Language Models", "categories": ["q-bio.GN", "cs.AI", "cs.LG"], "comment": "56 pages, 9 figures, 1 table", "summary": "Gene set analysis (GSA) is a foundational approach for interpreting genomic\ndata of diseases by linking genes to biological processes. However,\nconventional GSA methods overlook clinical context of the analyses, often\ngenerating long lists of enriched pathways with redundant, nonspecific, or\nirrelevant results. Interpreting these requires extensive, ad-hoc manual\neffort, reducing both reliability and reproducibility. To address this\nlimitation, we introduce cGSA, a novel AI-driven framework that enhances GSA by\nincorporating context-aware pathway prioritization. cGSA integrates gene\ncluster detection, enrichment analysis, and large language models to identify\npathways that are not only statistically significant but also biologically\nmeaningful. Benchmarking on 102 manually curated gene sets across 19 diseases\nand ten disease-related biological mechanisms shows that cGSA outperforms\nbaseline methods by over 30%, with expert validation confirming its increased\nprecision and interpretability. Two independent case studies in melanoma and\nbreast cancer further demonstrate its potential to uncover context-specific\ninsights and support targeted hypothesis generation.", "AI": {"title_translation": "知识引导的基于大型语言模型的上下文基因集分析", "tldr": "cGSA是一种新型AI框架，通过整合基因聚类、富集分析和大型语言模型，实现了上下文感知的通路优先排序，显著提高了基因集分析的准确性和可解释性。", "motivation": "传统的基因集分析（GSA）方法忽略了临床背景，常产生冗余、非特异或不相关的富集通路列表，导致解释困难，降低了可靠性和可重复性。", "method": "cGSA是一个AI驱动的框架，通过整合基因簇检测、富集分析和大型语言模型来增强GSA，从而识别出具有统计显著性且生物学意义的通路，实现上下文感知的通路优先排序。", "result": "在19种疾病和10种疾病相关生物机制的102个手动筛选基因集上的基准测试显示，cGSA的性能比基线方法提高了30%以上。专家验证证实其精度和可解释性增加。在黑色素瘤和乳腺癌的两个独立案例研究中，进一步证明了其发现上下文特定见解和支持靶向假设生成的潜力。", "conclusion": "cGSA通过整合上下文信息和大型语言模型，显著提高了基因集分析的精度和可解释性，克服了传统GSA方法的局限性，为疾病基因组数据的解释提供了更可靠和有意义的工具。", "translation": "基因集分析（GSA）是解释疾病基因组数据，通过将基因与生物过程联系起来的基础方法。然而，传统的GSA方法忽略了分析的临床背景，常常生成冗余、非特异性或不相关的富集通路长列表。解释这些结果需要大量临时的手动工作，降低了可靠性和可重复性。为了解决这一局限性，我们引入了cGSA，一个新颖的AI驱动框架，通过整合上下文感知的通路优先排序来增强GSA。cGSA整合了基因簇检测、富集分析和大型语言模型，以识别不仅具有统计显著性而且具有生物学意义的通路。在19种疾病和10种疾病相关生物机制的102个手动筛选基因集上的基准测试表明，cGSA的性能优于基线方法30%以上，专家验证证实其精度和可解释性增加。黑色素瘤和乳腺癌的两个独立案例研究进一步证明了其发现上下文特定见解和支持靶向假设生成的潜力。", "summary": "本研究提出了一种名为cGSA的新型AI驱动框架，旨在解决传统基因集分析（GSA）方法忽视临床背景导致结果冗余和解释困难的问题。cGSA通过结合基因簇检测、富集分析和大型语言模型，实现了上下文感知的通路优先排序，从而识别出统计显著且生物学有意义的通路。在多项疾病基因集上的基准测试显示，cGSA的性能优于现有方法30%以上，并通过专家验证和案例研究证实了其高精度和可解释性，为疾病基因组数据提供了更深入的见解。", "keywords": "基因集分析, 大型语言模型, 上下文感知, 疾病基因组学, 通路优先排序"}}
{"id": "2506.04837", "pdf": "https://arxiv.org/pdf/2506.04837", "abs": "https://arxiv.org/abs/2506.04837", "authors": ["Kunshen Zhang"], "title": "OpenMaskDINO3D : Reasoning 3D Segmentation via Large Language Model", "categories": ["cs.CV"], "comment": "Project Page: https://github.com/Zhangkuns/OpenMaskDINO3D", "summary": "Although perception systems have made remarkable advancements in recent\nyears, particularly in 2D reasoning segmentation, these systems still rely on\nexplicit human instruction or pre-defined categories to identify target objects\nbefore executing visual recognition tasks. Such systems have matured\nsignificantly, demonstrating the ability to reason and comprehend implicit user\nintentions in two-dimensional contexts, producing accurate segmentation masks\nbased on complex and implicit query text. However, a comparable framework and\nstructure for 3D reasoning segmentation remain absent. This paper introduces\nOpenMaskDINO3D, a LLM designed for comprehensive 3D understanding and\nsegmentation. OpenMaskDINO3D processes point cloud data and text prompts to\nproduce instance segmentation masks, excelling in many 3D tasks. By introducing\na SEG token and object identifier, we achieve high-precision 3D segmentation\nmask generation, enabling the model to directly produce accurate point cloud\nsegmentation results from natural language instructions. Experimental results\non large-scale ScanNet datasets validate the effectiveness of our\nOpenMaskDINO3D across various tasks.", "AI": {"title_translation": "OpenMaskDINO3D：基于大型语言模型的3D推理分割", "tldr": "OpenMaskDINO3D是一个利用大型语言模型进行3D理解和分割的框架，能根据自然语言指令生成高精度3D实例分割掩码。", "motivation": "尽管2D推理分割系统取得了显著进展，但3D推理分割仍缺乏类似的框架和结构。现有系统依赖明确的人工指令或预定义类别来识别目标对象，而无法像2D系统那样理解复杂的隐含用户意图。", "method": "本文引入了OpenMaskDINO3D，一个专为3D理解和分割设计的大型语言模型（LLM）。它处理点云数据和文本提示以生成实例分割掩码。通过引入SEG token和对象标识符，OpenMaskDINO3D能够直接从自然语言指令生成高精度的点云分割结果。", "result": "在大型ScanNet数据集上的实验结果验证了OpenMaskDINO3D在各种3D任务中的有效性。", "conclusion": "OpenMaskDINO3D成功弥补了3D推理分割领域的空白，实现了基于自然语言指令的高精度3D分割，并在实际数据集中展现了其有效性。", "translation": "尽管感知系统近年来取得了显著进步，特别是在2D推理分割方面，但这些系统在执行视觉识别任务之前仍然依赖于明确的人工指令或预定义类别来识别目标对象。此类系统已显著成熟，展示了在二维环境中推理和理解隐含用户意图的能力，并根据复杂和隐含的查询文本生成准确的分割掩码。然而，3D推理分割方面仍然缺乏类似的框架和结构。本文介绍了OpenMaskDINO3D，一个专为全面3D理解和分割设计的大型语言模型。OpenMaskDINO3D处理点云数据和文本提示以生成实例分割掩码，在许多3D任务中表现出色。通过引入SEG token和对象标识符，我们实现了高精度的3D分割掩码生成，使模型能够直接根据自然语言指令生成准确的点云分割结果。在大型ScanNet数据集上的实验结果验证了OpenMaskDINO3D在各种任务中的有效性。", "summary": "OpenMaskDINO3D是一个创新的大型语言模型框架，旨在解决3D推理分割领域缺乏类似2D系统理解复杂隐含用户意图的问题。该模型通过处理点云数据和文本提示，并引入SEG token和对象标识符，能够根据自然语言指令直接生成高精度的3D实例分割掩码。在大型ScanNet数据集上的实验结果验证了OpenMaskDINO3D在多种3D任务上的有效性。", "keywords": "3D分割, 大型语言模型, 点云, 实例分割, 自然语言处理"}}
{"id": "2506.04650", "pdf": "https://arxiv.org/pdf/2506.04650", "abs": "https://arxiv.org/abs/2506.04650", "authors": ["Zesheng Ye", "Chengyi Cai", "Ruijiang Dong", "Jianzhong Qi", "Lei Feng", "Pin-Yu Chen", "Feng Liu"], "title": "Neural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction", "categories": ["cs.LG"], "comment": null, "summary": "As large-scale pre-trained foundation models continue to expand in size and\ncapability, efficiently adapting them to specific downstream tasks has become\nincreasingly critical. Despite substantial progress, existing adaptation\napproaches have evolved largely in isolation, without a clear understanding of\ntheir interrelationships. This survey introduces neural network\nreprogrammability as a unifying framework that bridges mainstream model\nadaptation techniques--model reprogramming, prompt tuning, and prompt\ninstruction--previously fragmented research areas yet converges on a shared\nprinciple: repurposing a pre-trained model by manipulating information at the\ninterfaces while keeping the model parameters frozen. These methods exploit\nneural networks' sensitivity to manipulation on different interfaces, be it\nthrough perturbing inputs, inserting tokens into intermediate layers, or\nproviding task-specific examples in context, to redirect model behaviors\ntowards desired outcomes. We then present a taxonomy that categorizes such\ninformation manipulation-based adaptation approaches across four key\ndimensions: manipulation format (fixed or learnable), location (interfaces\nwhere manipulations occur), operator (how they are applied), and output\nalignment requirement (post-processing needed to align outputs with downstream\ntasks). Notably, this framework applies consistently across data modalities,\nindependent of specific model architectures. Moreover, viewing established\ntechniques like in-context learning and chain-of-thought prompting through this\nlens reveals both their theoretical connections and practical distinctions. We\nfurther analyze remaining technical challenges and ethical considerations,\npositioning neural network reprogrammability as a fundamental paradigm for\nefficient model adaptation. We lastly identify promising research directions\nemerging from this integrative viewpoint.", "AI": {"title_translation": "神经网络可重编程性：模型重编程、提示调优和提示指令的统一主题", "tldr": "本综述提出了神经网络可重编程性作为统一框架，整合了模型重编程、提示调优和提示指令等主流模型适应技术，它们都通过在接口处操作信息来重用预训练模型，同时保持模型参数冻结。", "motivation": "随着大规模预训练基础模型规模和能力的不断扩展，如何有效地将它们适应于特定的下游任务变得越来越重要。现有的适应方法大多是孤立发展的，缺乏对其相互关系的清晰理解。", "method": "本综述引入了神经网络可重编程性作为统一框架，它将模型重编程、提示调优和提示指令等主流模型适应技术联系起来。文章提出了一个分类法，从操作格式、位置、操作符和输出对齐要求四个关键维度对基于信息操作的适应方法进行分类。", "result": "该框架统一了之前分散的研究领域，揭示了不同数据模态和模型架构下这些方法的通用性。通过该视角，可以理解上下文学习和思维链提示的理论联系和实践区别。", "conclusion": "神经网络可重编程性是高效模型适应的基本范式，仍存在技术挑战和伦理考量，并由此视角识别出有前景的研究方向。", "translation": "随着大规模预训练基础模型规模和能力的不断扩展，如何有效地将它们适应于特定的下游任务变得越来越重要。尽管取得了实质性进展，但现有的适应方法大多是孤立发展的，对其相互关系缺乏清晰的理解。本综述引入了神经网络可重编程性作为统一框架，它将主流模型适应技术——模型重编程、提示调优和提示指令——联系起来，这些技术以前是分散的研究领域，但现在收敛于一个共同的原则：通过在接口处操作信息来重用预训练模型，同时保持模型参数冻结。这些方法利用神经网络对不同接口操作的敏感性，无论是通过扰动输入、在中间层插入token，还是在上下文中提供特定任务的示例，以将模型行为重定向到期望的结果。然后，我们提出了一个分类法，从四个关键维度对基于信息操作的适应方法进行分类：操作格式（固定或可学习）、位置（发生操作的接口）、操作符（如何应用它们）和输出对齐要求（将输出与下游任务对齐所需的后处理）。值得注意的是，该框架始终适用于不同的数据模态，与特定的模型架构无关。此外，通过这个视角审视上下文学习和思维链提示等既定技术，揭示了它们的理论联系和实际区别。我们进一步分析了剩余的技术挑战和伦理考量，将神经网络可重编程性定位为高效模型适应的基本范式。最后，我们从这一整合视角确定了有前景的研究方向。", "summary": "本综述提出了“神经网络可重编程性”作为统一框架，旨在整合模型重编程、提示调优和提示指令等主流模型适应技术。这些技术通过在模型接口处操作信息来重用冻结的预训练模型。文章提出了一个分类法，从操作格式、位置、操作符和输出对齐要求四个维度对这些方法进行分类，并指出该框架适用于不同数据模态和模型架构。此外，它还揭示了上下文学习和思维链提示的联系与区别，并分析了未来的挑战和研究方向。", "keywords": "神经网络可重编程性, 模型适应, 提示调优, 模型重编程, 提示指令"}}
{"id": "2506.04869", "pdf": "https://arxiv.org/pdf/2506.04869", "abs": "https://arxiv.org/abs/2506.04869", "authors": ["Vladislav Trifonov", "Ivan Oseledets", "Ekaterina Muravleva"], "title": "Geological Field Restoration through the Lens of Image Inpainting", "categories": ["cs.CV"], "comment": null, "summary": "We present a new viewpoint on a reconstructing multidimensional geological\nfields from sparse observations. Drawing inspiration from deterministic image\ninpainting techniques, we model a partially observed spatial field as a\nmultidimensional tensor and recover missing values by enforcing a global\nlow-rank structure. Our approach combines ideas from tensor completion and\ngeostatistics, providing a robust optimization framework. Experiments on\nsynthetic geological fields demonstrate that used tensor completion method\nsignificant improvements in reconstruction accuracy over ordinary kriging for\nvarious percent of observed data.", "AI": {"title_translation": "通过图像修复视角进行地质场恢复", "tldr": "本文提出了一种结合张量补全和地统计学的新方法，通过强制全局低秩结构来恢复稀疏观测中的多维地质场，实验表明其重建精度优于普通克里金法。", "motivation": "从稀疏观测中重建多维地质场是一个挑战，本文提出了一种新的视角和方法来解决这个问题。", "method": "本文从确定性图像修复技术中获得灵感，将部分观测到的空间场建模为多维张量，并通过强制全局低秩结构来恢复缺失值。该方法结合了张量补全和地统计学的思想，提供了一个鲁棒的优化框架。", "result": "在合成地质场上的实验表明，所使用的张量补全方法在不同观测数据百分比下，重建精度比普通克里金法有显著提高。", "conclusion": "Not mentioned in abstract", "translation": "我们提出了一种从稀疏观测中重建多维地质场的新观点。借鉴确定性图像修复技术，我们将部分观测到的空间场建模为多维张量，并通过强制全局低秩结构来恢复缺失值。我们的方法结合了张量补全和地统计学的思想，提供了一个鲁棒的优化框架。在合成地质场上的实验表明，所使用的张量补全方法在不同观测数据百分比下，重建精度比普通克里金法有显著提高。", "summary": "本文提出了一种新颖的方法，将多维地质场从稀疏观测中恢复，该方法借鉴了图像修复技术，将地质场建模为多维张量并通过强制低秩结构来补全缺失数据。该方法结合了张量补全和地统计学的优点，并在合成数据上表现出优于传统克里金法的重建精度。", "keywords": "地质场恢复, 图像修复, 张量补全, 低秩结构, 地统计学"}}
{"id": "2506.04653", "pdf": "https://arxiv.org/pdf/2506.04653", "abs": "https://arxiv.org/abs/2506.04653", "authors": ["MoonJeong Park", "Sunghyun Choi", "Jaeseung Heo", "Eunhyeok Park", "Dongwoo Kim"], "title": "The Oversmoothing Fallacy: A Misguided Narrative in GNN Research", "categories": ["cs.LG"], "comment": null, "summary": "Oversmoothing has been recognized as a main obstacle to building deep Graph\nNeural Networks (GNNs), limiting the performance. This position paper argues\nthat the influence of oversmoothing has been overstated and advocates for a\nfurther exploration of deep GNN architectures. Given the three core operations\nof GNNs, aggregation, linear transformation, and non-linear activation, we show\nthat prior studies have mistakenly confused oversmoothing with the vanishing\ngradient, caused by transformation and activation rather than aggregation. Our\nfinding challenges prior beliefs about oversmoothing being unique to GNNs.\nFurthermore, we demonstrate that classical solutions such as skip connections\nand normalization enable the successful stacking of deep GNN layers without\nperformance degradation. Our results clarify misconceptions about oversmoothing\nand shed new light on the potential of deep GNNs.", "AI": {"title_translation": "过度平滑谬误：GNN研究中的误导性叙述", "tldr": "本文认为GNN中的过度平滑被夸大了，它实际上是梯度消失问题，并且经典解决方案可以构建深度GNN。", "motivation": "纠正GNN研究中关于过度平滑的普遍误解，认为其对深度GNN的限制被夸大，并鼓励探索深度GNN架构。", "method": "通过分析GNN的核心操作（聚合、线性变换、非线性激活），指出先前的研究将过度平滑与由变换和激活而非聚合引起的梯度消失混淆。此外，通过展示跳跃连接和归一化等经典解决方案能成功堆叠深度GNN层而不降低性能来验证其观点。", "result": "发现过度平滑并非GNN独有，而是与梯度消失混淆。经典解决方案（如跳跃连接和归一化）能够实现深度GNN层堆叠且不影响性能。", "conclusion": "澄清了对过度平滑的误解，并揭示了深度GNN的潜力。", "translation": "过度平滑被认为是构建深度图神经网络（GNN）的主要障碍，限制了其性能。本文认为过度平滑的影响被夸大了，并倡导进一步探索深度GNN架构。鉴于GNN的三个核心操作：聚合、线性变换和非线性激活，我们表明先前的研究错误地将过度平滑与由变换和激活而非聚合引起的梯度消失混淆。我们的发现挑战了先前关于过度平滑是GNN独有的信念。此外，我们证明了跳跃连接和归一化等经典解决方案能够成功地堆叠深度GNN层而不会导致性能下降。我们的结果澄清了关于过度平滑的误解，并为深度GNN的潜力提供了新的启示。", "summary": "本文指出GNN中过度平滑的影响被夸大，并认为其与梯度消失混淆。研究表明，过度平滑并非GNN特有，且跳跃连接和归一化等经典方法可有效构建深度GNN，为深度GNN的发展提供了新视角。", "keywords": "GNN, 过度平滑, 梯度消失, 深度学习, 图神经网络"}}
{"id": "2506.04879", "pdf": "https://arxiv.org/pdf/2506.04879", "abs": "https://arxiv.org/abs/2506.04879", "authors": ["Yu-Feng Chen", "Tzuhsuan Huang", "Pin-Yen Chiu", "Jun-Cheng Chen"], "title": "Invisible Backdoor Triggers in Image Editing Model via Deep Watermarking", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion models have achieved remarkable progress in both image generation\nand editing. However, recent studies have revealed their vulnerability to\nbackdoor attacks, in which specific patterns embedded in the input can\nmanipulate the model's behavior. Most existing research in this area has\nproposed attack frameworks focused on the image generation pipeline, leaving\nbackdoor attacks in image editing relatively unexplored. Among the few studies\ntargeting image editing, most utilize visible triggers, which are impractical\nbecause they introduce noticeable alterations to the input image before\nediting. In this paper, we propose a novel attack framework that embeds\ninvisible triggers into the image editing process via poisoned training data.\nWe leverage off-the-shelf deep watermarking models to encode imperceptible\nwatermarks as backdoor triggers. Our goal is to make the model produce the\npredefined backdoor target when it receives watermarked inputs, while editing\nclean images normally according to the given prompt. With extensive experiments\nacross different watermarking models, the proposed method achieves promising\nattack success rates. In addition, the analysis results of the watermark\ncharacteristics in term of backdoor attack further support the effectiveness of\nour approach. The code is available\nat:https://github.com/aiiu-lab/BackdoorImageEditing", "AI": {"title_translation": "图像编辑模型中基于深度水印的隐形后门触发器", "tldr": "本文提出了一种通过深度水印在图像编辑模型中嵌入隐形后门触发器的新型攻击框架，实现了在水���输入下触发预定义目标，同时正常编辑干净图像。", "motivation": "现有的扩散模型后门攻击研究主要集中在图像生成管道，对图像编辑中的后门攻击探索较少。少数针对图像编辑的研究使用了可见触发器，这不切实际。因此，本文旨在提出一种通过隐形触发器在图像编辑模型中实现后门攻击的方法。", "method": "提出了一种通过中毒训练数据在图像编辑过程中嵌入隐形触发器的新型攻击框架。利用现成的深度水印模型将不可感知的水印编码为后门触发器。目标是使模型在接收到带水印的输入时产生预定义的后门目标，同时根据给定的提示正常编辑干净图像。", "result": "在不同的水印模型上进行了广泛的实验，所提出的方法取得了有希望的攻击成功率。对水印特征的分析结果进一步支持了该方法的有效性。", "conclusion": "本文提出的通过深度水印在图像编辑模型中嵌入隐形后门触发器的方法是有效的，并能成功实现预期的后门行为，同时保持对干净图像的正常编辑。", "translation": "扩散模型在图像生成和编辑方面取得了显著进展。然而，最近的研究揭示了它们在后门攻击方面的脆弱性，即输入中嵌入的特定模式可以操纵模型的行为。该领域现有的大多数研究都提出了侧重于图像生成管道的攻击框架，而图像编辑中的后门攻击相对 unexplored。在少数针对图像编辑的研究中，大多数利用可见触发器，这不切实际，因为它们在编辑前对输入图像引入了显著的改变。在本文中，我们提出了一种新的攻击框架，通过中毒训练数据将隐形触发器嵌入到图像编辑过程中。我们利用现成的深度水印模型将不可感知的水印编码为后门触发器。我们的目标是使模型在接收到带水印的输入时产生预定义的后门目标，同时根据给定的提示正常编辑干净图像。通过对不同水印模型进行广泛实验，所提出的方法取得了有希望的攻击成功率。此外，对水印特征在后门攻击方面的分析结果进一步支持了我们方法的有效性。代码可在以下网址获取：https://github.com/aiiu-lab/BackdoorImageEditing", "summary": "本文提出了一种新颖的攻击框架，旨在解决图像编辑模型中后门攻击的不足，特别是现有方法多采用可见触发器的问题。该框架通过中毒训练数据，利用深度水印技术将不可感知的触发器嵌入到图像编辑过程中。实验结果表明，该方法在多种水印模型下均能实现高攻击成功率，并在接收到带水印输入时使模型生成预定义的目标，同时不影响对干净图像的正常编辑。", "keywords": "图像编辑, 后门攻击, 深度水印, 扩散模型, 隐形触发器"}}
{"id": "2506.04669", "pdf": "https://arxiv.org/pdf/2506.04669", "abs": "https://arxiv.org/abs/2506.04669", "authors": ["Wanfu Gao", "Hanlin Pan", "Qingqi Han", "Kunpeng Liu"], "title": "Noise-Resistant Label Reconstruction Feature Selection for Partial Multi-Label Learning", "categories": ["cs.LG"], "comment": "accept in ijcai25", "summary": "The \"Curse of dimensionality\" is prevalent across various data patterns,\nwhich increases the risk of model overfitting and leads to a decline in model\nclassification performance. However, few studies have focused on this issue in\nPartial Multi-label Learning (PML), where each sample is associated with a set\nof candidate labels, at least one of which is correct. Existing PML methods\naddressing this problem are mainly based on the low-rank assumption. However,\nlow-rank assumption is difficult to be satisfied in practical situations and\nmay lead to loss of high-dimensional information. Furthermore, we find that\nexisting methods have poor ability to identify positive labels, which is\nimportant in real-world scenarios. In this paper, a PML feature selection\nmethod is proposed considering two important characteristics of dataset: label\nrelationship's noise-resistance and label connectivity. Our proposed method\nutilizes label relationship's noise-resistance to disambiguate labels. Then the\nlearning process is designed through the reformed low-rank assumption. Finally,\nrepresentative labels are found through label connectivity, and the weight\nmatrix is reconstructed to select features with strong identification ability\nto these labels. The experimental results on benchmark datasets demonstrate the\nsuperiority of the proposed method.", "AI": {"title_translation": "噪声鲁棒标签重建特征选择用于部分多标签学习", "tldr": "针对部分多标签学习中维度灾难和现有方法对正标签识别能力差的问题，本文提出了一种基于噪声鲁棒标签重建的特征选择方法，并在基准数据集上表现出优越性。", "motivation": "“维度灾难”普遍存在，增加模型过拟合风险并降低分类性能。在部分多标签学习（PML）中，此问题研究较少。现有PML方法主要基于低秩假设，但其在实际中难以满足且可能导致高维信息丢失。此外，现有方法识别正标签的能力较差。", "method": "提出一种PML特征选择方法，考虑了标签关系的噪声鲁棒性和标签连通性。利用标签关系的噪声鲁棒性消除标签歧义，通过改进的低秩假设设计学习过程，并通过标签连通性找到代表性标签，重建权重矩阵以选择具有强识别能力的特征。", "result": "在基准数据集上的实验结果表明了所提出方法的优越性。", "conclusion": "本文提出了一种新的噪声鲁棒标签重建特征选择方法，有效解决了部分多标签学习中的维度灾难和正标签识别问题，并在实验中验证了其优越性。", "translation": "“维度灾难”在各种数据模式中普遍存在，这增加了模型过拟合的风险并导致模型分类性能下降。然而，在部分多标签学习（PML）中很少有研究关注这个问题，其中每个样本都与一组候选标签相关联，其中至少有一个是正确的。解决此问题的现有PML方法主要基于低秩假设。然而，低秩假设在实际情况中难以满足，并可能导致高维信息的丢失。此外，我们发现现有方法识别正标签的能力较差，这在实际场景中非常重要。在本文中，提出了一种PML特征选择方法，该方法考虑了数据集的两个重要特性：标签关系的噪声鲁棒性和标签连通性。我们提出的方法利用标签关系的噪声鲁棒性来消除标签歧义。然后通过改进的低秩假设设计学习过程。最后，通过标签连通性找到代表性标签，并重建权重矩阵以选择对这些标签具有强识别能力的特征。在基准数据集上的实验结果证明了所提出方法的优越性。", "summary": "针对部分多标签学习（PML）中普遍存在的“维度灾难”和现有方法对正标签识别能力差的问题，本文提出了一种新颖的噪声鲁棒标签重建特征选择方法。该方法考虑了标签关系的噪声鲁棒性和标签连通性，通过利用噪声鲁棒性消除标签歧义，并通过改进的低秩假设设计学习过程。此外，通过标签连通性找到代表性标签并重建权重矩阵以选择具有强识别能力的特征。实验结果表明该方法在基准数据集上表现出优越性。", "keywords": "部分多标签学习, 特征选择, 噪声鲁棒性, 标签重建, 维度灾难"}}
{"id": "2506.04892", "pdf": "https://arxiv.org/pdf/2506.04892", "abs": "https://arxiv.org/abs/2506.04892", "authors": ["Andrew Hamara", "Greg Hamerly", "Pablo Rivas", "Andrew C. Freeman"], "title": "Learning to Plan via Supervised Contrastive Learning and Strategic Interpolation: A Chess Case Study", "categories": ["cs.CV"], "comment": null, "summary": "Modern chess engines achieve superhuman performance through deep tree search\nand regressive evaluation, while human players rely on intuition to select\ncandidate moves followed by a shallow search to validate them. To model this\nintuition-driven planning process, we train a transformer encoder using\nsupervised contrastive learning to embed board states into a latent space\nstructured by positional evaluation. In this space, distance reflects\nevaluative similarity, and visualized trajectories display interpretable\ntransitions between game states. We demonstrate that move selection can occur\nentirely within this embedding space by advancing toward favorable regions,\nwithout relying on deep search. Despite using only a 6-ply beam search, our\nmodel achieves an estimated Elo rating of 2593. Performance improves with both\nmodel size and embedding dimensionality, suggesting that latent planning may\noffer a viable alternative to traditional search. Although we focus on chess,\nthe proposed embedding-based planning method can be generalized to other\nperfect-information games where state evaluations are learnable. All source\ncode is available at https://github.com/andrewhamara/SOLIS.", "AI": {"title_translation": "通过监督对比学习和策略插值进行规划：以国际象棋为例", "tldr": "本文提出了一种基于监督对比学习和策略插值的方法，训练Transformer编码器将棋盘状态嵌入到潜在空间中，实现无需深度搜索的国际象棋规划，并达到2593的Elo等级分。", "motivation": "现代国际象棋引擎通过深度搜索实现超人表现，而人类玩家则依赖直觉和浅层搜索。为了模拟这种直觉驱动的规划过程，本文旨在探索一种不依赖深度搜索的规划方法。", "method": "本文训练了一个Transformer编码器，使用监督对比学习将棋盘状态嵌入到由位置评估构建的潜在空间中。在这个空间中，距离反映评估相似性，并通过在嵌入空间中向有利区域移动来选择走法，而不是依赖深度搜索。", "result": "该模型仅使用6层束搜索，就达到了2593的Elo等级分。性能随模型大小和嵌入维度的增加而提高。", "conclusion": "潜在规划可能为传统搜索提供一个可行的替代方案。尽管本文以国际象棋为例，但所提出的基于嵌入的规划方法可以推广到其他状态评估可学习的完美信息博弈。", "translation": "现代国际象棋引擎通过深度树搜索和回归评估实现超人表现，而人类玩家则依靠直觉选择候选走法，然后进行浅层搜索来验证它们。为了模拟这种直觉驱动的规划过程，我们训练了一个Transformer编码器，使用监督对比学习将棋盘状态嵌入到由位置评估构建的潜在空间中。在这个空间中，距离反映评估相似性，可视化轨迹显示游戏状态之间可解释的转换。我们证明，走法选择可以完全在这个嵌入空间中进行，通过向有利区域前进，而无需依赖深度搜索。尽管只使用了6层束搜索，我们的模型估计Elo等级分达到了2593。性能随模型大小和嵌入维度的增加而提高，这表明潜在规划可能为传统搜索提供一个可行的替代方案。尽管我们专注于国际象棋，但所提出的基于嵌入的规划方法可以推广到其他状态评估可学习的完美信息博弈。所有源代码均可在https://github.com/andrewhamara/SOLIS获取。", "summary": "本文提出了一种新的国际象棋规划方法，旨在模拟人类直觉驱动的规划过程。通过监督对比学习训练Transformer编码器，将棋盘状态嵌入到结构化的潜在空间中。在该空间中，模型能够通过向有利区域移动来选择走法，避免了传统深度搜索的需求。该模型在仅使用6层束搜索的情况下，达到了2593的Elo等级分，表明潜在规划是传统搜索的有效替代方案，并且该方法可推广到其他完美信息博弈。", "keywords": "国际象棋, 监督对比学习, 潜在规划, Transformer, 策略插值"}}
{"id": "2506.04672", "pdf": "https://arxiv.org/pdf/2506.04672", "abs": "https://arxiv.org/abs/2506.04672", "authors": ["Shengkun Zhu", "Feiteng Nie", "Jinshan Zeng", "Sheng Wang", "Yuan Sun", "Yuan Yao", "Shangfeng Chen", "Quanqing Xu", "Chuanhui Yang"], "title": "FedAPM: Federated Learning via ADMM with Partial Model Personalization", "categories": ["cs.LG"], "comment": null, "summary": "In federated learning (FL), the assumption that datasets from different\ndevices are independent and identically distributed (i.i.d.) often does not\nhold due to user differences, and the presence of various data modalities\nacross clients makes using a single model impractical. Personalizing certain\nparts of the model can effectively address these issues by allowing those parts\nto differ across clients, while the remaining parts serve as a shared model.\nHowever, we found that partial model personalization may exacerbate client\ndrift (each client's local model diverges from the shared model), thereby\nreducing the effectiveness and efficiency of FL algorithms. We propose an FL\nframework based on the alternating direction method of multipliers (ADMM),\nreferred to as FedAPM, to mitigate client drift. We construct the augmented\nLagrangian function by incorporating first-order and second-order proximal\nterms into the objective, with the second-order term providing fixed correction\nand the first-order term offering compensatory correction between the local and\nshared models. Our analysis demonstrates that FedAPM, by using explicit\nestimates of the Lagrange multiplier, is more stable and efficient in terms of\nconvergence compared to other FL frameworks. We establish the global\nconvergence of FedAPM training from arbitrary initial points to a stationary\npoint, achieving three types of rates: constant, linear, and sublinear, under\nmild assumptions. We conduct experiments using four heterogeneous and\nmultimodal datasets with different metrics to validate the performance of\nFedAPM. Specifically, FedAPM achieves faster and more accurate convergence,\noutperforming the SOTA methods with average improvements of 12.3% in test\naccuracy, 16.4% in F1 score, and 18.0% in AUC while requiring fewer\ncommunication rounds.", "AI": {"title_translation": "联邦学习中的FedAPM：基于ADMM的部分模型个性化", "tldr": "FedAPM是一种基于ADMM的联邦学习框架，通过引入一阶和二阶近端项来缓解客户端漂移，从而实现更稳定、高效的收敛，并在异构和多模态数据集上显著优于现有SOTA方法。", "motivation": "联邦学习中非独立同分布（non-i.i.d.）数据和多模态数据导致单一模型不切实际，部分模型个性化虽能解决这些问题，但可能加剧客户端漂移，降低联邦学习算法的有效性和效率。", "method": "提出FedAPM框架，基于交替方向乘子法（ADMM），通过在目标函数中加入一阶和二阶近端项来构建增广拉格朗日函数，其中二阶项提供固定校正，一阶项提供局部模型和共享模型之间的补偿校正，并使用拉格朗日乘子的显式估计。", "result": "FedAPM在收敛性方面比其他联邦学习框架更稳定和高效。从任意初始点到平稳点实现了全局收敛，在温和假设下达到了常数、线性、次线性三种收敛速率。在四种异构和多模态数据集上，FedAPM在测试准确率上平均提高12.3%，F1分数提高16.4%，AUC提高18.0%，同时需要更少的通信轮次，性能优于SOTA方法。", "conclusion": "FedAPM通过基于ADMM的方法，有效缓解了联邦学习中部分模型个性化导致的客户端漂移问题，显著提高了算法的稳定性、收敛效率和性能，在异构和多模态环境下表现优异。", "translation": "在联邦学习（FL）中，不同设备的数1据集独立同分布（i.i.d.）的假设通常由于用户差异而不成立，并且客户端存在各种数据模态使得使用单一模型不切实际。个性化模型的部分可以有效解决这些问题，通过允许这些部分在客户端之间有所不同，而其余部分作为共享模型。然而，我们发现部分模型个性化可能会加剧客户端漂移（每个客户端的本地模型与共享模型偏离），从而降低FL算法的有效性和效率。我们提出了一种基于交替方向乘子法（ADMM）的FL框架，称为FedAPM，以减轻客户端漂移。我们通过将一阶和二阶近端项纳入目标函数来构建增广拉格朗日函数，其中二阶项提供固定校正，一阶项提供本地模型和共享模型之间的补偿校正。我们的分析表明，FedAPM通过使用拉格朗日乘数的显式估计，在收敛性方面比其他FL框架更稳定和高效。我们在温和假设下建立了FedAPM训练从任意初始点到平稳点的全局收敛性，实现了三种类型的速率：常数、线性和次线性。我们使用四种异构和多模态数据集以及不同的指标进行实验，以验证FedAPM的性能。具体而言，FedAPM实现了更快、更准确的收敛，在测试准确率上平均提高12.3%，F1分数提高16.4%，AUC提高18.0%，同时需要更少的通信轮次，优于SOTA方法。", "summary": "本研究提出了一种名为FedAPM的联邦学习框架，旨在解决部分模型个性化在非独立同分布和多模态数据环境下可能加剧客户端漂移的问题。FedAPM基于交替方向乘子法（ADMM），通过在增广拉格朗日函数中引入一阶和二阶近端项来提供校正。理论分析表明FedAPM在收敛性上更稳定高效，并实现了全局收敛。实验结果证明，FedAPM在异构和多模态数据集上显著优于现有最先进方法，在准确率、F1分数和AUC等指标上均有显著提升，并减少了通信轮次。", "keywords": "联邦学习, ADMM, 模型个性化, 客户端漂移, 收敛性"}}
{"id": "2506.04897", "pdf": "https://arxiv.org/pdf/2506.04897", "abs": "https://arxiv.org/abs/2506.04897", "authors": ["Tianxu Wang", "Zhuofan Zhang", "Ziyu Zhu", "Yue Fan", "Jing Xiong", "Pengxiang Li", "Xiaojian Ma", "Qing Li"], "title": "From Objects to Anywhere: A Holistic Benchmark for Multi-level Visual Grounding in 3D Scenes", "categories": ["cs.CV"], "comment": null, "summary": "3D visual grounding has made notable progress in localizing objects within\ncomplex 3D scenes. However, grounding referring expressions beyond objects in\n3D scenes remains unexplored. In this paper, we introduce Anywhere3D-Bench, a\nholistic 3D visual grounding benchmark consisting of 2,632 referring\nexpression-3D bounding box pairs spanning four different grounding levels:\nhuman-activity areas, unoccupied space beyond objects, objects in the scene,\nand fine-grained object parts. We assess a range of state-of-the-art 3D visual\ngrounding methods alongside large language models (LLMs) and multimodal LLMs\n(MLLMs) on Anywhere3D-Bench. Experimental results reveal that space-level and\npart-level visual grounding pose the greatest challenges: space-level tasks\nrequire a more comprehensive spatial reasoning ability, for example, modeling\ndistances and spatial relations within 3D space, while part-level tasks demand\nfine-grained perception of object composition. Even the best performance model,\nOpenAI o4-mini, achieves only 23.57% accuracy on space-level tasks and 33.94%\non part-level tasks, significantly lower than its performance on area-level and\nobject-level tasks. These findings underscore a critical gap in current models'\ncapacity to understand and reason about 3D scene beyond object-level semantics.", "AI": {"title_translation": "从物体到任意位置：一个用于三维场景多级别视觉定位的综合基准", "tldr": "引入Anywhere3D-Bench，一个涵盖多级别（区域、空间、物体、部件）的3D视觉定位基准，揭示现有模型在空间和部件级别定位上的显著不足。", "motivation": "现有的3D视觉定位研究主要集中在复杂3D场景中的物体定位，但对于超出物体的指代表达在3D场景中的定位仍未被探索。", "method": "本文引入了Anywhere3D-Bench，一个综合性的3D视觉定位基准，包含2,632个指代表达-3D边界框对，涵盖了人类活动区域、超出物体的未占用空间、场景中的物体以及细粒度物体部件这四个不同的定位级别。研究评估了一系列最先进的3D视觉定位方法以及大型语言模型（LLMs）和多模态LLMs（MLLMs）在该基准上的表现。", "result": "实验结果表明，空间级别和部件级别的视觉定位带来了最大的挑战：空间级别任务需要更全面的空间推理能力，例如，建模3D空间内的距离和空间关系，而部件级别任务则需要对物体组成进行细粒度感知。即使是表现最好的模型OpenAI o4-mini，在空间级别任务上的准确率也仅为23.57%，在部件级别任务上为33.94%，显著低于其在区域级别和物体级别任务上的表现。", "conclusion": "这些发现强调了当前模型在理解和推理超出物体级别语义的三维场景能力方面存在关键空白。", "translation": "三维视觉定位在复杂三维场景中定位物体方面取得了显著进展。然而，在三维场景中定位超出物体的指代表达仍未被探索。在本文中，我们引入了Anywhere3D-Bench，一个综合性的三维视觉定位基准，包含2,632个指代表达-三维边界框对，涵盖了四个不同的定位级别：人类活动区域、超出物体的未占用空间、场景中的物体以及细粒度物体部件。我们评估了一系列最先进的三维视觉定位方法以及大型语言模型（LLMs）和多模态LLMs（MLLMs）在Anywhere3D-Bench上的表现。实验结果表明，空间级别和部件级别的视觉定位带来了最大的挑战：空间级别任务需要更全面的空间推理能力，例如，建模三维空间内的距离和空间关系，而部件级别任务则需要对物体组成进行细粒度感知。即使是表现最好的模型OpenAI o4-mini，在空间级别任务上的准确率也仅为23.57%，在部件级别任务上为33.94%，显著低于其在区域级别和物体级别任务上的表现。这些发现强调了当前模型在理解和推理超出物体级别语义的三维场景能力方面存在关键空白。", "summary": "该论文提出了Anywhere3D-Bench，一个用于3D视觉定位的综合性基准，旨在解决现有研究主要集中在物体定位而忽略其他类型指代表达的问题。该基准涵盖了区域、空间、物体和部件四个定位级别。通过评估现有模型（包括LLMs和MLLMs），研究发现模型在空间级别和部件级别的定位表现显著不足，揭示了当前模型在理解和推理3D场景超出物体级别语义方面的局限性。", "keywords": "3D视觉定位, 基准, 多级别定位, 空间推理, 部件感知"}}
{"id": "2506.04677", "pdf": "https://arxiv.org/pdf/2506.04677", "abs": "https://arxiv.org/abs/2506.04677", "authors": ["Marco Zanotti"], "title": "The cost of ensembling: is it always worth combining?", "categories": ["cs.LG", "stat.AP", "stat.OT"], "comment": null, "summary": "Given the continuous increase in dataset sizes and the complexity of\nforecasting models, the trade-off between forecast accuracy and computational\ncost is emerging as an extremely relevant topic, especially in the context of\nensemble learning for time series forecasting. To asses it, we evaluated ten\nbase models and eight ensemble configurations across two large-scale retail\ndatasets (M5 and VN1), considering both point and probabilistic accuracy under\nvarying retraining frequencies. We showed that ensembles consistently improve\nforecasting performance, particularly in probabilistic settings. However, these\ngains come at a substantial computational cost, especially for larger,\naccuracy-driven ensembles. We found that reducing retraining frequency\nsignificantly lowers costs, with minimal impact on accuracy, particularly for\npoint forecasts. Moreover, efficiency-driven ensembles offer a strong balance,\nachieving competitive accuracy with considerably lower costs compared to\naccuracy-optimized combinations. Most importantly, small ensembles of two or\nthree models are often sufficient to achieve near-optimal results. These\nfindings provide practical guidelines for deploying scalable and cost-efficient\nforecasting systems, supporting the broader goals of sustainable AI in\nforecasting. Overall, this work shows that careful ensemble design and\nretraining strategy selection can yield accurate, robust, and cost-effective\nforecasts suitable for real-world applications.", "AI": {"title_translation": "集合的成本：组合总是值得的吗？", "tldr": "集合学习在提高预测准确性方面有效，但计算成本高昂；通过优化集合设计和再训练策略可以实现成本效益。", "motivation": "随着数据集规模和预测模型复杂度的增加，预测准确性与计算成本之间的权衡成为一个极其相关的话题，尤其是在时间序列预测的集合学习背景下。", "method": "研究评估了十种基础模型和八种集合配置，在两个大型零售数据集（M5和VN1）上，考虑了点预测和概率预测的准确性，并分析了不同的再训练频率。", "result": "集合模型始终能提高预测性能，尤其是在概率设置中；然而，这些提升伴随着巨大的计算成本，特别是对于大型、以准确性为导向的集合；降低再训练频率能显著降低成本，对准确性影响最小；效率驱动的集合模型能以较低成本实现有竞争力的准确性；两三个模型的小型集合通常足以达到接近最优的结果。", "conclusion": "仔细的集合设计和再训练策略选择可以产生准确、稳健且成本效益高的预测，适用于实际应用。", "translation": "鉴于数据集规模和预测模型复杂度的持续增长，预测准确性与计算成本之间的权衡正成为一个极其相关的话题，尤其是在时间序列预测的集合学习背景下。为了评估这一点，我们评估了十种基础模型和八种集合配置，横跨两个大型零售数据集（M5和VN1），考虑了在不同再训练频率下的点预测和概率准确性。我们发现集合模型始终能提高预测性能，尤其是在概率设置中。然而，这些提升伴随着巨大的计算成本，特别是对于大型、以准确性为准确性导向的集合。我们发现降低再训练频率能显著降低成本，对准确性的影响最小，特别是对于点预测。此外，效率驱动的集合模型提供了一个强大的平衡，与以准确性优化的组合相比，它们能以相当低的成本实现有竞争力的准确性。最重要的是，由两三个模型组成的小型集合通常足以达到接近最优的结果。这些发现为部署可扩展且成本效益高的预测系统提供了实用指导，支持了预测领域可持续人工智能的更广泛目标。总的来说，这项工作表明，仔细的集合设计和再训练策略选择可以产生准确、稳健且成本效益高的预测，适用于实际应用。", "summary": "本文探讨了时间序列预测中集合学习的准确性与计算成本之间的权衡。研究发现，虽然集合模型能提升预测性能，但其高昂的计算成本不容忽视。通过优化再训练频率和选择效率驱动的集合配置（例如小型集合），可以在保持竞争性准确性的同时显著降低成本，从而为部署可扩展且经济高效的预测系统提供指导。", "keywords": "集合学习, 时间序列预测, 计算成本, 准确性-成本权衡, 再训练频率"}}
{"id": "2506.04373", "pdf": "https://arxiv.org/pdf/2506.04373", "abs": "https://arxiv.org/abs/2506.04373", "authors": ["Matthieu Tehenan", "Vikram Natarajan", "Jonathan Michala", "Milton Lin", "Juri Opitz"], "title": "Mechanistic Decomposition of Sentence Representations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Sentence embeddings are central to modern NLP and AI systems, yet little is\nknown about their internal structure. While we can compare these embeddings\nusing measures such as cosine similarity, the contributing features are not\nhuman-interpretable, and the content of an embedding seems untraceable, as it\nis masked by complex neural transformations and a final pooling operation that\ncombines individual token embeddings. To alleviate this issue, we propose a new\nmethod to mechanistically decompose sentence embeddings into interpretable\ncomponents, by using dictionary learning on token-level representations. We\nanalyze how pooling compresses these features into sentence representations,\nand assess the latent features that reside in a sentence embedding. This\nbridges token-level mechanistic interpretability with sentence-level analysis,\nmaking for more transparent and controllable representations. In our studies,\nwe obtain several interesting insights into the inner workings of sentence\nembedding spaces, for instance, that many semantic and syntactic aspects are\nlinearly encoded in the embeddings.", "AI": {"title_translation": "句子表示的机制分解", "tldr": "本研究提出了一种通过字典学习将句子嵌入分解为可解释组件的新方法，以揭示其内部结构。", "motivation": "现代NLP和AI系统中的句子嵌入是核心组成部分，但其内部结构鲜为人知。由于复杂的神经变换和最终的池化操作，嵌入的贡献特征难以解释，内容也难以追溯。", "method": "提出了一种新的方法，通过对标记级表示进行字典学习，将句子嵌入机制性地分解为可解释的组件。分析了池化如何将这些特征压缩成句子表示，并评估了句子嵌入中存在的潜在特征。", "result": "获得了关于句子嵌入空间内部运作的一些有趣见解，例如，许多语义和句法方面在线性编码在嵌入中。", "conclusion": "通过将标记级机制可解释性与句子级分析相结合，使表示更透明和可控。", "translation": "句子嵌入是现代自然语言处理和人工智能系统的核心，但对其内部结构知之甚少。虽然我们可以使用余弦相似度等度量来比较这些嵌入，但其贡献特征是人类不可解释的，并且嵌入的内容似乎无法追溯，因为它被复杂的神经网络变换和结合单个标记嵌入的最终池化操作所掩盖。为了缓解这个问题，我们提出了一种新的方法，通过对标记级表示进行字典学习，将句子嵌入机制性地分解为可解释的组件。我们分析了池化如何将这些特征压缩成句子表示，并评估了句子嵌入中存在的潜在特征。这弥合了标记级机制可解释性与句子级分析之间的鸿沟，从而使表示更透明和可控。在我们的研究中，我们对句子嵌入空间的内部运作获得了一些有趣的见解，例如，许多语义和句法方面在线性编码在嵌入中。", "summary": "本论文旨在解决句子嵌入内部结构不透明的问题。通过对标记级表示应用字典学习，研究人员开发了一种新方法来机制性地分解句子嵌入，使其成为可解释的组件。研究分析了池化如何压缩特征，并评估了句子嵌入中的潜在特征。结果表明，句子嵌入中线性编码了许多语义和句法信息，从而使句子表示更透明和可控。", "keywords": "句子嵌入, 机制分解, 字典学习, 可解释性, 自然语言处理"}}
{"id": "2506.04908", "pdf": "https://arxiv.org/pdf/2506.04908", "abs": "https://arxiv.org/abs/2506.04908", "authors": ["Filip Slezak", "Magnus K. Gjerde", "Joakim B. Haurum", "Ivan Nikolov", "Morten S. Laursen", "Thomas B. Moeslund"], "title": "Generating Synthetic Stereo Datasets using 3D Gaussian Splatting and Expert Knowledge Transfer", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we introduce a 3D Gaussian Splatting (3DGS)-based pipeline for\nstereo dataset generation, offering an efficient alternative to Neural Radiance\nFields (NeRF)-based methods. To obtain useful geometry estimates, we explore\nutilizing the reconstructed geometry from the explicit 3D representations as\nwell as depth estimates from the FoundationStereo model in an expert knowledge\ntransfer setup. We find that when fine-tuning stereo models on 3DGS-generated\ndatasets, we demonstrate competitive performance in zero-shot generalization\nbenchmarks. When using the reconstructed geometry directly, we observe that it\nis often noisy and contains artifacts, which propagate noise to the trained\nmodel. In contrast, we find that the disparity estimates from FoundationStereo\nare cleaner and consequently result in a better performance on the zero-shot\ngeneralization benchmarks. Our method highlights the potential for low-cost,\nhigh-fidelity dataset creation and fast fine-tuning for deep stereo models.\nMoreover, we also reveal that while the latest Gaussian Splatting based methods\nhave achieved superior performance on established benchmarks, their robustness\nfalls short in challenging in-the-wild settings warranting further exploration.", "AI": {"title_translation": "使用3D高斯泼溅和专家知识迁移生成合成立体数据集", "tldr": "本文介绍了一种基于3D高斯泼溅（3DGS）的立体数据集生成管道，比基于NeRF的方法更高效。通过专家知识迁移，利用FoundationStereo的深度估计而非直接使用3DGS重建几何，生成的合成数据集在零样本泛化基准测试中表现出有竞争力的性能，并揭示了3DGS在复杂场景下的鲁棒性不足。", "motivation": "传统的基于NeRF的方法生成立体数据集效率低下。研究旨在寻找一种更高效、低成本、高保真度的数据集生成方法，并实现深度立体模型的快速微调。", "method": "本文提出了一种基于3D高斯泼溅（3DGS）的立体数据集生成管道，作为NeRF方法的替代。为了获得有用的几何估计，该方法探索了利用显式3D表示的重建几何以及FoundationStereo模型的深度估计，采用专家知识迁移设置。", "result": "当在3DGS生成的合成数据集上微调立体模型时，在零样本泛化基准测试中表现出有竞争力的性能。直接使用3DGS重建的几何通常存在噪声和伪影，会将噪声传播到训练模型。相比之下，FoundationStereo的视差估计更清晰，从而在零样本泛化基准测试中表现更好。", "conclusion": "该方法突出了低成本、高保真度数据集创建和深度立体模型快速微调的潜力。同时，也揭示了虽然最新的基于高斯泼溅的方法在既定基准上取得了优越性能，但在具有挑战性的实际场景中其鲁棒性不足，需要进一步探索。", "translation": "本文介绍了一种基于3D高斯泼溅（3DGS）的立体数据集生成管道，为基于神经辐射场（NeRF）的方法提供了一种高效的替代方案。为了获得有用的几何估计，我们探索了利用来自显式3D表示的重建几何以及来自FoundationStereo模型的深度估计，采用专家知识迁移设置。我们发现，当在3DGS生成的数据集上微调立体模型时，我们在零样本泛化基准测试中表现出有竞争力的性能。当直接使用重建几何时，我们观察到它通常是嘈杂的并包含伪影，这会将噪声传播到训练模型。相比之下，我们发现FoundationStereo的视差估计更清晰，因此在零样本泛化基准测试中表现更好。我们的方法突出了低成本、高保真度数据集创建和深度立体模型快速微调的潜力。此外，我们还揭示了尽管最新的基于高斯泼溅的方法在既定基准上取得了优越性能，但在具有挑战性的实际场景中其鲁棒性不足，需要进一步探索。", "summary": "本研究提出了一种基于3D高斯泼溅（3DGS）的立体数据集生成新管道，旨在提高效率并降低成本。通过探索专家知识迁移，特别是利用FoundationStereo模型的深度估计，而非直接使用3DGS重建的噪声几何，该方法生成的合成数据集能够使立体模型在零样本泛化基准测试中达到有竞争力的性能。研究强调了这种方法在创建低成本、高保真度数据集和加速深度立体模型微调方面的潜力，同时也指出当前高斯泼溅方法在复杂实际场景中鲁棒性有待提高。", "keywords": "3D高斯泼溅, 立体数据集生成, 专家知识迁移, 零样本泛化, FoundationStereo"}}
{"id": "2506.04376", "pdf": "https://arxiv.org/pdf/2506.04376", "abs": "https://arxiv.org/abs/2506.04376", "authors": ["Emiliano Acevedo", "Martín Rocamora", "Magdalena Fuentes"], "title": "Domain Adaptation Method and Modality Gap Impact in Audio-Text Models for Prototypical Sound Classification", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Accepted at INTERSPEECH 2025", "summary": "Audio-text models are widely used in zero-shot environmental sound\nclassification as they alleviate the need for annotated data. However, we show\nthat their performance severely drops in the presence of background sound\nsources. Our analysis reveals that this degradation is primarily driven by SNR\nlevels of background soundscapes, and independent of background type. To\naddress this, we propose a novel method that quantifies and integrates the\ncontribution of background sources into the classification process, improving\nperformance without requiring model retraining. Our domain adaptation technique\nenhances accuracy across various backgrounds and SNR conditions. Moreover, we\nanalyze the modality gap between audio and text embeddings, showing that\nnarrowing this gap improves classification performance. The method generalizes\neffectively across state-of-the-art prototypical approaches, showcasing its\nscalability and robustness for diverse environments.", "AI": {"title_translation": "音频-文本模型中用于原型声音分类的域适应方法和模态鸿沟影响", "tldr": "本研究提出了一种域适应方法，通过量化和整合背景声源的贡献来提高音频-文本模型在存在背景噪声时的声音分类性能，并分析了模态鸿沟对性能的影响。", "motivation": "音频-文本模型在零样本环境声音分类中广泛应用，但其性能在存在背景声源时严重下降，且这种下降主要由背景声景的信噪比水平驱动，与背景类型无关。", "method": "本研究提出了一种新颖的方法，量化并整合背景声源的贡献到分类过程中，无需模型再训练即可提高性能。此外，该研究还分析了音频和文本嵌入之间的模态鸿沟，并发现缩小这一鸿沟可以提高分类性能。", "result": "所提出的域适应技术提高了在各种背景和信噪比条件下的分类准确性。缩小模态鸿沟改善了分类性能。该方法能够有效推广到最先进的原型方法，展示了其可扩展性和对多样化环境的鲁棒性。", "conclusion": "通过量化和整合背景声源贡献的域适应方法，可以有效提高音频-文本模型在复杂背景下的声音分类性能，并且缩小音频和文本嵌入之间的模态鸿沟也有助于提升性能。", "translation": "音频-文本模型在零样本环境声音分类中被广泛使用，因为它们减轻了对标注数据的需求。然而，我们发现它们在存在背景声源时性能严重下降。我们的分析表明，这种下降主要由背景声景的信噪比水平驱动，与背景类型无关。为了解决这个问题，我们提出了一种新颖的方法，量化并将背景声源的贡献整合到分类过程中，在无需模型再训练的情况下提高了性能。我们的域适应技术提高了在各种背景和信噪比条件下的准确性。此外，我们分析了音频和文本嵌入之间的模态鸿沟，表明缩小这一鸿沟可以提高分类性能。该方法能够有效推广到最先进的原型方法，展示了其对多样化环境的可扩展性和鲁棒性。", "summary": "本论文探讨了音频-文本模型在零样本环境声音分类中，面对背景噪声时性能下降的问题。研究发现性能下降主要受信噪比影响。为解决此问题，论文提出了一种域适应方法，通过量化和整合背景声源的贡献来提高分类准确性，且无需模型再训练。此外，研究还分析了音频和文本嵌入之间的模态鸿沟，并证明缩小该鸿沟能提升分类表现。该方法对多种原型方法具有良好的泛化能力和鲁棒性。", "keywords": "域适应, 音频-文本模型, 声音分类, 模态鸿沟, 信噪比"}}
{"id": "2506.04925", "pdf": "https://arxiv.org/pdf/2506.04925", "abs": "https://arxiv.org/abs/2506.04925", "authors": ["Antoine Laurent", "Jean Mélou", "Catherine Schwab", "Rolande Simon-Millot", "Sophie Féret", "Thomas Sagory", "Carole Fritz", "Jean-Denis Durou"], "title": "Light and 3D: a methodological exploration of digitisation techniques adapted to a selection of objects from the Mus{é}e d'Arch{é}ologie Nationale", "categories": ["cs.CV"], "comment": "in French language", "summary": "The need to digitize heritage objects is now widely accepted. This article\npresents the very fashionable context of the creation of ''digital twins''. It\nillustrates the diversity of photographic 3D digitization methods, but this is\nnot its only objective. Using a selection of objects from the collections of\nthe mus{\\'e}e d'Arch{\\'e}ologie nationale, it shows that no single method is\nsuitable for all cases. Rather, the method to be recommended for a given object\nshould be the result of a concerted choice between those involved in heritage\nand those involved in the digital domain, as each new object may require the\nadaptation of existing tools. It would therefore be pointless to attempt an\nabsolute classification of 3D digitization methods. On the contrary, we need to\nfind the digital tool best suited to each object, taking into account not only\nits characteristics, but also the future use of its digital twin.", "AI": {"title_translation": "光与3D：国家考古博物馆精选藏品数字化技术的方法论探索", "tldr": "本文探讨了文化遗产对象3D数字化的多种摄影方法，强调没有单一方法适用于所有情况，应根据对象特性和未来用途选择最合适的数字化工具，而非进行绝对分类。", "motivation": "文化遗产对象数字化需求被广泛接受，特别是在创建“数字双胞胎”的背景下，但目前缺乏针对不同对象选择合适3D数字化方法的指南。", "method": "文章通过展示多种摄影3D数字化方法，并以国家考古博物馆的精选藏品为例，说明没有单一方法适用于所有情况，而是强调应根据对象特性和未来用途，由遗产和数字领域相关人员协商选择最合适的工具。", "result": "研究结果表明，没有单一的3D数字化方法适用于所有文化遗产对象。相反，推荐的方法应是遗产和数字领域参与者共同协商的结果，因为每个新对象可能需要对现有工具进行调整。", "conclusion": "因此，试图对3D数字化方法进行绝对分类是毫无意义的。关键在于根据每个对象的特性及其数字双胞胎的未来用途，找到最适合的数字工具。", "translation": "文化遗产对象数字化的需求现已广为接受。本文介绍了创建“数字双胞胎”这一非常流行的背景。它阐述了摄影3D数字化方法的多样性，但这并非其唯一目标。通过国家考古博物馆精选藏品为例，本文表明没有单一方法适用于所有情况。相反，针对特定对象推荐的方法应该是遗产领域和数字领域相关人员协商选择的结果，因为每个新对象可能都需要调整现有工具。因此，试图对3D数字化方法进行绝对分类将是毫无意义的。相反，我们需要找到最适合每个对象的数字工具，这不仅要考虑其特性，还要考虑其数字双胞胎的未来用途。", "summary": "本文探讨了文化遗产对象3D数字化的方法论，指出虽然数字化需求普遍，但没有一种单一的摄影3D数字化方法适用于所有情况。通过国家考古博物馆的藏品案例，文章强调应根据对象的具体特征和数字双胞胎的未来用途，由遗产和数字专业人员共同协商，为每个对象选择最合适的数字化工具，而非追求方法上的绝对分类。", "keywords": "3D数字化, 文化遗产, 数字双胞胎, 摄影方法, 方法论探索"}}
{"id": "2506.04690", "pdf": "https://arxiv.org/pdf/2506.04690", "abs": "https://arxiv.org/abs/2506.04690", "authors": ["Yifan Hao", "Yanxin Lu", "Xinwei Shen", "Tong Zhang"], "title": "Towards Better Generalization via Distributional Input Projection Network", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As overparameterized models become increasingly prevalent, training loss\nalone offers limited insight into generalization performance. While smoothness\nhas been linked to improved generalization across various settings, directly\nenforcing smoothness in neural networks remains challenging. To address this,\nwe introduce Distributional Input Projection Networks (DIPNet), a novel\nframework that projects inputs into learnable distributions at each layer. This\ndistributional representation induces a smoother loss landscape with respect to\nthe input, promoting better generalization. We provide theoretical analysis\nshowing that DIPNet reduces both local smoothness measures and the Lipschitz\nconstant of the network, contributing to improved generalization performance.\nEmpirically, we validate DIPNet across a wide range of architectures and tasks,\nincluding Vision Transformers (ViTs), Large Language Models (LLMs), ResNet and\nMLPs. Our method consistently enhances test performance under standard\nsettings, adversarial attacks, out-of-distribution inputs, and reasoning\nbenchmarks. We demonstrate that the proposed input projection strategy can be\nseamlessly integrated into existing models, providing a general and effective\napproach for boosting generalization performance in modern deep learning.", "AI": {"title_translation": "通过分布输入投影网络实现更好的泛化", "tldr": "提出了一种名为DIPNet的新框架，通过将输入投影到可学习的分布中来提高模型的泛化能力，从而产生更平滑的损失景观，并在多种模型和任务上表现出一致的性能提升。", "motivation": "过度参数化模型日益普遍，但训练损失本身对泛化性能的洞察有限。尽管平滑性与泛化能力提升相关，但直接在神经网络中强制执行平滑性仍然具有挑战性。", "method": "引入了分布输入投影网络（DIPNet），一个将输入投影到每一层的可学习分布中的新颖框架。这种分布表示会产生相对于输入更平滑的损失景观。", "result": "理论分析表明DIPNet降低了局部平滑度度量和网络的Lipschitz常数，有助于提高泛化性能。在Vision Transformers (ViTs)、大型语言模型 (LLMs)、ResNet和MLP等多种架构和任务上进行了实证验证，在标准设置、对抗性攻击、域外输入和推理基准测试中，DIPNet始终能提高测试性能。所提出的输入投影策略可以无缝集成到现有模型中。", "conclusion": "DIPNet提供了一种通用且有效的方法，可以提高现代深度学习中模型的泛化性能。", "translation": "随着过度参数化模型日益普及，仅凭训练损失对泛化性能的洞察有限。尽管平滑性已在各种设置中与泛化能力提升相关联，但直接在神经网络中强制执行平滑性仍然具有挑战性。为了解决这个问题，我们引入了分布输入投影网络（DIPNet），这是一个将输入投影到每一层的可学习分布中的新颖框架。这种分布表示会产生相对于输入更平滑的损失景观，从而促进更好的泛化。我们提供了理论分析，表明DIPNet降低了局部平滑度度量和网络的Lipschitz常数，有助于提高泛化性能。在经验上，我们在包括Vision Transformers（ViTs）、大型语言模型（LLMs）、ResNet和MLP在内的各种架构和任务中验证了DIPNet。我们的方法在标准设置、对抗性攻击、域外输入和推理基准测试中始终能提高测试性能。我们证明了所提出的输入投影策略可以无缝集成到现有模型中，为提升现代深度学习中的泛化性能提供了一种通用且有效的方法。", "summary": "本研究提出了一种名为分布输入投影网络（DIPNet）的新框架，旨在解决过度参数化模型泛化能力不足的问题。DIPNet通过将输入投影到可学习的分布中来促进更平滑的损失景观，从而提升模型的泛化能力。理论分析和广泛的实证验证表明，DIPNet在各种架构和任务（包括ViTs和LLMs）中，能在标准设置、对抗性攻击、域外输入和推理基准测试中持续提高性能。该方法可以无缝集成到现有模型中，为提升深度学习模型的泛化能力提供了一种通用且有效的方法。", "keywords": "泛化, 分布式输入投影, 平滑性, 神经网络, DIPNet"}}
{"id": "2506.04364", "pdf": "https://arxiv.org/pdf/2506.04364", "abs": "https://arxiv.org/abs/2506.04364", "authors": ["Zheng-Xin Yong", "Vineel Pratap", "Michael Auli", "Jean Maillard"], "title": "Effects of Speaker Count, Duration, and Accent Diversity on Zero-Shot Accent Robustness in Low-Resource ASR", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to INTERSPEECH 2025", "summary": "To build an automatic speech recognition (ASR) system that can serve everyone\nin the world, the ASR needs to be robust to a wide range of accents including\nunseen accents. We systematically study how three different variables in\ntraining data -- the number of speakers, the audio duration per each individual\nspeaker, and the diversity of accents -- affect ASR robustness towards unseen\naccents in a low-resource training regime. We observe that for a fixed number\nof ASR training hours, it is more beneficial to increase the number of speakers\n(which means each speaker contributes less) than the number of hours\ncontributed per speaker. We also observe that more speakers enables ASR\nperformance gains from scaling number of hours. Surprisingly, we observe\nminimal benefits to prioritizing speakers with different accents when the\nnumber of speakers is controlled. Our work suggests that practitioners should\nprioritize increasing the speaker count in ASR training data composition for\nnew languages.", "AI": {"title_translation": "说话人数量、时长和口音多样性对低资源ASR零样本口音鲁棒性的影响", "tldr": "在低资源ASR训练中，增加说话人数量比增加每位说话人的音频时长更能提高对未见口音的鲁棒性。", "motivation": "构建一个能够服务全球用户的自动语音识别（ASR）系统，需要对包括未见口音在内的广泛口音具有鲁棒性。", "method": "系统研究了训练数据中的三个变量——说话人数量、每位说话人的音频时长以及口音多样性——如何影响低资源训练条件下ASR对未见口音的鲁棒性。", "result": "在固定ASR训练小时数的情况下，增加说话人数量（意味着每位说话人贡献较少）比增加每位说话人贡献的小时数更有益。更多的说话人使得ASR性能能够从扩展小时数中获得提升。在说话人数量受控时，优先选择不同口音的说话人带来的益处微乎其微。", "conclusion": "建议在为新语言构建ASR训练数据时，实践者应优先增加说话人数量。", "translation": "为了构建一个能够服务全世界每个人的自动语音识别（ASR）系统，ASR需要对包括未见口音在内的广泛口音具有鲁棒性。我们系统地研究了训练数据中的三个不同变量——说话人数量、每位说话人的音频时长以及口音的多样性——如何影响低资源训练条件下ASR对未见口音的鲁棒性。我们观察到，在固定ASR训练小时数的情况下，增加说话人数量（这意味着每位说话人贡献较少）比增加每位说话人贡献的小时数更有益。我们还观察到，更多的说话人使得ASR性能能够从扩展小时数中获得提升。令人惊讶的是，我们观察到在说话人数量受控时，优先选择不同口音的说话人带来的益处微乎其微。我们的工作表明，实践者在为新语言构建ASR训练数据时，应优先增加说话人数量。", "summary": "本研究系统探讨了在低资源ASR训练中，说话人数量、每位说话人的音频时长和口音多样性对系统零样本口音鲁棒性的影响。研究发现，在固定总训练时数下，增加说话人数量比增加每位说话人的音频时长更能提升性能，并且更多的说话人有助于性能随训练时数的扩展而提升。然而，当说话人数量受控时，优先考虑口音多样性带来的益处不显著。因此，研究建议在低资源ASR训练中应优先增加说话人数量。", "keywords": "ASR, 零样本鲁棒性, 低资源, 说话人数量, 口音多样性"}}
{"id": "2506.04931", "pdf": "https://arxiv.org/pdf/2506.04931", "abs": "https://arxiv.org/abs/2506.04931", "authors": ["Lukas Picek", "Elisa Belotti", "Michal Bojda", "Ludek Bufka", "Vojtech Cermak", "Martin Dula", "Rostislav Dvorak", "Luboslav Hrdy", "Miroslav Jirik", "Vaclav Kocourek", "Josefa Krausova", "Jirı Labuda", "Jakub Straka", "Ludek Toman", "Vlado Trulık", "Martin Vana", "Miroslav Kutal"], "title": "CzechLynx: A Dataset for Individual Identification and Pose Estimation of the Eurasian Lynx", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We introduce CzechLynx, the first large-scale, open-access dataset for\nindividual identification, 2D pose estimation, and instance segmentation of the\nEurasian lynx (Lynx lynx). CzechLynx includes more than 30k camera trap images\nannotated with segmentation masks, identity labels, and 20-point skeletons and\ncovers 219 unique individuals across 15 years of systematic monitoring in two\ngeographically distinct regions: Southwest Bohemia and the Western Carpathians.\nTo increase the data variability, we create a complementary synthetic set with\nmore than 100k photorealistic images generated via a Unity-based pipeline and\ndiffusion-driven text-to-texture modeling, covering diverse environments,\nposes, and coat-pattern variations. To allow testing generalization across\nspatial and temporal domains, we define three tailored evaluation\nprotocols/splits: (i) geo-aware, (ii) time-aware open-set, and (iii) time-aware\nclosed-set. This dataset is targeted to be instrumental in benchmarking\nstate-of-the-art models and the development of novel methods for not just\nindividual animal re-identification.", "AI": {"title_translation": "CzechLynx：一个用于欧亚猞猁个体识别和姿态估计的数据集", "tldr": "引入了CzechLynx，一个用于欧亚猞猁个体识别、2D姿态估计和实例分割的大规模、开放获取数据集，包含真实和合成图像，并定义了专门的评估协议。", "motivation": "目前缺乏用于欧亚猞猁个体识别和姿态估计的大规模、开放获取数据集，这阻碍了相关领域最先进模型的发展和基准测试。", "method": "该数据集包含超过3万张带有分割掩码、身份标签和20点骨骼标注的相机陷阱图像，覆盖219个个体，跨越15年的系统监测。为了增加数据多样性，还创建了一个包含超过10万张逼真图像的补充合成数据集，这些图像通过基于Unity的管道和扩散驱动的文本到纹理建模生成。定义了三种定制的评估协议/拆分：(i)地理感知、(ii)时间感知开放集和(iii)时间感知封闭集，以测试跨空间和时间域的泛化能力。", "result": "成功构建了CzechLynx数据集，这是第一个用于欧亚猞猁个体识别、2D姿态估计和实例分割的大规模、开放获取数据集。该数据集包括真实图像和通过Unity及扩散模型生成的合成图像，并定义了用于泛化测试的评估协议。", "conclusion": "该数据集旨在成为最先进模型基准测试和开发新型个体动物再识别方法的重要工具。", "translation": "我们引入了CzechLynx，这是第一个用于欧亚猞猁（Lynx lynx）个体识别、2D姿态估计和实例分割的大规模、开放获取数据集。CzechLynx包含超过3万张相机陷阱图像，这些图像经过分割掩码、身份标签和20点骨骼标注，涵盖了在两个地理上不同的区域（西南波西米亚和西喀尔巴阡山脉）15年系统监测中219个独特的个体。为了增加数据变异性，我们创建了一个补充的合成数据集，其中包含通过基于Unity的管道和扩散驱动的文本到纹理建模生成的超过10万张逼真图像，涵盖了不同的环境、姿态和皮毛图案变异。为了允许测试跨空间和时间域的泛化能力，我们定义了三种定制的评估协议/拆分：(i)地理感知、(ii)时间感知开放集和(iii)时间感知封闭集。该数据集旨在成为最先进模型基准测试以及开发不仅限于个体动物再识别的新型方法的重要工具。", "summary": "本文介绍了CzechLynx，一个用于欧亚猞猁个体识别、2D姿态估计和实例分割的大规模、开放获取数据集。该数据集包含超过3万张带标注的真实相机陷阱图像和超过10万张通过Unity和扩散模型生成的合成图像，涵盖了219个独特的个体和15年的监测数据。为了测试模型在空间和时间上的泛化能力，作者定义了三种定制的评估协议。该数据集旨在为最先进模型的基准测试和新型动物再识别方法的开发提供支持。", "keywords": "欧亚猞猁, 数据集, 个体识别, 姿态估计, 实例分割"}}
{"id": "2506.04694", "pdf": "https://arxiv.org/pdf/2506.04694", "abs": "https://arxiv.org/abs/2506.04694", "authors": ["Jaeseung Heo", "Kyeongheung Yun", "Seokwon Yoon", "MoonJeong Park", "Jungseul Ok", "Dongwoo Kim"], "title": "Influence Functions for Edge Edits in Non-Convex Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Understanding how individual edges influence the behavior of graph neural\nnetworks (GNNs) is essential for improving their interpretability and\nrobustness. Graph influence functions have emerged as promising tools to\nefficiently estimate the effects of edge deletions without retraining. However,\nexisting influence prediction methods rely on strict convexity assumptions,\nexclusively consider the influence of edge deletions while disregarding edge\ninsertions, and fail to capture changes in message propagation caused by these\nmodifications. In this work, we propose a proximal Bregman response function\nspecifically tailored for GNNs, relaxing the convexity requirement and enabling\naccurate influence prediction for standard neural network architectures.\nFurthermore, our method explicitly accounts for message propagation effects and\nextends influence prediction to both edge deletions and insertions in a\nprincipled way. Experiments with real-world datasets demonstrate accurate\ninfluence predictions for different characteristics of GNNs. We further\ndemonstrate that the influence function is versatile in applications such as\ngraph rewiring and adversarial attacks.", "AI": {"title_translation": "非凸图神经网络中边编辑的影响函数", "tldr": "本文提出了一种适用于非凸GNN的近端Bregman响应函数，能够准确预测边删除和插入的影响，并考虑消息传播效应，提高了GNN的可解释性和鲁棒性。", "motivation": "理解单个边如何影响图神经网络（GNNs）的行为对于提高其可解释性和鲁棒性至关重要。现有的图影响函数依赖严格的凸性假设，仅考虑边删除的影响而忽略边插入，并且未能捕捉由这些修改引起的消息传播变化。", "method": "提出了一种专门为GNNs定制的近端Bregman响应函数，该函数放宽了凸性要求，并能对标准神经网络架构进行精确的影响预测。此外，该方法明确考虑了消息传播效应，并以原则性的方式将影响预测扩展到边删除和插入。", "result": "在真实世界数据集上的实验证明了对GNNs不同特性的准确影响预测。作者进一步证明了该影响函数在图重布线和对抗性攻击等应用中的多功能性。", "conclusion": "Not mentioned in abstract", "translation": "理解单个边如何影响图神经网络（GNNs）的行为对于提高其可解释性和鲁棒性至关重要。图影响函数已成为一种有前景的工具，可以在不重新训练的情况下有效估计边删除的影响。然而，现有的影响预测方法依赖严格的凸性假设，仅考虑边删除的影响而忽略边插入，并且未能捕捉由这些修改引起的消息传播变化。在这项工作中，我们提出了一种专门为GNNs定制的近端Bregman响应函数，放宽了凸性要求，并能够对标准神经网络架构进行精确的影响预测。此外，我们的方法明确考虑了消息传播效应，并以原则性的方式将影响预测扩展到边删除和插入。在真实世界数据集上的实验证明了对GNNs不同特性的准确影响预测。我们进一步证明了该影响函数在图重布线和对抗性攻击等应用中的多功能性。", "summary": "本研究提出了一种针对图神经网络（GNNs）的近端Bregman响应函数，旨在解决现有影响函数在非凸性、边插入和消息传播效应方面的局限性。新方法能够准确预测非凸GNN中边删除和插入的影响，并考虑消息传播的变化。实验证明了该方法在真实数据集上的准确性，并展示了其在图重布线和对抗性攻击等应用中的多功能性，从而提高了GNN的可解释性和鲁棒性。", "keywords": "影响函数, 图神经网络, 边编辑, 非凸性, 可解释性"}}
{"id": "2506.04385", "pdf": "https://arxiv.org/pdf/2506.04385", "abs": "https://arxiv.org/abs/2506.04385", "authors": ["Kurt Micallef", "Claudia Borg"], "title": "MELABenchv1: Benchmarking Large Language Models against Smaller Fine-Tuned Models for Low-Resource Maltese NLP", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Findings Camera-Ready", "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious Natural Language Processing (NLP) tasks, largely due to their\ngeneralisability and ability to perform tasks without additional training.\nHowever, their effectiveness for low-resource languages remains limited. In\nthis study, we evaluate the performance of 55 publicly available LLMs on\nMaltese, a low-resource language, using a newly introduced benchmark covering\n11 discriminative and generative tasks. Our experiments highlight that many\nmodels perform poorly, particularly on generative tasks, and that smaller\nfine-tuned models often perform better across all tasks. From our\nmultidimensional analysis, we investigate various factors impacting\nperformance. We conclude that prior exposure to Maltese during pre-training and\ninstruction-tuning emerges as the most important factor. We also examine the\ntrade-offs between fine-tuning and prompting, highlighting that while\nfine-tuning requires a higher initial cost, it yields better performance and\nlower inference costs. Through this work, we aim to highlight the need for more\ninclusive language technologies and recommend that researchers working with\nlow-resource languages consider more \"traditional\" language modelling\napproaches.", "AI": {"title_translation": "MELABenchv1：针对低资源马耳他语自然语言处理，对大型语言模型与小型微调模型进行基准测试", "tldr": "本研究评估了55个大型语言模型在马耳他语（一种低资源语言）上的表现，发现许多模型表现不佳，特别是生成任务，而小型微调模型通常表现更好。预训练和指令调优期间对马耳他语的接触是关键因素。研究建议低资源语言应考虑更“传统”的语言建模方法。", "motivation": "尽管大型语言模型（LLMs）在各种自然语言处理（NLP）任务中表现出色，但它们在低资源语言方面的有效性仍然有限。", "method": "本研究使用一个新引入的基准，涵盖11个判别性和生成性任务，评估了55个公开可用的LLMs在马耳他语上的性能。进行了多维分析，调查影响性能的各种因素，并检查了微调和提示之间的权衡。", "result": "许多LLMs在马耳他语上表现不佳，尤其是在生成任务上。小型微调模型通常在所有任务中表现更好。预训练和指令调优期间对马耳他语的先前接触是影响性能的最重要因素。微调虽然初始成本较高，但能带来更好的性能和更低的推理成本。", "conclusion": "本研究强调了对更具包容性的语言技术的需求，并建议研究人员在处理低资源语言时考虑更“传统”的语言建模方法。", "translation": "大型语言模型（LLMs）在各种自然语言处理（NLP）任务中表现出卓越的性能，这主要归因于它们的泛化能力和无需额外训练即可执行任务的能力。然而，它们对低资源语言的有效性仍然有限。在本研究中，我们使用一个新引入的基准，涵盖11个判别性和生成性任务，评估了55个公开可用的LLMs在马耳他语（一种低资源语言）上的性能。我们的实验表明，许多模型表现不佳，特别是在生成任务上，而小型微调模型通常在所有任务中表现更好。通过我们的多维分析，我们调查了影响性能的各种因素。我们得出结论，预训练和指令调优期间对马耳他语的先前接触是最重要的因素。我们还检查了微调和提示之间的权衡，强调虽然微调需要更高的初始成本，但它能产生更好的性能和更低的推理成本。通过这项工作，我们旨在强调对更具包容性的语言技术的需求，并建议研究人员在处理低资源语言时考虑更“传统”的语言建模方法。", "summary": "本研究介绍了MELABenchv1，一个用于评估大型语言模型（LLMs）在低资源马耳他语自然语言处理（NLP）任务上性能的新基准。通过对55个LLMs在11项判别性和生成性任务上的评估，发现许多LLMs表现不佳，特别是生成任务，而小型微调模型通常表现更优。研究指出，模型在预训练和指令调优阶段对马耳他语的接触是影响性能的关键因素。此外，研究还探讨了微调和提示之间的权衡，强调微调尽管初始成本较高，但能提供更好的性能和更低的推理成本。本工作旨在呼吁开发更具包容性的语言技术，并建议低资源语言研究者考虑采用更传统的语言建模方法。", "keywords": "大型语言模型, 低资源语言, 马耳他语NLP, 基准测试, 微调"}}
{"id": "2506.04950", "pdf": "https://arxiv.org/pdf/2506.04950", "abs": "https://arxiv.org/abs/2506.04950", "authors": ["Yong Sun", "Yipeng Wang", "Junyu Shi", "Zhiyuan Zhang", "Yanmei Xiao", "Lei Zhu", "Manxi Jiang", "Qiang Nie"], "title": "Time-Lapse Video-Based Embryo Grading via Complementary Spatial-Temporal Pattern Mining", "categories": ["cs.CV"], "comment": null, "summary": "Artificial intelligence has recently shown promise in automated embryo\nselection for In-Vitro Fertilization (IVF). However, current approaches either\naddress partial embryo evaluation lacking holistic quality assessment or target\nclinical outcomes inevitably confounded by extra-embryonic factors, both\nlimiting clinical utility. To bridge this gap, we propose a new task called\nVideo-Based Embryo Grading - the first paradigm that directly utilizes\nfull-length time-lapse monitoring (TLM) videos to predict embryologists'\noverall quality assessments. To support this task, we curate a real-world\nclinical dataset comprising over 2,500 TLM videos, each annotated with a\ngrading label indicating the overall quality of embryos. Grounded in clinical\ndecision-making principles, we propose a Complementary Spatial-Temporal Pattern\nMining (CoSTeM) framework that conceptually replicates embryologists'\nevaluation process. The CoSTeM comprises two branches: (1) a morphological\nbranch using a Mixture of Cross-Attentive Experts layer and a Temporal\nSelection Block to select discriminative local structural features, and (2) a\nmorphokinetic branch employing a Temporal Transformer to model global\ndevelopmental trajectories, synergistically integrating static and dynamic\ndeterminants for grading embryos. Extensive experimental results demonstrate\nthe superiority of our design. This work provides a valuable methodological\nframework for AI-assisted embryo selection. The dataset and source code will be\npublicly available upon acceptance.", "AI": {"title_translation": "基于延时视频和互补时空模式挖掘的胚胎分级", "tldr": "本研究提出了一种基于延时视频的胚胎分级新任务，并开发了CoSTeM框架，通过整合形态学和形态动力学信息，实现对胚胎整体质量的预测，优于现有方法。", "motivation": "目前的AI辅助胚胎选择方法存在局限性，要么只进行部分胚胎评估，缺乏整体质量评估，要么针对受胚胎外因素影响的临床结果，从而限制了临床实用性。为了弥补这一空白，本研究提出了基于视频的胚胎分级新任务。", "method": "本研究提出了“基于视频的胚胎分级”新任务，利用全长延时监测（TLM）视频预测胚胎学家的整体质量评估。为此，研究构建了一个包含2500多个TLM视频的真实临床数据集，并提出了“互补时空模式挖掘（CoSTeM）”框架。CoSTeM包含两个分支：形态学分支（使用交叉注意力专家混合层和时间选择块选择判别性局部结构特征）和形态动力学分支（使用时间Transformer建模全局发育轨迹），协同整合静态和动态决定因素进行胚胎分级。", "result": "广泛的实验结果表明了本设计方法的优越性。", "conclusion": "这项工作为AI辅助胚胎选择提供了一个有价值的方法论框架。", "translation": "人工智能最近在体外受精（IVF）的自动化胚胎选择中显示出前景。然而，目前的方法要么只进行部分胚胎评估，缺乏整体质量评估，要么针对不可避免地受到胚胎外因素混淆的临床结果，两者都限制了临床实用性。为了弥补这一空白，我们提出了一项名为“基于视频的胚胎分级”的新任务——这是第一个直接利用全长延时监测（TLM）视频来预测胚胎学家整体质量评估的范例。为了支持这项任务，我们整理了一个包含2500多个TLM视频的真实世界临床数据集，每个视频都标注有指示胚胎整体质量的分级标签。基于临床决策原则，我们提出了一种“互补时空模式挖掘（CoSTeM）”框架，它概念性地复制了胚胎学家的评估过程。CoSTeM包含两个分支：（1）一个形态学分支，使用交叉注意力专家混合层和时间选择块来选择判别性局部结构特征；（2）一个形态动力学分支，采用时间Transformer来建模全局发育轨迹，协同整合静态和动态决定因素进行胚胎分级。广泛的实验结果证明了我们设计的优越性。这项工作为AI辅助胚胎选择提供了一个有价值的方法论框架。数据集和源代码将在接受后公开。", "summary": "本研究旨在解决当前AI辅助胚胎选择中整体质量评估不足和受外部因素干扰的问题，首次提出了“基于视频的胚胎分级”任务。通过收集包含2500多个延时监测视频的临床数据集，并开发了“互补时空模式挖掘（CoSTeM）”框架。CoSTeM框架包含形态学和形态动力学两个分支，分别处理局部结构特征和全局发育轨迹，以协同预测胚胎的整体质量。实验结果证明了该方法的优越性，为AI辅助胚胎选择提供了有价值的方法论框架。", "keywords": "延时视频, 胚胎分级, 互补时空模式挖掘, 体外受精, 人工智能"}}
{"id": "2506.04695", "pdf": "https://arxiv.org/pdf/2506.04695", "abs": "https://arxiv.org/abs/2506.04695", "authors": ["Xingwu Chen", "Tianle Li", "Difan Zou"], "title": "On the Mechanism of Reasoning Pattern Selection in Reinforcement Learning for Language Models", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "30 pages, 6 figures, 1 table", "summary": "Reinforcement learning (RL) has demonstrated remarkable success in enhancing\nmodel capabilities, including instruction-following, preference learning, and\nreasoning. Yet despite its empirical successes, the mechanisms by which RL\nimproves reasoning abilities remain poorly understood. We present a systematic\nstudy of Reinforcement Learning with Verifiable Rewards (RLVR), showing that\nits primary benefit comes from optimizing the selection of existing reasoning\npatterns. Through extensive experiments, we demonstrate that RLVR-trained\nmodels preferentially adopt high-success-rate reasoning patterns while mostly\nmaintaining stable performance on individual patterns. We further develop\ntheoretical analyses on the convergence and training dynamics of RLVR based on\na simplified question-reason-answer model. We study the gradient flow and show\nthat RLVR can indeed find the solution that selects the reason pattern with the\nhighest success rate. Besides, our theoretical results\n  reveal two distinct regimes regarding the convergence of RLVR training: (1)\nrapid convergence for models with relatively strong initial reasoning\ncapabilities versus (2) slower optimization dynamics for weaker models.\nFurthermore, we show that the slower optimization for weaker models can be\nmitigated by applying the supervised fine-tuning (SFT) before RLVR, when using\na feasibly high-quality SFT dataset. We validate the theoretical findings\nthrough extensive experiments. This work advances our theoretical understanding\nof RL's role in LLM fine-tuning and offers insights for further enhancing\nreasoning capabilities.", "AI": {"title_translation": "语言模型强化学习中推理模式选择机制研究", "tldr": "本文系统研究了可验证奖励强化学习（RLVR）在语言模型推理能力提升中的作用机制，发现其主要通过优化现有推理模式的选择来实现，并提出了理论分析和实验验证。", "motivation": "尽管强化学习（RL）在提升语言模型能力（包括推理）方面取得了显著成功，但其改善推理能力的具体机制尚不明确。", "method": "本文对可验证奖励强化学习（RLVR）进行了系统研究，通过实验证明其优化了现有推理模式的选择。进一步，基于简化的问答模型，进行了RLVR收敛性和训练动态的理论分析，并研究了梯度流。", "result": "RLVR的主要益处在于优化现有推理模式的选择。RLVR训练的模型倾向于采用高成功率的推理模式，同时保持个体模式的稳定性能。理论分析揭示了RLVR训练的两种收敛机制：初始推理能力强的模型收敛迅速，而较弱的模型优化动态较慢。通过高质量的SFT数据集在RLVR之前进行SFT可以缓解弱模型的优化速度慢的问题。", "conclusion": "本工作加深了对强化学习在大型语言模型微调中作用的理论理解，并为进一步提升推理能力提供了见解。", "translation": "强化学习（RL）在增强模型能力方面取得了显著成功，包括遵循指令、偏好学习和推理。然而，尽管其在经验上取得了成功，但RL改善推理能力的机制仍然知之甚少。我们对可验证奖励强化学习（RLVR）进行了系统研究，表明其主要益处来自于优化现有推理模式的选择。通过大量实验，我们证明了RLVR训练的模型优先采用高成功率的推理模式，同时在个体模式上基本保持稳定的性能。我们进一步基于简化的问答模型，对RLVR的收敛性和训练动态进行了理论分析。我们研究了梯度流，并表明RLVR确实可以找到选择成功率最高的推理模式的解决方案。此外，我们的理论结果揭示了RLVR训练收敛的两种不同机制：（1）初始推理能力相对较强的模型快速收敛，而（2）较弱模型的优化动态较慢。此外，我们表明，当使用高质量的SFT数据集时，通过在RLVR之前应用监督微调（SFT）可以缓解弱模型的较慢优化。我们通过大量实验验证了理论发现。这项工作提升了我们对RL在大型语言模型微调中作用的理论理解，并为进一步增强推理能力提供了见解。", "summary": "本文深入探讨了强化学习（RL）提升语言模型推理能力的机制，特别是针对可验证奖励强化学习（RLVR）。研究发现，RLVR主要通过优化现有推理模式的选择来提高模型性能，而非改变单个模式的内部表现。通过实验和理论分析，揭示了RLVR训练过程中两种不同的收敛速度，并提出在RLVR前结合高质量的监督微调（SFT）可以有效加速弱模型的优化。这项工作增进了对RL在LLM微调中作用的理解，并为增强推理能力提供了新思路。", "keywords": "强化学习, 语言模型, 推理模式选择, 可验证奖励, 监督微调"}}
{"id": "2506.04951", "pdf": "https://arxiv.org/pdf/2506.04951", "abs": "https://arxiv.org/abs/2506.04951", "authors": ["Igor Meleshin", "Anna Chistyakova", "Anastasia Antsiferova", "Dmitriy Vatolin"], "title": "Robustness as Architecture: Designing IQA Models to Withstand Adversarial Perturbations", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Image Quality Assessment (IQA) models are increasingly relied upon to\nevaluate image quality in real-world systems -- from compression and\nenhancement to generation and streaming. Yet their adoption brings a\nfundamental risk: these models are inherently unstable. Adversarial\nmanipulations can easily fool them, inflating scores and undermining trust.\nTraditionally, such vulnerabilities are addressed through data-driven defenses\n-- adversarial retraining, regularization, or input purification. But what if\nthis is the wrong lens? What if robustness in perceptual models is not\nsomething to learn but something to design? In this work, we propose a\nprovocative idea: robustness as an architectural prior. Rather than training\nmodels to resist perturbations, we reshape their internal structure to suppress\nsensitivity from the ground up. We achieve this by enforcing orthogonal\ninformation flow, constraining the network to norm-preserving operations -- and\nfurther stabilizing the system through pruning and fine-tuning. The result is a\nrobust IQA architecture that withstands adversarial attacks without requiring\nadversarial training or significant changes to the original model. This\napproach suggests a shift in perspective: from optimizing robustness through\ndata to engineering it through design.", "AI": {"title_translation": "鲁棒性即架构：设计能抵御对抗性扰动的IQA模型", "tldr": "本文提出一种通过架构设计而非对抗训练来提升图像质量评估（IQA）模型鲁棒性的方法。", "motivation": "图像质量评估（IQA）模型在实际系统中应用广泛，但其固有的不稳定性使其容易受到对抗性攻击，导致评估分数虚高，损害用户信任。传统方法依赖数据驱动的防御，但作者认为这可能不是最佳途径。", "method": "提出将鲁棒性作为架构先验，通过重塑模型内部结构来从根本上抑制敏感性。具体方法包括强制正交信息流、约束网络进行范数保留操作，并通过剪枝和微调进一步稳定系统。", "result": "结果是构建了一个鲁棒的IQA架构，能够抵御对抗性攻击，而无需对抗训练或对原始模型进行重大修改。", "conclusion": "该方法表明了从通过数据优化鲁棒性转向通过设计来工程化鲁棒性的视角转变。", "translation": "图像质量评估（IQA）模型在现实世界系统中（从压缩和增强到生成和流媒体）越来越依赖于评估图像质量。然而，它们的采用带来了一个根本性的风险：这些模型本身是不稳定的。对抗性操纵可以轻易地欺骗它们，夸大分数并损害信任。传统上，这种漏洞通过数据驱动的防御来解决——对抗性再训练、正则化或输入净化。但如果这不是正确的视角呢？如果感知模型中的鲁棒性不是需要学习的东西，而是需要设计的东西呢？在这项工作中，我们提出了一个具有启发性的想法：鲁棒性作为一种架构先验。我们不是训练模型来抵抗扰动，而是重塑它们的内部结构，从根本上抑制敏感性。我们通过强制正交信息流，约束网络进行范数保留操作来实现这一点——并通过剪枝和微调进一步稳定系统。结果是一个鲁棒的IQA架构，它能够抵御对抗性攻击，而无需对抗训练或对原始模型进行重大更改。这种方法表明了视角的转变：从通过数据优化鲁棒性转向通过设计来工程化鲁棒性。", "summary": "本文针对图像质量评估（IQA）模型易受对抗性攻击的问题，提出了一种新颖的“鲁棒性即架构”设计理念。不同于传统的数据驱动防御，作者通过强制正交信息流和范数保留操作等方式，从内部结构上增强模型的鲁棒性，并通过剪枝和微调进一步稳定系统。实验结果表明，该方法无需对抗训练即可使IQA模型有效抵御对抗性扰动，为鲁棒性设计提供了新的视角。", "keywords": "图像质量评估, 鲁棒性, 对抗性攻击, 架构设计, 正交信息流"}}
{"id": "2506.04696", "pdf": "https://arxiv.org/pdf/2506.04696", "abs": "https://arxiv.org/abs/2506.04696", "authors": ["Tonmoy Paul", "Mrittika Devi Mati", "Md. Mahmudul Islam"], "title": "Enhanced Drought Analysis in Bangladesh: A Machine Learning Approach for Severity Classification Using Satellite Data", "categories": ["cs.LG"], "comment": null, "summary": "Drought poses a pervasive environmental challenge in Bangladesh, impacting\nagriculture, socio-economic stability, and food security due to its unique\ngeographic and anthropogenic vulnerabilities. Traditional drought indices, such\nas the Standardized Precipitation Index (SPI) and Palmer Drought Severity Index\n(PDSI), often overlook crucial factors like soil moisture and temperature,\nlimiting their resolution. Moreover, current machine learning models applied to\ndrought prediction have been underexplored in the context of Bangladesh,\nlacking a comprehensive integration of satellite data across multiple\ndistricts. To address these gaps, we propose a satellite data-driven machine\nlearning framework to classify drought across 38 districts of Bangladesh. Using\nunsupervised algorithms like K-means and Bayesian Gaussian Mixture for\nclustering, followed by classification models such as KNN, Random Forest,\nDecision Tree, and Naive Bayes, the framework integrates weather data\n(humidity, soil moisture, temperature) from 2012-2024. This approach\nsuccessfully classifies drought severity into different levels. However, it\nshows significant variabilities in drought vulnerabilities across regions which\nhighlights the aptitude of machine learning models in terms of identifying and\npredicting drought conditions.", "AI": {"title_translation": "孟加拉国增强型干旱分析：一种利用卫星数据进行严重性分类的机器学习方法", "tldr": "本文提出了一种基于卫星数据的机器学习框架，用于分类孟加拉国不同地区的干旱严重程度，以解决传统方法和现有机器学习模型的局限性。", "motivation": "干旱对孟加拉国农业、社会经济稳定和粮食安全构成普遍挑战。传统干旱指数（如SPI和PDSI）忽略土壤湿度和温度等关键因素，分辨率有限。现有应用于孟加拉国干旱预测的机器学习模型对卫星数据的综合利用不足。", "method": "提出了一种卫星数据驱动的机器学习框架，用于对孟加拉国38个地区的干旱进行分类。该框架使用K-means和贝叶斯高斯混合等无监督算法进行聚类，并结合KNN、随机森林、决策树和朴素贝叶斯等分类模型。整合了2012-2024年的气象数据（湿度、土壤湿度、温度）。", "result": "该方法成功地将干旱严重程度分为不同级别。研究结果显示，孟加拉国不同地区的干旱脆弱性存在显著差异。", "conclusion": "机器学习模型在识别和预测干旱状况方面表现出强大的能力。", "translation": "干旱对孟加拉国构成普遍的环境挑战，由于其独特的地理和人为脆弱性，影响着农业、社会经济稳定和粮食安全。标准化降水指数（SPI）和帕尔默干旱严重程度指数（PDSI）等传统干旱指数通常忽略土壤湿度和温度等关键因素，限制了它们的分辨率。此外，目前应用于干旱预测的机器学习模型在孟加拉国背景下尚未得到充分探索，缺乏对多个地区卫星数据的全面整合。为了解决这些空白，我们提出了一个卫星数据驱动的机器学习框架，用于对孟加拉国38个地区的干旱进行分类。该框架使用K-means和贝叶斯高斯混合等无监督算法进行聚类，然后使用KNN、随机森林、决策树和朴素贝叶斯等分类模型，整合了2012-2024年的气象数据（湿度、土壤湿度、温度）。这种方法成功地将干旱严重程度分为不同级别。然而，它显示出不同地区干旱脆弱性存在显著差异，这突出了机器学习模型在识别和预测干旱状况方面的能力。", "summary": "鉴于孟加拉国干旱的普遍影响和传统干旱分析方法的局限性，本文提出了一种利用卫星数据和机器学习的综合框架，旨在对该国38个地区的干旱严重程度进行分类。该框架结合了聚类（K-means, Bayesian Gaussian Mixture）和分类（KNN, Random Forest, Decision Tree, Naive Bayes）算法，并整合了2012-2024年的气象数据。研究成功地将干旱严重程度划分为不同级别，并揭示了地区间干旱脆弱性的显著差异，验证了机器学习在干旱识别和预测中的潜力。", "keywords": "干旱分析, 机器学习, 卫星数据, 干旱分类, 孟加拉国"}}
{"id": "2506.04953", "pdf": "https://arxiv.org/pdf/2506.04953", "abs": "https://arxiv.org/abs/2506.04953", "authors": ["Hong Gao", "Yiming Bao", "Xuezhan Tu", "Bin Zhong", "Minling Zhang"], "title": "APVR: Hour-Level Long Video Understanding with Adaptive Pivot Visual Information Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Current video-based multimodal large language models struggle with hour-level\nvideo understanding due to computational constraints and inefficient\ninformation extraction from extensive temporal sequences. We propose APVR\n(Adaptive Pivot Visual information Retrieval), a training-free framework that\naddresses the memory wall limitation through hierarchical visual information\nretrieval. APVR operates via two complementary components: Pivot Frame\nRetrieval employs semantic expansion and multi-modal confidence scoring to\nidentify semantically relevant video frames, while Pivot Token Retrieval\nperforms query-aware attention-driven token selection within the pivot frames.\nThis dual granularity approach enables processing of hour-long videos while\nmaintaining semantic fidelity. Experimental validation on LongVideoBench and\nVideoMME demonstrates significant performance improvements, establishing\nstate-of-the-art results for not only training-free but also training-based\napproaches while providing plug-and-play integration capability with existing\nMLLM architectures.", "AI": {"title_translation": "APVR: 基于自适应支点视觉信息检索的小时级长视频理解", "tldr": "APVR通过分层视觉信息检索，解决了现有视频MLLM在小时级视频理解中的计算和信息提取限制，实现了最先进的性能。", "motivation": "当前基于视频的多模态大语言模型（MLLM）在小时级视频理解方面面临计算限制和从大量时间序列中进行低效信息提取的困难。", "method": "本文提出了APVR（自适应支点视觉信息检索），一个免训练的框架，通过分层视觉信息检索解决内存墙限制。APVR包含两个互补组件：支点帧检索（Pivot Frame Retrieval）利用语义扩展和多模态置信度评分来识别语义相关的视频帧；支点令牌检索（Pivot Token Retrieval）在支点帧内执行查询感知注意力驱动的令牌选择。这种双粒度方法能够处理小时级视频并保持语义保真度。", "result": "在LongVideoBench和VideoMME上进行了实验验证，结果显示出显著的性能改进，不仅在免训练方法中，而且在基于训练的方法中都达到了最先进的结果，并提供了与现有MLLM架构的即插即用集成能力。", "conclusion": "APVR通过其分层视觉信息检索方法，有效解决了小时级视频理解的挑战，并在多个基准测试中实现了卓越的性能，证明了其作为现有MLLM架构的通用且高效的增强方案的潜力。", "translation": "当前基于视频的多模态大语言模型（MLLM）由于计算限制和从大量时间序列中低效提取信息，在小时级视频理解方面面临困难。我们提出了APVR（自适应支点视觉信息检索），一个免训练的框架，通过分层视觉信息检索解决内存墙限制。APVR通过两个互补的组件运作：支点帧检索（Pivot Frame Retrieval）利用语义扩展和多模态置信度评分来识别语义相关的视频帧，而支点令牌检索（Pivot Token Retrieval）在支点帧内执行查询感知注意力驱动的令牌选择。这种双粒度方法能够处理小时级视频，同时保持语义保真度。在LongVideoBench和VideoMME上的实验验证表明，APVR取得了显著的性能改进，不仅在免训练方法中，而且在基于训练的方法中都取得了最先进的结果，同时提供了与现有MLLM架构的即插即用集成能力。", "summary": "该论文提出了APVR，一个免训练的框架，用于解决当前多模态大语言模型在小时级视频理解中面临的计算和信息提取效率问题。APVR通过支点帧检索和支点令牌检索实现分层视觉信息检索，从而在处理长视频时保持语义完整性。实验结果表明，APVR在长视频理解方面取得了最先进的性能，并能与现有模型无缝集成。", "keywords": "小时级视频理解, 多模态大语言模型, 视觉信息检索, 免训练, 支点帧"}}
{"id": "2506.04700", "pdf": "https://arxiv.org/pdf/2506.04700", "abs": "https://arxiv.org/abs/2506.04700", "authors": ["José Manuel de Frutos", "Manuel A. Vázquez", "Pablo M. Olmos", "Joaquín Míguez"], "title": "Explicit Density Approximation for Neural Implicit Samplers Using a Bernstein-Based Convex Divergence", "categories": ["cs.LG", "cs.AI", "math.PR", "stat.ML"], "comment": null, "summary": "Rank-based statistical metrics, such as the invariant statistical loss (ISL),\nhave recently emerged as robust and practically effective tools for training\nimplicit generative models. In this work, we introduce dual-ISL, a novel\nlikelihood-free objective for training implicit generative models that\ninterchanges the roles of the target and model distributions in the ISL\nframework, yielding a convex optimization problem in the space of model\ndensities. We prove that the resulting rank-based discrepancy $d_K$ is i)\ncontinuous under weak convergence and with respect to the $L^1$ norm, and ii)\nconvex in its first argument-properties not shared by classical divergences\nsuch as KL or Wasserstein distances. Building on this, we develop a theoretical\nframework that interprets $d_K$ as an $L^2$-projection of the density ratio $q\n= p/\\tilde p$ onto a Bernstein polynomial basis, from which we derive exact\nbounds on the truncation error, precise convergence rates, and a closed-form\nexpression for the truncated density approximation. We further extend our\nanalysis to the multivariate setting via random one-dimensional projections,\ndefining a sliced dual-ISL divergence that retains both convexity and\ncontinuity. We empirically show that these theoretical advantages translate\ninto practical ones. Specifically, across several benchmarks dual-ISL converges\nmore rapidly, delivers markedly smoother and more stable training, and more\neffectively prevents mode collapse than classical ISL and other leading\nimplicit generative methods-while also providing an explicit density\napproximation.", "AI": {"title_translation": "使用基于伯恩斯坦的凸散度对神经隐式采样器进行显式密度近似", "tldr": "本研究引入了一种名为dual-ISL的新型无似然目标，用于训练隐式生成模型。它通过将ISL框架中目标和模型分布的角色互换，生成了一个凸优化问题，并提供了显式密度近似，在收敛速度、训练稳定性和模式崩溃预防方面优于现有方法。", "motivation": "现有的基于排名的统计指标（如不变统计损失ISL）在训练隐式生成模型方面虽然有效，但可能存在非凸性或缺乏显式密度近似的问题。本研究旨在通过引入dual-ISL来解决这些问题，提供一个凸优化问题并实现显式密度近似。", "method": "本研究引入了dual-ISL，这是一种新颖的无似然目标，通过互换ISL框架中目标和模型分布的角色，从而产生一个模型密度空间中的凸优化问题。该方法将由此产生的基于排名的差异d_K解释为密度比q=p/p~在伯恩斯坦多项式基上的L^2投影，并在此基础上推导出截断误差的精确界限、精确收敛速度和截断密度近似的闭合形式表达式。此外，通过随机一维投影将分析扩展到多变量设置，定义了切片dual-ISL散度，该散度保留了凸性和连续性。", "result": "理论上，由此产生的基于排名的差异d_K在弱收敛和L^1范数下是连续的，并且在其第一个参数中是凸的，这些特性是经典散度（如KL或Wasserstein距离）所不具备的。该框架推导出了截断误差的精确界限、精确收敛速度以及截断密度近似的闭合形式表达式。切片dual-ISL散度保留了凸性和连续性。在实践中，dual-ISL在几个基准测试中收敛更快，提供了明显更平滑和更稳定的训练，并且比经典的ISL和其他领先的隐式生成方法更有效地防止了模式崩溃，同时还提供了显式密度近似。", "conclusion": "dual-ISL的理论优势转化为实际优势，使其在训练隐式生成模型方面表现出更快的收敛速度、更高的训练稳定性、更强的模式崩溃预防能力，并能提供显式密度近似，优于现有方法。", "translation": "基于排名的统计指标，例如不变统计损失（ISL），最近已成为训练隐式生成模型的稳健且实际有效的工具。在这项工作中，我们引入了dual-ISL，一种新颖的无似然目标，用于训练隐式生成模型，它在ISL框架中互换了目标和模型分布的角色，从而在模型密度空间中产生了一个凸优化问题。我们证明了由此产生的基于排名的差异d_K在弱收敛和L^1范数下是连续的，并且在其第一个参数中是凸的——这些性质是KL或Wasserstein距离等经典散度所不具备的。在此基础上，我们开发了一个理论框架，将d_K解释为密度比q = p/p~在伯恩斯坦多项式基上的L^2投影，并从中推导出截断误差的精确界限、精确收敛速度和截断密度近似的闭合形式表达式。我们通过随机一维投影进一步将分析扩展到多变量设置，定义了一个切片dual-ISL散度，该散度保留了凸性和连续性。我们经验性地表明，这些理论优势转化为实际优势。具体来说，在几个基准测试中，dual-ISL收敛更快，提供了明显更平滑和更稳定的训练，并且比经典的ISL和其他领先的隐式生成方法更有效地防止了模式崩溃——同时还提供了显式密度近似。", "summary": "本论文提出了一种名为dual-ISL的新型无似然目标，用于训练隐式生成模型。通过在不变统计损失(ISL)框架中互换目标和模型分布的角色，dual-ISL产生了一个模型密度空间中的凸优化问题。研究证明了所产生的基于排名的差异d_K的连续性和凸性，并建立了一个理论框架，将其解释为密度比在伯恩斯坦多项式基上的L^2投影，从而推导出精确的误差界限和收敛率。该方法还扩展到多变量设置。实验结果表明，dual-ISL在收敛速度、训练稳定性和模式崩溃预防方面均优于传统ISL及其他主流方法，并能提供显式密度近似。", "keywords": "dual-ISL, 隐式生成模型, 密度近似, 伯恩斯坦多项式, 凸散度"}}
{"id": "2506.04956", "pdf": "https://arxiv.org/pdf/2506.04956", "abs": "https://arxiv.org/abs/2506.04956", "authors": ["Huihan Wang", "Zhiwen Yang", "Hui Zhang", "Dan Zhao", "Bingzheng Wei", "Yan Xu"], "title": "FEAT: Full-Dimensional Efficient Attention Transformer for Medical Video Generation", "categories": ["cs.CV"], "comment": "This paper has been early accepted by MICCAI 2025", "summary": "Synthesizing high-quality dynamic medical videos remains a significant\nchallenge due to the need for modeling both spatial consistency and temporal\ndynamics. Existing Transformer-based approaches face critical limitations,\nincluding insufficient channel interactions, high computational complexity from\nself-attention, and coarse denoising guidance from timestep embeddings when\nhandling varying noise levels. In this work, we propose FEAT, a\nfull-dimensional efficient attention Transformer, which addresses these issues\nthrough three key innovations: (1) a unified paradigm with sequential\nspatial-temporal-channel attention mechanisms to capture global dependencies\nacross all dimensions, (2) a linear-complexity design for attention mechanisms\nin each dimension, utilizing weighted key-value attention and global channel\nattention, and (3) a residual value guidance module that provides fine-grained\npixel-level guidance to adapt to different noise levels. We evaluate FEAT on\nstandard benchmarks and downstream tasks, demonstrating that FEAT-S, with only\n23\\% of the parameters of the state-of-the-art model Endora, achieves\ncomparable or even superior performance. Furthermore, FEAT-L surpasses all\ncomparison methods across multiple datasets, showcasing both superior\neffectiveness and scalability. Code is available at\nhttps://github.com/Yaziwel/FEAT.", "AI": {"title_translation": "FEAT：用于医学视频生成的全维度高效注意力Transformer", "tldr": "FEAT是一种全维度高效注意力Transformer，通过统一的时空通道注意力机制、线性复杂度的注意力设计和残差值引导模块，解决了医学视频生成中现有Transformer方法的局限性，实现了与现有最佳模型相当或更优的性能。", "motivation": "由于需要建模空间一致性和时间动态性，合成高质量动态医学视频仍是一个重大挑战。现有基于Transformer的方法面临关键限制，包括通道交互不足、自注意力带来的高计算复杂性，以及在处理不同噪声水平时来自时间步嵌入的粗糙去噪指导。", "method": "本文提出了FEAT，一种全维度高效注意力Transformer，通过三项关键创新解决上述问题：1) 具有顺序时空通道注意力机制的统一范式，以捕获所有维度的全局依赖性；2) 每维度的线性复杂度注意力设计，利用加权键值注意力和全局通道注意力；3) 残差值引导模块，提供细粒度的像素级引导以适应不同噪声水平。", "result": "在标准基准和下游任务上评估了FEAT，结果表明，参数量仅为现有最佳模型Endora 23% 的FEAT-S实现了可比甚至更优的性能。此外，FEAT-L在多个数据集上超越了所有对比方法，展示了卓越的有效性和可扩展性。", "conclusion": "FEAT通过其创新的注意力机制和引导模块，有效克服了现有Transformer在医学视频生成中的局限性，并在性能和可扩展性方面均表现出色，为高质量动态医学视频合成提供了有效解决方案。", "translation": "由于需要建模空间一致性和时间动态性，合成高质量动态医学视频仍然是一个重大挑战。现有基于Transformer的方法面临关键限制，包括通道交互不足、自注意力带来的高计算复杂性，以及在处理不同噪声水平时来自时间步嵌入的粗糙去噪指导。在这项工作中，我们提出了FEAT，一种全维度高效注意力Transformer，它通过三项关键创新解决了这些问题：(1) 具有顺序时空通道注意力机制的统一范式，以捕获所有维度的全局依赖性；(2) 每维度的线性复杂度注意力设计，利用加权键值注意力和全局通道注意力；(3) 一个残差值引导模块，提供细粒度的像素级引导以适应不同的噪声水平。我们在标准基准和下游任务上评估了FEAT，结果表明，参数量仅为现有最佳模型Endora 23% 的FEAT-S实现了可比甚至更优的性能。此外，FEAT-L在多个数据集上超越了所有对比方法，展示了卓越的有效性和可扩展性。代码可在 https://github.com/Yaziwel/FEAT 获取。", "summary": "FEAT（全维度高效注意力Transformer）旨在解决高质量动态医学视频生成中的挑战，包括现有Transformer方法中通道交互不足、计算复杂性高以及去噪指导粗糙等问题。FEAT通过引入统一的顺序时空通道注意力机制、线性复杂度的注意力设计（利用加权键值注意力及全局通道注意力）和残差值引导模块（提供细粒度像素级指导）来克服这些限制。实验结果表明，FEAT-S以较少的参数实现了与现有最佳模型相当或更优的性能，而FEAT-L则在多个数据集上超越了所有对比方法，展示了卓越的有效性和可扩展性。", "keywords": "医学视频生成, Transformer, 注意力机制, 动态建模, 图像去噪"}}
{"id": "2506.04712", "pdf": "https://arxiv.org/pdf/2506.04712", "abs": "https://arxiv.org/abs/2506.04712", "authors": ["Pinak Mandal", "Georg A. Gottwald"], "title": "UNO: Unlearning via Orthogonalization in Generative models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As generative models become increasingly powerful and pervasive, the ability\nto unlearn specific data, whether due to privacy concerns, legal requirements,\nor the correction of harmful content, has become increasingly important. Unlike\nin conventional training, where data are accumulated and knowledge is\nreinforced, unlearning aims to selectively remove the influence of particular\ndata points without costly retraining from scratch. To be effective and\nreliable, such algorithms need to achieve (i) forgetting of the undesired data,\n(ii) preservation of the quality of the generation, (iii) preservation of the\ninfluence of the desired training data on the model parameters, and (iv) small\nnumber of training steps. We propose fast unlearning algorithms based on loss\ngradient orthogonalization. We show that our algorithms are able to forget data\nwhile maintaining the fidelity of the original model. Using MNIST and CelebA\ndata, we demonstrate that our algorithms achieve orders of magnitude faster\nunlearning times than their predecessors, such as gradient surgery.", "AI": {"title_translation": "UNO：生成模型中基于正交化的遗忘学习", "tldr": "提出了一种基于损失梯度正交化的快速遗忘学习算法UNO，能够在不影响模型质量的前提下，显著加速数据遗忘过程。", "motivation": "随着生成模型日益强大和普及，出于隐私、法律或纠正有害内容等原因，遗忘特定数据的能力变得越来越重要。与传统训练不同，遗忘学习旨在选择性地消除特定数据点的影响，而无需从头开始昂贵的再训练。有效的遗忘算法需要实现：遗忘不需要的数据、保持生成质量、保持期望训练数据对模型参数的影响，以及训练步骤少。", "method": "我们提出了基于损失梯度正交化的快速遗忘学习算法。", "result": "我们的算法能够遗忘数据，同时保持原始模型的保真度。在MNIST和CelebA数据集上，我们的算法比梯度手术等前辈实现了数量级更快的遗忘时间。", "conclusion": "所提出的基于损失梯度正交化的UNO算法能够高效、快速地实现生成模型的遗忘学习，同时保持模型性能。", "translation": "随着生成模型日益强大和普及，遗忘特定数据的能力变得越来越重要，无论是出于隐私问题、法律要求还是纠正有害内容。与传统训练中数据积累和知识强化不同，遗忘学习旨在选择性地消除特定数据点的影响，而无需从头开始昂贵的再训练。为了有效和可靠，此类算法需要实现：(i) 遗忘不需要的数据，(ii) 保持生成质量，(iii) 保持期望训练数据对模型参数的影响，以及 (iv) 少量训练步骤。我们提出了基于损失梯度正交化的快速遗忘学习算法。我们表明，我们的算法能够在遗忘数据的同时保持原始模型的保真度。使用MNIST和CelebA数据，我们证明了我们的算法比其前辈（如梯度手术）实现了数量级更快的遗忘时间。", "summary": "本论文提出了名为UNO的快速遗忘学习算法，该算法利用损失梯度正交化，旨在解决生成模型中遗忘特定数据的需求。该算法能够在遗忘不需要数据、保持生成质量和期望数据影响的同时，显著减少训练步骤。实验证明，UNO算法在MNIST和CelebA数据集上，比现有方法（如梯度手术）实现了数量级更快的遗忘速度。", "keywords": "遗忘学习, 生成模型, 正交化, 梯度手术, 数据隐私"}}
{"id": "2506.04405", "pdf": "https://arxiv.org/pdf/2506.04405", "abs": "https://arxiv.org/abs/2506.04405", "authors": ["Ran Xu", "Yuchen Zhuang", "Yishan Zhong", "Yue Yu", "Xiangru Tang", "Hang Wu", "May D. Wang", "Peifeng Ruan", "Donghan Yang", "Tao Wang", "Guanghua Xiao", "Carl Yang", "Yang Xie", "Wenqi Shi"], "title": "MedAgentGym: Training LLM Agents for Code-Based Medical Reasoning at Scale", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce MedAgentGYM, the first publicly available training environment\ndesigned to enhance coding-based medical reasoning capabilities in large\nlanguage model (LLM) agents. MedAgentGYM comprises 72,413 task instances across\n129 categories derived from authentic real-world biomedical scenarios. Tasks\nare encapsulated within executable coding environments, each featuring detailed\ntask descriptions, interactive feedback mechanisms, verifiable ground-truth\nannotations, and scalable training trajectory generation. Extensive\nbenchmarking of over 30 LLMs reveals a notable performance disparity between\ncommercial API-based models and open-source counterparts. Leveraging\nMedAgentGYM, Med-Copilot-7B achieves substantial performance gains through\nsupervised fine-tuning (+36.44%) and continued reinforcement learning\n(+42.47%), emerging as an affordable and privacy-preserving alternative\ncompetitive with gpt-4o. By offering both a comprehensive benchmark and\naccessible, expandable training resources within unified execution\nenvironments, MedAgentGYM delivers an integrated platform to develop LLM-based\ncoding assistants for advanced biomedical research and practice.", "AI": {"title_translation": "MedAgentGym：大规模训练基于代码的医疗推理LLM智能体", "tldr": "MedAgentGYM是一个用于训练LLM智能体进行基于代码的医疗推理的公开环境，包含大量真实生物医学任务，并展示了通过微调和强化学习显著提升模型性能，使其能与GPT-4o媲美。", "motivation": "为了提升大型语言模型（LLM）智能体在基于代码的医疗推理方面的能力，并解决现有模型在真实生物医学场景中表现的不足，以及提供一个可扩展的训练环境和基准。", "method": "MedAgentGYM是一个包含72,413个任务实例（涵盖129个类别）的训练环境，这些任务来源于真实的生物医学场景，并封装在可执行的编码环境中。每个任务都包含详细描述、交互式反馈、可验证的真实标注和可扩展的训练轨迹生成。作者通过广泛基准测试了30多个LLM，并利用MedAgentGYM对Med-Copilot-7B进行了监督微调和持续强化学习。", "result": "超过30个LLM的基准测试显示，商业API模型与开源模型之间存在显著性能差距。利用MedAgentGYM，Med-Copilot-7B通过监督微调实现了+36.44%的性能提升，通过持续强化学习实现了+42.47%的性能提升，使其成为一个经济实惠且保护隐私的替代方案，可与gpt-4o竞争。", "conclusion": "MedAgentGYM提供了一个集成的平台，包括全面的基准测试和可访问、可扩展的统一执行环境中的训练资源，用于开发基于LLM的编码助手，以促进先进的生物医学研究和实践。", "translation": "我们推出了MedAgentGYM，这是第一个公开可用的训练环境，旨在增强大型语言模型（LLM）智能体基于代码的医疗推理能力。MedAgentGYM包含72,413个任务实例，涵盖129个类别，这些任务来源于真实的生物医学场景。任务封装在可执行的编码环境中，每个环境都具有详细的任务描述、交互式反馈机制、可验证的真实标注以及可扩展的训练轨迹生成。对30多个LLM的广泛基准测试揭示了商业API模型和开源模型之间显著的性能差异。利用MedAgentGYM，Med-Copilot-7B通过监督微调（+36.44%）和持续强化学习（+42.47%）实现了显著的性能提升，成为一个经济实惠且保护隐私的替代方案，可与gpt-4o竞争。通过在统一的执行环境中提供全面的基准测试以及可访问、可扩展的训练资源，MedAgentGYM提供了一个集成平台，用于开发基于LLM的编码助手，以促进先进的生物医学研究和实践。", "summary": "MedAgentGYM是一个新颖的、公开可用的训练环境，旨在提高大型语言模型（LLM）智能体在基于代码的医疗推理方面的能力。该平台包含7万多个源自真实生物医学场景的任务实例，并提供详细的任务描述、交互式反馈和可验证的真实标注。通过使用MedAgentGYM，研究人员对30多个LLM进行了基准测试，并发现商业API模型和开源模型之间存在性能差异。此外，通过监督微调和强化学习，Med-Copilot-7B在MedAgentGYM上取得了显著的性能提升，使其成为一个具有成本效益且注重隐私的解决方案，性能可与gpt-4o相媲美。MedAgentGYM为开发用于高级生物医学研究和实践的LLM编码助手提供了一个全面的集成平台。", "keywords": "医疗推理, LLM智能体, 代码生成, 训练环境, 生物医学"}}
{"id": "2506.04970", "pdf": "https://arxiv.org/pdf/2506.04970", "abs": "https://arxiv.org/abs/2506.04970", "authors": ["Mélisande Teng", "Arthur Ouaknine", "Etienne Laliberté", "Yoshua Bengio", "David Rolnick", "Hugo Larochelle"], "title": "Bringing SAM to new heights: Leveraging elevation data for tree crown segmentation from drone imagery", "categories": ["cs.CV"], "comment": null, "summary": "Information on trees at the individual level is crucial for monitoring forest\necosystems and planning forest management. Current monitoring methods involve\nground measurements, requiring extensive cost, time and labor. Advances in\ndrone remote sensing and computer vision offer great potential for mapping\nindividual trees from aerial imagery at broad-scale. Large pre-trained vision\nmodels, such as the Segment Anything Model (SAM), represent a particularly\ncompelling choice given limited labeled data. In this work, we compare methods\nleveraging SAM for the task of automatic tree crown instance segmentation in\nhigh resolution drone imagery in three use cases: 1) boreal plantations, 2)\ntemperate forests and 3) tropical forests. We also study the integration of\nelevation data into models, in the form of Digital Surface Model (DSM)\ninformation, which can readily be obtained at no additional cost from RGB drone\nimagery. We present BalSAM, a model leveraging SAM and DSM information, which\nshows potential over other methods, particularly in the context of plantations.\nWe find that methods using SAM out-of-the-box do not outperform a custom Mask\nR-CNN, even with well-designed prompts. However, efficiently tuning SAM\nend-to-end and integrating DSM information are both promising avenues for tree\ncrown instance segmentation models.", "AI": {"title_translation": "将SAM推向新高度：利用高程数据对无人机图像中的树冠进行分割", "tldr": "本研究探讨了利用SAM模型结合高程数据（DSM）对无人机图像中的树冠进行自动实例分割。结果表明，开箱即用的SAM表现不如定制模型，但端到端微调SAM和整合DSM是有效的改进方向，BalSAM模型在种植园表现出潜力。", "motivation": "个体树木信息对于森林生态系统监测和森林管理规划至关重要。当前的监测方法（地面测量）成本高昂、耗时且需要大量劳动力。无人机遥感和计算机视觉的进步为大规模绘制个体树木提供了巨大潜力，尤其是在标记数据有限的情况下，预训练的大型视觉模型（如SAM）是引人注目的选择。", "method": "本研究比较了利用SAM模型进行高分辨率无人机图像中树冠实例分割的方法，并在三种用例中进行了测试：1）北方种植园，2）温带森林，3）热带森林。研究还探讨了将高程数据（数字表面模型，DSM）整合到模型中，DSM可以从RGB无人机图像中免费获取。提出了BalSAM模型，该模型结合了SAM和DSM信息。", "result": "研究发现，开箱即用的SAM方法即使有精心设计的提示，也未能超越定制的Mask R-CNN模型。然而，高效地对SAM进行端到端微调以及整合DSM信息是树冠实例分割模型的有前景的途径。BalSAM模型结合SAM和DSM信息，显示出优于其他方法的潜力，尤其是在种植园环境中。", "conclusion": "利用高程数据对预训练的视觉模型（如SAM）进行端到端微调，是提高无人机图像树冠实例分割性能的有效途径，尤其是在资源有限的种植园场景中。", "translation": "个体树木信息对于监测森林生态系统和规划森林管理至关重要。当前的监测方法涉及地面测量，需要大量的成本、时间和劳动力。无人机遥感和计算机视觉的进步为从航空图像中大规模绘制个体树木提供了巨大潜力。大型预训练视觉模型，例如Segment Anything Model (SAM)，鉴于标记数据有限，是一个特别引人注目的选择。在这项工作中，我们比较了利用SAM进行高分辨率无人机图像中自动树冠实例分割任务的方法，并在三个用例中进行测试：1）北方种植园，2）温带森林，3）热带森林。我们还研究了将高程数据以数字表面模型（DSM）信息的形式整合到模型中，DSM可以从RGB无人机图像中免费获得。我们提出了BalSAM，一个利用SAM和DSM信息的模型，它显示出优于其他方法的潜力，特别是在种植园背景下。我们发现，开箱即用的SAM方法即使有精心设计的提示，也未能超越定制的Mask R-CNN。然而，高效地对SAM进行端到端微调以及整合DSM信息都是树冠实例分割模型的有前景的途径。", "summary": "本研究探讨了利用大型预训练模型Segment Anything Model (SAM) 结合高程数据（数字表面模型，DSM）进行无人机图像树冠自动实例分割。研究比较了不同SAM应用方法在北方种植园、温带森林和热带森林中的表现，并引入了整合DSM信息的BalSAM模型。结果显示，开箱即用的SAM表现不如定制的Mask R-CNN，但端到端微调SAM和整合DSM是提高树冠分割模型性能的有效途径。BalSAM模型在种植园场景中表现出潜力。", "keywords": "SAM, 树冠分割, 无人机图像, 高程数据, 森林监测"}}
{"id": "2506.04746", "pdf": "https://arxiv.org/pdf/2506.04746", "abs": "https://arxiv.org/abs/2506.04746", "authors": ["Fei Ding", "Baiqiao Wang", "Zijian Zeng", "Youwei Wang"], "title": "Multi-Layer GRPO: Enhancing Reasoning and Self-Correction in Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "The Group Relative Policy Optimization (GRPO) algorithm has demonstrated\nconsiderable success in enhancing the reasoning capabilities of large language\nmodels (LLMs), as evidenced by DeepSeek-R1. However, the absence of\nintermediate supervision in GRPO frequently leads to inefficient exploration\ndynamics. A single error in a complex reasoning chain can invalidate the entire\nsolution, resulting in abrupt reward vanishing and compromising training\nstability.To address these challenges, we propose MGRPO (Multi-layer GRPO).\nMGRPO operates in two layers: the first layer employs standard GRPO to generate\nan initial response. This response, along with the original query, is then fed\ninto a second-layer GRPO process. This second layer is specifically trained to\nidentify and correct errors in the initial response, effectively creating a\nself-correction loop. This mechanism provides implicit process-level\nsupervision by rewarding successful error correction, without requiring an\nexplicit, densely-annotated reward model. Experimental results on several\nmathematical reasoning benchmarks demonstrate that MGRPO significantly\noutperforms standard GRPO, achieving superior performance by fostering both\nreasoning and self-correction abilities.", "AI": {"title_translation": "多层 GRPO：增强大型语言模型的推理和自我纠正能力", "tldr": "MGRPO通过两层结构，增强大型语言模型的推理和自我纠正能力，解决了传统GRPO中监督不足和训练不稳定的问题。", "motivation": "传统的GRPO算法在增强LLM推理能力方面取得成功，但缺乏中间监督，导致探索效率低下，复杂推理链中的单一错误可能导致整个解决方案无效，进而导致奖励突然消失和训练稳定性受损。", "method": "提出MGRPO（多层GRPO），其操作分为两层：第一层使用标准GRPO生成初始响应；第二层GRPO接收初始响应和原始查询，并专门训练用于识别和纠正初始响应中的错误，形成自我纠正循环。这种机制通过奖励成功的错误纠正提供隐式过程级监督，无需显式、密集注释的奖励模型。", "result": "在多个数学推理基准测试中，MGRPO显著优于标准GRPO，通过培养推理和自我纠正能力实现了卓越的性能。", "conclusion": "MGRPO通过引入多层结构和自我纠正机制，有效解决了传统GRPO的局限性，显著提升了大型语言模型的推理和自我纠正能力。", "translation": "群相对策略优化（GRPO）算法在增强大型语言模型（LLM）的推理能力方面取得了显著成功，如DeepSeek-R1所示。然而，GRPO中缺乏中间监督常常导致低效的探索动态。复杂推理链中的单个错误可能导致整个解决方案无效，从而导致奖励突然消失并损害训练稳定性。为了解决这些挑战，我们提出了MGRPO（多层GRPO）。MGRPO在两层中运行：第一层采用标准GRPO生成初始响应。然后，该响应与原始查询一起被馈送到第二层GRPO过程。这第二层经过专门训练，用于识别和纠正初始响应中的错误，有效地创建了一个自我纠正循环。这种机制通过奖励成功的错误纠正提供隐式过程级监督，而无需显式、密集注释的奖励模型。在几个数学推理基准测试上的实验结果表明，MGRPO显著优于标准GRPO，通过培养推理和自我纠正能力实现了卓越的性能。", "summary": "本文提出了MGRPO（多层GRPO），旨在解决传统GRPO在大型语言模型推理中面临的中间监督不足和训练稳定性问题。MGRPO采用双层结构：第一层生成初始响应，第二层则负责识别并纠正这些响应中的错误，形成一个自我纠正循环。这种方法通过奖励成功的错误纠正，提供了隐式的过程级监督。实验结果表明，MGRPO在数学推理基准测试上显著优于标准GRPO，有效提升了LLM的推理和自我纠正能力。", "keywords": "大型语言模型, GRPO, 自我纠正, 推理, 数学推理"}}
{"id": "2506.04375", "pdf": "https://arxiv.org/pdf/2506.04375", "abs": "https://arxiv.org/abs/2506.04375", "authors": ["Conor Rowan", "John Evans", "Kurt Maute", "Alireza Doostan"], "title": "Solving engineering eigenvalue problems with neural networks using the Rayleigh quotient", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "From characterizing the speed of a thermal system's response to computing\nnatural modes of vibration, eigenvalue analysis is ubiquitous in engineering.\nIn spite of this, eigenvalue problems have received relatively little treatment\ncompared to standard forward and inverse problems in the physics-informed\nmachine learning literature. In particular, neural network discretizations of\nsolutions to eigenvalue problems have seen only a handful of studies. Owing to\ntheir nonlinearity, neural network discretizations prevent the conversion of\nthe continuous eigenvalue differential equation into a standard discrete\neigenvalue problem. In this setting, eigenvalue analysis requires more\nspecialized techniques. Using a neural network discretization of the\neigenfunction, we show that a variational form of the eigenvalue problem called\nthe \"Rayleigh quotient\" in tandem with a Gram-Schmidt orthogonalization\nprocedure is a particularly simple and robust approach to find the eigenvalues\nand their corresponding eigenfunctions. This method is shown to be useful for\nfinding sets of harmonic functions on irregular domains, parametric and\nnonlinear eigenproblems, and high-dimensional eigenanalysis. We also discuss\nthe utility of harmonic functions as a spectral basis for approximating\nsolutions to partial differential equations. Through various examples from\nengineering mechanics, the combination of the Rayleigh quotient objective,\nGram-Schmidt procedure, and the neural network discretization of the\neigenfunction is shown to offer unique advantages for handling continuous\neigenvalue problems.", "AI": {"title_translation": "使用瑞利商通过神经网络求解工程特征值问题", "tldr": "本文提出了一种结合神经网络、瑞利商和格拉姆-施密特正交化过程的新方法，用于求解工程中的连续特征值问题，克服了传统方法在处理非线性离散化时的挑战。", "motivation": "尽管特征值分析在工程领域无处不在，但在物理信息机器学习文献中，与标准正向和逆向问题相比，特征值问题受到的关注相对较少，特别是使用神经网络离散化求解特征值问题。由于神经网络离散化的非线性特性，连续特征值微分方程无法转换为标准的离散特征值问题，这需要更专业的解决技术。", "method": "该方法使用特征函数的神经网络离散化，并结合特征值问题的变分形式——“瑞利商”以及格拉姆-施密特正交化过程，来寻找特征值及其对应的特征函数。", "result": "该方法被证明对于在不规则域上寻找调和函数集、参数和非线性特征值问题以及高维特征分析非常有用。瑞利商目标、格拉姆-施密特过程和特征函数神经网络离散化的结合，在处理连续特征值问题方面展现出独特的优势。", "conclusion": "将瑞利商目标、格拉姆-施密特过程与特征函数的神经网络离散化相结合，为处理连续特征值问题提供了独特的优势。", "translation": "从表征热系统响应速度到计算自然振动模式，特征值分析在工程领域无处不在。尽管如此，与物理信息机器学习文献中的标准正向和逆向问题相比，特征值问题受到的关注相对较少。特别是，神经网络离散化求解特征值问题仅有少数研究。由于其非线性，神经网络离散化阻止了连续特征值微分方程转换为标准的离散特征值问题。在这种情况下，特征值分析需要更专业的技术。我们展示了使用特征函数的神经网络离散化，结合被称为“瑞利商”的特征值问题的变分形式以及格拉姆-施密特正交化过程，是一种特别简单且鲁棒的寻找特征值及其相应特征函数的方法。该方法被证明对于在不规则域上寻找调和函数集、参数和非线性特征值问题以及高维特征分析非常有用。我们还讨论了调和函数作为谱基在近似偏微分方程解方面的效用。通过工程力学中的各种例子，瑞利商目标、格拉姆-施密特过程和特征函数神经网络离散化的结合被证明在处理连续特征值问题方面提供了独特的优势。", "summary": "本研究提出了一种利用神经网络、瑞利商和格拉姆-施密特正交化过程来解决工程特征值问题的新方法。鉴于特征值分析在工程中的重要性及其在物理信息机器学习领域中相对较少的研究，特别是神经网络离散化带来的非线性挑战，该方法提供了一种简单而鲁棒的解决方案。它被证明在寻找不规则域上的调和函数、处理参数和非线性特征问题以及高维特征分析方面具有实用性，并为处理连续特征值问题带来了独特的优势。", "keywords": "特征值问题, 神经网络, 瑞利商, 格拉姆-施密特正交化, 物理信息机器学习"}}
{"id": "2506.04408", "pdf": "https://arxiv.org/pdf/2506.04408", "abs": "https://arxiv.org/abs/2506.04408", "authors": ["Wesley Scivetti", "Tatsuya Aoyama", "Ethan Wilcox", "Nathan Schneider"], "title": "Unpacking Let Alone: Human-Scale Models Generalize to a Rare Construction in Form but not Meaning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Humans have a remarkable ability to acquire and understand grammatical\nphenomena that are seen rarely, if ever, during childhood. Recent evidence\nsuggests that language models with human-scale pretraining data may possess a\nsimilar ability by generalizing from frequent to rare constructions. However,\nit remains an open question how widespread this generalization ability is, and\nto what extent this knowledge extends to meanings of rare constructions, as\nopposed to just their forms. We fill this gap by testing human-scale\ntransformer language models on their knowledge of both the form and meaning of\nthe (rare and quirky) English LET-ALONE construction. To evaluate our LMs we\nconstruct a bespoke synthetic benchmark that targets syntactic and semantic\nproperties of the construction. We find that human-scale LMs are sensitive to\nform, even when related constructions are filtered from the dataset. However,\nhuman-scale LMs do not make correct generalizations about LET-ALONE's meaning.\nThese results point to an asymmetry in the current architectures' sample\nefficiency between language form and meaning, something which is not present in\nhuman language learners.", "AI": {"title_translation": "剖析“Let Alone”：人类规模模型在形式而非意义上泛化到罕见结构", "tldr": "人类规模语言模型能识别“Let Alone”等罕见结构的语法形式，但无法正确理解其语义。", "motivation": "人类能理解罕见的语法现象，近期研究表明大规模语言模型也可能通过泛化实现类似能力。然而，这种泛化能力的普遍性以及对罕见结构意义的理解程度仍是未解之谜。本研究旨在填补这一空白，测试人类规模的Transformer语言模型对英语“LET-ALONE”结构的形式和意义的掌握程度。", "method": "本研究测试了人类规模的Transformer语言模型对罕见英语“LET-ALONE”结构的形式和意义的掌握程度。为此，研究构建了一个定制的合成基准测试，旨在评估该结构的句法和语义特性。", "result": "研究发现人类规模的语言模型对“LET-ALONE”的形式敏感，即使从数据集中过滤掉相关结构。然而，人类规模的语言模型未能对“LET-ALONE”的意义进行正确的泛化。", "conclusion": "这些结果表明，当前架构在语言形式和意义之间的样本效率存在不对称性，而这种不对称性在人类语言学习者中并不存在。", "translation": "人类拥有一种卓越的能力，能够习得和理解在童年时期鲜有或从未见过的语法现象。最近的证据表明，拥有人类规模预训练数据的语言模型可能通过从常见结构泛化到罕见结构而拥有类似的能力。然而，这种泛化能力的普遍性，以及这种知识在多大程度上延伸到罕见结构的意义而非仅仅是其形式，仍然是一个悬而未决的问题。我们通过测试人类规模的Transformer语言模型对（罕见且独特的）英语“LET-ALONE”结构的形式和意义的知识来填补这一空白。为了评估我们的语言模型，我们构建了一个定制的合成基准测试，旨在针对该结构的句法和语义属性。我们发现人类规模的语言模型对形式敏感，即使在相关结构从数据集中过滤掉的情况下也是如此。然而，人类规模的语言模型未能对“LET-ALONE”的意义进行正确的泛化。这些结果表明，当前架构在语言形式和意义之间的样本效率存在不对称性，而这种不对称性在人类语言学习者中并不存在。", "summary": "本研究探讨了人类规模Transformer语言模型对罕见英语“LET-ALONE”结构的理解能力，特别关注其形式和意义的泛化。通过构建一个定制的合成基准测试，研究发现模型能够识别该结构的语法形式，但无法正确泛化其语义。这揭示了当前语言模型在处理语言形式和意义之间存在的样本效率不对称性，与人类学习者形成对比。", "keywords": "Let Alone, 语言模型, 泛化, 形式, 意义"}}
{"id": "2506.04983", "pdf": "https://arxiv.org/pdf/2506.04983", "abs": "https://arxiv.org/abs/2506.04983", "authors": ["Yangyang Zhong", "Ji Qi", "Yuan Yao", "Pengxin Luo", "Yunfeng Yan", "Donglian Qi", "Zhiyuan Liu", "Tat-Seng Chua"], "title": "TextVidBench: A Benchmark for Long Video Scene Text Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Despite recent progress on the short-video Text-Visual Question Answering\n(ViteVQA) task - largely driven by benchmarks such as M4-ViteVQA - existing\ndatasets still suffer from limited video duration and narrow evaluation scopes,\nmaking it difficult to adequately assess the growing capabilities of powerful\nmultimodal large language models (MLLMs). To address these limitations, we\nintroduce TextVidBench, the first benchmark specifically designed for\nlong-video text question answering (>3 minutes). TextVidBench makes three key\ncontributions: 1) Cross-domain long-video coverage: Spanning 9 categories\n(e.g., news, sports, gaming), with an average video length of 2306 seconds,\nenabling more realistic evaluation of long-video understanding. 2) A\nthree-stage evaluation framework: \"Text Needle-in-Haystack -> Temporal\nGrounding -> Text Dynamics Captioning\". 3) High-quality fine-grained\nannotations: Containing over 5,000 question-answer pairs with detailed semantic\nlabeling. Furthermore, we propose an efficient paradigm for improving large\nmodels through: (i) introducing the IT-Rope mechanism and temporal prompt\nengineering to enhance temporal perception, (ii) adopting non-uniform\npositional encoding to better handle long video sequences, and (iii) applying\nlightweight fine-tuning on video-text data. Extensive experiments on multiple\npublic datasets as well as TextVidBench demonstrate that our new benchmark\npresents significant challenges to existing models, while our proposed method\noffers valuable insights into improving long-video scene text understanding\ncapabilities.", "AI": {"title_translation": "TextVidBench：一个用于长视频场景文本理解的基准", "tldr": "TextVidBench是一个新的长视频场景文本理解基准，旨在解决现有短视频数据集的局限性，并提出了改进大型模型的方法。", "motivation": "尽管短视频文本-视觉问答（ViteVQA）任务取得了进展，但现有数据集存在视频时长有限和评估范围狭窄的问题，难以充分评估多模态大型语言模型（MLLMs）日益增长的能力。", "method": "本文引入了TextVidBench，这是第一个专门为长视频（>3分钟）文本问答设计的基准。TextVidBench具有三个主要贡献：跨领域长视频覆盖（9个类别，平均2306秒）、三阶段评估框架（“文本大海捞针 -> 时间定位 -> 文本动态字幕”）以及高质量的细粒度标注（超过5,000个问答对）。此外，本文提出了一种通过引入IT-Rope机制和时间提示工程、采用非均匀位置编码以及对视频-文本数据进行轻量级微调来改进大型模型的有效范式。", "result": "在多个公共数据集和TextVidBench上的大量实验表明，新的基准对现有模型提出了重大挑战，而所提出的方法为提高长视频场景文本理解能力提供了有价值的见解。", "conclusion": "TextVidBench通过提供一个具有挑战性的长视频文本问答基准，解决了现有数据集的局限性，并且所提出的方法为改进多模态大型语言模型在长视频场景文本理解方面的能力提供了有益的指导。", "translation": "尽管短视频文本-视觉问答（ViteVQA）任务取得了最新进展——主要由M4-ViteVQA等基准驱动——但现有数据集仍然存在视频时长有限和评估范围狭窄的问题，这使得难以充分评估强大的多模态大型语言模型（MLLMs）日益增长的能力。为了解决这些局限性，我们引入了TextVidBench，这是第一个专门为长视频（>3分钟）文本问答设计的基准。TextVidBench做出了三项关键贡献：1) 跨领域长视频覆盖：涵盖9个类别（例如，新闻、体育、游戏），平均视频长度为2306秒，从而能够更真实地评估长视频理解能力。2) 一个三阶段评估框架：“文本大海捞针 -> 时间定位 -> 文本动态字幕”。3) 高质量的细粒度标注：包含超过5,000个带有详细语义标注的问答对。此外，我们提出了一种改进大型模型的有效范式：(i) 引入IT-Rope机制和时间提示工程以增强时间感知能力，(ii) 采用非均匀位置编码以更好地处理长视频序列，以及 (iii) 对视频-文本数据应用轻量级微调。在多个公共数据集以及TextVidBench上进行的广泛实验表明，我们的新基准对现有模型提出了重大挑战，而我们提出的方法为提高长视频场景文本理解能力提供了有价值的见解。", "summary": "本文介绍了TextVidBench，这是一个专为长视频场景文本理解设计的新基准，旨在弥补现有短视频问答数据集在视频时长和评估范围上的不足。TextVidBench拥有跨领域长视频内容、独特的三阶段评估框架和高质量的标注。同时，文章提出了一种通过结合IT-Rope机制、时间提示工程、非均匀位置编码和轻量级微调来提升大型模型处理长视频能力的高效范式。实验证明该基准对现有模型构成显著挑战，且所提方法有效提升了长视频场景文本理解能力。", "keywords": "TextVidBench, 长视频, 场景文本理解, 基准, 多模态大型语言模型"}}
{"id": "2506.04761", "pdf": "https://arxiv.org/pdf/2506.04761", "abs": "https://arxiv.org/abs/2506.04761", "authors": ["Han Guo", "Songlin Yang", "Tarushii Goel", "Eric P. Xing", "Tri Dao", "Yoon Kim"], "title": "Log-Linear Attention", "categories": ["cs.LG"], "comment": null, "summary": "The attention mechanism in Transformers is an important primitive for\naccurate and scalable sequence modeling. Its quadratic-compute and\nlinear-memory complexity however remain significant bottlenecks. Linear\nattention and state-space models enable linear-time, constant-memory sequence\nmodeling and can moreover be trained efficiently through matmul-rich\nparallelization across sequence length. However, at their core these models are\nstill RNNs, and thus their use of a fixed-size hidden state to model the\ncontext is a fundamental limitation. This paper develops log-linear attention,\nan attention mechanism that balances linear attention's efficiency and the\nexpressiveness of softmax attention. Log-linear attention replaces the\nfixed-size hidden state with a logarithmically growing set of hidden states. We\nshow that with a particular growth function, log-linear attention admits a\nsimilarly matmul-rich parallel form whose compute cost is log-linear in\nsequence length. Log-linear attention is a general framework and can be applied\non top of existing linear attention variants. As case studies, we instantiate\nlog-linear variants of two recent architectures -- Mamba-2 and Gated DeltaNet\n-- and find they perform well compared to their linear-time variants.", "AI": {"title_translation": "对数线性注意力", "tldr": "对数线性注意力机制在保持效率的同时，通过对数增长的隐藏状态解决了传统线性注意力的局限性，实现了更高效的序列建模。", "motivation": "Transformer中的注意力机制虽然对序列建模至关重要，但其二次计算复杂度和线性内存复杂度是显著瓶颈。线性注意力和状态空间模型虽能实现线性时间、常数内存的序列建模，但其核心仍是RNN，使用固定大小的隐藏状态来建模上下文是其根本限制。", "method": "本文开发了对数线性注意力机制，它平衡了线性注意力的效率和softmax注意力的表达能力。对数线性注意力用一组对数增长的隐藏状态取代了固定大小的隐藏状态。通过特定的增长函数，对数线性注意力可以实现计算成本为序列长度对数线性的矩阵乘法并行形式。该框架可应用于现有线性注意力变体之上。", "result": "对数线性注意力机制实现了计算成本为序列长度对数线性的矩阵乘法并行形式。作为案例研究，将对数线性变体应用于Mamba-2和Gated DeltaNet两种近期架构，发现它们与线性时间变体相比表现良好。", "conclusion": "对数线性注意力机制通过引入对数增长的隐藏状态，成功地平衡了效率和表达能力，为序列建模提供了一种有前景的替代方案，并在实际应用中展现出优异性能。", "translation": "Transformer中的注意力机制是实现精确和可扩展序列建模的重要原语。然而，其二次计算和线性内存复杂性仍然是显著的瓶颈。线性注意力和状态空间模型能够实现线性时间、常数内存的序列建模，并且可以通过序列长度上的矩阵乘法并行化进行高效训练。然而，这些模型的核心仍然是RNN，因此它们使用固定大小的隐藏状态来建模上下文是一个根本限制。本文开发了对数线性注意力，这是一种平衡了线性注意力效率和softmax注意力表达能力的注意力机制。对数线性注意力用一组对数增长的隐藏状态取代了固定大小的隐藏状态。我们表明，通过特定的增长函数，对数线性注意力可以实现类似的富含矩阵乘法的并行形式，其计算成本在序列长度上是对数线性的。对数线性注意力是一个通用框架，可以应用于现有的线性注意力变体之上。作为案例研究，我们实例化了两种近期架构——Mamba-2和Gated DeltaNet的对数线性变体，发现它们与线性时间变体相比表现良好。", "summary": "本文提出了一种名为“对数线性注意力”的新型注意力机制，旨在解决传统Transformer注意力机制的计算复杂度和线性注意力机制的表达能力限制。该机制通过使用对数增长的隐藏状态集，而非固定大小的隐藏状态，实现了计算成本与序列长度呈对数线性的并行形式。实验表明，将对数线性注意力应用于Mamba-2和Gated DeltaNet等现有线性注意力变体上时，其性能优于原始线性时间变体。", "keywords": "对数线性注意力, 序列建模, 隐藏状态, 计算复杂度, 线性注意力"}}
{"id": "2506.04409", "pdf": "https://arxiv.org/pdf/2506.04409", "abs": "https://arxiv.org/abs/2506.04409", "authors": ["Lev Morozov", "Aleksandr Mogilevskii", "Alexander Shirnin"], "title": "Empaths at SemEval-2025 Task 11: Retrieval-Augmented Approach to Perceived Emotions Prediction", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to SemEval-2025, an ACL 2025 workshop", "summary": "This paper describes EmoRAG, a system designed to detect perceived emotions\nin text for SemEval-2025 Task 11, Subtask A: Multi-label Emotion Detection. We\nfocus on predicting the perceived emotions of the speaker from a given text\nsnippet, labeling it with emotions such as joy, sadness, fear, anger, surprise,\nand disgust. Our approach does not require additional model training and only\nuses an ensemble of models to predict emotions. EmoRAG achieves results\ncomparable to the best performing systems, while being more efficient,\nscalable, and easier to implement.", "AI": {"title_translation": "Empaths 参加 SemEval-2025 Task 11：感知情绪预测的检索增强方法", "tldr": "EmoRAG 系统使用检索增强方法，无需额外训练，即可在 SemEval-2025 Task 11 中有效预测文本中的感知情绪。", "motivation": "该研究旨在开发一个系统，用于在 SemEval-2025 Task 11 的多标签情绪检测子任务中，从文本片段中检测和预测说话者的感知情绪。", "method": "本文描述了 EmoRAG 系统，该系统采用检索增强方法，无需额外的模型训练，仅使用模型集成来预测情绪。", "result": "EmoRAG 系统在感知情绪预测方面取得了与最佳系统相当的结果，同时更高效、可扩展且更易于实现。", "conclusion": "EmoRAG 提供了一种无需额外训练即可有效预测感知情绪的方法，并且在性能上与领先系统相当，同时具有更高的效率和易用性。", "translation": "本文描述了 EmoRAG，一个旨在为 SemEval-2025 Task 11 子任务 A：多标签情绪检测，检测文本中感知情绪的系统。我们专注于从给定的文本片段中预测说话者的感知情绪，并用诸如喜悦、悲伤、恐惧、愤怒、惊讶和厌恶等情绪进行标记。我们的方法不需要额外的模型训练，只使用模型集成来预测情绪。EmoRAG 取得了与表现最佳系统相当的结果，同时更高效、可扩展且更易于实现。", "summary": "本论文介绍了 EmoRAG 系统，该系统专为 SemEval-2025 Task 11 的多标签情绪检测任务设计，用于预测文本中的感知情绪。该方法无需额外模型训练，仅通过模型集成即可实现与最佳系统相当的性能，并具有更高的效率、可扩展性和易于实现性。", "keywords": "感知情绪预测, SemEval-2025, EmoRAG, 检索增强, 模型集成"}}
{"id": "2506.04990", "pdf": "https://arxiv.org/pdf/2506.04990", "abs": "https://arxiv.org/abs/2506.04990", "authors": ["Enrique Sanchez", "Isma Hadji", "Adrian Bulat", "Christos Tzelepis", "Brais Martinez", "Georgios Tzimiropoulos"], "title": "Multi-scale Image Super Resolution with a Single Auto-Regressive Model", "categories": ["cs.CV"], "comment": "Enrique Sanchez and Isma Hadji equally contributed to this work.\n  Project site https://github.com/saic-fi/ms_sr_var", "summary": "In this paper we tackle Image Super Resolution (ISR), using recent advances\nin Visual Auto-Regressive (VAR) modeling. VAR iteratively estimates the\nresidual in latent space between gradually increasing image scales, a process\nreferred to as next-scale prediction. Thus, the strong priors learned during\npre-training align well with the downstream task (ISR). To our knowledge, only\nVARSR has exploited this synergy so far, showing promising results. However,\ndue to the limitations of existing residual quantizers, VARSR works only at a\nfixed resolution, i.e. it fails to map intermediate outputs to the\ncorresponding image scales. Additionally, it relies on a 1B transformer\narchitecture (VAR-d24), and leverages a large-scale private dataset to achieve\nstate-of-the-art results. We address these limitations through two novel\ncomponents: a) a Hierarchical Image Tokenization approach with a multi-scale\nimage tokenizer that progressively represents images at different scales while\nsimultaneously enforcing token overlap across scales, and b) a Direct\nPreference Optimization (DPO) regularization term that, relying solely on the\nLR and HR tokenizations, encourages the transformer to produce the latter over\nthe former. To the best of our knowledge, this is the first time a quantizer is\ntrained to force semantically consistent residuals at different scales, and the\nfirst time that preference-based optimization is used to train a VAR. Using\nthese two components, our model can denoise the LR image and super-resolve at\nhalf and full target upscale factors in a single forward pass. Additionally, we\nachieve \\textit{state-of-the-art results on ISR}, while using a small model\n(300M params vs ~1B params of VARSR), and without using external training data.", "AI": {"title_translation": "单一自回归模型的多尺度图像超分辨率", "tldr": "本文提出了一种新的图像超分辨率模型，通过分层图像tokenization和DPO正则化解决了现有VARSR模型的局限性，实现了多尺度超分辨率，并在更小的模型和无需外部数据的情况下达到了SOTA性能。", "motivation": "现有VARSR模型在固定分辨率下工作，无法处理中间输出，且依赖大型模型和私有数据集。", "method": "本文通过引入两个新组件解决了现有VARSR的局限性：a) 一种分层图像Tokenization方法，使用多尺度图像tokenizer逐步表示不同尺度的图像，并强制不同尺度间的token重叠；b) 一个直接偏好优化（DPO）正则化项，仅依靠LR和HR tokenization，鼓励transformer生成后者。", "result": "本文模型可以在单次前向传播中对LR图像进行去噪，并以半和全目标上采样因子进行超分辨率。模型在图像超分辨率（ISR）上实现了最先进的结果，同时使用了更小的模型（300M参数 vs VARSR的~1B参数），且无需使用外部训练数据。", "conclusion": "本文首次训练了一个量化器来强制不同尺度下的语义一致残差，并首次使用基于偏好的优化来训练VAR模型，成功地解决了多尺度图像超分辨率问题，并在效率和性能上取得了显著提升。", "translation": "本文利用视觉自回归（VAR）建模的最新进展来解决图像超分辨率（ISR）问题。VAR迭代地估计逐渐增加的图像尺度之间在潜在空间中的残差，这个过程被称为下一尺度预测。因此，预训练期间学到的强大先验知识与下游任务（ISR）很好地对齐。据我们所知，迄今为止只有VARSR利用了这种协同作用，并显示出有希望的结果。然而，由于现有残差量化器的局限性，VARSR只能在固定分辨率下工作，即它无法将中间输出映射到相应的图像尺度。此外，它依赖于一个10亿参数的transformer架构（VAR-d24），并利用大规模私有数据集来实现最先进的结果。我们通过两个新颖的组件解决了这些局限性：a) 一种分层图像Tokenization方法，使用多尺度图像tokenizer逐步表示不同尺度的图像，同时强制不同尺度间的token重叠，以及b) 一个直接偏好优化（DPO）正则化项，仅依靠LR和HR tokenization，鼓励transformer生成后者。据我们所知，这是首次训练量化器来强制不同尺度下语义一致的残差，也是首次使用基于偏好的优化来训练VAR。使用这两个组件，我们的模型可以在单次前向传播中对LR图像进行去噪，并以半和全目标上采样因子进行超分辨率。此外，我们在ISR上取得了最先进的结果，同时使用了小型模型（300M参数 vs VARSR的~1B参数），并且没有使用外部训练数据。", "summary": "本文利用视觉自回归（VAR）建模的最新进展来解决图像超分辨率（ISR）问题。针对现有VARSR模型在固定分辨率、模型大小和数据依赖方面的局限性，本文提出了两种新颖组件：一种分层图像Tokenization方法和一种直接偏好优化（DPO）正则化项。通过这些组件，所提出的模型能够在一个前向传播中实现多尺度超分辨率，并在更小的模型（300M参数）和无需外部训练数据的情况下，在ISR任务上达到了最先进的性能。", "keywords": "图像超分辨率, 自回归模型, 多尺度, 分层图像Tokenization, 直接偏好优化"}}
{"id": "2506.04765", "pdf": "https://arxiv.org/pdf/2506.04765", "abs": "https://arxiv.org/abs/2506.04765", "authors": ["Jiachen Tang", "Zhonghao Wang", "Sirui Chen", "Sheng Zhou", "Jiawei Chen", "Jiajun Bu"], "title": "OpenGT: A Comprehensive Benchmark For Graph Transformers", "categories": ["cs.LG"], "comment": "14 pages, 5 figures", "summary": "Graph Transformers (GTs) have recently demonstrated remarkable performance\nacross diverse domains. By leveraging attention mechanisms, GTs are capable of\nmodeling long-range dependencies and complex structural relationships beyond\nlocal neighborhoods. However, their applicable scenarios are still\nunderexplored, this highlights the need to identify when and why they excel.\nFurthermore, unlike GNNs, which predominantly rely on message-passing\nmechanisms, GTs exhibit a diverse design space in areas such as positional\nencoding, attention mechanisms, and graph-specific adaptations. Yet, it remains\nunclear which of these design choices are truly effective and under what\nconditions. As a result, the community currently lacks a comprehensive\nbenchmark and library to promote a deeper understanding and further development\nof GTs. To address this gap, this paper introduces OpenGT, a comprehensive\nbenchmark for Graph Transformers. OpenGT enables fair comparisons and\nmultidimensional analysis by establishing standardized experimental settings\nand incorporating a broad selection of state-of-the-art GNNs and GTs. Our\nbenchmark evaluates GTs from multiple perspectives, encompassing diverse tasks\nand datasets with varying properties. Through extensive experiments, our\nbenchmark has uncovered several critical insights, including the difficulty of\ntransferring models across task levels, the limitations of local attention, the\nefficiency trade-offs in several models, the application scenarios of specific\npositional encodings, and the preprocessing overhead of some positional\nencodings. We aspire for this work to establish a foundation for future graph\ntransformer research emphasizing fairness, reproducibility, and\ngeneralizability. We have developed an easy-to-use library OpenGT for training\nand evaluating existing GTs. The benchmark code is available at\nhttps://github.com/eaglelab-zju/OpenGT.", "AI": {"title_translation": "OpenGT：一个全面的图Transformer基准", "tldr": "OpenGT是一个全面的图Transformer基准，旨在解决当前GTs应用场景探索不足、设计选择有效性不明确以及缺乏统一基准的问题。它通过标准化实验设置和整合多种先进模型，实现了公平比较和多维度分析，并揭示了关于模型迁移、注意力机制和位置编码的关键洞察。", "motivation": "图Transformer（GTs）在不同领域表现出色，但其适用场景仍未被充分探索，且其多样化的设计空间（如位置编码、注意力机制和图特异性适应）中，哪些设计选择真正有效以及在何种条件下有效尚不清楚。社区缺乏一个全面的基准和库来促进对GTs的深入理解和进一步发展。", "method": "本文引入了OpenGT，一个用于图Transformer的全面基准。OpenGT通过建立标准化的实验设置并整合广泛的最先进GNN和GT，实现了公平比较和多维度分析。该基准从多个角度评估GT，涵盖了具有不同属性的各种任务和数据集。此外，还开发了一个易于使用的OpenGT库用于训练和评估现有GT。", "result": "通过广泛的实验，该基准揭示了几个关键洞察，包括：模型跨任务级别迁移的难度、局部注意力的局限性、几种模型的效率权衡、特定位置编码的应用场景，以及某些位置编码的预处理开销。", "conclusion": "作者希望这项工作能为未来的图Transformer研究奠定基础，强调公平性、可复现性和泛化性。", "translation": "图Transformer（GTs）最近在不同领域展现出卓越的性能。通过利用注意力机制，GTs能够建模超越局部邻域的长程依赖和复杂结构关系。然而，它们的适用场景仍未被充分探索，这凸显了识别它们何时以及为何表现出色的必要性。此外，与主要依赖消息传递机制的GNN不同，GTs在位置编码、注意力机制和图特异性适应等领域展现出多样化的设计空间。然而，目前尚不清楚这些设计选择中哪些是真正有效的，以及在何种条件下有效。因此，社区目前缺乏一个全面的基准和库来促进对GTs的深入理解和进一步发展。为了弥补这一空白，本文引入了OpenGT，一个用于图Transformer的全面基准。OpenGT通过建立标准化的实验设置并整合广泛的最先进GNN和GT，实现了公平比较和多维度分析。我们的基准从多个角度评估GT，涵盖了具有不同属性的各种任务和数据集。通过广泛的实验，我们的基准揭示了几个关键洞察，包括跨任务级别模型迁移的难度、局部注意力的局限性、几种模型的效率权衡、特定位置编码的应用场景，以及某些位置编码的预处理开销。我们希望这项工作能为未来的图Transformer研究奠定基础，强调公平性、可复现性和泛化性。我们开发了一个易于使用的OpenGT库，用于训练和评估现有GT。基准代码可在https://github.com/eaglelab-zju/OpenGT获取。", "summary": "OpenGT是一个为图Transformer（GTs）设计的全面基准，旨在解决当前GTs应用场景探索不足、设计选择有效性不明确以及缺乏统一基准的问题。它通过标准化实验设置和整合多种先进模型，实现了公平比较和多维度分析。其广泛的实验揭示了模型跨任务级别迁移的难度、局部注意力局限性、模型效率权衡以及位置编码的应用场景和预处理开销。该工作旨在为未来的图Transformer研究奠定基础，并提供一个易于使用的库。", "keywords": "图Transformer, 基准, OpenGT, 位置编码, 注意力机制"}}
{"id": "2506.04996", "pdf": "https://arxiv.org/pdf/2506.04996", "abs": "https://arxiv.org/abs/2506.04996", "authors": ["Edoardo Bianchi", "Antonio Liotta"], "title": "PATS: Proficiency-Aware Temporal Sampling for Multi-View Sports Skill Assessment", "categories": ["cs.CV"], "comment": null, "summary": "Automated sports skill assessment requires capturing fundamental movement\npatterns that distinguish expert from novice performance, yet current video\nsampling methods disrupt the temporal continuity essential for proficiency\nevaluation. To this end, we introduce Proficiency-Aware Temporal Sampling\n(PATS), a novel sampling strategy that preserves complete fundamental movements\nwithin continuous temporal segments for multi-view skill assessment. PATS\nadaptively segments videos to ensure each analyzed portion contains full\nexecution of critical performance components, repeating this process across\nmultiple segments to maximize information coverage while maintaining temporal\ncoherence. Evaluated on the EgoExo4D benchmark with SkillFormer, PATS surpasses\nthe state-of-the-art accuracy across all viewing configurations (+0.65% to\n+3.05%) and delivers substantial gains in challenging domains (+26.22%\nbouldering, +2.39% music, +1.13% basketball). Systematic analysis reveals that\nPATS successfully adapts to diverse activity characteristics-from\nhigh-frequency sampling for dynamic sports to fine-grained segmentation for\nsequential skills-demonstrating its effectiveness as an adaptive approach to\ntemporal sampling that advances automated skill assessment for real-world\napplications.", "AI": {"title_translation": "PATS：多视角体育技能评估中的熟练度感知时间采样", "tldr": "PATS是一种新颖的时间采样策略，通过保留连续时间段内的完整基本动作，显著提升了多视角体育技能评估的准确性。", "motivation": "现有的视频采样方法破坏了熟练度评估所需的时间连续性，无法有效捕捉区分专家和新手表现的基本运动模式。", "method": "本文引入了熟练度感知时间采样（PATS），这是一种新颖的采样策略，可在连续时间段内保留完整的关键动作，用于多视角技能评估。PATS自适应地分割视频，确保每个分析部分都包含关键性能组件的完整执行，并重复此过程以最大化信息覆盖范围同时保持时间连贯性。", "result": "在EgoExo4D基准测试和SkillFormer模型上进行评估，PATS在所有视角配置下均超越了现有技术水平的准确性（+0.65%至+3.05%），并在具有挑战性的领域取得了显著提升（攀岩+26.22%，音乐+2.39%，篮球+1.13%）。系统分析表明，PATS成功适应了各种活动特征。", "conclusion": "PATS作为一种自适应的时间采样方法，有效推动了自动化技能评估在实际应用中的发展。", "translation": "论文题目：PATS：多视角体育技能评估中的熟练度感知时间采样\n\n论文摘要：\n自动化体育技能评估需要捕捉区分专家和新手表现的基本运动模式，然而当前的视频采样方法破坏了熟练度评估所必需的时间连续性。为此，我们引入了熟练度感知时间采样（PATS），这是一种新颖的采样策略，它在连续时间段内保留了完整的关键动作，用于多视角技能评估。PATS自适应地分割视频，以确保每个分析部分都包含关键性能组件的完整执行，并重复此过程以最大化信息覆盖范围同时保持时间连贯性。在EgoExo4D基准测试和SkillFormer模型上进行评估，PATS在所有视角配置下均超越了现有技术水平的准确性（+0.65%至+3.05%），并在具有挑战性的领域取得了显著提升（攀岩+26.22%，音乐+2.39%，篮球+1.13%）。系统分析表明，PATS成功适应了各种活动特征——从动态运动的高频采样到顺序技能的精细分割——这证明了其作为一种自适应时间采样方法的有效性，该方法推动了自动化技能评估在实际应用中的发展。", "summary": "该论文提出了一种名为PATS（熟练度感知时间采样）的新型视频采样策略，旨在解决现有方法在体育技能评估中破坏时间连续性的问题。PATS通过自适应地分割视频以保留完整的关键动作，从而在多视角环境下提高技能评估的准确性。在EgoExo4D基准测试中，PATS结合SkillFormer模型显著优于现有技术，尤其在攀岩等高难度领域表现突出，证明其在各种活动中均具有良好的适应性和有效性，有助于推动自动化技能评估的实际应用。", "keywords": "熟练度感知时间采样, 体育技能评估, 多视角, 时间采样, 视频分析"}}
{"id": "2506.04999", "pdf": "https://arxiv.org/pdf/2506.04999", "abs": "https://arxiv.org/abs/2506.04999", "authors": ["Gengluo Li", "Huawen Shen", "Yu Zhou"], "title": "Beyond Cropped Regions: New Benchmark and Corresponding Baseline for Chinese Scene Text Retrieval in Diverse Layouts", "categories": ["cs.CV"], "comment": null, "summary": "Chinese scene text retrieval is a practical task that aims to search for\nimages containing visual instances of a Chinese query text. This task is\nextremely challenging because Chinese text often features complex and diverse\nlayouts in real-world scenes. Current efforts tend to inherit the solution for\nEnglish scene text retrieval, failing to achieve satisfactory performance. In\nthis paper, we establish a Diversified Layout benchmark for Chinese Street View\nText Retrieval (DL-CSVTR), which is specifically designed to evaluate retrieval\nperformance across various text layouts, including vertical, cross-line, and\npartial alignments. To address the limitations in existing methods, we propose\nChinese Scene Text Retrieval CLIP (CSTR-CLIP), a novel model that integrates\nglobal visual information with multi-granularity alignment training. CSTR-CLIP\napplies a two-stage training process to overcome previous limitations, such as\nthe exclusion of visual features outside the text region and reliance on\nsingle-granularity alignment, thereby enabling the model to effectively handle\ndiverse text layouts. Experiments on existing benchmark show that CSTR-CLIP\noutperforms the previous state-of-the-art model by 18.82% accuracy and also\nprovides faster inference speed. Further analysis on DL-CSVTR confirms the\nsuperior performance of CSTR-CLIP in handling various text layouts. The dataset\nand code will be publicly available to facilitate research in Chinese scene\ntext retrieval.", "AI": {"title_translation": "超越裁剪区域：多样化布局下中文场景文本检索的新基准和对应基线", "tldr": "本文提出了一个针对中文场景文本检索的新基准（DL-CSVTR）和一个名为CSTR-CLIP的新模型，旨在解决中文文本复杂多样的布局问题，并在现有基准上实现了显著的性能提升。", "motivation": "中文场景文本检索任务面临巨大挑战，因为中文文本在真实场景中常呈现复杂多样的布局。现有方法多沿袭英文场景文本检索方案，未能达到满意性能，且存在排除文本区域外视觉特征和依赖单一粒度对齐的局限性。", "method": "本文建立了针对中文街景文本检索的多样化布局基准（DL-CSVTR），专门用于评估在垂直、跨行和部分对齐等各种文本布局下的检索性能。为克服现有方法的局限性，提出了一种名为中文场景文本检索CLIP（CSTR-CLIP）的新型模型，该模型将全局视觉信息与多粒度对齐训练相结合，并采用两阶段训练过程。", "result": "在现有基准上，CSTR-CLIP的准确率比现有最先进模型高出18.82%，并提供了更快的推理速度。在DL-CSVTR上的进一步分析也证实了CSTR-CLIP在处理各种文本布局方面的卓越性能。", "conclusion": "本文通过建立DL-CSVTR基准并提出CSTR-CLIP模型，成功解决了中文场景文本检索中复杂多样的布局问题，显著提升了检索性能和效率。", "translation": "中文场景文本检索是一项实用任务，旨在搜索包含中文查询文本视觉实例的图像。这项任务极具挑战性，因为中文文本在真实场景中通常具有复杂多样的布局。目前的努力倾向于沿袭英文场景文本检索的解决方案，未能达到令人满意的性能。在本文中，我们建立了一个针对中文街景文本检索的多样化布局基准（DL-CSVTR），该基准专门设计用于评估各种文本布局（包括垂直、跨行和部分对齐）下的检索性能。为了解决现有方法的局限性，我们提出了一种名为中文场景文本检索CLIP（CSTR-CLIP）的新型模型，该模型将全局视觉信息与多粒度对齐训练相结合。CSTR-CLIP采用两阶段训练过程来克服以前的局限性，例如排除文本区域外的视觉特征和依赖单一粒度对齐，从而使模型能够有效地处理多样化的文本布局。在现有基准上的实验表明，CSTR-CLIP的准确率比现有最先进模型高出18.82%，并且提供了更快的推理速度。在DL-CSVTR上的进一步分析证实了CSTR-CLIP在处理各种文本布局方面的卓越性能。数据集和代码将公开发布，以促进中文场景文本检索领域的研究。", "summary": "本文针对中文场景文本检索中复杂多样的文本布局挑战，提出了一个名为DL-CSVTR的新基准，旨在评估模型在垂直、跨行和部分对齐等多种布局下的性能。同时，本文还提出了一种新颖的CSTR-CLIP模型，该模型通过整合全局视觉信息和多粒度对齐训练，并采用两阶段训练过程，有效克服了现有方法的局限性。实验结果表明，CSTR-CLIP在现有基准上大幅超越了现有最先进模型，并展现出处理各种文本布局的卓越能力。", "keywords": "中文场景文本检索, 多样化布局, 基准, CSTR-CLIP, 多粒度对齐"}}
{"id": "2506.04786", "pdf": "https://arxiv.org/pdf/2506.04786", "abs": "https://arxiv.org/abs/2506.04786", "authors": ["Thore Gerlach", "Sascha Mücke", "Christian Bauckhage"], "title": "Kernel $k$-Medoids as General Vector Quantization", "categories": ["cs.LG", "quant-ph"], "comment": null, "summary": "Vector Quantization (VQ) is a widely used technique in machine learning and\ndata compression, valued for its simplicity and interpretability. Among hard VQ\nmethods, $k$-medoids clustering and Kernel Density Estimation (KDE) approaches\nrepresent two prominent yet seemingly unrelated paradigms -- one\ndistance-based, the other rooted in probability density matching. In this\npaper, we investigate their connection through the lens of Quadratic\nUnconstrained Binary Optimization (QUBO). We compare a heuristic QUBO\nformulation for $k$-medoids, which balances centrality and diversity, with a\nprincipled QUBO derived from minimizing Maximum Mean Discrepancy in KDE-based\nVQ. Surprisingly, we show that the KDE-QUBO is a special case of the\n$k$-medoids-QUBO under mild assumptions on the kernel's feature map. This\nreveals a deeper structural relationship between these two approaches and\nprovides new insight into the geometric interpretation of the weighting\nparameters used in QUBO formulations for VQ.", "AI": {"title_translation": "核$k$-Medoids作为通用向量量化", "tldr": "本文通过二次无约束二元优化（QUBO）的视角，揭示了基于核密度估计（KDE）的向量量化（VQ）是核$k$-medoids VQ的一个特例，从而建立了这两种看似无关的方法之间的深层联系。", "motivation": "向量量化（VQ）因其简单性和可解释性而被广泛使用。$k$-medoids聚类和核密度估计（KDE）是两种突出但看似无关的硬VQ方法。本文旨在通过二次无约束二元优化（QUBO）的视角，探究它们之间的联系。", "method": "本文通过二次无约束二元优化（QUBO）的视角研究了$k$-medoids聚类和核密度估计（KDE）之间的联系。具体来说，它比较了$k$-medoids的启发式QUBO公式（平衡中心性和多样性）与通过最小化KDE-based VQ中的最大均值差异（MMD）导出的原理性QUBO。", "result": "研究发现，在对核的特征映射进行温和假设的情况下，KDE-QUBO是$k$-medoids-QUBO的一个特例。", "conclusion": "这项研究揭示了$k$-medoids和KDE这两种方法之间更深层次的结构关系，并为VQ中QUBO公式所使用的加权参数提供了新的几何解释。", "translation": "向量量化（VQ）是机器学习和数据压缩中广泛使用的技术，因其简单性和可解释性而备受重视。在硬VQ方法中，$k$-medoids聚类和核密度估计（KDE）方法代表了两种突出但看似无关的范式——一种基于距离，另一种植根于概率密度匹配。在本文中，我们通过二次无约束二元优化（QUBO）的视角研究了它们之间的联系。我们比较了$k$-medoids的启发式QUBO公式（平衡中心性和多样性）与通过最小化基于KDE的VQ中的最大均值差异（MMD）导出的原理性QUBO。令人惊讶的是，我们发现KDE-QUBO在对核的特征映射进行温和假设的情况下是$k$-medoids-QUBO的一个特例。这揭示了这两种方法之间更深层次的结构关系，并为VQ中QUBO公式所使用的加权参数提供了新的几何解释。", "summary": "本研究探讨了$k$-medoids聚类和核密度估计（KDE）这两种在向量量化（VQ）中看似独立的范式之间的联系。通过二次无约束二元优化（QUBO）的视角，研究发现基于KDE的QUBO在特定条件下是$k$-medoids-QUBO的一个特例。这一发现不仅揭示了这两种方法之间深层的结构关系，还为VQ中QUBO公式的加权参数提供了新的几何解释。", "keywords": "向量量化, $k$-medoids, 核密度估计, QUBO, 最大均值差异"}}
{"id": "2506.04381", "pdf": "https://arxiv.org/pdf/2506.04381", "abs": "https://arxiv.org/abs/2506.04381", "authors": ["Neeraj Agrawal", "Saurabh Kumar", "Priyanka Bhatt", "Tanishka Agarwal"], "title": "Hierarchical Text Classification Using Contrastive Learning Informed Path Guided Hierarchy", "categories": ["cs.CL", "cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2203.03825 by other authors", "summary": "Hierarchical Text Classification (HTC) has recently gained traction given the\nability to handle complex label hierarchy. This has found applications in\ndomains like E- commerce, customer care and medicine industry among other\nreal-world applications. Existing HTC models either encode label hierarchy\nseparately and mix it with text encoding or guide the label hierarchy structure\nin the text encoder. Both approaches capture different characteristics of label\nhierarchy and are complementary to each other. In this paper, we propose a\nHierarchical Text Classification using Contrastive Learning Informed Path\nguided hierarchy (HTC-CLIP), which learns hierarchy-aware text representation\nand text informed path guided hierarchy representation using contrastive\nlearning. During the training of HTC-CLIP, we learn two different sets of class\nprobabilities distributions and during inference, we use the pooled output of\nboth probabilities for each class to get the best of both representations. Our\nresults show that the two previous approaches can be effectively combined into\none architecture to achieve improved performance. Tests on two public benchmark\ndatasets showed an improvement of 0.99 - 2.37% in Macro F1 score using HTC-CLIP\nover the existing state-of-the-art models.", "AI": {"title_translation": "基于对比学习路径引导的层次文本分类", "tldr": "本文提出了一种结合对比学习和路径引导的层次文本分类模型HTC-CLIP，通过融合两种不同的表示方法，在两个公共基准数据集上实现了性能提升。", "motivation": "层次文本分类（HTC）在处理复杂标签层次结构方面具有优势，并在电子商务、客户服务和医疗等领域有广泛应用。现有HTC模型单独编码或在文本编码器中引导标签层次结构，但两者互补，可以进一步结合以提高性能。", "method": "本文提出了HTC-CLIP模型，该模型利用对比学习学习层次感知的文本表示和文本引导的路径引导层次表示。在训练过程中，模型学习两组不同的类别概率分布，并在推断时结合两者的池化输出来获得最佳表示。", "result": "HTC-CLIP在两个公共基准数据集上，相比现有最先进模型，Macro F1分数提高了0.99%至2.37%。这表明结合两种现有方法能有效提高性能。", "conclusion": "通过结合对比学习和路径引导，HTC-CLIP模型能够有效融合两种互补的层次文本分类方法，从而显著提升分类性能。", "translation": "层次文本分类（HTC）因其处理复杂标签层次结构的能力而最近受到关注。这已在电子商务、客户服务和医疗行业等实际应用领域找到应用。现有的HTC模型要么单独编码标签层次结构并将其与文本编码混合，要么在文本编码器中引导标签层次结构。这两种方法捕获了标签层次结构的不同特征，并且彼此互补。在本文中，我们提出了一种使用对比学习路径引导层次结构的层次文本分类（HTC-CLIP）模型，该模型利用对比学习学习层次感知的文本表示和文本引导的路径引导层次表示。在HTC-CLIP的训练过程中，我们学习两组不同的类别概率分布，并在推理过程中，我们使用两种概率的池化输出作为每个类别的最佳表示。我们的结果表明，以前的两种方法可以有效地组合到一个架构中以实现改进的性能。在两个公共基准数据集上的测试显示，使用HTC-CLIP比现有最先进模型在Macro F1分数上提高了0.99% - 2.37%。", "summary": "本文提出了一种名为HTC-CLIP的层次文本分类模型，它通过对比学习融合了层次感知的文本表示和文本引导的路径引导层次表示。该模型在训练阶段学习两种类别概率分布，并在推断时结合两者的优势。实验结果表明，HTC-CLIP在两个公共基准数据集上，相较于现有最先进模型，Macro F1分数提升了0.99%至2.37%，证明了其有效性。", "keywords": "层次文本分类, 对比学习, 路径引导, 标签层次结构, 文本表示"}}
{"id": "2506.05008", "pdf": "https://arxiv.org/pdf/2506.05008", "abs": "https://arxiv.org/abs/2506.05008", "authors": ["Fuyi Zhang", "Zhu Yu", "Chunhao Li", "Runmin Zhang", "Xiaokai Bai", "Zili Zhou", "Si-Yuan Cao", "Wang Wang", "Hui-Liang Shen"], "title": "Structure-Aware Radar-Camera Depth Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Monocular depth estimation aims to determine the depth of each pixel from an\nRGB image captured by a monocular camera. The development of deep learning has\nsignificantly advanced this field by facilitating the learning of depth\nfeatures from some well-annotated datasets\n\\cite{Geiger_Lenz_Stiller_Urtasun_2013,silberman2012indoor}. Eigen \\textit{et\nal.} \\cite{eigen2014depth} first introduce a multi-scale fusion network for\ndepth regression. Following this, subsequent improvements have come from\nreinterpreting the regression task as a classification problem\n\\cite{bhat2021adabins,Li_Wang_Liu_Jiang_2022}, incorporating additional priors\n\\cite{shao2023nddepth,yang2023gedepth}, and developing more effective objective\nfunction \\cite{xian2020structure,Yin_Liu_Shen_Yan_2019}. Despite these\nadvances, generalizing to unseen domains remains a challenge. Recently, several\nmethods have employed affine-invariant loss to enable multi-dataset joint\ntraining \\cite{MiDaS,ZeroDepth,guizilini2023towards,Dany}. Among them, Depth\nAnything \\cite{Dany} has shown leading performance in zero-shot monocular depth\nestimation. While it struggles to estimate accurate metric depth due to the\nlack of explicit depth cues, it excels at extracting structural information\nfrom unseen images, producing structure-detailed monocular depth.", "AI": {"title_translation": "结构感知雷达-相机深度估计", "tldr": "单目深度估计在泛化到未见领域和准确度量深度估计方面仍面临挑战，现有方法在结构信息提取方面表现良好，但在度量深度方面存在不足。", "motivation": "尽管深度学习在单目深度估计方面取得了显著进展，但泛化到未见领域仍然是一个挑战。特别是，现有方法（如Depth Anything）虽然擅长提取结构信息，但在估计准确的度量深度方面存在不足，因为缺乏明确的深度线索。", "method": "未在摘要中提及", "result": "未在摘要中提及", "conclusion": "未在摘要中提及", "translation": "单目深度估计旨在确定由单目相机捕获的RGB图像中每个像素的深度。深度学习的发展通过促进从一些良好标注的数据集中学习深度特征，显著推动了该领域的发展\\cite{Geiger_Lenz_Stiller_Urtasun_2013,silberman2012indoor}。Eigen等人\\cite{eigen2014depth}首次引入了多尺度融合网络用于深度回归。此后，通过将回归任务重新解释为分类问题\\cite{bhat2021adabins,Li_Wang_Liu_Jiang_2022}、引入额外先验\\cite{shao2023nddepth,yang2023gedepth}以及开发更有效的目标函数\\cite{xian2020structure,Yin_Liu_Shen_Yan_2019}，取得了后续改进。尽管取得了这些进展，但泛化到未见领域仍然是一个挑战。最近，几种方法采用了仿射不变损失来实现多数据集联合训练\\cite{MiDaS,ZeroDepth,guizilini2023towards,Dany}。其中，Depth Anything \\cite{Dany}在零样本单目深度估计中表现出领先性能。虽然由于缺乏明确的深度线索，它在估计准确的度量深度方面存在困难，但它擅长从未见图像中提取结构信息，生成结构详细的单目深度。", "summary": "单目深度估计旨在从RGB图像中确定每个像素的深度。深度学习的发展通过从标注数据集中学习深度特征极大地推动了该领域。尽管在多尺度融合、回归问题转化、引入先验和优化目标函数等方面取得了进展，但泛化到未见领域仍是挑战。近期方法利用仿射不变损失进行多数据集联合训练，其中Depth Anything在零样本单目深度估计中表现出色，能提取结构详细的深度信息，但由于缺乏明确深度线索，难以估计准确的度量深度。", "keywords": "单目深度估计, 结构感知, 泛化, 度量深度, 雷达-相机"}}
{"id": "2506.04805", "pdf": "https://arxiv.org/pdf/2506.04805", "abs": "https://arxiv.org/abs/2506.04805", "authors": ["Zhiwei Bai", "Zhangchen Zhou", "Jiajie Zhao", "Xiaolong Li", "Zhiyu Li", "Feiyu Xiong", "Hongkang Yang", "Yaoyu Zhang", "Zhi-Qin John Xu"], "title": "Adaptive Preconditioners Trigger Loss Spikes in Adam", "categories": ["cs.LG"], "comment": null, "summary": "Loss spikes emerge commonly during training across neural networks of varying\narchitectures and scales when using the Adam optimizer. In this work, we\ninvestigate the underlying mechanism responsible for Adam spikes. While\nprevious explanations attribute these phenomena to the lower-loss-as-sharper\ncharacteristics of the loss landscape, our analysis reveals that Adam's\nadaptive preconditioners themselves can trigger spikes. Specifically, we\nidentify a critical regime where squared gradients become substantially smaller\nthan the second-order moment estimates, causing the latter to undergo a\n$\\beta_2$-exponential decay and to respond sluggishly to current gradient\ninformation. This mechanism can push the maximum eigenvalue of the\npreconditioned Hessian beyond the classical stability threshold $2/\\eta$ for a\nsustained period, inducing instability. This instability further leads to an\nalignment between the gradient and the maximum eigendirection, and a loss spike\noccurs precisely when the gradient-directional curvature exceeds $2/\\eta$. We\nverify this mechanism through extensive experiments on fully connected\nnetworks, convolutional networks, and Transformer architectures.", "AI": {"title_translation": "Adam优化器中自适应预处理器引发损失尖峰", "tldr": "研究发现Adam优化器中的损失尖峰并非由于损失景观特性，而是由自适应预处理器在特定条件下导致预处理Hessian矩阵的最大特征值超出稳定阈值所致。", "motivation": "研究Adam优化器训练过程中普遍出现的损失尖峰的根本机制。", "method": "通过分析发现了一个关键机制，即当平方梯度远小于二阶矩估计时，二阶矩估计会经历指数衰减并对当前梯度信息响应迟钝，导致预处理Hessian矩阵的最大特征值超出经典稳定性阈值，进而引发不稳定性。通过在全连接网络、卷积网络和Transformer架构上进行大量实验验证了该机制。", "result": "Adam的自适应预处理器本身可以触发损失尖峰。具体来说，当平方梯度显著小于二阶矩估计时，二阶矩估计会经历$\\beta_2$指数衰减并对当前梯度信息响应迟钝。这种机制可以将预处理Hessian的最大特征值推高到超过经典稳定性阈值$2/\\eta$并持续一段时间，从而导致不稳定性。这种不稳定性进一步导致梯度与最大特征方向对齐，当梯度方向曲率超过$2/\\eta$时，精确地发生损失尖峰。", "conclusion": "Adam优化器中常见的损失尖峰是由其自适应预处理器在特定条件下引发的，而非传统认为的损失景观特性。", "translation": "在使用Adam优化器训练不同架构和规模的神经网络时，损失尖峰普遍出现。在这项工作中，我们研究了Adam尖峰背后的潜在机制。虽然之前的解释将这些现象归因于损失景观的“低损失-更尖锐”特性，但我们的分析表明，Adam的自适应预处理器本身可以触发尖峰。具体而言，我们识别出一个关键状态，在此状态下，平方梯度远小于二阶矩估计，导致后者经历$\\beta_2$指数衰减并对当前梯度信息响应迟钝。这种机制可以将预处理Hessian的最大特征值推高到超过经典稳定性阈值$2/\\eta$并持续一段时间，从而导致不稳定性。这种不稳定性进一步导致梯度与最大特征方向对齐，当梯度方向曲率超过$2/\\eta$时，精确地发生损失尖峰。我们通过在全连接网络、卷积网络和Transformer架构上的大量实验验证了这一机制。", "summary": "该论文深入研究了Adam优化器训练过程中普遍存在的损失尖峰现象。与以往归因于损失景观锐利度的解释不同，研究发现Adam的自适应预处理器本身是引发尖峰的原因。具体机制为：当平方梯度远小于二阶矩估计时，二阶矩估计响应迟钝并指数衰减，导致预处理Hessian的最大特征值长时间超出稳定阈值$2/\\eta$，引发不稳定性。这种不稳定性促使梯度与最大特征方向对齐，当梯度方向曲率超过$2/\\eta$时即发生损失尖峰。该机制已在多种神经网络架构上得到验证。", "keywords": "Adam, 损失尖峰, 自适应预处理器, 神经网络, 稳定性"}}
{"id": "2506.05009", "pdf": "https://arxiv.org/pdf/2506.05009", "abs": "https://arxiv.org/abs/2506.05009", "authors": ["Alfred T. Christiansen", "Andreas H. Højrup", "Morten K. Stephansen", "Md Ibtihaj A. Sakib", "Taman S. Poojary", "Filip Slezak", "Morten S. Laursen", "Thomas B. Moeslund", "Joakim B. Haurum"], "title": "Point Cloud Segmentation of Agricultural Vehicles using 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "Training neural networks for tasks such as 3D point cloud semantic\nsegmentation demands extensive datasets, yet obtaining and annotating\nreal-world point clouds is costly and labor-intensive. This work aims to\nintroduce a novel pipeline for generating realistic synthetic data, by\nleveraging 3D Gaussian Splatting (3DGS) and Gaussian Opacity Fields (GOF) to\ngenerate 3D assets of multiple different agricultural vehicles instead of using\ngeneric models. These assets are placed in a simulated environment, where the\npoint clouds are generated using a simulated LiDAR. This is a flexible approach\nthat allows changing the LiDAR specifications without incurring additional\ncosts. We evaluated the impact of synthetic data on segmentation models such as\nPointNet++, Point Transformer V3, and OACNN, by training and validating the\nmodels only on synthetic data. Remarkably, the PTv3 model had an mIoU of\n91.35\\%, a noteworthy result given that the model had neither been trained nor\nvalidated on any real data. Further studies even suggested that in certain\nscenarios the models trained only on synthetically generated data performed\nbetter than models trained on real-world data. Finally, experiments\ndemonstrated that the models can generalize across semantic classes, enabling\naccurate predictions on mesh models they were never trained on.", "AI": {"title_translation": "农用车辆点云分割基于3D高斯泼溅", "tldr": "本文提出一种利用3D高斯泼溅生成农用车辆合成点云数据的新方法，有效解决了真实数据获取成本高的问题，并表明在合成数据上训练的模型（特别是PTv3）在语义分割任务上表现出色，甚至在某些情况下优于真实数据训练的模型。", "motivation": "训练3D点云语义分割神经网络需要大量数据集，但获取和标注真实世界点云数据成本高昂且耗时费力。", "method": "引入了一种新的管道，利用3D高斯泼溅（3DGS）和高斯不透明度场（GOF）生成多种不同农用车辆的3D资产，而不是使用通用模型。这些资产被放置在模拟环境中，使用模拟激光雷达生成点云。这种方法灵活，允许更改激光雷达规格而无需额外成本。", "result": "在仅使用合成数据训练和验证PointNet++、Point Transformer V3 (PTv3)和OACNN等分割模型后，PTv3模型取得了91.35%的mIoU，这是一个显著的结果，因为它没有在任何真实数据上训练或验证。进一步研究表明，在某些情况下，仅在合成数据上训练的模型表现优于在真实数据上训练的模型。实验还证明模型可以跨语义类别泛化，对从未训练过的网格模型进行准确预测。", "conclusion": "通过3D高斯泼溅生成的合成数据可以有效替代真实数据用于农用车辆点云分割任务，在特定情况下甚至能取得更优的性能，并且模型具有良好的泛化能力。", "translation": "训练用于3D点云语义分割等任务的神经网络需要大量数据集，然而获取和标注真实世界点云数据成本高昂且耗时费力。这项工作旨在引入一种新颖的流程，通过利用3D高斯泼溅（3DGS）和高斯不透明度场（GOF）来生成逼真的合成数据，以生成多种不同农用车辆的3D资产，而不是使用通用模型。这些资产被放置在模拟环境中，其中点云使用模拟激光雷达生成。这是一种灵活的方法，允许更改激光雷达规格而无需额外成本。我们通过仅在合成数据上训练和验证模型，评估了合成数据对PointNet++、Point Transformer V3和OACNN等分割模型的影响。值得注意的是，PTv3模型的mIoU达到了91.35%，考虑到该模型既未在任何真实数据上训练也未验证，这是一个值得关注的结果。进一步研究甚至表明，在某些情况下，仅在合成生成数据上训练的模型表现优于在真实世界数据上训练的模型。最后，实验表明模型可以泛化到不同的语义类别，从而对从未训练过的网格模型进行准确预测。", "summary": "本文提出了一种创新的合成数据生成流程，利用3D高斯泼溅和高斯不透明度场为农用车辆创建逼真的3D资产，并通过模拟激光雷达生成点云。该方法旨在解决真实点云数据获取和标注成本高昂的问题。实验结果显示，在仅用合成数据训练后，Point Transformer V3模型在语义分割任务上取得了91.35%的mIoU，表现出色。研究还发现，在某些场景下，合成数据训练的模型性能优于真实数据训练的模型，且模型展现出良好的跨类别泛化能力。", "keywords": "3D高斯泼溅, 点云分割, 农用车辆, 合成数据, 语义分割"}}
{"id": "2506.04821", "pdf": "https://arxiv.org/pdf/2506.04821", "abs": "https://arxiv.org/abs/2506.04821", "authors": ["Zhen Hao Wong", "Jingwen Deng", "Runming He", "Zirong Chen", "Qijie You", "Hejun Dong", "Hao Liang", "Chengyu Shen", "Bin Cui", "Wentao Zhang"], "title": "LogicPuzzleRL: Cultivating Robust Mathematical Reasoning in LLMs via Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) excel at many supervised tasks but often\nstruggle with structured reasoning in unfamiliar settings. This discrepancy\nsuggests that standard fine-tuning pipelines may instill narrow,\ndomain-specific heuristics rather than fostering general-purpose thinking\nstrategies. In this work, we propose a \"play to learn\" framework that\nfine-tunes LLMs through reinforcement learning on a suite of seven custom logic\npuzzles, each designed to cultivate distinct reasoning skills such as\nconstraint propagation, spatial consistency, and symbolic deduction. Using a\nreinforcement learning setup with verifiable rewards, models receive binary\nfeedback based on puzzle correctness, encouraging iterative, hypothesis-driven\nproblem solving. We demonstrate that this training approach significantly\nimproves out-of-distribution performance on a range of mathematical benchmarks,\nespecially for mid-difficulty problems that require multi-step reasoning.\nAnalyses across problem categories and difficulty levels reveal that puzzle\ntraining promotes transferable reasoning routines, strengthening algebraic\nmanipulation, geometric inference, and combinatorial logic, while offering\nlimited gains on rote or highly specialized tasks. These findings show that\nreinforcement learning over logic puzzles reshapes the internal reasoning of\nLLMs, enabling more robust and compositional generalization without relying on\ntask-specific symbolic tools.", "AI": {"title_translation": "LogicPuzzleRL：通过强化学习培养LLM的鲁棒数学推理能力", "tldr": "LLMs通过强化学习在逻辑谜题上进行微调，显著提升了数学推理能力和泛化性。", "motivation": "大型语言模型（LLMs）在许多监督任务中表现出色，但在陌生环境中的结构化推理方面表现不佳，这表明标准微调可能灌输的是狭隘的、领域特定的启发式，而非通用思维策略。", "method": "本文提出了一个“玩中学”（play to learn）框架，通过强化学习在一系列七个自定义逻辑谜题上对LLMs进行微调。这些谜题旨在培养不同的推理技能，如约束传播、空间一致性和符号演绎。模型通过可验证的奖励接收基于谜题正确性的二元反馈，鼓励迭代的、假设驱动的问题解决。", "result": "该训练方法显著提高了LLMs在各种数学基准测试上的分布外性能，特别是对于需要多步推理的中等难度问题。分析表明，谜题训练促进了可迁移的推理例程，增强了代数操作、几何推理和组合逻辑，但在死记硬背或高度专业化的任务上收益有限。", "conclusion": "基于逻辑谜题的强化学习重塑了LLMs的内部推理，使其能够实现更鲁棒和组合的泛化，而无需依赖任务特定的符号工具。", "translation": "大型语言模型（LLMs）在许多监督任务中表现出色，但往往在不熟悉环境中的结构化推理方面遇到困难。这种差异表明，标准的微调流程可能灌输的是狭隘的、领域特定的启发式，而不是培养通用思维策略。在这项工作中，我们提出了一个“玩中学”框架，通过强化学习在一系列七个自定义逻辑谜题上微调LLMs，每个谜题都旨在培养不同的推理技能，如约束传播、空间一致性和符号演绎。使用带有可验证奖励的强化学习设置，模型根据谜题的正确性接收二元反馈，鼓励迭代的、假设驱动的问题解决。我们证明了这种训练方法显著改善了在各种数学基准测试上的分布外性能，特别是对于需要多步推理的中等难度问题。对问题类别和难度级别的分析表明，谜题训练促进了可迁移的推理例程，加强了代数操作、几何推理和组合逻辑，同时在死记硬背或高度专业化的任务上收益有限。这些发现表明，基于逻辑谜题的强化学习重塑了LLMs的内部推理，使其能够实现更鲁棒和组合的泛化，而无需依赖任务特定的符号工具。", "summary": "本文提出了LogicPuzzleRL框架，旨在通过强化学习在自定义逻辑谜题上对大型语言模型（LLMs）进行微调，以解决LLMs在陌生环境结构化推理中的不足。研究发现，这种“玩中学”的方法显著提升了LLMs在数学基准测试上的分布外性能，尤其是在多步推理问题上，培养了可迁移的推理能力，从而实现了更鲁棒和和组合的泛化。", "keywords": "强化学习, 大型语言模型, 数学推理, 逻辑谜题, 分布外泛化"}}
{"id": "2506.04452", "pdf": "https://arxiv.org/pdf/2506.04452", "abs": "https://arxiv.org/abs/2506.04452", "authors": ["Michael Hartisch", "Leroy Chew"], "title": "An Expansion-Based Approach for Quantified Integer Programming", "categories": ["cs.DM", "cs.AI", "cs.LO"], "comment": null, "summary": "Quantified Integer Programming (QIP) bridges multiple domains by extending\nQuantified Boolean Formulas (QBF) to incorporate general integer variables and\nlinear constraints while also generalizing Integer Programming through variable\nquantification. As a special case of Quantified Constraint Satisfaction\nProblems (QCSP), QIP provides a versatile framework for addressing complex\ndecision-making scenarios. Additionally, the inclusion of a linear objective\nfunction enables QIP to effectively model multistage robust discrete linear\noptimization problems, making it a powerful tool for tackling uncertainty in\noptimization.\n  While two primary solution paradigms exist for QBF -- search-based and\nexpansion-based approaches -- only search-based methods have been explored for\nQIP and QCSP. We introduce an expansion-based approach for QIP using\nCounterexample-Guided Abstraction Refinement (CEGAR), adapting techniques from\nQBF. We extend this methodology to tackle multistage robust discrete\noptimization problems with linear constraints and further embed it in an\noptimization framework, enhancing its applicability. Our experimental results\nhighlight the advantages of this approach, demonstrating superior performance\nover existing search-based solvers for QIP in specific instances. Furthermore,\nthe ability to model problems using linear constraints enables notable\nperformance gains over state-of-the-art expansion-based solvers for QBF.", "AI": {"title_translation": "量化整数规划的一种基于扩展的方法", "tldr": "针对量化整数规划（QIP），本文提出了一种基于扩展的CEGAR方法，在特定情况下优于现有搜索型求解器，并能有效处理鲁棒离散优化问题。", "motivation": "现有QIP和QCSP问题主要采用基于搜索的求解方法，缺乏基于扩展的方法。QIP作为一种通用框架，在复杂决策和多阶段鲁棒离散线性优化中具有重要应用，需要更有效的求解方法。", "method": "引入了一种基于扩展的量化整数规划（QIP）方法，该方法利用反例引导的抽象细化（CEGAR），并借鉴了量化布尔公式（QBF）中的技术。该方法进一步扩展到处理具有线性约束的多阶段鲁棒离散优化问题，并嵌入到优化框架中。", "result": "实验结果表明，该方法在特定情况下优于现有的QIP搜索型求解器。此外，通过使用线性约束建模问题，该方法在性能上显著优于最先进的QBF基于扩展的求解器。", "conclusion": "基于扩展的CEGAR方法为QIP提供了一种有效且高性能的求解范式，尤其在处理多阶段鲁棒离散优化问题时，展现出优于现有方法的优势。", "translation": "量化整数规划（QIP）通过将量化布尔公式（QBF）扩展以包含通用整数变量和线性约束，并泛化整数规划通过变量量化，从而连接了多个领域。作为量化约束满足问题（QCSP）的一个特例，QIP为解决复杂决策场景提供了一个通用的框架。此外，包含线性目标函数使得QIP能够有效地建模多阶段鲁棒离散线性优化问题，使其成为处理优化中不确定性的强大工具。\n虽然QBF存在两种主要的求解范式——基于搜索的方法和基于扩展的方法——但对于QIP和QCSP，目前只探索了基于搜索的方法。我们引入了一种基于扩展的QIP方法，该方法使用反例引导的抽象细化（CEGAR），并借鉴了QBF中的技术。我们将此方法扩展以解决具有线性约束的多阶段鲁棒离散优化问题，并进一步将其嵌入到优化框架中，增强了其适用性。我们的实验结果突出了这种方法的优势，在特定实例中，它表现出优于现有QIP基于搜索求解器的性能。此外，利用线性约束对问题进行建模的能力使得其在性能上显著优于最先进的QBF基于扩展的求解器。", "summary": "本文针对量化整数规划（QIP）引入了一种创新的基于扩展的求解方法，该方法利用反例引导的抽象细化（CEGAR），并借鉴了量化布尔公式（QBF）的技术。与目前QIP仅有的基于搜索的求解范式不同，该方法被扩展以处理多阶段鲁棒离散优化问题。实验结果表明，在特定实例中，该方法在性能上优于现有QIP搜索型求解器，并且通过线性约束建模，相对于最先进的QBF基于扩展求解器也有显著提升。", "keywords": "量化整数规划, 基于扩展方法, CEGAR, 鲁棒优化, 线性约束"}}
{"id": "2506.05011", "pdf": "https://arxiv.org/pdf/2506.05011", "abs": "https://arxiv.org/abs/2506.05011", "authors": ["Jaehoon Choi", "Dongki Jung", "Christopher Maxey", "Yonghan Lee", "Sungmin Eum", "Dinesh Manocha", "Heesung Kwon"], "title": "UAV4D: Dynamic Neural Rendering of Human-Centric UAV Imagery using Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "Despite significant advancements in dynamic neural rendering, existing\nmethods fail to address the unique challenges posed by UAV-captured scenarios,\nparticularly those involving monocular camera setups, top-down perspective, and\nmultiple small, moving humans, which are not adequately represented in existing\ndatasets. In this work, we introduce UAV4D, a framework for enabling\nphotorealistic rendering for dynamic real-world scenes captured by UAVs.\nSpecifically, we address the challenge of reconstructing dynamic scenes with\nmultiple moving pedestrians from monocular video data without the need for\nadditional sensors. We use a combination of a 3D foundation model and a human\nmesh reconstruction model to reconstruct both the scene background and humans.\nWe propose a novel approach to resolve the scene scale ambiguity and place both\nhumans and the scene in world coordinates by identifying human-scene contact\npoints. Additionally, we exploit the SMPL model and background mesh to\ninitialize Gaussian splats, enabling holistic scene rendering. We evaluated our\nmethod on three complex UAV-captured datasets: VisDrone, Manipal-UAV, and\nOkutama-Action, each with distinct characteristics and 10~50 humans. Our\nresults demonstrate the benefits of our approach over existing methods in novel\nview synthesis, achieving a 1.5 dB PSNR improvement and superior visual\nsharpness.", "AI": {"title_translation": "UAV4D：使用高斯泼溅技术对以人为中心的无人机图像进行动态神经渲染", "tldr": "UAV4D是一个针对无人机捕获场景的动态神经渲染框架，它解决了单目无人机视频中多移动行人重建的挑战，通过结合3D基础模型和人体网格重建模型，并利用高斯泼溅技术实现了逼真的渲染，性能优于现有方法。", "motivation": "现有动态神经渲染方法未能解决无人机捕获场景（特别是涉及单目相机设置、俯视视角和多个小型移动人类的场景）带来的独特挑战，且现有数据集中对此类场景的表示不足。", "method": "本文提出了UAV4D框架，用于无人机捕获的动态真实世界场景的光逼真渲染。它通过结合3D基础模型和人体网格重建模型来重建场景背景和人体，解决了从单目视频数据重建多移动行人的动态场景的挑战，无需额外传感器。通过识别“人-场景接触点”来解决场景尺度模糊性，并将人和场景置于世界坐标系中。此外，利用SMPL模型和背景网格初始化高斯泼溅，实现整体场景渲染。", "result": "该方法在VisDrone、Manipal-UAV和Okutama-Action三个复杂的无人机捕获数据集上进行了评估，这些数据集具有不同的特征，包含10~50个人。结果表明，该方法在新型视图合成方面优于现有方法，实现了1.5 dB的PSNR提升和卓越的视觉清晰度。", "conclusion": "UAV4D框架有效解决了无人机捕获场景中动态神经渲染的独特挑战，并在新型视图合成方面取得了显著的性能提升，证明了其在光逼真渲染方面的优越性。", "translation": "尽管动态神经渲染取得了显著进展，但现有方法未能解决无人机捕获场景带来的独特挑战，特别是那些涉及单目相机设置、俯视视角和多个小型移动人类的场景，这些在现有数据集中并未得到充分体现。在这项工作中，我们引入了UAV4D，一个用于实现无人机捕获的动态真实世界场景的光逼真渲染的框架。具体而言，我们解决了从单目视频数据重建包含多个移动行人的动态场景的挑战，而无需额外的传感器。我们结合使用3D基础模型和人体网格重建模型来重建场景背景和人体。我们提出了一种新颖的方法来解决场景尺度模糊性，并通过识别“人-场景接触点”将人和场景置于世界坐标系中。此外，我们利用SMPL模型和背景网格初始化高斯泼溅，实现整体场景渲染。我们在三个复杂的无人机捕获数据集上评估了我们的方法：VisDrone、Manipal-UAV和Okutama-Action，每个数据集都具有不同的特征，并包含10~50个人。我们的结果表明，与现有方法相比，我们的方法在新型视图合成方面具有优势，实现了1.5 dB的PSNR提升和卓越的视觉清晰度。", "summary": "UAV4D是一种针对无人机捕获场景的动态神经渲染框架，旨在解决现有方法在处理单目、俯视和多移动行人无人机数据时的不足。该框架结合了3D基础模型和人体网格重建模型，通过识别接触点解决尺度模糊性，并将人和场景置于世界坐标系中。它还利用SMPL模型和背景网格初始化高斯泼溅以实现整体渲染。实验结果表明，UAV4D在新型视图合成方面优于现有方法，PSNR提升1.5 dB，视觉清晰度更高。", "keywords": "无人机渲染, 动态神经渲染, 高斯泼溅, 人体重建, 尺度模糊性"}}
{"id": "2506.04831", "pdf": "https://arxiv.org/pdf/2506.04831", "abs": "https://arxiv.org/abs/2506.04831", "authors": ["Chantal Pellegrini", "Ege Özsoy", "David Bani-Harouni", "Matthias Keicher", "Nassir Navab"], "title": "From EHRs to Patient Pathways: Scalable Modeling of Longitudinal Health Trajectories with LLMs", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Healthcare systems face significant challenges in managing and interpreting\nvast, heterogeneous patient data for personalized care. Existing approaches\noften focus on narrow use cases with a limited feature space, overlooking the\ncomplex, longitudinal interactions needed for a holistic understanding of\npatient health. In this work, we propose a novel approach to patient pathway\nmodeling by transforming diverse electronic health record (EHR) data into a\nstructured representation and designing a holistic pathway prediction model,\nEHR2Path, optimized to predict future health trajectories. Further, we\nintroduce a novel summary mechanism that embeds long-term temporal context into\ntopic-specific summary tokens, improving performance over text-only models,\nwhile being much more token-efficient. EHR2Path demonstrates strong performance\nin both next time-step prediction and longitudinal simulation, outperforming\ncompetitive baselines. It enables detailed simulations of patient trajectories,\ninherently targeting diverse evaluation tasks, such as forecasting vital signs,\nlab test results, or length-of-stay, opening a path towards predictive and\npersonalized healthcare.", "AI": {"title_translation": "从电子病历到患者路径：使用大型语言模型对纵向健康轨迹进行可扩展建模", "tldr": "本文提出EHR2Path模型，利用大型语言模型将电子健康记录（EHR）数据转化为结构化患者路径，以实现对未来健康轨迹的可扩展预测和个性化医疗。", "motivation": "现有医疗系统在管理和解释大量异构患者数据以实现个性化护理方面面临重大挑战，现有方法通常侧重于狭窄的用例，特征空间有限，忽视了全面理解患者健康所需的复杂、纵向交互。", "method": "本文提出一种新的患者路径建模方法EHR2Path，通过将多样化的电子健康记录（EHR）数据转换为结构化表示，并设计一个整体路径预测模型来预测未来的健康轨迹。此外，该方法引入了一种新颖的摘要机制，将长期时间上下文嵌入到主题特定的摘要标记中，以提高性能和标记效率。", "result": "EHR2Path在下一步预测和纵向模拟中均表现出强大的性能，优于竞争基线。它能够详细模拟患者轨迹，并针对各种评估任务，例如预测生命体征、实验室测试结果或住院时间。", "conclusion": "EHR2Path为预测性和个性化医疗开辟了道路。", "translation": "医疗系统在管理和解释大量异构患者数据以实现个性化护理方面面临重大挑战。现有方法通常侧重于狭窄的用例，特征空间有限，忽视了全面理解患者健康所需的复杂、纵向交互。在这项工作中，我们提出了一种新的患者路径建模方法，通过将多样化的电子健康记录（EHR）数据转换为结构化表示，并设计了一个整体路径预测模型EHR2Path，该模型经过优化以预测未来的健康轨迹。此外，我们引入了一种新颖的摘要机制，将长期时间上下文嵌入到主题特定的摘要标记中，与纯文本模型相比，该机制提高了性能，同时标记效率更高。EHR2Path在下一步预测和纵向模拟中均表现出强大的性能，优于竞争基线。它能够详细模拟患者轨迹，固有地针对各种评估任务，例如预测生命体征、实验室测试结果或住院时间，为预测性和个性化医疗开辟了道路。", "summary": "本文提出EHR2Path模型，旨在解决医疗系统在个性化护理中处理复杂、纵向患者数据面临的挑战。该模型将电子健康记录（EHR）数据转换为结构化表示，并利用新颖的摘要机制将长期时间上下文嵌入到主题特定标记中。EHR2Path在健康轨迹预测和纵向模拟方面表现出色，超越现有基线，并能详细模拟患者轨迹，支持生命体征、实验室结果和住院时间等预测任务，为实现预测性和个性化医疗奠定基础。", "keywords": "EHRs, 患者路径, 纵向健康, 大型语言模型, 预测性医疗"}}
{"id": "2506.04386", "pdf": "https://arxiv.org/pdf/2506.04386", "abs": "https://arxiv.org/abs/2506.04386", "authors": ["Vicenzo Bonasorte"], "title": "Rumors on evolving graphs through stationary times", "categories": ["cs.DS", "cs.DM", "math.PR"], "comment": "11 pages", "summary": "We study rumor spreading in dynamic random graphs. Starting with a single\ninformed vertex, the information flows until it reaches all the vertices of the\ngraph (completion), according to the following process. At each step $k$, the\ninformation is propagated to neighbors of the informed vertices, in the $k$-th\ngenerated random graph. The way this information propagates from vertex to\nvertex at each step will depend on the ``protocol\". We provide a method based\non strong stationary times to study the completion time when the graphs are\nMarkovian time dependent, using known results of the literature for independent\ngraphs. The concept of strong stationary times is then extended to\nnon-Markovian Dynamics using coupling from the past algorithms. This allows to\nextend results on completion times for non-Markov dynamics", "AI": {"title_translation": "基于平稳时间的演化图上的谣言传播", "tldr": "本文研究了动态随机图中谣言传播的完成时间，提出了一种基于强平稳时间的方法，并将其扩展到非马尔可夫动态。", "motivation": "研究动态随机图中谣言（信息）从单个初始节点传播直到到达图中所有顶点的过程（完成），并分析其完成时间。", "method": "文章提出了一种基于强平稳时间的方法来研究马尔可夫时间相关图的完成时间，该方法利用了现有文献中关于独立图的结果。随后，通过“耦合自过去”算法将强平稳时间的概念扩展到非马尔可夫动态。", "result": "该方法成功地将完成时间的结果扩展到了非马尔可夫动态图。", "conclusion": "本文提出了一种有效的方法，利用强平稳时间的概念，成功地研究了马尔可夫和非马尔可夫动态图中谣言传播的完成时间，扩展了相关研究成果。", "translation": "我们研究了动态随机图中的谣言传播。从一个单一的知情顶点开始，信息根据以下过程流动，直到它到达图中的所有顶点（完成）。在每个步骤 k 中，信息在第 k 个生成的随机图中传播到知情顶点的邻居。信息在每个步骤中从一个顶点传播到另一个顶点的方式将取决于“协议”。我们提供了一种基于强平稳时间的方法，利用文献中关于独立图的已知结果，来研究图为马尔可夫时间相关时的完成时间。然后，使用“耦合自过去”算法将强平稳时间的概念扩展到非马尔可夫动态。这使得完成时间的结果能够扩展到非马尔可夫动态。", "summary": "本文探讨了动态随机图中谣言传播的机制和完成时间。研究从一个初始知情节点开始，信息如何在每个步骤中传播，直到到达图中的所有节点。作者提出了一种基于强平稳时间的方法来分析马尔可夫时间相关图的完成时间，并进一步通过“耦合自过去”算法将该概念推广到非马尔可夫动态，从而扩展了对非马尔可夫动态完成时间的研究成果。", "keywords": "谣言传播, 动态图, 平稳时间, 完成时间, 非马尔可夫动态"}}
{"id": "2506.05026", "pdf": "https://arxiv.org/pdf/2506.05026", "abs": "https://arxiv.org/abs/2506.05026", "authors": ["Oliver Krumpek", "Oliver Heimann", "Jörg Krüger"], "title": "Physical Annotation for Automated Optical Inspection: A Concept for In-Situ, Pointer-Based Trainingdata Generation", "categories": ["cs.CV"], "comment": null, "summary": "This paper introduces a novel physical annotation system designed to generate\ntraining data for automated optical inspection. The system uses pointer-based\nin-situ interaction to transfer the valuable expertise of trained inspection\npersonnel directly into a machine learning (ML) training pipeline. Unlike\nconventional screen-based annotation methods, our system captures physical\ntrajectories and contours directly on the object, providing a more intuitive\nand efficient way to label data. The core technology uses calibrated, tracked\npointers to accurately record user input and transform these spatial\ninteractions into standardised annotation formats that are compatible with\nopen-source annotation software. Additionally, a simple projector-based\ninterface projects visual guidance onto the object to assist users during the\nannotation process, ensuring greater accuracy and consistency. The proposed\nconcept bridges the gap between human expertise and automated data generation,\nenabling non-IT experts to contribute to the ML training pipeline and\npreventing the loss of valuable training samples. Preliminary evaluation\nresults confirm the feasibility of capturing detailed annotation trajectories\nand demonstrate that integration with CVAT streamlines the workflow for\nsubsequent ML tasks. This paper details the system architecture, calibration\nprocedures and interface design, and discusses its potential contribution to\nfuture ML data generation for automated optical inspection.", "AI": {"title_translation": "用于自动化光学检测的物理标注：一种用于原位、基于指针的训练数据生成概念", "tldr": "提出一种物理标注系统，利用指针原位交互为自动化光学检测生成训练数据，比传统屏幕标注更直观高效。", "motivation": "现有的屏幕标注方法不直观，难以将训练有素的检测人员的专业知识直接转化为机器学习训练数据，导致有价值的训练样本流失。该系统旨在弥合人类专业知识与自动化数据生成之间的差距，使非IT专家也能参与机器学习训练。", "method": "该系统采用基于指针的原位交互，直接在物体上捕获物理轨迹和轮廓。核心技术使用经过校准和跟踪的指针精确记录用户输入，并将其转换为标准化标注格式。辅助以基于投影仪的界面，将视觉指导投射到物体上，提高标注的准确性和一致性。", "result": "初步评估结果证实了捕获详细标注轨迹的可行性，并表明与CVAT集成可简化后续机器学习任务的工作流程。", "conclusion": "该系统为自动化光学检测的未来机器学习数据生成提供了新的贡献，通过弥合人类专业知识与自动化数据生成之间的差距，使非IT专家也能参与机器学习训练，并防止有价值训练样本的流失。", "translation": "本文介绍了一种新颖的物理标注系统，旨在为自动化光学检测生成训练数据。该系统采用基于指针的原位交互，将训练有素的检测人员的宝贵专业知识直接转化为机器学习（ML）训练流程。与传统的基于屏幕的标注方法不同，我们的系统直接在物体上捕获物理轨迹和轮廓，提供了一种更直观高效的数据标注方式。其核心技术使用经过校准和跟踪的指针精确记录用户输入，并将这些空间交互转换为与开源标注软件兼容的标准化标注格式。此外，一个简单的基于投影仪的界面将视觉指导投射到物体上，以协助用户进行标注过程，确保更高的准确性和一致性。所提出的概念弥合了人类专业知识与自动化数据生成之间的差距，使非IT专家也能为机器学习训练流程做出贡献，并防止有价值训练样本的流失。初步评估结果证实了捕获详细标注轨迹的可行性，并表明与CVAT集成可简化后续机器学习任务的工作流程。本文详细介绍了系统架构、校准程序和界面设计，并讨论了其对未来自动化光学检测机器学习数据生成的潜在贡献。", "summary": "本文提出一种创新的物理标注系统，专为自动化光学检测生成训练数据。该系统利用基于指针的原位交互，直接在物体上捕获物理轨迹和轮廓，克服了传统屏幕标注的局限性，实现了更直观高效的数据标注。通过校准和跟踪指针记录用户输入，并结合投影仪提供视觉指导，确保了标注的准确性和一致性。初步评估表明该系统可行，并能简化机器学习工作流程，有助于将人类专业知识有效转化为机器学习训练数据，并赋能非IT专家参与机器学习训练。", "keywords": "物理标注, 自动化光学检测, 训练数据生成, 指针交互, 机器学习"}}
{"id": "2506.04859", "pdf": "https://arxiv.org/pdf/2506.04859", "abs": "https://arxiv.org/abs/2506.04859", "authors": ["Yin Lu", "Tong He", "Xuening Zhu", "David Wipf"], "title": "Sparse Autoencoders, Again?", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to the International Conference on Machine Learning (ICML)\n  2025", "summary": "Is there really much more to say about sparse autoencoders (SAEs)?\nAutoencoders in general, and SAEs in particular, represent deep architectures\nthat are capable of modeling low-dimensional latent structure in data. Such\nstructure could reflect, among other things, correlation patterns in large\nlanguage model activations, or complex natural image manifolds. And yet despite\nthe wide-ranging applicability, there have been relatively few changes to SAEs\nbeyond the original recipe from decades ago, namely, standard deep\nencoder/decoder layers trained with a classical/deterministic sparse\nregularizer applied within the latent space. One possible exception is the\nvariational autoencoder (VAE), which adopts a stochastic encoder module capable\nof producing sparse representations when applied to manifold data. In this work\nwe formalize underappreciated weaknesses with both canonical SAEs, as well as\nanalogous VAEs applied to similar tasks, and propose a hybrid alternative model\nthat circumvents these prior limitations. In terms of theoretical support, we\nprove that global minima of our proposed model recover certain forms of\nstructured data spread across a union of manifolds. Meanwhile, empirical\nevaluations on synthetic and real-world datasets substantiate the efficacy of\nour approach in accurately estimating underlying manifold dimensions and\nproducing sparser latent representations without compromising reconstruction\nerror. In general, we are able to exceed the performance of equivalent-capacity\nSAEs and VAEs, as well as recent diffusion models where applicable, within\ndomains such as images and language model activation patterns.", "AI": {"title_translation": "稀疏自编码器，又来了？", "tldr": "本文形式化了传统稀疏自编码器（SAE）和变分自编码器（VAE）的弱点，并提出了一种混合模型，该模型在理论上可以恢复结构化数据，并在经验上超越了现有模型，能够更好地估计流形维度并产生更稀疏的潜在表示。", "motivation": "传统的稀疏自编码器（SAE）和变分自编码器（VAE）在建模低维潜在结构方面存在未被充分认识的弱点，尽管它们应用广泛，但其核心方法自几十年前以来几乎没有改变。", "method": "本文提出了一种混合替代模型，旨在规避传统稀疏自编码器和变分自编码器在类似任务中的局限性。", "result": "在理论上，该模型证明了其全局最小值可以恢复某些形式的分布在流形联合上的结构化数据。在经验上，该方法在合成和真实世界数据集上的评估证实了其在准确估计底层流形维度和生成更稀疏潜在表示方面的有效性，且不影响重建误差。该模型在图像和语言模型激活模式等领域，性能优于同等容量的SAE和VAE，以及适用的最新扩散模型。", "conclusion": "本文提出的混合模型能够有效地解决传统稀疏自编码器和变分自编码器的局限性，在理论和实践中均表现出优越性，尤其是在估计流形维度和生成稀疏表示方面。", "translation": "关于稀疏自编码器（SAE），真的还有更多要说的吗？\n自编码器，特别是SAE，代表了能够建模数据中低维潜在结构的深度架构。这种结构可能反映，除其他外，大型语言模型激活中的相关模式，或复杂的自然图像流形。然而，尽管应用广泛，SAE除了几十年前的原始配方（即，使用在潜在空间中应用的经典/确定性稀疏正则化器训练的标准深度编码器/解码器层）之外，变化相对较少。一个可能的例外是变分自编码器（VAE），它采用了一种随机编码器模块，当应用于流形数据时能够产生稀疏表示。在这项工作中，我们形式化了传统SAE以及应用于类似任务的类比VAE中未被充分认识的弱点，并提出了一种混合替代模型，该模型规避了这些先前的局限性。在理论支持方面，我们证明了我们提出的模型的全局最小值恢复了分布在流形联合上的某些形式的结构化数据。同时，在合成和真实世界数据集上的实证评估证实了我们方法在准确估计底层流形维度和生成更稀疏潜在表示方面的有效性，且不损害重建误差。总的来说，我们能够在图像和语言模型激活模式等领域，超越同等容量的SAE和VAE，以及适用的最新扩散模型的性能。", "summary": "本文深入探讨了稀疏自编码器（SAE）和变分自编码器（VAE）的固有弱点，并提出了一种创新的混合模型来克服这些局限性。该模型在理论上被证明能够恢复流形联合上的结构化数据，并在实践中展示了其在准确估计流形维度和生成更稀疏潜在表示方面的卓越性能，超越了现有SAE、VAE和扩散模型。", "keywords": "稀疏自编码器, 变分自编码器, 流形学习, 稀疏表示, 潜在结构"}}
{"id": "2506.04389", "pdf": "https://arxiv.org/pdf/2506.04389", "abs": "https://arxiv.org/abs/2506.04389", "authors": ["Saurabh Kumar", "Sourav Bansal", "Neeraj Agrawal", "Priyanka Bhatt"], "title": "Building a Few-Shot Cross-Domain Multilingual NLU Model for Customer Care", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Customer care is an essential pillar of the e-commerce shopping experience\nwith companies spending millions of dollars each year, employing automation and\nhuman agents, across geographies (like US, Canada, Mexico, Chile), channels\n(like Chat, Interactive Voice Response (IVR)), and languages (like English,\nSpanish). SOTA pre-trained models like multilingual-BERT, fine-tuned on\nannotated data have shown good performance in downstream tasks relevant to\nCustomer Care. However, model performance is largely subject to the\navailability of sufficient annotated domain-specific data. Cross-domain\navailability of data remains a bottleneck, thus building an intent classifier\nthat generalizes across domains (defined by channel, geography, and language)\nwith only a few annotations, is of great practical value. In this paper, we\npropose an embedder-cum-classifier model architecture which extends\nstate-of-the-art domain-specific models to other domains with only a few\nlabeled samples. We adopt a supervised fine-tuning approach with isotropic\nregularizers to train a domain-specific sentence embedder and a multilingual\nknowledge distillation strategy to generalize this embedder across multiple\ndomains. The trained embedder, further augmented with a simple linear\nclassifier can be deployed for new domains. Experiments on Canada and Mexico\ne-commerce Customer Care dataset with few-shot intent detection show an\nincrease in accuracy by 20-23% against the existing state-of-the-art\npre-trained models.", "AI": {"title_translation": "构建一个用于客户服务的少样本跨领域多语言NLU模型", "tldr": "本文提出了一种新的模型架构，通过少量的标注数据，将现有的领域特定NLU模型扩展到新的领域，并在客户服务数据上实现了显著的准确性提升。", "motivation": "现有预训练模型在客户服务NLU任务上表现良好，但高度依赖于充足的领域特定标注数据。跨领域数据稀缺是一个瓶颈，因此需要一个能够用少量标注数据泛化到不同领域（渠道、地理、语言）的意图分类器。", "method": "本文提出了一种结合嵌入器和分类器的模型架构。该方法采用带有各向同性正则化的监督微调来训练领域特定句子嵌入器，并使用多语言知识蒸馏策略将此嵌入器泛化到多个领域。训练好的嵌入器可与简单线性分类器结合用于新领域。", "result": "在加拿大和墨西哥电子商务客户服务数据集上进行的少样本意图检测实验表明，与现有最先进的预训练模型相比，准确率提高了20-23%。", "conclusion": "通过提出的嵌入器-分类器模型架构、监督微调和多语言知识蒸馏策略，可以有效地构建一个少样本、跨领域、多语言的NLU模型，显著提升客户服务领域在数据稀缺情况下的性能。", "translation": "客户服务是电子商务购物体验的重要支柱，公司每年投入数百万美元，在不同地区（如美国、加拿大、墨西哥、智利）、渠道（如聊天、交互式语音应答 (IVR)）和语言（如英语、西班牙语）部署自动化和人工客服。最先进的预训练模型，如多语言BERT，在标注数据上进行微调后，在与客户服务相关的下游任务中表现良好。然而，模型性能很大程度上取决于是否有足够的标注领域特定数据。跨领域数据的可用性仍然是一个瓶颈，因此，构建一个仅用少量标注数据就能在不同领域（由渠道、地理和语言定义）泛化的意图分类器具有重要的实际价值。在本文中，我们提出了一种嵌入器-分类器模型架构，它能将最先进的领域特定模型仅用少量标记样本扩展到其他领域。我们采用带有各向同性正则化的监督微调方法来训练领域特定句子嵌入器，并采用多语言知识蒸馏策略将此嵌入器泛化到多个领域。训练好的嵌入器，进一步通过简单的线性分类器增强，可以部署到新的领域。在加拿大和墨西哥电子商务客户服务数据集上进行的少样本意图检测实验显示，与现有最先进的预训练模型相比，准确率提高了20-23%。", "summary": "本文针对客户服务领域NLU模型面临的跨领域数据稀缺问题，提出了一种少样本、跨领域、多语言的NLU模型架构。该模型通过监督微调训练领域特定句子嵌入器，并利用多语言知识蒸馏策略实现跨领域泛化。实验结果显示，在少样本意图检测任务上，该模型比现有SOTA预训练模型准确率提高了20-23%。", "keywords": "少样本学习, 跨领域, 多语言NLU, 客户服务, 意图分类"}}
{"id": "2506.04467", "pdf": "https://arxiv.org/pdf/2506.04467", "abs": "https://arxiv.org/abs/2506.04467", "authors": ["Yuzhen Ding", "Jason Holmes", "Hongying Feng", "Martin Bues", "Lisa A. McGee", "Jean-Claude M. Rwigema", "Nathan Y. Yu", "Terence S. Sio", "Sameer R. Keole", "William W. Wong", "Steven E. Schild", "Jonathan B. Ashman", "Sujay A. Vora", "Daniel J. Ma", "Samir H. Patel", "Wei Liu"], "title": "Diffusion Transformer-based Universal Dose Denoising for Pencil Beam Scanning Proton Therapy", "categories": ["physics.med-ph", "cs.AI"], "comment": null, "summary": "Purpose: Intensity-modulated proton therapy (IMPT) offers precise tumor\ncoverage while sparing organs at risk (OARs) in head and neck (H&N) cancer.\nHowever, its sensitivity to anatomical changes requires frequent adaptation\nthrough online adaptive radiation therapy (oART), which depends on fast,\naccurate dose calculation via Monte Carlo (MC) simulations. Reducing particle\ncount accelerates MC but degrades accuracy. To address this, denoising\nlow-statistics MC dose maps is proposed to enable fast, high-quality dose\ngeneration.\n  Methods: We developed a diffusion transformer-based denoising framework. IMPT\nplans and 3D CT images from 80 H&N patients were used to generate noisy and\nhigh-statistics dose maps using MCsquare (1 min and 10 min per plan,\nrespectively). Data were standardized into uniform chunks with zero-padding,\nnormalized, and transformed into quasi-Gaussian distributions. Testing was done\non 10 H&N, 10 lung, 10 breast, and 10 prostate cancer cases, preprocessed\nidentically. The model was trained with noisy dose maps and CT images as input\nand high-statistics dose maps as ground truth, using a combined loss of mean\nsquare error (MSE), residual loss, and regional MAE (focusing on top/bottom 10%\ndose voxels). Performance was assessed via MAE, 3D Gamma passing rate, and DVH\nindices.\n  Results: The model achieved MAEs of 0.195 (H&N), 0.120 (lung), 0.172\n(breast), and 0.376 Gy[RBE] (prostate). 3D Gamma passing rates exceeded 92%\n(3%/2mm) across all sites. DVH indices for clinical target volumes (CTVs) and\nOARs closely matched the ground truth.\n  Conclusion: A diffusion transformer-based denoising framework was developed\nand, though trained only on H&N data, generalizes well across multiple disease\nsites.", "AI": {"title_translation": "基于扩散Transformer的铅笔束扫描质子治疗通用剂量去噪", "tldr": "开发了一种基于扩散Transformer的去噪框架，用于加速蒙特卡洛剂量计算，并在多种癌症类型中表现出良好的泛化能力。", "motivation": "强度调控质子治疗(IMPT)对解剖变化敏感，需要频繁适应。在线自适应放射治疗(oART)依赖于快速、准确的蒙特卡洛(MC)剂量计算。减少MC粒子数量可以加速计算但会降低精度，因此提出对低统计量MC剂量图进行去噪以实现快速、高质量的剂量生成。", "method": "开发了一个基于扩散Transformer的去噪框架。使用来自80名头颈部患者的IMPT计划和3D CT图像，通过MCsquare生成噪声（1分钟）和高统计量（10分钟）剂量图。数据经过标准化、归一化和准高斯分布转换。模型以噪声剂量图和CT图像作为输入，高统计量剂量图作为真实值进行训练，结合了均方误差(MSE)、残差损失和区域MAE（关注顶部/底部10%剂量体素）作为损失函数。在10名头颈部、10名肺部、10名乳腺和10名前列腺癌病例上进行测试。性能通过MAE、3D Gamma通过率和DVH指数评估。", "result": "模型在头颈部、肺部、乳腺和前列腺的MAE分别为0.195、0.120、0.172和0.376 Gy[RBE]。所有部位的3D Gamma通过率均超过92%（3%/2mm）。临床靶区(CTV)和危及器官(OAR)的DVH指数与真实值非常接近。", "conclusion": "开发了一种基于扩散Transformer的去噪框架，尽管仅在头颈部数据上进行训练，但在多种疾病部位上表现出良好的泛化能力。", "translation": "目的：强度调控质子治疗(IMPT)在头颈部(H&N)癌症中提供精确的肿瘤覆盖，同时保护危及器官(OARs)。然而，其对解剖变化的敏感性需要通过在线自适应放射治疗(oART)进行频繁适应，这依赖于通过蒙特卡洛(MC)模拟进行快速、准确的剂量计算。减少粒子数量可以加速MC但会降低精度。为了解决这个问题，提出了对低统计量MC剂量图进行去噪，以实现快速、高质量的剂量生成。\n方法：我们开发了一个基于扩散Transformer的去噪框架。使用来自80名头颈部患者的IMPT计划和3D CT图像，通过MCsquare分别生成噪声（每计划1分钟）和高统计量（每计划10分钟）剂量图。数据被标准化为带零填充的均匀块，进行归一化，并转换为准高斯分布。在10名头颈部、10名肺部、10名乳腺和10名前列腺癌病例上进行测试，预处理方式相同。模型以噪声剂量图和CT图像作为输入，高统计量剂量图作为真实值进行训练，使用均方误差(MSE)、残差损失和区域MAE（关注顶部/底部10%剂量体素）的组合损失。性能通过MAE、3D Gamma通过率和DVH指数评估。\n结果：模型在头颈部、肺部、乳腺和前列腺的MAE分别为0.195、0.120、0.172和0.376 Gy[RBE]。所有部位的3D Gamma通过率均超过92%（3%/2mm）。临床靶区(CTV)和危及器官(OAR)的DVH指数与真实值非常接近。\n结论：开发了一种基于扩散Transformer的去噪框架，尽管仅在头颈部数据上进行训练，但在多种疾病部位上表现出良好的泛化能力。", "summary": "本研究提出了一种基于扩散Transformer的去噪框架，旨在解决强度调控质子治疗中蒙特卡洛剂量计算速度与精度之间的矛盾。通过对低统计量蒙特卡洛剂量图进行去噪，该模型能够在加速计算的同时保持高精度。尽管仅使用头颈部患者数据进行训练，该框架在头颈部、肺部、乳腺和前列腺等多种癌症类型中均表现出优秀的去噪性能和泛化能力，为快速、高质量的剂量生成提供了可能。", "keywords": "扩散Transformer, 剂量去噪, 质子治疗, 蒙特卡洛模拟, 泛化能力"}}
{"id": "2506.05046", "pdf": "https://arxiv.org/pdf/2506.05046", "abs": "https://arxiv.org/abs/2506.05046", "authors": ["Guangzhao Li", "Yanming Yang", "Chenxi Song", "Chi Zhang"], "title": "FlowDirector: Training-Free Flow Steering for Precise Text-to-Video Editing", "categories": ["cs.CV"], "comment": "Project Page is https://flowdirector-edit.github.io", "summary": "Text-driven video editing aims to modify video content according to natural\nlanguage instructions. While recent training-free approaches have made progress\nby leveraging pre-trained diffusion models, they typically rely on\ninversion-based techniques that map input videos into the latent space, which\noften leads to temporal inconsistencies and degraded structural fidelity. To\naddress this, we propose FlowDirector, a novel inversion-free video editing\nframework. Our framework models the editing process as a direct evolution in\ndata space, guiding the video via an Ordinary Differential Equation (ODE) to\nsmoothly transition along its inherent spatiotemporal manifold, thereby\npreserving temporal coherence and structural details. To achieve localized and\ncontrollable edits, we introduce an attention-guided masking mechanism that\nmodulates the ODE velocity field, preserving non-target regions both spatially\nand temporally. Furthermore, to address incomplete edits and enhance semantic\nalignment with editing instructions, we present a guidance-enhanced editing\nstrategy inspired by Classifier-Free Guidance, which leverages differential\nsignals between multiple candidate flows to steer the editing trajectory toward\nstronger semantic alignment without compromising structural consistency.\nExtensive experiments across benchmarks demonstrate that FlowDirector achieves\nstate-of-the-art performance in instruction adherence, temporal consistency,\nand background preservation, establishing a new paradigm for efficient and\ncoherent video editing without inversion.", "AI": {"title_translation": "FlowDirector：免训练的流引导实现精确文本到视频编辑", "tldr": "FlowDirector是一种免反演的视频编辑框架，通过ODE和注意力引导机制实现精确、时序一致的文本到视频编辑，并在性能上超越现有方法。", "motivation": "现有的文本驱动视频编辑方法多依赖基于反演的技术，将输入视频映射到潜在空间，这常导致时间不一致性和结构保真度下降。", "method": "我们提出了FlowDirector，一个新颖的免反演视频编辑框架。它将编辑过程建模为数据空间的直接演化，通过常微分方程（ODE）引导视频在固有时空流形上平滑过渡，以保持时间连贯性和结构细节。为实现局部可控编辑，引入注意力引导的掩蔽机制来调节ODE速度场。此外，为解决不完整编辑并增强语义对齐，提出了一种受Classifier-Free Guidance启发的引导增强编辑策略，利用多候选流之间的差异信号来引导编辑轨迹。", "result": "广泛的基准实验表明，FlowDirector在指令依从性、时间一致性和背景保留方面达到了最先进的性能。", "conclusion": "FlowDirector为高效、连贯且无需反演的视频编辑建立了一个新范式。", "translation": "文本驱动的视频编辑旨在根据自然语言指令修改视频内容。尽管最近的免训练方法通过利用预训练扩散模型取得了进展，但它们通常依赖于将输入视频映射到潜在空间的反演技术，这常常导致时间不一致性和结构保真度下降。为解决此问题，我们提出了FlowDirector，一个新颖的免反演视频编辑框架。我们的框架将编辑过程建模为数据空间的直接演化，通过常微分方程（ODE）引导视频在其固有的时空流形上平滑过渡，从而保持时间连贯性和结构细节。为实现局部和可控编辑，我们引入了一种注意力引导的掩蔽机制，它调节ODE速度场，在空间和时间上保留非目标区域。此外，为解决不完整编辑并增强与编辑指令的语义对齐，我们提出了一种受Classifier-Free Guidance启发的引导增强编辑策略，该策略利用多个候选流之间的差异信号来引导编辑轨迹，以实现更强的语义对齐，同时不损害结构一致性。广泛的基准实验表明，FlowDirector在指令依从性、时间一致性和背景保留方面达到了最先进的性能，为无需反演的高效、连贯视频编辑建立了一个新范式。", "summary": "本文提出了FlowDirector，一种新颖的免反演文本驱动视频编辑框架，旨在解决现有基于反演方法的时间不一致性和结构保真度问题。FlowDirector将编辑过程视为数据空间的直接演化，利用常微分方程（ODE）来保持视频的时空连贯性。它还引入了注意力引导的掩蔽机制以实现局部编辑，并采用引导增强策略来提升语义对齐。实验证明，FlowDirector在指令依从性、时间一致性和背景保留方面均达到了最先进的性能。", "keywords": "FlowDirector, 文本到视频编辑, 免反演, ODE, 时间一致性"}}
{"id": "2506.04870", "pdf": "https://arxiv.org/pdf/2506.04870", "abs": "https://arxiv.org/abs/2506.04870", "authors": ["Antonio Almudévar", "José Miguel Hernández-Lobato", "Sameer Khurana", "Ricard Marxer", "Alfonso Ortega"], "title": "Aligning Multimodal Representations through an Information Bottleneck", "categories": ["cs.LG"], "comment": null, "summary": "Contrastive losses have been extensively used as a tool for multimodal\nrepresentation learning. However, it has been empirically observed that their\nuse is not effective to learn an aligned representation space. In this paper,\nwe argue that this phenomenon is caused by the presence of modality-specific\ninformation in the representation space. Although some of the most widely used\ncontrastive losses maximize the mutual information between representations of\nboth modalities, they are not designed to remove the modality-specific\ninformation. We give a theoretical description of this problem through the lens\nof the Information Bottleneck Principle. We also empirically analyze how\ndifferent hyperparameters affect the emergence of this phenomenon in a\ncontrolled experimental setup. Finally, we propose a regularization term in the\nloss function that is derived by means of a variational approximation and aims\nto increase the representational alignment. We analyze in a set of controlled\nexperiments and real-world applications the advantages of including this\nregularization term.", "AI": {"title_translation": "通过信息瓶颈对齐多模态表示", "tldr": "对比损失在多模态表示学习中未能有效对齐表示空间，本文通过信息瓶颈原理分析其原因，并提出一种正则化项以提高表示对齐度。", "motivation": "对比损失被广泛用于多模态表示学习，但经验观察表明它们在学习对齐的表示空间方面效果不佳。本文认为这是由于表示空间中存在模态特异性信息所致，尽管一些常用的对比损失最大化了两种模态表示之间的互信息，但它们并未设计用于去除模态特异性信息。", "method": "本文通过信息瓶颈原理对该问题进行了理论描述，并实证分析了不同超参数如何影响这种现象的出现。最后，提出了一种通过变分近似导出的损失函数中的正则化项，旨在提高表示对齐度。", "result": "在受控实验和实际应用中，分析了包含该正则化项的优势。", "conclusion": "本文提出了一种新的正则化项，有效解决了对比损失在多模态表示学习中表示对齐不佳的问题，并通过理论分析和实验验证了其有效性。", "translation": "对比损失已被广泛用作多模态表示学习的工具。然而，经验观察表明，它们的使用对于学习对齐的表示空间并不有效。在本文中，我们认为这种现象是由表示空间中存在模态特异性信息引起的。尽管一些最广泛使用的对比损失最大化了两种模态表示之间的互信息，但它们并未设计用于去除模态特异性信息。我们通过信息瓶颈原理从理论上描述了这个问题。我们还通过受控实验设置，实证分析了不同超参数如何影响这种现象的出现。最后，我们提出了一种损失函数中的正则化项，该项通过变分近似导出，旨在增加表示对齐度。我们在受控实验和实际应用中分析了包含该正则化项的优势。", "summary": "本文研究了对比损失在多模态表示学习中未能有效对齐表示空间的问题，并将其归因于表示空间中模态特异性信息的存在。作者通过信息瓶颈原理对该问题进行了理论阐述，并提出了一种基于变分近似的正则化项，以增强表示的对齐度。实验结果表明，该正则化项在受控实验和实际应用中均能带来优势。", "keywords": "多模态表示, 信息瓶颈, 对比学习, 表示对齐, 正则化"}}
{"id": "2506.05061", "pdf": "https://arxiv.org/pdf/2506.05061", "abs": "https://arxiv.org/abs/2506.05061", "authors": ["Anh Le", "Thanh Lam", "Dung Nguyen"], "title": "A Survey on Vietnamese Document Analysis and Recognition: Challenges and Future Directions", "categories": ["cs.CV"], "comment": null, "summary": "Vietnamese document analysis and recognition (DAR) is a crucial field with\napplications in digitization, information retrieval, and automation. Despite\nadvancements in OCR and NLP, Vietnamese text recognition faces unique\nchallenges due to its complex diacritics, tonal variations, and lack of\nlarge-scale annotated datasets. Traditional OCR methods often struggle with\nreal-world document variations, while deep learning approaches have shown\npromise but remain limited by data scarcity and generalization issues.\nRecently, large language models (LLMs) and vision-language models have\ndemonstrated remarkable improvements in text recognition and document\nunderstanding, offering a new direction for Vietnamese DAR. However, challenges\nsuch as domain adaptation, multimodal learning, and computational efficiency\npersist. This survey provide a comprehensive review of existing techniques in\nVietnamese document recognition, highlights key limitations, and explores how\nLLMs can revolutionize the field. We discuss future research directions,\nincluding dataset development, model optimization, and the integration of\nmultimodal approaches for improved document intelligence. By addressing these\ngaps, we aim to foster advancements in Vietnamese DAR and encourage\ncommunity-driven solutions.", "AI": {"title_translation": "越南文档分析与识别综述：挑战与未来方向", "tldr": "本综述全面回顾了越南文档分析与识别（DAR）领域的现有技术、挑战，并探讨了大型语言模型（LLMs）在DAR中的潜力及未来研究方向。", "motivation": "越南文档分析与识别（DAR）在数字化、信息检索和自动化方面至关重要，但面临复杂变音符号、声调变化和大规模标注数据集缺乏等独特挑战。传统OCR方法和深度学习方法存在局限性，而大型语言模型（LLMs）为该领域提供了新的方向，但仍有待解决的挑战。因此，本综述旨在全面回顾现有技术并探讨未来发展方向。", "method": "本综述全面回顾了越南文档识别中的现有技术，强调了其主要局限性，并探讨了大型语言模型（LLMs）如何彻底改变该领域。文章还讨论了未来的研究方向。", "result": "现有技术在越南文档识别方面存在局限性，特别是传统OCR方法和深度学习方法。大型语言模型（LLMs）和视觉-语言模型在文本识别和文档理解方面显示出显著改进，为越南DAR提供了新的方向，但仍面临领域适应、多模态学习和计算效率等挑战。", "conclusion": "通过解决数据集开发、模型优化和多模态方法集成等方面的差距，旨在促进越南文档分析与识别（DAR）的进步，并鼓励社区驱动的解决方案。", "translation": "越南文档分析与识别（DAR）是数字化、信息检索和自动化应用中的关键领域。尽管OCR和NLP取得了进展，但越南语文本识别因其复杂的变音符号、声调变化和缺乏大规模标注数据集而面临独特的挑战。传统的OCR方法通常难以应对真实世界的文档变化，而深度学习方法虽然前景广阔，但仍受数据稀缺和泛化问题的限制。最近，大型语言模型（LLMs）和视觉-语言模型在文本识别和文档理解方面表现出显著的改进，为越南DAR提供了新的方向。然而，领域适应、多模态学习和计算效率等挑战依然存在。本综述全面回顾了越南文档识别中的现有技术，强调了主要局限性，并探讨了LLMs如何彻底改变该领域。我们讨论了未来的研究方向，包括数据集开发、模型优化以及多模态方法的集成，以提高文档智能。通过解决这些差距，我们旨在促进越南DAR的进步并鼓励社区驱动的解决方案。", "summary": "本综述探讨了越南文档分析与识别（DAR）领域的挑战与进展。尽管OCR和NLP有所发展，但越南语的复杂性导致传统方法受限，深度学习也面临数据稀缺问题。大型语言模型（LLMs）和视觉-语言模型为DAR带来了新机遇，但仍存在领域适应、多模态学习和计算效率等挑战。该综述全面回顾了现有技术，强调了局限性，并探讨了LLMs的革命性潜力，提出了数据集开发、模型优化和多模态集成等未来研究方向，以期推动越南DAR的进步。", "keywords": "越南文档分析, 文档识别, 大型语言模型, 挑战, 未来方向"}}
{"id": "2506.04877", "pdf": "https://arxiv.org/pdf/2506.04877", "abs": "https://arxiv.org/abs/2506.04877", "authors": ["Antonio Almudévar", "José Miguel Hernández-Lobato", "Alfonso Ortega"], "title": "There Was Never a Bottleneck in Concept Bottleneck Models", "categories": ["cs.LG"], "comment": null, "summary": "Deep learning representations are often difficult to interpret, which can\nhinder their deployment in sensitive applications. Concept Bottleneck Models\n(CBMs) have emerged as a promising approach to mitigate this issue by learning\nrepresentations that support target task performance while ensuring that each\ncomponent predicts a concrete concept from a predefined set. In this work, we\nargue that CBMs do not impose a true bottleneck: the fact that a component can\npredict a concept does not guarantee that it encodes only information about\nthat concept. This shortcoming raises concerns regarding interpretability and\nthe validity of intervention procedures. To overcome this limitation, we\npropose Minimal Concept Bottleneck Models (MCBMs), which incorporate an\nInformation Bottleneck (IB) objective to constrain each representation\ncomponent to retain only the information relevant to its corresponding concept.\nThis IB is implemented via a variational regularization term added to the\ntraining loss. As a result, MCBMs support concept-level interventions with\ntheoretical guarantees, remain consistent with Bayesian principles, and offer\ngreater flexibility in key design choices.", "AI": {"title_translation": "概念瓶颈模型中从未存在瓶颈", "tldr": "概念瓶颈模型（CBMs）并非真正的瓶颈，因为其组件可能编码了与概念无关的信息。本文提出了最小概念瓶颈模型（MCBMs），通过引入信息瓶颈（IB）目标来限制每个组件只保留与其对应概念相关的信息，从而提高了可解释性和干预的有效性。", "motivation": "深度学习表示难以解释，阻碍了其在敏感应用中的部署。概念瓶颈模型（CBMs）旨在通过学习可预测具体概念的表示来解决此问题。然而，CBMs并未施加真正的瓶颈，其组件预测概念并不保证只编码该概念的信息，这引发了对可解释性和干预过程有效性的担忧。", "method": "本文提出了最小概念瓶颈模型（MCBMs）。MCBMs通过引入信息瓶颈（IB）目标来约束每个表示组件只保留与其对应概念相关的信息。该信息瓶颈通过在训练损失中添加一个变分正则化项来实现。", "result": "MCBMs支持具有理论保证的概念级干预，与贝叶斯原则保持一致，并在关键设计选择上提供了更大的灵活性。", "conclusion": "概念瓶颈模型（CBMs）存在无法保证其组件只编码相应概念信息的缺陷，这影响了模型的可解释性和干预的有效性。本文提出的最小概念瓶颈模型（MCBMs）通过信息瓶颈目标克服了这一限制，从而实现了更好的可解释性、理论保证的概念级干预，并符合贝叶斯原则。", "translation": "深度学习表示通常难以解释，这会阻碍它们在敏感应用中的部署。概念瓶颈模型（CBMs）已成为缓解此问题的一种有前景的方法，通过学习支持目标任务性能的表示，同时确保每个组件预测预定义集合中的具体概念。在这项工作中，我们认为CBMs并未施加真正的瓶颈：组件可以预测概念的事实并不能保证它只编码有关该概念的信息。这一缺陷引发了对可解释性和干预程序有效性的担忧。为了克服这一限制，我们提出了最小概念瓶颈模型（MCBMs），它结合了信息瓶颈（IB）目标，以约束每个表示组件仅保留与其相应概念相关的信息。该IB通过添加到训练损失中的变分正则化项来实现。因此，MCBMs支持具有理论保证的概念级干预，与贝叶斯原则保持一致，并在关键设计选择上提供了更大的灵活性。", "summary": "概念瓶颈模型（CBMs）旨在提高深度学习模型的可解释性，但其组件可能编码了与概念无关的信息，导致并非真正的“瓶颈”。为解决此问题，本文提出了最小概念瓶颈模型（MCBMs），该模型通过引入信息瓶颈（IB）目标，确保每个表示组件仅保留与其对应概念相关的信息。MCBMs通过变分正则化实现，支持具有理论保证的概念级干预，与贝叶斯原则一致，并提供设计灵活性。", "keywords": "概念瓶颈模型, 信息瓶颈, 可解释性, 最小概念瓶颈模型, 深度学习"}}
{"id": "2506.04391", "pdf": "https://arxiv.org/pdf/2506.04391", "abs": "https://arxiv.org/abs/2506.04391", "authors": ["Cecilia Bolaños", "Leonardo Pepino", "Martin Meza", "Luciana Ferrer"], "title": "Benchmarking Time-localized Explanations for Audio Classification Models", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Most modern approaches for audio processing are opaque, in the sense that\nthey do not provide an explanation for their decisions. For this reason,\nvarious methods have been proposed to explain the outputs generated by these\nmodels. Good explanations can result in interesting insights about the data or\nthe model, as well as increase trust in the system. Unfortunately, evaluating\nthe quality of explanations is far from trivial since, for most tasks, there is\nno clear ground truth explanation to use as reference. In this work, we propose\na benchmark for time-localized explanations for audio classification models\nthat uses time annotations of target events as a proxy for ground truth\nexplanations. We use this benchmark to systematically optimize and compare\nvarious approaches for model-agnostic post-hoc explanation, obtaining, in some\ncases, close to perfect explanations. Finally, we illustrate the utility of the\nexplanations for uncovering spurious correlations.", "AI": {"title_translation": "音频分类模型时间局部化解释的基准测试", "tldr": "本文提出了一个用于评估音频分类模型时间局部化解释的基准，利用时间标注作为真值代理，并用其优化和比较了各种解释方法，揭示了虚假相关性。", "motivation": "大多数现代音频处理方法不透明，缺乏对其决策的解释。尽管有多种解释方法被提出，但评估解释质量并非易事，因为大多数任务缺乏明确的真值解释作为参考。", "method": "本文提出了一个针对音频分类模型时间局部化解释的基准测试，该基准使用目标事件的时间标注作为真值解释的代理。研究者利用此基准系统地优化和比较了各种模型无关的后验解释方法。", "result": "通过该基准测试，研究者在某些情况下获得了接近完美的解释。此外，他们还展示了这些解释在揭示虚假相关性方面的效用。", "conclusion": "该基准测试为评估和改进音频分类模型的时间局部化解释提供了一个有效工具，有助于提高模型的可信度并发现数据或模型中的潜在问题。", "translation": "大多数现代音频处理方法是不透明的，因为它们没有为其决策提供解释。因此，已经提出了各种方法来解释这些模型产生的输出。好的解释可以带来关于数据或模型的有趣见解，并增加对系统的信任。不幸的是，评估解释的质量远非易事，因为对于大多数任务，没有明确的真值解释可以作为参考。在这项工作中，我们提出了一个用于音频分类模型时间局部化解释的基准，该基准使用目标事件的时间标注作为真值解释的代理。我们使用这个基准系统地优化和比较了各种模型无关的后验解释方法，在某些情况下获得了接近完美的解释。最后，我们阐明了这些解释在揭示虚假相关性方面的效用。", "summary": "本研究针对现代音频分类模型解释性差及解释质量评估困难的问题，提出了一个时间局部化解释的基准测试。该基准利用目标事件的时间标注作为真值代理，用于系统地优化和比较各种模型无关的后验解释方法。实验结果表明，该方法能够获得接近完美的解释，并有效揭示模型中的虚假相关性，从而提升了模型的可信度和洞察力。", "keywords": "时间局部化解释, 音频分类, 模型解释性, 基准测试, 虚假相关性"}}
{"id": "2506.05083", "pdf": "https://arxiv.org/pdf/2506.05083", "abs": "https://arxiv.org/abs/2506.05083", "authors": ["Peng Wang", "Yichun Shi", "Xiaochen Lian", "Zhonghua Zhai", "Xin Xia", "Xuefeng Xiao", "Weilin Huang", "Jianchao Yang"], "title": "SeedEdit 3.0: Fast and High-Quality Generative Image Editing", "categories": ["cs.CV"], "comment": "Our website: https://seed.bytedance.com/tech/seededit", "summary": "We introduce SeedEdit 3.0, in companion with our T2I model Seedream 3.0 [22],\nwhich significantly improves over our previous version [27] in both aspects of\nedit instruction following and image content (e.g., ID/IP) preservation on real\nimage inputs. Additional to model upgrading with T2I, in this report, we\npresent several key improvements. First, we develop an enhanced data curation\npipeline with a meta-info paradigm and meta-info embedding strategy that help\nmix images from multiple data sources. This allows us to scale editing data\neffectively, and meta information is helpfult to connect VLM with diffusion\nmodel more closely. Second, we introduce a joint learning pipeline for\ncomputing a diffusion loss and a reward loss. Finally, we evaluate SeedEdit 3.0\non our testing benchmarks, for real image editing, where it achieves a best\ntrade-off between multiple aspects, yielding a high usability rate of 56.1%,\ncompared to SeedEdit 1.6 (38.4%), GPT4o (37.1%) and Gemini 2.0 (30.3%).", "AI": {"title_translation": "SeedEdit 3.0：快速高质量的生成式图像编辑", "tldr": "SeedEdit 3.0显著提升了真实图像编辑中的指令遵循和内容保留能力，通过改进数据处理和引入联合学习流程，在可用性方面超越了现有模型。", "motivation": "为了解决先前版本在真实图像输入上编辑指令遵循和图像内容（如ID/IP）保留方面的不足，并提升图像编辑的质量和速度。", "method": "1. 结合T2I模型Seedream 3.0进行模型升级。2. 开发了增强型数据整理管道，采用元信息范式和元信息嵌入策略，以有效扩展编辑数据并连接VLM与扩散模型。3. 引入了用于计算扩散损失和奖励损失的联合学习管道。", "result": "SeedEdit 3.0在真实图像编辑测试基准上实现了多方面之间的最佳权衡，可用性达到了56.1%，相比SeedEdit 1.6 (38.4%)、GPT4o (37.1%)和Gemini 2.0 (30.3%)有显著提升。", "conclusion": "SeedEdit 3.0在真实图像编辑方面取得了显著的性能提升，在编辑指令遵循和图像内容保留方面表现优异，并在可用性方面超越了其他领先模型。", "translation": "我们介绍了SeedEdit 3.0，它与我们的T2I模型Seedream 3.0 [22]配套使用，在编辑指令遵循和真实图像输入上的图像内容（例如ID/IP）保留两方面都比我们之前的版本[27]有了显著改进。除了T2I模型升级之外，在本报告中，我们还介绍了几个关键改进。首先，我们开发了一个增强型数据整理管道，采用元信息范式和元信息嵌入策略，有助于混合来自多个数据源的图像。这使我们能够有效地扩展编辑数据，并且元信息有助于更紧密地连接VLM与扩散模型。其次，我们引入了一个用于计算扩散损失和奖励损失的联合学习管道。最后，我们在我们的测试基准上评估了SeedEdit 3.0，用于真实图像编辑，它在多个方面实现了最佳权衡，可用性达到了56.1%，相比SeedEdit 1.6 (38.4%)、GPT4o (37.1%)和Gemini 2.0 (30.3%)。", "summary": "本论文介绍了SeedEdit 3.0，它是Seedream 3.0的配套工具，旨在显著提升真实图像编辑中的指令遵循和图像内容（如ID/IP）保留能力。通过改进数据整理管道（引入元信息范式和嵌入策略以有效扩展数据并连接VLM与扩散模型）以及引入扩散损失和奖励损失的联合学习管道，SeedEdit 3.0在测试基准上实现了最佳权衡，可用性达到56.1%，优于SeedEdit 1.6、GPT4o和Gemini 2.0。", "keywords": "生成式图像编辑, SeedEdit 3.0, 指令遵循, 内容保留, 数据整理"}}
{"id": "2506.04886", "pdf": "https://arxiv.org/pdf/2506.04886", "abs": "https://arxiv.org/abs/2506.04886", "authors": ["Allen Paul", "George Grammatopoulos", "Adwaye Rambojun", "Neill D. F. Campbell", "Harinderjit S. Gill", "Tony Shardlow"], "title": "Gaussian Process Diffeomorphic Statistical Shape Modelling Outperforms Angle-Based Methods for Assessment of Hip Dysplasia", "categories": ["cs.LG"], "comment": null, "summary": "Dysplasia is a recognised risk factor for osteoarthritis (OA) of the hip,\nearly diagnosis of dysplasia is important to provide opportunities for surgical\ninterventions aimed at reducing the risk of hip OA. We have developed a\npipeline for semi-automated classification of dysplasia using volumetric CT\nscans of patients' hips and a minimal set of clinically annotated landmarks,\ncombining the framework of the Gaussian Process Latent Variable Model with\ndiffeomorphism to create a statistical shape model, which we termed the\nGaussian Process Diffeomorphic Statistical Shape Model (GPDSSM). We used 192 CT\nscans, 100 for model training and 92 for testing. The GPDSSM effectively\ndistinguishes dysplastic samples from controls while also highlighting regions\nof the underlying surface that show dysplastic variations. As well as improving\nclassification accuracy compared to angle-based methods (AUC 96.2% vs 91.2%),\nthe GPDSSM can save time for clinicians by removing the need to manually\nmeasure angles and interpreting 2D scans for possible markers of dysplasia.", "AI": {"title_translation": "高斯过程微分同胚统计形状建模在评估髋关节发育不良方面优于基于角度的方法", "tldr": "本文开发了一种新的高斯过程微分同胚统计形状模型（GPDSSM），用于半自动分类髋关节发育不良。该模型在分类准确性上优于传统基于角度的方法，并能显著节省临床医生时间。", "motivation": "髋关节发育不良是髋关节骨关节炎（OA）的已知风险因素，早期诊断对于通过手术干预降低OA风险至关重要。", "method": "开发了一个结合高斯过程潜在变量模型框架和微分同胚的统计形状模型（GPDSSM）。该方法利用患者髋关节的容积CT扫描和少量临床标注地标，通过半自动化流程进行髋关节发育不良的分类。模型在192个CT扫描数据集上进行了训练（100个）和测试（92个）。", "result": "GPDSSM能够有效区分发育不良样本和对照组，并突出显示表现出发育不良变化的表面区域。与基于角度的方法相比，GPDSSM的分类准确性更高（AUC 96.2% vs 91.2%）。此外，GPDSSM消除了手动测量角度和解释2D扫描的需要，从而为临床医生节省了时间。", "conclusion": "高斯过程微分同胚统计形状模型（GPDSSM）在髋关节发育不良的评估中表现出卓越的性能，不仅显著提高了诊断准确性，还大大提升了临床工作效率。", "translation": "髋关节发育不良是髋关节骨关节炎（OA）的一个公认风险因素，早期诊断发育不良对于提供旨在降低髋关节OA风险的手术干预机会至关重要。我们开发了一个半自动化分类发育不良的流程，该流程使用患者髋关节的容积CT扫描和最少量的临床标注地标，结合高斯过程潜在变量模型框架和微分同胚来创建统计形状模型，我们称之为高斯过程微分同胚统计形状模型（GPDSSM）。我们使用了192个CT扫描，其中100个用于模型训练，92个用于测试。GPDSSM能够有效地区分发育不良样本和对照组，同时突出显示显示出发育不良变化的底层表面区域。除了与基于角度的方法相比提高了分类准确性（AUC 96.2% vs 91.2%），GPDSSM还可以通过消除手动测量角度和解释2D扫描以寻找可能的发育不良标志的需要，从而为临床医生节省时间。", "summary": "本文提出了一种新颖的高斯过程微分同胚统计形状模型（GPDSSM），旨在通过半自动流程对髋关节发育不良进行分类。该模型结合了高斯过程潜在变量模型和微分同胚，并基于患者的容积CT扫描和少量临床地标数据进行操作。在包含192个CT扫描的测试中，GPDSSM在区分发育不良样本方面表现出色，其分类准确性（AUC 96.2%）显著优于传统的基于角度的方法（AUC 91.2%）。此外，GPDSSM还能识别病变区域，并能通过自动化测量过程节省临床医生宝贵的时间。", "keywords": "髋关节发育不良, 统计形状模型, 高斯过程, 微分同胚, CT扫描"}}
{"id": "2506.05087", "pdf": "https://arxiv.org/pdf/2506.05087", "abs": "https://arxiv.org/abs/2506.05087", "authors": ["HaoTian Lan"], "title": "Interpretable Multimodal Framework for Human-Centered Street Assessment: Integrating Visual-Language Models for Perceptual Urban Diagnostics", "categories": ["cs.CV", "cs.CL"], "comment": "24 pages, 10 figures", "summary": "While objective street metrics derived from imagery or GIS have become\nstandard in urban analytics, they remain insufficient to capture subjective\nperceptions essential to inclusive urban design. This study introduces a novel\nMultimodal Street Evaluation Framework (MSEF) that fuses a vision transformer\n(VisualGLM-6B) with a large language model (GPT-4), enabling interpretable\ndual-output assessment of streetscapes. Leveraging over 15,000 annotated\nstreet-view images from Harbin, China, we fine-tune the framework using LoRA\nand P-Tuning v2 for parameter-efficient adaptation. The model achieves an F1\nscore of 0.84 on objective features and 89.3 percent agreement with aggregated\nresident perceptions, validated across stratified socioeconomic geographies.\nBeyond classification accuracy, MSEF captures context-dependent contradictions:\nfor instance, informal commerce boosts perceived vibrancy while simultaneously\nreducing pedestrian comfort. It also identifies nonlinear and semantically\ncontingent patterns -- such as the divergent perceptual effects of\narchitectural transparency across residential and commercial zones -- revealing\nthe limits of universal spatial heuristics. By generating natural-language\nrationales grounded in attention mechanisms, the framework bridges sensory data\nwith socio-affective inference, enabling transparent diagnostics aligned with\nSDG 11. This work offers both methodological innovation in urban perception\nmodeling and practical utility for planning systems seeking to reconcile\ninfrastructural precision with lived experience.", "AI": {"title_translation": "以人为本的街道评估可解释多模态框架：整合视觉-语言模型用于感知城市诊断", "tldr": "本研究提出了一个可解释的多模态街道评估框架（MSEF），该框架融合了视觉变换器（VisualGLM-6B）和大型语言模型（GPT-4），用于街道景观的双输出评估。该模型在客观特征上F1分数为0.84，与居民感知的一致性达到89.3%，并能捕捉上下文相关的矛盾和非线性模式。", "motivation": "尽管基于图像或GIS的客观街道指标已成为城市分析的标准，但它们不足以捕捉包容性城市设计所需的 LING 觉感知。", "method": "本研究引入了一种新型多模态街道评估框架（MSEF），它融合了视觉变换器（VisualGLM-6B）和大型语言模型（GPT-4），实现了街道景观的可解释双输出评估。利用哈尔滨超过15,000张标注的街景图像，使用LoRA和P-Tuning v2对框架进行参数高效的微调。", "result": "模型在客观特征上达到了0.84的F1分数，与聚合居民感知的一致性达到89.3%。MSEF捕捉了上下文相关的矛盾，例如非正式商业在提升感知活力的同时降低了行人舒适度。它还识别了非线性且语义依赖的模式，例如建筑透明度在住宅和商业区中不同的感知效果。", "conclusion": "这项工作为城市感知建模提供了方法论创新，并为寻求协调基础设施精度与生活体验的规划系统提供了实用价值。通过生成基于注意力机制的自然语言解释，该框架将感官数据与社会情感推断联系起来，实现了符合SDG 11的透明诊断。", "translation": "尽管从图像或GIS获得的客观街道指标已成为城市分析的标准，但它们仍不足以捕捉对包容性城市设计至关重要的主观感知。本研究引入了一种新颖的多模态街道评估框架（MSEF），该框架将视觉变换器（VisualGLM-6B）与大型语言模型（GPT-4）融合，实现了街道景观的可解释双输出评估。我们利用来自中国哈尔滨的超过15,000张标注街景图像，使用LoRA和P-Tuning v2对框架进行参数高效的自适应微调。该模型在客观特征上实现了0.84的F1分数，并与聚合居民感知达到了89.3%的一致性，并在分层的社会经济地理区域中得到验证。除了分类准确性之外，MSEF还捕捉了上下文相关的矛盾：例如，非正式商业在提升感知活力的同时降低了行人舒适度。它还识别了非线性且语义依赖的模式——例如建筑透明度在住宅区和商业区中不同的感知效果——揭示了通用空间启发式的局限性。通过生成基于注意力机制的自然语言解释，该框架将感官数据与社会情感推断联系起来，实现了符合可持续发展目标11（SDG 11）的透明诊断。这项工作为城市感知建模提供了方法论创新，并为寻求协调基础设施精度与生活体验的规划系统提供了实用价值。", "summary": "本研究提出了一个新颖的可解释多模态街道评估框架（MSEF），该框架结合了视觉变换器和大型语言模型，用于客观和主观的街道景观评估。该框架在超过15,000张标注的街景图像上进行微调，在客观特征上表现良好，并与居民感知高度一致。它能够识别复杂的、上下文相关的感知模式和矛盾，从而弥补了传统客观指标在捕捉主观城市感知方面的不足。该框架通过生成自然语言解释，为城市规划提供了方法论创新和实用工具。", "keywords": "多模态框架, 街道评估, 视觉-语言模型, 城市感知, 可解释性"}}
{"id": "2506.04913", "pdf": "https://arxiv.org/pdf/2506.04913", "abs": "https://arxiv.org/abs/2506.04913", "authors": ["Yongyu Mu", "Jiali Zeng", "Bei Li", "Xinyan Guan", "Fandong Meng", "Jie Zhou", "Tong Xiao", "Jingbo Zhu"], "title": "Dissecting Long Reasoning Models: An Empirical Study", "categories": ["cs.LG", "cs.CL"], "comment": "Working in process", "summary": "Despite recent progress in training long-context reasoning models via\nreinforcement learning (RL), several open questions and counterintuitive\nbehaviors remain. This work focuses on three key aspects: (1) We systematically\nanalyze the roles of positive and negative samples in RL, revealing that\npositive samples mainly facilitate data fitting, whereas negative samples\nsignificantly enhance generalization and robustness. Interestingly, training\nsolely on negative samples can rival standard RL training performance. (2) We\nidentify substantial data inefficiency in group relative policy optimization,\nwhere over half of the samples yield zero advantage. To address this, we\nexplore two straightforward strategies, including relative length rewards and\noffline sample injection, to better leverage these data and enhance reasoning\nefficiency and capability. (3) We investigate unstable performance across\nvarious reasoning models and benchmarks, attributing instability to uncertain\nproblems with ambiguous outcomes, and demonstrate that multiple evaluation runs\nmitigate this issue.", "AI": {"title_translation": "剖析长推理模型：一项实证研究", "tldr": "本研究深入探讨了长上下文推理模型在强化学习训练中存在的未解问题和反直觉行为，分析了正负样本的作用、数据低效性，并提出了提高效率和稳定性的策略。", "motivation": "尽管通过强化学习训练长上下文推理模型取得了进展，但仍存在一些未解决的问题和反直觉行为，包括正负样本的作用、数据低效性以及模型性能的不稳定性。", "method": "本研究系统分析了强化学习中正负样本的角色；针对群组相对策略优化中的数据低效问题，探索了相对长度奖励和离线样本注入两种策略；并调查了不同推理模型和基准测试中不稳定的性能，提出通过多次评估运行来缓解。", "result": "研究发现正样本主要促进数据拟合，负样本显著增强泛化和鲁棒性，仅用负样本训练可与标准RL训练媲美。识别出群组相对策略优化中存在大量数据低效，通过提出的策略可提高推理效率和能力。性能不稳定源于结果模糊的不确定问题，多次评估运行可缓解此问题。", "conclusion": "负样本在强化学习中对泛化和鲁棒性至关重要；群组相对策略优化存在数据低效问题，可通过特定策略改进；模型性能不稳定可通过多次评估运行来缓解。", "translation": "尽管通过强化学习（RL）训练长上下文推理模型取得了最新进展，但仍存在一些未解决的问题和反直觉行为。这项工作侧重于三个关键方面：（1）我们系统地分析了强化学习中正负样本的作用，揭示了正样本主要促进数据拟合，而负样本显著增强泛化和鲁棒性。有趣的是，仅用负样本进行训练就可以与标准强化学习训练性能相媲美。（2）我们发现群组相对策略优化中存在显著的数据低效问题，其中超过一半的样本产生的优势为零。为了解决这个问题，我们探索了两种直接的策略，包括相对长度奖励和离线样本注入，以更好地利用这些数据并提高推理效率和能力。（3）我们调查了各种推理模型和基准测试中不稳定的性能，将不稳定性归因于结果模糊的不确定问题，并证明多次评估运行可以缓解这个问题。", "summary": "本研究对长上下文推理模型进行了实证分析，揭示了强化学习中正负样本的不同作用，指出负样本对泛化和鲁棒性的重要性。同时，研究发现了群组相对策略优化中的数据低效问题，并提出了相对长度奖励和离线样本注入等改进策略。此外，本研究还探讨了模型性能不稳定的原因，并提出通过多次评估运行来提高评估的稳定性。", "keywords": "长推理模型, 强化学习, 正负样本, 数据效率, 性能稳定性"}}
{"id": "2506.04515", "pdf": "https://arxiv.org/pdf/2506.04515", "abs": "https://arxiv.org/abs/2506.04515", "authors": ["Salil Patel"], "title": "The Latent Space Hypothesis: Toward Universal Medical Representation Learning", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": "51 pages, 12 figures. A position paper examining the latent space\n  hypothesis - the proposition that diverse medical data can be represented in\n  shared latent spaces reflecting fundamental biological processes. The paper\n  discusses theoretical foundations, reviews supporting evidence, and considers\n  potential implications for medical AI and representation learning", "summary": "Medical data range from genomic sequences and retinal photographs to\nstructured laboratory results and unstructured clinical narratives. Although\nthese modalities appear disparate, many encode convergent information about a\nsingle underlying physiological state. The Latent Space Hypothesis frames each\nobservation as a projection of a unified, hierarchically organized manifold --\nmuch like shadows cast by the same three-dimensional object. Within this\nlearned geometric representation, an individual's health status occupies a\npoint, disease progression traces a trajectory, and therapeutic intervention\ncorresponds to a directed vector. Interpreting heterogeneous evidence in a\nshared space provides a principled way to re-examine eponymous conditions --\nsuch as Parkinson's or Crohn's -- that often mask multiple pathophysiological\nentities and involve broader anatomical domains than once believed. By\nrevealing sub-trajectories and patient-specific directions of change, the\nframework supplies a quantitative rationale for personalised diagnosis,\nlongitudinal monitoring, and tailored treatment, moving clinical practice away\nfrom grouping by potentially misleading labels toward navigation of each\nperson's unique trajectory. Challenges remain -- bias amplification, data\nscarcity for rare disorders, privacy, and the correlation-causation divide --\nbut scale-aware encoders, continual learning on longitudinal data streams, and\nperturbation-based validation offer plausible paths forward.", "AI": {"title_translation": "潜在空间假设：迈向通用医学表征学习", "tldr": "该论文提出“潜在空间假设”，旨在通过将异构医学数据映射到统一的潜在空间，实现个性化诊断、监测和治疗，从而克服传统医学标签的局限性。", "motivation": "传统医学实践中，对疾病的定义（如帕金森氏症、克罗恩病）可能掩盖多种病理生理实体，且涉及比以往认为更广泛的解剖区域，导致分组诊断和治疗可能具有误导性。医学数据模态多样且分散，难以统一分析。", "method": "文章提出“潜在空间假设”，将每种医学观察视为统一的、分层组织的流形（manifold）的投影。在这种学习到的几何表示中，个体的健康状况占据一个点，疾病进展描绘一条轨迹，治疗干预对应一个有方向的向量。通过将异构证据置于共享空间中进行解释。", "result": "该框架通过揭示亚轨迹和患者特定的变化方向，为个性化诊断、纵向监测和量身定制的治疗提供了量化依据。它将临床实践从基于潜在误导性标签的分组，转向对每个人独特轨迹的导航。", "conclusion": "虽然存在偏见放大、罕见疾病数据稀缺、隐私问题和相关性-因果关系区分等挑战，但通过尺度感知编码器、纵向数据流上的持续学习以及基于扰动的验证，仍有可行的前进路径。", "translation": "医学数据涵盖从基因组序列、视网膜照片到结构化实验室结果和非结构化临床叙事等多种形式。尽管这些模态看似迥异，但许多都编码着关于单一底层生理状态的趋同信息。“潜在空间假设”将每种观察视为统一的、分层组织的流形（manifold）的投影——就像同一三维物体投射出的阴影。在这种学习到的几何表示中，个体的健康状况占据一个点，疾病进展描绘一条轨迹，治疗干预对应一个有方向的向量。在共享空间中解释异构证据，提供了一种有原则的方法来重新审视那些通常掩盖多种病理生理实体并涉及比以往认为更广泛解剖区域的以人名命名的疾病——例如帕金森氏症或克罗恩病。通过揭示亚轨迹和患者特定的变化方向，该框架为个性化诊断、纵向监测和量身定制的治疗提供了量化依据，使临床实践从基于潜在误导性标签的分组转向对每个人独特轨迹的导航。挑战依然存在——偏见放大、罕见疾病数据稀缺、隐私以及相关性-因果关系的分歧——但尺度感知编码器、纵向数据流上的持续学习以及基于扰动的验证提供了可行的前进路径。", "summary": "“潜在空间假设”提出了一种统一医学数据表示的新范式，将基因组、影像、实验室结果和临床叙事等异构医学数据视为同一底层生理状态在潜在空间中的投影。这种方法旨在通过构建一个统一的、分层组织的几何表示，使得个体健康状态、疾病进展和治疗干预能以点、轨迹和向量的形式呈现。这有助于重新审视传统疾病定义，并为个性化诊断、长期监测和定制治疗提供定量依据，从而推动临床实践从基于标签的分组转向对个体独特健康轨迹的导航。尽管面临数据偏见、稀缺性、隐私和因果关系等挑战，但文章也提出了潜在的解决方案。", "keywords": "潜在空间假设, 医学表征学习, 个性化医疗, 异构数据, 疾病轨迹"}}
{"id": "2506.05095", "pdf": "https://arxiv.org/pdf/2506.05095", "abs": "https://arxiv.org/abs/2506.05095", "authors": ["Jiaee Cheong", "Yang Liu", "Harold Soh", "Hatice Gunes"], "title": "FG 2025 TrustFAA: the First Workshop on Towards Trustworthy Facial Affect Analysis: Advancing Insights of Fairness, Explainability, and Safety (TrustFAA)", "categories": ["cs.CV"], "comment": null, "summary": "With the increasing prevalence and deployment of Emotion AI-powered facial\naffect analysis (FAA) tools, concerns about the trustworthiness of these\nsystems have become more prominent. This first workshop on \"Towards Trustworthy\nFacial Affect Analysis: Advancing Insights of Fairness, Explainability, and\nSafety (TrustFAA)\" aims to bring together researchers who are investigating\ndifferent challenges in relation to trustworthiness-such as interpretability,\nuncertainty, biases, and privacy-across various facial affect analysis tasks,\nincluding macro/ micro-expression recognition, facial action unit detection,\nother corresponding applications such as pain and depression detection, as well\nas human-robot interaction and collaboration. In alignment with FG2025's\nemphasis on ethics, as demonstrated by the inclusion of an Ethical Impact\nStatement requirement for this year's submissions, this workshop supports\nFG2025's efforts by encouraging research, discussion and dialogue on\ntrustworthy FAA.", "AI": {"title_translation": "FG 2025 TrustFAA：首届可信面部情感分析研讨会：推进公平性、可解释性和安全性见解 (TrustFAA)", "tldr": "随着情感AI面部情感分析工具的普及，可信度问题日益突出，TrustFAA研讨会旨在汇集研究人员，探讨面部情感分析中可信度相关的挑战，包括公平性、可解释性、安全性和隐私。", "motivation": "随着情感AI驱动的面部情感分析（FAA）工具日益普及和部署，人们对这些系统的可信度问题越来越关注。", "method": "摘要中未提及", "result": "摘要中未提及", "conclusion": "摘要中未提及", "translation": "随着情感AI驱动的面部情感分析（FAA）工具日益普及和部署，人们对这些系统的可信度问题越来越关注。首届“可信面部情感分析：推进公平性、可解释性和安全性见解（TrustFAA）”研讨会旨在汇集研究人员，共同探讨与可信度相关的各种挑战——例如可解释性、不确定性、偏见和隐私——这些挑战存在于各种面部情感分析任务中，包括宏/微表情识别、面部动作单元检测、疼痛和抑郁检测等其他相应应用，以及人机交互和协作。为了与FG2025对道德伦理的重视保持一致，本年度提交的论文要求包含道德影响声明，本次研讨会通过鼓励对可信FAA的研究、讨论和对话来支持FG2025的努力。", "summary": "TrustFAA研讨会旨在汇集研究人员，共同探讨情感AI面部情感分析工具的可信度问题，包括可解释性、不确定性、偏见和隐私等挑战，以推进公平性、可解释性和安全性方面的研究和对话。", "keywords": "面部情感分析, 可信度, 公平性, 可解释性, 安全性"}}
{"id": "2506.04924", "pdf": "https://arxiv.org/pdf/2506.04924", "abs": "https://arxiv.org/abs/2506.04924", "authors": ["Han Wang", "Ruoyun He", "Guoguang Lao", "Ting Liu", "Hejiao Luo", "Changqi Qin", "Hongying Luo", "Junmin Huang", "Zihan Wei", "Lu Chen", "Yongzhi Xu", "Ziqian Bi", "Junhao Song", "Tianyang Wang", "Chia Xin Liang", "Xinyuan Song", "Huafeng Liu", "Junfeng Hao", "Chunjie Tian"], "title": "Predicting ICU In-Hospital Mortality Using Adaptive Transformer Layer Fusion", "categories": ["cs.LG"], "comment": "21 pages, 6 figures", "summary": "Early identification of high-risk ICU patients is crucial for directing\nlimited medical resources. We introduce ALFIA (Adaptive Layer Fusion with\nIntelligent Attention), a modular, attention-based architecture that jointly\ntrains LoRA (Low-Rank Adaptation) adapters and an adaptive layer-weighting\nmechanism to fuse multi-layer semantic features from a BERT backbone. Trained\non our rigorous cw-24 (CriticalWindow-24) benchmark, ALFIA surpasses\nstate-of-the-art tabular classifiers in AUPRC while preserving a balanced\nprecision-recall profile. The embeddings produced by ALFIA's fusion module,\ncapturing both fine-grained clinical cues and high-level concepts, enable\nseamless pairing with GBDTs (CatBoost/LightGBM) as ALFIA-boost, and deep neuro\nnetworks as ALFIA-nn, yielding additional performance gains. Our experiments\nconfirm ALFIA's superior early-warning performance, by operating directly on\nroutine clinical text, it furnishes clinicians with a convenient yet robust\ntool for risk stratification and timely intervention in critical-care settings.", "AI": {"title_translation": "采用自适应Transformer层融合预测ICU住院死亡率", "tldr": "ALFIA是一种基于注意力机制的架构，通过融合BERT多层特征，在ICU住院死亡率预测任务上表现优异，并能辅助临床风险分层。", "motivation": "早期识别高风险ICU患者对于合理分配有限医疗资源至关重要。", "method": "本文提出ALFIA（Adaptive Layer Fusion with Intelligent Attention），一种模块化、基于注意力的架构。它联合训练LoRA（Low-Rank Adaptation）适配器和自适应层加权机制，以融合来自BERT骨干模型的多层语义特征。ALFIA的融合模块产生的嵌入可以与GBDTs（CatBoost/LightGBM）和深度神经网络结合，进一步提升性能。", "result": "在cw-24基准测试中，ALFIA在AUPRC方面超越了最先进的表格分类器，并保持了平衡的精确召回曲线。ALFIA与GBDTs和深度神经网络结合后，实现了额外的性能提升。实验证实了ALFIA卓越的早期预警性能。", "conclusion": "ALFIA通过直接处理常规临床文本，为临床医生提供了一个方便而强大的工具，用于重症监护环境中的风险分层和及时干预，从而实现ICU住院死亡率的早期预警。", "translation": "早期识别高危ICU患者对于指导有限的医疗资源至关重要。我们引入了ALFIA（Adaptive Layer Fusion with Intelligent Attention），这是一种模块化、基于注意力的架构，它联合训练LoRA（Low-Rank Adaptation）适配器和自适应层加权机制，以融合来自BERT骨干模型的多层语义特征。ALFIA在严格的cw-24（CriticalWindow-24）基准测试上进行训练，在AUPRC方面超越了最先进的表格分类器，同时保持了平衡的精确召回曲线。ALFIA融合模块产生的嵌入，能够捕捉细粒度的临床线索和高层概念，可以与GBDTs（CatBoost/LightGBM）无缝配对作为ALFIA-boost，以及与深度神经网络配对作为ALFIA-nn，从而获得额外的性能提升。我们的实验证实了ALFIA卓越的早期预警性能，通过直接操作常规临床文本，它为临床医生提供了一个方便而强大的工具，用于重症监护环境中的风险分层和及时干预。", "summary": "本文提出ALFIA，一种基于注意力机制的架构，通过融合BERT模型的多层语义特征来预测ICU住院死亡率。ALFIA在特定基准测试中表现优于现有方法，其生成的嵌入可与多种机器学习模型结合，进一步提升性能。该方法能从临床文本中提取信息，为ICU患者的风险分层和早期干预提供支持。", "keywords": "ICU死亡率预测, 自适应Transformer, 层融合, 注意力机制, 临床文本"}}
{"id": "2506.04534", "pdf": "https://arxiv.org/pdf/2506.04534", "abs": "https://arxiv.org/abs/2506.04534", "authors": ["William Sheffield", "Kanishka Misra", "Valentina Pyatkin", "Ashwini Deo", "Kyle Mahowald", "Junyi Jessy Li"], "title": "Is It JUST Semantics? A Case Study of Discourse Particle Understanding in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "To be published in Findings of The 63rd Annual Meeting of the\n  Association for Computational Linguistics (ACL 2025). The main paper is 5\n  pages and contains 3 figures and 1 table. In total, the paper is 12 pages and\n  contains 8 figures and 5 tables (References + Appendix)", "summary": "Discourse particles are crucial elements that subtly shape the meaning of\ntext. These words, often polyfunctional, give rise to nuanced and often quite\ndisparate semantic/discourse effects, as exemplified by the diverse uses of the\nparticle \"just\" (e.g., exclusive, temporal, emphatic). This work investigates\nthe capacity of LLMs to distinguish the fine-grained senses of English \"just\",\na well-studied example in formal semantics, using data meticulously created and\nlabeled by expert linguists. Our findings reveal that while LLMs exhibit some\nability to differentiate between broader categories, they struggle to fully\ncapture more subtle nuances, highlighting a gap in their understanding of\ndiscourse particles.", "AI": {"title_translation": "仅仅是语义吗？大型语言模型中语篇词理解的案例研究", "tldr": "大型语言模型在理解语篇词（如“just”）的细微差别方面存在困难。", "motivation": "研究大型语言模型区分英语语篇词“just”细微语义的能力。", "method": "使用语言学专家精心创建和标注的数据，测试大型语言模型区分“just”不同语义的能力。", "result": "大型语言模型能够区分较宽泛的类别，但在捕捉细微差别方面存在困难，这表明它们在理解语篇词方面存在不足。", "conclusion": "大型语言模型在完全捕捉语篇词的细微差别方面存在局限性，尽管它们能够区分较宽泛的类别。", "translation": "语篇词是微妙地塑造文本意义的关键元素。这些词通常是多功能的，会产生细致入微且往往截然不同的语义/语篇效果，例如“just”一词的多种用法（例如，排他性、时间性、强调性）。这项工作调查了大型语言模型区分英语“just”细微语义的能力，“just”是形式语义学中一个经过充分研究的例子，使用了由专业语言学家精心创建和标注的数据。我们的研究结果表明，虽然大型语言模型在区分更广泛的类别方面表现出一定的能力，但它们难以完全捕捉更细微的差别，突出了它们在理解语篇词方面的不足。", "summary": "本文以“just”为例，研究了大型语言模型理解语篇词细微语义的能力。研究发现，大型语言模型能区分较宽泛的类别，但难以完全捕捉细微的语义差异，这表明它们在语篇词理解方面存在不足。", "keywords": "大型语言模型, 语篇词, 语义学, 自然语言理解, just"}}
{"id": "2506.05096", "pdf": "https://arxiv.org/pdf/2506.05096", "abs": "https://arxiv.org/abs/2506.05096", "authors": ["Haosong Liu", "Yuge Cheng", "Zihan Liu", "Aiyue Chen", "Yiwu Yao", "Chen Chen", "Jingwen Leng", "Yu Feng", "Minyi Guo"], "title": "Astraea: A GPU-Oriented Token-wise Acceleration Framework for Video Diffusion Transformers", "categories": ["cs.CV"], "comment": null, "summary": "Video diffusion transformers (vDiTs) have made impressive progress in\ntext-to-video generation, but their high computational demands present major\nchallenges for practical deployment. While existing acceleration methods reduce\nworkload at various granularities, they often rely on heuristics, limiting\ntheir applicability.\n  We introduce ASTRAEA, an automatic framework that searches for near-optimal\nconfigurations for vDiT-based video generation. At its core, ASTRAEA proposes a\nlightweight token selection mechanism and a memory-efficient, GPU-parallel\nsparse attention strategy, enabling linear reductions in execution time with\nminimal impact on generation quality. To determine optimal token reduction for\ndifferent timesteps, we further design a search framework that leverages a\nclassic evolutionary algorithm to automatically determine the distribution of\nthe token budget effectively. Together, ASTRAEA achieves up to 2.4x inference\nspeedup on a single GPU with great scalability (up to 13.2x speedup on 8 GPUs)\nwhile retaining better video quality compared to the state-of-the-art methods\n(<0.5% loss on the VBench score compared to the baseline vDiT models).", "AI": {"title_translation": "Astraea：面向GPU的视频扩散Transformer逐Token加速框架", "tldr": "ASTRAEA是一个GPU加速框架，通过Token选择和稀疏注意力机制，显著提升视频扩散Transformer的推理速度，同时保持视频质量。", "motivation": "视频扩散Transformer（vDiTs）在文本到视频生成方面取得了显著进展，但其高计算需求限制了实际部署。现有加速方法通常依赖启发式方法，限制了其适用性。", "method": "ASTRAEA框架引入了轻量级Token选择机制和内存高效的GPU并行稀疏注意力策略，实现执行时间的线性缩减。它还设计了一个搜索框架，利用经典的进化算法自动确定不同时间步长的Token预算分布。", "result": "ASTRAEA在单GPU上实现了高达2.4倍的推理加速，在8个GPU上可扩展至13.2倍的加速。与现有最先进方法相比，它保持了更好的视频质量（与基线vDiT模型相比，VBenc h得分损失小于0.5%）。", "conclusion": "ASTRAEA通过其Token选择和稀疏注意力策略，显著提高了视频扩散Transformer的推理速度和可扩展性，同时保持了高质量的视频生成效果。", "translation": "视频扩散Transformer（vDiTs）在文本到视频生成方面取得了令人瞩目的进展，但其高计算需求给实际部署带来了巨大挑战。尽管现有加速方法在不同粒度上减少了工作负载，但它们通常依赖启发式方法，限制了其适用性。\n我们引入了ASTRAEA，一个自动框架，用于搜索基于vDiT的视频生成的近乎最优配置。ASTRAEA的核心是提出了一种轻量级的Token选择机制和一种内存高效的GPU并行稀疏注意力策略，从而以最小的生成质量影响实现执行时间的线性缩减。为了确定不同时间步长的最佳Token缩减量，我们进一步设计了一个搜索框架，该框架利用经典的进化算法来有效地自动确定Token预算的分布。总的来说，ASTRAEA在单个GPU上实现了高达2.4倍的推理加速，并具有出色的可扩展性（在8个GPU上高达13.2倍的加速），同时与最先进的方法相比，保持了更好的视频质量（与基线vDiT模型相比，VBenc h得分损失小于0.5%）。", "summary": "ASTRAEA是一个面向GPU的视频扩散Transformer加速框架，旨在解决vDiT高计算需求带来的部署挑战。该框架通过轻量级Token选择机制和内存高效的GPU并行稀疏注意力策略，结合进化算法优化Token预算分配，实现了显著的推理速度提升（单GPU 2.4倍，8 GPU 13.2倍），同时保持了出色的视频生成质量。", "keywords": "视频扩散Transformer, GPU加速, Token选择, 稀疏注意力, 进化算法"}}
{"id": "2506.04980", "pdf": "https://arxiv.org/pdf/2506.04980", "abs": "https://arxiv.org/abs/2506.04980", "authors": ["Marcos Lima Romero", "Ricardo Suyama"], "title": "Agentic AI for Intent-Based Industrial Automation", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "Preprint - Submitted to 16th IEEE/IAS International Conference on\n  Industry Applications - INDUSCON 2025", "summary": "The recent development of Agentic AI systems, empowered by autonomous large\nlanguage models (LLMs) agents with planning and tool-usage capabilities,\nenables new possibilities for the evolution of industrial automation and\nreduces the complexity introduced by Industry 4.0. This work proposes a\nconceptual framework that integrates Agentic AI with the intent-based paradigm,\noriginally developed in network research, to simplify human-machine interaction\n(HMI) and better align automation systems with the human-centric, sustainable,\nand resilient principles of Industry 5.0. Based on the intent-based processing,\nthe framework allows human operators to express high-level business or\noperational goals in natural language, which are decomposed into actionable\ncomponents. These intents are broken into expectations, conditions, targets,\ncontext, and information that guide sub-agents equipped with specialized tools\nto execute domain-specific tasks. A proof of concept was implemented using the\nCMAPSS dataset and Google Agent Developer Kit (ADK), demonstrating the\nfeasibility of intent decomposition, agent orchestration, and autonomous\ndecision-making in predictive maintenance scenarios. The results confirm the\npotential of this approach to reduce technical barriers and enable scalable,\nintent-driven automation, despite data quality and explainability concerns.", "AI": {"title_translation": "基于意图的工业自动化中的智能体AI", "tldr": "本文提出了一种将智能体AI与基于意图范式相结合的框架，以简化人机交互并实现可扩展的、意图驱动的工业自动化，并在预测性维护场景中进行了概念验证。", "motivation": "智能体AI系统在工业自动化中带来了新的可能性并降低了工业4.0引入的复杂性。本文旨在简化人机交互，使自动化系统更好地符合工业5.0以人为中心、可持续和有弹性的原则。", "method": "本文提出了一种概念框架，将智能体AI与基于意图的范式相结合。该框架允许操作员用自然语言表达高级业务或操作目标，这些目标被分解为可操作的组件（意图），进一步细分为期望、条件、目标、上下文和信息，以指导配备专业工具的子智能体执行特定领域的任务。", "result": "通过使用CMAPSS数据集和Google Agent Developer Kit (ADK)实现了一个概念验证，证明了在预测性维护场景中意图分解、智能体编排和自主决策的可行性。结果证实了该方法在减少技术障碍和实现可扩展的、意图驱动的自动化方面的潜力。", "conclusion": "尽管存在数据质量和可解释性问题，但该方法有望减少技术障碍并实现可扩展的、意图驱动的工业自动化。", "translation": "智能体AI在基于意图的工业自动化中的应用\n\n智能体AI系统的最新发展，得益于具备规划和工具使用能力的自主大型语言模型（LLMs）智能体，为工业自动化的演进带来了新的可能性，并降低了工业4.0引入的复杂性。这项工作提出了一个概念框架，将智能体AI与最初在网络研究中开发的基于意图的范式相结合，以简化人机交互（HMI），并使自动化系统更好地符合工业5.0以人为中心、可持续和有弹性的原则。基于意图处理，该框架允许人类操作员用自然语言表达高级业务或操作目标，这些目标被分解为可操作的组件。这些意图被分解为期望、条件、目标、上下文和信息，以指导配备专业工具的子智能体执行特定领域的任务。使用CMAPSS数据集和Google Agent Developer Kit (ADK)实现了一个概念验证，展示了在预测性维护场景中意图分解、智能体编排和自主决策的可行性。尽管存在数据质量和可解释性问题，但结果证实了这种方法在减少技术障碍和实现可扩展的、意图驱动的自动化方面的潜力。", "summary": "本文提出了一个将智能体AI与基于意图范式相结合的框架，旨在通过允许操作员使用自然语言表达高层目标来简化工业自动化中的人机交互。该框架将这些目标分解为可操作的意图，并由专业智能体执行。通过在预测性维护中的概念验证，该研究展示了该方法在实现可扩展、意图驱动自动化方面的潜力，从而降低了工业4.0的复杂性并符合工业5.0的原则。", "keywords": "智能体AI, 意图驱动自动化, 工业自动化, 人机交互, 预测性维护"}}
{"id": "2506.05108", "pdf": "https://arxiv.org/pdf/2506.05108", "abs": "https://arxiv.org/abs/2506.05108", "authors": ["Revant Teotia", "Candace Ross", "Karen Ullrich", "Sumit Chopra", "Adriana Romero-Soriano", "Melissa Hall", "Matthew J. Muckley"], "title": "DIMCIM: A Quantitative Evaluation Framework for Default-mode Diversity and Generalization in Text-to-Image Generative Models", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in text-to-image (T2I) models have achieved impressive\nquality and consistency. However, this has come at the cost of representation\ndiversity. While automatic evaluation methods exist for benchmarking model\ndiversity, they either require reference image datasets or lack specificity\nabout the kind of diversity measured, limiting their adaptability and\ninterpretability. To address this gap, we introduce the Does-it/Can-it\nframework, DIM-CIM, a reference-free measurement of default-mode diversity\n(\"Does\" the model generate images with expected attributes?) and generalization\ncapacity (\"Can\" the model generate diverse attributes for a particular\nconcept?). We construct the COCO-DIMCIM benchmark, which is seeded with COCO\nconcepts and captions and augmented by a large language model. With\nCOCO-DIMCIM, we find that widely-used models improve in generalization at the\ncost of default-mode diversity when scaling from 1.5B to 8.1B parameters.\nDIMCIM also identifies fine-grained failure cases, such as attributes that are\ngenerated with generic prompts but are rarely generated when explicitly\nrequested. Finally, we use DIMCIM to evaluate the training data of a T2I model\nand observe a correlation of 0.85 between diversity in training images and\ndefault-mode diversity. Our work provides a flexible and interpretable\nframework for assessing T2I model diversity and generalization, enabling a more\ncomprehensive understanding of model performance.", "AI": {"title_translation": "DIMCIM：文本到图像生成模型中默认模式多样性和泛化性的定量评估框架", "tldr": "DIMCIM是一个用于评估文本到图像模型多样性和泛化能力的无参考框架，发现模型泛化能力提高以牺牲默认模式多样性为代价。", "motivation": "现有文本到图像（T2I）模型在质量和一致性方面取得了进展，但牺牲了表示多样性。现有的自动评估方法需要参考图像数据集或缺乏对所测量多样性类型的特异性，限制了其适应性和可解释性。", "method": "本文引入了Does-it/Can-it (DIM-CIM) 框架，这是一种无参考的测量方法，用于评估默认模式多样性（模型是否生成具有预期属性的图像？）和泛化能力（模型能否为特定概念生成多样属性？）。研究构建了COCO-DIMCIM基准，该基准以COCO概念和标题为种子，并由大型语言模型增强。", "result": "通过COCO-DIMCIM，研究发现广泛使用的模型在参数从1.5B扩展到8.1B时，泛化能力提高但默认模式多样性下降。DIMCIM能识别细粒度故障案例，例如在通用提示下可生成但明确请求时却很少生成的属性。此外，评估T2I模型训练数据，发现训练图像多样性与默认模式多样性之间存在0.85的相关性。", "conclusion": "DIMCIM提供了一个灵活且可解释的框架，用于评估T2I模型的多样性和泛化能力，从而有助于更全面地理解模型性能。", "translation": "文本到图像（T2I）模型的最新进展在质量和一致性方面取得了令人印象深刻的成就。然而，这却是以牺牲表示多样性为代价的。尽管存在用于评估模型多样性的自动化方法，但它们要么需要参考图像数据集，要么缺乏对所测量多样性类型的特异性，从而限制了其适应性和可解释性。为了弥补这一空白，我们引入了Does-it/Can-it（DIM-CIM）框架，这是一种对默认模式多样性（模型是否生成具有预期属性的图像？）和泛化能力（模型能否为特定概念生成多样属性？）的无参考测量方法。我们构建了COCO-DIMCIM基准，该基准以COCO概念和标题为种子，并由大型语言模型进行增强。通过COCO-DIMCIM，我们发现广泛使用的模型在参数从1.5B扩展到8.1B时，泛化能力有所提高，但默认模式多样性却有所下降。DIMCIM还能识别细粒度故障案例，例如在通用提示下可以生成但明确请求时却很少生成的属性。最后，我们使用DIMCIM评估了T2I模型的训练数据，并观察到训练图像多样性与默认模式多样性之间存在0.85的相关性。我们的工作提供了一个灵活且可解释的框架，用于评估T2I模型的多样性和泛化能力，从而能够更全面地理解模型性能。", "summary": "本文介绍了DIMCIM框架，一个无参考的文本到图像模型评估工具，旨在解决现有方法在衡量模型多样性和泛化能力方面的局限性。DIMCIM通过测量默认模式多样性（模型是否生成具有预期属性的图像？）和泛化能力（模型能否为特定概念生成多样属性？）来评估模型表现。研究发现，随着模型规模的扩大，文本到图像模型在泛化能力上有所提升，但默认模式多样性却下降。此外，DIMCIM能够识别模型在生成特定属性时的失败案例，并揭示了训练数据多样性与模型默认模式多样性之间存在强关联性。", "keywords": "文本到图像模型, 多样性, 泛化, 评估框架, DIMCIM"}}
{"id": "2506.04985", "pdf": "https://arxiv.org/pdf/2506.04985", "abs": "https://arxiv.org/abs/2506.04985", "authors": ["Boris van Breugel", "Yelysei Bondarenko", "Paul Whatmough", "Markus Nagel"], "title": "FPTQuant: Function-Preserving Transforms for LLM Quantization", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) require substantial compute, and thus energy, at\ninference time. While quantizing weights and activations is effective at\nimproving efficiency, naive quantization of LLMs can significantly degrade\nperformance due to large magnitude outliers. This paper describes FPTQuant,\nwhich introduces four novel, lightweight, and expressive function-preserving\ntransforms (FPTs) to facilitate quantization of transformers: (1) a mergeable\npre-RoPE transform for queries and keys, (2) a mergeable transform for values,\n(3) a mergeable scaling transform within the MLP block, and (4) a cheap,\ndynamic scaling transform. By leveraging the equivariances and independencies\ninherent to canonical transformer operation, we designed these FPTs to maintain\nthe model's function while shaping the intermediate activation distributions to\nbe more quantization friendly. FPTQuant requires no custom kernels and adds\nvirtually no overhead during inference. The FPTs are trained both locally to\nreduce outliers, and end-to-end such that the outputs of the quantized and\nfull-precision models match. FPTQuant enables static INT4 quantization with\nminimal overhead and shows SOTA speed-up of up to 3.9 times over FP.\nEmpirically, FPTQuant has an excellent accuracy-speed trade-off -- it is\nperforming on par or exceeding most prior work and only shows slightly lower\naccuracy compared to a method that is up to 29% slower.", "AI": {"title_translation": "FPTQuant：用于LLM量化的功能保留变换", "tldr": "FPTQuant引入了四种轻量级功能保留变换（FPTs），以实现LLM的INT4量化，同时保持模型性能并提供显著的推理加速，无需自定义内核或额外开销。", "motivation": "大型语言模型（LLMs）在推理时需要大量的计算资源和能量。虽然量化可以提高效率，但朴素的LLM量化会导致性能显著下降，原因是存在大数值异常值。", "method": "本文介绍了FPTQuant，它引入了四种新颖、轻量级且富有表现力的功能保留变换（FPTs）来促进Transformer的量化：1）用于查询和键的可合并的pre-RoPE变换，2）用于值的可合并变换，3）MLP块内可合并的缩放变换，4）廉价的动态缩放变换。这些FPTs利用Transformer操作固有的等变性和独立性，旨在在保持模型功能的同时，使中间激活分布更适合量化。FPTQuant无需自定义内核，推理时几乎没有开销。FPTs在局部进行训练以减少异常值，并进行端到端训练，使量化模型和全精度模型的输出匹配。", "result": "FPTQuant实现了静态INT4量化，开销极小，并显示出比FP高达3.9倍的SOTA加速。经验表明，FPTQuant在精度-速度权衡方面表现出色，其性能与大多数现有工作持平或超越，并且与速度慢29%的方法相比，精度仅略低。", "conclusion": "FPTQuant通过引入功能保留变换，有效解决了LLM量化中的性能下降问题，在保持高精度的同时显著提升了推理速度，展现了出色的实用价值和效率。", "translation": "大型语言模型（LLMs）在推理时需要大量的计算资源，因此也需要大量的能源。虽然对权重和激活进行量化可以有效提高效率，但对LLMs进行朴素量化会由于大数值异常值的存在而显著降低性能。本文介绍了FPTQuant，它引入了四种新颖、轻量级且富有表现力的功能保留变换（FPTs），以促进Transformer的量化：(1) 用于查询和键的可合并的pre-RoPE变换，(2) 用于值的可合并变换，(3) MLP块内可合并的缩放变换，以及(4) 廉价的动态缩放变换。通过利用规范Transformer操作固有的等变性和独立性，我们设计了这些FPTs，以在保持模型功能的同时，将中间激活分布塑造成更适合量化的形式。FPTQuant无需自定义内核，推理时几乎不增加开销。FPTs在局部进行训练以减少异常值，并进行端到端训练，使得量化模型和全精度模型的输出匹配。FPTQuant能够实现静态INT4量化，开销极小，并显示出比FP高达3.9倍的SOTA加速。从经验上看，FPTQuant在精度-速度权衡方面表现出色——其性能与大多数现有工作持平或超越，并且与速度慢29%的方法相比，精度仅略低。", "summary": "FPTQuant提出了一种新颖的量化方法，通过引入四种轻量级且功能保留的变换（FPTs），解决了大型语言模型（LLMs）在量化过程中因大数值异常值导致的性能下降问题。这些FPTs旨在调整中间激活分布以适应量化，同时保持模型的原始功能。FPTQuant无需自定义内核，推理开销极低，并能实现静态INT4量化，相比全精度模型提供高达3.9倍的加速。实验结果表明，FPTQuant在精度与速度之间取得了出色的平衡，性能优于或媲美现有大部分工作。", "keywords": "LLM量化, 功能保留变换, FPTQuant, 模型加速, INT4量化"}}
{"id": "2506.05119", "pdf": "https://arxiv.org/pdf/2506.05119", "abs": "https://arxiv.org/abs/2506.05119", "authors": ["Benedikt Hopf", "Radu Timofte"], "title": "Practical Manipulation Model for Robust Deepfake Detection", "categories": ["cs.CV"], "comment": null, "summary": "Modern deepfake detection models have achieved strong performance even on the\nchallenging cross-dataset task. However, detection performance under non-ideal\nconditions remains very unstable, limiting success on some benchmark datasets\nand making it easy to circumvent detection. Inspired by the move to a more\nreal-world degradation model in the area of image super-resolution, we have\ndeveloped a Practical Manipulation Model (PMM) that covers a larger set of\npossible forgeries. We extend the space of pseudo-fakes by using Poisson\nblending, more diverse masks, generator artifacts, and distractors.\nAdditionally, we improve the detectors' generality and robustness by adding\nstrong degradations to the training images. We demonstrate that these changes\nnot only significantly enhance the model's robustness to common image\ndegradations but also improve performance on standard benchmark datasets.\nSpecifically, we show clear increases of $3.51\\%$ and $6.21\\%$ AUC on the DFDC\nand DFDCP datasets, respectively, over the s-o-t-a LAA backbone. Furthermore,\nwe highlight the lack of robustness in previous detectors and our improvements\nin this regard. Code can be found at https://github.com/BenediktHopf/PMM", "AI": {"title_translation": "鲁棒深度伪造检测的实用操作模型", "tldr": "本文提出了一个实用操作模型（PMM），通过扩展伪造空间和增加训练图像的降级来提高深度伪造检测模型的鲁棒性和泛化能力。", "motivation": "现代深度伪造检测模型在理想条件下表现良好，但在非理想条件下性能不稳定，容易被规避，限制了其在基准数据集上的成功。", "method": "开发了一个实用操作模型（PMM），通过使用泊松混合、更多样化的掩码、生成器伪影和干扰物来扩展伪伪造空间。此外，通过向训练图像添加强降级来提高检测器的泛化性和鲁棒性。", "result": "模型显著增强了对常见图像降级的鲁棒性，并在标准基准数据集上提高了性能。具体来说，在DFDC和DFDCP数据集上，相比SOTA LAA骨干网络，AUC分别提高了3.51%和6.21%。", "conclusion": "本文提出的PMM显著提高了深度伪造检测模型的鲁棒性和在基准数据集上的性能，解决了现有检测器鲁棒性不足的问题。", "translation": "现代深度伪造检测模型即使在具有挑战性的跨数据集任务中也取得了强大的性能。然而，在非理想条件下的检测性能仍然非常不稳定，这限制了在某些基准数据集上的成功，并且很容易规避检测。受图像超分辨率领域中向更真实世界降级模型发展的启发，我们开发了一个实用操作模型（PMM），涵盖了更大范围的可能伪造。我们通过使用泊松混合、更多样化的掩码、生成器伪影和干扰物来扩展伪伪造空间。此外，我们通过向训练图像添加强降级来提高检测器的泛化性和鲁棒性。我们证明这些改变不仅显著增强了模型对常见图像降级的鲁棒性，而且还提高了标准基准数据集上的性能。具体而言，我们展示了在DFDC和DFDCP数据集上，相比最先进的LAA骨干网络，AUC分别有3.51%和6.21%的明显提升。此外，我们强调了以前检测器缺乏鲁棒性以及我们在这方面的改进。代码可在https://github.com/BenediktHopf/PMM找到。", "summary": "本文针对现有深度伪造检测模型在非理想条件下鲁棒性不足的问题，提出了一个实用操作模型（PMM）。PMM通过扩展伪造空间（包括泊松混合、多样化掩码、生成器伪影和干扰物）并向训练图像添加强降级，显著提升了模型的泛化性和鲁棒性。实验证明，PMM不仅增强了模型对常见图像降级的鲁棒性，还在DFDC和DFDCP等标准基准数据集上取得了显著的性能提升，AUC分别提高了3.51%和6.21%。", "keywords": "深度伪造检测, 鲁棒性, 实用操作模型, 图像降级, 伪造"}}
{"id": "2506.05005", "pdf": "https://arxiv.org/pdf/2506.05005", "abs": "https://arxiv.org/abs/2506.05005", "authors": ["Ashkan Soleymani", "Georgios Piliouras", "Gabriele Farina"], "title": "Cautious Optimism: A Meta-Algorithm for Near-Constant Regret in General Games", "categories": ["cs.LG", "cs.GT", "math.OC"], "comment": "Extended abstract appeared at Twenty-Sixth ACM Conference on\n  Economics and Computation (EC), 2025", "summary": "Recent work [Soleymani et al., 2025] introduced a variant of Optimistic\nMultiplicative Weights Updates (OMWU) that adaptively controls the learning\npace in a dynamic, non-monotone manner, achieving new state-of-the-art regret\nminimization guarantees in general games. In this work, we demonstrate that\nno-regret learning acceleration through adaptive pacing of the learners is not\nan isolated phenomenon. We introduce \\emph{Cautious Optimism}, a framework for\nsubstantially faster regularized learning in general games. Cautious Optimism\ntakes as input any instance of Follow-the-Regularized-Leader (FTRL) and outputs\nan accelerated no-regret learning algorithm by pacing the underlying FTRL with\nminimal computational overhead. Importantly, we retain uncoupledness (learners\ndo not need to know other players' utilities). Cautious Optimistic FTRL\nachieves near-optimal $O_T(\\log T)$ regret in diverse self-play\n(mixing-and-matching regularizers) while preserving the optimal $O(\\sqrt{T})$\nregret in adversarial scenarios. In contrast to prior works (e.g. Syrgkanis et\nal. [2015], Daskalakis et al. [2021]), our analysis does not rely on monotonic\nstep-sizes, showcasing a novel route for fast learning in general games.", "AI": {"title_translation": "谨慎乐观：一种在一般博弈中实现近似常数后悔的元算法", "tldr": "“谨慎乐观”是一种新的元算法，通过自适应调整跟随正则化领导者 (FTRL) 的步调，显著加速了一般博弈中的无后悔学习，在自博弈中实现了近似最优的对数后悔，并在对抗性场景中保持了最优的平方根后悔，且不依赖单调步长。", "motivation": "近期工作表明通过自适应调整学习器步调可以加速无后悔学习，但本研究旨在证明这种加速并非孤立现象，并提供一个通用的框架，用于在一般博弈中实现更快的正则化学习，克服了先前依赖单调步长方法的局限性。", "method": "本文引入了“谨慎乐观”（Cautious Optimism）框架，该框架以任何跟随正则化领导者 (FTRL) 实例为输入，并通过以最小的计算开销自适应调整底层 FTRL 的步调，输出一个加速的无后悔学习算法。该方法保留了非耦合性，且不依赖单调步长。", "result": "谨慎乐观的 FTRL 在多样化的自博弈中实现了近似最优的 $O_T(\\log T)$ 后悔，同时在对抗性场景中保持了最优的 $O(\\sqrt{T})$ 后悔。与现有工作不同，其分析不依赖于单调步长。", "conclusion": "“谨慎乐观”为一般博弈中的快速学习提供了一条新颖且通用的途径，它在加速 FTRL 的同时保持了非耦合性，并克服了对单调步长的依赖。", "translation": "近期工作 [Soleymani et al., 2025] 引入了一种乐观乘法权重更新 (OMWU) 的变体，该变体以动态、非单调的方式自适应地控制学习速度，在一般博弈中实现了新的最先进的后悔最小化保证。在这项工作中，我们证明了通过学习器自适应调整步调来加速无后悔学习并非孤立现象。我们引入了“谨慎乐观”（Cautious Optimism），这是一个在一般博弈中显著加速正则化学习的框架。“谨慎乐观”将任何跟随正则化领导者 (FTRL) 实例作为输入，并通过以最小的计算开销调整底层 FTRL 的步调，输出一个加速的无后悔学习算法。重要的是，我们保留了非耦合性（学习器不需要知道其他玩家的效用）。谨慎乐观的 FTRL 在多样化的自博弈（混合和匹配正则化器）中实现了近似最优的 $O_T(\\log T)$ 后悔，同时在对抗性场景中保持了最优的 $O(\\sqrt{T})$ 后悔。与之前的工作（例如 Syrgkanis et al. [2015], Daskalakis et al. [2021]）相比，我们的分析不依赖于单调步长，展示了在一般博弈中快速学习的新途径。", "summary": "本文介绍了“谨慎乐观”这一元算法，它显著加速了一般博弈中的正则化无后悔学习。该算法通过以最小的计算开销自适应调整现有跟随正则化领导者 (FTRL) 算法的步调，并保持了非耦合性。这种方法在自博弈中实现了近似最优的对数后悔，并在对抗性场景中实现了最优的平方根后悔，尤其值得注意的是，它不依赖于单调步长，为快速学习提供了新的方向。", "keywords": "无后悔学习, 元算法, 一般博弈, FTRL, 自适应步调"}}
{"id": "2506.05146", "pdf": "https://arxiv.org/pdf/2506.05146", "abs": "https://arxiv.org/abs/2506.05146", "authors": ["Massimo Rizzoli", "Simone Alghisi", "Olha Khomyn", "Gabriel Roccabruna", "Seyed Mahed Mousavi", "Giuseppe Riccardi"], "title": "CIVET: Systematic Evaluation of Understanding in VLMs", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "While Vision-Language Models (VLMs) have achieved competitive performance in\nvarious tasks, their comprehension of the underlying structure and semantics of\na scene remains understudied. To investigate the understanding of VLMs, we\nstudy their capability regarding object properties and relations in a\ncontrolled and interpretable manner. To this scope, we introduce CIVET, a novel\nand extensible framework for systematiC evaluatIon Via controllEd sTimuli.\nCIVET addresses the lack of standardized systematic evaluation for assessing\nVLMs' understanding, enabling researchers to test hypotheses with statistical\nrigor. With CIVET, we evaluate five state-of-the-art VLMs on exhaustive sets of\nstimuli, free from annotation noise, dataset-specific biases, and uncontrolled\nscene complexity. Our findings reveal that 1) current VLMs can accurately\nrecognize only a limited set of basic object properties; 2) their performance\nheavily depends on the position of the object in the scene; 3) they struggle to\nunderstand basic relations among objects. Furthermore, a comparative evaluation\nwith human annotators reveals that VLMs still fall short of achieving\nhuman-level accuracy.", "AI": {"title_translation": "CIVET: 系统性评估视觉语言模型（VLMs）的理解能力", "tldr": "本研究引入了CIVET框架，用于系统性评估视觉语言模型（VLMs）对场景中物体属性和关系的理解能力。研究发现当前VLMs在识别基本物体属性、处理物体位置依赖性以及理解物体间基本关系方面存在不足，且未能达到人类水平的准确性。", "motivation": "尽管视觉语言模型（VLMs）在各种任务中表现出色，但其对场景底层结构和语义的理解仍未得到充分研究。缺乏评估VLMs理解能力的标准化系统评估方法。", "method": "本研究引入了一个名为CIVET的新颖且可扩展的框架，用于通过受控刺激进行系统评估。CIVET使用详尽的刺激集，排除了标注噪声、数据集特定偏差和不受控制的场景复杂性。研究使用CIVET评估了五种最先进的VLMs，并与人类标注者进行了比较评估。", "result": "研究发现：1) 当前的VLMs只能准确识别有限的基本物体属性；2) 它们的性能严重依赖于物体在场景中的位置；3) 它们难以理解物体间的基本关系。此外，与人类标注者的比较评估显示，VLMs仍未能达到人类水平的准确性。", "conclusion": "视觉语言模型在理解场景中物体属性和关系方面仍有显著不足，未能达到人类水平。未来的研究应关注提高VLMs对场景深层语义的理解能力。", "translation": "尽管视觉语言模型（VLMs）在各种任务中取得了有竞争力的表现，但它们对场景底层结构和语义的理解仍未得到充分研究。为了探究VLMs的理解能力，我们以受控和可解释的方式研究了它们在物体属性和关系方面的能力。为此，我们引入了CIVET，这是一个用于通过受控刺激进行系统评估的新颖且可扩展的框架。CIVET解决了评估VLMs理解能力时缺乏标准化系统评估的问题，使研究人员能够以统计学严谨性检验假设。通过CIVET，我们评估了五种最先进的VLMs，使用了详尽的刺激集，这些刺激集没有标注噪声、数据集特定偏差和不受控制的场景复杂性。我们的研究结果表明：1) 当前的VLMs只能准确识别有限的基本物体属性；2) 它们的性能严重依赖于物体在场景中的位置；3) 它们难以理解物体间的基本关系。此外，与人类标注者的比较评估显示，VLMs仍未能达到人类水平的准确性。", "summary": "本研究引入了CIVET框架，旨在系统性评估视觉语言模型（VLMs）对场景中物体属性和关系的理解能力。通过使用受控刺激集，研究发现当前的VLMs在识别基本物体属性、处理物体位置依赖性以及理解物体间基本关系方面存在局限。与人类表现的比较也显示，VLMs尚未达到人类水平的准确性，揭示了VLMs在深层场景理解方面的不足。", "keywords": "视觉语言模型, 理解能力, 系统评估, 物体属性, 物体关系"}}
{"id": "2506.05014", "pdf": "https://arxiv.org/pdf/2506.05014", "abs": "https://arxiv.org/abs/2506.05014", "authors": ["Nektarios Kalampalikis", "Kavya Gupta", "Georgi Vitanov", "Isabel Valera"], "title": "Towards Reasonable Concept Bottleneck Models", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "26 pages, 17 figures", "summary": "In this paper, we propose $\\textbf{C}$oncept $\\textbf{REA}$soning\n$\\textbf{M}$odels (CREAM), a novel family of Concept Bottleneck Models (CBMs)\nthat: (i) explicitly encodes concept-concept (${\\texttt{C-C}}$) and\nconcept-task (${\\texttt{C$\\rightarrow$Y}}$) relationships to enforce a desired\nmodel reasoning; and (ii) use a regularized side-channel to achieve competitive\ntask performance, while keeping high concept importance. Specifically, CREAM\narchitecturally embeds (bi)directed concept-concept, and concept to task\nrelationships specified by a human expert, while severing undesired information\nflows (e.g., to handle mutually exclusive concepts). Moreover, CREAM integrates\na black-box side-channel that is regularized to encourage task predictions to\nbe grounded in the relevant concepts, thereby utilizing the side-channel only\nwhen necessary to enhance performance. Our experiments show that: (i) CREAM\nmainly relies on concepts while achieving task performance on par with\nblack-box models; and (ii) the embedded ${\\texttt{C-C}}$ and\n${\\texttt{C$\\rightarrow$Y}}$ relationships ease model interventions and\nmitigate concept leakage.", "AI": {"title_translation": "迈向合理的概念瓶颈模型", "tldr": "本文提出了一种名为CREAM的新型概念瓶颈模型（CBM），它通过显式编码概念间和概念到任务的关系来强制模型推理，并利用正则化旁路通道在保持概念重要性的同时实现有竞争力的任务性能。", "motivation": "现有的概念瓶颈模型可能在模型推理和性能之间存在权衡，本文旨在通过显式编码概念关系和使用正则化旁路通道来改进CBM，以实现合理的模型推理和保持高性能。", "method": "本文提出了概念推理模型（CREAM），这是一种新的概念瓶颈模型（CBM）。CREAM通过架构上嵌入人类专家指定的概念-概念（C-C）和概念-任务（C→Y）关系，并切断不需要的信息流（例如，处理互斥概念）。此外，CREAM整合了一个黑盒旁路通道，该通道经过正则化以鼓励任务预测基于相关概念，仅在必要时利用旁路通道来提高性能。", "result": "实验表明：(i) CREAM主要依赖概念，同时实现了与黑盒模型相当的任务性能；(ii) 嵌入的C-C和C→Y关系简化了模型干预并减轻了概念泄露。", "conclusion": "CREAM通过显式编码概念关系和使用正则化旁路通道，在保持概念重要性的同时实现了与黑盒模型相当的性能，并改进了模型可干预性和减少了概念泄露。", "translation": "在本文中，我们提出了概念推理模型（CREAM），这是一种新型的概念瓶颈模型（CBM）家族，它：(i) 显式编码概念-概念（C-C）和概念-任务（C→Y）关系以强制实现期望的模型推理；以及 (ii) 使用正则化旁路通道以实现有竞争力的任务性能，同时保持高概念重要性。具体而言，CREAM在架构上嵌入了人类专家指定的（双）有向概念-概念和概念到任务关系，同时切断了不需要的信息流（例如，处理互斥概念）。此外，CREAM整合了一个黑盒旁路通道，该通道经过正则化以鼓励任务预测基于相关概念，从而仅在必要时利用旁路通道来提高性能。我们的实验表明：(i) CREAM主要依赖概念，同时实现了与黑盒模型相当的任务性能；以及 (ii) 嵌入的C-C和C→Y关系简化了模型干预并减轻了概念泄露。", "summary": "本文提出了一种名为概念推理模型（CREAM）的新型概念瓶颈模型（CBM）。CREAM通过显式编码概念-概念和概念-任务关系来强制模型进行期望的推理，并利用一个正则化的旁路通道来在保持高概念重要性的同时实现有竞争力的任务性能。CREAM在架构上嵌入了由人类专家指定的概念关系，并集成了正则化的黑盒旁路通道，以确保预测基于相关概念。实验证明，CREAM主要依赖概念，性能与黑盒模型相当，并且其嵌入的概念关系有助于模型干预和减轻概念泄露。", "keywords": "概念瓶颈模型, 模型推理, 概念关系, 正则化旁路通道, 可解释性"}}
{"id": "2506.04557", "pdf": "https://arxiv.org/pdf/2506.04557", "abs": "https://arxiv.org/abs/2506.04557", "authors": ["Senyu Li", "Jiayi Wang", "Felermino D. M. A. Ali", "Colin Cherry", "Daniel Deutsch", "Eleftheria Briakou", "Rui Sousa-Silva", "Henrique Lopes Cardoso", "Pontus Stenetorp", "David Ifeoluwa Adelani"], "title": "SSA-COMET: Do LLMs Outperform Learned Metrics in Evaluating MT for Under-Resourced African Languages?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Evaluating machine translation (MT) quality for under-resourced African\nlanguages remains a significant challenge, as existing metrics often suffer\nfrom limited language coverage and poor performance in low-resource settings.\nWhile recent efforts, such as AfriCOMET, have addressed some of the issues,\nthey are still constrained by small evaluation sets, a lack of publicly\navailable training data tailored to African languages, and inconsistent\nperformance in extremely low-resource scenarios. In this work, we introduce\nSSA-MTE, a large-scale human-annotated MT evaluation (MTE) dataset covering 13\nAfrican language pairs from the News domain, with over 63,000 sentence-level\nannotations from a diverse set of MT systems. Based on this data, we develop\nSSA-COMET and SSA-COMET-QE, improved reference-based and reference-free\nevaluation metrics. We also benchmark prompting-based approaches using\nstate-of-the-art LLMs like GPT-4o and Claude. Our experimental results show\nthat SSA-COMET models significantly outperform AfriCOMET and are competitive\nwith the strongest LLM (Gemini 2.5 Pro) evaluated in our study, particularly on\nlow-resource languages such as Twi, Luo, and Yoruba. All resources are released\nunder open licenses to support future research.", "AI": {"title_translation": "SSA-COMET：大型语言模型在低资源非洲语言机器翻译评估中是否优于学习度量？", "tldr": "本研究介绍了SSA-MTE数据集和SSA-COMET模型，用于评估低资源非洲语言的机器翻译质量。SSA-COMET模型显著优于现有模型，并与最强的LLM（Gemini 2.5 Pro）具有竞争力，尤其是在低资源语言上。", "motivation": "评估低资源非洲语言的机器翻译（MT）质量仍然是一个重大挑战，现有评估指标存在语言覆盖范围有限、在低资源设置中性能不佳、受限于小型评估集、缺乏针对非洲语言的公开可用训练数据以及在极低资源场景中性能不一致等问题。", "method": "本研究引入了SSA-MTE，一个大规模人工标注的MT评估数据集，涵盖13种非洲语言对，包含超过63,000个句子级标注。基于此数据，开发了SSA-COMET和SSA-COMET-QE，改进的基于引用和无引用评估指标。同时，还使用GPT-4o和Claude等最先进的LLM对基于提示的方法进行了基准测试。", "result": "实验结果表明，SSA-COMET模型显著优于AfriCOMET，并且与研究中评估的最强LLM（Gemini 2.5 Pro）具有竞争力，特别是在特威语、卢奥语和约鲁巴语等低资源语言上表现突出。", "conclusion": "SSA-COMET模型在评估低资源非洲语言的机器翻译质量方面表现出色，优于现有学习度量，并能与顶尖大型语言模型相媲美。", "translation": "评估低资源非洲语言的机器翻译（MT）质量仍然是一个重大挑战，因为现有指标通常存在语言覆盖范围有限和在低资源设置中性能不佳的问题。尽管最近的努力，例如AfriCOMET，已经解决了一些问题，但它们仍然受限于小型评估集、缺乏针对非洲语言的公开可用训练数据以及在极低资源场景中性能不一致。在这项工作中，我们引入了SSA-MTE，一个大规模人工标注的MT评估（MTE）数据集，涵盖了来自新闻领域的13个非洲语言对，包含超过63,000个来自各种MT系统​​的句子级标注。基于这些数据，我们开发了SSA-COMET和SSA-COMET-QE，改进的基于引用和无引用评估指标。我们还使用GPT-4o和Claude等最先进的LLM对基于提示的方法进行了基准测试。我们的实验结果表明，SSA-COMET模型显著优于AfriCOMET，并且与我们研究中评估的最强LLM（Gemini 2.5 Pro）具有竞争力，特别是在特威语、卢奥语和约鲁巴语等低资源语言上。所有资源均以开放许可证发布，以支持未来的研究。", "summary": "本论文旨在解决低资源非洲语言机器翻译评估的挑战，通过引入大规模人工标注数据集SSA-MTE，并在此基础上开发了改进的评估指标SSA-COMET和SSA-COMET-QE。研究还对GPT-4o和Claude等大型语言模型进行了基准测试。结果显示，SSA-COMET模型显著优于AfriCOMET，并且在低资源语言上与Gemini 2.5 Pro等最强大型语言模型具有竞争力。所有资源均已开源。", "keywords": "机器翻译评估, 低资源语言, SSA-COMET, 大型语言模型, 非洲语言"}}
{"id": "2506.05163", "pdf": "https://arxiv.org/pdf/2506.05163", "abs": "https://arxiv.org/abs/2506.05163", "authors": ["Gabriele Magrini", "Niccolò Marini", "Federico Becattini", "Lorenzo Berlincioni", "Niccolò Biondi", "Pietro Pala", "Alberto Del Bimbo"], "title": "FRED: The Florence RGB-Event Drone Dataset", "categories": ["cs.CV"], "comment": null, "summary": "Small, fast, and lightweight drones present significant challenges for\ntraditional RGB cameras due to their limitations in capturing fast-moving\nobjects, especially under challenging lighting conditions. Event cameras offer\nan ideal solution, providing high temporal definition and dynamic range, yet\nexisting benchmarks often lack fine temporal resolution or drone-specific\nmotion patterns, hindering progress in these areas. This paper introduces the\nFlorence RGB-Event Drone dataset (FRED), a novel multimodal dataset\nspecifically designed for drone detection, tracking, and trajectory\nforecasting, combining RGB video and event streams. FRED features more than 7\nhours of densely annotated drone trajectories, using 5 different drone models\nand including challenging scenarios such as rain and adverse lighting\nconditions. We provide detailed evaluation protocols and standard metrics for\neach task, facilitating reproducible benchmarking. The authors hope FRED will\nadvance research in high-speed drone perception and multimodal spatiotemporal\nunderstanding.", "AI": {"title_translation": "FRED: 佛罗伦萨RGB-事件无人机数据集", "tldr": "FRED是一个新的多模态RGB-事件无人机数据集，用于无人机检测、跟踪和轨迹预测，旨在解决现有数据集的局限性。", "motivation": "传统RGB相机在捕捉快速移动的无人机时面临挑战，尤其是在恶劣光照下。事件相机是理想解决方案，但现有基准数据集缺乏精细时间分辨率或无人机特定运动模式，阻碍了相关研究进展。", "method": "本文引入了佛罗伦萨RGB-事件无人机数据集（FRED），这是一个新颖的多模态数据集，专门为无人机检测、跟踪和轨迹预测设计，结合了RGB视频和事件流。", "result": "FRED数据集包含超过7小时密集标注的无人机轨迹，使用了5种不同无人机模型，并包括雨水和恶劣光照条件等挑战性场景。作者提供了详细的评估协议和标准指标。", "conclusion": "作者希望FRED数据集能推动高速无人机感知和多模态时空理解领域的研究。", "translation": "小型、快速、轻量级无人机对传统RGB相机提出了重大挑战，因为它们在捕捉快速移动物体方面存在局限性，尤其是在恶劣光照条件下。事件相机提供了一个理想的解决方案，提供高时间清晰度和动态范围，但现有基准通常缺乏精细的时间分辨率或无人机特定的运动模式，阻碍了这些领域的进展。本文介绍了佛罗伦萨RGB-事件无人机数据集（FRED），这是一个专门为无人机检测、跟踪和轨迹预测设计的新型多模态数据集，结合了RGB视频和事件流。FRED包含超过7小时的密集标注无人机轨迹，使用了5种不同的无人机模型，并包括雨水和恶劣光照条件等挑战性场景。我们为每项任务提供了详细的评估协议和标准指标，便于可重复的基准测试。作者希望FRED将推动高速无人机感知和多模态时空理解领域的研究。", "summary": "FRED数据集是一个新颖的多模态RGB-事件无人机数据集，旨在解决传统RGB相机捕捉快速移动无人机以及现有数据集缺乏精细时间分辨率和无人机特定运动模式的问题。该数据集包含7小时以上的密集标注无人机轨迹，涵盖5种无人机模型和多种挑战性环境，并提供评估协议和指标，以期推动高速无人机感知和多模态时空理解的研究。", "keywords": "无人机数据集, RGB-事件相机, 多模态, 无人机检测, 轨迹预测"}}
{"id": "2506.05016", "pdf": "https://arxiv.org/pdf/2506.05016", "abs": "https://arxiv.org/abs/2506.05016", "authors": ["John Collins"], "title": "Multi-Point Proximity Encoding For Vector-Mode Geospatial Machine Learning", "categories": ["cs.LG", "68T07, 68T30", "I.2.4; J.2"], "comment": "10 pages, 8 figures", "summary": "Vector-mode geospatial data -- points, lines, and polygons -- must be encoded\ninto an appropriate form in order to be used with traditional machine learning\nand artificial intelligence models. Encoding methods attempt to represent a\ngiven shape as a vector that captures its essential geometric properties. This\npaper presents an encoding method based on scaled distances from a shape to a\nset of reference points within a region of interest. The method, MultiPoint\nProximity (MPP) encoding, can be applied to any type of shape, enabling the\nparameterization of machine learning models with encoded representations of\nvector-mode geospatial features. We show that MPP encoding possesses the\ndesirable properties of shape-centricity and continuity, can be used to\ndifferentiate spatial objects based on their geometric features, and can\ncapture pairwise spatial relationships with high precision. In all cases, MPP\nencoding is shown to perform better than an alternative method based on\nrasterization.", "AI": {"title_translation": "多点邻近编码用于矢量模式地理空间机器学习", "tldr": "提出了一种多点邻近（MPP）编码方法，用于将矢量模式地理空间数据转换为机器学习模型可用的形式，并证明其性能优于栅格化方法。", "motivation": "矢量模式地理空间数据（点、线、多边形）需要被编码成适当的形式才能用于传统的机器学习和人工智能模型，现有的编码方法可能无法充分捕捉其几何特性。", "method": "本文提出了一种基于形状到区域内一组参考点的比例距离的多点邻近（MPP）编码方法。该方法适用于任何类型的形状，可以将矢量模式地理空间特征的编码表示参数化到机器学习模型中。", "result": "MPP编码具有以形状为中心和连续的理想特性，可以根据几何特征区分空间对象，并能高精度地捕获成对的空间关系。在所有情况下，MPP编码的性能均优于基于栅格化的替代方法。", "conclusion": "MPP编码是一种有效且优于栅格化方法的矢量模式地理空间数据编码方法，能够捕捉重要的几何属性和空间关系。", "translation": "矢量模式地理空间数据——点、线和多边形——必须被编码成适当的形式才能用于传统的机器学习和人工智能模型。编码方法试图将给定形状表示为一个捕获其基本几何属性的向量。本文提出了一种基于形状到感兴趣区域内一组参考点的比例距离的编码方法。这种方法，即多点邻近（MPP）编码，可以应用于任何类型的形状，从而能够用矢量模式地理空间特征的编码表示来参数化机器学习模型。我们展示了MPP编码具有以形状为中心和连续的理想特性，可以根据其几何特征区分空间对象，并且可以高精度地捕获成对的空间关系。在所有情况下，MPP编码的性能均优于基于栅格化的替代方法。", "summary": "本研究提出了一种名为多点邻近（MPP）的编码方法，旨在将矢量模式地理空间数据（如点、线、多边形）转换为机器学习模型可用的向量形式。该方法通过计算形状到一组参考点的比例距离来表示几何属性。实验结果表明，MPP编码具有形状中心性和连续性，能够有效区分空间对象并精确捕获空间关系，并且在性能上优于传统的栅格化编码方法。", "keywords": "地理空间数据, 矢量模式, 机器学习, 多点邻近编码, 空间关系"}}
{"id": "2506.05169", "pdf": "https://arxiv.org/pdf/2506.05169", "abs": "https://arxiv.org/abs/2506.05169", "authors": ["Weicheng Gao"], "title": "Through-the-Wall Radar Human Activity Recognition WITHOUT Using Neural Networks", "categories": ["cs.CV", "eess.SP", "68T45", "I.5.4"], "comment": "15 pages, 8 figures, 8 tables", "summary": "After a few years of research in the field of through-the-wall radar (TWR)\nhuman activity recognition (HAR), I found that we seem to be stuck in the\nmindset of training on radar image data through neural network models. The\nearliest related works in this field based on template matching did not require\na training process, and I believe they have never died. Because these methods\npossess a strong physical interpretability and are closer to the basis of\ntheoretical signal processing research. In this paper, I would like to try to\nreturn to the original path by attempting to eschew neural networks to achieve\nthe TWR HAR task and challenge to achieve intelligent recognition as neural\nnetwork models. In detail, the range-time map and Doppler-time map of TWR are\nfirst generated. Then, the initial regions of the human target foreground and\nnoise background on the maps are determined using corner detection method, and\nthe micro-Doppler signature is segmented using the multiphase active contour\nmodel. The micro-Doppler segmentation feature is discretized into a\ntwo-dimensional point cloud. Finally, the topological similarity between the\nresulting point cloud and the point clouds of the template data is calculated\nusing Mapper algorithm to obtain the recognition results. The effectiveness of\nthe proposed method is demonstrated by numerical simulated and measured\nexperiments. The open-source code of this work is released at:\nhttps://github.com/JoeyBGOfficial/Through-the-Wall-Radar-Human-Activity-Recognition-Without-Using-Neural-Networks.", "AI": {"title_translation": "穿墙雷达人体活动识别不使用神经网络", "tldr": "本文提出了一种不使用神经网络的穿墙雷达人体活动识别方法，通过信号处理和拓扑相似性实现智能识别。", "motivation": "作者认为当前穿墙雷达人体活动识别（TWR HAR）领域的研究过度依赖神经网络和雷达图像数据，希望回归到具有强物理可解释性且更接近理论信号处理基础的模板匹配方法，以挑战在不使用神经网络的情况下实现与神经网络模型相当的智能识别。", "method": "首先生成穿墙雷达的距离-时间图和多普勒-时间图。然后，使用角点检测方法确定地图上人体目标前景和噪声背景的初始区域，并使用多相主动轮廓模型分割微多普勒特征。接着，将微多普勒分割特征离散化为二维点云。最后，使用Mapper算法计算所得点云与模板数据点云之间的拓扑相似性以获得识别结果。", "result": "所提出的方法通过数值模拟和实测实验证明了其有效性。", "conclusion": "本文成功展示了一种不使用神经网络的穿墙雷达人体活动识别方法，其有效性已通过实验验证，表明传统信号处理方法结合拓扑分析也能实现智能识别。", "translation": "在穿墙雷达（TWR）人体活动识别（HAR）领域经过几年的研究后，我发现我们似乎陷入了通过神经网络模型对雷达图像数据进行训练的思维定势。该领域最早的基于模板匹配的相关工作不需要训练过程，我相信它们从未消亡。因为这些方法具有很强的物理可解释性，并且更接近理论信号处理研究的基础。在本文中，我想尝试通过避免使用神经网络来实现TWR HAR任务，并挑战达到与神经网络模型相当的智能识别水平，从而回归到最初的路径。具体来说，首先生成TWR的距离-时间图和多普勒-时间图。然后，使用角点检测方法确定地图上人体目标前景和噪声背景的初始区域，并使用多相主动轮廓模型分割微多普勒特征。微多普勒分割特征被离散化为二维点云。最后，使用Mapper算法计算所得点云与模板数据点云之间的拓扑相似性以获得识别结果。所提出方法的有效性通过数值模拟和实测实验得到证明。本工作的开源代码发布在：https://github.com/JoeyBGOfficial/Through-the-Wall-Radar-Human-Activity-Recognition-Without-Using-Neural-Networks。", "summary": "本文提出了一种不依赖神经网络的穿墙雷达人体活动识别新方法。该方法首先生成距离-时间图和多普勒-时间图，然后利用角点检测确定目标区域，并通过多相主动轮廓模型分割微多普勒特征。随后，将分割出的特征离散化为二维点云，并最终通过Mapper算法计算其与模板数据点云的拓扑相似性来完成识别。数值模拟和实际测量实验均验证了该方法的有效性。", "keywords": "穿墙雷达, 人体活动识别, 信号处理, 微多普勒, 拓扑相似性"}}
{"id": "2506.05027", "pdf": "https://arxiv.org/pdf/2506.05027", "abs": "https://arxiv.org/abs/2506.05027", "authors": ["Kuang He", "Wei Tang", "Tong Wei", "Min-Ling Zhang"], "title": "Tuning the Right Foundation Models is What you Need for Partial Label Learning", "categories": ["cs.LG"], "comment": "The code can be found at \\url{https://github.com/SEU-hk/PartialCLIP}", "summary": "Partial label learning (PLL) seeks to train generalizable classifiers from\ndatasets with inexact supervision, a common challenge in real-world\napplications. Existing studies have developed numerous approaches to\nprogressively refine and recover ground-truth labels by training convolutional\nneural networks. However, limited attention has been given to foundation models\nthat offer transferrable representations. In this work, we empirically conduct\ncomprehensive evaluations of 11 foundation models across 13 PLL approaches on 8\nbenchmark datasets under 3 PLL scenarios. We further propose PartialCLIP, an\nefficient fine-tuning framework for foundation models in PLL. Our findings\nreveal that current PLL approaches tend to 1) achieve significant performance\ngains when using foundation models, 2) exhibit remarkably similar performance\nto each other, 3) maintain stable performance across varying ambiguity levels,\nwhile 4) are susceptible to foundation model selection and adaptation\nstrategies. Additionally, we demonstrate the efficacy of text-embedding\nclassifier initialization and effective candidate label filtering using\nzero-shot CLIP. Our experimental results and analysis underscore the\nlimitations of current PLL approaches and provide valuable insights for\ndeveloping more generalizable PLL models. The source code can be found at\nhttps://github.com/SEU-hk/PartialCLIP.", "AI": {"title_translation": "为部分标签学习调整正确的基础模型是您所需要的", "tldr": "该研究全面评估了基础模型在部分标签学习中的表现，并提出了PartialCLIP框架，指出基础模型对PLL性能提升显著，但选择和适应策略是关键。", "motivation": "部分标签学习（PLL）在现实世界应用中面临不精确监督的挑战。现有研究主要关注训练卷积神经网络来恢复真实标签，但对提供可迁移表示的基础模型关注有限。", "method": "本文对11种基础模型在13种PLL方法上进行了综合评估，使用了8个基准数据集和3种PLL场景。此外，提出了PartialCLIP，一个高效的PLL基础模型微调框架。研究还探讨了文本嵌入分类器初始化和使用零样本CLIP进行有效候选标签过滤的方法。", "result": "研究发现：1) 使用基础模型能显著提升PLL性能；2) 不同PLL方法表现出相似的性能；3) 性能在不同歧义级别下保持稳定；4) PLL方法易受基础模型选择和适应策略的影响。此外，文本嵌入分类器初始化和零样本CLIP的有效性得到了验证。", "conclusion": "目前的PLL方法存在局限性，但本研究为开发更具泛化能力的PLL模型提供了宝贵见解。", "translation": "部分标签学习（PLL）旨在从不精确监督的数据集中训练出可泛化的分类器，这是现实世界应用中的一个常见挑战。现有研究开发了许多方法，通过训练卷积神经网络来逐步完善和恢复真实标签。然而，对于提供可迁移表示的基础模型关注有限。在这项工作中，我们通过实证对11种基础模型在13种PLL方法上进行了全面评估，使用了8个基准数据集和3种PLL场景。我们进一步提出了PartialCLIP，一个用于PLL中基础模型的高效微调框架。我们的研究结果表明，当前的PLL方法倾向于：1) 在使用基础模型时获得显著的性能提升，2) 彼此表现出非常相似的性能，3) 在不同歧义级别下保持稳定性能，而4) 易受基础模型选择和适应策略的影响。此外，我们展示了文本嵌入分类器初始化和使用零样本CLIP进行有效候选标签过滤的有效性。我们的实验结果和分析强调了当前PLL方法的局限性，并为开发更具泛化能力的PLL模型提供了宝贵的见解。源代码可在https://github.com/SEU-hk/PartialCLIP找到。", "summary": "本文深入研究了基础模型在部分标签学习（PLL）中的应用，通过对11种基础模型和13种PLL方法的广泛评估，证实了基础模型能显著提升PLL性能，并指出基础模型的选择和微调策略至关重要。研究提出了PartialCLIP框架，并强调了文本嵌入分类器初始化和零样本CLIP在PLL中的有效性，为未来开发更泛化的PLL模型提供了指导。", "keywords": "部分标签学习, 基础模型, 微调, PartialCLIP, 零样本CLIP"}}
{"id": "2506.04574", "pdf": "https://arxiv.org/pdf/2506.04574", "abs": "https://arxiv.org/abs/2506.04574", "authors": ["Dimitris Vamvourellis", "Dhagash Mehta"], "title": "Reasoning or Overthinking: Evaluating Large Language Models on Financial Sentiment Analysis", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We investigate the effectiveness of large language models (LLMs), including\nreasoning-based and non-reasoning models, in performing zero-shot financial\nsentiment analysis. Using the Financial PhraseBank dataset annotated by domain\nexperts, we evaluate how various LLMs and prompting strategies align with\nhuman-labeled sentiment in a financial context. We compare three proprietary\nLLMs (GPT-4o, GPT-4.1, o3-mini) under different prompting paradigms that\nsimulate System 1 (fast and intuitive) or System 2 (slow and deliberate)\nthinking and benchmark them against two smaller models (FinBERT-Prosus,\nFinBERT-Tone) fine-tuned on financial sentiment analysis. Our findings suggest\nthat reasoning, either through prompting or inherent model design, does not\nimprove performance on this task. Surprisingly, the most accurate and\nhuman-aligned combination of model and method was GPT-4o without any\nChain-of-Thought (CoT) prompting. We further explore how performance is\nimpacted by linguistic complexity and annotation agreement levels, uncovering\nthat reasoning may introduce overthinking, leading to suboptimal predictions.\nThis suggests that for financial sentiment classification, fast, intuitive\n\"System 1\"-like thinking aligns more closely with human judgment compared to\n\"System 2\"-style slower, deliberative reasoning simulated by reasoning models\nor CoT prompting. Our results challenge the default assumption that more\nreasoning always leads to better LLM decisions, particularly in high-stakes\nfinancial applications.", "AI": {"title_translation": "推理还是过度思考：评估大型语言模型在金融情感分析中的表现", "tldr": "本研究评估了大型语言模型在零样本金融情感分析中的表现，发现推理能力并不能提升模型在此任务上的准确性。令人惊讶的是，GPT-4o在没有使用思维链提示的情况下表现最佳，与人类标注最为一致。研究表明，对于金融情感分类，快速直观的“系统1”式思维比缓慢审慎的“系统2”式推理更符合人类判断，这挑战了“更多推理总是带来更好决策”的普遍假设。", "motivation": "调查大型语言模型（LLM），包括基于推理和非推理模型，在执行零样本金融情感分析方面的有效性，并挑战“更多推理总是带来更好的LLM决策”这一默认假设，尤其是在高风险的金融应用中。", "method": "使用由领域专家标注的Financial PhraseBank数据集，评估了多种LLM和提示策略（模拟系统1和系统2思维）与人类标注情感的一致性。比较了三种专有LLM（GPT-4o, GPT-4.1, o3-mini）与两个在金融情感分析上微调的较小型模型（FinBERT-Prosus, FinBERT-Tone）。此外，还探讨了语言复杂性和标注一致性水平对性能的影响。", "result": "推理（无论是通过提示还是固有的模型设计）并未提高金融情感分析任务的性能。最准确且与人类对齐的模型和方法组合是GPT-4o，无需任何思维链（CoT）提示。推理可能引入过度思考，导致次优预测。快速、直观的“系统1”式思维与人类判断的契合度更高。", "conclusion": "对于金融情感分类，快速、直观的“系统1”式思维比“系统2”式缓慢、审慎的推理更符合人类判断，这挑战了“更多推理总是带来更好的LLM决策”的普遍假设，尤其是在高风险的金融应用中。", "translation": "我们调查了大型语言模型（LLM），包括基于推理和非推理模型，在执行零样本金融情感分析方面的有效性。我们使用由领域专家标注的金融短语库数据集，评估了各种LLM和提示策略在金融语境中与人类标注情感的一致性。我们比较了三种专有LLM（GPT-4o、GPT-4.1、o3-mini）在模拟系统1（快速直观）或系统2（缓慢审慎）思维的不同提示范式下的表现，并将其与两个在金融情感分析上进行微调的较小型模型（FinBERT-Prosus、FinBERT-Tone）进行基准测试。我们的发现表明，无论是通过提示还是固有的模型设计，推理都不会提高此任务的性能。令人惊讶的是，最准确且与人类对齐的模型和方法组合是GPT-4o，无需任何思维链（CoT）提示。我们进一步探讨了性能如何受到语言复杂性和标注一致性水平的影响，发现推理可能会引入过度思考，导致次优预测。这表明，对于金融情感分类，快速、直观的“系统1”式思维与人类判断的契合度更高，而“系统2”式缓慢、审慎的推理（通过推理模型或CoT提示模拟）则不然。我们的结果挑战了“更多推理总是带来更好的LLM决策”这一默认假设，特别是在高风险的金融应用中。", "summary": "本研究评估了大型语言模型在零样本金融情感分析中的表现，发现推理能力并不能提升模型在此任务上的准确性。令人惊讶的是，GPT-4o在没有使用思维链提示的情况下表现最佳，与人类标注最为一致。研究表明，对于金融情感分类，快速直观的“系统1”式思维比缓慢审慎的“系统2”式推理更符合人类判断，这挑战了“更多推理总是带来更好决策”的普遍假设。", "keywords": "大型语言模型, 金融情感分析, 零样本, 推理, 系统1思维"}}
{"id": "2506.05175", "pdf": "https://arxiv.org/pdf/2506.05175", "abs": "https://arxiv.org/abs/2506.05175", "authors": ["Yuzhi Huang", "Chenxin Li", "Haitao Zhang", "Zixu Lin", "Yunlong Lin", "Hengyu Liu", "Wuyang Li", "Xinyu Liu", "Jiechao Gao", "Yue Huang", "Xinghao Ding", "Yixuan Yuan"], "title": "Track Any Anomalous Object: A Granular Video Anomaly Detection Pipeline", "categories": ["cs.CV"], "comment": null, "summary": "Video anomaly detection (VAD) is crucial in scenarios such as surveillance\nand autonomous driving, where timely detection of unexpected activities is\nessential. Although existing methods have primarily focused on detecting\nanomalous objects in videos -- either by identifying anomalous frames or\nobjects -- they often neglect finer-grained analysis, such as anomalous pixels,\nwhich limits their ability to capture a broader range of anomalies. To address\nthis challenge, we propose a new framework called Track Any Anomalous Object\n(TAO), which introduces a granular video anomaly detection pipeline that, for\nthe first time, integrates the detection of multiple fine-grained anomalous\nobjects into a unified framework. Unlike methods that assign anomaly scores to\nevery pixel, our approach transforms the problem into pixel-level tracking of\nanomalous objects. By linking anomaly scores to downstream tasks such as\nsegmentation and tracking, our method removes the need for threshold tuning and\nachieves more precise anomaly localization in long and complex video sequences.\nExperiments demonstrate that TAO sets new benchmarks in accuracy and\nrobustness. Project page available online.", "AI": {"title_translation": "跟踪任何异常对象：一种细粒度视频异常检测管道", "tldr": "TAO是一个新的视频异常检测框架，它首次将多细粒度异常对象检测集成到一个统一的管道中，并通过像素级跟踪实现更精确的异常定位，在准确性和鲁棒性方面建立了新基准。", "motivation": "现有的视频异常检测方法主要关注帧或对象的异常检测，但忽略了更细粒度的分析（例如异常像素），这限制了它们捕获更广泛异常的能力。", "method": "我们提出了一个名为TAO（Track Any Anomalous Object）的新框架，它引入了一个细粒度视频异常检测管道，首次将多个细粒度异常对象检测集成到一个统一的框架中。与为每个像素分配异常分数的方法不同，我们的方法将问题转化为异常对象的像素级跟踪，并通过将异常分数与下游任务（如分割和跟踪）关联，消除了阈值调整的需要，并在长而复杂的视频序列中实现了更精确的异常定位。", "result": "实验表明，TAO在准确性和鲁棒性方面建立了新的基准。", "conclusion": "TAO框架通过引入细粒度像素级异常对象跟踪，显著提升了视频异常检测的准确性和鲁棒性，解决了现有方法在细粒度分析上的不足。", "translation": "视频异常检测（VAD）在监控和自动驾驶等场景中至关重要，在这些场景中，及时检测意外活动是必不可少的。尽管现有方法主要集中于检测视频中的异常对象——无论是通过识别异常帧还是异常对象——它们通常忽略更细粒度的分析，例如异常像素，这限制了它们捕获更广泛异常的能力。为了解决这一挑战，我们提出了一个名为“跟踪任何异常对象”（TAO）的新框架，它引入了一个细粒度视频异常检测管道，首次将多个细粒度异常对象的检测集成到一个统一的框架中。与为每个像素分配异常分数的方法不同，我们的方法将问题转化为异常对象的像素级跟踪。通过将异常分数与下游任务（如分割和跟踪）关联，我们的方法消除了阈值调整的需要，并在长而复杂的视频序列中实现了更精确的异常定位。实验表明，TAO在准确性和鲁棒性方面建立了新的基准。项目页面可在线获取。", "summary": "该论文提出了一种名为TAO（Track Any Anomalous Object）的细粒度视频异常检测新框架。针对现有方法忽略细粒度异常分析的局限性，TAO首次将多细粒度异常对象检测集成到统一管道中，并通过将问题转化为异常对象的像素级跟踪，实现了更精确的异常定位，并消除了阈值调整需求。实验证明，TAO在准确性和鲁棒性方面设立了新基准。", "keywords": "视频异常检测, 细粒度分析, 像素级跟踪, TAO, 异常定位"}}
{"id": "2506.04583", "pdf": "https://arxiv.org/pdf/2506.04583", "abs": "https://arxiv.org/abs/2506.04583", "authors": ["Hongjun Liu", "Yilun Zhao", "Arman Cohan", "Chen Zhao"], "title": "SUCEA: Reasoning-Intensive Retrieval for Adversarial Fact-checking through Claim Decomposition and Editing", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 10 figures, 7 tables", "summary": "Automatic fact-checking has recently received more attention as a means of\ncombating misinformation. Despite significant advancements, fact-checking\nsystems based on retrieval-augmented language models still struggle to tackle\nadversarial claims, which are intentionally designed by humans to challenge\nfact-checking systems. To address these challenges, we propose a training-free\nmethod designed to rephrase the original claim, making it easier to locate\nsupporting evidence. Our modular framework, SUCEA, decomposes the task into\nthree steps: 1) Claim Segmentation and Decontextualization that segments\nadversarial claims into independent sub-claims; 2) Iterative Evidence Retrieval\nand Claim Editing that iteratively retrieves evidence and edits the subclaim\nbased on the retrieved evidence; 3) Evidence Aggregation and Label Prediction\nthat aggregates all retrieved evidence and predicts the entailment label.\nExperiments on two challenging fact-checking datasets demonstrate that our\nframework significantly improves on both retrieval and entailment label\naccuracy, outperforming four strong claim-decomposition-based baselines.", "AI": {"title_translation": "SUCEA：通过声明分解和编辑进行对抗性事实核查的推理密集型检索", "tldr": "SUCEA是一个无需训练的方法，通过分解和编辑对抗性声明来改进事实核查系统中的证据检索和标签预测。", "motivation": "尽管自动事实核查系统取得了显著进展，但基于检索增强型语言模型的事实核查系统在处理对抗性声明时仍面临困难，这些声明是人类故意设计来挑战事实核查系统的。", "method": "我们提出了一种无需训练的方法，旨在重新措辞原始声明，使其更容易找到支持证据。我们的模块化框架SUCEA将任务分解为三个步骤：1）声明分割和去语境化，将对抗性声明分割成独立的子声明；2）迭代证据检索和声明编辑，迭代地检索证据并根据检索到的证据编辑子声明；3）证据聚合和标签预测，聚合所有检索到的证据并预测蕴含标签。", "result": "在两个具有挑战性的事实核查数据集上的实验表明，我们的框架显著提高了检索和蕴含标签的准确性，超越了四个强大的基于声明分解的基线。", "conclusion": "SUCEA框架通过声明分解和编辑，有效解决了对抗性事实核查中的证据检索和标签预测挑战，显著提升了系统性能。", "translation": "自动事实核查作为打击虚假信息的一种手段，最近受到了更多关注。尽管取得了显著进展，但基于检索增强型语言模型的事实核查系统在处理对抗性声明时仍然面临困难，这些声明是人类故意设计来挑战事实核查系统的。为了应对这些挑战，我们提出了一种无需训练的方法，旨在重新措辞原始声明，使其更容易找到支持证据。我们的模块化框架SUCEA将任务分解为三个步骤：1）声明分割和去语境化，将对抗性声明分割成独立的子声明；2）迭代证据检索和声明编辑，迭代地检索证据并根据检索到的证据编辑子声明；3）证据聚合和标签预测，聚合所有检索到的证据并预测蕴含标签。在两个具有挑战性的事实核查数据集上的实验表明，我们的框架显著提高了检索和蕴含标签的准确性，超越了四个强大的基于声明分解的基线。", "summary": "本论文提出了一种名为SUCEA的无需训练方法，旨在解决现有事实核查系统在处理对抗性声明时面临的挑战。SUCEA框架通过将对抗性声明分解为独立的子声明，并迭代地检索证据和编辑子声明，最终聚合证据并预测标签。实验结果表明，SUCEA在证据检索和蕴含标签准确性方面均优于现有基线。", "keywords": "事实核查, 对抗性声明, 声明分解, 证据检索, 语言模型"}}
{"id": "2506.05184", "pdf": "https://arxiv.org/pdf/2506.05184", "abs": "https://arxiv.org/abs/2506.05184", "authors": ["Neeraj Kumar", "Swaraj Nanda", "Siddharth Singi", "Jamal Benhamida", "David Kim", "Jie-Fu Chen", "Amir Momeni-Boroujeni", "Gregory M. Goldgof", "Gabriele Campanella", "Chad Vanderbilt"], "title": "Single GPU Task Adaptation of Pathology Foundation Models for Whole Slide Image Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Pathology foundation models (PFMs) have emerged as powerful tools for\nanalyzing whole slide images (WSIs). However, adapting these pretrained PFMs\nfor specific clinical tasks presents considerable challenges, primarily due to\nthe availability of only weak (WSI-level) labels for gigapixel images,\nnecessitating multiple instance learning (MIL) paradigm for effective WSI\nanalysis. This paper proposes a novel approach for single-GPU \\textbf{T}ask\n\\textbf{A}daptation of \\textbf{PFM}s (TAPFM) that uses vision transformer\n(\\vit) attention for MIL aggregation while optimizing both for feature\nrepresentations and attention weights. The proposed approach maintains separate\ncomputational graphs for MIL aggregator and the PFM to create stable training\ndynamics that align with downstream task objectives during end-to-end\nadaptation. Evaluated on mutation prediction tasks for bladder cancer and lung\nadenocarcinoma across institutional and TCGA cohorts, TAPFM consistently\noutperforms conventional approaches, with H-Optimus-0 (TAPFM) outperforming the\nbenchmarks. TAPFM effectively handles multi-label classification of actionable\nmutations as well. Thus, TAPFM makes adaptation of powerful pre-trained PFMs\npractical on standard hardware for various clinical applications.", "AI": {"title_translation": "单GPU病理基础模型任务适应性用于全玻片图像分析", "tldr": "TAPFM是一种在单GPU上适应病理基础模型（PFMs）的新方法，它利用视觉Transformer注意力进行MIL聚合，并通过分离计算图实现稳定训练，在癌症突变预测任务中表现优于传统方法，使PFM适应性在标准硬件上变得实用。", "motivation": "病理基础模型（PFMs）在全玻片图像（WSIs）分析中表现出色，但将其适应特定临床任务面临挑战，主要是因为千兆像素图像只有弱（WSI级）标签，需要多示例学习（MIL）范式。", "method": "本文提出了一种新颖的单GPU任务适应PFM（TAPFM）方法，该方法利用视觉Transformer（ViT）注意力进行MIL聚合，并同时优化特征表示和注意力权重。它为MIL聚合器和PFM维护独立的计算图，以创建稳定的训练动态，使其在端到端适应期间与下游任务目标对齐。", "result": "TAPFM在膀胱癌和肺腺癌的突变预测任务中，跨机构和TCGA队列的评估中，始终优于传统方法，其中H-Optimus-0（TAPFM）超越了基准。TAPFM也能有效处理可操作突变的多标签分类。", "conclusion": "TAPFM使得在标准硬件上适应强大的预训练PFM以用于各种临床应用变得实用。", "translation": "病理基础模型（PFMs）已成为分析全玻片图像（WSIs）的强大工具。然而，将这些预训练PFMs适应于特定的临床任务带来了相当大的挑战，这主要是由于千兆像素图像仅有弱（WSI级）标签可用，因此需要多示例学习（MIL）范式才能有效分析WSI。本文提出了一种用于单GPU任务适应PFM（TAPFM）的新颖方法，该方法利用视觉Transformer（ViT）注意力进行MIL聚合，同时优化特征表示和注意力权重。所提出的方法为MIL聚合器和PFM维护独立的计算图，以创建稳定的训练动态，使其在端到端适应期间与下游任务目标对齐。在膀胱癌和肺腺癌的突变预测任务中，跨机构和TCGA队列进行评估，TAPFM始终优于传统方法，其中H-Optimus-0（TAPFM）超越了基准。TAPFM也能有效处理可操作突变的多标签分类。因此，TAPFM使得在标准硬件上适应强大的预训练PFM以用于各种临床应用变得实用。", "summary": "本文介绍了一种名为TAPFM的创新方法，旨在解决病理基础模型（PFMs）在全玻片图像（WSIs）分析中适应特定临床任务的挑战。该方法利用视觉Transformer（ViT）注意力进行多示例学习（MIL）聚合，并优化特征和注意力权重，同时通过分离计算图确保训练稳定性。TAPFM在膀胱癌和肺腺癌的突变预测任务上表现出卓越性能，超越了现有基准，并能有效处理多标签分类，从而使PFM在标准硬件上的实际应用成为可能。", "keywords": "病理基础模型, 全玻片图像, 任务适应, 多示例学习, 视觉Transformer"}}
{"id": "2506.05035", "pdf": "https://arxiv.org/pdf/2506.05035", "abs": "https://arxiv.org/abs/2506.05035", "authors": ["Hyeongwon Jang", "Changhun Kim", "Eunho Yang"], "title": "TIMING: Temporality-Aware Integrated Gradients for Time Series Explanation", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 Spotlight Presentation; Code is available at\n  https://github.com/drumpt/TIMING", "summary": "Recent explainable artificial intelligence (XAI) methods for time series\nprimarily estimate point-wise attribution magnitudes, while overlooking the\ndirectional impact on predictions, leading to suboptimal identification of\nsignificant points. Our analysis shows that conventional Integrated Gradients\n(IG) effectively capture critical points with both positive and negative\nimpacts on predictions. However, current evaluation metrics fail to assess this\ncapability, as they inadvertently cancel out opposing feature contributions. To\naddress this limitation, we propose novel evaluation metrics-Cumulative\nPrediction Difference (CPD) and Cumulative Prediction Preservation (CPP)-to\nsystematically assess whether attribution methods accurately identify\nsignificant positive and negative points in time series XAI. Under these\nmetrics, conventional IG outperforms recent counterparts. However, directly\napplying IG to time series data may lead to suboptimal outcomes, as generated\npaths ignore temporal relationships and introduce out-of-distribution samples.\nTo overcome these challenges, we introduce TIMING, which enhances IG by\nincorporating temporal awareness while maintaining its theoretical properties.\nExtensive experiments on synthetic and real-world time series benchmarks\ndemonstrate that TIMING outperforms existing time series XAI baselines. Our\ncode is available at https://github.com/drumpt/TIMING.", "AI": {"title_translation": "TIMING：面向时间序列解释的时序感知集成梯度", "tldr": "现有时间序列可解释AI方法和评估指标存在缺陷。本文提出了新的评估指标（CPD、CPP）和一种新的、时序感知的集成梯度方法（TIMING），并在实验中超越了现有基线。", "motivation": "现有的时间序列可解释人工智能（XAI）方法主要估计逐点归因幅度，但忽略了对预测的方向性影响，导致关键点识别不佳。此外，现有评估指标无法有效评估归因方法识别具有正负影响的关键点的能力，因为它们会抵消相反的特征贡献。直接将集成梯度（IG）应用于时间序列数据可能会忽略时间关系并引入分布外样本，从而导致次优结果。", "method": "提出新的评估指标——累积预测差异（CPD）和累积预测保持（CPP），用于系统评估归因方法是否准确识别时间序列XAI中的重要正负点。引入TIMING，通过融入时序感知来增强集成梯度（IG），同时保持其理论特性。", "result": "在提出的新指标下，传统集成梯度（IG）优于最近的同类方法。在合成和真实世界时间序列基准上的大量实验表明，TIMING优于现有时间序列XAI基线。", "conclusion": "TIMING是一种有效的、时序感知的时间序列解释集成梯度方法，解决了现有方法和评估指标的局限性。", "translation": "最近的时间序列可解释人工智能（XAI）方法主要估计逐点归因幅度，但忽略了对预测的方向性影响，导致关键点识别不佳。我们的分析表明，传统集成梯度（IG）能有效捕捉对预测具有正负影响的关键点。然而，当前的评估指标未能评估这种能力，因为它们无意中抵消了相反的特征贡献。为了解决这一限制，我们提出了新颖的评估指标——累积预测差异（CPD）和累积预测保持（CPP），以系统地评估归因方法是否准确识别时间序列XAI中的重要正负点。在这些指标下，传统IG优于最近的同类方法。然而，直接将IG应用于时间序列数据可能导致次优结果，因为生成的路径忽略了时间关系并引入了分布外样本。为了克服这些挑战，我们引入了TIMING，它通过融入时序感知来增强IG，同时保持其理论特性。在合成和真实世界时间序列基准上的大量实验表明，TIMING优于现有时间序列XAI基线。我们的代码可在https://github.com/drumpt/TIMING获取。", "summary": "本文旨在解决当前时间序列可解释人工智能（XAI）方法和评估指标的局限性。为此，论文提出了新的评估指标——累积预测差异（CPD）和累积预测保持（CPP），以系统地评估归因方法识别重要正负点的能力。此外，论文引入了TIMING，这是一种通过融入时序感知来增强集成梯度（IG）的方法，同时保持其理论特性。在合成和真实世界时间序列基准上的广泛实验表明，TIMING优于现有的时间序列XAI基线。", "keywords": "时间序列, 可解释AI, 集成梯度, 时序感知, 评估指标"}}
{"id": "2506.04416", "pdf": "https://arxiv.org/pdf/2506.04416", "abs": "https://arxiv.org/abs/2506.04416", "authors": ["Ziyao Xu", "Yong-Tao Zhang"], "title": "Exponential Time Differencing Runge-Kutta Discontinuous Galerkin (ETD-RKDG) Methods for Nonlinear Degenerate Parabolic Equations", "categories": ["math.NA", "cs.NA"], "comment": "34 pages", "summary": "In this paper, we study high-order exponential time differencing Runge-Kutta\n(ETD-RK) discontinuous Galerkin (DG) methods for nonlinear degenerate parabolic\nequations. This class of equations exhibits hyperbolic behavior in degenerate\nregions and parabolic behavior in non-degenerate regions, resulting in sharp\nwave fronts in the solution profiles and a parabolic-type time-step\nrestriction, $\\tau \\sim O(h^2)$, for explicit time integration. To address\nthese challenges and solve such equations in complex domains, we employ DG\nmethods with appropriate stabilizing limiters on unstructured meshes to capture\nthe wave fronts and use ETD-RK methods for time integration to resolve the\nstiffness of parabolic terms. We extract the system's stiffness using the\nJacobian matrix of the DG discretization for diffusion terms and adopt a nodal\nformulation to facilitate its computation. The algorithm is described in detail\nfor two-dimensional triangular meshes. We also conduct a linear stability\nanalysis in one spatial dimension and present computational results on\nthree-dimensional simplex meshes, demonstrating significant improvements in\nstability and large time-step sizes.", "AI": {"title_translation": "非线性退化抛物方程的指数时间差分龙格-库塔间断伽辽金 (ETD-RKDG) 方法", "tldr": "本文研究了一种用于非线性退化抛物方程的高阶ETD-RKDG方法，该方法通过ETD-RK时间积分和DG空间离散化，解决了此类方程的刚性和时间步限制问题，并在稳定性和时间步长方面取得了显著改进。", "motivation": "非线性退化抛物方程在退化区域表现出双曲行为，在非退化区域表现出抛物行为，导致解剖面出现尖锐波前，并且显式时间积分存在抛物型时间步限制（$\\tau \\sim O(h^2)$）。为了解决这些挑战并在复杂域中求解此类方程，需要开发新的方法。", "method": "本文采用间断伽辽金 (DG) 方法结合适当的稳定限制器，在非结构网格上捕捉波前，并使用指数时间差分龙格-库塔 (ETD-RK) 方法进行时间积分以解决抛物项的刚性。通过扩散项的DG离散化雅可比矩阵提取系统刚度，并采用节点公式简化计算。算法针对二维三角形网格进行了详细描述。", "result": "在三维单纯形网格上的计算结果表明，该方法在稳定性和大时间步长方面有显著改进。", "conclusion": "本文提出的ETD-RKDG方法能够有效解决非线性退化抛物方程的挑战，并在稳定性和时间步长方面表现出优越性。", "translation": "在本文中，我们研究了用于非线性退化抛物方程的高阶指数时间差分龙格-库塔 (ETD-RK) 间断伽辽金 (DG) 方法。这类方程在退化区域表现出双曲行为，在非退化区域表现出抛物行为，导致解剖面中出现尖锐波前，并且对于显式时间积分存在抛物型时间步限制，即 $\\tau \\sim O(h^2)$。为了解决这些挑战并在复杂域中求解此类方程，我们采用带有适当稳定限制器的DG方法在非结构网格上捕捉波前，并使用ETD-RK方法进行时间积分以解决抛物项的刚性。我们利用扩散项的DG离散化的雅可比矩阵提取系统刚度，并采用节点公式以方便其计算。该算法针对二维三角形网格进行了详细描述。我们还在一维空间中进行了线性稳定性分析，并给出了三维单纯形网格上的计算结果，证明了在稳定性和大时间步长方面的显著改进。", "summary": "本文提出了一种高阶指数时间差分龙格-库塔间断伽辽金 (ETD-RKDG) 方法，用于求解非线性退化抛物方程。该方法结合了DG方法在非结构网格上捕捉尖锐波前的能力和ETD-RK方法处理抛物项刚性的优势，有效克服了此类方程的时间步长限制和复杂行为。研究详细描述了算法，并在线性稳定性分析和三维计算结果中展示了该方法在稳定性和时间步长方面的显著提升。", "keywords": "ETD-RKDG方法, 非线性退化抛物方程, 间断伽辽金方法, 指数时间差分龙格-库塔方法, 数值稳定性"}}
{"id": "2506.04592", "pdf": "https://arxiv.org/pdf/2506.04592", "abs": "https://arxiv.org/abs/2506.04592", "authors": ["Chengwu Liu", "Ye Yuan", "Yichun Yin", "Yan Xu", "Xin Xu", "Zaoyu Chen", "Yasheng Wang", "Lifeng Shang", "Qun Liu", "Ming Zhang"], "title": "Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted in ACL 2025", "summary": "Chain-of-Thought (CoT) prompting has become the de facto method to elicit\nreasoning capabilities from large language models (LLMs). However, to mitigate\nhallucinations in CoT that are notoriously difficult to detect, current methods\nsuch as process reward models (PRMs) or self-consistency operate as opaque\nboxes and do not provide checkable evidence for their judgments, possibly\nlimiting their effectiveness. To address this issue, we draw inspiration from\nthe idea that \"the gold standard for supporting a mathematical claim is to\nprovide a proof\". We propose a retrospective, step-aware formal verification\nframework $Safe$. Rather than assigning arbitrary scores, we strive to\narticulate mathematical claims in formal mathematical language Lean 4 at each\nreasoning step and provide formal proofs to identify hallucinations. We\nevaluate our framework $Safe$ across multiple language models and various\nmathematical datasets, demonstrating a significant performance improvement\nwhile offering interpretable and verifiable evidence. We also propose\n$FormalStep$ as a benchmark for step correctness theorem proving with $30,809$\nformal statements. To the best of our knowledge, our work represents the first\nendeavor to utilize formal mathematical language Lean 4 for verifying natural\nlanguage content generated by LLMs, aligning with the reason why formal\nmathematical languages were created in the first place: to provide a robust\nfoundation for hallucination-prone human-written proofs.", "AI": {"title_translation": "Safe：通过回顾性步骤感知形式化验证增强大型语言模型的数学推理能力", "tldr": "Safe框架通过使用Lean 4进行回顾性、步骤感知形式化验证，显著提高了大型语言模型在数学推理方面的性能，并提供了可解释和可验证的证据，从而解决了CoT幻觉问题。", "motivation": "当前链式思考（CoT）提示方法在大型语言模型（LLM）中存在幻觉问题，且难以检测。现有的缓解方法（如过程奖励模型或自洽性）是不透明的，不提供可检查的证据，限制了其有效性。", "method": "提出了一种回顾性、步骤感知形式化验证框架Safe。该框架在每个推理步骤中将数学主张表述为形式化数学语言Lean 4，并提供形式化证明以识别幻觉。还提出了FormalStep作为步骤正确性定理证明的基准。", "result": "Safe框架在多个语言模型和各种数学数据集上表现出显著的性能提升，同时提供了可解释和可验证的证据。提出了包含30,809个形式化语句的FormalStep基准。", "conclusion": "本工作是首次利用形式化数学语言Lean 4来验证大型语言模型生成的自然语言内容，旨在为容易出现幻觉的人工证明提供一个稳固的基础。", "translation": "链式思考（CoT）提示已成为引发大型语言模型（LLM）推理能力的事实标准方法。然而，为了减轻CoT中臭名昭著的难以检测的幻觉，当前的方法，如过程奖励模型（PRM）或自洽性，作为不透明的黑箱运行，不提供可检查的证据来支持其判断，这可能会限制其有效性。为了解决这个问题，我们从“支持数学主张的黄金标准是提供证明”的思想中汲取灵感。我们提出了一种回顾性、步骤感知形式化验证框架Safe。我们不是分配任意分数，而是努力在每个推理步骤中用形式化数学语言Lean 4阐明数学主张，并提供形式化证明来识别幻觉。我们在多个语言模型和各种数学数据集上评估了我们的框架Safe，展示了显著的性能改进，同时提供了可解释和可验证的证据。我们还提出了FormalStep作为步骤正确性定理证明的基准，其中包含30,809个形式化语句。据我们所知，我们的工作代表了首次尝试利用形式化数学语言Lean 4来验证LLM生成的自然语言内容，这与形式化数学语言最初创建的原因相符：为容易出现幻觉的人工证明提供一个稳固的基础。", "summary": "本研究提出了Safe框架，一个回顾性、步骤感知形式化验证方法，旨在解决大型语言模型链式思考（CoT）中难以检测的幻觉问题。与现有不透明的方法不同，Safe利用形式化数学语言Lean 4在每个推理步骤中验证数学主张，通过提供形式化证明来识别幻觉。实验结果表明，Safe在多个数学数据集上显著提升了LLM的性能，并提供了可解释和可验证的证据。此外，本研究还引入了FormalStep基准，用于步骤正确性定理证明。这项工作首次尝试使用Lean 4验证LLM生成的自然语言内容，为提高LLM数学推理的可靠性提供了新途径。", "keywords": "大型语言模型, 数学推理, 形式化验证, Lean 4, 链式思考, 幻觉"}}
{"id": "2506.05191", "pdf": "https://arxiv.org/pdf/2506.05191", "abs": "https://arxiv.org/abs/2506.05191", "authors": ["Yake Wei", "Yu Miao", "Dongzhan Zhou", "Di Hu"], "title": "MokA: Multimodal Low-Rank Adaptation for MLLMs", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we reveal that most current efficient multimodal fine-tuning\nmethods are hindered by a key limitation: they are directly borrowed from LLMs,\noften neglecting the intrinsic differences of multimodal scenarios and even\naffecting the full utilization of all modalities. Inspired by our empirical\nobservation, we argue that unimodal adaptation and cross-modal adaptation are\ntwo essential parts for the effective fine-tuning of MLLMs. From this\nperspective, we propose Multimodal low-rank Adaptation (MokA), a\nmultimodal-aware efficient fine-tuning strategy that takes multimodal\ncharacteristics into consideration. It compresses unimodal information by\nmodality-specific parameters while explicitly enhancing cross-modal\ninteraction, ensuring both unimodal and cross-modal adaptation. Extensive\nexperiments cover three representative multimodal scenarios (audio-visual-text,\nvisual-text, and speech-text), and multiple LLM backbones (LLaMA2/3, Qwen2,\nQwen2.5-VL, etc). Consistent improvements indicate the efficacy and versatility\nof the proposed method. Ablation studies and efficiency evaluation are also\nconducted to fully asses our method. Overall, we think MokA provides a more\ntargeted solution for efficient adaptation of MLLMs, paving the way for further\nexploration. The project page is at https://gewu-lab.github.io/MokA.", "AI": {"title_translation": "MokA: 多模态低秩适应用于多模态大型语言模型", "tldr": "本文提出MokA，一种多模态低秩适应方法，通过同时考虑单模态和跨模态适应，有效微调多模态大型语言模型（MLLMs），解决了现有方法忽略多模态特性的问题。", "motivation": "当前高效的多模态微调方法直接借用自大型语言模型（LLMs），忽视了多模态场景的内在差异，甚至影响了所有模态的充分利用。", "method": "提出多模态低秩适应（MokA），这是一种多模态感知的SFT策略。它通过模态特定参数压缩单模态信息，同时明确增强跨模态交互，确保单模态和跨模态适应。", "result": "在三种代表性多模态场景（音视频-文本、视觉-文本和语音-文本）和多个LLM骨干（LLaMA2/3、Qwen2、Qwen2.5-VL等）上的广泛实验表明，所提出的方法具有有效性和通用性。消融研究和效率评估也充分验证了该方法。", "conclusion": "MokA为多模态大型语言模型（MLLMs）的有效适应提供了一个更具针对性的解决方案，为进一步探索铺平了道路。", "translation": "在本文中，我们揭示了当前大多数高效的多模态微调方法都受到一个关键限制的阻碍：它们直接借用自大型语言模型（LLMs），常常忽视多模态场景的内在差异，甚至影响所有模态的充分利用。受我们的经验观察启发，我们认为单模态适应和跨模态适应是多模态大型语言模型（MLLMs）有效微调的两个基本组成部分。从这个角度出发，我们提出了多模态低秩适应（MokA），这是一种考虑多模态特征的多模态感知高效微调策略。它通过模态特定参数压缩单模态信息，同时明确增强跨模态交互，确保单模态和跨模态适应。广泛的实验涵盖了三种代表性多模态场景（音视频-文本、视觉-文本和语音-文本），以及多个LLM骨干（LLaMA2/3、Qwen2、Qwen2.5-VL等）。持续的改进表明了所提出方法的有效性和通用性。还进行了消融研究和效率评估，以充分评估我们的方法。总的来说，我们认为MokA为MLLMs的有效适应提供了一个更具针对性的解决方案，为进一步探索铺平了道路。项目页面位于https://gewu-lab.github.io/MokA。", "summary": "本文提出了一种名为MokA的多模态低秩适应方法，旨在解决现有高效多模态微调方法直接沿用LLM策略，忽略多模态特性导致性能受限的问题。MokA通过模态特定参数压缩单模态信息并增强跨模态交互，实现了单模态和跨模态的有效适应。实验结果验证了MokA在多种多模态场景和LLM骨干上的有效性和通用性。", "keywords": "多模态低秩适应, MLLMs, 高效微调, 单模态适应, 跨模态交互"}}
{"id": "2506.05039", "pdf": "https://arxiv.org/pdf/2506.05039", "abs": "https://arxiv.org/abs/2506.05039", "authors": ["Nicolas Lell", "Ansgar Scherp"], "title": "iN2V: Bringing Transductive Node Embeddings to Inductive Graphs", "categories": ["cs.LG"], "comment": null, "summary": "Shallow node embeddings like node2vec (N2V) can be used for nodes without\nfeatures or to supplement existing features with structure-based information.\nEmbedding methods like N2V are limited in their application on new nodes, which\nrestricts them to the transductive setting where the entire graph, including\nthe test nodes, is available during training. We propose inductive node2vec\n(iN2V), which combines a post-hoc procedure to compute embeddings for nodes\nunseen during training and modifications to the original N2V training procedure\nto prepare the embeddings for this post-hoc procedure. We conduct experiments\non several benchmark datasets and demonstrate that iN2V is an effective\napproach to bringing transductive embeddings to an inductive setting. Using\niN2V embeddings improves node classification by 1 point on average, with up to\n6 points of improvement depending on the dataset and the number of unseen\nnodes. Our iN2V is a plug-in approach to create new or enrich existing\nembeddings. It can also be combined with other embedding methods, making it a\nversatile approach for inductive node representation learning. Code to\nreproduce the results is available at https://github.com/Foisunt/iN2V .", "AI": {"title_translation": "iN2V：将转导节点嵌入引入归纳图", "tldr": "iN2V将转导节点嵌入方法（如node2vec）扩展到归纳设置，使其能够处理新节点并提高节点分类性能。", "motivation": "现有的浅层节点嵌入方法（如node2vec, N2V）在处理新节点时存在局限性，限制了它们在归纳设置中的应用，因为它们要求在训练期间整个图（包括测试节点）都可用。", "method": "本文提出了归纳node2vec (iN2V)，它结合了一个后处理程序来计算训练期间未见节点的嵌入，并修改了原始N2V的训练过程，以准备这些嵌入用于后处理程序。", "result": "iN2V是将转导嵌入引入归纳设置的有效方法。使用iN2V嵌入将节点分类平均提高了1点，根据数据集和未见节点的数量，最高可提高6点。iN2V是一种插件式方法，可用于创建新嵌入或丰富现有嵌入，并且可以与其他嵌入方法结合使用。", "conclusion": "iN2V成功地将转导节点嵌入引入了归纳图设置，解决了现有方法在处理新节点时的局限性，并显著提高了节点分类性能，同时具有良好的通用性。", "translation": "浅层节点嵌入，如node2vec (N2V)，可用于没有特征的节点，或用基于结构的信息补充现有特征。然而，像N2V这样的嵌入方法在应用于新节点时受到限制，这使得它们仅限于转导设置，即在训练期间需要提供整个图，包括测试节点。我们提出了归纳node2vec (iN2V)，它结合了一个后处理程序来计算训练期间未见节点的嵌入，并对原始N2V训练过程进行了修改，以准备这些嵌入用于此后处理程序。我们在几个基准数据集上进行了实验，并证明iN2V是将转导嵌入引入归纳设置的有效方法。使用iN2V嵌入平均可将节点分类提高1点，根据数据集和未见节点的数量，最高可提高6点。我们的iN2V是一种插件式方法，可用于创建新嵌入或丰富现有嵌入。它还可以与其他嵌入方法结合使用，使其成为归纳节点表示学习的一种多功能方法。重现结果的代码可在https://github.com/Foisunt/iN2V获取。", "summary": "本文提出了一种名为iN2V的新方法，旨在将传统的转导节点嵌入（如node2vec）扩展到归纳图设置中，使其能够处理训练期间未见的新节点。iN2V通过结合一个后处理程序和对原始node2vec训练过程的修改来实现这一点。实验结果表明，iN2V在节点分类任务上表现出色，平均可提高1个百分点，最高可达6个百分点，证明了其在归纳节点表示学习中的有效性和多功能性。", "keywords": "节点嵌入, 归纳图, 转导学习, node2vec, 节点分类"}}
{"id": "2506.05195", "pdf": "https://arxiv.org/pdf/2506.05195", "abs": "https://arxiv.org/abs/2506.05195", "authors": ["Josue Marroquin", "Nan Inzali", "Miles Dillon Lantz", "Campbell Freeman", "Amod Ashtekar", "\\\\Ajinkya Umesh Mulik", "Mohammed E Eltayeb"], "title": "Vision-Based Autonomous MM-Wave Reflector Using ArUco-Driven Angle-of-Arrival Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Reliable millimeter-wave (mmWave) communication in non-line-of-sight (NLoS)\nconditions remains a major challenge for both military and civilian operations,\nespecially in urban or infrastructure-limited environments. This paper presents\na vision-aided autonomous reflector system designed to enhance mmWave link\nperformance by dynamically steering signal reflections using a motorized\nmetallic plate. The proposed system leverages a monocular camera to detect\nArUco markers on allied transmitter and receiver nodes, estimate their angles\nof arrival, and align the reflector in real time for optimal signal\nredirection. This approach enables selective beam coverage by serving only\nauthenticated targets with visible markers and reduces the risk of unintended\nsignal exposure. The designed prototype, built on a Raspberry Pi 4 and\nlow-power hardware, operates autonomously without reliance on external\ninfrastructure or GPS. Experimental results at 60\\,GHz demonstrate a 23\\,dB\naverage gain in received signal strength and an 0.89 probability of maintaining\nsignal reception above a target threshold of -65 dB in an indoor environment,\nfar exceeding the static and no-reflector baselines. These results demonstrate\nthe system's potential for resilient and adaptive mmWave connectivity in\ncomplex and dynamic environments.", "AI": {"title_translation": "基于视觉的自主毫米波反射器：利用ArUco驱动的到达角估计", "tldr": "本文提出了一种基于视觉的自主毫米波反射器系统，通过ArUco标记和摄像头实时调整反射器方向，显著提升了非视距毫米波通信的信号强度和可靠性。", "motivation": "在城市或基础设施受限的环境中，非视距（NLoS）条件下的可靠毫米波（mmWave）通信是军事和民用操作面临的重大挑战。", "method": "该系统利用单目摄像头检测友方发射器和接收器节点上的ArUco标记，估计它们的到达角，并实时调整电动金属板反射器以实现最佳信号重定向。该原型基于Raspberry Pi 4和低功耗硬件构建，可自主运行，不依赖外部基础设施或GPS。", "result": "在60 GHz的实验结果表明，接收信号强度平均增益达到23 dB，在室内环境中，信号接收保持在-65 dB目标阈值以上的概率为0.89，远超静态和无反射器基线。", "conclusion": "这些结果证明了该系统在复杂动态环境中实现弹性自适应毫米波连接的潜力。", "translation": "可靠的毫米波（mmWave）通信在非视距（NLoS）条件下仍然是军事和民用操作的主要挑战，尤其是在城市或基础设施受限的环境中。本文提出了一种视觉辅助的自主反射器系统，旨在通过使用电动金属板动态引导信号反射来增强毫米波链路性能。所提出的系统利用单目摄像头检测友方发射器和接收器节点上的ArUco标记，估计它们的到达角，并实时调整反射器以实现最佳信号重定向。这种方法通过仅为带有可见标记的经过认证的目标提供选择性波束覆盖，并降低了意外信号暴露的风险。设计的原型基于Raspberry Pi 4和低功耗硬件构建，可自主运行，不依赖外部基础设施或GPS。在60 GHz的实验结果表明，接收信号强度平均增益达到23 dB，在室内环境中，信号接收保持在-65 dB目标阈值以上的概率为0.89，远超静态和无反射器基线。这些结果证明了该系统在复杂动态环境中实现弹性自适应毫米波连接的潜力。", "summary": "本文提出了一种创新的基于视觉的自主毫米波反射器系统，旨在解决非视距毫米波通信的挑战。该系统利用单目摄像头识别ArUco标记，实时估计信号到达角，并精确调整电动反射器，以优化信号重定向。实验证明，该系统在60 GHz下实现了显著的信号增益和高可靠性，显示了其在复杂环境中提供弹性毫米波连接的巨大潜力。", "keywords": "毫米波通信, 反射器, ArUco标记, 视觉辅助, 非视距"}}
{"id": "2506.05047", "pdf": "https://arxiv.org/pdf/2506.05047", "abs": "https://arxiv.org/abs/2506.05047", "authors": ["Viet Nguyen Changjian Shui", "Vijay Giri", "Siddarth Arya", "Amol Verma", "Fahad Razak", "Rahul G. Krishnan"], "title": "Reliably detecting model failures in deployment without labels", "categories": ["cs.LG"], "comment": "36 pages, 6 figures, 7 tables, submitted to NeurIPS 2025, includes\n  theoretical analysis and extensive empirical evaluation across benchmark and\n  clinical datasets. Code available at https://github.com/teivng/d3m. Viet\n  Nguyen and Changjian Shui contributed equally", "summary": "The distribution of data changes over time; models operating operating in\ndynamic environments need retraining. But knowing when to retrain, without\naccess to labels, is an open challenge since some, but not all shifts degrade\nmodel performance. This paper formalizes and addresses the problem of\npost-deployment deterioration (PDD) monitoring. We propose D3M, a practical and\nefficient monitoring algorithm based on the disagreement of predictive models,\nachieving low false positive rates under non-deteriorating shifts and provides\nsample complexity bounds for high true positive rates under deteriorating\nshifts. Empirical results on both standard benchmark and a real-world\nlarge-scale internal medicine dataset demonstrate the effectiveness of the\nframework and highlight its viability as an alert mechanism for high-stakes\nmachine learning pipelines.", "AI": {"title_translation": "在没有标签的情况下可靠地检测部署中的模型故障", "tldr": "本文提出D3M算法，通过预测模型的不一致性，在无标签情况下有效监控模型部署后的性能下降（PDD），实现低误报率和高真报率，并已在基准数据集和真实世界医学数据集中得到验证。", "motivation": "数据分布随时间变化，动态环境中的模型需要再训练。然而，在无法获得标签的情况下，如何判断何时进行再训练是一个开放的挑战，因为并非所有的数据漂移都会导致模型性能下降。", "method": "本文提出了一种基于预测模型不一致性的实用高效监控算法D3M，用于解决部署后性能下降（PDD）监控问题。", "result": "D3M在非性能下降的数据漂移下实现了低误报率，并在性能下降的数据漂移下提供了高真报率的样本复杂度界限。在标准基准数据集和真实世界大规模内科医学数据集上的实证结果都证明了该框架的有效性，并强调了其作为高风险机器学习管道预警机制的可行性。", "conclusion": "D3M算法能够可靠地检测部署中模型的性能下降，即使在没有标签的情况下也能作为高风险机器学习管道的有效预警机制。", "translation": "数据分布随时间变化；在动态环境中运行的模型需要再训练。但是，在没有标签的情况下，如何知道何时进行再训练是一个开放的挑战，因为有些（但并非所有）数据漂移会降低模型性能。本文将部署后性能下降（PDD）监控问题形式化并加以解决。我们提出了D3M，一种基于预测模型不一致性的实用高效监控算法，在非性能下降的数据漂移下实现了低误报率，并在性能下降的数据漂移下提供了高真报率的样本复杂度界限。在标准基准数据集和真实世界大规模内科医学数据集上的实证结果都证明了该框架的有效性，并强调了其作为高风险机器学习管道预警机制的可行性。", "summary": "本文针对部署后模型性能下降（PDD）监控的开放性挑战，提出了一种名为D3M的实用高效算法。D3M通过利用预测模型之间的不一致性，在无标签情况下实现对模型性能下降的可靠检测，其在非性能下降的数据漂移下具有低误报率，在性能下降的数据漂移下具有高真报率。实验证明，D3M在基准数据集和真实世界医学数据集上均表现出色，证明了其作为高风险机器学习系统预警机制的有效性。", "keywords": "模型故障检测, 数据漂移, 无标签监控, D3M, 性能下降"}}
{"id": "2506.05198", "pdf": "https://arxiv.org/pdf/2506.05198", "abs": "https://arxiv.org/abs/2506.05198", "authors": ["Yuxin Wen", "Yangsibo Huang", "Tom Goldstein", "Ravi Kumar", "Badih Ghazi", "Chiyuan Zhang"], "title": "Quantifying Cross-Modality Memorization in Vision-Language Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Understanding what and how neural networks memorize during training is\ncrucial, both from the perspective of unintentional memorization of potentially\nsensitive information and from the standpoint of effective knowledge\nacquisition for real-world, knowledge-intensive tasks. While previous studies\nprimarily investigate memorization within a single modality, such as text\nmemorization in large language models or image memorization in diffusion\nmodels, unified multimodal models are becoming increasingly prevalent in\npractical applications. In this work, we focus on the unique characteristics of\ncross-modality memorization and conduct a systematic study centered on\nvision-language models. To facilitate controlled experiments, we first\nintroduce a synthetic persona dataset comprising diverse synthetic person\nimages and textual descriptions. We quantify factual knowledge memorization and\ncross-modal transferability by training models on a single modality and\nevaluating their performance in the other. Our results reveal that facts\nlearned in one modality transfer to the other, but a significant gap exists\nbetween recalling information in the source and target modalities. Furthermore,\nwe observe that this gap exists across various scenarios, including more\ncapable models, machine unlearning, and the multi-hop case. At the end, we\npropose a baseline method to mitigate this challenge. We hope our study can\ninspire future research on developing more robust multimodal learning\ntechniques to enhance cross-modal transferability.", "AI": {"title_translation": "视觉-语言模型中跨模态记忆的量化", "tldr": "研究视觉-语言模型中的跨模态记忆，发现信息在模态间可迁移但存在显著差距，并提出缓解方法。", "motivation": "了解神经网络的记忆机制对于敏感信息保护和有效知识获取至关重要。现有研究主要关注单模态记忆，但统一的多模态模型日益普及，因此需要系统研究视觉-语言模型中独特的跨模态记忆特性。", "method": "引入了一个包含多样化合成人物图像和文本描述的合成人物数据集，以进行受控实验。通过在单一模态上训练模型并在另一模态上评估其性能，量化事实知识记忆和跨模态可迁移性。", "result": "结果显示，在一个模态中学到的事实可以迁移到另一个模态，但在源模态和目标模态之间回忆信息存在显著差距。这种差距在各种场景中都存在，包括更强大的模型、机器遗忘和多跳情况。", "conclusion": "本研究系统揭示了视觉-语言模型中跨模态记忆的特点和挑战，发现知识在模态间可迁移但存在显著记忆差距。研究提出了一种缓解该挑战的基线方法，旨在启发未来研究开发更鲁棒的多模态学习技术，以增强跨模态可迁移性。", "translation": "理解神经网络在训练过程中记忆了什么以及如何记忆，无论是从无意中记忆潜在敏感信息的角度，还是从有效获取现实世界知识密集型任务知识的角度来看，都至关重要。虽然之前的研究主要调查单一模态内的记忆，例如大型语言模型中的文本记忆或扩散模型中的图像记忆，但统一的多模态模型在实际应用中变得越来越普遍。在这项工作中，我们专注于跨模态记忆的独特特性，并对视觉-语言模型进行了系统研究。为了促进受控实验，我们首先引入了一个包含多样化合成人物图像和文本描述的合成人物数据集。我们通过在单一模态上训练模型并在另一模态上评估其性能来量化事实知识记忆和跨模态可迁移性。我们的结果表明，在一个模态中学到的事实可以迁移到另一个模态，但在源模态和目标模态之间回忆信息存在显著差距。此外，我们观察到这种差距存在于各种场景中，包括更强大的模型、机器遗忘和多跳情况。最后，我们提出了一种缓解这一挑战的基线方法。我们希望我们的研究能够启发未来关于开发更鲁棒的多模态学习技术以增强跨模态可迁移性的研究。", "summary": "本文系统研究了视觉-语言模型中的跨模态记忆，引入合成数据集进行受控实验，以量化事实知识记忆和跨模态可迁移性。研究发现，虽然知识可以在模态间迁移，但源模态和目标模态之间存在显著的记忆差距，且该差距在多种场景下普遍存在。研究提出了一种缓解该挑战的基线方法，旨在推动更鲁棒的多模态学习技术发展。", "keywords": "跨模态记忆, 视觉-语言模型, 知识迁移, 记忆差距, 合成数据集"}}
{"id": "2506.05059", "pdf": "https://arxiv.org/pdf/2506.05059", "abs": "https://arxiv.org/abs/2506.05059", "authors": ["Shijian Xu", "Marcello Massimo Negri", "Volker Roth"], "title": "NIMO: a Nonlinear Interpretable MOdel", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Neural networks (NNs) have achieved tremendous success over the past decade,\nyet they are still extremely difficult to interpret. In contrast, linear models\nare less expressive but offer inherent interpretability. Linear coefficients\nare interpretable as the marginal effect of a feature on the prediction,\nassuming all other features are kept fixed. To combine the benefits of both\napproaches, we introduce NIMO (Nonlinear Interpretable MOdel). The key idea is\nto define a model where the NN is designed to learn nonlinear corrections to\nthe linear model predictions, while also maintaining the original\ninterpretability of the linear coefficients. Relevantly, we develop an\noptimization algorithm based on profile likelihood that elegantly allows for\noptimizing over the NN parameters while updating the linear coefficients\nanalytically. By relying on adaptive ridge regression we can easily incorporate\nsparsity constraints as well. We show empirically that we can recover the\nunderlying linear coefficients while significantly improving the predictive\naccuracy. Compared to other hybrid interpretable approaches, our model is the\nonly one that actually maintains the same interpretability of linear\ncoefficients as in linear models. We also achieve higher performance on various\nregression and classification settings.", "AI": {"title_translation": "NIMO：一种非线性可解释模型", "tldr": "NIMO结合了神经网络的表达能力和线性模型的可解释性，通过让神经网络学习对线性模型预测的非线性修正，同时保持线性系数的可解释性，实现了更高的预测精度。", "motivation": "神经网络虽然取得了巨大成功，但难以解释。线性模型虽然可解释但表达能力不足。本研究旨在结合两者的优点，构建一个既有非线性表达能力又可解释的模型。", "method": "NIMO（非线性可解释模型）的核心思想是设计一个神经网络来学习对线性模型预测的非线性修正，同时保持线性系数的原始可解释性。开发了一种基于剖面似然的优化算法，可以优化神经网络参数并解析地更新线性系数。通过自适应岭回归，可以轻松地加入稀疏性约束。", "result": "经验表明，NIMO能够恢复底层线性系数，同时显著提高预测精度。与其他混合可解释方法相比，NIMO是唯一一个能像线性模型一样保持线性系数可解释性的模型。在各种回归和分类设置中也取得了更高的性能。", "conclusion": "NIMO成功地结合了神经网络的强大预测能力和线性模型的固有可解释性，提供了一种在保持线性系数可解释性的同时，显著提高预测准确性的方法，并在多个任务中表现优异。", "translation": "NIMO：一种非线性可解释模型\n\n神经网络（NNs）在过去十年中取得了巨大的成功，但它们仍然极其难以解释。相比之下，线性模型表达能力较弱但提供了固有的可解释性。线性系数可以解释为在所有其他特征保持不变的情况下，某一特征对预测的边际效应。为了结合这两种方法的优点，我们引入了NIMO（非线性可解释模型）。其关键思想是定义一个模型，其中神经网络被设计为学习对线性模型预测的非线性修正，同时保持线性系数的原始可解释性。相应地，我们开发了一种基于剖面似然的优化算法，该算法能够优雅地优化神经网络参数，同时解析地更新线性系数。通过依赖自适应岭回归，我们也可以轻松地加入稀疏性约束。我们经验性地表明，我们能够恢复底层的线性系数，同时显著提高预测精度。与其他混合可解释方法相比，我们的模型是唯一一个实际保持与线性模型中相同的线性系数可解释性的模型。我们还在各种回归和分类设置中取得了更高的性能。", "summary": "NIMO（非线性可解释模型）旨在弥合神经网络的表达能力与线性模型的可解释性之间的差距。它通过让神经网络学习线性预测的非线性修正，同时保持线性系数的原始可解释性。该模型采用基于剖面似然的优化算法和自适应岭回归。实验证明，NIMO不仅能恢复底层线性系数，显著提高预测精度，而且是唯一能像线性模型一样保持线性系数可解释性的混合可解释方法，并在回归和分类任务中表现出更高的性能。", "keywords": "非线性可解释模型, 神经网络, 线性模型, 可解释性, 预测精度"}}
{"id": "2506.04624", "pdf": "https://arxiv.org/pdf/2506.04624", "abs": "https://arxiv.org/abs/2506.04624", "authors": ["Takashi Wada", "Yuki Hirakawa", "Ryotaro Shimizu", "Takahiro Kawashima", "Yuki Saito"], "title": "Static Word Embeddings for Sentence Semantic Representation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "15 pages", "summary": "We propose new static word embeddings optimised for sentence semantic\nrepresentation. We first extract word embeddings from a pre-trained Sentence\nTransformer, and improve them with sentence-level principal component analysis,\nfollowed by either knowledge distillation or contrastive learning. During\ninference, we represent sentences by simply averaging word embeddings, which\nrequires little computational cost. We evaluate models on both monolingual and\ncross-lingual tasks and show that our model substantially outperforms existing\nstatic models on sentence semantic tasks, and even rivals a basic Sentence\nTransformer model (SimCSE) on some data sets. Lastly, we perform a variety of\nanalyses and show that our method successfully removes word embedding\ncomponents that are irrelevant to sentence semantics, and adjusts the vector\nnorms based on the influence of words on sentence semantics.", "AI": {"title_translation": "静态词嵌入用于句子语义表示", "tldr": "提出一种新的静态词嵌入方法，通过PCA和知识蒸馏/对比学习优化，在句子语义任务上表现优异，计算成本低。", "motivation": "现有方法在句子语义表示方面可能存在不足或计算成本较高。本文旨在优化静态词嵌入以更好地表示句子语义，并降低计算成本。", "method": "从预训练的Sentence Transformer中提取词嵌入，然后通过句子级主成分分析（PCA）进行改进，接着使用知识蒸馏或对比学习进行优化。推理时，通过简单平均词嵌入来表示句子。", "result": "该模型在单语和跨语言任务上显著优于现有静态模型，甚至在某些数据集上与基本的Sentence Transformer模型（SimCSE）相当。分析表明该方法成功地移除了与句子语义无关的词嵌入成分，并根据词对句子语义的影响调整了向量范数。", "conclusion": "本文提出了一种有效的静态词嵌入优化方法，能够在低计算成本下实现高性能的句子语义表示，并通过分析验证了其有效性。", "translation": "我们提出了一种新的静态词嵌入方法，该方法针对句子语义表示进行了优化。我们首先从预训练的Sentence Transformer中提取词嵌入，并通过句子级主成分分析对其进行改进，然后采用知识蒸馏或对比学习。在推理过程中，我们通过简单地平均词嵌入来表示句子，这所需的计算成本很低。我们在单语和跨语言任务上评估了模型，结果表明我们的模型在句子语义任务上大大优于现有静态模型，甚至在某些数据集上可以与基本的Sentence Transformer模型（SimCSE）相媲美。最后，我们进行了各种分析，结果表明我们的方法成功地移除了与句子语义无关的词嵌入成分，并根据词对句子语义的影响调整了向量范数。", "summary": "本文提出了一种优化静态词嵌入的新方法，旨在高效地表示句子语义。该方法首先从预训练的Sentence Transformer中提取词嵌入，然后结合句子级主成分分析以及知识蒸馏或对比学习进行改进。实验结果表明，该模型在单语和跨语言句子语义任务上显著优于现有静态模型，并且在某些数据集上可与基础的Sentence Transformer模型（如SimCSE）媲美。此外，分析显示该方法能有效去除与句子语义无关的成分，并根据词的影响调整向量范数，从而以较低的计算成本实现高性能的句子语义表示。", "keywords": "静态词嵌入, 句子语义表示, 主成分分析, 知识蒸馏, 对比学习"}}
{"id": "2506.05199", "pdf": "https://arxiv.org/pdf/2506.05199", "abs": "https://arxiv.org/abs/2506.05199", "authors": ["Yani Zhang", "Dongming Wu", "Hao Shi", "Yingfei Liu", "Tiancai Wang", "Haoqiang Fan", "Xingping Dong"], "title": "Grounding Beyond Detection: Enhancing Contextual Understanding in Embodied 3D Grounding", "categories": ["cs.CV"], "comment": "1st place on embodiedscan", "summary": "Embodied 3D grounding aims to localize target objects described in human\ninstructions from ego-centric viewpoint. Most methods typically follow a\ntwo-stage paradigm where a trained 3D detector's optimized backbone parameters\nare used to initialize a grounding model. In this study, we explore a\nfundamental question: Does embodied 3D grounding benefit enough from detection?\nTo answer this question, we assess the grounding performance of detection\nmodels using predicted boxes filtered by the target category. Surprisingly,\nthese detection models without any instruction-specific training outperform the\ngrounding models explicitly trained with language instructions. This indicates\nthat even category-level embodied 3D grounding may not be well resolved, let\nalone more fine-grained context-aware grounding. Motivated by this finding, we\npropose DEGround, which shares DETR queries as object representation for both\nDEtection and Grounding and enables the grounding to benefit from basic\ncategory classification and box detection. Based on this framework, we further\nintroduce a regional activation grounding module that highlights\ninstruction-related regions and a query-wise modulation module that\nincorporates sentence-level semantic into the query representation,\nstrengthening the context-aware understanding of language instructions.\nRemarkably, DEGround outperforms state-of-the-art model BIP3D by 7.52\\% at\noverall accuracy on the EmbodiedScan validation set. The source code will be\npublicly available at https://github.com/zyn213/DEGround.", "AI": {"title_translation": "超越检测的定位：增强具身3D定位中的上下文理解", "tldr": "本文发现检测模型在具身3D定位中表现出人意料地优于语言训练的定位模型，并提出了DEGround框架，通过更好地整合检测和上下文理解，显著提升了具身3D定位性能。", "motivation": "研究动机源于对“具身3D定位是否充分受益于检测？”这一基本问题的探讨。令人惊讶的发现是，未经指令特定训练的检测模型竟然优于明确使用语言指令训练的定位模型，这表明即使是类别级别的具身3D定位也未得到很好的解决，从而促使提出新的方法。", "method": "本文提出了DEGround方法，该方法共享DETR查询作为检测和定位的对象表示，使定位能够受益于基本的类别分类和边界框检测。在此框架基础上，进一步引入了区域激活定位模块以突出指令相关区域，以及查询级调制模块以将句子级语义融入查询表示，从而增强对语言指令的上下文感知理解。", "result": "DEGround在EmbodiedScan验证集上的整体准确率方面，超越了最先进的模型BIP3D 7.52%。", "conclusion": "本文得出结论，目前的具身3D定位方法可能未能充分利用检测能力，并且通过整合检测和增强上下文理解（如DEGround所做），可以显著提高定位性能，甚至对于更细粒度的上下文感知定位也是如此。", "translation": "具身3D定位旨在从自我中心视角定位人类指令中描述的目标物体。大多数方法通常遵循两阶段范式，其中训练好的3D检测器的优化骨干参数用于初始化定位模型。在本研究中，我们探讨了一个基本问题：具身3D定位是否充分受益于检测？为了回答这个问题，我们评估了检测模型使用按目标类别过滤的预测框的定位性能。令人惊讶的是，这些未经任何指令特定训练的检测模型，其性能优于明确使用语言指令训练的定位模型。这表明即使是类别级别的具身3D定位也可能没有得到很好的解决，更不用说更细粒度的上下文感知定位了。受此发现的启发，我们提出了DEGround，它共享DETR查询作为检测和定位的对象表示，并使定位能够受益于基本的类别分类和边界框检测。基于此框架，我们进一步引入了一个区域激活定位模块，用于突出指令相关区域，以及一个查询级调制模块，将句子级语义融入查询表示中，从而增强对语言指令的上下文感知理解。值得注意的是，DEGround在EmbodiedScan验证集上的整体准确率方面，超越了最先进的模型BIP3D 7.52%。源代码将公开在https://github.com/zyn213/DEGround。", "summary": "本文探讨了具身3D定位中检测的充分性问题，发现未经语言指令训练的检测模型性能出人意料地优于专门训练的定位模型。受此启发，论文提出了DEGround框架，该框架通过共享DETR查询并引入区域激活和查询调制模块，显著提升了模型对语言指令的上下文理解能力，并在EmbodiedScan验证集上超越了现有最佳模型。", "keywords": "具身3D定位, 上下文理解, 目标检测, DETR, 语言指令"}}
{"id": "2506.05065", "pdf": "https://arxiv.org/pdf/2506.05065", "abs": "https://arxiv.org/abs/2506.05065", "authors": ["Marten Lienen", "Abdullah Saydemir", "Stephan Günnemann"], "title": "UnHiPPO: Uncertainty-aware Initialization for State Space Models", "categories": ["cs.LG", "stat.ML"], "comment": "Published at ICML 2025", "summary": "State space models are emerging as a dominant model class for sequence\nproblems with many relying on the HiPPO framework to initialize their dynamics.\nHowever, HiPPO fundamentally assumes data to be noise-free; an assumption often\nviolated in practice. We extend the HiPPO theory with measurement noise and\nderive an uncertainty-aware initialization for state space model dynamics. In\nour analysis, we interpret HiPPO as a linear stochastic control problem where\nthe data enters as a noise-free control signal. We then reformulate the problem\nso that the data become noisy outputs of a latent system and arrive at an\nalternative dynamics initialization that infers the posterior of this latent\nsystem from the data without increasing runtime. Our experiments show that our\ninitialization improves the resistance of state-space models to noise both at\ntraining and inference time. Find our implementation at\nhttps://cs.cit.tum.de/daml/unhippo.", "AI": {"title_translation": "UnHiPPO: 状态空间模型的不确定性感知初始化", "tldr": "本文提出了一种名为UnHiPPO的不确定性感知初始化方法，改进了状态空间模型在噪声数据下的性能。", "motivation": "现有的HiPPO框架在初始化状态空间模型时，假设数据是无噪声的，这在实际应用中往往不成立，导致模型对噪声的鲁棒性不足。", "method": "作者通过引入测量噪声扩展了HiPPO理论，并将HiPPO解释为线性随机控制问题。然后，他们将问题重新表述为数据是潜在系统的噪声输出，并推导了一种新的动态初始化方法，该方法能够在不增加运行时间的情况下，从数据中推断出潜在系统的后验信息。", "result": "实验结果表明，作者提出的初始化方法显著提高了状态空间模型在训练和推理时对噪声的抵抗能力。", "conclusion": "UnHiPPO通过引入不确定性感知初始化，有效提升了状态空间模型在存在噪声数据时的鲁棒性。", "translation": "状态空间模型正成为序列问题的主导模型类别，其中许多模型依赖于HiPPO框架来初始化其动态。然而，HiPPO从根本上假设数据是无噪声的；这一假设在实践中经常被违反。我们通过测量噪声扩展了HiPPO理论，并为状态空间模型的动态推导了一种不确定性感知初始化方法。在我们的分析中，我们将HiPPO解释为一个线性随机控制问题，其中数据作为无噪声控制信号输入。然后，我们重新表述了该问题，使得数据成为一个潜在系统的噪声输出，并得到了一种替代的动态初始化方法，该方法可以在不增加运行时间的情况下，从数据中推断出该潜在系统的后验信息。我们的实验表明，我们的初始化方法提高了状态空间模型在训练和推理时对噪声的抵抗能力。我们的实现代码可在https://cs.cit.tum.de/daml/unhippo 获取。", "summary": "本文针对现有HiPPO框架在状态空间模型初始化时忽略数据噪声的问题，提出了UnHiPPO。该方法通过将测量噪声纳入HiPPO理论，并重新构建问题，使得模型能够从噪声数据中推断潜在系统的后验信息，从而在不增加计算成本的情况下，显著增强了状态空间模型在训练和推理阶段对噪声的抵抗能力。", "keywords": "状态空间模型, HiPPO, 不确定性感知, 初始化, 噪声鲁棒性"}}
{"id": "2506.04422", "pdf": "https://arxiv.org/pdf/2506.04422", "abs": "https://arxiv.org/abs/2506.04422", "authors": ["Alexandros Efstratiou"], "title": "I'm Sorry Dave, I'm Afraid I Can't Return That: On YouTube Search API Use in Research", "categories": ["cs.IR"], "comment": "9 pages, 4 figures", "summary": "YouTube is among the most widely-used platforms worldwide, and has seen a lot\nof recent academic attention. Despite its popularity and the number of studies\nconducted on it, much less is understood about the way in which YouTube's Data\nAPI, and especially the Search endpoint, operates. In this paper, we analyze\nthe API's behavior by running identical queries across a period of 12 weeks.\nOur findings suggest that the search endpoint returns highly inconsistent\nresults between queries in ways that are not officially documented.\nSpecifically, the API seems to randomize returned videos based on the relative\npopularity of the respective topic during the query period, making it nearly\nimpossible to obtain representative historical video samples, especially during\nnon-peak topical periods. Our results also suggest that the API may prioritize\nshorter, more popular videos, although the role of channel popularity is not as\nclear. We conclude with suggested strategies for researchers using the API for\ndata collection, as well as future research directions on expanding the API's\nuse-cases.", "AI": {"title_translation": "对不起，戴夫，我恐怕无法返回那个：关于YouTube搜索API在研究中的应用", "tldr": "研究发现YouTube搜索API在返回结果方面高度不一致，且未正式说明，导致难以获取代表性历史视频样本。", "motivation": "尽管YouTube平台及其相关研究很受欢迎，但对于YouTube数据API（特别是搜索端点）的运作方式知之甚少。", "method": "通过在12周内运行相同的查询来分析API的行为。", "result": "搜索端点在查询之间返回高度不一致的结果，且未正式说明；API似乎根据查询期间相关主题的相对流行度随机化返回视频，使得获取代表性历史视频样本几乎不可能，尤其是在非高峰主题时期；API可能优先考虑较短、更受欢迎的视频。", "conclusion": "论文提出了使用API进行数据收集的研究策略，以及扩展API用例的未来研究方向。", "translation": "YouTube是全球使用最广泛的平台之一，最近受到了大量学术关注。尽管其受欢迎程度以及对其进行的研究数量众多，但对于YouTube数据API，尤其是搜索端点的运作方式知之甚少。在本文中，我们通过在12周内运行相同的查询来分析API的行为。我们的发现表明，搜索端点在查询之间返回高度不一致的结果，而这些不一致性并未在官方文档中提及。具体来说，API似乎根据查询期间相关主题的相对流行度随机化返回视频，这使得获取代表性历史视频样本几乎不可能，尤其是在非高峰主题时期。我们的结果还表明，API可能优先考虑较短、更受欢迎的视频，尽管频道受欢迎程度的作用尚不明确。最后，我们为使用API进行数据收集的研究人员提出了建议策略，以及扩展API用例的未来研究方向。", "summary": "本文分析了YouTube搜索API的行为，发现其在返回结果方面存在高度不一致性，且未正式说明。研究表明API会根据主题流行度随机化结果，使得获取代表性历史视频样本变得困难，并可能优先显示较短、更受欢迎的视频。论文最后为研究人员使用API进行数据收集提供了策略建议。", "keywords": "YouTube搜索API, API行为, 数据不一致性, 视频数据收集, 研究方法"}}
{"id": "2506.05204", "pdf": "https://arxiv.org/pdf/2506.05204", "abs": "https://arxiv.org/abs/2506.05204", "authors": ["Yanbo Wang", "Ziyi Wang", "Wenzhao Zheng", "Jie Zhou", "Jiwen Lu"], "title": "OGGSplat: Open Gaussian Growing for Generalizable Reconstruction with Expanded Field-of-View", "categories": ["cs.CV"], "comment": null, "summary": "Reconstructing semantic-aware 3D scenes from sparse views is a challenging\nyet essential research direction, driven by the demands of emerging\napplications such as virtual reality and embodied AI. Existing per-scene\noptimization methods require dense input views and incur high computational\ncosts, while generalizable approaches often struggle to reconstruct regions\noutside the input view cone. In this paper, we propose OGGSplat, an open\nGaussian growing method that expands the field-of-view in generalizable 3D\nreconstruction. Our key insight is that the semantic attributes of open\nGaussians provide strong priors for image extrapolation, enabling both semantic\nconsistency and visual plausibility. Specifically, once open Gaussians are\ninitialized from sparse views, we introduce an RGB-semantic consistent\ninpainting module applied to selected rendered views. This module enforces\nbidirectional control between an image diffusion model and a semantic diffusion\nmodel. The inpainted regions are then lifted back into 3D space for efficient\nand progressive Gaussian parameter optimization. To evaluate our method, we\nestablish a Gaussian Outpainting (GO) benchmark that assesses both semantic and\ngenerative quality of reconstructed open-vocabulary scenes. OGGSplat also\ndemonstrates promising semantic-aware scene reconstruction capabilities when\nprovided with two view images captured directly from a smartphone camera.", "AI": {"title_translation": "OGGSplat：开放高斯增长用于可泛化重建与扩展视野", "tldr": "OGGSplat通过开放高斯增长和RGB-语义一致性修复模块，实现了稀疏视图下可泛化3D场景重建，并扩展了视野。", "motivation": "从稀疏视图重建语义感知的3D场景是一个具有挑战性但重要的研究方向，现有每场景优化方法需要密集输入视图且计算成本高，而可泛化方法难以重建输入视图锥体外的区域，但虚拟现实和具身AI等新兴应用对此有需求。", "method": "本文提出了OGGSplat，一种开放高斯增长方法，旨在扩展可泛化3D重建的视野。其核心思想是利用开放高斯的语义属性作为图像外推的强先验。具体实现包括：从稀疏视图初始化开放高斯；引入RGB-语义一致性修复模块应用于选定的渲染视图，该模块强制图像扩散模型和语义扩散模型之间的双向控制；将修复区域提升回3D空间进行高效且渐进的高斯参数优化。为评估方法，建立了高斯外推（GO）基准。", "result": "OGGSplat在语义和生成质量方面表现出良好性能，并通过高斯外推（GO）基准进行了评估。即使仅提供两张智能手机相机捕获的视图图像，OGGSplat也展示了有前景的语义感知场景重建能力。", "conclusion": "OGGSplat通过其开放高斯增长方法和RGB-语义一致性修复机制，有效解决了稀疏视图下可泛化3D重建中视野受限的问题，并在语义感知场景重建方面表现出良好性能。", "translation": "从稀疏视图重建语义感知的3D场景是一个具有挑战性但必不可少的研究方向，这受到虚拟现实和具身AI等新兴应用需求的驱动。现有的每场景优化方法需要密集的输入视图并产生高计算成本，而可泛化方法通常难以重建输入视图锥体之外的区域。在本文中，我们提出了OGGSplat，一种开放高斯增长方法，用于扩展可泛化3D重建的视野。我们的关键见解是，开放高斯的语义属性为图像外推提供了强大的先验，从而实现了语义一致性和视觉合理性。具体而言，一旦开放高斯从稀疏视图初始化，我们引入一个RGB-语义一致性修复模块，应用于选定的渲染视图。该模块强制图像扩散模型和语义扩散模型之间的双向控制。然后，修复区域被提升回3D空间，用于高效且渐进的高斯参数优化。为了评估我们的方法，我们建立了一个高斯外推（GO）基准，该基准评估重建的开放词汇场景的语义和生成质量。OGGSplat在仅提供两张直接从智能手机相机捕获的视图图像时，也展示了有前景的语义感知场景重建能力。", "summary": "本文提出了OGGSplat，一种开放高斯增长方法，旨在解决从稀疏视图重建语义感知3D场景时，现有可泛化方法视野受限的问题。OGGSplat利用开放高斯的语义属性作为图像外推的强先验，通过RGB-语义一致性修复模块对渲染视图进行修复，并将修复区域提升回3D空间进行高斯参数优化。实验通过新建立的高斯外推（GO）基准评估，证明了OGGSplat在扩展视野和实现语义一致性、视觉合理性方面的有效性，即使在智能手机稀疏视图下也能表现出良好的场景重建能力。", "keywords": "开放高斯增长, 3D重建, 稀疏视图, 视野扩展, 语义感知"}}
{"id": "2506.05088", "pdf": "https://arxiv.org/pdf/2506.05088", "abs": "https://arxiv.org/abs/2506.05088", "authors": ["Tobias Pielok", "Bernd Bischl", "David Rügamer"], "title": "Semi-Implicit Variational Inference via Kernelized Path Gradient Descent", "categories": ["cs.LG", "stat.CO", "62F15, 68T07", "I.2.6; G.3"], "comment": "Preliminary version", "summary": "Semi-implicit variational inference (SIVI) is a powerful framework for\napproximating complex posterior distributions, but training with the\nKullback-Leibler (KL) divergence can be challenging due to high variance and\nbias in high-dimensional settings. While current state-of-the-art semi-implicit\nvariational inference methods, particularly Kernel Semi-Implicit Variational\nInference (KSIVI), have been shown to work in high dimensions, training remains\nmoderately expensive. In this work, we propose a kernelized KL divergence\nestimator that stabilizes training through nonparametric smoothing. To further\nreduce the bias, we introduce an importance sampling correction. We provide a\ntheoretical connection to the amortized version of the Stein variational\ngradient descent, which estimates the score gradient via Stein's identity,\nshowing that both methods minimize the same objective, but our semi-implicit\napproach achieves lower gradient variance. In addition, our method's bias in\nfunction space is benign, leading to more stable and efficient optimization.\nEmpirical results demonstrate that our method outperforms or matches\nstate-of-the-art SIVI methods in both performance and training efficiency.", "AI": {"title_translation": "通过核化路径梯度下降的半隐式变分推断", "tldr": "本文提出了一种新的半隐式变分推断（SIVI）方法，通过核化KL散度估计器和重要性采样校正来稳定训练并降低偏差，在性能和训练效率上优于或匹配现有SIVI方法。", "motivation": "传统的半隐式变分推断（SIVI）在处理高维数据时，由于KL散度训练的高方差和偏差，面临挑战。尽管现有的先进方法（特别是核半隐式变分推断KSIVI）在高维设置下表现良好，但训练成本仍然较高。", "method": "我们提出了一种核化的KL散度估计器，通过非参数平滑来稳定训练。为了进一步减少偏差，引入了重要性采样校正。理论上，该方法与Stein变分梯度下降的摊销版本有联系，两者最小化相同的目标，但我们的半隐式方法实现了更低的梯度方差，并且其在函数空间中的偏差是良性的，从而实现了更稳定和高效的优化。", "result": "实验结果表明，我们的方法在性能和训练效率上都优于或匹配了最先进的SIVI方法。", "conclusion": "所提出的方法通过稳定训练和降低梯度方差，显著提高了半隐式变分推断的性能和训练效率，使其成为处理复杂后验分布的有效工具。", "translation": "半隐式变分推断（SIVI）是近似复杂后验分布的强大框架，但在高维设置下，使用Kullback-Leibler（KL）散度进行训练可能因高方差和偏差而具有挑战性。尽管当前最先进的半隐式变分推断方法，特别是核半隐式变分推断（KSIVI），已被证明在高维环境中有效，但训练成本仍然适中。在这项工作中，我们提出了一种核化的KL散度估计器，通过非参数平滑来稳定训练。为了进一步减少偏差，我们引入了重要性采样校正。我们提供了与Stein变分梯度下降的摊销版本的理论联系，该方法通过Stein恒等式估计分数梯度，表明两种方法最小化相同的目标，但我们的半隐式方法实现了更低的梯度方差。此外，我们方法在函数空间中的偏差是良性的，从而导致更稳定和高效的优化。实证结果表明，我们的方法在性能和训练效率上都优于或匹配了最先进的SIVI方法。", "summary": "本文针对半隐式变分推断（SIVI）在高维设置下训练KL散度时面临的高方差和偏差问题，以及现有方法（如KSIVI）训练成本高昂的问题，提出了一种新的核化KL散度估计器，并引入了重要性采样校正。该方法通过非参数平滑稳定训练，并理论上证明其与Stein变分梯度下降最小化相同目标，但具有更低的梯度方差和良性的函数空间偏差，从而实现更稳定和高效的优化。实证结果显示，该方法在性能和训练效率方面均超越或达到了当前最先进的SIVI方法水平。", "keywords": "半隐式变分推断, 核化, KL散度, 梯度下降, 重要性采样"}}
{"id": "2506.04423", "pdf": "https://arxiv.org/pdf/2506.04423", "abs": "https://arxiv.org/abs/2506.04423", "authors": ["Xiaotian Su", "Thiemo Wambsganss", "Roman Rietsche", "Seyed Parsa Neshaei", "Tanja Käser"], "title": "Reviewriter: AI-Generated Instructions For Peer Review Writing", "categories": ["cs.HC", "68T50", "I.2.7; K.3.1"], "comment": null, "summary": "Large Language Models (LLMs) offer novel opportunities for educational\napplications that have the potential to transform traditional learning for\nstudents. Despite AI-enhanced applications having the potential to provide\npersonalized learning experiences, more studies are needed on the design of\ngenerative AI systems and evidence for using them in real educational settings.\nIn this paper, we design, implement and evaluate \\texttt{Reviewriter}, a novel\ntool to provide students with AI-generated instructions for writing peer\nreviews in German. Our study identifies three key aspects: a) we provide\ninsights into student needs when writing peer reviews with generative models\nwhich we then use to develop a novel system to provide adaptive instructions b)\nwe fine-tune three German language models on a selected corpus of 11,925\nstudent-written peer review texts in German and choose German-GPT2 based on\nquantitative measures and human evaluation, and c) we evaluate our tool with\nfourteen students, revealing positive technology acceptance based on\nquantitative measures. Additionally, the qualitative feedback presents the\nbenefits and limitations of generative AI in peer review writing.", "AI": {"title_translation": "Reviewriter：AI 生成的同行评审写作说明", "tldr": "本研究设计并评估了 Reviewriter 工具，该工具利用微调的德语大型语言模型为学生提供德语同行评审写作的 AI 生成说明，并显示出积极的技术接受度。", "motivation": "大型语言模型（LLMs）为教育应用提供了新机会，有潜力改变传统学习。尽管 AI 增强应用有潜力提供个性化学习体验，但仍需要更多关于生成式 AI 系统设计及其在真实教育环境中使用的证据。", "method": "本研究设计、实现并评估了 Reviewriter 工具，为学生提供德语同行评审写作的 AI 生成说明。研究确定了三个关键方面：a) 深入了解学生在使用生成模型进行同行评审写作时的需求，并据此开发了自适应说明系统；b) 在包含 11,925 篇学生撰写的德语同行评审文本的语料库上微调了三个德语语言模型，并基于定量测量和人工评估选择了 German-GPT2；c) 对 14 名学生进行了工具评估。", "result": "评估显示，基于定量测量，学生对该工具表现出积极的技术接受度。此外，定性反馈揭示了生成式 AI 在同行评审写作中的益处和局限性。", "conclusion": "Not mentioned in abstract", "translation": "大型语言模型（LLMs）为教育应用提供了新颖的机会，有潜力改变学生的传统学习方式。尽管 AI 增强应用有潜力提供个性化学习体验，但仍需要更多关于生成式 AI 系统设计及其在真实教育环境中使用的研究和证据。在本文中，我们设计、实现并评估了 Reviewriter，这是一种新颖的工具，旨在为学生提供 AI 生成的德语同行评审写作说明。我们的研究确定了三个关键方面：a) 我们深入了解了学生在使用生成模型撰写同行评审时的需求，并据此开发了一个提供自适应说明的新型系统；b) 我们在选定的包含 11,925 篇学生撰写的德语同行评审文本的语料库上微调了三个德语语言模型，并根据定量测量和人工评估选择了 German-GPT2；c) 我们对十四名学生评估了我们的工具，结果显示基于定量测量，技术接受度良好。此外，定性反馈也呈现了生成式 AI 在同行评审写作中的优点和局限性。", "summary": "本研究设计并评估了 Reviewriter 工具，旨在为学生提供 AI 生成的德语同行评审写作说明。该工具基于对学生需求的洞察而开发，并通过在大量学生撰写的德语同行评审文本上微调德语语言模型（最终选择 German-GPT2）来实现。对 14 名学生的评估显示，Reviewriter 具有积极的技术接受度，并且定性反馈揭示了生成式 AI 在同行评审写作中的潜在益处和局限性。", "keywords": "AI 生成说明, 同行评审, 大型语言模型, 教育应用, Reviewriter"}}
{"id": "2506.05207", "pdf": "https://arxiv.org/pdf/2506.05207", "abs": "https://arxiv.org/abs/2506.05207", "authors": ["Yue Ma", "Yulong Liu", "Qiyuan Zhu", "Ayden Yang", "Kunyu Feng", "Xinhua Zhang", "Zhifeng Li", "Sirui Han", "Chenyang Qi", "Qifeng Chen"], "title": "Follow-Your-Motion: Video Motion Transfer via Efficient Spatial-Temporal Decoupled Finetuning", "categories": ["cs.CV"], "comment": "project page: https://follow-your-motion.github.io/", "summary": "Recently, breakthroughs in the video diffusion transformer have shown\nremarkable capabilities in diverse motion generations. As for the\nmotion-transfer task, current methods mainly use two-stage Low-Rank Adaptations\n(LoRAs) finetuning to obtain better performance. However, existing\nadaptation-based motion transfer still suffers from motion inconsistency and\ntuning inefficiency when applied to large video diffusion transformers. Naive\ntwo-stage LoRA tuning struggles to maintain motion consistency between\ngenerated and input videos due to the inherent spatial-temporal coupling in the\n3D attention operator. Additionally, they require time-consuming fine-tuning\nprocesses in both stages. To tackle these issues, we propose\nFollow-Your-Motion, an efficient two-stage video motion transfer framework that\nfinetunes a powerful video diffusion transformer to synthesize complex\nmotion.Specifically, we propose a spatial-temporal decoupled LoRA to decouple\nthe attention architecture for spatial appearance and temporal motion\nprocessing. During the second training stage, we design the sparse motion\nsampling and adaptive RoPE to accelerate the tuning speed. To address the lack\nof a benchmark for this field, we introduce MotionBench, a comprehensive\nbenchmark comprising diverse motion, including creative camera motion, single\nobject motion, multiple object motion, and complex human motion. We show\nextensive evaluations on MotionBench to verify the superiority of\nFollow-Your-Motion.", "AI": {"title_translation": "Follow-Your-Motion: 通过高效时空解耦微调实现视频运动迁移", "tldr": "本文提出了Follow-Your-Motion，一个高效的两阶段视频运动迁移框架，通过时空解耦LoRA、稀疏运动采样和自适应RoPE等技术解决了现有方法在大型视频扩散Transformer中运动不一致和微调效率低的问题，并引入了综合基准MotionBench。", "motivation": "现有基于Low-Rank Adaptations (LoRAs) 微调的运动迁移方法在应用于大型视频扩散Transformer时，存在运动不一致和微调效率低下的问题。这是由于3D注意力操作中固有的时空耦合导致难以维持生成视频与输入视频之间的运动一致性，且两阶段微调过程耗时。", "method": "本文提出了Follow-Your-Motion，一个高效的两阶段视频运动迁移框架。具体包括：1) 提出空间-时间解耦LoRA，以解耦注意力架构，分别处理空间外观和时间运动；2) 在第二训练阶段设计稀疏运动采样和自适应RoPE，以加速微调速度；3) 引入MotionBench，一个包含创意相机运动、单对象运动、多对象运动和复杂人体运动等多样化运动的综合基准，以解决该领域基准缺乏的问题。", "result": "在MotionBench上进行了广泛评估，验证了Follow-Your-Motion的优越性。", "conclusion": "Follow-Your-Motion框架成功解决了现有视频运动迁移方法在大型视频扩散Transformer中存在的运动不一致和微调效率低下问题，并通过引入MotionBench为该领域提供了新的综合基准。", "translation": "最近，视频扩散Transformer的突破在多样化运动生成方面展现了卓越的能力。对于运动迁移任务，当前方法主要使用两阶段低秩适应（LoRAs）微调以获得更好的性能。然而，现有基于适应的运动迁移在应用于大型视频扩散Transformer时，仍然存在运动不一致和微调效率低下的问题。由于3D注意力操作中固有的时空耦合，朴素的两阶段LoRA微调难以保持生成视频与输入视频之间的运动一致性。此外，它们在两个阶段都需要耗时的微调过程。为了解决这些问题，我们提出了Follow-Your-Motion，一个高效的两阶段视频运动迁移框架，该框架对强大的视频扩散Transformer进行微调以合成复杂运动。具体而言，我们提出了一个时空解耦LoRA，以解耦注意力架构，用于空间外观和时间运动处理。在第二个训练阶段，我们设计了稀疏运动采样和自适应RoPE以加速微调速度。为了解决该领域缺乏基准的问题，我们引入了MotionBench，一个包含创意相机运动、单对象运动、多对象运动和复杂人体运动等多样化运动的综合基准。我们在MotionBench上进行了广泛评估，以验证Follow-Your-Motion的优越性。", "summary": "本文针对现有视频运动迁移方法在大型视频扩散Transformer中面临的运动不一致和微调效率低下问题，提出了Follow-Your-Motion框架。该框架通过引入时空解耦LoRA来分离空间外观和时间运动处理，并在第二训练阶段采用稀疏运动采样和自适应RoPE以提升微调效率。此外，论文还提出了MotionBench，一个包含多样化运动的综合基准，用于评估运动迁移任务。实验结果表明Follow-Your-Motion表现出优越性。", "keywords": "视频运动迁移, 扩散Transformer, LoRA, 时空解耦, MotionBench"}}
{"id": "2506.05210", "pdf": "https://arxiv.org/pdf/2506.05210", "abs": "https://arxiv.org/abs/2506.05210", "authors": ["Jan Ackermann", "Kiyohiro Nakayama", "Guandao Yang", "Tong Wu", "Gordon Wetzstein"], "title": "Towards Vision-Language-Garment Models For Web Knowledge Garment Understanding and Generation", "categories": ["cs.CV"], "comment": "Presented at MMFM CVPRW'25, code available at\n  https://georgenakayama.github.io/AIpparel/", "summary": "Multimodal foundation models have demonstrated strong generalization, yet\ntheir ability to transfer knowledge to specialized domains such as garment\ngeneration remains underexplored. We introduce VLG, a vision-language-garment\nmodel that synthesizes garments from textual descriptions and visual imagery.\nOur experiments assess VLG's zero-shot generalization, investigating its\nability to transfer web-scale reasoning to unseen garment styles and prompts.\nPreliminary results indicate promising transfer capabilities, highlighting the\npotential for multimodal foundation models to adapt effectively to specialized\ndomains like fashion design.", "AI": {"title_translation": "面向网络知识服装理解与生成的视觉-语言-服装模型", "tldr": "本文介绍了VLG模型，一个视觉-语言-服装模型，用于根据文本描述和视觉图像合成服装，并初步展示了其在服装设计领域中的零样本泛化能力。", "motivation": "多模态基础模型在通用领域表现出强大的泛化能力，但在服装生成等专业领域的知识迁移能力尚未得到充分探索。", "method": "本文引入了VLG（视觉-语言-服装）模型，该模型能够根据文本描述和视觉图像合成服装。", "result": "初步结果表明，VLG模型具有良好的迁移能力，证明了多模态基础模型能有效适应时尚设计等专业领域。", "conclusion": "多模态基础模型在适应时尚设计等专业领域方面具有潜力，VLG模型展示了将网络规模推理迁移到未见服装风格和提示的能力。", "translation": "多模态基础模型展现出强大的泛化能力，然而它们将知识迁移到服装生成等专业领域的能力仍未得到充分探索。我们引入了VLG，一个视觉-语言-服装模型，它能够从文本描述和视觉图像中合成服装。我们的实验评估了VLG的零样本泛化能力，调查了它将网络规模推理迁移到未见服装样式和提示的能力。初步结果表明了有前景的迁移能力，突显了多模态基础模型有效适应时尚设计等专业领域的潜力。", "summary": "本文提出VLG模型，一个结合视觉、语言和服装信息的多模态基础模型，旨在解决现有模型在服装生成专业领域知识迁移能力不足的问题。实验评估了VLG的零样本泛化能力，结果显示其在将网络知识迁移到新颖服装样式和提示方面表现出有前景的性能，突显了多模态基础模型在时尚设计等专业领域应用的潜力。", "keywords": "视觉-语言模型, 服装生成, 多模态基础模型, 零样本泛化, 时尚设计"}}
{"id": "2506.04688", "pdf": "https://arxiv.org/pdf/2506.04688", "abs": "https://arxiv.org/abs/2506.04688", "authors": ["Gio Paik", "Geewook Kim", "Jinbae Im"], "title": "MMRefine: Unveiling the Obstacles to Robust Refinement in Multimodal Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "ACL Findings 2025", "summary": "This paper introduces MMRefine, a MultiModal Refinement benchmark designed to\nevaluate the error refinement capabilities of Multimodal Large Language Models\n(MLLMs). As the emphasis shifts toward enhancing reasoning during inference,\nMMRefine provides a framework that evaluates MLLMs' abilities to detect and\ncorrect errors across six distinct scenarios beyond just comparing final\naccuracy before and after refinement. Furthermore, the benchmark analyzes the\nrefinement performance by categorizing errors into six error types. Experiments\nwith various open and closed MLLMs reveal bottlenecks and factors impeding\nrefinement performance, highlighting areas for improvement in effective\nreasoning enhancement. Our code and dataset are publicly available at\nhttps://github.com/naver-ai/MMRefine.", "AI": {"title_translation": "MMRefine：揭示多模态大型语言模型中稳健改进的障碍", "tldr": "MMRefine是一个用于评估多模态大语言模型错误纠正能力的基准测试，它揭示了模型改进的瓶颈。", "motivation": "随着推理过程中对增强推理能力的日益重视，需要一个能够评估多模态大型语言模型（MLLMs）检测和纠正错误能力的框架。", "method": "本文引入了MMRefine，一个多模态改进基准，旨在评估多模态大型语言模型（MLLMs）的错误改进能力。该基准通过在六种不同场景下评估MLLMs检测和纠正错误的能力，并根据六种错误类型对改进性能进行分类分析。", "result": "对各种开放和封闭的MLLM进行的实验揭示了阻碍改进性能的瓶颈和因素。", "conclusion": "研究结果突出了在有效推理增强方面需要改进的领域。", "translation": "本文介绍了MMRefine，一个旨在评估多模态大型语言模型（MLLMs）错误改进能力的多模态改进基准。随着推理过程中对增强推理能力的重视，MMRefine提供了一个框架，用于评估MLLMs在六种不同场景下检测和纠正错误的能力，而不仅仅是比较改进前后的最终准确性。此外，该基准通过将错误分为六种错误类型来分析改进性能。对各种开放和封闭的MLLM进行的实验揭示了阻碍改进性能的瓶颈和因素，突出了有效推理增强方面需要改进的领域。我们的代码和数据集已公开发布在https://github.com/naver-ai/MMRefine。", "summary": "本文提出了MMRefine，一个用于评估多模态大型语言模型（MLLMs）错误改进能力的基准。该基准通过在六种不同场景下，并根据六种错误类型来评估MLLMs检测和纠正错误的能力，超越了仅仅比较改进前后最终准确性的方法。对多种MLLMs的实验揭示了阻碍改进性能的瓶颈和因素，为未来的推理增强研究指明了方向。", "keywords": "多模态大型语言模型, 错误改进, 基准测试, MMRefine, 推理增强"}}
{"id": "2506.05217", "pdf": "https://arxiv.org/pdf/2506.05217", "abs": "https://arxiv.org/abs/2506.05217", "authors": ["Wenhao Hu", "Xuexiang Wen", "Xi Li", "Gaoang Wang"], "title": "DSG-World: Learning a 3D Gaussian World Model from Dual State Videos", "categories": ["cs.CV"], "comment": null, "summary": "Building an efficient and physically consistent world model from limited\nobservations is a long standing challenge in vision and robotics. Many existing\nworld modeling pipelines are based on implicit generative models, which are\nhard to train and often lack 3D or physical consistency. On the other hand,\nexplicit 3D methods built from a single state often require multi-stage\nprocessing-such as segmentation, background completion, and inpainting-due to\nocclusions. To address this, we leverage two perturbed observations of the same\nscene under different object configurations. These dual states offer\ncomplementary visibility, alleviating occlusion issues during state transitions\nand enabling more stable and complete reconstruction. In this paper, we present\nDSG-World, a novel end-to-end framework that explicitly constructs a 3D\nGaussian World model from Dual State observations. Our approach builds dual\nsegmentation-aware Gaussian fields and enforces bidirectional photometric and\nsemantic consistency. We further introduce a pseudo intermediate state for\nsymmetric alignment and design collaborative co-pruning trategies to refine\ngeometric completeness. DSG-World enables efficient real-to-simulation transfer\npurely in the explicit Gaussian representation space, supporting high-fidelity\nrendering and object-level scene manipulation without relying on dense\nobservations or multi-stage pipelines. Extensive experiments demonstrate strong\ngeneralization to novel views and scene states, highlighting the effectiveness\nof our approach for real-world 3D reconstruction and simulation.", "AI": {"title_translation": "DSG-World：从双状态视频学习3D高斯世界模型", "tldr": "DSG-World利用双状态视频构建3D高斯世界模型，解决了现有方法在训练难度、3D一致性和遮挡问题上的不足，实现了高效的真实到仿真转换和高保真渲染。", "motivation": "从有限观测中构建高效且物理一致的世界模型是一个长期挑战。现有隐式生成模型难以训练且缺乏3D或物理一致性；显式3D方法通常需要多阶段处理且受遮挡影响。", "method": "DSG-World是一个端到端框架，利用双状态（不同物体配置下的同一场景的两个扰动观测）显式构建3D高斯世界模型。该方法构建了双重分割感知高斯场，强制执行双向光度和语义一致性，引入伪中间状态进行对称对齐，并设计协同共剪枝策略以完善几何完整性。", "result": "DSG-World实现了纯粹在显式高斯表示空间中的高效真实到仿真转换，支持高保真渲染和对象级场景操作，无需密集观测或多阶段管道。大量实验表明其对新颖视图和场景状态具有强大的泛化能力。", "conclusion": "DSG-World通过利用双状态观测和创新的高斯表示方法，有效解决了3D世界建模中的挑战，为真实世界的3D重建和仿真提供了高效且高质量的解决方案。", "translation": "从有限观测中构建高效且物理一致的世界模型是计算机视觉和机器人领域的一个长期挑战。许多现有的世界建模流程基于隐式生成模型，这些模型难以训练且通常缺乏3D或物理一致性。另一方面，从单一状态构建的显式3D方法由于遮挡问题，通常需要多阶段处理——例如分割、背景补全和修复。为了解决这个问题，我们利用同一场景在不同物体配置下的两个扰动观测。这些双状态提供了互补的可见性，缓解了状态转换期间的遮挡问题，并实现了更稳定和完整的重建。本文提出了DSG-World，一个新颖的端到端框架，它从双状态观测中显式构建3D高斯世界模型。我们的方法构建了双重分割感知高斯场，并强制执行双向光度和语义一致性。我们进一步引入了一个伪中间状态用于对称对齐，并设计了协同共剪枝策略来完善几何完整性。DSG-World纯粹在显式高斯表示空间中实现了高效的真实到仿真转换，支持高保真渲染和对象级场景操作，无需依赖密集观测或多阶段管道。大量实验表明其对新颖视图和场景状态具有强大的泛化能力，突出了我们方法在真实世界3D重建和仿真中的有效性。", "summary": "DSG-World提出了一种新颖的端到端框架，通过利用同一场景的两个不同对象配置下的扰动观测（双状态），构建一个3D高斯世界模型。该方法解决了传统世界建模方法在训练难度、3D一致性和遮挡处理上的不足。DSG-World通过建立双重分割感知高斯场、强制双向一致性、引入伪中间状态和协同共剪枝策略，实现了高效的真实到仿真转换、高保真渲染和对象级场景操作，并在实验中展现出强大的泛化能力。", "keywords": "3D高斯世界模型, 双状态视频, 遮挡处理, 真实到仿真转换, 世界建模"}}
{"id": "2506.05178", "pdf": "https://arxiv.org/pdf/2506.05178", "abs": "https://arxiv.org/abs/2506.05178", "authors": ["Joshua Hess", "Quaid Morris"], "title": "Associative Memory and Generative Diffusion in the Zero-noise Limit", "categories": ["cs.LG", "cond-mat.dis-nn", "math.DS", "nlin.AO", "q-bio.NC"], "comment": null, "summary": "Connections between generative diffusion and continuous-state associative\nmemory models are studied. Morse-Smale dynamical systems are emphasized as\nuniversal approximators of gradient-based associative memory models and\ndiffusion models as white-noise perturbed systems thereof. Universal properties\nof associative memory that follow from this description are described and used\nto characterize a generic transition from generation to memory as noise levels\ndiminish. Structural stability inherited by Morse-Smale flows is shown to imply\na notion of stability for diffusions at vanishing noise levels. Applied to one-\nand two-parameter families of gradients, this indicates stability at all but\nisolated points of associative memory learning landscapes and the learning and\ngeneration landscapes of diffusion models with gradient drift in the zero-noise\nlimit, at which small sets of generic bifurcations characterize qualitative\ntransitions between stable systems. Examples illustrating the characterization\nof these landscapes by sequences of these bifurcations are given, along with\nstructural stability criterion for classic and modern Hopfield networks\n(equivalently, the attention mechanism).", "AI": {"title_translation": "联想记忆与零噪声极限下的生成扩散", "tldr": "本文通过莫尔斯-斯梅尔动力系统研究了生成扩散与联想记忆模型之间的联系，揭示了噪声降低时从生成到记忆的转变、零噪声极限下扩散的稳定性以及学习景观中的分岔特征，并提出了霍普菲尔德网络的结构稳定性判据。", "motivation": "研究生成扩散与连续态联想记忆模型之间的联系。", "method": "强调莫尔斯-斯梅尔动力系统作为梯度联想记忆模型和扩散模型的通用逼近器，并将其作为白噪声扰动系统进行研究。将理论应用于单参数和双参数梯度族，并提供了霍普菲尔德网络的结构稳定性判据。", "result": "描述了联想记忆的普遍性质，并表征了噪声水平降低时从生成到记忆的通用转变。证明了莫尔斯-斯梅尔流的结构稳定性意味着在噪声水平消失时扩散的稳定性。揭示了在零噪声极限下，联想记忆学习景观以及扩散模型的学习和生成景观在除孤立点外的所有点都具有稳定性，这些孤立点处的通用分岔表征了稳定系统之间的定性转变。提供了通过分岔序列表征这些景观的例子，并给出了经典和现代霍普菲尔德网络的结构稳定性判据。", "conclusion": "本文通过莫尔斯-斯梅尔动力系统揭示了生成扩散与联想记忆模型在零噪声极限下的深层联系、稳定性特征以及学习景观中的定性转变机制，并为霍普菲尔德网络提供了结构稳定性判据。", "translation": "研究了生成扩散与连续态联想记忆模型之间的联系。强调了莫尔斯-斯梅尔动力系统作为基于梯度的联想记忆模型和扩散模型的通用逼近器，以及作为其白噪声扰动系统。描述了由此产生的联想记忆的普遍性质，并用其来表征随着噪声水平降低，从生成到记忆的通用转变。莫尔斯-斯梅尔流所继承的结构稳定性被证明意味着在噪声水平消失时扩散的稳定性概念。将其应用于单参数和双参数梯度族，这表明在零噪声极限下，除了联想记忆学习景观的孤立点以及具有梯度漂移的扩散模型的学习和生成景观之外，所有点都具有稳定性，在这些孤立点处，小集合的通用分岔表征了稳定系统之间的定性转变。给出了说明通过这些分岔序列表征这些景观的例子，以及经典和现代霍普菲尔德网络（等效于注意力机制）的结构稳定性判据。", "summary": "本文研究了生成扩散与连续态联想记忆模型之间的关系，着重强调了莫尔斯-斯梅尔动力系统作为梯度联想记忆模型和扩散模型的通用逼近器。研究描述了联想记忆的普遍性质，并表征了噪声水平降低时从生成到记忆的转变。研究表明，莫尔斯-斯梅尔流的结构稳定性预示着在零噪声极限下扩散的稳定性。将此应用于梯度族，揭示了学习景观的稳定性以及由分岔引起的定性转变。此外，还提供了经典和现代霍普菲尔德网络的结构稳定性判据。", "keywords": "联想记忆, 生成扩散, 零噪声极限, 莫尔斯-斯梅尔系统, 霍普菲尔德网络"}}
{"id": "2506.05218", "pdf": "https://arxiv.org/pdf/2506.05218", "abs": "https://arxiv.org/abs/2506.05218", "authors": ["Zhang Li", "Yuliang Liu", "Qiang Liu", "Zhiyin Ma", "Ziyang Zhang", "Shuo Zhang", "Zidun Guo", "Jiarui Zhang", "Xinyu Wang", "Xiang Bai"], "title": "MonkeyOCR: Document Parsing with a Structure-Recognition-Relation Triplet Paradigm", "categories": ["cs.CV"], "comment": null, "summary": "We introduce MonkeyOCR, a vision-language model for document parsing that\nadvances the state of the art by leveraging a Structure-Recognition-Relation\n(SRR) triplet paradigm. This design simplifies what would otherwise be a\ncomplex multi-tool pipeline (as in MinerU's modular approach) and avoids the\ninefficiencies of processing full pages with giant end-to-end models (e.g.,\nlarge multimodal LLMs like Qwen-VL). In SRR, document parsing is abstracted\ninto three fundamental questions - \"Where is it?\" (structure), \"What is it?\"\n(recognition), and \"How is it organized?\" (relation) - corresponding to layout\nanalysis, content identification, and logical ordering. This focused\ndecomposition balances accuracy and speed: it enables efficient, scalable\nprocessing without sacrificing precision. To train and evaluate this approach,\nwe introduce the MonkeyDoc (the most comprehensive document parsing dataset to\ndate), with 3.9 million instances spanning over ten document types in both\nChinese and English. Experiments show that MonkeyOCR outperforms MinerU by an\naverage of 5.1%, with particularly notable improvements on challenging content\nsuch as formulas (+15.0%) and tables (+8.6%). Remarkably, our 3B-parameter\nmodel surpasses much larger and top-performing models, including Qwen2.5-VL\n(72B) and Gemini 2.5 Pro, achieving state-of-the-art average performance on\nEnglish document parsing tasks. In addition, MonkeyOCR processes multi-page\ndocuments significantly faster (0.84 pages per second compared to 0.65 for\nMinerU and 0.12 for Qwen2.5-VL-7B). The 3B model can be efficiently deployed\nfor inference on a single NVIDIA 3090 GPU. Code and models will be released at\nhttps://github.com/Yuliang-Liu/MonkeyOCR.", "AI": {"title_translation": "MonkeyOCR：基于结构-识别-关系三元组范式的文档解析", "tldr": "MonkeyOCR是一个新的视觉-语言模型，通过结构-识别-关系（SRR）三元组范式实现文档解析，在准确性和速度上均超越现有模型，特别是在公式和表格处理方面表现出色，且部署高效。", "motivation": "现有的文档解析方法存在复杂的多工具流程（如MinerU的模块化方法）或处理整页文档时效率低下（如大型多模态LLM如Qwen-VL），这些都导致了效率低下和复杂性。", "method": "MonkeyOCR引入了结构-识别-关系（SRR）三元组范式。文档解析被抽象为三个基本问题：“它在哪里？”（结构）、“它是什么？”（识别）和“它是如何组织的？”（关系），分别对应于布局分析、内容识别和逻辑排序。这种分解平衡了准确性和速度。为了训练和评估，引入了迄今为止最全面的文档解析数据集MonkeyDoc（包含390万个实例，涵盖十多种文档类型，包括中文和英文）。", "result": "MonkeyOCR平均性能优于MinerU 5.1%，在处理公式时提升15.0%，表格时提升8.6%。3B参数模型超越了更大的顶级模型（如Qwen2.5-VL 72B和Gemini 2.5 Pro），在英文文档解析任务上达到了最先进的平均性能。处理多页文档的速度显著更快（每秒0.84页，而MinerU为0.65页，Qwen2.5-VL-7B为0.12页）。3B模型可在单个NVIDIA 3090 GPU上高效部署。", "conclusion": "MonkeyOCR通过其创新的SRR三元组范式，在文档解析领域实现了准确性和效率的显著提升，超越了现有最先进的模型，并提供了高效的部署方案。", "translation": "我们引入了MonkeyOCR，一个用于文档解析的视觉-语言模型，它通过利用结构-识别-关系（SRR）三元组范式提升了现有技术水平。这种设计简化了原本复杂的多种工具管线（如MinerU的模块化方法），并避免了使用大型端到端模型（例如Qwen-VL等大型多模态LLM）处理整页文档的低效率。在SRR中，文档解析被抽象为三个基本问题——“它在哪里？”（结构）、“它是什么？”（识别）和“它是如何组织的？”（关系）——分别对应于布局分析、内容识别和逻辑排序。这种专注的分解平衡了准确性和速度：它能够在不牺牲精度的前提下实现高效、可扩展的处理。为了训练和评估这种方法，我们引入了MonkeyDoc（迄今为止最全面的文档解析数据集），包含390万个实例，涵盖十多种中英文文档类型。实验表明，MonkeyOCR平均性能优于MinerU 5.1%，在处理挑战性内容如公式（+15.0%）和表格（+8.6%）方面有特别显著的改进。值得注意的是，我们的3B参数模型超越了更大且性能顶尖的模型，包括Qwen2.5-VL（72B）和Gemini 2.5 Pro，在英文文档解析任务上实现了最先进的平均性能。此外，MonkeyOCR处理多页文档的速度显著更快（每秒0.84页，而MinerU为0.65页，Qwen2.5-VL-7B为0.12页）。该3B模型可以高效部署在单个NVIDIA 3090 GPU上进行推理。代码和模型将在https://github.com/Yuliang-Liu/MonkeyOCR发布。", "summary": "MonkeyOCR是一个创新的视觉-语言文档解析模型，采用结构-识别-关系（SRR）三元组范式，旨在解决现有方法的复杂性和效率问题。该范式将文档解析分解为结构、识别和关系三个核心任务，实现了准确性和速度的平衡。模型在MonkeyDoc数据集上进行训练和评估，实验结果表明，MonkeyOCR在多项任务上超越了MinerU等现有模型，尤其在公式和表格处理方面表现突出。即使是3B参数的模型，也能在性能上超越大型多模态LLM，并且具有更高的处理速度和更低的部署成本。", "keywords": "文档解析, 视觉-语言模型, 结构-识别-关系, MonkeyOCR, MonkeyDoc"}}
{"id": "2506.05183", "pdf": "https://arxiv.org/pdf/2506.05183", "abs": "https://arxiv.org/abs/2506.05183", "authors": ["Zhicheng Yang", "Zhijiang Guo", "Yinya Huang", "Xiaodan Liang", "Yiwei Wang", "Jing Tang"], "title": "TreeRPO: Tree Relative Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "13pages, 6 figures", "summary": "Large Language Models (LLMs) have shown remarkable reasoning capabilities\nthrough Reinforcement Learning with Verifiable Rewards (RLVR) methods. However,\na key limitation of existing approaches is that rewards defined at the full\ntrajectory level provide insufficient guidance for optimizing the intermediate\nsteps of a reasoning process. To address this, we introduce \\textbf{\\name}, a\nnovel method that estimates the mathematical expectations of rewards at various\nreasoning steps using tree sampling. Unlike prior methods that rely on a\nseparate step reward model, \\name directly estimates these rewards through this\nsampling process. Building on the group-relative reward training mechanism of\nGRPO, \\name innovatively computes rewards based on step-level groups generated\nduring tree sampling. This advancement allows \\name to produce fine-grained and\ndense reward signals, significantly enhancing the learning process and overall\nperformance of LLMs. Experimental results demonstrate that our \\name algorithm\nsubstantially improves the average Pass@1 accuracy of Qwen-2.5-Math on test\nbenchmarks, increasing it from 19.0\\% to 35.5\\%. Furthermore, \\name\nsignificantly outperforms GRPO by 2.9\\% in performance while simultaneously\nreducing the average response length by 18.1\\%, showcasing its effectiveness\nand efficiency. Our code will be available at\n\\href{https://github.com/yangzhch6/TreeRPO}{https://github.com/yangzhch6/TreeRPO}.", "AI": {"title_translation": "TreeRPO：树状相对策略优化", "tldr": "TreeRPO通过树状采样估计推理中间步骤的奖励，为LLM提供细粒度且密集的奖励信号，显著提升了LLM在推理任务上的性能和效率。", "motivation": "现有方法中，在完整轨迹层面定义的奖励不足以指导大型语言模型（LLMs）推理过程中间步骤的优化。", "method": "TreeRPO是一种新颖的方法，它利用树状采样来估计不同推理步骤的奖励数学期望。与以往依赖独立步骤奖励模型的方法不同，TreeRPO通过采样过程直接估计这些奖励。它在GRPO的组相对奖励训练机制基础上，创新性地根据树状采样过程中生成的步骤级组来计算奖励，从而产生细粒度且密集的奖励信号。", "result": "TreeRPO算法显著提高了Qwen-2.5-Math在测试基准上的平均Pass@1准确率，从19.0%提升至35.5%。此外，TreeRPO在性能上显著优于GRPO 2.9%，同时将平均响应长度减少了18.1%。", "conclusion": "TreeRPO通过引入树状采样和步骤级组相对奖励机制，有效解决了LLM推理中间步骤奖励信号不足的问题，从而显著提升了LLM的推理性能和效率。", "translation": "大型语言模型（LLMs）通过可验证奖励强化学习（RLVR）方法展现出卓越的推理能力。然而，现有方法的一个关键限制是，在完整轨迹层面定义的奖励不足以为推理过程的中间步骤优化提供足够的指导。为了解决这个问题，我们引入了\\textbf{\\name}，这是一种新颖的方法，它使用树状采样来估计各种推理步骤的奖励数学期望。与依赖单独步骤奖励模型的先前方法不同，\\name通过这种采样过程直接估计这些奖励。在GRPO的组相对奖励训练机制基础上，\\name创新性地根据树状采样过程中生成的步骤级组来计算奖励。这一进步使得\\name能够产生细粒度且密集的奖励信号，显著增强了LLMs的学习过程和整体性能。实验结果表明，我们的\\name算法显著提高了Qwen-2.5-Math在测试基准上的平均Pass@1准确率，从19.0%提升至35.5%。此外，\\name在性能上显著优于GRPO 2.9%，同时将平均响应长度减少了18.1%，展示了其有效性和效率。我们的代码将在\\href{https://github.com/yangzhch6/TreeRPO}{https://github.com/yangzhch6/TreeRPO}提供。", "summary": "本论文提出了一种名为TreeRPO的新型方法，旨在解决大型语言模型（LLMs）在推理任务中，现有强化学习方法因轨迹级奖励信号不足而导致的中间步骤优化困难问题。TreeRPO通过树状采样直接估计并提供细粒度、密集的步骤级奖励信号，从而显著增强了LLM的学习过程和整体性能。实验结果表明，TreeRPO在Qwen-2.5-Math上将Pass@1准确率从19.0%提升至35.5%，并优于GRPO 2.9%，同时减少了18.1%的响应长度，展现了其有效性和效率。", "keywords": "大型语言模型, 强化学习, 策略优化, 树状采样, 奖励信号"}}
{"id": "2506.05221", "pdf": "https://arxiv.org/pdf/2506.05221", "abs": "https://arxiv.org/abs/2506.05221", "authors": ["Jianghao Wu", "Yicheng Wu", "Yutong Xie", "Wenjia Bai", "You Zhang", "Feilong Tang", "Yulong Li", "Yasmeen George", "Imran Razzak"], "title": "SAM-aware Test-time Adaptation for Universal Medical Image Segmentation", "categories": ["cs.CV"], "comment": "10 pages, 4 figures", "summary": "Universal medical image segmentation using the Segment Anything Model (SAM)\nremains challenging due to its limited adaptability to medical domains.\nExisting adaptations, such as MedSAM, enhance SAM's performance in medical\nimaging but at the cost of reduced generalization to unseen data. Therefore, in\nthis paper, we propose SAM-aware Test-Time Adaptation (SAM-TTA), a\nfundamentally different pipeline that preserves the generalization of SAM while\nimproving its segmentation performance in medical imaging via a test-time\nframework. SAM-TTA tackles two key challenges: (1) input-level discrepancies\ncaused by differences in image acquisition between natural and medical images\nand (2) semantic-level discrepancies due to fundamental differences in object\ndefinition between natural and medical domains (e.g., clear boundaries vs.\nambiguous structures). Specifically, our SAM-TTA framework comprises (1)\nSelf-adaptive Bezier Curve-based Transformation (SBCT), which adaptively\nconverts single-channel medical images into three-channel SAM-compatible inputs\nwhile maintaining structural integrity, to mitigate the input gap between\nmedical and natural images, and (2) Dual-scale Uncertainty-driven Mean Teacher\nadaptation (DUMT), which employs consistency learning to align SAM's internal\nrepresentations to medical semantics, enabling efficient adaptation without\nauxiliary supervision or expensive retraining. Extensive experiments on five\npublic datasets demonstrate that our SAM-TTA outperforms existing TTA\napproaches and even surpasses fully fine-tuned models such as MedSAM in certain\nscenarios, establishing a new paradigm for universal medical image\nsegmentation. Code can be found at https://github.com/JianghaoWu/SAM-TTA.", "AI": {"title_translation": "面向通用医学图像分割的SAM感知测试时间自适应", "tldr": "提出了一种名为SAM-TTA的测试时间自适应方法，旨在提高Segment Anything Model (SAM)在医学图像分割中的性能，同时保持其泛化能力，并通过实验证明其优于现有方法甚至某些微调模型。", "motivation": "Segment Anything Model (SAM)在医学图像分割中适应性有限，现有方法如MedSAM虽然提升了性能但牺牲了对未见数据的泛化能力。", "method": "本文提出了SAM感知测试时间自适应（SAM-TTA）框架，该框架包括两个关键组件：1) 自适应贝塞尔曲线变换（SBCT），用于将单通道医学图像转换为SAM兼容的三通道输入，以解决输入层面的差异；2) 双尺度不确定性驱动的平均教师自适应（DUMT），采用一致性学习来调整SAM的内部表示以适应医学语义，无需辅助监督或昂贵的再训练。", "result": "在五个公共数据集上进行了广泛实验，结果表明SAM-TTA优于现有的测试时间自适应（TTA）方法，在某些情况下甚至超越了MedSAM等完全微调的模型。", "conclusion": "SAM-TTA为通用医学图像分割建立了一种新范式，证明了其在提高SAM医学图像分割性能同时保持泛化能力方面的有效性。", "translation": "通用医学图像分割使用Segment Anything Model (SAM) 仍然具有挑战性，因为它对医学领域的适应性有限。现有的适应方法，例如MedSAM，虽然增强了SAM在医学成像中的性能，但代价是降低了对未见数据的泛化能力。因此，在本文中，我们提出了SAM感知测试时间自适应（SAM-TTA），这是一种根本不同的流程，它在提高SAM在医学成像中的分割性能的同时，通过测试时间框架保持了SAM的泛化能力。SAM-TTA解决了两个关键挑战：(1) 由自然图像和医学图像之间图像采集差异引起的输入层面差异；(2) 由于自然和医学领域之间对象定义的根本差异（例如，清晰边界与模糊结构）引起的语义层面差异。具体而言，我们的SAM-TTA框架包括：(1) 自适应贝塞尔曲线变换（SBCT），它自适应地将单通道医学图像转换为三通道SAM兼容输入，同时保持结构完整性，以减轻医学图像和自然图像之间的输入差距；(2) 双尺度不确定性驱动的平均教师自适应（DUMT），它采用一致性学习来调整SAM的内部表示以适应医学语义，从而实现高效适应，无需辅助监督或昂贵的再训练。在五个公共数据集上进行的广泛实验表明，我们的SAM-TTA优于现有TTA方法，甚至在某些情况下超越了MedSAM等完全微调的模型，为通用医学图像分割建立了一种新范式。代码可在https://github.com/JianghaoWu/SAM-TTA找到。", "summary": "本研究提出了一种名为SAM-TTA的测试时间自适应框架，以解决Segment Anything Model (SAM)在医学图像分割中适应性不足的问题。SAM-TTA旨在弥补自然图像与医学图像之间的输入和语义差异，通过自适应贝塞尔曲线变换（SBCT）处理输入兼容性，并利用双尺度不确定性驱动的平均教师自适应（DUMT）进行高效的语义对齐。实验结果表明，SAM-TTA在多个医学图像数据集上表现优异，超越了现有测试时间自适应方法，并在某些场景下甚至优于完全微调模型，为通用医学图像分割开辟了新途径。", "keywords": "医学图像分割, SAM, 测试时间自适应, 泛化能力, 贝塞尔曲线变换"}}
{"id": "2506.05196", "pdf": "https://arxiv.org/pdf/2506.05196", "abs": "https://arxiv.org/abs/2506.05196", "authors": ["Jifei Luo", "Wenzheng Wu", "Hantao Yao", "Lu Yu", "Changsheng Xu"], "title": "Locality Preserving Markovian Transition for Instance Retrieval", "categories": ["cs.LG"], "comment": "This paper has been accepted by ICML2025", "summary": "Diffusion-based re-ranking methods are effective in modeling the data\nmanifolds through similarity propagation in affinity graphs. However, positive\nsignals tend to diminish over several steps away from the source, reducing\ndiscriminative power beyond local regions. To address this issue, we introduce\nthe Locality Preserving Markovian Transition (LPMT) framework, which employs a\nlong-term thermodynamic transition process with multiple states for accurate\nmanifold distance measurement. The proposed LPMT first integrates diffusion\nprocesses across separate graphs using Bidirectional Collaborative Diffusion\n(BCD) to establish strong similarity relationships. Afterwards, Locality State\nEmbedding (LSE) encodes each instance into a distribution for enhanced local\nconsistency. These distributions are interconnected via the Thermodynamic\nMarkovian Transition (TMT) process, enabling efficient global retrieval while\nmaintaining local effectiveness. Experimental results across diverse tasks\nconfirm the effectiveness of LPMT for instance retrieval.", "AI": {"title_translation": "保持局部性的马尔可夫转移用于实例检索", "tldr": "本文提出了一种名为LPMT的新框架，通过结合双向协同扩散、局部性状态嵌入和热力学马尔可夫转移，解决了扩散重排序方法在局部区域外判别力下降的问题，有效提升了实例检索性能。", "motivation": "现有的基于扩散的重排序方法在亲和图中通过相似性传播来建模数据流形，但其正向信号在远离源头几步后会减弱，导致局部区域外的判别力下降。", "method": "本文提出了局部性保持马尔可夫转移（LPMT）框架。LPMT首先通过双向协同扩散（BCD）整合不同图上的扩散过程，以建立强相似性关系。随后，局部性状态嵌入（LSE）将每个实例编码为分布，以增强局部一致性。这些分布通过热力学马尔可夫转移（TMT）过程相互连接，从而在保持局部有效性的同时实现高效的全局检索。", "result": "在各种任务上的实验结果证实了LPMT在实例检索方面的有效性。", "conclusion": "LPMT框架通过其独特的设计，有效解决了扩散重排序方法在局部区域外判别力不足的问题，并在实例检索中展现出优越的性能。", "translation": "基于扩散的重排序方法在通过亲和图中的相似性传播来建模数据流形方面是有效的。然而，正向信号在远离源头几步后往往会减弱，从而降低了局部区域之外的判别力。为了解决这个问题，我们引入了局部性保持马尔可夫转移（LPMT）框架，该框架采用具有多个状态的长期热力学转移过程，以实现精确的流形距离测量。所提出的LPMT首先使用双向协同扩散（BCD）整合不同图上的扩散过程，以建立强大的相似性关系。之后，局部性状态嵌入（LSE）将每个实例编码为一个分布，以增强局部一致性。这些分布通过热力学马尔可夫转移（TMT）过程相互连接，从而在保持局部有效性的同时实现高效的全局检索。在各种任务上的实验结果证实了LPMT在实例检索方面的有效性。", "summary": "本文提出了一种名为局部性保持马尔可夫转移（LPMT）的新框架，旨在解决扩散重排序方法在远离源头时判别力下降的问题。LPMT通过双向协同扩散（BCD）建立强相似性，利用局部性状态嵌入（LSE）增强局部一致性，并通过热力学马尔可夫转移（TMT）实现高效的全局检索。实验结果验证了LPMT在实例检索中的有效性。", "keywords": "实例检索, 扩散重排序, 马尔可夫转移, 局部性保持, 流形学习"}}
{"id": "2506.04433", "pdf": "https://arxiv.org/pdf/2506.04433", "abs": "https://arxiv.org/abs/2506.04433", "authors": ["Walter Gubinelli", "Ryan Tetro", "Pietro Simeoni", "Luca Colombo", "Matteo Rinaldi"], "title": "Laterally Excited Bulk Acoustic Wave (LBAW) X-Cut Lithium Niobate Resonators", "categories": ["eess.SY", "cs.SY"], "comment": "4 pages, 7 figures, IFCS-EFTF 2025 conference", "summary": "In this work, Laterally excited Bulk Acoustic Wave (LBAW) resonators on X-cut\nLithium Niobate (LiNbO3) and, for the first time their higher-order overtones\n(LOBAW) are demonstrated by embedding interdigitated electrodes recessed into\nthe piezoelectric thin film, allowing to exploit both S0 and SH0 vibrational\nmodes. This recessed electrode architecture decouples the dispersion relation\nfrom film thickness, enabling lithographic tuning of resonance frequency and\non-chip multi-frequency scaling on a single substrate, while concurrently\nincreasing static capacitance density (C0) and reducing ohmic losses (Rs). The\nexcited SH0 modes exhibits Figures of Merit (FoM) of 437 at 673 MHz for the\nfundamental tone and 53 at 1.05 GHz for the overtone. The proposed architecture\nholds large potential for future 5G/6G advanced radio frequency front-end\nmodules, enabling on-chip multi-frequency scaling and improved performance.", "AI": {"title_translation": "横向激励体声波 (LBAW) X切割铌酸锂谐振器", "tldr": "该研究首次展示了X切割铌酸锂上的LBAW谐振器及其高阶泛音(LOBAW)，通过嵌入凹进式叉指电极实现了优异的性能和片上多频可扩展性，对5G/6G射频模块有巨大潜力。", "motivation": "提升未来5G/6G高级射频前端模块的性能，实现片上多频可扩展性。", "method": "通过将叉指电极嵌入压电薄膜中，形成凹进式电极结构，首次演示了X切割铌酸锂上的横向激励体声波(LBAW)谐振器及其高阶泛音(LOBAW)。这种结构允许利用S0和SH0振动模式，解耦了色散关系与薄膜厚度的关联，实现了谐振频率的光刻调谐和单基板上的片上多频缩放，同时增加了静态电容密度(C0)并降低了欧姆损耗(Rs)。", "result": "激发的SH0模式在基频673 MHz时表现出437的品质因数(FoM)，在泛音1.05 GHz时表现出53的品质因数。该架构能够实现谐振频率的光刻调谐和单基板上的片上多频缩放，并同时提高静态电容密度(C0)和降低欧姆损耗(Rs)。", "conclusion": "所提出的凹进式电极架构在X切割铌酸锂LBAW谐振器上表现出优异的性能和多频可扩展性，对未来5G/6G高级射频前端模块具有巨大的应用潜力。", "translation": "在这项工作中，首次展示了在X切割铌酸锂（LiNbO3）上通过将叉指电极凹陷嵌入压电薄膜中来实现横向激励体声波（LBAW）谐振器及其高阶泛音（LOBAW），从而能够利用S0和SH0两种振动模式。这种凹陷电极结构将色散关系与薄膜厚度解耦，从而实现了谐振频率的光刻调谐和在单个基板上的片上多频缩放，同时提高了静态电容密度（C0）并降低了欧姆损耗（Rs）。激发的SH0模式在673 MHz的基频下表现出437的品质因数（FoM），在1.05 GHz的泛音下表现出53的品质因数。所提出的架构对未来的5G/6G高级射频前端模块具有巨大潜力，能够实现片上多频缩放和性能提升。", "summary": "本文首次展示了在X切割铌酸锂上通过嵌入凹进式叉指电极实现的横向激励体声波(LBAW)谐振器及其高阶泛音(LOBAW)。这种独特的电极结构解耦了色散关系与薄膜厚度，从而支持谐振频率的光刻调谐和单基板上的片上多频缩放，并能同时提高静态电容密度和降低欧姆损耗。实验结果显示，激发的SH0模式在基频673 MHz时品质因数达到437，在1.05 GHz泛音时品质因数达到53。该架构为未来5G/6G高级射频前端模块的性能提升和片上多频集成提供了巨大潜力。", "keywords": "LBAW, 铌酸锂, 谐振器, 5G/6G, 射频模块"}}
{"id": "2506.05200", "pdf": "https://arxiv.org/pdf/2506.05200", "abs": "https://arxiv.org/abs/2506.05200", "authors": ["Gen Li", "Yuchen Jiao", "Yu Huang", "Yuting Wei", "Yuxin Chen"], "title": "Transformers Meet In-Context Learning: A Universal Approximation Theory", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Modern large language models are capable of in-context learning, the ability\nto perform new tasks at inference time using only a handful of input-output\nexamples in the prompt, without any fine-tuning or parameter updates. We\ndevelop a universal approximation theory to better understand how transformers\nenable in-context learning. For any class of functions (each representing a\ndistinct task), we demonstrate how to construct a transformer that, without any\nfurther weight updates, can perform reliable prediction given only a few\nin-context examples. In contrast to much of the recent literature that frames\ntransformers as algorithm approximators -- i.e., constructing transformers to\nemulate the iterations of optimization algorithms as a means to approximate\nsolutions of learning problems -- our work adopts a fundamentally different\napproach rooted in universal function approximation. This alternative approach\noffers approximation guarantees that are not constrained by the effectiveness\nof the optimization algorithms being approximated, thereby extending far beyond\nconvex problems and linear function classes. Our construction sheds light on\nhow transformers can simultaneously learn general-purpose representations and\nadapt dynamically to in-context examples.", "AI": {"title_translation": "Transformer 遇到语境学习：一种普适逼近理论", "tldr": "本文提出一种普适逼近理论，解释Transformer如何通过普适函数逼近实现语境学习，无需微调即可动态适应新任务。", "motivation": "为了更好地理解Transformer如何实现语境学习能力，即仅通过少量上下文示例即可在推理时执行新任务，而无需任何微调或参数更新。", "method": "本文发展了一种普适逼近理论，展示了如何构建一个Transformer，使其在不进行任何权重更新的情况下，仅给定少量语境示例即可执行可靠的预测。与将Transformer视为算法逼近器的方法不同，本文采用基于普适函数逼近的根本不同方法。", "result": "本文构建的Transformer可以在不进行权重更新的情况下，仅通过少量语境示例进行可靠预测。这种方法提供了不受所逼近优化算法有效性限制的逼近保证，并且超越了凸问题和线性函数类。", "conclusion": "本文的构建揭示了Transformer如何同时学习通用表示并动态适应语境示例。", "translation": "现代大型语言模型具备语境学习能力，即在推理时仅使用提示中的少量输入-输出示例即可执行新任务，无需任何微调或参数更新。我们发展了一种普适逼近理论，以更好地理解Transformer如何实现语境学习。对于任何函数类（每个代表一个不同的任务），我们展示了如何构建一个Transformer，使其在不进行任何进一步的权重更新的情况下，仅给定少量语境示例即可执行可靠的预测。与最近许多将Transformer视为算法逼近器（即构建Transformer来模拟优化算法的迭代以逼近学习问题的解决方案）的文献不同，我们的工作采用了一种根本不同的方法，植根于普适函数逼近。这种替代方法提供了不受所逼近优化算法有效性限制的逼近保证，从而远远超出了凸问题和线性函数类。我们的构建揭示了Transformer如何同时学习通用表示并动态适应语境示例。", "summary": "本文提出一种普适逼近理论，以深入理解Transformer如何实现语境学习。研究表明，可以构建一个Transformer，使其无需权重更新，仅凭少量语境示例即可对新任务进行可靠预测。与现有将Transformer视为算法逼近器的工作不同，本文采用基于普适函数逼近的方法，提供了更广泛的逼近保证，并阐明了Transformer学习通用表示和动态适应的能力。", "keywords": "Transformer, 语境学习, 普适逼近理论, 大语言模型, 函数逼近"}}
{"id": "2506.05260", "pdf": "https://arxiv.org/pdf/2506.05260", "abs": "https://arxiv.org/abs/2506.05260", "authors": ["Xiaodong Wang", "Jinfa Huang", "Li Yuan", "Peixi Peng"], "title": "LeanPO: Lean Preference Optimization for Likelihood Alignment in Video-LLMs", "categories": ["cs.CV"], "comment": "Code: https://github.com/Wang-Xiaodong1899/LeanPO", "summary": "Most Video Large Language Models (Video-LLMs) adopt preference alignment\ntechniques, e.g., DPO~\\citep{rafailov2024dpo}, to optimize the reward margin\nbetween a winning response ($y_w$) and a losing response ($y_l$). However, the\nlikelihood displacement observed in DPO indicates that both $\\log \\pi_\\theta\n(y_w\\mid x)$ and $\\log \\pi_\\theta (y_l\\mid x) $ often decrease during training,\ninadvertently boosting the probabilities of non-target responses. In this\npaper, we systematically revisit this phenomenon from LLMs to Video-LLMs,\nshowing that it intensifies when dealing with the redundant complexity of video\ncontent. To alleviate the impact of this phenomenon, we propose \\emph{Lean\nPreference Optimization} (LeanPO), a reference-free approach that reformulates\nthe implicit reward as the average likelihood of the response with respect to\nthe policy model. A key component of LeanPO is the reward-trustworthiness\ncorrelated self-generated preference data pipeline, which carefully infuses\nrelevant prior knowledge into the model while continuously refining the\npreference data via self-reflection. This allows the policy model to obtain\nhigh-quality paired data and accurately estimate the newly defined reward, thus\nmitigating the unintended drop. In addition, we introduce a dynamic label\nsmoothing strategy that mitigates the impact of noise in responses from diverse\nvideo content, preventing the model from overfitting to spurious details.\nExtensive experiments demonstrate that LeanPO significantly enhances the\nperformance of state-of-the-art Video-LLMs, consistently boosting baselines of\nvarying capacities with minimal additional training overhead. Moreover, LeanPO\noffers a simple yet effective solution for aligning Video-LLM preferences with\nhuman trustworthiness, paving the way toward the reliable and efficient\nVideo-LLMs.", "AI": {"title_translation": "LeanPO：视频大语言模型中用于似然对齐的精益偏好优化", "tldr": "LeanPO提出一种无参考方法，通过重新定义奖励和自生成偏好数据，解决了视频大语言模型中DPO训练期间出现的似然位移问题，显著提升了模型性能并降低了训练开销。", "motivation": "现有的视频大语言模型（Video-LLMs）中，DPO等偏好对齐技术在训练过程中常导致获胜响应和失败响应的似然同时下降，无意中提高了非目标响应的概率。这种现象在处理视频内容的冗余复杂性时会加剧。", "method": "本文提出了精益偏好优化（LeanPO），这是一种无参考方法，将隐式奖励重新定义为响应相对于策略模型的平均似然。LeanPO的关键组成部分是奖励信任度相关的自生成偏好数据管道，该管道通过自反思不断完善偏好数据。此外，还引入了动态标签平滑策略，以减轻来自多样视频内容响应中的噪声影响。", "result": "LeanPO显著增强了最先进视频大语言模型的性能，以最小的额外训练开销持续提升了不同容量的基线模型。", "conclusion": "LeanPO为将视频大语言模型的偏好与人类信任度对齐提供了一个简单而有效的解决方案，为开发可靠和高效的视频大语言模型铺平了道路。", "translation": "大多数视频大语言模型（Video-LLMs）采用偏好对齐技术，例如DPO~\\citep{rafailov2024dpo}，来优化获胜响应（$y_w$）和失败响应（$y_l$）之间的奖励裕度。然而，DPO中观察到的似然位移表明，在训练过程中，$\\log \\pi_\\theta (y_w\\mid x)$ 和 $\\log \\pi_\\theta (y_l\\mid x)$ 通常都会下降，无意中提升了非目标响应的概率。在本文中，我们系统地重新审视了从大语言模型到视频大语言模型的这一现象，表明在处理视频内容的冗余复杂性时，这种现象会加剧。为了减轻这种现象的影响，我们提出了精益偏好优化（LeanPO），这是一种无参考方法，它将隐式奖励重新表述为响应相对于策略模型的平均似然。LeanPO的一个关键组成部分是奖励信任度相关的自生成偏好数据管道，该管道在将相关先验知识小心地注入模型的同时，通过自反思不断完善偏好数据。这使得策略模型能够获得高质量的配对数据并准确估计新定义的奖励，从而减轻了意外下降。此外，我们引入了一种动态标签平滑策略，以减轻来自多样视频内容响应中的噪声影响，防止模型对虚假细节过拟合。广泛的实验表明，LeanPO显著增强了最先进视频大语言模型的性能，以最小的额外训练开销持续提升了不同容量的基线模型。此外，LeanPO提供了一个简单而有效的解决方案，用于将视频大语言模型的偏好与人类信任度对齐，为实现可靠和高效的视频大语言模型铺平了道路。", "summary": "本文针对视频大语言模型（Video-LLMs）中DPO训练导致的似然位移问题，提出了精益偏好优化（LeanPO）方法。该方法通过将隐式奖励重新定义为响应的平均似然，并结合奖励信任度相关的自生成偏好数据管道和动态标签平滑策略，有效缓解了似然下降和噪声影响。实验证明，LeanPO显著提升了现有Video-LLMs的性能，且训练开销极小，为实现可靠高效的Video-LLMs提供了新的途径。", "keywords": "视频大语言模型, 偏好优化, 似然对齐, LeanPO, DPO"}}
{"id": "2506.05214", "pdf": "https://arxiv.org/pdf/2506.05214", "abs": "https://arxiv.org/abs/2506.05214", "authors": ["Jingyu Hu", "Hongbo Bo", "Jun Hong", "Xiaowei Liu", "Weiru Liu"], "title": "Mitigating Degree Bias Adaptively with Hard-to-Learn Nodes in Graph Contrastive Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Graph Neural Networks (GNNs) often suffer from degree bias in node\nclassification tasks, where prediction performance varies across nodes with\ndifferent degrees. Several approaches, which adopt Graph Contrastive Learning\n(GCL), have been proposed to mitigate this bias. However, the limited number of\npositive pairs and the equal weighting of all positives and negatives in GCL\nstill lead to low-degree nodes acquiring insufficient and noisy information.\nThis paper proposes the Hardness Adaptive Reweighted (HAR) contrastive loss to\nmitigate degree bias. It adds more positive pairs by leveraging node labels and\nadaptively weights positive and negative pairs based on their learning\nhardness. In addition, we develop an experimental framework named SHARP to\nextend HAR to a broader range of scenarios. Both our theoretical analysis and\nexperiments validate the effectiveness of SHARP. The experimental results\nacross four datasets show that SHARP achieves better performance against\nbaselines at both global and degree levels.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04436", "pdf": "https://arxiv.org/pdf/2506.04436", "abs": "https://arxiv.org/abs/2506.04436", "authors": ["Alperen A. Ergür", "Josué Tonelli-Cueto", "Elias Tsigaridas"], "title": "Beyond Worst-Case Analysis for Symbolic Computation: Root Isolation Algorithms", "categories": ["cs.SC", "cs.CC", "math.AG", "math.PR", "65H04, 14Q20, 68W30"], "comment": "27 pages. Extended journal-version of arXiv:2202.06428", "summary": "We introduce beyond-worst-case analysis into symbolic computation. This is an\nextensive field which almost entirely relies on worst-case bit complexity, and\nwe start from a basic problem in the field: isolating the real roots of\nunivariate polynomials. This is a fundamental problem in symbolic computation\nand it is arguably one of the most basic problems in computational mathematics.\nThe problem has a long history decorated with numerous ingenious algorithms and\nfurnishes an active area of research. However, most available results in\nliterature either focus on worst-case analysis in the bit complexity model or\nsimply provide experimental benchmarking without any theoretical justifications\nof the observed results. We aim to address the discrepancy between practical\nperformance of root isolation algorithms and prescriptions of worst-case\ncomplexity theory: We develop a smoothed analysis framework for polynomials\nwith integer coefficients to bridge this gap. We demonstrate (quasi-)linear\n(expected and smoothed) complexity bounds for Descartes algorithm, that is one\nmost well know symbolic algorithms for isolating the real roots of univariate\npolynomials with integer coefficients. Our results explain the surprising\nefficiency of Descartes solver in comparison to sophisticated algorithms that\nhave superior worst-case complexity. We also analyse the Sturm solver, ANewDsc\na symbolic-numeric algorithm that combines Descartes with Newton operator, and\na symbolic algorithm for sparse polynomials.", "AI": {"title_translation": "符号计算的超越最坏情况分析：根隔离算法", "tldr": "本文将超越最坏情况分析引入符号计算，并为 Descartes 算法证明了接近线性的平滑复杂度界限，解释了其在实践中的高效性。", "motivation": "符号计算领域几乎完全依赖最坏情况位复杂度分析，但这种理论与实际算法性能之间存在较大差距，尤其是在根隔离问题上。现有的文献要么侧重于最坏情况分析，要么只提供实验基准测试而缺乏理论解释。", "method": "引入超越最坏情况分析，特别是为整数系数多项式开发了平滑分析框架，并分析了 Descartes、Sturm、ANewDsc 以及稀疏多项式算法。", "result": "证明了 Descartes 算法的 (近似) 线性（期望和平滑）复杂度界限，解释了其在实际中比理论最坏情况复杂度更高的算法更有效的原因。", "conclusion": "通过平滑分析弥合了根隔离算法理论最坏情况复杂度与实际性能之间的差距。", "translation": "我们将超越最坏情况分析引入符号计算。这是一个广泛的领域，几乎完全依赖于最坏情况的位复杂度，我们从该领域的一个基本问题开始：隔离单变量多项式的实根。这是符号计算中的一个基本问题，可以说是计算数学中最基本的问题之一。这个问题历史悠久，涌现了无数巧妙的算法，是一个活跃的研究领域。然而，现有文献中的大多数结果要么侧重于位复杂度模型中的最坏情况分析，要么仅提供实验基准测试而没有任何对观察结果的理论证明。我们的目标是解决根隔离算法的实际性能与最坏情况复杂度理论预测之间的差异：我们开发了一个针对整数系数多项式的平滑分析框架来弥合这一差距。我们证明了 Descartes 算法的（准）线性（期望和平滑）复杂度界限，这是最著名的用于隔离整数系数单变量多项式实根的符号算法之一。我们的结果解释了 Descartes 求解器与具有更优越的最坏情况复杂度的复杂算法相比，其令人惊讶的效率。我们还分析了 Sturm 求解器、结合了 Descartes 和牛顿算子的符号数值算法 ANewDsc，以及一个用于稀疏多项式的符号算法。", "summary": "本文将超越最坏情况分析引入符号计算领域，重点研究了根隔离问题。通过开发平滑分析框架，为 Descartes 算法证明了接近线性的复杂度界限，从而解释了其在实践中的高效性，并分析了其他几种根隔离算法。", "keywords": "超越最坏情况分析, 平滑分析, 根隔离, 符号计算, Descartes 算法"}}
{"id": "2506.05263", "pdf": "https://arxiv.org/pdf/2506.05263", "abs": "https://arxiv.org/abs/2506.05263", "authors": ["Juan E. Tapia", "Christoph Busch"], "title": "Can Foundation Models Generalise the Presentation Attack Detection Capabilities on ID Cards?", "categories": ["cs.CV"], "comment": null, "summary": "Nowadays, one of the main challenges in presentation attack detection (PAD)\non ID cards is obtaining generalisation capabilities for a diversity of\ncountries that are issuing ID cards. Most PAD systems are trained on one, two,\nor three ID documents because of privacy protection concerns. As a result, they\ndo not obtain competitive results for commercial purposes when tested in an\nunknown new ID card country. In this scenario, Foundation Models (FM) trained\non huge datasets can help to improve generalisation capabilities. This work\nintends to improve and benchmark the capabilities of FM and how to use them to\nadapt the generalisation on PAD of ID Documents. Different test protocols were\nused, considering zero-shot and fine-tuning and two different ID card datasets.\nOne private dataset based on Chilean IDs and one open-set based on three ID\ncountries: Finland, Spain, and Slovakia. Our findings indicate that bona fide\nimages are the key to generalisation.", "AI": {"title_translation": "基础模型能否泛化身份证件演示攻击检测能力？", "tldr": "基础模型可以帮助泛化身份证件演示攻击检测，真实图像是关键。", "motivation": "身份证件演示攻击检测（PAD）的主要挑战是在不同国家实现泛化能力，因为隐私保护限制了训练数据的多样性。现有系统在未知国家表现不佳。预训练在大型数据集上的基础模型有望改善泛化能力。", "method": "本文探讨使用基础模型来改进和评估身份证件PAD的泛化能力。使用了零样本和微调等不同测试协议，并在两个身份证件数据集上进行了实验：一个智利身份证件的私有数据集和一个包含芬兰、西班牙、斯洛伐克三个国家身份证件的开放数据集。", "result": "研究结果表明，真实图像是实现泛化的关键。", "conclusion": "Not mentioned in abstract", "translation": "如今，身份证件演示攻击检测（PAD）的主要挑战之一是获得针对发行身份证件的多个国家的泛化能力。出于隐私保护的考虑，大多数PAD系统仅在一种、两种或三种身份证件上进行训练。因此，当在未知的新身份证件国家进行测试时，它们无法获得具有商业竞争力的结果。在这种情况下，在大型数据集上训练的基础模型（FM）可以帮助提高泛化能力。这项工作旨在改进和评估基础模型的能力以及如何使用它们来适应身份证件PAD的泛化。考虑了零样本和微调等不同的测试协议，并使用了两个不同的身份证件数据集。一个基于智利身份证件的私有数据集和一个基于芬兰、西班牙、斯洛伐克三个国家身份证件的开放数据集。我们的研究结果表明，真实图像是实现泛化的关键。", "summary": "本文研究了如何利用基础模型提高身份证件演示攻击检测（PAD）系统在不同国家的泛化能力。由于训练数据有限，现有系统在泛化方面存在困难。研究在两个数据集上使用基础模型，探索了零样本和微调等不同方法，发现真实图像对于泛化至关重要。", "keywords": "基础模型, 演示攻击检测, 身份证件, 泛化, 真实图像"}}
{"id": "2506.05215", "pdf": "https://arxiv.org/pdf/2506.05215", "abs": "https://arxiv.org/abs/2506.05215", "authors": ["Zhan Yu"], "title": "Learning Theory of Decentralized Robust Kernel-Based Learning Algorithm", "categories": ["cs.LG"], "comment": null, "summary": "We propose a new decentralized robust kernel-based learning algorithm within\nthe framework of reproducing kernel Hilbert space (RKHS) by utilizing a\nnetworked system that can be represented as a connected graph. The robust loss\nfunction $\\mathcal{L}_\\sigma$ induced by a windowing function $W$ and a\nrobustness scaling parameter $\\sigma>0$, can encompass a broad spectrum of\nrobust losses. Consequently, the proposed algorithm effectively provides a\nunified decentralized learning framework for robust regression, which\nfundamentally differs from the existing distributed robust kernel learning\nschemes, all of which are divide-and-conquer based. We rigorously establish the\nlearning theory and offer a comprehensive convergence analysis for the\nalgorithm. We show each local robust estimator generated from the decentralized\nalgorithm can be utilized to approximate the regression function. Based on\nkernel-based integral operator techniques, we derive general high confidence\nconvergence bounds for each local approximating sequence in terms of the mean\nsquare distance, RKHS norm, and generalization error, respectively. Moreover,\nwe provide rigorous selection rules for local sample size and show that, under\nproperly selected step size and scaling parameter $\\sigma$, the decentralized\nrobust algorithm can achieve optimal learning rates (up to logarithmic factors)\nin both norms. The parameter $\\sigma$ is shown to be essential for enhancing\nrobustness while also ensuring favorable convergence behavior. The intrinsic\nconnection among decentralization, sample selection, robustness of the\nalgorithm, and its convergence is clearly reflected.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05274", "pdf": "https://arxiv.org/pdf/2506.05274", "abs": "https://arxiv.org/abs/2506.05274", "authors": ["Animesh Gupta", "Jay Parmar", "Ishan Rajendrakumar Dave", "Mubarak Shah"], "title": "From Play to Replay: Composed Video Retrieval for Temporally Fine-Grained Videos", "categories": ["cs.CV"], "comment": null, "summary": "Composed Video Retrieval (CoVR) retrieves a target video given a query video\nand a modification text describing the intended change. Existing CoVR\nbenchmarks emphasize appearance shifts or coarse event changes and therefore do\nnot test the ability to capture subtle, fast-paced temporal differences. We\nintroduce TF-CoVR, the first large-scale benchmark dedicated to temporally\nfine-grained CoVR. TF-CoVR focuses on gymnastics and diving and provides 180K\ntriplets drawn from FineGym and FineDiving. Previous CoVR benchmarks focusing\non temporal aspect, link each query to a single target segment taken from the\nsame video, limiting practical usefulness. In TF-CoVR, we instead construct\neach <query, modification> pair by prompting an LLM with the label differences\nbetween clips drawn from different videos; every pair is thus associated with\nmultiple valid target videos (3.9 on average), reflecting real-world tasks such\nas sports-highlight generation. To model these temporal dynamics we propose\nTF-CoVR-Base, a concise two-stage training framework: (i) pre-train a video\nencoder on fine-grained action classification to obtain temporally\ndiscriminative embeddings; (ii) align the composed query with candidate videos\nusing contrastive learning. We conduct the first comprehensive study of image,\nvideo, and general multimodal embedding (GME) models on temporally fine-grained\ncomposed retrieval in both zero-shot and fine-tuning regimes. On TF-CoVR,\nTF-CoVR-Base improves zero-shot mAP@50 from 5.92 (LanguageBind) to 7.51, and\nafter fine-tuning raises the state-of-the-art from 19.83 to 25.82.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05216", "pdf": "https://arxiv.org/pdf/2506.05216", "abs": "https://arxiv.org/abs/2506.05216", "authors": ["Tyler Chen", "Akshay Seshadri", "Mattia J. Villani", "Pradeep Niroula", "Shouvanik Chakrabarti", "Archan Ray", "Pranav Deshpande", "Romina Yalovetzky", "Marco Pistoia", "Niraj Kumar"], "title": "A Unified Framework for Provably Efficient Algorithms to Estimate Shapley Values", "categories": ["cs.LG", "cs.DS", "quant-ph"], "comment": "44 pages, 7 figures, 7 tables", "summary": "Shapley values have emerged as a critical tool for explaining which features\nimpact the decisions made by machine learning models. However, computing exact\nShapley values is difficult, generally requiring an exponential (in the feature\ndimension) number of model evaluations. To address this, many model-agnostic\nrandomized estimators have been developed, the most influential and widely used\nbeing the KernelSHAP method (Lundberg & Lee, 2017). While related estimators\nsuch as unbiased KernelSHAP (Covert & Lee, 2021) and LeverageSHAP (Musco &\nWitter, 2025) are known to satisfy theoretical guarantees, bounds for\nKernelSHAP have remained elusive. We describe a broad and unified framework\nthat encompasses KernelSHAP and related estimators constructed using both with\nand without replacement sampling strategies. We then prove strong\nnon-asymptotic theoretical guarantees that apply to all estimators from our\nframework. This provides, to the best of our knowledge, the first theoretical\nguarantees for KernelSHAP and sheds further light on tradeoffs between existing\nestimators. Through comprehensive benchmarking on small and medium dimensional\ndatasets for Decision-Tree models, we validate our approach against exact\nShapley values, consistently achieving low mean squared error with modest\nsample sizes. Furthermore, we make specific implementation improvements to\nenable scalability of our methods to high-dimensional datasets. Our methods,\ntested on datasets such MNIST and CIFAR10, provide consistently better results\ncompared to the KernelSHAP library.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05280", "pdf": "https://arxiv.org/pdf/2506.05280", "abs": "https://arxiv.org/abs/2506.05280", "authors": ["Nan Wang", "Yuantao Chen", "Lixing Xiao", "Weiqing Xiao", "Bohan Li", "Zhaoxi Chen", "Chongjie Ye", "Shaocong Xu", "Saining Zhang", "Ziyang Yan", "Pierre Merriaux", "Lei Lei", "Tianfan Xue", "Hao Zhao"], "title": "Unifying Appearance Codes and Bilateral Grids for Driving Scene Gaussian Splatting", "categories": ["cs.CV"], "comment": "Project page: https://bigcileng.github.io/bilateral-driving; Code:\n  https://github.com/BigCiLeng/bilateral-driving", "summary": "Neural rendering techniques, including NeRF and Gaussian Splatting (GS), rely\non photometric consistency to produce high-quality reconstructions. However, in\nreal-world scenarios, it is challenging to guarantee perfect photometric\nconsistency in acquired images. Appearance codes have been widely used to\naddress this issue, but their modeling capability is limited, as a single code\nis applied to the entire image. Recently, the bilateral grid was introduced to\nperform pixel-wise color mapping, but it is difficult to optimize and constrain\neffectively. In this paper, we propose a novel multi-scale bilateral grid that\nunifies appearance codes and bilateral grids. We demonstrate that this approach\nsignificantly improves geometric accuracy in dynamic, decoupled autonomous\ndriving scene reconstruction, outperforming both appearance codes and bilateral\ngrids. This is crucial for autonomous driving, where accurate geometry is\nimportant for obstacle avoidance and control. Our method shows strong results\nacross four datasets: Waymo, NuScenes, Argoverse, and PandaSet. We further\ndemonstrate that the improvement in geometry is driven by the multi-scale\nbilateral grid, which effectively reduces floaters caused by photometric\ninconsistency.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05229", "pdf": "https://arxiv.org/pdf/2506.05229", "abs": "https://arxiv.org/abs/2506.05229", "authors": ["Danil Sivtsov", "Ivan Rodkin", "Gleb Kuzmin", "Yuri Kuratov", "Ivan Oseledets"], "title": "Diagonal Batching Unlocks Parallelism in Recurrent Memory Transformers for Long Contexts", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Transformer models struggle with long-context inference due to their\nquadratic time and linear memory complexity. Recurrent Memory Transformers\n(RMTs) offer a solution by reducing the asymptotic cost to linear time and\nconstant memory usage. However, their memory update mechanism leads to\nsequential execution, causing a performance bottleneck.\n  We introduce Diagonal Batching, a scheduling scheme that unlocks parallelism\nacross segments in RMTs while preserving exact recurrence. This approach\neliminates the sequential constraint, enabling efficient GPU inference even for\nsingle long-context inputs without complex batching and pipelining techniques.\nBecause the technique is purely a run-time computation reordering, existing RMT\nmodels adopt it with no retraining.\n  Applied to a LLaMA-1B ARMT model, Diagonal Batching yields a 3.3x speedup\nover standard full-attention LLaMA-1B and a 1.8x speedup over the sequential\nRMT implementation on 131,072-token sequences. By removing sequential\nbottleneck, Diagonal Batching reduces inference cost and latency, thereby\nstrengthening RMTs as a practical solution for real-world, long-context\napplications.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05231", "pdf": "https://arxiv.org/pdf/2506.05231", "abs": "https://arxiv.org/abs/2506.05231", "authors": ["Severi Rissanen", "RuiKang OuYang", "Jiajun He", "Wenlin Chen", "Markus Heinonen", "Arno Solin", "José Miguel Hernández-Lobato"], "title": "Progressive Tempering Sampler with Diffusion", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted for publication at ICML 2025", "summary": "Recent research has focused on designing neural samplers that amortize the\nprocess of sampling from unnormalized densities. However, despite significant\nadvancements, they still fall short of the state-of-the-art MCMC approach,\nParallel Tempering (PT), when it comes to the efficiency of target evaluations.\nOn the other hand, unlike a well-trained neural sampler, PT yields only\ndependent samples and needs to be rerun -- at considerable computational cost\n-- whenever new samples are required. To address these weaknesses, we propose\nthe Progressive Tempering Sampler with Diffusion (PTSD), which trains diffusion\nmodels sequentially across temperatures, leveraging the advantages of PT to\nimprove the training of neural samplers. We also introduce a novel method to\ncombine high-temperature diffusion models to generate approximate\nlower-temperature samples, which are minimally refined using MCMC and used to\ntrain the next diffusion model. PTSD enables efficient reuse of sample\ninformation across temperature levels while generating well-mixed, uncorrelated\nsamples. Our method significantly improves target evaluation efficiency,\noutperforming diffusion-based neural samplers.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04739", "pdf": "https://arxiv.org/pdf/2506.04739", "abs": "https://arxiv.org/abs/2506.04739", "authors": ["Ziyi Zhou", "Xiaoming Zhang", "Litian Zhang", "Yibo Zhang", "Zhenyu Guan", "Chaozhuo Li", "Philip S. Yu"], "title": "Lifelong Evolution: Collaborative Learning between Large and Small Language Models for Continuous Emergent Fake News Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The widespread dissemination of fake news on social media has significantly\nimpacted society, resulting in serious consequences. Conventional deep learning\nmethodologies employing small language models (SLMs) suffer from extensive\nsupervised training requirements and difficulties adapting to evolving news\nenvironments due to data scarcity and distribution shifts. Large language\nmodels (LLMs), despite robust zero-shot capabilities, fall short in accurately\ndetecting fake news owing to outdated knowledge and the absence of suitable\ndemonstrations. In this paper, we propose a novel Continuous Collaborative\nEmergent Fake News Detection (C$^2$EFND) framework to address these challenges.\nThe C$^2$EFND framework strategically leverages both LLMs' generalization power\nand SLMs' classification expertise via a multi-round collaborative learning\nframework. We further introduce a lifelong knowledge editing module based on a\nMixture-of-Experts architecture to incrementally update LLMs and a replay-based\ncontinue learning method to ensure SLMs retain prior knowledge without\nretraining entirely. Extensive experiments on Pheme and Twitter16 datasets\ndemonstrate that C$^2$EFND significantly outperforms existed methods,\neffectively improving detection accuracy and adaptability in continuous\nemergent fake news scenarios.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05284", "pdf": "https://arxiv.org/pdf/2506.05284", "abs": "https://arxiv.org/abs/2506.05284", "authors": ["Tong Wu", "Shuai Yang", "Ryan Po", "Yinghao Xu", "Ziwei Liu", "Dahua Lin", "Gordon Wetzstein"], "title": "Video World Models with Long-term Spatial Memory", "categories": ["cs.CV"], "comment": "Project page: https://spmem.github.io/", "summary": "Emerging world models autoregressively generate video frames in response to\nactions, such as camera movements and text prompts, among other control\nsignals. Due to limited temporal context window sizes, these models often\nstruggle to maintain scene consistency during revisits, leading to severe\nforgetting of previously generated environments. Inspired by the mechanisms of\nhuman memory, we introduce a novel framework to enhancing long-term consistency\nof video world models through a geometry-grounded long-term spatial memory. Our\nframework includes mechanisms to store and retrieve information from the\nlong-term spatial memory and we curate custom datasets to train and evaluate\nworld models with explicitly stored 3D memory mechanisms. Our evaluations show\nimproved quality, consistency, and context length compared to relevant\nbaselines, paving the way towards long-term consistent world generation.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05233", "pdf": "https://arxiv.org/pdf/2506.05233", "abs": "https://arxiv.org/abs/2506.05233", "authors": ["Johannes von Oswald", "Nino Scherrer", "Seijin Kobayashi", "Luca Versari", "Songlin Yang", "Maximilian Schlegel", "Kaitlin Maile", "Yanick Schimpf", "Oliver Sieberling", "Alexander Meulemans", "Rif A. Saurous", "Guillaume Lajoie", "Charlotte Frenkel", "Razvan Pascanu", "Blaise Agüera y Arcas", "João Sacramento"], "title": "MesaNet: Sequence Modeling by Locally Optimal Test-Time Training", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Sequence modeling is currently dominated by causal transformer architectures\nthat use softmax self-attention. Although widely adopted, transformers require\nscaling memory and compute linearly during inference. A recent stream of work\nlinearized the softmax operation, resulting in powerful recurrent neural\nnetwork (RNN) models with constant memory and compute costs such as DeltaNet,\nMamba or xLSTM. These models can be unified by noting that their recurrent\nlayer dynamics can all be derived from an in-context regression objective,\napproximately optimized through an online learning rule. Here, we join this\nline of work and introduce a numerically stable, chunkwise parallelizable\nversion of the recently proposed Mesa layer (von Oswald et al., 2024), and\nstudy it in language modeling at the billion-parameter scale. This layer again\nstems from an in-context loss, but which is now minimized to optimality at\nevery time point using a fast conjugate gradient solver. Through an extensive\nsuite of experiments, we show that optimal test-time training enables reaching\nlower language modeling perplexity and higher downstream benchmark performance\nthan previous RNNs, especially on tasks requiring long context understanding.\nThis performance gain comes at the cost of additional flops spent during\ninference time. Our results are therefore intriguingly related to recent trends\nof increasing test-time compute to improve performance -- here by spending\ncompute to solve sequential optimization problems within the neural network\nitself.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04742", "pdf": "https://arxiv.org/pdf/2506.04742", "abs": "https://arxiv.org/abs/2506.04742", "authors": ["Oliver G. S. Lundqvist", "Fabricio Oliveira"], "title": "Was Residual Penalty and Neural Operators All We Needed for Solving Optimal Control Problems?", "categories": ["math.OC", "cs.AI"], "comment": null, "summary": "Neural networks have been used to solve optimal control problems, typically\nby training neural networks using a combined loss function that considers data,\ndifferential equation residuals, and objective costs. We show that including\ncost functions in the training process is unnecessary, advocating for a simpler\narchitecture and streamlined approach by decoupling the optimal control problem\nfrom the training process. Thus, our work shows that a simple neural operator\narchitecture, such as DeepONet, coupled with an unconstrained optimization\nroutine, can solve multiple optimal control problems with a single\nphysics-informed training phase and a subsequent optimization phase. We achieve\nthis by adding a penalty term based on the differential equation residual to\nthe cost function and computing gradients with respect to the control using\nautomatic differentiation through the trained neural operator within an\niterative optimization routine. We showcase our method on nine distinct optimal\ncontrol problems by training three separate DeepONet models, each corresponding\nto a different differential equation. For each model, we solve three problems\nwith varying cost functions, demonstrating accurate and consistent performance\nacross all cases.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05285", "pdf": "https://arxiv.org/pdf/2506.05285", "abs": "https://arxiv.org/abs/2506.05285", "authors": ["Bardienus P. Duisterhof", "Jan Oberst", "Bowen Wen", "Stan Birchfield", "Deva Ramanan", "Jeffrey Ichnowski"], "title": "RaySt3R: Predicting Novel Depth Maps for Zero-Shot Object Completion", "categories": ["cs.CV"], "comment": null, "summary": "3D shape completion has broad applications in robotics, digital twin\nreconstruction, and extended reality (XR). Although recent advances in 3D\nobject and scene completion have achieved impressive results, existing methods\nlack 3D consistency, are computationally expensive, and struggle to capture\nsharp object boundaries. Our work (RaySt3R) addresses these limitations by\nrecasting 3D shape completion as a novel view synthesis problem. Specifically,\ngiven a single RGB-D image and a novel viewpoint (encoded as a collection of\nquery rays), we train a feedforward transformer to predict depth maps, object\nmasks, and per-pixel confidence scores for those query rays. RaySt3R fuses\nthese predictions across multiple query views to reconstruct complete 3D\nshapes. We evaluate RaySt3R on synthetic and real-world datasets, and observe\nit achieves state-of-the-art performance, outperforming the baselines on all\ndatasets by up to 44% in 3D chamfer distance. Project page:\nhttps://rayst3r.github.io", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05239", "pdf": "https://arxiv.org/pdf/2506.05239", "abs": "https://arxiv.org/abs/2506.05239", "authors": ["Valérie Costa", "Thomas Fel", "Ekdeep Singh Lubana", "Bahareh Tolooshams", "Demba Ba"], "title": "Evaluating Sparse Autoencoders: From Shallow Design to Matching Pursuit", "categories": ["cs.LG"], "comment": "Complementary work to arXiv:2506.03093", "summary": "Sparse autoencoders (SAEs) have recently become central tools for\ninterpretability, leveraging dictionary learning principles to extract sparse,\ninterpretable features from neural representations whose underlying structure\nis typically unknown. This paper evaluates SAEs in a controlled setting using\nMNIST, which reveals that current shallow architectures implicitly rely on a\nquasi-orthogonality assumption that limits the ability to extract correlated\nfeatures. To move beyond this, we introduce a multi-iteration SAE by unrolling\nMatching Pursuit (MP-SAE), enabling the residual-guided extraction of\ncorrelated features that arise in hierarchical settings such as handwritten\ndigit generation while guaranteeing monotonic improvement of the reconstruction\nas more atoms are selected.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04451", "pdf": "https://arxiv.org/pdf/2506.04451", "abs": "https://arxiv.org/abs/2506.04451", "authors": ["Santolo Leveque", "Yunhui He", "Maxim Olshanskii"], "title": "An Augmented Lagrangian Preconditioner for Navier--Stokes Equations with Runge--Kutta in Time", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We consider a Runge--Kutta method for the numerical time integration of the\nnonstationary incompressible Navier--Stokes equations. This yields a sequence\nof nonlinear problems to be solved for the stages of the Runge--Kutta method.\nThe resulting nonlinear system of differential equations is discretized using a\nfinite element method. To compute a numerical approximation of the stages at\neach time step, we employ Newton's method, which requires the solution of a\nlarge and sparse generalized saddle-point problem at each nonlinear iteration.\nWe devise an augmented Lagrangian preconditioner within the flexible GMRES\nmethod for solving the Newton systems at each time step. The preconditioner can\nbe applied inexactly with the help of a multigrid routine. We present numerical\nevidence of the robustness and efficiency of the proposed strategy for\ndifferent values of the viscosity, mesh size, time step, and number of stages\nof the Runge--Kutta method.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05286", "pdf": "https://arxiv.org/pdf/2506.05286", "abs": "https://arxiv.org/abs/2506.05286", "authors": ["Lijie Hu", "Songning Lai", "Yuan Hua", "Shu Yang", "Jingfeng Zhang", "Di Wang"], "title": "Stable Vision Concept Transformers for Medical Diagnosis", "categories": ["cs.CV", "cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2304.06129 by other authors", "summary": "Transparency is a paramount concern in the medical field, prompting\nresearchers to delve into the realm of explainable AI (XAI). Among these XAI\nmethods, Concept Bottleneck Models (CBMs) aim to restrict the model's latent\nspace to human-understandable high-level concepts by generating a conceptual\nlayer for extracting conceptual features, which has drawn much attention\nrecently. However, existing methods rely solely on concept features to\ndetermine the model's predictions, which overlook the intrinsic feature\nembeddings within medical images. To address this utility gap between the\noriginal models and concept-based models, we propose Vision Concept Transformer\n(VCT). Furthermore, despite their benefits, CBMs have been found to negatively\nimpact model performance and fail to provide stable explanations when faced\nwith input perturbations, which limits their application in the medical field.\nTo address this faithfulness issue, this paper further proposes the Stable\nVision Concept Transformer (SVCT) based on VCT, which leverages the vision\ntransformer (ViT) as its backbone and incorporates a conceptual layer. SVCT\nemploys conceptual features to enhance decision-making capabilities by fusing\nthem with image features and ensures model faithfulness through the integration\nof Denoised Diffusion Smoothing. Comprehensive experiments on four medical\ndatasets demonstrate that our VCT and SVCT maintain accuracy while remaining\ninterpretable compared to baselines. Furthermore, even when subjected to\nperturbations, our SVCT model consistently provides faithful explanations, thus\nmeeting the needs of the medical field.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05240", "pdf": "https://arxiv.org/pdf/2506.05240", "abs": "https://arxiv.org/abs/2506.05240", "authors": ["Yizhuo Li", "Yuying Ge", "Yixiao Ge", "Ying Shan", "Ping Luo"], "title": "Aligning Latent Spaces with Flow Priors", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "This paper presents a novel framework for aligning learnable latent spaces to\narbitrary target distributions by leveraging flow-based generative models as\npriors. Our method first pretrains a flow model on the target features to\ncapture the underlying distribution. This fixed flow model subsequently\nregularizes the latent space via an alignment loss, which reformulates the flow\nmatching objective to treat the latents as optimization targets. We formally\nprove that minimizing this alignment loss establishes a computationally\ntractable surrogate objective for maximizing a variational lower bound on the\nlog-likelihood of latents under the target distribution. Notably, the proposed\nmethod eliminates computationally expensive likelihood evaluations and avoids\nODE solving during optimization. As a proof of concept, we demonstrate in a\ncontrolled setting that the alignment loss landscape closely approximates the\nnegative log-likelihood of the target distribution. We further validate the\neffectiveness of our approach through large-scale image generation experiments\non ImageNet with diverse target distributions, accompanied by detailed\ndiscussions and ablation studies. With both theoretical and empirical\nvalidation, our framework paves a new way for latent space alignment.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05287", "pdf": "https://arxiv.org/pdf/2506.05287", "abs": "https://arxiv.org/abs/2506.05287", "authors": ["Yuqian Yuan", "Ronghao Dang", "Long Li", "Wentong Li", "Dian Jiao", "Xin Li", "Deli Zhao", "Fan Wang", "Wenqiao Zhang", "Jun Xiao", "Yueting Zhuang"], "title": "EOC-Bench: Can MLLMs Identify, Recall, and Forecast Objects in an Egocentric World?", "categories": ["cs.CV"], "comment": "32pages", "summary": "The emergence of multimodal large language models (MLLMs) has driven\nbreakthroughs in egocentric vision applications. These applications necessitate\npersistent, context-aware understanding of objects, as users interact with\ntools in dynamic and cluttered environments. However, existing embodied\nbenchmarks primarily focus on static scene exploration, emphasizing object's\nappearance and spatial attributes while neglecting the assessment of dynamic\nchanges arising from users' interactions. To address this gap, we introduce\nEOC-Bench, an innovative benchmark designed to systematically evaluate\nobject-centric embodied cognition in dynamic egocentric scenarios. Specially,\nEOC-Bench features 3,277 meticulously annotated QA pairs categorized into three\ntemporal categories: Past, Present, and Future, covering 11 fine-grained\nevaluation dimensions and 3 visual object referencing types. To ensure thorough\nassessment, we develop a mixed-format human-in-the-loop annotation framework\nwith four types of questions and design a novel multi-scale temporal accuracy\nmetric for open-ended temporal evaluation. Based on EOC-Bench, we conduct\ncomprehensive evaluations of various proprietary, open-source, and object-level\nMLLMs. EOC-Bench serves as a crucial tool for advancing the embodied object\ncognitive capabilities of MLLMs, establishing a robust foundation for\ndeveloping reliable core models for embodied systems.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05249", "pdf": "https://arxiv.org/pdf/2506.05249", "abs": "https://arxiv.org/abs/2506.05249", "authors": ["Zhen Qin", "Jinxin Zhou", "Zhihui Zhu"], "title": "On the Convergence of Gradient Descent on Learning Transformers with Residual Connections", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Transformer models have emerged as fundamental tools across various\nscientific and engineering disciplines, owing to their outstanding performance\nin diverse applications. Despite this empirical success, the theoretical\nfoundations of Transformers remain relatively underdeveloped, particularly in\nunderstanding their training dynamics. Existing research predominantly examines\nisolated components--such as self-attention mechanisms and feedforward\nnetworks--without thoroughly investigating the interdependencies between these\ncomponents, especially when residual connections are present. In this paper, we\naim to bridge this gap by analyzing the convergence behavior of a structurally\ncomplete yet single-layer Transformer, comprising self-attention, a feedforward\nnetwork, and residual connections. We demonstrate that, under appropriate\ninitialization, gradient descent exhibits a linear convergence rate, where the\nconvergence speed is determined by the minimum and maximum singular values of\nthe output matrix from the attention layer. Moreover, our analysis reveals that\nresidual connections serve to ameliorate the ill-conditioning of this output\nmatrix, an issue stemming from the low-rank structure imposed by the softmax\noperation, thereby promoting enhanced optimization stability. We also extend\nour theoretical findings to a multi-layer Transformer architecture, confirming\nthe linear convergence rate of gradient descent under suitable initialization.\nEmpirical results corroborate our theoretical insights, illustrating the\nbeneficial role of residual connections in promoting convergence stability.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04774", "pdf": "https://arxiv.org/pdf/2506.04774", "abs": "https://arxiv.org/abs/2506.04774", "authors": ["Jingyu Hu", "Mengyue Yang", "Mengnan Du", "Weiru Liu"], "title": "Fine-Grained Interpretation of Political Opinions in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Studies of LLMs' political opinions mainly rely on evaluations of their\nopen-ended responses. Recent work indicates that there is a misalignment\nbetween LLMs' responses and their internal intentions. This motivates us to\nprobe LLMs' internal mechanisms and help uncover their internal political\nstates. Additionally, we found that the analysis of LLMs' political opinions\noften relies on single-axis concepts, which can lead to concept confounds. In\nthis work, we extend the single-axis to multi-dimensions and apply\ninterpretable representation engineering techniques for more transparent LLM\npolitical concept learning. Specifically, we designed a four-dimensional\npolitical learning framework and constructed a corresponding dataset for\nfine-grained political concept vector learning. These vectors can be used to\ndetect and intervene in LLM internals. Experiments are conducted on eight\nopen-source LLMs with three representation engineering techniques. Results show\nthese vectors can disentangle political concept confounds. Detection tasks\nvalidate the semantic meaning of the vectors and show good generalization and\nrobustness in OOD settings. Intervention Experiments show these vectors can\nintervene in LLMs to generate responses with different political leanings.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05289", "pdf": "https://arxiv.org/pdf/2506.05289", "abs": "https://arxiv.org/abs/2506.05289", "authors": ["Pingyu Wu", "Kai Zhu", "Yu Liu", "Longxiang Tang", "Jian Yang", "Yansong Peng", "Wei Zhai", "Yang Cao", "Zheng-Jun Zha"], "title": "AliTok: Towards Sequence Modeling Alignment between Tokenizer and Autoregressive Model", "categories": ["cs.CV"], "comment": "Code: https://github.com/ali-vilab/alitok", "summary": "Autoregressive image generation aims to predict the next token based on\nprevious ones. However, existing image tokenizers encode tokens with\nbidirectional dependencies during the compression process, which hinders the\neffective modeling by autoregressive models. In this paper, we propose a novel\nAligned Tokenizer (AliTok), which utilizes a causal decoder to establish\nunidirectional dependencies among encoded tokens, thereby aligning the token\nmodeling approach between the tokenizer and autoregressive model. Furthermore,\nby incorporating prefix tokens and employing two-stage tokenizer training to\nenhance reconstruction consistency, AliTok achieves great reconstruction\nperformance while being generation-friendly. On ImageNet-256 benchmark, using a\nstandard decoder-only autoregressive model as the generator with only 177M\nparameters, AliTok achieves a gFID score of 1.50 and an IS of 305.9. When the\nparameter count is increased to 662M, AliTok achieves a gFID score of 1.35,\nsurpassing the state-of-the-art diffusion method with 10x faster sampling\nspeed. The code and weights are available at\nhttps://github.com/ali-vilab/alitok.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04788", "pdf": "https://arxiv.org/pdf/2506.04788", "abs": "https://arxiv.org/abs/2506.04788", "authors": ["Jisu An", "Junseok Lee", "Jeoungeun Lee", "Yongseok Son"], "title": "Towards LLM-Centric Multimodal Fusion: A Survey on Integration Strategies and Techniques", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "18 pages, 3 figures, 3 tables", "summary": "The rapid progress of Multimodal Large Language Models(MLLMs) has transformed\nthe AI landscape. These models combine pre-trained LLMs with various modality\nencoders. This integration requires a systematic understanding of how different\nmodalities connect to the language backbone. Our survey presents an LLM-centric\nanalysis of current approaches. We examine methods for transforming and\naligning diverse modal inputs into the language embedding space. This addresses\na significant gap in existing literature. We propose a classification framework\nfor MLLMs based on three key dimensions. First, we examine architectural\nstrategies for modality integration. This includes both the specific\nintegration mechanisms and the fusion level. Second, we categorize\nrepresentation learning techniques as either joint or coordinate\nrepresentations. Third, we analyze training paradigms, including training\nstrategies and objective functions. By examining 125 MLLMs developed between\n2021 and 2025, we identify emerging patterns in the field. Our taxonomy\nprovides researchers with a structured overview of current integration\ntechniques. These insights aim to guide the development of more robust\nmultimodal integration strategies for future models built on pre-trained\nfoundations.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05301", "pdf": "https://arxiv.org/pdf/2506.05301", "abs": "https://arxiv.org/abs/2506.05301", "authors": ["Jianyi Wang", "Shanchuan Lin", "Zhijie Lin", "Yuxi Ren", "Meng Wei", "Zongsheng Yue", "Shangchen Zhou", "Hao Chen", "Yang Zhao", "Ceyuan Yang", "Xuefeng Xiao", "Chen Change Loy", "Lu Jiang"], "title": "SeedVR2: One-Step Video Restoration via Diffusion Adversarial Post-Training", "categories": ["cs.CV"], "comment": "Draft Ver. Project page: https://iceclear.github.io/projects/seedvr2/", "summary": "Recent advances in diffusion-based video restoration (VR) demonstrate\nsignificant improvement in visual quality, yet yield a prohibitive\ncomputational cost during inference. While several distillation-based\napproaches have exhibited the potential of one-step image restoration,\nextending existing approaches to VR remains challenging and underexplored,\nparticularly when dealing with high-resolution video in real-world settings. In\nthis work, we propose a one-step diffusion-based VR model, termed as SeedVR2,\nwhich performs adversarial VR training against real data. To handle the\nchallenging high-resolution VR within a single step, we introduce several\nenhancements to both model architecture and training procedures. Specifically,\nan adaptive window attention mechanism is proposed, where the window size is\ndynamically adjusted to fit the output resolutions, avoiding window\ninconsistency observed under high-resolution VR using window attention with a\npredefined window size. To stabilize and improve the adversarial post-training\ntowards VR, we further verify the effectiveness of a series of losses,\nincluding a proposed feature matching loss without significantly sacrificing\ntraining efficiency. Extensive experiments show that SeedVR2 can achieve\ncomparable or even better performance compared with existing VR approaches in a\nsingle step.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05259", "pdf": "https://arxiv.org/pdf/2506.05259", "abs": "https://arxiv.org/abs/2506.05259", "authors": ["Guillaume Pourcel", "Maxence Ernoult"], "title": "Learning long range dependencies through time reversal symmetry breaking", "categories": ["cs.LG"], "comment": "45 pages", "summary": "Deep State Space Models (SSMs) reignite physics-grounded compute paradigms,\nas RNNs could natively be embodied into dynamical systems. This calls for\ndedicated learning algorithms obeying to core physical principles, with\nefficient techniques to simulate these systems and guide their design. We\npropose Recurrent Hamiltonian Echo Learning (RHEL), an algorithm which provably\ncomputes loss gradients as finite differences of physical trajectories of\nnon-dissipative, Hamiltonian systems. In ML terms, RHEL only requires three\n\"forward passes\" irrespective of model size, without explicit Jacobian\ncomputation, nor incurring any variance in the gradient estimation. Motivated\nby the physical realization of our algorithm, we first introduce RHEL in\ncontinuous time and demonstrate its formal equivalence with the continuous\nadjoint state method. To facilitate the simulation of Hamiltonian systems\ntrained by RHEL, we propose a discrete-time version of RHEL which is equivalent\nto Backpropagation Through Time (BPTT) when applied to a class of recurrent\nmodules which we call Hamiltonian Recurrent Units (HRUs). This setting allows\nus to demonstrate the scalability of RHEL by generalizing these results to\nhierarchies of HRUs, which we call Hamiltonian SSMs (HSSMs). We apply RHEL to\ntrain HSSMs with linear and nonlinear dynamics on a variety of time-series\ntasks ranging from mid-range to long-range classification and regression with\nsequence length reaching $\\sim 50k$. We show that RHEL consistently matches the\nperformance of BPTT across all models and tasks. This work opens new doors for\nthe design of scalable, energy-efficient physical systems endowed with\nself-learning capabilities for sequence modelling.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04458", "pdf": "https://arxiv.org/pdf/2506.04458", "abs": "https://arxiv.org/abs/2506.04458", "authors": ["Xueqiang Xu", "Jinfeng Xiao", "James Barry", "Mohab Elkaref", "Jiaru Zou", "Pengcheng Jiang", "Yunyi Zhang", "Max Giammona", "Geeth de Mel", "Jiawei Han"], "title": "Zero-Shot Open-Schema Entity Structure Discovery", "categories": ["cs.CL"], "comment": "14 pages, 3 figures", "summary": "Entity structure extraction, which aims to extract entities and their\nassociated attribute-value structures from text, is an essential task for text\nunderstanding and knowledge graph construction. Existing methods based on large\nlanguage models (LLMs) typically rely heavily on predefined entity attribute\nschemas or annotated datasets, often leading to incomplete extraction results.\nTo address these challenges, we introduce Zero-Shot Open-schema Entity\nStructure Discovery (ZOES), a novel approach to entity structure extraction\nthat does not require any schema or annotated samples. ZOES operates via a\nprincipled mechanism of enrichment, refinement, and unification, based on the\ninsight that an entity and its associated structure are mutually reinforcing.\nExperiments demonstrate that ZOES consistently enhances LLMs' ability to\nextract more complete entity structures across three different domains,\nshowcasing both the effectiveness and generalizability of the method. These\nfindings suggest that such an enrichment, refinement, and unification mechanism\nmay serve as a principled approach to improving the quality of LLM-based entity\nstructure discovery in various scenarios.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04810", "pdf": "https://arxiv.org/pdf/2506.04810", "abs": "https://arxiv.org/abs/2506.04810", "authors": ["Yujun Zhou", "Jiayi Ye", "Zipeng Ling", "Yufei Han", "Yue Huang", "Haomin Zhuang", "Zhenwen Liang", "Kehan Guo", "Taicheng Guo", "Xiangqi Wang", "Xiangliang Zhang"], "title": "Dissecting Logical Reasoning in LLMs: A Fine-Grained Evaluation and Supervision Study", "categories": ["cs.CL", "cs.AI", "cs.LO"], "comment": null, "summary": "Logical reasoning is a core capability for many applications of large\nlanguage models (LLMs), yet existing benchmarks often rely solely on\nfinal-answer accuracy, failing to capture the quality and structure of the\nreasoning process. We propose FineLogic, a fine-grained evaluation framework\nthat assesses logical reasoning across three dimensions: overall benchmark\naccuracy, stepwise soundness, and representation-level alignment. In addition,\nto better understand how reasoning capabilities emerge, we conduct a\ncomprehensive study on the effects of supervision format during fine-tuning. We\nconstruct four supervision styles (one natural language and three symbolic\nvariants) and train LLMs under each. Our findings reveal that natural language\nsupervision yields strong generalization even on out-of-distribution and\nlong-context tasks, while symbolic reasoning styles promote more structurally\nsound and atomic inference chains. Further, our representation-level probing\nshows that fine-tuning primarily improves reasoning behaviors through\nstep-by-step generation, rather than enhancing shortcut prediction or\ninternalized correctness. Together, our framework and analysis provide a more\nrigorous and interpretable lens for evaluating and improving logical reasoning\nin LLMs.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05302", "pdf": "https://arxiv.org/pdf/2506.05302", "abs": "https://arxiv.org/abs/2506.05302", "authors": ["Weifeng Lin", "Xinyu Wei", "Ruichuan An", "Tianhe Ren", "Tingwei Chen", "Renrui Zhang", "Ziyu Guo", "Wentao Zhang", "Lei Zhang", "Hongsheng Li"], "title": "Perceive Anything: Recognize, Explain, Caption, and Segment Anything in Images and Videos", "categories": ["cs.CV"], "comment": "19 pages, 13 figures, Website: https://Perceive-Anything.github.io", "summary": "We present Perceive Anything Model (PAM), a conceptually straightforward and\nefficient framework for comprehensive region-level visual understanding in\nimages and videos. Our approach extends the powerful segmentation model SAM 2\nby integrating Large Language Models (LLMs), enabling simultaneous object\nsegmentation with the generation of diverse, region-specific semantic outputs,\nincluding categories, label definition, functional explanations, and detailed\ncaptions. A key component, Semantic Perceiver, is introduced to efficiently\ntransform SAM 2's rich visual features, which inherently carry general vision,\nlocalization, and semantic priors into multi-modal tokens for LLM\ncomprehension. To support robust multi-granularity understanding, we also\ndevelop a dedicated data refinement and augmentation pipeline, yielding a\nhigh-quality dataset of 1.5M image and 0.6M video region-semantic annotations,\nincluding novel region-level streaming video caption data. PAM is designed for\nlightweightness and efficiency, while also demonstrates strong performance\nacross a diverse range of region understanding tasks. It runs 1.2-2.4x faster\nand consumes less GPU memory than prior approaches, offering a practical\nsolution for real-world applications. We believe that our effective approach\nwill serve as a strong baseline for future research in region-level visual\nunderstanding.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04824", "pdf": "https://arxiv.org/pdf/2506.04824", "abs": "https://arxiv.org/abs/2506.04824", "authors": ["Martin Andrews", "Sam Witteveen"], "title": "A Reasoning-Based Approach to Cryptic Crossword Clue Solving", "categories": ["cs.CL", "cs.AI"], "comment": "9 page paper plus Appendices. Accepted to ICML 2025", "summary": "Cryptic crossword clues are challenging language tasks for which new test\nsets are released daily by major newspapers on a global basis. Each cryptic\nclue contains both the definition of the answer to be placed in the crossword\ngrid (in common with regular crosswords), and 'wordplay' that proves that the\nanswer is correct (i.e. a human solver can be confident that an answer is\ncorrect without needing crossing words as confirmation). This work describes an\nLLM-based reasoning system built from open-licensed components that solves\ncryptic clues by (i) hypothesising answers; (ii) proposing wordplay\nexplanations; and (iii) using a verifier system that operates on codified\nreasoning steps. Overall, this system establishes a new state-of-the-art\nperformance on the challenging Cryptonite dataset of clues from The Times and\nThe Telegraph newspapers in the UK. Because each proved solution is expressed\nin Python, interpretable wordplay reasoning for proven answers is available for\ninspection.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05312", "pdf": "https://arxiv.org/pdf/2506.05312", "abs": "https://arxiv.org/abs/2506.05312", "authors": ["Olaf Dünkel", "Thomas Wimmer", "Christian Theobalt", "Christian Rupprecht", "Adam Kortylewski"], "title": "Do It Yourself: Learning Semantic Correspondence from Pseudo-Labels", "categories": ["cs.CV"], "comment": "Project page: https://genintel.github.io/DIY-SC", "summary": "Finding correspondences between semantically similar points across images and\nobject instances is one of the everlasting challenges in computer vision. While\nlarge pre-trained vision models have recently been demonstrated as effective\npriors for semantic matching, they still suffer from ambiguities for symmetric\nobjects or repeated object parts. We propose to improve semantic correspondence\nestimation via 3D-aware pseudo-labeling. Specifically, we train an adapter to\nrefine off-the-shelf features using pseudo-labels obtained via 3D-aware\nchaining, filtering wrong labels through relaxed cyclic consistency, and 3D\nspherical prototype mapping constraints. While reducing the need for dataset\nspecific annotations compared to prior work, we set a new state-of-the-art on\nSPair-71k by over 4% absolute gain and by over 7% against methods with similar\nsupervision requirements. The generality of our proposed approach simplifies\nextension of training to other data sources, which we demonstrate in our\nexperiments.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05276", "pdf": "https://arxiv.org/pdf/2506.05276", "abs": "https://arxiv.org/abs/2506.05276", "authors": ["Hao Yu", "Chu Xin Cheng", "Runlong Yu", "Yuyang Ye", "Shiwei Tong", "Zhaofeng Liu", "Defu Lian"], "title": "How to Unlock Time Series Editing? Diffusion-Driven Approach with Multi-Grained Control", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in time series generation have shown promise, yet controlling\nproperties in generated sequences remains challenging. Time Series Editing\n(TSE) - making precise modifications while preserving temporal coherence -\nconsider both point-level constraints and segment-level controls that current\nmethods struggle to provide. We introduce the CocktailEdit framework to enable\nsimultaneous, flexible control across different types of constraints. This\nframework combines two key mechanisms: a confidence-weighted anchor control for\npoint-wise constraints and a classifier-based control for managing statistical\nproperties such as sums and averages over segments. Our methods achieve precise\nlocal control during the denoising inference stage while maintaining temporal\ncoherence and integrating seamlessly, with any conditionally trained\ndiffusion-based time series models. Extensive experiments across diverse\ndatasets and models demonstrate its effectiveness. Our work bridges the gap\nbetween pure generative modeling and real-world time series editing needs,\noffering a flexible solution for human-in-the-loop time series generation and\nediting. The code and demo are provided for validation.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05313", "pdf": "https://arxiv.org/pdf/2506.05313", "abs": "https://arxiv.org/abs/2506.05313", "authors": ["Ta-Ying Cheng", "Prafull Sharma", "Mark Boss", "Varun Jampani"], "title": "MARBLE: Material Recomposition and Blending in CLIP-Space", "categories": ["cs.CV"], "comment": null, "summary": "Editing materials of objects in images based on exemplar images is an active\narea of research in computer vision and graphics. We propose MARBLE, a method\nfor performing material blending and recomposing fine-grained material\nproperties by finding material embeddings in CLIP-space and using that to\ncontrol pre-trained text-to-image models. We improve exemplar-based material\nediting by finding a block in the denoising UNet responsible for material\nattribution. Given two material exemplar-images, we find directions in the\nCLIP-space for blending the materials. Further, we can achieve parametric\ncontrol over fine-grained material attributes such as roughness, metallic,\ntransparency, and glow using a shallow network to predict the direction for the\ndesired material attribute change. We perform qualitative and quantitative\nanalysis to demonstrate the efficacy of our proposed method. We also present\nthe ability of our method to perform multiple edits in a single forward pass\nand applicability to painting.\n  Project Page: https://marblecontrol.github.io/", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05281", "pdf": "https://arxiv.org/pdf/2506.05281", "abs": "https://arxiv.org/abs/2506.05281", "authors": ["Haifeng Sun", "Yu Xiong", "Runze Wu", "Xinyu Cai", "Changjie Fan", "Lan Zhang", "Xiang-Yang Li"], "title": "Fast-DataShapley: Neural Modeling for Training Data Valuation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The value and copyright of training data are crucial in the artificial\nintelligence industry. Service platforms should protect data providers'\nlegitimate rights and fairly reward them for their contributions. Shapley\nvalue, a potent tool for evaluating contributions, outperforms other methods in\ntheory, but its computational overhead escalates exponentially with the number\nof data providers. Recent works based on Shapley values attempt to mitigate\ncomputation complexity by approximation algorithms. However, they need to\nretrain for each test sample, leading to intolerable costs. We propose\nFast-DataShapley, a one-pass training method that leverages the weighted least\nsquares characterization of the Shapley value to train a reusable explainer\nmodel with real-time reasoning speed. Given new test samples, no retraining is\nrequired to calculate the Shapley values of the training data. Additionally, we\npropose three methods with theoretical guarantees to reduce training overhead\nfrom two aspects: the approximate calculation of the utility function and the\ngroup calculation of the training data. We analyze time complexity to show the\nefficiency of our methods. The experimental evaluations on various image\ndatasets demonstrate superior performance and efficiency compared to baselines.\nSpecifically, the performance is improved to more than 2.5 times, and the\nexplainer's training speed can be increased by two orders of magnitude.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04463", "pdf": "https://arxiv.org/pdf/2506.04463", "abs": "https://arxiv.org/abs/2506.04463", "authors": ["Zhaoxuan Tan", "Zheng Li", "Tianyi Liu", "Haodong Wang", "Hyokun Yun", "Ming Zeng", "Pei Chen", "Zhihan Zhang", "Yifan Gao", "Ruijie Wang", "Priyanka Nigam", "Bing Yin", "Meng Jiang"], "title": "Aligning Large Language Models with Implicit Preferences from User-Generated Content", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "Learning from preference feedback is essential for aligning large language\nmodels (LLMs) with human values and improving the quality of generated\nresponses. However, existing preference learning methods rely heavily on\ncurated data from humans or advanced LLMs, which is costly and difficult to\nscale. In this work, we present PUGC, a novel framework that leverages implicit\nhuman Preferences in unlabeled User-Generated Content (UGC) to generate\npreference data. Although UGC is not explicitly created to guide LLMs in\ngenerating human-preferred responses, it often reflects valuable insights and\nimplicit preferences from its creators that has the potential to address\nreaders' questions. PUGC transforms UGC into user queries and generates\nresponses from the policy model. The UGC is then leveraged as a reference text\nfor response scoring, aligning the model with these implicit preferences. This\napproach improves the quality of preference data while enabling scalable,\ndomain-specific alignment. Experimental results on Alpaca Eval 2 show that\nmodels trained with DPO and PUGC achieve a 9.37% performance improvement over\ntraditional methods, setting a 35.93% state-of-the-art length-controlled win\nrate using Mistral-7B-Instruct. Further studies highlight gains in reward\nquality, domain-specific alignment effectiveness, robustness against UGC\nquality, and theory of mind capabilities. Our code and dataset are available at\nhttps://zhaoxuan.info/PUGC.github.io/", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05317", "pdf": "https://arxiv.org/pdf/2506.05317", "abs": "https://arxiv.org/abs/2506.05317", "authors": ["Daniel Rho", "Jun Myeong Choi", "Biswadip Dey", "Roni Sengupta"], "title": "ProJo4D: Progressive Joint Optimization for Sparse-View Inverse Physics Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Neural rendering has made significant strides in 3D reconstruction and novel\nview synthesis. With the integration with physics, it opens up new\napplications. The inverse problem of estimating physics from visual data,\nhowever, still remains challenging, limiting its effectiveness for applications\nlike physically accurate digital twin creation in robotics and XR. Existing\nmethods that incorporate physics into neural rendering frameworks typically\nrequire dense multi-view videos as input, making them impractical for scalable,\nreal-world use. When presented with sparse multi-view videos, the sequential\noptimization strategy used by existing approaches introduces significant error\naccumulation, e.g., poor initial 3D reconstruction leads to bad material\nparameter estimation in subsequent stages. Instead of sequential optimization,\ndirectly optimizing all parameters at the same time also fails due to the\nhighly non-convex and often non-differentiable nature of the problem. We\npropose ProJo4D, a progressive joint optimization framework that gradually\nincreases the set of jointly optimized parameters guided by their sensitivity,\nleading to fully joint optimization over geometry, appearance, physical state,\nand material property. Evaluations on PAC-NeRF and Spring-Gaus datasets show\nthat ProJo4D outperforms prior work in 4D future state prediction, novel view\nrendering of future state, and material parameter estimation, demonstrating its\neffectiveness in physically grounded 4D scene understanding. For demos, please\nvisit the project webpage: https://daniel03c1.github.io/ProJo4D/", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05292", "pdf": "https://arxiv.org/pdf/2506.05292", "abs": "https://arxiv.org/abs/2506.05292", "authors": ["Declan A. Norton", "Yuanzhao Zhang", "Michelle Girvan"], "title": "Learning Beyond Experience: Generalizing to Unseen State Space with Reservoir Computing", "categories": ["cs.LG", "math.DS", "nlin.CD", "physics.comp-ph"], "comment": "15 pages, 9 figures", "summary": "Machine learning techniques offer an effective approach to modeling dynamical\nsystems solely from observed data. However, without explicit structural priors\n-- built-in assumptions about the underlying dynamics -- these techniques\ntypically struggle to generalize to aspects of the dynamics that are poorly\nrepresented in the training data. Here, we demonstrate that reservoir computing\n-- a simple, efficient, and versatile machine learning framework often used for\ndata-driven modeling of dynamical systems -- can generalize to unexplored\nregions of state space without explicit structural priors. First, we describe a\nmultiple-trajectory training scheme for reservoir computers that supports\ntraining across a collection of disjoint time series, enabling effective use of\navailable training data. Then, applying this training scheme to multistable\ndynamical systems, we show that RCs trained on trajectories from a single basin\nof attraction can achieve out-of-domain generalization by capturing system\nbehavior in entirely unobserved basins.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04851", "pdf": "https://arxiv.org/pdf/2506.04851", "abs": "https://arxiv.org/abs/2506.04851", "authors": ["Giorgio Biancini", "Alessio Ferrato", "Carla Limongelli"], "title": "Multiple-Choice Question Generation Using Large Language Models: Methodology and Educator Insights", "categories": ["cs.CL", "cs.AI"], "comment": "Copyright ACM 2024. This is the author's version of the work. It is\n  posted here for your personal use. Not for redistribution. The definitive\n  Version of Record was published in Adjunct Proceedings of the 32nd ACM\n  Conference on User Modeling, Adaptation and Personalization (UMAP Adjunct\n  '24), http://dx.doi.org/10.1145/3631700.3665233", "summary": "Integrating Artificial Intelligence (AI) in educational settings has brought\nnew learning approaches, transforming the practices of both students and\neducators. Among the various technologies driving this transformation, Large\nLanguage Models (LLMs) have emerged as powerful tools for creating educational\nmaterials and question answering, but there are still space for new\napplications. Educators commonly use Multiple-Choice Questions (MCQs) to assess\nstudent knowledge, but manually generating these questions is\nresource-intensive and requires significant time and cognitive effort. In our\nopinion, LLMs offer a promising solution to these challenges. This paper\npresents a novel comparative analysis of three widely known LLMs - Llama 2,\nMistral, and GPT-3.5 - to explore their potential for creating informative and\nchallenging MCQs. In our approach, we do not rely on the knowledge of the LLM,\nbut we inject the knowledge into the prompt to contrast the hallucinations,\ngiving the educators control over the test's source text, too. Our experiment\ninvolving 21 educators shows that GPT-3.5 generates the most effective MCQs\nacross several known metrics. Additionally, it shows that there is still some\nreluctance to adopt AI in the educational field. This study sheds light on the\npotential of LLMs to generate MCQs and improve the educational experience,\nproviding valuable insights for the future.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05318", "pdf": "https://arxiv.org/pdf/2506.05318", "abs": "https://arxiv.org/abs/2506.05318", "authors": ["Haoyuan Li", "Yanpeng Zhou", "Yufei Gao", "Tao Tang", "Jianhua Han", "Yujie Yuan", "Dave Zhenyu Chen", "Jiawang Bian", "Hang Xu", "Xiaodan Liang"], "title": "Does Your 3D Encoder Really Work? When Pretrain-SFT from 2D VLMs Meets 3D VLMs", "categories": ["cs.CV"], "comment": null, "summary": "Remarkable progress in 2D Vision-Language Models (VLMs) has spurred interest\nin extending them to 3D settings for tasks like 3D Question Answering, Dense\nCaptioning, and Visual Grounding. Unlike 2D VLMs that typically process images\nthrough an image encoder, 3D scenes, with their intricate spatial structures,\nallow for diverse model architectures. Based on their encoder design, this\npaper categorizes recent 3D VLMs into 3D object-centric, 2D image-based, and 3D\nscene-centric approaches. Despite the architectural similarity of 3D\nscene-centric VLMs to their 2D counterparts, they have exhibited comparatively\nlower performance compared with the latest 3D object-centric and 2D image-based\napproaches. To understand this gap, we conduct an in-depth analysis, revealing\nthat 3D scene-centric VLMs show limited reliance on the 3D scene encoder, and\nthe pre-train stage appears less effective than in 2D VLMs. Furthermore, we\nobserve that data scaling benefits are less pronounced on larger datasets. Our\ninvestigation suggests that while these models possess cross-modal alignment\ncapabilities, they tend to over-rely on linguistic cues and overfit to frequent\nanswer distributions, thereby diminishing the effective utilization of the 3D\nencoder. To address these limitations and encourage genuine 3D scene\nunderstanding, we introduce a novel 3D Relevance Discrimination QA dataset\ndesigned to disrupt shortcut learning and improve 3D understanding. Our\nfindings highlight the need for advanced evaluation and improved strategies for\nbetter 3D understanding in 3D VLMs.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05294", "pdf": "https://arxiv.org/pdf/2506.05294", "abs": "https://arxiv.org/abs/2506.05294", "authors": ["Arnav Kumar Jain", "Vibhakar Mohta", "Subin Kim", "Atiksh Bhardwaj", "Juntao Ren", "Yunhai Feng", "Sanjiban Choudhury", "Gokul Swamy"], "title": "A Smooth Sea Never Made a Skilled $\\texttt{SAILOR}$: Robust Imitation via Learning to Search", "categories": ["cs.LG"], "comment": null, "summary": "The fundamental limitation of the behavioral cloning (BC) approach to\nimitation learning is that it only teaches an agent what the expert did at\nstates the expert visited. This means that when a BC agent makes a mistake\nwhich takes them out of the support of the demonstrations, they often don't\nknow how to recover from it. In this sense, BC is akin to giving the agent the\nfish -- giving them dense supervision across a narrow set of states -- rather\nthan teaching them to fish: to be able to reason independently about achieving\nthe expert's outcome even when faced with unseen situations at test-time. In\nresponse, we explore learning to search (L2S) from expert demonstrations, i.e.\nlearning the components required to, at test time, plan to match expert\noutcomes, even after making a mistake. These include (1) a world model and (2)\na reward model. We carefully ablate the set of algorithmic and design decisions\nrequired to combine these and other components for stable and\nsample/interaction-efficient learning of recovery behavior without additional\nhuman corrections. Across a dozen visual manipulation tasks from three\nbenchmarks, our approach $\\texttt{SAILOR}$ consistently out-performs\nstate-of-the-art Diffusion Policies trained via BC on the same data.\nFurthermore, scaling up the amount of demonstrations used for BC by\n5-10$\\times$ still leaves a performance gap. We find that $\\texttt{SAILOR}$ can\nidentify nuanced failures and is robust to reward hacking. Our code is\navailable at https://github.com/arnavkj1995/SAILOR .", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05327", "pdf": "https://arxiv.org/pdf/2506.05327", "abs": "https://arxiv.org/abs/2506.05327", "authors": ["Duochao Shi", "Weijie Wang", "Donny Y. Chen", "Zeyu Zhang", "Jia-Wang Bian", "Bohan Zhuang", "Chunhua Shen"], "title": "Revisiting Depth Representations for Feed-Forward 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": "Project page: https://aim-uofa.github.io/PMLoss", "summary": "Depth maps are widely used in feed-forward 3D Gaussian Splatting (3DGS)\npipelines by unprojecting them into 3D point clouds for novel view synthesis.\nThis approach offers advantages such as efficient training, the use of known\ncamera poses, and accurate geometry estimation. However, depth discontinuities\nat object boundaries often lead to fragmented or sparse point clouds, degrading\nrendering quality -- a well-known limitation of depth-based representations. To\ntackle this issue, we introduce PM-Loss, a novel regularization loss based on a\npointmap predicted by a pre-trained transformer. Although the pointmap itself\nmay be less accurate than the depth map, it effectively enforces geometric\nsmoothness, especially around object boundaries. With the improved depth map,\nour method significantly improves the feed-forward 3DGS across various\narchitectures and scenes, delivering consistently better rendering results. Our\nproject page: https://aim-uofa.github.io/PMLoss", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05295", "pdf": "https://arxiv.org/pdf/2506.05295", "abs": "https://arxiv.org/abs/2506.05295", "authors": ["Baihe Huang", "Shanda Li", "Tianhao Wu", "Yiming Yang", "Ameet Talwalkar", "Kannan Ramchandran", "Michael I. Jordan", "Jiantao Jiao"], "title": "Sample Complexity and Representation Ability of Test-time Scaling Paradigms", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Test-time scaling paradigms have significantly advanced the capabilities of\nlarge language models (LLMs) on complex tasks. Despite their empirical success,\ntheoretical understanding of the sample efficiency of various test-time\nstrategies -- such as self-consistency, best-of-$n$, and self-correction --\nremains limited. In this work, we first establish a separation result between\ntwo repeated sampling strategies: self-consistency requires\n$\\Theta(1/\\Delta^2)$ samples to produce the correct answer, while best-of-$n$\nonly needs $\\Theta(1/\\Delta)$, where $\\Delta < 1$ denotes the probability gap\nbetween the correct and second most likely answers. Next, we present an\nexpressiveness result for the self-correction approach with verifier feedback:\nit enables Transformers to simulate online learning over a pool of experts at\ntest time. Therefore, a single Transformer architecture can provably solve\nmultiple tasks without prior knowledge of the specific task associated with a\nuser query, extending the representation theory of Transformers from\nsingle-task to multi-task settings. Finally, we empirically validate our\ntheoretical results, demonstrating the practical effectiveness of\nself-correction methods.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05328", "pdf": "https://arxiv.org/pdf/2506.05328", "abs": "https://arxiv.org/abs/2506.05328", "authors": ["Lidong Lu", "Guo Chen", "Zhiqi Li", "Yicheng Liu", "Tong Lu"], "title": "AV-Reasoner: Improving and Benchmarking Clue-Grounded Audio-Visual Counting for MLLMs", "categories": ["cs.CV"], "comment": "21 pages, 11 figures", "summary": "Despite progress in video understanding, current MLLMs struggle with counting\ntasks. Existing benchmarks are limited by short videos, close-set queries, lack\nof clue annotations, and weak multimodal coverage. In this paper, we introduce\nCG-AV-Counting, a manually-annotated clue-grounded counting benchmark with\n1,027 multimodal questions and 5,845 annotated clues over 497 long videos. It\nsupports both black-box and white-box evaluation, serving as a comprehensive\ntestbed for both end-to-end and reasoning-based counting. To explore ways to\nimprove model's counting capability, we propose AV-Reasoner, a model trained\nwith GRPO and curriculum learning to generalize counting ability from related\ntasks. AV-Reasoner achieves state-of-the-art results across multiple\nbenchmarks, demonstrating the effectiveness of reinforcement learning. However,\nexperiments show that on out-of-domain benchmarks, reasoning in the language\nspace fails to bring performance gains. The code and benchmark have been\nrealeased on https://av-reasoner.github.io.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05300", "pdf": "https://arxiv.org/pdf/2506.05300", "abs": "https://arxiv.org/abs/2506.05300", "authors": ["Nirav Koley", "Prajwal Singhania", "Abhinav Bhatele"], "title": "Power Law Guided Dynamic Sifting for Efficient Attention", "categories": ["cs.LG"], "comment": null, "summary": "Efficient inference on GPUs using large language models remains challenging\ndue to memory bandwidth limitations, particularly during data transfers between\nHigh Bandwidth Memory (HBM) and SRAM in attention computations. Approximate\nattention methods address this issue by reducing computational and memory\noverhead but often rely on expensive top-$k$ operations, which perform poorly\non GPUs. We propose SiftAttention, a novel approximate attention method that\nreplaces the top-$k$ step with a computationally efficient element-wise\nfiltering operation based on a threshold value. Our intuition for doing this is\nbased on our empirical observation that the $\\tau$-th quantile of attention\nscores follows a predictable power-law over sequential generation steps.\nExploiting this insight, our approach dynamically estimates a threshold value\nper prompt at each generation step. Only attention scores above this threshold\nand their corresponding value vectors are loaded/used to compute the attention\noutput, reducing data movement between HBM and SRAM. Our evaluation\ndemonstrates that SiftAttention preserves model quality better than existing\napproximate attention methods while reducing memory bandwidth usage when\nloading value vectors.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04907", "pdf": "https://arxiv.org/pdf/2506.04907", "abs": "https://arxiv.org/abs/2506.04907", "authors": ["Alex Pan", "Mary-Anne Williams"], "title": "Verbose ListOps (VLO): Beyond Long Context -- Unmasking LLM's Reasoning Blind Spots", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs), whilst great at extracting facts from text,\nstruggle with nested narrative reasoning. Existing long context and multi-hop\nQA benchmarks inadequately test this, lacking realistic distractors or failing\nto decouple context length from reasoning complexity, masking a fundamental LLM\nlimitation. We introduce Verbose ListOps, a novel benchmark that\nprogrammatically transposes ListOps computations into lengthy, coherent\nstories. This uniquely forces internal computation and state management of\nnested reasoning problems by withholding intermediate results, and offers\nfine-grained controls for both narrative size \\emph{and} reasoning difficulty.\nWhilst benchmarks like LongReason (2025) advance approaches for synthetically\nexpanding the context size of multi-hop QA problems, Verbose ListOps pinpoints\na specific LLM vulnerability: difficulty in state management for nested\nsub-reasoning amongst semantically-relevant, distracting narrative. Our\nexperiments show that leading LLMs (e.g., OpenAI o4, Gemini 2.5 Pro) collapse\nin performance on Verbose ListOps at modest (~10k token) narrative lengths,\ndespite effortlessly solving raw ListOps equations. Addressing this failure is\nparamount for real-world text interpretation which requires identifying key\nreasoning points, tracking conceptual intermediate results, and filtering\nirrelevant information. Verbose ListOps, and its extensible generation\nframework thus enables targeted reasoning enhancements beyond mere\ncontext-window expansion; a critical step to automating the world's knowledge\nwork.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05331", "pdf": "https://arxiv.org/pdf/2506.05331", "abs": "https://arxiv.org/abs/2506.05331", "authors": ["Xinyan Chen", "Renrui Zhang", "Dongzhi Jiang", "Aojun Zhou", "Shilin Yan", "Weifeng Lin", "Hongsheng Li"], "title": "MINT-CoT: Enabling Interleaved Visual Tokens in Mathematical Chain-of-Thought Reasoning", "categories": ["cs.CV"], "comment": "Code is released at https://github.com/xinyan-cxy/MINT-CoT", "summary": "Chain-of-Thought (CoT) has widely enhanced mathematical reasoning in Large\nLanguage Models (LLMs), but it still remains challenging for extending it to\nmultimodal domains. Existing works either adopt a similar textual reasoning for\nimage input, or seek to interleave visual signals into mathematical CoT.\nHowever, they face three key limitations for math problem-solving: reliance on\ncoarse-grained box-shaped image regions, limited perception of vision encoders\non math content, and dependence on external capabilities for visual\nmodification. In this paper, we propose MINT-CoT, introducing Mathematical\nINterleaved Tokens for Chain-of-Thought visual reasoning. MINT-CoT adaptively\ninterleaves relevant visual tokens into textual reasoning steps via an\nInterleave Token, which dynamically selects visual regions of any shapes within\nmath figures. To empower this capability, we construct the MINT-CoT dataset,\ncontaining 54K mathematical problems aligning each reasoning step with visual\nregions at the token level, accompanied by a rigorous data generation pipeline.\nWe further present a three-stage MINT-CoT training strategy, progressively\ncombining text-only CoT SFT, interleaved CoT SFT, and interleaved CoT RL, which\nderives our MINT-CoT-7B model. Extensive experiments demonstrate the\neffectiveness of our method for effective visual interleaved reasoning in\nmathematical domains, where MINT-CoT-7B outperforms the baseline model by\n+34.08% on MathVista, +28.78% on GeoQA, and +23.2% on MMStar, respectively. Our\ncode and data are available at https://github.com/xinyan-cxy/MINT-CoT", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05310", "pdf": "https://arxiv.org/pdf/2506.05310", "abs": "https://arxiv.org/abs/2506.05310", "authors": ["Florentin Guth", "Zahra Kadkhodaie", "Eero P Simoncelli"], "title": "Learning normalized image densities via dual score matching", "categories": ["cs.LG"], "comment": null, "summary": "Learning probability models from data is at the heart of many machine\nlearning endeavors, but is notoriously difficult due to the curse of\ndimensionality. We introduce a new framework for learning \\emph{normalized}\nenergy (log probability) models that is inspired from diffusion generative\nmodels, which rely on networks optimized to estimate the score. We modify a\nscore network architecture to compute an energy while preserving its inductive\nbiases. The gradient of this energy network with respect to its input image is\nthe score of the learned density, which can be optimized using a denoising\nobjective. Importantly, the gradient with respect to the noise level provides\nan additional score that can be optimized with a novel secondary objective,\nensuring consistent and normalized energies across noise levels. We train an\nenergy network with this \\emph{dual} score matching objective on the ImageNet64\ndataset, and obtain a cross-entropy (negative log likelihood) value comparable\nto the state of the art. We further validate our approach by showing that our\nenergy model \\emph{strongly generalizes}: estimated log probabilities are\nnearly independent of the specific images in the training set. Finally, we\ndemonstrate that both image probability and dimensionality of local\nneighborhoods vary significantly with image content, in contrast with\ntraditional assumptions such as concentration of measure or support on a\nlow-dimensional manifold.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04920", "pdf": "https://arxiv.org/pdf/2506.04920", "abs": "https://arxiv.org/abs/2506.04920", "authors": ["Junior Cedric Tonga", "KV Aditya Srivatsa", "Kaushal Kumar Maurya", "Fajri Koto", "Ekaterina Kochmar"], "title": "Simulating LLM-to-LLM Tutoring for Multilingual Math Feedback", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint, in submission", "summary": "Large language models (LLMs) have demonstrated the ability to generate\nformative feedback and instructional hints in English, making them increasingly\nrelevant for AI-assisted education. However, their ability to provide effective\ninstructional support across different languages, especially for mathematically\ngrounded reasoning tasks, remains largely unexamined. In this work, we present\nthe first large-scale simulation of multilingual tutor-student interactions\nusing LLMs. A stronger model plays the role of the tutor, generating feedback\nin the form of hints, while a weaker model simulates the student. We explore\n352 experimental settings across 11 typologically diverse languages, four\nstate-of-the-art LLMs, and multiple prompting strategies to assess whether\nlanguage-specific feedback leads to measurable learning gains. Our study\nexamines how student input language, teacher feedback language, model choice,\nand language resource level jointly influence performance. Results show that\nmultilingual hints can significantly improve learning outcomes, particularly in\nlow-resource languages when feedback is aligned with the student's native\nlanguage. These findings offer practical insights for developing multilingual,\nLLM-based educational tools that are both effective and inclusive.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05332", "pdf": "https://arxiv.org/pdf/2506.05332", "abs": "https://arxiv.org/abs/2506.05332", "authors": ["Jingyang Lin", "Jialian Wu", "Ximeng Sun", "Ze Wang", "Jiang Liu", "Yusheng Su", "Xiaodong Yu", "Hao Chen", "Jiebo Luo", "Zicheng Liu", "Emad Barsoum"], "title": "Unleashing Hour-Scale Video Training for Long Video-Language Understanding", "categories": ["cs.CV", "cs.CL"], "comment": "Project page: https://videomarathon.github.io/", "summary": "Recent long-form video-language understanding benchmarks have driven progress\nin video large multimodal models (Video-LMMs). However, the scarcity of\nwell-annotated long videos has left the training of hour-long Video-LLMs\nunderexplored. To close this gap, we present VideoMarathon, a large-scale\nhour-long video instruction-following dataset. This dataset includes around\n9,700 hours of long videos sourced from diverse domains, ranging from 3 to 60\nminutes per video. Specifically, it contains 3.3M high-quality QA pairs,\nspanning six fundamental topics: temporality, spatiality, object, action,\nscene, and event. Compared to existing video instruction datasets,\nVideoMarathon significantly extends training video durations up to 1 hour, and\nsupports 22 diverse tasks requiring both short- and long-term video\ncomprehension. Building on VideoMarathon, we propose Hour-LLaVA, a powerful and\nefficient Video-LMM for hour-scale video-language modeling. It enables\nhour-long video training and inference at 1-FPS sampling by leveraging a memory\naugmentation module, which adaptively integrates user question-relevant and\nspatiotemporal-informative semantics from a cached full video context. In our\nexperiments, Hour-LLaVA achieves the best performance on multiple long\nvideo-language benchmarks, demonstrating the high quality of the VideoMarathon\ndataset and the superiority of the Hour-LLaVA model.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05316", "pdf": "https://arxiv.org/pdf/2506.05316", "abs": "https://arxiv.org/abs/2506.05316", "authors": ["Yifan Sun", "Jingyan Shen", "Yibin Wang", "Tianyu Chen", "Zhendong Wang", "Mingyuan Zhou", "Huan Zhang"], "title": "Improving Data Efficiency for LLM Reinforcement Fine-tuning Through Difficulty-targeted Online Data Selection and Rollout Replay", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement learning (RL) has become an effective approach for fine-tuning\nlarge language models (LLMs), particularly to enhance their reasoning\ncapabilities. However, RL fine-tuning remains highly resource-intensive, and\nexisting work has largely overlooked the problem of data efficiency. In this\npaper, we propose two techniques to improve data efficiency in LLM RL\nfine-tuning: difficulty-targeted online data selection and rollout replay. We\nintroduce the notion of adaptive difficulty to guide online data selection,\nprioritizing questions of moderate difficulty that are more likely to yield\ninformative learning signals. To estimate adaptive difficulty efficiently, we\ndevelop an attention-based framework that requires rollouts for only a small\nreference set of questions. The adaptive difficulty of the remaining questions\nis then estimated based on their similarity to this set. To further reduce\nrollout cost, we introduce a rollout replay mechanism that reuses recent\nrollouts, lowering per-step computation while maintaining stable updates.\nExtensive experiments across 6 LLM-dataset combinations show that our method\nreduces RL fine-tuning time by 25% to 65% to reach the same level of\nperformance as the original GRPO algorithm.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05336", "pdf": "https://arxiv.org/pdf/2506.05336", "abs": "https://arxiv.org/abs/2506.05336", "authors": ["Ghazi Shazan Ahmad", "Ahmed Heakl", "Hanan Gani", "Abdelrahman Shaker", "Zhiqiang Shen", "Ranjay Krishna", "Fahad Shahbaz Khan", "Salman Khan"], "title": "VideoMolmo: Spatio-Temporal Grounding Meets Pointing", "categories": ["cs.CV"], "comment": "20 pages, 13 figures", "summary": "Spatio-temporal localization is vital for precise interactions across diverse\ndomains, from biological research to autonomous navigation and interactive\ninterfaces. Current video-based approaches, while proficient in tracking, lack\nthe sophisticated reasoning capabilities of large language models, limiting\ntheir contextual understanding and generalization. We introduce VideoMolmo, a\nlarge multimodal model tailored for fine-grained spatio-temporal pointing\nconditioned on textual descriptions. Building upon the Molmo architecture,\nVideoMolmo incorporates a temporal module utilizing an attention mechanism to\ncondition each frame on preceding frames, ensuring temporal consistency.\nAdditionally, our novel temporal mask fusion pipeline employs SAM2 for\nbidirectional point propagation, significantly enhancing coherence across video\nsequences. This two-step decomposition, i.e., first using the LLM to generate\nprecise pointing coordinates, then relying on a sequential mask-fusion module\nto produce coherent segmentation, not only simplifies the task for the language\nmodel but also enhances interpretability. Due to the lack of suitable datasets,\nwe curate a comprehensive dataset comprising 72k video-caption pairs annotated\nwith 100k object points. To evaluate the generalization of VideoMolmo, we\nintroduce VPoS-Bench, a challenging out-of-distribution benchmark spanning five\nreal-world scenarios: Cell Tracking, Egocentric Vision, Autonomous Driving,\nVideo-GUI Interaction, and Robotics. We also evaluate our model on Referring\nVideo Object Segmentation (Refer-VOS) and Reasoning VOS tasks. In comparison to\nexisting models, VideoMolmo substantially improves spatio-temporal pointing\naccuracy and reasoning capability. Our code and models are publicly available\nat https://github.com/mbzuai-oryx/VideoMolmo.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05321", "pdf": "https://arxiv.org/pdf/2506.05321", "abs": "https://arxiv.org/abs/2506.05321", "authors": ["Maxwell A. Xu", "Girish Narayanswamy", "Kumar Ayush", "Dimitris Spathis", "Shun Liao", "Shyam A. Tailor", "Ahmed Metwally", "A. Ali Heydari", "Yuwei Zhang", "Jake Garrison", "Samy Abdel-Ghaffar", "Xuhai Xu", "Ken Gu", "Jacob Sunshine", "Ming-Zher Poh", "Yun Liu", "Tim Althoff", "Shrikanth Narayanan", "Pushmeet Kohli", "Mark Malhotra", "Shwetak Patel", "Yuzhe Yang", "James M. Rehg", "Xin Liu", "Daniel McDuff"], "title": "LSM-2: Learning from Incomplete Wearable Sensor Data", "categories": ["cs.LG"], "comment": "Xu and Narayanswamy are co-first authors. McDuff and Liu are co-last\n  authors", "summary": "Foundation models, a cornerstone of recent advancements in machine learning,\nhave predominantly thrived on complete and well-structured data. Wearable\nsensor data frequently suffers from significant missingness, posing a\nsubstantial challenge for self-supervised learning (SSL) models that typically\nassume complete data inputs. This paper introduces the second generation of\nLarge Sensor Model (LSM-2) with Adaptive and Inherited Masking (AIM), a novel\nSSL approach that learns robust representations directly from incomplete data\nwithout requiring explicit imputation. AIM's core novelty lies in its use of\nlearnable mask tokens to model both existing (\"inherited\") and artificially\nintroduced missingness, enabling it to robustly handle fragmented real-world\ndata during inference. Pre-trained on an extensive dataset of 40M hours of\nday-long multimodal sensor data, our LSM-2 with AIM achieves the best\nperformance across a diverse range of tasks, including classification,\nregression and generative modeling. Furthermore, LSM-2 with AIM exhibits\nsuperior scaling performance, and critically, maintains high performance even\nunder targeted missingness scenarios, reflecting clinically coherent patterns,\nsuch as the diagnostic value of nighttime biosignals for hypertension\nprediction. This makes AIM a more reliable choice for real-world wearable data\napplications.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05338", "pdf": "https://arxiv.org/pdf/2506.05338", "abs": "https://arxiv.org/abs/2506.05338", "authors": ["Alan Dolhasz", "Chen Ma", "Dave Gausebeck", "Kevin Chen", "Gregor Miller", "Lucas Hayne", "Gunnar Hovden", "Azwad Sabik", "Olaf Brandt", "Mira Slavcheva"], "title": "Defurnishing with X-Ray Vision: Joint Removal of Furniture from Panoramas and Mesh", "categories": ["cs.CV"], "comment": null, "summary": "We present a pipeline for generating defurnished replicas of indoor spaces\nrepresented as textured meshes and corresponding multi-view panoramic images.\nTo achieve this, we first segment and remove furniture from the mesh\nrepresentation, extend planes, and fill holes, obtaining a simplified\ndefurnished mesh (SDM). This SDM acts as an ``X-ray'' of the scene's underlying\nstructure, guiding the defurnishing process. We extract Canny edges from depth\nand normal images rendered from the SDM. We then use these as a guide to remove\nthe furniture from panorama images via ControlNet inpainting. This control\nsignal ensures the availability of global geometric information that may be\nhidden from a particular panoramic view by the furniture being removed. The\ninpainted panoramas are used to texture the mesh. We show that our approach\nproduces higher quality assets than methods that rely on neural radiance\nfields, which tend to produce blurry low-resolution images, or RGB-D\ninpainting, which is highly susceptible to hallucinations.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05325", "pdf": "https://arxiv.org/pdf/2506.05325", "abs": "https://arxiv.org/abs/2506.05325", "authors": ["Yingshuai Ji", "Haomin Zhuang", "Matthew Toole", "James McKenzie", "Xiaolong Liu", "Xiangliang Zhang"], "title": "Seeing the Invisible: Machine learning-Based QPI Kernel Extraction via Latent Alignment", "categories": ["cs.LG"], "comment": null, "summary": "Quasiparticle interference (QPI) imaging is a powerful tool for probing\nelectronic structures in quantum materials, but extracting the single-scatterer\nQPI pattern (i.e., the kernel) from a multi-scatterer image remains a\nfundamentally ill-posed inverse problem. In this work, we propose the first\nAI-based framework for QPI kernel extraction. We introduce a two-step learning\nstrategy that decouples kernel representation learning from\nobservation-to-kernel inference. In the first step, we train a variational\nautoencoder to learn a compact latent space of scattering kernels. In the\nsecond step, we align the latent representation of QPI observations with those\nof the pre-learned kernels using a dedicated encoder. This design enables the\nmodel to infer kernels robustly even under complex, entangled scattering\nconditions. We construct a diverse and physically realistic QPI dataset\ncomprising 100 unique kernels and evaluate our method against a direct one-step\nbaseline. Experimental results demonstrate that our approach achieves\nsignificantly higher extraction accuracy, and improved generalization to unseen\nkernels.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04965", "pdf": "https://arxiv.org/pdf/2506.04965", "abs": "https://arxiv.org/abs/2506.04965", "authors": ["Adrian Marius Dumitran", "Theodor-Pierre Moroianu", "Vasile Paul Alexe"], "title": "From Struggle (06-2024) to Mastery (02-2025) LLMs Conquer Advanced Algorithm Exams and Pave the Way for Editorial Generation", "categories": ["cs.CL", "cs.AI"], "comment": "15 pages Pre-print Paper accepted to ITS 2025", "summary": "This paper presents a comprehensive evaluation of the performance of\nstate-of-the-art Large Language Models (LLMs) on challenging university-level\nalgorithms exams. By testing multiple models on both a Romanian exam and its\nhigh-quality English translation, we analyze LLMs' problem-solving\ncapabilities, consistency, and multilingual performance. Our empirical study\nreveals that the most recent models not only achieve scores comparable to\ntop-performing students but also demonstrate robust reasoning skills on\ncomplex, multi-step algorithmic challenges, even though difficulties remain\nwith graph-based tasks. Building on these findings, we explore the potential of\nLLMs to support educational environments through the generation of high-quality\neditorial content, offering instructors a powerful tool to enhance student\nfeedback. The insights and best practices discussed herein pave the way for\nfurther integration of generative AI in advanced algorithm education.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05341", "pdf": "https://arxiv.org/pdf/2506.05341", "abs": "https://arxiv.org/abs/2506.05341", "authors": ["Xingjian Ran", "Yixuan Li", "Linning Xu", "Mulin Yu", "Bo Dai"], "title": "Direct Numerical Layout Generation for 3D Indoor Scene Synthesis via Spatial Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": "Project Page: https://directlayout.github.io/", "summary": "Realistic 3D indoor scene synthesis is vital for embodied AI and digital\ncontent creation. It can be naturally divided into two subtasks: object\ngeneration and layout generation. While recent generative models have\nsignificantly advanced object-level quality and controllability, layout\ngeneration remains challenging due to limited datasets. Existing methods either\noverfit to these datasets or rely on predefined constraints to optimize\nnumerical layout that sacrifice flexibility. As a result, they fail to generate\nscenes that are both open-vocabulary and aligned with fine-grained user\ninstructions. We introduce DirectLayout, a framework that directly generates\nnumerical 3D layouts from text descriptions using generalizable spatial\nreasoning of large language models (LLMs). DirectLayout decomposes the\ngeneration into three stages: producing a Bird's-Eye View (BEV) layout, lifting\nit into 3D space, and refining object placements. To enable explicit spatial\nreasoning and help the model grasp basic principles of object placement, we\nemploy Chain-of-Thought (CoT) Activation based on the 3D-Front dataset.\nAdditionally, we design CoT-Grounded Generative Layout Reward to enhance\ngeneralization and spatial planning. During inference, DirectLayout addresses\nasset-layout mismatches via Iterative Asset-Layout Alignment through in-context\nlearning. Extensive experiments demonstrate that DirectLayout achieves\nimpressive semantic consistency, generalization and physical plausibility.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05333", "pdf": "https://arxiv.org/pdf/2506.05333", "abs": "https://arxiv.org/abs/2506.05333", "authors": ["Ranajoy Sadhukhan", "Zhuoming Chen", "Haizhong Zheng", "Yang Zhou", "Emma Strubell", "Beidi Chen"], "title": "Kinetics: Rethinking Test-Time Scaling Laws", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "We rethink test-time scaling laws from a practical efficiency perspective,\nrevealing that the effectiveness of smaller models is significantly\noverestimated. Prior work, grounded in compute-optimality, overlooks critical\nmemory access bottlenecks introduced by inference-time strategies (e.g.,\nBest-of-$N$, long CoTs). Our holistic analysis, spanning models from 0.6B to\n32B parameters, reveals a new Kinetics Scaling Law that better guides resource\nallocation by incorporating both computation and memory access costs. Kinetics\nScaling Law suggests that test-time compute is more effective when used on\nmodels above a threshold than smaller ones. A key reason is that in TTS,\nattention, rather than parameter count, emerges as the dominant cost factor.\nMotivated by this, we propose a new scaling paradigm centered on sparse\nattention, which lowers per-token cost and enables longer generations and more\nparallel samples within the same resource budget. Empirically, we show that\nsparse attention models consistently outperform dense counterparts, achieving\nover 60 points gains in low-cost regimes and over 5 points gains in high-cost\nregimes for problem-solving accuracy on AIME, encompassing evaluations on\nstate-of-the-art MoEs. These results suggest that sparse attention is essential\nfor realizing the full potential of test-time scaling because, unlike training,\nwhere parameter scaling saturates, test-time accuracy continues to improve\nthrough increased generation. The code is available at\nhttps://github.com/Infini-AI-Lab/Kinetics.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05342", "pdf": "https://arxiv.org/pdf/2506.05342", "abs": "https://arxiv.org/abs/2506.05342", "authors": ["Shengcao Cao", "Zijun Wei", "Jason Kuen", "Kangning Liu", "Lingzhi Zhang", "Jiuxiang Gu", "HyunJoon Jung", "Liang-Yan Gui", "Yu-Xiong Wang"], "title": "Refer to Anything with Vision-Language Prompts", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent image segmentation models have advanced to segment images into\nhigh-quality masks for visual entities, and yet they cannot provide\ncomprehensive semantic understanding for complex queries based on both language\nand vision. This limitation reduces their effectiveness in applications that\nrequire user-friendly interactions driven by vision-language prompts. To bridge\nthis gap, we introduce a novel task of omnimodal referring expression\nsegmentation (ORES). In this task, a model produces a group of masks based on\narbitrary prompts specified by text only or text plus reference visual\nentities. To address this new challenge, we propose a novel framework to \"Refer\nto Any Segmentation Mask Group\" (RAS), which augments segmentation models with\ncomplex multimodal interactions and comprehension via a mask-centric large\nmultimodal model. For training and benchmarking ORES models, we create datasets\nMaskGroups-2M and MaskGroups-HQ to include diverse mask groups specified by\ntext and reference entities. Through extensive evaluation, we demonstrate\nsuperior performance of RAS on our new ORES task, as well as classic referring\nexpression segmentation (RES) and generalized referring expression segmentation\n(GRES) tasks. Project page: https://Ref2Any.github.io.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05340", "pdf": "https://arxiv.org/pdf/2506.05340", "abs": "https://arxiv.org/abs/2506.05340", "authors": ["Keshigeyan Chandrasegaran", "Michael Poli", "Daniel Y. Fu", "Dongjun Kim", "Lea M. Hadzic", "Manling Li", "Agrim Gupta", "Stefano Massaroli", "Azalia Mirhoseini", "Juan Carlos Niebles", "Stefano Ermon", "Li Fei-Fei"], "title": "Exploring Diffusion Transformer Designs via Grafting", "categories": ["cs.LG", "cs.AI"], "comment": "22 pages; Project website: https://grafting.stanford.edu", "summary": "Designing model architectures requires decisions such as selecting operators\n(e.g., attention, convolution) and configurations (e.g., depth, width).\nHowever, evaluating the impact of these decisions on model quality requires\ncostly pretraining, limiting architectural investigation. Inspired by how new\nsoftware is built on existing code, we ask: can new architecture designs be\nstudied using pretrained models? To this end, we present grafting, a simple\napproach for editing pretrained diffusion transformers (DiTs) to materialize\nnew architectures under small compute budgets. Informed by our analysis of\nactivation behavior and attention locality, we construct a testbed based on the\nDiT-XL/2 design to study the impact of grafting on model quality. Using this\ntestbed, we develop a family of hybrid designs via grafting: replacing softmax\nattention with gated convolution, local attention, and linear attention, and\nreplacing MLPs with variable expansion ratio and convolutional variants.\nNotably, many hybrid designs achieve good quality (FID: 2.38-2.64 vs. 2.27 for\nDiT-XL/2) using <2% pretraining compute. We then graft a text-to-image model\n(PixArt-Sigma), achieving a 1.43x speedup with less than a 2% drop in GenEval\nscore. Finally, we present a case study that restructures DiT-XL/2 by\nconverting every pair of sequential transformer blocks into parallel blocks via\ngrafting. This reduces model depth by 2x and yields better quality (FID: 2.77)\nthan other models of comparable depth. Together, we show that new diffusion\nmodel designs can be explored by grafting pretrained DiTs, with edits ranging\nfrom operator replacement to architecture restructuring. Code and grafted\nmodels: https://grafting.stanford.edu", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05343", "pdf": "https://arxiv.org/pdf/2506.05343", "abs": "https://arxiv.org/abs/2506.05343", "authors": ["Wenfeng Lin", "Renjie Chen", "Boyuan Liu", "Shiyue Yan", "Ruoyu Feng", "Jiangchuan Wei", "Yichen Zhang", "Yimeng Zhou", "Chao Feng", "Jiao Ran", "Qi Wu", "Zuotao Liu", "Mingyu Guo"], "title": "ContentV: Efficient Training of Video Generation Models with Limited Compute", "categories": ["cs.CV"], "comment": "Project Page: https://contentv.github.io", "summary": "Recent advances in video generation demand increasingly efficient training\nrecipes to mitigate escalating computational costs. In this report, we present\nContentV, an 8B-parameter text-to-video model that achieves state-of-the-art\nperformance (85.14 on VBench) after training on 256 x 64GB Neural Processing\nUnits (NPUs) for merely four weeks. ContentV generates diverse, high-quality\nvideos across multiple resolutions and durations from text prompts, enabled by\nthree key innovations: (1) A minimalist architecture that maximizes reuse of\npre-trained image generation models for video generation; (2) A systematic\nmulti-stage training strategy leveraging flow matching for enhanced efficiency;\nand (3) A cost-effective reinforcement learning with human feedback framework\nthat improves generation quality without requiring additional human\nannotations. All the code and models are available at:\nhttps://contentv.github.io.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05345", "pdf": "https://arxiv.org/pdf/2506.05345", "abs": "https://arxiv.org/abs/2506.05345", "authors": ["Adrian Łańcucki", "Konrad Staniszewski", "Piotr Nawrot", "Edoardo M. Ponti"], "title": "Inference-Time Hyper-Scaling with KV Cache Compression", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Inference-time scaling trades efficiency for increased reasoning accuracy by\ngenerating longer or more parallel sequences. However, in Transformer LLMs,\ngeneration cost is bottlenecked by the size of the key-value (KV) cache, rather\nthan the number of generated tokens. Hence, we explore inference-time\nhyper-scaling: by compressing the KV cache, we can generate more tokens within\nthe same compute budget and further improve the accuracy of scaled inference.\nThe success of this approach, however, hinges on the ability of compression\nmethods to preserve accuracy even at high compression ratios. To make\nhyper-scaling practical, we introduce Dynamic Memory Sparsification (DMS), a\nnovel method for sparsifying KV caches that only requires 1K training steps to\nachieve 8$\\times$ compression, while maintaining better accuracy than\ntraining-free sparse attention. Instead of prematurely discarding cached\ntokens, DMS delays token eviction, implicitly merging representations and\npreserving critical information. We demonstrate the effectiveness of\ninference-time hyper-scaling with DMS on multiple families of LLMs, showing\nthat it boosts accuracy for comparable inference runtime and memory load. For\ninstance, we enhance Qwen-R1 32B by an average of 9.1 points on AIME 24, 7.6 on\nGPQA, and 9.6 on LiveCodeBench across compute budgets.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05344", "pdf": "https://arxiv.org/pdf/2506.05344", "abs": "https://arxiv.org/abs/2506.05344", "authors": ["Jiahui Wang", "Zuyan Liu", "Yongming Rao", "Jiwen Lu"], "title": "SparseMM: Head Sparsity Emerges from Visual Concept Responses in MLLMs", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) are commonly derived by extending\npre-trained Large Language Models (LLMs) with visual capabilities. In this\nwork, we investigate how MLLMs process visual inputs by analyzing their\nattention mechanisms. We reveal a surprising sparsity phenomenon: only a small\nsubset (approximately less than 5%) of attention heads in LLMs actively\ncontribute to visual understanding, termed visual heads. To identify these\nheads efficiently, we design a training-free framework that quantifies\nhead-level visual relevance through targeted response analysis. Building on\nthis discovery, we introduce SparseMM, a KV-Cache optimization strategy that\nallocates asymmetric computation budgets to heads in LLMs based on their visual\nscores, leveraging the sparity of visual heads for accelerating the inference\nof MLLMs. Compared with prior KV-Cache acceleration methods that ignore the\nparticularity of visual, SparseMM prioritizes stress and retaining visual\nsemantics during decoding. Extensive evaluations across mainstream multimodal\nbenchmarks demonstrate that SparseMM achieves superior accuracy-efficiency\ntrade-offs. Notably, SparseMM delivers 1.38x real-time acceleration and 52%\nmemory reduction during generation while maintaining performance parity on\nefficiency test. Our project is open sourced at\nhttps://github.com/CR400AF-A/SparseMM.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.03177", "pdf": "https://arxiv.org/pdf/2506.03177", "abs": "https://arxiv.org/abs/2506.03177", "authors": ["Isarun Chamveha", "Supphanut Chaiyungyuen", "Sasinun Worakriangkrai", "Nattawadee Prasawang", "Warasinee Chaisangmongkon", "Pornpim Korpraphong", "Voraparee Suvannarerg", "Shanigarn Thiravit", "Chalermdej Kannawat", "Kewalin Rungsinaporn", "Suwara Issaragrisil", "Payia Chadbunchachai", "Pattiya Gatechumpol", "Chawiporn Muktabhant", "Patarachai Sereerat"], "title": "Deep Learning-Based Breast Cancer Detection in Mammography: A Multi-Center Validation Study in Thai Population", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "This study presents a deep learning system for breast cancer detection in\nmammography, developed using a modified EfficientNetV2 architecture with\nenhanced attention mechanisms. The model was trained on mammograms from a major\nThai medical center and validated on three distinct datasets: an in-domain test\nset (9,421 cases), a biopsy-confirmed set (883 cases), and an out-of-domain\ngeneralizability set (761 cases) collected from two different hospitals. For\ncancer detection, the model achieved AUROCs of 0.89, 0.96, and 0.94 on the\nrespective datasets. The system's lesion localization capability, evaluated\nusing metrics including Lesion Localization Fraction (LLF) and Non-Lesion\nLocalization Fraction (NLF), demonstrated robust performance in identifying\nsuspicious regions. Clinical validation through concordance tests showed strong\nagreement with radiologists: 83.5% classification and 84.0% localization\nconcordance for biopsy-confirmed cases, and 78.1% classification and 79.6%\nlocalization concordance for out-of-domain cases. Expert radiologists'\nacceptance rate also averaged 96.7% for biopsy-confirmed cases, and 89.3% for\nout-of-domain cases. The system achieved a System Usability Scale score of\n74.17 for source hospital, and 69.20 for validation hospitals, indicating good\nclinical acceptance. These results demonstrate the model's effectiveness in\nassisting mammogram interpretation, with the potential to enhance breast cancer\nscreening workflows in clinical practice.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04494", "pdf": "https://arxiv.org/pdf/2506.04494", "abs": "https://arxiv.org/abs/2506.04494", "authors": ["Yue Gong", "Chuan Lei", "Xiao Qin", "Kapil Vaidya", "Balakrishnan Narayanaswamy", "Tim Kraska"], "title": "SQLens: An End-to-End Framework for Error Detection and Correction in Text-to-SQL", "categories": ["cs.CL"], "comment": null, "summary": "Text-to-SQL systems translate natural language (NL) questions into SQL\nqueries, enabling non-technical users to interact with structured data. While\nlarge language models (LLMs) have shown promising results on the text-to-SQL\ntask, they often produce semantically incorrect yet syntactically valid\nqueries, with limited insight into their reliability. We propose SQLens, an\nend-to-end framework for fine-grained detection and correction of semantic\nerrors in LLM-generated SQL. SQLens integrates error signals from both the\nunderlying database and the LLM to identify potential semantic errors within\nSQL clauses. It further leverages these signals to guide query correction.\nEmpirical results on two public benchmarks show that SQLens outperforms the\nbest LLM-based self-evaluation method by 25.78% in F1 for error detection, and\nimproves execution accuracy of out-of-the-box text-to-SQL systems by up to 20%.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05347", "pdf": "https://arxiv.org/pdf/2506.05347", "abs": "https://arxiv.org/abs/2506.05347", "authors": ["Anagh Malik", "Benjamin Attal", "Andrew Xie", "Matthew O'Toole", "David B. Lindell"], "title": "Neural Inverse Rendering from Propagating Light", "categories": ["cs.CV"], "comment": "Website: https://anaghmalik.com/InvProp/", "summary": "We present the first system for physically based, neural inverse rendering\nfrom multi-viewpoint videos of propagating light. Our approach relies on a\ntime-resolved extension of neural radiance caching -- a technique that\naccelerates inverse rendering by storing infinite-bounce radiance arriving at\nany point from any direction. The resulting model accurately accounts for\ndirect and indirect light transport effects and, when applied to captured\nmeasurements from a flash lidar system, enables state-of-the-art 3D\nreconstruction in the presence of strong indirect light. Further, we\ndemonstrate view synthesis of propagating light, automatic decomposition of\ncaptured measurements into direct and indirect components, as well as novel\ncapabilities such as multi-view time-resolved relighting of captured scenes.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05348", "pdf": "https://arxiv.org/pdf/2506.05348", "abs": "https://arxiv.org/abs/2506.05348", "authors": ["Yifan Wang", "Peishan Yang", "Zhen Xu", "Jiaming Sun", "Zhanhua Zhang", "Yong Chen", "Hujun Bao", "Sida Peng", "Xiaowei Zhou"], "title": "FreeTimeGS: Free Gaussians at Anytime and Anywhere for Dynamic Scene Reconstruction", "categories": ["cs.CV"], "comment": "CVPR 2025; Project page: https://zju3dv.github.io/freetimegs/", "summary": "This paper addresses the challenge of reconstructing dynamic 3D scenes with\ncomplex motions. Some recent works define 3D Gaussian primitives in the\ncanonical space and use deformation fields to map canonical primitives to\nobservation spaces, achieving real-time dynamic view synthesis. However, these\nmethods often struggle to handle scenes with complex motions due to the\ndifficulty of optimizing deformation fields. To overcome this problem, we\npropose FreeTimeGS, a novel 4D representation that allows Gaussian primitives\nto appear at arbitrary time and locations. In contrast to canonical Gaussian\nprimitives, our representation possesses the strong flexibility, thus improving\nthe ability to model dynamic 3D scenes. In addition, we endow each Gaussian\nprimitive with an motion function, allowing it to move to neighboring regions\nover time, which reduces the temporal redundancy. Experiments results on\nseveral datasets show that the rendering quality of our method outperforms\nrecent methods by a large margin.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05349", "pdf": "https://arxiv.org/pdf/2506.05349", "abs": "https://arxiv.org/abs/2506.05349", "authors": ["Hanoona Rasheed", "Abdelrahman Shaker", "Anqi Tang", "Muhammad Maaz", "Ming-Hsuan Yang", "Salman Khan", "Fahad Khan"], "title": "VideoMathQA: Benchmarking Mathematical Reasoning via Multimodal Understanding in Videos", "categories": ["cs.CV"], "comment": "VideoMathQA Technical Report", "summary": "Mathematical reasoning in real-world video settings presents a fundamentally\ndifferent challenge than in static images or text. It requires interpreting\nfine-grained visual information, accurately reading handwritten or digital\ntext, and integrating spoken cues, often dispersed non-linearly over time. In\nsuch multimodal contexts, success hinges not just on perception, but on\nselectively identifying and integrating the right contextual details from a\nrich and noisy stream of content. To this end, we introduce VideoMathQA, a\nbenchmark designed to evaluate whether models can perform such temporally\nextended cross-modal reasoning on videos. The benchmark spans 10 diverse\nmathematical domains, covering videos ranging from 10 seconds to over 1 hour.\nIt requires models to interpret structured visual content, understand\ninstructional narratives, and jointly ground concepts across visual, audio, and\ntextual modalities. We employ graduate-level experts to ensure high quality,\ntotaling over $920$ man-hours of annotation. To reflect real-world scenarios,\nquestions are designed around three core reasoning challenges: direct problem\nsolving, where answers are grounded in the presented question; conceptual\ntransfer, which requires applying learned methods to new problems; and deep\ninstructional comprehension, involving multi-step reasoning over extended\nexplanations and partially worked-out solutions. Each question includes\nmulti-step reasoning annotations, enabling fine-grained diagnosis of model\ncapabilities. Through this benchmark, we highlight the limitations of existing\napproaches and establish a systematic evaluation framework for models that must\nreason, rather than merely perceive, across temporally extended and\nmodality-rich mathematical problem settings. Our benchmark and evaluation code\nare available at: https://mbzuai-oryx.github.io/VideoMathQA", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04240", "pdf": "https://arxiv.org/pdf/2506.04240", "abs": "https://arxiv.org/abs/2506.04240", "authors": ["Sydney Anuyah"], "title": "What does making money have to do with crime?: A dive into the National Crime Victimization survey", "categories": ["physics.soc-ph", "cs.LG"], "comment": null, "summary": "In this short article, I leverage the National Crime Victimization Survey\nfrom 1992 to 2022 to examine how income, education, employment, and key\ndemographic factors shape the type of crime victims experience (violent vs\nproperty). Using balanced classification splits and logistic regression models\nevaluated by F1-score, there is an isolation of the socioeconomic drivers of\nvictimization \"Group A\" models and then an introduction of demographic factors\nsuch as age, gender, race, and marital status controls called \"Group B\" models.\nThe results consistently proves that higher income and education lower the odds\nof violent relative to property crime, while men younger individuals and racial\nminorities face disproportionately higher violentcrime risks. On the geographic\nspectrum, the suburban models achieve the strongest predictive performance with\nan accuracy of 0.607 and F1 of 0.590, urban areas benefit from adding education\nand employment predictors and crime in rural areas are still unpredictable\nusing these current factors. The patterns found in this study shows the need\nfor specific interventions like educational investments in metropolitan\nsettings economic support in rural communities and demographicaware prevention\nstrategies.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05057", "pdf": "https://arxiv.org/pdf/2506.05057", "abs": "https://arxiv.org/abs/2506.05057", "authors": ["Moshe Ofer", "Orel Zamler", "Amos Azaria"], "title": "TALL -- A Trainable Architecture for Enhancing LLM Performance in Low-Resource Languages", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) excel in high-resource languages but struggle\nwith low-resource languages due to limited training data. This paper presents\nTALL (Trainable Architecture for Enhancing LLM Performance in Low-Resource\nLanguages), which integrates an LLM with two bilingual translation models. TALL\ntransforms low-resource inputs into high-resource representations, leveraging\nthe LLM's capabilities while preserving linguistic features through dimension\nalignment layers and custom transformers. Our experiments on Hebrew demonstrate\nsignificant improvements over several baselines, including direct use, naive\ntranslation, and fine-tuning approaches. The architecture employs a\nparameter-efficient strategy, freezing pre-trained components while training\nonly lightweight adapter modules, balancing computational efficiency with\nperformance gains.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05350", "pdf": "https://arxiv.org/pdf/2506.05350", "abs": "https://arxiv.org/abs/2506.05350", "authors": ["George Stoica", "Vivek Ramanujan", "Xiang Fan", "Ali Farhadi", "Ranjay Krishna", "Judy Hoffman"], "title": "Contrastive Flow Matching", "categories": ["cs.CV"], "comment": null, "summary": "Unconditional flow-matching trains diffusion models to transport samples from\na source distribution to a target distribution by enforcing that the flows\nbetween sample pairs are unique. However, in conditional settings (e.g.,\nclass-conditioned models), this uniqueness is no longer guaranteed--flows from\ndifferent conditions may overlap, leading to more ambiguous generations. We\nintroduce Contrastive Flow Matching, an extension to the flow matching\nobjective that explicitly enforces uniqueness across all conditional flows,\nenhancing condition separation. Our approach adds a contrastive objective that\nmaximizes dissimilarities between predicted flows from arbitrary sample pairs.\nWe validate Contrastive Flow Matching by conducting extensive experiments\nacross varying model architectures on both class-conditioned (ImageNet-1k) and\ntext-to-image (CC3M) benchmarks. Notably, we find that training models with\nContrastive Flow Matching (1) improves training speed by a factor of up to 9x,\n(2) requires up to 5x fewer de-noising steps and (3) lowers FID by up to 8.9\ncompared to training the same models with flow matching. We release our code\nat: https://github.com/gstoica27/DeltaFM.git.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05068", "pdf": "https://arxiv.org/pdf/2506.05068", "abs": "https://arxiv.org/abs/2506.05068", "authors": ["Iulia Comşa", "Murray Shanahan"], "title": "Does It Make Sense to Speak of Introspection in Large Language Models?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) exhibit compelling linguistic behaviour, and\nsometimes offer self-reports, that is to say statements about their own nature,\ninner workings, or behaviour. In humans, such reports are often attributed to a\nfaculty of introspection and are typically linked to consciousness. This raises\nthe question of how to interpret self-reports produced by LLMs, given their\nincreasing linguistic fluency and cognitive capabilities. To what extent (if\nany) can the concept of introspection be meaningfully applied to LLMs? Here, we\npresent and critique two examples of apparent introspective self-report from\nLLMs. In the first example, an LLM attempts to describe the process behind its\nown ``creative'' writing, and we argue this is not a valid example of\nintrospection. In the second example, an LLM correctly infers the value of its\nown temperature parameter, and we argue that this can be legitimately\nconsidered a minimal example of introspection, albeit one that is (presumably)\nnot accompanied by conscious experience.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2505.23449", "pdf": "https://arxiv.org/pdf/2505.23449", "abs": "https://arxiv.org/abs/2505.23449", "authors": ["Fanxiao Li", "Jiaying Wu", "Canyuan He", "Wei Zhou"], "title": "CMIE: Combining MLLM Insights with External Evidence for Explainable Out-of-Context Misinformation Detection", "categories": ["cs.MM", "cs.CV", "cs.IR"], "comment": null, "summary": "Multimodal large language models (MLLMs) have demonstrated impressive\ncapabilities in visual reasoning and text generation. While previous studies\nhave explored the application of MLLM for detecting out-of-context (OOC)\nmisinformation, our empirical analysis reveals two persisting challenges of\nthis paradigm. Evaluating the representative GPT-4o model on direct reasoning\nand evidence augmented reasoning, results indicate that MLLM struggle to\ncapture the deeper relationships-specifically, cases in which the image and\ntext are not directly connected but are associated through underlying semantic\nlinks. Moreover, noise in the evidence further impairs detection accuracy. To\naddress these challenges, we propose CMIE, a novel OOC misinformation detection\nframework that incorporates a Coexistence Relationship Generation (CRG)\nstrategy and an Association Scoring (AS) mechanism. CMIE identifies the\nunderlying coexistence relationships between images and text, and selectively\nutilizes relevant evidence to enhance misinformation detection. Experimental\nresults demonstrate that our approach outperforms existing methods.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05069", "pdf": "https://arxiv.org/pdf/2506.05069", "abs": "https://arxiv.org/abs/2506.05069", "authors": ["Keyu Zhao", "Fengli Xu", "Yong Li"], "title": "Reason-to-Recommend: Using Interaction-of-Thought Reasoning to Enhance LLM Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Driven by advances in Large Language Models (LLMs), integrating them into\nrecommendation tasks has gained interest due to their strong semantic\nunderstanding and prompt flexibility. Prior work encoded user-item interactions\nor metadata into prompts for recommendations. In parallel, LLM reasoning,\nboosted by test-time scaling and reinforcement learning, has excelled in fields\nlike mathematics and code, where reasoning traces and correctness signals are\nclear, enabling high performance and interpretability. However, directly\napplying these reasoning methods to recommendation is ineffective because user\nfeedback is implicit and lacks reasoning supervision. To address this, we\npropose $\\textbf{R2Rec}$, a reasoning-enhanced recommendation framework that\nsamples interaction chains from the user-item graph and converts them into\nstructured interaction-of-thoughts via a progressive masked prompting strategy,\nwith each thought representing stepwise reasoning grounded in interaction\ncontext. This allows LLMs to simulate step-by-step decision-making based on\nimplicit patterns. We design a two-stage training pipeline: supervised\nfine-tuning teaches basic reasoning from high-quality traces, and reinforcement\nlearning refines reasoning via reward signals, alleviating sparse explicit\nsupervision. Experiments on three real-world datasets show R2Rec outperforms\nclassical and LLM-based baselines with an average $\\textbf{10.48%}$ improvement\nin HitRatio@1 and $\\textbf{131.81%}$ gain over the original LLM. Furthermore,\nthe explicit reasoning chains enhance interpretability by revealing the\ndecision process. Our code is available at:\nhttps://anonymous.4open.science/r/R2Rec-7C5D.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05104", "pdf": "https://arxiv.org/pdf/2506.05104", "abs": "https://arxiv.org/abs/2506.05104", "authors": ["Alexander Lerch", "Claire Arthur", "Nick Bryan-Kinns", "Corey Ford", "Qianyi Sun", "Ashvala Vinay"], "title": "Survey on the Evaluation of Generative Models in Music", "categories": ["cs.SD", "cs.AI", "cs.LG"], "comment": "Submitted to ACM CSUR, 26-Jun-2024", "summary": "Research on generative systems in music has seen considerable attention and\ngrowth in recent years. A variety of attempts have been made to systematically\nevaluate such systems. We provide an interdisciplinary review of the common\nevaluation targets, methodologies, and metrics for the evaluation of both\nsystem output and model usability, covering subjective and objective\napproaches, qualitative and quantitative approaches, as well as empirical and\ncomputational methods. We discuss the advantages and challenges of such\napproaches from a musicological, an engineering, and an HCI perspective.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05128", "pdf": "https://arxiv.org/pdf/2506.05128", "abs": "https://arxiv.org/abs/2506.05128", "authors": ["Tanmay Parekh", "Kartik Mehta", "Ninareh Mehrabi", "Kai-Wei Chang", "Nanyun Peng"], "title": "DiCoRe: Enhancing Zero-shot Event Detection via Divergent-Convergent LLM Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Submitted at ACL ARR May 2025", "summary": "Zero-shot Event Detection (ED), the task of identifying event mentions in\nnatural language text without any training data, is critical for document\nunderstanding in specialized domains. Understanding the complex event ontology,\nextracting domain-specific triggers from the passage, and structuring them\nappropriately overloads and limits the utility of Large Language Models (LLMs)\nfor zero-shot ED. To this end, we propose DiCoRe, a divergent-convergent\nreasoning framework that decouples the task of ED using Dreamer and Grounder.\nDreamer encourages divergent reasoning through open-ended event discovery,\nwhich helps to boost event coverage. Conversely, Grounder introduces convergent\nreasoning to align the free-form predictions with the task-specific\ninstructions using finite-state machine guided constrained decoding.\nAdditionally, an LLM-Judge verifies the final outputs to ensure high precision.\nThrough extensive experiments on six datasets across five domains and nine\nLLMs, we demonstrate how DiCoRe consistently outperforms prior zero-shot,\ntransfer-learning, and reasoning baselines, achieving 4-7% average F1 gains\nover the best baseline -- establishing DiCoRe as a strong zero-shot ED\nframework.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04256", "pdf": "https://arxiv.org/pdf/2506.04256", "abs": "https://arxiv.org/abs/2506.04256", "authors": ["Konstantinos Kalimeris", "Leonidas Mindrinos", "Nikolaos Pallikarakis"], "title": "Estimating properties of a homogeneous bounded soil using machine learning models", "categories": ["physics.geo-ph", "cs.LG"], "comment": "35 pages, 15 figures, 19 tables", "summary": "This work focuses on estimating soil properties from water moisture\nmeasurements. We consider simulated data generated by solving the\ninitial-boundary value problem governing vertical infiltration in a\nhomogeneous, bounded soil profile, with the usage of the Fokas method. To\naddress the parameter identification problem, which is formulated as a\ntwo-output regression task, we explore various machine learning models. The\nperformance of each model is assessed under different data conditions: full,\nnoisy, and limited. Overall, the prediction of diffusivity $D$ tends to be more\naccurate than that of hydraulic conductivity $K.$ Among the models considered,\nSupport Vector Machines (SVMs) and Neural Networks (NNs) demonstrate the\nhighest robustness, achieving near-perfect accuracy and minimal errors.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05140", "pdf": "https://arxiv.org/pdf/2506.05140", "abs": "https://arxiv.org/abs/2506.05140", "authors": ["Chih-Kai Yang", "Neo Ho", "Yi-Jyun Lee", "Hung-yi Lee"], "title": "AudioLens: A Closer Look at Auditory Attribute Perception of Large Audio-Language Models", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "comment": "8 pages, 5 figures, 3 tables", "summary": "Understanding the internal mechanisms of large audio-language models (LALMs)\nis crucial for interpreting their behavior and improving performance. This work\npresents the first in-depth analysis of how LALMs internally perceive and\nrecognize auditory attributes. By applying vocabulary projection on three\nstate-of-the-art LALMs, we track how attribute information evolves across\nlayers and token positions. We find that attribute information generally\ndecreases with layer depth when recognition fails, and that resolving\nattributes at earlier layers correlates with better accuracy. Moreover, LALMs\nheavily rely on querying auditory inputs for predicting attributes instead of\naggregating necessary information in hidden states at attribute-mentioning\npositions. Based on our findings, we demonstrate a method to enhance LALMs. Our\nresults offer insights into auditory attribute processing, paving the way for\nfuture improvements.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05154", "pdf": "https://arxiv.org/pdf/2506.05154", "abs": "https://arxiv.org/abs/2506.05154", "authors": ["Chenyu Lin", "Yilin Wen", "Du Su", "Fei Sun", "Muhan Chen", "Chenfu Bao", "Zhonghou Lv"], "title": "Knowledgeable-r1: Policy Optimization for Knowledge Exploration in Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Retrieval-augmented generation (RAG) is a mainstream method for improving\nperformance on knowledge-intensive tasks. However,current RAG systems often\nplace too much emphasis on retrieved contexts. This can lead to reliance on\ninaccurate sources and overlook the model's inherent knowledge, especially when\ndealing with misleading or excessive information. To resolve this imbalance, we\npropose Knowledgeable-r1 that using joint sampling and define multi policy\ndistributions in knowledge capability exploration to stimulate large language\nmodels'self-integrated utilization of parametric and contextual knowledge.\nExperiments show that Knowledgeable-r1 significantly enhances robustness and\nreasoning accuracy in both parameters and contextual conflict tasks and general\nRAG tasks, especially outperforming baselines by 17.07% in counterfactual\nscenarios and demonstrating consistent gains across RAG tasks. Our code are\navailable at https://github.com/lcy80366872/ knowledgeable-r1.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05166", "pdf": "https://arxiv.org/pdf/2506.05166", "abs": "https://arxiv.org/abs/2506.05166", "authors": ["Bhavik Chandna", "Zubair Bashir", "Procheta Sen"], "title": "Dissecting Bias in LLMs: A Mechanistic Interpretability Perspective", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are known to exhibit social, demographic, and\ngender biases, often as a consequence of the data on which they are trained. In\nthis work, we adopt a mechanistic interpretability approach to analyze how such\nbiases are structurally represented within models such as GPT-2 and Llama2.\nFocusing on demographic and gender biases, we explore different metrics to\nidentify the internal edges responsible for biased behavior. We then assess the\nstability, localization, and generalizability of these components across\ndataset and linguistic variations. Through systematic ablations, we demonstrate\nthat bias-related computations are highly localized, often concentrated in a\nsmall subset of layers. Moreover, the identified components change across\nfine-tuning settings, including those unrelated to bias. Finally, we show that\nremoving these components not only reduces biased outputs but also affects\nother NLP tasks, such as named entity recognition and linguistic acceptability\njudgment because of the sharing of important components with these tasks.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04453", "pdf": "https://arxiv.org/pdf/2506.04453", "abs": "https://arxiv.org/abs/2506.04453", "authors": ["Hasin Us Sami", "Swapneel Sen", "Amit K. Roy-Chowdhury", "Srikanth V. Krishnamurthy", "Basak Guler"], "title": "Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning", "categories": ["eess.IV", "cs.CR", "cs.CV", "cs.LG"], "comment": "2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n  (CVPR 2025)", "summary": "Federated learning (FL) allows multiple data-owners to collaboratively train\nmachine learning models by exchanging local gradients, while keeping their\nprivate data on-device. To simultaneously enhance privacy and training\nefficiency, recently parameter-efficient fine-tuning (PEFT) of large-scale\npretrained models has gained substantial attention in FL. While keeping a\npretrained (backbone) model frozen, each user fine-tunes only a few lightweight\nmodules to be used in conjunction, to fit specific downstream applications.\nAccordingly, only the gradients with respect to these lightweight modules are\nshared with the server. In this work, we investigate how the privacy of the\nfine-tuning data of the users can be compromised via a malicious design of the\npretrained model and trainable adapter modules. We demonstrate gradient\ninversion attacks on a popular PEFT mechanism, the adapter, which allow an\nattacker to reconstruct local data samples of a target user, using only the\naccessible adapter gradients. Via extensive experiments, we demonstrate that a\nlarge batch of fine-tuning images can be retrieved with high fidelity. Our\nattack highlights the need for privacy-preserving mechanisms for PEFT, while\nopening up several future directions. Our code is available at\nhttps://github.com/info-ucr/PEFTLeak.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04516", "pdf": "https://arxiv.org/pdf/2506.04516", "abs": "https://arxiv.org/abs/2506.04516", "authors": ["Kun Zhao", "Bohao Yang", "Chen Tang", "Siyuan Dai", "Haoteng Tang", "Chenghua Lin", "Liang Zhan"], "title": "DRE: An Effective Dual-Refined Method for Integrating Small and Large Language Models in Open-Domain Dialogue Evaluation", "categories": ["cs.CL"], "comment": "arXiv admin note: text overlap with arXiv:2405.15924", "summary": "Large Language Models (LLMs) excel at many tasks but struggle with ambiguous\nscenarios where multiple valid responses exist, often yielding unreliable\nresults. Conversely, Small Language Models (SLMs) demonstrate robustness in\nsuch scenarios but are susceptible to misleading or adversarial inputs. We\nobserved that LLMs handle negative examples effectively, while SLMs excel with\npositive examples. To leverage their complementary strengths, we introduce\nSLIDE (Small and Large Integrated for Dialogue Evaluation), a method\nintegrating SLMs and LLMs via adaptive weighting. Building on SLIDE, we further\npropose a Dual-Refinement Evaluation (DRE) method to enhance SLM-LLM\nintegration: (1) SLM-generated insights guide the LLM to produce initial\nevaluations; (2) SLM-derived adjustments refine the LLM's scores for improved\naccuracy. Experiments demonstrate that DRE outperforms existing methods,\nshowing stronger alignment with human judgment across diverse benchmarks. This\nwork illustrates how combining small and large models can yield more reliable\nevaluation tools, particularly for open-ended tasks such as dialogue\nevaluation.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05167", "pdf": "https://arxiv.org/pdf/2506.05167", "abs": "https://arxiv.org/abs/2506.05167", "authors": ["Yeonseok Jeong", "Jinsu Kim", "Dohyeon Lee", "Seung-won Hwang"], "title": "ECoRAG: Evidentiality-guided Compression for Long Context RAG", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable performance in Open-Domain\nQuestion Answering (ODQA) by leveraging external documents through\nRetrieval-Augmented Generation (RAG). To reduce RAG overhead, from longer\ncontext, context compression is necessary. However, prior compression methods\ndo not focus on filtering out non-evidential information, which limit the\nperformance in LLM-based RAG. We thus propose Evidentiality-guided RAG, or\n\\textbf{ECoRAG} framework. ECoRAG improves LLM performance by compressing\nretrieved documents based on evidentiality, ensuring whether answer generation\nis supported by the correct evidence. As an additional step, ECoRAG reflects\nwhether the compressed content provides sufficient evidence, and if not,\nretrieves more until sufficient. Experiments show that ECoRAG improves LLM\nperformance on ODQA tasks, outperforming existing compression methods.\nFurthermore, ECoRAG is highly cost-efficient, as it not only reduces latency\nbut also minimizes token usage by retaining only the necessary information to\ngenerate the correct answer. Code is available at\nhttps://github.com/ldilab/ECoRAG.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04470", "pdf": "https://arxiv.org/pdf/2506.04470", "abs": "https://arxiv.org/abs/2506.04470", "authors": ["Isha Rao", "Sanjay Ghosh"], "title": "A Poisson-Guided Decomposition Network for Extreme Low-Light Image Enhancement", "categories": ["eess.IV", "cs.CV"], "comment": "8 pages, 3 figures and 1 table", "summary": "Low-light image denoising and enhancement are challenging, especially when\ntraditional noise assumptions, such as Gaussian noise, do not hold in majority.\nIn many real-world scenarios, such as low-light imaging, noise is\nsignal-dependent and is better represented as Poisson noise. In this work, we\naddress the problem of denoising images degraded by Poisson noise under extreme\nlow-light conditions. We introduce a light-weight deep learning-based method\nthat integrates Retinex based decomposition with Poisson denoising into a\nunified encoder-decoder network. The model simultaneously enhances illumination\nand suppresses noise by incorporating a Poisson denoising loss to address\nsignal-dependent noise. Without prior requirement for reflectance and\nillumination, the network learns an effective decomposition process while\nensuring consistent reflectance and smooth illumination without causing any\nform of color distortion. The experimental results demonstrate the\neffectiveness and practicality of the proposed low-light illumination\nenhancement method. Our method significantly improves visibility and brightness\nin low-light conditions, while preserving image structure and color constancy\nunder ambient illumination.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04290", "pdf": "https://arxiv.org/pdf/2506.04290", "abs": "https://arxiv.org/abs/2506.04290", "authors": ["Muhammed Golec", "Maha AlabdulJalil"], "title": "Interpretable LLMs for Credit Risk: A Systematic Review and Taxonomy", "categories": ["q-fin.RM", "cs.LG"], "comment": "20 pages, 6 figures, preprint under review at Information Processing\n  & Management", "summary": "Large Language Models (LLM), which have developed in recent years, enable\ncredit risk assessment through the analysis of financial texts such as analyst\nreports and corporate disclosures. This paper presents the first systematic\nreview and taxonomy focusing on LLMbased approaches in credit risk estimation.\nWe determined the basic model architectures by selecting 60 relevant papers\npublished between 2020-2025 with the PRISMA research strategy. And we examined\nthe data used for scenarios such as credit default prediction and risk\nanalysis. Since the main focus of the paper is interpretability, we classify\nconcepts such as explainability mechanisms, chain of thought prompts and\nnatural language justifications for LLM-based credit models. The taxonomy\norganizes the literature under four main headings: model architectures, data\ntypes, explainability mechanisms and application areas. Based on this analysis,\nwe highlight the main future trends and research gaps for LLM-based credit\nscoring systems. This paper aims to be a reference paper for artificial\nintelligence and financial researchers.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04521", "pdf": "https://arxiv.org/pdf/2506.04521", "abs": "https://arxiv.org/abs/2506.04521", "authors": ["Di Wu", "Seth Aycock", "Christof Monz"], "title": "Please Translate Again: Two Simple Experiments on Whether Human-Like Reasoning Helps Translation", "categories": ["cs.CL"], "comment": "16 pages, 16 figures", "summary": "Large Language Models (LLMs) demonstrate strong reasoning capabilities for\nmany tasks, often by explicitly decomposing the task via Chain-of-Thought (CoT)\nreasoning. Recent work on LLM-based translation designs hand-crafted prompts to\ndecompose translation, or trains models to incorporate intermediate\nsteps.~\\textit{Translating Step-by-step}~\\citep{briakou2024translating}, for\ninstance, introduces a multi-step prompt with decomposition and refinement of\ntranslation with LLMs, which achieved state-of-the-art results on WMT24. In\nthis work, we scrutinise this strategy's effectiveness. Empirically, we find no\nclear evidence that performance gains stem from explicitly decomposing the\ntranslation process, at least for the models on test; and we show that simply\nprompting LLMs to ``translate again'' yields even better results than\nhuman-like step-by-step prompting. Our analysis does not rule out the role of\nreasoning, but instead invites future work exploring the factors for CoT's\neffectiveness in the context of translation.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04562", "pdf": "https://arxiv.org/pdf/2506.04562", "abs": "https://arxiv.org/abs/2506.04562", "authors": ["Xingpeng Sun", "Shiyang Jia", "Zherong Pan", "Kui Wu", "Aniket Bera"], "title": "Handle-based Mesh Deformation Guided By Vision Language Model", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Mesh deformation is a fundamental tool in 3D content manipulation. Despite\nextensive prior research, existing approaches often suffer from low output\nquality, require significant manual tuning, or depend on data-intensive\ntraining. To address these limitations, we introduce a training-free,\nhandle-based mesh deformation method. % Our core idea is to leverage a\nVision-Language Model (VLM) to interpret and manipulate a handle-based\ninterface through prompt engineering. We begin by applying cone singularity\ndetection to identify a sparse set of potential handles. The VLM is then\nprompted to select both the deformable sub-parts of the mesh and the handles\nthat best align with user instructions. Subsequently, we query the desired\ndeformed positions of the selected handles in screen space. To reduce\nuncertainty inherent in VLM predictions, we aggregate the results from multiple\ncamera views using a novel multi-view voting scheme. % Across a suite of\nbenchmarks, our method produces deformations that align more closely with user\nintent, as measured by CLIP and GPTEval3D scores, while introducing low\ndistortion -- quantified via membrane energy. In summary, our approach is\ntraining-free, highly automated, and consistently delivers high-quality mesh\ndeformations.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05188", "pdf": "https://arxiv.org/pdf/2506.05188", "abs": "https://arxiv.org/abs/2506.05188", "authors": ["Moritz Miller", "Bernhard Schölkopf", "Siyuan Guo"], "title": "Counterfactual reasoning: an analysis of in-context emergence", "categories": ["cs.CL", "cs.AI", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Large-scale neural language models (LMs) exhibit remarkable performance in\nin-context learning: the ability to learn and reason the input context on the\nfly without parameter update. This work studies in-context counterfactual\nreasoning in language models, that is, to predict the consequences of changes\nunder hypothetical scenarios. We focus on studying a well-defined synthetic\nsetup: a linear regression task that requires noise abduction, where accurate\nprediction is based on inferring and copying the contextual noise from factual\nobservations. We show that language models are capable of counterfactual\nreasoning in this controlled setup and provide insights that counterfactual\nreasoning for a broad class of functions can be reduced to a transformation on\nin-context observations; we find self-attention, model depth, and data\ndiversity in pre-training drive performance in Transformers. More\ninterestingly, our findings extend beyond regression tasks and show that\nTransformers can perform noise abduction on sequential data, providing\npreliminary evidence on the potential for counterfactual story generation. Our\ncode is available under\nhttps://github.com/moXmiller/counterfactual-reasoning.git .", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04524", "pdf": "https://arxiv.org/pdf/2506.04524", "abs": "https://arxiv.org/abs/2506.04524", "authors": ["Jakub Łącki", "Slobodan Mitrović", "Srikkanth Ramachandran", "Wen-Horng Sheu"], "title": "Faster MPC Algorithms for Approximate Allocation in Uniformly Sparse Graphs", "categories": ["cs.DS"], "comment": null, "summary": "We study the allocation problem in the Massively Parallel Computation (MPC)\nmodel. This problem is a special case of $b$-matching, in which the input is a\nbipartite graph with capacities greater than $1$ in only one part of the\nbipartition. We give a $(1+\\epsilon)$ approximate algorithm for the problem,\nwhich runs in $\\tilde{O}(\\sqrt{\\log \\lambda})$ MPC rounds, using sublinear\nspace per machine and $\\tilde{O}(\\lambda n)$ total space, where $\\lambda$ is\nthe arboricity of the input graph. Our result is obtained by providing a new\nanalysis of a LOCAL algorithm by Agrawal, Zadimoghaddam, and Mirrokni [ICML\n2018], which improves its round complexity from $O(\\log n)$ to $O(\\log\n\\lambda)$. Prior to our work, no $o(\\log n)$ round algorithm for\nconstant-approximate allocation was known in either LOCAL or sublinear space\nMPC models for graphs with low arboricity.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04623", "pdf": "https://arxiv.org/pdf/2506.04623", "abs": "https://arxiv.org/abs/2506.04623", "authors": ["Wuyang Li", "Zhu Yu", "Alexandre Alahi"], "title": "VoxDet: Rethinking 3D Semantic Occupancy Prediction as Dense Object Detection", "categories": ["cs.GR", "cs.CV"], "comment": "Project Page: https://vita-epfl.github.io/VoxDet/", "summary": "3D semantic occupancy prediction aims to reconstruct the 3D geometry and\nsemantics of the surrounding environment. With dense voxel labels, prior works\ntypically formulate it as a dense segmentation task, independently classifying\neach voxel. However, this paradigm neglects critical instance-centric\ndiscriminability, leading to instance-level incompleteness and adjacent\nambiguities. To address this, we highlight a free lunch of occupancy labels:\nthe voxel-level class label implicitly provides insight at the instance level,\nwhich is overlooked by the community. Motivated by this observation, we first\nintroduce a training-free Voxel-to-Instance (VoxNT) trick: a simple yet\neffective method that freely converts voxel-level class labels into\ninstance-level offset labels. Building on this, we further propose VoxDet, an\ninstance-centric framework that reformulates the voxel-level occupancy\nprediction as dense object detection by decoupling it into two sub-tasks:\noffset regression and semantic prediction. Specifically, based on the lifted 3D\nvolume, VoxDet first uses (a) Spatially-decoupled Voxel Encoder to generate\ndisentangled feature volumes for the two sub-tasks, which learn task-specific\nspatial deformation in the densely projected tri-perceptive space. Then, we\ndeploy (b) Task-decoupled Dense Predictor to address this task via dense\ndetection. Here, we first regress a 4D offset field to estimate distances (6\ndirections) between voxels and object borders in the voxel space. The regressed\noffsets are then used to guide the instance-level aggregation in the\nclassification branch, achieving instance-aware prediction. Experiments show\nthat VoxDet can be deployed on both camera and LiDAR input, jointly achieving\nstate-of-the-art results on both benchmarks. VoxDet is not only highly\nefficient, but also achieves 63.0 IoU on the SemanticKITTI test set, ranking\n1st on the online leaderboard.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04354", "pdf": "https://arxiv.org/pdf/2506.04354", "abs": "https://arxiv.org/abs/2506.04354", "authors": ["Elmira Mirzabeigi", "Rezvan Salehi", "Kourosh Parand"], "title": "BridgeNet: A Hybrid, Physics-Informed Machine Learning Framework for Solving High-Dimensional Fokker-Planck Equations", "categories": ["physics.comp-ph", "cs.LG", "math-ph", "math.AP", "math.MP"], "comment": null, "summary": "BridgeNet is a novel hybrid framework that integrates convolutional neural\nnetworks with physics-informed neural networks to efficiently solve non-linear,\nhigh-dimensional Fokker-Planck equations (FPEs). Traditional PINNs, which\ntypically rely on fully connected architectures, often struggle to capture\ncomplex spatial hierarchies and enforce intricate boundary conditions. In\ncontrast, BridgeNet leverages adaptive CNN layers for effective local feature\nextraction and incorporates a dynamically weighted loss function that\nrigorously enforces physical constraints. Extensive numerical experiments\nacross various test cases demonstrate that BridgeNet not only achieves\nsignificantly lower error metrics and faster convergence compared to\nconventional PINN approaches but also maintains robust stability in\nhigh-dimensional settings. This work represents a substantial advancement in\ncomputational physics, offering a scalable and accurate solution methodology\nwith promising applications in fields ranging from financial mathematics to\ncomplex system dynamics.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04527", "pdf": "https://arxiv.org/pdf/2506.04527", "abs": "https://arxiv.org/abs/2506.04527", "authors": ["Hien Ohnaka", "Yuma Shirahata", "Byeongseon Park", "Ryuichi Yamamoto"], "title": "Grapheme-Coherent Phonemic and Prosodic Annotation of Speech by Implicit and Explicit Grapheme Conditioning", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "5 pages, 2 figures, and 4 tables, accepted to INTERSPEECH 2025", "summary": "We propose a model to obtain phonemic and prosodic labels of speech that are\ncoherent with graphemes. Unlike previous methods that simply fine-tune a\npre-trained ASR model with the labels, the proposed model conditions the label\ngeneration on corresponding graphemes by two methods: 1) Add implicit grapheme\nconditioning through prompt encoder using pre-trained BERT features. 2)\nExplicitly prune the label hypotheses inconsistent with the grapheme during\ninference. These methods enable obtaining parallel data of speech, the labels,\nand graphemes, which is applicable to various downstream tasks such as\ntext-to-speech and accent estimation from text. Experiments showed that the\nproposed method significantly improved the consistency between graphemes and\nthe predicted labels. Further, experiments on accent estimation task confirmed\nthat the created parallel data by the proposed method effectively improve the\nestimation accuracy.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04635", "pdf": "https://arxiv.org/pdf/2506.04635", "abs": "https://arxiv.org/abs/2506.04635", "authors": ["Thai-Binh Nguyen", "Thi Van Nguyen", "Quoc Truong Do", "Chi Mai Luong"], "title": "ViCocktail: Automated Multi-Modal Data Collection for Vietnamese Audio-Visual Speech Recognition", "categories": ["cs.CL", "cs.CV"], "comment": "Accepted at Interspeech 2025", "summary": "Audio-Visual Speech Recognition (AVSR) has gained significant attention\nrecently due to its robustness against noise, which often challenges\nconventional speech recognition systems that rely solely on audio features.\nDespite this advantage, AVSR models remain limited by the scarcity of extensive\ndatasets, especially for most languages beyond English. Automated data\ncollection offers a promising solution. This work presents a practical approach\nto generate AVSR datasets from raw video, refining existing techniques for\nimproved efficiency and accessibility. We demonstrate its broad applicability\nby developing a baseline AVSR model for Vietnamese. Experiments show the\nautomatically collected dataset enables a strong baseline, achieving\ncompetitive performance with robust ASR in clean conditions and significantly\noutperforming them in noisy environments like cocktail parties. This efficient\nmethod provides a pathway to expand AVSR to more languages, particularly\nunder-resourced ones.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04357", "pdf": "https://arxiv.org/pdf/2506.04357", "abs": "https://arxiv.org/abs/2506.04357", "authors": ["Amirreza Ahmadnejad", "Somayyeh Koohi"], "title": "Optical Physics-Based Generative Models", "categories": ["physics.optics", "cs.LG"], "comment": null, "summary": "This paper establishes a comprehensive mathematical framework connecting\noptical physics equations to generative models, demonstrating how light\npropagation dynamics inspire powerful artificial intelligence approaches. We\nanalyze six fundamental optical equations, comparing linear models (Helmholtz,\ndissipative wave, and Eikonal equations) with their nonlinear extensions\nincorporating Kerr effects, cubic-quintic nonlinearities, and\nintensity-dependent refractive indices. Our nonlinear optical models reveal\nremarkable capabilities through natural self-organization principles. The\nnonlinear Helmholtz model achieves 40-60% parameter reduction while maintaining\nsuperior mode separation via self-focusing phenomena. The cubic-quintic\ndissipative wave model prevents mode collapse through balanced\nattractive-repulsive interactions, enabling stable soliton formation with\n20-40% improved coverage. The intensity-dependent Eikonal model creates\nadaptive pathways that dynamically respond to content, providing enhanced\ncontrollability in conditional generation. Experimental validation demonstrates\nconsistent superiority over linear predecessors and traditional generative\napproaches. The nonlinear Helmholtz model achieves FID scores of 0.0089 versus\n1.0909 for linear versions, while the cubic-quintic model reaches 0.0156 FID\nwith exceptional stability. Memory usage drops 40-60% and training time\nimproves 30-50% due to inherent nonlinear stability properties. The framework\nenables bidirectional benefits, advancing both generative AI and optical\nphysics through novel approaches to soliton analysis, wavefront control, and\nrefractive index reconstruction with 95% accuracy. This work reveals deep\nconnections between physical self-organization and artificial intelligence,\nopening pathways toward efficient optical computing implementations.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05278", "pdf": "https://arxiv.org/pdf/2506.05278", "abs": "https://arxiv.org/abs/2506.05278", "authors": ["Nan Huo", "Jinyang Li", "Bowen Qin", "Ge Qu", "Xiaolong Li", "Xiaodong Li", "Chenhao Ma", "Reynold Cheng"], "title": "Micro-Act: Mitigate Knowledge Conflict in Question Answering via Actionable Self-Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ACL 2025 Main", "summary": "Retrieval-Augmented Generation (RAG) systems commonly suffer from Knowledge\nConflicts, where retrieved external knowledge contradicts the inherent,\nparametric knowledge of large language models (LLMs). It adversely affects\nperformance on downstream tasks such as question answering (QA). Existing\napproaches often attempt to mitigate conflicts by directly comparing two\nknowledge sources in a side-by-side manner, but this can overwhelm LLMs with\nextraneous or lengthy contexts, ultimately hindering their ability to identify\nand mitigate inconsistencies. To address this issue, we propose Micro-Act a\nframework with a hierarchical action space that automatically perceives context\ncomplexity and adaptively decomposes each knowledge source into a sequence of\nfine-grained comparisons. These comparisons are represented as actionable\nsteps, enabling reasoning beyond the superficial context. Through extensive\nexperiments on five benchmark datasets, Micro-Act consistently achieves\nsignificant increase in QA accuracy over state-of-the-art baselines across all\n5 datasets and 3 conflict types, especially in temporal and semantic types\nwhere all baselines fail significantly. More importantly, Micro-Act exhibits\nrobust performance on non-conflict questions simultaneously, highlighting its\npractical value in real-world RAG applications.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04664", "pdf": "https://arxiv.org/pdf/2506.04664", "abs": "https://arxiv.org/abs/2506.04664", "authors": ["Bimal Kumar Ray"], "title": "A Fast Unsupervised Scheme for Polygonal Approximation", "categories": ["cs.GR", "cs.CG", "cs.CV"], "comment": null, "summary": "This paper proposes a fast and unsupervised scheme for a polygonal\napproximation of a closed digital curve. It is demonstrated that the\napproximation scheme is faster than state-of-the-art approximation and is\ncompetitive with the same in Rosin's measure and in its aesthetic aspect. The\nscheme comprises of three phases: initial segmentation, iterative vertex\ninsertion, and iterative merging, followed by vertex adjustment. The initial\nsegmentation is used to detect sharp turnings - the vertices that seemingly\nhave high curvature. It is likely that some of important vertices with low\ncurvature might have been missed out at the first phase and so iterative vertex\ninsertion is used to add vertices in a region where the curvature changes\nslowly but steadily. The initial phase may pick up some undesirable vertices\nand so merging is used to eliminate the redundant vertices. Finally, vertex\nadjustment is used to facilitate enhancement in the aesthetic look of the\napproximation. The quality of the approximations is measured using Rosin's\nmeasure. The robustness of the proposed scheme with respect to geometric\ntransformation is observed.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04529", "pdf": "https://arxiv.org/pdf/2506.04529", "abs": "https://arxiv.org/abs/2506.04529", "authors": ["Jiatu Li", "Mengdi Wu"], "title": "Identity Testing for Circuits with Exponentiation Gates", "categories": ["cs.CC", "cs.DS", "F.2.2"], "comment": null, "summary": "Motivated by practical applications in the design of optimization compilers\nfor neural networks, we initiated the study of identity testing problems for\narithmetic circuits augmented with \\emph{exponentiation gates} that compute the\nreal function $x\\mapsto e^x$. These circuits compute real functions of form\n$P(\\vec x)/P'(\\vec x)$, where both $P(\\vec x)$ and $P'(\\vec x)$ are exponential\npolynomials\n  \\[\n  \\sum_{i=1}^k f_i(\\vec x)\\cdot \\exp\\left(\\frac{g_i(\\vec x)}{h_i(\\vec\nx)}\\right),\n  \\]\n  for polynomials $f_i(\\vec x),g_i(\\vec x)$, and $h_i(\\vec x)$.\n  We formalize a black-box query model over finite fields for this class of\ncircuits, which is mathematical simple and reflects constraints faced by\nreal-world neural network compilers. We proved that a simple and efficient\nrandomized identity testing algorithm achieves perfect completeness and\nnon-trivial soundness. Concurrent with our work, the algorithm has been\nimplemented in the optimization compiler Mirage by Wu et al.~(OSDI 2025),\ndemonstrating promising empirical performance in both efficiency and soundness\nerror. Finally, we propose a number-theoretic conjecture under which our\nalgorithm is sound with high probability.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04781", "pdf": "https://arxiv.org/pdf/2506.04781", "abs": "https://arxiv.org/abs/2506.04781", "authors": ["Christoph Schirninger", "Robert Jarolim", "Astrid M. Veronig", "Christoph Kuckein"], "title": "Deep learning image burst stacking to reconstruct high-resolution ground-based solar observations", "categories": ["astro-ph.SR", "astro-ph.IM", "cs.CV", "physics.comp-ph"], "comment": null, "summary": "Large aperture ground based solar telescopes allow the solar atmosphere to be\nresolved in unprecedented detail. However, observations are limited by Earths\nturbulent atmosphere, requiring post image corrections. Current reconstruction\nmethods using short exposure bursts face challenges with strong turbulence and\nhigh computational costs. We introduce a deep learning approach that\nreconstructs 100 short exposure images into one high quality image in real\ntime. Using unpaired image to image translation, our model is trained on\ndegraded bursts with speckle reconstructions as references, improving\nrobustness and generalization. Our method shows an improved robustness in terms\nof perceptual quality, especially when speckle reconstructions show artifacts.\nAn evaluation with a varying number of images per burst demonstrates that our\nmethod makes efficient use of the combined image information and achieves the\nbest reconstructions when provided with the full image burst.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04535", "pdf": "https://arxiv.org/pdf/2506.04535", "abs": "https://arxiv.org/abs/2506.04535", "authors": ["K. O. T. Erziev"], "title": "BSBench: will your LLM find the largest prime number?", "categories": ["cs.CL"], "comment": "7 + 2 pages", "summary": "We propose that benchmarking LLMs on questions which have no reasonable\nanswer actually isn't as silly as it sounds. We also present a benchmark that\nallows such testing and a method to modify the existing datasets, and discover\nthat existing models demonstrate a performance far from the perfect on such\nquestions. Our code and data artifacts are available at\nhttps://github.com/L3G5/impossible-bench", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05305", "pdf": "https://arxiv.org/pdf/2506.05305", "abs": "https://arxiv.org/abs/2506.05305", "authors": ["Deepak Pandita", "Tharindu Cyril Weerasooriya", "Ankit Parag Shah", "Christopher M. Homan", "Wei Wei"], "title": "ProRefine: Inference-time Prompt Refinement with Textual Feedback", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Agentic workflows, where multiple AI agents collaborate to accomplish complex\ntasks like reasoning or planning, are becoming increasingly prevalent. However,\nthese workflows often suffer from error propagation and sub-optimal\nperformance, largely due to poorly designed prompts that fail to effectively\nguide individual agents. This is a critical problem because it limits the\nreliability and scalability of these powerful systems. We introduce ProRefine,\nan innovative inference-time prompt optimization method that leverages textual\nfeedback from large language models (LLMs) to address this challenge. ProRefine\ndynamically refines prompts for multi-step reasoning tasks without additional\ntraining or ground truth labels. Evaluated on five benchmark mathematical\nreasoning datasets, ProRefine significantly surpasses zero-shot\nChain-of-Thought baselines by 3 to 37 percentage points. This approach not only\nboosts accuracy but also allows smaller models to match the performance of\nlarger ones, highlighting its potential for efficient and scalable AI\ndeployment, and democratizing access to high-performing AI.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05010", "pdf": "https://arxiv.org/pdf/2506.05010", "abs": "https://arxiv.org/abs/2506.05010", "authors": ["Zhenran Xu", "Xue Yang", "Yiyu Wang", "Qingli Hu", "Zijiao Wu", "Longyue Wang", "Weihua Luo", "Kaifu Zhang", "Baotian Hu", "Min Zhang"], "title": "ComfyUI-Copilot: An Intelligent Assistant for Automated Workflow Development", "categories": ["cs.CL", "cs.CV"], "comment": "ACL 2025 Demo. Github: https://github.com/AIDC-AI/ComfyUI-Copilot", "summary": "We introduce ComfyUI-Copilot, a large language model-powered plugin designed\nto enhance the usability and efficiency of ComfyUI, an open-source platform for\nAI-driven art creation. Despite its flexibility and user-friendly interface,\nComfyUI can present challenges to newcomers, including limited documentation,\nmodel misconfigurations, and the complexity of workflow design. ComfyUI-Copilot\naddresses these challenges by offering intelligent node and model\nrecommendations, along with automated one-click workflow construction. At its\ncore, the system employs a hierarchical multi-agent framework comprising a\ncentral assistant agent for task delegation and specialized worker agents for\ndifferent usages, supported by our curated ComfyUI knowledge bases to\nstreamline debugging and deployment. We validate the effectiveness of\nComfyUI-Copilot through both offline quantitative evaluations and online user\nfeedback, showing that it accurately recommends nodes and accelerates workflow\ndevelopment. Additionally, use cases illustrate that ComfyUI-Copilot lowers\nentry barriers for beginners and enhances workflow efficiency for experienced\nusers. The ComfyUI-Copilot installation package and a demo video are available\nat https://github.com/AIDC-AI/ComfyUI-Copilot.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05314", "pdf": "https://arxiv.org/pdf/2506.05314", "abs": "https://arxiv.org/abs/2506.05314", "authors": ["Taha Entesari", "Arman Hatami", "Rinat Khaziev", "Anil Ramakrishna", "Mahyar Fazlyab"], "title": "Constrained Entropic Unlearning: A Primal-Dual Framework for Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) deployed in real-world settings increasingly\nface the need to unlearn sensitive, outdated, or proprietary information.\nExisting unlearning methods typically formulate forgetting and retention as a\nregularized trade-off, combining both objectives into a single scalarized loss.\nThis often leads to unstable optimization and degraded performance on retained\ndata, especially under aggressive forgetting. We propose a new formulation of\nLLM unlearning as a constrained optimization problem: forgetting is enforced\nvia a novel logit-margin flattening loss that explicitly drives the output\ndistribution toward uniformity on a designated forget set, while retention is\npreserved through a hard constraint on a separate retain set. Compared to\nentropy-based objectives, our loss is softmax-free, numerically stable, and\nmaintains non-vanishing gradients, enabling more efficient and robust\noptimization. We solve the constrained problem using a scalable primal-dual\nalgorithm that exposes the trade-off between forgetting and retention through\nthe dynamics of the dual variable. Evaluations on the TOFU and MUSE benchmarks\nacross diverse LLM architectures demonstrate that our approach consistently\nmatches or exceeds state-of-the-art baselines, effectively removing targeted\ninformation while preserving downstream utility.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05041", "pdf": "https://arxiv.org/pdf/2506.05041", "abs": "https://arxiv.org/abs/2506.05041", "authors": ["Usman Muhammad", "Jorma Laaksonen"], "title": "DACN: Dual-Attention Convolutional Network for Hyperspectral Image Super-Resolution", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "2D convolutional neural networks (CNNs) have attracted significant attention\nfor hyperspectral image super-resolution tasks. However, a key limitation is\ntheir reliance on local neighborhoods, which leads to a lack of global\ncontextual understanding. Moreover, band correlation and data scarcity continue\nto limit their performance. To mitigate these issues, we introduce DACN, a\ndual-attention convolutional network for hyperspectral image super-resolution.\nSpecifically, the model first employs augmented convolutions, integrating\nmulti-head attention to effectively capture both local and global feature\ndependencies. Next, we infer separate attention maps for the channel and\nspatial dimensions to determine where to focus across different channels and\nspatial positions. Furthermore, a custom optimized loss function is proposed\nthat combines L2 regularization with spatial-spectral gradient loss to ensure\naccurate spectral fidelity. Experimental results on two hyperspectral datasets\ndemonstrate that the combination of multi-head attention and channel attention\noutperforms either attention mechanism used individually.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05080", "pdf": "https://arxiv.org/pdf/2506.05080", "abs": "https://arxiv.org/abs/2506.05080", "authors": ["HaoTian Lan"], "title": "Parking, Perception, and Retail: Street-Level Determinants of Community Vitality in Harbin", "categories": ["cs.CL", "cs.CV"], "comment": "22 pages,5 figures", "summary": "The commercial vitality of community-scale streets in Chinese cities is\nshaped by complex interactions between vehicular accessibility, environmental\nquality, and pedestrian perception. This study proposes an interpretable,\nimage-based framework to examine how street-level features -- including parked\nvehicle density, greenery, cleanliness, and street width -- impact retail\nperformance and user satisfaction in Harbin, China. Leveraging street view\nimagery and a multimodal large language model (VisualGLM-6B), we construct a\nCommunity Commercial Vitality Index (CCVI) from Meituan and Dianping data and\nanalyze its relationship with spatial attributes extracted via GPT-4-based\nperception modeling. Our findings reveal that while moderate vehicle presence\nmay enhance commercial access, excessive on-street parking -- especially in\nnarrow streets -- erodes walkability and reduces both satisfaction and\nshop-level pricing. In contrast, streets with higher perceived greenery and\ncleanliness show significantly greater satisfaction scores but only weak\nassociations with pricing. Street width moderates the effects of vehicle\npresence, underscoring the importance of spatial configuration. These results\ndemonstrate the value of integrating AI-assisted perception with urban\nmorphological analysis to capture non-linear and context-sensitive drivers of\ncommercial success. This study advances both theoretical and methodological\nfrontiers by highlighting the conditional role of vehicle activity in\nneighborhood commerce and demonstrating the feasibility of multimodal AI for\nperceptual urban diagnostics. The implications extend to urban design, parking\nmanagement, and scalable planning tools for community revitalization.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04480", "pdf": "https://arxiv.org/pdf/2506.04480", "abs": "https://arxiv.org/abs/2506.04480", "authors": ["Nina Vesseron", "Elsa Cazelles", "Alice Le Brigant", "Thierry Klein"], "title": "On the Wasserstein Geodesic Principal Component Analysis of probability measures", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "This paper focuses on Geodesic Principal Component Analysis (GPCA) on a\ncollection of probability distributions using the Otto-Wasserstein geometry.\nThe goal is to identify geodesic curves in the space of probability measures\nthat best capture the modes of variation of the underlying dataset. We first\naddress the case of a collection of Gaussian distributions, and show how to\nlift the computations in the space of invertible linear maps. For the more\ngeneral setting of absolutely continuous probability measures, we leverage a\nnovel approach to parameterizing geodesics in Wasserstein space with neural\nnetworks. Finally, we compare to classical tangent PCA through various examples\nand provide illustrations on real-world datasets.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04545", "pdf": "https://arxiv.org/pdf/2506.04545", "abs": "https://arxiv.org/abs/2506.04545", "authors": ["Chen Chen"], "title": "Seamless and Efficient Interactions within a Mixed-Dimensional Information Space", "categories": ["cs.HC", "H.5.0"], "comment": "PhD Dissertation from University of California San Diego; 134 pages", "summary": "Mediated by today's visual displays, information space allows users to\ndiscover, access and interact with a wide range of digital and physical\ninformation. The information presented in this space may be digital, physical\nor a blend of both, and appear across different dimensions - such as texts,\nimages, 3D content and physical objects embedded within real-world environment.\nNavigating within the information space often involves interacting with\nmixed-dimensional entities, visually represented in both 2D and 3D. At times,\ninteractions also involve transitioning among entities represented in different\ndimensions. We introduce the concept of mixed-dimensional information space,\nencompassing entities represented in both 2D and 3D. Interactions within the\nmixed-dimensional information space should be seamless and efficient: users\nshould be able to focus on their primary tasks without being distracted by\ninteractions with or transitions between entities. While incorporating 3D\nrepresentations into the mixed-dimensional information space offers intuitive\nand immersive ways to interact with complex information, it is important to\naddress potential seams and inefficiencies that arise while interacting with\nboth 2D and 3D entities. This dissertation introduces new interactive\ntechniques and systems to realize seamless and efficient interactions within\nthe mixed-dimensional information space. This dissertation introduces three\ninteractive systems: MemoVis which aims to use emergent generative AI to help\nusers create reference images for 3D design feedback; PaperToPlace which\ndemonstrates how paper-based instruction documents can be transformed and\nspatialized into a context-aware MR experience; and VRContour which explores\nhow contour delineation workflow can be brought into VR.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05127", "pdf": "https://arxiv.org/pdf/2506.05127", "abs": "https://arxiv.org/abs/2506.05127", "authors": ["Srikar Yellapragada", "Alexandros Graikos", "Zilinghan Li", "Kostas Triaridis", "Varun Belagali", "Saarthak Kapse", "Tarak Nath Nandi", "Ravi K Madduri", "Prateek Prasanna", "Tahsin Kurc", "Rajarsi R. Gupta", "Joel Saltz", "Dimitris Samaras"], "title": "PixCell: A generative foundation model for digital histopathology images", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "comment": null, "summary": "The digitization of histology slides has revolutionized pathology, providing\nmassive datasets for cancer diagnosis and research. Contrastive self-supervised\nand vision-language models have been shown to effectively mine large pathology\ndatasets to learn discriminative representations. On the other hand, generative\nmodels, capable of synthesizing realistic and diverse images, present a\ncompelling solution to address unique problems in pathology that involve\nsynthesizing images; overcoming annotated data scarcity, enabling\nprivacy-preserving data sharing, and performing inherently generative tasks,\nsuch as virtual staining. We introduce PixCell, the first diffusion-based\ngenerative foundation model for histopathology. We train PixCell on PanCan-30M,\na vast, diverse dataset derived from 69,184 H\\&E-stained whole slide images\ncovering various cancer types. We employ a progressive training strategy and a\nself-supervision-based conditioning that allows us to scale up training without\nany annotated data. PixCell generates diverse and high-quality images across\nmultiple cancer types, which we find can be used in place of real data to train\na self-supervised discriminative model. Synthetic images shared between\ninstitutions are subject to fewer regulatory barriers than would be the case\nwith real clinical images. Furthermore, we showcase the ability to precisely\ncontrol image generation using a small set of annotated images, which can be\nused for both data augmentation and educational purposes. Testing on a cell\nsegmentation task, a mask-guided PixCell enables targeted data augmentation,\nimproving downstream performance. Finally, we demonstrate PixCell's ability to\nuse H\\&E structural staining to infer results from molecular marker studies; we\nuse this capability to infer IHC staining from H\\&E images. Our trained models\nare publicly released to accelerate research in computational pathology.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05297", "pdf": "https://arxiv.org/pdf/2506.05297", "abs": "https://arxiv.org/abs/2506.05297", "authors": ["Hangyu Ji"], "title": "DM-SegNet: Dual-Mamba Architecture for 3D Medical Image Segmentation with Global Context Modeling", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Accurate 3D medical image segmentation demands architectures capable of\nreconciling global context modeling with spatial topology preservation. While\nState Space Models (SSMs) like Mamba show potential for sequence modeling,\nexisting medical SSMs suffer from encoder-decoder incompatibility: the\nencoder's 1D sequence flattening compromises spatial structures, while\nconventional decoders fail to leverage Mamba's state propagation. We present\nDM-SegNet, a Dual-Mamba architecture integrating directional state transitions\nwith anatomy-aware hierarchical decoding. The core innovations include a\nquadri-directional spatial Mamba module employing four-directional 3D scanning\nto maintain anatomical spatial coherence, a gated spatial convolution layer\nthat enhances spatially sensitive feature representation prior to state\nmodeling, and a Mamba-driven decoding framework enabling bidirectional state\nsynchronization across scales. Extensive evaluation on two clinically\nsignificant benchmarks demonstrates the efficacy of DM-SegNet: achieving\nstate-of-the-art Dice Similarity Coefficient (DSC) of 85.44% on the Synapse\ndataset for abdominal organ segmentation and 90.22% on the BraTS2023 dataset\nfor brain tumor segmentation.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04551", "pdf": "https://arxiv.org/pdf/2506.04551", "abs": "https://arxiv.org/abs/2506.04551", "authors": ["Chenglong Ma", "Ziqi Xu", "Yongli Ren", "Danula Hettiachchi", "Jeffrey Chan"], "title": "PUB: An LLM-Enhanced Personality-Driven User Behaviour Simulator for Recommender System Evaluation", "categories": ["cs.IR", "H.3.3"], "comment": null, "summary": "Traditional offline evaluation methods for recommender systems struggle to\ncapture the complexity of modern platforms due to sparse behavioural signals,\nnoisy data, and limited modelling of user personality traits. While simulation\nframeworks can generate synthetic data to address these gaps, existing methods\nfail to replicate behavioural diversity, limiting their effectiveness. To\novercome these challenges, we propose the Personality-driven User Behaviour\nSimulator (PUB), an LLM-based simulation framework that integrates the Big Five\npersonality traits to model personalised user behaviour. PUB dynamically infers\nuser personality from behavioural logs (e.g., ratings, reviews) and item\nmetadata, then generates synthetic interactions that preserve statistical\nfidelity to real-world data. Experiments on the Amazon review datasets show\nthat logs generated by PUB closely align with real user behaviour and reveal\nmeaningful associations between personality traits and recommendation outcomes.\nThese results highlight the potential of the personality-driven simulator to\nadvance recommender system evaluation, offering scalable, controllable,\nhigh-fidelity alternatives to resource-intensive real-world experiments.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04554", "pdf": "https://arxiv.org/pdf/2506.04554", "abs": "https://arxiv.org/abs/2506.04554", "authors": ["Hao Huang", "Zelda B. Zabinsky"], "title": "Non-linear Multi-objective Optimization with Probabilistic Branch and Bound", "categories": ["math.OC", "cs.LG"], "comment": "26 pages, 5 Figures", "summary": "A multiple objective simulation optimization algorithm named Multiple\nObjective Probabilistic Branch and Bound with Single Observation (MOPBnB(so))\nis presented for approximating the Pareto optimal set and the associated\nefficient frontier for stochastic multi-objective optimization problems.\nMOPBnB(so) evaluates a noisy function exactly once at any solution and uses\nneighboring solutions to estimate the objective functions, in contrast to a\nvariant that uses multiple replications at a solution to estimate the objective\nfunctions. A finite-time performance analysis for deterministic multi-objective\nproblems provides a bound on the probability that MOPBnB(so) captures the\nPareto optimal set. Asymptotic convergence of MOPBnB(so) on stochastic problems\nis derived, in that the algorithm captures the Pareto optimal set and the\nestimations converge to the true objective function values. Numerical results\nreveal that the variant with multiple replications is extremely intensive in\nterms of computational resources compared to MOPBnB(so). In addition, numerical\nresults show that MOPBnB(so) outperforms a genetic algorithm NSGA-II on test\nproblems.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04602", "pdf": "https://arxiv.org/pdf/2506.04602", "abs": "https://arxiv.org/abs/2506.04602", "authors": ["Haifeng Sun", "Yu Xiong", "Runze Wu", "Kai Wang", "Lan Zhang", "Changjie Fan", "Shaojie Tang", "Xiang-Yang Li"], "title": "MVP-Shapley: Feature-based Modeling for Evaluating the Most Valuable Player in Basketball", "categories": ["cs.GT", "cs.LG"], "comment": null, "summary": "The burgeoning growth of the esports and multiplayer online gaming community\nhas highlighted the critical importance of evaluating the Most Valuable Player\n(MVP). The establishment of an explainable and practical MVP evaluation method\nis very challenging. In our study, we specifically focus on play-by-play data,\nwhich records related events during the game, such as assists and points. We\naim to address the challenges by introducing a new MVP evaluation framework,\ndenoted as \\oursys, which leverages Shapley values. This approach encompasses\nfeature processing, win-loss model training, Shapley value allocation, and MVP\nranking determination based on players' contributions. Additionally, we\noptimize our algorithm to align with expert voting results from the perspective\nof causality. Finally, we substantiated the efficacy of our method through\nvalidation using the NBA dataset and the Dunk City Dynasty dataset and\nimplemented online deployment in the industry.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04626", "pdf": "https://arxiv.org/pdf/2506.04626", "abs": "https://arxiv.org/abs/2506.04626", "authors": ["Haochen Zhang", "Zhong Zheng", "Lingzhou Xue"], "title": "Regret-Optimal Q-Learning with Low Cost for Single-Agent and Federated Reinforcement Learning", "categories": ["stat.ML", "cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2502.02859", "summary": "Motivated by real-world settings where data collection and policy deployment\n-- whether for a single agent or across multiple agents -- are costly, we study\nthe problem of on-policy single-agent reinforcement learning (RL) and federated\nRL (FRL) with a focus on minimizing burn-in costs (the sample sizes needed to\nreach near-optimal regret) and policy switching or communication costs. In\nparallel finite-horizon episodic Markov Decision Processes (MDPs) with $S$\nstates and $A$ actions, existing methods either require superlinear burn-in\ncosts in $S$ and $A$ or fail to achieve logarithmic switching or communication\ncosts. We propose two novel model-free RL algorithms -- Q-EarlySettled-LowCost\nand FedQ-EarlySettled-LowCost -- that are the first in the literature to\nsimultaneously achieve: (i) the best near-optimal regret among all known\nmodel-free RL or FRL algorithms, (ii) low burn-in cost that scales linearly\nwith $S$ and $A$, and (iii) logarithmic policy switching cost for single-agent\nRL or communication cost for FRL. Additionally, we establish gap-dependent\ntheoretical guarantees for both regret and switching/communication costs,\nimproving or matching the best-known gap-dependent bounds.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04658", "pdf": "https://arxiv.org/pdf/2506.04658", "abs": "https://arxiv.org/abs/2506.04658", "authors": ["Jędrzej Maskiewicz", "Paweł Sakowski"], "title": "Can Artificial Intelligence Trade the Stock Market?", "categories": ["q-fin.TR", "cs.LG", "q-fin.CP"], "comment": null, "summary": "The paper explores the use of Deep Reinforcement Learning (DRL) in stock\nmarket trading, focusing on two algorithms: Double Deep Q-Network (DDQN) and\nProximal Policy Optimization (PPO) and compares them with Buy and Hold\nbenchmark. It evaluates these algorithms across three currency pairs, the S&P\n500 index and Bitcoin, on the daily data in the period of 2019-2023. The\nresults demonstrate DRL's effectiveness in trading and its ability to manage\nrisk by strategically avoiding trades in unfavorable conditions, providing a\nsubstantial edge over classical approaches, based on supervised learning in\nterms of risk-adjusted returns.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04689", "pdf": "https://arxiv.org/pdf/2506.04689", "abs": "https://arxiv.org/abs/2506.04689", "authors": ["Thao Nguyen", "Yang Li", "Olga Golovneva", "Luke Zettlemoyer", "Sewoong Oh", "Ludwig Schmidt", "Xian Li"], "title": "Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Scaling laws predict that the performance of large language models improves\nwith increasing model size and data size. In practice, pre-training has been\nrelying on massive web crawls, using almost all data sources publicly available\non the internet so far. However, this pool of natural data does not grow at the\nsame rate as the compute supply. Furthermore, the availability of high-quality\ntexts is even more limited: data filtering pipelines often remove up to 99% of\nthe initial web scrapes to achieve state-of-the-art. To address the \"data wall\"\nof pre-training scaling, our work explores ways to transform and recycle data\ndiscarded in existing filtering processes. We propose REWIRE, REcycling the Web\nwith guIded REwrite, a method to enrich low-quality documents so that they\ncould become useful for training. This in turn allows us to increase the\nrepresentation of synthetic data in the final pre-training set. Experiments at\n1B, 3B and 7B scales of the DCLM benchmark show that mixing high-quality raw\ntexts and our rewritten texts lead to 1.0, 1.3 and 2.5 percentage points\nimprovement respectively across 22 diverse tasks, compared to training on only\nfiltered web data. Training on the raw-synthetic data mix is also more\neffective than having access to 2x web data. Through further analysis, we\ndemonstrate that about 82% of the mixed in texts come from transforming\nlower-quality documents that would otherwise be discarded. REWIRE also\noutperforms related approaches of generating synthetic data, including\nWikipedia-style paraphrasing, question-answer synthesizing and knowledge\nextraction. These results suggest that recycling web texts holds the potential\nfor being a simple and effective approach for scaling pre-training data.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04572", "pdf": "https://arxiv.org/pdf/2506.04572", "abs": "https://arxiv.org/abs/2506.04572", "authors": ["Can Zheng", "Yuhan Cao", "Xiaoning Dong", "Tianxing He"], "title": "Demonstrations of Integrity Attacks in Multi-Agent Systems", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding, code generation, and complex planning.\nSimultaneously, Multi-Agent Systems (MAS) have garnered attention for their\npotential to enable cooperation among distributed agents. However, from a\nmulti-party perspective, MAS could be vulnerable to malicious agents that\nexploit the system to serve self-interests without disrupting its core\nfunctionality. This work explores integrity attacks where malicious agents\nemploy subtle prompt manipulation to bias MAS operations and gain various\nbenefits. Four types of attacks are examined: \\textit{Scapegoater}, who\nmisleads the system monitor to underestimate other agents' contributions;\n\\textit{Boaster}, who misleads the system monitor to overestimate their own\nperformance; \\textit{Self-Dealer}, who manipulates other agents to adopt\ncertain tools; and \\textit{Free-Rider}, who hands off its own task to others.\nWe demonstrate that strategically crafted prompts can introduce systematic\nbiases in MAS behavior and executable instructions, enabling malicious agents\nto effectively mislead evaluation systems and manipulate collaborative agents.\nFurthermore, our attacks can bypass advanced LLM-based monitors, such as\nGPT-4o-mini and o3-mini, highlighting the limitations of current detection\nmechanisms. Our findings underscore the critical need for MAS architectures\nwith robust security protocols and content validation mechanisms, alongside\nmonitoring systems capable of comprehensive risk scenario assessment.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04575", "pdf": "https://arxiv.org/pdf/2506.04575", "abs": "https://arxiv.org/abs/2506.04575", "authors": ["Qingchuan Li", "Jiatong Li", "Zirui Liu", "Mingyue Cheng", "Yuting Zeng", "Qi Liu", "Tongxuan Liu"], "title": "Are LLMs Reliable Translators of Logical Reasoning Across Lexically Diversified Contexts?", "categories": ["cs.CL"], "comment": null, "summary": "Neuro-symbolic approaches combining large language models (LLMs) with solvers\nexcels in logical reasoning problems need long reasoning chains. In this\nparadigm, LLMs serve as translators, converting natural language reasoning\nproblems into formal logic formulas. Then reliable symbolic solvers return\ncorrect solutions. Despite their success, we find that LLMs, as translators,\nstruggle to handle lexical diversification, a common linguistic phenomenon,\nindicating that LLMs as logic translators are unreliable in real-world\nscenarios. Moreover, existing logical reasoning benchmarks lack lexical\ndiversity, failing to challenge LLMs' ability to translate such text and thus\nobscuring this issue. In this work, we propose SCALe, a benchmark designed to\naddress this significant gap through **logic-invariant lexical\ndiversification**. By using LLMs to transform original benchmark datasets into\nlexically diversified but logically equivalent versions, we evaluate LLMs'\nability to consistently map diverse expressions to uniform logical symbols on\nthese new datasets. Experiments using SCALe further confirm that current LLMs\nexhibit deficiencies in this capability. Building directly on the deficiencies\nidentified through our benchmark, we propose a new method, MenTaL, to address\nthis limitation. This method guides LLMs to first construct a table unifying\ndiverse expressions before performing translation. Applying MenTaL through\nin-context learning and supervised fine-tuning (SFT) significantly improves the\nperformance of LLM translators on lexically diversified text. Our code is now\navailable at https://github.com/wufeiwuwoshihua/LexicalDiver.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04813", "pdf": "https://arxiv.org/pdf/2506.04813", "abs": "https://arxiv.org/abs/2506.04813", "authors": ["Sébastien Da Veiga"], "title": "Distributional encoding for Gaussian process regression with qualitative inputs", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Gaussian Process (GP) regression is a popular and sample-efficient approach\nfor many engineering applications, where observations are expensive to acquire,\nand is also a central ingredient of Bayesian optimization (BO), a highly\nprevailing method for the optimization of black-box functions. However, when\nall or some input variables are categorical, building a predictive and\ncomputationally efficient GP remains challenging. Starting from the naive\ntarget encoding idea, where the original categorical values are replaced with\nthe mean of the target variable for that category, we propose a generalization\nbased on distributional encoding (DE) which makes use of all samples of the\ntarget variable for a category. To handle this type of encoding inside the GP,\nwe build upon recent results on characteristic kernels for probability\ndistributions, based on the maximum mean discrepancy and the Wasserstein\ndistance. We also discuss several extensions for classification, multi-task\nlearning and incorporation or auxiliary information. Our approach is validated\nempirically, and we demonstrate state-of-the-art predictive performance on a\nvariety of synthetic and real-world datasets. DE is naturally complementary to\nrecent advances in BO over discrete and mixed-spaces.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04579", "pdf": "https://arxiv.org/pdf/2506.04579", "abs": "https://arxiv.org/abs/2506.04579", "authors": ["Jianfei Zhang", "Bei Li", "Jun Bai", "Rumei Li", "Yanmeng Wang", "Chenghua Lin", "Wenge Rong"], "title": "Selecting Demonstrations for Many-Shot In-Context Learning via Gradient Matching", "categories": ["cs.CL"], "comment": "accepted to the ACL2025 Findings", "summary": "In-Context Learning (ICL) empowers Large Language Models (LLMs) for rapid\ntask adaptation without Fine-Tuning (FT), but its reliance on demonstration\nselection remains a critical challenge. While many-shot ICL shows promising\nperformance through scaled demonstrations, the selection method for many-shot\ndemonstrations remains limited to random selection in existing work. Since the\nconventional instance-level retrieval is not suitable for many-shot scenarios,\nwe hypothesize that the data requirements for in-context learning and\nfine-tuning are analogous. To this end, we introduce a novel gradient matching\napproach that selects demonstrations by aligning fine-tuning gradients between\nthe entire training set of the target task and the selected examples, so as to\napproach the learning effect on the entire training set within the selected\nexamples. Through gradient matching on relatively small models, e.g.,\nQwen2.5-3B or Llama3-8B, our method consistently outperforms random selection\non larger LLMs from 4-shot to 128-shot scenarios across 9 diverse datasets. For\ninstance, it surpasses random selection by 4% on Qwen2.5-72B and Llama3-70B,\nand by around 2% on 5 closed-source LLMs. This work unlocks more reliable and\neffective many-shot ICL, paving the way for its broader application.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04852", "pdf": "https://arxiv.org/pdf/2506.04852", "abs": "https://arxiv.org/abs/2506.04852", "authors": ["Vishwa Mohan Singh", "Sai Anirudh Aryasomayajula", "Ahan Chatterjee", "Beste Aydemir", "Rifat Mehreen Amin"], "title": "Improving AI-generated music with user-guided training", "categories": ["cs.SD", "cs.HC", "cs.LG", "eess.AS"], "comment": "Select for presentation in HHAI 2025", "summary": "AI music generation has advanced rapidly, with models like diffusion and\nautoregressive algorithms enabling high-fidelity outputs. These tools can alter\nstyles, mix instruments, or isolate them. Since sound can be visualized as\nspectrograms, image-generation algorithms can be applied to generate novel\nmusic. However, these algorithms are typically trained on fixed datasets, which\nmakes it challenging for them to interpret and respond to user input\naccurately. This is especially problematic because music is highly subjective\nand requires a level of personalization that image generation does not provide.\nIn this work, we propose a human-computation approach to gradually improve the\nperformance of these algorithms based on user interactions. The\nhuman-computation element involves aggregating and selecting user ratings to\nuse as the loss function for fine-tuning the model. We employ a genetic\nalgorithm that incorporates user feedback to enhance the baseline performance\nof a model initially trained on a fixed dataset. The effectiveness of this\napproach is measured by the average increase in user ratings with each\niteration. In the pilot test, the first iteration showed an average rating\nincrease of 0.2 compared to the baseline. The second iteration further improved\nupon this, achieving an additional increase of 0.39 over the first iteration.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04585", "pdf": "https://arxiv.org/pdf/2506.04585", "abs": "https://arxiv.org/abs/2506.04585", "authors": ["Yash Kumar Lal", "Manikanta Bandham", "Mohammad Saqib Hasan", "Apoorva Kashi", "Mahnaz Koupaee", "Niranjan Balasubramanian"], "title": "MuSciClaims: Multimodal Scientific Claim Verification", "categories": ["cs.CL"], "comment": null, "summary": "Assessing scientific claims requires identifying, extracting, and reasoning\nwith multimodal data expressed in information-rich figures in scientific\nliterature. Despite the large body of work in scientific QA, figure captioning,\nand other multimodal reasoning tasks over chart-based data, there are no\nreadily usable multimodal benchmarks that directly test claim verification\nabilities. To remedy this gap, we introduce a new benchmark MuSciClaims\naccompanied by diagnostics tasks. We automatically extract supported claims\nfrom scientific articles, which we manually perturb to produce contradicted\nclaims. The perturbations are designed to test for a specific set of claim\nverification capabilities. We also introduce a suite of diagnostic tasks that\nhelp understand model failures. Our results show most vision-language models\nare poor (~0.3-0.5 F1), with even the best model only achieving 0.77 F1. They\nare also biased towards judging claims as supported, likely misunderstanding\nnuanced perturbations within the claims. Our diagnostics show models are bad at\nlocalizing correct evidence within figures, struggle with aggregating\ninformation across modalities, and often fail to understand basic components of\nthe figure.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04878", "pdf": "https://arxiv.org/pdf/2506.04878", "abs": "https://arxiv.org/abs/2506.04878", "authors": ["Iosif Lytras", "Sotirios Sabanis", "Ying Zhang"], "title": "kTULA: A Langevin sampling algorithm with improved KL bounds under super-linear log-gradients", "categories": ["math.ST", "cs.LG", "math.PR", "stat.ML", "stat.TH"], "comment": null, "summary": "Motivated by applications in deep learning, where the global Lipschitz\ncontinuity condition is often not satisfied, we examine the problem of sampling\nfrom distributions with super-linearly growing log-gradients. We propose a\nnovel tamed Langevin dynamics-based algorithm, called kTULA, to solve the\naforementioned sampling problem, and provide a theoretical guarantee for its\nperformance. More precisely, we establish a non-asymptotic convergence bound in\nKullback-Leibler (KL) divergence with the best-known rate of convergence equal\nto $2-\\overline{\\epsilon}$, $\\overline{\\epsilon}>0$, which significantly\nimproves relevant results in existing literature. This enables us to obtain an\nimproved non-asymptotic error bound in Wasserstein-2 distance, which can be\nused to further derive a non-asymptotic guarantee for kTULA to solve the\nassociated optimization problems. To illustrate the applicability of kTULA, we\napply the proposed algorithm to the problem of sampling from a high-dimensional\ndouble-well potential distribution and to an optimization problem involving a\nneural network. We show that our main results can be used to provide\ntheoretical guarantees for the performance of kTULA.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04586", "pdf": "https://arxiv.org/pdf/2506.04586", "abs": "https://arxiv.org/abs/2506.04586", "authors": ["Wen Ding", "Fan Qian"], "title": "LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "We introduce LESS (Large Language Model Enhanced Semi-supervised Learning), a\nversatile framework that leverages Large Language Models (LLMs) to correct\npseudo labels generated from in-the-wild data. Within the LESS framework,\npseudo-labeled text from Automatic Speech Recognition (ASR) or Automatic Speech\nTranslation (AST) of the unsupervised data is refined by an LLM, and augmented\nby a data filtering strategy to optimize LLM knowledge transfer efficiency.\nExperiments on both Mandarin ASR and Spanish-to-English AST tasks show that\nLESS achieves a notable absolute WER reduction of 3.77% on the Wenet Speech\ntest set, as well as BLEU scores of 34.0 and 64.7 on Callhome and Fisher test\nsets respectively. These results validate the adaptability of LESS across\ndifferent languages, tasks, and domains. Ablation studies conducted with\nvarious LLMs and prompt configurations provide novel insights into leveraging\nLLM-derived knowledge for speech processing applications.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04945", "pdf": "https://arxiv.org/pdf/2506.04945", "abs": "https://arxiv.org/abs/2506.04945", "authors": ["Armin Kekić", "Sergio Hernan Garrido Mejia", "Bernhard Schölkopf"], "title": "Learning Joint Interventional Effects from Single-Variable Interventions in Additive Models", "categories": ["stat.ML", "cs.LG"], "comment": "To be published at the International Conference on Machine Learning\n  (ICML) 2025", "summary": "Estimating causal effects of joint interventions on multiple variables is\ncrucial in many domains, but obtaining data from such simultaneous\ninterventions can be challenging. Our study explores how to learn joint\ninterventional effects using only observational data and single-variable\ninterventions. We present an identifiability result for this problem, showing\nthat for a class of nonlinear additive outcome mechanisms, joint effects can be\ninferred without access to joint interventional data. We propose a practical\nestimator that decomposes the causal effect into confounded and unconfounded\ncontributions for each intervention variable. Experiments on synthetic data\ndemonstrate that our method achieves performance comparable to models trained\ndirectly on joint interventional data, outperforming a purely observational\nestimator.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05017", "pdf": "https://arxiv.org/pdf/2506.05017", "abs": "https://arxiv.org/abs/2506.05017", "authors": ["Zeno Belligoli", "Emmanouil Stergiadis", "Eran Fainman", "Ilya Gusev"], "title": "Controlling Summarization Length Through EOS Token Weighting", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Controlling the length of generated text can be crucial in various\ntext-generation tasks, including summarization. Existing methods often require\ncomplex model alterations, limiting compatibility with pre-trained models. We\naddress these limitations by developing a simple approach for controlling the\nlength of automatic text summaries by increasing the importance of correctly\npredicting the EOS token in the cross-entropy loss computation. The proposed\nmethodology is agnostic to architecture and decoding algorithms and orthogonal\nto other inference-time techniques to control the generation length. We tested\nit with encoder-decoder and modern GPT-style LLMs, and show that this method\ncan control generation length, often without affecting the quality of the\nsummary.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04603", "pdf": "https://arxiv.org/pdf/2506.04603", "abs": "https://arxiv.org/abs/2506.04603", "authors": ["Firoz Shaik", "Mobashir Sadat", "Nikita Gautam", "Doina Caragea", "Cornelia Caragea"], "title": "A MISMATCHED Benchmark for Scientific Natural Language Inference", "categories": ["cs.CL"], "comment": "Accepted to Findings of ACL 2025", "summary": "Scientific Natural Language Inference (NLI) is the task of predicting the\nsemantic relation between a pair of sentences extracted from research articles.\nExisting datasets for this task are derived from various computer science (CS)\ndomains, whereas non-CS domains are completely ignored. In this paper, we\nintroduce a novel evaluation benchmark for scientific NLI, called MISMATCHED.\nThe new MISMATCHED benchmark covers three non-CS domains-PSYCHOLOGY,\nENGINEERING, and PUBLIC HEALTH, and contains 2,700 human annotated sentence\npairs. We establish strong baselines on MISMATCHED using both Pre-trained Small\nLanguage Models (SLMs) and Large Language Models (LLMs). Our best performing\nbaseline shows a Macro F1 of only 78.17% illustrating the substantial headroom\nfor future improvements. In addition to introducing the MISMATCHED benchmark,\nwe show that incorporating sentence pairs having an implicit scientific NLI\nrelation between them in model training improves their performance on\nscientific NLI. We make our dataset and code publicly available on GitHub.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05120", "pdf": "https://arxiv.org/pdf/2506.05120", "abs": "https://arxiv.org/abs/2506.05120", "authors": ["Konstantin Göbler", "Tobias Windisch", "Mathias Drton"], "title": "Nonlinear Causal Discovery for Grouped Data", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "9 pages, 5 figures, to be published at UAI'25", "summary": "Inferring cause-effect relationships from observational data has gained\nsignificant attention in recent years, but most methods are limited to scalar\nrandom variables. In many important domains, including neuroscience,\npsychology, social science, and industrial manufacturing, the causal units of\ninterest are groups of variables rather than individual scalar measurements.\nMotivated by these applications, we extend nonlinear additive noise models to\nhandle random vectors, establishing a two-step approach for causal graph\nlearning: First, infer the causal order among random vectors. Second, perform\nmodel selection to identify the best graph consistent with this order. We\nintroduce effective and novel solutions for both steps in the vector case,\ndemonstrating strong performance in simulations. Finally, we apply our method\nto real-world assembly line data with partial knowledge of causal ordering\namong variable groups.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04611", "pdf": "https://arxiv.org/pdf/2506.04611", "abs": "https://arxiv.org/abs/2506.04611", "authors": ["Ho-Lam Chung", "Teng-Yun Hsiao", "Hsiao-Ying Huang", "Chunerh Cho", "Jian-Ren Lin", "Zhang Ziwei", "Yun-Nung Chen"], "title": "Revisiting Test-Time Scaling: A Survey and a Diversity-Aware Method for Efficient Reasoning", "categories": ["cs.CL"], "comment": "emnlp 2025 submission", "summary": "Test-Time Scaling (TTS) improves the reasoning performance of Large Language\nModels (LLMs) by allocating additional compute during inference. We conduct a\nstructured survey of TTS methods and categorize them into sampling-based,\nsearch-based, and trajectory optimization strategies. We observe that\nreasoning-optimized models often produce less diverse outputs, which limits TTS\neffectiveness. To address this, we propose ADAPT (A Diversity Aware Prefix\nfine-Tuning), a lightweight method that applies prefix tuning with a\ndiversity-focused data strategy. Experiments on mathematical reasoning tasks\nshow that ADAPT reaches 80% accuracy using eight times less compute than strong\nbaselines. Our findings highlight the essential role of generative diversity in\nmaximizing TTS effectiveness.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05202", "pdf": "https://arxiv.org/pdf/2506.05202", "abs": "https://arxiv.org/abs/2506.05202", "authors": ["Daniele Tramontano", "Yaroslav Kivva", "Saber Salehkaleybar Mathias Drton", "Negar Kiyavash"], "title": "Causal Effect Identification in lvLiNGAM from Higher-Order Cumulants", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "Accepted at ICML 2025", "summary": "This paper investigates causal effect identification in latent variable\nLinear Non-Gaussian Acyclic Models (lvLiNGAM) using higher-order cumulants,\naddressing two prominent setups that are challenging in the presence of latent\nconfounding: (1) a single proxy variable that may causally influence the\ntreatment and (2) underspecified instrumental variable cases where fewer\ninstruments exist than treatments. We prove that causal effects are\nidentifiable with a single proxy or instrument and provide corresponding\nestimation methods. Experimental results demonstrate the accuracy and\nrobustness of our approaches compared to existing methods, advancing the\ntheoretical and practical understanding of causal inference in linear systems\nwith latent confounders.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05203", "pdf": "https://arxiv.org/pdf/2506.05203", "abs": "https://arxiv.org/abs/2506.05203", "authors": ["Leonardo Ceragioli", "Giuseppe Primiero"], "title": "Trustworthiness Preservation by Copies of Machine Learning Systems", "categories": ["cs.LO", "cs.LG", "I.2.3; I.2.4"], "comment": null, "summary": "A common practice of ML systems development concerns the training of the same\nmodel under different data sets, and the use of the same (training and test)\nsets for different learning models. The first case is a desirable practice for\nidentifying high quality and unbiased training conditions. The latter case\ncoincides with the search for optimal models under a common dataset for\ntraining. These differently obtained systems have been considered akin to\ncopies. In the quest for responsible AI, a legitimate but hardly investigated\nquestion is how to verify that trustworthiness is preserved by copies. In this\npaper we introduce a calculus to model and verify probabilistic complex queries\nover data and define four distinct notions: Justifiably, Equally, Weakly and\nAlmost Trustworthy which can be checked analysing the (partial) behaviour of\nthe copy with respect to its original. We provide a study of the relations\nbetween these notions of trustworthiness, and how they compose with each other\nand under logical operations. The aim is to offer a computational tool to check\nthe trustworthiness of possibly complex systems copied from an original whose\nbehavour is known.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05209", "pdf": "https://arxiv.org/pdf/2506.05209", "abs": "https://arxiv.org/abs/2506.05209", "authors": ["Nikhil Kandpal", "Brian Lester", "Colin Raffel", "Sebastian Majstorovic", "Stella Biderman", "Baber Abbasi", "Luca Soldaini", "Enrico Shippole", "A. Feder Cooper", "Aviya Skowron", "John Kirchenbauer", "Shayne Longpre", "Lintang Sutawika", "Alon Albalak", "Zhenlin Xu", "Guilherme Penedo", "Loubna Ben Allal", "Elie Bakouch", "John David Pressman", "Honglu Fan", "Dashiell Stander", "Guangyu Song", "Aaron Gokaslan", "Tom Goldstein", "Brian R. Bartoldson", "Bhavya Kailkhura", "Tyler Murray"], "title": "The Common Pile v0.1: An 8TB Dataset of Public Domain and Openly Licensed Text", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) are typically trained on enormous quantities of\nunlicensed text, a practice that has led to scrutiny due to possible\nintellectual property infringement and ethical concerns. Training LLMs on\nopenly licensed text presents a first step towards addressing these issues, but\nprior data collection efforts have yielded datasets too small or low-quality to\nproduce performant LLMs. To address this gap, we collect, curate, and release\nthe Common Pile v0.1, an eight terabyte collection of openly licensed text\ndesigned for LLM pretraining. The Common Pile comprises content from 30 sources\nthat span diverse domains including research papers, code, books,\nencyclopedias, educational materials, audio transcripts, and more. Crucially,\nwe validate our efforts by training two 7 billion parameter LLMs on text from\nthe Common Pile: Comma v0.1-1T and Comma v0.1-2T, trained on 1 and 2 trillion\ntokens respectively. Both models attain competitive performance to LLMs trained\non unlicensed text with similar computational budgets, such as Llama 1 and 2\n7B. In addition to releasing the Common Pile v0.1 itself, we also release the\ncode used in its creation as well as the training mixture and checkpoints for\nthe Comma v0.1 models.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04616", "pdf": "https://arxiv.org/pdf/2506.04616", "abs": "https://arxiv.org/abs/2506.04616", "authors": ["Likun Cao", "Rui Pan", "James Evans"], "title": "Subjective Perspectives within Learned Representations Predict High-Impact Innovation", "categories": ["cs.CL", "stat.AP", "stat.ML"], "comment": "107 pages, 20 figures", "summary": "Existing studies of innovation emphasize the power of social structures to\nshape innovation capacity. Emerging machine learning approaches, however,\nenable us to model innovators' personal perspectives and interpersonal\ninnovation opportunities as a function of their prior trajectories of\nexperience. We theorize then quantify subjective perspectives and innovation\nopportunities based on innovator positions within the geometric space of\nconcepts inscribed by dynamic language representations. Using data on millions\nof scientists, inventors, writers, entrepreneurs, and Wikipedia contributors\nacross the creative domains of science, technology, film, entrepreneurship, and\nWikipedia, here we show that measured subjective perspectives anticipate what\nideas individuals and groups creatively attend to and successfully combine in\nfuture. When perspective and background diversity are decomposed as the angular\ndifference between collaborators' perspectives on their creation and between\ntheir experiences, the former consistently anticipates creative achievement\nwhile the latter portends its opposite, across all cases and time periods\nexamined. We analyze a natural experiment and simulate creative collaborations\nbetween AI (large language model) agents designed with various perspective and\nbackground diversity, which are consistent with our observational findings. We\nexplore mechanisms underlying these findings and identify how successful\ncollaborators leverage common language to weave together diverse experience\nobtained through trajectories of prior work that converge to provoke one\nanother and innovate. We explore the importance of these findings for team\nassembly and research policy.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05245", "pdf": "https://arxiv.org/pdf/2506.05245", "abs": "https://arxiv.org/abs/2506.05245", "authors": ["Shaoxuan Chen", "Su Yang", "Panayotis G. Kevrekidis", "Wei Zhu"], "title": "Robust Moment Identification for Nonlinear PDEs via a Neural ODE Approach", "categories": ["nlin.PS", "cs.LG"], "comment": null, "summary": "We propose a data-driven framework for learning reduced-order moment dynamics\nfrom PDE-governed systems using Neural ODEs. In contrast to derivative-based\nmethods like SINDy, which necessitate densely sampled data and are sensitive to\nnoise, our approach based on Neural ODEs directly models moment trajectories,\nenabling robust learning from sparse and potentially irregular time series.\nUsing as an application platform the nonlinear Schr\\\"{o}dinger equation, the\nframework accurately recovers governing moment dynamics when closure is\navailable, even with limited and irregular observations. For systems without\nanalytical closure, we introduce a data-driven coordinate transformation\nstrategy based on Stiefel manifold optimization, enabling the discovery of\nlow-dimensional representations in which the moment dynamics become closed,\nfacilitating interpretable and reliable modeling. We also explore cases where a\nclosure model is not known, such as a Fisher-KPP reaction-diffusion system.\nHere we demonstrate that Neural ODEs can still effectively approximate the\nunclosed moment dynamics and achieve superior extrapolation accuracy compared\nto physical-expert-derived ODE models. This advantage remains robust even under\nsparse and irregular sampling, highlighting the method's robustness in\ndata-limited settings. Our results highlight the Neural ODE framework as a\npowerful and flexible tool for learning interpretable, low-dimensional moment\ndynamics in complex PDE-governed systems.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04625", "pdf": "https://arxiv.org/pdf/2506.04625", "abs": "https://arxiv.org/abs/2506.04625", "authors": ["Zhiyuan Ma", "Jiayu Liu", "Xianzhen Luo", "Zhenya Huang", "Qingfu Zhu", "Wanxiang Che"], "title": "Advancing Tool-Augmented Large Language Models via Meta-Verification and Reflection Learning", "categories": ["cs.CL"], "comment": "Accepted at the Research Track of KDD 2025", "summary": "Empowering large language models (LLMs) with effective tool utilization\ncapabilities is crucial for enabling AI agents to solve complex problems.\nHowever, current models face two major limitations: (1) unreliable tool\nplanning and invocation due to low-quality instruction datasets (e.g.,\nwidespread hallucinated API calls), and (2) weak tool reflection abilities\n(over 90% of errors cannot be corrected) resulting from static imitation\nlearning. To address these critical limitations, we propose Tool-MVR, a novel\nTool-Augmented LLM that achieves comprehensive System 2 reasoning through two\nkey innovations. Specifically, we first introduce Multi-Agent Meta-Verification\n(MAMV), a systematic pipeline that rigorously validates APIs, queries, and\nreasoning trajectories to construct ToolBench-V, a new high-quality instruction\ndataset that addresses the limitation of unreliable tool planning and\ninvocation. Second, we propose Exploration-based Reflection Learning (EXPLORE),\nwhich enhances tool reflection capabilities by leveraging tool feedback through\na dynamic \"Error -> Reflection -> Correction\" learning paradigm, resulting in\nour reflection dataset ToolBench-R and addressing the critical weakness in tool\nreflection. Finally, we obtain Tool-MVR by finetuning open-source LLMs (e.g.,\nQwen-7B) on both ToolBench-V and ToolBench-R. Our experiments demonstrate that\nTool-MVR achieves state-of-the-art performance on StableToolBench, surpassing\nboth ToolLLM (by 23.9%) and GPT-4 (by 15.3%) while reducing API calls by 31.4%,\nwith strong generalization capabilities across unseen tools and scenarios.\nAdditionally, on our proposed RefineToolBench, the first benchmark specifically\ndesigned to evaluate tool reflection capabilities, Tool-MVR achieves a 58.9%\nerror correction rate, significantly outperforming ToolLLM's 9.1%.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05320", "pdf": "https://arxiv.org/pdf/2506.05320", "abs": "https://arxiv.org/abs/2506.05320", "authors": ["Avery Hee-Woon Ryoo", "Nanda H. Krishna", "Ximeng Mao", "Mehdi Azabou", "Eva L. Dyer", "Matthew G. Perich", "Guillaume Lajoie"], "title": "Generalizable, real-time neural decoding with hybrid state-space models", "categories": ["q-bio.NC", "cs.LG"], "comment": "Preprint. Under review", "summary": "Real-time decoding of neural activity is central to neuroscience and\nneurotechnology applications, from closed-loop experiments to brain-computer\ninterfaces, where models are subject to strict latency constraints. Traditional\nmethods, including simple recurrent neural networks, are fast and lightweight\nbut often struggle to generalize to unseen data. In contrast, recent\nTransformer-based approaches leverage large-scale pretraining for strong\ngeneralization performance, but typically have much larger computational\nrequirements and are not always suitable for low-resource or real-time\nsettings. To address these shortcomings, we present POSSM, a novel hybrid\narchitecture that combines individual spike tokenization via a cross-attention\nmodule with a recurrent state-space model (SSM) backbone to enable (1) fast and\ncausal online prediction on neural activity and (2) efficient generalization to\nnew sessions, individuals, and tasks through multi-dataset pretraining. We\nevaluate POSSM's decoding performance and inference speed on intracortical\ndecoding of monkey motor tasks, and show that it extends to clinical\napplications, namely handwriting and speech decoding in human subjects.\nNotably, we demonstrate that pretraining on monkey motor-cortical recordings\nimproves decoding performance on the human handwriting task, highlighting the\nexciting potential for cross-species transfer. In all of these tasks, we find\nthat POSSM achieves decoding accuracy comparable to state-of-the-art\nTransformers, at a fraction of the inference cost (up to 9x faster on GPU).\nThese results suggest that hybrid SSMs are a promising approach to bridging the\ngap between accuracy, inference speed, and generalization when training neural\ndecoders for real-time, closed-loop applications.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05329", "pdf": "https://arxiv.org/pdf/2506.05329", "abs": "https://arxiv.org/abs/2506.05329", "authors": ["Guido Imbens", "Chao Qin", "Stefan Wager"], "title": "Admissibility of Completely Randomized Trials: A Large-Deviation Approach", "categories": ["stat.ML", "cs.LG", "econ.EM"], "comment": "A one-page abstract of this work will appear at the 26th ACM\n  Conference on Economics and Computation (EC'25)", "summary": "When an experimenter has the option of running an adaptive trial, is it\nadmissible to ignore this option and run a non-adaptive trial instead? We\nprovide a negative answer to this question in the best-arm identification\nproblem, where the experimenter aims to allocate measurement efforts\njudiciously to confidently deploy the most effective treatment arm. We find\nthat, whenever there are at least three treatment arms, there exist simple\nadaptive designs that universally and strictly dominate non-adaptive completely\nrandomized trials. This dominance is characterized by a notion called\nefficiency exponent, which quantifies a design's statistical efficiency when\nthe experimental sample is large. Our analysis focuses on the class of batched\narm elimination designs, which progressively eliminate underperforming arms at\npre-specified batch intervals. We characterize simple sufficient conditions\nunder which these designs universally and strictly dominate completely\nrandomized trials. These results resolve the second open problem posed in Qin\n[2022].", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05334", "pdf": "https://arxiv.org/pdf/2506.05334", "abs": "https://arxiv.org/abs/2506.05334", "authors": ["Mihran Miroyan", "Tsung-Han Wu", "Logan King", "Tianle Li", "Jiayi Pan", "Xinyan Hu", "Wei-Lin Chiang", "Anastasios N. Angelopoulos", "Trevor Darrell", "Narges Norouzi", "Joseph E. Gonzalez"], "title": "Search Arena: Analyzing Search-Augmented LLMs", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": "Preprint. Code: https://github.com/lmarena/search-arena. Dataset:\n  https://huggingface.co/datasets/lmarena-ai/search-arena-24k", "summary": "Search-augmented language models combine web search with Large Language\nModels (LLMs) to improve response groundedness and freshness. However,\nanalyzing these systems remains challenging: existing datasets are limited in\nscale and narrow in scope, often constrained to static, single-turn,\nfact-checking questions. In this work, we introduce Search Arena, a\ncrowd-sourced, large-scale, human-preference dataset of over 24,000 paired\nmulti-turn user interactions with search-augmented LLMs. The dataset spans\ndiverse intents and languages, and contains full system traces with around\n12,000 human preference votes. Our analysis reveals that user preferences are\ninfluenced by the number of citations, even when the cited content does not\ndirectly support the attributed claims, uncovering a gap between perceived and\nactual credibility. Furthermore, user preferences vary across cited sources,\nrevealing that community-driven platforms are generally preferred and static\nencyclopedic sources are not always appropriate and reliable. To assess\nperformance across different settings, we conduct cross-arena analyses by\ntesting search-augmented LLMs in a general-purpose chat environment and\nconventional LLMs in search-intensive settings. We find that web search does\nnot degrade and may even improve performance in non-search settings; however,\nthe quality in search settings is significantly affected if solely relying on\nthe model's parametric knowledge. We open-sourced the dataset to support future\nresearch in this direction. Our dataset and code are available at:\nhttps://github.com/lmarena/search-arena.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04642", "pdf": "https://arxiv.org/pdf/2506.04642", "abs": "https://arxiv.org/abs/2506.04642", "authors": ["Vinay Joshi", "Pratik Prabhanjan Brahma", "Zicheng Liu", "Emad Barsoum"], "title": "TaDA: Training-free recipe for Decoding with Adaptive KV Cache Compression and Mean-centering", "categories": ["cs.CL"], "comment": "ACL-2025 industry-track accepted", "summary": "The key-value (KV) cache in transformer models is a critical component for\nefficient decoding or inference, yet its memory demands scale poorly with\nsequence length, posing a major challenge for scalable deployment of large\nlanguage models. Among several approaches to KV cache compression, quantization\nof key and value activations has been widely explored. Most KV cache\nquantization methods still need to manage sparse and noncontiguous outliers\nseparately. To address this, we introduce TaDA, a training-free recipe for KV\ncache compression with quantization precision that adapts to error sensitivity\nacross layers and a mean centering to eliminate separate outlier handling. Our\napproach yields substantial accuracy improvements for multiple models\nsupporting various context lengths. Moreover, our approach does not need to\nseparately manage outlier elements -- a persistent hurdle in most traditional\nquantization methods. Experiments on standard benchmarks demonstrate that our\ntechnique reduces KV cache memory footprint to 27% of the original 16-bit\nbaseline while achieving comparable accuracy. Our method paves the way for\nscalable and high-performance reasoning in language models by potentially\nenabling inference for longer context length models, reasoning models, and\nlonger chain of thoughts.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04649", "pdf": "https://arxiv.org/pdf/2506.04649", "abs": "https://arxiv.org/abs/2506.04649", "authors": ["Juhyun Oh", "Eunsu Kim", "Alice Oh"], "title": "Flex-TravelPlanner: A Benchmark for Flexible Planning with Language Agents", "categories": ["cs.CL"], "comment": null, "summary": "Real-world planning problems require constant adaptation to changing\nrequirements and balancing of competing constraints. However, current\nbenchmarks for evaluating LLMs' planning capabilities primarily focus on\nstatic, single-turn scenarios. We introduce Flex-TravelPlanner, a benchmark\nthat evaluates language models' ability to reason flexibly in dynamic planning\nscenarios. Building on the TravelPlanner dataset~\\citep{xie2024travelplanner},\nwe introduce two novel evaluation settings: (1) sequential constraint\nintroduction across multiple turns, and (2) scenarios with explicitly\nprioritized competing constraints. Our analysis of GPT-4o and Llama 3.1 70B\nreveals several key findings: models' performance on single-turn tasks poorly\npredicts their ability to adapt plans across multiple turns; constraint\nintroduction order significantly affects performance; and models struggle with\nconstraint prioritization, often incorrectly favoring newly introduced lower\npriority preferences over existing higher-priority constraints. These findings\nhighlight the importance of evaluating LLMs in more realistic, dynamic planning\nscenarios and suggest specific directions for improving model performance on\ncomplex planning tasks. The code and dataset for our framework are publicly\navailable at https://github.com/juhyunohh/FlexTravelBench.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04657", "pdf": "https://arxiv.org/pdf/2506.04657", "abs": "https://arxiv.org/abs/2506.04657", "authors": ["Nanako Omiya", "Ryo Yoshinaka", "Ayumi Shinohara"], "title": "Misère Greedy Nim and Misère Bounded Greedy Nim", "categories": ["cs.GT", "cs.DM"], "comment": null, "summary": "In this paper, we analyze the mis\\`ere versions of two impartial\ncombinatorial games: k-Bounded Greedy Nim and Greedy Nim. We present a complete\nsolution to both games by showing necessary and sufficient conditions for a\nposition to be P-positions.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04659", "pdf": "https://arxiv.org/pdf/2506.04659", "abs": "https://arxiv.org/abs/2506.04659", "authors": ["Mukesh Rajmohan", "Smit Desai", "Sanchari Das"], "title": "Multi-Tool Analysis of User Interface & Accessibility in Deployed Web-Based Chatbots", "categories": ["cs.HC", "H.5.2; K.4.2"], "comment": "9 pages, 6 figures. Submitted to ACM Conversational User Interfaces\n  (CUI) 2025", "summary": "In this work, we present a multi-tool evaluation of 106 deployed web-based\nchatbots, across domains like healthcare, education and customer service,\ncomprising both standalone applications and embedded widgets using automated\ntools (Google Lighthouse, PageSpeed Insights, SiteImprove Accessibility\nChecker) and manual audits (Microsoft Accessibility Insights). Our analysis\nreveals that over 80% of chatbots exhibit at least one critical accessibility\nissue, and 45% suffer from missing semantic structures or ARIA role misuse.\nFurthermore, we found that accessibility scores correlate strongly across tools\n(e.g., Lighthouse vs PageSpeed Insights, r = 0.861), but performance scores do\nnot (r = 0.436), underscoring the value of a multi-tool approach. We offer a\nreplicable evaluation insights and actionable recommendations to support the\ndevelopment of user-friendly conversational interfaces.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04665", "pdf": "https://arxiv.org/pdf/2506.04665", "abs": "https://arxiv.org/abs/2506.04665", "authors": ["Rian Neogi", "Kanstantsin Pashkovich", "Chaitanya Swamy"], "title": "An O(log log n)-approximate budget feasible mechanism for subadditive valuations", "categories": ["cs.GT"], "comment": null, "summary": "In budget-feasible mechanism design, there is a set of items $U$, each owned\nby a distinct seller. The seller of item $e$ incurs a private cost\n$\\overline{c}_e$ for supplying her item. A buyer wishes to procure a set of\nitems from the sellers of maximum value, where the value of a set $S\\subseteq\nU$ of items is given by a valuation function $v:2^U\\to \\mathbb{R}_+$. The buyer\nhas a budget of $B \\in \\mathbb{R}_+$ for the total payments made to the\nsellers. We wish to design a mechanism that is truthful, that is, sellers are\nincentivized to report their true costs, budget-feasible, that is, the sum of\nthe payments made to the sellers is at most the budget $B$, and that outputs a\nset whose value is large compared to $\\text{OPT}:=\\max\\{v(S):\\overline{c}(S)\\le\nB,S\\subseteq U\\}$.\n  Budget-feasible mechanism design has been extensively studied, with the\nliterature focussing on (classes of) subadditive valuation functions, and\nvarious polytime, budget-feasible mechanisms, achieving constant-factor\napproximation, have been devised for the special cases of additive, submodular,\nand XOS valuations. However, for general subadditive valuations, the best-known\napproximation factor achievable by a polytime budget-feasible mechanism (given\naccess to demand oracles) was only $O(\\log n / \\log \\log n)$, where $n$ is the\nnumber of items.\n  We improve this state-of-the-art significantly by designing a budget-feasible\nmechanism for subadditive valuations that \\emph{achieves a\nsubstantially-improved approximation factor of $O(\\log\\log n)$ and runs in\npolynomial time, given access to demand oracles.}", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04678", "pdf": "https://arxiv.org/pdf/2506.04678", "abs": "https://arxiv.org/abs/2506.04678", "authors": ["Ming Li", "Wendi Cheng", "Jiahe Wei", "Xueqiang Shan", "Liu Weikai", "Xiaonan Zhao", "Xiao Zhang"], "title": "BVLSM: Write-Efficient LSM-Tree Storage via WAL-Time Key-Value Separation", "categories": ["cs.DB"], "comment": null, "summary": "Modern data-intensive applications increasingly store and process big-value\nitems, such as multimedia objects and machine learning embeddings, which\nexacerbate storage inefficiencies in Log-Structured Merge-Tree (LSM)-based\nkey-value stores. This paper presents BVLSM, a Write-Ahead Log (WAL)-time\nkey-value separation mechanism designed to address three key challenges in\nLSM-Tree storage systems: write amplification, poor memory utilization, and I/O\njitter under big-value workloads. Unlike state-of-the-art approaches that delay\nkey-value separation until the flush stage, leading to redundant data in\nMemTables and repeated writes. BVLSM proactively decouples keys and values\nduring the WAL phase. The MemTable stores only lightweight metadata, allowing\nmulti-queue parallel store for big value. The benchmark results show that BVLSM\nsignificantly outperforms both RocksDB and BlobDB under 64KB random write\nworkloads. In asynchronous WAL mode, it achieves throughput improvements of\n7.6x over RocksDB and 1.9x over BlobDB.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04679", "pdf": "https://arxiv.org/pdf/2506.04679", "abs": "https://arxiv.org/abs/2506.04679", "authors": ["Raphaël Millière"], "title": "Normative Conflicts and Shallow AI Alignment", "categories": ["cs.CL"], "comment": "Published in Philosophical Studies", "summary": "The progress of AI systems such as large language models (LLMs) raises\nincreasingly pressing concerns about their safe deployment. This paper examines\nthe value alignment problem for LLMs, arguing that current alignment strategies\nare fundamentally inadequate to prevent misuse. Despite ongoing efforts to\ninstill norms such as helpfulness, honesty, and harmlessness in LLMs through\nfine-tuning based on human preferences, they remain vulnerable to adversarial\nattacks that exploit conflicts between these norms. I argue that this\nvulnerability reflects a fundamental limitation of existing alignment methods:\nthey reinforce shallow behavioral dispositions rather than endowing LLMs with a\ngenuine capacity for normative deliberation. Drawing from on research in moral\npsychology, I show how humans' ability to engage in deliberative reasoning\nenhances their resilience against similar adversarial tactics. LLMs, by\ncontrast, lack a robust capacity to detect and rationally resolve normative\nconflicts, leaving them susceptible to manipulation; even recent advances in\nreasoning-focused LLMs have not addressed this vulnerability. This ``shallow\nalignment'' problem carries significant implications for AI safety and\nregulation, suggesting that current approaches are insufficient for mitigating\npotential harms posed by increasingly capable AI systems.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04693", "pdf": "https://arxiv.org/pdf/2506.04693", "abs": "https://arxiv.org/abs/2506.04693", "authors": ["Lu Wei", "Liangzhi Li", "Tong Xiang", "Xiao Liu", "Noa Garcia"], "title": "Cracking the Code: Enhancing Implicit Hate Speech Detection through Coding Classification", "categories": ["cs.CL"], "comment": "Proceedings of the 5th Workshop on Trustworthy NLP (TrustNLP 2025),\n  112-126", "summary": "The internet has become a hotspot for hate speech (HS), threatening societal\nharmony and individual well-being. While automatic detection methods perform\nwell in identifying explicit hate speech (ex-HS), they struggle with more\nsubtle forms, such as implicit hate speech (im-HS). We tackle this problem by\nintroducing a new taxonomy for im-HS detection, defining six encoding\nstrategies named codetypes. We present two methods for integrating codetypes\ninto im-HS detection: 1) prompting large language models (LLMs) directly to\nclassify sentences based on generated responses, and 2) using LLMs as encoders\nwith codetypes embedded during the encoding process. Experiments show that the\nuse of codetypes improves im-HS detection in both Chinese and English datasets,\nvalidating the effectiveness of our approach across different languages.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04698", "pdf": "https://arxiv.org/pdf/2506.04698", "abs": "https://arxiv.org/abs/2506.04698", "authors": ["Hugo Alcaraz-Herrera", "Michail-Antisthenis Tsompanas", "Igor Balaz", "Andrew Adamatzky"], "title": "NEAT and HyperNEAT based Design for Soft Actuator Controllers", "categories": ["cs.NE"], "comment": null, "summary": "Since soft robotics are composed of compliant materials, they perform better\nthan conventional rigid robotics in specific fields, such as medical\napplications. However, the field of soft robotics is fairly new, and the design\nprocess of their morphology and their controller strategies has not yet been\nthoroughly studied. Consequently, here, an automated design method for the\ncontroller of soft actuators based on Neuroevolution is proposed. Specifically,\nthe suggested techniques employ Neuroevolution of Augmenting Topologies (NEAT)\nand Hypercube-based NEAT (HyperNEAT) to generate the synchronization profile of\nthe components of a simulated soft actuator by employing Compositional Pattern\nProducing Networks (CPPNs). As a baseline methodology, a Standard Genetic\nAlgorithm (SGA) was used. Moreover, to test the robustness of the proposed\nmethodologies, both high- and low-performing morphologies of soft actuators\nwere utilized as testbeds. Moreover, the use of an affluent and a more limited\nset of activation functions for the Neuroevolution targets was tested\nthroughout the experiments. The results support the hypothesis that\nNeuroevolution based methodologies are more appropriate for designing\ncontrollers that align with both types of morphologies. In specific, NEAT\nperformed better for all different scenarios tested and produced more\nsimplistic networks that are easier to implement in real life applications.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04708", "pdf": "https://arxiv.org/pdf/2506.04708", "abs": "https://arxiv.org/abs/2506.04708", "authors": ["Woomin Song", "Saket Dingliwal", "Sai Muralidhar Jayanthi", "Bhavana Ganesh", "Jinwoo Shin", "Aram Galstyan", "Sravan Babu Bodapati"], "title": "Accelerated Test-Time Scaling with Model-Free Speculative Sampling", "categories": ["cs.CL"], "comment": null, "summary": "Language models have demonstrated remarkable capabilities in reasoning tasks\nthrough test-time scaling techniques like best-of-N sampling and tree search.\nHowever, these approaches often demand substantial computational resources,\ncreating a critical trade-off between performance and efficiency. We introduce\nSTAND (STochastic Adaptive N-gram Drafting), a novel model-free speculative\ndecoding approach that leverages the inherent redundancy in reasoning\ntrajectories to achieve significant acceleration without compromising accuracy.\nOur analysis reveals that reasoning paths frequently reuse similar reasoning\npatterns, enabling efficient model-free token prediction without requiring\nseparate draft models. By introducing stochastic drafting and preserving\nprobabilistic information through a memory-efficient logit-based N-gram module,\ncombined with optimized Gumbel-Top-K sampling and data-driven tree\nconstruction, STAND significantly improves token acceptance rates. Extensive\nevaluations across multiple models and reasoning tasks (AIME-2024,\nGPQA-Diamond, and LiveCodeBench) demonstrate that STAND reduces inference\nlatency by 60-65% compared to standard autoregressive decoding while\nmaintaining accuracy. Furthermore, STAND outperforms state-of-the-art\nspeculative decoding methods by 14-28% in throughput and shows strong\nperformance even in single-trajectory scenarios, reducing inference latency by\n48-58%. As a model-free approach, STAND can be applied to any existing language\nmodel without additional training, being a powerful plug-and-play solution for\naccelerating language model reasoning.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04710", "pdf": "https://arxiv.org/pdf/2506.04710", "abs": "https://arxiv.org/abs/2506.04710", "authors": ["Lucas Åkerstedt", "Harald Hultin", "B. L. G. Jonsson"], "title": "An Array Decomposition Method for Finite Arrays with Electrically Connected Elements for fast Toeplitz Solvers", "categories": ["math.NA", "cs.NA", "eess.SP"], "comment": "12 pages, 17 figures", "summary": "A large part of the geometry of array antennas is often partially defined by\nfinite translational symmetries. Applying the method of moments (MoM) with the\nRWG-like element on an appropriately structured mesh to these arrays results in\nan impedance matrix where the main part exhibits a multilevel block Toeplitz\nstructure. This article introduces a memory-efficient construction method that\neffectively represents and reuses impedance calculations. The proposed method,\napplicable to electrically connected elements, also accounts for all\nnon-symmetric parts of the array. The core idea involves nine distinct\nelectrically connectable components from which the array can be assembled. The\nderived multilevel block Toeplitz matrix is further utilized by an in-house\ninverse solver to achieve faster and more memory-efficient MoM current vector\ncalculations. We demonstrate the method by computing the far-field of a 32x32\narray and the scattering parameters of two tightly coupled 9x9 arrays. This\napproach reduces the memory allocation from $\\mathcal{O}(N_x^2 N_y^2)$ to\n$\\mathcal{O}(N_x N_y)$, for an $N_x \\times N_y$ array.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04711", "pdf": "https://arxiv.org/pdf/2506.04711", "abs": "https://arxiv.org/abs/2506.04711", "authors": ["Te Ma", "Min Bi", "Saierdaer Yusuyin", "Hao Huang", "Zhijian Ou"], "title": "LLM-based phoneme-to-grapheme for phoneme-based speech recognition", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "Interspeech 2025", "summary": "In automatic speech recognition (ASR), phoneme-based multilingual\npre-training and crosslingual fine-tuning is attractive for its high data\nefficiency and competitive results compared to subword-based models. However,\nWeighted Finite State Transducer (WFST) based decoding is limited by its\ncomplex pipeline and inability to leverage large language models (LLMs).\nTherefore, we propose LLM-based phoneme-to-grapheme (LLM-P2G) decoding for\nphoneme-based ASR, consisting of speech-to-phoneme (S2P) and\nphoneme-to-grapheme (P2G). A challenge is that there seems to have information\nloss in cascading S2P and P2G. To address this challenge, we propose two\ntraining strategies: data augmentation with noisy phonemes (DANP), and\nrandomized top-$K$ marginalized (TKM) training and decoding. Our experimental\nresults show that LLM-P2G outperforms WFST-based systems in crosslingual ASR\nfor Polish and German, by relative WER reductions of 3.6% and 6.9%\nrespectively.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04714", "pdf": "https://arxiv.org/pdf/2506.04714", "abs": "https://arxiv.org/abs/2506.04714", "authors": ["Bhavana Akkiraju", "Aishwarya Pothula", "Santosh Kesiraju", "Anil Kumar Vuppala"], "title": "IIITH-BUT system for IWSLT 2025 low-resource Bhojpuri to Hindi speech translation", "categories": ["cs.CL", "eess.AS"], "comment": "Paper is accepted to IWSLT2025", "summary": "This paper presents the submission of IIITH-BUT to the IWSLT 2025 shared task\non speech translation for the low-resource Bhojpuri-Hindi language pair. We\nexplored the impact of hyperparameter optimisation and data augmentation\ntechniques on the performance of the SeamlessM4T model fine-tuned for this\nspecific task. We systematically investigated a range of hyperparameters\nincluding learning rate schedules, number of update steps, warm-up steps, label\nsmoothing, and batch sizes; and report their effect on translation quality. To\naddress data scarcity, we applied speed perturbation and SpecAugment and\nstudied their effect on translation quality. We also examined the use of\ncross-lingual signal through joint training with Marathi and Bhojpuri speech\ndata. Our experiments reveal that careful selection of hyperparameters and the\napplication of simple yet effective augmentation techniques significantly\nimprove performance in low-resource settings. We also analysed the translation\nhypotheses to understand various kinds of errors that impacted the translation\nquality in terms of BLEU.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04721", "pdf": "https://arxiv.org/pdf/2506.04721", "abs": "https://arxiv.org/abs/2506.04721", "authors": ["Yuru Jiang", "Wenxuan Ding", "Shangbin Feng", "Greg Durrett", "Yulia Tsvetkov"], "title": "SPARTA ALIGNMENT: Collectively Aligning Multiple Language Models through Combat", "categories": ["cs.CL"], "comment": null, "summary": "We propose SPARTA ALIGNMENT, an algorithm to collectively align multiple LLMs\nthrough competition and combat. To complement a single model's lack of\ndiversity in generation and biases in evaluation, multiple LLMs form a \"sparta\ntribe\" to compete against each other in fulfilling instructions while serving\nas judges for the competition of others. For each iteration, one instruction\nand two models are selected for a duel, the other models evaluate the two\nresponses, and their evaluation scores are aggregated through a adapted\nelo-ranking based reputation system, where winners/losers of combat gain/lose\nweight in evaluating others. The peer-evaluated combat results then become\npreference pairs where the winning response is preferred over the losing one,\nand all models learn from these preferences at the end of each iteration.\nSPARTA ALIGNMENT enables the self-evolution of multiple LLMs in an iterative\nand collective competition process. Extensive experiments demonstrate that\nSPARTA ALIGNMENT outperforms initial models and 4 self-alignment baselines\nacross 10 out of 12 tasks and datasets with 7.0% average improvement. Further\nanalysis reveals that SPARTA ALIGNMENT generalizes more effectively to unseen\ntasks and leverages the expertise diversity of participating models to produce\nmore logical, direct and informative outputs.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04732", "pdf": "https://arxiv.org/pdf/2506.04732", "abs": "https://arxiv.org/abs/2506.04732", "authors": ["Nicola Cavallini", "Gianmarco Manzini", "Daniele Funaro", "Andrea Favalli"], "title": "A Fast, Accurate and Oscillation-free Spectral Collocation Solver for High-dimensional Transport Problems", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Transport phenomena-describing the movement of particles, energy, or other\nphysical quantities-are fundamental in various scientific disciplines,\nincluding nuclear physics, plasma physics, astrophysics, engineering, and the\nnatural sciences.\n  However, solving the associated seven-dimensional transport equations poses a\nsignificant computational challenge due to the curse of dimensionality.\n  We introduce the Tensor Train Superconsistent Spectral (T${^2}$S${^2}$)\nsolver to address this challenge, integrating Spectral Collocation for\nexponential convergence, Superconsistency for stabilization in\ntransport-dominated regimes, and Tensor Train format for substantial data\ncompression. T${^2}$S${^2}$ enforces a dimension-wise superconsistent condition\ncompatible with tensor structures, achieving extremely low compression ratios,\nin the order of $(10^{-12})$, while preserving spectral accuracy. Numerical\nexperiments on linear problems demonstrate that T${^2}$S${^2}$ can solve\nhigh-dimensional transport problems in minutes on standard hardware, making\npreviously intractable problems computationally feasible. This advancement\nopens new avenues for efficiently and accurately modeling complex transport\nphenomena.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04745", "pdf": "https://arxiv.org/pdf/2506.04745", "abs": "https://arxiv.org/abs/2506.04745", "authors": ["Camilla Mannino", "Pierpaolo Sorrentino", "Mario Chavez", "Marie-Costance Corsi"], "title": "Neuronal avalanches as a predictive biomarker of BCI performance: towards a tool to guide tailored training program", "categories": ["cs.HC"], "comment": null, "summary": "Brain-Computer Interfaces (BCIs) based on motor imagery (MI) hold promise for\nrestoring control in individuals with motor impairments. However, up to 30% of\nusers remain unable to effectively use BCIs-a phenomenon termed ''BCI\ninefficiency.'' This study addresses a major limitation in current BCI training\nprotocols: the use of fixed-length training paradigms that ignore individual\nlearning variability. We propose a novel approach that leverages neuronal\navalanches-spatiotemporal cascades of brain activity-as biomarkers to\ncharacterize and predict user-specific learning mechanism. Using\nelectroencephalography (EEG) data collected across four MI-BCI training\nsessions in 20 healthy participants, we extracted two features: avalanche\nlength and activations. These features revealed significant training and\ntaskcondition effects, particularly in later sessions. Crucially, changes in\nthese features across sessions ($\\Delta$avalanche length and\n$\\Delta$activations) correlated significantly with BCI performance and enabled\nprediction of future BCI success via longitudinal Support Vector Regression and\nClassification models. Predictive accuracy reached up to 91%, with notable\nimprovements after spatial filtering based on selected regions of interest.\nThese findings demonstrate the utility of neuronal avalanche dynamics as robust\nbiomarkers for BCI training, supporting the development of personalized\nprotocols aimed at mitigating BCI illiteracy.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04760", "pdf": "https://arxiv.org/pdf/2506.04760", "abs": "https://arxiv.org/abs/2506.04760", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "title": "Exp4Fuse: A Rank Fusion Framework for Enhanced Sparse Retrieval using Large Language Model-based Query Expansion", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have shown potential in generating hypothetical\ndocuments for query expansion, thereby enhancing information retrieval\nperformance. However, the efficacy of this method is highly dependent on the\nquality of the generated documents, which often requires complex prompt\nstrategies and the integration of advanced dense retrieval techniques. This can\nbe both costly and computationally intensive. To mitigate these limitations, we\nexplore the use of zero-shot LLM-based query expansion to improve sparse\nretrieval, particularly for learned sparse retrievers. We introduce a novel\nfusion ranking framework, Exp4Fuse, which enhances the performance of sparse\nretrievers through an indirect application of zero-shot LLM-based query\nexpansion. Exp4Fuse operates by simultaneously considering two retrieval\nroutes-one based on the original query and the other on the LLM-augmented\nquery. It then generates two ranked lists using a sparse retriever and fuses\nthem using a modified reciprocal rank fusion method. We conduct extensive\nevaluations of Exp4Fuse against leading LLM-based query expansion methods and\nadvanced retrieval techniques on three MS MARCO-related datasets and seven\nlow-resource datasets. Experimental results reveal that Exp4Fuse not only\nsurpasses existing LLM-based query expansion methods in enhancing sparse\nretrievers but also, when combined with advanced sparse retrievers, achieves\nSOTA results on several benchmarks. This highlights the superior performance\nand effectiveness of Exp4Fuse in improving query expansion for sparse\nretrieval.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04762", "pdf": "https://arxiv.org/pdf/2506.04762", "abs": "https://arxiv.org/abs/2506.04762", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "title": "GOLFer: Smaller LM-Generated Documents Hallucination Filter & Combiner for Query Expansion in Information Retrieval", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Large language models (LLMs)-based query expansion for information retrieval\naugments queries with generated hypothetical documents with LLMs. However, its\nperformance relies heavily on the scale of the language models (LMs),\nnecessitating larger, more advanced LLMs. This approach is costly,\ncomputationally intensive, and often has limited accessibility. To address\nthese limitations, we introduce GOLFer - Smaller LMs-Generated Documents\nHallucination Filter & Combiner - a novel method leveraging smaller open-source\nLMs for query expansion. GOLFer comprises two modules: a hallucination filter\nand a documents combiner. The former detects and removes non-factual and\ninconsistent sentences in generated documents, a common issue with smaller LMs,\nwhile the latter combines the filtered content with the query using a weight\nvector to balance their influence. We evaluate GOLFer alongside dominant\nLLM-based query expansion methods on three web search and ten low-resource\ndatasets. Experimental results demonstrate that GOLFer consistently outperforms\nother methods using smaller LMs, and maintains competitive performance against\nmethods using large-size LLMs, demonstrating its effectiveness.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04772", "pdf": "https://arxiv.org/pdf/2506.04772", "abs": "https://arxiv.org/abs/2506.04772", "authors": ["Léane Jourdan", "Florian Boudin", "Richard Dufour", "Nicolas Hernandez"], "title": "Identifying Reliable Evaluation Metrics for Scientific Text Revision", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 main", "summary": "Evaluating text revision in scientific writing remains a challenge, as\ntraditional metrics such as ROUGE and BERTScore primarily focus on similarity\nrather than capturing meaningful improvements. In this work, we analyse and\nidentify the limitations of these metrics and explore alternative evaluation\nmethods that better align with human judgments. We first conduct a manual\nannotation study to assess the quality of different revisions. Then, we\ninvestigate reference-free evaluation metrics from related NLP domains.\nAdditionally, we examine LLM-as-a-judge approaches, analysing their ability to\nassess revisions with and without a gold reference. Our results show that LLMs\neffectively assess instruction-following but struggle with correctness, while\ndomain-specific metrics provide complementary insights. We find that a hybrid\napproach combining LLM-as-a-judge evaluation and task-specific metrics offers\nthe most reliable assessment of revision quality.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04779", "pdf": "https://arxiv.org/pdf/2506.04779", "abs": "https://arxiv.org/abs/2506.04779", "authors": ["Dingdong Wang", "Jincenzi Wu", "Junan Li", "Dongchao Yang", "Xueyuan Chen", "Tianhua Zhang", "Helen Meng"], "title": "MMSU: A Massive Multi-task Spoken Language Understanding and Reasoning Benchmark", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "MMSU benchmark is available at\n  https://huggingface.co/datasets/ddwang2000/MMSU. Evaluation Code is available\n  at https://github.com/dingdongwang/MMSU_Bench", "summary": "Speech inherently contains rich acoustic information that extends far beyond\nthe textual language. In real-world spoken language understanding, effective\ninterpretation often requires integrating semantic meaning (e.g., content),\nparalinguistic features (e.g., emotions, speed, pitch) and phonological\ncharacteristics (e.g., prosody, intonation, rhythm), which are embedded in\nspeech. While recent multimodal Speech Large Language Models (SpeechLLMs) have\ndemonstrated remarkable capabilities in processing audio information, their\nability to perform fine-grained perception and complex reasoning in natural\nspeech remains largely unexplored. To address this gap, we introduce MMSU, a\ncomprehensive benchmark designed specifically for understanding and reasoning\nin spoken language. MMSU comprises 5,000 meticulously curated\naudio-question-answer triplets across 47 distinct tasks. To ground our\nbenchmark in linguistic theory, we systematically incorporate a wide range of\nlinguistic phenomena, including phonetics, prosody, rhetoric, syntactics,\nsemantics, and paralinguistics. Through a rigorous evaluation of 14 advanced\nSpeechLLMs, we identify substantial room for improvement in existing models,\nhighlighting meaningful directions for future optimization. MMSU establishes a\nnew standard for comprehensive assessment of spoken language understanding,\nproviding valuable insights for developing more sophisticated human-AI speech\ninteraction systems. MMSU benchmark is available at\nhttps://huggingface.co/datasets/ddwang2000/MMSU. Evaluation Code is available\nat https://github.com/dingdongwang/MMSU_Bench.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04808", "pdf": "https://arxiv.org/pdf/2506.04808", "abs": "https://arxiv.org/abs/2506.04808", "authors": ["Quentin Bourgeais", "Rodolphe Charrier", "Eric Sanlaville", "Ludovic Seifert"], "title": "Temporal passing network in basketball: the effect of time pressure on the dynamics of team organization at micro and meso levels", "categories": ["cs.DM"], "comment": null, "summary": "In this study, basketball teams are conceptualized as complex adaptive\nsystems to examine their (re)organizational processes in response the time\nremaining to shoot. Using temporal passing networks to model team behavior, the\nfocus is on the dynamics of the temporal patterns of interaction between\nplayers. Several metrics grounded in social network analysis are calculated at\ndifferent level to assess the dynamics of the patterns used by teams and of the\nindividual roles within those patterns. The results reveal a 3-phase dynamic,\ndifferentiated by more or less complex and diversified patterns, and by more or\nless specialized or flexible roles. Additionally, time-dependent features of\nthe different tactical playing positions are identified, some of which linked\nto team performance. The findings are intended to explain how basketball teams\nadapt their organization to cope with time pressure, offering potential\ninsights for other type of teams facing similar constraints. Moreover, this\nwork provides a useful framework for a multilevel understanding of how\nconstraints shape team adaptations dynamically, making it applicable to a wide\nrange of team settings.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04809", "pdf": "https://arxiv.org/pdf/2506.04809", "abs": "https://arxiv.org/abs/2506.04809", "authors": ["Michael J. Carley"], "title": "Numerical solution of the wave equation outside a sphere", "categories": ["math.NA", "cs.NA", "math.AP", "physics.class-ph", "physics.comp-ph"], "comment": null, "summary": "A method is presented for the fast evaluation of the transient acoustic field\ngenerated outside a spherical surface by sources inside the surface. The method\nemploys Lebedev quadratures, which are the optimal method for spatial\nintegration, and Lagrange interpolation and differentiation in an advanced time\nalgorithm for the evaluation of the transient field. Numerical testing\ndemonstrates that the approach gives near machine-precision accuracy and a\nspeed-up in evaluation time which depends on the order of quadrature rule\nemployed but breaks even with direct evaluation at a number of field points\nabout 1.15 times the number of surface quadrature nodes.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04811", "pdf": "https://arxiv.org/pdf/2506.04811", "abs": "https://arxiv.org/abs/2506.04811", "authors": ["Feijun Liu", "Huifeng Wang", "Kun Wang", "Yizhen Wang"], "title": "Design of intelligent proofreading system for English translation based on CNN and BERT", "categories": ["cs.CL"], "comment": null, "summary": "Since automatic translations can contain errors that require substantial\nhuman post-editing, machine translation proofreading is essential for improving\nquality. This paper proposes a novel hybrid approach for robust proofreading\nthat combines convolutional neural networks (CNN) with Bidirectional Encoder\nRepresentations from Transformers (BERT). In order to extract semantic\ninformation from phrases and expressions, CNN uses a variety of convolution\nkernel filters to capture local n-gram patterns. In the meanwhile, BERT creates\ncontext-rich representations of whole sequences by utilizing stacked\nbidirectional transformer encoders. Using BERT's attention processes, the\nintegrated error detection component relates tokens to spot translation\nirregularities including word order problems and omissions. The correction\nmodule then uses parallel English-German alignment and GRU decoder models in\nconjunction with translation memory to propose logical modifications that\nmaintain original meaning. A unified end-to-end training process optimized for\npost-editing performance is applied to the whole pipeline. The multi-domain\ncollection of WMT and the conversational dialogues of Open-Subtitles are two of\nthe English-German parallel corpora used to train the model. Multiple loss\nfunctions supervise detection and correction capabilities. Experiments attain a\n90% accuracy, 89.37% F1, and 16.24% MSE, exceeding recent proofreading\ntechniques by over 10% overall. Comparative benchmarking demonstrates\nstate-of-the-art performance in identifying and coherently rectifying\nmistranslations and omissions.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04822", "pdf": "https://arxiv.org/pdf/2506.04822", "abs": "https://arxiv.org/abs/2506.04822", "authors": ["Nurul Aisyah", "Muhammad Dehan Al Kautsar", "Arif Hidayat", "Raqib Chowdhury", "Fajri Koto"], "title": "Evaluating Vision-Language and Large Language Models for Automated Student Assessment in Indonesian Classrooms", "categories": ["cs.CL"], "comment": null, "summary": "Although vision-language and large language models (VLM and LLM) offer\npromising opportunities for AI-driven educational assessment, their\neffectiveness in real-world classroom settings, particularly in\nunderrepresented educational contexts, remains underexplored. In this study, we\nevaluated the performance of a state-of-the-art VLM and several LLMs on 646\nhandwritten exam responses from grade 4 students in six Indonesian schools,\ncovering two subjects: Mathematics and English. These sheets contain more than\n14K student answers that span multiple choice, short answer, and essay\nquestions. Assessment tasks include grading these responses and generating\npersonalized feedback. Our findings show that the VLM often struggles to\naccurately recognize student handwriting, leading to error propagation in\ndownstream LLM grading. Nevertheless, LLM-generated feedback retains some\nutility, even when derived from imperfect input, although limitations in\npersonalization and contextual relevance persist.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04832", "pdf": "https://arxiv.org/pdf/2506.04832", "abs": "https://arxiv.org/abs/2506.04832", "authors": ["Changyue Wang", "Weihang Su", "Qingyao Ai", "Yiqun Liu"], "title": "Joint Evaluation of Answer and Reasoning Consistency for Hallucination Detection in Large Reasoning Models", "categories": ["cs.CL"], "comment": null, "summary": "Large Reasoning Models (LRMs) extend large language models with explicit,\nmulti-step reasoning traces to enhance transparency and performance on complex\ntasks. However, these reasoning traces can be redundant or logically\ninconsistent, making them a new source of hallucination that is difficult to\ndetect. Existing hallucination detection methods focus primarily on\nanswer-level uncertainty and often fail to detect hallucinations or logical\ninconsistencies arising from the model's reasoning trace. This oversight is\nparticularly problematic for LRMs, where the explicit thinking trace is not\nonly an important support to the model's decision-making process but also a key\nsource of potential hallucination. To this end, we propose RACE (Reasoning and\nAnswer Consistency Evaluation), a novel framework specifically tailored for\nhallucination detection in LRMs. RACE operates by extracting essential\nreasoning steps and computing four diagnostic signals: inter-sample consistency\nof reasoning traces, entropy-based answer uncertainty, semantic alignment\nbetween reasoning and answers, and internal coherence of reasoning. This joint\nanalysis enables fine-grained hallucination detection even when the final\nanswer appears correct. Experiments across datasets and different LLMs\ndemonstrate that RACE outperforms existing hallucination detection baselines,\noffering a robust and generalizable solution for evaluating LRMs. Our code is\navailable at: https://github.com/bebr2/RACE.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04840", "pdf": "https://arxiv.org/pdf/2506.04840", "abs": "https://arxiv.org/abs/2506.04840", "authors": ["Maolin Che", "Yimin Wei", "Chong Wu", "Hong Yan"], "title": "Efficient randomized algorithms for the fixed Tucker-rank problem of Tucker decomposition with adaptive shifts", "categories": ["math.NA", "cs.NA", "65F55, 68W20, 15A18, 15A69"], "comment": "41 pages, 43 figures", "summary": "Randomized numerical linear algebra is proved to bridge theoretical\nadvancements to offer scalable solutions for approximating tensor\ndecomposition. This paper introduces fast randomized algorithms for solving the\nfixed Tucker-rank problem of Tucker decomposition, through the integration of\nadaptive shifted power iterations. The proposed algorithms enhance randomized\nvariants of truncated high-order singular value decomposition (T-HOSVD) and\nsequentially T-HOSVD (ST-HOSVD) by incorporating dynamic shift strategies,\nwhich accelerate convergence by refining the singular value gap and reduce the\nnumber of required power iterations while maintaining accuracy. Theoretical\nanalyses provide probabilistic error bounds, demonstrating that the proposed\nmethods achieve comparable or superior accuracy compared to deterministic\napproaches. Numerical experiments on synthetic and real-world datasets validate\nthe efficiency and robustness of the proposed algorithms, showing a significant\ndecline in runtime and approximation error over state-of-the-art techniques.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04841", "pdf": "https://arxiv.org/pdf/2506.04841", "abs": "https://arxiv.org/abs/2506.04841", "authors": ["Indrajeet Sahu", "Nik Petrinic"], "title": "Midplane based 3D single pass unbiased segment-to-segment contact interaction using penalty method", "categories": ["cs.GR", "math-ph", "math.MP"], "comment": null, "summary": "This work introduces a contact interaction methodology for an unbiased\ntreatment of contacting surfaces without assigning surfaces as master and\nslave. The contact tractions between interacting discrete segments are\nevaluated with respect to a midplane in a single pass, inherently maintaining\nthe equilibrium of tractions. These tractions are based on the penalisation of\ntrue interpenetration between opposite surfaces, and the procedure of their\nintegral for discrete contacting segments is described in this paper. A\nmeticulous examination of the different possible geometric configurations of\ninteracting 3D segments is presented to develop visual understanding and better\ntraction evaluation accuracy. The accuracy and robustness of the proposed\nmethod are validated against the analytical solutions of the contact patch\ntest, two-beam bending, Hertzian contact, and flat punch test, thus proving the\ncapability to reproduce contact between flat surfaces, curved surfaces, and\nsharp corners in contact, respectively. The method passes the contact patch\ntest with the uniform transmission of contact pressure matching the accuracy\nlevels of finite elements. It converges towards the analytical solution with\nmesh refinement and a suitably high penalty factor. The effectiveness of the\nproposed algorithm also extends to self-contact problems and has been tested\nfor self-contact between flat and curved surfaces with inelastic material.\nDynamic problems of elastic and inelastic collisions between bars, as well as\noblique collisions of cylinders, are also presented. The ability of the\nalgorithm to resolve contacts between flat and curved surfaces for nonconformal\nmeshes with high accuracy demonstrates its versatility in general contact\nproblems.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04848", "pdf": "https://arxiv.org/pdf/2506.04848", "abs": "https://arxiv.org/abs/2506.04848", "authors": ["Dávid Javorský", "Ondřej Bojar", "François Yvon"], "title": "MockConf: A Student Interpretation Dataset: Analysis, Word- and Span-level Alignment and Baselines", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "In simultaneous interpreting, an interpreter renders a source speech into\nanother language with a very short lag, much sooner than sentences are\nfinished. In order to understand and later reproduce this dynamic and complex\ntask automatically, we need dedicated datasets and tools for analysis,\nmonitoring, and evaluation, such as parallel speech corpora, and tools for\ntheir automatic annotation. Existing parallel corpora of translated texts and\nassociated alignment algorithms hardly fill this gap, as they fail to model\nlong-range interactions between speech segments or specific types of\ndivergences (e.g., shortening, simplification, functional generalization)\nbetween the original and interpreted speeches. In this work, we introduce\nMockConf, a student interpreting dataset that was collected from Mock\nConferences run as part of the students' curriculum. This dataset contains 7\nhours of recordings in 5 European languages, transcribed and aligned at the\nlevel of spans and words. We further implement and release InterAlign, a modern\nweb-based annotation tool for parallel word and span annotations on long\ninputs, suitable for aligning simultaneous interpreting. We propose metrics for\nthe evaluation and a baseline for automatic alignment. Dataset and tools are\nreleased to the community.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04855", "pdf": "https://arxiv.org/pdf/2506.04855", "abs": "https://arxiv.org/abs/2506.04855", "authors": ["Dávid Javorský", "Ondřej Bojar", "François Yvon"], "title": "Prompting LLMs: Length Control for Isometric Machine Translation", "categories": ["cs.CL"], "comment": "Accepted to IWSLT 2025", "summary": "In this study, we explore the effectiveness of isometric machine translation\nacross multiple language pairs (En$\\to$De, En$\\to$Fr, and En$\\to$Es) under the\nconditions of the IWSLT Isometric Shared Task 2022. Using eight open-source\nlarge language models (LLMs) of varying sizes, we investigate how different\nprompting strategies, varying numbers of few-shot examples, and demonstration\nselection influence translation quality and length control. We discover that\nthe phrasing of instructions, when aligned with the properties of the provided\ndemonstrations, plays a crucial role in controlling the output length. Our\nexperiments show that LLMs tend to produce shorter translations only when\npresented with extreme examples, while isometric demonstrations often lead to\nthe models disregarding length constraints. While few-shot prompting generally\nenhances translation quality, further improvements are marginal across 5, 10,\nand 20-shot settings. Finally, considering multiple outputs allows to notably\nimprove overall tradeoff between the length and quality, yielding\nstate-of-the-art performance for some language pairs.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04857", "pdf": "https://arxiv.org/pdf/2506.04857", "abs": "https://arxiv.org/abs/2506.04857", "authors": ["Junming Duan", "Praveen Chandrashekar", "Christian Klingenberg"], "title": "Active flux for ideal magnetohydrodynamics: A positivity-preserving scheme with the Godunov-Powell source term", "categories": ["math.NA", "cs.NA"], "comment": "27 pages, 12 figures", "summary": "The Active Flux (AF) is a compact, high-order finite volume scheme that\nallows more flexibility by introducing additional point value degrees of\nfreedom at cell interfaces. This paper proposes a positivity-preserving (PP) AF\nscheme for solving the ideal magnetohydrodynamics, where the Godunov-Powell\nsource term is employed to deal with the divergence-free constraint. For the\nevolution of the cell average, apart from the standard conservative finite\nvolume method for the flux derivative, the nonconservative source term is built\non the quadratic reconstruction in each cell, which maintains the compact\nstencil in the AF scheme. For the point value update, the local Lax-Friedrichs\n(LLF) flux vector splitting is adopted for the flux derivative, originally\nproposed in [Duan, Barsukow, and Klingenberg, SIAM Journal on Scientific\nComputing, 47(2), A811--A837, 2025], and a central difference is used to\ndiscretize the divergence in the source term. A parametrized flux limiter and a\nscaling limiter are presented to preserve the density and pressure positivity\nby blending the AF scheme with the first-order PP LLF scheme with the source\nterm. To suppress oscillations, a new shock sensor considering the divergence\nerror is proposed, which is used to compute the blending coefficients for the\ncell average. Several numerical tests are conducted to verify the third-order\naccuracy, PP property, and shock-capturing ability of the scheme. The key role\nof the Godunov-Powell source term and its suitable discretization in\ncontrolling divergence error is also validated.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04865", "pdf": "https://arxiv.org/pdf/2506.04865", "abs": "https://arxiv.org/abs/2506.04865", "authors": ["Mohan Sunkara", "Akshay Kolgar Nayak", "Sandeep Kalari", "Yash Prakash", "Sampath Jayarathna", "Hae-Na Lee", "Vikas Ashok"], "title": "Adapting Online Customer Reviews for Blind Users: A Case Study of Restaurant Reviews", "categories": ["cs.HC"], "comment": null, "summary": "Online reviews have become an integral aspect of consumer decision-making on\ne-commerce websites, especially in the restaurant industry. Unlike sighted\nusers who can visually skim through the reviews, perusing reviews remains\nchallenging for blind users, who rely on screen reader assistive technology\nthat supports predominantly one-dimensional narration of content via keyboard\nshortcuts. In an interview study, we uncovered numerous pain points of blind\nscreen reader users with online restaurant reviews, notably, the listening\nfatigue and frustration after going through only the first few reviews. To\naddress these issues, we developed QuickQue assistive tool that performs\naspect-focused sentiment-driven summarization to reorganize the information in\nthe reviews into an alternative, thematically-organized presentation that is\nconveniently perusable with a screen reader. At its core, QuickQue utilizes a\nlarge language model to perform aspect-based joint classification for grouping\nreviews, followed by focused summarizations within the groups to generate\nconcise representations of reviewers' opinions, which are then presented to the\nscreen reader users via an accessible interface. Evaluation of QuickQue in a\nuser study with 10 participants showed significant improvements in overall\nusability and task workload compared to the status quo screen reader.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04880", "pdf": "https://arxiv.org/pdf/2506.04880", "abs": "https://arxiv.org/abs/2506.04880", "authors": ["Heiko Gimperlein", "Ruma R. Maity"], "title": "Numerical analysis for constrained and unconstrained Q-tensor energies for liquid crystals", "categories": ["math.NA", "cs.NA", "65N12, 35J47, 65N30, 76A15"], "comment": null, "summary": "This paper introduces a comprehensive finite element approximation framework\nfor three-dimensional Landau-de Gennes $Q$-tensor energies for nematic liquid\ncrystals, with a particular focus on the anisotropy of the elastic energy and\nthe Ball-Majumdar singular potential. This potential imposes essential physical\nconstraints on the eigenvalues of the $Q$-tensor, ensuring realistic modeling.\nWe address the approximation of regular solutions to nonlinear elliptic partial\ndifferential equations with non-homogeneous boundary conditions associated with\nLandau-de Gennes energies. The well-posedness of the discrete linearized\nproblem is rigorously demonstrated. The existence and local uniqueness of the\ndiscrete solution is derived using the Newton-Kantorovich theorem. Furthermore,\nwe demonstrate an optimal order convergence rate in the energy norm and discuss\nthe impact of eigenvalue constraints on the a priori error analysis.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04887", "pdf": "https://arxiv.org/pdf/2506.04887", "abs": "https://arxiv.org/abs/2506.04887", "authors": ["Wenxi Li"], "title": "Evaluating the Effectiveness of Linguistic Knowledge in Pretrained Language Models: A Case Study of Universal Dependencies", "categories": ["cs.CL"], "comment": null, "summary": "Universal Dependencies (UD), while widely regarded as the most successful\nlinguistic framework for cross-lingual syntactic representation, remains\nunderexplored in terms of its effectiveness. This paper addresses this gap by\nintegrating UD into pretrained language models and assesses if UD can improve\ntheir performance on a cross-lingual adversarial paraphrase identification\ntask. Experimental results show that incorporation of UD yields significant\nimprovements in accuracy and $F_1$ scores, with average gains of 3.85\\% and\n6.08\\% respectively. These enhancements reduce the performance gap between\npretrained models and large language models in some language pairs, and even\noutperform the latter in some others. Furthermore, the UD-based similarity\nscore between a given language and English is positively correlated to the\nperformance of models in that language. Both findings highlight the validity\nand potential of UD in out-of-domain tasks.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04894", "pdf": "https://arxiv.org/pdf/2506.04894", "abs": "https://arxiv.org/abs/2506.04894", "authors": ["Shiyi Xu", "Yiwen Hu", "Yingqian Min", "Zhipeng Chen", "Wayne Xin Zhao", "Ji-Rong Wen"], "title": "ICPC-Eval: Probing the Frontiers of LLM Reasoning with Competitive Programming Contests", "categories": ["cs.CL"], "comment": null, "summary": "With the significant progress of large reasoning models in complex coding and\nreasoning tasks, existing benchmarks, like LiveCodeBench and CodeElo, are\ninsufficient to evaluate the coding capabilities of large language models\n(LLMs) in real competition environments. Moreover, current evaluation metrics\nsuch as Pass@K fail to capture the reflective abilities of reasoning models. To\naddress these challenges, we propose \\textbf{ICPC-Eval}, a top-level\ncompetitive coding benchmark designed to probing the frontiers of LLM\nreasoning. ICPC-Eval includes 118 carefully curated problems from 11 recent\nICPC contests held in various regions of the world, offering three key\ncontributions: 1) A challenging realistic ICPC competition scenario, featuring\na problem type and difficulty distribution consistent with actual contests. 2)\nA robust test case generation method and a corresponding local evaluation\ntoolkit, enabling efficient and accurate local evaluation. 3) An effective\ntest-time scaling evaluation metric, Refine@K, which allows iterative repair of\nsolutions based on execution feedback. The results underscore the significant\nchallenge in evaluating complex reasoning abilities: top-tier reasoning models\nlike DeepSeek-R1 often rely on multi-turn code feedback to fully unlock their\nin-context reasoning potential when compared to non-reasoning counterparts.\nFurthermore, despite recent advancements in code generation, these models still\nlag behind top-performing human teams. We release the benchmark at:\nhttps://github.com/RUCAIBox/Slow_Thinking_with_LLMs", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04915", "pdf": "https://arxiv.org/pdf/2506.04915", "abs": "https://arxiv.org/abs/2506.04915", "authors": ["Ondřej Klejch", "William Lamb", "Peter Bell"], "title": "A Practitioner's Guide to Building ASR Models for Low-Resource Languages: A Case Study on Scottish Gaelic", "categories": ["cs.CL", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "An effective approach to the development of ASR systems for low-resource\nlanguages is to fine-tune an existing multilingual end-to-end model. When the\noriginal model has been trained on large quantities of data from many\nlanguages, fine-tuning can be effective with limited training data, even when\nthe language in question was not present in the original training data. The\nfine-tuning approach has been encouraged by the availability of public-domain\nE2E models and is widely believed to lead to state-of-the-art results. This\npaper, however, challenges that belief. We show that an approach combining\nhybrid HMMs with self-supervised models can yield substantially better\nperformance with limited training data. This combination allows better\nutilisation of all available speech and text data through continued\nself-supervised pre-training and semi-supervised training. We benchmark our\napproach on Scottish Gaelic, achieving WER reductions of 32% relative over our\nbest fine-tuned Whisper model.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04921", "pdf": "https://arxiv.org/pdf/2506.04921", "abs": "https://arxiv.org/abs/2506.04921", "authors": ["Maria Cherifa", "Clément Calauzènes", "Vianney Perchet"], "title": "Online matching on stochastic block model", "categories": ["cs.DS"], "comment": null, "summary": "While online bipartite matching has gained significant attention in recent\nyears, existing analyses in stochastic settings fail to capture the performance\nof algorithms on heterogeneous graphs, such as those incorporating inter-group\naffinities or other social network structures. In this work, we address this\ngap by studying online bipartite matching within the stochastic block model\n(SBM). A fixed set of offline nodes is matched to a stream of online arrivals,\nwith connections governed probabilistically by latent class memberships. We\nanalyze two natural algorithms: a $\\tt{Myopic}$ policy that greedily matches\neach arrival to the most compatible class, and the $\\tt{Balance}$ algorithm,\nwhich accounts for both compatibility and remaining capacity. For the\n$\\tt{Myopic}$ algorithm, we prove that the size of the matching converges, with\nhigh probability, to the solution of an ordinary differential equation (ODE),\nfor which we provide a tractable approximation along with explicit error\nbounds. For the $\\tt{Balance}$ algorithm, we demonstrate convergence of the\nmatching size to a differential inclusion and derive an explicit limiting\nsolution. Lastly, we explore the impact of estimating the connection\nprobabilities between classes online, which introduces an\nexploration-exploitation trade-off.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04926", "pdf": "https://arxiv.org/pdf/2506.04926", "abs": "https://arxiv.org/abs/2506.04926", "authors": ["Florian Ingels", "Anaïs Denis", "Bastien Cazaux"], "title": "Decomposing Words for Enhanced Compression: Exploring the Number of Runs in the Extended Burrows-Wheeler Transform", "categories": ["cs.DS", "cs.DM", "cs.FL"], "comment": null, "summary": "The Burrows-Wheeler Transform (BWT) is a fundamental component in many data\nstructures for text indexing and compression, widely used in areas such as\nbioinformatics and information retrieval. The extended BWT (eBWT) generalizes\nthe classical BWT to multisets of strings, providing a flexible framework that\ncaptures many BWT-like constructions. Several known variants of the BWT can be\nviewed as instances of the eBWT applied to specific decompositions of a word. A\ncentral property of the BWT, essential for its compressibility, is the number\nof maximal ranges of equal letters, named runs. In this article, we explore how\ndifferent decompositions of a word impact the number of runs in the resulting\neBWT. First, we show that the number of decompositions of a word is\nexponential, even under minimal constraints on the size of the subsets in the\ndecomposition. Second, we present an infinite family of words for which the\nratio of the number of runs between the worst and best decompositions is\nunbounded, under the same minimal constraints. These results illustrate the\npotential cost of decomposition choices in eBWT-based compression and underline\nthe challenges in optimizing run-length encoding in generalized BWT frameworks.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04929", "pdf": "https://arxiv.org/pdf/2506.04929", "abs": "https://arxiv.org/abs/2506.04929", "authors": ["Mikołaj Pokrywka", "Wojciech Kusa", "Mieszko Rutkowski", "Mikołaj Koszowski"], "title": "ConECT Dataset: Overcoming Data Scarcity in Context-Aware E-Commerce MT", "categories": ["cs.CL"], "comment": "Accepted at ACL 2025 (The 63rd Annual Meeting of the Association for\n  Computational Linguistics)", "summary": "Neural Machine Translation (NMT) has improved translation by using\nTransformer-based models, but it still struggles with word ambiguity and\ncontext. This problem is especially important in domain-specific applications,\nwhich often have problems with unclear sentences or poor data quality. Our\nresearch explores how adding information to models can improve translations in\nthe context of e-commerce data. To this end we create ConECT -- a new\nCzech-to-Polish e-commerce product translation dataset coupled with images and\nproduct metadata consisting of 11,400 sentence pairs. We then investigate and\ncompare different methods that are applicable to context-aware translation. We\ntest a vision-language model (VLM), finding that visual context aids\ntranslation quality. Additionally, we explore the incorporation of contextual\ninformation into text-to-text models, such as the product's category path or\nimage descriptions. The results of our study demonstrate that the incorporation\nof contextual information leads to an improvement in the quality of machine\ntranslation. We make the new dataset publicly available.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04935", "pdf": "https://arxiv.org/pdf/2506.04935", "abs": "https://arxiv.org/abs/2506.04935", "authors": ["Pengxin Bian", "Panagiotis Charalampopoulos", "Lorraine A. K. Ayad", "Manal Mohamed", "Solon P. Pissis", "Grigorios Loukides"], "title": "Resilient Pattern Mining", "categories": ["cs.DS"], "comment": "35 pages, 13 figures", "summary": "Frequent pattern mining is a flagship problem in data mining. In its most\nbasic form, it asks for the set of substrings of a given string $S$ of length\n$n$ that occur at least $\\tau$ times in $S$, for some integer $\\tau\\in[1,n]$.\nWe introduce a resilient version of this classic problem, which we term the\n$(\\tau, k)$-Resilient Pattern Mining (RPM) problem. Given a string $S$ of\nlength $n$ and two integers $\\tau, k\\in[1,n]$, RPM asks for the set of\nsubstrings of $S$ that occur at least $\\tau$ times in $S$, even when the\nletters at any $k$ positions of $S$ are substituted by other letters. Unlike\nfrequent substrings, resilient ones account for the fact that changes to string\n$S$ are often expensive to handle or are unknown.\n  We propose an exact $\\mathcal{O}(n\\log n)$-time and $\\mathcal{O}(n)$-space\nalgorithm for RPM, which employs advanced data structures and combinatorial\ninsights. We then present experiments on real large-scale datasets from\ndifferent domains demonstrating that: (I) The notion of resilient substrings is\nuseful in analyzing genomic data and is more powerful than that of frequent\nsubstrings, in scenarios where resilience is required, such as in the case of\nversioned datasets; (II) Our algorithm is several orders of magnitude faster\nand more space-efficient than a baseline algorithm that is based on dynamic\nprogramming; and (III) Clustering based on resilient substrings is effective.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04949", "pdf": "https://arxiv.org/pdf/2506.04949", "abs": "https://arxiv.org/abs/2506.04949", "authors": ["Marta Vanin", "Frederik Geth", "Rahmat Heidari", "Dirk Van Hertem"], "title": "Distribution System State and Impedance Estimation Augmented with Carson's Equations", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "The impedances of cables and lines used in (multi-conductor) distribution\nnetworks are usually unknown or approximated, and may lead to problematic\nresults for any physics-based power system calculation, e.g., (optimal) power\nflow. Learning parameters from time series data is one of the few available\noptions to obtain improved impedance models. This paper presents an approach\nthat combines statistical learning concepts with the exploitation of domain\nknowledge, in the form of Carson's equations, through nonlinear mathematical\noptimization. The proposed approach derives impedance matrices for\nup-to-four-wire systems, using measurement data like those obtained from smart\nmeters. Despite the lack of phasor measurements, the low signal-to-noise ratio\nof smart meter measurements, and the inherent existence of multiple equivalent\nsolutions, our method produces good quality impedance models that are fit for\npower system calculations, significantly improving on our previous work both in\nterms of accuracy and computational time.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04968", "pdf": "https://arxiv.org/pdf/2506.04968", "abs": "https://arxiv.org/abs/2506.04968", "authors": ["Pengbo Zhu", "Giancarlo Ferrari-Trecate", "Nikolas Geroliminis"], "title": "En Route Path-planning for Partially Occupied Vehicles in Ride-pooling Systems", "categories": ["eess.SY", "cs.SY"], "comment": "Accepted by European Control Conference (ECC 2025), 24-27 June,\n  Thessaloniki, Greece", "summary": "Ride-pooling services, such as UberPool and Lyft Shared Saver, enable a\nsingle vehicle to serve multiple customers within one shared trip. Efficient\npath-planning algorithms are crucial for improving the performance of such\nsystems. For partially occupied vehicles with available capacity, we introduce\na novel routing algorithm designed to maximize the likelihood of picking up\nadditional passengers while serving the current passengers to their\ndestination. Unlike traditional methods that group passengers and vehicles\nbased on predefined time windows, our algorithm allows for immediate responses\nto passenger requests. Our approach optimizes travel time while dynamically\nconsidering passenger demand and coordinating with other vehicles. Formulated\nas an integer linear programming (ILP) problem, our method is computationally\nefficient and suitable for real-time applications. Simulation results\ndemonstrate that our proposed method can significantly enhance service quality.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04969", "pdf": "https://arxiv.org/pdf/2506.04969", "abs": "https://arxiv.org/abs/2506.04969", "authors": ["Yema Paul", "Emmanuel Delande", "Francois Vinet", "Francois Laporte", "Manuel Sanjurjo-Rivo", "Aldo Tonnini", "Joan-Pau Sanchez"], "title": "Probability of Collision with Tethered Spacecraft", "categories": ["math.NA", "cs.NA"], "comment": "13 pages, 2 figures, Engineering Note", "summary": "This Engineering Note addresses the challenge of estimating the probability\nof collision for tethered spacecraft during close encounters with other space\nobjects. Standard probability of collision methods, based on spherical\nhard-body assumptions, tend to be overly conservative when applied to long\ntether systems. We introduce a method that accounts for the tether's spatial\nextent and configuration uncertainty by maximizing the probability of collision\nover all physically admissible tether shapes. Applied to real-world conjunction\nevents involving a kilometer-scale flexible inextensible tether, the method\nyields more realistic risk estimates. This approach improves the ability to\ndistinguish hazardous from benign encounters, thereby supporting more informed\ncollision avoidance decisions.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04981", "pdf": "https://arxiv.org/pdf/2506.04981", "abs": "https://arxiv.org/abs/2506.04981", "authors": ["Andres Carofilis", "Pradeep Rangappa", "Srikanth Madikeri", "Shashi Kumar", "Sergio Burdisso", "Jeena Prakash", "Esau Villatoro-Tello", "Petr Motlicek", "Bidisha Sharma", "Kadri Hacioglu", "Shankar Venkatesan", "Saurabh Vyas", "Andreas Stolcke"], "title": "Better Semi-supervised Learning for Multi-domain ASR Through Incremental Retraining and Data Filtering", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted at Interspeech 2025, Netherlands", "summary": "Fine-tuning pretrained ASR models for specific domains is challenging when\nlabeled data is scarce. But unlabeled audio and labeled data from related\ndomains are often available. We propose an incremental semi-supervised learning\npipeline that first integrates a small in-domain labeled set and an auxiliary\ndataset from a closely related domain, achieving a relative improvement of 4%\nover no auxiliary data. Filtering based on multi-model consensus or named\nentity recognition (NER) is then applied to select and iteratively refine\npseudo-labels, showing slower performance saturation compared to random\nselection. Evaluated on the multi-domain Wow call center and Fisher English\ncorpora, it outperforms single-step fine-tuning. Consensus-based filtering\noutperforms other methods, providing up to 22.3% relative improvement on Wow\nand 24.8% on Fisher over single-step fine-tuning with random selection. NER is\nthe second-best filter, providing competitive performance at a lower\ncomputational cost.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04997", "pdf": "https://arxiv.org/pdf/2506.04997", "abs": "https://arxiv.org/abs/2506.04997", "authors": ["Yubo Ma", "Jinsong Li", "Yuhang Zang", "Xiaobao Wu", "Xiaoyi Dong", "Pan Zhang", "Yuhang Cao", "Haodong Duan", "Jiaqi Wang", "Yixin Cao", "Aixin Sun"], "title": "Towards Storage-Efficient Visual Document Retrieval: An Empirical Study on Reducing Patch-Level Embeddings", "categories": ["cs.IR", "cs.CL"], "comment": "Accepted by ACL 2025 findings", "summary": "Despite the strong performance of ColPali/ColQwen2 in Visualized Document\nRetrieval (VDR), it encodes each page into multiple patch-level embeddings and\nleads to excessive memory usage. This empirical study investigates methods to\nreduce patch embeddings per page at minimum performance degradation. We\nevaluate two token-reduction strategies: token pruning and token merging.\nRegarding token pruning, we surprisingly observe that a simple random strategy\noutperforms other sophisticated pruning methods, though still far from\nsatisfactory. Further analysis reveals that pruning is inherently unsuitable\nfor VDR as it requires removing certain page embeddings without query-specific\ninformation. Turning to token merging (more suitable for VDR), we search for\nthe optimal combinations of merging strategy across three dimensions and\ndevelop Light-ColPali/ColQwen2. It maintains 98.2% of retrieval performance\nwith only 11.8% of original memory usage, and preserves 94.6% effectiveness at\n2.8% memory footprint. We expect our empirical findings and resulting\nLight-ColPali/ColQwen2 offer valuable insights and establish a competitive\nbaseline for future research towards efficient VDR.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05000", "pdf": "https://arxiv.org/pdf/2506.05000", "abs": "https://arxiv.org/abs/2506.05000", "authors": ["Yongjie Xiao", "Hongru Liang", "Peixin Qin", "Yao Zhang", "Wenqiang Lei"], "title": "SCOP: Evaluating the Comprehension Process of Large Language Models from a Cognitive View", "categories": ["cs.CL"], "comment": "arXiv admin note: text overlap with arXiv:2004.14535 by other authors", "summary": "Despite the great potential of large language models(LLMs) in machine\ncomprehension, it is still disturbing to fully count on them in real-world\nscenarios. This is probably because there is no rational explanation for\nwhether the comprehension process of LLMs is aligned with that of experts. In\nthis paper, we propose SCOP to carefully examine how LLMs perform during the\ncomprehension process from a cognitive view. Specifically, it is equipped with\na systematical definition of five requisite skills during the comprehension\nprocess, a strict framework to construct testing data for these skills, and a\ndetailed analysis of advanced open-sourced and closed-sourced LLMs using the\ntesting data. With SCOP, we find that it is still challenging for LLMs to\nperform an expert-level comprehension process. Even so, we notice that LLMs\nshare some similarities with experts, e.g., performing better at comprehending\nlocal information than global information. Further analysis reveals that LLMs\ncan be somewhat unreliable -- they might reach correct answers through flawed\ncomprehension processes. Based on SCOP, we suggest that one direction for\nimproving LLMs is to focus more on the comprehension process, ensuring all\ncomprehension skills are thoroughly developed during training.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05023", "pdf": "https://arxiv.org/pdf/2506.05023", "abs": "https://arxiv.org/abs/2506.05023", "authors": ["Enno Adler", "Stefan Böttcher", "Rita Hartel"], "title": "Compressing Hypergraphs using Suffix Sorting", "categories": ["cs.DS"], "comment": null, "summary": "Hypergraphs model complex, non-binary relationships like co-authorships,\nsocial group memberships, and recommendations. Like traditional graphs,\nhypergraphs can grow large, posing challenges for storage, transmission, and\nquery performance. We propose HyperCSA, a novel compression method for\nhypergraphs that maintains support for standard queries over the succinct\nrepresentation. HyperCSA achieves compression ratios of 26% to 79% of the\noriginal file size on real-world hypergraphs - outperforming existing methods\non all large hypergraphs in our experiments. Additionally, HyperCSA scales to\nlarger datasets than existing approaches. Furthermore, for common real-world\nhypergraphs, HyperCSA evaluates neighbor queries 6 to 40 times faster than both\nstandard data structures and other hypergraph compression approaches.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05038", "pdf": "https://arxiv.org/pdf/2506.05038", "abs": "https://arxiv.org/abs/2506.05038", "authors": ["Yutao Hou", "Zeguan Xiao", "Fei Yu", "Yihan Jiang", "Xuetao Wei", "Hailiang Huang", "Yun Chen", "Guanhua Chen"], "title": "Automatic Robustness Stress Testing of LLMs as Mathematical Problem Solvers", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have achieved distinguished performance on\nvarious reasoning-intensive tasks. However, LLMs might still face the\nchallenges of robustness issues and fail unexpectedly in some simple reasoning\ntasks. Previous works evaluate the LLM robustness with hand-crafted templates\nor a limited set of perturbation rules, indicating potential data contamination\nin pre-training or fine-tuning datasets. In this work, inspired by stress\ntesting in software engineering, we propose a novel framework, Automatic\nRobustness Checker (AR-Checker), to generate mathematical problem variants that\nmaintain the semantic meanings of the original one but might fail the LLMs. The\nAR-Checker framework generates mathematical problem variants through\nmulti-round parallel streams of LLM-based rewriting and verification. Our\nframework can generate benchmark variants dynamically for each LLM, thus\nminimizing the risk of data contamination. Experiments on GSM8K and MATH-500\ndemonstrate the strong performance of AR-Checker on mathematical tasks. We also\nevaluate AR-Checker on benchmarks beyond mathematics, including MMLU, MMLU-Pro,\nand CommonsenseQA, where it also achieves strong performance, further proving\nthe effectiveness of AR-Checker.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05044", "pdf": "https://arxiv.org/pdf/2506.05044", "abs": "https://arxiv.org/abs/2506.05044", "authors": ["Xiaokun Zhang", "Bo Xu", "Fenglong Ma", "Zhizheng Wang", "Liang Yang", "Hongfei Lin"], "title": "Rethinking Contrastive Learning in Session-based Recommendation", "categories": ["cs.IR"], "comment": "This work has been accepted by Pattern Recognition", "summary": "Session-based recommendation aims to predict intents of anonymous users based\non limited behaviors. With the ability in alleviating data sparsity,\ncontrastive learning is prevailing in the task. However, we spot that existing\ncontrastive learning based methods still suffer from three obstacles: (1) they\noverlook item-level sparsity and primarily focus on session-level sparsity; (2)\nthey typically augment sessions using item IDs like crop, mask and reorder,\nfailing to ensure the semantic consistency of augmented views; (3) they treat\nall positive-negative signals equally, without considering their varying\nutility. To this end, we propose a novel multi-modal adaptive contrastive\nlearning framework called MACL for session-based recommendation. In MACL, a\nmulti-modal augmentation is devised to generate semantically consistent views\nat both item and session levels by leveraging item multi-modal features.\nBesides, we present an adaptive contrastive loss that distinguishes varying\ncontributions of positive-negative signals to improve self-supervised learning.\nExtensive experiments on three real-world datasets demonstrate the superiority\nof MACL over state-of-the-art methods.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05062", "pdf": "https://arxiv.org/pdf/2506.05062", "abs": "https://arxiv.org/abs/2506.05062", "authors": ["Noy Sternlicht", "Ariel Gera", "Roy Bar-Haim", "Tom Hope", "Noam Slonim"], "title": "Debatable Intelligence: Benchmarking LLM Judges via Debate Speech Evaluation", "categories": ["cs.CL"], "comment": "Code: https://github.com/noy-sternlicht/Debatable-Intelligence", "summary": "We introduce Debate Speech Evaluation as a novel and challenging benchmark\nfor assessing LLM judges. Evaluating debate speeches requires a deep\nunderstanding of the speech at multiple levels, including argument strength and\nrelevance, the coherence and organization of the speech, the appropriateness of\nits style and tone, and so on. This task involves a unique set of cognitive\nabilities that have previously received limited attention in systematic LLM\nbenchmarking. To explore such skills, we leverage a dataset of over 600\nmeticulously annotated debate speeches and present the first in-depth analysis\nof how state-of-the-art LLMs compare to human judges on this task. Our findings\nreveal a nuanced picture: while larger models can approximate individual human\njudgments in some respects, they differ substantially in their overall judgment\nbehavior. We also investigate the ability of frontier LLMs to generate\npersuasive, opinionated speeches, showing that models may perform at a human\nlevel on this task.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05070", "pdf": "https://arxiv.org/pdf/2506.05070", "abs": "https://arxiv.org/abs/2506.05070", "authors": ["Tianjiao Li", "Mengran Yu", "Chenyu Shi", "Yanjun Zhao", "Xiaojing Liu", "Qiang Zhang", "Qi Zhang", "Xuanjing Huang", "Jiayin Wang"], "title": "RIVAL: Reinforcement Learning with Iterative and Adversarial Optimization for Machine Translation", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) possess strong multilingual capabilities, and\ncombining Reinforcement Learning from Human Feedback (RLHF) with translation\ntasks has shown great potential. However, we observe that this paradigm\nperforms unexpectedly poorly when applied to colloquial subtitle translation\ntasks. In this work, we investigate this issue and find that the offline reward\nmodel (RM) gradually diverges from the online LLM due to distributional shift,\nultimately leading to undesirable training outcomes. To address this, we\npropose RIVAL, an adversarial training framework that formulates the process as\na min-max game between the RM and the LLM. RIVAL iteratively updates the both\nmodels, with the RM trained to distinguish strong from weak translations\n(qualitative preference reward), and the LLM trained to enhance its translation\nfor closing this gap. To stabilize training and improve generalizability, we\nalso incorporate quantitative preference reward (e.g., BLEU) into the RM,\nenabling reference-free quality modeling aligned with human evaluation. Through\nextensive experiments, we demonstrate that the proposed adversarial training\nframework significantly improves upon translation baselines.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05073", "pdf": "https://arxiv.org/pdf/2506.05073", "abs": "https://arxiv.org/abs/2506.05073", "authors": ["Soumitra Ghosh", "Gopendra Vikram Singh", "Shambhavi", "Sabarna Choudhury", "Asif Ekbal"], "title": "Just a Scratch: Enhancing LLM Capabilities for Self-harm Detection through Intent Differentiation and Emoji Interpretation", "categories": ["cs.CL"], "comment": "To be published in the Proceedings of the 63rd Annual Meeting of the\n  Association for Computational Linguistics (ACL 2025 Main)", "summary": "Self-harm detection on social media is critical for early intervention and\nmental health support, yet remains challenging due to the subtle,\ncontext-dependent nature of such expressions. Identifying self-harm intent aids\nsuicide prevention by enabling timely responses, but current large language\nmodels (LLMs) struggle to interpret implicit cues in casual language and\nemojis. This work enhances LLMs' comprehension of self-harm by distinguishing\nintent through nuanced language-emoji interplay. We present the Centennial\nEmoji Sensitivity Matrix (CESM-100), a curated set of 100 emojis with\ncontextual self-harm interpretations and the Self-Harm Identification aNd\nintent Extraction with Supportive emoji sensitivity (SHINES) dataset, offering\ndetailed annotations for self-harm labels, casual mentions (CMs), and serious\nintents (SIs). Our unified framework: a) enriches inputs using CESM-100; b)\nfine-tunes LLMs for multi-task learning: self-harm detection (primary) and\nCM/SI span detection (auxiliary); c) generates explainable rationales for\nself-harm predictions. We evaluate the framework on three state-of-the-art\nLLMs-Llama 3, Mental-Alpaca, and MentalLlama, across zero-shot, few-shot, and\nfine-tuned scenarios. By coupling intent differentiation with contextual cues,\nour approach commendably enhances LLM performance in both detection and\nexplanation tasks, effectively addressing the inherent ambiguity in self-harm\nsignals. The SHINES dataset, CESM-100 and codebase are publicly available at:\nhttps://www.iitp.ac.in/~ai-nlp-ml/resources.html#SHINES .", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05076", "pdf": "https://arxiv.org/pdf/2506.05076", "abs": "https://arxiv.org/abs/2506.05076", "authors": ["Darren Leniston", "David Ryan", "Ammar Malik", "Jack Jackman", "Terence O'Donnell"], "title": "Cloud-Based Interoperability in Residential Energy Systems", "categories": ["eess.SY", "cs.SY"], "comment": "15 pages, 12 figures, GIECS 2025 conference", "summary": "As distributed energy resources (DERs) such as solar PV, batteries and\nelectric vehicles become increasingly prevalent at the edge, maintaining grid\nstability requires advanced monitoring and control mechanisms. This paper\npresents a scalable smart grid gateway architecture that enables\ninteroperability between Modbus-based inverters and IEEE 2030.5 cloud-based\ncontrol systems. The proposed solution leverages Azure cloud services and\nedge-computing gateway devices to support dynamic configuration, telemetry\ningestion, remote control and Volt-VAR Curve deployment. A microservice-based\narchitecture ensures flexibility and scalability across diverse deployment\nscenarios, including both gateway-mediated and direct-to-cloud device\ncommunication. Results demonstrate the successful mapping of a Fronius Primo\ninverter's Modbus registers to IEEE 2030.5-compliant telemetry and control\nfunctions. Additionally, we evaluate real-time VVC updates and their impact on\nlocal voltage regulation, showcasing dynamic cloud-to-edge control with minimal\nlatency. This work highlights the potential of virtualised, standards-based\ncontrol infrastructures to support DER integration and active grid\nparticipation, while remaining adaptable to evolving smart grid architectures.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05107", "pdf": "https://arxiv.org/pdf/2506.05107", "abs": "https://arxiv.org/abs/2506.05107", "authors": ["Tianyi Huang", "Zikun Cui", "Cuiqianhe Du", "Chia-En Chiang"], "title": "CL-ISR: A Contrastive Learning and Implicit Stance Reasoning Framework for Misleading Text Detection on Social Media", "categories": ["cs.CL"], "comment": "6 pages, 2 figures", "summary": "Misleading text detection on social media platforms is a critical research\narea, as these texts can lead to public misunderstanding, social panic and even\neconomic losses. This paper proposes a novel framework - CL-ISR (Contrastive\nLearning and Implicit Stance Reasoning), which combines contrastive learning\nand implicit stance reasoning, to improve the detection accuracy of misleading\ntexts on social media. First, we use the contrastive learning algorithm to\nimprove the model's learning ability of semantic differences between truthful\nand misleading texts. Contrastive learning could help the model to better\ncapture the distinguishing features between different categories by\nconstructing positive and negative sample pairs. This approach enables the\nmodel to capture distinguishing features more effectively, particularly in\nlinguistically complicated situations. Second, we introduce the implicit stance\nreasoning module, to explore the potential stance tendencies in the text and\ntheir relationships with related topics. This method is effective for\nidentifying content that misleads through stance shifting or emotional\nmanipulation, because it can capture the implicit information behind the text.\nFinally, we integrate these two algorithms together to form a new framework,\nCL-ISR, which leverages the discriminative power of contrastive learning and\nthe interpretive depth of stance reasoning to significantly improve detection\neffect.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05121", "pdf": "https://arxiv.org/pdf/2506.05121", "abs": "https://arxiv.org/abs/2506.05121", "authors": ["Hong-Yun Lin", "Tien-Hong Lo", "Yu-Hsuan Fang", "Jhen-Ke Lin", "Chung-Chun Wang", "Hao-Chien Lu", "Berlin Chen"], "title": "The NTNU System at the S&I Challenge 2025 SLA Open Track", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "submitted to the ISCA SLaTE-2025 Workshop", "summary": "A recent line of research on spoken language assessment (SLA) employs neural\nmodels such as BERT and wav2vec 2.0 (W2V) to evaluate speaking proficiency\nacross linguistic and acoustic modalities. Although both models effectively\ncapture features relevant to oral competence, each exhibits modality-specific\nlimitations. BERT-based methods rely on ASR transcripts, which often fail to\ncapture prosodic and phonetic cues for SLA. In contrast, W2V-based methods\nexcel at modeling acoustic features but lack semantic interpretability. To\novercome these limitations, we propose a system that integrates W2V with Phi-4\nmultimodal large language model (MLLM) through a score fusion strategy. The\nproposed system achieves a root mean square error (RMSE) of 0.375 on the\nofficial test set of the Speak & Improve Challenge 2025, securing second place\nin the competition. For comparison, the RMSEs of the top-ranked, third-ranked,\nand official baseline systems are 0.364, 0.384, and 0.444, respectively.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05136", "pdf": "https://arxiv.org/pdf/2506.05136", "abs": "https://arxiv.org/abs/2506.05136", "authors": ["Taiga Someya", "Anej Svete", "Brian DuSell", "Timothy J. O'Donnell", "Mario Giulianelli", "Ryan Cotterell"], "title": "Information Locality as an Inductive Bias for Neural Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Inductive biases are inherent in every machine learning system, shaping how\nmodels generalize from finite data. In the case of neural language models\n(LMs), debates persist as to whether these biases align with or diverge from\nhuman processing constraints. To address this issue, we propose a quantitative\nframework that allows for controlled investigations into the nature of these\nbiases. Within our framework, we introduce $m$-local entropy$\\unicode{x2013}$an\ninformation-theoretic measure derived from average lossy-context\nsurprisal$\\unicode{x2013}$that captures the local uncertainty of a language by\nquantifying how effectively the $m-1$ preceding symbols disambiguate the next\nsymbol. In experiments on both perturbed natural language corpora and languages\ndefined by probabilistic finite-state automata (PFSAs), we show that languages\nwith higher $m$-local entropy are more difficult for Transformer and LSTM LMs\nto learn. These results suggest that neural LMs, much like humans, are highly\nsensitive to the local statistical structure of a language.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05142", "pdf": "https://arxiv.org/pdf/2506.05142", "abs": "https://arxiv.org/abs/2506.05142", "authors": ["Diege Sun", "Guanyi Chen", "Fan Zhao", "Xiaorong Cheng", "Tingting He"], "title": "Do Large Language Models Judge Error Severity Like Humans?", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used as automated evaluators in\nnatural language generation, yet it remains unclear whether they can accurately\nreplicate human judgments of error severity. In this study, we systematically\ncompare human and LLM assessments of image descriptions containing controlled\nsemantic errors. We extend the experimental framework of van Miltenburg et al.\n(2020) to both unimodal (text-only) and multimodal (text + image) settings,\nevaluating four error types: age, gender, clothing type, and clothing colour.\nOur findings reveal that humans assign varying levels of severity to different\nerror types, with visual context significantly amplifying perceived severity\nfor colour and type errors. Notably, most LLMs assign low scores to gender\nerrors but disproportionately high scores to colour errors, unlike humans, who\njudge both as highly severe but for different reasons. This suggests that these\nmodels may have internalised social norms influencing gender judgments but lack\nthe perceptual grounding to emulate human sensitivity to colour, which is\nshaped by distinct neural mechanisms. Only one of the evaluated LLMs, Doubao,\nreplicates the human-like ranking of error severity, but it fails to\ndistinguish between error types as clearly as humans. Surprisingly,\nDeepSeek-V3, a unimodal LLM, achieves the highest alignment with human\njudgments across both unimodal and multimodal conditions, outperforming even\nstate-of-the-art multimodal models.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05156", "pdf": "https://arxiv.org/pdf/2506.05156", "abs": "https://arxiv.org/abs/2506.05156", "authors": ["Thomas Depian", "Simon D. Fink", "Robert Ganian", "Martin Nöllenburg"], "title": "The Peculiarities of Extending Queue Layouts", "categories": ["cs.CG", "cs.DS"], "comment": "Appears in the Proceedings of the 51st International Workshop on\n  Graph-Theoretic Concepts in Computer Science (WG 2025); 24 pages, 6 figures,\n  1 table", "summary": "We consider the problem of computing $\\ell$-page queue layouts, which are\nlinear arrangements of vertices accompanied with an assignment of the edges to\npages from one to $\\ell$ that avoid the nesting of edges on any of the pages.\nInspired by previous work in the extension of stack layouts, here we consider\nthe setting of extending a partial $\\ell$-page queue layout into a complete one\nand primarily analyze the problem through the refined lens of parameterized\ncomplexity. We obtain novel algorithms and lower bounds which provide a\ndetailed picture of the problem's complexity under various measures of\nincompleteness, and identify surprising distinctions between queue and stack\nlayouts in the extension setting.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05158", "pdf": "https://arxiv.org/pdf/2506.05158", "abs": "https://arxiv.org/abs/2506.05158", "authors": ["Thomas A. Henzinger", "Pavol Kebis", "Nicolas Mazzocchi", "N. Ege Saraç"], "title": "Quantitative Language Automata", "categories": ["cs.FL"], "comment": "Full version of the CONCUR 2025 paper", "summary": "A quantitative word automaton (QWA) defines a function from infinite words to\nvalues. For example, every infinite run of a limit-average QWA A obtains a mean\npayoff, and every word w is assigned the maximal mean payoff obtained by\nnondeterministic runs of A over w. We introduce quantitative language automata\n(QLAs) that define functions from language generators (i.e., implementations)\nto values, where a language generator can be nonprobabilistic, defining a set\nof infinite words, or probabilistic, defining a probability measure over\ninfinite words. A QLA consists of a QWA and an aggregator function. For\nexample, given a QWA A, the infimum aggregator maps each language L to the\ngreatest lower bound assigned by A to any word in L. For boolean value sets,\nQWAs define boolean properties of traces, and QLAs define boolean properties of\nsets of traces, i.e., hyperproperties. For more general value sets, QLAs serve\nas a specification language for a generalization of hyperproperties, called\nquantitative hyperproperties. A nonprobabilistic (resp. probabilistic)\nquantitative hyperproperty assigns a value to each set (resp. distribution) G\nof traces, e.g., the minimal (resp. expected) average response time exhibited\nby the traces in G. We give several examples of quantitative hyperproperties\nand investigate three paradigmatic problems for QLAs: evaluation, nonemptiness,\nand universality. In the evaluation problem, given a QLA AA and an\nimplementation G, we ask for the value that AA assigns to G. In the\nnonemptiness (resp. universality) problem, given a QLA AA and a value k, we ask\nwhether AA assigns at least k to some (resp. every) language. We provide a\ncomprehensive picture of decidability for these problems for QLAs with common\naggregators as well as their restrictions to omega-regular languages and trace\ndistributions generated by finite-state Markov chains.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05164", "pdf": "https://arxiv.org/pdf/2506.05164", "abs": "https://arxiv.org/abs/2506.05164", "authors": ["Pasquale Cascarano", "Andrea Loretti", "Matteo Martinoni", "Luca Zanuttini", "Alessio Di Pasquale", "Gustavo Marfia"], "title": "Towards the target and not beyond: 2d vs 3d visual aids in mr-based neurosurgical simulation", "categories": ["cs.GR"], "comment": "15 pages, 7 figures, 3 tables, journal", "summary": "Neurosurgery increasingly uses Mixed Reality (MR) technologies for\nintraoperative assistance. The greatest challenge in this area is mentally\nreconstructing complex 3D anatomical structures from 2D slices with millimetric\nprecision, which is required in procedures like External Ventricular Drain\n(EVD) placement. MR technologies have shown great potential in improving\nsurgical performance, however, their limited availability in clinical settings\nunderscores the need for training systems that foster skill retention in\nunaided conditions. In this paper, we introduce NeuroMix, an MR-based simulator\nfor EVD placement. We conduct a study with 48 participants to assess the impact\nof 2D and 3D visual aids on usability, cognitive load, technology acceptance,\nand procedure precision and execution time. Three training modalities are\ncompared: one without visual aids, one with 2D aids only, and one combining\nboth 2D and 3D aids. The training phase takes place entirely on digital\nobjects, followed by a freehand EVD placement testing phase performed with a\nphysical catherer and a physical phantom without MR aids. We then compare the\nparticipants performance with that of a control group that does not undergo\ntraining. Our findings show that participants trained with both 2D and 3D aids\nachieve a 44\\% improvement in precision during unaided testing compared to the\ncontrol group, substantially higher than the improvement observed in the other\ngroups. All three training modalities receive high usability and technology\nacceptance ratings, with significant equivalence across groups. The combination\nof 2D and 3D visual aids does not significantly increase cognitive workload,\nthough it leads to longer operation times during freehand testing compared to\nthe control group.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05171", "pdf": "https://arxiv.org/pdf/2506.05171", "abs": "https://arxiv.org/abs/2506.05171", "authors": ["Linxuan He", "Qing-Shan Jia", "Ang Li", "Hongyan Sang", "Ling Wang", "Jiwen Lu", "Tao Zhang", "Jie Zhou", "Yi Zhang", "Yisen Wang", "Peng Wei", "Zhongyuan Wang", "Henry X. Liu", "Shuo Feng"], "title": "Towards provable probabilistic safety for scalable embodied AI systems", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "Embodied AI systems, comprising AI models and physical plants, are\nincreasingly prevalent across various applications. Due to the rarity of system\nfailures, ensuring their safety in complex operating environments remains a\nmajor challenge, which severely hinders their large-scale deployment in\nsafety-critical domains, such as autonomous vehicles, medical devices, and\nrobotics. While achieving provable deterministic safety--verifying system\nsafety across all possible scenarios--remains theoretically ideal, the rarity\nand complexity of corner cases make this approach impractical for scalable\nembodied AI systems. To address this challenge, we introduce provable\nprobabilistic safety, which aims to ensure that the residual risk of\nlarge-scale deployment remains below a predefined threshold. Instead of\nattempting exhaustive safety proof across all corner cases, this paradigm\nestablishes a probabilistic safety boundary on overall system performance,\nleveraging statistical methods to enhance feasibility and scalability. A\nwell-defined probabilistic safety boundary enables embodied AI systems to be\ndeployed at scale while allowing for continuous refinement of safety\nguarantees. Our work focuses on three core questions: what is provable\nprobabilistic safety, how to prove the probabilistic safety, and how to achieve\nthe provable probabilistic safety. By bridging the gap between theoretical\nsafety assurance and practical deployment, our work offers a pathway toward\nsafer, large-scale adoption of embodied AI systems in safety-critical\napplications.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05176", "pdf": "https://arxiv.org/pdf/2506.05176", "abs": "https://arxiv.org/abs/2506.05176", "authors": ["Yanzhao Zhang", "Mingxin Li", "Dingkun Long", "Xin Zhang", "Huan Lin", "Baosong Yang", "Pengjun Xie", "An Yang", "Dayiheng Liu", "Junyang Lin", "Fei Huang", "Jingren Zhou"], "title": "Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models", "categories": ["cs.CL"], "comment": null, "summary": "In this work, we introduce the Qwen3 Embedding series, a significant\nadvancement over its predecessor, the GTE-Qwen series, in text embedding and\nreranking capabilities, built upon the Qwen3 foundation models. Leveraging the\nQwen3 LLMs' robust capabilities in multilingual text understanding and\ngeneration, our innovative multi-stage training pipeline combines large-scale\nunsupervised pre-training with supervised fine-tuning on high-quality datasets.\nEffective model merging strategies further ensure the robustness and\nadaptability of the Qwen3 Embedding series. During the training process, the\nQwen3 LLMs serve not only as backbone models but also play a crucial role in\nsynthesizing high-quality, rich, and diverse training data across multiple\ndomains and languages, thus enhancing the training pipeline. The Qwen3\nEmbedding series offers a spectrum of model sizes (0.6B, 4B, 8B) for both\nembedding and reranking tasks, addressing diverse deployment scenarios where\nusers can optimize for either efficiency or effectiveness. Empirical\nevaluations demonstrate that the Qwen3 Embedding series achieves\nstate-of-the-art results across diverse benchmarks. Notably, it excels on the\nmultilingual evaluation benchmark MTEB for text embedding, as well as in\nvarious retrieval tasks, including code retrieval, cross-lingual retrieval and\nmultilingual retrieval. To facilitate reproducibility and promote\ncommunity-driven research and development, the Qwen3 Embedding models are\npublicly available under the Apache 2.0 license.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05182", "pdf": "https://arxiv.org/pdf/2506.05182", "abs": "https://arxiv.org/abs/2506.05182", "authors": ["Shivani Upadhyay", "Messiah Ataey", "Shariyar Murtuza", "Yifan Nie", "Jimmy Lin"], "title": "On the Comprehensibility of Multi-structured Financial Documents using LLMs and Pre-processing Tools", "categories": ["cs.IR"], "comment": "15 pages, 5 figures, 9 tables", "summary": "The proliferation of complex structured data in hybrid sources, such as PDF\ndocuments and web pages, presents unique challenges for current Large Language\nModels (LLMs) and Multi-modal Large Language Models (MLLMs) in providing\naccurate answers. Despite the recent advancements of MLLMs, they still often\nfalter when interpreting intricately structured information, such as nested\ntables and multi-dimensional plots, leading to hallucinations and erroneous\noutputs. This paper explores the capabilities of LLMs and MLLMs in\nunderstanding and answering questions from complex data structures found in PDF\ndocuments by leveraging industrial and open-source tools as part of a\npre-processing pipeline. Our findings indicate that GPT-4o, a popular MLLM,\nachieves an accuracy of 56% on multi-structured documents when fed documents\ndirectly, and that integrating pre-processing tools raises the accuracy of LLMs\nto 61.3% for GPT-4o and 76% for GPT-4, and with lower overall cost. The code is\npublicly available at https://github.com/OGCDS/FinancialQA.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05192", "pdf": "https://arxiv.org/pdf/2506.05192", "abs": "https://arxiv.org/abs/2506.05192", "authors": ["Christel Baier", "Rio Klatt", "Sascha Klüppelholz", "Johannes Lehmann"], "title": "Backward Responsibility in Transition Systems Beyond Safety", "categories": ["cs.FL"], "comment": null, "summary": "As the complexity of software systems rises, methods for explaining their\nbehaviour are becoming ever-more important. When a system fails, it is critical\nto determine which of its components are responsible for this failure. Within\nthe verification community, one approach uses graph games and the Shapley value\nto ascribe a responsibility value to every state of a transition system. As\nthis is done with respect to a specific failure, it is called backward\nresponsibility.\n  This paper provides tight complexity bounds for backward responsibility for\nreachability, B\\\"uchi and parity objectives. For B\\\"uchi objectives, a\npolynomial algorithm is given to determine the set of responsible states. To\nanalyse systems that are too large for standard methods, the paper presents a\nnovel refinement algorithm that iteratively computes responsibility and\ndemonstrates its utility with a prototypical implementation.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05205", "pdf": "https://arxiv.org/pdf/2506.05205", "abs": "https://arxiv.org/abs/2506.05205", "authors": ["Jackson Petty", "Michael Y. Hu", "Wentao Wang", "Shauli Ravfogel", "William Merrill", "Tal Linzen"], "title": "RELIC: Evaluating Compositional Instruction Following via Language Recognition", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly expected to perform tasks based\nonly on a specification of the task provided in context, without examples of\ninputs and outputs; this ability is referred to as instruction following. We\nintroduce the Recognition of Languages In-Context (RELIC) framework to evaluate\ninstruction following using language recognition: the task of determining if a\nstring is generated by formal grammar. Unlike many standard evaluations of\nLLMs' ability to use their context, this task requires composing together a\nlarge number of instructions (grammar productions) retrieved from the context.\nBecause the languages are synthetic, the task can be increased in complexity as\nLLMs' skills improve, and new instances can be automatically generated,\nmitigating data contamination. We evaluate state-of-the-art LLMs on RELIC and\nfind that their accuracy can be reliably predicted from the complexity of the\ngrammar and the individual example strings, and that even the most advanced\nLLMs currently available show near-chance performance on more complex grammars\nand samples, in line with theoretical expectations. We also use RELIC to\ndiagnose how LLMs attempt to solve increasingly difficult reasoning tasks,\nfinding that as the complexity of the language recognition task increases,\nmodels switch to relying on shallow heuristics instead of following complex\ninstructions.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05219", "pdf": "https://arxiv.org/pdf/2506.05219", "abs": "https://arxiv.org/abs/2506.05219", "authors": ["Cynthia Kop", "Helida Salles Santos"], "title": "Proceedings of the 19th International Workshop on Logical and Semantic Frameworks, with Applications", "categories": ["cs.LO", "cs.SC"], "comment": null, "summary": "This volume contains the post-proceedings of the 19th LSFA, which was held in\nGoi\\^ania, the capital of Goi\\'as state in Brazil, from September 18 to\nSeptember 20, 2024.\n  Logical and semantic frameworks are formal languages used to represent\nlogics, languages and systems. These frameworks provide foundations for the\nformal specification of systems and programming languages, supporting tool\ndevelopment and reasoning.\n  The aim of this series is bringing together theoreticians and practitioners\nto promote new techniques and results, from the theoretical side, and feedback\non the implementation and use of such techniques and results, from the\npractical side. LSFA includes areas such as proof and type theory, equational\ndeduction and rewriting systems, automated reasoning and concurrency theory.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05226", "pdf": "https://arxiv.org/pdf/2506.05226", "abs": "https://arxiv.org/abs/2506.05226", "authors": ["Mohammed Almutairi", "Diego Gómez-Zará"], "title": "Towards Effective Multidisciplinary Health and HCI Teams based on AI Framework", "categories": ["cs.HC"], "comment": "4 pages, 1 figure, Presented at CHI24, Workshop on Conducting\n  Research at the Intersection of HCI and Health Building and Supporting Teams\n  with Diverse Expertise to Increase Public Health Impact, May 11 to 16, 2024,\n  Honolulu, HI, USA", "summary": "As a Ph.D. student with a diverse background in both public and private\nsectors, I have encountered numerous challenges in cross-disciplinary and\nmulti-stakeholder team projects. My research on developing team compositions\nthat involve multidisciplinary members from fields including education,\nacademia, and health. Along with my advisor, we are focused on exploring how\nHCI can help individuals assemble more effective teams. This effort involves\ndeveloping socio-technical systems that guide and inform individuals of the\npotential teams that they can assemble. We employ state-of-the-art algorithms\nthat prioritize inclusion among team members from diverse areas of expertise\nand familiarity between the team members. Our goal for attending this workshop\nis to engage in meaningful dialogues with scholars and researchers, leveraging\nthese interactions to refine our approach to building an AI-driven team\ncomposition system to foster effective, interdisciplinary collaboration in\nhealth-focused HCI research.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05227", "pdf": "https://arxiv.org/pdf/2506.05227", "abs": "https://arxiv.org/abs/2506.05227", "authors": ["Adam Wiemerslage", "Katharina von der Wense"], "title": "Improving Low-Resource Morphological Inflection via Self-Supervised Objectives", "categories": ["cs.CL"], "comment": "ACL 2025 main", "summary": "Self-supervised objectives have driven major advances in NLP by leveraging\nlarge-scale unlabeled data, but such resources are scarce for many of the\nworld's languages. Surprisingly, they have not been explored much for\ncharacter-level tasks, where smaller amounts of data have the potential to be\nbeneficial. We investigate the effectiveness of self-supervised auxiliary tasks\nfor morphological inflection -- a character-level task highly relevant for\nlanguage documentation -- in extremely low-resource settings, training\nencoder-decoder transformers for 19 languages and 13 auxiliary objectives.\nAutoencoding yields the best performance when unlabeled data is very limited,\nwhile character masked language modeling (CMLM) becomes more effective as data\navailability increases. Though objectives with stronger inductive biases\ninfluence model predictions intuitively, they rarely outperform standard CMLM.\nHowever, sampling masks based on known morpheme boundaries consistently\nimproves performance, highlighting a promising direction for low-resource\nmorphological modeling.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05232", "pdf": "https://arxiv.org/pdf/2506.05232", "abs": "https://arxiv.org/abs/2506.05232", "authors": ["Suwei Yang", "Yong Lai", "Kuldeep S. Meel"], "title": "On Top-Down Pseudo-Boolean Model Counting", "categories": ["cs.LO"], "comment": "To appear in SAT 2025", "summary": "Pseudo-Boolean model counting involves computing the number of satisfying\nassignments of a given pseudo-Boolean (PB) formula. In recent years, PB model\ncounting has seen increased interest partly owing to the succinctness of PB\nformulas over typical propositional Boolean formulas in conjunctive normal form\n(CNF) at describing problem constraints. In particular, the research community\nhas developed tools to tackle exact PB model counting. These recently developed\ncounters follow one of the two existing major designs for model counters,\nnamely the bottom-up model counter design. A natural question would be whether\nthe other major design, the top-down model counter paradigm, would be effective\nat PB model counting, especially when the top-down design offered superior\nperformance in CNF model counting literature.\n  In this work, we investigate the aforementioned top-down design for PB model\ncounting and introduce the first exact top-down PB model counter, PBMC. PBMC is\na top-down search-based counter for PB formulas, with a new variable decision\nheuristic that considers variable coefficients. Through our evaluations, we\nhighlight the superior performance of PBMC at PB model counting compared to the\nexisting state-of-the-art counters PBCount, PBCounter, and Ganak. In\nparticular, PBMC could count for 1849 instances while the next-best competing\nmethod, PBCount, could only count for 1773 instances, demonstrating the\npotential of a top-down PB counter design.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05235", "pdf": "https://arxiv.org/pdf/2506.05235", "abs": "https://arxiv.org/abs/2506.05235", "authors": ["Ratna Kandala", "Prakash Mondal"], "title": "Towards a Unified System of Representation for Continuity and Discontinuity in Natural Language", "categories": ["cs.CL"], "comment": null, "summary": "Syntactic discontinuity is a grammatical phenomenon in which a constituent is\nsplit into more than one part because of the insertion of an element which is\nnot part of the constituent. This is observed in many languages across the\nworld such as Turkish, Russian, Japanese, Warlpiri, Navajo, Hopi, Dyirbal,\nYidiny etc. Different formalisms/frameworks in current linguistic theory\napproach the problem of discontinuous structures in different ways. Each\nframework/formalism has widely been viewed as an independent and non-converging\nsystem of analysis. In this paper, we propose a unified system of\nrepresentation for both continuity and discontinuity in structures of natural\nlanguages by taking into account three formalisms, in particular, Phrase\nStructure Grammar (PSG) for its widely used notion of constituency, Dependency\nGrammar (DG) for its head-dependent relations, and Categorial Grammar (CG) for\nits focus on functor-argument relations. We attempt to show that discontinuous\nexpressions as well as continuous structures can be analysed through a unified\nmathematical derivation incorporating the representations of linguistic\nstructure in these three grammar formalisms.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05243", "pdf": "https://arxiv.org/pdf/2506.05243", "abs": "https://arxiv.org/abs/2506.05243", "authors": ["Ron Eliav", "Arie Cattan", "Eran Hirsch", "Shahaf Bassan", "Elias Stengel-Eskin", "Mohit Bansal", "Ido Dagan"], "title": "CLATTER: Comprehensive Entailment Reasoning for Hallucination Detection", "categories": ["cs.CL"], "comment": null, "summary": "A common approach to hallucination detection casts it as a natural language\ninference (NLI) task, often using LLMs to classify whether the generated text\nis entailed by corresponding reference texts. Since entailment classification\nis a complex reasoning task, one would expect that LLMs could benefit from\ngenerating an explicit reasoning process, as in CoT reasoning or the explicit\n``thinking'' of recent reasoning models. In this work, we propose that guiding\nsuch models to perform a systematic and comprehensive reasoning process -- one\nthat both decomposes the text into smaller facts and also finds evidence in the\nsource for each fact -- allows models to execute much finer-grained and\naccurate entailment decisions, leading to increased performance. To that end,\nwe define a 3-step reasoning process, consisting of (i) claim decomposition,\n(ii) sub-claim attribution and entailment classification, and (iii) aggregated\nclassification, showing that such guided reasoning indeed yields improved\nhallucination detection. Following this reasoning framework, we introduce an\nanalysis scheme, consisting of several metrics that measure the quality of the\nintermediate reasoning steps, which provided additional empirical evidence for\nthe improved quality of our guided reasoning scheme.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05251", "pdf": "https://arxiv.org/pdf/2506.05251", "abs": "https://arxiv.org/abs/2506.05251", "authors": ["J. Carlos Martínez Mori", "Alejandro Toriello"], "title": "Cooperation and the Design of Public Goods", "categories": ["cs.GT", "math.OC", "91A12, 90C90, 90B06"], "comment": "26th ACM Conference on Economics and Computation (EC '25)", "summary": "We consider the cooperative elements that arise in the design of public\ngoods, such as transportation policies and infrastructure. These involve a\nvariety of stakeholders: governments, businesses, advocates, and users. Their\neventual deployment depends on the decision maker's ability to garner\nsufficient support from each of these groups; we formalize these strategic\nrequirements from the perspective of cooperative game theory. Specifically, we\nintroduce non-transferable utility, linear production (NTU LP) games, which\ncombine the game-theoretic tensions inherent in public decision-making with the\nmodeling flexibility of linear programming. We derive structural properties\nregarding the non-emptiness, representability and complexity of the core, a\nsolution concept that models the viability of cooperation. In particular, we\nprovide fairly general sufficient conditions under which the core of an NTU LP\ngame is guaranteed to be non-empty, prove that determining membership in the\ncore is co-NP-complete, and develop a cutting plane algorithm to optimize\nvarious social welfare objectives subject to core membership. Lastly, we apply\nthese results in a data-driven case study on service plan optimization for the\nChicago bus system. As our study illustrates, cooperation is necessary for the\nsuccessful deployment of transportation service plans and similar public goods,\nbut it may also have adverse or counterintuitive distributive implications.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05268", "pdf": "https://arxiv.org/pdf/2506.05268", "abs": "https://arxiv.org/abs/2506.05268", "authors": ["Selena Ling", "Abhishek Madan", "Nicholas Sharp", "Alec Jacobson"], "title": "Uniform Sampling of Surfaces by Casting Rays", "categories": ["cs.GR"], "comment": "15 pages, 17 figures, Symposium on Geometry Processing 2025", "summary": "Randomly sampling points on surfaces is an essential operation in geometry\nprocessing. This sampling is computationally straightforward on explicit\nmeshes, but it is much more difficult on other shape representations, such as\nwidely-used implicit surfaces. This work studies a simple and general scheme\nfor sampling points on a surface, which is derived from a connection to the\nintersections of random rays with the surface. Concretely, given a subroutine\nto cast a ray against a surface and find all intersections, we can use that\nsubroutine to uniformly sample white noise points on the surface. This approach\nis particularly effective in the context of implicit signed distance functions,\nwhere sphere marching allows us to efficiently cast rays and sample points,\nwithout needing to extract an intermediate mesh. We analyze the basic method to\nshow that it guarantees uniformity, and find experimentally that it is\nsignificantly more efficient than alternative strategies on a variety of\nrepresentations. Furthermore, we show extensions to blue noise sampling and\nstratified sampling, and applications to deform neural implicit surfaces as\nwell as moment estimation.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05277", "pdf": "https://arxiv.org/pdf/2506.05277", "abs": "https://arxiv.org/abs/2506.05277", "authors": ["Arseny Shur"], "title": "On Minimizers of Minimum Density", "categories": ["cs.DS", "cs.FL"], "comment": "30 pages, 4 figures", "summary": "Minimizers are sampling schemes with numerous applications in computational\nbiology. Assuming a fixed alphabet of size $\\sigma$, a minimizer is defined by\ntwo integers $k,w\\ge2$ and a linear order $\\rho$ on strings of length $k$ (also\ncalled $k$-mers). A string is processed by a sliding window algorithm that\nchooses, in each window of length $w+k-1$, its minimal $k$-mer with respect to\n$\\rho$. A key characteristic of the minimizer is its density, which is the\nexpected frequency of chosen $k$-mers among all $k$-mers in a random infinite\n$\\sigma$-ary string. Minimizers of smaller density are preferred as they\nproduce smaller samples with the same guarantee: each window is represented by\na $k$-mer.\n  The problem of finding a minimizer of minimum density for given input\nparameters $(\\sigma,k,w)$ has a huge search space of $(\\sigma^k)!$ and is\nrepresentable by an ILP of size $\\tilde\\Theta(\\sigma^{k+w})$, which has\nworst-case solution time that is doubly-exponential in $(k+w)$ under standard\ncomplexity assumptions. We solve this problem in $w\\cdot 2^{\\sigma^k+O(k)}$\ntime and provide several additional tricks reducing the practical runtime and\nsearch space. As a by-product, we describe an algorithm computing the average\ndensity of a minimizer within the same time bound. Then we propose a novel\nmethod of studying minimizers via regular languages and show how to find, via\nthe eigenvalue/eigenvector analysis over finite automata, minimizers with the\nminimal density in the asymptotic case $w\\to\\infty$. Implementing our\nalgorithms, we compute the minimum density minimizers for\n$(\\sigma,k)\\in\\{(2,2),(2,3),(2,4),(2,5),(4,2)\\}$ and \\textbf{all} $w\\ge 2$. The\nobtained densities are compared against the average density and the theoretical\nlower bounds, including the new bound presented in this paper.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05322", "pdf": "https://arxiv.org/pdf/2506.05322", "abs": "https://arxiv.org/abs/2506.05322", "authors": ["Aris Filos-Ratsikas", "Yiannis Giannakopoulos", "Alexandros Hollender", "Charalampos Kokkalis"], "title": "Equilibrium Computation in First-Price Auctions with Correlated Priors", "categories": ["cs.GT", "cs.CC"], "comment": null, "summary": "We consider the computational complexity of computing Bayes-Nash equilibria\nin first-price auctions, where the bidders' values for the item are drawn from\na general (possibly correlated) joint distribution. We show that when the\nvalues and the bidding space are discrete, determining the existence of a pure\nBayes-Nash equilibrium is NP-hard. This is the first hardness result in the\nliterature of the problem that does not rely on assumptions of subjectivity of\nthe priors, or convoluted tie-breaking rules. We then present two main\napproaches for achieving positive results, via bid sparsification and via bid\ndensification. The former is more combinatorial and is based on enumeration\ntechniques, whereas the latter makes use of the continuous theory of the\nproblem developed in the economics literature. Using these approaches, we\ndevelop polynomial-time approximation algorithms for computing equilibria in\nsymmetric settings or settings with a fixed number of bidders, for different\n(discrete or continuous) variants of the auction.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05339", "pdf": "https://arxiv.org/pdf/2506.05339", "abs": "https://arxiv.org/abs/2506.05339", "authors": ["Anirudh Bharadwaj", "Chaitanya Malaviya", "Nitish Joshi", "Mark Yatskar"], "title": "Flattery, Fluff, and Fog: Diagnosing and Mitigating Idiosyncratic Biases in Preference Models", "categories": ["cs.CL"], "comment": "Code and data available at\n  https://github.com/anirudhb123/preference-model-biases", "summary": "Language models serve as proxies for human preference judgements in alignment\nand evaluation, yet they exhibit systematic miscalibration, prioritizing\nsuperficial patterns over substantive qualities. This bias manifests as\noverreliance on features like length, structure, and style, leading to issues\nlike reward hacking and unreliable evaluations. Evidence suggests these biases\noriginate in artifacts in human training data. In this work, we systematically\ninvestigate the relationship between training data biases and preference model\nmiscalibration across five idiosyncratic features of language model\ngenerations: length, structure, jargon, sycophancy and vagueness. Using\ncontrolled counterfactual pairs, we first quantify the extent to which\npreference models favor responses with magnified biases (skew), finding this\npreference occurs in >60% of instances, and model preferences show high\nmiscalibration (~40%) compared to human preferences. Notably, bias features\nonly show mild negative correlations to human preference labels (mean r_human =\n-0.12) but show moderately strong positive correlations with labels from a\nstrong reward model (mean r_model = +0.36), suggesting that models may overrely\non spurious cues. To mitigate these issues, we propose a simple post-training\nmethod based on counterfactual data augmentation (CDA) using synthesized\ncontrastive examples. Finetuning models with CDA reduces average miscalibration\nfrom 39.4% to 32.5% and average absolute skew difference from 20.5% to 10.0%,\nwhile maintaining overall RewardBench performance, showing that targeted\ndebiasing is effective for building reliable preference models.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04279", "pdf": "https://arxiv.org/pdf/2506.04279", "abs": "https://arxiv.org/abs/2506.04279", "authors": ["Adama Nouboukpo", "Kodzo Michel Aladji", "Muktar Bappa"], "title": "Nombre Effectif de Partis Politiques en Afrique: Une Nouvelle Méthode pour un Calcul Objectif et Institutionnellement Neutre", "categories": ["physics.soc-ph", "cs.NA", "math.NA"], "comment": "in French language", "summary": "Political fragmentation in Africa poses to a significant challenge to\neffective governance and stability. Traditional measures of party system\nfragmentation, such as the Effective Number of Parties (ENP) index, often fail\nto capture the nuanced realities of African political landscapes, particularly\nthe influence of dominant parties, fluid party affiliations, and the impact of\nethnic and regional cleavages. To address these limitations, this paper\nintroduces two novel \"apolitical\" or \"institutionally neutral\" measures for\ncalculating the effective number of parties, focusing on geographical and\ndemographic dimensions, notably population size and territorial area. By\nincorporating these local realities and ensuring a minimum threshold of two\nparties, the proposed models offer a simpler and more contextually relevant\nframework for understanding political dynamics in Africa, especially in\ndata-scarce environments. This approach provides a valuable tool for analyzing\nand streamlining political systems, with potential for broader application\nbeyond the African context.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04397", "pdf": "https://arxiv.org/pdf/2506.04397", "abs": "https://arxiv.org/abs/2506.04397", "authors": ["Ariadna Sanchez", "Simon King"], "title": "Can we reconstruct a dysarthric voice with the large speech model Parler TTS?", "categories": ["eess.AS", "cs.CL", "cs.SD"], "comment": "Accepted at Interspeech 2025", "summary": "Speech disorders can make communication hard or even impossible for those who\ndevelop them. Personalised Text-to-Speech is an attractive option as a\ncommunication aid. We attempt voice reconstruction using a large speech model,\nwith which we generate an approximation of a dysarthric speaker's voice prior\nto the onset of their condition. In particular, we investigate whether a\nstate-of-the-art large speech model, Parler TTS, can generate intelligible\nspeech while maintaining speaker identity. We curate a dataset and annotate it\nwith relevant speaker and intelligibility information, and use this to\nfine-tune the model. Our results show that the model can indeed learn to\ngenerate from the distribution of this challenging data, but struggles to\ncontrol intelligibility and to maintain consistent speaker identity. We propose\nfuture directions to improve controllability of this class of model, for the\nvoice reconstruction task.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04489", "pdf": "https://arxiv.org/pdf/2506.04489", "abs": "https://arxiv.org/abs/2506.04489", "authors": ["Lukas Exl", "Sebastian Schaffer"], "title": "Spectrally accurate and efficient convolution with the 3D free-space Laplace Green's function via the super-potential", "categories": ["physics.comp-ph", "cs.NA", "math.NA", "65N35, 65N80"], "comment": "11 pages, 1 figure", "summary": "We present a high-accuracy spectral method for solving the unbounded\nthree-dimensional Poisson equation with smooth, compactly supported sources.\nThe approach is based on a super-potential formulation, where the solution is\nobtained by applying the Laplacian to a convolution with the biharmonic Green's\nfunction. A separable Gaussian-sum (GS) approximation enables efficient\nFFT-based computation with quasi-linear complexity. Owing to the improved\nregularity of the biharmonic kernel, the GS cutoff error is of order four,\neliminating the need for correction terms or Taylor expansions required in\nstandard GS or Ewald-type methods. Numerical benchmarks demonstrate that the\nmethod achieves machine-precision accuracy and outperforms existing GS-based\nschemes in both error and runtime, making it a robust and efficient tool for\nfree-space Poisson problems on uniform grids.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04518", "pdf": "https://arxiv.org/pdf/2506.04518", "abs": "https://arxiv.org/abs/2506.04518", "authors": ["Haibin Wu", "Yuxuan Hu", "Ruchao Fan", "Xiaofei Wang", "Kenichi Kumatani", "Bo Ren", "Jianwei Yu", "Heng Lu", "Lijuan Wang", "Yao Qian", "Jinyu Li"], "title": "Towards Efficient Speech-Text Jointly Decoding within One Speech Language Model", "categories": ["eess.AS", "cs.CL"], "comment": null, "summary": "Speech language models (Speech LMs) enable end-to-end speech-text modelling\nwithin a single model, offering a promising direction for spoken dialogue\nsystems. The choice of speech-text jointly decoding paradigm plays a critical\nrole in performance, efficiency, and alignment quality. In this work, we\nsystematically compare representative joint speech-text decoding\nstrategies-including the interleaved, and parallel generation paradigms-under a\ncontrolled experimental setup using the same base language model, speech\ntokenizer and training data. Our results show that the interleaved approach\nachieves the best alignment. However it suffers from slow inference due to long\ntoken sequence length. To address this, we propose a novel early-stop\ninterleaved (ESI) pattern that not only significantly accelerates decoding but\nalso yields slightly better performance. Additionally, we curate high-quality\nquestion answering (QA) datasets to further improve speech QA performance.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04652", "pdf": "https://arxiv.org/pdf/2506.04652", "abs": "https://arxiv.org/abs/2506.04652", "authors": ["Yi-Cheng Lin", "Huang-Cheng Chou", "Yu-Hsuan Li Liang", "Hung-yi Lee"], "title": "EMO-Debias: Benchmarking Gender Debiasing Techniques in Multi-Label Speech Emotion Recognition", "categories": ["eess.AS", "cs.CL"], "comment": "8 pages", "summary": "Speech emotion recognition (SER) systems often exhibit gender bias. However,\nthe effectiveness and robustness of existing debiasing methods in such\nmulti-label scenarios remain underexplored. To address this gap, we present\nEMO-Debias, a large-scale comparison of 13 debiasing methods applied to\nmulti-label SER. Our study encompasses techniques from pre-processing,\nregularization, adversarial learning, biased learners, and distributionally\nrobust optimization. Experiments conducted on acted and naturalistic emotion\ndatasets, using WavLM and XLSR representations, evaluate each method under\nconditions of gender imbalance. Our analysis quantifies the trade-offs between\nfairness and accuracy, identifying which approaches consistently reduce gender\nperformance gaps without compromising overall model performance. The findings\nprovide actionable insights for selecting effective debiasing strategies and\nhighlight the impact of dataset distributions.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04655", "pdf": "https://arxiv.org/pdf/2506.04655", "abs": "https://arxiv.org/abs/2506.04655", "authors": ["Mengjiao Bai", "Huaian Diao", "Weisheng Zhou"], "title": "Inverse elastic obstacle scattering problems by monotonicity method", "categories": ["math.AP", "cs.NA", "math.NA"], "comment": null, "summary": "We consider the elastic wave scattering problem involving rigid obstacles.\nThis work addresses the inverse problem of reconstructing the position and\nshape of such obstacles using far-field measurements. A novel\nmonotonicity-based approach is developed for this purpose. By factorizing the\nfar-field operator and utilizing the existence of localized wave functions, we\nderive a shape characterization criterion for the obstacle boundary. The\nproposed method employs monotonicity tests to determine the geometric\nrelationship between any given test domain and the actual scatterer. As a\nresult, the shape and location of rigid elastic obstacles can be uniquely\nidentified without requiring any initial guesses or prior knowledge of the\nphysical parameters of the homogeneous background medium.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04843", "pdf": "https://arxiv.org/pdf/2506.04843", "abs": "https://arxiv.org/abs/2506.04843", "authors": ["Philipp Härtel", "Michael von Bonin"], "title": "Bilevel Optimization for Improved Flexibility Aggregation Models of Electric Vehicle Fleets", "categories": ["math.OC", "cs.SY", "eess.SY"], "comment": null, "summary": "Electric vehicle (EV) fleets are expected to become an increasingly important\nsource of flexibility for power system operations. However, accurately\ncapturing the flexibility potential of numerous and heterogeneous EVs remains a\nsignificant challenge. We propose a bilevel optimization formulation to enhance\nflexibility aggregations of electric vehicle fleets. The outer level minimizes\nscheduling deviations between the aggregated and reference EV units, while the\ninner level maximizes the aggregated unit's profits. Our approach introduces\nhourly to daily scaling factor mappings to parameterize the aggregated EV\nunits. Compared to simple aggregation methods, the proposed framework reduces\nthe root-mean-square error of charging power by 78~per cent, providing more\naccurate flexibility representations. The proposed framework also provides a\nfoundation for several potential extensions in future work.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.04863", "pdf": "https://arxiv.org/pdf/2506.04863", "abs": "https://arxiv.org/abs/2506.04863", "authors": ["Blake McGrane-Corrigan", "Rafael de Andrade Moral", "Oliver Mason"], "title": "Observations on robust diffusive stability and common Lyapunov functions", "categories": ["math.DS", "cs.SY", "eess.SY", "15B48, 39A30, 92D25"], "comment": null, "summary": "We consider the problem of robust diffusive stability (RDS) for a pair of\nSchur-stable nonnegative matrices. Specifically, we show that the existence of\na common diagonal Lyapunov function is sufficient for RDS and highlight how\nthis condition differs from recently published results based on linear\ncopositive Lyapunov functions. We also present two results on RDS for extended\nLeslie matrices arising in population dynamics.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
{"id": "2506.05283", "pdf": "https://arxiv.org/pdf/2506.05283", "abs": "https://arxiv.org/abs/2506.05283", "authors": ["Michael Ruderman", "Denis Efimov"], "title": "Regularization of non-overshooting quasi-continuous sliding mode control for chattering suppression at equilibrium", "categories": ["math.OC", "cs.SY", "eess.SY"], "comment": "6 pages, 2 figures", "summary": "Robust finite-time feedback controller introduced for the second-order\nsystems in [1] can be seen as a non-overshooting quasi-continuous sliding mode\ncontrol. The paper proposes a regularization scheme to suppress inherent\nchattering due to discontinuity of the control [1] in the origin, in favor of\npractical applications. A detailed analysis with ISS and iISS proofs are\nprovided along with supporting numerical results.", "AI": {"title_translation": "错误：AI分析失败。", "tldr": null, "motivation": null, "method": null, "result": null, "conclusion": null, "translation": null, "summary": null, "comments": null, "keywords": null}}
